{"patent_id": "10-2023-0027983", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0143925", "출원번호": "10-2023-0027983", "발명의 명칭": "인공 신경망 가속 장치 및 그 방법", "출원인": "삼성전자주식회사", "발명자": "고피나트 바산스 마할레"}}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "위노그라드 도메인에서 순방향 변환 연산에 기초하여, 입력 특징 맵들을 변환하는 순방향 변환 모듈;상기 변환된 입력 특징 맵들과 변환된 커널들에 대한 곱셈 연산을 수행하고, 상기 곱셈 연산 결과들에 기초하여제1 역변환 연산을 수행하는 복수의 MAA유닛들-상기 복수의 MAA 유닛들은 에더 트리들 및 복수의 멀티플라이어를 포함함-; 및상기 제1 역변환 연산 결과에 기초하여, 출력 특징 맵(Output Feature Map, OFM)들을 생성하는 역방향 변환 모듈;을 포함하는 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 MAA 유닛들은상기 곱셈 연산 결과들과 전치된 출력 변환 행렬에 기초하여 상기 제1 역변환 연산을 수행하고,상기 역방향 변환 모듈은상기 제1 역변환 연산 결과와 상기 출력 변환 행렬 사이의 제2 역변환 연산을 수행하여 상기 출력 특징 맵들을생성하는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 MAA 유닛들은제1 MAA 유닛 세트 및 제2 MAA 유닛 세트를 포함하고,상기 제1 MAA 유닛 세트는 교대 MAA 유닛들에 대응하고, 상기 제2 MAA 유닛 세트는 상기 교대 MAA 유닛들을 제외한 나머지 MAA 유닛들에 대응하는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 MAA 유닛 세트는상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 포함하고,상기 제2 MAA 유닛 세트는상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 제외한 제2 멀티플라이어 세트를 포함하고,상기 제2 MAA 유닛 세트는상기 제1 MAA 유닛 세트에서 상기 변환된 IFM들과 상기 변환된 커널들이 상기 곱셈 연산을 수행하는 동안, 상기공개특허 10-2023-0143925-3-제2 멀티플라이어 세트의 입력 단자들에서의 제로 게이팅에 기초하여 제2 멀티플라이어 세트를 비활성화하는,인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제1 멀티플라이어 세트 중 제1 멀티플라이어 수는 상기 변환된 IFM들과 상기 변환된 커널들의 곱셈 연산을위해 상기 제1 MAA 유닛 세트에 의해 사용되고,상기 제1 멀티플라이어 세트 중 상기 제1 멀티플라이어 수가 아닌 제2 멀티플라이어 수는 상기 제2 멀티플라이어 수의 입력 단자들에서의 제로 게이팅에 기초한 곱셈동안 비활성화 되는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 복수의 MAA 유닛들은상기 곱셈 연산 결과에 대해 상기 에더 트리들에서 덧셈 연산을 이용하여 상기 제1 역변환 연산을 수행하고,상기 제1 역변환 연산 결과, 복수의 내적들을 생성하는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 역방향 변환 모듈은상기 제1 역변환 연산 결과에 대해 위노그라드 역변환 연산을 이용한 제2 역변환 연산을 수행하고,상기 제2 역변환 연산 결과에 기초하여 상기 출력 특징 맵들을 생성하는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 변환된 커널들은상기 복수의 MAA 유닛들에 의해 상기 위노그라드 도메인으로 변환되는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 각각의 입력 특징 맵들의 좌표들의 채널들을 z-first 데이터 스토리지 레이아웃에 IFM 블록들로서 저장하고,상기 IFM블록들을 IFM 페처로 전송하는 복수의 메모리 뱅크들; 및상기 IFM블록들을 페칭하는 IFM 페처를 더 포함하는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2023-0143925-4-제1항에 있어서,상기 변환된 입력 특징 맵들을 복수의 IFM 버퍼들로 분배하고,상기 복수의 MAA 유닛들 각각의 입력단에서 각 채널 당 4개의 픽셀이 함께 제공되도록 상기 변환된 IFM들을 재배열하는 데이터 스테이징 유닛(Data Staging Unit)을 더 포함하는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 순방향 변환 모듈은커널의 크기 및 입력 특징 맵의 윈도우의 위치에 기초하여, 변환 행렬 및 전치된 변환 행렬을 선택하고,상기 커널의 크기, 상기 선택된 변환 행렬 및 상기 선택된 전치된 변환 행렬에 기초하여, 상기 입력 특징 맵들을 상기 위노그라드 도메인으로 변환하여 상기 변환된 IFM들을 생성하는, 인공 신경망 가속 장치."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "위노그라드 도메인에서 순방향 변환 연산에 기초하여, 입력 특징 맵들을 변환하는 단계;복수의 MAA유닛들-상기 복수의 MAA 유닛들은 에더 트리들 및 복수의 멀티플라이어를 포함함-에서 상기 변환된입력 특징 맵들과 변환된 커널들에 대한 곱셈 연산을 수행하는 단계;상기 곱셈 연산 결과들에 기초하여 제1 역변환 연산을 수행하는 단계; 및상기 제1 역변환 연산 결과에 기초하여, 출력 특징 맵(Output Feature Map, OFM)들을 생성하는 단계;를 포함하는, 인공 신경망 가속 방법."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제1 역변환 연산을 수행하는 단계는상기 곱셈 연산 결과들과 전치된 출력 변환 행렬에 기초하여 상기 제1 역변환 연산을 수행하고,상기 출력 특징 맵들을 생성하는 단계는상기 제1 역변환 연산 결과와 상기 출력 변환 행렬 사이의 제2 역변환 연산을 수행하여 상기 출력 특징 맵들을생성하는, 인공 신경망 가속 방법."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 복수의 MAA 유닛들은제1 MAA 유닛 세트 및 제2 MAA 유닛 세트를 포함하고,상기 제1 MAA 유닛 세트는 교대 MAA 유닛들에 대응하고, 상기 제2 MAA 유닛 세트는 상기 교대 MAA 유닛들을 제외한 나머지 MAA 유닛들에 대응하는, 인공 신경망 가속 방법.공개특허 10-2023-0143925-5-청구항 15 제14항에 있어서,상기 제1 MAA 유닛 세트는상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 포함하고,상기 제2 MAA 유닛 세트는상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 제외한 제2 멀티플라이어 세트를 포함하고,상기 제2 MAA 유닛 세트는상기 제1 MAA 유닛 세트에서 상기 변환된 IFM들과 상기 변환된 커널들이 상기 곱셈 연산을 수행하는 동안, 상기제2 멀티플라이어 세트의 입력 단자들에서의 제로 게이팅에 기초하여 제2 멀티플라이어 세트를 비활성화하는,인공 신경망 가속 방법."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 제1 멀티플라이어 세트 중 제1 멀티플라이어 수는 상기 변환된 IFM들과 상기 변환된 커널들의 곱셈 연산을위해 상기 제1 MAA 유닛 세트에 의해 사용되고,상기 제1 멀티플라이어 세트 중 상기 제1 멀티플라이어 수가 아닌 제2 멀티플라이어 수는 상기 제2 멀티플라이어 수의 입력 단자들에서의 제로 게이팅에 기초한 곱셈동안 비활성화 되는, 인공 신경망 가속 방법."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 복수의 MAA 유닛들은상기 곱셈 연산 결과에 대해 상기 에더 트리들에서 덧셈 연산을 이용하여 상기 제1 역변환 연산을 수행하고,상기 제1 역변환 연산 결과, 복수의 내적들을 생성하는, 인공 신경망 가속 방법."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 출력 특징 맵들을 생성하는 단계는상기 제1 역변환 연산 결과에 대해 위노그라드 역변환 연산을 이용한 제2 역변환 연산을 수행하고,상기 제2 역변환 연산 결과에 기초하여 상기 출력 특징 맵들을 생성하는, 인공 신경망 가속 방법."}
{"patent_id": "10-2023-0027983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 변환된 커널들은상기 복수의 MAA 유닛들에 의해 상기 위노그라드 도메인으로 변환되는, 인공 신경망 가속 방법.공개특허 10-2023-0143925-6-청구항 20 제12항에 있어서,상기 각각의 입력 특징 맵들의 좌표들의 채널들을 z-first 데이터 스토리지 레이아웃에 IFM 블록들로서 저장하는 단계; 및상기 IFM블록들을 페칭하는 단계;를 더 포함하는, 인공 신경망 가속 방법."}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "아래의 개시는 인공 신경망 가속 장치 및 그 방법에 관한 것이다. 인공 신경망 가속 장치는 위노그라드 도메인 에서 순방향 변환 연산에 기초하여, 입력 특징 맵들을 변환하는 순방향 변환 모듈, 변환된 입력 특징 맵들과 변 환된 커널들에 대한 곱셈 연산을 수행하고, 곱셈 연산 결과들에 기초하여 제1 역변환 연산을 수행하는 복수의 MAA유닛들 및 제1 역변환 연산 결과에 기초하여, 출력 특징 맵(Output Feature Map, OFM)들을 생성하는 역방향 변환 모듈을 포함할 수 있다."}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 실시예들은 인공 신경망 가속 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 기술의 발전으로, 이미지 터리, 기계 번역, 물체 감지, 자율 주행 차량, 실시간 얼굴 인식등과 같은 많은 어플리케이션이 인공 지능 알고리즘, 또는 기계 학습 알고리즘을 사용하여 처리되고 있다. 신경 처리 장치 (NPU)는 일반적으로 컨볼루션 신경망(CNN), 심층 컨볼루션 네트워크(DCN), 인공 신경망(ANN) 등과 같은 예측 모 델에서 작동하여 AI/ML 알고리즘의 가속화를 위해 특별히 설계된 마이크로프로세서이다. NPU는 대형 시스템 온 칩(SoC)의 일부이거나 전용 신경망 가속기의 일부일 수 있다. NPU 자체는 클라우드 서버에 의존하지 않고 디바 이스에서 AI/ML 알고리즘을 사용하여 데이터를 처리할 수 있다. 행렬 곱셈 연산과 컨볼루션 연산은 현재 CNN의 필수적인 부분을 형성하고 있다. 컨볼루션 연산은 CNN의 기본 구성 요소이다. 에너지 제약이 있는 디바이스를 대상으로 하는 CNN의 경우, 경량의 뎁스 와이즈(depth-wise) 분 리 가능 레이어가 사용될 수 있다. 뎁스 와이즈 분리 가능 레이어에는 일반적으로 1X1 커널을 사용하는 포인트 별 3D 컨볼루션과 입력 및 출력 특징 맵의 수가 동일한 뎁스 와이즈 2D 컨볼루션의 두 가지 유형의 계산이 있을 수 있다. CNN의 연산은 대부분 계산 집약적인 컨볼루션으로 구성될 수 있다. 정확도를 잃지 않으면서 컨볼루션 의 계산 복잡도를 줄일 수 있는 컨볼루션 방법 중 하나는 위노그라드 컨볼루션일 수 있다. 위노그라드 컨볼루 션 방식은 곱셈 횟수를 줄이고 덧셈과 뺄셈 횟수를 늘리는 방식이다."}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 인공 신경망 가속 장치는 위노그라드 도메인에서 순방향 변환 연산에 기초하여, 입력 특징 맵 들을 변환하는 순방향 변환 모듈, 상기 변환된 입력 특징 맵들과 변환된 커널들에 대한 곱셈 연산을 수행하고, 상기 곱셈 연산 결과들에 기초하여 제1 역변환 연산을 수행하는 복수의 MAA유닛들-상기 복수의 MAA 유닛들은 에 더 트리들 및 복수의 멀티플라이어를 포함함- 및 상기 제1 역변환 연산 결과에 기초하여, 출력 특징 맵(Output Feature Map, OFM)들을 생성하는 역방향 변환 모듈을 포함할 수 있다. 상기 복수의 MAA 유닛들은 상기 곱셈 연산 결과들과 전치된 출력 변환 행렬에 기초하여 상기 제1 역변환 연산을 수행하고, 상기 역방향 변환 모듈은 상기 제1 역변환 연산 결과와 상기 출력 변환 행렬 사이의 제2 역변환 연산 을 수행하여 상기 출력 특징 맵들을 생성할 수 있다. 상기 복수의 MAA 유닛들은 제1 MAA 유닛 세트 및 제2 MAA 유닛 세트를 포함하고, 상기 제1 MAA 유닛 세트는 교 대 MAA 유닛들에 대응하고, 상기 제2 MAA 유닛 세트는 상기 교대 MAA 유닛들을 제외한 나머지 MAA 유닛들에 대응할 수 있다. 상기 제1 MAA 유닛 세트는 상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 포함하고, 상기 제2 MAA 유 닛 세트는 상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 제외한 제2 멀티플라이어 세트를 포함할 수 있고, 상기 제2 MAA 유닛 세트는 상기 제1 MAA 유닛 세트에서 상기 변환된 IFM들과 상기 변환된 커널들이 상기 곱셈 연산을 수행하는 동안, 상기 제2 멀티플라이어 세트의 입력 단자들에서의 제로 게이팅에 기초하여 제2 멀 티플라이어 세트를 비활성화할 수 있다. 상기 제1 멀티플라이어 세트 중 제1 멀티플라이어 수는 상기 변환된 IFM들과 상기 변환된 커널들의 곱셈 연산을 위해 상기 제1 MAA 유닛 세트에 의해 사용되고, 상기 제1 멀티플라이어 세트 중 상기 제1 멀티플라이어 수가 아 닌 제2 멀티플라이어 수는 상기 제2 멀티플라이어 수의 입력 단자들에서의 제로 게이팅에 기초한 곱셈동안 비활 성화될 수 있다. 상기 복수의 MAA 유닛들은 상기 곱셈 연산 결과에 대해 상기 에더 트리들에서 덧셈 연산을 이용하여 상기 제1 역변환 연산을 수행하고, 상기 제1 역변환 연산 결과, 복수의 내적들을 생성할 수 있다. 상기 역방향 변환 모듈은 상기 제1 역변환 연산 결과에 대해 위노그라드 역변환 연산을 이용한 제2 역변환 연산 을 수행하고, 상기 제2 역변환 연산 결과에 기초하여 상기 출력 특징 맵들을 생성할 수 있다. 상기 변환된 커널들은 상기 복수의 MAA 유닛들에 의해 상기 위노그라드 도메인으로 변환될 수 있다. 상기 각각의 입력 특징 맵들의 좌표들의 채널들을 z-first 데이터 스토리지 레이아웃에 IFM 블록들로서 저장할 수 있고, 상기 IFM블록들을 IFM 페처로 전송하는 복수의 메모리 뱅크들 및 상기 IFM블록들을 페칭하는 IFM 페처 를 더 포함할 수 있다. 상기 변환된 입력 특징 맵들을 복수의 IFM 버퍼들로 분배하고, 상기 복수의 MAA 유닛들 각각의 입력단에서 각 채널 당 4개의 픽셀이 함께 제공되도록 상기 변환된 IFM들을 재배열하는 데이터 스테이징 유닛(Data Staging Unit)을 더 포함할 수 있다. 상기 순방향 변환 모듈은 커널의 크기 및 입력 특징 맵의 윈도우의 위치에 기초하여, 변환 행렬 및 전치된 변환 행렬을 선택하고, 상기 커널의 크기, 상기 선택된 변환 행렬 및 상기 선택된 전치된 변환 행렬에 기초하여, 상 기 입력 특징 맵들을 상기 위노그라드 도메인으로 변환하여 상기 변환된 IFM들을 생성할 수 있다. 일 실시예에 따른 인공 신경망 가속 방법은 위노그라드 도메인에서 순방향 변환 연산에 기초하여, 입력 특징 맵 들을 변환하는 단계, 복수의 MAA유닛들-상기 복수의 MAA 유닛들은 에더 트리들 및 복수의 멀티플라이어를 포함 함-에서 상기 변환된 입력 특징 맵들과 변환된 커널들에 대한 곱셈 연산을 수행하는 단계 상기 곱셈 연산 결과 들에 기초하여 제1 역변환 연산을 수행하는 단계 및 상기 제1 역변환 연산 결과에 기초하여, 출력 특징 맵 (Output Feature Map, OFM)들을 생성하는 단계를 포함할 수 있다. 상기 제1 역변환 연산을 수행하는 단계는 상기 곱셈 연산 결과들과 전치된 출력 변환 행렬에 기초하여 상기 제1 역변환 연산을 수행하고, 상기 출력 특징 맵들을 생성하는 단계는 상기 제1 역변환 연산 결과와 상기 출력 변환 행렬 사이의 제2 역변환 연산을 수행하여 상기 출력 특징 맵들을 생성할 수 있다. 상기 복수의 MAA 유닛들은 제1 MAA 유닛 세트 및 제2 MAA 유닛 세트를 포함하고, 상기 제1 MAA 유닛 세트는 교 대 MAA 유닛들에 대응하고, 상기 제2 MAA 유닛 세트는 상기 교대 MAA 유닛들을 제외한 나머지 MAA 유닛들에 대 응할 수 있다. 상기 제1 MAA 유닛 세트는 상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 포함하고, 상기 제2 MAA 유 닛 세트는 상기 복수의 멀티플라이어들 중 제1 멀티플라이어 세트를 제외한 제2 멀티플라이어 세트를 포함하고, 상기 제2 MAA 유닛 세트는 상기 제1 MAA 유닛 세트에서 상기 변환된 IFM들과 상기 변환된 커널들이 상기 곱셈 연산을 수행하는 동안, 상기 제2 멀티플라이어 세트의 입력 단자들에서의 제로 게이팅에 기초하여 제2 멀티플라 이어 세트를 비활성화할 수 있다. 상기 제1 멀티플라이어 세트 중 제1 멀티플라이어 수는 상기 변환된 IFM들과 상기 변환된 커널들의 곱셈 연산을 위해 상기 제1 MAA 유닛 세트에 의해 사용되고, 상기 제1 멀티플라이어 세트 중 상기 제1 멀티플라이어 수가 아 닌 제2 멀티플라이어 수는 상기 제2 멀티플라이어 수의 입력 단자들에서의 제로 게이팅에 기초한 곱셈동안 비활 성화 할 수 있다. 상기 복수의 MAA 유닛들은 상기 곱셈 연산 결과에 대해 상기 에더 트리들에서 덧셈 연산을 이용하여 상기 제1 역변환 연산을 수행하고, 상기 제1 역변환 연산 결과, 복수의 내적들을 생성할 수 있다. 상기 출력 특징 맵들을 생성하는 단계는 상기 제1 역변환 연산 결과에 대해 위노그라드 역변환 연산을 이용한 제2 역변환 연산을 수행하고, 상기 제2 역변환 연산 결과에 기초하여 상기 출력 특징 맵들을 생성할 수 있다. 상기 변환된 커널들은 상기 복수의 MAA 유닛들에 의해 상기 위노그라드 도메인으로 변환될 수 있다. 상기 각각의 입력 특징 맵들의 좌표들의 채널들을 z-first 데이터 스토리지 레이아웃에 IFM 블록들로서 저장하 는 단계 및 상기 IFM블록들을 페칭하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에 대한 특정한 구조적 또는 기능적 설명들은 단지 예시를 위한 목적으로 개시된 것으로서, 다양한 형 태로 변경되어 구현될 수 있다. 따라서, 실제 구현되는 형태는 개시된 특정 실시예로만 한정되는 것이 아니며, 본 명세서의 범위는 실시예들로 설명한 기술적 사상에 포함되는 변경, 균등물, 또는 교대물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 해석되어야 한다. 예를 들어, 제1 구성요소는 제2 구성요소로 명 명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들 을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다.다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면들을 참조하여 상세하게 설명한다. 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부여하고, 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 일 실시예에 따른 2차원(2D) 위노그라드(Winograd) 컨볼루션(Convolution) 방법을 설명하기 위한 블록도 이다. 일 실시예에 따른 CNN(Convoution Neural Network)은 일반적으로 입력 특징 맵들(input feature maps, IFMs), 커널들(kernels) 및 출력 특징 맵들(output feature maps, OFMs)을 포함할 수 있다. 2차원 위노그라드 컨볼루 션 방법에서, 입력 행렬(input matrix)은 4Х4 크기의 세그먼트들(segments)로 나뉠 수 있다. 세그먼트들은 공 간과 변환된 도메인에서 미니 블록들이라는 용어로 불릴 수 있다. 미니 블록들(예: 도 1의 d) 및 커널들(예: 도 1의 g)은 위노그라드 도메인으로 변환될 수 있다. 또한, 역변환 연산(inverse transform operation)은 결 과 행렬들(예: 도 1의 BTdB 및 GTgGT)의 엘리먼트 와이스(element-wise) 곱셈 연산에 뒤이어서 수행될 수 있다. 예를 들어, 도 1을 참조하면, 입력 특징 맵들 및 커널들은 은 공간 및 변환된 도메인들에서 미니 블록들로 지칭 되는 4Х4 행렬인 변환된 입력 특징 맵들 및 변환된 커널들로 변환(convert)될 수 있다. 각각의 미 니 블록들(d)은 변환 행렬(B) 및 전치된 변환 행렬 BT를 사용하여 위노그라드 도메인으로 변환되어 4x4 행렬 BTdB(112-1)를 획득할 수 있다. 각각의 3x3 커널(g)은 변환 행렬 G 및 전치된 변환 행렬 GT를 사용하여 위노그 라드 도메인으로 변환되어 4x4 행렬 GgGT(111-1)를 획득할 수 있다. 행렬 B 및 G는 각각 입력 d 및 g에 대한 선형 조합을 지정(specify)할 수 있다. 그리고, 결과 행렬들(예: 도 1의 BTdB 및 GTgGT)에 대해 엘리먼트 와이 스(element-wise) 곱셈 연산을 수행하여 4x4 중간 OFM 행렬을 획득할 수 있다. 또한, 역방향 변환 모듈 은 AT(중간 OFM 행렬)A에 대한 곱셈 연산을 수행하여 최종 2x2 OFM 행렬을 생성할 수 있다. 뎁 스 와이스(depth-wise) 컨볼루션의 경우에도, IFM의 각 채널에 위노그라드 컨볼루션을 적용할 수 있다. 용어 \"모듈\"은, 예를 들면, 하드웨어, 소프트웨어 또는 펌웨어(firmware) 중 하나 또는 둘 이상의 조합을 포함 하는 단위(unit)를 의미할 수 있다. \"모듈\"은, 예를 들면, 유닛(unit), 로직(logic), 논리 블록(logical block), 부품(component), 또는 회로(circuit) 등의 용어와 바꾸어 사용(interchangeably use)될 수 있다. \"모 듈\"은, 일체로 구성된 부품의 최소 단위 또는 그 일부가 될 수 있다. \"모듈\"은 하나 또는 그 이상의 기능을 수 행하는 최소 단위 또는 그 일부가 될 수도 있다. \"모듈\"은 기계적으로 또는 전자적으로 구현될 수 있다. 예를 들면,\"모듈\"은, 알려졌거나 앞으로 개발될, 어떤 동작들을 수행하는 ASIC(application-specific integrated circuit) 칩, FPGAs(field-programmable gate arrays) 또는 프로그램 가능 논리 장치(programmable-logic device) 중 적어도 하나를 포함할 수 있다. 컨볼루션은 하나의 함수와 또 다른 함수를 반전 이동한 값을 곱한 다음, 구간에 대해 적분하여 새로운 함수를 구하는 수학 연산자일 수 있다. 컨볼루션 연산은 주어진 목적에 상응하는 필터를 선택하고, 선택된 필터로 입 력 데이터의 모든 영역을 훑으면서 입력 데이터에 대응하는 특정 특징(feature)을 추출하는 연산을 의미할 수 있다. 일례로, 시스템은 입력 데이터에 필터 데이터를 컨볼루션 연산하여 출력 데이터를 획득할 수 있고, 각 데이터는 행렬 형태로 정의될 수 있다. 데이터가 행렬 형태로 정의되는 경우, 컨볼루션 연산은 행렬 연산으로 구성될 수 있다. 행렬 연산은 행렬의 가감, 행렬의 스칼라 곱셈, 행렬의 곱셈, 행렬의 요소별 곱셈 등 복수의 행렬 사이에 가능 한 모든 연산법칙을 포함할 수 있다. 나아가, 행렬 연산은 선형방정식과 같이 행렬의 형태로 표현될 수 있는 체계들의 연산도 포함할 수 있다. 컨볼루션 연산은 행렬의 가감 연산과 행렬의 곱셈 연산의 조합으로 이루어질 수 있는데, 이 중 행렬의 곱셈 연 산에 소모되는 시간 및 전력이 행렬의 가감 연산에 소모되는 시간 및 전력보다 훨씬 클 수 있다. 시스템 관점 에서, 행렬의 곱셈 연산의 횟수를 줄이는 것이 컨볼루션 연산 처리 속도 향상 및 전력 소모 감소의 중요한 키일 수 있다. 도 2는 일 실시예에 따른 위노그라드 컨볼루션에 사용되는 행렬들을 간략하게 도시한 것이다. 도 2를 참조하면, 일 실시예에 따른 행렬 B, G 및 A는 위노그라드 컨볼루션 방법에 사용될 수 있다. 위노그라드 컨볼루션 방법은 3x3 위노그라드 컨볼루션에 대한 순방향 및 역변환(inverse transform) 연산을 포함할 수 있다. 또한, 도 2에 도시된 바와 같이, 위노그라드 컨볼루션은 행렬 B의 전치된 변환 행렬 BT 및 전치된 변환 행렬 AT를 이용할 수 있다. 2D 위노그라드 컨볼루션은 아래와 같은 수학식 1로 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, Y는 2x2 OFM을 의미하고, 는 엘리먼트 와이스 곱셈을 의미한다. 도 3은 일 실시예에 따른 3D 컨볼루션을 위한 베이스라인 아키텍쳐를 간략하게 도시한 것이다. 도 3을 참조하면, 일 실시예에 따른 베이스라인 아키텍쳐는 4개의 XMAA들(예: XMAA0, XMAA1, XMAA2 및 XMAA3)을 포함하는 8개의 XMAAG들(예: XMAAG0 내지 XMAAG7)를 포함할 수 있다. XMAAG들은 IFM 벡터 세트를 공 유하는 그룹일 수 있다. 베이스라인 아키텍쳐는 각각의 XMAA들에서 누적 배열 곱셈(Multiply Accumulate Array, MAA) 유닛들(예: MAA0, MAA1, MAA2 및 MAA3)을 더 포함할 수 있다. 각 MAA는 OFM 채널과 상이한 OFM 픽셀들에서 동작할 수 있다. 각 XMAA는 동일한 커널을 공유하는 MAA들의 그룹(MAA0, MAA1, MAA2 및 MAA3)을 포 함할 수 있고, 각 XMAAG는 IFM 벡터 세트를 공유하는 4개의 XMAA들의 그룹(XMAA0, XMAA1, XMAA2 및 XMAA3)을 포함할 수 있다. 3D 컨볼루션의 경우, IFM 벡터는 XMAAG에 포함된 모든 XMAA들에서 MAA들 간에 공유될 수 있다. 각 XMAAG는 각각 4개의 OFM 채널에서, x-y 평면에서 4개의 OFM 픽셀 계산에 기여하는 IFM 벡터들을 수신 할 수 있다. 또한, 도 3의 입력 버퍼들(예: 버퍼(Buffer) 0, 1, 2, 3)은 데이터 희소성(sparsity)이 이용되는 입력 IFM 벡터들을 저장할 수 있다. 버퍼들의 출력(예: 4x256 bits of data)은 베이스라인 아키텍쳐의 각 XMAAG에 브로드캐스트(broadcast)될 수 있다. 따라서, XMAAG들은 채널당 4픽셀을 갖는 OFM 데이터의 32 채널을 계산하고, 계산 결과에 따라서 총 4x32 OFM 픽셀이 생성될 수 있다. 베이스라인 아키텍처를 사용하는 위노그라드 컨볼루션의 경우, 순방향 및 역변환(inverse transform) 모듈 들이 베이스라인 아키텍처의 입력 및 출력에 도입(introduce)될 수 있다. 순방향 및 역변환 모듈들은 두 개의 에더 계층들(layer)을 포함할 수 있다. 베이스라인 아키텍처는 각각 16개의 입력 채널 및 8개의 출 력 채널에 대한 계산 논리가 필요할 수 있다. 따라서, 변환된 각각의 IFM 미니 블록들의 두 픽셀은 각 XMAA에 공급될 수 있고, 두 픽셀에 대응되는 미리 계산된 변환된 커널(예: 도1의 변환된 커널) 요소가 커널 버퍼 들에 채워질 수 있다. 또한, 모든 XMAAG들의 출력들은 역변환을 위해 역변환 모듈에 의해 결합되어 매 사이클 마다 2x2x8 OFM 픽셀들을 생성할 수 있다. 도 4는 일 실시예에 따른 베이스라인 아키텍처의 3D 위노그라드 컨볼루션 맵핑을 도시한 것이다. 모든 컴퓨팅 요소에서 에더 트리들을 사용하여 z 방향으로 곱셈(product)이 추가되는 기본 계산 때문에, 3D 컨 볼루션을 위해 설계된 z-first 스토리지 CNN 가속기 아키텍처(예: 도 3의 베이스라인 아키텍처)에서 뎁스 와이즈 컨볼루션을 매핑하는 것은 어려울 수 있다. 3D 컨볼루션을 위해 설계된 z-first 스토리지 CNN 가속기 아키텍처에서 뎁스 와이즈 컨볼루션의 매핑과 관련한 전술한 문제 중 적어도 하나를 극복하도록 설계될 수 있다. 예를 들어, 컴퓨팅 요소당 단일 멀티플라이어(multiplier)만을 사용하여, 리소스 사용률을 크게 줄일 수 있는 해결 방법이 있을 수 있다. 도 5는 일 실시예에 따른 베이스라인 아키텍처에서 뎁스 와이즈 컨볼루션을 매핑하는 방법을 개략적으로 도시한 것이다. 도 5를 참조하면, 일 실시예에 따른 IFM 윈도우에서 첫 번째 4개의 픽셀들 중 채널 0 내지 채널 3은 XMAAG0의 MAA0들에게 공유된 입력 벡터와 연접(concatenate)될 수 있다. 마찬가지로, 남은 12개의 채널들(채널 4 내지 채널 15)도 XMAAG1 에서 XMAAG3의 MAA0들에 입력될 수 있다. 또한, XMAAG들의 MAA1 내지 MAA3는 인접 한(adjacent) IFM으로부터 픽셀들을 수신하여, 인접한 OFM 픽셀들에 기여할 수 있다. 전술한 방법에 따라, 3D 위노그라드 컨볼루션 방법과 유사하게, 베이스라인 아키텍처에서 위노그라드 방법을 사용하는 뎁스 와이즈 컨볼루션 매핑이 가능할 수 있다. 그러나, 뎁스 와이즈 컨볼루션에서 z 방향에 따른 곱셈(product)의 추가가 필요하지 않기 때문에, 모든 MAA에서 하나의 멀티플라이어만 활성 상태를 유지할 수 있다는 문제가 있을 수 있 다. 전술한 문제로 인해 컴퓨팅 리소스의 사용률이 낮아지고, 위노그라드 방법은 성능 향상이 되지 않을 수 있 다. 그래서 일반적인 위노그라드 컨볼루션 매핑이 컴퓨팅 단위단 하나 이상의 멀티플라이어를 활용하여 리소스 활용도를 높이고, 전반적인 성능을 향상시킬 수 있는 시스템과 방법이 필요할 수 있다. 도 6a 및 도 6b는 일 실시예에 따른 위노그라드 컨볼루션 연산 수행 방법을 설명하기 위한 순서도이다. 도 7은 일 실시예에 따른 위노그라드 컨볼루션 연산을 수행하기 위한 시스템을 개략적으로 도시한 것이다. 도 1 내지 도 5를 참조한 설명은, 도 6a, 도 6b 및 도 7에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 도 6a 및 도 6b의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나 지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 6에 도시된 다수의 동작은 병렬 로 또는 동시에 수행될 수 있다. 도 7의 하나 이상의 블록들 및 블록들의 조합은 특정 기능을 수행하는 특수 목적 하드웨어 기반 컴퓨터, 또는 특수 목적 하드웨어 및 컴퓨터 명령들의 조합에 의해 구현될 수 있다. 도 6a, 도 6b 및 도 7을 참조하면, 일 실시예에 따른 시스템은 z-first 저장 CNN 가속기 상에서 에너지 효 율적인 뎁스 와이즈 위노그라드 컨볼루션 연산을 수행할 수 있다. 일 실시예에 따른 시스템의 구성요소들 의 기능에 대한 상세한 설명은 도 6 내지 도 10을 참조하여 의해 상세히 설명될 수 있다. 일 실시예에 따른 시스템은 입력 특징 맵(IFM)(예: 도 1의 입력 특징 맵) 페처(fetcher), 순방 향 변환 모듈(예: 도 1의 순방향 변환 모듈, 데이터 스테이징 유닛(Data Staging Unit, DSU), 복수의 곱하기 및 누적 어레이(Multiply and Accumulate Array, MAA) 유닛들 또는 XMAAG들(이하, 복수의 MAA 유닛들 또는 XMAAG들라고 한다) 및 역변환 모듈을 포함할 수 있다. XMAAG들 각각은 MAA들 의 그룹(예: MAA0, MAA1, MAA2 및 MAA3)을 포함하는 XMAA들의 그룹(예: XMAA0, XMAA1, XMAA2 및 XMAA3)을 포함할 수 있다. XMAA들 각각은 동일한 커널을 공유하는 MAA들의 그룹이고, XMAAG들 각각은 IFM 벡터들의 세트를 공유하는 XMAA들의 그룹이다. 또한, 시스템은 IFM 페처에 결합(couple)된 복수의 메모리 뱅크들(S0 내지 S15)를 포함할 수 있다. 전술한 시스템의 구성요소들은 시 스템 내의 하나의 구성요소로부터 다른 구성요소로 계산 데이터의 전송을 위해서 서로 결합될 수 있다. 도 7에 도시되진 않았지만, 복수의 MAA 유닛들은 복수의 에더 트리들 및 복수의 멀티플라이어들을 포함할 수 있다. 복수의 에더 트리들 및 복수의 멀티플라이어들은 각각의 XMAAG들 내의 XMAA들의 그룹 내의 MAA들의 그룹에 대응하는 에더 트리들 및 멀티플라이어들로 지칭될 수 있다. 복수의 MAA 유닛들은 XMAA들 그룹 내의 각각의 XMAA 내에서 두 세트의 MAA 유닛들(MAA0 및 MAA2) 및 (MAA1 및 MAA3)로 구성될 수 있다. 본 개시에서, (MAA0 및 MAA2)는 제1 MAA 유닛 세트로 지칭되고, (MAA1 및 MAA3)은 본 개시의 범위 를 벗어나지 않는 범위 내에서 제2 MAA유닛 세트로 지칭된다. 또한, (MAA0 및 MAA2)의 멀티플라이어는 제1 멀티 플라이어 세트로 지칭되고, (MAA1 및 MAA3)의 멀티플라이어는 본 개시의 범위를 벗어나지 않는 범위 내에서 제2 멀티플라이어 세트로 지칭된다. 일 실시예에 따른 제 1 MAA 유닛 세트는 각각의 XMAAG들의 XMAA들의 각각들 내의 MAA들들의 그 룹 내의 교대(alternate) MAA 유닛들(MAA0 및 MAA2)에 대응한다. 제1 MAA 유닛 세트는 제1 멀티플라이어 세트 를 포함할 수 있다. 제 2 MAA 유닛 세트는 각각의 XMAAG들의 XMAA들의 각각들 내의 MAA들들의 그룹 내의 교대 MAA 유닛들(MAA1 및 MAA3)에 대응한다. 제2 MAA 유닛 세트는 제2 멀티플라이어 세트를 포함할 수 있다. 일 실시예에 따른 시스템은 본 개시의 범위를 벗어나지 않는 범위 내에서 z-first NPU의 아키텍처로 지칭 될 수 있으나, 이에 한정되는 것은 아니다. 시스템은 에너지 효율적인 뎁스 와이즈 위노그라드 컨볼루션 동작을 수행하기 위한 임의의 타입의 z-first 스토리지 CNN 가속기로 지칭될 수 있다. 본 개시에서, 반정밀 도 부동 소수점(harf-precision floating-point, FP16) 산술(arithmetic) 지원을 갖는 베이스라인 아키텍처가 z-first 스토리지 CNN 가속기 상에서 에너지 효율적인 뎁스 와이즈 위노그라드 컨볼루션 연산을 수행할 수 있다. 본 개시의 베이스라인 아키텍처는 상술한 아키텍처에 한정되지 않는다. 또한, 통상의 기술자는 제안된 아키텍처의 개념이 z-first 스토리지 CNN 가속기 상에서 뎁스 와이즈 위노그라드 컨볼루션 동작을 수행하도록 구성되는 임의의 종류의 시스템에 적용될 수 있는 것을 이해할 수 있다. 전술한 FP16의 예는 단지 예시적인 것 이며, 따라서, 본 개시의 시스템은 또한 상이한 데이터 타입들을 지원할 수 있고, 정수(Integer) 데이터 타입들, 부동 소수점 데이터 타입들 등으로 한정되지 않는다. 도 6a 및 도 6b에 도시된 바와 같이, 단계들(602 내지 612 및 620 내지 623)은 도 7에 도시된 시스템을 사 용하여 수행되는 것으로 기술된다. 그러나 이 단계들(602 내지 612 및 620 내지 623)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서도 사용될 수 있을 것이다. 또한, 단계들(602 내지 612 및 620 내지 623)은은 후술하는 도 8 내지 도 10의 설명과 함께 상세히 설명될 수 있다. 또한, 시스템은 일 실시 예에 따른 인공 신경망 가속 장치를 포함할 수 있다. 도 6a는 일 실시예에 시스템이 수행하는 인공 신경망 가속 방법을 단계들(620 내지 623)으로 간략하게 도 시한 것이다. 단계에서, 일 실시예에 따른 시스템은 위노그라드 도메인에서 순방향 변환 연산에 기초하여, 입력 특 징 맵들을 변환할 수 있다. 단계에서, 일 실시예에 따른 시스템은 변환된 입력 특징 맵들과 변환된 커널들에 대한 곱셈 연산을 수행할 수 있다. 단계에서, 일 실시예에 따른 시스템은 곱셈 연산 결과들에 기초하여, 제1 역변환 연산을 수행할 수 있다. 시스템은 곱셈 연산 결과들과 전치된 출력 변환 행렬(예: 도 2의 AT)에 기초하여, 제1 역변환 연산 을 수행할 수 있다. 단계에서, 일 실시예에 따른 시스템은 제1 역변환 연산 결과에 기초하여, 출력 특징 맵들을 생성할 수 있다. 시스템은 제1 역변환 연산 결과와 출력 변환 행렬(예: 수학식 1의 행렬 A)사이의 제2 역변환 연 산을 수행하여 출력 특징 맵들을 생성할 수 있다. 상술한 단계들(620 내지 623)은 후술하는 도 6b를 참조하여 설명하는 단계들(602 내지 612)을 통해 상세히 설명 될 수 있다. 단계에서, 일 실시예에 따른 시스템에서, IFM 페처는 복수의 메모리 뱅크들로부터 입력 특징 맵 (IFM)들을 수신하고, 페칭할 수 있다. 예를 들어, 시스템의 IFM 페처는 복수의 메모리 뱅크(S0 내지 S15)로부터 수신한 IFM을 페칭(fetching)할 수 있다. 뎁스 와이즈 위노그라드 컨볼루션 모드에서, 복수의 메모리 뱅크(S0 내지 S15)는 z-first 데이터 스토리지 레이아웃에서 각각의 IFM들의 각각의 좌표의 채널들 을 IFM 블록들로서 저장하도록 구성될 수 있고, 각각의 IFM 블록의 크기는 4x4이다. 시스템의 IFM 페처는 뎁스 와이즈 위노그라드 컨볼루션 모드에서, 메모리 뱅크(S0 내지 S15)로부터 수신한 IFM을 페칭한 후, 페칭된 IFM(716-1)을 순방향 변환 모듈로 전달할 수 있다. 단계에서, 일 실시예에 따른 위노그라드 컨볼루션 모드의 순방향 변환 모듈은 페칭된 IFM(716-1)들을 수신한 후, 위노그라드 도메인에서 페칭된 IFM들(716-1)을 변환하여, 커널의 차원에 기초하는 변환된 IFM들 (716-2)을 생성할 수 있다. 예를 들어, 뎁스 와이즈 위노그라드 컨볼루션 모드에서, 순방향 변환 모듈은 위노그라드 도메인에서 IFM 페처로부터 수신된 페칭된 IFM(716-1)을 변환하고, 변환 후에 변환된 IFM들 (716-2)을 생성할 수 있다.페칭된 IFM들(716-1)을 위노그라드 도메인으로 변환하기 위해, 순방향 변환 모듈은 커널의 크기 및 IFM 윈 도우의 위치에 기초하여 변환 행렬 및 전치된 변환 행렬를 선택할 수 있다. 상기 선택 이후, 순방향 변환 모듈 은 커널의 크기, 선택된 변환 행렬 및 선택된 전치된 변환 행렬에 기초하여, 수신된 페칭된 IFM(716-1)을 위노그라드 도메인으로 변환하고, 변환된 IFM들(716-2)을 생성할 수 있다. 상기 복수의 커널의 크기는 3x3이고, 복수의 변환된 IFM들(716-2)의 크기는 4x4이다. 예를 들어, (a) 3x3, (b) 3x1, 또는 (c) 1x3 중 어느 하나의 커널 크기가 변환된 IFM을 생성하기 위해 사용될 수 있다. 일례로, 순방향 변환 모듈은 4x4 크기의 변환된 IFM을 생성하기 위해 커널의 크기가 (a) 3x3인 커널을 사용할 수 있다. 순방향 변환 모듈는 4x1 크기의 변환된 IFM을 생성하기 위해 커널 크기가 (b) 3x1인 커널을 사용할 수 있다. 순방향 변환 모듈은 크기가 1x4인 변환된 IFM을 생성하기 위해 커널 크기 가 (c) 1x3인 커널을 사용할 수 있다. 순방향 변환 모듈은 커널의 크기에 기초하여 변환 행렬 및 전치된 변환 행렬를 선택하고, 선택 후에 선택된 변환 행렬, 선택된 전치된 변환 행렬, 및 IFM 윈도우의 위치에 기초하 여 IFM을 위노그라드 도메인으로 변환할 수 있다. 전술한 커널 크기는 제한되지 기재된 실시예로 제한되지 않 고, 5 x 5의 커널 크기가 IFM을 변환하는데 사용될 수도 있다. 통상의 기술자는 기재된 실시예가 단지 예시적 인 것이며, 본 개시의 범위를 제한하려는 의도가 아님을 이해할 수 있을 것이다. 마찬가지로, 크기가 (a) 3x3, (b) 3x1 또는 (c) 1x3인 커널 중 하나를 사용하여 변환된 커널(예: 도 1의 변환된 커널)을 생성할 수 있다. 예를 들어, 순방향 변환 모듈은 4x4 크기의 변환된 커널을 생성하기 위해 커널 크기가 (a) 3x3인 커널을 사용할 수 있다. 순방향 변환 모듈은 4x1 크기의 변환된 커널을 생성하기 위해 커널 크기가 (b) 3x1인 을 사용할 수 있고, 1x4 크기의 변환된 커널을 생성하기 위해 커널 크기가 (c) 1x3 인 커널을 사용할 수 있다. 일 실시예에 따른 순방향 변환 모듈은 변환된 IFM들(716-2)을 데이터 스테이징 유닛(DSU)으로 전송할 수 있다. DSU는 변환된 IFM들(716-2)을 복수의 IFM 버퍼들(예: 버퍼 0, 1, 2, 3)로 분배할 수 있다. 또 한, DSU는 복수의 MAA 유닛들의 교대 MAA 유닛들(MAA0 및 MAA2) 각각의 입력 단자에 각각의 채널로부 터의 4개의 픽셀들이 함께 제공되도록 변환된 IFM들(716-2)을 재배열할 수 있다. 특히, 변환된 IFM들(716-2)은 각각의 채널들로부터의 4개의 픽셀들이 각각의 XMAAG들의 XMAA들 각각들 내의 MAA들의 그룹들의 교대 MAA들 각각의 입력 단자에 함께 제공되는 방식으로, DSU에 의해 재배열될 수 있다. 변환된 IFM들 (716-2)을 복수의 IFM 버퍼(예를 들어, 버퍼 0, 1, 2, 3)로 분배하는 예시는 후술하는 도 8을 참조하여 상세히 설명된다. 도 8은 일 실시예에 따른 데이터 버퍼 내로의 순방향 변환 IFM들의 예시적인 분포를 도시한 것이다. 도 1 내지 도 7을 참조한 설명은, 도 8에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 도 6 및 도 8을 참조하면, 단계에서, 일 실시예에 따른 시스템은 순방향 변환 모듈을 통해 복수 의 메모리 뱅크에서 데이터 버퍼로 판독(read)되는 데이터 인덱스들을 생성할 수 있다. 시스템의 DSU는 순방향 변환 모듈로부터 변환된 IFM들(716-2)을 판독한 다음, IFM 버퍼의 인덱스에 따라 변환 된 IFM들(716-2)을 IFM 버퍼로 분배할 수 있다. 따라서, DSU는 각각의 XMAAG들의 모든 이용 가능한 XMAA들 사이에 입력 데이터를 분배할 수 있다. 단계에서, 변환된 IFM들(716-2)의 생성 후에, 복수의 MAA 유닛들 중에서 교대 MAA 유닛들은 변환된 커널(예: 도 1의 변환된 커널)들과 변환된 IFM들을 곱하여 복수의 곱셈을 생성할 수 있다. 예를 들어, 복 수의 MAA 유닛들은 각각의 XMAAG들들의 XMAA들 각각들 내의 MAA들의 그룹 내의 교대 MAA 유닛들(MAA0 및 MAA2) 내에서 변환된 커널들과 변환된 IFM들을 곱하여 복수의 곱셈(product)들을 생성할 수 있 다. 4×4 크기의 변환된 커널이 곱셈 연산에 사용될 수 있다. 단계에서, 교대 MAA 유닛들에서 변환된 IFM을 변환된 커널과 곱한 후에, 시스템의 복수의 MAA 유닛들 은 생성된 복수의 곱셈(products)들을 더하여, 복수의 내적(dot product)들을 생성할 수 있고, 위노그라드 역변환 연산에 대한 제1 행렬 곱셈을 실현할 수 있다. 제1 행렬 곱셈은 전술한 제1 역변환 연산에 대응할 수 있다. 생성된 복수의 내적은 생성된 복수의 곱셈(product)의 덧셈에 기초한 엘리먼트 와이즈 곱셈 연산의 출력 결과에 대응할 수 있다. 복수의 내적들은 전술한 제1 역변환 연산 결과들에 대응할 수 있다. 예를 들어, 복수 의 MAA 유닛들의 복수의 에더 트리들은 생성된 복수의 곱셈(product)들을 더하고, 그 후에 복수의 내적을 생성할 수 있다. 전술한 곱셈 및 덧셈의 계산 예시는 도 9 및 도 10을 참조하여 상세히 설명될 수 있다.도 9는 일 실시예에 따른 뎁스 와이즈 위노그라드 컨볼루션 모드에서 XMAA들이 수행하는 계산 예를 도시한 것 이다. 도 10은 일 실시예에 따른 뎁스 와이즈 위노그라드 컨볼루션 모드에서 XMAAG들이 수행하는 계산 예를 도시한 것이다. 도 9를 참조하면, 시스템은 멀티플라이어를 사용하여 교대 MAA 유닛에서 변환된 커널(예: 도 1의 변환된 커널)과 변환된 IFM을 곱하고, 또한 에더 트리를 사용하여 생성된 복수의 곱셈을 더할 수 있다. 일 실시예에 따르면, 제1 역변환 연산은 복수의 MAA 유닛들에서 수행될 수 있다. 역변환 행렬(예: 도 2의 AT)이 덧셈과 뺄셈으로 구성되기 때문에, 덧셈 및 뺄셈 연산들은 복수의 MAA 유닛들의 에더 트리들에서 에 더들을 사용하여 실현될 수 있다. 역변환 행렬의 2개의 행은 서로 다른 덧셈 및 빼기를 포함하기 때문에, 복수 의 MAA 유닛들 중 교대 MAA 유닛들에서 생성된 곱셈들은 각각 2개의 MAA 사이의 바이패스 경로를 사용하여 (MAA0, MAA1) 및 (MAA2, MAA3)의 에더 트리에 공유될 수 있다. \"바이패스\"는 MAA1 및 MAA3의 에더 트리에서 멀티플라이어로부터의 곱셈(product)들이 사용되지 않음을 의미한다. 그러나, 복수의 MAA 유닛들 중 MAA 유닛들(예: MAA0 및 MAA2)로부터의 곱셈들은 복수의 내적들의 생성에만 사용된다. 따라서, 제1 MAA 유닛 세트(각각의 XMAAG들의 XMAA들 내의 MAA들의 그룹 내의 교대 MAA 유닛 들인 MAA0 및 MAA2)에서의 변환된 커널들을 갖는 변환된 IFM들(716-2)의 곱셈을 위해, 변환된 IFM들(716-2)에 제1 MAA 유닛 세트에서 변환된 커널을 곱하는 곱셈 연산이 수행될 때, 제2 MAA 유닛 세트는 제 2 멀티플라이어 세트의 입력 단자들에서의 제로 게이팅에 기초하여 제 2 멀티플라이어 세트를 비활성화할 수 있다. 또한, 생성 된 복수의 곱셈들의 덧셈 연산이 수행될 때, 제2 MAA유닛 세트는 제2 멀티플라이어 세트를 비활성화 상태로 유 지할 수 있다. 예를 들어, 도 9에 도시된 바와 같이, 각각의 채널로부터의 4개의 픽셀에 대응하는 입력 벡터들은 XMAA들 의 XMAA0 및 XMAA1 내의 MAA들의 입력 단자에 함께 제공될 수 있다. 또한, 전치된 행렬 AT(도 2의 AT)의 첫 번째 행과 변환된 IFM의 첫 번째 열을 고려하여, 각 XMAA0에서 MAA0의 멀티플라이어 및 에더 트리를 전술한 바 와 같은 곱셈 연산 및 덧셈 연산에 사용할 수 있다. 다른 예로, 전치된 행렬 AT의 두 번째 행과 변환된 IFM의 첫 번째 열에 대해서는 각 XMAA0에서 MAA1의 에더 트 리만이 덧셈 연산을 수행하기 위해 사용될 수 있다. 유사한 프로세스가 각각의 XMAAG들의 XMAA들 내의 복수의 MAA 유닛들 각각에 대해 반복될 수 있다. 도 9에서 설명한 예시에서, XMAA0 및 XMAA1내에 포함된 MAA0 및 MAA2에 대해, 곱셈 및 덧셈 연산을 위해 멀티플 라이어 및 에더 트리가 사용될 수 있다. 그러나, XMAA0 및 XMAA1내에 포함된 각각의 MAA1 및 MAA3는 곱셈 및 덧 셈 연산이 수행될 때만 에더 트리들을 사용하고, XMAA0 및 XMAA1내에 포함된 각각의 MAA1 및 MAA3의 멀티플라이 어는 비활성화될 수 있다. 따라서, MAA1 및 MAA3의 멀티플라이어는 곱셈 연산에 참여하지 않으며, MAA1 및 MAA3의 에더 트리들에 있는 에더는 활성 상태로 유지되어 MAA들 간의 바이패스 경로를 통해 MAA0 및 MAA2의 입 력을 수신할 수 있다. 통상의 기술자는 전술한 실시예가 단지 예시적인 것이며, 기재된 실시예를 제한하려는 의도가 아님을 이해할 수 있다. 또한, z-first 스토리지 CNN 가속기 상에서 뎁스 와이즈 위노그라드 컨볼루션 동작이 수행될 때, 제2 멀 티플라이어 세트는 비활성화 상태로 유지될 수 있다. 또다른 예로, 도 10에 도시된 바와 같이, XMAAG0의 XMAA들 내의 MAA들의 그룹 내의 교대 MAA 유닛들 (MAA0 및 MAA2)의 제1 멀티플라이어 세트 및 에더 트리들 모두는 순방향 변환된 IFM(F)들(716-2) 및 순방향 변 환된 커널(K)들의 엘리먼트-와이즈 곱셈을 위해 사용될 수 있다. XMAAG0의 XMAA들 내의 MAA들 그룹 에 있는 제2 MAA 유닛 세트(MAA1 및 MAA3)의 에더 트리들만이 순방향 변환된 IFM들(716-2) 및 순방향 변환된 커 널의 엘리먼트-와이즈 곱셈에 사용되고, 엘리먼트-와이즈 곱셈이 수행될 때, 제2 멀티플라이어 세트는 비활성화 될 수 있다. 상술한 예시에서, 곱셈 연산의 결과로서 XMAAG들 내의 MAA 유닛들에 의해 생성된 복수의 곱셈들은 2개의 MAA들 사이의 바이패스 경로들을 이용하여 공유될 수 있다. 따라서, 복수의 내적들(제1 역변환 연산 결과들)은 제1 역변환 연산(예: 위노그라드 역변환 연산에 대한 제1 행렬 곱셈)을 실현하기 위해 복수의 에더 트리들에 의해 생성될 수 있다. 또한, XMAAG들 내의 복수의 MAA 유닛들은 생성된 복수의 내적(제1 역변환 연상 결 과)을 역변환 모듈로 전달할 수 있고, 역변환 모듈에서 제2 역변환 연산(예: 역변환 연산에서의 제2 행렬 곱셈)이 수행될 수 있다. 일 실시예에 따르면, 제1 멀티플라이어 세트 중에서 제1 멀티플라이어 수(number)는 변환된 IFM들(716-2)을 변 환된 커널들로 곱하기 위해 제1 MAA 유닛 세트에 의해 사용될 수 있다. 그리고, 나머지 멀티플라이어들(즉, 제 1 멀티플라이어 수 이외의 제 1 멀티플라이어 세트 중에서 제2 멀티플라이어 수)은 제2 멀티플라이어 수의 입 력 단자의 제로 게이팅에 기초한 곱셈 연산 동안에 비활성화될 수 있다. 단계에서, 일 실시예에 따른 시스템의 역변환 모듈은 복수의 MAA 유닛 또는 XMAAG들로부터 생성된 복수의 내적(제1 역변환 연산 결과)을 수신할 수 있다. 단계에서, 일 실시예에 따른 시스템은 역변환 모듈로 복수의 내적(제1 역변환 연산 결과)을 수 신한 이후, 위노그라드 역변환 연산을 이용하여, 수신된 복수의 내적에 대해 제2 행렬 곱셈(제2 역변환 연산)을 수행하여 복수의 출력 특징 맵(OFM)을 생성할 수 있다. 예를 들어, 시스템의 역변환 모듈은 위노그 라드 역변환 연산에서 제2 단계의 곱셈(즉, 제2 행렬 곱셈)을 위해 수신된 복수의 내적에 대해 제2 행렬 곱셈을 수행하고, 곱셈 수행 후 수신된 복수의 내적에 대한 제 2 행렬 곱셈에 기초하여 복수의 OFM들을 생성할 수 있 다. 제2 행렬 곱셈은 출력 변환 행렬을 사용하는 제2 역변환 연산이고, 제2 행렬 곱셈에 사용되는 행렬은 수학 식 1에서의 행렬 A이다. 전술한 실시예들에서, 역변환 연산의 일부가 XMAAG들의 XMAA들 상에서 수행될 수 있다. 특히, 제1 역 변환 연산은 XMAAG들의 MAA 유닛들의 에더 트리들을 사용하여 XMAAG들의 복수의 MAA 유닛들에 대해 수행되는 반면, 제2 역변환 연산은 역변환 모듈상에서 수행될 수 있다. 따라서, 전술한 종류의 뎁스 와이 즈 위노그라드 컨볼루션 매핑 방법에서, 다수의 멀티플라이어들 및 에더 트리들이 XMAAG에서 효율적으로 사용될 수 있고, 따라서 리소스의 활용도가 증가할 수 있고, 시스템의 전반적인 성능이 향상될 수 있다. 도 11은 일 실시예에 따른 뎁스 와이즈 컨볼루션 연산의 결과를 비교한 예시적인 그래프이다. 본 개시의 뎁스 와이즈 위노그래드 컨볼루션 연산 방법에 따르면, 3X3 깊이별 컨볼루션 레이어에서 3배의 개선 효과가 있을 수 있다. 평균적으로, 깊이 기반 CNN에서 평균 13.8% 이상의 속도 향상을 가져올 수 있다. 도 11 을 참조하면, 본 개시의 실시예에 따라, 서로 다른 CNN을 참조하여 본 개시의 깊이별 위노그래드 컨볼루션 연산 과 종래 기술 간의 연산에 소요되는 사이클을 비교할 수 있다. 비교를 위해 모바일넷V1, 모바일넷V2, 이피션트 넷, 및 엠나스넷과 같은 CNN이 사용될 수 있다. 종래 기술의 경우, 뎁스 와이즈 계산 매핑에서, MAA에는 비활성 행이 존재할 수 있다. 비활성 행이 전력 소비에 기여하기 때문에, 경로에서 로직의 전환을 피하기 위해 입력이 0으로 강제된다. 그러나, 본 개시의 시스템(70 0)의 XMAAG는 종래 방식에서 4개의 데이터 벡터를 소비하는 것과는 대조적으로 2개의 데이터 벡터만을 소비할 수 있다. 도 12는 일 실시예에 따른 뎁스 와이즈 컨볼루션에 소비되는 에너지를 비교한 예시적인 그래프이다. 본 개시의 방법 및 시스템은 계산 사이클의 속도 향상으로 인해 종래 방식에 비해 더 낮은 에너지를 소비할 수 있다. 도 12를 참조하면, 본 개시의 실시예에 따라, 모바일넷V1, 모바일넷V2, 이피션트넷, 및 엠나스넷과 같은 상이한 CNN을 참조하여, 본 개시의 뎁스 와이즈 위노그라드 컨볼루션 연산과 종래 기술 간의 스트라이드 (stride) 1의 뎁스 와이즈 컨볼루션 연산에 소비되는 에너지를 비교할 수 있다. 도 12에 도시된 그래프를 참조 하면, 본 개시에 따른 깊이별 위노그라드 컨볼루션 매핑으로 인해 3x3 깊이별 컨볼루션 레이어에서 소비되는 에 너지가 1.9배 감소할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0027983", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6a 도면6b 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2023-0027983", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 2차원(2D) 위노그라드(Winograd) 컨볼루션(Convolution) 방법을 설명하기 위한 블록도 이다. 도 2는 일 실시예에 따른 위노그라드 컨볼루션에 사용되는 행렬들을 간략하게 도시한 것이다. 도 3은 일 실시예에 따른 3D 컨볼루션을 위한 베이스라인 아키텍쳐를 간략하게 도시한 것이다. 도 4는 일 실시예에 따른 베이스라인 아키텍처의 3D 위노그라드 컨볼루션 맵핑을 도시한 것이다. 도 5 는 일 실시예에 따른 베이스라인 아키텍처에서 뎁스 와이즈 컨볼루션을 매핑하는 방법을 개략적으로 도시 한 것이다. 도 6 a 및 도 6b는 일 실시예에 따른 위노그라드 컨볼루션 연산 수행 방법을 설명하기 위한 순서도이다. 도 7은 일 실시예에 따른 위노그라드 컨볼루션 연산을 수행하기 위한 시스템을 개략적으로 도시한 것이다. 도 8은 일 실시예에 따른 데이터 버퍼 내로의 순방향 변환 IFM들의 예시적인 분포를 도시한 것이다. 도 9는 일 실시예에 따른 뎁스 와이즈 위노그라드 컨볼루션 모드에서 XMAA들이 수행하는 계산 예를 도시한 것 이다. 도 10은 일 실시예에 따른 뎁스 와이즈 위노그라드 컨볼루션 모드에서 XMAAG들이 수행하는 계산 예를 도시한 것이다. 도 11은 일 실시예에 따른 뎁스 와이즈 컨볼루션 연산의 결과를 비교한 예시적인 그래프이다. 도 12는 일 실시예에 따른 뎁스 와이즈 컨볼루션에 소비되는 에너지를 비교한 예시적인 그래프이다."}
