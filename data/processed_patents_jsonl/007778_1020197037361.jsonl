{"patent_id": "10-2019-7037361", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0022386", "출원번호": "10-2019-7037361", "발명의 명칭": "정보 처리 장치 및 정보 처리 방법", "출원인": "가부시키가이샤 아라야", "발명자": "마츠모토 와타루"}}
{"patent_id": "10-2019-7037361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 데이터에 대해 뉴럴 네트워크의 연산을 행함으로써, 인공지능 기능을 실현하는 연산 처리부를 구비한 정보처리 장치에 있어서,상기 연산 처리부는 상기 뉴럴 네트워크에 있어서의 노드 사이를 연결하는 네트워크의 계산을 위한 가중치 행렬의 행수 혹은 열수를, 입력 데이터 또는 출력 데이터에 의해 정해지는 행수 혹은 열수로부터 삭감한 행수 혹은열수로 하고,삭감한 행수 혹은 열수의 가중치 성분과 입력 데이터의 벡터의 일부의 요소와의 곱합을 취하고, 조합이 모두 상이한 방정식을 구성하는 것을 특징으로 하는 정보 처리 장치."}
{"patent_id": "10-2019-7037361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "입력 데이터에 대해 뉴럴 네트워크의 연산을 행함으로써, 인공지능 기능을 실현하는 연산 처리부를 구비한 정보처리 장치에 있어서,상기 연산 처리부는 상기 뉴럴 네트워크에 있어서의 노드 사이를 연결하는 네트워크의 계산을 위한 가중치 행렬의 행수 혹은 열수를, 입력 데이터 혹은 출력 데이터에 의해 정해지는 행수 혹은 열수로부터 삭감한 행수 혹은열수로 하고,삭감한 행수 혹은 열수의 가중치 성분을 입력 데이터의 벡터와 곱셈을 하며, 그 곱셈을 한 결과의 행렬을 일정한 열수마다 혹은 행수마다의 부분 행렬로 분할하고, 분할하여 얻어진 부분 행렬마다 행렬의 합을 행하는 것을특징으로 하는 정보 처리 장치."}
{"patent_id": "10-2019-7037361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 부분 행렬마다 임의의 치환의 조작을 가하는 것을 특징으로 하는 정보 처리 장치."}
{"patent_id": "10-2019-7037361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "입력 데이터에 대해 뉴럴 네트워크의 연산을 행함으로써, 인공지능 기능을 실현하는 연산 처리부를 구비한 정보처리 장치에 있어서,상기 연산 처리부는 상기 뉴럴 네트워크에 있어서의 노드 사이를 연결하는 네트워크의 계산을 위한 가중치 행렬의 행수 혹은 열수를, 입력 데이터 또는 출력 데이터에 의해 정해지는 행수 혹은 열수로부터 삭감한 행수 혹은열수로 하고,삭감한 행수 혹은 열수의 가중치 성분과 입력 데이터의 벡터의 일부의 요소와의 곱합을 취하고, 조합이 모두 상이한 방정식을 구성하는 것을 특징으로 하는 정보 처리 방법."}
{"patent_id": "10-2019-7037361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "입력 데이터에 대해 뉴럴 네트워크의 연산을 행함으로써, 인공지능 기능을 실현하는 연산 처리 방법에 있어서,상기 뉴럴 네트워크에 있어서의 노드 사이를 연결하는 네트워크의 계산을 위한 가중치 행렬의 행수 혹은열수를, 입력 데이터 또는 출력 데이터에 의해 정해지는 행수 혹은 열수로부터 삭감한 행수 혹은 열수로 하는삭감 스텝과,상기 삭감 스텝에서 삭감한 행수 혹은 열수의 가중치 성분을 입력 데이터의 벡터와 곱셈을 하는 곱셈 스텝과,상기 곱셈 스텝에서 얻은 결과의 행렬을 일정한 열수마다 혹은 행수마다의 부분 행렬로 분할하는 분할 스텝과,상기 분할 스텝에서 분할하여 얻어진 부분 행렬마다 행렬의 합을 행하는 합연산 스텝을 포함하는 것을 특징으로공개특허 10-2020-0022386-3-하는 정보 처리 방법."}
{"patent_id": "10-2019-7037361", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 부분 행렬마다에 임의의 치환의 조작을 가하는 것을 특징으로 하는 정보 처리 방법."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "뉴럴 네트워크에 있어서의 노드 사이를 연결하는 네트워크의 계산에 적용한다. 네트워크의 가중치 행렬의 행수 혹은 열수를 입력 데이터 또는 출력 데이터에 의해 정해지는 행수 혹은 열수로부터 삭감한 행수 혹은 열수로 한 다. 그리고, 삭감한 행수 혹은 열수의 가중치 성분을 그 입력 데이터의 벡터와 곱셈을 하고, 그 곱셈을 한 결과 의 행렬을 일정한 열수마다 혹은 행수마다의 부분 행렬로 분할하고, 분할하여 얻어진 부분 행렬마다 행렬의 합을 행한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능에 사용하는 뉴럴 네트워크의 연산을 행하는 정보 처리 장치 및 정보 처리 방법에 관한 것으 로, 특히 뉴럴 네트워크의 연산을 행할 때의 연산량을 삭감하는 기술에 관한 것이다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "뉴럴 네트워크(이하, 「NN」이라고 칭한다)에 있어서, 특히 인식 성능이나 예측 성능이 높고 깊은 층 구조를 갖 는 딥 뉴럴 네트워크(이하, 「DNN」이라고 칭한다), 합성곱 뉴럴 네트워크(이하, 「CNN」이라고 칭한다) 등은 인터넷 서비스나 클라우드 경유·기기 탑재 등의 수단에 의해 스마트폰, 자동차 기기, 가전 기기, 공장용 기기, 로봇 등에 대한 어플리케이션으로서 제공되고 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) Coates, Adam, Huval, Brody, Wang, Tao, Wu, David, Catanzaro, Bryan, and Andrew, Ng. \"Deep learning with cots hpc systems.\" In Proceedings of The 30th International Conference on Machine Learning, pp. 1337-1345, 2013. (비특허문헌 0002) R. Vershynin, On the role of sparsity in Compressed Sensing and Random Matrix Theory, CAMSAP'09 (3rd International Workshop on Computational Advances in Multi-Sensor Adaptive Processing), 2009, 189--192."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "그러나, 종래 인공지능 기능의 실현으로서 많이 채용되고 있는 DNN이나 CNN 등의 NN은 연산량이 크고, 계산기 자원에 대규모 서버를 준비하거나, 그래픽 프로세싱 유닛(이하, 「GPU」라고 칭한다) 등의 추가 유닛을 탑재할 필요가 있다. 이 때문에, 지능용 설비의 도입이나 기기에 대한 실장시 고가가 되거나 대량의 소비 전력이 필요 해지는 문제가 있다. 본 발명은 상기 사정을 감안하여 이루어진 것으로, DNN이나 CNN 등의 NN의 연산량을 삭감함으로써, 계산기 자원 을 대폭으로 삭감하고, 소형화나 저소비 전력화를 가능하게 하며, 범용 기기에 탑재할 수 있는 인공지능의 기능 이나 서비스를 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 정보 처리 장치는 입력 데이터에 대해 뉴럴 네트워크의 연산을 행함으로써, 인공지능 기능을 실현하 는 연산 처리부를 구비한 정보 처리 장치에 있어서, 연산 처리부는 뉴럴 네트워크에 있어서의 노드 사이를 연결하는 네트워크의 계산을 위한 가중치 행렬의 행수 혹 은 열수를, 입력 데이터 또는 출력 데이터에 의해 정해지는 행수 혹은 열수로부터 삭감한 행수 혹은 열수로 하 고, 삭감한 행수 혹은 열수의 가중치 성분을 입력 데이터의 벡터와 곱셈을 하며, 그 곱셈을 한 결과의 행렬을 일정 한 열수마다 혹은 행수마다의 부분 행렬로 분할하고, 분할하여 얻어진 부분 행렬마다 행렬의 합을 행하는 것을특징으로 한다. 또한, 본 발명의 정보 처리 방법은 입력 데이터에 대해 뉴럴 네트워크의 연산을 행함으로써, 인공지능 기능을 실현하는 연산 처리 방법에 있어서, 뉴럴 네트워크에 있어서의 노드 사이를 연결하는 네트워크의 계산을 위한 가중치 행렬의 행수 혹은 열수를, 입 력 데이터 또는 출력 데이터에 의해 정해지는 행수 혹은 열수로부터 삭감한 행수 혹은 열수로 하는 삭감 스텝과, 삭감 스텝에서 삭감한 행수 혹은 열수의 가중치 성분을 입력 데이터의 벡터와 곱셈을 하는 곱셈 스텝과, 곱셈 스텝에서 얻은 결과의 행렬을 일정한 열수마다 혹은 행수마다의 부분 행렬로 분할하는 분할 스텝과, 분할 스텝에서 분할하여 얻어진 부분 행렬마다 행렬의 합을 행하는 합연산 스텝을 포함하는 것을 특징으로 한다. 본 발명에 의하면, 인공지능 기능을 실현하는 계산기 자원을 대폭으로 삭감할 수 있기 때문에, 계산기에 점유되 는 스페이스나 가격, 소비 전력을 삭감할 수 있게 된다. 따라서, 인공지능 기능을 기기에 탑재할 때, 저가격 CPU나 범용 FPGA(field-programable gate array)나 LSI를 사용하여 뉴럴 네트워크의 연산을 행하는 것이 가능 하게 되고, 소형, 저가격화, 저소비 전력, 고속화를 실현할 수 있다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 따른 제1 실시형태예에 대해, 도 1∼도 12를 참조하여 설명한다. 제1 실시형태예는 DNN(딥 뉴럴 네트 워크)에 적용한 예이다. 도 1에 기초하여 DNN의 구조를 정의한다. 우선 입력 신호를 N차원 벡터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "으로 한다. 한편, (＊)T는 행렬의 전치를 나타내고 있다. l＝1, 2, 3, …라는 층의 색인을 나타내는 l을 이용하 여 다층 구조를 표현한다. 또한"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "은 실수를 의미한다. 벡터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "을"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "으로서 계산하는 l번째 층의 가중치 계수의 합을 벡터로 한다. 여기서"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "은 가중치 행렬이고,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "은 바이어스 벡터이다. 주어진 uj(l)에 대해 활성화 함수 f가 다음의 l＋1층의 입력 벡터 xj(l＋1)를 노드별 계산 xj(l＋1)＝f(uj(l))를 실행함 으로써 생성된다. 설명을 간이화하기 위해 이후는 bj(l)＝0과 f(u)＝u로서 설명을 진행한다. 일반적으로, DNN은 식별용 교사가 있는 학습 전에 적층 자기부호화기를 사용하여 교사가 없는 학습에 의한 예비 트레이닝을 행한다. 도 2에 나타내는 바와 같이, 이 자기부호화기에서는 고차원 입력 신호의 주요한 정보를 획 득하고 저차원 특징 데이터로 변환하는 것을 목적으로 하고 있다. 각 층에서는 자기부호화기를 사용하여 복원된 데이터와 입력 데이터의 차이를 최소화하도록 학습을 행한다. 이 학습은 하위층으로부터 상위층까지 층마다 구 배 강하법이나 오차역전파법 등을 이용하여 실시된다.x(l＋1)＝W(l)x(l)로 나타내는 네트워크층에 대해, 가중치 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "을 이용하여"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "을 계산함으로써, x(l＋1)로부터 복원 벡터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "을 생성한다. 자기부호화기 학습시에는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "을 구하는 최적화 문제를 해결함으로써, 가중치 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "과"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "을 도출한다. 여기서는, x(l)의 벡터의 길이를 J(l)로 한다. 일반적으로 J(l＋1)≤J(l)이기 때문에, 자기부호화기는 데이터의 차원을 삭감하게 된다. 즉, 차원 압축된 신호 x(l＋1)로부터 W(l)를 이용하여 원신호 x(l)를 복원하는 문제로 간주할 수 있다. 반대로 말하면, 가중치 행렬 W(l)가 차원 압축된 신호 x(l＋1)로부터 원신호 x(l)를 복원하는 특성을 갖고 있으면 된다. 예를 들면, 비특허문헌 2에서 나타내는 논문에서는 W(l)에 그 성분을 표준적인 가우스 분포로부터 랜덤으로 선택 한 행렬로, 압축 차원 벡터로부터 원신호 벡터를 재생할 수 있는 것을 나타내고 있다. 여기서, 도 3을 참조하여 DNN을 자필 숫자의 인식에 적용한 예에 대해 설명한다. 예를 들면, 도 3에서 나타내는 바와 같이, 자필 숫자의 「5」를 벡터 x로 표현했다고 하고, 랜덤 행렬인 W 와 행렬의 곱셈을 하여 얻은 차원 압축된 벡터 x를 얻는다. 지금 벡터 x가 어떤 그림인지 모르는 상태에서 도 벡터 x와 랜덤인 행렬 W로부터 벡터 x를 재생할 수 있고, 결과 자필 숫자의 「5」를 재생할 수 있는 것을 나타내고 있다. 한편, 가중치 행렬의 랜덤성을 만족시키는 방법은 행렬의 성분을 랜덤으로 선택하는 방법 이외에도 생각된다. 본 발명에서는 이 점에 착안한 구성법을 나타낸다.이 특성을 나타내는 가중치 행렬의 구성법을 이하에 나타낸다. 여기서는, 일례로서 도 3에 나타내는 바와 같은 자필 숫자의 인식에 사용하는 DNN으로 설명한다. 입력 신호는 자필 문자의 사이즈가 28×28＝784 화소라고 하면, 1층째의 입력 신호 x의 벡터의 길이는 N＝784 가 된다. 중간층으로서 2층째의 노드 x의 벡터의 길이를 M＝500으로 하면, 도 3에 나타내는 바와 같이 500× 784의 가중치 행렬 W에 입력 신호 벡터 x를 곱하여 차원 압축된 중간 노드의 신호 x를 얻게 된다. 도 4에 이 때의 가중치 행렬 W와 입력 신호 벡터 x의 행렬 계산에 의해, 중간 노드의 벡터 x가 얻어지는 모습을 나타낸다. 이 때, 연산량이 큰 곱셈의 횟수는 M×N＝500×784＝392000회가 된다. 도 4, 도 5에 본 실시형태예의 네트워크 압축 방법을 나타낸다. 종래의 DNN에서는 각 층마다 입력 벡터 길이 N, 출력 벡터 길이 M에 대해 M×N의 성분에 대한 곱이 필요하고, 이 곱의 횟수가 연산량을 증대시키는 원인이었다. 본 실시형태예에서는 도 5에 나타내는 바와 같이 원래의 M×N＝500×784의 가중치 행렬을 M'×N＝10×784까지 압축시키는 방법을 나타낸다. 우선은 종래예와 비교하여 압축한 가중치 행렬을 준비하고, 그 압축한 가중치 행렬 아래에서의 계산 방법을 나 타낸다. 또한, 본 발명의 계산 방법에서 정밀도가 거의 떨어지지 않는 이유를 설명하며, 그 하드웨어 구성예와 플로우 차트예를 나타낸다. 이 압축한 가중치 행렬을"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "으로 한다. 또한, 압축률을 γ로 표현하면, 이 압축률은 γ＝M'/M＝10/500＝1/50이 된다. 이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "의 가중치 행렬을 이용하여 하기 계산을 행한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "여기서, 이고, 연산자°는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "으로 A를 행렬, B를 벡터했을 때, 행렬 A의 i열째의 성분과 벡터 B의 i번째의 요소의 곱을 행하는 연산이다. 이어서, 도 6에 나타내는 바와 같이 M'×N＝10×784의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "을 1/γ＝50열마다 M'×N'＝10×50의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "으로 이하와 같이 분할한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "게다가"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "에 대해 특정의 룰로 치환 또는 랜덤으로 치환된 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "의 행렬의 합을 하기와 같이 실행한다. 여기서, 치환이란 행렬의 임의의 2요소의 장소를 서로 교환하는 조작을 임의의 횟수로 행하는 것을 의미한다. 그 결과, 도 6의 우단에 나타내는 바와 같은 M'×N'＝10×50의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "이 출력된다. 이 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 24, "content": "을 벡터로 변환하고"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 25, "content": "을 구성한다. 상기 예에서는 10×50의 행렬 X로부터 벡터 길이 500의 x가 생성된다. 따라서 500×784의 가중치 행렬 W를 이용한 계산과 동일한 784차원의 입력 신호로부터 500차원의 중간 노드의 신호를 출력하는 연산을 실행할 수 있다. 특히 치환된 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 26, "content": "의 조합에 의한 행렬의 합을 이용함으로써 랜덤 행렬에 가까운 특성을 실현할 수 있다. 결과 인식 성능이나 예측 성능은 종래 방법과 본 발명 방법에서는 사소한 성능 차이로 억제된다. 한편, 본 실시형태예에서는 연산량이 큰 곱셈의 횟수는 M'×N＝10×784＝7840회가 되고, 종래 M×N＝500×784＝ 392000회에 비해 γ＝1/50까지 낮춰지는 효과가 있다. 예를 들면, 원래 6×9의 가중치 행렬 W로 입력 신호 벡터 x의 벡터 길이를 9, 출력 벡터 x의 벡터 길이 6 인 것을 대상으로 한다. 예를 들면,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 27, "content": "이라는 계산을 행한다. 일반적으로, 가중치는 wi,j∈[－1, 1]의 범위로 설정된다. 여기서, 가중치 분포의 분산값 이 큰 경우는 가중치가 -1이나 1의 값을 취하는 경우가 많아지고, 학습을 하는 과정에 있어서도 학습이 수속하 지 않는 구배 소실 문제라는 문제도 발생시킨다. 예를 들면, 상기 식 1행째와 2행째의 가중치가 모두 1이 되었을 경우,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 28, "content": "이라는 형태로 상기 식의 우변을 보면 알 수 있듯이 동일한 방정식이 2개 중복하여 존재하고, 출력하는 x의 1 번째의 요소와 2번째 요소가 동일해지기 때문에, 그 요소가 하나 줄어든 것과 동일해지며, x의 정보 그 자체의 결손이 발생한다. 즉, x의 요소는 본래 6개이지만, 1번째의 요소와 2번째의 요소가 동일해지기 때문에 요 소 5개분의 정보로 삭감된다. 이 계산을 행하는 하나의 층에서 정보의 결손은 최종적인 식별로 이용하는 정보의 결손으로 이어지기 때문에 식별 성능을 낮추는 요인이 된다. 한편, 가중치 wi,j가 -1이나 1의 값을 취했다고 하 더라도 동일한 방정식의 발생을 최초부터 회피할 수 있는 방법을 이용하면, x의 요소의 결손은 방지할 수 있 고, 식별에 필요한 정보량도 유지할 수 있으며, 최종적인 식별의 정밀도를 낮추지 않는 효과가 얻어진다. 이 관점으로부터, 본 발명에서 취한 방법은 가중치 행렬 W(l)의 각 행의 성분과 벡터 x(l)의 모든 요소의 곱합을 취하지 않고, 일부 요소의 곱합을 취하여 방정식이 일치하지 않는 조합의 룰을 만드는 수단을 취함으로써 동일 한 방정식의 발생을 회피했다. 우선, 압축률에 따라 행수를 압축한 가중치 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 29, "content": "을 만들고, 압축률의 역수 1/γ마다 W(l)를 분할하여 식 로 나타내는 바와 같이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 30, "content": "을 계산하고, 게다가"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 31, "content": "에 대해 특정 룰로 치환 또는 랜덤으로 치환된 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 32, "content": "과의 행렬의 합을 식 로 나타내는 바와 같이 실행한다. 이들의 실장은 소프트웨어 상에서도 실장 가능하지만, FPGA 등의 하드웨어에서의 실장도 가능하다. 구체예로서 γ＝1/3의 경우를 나타낸다. 우선 행수를 6으로부터 압축 후 행수 6×γ＝2행으로 한다. 이어서 열 수를 1/γ＝3열마다 구분하여, 2×3의 가중치 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 33, "content": "을 구성하고, 벡터 길이는 1/γ＝3의 x1, x2, x3을 이용하여"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 34, "content": "으로 계산한다. 한편, 간이화를 위해 행렬의 성분 및 벡터의 요소의 윗첨자의 표현은 생략하고 있다. 여기서, 의 2행째를 좌측으로 1열 순회 시프트하는 치환을 하고, 하기와 같이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 35, "content": "으로 한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 36, "content": "또한,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 37, "content": "의 2행째를 좌측으로 2열 순회 시프트하는 치환을 하고, 하기와 같이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 38, "content": "으로 한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 39, "content": "결과,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 40, "content": "은 이하와 같이 계산한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 41, "content": "한편, 간이화를 위해,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 42, "content": "으로 한다. 이 순서에 의해, 가중치 wi,j가 -1이나 1의 값을 취하더라도, 동일한 방정식의 발생을 최초부터 회피할 수 있다. 예를 들면, 상기 실례에 있어서 모든 가중치 wi,j를 1로 했다 하더라도,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 43, "content": "이 되고, 중복하는 방정식은 발생하지 않는다. 또한, 하나의 방정식당 곱합의 수도 식 , 식 로 행해진 9 회 곱, 8회 합으로부터, 식 로 나타내는 바와 같이, 3회 곱, 2회 합으로 삭감되어 있다.이 순서에서는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 44, "content": "의 2행째의 성분을 좌측으로 1열 순회 시프트,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 45, "content": "의 2행째의 성분을 좌측으로 2열 순회 시프트한 것뿐이다. 이와 같이 심플한 구조에서도 동일한 방정식의 발생 은 피할 수 있다. 도 7 및 도 8에 상기 계산예의 정리와 그 계산을 하드웨어화했을 경우의 구체적인 회로를 나타낸다. 도 7에 나 타내는 행렬의 1열 순회 시프트와 2열 순회 시프트를 행하는 하드웨어 구성이 도 8에 나타내는 하드웨어로 실현 된다. 도 8 중, 「○」에 「×」를 조합한 표시는 곱셈 회로를 나타내고, 「○」에 「＋」를 조합한 표시는 가산 회로 를 나타낸다. 도 8로부터 알 수 있듯이, 한번 입력 벡터의 값 x와 가중치 W를 레지스터 등에 세트하면, 곱 합이 동시에 실행 가능하다. 압축에 의해 회로에 필요한 곱합의 회로수와 메모리수도 행렬의 성분의 압축률에 비례하여 삭감할 수 있다. 또한,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 46, "content": "으로부터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 47, "content": "에 대한 치환 패턴을 고정화함으로써, 도 8에 나타내는 바와 같이 접속 패턴을 고정할 수 있어 하드웨어화가 용 이해진다. 도 9 및 도 10은"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 48, "content": "으로부터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 49, "content": "에 대한 치환 패턴에 랜덤인 치환을 이용하는 경우를 나타낸다. 도 9에 나타내는 행렬의 1행째와 2행째 모두 랜 덤으로 치환되는 하드웨어 구성이 도 10에 나타내는 하드웨어에서 실현된다. 이 경우에도, 치환 패턴을 고정화 하는 것은 가능하기 때문에 하드웨어화는 동일하게 용이하다. 도 11은 본 실시형태예의 연산 처리를 실행하는 플로우 차트를 종래의 DNN과 비교한 것이다. 도 11의 좌측 스텝 (S11∼S19)은 종래 DNN 실행시의 플로우 차트이고, 도 11의 우측 스텝(S21∼S31)은 본 실시형태예의 DNN 실행시 의 플로우 차트이다. 종래의 DNN에서는 화상 데이터 등의 입력 데이터는 일반적으로 1화소씩 데이터의 조합을 벡터로서 취급하고, 입 력 벡터 x로서 정규화나 양자화의 전처리가 행해진다(스텝 S11). 그 후, 도 4에서 설명한 것처럼 최초의 층 l ＝1의 가중치 행렬 W와 벡터 x에 의해 행렬의 곱셈 Wx을 실시하고(스텝 S12), 계속하여 활성화 함수 f를 실행하며(스텝 S13), 다음 층 l＝2의 노드의 벡터 x를 얻는다. 이 처리를 반복하고(스텝 S14∼S16), 예를 들면, l＝L층까지 반복하며(스텝 S17∼S18), 최종적으로 Softmax 등의 계산을 실시하여, 인식 계산을 행한다(스 텝 S19). 도 11의 예에서는 l＝L층은 압축하지 않는 행렬을 이용한 방법을 나타냈지만, l＝L층도 본 발명의 압 축한 행렬을 이용한 계산을 행해도 된다. 또는, 본 발명 방법의 계산은 전체의 일부의 층만 적용해도 된다. 이어서, 도 11의 우측에 나타내는 본 실시형태예의 DNN 실행시의 처리를 설명한다. 우선, 종래예와 동일하게 입력 신호의 전처리가 행해진다(스텝 S21). 그 후, 행렬 계산으로서 설명한 바와 같이, 압축한 가중치 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 50, "content": "을 이용하여"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 51, "content": "의 계산을 실행하고(스텝 S22), 추가로"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 52, "content": "의 계산을 실행한다(스텝 S23). 그 후, 활성화 함수 f를 실행한다(스텝 S24). 이 전처리로부터 활성화 함수의 실행까지를 다음의 중간 노드에 대해 반복하고(스텝 S25∼S28), 예를 들면, l＝L층까지 반복하며(스텝 S29∼S30), 최종적으로 Softmax 등의 계 산을 실시하여, 인식 계산을 행한다(스텝 S31). 한편, 도 11에서는 l＝L층은 압축하지 않는 행렬을 이용한 방법 을 나타냈지만, l＝L층도 압축한 행렬을 이용한 계산을 행해도 된다. 추가로, 본 실시형태예의 계산 처리는 전체의 일부 층만 적용해도 된다. 이상과 같이 본 실시형태예는 종래 행렬 계산 부분에 그대로 적용할 수 있다. 상기와 같이 가중치 행렬을 압축해도 특성이 거의 변하지 않기 때문에, 계산량이 삭감할 수 있다. 가중치 행렬 은 네트워크 구조 그 자체의 표현이기도 하고, 가중치 행렬의 압축은 네트워크 압축으로 간주할 수 있다. DNN을 네트워크 압축했을 때의 평가 결과를 표 1 및 도 12에 나타낸다. 입력 차원은 784에서 중간층은 500차원 으로 하고, 마지막에 0∼9까지의 인식 계산(Softmax)으로 출력하는 구조를 채용하고 있다. 표 1 및 도 12의 평 가 결과로부터 알 수 있듯이, 1/50로 연산량을 삭감해도 정답률은 약간 열화하지 않는 것을 확인할 수 있다. 표 1은 자필 숫자 0∼9까지의 인식의 정답률이다. 표 1"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 53, "content": "이어서, 본 발명의 제2 실시형태예를 도 13∼도 18을 참조하여 설명한다. 제2 실시형태예는 CNN(합성곱 뉴럴 네 트워크)에 적용한 예이다. 도 13에 CNN의 기본 네트워크 구성을 나타낸다. 일반적으로, CNN은 화상 등에 비추는 물체의 인식에 사용되는 용도 등에 사용되기 때문에 이후의 설명에서는 화상에서의 물체 식별을 의식한 설명을 행한다. 우선, l층째의 입력 데이터 사이즈를 M×M으로 하고, 입력 채널의 총수를 CN으로 한다. 또한, l층째의 출 력 데이터의 사이즈는 l＋1층의 입력 데이터 사이즈 M(1＋1)×M(1＋1)과 동일하고, l층째의 출력 채널의 총수는 l＋1층의 입력 채널의 총수 CN(l＋1)과 동일하다. 또한, 합성곱 대상 영역을 커넬 또는 필터라고 부르지만, 이 필터 영역의 사이즈를 H×H로 하며, l층, l＋1층의 각 채널 C(l), C(l＋1)에 대응하는 필터의 행렬을 F(l),C(l),C(l＋ 1)로 한다. 각 C(l)에 대응하는 입력 데이터를"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 54, "content": "입력 채널 C(l), 출력 채널 C(l＋1)에 대응하는 필터를"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 55, "content": "으로 한다. 도 14에 일례를 나타낸다. 예를 들면, RGB의 화상 데이터를 상정하고 생각하면, RGB의 각각에 대해 채널이 필요 하고, 입력의 제l＝1층째의 채널의 총수는 CN(l＝1)＝3이 된다. 또한, M＝3, M＝3, CN＝2, H＝2로 한다. 이 경우"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 56, "content": "이 된다. 도 14에 따라 계산하면,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 57, "content": "단,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 58, "content": "에 있어서, i〉M(l) 혹은 j〉M(l)일 때에는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 59, "content": "이다. 상기에 나타내는 바와 같이 행렬인 채로 합성곱 계산하는 것은 실장이 복잡하게 되므로, 계산의 효율화를 위해 행렬 X(l),C(l)를 길이 M(l)×M(l)의 벡터에 하기와 같이 변환한 것을 x(l),C(l)로 한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 60, "content": "한편, 합성곱 계산을 위해 출력 데이터의 사이즈에 맞춰 X(l),C(l)를 길이 M(l＋1)×M(l＋1)의 벡터로 변환한 것을 xr(l),C(l)로 한다. 여기서, r은 r번째의 합성곱 계산의 대상이 되는 벡터의 의미이다. 예를 들면, 최초 r＝1회째 의 합성곱 계산을 위해 생성하는 벡터 xr＝1(l),C(l)는 이어서, r＝2번째의 합성곱 계산을 위해 생성하는 벡터 xr＝2(l),C(l)는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 61, "content": "동일한 순서로 합성곱 계산의 계산 순서에 대응하도록 행렬 X(l),C(l)의 합성곱 계산 영역을 순서대로 벡터로 변환 하고, 이것을 행 방향으로 연결하는 형태로 각 채널 C(l)마다 사이즈(H(l)×H(l))×(M(l＋1)×M(l＋1))의 행렬 xb(l),C(l)를 하기와 같이 생성한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 62, "content": "이 행렬을 채널수 CN(l)개만큼 행 방향으로 연결시키고, 하기와 같이 xb(l)를 생성한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 63, "content": "단,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 64, "content": "에 있어서 i〉M(l) 혹은 j〉M(l)일 때에는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 65, "content": "이다. 이어서, xb(l)를 이용하여 그 벡터의 곱셈으로 계산할 수 있도록 F(l),C(l),C(l＋1)를 길이 H(l)×H(l)의 벡터 f(l),C(l),C(l ＋1)로 변환하고, 그것을 CN(l)개 및 CN(l＋1)개의 채널수에 순서대로 대응하도록 사이즈 CN(l＋1)×(H(l)×H(l)×CN(l)) 의 필터 행렬 FB(l)를 생성한다. 이 필터 행렬 FB(l)와 x(l)의 곱으로부터 xb(l＋1)를 하기와 같이 계산한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 66, "content": "또한, 각 행은 xb(l＋1)의 각 행은 하기와 같이 x(l＋1),C(l＋1)로 간주할 수 있다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 67, "content": "일반적으로, CNN의 합성곱층에서는 상기와 같이 계산한다. 도 14의 예에서는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 68, "content": "여기부터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 69, "content": "을 계산한다. 이어서, 네트워크 압축에 관하여 설명한다. H＝2, CN＝3, CN＝4를 예로 하고, 도 15에 그 때의 FB(l)를 나타낸다. 한편, 도 15의 행렬의 요소의 윗첨자 중, 층을 나타내는 (l)은 간이화를 위해 생략하고 있다. CNN에 대해 본 실시형태예의 네트워크 압축법을 이 FB(l)에 적용하여 압축한다. 이 압축한 필터 행렬을"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 70, "content": "으로 한다. 예를 들면, 도 16에서는 압축률 γ＝1/2의 예를 나타내고 있다. CNN의 경우와 동일하게 곱셈의 횟수를 ＝1/2까 지 낮출 수 있다. 종래의 CNN에서는 그 일부인 합성곱층에 도 14와 같은 계산을 행하는 것에 도 17의 (a)의 종 래예로서 나타내는 바와 같은 계산이 필요했다. 즉, CN(l＋1)·CN(l)·H(l)·H(l)·M(l＋1)·M(l＋1)회 곱이 필요하고, 이 곱의 횟수가 연산량을 증대시키는 원인으로 되 어 있었다. 본 실시형태예에서는 도 16의 (b)에 나타내는 바와 같이 원래의 CN(l＋1)×(CN(l)·H(l)·H(l))의 행렬을 (CN(l＋1)·γ)×(CN(l)·H(l)·H(l))까지 γ로 나타내는 압축률까지 압축시킨다.이 예에서는 설명의 지면의 형편상, 압축률은 γ＝1/2을 예로 들었지만, DNN의 경우와 동일하게 압축률은 수십 분의 1 등 보다 높은 압축률의 설정도 가능하다. 이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 71, "content": "의 행렬을 이용하여 하기 계산을 행한다. 우선"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 72, "content": "을 이하와 같이 정의한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 73, "content": "또한, xb(l)의 i열째의 부분 행렬을 xbi(l)로 하고, 이하의 계산을 i＝1, 2, …, M(l＋1)·M(l＋1)에 대해 행한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 74, "content": "도 17의 (b)의 예에서는 M(l＋1)·M(l＋1)＝9 로부터 9회 행한다. 이어서, 도 17의 (b)에 나타내는 바와 같이, (CN(l＋1)·γ)×(CN(l)·H(l)·H(l))의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 75, "content": "을 1/γ＝2열마다 (CN(l＋1)·γ)×1/γ의 행렬 으로 이하와 같이 분할한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 76, "content": "게다가"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 77, "content": "에 대해 상이한 룰로 성분을 치환한 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 78, "content": "과의 행렬의 합을 하기와 같이 실행한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 79, "content": "그 결과, 도 17의 최하단에 나타내는 바와 같이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 80, "content": "의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 81, "content": "이 i＝1, 2, …, M(l＋1)·M(l＋1)에 대응하도록 M(l)·M(l)＝9개 출력된다. 이 행렬 을 하기와 같이 각 행을 열 방향으로 연결시킨 벡터로 변환하여 전치를 하고,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 82, "content": "을 구성한다. 이들을 이용하여 CN(l＋1)×(M(l＋1)·M(l＋1))의 xb(l＋1)을 구한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 83, "content": "상기 예에서는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 84, "content": "의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 85, "content": "으로부터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 86, "content": "의"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 87, "content": "이 생성된다. 최종적으로는, CN(l)×(M(l＋1)·M(l＋1))＝4×9의 출력 행렬 xb(l＋1＝2)가 얻어지고, 종래와 동일한 노드 수의 출력 행 렬 xb(l＋1＝2)의 연산을 실행할 수 있다. 특히, 치환된 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 88, "content": "의 조합에 의한 행렬의 합을 이용함으로써 랜덤 행렬에 가까운 특성을 실현할 수 있다. 결과 인식 성능이나 예측 성능은 종래예와 본 실시형태예에서는 약간의 성능차이로 억제된다. 한편, 본 실시형 태예의 경우에는 연산량이 큰 곱셈의 횟수는 DNN의 경우와 동일 압축률 γ까지 낮추는 효과가 있다. 이들의 실 장은 소프트웨어 상에서도 실장 가능하지만, FPGA 등의 하드웨어에서의 실장도 가능하다. 이어서, 실장예를 나타낸다. 예를 들면, 원래 6×9의 행렬 FB에서 입력 신호 벡터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 89, "content": "의 벡터 길이 9인 것을 대상으로서 압축한다. γ＝1/4로 하고 2×9의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 90, "content": "과 벡터 길이 9의 2×9의 행렬의"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 91, "content": "을 이용하여,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 92, "content": "단, 간이화를 위해 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 93, "content": "의 성분은 wi,j, 벡터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 94, "content": "의 요소는 xj로 표기하고 있다. 여기서는,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 95, "content": "으로 한다. 여기서,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 96, "content": "의 2행째를 치환하고, 하기와 같이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 97, "content": "으로 한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 98, "content": "또한, 의 2행째를 좌측으로 2열 시프트하는 치환을 하고, 하기와 같이"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 99, "content": "으로 한다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 100, "content": "결과"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 101, "content": "은 이하와 같이 계산한다"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 102, "content": "한편, 간이화를 위해,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 103, "content": "으로 한다. 이 계산의 회로는 도 8에 나타내는 바와 같이 하드웨어화했을 경우와 동일한 회로가 된다."}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 104, "content": "으로부터"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 105, "content": "에 대한 치환 패턴으로 랜덤 치환을 이용하는 경우는 도 10과 동일한 회로가 된다. 한편, 본 실시형태예에서는"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 106, "content": "의 계산시"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 107, "content": "을 치환하지 않는 방법을 나타냈지만, 이 부분을 치환해도 된다. 도 18은 본 실시형태예의 연산 처리를 실행하는 플로우 차트를 종래의 CNN과 비교한 것이다. 도 18의 좌측 스텝 (S41∼S51)은 종래 CNN 실행시의 플로우 차트이며, 도 18의 우측 스텝(S61∼S73)은 본 실시형태예의 CNN 실행시 의 플로우 차트이다. 본 실시형태예의 처리는 종래 행렬 계산 부분에 적용할 수 있다. 한편, 도 18의 플로우 차트 중 Max Pooling은 필터 출력이 있는 영역의 조합으로 최대치를 취한 값만을 추출하 는 기능이다. 단, 인식을 위한 인식 계산(Softmax) 등의 직전에 이용하는 행렬 계산 등의 일부에 종래 방식을 이용해도 된다.우선 종래 CNN 실행 처리를 설명하면, 화상 데이터 등의 입력 신호는 일반적으로 1화소씩의 신호의 조합을 벡터 로서 취급한다. 그리고, 입력 벡터 x로 하고, 합성곱의 룰에 맞춘 행렬 xb로 변환하고, 정규화나 양자화의 전처리가 행해진 다(스텝 S41). 그 후, 도 17의 (a)에서 설명한 바와 같이, 최초 층 l＝1의 필터 FB와 xb에 의해 행렬의 곱셈 FB와 xb 를 실시하고(스텝 S42), 그 후 활성화 함수 f를 실행하며(스텝 S43), MAX pooling 등의 처리를 하고(스텝 S44), 다음 층 l＝2의 노드의 벡터 x를 얻고, xb를 구성한다. 이 처리를 반복 실행한다(스텝 S45∼S50). 도 18의 예에서는 예를 들면, l＝L층까지 반복하며, 최종적으로 Softmax 등의 계산을 실시하여 인식한다(스텝 S51). 이어서, 본 실시형태예의 처리인 CNN에 적용한 예(도 18의 우측)를 설명한다. 우선, 종래예와 동일하게 입력 신호의 전처리가 행해진다(스텝 S61). 그리고, 행렬 계산의 부분에서 이미 설명한 바와 같이 압축한 필터의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 108, "content": "을 이용하여,"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 109, "content": "의 계산을 실시하며(스텝 S62), 그 후에"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 110, "content": "및"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 111, "content": "을 실행한다(스텝 S63). 추가로, 활성화 함수 f를 실행한다(스텝 S64). 이어서, MAX pooling 등의 처리(스텝 S65)가 행해진다. 그리고 예를 들면, 전처리와 활성화 함수의 실시를 포함한 l＝L－1층까지 동일한 계산을 실행하고(스텝 S66∼ S70), l＝L층만 압축하지 않는 행렬을 이용하여 계산한다(스텝 S71∼S72). 그리고, Softmax 등의 계산을 실시하여 인식한다(스텝 S73). 도 18의 예에서는 l＝L층은 압축하지 않는 행렬을 이용한 방법을 나타냈지만, l＝L층도 압축한 행렬을 이용한 계산을 행해도 된다. 또한 본 실시형태예의 계산은 전체의 일부의 층만 적용해도 된다. 상기와 같이 가중치 행렬을 압축해도 특성이 거의 변하지 않기 때문에, 계산량이 삭감될 수 있다. 필터 행렬은 네트워크 구조의 일부를 나타내는 표현이기도 하고, 필터 행렬의 압축은 네트워크 압축으로 간주할 수 있다. 이상, 설명한 제1 실시형태예 및 제2 실시형태예에서는 DNN, CNN에 대한 네트워크의 압축 방법을 나타냈지만, 이들 실시형태예의 방법에 추가로 더욱 압축해도 된다. 이어서, 제1 실시형태예 및 제2 실시형태예의 방법에 추가로 더욱 압축하는 방법을 나타낸다. 여기서는 제2 실 시형태예를 바탕으로 설명한다. 제2 실시형태예에서는 CN(l)·H(l)·H(l)＝3·2·2＝12로 하고, CN(l＋1)＝4로 한 4×12의 행렬 FB(l)를 압축률 γ＝ 1/2로, 2×12의 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 112, "content": "으로 압축하는 방법을 나타냈다. 여기서는, 더욱 큰 행렬 FB(l)를 이용하여 설명한다. CN(l)·H(l)·H(l)＝64·3·3＝576, CN(l＋1)＝192로 한다. 지금, 행렬의 압축률을 γ＝1/16로 하고, 또한 그 압축한 행렬 중을 부분 행렬로 하며, 부분 행렬끼리가 일부의 열, 또는 행이 중복되도록 구성하는 것을 특징으로 하는 행렬로 한다. 구체적인 예를 도 19에 나타낸다. 압축한 12×576 행렬"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 113, "content": "중의 왼쪽 위에 4×(16·12)의 부분 행렬, 한가운데에 4×(16·13)의 부분 행렬, 오른쪽 아래에 4×(16·13)의 부분 행렬을 배치한다. 여기서, 각 부분 행렬은 중복하는 행은 없고, 중복하는 열은 존재하는 것으로 한다. 이 예에서는 각 부분 행렬 사이에는 1/γ＝16열의 중복이 있는 것으로 한다. 각 부분 행렬의 계산은 식 , , , , 에 따르는 것으로 한다. 이 방법에 의해 연산량은 더욱 삭감되고"}
{"patent_id": "10-2019-7037361", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 114, "content": "으로 약 1/50까지 삭감할 수 있다. 이러한 구조로 해도 식 에 나타내는 바와 같은 계산에 있어서 가중치가 -1이나 1의 값을 취해도 동일한 방정식의 발생을 회피할 수 있기 때문에, 제1 실시형태예나 제2 실시형태예와 동일한 효과가 기대된다. 이 연산 처리를 실장할 때에는 각 부분 행렬마다 도 8이나 도 10에 나타내는 바와 같 은 회로 구성을 이용함으로써 실현될 수 있다. 이상과 같이, DNN에서도 CNN에서도 본 발명의 네트워크 압축법에 의해 연산량을 압축률 γ와 부분 행렬화에 따 라 대폭으로 삭감할 수 있고, 표 1에 나타내는 바와 같이, 압축해도 거의 동등의 정답률을 달성할 수 있기 때문 에 보다 저가격으로 저소비 전력의 CPU, 범용 FPGA 등을 이용하여 실장할 수 있는 효과가 있다. 또한, 본 실시예에서는 x(l＋1)를 구할 때 가중치 행렬 W(l)와 벡터 x(l)에 있어서 가중치 행렬 W(l)의 각 행의 성분 과 벡터 x(l)의 모든 요소의 곱합을 취하지 않고, 일부 요소의 곱합을 취하는 방정식이 일치하지 않는 조합의 룰 을 만드는 수단을 취함으로써 동일한 방정식의 발생을 회피했다. 이 방정식이 일치하지 않는 조합을 생성할 수 있는 계산이면, 상기 방법으로 한정되지 않고 적용 가능해진다. 여기서, 본 발명의 각 실시형태예의 연산 처리를 실행하는 정보 처리 장치인 컴퓨터 장치의 하드웨어 구성의 일 례를 도 20에 나타낸다. 도 20에 나타내는 컴퓨터 장치(C)는 버스(C8)에 각각 접속된 CPU(Central Processing Unit：중앙처리장 치)(C1), ROM(Read Only Memory)(C2) 및 RAM(Random Access Memory)(C3)을 구비한다. 또한, 컴퓨터 장치(C)는 불휘발성 스토리지(C4), 네트워크 인터페이스(C5), 입력 장치(C6) 및 표시 장치(C7)를 구비한다. 또한, 필요에 따라 FPGA(field-programmable gate array)(C9)를 구비해도 된다. CPU(C1)는 본 예의 정보 처리 시스템 장치가 구비하는 각 기능을 실현하는 소프트웨어의 프로그램 코드를 ROM(C2)으로부터 읽어내서 실행한다. RAM(C3)에는 연산 처리 도중에 발생한 변수나 파라미터 등이 일시적으로 기입된다. 예를 들면, CPU(C1)가 ROM(C2)에 기억되어 있는 프로그램을 읽어냄으로써, 이미 설명한 DNN이나 CNN 의 연산 처리가 실행된다. 또한, FPGA(C9)에 DNN이나 CNN의 일부 혹은 모든 것을 실장하여 연산 처리를 실장하 는 것도 가능하다. FPGA를 이용한 경우에는 소비 전력을 삭감이나 고속 연산이 실현될 수 있는 효과가 있다. 불휘발성 스토리지(C4)로는 예를 들면, HDD(Hard disk drive), SSD(Solid State Drive) 등이 이용된다. 이 불 휘발성 스토리지(C4)에는 OS(Operating System), 각종 파라미터, DNN 또는 CNN을 실행하는 프로그램 등이 기록 되어 있다. 네트워크 인터페이스(C5)에는 단자가 접속된 LAN(Local Area Network), 전용선 등을 개재하여 각종 데이터를 입 출력하는 것이 가능하다. 예를 들면, DNN 또는 CNN의 연산을 행하기 위한 입력 신호를 네트워크 인터페이스(C5)가 수신한다. 또한, DNN 또는 CNN의 연산 결과를 네트워크 인터페이스(C5)로부터 외부의 단말장치로 송신한다. 입력 장치(C6)는 키보드 등으로 구성된다. 표시 장치(C7)에는 연산 결과 등이 표시된다. 상술한 실시형태예에서는 DNN이나 CNN의 예를 나타냈지만, 본 발명은 일반 뉴럴 네트워크나 리커런트 뉴럴 네트 워크(RNN) 등 그 일부에 네트워크 구조를 갖는 인공지능이나 기계 학습 또는 행렬 연산에 의해 입력 데이터의 차원 압축이나 압축 센싱을 행하는 시스템이면, 모두에 대해 적용할 수 있다."}
{"patent_id": "10-2019-7037361", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 DNN 구조의 예를 나타내는 도면이다. 도 2는 자기부호화기에 있어서의 예비 트레이닝(각 층마다 행함)의 예를 나타내는 도면이다. 도 3은 본 발명에 의한 자필 숫자의 인식예를 나타내는 도면이다. 도 4는 DNN의 중간 노드의 벡터가 얻어지는 모습을 나타내는 도면이다. 도 5는 본 발명의 제1 실시형태예에 의한 압축 상태의 개요를 나타내는 도면이다. 도 6은 본 발명의 제1 실시형태예에 의한 분할 상태의 개요를 나타내는 도면이다. 도 7은 본 발명의 제1 실시형태예에 의한 시프트를 행하는 계산예를 나타내는 도면이다. 도 8은 도 7의 계산을 행하는 회로 구성예를 나타내는 도면이다. 도 9는 본 발명의 제1 실시형태예에 의한 랜덤 치환을 행하는 계산예를 나타내는 도면이다. 도 10은 도 9의 계산을 행하는 회로 구성예를 나타내는 도면이다. 도 11은 종래 DNN의 처리의 흐름(스텝 S11∼S20)과 본 발명의 제1 실시형태예에 의한 처리의 흐름(스텝 S21∼ S31)을 비교하여 나타내는 플로우 차트이다. 도 12는 본 발명의 제1 실시형태예에 의한 압축률에 의한 정답률의 변화예를 나타내는 특성도이다. 도 13은 CNN의 구조예를 나타내는 도면이다. 도 14는 본 발명의 제2 실시형태예에 의한 압축 상태의 개요를 나타내는 도면이다. 도 15는 본 발명의 제2 실시형태예에 의한 압축 상태의 구체적인 예를 나타내는 도면이다. 도 16은 종래의 처리(a)와 본 발명의 제2 실시형태예에 의한 처리(b)를 비교하여 나타내는 도면이다. 도 17은 종래의 처리(a)와 본 발명의 제2 실시형태예에 의한 처리(b)를 비교하여 나타내는 도면이다. 도 18은 종래 CNN의 처리의 흐름(스텝 S41∼S51)과 본 발명의 제2 실시형태예에 의한 처리의 흐름(스텝 S61∼ S73)을 비교하여 나타내는 플로우 차트이다. 도 19는 본 발명의 실시형태예의 변형예에 의한 처리를 나타내는 도면이다. 도 20은 본 발명의 실시형태예를 적용하는 하드웨어 구성예를 나타내는 블럭도이다."}
