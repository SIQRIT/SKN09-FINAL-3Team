{"patent_id": "10-2023-7017363", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0098817", "출원번호": "10-2023-7017363", "발명의 명칭": "반응형영상 제작 및 서비스 제공방법 및 이를 이용한 프로그램", "출원인": "모멘티 인코포레이션", "발명자": "이철우"}}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장치에 의해 수행되는, 다중 반응형영상 생성 방법에 있어서,제1 사용자 단말로부터 적어도 하나의 기초영상이 수신되면, 상기 적어도 하나의 기초영상을 기반으로 제2 사용자의 조작에 따른 구현하고자 하는 대상체의 움직임만을 포함하는 압축영상을 생성하는 단계-적어도 하나의 기초영상은 사용자의 조작에 따른 반응형으로 구현하고자 하는 대상체의 움직임을 포함하는 원본 영상임-;상기 압축영상에서 생성 가능한 반응에 대응하는 복수의 조작입력으로서 다중 반응형영상 생성조건을 생성하는단계;상기 다중 반응형영상 생성조건을 상기 압축영상에 적용하여 다중 반응형영상을 생성 및 업로드하는 단계; 및제2 사용자가 상기 다중 반응형영상에 대한 조작을 입력함에 따라 조작입력정보가 수신되면, 상기 조작입력정보를 상기 다중 반응형영상에 적용하여 영상을 재생하는 단계;를 포함하며,상기 압축영상은, 상기 적어도 하나의 기초영상을 분할 또는 보정하여 생성된 이미지의 조합에 대한 정보를 포함하는 스텍 구조의 데이터이고,상기 다중 반응형영상 생성조건은, 상기 압축영상의 특정 영역에 결합되어 반응형으로 구현하기 위한 정보를 포함하는 데이터를 포함하고,상기 조작입력정보는, 상기 다중 반응형영상을 기반으로 사용자 조작에 대한 정보를 포함하는 데이터를 포함하는 것을 특징으로 하는,반응형 영상 기반 서비스 제공방법."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 업로드하는 단계 이후,상기 제2 사용자 단말로부터 상기 다중 반응형영상을 기반으로 하는 요청 정보가 입력되면, 상기 요청 정보를기반으로 요소 영상을 획득하고, 인공지능을 기반으로 상기 획득된 요소 영상을 변형한 복수의 반응영상을 생성하는 단계를 더 포함하는 것을 특징으로 하는,반응형 영상 기반 서비스 제공방법."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 업로드하는 단계 이후,상기 제2 사용자 단말로부터 상기 다중반응형 영상을 기반으로 하는 반응 스크립트 정보가 수신되면, 상기 다중반응형영상에 상기 반응 스크립트 정보를 더 결합하고, 이후 입력되는 조작입력정보에 따라 반응을 구현하는 것을 특징으로 하는,반응형 영상 기반 서비스 제공방법."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 압축영상을 생성하는 단계는,상기 적어도 하나의 기초영상에서 영상구간 분할 또는 영상프레임의 유사도 인식을 통해 반응형으로 구현하지공개특허 10-2023-0098817-3-않는 영상프레임을 삭제하는 것을 특징으로,반응형 영상 기반 서비스 제공방법."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 압축영상을 생성하는 단계는,동일한 대상체를 포함하는 제1기초영상 및 제2기초영상이 상기 대상체가 동일한 경로에 대한 움직임을 포함하는경우,상기 제1기초영상 및 상기 제2기초영상에서 동일한 경로의 움직임이 포함된 구간영상을 추출하여, 상기 제1기초영상 및 상기 제2기초영상 중에서 하나에 포함된 중복 구간영상을 남기는 것을 특징으로 하는,반응형 영상 기반 서비스 제공방법."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 복수의 조작입력은,멀티 터치(multi touch), 멀티액션(multi actions), 멀티 오브젝트(multi objects), 멀티 씬(multi scenes),멀티 아웃컴(multi outcomes) 및 멀티 리액션(multi reactions) 중 적어도 하나의 형태인 것을 특징으로 하는,반응형 영상 기반 서비스 제공방법."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "통신모듈;다중 반응형영상 기반의 서비스를 제공하기 위해 필요한 적어도 하나의 프로세스를 저장하는 저장모듈;상기 적어도 하나의 프로세스를 기반으로, 상기 다중 반응형영상 기반의 서비스를 제공하기 위한 동작을 제어하는 제어모듈을 포함하며,상기 제어모듈은,제1 사용자 단말로부터 적어도 하나의 기초영상이 수신되면, 상기 적어도 하나의 기초영상을 기반으로 제2 사용자의 조작에 따른 구현하고자 하는 대상체의 움직임만을 포함하는 압축영상을 생성하고-적어도 하나의 기초영상은 사용자의 조작에 따른 반응형으로 구현하고자 하는 대상체의 움직임을 포함하는 원본 영상임-, 상기 압축영상에서 생성 가능한 반응에 대응하는 복수의 조작입력으로서 다중 반응형영상 생성조건을 생성하고, 상기 다중반응형영상 생성조건을 상기 압축영상에 적용하여 다중 반응형영상을 생성 및 업로드하고, 상기 제2 사용자가상기 다중 반응형영상에 대한 조작을 입력함에 따라 조작입력정보가 수신되면, 상기 조작입력정보를 상기 다중반응형영상에 적용하여 영상을 재생하며,상기 압축영상은, 상기 적어도 하나의 기초영상을 분할 또는 보정하여 생성된 이미지의 조합에 대한 정보를 포함하는 스텍 구조의 데이터이고,상기 다중 반응형영상 생성조건은, 상기 압축영상의 특정 영역에 결합되어 반응형으로 구현하기 위한 정보를 포함하는 데이터를 포함하고,상기 조작입력정보는, 상기 다중 반응형영상을 기반으로 사용자 조작에 대한 정보를 포함하는 데이터를 포함하는 것을 특징으로 하는,반응형 영상 기반 서비스 제공장치."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제어모듈은, 상기 업로드할 시,공개특허 10-2023-0098817-4-상기 제2 사용자 단말로부터 상기 다중 반응형영상을 기반으로 하는 요청 정보가 입력되면, 상기 요청 정보를기반으로 요소 영상을 획득하고, 인공지능을 기반으로 상기 획득된 요소 영상을 변형한 복수의 반응영상을 생성하는 단계를 더 포함하는 것을 특징으로 하는,반응형 영상 기반 서비스 제공장치."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 제어모듈은, 상기 업로드할 시,상기 제2 사용자 단말로부터 상기 다중반응형 영상을 기반으로 하는 반응 스크립트 정보가 수신되면, 상기 다중반응형영상에 상기 반응 스크립트 정보를 더 결합하고, 이후 입력되는 조작입력정보에 따라 반응을 구현하는 것을 특징으로 하는,반응형 영상 기반 서비스 제공방법."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 제어모듈은, 상기 압축영상을 생성할 시,상기 적어도 하나의 기초영상에서 영상구간 분할 또는 영상프레임의 유사도 인식을 통해 반응형으로 구현하지않는 영상프레임을 삭제하는 것을 특징으로,반응형 영상 기반 서비스 제공장치."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 제어모듈은, 상기 압축영상을 생성할 시,동일한 대상체를 포함하는 제1기초영상 및 제2기초영상이 상기 대상체가 동일한 경로에 대한 움직임을 포함하는경우,상기 제1기초영상 및 상기 제2기초영상에서 동일한 경로의 움직임이 포함된 구간영상을 추출하여, 상기 제1기초영상 및 상기 제2기초영상 중에서 하나에 포함된 중복 구간영상을 남기는 것을 특징으로 하는,반응형 영상 기반 서비스 제공장치."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 복수의 조작입력은,멀티 터치(multi touch), 멀티액션(multi actions), 멀티 오브젝트(multi objects), 멀티 씬(multi scenes),멀티 아웃컴(multi outcomes) 및 멀티 리액션(multi reactions) 중 적어도 하나의 형태인 것을 특징으로 하는,반응형 영상 기반 서비스 제공장치."}
{"patent_id": "10-2023-7017363", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "하드웨어인 컴퓨터와 결합되어, 제1항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된, 반응형영상 제공프로그램."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 반응형영상 제작 및 서비스 제공방법 및 이를 이용한 프로그램 에 관한 것으로, 특히, 본 발명의 일실 시예에 따른 반응형 영상 기반 서비스 제공방법은, 제1사용자의 요청에 따라 제1반응형 영상을 업로드하는 단계; 제1반응형 영상에 대한 제2사용자의 조작을 수신하는 단계; 상기 제2사용자의 조작을 제1반응형 영상에 적용하기 위한 반응생성데이터를 생성하는 단계; 및 제2사용자 조작에 따른 반응생성데이터를 적용한 반응 구현이 요청되 면, 상기 반응생성데이터를 상기 제1반응형 영상에 적용하여 재생하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다중 반응형영상 제작 및 서비스 제공방법 및 이를 이용한 프로그램에 관한 것으로, 보다 자세하게는 영상을 시청하는 사용자의 입력조작에 따라 변동적으로 재생될 수 있는 영상을 생성하는 다중 반응형영상 제작 및 서비스 제공방법 및 이를 이용한 프로그램에 관한 것이다."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 영상촬영기술이 매우 발전하고 있다. 캠코더, 디지털카메라뿐만 아니라 스마트폰 등의 이동단말기도 높은 해상도의 영상을 촬영할 수 있다. 또한, 360도 카메라, 3D영상 카메라 등이 등장하고 있다. 영상은 영상촬영장치에 의해 촬영되어 특정한 포맷으로 저장되고, 재생 가능한 단말기에 의해 재생된다. 영상 재생은 시청자와 상호작용(Interaction)이 없이 일방적으로 시간순서대로 제공된다. 즉, 시청자는 재생되는 영 상을 통해 시각적인 감각만을 느낄 수 있다."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 일반동영상 또는 복수의 영상프레임이 저장된 영상데이터베이스(예를 들어, 기초영상)를 기반으로, 사용자의 조작에 따라 다양한 조건 재생을 수행하는 다중 반응형영상을 제작하는, 다중 반응형영상 제작방법을 제공하고자 한다. 또한, 본 발명은 복수의 기초영상을 기반으로 여러 입력조작에 대한 출력영상을 제공할 수 있으면서 압축을 통 해 용량을 줄여서 다중 반응형 영상을 생성하는 방법을 제공하고자 한다. 또한, 본 발명은 복수의 입력조작이 함께 반영되어 별개 조작 또는 동시 조작을 통해 다양한 출력 영상을 생성 할 수 있는 다중 반응형 영상을 생성 및 사용하는 방법을 제공하고자 한다. 또한, 본 발명은 일반동영상 또는 2차원 또는 3차원 영상데이터베이스에 특정조건을 적용하여 다양한 기능이 적 용되는 다중 반응형영상을 구현하는 다중 반응형영상 생성파일을 제공하는, 다중 반응형영상 생성파일 구현방법 및 프로그램을 제공하고자 한다. 또한, 본 발명은 사용자의 다중 반응형영상 조작을 획득하여 영상 내의 대상체에 대한 사용자 관심도를 산출하 는, 다중 반응형영상 기반의 사용자 관심도 분석방법을 제공하고자 한다. 또한, 기존에 동영상의 시간 순으로 재생되는 것으로 제한되던 컨텐츠의 한계를 극복하기 위해, 영상 내의 사건 (Event)축을 추가(예를 들어, 사건 단위로 영상이 제어되는 것을 추가)함에 따라 영상이 출력되는 방향 또는 순 서를 사용자의 조작에 의해 조절할 수 있게하는 다중 반응형 자료구조를 생성하는, 다중 반응형 영상 생성방법 을 제공하고자 한다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른 반응형 영상 기반 서비스 제공방법은, 제1사용자의 요청에 따라 제1반응형 영상을 업로드하는 단계; 제1반응형 영상에 대한 제2사용자의 조작을 수신하는 단계; 상기 제2사용자의 조작을 제1반응 형 영상에 적용하기 위한 반응생성데이터를 생성하는 단계; 및 제2사용자 조작에 따른 반응생성데이터를 적용한 반응 구현이 요청되면, 상기 반응생성데이터를 상기 제1반응형 영상에 적용하여 재생하는 단계;를 포함한다. 본 발명의 다른 일실시예에 따른 반응형 영상 기반 서비스 제공방법은, 서비스서버가 복수의 사용자로부터 특정 한 반응형 영상에 대한 사용자 조작을 수신하는 단계; 및 상기 반응형 영상에 대한 조작 통계 분석결과를 제공 하는 단계;를 포함한다. 본 발명의 또 다른 일실시예에 따른 반응형 영상 재생방법은, 서비스서버가 사용자 클라이언트로부터 반응형 영 상의 조작 위치를 획득하는 단계; 서비스서버가 조작 위치에 대한 어드레스를 사용자 클라이언트로 전송하되, 상기 어드레스는 클라이언트에서 출력해야하는 프레임 정보인, 어드레스 전송단계; 및 사용자 클라이언트가 상 기 어드레스에 대응되는 이미지 처리를 통해 실시간 출력하는 단계;를 포함한다."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같은 본 발명에 따르면, 아래와 같은 다양한 효과들을 가진다. 첫째, 사용자의 조작에 따른 다양한 재생조건을 다중 반응형영상에 적용함에 따라, 사용자에게 단순히 시간의 축에 의해 제한되는 기존 미디어들과는 달리, 사건(Event)에 따라 각기 다른 다양한 출력이 가능한 다중 반응형 영상을 제공할 수 있다. 이를 통해, 사용자들의 다양한 결과를 확인해보기 위한 반복적인 시도를 유도함에 따라, 다중 반응형영상에 포함된 대상체(즉, 물체)에 대한 사용자 관심도를 높일 수 있다. 즉, 다중 반응형영상 생성파일을 통해 영상에 특정한 조건설정을 수행함에 따라, 사용자에게 다양한 사건(Event)들이 적용된 다중 반 응형영상을 제공할 수 있다. 둘째, 다중 반응형영상 생성파일을 일반동영상이나 복수의 영상프레임 조합과 함께 재생함에 따라 다양한 액션 (즉, 반응)을 적용할 수 있다. 셋째, 동영상 프레임에 영상 분할 또는 크롭을 적용함에 따라 촬영한 하나의 영상을 기반으로 여러가지 액션을 구현할 수 있는 효과가 있다. 넷째, 특정한 사용자의 다중 반응형영상에 대한 조작 내역을 기록함에 따라 사용자의 영상에 대한 반응을 파악 할 수 있다. 예를 들어, 사용자의 다중 반응형영상에 대한 터치조작 횟수, 터치조작을 수행한 프레임과 프레임 내 대상체 등을 파악하여 사용자가 관심대상, 관심도를 파악할 수 있으며, 사용자에 대한 사용자 관심도를 파악 할 수 있다. 또한, 각각의 이벤트가 다양한 입력 방식의 조건들과 결합되어, 현실세계 현상들의 다양한 속성(예를 들어, 중 력과 힘의작용, 무게감, 저항값, 환경측면과 사물측면 모두에서의 표면질감, 탄성, 밀도, 크기, 모양, 대상체와 의 거리 그리고 소리 등)을 온전히 담아내어 현실감을 극대화하고, 직접 다양한 방식으로 상호작용 할 수 있는 풍부한 경험 컨텐츠를 만들어 낼 수 있다. 또한, 본 발명의 실시예들에 의해 생성된 다중 반응형 영상을 이용하여, 사용자의 다중 반응형 영상 컨텐츠에 대한 상호작용 데이터를 축적 및 분석하여 사용자의 의도와 욕구를 파악하고, 데이터 분석 결과를 기반으로 사 용자 특성을 파악하는 초개인화를 수행할 수 있다."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명한다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 게시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현"}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "될 수 있으며, 단지 본 실시예들은 본 발명의 게시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 본 명세서에서 다중 반응형영상은, 영상을 시청하는 사용자(즉, 시청자)의 특정한 입력조작에 상응하는 형태로 영상이 변화 또는 재생되는 영상을 의미한다. 예를 들어, 촬영된 원본영상의 특정한 움직임에 대응되는 사용자 의 입력조작이 연결되어, 사용자의 조작에 따라 해당 영상 내의 물체가 움직이는 것과 같이 재생되는 영상을 의 미할 수 있다. 본 명세서에서 '컴퓨터'는 연산처리를 수행할 수 있는 다양한 장치들이 모두 포함된다. 예를 들어, 컴퓨터는 데 스크 탑 PC, 노트북(Note Book) 뿐만 아니라 스마트폰(Smart phone), 태블릿 PC, 셀룰러폰(Cellular phone), 피씨에스폰(PCS phone; Personal Communication Service phone), 동기식/비동기식 IMT-2000(International Mobile Telecommunication-2000)의 이동 단말기, 팜 PC(Palm Personal Computer), 개인용 디지털 보조기(PDA; Personal Digital Assistant) 등도 해당될 수 있다. 또한, 컴퓨터는 클라이언트로부터 정보를 수신하는 서버컴 퓨터가 해당될 수도 있다. 이하, 본 명세서에서 컴퓨터는 단말기로 표현될 수도 있다. 본 명세서에서 '입력조작'은, 다중 반응형영상을 재생하는 컴퓨터의 입력수단을 통해 수신되는 사용자의 영상에 대한 조작을 의미한다. 예를 들어, 상기 입력조작은 마우스 또는 터치스크린과 같은 입력수단을 통해 영상 내 특정한 지점 또는 영역에 입력될 수 있는 조작(예를 들어, 클릭 조작, 드래그 조작, 특정 시간 이상의 접촉터치 조작, 포스터치 조작(즉, 터치스크린 또는 터치패드에 특정압력을 가하는 터치조작) 등)을 포함할 수 있다. 또 한, 예를 들어, 상기 입력조작은, 컴퓨터(또는 단말기)가 구비하는 센서(예를 들어, 가속도센서, 자이로센서 등)을 입력수단으로 하여 획득될 수 있는 단말기 자체의 배치상태 또는 움직임 등을 포함할 수 있다. 본 명세서에서 '대상체'는 사용자에 의해 조작될 물체를 의미한다. 예를 들어, 사용자가 손으로 특정한 물체를 만지는 동작을 촬영한 영상인 경우, 상기 대상체는 사용자에 의해 만져지는 물체를 의미한다. 또한, 특정한 사 람의 움직임을 촬영한 영상인 경우, 상기 대상체는 영상 내의 사람일 수 있다. 본 명세서에서 '조작체'는 영상 내에서 대상체에 조작을 수행하는 것을 의미한다. 예를 들어, 영상 내에서 손으 로 가방 또는 배게를 만지거나 누르는 경우, 조작체는 가방 또는 배게를 만지는 손을 의미한다. 본 명세서에서 '기초영상'은 반응형으로 구현되지 않은 영상을 의미한다. 즉, 기초영상은 일반적인 촬영방식으 로 생성된 동영상 또는 공간상의 대상체 위치별로 영상프레임을 저장한 복수의 영상프레임 조합이 해당된다. 본 명세서에서 '압축영상'은 기초영상을 반응형 영상으로 구현하기 위해 최소 움직임 단위로 압축된 영상을 의 미한다. 예를 들어, 기초 영상에 동일한 움직임이 반복적으로 포함된 경우, 압축영상은 반복되는 움직임을 삭제 하고 하나만 남긴 것이다. 또한, 예를 들어, 기초영상에 제1위치에서 제2위치로의 움직임과 제2위치에서 제1위 치로의 움직임을 모두 포함하는 경우, 압축영상은 제1위치에서 제2위치로 움직이는 기초영상만으로 남기고, 제2 위치에서 제1위치로의 움직임은 남겨진 기초영상을 역방향으로 재생할 수 있다. 본 명세서에서 '다중 반응형영상 생성파일'은, 복수의 기초영상이 압축되어 생성된 것으로 사용자의 조작에 따 라 여러 동작을 재생할 수 있는 영상 파일이거나, 하나 이상의 기초영상과 함께 재생됨에 따라 다중 반응형영상 으로 구현할 수 있는 메타데이터를 의미한다. 이하, 도면들을 참고하여, 본 발명의 실시예들에 따른 다중 반응형영상 생성방법를 설명한다. 도 1은 본 발명의 일실시예에 따른 다중 반응형영상 생성방법에 대한 순서도이다. 컴퓨터가 기초영상을 획득한다(S200). 상기 기초영상은 사용자의 조작에 따른 반응형으로 구현하고자 하는 대상 체의 움직임을 포함하는 원본 영상이다. 컴퓨터는 이미 생성되어 저장된 기초영상을 로드할 수 있고, 영상프레임을 실시간으로 획득하여 기초영상을 생 성(즉, 다중 반응형영상 생성기능이 포함된 프로그램 또는 어플리케이션을 구동한 후, 해당 프로그램 또는 어플 리케이션을 통해 카메라 기능을 활성화하여 기초영상을 바로 촬영)할 수도 있다. 반응형 영상 제작자(예를 들어, 컨텐츠 공급자 또는 개인 사용자)는 반응형으로 구현하고자 하는 동작이 포함된 영상을 촬영한다. 구체적인 일실시예로, 컴퓨터는 사용자로부터 동일한 대상체의 여러 움직임에 대한 영상을 획득한 후 다중 반응 형 영상의 형태로 생성할 수 있다. 예를 들어, 대상체가 사용자의 손인 경우, 컴퓨터는 사용자의 검지손가락을 펼친 상태에서 여러 방향으로 움직이거나 구부리는 복수의 영상을 획득한다. 또한, 예를 들어, 도 2에서와 같이, 특정한 조작에 따른 반응으로 본인의 머리를 상하좌우로 회전하거나 얼굴 표정 변화가 제공되는 반응형 영상을 제작하고자 하는 경우, 사용자는 원하는 고개 움직임과 표정들이 모두 포 함된 영상을 촬영한다. 또한, 사용자에 의해 입력되는 조작에 따라 물풍선이 터지거나 바닥에서 튀어져 올라오는 반응형 영상을 생성하 고자 하는 경우, 사용자는 동일한 색상 및 크기의 물풍선을 떨어뜨려서 터지는 제1영상과 물풍선이 터지지 않고 튀어오르는 제2영상을 순차적으로 촬영한다. 또한, 특정한 움직임을 수행한 후 기존 움직임의 반복이 아닌 상이한 사건이 발생하는 하나의 기초영상을 획득 한다. 즉, 컴퓨터는 대상체에 대해 복수의 사건이 발생하는 영상을 기초영상으로 획득한다. 예를 들어, 도 3에 서와 같이, 컴퓨터는 물풍선이 아래로 이동하는 움직임의 사건(제1 사건)과 물풍선이 바닥에 충돌한 후 터지는 사건(제2 사건)을 포함하는 기초영상을 획득한다. 또한, 예를 들어, 나뭇가지가 구부러지는 사건(제1 사건)과 나뭇가지가 부러지는 사건(제2 사건)을 포함하는 영상을 기초영상으로 획득한다. 또한, 컴퓨터는 공기가 채워진 풍선을 누름에 따라 움푹들어가는 사건(제1 사건)과 풍선이 터지는 사건(제2사건)을 포함하는 영상을 기초영상 으로 획득한다. 또한, 도 4에서와 같이, 여러 방향 또는 여러 높이로 그릇에 담긴 파스타를 들어올리는 동작을 구현할 수 있는 반응형 영상을 구현하고자 하는 경우, 사용자는 파스타를 들어올리는 동작을 반복하거나 그릇에 담긴 파스타를 들어서 3차원공간 상의 여러 위치로 이동시키는 영상을 촬영한다. 또한, 컴퓨터는 조작체를 이용하여 대상체를 변형하는 영상을 획득한 후, 조작체를 삭제하는 보정을 수행한 영 상을 기초영상으로 저장할 수 있다. 컴퓨터가 상기 기초영상을 기반으로 압축영상을 생성한다(S400; 압축영상 생성단계). 상기 압축영상은 반응형으 로 사용자의 조작에 따른 구현하고자 하는 대상체의 움직임만을 포함하는 것이다. 이하, 압축영상을 생성하는 방식에 대한 상세한 설명을 기술한다. 일실시예로, 컴퓨터는 기초영상 내에서 반응형으로 구현하는 과정에서 불필요한 영상 구간을 삭제한다. 예를 들 어, 사용자가 다중 반응이 가능한 영상을 구현하고자 대상체의 여러 움직임을 촬영하는 경우, 기초영상은 제1움 직임 획득과 제2움직임 획득 사이에 반응형으로 구현되지 않을 영상프레임을 포함할 수 있다. 컴퓨터는 반응형 으로 구현되지 않을 영상구간을 분리하여 삭제할 수 있다. 예를 들어, 컴퓨터는 기초영상에 포함된 전체프레임을 인식한 후 대상체 움직임의 유사도 차이가 큰 프레임을 삭제 가능한 것으로 자동 분리한 후 제거할 수 있다. 또한, 예를 들어, 컴퓨터는 기초영상을 복수의 구간으로 자동 분할하고, 사용자로부터 반응형으로 구현하지 않는 영상 구간을 선택받은 후 삭제할 수 있다. 구체적인 예 로, 컴퓨터는 기초영상을 대상체 움직임 단위(예를 들어, 고개를 오른쪽으로 돌리는 움직임, 고개를 왼쪽으로 돌리는 움직임 등)로 영상구간을 분리하고, 복수의 대상체 움직임 단위 사이의 영상구간을 삭제할 수 있다. 또한, 다른 일실시예로, 기초영상에 포함된 복수의 움직임 영상에 중복되는 영상이 포함되어 있는 경우, 컴퓨터 는 중복되는 구간을 삭제할 수 있다. 예를 들어, 제1기초영상, 제2기초영상 및 제3기초영상이 처음에 동일한 손 가락 위치에서 배치된 상태에서 상이한 방향으로 움직임을 수행하는 경우, 컴퓨터는 동일한 위치에 배치된 영상 프레임을 하나만 남긴다. 그 후, 제1기초영상과 제2기초영상이 동일한 움직임을 유지하고 제3기초영상이 나눠져서 움직임을 수행하게 되면, 컴퓨터는 제1기초영상과 제2기초영상의 해당 시점의 프레임을 하나만 남기게 되고, 제3기초영상에 대한 프레임은 별도로 저장한다. 또한, 예를 들어, 대상체가 동일한 움직임이 생성된 후 상이한 결과가 구현되는 제1기초영상과 제2기초영상의 경우(예를 들어, 풍선을 바닥으로 떨어뜨리는 복수 영상에서 속도 차이에 의해 떨어진 후 결과가 달라지는 경우), 동일한 경로를 움직이는 구간은 하나만 남기고 결과에 제1기초영상과 제2기초영상의 반응 결과에 해당하 는 구간만 각각 남길 수 있다. 이를 위해, 컴퓨터는 제1기초영상과 제2기초영상을 비교하여 동일한 대상체 움직 임을 가지는 구간을 분리하여 중복 구간을 하나만 남기고, 중복 영상구간, 제1 결과영상 및 제2결과영상으로 분 리하여 저장할 수 있다. 또한, 예를 들어, 전체 기초영상 내에서 대상체가 동일한 구간을 반복 이동하는 경우(예를 들어, 고개를 좌우로 회전하는 경우), 정면을 바라보는 상태에서 왼쪽을 바라본 후 정면으로 돌아오는 제1구간영상 및 정면을 바라보 는 상태에서 오른쪽을 바라본 후 정면으로 돌아오는 제2구간영상이 반복되는 것이므로, 컴퓨터는 제1구간영상과 중복되는 부분과 제2구간영상과 중복되는 부분을 제거한다. 또한, 예를 들어, 제1위치에서 제2위치로 이동한 후 다시 제1위치로 되돌아오는 경우, 컴퓨터는 제1위치에서 제 2위치로 이동하는 제1구간영상만 남기고, 제2위치에서 제1위치로 돌아오는 제2구간영상을 삭제하여 압축할 수 있다. 제2구간영상은 제1구간영상을 역방향으로 재생함에 따라 출력할 수 있으므로, 컴퓨터는 제2구간영상을 삭 제하고 제1구간영상만을 압축영상에 남긴다. 예를 들어, 기초영상 내 대상체인 사람이 정면을 바라보다가 좌측 으로 고개를 돌렸다가 정면으로 돌아오는 경우, 컴퓨터는 정면에서 좌측을 바라보는 제1구간영상만을 남길 수 있다. 이를 위해, 컴퓨터는 기초영상 내에 대상체의 움직임이 동일 경로 왕복으로 이루어지는 부분을 탐색하고, 움직임 방향이 변경되기 시작하는 프레임(예를 들어, 제1방향으로의 움직임에서 반대인 제2방향으로의 움직임으 로 변화되기 시작하는 프레임)을 기준으로 영상을 분할한 후 제1구간영상만을 남기는 과정을 수행한다. 또한, 특정한 움직임을 수행한 후 기존 움직임의 구간 반복이 아닌 상이한 사건이 발생하는 하나의 기초영상(예 를 들어, 물풍선을 공중에서 떨어뜨린 후 터지는 영상)을 복수의 사건으로 분할하여 저장하는 압축영상을 생성 할 수 있다. 구체적으로, 상기 압축영상 생성단계는, 상기 기초영상이 특정한 기준시점 전후로 대상체의 외형 변화가 상이한 제1사건 구간 및 제2사건 구간을 포함하는 경우, 상기 제1사건 구간을 순방향 재생한 후 상기 제2사건 구간을 이어서 재생하는 제1재생 유형 및 제1사건 구간을 순방향 재생한 후 역방향 재생을 수행하는 제2재생 유형을 설 정한다. 후술되는 다중 반응형영상 생성조건 수신단계에서, 동일한 사용자조작 유형에 대해 특정한 기준 조작세 기, 기준 이동 길이(즉, 터치 디스플레이 상에 스와이핑 조작이 가해지는 길이), 기준 조작속도 또는 기준 조작 시간길이(즉, 특정 위치에 연속으로 터치조작이 인가되는 시간길이)를 기반으로 제1조작과 제2조작을 나누어 상 기 제1 재생유형 및 상기 제2 유형을 연결할 수 있다. 이하, 컴퓨터가 복수의 사건을 포함하는 하나의 기초영상으로 반응형 영상 구현이 가능한 압축영상을 생성하는 방식을 상세히 설명한다. 사용자에 의해 입력되는 조작에 따라 물풍선이 터지거나 바닥에서 튀어져 올라오는 반응형 영상을 생성하고자 하는 경우, 사용자는 물풍선을 떨어뜨려서 터지는 제1영상만 촬영한 뒤 하나의 이벤트에 해당되는 제1영상을 제 1 사건 구간과 제2 사건 구간으로 나눈 다음, 제1 사건 구간만 순방향 재생을 한 후 역방향 재생을 수행하는 제 1 재생과 제1 사건 구간을 순방향 재생 후에 제1 사건 구간을 재생하는 제2 재생으로 생성할 수 있다. 컴퓨터는 제1 재생과 제2 재생을 각각 상이한 사용자 조작에 연결하여, 사용자에 의해 입력되는 사용자 조작에 따라 재생 되도록 할 수 있다. 일 예로, 도 3에서와 같이, 물풍선을 떨어뜨려서 물풍선이 터지는 영상을 기초영상으로 이용하는 경우, 컴퓨터 는 물풍선이 떨어지다가 터지기 전의 기준시점을 획득하고, 기준시점을 중심으로 제1 사건 구간과 제2 사건 구 간을 분할한다. 컴퓨터는 반응형 영상을 생성하는 사용자로부터 기준시점을 입력받을 수도 있고, 딥러닝 트레이 닝이 된 학습모델을 통해 자동으로 기준시점을 산출할 수도 있다. 예를 들어, 대상체의 외형에 변형이 기준값 이상 발생하는 시점을 탐색하는 학습모델을 통해 자동으로 인식할 수도 있다. 이에 따라, 컴퓨터는 제1사용자 조작(예를 들어, 특정한 기준속도 이하로 대상체인 물풍선이 움직이도록 하는 약한 스와이핑 조작)에 따라 물풍 선이 떨어지는 제1 사건 구간을 순방향 재생한 후 제1 사건 구간을 역방향 재생하는 제1 재생과 제2 사용자 조 작(예를 들어, 특정한 기준속도 초과로 대상체인 물풍선이 움직이도록 하는 강한 스와이핑 조작)에 따라 물풍선 이 떨어지는 제1 사건 구간을 순방향 재생한 후 제2 사건 구간을 이어서 재생하는 제2 재생을 구현할 수 있다.또한, 특정한 기준속도 이하로 대상체를 떨어뜨리는 경우에도 사용자의 스와이핑 조작에 대응되는 속도에 따라 상이한 사건(이벤트)를 분류할 수 있다. 예를 들어, 후술되는 바와 같이 물풍선의 이동방향으로 사용자조작이 연결된 후, 컴퓨터는 터치조작의 세기에 따라 제1 사건 구간의 역방향 재생이 시작되는 시점을 설정할 수 있다. 풍선이 떨어뜨리는 속도에 따라 바닥에 접촉된 후 풍선이 변형되는 정도에 차이가 있으므로, 컴퓨터는 사용자조 작의 세기가 약할수록 제2 사건과의 분할 기준이 기준시점으로부터 긴 시간 이전까지 재생한 후 역방향 재생을 시작할 수 있다. 또한, 다른 일 예로, 나뭇가지를 부러뜨리는 당겨서 휘어진 후 부러지는 영상을 기초영상으로 이용하는 경우, 컴퓨터는 나뭇가지가 부러지는 시점을 기준시점으로 설정하고 제1 사건 구간과 제2 사건 구간으로 분할한다. 상 기 기준시점은 반응형 영상을 제작하는 사용자에 의해 입력되어 설정될 수도 있고, 대상체 외형의 기준 이상의 변화(즉, 나뭇가지가 부러지는 변화)가 발생하는 시점을 자동으로 산출하여 설정할 수도 있다. 또한, 제1사건이 순방향 재생과 역방향 재생이 수행됨에 따라 현실적으로 처음 움직임을 시작한 위치보다 위로 반동하는 영상을 생성하기 위해, 제1 사건 구간의 움직임에서 중심 위치를 압축영상의 시작시점으로 설정한다. 상기 시작시점은 반응형 영상을 생성하는 사용자에 의해 설정될 수도 있고, 컴퓨터가 기초영상 내에서 대상체가 이동하는 경로를 산출한 후 경로의 중심위치가 되는 프레임을 시작시점으로 설정할 수도 있다. 또한, 제1 사건 구간 내에서 사용 자에 의해 입력되는 사용자 조작 수준(예를 들어, 터치 디스플레이에 입력되는 스와이핑 조작의 길이)에 따라 시작시점으로부터 순방향 재생을 수행한 후 역방향 재생이 시작되는 시점을 상이하게 설정할 수 있다. 이에 따라, 컴퓨터는 하나의 기초영상을 이용하여, 사용자 조작에 따라 여러가지 반응을 생성하는 반응형 영상 을 구현할 수 있는 압축영상을 생성할 수 있다. 컴퓨터는 제1 사건 구간을 시작시점으로부터 영상프레임을 순방 향으로 재생한 후 기준시점 이후의 제2 사건 구간을 이어서 재생하는 제1 재생유형을 구현할 수 있다. 또한, 제 1 사건 구간 내의 시작시점으로부터 특정한 제1 정지시점까지 순방향 재생을 한 후 시작시점까지 역방향 재생을 하고, 시작시점으로부터 기초영상의 초기시점 방향으로 제2 정지시점까지 역방향 재생을 한 후 시작시점으로 다 시 순방향 재생을 진행하는 제2 재생 유형을 구현할 수 있다. 컴퓨터는 제2 재생 시에 제1 정지시점과 제2 정지 시점을 점차적으로 시작시점에 근접하도록 줄이는 재생을 반복함에 따라 나뭇가지 진동할 때 진동폭이 줄어들면 서 멈추는 현실감 있는 반응형 영상을 구현할 수 있게 한다. 상기 제2 정지시점은 상기 제1 정지시점에 대응하여 설정된다. 예를 들어, 시작시점의 프레임 상의 대상체 위치 (이하, 시작위치)와 상기 제1 정지시점 상의 대상체 위치의 차이값과 동일하거나 특정 비율만큼 줄어든 값만큼 시작위치에서 초기영상 내의 초기위치 방향으로 대상체가 떨어진 영상프레임의 시점을 제2 정지시점으로 설정한 다. 또한, 컴퓨터는 제2 재생유형에서 제1 정지시점의 위치에 따라 세부 재생유형(예를 들어, 제2-1 재생유형, 제2- 2 재생유형 등)을 나눌 수 있다. 즉, 대상체의 기준위치로부터 순방향으로 변형된 후 진동 운동을 하는 정도를 세부유형으로 나눌 수 있다. 후술되는 바와 같이, 컴퓨터는 제1 재생유형과 제2 재생유형에 상이한 사용자조작을 연결할 수 있다. 예를 들어, 대상체에 대해 스와이핑하는 사용자조작을 연결하는 경우, 컴퓨터는 사용자의 요청에 따라 특정 기준속도 또는 특정 기준길이 초과의 스와이핑 조작과 제1 재생 유형을 연결하고, 특정한 기준속도 또는 기준길이 이하의 스와이핑 조작과 제2 재생 유형을 연결할 수 있다. 또한, 컴퓨터는 상기 기준속도 또는 기준길이를 분할하여 제 2재생 유형의 세부유형과 순차적으로 연결할 수 있다. 또한, 다른 일 예로, 컴퓨터는 공기가 채워진 풍선을 눌러서 움푹들어가는 변형 후에 풍선이 터지는 영상을 기 초영상으로 활용하여, 풍선이 터지기 직전 시점을 기준시점으로 설정한다. 컴퓨터는 기준시점 이전을 제1 사건 구간으로 설정하고, 기준 시점 이후를 제2 사건 구간으로 설정한다. 이에 따라, 컴퓨터는 제1 사건 구간 재생 후에 제2 사건 구간을 이어서 재생하는 제1 재생유형과 제1 구간을 순방향 재생과 역방향 재생을 수행하는 제2 재생 유형을 설정한다. 후술되는 바와 같이, 컴퓨터는 특정한 포스터치 세기 초과 또는 터치조작이 입력되는 시 간길이 초과의 사용자조작과 제1재생 유형을 연결하고, 특정한 포스터치 세기 이하 또는 터치조작이 입력되는 시간길이 이하의 사용자조작과 제2 재생 유형을 연결한다. 반응형 영상을 생성하기 위해 기초영상을 압축영상으로 생성하는 방식은 이에 한정되지 않고 다양한 방식이 적 용될 수 있다. 컴퓨터는 상기와 같은 영상프레임 또는 영상구간 추출과정을 복수의 기초영상에 대해 수행하게 된다. 이를 통해, 컴퓨터는 하나의 대상체가 움직임을 수행하는 복수의 기초영상으로 다중 반응형 영상을 제작하는 과정에서 필요한 영상프레임을 최소화할 수 있다. 또한, 컴퓨터는 복수의 기초영상 내에 포함된 복수의 프레임에 대해 각 프레임 내의 영역을 나누어서, 여러 영 상프레임에서 중복 저장되는 영역을 중복 저장하지 않도록 처리한다. 예를 들어, 검지손가락을 상이하게 움직이는 영상인 복수의 기초영상(예를 들어, 제1기초영상, 제2기초영상 및 제3기초영상)으로 다중 반응형 영상을 생성하는 경우, 컴퓨터는 대상체인 손가락을 제외한 배경영역을 추출한다. 배경영역은 검지손가락 움직임에 대한 복수의 영상에서 공통되는 부분이므로, 컴퓨터는 추출된 배경 영역을 공통영역으로 설정한다. 이 때, 컴퓨터는 복수의 기초영상에서 대상체인 손가락이 나타나지 않고 배경으 로 유지되는 영역만을 추출 및 수집하여 배경영역으로 추출할 수 있다. 또 다른 예로, 컴퓨터는 대상체의 움직 임 과정 중에 드러난 배경 정보 및 배경의 주변 영상을 기반으로 손가락이 배치된 부분까지 채운 배경이미지를 생성한다. 이를 통해, 컴퓨터는 모든 프레임에 배경으로 포함된 부분을 저장하기 위한 용량을 줄일 수 있다. 또한, 컴퓨터는 복수의 기초영상에서 대상체 영역(예를 들어, 사용자의 손)을 나누어서 저장함에 따라 데이터 용량을 줄인다. 예를 들어, 제1기초영상과 제2기초영상이 손가락만을 움직이고 손등 영역은 동일한 위치에 유지 되는 경우, 컴퓨터는 손등영역을 분리하여 제1기초영상과 제2기초영상의 특정한 하나 이상의 프레임을 위해 하 나만 저장하고, 움직임을 수행하는 손가락 부분만 각각 저장할 수 있다. 이후 다중 반응형 영상을 재생하는 경 우, 컴퓨터는 사용자의 입력조작에 의해 요청되는 특정한 기초영상을 재생하기 위해 필요한 복수의 영역(예를 들어, 배경영역, 손등영역과 각 프레임에 부합하는 복수의 손가락 영역)을 추출하여 영상을 출력할 수 있다. 컴퓨터가 압축영상에 대한 다중 반응형영상 생성조건을 수신한다(S600). 상기 다중 반응형영상 생성조건은 상기 압축영상에서 생성 가능한 반응에 대응하는 복수의 조작입력이다. 즉, 컴퓨터는 압축영상을 통해 구현할 수 있 는 여러가지 대상체의 움직임과 연결할 복수의 사용자조작을 각 영상구간 또는 프레임에 매칭하여 획득한다. 상기 다중 반응형영상 생성조건의 일실시예는, 기초영상이 사용자의 터치조작에 의해 반응(즉, 사용자의 터치조 작에 부합하는 영상프레임을 실시간 제공)하도록 하는 조건을 의미한다. 이를 통해, 사용자는 본인이 입력하는 조작에 따라 영상 내의 액션이 발생(예를 들어, 사용자의 터치조작에 부합하게 조작체 또는 대상체가 움직임 발 생)하는 것으로 시각적으로 인식할 수 있다. 또한, 컴퓨터는 다중 반응형영상을 생성하기 위한 복수의 기초영상을 획득하여 압축하는 과정을 수행한 후, 사 용자의 입력조작 유형을 다중 반응형 영상에 연결하는 과정을 수행한다. 예를 들어, 컴퓨터는 사용자의 각각의 입력조작과 압축영상 내의 특정 구간영상 또는 하나 이상의 영상프레임을 연결한다. 예를 들어, 컴퓨터는 다중 반응형 영상을 생성하는 과정에서 입력조작 제공 위치, 입력조작의 종류, 포스터치 형태이면 가해지는 세기, 누 르는 각도, 드래그 동작인 경우 이동방향 등에 부합하게 구간영상 또는 영상프레임을 연결한다. 예를 들어, 컴퓨터는 사용자에 의해 입력된 우측에서 좌측으로 화면을 스와이핑하는 조작과 대상체인 얼굴이 정 면을 향한 상태에서 좌측을 향하도록 변하는 구간영상을 매칭하고, 사용자 조작이 우측에서 좌측으로 이동함에 따라 대상체인 얼굴이 정면에서 좌측으로 회전하는 것으로 연결할 수 있다. 또한, 예를 들어, 제1기초영상은 다른 손가락을 접은 상태에서 검지손가락을 왼쪽으로 움직이는 영상이고, 제2 기초영상은 검지손가락을 오른쪽으로 움직이는 영상인 경우, 컴퓨터는 제작자 클라이언트에서 검지손가락 영역 에 터치하여 왼쪽으로 드래그하는 입력조작을 획득하여 제1구간영상과 매칭하고, 검지손가락 영역에 터치하여 오른쪽으로 드래그하는 입력조작을 획득하여 제2구간영상과 매칭한다. 컴퓨터는 기초영상의 형태에 따라 다양한 입력조작을 입력받은 후 매칭하여 저장한다. 또한, 일실시예로, 컴퓨터가 입력조작의 가압방식에 따라 깊이정보 변화에 의해 제공되는 영상프레임을 상이하 게 제공하도록 구현할 수 있다. 즉, 컴퓨터가 가압되는 각도에 의해 상이한 영상프레임이 제공되도록 구현되어, 사용자는 가압 각도가 실제로 반영된 반응을 확인할 수 있다. 또한, 다중 반응형영상 생성조건의 다른 일실시예는, 특정한 입력조작이 특정한 조건에 도달하면 기초영상에 포 함된 특정한 부분의 영상이 재생(즉, 액션이 발생)되는 조건을 의미한다. 또한, 다른 실시예로, 하나의 기초영 상을 통해 프레임 내의 복수의 영역이 개별적 또는 동시에 반응하도록 다중 반응형영상을 생성하는 조건을 의미 한다. 다중 반응형영상 생성조건이 기초영상을 사용자 조작에 따라 반응하는 다중 반응형영상으로 구현하기 위한 조건 인 경우, 기초영상의 유형에 따라 상이한 방식으로 다중 반응형영상 생성파일에 저장할 생성조건을 입력받을 수 있다.일실시예로, 기초영상이 일반적인 방식으로 촬영된 동영상(즉, 카메라를 통해 프레임이 시간순으로 획득되어 저 장된 일반동영상)인 경우, 컴퓨터는 다중 반응형영상으로 구현하기 위해 특정한 재생범위 및 프레임 내의 영역 을 설정하는 데이터를 수신한다. 이 때, 컴퓨터는 다중 반응형영상 생성파일 생성프로그램을 실행하여 사용자로 부터 조건데이터를 입력받을 수 있다. 구체적으로 살펴보면, 컴퓨터는 사용자로부터 특정한 재생범위를 지정하는 입력을 수신한다. 즉, 하나의 파일 내에 여러 세부영상이 저장되어 있어서 사용자의 조작에 따라 원하는 위치로 이동하는 다중 반응형 영상을 생성 하는 경우, 컴퓨터는 사용자로부터 기초영상의 특정한 시작프레임(즉, 다중 반응형영상으로 제작될 시간영역의 최초 프레임)부터 최종프레임(즉, 다중 반응형영상으로 제작될 시간영역의 마지막 프레임)까지 선택받고 이를 특정한 입력조작이 원하는 조건에 도달하면 재생되도록 할 수 있다. 그 후, 컴퓨터는 상기 재생범위 내 프레임의 전체영역 또는 특정한 영역에 연결할 특정한 입력조작을 사용자로 부터 수신하거나 영상 내에 조작체의 움직임을 분석하여, 조작체의 움직임에 부합하는 입력조작을 적용한다. 즉, 컴퓨터는 지정된 재생범위 내의 물체 움직임에 부합하는 입력조작을 수신 또는 지정할 수 있다. 또한, 기초영상 또는 압축영상의 재생범위(또는 구간영상)을 입력조작과 연결하는 방식으로는 다양한 방식이 적 용될 수 있다. 재생범위와 특정한 입력조작을 연결하는 방식의 일실시예로, 컴퓨터는 지정된 재생범위 내의 각각의 프레임 전 체영역 또는 특정영역에 가상레이어를 생성하는 방식을 적용할 수 있다. 가상레이어는 화면에 외관으로는 나타 나지 않으면서 사용자의 입력을 수신할 수 있는, 상기 프레임 위에 덮어지는 레이어를 의미할 수 있다. 즉, 컴 퓨터는 특정한 개수의 세부셀로 구성된 가상레이어를 프레임 상에 생성하기 위한 조건(즉, 가상레이어가 생성될 시간범위 또는 프레임 개수, 프레임 상의 범위 등)을 사용자로부터 획득한다. 컴퓨터는 다중 반응형영상 재생 시에 다중 반응형영상 생성파일 내에 포함된 가상레이어 생성조건을 기반으로 특정한 개수의 세부셀로 분할하여 생성된 가상레이어를 기초영상 상에 제공한다. 상기 가상레이어가 분할되는 세부셀의 개수는 가상레이어 생성조 건 내에 포함된 매칭될 영상프레임 수에 따라 결정될 수 있다. 예를 들어, 사용자로부터 다중 반응형영상 생성 조건(즉, 가상레이어 생성조건)에 따라 n개의 프레임이 변동적으로 재생(즉, 조작재생)되도록 다중 반응형영상 을 생성하고자 하는 경우, 컴퓨터는 특정영역을 n개의 세부셀로 분할할 수 있다. 또한, 다른 일실시예로, 기초영상이 대상체의 공간상 위치별로 영상프레임을 저장한 복수의 영상프레임 조합인 경우, 컴퓨터는 사용자로부터 특정한 프레임을 터치스크린 상의 각 지점에 매칭하기 위한 조건설정을 수신한다. 구체적으로 살펴보면, 컴퓨터는 기초영상 내의 복수의 영상프레임에서 반응형으로 생성될 영역을 설정하는 입력 을 사용자로부터 수신한다. 일실시예로, 컴퓨터는 사용자로부터 특정한 영상프레임에 반응형 영역을 설정하는 입력을 수신한다. 예를 들어, 컴퓨터는 화면 상에 기초영상 내의 특정한 영상프레임을 추출하여 제공하고, 사용 자로부터 대상체의 범위를 지정받을 수 있다. 기초영상에서 카메라 및 대상체의 위치는 고정되어 있으므로, 컴 퓨터는 임의의 영상프레임을 제공한 후 대상체의 영역을 터치조작을 통해 설정받을 수 있다. 또한, 다른 일실시 예는, 컴퓨터는 사용자로부터 기초영상 내 복수의 프레임에 동일하게 존재하는 대상체 이미지를 추출하여, 반응 형 생성영역으로 구현하는 명령을 수신하여 수행한다. 또한, 다른 일실시예는, 컴퓨터는 사용자로부터 조작체 (예를 들어, 손)의 움직임을 트래킹하여, 조작체(예를 들어, 손)의 이동경로를 포함하는 범위를 반응형 생성영 역으로 구현하는 명령을 수신한다. 그 후, 컴퓨터는 사용자로부터 터치조작이 입력될 밀도 설정을 수신한다. 즉, 컴퓨터는 반응형 영역에 매칭될 프레임 개수를 수신한다. 예를 들어, 기초영상이 L(시간 프레임 개수) X M(사건 프레임 개수) X N(깊이 프레임 개수)으로 구성되는 경우, 이보다 작거나 같은 프레임 밀도를 반응형 생성영역에 적용할 수 있다. 이에 따라, 다중 반응형영상 재생 시에, 컴퓨터는 상기 설정된 밀도를 기반으로 반응형 생성영역을 분할하고 반응형 생성영 역을 구성하는 복수의 세부셀에 대응되는 영상프레임을 각 세부셀에 매칭하여, 다중 반응형영상으로 구현한다. 또한, 다른 일실시예로, 사용자의 조작에 대응하는 프레임이 제공되도록 설정된 경우, 컴퓨터는 사용자로부터 특정한 재생조건을 입력받는다. 상기 재생조건은 조건 도달 시에 재생이 이어지거나 특정 시점으로 재생이 이동 하여 재생하도록 구현하는 것을 의미한다. 예를 들어, 컴퓨터는 특정한 입력조건을 선택받는다. 즉, 특정한 지점에 대한 푸쉬조작, 특정한 범위에 대한 드 래그 조작 또는 핀치조작을 입력받는다. 그 후, 컴퓨터는 해당 입력조건 도달 시에 발생할 재생조건을 입력받는 다. 컴퓨터는 특정한 재생범위를 재생(즉, 특정한 영상프레임으로 이동하여 재생, 특정한 제1영상프레임부터 제 2영상프레임까지의 구간을 재생)하도록 설정할 수 있고, 입력조건 도달 시 특정한 링크를 제공하도록 할 수 있다. 또한, 컴퓨터는 특정한 재생범위의 프레임 내의 전체영역 또는 일부영역을 다른 영상을 결합하거나 대체하 도록 설정할 수 있다. 또한, 다른 일실시예로, 컴퓨터는 복수의 다중 반응형영상을 하나의 화면에 제공하며, 다중 반응형영상 사이에 연결관계를 형성한다. 예를 들어, 2개의 다중 반응형영상 사이에 연결관계를 형성하는 경우, 컴퓨터는 제1다중 반응형영상과 제2다중 반응형영상이 결합된 최종다중 반응형영상을 형성하고, 특정한 다중 반응형영상에 대한 사용자조작 시에 해당 다중 반응형영상에 반응(즉, 액션)이 발생할 뿐만 아니라 다른 다중 반응형영상도 연결관 계에 따른 액션이 발생한다. 구체적으로, 제1다중 반응형영상이 사용자의 얼굴이미지에 대한 영상이고, 제2다중 반응형영상이 사용자의 얼굴에 포함된 일부 피부영역만을 표현한 영상인 경우, 컴퓨터가 사용자로부터 제2다중 반응형영상에 색조화장품을 바르는 것과 같은 드래그조작을 반복적으로 입력받으면, 컴퓨터는 제2다중 반응형영 상과 연결된 제1다중 반응형영상을 재생하여 피부 화장이 되는 액션을 구현(예를 들어, 색조화장을 하지 않은 얼굴이미지에서 색조화장을 한 얼굴이미지로 변하는 동영상을 순차적으로 재생)한다. 또한, 제2다중 반응형영상 에 입력되는 조작의 유형에 따라 제1다중 반응형영상 및 제2다중 반응형영상에 생성되는 액션의 종류가 달라질 수 있다. 다만, 연결관계를 형성할 수 있는 다중 반응형영상의 개수는 제한되지 않으며, 하나의 다중 반응형영상은 복수 의 다중 반응형영상과의 연결관계가 형성될 수 있다. 예를 들어, 컴퓨터는 하나의 화면 내에 16분할로 16개의 개별다중 반응형영상을 제공하고, 각 다중 반응형영상 간의 연결관계를 형성할 수 있다. 컴퓨터는 다양한 방식으로 다중 반응형영상 생성조건(예를 들어, 다중 반응형영상에 대한 입력조건과 재생조 건)을 설정한다. 일실시예로, 컴퓨터는 다중 반응형영상에 반응을 구현할 수 있는 조건함수를 직접 입력받는다. 즉, 컴퓨터는 사용자로부터 반응을 구현하는 함수 코드를 직접 입력받을 수 있다. 예를 들어, 복수의 영상을 포 함하는 프레임셋을 화면에 제공하는 경우(즉, 제1다중 반응형영상과 제2다중 반응형영상이 결합되는 경우), 컴 퓨터는 사용자로부터 2가지 다중 반응형영상 함수를 입력받는다. 또한, 다른 일실시예로, 컴퓨터는, 다중 반응형영상 생성파일 구현프로그램을 이용하여 사용자로부터 입력된 다 중 반응형영상 생성조건을 기초영상에 직접 입력함에 따라 다중 반응형영상으로 구현한다. 컴퓨터는 다중 반응 형영상 생성파일 구현프로그램을 구동하고 사용자의 조작에 의해 특정한 기초영상을 로드할 수 있다. 그 후, 컴 퓨터는 사용자로부터 다중 반응형영상으로 구현할 생성조건(즉, 입력조건, 재생조건 등)에 해당하는 조작을 수 신하고, 다중 반응형영상 생성프로그램 또는 생성어플리케이션이 해당 생성조건을 구현하는 함수로 생성한다. 후술하는 바와 같이, 하나 이상의 기초영상과 함께 재생되는 다중 반응형영상 생성파일이 별도로 존재하는 경우, 컴퓨터는 사용자로부터 입력된 생성조건을 생성파일 구현프로그램을 통해 다중 반응형영상 생성파일 내에 저장한다. 예를 들어, 컴퓨터는 생성조건에 상응하는 다중 반응형영상 구현함수 코드를 별도 파일로 저장한다. 컴퓨터는 기초영상에 조작(예를 들어, 터치조작, 마우스 조작 등)을 수신하고, 이에 대응하는 조건(예를 들어, 액션 유형, 액션이 입력될 재생범위, 조건 도달 시 실행되는 액션 등)을 다중 반응형영상 생성파일 상에 기록할 수 있다. 또한, 다른 일실시예로, 다중 반응형영상 생성조건이 특정한 입력조작이 특정한 조건에 도달하면 특정한 액션 (예를 들어, 기초영상에 포함된 특정한 부분의 영상)이 재생되는 조건인 경우, 컴퓨터는 사용자로부터 특정한 입력조작 유형, 조건도달 시 발생되는 액션 유형(예를 들어, 기초영상 내에서 이동될 재생시점), 도달되어야 하 는 조건값을 수신한다. 또한, 다른 실시예로, 다중 반응형영상 생성조건이 하나의 기초영상을 통해 프레임 내의 복수의 영역이 개별적 또는 동시에 반응하도록 다중 반응형영상을 생성하는 조건인 경우, 컴퓨터는 사용자로부터 분할 또는 크롭을 수 행할 재생범위를 설정받고, 해당 범위 내에 분할 또는 크롭을 수행할 영역을 설정받는다. 그 후, 컴퓨터는 사용 자로부터 분할 또는 크롭을 수행하는 영역에 개별적으로 재생할 영상정보를 입력받는다. 예를 들어, 기초영상이 좌우에 배치된 컵에 차례대로 물이 부어지는 영상인 경우, 두 컵이 나누어지는 분할선을 기준으로 프레임을 구 별하고, 양쪽이 독립적으로 반응형으로 구현되도록 할 수 있다. 이를 통해, 하나의 기초영상으로 다양한 다중 반응형영상을 구현할 수 있어서 다중 반응형영상의 용량을 절감할 수 있으며, 다중 반응형영상 구현을 위한 기 초영상 촬영도 간편해질 수 있다. 컴퓨터가 상기 생성조건을 상기 압축영상에 적용하여 다중 반응형영상을 생성한다(S800). 컴퓨터가 다중 반응형 영상 생성조건을 적용하여 다중 반응형영상 데이터로 저장한다. 일실시예로, 컴퓨터는 복수의 기초영상 압축과 각 기초영상에 대한 입력조작을 획득한 결과를 반영하여 최종 다 중 반응형 영상 파일을 생성한다. 즉, 컴퓨터는 사용자의 입력조작에 따라 압축된 복수의 영역을 병합하여 다중 반응형 영상에서 특정한 동작이 재생될 수 있는 형태로 파일을 구축한다. 또한, 다른 일실시예로, 사용자로부터 다중 반응형영상 생성조건을 함수 형태로 직접 입력받는 경우, 컴퓨터는 하나 이상의 기초영상과 함께 사용되는 다중 반응형영상 생성파일 내에 입력된 함수 형태를 그대로 저장한다. 다른 일실시예로, 다중 반응형영상 생성파일 제작프로그램(또는 생성프로그램)을 이용하여 사용자로부터 기초영 상에 특정한 입력조작을 직접 수신하는 경우, 컴퓨터는 해당 입력조작에 부합하는 함수를 생성하여 저장한다. 즉, 컴퓨터는 사용자에 의해 기초영상에 대해 입력된 다중 반응형영상 생성조건에서 프레임, 해당 프레임 내의 범위, 반응(즉, 액션) 유형 등의 데이터를 추출하여 함수 형태로 저장할 수 있다. 이를 통해, 사용자는 다중 반응형영상 생성조건이 저장된 다중 반응형영상 생성파일을 이용하여 특정한 영상을 간편하게 다중 반응형영상으로 구현할 수 있다. 즉, 사용자는 기초영상 자체를 재생하기를 원하는 경우에는 다 중 반응형영상 생성파일을 제외하고 재생을 수행하면 되고, 다중 반응형영상으로 구현하기를 원하는 경우에는 기초영상 파일과 다중 반응형영상 생성파일을 함께 재생함에 따라 다중 반응형영상으로 재생할 수 있다. 또한, 컴퓨터가 압축영상 내의 구간영상 간의 관계를 기반으로 스텍 구조의 저장형식을 생성하는 단계;를 더 포 함한다. 예를 들어, 컴퓨터는 압축과정에서 획득된 프레임 또는 복수의 영역을 스텍(Stack)구조로 구축할 수 있 다. 즉, 컴퓨터는 기초영상의 프레임 범위(즉, 2차원 범위) 내에서 영상 압축을 위해 생성된 복수의 영역을 하 나 이상의 스텍으로 쌓아서 다중 반응형 영상 파일을 생성한다. 구체적으로, 컴퓨터는 사용자로부터 입력조작이 가해질 때 특정한 추출영역이 제공되어야 하는 위치들의 집합을 해당 추출영역의 표시범위로 설정한다. 예를 들어, 배경영역은 입력조작이 제공되는 모든 위치에서 표시되어야 하므로, 컴퓨터는 프레임 전체를 배경영역의 표시범위로 설정한다. 그리고, 컴퓨터는 각 위치에서 포스터치 세 기 또는 시간에 따른 변화를 각각 스텍으로 쌓아서 저장할 수 있다. 또한, 하나의 다중 반응형 영상 내에서 상이한 위치에서 여러 동작을 구현하는 경우, 컴퓨터는 복수의 위치에서 구현된 각 동작에 대한 스텍을 형성한다. 이를 통해, 사용자가 다중 반응형 영상을 재생하면서 여러 동작을 구 현하기 위한 입력조작을 한번에 입력하는 경우, 컴퓨터는 각 입력조작이 가해진 스텍에서 추출영역을 추출하여 병합함에 따라 복수의 입력조작에 따른 움직임이 한번에 반영된 영상을 출력할 수 있다. 예를 들어, 입을 벌리는 제1조작과 음식을 입으로 이동시키는 제2조작이 함께 포함된 다중 반응형 영상의 경우, 사용자가 입을 벌리기 위한 제1입력조작(예를 들어, 상하 입술 위치를 두 손가락으로 터치한 후 벌리는 조작)과 음식을 터치하여 입 쪽으로 드래그하는 제2조작을 동시에 입력하면, 컴퓨터는 입을 벌리는 조작이 입력되는 위 치의 스텍에서 추출된 제1 추출영역을 병합하고 음식을 이동시키는 조작이 입력된 위치의 스텍에서 추출된 제2 추출영역을 병합하여 출력영상을 생성한다. 이를 통해, 컴퓨터는 제1입력조작과 제2조작의 입력정도에 따라 상이한 출력영상을 제공할 수 있다. 예를 들어, 컴퓨터는 제1입력조작만 입력되면 입을 벌리는 출력영상을 제공하고, 제2입력조작만 입력되면 음식을 입 쪽으로 이동시키는 출력영상을 제공하고, 제1입력조작과 제2입력조작을 동시에 입력하면 입을 벌리면서 입에 음식을 넣 는 출력영상을 제공한다. 또한, 컴퓨터는 제1입력조작과 제2입력조작이 가해지는 패턴에 따라 상이한 출력영상 을 제공할 수도 있다. 또한, 도 5에서와 같이, 각 추출영역(제1추출영역 및 제2추출영역)은 상이한 사건에 대한 복수의 스텍을 포함할 수 있다. 예를 들어, 실선으로 표현되는 제1 스텍과 점선으로 표현되는 제2 스텍을 각 추출영역에 포함할 수 있 다. 컴퓨터는 사용자로부터 각 추출영역에 최초 조작이 입력되는 위치를 기반으로 제1스텍과 제2스텍 중에서 실 행되는 스텍을 결정하는 것으로 구현될 수 있다. 또한, 도 5에서와 같이, 각 추출영역 내 제1 사건과 제2사건은 중첩되는 픽셀을 포함할 수 있고, 컴퓨터는 제1 사건에 대한 스텍과 제2사건에 대한 스텍 중에서 중첩되는 픽셀 중 하나만 남길 수 있다. 압축영상이 특정 추출 영역 내의 중첩 픽셀에 대한 데이터를 하나만 포함하더라도, 사용자의 다음 조작(예를 들어, 터치조작의 움직임 방향 또는 가해지는 압력세기의 변화)에 따라 제1사건과 제2사건 중 하나의 스텍이 결정될 수 있다. 이를 통해, 컴퓨터는 최소한의 데이터만으로 압축영상을 생성할 수 있다. 이하, 사용자가 다중 반응형 영상을 이용하는 방식에 대해 설명한다. 본 발명의 일실시예에 따른 다중 반응형 영상 재생 및 이용방법은, 클라이언트가 특정한 다중 반응형 영상을 로 드하는 단계; 상기 다중 반응형 영상에 대한 사용자 조작을 수신하는 단계; 상기 사용자조작에 따른 반응을 산출하여 출력하는 단계(반응출력단계);를 포함한다. 상기 반응출력단계에서, 컴퓨터(즉, 다중 반응형 영상을 재생하는 클라이언트 장치)가 디스플레이에 가해진 터 치조작의 이동방향, 속도, 화면에 대한 입력각도, 입력시간길이, 압력세기 등을 산출한다. 예를 들어, 다중 반응형 영상을 재생하는 사용자(이하, 제2사용자)가 다중 반응형 영상을 재생하는 클라이언트 (이하, 제2클라이언트)의 화면에 수직하게 압력을 가하는 경우와 비스듬하게 압력을 가하는 경우에 상이한 세부 셀을 선택하여 제공할 수 있다. 실제 대상체를 수직한 방향으로 누르면 수직방향으로 들어가고 비스듬한 방향으 로 누르면 대각선방향으로 움푹 들어가는 것과 같이, 반응형 영상에서도 제2사용자에게 현실감을 제공하기 위해 동일한 지점에 압력을 가하더라도 누르는 방식에 따라 상이한 영상프레임을 재생하여 대상체의 다른 움직임을 구현할 필요가 있다. 이를 위해, 제2클라이언트는 다양한 방식으로 가압방식을 구별할 수 있다. 예를 들어, 제2클라이언트는 손가락 이 화면상에 접촉되는 단면 형태(예를 들어, 손가락에 접촉되는 픽셀 개수와 픽셀분포)를 기반으로 가압방식을 판단할 수 있다. 또한, 예를 들어, 제2클라이언트는 화면상에 가해지는 압력분포를 기반으로 가압방식을 판단할 수 있다. 즉, 제 2클라이언트는 터치조작이 입력되는 범위에 전체적으로 가해지는 압력세기가 균일한지, 가해지는 압력세기가 부 분별로 상이한지에 따라 사용자에 의해 화면에 가해지고 있는 가압방식을 판단할 수 있다. 또한, 예를 들어, 제2클라이언트는 조작체(예를 들어, 손가락)로 화면을 가압 시에 화면 상에서의 손가락의 미 세한 움직임을 측정하여 가압방향을 결정할 수 있다. 제2클라이언트는 가압방식이 대상체를 비스듬히 누르는 것으로 판단되면, 깊이정보가 변경됨에 따라 압력이 가 해지는 방향으로 변경된 2차원공간 상의 위치의 프레임을 제공한다. 구체적으로, 비스듬한 방향으로 화면을 누 르는 경우, 제2클라이언트는 제2사용자의 손가락이 접촉된 지점의 영상프레임을 제공한 후 화면에 가해지는 압 력이 높아질수록 손가락이 기울어지는 방향의 연장선 방향에 대응하는 세부셀을 추출하여 제공한다. 또한, 본 발명의 다른 일실시예는, 기초영상에 대한 재생요청이 수신되면, 컴퓨터가 다중 반응형영상 생성파일 을 함께 로드하여 다중 반응형영상으로 구현하는 단계를 더 포함한다. 예를 들어, 컴퓨터는 기초영상이 저장된 폴더 내에 다중 반응형영상 생성파일이 함께 포함되어 있거나 데이터베이스 내에 해당하는 다중 반응형영상 생 성파일이 매칭되어 있으면, 기초영상 재생 시에 다중 반응형영상 생성파일을 함께 재생하여 다중 반응형영상으 로 구현할 수 있다. 또한, 본 발명의 다른 일실시예는, 컴퓨터가 사용자로부터 다중 반응형영상에 대해 입력되는 조작 횟수, 프레임 내 조작범위, 프레임 내에 가해진 압력세기 등의 데이터를 획득하는 단계;를 더 포함한다. 예를 들어, 컴퓨터가 다중 반응형영상 생성파일에 의해 다중 반응형영상에 입력되는 입력조작 내역을 기록한다. 이를 통해, 다중 반 응형영상을 마케팅용도로 활용하는 업체는 다중 반응형영상 내의 대상체에 대한 마케팅 효과를 확인할 수 있다. 또한, 다른 일실시예로, 사용자가 다중 반응형 영상을 사용하면서 입력조작을 입력하는 경우, 컴퓨터는 사용자 가 특정한 다중 반응형 영상에서 제공한 입력조작 패턴을 저장한다. 또한, 컴퓨터는 입력조작에 따른 출력영상 데이터와 입력조작 패턴을 함께 매칭하여 저장할 수 있다. 이를 통해, 컴퓨터는 딥러닝 학습에 각 사용자의 입 력조작과 출력영상데이터를 입력함에 따라 사용자의 성향을 파악할 수 있다. 예를 들어, 사용자가 다중 반응형 영상 내의 어떤 대상체에 대해 입력조작을 많이 입력하였는지, 입력조작을 어떠한 패턴으로 입력하였는지 등을 통해서, 특정한 대상체에 대한 관심도 등을 파악할 수 있다. 구체적으로, 다중 반응형 영상에 입력되는 사용자의 입력조작을 기반으로 사용자 행동을 이해하기 위한 상호작 용 데이터 분석 방법을 구체적인 예시로 설명하면 다음과 같다. 예를 들어, 컴퓨터는, 고양이에 관련된 컨텐츠 에서, '작용체를 이용하여 천천히 약한 힘을 가하면서 궤적을 그리는 것을 반복하는 것'과 '빠르게 강한 힘을 짧은 시간차를 두고 반복하는 것'을 구별하여, 사용자가 대상체에 대한 애정을 가지고 만지고 있는지, 또는 거 부감 또는 부정적인 심리를 가지고 만지고 있는지를 구분할 수 있다. 이를 통해, 사용자의 의도와 욕구를 파악 할 수 있다. 또한, 사용자에 따라 각자의 특성이 반영된 사용자 조작 패턴을 제공하여 초개인화될 수 있으므로, 컴퓨터는 사용자의 조작패턴(즉, 상호작용 데이터)를 사용자를 구별할 수 있는 식별데이터(예를 들어, 조작패턴 지문)으로 사용할 수 있다. 또한, 이는 사용자의 감정을 담은 제스쳐 방식의 액션 리플로 활용 가능하다. 또한, 다른 일실시예로, 컴퓨터가 사용자 요청에 따라 반응형 영상 컨텐츠를 제공하는 단계;를 더 포함할 수 있 다. 컴퓨터는 영상데이터 내에서 상호작용 가능한 구간에 대한 정보들을 메타 데이터로부터 받아와 다중 반응형영상으로 전환한다. 컴퓨터는 다중 반응형 영상데이터에 입력되는 사용자조작의 형태(예를 들어, 사용자조작이 가해지는 각도의 차이 등)에 따라 상이한 반응을 출력할 수 있다. 또한, 컴퓨터는 컨텐츠와 상호작용하는 작용 체들의 다중 궤적들(예를 들어, 사용자의 조작 형태, 유형 등)을 실시간으로 분석 및 예측하여 행위의 의미를 파악하고, 이에 상응하는 반응형태에 해당 이벤트를 매칭하여 출력할 수 있다. 또한, 컴퓨터는 반응형태에 따른 이벤트에 따라 맵핑 데이터는 실시간으로 재배치할 수 있다. 이하, 본 발명의 일실시예에 따른 반응형 영상 기반의 서비스 제공방법에 대한 상세한 설명을 기재한다. 도 6은 본 발명의 일 실시예에 따른 다중반응형 영상 기반의 서비스 제공 시스템에 대한 네트워크 구조를 나타 내는 도면이다. 이하에서는, 도 6을 설명하면서 도 7a 내지 도 7d을 참조하여 설명하도록 한다. 도 6을 참조하면, 본 발명의 일 실시예에 따른 반응형 영상 기반의 서비스 제공 시스템은 서비스 서버 , 제1 사용자 단말 및 제2 사용자 단말을 포함하여 구성될 수 있다. 다만, 설명의 편의를 위하 여 제1 사용자 단말 및 제2 사용자 단말을 하나씩 도시하였으나, 각각 복수개로 구성될 수 있으며, 이를 한정하지 않는다. 제1 사용자 단말은 다중 반응형영상을 제2 사용자 단말로 제공하고자 하는 사용자의 단말로서, 다중 반응형영상 기반의 서비스를 이용하기 위해 특정 대상체를 포함하는 적어도 하나의 기초영상을 촬영하여 서비스 서버로 송신한다. 이때, 제1 사용자 단말은 적어도 하나의 기초영상을 송신할 시, 각 기초영상 내의 복수의 영상프레임에서 반응형으로 생성될 영역(대상체의 영역)을 설정하여 송신함으로써 해당 영역을 기반으로 하는 다중 반응형영상의 생성을 요청할수 있다. 서비스 서버는 제1 사용자 단말로부터 적어도 하나의 기초영상을 수신하면, 이 적어도 하나의 기초영 상을 기반으로 제1 사용자 단말의 요청에 따라 다중 반응형영상을 생성 및 업로드하고, 제2 사용자 단말 로부터 그 다중 반응형영상을 기반으로 하는 조작입력정보가 수신되면, 그 조작입력정보를 기반으로 반응 맵 데이터를 매칭되는 반응형영상을 재생하여 제2 사용자 단말에게 제공한다. 이를 위해, 다중 반응형영상은 보정영상데이터, 반응 맵(Map) 데이터 및 반응생성데이터를 중 적어도 하나를 포 함할 수 있다. 구체적으로, 보정영상데이터는 반응형 영상으로 구현하기 위해 분할 또는 보정을 통해 생성된 이미지의 조합에 대한 정보를 포함하는 데이터로서, 압축 데이터 즉, 앞서 설명한 압축영상에 해당한다고 할 수 있다. 예를 들어, 보정영상데이터는 상술된 스텍구조의 데이터 등이 해당될 수 있으며, 인공지능을 기반으로 자동으로 생성 될 수도 있다. 또한, 반응 맵 데이터(Response Map Data)는 보정영상데이터의 특정한 영역에 결합되어, 다중 반응형영상으로 구현하기 위한 정보를 포함하는 데이터로서, 앞서 설명한 다중 반응형영상 생성조건을 포함할 수 있다. 이 반응 맵 데이터는 보정영상데이터를 구성하는 영상프레임과 디스플레이 상의 조작위치를 연결하는 역할을 수행하며, 특정한 조작 위치 또는 범위와 영상프레임(또는 이미지정보)를 매핑하기 위한 데이터를 포함할 수 있다. 예를 들어, 반응 맵 데이터는 화면 상의 범위 또는 위치와 특정 영상프레임의 식별값(예를 들어, 주소 또는 어드레스)를 연결한다. 또한, 반응영상데이터는 다중 반응형영상에 입력되는 사용자 조작에 대한 정보를 포함하는 데이터로서, 앞서 설 명한 조작입력정보에 해당하는 것일 수 있다. 이 보정영상데이터와 반응 맵 데이터가 결합되면 사용자 조작에 따라 반응 출력이 가능한 다중반응형 영상으로 생성되고, 반응생성데이터가 결합되면 특정한 반응이 출력되는 영상이 된다. 또한, 다중반응형 영상은 반응 스크립트(Response Script) 데이터를 더 포함할 수 있다. 이 반응 스크립트 데이 터는 제2 사용자의 조작에 따라 제공되는 이미지 정보의 조건에 대한 것이다. 즉, 반응 스크립트 데이터는 다중 반응형 영상 제작자에 의해 설정되는 반응 조건이 해당될 수 있다. 다중 반응형영상이 보정영상데이터, 반응 맵 데이터 및 반응 스크립트 데이터가 결합되는 경우, 반응형 영상은 사용자가 조작을 입력함에 따라 달성되는 조 건에 따라 상이한 반응이 구현되도록 구현될 수 있다. 구체적으로, 서비스 서버는 제1 사용자 단말로부터 수신된 적어도 하나의 기초영상을 기반으로 다중 반응형영상을 생성할 시, 적어도 하나의 기초영상을 기반으로 대상체의 움직임만을 포함하는 보정영상데이터(압 축영상)을 생성한다. 예를 들어, 동일한 대상체를 포함하는 제1 기초영상 및 제2 기초영상이 수신된 경우라 가 정하였을 때, 두 영상에 포함된 대상체가 동일한 경로에 대한 움직임을 포함하고 있다면, 제1 기초영상 및 제2기초영상에서 동일한 경로의 움직임이 포함된 구간영상을 추출하고, 그 추출된 구간영상을 중복 구간영상으로 결정하고, 제1 기초영상 및 제2 기초영상 중에서 하나에 포함된 중복 구간영상만을 남겨두도록 한다. 이후, 서비스 서버는 각 기초영상에서 대상체의 움직임을 확인하고, 제2 사용자에 의한 특정한 조작 위치 또는 범위와 영상프레임을 매핑한 반응 맵 데이터(다중 반응형영상 생성조건)를 생성 및 저장한다. 이때, 서비 스 서버는 두 기초영상에서 상호 상반되는 움직임에 대해서는 별도로 데이터를 생성하지 않고 재생 또는 역재생을 통해 구현하도록 한다. 이로써, 압축영상에 반응 맵 데이터를 결합하여 다중 반응형영상이 생성된다. 그 다음으로, 서비스 서버 제2 사용자 단말로부터 그 다중 반응형영상을 기반으로 하는 조작입력정보 (반응생성데이터)가 수신되면, 그 조작입력정보를 기반으로 반응 맵 데이터를 매칭되는 반응형영상을 재생하여 제2 사용자 단말에게 제공한다. 또한, 다중 반응형 영상은 멀티 터치(multi touch), 멀티액션(multi actions), 멀티 오브젝트(multi objects), 멀티 씬(multi scenes), 멀티 아웃컴(multi outcomes) 및 멀티 리액션(multi reactions) 중 적어도 하나의 형 태로 구성될 수 있다. 구체적으로, 멀티 터치는 복수의 접촉에 반응하도록 구성된 반응형 영상으로서, 사용자가 자신의 단말 상에 디 스플레이 된 다중 반응형영상을 기반으로 복수의 접촉을 포함하는 사용자 조작을 입력하면, 그 조작에 대응하는 반응형 영상이 구현될 수 있다. 예를 들어, 도 7a와 같이 사용자가 이등분된 햄버거의 각 부분에 손가락을 각각 접촉하여 서로 반대 방향을 향하여 벌리는 듯한 사용자 조작을 입력하면, 이등분된 햄버거가 벌어지는 반응형 영상이 재생된다. 또한, 멀티 액션은 복수의 사용자 조작에 반응하도록 구성된 반응형 영상으로서, 복수의 사용자 조작 각각에 대 응하는 액션을 제공한다. 예를 들어, 도 7b와 같이 자신의 단말 상에 디스플레이 된 다중 반응형영상을 기반으 로 사용자가 지퍼 부분을 터치한 상태에서 밑으로 내리는 사용자 조작을 입력하면, 기초영상 내의 대상체가 지 퍼를 내리는 반응형 영상이 재생되고, 사용자가 기초영상 내의 대상체의 손 부분을 터치한 상태에서 위로 들어 올리는 사용자 조작을 입력하면, 그 대상체가 손을 들어보이는 반응형 영상이 재생된다. 또한, 멀티 오브젝트(multi objects)는 도 7c와 같이 다중 반응형영상 내에 포함된 복수의 대상체 각각에 대하 여 개별적으로 반응하도록 구성된 반응형 영상이다. 또한, 멀티 씬(multi scenes)은 사용자 조작에 대해 복수의 씬이 포함되어 제공되는 반응형 영상이다. 예를 들 어, 도 7d와 같이 사용자가 기초영상을 기반으로 병의 앞부분에 터치한 상태로 밑으로 내리는 사용자 조작을 입 력하면, 병이 기울어지면 음료가 쏟아지는 영상과 잔에 음료가 채워지는 영상을 포함하는 반응형 영상이 재생된 다. 또한, 멀티 아웃컴(multi outcomes)은 사용자 조작에 따라 미리 설정된 조건에 대응하여 서로 다른 결과가 선택 적으로 제공되는 반응형 영상이다. 예를 들어, 도 3에서와 같이 사용자가 기초영상을 기반으로 풍선을 터치한 상태로 위로 들어올리는 사용자 조작을 입력하면, 풍선이 최대치로 들어올려진 후 또는 터치가 해제된 후에 풍 선이 떨어지되, 사용자가 풍선을 들어올리는 사용자 조작을 입력할 시의 속도에 따라 풍선이 터지는 반응형 영 상 또는 풍선이 터지지 않고 바닥에 부딪혀 튕기는 반응형 영상이 재생된다. 또한, 멀티 리액션(multi reactions)은 사용자 조작에 따라 미리 설정된 조건에 대응하여 그 기초영상 내의 대 상체로부터 서로 다른 리액션이 제공되는 반응형 영상이다. 이는 도 2와 같이 제공될 수 있다. 즉, 사용자가 기 초영상 내의 대상체를 대상으로 어떠한 사용자 조작이 이뤄지느냐에 따라 사용자가 고개를 상하좌우 중 어느 하 나의 방향으로 돌리는 리액션을 취하는 동시에, 그 사용자 조작의 속도에 따라 대상체의 표정 또한 상이하도록 반응형 영상이 재생된다. 즉, 다중 반응형영상은 사용자 조작에 대응하여 매칭되는 반응형영상이 제공되는데, 서비스 서버는 사용자 조작에 대한 정보로서 조작횟수, 조작세기, 이동길이, 조작속도, 조작시간길이, 조작방향 및 조작위치 중 적어 도 하나를 포함하는 조작입력정보가 제2 사용자 단말로부터 수신되면, 이를 기반으로 기준값들을 고려하여 사용자 조작을 확인하고, 그 사용자 조작에 매칭되는 반응형영상에 대한 재생정보를 제2 사용자 단말로 송 신한다. 이로써, 제2 사용자 단말은 재생정보에 따라 반응형영상을 구현할 수 있다. 서비스 서버는 다중 반응형 영상을 제공할 시, 사용자 조작을 유도하도록 하는 가이드 포인트를 더 포함하 도록 할 수 있다. 이로써, 사용자는 다중 반응형영상을 기반으로 자신이 어떠한 조작을 수행할 수 있는지를 확 인할 수 있다.한편, 서비스 서버는 제2 사용자 단말로부터 수신되는 조작입력정보를 누적하여 저장하고, 그 누적된 조작입력정보를 분석하여 적어도 하나의 사용자들의 관심이 반영된 분석 결과를 상품 또는 서비스에 대한 광고 주 클라이언트(서비스를 이용하고 있는 제1 사용자, 서비스를 이용하고자 하는 사용자 등일 수 있음)에게 제공 할 수 있다. 이때, 분석 결과는 조작 통계는 물론, 사용자들이 선호하는 조작 패턴 등에 대한 정보를 포함할 수 있다. 이를 통해, 이 다중 반응형영상 기반의 서비스를 이용하는 기업 또는 개인이 그 분석 결과를 고려하여 자신이 판매하 는 물건 또는 서비스에 대한 광고(홍보) 컨텐츠를 제작할 수 있도록 함으로써, 그 광고 효과를 향상시킬 수 있 도록 한다. 구체적으로, 서비스 서버는 각 반응형 영상에 대한 히트맵 데이터를 분석 결과 데이터로서 광고주 클라이 언트에게 제공할 수 있다. 예를 들어, 하나의 반응형 영상 내에 여러 조작이 포함되어 있는 경우, 광고주 클라 이언트는 히트맵을 통해 사용자들이 상품 또는 서비스에 대한 어떤 조작에 관심이 많은지, 사용자들이 관심이 높은 조작 패턴 등을 파악할 수 있다. 한편, 서비스 서버는 특정한 광고용 반응형 영상에 대한 클립 저장 요청을 수신하면, 그 광고용 반응형 영 상을 사용자의 어플리케이션에서 확인 가능하도록 연결하도록 할 수 있다. 제2 사용자 단말은 다중 반응형영상을 구현하여 제공받는 제2 사용자의 단말로서, 자신의 단말을 통해 별 도의 어플리케이션을 실행하거나 웹 사이트에 접속함으로써 다중 반응형영상을 제공받을 수 있다. 즉, 제2 사용 자가 제2 사용자 단말 상에 디스플레이 된 다중 반응형영상을 기반으로 사용자 조작을 실행하면, 제2 사용 자 단말이 그 입력된 사용자 조작을 기반으로 조작입력정보를 생성하여 서비스 서버로 송신한다. 도 8은 본 발명의 일 실시예에 따른 다중반응형 영상 기반의 서비스 제공을 위한 서비스 서버에 대한 구성을 나 타내는 도면이다. 도 8을 참조하면, 다중 반응형영상 기반의 서비스 제공을 위한 서비스 서버는 통신모듈, 저장모듈 및 제어모듈을 포함하여 구성될 수 있다. 통신모듈은 제1 사용자 단말 및 제2 사용자 단말과 적어도 하나의 정보 또는 데이터를 송수신한 다. 또한, 이 통신모듈은 그 외 다른 장치들과의 통신을 수행할 수도 있는 것으로, 무선 인터넷 기술들에 따른 통신망에서 무선 신호를 송수신하도록 한다. 무선 인터넷 기술로는, 예를 들어 WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등이 있으며, 서비스 서버는 앞에서 나열되지 않은 인터넷 기술까지 포함한 범위에서 적어도 하나의 무선 인터넷 기술에 따라 데이터를 송수 신하게 된다. 근거리 통신(Short range communication)을 위한 것으로서, 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless-Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 근거리 통신을 지원할 수 있다. 이러한, 근거리 무선 통신망(Wireless Area Networks)을 서비스 서버 및 제1 사용자 단말 간, 서비스 서버 및 제2 사용자 단말 간 무선 통신을 지원할 수 있다. 이때, 근거리 무선 통신망은 근거리 무선 개인 통신망(Wireless Personal Area Networks)일 수 있다. 저장모듈은 다중 반응형영상 기반의 서비스를 제공하기 위해 필요한 적어도 하나의 프로세스를 저장한다. 뿐만 아니라, 저장모듈은 그 외 다른 동작을 수행하기 위한 프로세스들을 더 저장할 수 있으며, 이를 한정 하지 않는다. 저장모듈은 서비스 서버의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 저장모듈은 서비 스 서버에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application), 서비 스 서버의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 서비스 서버의 기본적인 기능을 위하여 존재할 수 있다. 한편, 응용 프로그램은, 저장모듈에 저장되 고, 서비스 서버 상에 설치되어, 제어모듈에 의하여 서비스 서버의 동작(또는 기능)을 수행하도록 구동될 수 있다. 특히, 저장모듈은 제1 사용자 단말로부터 수신된 적어도 하나의기초영상 및 이를 기반으로 생성된 다 중 반응형영상이 저장된다. 이때, 기초영상이 저장된 폴더 내에 다중 반응형영상 생성파일이 함께 포함되어 있 거나 데이터베이스 내에 해당하는 다중 반응형영상 생성파일이 매칭될 수 있다. 이로써, 기초영상 재생 시에 다 중 반응형영상 생성파일을 함께 재생하여 다중 반응형영상으로 구현 가능하도록 한다. 제어모듈은 응용 프로그램과 관련된 동작 외에도, 통상적으로 서비스 서버의 전반적인 동작을 제어할 수 있다. 제어모듈은 앞서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하 거나 저장모듈에 저장된 응용 프로그램을 구동함으로써, 사용자들에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 제어모듈은 제1 사용자 단말로부터 적어도 하나의 기초영상이 수신되면, 그 수신된 적어도 하나의 기 초영상을 기반으로 압축영상을 생성하고, 각각의 기초영상에서 대상체의 움직임을 확인하여 특정한 조작 위치 또는 범위와 영상프레임을 매핑한 다중 반응형 생성조건을 생성하여 다중 반응형영상을 생성한다. 이후, 제어모듈은 그 다중 반응형영상을 업로드하여 제2 사용자 단말을 통해 확인 가능하도록 하고, 제2 사용자 단말로부터 그 업로드된 다중 반응형영상을 기반으로 하는 조작입력정보를 수신되면, 그 조작 입력정보를 다중 반응형영상에 적용하여 영상을 재생한다. 한편, 제어모듈은 제2 사용자 단말, 즉, 적어도 하나의 제2 사용자로부터 수신된 조작입력정보들을 저장모듈에 누적하여 저장한다. 그 저장된 조작입력정보들을 미리 설정된 주기 또는 요청에 따라 분석하고, 그 분석 결과를 제1 사용자 단말, 즉, 적어도 하나의 제1 사용자에게 제공한다. 한편, 업로드된 다중 반응형영상에 대해 제2 사용자에 의해 다중 반응형 생성조건이 추가 설정될 수 있는데, 제 어모듈은 제2 사용자 단말로부터 요청 정보가 입력 또는 수신되면, 그 요청 정보를 기반으로 요소 영 상을 획득하고, 인공지능을 기반으로 획득된 요소 영상을 변형한 복수의 반응영상을 생성한다. 이때, 대상체(예 를 들어, 특정한 등장인물)의 모든 반응(예를 들어, 표정이나 동작)을 획득할 수 없으므로, 획득 가능한 일부 반응을 포함하는 요소 영상을 기반으로 변형하여 더 많은 반응을 구현한다. 여기서, 요청 정보는 제2 사용자가 다중 반응형영상을 기반으로 재생하고자 하는 영상 형태에 대한 요청을 포함하는 정보로서, SNS 등에 댓글 형태 로 저장될 수 있다. 예를 들어, 연예인이 팬과 소통을 할 수 있는 SNS 서비스를 제공하는 경우, 연예인이나 소속사에서 SNS 서비스 에 연예인에 대한 반응형 영상을 생성하여 업로드하고, 팬에 해당하는 제2사용자는 사용자 클라이언트를 통해 제공되는 반응형 영상에 본인이 원하는 조작을 입력한다. 제어모듈은 제2 사용자 단말로부터 사용자조작 자체 또는 영상생성데이터를 수신하여 SNS 상의 댓글과 같이 저장한다. 다른 SNS 유저 또는 연예인이 제2 사용 자의 영상생성데이터에 해당하는 탭을 선택하면 SNS 상의 반응형 영상에 영상생성데이터를 적용한 영상이 제공 될 수 있다. 이로써, 적어도 하나의 제2 사용자 별로 커스터마이징 된 다중 반응형영상이 생성될 수 있다. 도 9는 본 발명의 일 실시예에 따른 다중반응형 영상 기반의 서비스 제공 방법에 대한 순서도이다. 먼저, 제1 사용자 단말로부터 적어도 하나의 기초영상이 수신되면(S210), 그 수신된 적어도 하나의 기초영 상을 기반으로 압축영상을 생성한다(S220). 이후, 각각의 기초영상에서 대상체의 움직임을 확인하여 특정한 조작 위치 또는 범위와 영상프레임을 매핑한 다 중 반응형 생성조건을 생성하고(S230), S220 단계에서 생성된 압축영상에 S230 단계에서 생성된 다중 반응형 생 성조건을 적용하여 다중 반응형영상을 생성한 후, 업로드 한다(S240). 이때, 다중 반응형영상은 특정 플랫폼, SNS, 어플리케이션 등이 될 수 있다. 그 다음으로, 제2 사용자 단말로부터 다중 반응형영상을 기반으로 하는 조작입력정보가 수신되면(S250), 그 조작입력정보를 다중 반응형영상에 적용하여 영상을 재생한다(S260).본 발명의 일실시예에 따른 반응형 영상 기반 서비스 제공방법은, 제1사용자의 요청에 따라 제1반응형 영상을 업로드하는 단계; 제1반응형 영상에 대한 제2사용자의 조작을 수신하는 단계; 상기 제2사용자의 조작을 제1반응형 영상에 적용하기 위한 반응생성데이터 를 생성하는 단계; 및 제2사용자 조작에 따른 반응생성데이터를 적용한 반응 구현이 요청되면, 상기 반응생성데 이터를 상기 제1반응형 영상에 적용하여 재생하는 단계;를 포함한다.컴퓨터(예를 들어, 서비스서버)는 제1사용자의 요청에 따라 제1반응형 영상을 업로드한다. 상기 제1반응형 영상 은 제1사용자가 특정한 대상체 조작이 가능한 것으로 구현한 영상일 수 있다. 예를 들어, 연예인의 얼굴을 만지 는 등의 조작을 입력하여 반응을 구현할 수 있는 영상일 수 있다. 컴퓨터는 제1반응형 영상에 대한 제2사용자의 조작을 수신한다. 컴퓨터는 각 사용자로부터 각자가 의도하는 조 작을 제1반응형 영상에 입력할 수 있다. 예를 들어, 제2사용자가 제1반응형 영상에 대한 조작을 입력하기를 원 하는 경우, 서비스서버는 제2사용자의 클라이언트 장치에 제1 반응형 영상데이터를 제공한다. 사용자 클라이언 트에서 제1 반응형 영상을 처리하는 프로세스에 대한 설명을 상세히 후술한다. 제2사용자의 조작을 수신하는 방 식의 일 예로, 제1반응형 영상이 연예인의 얼굴을 조작할 수 있는 영상인 경우, 제2사용자 조작은 연예인을 팬 으로서 얼굴을 만지는 조작일 수 있다. 컴퓨터가 상기 제2사용자의 조작을 제1반응형 영상에 적용하기 위한 반응생성데이터를 생성 또는 수신한다. 상 기 반응생성데이터는 반응형 영상에 대한 사용자 조작이 저장된 것으로서, 반응형 영상과 함께 재생됨에 따라 반응형 영상을 저장된 조작에 따라 재생하는 것이다. 예를 들어, 서비스서버는, 제2사용자가 사용자 클라이언트 에 제공된 제1반응형 영상에 조작을 입력하면, 제2사용자의 조작을 수신하여 반응생성데이터로 생성하거나, 상 기 사용자 클라이언트에서 생성된 반응생성데이터를 수신한다. 제2사용자 조작에 따른 반응생성데이터를 적용한 반응 구현이 요청되면, 컴퓨터가 상기 반응생성데이터를 상기 제1반응형 영상에 적용하여 재생한다. 예를 들어, 특정한 유저로부터 제2사용자에 의해 생성된 반응생성데이터 를 제1반응형 영상에 적용 요청을 받으면, 서비스서버는 제1반응형 영상에 제2영상생성데이터를 적용하여 재생 성되는 영상을 전송할 수 있다. 구체적으로, 연예인이 팬과 소통을 할 수 있는 SNS 서비스를 제공하는 경우, 연예인이나 소속사에서 SNS 서비스 에 연예인에 대한 반응형 영상을 생성하여 업로드하고, 팬에 해당하는 제2사용자는 사용자 클라이언트를 통해 제공되는 반응형 영상에 본인이 원하는 조작을 입력한다. 서비스서버는 제2사용자의 사용자 클라이언트로부터 사용자조작 자체 또는 영상생성데이터를 수신하여 SNS 상의 댓글과 같이 저장한다. 다른 SNS 유저 또는 연예인 이 제2사용자의 영상생성데이터에 해당하는 탭을 선택하면 SNS 상의 반응형 영상에 영상생성데이터를 적용한 영 상이 제공될 수 있다. 본 발명의 또 다른 일실시예에 따른 반응형 영상 기반 서비스 제공방법은, 서비스서버가 복수의 사용자로부터 특정한 반응형 영상에 대한 사용자 조작을 수신하는 단계; 및 상기 반응형 영상에 대한 조작 통계 분석결과를 제공하는 단계;를 포함한다. 반응형 영상은 사용자의 조작 입력에 따른 반응을 출력함에 따라 사용자 경험을 통해 광고 효과를 제공하므로, 반응형 영상은 상품 또는 서비스에 대한 광고용 컨텐츠로 제작될 수 있다. 이 때, 서비스서버는 상품 또는 서비 스에 대한 광고주에게 유저들의 관심에 대한 분석데이터를 제공할 필요가 있다. 서비스서버는 각 반응형 영상에 대한 히트맵 데이터를 분석결과 데이터로 광고주 클라이언트에 제공할 수 있다. 예를 들어, 하나의 반응형 영상 내에 여러 조작이 포함되어 있는 경우, 광고주는 히트맵을 통해 유저들이 상품 또는 서비스에 대한 어떤 조작에 관심이 많은 지 파악할 수 있다. 또한, 예를 들어, 광고주는 유저들이 관심이 높은 조작 패턴을 파악할 수 있다. 또한, 서비스서버는 광고주에게 유저들의 관심도를 높일 수 있는 반응형 영상 제작 방향을 제안할 수 있다. 또한, 본 발명의 또 다른 일실시예에 따른 반응형 영상 기반 서비스 제공방법은, 서비스서버가 특정한 광고용 반응형 영상에 대한 클립 저장요청을 수신하는 단계; 및 서비스서버가 광고용 반응형 영상을 유저의 어플리케이 션에서 확인 가능하도록 연결하는 단계;를 포함한다. 또한, 본 발명의 또 다른 실시예에 따른 반응형 영상 기반 서비스 제공방법은, 서비스서버가 특정한 반응형 영 상에 접근한 유저정보를 획득하는 단계; 상기 유저정보 기반의 인터렉션 데이터를 추출하는 단계; 및 상기 인터 렉션 데이터에 따른 반응생성데이터를 선택하여 반응형 영상에 적용하는 단계;를 포함한다. 사용자에 따라 자동으로 상이한 반응을 출력하기 위해, 서비스서버가 특정한 반응형 영상에 접근한 유저정보를 획득한다. 유저정보는 유저의 사용자 계정이 해당될 수 있다. 그 후, 서비스서버가 상기 유저정보 기반의 인터렉션 데이터를 추출한다. 상기 인터렉션 데이터는 반응형 영상 에 포함된 대상체와 유저의 상호작용 수준을 나타내는 데이터이다. 예를 들어, 반응형 영상 내의 대상체가 사람 인 경우, 상기 인터렉션 데이터는 유저와 반응형 영상 내의 등장인물과의 관계, 상호 간의 온라인/오프라인 상호작용 빈도 등을 포함할 수 있다. 서비스서버는 상기 인터렉션 데이터에 따른 반응생성데이터를 선택하여 반응형 영상에 적용한다. 반응형 영상 내의 대상체와 유저 간의 인터렉션에 대응하는 반응을 구현하기 위한 반응생성데이터를 추출하여 적용한다. 예 를 들어, 상기 반응형 영상이 할머니의 표정과 움직임을 구현하는 것이고 유저가 손자인 경우, 손자와 할머니의 호감도 높은 인터렉션 데이터를 기반으로 웃는 표정 등의 긍정적인 리액션을 구현하는 반응생성데이터를 추출하 여 적용할 수 있다. 또한, 다른 일실시예로, 서비스서버가 특정한 대상체에 대한 반응형 영상 구현을 위한 요소 영상을 획득하는 단 계; 및 서비스서버가 인공지능을 기반으로 요소 영상을 변형한 복수의 반응영상을 생성하는 단계;를 더 포함한 다. 서비스서버는 대상체(예를 들어, 특정한 등장인물)의 모든 반응(예를 들어, 표정이나 동작)을 획득할 수 없 으므로, 획득 가능한 일부 반응을 포함하는 요소 영상을 기반으로 변형하여 더 많은 반응을 구현한다. 이하, 본 발명의 일실시예에 따른 반응형 영상의 구조에 대한 설명을 기재한다. 본 발명의 일실시예에 따른 반응형 영상은, 보정영상데이터; 반응 맵(Map) 데이터; 및 반응생성데이터;를 포함 한다. 상기 보정영상데이터는 반응형 영상으로 구현하기 위해 분할 또는 보정을 통해 생성된 이미지의 조합에 해당한 다. 예를 들어, 보정영상데이터는 상술된 스텍구조의 데이터 등이 해당될 수 있다. 상기 반응 맵 데이터(Response Map Data)는 보정영상데이터의 특정한 영역에 결합되어, 반응형으로 구현하는 데 이터이다. 상기 반응 맵 데이터는 상기 보정영상데이터를 구성하는 영상프레임과 디스플레이 상의 조작위치를 연결하는 역할을 수행한다. 구체적으로, 반응 맵(Map) 데이터는 특정한 조작 위치 또는 범위와 영상프레임(또는 이미지정보)를 매핑한다. 예를 들어, 반응 맵 데이터는 화면 상의 범위 또는 위치와 특정 영상프레임의 식별값(예를 들어, 주소 또는 어 드레스)를 연결한다. 상기 반응생성데이터(Response Trigger Data)는 반응형 영상에 입력되는 사용자 조작에 대한 데이터이다. 보정영상데이터와 반응 맵 데이터가 결합되면 사용자 조작에 따라 반응 출력이 가능한 반응형 영상으로 생성되 고, 반응생성데이터가 결합되면 특정한 반응이 출력되는 영상이 된다. 또한, 반응형 영상은 반응 스크립트(Response Script) 데이터를 더 포함할 수 있다. 상기 반응 스크립트 데이터 는 사용자의 조작에 따라 제공되는 이미지 정보의 조건에 대한 것이다. 즉, 반응 스크립트 데이터는 반응형 영 상 제작자에 의해 설정되는 반응 조건이 해당될 수 있다. 상기 반응형 영상이 보정영상데이터, 반응 맵 데이터 및 반응 스크립트 데이터가 결합되는 경우, 반응형 영상은 사용자가 조작을 입력함에 따라 달성되는 조건에 따 라 상이한 반응이 구현되도록 구현될 수 있다. 이하, 본 발명의 일실시예에 따른 반응형 영상 재생방법을 설명한다. 본 발명의 일실시예에 따른 반응형 영상 재생방법은, 서비스서버가 사용자 클라이언트로부터 반응형 영상의 조 작 위치를 획득하는 단계; 서비스서버가 조작 위치에 대한 어드레스를 사용자 클라이언트로 전송하되, 상기 어 드레스는 클라이언트에서 출력해야하는 프레임 정보인, 어드레스 전송단계; 및 사용자 클라이언트가 상기 어드 레스에 대응되는 이미지 처리를 통해 실시간 출력하는 단계;를 포함한다. 사용자 클라이언트가 반응형 영상 자체를 그대로 저장하고 있으면, 반응형 영상 자체가 유출될 우려가 존재하므 로 보안성을 높이기 위한 방안이 필요하다. 이를 위해, 사용자 클라이언트에는 반응형 영상을 구성하는 복수의 이미지 정보만을 저장하도록 할 수 있다. 예를 들어, 사용자 클라이언트는 반응형 영상을 그대로 저장하지 않고, 반응형 영상을 구성하는 프레임을 압축 과정에 분할하고 각 프레임의 저장순서를 변경하여 둠에 따라 보 안성을 높일 수 있다. 다만, 사용자 클라이언트가 이러한 방식으로 이미지 정보를 저장할 때 사용자의 조작에 따라 반응형 영상을 출력하기 위한 방안이 필요하다. 먼저, 서비스서버가 사용자 클라이언트로부터 반응형 영상의 조작 위치를 획득한다. 즉, 서비스서버가 사용자 클라이언트로부터 사용자가 어느 부분을 반응형으로 출력하기 위한 조작을 입력하였는지 수신한다. 예를 들어, 서비스서버는 사용자클라이언트의 터치 디스플레이 상 조작 위치 데이터를 수신한다. 그 후, 서비스서버가 조작 위치에 대한 어드레스를 사용자 클라이언트로 전송한다. 상기 어드레스는 클라이언트 에서 저장되어 있는 것 중에서 출력해야 하는 프레임 정보(즉, 프레임의 식별값)이다. 그 후, 사용자 클라이언트가 상기 어드레스에 대응되는 이미지 처리를 통해 실시간 출력한다. 또한, 상기 조작위치 획득단계는, 사용자 조작이 입력되는 시간데이터 또는 압력세기를 더 획득할수 있다. 사용 자가 조작하는 압력세기 또는 시간에 따라 상이한 프레임을 출력하여야 할 수 있으므로, 서비스서버는 사용자 클라이언트로부터 조작위치(xy좌표)와 함께 조작시간길이 또는 압력세기를 수신한다. 또한, 본 발명의 다른 일실시예에 따른 반응형 영상 기반 서비스 제공방법은, 컴퓨터가 동영상 재생시간에 따라 반응 맵 데이터를 이동하도록 구현한다. 이를 통해, 동영상이 재생되는 중에 사용자의 조작을 입력하여 반응을 구현할 수 있다. 예를 들어, 사람이 걸어가는 동영상 재생 중에 유저가 조작을 입력하는 위치에 따라 상이한 프레임이 재생(예를 들어, 등장인물이 넘어지는 위치가 조작 위치에 따라 다르게 재생)되도록 구현할 수 있다. 이를 위해, 컴퓨터는 반응 맵 데이터가 시간 흐름에 따라 위치가 변경되도록 설정할 수 있고, 반응 맵 데이터 상의 각 구획에 매핑되는 프레임을 조작시점(즉, 동영상 내의 재생시간)에 따라 다르게 설정할 수 있다. 즉, 컴 퓨터는 사용자의 조작이 입력되는 반응 맵 데이터 상의 구획값과 조작이 입력되는 시간값의 조합에 대해 상이한 이미지정보를 매핑할 수 있다. 이상에서 전술한 본 발명의 일실시예에 따른 다중 반응형영상 제작 및 서비스방법은, 하드웨어인 컴퓨터와 결합 되어 실행되기 위해 프로그램(또는 어플리케이션)으로 구현되어 매체에 저장될 수 있다. 상기 전술한 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, 기 계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필요 한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들을 상기 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있다. 또한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨 터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠 한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어 떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는지 등 에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다. 첫째, 다중 반응형영상 생성파일을 일반동영상이나 복수의 영상프레임 조합과 함께 재생함에 따라 다양한 액션 (즉, 반응)을 적용할 수 있다. 둘째, 다중 반응형영상 생성파일을 통해 영상에 특정한 조건설정을 수행함에 따라, 사용자에게 단순히 시간의 축에 의해 제한되는 기존 미디어들과는 달리, 사건(Event)에 따라 각기 다른 다양한 출력이 적용된 다중 반응형 영상을 제공할 수 있다. 셋째, 동영상 프레임에 영상 분할 또는 크롭을 적용함에 따라 촬영한 하나의 영상을 기반으로 여러가지 액션을 구현할 수 있는 효과가 있다. 넷째, 다중 반응형영상 생성파일을 통해 특정한 사용자의 영상에 대한 조작 내역을 기록함에 따라 사용자의 영 상에 대한 반응을 파악할 수 있다. 예를 들어, 사용자의 다중 반응형영상에 대한 터치조작 횟수, 터치조작을 수 행한 프레임과 프레임 내 대상체 등을 파악할 수 있다."}
{"patent_id": "10-2023-7017363", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-7017363", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 다중 반응형영상 생성방법에 대한 순서도이다. 도 2는 본 발명의 일실시예에 따라, 사용자조작에 따라 대상체인 얼굴의 고개방향 및 표정 변화를 제공하는 예 시도면이다. 도 3은 본 발명의 일실시예에 따라, 사용자에 의해 입력되는 조작에 대응하여 상이한 결과들을 구현할 수 있도 록 복수의 사건을 포함하는 기초영상의 예시도면이다. 도 4은 본 발명의 일실시예에 따른 사용자의 각 터치조작 위치에 따른 대상체 위치 변화를 구현하기 위한 기초 영상의 예시도면이다. 도 5는 본 발명의 일실시예에 따른 압축영상의 스텍구조를 나타낸 예시도면이다. 도 6은 본 발명의 일 실시예에 따른 다중반응형 영상 기반의 서비스 제공 시스템에 대한 네트워크 구조를 나타 내는 도면이다. 도 7a 내지 도 7d는 본 발명의 일 실시예에 따라 구현되는 다중반응형 영상의 일 예들을 나타내는 도면이다. 도 8은 본 발명의 일 실시예에 따른 다중반응형 영상 기반의 서비스 제공을 위한 서비스 서버에 대한 구성을 나 타내는 도면이다. 도 9는 본 발명의 일 실시예에 따른 다중반응형 영상 기반의 서비스 제공 방법에 대한 순서도이다."}
