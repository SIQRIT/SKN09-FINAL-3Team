{"patent_id": "10-2023-0035316", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0140660", "출원번호": "10-2023-0035316", "발명의 명칭": "딥러닝 기반 심폐소생술 교육 시스템", "출원인": "한림대학교 산학협력단", "발명자": "이정아"}}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥러닝 기반의 심폐소생술 교육 시스템에 있어서, 카메라를 구비하며, 상기 카메라로 사용자의 심폐소생술 동작을 촬영하는 사용자 단말; 및 상기 사용자 단말에 의해 촬영된 영상을 수신하고, 상기 영상을 동작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보를 도출하되, 상기 영상에서 기설정된 사용자의 신체 부위를 추출하고, 상기 신체부위의 위치 정보를 기반으로 평가 요소 별 적합도를 측정하는 서버;를 포함하며, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함하는 것을 특징으로 하는 심폐소생술 교육 시스템."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서상기 서버는 상기 사용자의 심폐소생술 동작을 촬영하기 위한 상기 사용자 단말의 설치 위치 및 각도를 확인하고, 촬영 조건에 부합하는지 여부를 판단하는 환경 설정부;를 포함하는 것을 특징으로 하는 심폐소생술 교육 시스템."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 서버는 상기 사용자의 심폐소생술 동작에 대한 평가 정보에 대응하여 사용자의 심폐소생술 동작을 교정하기 위한 교정정보를 제공하는 피드백 분석부;를 포함하는 것을 특징으로 하는 심폐소생술 교육 시스템."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 서버는상기 영상으로부터 상기 사용자의 기설정된 신체 부위 및 평가용 마네킹의 신체 부위를 추출하여, 상기 사용자가 상기 마네킹에 대하여 심폐소생술을 실시하는 기본 자세의 적합도를 평가하며, 상기 기본 자세는 사용자의 팔의 굽힘 여부 및 사용자의 손이 위치되는 마네킹의 신체 부위를 포함하는 것을특징으로 하는 심폐소생술 교육 시스템."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 서버는 상기 영상에 대하여 기설정된 레이블 데이터로 흉부 압박 1회 동작 별 적합성 평가를 수행하고, 상기 영상의 총시간 동안 확인된 전체 흉부 압박 동작에 대한 평가 데이터를 종합하여 평가 점수를 산출하되, 상기 레이블 데이터는 흉부압박 1회당 걸리는 시간, 흉부압박 깊이, 흉부압박 최고 깊이까지 도달하는 데 걸리는 시간, 흉부압박 최고 깊이 절대값, 흉부압박 후 이완하는 깊이, 잘못된 위치 압박 여부, 불완전 이완 여부,평균 압박 속도를 포함하는 항목으로 구성되는 것을 특징으로 하는 심폐소생술 교육 시스템."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0140660-3-제1항에 있어서,상기 동작분석 딥러닝 모델은PoseNet 및 Vnect 중 적어도 하나의 오픈소스 모델을 기반으로, 사용자의 상반신, 팔 및 손을 포함하는 기설정된 신체부위를 추출하고, 추출된 신체 부위의가 위치되는 좌표 위치, 상기 좌표의 이동 정도 및 이동 속도를 판단하도록 학습된 것을 특징으로 하는 심폐소생술 교육 시스템."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "딥러닝 기반의 심폐소생술 교육을 수행하는 전자 장치에 있어서,사용자 단말에 의해 사용자의 심폐소생술 동작이 촬영된 영상을 동작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보를 도출하되, 상기 영상에서 기설정된 사용자의 신체 부위를 추출하고, 상기 신체부위의 위치 정보를 기반으로 평가 요소 별 적합도를 측정하는 딥러닝 분석부; 및상기 평가 정보에 대응하여 사용자의 심폐소생술 동작을 교정하기 위한 교정 정보를 제공하는 피드백 제공부;를포함하고, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함하는 것을 특징으로 하는 서버."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "딥러닝 기반의 심폐소생술 교육 시스템에 있어서, 카메라를 구비하며, 상기 카메라로 사용자의 심폐소생술 동작을 촬영하는 사용자 단말; 및 상기 사용자 단말에 의해 촬영된 영상을 수신하고, 상기 영상을 동작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보를 도출하는 서버;를 포함하며, 상기 서버는 상기 사용자의 심폐소생술 동작을 촬영하기 위한 상기 사용자 단말의 설치 위치 및 각도를 확인하고, 촬영 조건에 부합하는지 여부를 판단하는 환경 설정부;상기 영상에서 기설정된 사용자의 신체 부위를 추출하고, 상기 신체 부위의 위치 정보를 기반으로 평가 요소 별적합도를 측정하는 딥러닝 분석부;및상기 평가 정보에 대응하여 사용자의 심폐소생술 동작을 교정하기 위한 교정 정보를 제공하는 피드백 제공부;를포함하고, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함하는 것을 특징으로 하는 심폐소생술 교육 시스템."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "딥러닝 기반의 심폐소생술 교육 방법에 있어서,사용자 단말로 촬영되는 대상자의 위치를 판단하여 심폐소생술의 촬영 조건이 만족되었는지 여부를 확인하는 조건 확인 단계;상기 촬영 조건이 만족된 것으로 판단됨에 따라, 상기 사용자 단말로 대상자의 심폐소생술 동작을 촬영하는 촬영 단계;서버가, 상기 사용자 단말로부터 상기 심폐소생술 동작을 촬영한 영상을 수신하고, 상기 영상을 동작분석 딥러닝 모델에 입력하여 상기 영상 내 사용자의 동작에 대한 평가를 수행하는 평가 단계; 및상기 서버가, 상기 평가의 결과에 대응하여 상기 사용자에게 요구되는 교정 정보를 제공하는 교육 단계;를 포함하는 것을 특징으로 하는 심폐소생술 교육 방법."}
{"patent_id": "10-2023-0035316", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램에 있어서,공개특허 10-2024-0140660-4-전자 장치의 프로세서에 의해 실행되어, 상기 전자 장치로 하여금, 제9항의 상담 방법을 수행하도록 하는, 컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0035316", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 딥러닝 기반의 심폐소생술 교육 시스템은 카메라를 구비하며, 상기 카메라로 사용자의 심폐소생술 동작을 촬영하는 사용자 단말 및 상기 사용자 단말에 의해 촬영된 영상을 수신하고, 상기 영상을 동 작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보를 도출하되, 상기 영상에서 기설정된 사 용자의 신체 부위를 추출하고, 상기 신체 부위의 위치 정보를 기반으로 평가 요소 별 적합도를 측정하는 서버를 포함하며, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함할 수 있다."}
{"patent_id": "10-2023-0035316", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 기반의 심폐소생술 교육을 지원하는 장치에 관한 것이다. 보다 구체적으로, 본 발명은 스마트 폰으로 촬영한 심폐소생술 동작에 대한 영상을 인공지능을 활용하여 분석하고, 이를 통해 올바른 심폐소생술 방 법을 교육할 수 있도록 지원하는 장치에 관한 것이다."}
{"patent_id": "10-2023-0035316", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존 심폐소생술(CPR) 교육은 Kinect를 사용하는 방식으로 이루어져왔다. 이러한 Kinect는 RGB카메라와 IR 카메 라를 모두 사용하는 방식이다. 그로 인해 RGB 카메라와 IR카메라가 물리적으로 서로 떨어져 있으므로, 두 카메 라의 영상을 일치시키기 위한 조정이 필요하였다. 다양한 방법으로 두 영상의 일치율을 높이는 것은 가능하나 완벽히 일치시키는 데에는 한계가 있으며, 정밀한 일치를 위해서는 고난도의 기술이 요구된다. 이러한 문제에 따라 전문 장비가 없더라도, 스마트폰의 단안 카메라를 활용하여 촬영한 영상만으로도 딥러닝을 활용해 보다 정확하게 심폐소생술 동작에 대하여 평가할 수 있는 방안이 요구되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 10-1973139호(자가학습 및 평가를 위한 심폐소생술 시뮬레이터)"}
{"patent_id": "10-2023-0035316", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 기존의 전문장비에 비해 간편한 장비인 스마트폰을 활용하여 보다 정확한 동작 평가를 수행하는 데 목적이 있다. 또한 본 발명은 딥러닝 모델을 활용하여 스마트폰을 활용하여 촬영된 사용자의 심폐소생술 동작을 정확하게 분 석하고, 이에 대응하는 피드백을 제공하는 데 목적이 있다. 본 개시의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 개시의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0035316", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 딥러닝 기반의 심폐소생술 교육 시스템은 카메라를 구비하며, 상기 카메라로 사용자 의 심폐소생술 동작을 촬영하는 사용자 단말 및 상기 사용자 단말에 의해 촬영된 영상을 수신하고, 상기 영상을 동작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보를 도출하되, 상기 영상에서 기설정된 사용자의 신체 부위를 추출하고, 상기 신체 부위의 위치 정보를 기반으로 평가 요소 별 적합도를 측정하는 서버 를 포함하며, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함할 수 있다. 이 때, 상기 서버는 상기 사용자의 심폐소생술 동작을 촬영하기 위한 상기 사용자 단말의 설치 위치 및 각도를 확인하고, 촬영 조건에 부합하는지 여부를 판단하는 환경 설정부를 포함할 수 있다. 또한, 상기 서버는 상기 사용자의 심폐소생술 동작에 대한 평가 정보에 대응하여 사용자의 심폐소생술 동작을 교정하기 위한 교정 정보를 제공하는 피드백 분석부를 포함할 수 있다. 또한, 상기 서버는 상기 영상으로부터 상기 사용자의 기설정된 신체 부위 및 평가용 마네킹의 신체 부위를 추출 하여, 상기 사용자가 상기 마네킹에 대하여 심폐소생술을 실시하는 기본 자세의 적합도를 평가할 수 있으며, 상 기 기본 자세는 사용자의 팔의 굽힘 여부 및 사용자의 손이 위치되는 마네킹의 신체 부위를 포함할 수 있다. 또한, 상기 서버는 상기 영상에 대하여 기설정된 레이블 데이터로 흉부 압박 1회 동작 별 적합성 평가를 수행하 고, 상기 영상의 총 시간 동안 확인된 전체 흉부 압박 동작에 대한 평가 데이터를 종합하여 평가 점수를 산출할 수 있다. 그리고 이 때 상기 레이블 데이터는 흉부압박 1회당 걸리는 시간, 흉부압박 깊이, 흉부압박 최고 깊이 까지 도달하는 데 걸리는 시간, 흉부압박 최고 깊이 절대값, 흉부압박 후 이완하는 깊이, 잘못된 위치 압박 여 부, 불완전 이완 여부 및 평균 압박 속도를 포함할 수 있다. 그리고 상기 동작분석 딥러닝 모델은 PoseNet 및 Vnect 중 적어도 하나의 오픈소스 모델을 기반으로, 사용자의 상반신, 팔 및 손을 포함하는 기설정된 신체부위를 추출하고, 추출된 신체 부위의가 위치되는 좌표 위치, 상기 좌표의 이동 정도 및 이동 속도를 판단하도록 학습될 수 있다. 본 발명의 실시 예에 따른 딥러닝 기반의 심폐소생술 교육을 수행하는 전자 장치는 사용자 단말에 의해 사용자 의 심폐소생술 동작이 촬영된 영상을 동작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보 를 도출하되, 상기 영상에서 기설정된 사용자의 신체 부위를 추출하고, 상기 신체 부위의 위치 정보를 기반으로 평가 요소 별 적합도를 측정하는 딥러닝 분석부 및 상기 평가 정보에 대응하여 사용자의 심폐소생술 동작을 교 정하기 위한 교정 정보를 제공하는 피드백 제공부를 포함하고, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함할 수 있다. 또한, 본 발명의 실시 예에 따른 딥러닝 기반의 심폐소생술 교육 방법은 사용자 단말로 촬영되는 대상자의 위치 를 판단하여 심폐소생술의 촬영 조건이 만족되었는지 여부를 확인하는 조건 확인 단계, 상기 촬영 조건이 만족 된 것으로 판단됨에 따라, 상기 사용자 단말로 대상자의 심폐소생술 동작을 촬영하는 촬영 단계, 서버가, 상기 사용자 단말로부터 상기 심폐소생술 동작을 촬영한 영상을 수신하고, 상기 영상을 동작분석 딥러 닝 모델에 입력하여 상기 영상 내 사용자의 동작에 대한 평가를 수행하는 평가 단계 및 상기 서버가, 상기 평가 의 결과에 대응하여 상기 사용자에게 요구되는 교정 정보를 제공하는 교육 단계를 포함하여 구성될 수 있다. 또한, 본 발명에 따르면 이와 같은 방법을 수행하는 컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램이 개시될 수 있다."}
{"patent_id": "10-2023-0035316", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 딥러닝 모델을 활용하여 간편하게 사용자의 심폐소생술 동작을 평가할 수 있으며, 그에 대한 피드백 제공이 가능하다. 또한 본 발명은 적외선 카메라, 센서가 구비된 전문 마네킹이 구비되지 않더라도 촬영된 사용자의 심폐소생술 동작 영상만을 토대로 동작의 완성도를 평가할 수 있다."}
{"patent_id": "10-2023-0035316", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 명세서에서 사용되는 \"부\" 또는 “모듈”이라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소 를 의미하며, \"부\" 또는 “모듈”은 어떤 역할들을 수행한다. 그렇지만 \"부\" 또는 “모듈”은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\" 또는 “모듈”은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수 도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\" 또는 “모 듈”은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라 이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 \"부\" 또는 “모듈”들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\" 또는 “모듈”들로 결합되거나 추가적인 구성요소들과 \"부\" 또는 “모듈”들로 더 분리될 수 있다. 공간적으로 상대적인 용어인 \"아래(below)\", \"아래(beneath)\", \"하부(lower)\", \"위(above)\", \"상부(upper)\" 등 은 도면에 도시되어 있는 바와 같이 하나의 구성요소와 다른 구성요소들과의 상관관계를 용이하게 기술하기 위 해 사용될 수 있다. 공간적으로 상대적인 용어는 도면에 도시되어 있는 방향에 더하여 사용시 또는 동작시 구성 요소들의 서로 다른 방향을 포함하는 용어로 이해되어야 한다. 예를 들어, 도면에 도시되어 있는 구성요소를 뒤 집을 경우, 다른 구성요소의 \"아래(below)\"또는 \"아래(beneath)\"로 기술된 구성요소는 다른 구성요소의 \"위 (above)\"에 놓여질 수 있다. 따라서, 예시적인 용어인 \"아래\"는 아래와 위의 방향을 모두 포함할 수 있다. 구성 요소는 다른 방향으로도 배향될 수 있으며, 이에 따라 공간적으로 상대적인 용어들은 배향에 따라 해석될 수 있 다. 이하 첨부된 도면을 참조하여, 본 발명의 실시 예를 설명하기로 한다. 도 1은 본 발명의 실시 예에 따른 심폐소생술 교육 시스템의 구성을 도시한 도면이다. 도 1에서 도시되는 바와 같이, 본 발명의 실시 예에 따른 심폐소생술 교육 시스템은 서버와 사용자 단말 로 구성될 수 있다. 상기 사용자 단말은 사용자가 심폐소생술의 실습을 위해 마네킹을 대상으로 심폐소생술의 동작을 수행하는 동안 해당 동작을 영상으로 촬영할 수 있다. 그리고 상기 사용자 단말은 사용자의 심폐소생술 동작을 촬영 한 영상을 서버에 전송하며 딥러닝 모델을 기반으로 하여 사용자의 심폐소생술 동작에 대한 평가가 자동으 로 이루어질 수 있도록 요청할 수 있다. 이에 대응하여 상기 서버는 사용자 단말로부터 사용자의 심폐소생술 동작이 촬영된 영상이 수신되면, 해당 영상을 동작분석 딥러닝 모델에 적용하여 이를 자동으로 평가할 수 있다. 상기 서버가 사용자의 심폐소생술 동작을 평가하는 과정은 상기 촬영된 영상으로부터 기설정된 신체 부위 를 추출하고, 상기 추출된 사용자의 신체 부위의 위치 정보(예, 좌표값), 상기 위치 정보의 이동 정도 및 이동 속도에 대응하여 심폐소생술의 적합도를 판단할 수 있다. 상기 시스템의 구성은 이하의 도 2 내지 도 4를 참조하여 보다 자세히 기술하기로 한다. 도 2는 본 발명의 실시 예에 따른 사용자 단말의 구성을 도시하는 도면이다. 도 3은 본 발명의 실시 예에 따른 서버의 구성을 도시한 도면이다. 도 4는 본 발명의 실시 예에 따른 서버의 딥러닝 분석부의 구성을 도시한 도면이다. 먼저, 도 2에서 도시되는 바와 같이, 본 발명의 실시 예에 따른 사용자 단말은 카메라 및 디스플레이 를 구비할 수 있다. 또한 상기 사용자 단말은 도면에 도시되지 않았으나, 서버에 사용자의 심폐 소생술 동작을 촬영한 영상을 저장하는 메모리, 상기 영상을 서버로 전송하기 위한 통신 모듈 등을 더 포 함할 수 있다. 상기 사용자 단말은 구비된 카메라를 이용하여 사용자의 심폐소생술 동작을 촬영하여 동영상 데이터 를 제작할 수 있다. 이 때 상기 사용자 단말은 상기 카메라로 동영상 데이터의 촬영 착수 전에, 서버 의 제어 하에 상기 카메라의 촬영 환경을 체크할 수 있다. 예를 들어, 상기 사용자 단말은 서버 에 접속한 상태에서 카메라 촬영 기능을 동작할 수 있으며, 촬영 버튼이 선택되기 전, 카메라를 통해 확인되는 사용자 및 심폐소생술 교육용 마네킹에 대하여 대상체의 확인 및 촬영 각도 등의 촬영 관련 요소 를 체크할 수 있다. 또한, 상기 사용자 단말은 디스플레이를 포함할 수 있으며, 상기 디스플레이는 사용자 단말 에서 촬영된 사용자의 심폐소생술 동작 영상의 재생 화면을 표시할 수 있으며, 서버에 해당 영상이 전송됨에 따라 산출되는 상기 영상에 대한 평가 결과를 표시할 수 있다. 상기 영상에 대한 평가 요소로는 예를 들어, 사용자가 수행한 심폐소생술의 기본 자세, 심폐소생술을 수행하는 동안 확인된 흉부압박 속도, 흉부압박 깊이 등이 포함될 수 있다. 상기 사용자 단말은 이와 같이 구비된 카메라를 이용하여 사용자의 심폐소생술 영상이 촬영되기 전 단계에서 촬영 환경을 체크하고, 사용자의 심폐소생술 동작을 촬영하여 동영상 데이터를 생성할 수 있다. 그리 고 생성된 동영상 데이터를 서버에 전송하여 사용자의 심폐소생술 동작의 정확도를 평가하도록 요청할 수 있으며, 서버로부터 심폐소생술 동작의 평가 결과를 수신하여 이를 디스플레이를 통해 표시할 수 있 다. 상기 서버는 도 3에서 도시되는 바와 같이, 메모리, 통신부 및 프로세서를 포함하여 구성 될 수 있다. 그리고 상기 프로세서는 환경 설정부, 딥러닝 분석부 및 피드백 제공부를 포 함하여 구성될 수 있다. 상기 메모리는 상기 사용자 단말 측으로부터 획득된 복수의 심폐소생술 촬영 영상을 저장할 수 있다. 또한 상기 메모리는 사용자 별 계정 정보를 저장할 수 있다. 상기 계정 정보는 사용자 각각에 대한 심폐소 생술 동작의 평가 결과가 평가 일자에 따라 순차적으로 저장될 수 있다. 다양한 실시 예에 따라 상기 메모리 에 저장된 일 사용자가 획득한 평가 결과들은 추후 해당 사용자의 실력 향상 수준, 취약점 등을 판단하는 데 활용될 수 있다. 상기 통신부는 사용자 단말과 서버 간의 데이터 송수신에 요구되는 통신 기능을 수행할 수 있다. 예를 들어, 상기 통신부는 사용자 단말에서 촬영된 사용자의 심폐소생술에 대한 동영상 데이터 를 수신하기 위한 통신 기능을 수행할 수 있다. 상기 프로세서는 앞서 기술한 바와 같이 환경 설정부, 딥러닝 분석부, 피드백 제공부를 포 함할 수 있다. 상기 프로세서는 사용자 단말로부터 획득된 사용자의 심폐소생술 동작이 기록된 촬영 영상을 대상으 로 동작분석 딥러닝 모델에 기반한 평가를 수행하고, 평가 결과에 대응하여 사용자에게 적합한 피드백을 제공할 수 있다. 구체적으로, 상기 프로세서의 환경 설정부는 사용자의 심폐소생술 동작을 촬영하기 위한 사용자 단말 의 설치 위치 및 각도를 확인하고, 촬영 조건에 부합하는지 여부를 판단할 수 있다. 구체적으로, 상기 환경 설정부는 사용자 단말이 서버에 접속하여 카메라 기능을 실행할 수 있도 록 지원할 수 있다. 예컨대, 사용자 단말이 서버가 지원하는 심폐소생술 교육 앱 또는 웹을 실행하여 서버에 접속할 경우, 상기 환경 설정부는 사용자 단말이 심폐소생술 동작을 촬영할 조건에 부합하는지 여부를 판단하여 촬영 조건이 부합되는 것으로 판단될 경우 촬영을 시작하도록 안내할 수 있다. 상기 환경 설정부는 도 6에서 도시되는 바와 같이, 사용자 단말로 촬영되는 대상체(사용자 및 마네킹)의 위치 정보를 기반으로 사용자 단말의 설치 위치를 판단할 수 있다. 예컨대, 상기 환경 설정부는 사용자 단말에 의해 촬영되는 촬영 환경을 판단하기 위한 판단 모드를 수행할 수 있다. 상기 환경 설정부는 상기 판단 모드에서, 심폐소생술의 대상이 되는 교육용 마네킹이 누 워있는 위치와 사용자 단말이 이격된 가로 길이 및 상기 사용자 단말이 거치된 상태에서의 높이 를 판단할 수 있다. 상기 사용자 단말은 삼각대 등 거치할 수 있는 기구에 의해 높이 조절이 가능하 도록 거치된 상태일 수 있다. 그리고 상기 사용자 단말이 거치된 상태에서의 높이는 지면으로부터 거 치대에 거치된 사용자 단말의 화면의 중심점까지의 길이를 의미할 수 있다. 또한 상기 환경 설정부는 마네킹의 흉부 표면의 높이로부터 사용자 단말의 화면의 중심점의 높이까지 의 거리를 판단하기 위한 동작을 수행할 수 있다. 이와 같이 상기 환경 설정부는 카메라를 통해 확인되는 대상체의 위치를 기반으로 화면 상에서 확인되는 대상체의 크기 정보에 일정 계산 식을 적용하여, 각종 거리 항목(상기 사용자 단말과 마네킹의 가로 이격 거리 , 사용자 단말의 지면으로부터의 높이 및 마네킹의 흉부 표면의 높이로부터 사용자 단말의 화면 중심 점까지의 높이까지의 거리)를 계산하고, 계산된 결과로 상기 거리 항목의 값들을 유추할 수 있다. 또는 상기 환경 설정부는 다양한 실시 예에 따라 사용자 단말에 구비된 센서(예, 근접센서, 자이로 센서 등)를 기반으로 대상체와 사용자 단말 간의 거리가 과도하게 근접한지의 여부, 사용자 단말이 고정되어 있는지 여부를 추가로 판단할 수 있다. 그리고, 상기 환경 설정부는 촬영 대상체와의 적정 근접 성, 사용자 단말의 고정 안정성을 평가한 결과를 기반으로 촬영 조건이 부합되는지 여부를 판단할 수 있다. 상기 환경 설정부는 이와 같은 거리 요건이 기설정된 기준 범위를 충족하지 않는 경우, 사용자 단말(20 0)의 설치 위치를 변경하도록 안내할 수 있다. 이 때 안내되는 내용에는 사용자 단말의 화면 방향, 사용자 단말의 높이, 사용자 단말과 마네킹의 이격 거리 등을 포함할 수 있다. 또한, 상기 환경 설정부는 도 6의 630과 같이 사용자 단말을 통해 촬영되는 화면에 사용자와 마네킹 의 영역이 기준 부위(예, 머리 끝 지점 및 허벅지)를 포함하는지 여부를 확인하고, 기준 부위가 모두 포함되는 것으로 확인되는 경우에 한하여 촬영 동작이 개시될 수 있도록 지원할 수 있다. 다양한 실시 예에 따라 상기 환경 설정부는 촬영 조건이 만족됨에 따라 자동으로 촬영될 수 있도록 지원하 는 자동 촬영 모드를 지원할 수 있다. 상기 환경 설정부는 상기 자동 촬영 모드에서, 사용자가 마네킹 또 는 사용자 단말의 위치를 조절하는 동작을 수행하여 기설정된 거리 요건이 만족되는 경우, 신호음을 울리 고, 신호음이 출력된 이후 일정 시간(예, 5초) 이후 동영상 녹화를 자동으로 시작할 수 있다. 상기 환경 설정부에서 촬영 조건이 만족된 것으로 확인됨에 따라, 또는 자동 촬영 모드가 동작함에 따라 사용자 단말은 촬영 동작을 개시하고 이에 대응하여 사용자의 심폐소생술 동작이 담긴 동영상 데이터를 생 성할 수 있다. 이에 따라 생성된 사용자의 심폐소생술 동영상은 이후 딥러닝 분석부에 의해 분석 및 평가될 수 있다. 상기 딥러닝 분석부는 사용자 단말로부터 획득된 사용자의 심폐소생술 동작이 기록된 촬영 영상을 동 작분석 딥러닝 모델에 적용하여 자동으로 사용자의 심폐소생술 동작을 평가할 수 있다. 상기 딥러닝 분석부는 도 4에서와 같이 구성될 수 있다. 도 4에서 도시되는 바와 같이, 상기 딥러닝 분석부는 신체 부위 추출부, 동작 변수 측정부, 정 확도 판단부를 포함하여 구성될 수 있다. 먼저, 상기 신체부위 추출부는 상기 촬영 영상으로부터 사용자의 기설정된 신체 부위를 추출하는 동작을 수행할 수 있다. 이 때 상기 신체부위 추출부는 신체 부위를 추출하는 동작을 동작분석 딥러닝 모델을 통해 수행할 수 있는 데, 상기 딥러닝 모델은 흉부압박 동작을 촬영한 복수의 동영상 데이터를 이용해 학습된 모델일 수 있다. 도면에 도시되지는 않았으나, 상기 딥러닝 분석부는 상기 딥러닝 모델의 학습 동작을 지원할 수 있다. 상 기 딥러닝 모델의 학습 과정에 대하여 설명하면 다음과 같다. 상기 딥러닝 모델의 학습에 요구되는 동영상 데이터도 평가 대상 동영상을 생성할 때와 마찬가지로, 촬영 조건이 만족되는지 여부를 판단하고, 촬영 조건이 만족 되는 것을 확인한 후 촬영될 수 있다. 이에 따라 학습에 사용되는 학습용 데이터도 마네킹과 촬영 기기(사용자 단말) 간의 간격 및 촬영 기기(사용자 단말)의 지면으로부터의 높이 등의 촬영 요건이 기준값을 만족하는지 여 부를 판단할 수 있다. 또한 상기 학습용 데이터는 1회의 흉부압박 동작에 대한 데이터를 의미할 수 있다. 일 실시 예에 따라, 학습용 데이터로 활용될 교육생들의 심폐소생술 동영상은 흉부압박 동작을 흉부압박 1회 단위로 분할될 수 있고, 흉부 압박 1회가 실시되는 동안의 동영상 데이터는 1개의 데이터로 설정될 수 있다. 또한 상기 딥러닝 분석부는 상기 학습용 데이터인 동영상 데이터가 촬영되는 동안 평가 전문 마네킹(예, 가해지는 힘을 센싱하여 압박되는 위치와 압박의 깊이 및 속도 등의 요소를 측정할 수 있는 마네킹)에 의해 측 정되는 수치 정보를 딥러닝 모델 학습 시, 라벨링 데이터로 활용할 수 있다. 예를 들어, 상기 딥러닝 분석부 는 1회 단위로 분할된 동영상 데이터와, 해당 동작이 촬영되는 동안 확인된 흉부 압박 동작과 관련된 수치 (평가 전문 마네킹에서 측정된 심폐소생술 동작에 대한 데이터)를 매칭하여 학습에 활용할 수 있다. 흉부압박 1 회당 평가 전문 마네킹에 의해 획득되는 정보는 예컨대, 흉부압박 1회당 걸리는 시간(ms), 흉부압박 깊이(mm), 흉부압박 최고 깊이까지의 시간(ms), 흉부압박 최고 깊이 절대값(mm), 흉부압박 후 다시 이완하는 깊이(mm), 잘 못된 위치 압박 여부, 불완전 이완 여부, 평균 압박 속도(/min)를 포함할 수 있다. 이 때 상기 딥러닝 분석부는 딥러닝 모델 학습 시, 흉부압박의 수치화된 정보에 대하여 명목화 된 변수로 변환하고 이를 레이블 데이터로 활용할 수 있다. 예를 들어, 흉부압박 속도는 느림(분당 100회 미만), 적정(분 당 100~120회), 빠름(분당 120회 미만)으로 지정되어 딥러닝 모델 학습에 활용될 수 있다. 또한 흉부압박 깊이 는 얕음(50mm 미만)과 충분(50mm이상)으로 구분될 수 있고, 압박 위치의 적정성과, 불완전 이완여부는 적정 항 목과, 교정 필요 항목으로 구분될 수 있다. 그러나 이에 제한되는 것은 아니며, 더욱 다양한 항목으로 분류될 수도 있다. 그리고 상기 딥러닝 모델은 일 실시 예에 따라 PoseNet 또는 Vnect과 같은 기학습 오픈소스 모델을 기반으로 생 성되어 사용자의 포즈추출 동작을 수행할 수 있도록 설계될 수 있다. 예를 들어, 본 발명의 딥러닝 모델은 PoseNet 또는 Vnect과 같은 기존 포즈 추출용 오픈소스 모델을 기반으로 하되, 심폐소생술 동작 측정을 위해 특 정 신체 부위(예, 상반신, 팔, 손 등)만을 추출하도록 파라미터를 재학습하도록 할 수 있다. 상기 신체부위 추출부는 이러한 과정에 따라 완성된 동작분석 딥러닝 모델을 활용하여 사용자의 심폐소생 술 촬영 영상에서 보여지는 사용자의 신체 부위를 자동으로 추출할 수 있다. 앞서 언급한 바와 같이, 본 발명의 실시 예에 따른 상기 딥러닝 모델은 사용자의 모든 신체부위를 추출하지 않 고, 심폐소생술 동작을 평가하는 데 요구되는 필수 신체 부위를 설정하고, 해당 부위를 위주로 추출하도록 설계 될 수 있다. 그에 따라 상기 신체부위 추출부는 예컨대, 사용자의 상반신, 팔, 손의 위치를 추출할 수 있 다. 상기 신체부위 추출부는 이와 같이 기설정된 신체 부위를 추출하고, 이들의 좌표 위치를 확인하여 사용자 의 기본 자세를 평가할 수 있다. 상기 신체부위 추출부는 도 7에서 도시되는 바와 같이 사용자의 손의 위 치, 팔꿈치 모양 등의 심폐소생술의 기본 자세를 평가할 수 있다. 도 7은 본 발명의 실시 예에 따른 심폐소생술 기본 자세를 설명하기 위한 도면이다. 도 7에서 도시되는 바와 같이, 심폐소생술의 기본 자세에서 평가되는 항목은 도 7의 710에서의 팔꿈치 부 위의 자세 적정성(팔꿈치가 제대로 펴져있으며 굽혀지지 않았는지)이 포함된다. 또한 기본 자세에서 평가되는 항목에는 사용자의 손의 위치의 적정성(마네킹의 흉부 압박 지점에 제대로 손을 위치시켰는가)이 포함된다. 다양한 실시 예에 따라, 상기 신체부위 추출부는 도 7의 720에서와 같이 마네킹의 정수리를 보이도록 위치 되고, 사용자는 측면이 보이도록 위치되어 촬영된 영상을 대상으로 신체부위를 추출할 수 있다. 그리고 상기 신 체부위 추출부는 추출된 신체부위를 기반으로 심폐소생술의 기본 자세를 평가할 수 있다. 이와 같이 사용 자의 측면 자세가 촬영된 영상을 대상으로 평가하는 경우, 상기 신체부위 추출부는 정면 자세가 촬영된 영 상을 분석할때와 마찬가지로 사용자의 팔꿈치가 펴져있는지 여부와, 손의 위치를 확인할 수 있다. 또 한 상기 신체부위 추출부는 사용자의 어깨 부위와 사용자의 손의 위치 및 마네킹의 위치를 기반 으로 사용자의 팔이 마네킹을 수직으로 압박하는 자세인지 여부를 판단할 수 있다. 기본 자세에 대한 평가를 1차적으로 수행한 이후, 딥러닝 분석부는 사용자의 심폐소생술 동작의 적정성을 평가하기 위해 동작 변수 측정부를 활용할 수 있다. 상기 동작 변수 측정부는 촬영 영상에서 추출된 신체 부위의 위치의 변화값 및 변화 속도를 측정하여, 사 용자의 심폐소생술 동작에서의 흉부 압박의 깊이 및 속도를 측정할 수 있다. 구체적으로, 상기 동작 변수 측정 부는 촬영 영상에서 확인되는 사용자의 손의 위치가 이동되는 지점 간 거리를 파악하고, 그로부터 사용자 의 흉부 압박 깊이를 판단할 수 있다. 그리고 기설정된 시간동안 사용자의 흉부압박이 이루어진 횟수를 판단하 고, 이를 통해 흉부압박 속도를 측정할 수 있다. 이 때, 상기 동작 변수 측정부는 다양한 사용자들에 대한 형평성 있는 심폐소생술 평가를 위해, 평가를 수행하는 동영상 재생 시간(평가 대상 시간)을 동일한 값으로 설정할 수 있다. 예를 들어, 상기 동작 변수 측정 부는 사용자의 최초 흉부압박 동작이 확인된 시점으로부터 30초까지의 재생 시간까지의 영상 데이터를 평 가 대상이 되는 영상으로 지정할 수 있다. 또는 이러한 평가 대상 시간은 촬영 당시에 미리 신호음 등으로 안내 될 수 있다. 이후 상기 동작 변수 측정부는 이러한 평가 대상 시간 동안 기학습된 딥러닝 모델이 레이블 데이터에 의해 확인한 '적정'항목과, '교정 필요'항목의 비율을 판단하고, 해당 분야의 점수를 산출할 수 있다. 예를 들어, 상 기 동작 변수 측정부는 평가 대상 시간인 30초 동안 이루어지는 심폐소생술 동작에서 사용자의 불완전 이 완 여부가 N회 '적정'으로 판단되고, M회 '교정 필요' 항목으로 판단되었으며, N의 비율이 50%인 것으로 판단될 수 있다. 이 때 적정성의 비율이 0이상 20(%)미만까지 0점, 20(%)이상~40(%)미만까지 1점, 40(%)이상~70(%)미만 까지 2점, 70(%)이상은 3점이 부여된다고 가정하면, '적정'판정이 50%의 비율로 확인된 사용자는 '불완전 이완 여부'분야에서 2점을 획득할 수 있다. 그 외 상기 동작 변수 측정부는 전체 평가 대상 시간 동안 수행된 흉부 압박 횟수를 기반으로 흉부 압박 속도를 측정하고, 이를 기설정된 평가 기준에 따라 점수를 산정할 수 있다. 예를 들어, 평가 대상 시간(예, 30 초) 동안 확인된 사용자의 흉부 압박 속도가 분당 100회 미만이면 느림에 해당하므로 0점을 부여하며, 분당 120 회 미만이면 빠름에 해당하므로 0점을 부여하며, 분당 100~120회인 것으로 판단될 경우 적정에 해당하므로 1점 을 부여할 수 있다. 이 때 상기 흉부압박 속도 측정의 결과로 부여되는 점수는 상대적인 평가 정도를 설명하기 위하여 언급한 것일 뿐, 고정된 값은 아니며, 평가 항목들 별 중요도를 고려하여 가중치가 추가로 적용될 수 있 다. 상기 정확도 판단부는 강사의 동영상을 통해 학습된 딥러닝 모델을 기반으로 사용자의 자세와 강사의 자세 가 얼마나 다른지를 탐지하여 결과를 안내하기 위한 구성이다. 상기 정확도 판단부에서 활용하는 딥러닝 모델은 별도의 라벨 데이터가 필요하지 않으며, 강사의 시범 동 영상만으로 학습이 가능하다. 상기 정확도 판단부는 이와 같이 전문가 동작으로 학습된 딥러닝 모델과 사용자의 심폐소생술 동작을 비교 하여 일치율을 산출할 수 있다. 이 때, 상기 정확도 판단부는 전문가 동작에서 확인되는 마네킹과 사용자 의 배치 구조가 같은 경우끼리 일치율을 판단할 수 있다. 예를 들어, 상기 정확도 판단부는 사용자의 정면 자세를 촬영한 영상은 정면 자세가 촬영된 전문가 영상들로 학습된 모델을 활용하여 일치율을 판단하고, 사용자 의 측면 자세가 촬영된 영상은 측면 자세가 촬영된 전문가 영상으로 학습된 모델을 활용하여 일치율을 판단할 수 있다. 상기 정확도 판단부는 또한 마네킹의 사이즈(성인, 어린이)를 고려하여 사용자 동작과 전문가 영상의 일치 율이 평가되도록 할 수 있다. 예를 들어, 상기 정확도 판단부는 사용자가 촬영한 영상에서 확인되는 심폐 소생술의 대상이 어린이 사이즈에 해당하는 경우, 전문가 영상에서의 심폐소생술 대상(마네킹)과, 사용자 영상 에서의 심폐소생술 대상의 사이즈축소 비율을 판단을 할 수 있다. 그리고 상기 판단된 비율 정보에 근거하여 상 기 정확도 판단부는 사용자 영상에서의 심폐소생술 대상에 대한 흉부압박의 동작의 적정 수치의 값(적정 흉부압박 깊이)을 산출하고, 사용자 영상과 전문가 영상의 동일성을 평가할 수 있다. 이 때 상기 정확도 판단부 는 심폐소생술의 대상이 갖는 신체부의의 사이즈(예, 머리 크기, 상반신 길이 등)를 기반으로 사용자 영상 에서의 심폐소생술 대상과 전문가 영상에서의 심폐소생술 대상 간 비율을 산출할 수 있다. 도 2에서 도시되는 프로세서의 구성 중 피드백 제공부는 사용자의 심폐소생술 동작에 대한 평가 결과 를 기반으로, 사용자에게 제공할 교정 정보를 산출하고, 이를 사용자 측에 제공할 수 있다. 구체적으로, 상기 서버는 사용자의 심폐소생술 동작의 적정성을 평가하는 과정에서, 각 평가 항목별 점수 를 산정하는 동작을 수행할 수 있다. 그리고, 상기 피드백 제공부는 각 평가 항목에 대한 점수를 기반으로 사용자의 점수가 기준치 이하인 항목 을 사용자가 취약한 항목으로 판할 수 있다. 그리고 상기 피드백 제공부는 사용자의 취약 항목을 교정하기 위한 교정 정보를 산출할 수 있다. 예를 들어, 상기 피드백 제공부는 흉부 압박의 위치의 적정성 항목에서 의 평가 점수는 기준치 이상이나, '흉부 압박의 깊이' 항목에서 기준치 이하의 점수를 획득한 사용자에게는 흉 부 압박을 깊게 하도록 조언하는 멘트를 출력하는 방식으로 교정 정보를 제공할 수 있다. 또한, 상기 피드백 제공부는 동일 사용자가 복수 회 평가를 실시한 경우, 평가 결과들을 통해 해당 사용자 의 개선 정도가 크거나 작은(점수의 향상 정도가 기준치 이상 또는 미만인) 항목을 추출할 수 있다. 그리고 그 에 대응하여 상기 피드백 제공부는 학습에 활용된 전문가 영상 데이터들 중 불일치율이 기준 퍼센트 이상 인 영상을 추출하여 교육 자료로 제공할 수 있다. 구체적으로, 상기 피드백 제공부는 사용자의 점수 향상 정도가 기준치 미만으로 판단된(개선 정도가 낮은) 항목의 신체 부위를 포함하는 일부 영역(특정 신체 부위인 팔꿈치 또는 어깨 등이 포함된 전체 화면이 대비 소규모 영역)을 추출할 수 있다. 그리고 상기 피드백 제공부 는 해당 영역과 동일한 위치에서의 동작과 불일치율이 기준치 이상인 전문가 영상을 탐색하여 사용자에게 제공할 수 있다. 이에 따라 사용자는 자신이 고치지 못하고 있는 자세에 대하여 제대로 된 동작을 수행하고 있 으면서도 가장 달라 보이는 동작을 확인하고, 이를 자신의 동작 교정에 활용할 수 있다. 또한 상기 피드백 제공부는 마네킹 사이즈(성인, 어린이)별 사용자의 점수를 구분하고, 이에 대한 교정 정 보를 제공할 수 있다. 이하에서는 도 5를 참조하여, 본 발명에 실시하는 심폐소생술 교육의 과정에 대하여 설명하기로 한다. 도 5는 본 발명의 실시 예에 따른 심폐소생술 교육 과정의 순서를 도시한 도면이다. 도 5에서 도시되는 바와 같이, 본 발명의 실시 예에 따른 서버는 사용자 단말의 요청에 따라 영상 촬 영 조건이 만족되는지 여부를 확인하는 505동작을 수행할 수 있다. 이 때 상기 사용자 단말의 요청이란, 사용자 단말을 통해 서버가 지원하는 앱 또는 웹에 접속하여, 자동 촬영 모드(촬영 조건이 만족됨에 따라 자동으로 촬영 개시)를 수행하는 동작을 포함할 수 있다. 또는 상기 사용자 단말의 요청이란, 사용자 단말을 통해 서버가 지원하는 앱 또는 웹에 접속하여 심폐소생술 촬영 조건이 만족되는지를 확인하는 별도 기능을 수행함을 의미할 수 있다. 이후, 상기 서버는 심폐소생술 촬영 조건이 만족되는 것으로 판단되지 않으면 촬영 조건을 만족하도록 사 용자 단말의 위치 또는 대상체의 위치 변경을 요청할 수 있다. 반면, 상기 서버는 심폐소생술 촬영 조건이 만족된 것으로 판단되면, 심폐소생술 영상을 촬영하도록 할 수 있다. 예를 들어, 서버는 심폐소생술 영상 을 촬영해도 좋다는 의미의 시그널을 사용자 단말에 제공하거나 또는 사용자 단말의 접근 권한을 활용해 자동으 로 녹화 기능이 시작되도록 제어할 수 있다. 그리고 그에 따라 사용자 단말은 카메라 기능을 활용해 영상을 촬영하고 분석을 요청하는 510단계가 이루 어질 수 있다. 이에 따라 상기 서버는 촬영된 심폐소생술 영상에서 사용자의 심폐소생술 동작을 평가하되, 먼저, 사용자 의 대상 신체 부위를 추출하는 515동작을 수행할 수 있다. 이후 상기 서버는 상기 심폐소생술 영상 내에서 사용자의 동작 요소를 측정하는 520동작을 수행할 수 있다. 이 때 동작 요소는, 사용자의 심폐소생술의 기본 자세, 흉부압박 속도, 흉부 압박의 깊이를 포함할 수 있 다. 즉, 상기 서버는 사용자의 신체 부위를 추출함을 통해, 해당 신체부위가 위치한 지점의 좌표를 기반으 로 사용자의 자세 적정성과, 상기 신체 부위가 위치의 좌표가 변경되는 정도 및 그 속도를 기반으로 동작(흉부 압박의 속도, 흉부압박의 깊이)의 적정성을 평가할 수 있다. 또한 상기 서버는 상기 사용자의 동작에 대한 정확도를 평가하는 525단계를 수행하고, 이후 평가 결과에 대응하는 교정 정보를 사용자 측에 제공하는 530 단계를 수행할 수 있다. 상기 서버에서 적정성을 평가하는 과정에서, 각 평가 항목별 점수를 산정하는 동작을 수행할 수 있으며, 각 평가 항목에 대한 점수를 바탕으로 사용자가 가장 취약한 항목 및 이를 교정하기 위한 교정 정보를 산출할수 있다. 요컨대, 본 발명의 실시 예에 따른 딥러닝 기반의 심폐소생술 교육 시스템은 카메라를 구비하며, 상기 카메라로 사용자의 심폐소생술 동작을 촬영하는 사용자 단말 및 상기 사용자 단말에 의해 촬영된 영상을 수신하고, 상기 영상을 동작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보를 도출하되, 상기 영상에서 기설정된 사용자의 신체 부위를 추출하고, 상기 신체 부위의 위치 정보를 기반으로 평가 요소 별 적합도를 측정 하는 서버를 포함하며, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함할 수 있다. 이 때, 상기 서버는 상기 사용자의 심폐소생술 동작을 촬영하기 위한 상기 사용자 단말의 설치 위치 및 각도를 확인하고, 촬영 조건에 부합하는지 여부를 판단하는 환경 설정부를 포함할 수 있다. 또한, 상기 서버는 상기 사용자의 심폐소생술 동작에 대한 평가 정보에 대응하여 사용자의 심폐소생술 동작을 교정하기 위한 교정 정보를 제공하는 피드백 분석부를 포함할 수 있다. 또한, 상기 서버는 상기 영상으로부터 상기 사용자의 기설정된 신체 부위 및 평가용 마네킹의 신체 부위를 추출 하여, 상기 사용자가 상기 마네킹에 대하여 심폐소생술을 실시하는 기본 자세의 적합도를 평가할 수 있으며, 상 기 기본 자세는 사용자의 팔의 굽힘 여부 및 사용자의 손이 위치되는 마네킹의 신체 부위를 포함할 수 있다. 또한, 상기 서버는 상기 영상에 대하여 기설정된 레이블 데이터로 흉부 압박 1회 동작 별 적합성 평가를 수행하 고, 상기 영상의 총 시간 동안 확인된 전체 흉부 압박 동작에 대한 평가 데이터를 종합하여 평가 점수를 산출할 수 있다. 그리고 이 때 상기 레이블 데이터는 흉부압박 1회당 걸리는 시간, 흉부압박 깊이, 흉부압박 최고 깊이 까지 도달하는 데 걸리는 시간, 흉부압박 최고 깊이 절대값, 흉부압박 후 이완하는 깊이, 잘못된 위치 압박 여 부, 불완전 이완 여부 및 평균 압박 속도를 포함할 수 있다. 그리고 상기 동작분석 딥러닝 모델은 PoseNet 및 Vnect 중 적어도 하나의 오픈소스 모델을 기반으로, 사용자의 상반신, 팔 및 손을 포함하는 기설정된 신체부위를 추출하고, 추출된 신체 부위의가 위치되는 좌표 위치, 상기 좌표의 이동 정도 및 이동 속도를 판단하도록 학습될 수 있다. 본 발명의 실시 예에 따른 딥러닝 기반의 심폐소생술 교육을 수행하는 전자 장치는 사용자 단말에 의해 사용자 의 심폐소생술 동작이 촬영된 영상을 동작분석 딥러닝 모델에 적용하여 상기 심폐소생술 동작에 대한 평가 정보 를 도출하되, 상기 영상에서 기설정된 사용자의 신체 부위를 추출하고, 상기 신체 부위의 위치 정보를 기반으로 평가 요소 별 적합도를 측정하는 딥러닝 분석부 및 상기 평가 정보에 대응하여 사용자의 심폐소생술 동작을 교 정하기 위한 교정 정보를 제공하는 피드백 제공부를 포함하고, 상기 평가 요소는 기본 자세, 흉부 압박의 깊이 및 흉부 압박의 속도를 포함할 수 있다. 또한, 본 발명의 실시 예에 따른 딥러닝 기반의 심폐소생술 교육 방법은 사용자 단말로 촬영되는 대상자의 위치 를 판단하여 심폐소생술의 촬영 조건이 만족되었는지 여부를 확인하는 조건 확인 단계, 상기 촬영 조건이 만족 된 것으로 판단됨에 따라, 상기 사용자 단말로 대상자의 심폐소생술 동작을 촬영하는 촬영 단계, 서버가, 상기 사용자 단말로부터 상기 심폐소생술 동작을 촬영한 영상을 수신하고, 상기 영상을 동작분석 딥러 닝 모델에 입력하여 상기 영상 내 사용자의 동작에 대한 평가를 수행하는 평가 단계 및 상기 서버가, 상기 평가 의 결과에 대응하여 상기 사용자에게 요구되는 교정 정보를 제공하는 교육 단계를 포함하여 구성될 수 있다. 또한, 본 발명에 따르면 이와 같은 방법을 수행하는 컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램이 개시될 수 있다. 본 발명의 실시 예에 따른 서버는 메모리, 통신부 및 프로세서를 포함할 수 있다. 메모리는 전자 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 통신부는 외부 장치와 통신을 수행할 수 있다. 특히, 통신부는 와이파이 칩, 블루투스 칩, 무선 통신 칩, NFC칩, 저전력 블루투스 침(BLE 칩) 등과 같은 다양한 통신 칩을 포함할 수 있다. 이때, 와이파이 칩, 블루투스 칩, NFC 칩은 각각 LAN 방식, WiFi 방식, 블루투스 방식, NFC 방식으로 통신을 수행한다. 와이파이 칩이나 블루 투스칩을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신 하여, 이를 이용하여 통 신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신칩은 IEEE, 지그비, 3G(3rd Generation), 3GPP(3rdGeneration Partnership Project), LTE(Long Term Evolution) 등과 같은 다양한 통신 규격에 따라 통신을 수행 하는 칩을 의미한다. 프로세서는 메모리에 저장된 각종 프로그램을 이용하여 사용자 기기의 전반적인 동작을 제어할 수 있다. 프로세 서는 RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스 및 버스로 구성될 수 있다. 이때, RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스 등은 버스를 통해 서로 연결될 수 있다. RAM은 O/S 및 어플리케이션 프로그램을 저장한다. 구체적으로, 전자 장치가 부팅되면 O/S가 RAM에 저장되고, 사 용자가 선택한 각종 어플리케이션 데이터가 RAM에 저장될 수 있다. ROM에는 시스템 부팅을 위한 명령어 세트 등이 저장된다. 턴 온 명령이 입력되어 전원이 공급되면, 메인 CPU는 ROM에 저장된 명령어에 따라 메모리에 저장된 O/S를 RAM에 복사하고, O/S를 실행시켜 시스템을 부팅시킨다. 부팅이 완료되면, 메인 CPU는 메모리에 저장된 각종 어플리케이션 프로그램을 RAM에 복사하고, RAM 에 복사된 어플리케이션 프로그램을 실행시켜 각종 동작을 수행한다. 메인 CPU는 메모리에 액세스하여, 메모리에 저장된 OS를 이용하여 부팅 및 실행을 포함한 동작들을 수행한다. 그리고, 메인 CPU는 메모리에 저장된 각종 프로그램, 컨텐츠, 데이터 등을 이용하여 다양한 동작을 수행한다. 제1 내지 n 인터페이스는 상술한 각종 구성요소들과 연결된다. 제1 내지 n 인터페이스 중 하나는 네트워크를 통 해 외부 장치와 연결되는 네트워크 인터페이스가 될 수도 있다. 한편, 나아가, 프로세서는 인공지능 모델을 제어할 수 있다. 이 경우, 제어부는 인공지능 모델을 제어하기 위한 그래픽 전용 프로세서(예: GPU)를 포함할 수 있음은 물론이다. 프로세서는 하나 이상의 코어(core, 미도시) 및 그래픽 처리부(미도시) 및/또는 다른 구성 요소와 신호를 송수 신하는 연결 통로(예를 들어, 버스(bus) 등)를 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 본 발명과 관련하여 설 명된 방법을 수행한다. 한편, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저장하는 램 (RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포함할 수 있다. 또한, 프 로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리에는 프로세서의 처리 및 제어를 위한 프로그램들(하나 이상의 인스트럭션들)을 저장할 수 있다. 저장부 에 저장된 프로그램들은 기능에 따라 복수 개의 모듈들로 구분될 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 상술한 예를 참조하여 본 발명을 상세하게 설명하였지만, 당업자라면 본 발명의 범위를 벗어나지 않으면서도 본 예들에 대한 개조, 변경 및 변형을 가할 수 있다. 요컨대 본 발명이 의도하는 효과를 달성하기 위해 도면에 도 시된 모든 기능 블록을 별도로 포함하거나 도면에 도시된 모든 순서를 도시된 순서 그대로 따라야만 하는 것은 아니며, 그렇지 않더라도 얼마든지 청구항에 기재된 본 발명의 기술적 범위에 속할 수 있음에 주의한다. 부호의 설명100 : 서버 110 : 메모리 120 : 통신부 130 : 프로세서 140 : 환경 설정부 150 : 딥러닝 분석부 160 : 피드백 제공부 200 : 사용자 단말"}
{"patent_id": "10-2023-0035316", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 심폐소생술 교육 시스템의 구성을 도시한 도면이다. 도 2는 본 발명의 실시 예에 따른 사용자 단말의 구성을 도시하는 도면이다. 도 3은 본 발명의 실시 예에 따른 서버의 구성을 도시한 도면이다. 도 4는 본 발명의 실시 예에 따른 서버의 딥러닝 분석부의 구성을 도시한 도면이다. 도 5는 본 발명의 실시 예에 따른 심폐소생술 교육 과정의 순서를 도시한 도면이다. 도 6은 본 발명의 실시 예에 따른 심폐소생술 동작의 촬영 예시를 도시한 도면이다. 도 7은 본 발명의 실시 예에 따른 심폐소생술 기본 자세를 설명하기 위한 도면이다."}
