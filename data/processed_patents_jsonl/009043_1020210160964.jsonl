{"patent_id": "10-2021-0160964", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0076877", "출원번호": "10-2021-0160964", "발명의 명칭": "불변 모멘트와 머신러닝 융합기반 객체 인식엔진을 탑재한 임베디드용 자동 어노테이션 시스", "출원인": "(주)다울디엔에스", "발명자": "장용석"}}
{"patent_id": "10-2021-0160964", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "어노테이션 시스템에 의해 수행되는 어노테이션 방법에 있어서,임베디드용 보드에 탑재된 객체 인식을 위한 객체 인식 및 자동 어노테이션 엔진과 임베디드용 카메라의 환경정보가 세팅되는 단계;상기 객체 인식 및 자동 어노테이션 엔진에서, 상기 세팅된 환경 정보에 따라 임베디드용 카메라를 통해 입력되는 영상 정보로부터 객체 정보를 탐지하는 단계;상기 객체 인식 및 자동 어노테이션 엔진에서, 객체 인식을 위한 학습 모델을 이용하여 상기 탐지된 객체 정보로부터 객체를 인식하는 단계; 및상기 객체 인식 및 자동 어노테이션 엔진에서, 상기 인식된 객체를 자동으로 어노테이션하는 단계를 포함하고,상기 객체 인식을 위한 학습 모델은,영상 정보로부터 탐지된 객체 정보에 대하여 생성된 불변 모멘트와 상기 탐지된 객체 정보를 합성(Mix)한 데이터 셋을 이용하여 객체가 인식되도록 학습된 것을 특징으로 하는 어노테이션 방법."}
{"patent_id": "10-2021-0160964", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 객체 인식을 위한 학습 모델은, 임베디드용 카메라를 통해 입력되는 산업 현장의 영상 정보가 캡쳐되는 단계;상기 캡쳐된 산업 현장의 영상 정보에 대한 불변 모멘트가 생성되는 단계;상기 생성된 불변 모멘트와 상기 캡쳐된 산업 현장의 영상 정보가 합성됨에 따라 정방 행렬 기반의 데이터 셋이생성되는 단계;상기 생성된 정방 행렬 기반의 데이터 셋이 상기 객체 인식을 위한 학습 모델에 입력되어 학습이 진행되는단계;상기 진행된 학습을 통해 상기 생성된 정방 행렬 기반의 데이터 셋으로부터 객체가 인식되는 단계 를 통해 구축된 것을 특징으로 하는 어노테이션 방법."}
{"patent_id": "10-2021-0160964", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 객체 인식을 위한 학습 모델은, 상기 캡쳐된 영상 정보로부터 객체 정보가 탐지되는 단계; 상기 탐지된 객체 정보를 포함하는 영역에 대한 불변 모멘트가 생성되는 단계; 상기 탐지된 객체 정보를 포함하는 영역이 객체 인식을 위한 학습 모델에 입력 데이터로 입력되기 전에, 전처리과정이 수행되는 단계; 및상기 생성된 불변 모멘트와 상기 전처리 과정이 수행된 객체 정보를 포함하는 영역이 기 설정된 비율로 합성되는 단계 를 더 포함하고, 공개특허 10-2023-0076877-3-상기 구축된 객체 인식을 위한 학습 모델을 구성하는 하이퍼 파라미터가 사용자의 입력에 의하여 조정되는 것을특징으로 하는 어노테이션 방법."}
{"patent_id": "10-2021-0160964", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 객체 정보를 탐지하는 단계는,임베디드용 카메라를 통해 입력되는 산업 현장의 영상 정보를 캡쳐하고, 객체 탐지 알고리즘을 이용하여 상기캡쳐된 산업 현장의 영상 정보로부터 객체 정보를 탐지하는 단계 를 포함하고, 상기 객체 탐지 알고리즘은, YOLO DarkNet을 포함하는 것을 특징으로 하는 어노테이션 방법."}
{"patent_id": "10-2021-0160964", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 자동으로 어노테이션하는 단계는, 상기 인식된 객체에 대하여 자동으로 어노테이션함에 따라 MSCOCO 타입(Type) 기반의 어노테이션 데이터를 생성하고, 상기 생성된 MSCOCO 타입(Type) 기반의 어노테이션 데이터 및 캡쳐된 영상을 로컬 저장소 또는 네트워크전송 모듈을 통해 원격 저장소로 전달하는 단계를 포함하는 어노테이션 방법."}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "불변 모멘트와 머신러닝 융합기반 객체 인식엔진을 탑재한 임베디드용 자동 어노테이션 시스템 및 방법이 개시된 다. 일 실시예에 따른 어노테이션 시스템에 의해 수행되는 어노테이션 방법은, 임베디드용 보드에 탑재된 객체 인식을 위한 객체 인식 및 자동 어노테이션 엔진과 임베디드용 카메라의 환경 정보가 세팅되는 단계; 상기 객체 (뒷면에 계속)"}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 어노테이션 기술에 관한 것이다."}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "머신러닝은 얼굴 인식, 전신 인식, 자세 인식, 음성 인식, 객체 인식, 데이터 마이닝 등 다양한 인식에 적용되 고 있다. 특히, 영상으로부터 특정 객체를 인식하는 객체 인식과 학습 네트워크를 접목시키는 연구는 다양한 방식으로 활발히 이루어지고 있다. 머신러닝을 학습하기 위해서는 어노테이션(annotation) 작업을 수행하고, 어노테이션된 이미지를 이용하여 학습 을 진행하는데, 컴퓨터를 이용하여 학습에 사용되는 이미지를 로딩하고, 로딩된 이미지에서 마우스 등으로 블록 을 지정하여 지정된 블록에 대한 어노테이션을 생성한다. 하지만, 종래 기술은 어노테이션을 생성하기 위한 해당 사용자가 모든 이미지들 각각에 대한 어노테이션 수작업 을 수행하기 때문에 시간과 비용이 많이 들고, 데이터를 수집하기에도 어렵다는 문제점이 존재한다."}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "불변 모멘트와 머신러닝 융합기반 객체 인식 엔진을 탑재한 임베디드용 자동 어노테이션 시스템 및 방법을 제공 할 수 있다."}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "어노테이션 시스템에 의해 수행되는 어노테이션 방법은, 임베디드용 보드에 탑재된 객체 인식을 위한 객체 인식 및 자동 어노테이션 엔진과 임베디드용 카메라의 환경 정보가 세팅되는 단계; 상기 객체 인식 및 자동 어노테이 션 엔진에서, 상기 세팅된 환경 정보에 따라 임베디드용 카메라를 통해 입력되는 영상 정보로부터 객체 정보를 탐지하는 단계; 상기 객체 인식 및 자동 어노테이션 엔진에서, 객체 인식을 위한 학습 모델을 이용하여 상기 탐 지된 객체 정보로부터 객체를 인식하는 단계; 및 상기 객체 인식 및 자동 어노테이션 엔진에서, 상기 인식된 객 체를 자동으로 어노테이션하는 단계를 포함하고, 상기 객체 인식을 위한 학습 모델은, 영상 정보로부터 탐지된 객체 정보에 대하여 생성된 불변 모멘트와 상기 탐지된 객체 정보를 합성(Mix)한 데이터 셋을 이용하여 객체가 인식되도록 학습된 것일 수 있다. 상기 객체 인식을 위한 학습 모델은, 임베디드용 카메라를 통해 입력되는 산업 현장의 영상 정보가 캡쳐되는 단 계; 상기 캡쳐된 산업 현장의 영상 정보에 대한 불변 모멘트가 생성되는 단계; 상기 생성된 불변 모멘트와 상기 캡쳐된 산업 현장의 영상 정보가 합성됨에 따라 정방 행렬 기반의 데이터 셋이 생성되는 단계; 상기 생성된 정 방 행렬 기반의 데이터 셋이 상기 객체 인식을 위한 학습 모델에 입력되어 학습이 진행되는 단계; 상기 진행된 학습을 통해 상기 생성된 정방 행렬 기반의 데이터 셋으로부터 객체가 인식되는 단계를 통해 구축된 것일 수 있 다. 상기 객체 인식을 위한 학습 모델은, 상기 캡쳐된 영상 정보로부터 객체 정보가 탐지되는 단계; 상기 탐지된 객 체 정보를 포함하는 영역에 대한 불변 모멘트가 생성되는 단계; 상기 탐지된 객체 정보를 포함하는 영역이 객체 인식을 위한 학습 모델에 입력 데이터로 입력되기 전에, 전처리 과정이 수행되는 단계; 및 상기 생성된 불변 모 멘트와 상기 전처리 과정이 수행된 객체 정보를 포함하는 영역이 기 설정된 비율로 합성되는 단계를 더 포함하 고, 상기 구축된 객체 인식을 위한 학습 모델을 구성하는 하이퍼 파라미터가 사용자의 입력에 의하여 조정될 수 있다. 상기 객체 정보를 탐지하는 단계는, 임베디드용 카메라를 통해 입력되는 산업 현장의 영상 정보를 캡쳐하고, 객 체 탐지 알고리즘을 이용하여 상기 캡쳐된 산업 현장의 영상 정보로부터 객체 정보를 탐지하는 단계를 포함하고, 상기 객체 탐지 알고리즘은, YOLO DarkNet을 포함할 수 있다. 상기 자동으로 어노테이션하는 단계는, 상기 인식된 객체에 대하여 자동으로 어노테이션함에 따라 MSCOCO 타입 (Type) 기반의 어노테이션 데이터를 생성하고, 상기 생성된 MSCOCO 타입(Type) 기반의 어노테이션 데이터 및 캡 쳐된 영상을 로컬 저장소 또는 네트워크 전송 모듈을 통해 원격 저장소로 전달하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "경량화된 임베디드용 인공지능 모델을 이용하여 영상 정보에 대한 어노테이션을 자동화함에 따라 사용자의 수작 업의 비율을 획기적으로 줄이고, 학습 데이터의 생성 비용을 감소시킬 수 있다."}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 도 1은 일 실시예에 따른 어노테이션 시스템의 개괄적인 동작을 설명하기 위한 도면이다. 임베디드용 보드에 임베디드용 카메라가 부착될 수 있다. 임베디드용 카메라가 부착된 임베디드용 보드에 객체 인식 및 자동 어노테이션 엔진이 탑재될 수 있다. 객체 인식 및 자동 어노테이션 엔진을 이용한 어노테이션 자 동화를 통해 학습 데이터를 생성할 수 있다. 예를 들면, 임베디드용 보드로는 Google Coral이 사용될 수 있다. 어노테이션 시스템은 임베디드용 카메라, 임베디드용 카메라가 부착된 임베디드용 보드, 및 상기 임베디드용 보 드에 탑재된 객체 인식 및 자동 어노테이션 엔진을 포함할 수 있다. 어노테이션 시스템은 객체 인식 및 자동 어노테이션 엔진을 이용하여 불변 모멘트와 머신러닝 융합기반 객체 인식을 통해 자동 어노테이션을 수행할 수 있다. 어노테이션 시스템은 임베디드용 보드에 부착된 임베디드용 카메라를 이용하여 영상 정보를 캡쳐할 수 있고, 임베디드용 보드에 탑재된 객체 인식 및 자동 어노테이션 엔진을 이용하여 캡쳐된 영상 정보에 대한 객체 정보를 탐지하고, 탐지된 객체 정보로부터 객체를 인식하고, 인식된 객체에 자동으로 어노테이션할 수 있다. 예를 들면, 임베디드용 카메라는 적어도 하나의 카메라로 구성될 수 있으며, 특정 각도 또는 360도 범위(상, 하, 좌, 우, 앞, 뒤)의 촬영이 가능할 수 있다. 이러한 임베디드용 카메라는 다양한 환경에서 촬영이 가능할 수 있다. 실시예에서는 설명의 편의를 위하여 산업 현장에서 촬영되는 산업 안전 인공지능 인식용 테스트 영상 정보를 이용하여 어노테이션을 수행하는 동작에 대하여 예를 들어 설명하기로 한다. 어노테이션 시스템은 임베디드용 카메라에서 촬영되는 산업 현장의 산업 안전 인공지능 인식용 테스트 영상을 획득할 수 있다. 예를 들면, 산업 현장에 존재하는 지게차에 카메라가 설치되고, 지게차에 설치된 카메라를 통 해 산업 현장의 산업 안전 인공지능 인식용 테스트 영상이 촬영될 수 있다. 어노테이션 시스템은 획득된 산업 안전 인공지능 인식용 테스트 영상 정보를 임베디드용 보드를 통해 캡쳐할 수 있고, 캡쳐된 산업 안전 인공지능 인식용 테스트 영상 정보로부터 객체 탐지 알고리즘(예를 들면, YOLO DarkNet)을 이용하여 객체 정보를 탐지할 수 있다. 어노테이션 시스템은 탐지된 객체 정보를 포함하는 산업 안전 인공지능 인식용 테스트 영상 정보를 객체 인식을 위한 학습 모델에 입력받을 수 있다. 어노테이션 시스템은 객체 인식을 위한 학습 모델을 이용하여 탐지된 객 체 정보를 포함하는 산업 안전 인공지능 인식용 테스트 영상 정보로부터 객체를 인식하여 어노테이션할 수 있다. 다시 말해서, 어노테이션 시스템은 탐지된 객체 정보를 포함하는 산업 안전 인공지능 인식용 테스트 영 상 정보로부터 객체를 인식하고, 인식된 객체에 MSCOCO 타입(Type)의 어노테이션을 생성할 수 있다. 또는, 어노테이션 시스템은 탐지된 객체 정보를 객체 인식을 위한 학습 모델에 입력받을 수 있다. 어노테이션 시스템은 객체 인식을 위한 학습 모델을 이용하여 탐지된 객체 정보로부터 객체를 인식하여 어노테이션할 수 있 다. 다시 말해서, 어노테이션 시스템은 탐지된 객체 정보로부터 객체를 인식하고, 인식된 객체에 MSCOCO 타입 (Type)의 어노테이션을 생성할 수 있다. 어노테이션 시스템은 인식된 객체의 영역에 대한 좌표 정보를 획득할 수 있고, 인식된 객체의 영역에 어노테이 션할 수 있다. 어노테이션 시스템은 인식된 객체의 영역에 대하여 사람(person), 얼굴(face), 상체(upper body), 하체(lower body), 포크 리프트(Forklift), 배터리 차(Battery car) 등을 포함하는 경계 박스(Bound Box) 타입의 어노테이션을 생성할 수 있다. 보다 상세하게는, 예를 들면, 어노테이션 시스템은 인식된 객체에 대한 식별 정보를 1차적으로 어노테이션한 다 음, 인식된 객체에 대한 상세 정보를 2차적으로 어노테이션할 수 있다. 어노테이션 시스템은 인식된 객체가 사 람일 경우, 인식된 객체에 대하여 1차적으로 사람이라고 어노테이션할 수 있고, 사람에 대한 상세 정보(예를 들 면, 상체, 하체 등)를 2차적으로 어노테이션할 수 있다. 또는, 어노테이션 시스템은 인식된 객체가 물체일 경 우, 인식된 객체에 대하여 지게차라고 1차적으로 어노테이션할 수 있고, 지게차에 대한 상세 정보(예를 들면, 바퀴, 운전대 등)를 2차적으로 어노테이션할 수 있다. 또한, 어노테이션 시스템에서 경계 박스(Bound Box) 타 입의 어노테이션이 생성된 후, 다시 사용자에 의한 확인 과정을 통해 어노테이션이 수정될 수 있다. 도 2는 일 실시예에 있어서, 객체 인식을 위한 학습 동작을 설명하기 위한 도면이다. 객체 인식 및 자동 어노테이션 엔진은 객체 인식을 위한 학습 모델을 이용하여 객체를 인식할 수 있다. 객체 인식을 위한 학습 모델은, 영상 정보로부터 탐지된 객체 정보에 대하여 생성된 불변 모멘트와 탐지된 객체 정보 를 합성(Mix)한 데이터 셋을 이용하여 객체가 인식되도록 학습된 것일 수 있다. 상세하게는, 임베디드용 카메라를 통해 입력되는 산업 현장의 영상 정보가 캡쳐될 수 있다. 이때, 캡쳐된 영상 정보로부터 객체 정보가 탐지될 수 있고, 탐지된 객체 정보를 포함하는 영역이 객체 인식을 위한 학습 모델에 입력 데이터로 입력되기 전에, 다운 샘플링 및 정규화 등의 전처리 과정이 수행될 수 있다. 예를 들면, 탐지된객체 정보를 포함하는 영역의 사이즈가 기 설정된 비율(예를 들면, 7:6의 비율)로 조정될 수 있다. 캡쳐된 산업 현장의 영상 정보에 대한 불변 모멘트가 생성될 수 있다. 이때, 캡쳐된 산업 현장의 영상 정보로 부터 탐지된 객체 정보의 영역에 대한 불변 모멘트가 생성될 수 있다. 불변 모멘트(invariant moment)란 영상 내에 존재하는 물체의 형태나 질감 같은 가시적인 특징을 표현해 주는 방법 중 하나이다. 불변 모멘트는 영상 내의 객체의 중심으로부터 퍼진 정도, 회전 정도, 대칭 정도, 뒤틀림 정도 등을 수학식으로 표현한 것이다. 동 일한 형태의 영상에 대해서는 크기 변화나 회전 등에 무관하게 일정한 크기의 값을 나타내며, 다른 형태의 영상 에 대해서는 상이한 갓을 나타낸다. 이에, 영상 정보로부터 특징 벡터를 추출하기 위하여 이진 모양 영상에 대 한 불면 모멘트 셋의 계수(예를 들면, 7차원)를 특징 벡터로 사용할 수 있다. 일례로, 캡쳐된 산업 현장의 영상 정보에 대하여 비특허문헌 1<장용석 외 4명, \"모양 영상 검색을 위한 효율적 인 색인구조와 검색방법\", 정보과학회, 1999>에 개시된 불변 모멘트의 생성 동작을 참고하여 7차원 벡터 형태의 불변 모멘트가 생성될 수 있다. 이때, 생성된 불변 모멘트에 캡쳐된 영상 정보와의 합성을 위한 가중치가 부여 될 수 있다. 생성된 불변 모멘트와 캡쳐된 산업 현장의 영상 정보가 합성됨에 따라 정방 행렬 기반의 데이터 셋이 생성될 수 있다. 다시 말해서, 캡쳐된 산업 현장의 영상 정보에 불변 모멘트가 부가된(덧붙여진) 형태로 데이터 셋이 생 성될 수 있다. 생성된 불변 모멘트와 다운 샘플링 및 정규화의 과정이 수행된 영상 정보가 기 설정된 비율로 합성될 수 있다. 예를 들면, 다운 샘플링 및 정규화의 과정이 수행된 영상 정보가 7:6 비율(M:N)로 합성되고, 생성된 불변 모멘트에 대하여 7:1 비율로 합성됨에 따라 7:7(1:1) 정방 행렬 기반의 데이터 셋이 생성될 수 있 다. 생성된 정방 행렬 기반의 데이터 셋이 객체 인식을 위한 학습 모델에 입력되어 학습이 진행될 수 있다. 예를 들면, 객체 인식을 위한 학습 모델에 SVM, Decision Tree, K-Nearest Neighbors, Logistic Regression, Random Forest, DNN (예를 들면, CNN(MTCNN, DCUnet 등), RNN(LSTM, DCCRN, FullSubNet 등)) 중 어느 하나의 학습 네 트워크가 구성될 수 있고, 구성된 어느 하나의 학습 네트워크에 기반하여 정방 행령 기반의 데이터 셋을 통해 객체 인식을 위한 학습이 진행될 수 있다. 이때, 학습 네트워크는 상기 언급한 학습 네트워크 이외의 다양한 네트워크가 적용될 수 있다. 다시 말해서, 추후에 출시되는 최신의 네트워크도 적용이 가능하다. 진행된 학습을 통해 생성된 정방 행렬 기반의 데이터 셋으로부터 객체가 인식될 수 있다. 도 2에서 설명한 전 체 과정이 반복적으로 수행됨에 따라 객체 인식을 위한 학습 모델이 구축될 수 있다. 도 3을 참고하면, 객체 인식을 위한 학습 모델을 경량화하는 동작을 설명하기 위한 도면이다. 도 2와 같이 구 축된 객체 인식을 위한 학습 모델의 하이퍼 파라미터 조정(튜닝)이 수행될 수 있다. 일례로, 객체 인식을 위한 학습 모델이 모델링될 때, 사용자의 입력에 의하여 각각의 하이퍼 파라미터 값이 조정될 수 있다. 하이퍼 파라 미터를 조정하는 유저 인터페이스가 제공될 수 있고, 제공된 유저 인터페이스를 이용한 사용자에 입력 정보에 의하여 하이퍼 파라미터가 조정될 수 있다. 예를 들면, 객체 인식을 위한 학습 모델에 드랍아웃 비율, 학습율 비율 등을 포함하는 하이퍼 파라미터(값)가 조정될 수 있다. 사용자에 의하여 조정된 하이퍼 파라미터에 따라 구축된 객체 인식을 위한 학습 모델이 학습 및 재학습될 수 있고, 학습 및 재학습된 객체 인식을 위한 학습 모 델을 이용하여 객체 인식이 수행될 수 있다. 이러한 하이퍼 파라미터 조정을 통해 임베디드용 보드에 탑재될 임베디드용 인공지능 모델을 최적화할 수 있다. 이에, 경량화된 임베디드용 인공지능 모델이 구축될 수 있다. 도 4는 일 실시예에 따른 어노테이션 시스템의 구성을 설명하기 위한 블록도이다. 어노테이션 시스템은 영상 캡쳐 모듈, 객체 인식 및 자동 어노테이션 엔진, 로컬 저장 모듈 및 네트워크 전송 모듈을 포함할 수 있다. 영상 캡쳐 모듈은 임베디드용 카메라를 통해 촬영되는 산업 현장의 영상 정보를 캡쳐할 수 있다. 예를 들 면, 영상 캡쳐 모듈는 기 설정된 시간(예를 들면, 분 단위, 시간 단위 등)마다 주기적으로 영상 정보를 캡 쳐할 수 있다. 또는, 영상 캡쳐 모듈는 비주기적으로 영상 정보를 캡쳐할 수 있다. 또는, 영상 캡쳐 모 듈는 실시간으로 영상 정보를 캡쳐할 수 있다. 객체 인식 및 자동 어노테이션 엔진은 캡쳐된 산업 현장의 영상 정보로부터 객체 정보를 탐지할 수 있다. 이때, 객체 인식 및 자동 어노테이션 엔진은 객체 탐지 알고리즘으로 YOLO DarkNet를 사용할 수 있다. 그 러나, YOLO DarkNet은 객체 탐지 알고리즘의 예시일 뿐, 이에 한정되는 것은 아니다. 객체 인식 및 자동 어노테이션 엔진은 객체 인식을 위한 학습 모델을 이용하여 탐지된 객체 정보로부터 객 체를 인식할 수 있다. 객체 인식을 위한 학습 모델에 대한 설명은 도 2에서 설명한 바, 생략하기로 한다. 객 체 인식 및 자동 어노테이션 엔진은 인식된 객체에 대하여 자동으로 어노테이션함에 따라 어노테이션 데이 터를 생성하고, 어노테이션 데이터 및 캡쳐된 영상을 획득할 수 있다. 로컬 저장 모듈는 캡쳐된 영상 및 어노테이션 데이터를 로컬에 저장할 수 있다. 이때, 로컬은 임베디드 기반의 전자 기기일 수 있으며, 로컬에 새로운 영상 및 어노테이션 데이터가 저장될 때마다 캡쳐된 영상 및 어 노테이션 데이터가 업데이트될 수 있다. 네트워크 전송 모듈은 캡쳐된 영상 및 어노테이션 데이터를 원격 저장소에 전달할 수 있다. 예를 들면, 네트워크 전송 모듈는 캡쳐된 영상 및 어노테이션 데이터를 무선 통신 또는 유선 통신을 통해 원격 저장소 에 전달할 수 있다. 원격 저장소는 네트워크 전송 모듈로부터 전달된 캡쳐된 영상 및 어노테이션 데이터 를 저장할 수 있다. 도 5는 일 실시예에 있어서, 불변 모멘트와 머신러닝 융합기반 객체 인식엔진을 탑재한 임베디드용 자동 어노테 이션 동작을 설명하기 위한 도면이다. 도 5에서는 사용자, 임베디드용 카메라, 임베디드용 보드, 객체 인식 및 자동 어노테이션 엔진 및 저장소 간 데이터 송수신 동작을 설명하기로 한다. 사용자로부터 임베디드용 보드에 구동을 위한 환경 세팅 및 구동 시작이 요청될 수 있다. 다시 말해 서, 사용자로부터 임베디드 보드에 실행 명령이 입력될 수 있다. 사용자로부터 입력된 실행 명 령에 기초하여 세팅된 환경 정보에 따라 임베디드용 보드에서 객체 인식을 위한 객체 인식 및 자동 어노테 이션 엔진과 임베디드용 카메라의 환경이 세팅될 수 있다. 임베디드용 보드에서 객체 인식을 위한 객체 인식 및 자동 어노테이션 엔진과 임베디드용 카메라의 환경이 세팅됨에 따라 임베디드용 카메라 및 객체 인식 및 자동 어노테이션 엔진이 초기화될 수 있다. 사용자로부터 산업 현장 영상이 입력될 수 있다. 임베디드용 카메라가 부착된 임베디드용 보드(50 3)에서 산업 현장 영상이 캡쳐될 수 있다. 객체 인식 및 자동 어노테이션 엔진은 임베디드용 보드로부터 캡쳐된 산업 현장 영상을 이용하여 YOLO DarkNet기반으로 객체 정보를 탐지할 수 있다. 객체 인식 및 자동 어노테이션 엔진에서 탐지된 객체 정보에 대하여 불변 모멘트와 머신러닝 융합기반 객체 인식이 수행될 수 있다. 객체 인식 및 자동 어노테이션 엔진은 탐지된 객체 정보로부터 객체가 인식될 경우, 인식된 객체를 MSCOCO 타입으로 자동 어노테이션할 수 있다. 자동 어노테이션을 수행함에 따라 캡쳐된 영상 및 어노테이션 데이터 (MSCOCO 타입의 어노테이션 데이터)를 획득할 수 있다. 다시 말해서, 캡쳐된 영상과 레이블링된 데이터가 획득 될 수 있다. 이에, 객체 인식을 위한 새로운 데이터 셋이 생성될 수 있다. 객체 인식 및 자동 어노테이션 엔진은 캡쳐된 영상 및 어노테이션 데이터를 저장소에 저장할 수 있다. 객체 인식 및 자동 어노테이션 엔진은 캡쳐된 영상 및 어노테이션 데이터를 로컬에 저장하거나 네 트워크를 통해 원격 저장소로 전달할 수 있다. 객체 인식 및 자동 어노테이션 엔진은 탐지된 객체 정보로부터 객체가 인식되지 않을 경우, 임베디드용 보 드를 통해 산업 현장 영상을 다시 캡쳐할 수 있다. 예를 들면, 다시 캡쳐된 산업 현장 영상은 영상을 구 성하는 복수 개의 프레임 중 이전에 캡쳐된 영상과 동일한 프레임 또는 다른 영상의 프레임일 수 있다. 상기 설명한 임베디드용 보드의 동작은 사용자의 중지 명령이 있을 때까지 반복될 수 있다. 이때, 사용자 로부터 자동 어노테이션 구동 중지 명령이 입력될 수 있다. 자동 어노테이션 구동 중지 명령은 캡쳐링 중 지, 객체 인식 및 자동 어노테이션 엔진 셧다운, 저장소 셧다운을 포함하는 명령을 포함할 수 있다. 예를 들면, 임베디드용 보드에 캡쳐링 중지, 객체 인식 및 자동 어노테이션 엔진 셧다운, 저장소 셧다운 명령 중 어느 하나의 명령이 입력될 수 있다. 상기 어느 하나의 명령이 입력될 경우, 임베디드용 보드 전체의 구동을 중단시킬 수 있고, 또는 상기 명령에 대응하는 구성에 대해서만 구동을 중단시킬 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2021-0160964", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2021-0160964", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 어노테이션 시스템의 개괄적인 동작을 설명하기 위한 도면이다. 도 2는 일 실시예에 있어서, 객체 인식을 위한 학습 동작을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 객체 인식을 위한 학습 모델을 경량화하는 동작을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 어노테이션 시스템의 구성을 설명하기 위한 블록도이다. 도 5는 일 실시예에 있어서, 불변 모멘트와 머신러닝 융합기반 객체 인식엔진을 탑재한 임베디드용 자동 어노테 이션 동작을 설명하기 위한 도면이다."}
