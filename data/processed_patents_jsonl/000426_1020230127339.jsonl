{"patent_id": "10-2023-0127339", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0043970", "출원번호": "10-2023-0127339", "발명의 명칭": "인공지능 모델 학습 장치 및 그 방법", "출원인": "주식회사 딜리셔스", "발명자": "송철환"}}
{"patent_id": "10-2023-0127339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 속성(attribute)들과 관련된 이미지 정보로부터 각 속성에 대응하는 정보를 추출하는 인공지능 모델을학습하는 장치에 있어서,이미지 정보 및 속성 정보를 포함하는 학습 정보를 수신하는 수신부;상기 수신된 이미지 정보 및 상기 수신된 속성 정보를 임베딩하는 임베딩부;상기 임베딩된 이미지 정보 및 상기 임베딩된 속성 정보 중 적어도 하나를 인코딩하는 인코딩부; 및상기 인코딩된 이미지 정보 및 상기 인코딩된 속성 정보 중 적어도 하나를 기반으로 손실을 계산하는 손실함수계산부; 를 포함하고,상기 인코딩부는 복수의 인코딩 블록들을 포함하고, 상기 임베딩된 이미지 정보는 상기 복수의 인코딩 블록들을순차적으로 통과하며 인코딩되고, 상기 임베딩된 속성 정보는 상기 복수의 인코딩 블록들 중 어느 하나만을 통과하며 인코딩되는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0127339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 복수의 인코딩 블록들은 서로 직렬(serially)로 연결되고,상기 임베딩된 속성 정보를 인코딩하는 인코딩 블록은 상기 직렬로 연결된 복수의 인코딩 블록들 중 마지막 인코딩 블록인,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0127339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 임베딩부는,상기 수신된 이미지 정보를 임베딩하는 제1 임베딩부 및 상기 수신된 속성 정보를 임베딩하는 제2 임베딩부를포함하고,상기 제1 임베딩부는 상기 이미지 정보 보다 작은 이미지 패치(patch) 단위로 임베딩하고,상기 제2 임베딩부는 상기 수신된 속성 정보를 원-핫 벡터(one-hot vector)로 변환하여 임베딩하거나, CSN(Conditional Similarity Networks) 모델에 기반하여 임베딩하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0127339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 복수의 인코딩 블록들 중 상기 마지막 인코딩 블록을 제외한 인코딩 블록들 각각은 비전 트랜스포머(Vision Transformer, ViT) 아키텍처의 셀프 어텐션(Self Attention) 모델에 기반하여 인코딩 하는,인공지능 모델 학습 장치.공개특허 10-2025-0043970-3-청구항 5 제3 항에 있어서,상기 마지막 인코딩 블록은 컨디셔널 크로스 어텐션(Conditional Cross Attention) 모델에 기반하여 인코딩 하고,상기 컨디셔널 크로스 어텐션 모델은 함수로 표현되고, 상기 함수는,으로 표현되고, 상기 는 상기 제2 임베딩부에 의해 임베딩된 c번째 속성 정보에 관한 쿼리(query) 값을 나타내고, 상기 는 i번째 이미지 패치에 관한 키(Key) 값을 나타내고, 상기 는 i번째 이미지 패치에 관한밸류(Value) 값을 나타내고, 상기 는 히든 스페이스(hidden space)의 차원수를 나타내는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0127339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 손실함수 계산부는 트리플렛 로스(Triplet Loss) 모델에 기반하여 상기 손실을 계산하고,상기 트리플렛 로스 모델은 함수로 표현되고, 상기 함수는,으로 표현되고, 상기 는 c번째 속성 정보에 관한 손실을 나타내고, 상기 는c번째 속성 정보에 관한 앵커(anchor)를 나타내는 이미지 정보이고, 상기 는 상기 앵커와 동일한 클래스(class)를 가지는 이미지 정보이고, 상기 는 상기 앵커와 다른 클래스를 가지는 이미지 정보이고, 상기는 상기 와 상기 간의 코사인 거리(cosine distance)를 나타내고, 상기는 상기 와 상기 간의 코사인 거리를 나타내고, 상기 은 기 설정된 마진(margin)을 나타내는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0127339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "복수의 속성(attribute)들과 관련된 이미지 정보로부터 각 속성에 대응하는 정보를 추출하는 인공지능 모델을학습하는 방법에 있어서,이미지 정보 및 속성 정보를 포함하는 학습 정보를 수신하는 단계;상기 수신된 이미지 정보 및 상기 수신된 속성 정보를 임베딩하는 단계;공개특허 10-2025-0043970-4-상기 임베딩된 이미지 정보 및 상기 임베딩된 속성 정보를 인코딩하는 단계; 및상기 인코딩된 이미지 정보 및 상기 인코딩된 속성 정보를 기반으로 손실을 계산하는 단계; 를 포함하고,인코딩부는 복수의 인코딩 블록들을 포함하고, 상기 임베딩된 이미지 정보는 상기 복수의 인코딩 블록들을 순차적으로 통과하며 인코딩되고, 상기 임베딩된 속성 정보는 상기 복수의 인코딩 블록들 중 어느 하나만을 통과하며 인코딩되는,인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 이미지 정보 및 속성 정보를 포함하는 학습 정보를 수신하는 수신부, 수신된 이미지 정보 및 수신된 속성 정보를 임베딩하는 임베딩부, 임베딩된 이미지 정보 및 임베딩된 속성 정보 중 적어도 하나를 인코딩하는 인코딩부 및 인코딩된 이미지 정보 및 인코딩된 속성 정보 중 적어도 하나를 기반으로 손실을 계산하는 손실함수 계산부를 포함하고, 인코딩부는 복수의 인코딩 블록들을 포함하고, 임베딩된 이미지 정보는 복수의 인코딩 블록 들을 순차적으로 통과하며 인코딩되고, 임베딩된 속성 정보는 복수의 인코딩 블록들 중 어느 하나만을 통과하며 인코딩되는, 복수의 속성(attribute)들과 관련된 이미지 정보로부터 각 속성에 대응하는 정보를 추출하는 인공지 능 모델을 학습하는 장치에 관한 것이다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델 학습 장치 및 그 방법에 관한 것이다. 구체적으로 복수의 속성(attribute)들과 관련된 이미지 정보로부터 각 속성에 대응하는 정보를 추출하는 인공지능 모델을 학습하는 장치 및 그 방법에 관한 것 이다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 비전(Vision) 분야의 인공지능 모델은 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출하기 위해서는 속성 별로 네트워크를 활용해야 한다. 예를 들어 자동차를 나타내는 이미지에서 차량 종류 속성, 차량 색 속성 및 차량 사이즈 속성을 파악하기 위해서는 총 3개의 뉴럴 네트워크를 활용해야 한다. 다만 이와 같은 경우, 속성이 증가할수록 연산량이 증가하고 전체적인 인공지능 모델의 학습에 비효율을 초래하 는 문제점이 발생한다. 또한 위 문제점을 해결하기 위해 단일 네트워크를 사용하는 경우에도, CNN (Convolutional neural network) 기 반의 임베딩(embebbing) 또는 CNN 기반의 어텐션(Attention) 모델을 사용하는 경우에도, 상술한 비효율을 효과 적으로 개선하지 못하는 문제점이 여전히 존재한다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 단일 네트워크를 사용하여, 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출 할 수 있는 인공지능 모델 학습 장치 또는 방법을 제공하는 것을 과제로 한다. 또한 본 개시는 비전 트랜스포머(ViT)의 셀프 어텐션(Self Attention) 모델에 기반하여, 여러 속성을 가지는 개 체의 이미지에서 각 속성에 대응하는 정보를 추출할 수 있는 인공지능 모델 학습 장치 또는 방법을 제공하는 것 을 과제로 한다. 다만, 기술적 과제는 상술한 기술적 과제들로 한정되는 것은 아니며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시에 따른 동물용 의료영상 출력 장치는 이미지 정보 및 속성 정보를 포함하는 학습 정보를 수신하는 수신 부, 수신된 이미지 정보 및 수신된 속성 정보를 임베딩하는 임베딩부 임베딩된 이미지 정보 및 임베딩된 속성 정보 중 적어도 하나를 인코딩하는 인코딩부 및 인코딩된 이미지 정보 및 인코딩된 속성 정보 중 적어도 하나를 기반으로 손실을 계산하는 손실함수 계산부를 포함하고, 인코딩부는 복수의 인코딩 블록들을 포함하고, 임베딩 된 이미지 정보는 복수의 인코딩 블록들을 순차적으로 통과하며 인코딩되고, 임베딩된 속성 정보는 복수의 인코 딩 블록들 중 어느 하나만을 통과하며 인코딩될 수 있다. 본 개시에 따른 복수의 인코딩 블록들은 서로 직렬(serially)로 연결되고, 임베딩된 속성 정보를 인코딩하는 인 코딩 블록은 직렬로 연결된 복수의 인코딩 블록들 중 마지막 인코딩 블록일 수 있다. 본 개시에 따른 임베딩부는, 수신된 이미지 정보를 임베딩하는 제1 임베딩부 및 수신된 속성 정보를 임베딩하는 제2 임베딩부를 포함하고, 제1 임베딩부는 이미지 정보 보다 작은 이미지 패치(patch) 단위로 임베딩하고, 제2 임베딩부는 수신된 속성 정보를 원-핫 벡터(one-hot vector)로 변환하여 임베딩하거나, CSN (Conditional Similarity Networks) 모델에 기반하여 임베딩할 수 있다. 본 개시에 따른 마지막 인코딩 블록을 제외한 인코딩 블록들 각각은 비전 트랜스포머(Vision Transformer, ViT) 아키텍처의 셀프 어텐션(Self Attention) 모델에 기반하여 인코딩 할 수 있다. 본 개시에 따른 마지막 인코딩 블록은 컨디셔널 크로스 어텐션(Conditional Cross Attention) 모델에 기반하여 인코딩 하고, 컨디셔널 크로스 어텐션 모델은 함수로 표현되고, 함수는, 으로 표현되고, 는 제2 임베딩 부에 의해 임베딩된 c번째 속성 정보에 관한 쿼리(query) 값을 나타내고, 는 i번째 이미지 패치에 관한 키 (Key) 값을 나타내고, 는 i번째 이미지 패치에 관한 밸류(Value) 값을 나타내고, 는 히든 스페이스 (hidden space)의 차원수를 나타낼 수 있다. 본 개시에 따른 손실함수 계산부는 트리플렛 로스(Triplet Loss) 모델에 기반하여 손실을 계산하고, 트리플렛 로스 모델은 함수로 표현되고, 함수는, 으로 표 현되고, 는 c번째 속성 정보에 관한 손실을 나타내고, 는 c번째 속성 정보 에 관한 앵커(anchor)를 나타내는 이미지 정보이고, 는 앵커와 동일한 클래스(class)를 가지는 이미지 정 보이고, 는 앵커와 다른 클래스를 가지는 이미지 정보이고, 는 와 간의 코사인 거리(cosine distance)를 나타내고, 는 와 간의 코사인 거 리를 나타내고, 은 기 설정된 마진(margin)을 나타낼 수 있다. 본 개시에 따른 인공지능 모델 학습 방법은 이미지 정보 및 속성 정보를 포함하는 학습 정보를 수신하는 단계, 상기 수신된 이미지 정보 및 수신된 속성 정보를 임베딩하는 단계, 임베딩된 이미지 정보 및 임베딩된 속성 정 보 중 적어도 하나를 인코딩하는 단계 및 인코딩된 이미지 정보 및 인코딩된 속성 정보 중 적어도 하나를 기반 으로 손실을 계산하는 단계를 포함하고, 인코딩부는 복수의 인코딩 블록들을 포함하고, 임베딩된 이미지 정보는 복수의 인코딩 블록들을 순차적으로 통과하며 인코딩되고, 임베딩된 속성 정보는 복수의 인코딩 블록들 중 어느 하나만을 통과하며 인코딩될 수 있다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 인공지능 모델 학습 장치는 단일 네트워크를 사용하여, 여러 속성을 가지는 개체의 이미지에서 각 속 성에 대응하는 정보를 추출할 수 있다. 본 개시의 인공지능 모델 학습 장치는 비전 트랜스포머(ViT)의 셀프 어텐션(Self Attention) 모델에 기반하여, 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출할 수 있다.본 개시의 효과는 이에 한정되지 않는다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또 한 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 \"부\"라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, \"부\"는 어떤 역할 들을 수행한다. 그렇지만 \"부\"는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\"는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\"는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태 스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들을 포함한다. 구성요소들과 \"부\"들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\"들 로 결합되거나 추가적인 구성요소들과 \"부\"들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면 \"장치\" 및 \"부\" 중 적어도 하나는 프로세서 및 메모리로 구현될 수 있다. 용어 \"프로세서\" 는 범용 프로세서, 중앙 처리 장치 (CPU), 마이크로프로세서, 디지털 신호 프로세서 (DSP), 제어기, 마이크로제어기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서는, \"프로세서\" 는 주문형 반도체 (ASIC), 프로그램가능 로직 디바이스 (PLD), 필드 프로그램가능 게이트 어레이 (FPGA) 등을 지칭 할 수도 있다. 용어 \"프로세서\" 는, 예를 들어, DSP 와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있다. 용어 \"메모리\" 는 전자 정보를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한다. 용어 메 모리는 임의 액세스 메모리 (RAM), 판독-전용 메모리 (ROM), 비-휘발성 임의 액세스 메모리 (NVRAM), 프로그램 가능 판독-전용 메모리 (PROM), 소거-프로그램가능 판독 전용 메모리 (EPROM), 전기적으로 소거가능 PROM (EEPROM), 플래쉬 메모리, 자기 또는 광학 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체의 다양한 유형들을 지칭할 수도 있다. 프로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기록할 수 있다면 메모리는 프로세서와 전자 통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서와 전자 통신 상태에 있다. 아래에서는 첨부한 도면을 참고하여 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략한다. 또한 본 명세서에서 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의 미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거 나 과도하게 형식적인 의미로 해석되지 않는다. 도 1은 본 발명 일 실시예에 따른 인공지능 모델 학습 장치를 설명하기 위한 블록도이다. 이 도면은 본 발명의 일 실시예에 따른 인공지능 모델 학습 장치의 예시 및 인공지능 모델 학습 장치의 구 조의 예시를 설명하기 위한 도면이다. 일 실시예에 따른 인공지능 모델 학습 장치는 복수의 속성(attribute)들과 관련된 이미지 정보로부터 각 속성에 대응하는 정보를 추출하는 인공지능 모델을 학습하는 장치일 수 있다. 이미지 정보는 특정 오브젝트에 관한 이미지를 나타낼 수 있다. 즉 이미지 정보는 서로 같거나 다른 복수의 픽 셀(pixel)들로 구성된 데이터를 나타낼 수 있다. 예를 들어 이미지 정보는 셔츠에 대한 이미지 데이터를 나타낸 다. 속성은 이미지 정보가 나타내는 오브젝트의 특징을 나타낼 수 있다. 즉 속성은 이미지 정보가 나타내는 오브젝 트에 따라 결정될 수 있다. 또한 이미지 정보가 하나의 오브젝트만을 나타내더라도, 하나의 오브젝트는 복수의 속성들을 가질 수 있다. 속성은 옷의 모양, 색, 및 길이 중 적어도 하나를 포함할 수 있다. 보다 구체적으로 속 성은 카라 디자인(collar design), 라펠 디자인(lapel design), 옷의 목부위 디자인, 코트의 길이, 바지의 길이, 셔츠의 길이, 및 소매의 길이 중 적어도 하나를 포함할 수 있다. 속성은 옷의 종류에 미리 정해져 있을 수 있다. 예를 들어 이미지 정보에 포함된 옷의 종류가 셔츠인 경우, 속성들은 셔츠의 모양(shape), 셔츠의 색 (color) 및 셔츠의 길이(length) 중 적어도 하나를 포함할 수 있다. 즉 일 실시예에 따른 인공지능 모델 학습 장치는 복수의 속성과 관련된 이미지 정보로부터 각 속성을 나타 내는 정보를 추출하는 인공지능 모델을 학습하는 장치일 수 있다. 예를 들어 인공지능 모델 학습 장치는 셔츠를 나타내는 이미지 정보로부터 셔츠의 모양을 파악하기 위해, 셔츠의 모양에 해당하는 정보를 추출하는 인 공지능 모델을 학습할 수 있다. 또한 인공지능 모델 학습 장치는 셔츠를 나타내는 이미지 정보로부터 셔츠 의 길이를 파악하기 위해, 셔츠의 길이에 해당하는 정보를 추출하는 인공지능 모델을 학습할 수 있다. 또한 인 공지능 모델 학습 장치는 셔츠를 나타내는 이미지 정보로부터 셔츠의 색을 파악하기 위해, 셔츠의 색에 해 당하는 정보를 추출하는 인공지능 모델을 학습할 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치의 구조에 도시된 바와 같이, 인공지능 모델 학습 장치 는 상술한 목표를 달성하기 위해 하나의 네트워크(network, 예를 들어 뉴럴 네트워크)에 기반하여 학습을 수행할 수 있다. 예를 들어 인공지능 모델 학습 장치는 ICLR (International Conference on Learning Representations), 2021에 개제된 \"Kolesnikov et al., AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\" 에서 설명하는 비전 트랜스포머(Vision Transformer, ViT)를 사용하는 네트워크 에 기반하여 학습을 수행한다. 일반적으로 비전(Vision) 분야의 인공지능 모델은 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출하기 위해서는 속성 별로 네트워크를 활용해야 한다. 예를 들어 자동차를 나타내는 이미지에서 차량 종류 속성, 차량 색 속성 및 차량 사이즈 속성을 파악하기 위해서는 총 3개의 뉴럴 네트워크를 활용해야 한다. 다만 이와 같은 경우, 속성이 증가할수록 연산량이 증가하고 전체적인 인공지능 모델의 학습에 비효율을 초래하는 문제점이 발생한다. 또한 위 문제점을 해결하기 위해 단일 네트워크를 사용하는 경우에도, CNN (Convolutional neural network) 기 반의 임베딩(embebbing) 또는 CNN 기반의 어텐션(Attention) 모델을 사용하는 경우에도, 상술한 비효율을 효과 적으로 개선하지 못하는 문제점이 여전히 존재한다. 상술한 문제점을 해결하기 위하여, 일 실시예에 따른 인공지능 모델 학습 장치는 단일 네트워크를 사용하 여, 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출할 수 있으며, 그 인공지능 모델을 학습할 수 있다. 또한, 상술한 문제점을 해결하기 위하여, 일 실시예에 따른 인공지능 모델 학습 장치는 비전 트랜스포머 (ViT)의 셀프 어텐션(Self Attention) 모델에 기반하여, 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응 하는 정보를 추출할 수 있으며, 그 인공지능 모델을 학습할 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치는 수신부, 임베딩부, 인코딩부 및/또는 손실함 수 계산부를 포함할 수 있다. 인공지능 모델 학습 장치는 상술한 목표 달성을 위해 이 도면에 도시되 지 않은 하나 또는 그 이상의 모듈들을 더 포함할 수 있다. 상술한 바와 같이 일 실시예에 따른 인공지능 모델 학습 장치는 복수의 속성들과 관련된 이미지 정보로부 터 각 속성에 대응하는 이미지 정보의 일부를 추출할 수 있다. 일 실시예에 따른 수신부는 이미지 정보 및 속성 정보를 포함한 학습 정보를 수신할 수 있다. 인공지능 모 델 학습 장치는 수신부를 통해 수신된 학습 정보를 기반으로 상술한 학습을 수행할 수 있다. 상술한 바와 같이, 이미지 정보는 특정 오브젝트(또는 개체)에 관한 이미지를 나타내는 정보로, 하나 또는 그 이상의 픽셀들로 구성된 데이터일 수 있다. 속성에 대한 설명은 상술한 바와 동일하다. 속성 정보는 상술한 속성을 나타내는 정보일 수 있다. 즉 속성 정보 는 상술한 속성을 나타내는 텍스트 데이터일 수 있다. 즉 이미지 정보와 속성 정보는 서로 다른 형태로 표현될 수 있다. 예를 들어 속성 정보는 모양(shape), 색(color) 및/또는 길이(length)를 나타낸다. 일 실시예에 따른 임베딩부는 수신된 이미지 정보 및 수신된 속성 정보를 임베딩(embedding)할 수 있다. 즉 임베딩부는 수신된 이미지 정보 및/또는 수신된 속성 정보를 하나 또는 그 이상의 벡터(vector) 데이터 로 변환하는 등의 임베딩을 수행할 수 있다. 일 실시예에 따른 임베딩부는 제1 임베딩부(이 도면에 도시되어 있지 않음) 및/또는 제2 임베딩부(이 도면 에 도시되어 있지 않음)를 포함할 수 있다. 제1 임베딩부는 수신된 이미지 정보를 임베딩하고, 제2 임베딩부는 수신된 속성 정보를 임베딩할 수 있다. 즉 제1 임베딩부와 제2 임베딩부가 임베딩하는 대상은 서로 다를 수 있 다. 예를 들어 제1 임베딩부 및/또는 제2 임베딩부는 NIPS (Neural Information Processing Systems), 2013. 3 에 개제된 \"Frome et al., Devise: A deep visual-semantic embedding model\"에서 설명하는 멀티 모달(multi- modal) 기반의 임베딩과 동일 또는 유사한 임베딩을 수행한다. 일 실시예에 따른 인코딩부는 임베딩된 이미지 정보 및 임베딩된 속성 정보 중 적어도 하나를 인코딩 (encoding)할 수 있다. 인코딩부는 하나의 인코더 블록(encoder block)을 포함할 수도 있으나, 복수의 인 코더 블록들을 포함할 수도 있다. 예를 들어 인코딩부는 상술한 비전 트랜스포머(ViT) 기반의 인코딩과 동일 또 는 유사한 인코딩을 수행한다. 일 실시예에 따른 인코딩부가 복수의 인코딩 블록들을 포함하는 경우, 복수의 인코딩 블록들은 서로 직렬 (serially)로 연결될 수 있다. 이 경우, 상술한 임베딩된 이미지 정보는 복수의 인코딩 블록들을 순차적으로 통 과하면 인코딩될 수 있다. 또한 상술한 임베딩된 속성 정보는 복수의 인코딩 블록들 중 어느 하나만을 통과하며 인코딩될 수 있다. 예를 들어 임베딩된 속성 정보는 직렬로 연결된 복수의 인코딩 블록들 중 마지막 인코딩 블 록(L)만을 통과하며 인코딩된다. 즉 일 실시예에 따른 인코딩부는 마지막 인코딩 블록(L)에서 임베딩된 속 성 정보에 대한 인코딩을 수행하여, 복수의 속성들 각각에 대해 대응하는 정보를 효율적으로 출력할 수 있다. 예를 들어 인코딩부를 기반으로, 마지막 인코딩 블록을 제외한 나머지 인코딩 블록들에 대해서는 기존의 비전 트랜스포머(ViT) 모델을 그대로 적용하여 학습하고, 마지막 인코딩 블록(L)에 대해서만 속성을 분류하는 학습을 수행하여 효율적인 인공지능 모델 학습을 구현할 수 있다. 일 실시예에 따른 손실함수 계산부는 인코딩된 이미지 정보 및 인코딩된 속성 정보 중 적어도 하나를 기반 으로, 손실 함수(loss function)에 따른 손실(loss)을 계산할 수 있다. 손실함수 계산부에서 계산한 손실 은 상술한 학습 과정에 이용될 수 있다. 즉 손실함수 계산부는 계산되는 손실이 작아지도록 학습할 수 있 다. 예를 들어 손실함수 계산부에 의하여 계산된 손실은 트리플렉 로스(Triplet Loss) 모델에 기반하여 계 산된 트리플렛 로스이다. 일 실시예에 따른 인공지능 모델 학습 장치는 상술한 구성들을 기반으로 인공지능 모델의 학습 성능 개선 하고, 단일 네트워크를 사용하여 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출할 수 있고, 그 인공지능 모델을 학습하는 효과가 있다. 또한, 일 실시예에 따른 인공지능 모델 학습 장치는 비전 트랜스포머(ViT)의 셀프 어텐션(Self Attention) 모델에 기반하여, 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출할 수 있으며, 그 인 공지능 모델을 학습하는 효과가 있다. 도 2는 본 발명 일 실시예에 따른 인공지능 모델 학습 장치와 기존의 인공지능 모델 학습 장치들과의 차별점을 설명하기 위한 도면이다. 이 도면은 일 실시예에 따른 인공지능 모델 학습 장치와 기존의 인공지능 모델 학습 장치들과의 차별 점을 개념적으로 도식화하여 설명하기 위한 블록도이다. 일 실시예에 따른 인공지능 모델 학습 장치와 기존의 인공지능 모델 학습 장치들은 뉴럴 네트워크와 관련된 여러 모델들/레이어들을 사용할 수 있다. 예를 들어 인공지능 모델 학습 장치와 기존의 인공 지능 모델 학습 장치들은 CNN 모델, FC (Fully Connected) 레이어, 임베딩 레이어(Embedding layer), 어 텐션 네트워크(Attention Network), 셀프 어텐션 네트워크(Self Attention Network), 컨디셔널 크로스 어텐션 네트워크(Conditional Cross Attention Network, CCA, 또는 컨디셔널 크로스 어텐션 모델) 및/또는 패치 토큰 (Patch Token) 레이어의 조합을 사용한다. 일 실시예에 따른 인공지능 모델 학습 장치와 기존의 인공지능 모델 학습 장치들은 뉴럴 네트워크와 관련된 여러 모델들/레이어들에 도시되지 않은 하나 또는 그 이 상의 모델/네트워크/레이어를 더 포함할 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치는 상술한 여러 모델들/레이어들 중 컨디셔널 크로스 어텐 션 네트워크, 셀프 어텐션 네트워크, 임베딩 레이어 및/또는 패치 토큰 레이어의 조합을 사용할 수 있다. 셀프 어텐션 네트워크, 임베딩 레이어 및/또는 패치 토큰 레이어는 비전 트랜스포머(ViT) 및/또는 트랜스포머에서 사 용하는 네트워크 및/또는 레이어일 수 있다. 컨디셔널 크로스 어텐션 네트워크는 본 명세서의 실시예들을 통해 설명되는 기술일 수 있다. 즉 일 실시예에 따른 인공지능 모델 학습 장치는 기존의 셀프 어텐션 네트워크, 임베딩 레이어 및 패치 토큰 레이어에 실시예들을 통해 제안되는 컨디셔널 크로스 어텐션 네트워크를 추가 또는 조합하여 도 1 내지 도 7에서 설명하는 목적을 달성하거나 효과를 이뤄낼 수 있다. 비전 분야에서 하나의 이미지 정보가 포함하는 복수의 속성들에 대응하는 정보를 추출하고 이를 학습하기 위한 여러 인공지능 모델 학습 장치들이 개발되어 왔다. 예를 들어 CNN 모델 및 FC 레이어에 기반한 CSN (Conditional Similarity Networks) 모델을 사용하는 인공지능 모델 학습 장치가 있다. 또한 CNN 모델, 셀프 어텐션 네트워크, 임베딩 레이어 및 FC 레이어의 조합에 기반한 ASEN (Attribute-Specific Embedding Network) 모델을 사용하는 인공지능 모델 학습 장치가 있다. 또한 CNN 모델, 셀프 어텐션 모델 및 FC 레이어에 기반한 CAMNet (Convolutional Attribute Mask Network) 모델을 사용하는 인공지능 모델 학습 장치가 있다. 상술한 기존의 여러 인공지능 모델 학습 장치들은 모두 CNN 모델을 기반으로 인공지능 모델의 학습을 수행 한다. 다만 기존의 여러 인공지능 모델 학습 장치들과 같이 CNN 모델을 기반으로 학습을 수행하는 경우, 다수의 속성을 가지는 이미지 정보에 대해 각 속성에 대응하는 정보를 단일 네트워크를 통해 추출하는 경우 얽 힘(entanglement) 문제가 발생할 수 있다. 또한 기존의 인공지능 모델 학습 장치들은 비전 트랜스포머 (ViT) 모델 상에 상당한 변경을 가하기에 효율적인 비전 인공지능 학습을 수행할 수 없었다. 이에 반해, 일 실시예에 따른 인공지능 모델 학습 장치는 단일 네트워크를 통하여 상술한 학습을 수행하는 경우 발생하는 얽힘 문제를 해결하기 위해 상술한 컨디셔널 크로스 어텐션 네트워크를 사용할 수 있다. 또한 일 실시예에 따른 인공지능 모델 학습 장치는 비전 분야의 인공지능 모델로 활용되는 비전 트랜스포 머(ViT)의 전체 아키텍처에 큰 변경없이 상술한 컨디셔널 크로스 어텐션 네트워크를 적용하여 효율적인 비전 분 야 인공지능 학습을 수행할 수 있다. 또한 일 실시예에 따른 인공지능 모델 학습 장치는 상술한 컨디셔널 크로스 어텐션 네트워크(또는 모델)을 사용하여, 특정 데이터셋에서만 좋은 성능을 보이는 것이 아닌 대부분의 데이터셋에서 일관되게 높은 성능을 보 일 수 있다. 도 3은 본 발명 일 실시예에 따른 인공지능 모델 학습 장치를 설명하기 위한 블록도이다. 이 도면은 일 실시예에 따른 인공지능 모델 학습 장치의 동작의 예시를 설명하기 위한 블록도이다. 일 실 시예에 따른 인공지능 모델 학습 장치는 이 도면에 도시되지 않은 하나 또는 그 이상의 블록들을 더 포함 할 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치는 제 1 패치 토큰 블록, 셀프 어텐션 네트워크 블록 , 제 2 패치 토큰 블록, 컨디셔널 크로스 어텐션 네트워크 블록, 컨디셔널 토큰 임베딩 블록 , CSN (Conditional Similarity Networks) 모델 블록, 원-핫 인코딩 블록, 제 3 패치 토큰 블 록, FC (Fully Connected) 레이어 블록 및/또는 L2 정규화 블록을 포함할 수 있다. 인공지능 모델 학습 장치는 이 도면에 도시되어 있지 않은 하나 또는 그 이상의 블록들을 더 포함할 수 있다. 일 실시예에 따른 제 1 패치 토큰 블록은 상술한 제1 임베딩부와 동일 또는 유사할 수 있다. 이상에서 설 명한 바와 같이 제 1 패치 토큰 블록은 토큰화를 수행하는 '모듈'일 수 있다. 제 1 패치 토큰 블록은 x_0을 출력할 수 있다. 하지만 이에 한정되는 것은 아니며, 제 1 패치 토큰 블록은 임베딩된 '결과물'을 나타낼 수도 있다. 즉, 본 개시의 다양한 실시예에 따르면, 제 1 패치 토큰 블록은 이미지 정보를 상 술한 제1 임베딩부에 적용하여 생성된 블록을 의미할 수도 있다. 예를 들어, 제 1 패치 토큰 블록은 임베 딩된 이미지 정보를 나타낼 수도 있다. 제 1 패치 토큰 블록은 CLS 토큰 블록 및 PATCH 토큰 블록을 포함 할 수 있다. 예를 들어 도 3에서 제 1 패치 토큰 블록의 CLS 토큰 블록은 분홍색으로 표시되고, 제 1 패치 토큰 블록의 PATCH 토큰 블록은 보라색으로 표시될 수 있다. 제 1 패치 토큰 블록은 x_0에 대응될 수 도 있다. 일 실시예에 따른 컨디셔널 토큰 임베딩 블록은 상술한 제2 임베딩부와 동일 또는 유사할 수 있다. 일 실 시예에 따른 셀프 어텐션 네트워크 블록은 상술한 마지막 인코딩 블록을 제외한 인코딩 블록(1~L-1)들과 각각과 동일 또는 유사할 수 있다. 일 실시예에 따른 컨디셔널 크로스 어텐션 네트워크 블록은 상술한 마 지막 인코딩 블록(L)과 동일 또는 유사할 수 있다. 임베딩에 대한 설명은 도 1에서 상술한 바와 동일할 수 있다. 즉 제 1 패치 토큰 블록은 임베딩된 이미지 정보를 출력할 수 있다. 또한 본 개시의 다양한 실시예에 따르 면 제 1 패치 토큰 블록은 임베딩된 이미지 정보 일 수 있다. 컨디셔널 토큰 임베딩 블록은 임베딩된 속성 정보를 출력할 수 있다. 임베딩된 이미지 정보는 셀프 어텐션 네트워크 블록으로 입력될 수 있다. 임 베딩된 속성 정보는 컨디셔널 크로스 어텐션 네트워크 블록에 입력될 수 있다. 이미지 정보는 인공지능 모델 학습 장치에 입력될 수 있다. 이미지 정보에 대한 설명은 도 1 내 지 도 2에서 상술한 바와 동일하다. 구체적으로 인공지능 모델 학습 장치의 수신부는 이미지 정보 를 수신할 수 있다. 일 실시예에 따른 제 1 패치 토큰 블록은 이미지 정보에 대하여 토큰화 과정 및/또는 임베딩 과정을 수행할 수 있다. 즉 제 1 패치 토큰 블록은 이미지 정보를 이미지 정보 보다 작은 이미지 패치 단위 로 임베딩할 수 있다. 예를 들어 제 1 패치 토큰 블록은 이미지 정보를 패치(patch) 사이즈에 따라 복수의 이미지 패치들로 나누고, 복수의 이미지 패치들 각각에 패치 토큰(patch token)을 부여할 수 있다. 또한 패치 토근 블록은 이미지 패치들 각각에 대하여, 패치 토큰에 부가적으로 분류 토큰(classification token) 및/ 또는 위치 토큰(position token)을 부가할 수 있다. 상술한 제 1 패치 토큰 블록은 도 1에서 상술한 제1 임베딩부와 동일 또는 유사한 기능을 수행할 수 있다. 상술한 제 1 패치 토큰 블록의 토큰화 과정은 상술 한 제1 임베딩 과정에 포함되는 과정일 수 있다. 일 실시예에 따른 셀프 어텐션 네트워크 블록은 임베딩된(또는 토큰화된) 이미지 패치에 대하여 인코딩을 수행할 수 있다. 예를 들어 셀프 어텐션 네트워크 블록은 이미지 패치에 대해 정규화 과정, 셀프 어텐션 정보 계산 과정, 합산 및 정규화 과정 및/또는 피드-포워드 네트워크 (Feed-Forward Network, FFN) 과정을 순차 적으로 수행할 수 있다. 상술한 과정들은 비전 트랜스포머(ViT) 아키텍처에 기반한 과정들일 수 있다. 상술한셀프 어텐션 네트워크 블록은 도 1에서 상술한 인코딩 블록(예를 들어 마지막 인코딩 블록을 제외한 인코딩 블 록들(1~L-1) 각각)과 동일 또는 유사한 기능을 수행할 수 있다. 일 실시예에 따른 셀프 어텐션 네트워크 블록(302, 또는 마지막 인코딩 블록을 제외한 인코딩 블록들 각각)은 모두 L-1 개 존재할 수 있다. 즉 이미지 패치들 각각은 총 L-1 개의 셀프 어텐션 네트워크 블록을 순차적 으로 거치면서 인코딩될 수 있다. 구체적으로 셀프 어텐션 네트워크 블록(또는 마지막 인코딩 블록을 제외한 인코딩 블록들 각각)은 비전 트랜스 포머(ViT) 아키텍처의 셀프 어텐션 모델에 기반하여 인코딩(예를 들어 셀프 어텐션 정보 계산)할 수 있다. 예를 들어 l 번째 셀프 어텐션 네트워크 블록을 통과한 임베딩된 이미지 패치(x_l)에 대한 수식(식 1)은 아래와 같을 수 있다. ... (식 1) x_0는 첫번째 셀프 어텐션 네트워크 블록에 입력된 임베딩된 이미지 패치일 수 있다. x_[CLS]는 상술한 분 류 토큰에 관한 분류 임베딩 벡터일 수 있다. x_[CLS]의 행렬의 크기는 1 X D일 수 있다. x_[PATCH]는 상술한 임베딩된 이미지 패치에 관한 임베딩 벡터일 수 있다. x_[PATCH]의 행렬의 크기는 N x D일 수 있다. x_[POS]는 상술한 위치 토큰에 관한 위치 임베딩 벡터일 수 있다. x_[POS]의 행렬의 크기는 (1+N) X D일 수 있다. LN(x_l- 1)은 x_l-1 값의 레이어 정규화(Layer Normalization)를 거친 값일 수 있다. MSA(LN(x_l-1))은 LN(x_l-1) 값에 대한 멀티-헤드 셀프 어텐션(Multi-headed Self Attention)을 거친 값일 수 있다. FFN(LN(x'_l)은 LN(x'_l) 값 에 대한 피드 포워드 네트워크를 거친 값일 수 있다. 또한 상술한 바와 같이, 셀프 어텐션 네트워크 블록이 수행하는 비전 트랜스포머(ViT) 기반의 셀프 어텐션 정보 계산 과정에 의하여 계산되는 i 번째 이미지 패치의 어텐션 정보 값은 아래의 수식(식 2)과 같을 수 있다. ... (식 2) Q_i는 i 번째 이미지 패치에 대한 쿼리(query) 값을 나타낼 수 있다, K_i는 i 번째 이미지 패치에 관한 키(Key) 값을 나타낼 수 있다, V_i는 i 번째 이미지 패치에 대한 밸류(Value) 값을 나타낼 수 있다. d는 히든 스페이스 (hidden space)의 차원수를 나타낼 수 있다. Q_i, K_i, 및 V_i의 행렬의 크기는 N X D일 수 있다. 즉 이 도면에 도시된 바와 같이, 인공지능 모델 학습 장치가 직렬로 연결된 복수의 인코딩 블록들을 포함 하는 경우, 마지막 인코딩 블록을 제외한 인코딩 블록들은 비전 트랜스포머(Vit)의 셀프 어텐션 모델에 기반하 여 인코딩을 수행할 수 있다. 또한 임베딩된 이미지 패치는 상술한 인코딩 블록들을 순차적으로 통과하며 인코 딩될 수 있다. 셀프 어텐션 네트워크 블록은 인코딩된 이미지 정보(또는 인코딩된 이미지 패치)를 출력할 수 있다. 본 개 시의 다양한 실시예에 따르면, 인코딩된 이미지 정보(또는 인코딩된 이미지 패치)는 제 2 패치 토큰 블록 일 수 있다. 예를 들어 셀프 어텐션 네트워크 블록이 전체 L개의 인코딩 블록들 중 첫번째 인코딩 블록인 경우, 제 2 패치 토큰 블록은 첫번째 인코딩 블록에 의하여 인코딩된 이미지 정보(또는 인코딩된 이미지 패치)이다. 이 경우 셀프 어텐션 네트워크 블록에 의하여 인코딩된 이미지 정보는 전체 L개의 인코딩 블록 들 중 두번째 인코딩 블록에 입력될 수 있다. 일 실시예에 따른 컨디셔널 토큰 임베딩 블록은 속성 정보에 대하여 토큰화 과정 및/또는 임베딩 과정을 수행할 수 있다. 컨디션(condition)은 상술한 속성(attribute)에 대응할 수 있다. 즉 컨디셔널 토큰 임베딩 블 록은 텍스트 형태로 표현된 속성 정보에 대하여 토큰화 과정 및 임베딩 과정을 수행할 수 있다. 일 실시예에 따른 컨디셔널 토큰 임베딩 블록에 의하여 토큰화 및/또는 임베딩된 c 번째 속성 정보(Q_c, 예를 들어 전체 K개의 속성 정보 중 c 번째 속성 정보)에 대한 수식(식 3)은 아래와 같을 수 있다. ... (식 3) 상술한 임베딩된 이미지 패치의 패치 토큰의 수는 N+1 개 일 수 있다. 즉 컨디셔널 토큰 임베딩 블록은 상 술한 패치 토큰의 차원 수와 임베딩된 c 번째 속성 정보의 차원 수를 서로 일치시키기 위하여 q_c 벡터를 N+1 만큼 반복시킬 수 있다. R은 이미지 패치들을 나타내는 행렬일 수 있다. 상술한 N은 R의 열(column)의 개수를 나타낼 수 있다. D는 R의 행(row)의 개수를 나타낼 수 있다. Qc의 행렬의 크기는 D X (N+1)일 수 있다. Qc는 임 베딩된 속성 정보일 수 있다. 일 실시예에 따른 컨디셔널 토큰 임베딩 블록은 속성 정보를 원-핫 벡터로 변환하여 임베딩할 수 있다. 이 때 상술한 q_c 벡터는 아래의 수식(식 4)에 의하여 계산될 수 있다. ... (식 4) onehot(c)는 c번째 속성 정보의 원-핫 벡터(one-hot vector)일 수 있다. FC(onehot(c))은 onehot(c)에 대한 FC(fully connected) 레이어 변환 값일 수 있다. q_c의 행렬의 크기는 D X 1일 수 있다. 또한 일 실시예에 따른 컨디셔널 토큰 임베딩 블록은 속성 정보를 CSN (Conditional Similarity Networks) 모델에 기반하여 임베딩할 수 있다. 이때 상술한 q_c 벡터는 아래의 수식(식 5)에 의하여 계산될 수 있다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "... (식 5) 는 CSN의 mask를 나타낼 수 있다. Mask는 상술한 수식에 의해 표현될 수 있고, K는 상술한 바와 같이 속성 정보의 전체 개수를 나타낼 수 잇다. R 및 D에 대한 설명은 상술한 바와 같다. 는 활성화 함수(예를 들어 Rectified Linear Activation Function, ReLU)를 나타낼 수 있다. FC에 대한 설명은 상술한 바와 같다. 일 실시예에 따른 제 2 패치 토큰 블록은 셀프 어텐션 네트워크 블록에 의하여 인코딩된 이미지 패치 에 대하여 토큰화 과정 및/또는 임베딩 과정을 수행할 수 있다. 토큰화 과정 및/또는 임베딩 과정에 대한 설명 은 상술한 바와 동일 또는 유사하다. 이상에서 설명한 바와 같이 제 2 패치 토큰 블록은 토큰화를 수행하는 '모듈'일 수 있다. 제 2 패치 토큰 블록은 식 1 의 x_l를 출력할 수 있다. 하지만 이에 한정되는 것은 아니며, 제 2 패치 토큰 블록은 임베딩된 '결과물'을 나타낼 수도 있다. 본 개시의 다양한 실시예에 따르면, 제 2 패치 토큰 블록은 셀프 어텐션 네트워크 블록에 의해 생성된 블록일 수도 있다. 제 2 패치 토큰 블록은 CLS 토큰 블록 및 PATCH 토큰 블록을 포함할 수 있다. 제 2 패치 토큰 블록은 제 1 패치 토큰 블록에 셀프 어텐션 네트 워크 블록을 적용하였으므로, 제 2 패치 토큰 블록의 CLS 토큰 블록 및 PATCH 토큰 블록은 제 1 패치 토큰 블록의 CLS 토큰 블록 및 PATCH 토큰 블록과 다를 수 있다. 도 3에서 제 2 패치 토큰 블록의 CLS 토큰 블록은 분홍색으로 표시되고, 제 2 패치 토큰 블록의 PATCH 토큰 블록은 보라색으로 표시될 수 있다. 제 2 패치 토큰 블록은 식 1 의 x_l에 대응될 수 있다. x_l은 L-1 개의 셀프 어텐션 네트워크 블록 을 순차적으로 거치면서 인코딩된 블록일 수 있다. 하지만 이에 한정되는 것은 아니다. 일 실시예에 따른 컨디셔널 크로스 어텐션 네트워크 블록(304, 또는 마지막 인코딩 블록)은 제 2 패치 토큰 블 록에 대하여 인코딩 과정을 수행할 수 있다. 예를 들어 컨디셔널 크로스 어텐션 네트워크 블록은 이 미지 패치에 대하여 정규화 과정, 셀프 어텐션 정보 계산 과정, 합산 및 정규화 과정 및/또는 피드-포워드 네트 워크(FFN) 과정을 순차적으로 수행할 수 있다. 정규화 과정, 합산 및 정규화 과정 및/또는 피드-포워드 네트워 크(FFN) 과정에 대한 설명은 상술한 바와 동일할 수 있다. 다만 컨디셔널 크로스 어텐션 네트워크 블록이 수행하는 셀프 어텐션 정보 계산 과정은 상술한 셀프 어텐션 네트워크 블록이 수행하는 셀프 어텐션 정보계산 과정과 다를 수 있다. 상술한 컨디셔널 크로스 어텐션 네트워크 블록이 수행하는 셀프 어텐션 정보 계산 과정은 컨디셔널 크로스 어텐션(Conditional Cross Attention) 모델에 기반할 수 있다. 즉 컨디셔널 크로스 어텐션 네트워크 블록(304, 또는 마지막 인코딩 블록)은 컨디셔널 크로스 어텐션 모델에 기반하여 인코딩 할 수 있다. 일 실시예에 따른 컨디셔널 크로스 어텐션 모델은 비전 트랜스포머(ViT)의 셀프 어텐션 모델과 유사할 수 있다. 즉 컨디셔널 크로스 어텐션 모델은 소프트맥스(softmax) 함수에 기반하여 표현될 수 있다. 예를 들어 상술한 컨 디셔널 크로스 어텐션 모델은 다음과 같은 수식(식 6)으로 표현될 수 있다. ... (식 6) 는 제2 임베딩부(또는 컨디셔널 토큰 임베딩 블록)에 의해 임베딩된 c번째 속성 정보에 관한 쿼리 (query) 값을 나타낼 수 있다. 는 i번째 이미지 패치에 관한 키(Key) 값을 나타낼 수 있다. 는 i번째 이미지 패치에 관한 밸류(Value) 값을 나타낼 수 있다. 는 히든 스페이스(hidden space)의 차원수를 나타낼 수 있다. 즉 상술한 컨디셔널 크로스 어텐션 모델에 기반한 인코딩은 마지막 인코딩 블록(예를 들어 서로 직렬로 연결된 전체 L개의 인코딩 블록들 중 L번째 인코딩 블록)에 의해서만 수행될 수 있다. 즉 일 실시예에 따른 인공지능 모델 학습 장치는 전체 L개의 인코딩 블록들 중 L-1 번째 인코딩 블록까지는 비전 트랜스포머(ViT) 기반의 인코딩을 그대로 수행하고, 마지막 L 번째 인코딩 블록에서는 컨디셔널 크로스 어텐션 모델에 기반한 인코딩을 수행할 수 있다. 즉 컨디셔널 크로스 어텐션 네트워크 블록은 인코딩된 이미지 정보 및/또는 인코딩된 속성 정보를 출력할 수 있다. 다만 상술한 바와 같이,인코딩된 이미지 정보는 전체 L개의 인코딩 블록들에 의하여 인코딩된 정보일 수 있다. 또한 인코딩된 속성 정보는 마지막 L 번째 인코딩 블록에 의하여 인코딩된 정보일 수 있다. 본 개시의 다양한 실시예에 따르면, 제 3 패치 토큰 블록은 상술한 인코딩된 이미지 정보 및 인코딩된 속성 정보 중 적어도 하나를 포함할 수 있다. 이상에서 설명한 바와 같이 제 3 패치 토큰 블록은 토큰화를 수행하는 '모듈'일 수 있다. 본 개시의 다양 한 실시예에 따르면, 제 3 패치 토큰 블록은 컨디셔널 크로스 어텐션 네트워크 블록에 의하여 생성된 블록일 수 있다. 제 3 패치 토큰 블록은 CLS 토큰 블록 및 PATCH 토큰 블록을 포함할 수 있다. 제 3 패치 토큰 블록은 제 2 패치 토큰 블록에 컨디셔널 크로스 어텐션 네트워크 블록을 적용하였으므로, 제 3 패치 토큰 블록의 CLS 토큰 블록 및 PATCH 토큰 블록은 제 2 패치 토큰 블록의 CLS 토큰 블록 및 PATCH 토큰 블록과 다를 수 있다. 도 3에서 제 3 패치 토큰 블록의 CLS 토큰 블록은 분홍색으로 표시되 고, 제 3 패치 토큰 블록의 PATCH 토큰 블록은 보라색으로 표시될 수 있다. 제 3 패치 토큰 블록의 CLS 토큰 블록은 분류 토큰에 관한 분류 임베딩 벡터일 수 있다. 이 실시예에서 인코딩부는 임베딩된 이미 지 정보 및 임베딩된 속성 정보를 인코딩하여 제 3 패치 토큰 블록을 생성할 수 있다. 또한, 손실함수 계산부 는 제 3 패치 토큰 블록을 기반으로 손실을 계산할 수 있다. 컨디셔널 크로스 어텐션 네트워크 블록이 수행하는 인코딩 과정은 상술한 셀프 어텐션 네트워크 블록(30 2)이 수행하는 인코딩 과정과 유사할 수 있다. 예를 들어 컨디셔널 크로스 어텐션 네트워크 블록이 수행하 는 인코딩 과정 중 상술한 식 6에 기반한 어탠션 정보 계산 과정을 제외한 과정들은 셀프 어텐션 네트워크 블록 이 수행하는 인코딩 과정과 동일하다. 일 실시예에 따른 FC 레이어 블록 및 L2 정규화 블록은 제 3 패치 토큰 블록에 대하여 FC 레이 어 변환 및 L2 정규화를 수행할 수 있다. 예를 들어 FC 레이어 블록 및 L2 정규화 블록에 의하여 FC 레이어 변환 및 L2 정규화된 이미지 패치(f^final)에 대한 수식(식 7)은 아래와 같을 수 있다.... (식 7) x_[CLS]는 상술한 바와 같이 분류 토큰에 관한 분류 임베딩 벡터일 수 있다. FC(x_[CLS])는 상술한 바와 같이 x_[CLS]에 대한 FC 레이어 변환 값일 수 있다. 즉 f^final(또는 최종 출력물)은 상술한 x_[CLS] FC 레이어 변환 과정 및 L2 정규화 과정을 적용하여 얻어진 결과물일 수 있다. 또한 x_[CLS]는 후술하는 손실함수 계산부에 의 한 손실 계산 과정에 사용될 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치는 손실함수 계산부(이 도면에 도시되어 있지 않음)을 더 포함 할 수 있다. 손실함수 계산부에 대한 설명은 도 1에서 상술한 바와 동일할 수 있다. 즉 손실함수 계산부는 인코 딩된 이미지 패치를 이용하여, 손실 함수(loss function)에 따라 손실(loss)을 계산할 수 있다. 일 실시예에 따른 손실함수 계산부는 트리플렛 로스(Triplet Loss) 모델에 기반하여 상술한 손실을 계산할 수 있다. 트리플렛 로스 모델에 기반하여 계산된 손실 에 대한 수식(식 8)은 아래와 같을 수 있다."}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "... (식 8)"}
{"patent_id": "10-2023-0127339", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "는 c번째 속성 정보에 관한 손실을 나타낼 수 있다. 는 c번째 속성 정보 에 관한 앵커(anchor)를 나타내는 이미지 정보일 수 있다. 는 앵커와 동일한 클래스(class)를 가지는 이미 지 정보일 수 있다. 는 앵커와 다른 클래스를 가지는 이미지 정보일 수 있다. 는 와 간의 코사인 거리(cosine distance)를 나타낼 수 있다. 는 와 간의 코사인 거리를 나타낼 수 있다. 은 기 설정된 마진 (margin)을 나타낼 수 있다. 예를 들어 기 설정된 마진은 0.2 일 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치는 이 도면에서 설명하는 하나 또는 그 이상의 블록들(또는 구 성들)을 기반으로 상술한 컨디셔널 크로스 어텐션 네트워크를 적용한 효율적인 비전 분야 인공지능 학습을 수행 할 수 있다. 또한 일 실시예에 따른 인공지능 모델 학습 장치는 상술한 컨디셔널 크로스 어텐션 네트워크(또는 모델)을 사용하여, 특정 데이터셋에서만 좋은 성능을 보이는 것이 아닌 대부분의 데이터셋에서 일관되게 높은 성능을 보 일 수 있다. 도 4는 본 발명 일 실시예에 따른 인공지능 모델 학습 장치의 효과의 예시를 설명하기 위한 도면이다. 이 도면은 일 실시예에 따른 인공지능 모델 학습 장치의 효과의 예시를 설명하기 위한 도면이다. 본 명세 서에서 설명하는 인공지능 모델 학습 장치가 학습하는 인공지능 모델은 패션AI (FashionAI) 모델로 호칭될 수도 있다. 이 도면에 도시된 표는 일 실시예에 따른 인공지능 모델 학습 장치의 각 속성에 따른 어텐션 히트 맵 (attention heat map)일 수 있다. 예를 들어 인공지능 모델 학습 장치가 각 속성에 따라 이미지 정보 내 어떤 부분을 집중했는지를 시각적으로 나타내는 히트 맵이다. 이 도면에 도시된 어텐션 히트 맵은 인공지능 모델 학습 장치가 총 8개의 속성들을 기반으로 각 속성에 대 응하는 정보를 추출하는 과정에서 생성되는 히트 맵일 수 있다. 예를 들어 이 도면에 도시된 어텐션 히트 맵은 코트 길이(coat length), 카라 디자인(collar design), 옷깃 디자인(lapel design), 넥 디자인(neck design), 넥크리스 디자인(necklace design), 팬트 디자인(pant design), 스커트 길이(skirts length) 및 소매 길이 (sleeve length) 각각에 대응하는 정보를 추출하는 과정에서 생성되는 히트 맵일 수 있다. 예를 들어 카라 디자인에 대응하는 정보를 추출하는 과정에서 생성되는 히트 맵은, 이미지 정보 중 카라 디자인에 해당하는 이미지 정보의 부분이 집중된 것을 시각적으로 나타내는 히트 맵일 수 있다. 또한 예를 들어 코트 길이에 대응하는 정보를 추출하는 과정에서 생성되는 히트 맵은, 이미지 정보 중 코트 길이에 해당하 는 이미지 정보의 부분이 집중된 것을 시각적으로 나타내는 히트 맵일 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치는 이 도면에서 설명하는 어텐션 히트 맵을 기반으로 각 속성에 대응 하는 정보를 추출 및/또는 학습할 수 있다. 예를 들어 인공지능 모델 학습 장치는 코트 길이 속성에 대하 여 \"midi\"를 추출하고, 카라 디자인 속성에 대하여 \"peter pan\"을 추출하고, 옷깃 디자인 속성에 대하여 \"notched\"를 추출하고, 넥 디자인 속성에 대하여 \"low turtle\"을 추출하고, 넥크리스 디자인 속성에 대하여 \"round\"를 추출하고, 팬트 길이 속성에 대하여 \"midi\"를 추출하고, 스커트 길이 속성에 대하여 \"floor\"을 추출 하고, 소매 길이 속성에 대하여 \"short\"를 추출할 수 있다. 도 5는 본 발명 일 실시예에 따른 인공지능 모델 학습 장치의 효과의 예시를 설명하기 위한 도면이다. 이 도면은 일 실시예에 따른 인공지능 모델 학습 장치의 효과를 시각화하여 나타낸 표 및 다른 종류 의 인공지능 모델 학습 장치의 효과를 시각화하여 나타낸 표를 비교한 도면이다. 예를 들어 표 및 표 는 t-SNE (t-Stochastic Neighbor Embedding) 시각화 모델을 이용한 표일 수 있다. 즉 이 도면에 도시된 표들(500, 501)은 각 속성별로 클래스에 대한 임베딩이 적절하게 되어 있는지를 나타낼 수 있다. 속성, 클래스 및 임베딩에 대한 설명은 도 1 내지 도 4에서 상술한 바와 동일하다. 예를 들어 표들(500, 501)은 고차원 공간에서 유사한 벡터들이 2차원 공간에서도 유사하도록, 고차원 공간 내 각 점들(임베딩된 결과 물)의 유사도록을 보존하면서 차원을 축소한 것을 시각적으로 나타내는 표일 수 있다. 즉 표들(500, 501)은 2차 원 벡터를 x축 및 y축을 기반으로 표현(또는 플로팅(plotting)한 표일 수 있다. 이 도면에 도시된 표들(500, 501) 각각은 총 55개의 클래스를 가지는 8개의 속성들에 대한 t-SNE 시각화 모델일 수 있다. 즉 표는 일 실시예에 따른 인공지능 모델 학습 장치가 총 55개의 클래스를 가지는 8개의 속 성들(넥크리스 디자인, 소매 길이, 코트 길이, 옷깃 디자인, 카라 디자인, 팬트 길이, 넥 디자인 및 스커트 길 이)에 대한 임베딩 분류를 t-SNE 시각화 모델을 기반으로 시각화한 표일 수 있다. 또한, 표는 일 실시예에 따른 인공지능 모델 학습 장치와 다른 종류의 인공지능 모델 학습 장치(예를 들어 도 3에서 상술한 컨디셔널 크 로스 네트워크 어텐션 네트워크 모델 이외의 어텐션 모델을 사용하는 인공지능 모델 학습 장치)가 총 55개의 클 래스를 가지는 8개의 속성들(넥크리스 디자인, 소매 길이, 코트 길이, 옷깃 디자인, 카라 디자인, 팬트 길이, 넥 디자인 및 스커트 길이)에 대한 임베딩 분류를 t-SNE 시각화 모델을 기반으로 시각화한 표일 수 있다. 이 도면에 도시된 바와 같이, 인공지능 모델 학습 장치는 다른 종류의 인공지능 모델 학습 장치에 비하여 각 속성 별로 임베딩 및 분류의 성능이 향상된 것을 알 수 있다. 즉 이 도면에 도시된 바와 같이, 인공지능 모 델 학습 장치는 상술한 얽힘 문제를 해결하여 인공지능 모델을 학습할 수 있다. 도 6은 본 발명 일 실시예에 따른 인공지능 모델 학습 장치의 효과의 예시를 설명하기 위한 도면이다. 이 도면은 일 실시예에 따른 인공지능 모델 학습 장치의 효과를 시각화하여 나타낸 표 및 다른 종류 의 인공지능 모델 학습 장치의 효과를 시각화하여 나타낸 표(601, 602)를 비교한 도면이다. 예를 들어 표들(600 내지 602)은 상술한 t-SNE (t-Stochastic Neighbor Embedding) 시각화 모델을 이용한 표일 수 있다. 구체적으로 이 도면은 일 실시예에 따른 인공지능 모델 학습 장치의 효과를 t-SNE 시각화 모델을 기반으로 시각화하여 나타낸 표, ASEN 모델에 기반한 인공지능 모델 학습 장치의 효과를 t-SNE 시각화 모델을 기반 으로 시각화하여 나타낸 표 및 시각화 CAMNet 모델에 기반한 인공지능 모델 학습 장치의 효과를 t-SNE 모 델을 기반으로 시각화하여 나타낸 표를 비교한 도면일 수 있다. ASEN 모델 및 CAMNet 모델에 대한 설명은 도 2에서 상술한 바와 동일하다.도 5에서 상술한 바와 같이 표들(600 내지 602) 각각은 총 55개의 클래스를 가지는 8개의 속성들에 대한 t-SNE 시각화 모델일 수 있다. 이 도면에 도시된 바와 같이, 이 도면은 총 8개 속성들 중 넥 디자인, 소매 길이 및 코트 길이에 대한 인공지능 모델 학습 장치의 효과를 t-SNE 시각화 모델을 기반으로 시각화하여 나타낸 벡터들, 넥 디자인, 소매 길이 및 코트 길이에 대한 ASEN 모델 기반 인공지능 모델 학습 장치의 효과를 t-SNE 시각화 모델을 기반으로 시 각화하여 나타낸 벡터들 및 넥 디자인, 소매 길이 및 코트 길이에 대한 CAMNet 모델 기반 인공지능 모델 학습 장치의 효과를 t-SNE 시각화 모델을 기반으로 시각화하여 나타낸 벡터들을 비교한 도면일 수 있다. 즉 이 도면에 도시된 바와 같이, 인공지능 모델 학습 장치와 다른 종류의 인공지능 모델 학습 장치들이 해 결하지 못한 얽힘 문제를 인공지능 모델 학습 장치에서 해결하였음을 알 수 있다. 도 7은 본 발명 일 실시예에 따른 인공지능 모델 학습 방법을 설명하기 위한 흐름도이다. 이 도면은 도 1 내지 도 6에서 상술한 인공지능 모델 학습 장치가 수행하는 인공지능 모델 학습 방법을 설 명하기 위한 흐름도의 예시를 나타낼 수 있다. 즉 일 실시예에 따른 인공지능 모델 학습 방법은 복수의 속성(attribute)들과 관련된 이미지 정보로부터 각 속 성에 대응하는 정보를 추출하는 인공지능 모델을 학습하는 방법일 수 있다. 일 실시예에 따른 인공지능 모델 학 습 방법은 이미지 정보 및 속성 정보를 포함하는 학습 정보를 수신하는 단계, 수신된 이미지 정보 및 수신 된 속성 정보를 임베딩하는 단계, 임베딩된 이미지 정보 및 임베딩된 속성 정보 중 적어도 하나를 인코딩 하는 단계 및 인코딩된 이미지 정보 및 인코딩된 속성 정보 중 적어도 하나를 기반으로 손실을 계산하는 단계를 포함할 수 있다. 상술한 바와 같이, 인코딩하는 단계는 복수의 인코딩 블록들에 의하여 수행될 수 있다. 즉 임베딩된 이미 지 정보는 복수의 인코딩 블록들을 순차적으로 통과하며 인코딩되고, 임베딩된 속성 정보는 상기 복수의 인코딩 블록들 중 어느 하나만을 통과하며 인코딩될 수 있다. 상술한 바와 같이, 복수의 인코딩 블록들은 서로 직렬(serially)로 연결될 수 있다. 임베딩된 속성 정보를 인코 딩하는 인코딩 블록은 직렬로 연결된 복수의 인코딩 블록들 중 마지막 인코딩 블록일 수 있다. 상술한 바와 같이, 임베딩하는 단계는 제1 임베딩부 및 제2 임베딩부에 의하여 수행될 수 있다. 제1 임베 딩부는 수신된 이미지 정보를 임베딩하고, 제2 임베딩부는 수신된 속성 정보를 임베딩할 수 있다. 제1 임베딩부 는 이미지 정보 보다 작은 이미지 패치(patch) 단위로 임베딩할 수 있다. 제2 임베딩부는 수신된 속성 정보를 원-핫 벡터(one-hot vector)로 변환하여 임베딩하거나, CSN (Conditional Similarity Networks) 모델에 기반하 여 임베딩할 수 있다. 상술한 바와 같이, 마지막 인코딩 블록을 제외한 인코딩 블록들 각각은 비전 트랜스포머(Vision Transformer, ViT) 아키텍처의 셀프 어텐션(Self Attention) 모델에 기반하여 인코딩할 수 있다. 상술한 바와 같이, 마지막 인코딩 블록은 컨디셔널 크로스 어텐션(Conditional Cross Attention) 모델에 기반하 여 인코딩할 수 있다. 컨디셔널 크로스 어텐션 모델은 함수(상술한 식 6)로 표현되고, 함수는, ... (식 6) 으로 표현될 수 있다. 는 제2 임베딩부에 의해 임베딩된 c번째 속성 정보에 관한 쿼리(query) 값을 나타낼 수 있다. 는 i번째 이미지 패치에 관한 키(Key) 값을 나타낼 수 있다. 는 i번째 이미지 패치에 관한 밸 류(Value) 값을 나타낼 수 있다. 는 히든 스페이스(hidden space)의 차원수를 나타낼 수 있따. 상술한 바와 같이, 손실함수 계산부는 트리플렛 로스(Triplet Loss) 모델에 기반하여 손실을 계산할 수 있다. 트리플렛 로스 모델은 함수(상술한 식 8)로 표현되고, 함수는, ... (식 8) 으로 표현될 수 있다. 는 c번째 속성 정보에 관한 손실을 나타낼 수 있다. 는 c번째 속성 정보에 관한 앵커(anchor)를 나타내는 이미지 정보일 수 있다. 는 앵커와 동일한 클래 스(class)를 가지는 이미지 정보일 수 있다. 는 앵커와 다른 클래스를 가지는 이미지 정보일 수 있다. 는 와 간의 코사인 거리(cosine distance)를 나타낼 수 있다. 는 와 간의 코사인 거리를 나타낼 수 있다. 은 기 설정된 마진 (margin)을 나타낼 수 있다. 일 실시예에 따른 인공지능 모델 학습 장치는 이 도면에서 설명하는 인공지능 모델 학습 방법을 기반으로 인공지능 모델의 학습 성능 개선하고, 단일 네트워크를 사용하여 여러 속성을 가지는 개체의 이미지에서 각 속 성에 대응하는 정보를 추출할 수 있고, 그 인공지능 모델을 학습하는 효과가 있다. 또한, 일 실시예에 따른 인공지능 모델 학습 장치는 이 도면에서 설명하는 인공지능 모델 학습 방법을 기 반으로 여러 속성을 가지는 개체의 이미지에서 각 속성에 대응하는 정보를 추출할 수 있으며, 그 인공지능 모델 을 학습하는 효과가 있다. 이제까지 다양한 실시예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있 을 것이다. 그러므로 개시된 실시예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명 의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다. 한편, 상술한 본 발명의 실시예들은 컴퓨터에서 실행될 수 있는 프로그램으로 작성가능하고, 컴퓨터로 읽을 수 있는 기록매체를 이용하여 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 컴퓨터로 읽을 수 있는 기록매체는 마그네틱 저장매체(예를 들면, 롬, 플로피 디스크, 하드디스크 등), 광학적 판독 매체(예를 들 면, 시디롬, 디브이디 등)와 같은 저장매체를 포함한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2023-0127339", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명 일 실시예에 따른 인공지능 모델 학습 장치를 설명하기 위한 블록도이다. 도 2는 본 발명 일 실시예에 따른 인공지능 모델 학습 장치와 기존의 인공지능 모델 학습 장치들과의 차별점을 설명하기 위한 도면이다. 도 3은 본 발명 일 실시예에 따른 인공지능 모델 학습 장치를 설명하기 위한 블록도이다. 도 4는 본 발명 일 실시예에 따른 인공지능 모델 학습 장치의 효과의 예시를 설명하기 위한 도면이다. 도 5는 본 발명 일 실시예에 따른 인공지능 모델 학습 장치의 효과의 예시를 설명하기 위한 도면이다. 도 6은 본 발명 일 실시예에 따른 인공지능 모델 학습 장치의 효과의 예시를 설명하기 위한 도면이다. 도 7은 본 발명 일 실시예에 따른 인공지능 모델 학습 방법을 설명하기 위한 흐름도이다."}
