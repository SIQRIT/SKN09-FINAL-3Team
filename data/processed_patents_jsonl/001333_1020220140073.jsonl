{"patent_id": "10-2022-0140073", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0059159", "출원번호": "10-2022-0140073", "발명의 명칭": "언어모델을 사용한 이야기 생성 방법", "출원인": "성균관대학교산학협력단", "발명자": "정윤경"}}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "언어모델을 사용한 이야기 생성 방법에 있어서,첫 문장, 직전 문장 및 갈등 문장을 포함하는 비교 문장으로 구성된 이야기에 추가될 후보 문장을 학습 데이터셋을 통해 파인튜닝된 언어모델을 사용하여 생성하는 단계;COMET 모델을 사용하여 상기 비교 문장 및 상기 생성된 후보 문장 각각에 대한 관계 문장들을 생성하는 단계;상기 후보 문장에 대한 관계 문장을 기 설정된 유사에 관한 제1 규칙을 기반으로 상기 비교 문장에 대한 관계문장과 비교하여 제1 값을 산출하는 단계;상기 후보 문장에 대한 관계 문장을 기 설정된 함의 또는 모순에 관한 제2 규칙을 기반으로 상기 비교 문장에대한 관계 문장과 비교하여 제2 값을 산출하는 단계; 및상기 제1 값 및 상기 제2 값을 기반으로 일관성 점수를 산출하고, 상기 산출된 일관성 점수가 기 설정된 임계값이상인 경우 상기 생성된 후보 문장을 추가될 이야기로 결정하는 단계를 포함하는, 이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 규칙은 제1 확장규칙을, 상기 제2 규칙은 제2 확장규칙을 추가적으로 포함하고,상기 제1 값 및 상기 제2 값 산출을 위한 상기 관계 문장 비교 시에 상기 후보 문장 또는 상기 비교 문장에 대한 상기 관계 문장의 주어가 변경된 경우는, 상기 제1 확장규칙을 기반으로 상기 제1 값을 산출하고, 상기 제2확장규칙을 기반으로 상기 제2 값을 산출하는 것을 특징으로 하는 이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 일관성 점수의 산출 시, 상기 비교 문장의 종류 및 상기 비교 문장과 상기 후보 문장 간의 거리에 기반한가중치를 사용하는 것을 특징으로 하는 이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 규칙은,상기 비교 문장은 상기 직전 문장이고,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은, 유사와 연관된조합인 xEffect와 xNeed, xReact와 xAttr, xWant와 xIntent인 것을 특징으로 하는 이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제2 규칙은,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은,상기 비교 문장이 상기 첫 문장 및 상기 직전 문장인 경우, 함의와 연관된 조합인 oReact와 oReact, xAttr과xAttr, xReact와 xReact이고,상기 비교 문장이 상기 후보 문장보다 이전에 등장하는 상기 갈등 문장인 경우, 강한 함의와 연관된 조합인공개특허 10-2024-0059159-3-oReact와 oReact, xAttr과 xAttr, xReact와 xReact 및 함의와 연관된 조합인 oEffect와 oEffect, xEffect와xEffect, xIntent와 xIntent, xNeed와 xNeed이며,상기 비교 문장이 상기 후보 문장보다 이후에 등장하는 상기 갈등 문장인 경우, 함의와 연관된 조합인 xEffect와 xIntent, xReact와 xIntent 및 모순과 연관된 조합인 oWant와 xWant, xWant와 oWant인 것을 특징으로 하는이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 제1 확장규칙은,상기 비교 문장은 상기 직전 문장이고,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은, 유사와 연관된조합인 oEffect와 xNeed, oReact와 xAttr, oWant와 xIntent인 것을 특징으로 하는 이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서,상기 제2 확장규칙은,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은,상기 비교 문장이 상기 첫 문장 및 상기 직전 문장인 경우, 함의와 연관된 조합인 xReact와 oReact, oReact와xReact이고,상기 비교 문장이 상기 후보 문장보다 이전에 등장하는 상기 갈등 문장인 경우, 강한 함의와 연관된 조합인xReact와 oReact, oReact와 xReact 및 함의와 연관된 조합인 xEffect와 oEffect, oEffect와 xEffect이며,상기 비교 문장이 상기 후보 문장보다 이후에 등장하는 상기 갈등 문장인 경우, 함의와 연관된 조합인 oEffect와 xIntent, oReact와 xIntent 및 모순과 연관된 조합인 xWant와 xWant, oWant와 oWant인 것을 특징으로 하는이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서,상기 일관성 점수는,(a) 조정 파라미터값(b) 상기 가중치를 정규화한 값(c1) 상기 제2 값(c2) 상기 제1 값상기 비교 문장이 상기 첫 문장, 상기 직전 문장 및 상기 갈등 문장인 각각의 경우의 상기 (a)값, 상기 (b)값및 상기 (c1)값을 모두 곱하여 산출된 상기 각각의 경우에 대한 값들과, 상기 비교 문장이 상기 직전 문장인 경우의 상기 (a)값, 상기 (b)값 및 상기 (c2)값을 모두 곱하여 산출된 값을 모두 더하여 산출되는 것을 특징으로하는 이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제3항에 있어서,상기 가중치는,상기 비교 문장이 상기 첫 문장 및 상기 갈등 문장인 경우, 상기 후보 문장과의 거리가 가까울수록 보다 큰 값을 갖도록 문장 간 거리에 따른 값이 기 설정되고,상기 비교 문장이 상기 직전 문장인 경우, 상기 문장 간 거리에 따른 값과 연관된 고정 값을 갖도록 기 설정되공개특허 10-2024-0059159-4-는 것을 특징으로 하는 이야기 생성 방법."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "언어모델을 사용한 이야기 생성을 제공하기 위해 디지털 처리 장치에 의해 실행될 수 있는 명령어들의 프로그램이 유형적으로 구현되어 있으며, 디지털 처리 장치에 의해 판독될 수 있는 기록매체로서,제1항 내지 제9항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램이 기록된 컴퓨터 판독 가능한기록매체."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "언어모델을 사용한 이야기 생성 장치에 있어서,신호를 송수신하기 위한 통신부;메모리; 및상기 통신부 및 상기 메모리를 기능적으로 제어하기 위한 프로세서를 포함하고,상기 프로세서는,첫 문장, 직전 문장 및 갈등 문장을 포함하는 비교 문장으로 구성된 이야기에 추가될 후보 문장을 학습 데이터셋을 통해 파인튜닝된 언어모델을 사용하여 생성하는 동작;COMET 모델을 사용하여 상기 비교 문장 및 상기 생성된 후보 문장 각각에 대한 관계 문장들을 생성하는 동작;상기 후보 문장에 대한 관계 문장을 기 설정된 유사에 관한 제1 규칙을 기반으로 상기 비교 문장에 대한 관계문장과 비교하여 제1 값을 산출하는 동작;상기 후보 문장에 대한 관계 문장을 기 설정된 함의 또는 모순에 관한 제2 규칙을 기반으로 상기 비교 문장에대한 관계 문장과 비교하여 제2 값을 산출하는 동작; 및상기 제1 값 및 상기 제2 값을 기반으로 일관성 점수를 산출하고, 상기 산출된 일관성 점수가 기 설정된 임계값이상인 경우 상기 생성된 후보 문장을 추가될 이야기로 결정하는 동작을 포함하는, 이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제1 규칙은 제1 확장규칙을, 상기 제2 규칙은 제2 확장규칙을 추가적으로 포함하고,상기 제1 값 및 상기 제2 값 산출을 위한 상기 관계 문장 비교 시에 상기 후보 문장 또는 상기 비교 문장에 대한 상기 관계 문장의 주어가 변경된 경우는, 상기 제1 확장규칙을 기반으로 상기 제1 값을 산출하고, 상기 제2확장규칙을 기반으로 상기 제2 값을 산출하는 것을 특징으로 하는 이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 일관성 점수의 산출 시, 상기 비교 문장의 종류 및 상기 비교 문장과 상기 후보 문장 간의 거리에 기반한가중치를 사용하는 것을 특징으로 하는 이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제1 규칙은,상기 비교 문장은 상기 직전 문장이고,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은, 유사와 연관된조합인 xEffect와 xNeed, xReact와 xAttr, xWant와 xIntent인 것을 특징으로 하는 이야기 생성 장치.공개특허 10-2024-0059159-5-청구항 15 제13항에 있어서,상기 제2 규칙은,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은,상기 비교 문장이 상기 첫 문장 및 상기 직전 문장인 경우, 함의와 연관된 조합인 oReact와 oReact, xAttr과xAttr, xReact와 xReact이고,상기 비교 문장이 상기 후보 문장보다 이전에 등장하는 상기 갈등 문장인 경우, 강한 함의와 연관된 조합인oReact와 oReact, xAttr과 xAttr, xReact와 xReact 및 함의와 연관된 조합인 oEffect와 oEffect, xEffect와xEffect, xIntent와 xIntent, xNeed와 xNeed이며,상기 비교 문장이 상기 후보 문장보다 이후에 등장하는 상기 갈등 문장인 경우, 함의와 연관된 조합인 xEffect와 xIntent, xReact와 xIntent 및 모순과 연관된 조합인 oWant와 xWant, xWant와 oWant인 것을 특징으로 하는이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 제1 확장규칙은,상기 비교 문장은 상기 직전 문장이고,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은, 유사와 연관된조합인 oEffect와 xNeed, oReact와 xAttr, oWant와 xIntent인 것을 특징으로 하는 이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 제2 확장규칙은,상기 비교 문장에 대한 관계 문장의 타입 및 상기 후보 문장에 대한 관계 문장의 타입의 조합은,상기 비교 문장이 상기 첫 문장 및 상기 직전 문장인 경우, 함의와 연관된 조합인 xReact와 oReact, oReact와xReact이고,상기 비교 문장이 상기 후보 문장보다 이전에 등장하는 상기 갈등 문장인 경우, 강한 함의와 연관된 조합인xReact와 oReact, oReact와 xReact 및 함의와 연관된 조합인 xEffect와 oEffect, oEffect와 xEffect이며,상기 비교 문장이 상기 후보 문장보다 이후에 등장하는 상기 갈등 문장인 경우, 함의와 연관된 조합인 oEffect와 xIntent, oReact와 xIntent 및 모순과 연관된 조합인 xWant와 xWant, oWant와 oWant인 것을 특징으로 하는이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제3항에 있어서,상기 일관성 점수는,(a) 조정 파라미터값(b) 상기 가중치를 정규화한 값(c1) 상기 제2 값(c2) 상기 제1 값상기 비교 문장이 상기 첫 문장, 상기 직전 문장 및 상기 갈등 문장인 각각의 경우의 상기 (a)값, 상기 (b)값및 상기 (c1)값을 모두 곱하여 산출된 상기 각각의 경우에 대한 값들과, 상기 비교 문장이 상기 직전 문장인 경우의 상기 (a)값, 상기 (b)값 및 상기 (c2)값을 모두 곱하여 산출된 값을 모두 더하여 산출되는 것을 특징으로공개특허 10-2024-0059159-6-하는 이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,상기 가중치는,상기 비교 문장이 상기 첫 문장 및 상기 갈등 문장인 경우, 상기 후보 문장과의 거리가 가까울수록 보다 큰 값을 갖도록 문장 간 거리에 따른 값이 기 설정되고,상기 비교 문장이 상기 직전 문장인 경우, 상기 문장 간 거리에 따른 값과 연관된 고정 값을 갖도록 기 설정되는 것을 특징으로 하는 이야기 생성 장치."}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 언어모델을 사용한 이야기 생성 방법은, 첫 문장, 직전 문장 및 갈등 문장을 포함 하는 비교 문장으로 구성된 이야기에 추가될 후보 문장을 학습 데이터셋을 통해 파인튜닝된 언어모델을 사용하여 생성하는 단계; COMET 모델을 사용하여 상기 비교 문장 및 상기 생성된 후보 문장 각각에 대한 관계 문장들을 생 (뒷면에 계속)"}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 언어모델을 사용한 이야기 생성 방법에 관한 것으로, 보다 구체적으로는 관계 문장들을 사용하여 특 유하게 설정된 규칙을 기반으로 후보 문장의 적합성을 판단함으로써 갈등 요소를 반영하여 흥미로우면서도 이야 기의 일관성은 유지되도록 문장을 생성하는 언어모델을 사용한 이야기 생성 방법에 관한 것이다."}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "창작 예술 분야에서 인공지능의 역할은 점점 커져가는 추세다. 예술은 창의성과 독창성이 요구되는 관계로 오랫 동안 인간의 고유한 영역으로 여겨져 왔다. 그러나, 최근 기계학습(machine learning)의 눈부신 발전을 통해 인 공지능의 효율성과 정확성이 높아짐에 따라 창작 예술에까지 활용 영역을 넓혀가고 있다. 인간의 창작 과정을 모사하려는 노력은 오랜 기간에 걸쳐 인공지능을 비롯한 다양한 분야의 연구 주제였고 과거에는 서사 이론들에 근거하여 서사 창작 과정을 체계화하고 이를 컴퓨터 프로그램으로 구현한 소프트웨어들의 개발이 있었다. 인공지능 분야에서는 소설부터 영화 시나리오를 아우르는 다양한 장르의 이야기 자동 생성(story generation)이 큰 주목을 받고 있다. 현재, 일기예보나 스포츠 기사와 같은 정보 전달을 위한 텍스트는 로봇에 의해 점차 대체 되고 있는 상황이나, 이야기는 인간의 상상력과 창의성이 최고로 발현되는 고차원적 인지 영역이므로 이야기 자 동 생성은 인공지능과 자연어생성(Natural Language Generation) 분야에서 상당히 도전적인 연구 주제이다. 기존에 자동으로 일관된 맥락의 이야기를 생성하는 연구들은 존재하였으나, 이에 더해 독자들의 흥미를 유발할 수 있도록 재미있는 이야기를 생성하고자 하는 영역에 대해서는 연구가 부족한 실정이다. 이야기의 일관성을 유 지하면서도 갈등 요소를 이야기에 충분히 반영하여 주인공이 겪을 갈등을 다루면서 사건 전개를 흥미롭게 진행 해 나감으로써 독자들의 재미를 이끌어낼 수 있는 이야기 생성 방법이 요구된다."}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 바와 같은 종래 기술의 문제점을 해결하기 위한 것으로서, 관계 문장들을 사용하여 특유하게 설정된 규칙을 기반으로 후보 문장의 적합성을 판단함으로써 갈등 요소를 반영하여 흥미로우면서도 이야기의 일 관성은 유지되도록 문장을 생성하는 언어모델을 사용한 이야기 생성 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 제1 특징에 따른 언어모델을 사용한 이야기 생성 방법은, 첫 문장, 직전 문장 및 갈등 문장을 포함하 는 비교 문장으로 구성된 이야기에 추가될 후보 문장을 학습 데이터셋을 통해 파인튜닝된 언어모델을 사용하여 생성하는 단계; COMET 모델을 사용하여 상기 비교 문장 및 상기 생성된 후보 문장 각각에 대한 관계 문장들을 생성하는 단계; 상기 후보 문장에 대한 관계 문장을 기 설정된 유사에 관한 제1 규칙을 기반으로 상기 비교 문 장에 대한 관계 문장과 비교하여 제1 값을 산출하는 단계; 상기 후보 문장에 대한 관계 문장을 기 설정된 함의 또는 모순에 관한 제2 규칙을 기반으로 상기 비교 문장에 대한 관계 문장과 비교하여 제2 값을 산출하는 단계; 및 상기 제1 값 및 상기 제2 값을 기반으로 일관성 점수를 산출하고, 상기 산출된 일관성 점수가 기 설정된 임 계값 이상인 경우 상기 생성된 후보 문장을 추가될 이야기로 결정하는 단계를 포함하는 것을 특징으로 한다.본 발명의 제2 특징에 따른 언어모델을 사용한 이야기 생성을 제공하기 위해 디지털 처리 장치에 의해 실행될 수 있는 명령어들의 프로그램이 유형적으로 구현되어 있으며, 디지털 처리 장치에 의해 판독될 수 있는 기록매 체는, 본 발명의 제1 특징에 따른 언어모델을 사용한 이야기 생성 방법을 컴퓨터에서 실행시키기 위한 프로그램 이 기록된 것을 특징으로 한다. 본 발명의 제3 특징에 따른 언어모델을 사용한 이야기 생성 장치는, 신호를 송수신하기 위한 통신부; 메모리; 및 상기 통신부 및 상기 메모리를 기능적으로 제어하기 위한 프로세서를 포함하고, 상기 프로세서는, 첫 문장, 직전 문장 및 갈등 문장을 포함하는 비교 문장으로 구성된 이야기에 추가될 후보 문장을 학습 데이터셋을 통해 파인튜닝된 언어모델을 사용하여 생성하는 동작; COMET 모델을 사용하여 상기 비교 문장 및 상기 생성된 후보 문장 각각에 대한 관계 문장들을 생성하는 동작; 상기 후보 문장에 대한 관계 문장을 기 설정된 유사에 관한 제 1 규칙을 기반으로 상기 비교 문장에 대한 관계 문장과 비교하여 제1 값을 산출하는 동작; 상기 후보 문장에 대 한 관계 문장을 기 설정된 함의 또는 모순에 관한 제2 규칙을 기반으로 상기 비교 문장에 대한 관계 문장과 비 교하여 제2 값을 산출하는 동작; 및 상기 제1 값 및 상기 제2 값을 기반으로 일관성 점수를 산출하고, 상기 산 출된 일관성 점수가 기 설정된 임계값 이상인 경우 상기 생성된 후보 문장을 추가될 이야기로 결정하는 동작을 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따른 언어모델을 사용한 이야기 생성 방법은 다음과 같은 효과를 제공한다. 이야기에 추가될 후보 문장 및 기존 이야기를 구성하는 비교 문장에 대한 관계 문장들을 특유의 방식으로 설정 된 유사, 함의/모순에 관한 규칙을 기반으로 비교하여 산출된 일관성 점수를 통해 후보 문장의 적합성 여부를 판단함으로써 갈등 요소를 반영하여 흥미로우면서도 이야기의 일관성은 유지되도록 문장을 생성할 수 있고, 이 에 따라 최종 이야기의 완성도가 높아진다. 또한, 생성된 이야기 문장들의 적합성에 대한 판단이 추론 단계에서 이루어지기 때문에 문장이 생성되는 과정, 이야기의 종류에 대한 제한을 설정하지 않으므로 문장 생성 모델 혹은 데이터의 종류에 관계없이 범용적인 적용 이 가능하다."}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 대해서 실시예 및 도면을 참조하여 구체적으로 설명한다. 그러나, 이하의 설명은 본 발명을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 이야기의 생성에 있어서 중요한 점으로는, 전체적인 이야기의 맥락이 자연스러운지 여부와 생성된 이야기가 독 자들의 재미나 흥미를 충분히 유발할 수 있는지 여부 등이 있다. 인공지능을 사용한 이야기의 생성의 경우 주어 진 문장에서부터 이어지는 문장을 추가적으로 생성하며 이야기가 구성되는데, 새로이 생성되는 문장이 기존 이 야기의 맥락을 소정 정도 따르는 이야기의 일관성을 갖추는 선에서 충분한 재미를 유발하는지가 고려되어야 한 다.도 1은 개시된 실시 예에 따른 언어모델을 사용한 이야기 생성 방법의 전체적인 흐름도이다. 개시된 실시 예에서, 언어모델을 사용한 이야기 생성 방법은 전체적인 관점에서, 이야기를 이어갈 후보 문장들 을 생성하는 생성 프로세스 및 생성된 후보 문장들의 일관성과 갈등 요소를 고려하여 적합성을 판단하는 판단 프로세스의 2가지 프로세스로 구성될 수 있고, 이야기가 최종적으로 완성될 때까지 상기 프로세스들을 반복적으 로 수행할 수 있다. 생성 프로세스에서는 이야기 생성의 대상이 되는 이야기에서 기존에 주어진 문장들인 첫 문장, 갈등 문장 및 직 전 문장을 사용하여 학습된 언어모델(다시 말하면, 이야기 생성 모델)을 통해 이야기를 이어 나갈 후보 문장들 을 생성한다. 이야기를 생성하는 언어모델은 문자를 생성할 수 있는 능력을 가진 모델이면 되고, 모델의 종류 등에 의해 제한 되지 않는다. 개시된 일 실시 예에서, 이야기 생성을 위해 사용되는 언어모델은 GPT2(Generative Pre-trained Transformer 2)일 수 있다. 이야기를 생성하는 언어모델은 모델 학습을 위한 이야기 데이터셋을 사용하여 파인 튜닝(fine-tunning) 과정을 거쳐 이야기를 생성하는 방식이 학습된다. 판단 프로세스에서는 생성 프로세스에서 생성된 후보 문장들의 일관성과 갈등 요소를 고려하여 이야기의 추가적 인 문장으로서의 적합성을 판단한다. COMET 모델을 통해 첫 문장, 갈등 문장 및 직전 문장을 포함하는 비교 문장, 그리고 후보 문장에 대해 관계 문 장들(relational sentences)을 각각 생성한다. 관계 문장들은 총 9가지의 종류로 구성되며, 각각 oEffect, oReact, oWant, xAttr, xEffect, xIntent, xNeed, xReact, xWant로 정의된다. 이후, 비교 문장인 첫 문장, 갈등 문장 및 직전 문장의 3종류 각각에 대한 상기 관계 문장의 9가지 관계 타입을 추출하고 이를 후보 문장에 대한 관계 문장과 비교하여 각 후보 문장의 적합성을 판단하게 된다. 적합성을 구체적으로 판단하기 위해, 갈등 요소를 반영하면서도 일관성을 고려하여 최종 이야기의 완성도를 높 이도록 설정된 유사성 규칙 및 함의/모순 규칙의 2가지 규칙을 사용한다. 상기 2가지 적합성 판단 규칙의 사용 에 있어서 관계 문장의 방향과 관련하여 문장의 주어 변경 여부의 확인이 필요하고, 이를 반영하여 적합성 판단 이 이루어진다. 최종적으로 일관성 점수(coherency score)를 산출하여 후보 문장의 일관성 점수가 기 설정된 임계값 이상인 경 우 해당 후보 문장이 이야기에 추가될 문장으로서 적합하다고 판단한다. 이러한 일관성 점수의 산출에 있어서 비교 문장의 종류(즉, 첫 문장, 갈등 문장 및 직전 문장) 및 비교 문장과 후보 문장의 위치에 따른 거리에 기반 하여 가중치가 설정되고, 설정된 가중치를 사용하여 일관성 점수가 산출된다. 관계 문장 관계 문장이란, 하나의 문장으로부터 유추될 수 있는 상식 기반 정보를 표현하는 문장들로 관계 타입에 의해 얻 을 수 있는 정보의 종류가 달라진다. 관계 타입은 9가지 종류로서, oEffect, oReact, oWant, xAttr, xEffect, xIntent, xNeed, xReact, xWant가 있다. 여기서, x는 주어진 문장의 주체(subject)를 뜻하며, o는 주체 외의 3 자(others)를 의미한다. 보다 구체적으로, Effect는 해당 문장이 미치는 영향을 다루고, React의 경우 해당 문장이 일으키는 사건이 사 람들에게서 어떠한 심리적 반응을 일으킬 수 있는가에 대해 다룬다. Want는 그 인물의 목표를 예측하며, Attr는 특성(attribute)이 무엇일지를 추측한다. Intent는 문장에 나타난 사건을 일으킨 의도에 대한 정보이고, Need는 그 문장이 나오기 위해 어떠한 조건이 필요한가에 대한 정보이다. 주어 변경 확인 도 2는 개시된 실시 예에 따른 문장의 주어 변경 확인 과정을 개념적으로 도시한 도면이다. CAST 방식은 두 명의 등장인물에 의한 이야기를 다루고, 이야기를 이루는 각 문장의 주체가 순차적으로 변경되 는 경우만을 고려한다. 이에 따라, 관계 문장을 이용하여 생성되는 이야기의 일관성 여부를 판단할 시 주체에서 3자의 방향만을 고려하면 된다. 그러나, 일반적인 이야기의 경우 여러 사람이 등장인물로 등장할 수 있고, 각각 의 등장인물들은 등장 순서에 대한 제약 없이 자유롭게 그 서사가 풀어나가진다. 따라서, 연속되는 문장의 주어 변동 여부를 확인하여 관계 문장의 방향을 확인해 줄 필요가 있다. 먼저, Neural Coreference 라이브러리를 통해 문장으로부터 동일인물을 지칭하는 클러스터(cluster)를 뽑아준다. 도 2를 참조하면, 첫번째 문장의 \"Tina\"와 두번째 문장의 \"she\"는 동일인물을 의미한다. 그 다음, SpaCy 라이브러리를 사용하여 각 문장의 주어를 추출한다. 이후, 문장의 각 주어들이 앞서 추출한 클러스터 중 어느 것에 속해 있는지를 확인하여 연속되는 문장의 주어에 대한 변동 여부를 확인한다. 생성 문장 위치 도 3은 개시된 일 실시 예에 따른 문장 위치에 따라 반영되는 가중치를 도시한 표이다. 흥미도는 매력적인 이야기를 완성하기 위해 매우 중요한 요소 중 하나이며, 이를 고려하기 위해 갈등 요소를 반 영하여 이야기를 생성할 수 있다. 그러나 직전 문장과 달리 갈등 문장은 그 위치가 정해져 있으므로 생성되는 문장의 뒤, 혹은 앞에 존재할 수 있으며 또한, 해당 갈등이 일어나는 시기에 따라 갈등 요소에 대한 영향력이 약화 또는 강화될 수 있다. 이와 같은 문장 위치에 따른 영향력을 반영하기 위해 개시된 일 실시 예에서는 위치 적 가중치(positional weight)를 도 3의 표와 같이 정의할 수 있다. 이는 현재 생성되는 문장의 위치와 첫 문장, 혹은 갈등 문장 간의 거리에 따라 해당 생성 문장이 미치는 영향력이 달라짐을 의미한다. 개시된 실시 예에서, 일관성 점수 산출에 사용되는 가중치는, 비교 문장이 첫 문장 및 갈등 문장인 경우, 후보 문장과의 거리가 가까울수록 보다 큰 값을 갖도록 문장 간 거리에 따른 값이 기 설정되고, 비교 문장이 직전 문 장인 경우, 문장 간 거리에 따른 값과 연관된 고정 값을 갖도록 기 설정될 수 있다. 일 실시 예에서, 가중치는 비교 문장이 첫 문장 및 갈등 문장인 경우, 후보 문장과의 거리가 0, 1, 2, 3, 4인 경우, 각각 100%, 77.5%, 55%, 32.5%, 10%로 설정될 수 있고, 비교 문장이 직전 문장인 경우, 60%로 설정될 수 있다. 유사 관련 규칙 유사 관련 규칙은 후보 문장의 관계 문장과 직전 문장의 관계 문장 간의 유사도를 기준으로 판단한다. 두 명의 등장인물이 주체로 번갈아 등장하고 일관적 이야기를 생성하는 CAST 방식을 차용해 직전 문장의 oWant 와 후보 문장의 xIntent (oWant → xIntent), 직전 문장의 oEffect와 후보 문장의 xNeed (oEffect → xNeed), 그리고 직전 문장의 oReact와 후보 문장의 xAttr (oReact → xAttr) 관계 문장을 비교한다. 일 실시 예에서, 각 조합 쌍의 유사도는 SentenceBert를 통해 두 문장의 관계 문장들마다 임베딩 벡터 (embedding vector)를 추출하고, 코사인 유사도(cosine similarity)를 모든 조합에 대해 계산하여 산출할 수 있다. 또한, 각 관계 문장 쌍의 코사인 유사도가 0.5를 넘을 경우 1로, 그렇지 못할 경우 0으로 규정하여 모든 조합의 평균값을 최종 유사도로 정의할 수 있다. 함의/모순 관련 규칙 도 4는 개시된 실시 예에 따른 관계 문장들 간의 모든 조합 쌍에 대한 함의/모순의 정도를 분류 모델을 사용해 추론한 결과를 그래프들로 도시한 도면이다. 함의/모순 규칙을 정의하기 위한 기준 설정을 위해 기존의 이야기 데이터셋인 ROCStories를 활용한다. 상기 데 이터셋은 사람이 직접 구축한 5개의 문장으로 구성된 이야기로, 일관성 측면에서 우수한 데이터셋이다. 우선, 각 문장의 시간적 순서를 유지한 후 각 순서쌍에 포함된 두 문장으로부터 COMET 모델을 활용하여 관계 문 장들을 추출한다. 주어 변동에 대한 오차 범위를 줄일 수 있는 방향으로 측정을 하였고, 관계 문장들 간의 모든 조합 쌍으로부터 함의/모순의 정도를 분류 모델을 사용하여 추론한 후 결과값을 획득한다. 이에 따라, 도 4와 같은 결과를 획득할 수 있고, 상기 결과를 범위에 따라 강한 함의/모순, 함의/모순, 중립의 세 가지 유형으로 재분류 한다. 함의/모순의 경우 3가지 범주의 기댓값에 근접하는 30%를 넘는 경우를 의미하고, 강한 함의/모순의 경우 50%, 중립의 경우 함의/모순 둘 모두 30%가 넘는 경우를 의미한다. 중립의 경우는 맥락이 맞는다면 이야기 생성에 있 어서 비중이 작다는 의미로 판단되어 별도의 규칙으로 다루지 않는다. 도 5는 도 4의 분류 결과에서 함의와 관련된 부분을 추출한 표이다. 새롭게 생성되는 문장과 이야기의 첫 문장, 그리고 직전 문장을 살펴볼 때에는 일관성을 위해 이야기의 맥락을 해치지 않는지 여부와 문장 연결이 논리적인지 여부를 중점적으로 살펴볼 필요가 있다. 이에 따라, 상기 분류 결과 중 함의에 해당하는 부분만을 추출한 것이 도 5이다. 이 중 최소한의 규칙을 정의하기 위해 강한 함의에 해당하는 부분만 채용하여 최소 함의하도록 설정하였다. 다만, 도 5에서의 관계 중 xReact와 oReact 관계 문장 들이 강하게 함의하는 것으로 특정되었는데, 이는 ROCStories 데이터 특성상 일상에 관련된 이야기를 주로 다루어 등장인물들의 심리적 변화가 크게 없는 것이 원인으로 판단되었으므로 해당 관계 문장들은 최종 규칙에서 제 외한다. ROCStories의 경우 일상적인 이야기를 다룬 것이므로 갈등 요소에 대한 분석에는 난점이 있어 몇 가지의 조건 설정이 필요하다. 우선, 갈등 문장이 오기 전에 문장을 생성하는 경우, 갈등 문장의 등장 역시 직전 문장이나 첫 문장과 마찬가지로 그 이전에 오는 문장과의 일관성이 유지되어야 한다. 그러나, 주인공의 목표를 방해하는 내용의 갈등 문장 특성상 그 외의 문장보다 일관성이 유지되기는 쉽지 않다. 따라서, 도 5의 규칙 중 강한 함의 를 그대로 규칙에 적용시켜 최대한 갈등 문장이 두드러지지 않도록 조정한다. 이후, 갈등 문장 이후에 등장하는 문장을 생성하는 경우에는 갈등 문장이 부여하는 흥미로운 사건에 대한 비중 을 낮추지 않으면서 최대한으로 조화를 이루기 위해 갈등 문장이 주인공에게 미치는 여파와 심경의 변화에 대한 조건을 추가한다. 즉, 갈등 문장의 xEffect와 xReact는 생성되는 문장의 xIntent와 함의해야 한다. 또한, 갈등 문장이 외부적인 갈등을 다루는 경우 주인공과 그 외의 주체들이 원하는 것은 반대될 것이기에 xWant와 oWant, oWant와 xWant 간의 관계가 모순되어야 하는 조건을 추가한다. 마지막으로, 앞서 비교하는 두 문장의 주체가 바뀌었다고 판단한 경우에는 기존의 규칙을 그대로 적용하되 o를 x로, 그리고 x를 o로 바꾸어 준다. 따라서, 상술한 바와 같은 조건들을 모두 반영한 최종적인 함의/모순 관련 규칙은 도 6의 표와 같다. 도 6은 개시된 실시 예의 최종적인 유사, 함의/모순에 관한 규칙을 도시한 표이다. 도 6의 표를 참조하면 개시된 실시 예에서, 유사에 관한 규칙 및 함의/모순에 관한 규칙은 후보 문장 또는 비교 문장에 대한 관계 문장의 주어가 변경된 경우에는 주어 변경에 따른 확장된 규칙이 대신 적용될 수 있다. 이 경우, 기 설정된 유사에 관한 규칙 대신 기 설정된 유사에 관한 확장규칙을 기반으로 후보 문장에 대한 관계 문장을 직전 문장에 대한 관계 문장과 비교하여 SIM값을 산출하고, 기 설정된 함의/모순에 관한 규칙 대신 기 설정된 함의/모순에 관한 확장규칙을 기반으로 후보 문장에 대한 관계 문장을 첫 문장, 직전 문장 및 갈등 문장 각각에 대한 관계 문장과 비교하여 각각의 NLI값을 산출한다. 도 6의 표에서 \"직전 문장과의 비교\" 항목의 \"유사\" 항목에 포함되는 부분이 유사에 관한 규칙이고, 그 외 나머 지 부분이 함의/모순에 관한 규칙에 해당한다. 개시된 실시 예에서, 유사에 관한 규칙은, 비교 문장은 직전 문장이고, 비교 문장에 대한 관계 문장의 타입 및 후보 문장에 대한 관계 문장의 타입의 조합은, 유사와 연관된 조합인 xEffect와 xNeed, xReact와 xAttr, xWant 와 xIntent일 수 있다. 이는 도 6의 표에서 \"주어가 변경되지 않은 경우\" 항목 중 \"직전 문장과의 비교\" 항목의 \"유사\" 항목의 영역에 해당한다. 개시된 실시 예에서, 함의/모순에 관한 규칙은, 비교 문장에 대한 관계 문장의 타입 및 후보 문장에 대한 관계 문장의 타입의 조합은, 1) 비교 문장이 첫 문장 및 직전 문장인 경우, 함의와 연관된 조합인 oReact와 oReact, xAttr과 xAttr, xReact와 xReact이고, 2) 비교 문장이 후보 문장보다 이전에 등장하는 갈등 문장인 경우, 강한 함의와 연관된 조합인 oReact와 oReact, xAttr과 xAttr, xReact와 xReact 및 함의와 연관된 조합인 oEffect와 oEffect, xEffect와 xEffect, xIntent와 xIntent, xNeed와 xNeed이며, 3) 비교 문장이 후보 문장보다 이후에 등장하는 갈등 문장인 경우, 함의와 연관된 조합인 xEffect와 xIntent, xReact와 xIntent 및 모순과 연관된 조 합인 oWant와 xWant, xWant와 oWant일 수 있다. 이는 도 6의 표에서 \"주어가 변경되지 않은 경우\" 항목 중 \"직 전 문장과의 비교\" 항목의 \"유사\" 항목의 영역을 제외한 나머지 영역에 해당한다. 개시된 실시 예에서, 유사에 관한 확장규칙은, 비교 문장은 직전 문장이고, 비교 문장에 대한 관계 문장의 타입 및 후보 문장에 대한 관계 문장의 타입의 조합은, 유사와 연관된 조합인 oEffect와 xNeed, oReact와 xAttr, oWant와 xIntent일 수 있다. 이는 도 6의 표에서 \"주어가 변경된 경우\" 항목 중 \"직전 문장과의 비교\" 항목의 \"유사\" 항목의 영역에 해당한다. 개시된 실시 예에서, 함의/모순에 관한 확장규칙은, 비교 문장에 대한 관계 문장의 타입 및 후보 문장에 대한 관계 문장의 타입의 조합은, 1) 비교 문장이 첫 문장 및 직전 문장인 경우, 함의와 연관된 조합인 xReact와 oReact, oReact와 xReact이고, 2) 비교 문장이 후보 문장보다 이전에 등장하는 갈등 문장인 경우, 강한 함의와 연관된 조합인 xReact와 oReact, oReact와 xReact 및 함의와 연관된 조합인 xEffect와 oEffect, oEffect와 xEffect이며, 3) 비교 문장이 후보 문장보다 이후에 등장하는 갈등 문장인 경우, 함의와 연관된 조합인 oEffect 와 xIntent, oReact와 xIntent 및 모순과 연관된 조합인 xWant와 xWant, oWant와 oWant일 수 있다. 이는 도 6의 표에서 \"주어가 변경된 경우\" 항목 중 \"직전 문장과의 비교\" 항목의 \"유사\" 항목의 영역을 제외한 나머지 영 역에 해당한다. 일관성 점수 개시된 실시 예에서, 일관성 점수는 하기의 수학식 1을 통해 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, i는 초기(initial) 문장, c는 갈등(conflict) 문장, l은 직전(latest) 문장, g는 생성된(generated) 후보 문장, s는 유사(similarity)에 관한 규칙과 각각 관련된 값임을 의미하고, k는 조정 파라미터값, w는 문장 위치에 따른 가중치를 정규화(normalize)한 값이다. 개시된 실시 예에서, 도 6의 표를 기반으로 SIM값 및 NLI값 들을 산출한 후 상기 수학식 1과 같이 유형별로 상기 k 및 w를 곱하여 모두 더해주는 방식으로 일관성 점수가 산출될 수 있다. 다시 말하면, 일관성 점수는 비교 문장이 첫 문장, 직전 문장 및 갈등 문장인 각각의 경우의 조정 파라미터값, 가중치를 정규화한 값 및 NLI값을 모두 곱하여 산출된 각각의 경우에 대한 값들( , , )과, 비교 문장이 직전 문장인 경우의 조정 파라미터값, 가중치를 정 규화한 값 및 SIM값을 모두 곱하여 산출된 값( )을 모두 더하여 산출된다. 관계 문장에 대한 R값들은 하기 수학식 2와 같고, NLI값 및 SIM값은 하기 수학식 3 및 수학식 4를 통해 산출된 다. 또한, 수학식 3은 함의/모순에 관한 규칙을 기반으로, 수학식 4는 유사에 관한 규칙을 기반으로 적용된다. 수학식 2"}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, m: sampling 개수, R: COMET을 통해 추출된 관계 문장 m개이다. 수학식 3"}
{"patent_id": "10-2022-0140073", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, nli_score(): 두 관계 문장들 간의 함의/모순 규칙 만족 개수, NLI(): nli_score()의 평균이다. 수학식 4 여기서, cosine_similarity(): 두 관계 문장들 간 유사한 문장 개수, SIM(): cosine_similarity()의 평균이다. 도 7은 개시된 실시 예에 따른 언어모델을 사용한 이야기 생성 장치를 개념적으로 도시한 블록도이다. 언어모델을 사용한 이야기 생성 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 상기 AI 모듈을 포함하는 서버 등을 포함할 수 있으며, 프로세서, 메모리 및/또는 통신부를 포 함할 수 있다. 상기 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태 블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, 프로세서는 실시간 환경 또는 상황과 관련된 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여기서, 실시간 환경 또는 상황과 관련된 데이터를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데이터를 주고받을 수 있다. 여기서 신경망은 신경망 모델에서 발전한 딥 러닝 모델을 포함할 수도 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지능 학 습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 언어모델을 사용한 이야기 생성 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SDD) 등으로 구현할 수 있다. 메모리는 프로세서에 의해 액세 스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 개시된 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예를 들어, 머신 러닝 모델)을 저장할 수 있다. 한편, 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 데 이터 학습부는 데이터 분류/인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하 여 데이터를 어떻게 분류하고 인식할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학 습 데이터를 획득하고, 획득된 학습데이터를 머신러닝 모델에 적용함으로써, 머신러닝 모델을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 상기 장치에 탑재될 수 있다. 예를 들 어, 데이터 학습부는 인공지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 범용 프로세서 (CPU) 또는 그래픽 전용 프로세서(GPU)의 일부로 제작되어 상기 장치에 탑재될 수도 있다. 또한, 데이터 학습부는 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(또는 인스트럭션(instruction)을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록 매체(non-transitory computer readable media)에 저장될 수 있다. 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 애플리케이션에 의해 제공될 수 있다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있다. 학습 데이터 획득부 는 데이터를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있다. 예를 들어, 학 습 데이터 획득부는 학습 데이터로서, 신경망 모델에 입력하기 위한 환경 또는 상황과 관련된 데이터, 또 는 프로파일 기반으로 수집하여 가공한 데이터를 획득할 수 있다. 모델 학습부는 상기 획득된 학습 데이터를 이용하여, 신경망 모델이 소정의 데이터를 어떻게 분류할지에 관한 판단 기준을 가지도록 학습할 수 있다. 이 때 모델 학습부는 학습 데이터 중 적어도 일부를 판단 기 준으로 이용하는 지도 학습(supervised learning)을 통하여, 지도 없이 학습 데이터를 이용하여 스스로 학습함 으로써, 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 또는 학습에 따른 상황 판단의 결과가 올바른지에 대한 피드백을 이용하여 강화 학습(reinforcement learning)을 통하여, 신경망 모델을 학습 시킬 수 있다. 또한, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient decent)을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 학습부는 학습된 신경망 모델을 메모리에 저장할 수 있다. 모델 학습 부는 학습된 신경망 모델을 상기 장치와 유선 또는 무선 네트워크로 연결된 서버의 메모리에 저장할 수도 있다.데이터 학습부는 구축된 모델의 분석 결과를 향상시키거나, 구축된 모델의 생성에 필요한 리소스 또는 시 간을 절약하기 위해 학습 데이터 전처리부(미도시) 및 학습 데이터 선택부(미도시)를 포함할 수도 있다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여 모델 평가부(미도시)를 더 포함할 수도 있 다. 학습 데이터 전처리부는 획득된 데이터가 상황 판단을 위한 학습에 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있고, 학습 데이터 선택부는 학습 데이터 획득부에서 획득된 학습 데이터 또는 전처리부에서 전처리 된 학습 데이터 중 학습에 필요한 데이터를 선택할 수 있다. 모델 평가부는, 신경망 모델에 평가 데이터를 입력 하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 인식 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 통신부는 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 여기서 외부 전자 기기는 단말 또는 클라이언트로 정의될 수 있다. 또한, 상기 장치는 서버 또는 네트워크를 통해 구현될 수 도 있다. 한편, 도 7에 도시된 언어모델을 사용한 이야기 생성 장치는 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈로 지칭될 수 도 있다. 도 8은 개시된 실시 예에 따른 언어모델을 사용한 이야기 생성 방법을 도시한 플로우차트이다. 개시된 실시 예에서, 언어모델을 사용한 이야기 생성 방법은, 첫 문장, 직전 문장 및 갈등 문장을 포함하 는 비교 문장으로 구성된 이야기에 추가될 후보 문장을 학습 데이터셋을 통해 파인튜닝된 언어모델을 사용하여 생성하는 단계, COMET 모델을 사용하여 비교 문장 및 생성된 후보 문장 각각에 대한 관계 문장들을 생성하 는 단계, 후보 문장에 대한 관계 문장을 기 설정된 유사에 관한 제1 규칙을 기반으로 비교 문장에 대한 관 계 문장과 비교하여 제1 값을 산출하는 단계, 후보 문장에 대한 관계 문장을 기 설정된 함의 또는 모순에 관한 제2 규칙을 기반으로 비교 문장에 대한 관계 문장과 비교하여 제2 값을 산출하는 단계 및 제1 값 및 제2 값을 기반으로 일관성 점수를 산출하고, 산출된 일관성 점수가 기 설정된 임계값 이상인 경우 생성된 후보 문장을 추가될 이야기로 결정하는 단계를 포함할 수 있다. 다시 말하면, 210단계에서 생성 프로세스를 통해 후보 문장을 생성하고, 220단계 내지 250단계에서 판단 프로세 스를 통해 생성 프로세스에서 생성된 후보 문장들의 일관성과 갈등 요소를 고려하여 이야기의 추가적인 문장으 로서의 적합성을 판단한다. 좀 더 구체적으로, 220단계에서, 비교 문장 및 후보 문장에 대한 9가지 관계 타입의 관계 문장들을 생성하고, 230단계에서, 기 설정된 유사에 관한 규칙을 기반으로 후보 문장에 대한 관계 문장을 직전 문장에 대한 관계 문 장과 비교하여 SIM값을 산출하며, 240단계에서, 기 설정된 함의/모순에 관한 규칙을 기반으로 후보 문장에 대한 관계 문장을 첫 문장, 직전 문장 및 갈등 문장 각각에 대한 관계 문장과 비교하여 각각의 NLI값을 산출한다. 최종적으로, 250단계에서, 산출된 SIM값 및 NLI값들을 기반으로 각각에 대한 조정 파라미터값 및 가중치를 반영 하여 일관성 점수를 산출하고, 산출된 일관성 점수가 기 설정된 임계값 이상인 경우 생성된 후보 문장을 추가될 이야기로 결정한다. 이렇게 추가된 이야기는 갈등 요소가 반영되면서도 이야기의 일관성은 유지될 수 있다. 지금까지 살펴본 바와 같이, 개시된 실시 예의 언어모델을 사용한 이야기 생성 방법은, 관계 문장들을 사용하여 특유하게 설정된 규칙을 기반으로 후보 문장의 적합성을 판단함으로써 갈등 요소를 반영하여 흥미로우면서도 이 야기의 일관성은 유지되도록 문장을 생성할 수 있는 장점을 가진다. 한편, 본 발명의 실시예들은 컴퓨터로 읽을 수 있는 기록 매체에 컴퓨터가 읽을 수 있는 코드로 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있으며, 또한 캐리어 웨이브(예를 들어 인터넷을 통한 전송)의 형태로 구현하는 것을 포함한다. 또한, 컴 퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고 본 발명을 구현하기 위한 기능적인(functional) 프로그램, 코 드 및 코드 세그먼트들은 본 발명이 속하는 기술 분야의 프로그래머들에 의하여 용이하게 추론될 수 있다. 다양한 변형예가 본 발명의 범위를 벗어남이 없이 본 명세서에 기술되고 예시된 구성 및 방법으로 만들어질 수 있으므로, 상기 상세한 설명에 포함되거나 첨부 도면에 도시된 모든 사항은 예시적인 것으로 본 발명을 제한하 기 위한 것이 아니다. 따라서, 본 발명의 범위는 상술한 예시적인 실시예에 의해 제한되지 않으며, 이하의 청구 범위 및 그 균등물에 따라서만 정해져야 한다."}
{"patent_id": "10-2022-0140073", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 개시된 실시 예에 따른 언어모델을 사용한 이야기 생성 방법의 전체적인 흐름도이다. 도 2는 개시된 실시 예에 따른 문장의 주어 변경 확인 과정을 개념적으로 도시한 도면이다. 도 3은 개시된 일 실시 예에 따른 문장 위치에 따라 반영되는 가중치를 도시한 표이다. 도 4는 개시된 실시 예에 따른 관계 문장들 간의 모든 조합 쌍에 대한 함의/모순의 정도를 분류 모델을 사용해 추론한 결과를 그래프들로 도시한 도면이다. 도 5는 도 4의 분류 결과에서 함의와 관련된 부분을 추출한 표이다. 도 6은 개시된 실시 예의 최종적인 유사, 함의/모순에 관한 규칙을 도시한 표이다. 도 7은 개시된 실시 예에 따른 언어모델을 사용한 이야기 생성 장치를 개념적으로 도시한 블록도이다. 도 8은 개시된 실시 예에 따른 언어모델을 사용한 이야기 생성 방법을 도시한 플로우차트이다."}
