{"patent_id": "10-2017-0134784", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0046363", "출원번호": "10-2017-0134784", "발명의 명칭": "DRAM 기반 프로세싱 장치를 위한 확장 아키텍처", "출원인": "삼성전자주식회사", "발명자": "니우, 디민"}}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 메모리 장치를 포함하되,상기 복수의 메모리 장치 각각은 복수의 메모리 셀을 포함하고,상기 복수의 메모리 장치 각각은 메모리로서, 계산 장치로서, 또는 하이브리드 메모리 계산 장치(hybridmemory-computation unit)로서 동작하도록 구성 가능한 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 복수의 메모리 장치의 적어도 하나는 호스트로부터 작업(job)을 수신하도록 구성되는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 복수의 메모리 장치는 상기 복수의 메모리 장치에 대한 작업 분할, 상기 복수의 메모리 장치로의 데이터분배, 상기 복수의 메모리 장치로부터의 데이터 수집, 또는 상기 복수의 데이터 장치로의 작업 분배 중 적어도하나를 수행하도록 구성되는 호스트에 의해 제어되도록 구성되는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,메모리 장치 작업 맵핑(memory unit-job mapping) 정보를 저장하도록 구성되는 저장 장치를 더 포함하는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 복수의 메모리 장치 각각은 DRAM을 포함하는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,계산 장치들로서 구성되는 상기 복수의 메모리 장치는 작업을 전체로서 수행하는데 사용할 수 있는 또는 수행할수 있는 계산 장치들이 없으면 상기 작업의 해당 일부를 각각 수행하도록 구성 가능한 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 복수의 메모리 장치는 확장 가능한 클러스터 아키텍처 내에 배치되는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,복수의 메모리 컨트롤러를 더 포함하되,상기 복수의 메모리 컨트롤러 각각은 상기 복수의 메모리 장치 중 하나 이상을 제어하도록 구성되는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2018-0046363-3-제 8 항에 있어서,상기 복수의 메모리 장치 사이의 워크 플로(work flow)를 라우팅(routing)하기 위한 복수의 라우터(router)를더 포함하는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 복수의 라우터 중 적어도 하나는 상기 복수의 메모리 컨트롤러 중 해당하는 것에 내장되는 프로세서."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "복수의 메모리 장치를 포함하는 분산된 계산 시스템 내 워크 플로(work flow)를 제어하는 방법에 있어서,상기 복수의 메모리 장치들 중 하나 이상에 의해 수행되는 작업(job)을 포함하는 상기 워크 플로를 수신하는 단계;상기 복수의 메모리 장치 중 하나에 의해 상기 워크 플로에 따라 상기 작업 또는 상기 작업의 일부를 수행하는단계; 및상기 복수의 메모리 장치 중 상기 하나에 의해 상기 작업 또는 상기 작업의 상기 일부의 완료 후에 상기 워크플로 중 나머지를 상기 복수의 메모리 장치 중 다른 하나에 보내는 단계를 포함하는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 워크 플로는 작업 요청을 수신하는 호스트에 의해 생성되고, 그리고 상기 복수의 메모리 장치 중 적어도하나에 제공되는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 워크 플로는 상기 복수의 메모리 장치 중 하나 이상에 의해 생성되는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서,자원들의 가용성에 따라 계산 장치들로서 또는 메모리로서 상기 복수의 메모리 장치 중 하나 이상을 재구성하는단계를 더 포함하는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서,비동기식 통신 프로토콜이 상기 복수의 메모리 장치 사이의 통신에 사용되는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서,상기 워크 플로의 상기 나머지는 상기 워크 플로 내 모든 작업들이 완료되거나 실패로 끝날 때까지 상기 복수의메모리 장치 중 그 다음의 것에 보내지는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11 항에 있어서,복수의 메모리 장치 중 하나가 상기 작업을 전체적으로 완료할 수 없으면 상기 작업은 분할되는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "공개특허 10-2018-0046363-4-복수의 메모리 장치를 포함하는 분산된 계산 시스템 내 워크 플로(work flow)를 제어하는 방법에 있어서,제 1 작업을 수행하기 위해 상기 복수의 메모리 장치 중 하나에 의해 호스트로부터 제 1 요청을 수신하는 단계;상기 복수의 메모리 장치 중 상기 하나에 의해 상기 제 1 작업을 수행하는 단계;상기 제 1 작업의 결과를 상기 복수의 장치 중 상기 하나로부터 상기 호스트에 제공하는 단계; 및제 2 작업을 수행하기 위해 상기 복수의 메모리 장치 중 다른 하나에 의해 상기 호스트로부터 제 2 요청을 수신하는 단계를 포함하는 방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 복수의 메모리 장치 중 상기 다른 하나는 상기 호스트로부터 상기 제 1 작업의 상기 결과를 더 수신하는방법."}
{"patent_id": "10-2017-0134784", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 18 항에 있어서,상기 분산된 계산 시스템은 상기 제 1 작업 및 제 2 작업을 전송하고, 그리고 상기 제 1 작업 및 상기 제 2 작업의 결과들을 읽도록 구성되는 호스트를 더 포함하는 방법."}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "프로세서는 복수의 메모리 장치를 포함하고, 복수의 메모리 장치 각각은 복수의 메모리 셀을 포함하되, 복수의 메모리 장치 각각은 메모리로서, 계산 장치로서, 또는 하이브리드 메모리 계산 장치로서 동작하도록 구성 가능하 다."}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명에 따른 실시 예들의 하나 이상의 측면들은 DPU(DRAM-based processing unit)와 관련되고, 좀 더 구체적 으로, DPU 클러스터 아키텍처에 관한 것이다."}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "DPU(DRAM-based processing unit)는 예를 들면, GPU들(graphics processing units) 및 ASIC들(application specific integrated circuits)과 같은 다른 프로세서(processor) 및/또는 그래픽 가속기들(graphics accelerators)에 대한 대체 가속기로서 사용될 수 있다. DPU에 대응하는 새로운 에코시스템(ecosystem)은 DPU를 위한 향상된 또는 최적의 맵핑(mapping) 및 스케줄링(scheduling)을 달성하기 위해 설계된 드라이버들(drives) 및 라이브러리들(libraries)을 제공받을 수 있다. DPU는 재구성이 가능할 수 있고 프로그램이 가능할 수 있다. 예를 들어, DRAM 셀들에 의해 제공되는 로직은 예 를 들면, 덧셈기, 곱셈기, 등의 다른 연산들을 제공하기 위해 구성(또는 재구성)될 수 있다. 예를 들어, DPU는 약간의 수정들과 함께 3개 트랜지스터, 1개 커패시터(3T1C) / 1개 트랜지스터, 1개 커패시터(1T1C) DRAM 프로세 스 및 구조에 기초할 수 있다. DPU는 보통 특정 컴퓨팅 로직(예를 들면, 덧셈기들)을 포함하지 않기 때문에, 메 모리 셀들은 계산들을 위해 사용될 수 있다."}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 기술적 과제를 해결하기 위한 것으로, 본 발명은 DRAM 기반 프로세싱 장치를 위한 확장 아키 텍처를 제공할 수 있다."}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예들의 측면들은 복수의 DPU(DRAM-based processing unit)의 클러스터 아키텍처를 위한 방법들 및 연관된 구조들에 관한 것이다. 각 DPU는 예를 들면, 16 GB(giga-byte) 용량을 가질 수 있고 칩상에 8 M(million) 컴퓨팅 장치들을 가질 수 있 는 반면에, 예를 들면, 각 DPU는 10억개의 뉴런을 포함하는 인간의 뇌에 훨씬 미치지 못할 수 있다. 예를 들어, 수백에서 수천 개의 DPU들이 인간의 뇌와 유사한 신경망(NN)을 구현하기 위해 필요할 수 있다. 하나 이상의 예시적인 실시 예들에 따라, 다중 DPU 확장 아키텍처가 인간의 뇌와 유사한 신경망을 제공하기 위해 사용될 수 있 다. CPU/GPU의 확장과 비교하여, DPU는 메모리(예를 들면, DIMM) 확장과 좀 더 유사하고, 더 많은 수의 집적을 지원 한다. 또한, 통신 오버헤드가 감소될 수 있거나 최소화될 수 있다. 본 발명의 예시적인 실시 예들에 따라, 프로세서는 복수의 메모리 장치를 포함하고, 복수의 메모리 장치 각각은 복수의 메모리 셀을 포함하되, 복수의 메모리 장치 각각은 메모리로서, 계산 장치로서, 또는 하이브리드 메모리 계산 장치로서 동작하도록 구성 가능하다. 복수의 메모리 장치의 적어도 하나는 호스트로부터 작업을 수신하도록 구성될 수 있다. 복수의 메모리 장치는 복수의 메모리 장치에 대한 작업 분할, 복수의 메모리 장치로의 데이터 분배, 복수의 메 모리 장치로부터의 데이터 수집, 또는 복수의 데이터 장치로의 작업 분배 중 적어도 하나를 수행하도록 구성되 는 호스트에 의해 제어되도록 구성될 수 있다. 프로세서는 메모리 장치 작업 맵핑 정보를 저장하도록 구성되는 저장 장치를 더 포함할 수 있다. 복수의 메모리 장치 각각은 DRAM을 포함할 수 있다. 계산 장치들로서 구성된 복수의 메모리 장치는 작업을 전체로서 수행하는데 사용할 수 있는 또는 수행할 수 있 는 계산 장치들이 없으면 작업의 해당 일부를 각각 수행하도록 구성될 수 있다. 복수의 메모리 장치는 확장 가능한 클러스터 아키텍처 내에 배치될 수 있다. 프로세서는 복수의 메모리 컨트롤러를 더 포함하고, 복수의 메모리 컨트롤러 각각은 복수의 메모리 장치 중 하 나 이상을 제어하도록 구성될 수 있다. 프로세서는 복수의 메모리 장치 사이의 워크 플로를 라우팅하기 위한 복수의 라우터를 더 포함할 수 있다. 복수의 라우터 중 적어도 하나는 복수의 메모리 컨트롤러 중 해당하는 것에 내장될 수 있다. 본 발명의 예시적인 실시 예들에 따라, 복수의 메모리 장치를 포함하는 분산된 계산 시스템 내 워크 플로를 제 어하는 방법이 제공된다. 방법은 포함한다: 복수의 메모리 장치들 중 하나 이상에 의해 수행되는 작업을 포함하 는 워크 플로를 수신하는 단계; 복수의 메모리 장치 중 하나에 의해 워크 플로에 따라 작업 또는 작업의 일부를 수행하는 단계; 및 복수의 메모리 장치 중 하나에 의해 작업 또는 작업의 일부의 완료 후에 워크 플로 중 나머 지를 복수의 메모리 장치 중 다른 하나에 보내는 단계. 워크 플로는 작업 요청을 수신하는 호스트에 의해 생성될 수 있고, 그리고 복수의 메모리 장치 중 적어도 하나 에 제공될 수 있다. 워크 플로는 복수의 메모리 장치 중 하나 이상에 의해 생성될 수 있다. 방법은 자원들의 가용성에 따라 계산 장치들로서 또는 메모리로서 복수의 메모리 장치 중 하나 이상을 재구성하 는 단계를 더 포함할 수 있다. 비동기식 통신 프로토콜이 복수의 메모리 장치 사이의 통신에 사용될 수 있다. 워크 플로의 나머지는 워크 플로 내 모든 작업들이 완료되거나 실패로 끝날 때까지 복수의 메모리 장치 중 그 다음의 것에 보내질 수 있다. 복수의 메모리 장치 중 하나가 작업을 전체적으로 완료할 수 없으면 작업은 분할될 수 있다. 본 발명의 예시적인 실시 예들에 따라, 복수의 메모리 장치를 포함하는 분산된 계산 시스템 내 워크 플로를 제 어하는 방법이 제공된다. 방법은 포함한다: 제 1 작업을 수행하기 위해 복수의 메모리 장치 중 하나에 의해 호 스트로부터 제 1 요청을 수신하는 단계; 복수의 메모리 장치 중 하나에 의해 제 1 작업을 수행하는 단계; 제 1 작업의 결과를 복수의 장치 중 하나로부터 호스트에 제공하는 단계; 및 제 2 작업을 수행하기 위해 복수의 메모 리 장치 중 다른 하나에 의해 호스트로부터 제 2 요청을 수신하는 단계. 복수의 메모리 장치 중 다른 하나는 호스트로부터 제 1 작업의 결과를 더 수신할 수 있다. 분산된 계산 시스템은 제 1 작업 및 제 2 작업을 전송하고, 그리고 제 1 작업 및 제 2 작업의 결과들을 읽도록 구성되는 호스트를 더 포함할 수 있다."}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따라, 복수의 DPU가 배치되고 인간의 뇌와 유사한 신경망 능력을 제공할 수 있는 분산된 아키텍처를 갖는 클러스터 아키텍처가 제공될 수 있다."}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 실시 예들은 복수의 DPU(DRAM-based processing unit(DRAM 기반 프로세싱 장치))를 위한 방법들 및 연관된 구조들에 관한 것이고, 복수의 DPU 각각은 DPU 클러스터 아키텍처(cluster architecture) 내 노드 (node)로서 구성된다. 본 발명의 다양한 실시 예들에 따라, 각 DPU는 노드로서 언급될 수 있거나 또는 (복수의 DPU를 포함하는) 각 DPU 모듈이 노드로서 언급될 수 있다. 예시적인 실시 예들에서, 각 노드는 다중 DPU 모듈들 의 집합을 포함한다. 예를 들어, 노드는 복수의 DPU 모듈을 가진 서버를 포함할 수 있고, 여기서 각 DPU 모듈은 다중 DPU들(또는 DPU 장치들)을 갖는다. DPU들은 일반적인 초병렬 프로세서들(massively parallel processors) 또는 프로세싱을 제공할 수 있는 균일하게 병합된 메모리 및 가속기 풀(pool)을 구성한다. 각 노드 내 자원들은 하드웨어(예를 들면, 산술 논리 장치들(arithmetic logic units; ALUs)의 수)에 의해 제한될 수 있다. 본 발명의 예시적인 실시 예들에 따른 컴퓨터 프로세싱 아키텍처(또는 시스템)는 복수의 메모리 장치(예를 들면, DPU들)를 포함하는 프로세서로서 언급될 수 있고, 여기서 메모리 장치들 각각은 3T1C 메모리 셀들 및/또 는 1T1C 메모리 셀들을 포함할 수 있는 복수의 메모리 셀을 포함한다. 예시적인 실시 예들에 따라, 시스템의 자 원 요구에 기초하여 및/또는 유저 설계/선호들에 기초하여 메모리로서, 계산 장치로서, 또는 하이브리드 메모리 계산 장치(hybrid memory-computation unit)로서 동작하기 위해 실질적으로 동일한 구조를 갖는 메모리 장치들 을 구성(및/또는 재구성)하기 위해 유연성이 제공된다. 도 1은 본 발명의 예시적인 실시 예들에 따른 컴퓨터 프로세싱 아키텍처(100, 또는 시스템 아키텍처)의 개략 블 록도이다. 컴퓨터 프로세싱 아키텍처는 소프트웨어 스택(software stack)이 동작하기 위해 생성되는 하드웨어(150, 또는 하드웨어 레이어(layer))를 포함한다. 컴퓨터 프로세싱 아키텍처는 딥러닝(deep learning)을 가속하 기 위해 구성될 수 있고, 신경망(neural network)을 모방(emulate)하거나 모의 실험(simulation)할 수 있다. 하드웨어는, 예를 들면 GPU 모듈(GPU module, 152), TPU 모듈(tensor processing unit module; TPU module, 154), DPU 모듈, 및 다중 DPU 모듈을 포함한다. GPU 모듈 및 TPU 모듈 각각은 GPU 또는 TPU를 각각 포함할 수 있고 복수의 지원 칩을 포함할 수 있다. TPU는, 예를 들면, ASIC 상에서 구현될 수 있고, 머신 러닝(machine learning)을 위해 구성될 수 있거나 최적화될 수 있다. 예시적인 실시 예들에 따라, DPU들은 당업자에게 알려진 TPU 또는 GPU와 같은 다른 가속기들과 유사하게 작동할 수 있다. 도 1에서 도시된 DPU 모듈들은 두 형태의 인자들을 갖는다. 첫 번째 인자는 PCIe(Peripheral Component Interconnect Express) 버스 상의 DPU 모듈이고, 두 번째 인자는 DIMM(Dual In-line Memory Module) 버스 상의 다중 DPU 모듈이다. DPU 모듈이 도 1에서 1개 DPU 장치를 갖는 것으로 도시되었으나, DPU 모듈은 하나 이상의 내장형 DPU들을 포함하는 PCIe 장치일 수 있다. 다중 DPU 모듈이 도 1에서 다수의 DPU 장치들을 갖는 것으로 도시되었으나, 다수의 DPU 모듈은 하나 이상의 내장형 DPU들을 포함하는 DIMM일 수 있다. 컴퓨터 프로세싱 아키텍처의 하드웨어 내 DPU 모듈들은 PCIe 장치들 및/또는 DIMM들로 제한 되지 않으며, SoC(system on chip) 장치들 또는 DPU들을 포함할 수 있는 다른 유형의 메모리 장치들을 포함할 수 있는 것이 이해되어야 한다. DPU의 컴퓨팅 셀 어레이들(computing cell arrays)은 3개 트랜지스터, 1개 커패 시터 (3T1C) DRAM 컴퓨팅 셀 토포그래피(topography) 및/또는 1개 트랜지스터, 1개 커패시터 (1T1C) DRAM 컴퓨 팅 셀 토포그래피를 포함하도록 구성될 수 있다. 도 1에서 도시된 하드웨어는 GPU 모듈, TPU 모듈, DPU 모듈, 및 다수의 DPU 모듈 각 각을 1개씩 가지지만, 다른 실시 예들에 있어서, 하드웨어는 GPU 모듈들, TPU 모듈들, DPU 모듈들, 및/또는 다 중 DPU 모듈들의 임의의 다른 적합한 조합들을 포함할 수 있다. 예를 들어, 일 실시 예에 있어서, 하드웨어는 DPU 모듈들 및/또는 다중 DPU 모듈들만을 포함할 수 있다. 소프트웨어 스택은 하나 이상의 라이브러리들 및 드라이버들(140, 예를 들면, 라이브러리 및 드라이버 레 이어), 하나 이상의 프레임워크들(frameworks, 130, 예를 들면, 프레임워크 레이어), 및 하나 이상의 어플리케 이션들(applications, 120, 예를 들면, 어플리케이션 레이어)을 포함한다. 하나 이상의 라이브러리들은 예를 들 면, CUDA® 딥 신경망 라이브러리(CUDA® Deep Neural Network library; cuDNN)와 같은, NVIDIA®로부터 이용 가 능한 딥 신경망들에 대한 프리미티브들(primitives)의 GPU 가속화 라이브러리(GPU-accelerated library)이고 GPU 모듈을 동작시키기 위해 사용되는 신경망 라이브러리(neural network library; NNL, 142)를 포함할 수 있다. CUDA® 및 NVIDIA®는 NVidia Corporation, Santa Clara, CA의 등록된 상표들이다. 물론, 본 발명의 실 시 예들에 따라, 임의의 다른 적합한 상업적으로 이용 가능한 및/또는 주문 제작한(custom-made) 신경망 라이브 러리들이 CUDA® 딥 신경망 라이브러리 대신에 또는 CUDA® 딥 신경망 라이브러리에 더해 사용될 수 있다. 하나 이상의 드라이버들은 TPU 모듈을 구동하기 위해 TPU 드라이버를 포함할 수 있다. 하나 이상의 실시 예들에 따른 하나 이상의 라이브러리들 및 드라이버들은 DPU 하드웨어(예를 들면, DPU 모듈들(156, 158))를 지원하기 위해 DPU 라이브러리 및 DPU 드라이버를 포함할 수 있다. DPU 컴파일 러(DPU compiler, 149)는 DPU 모듈 및/또는 다중 DPU 모듈을 동작시키기 위해 DPU 라이브러리 및 DPU 드라이버를 이용하여 생성된 루틴들(routines)을 컴파일하는데 사용될 수 있다. 본 발명의 예시적 인 실시 예들에 따라, 하나 이상의 DPU 장치들을 포함하는 가속기를 가능하게 하기 위해, DPU 드라이버는 TPU 드라이버와 매우 유사할 수 있다. DPU 라이브러리는, 예를 들면, 어플리케이션 레이어에서 동작할 수 있는 다른 어플리케이션들을 위해 하드웨어 내 DPU 내 각 서브 어레이에 대한 최적의 맵핑 기능, 자원 할당 기능, 및 스케줄링 기능을 제공하도록 구성될 수 있다. 일 실시 예에 있어서, DPU 라이브러리는 이동, 더하기, 곱하기, 등과 같은 연산들을 포함할 수 있는 프레 임워크 레이어를 위한 고급의(high-level) 어플리케이션 프로그래밍 인터페이스(application programming interface; API)를 제공할 수 있다. 예를 들어, DPU 라이브러리는 또한 가속화된 딥러닝 프로세스를 위해 적용될 수 있는 포워드(forward) 및 백워드(backward) 콘볼루션(convolution), 풀링(pooling), 표준화 (normalization), 및 활성 레이어들과 같은, 그러나 이에 제한되지는 않는, 표준형의 루틴들의 구현들을 포함할 수 있다. 일 실시 예에 있어서, DPU 라이브러리는 콘볼루션 신경망(convolution neural network; CNN)의 전체 콘볼루션 레이어에 대한 계산을 맵핑하는 API 유사 기능을 포함할 수 있다. 또한, DPU 라이브러리는 콘볼루션 레이어 계산을 DPU로 맵핑하는 것을 최적화하기 위해 API 유사 기능들을 포함할 수 있다. DPU 라이브러리는 또한 태스크(task, 배치(batch), 출력 채널, 픽셀들(pixels), 입력 채널들, 콘볼루션 커 널들(kernels)) 내의 임의의 개별의 또는 다수의 병렬처리들(parallelisms)을 칩, 뱅크(bank), 서브 어레이 (sub-array) 및/또는 매트(mat) 레벨에서 해당 DPU 병렬처리들로 맵핑함으로써 자원 할당을 향상시키거나 최적 화하기 위한 API 유사 기능들을 포함할 수 있다. 또한, DPU 라이브러리는 성능(즉, 데이터 이동 플로 (flow)) 및 파워 소모간의 균형을 유지하는 초기화 및/또는 런타임에서 최적의 DPU 구성을 제공하는 API 유사 기능들을 포함할 수 있다. DPU 라이브러리에 의해 제공되는 다른 API 유사 기능들은 뱅크당 활성 서브 어 레이들의 수, 활성 서브 어레이들당 입력 특징 맵들의 수, 특정 맵의 분할, 및/또는 콘볼루션 커널의 재사용 방 식을 설정하는 것과 같은 디자인 노브 유형(design-knob-type)의 기능들을 포함할 수 있다. 계속해서 다른 API"}
{"patent_id": "10-2017-0134784", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "유사 기능들은 각 서브 어레이에 대해 콘볼루션 컴퓨팅(convolution computing), 채널 요약(channel sum up), 및/또는 데이터 디스패치(data dispatching)와 같은 특정 태스크를 할당함으로써 추가적인 자원 할당 최적화를 제공할 수 있다. 피연산자들이 정수 및 확률적인 수 사이에서 변환되면, DPU 라이브러리는 정밀도 제약들을 충족시키면서 오버헤드(overhead)를 감소시키거나 최소화하는 API 유사 기능들을 포함할 수 있다. 정밀도가 예상보다 낮은 경우, DPU 라이브러리는 확률적인 표현을 위한 추가 비트들을 이용하여 값을 다시 계산하거 나, 또는 CPU와 같은 다른 하드웨어로 태스크를 떠넘기는(offload) API 유사 기능들을 포함할 수 있다. DPU 라이브러리는 또한 DPU 내 활성화된 서브 어레이들을 동시에(또는 일제히) 스케줄링하고, 그리고 컴퓨 팅 연산들에 의해 데이터 이동이 숨겨지도록 데이터 이동을 스케줄링하는 API 유사 기능들을 포함할 수 있다. DPU 라이브러리의 다른 측면은 더 나아간 DPU 개발을 위한 확장 인터페이스를 포함할 수 있다. 일 실시 예 에 있어서, DPU 라이브러리는 표준 유형의 연산들(즉, 더하기, 곱하기, 최대/최소, 등) 이외의 연산들이 제공될 수 있도록 노어(NOR) 및 쉬프트(shift) 로직을 이용하여 기능을 직접적으로 프로그램하기 위한 인터페이 스를 제공할 수 있다. 확장 인터페이스는 또한 DPU 라이브러리에 의해 특별히 지원되지 않는 동작이 라이 브러리 및 드라이버 레이어에서 SoC 컨트롤러, CPU(central processing unit)/GPU 요소 및/또는 CPU/TPU 요소로 떠넘기게 될 수 있도록 인터페이스를 제공할 수 있다. DPU 라이브러리의 또 다른 측면은 DPU 메모 리가 컴퓨팅을 위해 사용되지 않고 있을 때 메모리의 확장으로서 DPU의 메모리를 사용하기 위해 API 유사 기능 을 제공할 수 있다. DPU 드라이버는 DPU 하드웨어 레이어를 시스템으로 통합하기 위해 하드웨어 레이어에서의 DPU, DPU 라이브러리, 및 상위 레이어에서의 운영 체제(operating system; OS) 사이의 인터페이스 연결을 제공하도 록 구성될 수 있다. 즉, DPU 드라이버는 DPU를 시스템 OS 및 DPU 라이브러리에 드러낸다. 일 실시 예 에 있어서, DPU 드라이버는 초기화에서 DPU 제어를 제공할 수 있다. 일 실시 예에 있어서, DPU 드라이버 는 DRAM 유형의 주소들 또는 DRAM 유형의 주소들의 시퀀스들의 형태로 명령어들을 DPU로 전송할 수 있고 DPU로의 및 DPU의 밖으로의 데이터 이동을 제어할 수 있다. DPU 드라이버는 DPU-CPU 및/또는 DPU-GPU 통신 을 다루는 것과 더불어 다중 DPU 통신을 제공할 수 있다. DPU 컴파일러는 DPU를 제어하기 위해 DPU 라이브러리에서부터 DPU 드라이버에 의해 사용되는 메 모리 주소들의 형태의 DPU 명령어들로 DPU 코드를 컴파일할 수 있다. DPU 컴파일러에 의해 생성된 DPU 명 령어들은 DPU, 벡터 명령어들, 및/또는 모여진(gathered) 벡터, 읽기 동작(read-on-operation) 명령어들의 1개 및/또는 2개 행들에서 동작하는 단일 명렁어들일 수 있다. DPU 모듈은, 예를 들면, 통신을 위해 PCIe 인터페이스를 사용할 수 있고, 그리고 다중 DPU 모듈은 통 신을 위해 DIMM 인터페이스를 사용할 수 있다. DPU 모듈은 DPU에 더해 컨트롤러 및 하나 이상의 DRAM 칩들 /모듈들을 포함한다. 다중 DPU 모듈은 둘 이상의 DPU들을 제어하도록 구성된 컨트롤러를 포함할 수 있다. 예를 들어, 다중 DPU 모듈 내 DPU들은 프로세싱 또는 작업들(jobs)이 하나 이상의 DPU들 사이에 분산되거 나 공유될 수 있게 DPU들이 배치된 분산된 DPU 클러스터 아키텍처를 갖도록 구성될 수 있다. 예를 들어, 다중 DPU 모듈은 인간의 뇌와 유사한 신경망 용량을 제공할 수 있는 클러스터 아키텍처를 가질 수 있다. 신경망 용량 을 제공하기 위해, 클러스터 아키텍처는 복수의 DPU, 복수의 DPU 모듈, 및 복수의 DPU 노드들로 구성될 수 있다. 여기서, 복수의 DPU 모듈 각각은 다수의 DPU들을 포함하고, 복수의 DPU 노드 각각은 다수의 DPU 모듈들을 포함한다. 클러스터 아키텍처 내 DPU들 각각은 모든 메모리로서, 모든 계산으로서, 또는 조합(예를 들면, 하이 브리드 메모리 계산 아키텍처)으로서 구성될 수 있다. 프레임워크는 제 1 머신 러닝 소프트웨어 라이브러리 프레임워크(machine learning software library framework, 132), 제 2 머신 러닝 소프트웨어 라이브러리 프레임워크를 포함할 수 있고, 그리고/또는 DPU 들을 가능하게 하기 위해 당업자에게 알려진 하나 이상의 다른 오픈 소스 프레임워크들(open source frameworks, 136)로 확장할 수 있다. 예시적인 실시 예들에서, 기존의 머신 러닝 라이브러리들은 프레임워크들 에 사용될 수 있다. 예를 들어, 프레임워크들은 터치 7(Touch 7) 및/또는 텐서플로(Tensor Flow), 또는 당업자 에게 알려진 임의의 다른 적합한 프레임 워크 또는 프레임워크들을 포함할 수 있다. 예시적인 실시 예들에서, 프레임워크 레이어는 유저 친화적인 인터페이스를 라이브러리 및 드라이버 레이 어 및 하드웨어 레이어에 제공하도록 구성될 수 있다. 일 실시 예에 있어서, 프레임워크 레이어(13 0)는 어플리케이션 레이어에서 넓은 범위의 어플리케이션들과 호환 가능하고 DPU 하드웨어 레이어를 유저에 대해 투명하게 하는 유저 친화적인 인터페이스를 제공할 수 있다. 다른 실시 예에 있어서, 프레임워크 레이어는 정량 측정 기능들(quantitation functions)을 터치 7 유형의 어플리케이션들 및 텐서플로 유형의 어플리케이션들과 같은, 그러나 이에 제한되지 않는, 기존의, 종래의 방법들에 더하는 프레임워크 확장들을 포 함할 수 있다. 일 실시 예에 있어서, 프레임워크 레이어는 정량 측정 기능들을 트레이닝 알고리즘(training algorithm)에 더하는 것을 포함할 수 있다. 다른 실시 예에 있어서, 프레임워크 레이어는 나누 기, 곱하기 및 제곱근의 쉬프트 근사 방법들(shift approximated methods)이 되기 위해 나누기, 곱하기 및 제곱 근의 기존의 배치 표준화(batch-normalization) 방법들을 재지정(override)할 수 있다. 계속해서 다른 실시 예 에 있어서, 프레임워크 레이어는 유저가 계산을 위해 사용되는 비트들 수를 설정하게 하는 확장을 제공할 수 있다. 또 다른 실시 예에 있어서, 프레임워크 레이어는 다중 DPU API를 감싸는 용량을 DPU 라이브러리 및 드라이버 레이어로부터 프레임워크 레이어로 제공할 수 있고 그 결과 유저가 다수의 GPU들의 사용 과 유사하게 하드웨어 레이어에서 다수의 DPU들을 사용할 수 있다. 프레임워크의 또 다른 특징은 유저가 하드웨어 레이어에서 DPU 또는 GPU 중 어느 하나에 기능들을 할당하게 할 수 있다. 프레임워크들의 위에는 이미지 태그(image tag, 122), 셀프 드라이브 알고리즘(self-drive algorithm, 124), 인공지능(artificial intelligence, 126), 및/또는 음성 연구/인식을 포함할 수 있는 하나 이상의 어플리 케이션들, 및/또는 당업자에게 알려진 임의의 다른 적합하고 바람직한 어플리케이션들이 구현될 수 있다. 일부 실시 예들에 있어서, 호스트는 작업들을 분할하고 DPU 클러스터 아키텍처 내 각각의 분할된 것에 대해 데 이터/작업들을 분배/수집할 수 있다. 일부 실시 예들에 있어서, 하나 이상의 라우터들(routers)은 DIMM 컨트롤 러 내부에 내장될 수 있고, 비동기식 통신 프로토콜(asynchronous communication protocol)에 따라 동작할 수 있다. 다른 실시 예들에 있어서, 라우터들은 DIMM 또는 다른 메모리 컨트롤러들의 외부(또는 DIMM 또는 다른 메 모리 컨트롤러로부터 분리)에 설치될 수 있다. 본 발명의 실시 예들이 주로 DRAM들(예를 들면, 3T1C 또는 1T1C DRAM들)에 관하여 설명되었으나, 본 발명은 이 에 제한되지 않는다. 예를 들어, 일부 실시 예들에 있어서, 임의의 다른 적합한 메모리가 메모리 기반 프로세싱 장치들(예를 들면, 메모리 장치들)을 생성하기 위해 DRAM들 대신에 사용될 수 있다. 가속기들의 풀 및 메모리의 풀을 포함하는 일반적인 아키텍처에 있어서, 호스트는 보통 가속기들 및 메모리 사 이에 인터페이스를 제공한다. 호스트가 가속기들 및 메모리 사이에 끼워진 이러한 아키텍처 때문에, 호스트는 가속기들 및 메모리 사이에 병목 현상(bottleneck)을 생성할 수 있다. 이러한 병목현상을 감소시키고 방지하기 위해, 본 발명에 따른 예시적인 실시 예들에 있어서, 호스트는 가속기 들 및 메모리 사이에 위치하지 않는다. 대신에, 가속기들은 복수의 DPU를 이용하여 구현될 수 있다. 예를 들어, 각 DPU 모듈은 복수의 DPU 및 DPU 컨트롤러를 포함할 수 있으며 SoC로서 구현될 수 있다. 또한, 복수의 DPU 모 듈은 DPU 라우터에 함께 연결된다. DPU 라우터는 DPU 컨트롤러와 동일한 SoC에 구현될 수 있다. 그러나, 본 발 명은 이에 제한되지 않고, 컨트롤러 및 라우터는 DPU 컨트롤러를 포함하는 SoC 외부에서 구현될 수 있다. 또한 DPU 모듈들 각각은 DPU 라우터를 포함할 수 있거나 또는 1개 DPU 라우터는 둘 이상의 DPU 모듈들에 의해 공유될 수 있다. 도 2는 본 발명의 예시적인 실시 예들에 따른 분산된 DPU 클러스터 아키텍처의 도식의 블록도이다. 도 2의 분산된 DPU 클러스터 아키텍처에서, 복수의 DPU 모듈(202, 204, 208) 및 DRAM 모듈은 컨트롤 러 및 라우터들(210, 212, 214, 216)을 통해 서로 연결된다. 단지 DRAM 모듈이 메모리로서 구성된 것으로 도시되었으나, 본 발명은 이에 제한되지 않고, 임의의 DPU/DRAM 모듈들이 메모리로서, 계산 장치로서(또는 프로 세싱 장치/프로세서), 또는 하이브리드 메모리 계산 장치로서 구현될 수 있다. DPU들 및 DRAM들은 각각 가속기 들 및 메모리 모듈들(또는 메모리)이라고 할 수 있고, 그들은 실질적으로 서로 동일한 하드웨어 구조들을 갖고, DPU들 및 DRAM들은 계산들 및 저장을 위해 각각 다르게 구성된 DPU들(또는 메모리 장치들)로서 볼 수 있다. 또 한, 예시적인 실시 예들에 따라, DPU들 각각은 가속기로서의 (계산들을 위해) 또는 메모리로서 (저장을 위해) 기능을 하도록 재구성될 수 있거나, 또는 가속기 및 메모리의 기능들 모두를 갖도록 재구성될 수 있다. 호스트는 또한 컨트롤러 및 라우터 중 하나를 통해 DPU들과 연결된다. 아키텍처는 모든 워크 (work, 예를 들면, 작업들)가 호스트에 의해 생성되는, 호스트 중심 아키텍처(host centric architecture)이라고 할 수 있다. 여기서, 호스트는 어떤 자원들이 네트워크상에 있는지를 알고, 그리고 특정 명령 또는 명령들 및 워크 로드(work load)를 하나 이상의 컨트롤러들 및 라우터들(210, 212, 214, 216)을 통해 특정 DPU로 전송할 것이다. 예시적인 실시 예들에 있어서, DPU들은 단지 계산들 및 저장을 수행하는 반면 에 스케줄링 및 맵핑과 관련된 모든 태스크들(tasks)을 수행하는 것은 호스트의 책임이므로 성능은 호스트(22 0)에 얽매일 수 있다. 예를 들어, 다수의 DPU들이 1개 서버/컴퓨터/노드 내에 위치하면, DPU들은 직접적으로 서로 통신할 수 있다. 동 일한 서버/컴퓨터/노드 내에 있지 않은 DPU들에 대해, 그들은 하나 이상의 라우터들 및/또는 스위치들(예를 들면, 컨트롤러들 및 라우터들(210, 212, 214, 216))을 통해 서로 통신할 수 있고, 이것은 인터넷과 같은, 하나 이상의 통신 경로들을 통해 일어날 수 있다. DPU 모듈들 각각은, 예를 들면, DPU 모듈(202-1)은 동일한 DPU 컨트롤러(예를 들면, 컨트롤러 SoC)에 연결된 복 수의 DPU를 포함한다. 동일한 DPU 모듈상의 DPU들은 버스(bus) 기반의 연결(예를 들면, 계층 버스 기반의 연 결)일 수 있는 DIMM 내부 연결을 통해 DPU 컨트롤러에 연결된다. 이런 이유로, 동일한 DPU 모듈상의 이들 DPU들 은 SoC 컨트롤러가 제어하는 DPU들과 동일한 DPU 모듈에 탑재된 DIMM상의 SoC 컨트롤러와 함께 제어될 수 있다. 여기서, DPU 내 SoC 컨트롤러는 명령들/데이터를 수신하고 DPU 모듈 내 DPU들을 관리하는 책임이 있을 수 있다. DPU 모듈들은 DPU 모듈들이 메모리 컨트롤러에 연결되는 DIMM 상호간의 연결을 통해 서로 연결될 수 있고, 여기 서 메모리 컨트롤러는 라우터에 연결된다. 라우터는 DPU들/DRAM들을 메모리/가속기 네트워크에 연결할 수 있다. 도 2의 분산된 DPU 클러스터 아키텍처에서, 예를 들면, 메모리 및 가속기들 사이의 인터페이스에서 병목 현상은 균일하게 병합된 메모리 및 가속기 풀을 제공함으로써 방지될 수 있다. 예를 들어, 호스트가 네트워크의 끝에서 컨트롤러 및 라우터에 연결됨에 따라, 메모리 및 가속기들 사의의 호스트에 의해 야기되는 병 목 현상은 거의 없거나 없다. 예를 들어, 메모리 및 가속기들의 풀은 유연한 네트워크 연결을 갖는다. 또한, 각 노드는 가속기(DPU) 또는 메모리(DRAM) 중 어느 하나로서 구성될 수 있다. 일부 실시 예들에 있어서, 각 노드는 가속기 및 메모리 특징들을 모두 포함하는 가속기 메모리 하이브리드(accelerator-memory hybrid)로서 동작할 수 있다. 예를 들어, 각 노드는 다수의 DPU 모듈들의 집합일 수 있고, 복수의 DPU 모듈을 갖는 서버를 포함할 수 있고, 여기서 각 DPU 모듈은 다수의 DPU 장치들을 포함할 수 있다. 이런 이유로, 본 발명의 하나 이상의 예시적인 실시 예들에 따른 분산된 DPU 클러스터 아키텍처에서, 균일하게 병합된 메모리 및 가속기 풀은 일반적인 초병렬(massively parallel) 프로세서들을 생성하기 위해 제공된다. 여 기서, 각 노드의 자원은 하드웨어(예를 들면, ALU들의 수, 등)에 의해 제한될 수 있다. 즉, ALU들의 제한된 수 는 DPU가 제공할 수 있는 최대 메모리 용량 또는 최대 계산 용량을 결정할 수 있다. DPU 클러스터 아키텍처는 재구성 가능한 메모리/계산 자원들을 제공하고, 그리고 각 DPU 노드 내 모든 자원들은 모든 메모리로서, 모든 계산 장치로서, 또는 메모리 및 계산 장치의 조합(또는 하이브리드)로서 구성될 수 있다. 이 방법으로, 각 노드에서 저장 및/또는 계산 요구들에 따라, 저장 및/또는 계산 자원들의 낭비는 방지될 수 있거나 감소될 수 있다. 이것은 노드들 각각이 더 많은 저장 자원들 및 더 많은 계산 자원들을 제공하기 위 해 필요하거나 유저가 원하는 만큼 사용 중에 구성될 수 있거나 재구성될 수 있기 때문이다. 도 3은 본 발명의 예시적인 실시 예에 따라 내장된 라우터들을 갖는 분산된 DPU 클러스터 아키텍처의 도식 의 블록도이다. 도 3의 아키텍처은 라우터들이 DPU 컨트롤러에 결합된다는 점에서 도 2의 아키텍처와 상이하다. 분산된 DPU 클러스터 아키텍처는 또한 호스트 중심 아키텍처라고 할 수 있다. 도 2의 DPU 클러스터 아키텍처와 유사하게, 도 3에서, 가속기 풀 및 메모리 풀 사이의 인터페이스에 위치한 호 스트가 없기 때문에 가속기 풀 및 메모리 풀 사이의 인터페이스에서의 병목 현상은 감소되거나 방지될 수 있다. 도 3의 분산된 DPU 클러스터 아키텍처에 따라, 복수의 DPU 모듈/복수의 DRAM 모듈(302, 304, 306, 312, 314, 316, 322, 324, 326, 332, 334, 336)은 행들 및 열들로 배치된다. DPU 모듈들 중 하나가 네트워크의 끝에서 호스트와 연결되기 때문에, 호스트에 의해 야기되는 병목 현상은 작거나 없다. 본 발명의 예시적인 실시 예에 따른 호스트 중심 아키텍처에서, 처음에 호스트는 상이한 DPU들에 대해 워크 또 는 워크 일부를 생성할 것이다. 예를 들어, 제 1 워크(또는 제 1 워크 일부)는 제 1 DPU에 할당될 수 있고, 그 리고 제 2 워크(또는 제 2 워크 일부)는 제 2 DPU에 할당될 수 있다. 그 다음, 호스트는 워크 플로(work flow) 의 제 1 워크를 제 1 DPU로 전송할 수 있다. 워크 플로는 또한 제 2 DPU로 전송되는 제 2 워크를 포함할 수 있 다. 제 1 DPU가 자신의 워크를 끝낼 때, 제 1 DPU는 (호스트에 의해 맵핑된/스케줄된) 다음 단계가 어디인지 알 고 있으므로 제 1 DPU는 결과를 호스트로 다시 전송하지 않고 제 2 DPU로 직접 전송할 수 있다. 예를 들어, 제 1 DPU가 그것의 워크를 끝낼 때, 제 1 DPU는 다른 계산들을 위해 중간 데이터(또는 중간 결과)를 제 2 DPU로 직 접 전송할 수 있다. 그러므로, 제 1 DPU가 중간 데이터를 호스트에 다시 전송하고 호스트가 수신된 중간 데이터 를 제 2 DPU에 전송할 필요가 없다. 이런 이유로, 도 3의 DPU 클러스터 아키텍처에서, DPU 노드들은 호스트 없 이 서로 통신할 수 있다. 예를 들어, 호스트는 제 1 DPU에 요청하여 데이터를 제 2 DPU로 보내기 위해 단지 명 령 또는 명령들을 전송할 수 있고, 데이터를 이동시키는 것은 SoC 컨트롤러의 책임이다. 이것은 호스트가 네트 워크 내 모든 자원들을 알고 있기 때문에 예시적인 실시 예들에 따른 도 2 및 도 3의 호스트 중심 아키텍처 내 에서 가능하고, 맵핑 및 스케줄링을 수행하는 것은 호스트의 책임이다. 이런 이유로, 호스트는 계산들의 각 단계에서 관련될 필요가 없을 수 있다. 본 발명의 일부 다른 예시적인 실시 예들에 따라, 네트워크 상의 어느 장 치도 네트워크가 어떻게 생겼는지 또는 네트워크상의 어느 자원들이 이용 가능한지를 반드시 알아야 할 필요가 없는 시스템 아키텍처가 제공된다. 도 3에서 도시된 바와 같이, 모듈들 중 단지 하나(즉, DRAM 모듈)가 메모리로서 구성되고, 반면에 모듈들 중 나머지는 프로세싱/계산 모듈들로서 구성된다. 다른 실시 예들에 있어서, 모듈들 중 하나 이상은 메모리 모 듈들 또는 하이브리드 계산/메모리 모듈들로서 구성될 수 있다. DPU/DRAM 모듈들 각각은 복수의 DPU 및 DPU 컨 트롤러(즉, 컨트롤러 SoC)를 포함하고, 그렇게 함으로써 모듈들 각각은 DPU 모듈 또는 DRAM 모듈로서 구성 또는 재구성될 수 있다. 또한, 동일한 DPU/DRAM 모듈 내에서, 모든 DPU들/DRAM들이 실질적으로 서로 동일한 하드웨어 를 갖고 있을지라도 DPU들 중 하나 이상은 메모리로서 구성될 수 있고 반면에 DPU들 중 다른 하나 이상은 계산 장치들(또는 프로세싱 장치들)로서 구성될 수 있다. 예를 들어, 일부 실시 예들에서, 라우터들은 DIMM 컨트롤러 SoC와 함께 구현된다. 또한, 적절한 DIMM 상호간 통 신을 보장하기 위해 비동기식 통신 프로토콜이 사용될 수 있고, 여기서 핸드셰이크(handshake)가 사용될 수 있 다. 다른 실시 예들에 있어서, DDR(double data rate)과 같은, 동기식 프로토콜이 사용될 수 있다. 호스트(35 0)가 DPU/DRAM 모듈들 사이가 아닌 네트워크의 일단에 위치하므로, 보다 적은 호스트 대역폭 사용이 발생할 수 있고 호스트에 의해 야기된 임의의 병목 현상은 감소되거나 제거될 수 있다. 일부 예시적인 실시 예들에 있어서, DPU들/DRAM들 또는 DPU 모듈들/DRAM 모듈들이 분산된 DPU 클러스터 아키텍 처에 배치되는 반면에, 그들은 계속해서 호스트를 중심으로 제어될 수 있다. 이러한 실시 예들에서, 호스트는 DPU/DRAM 작업 맵핑 정보(job mapping information)를 유지한다. 작업 맵핑 정보는 소프트웨어 및/또는 드라이 버의 형태일 수 있다. 네트워크에서, 신경망 변수들 및 다른 유용한 데이터는 클러스터 내 노드들 중 하나에 있 을 수 있는 DRAM에 저장될 수 있다. 본 발명의 예시적인 실시 예들에 따라, 두 개의 분리된 호스트 중심 아키텍처들/구성들이 제공된다. 제 1 호스 트 중심 아키텍처에서, 호스트는 워크 플로 내 모든 워크 로드를 제 1 DPU로 보낼 것이고, 제 1 DPU는 워크 로 드의 나머지 및/또는 결과를 제 2 DPU로 보낼 것이다. 제 2 DPU는 계산들을 수행할 것이고 결과 및 워크 플로 내 워크 로드의 나머지를 제 3 DPU에 보낼 것이고, 이러한 방식이다. 제 2 호스트 중심 아키텍처에서, 각 단계 에서, 호스트는 데이터를 다시 읽고, 다음 워크를 생성하고 다음 워크를 중간 데이터(예를 들면, 이전 DPU(들) 에서 수행된 계산들의 결과)와 함께 다음 DPU 또는 DPU들에 전송한다. 다른 예시적인 실시 예들에서, 하나 이상 의 DPU들이 호스트에 의한 맵핑/스케줄링 없이 작업들을 포함하는 워크 플로들을 생성하는 것이 가능하고, 그리 고 호스트가 심지어 필요하지 않을 수 있는 애드 혹(ad hoc) 제어가 제공될 수 있다. 전술한 예시적인 실시 예 들 각각은 도 1, 도 2, 및 도 3 중 임의의 것에서 설명된 적합한 시스템/하드웨어 아키텍처를 이용하여 구현될 수 있다. 도 4는 호스트에 의한 중앙 집중식 제어가 구현된 본 발명의 예시적인 실시 예들에 따라 호스트에 의한 분산된 DPU 클러스터 제어의 순서도이다. 도 4의 단계 400에서, 호스트는 작업 요청을 수신한다. 단계 402에서, 호스트는 메모리에 저장된 DPU/DRAM 작업 맵핑 테이블을 확인한다. 작업 맵핑 테이블 확인 과정에서, 호스트는 작업의 변수들을 저장하는 DRAM들을 찾는 다. 예를 들어, 신경망 어플리케이션들을 위해, 호스트는 NN 변수들을 갖는 DRAM들을 찾을 수 있다. 호스트는 또한 사용 가능한 DPU 자원들을 찾는다. 단계 404에서, DPU가 개별적으로 작업을 끝낼 수 없으면, 호스트는 작업을 둘 이상의 DPU 자원들로 분할한다. 예를 들어, 작업은 제 1 작업, 제 2 작업, 등으로 분할될 수 있고 그들은 둘 이상의 다른 DPU 자원들, 예를 들 면, 제 1 작업은 제 1 DPU에, 제 2 작업은 제 2 DPU에, 이러한 방식으로 할당될 수 있다. 단계 406에서, 호스트는 워크 플로를 생성한다. 예를 들어, 호스트는 각 작업 및/또는 작업의 각 분할된 부분에 대해 자원 번호 및 작업 번호(예를 들면, (resource#, Job#))를 할당한다. 예를 들어, 워크 플로(WF)는 다음의 서식을 갖는다: WF = [(resource1, job1), (resource2, job2), (resource3, job3) . . . (resourceN, jobN), (host, Done)], 등등. 여기서, 작업들은 DPU들/DRAM들(또는 DPU/DRAM 모듈들)에 관한 것일 수 있다. 본 발명에 따른 예시적인 실시 예들에 있어서, 워크 플로는 당업자에게 알려진 임의의 다른 적합한 서식을 가질 수 있다. 단계 408에서, 호스트는 워크 플로를 호스트에 연결된 DPU/DRAM에 전송한다. 단계 410에서, DPU/DRAM(또는 DPU/DRAM 모듈)은 워크 플로 패키지(work flow package)를 읽는다. 워크 플로 맨 위의 자원이 현재 자원과 일치 하면, 그것은 워크 플로의 맨 위의 작업을 수행하고, 그 다음 워크 플로로부터 쌍들(resource#, job#)을 제거한다. 그 다음 워크 플로의 나머지는 하나 이상의 다른 자원들(예를 들면, DPU들)로 보내진다. 일치하지 않으면, DPU/DRAM는 워크 플로를 다음 쌍(resource#, job#)의 자원일 수 있는 제 1 자원을 향하여 보낸다. 그러나, 본 발명은 임의의 특정한 방식에 제한되지 않고, 당업자에게 알려진 임의의 적합한 방식이 사용될 수 있다. 일단 워크 플로가 완료되면, 호스트는 모든 작업들이 끝났는지 판별하고, 이것은 모든 쌍들(resource#, job#)이 0부 터 N까지 끝난 것을 의미한다. 도 5는 호스트가 각 계산 단계에서 적극적인 역할을 취하는 본 발명의 예시적인 실시 예들에 따른 분산된 DPU 클러스터 제어의 순서도이다. 도 5의 단계 500에서, 호스트는 워크 요청을 DPU로 전송하고, 그 다음 단계 502에서, 호스트는 DPU로부터 계산 들의 결과를 읽거나, 또는 DPU는 결과를 호스트로 되돌려 보낼 수 있다. 그 다음 단계 504에서 호스트는 워크 요청 및/또는 DPU로부터의 결과를 다음 DPU에 전송하고, 단계 506에서 다음 DPU로부터 계산들의 결과를 읽고, 단계 508에서 모든 워크가 완료될 때까지 이런 방식으로 진행된다. 이러한 호스트 중심 아키텍처에서, 호스트는 각 계산 단계에 개입되고, 워크 플로 및 DPU들 사이의 데이터 플로를 더 활발히 제어한다. 도 4 및 도 5의 순서도에서 설명된 호스트 중심 아키텍처의 중앙 집중식 제어와 달리, 본 발명의 하나 이상의 예시적인 실시 예들에 따라, 분산된 DPU 클러스터 아키텍처는 중앙 집중식 제어 없이 또는 작거나 최소의 중앙 집중식 제어와 함께 애드 혹 방식으로 제어될 수 있다. 도 6은 애드 혹 제어가 구현된 본 발명의 예시적인 실시 예들에 따른 분산된 DPU 클러스터 제어의 순서도이다. 예를 들어, 일부 예시적인 실시 예들에 따른 애드 혹 제 어 메커니즘에서, 도 6의 단계 600에서 도시된 바와 같이 각 DPU는 작업(또는 작업들의 워크 플로)을 생성할 수 있다. 또한, 자원 테이블의 필요가 없을 수 있고, DPU/DRAM 작업 맵핑 정보가 메모리 내에 저장되어야 한다는 요구도 없을 수 있다. 이러한 애드 혹 방식에 따라, 단계 602에서 도시된 바와 같이 작업(또는 작업들의 워크 플로)을 생성하는 DPU(예를 들면, DPU0)는 작업 또는 작업의 일부를 끝내고, 그 다음 단계 604에서 도시된 바와 같이 나머지 작업(들) 및/또는 작업의 일부(들)을 (예를 들면, 워크 플로의 나머지) 라우팅 정보와 함께 하나 이상의 인접 DPU 노드들(예를 들면, 다음 DPU 또는 DPU1,2,3, 등)로 전송한다. 그 다음, 단계 606에서, 다음 DPU(또는 DPU들)는 작업(들) 및/또는 작업의 일부(들)을 끝낸다. 단계 608에서 도시된 바와 같이 작업(또는 작 업의 일부)를 끝내고, 나머지 작업(들) (또는 작업(들)의 일부(들))을 전송하는 프로세서는 모든 작업이 완료되 거나 작업 할당이 실패(예를 들면, 자원이 더 이상 사용 가능하지 않은 경우)할 때까지 반복된다. 애드 혹 제어의 특징들 중 일부는 호스트 서버가 필요 없는 것이고, 큰 클러스터 정보를 유지할 필요가 없고, 거대한 클러스터(예를 들면, 인간의 뇌의 신경망과 유사한 크기의 신경망을 생성하기 위한 기존의 네트워크들 내 이용할 수 있는 DPU들의 가능한 100배부터 1000배까지)가 지원될 수 있다는 것이다. 그러나, 제어가 중앙 집 중식이 되지 않는 한, 자원 관리는 덜 최적화될 수 있고, 결국 실패들이 발생할 수 있다. 실패들의 중요성은 크 게 어플리케이션들에 의존할 수 있다. 일부 어플리케이션들에 대해, 실패들은 중대할 수 있고, 다른 어플리케이 션들에서는 중대하지 않을 수 있다. 예를 들어, 인간의 뇌의 행동(behavior)을 흉내를 내는 인공지능(AI) 어플 리케이션에 있어서, 그것은 무언가를 기억할 수 있거나 그렇지 않을 수 있다. 또한, 그것은 어느 시점에서 무언 가를 기억할 수 있으나 다른 시점에서는 그것을 기억할 수 없다. 본 발명의 실시 예들에 따른 DPU 시스템 아키 텍처는 대규모 신경망 어플리케이션에 사용된다면, 일부 실패들은 용인될 수 있다. 또 다른 실시 예들에 있어서, 분산된 DPU 클러스터 아키텍처는 하이브리드 중앙 집중식 및 애드 혹 제어들과 함 께 동작할 수 있다. 예를 들어, DPU들 및/또는 DPU 모듈들의 일부는 호스트에 의해 제어될 수 있고, 반면에 DPU 들 및/또는 DPU 모듈들의 다른 것들은 애드 혹 방식으로 제어될 수 있다. 다른 예를 들어, DPU들 및/또는 DPU 모듈들의 적어도 일부는 그들의 제어가 중앙 집중식 제어 및 애드 혹 제어 사이를 원하는 대로 또는 필요에 따 라 전환할 수 있게 재구성될 수 있다. 그러므로, 본 발명의 실시 예들은 복수의 DRAM 기반 프로세싱 장치(DPUs)가 배치되고 인간의 뇌와 유사한 신경 망 능력을 제공할 수 있는 분산된 아키텍처를 갖는 클러스터 아키텍처에 관한 것이다. DPU 클러스터는 재구성 가능한 메모리/계산 자원들을 제공하고, 그렇게 함으로써 DPU 노드 내 모든 자원들은 모든 메모리로서, 모든 계 산으로서, 또는 결합된 것(즉, 하이브리드 메모리 계산 장치)으로서 구성될 수 있다. 호스트 중심 아키텍처를 갖는 일부 실시 예들에 있어서, 각 분할을 위해 호스트는 작업들을 분할할 수 있거나 및/또는 데이터/작업들을 분산시키거나/수집할 수 있다. 여기서, 호스트는 작업들을 끝내고 나머지 작업들 및/ 또는 결과 데이터를 다른 DPU들에 보내기 위해 DPU들에 대한 워크 플로들을 생성하고 전송할 수 있거나, 또는 호스트는 수신함으로써 각 계산 단계를 제어할 수 있고 작업들과 함께 결과 데이터를 다른 DPU들에 보낼 수 있 다. 다른 실시 예들에 있어서, 클러스터 아키텍처의 제어는 하나 이상의 DPU들이 작업들/워크 플로들을 생성할수 있고, 작업을 완료하고, 및/또는 작업들/워크 플로들의 나머지를 네트워크 내 다른 DPU들로 전송할 수 있는 애드 혹으로 제공될 수 있다. 다른 실시 예들에 있어서, 중앙 집중식 제어 및 애드 혹 제어의 하이브리드는 DPU/DRAM 클러스터 아키텍처를 제어하기 위해 구현될 수 있다. 라우터는 비동기식 통신 프로토콜에 따라 동작할 수 있고, DIMM 컨트롤러 내부에 내장될 수 있다. 비록 여기에서 제 1, 제 2, 제 3 등의 용어들은 다양한 요소들, 성분들, 영역들, 층들 및/또는 섹션들을 설명하 기 위해 사용되지만, 이러한 요소들, 성분들, 영역들, 층들 및/또는 섹션들은 이러한 용어들로 인해 제한되지 않는 것으로 이해될 것이다. 이러한 용어들은 다른 요소, 성분, 영역, 층, 또는 섹션으로부터 하나의 요소, 구 성, 영역, 층 또는 섹션을 구별하기 위해 사용된다. 따라서, 후술하는 제 1 요소, 성분, 영역, 층, 또는 섹션은 본 발명의 사상 및 범위를 벗어나지 않고, 제 2 요소, 성분, 영역, 층, 또는 섹션을 지칭 할 수 있다. 예를 들어, 본 명세서에서 설명된 본 발명의 실시 예들에 따라 관련 있는 장치 또는 성분(또는 관련 있는 장치 들 또는 성분들)은 임의의 적합한 하드웨어(예를 들면, ASIC(application-specific integrated circuit)), 펌 웨어(예를 들면, DSP 또는 FPGA), 소프트웨어, 또는 소프트웨어, 펌웨어, 및 하드웨어의 적합한 조합을 이용하 여 구현될 수 있다. 예를 들어, 관련 있는 장치(들)의 다양한 성분들은 하나의 집적 회로(integrated circuit; IC) 또는 분리된 IC 칩들에 형성될 수 있다. 또한, 관련 있는 장치(들)의 다양한 성분들은 플렉서블 인쇄 회로 필름(flexible printed circuit film), TCP(tape carrier package), PCB(printed circuit board)에 구현될 수 있거나, 또는 하나 이상의 회로들 및/또는 다른 장치들로서 동일한 기판 위에 형성될 수 있다. 또한, 관련 있는 장치(들)의 다양한 성분들은 하나 이상의 프로세서들에서 실행되고, 하나 이상의 컴퓨팅 장치들에서, 본 명세서 에서 설명된 다양한 기능들을 수행하기 위해 컴퓨터 프로그램 명령어들을 실행하고 다른 시스템 성분들과 상호 작용하는 프로세스 또는 스레드(thread)일 수 있다. 컴퓨터 프로그램 명령어들은 예를 들면, RAM(random access memory)과 같은, 표준 메모리 장치를 이용하여 컴퓨팅 장치에서 구현될 수 있는 메모리에 저장된다. 컴퓨터 프 로그램 명령어들은 예를 들면, CD-ROM, 플래시 드라이브(flash drive) 등과 같은 다른 일시적이지 않은(non- transitory) 컴퓨터 판독 가능 매체에 저장될 수 있다. 또한, 본 발명의 당업자는 본 발명의 예시적인 실시 예 들의 사상 및 범위를 벗어나지 않고 다양한 컴퓨팅 장치들의 기능은 하나의 컴퓨팅 장치에 통합되거나 집적되거 나, 또는 특정 컴퓨팅 장치의 기능은 하나 이상의 다른 컴퓨팅 장치들에 걸쳐 분산될 수 있음을 인식해야 한다. 또한, 하나의 요소, 구성 요소, 영역, 층, 및/또는 섹션이 두 요소들, 구성 요소들, 영역들, 층들, 및/또는 섹 션들 사이에서 있는 것으로 언급되면, 두 요소들, 구성 요소들, 영역들, 층들, 및/또는 섹션들 사이에 단지 요 소, 구성 요소, 영역, 층, 및/또는 섹션이 있을 수 있거나, 또는 하나 이상의 사이의 요소들, 구성 요소들, 영 역들, 층들, 및/또는 섹션들이 또한 존재할 수 있음이 또한 이해될 것이다. 본 명세서에서 사용된 용어는 특정 실시 예들을 설명하기 위한 것이고 본 발명을 제한하려는 것으로 의도되지 않는다. 본 명세서에서 사용된 바와 같이, 단수 형태들은 문맥상 명백히 다르게 나타내지 않는 한 복수 형태들 도 포함하도록 의도된다. “구성되는”, “구성되고 있는”, “포함하는”, 및 “포함하고 있는” 용어들이 본 명세서에서 사용되면 기술된 특징들, 정수들, 단계들, 동작들, 요소들, 및/또는 구성 요소들의 존재를 명시하되, 그러나 하나 이상의 특징들, 정수들, 단계들, 동작들, 요소들, 요소들, 구성 요소들, 및/또는 이들의 그룹의 존재를 불가능하게 하지 않는 것으로 더 이해될 것이다. 본 명세서에서 사용된 바와 같이, “그리고/또는” 용어는 하나 이상의 연관된 열거된 항목들의 임의의 것 또는 모든 조합들을 포함한다. “적어도 하나”, “중 하나”, 및 “로부터 선택된” 같은 표현들은 요소들의 전체 리스트를 수정하고 그리고 리스트의 개별 요소들을 수정하지 않는다. 또한, 본 발명의 실시 예들을 기술할 때 \"할 수 있다\"의 사용은 \"본 발명의 하나 이상의 실시 예들\"을 나타낸다. 또한, \"예시\" 용어는 예 또는 그림을 의미한다. 본 명세서에서 사용된 바와 같이, “사용”, “사용되는”, 및 “사용된” 용어들은 “이용”, “이용되는”, 및 “이용된” 용어들과 밀접한 것으로 각각 간주 될 수 있다. 본 발명의 하나 이상의 실시 예들에 관하여 설명된 특징들은 본 발명의 다른 실시 예들의 특징들과 함께 사용하 기 위해 가능할 수 있다. 예를 들어, 제 3 실시 예가 본 명세서에서 명확하게 설명되지 않을 수 있어도, 제 1 실시 예에 있어서 설명된 특징들은 제 3 실시 예를 형성하기 위해 제 2 실시 예에 있어서 설명된 특징들과 결합 될 수 있다. 당업자는 프로세스는 하드웨어, 펌웨어(예를 들면, ASIC을 통해), 또는 소프트웨어, 펌웨어, 및/또는 하드웨어 의 임의의 조합을 통해 실행될 수 있는 것을 또한 인식해야 한다. 또한, 프로세스의 단계들의 시퀀스는 고정되지 않고, 당업자에 의해 인식된 것으로서 임의의 원하는 시퀀스로 변경될 수 있다. 변경된 시퀀스는 모든 단계 들 또는 단계들의 부분을 포함할 수 있다. 특정한 구체적인 실시 예들에 관해 본 발명이 설명되었지만, 당업자는 설명된 실시 예들의 변형들을 고안하는데 어려움이 없을 것이고, 본 발명의 범위 및 사상으로부터 벗어나는 것은 결코 없을 것이다. 또한, 다양한 분야들 의 당업자에게, 본 명세서에서 설명된 발명 자체는 다른 응용들을 위한 다른 과제들 및 적응들의 해법들을 제안 할 것이다. 본 발명 및 본 발명의 사상 및 범위를 벗어나지 않고 개시의 목적으로 본 명세서에서 선택된 발명의 실시 예들로 만들어질 수 있는 본 발명의 변경들 및 수정들의 그러한 모든 사용들을 청구 범위에 포함시키는 것 이 출원인의 의도이다. 따라서, 본 발명의 본 실시 예들은 제한적이 아니라 모든 측면들을 설명하기 위한 것으 로서 간주되고, 본 발명의 범위는 첨부된 청구항들 및 이들의 등가물들에 의해 나타난다."}
{"patent_id": "10-2017-0134784", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 이들 및 다른 특징들 및 측면들은 명세서, 청구항들, 및 첨부 도면들을 참조하여 인식되고 이해될 것 이다: 도 1은 본 발명의 예시적인 실시 예들에 따른 컴퓨터 프로세싱 아키텍처의 개략 블록도이다. 도 2는 본 발명의 예시적인 실시 예들에 따른 분산된 DPU 클러스터 아키텍처의 도식의 블록도이다. 도 3은 본 발명의 예시적인 실시 예에 따라 내장된 라우터들을 갖는 분산된 DPU 클러스터 아키텍처의 도식의 블 록도이다. 도 4는 호스트에 의한 중앙 집중식 제어가 구현된 본 발명의 예시적인 실시 예들에 따라 호스트에 의한 분산된 DPU 클러스터 제어의 순서도이다. 도 5는 호스트가 각 계산 단계에서 적극적인 역할을 취하는 본 발명의 예시적인 실시 예들에 따른 분산된 DPU 클러스터 제어의 순서도이다. 도 6은 애드 혹 제어가 구현된 본 발명의 예시적인 실시 예들에 따른 분산된 DPU 클러스터 제어의 순서도이다."}
