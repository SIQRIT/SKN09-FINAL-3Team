{"patent_id": "10-2022-0083591", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0104106", "출원번호": "10-2022-0083591", "발명의 명칭": "음성 합성 방법, 장치, 전자 기기 및 저장 매체", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "가오, 쩡쿤"}}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 합성 방법에 있어서, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는 단계;상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 상기타겟 템플릿 오디오의 제2 음향 특징을 추출하는 단계;상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계; 및상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성하는 단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계는, 상기 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트를 획득하는 단계;상기 합성하고자 하는 텍스트와 상기 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 획득하는 단계;상기 제1 음향 특징에서 상기 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하고, 상기 제2 음향 특징에서상기 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 단계; 및 상기 타겟 제1 음향 특징 및 상기 타겟 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하는단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 음향 특징에서 상기 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하는 단계는, 상기 합성하고자 하는 텍스트에서의 상기 차이 텍스트의 제1 시작 위치 및 제1 종료 위치를 획득하는 단계; 및 상기 제1 음향 특징에서 상기 제1 시작 위치 내지 상기 제1 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 상기 음향 특징을 상기 타겟 제1 음향 특징으로 하는 단계;를 포함하고,상기 제2 음향 특징에서 상기 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 단계는, 상기 타겟 템플릿 텍스트에서의 상기 일치 텍스트의 제2 시작 위치 및 제2 종료 위치를 획득하는 단계; 및상기 제2 음향 특징에서 상기 제2 시작 위치 내지 상기 제2 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 상기 음향 특징을 상기 타겟 제2 음향 특징으로 하는 단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 공개특허 10-2022-0104106-3-상기 타겟 사용자의 음성 특징을 획득하는 단계는, 상기 타겟 사용자의 식별자 정보를 획득하는 단계; 및 상기 식별자 정보에 따라, 상기 타겟 사용자의 음성 특징을 획득하는 단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 음성 특징은 스타일 특징 및 음색 특징을 포함하며;상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는 단계는, 상기 합성하고자 하는 텍스트 및 상기 스타일 특징에 따라, 상기 제1 음향 특징을 획득하는 단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 합성하고자 하는 텍스트 및 상기 스타일 특징에 따라, 상기 제1 음향 특징을 획득하는 단계는, 상기 합성하고자 하는 텍스트에 대해 벡터화 처리를 수행하여, 벡터 특징을 획득하는 단계;상기 벡터 특징에 대해 순차적으로 컨볼루션 처리 및 양방향 타임 루프 처리를 수행하여, 상기 합성하고자 하는텍스트의 텍스트 특징을 획득하는 단계;상기 텍스트 특징 및 상기 스타일 특징을 스플라이싱하여, 제1 스플라이싱 특징을 획득하는 단계; 및상기 제1 스플라이싱 특징에 대해 순차적으로 컨볼루션 처리, 양방향 타임 루프 처리 및 선형 처리를 수행하여,상기 제1 음향 특징을 획득하는 단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성하는 단계는, 상기 합성하고자 하는 텍스트의 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 제2스플라이싱 특징을 생성하는 단계; 및 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는 단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 방법은,상기 합성하고자 하는 텍스트, 상기 타겟 템플릿 오디오 및 상기 음성 특징을 타겟 음성 합성 모델에 입력하는단계 - 상기 타겟 음성 합성 모델은 특징 예측층, 제1 특징 추출층, 제2 특징 추출층, 특징 스플라이싱층 및 음성 합성층을 포함함 -;상기 특징 예측층에 의해 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 상기 제1 음향 특징을 획득하는 단계;상기 제1 특징 추출층에 의해 상기 타겟 템플릿 오디오의 상기 제2 음향 특징을 추출하는 단계;공개특허 10-2022-0104106-4-상기 제2 특징 추출층에 의해 상기 합성하고자 하는 텍스트의 상기 텍스트 특징을 추출하는 단계;상기 특징 스플라이싱층에 의해 상기 제1 음향 특징과 상기 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향특징을 생성하고, 상기 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 상기 제2 스플라이싱 특징을 생성하는 단계; 및 상기 음성 합성층에 의해 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는 단계;를 더 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하는 단계는, 상기 템플릿 오디오 라이브러리에서 상기 템플릿 오디오에 대응되는 템플릿 텍스트를 획득하는 단계; 상기 합성하고자 하는 텍스트와 상기 템플릿 텍스트 사이의 유사도를 획득하는 단계; 및유사도가 가장 높은 상기 템플릿 텍스트에 대응되는 상기 템플릿 오디오를 상기 타겟 템플릿 오디오로 하는 단계;를 포함하는,것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 음향 특징은 기본 주파수 특징, 에너지 특징, 지속 시간 특징 중의 적어도 하나를 포함하는, 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "음성 합성 장치에 있어서, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는 예측 모듈;상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 상기타겟 템플릿 오디오의 제2 음향 특징을 추출하는 추출 모듈;상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 스플라이싱 모듈; 및상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성하는 합성 모듈;을 포함하는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 스플라이싱 모듈은, 상기 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트를 획득하는 제1 획득 유닛;상기 합성하고자 하는 텍스트와 상기 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 획득하는 제2획득 유닛;상기 제1 음향 특징에서 상기 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하고, 상기 제2 음향 특징에서상기 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 추출 유닛; 및 상기 타겟 제1 음향 특징 및 상기 타겟 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하는 스플공개특허 10-2022-0104106-5-라이싱 유닛;을 포함하는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 추출 유닛은, 상기 합성하고자 하는 텍스트에서의 상기 차이 텍스트의 제1 시작 위치 및 제1 종료 위치를 획득하고; 상기 제1 음향 특징에서 상기 제1 시작 위치 내지 상기 제1 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 상기 음향 특징을 상기 타겟 제1 음향 특징으로 하는데 더 사용되고,상기 추출 유닛은, 상기 타겟 템플릿 텍스트에서의 상기 일치 텍스트의 제2 시작 위치 및 제2 종료 위치를 획득하고; 상기 제2 음향 특징에서 상기 제2 시작 위치 내지 상기 제2 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 상기 음향 특징을 상기 타겟 제2 음향 특징으로 하는데 더 사용되는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항 내지 제13항 중 어느 한 항에 있어서, 상기 예측 모듈은, 상기 타겟 사용자의 식별자 정보를 획득하고; 상기 식별자 정보에 따라, 상기 타겟 사용자의 음성 특징을 획득하는데 더 사용되는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 음성 특징은 스타일 특징 및 음색 특징을 포함하며;상기 예측 모듈은, 상기 합성하고자 하는 텍스트 및 상기 스타일 특징에 따라, 상기 제1 음향 특징을 획득하는데 더 사용되는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 예측 모듈은, 상기 합성하고자 하는 텍스트에 대해 벡터화 처리를 수행하여, 벡터 특징을 획득하고;상기 벡터 특징에 대해 순차적으로 컨볼루션 처리 및 양방향 타임 루프 처리를 수행하여, 상기 합성하고자 하는텍스트의 텍스트 특징을 획득하고;상기 텍스트 특징 및 상기 스타일 특징을 스플라이싱하여, 제1 스플라이싱 특징을 획득하고; 상기 제1 스플라이싱 특징에 대해 순차적으로 컨볼루션 처리, 양방향 타임 루프 처리 및 선형 처리를 수행하여,상기 제1 음향 특징을 획득하는데 더 사용되는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2022-0104106-6-제15항에 있어서, 상기 합성 모듈은, 상기 합성하고자 하는 텍스트의 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 제2스플라이싱 특징을 생성하고; 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는데 더 사용되는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 장치는 입력 모듈을 더 포함하며, 상기 입력 모듈은,상기 합성하고자 하는 텍스트, 상기 타겟 템플릿 오디오 및 상기 음성 특징을 타겟 음성 합성 모델에 입력하고,상기 타겟 음성 합성 모델은 특징 예측층, 제1 특징 추출층, 제2 특징 추출층, 특징 스플라이싱층 및 음성 합성층을 포함하고;상기 특징 예측층에 의해 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 상기 제1 음향 특징을 획득하고;상기 제1 특징 추출층에 의해 상기 타겟 템플릿 오디오의 상기 제2 음향 특징을 추출하고;상기 제2 특징 추출층에 의해 상기 합성하고자 하는 텍스트의 상기 텍스트 특징을 추출하고;상기 특징 스플라이싱층에 의해 상기 제1 음향 특징과 상기 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향특징을 생성하고, 상기 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 상기 제2 스플라이싱 특징을 생성하고; 상기 음성 합성층에 의해 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는데 더 사용되는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항 내지 제13항 중 어느 한 항에 있어서, 상기 추출 모듈은, 상기 템플릿 오디오 라이브러리에서 상기 템플릿 오디오에 대응되는 템플릿 텍스트를 획득하고; 상기 합성하고자 하는 텍스트와 상기 템플릿 텍스트 사이의 유사도를 획득하고; 유사도가 가장 높은 상기 템플릿 텍스트에 대응되는 상기 템플릿 오디오를 상기 타겟 템플릿 오디오로 하는데더 사용되는,것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항 내지 제13항 중 어느 한 항에 있어서, 상기 음향 특징은 기본 주파수 특징, 에너지 특징, 지속 시간 특징 중의 적어도 하나를 포함하는, 것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리;를 포함하고, 공개특허 10-2022-0104106-7-상기 메모리에 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제10항 중 어느 한 항에 따른방법을 구현하는,것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령은 컴퓨터가 제1항 내지 제10항 중 어느 한 항에 따른 방법을 수행하는데 사용되는, 것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-0083591", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행되는 경우, 제1항 내지 제10항 중 어느 한 항에 따른 방법을 구현하는,것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 음성 합성 방법, 장치, 전자 기기 및 저장 매체를 제공하며, 음성, 인공지능"}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로, 특히 음성 합성, 자연어 처리, 딥러닝 기술 분야에 관한 것이다. 구체적인 구현 수단은 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 합성하고자 하는 텍스트 및 음성 특징에 따라, 예측한 (뒷면에 계속) 대 표 도 - 도1"}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2022-0104106 제1 음향 특징을 획득하는 단계; 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 타겟 템플릿 오디오의 제2 음향 특징을 추출하는 단계; 제1 음향 특징 및 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계; 및 타겟 음향 특징 및 음성 특징을 기반으로, 합성하고자 하 는 텍스트에 대해 음성 합성을 수행하여, 타겟 음성을 생성하는 단계를 포함한다. 이에 따라, 타겟 음향 특징은 합성하고자 하는 텍스트의 제1 음향 특징 및 타겟 템플릿 오디오의 제2 음향 특징을 구비할 수 있으므로, 특징 표현 효과가 더 우수하고, 타겟 음성의 진실 정도 및 자연스러운 정도를 향상시키는데 유리하고, 음성 합성 효과 가 더 우수하다. CPC특허분류 G10L 13/08 (2013.01) G10L 15/02 (2013.01) G10L 25/30 (2013.01) 발명자 순, 타오 중국 베이징 100085 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층지아, 레이 중국 베이징 100085 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 음성 합성 방법에 있어서, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 상기 합성하고자 하는 텍스트 및 상 기 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는 단계; 상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 상기 타겟 템플릿 오디오의 제2 음향 특징을 추출하는 단계; 상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계; 및 상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하 여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성하는 단계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 2 제1항에 있어서, 상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계는, 상기 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트를 획득하는 단계; 상기 합성하고자 하는 텍스트와 상기 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 획득하는 단계; 상기 제1 음향 특징에서 상기 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하고, 상기 제2 음향 특징에서 상기 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 단계; 및 상기 타겟 제1 음향 특징 및 상기 타겟 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하는 단계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 3 제2항에 있어서, 상기 제1 음향 특징에서 상기 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하는 단계는, 상기 합성하고자 하는 텍스트에서의 상기 차이 텍스트의 제1 시작 위치 및 제1 종료 위치를 획득하는 단계; 및 상기 제1 음향 특징에서 상기 제1 시작 위치 내지 상기 제1 종료 위치에 대응되는 음향 특징을 추출하여, 추출 된 상기 음향 특징을 상기 타겟 제1 음향 특징으로 하는 단계;를 포함하고, 상기 제2 음향 특징에서 상기 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 단계는, 상기 타겟 템플릿 텍스트에서의 상기 일치 텍스트의 제2 시작 위치 및 제2 종료 위치를 획득하는 단계; 및 상기 제2 음향 특징에서 상기 제2 시작 위치 내지 상기 제2 종료 위치에 대응되는 음향 특징을 추출하여, 추출 된 상기 음향 특징을 상기 타겟 제2 음향 특징으로 하는 단계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 4 제1항에 있어서, 상기 타겟 사용자의 음성 특징을 획득하는 단계는, 상기 타겟 사용자의 식별자 정보를 획득하는 단계; 및 상기 식별자 정보에 따라, 상기 타겟 사용자의 음성 특징을 획득하는 단계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 5 제4항에 있어서, 상기 음성 특징은 스타일 특징 및 음색 특징을 포함하며; 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는 단계는, 상기 합성하고자 하는 텍스트 및 상기 스타일 특징에 따라, 상기 제1 음향 특징을 획득하는 단계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 6 제5항에 있어서, 상기 합성하고자 하는 텍스트 및 상기 스타일 특징에 따라, 상기 제1 음향 특징을 획득하는 단계는, 상기 합성하고자 하는 텍스트에 대해 벡터화 처리를 수행하여, 벡터 특징을 획득하는 단계; 상기 벡터 특징에 대해 순차적으로 컨볼루션 처리 및 양방향 타임 루프 처리를 수행하여, 상기 합성하고자 하는 텍스트의 텍스트 특징을 획득하는 단계; 상기 텍스트 특징 및 상기 스타일 특징을 스플라이싱하여, 제1 스플라이싱 특징을 획득하는 단계; 및 상기 제1 스플라이싱 특징에 대해 순차적으로 컨볼루션 처리, 양방향 타임 루프 처리 및 선형 처리를 수행하여, 상기 제1 음향 특징을 획득하는 단계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 7 제5항에 있어서, 상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하 여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성하는 단계는, 상기 합성하고자 하는 텍스트의 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 제2 스플라이싱 특징을 생성하는 단계; 및 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는 단계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 8 제7항에 있어서, 상기 방법은, 상기 합성하고자 하는 텍스트, 상기 타겟 템플릿 오디오 및 상기 음성 특징을 타겟 음성 합성 모델에 입력하는 단계 - 상기 타겟 음성 합성 모델은 특징 예측층, 제1 특징 추출층, 제2 특징 추출층, 특징 스플라이싱층 및 음 성 합성층을 포함함 -; 상기 특징 예측층에 의해 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 상기 제1 음향 특징을 획득 하는 단계; 상기 제1 특징 추출층에 의해 상기 타겟 템플릿 오디오의 상기 제2 음향 특징을 추출하는 단계;상기 제2 특징 추출층에 의해 상기 합성하고자 하는 텍스트의 상기 텍스트 특징을 추출하는 단계; 상기 특징 스플라이싱층에 의해 상기 제1 음향 특징과 상기 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하고, 상기 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 상기 제2 스플 라이싱 특징을 생성하는 단계; 및 상기 음성 합성층에 의해 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는 단계;를 더 포함하 는, 것을 특징으로 하는 음성 합성 방법. 청구항 9 제1항에 있어서, 상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하는 단계는, 상기 템플릿 오디오 라이브러리에서 상기 템플릿 오디오에 대응되는 템플릿 텍스트를 획득하는 단계; 상기 합성하고자 하는 텍스트와 상기 템플릿 텍스트 사이의 유사도를 획득하는 단계; 및 유사도가 가장 높은 상기 템플릿 텍스트에 대응되는 상기 템플릿 오디오를 상기 타겟 템플릿 오디오로 하는 단 계;를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 10 제1항에 있어서, 상기 음향 특징은 기본 주파수 특징, 에너지 특징, 지속 시간 특징 중의 적어도 하나를 포함하는, 것을 특징으로 하는 음성 합성 방법. 청구항 11 음성 합성 장치에 있어서, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 상기 합성하고자 하는 텍스트 및 상 기 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는 예측 모듈; 상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 상기 타겟 템플릿 오디오의 제2 음향 특징을 추출하는 추출 모듈; 상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 스플라이싱 모듈; 및 상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하 여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성하는 합성 모듈;을 포함하는, 것을 특징으로 하는 음성 합성 장치. 청구항 12 제11항에 있어서, 상기 스플라이싱 모듈은, 상기 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트를 획득하는 제1 획득 유닛; 상기 합성하고자 하는 텍스트와 상기 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 획득하는 제2 획득 유닛; 상기 제1 음향 특징에서 상기 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하고, 상기 제2 음향 특징에서 상기 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 추출 유닛; 및 상기 타겟 제1 음향 특징 및 상기 타겟 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하는 스플라이싱 유닛;을 포함하는, 것을 특징으로 하는 음성 합성 장치. 청구항 13 제12항에 있어서, 상기 추출 유닛은, 상기 합성하고자 하는 텍스트에서의 상기 차이 텍스트의 제1 시작 위치 및 제1 종료 위치를 획득하고; 상기 제1 음향 특징에서 상기 제1 시작 위치 내지 상기 제1 종료 위치에 대응되는 음향 특징을 추출하여, 추출 된 상기 음향 특징을 상기 타겟 제1 음향 특징으로 하는데 더 사용되고, 상기 추출 유닛은, 상기 타겟 템플릿 텍스트에서의 상기 일치 텍스트의 제2 시작 위치 및 제2 종료 위치를 획득하고; 상기 제2 음향 특징에서 상기 제2 시작 위치 내지 상기 제2 종료 위치에 대응되는 음향 특징을 추출하여, 추출 된 상기 음향 특징을 상기 타겟 제2 음향 특징으로 하는데 더 사용되는, 것을 특징으로 하는 음성 합성 장치. 청구항 14 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 예측 모듈은, 상기 타겟 사용자의 식별자 정보를 획득하고; 상기 식별자 정보에 따라, 상기 타겟 사용자의 음성 특징을 획득하는데 더 사용되는, 것을 특징으로 하는 음성 합성 장치. 청구항 15 제14항에 있어서, 상기 음성 특징은 스타일 특징 및 음색 특징을 포함하며; 상기 예측 모듈은, 상기 합성하고자 하는 텍스트 및 상기 스타일 특징에 따라, 상기 제1 음향 특징을 획득하는데 더 사용되는, 것을 특징으로 하는 음성 합성 장치. 청구항 16 제15항에 있어서, 상기 예측 모듈은, 상기 합성하고자 하는 텍스트에 대해 벡터화 처리를 수행하여, 벡터 특징을 획득하고; 상기 벡터 특징에 대해 순차적으로 컨볼루션 처리 및 양방향 타임 루프 처리를 수행하여, 상기 합성하고자 하는 텍스트의 텍스트 특징을 획득하고; 상기 텍스트 특징 및 상기 스타일 특징을 스플라이싱하여, 제1 스플라이싱 특징을 획득하고; 상기 제1 스플라이싱 특징에 대해 순차적으로 컨볼루션 처리, 양방향 타임 루프 처리 및 선형 처리를 수행하여, 상기 제1 음향 특징을 획득하는데 더 사용되는, 것을 특징으로 하는 음성 합성 장치. 청구항 17 제15항에 있어서, 상기 합성 모듈은, 상기 합성하고자 하는 텍스트의 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 제2 스플라이싱 특징을 생성하고; 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는데 더 사용되는, 것을 특징으로 하는 음성 합성 장치. 청구항 18 제17항에 있어서, 상기 장치는 입력 모듈을 더 포함하며, 상기 입력 모듈은, 상기 합성하고자 하는 텍스트, 상기 타겟 템플릿 오디오 및 상기 음성 특징을 타겟 음성 합성 모델에 입력하고, 상기 타겟 음성 합성 모델은 특징 예측층, 제1 특징 추출층, 제2 특징 추출층, 특징 스플라이싱층 및 음성 합성 층을 포함하고; 상기 특징 예측층에 의해 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 상기 제1 음향 특징을 획득 하고; 상기 제1 특징 추출층에 의해 상기 타겟 템플릿 오디오의 상기 제2 음향 특징을 추출하고; 상기 제2 특징 추출층에 의해 상기 합성하고자 하는 텍스트의 상기 텍스트 특징을 추출하고; 상기 특징 스플라이싱층에 의해 상기 제1 음향 특징과 상기 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하고, 상기 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 상기 제2 스플 라이싱 특징을 생성하고; 상기 음성 합성층에 의해 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성하는데 더 사용되는, 것을 특징으로 하는 음성 합성 장치. 청구항 19 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 추출 모듈은, 상기 템플릿 오디오 라이브러리에서 상기 템플릿 오디오에 대응되는 템플릿 텍스트를 획득하고; 상기 합성하고자 하는 텍스트와 상기 템플릿 텍스트 사이의 유사도를 획득하고; 유사도가 가장 높은 상기 템플릿 텍스트에 대응되는 상기 템플릿 오디오를 상기 타겟 템플릿 오디오로 하는데 더 사용되는, 것을 특징으로 하는 음성 합성 장치. 청구항 20 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 음향 특징은 기본 주파수 특징, 에너지 특징, 지속 시간 특징 중의 적어도 하나를 포함하는, 것을 특징으로 하는 음성 합성 장치. 청구항 21 전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리;를 포함하고, 상기 메모리에 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어 도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제10항 중 어느 한 항에 따른 방법을 구현하는, 것을 특징으로 하는 전자 기기. 청구항 22 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령은 컴퓨터가 제1항 내지 제10항 중 어느 한 항에 따른 방법을 수행하는데 사용되는, 것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체. 청구항 23 컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행되는 경우, 제1항 내지 제10항 중 어느 한 항에 따른 방법을 구현 하는, 것을 특징으로 하는 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 개시는 컴퓨터 기술 분야에 관한 것으로, 특히 음성 합성 방법, 장치, 전자 기기, 저장 매체 및 컴퓨터 프로 그램에 관한 것이다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 음성 합성 방법을 통해 텍스트를 타겟 사용자의 음성 특징을 구비하는 오디오로 전환할 수 있으며, 음성 채팅, 스마트 가전 제품 등 분야에서 널리 사용되고 있다. 예를 들어, 음성 채팅 시나리오에서 사용자의 채팅 음성을 수신한 후, 당해 채팅 음성과 매칭되는 채팅 텍스트를 획득할 수 있고, 채팅 텍스트를 실시간으로 타겟 사용자의 음성 특징을 구비하는 오디오로 전환한 후, 오디오를 재생하거나 사용자 단말에 피드백할 수 있다. 그 러나, 기존 기술의 음성 합성 방법에 따르면, 합성된 음성의 진실 정도 및 자연스러운 정도가 좋지 않다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 음성 합성 방법, 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 음성 합성 방법을 제공하며, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 예측한 제1 음향 특징을 획득 하는 단계; 상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득 하고, 상기 타겟 템플릿 오디오의 제2 음향 특징을 추출하는 단계; 상기 제1 음향 특징 및 상기 제2 음향 특징 을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계; 및 상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성 하는 단계;를 포함한다. 본 개시의 다른 측면에 따르면, 음성 합성 장치를 제공하며, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 예측한 제1 음향 특징을 획득 하는 예측 모듈; 상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 상기 타겟 템플릿 오디오의 제2 음향 특징을 추출하는 추출 모듈; 상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 스플라이싱 모듈; 및 상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 상기 합성하고자 하는 텍스트 의 타겟 음성을 생성하는 합성 모듈;을 포함한다. 본 개시의 다른 측면에 따르면, 전자 기기를 제공하며, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세 서와 통신 가능하게 연결되는 메모리;를 포함하고, 상기 메모리에 상기 적어도 하나의 프로세서에 의해 수행 가 능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서가 음성 합성 방법을 구현할 수 있도록 한다. 본 개시의 다른 측면에 따르면, 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공하며, 상기 컴퓨터 명령은 상기 컴퓨터가 음성 합성 방법을 수행하는데 사용된다. 본 개시의 다른 측면에 따르면, 컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램을 제공하며, 상 기 컴퓨터 프로그램이 프로세서에 의해 수행되는 경우, 음성 합성 방법의 단계를 구현한다. 이해 가능한 바로는, 본 부분에서 설명된 내용은 본 개시의 실시예의 핵심 또는 중요한 특징을 식별하기 위한 것이 아니며, 본 개시의 범위를 한정하지도 않는다. 본 개시의 기타 특징들은 하기의 명세서에 의해 쉽게 이해 될 것이다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이에 따라, 타겟 음향 특징은 합성하고자 하는 텍스트의 제1 음향 특징 및 타겟 템플릿 오디오의 제2 음향 특징 을 구비할 수 있으므로, 특징 표현 효과가 더 우수하고, 타겟 음성의 진실 정도 및 자연스러운 정도를 향상시키 는데 유리하고, 음성 합성 효과가 더 우수하다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 결합하여 본 개시의 예시적인 실시예에 대해 설명하며, 여기에는 이해를 돕기 위해 본 개 시의 실시예의 다양한 세부 사항을 포함하므로, 이는 단지 예시적인 것으로 이해해야 한다. 따라서, 당업자는 본 개시의 범위 및 사상을 벗어나지 않는 한 여기에 설명된 실시예에 대해 다양한 변경 및 수정이 이루어질 수 있음을 인식해야 한다. 마찬가지로, 명확성과 간결성을 위해, 하기의 설명에서는 공지된 기능 및 구조에 대한 설명을 생략한다. 음성은 음성 인식, 음성 분리, 음성 인터랙션, 음성 합성 등 기술 분야를 포함할 수 있고, 인공지능 분야의 주 요 방향 중 하나이다. 음성 합성(Voice Synthesis)은 기계로 하여금 문자 정보를 출력 가능한 음성으로 전환하는 기술이며, 음향학, 언어학, 디지털 신호 처리 및 컴퓨터 과학 등 분야에 관한 것이다. AI(Artificial Intelligence, 인공지능)은 인간의 지능을 시뮬레이션, 연장 및 확장하기 위한 이론, 방법, 기술 및 응용 시스템을 연구하고 개발하는 기술 과학이다. 현재, AI 기술은 고도의 자동화, 고정밀도, 저비용의 장점 을 가지고 있으며, 널리 사용되고 있다. NLU(Natural Language Processing, 자연어 처리)는 자연어 통신을 효과적으로 구현할 수 있는 컴퓨터 시스템, 특히 소프트웨어 시스템을 연구하는 학과이며, 컴퓨터 과학 분야와 인공지능 분야의 주요 방향 중 하나이다. 딥러닝(Deep Learning)은 기계 러닝(Machine Learning) 분야의 새로운 연구 방향으로서, 샘플 데이터의 내재적 법칙 및 표현 계층을 러닝하는 것이며, 기계로 하여금 인간과 같은 분석 러닝 능력을 구비할 수 있고, 문자, 이 미지 및 소리 등과 같은 데이터를 인식할 수 있도록 하며, 음성 및 이미지 인식에 널리 사용되고 있다. 도 1은 본 개시의 제1 실시예에 따른 음성 합성 방법의 개략적인 흐름도이다. 도 1에 도시된 바와 같이, 본 개시의 제1 실시예의 음성 합성 방법은 단계 S101 내지 단계 S104를 포함한다. S101, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 합성하고자 하는 텍스트 및 음 성 특징에 따라, 예측한 제1 음향 특징을 획득한다. 설명해야 하는 바로는, 본 개시의 실시예의 음성 합성 방법의 수행 주체는 데이터 정보 처리 능력을 구비한 하 드웨어 기기 및/또는 당해 하드웨어 기기를 구동하는데 필요한 소프트웨어일 수 있다. 선택적으로, 수행 주체는 워크스테이션, 서버, 컴퓨터, 사용자 단말 및 기타 스마트 기기를 포함할 수 있다. 사용자 단말은 휴대폰, 컴퓨 터, 스마트 음성 인터랙션 기기, 스마트 가전 제품, 차량 탑재 단말 등을 포함하지만, 이에 제한되지 않는다. 본 개시의 실시예에서, 합성하고자 하는 텍스트를 획득할 수 있다. 설명해야 할 점은, 합성하고자 하는 텍스트 의 언어, 유형 등에 대해 구체적으로 한정하지 않는다. 예를 들어, 합성하고자 하는 텍스트의 언어는 중국어, 영어 등을 포함할 수 있지만, 이에 제한되지 않는다. 합성하고자 하는 텍스트의 유형은 채팅 텍스트, 강연 텍스 트 등을 포함할 수 있지만, 이에 제한되지 않는다. 본 개시의 실시예에서, 타겟 사용자의 음성 특징을 획득할 수 있다. 이해 가능한 바로는, 상이한 타겟 사용자에 상이한 음성 특징이 대응될 수 있다. 설명해야 할 점은, 음성 특징의 유형에 대해 구체적으로 한정하지 않는다. 일 실시 방식에서, 타겟 사용자의 음성 특징은 사전에 로컬에 저장될 수 있고, 음성 합성 과정에서 로컬 저장 공간으로부터 타겟 사용자의 음성 특징을 획득할 수 있으며, 오프라인으로 타겟 사용자의 음성 특징을 획득할 수 있고, 음성 합성의 연산량을 효과적으로 줄일 수 있다. 본 개시의 실시예에서, 합성하고자 하는 텍스트 및 음성 특징에 따라, 예측한 제1 음향 특징을 획득할 수 있으 므로, 합성하고자 하는 텍스트 및 타겟 사용자의 음성 특징이 예측한 제1 음향 특징에 대한 영향을 종합적으로 고려할 수 있고, 예측한 제1 음향 특징으로서 합성하고자 하는 텍스트의 특징 및 음성 특징을 구비하여, 개인화 된 음성 합성을 구현할 수 있다. 일 실시 방식에서, 합성하고자 하는 텍스트 및 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는 단계는 합 성하고자 하는 텍스트 및 음성 특징을 특징 예측 알고리즘에 입력하여, 특징 예측 알고리즘에 의해 예측한 제1 음향 특징을 출력하는 단계를 포함할 수 있다. 특징 예측 알고리즘은 실제 상황에 따라 설정 가능하므로, 여기 서 구체적으로 한정하지 않는다. S102, 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 타겟 템플릿 오디오의 제2 음향 특징을 추출한다. 본 개시의 실시예에서, 템플릿 오디오 라이브러리를 획득할 수 있으며, 템플릿 오디오 라이브러리는 복수의 템 플릿 오디오를 포함한다. 이해 가능한 바로는, 템플릿 오디오 라이브러리는 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않는다. 본 개시의 실시예에서, 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득할 수 있다. 나아가, 타겟 템플릿 오디오의 제2 음향 특징을 추출할 수 있다. 일 실시 방식에서, 타겟 템플릿 오디오의 제2 음향 특징을 추출하는 단계는 타겟 템플릿 오디오를 특징 추출 알 고리즘에 입력하여 특징 추출 알고리즘에 의해 제2 음향 특징을 출력하는 단계를 포함할 수 있다. 특징 추출 알 고리즘은 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않는다. S103, 제1 음향 특징 및 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성한다. 본 개시의 실시예에서, 제1 음향 특징 및 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성할 수 있으며, 따라서 생성된 타겟 음향 특징은 합성하고자 하는 텍스트의 제1 음향 특징 및 타겟 템플릿 오디오의 제 2 음향 특징을 동시 구비할 수 있으며, 특징 표현 효과가 더 우수하다. 일 실시 방식에서, 제1 음향 특징 및 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계는 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트를 획득하고, 타겟 템플릿 텍스트 및 합성하고자 하는 텍스트를 기반으로, 제1 음향 특징 및 제2 음향 특징의 스플라이싱 위치를 결정하고, 스플라이싱 위치에 따라 제1 음향특징 및 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하는 단계를 포함할 수 있다. 예를 들어, 합성하고자 하는 텍스트는 \"당신의 이번 달의 전화 요금은 16원입니다 ( )\"이고, 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트는 \"당신의 이번 달의 전화 요금은 100원입니다( )\"인 경우, 제1 음향 특징 중 \"16\"에 대응되는 특징 2 의 스플라이싱 위치를 제2 음향 특징 중 \"100\"에 대응되는 특징 위치로 결정할 수 있고, 제2 음향 특징 중 \"당 신의 이번 달의 전화 요금은( )\"에 대응되는 특징 1과 제1 음향 특징 중 \"16\"에 대응되는 특 징 2 및 제2 음향 특징 중 \"원(元)\"에 대응되는 특징 3을 스플라이싱할 수 있으며, 특징 1은 특징 2의 시간 순 서 앞에 있고, 특징 2는 특징 3의 시간 순서 앞에 있다. S104, 타겟 음향 특징 및 음성 특징을 기반으로, 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 합성하 고자 하는 텍스트의 타겟 음성을 생성한다. 본 개시의 실시예에서, 타겟 음향 특징 및 음성 특징을 기반으로, 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 합성하고자 하는 텍스트의 타겟 음성을 생성할 수 있다. 일 실시 방식에서, 타겟 음향 특징 및 음성 특징을 기반으로, 합성하고자 하는 텍스트에 대해 음성 합성을 수행 하여, 합성하고자 하는 텍스트의 타겟 음성을 생성하는 단계는 타겟 음향 특징, 음성 특징, 합성하고자 하는 텍 스트를 음성 합성 알고리즘에 입력하여, 음성 합성 알고리즘에 의해 합성하고자 하는 텍스트의 타겟 음성을 출 력하는 단계를 포함할 수 있다. 음성 합성 알고리즘은 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않는다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요약하면, 본 개시의 실시예의 음성 합성 방법에 따르면, 합성하고자 하는 텍스트 및 음성 특징에 따라, 예측한 제1 음향 특징을 획득하고, 타겟 템플릿 오디오의 제2 음향 특징을 추출하며, 제1 음향 특징 및 제2 음향 특징 을 스플라이싱하여, 타겟 음향 특징을 생성하고, 타겟 음향 특징 및 음성 특징을 기반으로, 합성하고자 하는 텍 스트에 대해 음성 합성을 수행하여, 합성하고자 하는 텍스트의 타겟 음성을 생성할 수 있다. 이에 따라, 타겟 음향 특징으로서 합성하고자 하는 텍스트의 제1 음향 특징 및 타겟 템플릿 오디오의 제2 음향 특징을 동시 구비 할 수 있으며, 특징 표현 효과가 더 우수하고, 타겟 음성의 진실 정도 및 자연스러운 정도를 향상시키는데 유리 하고, 음성 합성 효과가 더 우수하다. 도 2는 본 개시의 제2 실시예에 따른 음성 합성 방법의 개략적인 흐름도이다. 도 2에 도시된 바와 같이, 본 개시의 제2 실시예의 음성 합성 방법은 단계 S201 내지 단계 S204를 포함한다. S201, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 음성 특징은 스타일 특징 및 음색 특징을 포함하며, 합성하고자 하는 텍스트 및 스타일 특징에 따라, 예측한 제1 음향 특징을 획득한다. 본 개시의 실시예에서, 타겟 사용자의 식별자 정보와 타겟 사용자의 음성 특징 사이에는 대응 관계가 구비된다. 식별자 정보는 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않으며, 예를 들어, 타겟 사용 자의 식별자 정보는 \"장산\", \"이사\"로 설정 가능하다. 일 실시 방식에서, 타겟 사용자의 음성 특징을 획득하는 단계는, 타겟 사용자의 식별자 정보를 획득하여, 식별 자 정보에 따라, 타겟 사용자의 음성 특징을 획득하는 단계를 포함할 수 있다. 이에 따라, 당해 방법은 타겟 사 용자의 식별자 정보를 기반으로, 타겟 사용자의 음성 특징을 획득할 수 있다. 예를 들어, 타겟 사용자의 식별자 정보 및 타겟 사용자의 음성 특징 사이의 매핑 관계 또는 매핑 테이블을 사전 구축할 수 있으며, 타겟 사용자의 식별자 정보를 획득한 후, 식별자 정보에 따라 상기 매핑 관계 또는 매핑 테 이블에서 당해 식별자 정보에 매핑되는 음성 특징을 조회하여, 타겟 사용자의 음성 특징으로 할 수 있다. 본 개시의 실시예에서, 음성 특징은 스타일 특징 및 음색 특징을 포함할 수 있으며, 스타일 특징은 하나의 사용 자의 상이한 스타일을 구별하는데 사용될 수 있고, 음색 특징은 상이한 사용자를 구별하는데 사용될 수 있다. 본 개시의 실시예에서, 합성하고자 하는 텍스트 및 스타일 특징에 따라, 예측한 제1 음향 특징을 획득할 수 있 다. 일 실시 방식에서, 합성하고자 하는 텍스트 및 스타일 특징에 따라, 제1 음향 특징을 획득하는 단계는 합성하고 자 하는 텍스트에 대해 벡터화 처리를 수행하여, 벡터 특징을 획득하고, 벡터 특징에 대해 순차적으로 컨볼루션처리 및 양방향 타임 루프 처리를 수행하여, 합성하고자 하는 텍스트의 텍스트 특징을 획득하며, 텍스트 특징 및 스타일 특징을 스플라이싱하여, 제1 스플라이싱 특징을 획득하고, 제1 스플라이싱 특징에 대해 순차적으로 컨볼루션 처리, 양방향 타임 루프 처리 및 선형 처리를 수행하여, 제1 음향 특징을 획득하는 단계를 포함할 수 있다. 선택적으로, 텍스트 특징 및 스타일 특징을 스플라이싱하여, 제1 스플라이싱 특징을 획득하는 단계는 텍스트 특 징 및 스타일 특징의 합을 제1 스플라이싱 특징으로 하는 단계를 포함할 수 있다. 본 개시의 실시예에서, 음향 특징은 기본 주파수 특징, 에너지 특징, 지속 시간 특징 중의 적어도 하나를 포함 한다. 설명해야 할 점은, 음향 특징의 입도에 대해 구체적으로 한정하지 않으며, 예를 들어, 음향 특징은 음소 입도의 음향 특징일 수 있다. S202, 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 타겟 템플릿 오디오의 제2 음향 특징을 추출한다. 본 개시의 실시예에서, 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하는 단계는 템플릿 오디오 라이브러리에서 템플릿 오디오에 대응되는 템플릿 텍스트를 획득하고, 합성하고 자 하는 텍스트와 템플릿 텍스트 사이의 유사도를 획득하고, 유사도가 가장 높은 템플릿 텍스트에 대응되는 템 플릿 오디오를 타겟 템플릿 오디오로 하는 단계를 포함할 수 있다. 이에 따라, 당해 방법은 합성하고자 하는 텍 스트와 템플릿 텍스트 사이의 유사도에 따라, 템플릿 오디오 라이브러리로부터 유사도가 가장 높은 템플릿 텍스 트에 대응되는 템플릿 오디오를 선별하여 타겟 템플릿 오디오로 할 수 있으므로, 선택된 타겟 템플릿 오디오와 합성하고자 하는 텍스트의 매칭도가 가장 높으며, 음성 합성 효과가 더 우수하다. 예를 들어, 스마트 고객 서비스 시나리오에서, 템플릿 오디오 라이브러리는 템플릿 오디오 A, B, C, D를 포함하 고, 템플릿 오디오 A, B, C, D에 템플릿 텍스트 a, b, c, d가 각각 대응될 수 있으며, 템플릿 텍스트 a, b, c, d는 각각 \"당신의 이번 달의 전화 요금은 100원입니다( )\", \"당신은 100원을 성공적 으로 충전하였습니다( )\", \"당신의 계정 잔액은 100원입니다 ( )\", \"당신의 이번 달의 남은 일반 트래픽은 5GB입니다 ( )\"이다. 합성하고자 하는 텍스트가 \"당신의 이번 달의 전화 요금은 16원입 니다( )\"인 경우, 당해 합성하고자 하는 텍스트는 템플릿 텍스트 a와의 유사도가 가장 높은 것을 알 수 있고, 템플릿 오디오 라이브러리로부터 템플릿 오디오 A를 타겟 템플릿 오디오로 획득할 수 있 다. S203, 제1 음향 특징 및 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성한다. S204, 타겟 음향 특징 및 음성 특징을 기반으로, 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 합성하 고자 하는 텍스트의 타겟 음성을 생성한다. 단계 S203-S204에 관련된 내용은 상기 실시예를 참조할 수 있으나, 여기서 반복하지 않는다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "요약하면, 본 개시의 실시예의 음성 합성 방법에 따르면, 음성 특징은 스타일 특징 및 음색 특징을 포함하며, 합성하고자 하는 텍스트 및 스타일 특징에 따라, 예측한 제1 음향 특징을 획득할 수 있고, 합성하고자 하는 텍 스트 및 타겟 사용자의 스타일 특징이 예측한 제1 음향 특징에 대한 영향을 종합적으로 고려할 수 있고, 예측한 제1 음향 특징으로서 타겟 사용자의 스타일 특징을 구비하여, 음성 합성의 개인화를 향상시키는데 유리하다. 도 3은 본 개시의 제3 실시예에 따른 음성 합성 방법의 개략적인 흐름도이다. 도 3에 도시된 바와 같이, 본 개시의 제3 실시예의 음성 합성 방법은 단계 S301 내지 단계 308을 포함한다. S301, 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 합성하고자 하는 텍스트 및 음 성 특징에 따라, 예측한 제1 음향 특징을 획득한다. S302, 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 타겟 템플릿 오디오의 제2 음향 특징을 추출한다. 단계 S301-S302에 관련된 내용은 상기 실시예를 참조할 수 있으나, 여기서 반복하지 않는다. S303, 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트를 획득한다. 본 개시의 실시예에서, 템플릿 오디오와 템플릿 텍스트는 대응 관계를 구비하며, 상이한 템플릿 오디오에 상이 한 템플릿 텍스트가 대응될 수 있고, 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스트를 획득할 수 있다. 일 실시 방식에서, 템플릿 오디오 및 템플릿 텍스트 사이의 매핑 관계 또는 매핑 테이블을 사전 구축할 수 있으 며, 타겟 템플릿 오디오를 획득한 후, 상기 매핑 관계 또는 매핑 테이블에서 당해 타겟 템플릿 오디오에 매핑되 는 템플릿 텍스트를 조회하여, 타겟 템플릿 텍스트로 할 수 있다. 설명해야 할 점은, 상기 매핑 관계 또는 매핑 테이블은 모두 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않는다. 예를 들어, 스마트 고객 서비스 시나리오에서, 템플릿 오디오 라이브러리는 템플릿 오디오 A, B, C, D를 포함하 고, 템플릿 오디오 A, B, C, D에 템플릿 텍스트 a, b, c, d가 각각 대응될 수 있으며, 템플릿 텍스트 a, b, c, d는 각각 \"당신의 이번 달의 전화 요금은 100원입니다( )\", \"당신은 100원을 성공적 으로 충전하였습니다\", \"당신의 계정 잔액은 100원입니다\", \"당신의 이번 달의 남은 일반 트래픽은 5GB입니다\" 이다. 타겟 템플릿 오디오가 템플릿 오디오 A인 경우, 템플릿 텍스트 a \"당신의 이번 달의 전화 요금은 100원입 니다( )\"를 타겟 템플릿 텍스트로 할 수 있다. S304, 합성하고자 하는 텍스트와 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 획득한다. 본 개시의 실시예에서, 합성하고자 하는 텍스트 및 타겟 템플릿 텍스트는 일치한 부분과 상이한 부분이 있을 수 있으므로, 합성하고자 하는 텍스트 및 타겟 템플릿 텍스트를 비교하여 합성하고자 하는 텍스트와 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 획득할 수 있다. 이해 가능한 바로는, 합성하고자 하는 텍스트 및 타겟 템플릿 텍스트는 모두 일치 텍스트를 포함한다. 일 실시 방식에서, 차이 텍스트는 합성하고자 하는 텍스트 중 타겟 템플릿 텍스트와 다른 텍스트를 의미한다. 예를 들어, 합성하고자 하는 텍스트는 \"당신의 이번 달의 전화 요금은 16원입니다 ( )\"이고, 타겟 템플릿 텍스트는 \"당신의 이번 달의 전화 요금은 100원입니다 ( )\"인 경우, 일치 텍스트는 \"당신의 이번 달의 전화 요금은( )\" 및 \"원(元)\"을 포함할 수 있고, 차이 텍스트는 \"16\"일 수 있다. S305, 제1 음향 특징에서 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하고, 제2 음향 특징에서 일치 텍 스트에 대응되는 타겟 제2 음향 특징을 추출한다. 본 개시의 실시예에서, 합성하고자 하는 텍스트는 차이 텍스트를 포함할 수 있으며, 합성하고자 하는 텍스트에 대응되는 제1 음향 특징에서 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출할 수 있다. 타겟 템플릿 오디 오에 대응되는 타겟 템플릿 텍스트는 일치 텍스트를 포함하며, 타겟 템플릿 오디오에 대응되는 제2 음향 특징에 서 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출할 수 있다. 예를 들어, 합성하고자 하는 텍스트는 \"당신의 이번 달의 전화 요금은 16원입니다 ( )\"이고, 타겟 템플릿 텍스트는 \"당신의 이번 달의 전화 요금은 100원입니다 ( )\"인 경우, 일치 텍스트는 \"당신의 이번 달의 전화 요금은( )\" 및 \"원(元)\"을 포함할 수 있고, 차이 텍스트는 \"16\"일 수 있으며, 제1 음향 특징에서 \"16\"에 대응되는 타겟 제1 음향 특징을 추출할 수 있고, 제2 음향 특징에서 \"당신의 이번 달의 전화 요금은( )\" 및 \"원 (元)\"에 대응되는 타겟 제2 음향 특징을 추출할 수 있다. 일 실시 방식에서, 제1 음향 특징에서 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하는 단계는 합성하고 자 하는 텍스트에서의 차이 텍스트의 제1 시작 위치 및 제1 종료 위치를 획득하여, 제1 음향 특징에서 제1 시작 위치 내지 제1 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 음향 특징을 타겟 제1 음향 특징으로 하는 단계를 포함할 수 있다. 이에 따라, 당해 방법은 제1 시작 위치 및 제1 종료 위치를 기반으로, 제1 음향 특징에 서 타겟 제1 음향 특징을 정확하게 추출할 수 있다. 예를 들어, 합성하고자 하는 텍스트는 \"당신의 이번 달의 전화 요금은 16원입니다 ( )\"이고, 차이 텍스트는 \"16\"인 경우, 합성하고자 하는 텍스트에서의 차이 텍스트 \"16\"의 제1 시작 위치는 \"1\"에 대응되는 텍스트 위치이고, 제1 종료 위치는 \"6\"에 대응되는 텍스트 위치이며, 제1 음향 특징에서 제1 시작 위치 내지 제1 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 음향 특징을 타겟 제1 음향 특징으로 할 수 있다. 일 실시 방식에서, 제2 음향 특징에서 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 단계는 타겟 템 플릿 텍스트에서의 일치 텍스트의 제2 시작 위치 및 제2 종료 위치를 획득하여, 제2 음향 특징에서 제2 시작 위 치 내지 제2 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 음향 특징을 타겟 제2 음향 특징으로 하는 단 계를 포함할 수 있다. 이에 따라, 당해 방법은 제2 시작 위치 및 제2 종료 위치를 기반으로, 제2 음향 특징에서 타겟 제2 음향 특징을 정확하게 추출할 수 있다. 예를 들어, 타겟 템플릿 텍스트가 \"당신의 이번 달의 전화 요금은 100원입니다( )\" 인 경우, 일치 텍스트는 \"당신의 이번 달의 전화 요금은( )\" 및 \"원(元)\"을 포함하고, 타겟 템플릿 텍스트에서의 일치 텍스트 \"당신의 이번 달의 전화 요금은( )\"의 제2 시작 위치는 \"당 신()\"에 대응되는 텍스트 위치이고, 제2 종료 위치는 \"\" 에 대응되는 텍스트 위치이며, 타겟 템플릿 텍스 트에서의 일치 텍스트 \"원(元)\"의 제2 시작 위치 및 제2 종료 위치는 모두 \"원(元)\"에 대응되는 텍스트 위치이 며, 제2 음향 특징에서 제2 시작 위치 내지 제2 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 음향 특징 을 타겟 제2 음향 특징으로 할 수 있다. 일 실시 방식에서, 제1 음향 특징에서 제1 시작 위치 내지 제1 종료 위치에 대응되는 음향 특징을 추출하는 단 계는 합성하고자 하는 텍스트의 텍스트 위치와 제1 음향 특징의 특징 위치 사이의 대응 관계를 획득하여, 대응 관계를 기반으로 제1 시작 위치 및 제1 종료 위치에 대응되는 제1 음향 특징 중의 제3 시작 위치 및 제3 종료 위치를 획득하고, 제1 음향 특징에서 제3 시작 위치 및 제3 종료 위치에 대응되는 음향 특징을 추출하는 단계를 포함할 수 있다. 설명해야 하는 바로는, 제2 음향 특징에서 제2 시작 위치 내지 제2 종료 위치에 대응되는 음향 특징을 추출하는 단계에 관련된 내용은 제1 음향 특징에서 제1 시작 위치 내지 제1 종료 위치에 대응되는 음향 특징을 추출하는 단계에 관련된 내용을 참조할 수 있으나, 여기서 반복하지 않는다. S306, 상기 타겟 제1 음향 특징 및 상기 타겟 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성한 다. 단계 S306에 관련된 내용은 상기 실시예를 참조할 수 있으나, 여기서 반복하지 않는다. S307, 합성하고자 하는 텍스트의 텍스트 특징, 음색 특징 및 타겟 음향 특징을 스플라이싱하여, 제2 스플라이싱 특징을 생성한다. 설명해야 하는 바로는, 합성하고자 하는 텍스트의 텍스트 특징에 관련된 내용은 상기 실시예를 참조할 수 있으 나, 여기서 반복하지 않는다. 본 개시의 실시예에서, 합성하고자 하는 텍스트의 텍스트 특징, 음색 특징 및 타겟 음향 특징을 스플라이싱하여, 제2 스플라이싱 특징을 생성할 수 있으므로, 생성된 제2 스플라이싱 특징으로서 합성하고자 하 는 텍스트의 텍스트 특징, 음색 특징 및 타겟 음향 특징을 동시 구비할 수 있으며, 특징 표현 효과가 더 우수하 다. 일 실시 방식에서, 합성하고자 하는 텍스트의 텍스트 특징, 음색 특징 및 타겟 음향 특징을 스플라이싱하여, 제 2 스플라이싱 특징을 생성하는 단계는 텍스트 특징, 음색 특징 및 타겟 음향 특징의 합을 제2 스플라이싱 특징 으로 하는 단계를 포함할 수 있다. S308, 제2 스플라이싱 특징을 기반으로 타겟 음성을 합성한다. 일 실시 방식에서, 제2 스플라이싱 특징을 기반으로 타겟 음성을 합성하는 단계는 제2 스플라이싱 특징을 음성 합성 알고리즘에 입력하여, 음성 합성 알고리즘에 의해 합성하고자 하는 텍스트의 타겟 음성을 출력하는 단계를 포함할 수 있다. 음성 합성 알고리즘은 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지"}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "않는다.요약하면, 본 개시의 실시예의 음성 합성 방법에 따르면, 합성하고자 하는 텍스트와 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 기반으로, 제1 음향 특징에서 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추 출하고, 제2 음향 특징에서 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하며, 타겟 제1 음향 특징 및 타 겟 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하고, 합성하고자 하는 텍스트의 텍스트 특징, 음색 특징 및 타겟 음향 특징을 스플라이싱하여, 제2 스플라이싱 특징을 생성하며, 제2 스플라이싱 특징을 기반으로 타겟 음성을 합성할 수 있으므로, 타겟 음성으로서 타겟 사용자의 음색 특징을 구비하여, 음성 합성의 개인화를 향상시키는데 유리하다. 본 개시의 실시예에서, 사전 트레이닝된 타겟 음성 합성 모델을 획득할 수 있고, 합성하고자 하는 텍스트, 타겟 템플릿 오디오 및 음성 특징을 타겟 음성 합성 모델에 입력하여, 타겟 음성 합성 모델에 의해 합성하고자 하는 텍스트의 타겟 음성을 출력할 수 있다. 이에 따라, 당해 방법은 타겟 음성 합성 모델을 통해 자동으로 음성 합 성을 구현하여, 음성 합성 효율을 향상시키는데 유리하다. 이해 가능한 바로는, 타겟 음성 합성 모델은 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않는다. 예를 들어, 타겟 음성 합성 모델은 NNS(Neural Networks, 신경망) 모델일 수 있다. 도 4에 도시된 바와 같이, 타겟 음성 합성 모델은 특징 예측층, 제1 특징 추출층, 제2 특징 추 출층, 특징 스플라이싱층 및 음성 합성층을 포함한다. 특징 예측층에 의해 합성하고자 하는 텍스트 및 음성 특징에 따라, 예측한 제1 음향 특징을 획득한다. 제1 특징 추출층에 의해 타겟 템플릿 오디오의 제2 음향 특징을 추출한다. 제2 특징 추출층에 의해 합성하고자 하는 텍스트의 텍스트 특징을 추출한다. 특징 스플라이싱층에 의해 제1 음향 특징, 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성하고, 텍스트 특징, 음성 특징 중의 음색 특징 및 타겟 음향 특징을 스플라이싱하여, 제2 스플라이싱 특징을 생성한다. 음성 합성층에 의해 제2 스플라이싱 특징을 기반으로 타겟 음성을 합성한다. 일 실시 방식에서, 트레이닝 샘플을 획득할 수 있으며, 트레이닝 샘플은 샘플 합성하고자 하는 텍스트, 샘플 타 겟 템플릿 오디오, 샘플 타겟 사용자의 음성 특징 및 샘플 타겟 음성을 포함한다. 이해 가능한 바로는, 트레이 닝 샘플은 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않는다. 트레이닝 샘플을 기반으로 음성 합성 모델에 대해 트레이닝하여, 모델 트레이닝 종료 조건을 충족하지 못함에 응답하여, 되돌아가서 다음 트레이닝 샘플을 사용하여 트레이닝 종료 조건을 충족할 때까지 모델 파라미터가 조 정된 음성 합성 모델에 대해 계속 트레이닝하여, 타겟 음성 합성 모델을 생성한다. 모델 트레이닝 종료 조건은 실제 상황에 따라 설정 가능하므로, 여기서 구체적으로 한정하지 않으며, 예를 들어 모델 트레이닝 횟수가 사전 설정된 횟수 임계값에 도달하는 조건, 모델 정밀도가 미리 설정된 정밀도 임계값에 도달하는 조건으로 설정 가 능하다. 도 5는 본 개시의 제1 실시예에 따른 음성 합성 장치의 블록도이다. 도 5에 도시된 바와 같이, 본 개시의 실시예의 음성 합성 장치는 예측 모듈, 추출 모듈, 스플라 이싱 모듈, 합성 모듈을 포함한다. 예측 모듈은 합성하고자 하는 텍스트를 획득하고 타겟 사용자의 음성 특징을 획득하여, 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 예측한 제1 음향 특징을 획득하는데 사용되고; 추출 모듈은 상기 합성하고자 하는 텍스트에 따라, 템플릿 오디오 라이브러리로부터 타겟 템플릿 오디오를 획득하고, 상기 타겟 템플릿 오디오의 제2 음향 특징을 추출하는데 사용되고; 스플라이싱 모듈은 상기 제1 음향 특징 및 상기 제2 음향 특징을 스플라이싱하여, 타겟 음향 특징을 생성 하는데 사용되고; 합성 모듈은 상기 타겟 음향 특징 및 상기 음성 특징을 기반으로, 상기 합성하고자 하는 텍스트에 대해 음 성 합성을 수행하여, 상기 합성하고자 하는 텍스트의 타겟 음성을 생성하는데 사용된다. 본 개시의 일 실시예에서, 상기 스플라이싱 모듈은 상기 타겟 템플릿 오디오에 대응되는 타겟 템플릿 텍스 트를 획득하는 제1 획득 유닛; 상기 합성하고자 하는 텍스트와 상기 타겟 템플릿 텍스트 사이의 일치 텍스트 및 차이 텍스트를 획득하는 제2 획득 유닛; 상기 제1 음향 특징에서 상기 차이 텍스트에 대응되는 타겟 제1 음향 특징을 추출하고, 상기 제2 음향 특징에서 상기 일치 텍스트에 대응되는 타겟 제2 음향 특징을 추출하는 추출 유닛; 상기 타겟 제1 음향 특징 및 상기 타겟 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하 는 스플라이싱 유닛;을 포함한다. 본 개시의 일 실시예에서, 상기 추출 유닛은 상기 합성하고자 하는 텍스트에서의 상기 차이 텍스트의 제1 시작 위치 및 제1 종료 위치를 획득하고; 상기 제1 음향 특징에서 상기 제1 시작 위치 내지 상기 제1 종료 위치에 대 응되는 음향 특징을 추출하여, 추출된 상기 음향 특징을 상기 타겟 제1 음향 특징으로 하는데 더 사용된다. 상기 추출 유닛은 상기 타겟 템플릿 텍스트에서의 상기 일치 텍스트의 제2 시작 위치 및 제2 종료 위치를 획득 하고; 상기 제2 음향 특징에서 상기 제2 시작 위치 내지 상기 제2 종료 위치에 대응되는 음향 특징을 추출하여, 추출된 상기 음향 특징을 상기 타겟 제2 음향 특징으로 하는데 더 사용된다. 본 개시의 일 실시예에서, 상기 예측 모듈은 상기 타겟 사용자의 식별자 정보를 획득하고; 상기 식별자 정 보에 따라, 상기 타겟 사용자의 음성 특징을 획득하는데 더 사용된다. 본 개시의 일 실시예에서, 상기 음성 특징은 스타일 특징 및 음색 특징을 포함하며; 상기 예측 모듈은 상 기 합성하고자 하는 텍스트 및 상기 스타일 특징에 따라, 상기 제1 음향 특징을 획득하는데 더 사용된다. 본 개시의 일 실시예에서, 상기 예측 모듈은 상기 합성하고자 하는 텍스트에 대해 벡터화 처리를 수행하여, 벡터 특징을 획득하고; 상기 벡터 특징에 대해 순차적으로 컨볼루션 처리 및 양방향 타임 루프 처리 를 수행하여, 상기 합성하고자 하는 텍스트의 텍스트 특징을 획득하고; 상기 텍스트 특징 및 상기 스타일 특징 을 스플라이싱하여, 제1 스플라이싱 특징을 획득하고; 상기 제1 스플라이싱 특징에 대해 순차적으로 컨볼루션 처리, 양방향 타임 루프 처리 및 선형 처리를 수행하여, 상기 제1 음향 특징을 획득하는데 더 사용된다. 본 개시의 일 실시예에서, 상기 합성 모듈은 상기 합성하고자 하는 텍스트의 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 제2 스플라이싱 특징을 생성하고; 상기 제2 스플라이싱 특징을 기반 으로 상기 타겟 음성을 합성하는데 더 사용된다. 본 개시의 일 실시예에서, 상기 장치는 입력 모듈을 더 포함하며, 상기 입력 모듈은 상기 합성하고자 하는 텍스 트, 상기 타겟 템플릿 오디오 및 상기 음성 특징을 타겟 음성 합성 모델에 입력하는데 사용된다. 상기 타겟 음 성 합성 모델은 특징 예측층, 제1 특징 추출층, 제2 특징 추출층, 특징 스플라이싱층 및 음성 합성층을 포함한 다. 상기 특징 예측층에 의해 상기 합성하고자 하는 텍스트 및 상기 음성 특징에 따라, 상기 제1 음향 특징을 획득 하고; 상기 제1 특징 추출층에 의해 상기 타겟 템플릿 오디오의 상기 제2 음향 특징을 추출하고; 상기 제2 특징 추출층에 의해 상기 합성하고자 하는 텍스트의 상기 텍스트 특징을 추출하고; 상기 특징 스플라이싱층에 의해 상기 제1 음향 특징과 상기 제2 음향 특징을 스플라이싱하여, 상기 타겟 음향 특징을 생성하고, 상기 텍스트 특징, 상기 음색 특징 및 상기 타겟 음향 특징을 스플라이싱하여, 상기 제2 스플 라이싱 특징을 생성하고; 상기 음성 합성층에 의해 상기 제2 스플라이싱 특징을 기반으로 상기 타겟 음성을 합성한다. 본 개시의 일 실시예에서, 상기 추출 모듈은 상기 템플릿 오디오 라이브러리에서 상기 템플릿 오디오에 대 응되는 템플릿 텍스트를 획득하고; 상기 합성하고자 하는 텍스트와 상기 템플릿 텍스트 사이의 유사도를 획득하 고; 유사도가 가장 높은 상기 템플릿 텍스트에 대응되는 상기 템플릿 오디오를 상기 타겟 템플릿 오디오로 하는 데 더 사용된다. 본 개시의 일 실시예에서, 상기 음향 특징은 기본 주파수 특징, 에너지 특징, 지속 시간 특징 중의 적어도 하 나를 포함한다."}
{"patent_id": "10-2022-0083591", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "요약하면, 본 개시의 실시예의 음성 합성 장치에 따르면, 합성하고자 하는 텍스트 및 음성 특징에 따라, 예측한 제1 음향 특징을 획득하고, 타겟 템플릿 오디오의 제2 음향 특징을 추출하며, 제1 음향 특징 및 제2 음향 특징 을 스플라이싱하여, 타겟 음향 특징을 생성하고, 타겟 음향 특징 및 음성 특징을 기반으로, 합성하고자 하는 텍스트에 대해 음성 합성을 수행하여, 합성하고자 하는 텍스트의 타겟 음성을 생성할 수 있다. 이에 따라, 타겟 음향 특징으로서 합성하고자 하는 텍스트의 제1 음향 특징 및 타겟 템플릿 오디오의 제2 음향 특징을 동시 구비 할 수 있으며, 특징 표현 효과가 더 우수하고, 타겟 음성의 진실 정도 및 자연스러운 정도를 향상시키는데 유리 하고, 음성 합성 효과가 더 우수하다. 본 개시의 기술적 수단에서 관련된 사용자 개인 정보의 수집, 저장, 사용, 프로세싱, 전송, 제공 및 공개 등의 처리는 모두 관계법령을 준수하고, 공서양속에 반하지 않는다. 본 개시의 실시예에 따르면, 본 개시는 또한 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램을 제공한다. 도 6은 본 개시의 실시예를 실시하기 위한 예시적인 전자 기기의 개략적인 블록도이다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크 스테이션, 개인용 디지털 비서, 서버, 블레이드 서버, 메인 프레임워크 컴퓨터 및 기타 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 나타내기 위한 것이다. 전자 기기는 또한 개인용 디지털 처리, 셀룰러 폰, 스마트 폰, 웨어러블 기기 및 기타 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 나타낼 수도 있다. 본 명세서에서 제시된 구성 요소, 이들의 연결 및 관계, 또한 이들의 기능은 단지 예 일 뿐이며 본문에서 설명되거나 및/또는 요구되는 본 개시의 구현을 제한하려는 의도가 아니다. 도 6에 도시된 바와 같이, 기기는 컴퓨팅 유닛을 포함하며, 읽기 전용 메모리(ROM)에 저장된 컴 퓨터 프로그램에 의해 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 의해 수행되어 각종 적절한 동작 및 처리를 수행할 수 있다. RAM에, 또한 기기가 오퍼레이션을 수행 하기 위해 필요한 각종 프로그램 및 데이터가 저장되어 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스 를 통해 서로 연결되어 있다. 입력/출력(I/O) 인터페이스도 버스에 연결되어 있다. 키보드, 마우스 등과 같은 입력 유닛; 각종 유형의 모니터, 스피커 등과 같은 출력 유닛; 자기 디스 크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 트랜시버 등과 같은 통신 유닛 을 포함하는 기기 중의 복수의 부품은 I/O 인터페이스에 연결된다. 통신 유닛은 장치(60 0)가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보/데이터를 교환하 는 것을 허락한다. 컴퓨팅 유닛은 프로세싱 및 컴퓨팅 능력을 구비한 다양한 범용 및/또는 전용 프로세싱 컴포넌트일 수 있다. 컴퓨팅 유닛의 일부 예시는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공 지능 (AI) 컴퓨팅 칩, 기계 러닝 모델 알고리즘을 수행하는 다양한 컴퓨팅 유닛, 디지털 신호 처리기(DSP), 및 임의 의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만, 이에 제한되지 않는다. 컴퓨팅 유닛 은 예를 들어 음성 합성 방법과 같은 윗글에서 설명된 각각의 방법 및 처리를 수행한다. 예를 들어, 일부 실시 예에서, 음성 합성 방법은 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함되어 있는 컴퓨터 소 프트웨어 프로그램으로 구현될 수 있다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또 는 통신 유닛을 통해 기기에 로드 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴퓨팅 유닛에 의해 수행되는 경우, 전술한 음성 합성 방법의 하나 또는 하나 이상의 단계를 수행할 수 있 다. 대안적으로, 다른 실시예에서, 컴퓨팅 유닛은 임의의 다른 적절한 방식을 통해(예를 들어, 펌웨어에 의해) 구성되어 음성 합성 방법을 수행하도록 한다. 여기서 설명되는 시스템 및 기술의 다양한 실시 방식은 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로 그래머블 게이트 어레이(FPGA), 주문형 집적 회로(ASIC), 특정 용도 표준 제품(ASSP), 시스템온칩(SOC), 복합 프로그래머블 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및 이들의 조합 중의 적어도 하나로 구현 될 수 있다. 이러한 다양한 실시 방식은 하나 또는 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있으 며, 당해 하나 또는 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그 램 가능 시스템에서 수행 및/또는 해석될 수 있고, 당해 프로그램 가능 프로세서는 전용 또는 일반용일 수 있고, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신하고 또 한 데이터 및 명령을 당해 저장 시스템, 당해 적어도 하나의 입력 장치 및 당해 적어도 하나의 출력 장치에 전 송할 수 있다. 본 개시의 방법을 구현하기 위해 사용되는 프로그램 코드는 하나 또는 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그래머블 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공될 수 있으므로, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 수행되는 경우, 흐름도 및/또는 블록도에서 규정한 기능/조작을 구현하도록 한다. 프로그램 코드는 전체적으로기계에서 수행되거나, 부분적으로 기계에서 수행되거나, 독립 소프트웨어 패키지로서 부분적으로 기계에서 수행 되고 부분적으로 원격 기계에서 수행되거나 또는 전체적으로 원격 기계 또는 서버에서 수행될 수 있다. 본 개시의 문맥에서, 기계 판독 가능 매체는 자연어 수행 시스템, 장치 또는 기기에 의해 사용되거나 자연어 수 행 시스템, 장치 또는 기기와 결합하여 사용되는 프로그램을 포함하거나 저장할 수 있는 유형의 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절한 조합을 포함할 수 있지만 이에 제한되지 않는다. 기계 판독 가능 저장 매체의 더 구체적인 예시는 하나 또는 하나 이상의 전선을 기반하는 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 지울 수 있는 프로그래머블 읽기 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 휴 대용 컴팩트 디스크 읽기 전용 메모리(CD-ROM), 광학 저장 기기, 자기 저장 기기 또는 상기 내용의 임의의 적절 한 조합을 포함할 수 있지만 이에 제한되지 않는다. 사용자와의 인터랙션을 제공하기 위해 여기에 설명된 시스템 및 기술은 컴퓨터에서 실시될 수 있다. 당해 컴퓨 터는 사용자에게 정보를 디스플레이하기 위한 디스플레이 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 디스플 레이) 모니터); 및 키보드 및 포인팅 장치(예를 들어, 마우스 또는 트랙볼)를 구비하며, 사용자는 당해 키보드 및 당해 포인팅 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 다른 유형의 장치를 사용하여 사용자와의 인터랙 션을 제공할 수도 있으며, 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 감지 피드백(예를 들어, 시 각적 피드백, 청각적 피드백 또는 촉각적 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력 또는 촉각 입 력을 포함)로 사용자로부터의 입력을 수신할 수 있다. 여기서 설명된 시스템 및 기술은 백엔드 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버로서), 또는 미 들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프런트 엔드 부품을 포함하는 컴퓨팅 시스 템(예를 들어, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터인 바, 사용자는 당 해 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 통해 여기서 설명된 시스템 및 기술의 실시 방식과 인 터랙션할 수 있음), 또는 이러한 백엔드 부품, 미들웨어 부품 또는 프런트 엔드 부품의 임의의 조합을 포한하는 컴퓨팅 시스템에서 실시될 수 있다. 시스템의 부품은 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 서로 연결될 수 있다. 통신 네트워크의 예시는 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통신 네트워크를 통해 인터랙션한다. 서로 클라이언트-서버 관계를 가지는 컴퓨터 프로그램을 대응되는 컴 퓨터에서 수행하여 클라이언트와 서버 간의 관계를 생성한다. 서버는 클라우드 컴퓨팅 서버일 수 있고, 분산 시 스템의 서버일 수도 있고, 또는 블록체인을 결합한 서버일 수도 있다. 본 개시의 실시예에 따르면, 본 개시는 또한 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램을 제공하며, 상기 컴 퓨터 프로그램이 프로세서에 의해 수행되는 경우, 본 개시의 상기 실시예에 따른 음성 합성 방법의 단계를 구현 한다. 이해 가능한 바로는, 전술한 다양한 형식의 프로세스에 있어서 단계 재정렬, 추가 또는 삭제를 할 수 있다. 예 를 들어, 본 개시에 개시된 기술 솔루션이 이루고자 하는 결과를 구현할 수 있는 한, 본 개시에 기재된 각 단계 들은 병렬로, 순차적으로 또는 다른 순서로 수행될 수 있으나, 본 명세서에서 이에 대해 한정하지 않는다. 전술한 구체적인 실시 방식들은 본 개시의 보호 범위에 대한 한정을 구성하지 않는다. 당업자라면 본 개시의 설 계 요건 및 기타 요인에 따라 다양한 수정, 조합, 서비스 조합 및 대체가 이루어질 수 있음을 이해해야 한다. 본 개시의 정신과 원칙 내에서 이루어진 모든 수정, 동등한 대체 및 개선은 본 개시의 보호 범위에 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2022-0083591", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 개시의 수단을 더 잘 이해하기 위한 것으로, 본 개시에 대한 한정이 구성되지 않는다. 도 1은 본 개시의 제1 실시예에 따른 음성 합성 방법의 개략적인 흐름도이다. 도 2는 본 개시의 제2 실시예에 따른 음성 합성 방법의 개략적인 흐름도이다. 도 3은 본 개시의 제3 실시예에 따른 음성 합성 방법의 개략적인 흐름도이다. 도 4는 본 개시의 제1 실시예에 따른 타겟 음성 합성 모델의 개략도이다. 도 5는 본 개시의 제1 실시예에 따른 음성 합성 장치의 블록도이다. 도 6은 본 개시의 실시예의 음성 합성 방법을 구현하기 위한 전자 기기의 블록도이다."}
