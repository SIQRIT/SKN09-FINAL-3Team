{"patent_id": "10-2021-0173545", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0085409", "출원번호": "10-2021-0173545", "발명의 명칭": "다중 전환 대화를 위한 상황 인지 질의응답 시스템", "출원인": "한양대학교 에리카산학협력단", "발명자": "이동호"}}
{"patent_id": "10-2021-0173545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대화의 주제를 분류하여 저장소에 저장을 하여 여러 주제 및 이미 대화가 끝난 주제에 대해 다시 확인이 가능한다중 전환 대화를 위한 상황 인지 질의응답 시스템."}
{"patent_id": "10-2021-0173545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "하나의 대화 기록에 서로 다른 대화 주제가 존재할 경우 현재 질문에 답변을 줄 때, 상관없는 주제에 대한 노이즈를 제거하고 과거 대화 기록을 학습에 반영하여 답변을 주는 다중 전환 대화를 위한 상황 인지 질의응답 시스템."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "기존의 질의응답 시스템의 문제들을 해결하기 위하여 주제 분류 모델, 히스토리 스토리지, 정답 예측 모델이라는 새로운 시스템 구조를 활용하여 멀티턴 기반의 상황 인지가 가능한 질의응답 시스템을 제공한다."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티턴 기반의 인공지능 질의응답 시스템에 관한 것이다."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 챗봇은 인간-상호작용 대화와 비슷한 자연스러운 대화를 추구하기 위해, 단답형 대화가 아닌 연속된 대화가 가능한 멀티턴 대화를 추구한다. CHEN, Danqi, et al. “Reading wikipedia to answer open-domain questions“에서 제안하는 DrQA는 TF-IDF를 통해 사용자 질의 안에 존재하는 키워드들이 Wikipedia에 있는 문서 내부에 얼마나 많이 존재하는지 빈도수를 계산하여 관련 문서들을 선택하고 RNN 구조의 QA 모델을 통해 답변을 제공해주는 시스템이다. HUANG, Hsin-Yuan; CHOI, Eunsol; YIH, Wen-tau. “Flowqa: Grasping flow in history for conversational machine comprehension”는 전체 대화 기록을 보다 포괄적으로 통합하는 다중 전환 시스템이다. FlowQA는 현재 질문에 대해 답벼을 해줄 때, 이전에 나온 대화 기록을 모두 통합한 후, 통합된 정보를 고려해서 답변을 주기 때문에 보다 정확한 답을 줄 수 있다. 하지만 기존 인공지능 챗봇에서는 한 주제에 대해서 대화를 하던 도중 다른 주제로 대화를 전환하는 경우 변화 된 대화의 상황을 인지하지 못하여 적절한 대답을 하지 못하는 문제가 존재한다."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "DrQA는 단답형 대화가 아닌 연속된 대화를 위해 이전 질문 키워드와 관련된 질문을 대명사(예: 그것, 이거, 저 거 등)로 대체해서 질문했을 경우, QA 시스템이 대명사를 이해 못 하고 대답을 못 해주거나 잘못된 대답을 해줄 수 있다는 단점이 있다. FlowQA는 하나의 대화 기록에 서로 다른 대화 주제가 존재할 경우 현재 질문에 대한 답변을 줄 때, 상관없는 주 제가 노이즈로 작용되어 잘못된 답변을 줄 수 있다는 단점이 있다. 이러한 문제들을 해결하기 위해 주제 분류 모델, 히스토리 스토리지, 정답 예측 모델이라는 새로운 시스템 구조 를 활용하여 멀티턴 기반의 상황 인지가 가능한 질의응답 시스템을 제공하고자 한다."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "JointKoBERT를 사용한 주제 분류 모델을 통해 한 대화에 존재하는 여러 주제에 대해서 분류할 수 있게 되고, 히 스토리 스토리지를 통해 여러 주제에 대한 대화를 각각 저장하여 각각의 주제에 대한 대답이나 끝난 주제에 대 해서 다시 질문이 들어왔을 때, 이전의 대화를 불러와 대답을 해줄 수 있게 된다. 이렇게 함으로써 대화의 주제가 변경되었을 때나 지나간 주제에 대한 문제를 해결할 수 있다. BERT와 HAE(History Attention Embedding)을 활용한 정답 예측 모델 구조를 활용하여 이전 대화의 위치 정보를 이용함으로써 기존의 방법들보다 과거의 문맥적 관계를 좀 더 자세히 이해시켜 학습시킬 수 있다."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "기존의 질의응답 시스템과 다르게 과거의 대화도 고려하여 문맥적 의미를 좀 더 자세히 파악할 수 있고, 한 대 화에서 여러 주제가 등장했을 때의 구분하여 대답해줄 수 있고 지나간 주제에 대한 질문에 대답을 해줄 수 있다."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1 내지 도 7을 참조하여 본 발명의 기술에 대해 설명하도록 한다. 도 1은, 본 발명의 전체 시스템 구조도로, 주제 분류 모델을 통해 질문에 대한 각 주제를 분류하고, 히스토리 스토리지에 주제 분류 모델을 통해 분류한 각 주제 질문을 저장한다. 이후 각 주제에 대해 히스토리 스토리지에 저장된 모든 문장을 정답 예측 모델에 입력이 되어 디코더에서 입력된 데이터를 통해 새로운 단어들을 생성한 후 하나의 정답 문장을 출력한다. 입력에 질문이 들어왔을 때, 질문이 주제 분류 모델의 입력으로 들어가 질문에 해당하는 주제로 분류해서 모델 의 출력으로 나오게 된다. 그 후 히스토리 저장소에 들어가게 되는데, ① 히스토리 저장소에 존재하는 주제(M T:정육점, GR:청과점, CF:카페, BK:제과점)가 들어온다면 각 주제에 맞는 히스토리에 저장이 되고, 히스토리 스 토리지에 존재하는 주제가 아닌 다른 주제 즉, CM(COMMON : 공통된 질문)이 나온다면 Qk에서 가장 가까운 HQk-1 의 주제로 변환되어 저장된다. 이후, Hsuject(Q,A)k와 관련이 있는 P와 함께 정답 예측 모델의 입력으로 들어가게 되고 Hak이 출력으로 나오게 된다. ② 정답 예측 모델에서 나온 Hak은 Qk와 같은 주제로 히스토리에 Hak로 저장된다. 실시예 1. 데이터 셋 한국어 기반 주제 변경에 강한 다중 전환 QA 시스템을 구축하기 위해 주제 변경에 관한 한국어 데이터 세트를 자체적으로 구축하였다. 데이터 세트는 AI Hub의 한국어 대화 AI 데이터의 정육점, 제과점, 청과점, 카페에 해 당하는 한국어 대화 데이터 셋을 활용하여 정답 예측 모델에 사용할 문서와 문서의 내용에 관한 질문, 답변 쌍 데이터 세트를 구축하였고, 주제 분류 모델에 사용할 질문 리스트를 추출한 후 질문 리스트 안의 문장들의 각 단어에 맞는 태그에 따라 도 6과 같이 수동적으로 태깅을 한 후, 학습 데이터 세트를 구축하였다. 주제 분류 모델에서 입력 질문에 대해 분류하고자 하는 주제는 도 7의 5개에 해당하는 주제이며, 각 주제에 대 한 세부 태그는 주제에 해당하는 이름, 물품, 속성 3가지 형태로 정의하였다. 실시예 2. 주제 분류 모델 개체명 인식은 문장의 각 토큰에서 이름을 가진 개체를 인식하는 것이므로 문맥에 대한 분석이 매우 중요하게 작용한다. 공백을 기준으로 명확하게 단어를 구분할 수 있는 영어와 달리 한국어의 경우에는 문장에 따라 단어 앞뒤에 어절이나 어미가 붙기 때문에 똑같은 단어가 존재하는 여러 문장이 있다고 하더라도 공백 단위로 자르게되면 문장의 종류에 따라 다른 형태로 나올 수 있다. 그렇기 때문에 같은 단어라고 해도 모델 학습을 시켰을 때, 다른 분류 결과가 나올 수 있는 문제가 발생할 수 있다. 이러한 문제를 해결하기 위하여 형태소 분석기를 사용해 한국어 문장의 단어에 붙어 있는 어미, 어절, 조사를 분리한 후 학습하였다. 기존의 JointBERT에서는 사전 학습 모델인 BERT를 사용했지만, 본 발명에서는 보다 한국어 기반 데이터 셋을 잘 학습시키기 위해 대량의 한국어 텍스트 데이터로 사전 학습된 KoBERT와 결합하여 JointKoBERT로 사용하였다. JointKoBERT의 주제 분류 예시는 도 6과 같다. 입력 질문 문장이 주어지면 형태소 분석기(Mecab)를 통해 문장을 나눠 모델로 입력된다. 이후 모델의 산출물로 Pooled Output과 Sequence Output이 나오는데, Pooled Output은 주제 예측에 대한 결과, Sequence Output은 문장 토큰별 태그 예측 결과이다. 실시예 3. 정답 예측 모델 도 3은, 본 발명의 정답 예측 모델을 나타낸 것으로, 기존 FlowQA와 HAE와 달리 디코더의 입력으로 모든 대화 기록을 사용하고 출력에서 나온 벡터 값의 문장 표현을 소프트맥스 함수를 사용하여 문장의 확률을 계산하고, 그런 다음, 계산된 문장 확률과 토큰 수준의 벡터 값과의 내적 계산을 통홰 통합 표현을 만들고, Dense Layer에 서 소프트맥스 함수를 통해 정답일 확률이 가장 높은 시작 토큰과 종료 토큰을 예측 한, 최종적으로 정답을 출 력한다. 도 3에서 정답 예측은 다음과 같이 진행된다. 주제 분류 모델을 통해 얻은 Qk의 주제와 관련된 구절(P)과 Hsuject(Q,A)k을 히스토리 저장소를 통해 가져온다. 각 Hsuject(Q,A)k를 P와 연결한 값은 BERT 인코더의 입력 값이 되고, 인코더의 출력 값으로 토큰 수준과 문장 수준의 벡터 값이 출력된다. 이후 Qk의 어텐션 벡터 값을 문장 표현의 로짓에 매핑한 후, 소프트맥스 함수를 사용하여 동일한 인스턴스에서 생성된 모든 문장의 확률을 계산한다. 그런 다음, 계산된 문장 확률과 토큰 수준의 벡터 값과의 내적 계산을 통해 통합 표현을 만들고, Dense Layer에서 소프트맥스 함수를 통해 정답일 확률이 가장 높은 시작 토큰과 종료 토큰을 예측한 후, 최종적 으로 OutputAk을 출력한다. 실시예 4. QA 시스템의 성능 평가 본 발명의 QA 시스템의 성능을 평가하기 위해 주제 분류 모델에 5가지 주제(정육점, 청과점, 카페, 제과점, 공 통질문)에 대한 질문을 총 3,443개를 사용했고, 정답 예측 모델에 4가지 주제(정육점, 청과점, 카페, 제과점)에 대한 주제 변경 문서를 12가지 경우의 수에 대해서 각 500개씩 만들어 총 6,000개의 문서를 활용하고, 각 모델 에 사용된 질문과 문서들은 학습 데이터 세트 80%. 테스트 데이터 세트 20%의 비율로 사용하였다. 실험 결과는 도 5와 같다. FlowQA는 모델을 LSTM과 GRU를 사용하기 때문에 OOV에 대한 문제가 존재하여 성능 하 락에 영향을 끼치고, 모든 대화 기록을 활용하여 현재 질문에 답을 주기 때문에 대화 기록안에 현재 질문의 주 제와 일치하지 않은 주제들이 존재할 경우, 그것들이 노이즈로 작용하여 현재 질문에 대한 답변에 영향을 끼치 기 때문에 다른 모델들보다 성능이 낮게 나온다. BERT with HAE는 BERT를 사용했기에 OOV에 대한 문제가 해소되 지만, 현재 질문에 답변을 줄 때 이전 답변의 대한 정보만을 활용하기 때문에 현재 질문에 필요한 정보가 이전 답변에 존재하지 않은 경우 성능 하락에 영향을 끼칠 수 있다. 하지만 FlowQA에 비해서는 다른 주제들의 영향이 적게 작용한다. 본 발명에서 제안한 시스템은 히스토리 저장소와 주제 분류 모델을 활용하여 앞서 얘기했던 모 델들에 대한 문제들을 보완했기에 의미 있는 성능 향상을 보였다."}
{"patent_id": "10-2021-0173545", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였으나 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정 적이 아닌 것으로 이해해야만 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2021-0173545", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 전체 시스템 구조도를 나타낸 것이다. 도 2는 본 발명의 주제 분류 모델(JointKoBERT) 구조를 나타낸 것이다. 도 3은 본 발명의 정답 예측 모델 구조를 나타낸 것이다. 도 4은 본 발명 모델을 통해 생성된 질문의 대답 중 올바른 경우(Good Case)와 기존 질의응답 시스템의 대답 (Bad Case)을 나타낸 것이다. 도 5는 f1-score를 통해 본 발명 모델과 기존 질의응답 모델들 간의 점수 비교표를 나타낸 것이다. 도 6은 입력 질ㄹ문 문장에 대한 태그별 주제 분류 예시를 나타낸 것이다. 도 7은 주제 및 세부 태그 리스트를 나타낸 것이다."}
