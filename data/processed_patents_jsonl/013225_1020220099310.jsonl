{"patent_id": "10-2022-0099310", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0020948", "출원번호": "10-2022-0099310", "발명의 명칭": "디지털휴먼 컨텐츠 생성 시스템 및 이를 이용한 디지털휴먼 컨텐츠 생성 방법", "출원인": "트라이콤텍 주식회사", "발명자": "이상윤"}}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디지털휴먼 서버(100), 컨텐츠관리 서버(200) 및 이와 네트워크 연결된 메타버스 클라우드 서버(300)를 포함하는, 디지털휴먼 컨텐츠 생성 시스템(1)에서 이뤄지는 디지털휴먼 컨텐츠 생성 방법으로,a) 상기 디지털휴먼 서버(100)가, 미리 설정된 가상 모델 구성방법에 기초하여 가상 모델을 구성하는 단계;b) 상기 디지털휴먼 서버(100)가, 미리 수집된 모션 정보를 상기 가상 모델과 매칭하여 디지털휴먼 정보를 생성하는 단계;c) 상기 디지털휴먼 서버(100)가, 상기 디지털휴먼 정보를 상기 메타버스 클라우드 서버(300)로 전달하는 단계;및d) 상기 메타버스 클라우드 서버(300)가, 상기 컨텐츠관리 서버(200)로부터 수신된 가상현실 컨텐츠 정보 및 상기 디지털휴먼 정보를 결합하여 디지털휴먼 컨텐츠를 생성하는 단계;를 포함하는, 디지털휴먼 컨텐츠 생성방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 a) 단계의 미리 설정된 가상 모델 구성방법은,a1) 상기 디지털휴먼 서버(100)와 네트워크 연결된 가상 모델 생성 스튜디오(120)에 구비된 전신 캡쳐 장치를통해 사용자 모델을 촬영하여 사용자 이미지 정보를 수집하는 단계;a2) 상기 사용자 이미지 정보에 기초하여 가상 모델 기초 모델링 정보를 생성하는 단계; 및a3) 상기 생성된 가상 모델 기초 모델링 정보를 후처리하여 가상 모델을 구성하는 단계;를 포함하는 것을 특징으로 하는, 디지털휴먼 컨텐츠 생성 방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 a3) 단계는,a31) 상기 가상 모델 기초 모델링 정보에 색상 및 질감을 부여하는 텍스쳐링 단계; 및a32) 상기 가상 모델 기초 모델링 정보에 관절 및 뼈대를 부여하는 리깅 단계;를 포함하며, 상기 a31) 단계 및 a32) 단계 중 적어도 어느 하나는 인공지능 처리 모듈에 의해 자동으로 이뤄지는 것을 특징으로 하는, 디지털휴먼 컨텐츠 생성 방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서,상기 a31) 단계는, 상기 전신 캡쳐 장치에 구비된 적어도 하나 이상의 서로 다른 위치 또는 서로 다른 파장을갖는 복수개의 조명에 의해 촬영된 적어도 2 이상의 사용자 이미지 정보에 기초하여 자동으로 처리되는 것을 특징으로 하는, 디지털휴먼 컨텐츠 생성 방법.공개특허 10-2024-0020948-3-청구항 5 제3항에서,상기 사용자 이미지 정보는, 상기 사용자 모델의 복수개의 미리 설정된 포즈 이미지 정보를 포함하며,상기 a32) 단계는, 상기 사용자 모델의 포즈 이미지 정보에 기초하여 자동으로 처리되는 것을 특징으로 하는,디지털휴먼 컨텐츠 생성 방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에서,상기 미리 수집된 모션 정보는,상기 디지털휴먼 서버(100)와 네트워크 연결된 모션 정보 수집 스튜디오(140)에 구비된 모션 캡쳐 장치를 통해수집된 사용자 모델의 움직임 정보이며,얼굴의 움직임을 나타내는 페이스모션 정보와, 바디 및 손의 움직임을 나타내는 바디모션 정보 중 적어도 어느하나를 포함하는 것을 특징으로 하는, 디지털휴먼 컨텐츠 생성 방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에서,상기 디지털휴먼 정보는 복수의 가상 모델에 대해 적어도 하나 이상의 모션 정보를 결합하여 복수개로구성되며,상기 복수개의 디지털휴먼 정보는, 상기 미리 수집된 모션 정보에서 상기 페이스모션 정보 및 바디모션 정보 중적어도 어느 하나가 다른 디지털휴먼 정보와 구별 가능하도록 하는 하나 이상의 시그니처 모션 정보를 각각 포함하는 것을 특징으로 하는, 디지털휴먼 컨텐츠 생성 방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에서,상기 디지털휴먼 컨텐츠는 미리 설정된 이벤트 정보를 더 포함하며,상기 미리 설정된 이벤트 정보는, 상기 시그니처 모션 정보에 기초하여 생성되는 것을 특징으로 하는, 디지털휴먼 컨텐츠 생성 방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에서,상기 디지털휴먼 정보는,상기 모션 정보 수집 스튜디오(140)에서 수집된 사용자 모델의 음성 정보를 더 포함하여 구성되는 것을 특징으로 하는, 디지털휴먼 컨텐츠 생성 방법."}
{"patent_id": "10-2022-0099310", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "디지털휴먼 서버(100), 컨텐츠관리 서버(200) 및 이와 네트워크 연결된 메타버스 클라우드 서버(300)를 포함하공개특허 10-2024-0020948-4-는 디지털휴먼 컨텐츠 생성 시스템(1)으로,미리 설정된 가상 모델 구성방법에 기초하여 가상 모델을 구성하고, 미리 수집된 모션 정보를 상기 가상 모델과매칭하여 디지털휴먼 정보를 생성하며, 상기 디지털휴먼 정보를 상기 메타버스 클라우드 서버(300)로 전달하는기능을 수행하는 디지털휴먼 서버(100);복수의 가상현실 컨텐츠 정보를 관리하고, 상기 메타버스 클라우드 서버(300)의 요청에 의해 적어도 어느 하나의 가상현실 컨텐츠 정보를 상기 메타버스 클라우드 서버(300)로 전달하는 기능을 수행하는 컨텐츠관리 서버(200); 및상기 컨텐츠관리 서버(200)로부터 수신된 가상현실 컨텐츠 정보 및 상기 디지털휴먼 정보를 결합하여 디지털휴먼 컨텐츠를 생성하는 기능을 수행하는 메타버스 클라우드 서버(300);를 포함하는, 디지털휴먼 컨텐츠 생성 시스템."}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 디지털휴먼 컨텐츠 생성 시스템 및 이를 이용한 디지털휴먼 컨텐츠 생성 방법에 관한 것으로, 본 발명의 바람직한 실시예에 따르면, 디지털휴먼 서버, 컨텐츠관리 서버 및 이와 네트워크 연결된 메 타버스 클라우드 서버를 포함하는, 디지털휴먼 컨텐츠 생성 시스템에서 이뤄지는 디지털휴먼 컨텐츠 생 (뒷면에 계속)"}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디지털휴먼 컨텐츠 생성 시스템 및 이를 이용한 디지털휴먼 컨텐츠 생성 방법으로서, 상세하게는 미 리 설정된 가상 모델 구성방법에 기초하여 구성된 가상 모델과 미리 수집된 모션 정보를 매칭하여 디지털휴먼 정보를 생성하고, 이를 가상현실 컨텐츠 정보와 결합함으로써 가상현실 내에서 가상 모델의 자연스러운 동작이 이뤄질 수 있고 하나의 시스템에서 효율적으로 디지털휴먼 컨텐츠를 생성할 수 있도록 하는 디지털휴먼 컨텐츠 생성 시스템 및 이를 이용한 디지털휴먼 컨텐츠 생성 방법에 관한 것이다."}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "코로나 등 전세계적인 감염병의 확산으로 인해, 교육, 회의, 전시회 및 대회 등에서 온라인 및 비대면 환경에 대한 요구가 증가되고 있으며, 이에 관한 연구나 수요도 급증하고 있는 실정이다. 종래 기술은 주로 특정 컨텐츠를 대상으로 하고 사용자에게 일방적인 컨텐츠를 전달하는데 그치고 있으므로, 가 상현실을 기반으로 하되 사용자의 다양한 참여가 가능하도록 하는 기술로 디지털휴먼을 생성하고 이를 활용하는 기술이 주목받고 있다. 종래 기술의 일례로서, 대한민국 등록특허 제10-2373608호의 \"디지털 휴먼 영상 형성을 위한 전자 장치 및 방법 과, 그를 수행하도록 컴퓨터 판독 가능한 기록 매체에 저장된 프로그램\"이 있다. 상기 종래기술은, 대상체의 이미지를 획득하고, 대상체의 이미지로부터 디지털 휴먼 영상의 얼굴 이미지 형성을 위한 제1 특징점 및 디지털 휴먼 영상의 모발 이미지 형성을 위한 제2 특징점을 추출하고, 대상체와 디지털 휴 먼 영상과의 친밀도 및 대상체의 나이를 고려하여 제1 특징점에 제1 가중치를 부여하고, 대상체의 움직임, 바람 및 대상체 외부에서 작용하는 힘을 고려하여 제2 특징점에 제2 가중치를 부여하고, 대상체의 실시간 얼굴 형상 및 실시간 자세를 고려하여 제1 특징점 및 제2 특징점에 제3 가중치를 부여하고, 제1 가중치 및 제3 가중치가 반영된 제1 특징점 및 제2 가중치 및 제3 가중치가 반영된 제2 특징점을 이용하여 대상체와 일치도가 가장 높은 대역 모델을 선택하고, 대역 모델을 3차원 스캐닝하고, 다양한 각도에서의 이미지를 촬영하여 제1 3차원 데이터 를 형성하고, 제1 3차원 데이터를 이용하여 대상체의 제1 영상을 형성하고, 미리 설정된 표정 템플릿을 뎁스 카 메라로 촬영하여 제2 3차원 데이터를 형성하고, 제2 3차원 데이터를 이용하여 대상체의 표정을 나타내는 제2 영 상을 형성하고, 3차원 애니메이션 포인트를 이용하여 제1 영상과 제2 영상을 합성하여 디지털 휴먼 영상을 형성 하도록 구성된다. 상기 종래기술은 대상체와 디지털 휴먼 영상과의 친밀도 및 대상체의 나이를 고려하여 디지털 휴먼 영상에 가중 치를 부여함으로써 보다 정교하면서도 실감나는 디지털 휴먼 영상을 형성할 수 있다는 장점이 있으나, 디지털 휴먼 영상을 구성하는데 친밀도, 나이 및 다수의 가중치 등 많은 고려사항으로 인해 얼굴 및 몸(바디)을 포함한 전신의 고해상도의 영상을 구성하기 위해서는 리소스(자원)가 많이 소요되고, 가상현실 컨텐츠와의 결합을 통한 디지털휴먼 컨텐츠를 생성하는데 많은 시간이 필요함은 물론 끊김없는 영상 제공이 어렵다는 한계가 있으며, 친"}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "밀도 및 가중치 등에 의한 영상 구성의 효율성 향상이 크지 않다는 문제가 있다.발명의 내용"}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 종래기술이 가지는 문제점을 해결하기 위한 것으로서, 사용자 모델을 통한 이미지 수집부터 가 상현실 기반의 디지털휴먼 컨텐츠 생성까지 하나의 시스템에서 이뤄지도록 하는 디지털휴먼 컨텐츠 생성 시스템 및 방법을 제공하고자 한다. 또한, 본 발명은 사람에 의한 텍스쳐링 및/또는 리깅 등의 후처리 과정을 최소화하는 자동화된 후처리 공정을 제공하며, 다양한 디지털휴먼 컨텐츠를 효율적으로 관리하는 기술을 제공고자 한다."}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 과제를 해결하기 위한 본 발명의 바람직한 실시예에 따르면, 디지털휴먼 서버, 컨텐츠관리 서버 및 이와 네트워크 연결된 메타버스 클라우드 서버를 포함하는, 디지털휴먼 컨텐츠 생성 시스템에서 이뤄지는 디지 털휴먼 컨텐츠 생성 방법으로, a) 상기 디지털휴먼 서버가, 미리 설정된 가상 모델 구성방법에 기초하여 가상 모델을 구성하는 단계; b) 상기 디지털휴먼 서버가, 미리 수집된 모션 정보를 상기 가상 모델과 매칭하여 디지 털휴먼 정보를 생성하는 단계; c) 상기 디지털휴먼 서버가, 상기 디지털휴먼 정보를 상기 메타버스 클라우드 서 버로 전달하는 단계; 및 d) 상기 메타버스 클라우드 서버가, 상기 컨텐츠관리 서버로부터 수신된 가상현실 컨텐 츠 정보 및 상기 디지털휴먼 정보를 결합하여 디지털휴먼 컨텐츠를 생성하는 단계;를 포함하는, 디지털휴먼 컨 텐츠 생성 방법이 제공된다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 a) 단계의 미리 설정된 가상 모델 구성방법은, a1) 상기 디 지털휴먼 서버와 네트워크 연결된 가상 모델 생성 스튜디오에 구비된 전신 캡쳐 장치를 통해 사용자 모델을 촬 영하여 사용자 이미지 정보를 수집하는 단계; a2) 상기 사용자 이미지 정보에 기초하여 가상 모델 기초 모델링 정보를 생성하는 단계; 및 a3) 상기 생성된 가상 모델 기초 모델링 정보를 후처리하여 가상 모델을 구성하는 단 계;를 포함하는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 a3) 단계는, a31) 상기 가상 모델 기초 모델링 정보에 색상 및 질감을 부여하는 텍스쳐링 단계; 및 a32) 상기 가상 모델 기초 모델링 정보에 관절 및 뼈대를 부여하는 리깅 단계;를 포함하며, 상기 a31) 단계 및 a32) 단계 중 적어도 어느 하나는 인공지능 처리 모듈에 의해 자동으로 이뤄지는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 a31) 단계는, 상기 전신 캡쳐 장치에 구비된 적어도 하나 이상의 서로 다른 위치 또는 서로 다른 파장을 갖는 복수개의 조명에 의해 촬영된 적어도 2 이상의 사용자 이미 지 정보에 기초하여 자동으로 처리되는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 사용자 이미지 정보는, 상기 사용자 모델의 복수개의 미리 설정된 포즈 이미지 정보를 포함하며, 상기 a32) 단계는, 상기 사용자 모델의 포즈 이미지 정보에 기초하여 자 동으로 처리되는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 미리 수집된 모션 정보는, 상기 디지털휴먼 서버와 네트워 크 연결된 모션 정보 수집 스튜디오에 구비된 모션 캡쳐 장치를 통해 수집된 사용자 모델의 움직임 정보이며, 얼굴의 움직임을 나타내는 페이스모션 정보와, 바디 및 손의 움직임을 나타내는 바디모션 정보 중 적어도 어느 하나를 포함하는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 디지털휴먼 정보는 복수의 가상 모델에 대해 적어도 하나 이상의 모션 정보를 결합하여 복수개로 구성되며, 상기 복수개의 디지털휴먼 정보는, 상기 미리 수집된 모션 정 보에서 상기 페이스모션 정보 및 바디모션 정보 중 적어도 어느 하나가 다른 디지털휴먼 정보와 구별 가능하도 록 하는 하나 이상의 시그니처 모션 정보를 각각 포함하는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 디지털휴먼 컨텐츠는 미리 설정된 이벤트 정보를 더 포함하 며, 상기 미리 설정된 이벤트 정보는, 상기 시그니처 모션 정보에 기초하여 생성되는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 디지털휴먼 정보는, 상기 모션 정보 수집 스튜디오에서 수 집된 사용자 모델의 음성 정보를 더 포함하여 구성되는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 디지털휴먼 서버, 컨텐츠관리 서버 및 이와 네트워크 연결된 메 타버스 클라우드 서버를 포함하는 디지털휴먼 컨텐츠 생성 시스템으로, 미리 설정된 가상 모델 구성방법에 기초 하여 가상 모델을 구성하고, 미리 수집된 모션 정보를 상기 가상 모델과 매칭하여 디지털휴먼 정보를 생성하며, 상기 디지털휴먼 정보를 상기 메타버스 클라우드 서버로 전달하는 기능을 수행하는 디지털휴먼 서버; 복수의 가 상현실 컨텐츠 정보를 관리하고, 상기 메타버스 클라우드 서버의 요청에 의해 적어도 어느 하나의 가상현실 컨 텐츠 정보를 상기 메타버스 클라우드 서버로 전달하는 기능을 수행하는 컨텐츠관리 서버; 및 상기 컨텐츠관리 서버로부터 수신된 가상현실 컨텐츠 정보 및 상기 디지털휴먼 정보를 결합하여 디지털휴먼 컨텐츠를 생성하는 기능을 수행하는 메타버스 클라우드 서버;를 포함하는, 디지털휴먼 컨텐츠 생성 시스템이 제공된다."}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 가상 모델 구성, 디지털휴먼 정보 생성 및 가상현실 컨텐츠와 디지털휴먼 정보 결합을 통한 디지털휴먼 컨텐츠의 생성이 하나의 시스템에서 이뤄지도록 함으로써, 필요 자원을 최소화하는 가상현실 기반의 디지털휴먼 컨텐츠 생성이 가능하도록 하는 효과가 있다. 특히 본 발명은 가상 모델을 구성하기 위한 텍스쳐링 및/또는 리깅 등의 후처리 공정이 인공지능에 의해 자동으 로 수행되도록 함으로써, 신속하고 효율적인 가상 모델 구성이 이뤄질 수 있다는 장점이 있다. 또한 본 발명은 시그니처 모션을 통해 디지털휴먼 컨텐츠 구성 및 관리가 용이하게 이뤄질 수 있다는 장점이 있 다."}
{"patent_id": "10-2022-0099310", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명의 실시예를 첨부된 도면을 참조하여 상세히 설명한다. 그러나 본 발명을 설명함에 있어 공 지의 구성을 구체적으로 설명함으로 인하여 본 발명의 기술적 사상을 흐리게 하거나 불명료하게 하는 경우에는 위 공지의 구성에 관하여는 그 설명을 생략하기로 한다. 본 발명에 따른 '사용자 모델'은 가상 모델을 구성하는 기초가 되는 사용자 이미지 정보, 디지털휴먼 정보에 포 함된 모션 정보 및/또는 음성 정보를 수집하는 대상이 되는 현실의 모델로서, 상기 사용자 이미지 정보, 모션정보 및 음성 정보는 하나의 사용자 모델이 2 이상의 정보를 제공할 수도 있고, 서로 다른 사용자 모델이 각각 의 정보를 제공할 수도 있다. 예를들어, 하나의 사용자 모델이 가상 모델을 구성하는 기초가 되는 사용자 이미 지 정보를 제공하고, 다른 사용자 모델이 모션 정보 및 음성 정보를 제공하도록 구성될 수 있다. 이하, 디지털휴먼 컨텐츠 생성 시스템 및 이를 이용한 디지털휴먼 컨텐츠 생성 방법에 대해 도면을 기준으로 상세히 설명한다. 도 1은 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 생성 시스템의 구성도, 도 2는 본 발명의 다른 실시예에 따른 디지털휴먼 컨텐츠 생성 시스템의 구성도, 도 5는 본 발명의 일실시예에 따른 디지털휴먼 서버의 구성도, 도 6은 본 발명의 일실시예에 따른 가상 모델 생성 스튜디오의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타내는 모식도, 도 7은 본 발명의 일실시예에 따른 모션 정보 수집 스튜디오의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타내는 모식도, 도 9는 본 발명의 다른 실시예에 따른 가상 모델 생성 스튜디오의 구성을 나 타내는 모식도이다. 본 발명의 일례에 따른 디지털휴먼 컨텐츠 생성 시스템은, 도 1에 도시된 바와 같이, 디지털휴먼 서버, 컨텐츠관리 서버 및 이와 네트워크 연결된 메타버스 클라우드 서버를 포함한다. 상기 디지털휴먼 서버는, 미리 설정된 가상 모델 구성방법에 기초하여 가상 모델을 구성한다. 상기 디지털 휴먼 서버는 미리 수집된 모션 정보를 상기 가상 모델과 매칭하여 디지털휴먼 정보를 생성하고, 상기 디지 털휴먼 정보를 상기 메타버스 클라우드 서버로 전달하는 기능을 수행한다. 본 발명의 일례에 따른 디지털휴먼 서버는, 도 5에 도시된 바와 같이, 후술하는 가상 모델 생성 스튜디오 에서 수집된 사용자 이미지 정보, 모션 정보 수집 스튜디오에서 수집된 모션 정보는 물론 가상 모델 구성 및 디지털휴먼 생성 과정에서 일시적으로 발생된 데이터(정보)를 저장하도록 하는 메모리부, 통신모 듈을 포함하여 구성되는 통신부, 가상 모델의 구성 및 관리가 이뤄지도록 하는 가상 모델 구성/관리부 , 디지털휴먼 정보의 생성 및 관리가 이뤄지도록 하는 디지털휴먼 정보 생성/관리부 및 서버의 전반 적인 운영이 이뤄지도록 하는 운영부를 포함한다. 상기 컨텐츠관리 서버는, 복수의 가상현실 컨텐츠 정보, 다양한 사용자 모델 정보 및 디지털휴먼 정보를 관리하는 등 컨텐츠 전반의 관리를 담당하는 서버이며, 상기 메타버스 클라우드 서버의 요청에 의해 적어 도 어느 하나의 가상현실 컨텐츠 정보를 상기 메타버스 클라우드 서버로 전달하는 기능을 수행한다. 상기 컨텐츠관리 서버는, 서버 운영의 전반적인 기능을 담당하는 운영모듈, 사용자 모델 관리모듈, 디지털 휴먼 정보 관리모듈, 가상현실 컨텐츠 정보 관리모듈 및 통신모듈을 구비할 수 있다. 일례로, 상기 컨텐츠관리 서버는, 상기 메타버스 클라우드 서버와 후술하는 스트리밍 서버(500, 도 5 참고)를 중계하여 메타버스 클라우드 서버로부터 디지털휴먼 컨텐츠를 스트리밍 서버로 전달하도록 구성될 수도 있으며, 이 경우 상기 디지털휴먼 컨텐츠를 관리하는 디지털휴먼 컨텐츠 관리모듈(미도시)을 더 구 비할 수 있다. 상기 복수의 가상현실 컨텐츠 정보는 상기 컨텐츠관리 서버에 구비된 저장매체(미도시)에 미리 저장될 수 도 있으나, 바람직하게 상기 컨텐츠관리 서버와 네트워크 연결된 별도의 가상현실 컨텐츠 정보 DB(미도 시)에 저장될 수 있으며, 스트리밍 가능한 영상컨텐츠 형태로 구성되어 후술하는 스트리밍 서버로부터 전 달 받을 수도 있다. 일례로, 상기 가상현실 컨텐츠 정보는 교육컨텐츠 및 공연컨텐츠를 포함 다양한 분야에서 가상현실을 직접, 간접적으로 체험할 수 있는 영상컨텐츠에 관한 것으로, 다양한 컨텐츠 서버에서 생성 및 저장 될 수 있다. 상기 메타버스 클라우드 서버는, 상기 컨텐츠관리 서버로부터 수신된 가상현실 컨텐츠 정보 및 상기 디지털휴먼 정보를 결합하여 디지털휴먼 컨텐츠를 생성하는 기능을 수행한다. 일례로, 상기 메타버스 클라우드 서버는, 서버 운영의 전반적인 기능을 담당하는 운영모듈, 디지털휴먼 컨 텐츠 DB, 디지털휴먼 컨텐츠 관리모듈, 이벤트 정보 관리모듈 및 통신모듈을 구비할 수 있다. 상기 이벤트 정보 관리모듈은 디지털휴먼 컨텐츠 관리모듈에 통합될 수 있으며, 상기 디지털휴먼 컨텐츠 DB에는 미리 설정된 이벤트 정보가 함께 저장될 수 있다. 본 발명의 다른 실시예에 따른 디지털휴먼 컨텐츠 생성 시스템은, 상기 디지털휴먼 서버, 컨텐츠관리 서버 및 메타버스 클라우드 서버 외에도 상기 메타버스 클라우드 서버에서 생성된 디지털휴먼 컨텐츠를 표시할 수 있도록 하는 표시장치를 더 구비할 수 있으며, 가상 모델을 구성하기 위해 사용자 모 델의 사용자 이미지를 수집할 수 있도록 하는 가상 모델 생성 스튜디오 및/또는 사용자 모델의 모션 정보 를 수집할 수 있도록 하는 모션 정보 수집 스튜디오를 더 구비할 수 있다. 상기 네트워크는 5G 기반의 네트워크로 구성될 수 있으며, 기존의 저속 네트워크망에 비해 5G 기반의 네트워크 로 구성되는 경우, 상기 가상현실 컨텐츠 정보는 물론 디지털휴먼 정보의 데이터를 효율적으로 전달하는 과정에 서 데이터 손실이나 시간 지연이 발생할 가능성이 높으므로, 보다 빠르고 대용량의 데이터 전송이 이뤄질 수 있 도록 한다는 점에서 5G 기반의 네트워크로 구성되는 것이 바람직하다. 도 3은 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 생성 방법의 순서도, 도 4는 본 발명의 다른 실시예에 따 른 디지털휴먼 컨텐츠 생성 방법의 순서도, 도 8은 본 발명의 일실시예에 따른 가상 모델을 구성하는 단계를 설 명하는 순서도, 도 10은 본 발명의 다른 실시예에 따른 가상 모델을 구성하는 단계를 설명하는 모식도이다. 본 발명의 바람직한 실시예에 따른 디지털휴먼 컨텐츠 생성 방법은, 디지털휴먼 서버, 컨텐츠관리 서버 및 이와 네트워크 연결된 메타버스 클라우드 서버를 포함하는, 디지털휴먼 컨텐츠 생성 시스템에 서 이뤄진다. 상기 디지털휴먼 컨텐츠 생성 방법은, 도 4에 도시된 바와 같이, 상기 디지털휴먼 서버가, 미리 설정된 가 상 모델 구성방법에 기초하여 가상 모델을 구성하는 단계(a), 상기 디지털휴먼 서버가, 미리 수집된 모션 정보를 상기 가상 모델과 매칭하여 디지털휴먼 정보를 생성하는 단계(b), 상기 디지털휴먼 서버가, 상기 디지털휴먼 정보를 상기 메타버스 클라우드 서버로 전달하는 단계(c) 및 상기 메타버스 클라우드 서버 가 상기 컨텐츠관리 서버로부터 수신된 가상현실 컨텐츠 정보 및 상기 디지털휴먼 정보를 결합하여 디지털휴먼 컨텐츠를 생성하는 단계(d)를 포함하여 이뤄진다. 상기 b 단계의 모션 정보의 수집은 a 단계와 동시 에 또는 a 단계보다 먼저 이뤄질 수도 있다. 다른 예로, 상기 디지털휴먼 컨텐츠 생성 방법은, 도 5에 도시된 바와 같이, 상기 메타버스 클라우드 서버(30 0)가, 디지털휴먼 컨텐츠를 스트리밍 서버에 전달하는 단계(e)를 더 포함할 수 있다. 상기 스트리밍 서버는 상기 메타버스 클라우드 서버와 네트워크 연결되며, 일례로, 상기 디지털휴먼 컨텐츠를 메타버스 클라우드 서버로부터 전달받아 실시간 스트리밍 형태로 사용자 단말 등에 제공할 수 있 다. 다양한 사용자들은 사용자 단말을 통해 상기 스트리밍 서버에서 제공되는 해당 디지털휴먼 컨텐츠를 시청할 수 있게 된다. 또한, 상기 스트리밍 서버는 상기 디지털휴먼 컨텐츠의 실시간 스트리밍 서비스 이외에도, 다양한 형태의 영상컨텐츠를 보유할 수도 있으며, 상기 컨텐츠관리 서버에 영상컨텐츠를 제공할 수 있다. 일례로, 상기 디지털휴먼 컨텐츠는 메타버스 클라우드 서버에서 네트워크를 통해 직접 스트리밍 서버(50 0)로 전달될 수도 있고, 다른 예로, 전술한 컨텐츠관리 서버가 상기 메타버스 클라우드 서버와 스트 리밍 서버를 중계하도록 구성될 수도 있다. 상기 메타버스 클라우드 서버가 디지털휴먼 컨텐츠를 네 트워크를 통하여 컨텐츠관리 서버를 거쳐 스트리밍 서버로 전달하는 구성은, 메타버스 클라우드 서버 의 부하를 감소시키고 컨텐츠관리 서버에서 일원화된 컨텐츠관리가 이뤄지도록 함으로써 효율적이고 정확한 컨텐츠관리가 이뤄질 수 있다. 상기 사용자 단말은 전술한 표시장치 및/또는 표시장치를 포함한 컴퓨터 등으로 이해될 수 있으며, 디지털휴먼 컨텐츠를 시청하는 사용자의 스마트폰, 태블릿, PC 모니터, HMD(Head mount display) 등 가상현실 컨텐츠를 시청할 수 있는 다양한 형태의 장치일 수 있다. 상기 사용자 단말은 이동 가능하도록 구성함으로써 언 제 어디서나 다양한 디지털휴먼 컨텐츠를 활용할 수 있도록 하는 것이 바람직하며, 이를 위해 무선으로 네트워 크를 구성하는 것이 바람직하다. 상기 e 단계에서는, 후술하는 미리 설정된 이벤트 정보가 함께 표시될 수 있으며, 사용자는 상기 이벤트 정보를 통해 가상현실 컨텐츠와 디지털휴먼 정보가 포함된 디지털휴먼 컨텐츠를 더욱 실감있게 시청할 수 있다. 도 8에 도시된 바와 같이, 상기 a 단계의 미리 설정된 가상 모델 구성방법은, 상기 디지털휴먼 서버와 네 트워크 연결된 가상 모델 생성 스튜디오에 구비된 전신 캡쳐 장치를 통해 사용자 모델을 촬영하여 사용자 이미지 정보를 수집하는 단계(a1), 상기 사용자 이미지 정보에 기초하여 가상 모델 기초 모델링 정보를 생성하 는 단계(a2) 및 상기 생성된 가상 모델 기초 모델링 정보를 후처리하여 가상 모델을 구성하는 단계(a3)를 포함 하여 이뤄질 수 있다. 상기 가상 모델 생성 스튜디오는, 도 6에 도시된 바와 같이, 전신 캡쳐 장치를 포함하며, 상기 전신 캡쳐 장치는 적어도 복수개의 카메라와 조명(126, 126')을 구비하며, 상기 복수개의 카메라 및 조명(126, 126')을 제어하고 사용자 이미지 정보를 획득하여 네트워크를 통해 상기 디지털휴먼 서버로 전 달하는 기능을 수행하는, 통신모듈이 구비된 제어부를 포함하여 이뤄진다. 예를 들어, 상기 전신 캡쳐 장치는, 16 내지 64개의 볼류메트릭 카메라(volumetric camera) 또는 32 내지 128개의 포토그래메트릭 카메라(photogrammetric camera)가 사용자 모델이 내부에 수용될 수 있는 철제 프레임 (도면 부호 미도시)의 외부에 고르게 구비되어 사용자 모델의 360도 전신을 촬영할 수 있도록 구성될 수 있다. 예를 들어, 상기 볼류메트릭 카메라는 RGB-D 카메라, 키넥트 센서가 결합된 RGB 카메라 등 깊이값을 생성할 수 있는 카메라일 수 있다. 상기 조명(126, 126')은 사용자 모델에 그림자가 발생하지 않도록 다수개 구비될 수 있으며, 불필요한 그림자로 인해 사용자 이미지의 품질이 저하되는 것을 방지하면서 사용자 모델의 텍스쳐가 잘 드러날 수 있도록 배치 및 설정하는 것이 바람직하다. 상기 조명(126, 126')은 후술하는 텍스쳐링 및 리깅 자동화를 위해 다양한 위치에 구비되거나 2 이상의 파장을 조사할 수 있도록 구성될 수도 있다. 상기 사용자 이미지 정보에 기초하여 가상 모델 기초 모델링 정보를 생성하는 단계(a2)는, 사용자 모델(UM)의 360도 전신에 대한 사용자 이미지를 수집하고, 각각의 이미지를 인공지능을 이용하여 결합시키면서 자동화된 모 델링 과정을 거쳐 가상 모델 기초 모델링 정보를 생성하는 것이다. 일례로, 상기 가상 모델 기초 모델링 정보는 사용자 모델(UM)의 입체감 없는 360도 외형으로 이해될 수 있다. 다른 예로, 상기 가상 모델 기초 모델링 정보는 상기 전신 캡쳐 장치에 볼류메트릭 카메라를 이용하는 경 우 사용자 모델의 사용자 이미지로부터 깊이값을 측정하여 저품질의 텍스쳐링 및/또는 리깅이 이뤄짐으로써 색 상 및 질감이나 관절 및 뼈대가 간단히 부여된 상태의 360도 외형일 수도 있다. 상기 가상 모델 기초 모델링 정보는 텍스쳐링(texturing) 및 리깅(rigging) 등의 후처리를 거쳐 입체감 있는 3 차원의 가상 모델을 구성할 수 있다. 일례로, 상기 a3 단계는, 상기 가상 모델 기초 모델링 정보에 색상 및 질감을 부여하여 입체감이 생기도록 하는 텍스쳐링 단계(a31) 및 상기 가상 모델 기초 모델링 정보에 관절 및 뼈대를 부여함으로써 후술하는 모션 정보와 결합하여 가상 모델의 움직임이 가능하도록 하는 리깅 단계(a32)를 포함할 수 있다. 이 때, 상기 a31 단계(텍스 쳐링 단계) 및 a32 단계(리깅 단계) 중 적어도 어느 하나는 인공지능 처리 모듈에 의해 자동으로 이뤄질 수 있 다. 예를 들어, 도 10에 도시된 바와 같이, 사용자 모델(UM)의 사용자 이미지를 수집하고, 상기 사용자 이미지에 기 초하여 가상 모델 기초 모델링 정보(AM1)를 생성할 수 있으며, 텍스쳐링된 가상 모델 기초 모델링 정보(AM2) 및 리깅을 통한 입체화가 이뤄진 가상 모델(AM)을 순차적으로 구성할 수 있다. 미설명된 도면부호 RGM은 상기 텍스 쳐링된 가상 모델 기초 모델링 정보(AM2)에 관절 및 뼈대를 부여하기 위한 리깅 기초 모델이다. 종래 상기 텍스쳐링 단계 및 리깅 단계는 디자이너 또는 그래픽 엔지니어가 가상 모델을 구성(생성)하기 위해 수작업을 통해 후처리하도록 함으로써 디지털휴먼 컨텐츠 생성에 많은 시간과 인력이 소비된다는 문제가 있었으 며, 볼류메트릭 카메라를 이용하는 경우에도 텍스쳐링 및 리깅의 품질이 좋지 않아 추가적인 작업을 필요로 하 였다. 그러나 본 발명에 따른 후처리 공정은 상기 텍스쳐링 단계(a31) 및/또는 리깅 단계(a32)를 자동으로 이뤄질 수 있도록 함으로써 효율적으로 디지털휴먼 컨텐츠를 생성할 수 있다. 일례로, 상기 a31 단계는, 상기 전신 캡쳐 장치에 구비된 적어도 하나 이상의 서로 다른 위치 또는 서로 다른 파장을 갖는 복수개의 조명에 의해 촬영된 적어도 2 이상의 사용자 이미지 정보에 기초하여 자동으로 처리될 수 있다. 도 9에 도시된 바와 같이, 우선 사용자 모델(UM)의 그림자가 발생하지 않도록 조명을 제어하면서 사용자 이미지를 획득(도 9 (a) 참고)한 다음, 특정 위치의 조명을 더 켜거나 끈 상태 또는 조명의 파장을 조절하여 일부 조명(126')이 다른 파장을 갖도록 함으로써 기존 수집된 사용자 이미지에서 변경된 사용자 이미지를 획득(도 9 (b) 참고)하고, 최초의 사용자 이미지와 변경된 사용자 이미지의 차이점 분석을 인공지능 처리 모듈로 수행함 으로써 텍스쳐링이 더욱 부각되고 가상 모델 기초 모델링 정보에 텍스쳐링이 자동으로 처리될 수 있게 된다. 도 11은 본 발명의 일실시예에 따른 사용자 모델의 포즈 이미지를 설명하는 모식도이다. 일례로, 상기 사용자 이미지 정보는, 상기 사용자 모델의 복수개의 미리 설정된 포즈 이미지 정보(PI1, PI2, PI3)를 포함하며, 상기 a32 단계는, 상기 사용자 모델의 포즈 이미지 정보(PI1, PI2, PI3)에 기초하여 자동으로 처리될 수 있다. 예를 들어, 본 발명의 일례에 따른 디지털휴먼 컨텐츠 생성 시스템은 상기 가상 모델 생성 스튜디오에 서 사용자 모델이 미리 설정된 포즈를 취하도록 하면서, 각각의 미리 설정된 포즈에 기초한 사용자 이미지를 추 가적으로 수집하도록 할 수 있다. 이 경우 상기 미리 설정된 포즈를 취하기 전의 사용자 이미지 정보(PI0)와 상기 사용자 모델의 포즈 이미지 정 보(PI1, PI2, PI3)를 비교함으로써 리깅 작업을 위한 사용자 모델의 관절과 뼈대의 형태를 용이하게 파악할 수 있다. 이러한 미리 설정된 포즈를 취하기 전의 사용자 이미지 정보(PI0)와 사용자 모델의 포즈 이미지 정보(PI1, PI2, PI3)를 비교한 데이터 즉, 차이점 분석 정보는 지속적으로 디지털휴먼 서버에 저장될 수 있다. 다양한 크기 및 형상을 갖는 사용자 모델의 미리 설정된 포즈를 통한 차이점 분석 정보가 누적되면서 가상 모델 기초 모델링 정 보에 대한 리깅작업의 고도화(정밀한 리깅 작업)가 이뤄질 수 있다. 특히 각각의 사용자 이미지 정보(PI0)와 상 기 사용자 모델의 미리 설정된 포즈 이미지 정보(PI1, PI2, PI3)의 비교 분석을 인공지능 처리 모듈로 수행함으 로써 가상 모델 기초 모델링 정보에 리깅이 자동으로 처리될 수 있게 된다. 상기 텍스쳐링 단계(a31) 및 리깅 단계(a32)는 동시 또는 순차로 이뤄질 수 있으며, a32 단계가 a31 단계 이전에 이뤄질 수도 있다. 일례로, 상기 미리 수집된 모션 정보는, 상기 디지털휴먼 서버와 네트워크 연결된 모션 정보 수집 스튜디 오에 구비된 모션 캡쳐 장치를 통해 수집된 사용자 모델의 움직임 정보(표정 및/또는 움직임)이며, 얼굴의 움직임을 나타내는 페이스모션 정보와, 바디 및 손의 움직임을 나타내는 바디모션 정보 중 적어도 어느 하나를 포함할 수 있다. 상기 페이스모션 정보는, 사용자 모델의 시선이나 표정 등을 통해 사용자 모델의 감정이나 심리 상태 등이 전달 될 수 있도록 하는 것이며, 바디모션 정보는 사용자 모델의 움직임이 전달될 수 있도록 하는 것이다. 상기 모션 정보 수집 스튜디오는, 도 7에 도시된 바와 같이, 모션 캡쳐 장치(142, 142', 144', 146', 148')를 포함하며, 상기 모션 캡쳐 장치(142, 142', 144', 146', 148')를 제어하고 사용자 모델(UM)의 얼굴 (UF)의 움직임을 나타내는 페이스모션 정보와 사용자 모델(UM)의 손/바디(UB)의 움직임을 나타내는 바디모션 정 보 중 적어도 어느 하나를 획득하여 네트워크를 통해 상기 디지털휴먼 서버로 전달하는 기능을 수행하는, 통신모듈이 구비된 제어부를 포함하여 이뤄진다. 일례로, 상기 모션 캡쳐 장치는 카메라 형태로 이뤄져서 사용자 모델(UM)의 신체 전체를 촬영하면서 얼굴 (UF)의 움직임과 바디(UB)의 움직임을 각각 구분하여 인식, 저장할 수 있도록 구성될 수 있다. 다른 예로, 상기 모션 캡쳐 장치는, 사용자 모델의 얼굴(UF)의 움직임 및/또는 후술하는 사용자 모델의 음성 정 보를 수집하는 페이스모션 캡쳐(감지) 장치(142')나, 사용자 모델의 바디(UB)에 다수개 부착하여 사용자 모델의 바디(UB)의 움직임 정보를 수집하는 센서(144'), 장갑(146'), 스마트 워치(148') 형태의 바디모션 캡쳐(감지) 장치(144', 146', 148')로 나누어 구성될 수도 있다. 상기 카메라 또는 페이스모션 캡쳐 장치(142')는, 사용자 모델의 얼굴의 시선처리, 표정 등을 촬영하고 시 선이나 표졍의 변화에 따른 특징점을 확인할 수 있도록 하며, 상기 디지털휴먼 서버는 이러한 특징점의 변 화를 통해 사용자 모델의 페이스모션 정보를 수집할 수 있다. 예를 들어, 상기 카메라에 의해 사용자 모델의 동작 이전과 이후를 비교하여 사용자 모델의 신체 움직임을 감지함으로써 사용자 모델의 바디모션 정보를 수집할 수 있다.다른 예로, 상기 모션 정보 수집 스튜디오에 구비된 제어부와 유/무선 연결된 바디모션 캡쳐 장치 (144')를 이용하는 경우, 상기 바디모션 캡쳐 장치(144')는 위치센서, 기울기 센서 등의 다양한 형태의 센서일 수 있으며, 사용자 모델의 신체에 부착되어 사용자 모델의 동작에 따라 위치가 변경되는 경우 변경된 상태 정보 를 제어부에 전달함으로써 사용자 모델의 움직임에 따른 사용자 모델 바디모션 정보를 수집할 수 있게 된 다. 상기 제어부는 통신모듈을 통해 상기 카메라, 페이스모션 감지장치(142') 및/또는 바디모션 감지장치 (144', 146', 148')에 의해 수집된 사용자 모델의 페이스모션 정보 및/또는 사용자 모델의 바디모션 정보를 상 기 디지털휴먼 서버로 전달한다. 도 12는 본 발명의 일실시예에 따른 사용자 모델의 시그니처 모션 정보를 설명하는 모식도이다. 본 발명의 상기 디지털휴먼 정보는 복수의 가상 모델에 대해 적어도 하나 이상의 모션 정보를 결합하여 복수개 로 구성될 수 있다. 일례로, 도 12에 도시된 바와 같이, 상기 복수개의 디지털휴먼 정보는, 상기 미리 수집된 모션 정보에서 상기 페이스모션 정보 및 바디모션 정보 중 적어도 어느 하나가 다른 디지털휴먼 정보와 구별 가능하도록 하는 하나 이상의 시그니처 모션 정보(SM1, SM2, SM3)를 각각 포함할 수 있다. 일례로, 상기 시그니처 모션 정보(SM1, SM2, SM3)는 사용자 모델에 따라 미리 설정될 수 있다. 예를 들어, 각각 의 사용자 모델에 따라 사용자 모델 스스로 또는 협의에 의해 시그니처 모션을 설정하고 이를 사용자 모델 고유 의 시그니처 모션으로 결정할 수 있으며, 해당 모션을 적어도 한 번 이상 수행하여 모션 정보를 해당 디지털휴 먼 정보와 결합되도록 할 수 있다. 다른 예로, 상기 시그니처 모션 정보(SM1, SM2, SM3)는 사용자 모델의 움직임에 의해 수집되는 다양한 모션 정 보를 다른 사용자 모델의 움직임에 의해 수집되는 모션 정보와 비교/분석하여 다른 사용자 모델의 움직임에 의 해 수집되는 모션 정보와 차이점을 갖는 모션 정보를 해당 사용자 모델의 시그니처 모션으로 자동으로 결정할 수도 있다. 상기 시그니처 모션 정보(SM1, SM2, SM3)는 다수의 디지털휴먼 정보를 다른 디지털휴먼 정보와 구별할 수 있도 록 하는 것으로, 디지털휴먼 정보의 관리 및 후술하는 이벤트 정보의 설정 및 관리를 효율적으로 이뤄지도록 한 다. 일례로, 상기 디지털휴먼 컨텐츠는 미리 설정된 이벤트 정보(미도시)를 더 포함할 수 있다. 상기 미리 설정된 이벤트 정보는, 가상현실 컨텐츠 생성시 미리 설정된 특정 상황에서 이벤트 정보가 표시되도록 생성될 수 있으 며, 일례로, 상기 시그니처 모션 정보에 기초하여 표시되도록 구성될 수 있다. 상기 이벤트 정보는 디지털휴먼 컨텐츠가 표시장치에 표시될 때, 특정 행동이나 상황에서 가상현실 컨텐츠 정보에 추가적으로 표시되는 것으로, 디지털휴먼의 모션에 따라 다양한 형태(모양, 색상 등)로 표시될 수 있다. 상기 이벤트 정보는 독립적으로 또는 상기 디지털휴먼 컨텐츠에 포함된 상태에서 상기 메타버스 클라우드 서버 에 저장될 수 있다. 특히 상기 이벤트 정보는 해당 디지털휴먼이 다른 디지털휴먼과 구별될 수 있도록 하는 상기 시그니처 모션 정 보(SM1, SM2, SM3)에 기초하여 생성될 수 있도록 함으로써, 디지털휴먼별로 독특한 이벤트 정보가 표시되므로 디지털휴먼 컨텐츠를 더욱 다각화되도록 하는 장점이 있다. 예를 들어, 상기 이벤트 정보는 표시장치에 표시되는 디지털휴먼 정보가 시그니처 모션 정보(SM1, SM2, SM3)를 포함할 때마다, 즉 사용자 모델이 해당 시그니처 모션을 동작할 때마다 디지털휴먼 컨텐츠에 포함되어 표시되도록 할 수 있으며, 다른 디지털휴먼 정보가 자신의 시그니처 모션 정보(SM1, SM2, SM3)를 동시에 포함하 여 표시되는 경우 각각의 이벤트 정보가 더욱 극대화되어 표시되도록 구성될 수도 있다. 일례로, 상기 디지털휴먼 정보는, 상기 모션 정보 수집 스튜디오에서 수집된 사용자 모델의 음성 정보를 더 포함하여 구성될 수 있다. 상기 사용자 모델의 음성 정보는 2 이상의 디지털휴먼 정보의 관리 및/또는 디지털휴먼 컨텐츠가 더욱 다양한 형태로 이뤄질 수 있도록 한다. 예를 들어, 상기 사용자 모델의 음성 정보는 사용자 모델의 음색이나 톤 또는 말투 정보를 포함할 수 있으며, 상기 페이스모션 정보와 바디모션 정보 이외에도 음색이나 톤 또는 말투를 시그니처 모션 정보로 구성할 수도 있다. 이 경우 또 다른 사용자 모델의 음성 정보를 상기 디지털휴먼 정보와 결합 시 해당 시그니처 모션 정보인 음색 이나 톤 또는 말투가 포함되는 경우 전술한 이벤트 정보가 포함되도록 구성될 수도 있다. 본 발명의 일 실시예에 따른 디지털휴먼 컨텐츠 생성 방법은 다양한 컴퓨터에서 실행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터로 판독 가능한 기록매체에 기록된다. 상기 기록매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있으며, 일 례로, 하드 디스크나 플로피 디스크 등의 자기 기록매체, CD나 DVD 등의 광기록 매체, 플롭티컬 디스크 등의 자 기광 매체, 롬, 램, 플래쉬 메모리 등일 수 있다. 상기 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되거나 구성될 수 있으며, 공지되어 사용 가능한 것일 수 있다. 일례로, 상기 프로그램 명령은 기계어 코드 또는 고급 언어 코드를 포함할 수 있다. 이상에서 본 발명은 구체적인 실시예를 참조하여 상세히 설명하였으나, 상기 실시예는 본 발명을 이해하기 쉽도 록 하기 위한 예시에 불과한 것이므로, 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 치환, 부가 및 변 형된 실시 형태들 역시 하기의 청구범위에 의하여 정해지는 본 발명의 보호범위에 속한다고 할 것이다."}
{"patent_id": "10-2022-0099310", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 생성 시스템의 구성도, 도 2는 본 발명의 다른 실시예에 따른 디지털휴먼 컨텐츠 생성 시스템의 구성도, 도 3은 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 생성 방법의 순서도, 도 4는 본 발명의 다른 실시예에 따른 디지털휴먼 컨텐츠 생성 방법의 순서도, 도 5는 본 발명의 일실시예에 따른 디지털휴먼 서버의 구성도, 도 6은 본 발명의 일실시예에 따른 가상 모델 생성 스튜디오의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타내는 모식도, 도 7은 본 발명의 일실시예에 따른 모션 정보 수집 스튜디오의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타내는 모식도, 도 8은 본 발명의 일실시예에 따른 가상 모델을 구성하는 단계를 설명하는 순서도, 도 9는 본 발명의 다른 실시예에 따른 가상 모델 생성 스튜디오의 구성을 나타내는 모식도, 도 10은 본 발명의 다른 실시예에 따른 가상 모델을 구성하는 단계를 설명하는 모식도, 도 11은 본 발명의 일실시예에 따른 사용자 모델의 포즈 이미지를 설명하는 모식도, 도 12는 본 발명의 일실시예에 따른 사용자 모델의 시그니처 모션 정보를 설명하는 모식도이다."}
