{"patent_id": "10-2022-0075230", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0174375", "출원번호": "10-2022-0075230", "발명의 명칭": "TOF", "출원인": "(주)에리", "발명자": "김현석"}}
{"patent_id": "10-2022-0075230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "TOF(Time Of Flight) 센서를 이용하여 관찰영역에 대한 이미지와 깊이 데이터를 구하는 (a)단계;상기 이미지 데이터를 기초로 제 1 인공 신경망을 이용하여 제 1 객체 감지 데이터를 획득하는 (b)단계;상기 깊이 데이터를 기초로 제 2 인공 신경망을 이용하여 제 2 객체 감지 데이터를 획득하는 (c)단계;상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 바탕으로 앙상블 결합을 수행하는 (d)단계를 포함하는 객체 탐지 방법."}
{"patent_id": "10-2022-0075230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제 1 인공 신경망 및 상기 제 2 인공 신경망 중 적어도 하나는,DNN(Deep Neural Network), CNN(Convolution Neural Network), R-CNN(Regions with CNN), fast R-CNN, fasterR-CNN, YOLO(You Only Look Once) 또는 SSD(Single Shot Multi-box Detector)를 포함하는 객체 탐지 방법."}
{"patent_id": "10-2022-0075230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 (d)단계는,제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 평균하는 단계를 포함하는 객체 탐지 방법."}
{"patent_id": "10-2022-0075230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "소정의 관찰영역으로 광을 조사하는 송광부와, 반사광을 수신하는 수광부를 구비하여, 상기 수광부에서 수광한광량을 바탕으로 상기 관찰영역에 대한 이미지 데이터를 획득하고, 상기 송광부로부터 출사된 광이 상기 수광부에 수신될 때까지의 광의 비행 시간(TOF: Time Of Flight)를 바탕으로 상기 관찰영역에 대한 깊이 데이터를 구하는 TOF 센서; 및상기 이미지 데이터를 기초로 제 1 인공 신경망을 이용하여 제 1 객체 감지 데이터를 획득하고, 상기 깊이 데이터를 기초로 제 2 인공 신경망을 이용하여 제 2 객체 감지 데이터를 획득하고, 상기 제 1 객체 감지 데이터와상기 제 2 객체 감지 데이터를 바탕으로 앙상블 결합을 수행하는 객체 인식기를 포함하는 객체 탐지 장치."}
{"patent_id": "10-2022-0075230", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 앙상블 결합은,상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 평균한 것인 객체 탐지 장치."}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 객체 탐지 방법은, TOF(Time Of Flight) 센서를 이용하여 관찰영역에 대한 이미지와 깊이 데이터를 구 하는 (a)단계와, 상기 이미지 데이터를 기초로 제 1 인공 신경망을 이용하여 제 1 객체 감지 데이터를 획득하는 (b)단계와, 상기 깊이 데이터를 기초로 제 2 인공 신경망을 이용하여 제 2 객체 감지 데이터를 획득하는 (c)단계 와, 상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 바탕으로 앙상블 결합을 수행하는 (d)단계를 포함한다."}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, TOF와 앙상블 신경망을 이용하여 객체를 탐지하는 방법과 이를 수행하는 객체 탐지 장치에 관한 것 이다."}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능을 이용한 객체를 인식하는 방법들이 공지되어 있다. 종래에는 관찰 영역으로부터 구해진 이미지를 기 초로 인공 신경망을 이용하여 객체 인식을 하였으나, 이러한 방식은 주변 상황, 특히, 광량이나 조도 또는 반사 등의 요인으로 인해 정확한 탐지가 어려운 경우가 있다. 최근에는 객체 인식에 대한 정확도를 향상하기 위해 앙상블 학습(Ensemble Learning)이 이용되고 있다. 앙상블 학습은, 여러 개의 분류기를 생성하고, 그 예측을 결합함으로써 보다 정확한 예측을 도출하는 기법으로써, 강력 한 하나의 모델을 사용하는 대신 보다 약한 모델 여러 개를 조합하여 더 정확한 예측을 가능케한다. 그런데, 종래의 앙상블 학습을 기반의 객체 인식에서는 분류기는 여러 개이나 입력되는 데이터 셋(data set)은 동일하기 때문에, 데이터 셋이 광량이나 반사 등의 주변 상황의 영향으로 부정확한 경우 여전히 정확도가 떨어 지는 문제가 있다."}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 광량이나 반사 등의 주변 상황에 의한 영향에도 불구하고 정확한 객체 인식 을 가능하게 하는 객체 탐지 방법 및 이를 실행하는 객체 탐지 장치를 제공하는 것이다."}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명이 객체 탐지 방법은, TOF(Time Of Flight) 센서를 이용하여 관찰영역에 대한 이미지와 깊이 데이터를 구하는 (a)단계와, 상기 이미지 데이터를 기초로 제 1 인공 신경망을 이용하여 제 1 객체 감지 데이터를 획득하 는 (b)단계와, 상기 깊이 데이터를 기초로 제 2 인공 신경망을 이용하여 제 2 객체 감지 데이터를 획득하는 (c)단계와, 상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 바탕으로 앙상블 결합을 수행하는 (d)단계를 포함한다. 상기 제 1 인공 신경망 및 상기 제 2 인공 신경망 중 적어도 하나는, DNN(Deep Neural Network), CNN(Convolution Neural Network), R-CNN(Regions with CNN), fast R-CNN, faster R-CNN, YOLO(You Only Look Once) 또는 SSD(Single Shot Multi-box Detector)를 포함할 수 있다. 상기 (d)단계는, 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 평균하는 단계를 포함할 수 있다. 본 발명의 객체 탐지 장치는, 소정의 관찰영역으로 광을 조사하는 송광부와, 반사광을 수신하는 수광부를 구비 하여, 상기 수광부에서 수광한 광량을 바탕으로 상기 관찰영역에 대한 이미지 데이터를 획득하고, 상기 송광부 로부터 출사된 광이 상기 수광부에 수신될 때까지의 광의 비행 시간(TOF: Time Of Flight)를 바탕으로 상기 관 찰영역에 대한 깊이 데이터를 구하는 TOF 센서와, 상기 이미지 데이터를 기초로 제 1 인공 신경망을 이용하여 제 1 객체 감지 데이터를 획득하고, 상기 깊이 데이터를 기초로 제 2 인공 신경망을 이용하여 제 2 객체 감지 데이터를 획득하고, 상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 바탕으로 앙상블 결합을 수행 하는 객체 인식기를 포함한다. 상기 앙상블 결합은, 상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 평균한 것일 수 있다."}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 객체 탐지 방법 및 객체 탐지 장치는, 객체 인식에 필요한 관찰영역의 이미지를 획득하는 과정에서 광량, 조도, 휘도, 밝기, 반사 등의 주변 광의 영향이 미치더라도, 이러한 영향을 받지 않는 깊이 데이터를 추 가적으로 사용하여 앙상블 학습 기반의 신경망을 통해 객체 인식을 수행함으로써 보다 정확한 객체 인식이 가능 한 효과가 있다."}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2022-0075230", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 도 1은 본 발명의 일 실시예에 따른 객체 탐지 방법을 보인 개략도이다. 도 2는 본 발명의 일 실시예에 따른 객 체 탐지 방법에서 앙상블 신경망의 구조를 도시한 것이다. 도 3은 본 발명의 일 실시예에 따른 객체 탐지 방법을 보인 순서도이다. 도 4는 본 발명의 일 실시예에 따른 객체 탐지 장치의 구성도이다. 도 1 및 도 4를 참조하면, 본 발명의 일 실시예에 따른 객체 탐지 방법은, TOF 센서에 의해 획득한 관찰영 역에 대한 이미지 데이터(10a) 및 깊이 데이터(10b)를 기초로 앙상블 신경망을 이용하여 객체 인식 결과 를 구하는 것을 특징으로 한다. 객체 인식 결과는 관찰영역 내의 사람들을 계수하는 피플 카운팅(people counting)일 수 있다. 다만, 후술 하는 분류 객체 인식기를 학습(training)시키는 방법에 따라 관찰영역 내의 장애물 감지(예를 들어, 횡단 보도나 계단)나, 인체의 동작(gesture) 등을 객체 인식 결과로 얻는 것도 가능하다. 도 2를 참조하면, 앙상블 학습(ensemble learning)은 여러 개의 분류기를 생성하고 그 예측을 결합하여 성능을 개선하는 학습 방법이다. 앙상블 학습에서는 여러 종류의 분류기 또는 학습 모델이 투표(voting)을 통해 최종 예측 결과를 결정할 수 있다.(Final Inference) 이하, 앙상블 학습을 구현한 인공 신경망을 앙상블 신경망이라고 정의하며, 본 실시예에서는, 제 1 인공 신 경망과 제 2 인공 신경망을 포함한다. 여기서, 제 1 인공 신경망은 이미지 데이터를 이용하여 학습된 신경망일 수 있고, 제 2 인공 신경망은 깊이 데이터를 이용하여 학습된 신경망일 수 있다. 제 1 인공 신경망 및 제 2 인공 신경망 중 적어도 하나는, DNN(Deep Neural Network), CNN(Convolution Neural Network), R-CNN(Regions with CNN), fast R- CNN, faster R-CNN, YOLO(You Only Look Once) 또는 SSD(Single Shot Multi-box Detector)를 포함할 수 있다. 예를 들어, 제 1 인공 신경망과 제 2 인공 신경망은 각각 Google Inc.에서 발표한 모바일넷 (Mobilenet)을 포함할 수 있다. 제 1 인공 신경망과 제 2 인공 신경망은 같은 구조의 모델(예를 들어, Mobilenet)로 이루어지나 학습에 사용된 데이터가 서로 다른 종류일 수 있다. 다만 이에 한하지 않고, 제 1 인공 신경망과 제 2 인공 신경망 은 서로 다른 구조 또는 종류의 신경망으로 이루어져 서로 다른 종류의 데이터에 의해 학습된 것일 수도 있 다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 객체 탐지 방법은, TOF 센서를 이용하여 관찰영역에 대한 이미지와 깊이 데이터를 구하는 단계(S1)와, 상기 이미지 데이터를 기초로 제 1 인공 신경망을 이용하여 제 1 객체 감지 데이터를 획득하는 단계(S2)와, 상기 깊이 데이터를 기초로 제 2 인공 신경망을 이용하여 제 2 객체 감지 데이터를 획득하는 단계(S3)와, 상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 바탕으 로 앙상블 결합을 수행하는 단계(S4)를 포함할 수 있다. 한편, TOF(Time of Flight)는 신호(근적외선, 초음파, 레이저 등)를 이용하여 어떤 사물의 거리를 측정하는 기 술이며, TOF 센서는 이러한 기술을 이용하여 관찰영역에 대한 데이터를 구하는 센서이다. TOF 센서는 소정의 관찰영역으로 광을 조사하는 송광부(미도시)와, 상기 송광부와 소정 거리 이격된 위치 에서 반사광을 수신하는 수광부(미도시)를 포함할 수 있다. TOF 센서는 상기 수광부에서 수광한 광량을 바 탕으로 상기 관찰영역에 대한 이미지 데이터 셋을 획득할 수 있다. 이미지 데이터 셋을 구성하는 각 이미지 데이터는 광이 조사된 복수의 포인트들에서의 광량, 밝기, 조도, 휘도 또는 인텐서티(intensity)를 포함할 수 있다. 또한, TOF 센서는 상기 송광부로부터 출사된 광이 상기 수광부에 수신될 때까지의 광의 비행 시간(TOF: Time Of Flight)를 바탕으로 상기 관찰영역에 대한 깊이 데이터 셋을 구할 수 있다.깊이 데이터 셋을 구성하는 각 깊이 데이터는 광이 조사된 복수의 포인트들까지의 깊이 또는 거리를 포함할 수 있다. 한편, 본 발명의 일 실시예에 따른 객체 탐지 장치는 TOF 센서와 객체 인식기를 포함할 수 있으 며, S2 단계 내지 S4단계는 객체 인식기에 의해 이루어질 수 있다. 객체 인식기는 앙상블 신경망을 기반으로 객체 인식을 수행할 수 있다. 객체 인식기는 인공 신경 망(21, 22)에서 입력 레이어(input layer)에 입력된 데이터들(data set)을 바탕으로 분류(classification)를 수행하는 분류 모듈과, 분류된 이미지들에서 객체를 인식(localization)하는 객체 인식 모듈을 포함 할 수 있다. 객체 인식기에 의해 분류와 객체 인식은 각각의 인공 신경망(21, 22)에서 실시될 수 있다. 특히, 객체 인식기는 딥러닝 계열의 제 1 인공 신경망의 입력 계층(input layer)으로 이미지 데이터셋 이 입력되면, 출력 계층(out layer)에서 제 1 객체 감지 데이터들을 구할 수 있다. 또한, 객체 인식기는 딥러닝 계열의 제 2 인공 신경망의 입력 계층(input layer)으로 깊이 데이터셋이 입력되면, 출력 계층(out layer)에서 제 2 객체 감지 데이터들을 구할 수 있다. 여기서, 딥러닝 계열의 인공 신경망은, 데이터가 입력되는 입력 레이어와, 결과를 출력하는 출력 레이어와, 입 력 레이어와 출력 레이어 사이에서 데이터를 처리하는 히든 레이어(hidden layer)를 포함하여 구성되며, 합성곱 인공 신경망(Convolution Neural Network), 순환신경망(Recurrent NeuralNetwork), 심층신경망(Deep Neural Network) 등이 있을 수 있음은 이미 잘 알려져 있으므로 구체적인 설명은 생략한다. S2 단계와 S3 단계에서 각각 구한 제 1 객체 감지 데이터와 제 2 객체 감지 데이터는, 실질적으로는 같은 객체 에 대해서 이미지와 깊이라는 다른 종류의 데이터를 기반으로 구한 결과이다. S4단계는, 상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 앙상블 결합하여 최종적으로 객체에 대 한 데이터(객체 인식 데이터)를 결정하는 단계이다. 상기 앙상블 결합은 제 1 인공 신경망의 출력과 제 2 인공 신경망의 출력을 바탕으로 투표(voting)을 하는 것 또는 신경망의 앙상블 결합으로 정의될 수 있으며, 이러한 과정은, 객체 인식기의 객체 인식 모듈에 의해 수행될 수 있다. 실시예에서 앙상블 결합은 상기 제 1 객체 감지 데이터와 상기 제 2 객체 감지 데이터를 산술 평균한 것이나, 반드시 이에 한정될 필요는 없다. 한편, 객체 인식 모듈은 상기 앙상블 결합에 의해 구해진 결과로부터 최종적으로 객체 인식 데이터를 구하 며, 이러한 과정이 최종 추론(Final Inference)에 해당한다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2022-0075230", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 객체 탐지 방법을 보인 개략도이다. 도 2는 본 발명의 일 실시예에 따른 객체 탐지 방법에서 앙상블 신경망의 구조를 도시한 것이다. 도 3은 본 발명의 일 실시예에 따른 객체 탐지 방법을 보인 순서도이다. 도 4는 본 발명의 일 실시예에 따른 객체 탐지 장치의 구성도이다."}
