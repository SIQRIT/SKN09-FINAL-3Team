{"patent_id": "10-2022-0147608", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0035290", "출원번호": "10-2022-0147608", "발명의 명칭": "실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법, 장치 및 컴퓨터 프로그램", "출원인": "숙명여자대학교산학협력단", "발명자": "동서연"}}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라, 디스플레이부, 프로세서가 구비된 심박 측정 장치를 이용한 심박 측정 방법에 있어서,사용자 정보를 획득하는 과정;상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정;상기 프로세서에 의해 상기 모바일 얼굴 영상 중 제1 소정 개수의 이미지 프레임들을 추출하는 과정;상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG신호를 예측하는 과정; 및상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정은, 상기 카메라에 의해 실시간으로 촬영되는 사용자의 얼굴 영상과 얼굴 가이드 영역이 일치하는 경우 제1 소정 시간 간격으로 상기 사용자를 촬영하여 복수의 모바일 얼굴 영상을 획득하는 과정을 포함하는,실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG신호를 예측하는 과정은,상기 복수의 모바일 얼굴 영상 각각에 예측기 모델을 적용하여 복수의 예측된 rPPG 신호를 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정은, 상기 복수의 예측된 rPPG 신호에 기초해 사용자의 심박 값을 계산하고, 제2 소정 개수의 심박 값을 평균한 평균심박 값을 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 예측기 모델은 상기 사용자 정보에 기초해 다른 학습 데이터로 학습된 예측기 모델로 구성되거나,상기 심박은 상기 사용자 정보의 가중치가 적용된 심박 값인 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법.공개특허 10-2024-0035290-3-청구항 6 제1항에 있어서,상기 예측기 모델은, 대상자의 얼굴 영상 및 상기 얼굴 영상을 촬영하면서 동시에 측정된 상기 대상자의 실제심박 신호를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 예측기 모델의 손실함수는 상기 대상자의 얼굴 영상으로 추청되는 심박 신호와 실제 심박 신호의 차이가최소화되는 방향으로 학습되는 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "카메라, 디스플레이부, 프로세서가 구비된 심박 측정 장치에 있어서,상기 프로세서는, 사용자 정보를 획득하는 과정;상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정;상기 프로세서에 의해 상기 모바일 얼굴 영상 중 제1 소정 개수의 이미지 프레임들을 추출하는 과정;상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG신호를 예측하는 과정; 및상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정을 수행하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정은, 상기 카메라에 의해 실시간으로 촬영되는 사용자의 얼굴 영상과 얼굴 가이드 영역이 일치하는 경우 제1 소정 시간 간격으로 상기 사용자를 촬영하여 복수의 모바일 얼굴 영상을 획득하는 과정을 포함하는,실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG신호를 예측하는 과정은,상기 복수의 모바일 얼굴 영상 각각에 예측기 모델을 적용하여 복수의 예측된 rPPG 신호를 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정은, 공개특허 10-2024-0035290-4-상기 복수의 예측된 rPPG 신호에 기초해 사용자의 심박 값을 계산하고, 제2 소정 개수의 심박 값을 평균한 평균심박 값을 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 예측기 모델은 상기 사용자 정보에 기초해 다른 학습 데이터로 학습된 예측기 모델로 구성되거나,상기 심박은 상기 사용자 정보의 가중치가 적용된 심박 값인 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 예측기 모델은, 대상자의 얼굴 영상 및 상기 얼굴 영상을 촬영하면서 동시에 측정된 상기 대상자의 실제심박 신호를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 예측기 모델의 손실함수는 상기 대상자의 얼굴 영상으로 추청되는 심박 신호와 실제 심박 신호의 차이가최소화되는 방향으로 학습되는 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치."}
{"patent_id": "10-2022-0147608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨팅 장치와 결합되어,사용자 정보를 획득하는 과정;카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정;프로세서에 의해 상기 모바일 얼굴 영상 중 제1 소정 개수의 이미지 프레임들을 추출하는 과정;상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG신호를 예측하는 과정; 및상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정을 실행시키기 위하여 컴퓨터로 판독가능한 기록매체에 저장된,실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 컴퓨터 프로그램."}
{"patent_id": "10-2022-0147608", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는, 카메라, 디스플레이부, 프로세서가 구비된 심박 측정 장치를 이용한 심박 측정 방법에 있어서, 사용자 정보를 획득하는 과정; 상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획 득하는 과정; 상기 프로세서에 의해 상기 모바일 얼굴 영상 중 제1 소정 개수의 이미지 프레임들을 추출하는 과 정; 상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG 신호를 예측하는 과정; 및 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하 는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0147608", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법에 관한 것으로, 상세히는 모 바일 단말기에서 실시간으로 촬영한 모바일 얼굴 영상을 이용해 모바일 단말기 자체적으로 rPPG 신호를 추출하 는 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0147608", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비침습적인 방식으로 PPG 센서로 생체신호를 센싱하여 인간의 질병에 대한 사항을 파악하는 연구는 존재한다. 그러나 현재 COVID-19의 대유행으로 인해 비침습적인 방식이면서 원격으로 건강을 모니터링할 수 있는 기술이상당히 중요해졌다. 각국은 의료 환경에서 COVID-19의 위험을 줄이기 위해 가능하면 원격 건강 전략을 사용할 것을 권고하고 있다. 그렇기 때문에 기존의 신체에 접촉이 필요한 센서를 통한 생체 정보 모니터링 방법이 아닌 새로운 방법이 요구 된다. 원격 건강 모니터링 기술은 휴대전화나 온라인 건강 포털과 같은 통신 시스템에 기반을 두고 있다. 이러한 원격 건강 모니터링 기술은 COVID-19와 같은 유행병이 끝난 후에도 지속적인 환자 모니터링에 매우 인접하게 요구될 수 있다. 종래의 rPPG(remote Photoplethysmography) 추정 방법은 RGB 비디오를 수집하여 얼굴 관심 영역(ROI)을 분리하 고 신호처리 접근 방식을 사용하여 얼굴의 미묘한 색상 변화를 분석한다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2096617호 (2020.03.27.)"}
{"patent_id": "10-2022-0147608", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는, 심박 측정을 위한 추가 센서 없이 스마트폰과 같이 모바일 단말기에 구비된 카메라를 이용해 촬영된 사용자의 모바일 얼굴 영상으로 사용자의 심박을 측정할 수 있는 실시간 딥러닝 기반 모바일 얼 굴 영상을 이용한 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 신생아나 운전 혹은 운동 상황과 같이 비접촉으로 심박을 측정할 수 있는 실시간 딥러 닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 스마트폰과 같이 모바일 장치 내부에 탑재된 AI 모델을 기반으로 실시간으로 사용자의 심박을 측정할 수 있는 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공할 수 있 다. 본 발명의 일 실시예는, 모바일 얼굴 영상에서 관심 영역(ROI)를 분리하지 않고, 바로, AI 모델을 기반으로 사 용자의 심박을 측정하는 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 외부 서버에 대한 연결이 없이 자체 프로세서를 이용하기 때문에 네트워크 지연 혹은 외부 서버의 연산 지연 없이 실시간으로 사용자의 심박을 측정할 수 있는 실시간 딥러닝 기반 모바일 얼굴 영상 을 이용한 심박 측정 장치 및 방법을 제공할 수 있다. 본 발명의 일 실시예는, 원격 광용적맥파(remote Photoplethysmography, rPPG)에 기반해 사용자의 심박을 측정 할 수 있는 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0147608", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예는, 카메라, 디스플레이부, 프로세서가 구비된 심박 측정 장치를 이용한 심박 측정 방법에 있어서, 사용자 정보를 획득하는 과정; 상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획 득하는 과정; 상기 프로세서에 의해 상기 모바일 얼굴 영상 중 제1 소정 개수의 이미지 프레임들을 추출하는 과 정; 상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG 신호를 예측하는 과정; 및 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하 는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정은, 상기 카메라에 의해 실시간으로 촬영되는 사용자의 얼굴 영상과 얼굴 가이드 영역이 일치하는 경우 제1 소정 시 간 간격으로 상기 사용자를 촬영하여 복수의 모바일 얼굴 영상을 획득하는 과정을 포함하는, 실시간 딥러닝 기 반 모바일 얼굴 영상을 이용한 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예 측기 모델에 기반한 rPPG 신호를 예측하는 과정은, 상기 복수의 모바일 얼굴 영상 각각에 예측기 모델을 적용하 여 복수의 예측된 rPPG 신호를 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정 은, 상기 복수의 예측된 rPPG 신호에 기초해 사용자의 심박 값을 계산하고, 제2 소정 개수의 심박 값을 평균한 평균 심박 값을 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 예측기 모델은 상기 사용자 정보에 기초해 다른 학습 데이터로 학습된 예측기 모 델로 구성되거나, 상기 심박은 상기 사용자 정보의 가중치가 적용된 심박 값인 것을 특징으로 하는, 실시간 딥 러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 예측기 모델은, 대상자의 얼굴 영상 및 상기 얼굴 영상을 촬영하면서 동시에 측정 된 상기 대상자의 실제 심박 신호를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 상기 예측기 모델의 손실함수는 상기 대상자의 얼굴 영상으로 추청되는 심박 신호와 실 제 심박 신호의 차이가 최소화되는 방향으로 학습되는 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영 상을 이용한 심박 측정 방법을 제공할 수 있다. 본 발명의 일 실시예는, 카메라, 디스플레이부, 프로세서가 구비된 심박 측정 장치에 있어서, 상기 프로세서는, 사용자 정보를 획득하는 과정; 상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정; 상기 프로세서에 의해 상기 모바일 얼굴 영상 중 제1 소정 개수의 이미지 프레임들을 추출하는 과정; 상 기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG 신호를 예측하는 과정; 및 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과 정을 수행하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 카메라에 의해 촬영된 사용자의 모바일 얼굴 영상을 실시간으로 획득하는 과정은, 상기 카메라에 의해 실시간으로 촬영되는 사용자의 얼굴 영상과 얼굴 가이드 영역이 일치하는 경우 제1 소정 시 간 간격으로 상기 사용자를 촬영하여 복수의 모바일 얼굴 영상을 획득하는 과정을 포함하는, 실시간 딥러닝 기 반 모바일 얼굴 영상을 이용한 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예 측기 모델에 기반한 rPPG 신호를 예측하는 과정은, 상기 복수의 모바일 얼굴 영상 각각에 예측기 모델을 적용하 여 복수의 예측된 rPPG 신호를 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정 은, 상기 복수의 예측된 rPPG 신호에 기초해 사용자의 심박 값을 계산하고, 제2 소정 개수의 심박 값을 평균한 평균 심박 값을 획득하는 과정을 포함하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 예측기 모델은 상기 사용자 정보에 기초해 다른 학습 데이터로 학습된 예측기 모 델로 구성되거나, 상기 심박은 상기 사용자 정보의 가중치가 적용된 심박 값인 것을 특징으로 하는, 실시간 딥 러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 예측기 모델은, 대상자의 얼굴 영상 및 상기 얼굴 영상을 촬영하면서 동시에 측정 된 상기 대상자의 실제 심박 신호를 학습 데이터로 학습된 인공지능 모델인 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 상기 예측기 모델의 손실함수는 상기 대상자의 얼굴 영상으로 추청되는 심박 신호와 실 제 심박 신호의 차이가 최소화되는 방향으로 학습되는 것을 특징으로 하는, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치를 제공할 수 있다. 본 발명의 일 실시예는, 컴퓨팅 장치와 결합되어, 사용자 정보를 획득하는 과정; 카메라에 의해 촬영된 사용자 의 모바일 얼굴 영상을 실시간으로 획득하는 과정; 프로세서에 의해 상기 모바일 얼굴 영상 중 제1 소정 개수의 이미지 프레임들을 추출하는 과정; 상기 제1 소정 개수의 이미지 프레임들을 이용해 3차원 컨볼루션 신경망으로 구성된 예측기 모델에 기반한 rPPG 신호를 예측하는 과정; 및 상기 프로세서에 의해 상기 예측된 rPPG 신호에 기초해 사용자의 심박을 획득하는 과정을 실행시키기 위하여 컴퓨터로 판독가능한 기록매체에 저장된, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 컴퓨터 프로그램을 제공할 수 있다."}
{"patent_id": "10-2022-0147608", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예는, 심박 측정을 위한 추가 센서 없이 스마트폰과 같이 모바일 단말기에 구비된 카메라를 이용해 촬영된 사용자의 모바일 얼굴 영상으로 사용자의 심박을 측정할 수 있는 실시간 딥러닝 기반 모바일 얼 굴 영상을 이용한 심박 측정 장치 및 방법을 제공하는 효과를 가진다. 본 발명의 일 실시예는, 신생아나 운전 혹은 운동 상황과 같이 비접촉으로 심박을 측정할 수 있는 실시간 딥러 닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공하는 효과를 가진다. 본 발명의 일 실시예는, 스마트폰과 같이 모바일 장치 내부에 탑재된 AI 모델을 기반으로 실시간으로 사용자의 심박을 측정할 수 있는 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공하는 효 과를 가진다. 본 발명의 일 실시예는, 모바일 얼굴 영상에서 관심 영역(ROI)를 분리하지 않고, 바로, AI 모델을 기반으로 사 용자의 심박을 측정하는 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공하는 효 과를 가진다. 본 발명의 일 실시예는, 외부 서버에 대한 연결이 없이 자체 프로세서를 이용하기 때문에 네트워크 지연 혹은 외부 서버의 연산 지연 없이 실시간으로 사용자의 심박을 측정할 수 있는 실시간 딥러닝 기반 모바일 얼굴 영상 을 이용한 심박 측정 장치 및 방법을 제공하는 효과를 가진다. 본 발명의 일 실시예는, 원격 광용적맥파(remote Photoplethysmography, rPPG)에 기반해 사용자의 심박을 측정 할 수 있는 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 제공하는 효과를 가진다."}
{"patent_id": "10-2022-0147608", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명은 단지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예 들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에서 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시 예들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변 경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 벗어나지 않은 채, 제1구성 요소는 제2구성 요소로 명명될 수 있고 유사하게 제2구성 요소는 제1구성 요소로도 명명될 수 있다. 어떤 구성 요소가 다른 구성 요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성 요소 에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성 요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성 요소가 다른 구성 요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는 중간에 다른 구성 요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성 요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등 도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하 려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세 서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 본 명세서에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 명세서에 서 특별히 다른 의미로 정의되지 않는 한, 본 명세서에 개시된 기술이 속하는 분야에서 통상의 지식을 가진 자 에 의해 일반적으로 이해되는 것과 동일한 의미를 나타낸다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에 서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않아야 한다. 본 명세서에서 사용되는 구성요소에 대한 접미사 \"모듈(module)\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니며, 본 발명의 실시 예에 따른 방법을 수행하기 위한 하드웨어 또는 상기 하드웨어를 구동할 수 있는 소프트웨어의 기능적 또는 구 조적 결합을 의미할 수 있다. 이하에서 첨부된 도면을 참조하여, 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 및 방법을 설명한다. 도 1은 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치의 하드웨어 구성도이다. 도 1을 참조하여, 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치 (이하 '컴퓨팅 장치'라 함)를 설명한다. 컴퓨팅 장치는 사용자에 물리적으로 접촉하는 센서가 없이도 사용자의 모바일 얼굴 영상을 이용해 사용자 의 심박을 측정할 수 있다. 이는 비전 컴퓨팅 기반으로 원격 심박 측정 기술 혹은 원격 광혈류측정 기술이라 한 다.원격 광혈류측정(Remote photoplethysmography, rPPG)은 심장 주기로 인해 변화되는 혈류량으로부터 포착되는 피부색의 미묘한 변화를 포착해 심박 신호를 추출하는 기술이다. 심박은 단위시간 당 심장 박동 횟수로 교감 신경계와 부교감 신경계로 구성된 자율 신경계의 영향을 받아 사람 의 신체적, 정신적 상태를 반영한다. 일반적으로 심장의 전기적 활동을 기록하는 심전도(ECG; electrocardiogram) 또는 광학센서를 이용하는 광혈류 측정기(PPG; photoplethysmogram)를 사용하여 이러한 심박을 모니터링할 수 있다. 그러나 이러한 방법들은 일반 적으로 센서를 피부 표면에 부착하여 신호를 얻으므로 대상과의 물리적 접촉이 필수적이거나 움직임이 제약된다 는 한계점을 가지고 있다. 이러한 문제를 해결하기 위해, 본 발명의 일 실시예에 따른 컴퓨팅 장치는 실시간으로 딥러닝 기반하여 모 바일 얼굴 영상을 이용한 사용자의 rPPG 신호 및 심박을 측정하는 방법을 제안한다. 도 1을 참조하면, 본 발명의 일 실시예에 컴퓨팅 장치는 하나 이상의 프로세서, 프로세서에 의 하여 수행되는 컴퓨터 프로그램을 로드(Load)하는 메모리, 통신 인터페이스 및 컴퓨터 프로그램 을 저장하는 스토리지를 포함할 수 있다. 다양한 실시예에서, 컴퓨팅 장치는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이 해될 수 있다. 컴퓨팅 장치는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애 플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 본 명세서에서 설명되는 각 과정들은 컴퓨팅 장치에 의하여 수행될 수 있다. 또한, 각 과정의 주체는 하나 의 컴퓨팅 장치에 의해 수행되는 것으로 제한되는 것은 아니며, 실시예에 따라 각 과정들의 적어도 일부가 서로 다른 컴퓨팅 장치에서 수행될 수도 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프 로그램에 대한 연산을 수행할 수 있으며, 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 또한, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저 장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 프로세서는 본 발명의 다양한 실시예에 따른 방법/과정들을 수행할 수 있다. 일 예로, 프로세서는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법 및 이 방법을 이루는 적어도 하나의 과정들의 조합을 수행할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예에 따른 방 법/동작을 실행하기 위하여 스토리지로부터 컴퓨터 프로그램을 로드할 수 있다. 메모리에 컴퓨 터 프로그램이 로드되면, 프로세서는 컴퓨터 프로그램을 구성하는 하나 이상의 인스트럭션들을 실행함으로써 상기 방법/동작을 수행할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있을 것 이나, 본 개시의 기술적 범위가 이에 한정되는 것은 아니다. 버스(BUS)는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공한다. 버스(BUS)는 주소 버스(address Bus), 데 이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인 터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 예를 들어, 통신 인터페이스는, 근거리 통신, 이동 통신, 방송 통신 방식 중 적어도 하나를 지원할 수 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예에서, 통신 인터페이스는 생략될 수도 있다. 통신 인터페이스는 심박 측정기와 유선 혹은 무선 통신으로 연결될 수 있다. 통신 인터페이스는 심박 측정기와 실시간으로 통신하여 심박 측정기에서 측정한 셀제 심박 신호를 실시간으로 수신할 수 있다. 스토리지는 컴퓨터 프로그램을 비 임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모 리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방 법/과정을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이상 의 인스트럭션들을 실행함으로써, 본 발명의 다양한 실시예에 따른 방법/과정을 수행할 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 과정들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 일 실시예에서, 컴퓨터 프로그램은 컴퓨팅 장치와 결합되어, 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 실행시키기 위하여 컴퓨터로 판독가능한 기록매체에 저장된, 컴퓨터 프로그램일 수 있 다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 나아가, 컴퓨팅 장치는 출력부, A/V입력부, 사용자 입력부 중 적어도 하나를 더 포함할 수 있다. 출력부는 실행되는 프로그램(또는 애플리케이션)에 의해 생성 혹은 실행되는 비디오 신호 및 오디오 신호 중 적어도 하나를 출력할 수 있다. 출력부는 비디오(영상) 신호를 출력하는 디스플레이부 및 오디오 신호를 출력하는 음향 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이부는 컴퓨팅 장치의 전면에 구비될 수 있다. A/V(Audio/Video) 입력부는 외부로부터 컴퓨팅 장치로 컬러(RGB) 비디오 신호의 입력을 위한 카메라 를 포함할 수 있다. 카메라는 컴퓨팅 장치의 전면 혹은 후면에 구비될 수 있다. 카메라는 RGB 이미지를 촬영하는 RGB 카메라일 수 있으며, 촬영모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 RGB 이미지로 이루어진 화상 프레임을 얻을 수 있다. RGB카메라는 사용자를 촬영하여 사용자의 모바일 얼굴 영상을 촬영할 수 있 다. 카메라에서 촬영된 사용자의 모바일 얼굴 영상은 사용자에 대한 복수의 이미지 프레임으로 구성될 수 있으 며, 촬영 시점 정보를 포함할 수 있다. 사용자 입력부는, 사용자가 컴퓨팅 장치를 제어하기 위한 사용자 입력 신호 혹은 데이터를 입력하는 수단을 의미한다. 사용자 입력부는 터치 패드(일 예로, 접촉식 정전 용량 방식, 압력식 저항막 방식, 적외 선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등)와, 키 패드(key pad), 전 원 버튼, 볼륨 버튼 등과 같은 물리 버튼을 포함할 수 있으나, 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 컴퓨팅 장치는 후술할 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법 및 이 방법을 구성하는 적어도 하나의 과정들의 조합을 수행할 수 있다. 심박 측정기는 컴퓨팅 장치와 유선 혹은 무선으로 통신하여 사용자의 심박 정보를 송신할 수 있다. 심박 측정기는 컴퓨팅 장치의 카메라에서 실시간으로 촬영되는 사용자의 모바일 얼굴 영상과 시 간적으로 페어링되는 사용자의 심박을 실시간으로 측정할 수 있다. 심박 측정기에서 컴퓨팅 장치로 송신하는 사용자의 심박 정보는 심박 신호 및 해당 심박 신호를 측정한 시점 정보를 포함할 수 있다. 도 2는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 흐름도를 도시한 것이다. 도 3는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 예시 화면을 도시한 것이다. 도 4는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상 을 이용한 심박 측정 방법의 추론 과정의 흐름도를 도시한 것이다. 도 5은 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 추론 과정의 개념도를 도시한 것이다. 도 6은 본 발 명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 추론 과정의 개념도를 도시한 것이다. 도 2 내지 도 6을 참조하여, 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법을 설명한다. S100 과정에서, 컴퓨팅 장치는 사용자 정보를 획득할 수 있다. 도 3(a)를 참조하면, 컴퓨팅 장치는 디스플레이부를 통해 사용자에게 사용자 정보 질의 화면(SC1)을 제공할 수 있다. 사용자 정보 질의 화면(SC1)은 사용자의 이름, 나이, 성별, 현재 상태 정보 중 적어도 하나를 입력할 수 있는 정보 입력공간을 제공한다. 컴퓨팅 장치는 사용자가 사용자 정보 질의 화면을 통해 입력한 사용자의 이름, 나이 성별, 현상태 정보 중 적어도 하나를 획득하고, 스토리지에 저장할 수 있다. 사용자의 이름은 사용자를 구별하는 주 식별 정보로 사용될 수 있다. 현상태 정보는 휴식 상태(rest state)인지 혹은 활동 상태(active state)인지에 관한 정보를 포함할 수 있다. S200 과정에서, 컴퓨팅 장치는 사용자의 모바일 얼굴 영상을 획득할 수 있다. 사용자의 모바일 얼굴 영상은 컴퓨팅 장치에 구비된 카메라에 의해 촬영된 컬러 비디오 혹은RGB 비디 오와 같이 가시광선 대역의 광을 센싱하는 이미지 센서에 의해 촬영된 복수의 이미지 프레임들의 집합일 수 있 다. 도 3(b)를 참조하면, 컴퓨팅 장치는 디스플레이부를 통해 사용자에게 얼굴 영상 촬영 화면(SC2)을 제 공할 수 있다. 디스플레이부는 컴퓨팅 장치의 전면에 구비되며, 동일한 전면에 카메라가 구비될 수 있다. 얼굴 영상 촬영 화면(SC2)은 카메라를 이용해 촬영되는 실시간 영상이 보여지는 실시간 영상 표시 영역 (SC2-A1)과, 사용자의 얼굴을 정렬시키기 위해 실시간 영상 표시 영역(SC2-A1) 내부에 구비된 얼굴 가이드 영역 (SC2-A2)을 포함할 수 있다. 실시간 영상 표시 영역(SC2-A1)은 디스플레이부 상에 위치하며 카메라를 통해서 촬영되는 실시간 영 상을 출력할 수 있다. 얼굴 가이드 영역(SC2-A2)은 실시간 영상 표시 영역(SC2-A1) 내부에 위치하여 사용자의 얼굴 위치를 조절할 수 있는 가이드 역할을 제공한다. 얼굴 가이드 영역(SC2-A2)은 세로로 긴 타원 혹은 사람의 얼굴 형상으로 구성될 수 있다. 사용자는 카메라를 통해서 실시간으로 촬영되는 자신의 얼굴 영상의 사이즈와 얼굴 가이드 영역 (SC2-A2)의 사이즈가 일치하도록 카메라와 자신의 얼굴 사이 거리를 조절할 수 있다. 얼굴 영상 촬영 화면(SC2)은 사용자의 심박을 예측하는 진행 과정을 보여주는 진행 과정 표시 영역(SC2-A3)을 포함할 수 있다. 다양한 실시예에서, 진행 과정 표시 영역(SC2-A3)은 도 3(b)와 같이 종방향으로 구성되며, 비어 있거나 특정 색 으로 채워진, 복수의 하트 형상들로 표시할 수 있다. 또는, 진행 과정 표시 영역(SC2-A3)은 모래시계 형상, 백 분율로 표시된 숫자의 증감, 종방향으로 비어 있거나 특정 색으로 채워진 바 형상 중 하나로 표시할 수 있다.또는, 진행 과정 표시 영역(SC2-A3)은 사용자의 얼굴 위치를 얼굴 가이드 영역(SC2-A2)에 일치하도록 조절하라 는 취지의 문자/문장/도형을 제공하거나, 사용자 얼굴 영상에 대한 심박을 예측하는 진행 상태 정도를 나타내는 문자/문장/도형을 제공할 수 있다. 다양한 실시예에서, 진행 과정 표시 영역(SC2-A3)은 사용자의 얼굴 영상의 사이즈와 얼굴 가이드 영역(SC2- A2)의 사이즈가 일치하는지 여부에 대한 사이즈 일치 정보 및 사용자의 얼굴 영상을 이용해 심박을 예측하는 진 행 상태 정보를 포함할 수 있다. 예를 들어, 사이즈 일치 정보는 사용자의 얼굴 영상의 사이즈와 얼굴 가이드 영역(SC2-A2)의 사이즈가 일치하지 않는 경우에 빈 하트 형상이 깜빡이거나, 모래시계 형상을 보여주거나, 0% 숫자를 보여주거나, 비어 있는 바 형 상을 보여주거나, \"얼굴 위치를 조절하세요\" 문자를 보여주거나, 얼굴 위치를 조절하는 화살표 형상을 포함할 수 있다. 또한, 진행 상태 정보는 컴퓨팅 장치의 예측기 모델(PM) 혹은 프로세서에 의해 심박 측정 과정의 정도를 복수의 하트 형상들 중 일부 하트가 특정 색이 채워진 하트 형상으로 보여주거나, 진행 정도를 보여주는 백분율 숫자를 보여주거나, 일부분이 특정 색으로 채워진 바 형상으로 보여주거나, \"심박 측정 중\" 문자를 보여주는 형 상으로 보여줄 수 있다. S200 과정에서, 컴퓨팅 장치는 실시간 영상 표시 영역(SC2-A1)에서 보여지는 사용자의 실시간 얼굴 영상과 얼굴 가이드 영역(SC2-A2)이 서로 교차하는 영역이 일치하지 않는 경우에, 사용자의 얼굴 영상의 크기 및 위치 를 조절할 수 있도록 사이즈 일치 정보를 진행 과정 표시 영역(SC2-A3)을 통해 제공할 수 있다. 또한, 컴퓨팅 장치는 사용자의 얼굴 영상과 얼굴 가이드 영역(SC2-A2)이 교차하는 영역이 일치하는 경우에, 사용자 얼굴 영상에 대한 심박을 예측하는 진행 정도의 정보를 진행 과정 표시 영역(SC2-A3)을 통해 제공할 수 있다. S200 과정에서, 컴퓨팅 장치는 사용자의 얼굴 영상과 얼굴 가이드 영역(SC2-A2)이 일치하는지 확인하는 과 정으로, 카메라를 통해 실시간으로 촬영되어 실시간 영상 표시 영역(SC2-A1)에 표시되는 사용자의 얼굴 영상과 얼굴 가이드 영역(SC2-A2)이 교차하는 영역이 소정 면적 이하인 경우 일치하지 않는 것으로 판단하는 과 정, 사용자의 얼굴 영상이 얼굴 가이드 영역(SC2-A2)을 벗어나는 경우 일치하지 않는 것으로 판단하는 과정, 사용자의 얼굴 영상이 얼굴 가이드 영역(SC2-A2)의 내부에 위치하더라도 사용자의 얼굴 영상의 면적이 소정 면적 이하인 경우 일치하지 않는 것으로 판단하는 과정, 사용자의 얼굴 영상의 양쪽 눈, 양쪽 눈썹, 코, 입, 양쪽 귀 중 적어도 2개의 특징점들이 얼굴 가이드 영역(SC2-A2) 내부에 위치하지 않거나 혹은 적어도 2개의 특 징점들 사이의 거리가 소정 거리 보다 작은 경우 일치하지 않는 것으로 판단하는 과정 중 어느 하나 혹은 둘 이 상의 조합으로 수행할 수 있다. 얼굴 영상 촬영 화면(SC2)은 사용자의 심박 정보를 표시하는 심박 표시 영역(SC2-A4)를 포함할 수 있다. 심박 표시 영역(SC2-A4)은 심박을 예측하는 중이라면 \"심박 측정 중\"과 같이 심박 예측 프로세스가 진행 중임을 표시하는 문자를 포함할 수 있다. 또한, 심박 표시 영역(SC2-A4)은 심박 예측이 끝난 경우라면 \"평균 bpm : 8 8\"과 같이 예측된 심박을 표시하는 문자 및 숫자를 포함할 수 있다. 다양한 실시예에서, 컴퓨팅 장치는 사용자의 얼굴 영상과 얼굴 가이드 영역(SC2-A2)이 서로 일치하는 경우 카메라를 통해 사용자의 얼굴 영상의 촬영을 시작함으로써, 사용자의 모바일 얼굴 영상을 획득할 수 있다. 모바일 얼굴 영상은 컴퓨팅 장치의 카메라에 포함된 이미지 센서를 통해 촬영되며, 비디오 파일로 스 토리지에 저장된다. 컴퓨팅 장치는 촬영이 시작된 후에 제1 소정 시간 동안 사용자를 촬영하여 사용자의 모바일 얼굴 영상을 저장할 수 있다. 다시 말해, 컴퓨팅 장치는 촬영 시작 이후에 제1 소정 시간의 길이를 가지는 비디오 파일 을 생성하여 저장할 수 있다. 또는, 컴퓨팅 장치는 제1 소정 시간 간격으로 사용자의 모바일 얼굴을 촬영 한 얼굴 영상을 생성하여 저장할 수 있다. 여기서, 제1 소정 시간은 3초 내지 7초 사이로 설정될 수 있으며, 바 람직하게는 5초로 설정될 수 있다. 컴퓨팅 장치는 제1 소정 시간 간격으로 복수의 모바일 얼굴 영상을 촬영하여 저장함으로써, 복수의 모바일 얼굴 영상을 획득할 수 있다. 여기서, 복수의 모바일 얼굴 영상은 촬영이 시작된 후 0~5초 사이(제1 주기)에서 촬영된 제1 모바일 얼굴 영상, 5~10초 사이(제2 주기)에 촬영된 제2 모바일 얼굴 영상, 10~15초 사이(제3 주 기)에 촬영된 제3 모바일 얼굴 영상, 15~20초 사이(제4 주기)에 촬영된 제4 모바일 얼굴 영상 등을 포함할 수 있다. 다시 말해, 컴퓨팅 장치는 촬영이 시작된 후에 주기 별로 복수의 모바일 얼굴 영상을 촬영하여 저장할 수 있다. S300 과정에서, 컴퓨팅 장치는 예측기 모델(PM)을 이용해 심박 정보를 예측할 수 있다. 컴퓨팅 장치 는 예측기 모델(PM)을 이용해 사용자의 모바일 얼굴 영상에 기초한 심박 정보를 측정할 수 있다. 컴퓨팅 장치는 모바일 얼굴 영상 중 적어도 하나를 이용해 예측기 모델(PM)에 기반하여 사용자의 심박 값 (rPPG 신호)을 예측할 수 있다. 일 예로, 예측기 모델(PM)은 사용자의 나이, 성별, 현 상태에 상관없이 촬영된 얼굴 영상 및 심박 데이터로 학 습된 모델일 수 있다. 이 경우, 컴퓨팅 장치는 사용자 정보에 상관없이 촬영된 사용자의 모바일 얼굴 영상 에 예측기 모델(PM)을 적용하여 사용자의 심박 값(rPPG 신호)을 예측할 수 있다. 이 경우 컴퓨팅 장치는 예측된 사용자의 심박 값(pb)에 사용자 정보에 따른 가중치를 적용하여 가중치 적 용된 심박 값(wb)을 계산할 수 있다. 즉, 컴퓨팅 장치는 사용자의 나이대에 대응한 나이 가중치(aw), 사용 자의 성별에 대응한 성별 가중치(gw), 사용자의 현상태에 대응한 상태 가중치(sw)를 적용하여 심박 값을 계산할 수 있다. 예를 들어, 예측된 심박 값에 나이, 성별, 상태 가중치 각각을 곱한 값들의 평균 값을 가중치가 적용 된 심박 값으로 할 수 있다(wb = pb x (aw+gw+sw)/3). 다양한 실시예에서, 예측기 모델(PM)은 사용자의 나이대에 따라 복수의 예측기 모델(PM)이 있을 수 있다. 예를 들어, 20대 예측기 모델(PM), 30대 예측기 모델(PM), 40대 예측기 모델(PM) 등이 있을 수 있다. 나이대별 예측 기 모델(PM)은 해당 나이대에 대응하는 사용자의 모바일 얼굴 영상과 심박 데이터로 학습된 모델일 수 있다. 다양한 실시예에서, 예측기 모델(PM)은 사용자의 성별에 따른 복수의 예측기 모델(PM)이 있을 수 있다. 예를 들 어, 남성용 예측기 모델(PM), 여성용 예측기 모델(PM)이 있을 수 있다. 성별 예측기 모델(PM)은 해당 성에 대응 하는 사용자의 모바일 얼굴 영상과 심박 데이터로 학습된 모델일 수 있다. 다양한 실시예에서, 예측기 모델(PM)은 사용자의 현 상태에 따른 복수의 예측기 모델(PM)이 있을 수 있다. 예를 들어, 활동용 예측기 모델(PM), 휴식용 예측이 모델이 있을 수 있다. 상태별 예측기 모델(PM)은 해당 상태에 대 응하는 사용자의 모바일 얼굴 영상과 심박 데이터로 학습된 모델일 수 있다. 여기서, 컴퓨팅 장치는 사용자 정보에 기초해 서로 다른 예측기 모델(PM)을 사용할 수 있다. 다시 말해, 컴퓨팅 장치는 사용자 정보에 기초해 나이대별 예측기 모델(PM), 성별 예측기 모델(PM), 상태별 예측기 모 델(PM) 중 하나를 사용하여 사용자의 심박 값(rPPG 신호)를 예측하거나, 모든 모델들을 병렬로 사용하여 출력 값들의 평균 혹은 중간 값을 사용자의 심박 값(rPPG 신호)으로 예측할 수 있다. 컴퓨팅 장치는 적어도 제2 소정 개수의 심박 값의 평균 값을 계산하여 평균 심박 값을 획득할 수 있으며, 이를 사용자에게 제공할 수 있다. 제2 소정 개수는 2회 내지 4회일 수 있으며, 바람직하게는 3회일 수 있다. 이 경우, 평균 심박 값은 연속적으로 예측된 3개의 심박 값을 평균한 값일 수 있다. 예측기 모델(PM)은 사용자의 모바일 얼굴 영상을 입력받아, 심박 정보를 출력할 수 있다. 이에 대한 상세한 내 용은 후술하기로 한다. S400과정에서, 컴퓨팅 장치는 심박 정보를 디스플레이부에 표시할 수 있다. 도 3(c)를 참조하면, 다양한 실시예에서, 컴퓨팅 장치는 디스플레이부를 통해 사용자에게 얼굴 영상 촬영 화면(SC2) 상에서, 심박 표시 영역(SC2-A4)에서 예측된 심박 값을 표시할 수 있다. 예측된 심박 값은 소정 횟수로 연속적으로 예측된 심박 값의 평균값일 수 있다. 도 3(d)를 참조하면, 다양한 실시예에서, 컴퓨팅 장치는 디스플레이부를 통해 예측 심박의 통계 정보 를 제공하는 심박 추적관리 화면(SC3)을 제공할 수 있다. 심박 추적관리 화면(SC3)는 각각 다른 시간대에 측정된 심박의 이력, 일별 하루 평균 심박의 이력, 월별 달 평 균 심박의 이력, 및 이들의 그래프를 표시하여 제공할 수 있다. 도 4, 도 5, 및 도 6을 참조하여, 모바일 얼굴 영상을 이용해 심박 정보를 예측하는 방법을 상세히 설명한다. S310과정에서, 컴퓨팅 장치는 자체적으로 가지는 카메라를 통해 촬영한 모바일 얼굴 영상을 전처리할 수 있다. 컴퓨팅 장치는 스토리지에 저장된 모바일 얼굴 영상을 획득할 수 있다. 여기서, 스토리지에 저 장된 모바일 얼굴 영상은 컴퓨팅 장치에 구비된 카메라로 촬영된 사용자의 모바일 얼굴 영상이다. 컴퓨팅 장치는 사용자의 모바일 얼굴 영상에서 복수의 이미지 프레임들을 추출할 수 있다. 컴퓨팅 장치 는 복수의 이미지 프레임들에서 제1 소정 개수의 이미지 프레임들을 추출할 수 있다. 제1 소정 개수는 90 frames에서 160 frames 사이일 수 있으며, 바람직하게는 90 frames으로 설정될 수 있다. 제 1 소정 개수의 이미지 프레임들로 구성된 모바일 얼굴 영상은 제1 소정 시간으로 촬영된 모바일 얼굴 영상과 동 일할 수 있다. rPPG 신호의 예측에 대한 정확도를 높이기 위해 160frames 보다 많은 이미지 프레임을 사용할 수 있지만, 처리 속도가 늦어지는 문제점이 발생한다. 이를 해결하기 위해, 제1 소정 개수의 이미지 프레임들을 사용하여 연산 처리 속도를 높이면서, 검증 손실을 최소화시킬 수 있다. 제1 소정 개수의 이미지 프레임들은 모바일 얼굴 영상에서 서로 연속적으로 위치한 이미지 프레임들일 수 있다. 본 발명의 일 실시예는, 처리 대상의 사이즈를 최소화함으로써, 얼굴 영상을 서버 혹은 클라우드로 보내 rPPG 신호를 예측하는게 아니라 스마트폰과 같은 모바일 컴퓨팅 장치 자체에서 실시간으로 rPPG 신호를 예측할 수 있다. 이는 서버로 데이터를 전송할 때 발생하는 네트워크의 지원이나 서버에서 데이터 처리 시간을 제거하고, 컴퓨팅 장치의 자체 프로세서를 통해 rPPG 신호를 예측하기 위한 연산을 수행하고 자체 데이터베이스에 심박 정보 를 저장함으로써 실시간 처리가 가능하고 민감한 데이터의 외부 전송 문제를 해결할 수 있다. 컴퓨팅 장치는 복수의 이미지 프레임들을 복수의 비트맵 이미지들로 변환할 수 있다. 이후, 컴퓨팅 장치 는 복수의 비트맵 이미지들을 얼굴 영상 텐서로 변경할 수 있다. 여기서, 얼굴 영상 텐서는 이미지 프레임의 개수(시간), H는 이미지 프레임의 세로 크기, W는 이미지 프레임의 가로 크기, C는 비디오 양식의 채널 개수를 포함하는 4차원 텐서일 수 있다. 또한, 얼굴 영상 텐서는 4차원 텐서에 torch.stack으로torch.jit.script를 사용하여 변형된 5차원 텐서일 수 있 다. S320과정에서, 컴퓨팅 장치는 에측기를 이용해 rPPG신호를 예측할 수 있다. 예측기 모델(PM)은 사용자의 모바일 얼굴 영상을 이용해 rPPG 신호를 예측할 수 있다. 상세히는, 예측기 모델 (PM)은 모바일 얼굴 영상의 복수의 이미지 프레임들을 이용해 rPPG 신호를 예측할 수 있다. 또는, 예측기 모델 (PM)은 사용자의 얼굴 영상 텐서를 이용해 rPPG신호를 예측할 수 있다. 예측기 모델(PM)은 사용자의 모바일 얼굴 영상, 얼굴 영상의 복수의 이미지 프레임들, 사용자의 얼굴 텐서 중 적어도 하나를 입력받아서 사용자의 rPPG 신호를 출력할 수 있다. 도 6을 참조하면, 예측기 모델(PM)은 볼륨 형태의 데이터에서 3차원 시공간 특징을 추출하는 3차원 컨볼루션 신 경망으로 구성될 수 있다. 예측기 모델(PM)은 볼륨 형태를 가지는 복수의 이미지 프레임으로 구성된 얼굴 영상 에서 rPPG 특징을 추출하며, rPPG 특징에 기초해 rPPG 신호를 추출할 수 있다. rPPG 특징은 하나의 이미지 프레임이 아닌 복수의 이미지 프레임이 가지는 특성 정보를 포함할 수 있다. 모바일 얼굴 영상을 구성하는 연속적인 복수의 이미지 프레임들을 이용하기 때문에, 모바일 얼굴 영상의 시간적 정보를 rPPG 특징은 포함한다. rPPG 신호는 얼굴 영상에서 시계열적 비디오 시퀀스들을 활용해야 사용자의 정확한 현재 심박을 측정할 수 있다. 3차원 컨볼루션 신경망은 시계열적으로 연속된 복수의 이미지 프레임들을 사용하여 현재 출력 값을 얻으 므로, 얼굴 영상으로부터 정확한 rPPG 신호를 측정하기 적합하다. S330과정에서, 컴퓨팅 장치는 rPPG 신호로 심박 정보를 회득할 수 있다. 컴퓨팅 장치는 rPPG 신호로부터 심박(bpm)을 포함하는 심박 정보를 획득할 수 있다. 컴퓨팅 장치는 rPPG 신호의 피크 값을 검출하고, 피크 값에 기초해 사용자의 심박을 계산할 수 있다. 심박 정보는 실시간으로 계산된 사용자의 실시간 심박, 실시간 심박이 계산된 시점 정보를 포함할 수 있다. 심 박 정보는 실시간 심박, 과거 시점에 계산된 사용자의 과거 심박을 포함할 수 있다. 도 7는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 학습 과 정의 흐름도를 도시한 것이다. 도 8는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이 용한 심박 측정 방법의 학습 과정의 개념도를 도시한 것이다. 도 9은 본 발명의 일 실시예에 따른 실시간 딥러 닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 학습 과정에서 손실함수의 학습 과정에 따른 그래프를 도 시한 것이다. 도 7 내지 도 9을 참조하여, 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 학습 과정에서 손실함수의 학습 과정을 설명한다. S500과정에서, 컴퓨팅 장치는 대상자의 얼굴 영상 및 대상자의 심박 데이터를 획득할 수 있다. 대상자의 얼굴 영상은 대상자인 사람 정보, 시나리오 정보, 소스 이름 정보를 포함하는 대상자의 식별 정보를 포함할 수 있으며, 식별 정보는 'P1/V1/Source1'와 같이 표현될 수 있다. 심박 데이터는 대상자의 얼굴 영상을 촬영할 때 실시간으로 측정된 대상자의 실제 심박 신호 및 대상자의 식별 정보를 포함할 수 있다. 실시간으로 측정된 실제 심박 신호는 얼굴 영상의 각 이미지 프레임에 대응하는 BVP(Blood Volume Pulse) 신호들을 포함할 수 있다. S600과정에서, 컴퓨팅 장치는 얼굴 영상 및 심박 데이터를 이용해 학습 데이터를 생성할 수 있다. 또한, 컴퓨팅 장치는 얼굴 영상 및 심박 데이터를 이용해 테스트 데이터를 생성할 수 있다. 컴퓨팅 장치는 얼굴 영상에서 복수의 이미지 프레임들을 추출할 수 있다. 또한, 컴퓨팅 장치는 복수 의 이미지 프레임들 각각에 대응하는 심박 신호를 동기화하여 각 이미지 프레임에 대응하는 심박 신호를 추출할 수 있다. 또한, 컴퓨팅 장치는 심박 신호를 PPG 신호로 변환하여 추출할 수 있다. 컴퓨팅 장치는 복수의 이미지 프레임과 각 이미지 프레임에 해당하는 심박 신호를 학습 데이터 혹은 테스 트 데이터로 생성할 수 있다. 또는, 컴퓨팅 장치는 복수의 이미지 프레임과 각 이미지 프레임에 해당하는 PPG 신호를 학습 데이터 혹은 테스트 데이터로 생성할 수 있다. S700과정에서, 컴퓨팅 장치는 학습 데이터를 이용해 예측기 모델(PM)을 학습시킬 수 있다. 또한, 컴퓨팅 장치는 테스트 데이터를 이용해 학습된 예측기 모델(PM)을 평가할 수 있다. 컴퓨팅 장치는 얼굴 영상 및 심박 신호를 학습 데이터로 예측기 모델(PM)을 학습시킬 수 있다. 예측기 모 델(PM)은 얼굴 영상에 대한 예측 심박 신호와 얼굴 영상에 대한 실제 심박 신호의 차이가 최소화되도록 손실함 수를 학습시킬 수 있다. 또한, 컴퓨팅 장치는 얼굴 영상 및 실제 PPG 신호를 학습 데이터로 예측기 모델(PM)을 학습시킬 수 있다. 예측기 모델(PM)은 얼굴 영상에 대한 예측 rPPG 신호와 얼굴 영상에 대응하는 실제 PPG 신호의 차이가 최소화되 도록 손실함수를 학습시킬 수 있다. 여기서, 손실함수는 얼굴 영상에서 추정되는 심박 신호(혹은 추정 rPPG 신호)와 실제 심박 신호(혹은 실제 PPG 신호)의 차이를 최소화하기 위해 사용된다. 실제 심박 신호는 BVP 신호를 사용할 수 있다. 일 예로, 손실함수(Loss)는 추정 rPPG 신호와 실제 PPG신호가 +1에 가까운 양의 선형 관계를 나타내는 방향으로 학습되어야 하므로, 음의 피어슨 상관 계수로 설정된다. 이를 통해서, 학습 과정 동안 손실이 0에 가까워지도록 학습된다(도 9 참조). 여기 손실함수(Loss)에서, T는 전체 신호 길이(프레임 길이)이며, x는 예측기 모델(PM)가 예측한 추정 rPPG 신 호이며, y는 실제 PPG 신호(혹은 실제 BVP 신호)일 있다. 상술한 학습 과정(S500과정 내지 S700과정)은 추론 과정(S100과정 내지 S400과정)이 수행되는 컴퓨팅 장치(10 0)에서 함께 수행될 수 있으며, 또는 다른 컴퓨팅 장치(미도시)에서 수행될 수 있다. 전자의 학습 과정과 추론 과정이 하나의 컴퓨팅 장치에서 수행되는 경우에, 컴퓨팅 장치는 자체적으 로 가지는 카메라에서 촬영한 사용자의 모바일 얼굴 영상 및 유무선으로 연결된 심박 측정기에서 얼 굴 영상을 촬영하면서 실시간으로 측정된 심박 신호를 학습 데이터로 예측기 모델(PM)을 학습하는 학습 과정을 수행한 후에, 학습된 예측기 모델(PM)을 이용해 실시간으로 촬영되는 사용자의 모바일 얼굴 영상으로부터 사용 자의 rPPG 신호를 예측하고, 심박을 계산하여 사용자에게 제공할 수 있다. 후자의 학습 과정과 추론 과정이 다른 컴퓨팅 장치에서 수행되는 경우에, 컴퓨팅 장치는 다른 컴퓨팅 장치 (미도시)에서 학습된 예측기 모델(PM)을 수신하여 저장한 후에 학습된 예측기 모델(PM)을 이용해 실시간으로 촬 영되는 사용자의 모바일 얼굴 영상으로부터 사용자의 rPPG 신호를 예측하고, 심박을 계산하여 사용자에게 제공 할 수 있다. 본 발명은 도면에 도시된 실시 예를 참조로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2022-0147608", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 장치의 하드웨어 구성도이다. 도 2는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 흐름도를 도시한 것이다. 도 3는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 예시 화 면을 도시한 것이다. 도 4는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 추론 과 정의 흐름도를 도시한 것이다. 도 5은 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 추론 과 정의 개념도를 도시한 것이다. 도 6은 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 추론 과 정의 개념도를 도시한 것이다. 도 7는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 학습 과 정의 흐름도를 도시한 것이다. 도 8는 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 학습 과정의 개념도를 도시한 것이다. 도 9은 본 발명의 일 실시예에 따른 실시간 딥러닝 기반 모바일 얼굴 영상을 이용한 심박 측정 방법의 학습 과 정에서 손실함수의 학습 과정에 따른 그래프를 도시한 것이다."}
