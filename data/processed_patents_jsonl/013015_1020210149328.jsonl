{"patent_id": "10-2021-0149328", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0064107", "출원번호": "10-2021-0149328", "발명의 명칭": "카메라 및 IMU 기반 드론 제어 장치 및 방법", "출원인": "건국대학교 산학협력단", "발명자": "조기춘"}}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 및 IMU 기반 드론 제어 장치에 있어서,사용자의 양 손 중 제1손에 착용 가능하며, 복수의 골무를 포함하는 제1웨어러블 장치; 사용자의 양 손 중 제2손에 착용 가능하며, IMU 센서를 포함하는 제2웨어러블 장치;상기 제1웨어러블 장치를 촬영하고, 상기 복수의 골무의 위치 및 움직임에 관한 정보를 포함하는 제1데이터를생성하는 카메라; 및상기 제1데이터를 수신하고, 상기 제1데이터에 기초하여 상기 제1손의 제1 제스처 정보를 생성하고, 상기 제2손의 움직임에 따라 상기 IMU 센서로부터 생성되며 3축 정보를 포함하는 제2데이터를 수신하고, 상기 제2데이터를기반으로 상기 제2손의 제2제스처 정보를 생성하고, 상기 제1제스처 정보 및 상기 제2제스처 정보 중 적어도 하나에 기초하여, 선택된 드론의 동작 상태를 제어하는 제어부,를 포함하는 드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제어부는,상기 카메라로부터 상기 제1데이터를 수신하고, 상기 제1데이터에 기초하여, 신경망 모델을 통해 상기 제1손의위치를 나타내는 바운딩 박스의 예측 및 제스처 명령의 예측을 수행하고, 예측 결과를 기반으로 상기 제1제스처정보를 생성하는 것인,드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제어부는,상기 IMU 센서로부터 상기 제2데이터를 수신하고, 기 설정된 시간 동안 제2데이터가 유지되는 경우의 헤딩을 기준으로 헤딩을 설정하고, 상기 제2데이터에 기초하여, 상기 제2제스처 정보를 생성하는 것인,드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 드론 제어 장치는,드론을 선택하는 제1입력과 제1인식 모드, 제2인식 모드 및 중립 모드 중 하나의 모드를 선택하는 제2입력을 수신하는 입력 장치,를 더 포함하고,상기 제어부는, 상기 제1입력 및 상기 제2입력에 기초하여 상기 드론의 동작 상태를 제어하는 것인, 드론 제어 장치.공개특허 10-2023-0064107-3-청구항 5 제4항에 있어서,상기 제어부는,상기 제2입력이 상기 중립 모드에 대한 선택 입력을 포함하는 경우, 상기 드론의 제어를 수행하지 않고,상기 제2입력이 상기 제1인식 모드에 대한 선택 입력을 포함하는 경우, 상기 제1제스처 정보에 기초하여 상기드론의 동작 상태를 제어하고,상기 제2입력이 상기 제2인식 모드에 대한 선택 입력을 포함하는 경우, 상기 제2제스처 정보에 기초하여 상기드론의 동작 상태를 제어하는 것인,드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1제스처 정보는,시동 켜기(Arming), 시동 끄기(Disarming), 이륙(Take off), 착륙(Landing), 귀환(Back home) 및 멈춤(Stop)을포함하는 것인,드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제2데이터는,롤, 피치 및 요우를 포함하는 상기 3축 정보 및 스로틀 조작에 따른 스로틀 정보를 포함하는 것인, 드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제2제스처 정보는, 전진, 후진, 왼쪽으로 이동, 오른쪽으로 이동, 왼쪽으로 회전, 오른쪽으로 회전, 상승 및 하강을 포함하는것인,드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 복수의 골무는, 상기 제1손의 손가락 중 적어도 3 개 이상의 손가락에 착용 되고, 각각 다른 색상인 것인,드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서, 상기 신경망 모델은, 상기 바운딩 박스의 예측 및 상기 제스처 명령의 예측을 동시에 수행하고, 상기 예측 결과의 신뢰도가 기 설정된 기준값보다 낮을 경우, 상기 예측에 의한 제스처 명령을 배제하는 것인, 공개특허 10-2023-0064107-4-드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제4항에 있어서, 상기 드론은, 복수의 드론을 포함하고,상기 제1입력은, 상기 복수의 드론 중 적어도 2개 이상의 드론에 대한 선택을 포함하고,상기 제어부는,상기 제1입력에 기초하여, 상기 적어도 2개 이상의 드론의 동작 상태를 동시에 제어하는 것인, 드론 제어 장치."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "카메라 및 IMU 기반 드론 제어 방법에 있어서,사용자의 양 손 중 제1손에 착용 가능하며, 복수의 골무를 포함하는 제1웨어러블 장치를 촬영하는 카메라로부터제1데이터를 수신하고, 상기 제1데이터에 기초하여, 제1제스처 정보를 생성하는 단계;사용자의 양 손 중 제2손에 착용 가능하며, IMU 센서를 포함하는 제2웨어러블 장치로부터 제2데이터를수신하고, 상기 제2데이터에 기초하여, 제2제스처 정보를 생성하는 단계; 및상기 제1제스처 정보 및 상기 제2제스처 정보에 기초하여, 드론의 동작 상태를 제어하는 단계,를 포함하는 드론 제어 방법."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 드론 제어 방법은,드론을 선택하는 제1입력을 수신하는 단계; 및제1인식 모드, 제2인식 모드 및 중립 모드 중 하나의 모드를 선택하는 제2입력을 수신하는 단계,를 더 포함하고,상기 드론의 동작 상태를 제어하는 단계는,상기 제1입력 및 상기 제2입력을 고려하여 상기 드론의 동작 상태를 제어하는 것인,드론 제어 방법."}
{"patent_id": "10-2021-0149328", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 제1제스처 정보를 생성하는 단계는,카메라로부터 상기 제1데이터를 수신하고, 상기 제1데이터에 기초하여, 신경망 모델을 통해 제스처의 위치를 나타내는 바운딩 박스의 예측 및 제스처 명령의 예측을 수행하고, 예측 결과를 기반으로 상기 제1제스처 정보를생성하는 것이고,상기 제2제스처 정보를 생성하는 단계는,IMU 센서로부터 상기 제2 데이터를 수신하고, 기 설정된 시간 동안 상기 제2데이터가 유지되는 경우의 헤딩을기준으로 헤딩을 설정하고, 상기 제2데이터에 기초하여, 상기 제2제스처 정보를 생성하는 것인,공개특허 10-2023-0064107-5- 드론 제어 방법."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본원의 일 실시예에 따른 카메라 및 IMU 기반 드론 제어 장치는, 사용자의 양 손 중 제1손에 착용 가능하며, 복 수의 골무를 포함하는 제1웨어러블 장치, 사용자의 양 손 중 제2손에 착용 가능하며, IMU 센서를 포함하는 제2웨 어러블 장치, 상기 제1웨어러블 장치를 촬영하고, 상기 복수의 골무의 위치 및 움직임에 관한 정보를 포함하는 제1데이터를 생성하는 카메라 및 상기 제1데이터를 수신하고, 상기 제1데이터에 기초하여 상기 제1손의 제1 제스 처 정보를 생성하고, 상기 제2손의 움직임에 따라 상기 IMU 센서로부터 생성되며 3축 정보를 포함하는 제2데이터 를 수신하고, 상기 제2데이터를 기반으로 상기 제2손의 제2제스처 정보를 생성하고, 상기 제1제스처 정보 및 상 기 제2제스처 정보 중 적어도 하나에 기초하여, 선택된 드론의 동작 상태를 제어하는 제어부를 포함할 수 있다."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 카메라 및 IMU 기반 드론 제어 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무인이동체란 외부환경을 인식해 스스로 상황을 판단하여 이동하고, 필요 시에는 작업을 수행할 수 있는 이동체 로 정의된다. 무인이동체는 공중/육상/해양 등 운용환경에 따라 분류될 수 있으며 농업 및 조업 등의 1차 산업, 운송업, 공공서비스, 국방 등 다양한 분야에 멀티콥터, 드로이드, 수상무인선 등 여러 종류의 무인이동체가 활 용되고 있다. 이 중 공중무인이동체는 조종사의 탑승 없이 자율적 혹은 무선전파유도를 통한 원격조종으로 비행/조종 가능한 비행기나 헬리콥터 모양의 무인기를 의미한다. UAV는 개발 초기 군용으로 주로 활용되었으나 최근 취미, 촬영 등 민수용 시장이 점차 확대되고 있으며 인공지능, 네트워크(IoT, mobile) 등 4차 산업혁명의 중심기술들의 발 전과 더불어 기술융합의 플랫폼으로 활용될 가능성이 크며 이에 따라 공중무인이동체를 활용한 도심형 항공 모 빌리티, 드론 택배 배송 등의 운송분야 및 국토 및 인프라 관리, 미래 국방 등의 산업에서 중요한 역할을 하게 될 것으로 전망된다. 또한, 공중무인이동체의 기술 발전 및 시장의 활성화에 따라, 복수의 공중무인이동체의 동시 제어가 가능한 기 술 및 공중무인이동체의 안전 운용에 대한 관심이 증가하고 있으며, 이 같은 기술의 필요성이 대두되고 있다. 따라서 직관적인 인간 중심의 인터페이스 구축을 통하여 안전하고 효율적인 임무수행이 가능하고, 그와 함께 복 수의 공중무인이동체의 동시 제어가 가능한 기술이 필요한 실정이다. 본원의 배경이 되는 기술은 한국등록특허공보 제 10-2264185호에 개시되어 있다."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 카메라 및 인공 신경망을 이용한 실시간 객체 탐 지 기능 및 IMU 센서의 가속도 정보를 활용함으로써, 안전하고 직관적으로 제어할 수 있는 카메라 및 IMU 기반 드론 제어 장치 및 방법을 제공하려는 것을 목적으로 한다. 본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 간단한 제어로 복수의 드론을 동시에 제어할 수 있는 카메라 및 IMU 기반 드론 제어 장치 및 방법을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 카메라 및 IMU 기반 드론 제 어 장치는, 사용자의 양 손 중 제1손에 착용 가능하며, 복수의 골무를 포함하는 제1웨어러블 장치, 사용자의 양 손 중 제2손에 착용 가능하며, IMU 센서를 포함하는 제2웨어러블 장치, 상기 제1웨어러블 장치를 촬영하고, 상 기 복수의 골무의 위치 및 움직임에 관한 정보를 포함하는 제1데이터를 생성하는 카메라 및 상기 제1데이터를 수신하고, 상기 제1데이터에 기초하여 상기 제1손의 제1 제스처 정보를 생성하고, 상기 제2손의 움직임에 따라 상기 IMU 센서로부터 생성되며 3축 정보를 포함하는 제2데이터를 수신하고, 상기 제2데이터를 기반으로 상기 제 2손의 제2제스처 정보를 생성하고, 상기 제1제스처 정보 및 상기 제2제스처 정보 중 적어도 하나에 기초하여, 선택된 드론의 동작 상태를 제어하는 제어부를 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 제어부는, 상기 카메라로부터 상기 제1데이터를 수신하고, 상기 제1데이터에 기초하여, 신경망 모델을 통해 상기 제1손의 위치를 나타내는 바운딩 박스의 예측 및 제스처 명령의 예측을 수행하고, 예측 결과를 기반으로 상기 제1제스처 정보를 생성할 수 있다. 본원의 일 실시예에 따르면, 상기 제어부는, 상기 IMU 센서로부터 상기 제2데이터를 수신하고, 기 설정된 시간 동안 제2데이터가 유지되는 경우의 헤딩을 기준으로 헤딩을 설정하고, 상기 제2데이터에 기초하여, 상기 제2제 스처 정보를 생성할 수 있다. 본원의 일 실시예에 따르면, 상기 드론 제어 장치는, 드론을 선택하는 제1입력과 제1인식 모드, 제2인식 모드 및 중립 모드 중 하나의 모드를 선택하는 제2입력을 수신하는 입력 장치를 더 포함하고, 상기 제어부는, 상기 제1입력 및 상기 제2입력에 기초하여 상기 드론의 동작 상태를 제어할 수 있다. 본원의 일 실시예에 따르면, 상기 제어부는, 상기 제2입력이 상기 중립 모드에 대한 선택 입력을 포함하는 경우, 상기 드론의 제어를 수행하지 않고, 상기 제2입력이 상기 제1인식 모드에 대한 선택 입력을 포함하는 경 우, 상기 제1제스처 정보에 기초하여 상기 드론의 동작 상태를 제어하고, 상기 제2입력이 상기 제2인식 모드에 대한 선택 입력을 포함하는 경우, 상기 제2제스처 정보에 기초하여 상기 드론의 동작 상태를 제어할 수 있다. 본원의 일 실시예에 따르면, 상기 제1제스처 정보는, 시동 켜기(Arming), 시동 끄기(Disarming), 이륙(Take off), 착륙(Landing), 귀환(Back home) 및 멈춤(Stop)을 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 제2데이터는, 롤, 피치 및 요우를 포함하는 상기 3축 정보 및 스로틀 조작에 따른 스로틀 정보를 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 제2제스처 정보는, 전진, 후진, 왼쪽으로 이동, 오른쪽으로 이동, 왼쪽으로 회전, 오른쪽으로 회전, 상승 및 하강을 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 복수의 골무는, 상기 제1손의 손가락 중 적어도 3 개 이상의 손가락에 착용 되고, 각각 다른 색상일 수 있다. 본원의 일 실시예에 따르면, 상기 신경망 모델은, 상기 바운딩 박스의 예측 및 상기 제스처 명령의 예측을 동시 에 수행하고, 상기 예측 결과의 신뢰도가 기 설정된 기준값보다 낮을 경우, 상기 예측에 의한 제스처 명령을 배 제할 수 있다. 본원의 일 실시예에 따르면, 상기 드론은, 복수의 드론을 포함하고, 상기 제1입력은, 상기 복수의 드론 중 적어 도 2개 이상의 드론에 대한 선택을 포함하고, 상기 제어부는, 상기 제1입력에 기초하여, 상기 적어도 2개 이상 의 드론의 동작 상태를 동시에 제어할 수 있다. 본원의 일 실시예에 따르면, 카메라 및 IMU 기반 드론 제어 방법은, 사용자의 양 손 중 제1손에 착용 가능하며, 복수의 골무를 포함하는 제1웨어러블 장치 및 상기 제1웨어러블 장치를 촬영하는 카메라로부터 제1데이터를 수 신하고, 상기 제1데이터에 기초하여, 제1제스처 정보를 생성하는 단계, 사용자의 양 손 중 제2손에 착용 가능하 며, IMU 센서를 포함하는 제2웨어러블 장치로부터 제2데이터를 수신하고, 상기 제2데이터에 기초하여, 제2제스 처 정보를 생성하는 단계 및 상기 제1제스처 정보 및 상기 제2제스처 정보에 기초하여, 드론의 동작 상태를 제 어하는 단계를 포함할 수 있다. 본원의 일 실시예에 따르면, 상기 드론 제어 방법은, 드론을 선택하는 제1입력을 수신하는 단계 및 제1인식 모 드, 제2인식 모드 및 중립 모드 중 하나의 모드를 선택하는 제2입력을 수신하는 단계를 더 포함하고, 상기 드론 의 동작 상태를 제어하는 단계는, 상기 제1입력 및 상기 제2입력을 고려하여 상기 드론의 동작 상태를 제어하는 것일 수 있다. 본원의 일 실시예에 따르면, 상기 제1제스처 정보를 생성하는 단계는, 카메라로부터 상기 제1데이터를 수신하고, 상기 제1데이터에 기초하여, 신경망 모델을 통해 제스처의 위치를 나타내는 바운딩 박스의 예측 및 제스처 명령의 예측을 수행하고, 예측 결과를 기반으로 상기 제1제스처 정보를 생성하는 것이고, 상기 제2제스 처 정보를 생성하는 단계는, IMU 센서로부터 상기 제2 데이터를 수신하고, 기 설정된 시간 동안 상기 제2데이터 가 유지되는 경우의 헤딩을 기준으로 헤딩을 설정하고, 상기 제2데이터에 기초하여, 상기 제2제스처 정보를 생 성하는 것일 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 카메라 및 인공 신경망을 이용한 실시간 객체 탐지 기능 및 IMU 센서 의 가속도 정보를 활용함으로써, 안전하고 직관적으로 제어할 수 있는 카메라 및 IMU 기반 드론 제어 장치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 간단한 제어로 복수의 드론을 동시에 제어할 수 있는 카메라 및 IMU 기반 드론 제어 장치 및 방법을 제공할 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 도 1은 본원의 일 실시예에 따른 드론 제어 시스템의 개략적인 구성도이다. 도 1을 참조하면, 본원의 일 실시예에 따른 드론 제어 시스템은 드론 제어 장치, 네트워크 및 드 론을 포함할 수 있다. 이하에서는 본원의 일 실시예에 따른 드론 제어 장치를 설명의 편의상 본 장치(10 0)라 하기로 한다. 본원의 일 실시예에 따른 본 장치는 드론의 제어를 위해, 네트워크로 드론과 연결될 수 있 다. 네트워크는 단말 및 서버와 같은 각각의 노드 상호 간에 정보 교환이 가능한 유, 무선의 연결 구조를 의미 하는 것으로, 이러한 네트워크의 일 예에는 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인 터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 본원의 일 실시예에 따르면, 드론은 하나 또는 복수의 드론을 포함할 수 있으며, 본 장치는 하나 또 는 복수의 드론은 제어하기 위한 장치일 수 있다. 도 2는 본원의 일 실시예에 따른 본 장치의 개략적인 구성도 이다. 도 2를 참조하면, 본 장치는 사용자의 양 손 중 제1손에 착용 가능하며, 복수의 골무를 포함하는 제1 웨어러블 장치 및 상기 제1웨어러블 장치를 촬영하고, 복수의 골무의 위치 및 움직임에 관한 정 보를 포함하는 제1데이터를 생성하는 카메라를 포함할 수 있다. 본원의 일 실시예에 따르면, 제1웨어러블 장치는 사용자의 제1손에 착용되기 위해 장갑의 형태일 수 있으 나, 이에 한정되는 것은 아니며, 카메라는 타 센서 대비 높은 해상도를 가지며 산출 데이터의 색상 정보 포함으로 객체 분류 및 인식에서 높은 성능을 보이는 RGB 카메라일 수 있으나, 이에 한정되는 것은 아니다. 또 한, 본원의 일 실시예에 따르면, 상기 제1손은 사용자의 오른손일 수 있다. 본원의 일 실시예에 따르면, 복수의 골무는 카메라의 실시간 객체 탐지를 통한 제스처 인식의 정확도 향상을 위해, 제1손의 손가락 중 적어도 3개 이상의 손가락에 착용 되고, 골무의 각각은 다른 색상일 수 있다. 예를 들어, 복수의 골무는 제1손의 엄지, 검지 및 중지에 착용 되고, 각각 분홍, 초록 및 파랑 색일 수 있으나, 이에 한정되는 것은 아니다. 도 2를 참조하면, 본 장치는 사용자의 양 손 중 제2손에 착용 가능하며, IMU 센서을 포함하는 제2웨 어러블 장치을 포함할 수 있다. 본원의 일 실시예에 따르면, 제2웨어러블 장치는 사용자의 제2손에 착용되기 위해 장갑의 형태일 수 있으 나, 이에 한정되는 것은 아니며, IMU 센서는 3축 자이로스코프, 3축 가속도 센서 및 3축 지자기 센서 등을 포함하는 센서일 수 있으며, 3축 선형 가속도 및 각속도 값과 3축 자세 값 등의 지원이 가능한 것일 수 있고, IMU 센서는 제2손의 엄지에 부착되는 형태일 수 있으나, 이에 한정되는 것은 아니다. 또한, 본원의 일 실 시예에 따르면, 상기 제2손은 사용자의 오른손일 수 있다. 또한, 본원의 일 실시예에 따르면, 제1웨어러블 장치 및 제2웨어러블 장치는 사용자의 양 손에 용이 하게 착용 되기 위해 장갑의 형태일 수 있으나, 이에 한정되는 것은 아니다. 도 2를 참조하면, 본 장치는 제어부를 포함하고, 제어부는 카메라로부터 제1데이터를 수신 하고, 제2손의 움직임에 따라 IMU 센서로부터 생성되는 제2데이터를 수신할 수 있다. 본원의 일 실시예에 따르면, 제1데이터는 카메라를 이용하여 촬영되는 제1웨어러블 장치의 실시간 화 면, 영상 및 사진일 수 있으나, 이에 한정되는 것은 아니며, 제2데이터는 IMU 센서에서 출력되는 센서 값 일 수 있고, 이는 롤(Roll), 피치(Pitch) 및 요우(Yaw)를 포함하는 3축 정보 및 스로틀(Throttle) 정보를 포함 하는 것일 수 있으나, 이에 한정되는 것은 아니다. 또한, 도 2를 참조하면, 본 장치는 별도의 입력 장치를 더 포함할 수 있다. 입력 장치은 여러 개의 드론 중 제어하고자 하는 하나 또는 복수의 드론을 선택하는 제1입력 및 제1인식 모드, 제2 인식 모 드 및 중립 모드 중 하나의 모드를 선택하는 제2입력을 수신할 수 있다. 즉, 제어부는 입력 장치로부 터 제1입력 및 제2입력을 수신하고, 제1입력 및 제2입력에 기초하여, 선택된 드론의 동작 상태를 제어할 수 있고, 입력 장치는 사용의 편의를 위해 키보드일 수 있으나, 이에 한정되는 것은 아니다. 본원의 일 실시예에 따르면, 제어부는 입력 장치를 통해 제1입력을 수신하고, 제1입력에 따른 사용자 가 제어하고자 하는 하나 혹은 복수의 드론을 동시에 제어할 수 있다. 제1입력은 제어하고자 하는 드론을 선택하는 입력일 수 있으며, 복수의 드론 중 적어도 2개 이상의 드론에 대한 선택을 포함할 수 있고, 제어부 는 선택된 드론의 동작 상태를 동시에 제어할 수 있다. 예를 들어, 제어할 수 있는 드론이 총 10개가 있고, 제1입력이 제1드론 내지 제4드론에 대한 선택일 경우, 제어부는 제1드론 내지 제4드론을 동시에 제어할 수 있으며, 제5드론 내지 제10드론은 제어하지 않을 수 있고, 제1입력이 제1드론에 대한 선택일 경우, 제어부는 제1드론 하나만을 제어할 수 있으나, 이에 한정되 는 것은 아니다. 또한, 제어부는 입력 장치를 통해 제2입력을 수신하고, 제2입력에 따라 제1인식 모드, 제2인식 모드 및 중립 모드 중 하나의 제어 모드로 드론을 제어할 수 있다. 즉, 제2입력은 드론 제어를 위한 제어 모드를 선택하는 입력일 수 있다. 제2입력이 제1인식 모드에 대한 선택 입력을 포함하는 경우, 제어부는 제1제스처 정보에 기초하여 드론 의 동작 상태를 제어하고, 제2입력이 제2인식 모드에 대한 선택 입력을 포함하는 경우, 제어부는 제2 제스처 정보에 기초하여 드론의 동작 상태를 제어하며, 제2입력이 중립 모드에 대한 선택 입력을 포함하는경우, 제어부는 드론을 제어하지 않을 수 있다. 즉, 중립 모드는 드론 제어를 중지하는 것을 의미할 수 있으며, 중립 모드가 선택된 경우, 제1웨어러블 장 치 및 제2웨어러블 장치의 움직임에도, 드론 제어가 수행되지 않을 수 있다. 본원의 일 실시예에 따르면, 제1인식 모드는 제어부가 제1웨어러블 장치로부터 제1데이터를 수신하고, 제1 제스처 정보를 생성하여, 드론을 제어하는 모드일 수 있다. 본원의 일 실시예에 따르면, 제어부는 제1데이터에 기초하여, 신경망 모델을 통해 제1손의 위치를 나타내 는 바운딩 박스의 예측 및 제1손에서의 복수의 골무의 위치에 따른 제스처 명령의 예측을 수행하고, 예측 결과 를 기반으로 제1제스처 정보를 생성할 수 있다. 본원의 일 실시예에 따르면, 상기 제1데이터는 복수의 골무의 위치 및 복수의 골무들 간의 위치 상관 관계에 관 한 정보를 포함할 수 있다. 또한, 제스처 명령은 신경망 모델을 통해 제1데이터에 따른 예측 결과를 의미할 수 있고, 제1제스처 정보는 신경망 모델이 예측한 결과가 기 설정된 기준값보다 높을 때 생성되는, 드론 제어 를 위한 명령어 정보일 수 있다. 본원의 일 실시예에 따르면, 제어부는 신경망 모델의 예측 결과를 기반으로 제1제스처 정보를 생성할 수 있다. 도 3을 참조하면, 제1손의 제스처 명령과 제어부에서 생성되는 제1제스처 정보의 일 실시예를 확인할 수 있다. 제1제스처 정보는 시동 켜기(Arming), 시동 끄기(Disarming), 이륙(Take off), 착륙(Landing), 귀환 (Back home) 및 멈춤(Stop)을 포함할 수 있으나, 이에 한정되는 것은 아니다. 시동 켜기(Arming), 시동 끄기(Disarming), 이륙(Take off), 착륙(Landing), 귀환(Back home) 및 멈춤(Stop) 등의 동작은 후술할 IMU 센서 기반의 제어에 의한 동작들보다 조작 빈도가 적으며 연속적인 명령 입력을 필요로 하지 않으므로, 제1웨어러블 장치 및 카메라 기반의 객체 탐지 기능을 이용하여 제어되도록 구성되었으며, 제1데이터는 조작 수행 시 불필요한 명령 입력이 이루어지지 않도록 일상적으로 잘 사용되지 않 는 손동작들을 포함하는 것일 수 있으나, 이에 한정되는 것은 아니다. 다시 도 3을 참조하면, 제1손의 제스처 모양 및 제1데이터와 그에 대응하는 제1제스처 정보를 확인할 수 있다. 제1데이터는 제1손의 제스처 모양을 촬영한 것으로, 도면 상 같은 것으로 표현될 수 있다. 본원의 일 실시예에 따르면, 손바닥을 보이며 엄지와 소지만 펼친 제스처는 시동 켜기(Arming)이라는 제1제스처 정보를 생성하기 위한 제스처일 수 있고, 손등을 보이며 엄지와 소지만 펼친 제스처는 시동 끄기(Disarming)이 라는 제1제스처 정보를 생성하기 위한 제스처일 수 있다. 이와 같이 손바닥을 보이며 엄지와 검지만 펼친 제스처는 이륙(Take off), 손등을 보이며 엄지와 검지만 펼친 제스처는 착륙(Landing), 손바닥을 보이며 검지와 중지만 펼친 제스처는 귀환(Back home), 그리고 손바닥을 보 이며 다섯 손가락을 모두 펼친 제스처는 멈춤(Stop)이라는 제1제스처 정보를 생성하기 위한 제스처일 수 있다. 또한, 여기서, 귀환(Back home)은 드론이 기 설정된 홈 위치로 돌아오는 것을 의미할 수 있으며, 멈춤 (Stop)은 드론이 일정한 고도를 유지한 채 움직이지 않는 상태인 제자리 비행, 즉 호버링(Hovering)을 의 미할 수 있고, 또는 수행 중이던 동작 상태를 멈추라는 의미일 수 있으나, 이에 한정되는 것은 아니다. 도 3에 도시된 제1손의 제스처 및 제1데이터와 제1제스처 정보는 본원의 일 실시예에 따른 것이며, 각각의 제스 처 및 생성되는 정보는 일부 혹은 전부 상이한 것일 수 있으므로, 도 3에 도시된 내용으로 한정되는 것은 아니 다. 또한, 신경망 모델은 바운딩 박스의 예측 및 제스처 명령의 예측을 동시에 수행 가능한 모델일 수 있다. 본원의 일 실시예에 따르면, 신경망 모델은 바운딩 박스의 예측과 제스처 명령의 예측을 동시에 예측 가능하고, 예측 시간이 빨라 드론의 제어에 유용한 YOLO 모델일 수 있으나, 이에 한정되는 것은 아니다. 또한, 신경망 모델은 바운딩 박스의 예측 및 제스처 명령의 예측에 대한 예측 결과의 신뢰도가 기 설정된 기준 값보다 낮을 경우, 이러한 낮은 신뢰도의 예측에 의한 제스처 명령은 배제할 수 있다. 예를 들어, 사용자가 시 동 켜기(Arming)이라는 제1제스처 정보를 생성하기 위해 제1손의 손바닥을 보이며 엄지와 소지만 펼친 제스처를 카메라 앞에 취하면, 신경망 모델은 해당 제스처를 둘러싸는 바운딩 박스를 알맞게 예측하고, 제스처 명령 을 예측하되, 예측한 제스처 명령이 시동 켜기(Arming)에 대한 제스처 명령일 확률, 즉 신뢰도를 함께 예측할 수 있다. 이때, 기 설정된 기준값이 80%이고, 예측한 제스처 명령의 신뢰도가 90%일 경우, 제어부는 예측한 바운딩 박스 및 해당 제스처 명령을 기반으로 제1제스처 정보를 생성할 수 있고, 예측한 명령의 신뢰도가 60%일 경우에는 신경망 모델이 해당 제스처 명령을 배제하여, 드론 제어를 위한 제1제스처 정보가 생성되 지 않을 수 있다. 또한, 본원의 또 다른 일 실시예에 따르면, 어떤 경우이던 제1제스처 정보는 생성하되, 신뢰도가 기 설정된 기 준값보다 낮을 때, 제어부에서 해당 제1제스처 정보를 배제하여, 그에 대응하는 드론의 제어를 하지 않을 수도 있으나, 이에 한정되는 것은 아니다. 이처럼, 본 장치는 기 설정된 기준값보다 낮은 신뢰도의 예측에 의한 제스처 명령을 배제함으로써, 보다 안정적이고, 정확하게 드론을 제어할 수 있다. 본원의 일 실시예에 따르면, 제2인식 모드는 제어부가 제2웨어러블 장치로부터 제2데이터를 수신하고, 제2 제스처 정보를 생성하여, 드론을 제어하는 모드일 수 있다. 본원의 일 실시예에 따르면, 제어부는 기 설정된 시간 동안 제2데이터가 유지되는 경우의 헤딩을 기준으로 헤딩을 설정하고, 제2데이터에 기초하여, 제2제스처 정보를 생성할 수 있다. 상술한 바와 같이, 제2데이터는 IMU 센서로부터 수신한 센서 값을 의미하고, 제2제스처 정보는 센서 값에 따라 생성되는 명령어 정보일 수 있으며, 본원의 일 실시예에 따른 제어부는 제2데이터를 기반으로 제2제 스처 정보를 생성할 수 있다. 또한, 제어부는 제2제스처 정보의 생성에 앞서 IMU 센서의 센서 값의 기준 점이 될 헤딩을 설정할 수 있다. 헤딩 설정은 기 설정된 시간 동안 제2데이터가 유지되는 경우의 헤딩을 기준으로 설정될 수 있다. 예를 들어, 엄지에 IMU 센서가 부착된 제2웨어러블 장치를 제2손에 착용한 사용자가, 제2손의 엄지를 위로 향해 들고 있는 상태로 5초(기 설정된 시간)동안 유지할 경우, 제어부는 제2손의 엄지가 위를 향한 상태의 IMU 센서 의 센서 값을 수신하고, 그 값을 기준으로 설정할 수 있으나, 이에 한정되는 것은 아니다. 또한, 제어부는 처음 설정된 헤딩을 저장할 수 있으며, 헤딩 설정이 새롭게 필요하지 않은 경우, 저장된 직전에 설정된 헤딩을 기준으로 제2데이터를 수신할 수 있다. 예를 들어, 상술한 입력 장치로부터 헤딩 설 정의 수행을 위한 입력을 수신한 경우, 그 때마다 헤딩 설정을 수행하거나, 제2인식 모드가 선택된 이후, 항상 새롭게 헤딩 설정을 수행할 수 있고, 본 장치의 사용 중 가장 처음에 설정한 헤딩을 저장하고, 본 장치 의 사용을 종료할 때까지 저장한 헤딩을 기준으로 제2데이터를 수신할 수 있다. 즉, 헤딩 설정은 헤딩 설 정에 대한 입력이 들어온 경우 또는 제2입력이 제2인식 모드에 대한 선택인 경우에 수행되는 것일 수 있고, 설 정된 헤딩은 저장되어, 사용자가 새로운 헤딩 설정을 필요로 하지 않는 경우, 저장된 헤딩을 기준으로 제2데이 터를 수신할 수 있으나, 이에 한정되는 것은 아니다. 본원의 일 실시예에 따르면, 상술한 과정을 통해, 제어부는 설정된 헤딩을 기준으로 IMU 센서의 롤 (Roll), 피치(Pitch), 요우(Yaw) 및 스로틀(Throttle) 값의 변화를 제2데이터로써 수신하고, 제2데이터를 기반 으로 제2제스처 정보를 생성할 수 있다. 본원의 일 실시예에 따르면, 제어부는 제2데이터에 포함된 롤 (Roll), 피치(Pitch), 요우(Yaw) 및 스로틀(Throttle) 값의 변화 방향 및 변화 정도에 기초하여, 제2제스처 정 보를 생성할 수 있다. 도 4를 참조하면, 제2손의 제스처, 제2데이터, 제2제스처 정보 및 그에 따른 드론의 동작 상태를 확인할 수 있다. 제2제스처 정보는 전진, 후진, 왼쪽으로 이동, 오른쪽으로 이동, 왼쪽으로 회전, 오른쪽으로 회전, 상 승 및 하강을 포함할 수 있으나, 이에 한정되는 것은 아니다. 예를 들어, 제2웨어러블 장치는 IMU 센서가 오른손(제2손)의 엄지에 대응하는 위치에 부착되어 있는 것이며, IMU 센서의 축은 엄지가 앞을 가리키는 방향을IMU 센서의 +X, 왼쪽을 가리키는 방향을 +Y, 그리고 위를 가리키는 방향을 +Z인 것으로 축을 설정할 수 있고, 이 경우, 엄지를 앞뒤로 회전시키면, Y축을 중 심으로 회전하는 것인 피치(Pitch)의 값이 변화하고, 엄지를 좌우로 회전시키면, X축을 중심으로 회전하는 것인 롤(Roll) 값이 변화하고, 손목을 좌우로 돌리며 회전시키면, Z축을 중심으로 회전하는 것인 Yaw의 값이 변화하 게 될 수 있으나, 이에 한정되는 것이 아니다. 위와 같은 경우, 도 4와 같이 사용자가 만약 엄지를 앞 방향으로 내리는 제스처를 취하면, 제2데이터는 피치 다 운(Pitch down)이고, 제어부는 제2데이터를 수신하고, 이를 기반으로 전진을 의미하는 제2제스처 정보를 생성할 수 있고, 드론의 동작 상태를 전진으로 제어할 수 있다. 반면에, 사용자가 만약 엄지를 뒤 방향을 가리키는 제스처를 취하면, 제2데이터는 피치 업(Pitch up)이고, 제어 부는 제2데이터를 수신하고, 이를 기반으로 후진을 의미하는 제2제스처 정보를 생성할 수 있고, 드론(30 0)의 동작 상태를 후진으로 제어할 수 있다. 마찬가지로, 도 4를 참조하면, 사용자의 제2손의 제스처에 따라 IMU 센서는 제2데이터를 생성하고, 제어부 는 제2데이터가 Roll left일 때는 왼쪽으로 이동, Roll right일 때는 오른쪽으로 이동, Yaw left 일 때는 왼쪽으로 회전, Yaw right일 때는 오른쪽으로 회전, Throttle up일 때는 상승, 그리고 Throttle down일 때는 하강을 의미하는 제2 제스처 정보를 생성하고, 그에 따른 동작 상태로 드론을 제어할 수 있다. 요우(Yaw)의 값은 상하좌우 앞뒤 방향들의 기존 임계값들과는 독립적으로 출력되도록 설정할 수 있고, 본원의 일 실시예에 따르면, 요우(Yaw)가 ±15도 범위 안에서 움직일 경우, 제어부는 입력 되는 제2데이터를 Yaw left 및 Yaw right로써 수신하고, 제2제스처 정보를 왼쪽으로 회전 및 오른쪽으로 회전으로 생성할 수 있고, 요 우(Yaw)의 범위가 ±15도 범위를 벗어나는 경우, 사용자가 제2손을 위, 아래로 움직이면, 제어부는 입력 되는 제2데이터를 Throttle up 및 Throttle down으로써 수신하고, 제2제스처 정보를 상승 및 하강으로 생성할 수 있으나, 이에 한정되는 것은 아니다. 도 4에 도시된 제2손의 제스처, 제2데이터, 제2제스처 정보 및 동작 상태는 본원의 일 실시예에 따른 것이며, 각각의 제스처 및 생성되는 정보는 일부 혹은 전부 상이한 것일 수 있으므로, 도 4에 도시된 내용으로 한정되는 것은 아니다. 이처럼, 본 장치는 카메라 및 인공 신경망을 이용한 실시간 객체 탐지 기능 및 IMU 센서의 가속도 정보를 활용함으로써, 드론을 안전하고 직관적으로 제어할 수 있다. 즉, 제어부는 제1데이터를 수신하고, 제1데이터에 기초하여 제1손의 제1제스처 정보를 생성하고, 제2손의 움직임에 따라 IMU 센서로부터 생성 되며 3축 정보를 포함하는 제2데이터를 수신하고, 제2데이터를 기반으 로 제2손의 제2제스처 정보를 생성하고, 제1제스처 정보 및 제2제스처 정보 중 적어도 하나에 기초하여, 선택된 드론의 동작 상태를 제어할 수 있다. 다시 말해, 제어부는 제1입력을 수신하여 제어하고자 하는 드론을 선택하고, 제1인식 모드, 제2인식 모드 및 중립 모드 중 하나의 모드를 선택하는 제2입력을 수신하고, 제2입력에 따라 제어 모드를 선택하고, 선 택된 제어 모드가 중립 모드일 경우, 드론을 제어하지 않고, 선택된 제어 모드가 제1인식 모드일 경우, 상 술한 과정을 통해 제1제스처 정보를 생성하고, 이를 기반으로 드론을 제어하며, 선택된 제어 모드가 제2인 식 모드일 경우, 상술한 과정을 통해 제2제스처 정보를 생성하고, 이를 기반으로 드론을 제어할 수 있다. 이처럼, 본 장치는 사용자의 양 손에 착용 되는 제1웨어러블 장치 및 제2웨어러블 장치, 그리고 입력 장치를 통한 간단한 제어로 복수의 드론을 동시에 제어할 수 있으며, 카메라 및 IMU 센서 기반의 제어로, 안전하고 직관적인 드론 제어가 가능하다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 살펴보기로 한다. 도 5는 본원의 일 실시예에 따른 드론 제어 방법에 대한 동작 흐름도이다. 도 5에 도시된 드론 제어 방법은 앞서 설명된 본 장치, 즉 드론 제어 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 드론 제어 장치에 대하여 설명된 내용은 드론 제어 방법 에 대한 설명에도 동일하게 적용될 수 있다. 도 5를 참조하면, 드론 제어 방법은, 드론을 선택하는 제1입력을 수신하는 단계(S410)를 포함할 수 있다. 단계 S410은 드론의 제어를 위해, 사용자로부터 제어하고자 하는 드론에 대한 선택을 수신하는 단계일 수 있다. 예를 들어, 제어 할 수 있는 드론이 총 10개일 경우, 본 장치는 제어하기 위한 드론의 선택으 로, 제1드론 내지 제5드론에 대한 선택을 수신할 수 있으나, 이에 한정되는 것은 아니다. 또한, 도 5를 참조하면, 드론 제어 방법은 제1인식 모드, 제2인식 모드 및 중립 모드 중 하나의 제어 모드 를 선택하는 제2입력을 수신하는 단계(S420)를 포함할 수 있다. 단계 S410은 드론을 제어하기 위한 제어 모드의 선택, 즉 제2입력을 수신하는 단계일 수 있다. 예를 들어, 제2입력이 중립 모드에 대한 선택인 경우, 본 장치는 중립 모드에 따라 상술한 예에 따른 제1드론 내지 제5드론에 아무런 제어도 하지 않을 수 있다. 또한, 도 5를 참조하면, 드론 제어 방법은 사용자의 양 손 중 제1손에 착용 가능하며, 복수의 골무를 포함 하는 제1웨어러블 장치 및 제1웨어러블 장치를 촬영하는 카메라로부터 제1데이터를 수신하고, 제1데이터에 기초 하여, 제1제스처 정보를 생성하는 단계(S430)를 포함할 수 있다.구체적으로, 단계 S430은 제2입력이 제1인식 모드에 대한 선택일 경우 수행되는 단계이며, 카메라로부터 제1데 이터를 수신하고, 제1데이터에 기초하여, 신경망 모델을 통해 제스처의 위치를 나타내는 바운딩 박스의 예측 및 제스처 명령의 예측을 수행(S431)하고, 예측 결과를 기반으로 상기 제1제스처 정보를 생성(S432)하는 것일 수 있다. 예를 들어, 단계 S430는 제1웨어러블 장치 및 카메라로부터 손바닥을 보이며 엄지와 소지만 펼친 제 스처에 대한 제1데이터를 수신하고, 제1데이터에 대한 바운딩 박스 및 제스처 명령을 예측(S431)하고, 예측한 제스처 명령이 시동 켜기(Arming)일 경우, 시동 켜기(Arming)에 대한 제1제스처 정보를 생성(S432)하는 단계일 수 있으나, 이에 한정되는 것은 아니다. 또한, 도 5를 참조하면, 드론 제어 방법은 사용자의 양 손 중 제2손에 착용 가능하며, IMU 센서를 포함하 는 제2웨어러블 장치로부터 제2데이터를 수신하고, 제2데이터에 기초하여, 제2제스처 정보를 생성하는 단계 (S440)를 포함할 수 있다. 구체적으로, 단계 S440은 제2입력이 제2인식 모드에 대한 선택일 경우 수행되는 단계이며, IMU 센서로부터 제2 데이터를 수신하고, 기 설정된 시간 동안 제2데이터가 유지되는 경우의 헤딩을 기준으로 헤딩을 설정 하고, 제2데이터에 기초하여, 상기 제2제스처 정보를 생성(S442)하는 것일 수 있다. 예를 들어, 단계 S440은 제2웨어러블 장치로부터 제2데이터를 수신하되, 수신 중인 제2데이터의 값이 기 설정된 시간(예를 들어 5초)동안 유지될 경우, 그때의 헤딩을 기준으로 설정(S441)하고, 그 이후, Throttle up 에 대한 제2데이터를 수신하고, 제2데이터에 따라 상승을 의미하는 제2제스처 정보를 생성(S442)하는 단계일 수 있으나, 이에 한정되는 것은 아니다. 또한, 도 5를 참조하면, 드론 제어 방법은 상술한 제1입력 및 상기 제2입력을 고려하여 드론의 동작 상태 를 제어하는 단계(S450)를 포함할 수 있고, 단계 S450는 상술한 제1제스처 정보 및 제2제스처 정보에 기초하여, 드론의 동작 상태를 제어하는 단계일 수 있다. 예를 들어, 단계 S450은, 총 10개의 드론 중, 제1입력에 의해 선택된 드론이 제8드론 내지 제10드론이고, 제2입 력이 제1인식 모드에 대한 선택일 경우, 단계 S450은 S430에서 생성된 제1제스처 정보에 따라 제8드론 내지 제 10드론을 제어하는 단계일 수 있고, 제1입력에 의해 선택된 드론이 제1드론 및 제5드론이고, 제2입력이 제2인식 모드에 대한 선택일 경우, 단계 S450은 S440에서 생성된 제2제스처 정보에 따라 제1드론 및 제5드론을 제어하는 단계일 수 있으나, 이에 한정되는 것은 아니다. 또한, 예를 들어, 상술한 예시의 제1드론, 제5드론 및 제8드론 내지 제10드론의 제어 이후, 사용자로부터 제1입 력으로 제1드론, 제5드론 및 제8드론 내지 제10드론에 대한 선택을 수신하고, 제2입력으로 중립 모드에 대한 선 택을 수신할 경우, 본 장치는 제1드론, 제5드론 및 제8드론 내지 제10드론의 제어를 중지할 수 있으나, 이 에 한정되는 것은 아니다. 또한, 도시하지는 않았으나, 본원의 또 다른 일 실시예 따르면, 드론 제어 장치에서, 단계 S410과 단계 S420은 수행되는 순서가 바뀔 수도 있다. 즉, 본 장치는 드론의 제어 모드에 대한 선택을 먼저 수신 하고, 그 이후에 제어하고자 하는 드론에 대한 선택을 수신할 수 있다. 예를 들어, 본 장치는 제2입 력으로 제2인식 모드에 대한 선택을 수신한 뒤, 제1입력으로 제6드론에 대한 선택을 수신할 수 있고, 이 경우, 본 장치는 제2인식 모드에 따른 단계 S440를 따라 선택된 드론인 제6드론을 제어할 수 있으나, 이에 한정되는 것은 아니다. 다시 말해, 도 5를 참조하면, 드론 제어 방법은 제1입력을 수신(S410)하고, 제2입력을 수신(S420)하고, 제 2입력이 중립 모드에 대한 선택일 경우, 제1입력에 의해 선택된 드론을 제어하지 않고, 제2입력이 제1인식 모드 에 대한 선택일 경우, 제1제스처 정보를 생성(S430)하여, 제1입력에 의해 선택된 드론을 제어(S450)하고, 제2입 력이 제2인식 모드에 대한 선택일 경우, 제2제스처 정보를 생성(S440)하여, 제1입력에 의해 선택된 드론을 제어 (S450)하는 것일 수 있으나, 이에 한정되는 것은 아니다. 도 6은 본원의 또 다른 일 실시예에 따른 드론 제어 방법의 동작 흐름도이다. 도 6에 도시된 드론 제어 방법은 앞서 설명된 본 장치, 즉 드론 제어 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 드론 제어 장치에 대하여 설명된 내용은 드론 제어 방법 에 대한 설명에도 동일하게 적용될 수 있다. 도 6를 참조하면, 드론 제어 방법은, 드론을 선택하는 제1입력을 수신하는 단계(S510)를 포함할 수 있다. 단계 S510은 드론의 제어를 위해, 사용자로부터 제어하고자 하는 드론에 대한 선택을 수신하는 단계로, 상 술한 도 5의 단계 S410과 동일한 수행을 하는 단계일 수 있다. 또한, 도 6를 참조하면, 드론 제어 방법은, 사용자의 양 손 중 제1손에 착용 가능하며, 복수의 골무를 포 함하는 제1웨어러블 장치 및 제1웨어러블 장치를 촬영하는 카메라로부터 제1데이터를 수신하고, 제1데이터에 기 초하여, 제1제스처 정보를 생성하는 단계(S520)를 포함할 수 있다. 구체적으로, 단계 S520은 카메라로부터 제1데이터를 수신하고, 제1데이터에 기초하여, 신경망 모델을 통해 제스 처의 위치를 나타내는 바운딩 박스의 예측 및 제스처 명령의 예측을 수행(S521)하고, 예측 결과를 기반으로 상 기 제1제스처 정보를 생성(S522)하는 것일 수 있다. 즉, 단계 S520은 상술한 도 5의 단계 S430과 동일한 수행을 하는 단계일 수 있다. 또한, 도 6를 참조하면, 드론 제어 방법은 사용자의 양 손 중 제2손에 착용 가능하며, IMU 센서를 포함하 는 제2웨어러블 장치로부터 제2데이터를 수신하고, 제2데이터에 기초하여, 제2제스처 정보를 생성하는 단계 (S530)를 포함할 수 있다. 구체적으로, 단계 S530는 IMU 센서로부터 제2 데이터를 수신하고, 기 설정된 시간 동안 제2데이터가 유지 되는 경우의 헤딩을 기준으로 헤딩을 설정(S531)하고, 제2데이터에 기초하여, 상기 제2제스처 정보를 생성 (S532)하는 것일 수 있다. 즉, 단계 S530은 상술한 도 5의 단계 S440과 동일한 수행을 하는 단계일 수 있다. 또한, 도 6를 참조하면, 드론 제어 방법은 입력 장치를 통해, 제1인식 모드, 제2인식 모드 및 중립 모드 중 하나의 제어 모드 선택에 대한 제2입력을 수신하는 단계(S540)을 포함할 수 있다. 또한, 도 6를 참조하면, 드론 제어 방법은 단계 S540에서 수신한 제2입력에 기초하여, 제1인식 모드, 제2 인식 모드 및 중립 모드 중 하나의 제어 모드를 선택하는 단계(S550)을 포함할 수 있다. 구체적으로, 단계 S540에서 수신한 제2입력이 제1인식 모드 일 경우, 단계 S550에서 제1인식 모드가 제어 모드 로 선택될 수 있고, 단계 S540에서 수신한 제2입력이 제2인식 모드 일 경우, 단계 S550에서 제2인식 모드가 제 어 모드로 선택될 수 있다. 또한, 도 6를 참조하면, 드론 제어 방법은 단계 S550에서 선택된 제어 모드를 기반으로 드론의 제어 를 위한 제스처 정보를 선택하는 단계(S560)을 포함할 수 있다. 단계 S520 및 단계 S530에서 생성된 제1 제스처 정보 및 제2제스처 정보는 본 장치에 저장될 수 있고, 단 계 S560은 단계 S540 및 단계 S550에서 수신한 제어 모드가 제1인식 모드일 경우, 단계 S560은 저장된 제1제스 처 정보들 중 가장 마지막으로 저장된 제1제스처 정보를 선택하는 단계일 수 있고, 또는, 단계 S560은 단계 S540 및 단계 S550에서 수신한 제어 모드가 제1인식 모드일 경우, 단계 S560은 기 설정된 시간 동안 저장되어 있던 제1제스처 정보들을 순서대로 선택하는 단계일 수 있으나, 이에 한정되는 것은 아니다. 또한, 드론 제어 방법은 상술한 제1입력 및 선택된 제스처 정보를 기반으로 드론의 동작 상태를 제어하는 단계(S570)를 포함할 수 있다. 즉, 단계 S570은 상술한 도 5의 단계 S450과 동일한 수행을 하는 단계일 수 있다. 예를 들어, 도 6을 참조하면, 드론 제어 방법은 단계 S510에서 총 10개의 드론 중 제3드론 내지 제5드론에 대한 선택인 제1입력을 수신하고, 단계 S520 및 단계 S530에서 각각 제1제스처 정보 및 제2제스처 정보를 생성 하고, 단계 S540에서 중립 모드, 제1인식 모드 및 제2인식 모드 중 제2인식 모드에 대한 선택인 제2입력을 수신 하고, 단계 S550에서 수신한 제2입력에 기초하여, 제어 모드로 제2인식 모드를 선택하고, 단계 S560에서 저장되 어 있는 제2제스처 정보들 중 가장 최근에 저장된 제2제스처 정보를 선택하고, 단계 S570에서 선택한 제2제스처 정보를 기반으로 제3드론 내지 제5드론을 제어하는 것일 수 있으나, 이에 한정되는 것은 아니다. 또한, 도시하지는 않았으나, 본원의 일 실시예에 따르면, 제1입력을 수신하는 단계(S410 또는 S510)는, 제1제스 처 정보 생성 단계(S430 또는 S520) 및 제2제스처 정보 생성 단계(S440 또는 S530) 수행 후, 수행될 수도 있다. 즉, 제1제스처 정보 및 제2제스처 정보는 계속 생성하되, 생성된 제1제스처 정보 및 제2제스처 정보를 기반으로 제어하고자 하는 드론 선택에 대한 제1입력을 수신(S410 또는 S510)하고, 제어 모드 선택에 대한 제2입력을 수 신(S420 또는 S540) 할 수 있으나, 이에 한정되는 것은 아니다. 또한, 도시하지는 않았으나, 본원의 일 실시예에 따르면, 드론을 제어하는 단계(S450 또는 S570)는 수행 중, 제 1입력 및 제2입력을 새로 수신(S410 또는 S510 및 S420 또는 S540)하는 경우, 수행을 마치거나 제어하고자 하는드론, 또는 제어 모드가 변경되어 드론을 제어하는 것일 수 있으나, 이에 한정되는 것은 아니다. 예를 들어, 드론을 제어하는 단계(S450 또는 S570)는 제1제스처 정보를 기반으로 제1드론의 제어를 수행하는 도 중, 제2인식 모드 선택에 대한 제2입력을 수신(S420 또는 S540)한 경우, 제2제스처 정보를 기반으로 제1드론을 제어할 수 있고, 제2제스처 정보를 기반으로 제1드론 제어를 수행하는 도중, 제2드론 선택에 대한 제1입력을 수 신(S410 또는 S510)하는 경우, 제1드론의 제어를 중지하고, 제2제스처 정보를 기반으로 제2드론을 제어할 수 있 으나, 이에 한정되는 것은 아니다. 또한, 본 장치는 제1입력, 제2입력, 생성된 제1제스처 정보 및 생성된 제2제스처 정보를 저장할 수 있으며, 드론을 제어하는 단계(S450 또는 S570)는 저장된 정보를 기반으로 드론 제어를 수행하는 것일 수 있으 나, 이에 한정되는 것은 아니다. 예를 들어, 제1입력으로 제3드론에 대한 선택을 수신(S410 또는 S510)하고, 제2입력으로 제2인식 모드에 대한 선택을 수신(S420 또는 S540)하여, 제2제스처 정보를 기반으로 드론을 제어(S450 또는 S570)하는 중, 제2입력으 로 제1인식 모드에 대한 선택을 수신(S420 또는 S540)하면, 제1입력은 새로 수신하지 않아도, 이전의 제1입력을 저장하고 있기 때문에, 이전의 제1입력으로 선택된 제3드론을 제1제스처 정보를 기반으로 제어할 수 있으나, 이 에 한정되는 것은 아니다. 또 다른 예를 들어, 제1입력으로 제5드론에 대한 선택을 수신(S410 또는 S510)하고, 제2입력으로 제1인식 모드 에 대한 선택을 수신(S420 또는 S540)하여, 제1제스처 정보를 기반으로 드론을 제어(S450 또는 S570)하는 중, 제1입력으로 제8드론에 대한 선택을 수신(S410 또는 S510)하면, 제2입력을 새로 수신하지 않아도, 이전의 제2입 력을 저장하고 있기 때문에, 이전의 제2입력으로 선택된 제1인식 모드에 따라, 제1제스처 정보를 기반으로 새로 수신한 제2입력을 따라 제8드론을 제어할 수 있으나, 이에 한정되는 것은 아니다. 상술한 드론 제어 방법(400 및 500)에 따르면 본 장치는 간단한 제어로 복수의 드론 및 제어 모드를 선택 하여, 복수의 드론을 동시에 제어할 수 있다. 상술한 단계 S410 내지 S450 또는 S510 내지 S570은 본 장치의 제어부에서 수행될 수 있으나, 이에 한정되는 것은 아니다. 상술한 설명에서, 단계 S410 내지 S450 또는 S510 내지 S570은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시 예에 따른 드론 제어 방법(400 또는 500)은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로 그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가 능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의 해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2021-0149328", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다. 부호의 설명10: 드론 제어 시스템 100: 드론 제어 장치 110: 제1웨어러블 장치 111: 복수의 골무 120: 카메라 130: 제2웨어러블 장치 131: IMU 센서 140: 제어부 150: 입력 장치"}
{"patent_id": "10-2021-0149328", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 드론 제어 시스템의 개략적인 구성도이다. 도 2는 본원의 일 실시예에 따른 드론 제어 장치의 개략적인 구성도이다. 도 3는 본원의 일 실시예에 따른 드론 제어 장치의 제1데이터 및 제1제스처 정보를 나타내는 도면이다. 도 4는 본원의 일 실시예에 따른 드론 제어 장치의 제2데이터 및 제2제스처 정보를 나타내는 도면이다. 도 5은 본원의 일 실시예에 따른 드론 제어 방법에 대한 동작 흐름도이다. 도 6은 본원의 또 다른 일 실시예에 따른 드론 제어 방법에 대한 동작 흐름도이다."}
