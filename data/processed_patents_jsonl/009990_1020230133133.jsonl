{"patent_id": "10-2023-0133133", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0050285", "출원번호": "10-2023-0133133", "발명의 명칭": "공간 터치 기능을 수행하는 사용자 인터페이스 제공 장치 및 방법", "출원인": "주식회사 초이웍스", "발명자": "최승일"}}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방법으로서,가상 공간 내에서 사용자 인터페이스를 위한 실물 오브젝트를 인식하는 단계; IOT센서를 이용하여 사용자 인터페이스를 위한 실물 오브젝트의 모션을 감지하는 단계; 상기 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 가상 공간 내의 모션으로 동기화시키는 단계; 및비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하고 오브젝트 모션마다 대응되게상기 동기화된 가상 공간 내에서의 조작 신호로 반영하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 비접촉 대형 스크린 내의 모션으로 동기화시키는 단계; 및 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마다 대응되게상기 대형 스크린 공간 내에서의 조작 신호로 반영하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 동기화시키는 단계는, 기 정의된 설비 제어를 위한 가상 환경을 제공하고, 상기 조작 신호로 반영하는 단계는, 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마다 대응되게기 정의된 설비의 실제 조작 신호를 생성하여 설비 제어 장치로 전달하는, 방법."}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 조작 신호로 반영하는 단계는, 사용자가 인식하는 가상 공간 내에서 터치 대상 물체와 사용자 인터페이스를 위한 오브젝트 간의 상대적 거리를파악하고, 터치 대상 물체와 오브젝트 간 상대적 거리가 감소하면 터치 조작 신호로 인식하는, 방법."}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0050285-3-하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨터 장치로서,가상 공간 내에서 사용자 인터페이스를 위한 실물 오브젝트를 인식하는 오브젝트 인식부;IOT센서를 이용하여 사용자 인터페이스를 위한 실물 오브젝트의 모션을 감지하는 모션 감지부; 상기 모션 감지부에서 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 가상 공간 내의 모션으로 동기화시키는 동기화부; 및비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하고 오브젝트 모션마다 대응되게상기 동기화된 가상 공간 내에서의 조작 신호로 반영하는 조작신호 반영부;를 포함하는, 장치."}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 동기화부는, 상기 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 비접촉 대형 스크린 내의 모션으로 동기화시키고, 상기 조작 신호 반영부는, 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마다 대응되게상기 대형 스크린 공간 내에서의 조작 신호로 반영하는, 장치."}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항에 있어서, 상기 동기화부는, 기 정의된 설비 제어를 위한 가상 환경을 제공하고, 상기 조작 신호로 반영부는, 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마다 대응되게기 정의된 설비의 실제 조작 신호를 생성하여 설비 제어 장치로 전달하는, 장치."}
{"patent_id": "10-2023-0133133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 5 항에 있어서, 상기 조작신호 반영부는, 사용자가 인식하는 가상 공간 내에서 터치 대상 물체와 사용자 인터페이스를 위한 오브젝트 간의 상대적 거리를파악하고, 터치 대상 물체와 오브젝트 간 상대적 거리가 감소하면 터치 조작 신호로 인식하는, 장치."}
{"patent_id": "10-2023-0133133", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 공간 터치 기능을 수행하는 사용자 인터페이스 기술에 관한 것으로, 가상 공간 내에서 사용자 인터페 이스를 위한 실물 오브젝트를 인식하는 단계, IOT센서를 이용하여 사용자 인터페이스를 위한 실물 오브젝트의 모 션을 감지하는 단계, 상기 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 가상 공간 내의 모션으로 동기화시키는 단계 및 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하고 오브젝트 모션마다 대응되게 상기 동기화된 가상 공간 내에서의 조작 신호로 반영하는 단계를 포함하는, 방법에 의해 인공지능 비전 기술과 IOT센싱 기술을 이용하여 시공간 제약 없이 터치 가능한 사용자 인터페이스 장치 및 그 동작 방법을 제공할 수 있는 효과가 도출된다."}
{"patent_id": "10-2023-0133133", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 공간 터치 기능을 수행하는 사용자 인터페이스 기술에 관한 것이다."}
{"patent_id": "10-2023-0133133", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 비전 기술은 컴퓨터 비전(Computer Vision) 분야에서 인공지능 기술을 활용하여 시각 정보를 처리하고 해석하는 기술이다. 이는 사진, 비디오, 그래픽 이미지 등의 시각적 데이터를 이해하고 분석하는 데 사용된다. 인공지능 비전 기술은 머신 러닝 및 딥 러닝 기법을 기반으로 하며, 자율 주행 자동차, 의료 진단, 보안 시스템, 엔터테인먼트 산업, 로봇공학 등 다양한 분야에서 인공지능 비전 기술의 활용이 확대되고 있다. 한편 IOT 센싱 기술은 사물 인터넷 (Internet of Things, IOT) 응용 분야에서 센서를 사용하여 환경 데이터를 수집하고 모니터링하는 기술을 의미한다. IOT 센싱 기술은 다양한 센서와 통신 기술을 결합하여 물리적인 세계 의 정보를 디지털 데이터로 변환하고 전송하는 것을 중심으로 동작한다. IOT 센싱 기술은 다양한 센서를 사용하여 데이터를 수집하고, IOT 센서는 무선 통신 기술을 사용하여 데이터를 수집하고 전송할 수 있다. 또한 IOT 센싱 기술은 실시간 또는 거의 실시간으로 데이터를 수집하므로 응용 프로그램은 실제 시간 데이터를 기반으로 의사 결정을 내릴 수 있다. 또한 스마트 시티에서는 공공 안전, 교통 관리 및 에너지 효율을 향상시 키기 위해 센서 데이터를 활용할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2013-0129775 A"}
{"patent_id": "10-2023-0133133", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 이 같은 기술적 배경에서 도출된 것으로, 인공지능 비전 기술과 IOT센싱 기술을 이용하여 시공간 제 약 없이 터치 가능한 사용자 인터페이스 제공장치 및 그 동작 방법을 제공함에 그 목적이 있다."}
{"patent_id": "10-2023-0133133", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기의 과제를 달성하기 위한 본 발명은 다음과 같은 구성을 포함한다. 즉 본 발명의 일 실시예에 따른 사용자 인터페이스 제공 방법은 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방 법으로서, 가상 공간 내에서 사용자 인터페이스를 위한 실물 오브젝트를 인식하는 단계, IOT센서를 이용하여 사 용자 인터페이스를 위한 실물 오브젝트의 모션을 감지하는 단계, 상기 감지된 모션 정보에 기반하여 사용자 인 터페이스를 위한 오브젝트를 가상 공간 내의 모션으로 동기화시키는 단계 및 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하고 오브젝트 모션마다 대응되게 상기 동기화된 가상 공간 내에서의 조작 신호로 반영하는 단계를 포함한다. 한편, 일 실시예에 따른 사용자 인터페이스 제공 장치는 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세 서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨터 장치로서, 가상 공간 내에서 사용자 인터페이스를 위한 실물 오브젝트를 인식하는 오브젝트 인식부, IOT센서를 이용하여 사용자 인터페이스 를 위한 실물 오브젝트의 모션을 감지하는 모션 감지부, 상기 모션 감지부에서 감지된 모션 정보에 기반하여 사 용자 인터페이스를 위한 오브젝트를 가상 공간 내의 모션으로 동기화시키는 동기화부 및 비전 AI 기술을 이용하 여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하고 오브젝트 모션마다 대응되게 상기 동기화된 가상 공 간 내에서의 조작 신호로 반영하는 조작신호 반영부를 포함한다."}
{"patent_id": "10-2023-0133133", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면 인공지능 비전 기술과 IOT센싱 기술을 이용하여 시공간 제약 없이 터치 가능한 사용자 인터페 이스 장치 및 그 동작 방법을 제공할 수 있는 효과가 도출된다."}
{"patent_id": "10-2023-0133133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에서 사용되는 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려 는 의도가 아님을 유의해야 한다. 또한, 본 발명에서 사용되는 기술적 용어는 본 발명에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명한다. 본 발명의 실시예들에 따른 사용자 인터페이스 제공장치는 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있으며, 본 발명의 실시예들에 따른 사용자 인터페이스 제공 방법은 사용자 인터페이스 제공장치에 포함되는 적 어도 하나의 컴퓨터 장치를 통해 수행될 수 있다. 이때, 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴퓨터 프 로그램이 설치 및 구동될 수 있고, 컴퓨터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 실시예들에 따른 사용자 인터페이스 제공 방법을 수행할 수 있다. 상술한 컴퓨터 프로그램은 컴퓨터 장치와 결합되어 사용 자 인터페이스 제공 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 도 1 은 본 발명의 일 실시예에 따른 사용자 인터페이스 제공장치의 구성을 도시한 블록도이다. 일 실시예에 따른 사용자 인터페이스 제공장치는 신체모션의 크기 변화에 따라 가상공간 또는 가상공간 내 의 오브젝트를 터치하도록 인식하거나, 압력 센서를 이용하여 압력 크기 변화에 따라 가상 공간 내의 오브젝트 를 터치한 것으로 인식할 수 있다. 도 1 과 같이 일 실시예에 따른 사용자 인터페이스 제공장치는 통신 인터페이스, 메모리, 입출력 인터페이스 및 프로세서를 포함한다. 통신 인터페이스는 네트워크를 통해 사용자 인터페이스 제공장치가 다른 장치(일례로, 앞서 설명 한 저장 장치들)와 서로 통신하기 위한 기능을 제공할 수 있다. 일례로, 사용자 인터페이스 제공장치의 프 로세서가 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페이스의 제어에 따라 네트워크를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신호나 명령, 데이터, 파일 등이 네트워크를 거쳐 사용자 인터페이스 제공장치 의 통신 인터페이스를 통해 사용자 인터페이스 제공장치로 수신될 수 있다. 통신 인터페이스(11 0)를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 사용자 인터페이스 제공장치가 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. AI서버 및 IOT서버는 웹 서버, 데이터베이스 서버, 프록시 서버 등의 형태로 구현될 수 있다. 또한, AI 서버 및 IOT서버에는 네트워크 부하 분산 메커니즘, 내지 해당 AI서버 및 IOT서버가 인터넷 또 는 다른 네트워크상에서 동작할 수 있도록 하는 다양한 소프트웨어 중 하나 이상이 설치될 수 있으며, 이를 통 해 컴퓨터화된 시스템으로 구현될 수 있다. 또한, 네트워크는 http 네트워크일 수 있으며, 전용 회선(private line), 인트라넷 또는 임의의 다른 네트워크 일 수 있다. 나아가, 사용자 인터페이스 제공장치, AI서버 및 IOT서버 간의 연결은 데이터가 임의 의 해커 또는 다른 제3자에 의한 공격을 받지 않도록 보안 네트워크로 연결될 수 있다. 또한, AI서버 및 IOT서버는 복수의 데이터베이스 서버를 포함할 수 있으며, 이러한 데이터베이스 서버가 분산 데이터베이스 서버 아키텍처를 비롯한 임의의 유형의 네트워크 연결을 통해 AI서버 및 IOT서버와 별도로 연결되는 방 식으로 구현될 수 있다. AI 서버는 인공지능 (AI) 응용 프로그램 및 서비스를 구현하고 실행하는 서버 컴퓨터 또는 컴퓨팅 클러스터 를 포괄하도록 해석된다. 일 실시예에 있어서 AI 서버는 AI 모델의 훈련, 추론 (inference), 데이터 처리, 및 다른 AI 관련 작업을 수행하기 위한 하드웨어와 소프트웨어 인프라를 포함한다. AI 서버는 클라우드 환경에서 구축될 수도 있으며, 여러 사용자 및 응용 프로그램에서 공유되는 리소스를 제공하거나, 기업 내부에서 단독으로 운영되도록 구현될 수도 있다. 또한 AI 서버는 대규모 데이터 세트를 사용하여 AI 모델을 훈련하는 데 필요한 연산량과 자원을 제공하고, 딥 러닝 모델은 수천 개의 그래픽 처리 장치(GPU) 또는 텐서 처리 장치(TPU)와 같은 고성능 하드웨어를 사용하 여 훈련하도록 구현될 수 있다. 그리고 AI 모델을 사용하여 예측, 분류, 객체 감지 및 기타 작업을 수행하고, 실제 응용 프로그램 또는 서비스를 위해 결과를 반환할 수 있다. IOT 서버는 Internet of Things (IOT) 기기와 시스템의 데이터 수집, 관리, 분석, 제어 및 연결을 관리한 다. 구체적으로 다양한 IOT 디바이스로부터 생성되는 데이터를 수집하고 저장한다. 이때 생성되는 데이터는 센 서에서 수집되는 정보, 온도, 습도, 위치 정보, 센서 상태 및 기타 환경 데이터 등 다양한 형태의 데이터일 수 있다. 그리고 수집된 데이터를 처리하고 분석하여 유용한 정보와 인사이트를 생성한다. 예를 들어, IOT 서버는 데 이터 패턴, 이상 징후, 예측 모델, 효율적인 자원 사용 등을 분석할 수 있다. 또한 IOT 서버는 연결된 기기의 동작을 변경하거나 업데이트를 배포할수 있고, 연결된 기기를 원격으로 제 어하고 관리할 수도 있다. IOT 서버는 연결된 기기와 실시간 통신을 통해 데이터를 주고받을 수 있으며, 기기 간의 상호 작용과 협업 을 가능케 하고, 데이터 보안을 강화하고 인증 및 암호화를 제공하여 민감한 정보의 유출을 방지할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량기록장치는 메모리와는 구분되는 별도의 영구 저장 장치로 서 사용자 인터페이스 제공장치에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요 소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 메모리로 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카 드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터 에서 판독 가능한 기록매체가 아닌 통신 인터페이스를 통해 메모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크를 통해 수신되는 파일들에 의해 설치되는 컴퓨터 프로그램에 기반하여 사용자 인터페이스 제공장치의 메모리에 로딩될 수 있다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함할 수 있 다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와 의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 사용자 인터페이스 제공장치와 하나의 장치로 구성 될 수도 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도 록 구성될 수 있다. 보다 상세하게 프로세서는 오브젝트 인식부, 모션 감지부, 동기화부 및 조작 신호 반영 부를 포함한다. 오브젝트 인식부는 가상 공간 내에서 사용자 인터페이스를 위한 실물 오브젝트를 인식한다. 일 실시예에 있어서 사용자 인터페이스를 위한 실물 오브젝트라함은 사용자의 손일 수도 있고, 펜이나 마우스등 의 물체일 수도 있다. 오브젝트 인식부는 초기화 과정에서 카메라를 통해 이미지로 실물 오브젝트 촬영 영상을 먼저 입력받고, AI 서버 및 IOT 서버와 연동하여 사용자 인터페이스를 위한 실물 오브젝트 형태 정보를 지정받아서 인식할 수 있다. 이에 따라 다른 물체나 다른 신체부위의 움직임을 조작신호로 잘못 인식하는 오류를 줄일 수 있다. 촬영 영상에 기반한 형태로 인식하거나, 바코드로 사용자 인터페이스를 위한 실물 오브젝트를 인식 및 지정하도 록 구현될 수도 있다. 일예로 오브젝트 인식부는 사용자의 손크기나 손 모양을 더 인지하여 사용자의 손이나 손가락 움직임에 의한 조작신호만 입력받도록 구현될 수도 있다. 예를들어 오브젝트 인식부는 Convolutional Neural Network (CNN)와 같은 이미지 분류나 객체 감지를 수행할 수 있는 딥러닝 모델을 이용하여 손가락을 구분하는 클래스를 정의할 수 있다. 그리고 학습된 딥러닝 모델을 이용하여 손가락을 감지하여 구분할 수 있다. 모션 감지부는 IOT센서를 이용하여 사용자 인터페이스를 위한 실물 오브젝트 모션을 감지한다. 모션 감지 부는 IOT 서버로부터 수신되는 IOT 센서 감지 데이터에 기반하여 실물 오브젝트의 모션을 감지할 수 있다. IOT 센싱 기술은 환경 데이터 수집을 위해 다양한 종류의 센서를 사용하는데 공간 터치 기술에서는 이러한 센서 를 사용자와 상호작용 하는데 활용할 수 있다. 예를 들어 사용자가 공간 내에서 손가락으로 물체를 가리키면, 센서를 통해 해당 물체의 위치와 상태를 파악할 수 있다. 또한 손가락의 위치나 손가락 형태를 파악할 수도 있 다. 순간적인 손가락의 이동 및 이동 방향을 감지하는 것도 가능하다. 예를 들어 IOT 서버는 열을 방출하는 물체의 움직임을 감지하는 PIR (Passive Infrared) 센서로부터 체온을 방출하는 사용자의 손이나 팔의 움직임을 감지하고 열의 변화에 따른 모션 감지를 수행할 수 있다. 또한, 오브 젝트의 거리의 변화를 초음파 파울스를 통해 감지하여 모션을 감지하거나, 공간 내의 물체와의 거리를 정밀하게 측정하는 레이저 레인지 파인더, 인체 감지 센서등을 통해 모션을 감지할 수 있다. 뿐만 아니라 모션 감지부는 AI 서버와 연동하여 카메라를 통해 촬영된 영상에 기반한 실물 오브젝트 의 모션을 감지하도록 구현될 수도 있다. 카메라로 촬영된 영상에 기반하여 사용자 인터페이스 객체의 모션을 분석하여 이동 방향 및 이동 거리 등의 정보를 파악할 수 있다. 이동 거리 및 방향을 파악함으로써 가상공간 내 의 물체에 단순히 터치만 하는 것과 터치 후 물리적으로 누르거나 미는 행위를 보다 세밀하게 인식할 수 있는 효과가 있다. 동기화부는 모션 감지부에서 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 가상 공간 내의 모션으로 동기화시킨다. 일 양상에 있어서, 동기화부는 모션 감지부에서 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 비접촉 대형 스크린 내의 모션으로 동기화시킬 수도 있다. 동기화부는 물리 시뮬레이션 엔진을 통해 물리적인 움직임 및 상호 작용을 시뮬레이션 할 수 있다. 이때 시뮬레이션은 실제 물리 법칙을 따 르며 사용자의 움직임에 반응한다. 동기화부는 사용자 움직임 데이터를 실시간 처리하여 가상환경 내의 렌더링 엔진으로 전달하고 이에 따라 가상 환경에서의 뷰포인트와 물체 위치를 업데이트할 수 있다. 동기화부는 사용자의 움직임 데이터와 물리 시뮬레이션을 렌더링 엔진에 동기화시켜서 가상 환경 내에 실 시간으로 반영할 수 있다. 일 실시예에 있어서 동기화부는 가상 공간 또는 대형 스크린, 홀로그램상에 표 시되는 버튼, 키보드, 물체에 사용자 인터페이스를 위한 객체 움직임에 의해 인식되는 터치 및 키 입력 동작을 동기화시킬 수 있다. 조작 신호 반영부는 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하고 오 브젝트 모션마다 대응되게 동기화된 가상 공간 내에서의 조작 신호로 반영한다. 조작 신호 반영부는 비전 AI 기술을 이용하여 카메라를 통해 사용자의 손 동작을 감지하고 해석하여 터치, 스와이프, 확대/축소 등의 제 스처를 감지하도록 구현될 수 있다. 조작 신호 반영부는 대형 스크린, 홀로그램, 가상 환경의 버튼, 키보드, 가상 공간 또는 대형 스크린에 표시되는 물체등에 대한 조작 신호를 생성 및 제공할 수 있다. 즉 비전 AI 기술을 반영하여 손모양이나 손가락 움직임을 인지하여 조작 신호로 반영하거나, IOT 센서를 이용하여 감지되는 움직임이나 상대적 거리에 기반하여 조작 신호로 반영할 수 있다. 인공지능 비전 기술과 IOT 센싱 기술을 이용하여 시공간의 제약이 없는 제어 신호 를 생성 및 제공할 수 있는 효과가 도출된다. 비전 AI 기술은 기계 학습 및 딥 러닝 알고리즘을 기반으로 하며 컴퓨터 비전(Computer Vision) 분야에서 인공 지능 기술을 활용하여 이미지 데이터를 이해하고 해석하는 기술로 사진, 비디오, 그래픽 이미지 등의 시각적 데 이터를 이해하고 분석할 수 있다. 예를들어 카메라나 광학 센서를 통해 수집된 비디오 스트림 또는 이미지 데이 터를 분석 및 해석할 수 있다. 비전 AI는 정적 이미지나 동영상 데이터를 분석하고 이해하고, 물체, 얼굴, 텍스트, 장면 등을 탐지, 분류 및 추적할 수 있다. 또한 미지 또는 비디오에서 특정 물체를 탐지하여 객체를 탐지하고 그 위치를 추적할 수도 있 다. 일 양상에 있어서, 조작 신호 반영부는 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마다 대응되게 상기 대형 스크린 공간 내에서의 조작 신호로 반영한다. 추가적인 양상에 있어서, 동기화부는 기 정의된 설비 제어를 위한 가상 환경을 제공하고, 조작 신호 반영 부는, 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마 다 대응되게 기 정의된 설비의 실제 조작 신호를 생성하여 설비 제어 장치로 전달한다. 이때 동기화부는 다수의 설비 장치를 정의하도록 구현될 수 있으며, 조작 신호 반영부는 다수의 설 비 장치 중 하나를 선택하면 해당 설비 장치에 대한 조작 신호로 식별하여 식별된 설비 장치로 조작 신호를 전 달할 수 있다. 일 양상에 있어서, 조작 신호 반영부는 사용자가 인식하는 가상 공간 내에서 터치 대상 물체와 사용자 인 터페이스를 위한 오브젝트 간의 상대적 거리를 파악하고, 터치 대상 물체와 오브젝트 간 상대적 거리가 감소하 면 터치 조작 신호로 인식한다. 조작 신호 반영부는 먼저 손가락이나 펜등의 초기 위치를 인식받고 초기 위치에 기반하여 입력 대상을 인 식하도록 구현될 수 있다. 예를들어 가상공간 또는 대형 스크린 상에서 비접촉식 키보드 툴을 제공하는 경우에, 키보드 실행 초기에 엄지손가락의 위치를 기준으로 스페이스 키 위치로 인식하고, 해당 위치를 기준으로 상대적 거리에 따라 키보드 또는 다수 버튼들 중 어떤 키를 터치하는지를 인식하도록 구현될 수 있다. 또는 초기 설정단계에서 사용자로부터 가상 공간 또는 대형 화면에 표시되는 키보드의 가장자리에 있는 적어도 두개의 키 입력을 받아 키인식을 위한 초기화 동작을 수행하여, 입력 위치를 인식하도록 구현될 수 있다. 그리고 사용자가 터치한 손가락 위치와 가상 공간 또는 대형 스크린 상에 표시된 키보드의 키 위치를 보다 정확 히 파악할 수 있다. 파악된 정보에 기반하여 상대적 터치 위치를 인식하고, 어떤 키를 터치하는지에 대한 정보 를 인식하도록 구현될 수 있다. 이에 따라 동일한 가상 공간 내에서 모션에 기반한 터치 인식 기술을 적용하더라도 상대적으로 사용자에 따라 초기 설정이 가능하여 정확도를 향상시킬 수 있다. 예를 들어 앉은 자세로 가상 공간 내의 키보드를 입력하는 경우와, 누운 자세로 가상 공간 내의 키보드를 입력 하는 경우에도 사용자 신체의 적어도 일부를 감지하여 동기화시키고 보다 정확히 어떤 키나 버튼을 터치하는지 정확히 파악할 수 있다. 일 실시예에 있어서, 사용자 인터페이스 제공 장치는 인공지능 비전 기술과 IOT센싱 기술을 이용해서 시공 간 제약없이 터치가 가능한 사용자 인터페이스를 제공할 수 있다. 즉, 오프라인 공간을 디지털화하여 키오스크, 가상 키보드, 게임, 퍼스널 모빌리티 및 스마트 모빌리티 조종, 스마트 칠판에 적용 가능하다. 뿐만 아니라 공 장, 물류창고, 건설 현장 등 공간이 넓고 장비가 많아 직접 이동하여 일일이 설비 제어가 어려운 공간 상에서 통합 제어 기술에 적용 할 수도 있다. 인공지능 비전 기술과 IOT센싱 기술을 결합 적용하여 사용자 제스처 인식 및 제어 정밀도를 향상시킬 수 있다. 또한 일 실시예에 따른 사용자 인터페이스 제공 장치가 제공하는 공간 터치 기술을 적용한 사용자 인터페이 스는 조명, 난방, 냉방, 보안 시스템 등 스마트 홈 및 스마트 빌딩의 다양한 시스템을 제어하는 데 사용될 수 있다. 사용자가 공간 내에서 제스처를 사용하여 이러한 시스템을 편리하게 제어할 수 있다. 또한 박물관, 전시회, 교육 기관에서 작품, 전시물 또는 교육 콘텐츠와 상호 작용할 수 있는 환경을 제공하기 위해 공간 터치 기술을 적용할 수 있으며, 의료 분야에서는 환자 모니터링 및 의료 장비 조작을 위해 손동작 또 는 제스처를 사용하여 공간 터치 기술을 적용할 수도 있다. 즉 인공지능 비전 기술과 IOT 센싱 기술의 결합을 통해 사용자와 환경 간의 상호 작용을 더 직관적이고 효율적으로 만들어줄 수 있다.도 2 내지 도 5 는 일 실시예에 따른 사용자 인터페이스 제공장치에 의한 사용자 인터페이스 구동 실시예를 설 명하기 위한 예시도이다. 도 2 에서 AI 서버가 손이나 발, 펜 등의 사용자 인터페이스를 위한 오브젝트의 크기가 작아지거나, 손가락 중 하나가 앞으로 구부러지는 경우에는 가상 공간 또는 대형 스크린에 표시된 키 또는 버튼을 터치하거나 누른 것으로 인식하고 해당 조작 신호를 반영할 수 있다. 반대로 손이나 발, 펜 등이 사용자 인터페이스를 위한 오브 젝트 크기가 작아지거나 구부렸던 손가락이 펴지는 경우에는 눌렀던 가상 공간 또는 대형 스크린의 키 또는 버 튼을 해제하였다고 판단할 수 있다. 도 3 과 같이 , AI 서버는 특정 자세 또는 동작을 인식하여 가상 공간 내의 버튼이나 키를 터치 또는 입력 해다고 인식하도록 구현될 수 있다. 예를 들어 도 3 에서와 같이 손으로 V를 표시하거나 손을 좌우로 흔들거나 주먹을 쥐었다가 펼치는 것으로 터치 입력 동작을 인식할 수 있다. 즉 거리에 상관없이 가상 공간 내에서 터치 조작이 가능하다. 도 4 와 같이 AI 서버가 기 설정된 형태 또는 바코드 인식된 특정 물체의 움직임 및 각도를 인식하여 가상 공간 또는 대형 스크린에 표시된 키보드 또는 버튼을 선택 및 입력하는 것으로 인식하도록 구현되는 것도 가능 하다. 예를 들어 자체 제작한 막대를 AI 서버가 학습하여 인식하고, 좌우로 흔들면 가상 공간 또는 대형 스크린에 표시된 키보드 또는 버튼을 선택 및 입력하는 것으로 인식하도록 구현되는 것도 가능하다. 또한 도 5 와 같이 IOT 센서가 화면과 손이나 발, 특정 물체등의 거리를 측정하여 상대적으로 화면과 가까워 지 는 경우 또는 압력을 측정하여 압력이 갑자기 높아지는 경우에 가상 공간 또는 대형 스크린에 표시된 키보드 또 는 버튼을 선택 및 입력하는 것으로 인식하도록 구현되는 것도 가능하다. 반대로 IOT 센서가 화면과 손이나 발, 특정 물체 등의 거리를 측정하여 상대적으로 화면으로부터 멀어지는 경우 또는 압력을 측정하여 압력이 갑자기 낮아지는 경우에 가상 공간 또는 대형 스크린에 표시된 키보드 또는 버튼 을 선택 및 입력을 해제하는 것으로 인식하도록 구현되는 것도 가능하다. 이때 화면과 손이나 발, 특정 물체등의 거리를 측정하는 것은 초음파, 적외선, 음파, 레이저, 라이드등의 센서 를 이용하여 구현될 수 있다. 그러나 이에 한정되는 것은 아니고 다양한 변형예들을 포괄하도록 해석된다. 도 6 은 본 발명의 일 실시예에 따른 사용자 인터페이스 제공방법을 설명하기 위한 흐름도이다. 일 실시예에 따른 사용자 인터페이스 제공 방법은 가상 공간 내에서 사용자 인터페이스를 위한 실물 오브젝트를 인식한다(S600). 그리고 IOT센서를 이용하여 사용자 인터페이스를 위한 실물 오브젝트의 모션을 감지한다(S610). 이후에 감지된 모션 정보에 기반하여 사용자 인터페이스를 위한 오브젝트를 가상 공간 내의 모션으로 동기화시 킨다(S620). 그리고 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하고(S630), 오브젝트 모션 마다 대응되게 상기 동기화된 가상 공간 내에서의 조작 신호로 반영한다(S640). 일양상에 있어서, 사용자가 인식하는 가상 공간 내에서 터치 대상 물체와 사용자 인터페이스를 위한 오브젝트 간의 상대적 거리를 파악하고, 터치 대상 물체와 오브젝트 간 상대적 거리가 감소하면 터치 조작 신호로 인식한 다. 일 양상에 있어서, 일 실시예에 따른 사용자 인터페이스 제공 방법은 감지된 모션 정보에 기반하여 사용자 인터 페이스를 위한 오브젝트를 비접촉 대형 스크린 내의 모션으로 동기화시킬 수도 있다(S650). 그리고 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마다 대 응되게 상기 대형 스크린 공간 내에서의 조작 신호로 반영할 수 있다(S660). 본 발명의 추가적인 양상에 있어서, 동기화시키는 단계는 기 정의된 설비 제어를 위한 가상 환경을 제공한다. 그리고 조작 신호로 반영하는 단계는, 비전 AI 기술을 이용하여 사용자 인터페이스를 위한 오브젝트의 모션을 인식하여 오브젝트 모션마다 대응되게 기 정의된 설비의 실제 조작 신호를 생성하여 설비 제어 장치로 전달한다. 전술한 방법은 애플리케이션으로 구현되거나 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어 의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프 로그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거니와 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD 와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서는 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구범위에 기 재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있 음을 이해할 수 있을 것이다."}
{"patent_id": "10-2023-0133133", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 은 본 발명의 일 실시예에 따른 사용자 인터페이스 제공장치의 구성을 도시한 블록도이다. 도 2 내지 5 는 일 실시예에 따른 사용자 인터페이스 제공장치에 의한 사용자 인터페이스 구동 실시예를 설명하 기 위한 예시도이다. 도 6 은 본 발명의 일 실시예에 따른 사용자 인터페이스 제공방법을 설명하기 위한 흐름도이다."}
