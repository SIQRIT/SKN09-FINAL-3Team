{"patent_id": "10-2021-0067778", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0159762", "출원번호": "10-2021-0067778", "발명의 명칭": "유전 알고리즘을 이용한 인공 신경망 모델 구축방법 및 이를 이용한 변수 최적화 방법", "출원인": "인하대학교 산학협력단", "발명자": "황성원"}}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계;상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단계; 및상기 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계;를 포함하는 유전 알고리즘을 이용한 인공 신경망 모델 구축방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수로 사용하여, 유전 알고리즘의변수 최적화에 사용하는 단계를 더 포함하는 것을 특징으로 하는 유전 알고리즘을 이용한 인공 신경망 모델 구축방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상인 것을특징으로 하는 유전 알고리즘을 이용한 인공 신경망 모델 구축방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계;상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단계;상기 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계; 및상기 구축된 인공 신경망 모델을 이용하여 변수값을 최적화하는 단계;를 포함하는 변수 최적화 방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수로 사용하여, 유전 알고리즘의변수 최적화에 사용하는 단계를 더 포함하는 것을 특징으로 하는 변수 최적화 방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상인 것을특징으로 하는 변수 최적화 방법.공개특허 10-2022-0159762-3-청구항 7 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 공정 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계;상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단계; 및상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계;를 포함하는 유전 알고리즘을 이용한 화학 공정 모델링을 위한 인공 신경망 모델 구축방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수로 사용하여, 유전 알고리즘의변수 최적화에 사용하는 단계를 더 포함하는 것을 특징으로 하는 유전 알고리즘을 이용한 화학 공정 모델링을위한 인공 신경망 모델 구축방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상인 것을특징으로 하는 유전 알고리즘을 이용한 화학 공정 모델링을 위한 인공 신경망 모델 구축방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계;상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단계;상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 및상기 구축된 인공 신경망 모델을 이용하여 화학 공정의 변수값을 최적화하는 단계;를 포함하는 화학 공정 변수 최적화 방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수로 사용하여, 유전 알고리즘의 변수 최적화에 사용하는 단계를 더 포함하는 것을 특징으로 하는 화학 공정 변수 최적화 방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상인 것을 특징으로 하는 화학 공정 변수 최적화 방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세공개특허 10-2022-0159762-4-트의 생성단계;상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단계;상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 및상기 구축된 인공 신경망 모델에 변수값을 도입하여 이에 따른 결과 데이터를 도출하는 단계;를 포함하는 화학 공정 변수에 따른 결과 데이터 예측방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수로 사용하여, 유전 알고리즘의 변수 최적화에 사용하는 단계를 더 포함하는 것을 특징으로 하는 화학 공정 변수에 따른 결과 데이터 예측방법."}
{"patent_id": "10-2021-0067778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상인 것을 특징으로 하는 화학 공정 변수에 따른 결과 데이터 예측방법."}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 목적은 유전 알고리즘을 이용한 인공 신경망 모델 구축방법을 제공하는데 있다. 이를 위하여 본 발 명은 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 및 상기 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계;를 포함하는 유전 알고리즘을 이용한 인공 신경망 모델 구축방법을 제공한다. 본 발명에 따르면, 학습 데이터 세트를 이용한 딥러닝을 통하 여 변수값과 결과값 사이의 상관관계를 도출하기 위한 인공 신경망을 구축함에 있어서, 그 정확성과 적합성을 결 정하는 다양한 하이퍼파라미터를 짧은 시간에 최적의 조합을 도출할 수 있는 장점이 있고, 이를 특히 화학 공정 에 적용하는 경우, 짧은 시간에 화학 공정을 모델링하고, 최적값을 도출할 수 있는 효과가 있다."}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 유전 알고리즘을 이용한 인공 신경망 모델 구축방법 및 이를 이용한 변수 최적화 방법, 나아가, 유전 알고리즘을 이용한 화학 공정 모델링을 위한 인공신경망 모델 구축방법 및 이를 이용한 화학 공정 변수 최적화 방법에 관한 것이다. 또한, 본 발명은 더 나아가 화학 공정 변수에 따른 결과 데이터 예측방법에 관한 것이다."}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 4차 산업의 발전에 따라 인공 신경망(Artificial neural network, ANN) 과 같은 최적화 알고리즘이 화학 공정 변수 간의 관계를 도출하고, 나아가 변수 최적화에 널리 적용되고 있다. 이러한 인공 신경망과 최적화 알고리즘의 결합은 실험 단계에서부터 실제 플랜트 운영 데이터까지 널리 적용되고 있다. 한편, 이와 같은 인공신경망은 높은 계산 부담을 갖는 시뮬레이션을 반복 실행할 필요성을 대체하고 여러 프로 세스를 최적화하기 위하여 채택되고 있다. 많은 화학 공학 응용분야에서, 산업 데이터를 사용하여 프로세스 출력을 예측하고, 복잡한 프로세스 시뮬레이션과 관련된 계산 비용을 줄이고, 또한 그 프로세스의 제어 및 최적 화를 위해 ANN 모델을 채택하였다. ANN 기반의 모델은 시스템의 효율성을 손상시키지 않으면서, 계산 비용과 시 간을 줄이는데 바람직하다. 예를 들어, 대한민국 공개특허 제10-2007-0118245호는 제품설계 방법 및 시스템을 개시하고 있으며 구체적으로 는 제품과 연관된 하나 이상의 입력 변수 및 하나 이상의 출력 파라미터에 관련된 데이터 기록들을 획득하는 단 계; 상기 하나 이상의 입력 변수로부터 하나 이상의 입력 파라미터를 선택하는 단계; 상기 데이터 기록들에 기 초한 상기 하나 이상의 입력 파라미터와 상기 하나 이상의 출력 파라미터 사이의 상관관계들을 나타내는 계산 모델을 생성하는 단계; 상기 제품에 대한 적합 상태(compliance state)를 표현하는 제약 조건들의 세트를 상기계산 모델에 제공하는 단계; 및 상기 계산 모델을 사용하여, 상기 제품에 대한 설계를 표현하는 상기 하나 이상 의 입력 파라미터 및 상기 하나 이상의 출력 파라미터에 대한 통계적 분포들을 상기 제약 조건들의 세트에 기초 하여 생성하는 단계를 포함하는 제품 설계 방법을 개시하고 있다. 그러나, 해당 기술에서는 입력 파라미터들 의 원하는 분포 탐색을 위해 유전 알고리즘을 사용하고 있을 뿐, 인공 신경망 구축을 위하여 적절한 하이퍼파라 미터 조합을 도출하기 위하여 유전 알고리즘을 사용하는 아이디어는 개시하고 있지 않다. 또한, 대한민국 공개특허 제10-2019-0105429호는 독성 가스 릴리스 모델링 장치 및 모델링 방법에 대하여 개시 하고 있으며, 구체적으로는 독성 가스 분산 데이터를 변환하는 변환 모듈; 및 상기 변환 모듈에 연결되어 상기 변환된 데이터를 일정 변수로 매핑하여 예측 모델을 생성하는 생성 모듈을 포함하는 것을 특징으로 하는 독성 가스 릴리스 모델링 장치를 개시하고 있다. 보다 구체적으로 상기 문헌은 독성 가스의 거동을 전산유체역학으 로 시뮬레이션한 데이터를 이용하여 신경망 예측 모델을 구축하는 내용을 개시하고 있으나, 인공 신경망 모델을 구축하기 위한 하이퍼파라미터 도출을 위하여 유전 알고리즘을 사용하는 아이디어는 개시하고 있지 않다. 이에 본 발명의 발명자들은 신뢰성이 높은 인공신경망 모델 구축을 위한 적절한 하이퍼파라미터 도출을 위하여 유전 알고리즘 최적화 방법을 적용하는 것을 연구하여 본 발명을 도출하게 되었다. <선행기술문헌> 대한민국 공개특허 제10-2007-0118245호 대한민국 공개특허 제10-2019-0105429호"}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 유전 알고리즘을 이용한 인공 신경망 모델 구축방법을 제공하는데 있다. 본 발명의 다른 목 적은 구축된 인공 신경망 모델을 이용하여 변수를 최적화하는 방법을 제공하는데 있다. 본 발명의 또 다른 목 적은 유전 알고리즘을 이용한 화학 공정 모델링을 위한 인공 신경망 모델 구축방법을 제공하는데 있다. 본 발 명의 또 다른 목적은 구축된 인공 신경망 모델을 이용하여 화학 공정 변수를 최적화하는 방법을 제공하는데 있 다. 본 발명의 또 다른 목적은 구축된 인공 신경망 모델을 이용하여 화학공정 변수에 따른 결과 데이터 예측 방법을 제공하는데 있다."}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여 본 발명은 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 및 상기 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계; 를 포함하는 유전 알고리즘을 이용한 인공 신경망 모델 구축방법을 제공한다. 또한, 본 발명은 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 상기 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계; 및 상기 구축된 인공 신경망 모델을 이용하여 변수값을 최적화하는 단계; 를 포함하는 변수 최적화 방법을 제공한다. 또한, 본 발명은 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 공정 변수값에 따른 결과 데이터를 생성하는 학습 데이 터 세트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 및 상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 를 포함하는 유전 알고리즘을 이용한 화학 공정 모델링을 위한 인공 신경망 모델 구축방법을 제공한다. 또한, 본 발명은 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세 트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 및 상기 구축된 인공 신경망 모델을 이용하여 화학 공정의 변수값을 최적화하는 단계; 를 포함하는 화학 공정 변수 최적화 방법을 제공한다. 또한, 본 발명은 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세 트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 및 상기 구축된 인공 신경망 모델에 변수값을 도입하여 이에 따른 결과 데이터를 도출하는 단계; 를 포함하는 화학 공정 변수에 따른 결과 데이터 예측방법을 제공한다."}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 학습 데이터 세트를 이용한 딥러닝을 통하여 변수값과 결과값 사이의 상관관계를 도출하기 위한 인공 신경망을 구축함에 있어서, 그 정확성과 적합성을 결정하는 다양한 하이퍼파라미터를 짧은 시간에 최 적의 조합을 도출할 수 있는 장점이 있고, 이를 특히 화학 공정에 적용하는 경우, 짧은 시간에 화학 공정을 모 델링하고, 최적값을 도출할 수 있는 효과가 있다."}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 여러 변경을 가할 수 있으며 이에 따라 다양한 실시예가 나올 수 있는 바, 특정 실시예를 하단에 제 시하고 상세하게 설명하고자 한다."}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한 특별히 정의가 되지 않은 본 명세서의 모든 용어들은 본 발명이 속하는 기술분야의 통상적인 지식을 가진 자 모두에게 이해가 가능한 의미로 사용할 수 있을 것이다. 그러나 이는 본 발명은 하단에 기술될 특정한 실시예에만 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범 위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 따라서 본 명세서에 기재된 실시예와 다른 균등물과 변형 예들이 있을 수 있으며, 본 명세서에서 제시하는 실시 예는 가장 바람직한 실시예 일 뿐이다. 본 발명에서 '인풋'과 '입력', '아웃풋'과 '출력'은 각각 동일한 의미로 사용되었다. 이하, 본 발명을 상세히 설명한다. 본 발명은 인공 신경망 모델의 구축방법을 제공하고, 구체적으로는 인공 신경망 모델의 구조와 정확성 및 학습 과정을 결정하는 주요 변수인 하이퍼파라미터의 조합을 도출하기 위하여 유전 알고리즘(genetic algorithm, G A)을 사용하는 방법을 제공한다. 보다 구체적으로 본 발명은 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 및 상기 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계; 를 포함하는 유전 알고리즘을 이용한 인공 신경망 모델 구축방법을 제공한다. 이하 본 발명의 방법을 각 단계별로 상세히 설명한다. 본 발명의 방법은 인공 신경망이 학습을 하기 위한 학습 데이터 세트를 생성하는 단계를 포함하며, 이는 예를 들어 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하여 그 결과로부터 학습 데이터 세트를 생성하는 단계이다. 이하의 단계에서 인공신경망은 상기 학습 데이터 세트를 학습하여 일정 기준을 만 족하는 하이퍼파라미터 조합을 찾게 되고, 기준을 만족하는 최적의 조합이 발견되면, 이를 이용하여 인공 신경 망 모델이 구축되게 된다. 본 발명의 방법은 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단계를 포함한다. 입력값 및 출력값, 또는 변수값 및 결과 데이터 간의 관계가 비선형적이고, 복잡하며, 또한 명시적이지 않아 수학적인 식을 통하여 모델링이 가능하지 않은 경우, 인공신경 망을 대체 모델로 사용하면 새로운 데이터에 대해서도 쉽게 그 결과값을 예측할 수 있게 된다. 이러한 인공 신경망의 정확성과 적합성을 결정하는 다양한 하이퍼파라미터는 기존에는 시행오차법을 통하여 결정하였지만, 이는 사용자의 배경지식을 요구하고, 상당한 시간이 소요되는 문제점이 있었고, 이에 본 발명의 방법은 기존의 시행오차법이 아니라 유전 알고리즘이라는 최적화 알고리즘을 사용하여 높은 정확도를 보이는 하이퍼파라미터 조합을 도출하는 단계를 포함한다. 유전 알고리즘은 최적화 알고리즘의 하나로, 지역 최적해(local solution) 대신 전역 최적해(global solution) 을 제공할 수 있다는 장점으로 인해 다양하게 응용되고 있다. 알고리즘은 미리 정의된 입력치의 최대 및 최소 범위 내에서 입력치들의 무작위 조합인 유전자(gene)로 구성된 초기 모집단(initial population)을 생성한다. 이어서, 현재 모집단 안의 각 개체들의 적합도(fitness function)을 계산하고, 다음 세대에서 새로운 모집단을 구성하기 위해 적합도가 높은 개체들을 선택한다. 이때, 일반적으로 적합도가 좋을수록 후손을 남길 확률이 높아지고, 나쁠수록 확률이 낮아지는 적자 생존의 법칙이 적용된다. 선택된 두 개체로부터 교차점을 무작위로 선택하여, 그 교차점을 기준으로 교차 연산(crossover)을 적용하고, 지역 최적화가 되는 것을 방지하기 위하여 각각의 개체에서 무작위로 돌연변이(mutation)를 시킨다. 이러한 유전 알고리즘의 주요 변수로는 모집단의 크 기(population size), 세대의 수(number of generation), 부모-자식 비율(parent-to-children ratio), 변이 확 률(mutation probability), 교차 확률(crossover probability), 선택방법(selection methodology) 등이 있다. 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단계를 보다 구체적으로 설명하면, 우선 생성된 학습 데이터 세트는 정의된 인풋 컬럼(input column)과 아웃풋 컬럼 (output column)에 따라 판다스(Pandas) 라이브러리를 사용하여 인풋 데이터와 아웃풋 데이터로 분류된다. 분 류된 데이터는 이어 -1과 1 사이로 정규화되면서 예를 들어 8:1:1의 비율로 훈련, 테스트, 검증 데이터로 분할 된다. 이어서, 훈련과 검증 데이터는 대체 모델을 학습하기 위하여 전달된다. 이때 인공신경망을 구성하는 하이퍼파라미터들은 유전 알고리즘을 통해 무작위 조합이 생성된다. 생성된 무작위 조합의 정보가 인공신경망 을 구축하는데 적용되면, 이를 기반으로 구축된 인공신경망이 입력된 데이터에 대해 학습을 진행한다. 학습이 완료되면 예측값과 실제값의 오차를 계산하여 정확도를 평가하고, 높은 정확도를 보이는 하이퍼파라미터 조합은 유전 알고리즘 내에서 다음 세대로 전달되어, 교차 및 변이를 거치게 된다. 이때 무작위 조합을 형성하는 하 이퍼파라미터는 에폭 수, 뉴런의 수, 활성화 함수의 수, 손실 함수의 종류, 학습률, 옵티마이저(optimizer)일 수 있다. 각 세대에서는 이러한 인공신경망을 구성하는 하이퍼파라미터들의 무작위 조합을 갖는다. 적합도 는 생성된 인공신경망 모델로부터 얻은 예측값과 실제값의 차이를 기반으로 계산된다. 예를 들어 99% 등과 같 이 정해진 정확도에 도달할 때까지 계산이 반복된다. 만약 첫번째 모집단에서 이를 만족하지 못하면 계속 계 산이 진행된다. 다음 세대에서 더 나은 모집단을 생성하기 위해서, 이전 세대의 일부가 선택되어, 높은 적합 도 값을 가지는 해를 유지하고, 동시에 낮은 적합도를 가지는 해를 선택지에서 제거하게 한다. 한 세대에서 하이퍼파라미터의 조합들은 적합도 값(모델 정확도)이 높은 순서대로 정렬되어 낮은 정확도를 보이는 하이퍼파 라미터 조합은 다음 세대로 넘어가지 못하고 제거된다. 또한, 두가지 조합을 교차하여 새로운 조합을 만들어 서(자손의 생성) 다음 새대로 전달한다. 생물학적인 돌연변이와 유사하게, 변이 확률에 따라 에폭 수와 뉴런 의 수와 같은 하이퍼파라미터의 수는 세대의 다양성을 유지시키기 위해 매 세대에서 변이된다. 새롭게 생성된모집단에 대해 다시 적합도가 계산되며, 일정 기준(stopping criteria)을 만족하는 하이퍼파라미터 조합을 찾을 때까지 계산이 반복된다. 만족하는 조합을 발견하면 해당 인공신경망의 가중치와 편향 등 정보를 포함하는 최 적 모델이 작업 공간에 자동으로 저장되며, 이는 이후 추가적인 데이터에 대한 예측 및 변수의 최적화에 사용될 수 있다. 본 발명은 상기와 같이 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출한 후, 도출된 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계를 포함한다. 인공지능은 인간의 지능을 모방하여 사람이 하는 것과 같이 복잡한 일을 하게 하는 기계를 만드는 것으로, 이를 구현하는 방법을 기계학습 또는 머신러닝이라고 한다. 머신러닝은 컴퓨터가 데이터 간의 숨겨진 경향 또는 관 계를 발견할 수 있도록 하여 복잡한 문제를 풀게 하는 알고리즘을 말한다. 머신러닝은 지도학습, 비지도학습, 딥러닝으로 분류할 수 있다. 지도학습은 정답이 있는 데이터를 활용해 데이터를 학습시키는 것으로 대표적으 로 분류, 회기가 있다. 비지도학습은 정답 라벨이 없는 데이터를 비슷한 특징을 가지는 데이터끼리 군집화하 는 것으로, 대표적으로 클러스터링이 있다. 딥러닝은 기계가 자동으로 학습하려는 데이터에서 특징을 추출하 여 학습을 하는 것으로, 여러 층을 가진 인공 신경망을 사용하여 이러한 학습을 수행한다. 인공 신경망은 인 간의 뇌에 존재하는 수 많은 뉴런 사이에 일어나는 신호 전달을 통하여 인간이 다양한 사고를 할 수 있게 하는 것을 컴퓨터로 구현한 것으로, 인간의 뉴런을 본따서 신호를 처리하는 퍼셉트론(perceptron)이 여러 개 조합되 어 있는 다층 퍼셉트론(multiple layer perceptron)의 조합이라고 할 수 있다. 입력층(input layer)을 통하여 학습하고자 하는 데이터를 입력 받고, 입력된 데이터들은 여러 단계의 은닉층 (hidden layer)으로 전달된다. 이때 은닉층에 있는 각 뉴런(단층 퍼셉트론)에 전달되는 입력치에 가중치 (weight)가 곱해지면, 입력치와 가중치의 곱을 모두 합한 값에 편향(bias)을 더한 값이 은닉층에 있는 활성화 함수가 가지고 있는 임계치값과 비교되고, 만약 그 합이 임계치 값보다 클 경우 뉴런은 활성화되고, 임계치보다 작을 경우 뉴런은 비활성화되는 방법으로 신호가 전달된다. <식 1>"}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 식 1은 (n-1)번째 층의 k번째 뉴런으로부터 n번째 층의 j번째 뉴런으로 전달되는 신호(아웃풋)를 나타내는 것으로, 상기 식 1에서 xn j는 뉴런의 계산된 아웃풋이고, fn은 n 층의 활성화 함수, wn jk는 (n-1)번째 층의 k번째 뉴런으로부터 n번째 층의 j번째 뉴런까지의 가중치이고, xn-1 k는 (n-1)번째 층의 k번째 뉴런의 입력치이고, bn j는 n번째 층의 j번째 뉴런의 편향이다. 은닉층을 통하여 처리된 결과는 출력층(output layer)을 통하여 최종적으로 출력된다. 데이터가 입력층으로부 터 출력층으로 전달되는 것을 피드 포워드(feed forward)라고 한다. 이때, 가중치와 편향은 초기에는 랜덤한 값으로 설정되지만, 경사하강법을 통해 예측값과 실제값의 차이(오차, 손실함수)를 줄이는 방향으로 인공신경망 이 훈련된다. 다음의 식 2와 식 3은 경사하강법을 사용하여 가중치와 편향 각각을 업데이트하는 식이다.<식 2>"}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "<식 3>"}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기 식 2 및 식 3에서, η는 학습률이고, C는 예측된 출력값과 실제 출력값 사이의 차이를 정량화하는 손실 함 수이고, w는 가중치, b는 편향이다. 이때, 현재의 가중치와 편향으로부터 얻은 결과값을 통해 역으로 오차를 전파하여 가중치와 편향을 업데이트하 는 방법을 오차역전파(error backpropagation)법이라고 한다. 이러한 가중치의 업데이트 과정에서 인공신경망 의 훈련을 위하여 사용되는 데이터 세트의 개수가 아주 많을 경우, 모든 데이터 세트를 가중치의 업데이트에 사 용하는 것은 비효율적이다. 따라서, 데이터 세트를 배치(가중치를 한번 업데이트 시킬 때 사용되는 샘플의 묶 음)로 분할하여, 샘플 단위로 가중치를 업데이트하고, 전체 데이터 세트에 대하여 한번 학습을 완료한 것으로 에폭(epoch)이라고 한다. 인공신경망을 학습할 때 과적합 또는 과소적합(모델 적합성)을 판단하기 위하여 학 습 데이터를 일정한 비율로 훈련(training), 테스트(test), 검증(validation) 데이터로 분할하여 학습을 진행하 는데, 에폭 수가 많아지면 과적합이 일어날 가능성이 높아지므로 일정 횟수 이상의 에폭에서 검증 데이터에 대 한 모델의 성능이 증가하지 않으면 학습을 중단하여 과적합을 방지하는 학습 조기 종료(early stopping)를 적용 한다. 이처럼 인공신경망의 모델 적합성 및 성능에는 뉴런의 수, 활성화 함수의 종류, 손실함수의 종류, 최적 의 가중치와 편향을 탐색하기 위한 최적화 기법의 종류, 에폭 수 등과 같은 다양한 하이퍼파라미터 (hyperparameter)가 영향을 미치며, 이를 적절하게 선정하는 것이 정확한 예측을 위하여 매우 중요하다. 하이퍼파라미터는 인공신경망의 구조와 정확성 및 학습 과정을 결정하는 주요 변수를 말하고, 주요한 하이퍼파 라미터로는 은닉층의 개수(the number of hidden layer), 은닉층 당 뉴런의 개수(the number of neurons per layer), 학습률(learning rate), 에폭 수(number of epochs), 각 은닉층 내 활성화 함수의 종류(activation functions of each layer), 옵티마이저(optimizer) 등이 있다. 상기한 바와 같이, 본 발명은 생성된 학습 데 이터 세트로부터 유전 알고리즘(genetic algorithm, GA)을 이용하여 인공신경망을 위한 적합한 하이퍼파라미터 조합을 도출한다. 구체적으로 활성화 함수(activation function)은 각 뉴런에 입력된 가중치와 입력치의 곱에 편향을 합한 값(식 1)이 임계치를 넘을 경우 신호를 발생시키는 함수로, 가장 간단한 형태는 계단 함수(step function)이나, 보통 은 0에서 1 사이의 값을 반환하는 로지스틱 펑션(logistic function)의 한 종류인 시그모이드 펑션(sigmoid function)(도 2의 (a))이 널리 사용되고 있다. 그러나, 시그모이드 펑션의 사용은 오차역전파법에서 기울기 소실 문제(vanishing gradient problem)가 발생한다는 문제점이 있다. 이와 같은 문제점을 해결하기 위하여 하이퍼볼릭 탄젠트 펑션(도 2의 (b))이 사용되며, 이외에도 다양한 활성화함수가 은닉층마다 선택될 수 있다. 도 2는 다양한 활성화 함수의 그래프를 보여주고 있고, 이중 (a)는 시그모이드 펑션, (b)는 하이퍼볼릭 탄젠트 펑션, (c)는 ReLU, (d)는 리키(leaky) ReLU, 및 (f)는 SELU를 보여주고 있다. 다음으로, 손실함수(cost function)는 훈련 결과인 예측값과 실제값과의 오차를 계산하여 훈련 오차를 최소화하 기 위해 정의되는 함수로, 상기 식 2와 식 3을 통하여 오차 역전파법을 시행할 경우, 가중치와 편향에 대한 손 실함수(C)의 편미분값을 사용하여 오차를 최소화하는 방향으로 가중치와 편향이 업데이트됨을 확인할 수 있다. 이러한 손실함수로 주로 사용되는 지표에는 평균제곱오차(mean squared error)(식 4)와 평균 절대 오차(mean absolute error)(식 5)가 있다. <식 4>"}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "<식 5>"}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "상기 식 4와 식 5에서 yi는 i번째 실험(실제)값이고, 는 i번째 예측값이다. 한편, 상기한 바와 같이 정의되는 손실함수를 최소화하는 가중치와 편향을 찾기 위해 경사 기법(gradient technique)을 사용하는 알고리즘을 옵티마이저(optimizer)라고 한다. 특별히, 경사하강법이란 손실함수가 최 소가 되는 지점, 즉 손실함수에 대한 가중치와 편향의 편미분값이 0이 되도록 가중치와 편향을 업데이트하는 방 법이다. 이러한 경사하강법에서는 학습률 또는 보폭으로 불리는 스칼라값을 곱하여 다음 지점을 결정한다. 학습률은 0에서 1 사이의 값을 가지며, 손실함수를 최소화하는 방향으로 학습을 시키며 학습의 속도를 결정한다. 학습률이 너무 크면 최저점을 지나칠 우려가 있고, 학습률이 너무 작으면 학습 시간이 매우 오래 걸리게 된다. 따라서, 보통 0.1 에서 0.01 사이의 값을 학습률로 설정한다. 또한, 최대한 빠른 시간 내에 손실 함수의 최소값을 찾기 위해서 에폭 수가 증가할수록 학습률을 감소시키는 감쇠 함수(decay function)를 적 용한다. 이와 같은 구체적인 하이퍼파라미터의 최적의 조합을 도출하고, 이를 이용하여 인공신경망 모델을 구축한다. 본 발명은 이와 같은 방법으로 인공신경망 모델을 구축함으로써, 기존의 시행오차법을 통하여 하이퍼파라미터를 결정하던 방법과 비교하여, 훨씬 빠른 속도로 신뢰성이 높은 인공 신경망 모델을 구축할 수 있는 장점이 있다. 한편, 본 발명의 인공 신경망 모델 구축방법은 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수 로 사용하여, 유전 알고리즘의 변수 최적화에 사용하는 단계를 더 포함할 수 있고, 이를 통하여, 목적합수를 최 대 또는 최소화하는 최적의 입력값을 도출하는데 사용될 수 있다. 다시말해, 구축된 인공신경망 모델의 가중 치 및 최적화는 유전 알고리즘 내에서 목적 함수로 사용될 수 있다. 본 발명의 방법에서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상일 수 있으며, 구체적인 하이퍼파라미터의 정의는 상기한 바와 같으며, 그 외의 구체적인 하이퍼파라미터는 통상의 기술자들에게 자명한 사항이다. 또한, 본 발명은 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 상기 하이퍼파라미터 조합을 이용하여 인공 신경망 모델을 구축하는 단계; 및 상기 구축된 인공 신경망 모델을 이용하여 변수값을 최적화하는 단계; 를 포함하는 변수 최적화 방법을 제공한다. 이하 본 발명을 각 단계별로 상세히 설명한다. 단, 학습 테이터 세트를 생성하는 단계, 이로부터 인공신경망 을 위한 하이퍼파라미터 조합을 도출하는 단계, 및 도출된 하이퍼파라미터 조합으로부터 인공 신경망 모델을 구 축하는 단계는 상기한 바와 동일하므로, 설명을 생락한다. 본 발명의 변수 최적화 방법은 상기한 바와 같은 단계를 통하여 구축된 인공 신경망 모델을 이용하여 변수값을 최적화하는 단계를 포함한다. 구체적으로, 구축된 인공 신경망 모델의 결과값 중 원하는 결과값의 최대화 또 는 최소화 등을 위하여 요구되는 변수값을 상기 구축된 인공 신경망 모델을 통하여 도출하는 것이 가능하다. 단순히 특정 시스템을 시뮬레이션하여 원하는 결과값을 얻기 위하여 어떠한 변수값을 입력해야 하는지를 도출하 는 것은 너무나 많은 시간이 소요되는 문제점이 있다. 그러나, 본 발명의 방법에 따라 인공 신경망 모델을 구 축하는 경우, 원하는 결과값만 입력하면, 그와 같은 결과값을 도출하기 위하여 변수값을 어떻게 최적화해야 하 는지를 짧은 시간에 알 수 있는 장점이 있다. 특히, 신뢰성이 높은 인공 신경망 모델을 구축하는 과정에서, 유전 알고리즘을 이용하여 적합한 하이퍼파라미터 조합을 도출함으로써, 기존의 방법과 비교하여 훨씬 빠른 속 도로, 신뢰성이 높은 인공 신경망 모델을 구축할 수 있는 장점이 있다. 한편, 본 발명의 변수 최적화 방법은 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수로 사용하 여, 유전 알고리즘의 변수 최적화에 사용하는 단계를 더 포함할 수 있고, 이를 통하여, 목적합수를 최대 또는 최소화하는 최적의 입력값을 도출하는데 사용될 수 있다. 다시말해, 구축된 인공신경망 모델의 가중치 및 최 적화는 유전 알고리즘 내에서 목적 함수로 사용될 수 있다. 본 발명의 방법에서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상일 수 있으며, 구체적인 하이퍼파라미터의 정의는 상기한 바와 같으며, 그 외의 구체적인 하이퍼파라미터는 통상의 기술자들에게 자명한 사항이다. 본 발명은 특히 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 공정 변수값에 따른 결과 데이터를 생성하는 학습 데이 터 세트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 및 상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 를 포함하는 유전 알고리즘을 이용한 화학 공정 모델링을 위한 인공 신경망 모델 구축방법을 제공한다. 이하 본 발명의 방법을 각 단계별로 상세히 설명한다. 다만, 각 단계들 중 상기한 내용과 동일한 부분은 중복 을 방지하기 위하여 설명을 생략하고, 추가적인 부분만을 이하에서 설명한다. 본 발명의 방법은 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 공정 변수값에 따른 결과 데이터를 생 성하는 학습 데이터 세트의 생성단계를 포함한다. 화학 공정의 경우 실제 실험을 통하여 공정 변수값에 따른 결과 데이터를 얻을 수도 있으나, 그 데이터를 얻을 수 있는 다양한 시뮬레이션 방법이 존재한다. 뿐만 아니 라, 이미 특정 시스템을 이용한 화학 공정에 대한 공정 변수값에 대한 결과 데이터를 얻을 공지의 데이터 세트 도 다양하게 존재한다. 본 발명에서 학습 데이터 세트의 생성단계는 실제로 실험을 수행하거나 시뮬레이션을 수행하여 얻은 데이터를 이용하여 학습 데이터 세트를 생성하는 것 뿐만 아니라, 공지의 데이터를 이용하여 학 습 데이터 세트를 생성하는 것 또한 포함한다. 본 발명의 방법은 상기 학습 데이터 세트로부터 유전 알고리즘을 이용한 인공신경망을 위한 하이퍼파라미터 조 합을 도출하는 단계를 포함하며, 이는 상기한 바와 동일하다. 이와 같이 도출된 하이퍼파라미터 조합을 이용하여 본 발명의 방법은 화학 공정 모델링을 위한 인공 신경망 모 델을 구축하는 단계를 포함한다. 본 단계를 통하여, 인공 신경망 모델을 통하여 원하는 화학 공정을 모델링하 는 것이 가능하고, 특정 화학 공정에 있어서 특정 공정 변수값의 변화에 따른 결과값의 변화, 경향, 연관성 등 을 확인할 수 있다. 한편, 본 발명의 화학 공정 모델링을 위한 인공 신경망 모델 구축방법은 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함수로 사용하여, 유전 알고리즘의 변수 최적화에 사용하는 단계를 더 포함할 수 있고, 이 를 통하여, 목적합수를 최대 또는 최소화하는 최적의 입력값을 도출하는데 사용될 수 있다. 다시말해, 구축된 인공신경망 모델의 가중치 및 최적화는 유전 알고리즘 내에서 목적 함수로 사용될 수 있다. 본 발명의 방법에서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상일 수 있으며, 구체적인 하이퍼파라미터의 정의는 상기한 바와 같으며, 그 외의 구체적인 하이퍼파라미터는 통상의 기술자들에게 자명한 사항이다. 또한 본 발명은 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세 트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 및 상기 구축된 인공 신경망 모델을 이용하여 화학 공정의 변수값을 최적화하는 단계; 를 포함하는 화학 공정 변수 최적화 방법을 제공한다. 이하 본 발명의 화학 공정 변수 최적화 방법을 각 단계별로 상세히 설명하되, 상기한 바와 동일한 부분은 중복 을 방지하기 위하여 생략하고, 추가적인 설명이 필요한 부분에 대하여 이하에서 설명한다. 화학 공정의 경우, 원하는 결과값의 원하는 값, 예를 들어 최대값 또는 최소값 등을 도출하기 위하여 어떠한 공 정 변수를 조절해야 하는지를 고려해야 할 필요가 있다. 본 발명의 방법에 따르면, 생성된 학습 데이터 세트 를 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 유전 알고리즘을 이용하여 도출한 후, 이를 통하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하고, 그 구축된 인공 신경망 모델을 이용하여 화학 공정의 변수값 을 최적화할 수 있다. 즉, 본 발명의 방법으로 인공 신경망 모델을 구축하는 경우, 특정 시스템의 화학 공정 을 모델링하는 것이 가능하기 때문에, 변수값과 결과값 사이의 관계, 경향 등을 확인할 수 있게 되고, 따라서,원하는 결과값을 위한 변수의 최적화가 가능하게 된다. 한편, 본 발명의 화학 공정 변수 최적화 방법은 상기 구축된 인공 신경망 모델을 상기 유전 알고리즘의 목적함 수로 사용하여, 유전 알고리즘의 변수 최적화에 사용하는 단계를 더 포함할 수 있고, 이를 통하여, 목적합수를 최대 또는 최소화하는 최적의 입력값을 도출하는데 사용될 수 있다. 다시말해, 구축된 인공신경망 모델의 가 중치 및 최적화는 유전 알고리즘 내에서 목적 함수로 사용될 수 있다. 본 발명의 방법에서, 상기 하이퍼파라미터는 은닉층의 수, 은닉층 당 뉴런의 수, 학습률, 활성화 함수의 종류, 손실함수의 종류, 가중치 및 편향 도출을 위한 기법, 및 에폭 수로 이루어진 군으로부터 선택되는 1종 이상일 수 있으며, 구체적인 하이퍼파라미터의 정의는 상기한 바와 같으며, 그 외의 구체적인 하이퍼파라미터는 통상의 기술자들에게 자명한 사항이다. 더 나아가 본 발명은 화학 공정을 위한 시뮬레이션 또는 실제 실험을 통하여 변수값에 따른 결과 데이터를 생성하는 학습 데이터 세 트의 생성단계; 상기 학습 데이터 세트로부터 유전 알고리즘을 이용하여 인공신경망을 위한 하이퍼파라미터 조합을 도출하는 단 계; 상기 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경망 모델을 구축하는 단계; 및 상기 구축된 인공 신경망 모델에 변수값을 도입하여 이에 따른 결과 데이터를 도출하는 단계; 를 포함하는 화학 공정 변수에 따른 결과 데이터 예측방법을 제공한다. 이하 본 발명의 화학 공정 변수에 따른 결과 데이터 예측방법을 각 단계별로 상세히 설명하되, 상기한 바와 동 일한 부분은 중복을 방지하기 위하여 생략하고, 추가적인 설명이 필요한 부분에 대하여 이하에서 설명한다. 본 발명의 방법은 학스 데이터 세트를 생성하고, 이로부터 유전 알고리즘을 이용하여 인공신경망을 위한 적절한 하이퍼파라미터 조합을 도출한 후, 도출된 하이퍼파라미터 조합을 이용하여 화학 공정 모델링을 위한 인공 신경 망 모델을 구축한다. 이와 같이 구축된 인공 신경망 모델에 조절하고자 하는 변수값을 도입하면, 해당 모델링 을 통하여 변수값에 따른 결과 데이터를 도출하는 것이 가능하다. 즉, 본 발명의 방법에 따라 구축된 인공 신 경망 모델은 특정 화학 공정의 모델링이기 때문에, 다양한 변수와 결과 사이의 관련성, 경향성 등을 확인할 수 있고, 따라서, 이에 원하는 변수 및 그 값을 입력하게 되면, 이에 따른 해당 시스템의 결과값을 확인하는 것이 가능하게 된다. 특히, 본 발명의 방법은 상기와 같은 인공 신경망 모델을 도출함에 있어서, 기존의 방법과는 달리 유전 알고리즘을 이용하여 하이퍼파라미터 조합을 도출하기 때문에, 기존 방법보다 훨씬 빠르게 신뢰성이 높은 인공 신경망 모델을 도출하는 것이 가능하다는 장점이 있다. 이하에서는 본 발명의 신뢰성을 확인하기 위하여 기존 연구에 의하여 도출된 결과와 본 발명의 결과를 비교하는"}
{"patent_id": "10-2021-0067778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "실험을 수행하였다. 이하의 실험예는 본 발명의 효과를 확인하기 위한 구체적인 예시일 뿐, 이하의 기재 내용 에 의하여 본 발명의 권리범위가 한정되어 해석되는 것을 의도하는 것은 아니다. 이하의 실험에서 비교를 위하여 사용된 데이터 세트는 다음과 같다. 표 1 저자 타겟 변수 데이터 세트 수 Shin et al. NOx 환원 63 Gbadago et al. 부타디엔 합성에서의 전환율, 수율 및 선택도 최대화 56 Asgari et al. 폐수로부터 디우론(diuron) 제거 50 Mohammadi et al. 토양으로부터 피린(pyrene) 제거 30 Okpalaekeet al. 고도의 자유 지방산(FFA) 제거 17 상기 표 1에서, Shin et al.은 Shin Y, Kim Z, Yu J, Kim G, Hwang S Development of NOx reduction system utilizing artificial neural network (ANN) and genetic algorithm (GA) J Clean Prod 2019;232:1418-29 https://doiorg/101016/jjclepro201905276이고, Gbadago et al.은 Gbadago DQ, Moon J, Kim M, Hwang S A Unified Framework for the Mathematical Modelling, Predictive Analysis, and Optimization of Reaction Systems using Computational Fluid Dynamics, Deep Neural Network and Genetic Algorithm: A Case of Butadiene Synthesis Chem Eng J 2020;409:128163 https://doiorg/101016/jcej2020128163 이고, Asgari et al.은 Asgari G, Seid-mohammadi A, Rahmani A, Samadi MT, Salari M, Alizadeh S, et al Diuron degradation using three-dimensional electro-peroxone (3D/E-peroxone) process in the presence of TiO2/GAC: Application for real wastewater and optimization using RSM-CCD and ANN-GA approaches Chemosphere 2021;266:129179 https://doiorg/101016/jchemosphere2020129179 이고, Mohammadi et al.은 Mohammadi F, Samaei MR, Azhdarpoor A, Teiri H, Badeenezhad A, Rostami S Modelling and Optimizing Pyrene Removal from the Soil by Phytoremediation using Response Surface Methodology, Artificial Neural Networks, and Genetic Algorithm Chemosphere 2019;237:124486 https://doiorg/101016/jchemosphere2019124486 이고, Okpalaekeet al.은 Okpalaeke KE, Ibrahim TH, Latinwo LM, Betiku E Mathematical Modeling and Optimization Studies by Artificial Neural Network, Genetic Algorithm and Response Surface Methodology: A Case of Ferric Sulfate-Catalyzed Esterification of Neem (Azadirachta indica) Seed Oil Front Energy Res 2020;8:1-14 https://doiorg/103389/fenrg2020614621 이다. 본 발명의 실험 중 본 발명의 방법에서 최적화된 인공신경망에서 사용된 파라미터는 다음과 같다. 표 2 타입 후보군의 범위 에폭 수 1 - 10000 첫번째 층의 뉴런 수 1 - 500 두번째 층의 뉴런 수 1 - 100 활성화 함수 하이퍼볼릭 탄젠트 펑션, ReLU, 리키 ReLU, ELU, SELU 학습율 0.1, 0.05, 0.04, 0.03, 0.02, 0.01, 0.007, 0.005, 0.003, 0.001 손실함수 평균제곱오차(MSE), 평균절대오차(MAE) 옵티마이저 AdaGrad, RMSProp, AdaDelta, Adam, AdaMax, Nadam 교차비율 0.8 모집단 크기 10 세대 수 50 변이 확률 0.1 부모-자식 비율 1 유전 알고리즘에서 초기(default) 조합으로 사용된 파라미터는 다음과 같다. 표 3 파라미터 값 세대 100 모집단 크기 50 선택압(beta) 1 부모-자식 비율 1 교차 팩터(gammar) 0.1 변이율(mu) 0.01 변이 스텝 사이즈(sigma) 0.3 <실험예 1> Shin et al.의 NOx 저감 실험 결과와의 비교 Shin Y, Kim Z, Yu J, Kim G, Hwang S. Development of NOx reduction system utilizing artificial neural network (ANN) and genetic algorithm (GA). J Clean Prod 2019;232:1418-29. https://doi.org/10.1016/j.jclepro.2019.05.276의 NOx 저감 실험과 본 발명에 따른 인공 신경망 모델의 예측 결과를 다음과 같이 비교하였다. 본 발명에 따라 유전 알고리즘을 이용한 인공신경망 모델은 63 데이터 세트를 이용하여 공정을 최적화하였다. 본 발명의 모델에 의하여 얻어진 최적 조건은 실험 결과에 의하여 검증되었다. 공정 변수(입력값)은 과 O2 농도, 온도, 물의 pH, 및 과산화수소 농도이고, 출력값은 NOx 환원 정도였다. 본 발명의 모델 구축을 위하여 사용된 하이퍼파라미터들은 다음과 같다. 표 4 하이퍼파라미터 값 에포크 5735 첫번째 히든레이어의 뉴런 수 122 첫번째 히든레이어의 활성함수 하이퍼볼릭 탄젠트 두번째 히든레이어의 뉴런 수 83 두번째 히든레이어의 활성함수 하이퍼볼릭 탄젠트 손실함수 평균절대오차(MAE) 옵티마이저 AdaMax 학습률 0.01 본 발명과 Shin et al.에 따른 R-값, MSE, MAPE는 다음과 같다. 표 5 R MSE MAPE Shin et al. 0.9985 0.9968 4.4433 본 발명 0.9991 0.5528 1.8610 상기 표 5에 따르면, 실제로 본 발명에 따른 모델이 Shin et al. 대비 높은 R-값과, 낮은 MSE, MAPE 값을 갖는 다는 것을 확인할 수 있다. 이를 통하여, 본 발명의 모델이 높은 정확도와, 낮은 오류값을 갖는다는 것을 알 수 있다. 도 4는 본 발명의 모델에 따라 얻어진 그래프이다. 도 4의 (a)는 변수들간의 관계를 보여주며, 이를 통하여 가장 연관성이 있는 변수들을 분석할 수 있다. 도 4의 (b), (c)를 통하여, 본 발명의 모델에 따라 예측된 값 이 실험 데이터와 매우 가까우며, Shin et al.의 결과보다 더 정확도가 높다는 것을 알 수 있다. 또한 본 발 명의 모델에 따른 연산 결과는 9분 25초만에 도출되었고, 이를 통하여 일반적으로 수 일의 시간이 소요되는 기 존의 트라이얼-앤드-에러(trial-and-error) 방식의 모델보다 현저히 빠른 기술이라는 것을 알 수 있다. 도 4의 (d)를 통하여, NO 저감을 최대화할 수 있는 공정 변수를 찾을 수 있다. 도 4는 Shin et al.과 본 발명 의 모델로부터 얻어진 최적 조건들을 비교하고 있으며, 양 실험의 결과는 최대 NO 저감이 26.68 %임을 보여주고 있다. 본 발명과 Shin et al.에서 얻어진 최적의 공정 입력값의 비교는 다음의 표와 같다. 표 6 O2 농도(%) 온도(℃) pHH2O2 농도(%) NO 예상 저감(reduction)(%) Shin et al. 9.23 28 5 0.13 26.68 본 발명 9.80 10.10 4.71 0.057 26.68 <실험예 2> Gbadago et al.의 반응기 퍼포먼스 최적화 실험 결과와의 비교 Gbadago DQ, Moon J, Kim M, Hwang S. A Unified Framework for the Mathematical Modelling, Predictive Analysis, and Optimization of Reaction Systems using Computational Fluid Dynamics, Deep Neural Network and Genetic Algorithm: A Case of Butadiene Synthesis. Chem Eng J 2020;409:128163. https://doi.org/10.1016/j.cej.2020.128163의 반응기 퍼포먼스 최적화 실험 결과와 본 발명의 모델에 따른 결 과를 비교하기 위하여 다음과 같은 실험을 수행하였다. 부타디엔 합성을 위한 다중관 반응기의 공정 변수에 대한 예측 및 최적화의 실험을 수행하였다. 입력값은 반 응온도, 부텐과 산소의 비율, 및 가스 유속이었다. 전환율, 수율 및 선택도와 가은 반응기 퍼포먼스 지표는 출력값으로 평가되었다. 예측의 결과로, CFD 결과와 학습된 모델 사이의 크로스-벨리데이션으로부터 계산된 정확도는 98.80%(1.2%의 에러)였다. 본 발명의 모델을 이용하여 다른 DNN을 구축하였고, 사용된 하이퍼파라미 터들은 다음과 같다. 표 7 하이퍼파라미터 값 에포크 4556 첫번째 히든레이어의 뉴런 수 314 첫번째 히든레이어의 활성함수 하이퍼볼릭 탄젠트 두번째 히든레이어의 뉴런 수 22 두번째 히든레이어의 활성함수 ELU 손실함수 평균절대오차(MAE) 옵티마이저 Adam 학습률 0.003도 5에 따르면 전환율, 수율 및 부타디엔의 선택도에 대한 예측값이 CFD 모델의 결과와 매우 일치하는 것을 알 수 있고, 1.2 %의 에러를 보여주는 Gbadago et al.의 DNN과 비교하여 다소 높은 정확도인 98.92%(1.08% 에러) 를 보여주고 있음을 알 수 있다. 본 발명에 따른 최적화 DNN 모델은 10분 3초만에 구축되었다. 본 발명의 모델은 단일 출력값 최적화를 지원하기 때문에, Gbadago et al.와 동일한 입력 변수(온도, 부텐과 산 소의 비율, 가스 유속)와 함께, 부타디엔 수율을 결정 변수로 선택하였다. 구축된 DNN 모델은 공정 변수를 최 적화하기 위하여 파라미터 최적화 유전 알고리즘과 통합되었다. 예측된 최대 수율(최적화된 값)의 값은 720 K 의 온도, C4/O2 비율은 1.21, 유속은 0.00078 kg/s의 조건에서 88.34 %였다. 그 후 전환율과 선택도는 각각 98 % 및 90 %로 계산되었다. 이와 같은 결과는 Gbadago et al.의 결과에 상응하는 결과이다. <실험예 3> Asagari et al.의 폐수로부터 디우론(N-(3,4-디클로로페닐)-N,N-디메틸우레아) 제거 실험 결과와의 비교 Asgari G, Seid-mohammadi A, Rahmani A, Samadi MT, Salari M, Alizadeh S, et al. Diuron degradation using three-dimensional electro-peroxone (3D/E-peroxone) process in the presence of TiO2/GAC: Application for real wastewater and optimization using RSM-CCD and ANN-GA approaches. Chemosphere 2021;266:129179. https://doi.org/10.1016/j.chemosphere.2020.129179에 따르면, 디우론은 농업분야에서 광범 위하게 사용되는 광합성을 억제하는 제초제이다. 환경 및 인류의 건강에 대한 증가하는 관심에 따라, 자연에 존재하는 물 및 음용수 내 농약성분의 존재는 그 독성 및 위험성 때문에 엄격하게 통제되고 있다. Asagari et al.에는 액상 용액 내 디우론을 제거하는 입자 전극으로서 TiO2-GAC를 갖는 3D/E-페록손(peroxone) 반응기의 효 율을 조사하고 있다. 본 발명에 따라 구축된 모델을 이용하여 pH, 인가 전류, 지지 전해질, 오존 농도, 및 반 응 시간 등의 독립 변수가 디우론 제거에 미치는 영향을 조사하였다. Asagari et al.은 50 데이터 세트를 이용 하여 구축된 ANN 모델을 이용하여 3D 서피스 플로팅에 의하여 디우론 제거에 대한 서로 다른 공정 파라미터의 효과를 조사하였다. 동일 실험을 위하여 본 발명의 모델이 사용한 하이퍼파라미터는 다음과 같다. 표 8 하이퍼파라미터 값 에포크 7271 첫번째 히든레이어의 뉴런 수 436 첫번째 히든레이어의 활성함수 SELU 두번째 히든레이어의 뉴런 수 93 두번째 히든레이어의 활성함수 리키 ReLu 손실함수 평균제곱오차(MSE) 옵티마이저 AdaGrad 학습률 0.02 도 6에 따르면, 본 발명에 따른 모델이 매우 짧은 시간(10분 2초) 내에, Asagari et al.와 거의 유사한 결과(신 경망 구축 및 반응 서피스 플로팅)를 도출할 수 있다는 것을 알 수 있다. 추가적으로, Asagari et al.의 모델 에 따른 결과에 따르면, 입력 변수의 최적 조건은 다음과 같다: 초기 pH = 10, 인가 전류 = 500 mA 지지 전해질 = 0.07 M 오존 농도 = 10 mg/L 반응시간 = 10 분. 비교하여 본 발명의 모델에 따른 결과에 따르면, 입력 변수의 최적 조건은 다음과 같다: 초기 pH = 9.96, 인가 전류 = 464 mA 지지 전해질 = 0.0736 M 오존 농도 = 9.9994 mg/L 반응시간 = 9.998 분. <실험예 4> Mohammadi et al.의 토양으로부터 피린 제거 실험 결과와의 비교 Mohammadi F, Samaei MR, Azhdarpoor A, Teiri H, Badeenezhad A, Rostami S. Modelling and Optimizing Pyrene Removal from the Soil by Phytoremediation using Response Surface Methodology, Artificial Neural Networks, and Genetic Algorithm. Chemosphere 2019;237:124486. https://doi.org/10.1016/j.chemosphere.2019.124486에서 토양으로부터 피린을 제거하는 실험을 수학적 모델을 통하여 조사하였다. 구체적으로, Mohammadi et al.에서는 총 20 데이터 세트를 이용하여, 초기 피린 농도, 인돌 아세트산(IAA), 및 샘플링 데이 등의 피린 제거 효율에의 영향이 조사되었다. 실험 결과가 네트워크 입력값으 로 사용되었고, 해당 모델은 R-값이 0.995, MSE는 0.00007, 및 MAE는 0.0076이었다. 동일 데이터 세트를 본 발명의 모델에 적용하는 경우, R-값은 0.99849, MSE는 0.0013, 및 MAE는 0.02331이었다. 변수들 사이의 예측 결과의 정확도 및 관계는 도 7에 도시되었다. 본 발명의 모델에서 사용된 하이퍼 파라미터는 다음과 같다. 표 9 하이퍼파라미터 값 에포크 2067 첫번째 히든레이어의 뉴런 수 43 첫번째 히든레이어의 활성함수 하이퍼볼릭 탄젠트 두번째 히든레이어의 뉴런 수 21 두번째 히든레이어의 활성함수 ELU 손실함수 평균제곱오차(MSE) 옵티마이저 Nadam 학습률 0.04 본 발명의 모델과 Mohammadi et al. 모델의 피린 제거 최적화 결과는 다음의 표에서 비교되었다. 표 10 피린 농도 (mg/kg)인돌 아세트산 (mg/L)수도모나스 박테리아 (cc)샘플링데이 (day)최대 피린 제거 (%) Mohammadi et al.226.02 10 36.47 81.36 90.55 본 발명 200.05 9.69 39.28 70.09 88.70 차이(%) 11.49 3.08 7.70 13.85 2.04 상기 표에 따르면, 피린 제거 퍼센트와 관련하여 2.04 %의 차이가 있음을 확인할 수 있다. 본 발명의 모델은 단지 디폴트 유전 알고리즘 세팅에 의하여 수행되었으며, Mohammadi et al. 모델과는 달리 세밀하게 튜닝된 것 은 아니며, 사용자는 뮤테이션, 프로바빌리티 등에 있어서 최적화 세팅을 변경할 수 있다. <실험예 5> Okpalaeke et al.의 바이오디젤 생산 공정에서 고도의 자유 지방산(FFA) 제거 실험 결과와의 비교 Okpalaeke KE, Ibrahim TH, Latinwo LM, Betiku E. Mathematical Modeling and Optimization Studies by Artificial Neural Network, Genetic Algorithm and Response Surface Methodology: A Case of Ferric Sulfate-Catalyzed Esterification of Neem (Azadirachta indica) Seed Oil. Front Energy Res 2020;8:1-14. https://doi.org/10.3389/fenrg.2020.614621는 17개의 데이터 세트를 이용하여, FFA의 환원에 대한 3개의 입력 파라미터(메탄올과 NSO의 몰비, 페릭셀페이트 촉매 주입량, 및 반응시간)의 효과를 조사하였다. 추가적으로, 에스테르화반응 중 FFA 환원과 바이오디젤 수율을 최대화하기 위한 최적의 공정 조건이 RSM, ANN 및 GA를 이용 하여 얻어졌다. Mohammadi et al. 모델에 따르면, R-값은 0.9954, MSE는 0.002, 및 MAE는 0.030이었다. 본 발명의 모델에서 사용된 하이퍼 파라미터는 다음과 같다. 표 11 하이퍼파라미터 값 에포크 2905 첫번째 히든레이어의 뉴런 수 5 첫번째 히든레이어의 활성함수 하이퍼볼릭 탄젠트 두번째 히든레이어의 뉴런 수 9 두번째 히든레이어의 활성함수 SELU 손실함수 평균절대오차(MAE) 옵티마이저 Adam 학습률 0.1 본 발명의 모델에 따른 R-값은 0.9964, MSE는 0.0099, 및 MAE는 0.046이었다. 도 8은 Mohammadi et al.와 본 발명의 모델에 따른 예측 결과를 비교하고 있다. 도 8에 따르면 20분 12초만에 구축된 본 발명의 모델이 Mohammadi et al.의 모델과 매우 유사한 결과를 도출하고 있음을 알 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2021-0067778", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다중 퍼셉트론(multilayer perceptron, MLP)의 개략도이고, 도 2는 다양한 활성화 함수의 종류를 나타내는 그래프이고, 도 3은 본 발명에 따른 유전 알고리즘을 사용한 인공신경망 하이퍼파라미터 최적화 알고리즘을 보여주는 순서도 이고, 도 4는 본 발명의 실험예 1에 따른 결과 그래프들이고, 도 5는 본 발명의 실험예 2에 따른 결과 그래프들이고, 도 6은 본 발명의 실험예 3에 따른 결과 그래프들이고, 도 7은 본 발명의 실험예 4에 따른 결과 그래프들이고, 및 도 8은 본 발명의 실험예 5에 따른 결과 그래프들이다."}
