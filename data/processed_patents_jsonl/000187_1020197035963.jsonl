{"patent_id": "10-2019-7035963", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0028330", "출원번호": "10-2019-7035963", "발명의 명칭": "네트워크 연산 에지 전반에 걸쳐 연속적으로 애플리케이션을 작동하는 딥 러닝과 인공 지능에", "출원인": "뉴럴라 인코포레이티드", "발명자": "루시 매튜"}}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "환경에서 객체를 분석하는 방법으로서, 상기 방법은,상기 환경에서 상기 객체를 나타내는 데이터 스트림을 센서로 수집하는 단계;상기 센서에 작동 가능하게 결합된 프로세서 상에서 실행되는 신경망을 이용하여, 상기 데이터 스트림으로부터상기 객체의 특징을 표현하는 콘볼루션 출력을 추출하는 단계; 및상기 신경망에 작동 가능하게 결합된 분류기를 이용하여, 상기 콘볼루션 출력을 기반으로 상기 객체를 분류하는단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 센서는 이미지 센서이고 상기 데이터 스트림은 이미지를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 특징 세트를 추출하는 단계는,제1 이미지의 복수의 세분화된 하위 영역을 생성하는 단계; 및상기 복수의 세분화된 하위 영역 각각을 상기 신경망에 의해 암호화하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 특징 세트를 추출하는 단계는,사용자가 상기 데이터 스트림에서 관심 부분을 선택할 수 있게 하는 단계;상기 사용자가 상기 관심 부분을 복수의 세그먼트로 분할할 수 있게 하는 단계; 및상기 신경망에 의해 상기 복수의 세그먼트 각각을 암호화하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 센서는 리다(lidar), 레이더, 또는 음향 센서 중 적어도 하나이고, 상기 데이터 스트림은리다 데이터, 레이더 데이터, 또는 음향 데이터 중 대응하는 하나를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "환경 내의 객체를 표현하는 데이터 스트림을 상기 환경에서 수집하는 센서; 및상기 이미지 센서에 작동 가능하게 결합되고, (i) 상기 객체의 특징을 표현하는 콘볼루션 출력을 상기 데이터스트림으로부터 추출하기 위한 신경망, 및 (ii) 상기 콘볼루션 출력을 기반으로 상기 객체를 분류하는 분류기를실행하는 적어도 하나의 프로세서를 포함하는 장치."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 센서는 이미지 센서, 리다, 레이더, 또는 음향 센서 중 적어도 하나를 포함하는 장치."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 신경망은 심층 신경망(DNN)을 포함하는 장치."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 신경망은 적응형 공진 이론(ART) 네트워크를 포함하는 장치.공개특허 10-2020-0028330-3-청구항 10 실시간 작동 기기에 평생 학습 심층 신경망(L-DNN)을 구현하는 방법으로서, 상기 방법은,상기 L-DNN에 의해, (i) 상기 실시간 작동 기기의 환경에 대한 센서의 관찰 및 (ii) 상기 L-DNN의 사전 결정된가중치에 기반하여 상기 실시간 작동 기기에 대한 제1 조치를 예측하는 단계;상기 관찰에 기반하여 상기 실시간 작동 기기의 예측과 인식 사이의 불일치를 상기 L-DNN에 의해 결정하는단계, 및상기 불일치에 응답하여, 상기 L-DNN의 사전 결정된 가중치를 변경하지 않고 상기 관찰에 기반하여 수정된 예측을 생성하는 고속 학습 모드를 상기 L-DNN에 의해 작동시키는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 실시간 작동 기기가 오프라인 상태인지 결정하는 단계; 및 상기 실시간 작동 기기가 오프라인 상태인지 결정하는 단계에 응답하여, 상기 관찰을 기반으로 상기 L-DNN의 사전 결정된 가중치를 변경하는 느린 학습 모드를 작동시키는 단계를 추가로 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "가중치 매트릭스 각각의 사본으로 신경망을 구현하는 각각의 실시간 작동 기기로 이루어진 복수의 실시간 작동기기 사이에서 지식을 추출, 통합, 및 공유하는 방법으로서, 상기 방법은,상기 복수의 실시간 작동 기기 중 제1 실시간 작동 기기의 고속 학습 서브시스템으로 적어도 하나의 새로운 객체를 학습하는 단계;적어도 하나의 새로운 객체의 표현을 통신 채널을 통해 상기 제1 실시간 작동 기기로부터 서버로 전송하는단계;상기 제1 실시간 작동 기기로부터의 상기 적어도 하나의 새로운 객체의 표현에 적어도 부분적으로 기초하여, 업데이트된 가중치 매트릭스를 상기 중앙 서버에 형성하는 단계; 및 상기 업데이트된 가중치 매트릭스의 사본을 상기 서버로부터 상기 복수의 실시간 작동 기기 중 적어도 하나의제2 실시간 작동 기기로 전송하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 새로운 객체를 학습하는 단계는,상기 제1 실시간 작동 기기의 고속 학습 서브시스템에 작동 가능하게 결합된 이미지 센서를 이용하여, 상기 적어도 하나의 새로운 객체의 이미지를 획득하는 단계; 및 상기 제1 실시간 작동 기기의 고속 학습 서브시스템을 이용하여, 상기 적어도 하나의 새로운 객체의 이미지를프로세싱하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 신경망은 적응형 공진 이론(ART) 신경망을 포함하고,상기 ART 신경망을 이용하여, 상기 적어도 하나의 새로운 객체의 표현을 생성하는 단계를 추가로 포함하는방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 적어도 하나의 새로운 객체의 표현은 가중치 벡터를 포함하고,상기 제1 실시간 작동 기기에 의해 사용되는 상기 가중치 매트릭스의 사본과 상기 가중치 벡터를 통합하여 상기적어도 하나의 새로운 객체의 표현의 메모리 크기를 감소시키는 단계를 추가로 포함하는 방법.공개특허 10-2020-0028330-4-청구항 16 제12항에 있어서,적어도 하나의 이전에 알려진 객체의 표현과 상기 새로운 객체의 표현을 통합하는 단계를 추가로 포함하는방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서, 상기 적어도 하나의 새로운 객체의 표현을 전송하는 단계는,상기 적어도 하나의 새로운 객체의 표현을 상기 복수의 실시간 작동 기기 중 제2 실시간 작동 기기를 통해 상기서버로 전송하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서, 상기 업데이트된 가중치 매트릭스를 형성하는 단계는,상기 복수의 실시간 작동 기기 중 적어도 하나의 다른 실시간 작동 기기로부터의 적어도 다른 하나의 새로운 객체의 표현과 상기 적어도 하나의 새로운 객체의 표현을 융합하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "복수의 카테고리 내의 객체를 인식하도록 훈련된 신경망을 이용하여 객체를 분류하는 방법으로서, 상기 방법은,상기 신경망에 객체를 제시하는 단계;상기 신경망에 의해 복수의 신뢰 수준을 결정하는 단계(상기 복수의 신뢰 수준의 각 신뢰 수준은, 상기 객체가상기 복수의 카테고리 내의 대응하는 카테고리에 속하는 가능성을 표현함);상기 복수의 신뢰 수준을 임계값과 비교하는 것을 수행하는 단계; 및상기 비교에 기반하여, 상기 객체가 상기 복수의 카테고리 중 어느 것에 속하지 않음을 판정하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 비교를 수행하는 단계는,상기 복수의 신뢰 수준에서 어느 신뢰 수준도 상기 임계값을 초과하지 못함을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제19항에 있어서,상기 임계값을 상기 복수의 신뢰 수준의 평균보다 더 크도록 설정하는 단계를 추가로 포함하는 방법."}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "평생 심층 신경망(L-DNN) 기술은 광범위한 훈련, 고비용 연산 자원 또는 대용량 데이터 저장 없이, 배치 후 고속 학습을 가능하게 함으로써 딥 러닝을 혁신한다. 이는, 이전에 학습한 특징을 망각하지 않고 새로운 특징을 빠르 게 학습하기 위해, 표현 풍부한 DNN 기반 서브시스템(모듈 A)을 고속 학습 서브시스템(모듈 B)과 사용한다. 종래 (뒷면에 계속)"}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원에 대한 교차 참조 본 출원은, 미국 특허법 35 U.S.C. § 119(e)조에 의거하여, 2017년 12월 31일에 출원된 미국 특허 출원 제 62/612,529호, 및 2017년 5월 9일에 출원된 미국 특허 출원 제62/503,639호의 우선권의 이익을 주장한다. 이들 출원 각각은 그 전체가 본원에 참조로서 통합된다."}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "입력 계층과 출력 계층 사이에 개재된 뉴런의 많은 계층을 포함하는 심층 신경망(DNN)을 포함하는 전통적인 신 경망은 특정 데이터 세트에 걸쳐 훈련하기 위해 수천 회 또는 수백만 회의 반복적인 사이클을 필요로 한다. 이 러한 사이클은 종종 고 성능 연산 서버에서 수행된다. 실제로, 일부 전통적인 DNN을 훈련하기 위해 입력 데이터 세트의 크기에 따라 며칠 또는 몇 주가 걸릴 수 있다.DNN을 훈련하기 위한 하나의 기술은, 역전달 알고리즘을 포함한다. 역전달 알고리즘은, 에러 경사를 역전달시키 기 위해 체인 룰을 적용하여, 라벨링된 데이터 세트로부터의 에러 경사에 비례하여 DNN의 모든 가중치의 변화를 연산한다. 역전달은 각 데이터에 대한 가중치에 작은 변화를 만들고, 많은 사건에 대한 세트의 모든 데이터에 걸쳐 실행된다. 반복 사이클 당 학습 속도가 클수록, 손실 함수의 경사는 글로벌 최소값 대신 로컬 최소값으로 안착할 가능성이 높고, 이는 성능을 저하시킬 수 있다. 손실 함수가 글로벌 최소값으로 안착할 가능성을 높이기 위해, DNN은 학 습 속도를 감소시키고, 이는 모든 훈련 사건에 있어서 가중치에 조그마한 변화를 주게 된다. 이는 훈련 사이클 의 횟수와 총 학습 시간을 증가시킨다. 그래픽 프로세싱 유닛(GPU) 기술의 발전은, 몇 주 또는 몇 개월에 걸쳐 사용되는 훈련 작업을 달성하는 데 사용 되는 고도의 병렬 작동에 대한 연산 능력의 엄청난 개선을 이끌었다. 이러한 작업은 GPU와 함께 지금은 몇 시간 또는 몇 일 내에 완료될 수 있지만, 실시간 지식 업데이트를 위해 여전히 빠르지 않다. 또한, DNN을 업데이트하 기 위해 고성능 연산 서버를 활용하는 것은 서버 가격 및 에너지 소비의 관점에서 비용을 증가시킨다. 이것은, DNN 기반 시스템의 지식을 즉각적으로 업데이트하는 것(이는 실시간 작동의 수 많은 사례에 있어서 요구됨)을 극히 어렵게 한다. 또한, 임의의 단일 훈련 샘플에 대해 연산된 손실 함수의 경사는 (일반적으로 분포된 표현으로 인해) 네트워크 의 모든 가중치에 영향을 미칠 수 있기 때문에, 표준 DNN은 새로운 객체를 학습하는 경우에 이전의 지식을 망각 하는 것에 취약하다. 다수의 사건에 대한 동일한 입력의 반복적인 프레젠테이션은 이러한 문제를 완화시키나, 이는 새로운 지식을 시스템에 빠르게 추가하는 것을 극히 어렵게 하는 단점을 갖는다. 이는, 왜 학습이 비현실 적이거나, 학습이 연산 제한된 에지 장치(예, 휴대폰, 태블릿 또는 소형 프로세서)에서 불가능한지에 대한 하나 의 이유이다. 망각의 문제가 설령 해결되었더라도, 훈련 중의 높은 연산 하중, 작은 훈련 단계, 모든 입력의 반 복적인 프레젠테이션으로 인해 에지 장치에 대한 학습은 여전히 비실용적일 것이다. 배치 수명 전반에 걸쳐, 지식을 업데이트할 필요가 있는 단일 연산 에지에 있어서 이러한 제한은 사실일 뿐만 아니라, (새로이 얻은 지식을 신속하게 공유하는 것이 배치 수명 주기 전체에 걸쳐 지능형 제제를 위한 바람직 한 특성인) 분포된 멀티 에지 시스템(예, 네트워크, 네트워크화된 스마트 카메라, 전체 드론 또는 자가 운행 차 량 등)에도 이러한 제한은 유효하다. 역전달 알고리즘을 실행하는 프로세서는, 출력에서 각 뉴런의 에러 기여도를 계산하고 네트워크 계층을 통해 에 러를 다시 분포시킨다. 모든 뉴런의 가중치는 손실 함수의 경사를 계산함으로써 조정된다. 따라서, 네트워크가 오래된 예시를 올바르게 분류할 수 있는 능력을 잃지 않게 하도록 오래된 예시를 재 훈련하지 않고서, 사전 훈 련된 네트워크에 새로운 훈련 예시를 추가할 수 없다. 오래된 예시를 정확하게 분류하는 능력을 상실하는 것을 \"치명적 망각\"으로 부른다. 작동 중에 자주 새로운 정보를 즉각적으로 학습하고 통합해야 할 필요가 있는 실시 간 작동 기기와 연관하여 고려되는 경우, 이러한 망각 문제는 특히 관련된다. 지식을 학습하기 위해 전통적인 DNN을 사용하는 실시간 작동 기기는, DNN을 재 훈련하기 위해 다량의 데이터를 축적해야만 할 수 있다. 실시간 작동 기기의 \"에지\"(즉, 장치 자체, 예컨대, 자가 운행 차량, 드론, 로봇 등)로 부터 중앙 서버(예, 클라우드 기반 서버)로 축적된 데이터를 전달하여 운영자로부터 라벨을 얻은 다음, 에지 상 에 실행된 DNN을 재 훈련한다. 축적 데이터가 많을수록, 시간 및 네트워크 대역폭의 관점에서 전달 프로세스는 비용이 더 많이 든다. 또한, 중앙 서버에 대한 인터리브 훈련은, 시스템의 전체 수명 주기 동안에 저장되는 원 래의 데이터와 새로운 데이터를 결합해야 한다. 이는, 전송 대역폭과 데이터 스토리지의 심각한 제한을 만든다."}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "요약하면, 종래의 역전달 기반 DNN 훈련을 실시간 작동 시스템에 적용하면, 다음의 단점을 겪는다: a. 시스템을 새로운 지식으로 즉각 업데이트하는 것은 불가능하다; b. 서버와 정기적으로 통신하지 않고 지식 업데이트를 위한 상당한 대기 시간을 갖지 않고서, 에지의 배치 사이 클 전반에 걸쳐 학습은 불가능하다; c. 새로운 정보를 학습하려면, 추가 훈련을 위해 모든 입력 데이터를 무기한으로 저장하기 위해 서버 공간, 에 너지 소비 및 디스크 공간 소비가 필요하다; d. 소형 연산 에지 장치 상에서의 학습할 수 없음; 및"}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "e. 저속인 고가 서버 측의 재 훈련 및 재 배치를 하지 않고서는 다수의 에지에 지식을 병합할 수 없음. 발명의 내용 평생 심층 신경망(L-DNN)은, 시간 소모적이고 연산 집약적인 학습을 요구하지 않고서, 경량의 연산 장치(에지) 에서 인공 신경망(ANN) 및 심층 신경망(DNN) 내 연속적인 온라인 평생 학습을 가능하게 한다. L-DNN은 연속 데 이터 스트림으로부터 실시간 학습을 가능하게 하고, 역전달 학습의 다수 반복에 대한 입력 데이터를 저장할 필 요성을 우회시킨다. L-DNN 기술은, 표현이 풍부한 DNN 기반 서브시스템(모듈 A)을 고속 학습 서브시스템(모듈 B)과 결합시켜, 관심 실체 또는 이벤트를 표현하는 특징의 빠르지만 안정한 학습을 달성한다. 이들 특징 세트는, 역전달과 같이 느린 학습 방법론에 의해 사전 훈련될 수 있다. 본 개시에 상세히 기술된 DNN 기반 사례(다른 특징의 설명은 모듈 A 에 대한 비 DNN 방법론을 채용함으로써 가능함)에서, DNN의 높은 수준인 특징 추출 계층은 모듈 B의 고속 학습 시스템으로의 입력으로서 역할하여 익숙한 실체 및 이벤트를 분류하고, 익숙하지 않은 실체 및 이벤트에 대한 지식을 즉각적으로 추가한다. 모듈 B는, 느린 학습의 단점 없이 중요 정보를 학습하고 환경의 특징을 묘사하고 매우 예측 가능하게 캡처할 수 있다. L-DNN 기술은 다른 양상 중에서 시각적이고 구조화된 광, LIDAR, SONAR, RADAR, 또는 오디오 데이터에 적용될 수 있다. 시각적 또는 유사한 데이터의 경우, L-DNN 기술이 시각적 프로세싱에 적용될 수 있는데, 예를 들어, 전체 이미지 분류(예, 장면 검출), 경계 박스 기반 객체 인식, 픽셀 방향 세분화, 및 다른 시각적 인식 작업이 가능하다. 이들은 또한, 비시각적 신호 분류와 같은 비시각적 인식 작업, 및 로봇, 자가 운행 차량, 드론 또는 다른 장치가 환경을 탐색할 때, 지식을 증분으로 추가하여 동시 국부화 및 맵핑(SLAM) 생성된 맵을 업데이트하 는 것과 같은 다른 작업을 수행할 수 있다. L-DNN에서의 메모리 통합은, L-DNN이 더 많은 실체 또는 이벤트(시각적인 용어로, '객체' 또는 '카테고리')를 학습할 때에 메모리가 모듈(B)의 제어 하에 유지되도록 요구한다. 또한, L-DNN 방법론은 다수의 에지 연산 장치 로 하여금 에지 전체에 걸쳐 그들의 지식(또는 입력 데이터를 분류하는 능력)을 병합시킨다. 병합은 P2P 기반으 로 발생할 수 있고, 2개의 모듈 B 사이의 신경망 표현의 직접 교환에 의해서, 또는 여러 에지로부터 다수의 모 듈 B의 표현을 병합하는 중개 서버를 통해 발생한다. 마지막으로, L-DDN은 역전달에 의존하지 않음으로써, 새로 운 입력 데이터를 사용하여 L-DNN 지식을 업데이트하기 위해 훈련 시간, 전력 요구 및 연산 자원을 크게 감소시 킨다. 아래에서 더욱 상세히 논의되는 전술한 개념 및 추가 개념의 모든 조합이(이들 개념이 상호 불일치하지 않는다 면) 본원에 개시된 본 발명의 주제의 일부로서 고려됨을 이해해야 한다. 특히, 본 개시의 끝에서 나타나는 청구 된 주제의 모든 조합은, 본원에 개시된 본 발명의 주제의 일부로서 간주된다. 또한 본원에 참조로서 통합된 임 의의 개시에서 나타날 수도 있는 용어로서, 본원에서 명시적으로 사용된 용어에는, 본원에 개시된 특정 개념과 가장 일치하는 의미가 부여되어야 함을 또한 이해해야 한다. 다음의 도면 및 상세한 설명을 검토하면, 다른 시스템, 프로세스 및 특징은 당업자에게 명백해질 것이다. 이러 한 모든 추가적인 시스템, 공정 및 특징은 본 설명 내에 포함되고, 본 발명의 범주 내에 있고, 첨부된 청구범위 에 의해 보호되도록 의도한다."}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시간 작동 기기에서 지속적인 학습 평생 학습 심층 신경망 또는 평생 심층 신경망(L-DNN)은, 실시간 작동 기기로 하여금 중앙 서버 또는 클라우드 상에서 학습할 필요 없이 에지에서 즉각적으로 학습시킬 수 있다. 이는 네트워크 대기 시간을 제거하고, 실시간 성능을 증가시키며, 원하는 경우 프라이버시를 보장한다. 일부 예에서, 실시간 작동 기기는 L-DNN을 사용하여 현장에서 특정 작업에 대해 업데이트될 수 있다. 예를 들어 L-DNN을 갖고서, 검사 드론은 셀 타워 또는 태양 패 널 어레이의 상단에서 문제점을 식별하는 방법을 학습할 수 있고, 스마트 장난감은 로컬 장치 외부로 공유하지 않기 때문에 사생활에 대해 걱정 없이 사용자 선호도에 기반하여 개인 설정화될 수 있고, 스마트 폰은 설명이 긴 학습을 위해 중앙 서버에 정보 출하 없이 에지에서(P2P 또는 모든 장치와 글로벌하게 학습된 지식을 공유하 고, 또는 자가 운행 차량은 작동하면서 지식을 학습하고 공유할 수 있다. 또한 L-DNN은 오래된 지식을 망각하지 않고서 새로운 지식을 습득할 수 있음으로써, 치명적 망각을 완화하거나 제거한다. 즉, 본 기술은 a) 입력 이미지를 송신 또는 저장할 필요가 없고, b) 시간 소모적인 훈련이 없고, 또 는 c) 대형 연산 자원이 없이, 실시간 작동 기기로 하여금 사용자 입력에 기반하여 에지에서 거동을 지속적으로 그리고 최적으로 조정시킬 수 있다. L-DNN을 갖고서 배치된 후의 학습은, 실시간 작동 기기로 하여금 환경 및 사용자 상호 작용에서의 변화에 적응하도록 하고, 원래 데이터 세트의 결함을 취급하도록 하고, 사용자에게 맞 춤형 경험을 제공하도록 한다. 개시된 기술은 또한 다수의 에지 장치로부터의 지식을 병합할 수 있다. 이러한 병합에는 \"집단 수집\" 및 지식의 라벨링 및 에지 장치 간에 수집된 지식을 공유하는 것, 지루한 중앙 집중식 라벨링 시간을 제거하는 것을 포함 한다. 즉, 하나 이상의 에지 장치로부터의 두뇌 장치는 서로(P2P) 또는 에지에서 장치 중 일부 또는 전부로 다 시 밀어내는 공유 두뇌 장치로 병합될 수 있다. L-DNN은 지식의 병합/융합/공유/조합이 객체 수의 선형보다 빠 르지 않게 메모리 크기를 크게 하는 결과를 보장하고, 실시간으로 일어나고, 소량의 정보가 장치 사이에 교환되 는 결과를 생성한다. 이러한 특징은 현실 세계 애플리케이션에 대해 L-DNN을 실용적으로 만든다. L-DNN은 두 모듈을 특징으로 하는 이질적인 신경망 아키텍처를 구현한다: 1) 제조 시 사전 훈련되고 고정되거나, 데이터 입력의 시퀀스에 기반하여 역전달 또는 기타 학습 알고리즘을 통 해 학습하도록 구성된 신경망(예, 심층 신경망)을 포함하는 느린 학습 모듈 A; 및 2) 매우 적은 훈련 샘플로 시냅스 가중치 및 표현을 동시에 변경할 수 있는 증분 분류기를 제공하는 모듈 B. 이 러한 증분 분류기의 예시적인 인스턴스화는, 예를 들어 적응형 공진 이론(ART) 네트워크, 또는 대조 발산 훈련 신경 네트워크를 갖는 제한형 볼쯔만 기기(RBM)를 포함할 뿐만 아니라, 지원 벡터 기기(SVMs) 또는 다른 고속 학습 감독형 분류 공정과 같은 비 신경 방법을 포함한다. L-DNN의 전형적인 애플리케이션은 다음과 같이 예시되나 이에 한정되지 않는다: 사용자 습관에 기반하여 사용 패턴을 학습한 사물 인터넷(IoT); 사용자로부터 운전 '스타일'을 적응시키고 빨리 즉각적으로 새로운 기술을 학 습하거나 새로운 도로에 주차하는 자가 운행 차량; 인프라스트럭처에 주는 새로운 손상 클래스를 즉각적으로 학습할 수 있고 짧은 학습 기간 후 작동 중에 이러한 손상을 찾아낼 수 있는 드론; 소유자 정체성을 위해 클라우 드에 연결하지 않고서 (거의) 즉각적으로 학습할 수 있는 장난감 또는 친구 로봇과 같은 가정용 로봇; 이전에 결코 보지 못한 객체를 인식하고 이에 반응하며, 새로운 장애물을 피하거나 세계 지도에서 새로운 객체를 위치 시킬 수 있는 로봇; 새로운 부품과 즉각적으로 그것을 조작하는 법을 학습할 수 있는 산업용 로봇; 및 새로운 개인 또는 객체를 학습하고 그것을 빠르게 네트워크에 연결된 다른 카메라에 의해 제공되는 이미지 모음에서 찾 을 수 있는 보안 카메라. 상기 애플리케이션은, 본원에서 기술된 혁신(들)에 의해 잠금 해제되고 가능하게 되는 문제의 클래스의 예시일 뿐이며, 여기서 학습은 특정 애플리케이션에 내장된 연산 장치에서 바로 일어날 수 있 어나고, 서버 상에서 비용이 많이 들고 긴 반복 학습을 수행할 필요 없다. 본원에 개시된 기술은 비디오 스트림, 활성 센서로부터의 데이터(예, 적외선(IR) 이미지, LIDAR 데이터, SONAR 데이터 등), 음향 데이터, 다른 시간 일련 데이터(예, 센서 데이터, 공장 생성 데이터, IoT 장치 데이터, 금융 데이터 등을 포함하는 실시간 데이터 스트림), 및 이러한 데이터 스트림의 임의의 복수 모드 선형/비선형 조합 을 포함하나 이에 제한되지 않는 여러 입력 양상에 적용될 수 있다. L-DNN의 개요 위에 개시된 바와 같이, L-DNN은 고속 학습 모드와 느린 학습 모드를 결합하기 위해, 이질적인 신경망 아키텍처 를 구현한다. 고속 학습 모드에서, L-DNN을 구현하는 실시간 작동 기기는 새로운 지식과 새로운 경험을 빠르게 학습하여 새로운 지식에 거의 즉시 대응할 수 있도록 한다. 이 모드에서, 고속 학습 서브시스템의 학습 속도는 새로운 지식 및 대응하는 새로운 경험에 대해 높은 반면, 느린 학습 서브시스템의 학습 속도는 낮은 값 또는 영 (zero)으로 설정되어 오래된 지식 및 대응하는 오래된 경험을 보존한다. 도 1은 L-DNN 아키텍처의 개요를 제공하고, 여기서 다수의 장치는 마스터 에지/중앙 서버 및 여러 개의 연산 에 지(예, 드론, 로봇, 스마트폰 또는 다른 IoT 장치)를 포함하고 L-DNN 작동을 일제히 실행한다. 각 장치는 감각 적 입력을 수신하고, 이를 느린 학습 모듈 A 및 고속 학습 모듈 B을 포함하는 해당 L- DNN에 공급한다. 각각의 모듈 A는 사전 학습된(고정 가중치) DNN에 기반하고 특징 추출기 역할을 한 다. 입력을 수신하고, 관련 특징을 객체의 압축된 표현으로 추출하고, 이들 표현을 대응하는 모듈 B 에 공급한다. 모듈 B는 이들 객체 표현을 고속 학습할 수 있다. 사용자와의 상호 작용을 통해, 익숙치 않 은 객체에 대한 정확한 라벨을 수신하고, 각 특징 벡터 및 해당 라벨 사이의 연관성을 신속하게 학습하고, 그 결과 이들 새로운 객체를 즉시 인식할 수 있다. 다수의 L-DNN이 상이한 입력을 학습했기 때문에, 이들은 P2P(파선) 또는 중앙 서버(점선)에 연결하여 새롭게 획득된 지식을 융합(용융, 병합 또는 결합)시키고, 아래에 개시된 바와 같은 다른 L-DNN과 공유할 수 있다. 아래에 제시된 예시적인 객체 검출 L-DNN 구현은, 전통적인 객체 검출 DNN \"한번만 보기\"(YOLO)와 비교해 다음 의 파일럿 결과를 생성하였다. 하나의 객체를 구비한 작고(600개의 이미지) 동일한 맞춤형 데이터 세트를 사용 하여 양쪽 네트워크를 훈련하고 검증하였고, 이들 이미지 중 200개는 검증 세트로서 사용하였다. 나머지 400개 의 이미지로부터, 상이한 크기(100, 200, 300, 및 400개의 이미지)인 4개의 훈련 세트를 생성하였다. L-DNN 훈 련의 경우, 훈련 세트의 각 이미지는 한 번만 제시되었다. 전통적인 DNN YOLO의 경우, 훈련 세트를 무작위로 셔 플링함으로써 배치(batch)를 만들었고 훈련은 이들 배치(batch)를 통해 다수의 반복에 걸쳐 진행되었다. 훈련 후, 두 네트워크에 대해 검증을 실행했고, 다음과 같은 평균 정밀도(mAP) 결과를 가졌다:"}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, L-DNN이 400개의 이미지 훈련 세트를 사용하여 훈련한 시간은 1.1 초였고, YOLO에 대한 훈련 시간은 21.5 시간이었다. 이는 엄청난 성과의 개선이다. L-DNN의 메모리 크기는 320 MB인 반면, YOLO 크기는 500 MB였다. 이 들 결과는, L-DNN이 통상적인 DNN YOLO보다 더 나은 정밀도를 달성할 수 있고, 더 작은 데이터 세트, 훨씬 더 빠른 훈련 시간, 및 더 작은 메모리 요건으로 이것을 할 수 있음을 분명히 나타낸다. L-DNN 아키텍처 예시 도 2는 로봇, 드론, 스마트폰 또는 IoT 장치와 같은 실시간 작동 기기가 사용하는 L-DNN 아키텍처 예시를 도시 한다. L-DNN은 2개의 서브시스템, 느린 학습 모듈 A와 고속 학습 모듈 B를 사용한다. 일 구현에 서, 모듈 A는 사전 훈련 DNN을 포함하고, 모듈 B는 고속 학습 적응형 공진 이론(ART) 패러다임을 기반으로 하며, 여기서 DNN은 ART로 마지막 특징 계층(전형적으로, DNN이 완전히 연결된 계층들을 분류하기 전의 마지막또는 마지막에서 두 번째 계층) 중 하나의 출력을 공급한다. 다수의 DNN 계층이 하나 이상의 모듈 B에 (예를 들 어, 다중 스케일, 표결 또는 계층적 형태로) 입력을 제공할 수 있는 다른 구성이 가능하다. 디지털 카메라, 검출기 어레이, 또는 마이크로폰과 같은 입력 출처는, 환경으로부터 정보/데이터(예, 비디 오 데이터, 구조화된 광 데이터, 오디오 데이터, 이들의 조합 등)를 취득한다. 입력 출처가 카메라 시스템 을 포함하는 경우, 실시간 작동 기기를 둘러싸는 환경의 비디오 스트림을 취득할 수 있다. 입력 출처로부 터의 입력 데이터는 모듈 A에 의해 실시간으로 처리되고, 이는 모듈 B에 입력으로서 압축된 특징 신 호를 제공한다. 이 예에서, 비디오 스트림은 모듈 A 및 B에 의해 실시간으로 일련의 이미지 프레임으로서 처리 될 수 있다. 적절한 휘발성 및 비휘발성 메모리 및 적절한 입력/출력 인터페이스를 갖는 그래픽 프로세서 유닛, 필드 프로그래머블 게이트 어레이, 또는 주문형 집적 회로와 같은 적절한 컴퓨터 프로세서에서 모듈 A와 모듈 B 를 구현할 수 있다. 일 구현예에서, 입력 데이터는 모듈 A의 사전 훈련된 심층 신경망(DNN)에 송신된다. DNN은 예시적인 구현 섹션에 상세히 설명된 바와 같이 입력 정보/데이터를 표현하기 위해 사용될 수 있는 특징을 추출하는 데 사용될 수 있는 콘볼루션 계층의 스택을 포함한다. DNN은 배치하기 전에 원하는 수준의 데이터 표현을 달성하기 위해 제조 시 사전 훈련을 받을 수 있다. 이는, 아키텍처를 결정하는 구성 파일 및 훈련 중 획 득된 지식을 표현하는 해당 가중치 세트에 의해 완전히 정의될 수 있다. L-DNN 시스템은, DNN의 가중치가 우수한 특징 추출기라는 사실을 이용한다. 하나 이상의 고속 학습 신경망 분류기를 포함하는 모듈 B를 모듈 A의 DNN에 연결하기 위해, 원래의 DNN(예, 도 2의 계층(206 및 208))에 의한 분류에만 참여한 DNN의 상위 계층 중 일부는 무시되거나 심지어 시스템으로부터 완전히 떨구어 진다. 높은 수준인 특징 추출 계층의 원하는 콘볼루션 원시 결과는, 모듈 B에 대한 입력으로서 역할 하도록 액세스된다. 예를 들어, 원래 DNN은, 다수의 완전 연결되고 평균화된 풀링 계층, 및 훈련 중 에 가중치를 최적화하기 위한 경사 하강 기법을 가능하도록 사용되는 비용 계층을 일반적으로 포함한다. 이들 계층은 DNN 훈련 중에 또는 DNN으로부터 직접적인 예측을 얻기 위해 사용되지만, 모듈 B에 대한 입력을 생성하기 위해 필요하지 않다(도 2에서의 음영은 계층(206 및 208)이 필요하지 않음을 나타냄). 그 대신, 모듈 B의 신경망 분류기에 대한 입력은 DNN의 콘볼루션 계층의 서브세트로부터 취해진다. 모듈 B에 입력을 제공하기 위해 상이한 계층 또는 다수의 계층을 사용할 수 있다. DNN 상의 각 콘볼루션 계층은, 로컬 수용 필드를 사용하여 이전 계층의 작은 영역으로부터 정보를 수집하 는 필터를 포함한다. 이들 필터는 DNN의 콘볼루션 계층을 통해 공간 정보를 유지한다. 기능 추출기에서 하나 이 상의 후기 단계 콘볼루션 계층으로부터의 출력(텐서로서 그림 표현됨)을, 모듈 B의 신경망 분류 기(예, ART 분류기)의 입력 신경 계층로 공급한다. 실시예 구현 섹션에서 상세히 설명된 바와 같이, 전체 이미지 분류 또는 객체 검출을 위해 L-DNN을 설계하는지 여부에 따라, 모듈 A의 각 후기 단계 콘볼루 션 계층과 모듈 B의 각각의 고속 학습 신경망 분류기 사이에 일대일 또는 일대다의 대응이 있을 수 있다. DNN으로부터 모듈 B 시스템으로 전송된 텐서를, 원래 입력 데이터(예, 센서로부터의 원래 이미지)로부터의 표현의 n 계층 스택으로 볼 수 있다. 이 예에서, 스택의 각 요소는 카메라로부터의 입력 이미 지와 동일한 공간 지형을 갖는 그리드로서 표현된다. 각 그리드 요소는, n 스택에 걸쳐, 신경망으로의 실제 입 력이다. 배치 후에 즉각적으로 학습을 촉진하기 위해서, 초기 모듈 B 신경망 분류기는 임의적인 초기 지식이나 모듈 A 의 훈련된 분류를 이용하여 사전 훈련될 수 있다. 입력 출처가 환경에 관한 데이터를 L-DNN에 제공함에 따라, 신경망 분류기는 DNN으로부터 데이터(예, 텐서)를 연속적으로 처리한다. 모듈 B 신경 망 분류기는 빠르고, 바람직하게는 즉석 학습을 사용한다. ART 분류기는 뉴런과 유사한 요소 사이에서 상향식 (입력) 및 하향식 (피드백) 연관 투영을 사용하여, 매치 기반 패턴 학습뿐만 아니라 카테고리 간의 경쟁을 구현 하기 위한 수평 투영을 구현한다. 고속 학습 모드에서, 모듈 A로부터의 입력으로서 신규 특징 세트를 제시하는 경우, ART 기반 모듈 B 는 F1 계층에서 입력 벡터로서 특징을 집어 넣고, 이 입력 벡터와 기존의 가중치 벡터 사이의 거리 작동을 연산하여 F2 계층 내 모든 카테고리 노드의 활성화를 결정한다. 거리는 (ART의 기본 버전인) 퍼지 및, 내적(dot product), 또는 벡터 말단 사이의 유클리드 거리로서 연산된다. 그 다음, 카테고리 노드는 가장 높은 활성화로부터 가장 낮은 것까지 분류되어 이들 사이의 경쟁을 구현하고, 이 순서로 당선 후보를 고려한다. 당선 후보의 라벨이 사용자가 제공한 라벨과 일치하는 경우, 가장 간단한 구현예에서 새로운 입력과 당선 노드에 대한 기존의 가중치 벡터 간에 가중 평균을 취하는 학습 프로세스를 통해 새로운 입력을 일반화하고 커버하 도록, 대응하는 가중치 벡터를 업데이트한다. 당선 객체가 정확한 라벨을 갖지 않는 경우, 입력의 사본인 가중 치 벡터를 갖고서 카테고리 계층 F2에 새로운 카테고리 노드를 도입한다. 어느 경우든, 모듈 B는 이 제 이 입력에 익숙해지고, 다음 프레젠테이션에서 이를 인식할 수 있다. 모듈 B의 결과는, L-DNN이 해결 중인 작업에 따라, 자체에 의해서 또는 모듈 A로부터의 특정 DNN 층으로부터의 출력과의 조합에 의해서 L-DNN의 출력으로서 역할한다. 전체 장면 객체 인식의 경우, 모 듈 B 출력은 전체 이미지를 분류하기 때문에 충분할 수 있다. 객체 검출을 위해, 모듈 B는 모듈 A 활동으 로부터 결정된 경계 박스에 중첩된 클래스 라벨을 제공하여, 각 객체는 모듈 A에 의해 정확하게 위치하고 모듈 B에 의해 정확하게 라벨링되도록 한다. 객체 세분화를 위해, 모듈 A로부터의 경계 박스는 픽셀- 방향 마스크로 대체될 수 있고, 모듈 B는 이들 마스크용 라벨을 제공한다. 모듈 A 및 모듈 B에 대한 더 많은 상세 내용이 아래에 제공되어 있다. 실시간 작동 및 신경망에서 알려지지 않은 개념 일반 L-DNN 그리고 특정 모듈 B는 연속적인 감각 입력에서 실시간으로 작동하도록 설계되기 때문에, 익숙한 객 체가 제시되지 않는 시점에 의해 혼란스럽지 않도록 모듈 B의 신경망을 구현해야 한다. 종래 신경망은, 입력 내 에 라벨링된 객체를 자주 포함하는 데이터 세트를 타겟으로 하며, 그 결과 익숙한 객체의 존재가 없다면 입력을 처리할 필요가 없다. 따라서, L-DNN의 모듈 B에 이러한 네트워크를 사용하기 위해, \"알지 못하는 것\"의 추가 특 별 카테고리를 네트워크에 추가해서, 익숙치 않은 물체를 익숙한(긍정 오류) 것으로 실수로 분류하려는 모듈 B 의 시도를 줄인다. 단독으로 이전에 보이지 않고 라벨링되지 않은 객체를 포함할 수 있는 생 감각 스트림을 처리하는 경우, \"알지 못하는 것\"이라는 이 개념은 유용하다. 이는 모듈 B와 L-DNN으로 하여금 잠재적으로 익숙치 않은 객체를 익숙한 객체로 부정확하게 식별시키는 대신에, 익숙치 않은 객체를 \"알지 못하는 것\" 또는 \"이전에 보이지 않음\"으로서 식별시킨다. \"알지 못하는 것\" 개념을 구현해서 종래의 설계를 확장하는 것은, 네트워크에 바이어스 노드를 추 가하는 만큼 간단할 수 있다. 알려진 객체 클래스 수와 해당 활성화에 따라 이의 영향을 자동적으로 스케일링하 는 버전에서, \"알지 못하는 것\" 개념을 구현할 수도 있다. \"알지 못하는 것\" 개념의 한 가지 가능한 구현은 암시적으로 동적 임계값으로서 작동하며, 이 값은 내부 지식 분포가 여러 카테고리에 걸쳐 평탄하게 분포되는 것과 대조적으로 공통 카테고리에 명확히 집중되는 예측을 선 호한다. 즉, 모듈 B의 신경망 분류기가 객체에 대해 알려진 객체 클래스 사이에 명확한 당선 객체가 있음을 지 시하는 경우, 이는 객체를 당선 클래스에 속하는 것으로 인식한다. 그러나, 다수의 상이한 객체가 유사한 활성 화를 갖는 경우(즉, 명확한 당선 객체가 없는 경우), 시스템은 객체를 모르는 것으로 보고한다. 학습 프로세스 는 라벨을 명시적으로 사용하기 때문에, \"알지 못하는 것\" 구현은 인식 모드에만 영향을 미칠 수 있고 학습 모 드와는 간섭하지 않을 수 있다. ART 네트워크를 사용하여 \"알지 못하는 것\" 개념의 예시적인 구현은 도 3에 제시되어 있다. 입력을 프레젠테이 션하는 동안, 카테고리 계층 F2은 그 노드에 걸쳐 활성화 패턴과 반응한다. 익숙한 객체를 포함하는 입력 은, 도 3의 상위 사례에서와 같이 현저한 당선 객체를 가질 수 있다. 익숙한 객체를 포함하지 않는 입력은, 도 3의 하위 사례에서 나타낸 바와 같이 F2 계층에서 활성의 평평한 분포를 가질 수 있다. 모든 활성화 의 평균을 계산하고 이를 임계값으로 사용하는 것은, 이들 두 사례를 구별하기가 불충분한데, 그 이유는 제2 사 례에서조차 임계값(도 3에서 점선)보다 더 높은 활성을 갖는 노드가 있을 수 있기 때문이다. 1보다 작지 않은 파라미터로 평균을 곱해서 임계값(도 3에서 파선)을 높여서, 도 3의 상위 사례에서처럼 그 위에 명백한 당 선 객체만 남을 수 있도록 한다. 이 파라미터의 정확한 값은 여러 인자에 의존하고, 네트워크 내 카테고리 노드 총 수와 네트워크가 학습했던 카 테고리 수를 기반으로 자동으로 계산될 수 있다. 계산 예는 아래와 같다."}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, θ 는 임계값, C 는 알려진 카테고리 수, N 은 카테고리 노드 수이고, 스케일링 인자 s 는 모듈 A에서 사용된 DNN의 유형을 기반으로 설정되고, L-DNN 준비 동안 미세 조정된다. 이를 너무 높게 설정하면 신경망의 부정 오류 속도가 증가할 수 있고, 이를 너무 낮게 설정하면 긍정 오류 속도를 증가시킬 수 있다.\"알지 못하는 것\" 개념을 활용한 독립적 모듈 B는 다음의 결과를 만들었다. 콜럼비아 객체 이미지 라이브러리 100(COIL-100) 데이터 세트 내의 100개 객체에서 50개 객체를 훈련 세트로 사용하였다. 독립적 모듈 B가 50개의 신규 객체를 \"알지 못하는 것\"으로 인식하도록, COIL-100 데이터 세트로부터의 100개 객체를 모두 사용했다. 훈 련 중에, 독립형 모듈 B의 ART 분류기는 실시간 연산을 시뮬레이션하기 위해 임의의 셔플링 없이 객체를 하나씩 공급받았다. 훈련 후, ART 분류기는 95.5 %의 정확한 인식 속도(조합된 객체 및 \"모르는 것\")를 시현했다. 비교 를 위해, 코일-100 데이터 세트의 모든 100개 객체 중에 셔플링하지 않은 데이터 세트를 종래의 ART에 공급하면 55 %만의 정확한 인식 속도를 나타냈다. 이는 이하에서 논의된 ART의 순서 의존성에 기인할 수 있다. 모듈 B의 ART 분류기가 입력을 인식하지 않는 경우, 원하는 입력을 수정하고 라벨링하는 것은 사용자에게 달려 있다. 인식되지 않은 입력이 중요하지 않은 경우, 사용자는 이를 무시할 수 있고 ART 분류기는 계속해서 이를 \"알지 못하는 것\"이라고 식별할 수 있다. 객체가 사용자에게 중요한 경우, 사용자는 그것을 라벨링할 수 있고, 고속 학습 모듈 B 네트워크는 객체의 특징과 해당 라벨을 지식에 추가할 것이다. 모듈 B는 이 새로운 객체를 계 속 감시하고 더 많은 뷰를 추가하는 추적기 시스템과 결합할 수 있어 객체와 연관된 기능 세트를 풍부하게 한다. 모듈 A의 구현 예시 동작 시, 모듈 A는 객체의 압축된 표현을 추출하고 생성한다. 콘볼루션 심층 신경망은 아래에 개요된 이 작업에 매우 적합하다. 콘볼루션 신경망(CNN)은, 콘볼루션 유닛을 사용하는 DNN이며, 여기서 유닛 필터의 수용성 필드(가중치 벡터)가 입력의 높이 및 폭 치수 전체에 걸쳐 단계적으로 이동된다. 시각적 입력에 적용되는 경우, CNN의 초기 계층에 대한 입력은 높이(h), 폭(w), 및 1 내지 3개의 채널(c)(예, 적색, 녹색, 및 청색 픽셀 구성 요소) 치수를 갖는 이미지인 반면, CNN의 후속 계층에 대한 입력은 선행 계층로부터의 높이(h), 폭(w) 치수 및 필터(c) 수를 갖는 다. 각 필터가 작기 때문에, 파라미터의 수는 완전히 연결된 계층에 비해 크게 감소되고, 여기서, (h, w, c) 각 각으로부터 각각의 유닛으로 그 다음 계층 상에 투영되는 독자적 가중치가 있다. 콘볼루션 계층에 있어서, 각 유닛은 (f, f, c)와 동일한 가중치 수를 갖고, 여기서 f는 공간 필터 크기(전형적으로 3)이며, 이는 h 또는 w보 다 훨씬 작다. 입력의 상이한 공간적 위치에서 각각의 필터를 적용하는 것은, 다음의 의미에서 병진 불변성의 매력적인 특성을 제공한다: 객체가 하나의 공간 위치에 있을 경우에 객체가 분류될 수 있으면, 모든 공간 위치 에서 분류될 수 있는데 그 이유는 객체를 포함하는 특징이 그 공간적 위치와 무관하기 때문이다. 콘볼루션 계층 다음은 보통 서브샘플링(하향 샘플링) 계층이다. 이들은, 입력의 조그만 공간적 윈도우(예, 2 x 2)를 단일 값으로 줄임으로써, 입력의 높이(h) 및 폭(w)을 줄인다. 감소는 평균(평균 풀링) 또는 최대 값(최대 풀링)을 사용하였다. 서브샘플링 계층의 응답은 이미지의 작은 이동에 대해 불변적이고, 이러한 효과는 전형적 인 CNN의 다중 계층에 걸쳐 축적된다. 추론에서, 다수의 콘볼루션 및 서브샘플링 계층이 이미지에 적용되는 경 우, 출력은 병진, 회전, 스케일링, 및 심지어 왜곡, 예를 들어 훈련 세트로부터의 숫자 \"3\"과 조그만 원을 합체 하여 쓴 숫자 \"3\"에 동일한 응답을 갖는 수기의 끊김없는(펜을 들지 않고 쓴) 숫자로 훈련된 네트워크와 같이 입력의 다양한 변형에 대해 인상적인 안정성을 나타낸다. 이러한 불변성은 특징 공간을 제공하며, 이 공간에서 입력의 암호화는 시각적 변화에 향상된 안정성을 갖고, 입 력이 변할 시(예, 객체가 이미지 프레임 내에서 이동하거나 회전함), 출력 값은 입력 값보다 훨씬 적게 변화함 을 의미한다. 이는 학습을 가능하게 한다. 예를 들어, 소수의 픽셀 정도 이동된 객체를 갖는 2개의 프레임의 암 호화가 유사성을 거의 또는 전혀 갖지 않는 다른 방법에서는 학습하는 것이 어려울 수 있다. 또한, 대형 데이터 세트로부터 필터를 학습하기 위해 GPU 가속 경사 하강 기법을 최근에 사용되면서, CNN은 잘 훈련된 객체 클래스에 대한 인상적인 일반화 성능에 도달할 수 있다. 일반화는, 훈련된 클래스 내에서 훈련된 이미지와 동일하지 않은 테스트 이미지에 대해 네트워크가 유사한 출력을 만들 수 있음을 의미한다. 클래스를 정의하는 주요 규칙을 학습하기 위해 많은 양의 데이터를 취한다. 네트워크가 많은 클래스에 대해 훈련을 받는 경우, 하위 계층은 그의 필터가 모든 클래스 사이에서 공유되며, 모든 자연적인 입력에 대한 양호한 규칙의 세 트를 제공한다. 따라서, 다른 작업에 대한 초기화로 사용되는 경우 또는 보다 높은 수준의 새로운 표현을 위해 예비프로세서로서 하위 계층을 사용하는 경우에, 하나의 작업에 대해 훈련 받은 DNN은 뛰어난 결과를 제공할 수 있다. 자연 이미지는 통계적 특성의 보편적 세트를 공유한다. 잘 훈련된 신경망의 내부를 시각화한 최근 작업에 서 볼 수 있는 바와 같이, 하위 계층에서 학습된 특징은 상당히 클래스 독립적인 반면에 상위 계층은 상위일수 록 점점 클래스 의존적이다.L-DNN은 모듈 A에서 CNN의 이러한 능력을 활용하여, 모듈 B가 분류를 위한 객체 특징을 고품질로 압축하고 일반 화된 표현을 갖도록 한다. 이러한 장점을 증가시키거나 최대화하기 위해, L-DNN에 사용된 DNN은 가능한 상이하 고 수 많은 객체에 대해 사전 훈련될 수 있어서, 높은 수준의 특징 계층의 객체 특이성이 L-DNN의 고속 학습 능 력과 간섭하지 않도록 한다. 모듈 B의 구현 예시 작동 시, 모듈 B는 빠르고 치명적 망각 없이 새로운 객체를 학습한다. 적응형 공진 이론(ART) 모듈 B의 구현 예시 하나는 ART 신경망이다. ART는 카테고리 노드 간의 경쟁을 활용하여 각 객체 프레젠테이션 에 대한 당선 노드를 결정함으로써 치명적 망각을 회피한다. 만약 이 당선 노드가 객체에 대한 정확한 라벨과 연관된 경우에만, 학습 알고리즘은 그 가중치를 업데이트한다. 각 노드가 하나의 객체만 연관되기 때문에, 학습 알고리즘은 당선 노드만을 위한 가중치를 업데이트하고, ART에서의 임의의 학습 에피소드는 오직 하나의 객체에 만 영향을 끼친다. 따라서, 새로운 객체를 시스템에 추가하는 경우에 이전의 지식과 간섭하지 않으며, 오히려 ART는 단순히 새로운 카테고리 노드를 생성하고 대응하는 가중치를 업데이트한다. 불행하게도, ART는 문헌에 기술된 바와 같이, 그것이 L-DNN 모듈 B로서 성공적 사용을 하지 못하게 하는 여러 단점을 갖는다. 이러한 단점 중 하나, 구체적으로 \"알지 못하는 것\" 개념의 결여는 ART 특이적이지 않으며 위에 서 논의되었다. ART 특이적 문제 및 이들 문제에 대한 해결책의 목록을 아래에 개시한다. 고전적인 퍼지 ART는, 이 디자인의 핵심 부분인 보수 코딩으로 인해 희박한 입력을 잘 취급하지 않는다. 희박한 입력을 보수 코딩하는 경우, 보수 부분은 대부분의 구성 요소에 있어서 높은 활성화를 갖는데, 그 이유는 희박 한 입력에 풍부하게 존재하는 제로(zero)의 보수는 일(one)이기 때문이다. 입력의 보수 부분에 모두 일(one)을 가지면, 거리 연산 중에 서로 상이한 입력을 분리하는 것이 매우 어려워져서 시스템은 혼란스럽게 된다. 다른 한편, DNN과 같은 강력한 특징 추출기는, 높은 수준의 기능 추출에 단독적으로 희박한 신호를 제공하는 경향이 있다. ART 패러다임을 유지하나 고전적인 퍼지 설계 및 보수 코딩을 멀리하는 것은, L-DNN의 모듈 B에서 ART를 사용하기 위해 유용성이 많아진다. 해결책 중 하나는 보수 코딩을 제거하고 퍼지 ART에 의해 사용된 퍼지 및 거 리 메트릭을 내적(dot product) 기반의 메트릭을 이용해 대체하는 것이다. 이 내적 기반 메트릭은, 결과가 정규 화되고 퍼지 ART에 대한 다른 변화가 필요하지 않다라는 장점을 갖는다. 신경망의 ART 계열은 입력 프레젠테이션의 순서에 매우 민감하다. 즉, ART는 일관 특성이 결여되어 있고, 입력 의 상이한 순서는 ART 네트워크에서 대응하는 객체의 다른 표현을 유도한다. 불행하게도, L-DNN과 같은 실시간 작동 시스템은, 자신의 훈련 데이터를 센서로부터 수신하면서 그들의 훈련 데이터를 소모하기 때문에, 일관성을 제공하기 위해서는 자신의 훈련 데이터를 셔플링할 수 없다. 종종 실시간 작동 중에, 센서는 후속 객체의 모든 샘플에 앞서 제1 객체의 대부분 또는 모든 샘플을 제공하므로, 시스템은 한 번에 하나의 객체 표현을 학습한다. 이는 몇 개의 노드만이 제1 객체를 표현하는 상황으로 유도할 수 있는데, 다른 객체로부터의 경쟁 없이 시스템 은 실수를 하지 않을 수 있고, 따라서 객체 표현을 개선할 수 있기 때문이다. 다른 한편으로, 후속 객체는 과표 현될 수 있는데, 제1 객체의 표현에 의해 이미 대부분 점유되는 하이퍼 공간으로 표현을 짜집기하기 때문이다. 전술한 \"알지 못하는 것\"의 메커니즘은 초기 단계에서 경쟁을 도입하고, 제1 객체의 미세 입자 표현을 보장한다. 후술하는 통합은 후속 객체에 대한 과표현을 감소시키거나 제거한다. 통합은, 제한된 메모리를 갖는 에지 장치에 특히 유익한 객체 표현의 메모리 크기를 또한 감소시킨다. 시스템이 분류할 수 없는 객체의 모든 뷰에 대한 새로운 카테고리 노드를 생성하는 것은, 새로운 객체를 입력으로서 추가 함에 따라 ART 시스템에 대한 메모리 크기의 일정한 증가를 유도한다. 전술한 바와 같이 객체의 실시간 동작 및 순차적인 프레젠테이션 중에, 시스템은 각각의 연속 객체에 대해 초선형적으로 증가하는 노드 수를 생성한다. 일부 경우에, 시스템은 객체 수에 대해 노드 수의 지수 성장을 경험한다. 따라서, 종래의 ART를 사용하는 모듈 B의 메모리 크기는 객체 수와 선형으로 증가하는 것보다 더 빠른 속도로 성장할 수 있다. 최악의 경우에, 이 성 장은 지수일 수 있다. 통합은 객체 수와 선형적인 것보다 더 빠르지 않게 메모리 성장을 제한하고, L-DNN이 학 습한 각 객체에 대해 고정된 크기의 최적에 준하는 표현을 생성시킬 수 있다. 완전한 L-DNN 구현 예시 L-DNN 분류기 도 4는 전체 이미지 분류에 대한 L-DNN 구현 예시를 나타내고 모듈 A의 코어로서 변형된 VGG-16 DNN을 사용한다. 소프맥스(Sofmax)와 마지막 2개의 완전 연결된 계층은 원래의 VGG-16 DNN로부터 제거되고, ART 기반 모듈 B는 VGG-16 DNN의 완전 연결된 제1 층에 연결된다. 유사하나 훨씬 더 간단한 L-DNN은, VGG-16 대신 알렉스 네트(Alexnet)을 사용하여 생성될 수 있다. 이는 매우 간단하고 연산적으로 저렴한 시스템이고, 현대의 스마트 폰 상에서 실행되고, GPU 또는 다른 특수 프로세서를 필요로 하지 않고, 스마트폰 카메라에 의해 제공된 여러 입력 프레임으로부터 임의의 객체 세트를 학습할 수 있다. L-DNN 그리드 기반 검출기 이미지에서 관심 대상 객체를 검출하는 한 가지 방법은, 이미지를 그리드로 분할하고 각 그리드 셀에서 분류를 실행하는 것이다. L-DNN의 이러한 구현에서, CNN의 다음 특징은 특히 유용하다. 위에 기술된 계층에 걸쳐 종적이고 계층적인 조직화 외에도, 각각의 계층은 표면 형태 조직을 유지하는 데이터 를 처리한다. 이는, 네트워크 또는 커넬, 스트라이드, 또는 패드 크기에서 얼마나 심층인지에 관계없이, 이미지 상의 특정 관심 영역에 대응하는 특징을 계층의 유사한 영역에서 다양한 해상도로 발견할 수 있음을 의미한다. 예를 들어, 객체가 이미지의 왼쪽 상단 코너에 있는 경우, 대응하는 특징은 계층의 계층적 구조를 따라 각 계층 의 왼쪽 상단 코너에 위치할 것이다. 따라서, 모듈 B를 계층 내의 각각의 위치에 두면, 모듈 B로 하여금 이미지 의 특정 위치 상의 분류를 실행시킬 수 있고, 임의의 익숙한 물체가 이 위치에 존재하는지의 여부를 결정시킬 수 있다. 또한, 입력으로서 사용된 각 DNN 계층(또는 스케일)마다 하나의 모듈 B만을 생성해야 되는데, 그 이유는 동일한 특징 벡터가 이미지의 위치와 상관없이 동일한 객체를 표현하기 때문이다. 따라서, 오른쪽 상단 모서리에 있는 하나의 객체를 학습하면 모듈 B로 하여금 이미지 내의 어느 곳에서나 이를 인식시킬 수 있다. 모듈 B를 분리하 기 위해 입력으로서 상이한 크기(스케일)의 다수 DNN 계층을 사용하면 다중 스케일의 검출을 허용한다. 다음 프 로세스에서처럼 전체 이미지를 더 미세하게 프로세싱하지 않고, 이미지 내의 객체의 위치를 미세하게 조정하는 데 이를 사용할 수 있다. 이 프로세스에서 모듈 A는 분류를 위해 모듈 B로 (예를 들어, 공개적으로 이용 가능한 ExtractionNet에서 7 x 7 로) 가장 거친 스케일의 이미지를 제공한다. 객체가 왼쪽 가장자리로부터 두 번째 그리고 최상부 가장자리로부 터 네 번째인 셀에 위치한다고 모듈 B가 말하는 경우, 객체의 위치를 더 개선하기 위해, 더 미세한 DNN 입력의 해당 부분만(예, 동일한 ExtractionNet 내의 14 Х 14)을 분석해야 한다. 다중 스케일 검출의 다른 애플리케이션은, 계층 크기가 서로의 배수가 아닌 DNN 설계를 사용할 수 있다. 예를 들어, DNN이 30 Х 30 계층을 갖는 경우, 이는 2 Х 2(압축 인자 15), 3 Х 3(압축 인자 10), 5 Х 5(압축 인 자 6)인 계층으로 감소될 수 있다. 도 5에 도시된 바와 같이, 모듈 B를 이들 압축된 DNN 각각에 두는 것은 객체 의 거친 위치를 제공한다(502, 504, 506으로 표시됨). 그러나, 이들 모듈 B의 출력을 조합하면(508로 표시됨), 공간 해상도는 중앙에서 해상도가 높고 가장자리를 향해 해상도가 낮은 비균일한 8 Х 8 그리드가 된다. 이 해상도를 달성하기 위해 시스템은 모듈 B 연산만 (2 Х 2) + (3 Х 3) + (5 Х 5) = 38회만 실행하는 반면, 균일한 8 Х 8 그리드를 연산하기 위해, 모듈 B 연산을 64회 한다. 더 적은 연산으로 계산되는 것 이외에, 중앙 36개 위치에 대한 도 5의 다중 스케일 그리드의 해상도는 균일한 8 Х 8 그리드의 해상도와 같거나 더 미세하다. 따라서, 다중 스케일 검출로, 시스템은 견줄만한 균일 그리드의 연산 자원의 단지 60 %를 사용하여 객체의 위치를 더욱 정확하게 파악할 수 있다. 이러한 성능 차이는 더 큰 계층에 대해 증가하는데, 그 이 유는 (균일한 그리드에 대한 연산의 수를 나타내는) 합계의 제곱이 (불균일한 그리드에 대한 연산의 수를 나타 내는) 제곱의 합계보다 빠르게 커지기 때문이다. 불균일한(다중 스케일) 검출은, 뷰의 중심 내 객체가 로봇의 경로에 있을 가능성이 가장 클 때처럼 이동식 로봇 에 특히 이로울 수 있고, 충돌 위협을 주지 않는 주변부의 객체보다 더 정확한 검출로부터 이점이 있을 수 있다. 이미지 세분화를 위한 L-DNN 이미지의 경우, 객체 주위에 경계 박스를 배치하고 이를 연관된 클래스(예, \"개\")로 라벨링하는 작업으로서 객 체 검출을 일반적으로 정의한다. 이전 섹션의 그리드 기반 방법 이외에, 경계 박스를 갖는 이미지의 하나 이상 의 영역을 선택한 다음 그 박스 내의 특징을 특정 클래스로 분류하면서 동시에 경계 박스 위치 오프셋을 회귀함 으로써, 객체 검출 기법을 일반적으로 구현한다. 이 객체 검출의 방법을 구현하는 알고리즘은 지역 기반 CNN(R- CNN), 고속 R-CNN, 및 초고속 R-CNN을 포함하지만, 국부화를 분류 정보에 직접 의존하지 않게 하는 임의의 방법을 검출 모듈로서 대체할 수 있다. 이미지 세분화는 이미지에서 전체 또는 모든 픽셀에 대한 클래스 라벨을 결정하는 작업이다. 세분화는 의미 세 분화(여기서, 동일한 클래스의 두 개의 분리 객체로부터의 개별 픽셀이 모호함), 및 인스턴스 세분화(여기서, 동일한 클래스의 두 개의 분리 객체로부터의 개별 픽셀이 고유하게 식별되거나 인스턴스됨)로 분할될 수 있다. (R-CNN, 고속 R-CNN, 또는 초고속 R-CNN과 같은) 객체 검출 방법의 경계 박스 출력을 취하고 그 박스에서 가장 눈에 띄는 객체를 세분화함으로써, 이미지 세분화를 일반적으로 구현한다. 그 다음 경계 박스와 연관된 클래스 라벨을 세분화된 객체와 연관시킨다. 클래스 라벨을 경계 박스에 줄 수 없다면, 세분화 결과를 폐기한다. 최종 세분화된 객체는 인스턴스 정보를 가질 수도 있고 아닐 수도 있다. 이러한 세분화 방법을 구현하는 알고리즘 하 나는 마스크 R-CNN이다. 네트워크의 R-CNN 계열에 기반한 이미지 검출 또는 세분화를 위한 L-DNN 디자인을 도 6에 제시하고 있다. 마스 크 R-CNN과 같은 정적 분류 모듈을 사용하는 이미지 세분화 프로세스를 고려하기 바란다. 이 시나리오에서, 정 적 분류 모듈을 L-DNN 모듈 B로 대체할 수 있다. 즉, 네트워크의 세분화 경로는 변하지 않고 유지되 며, 영역 제안을 평소와 같이 만들고 이어서 세분화한다. 정적 분류 모듈을 갖는 사례처럼, L-DNN 모듈 B 가 임계값을 통과한 부정 클래스 예측을 반환하는 경우(예를 들어, 전술한 바와 같이 네트워크가 훈련을 받지 않거나 세분화된 영역을 \"알지 못하는 것\"이라고 인식하는 경우에 발생하는 것과 같음), 세분화 결과를 폐기한 다. 유사하게, L-DNN 모듈 B가 허용 가능한 클래스 예측을 반환할 때, 세분화 결과는 정적 분류 모듈과 마 찬가지로 유지된다. 정적 분류 모듈과 달리, L-DNN 모듈 B는 사용자 피드백을 통해 전자로부터 후자 로 상태를 변화하기 위한 연속적인 적응을 제공한다. 예를 들어 사용자가 소셜 미디어 프로필에서 객체를 선택 및 태그하는 경우, 경계 박스 및 클래스 라벨을 통해 사용자 피드백을 직접적으로 제공할 수 있거나, 예를 들어 사용자가 비디오에서 객체를 선택하는 경우, 간접적 피드백을 통해서 사용자 피드백을 제공될 수 있고, 이는 새로운 객체 클래스에 대한 연속 피드백을 L-DNN에 제 공하도록 비디오를 통해 추적될 수 있다. 시간이 지남에 따라 신규 클래스 네트워크를 분류하는 방법을 L-DNN에 게 훈련시키기 위해 이런 피드백을 사용한다. 이 프로세스는 네트워크의 세분화 구성 요소에 영향을 끼치지 않 는다. 이 패러다임에서 모듈 B의 배치는 또한 약간의 유연성을 갖는다. 모듈 B에 대한 입력을 모듈 A 콘볼 루션 계층의 출력에 직접 연결시켜, 클래스 라벨이 세분화 출력과 조합되어 라벨링된 세분화 출력을 만들 수 있도록 해야 한다. 모듈 A 및 B 둘 모두가 영역 제안 단계의 결과를 갖도록 함으로써, 이 제약 사항을 완수할 수 있다. 모듈 A는 모듈 B의 동적 부분에 의존해서는 안 된다. 즉, 모듈 B는 그 네트워크의 가중치에 적 응하나 모듈 A는 정적 상태이기 때문에, 만약 모듈 B가 가중치를 바꾸어 그 결과를 모듈 A에 전달하면, 모듈 A 는 성능 강하를 볼 가능성이 있고, 이는 대부분의 정적 신경망이 네트워크의 입력 표현의 갑작스러운 변화를 다 룰 수 없는 무능력에 기인한다. 두뇌 장치 통합 및 두뇌 장치 융합 L-DNN을 구현하는 다수의 실시간 작동 기기는, L-DNN을 통해 새로운 정보를 즉각적으로 개별 학습할 수 있다. 일부 상황에서는, 다음 섹션에서 설명된 여러 사용 사례에서 개요된 것처럼 실시간 작동 기기 사이에 지식을 공 유하는 것이 유리할 수 있다. 실시간 작동 기기는 에지에서 새로운 지식을 학습하기 때문에, 각각의 실시간 작 동 기기는 새로운 지식을 공유하기 위해 중앙 서버로 또는 다른 실시간 작동 기기(들)로 새로운 정보의 압축되 고 일반화된 표현(모듈 B에서 시냅스 가중치 매트릭스의 관점에서 네트워크에 표현됨)을 전송한다. 다음의 단계 를 구현함으로써, 각 실시간 작동 기기에 의해 획득된 지식은 중앙 서버 내에서 또는 에지 장치 상에 직접 추출 되고, 첨부되고, 통합될 수 있고, 중앙 집중식 또는 P2P 통신을 통해 다른 실시간 작동 기기와 공유될 수 있다. ㆍ현장 배치 시 새로운 정보 학습 - 전술한 바와 같이 실시간 작동 기기는 L-DNN을 통해 즉각적으로 새로운 정 보를 학습할 수 있다. 실시간 작동 기기가 새로운 객체 및/또는 새로운 지식을 직면하고 있음을 사용자가 알 수 있는 경우, 사용자는 새로운 객체에 대한 라벨을 제공하고 고속 학습 모드를 작동시켜 실시간 작동 기기가 새로 운 객체 및/또는 새로운 지식을 즉각적으로 학습할 수 있도록 한다. 이 방식으로, 실시간 작동 기기는 자신의 거동을 변경할 수 있고 새로운 객체 및/또는 새로운 지식에 빠르게 적응할 수 있다. ㆍ새로운 지식 통합 - 하나 이상의 객체를 즉각적으로 학습한 후, 시스템은 고속 학습 모듈 B에서 통합 프로세 스를 실행한다. 이 프로세스는 새로운 객체(들)의 표현(들)을 이전에 공지된 객체의 표현과 통합하고, 네트워크 일반화 능력을 개선하고, 모듈 B의 메모리 크기를 감소시킨다. ART 네트워크에 기초한 예시적인 구현을 이하에서 상세히 설명한다. ㆍ통합된 개별 두뇌 장치에서 다른 장치로 통신 - 작동 중 또는 미션 완료 후 임의의 시점에서, 실시간 작동 기 기는 자신의 고속 학습 모듈(모듈 B)의 통합 가중치 매트릭스를 유선 또는 무선 통신 채널을 통해 중앙 서버(예, 클라우드 기반 서버)로 송신할 수 있다. 일부 예에서, 각각의 실시간 운영 기기의 고속 학습 모듈의 가중치 매트릭스는 외부 저장 장치에 다운로드될 수 있고, 중앙 서버에 물리적으로 결합될 수 있다. 중앙 서버 를 이용할 수 없거나 바람직하지 않은 경우, 통신은 실시간 작동 기기(에지 장치) 간의 P2P 방식으로 발생할 수 있다. ㆍ두뇌 장치 융합(또는 용융, 병합, 조합) - 몇몇 실시간 작동 기기로부터의 가중치 매트릭스를 중앙 서버 또는 에지 장치 중 하나에서 수집한 이후에 중앙 서버 또는 에지 장치는, 각 실시간 작동 기기로부터 새로이 획득되 는 지식을 단일 가중치 매트릭스 내에 조합하고, 압축하고, 통합하는 융합 유틸리티를 실행할 수 있다. 융합 유 틸리티는 최종 매트릭스의 메모리 크기를 감소시키고, 전체 시스템의 정확도를 유지하면서 중복성을 제거한다. ART 네트워크에 기반한 예시적인 구현이 아래에 상세히 설명되어 있다. ㆍ융합 후 개별 두뇌 장치를 업데이트 - 그 후, 두뇌 장치 융합 중에 생성된 최종 가중치 매트릭스를 유선 또는 무선 통신 채널을 통해 하나 이상의 실시간 작동 기기에 다운로드하거나, 이를 물리적 외부 저장/메모리 장치에 다운로드하고 저장/메모리 장치를 실시간 작동 기기에 물리적으로 전달한다. 이 방식으로, 다수의 실시간 작동 기기로부터의 지식은 통합될 수 있고, 이들 기기 각각에 의해 학습되는 새로 운 지식은 다른 실시간 작동 기기와 공유될 수 있다. ART를 이용한 두뇌 장치 통합 및 융합 프로세스의 구현 예시 도 7a는 ART를 이용한 예시적인 두뇌 장치 통합 및 융합 프로세스를 도시한다. 다음과 같이 기본 ART 프로세스 를 확장한다. 계층 F2 내 ART의 카테고리 노드 각각은 특정 객체를 표현하고, 각 객체는 이를 표현하는 하 나 이상의 카테고리 노드를 갖는다. 도 7a의 좌측은, 계층 F1에 의해 활성화된 계층 F2 내 카테고리 노드에 대한 가중치 패턴을 도시한다. 각각의 가중치 패턴은 계층 F1에 제공된 다수의 실제 특징 입 력으로부터 학습되고 일반화된 입력 패턴을 표현한다. ART에서의 학습은 카테고리 노드 및 해당 객체가 경 쟁에서 당선하고 문제의 객체를 올바르게 식별하는 경우에만 발생함을 유의한다. 도 7a의 중간은, 상이한 객체에 대한 다수의 입력을 ART 네트워크에 제시한 이후, 계층 F2에서 상이 한 카테고리 노드에 대한 가중치 패턴을 나타낸다. 각각의 가중치 패턴은 대응하는 노드가 대응하는 객체 라벨을 식별하도록 학습되는 입력 버전을 일반적으로 표현한다. 도 7a의 중간에 있는 가중치 패턴은, 도 7a의 우측에 도시된 통합 입력이 된다. 일반적으로 통합 또는 융합 시점에서, 원래 입력을 시스템에 이용할 수 없다. 다른 한편, 가중치 패턴 의 수집은, ART 네트워크가 훈련 동안 노출되는 모든 입력에 대해 일반화된다. 이와 같이, 가중치 패 턴은 원래 입력보다 보다 양호하게 입력의 중요한 특징을 표현하고, 훈련 과정 동안 실제 입력 을 대체하는 역할을 할 수 있다. 통합은 가중치 패턴을 실제 입력의 대체물로서 사용한다. 통합 동안 다음 단계가 일어난다: ㆍ기존의 가중치 매트릭스(예, 도 2의 가중치 벡터의 매트릭스)의 가중치 벡터를 통합 입력 세트(도 7a의 우측) ai = wi에 추가하고, 여기서 a는 입력 벡터이고, w는 가중치 벡터이고, i는 1 내지 네트워크의 기존 카테고리 노드의 숫자이다. ART 네트워크가 보수 코딩을 사용하는 경우, 가중치 벡터의 보수 절반은 탈보수되고 벡터의 초기 절반으로 평균화된다(ai = (wi + (1 - wic))/2). 통합 입력 세트의 각 벡터는 각각의 카테고리 노드 로부터 추출된 해당 라벨을 수신한다. ㆍ기존의 모든 F2 노드 및 대응하는 가중치가 ART 네트워크에서 제거되므로, ART 네트워크는 그의 공백 초기 상 태에 있다. ㆍ통합 입력 세트는 무작위로 셔플링되고, ART 네트워크는 원래 입력을 학습했던 동일한 방식으로 이 세트를 학 습한다. 무작위 셔플링은 종래의 ART 네트워크에서 순서 의존성의 영향을 감소시키고 ART 네트워크로 하여금 더 컴팩트하고(더 적은 카테고리 노드가 생성됨) 더 최적인(더 나은 일반화) 표현을 구축시킬 수 있다. 통합 입력 세트에 대한 가중치를 사용하게 되면, 단일 벡터가 수 많은 원래 입력 벡터를 대체하는 장점을 추가 로 가지게 되어, 통합 공정은 원래 학습 프로세스보다 복잡성을 줄이고 더 빠른 연산 시간을 갖을 수 있다.통합 프로세스는 L-DNN 기반 시스템 작동 중에 언제든지 일어날 수 있다. 이는 모듈 B의 ART 기반 구현의 메모 리 크기를 감소시키고 ART 기반 시스템의 순서 의존성을 감소시킨다. 순서 의존성을 감소시키는 것은 L-DNN에 기반한 임의의 실시간 작동 기기에 유익한데, 그 이유는 이러한 작동 중에 작동하면서 시스템에 들어오는 감각 적 입력 순서를 변경할 방법이 없기 때문이다. 사용자 행위에 의해, 또는 메모리 크기가 너무 커지거나(예, 임 계 값 크기에 도달 또는 초과) 작동 지속 시간에 규칙적으로 기반하는 경우에 의해, 자동적으로 통합을 작동시 킬 수 있다. ART 네트워크에 의도적으로 제시된 COIL 데이터 세트에 대해, 마치 실시간으로 작동되고 차례로 객체를 보았던 것처럼, 예시적인 통합을 수행하였다. 초기 훈련은 통합 훈련보다 4.5배 더 길었다. 통합은 메모리 크기를 25 % 감소시켰고, 객체 인식 성능을 50 % 정확성에서 75 % 정확성으로 개선했다. 순서 결함을 감소시키기 위해 훈련 데이터 세트를 처음에 셔플링한 경우에 대해, 통합은 여전히 성능 개선을 나타냈다. 시스템이 초기 훈련 후에 이미 잘 압축되었으므로 상당한 메모리 크기 감소는 없었지만, 객체 인식에 대해 정확성 비율은 평균적으로 87 %에서 98 %로 올라갔다. 이들 실험 결과는 예기치 않은 큰 성능 개선을 나타낸다. 융합은 통합 연장으로, 통합 훈련 세트는 하나 이상의 ART 네트워크의 가중치 매트릭스로부터 조합된다. 이는 통합의 모든 장점을 이어받고, ART 네트워크의 일반화 특성을 활용한다. 그 결과, 다수의 융합된 ART 네트워크 가 동일한 객체에 대한 지식을 갖는 경우, 다수의 ART 네트워크에 걸쳐 이러한 객체의 모든 유사한 표현을 ART 학습 프로세스에 의해 자연스럽게 조합시키면서, 구별되는 모든 표현을 보존한다. 이는 객체 표현을 스마트하게 압축하고 추가적으로 융합 시스템의 메모리 크기 감소를 유도한다. 예를 들어, 하나의 ART 인스턴스를 이용해 COIL 데이터 세트로부터 50개의 객체를 학습하고, 다른 ART 인스턴스 를 이용해 33개의 객체를 학습하는 것은(17개의 객체가 2개의 세트에 대해 동일함), 처음 인스턴스의 경우 92.9 % 정확성, 제2 인스턴스에 대해 90.5 % 정확성을 유도한다. 이들을 함께 융합시키면 두 ART 인스턴스 모두에 의 해 학습된 66개의 고유한 객체 모두에 대해 97 % 정확한 네트워크를 생성한다. 또한, 융합 버전은 2개의 네트워 크가 단순하게 갖는 힘의 조합인 메모리 크기의 83 %를 갖는다. 또한, 융합 버전의 메모리 크기는, 제1 네트워 크를 제2 네트워크의 신규 입력(중첩된 17개의 객체를 제외함)만을 조합하는 경우보다 3 % 작다. 따라서, 실제 로 융합은 스마트한 압축과 정확성을 증가시켜 객체 표현을 개선한다. 입력이 무작위로 셔플링되지 않는 경우, 융합의 결과는 정확성 측면에서 훨씬 더 분명하다: 85.3 % 및 77.6 % 정확한 네트워크는 96.6 % 정확한 네트워 크로 융합되었고, 두 네트워크가 조합된 메모리 크기의 84.6 %를 갖는다. 이들 융합 실험 결과는 예기치 않은 큰 성능 개선을 나타낸다. 개선된 성능에 대한 상황적 정보 사용 L-DNN 기반 시스템은, 현재 객체 정보와 상황적 정보를 조합함으로써 성능 정확도를 더 향상시킬 수 있다. 상황 적 L-DNN은 특정 객체가 입력 스트림에서 동시에 일어날 가능성이 있음을 학습할 수 있다. 예를 들어, 낙타, 야 자나무, 모래 언덕, 및 오프로드 차량은 사막 장면(도 7b 참조)에서 전형적인 객체인 반면, 집, 스포츠 카, 참 나무, 개는 도시 근교 장면에 전형적인 객체이다. 픽셀 레벨에서 국부적으로 모호한 정보 및 드론 입력으로서 얻어진 정보를, 상황에 따라 두 개의 객체 클래스(예, 낙타 또는 개)에 매핑할 수 있다. 두 경우 모두, 객체의 관심 초점은 모호한 표현을 갖고, 이는 저해상도 이미지에서 자주 있는 것이다. 사막 장면에서, 낙타의 픽셀화 된 이미지는 객체 간에 학습된 장면 및 과거의 연관성에 대한 글로벌 정보에 의해 풀릴 수 있지만, 그럼에도 \" 낙타\"는 L-DNN에 의해 추론되는 4 번째로 가능성 있는 클래스일 뿐이고 로컬 픽셀 정보만에 기반하면 가장 가능 성 있는 것은 \"말\"이다. 상황적 객체(모래 언덕, 오프로드 차량, 야자나무)가 과거에 \"낙타\"와 연관되어, 상황 적 분류기는 \"말\" 클래스를 \"낙타\" 클래스 선호로 뒤집을 수 있다. 유사하게, \"하우스\", \"스포츠 카\", 및 \"참나 무\"를 포함하는 도시 장면에서는, 동일한 픽셀 세트는 \"개\"에 매핑될 수 있다. 보수로서, 상기 예의 낙타에서처럼 객체를 모호하거나 이상한 것으로 식별하는 경우, L-DNN 시스템은 분석자/사 용자에게 객체를 더욱 자세히 보도록 촉구할 수 있다. 이러한 이상 검출 및 경보 서브시스템은, 장면에 속하지 않는 관심 객체를 식별하는 것과 정상적인 객체의 정체성을 확실하게 하는 문맥을 사용하는 것 사이에서, 균형 을 잡을 수 있다. 무한 회귀 문제점, 즉 상황적 모듈이 객체 클래스를 생산하기 전에 객체 분류를 필요로 하는 점은, 최대 확률로 상황적 분류기에 입력 라벨을 제공함으로써 해결된다. 이 방식으로 객체를 각각 고정 시, 상황적 분류기는 객체 라벨의 추측을 반복적으로 개선할 수 있다. L-DNN은 방대한 양의 라벨링되지 않은 데이터를 레버리지할 수 있다. 방대한 양의 비구조화된 콘텐츠는, 어떤 라벨조차 없이 L-DNN의 모듈 A에 대한 귀중한 훈련 데이터를 제공한다. 욕심 많은 계층-현명한 사전 훈련(greedy layer-wise pre-training)으로 알려진 기법은, DNN으로 하여금 각 계 층을 상향식으로 차례로 훈련함으로써 감독 없는 학습을 수행시킬 수 있다. 계층 방향 훈련의 메커니즘은, 대조 발산 노이즈 제거 자동 인코더 및 콘볼루션 자동 인코더를 포함한다. 자동 인코더는 입력을 취하고, 가중치 및 전달 함수를 통해 암호화하고, 입력 재건 오류의 관점에서 출력을 평가한다. 계층을 훈련한 이후, 그 출력은 다 음 계층의 입력이 된다. 사전 훈련된 네트워크는 임의의 심층 네트워크의 이점을 가지며, 즉 이는 종종 유용한 계층적 특징 관계를 캡처하고, 예를 들어 계층-1의 가장자리와 계층-2의 코너와 다른 가장자리 그룹, 및 후속 계층에서 높은 순서인 데이터 특이적 특징을 학습한다. 또한, 콘볼루션 변이체는 콘볼루션 네트의 내장된 병진 불변성을 갖는다. 이후 감독 학습을 선행하는(\"미세 조정\") 경향이 있기 때문에, 이 프로세스는 사전 훈련으로 불린다. 많은 경우 에 사전 훈련된 네트워크의 성능은 사전 훈련 없는 것보다 우수하다. 라벨은 분석자에게 일부 부담을 주기 때문 에 라벨링된 데이터가 대량으로 있는 경우에, 사전 훈련된 네트는 사전 훈련되지 않은 네트를 이기지 못한다. 사전 훈련된 \"환경 특이적\" 네트는 라벨링 부담을 덜면서, 다른 사전 훈련된 네트에 비해 L-DNN 시스템의 인식 성능을 개선할 것이다. 즉, 분석자 보고의 결과로 제한된 라벨과 라벨링되지 않은 라벨에 대해 훈련된 DNN은, 심하게 라벨링된 데이터 세트뿐만 아니라 비교적 적은 수의 분석자 보고로부터 훈련된 것들에 비해 개선된 성능 을 유도한다. 마지막으로, 모듈 B의 구현으로서의 ART는, 감독 없는 학습을 수행할 수 있을 때에 또 다른 이점을 갖는다. ART 는 \"반-감독(semi-supervised)\"으로 간주될 수 있고, 이는 학습을 위한 라벨을 필요로 하지 않지만 사용 가능한 경우 라벨을 이용할 수 있다는 점을 의미한다. 미감독 학습 모드에서 작동하면서 각 노드에 대해 가장 일치하는 관찰 이미지 영역과 프레임에 대한 검색 정보를 저장함으로써, ART는 라벨링되지 않은 데이터의 조직화를 보조 한다. 각 ART 노드는 분석자로 하여금 유사한 많은 관찰을 액세스하고 조사시킬 수 있다. L-DNN의 사용 사례 예시 다음의 사용 사례는, L-DNN이 다양한 분야의 기술적 문제를 해결할 수 있는 방법의 비제한적인 예시이다. 검사를 자동화하기 위한 L-DNN의 사용: 이미지의 단일 또는 다수의 출처 산업 인프라, 예를 들어 전력선, 셀 타워 또는 풍력 터빈을 위한 검사 프로세스를 자동화하고자 하는 드론 서비 스 제공업체를 고려하기 바란다. 기존 해결책은, 검사자가 검사할 필요가 있는 핵심 구성 요소를 포함하는 프레 임을 찾기 위해 드론 비디오를 몇 시간씩 시청해야 한다. 검사자는 각 프레임에서 이들 주요 구성 요소를 수동 으로 식별해야 한다. 대조적으로, L-DNN 기반 보조 장치를 식별 도구에 도입할 수 있다. 종래의 느린 DNN 제조 시점 훈련 중에 사전 훈련된 세트로서, 관심 객체 또는 이상에 대한 라벨을 포함하는 데이터를 L-DNN 기반 보조 장치에 제공할 수 있 다. 후술하는 바와 같이, 고속 학습 모드 동안 사용자는 이러한 세트에 추가 내용을 만들 수 있다. 도 8은 L-DNN 기반 보조 장치의 작동을 도시하고, \"스마트(smart)\" 드론 상에 또는 \"덤(dumb)\" 드론에 의해 획 득된 비디오를 검토하는 데 사용되는 컴퓨터에 이를 포함할 수 있다. 드론은, 텔레콤 타워, 태양광 패널 어레이, 풍력 터빈 팜, 또는 전력선 분배 설비와 같은 구조를 검사한다(이들은 단지 예시 적인 구조이고, 다른 것을 고려할 수 있음). 드론 작동자는 드론의 수동 제어를 사용하거나, 드론 기능을 자동으로 감독할 수도 있다. 제어실 내의 분석자와 같은 분석자는, 드론이 비행 중 또는 비행 후에 드론 으로부터 감각 입력(예, 비디오, LIDAR 등)을 처리하는 L-DNN 시스템 내의 모듈 B에 라벨 을 제공할 수 있다. 초기에, 드론은 L-DNN의 사본을 자신의 개별 로컬 분류기로 수신한다. 드론이 이들 전력선 , 셀 타워, 및 풍력 터빈을 검사하면서 비디오 프레임을 취득하는 경우, L-DNN의 모 듈 A는 사전 훈련된 데이터에 기반하여 비디오 프레임으로부터 이미지 특징을 추출한다. 그 다음 모 듈 B는 이들 특징에 기반하여 각 객체에 대해 가능한 라벨을 제공한다. 이 정보는 사용자에게 전달된 다. 사용자가 라벨이 불만족스러움을 발견하면, 사용자는 고속 학습 모드를 참여시켜 모듈 B 네트워크를 정확한 라벨로 업데이트할 수 있다. 이 방식으로, 사용자 제공 정보는 현재 라벨을 보정할 수 있다. 따라서, 고 속 학습 서브시스템은 일회 시도 학습을 활용하여 전력선, 셀 타워, 풍력 터빈 등과 같이 이미 학습된 객체의 위치와 특징을 업데이트 후 제1 프레임에서처럼 초기에 결정할 수 있다. 이전에 촬영한 비디오를 분석하는 경우, 이는 이미 사용자가 수정 사항을 도입한 이후를 의미한다. 따라서, 시스템은 시간이 지남에 따라 더많이 알게 되고, 사용자의 도움으로 시간이 지남에 따라 더 잘 식별할 수 있게 된다. 도 9는 본원에 기술된 L-DNN 기술이 도 8의 일반화된 사례처럼 어떻게 적용될 수 있는지 도시하고, 여기서 다수 의 드론(예, 덤 드론(800 및 900) 및 스마트 드론)은 데이터를 동기식으로 또는 비동기식으로 수집한다. 각 드론과 연관된 L-DNN에 의해 학습된 정보는 병합될 수 있고(조합되거나 융합될 수 있음) 다른 드론으로 다시 밀어내거나, 드론 사이에서 P2P로 공유되거나, 모듈 B를 포함하는 중앙 서버와 공유될 수 있다. 상기 중앙 서버는 개별 L-DNN 학습 정보를 병합하고, 드론(800, 900)에 의해 획득된 데이터로부터 유도된, 텔레콤 타워 , 태양광 패널 어레이, 풍력 터빈 팜, 또는 전력선 분배 장치에 관한 정보에 노출되지 않 은 드론을 포함하는 모든 드론으로 병합된 정보를 다시 밀어내지만, 병합 공정으로 인해 이들 항목을 이제 이해하고 분류할 수 있다. 창고 운영을 자동화하기 위한 L-DNN의 사용: 여러 출처로부터 지식을 통합 및 융합 전술된 시스템을, 일제히 작동하는 다수의 기기나 카메라(고정식, 드론 결합식 등)용으로 연장할 수 있다. 다양 한 지리적 위치에 있는 대형 창고를 여러 개 갖는 회사를 고려하기 바란다. 대형 창고에 수동 재고를 조사하면 많은 인력 시간이 필요하고, 창고는 보통 이 시간 동안 폐쇄되어야 한다. 기존 자동화 해결책은 숨겨질 수 있는 적층된 객체를 식별하는 데 어려움이 있다. 또한, 기존 자동화 해결책에서, 한 지리적 위치에서 학습된 정보는 다른 위치로 전달되지 않는다. 일부 예에서, 상이한 지리적 위치에서 수집된 방대한 양의 데이터 때문에, 이들 자동화 해결책은 새로운 데이터를 학습하고 새로운 데이터에 대한 조치를 취하는 데 몇 주 소요될 수 있다. 대조적으로, 본원에 설명된 L-DNN 기술은 도 10에 도시된 바와 같이 창고, 산업 시설, 또는 유통 센터 환경에 적용될 수 있고, 여기서 센서(예, 고정 카메라(1010a 내지 1010c) 또는 로봇 또는 드론 상에 장착된 이동 카메 라)는 센서에 연결된 다양한 L-DNN 모듈을 통해 재고 신품목을 즉각적으로 학습할 수 있다. 또한, 작동자(805 및 1005)는 비 중앙 방식으로 다양한 L-DNN 모듈에 새로운 정보를 가르칠 수 있다. 이 새로운 지식을 중앙으로 통합하거나 P2P로 통신하고 각 개별 장치(예, 카메라)에 융합시킨 후에 다시 밀어낼 수 있다. 예를 들어, 도 10의 고정 카메라(1010a 내지 1010c)(집합적으로, 카메라)를 고려한다. 이들 카메라 각각은 컨베이어 벨트 상의 객체에 대응하는 비디오 이미지를 획득하고 그 이미지를 대응하는 L- DNN(106a 내지 106c)(총괄적으로, L-DNN)에 제공한다. L-DNN은 이미지에서, 예를 들어 검사, 정렬 또는 다른 유통 센터 기능을 위해 알려진 객체를 인식한다. 각각의 L-DNN은 작업자(805 및 1005)에 의한 평가로서 또는 \"알지 못하는 것\"으로서 미지의 객체를 태그한 다. 예를 들어, 미지의 객체를 제시하는 경우, L-DNN(106a)은 작동자에 의한 분류를 위해 미지 객체 를 플래그 설정한다. 유사하게, L-DNN(106c)은 작동자에 의한 분류를 위해 미지 객체를 플래 그 설정한다. L-DNN(106b)이 미지의 객체를 제시 받는 경우, 이는 단순히 미지의 객체를 \"알지 못 하는 것\"으로 태그한다. L-DNN에 결합된 독립형 모듈 B(104d)는, 작동자(805 및1005)로부터 L-DNN(106a 및 106c)에 의해 획득된 지식을 병합하여, 모듈 B(104b)가 객체(1040 및 1060)의 미래 인스턴스를 인식할 수 있 도록 L-DNN(106b) 내의 모듈 B(104b)로 이를 밀어 낸다. 각 장치에 대한 L-DNN은, 폴 마킹, 출구 표지판 등의 특징, 이들의 조합 등과 같이, 창고에서 기존 랜드마 크를 인식하도록 사전 훈련될 수 있다. 이는 시스템으로 하여금, 센서가 장착된 무인 차량 또는 센서(예, 카메 라)에 의해 획득된 이미지에서 위치를 삼각 측량할 수 있게 한다. 각 차량의 L-DNN은 전술한 사용 사례와 정확히 동일한 방식으로 작동한다. 이 방식으로, 다수의 무인 차량으로부터의 지식을 통합하고, 융합하고, 각각 의 무인 차량에 재분포시킬 수 있다. 모든 위치로부터의 지식의 통합 및 융합은, 상기 통합 및 융합 섹션에 기 술된 바와 같이 중앙 서버에 의해 수행될 수 있고; 추가적으로 P2P 융합도 적용될 수 있다. 따라서, 재고 조사 는 복수의 창고에서 취해질 수 있고, 창고 운영에 최소한의 방해로 지식을 통합할 수 있다. 전체 모바일 장치 내에서 L-DNN의 사용 소비자 스마트폰 및 태블릿 같은 소비자 휴대 장치, 또는 공중 안전 요원 또는 제1 응답자가 공공 안전을 위해 사용하는 모바일 카메라, 신체 착용 카메라 및 LTE 휴대 장치와 같은 전문 장치의 분포된 네트워크를 고려하기 바란다. 사진을 찍는 경우와 같이, 소비자의 주변 환경을 이해하기 위해 소비자 장치를 사용할 수 있다. 이들 경우에 본원에 기술된 L-DNN 기술은, 도 11에 도시된 스마트폰 또는 태블릿 장치(1110, 1120, 및 1130)에 적용 될 수 있다. 개인(예, 사용자(1105 및 1106))은 각각 장치(1110, 1130)의 L-DNN 모듈에 지식을 가르칠 수 있고, 이 정보를 모듈(B104)을 포함하는 P2P 또는 서버에 병합시킬 수 있다. 서버는 병합된 지식을 다시 일부 또는 전체 접속된 장치(가능하게는 원래 훈련에 참여하지 않은 장치도 포함함)로 밀어낸다.L-DNN 모듈은, 예를 들어 사용자가 촬영한 사진에 이미지 처리 기술을 적용하는 것을 학습할 수 있고, 여기서 사용자는 사진 양태와 연관된 일부 맞춤화된 동작(예, 이들 객체 또는 영역 클래스에 필터나 이미지 왜곡을 적 용)을 각 L-DNN에게 가르칠 수 있다. 학습된 통합 동작은 P2P 또는 장치에 걸쳐 총괄적으로 공유되거나 병합되 거나 조합될 수 있다. 또한, L-DNN 기술은 스마트 폰 사용의 일반화된 사용 사례에 적용될 수 있고, 여기서 입 력 변수는 감각적이거나 비감각적(스마트폰을 임의로 사용하는 패턴)일 수 있다. 입력 변수와 출력 변수의 임의 조합일 수 있는 이들 사용 패턴은, 스마트 폰 수준에서 학습될 수 있고, 중앙 L-DNN 모듈로 밀어내고, 병 합되고, 다시 개별 장치로 들어올 수 있다. 다른 예에서, 경찰은 L-DNN을 실행하는 전문 장치를 사용하여 미아, 수배자, 또는 수상한 객체를 찾을 수 있다. 이러한 상황에서 경찰 및/또는 제1 응답자는 시간을 낭비할 수 없다. 경찰 및/또는 제1 응답자에게 제공되는 기 존 해결책은, 수동으로 분석되고 조정되기 위해 카메라로부터의 비디오 피드를 필요로 한다. 이러한 해결책은 객체를 분석하고 식별하기 위해 중앙 서버를 사용해야 하기 때문에 너무 오래 걸린다. 즉, 이러한 해결책은 주 요 지연 문제를 갖는데, 그 이유는 비디오 데이터가 클라우드/중앙 서버에서 분석될 필요가 있기 때문이다. 이 는, 데이터를 수신할 때 즉시 조치를 자주 취해야 하는 제1 응답자 또는 경찰에게 심각한 장애물일 수 있다. 또 한, 비디오 데이터를 중앙 서버에 연속적으로 전송하는 것은 통신 채널에 변형을 줄 수 있다. 대신, 휴대 전화, 신체 착용 카메라 및 LTE 휴대폰 장치에 L-DNN을 사용함으로써, 에지 자체에 데이터를 학습하 고 분석할 수 있다. 소비자는 자신의 장치를 현장에서 맞춤화하는 것을 학습할 수 있고, 경찰/제1 응답자는 개 인/객체의 위치를 찾고 제공할 수 있을 뿐만 아니라, 경찰이 능동적으로 볼 수 없는 관심 개인/객체를 찾고 식 별할 수 있다. L-DNN은 원격 서버 상에서 조작자로부터 학습하는 대신에, 장치 상에서 경찰로부터 현장에서 학 습하기 위해 고속 학습 모드를 활용할 수 있고, 중앙 집중화된 학습과 연관된 지연 문제를 줄이거나 제거한다. 도 1은, 소비자가 한 장면에 전화를 가리키고 전체 장면 또는 장면의 일부(객체, 장면의 일부, 예를 들어 하늘, 물 등)를 라벨링할 때, 이미지 내의 구성 요소를 라벨링하기 위해 휴대폰에서 L-DNN의 작동을 도시한다. 또한, 경찰관이 비디오 프레임에 액세스할 수 있고 수배자/객체를 식별한다. 휴대폰이 비디오 프레임을 취득하면, 모듈 A는 사전 훈련된 데이터에 기반하여 이들 프레임으로부터 이미지 특징을 추출할 수 있다. 그 다음 모듈 B는 이들 특징을 사용하여 각 객체에 대해 가능한 라벨을 제공할 수 있다. 예를 들어, A라는 사람이 이웃 B에 살고 과거에 이웃 B에서 관찰된 경우, A라는 사람은 이웃 B의 \"거주자\"로 라벨링될 수 있다. 따라서, 고속 학습 서브시스템은 일회 시도 학습을 활용하여 학습의 제1 프레임 직후에 즉시 집, 나무와 같이 이미 학습한 객체의 상대적인 위치 및 특징을 결정할 수 있다. 더욱 중요한 것은, 중앙 서버 상의 응답자 는 새로 찾을 객체를 서버측 L-DNN에 소개할 수 있고, 이는 필요에 따라 로컬 제1 반응자에게 융합되고 분배될 것이다. 이 사용 사례는 이전 사용 사례와 매우 유사하지만, 오래된 것을 망각하지 않고서 빨리 새로운 객체를 학습하는 L-DNN의 능력을 잘 이용한다. 검사 및 재고 수집 동안은 느린 학습 모드에서 시간 압력과 메모리 통합은 보통 거의 이루어지지 않으나, 제1 응답자의 사례에서는 다수의 장치로부터 지식을 가능한 한 빨리 통합하고 융합하 는 것이 중요할 수 있어서, 영역 내의 모든 장치가 수배자 또는 미아를 찾기 시작할 수 있게 한다. 따라서, 제1 응답자 한 명에 의해 가이드되는 새로운 객체를 신속하게 학습하고 거의 순간적으로 그것을 서버에 통합하고 영 역 내 제1 응답자 모두에게 분배하는 L-DNN의 능력은, 이러한 사용 사례의 경우 엄청난 이점이 된다. 데이터 센터에 있는 L-DNN으로 종래 DNN을 교체 본원에 설명된 L-DNN 기술을, 도 12에 도시된 바와 같이, 대형 데이터 센터의 개별 연산 노드 또는 서버 에서 DNN 프로세스에 대한 연산 시간을 감소시키기 위한 도구로서 적용할 수 있다. L-DNN 기술은 DNN에서의 학 습을 여러 차수의 양으로 가속화한다. 이러한 특징은 서버 상의 연산 자원의 필요성을 크게 감소시키거나, 연산 자원의 소비를 줄이는 데 사용될 수 있고, 여기서 훈련 시간이 보통 시/일/주를 필요로 하는 대용량 데이터 세 트 전반에 걸쳐 정보를 수 초로 학습할 수 있다. L-DNN의 사용은, 데이터 센터의 서버 자원을 전반 적으로 더 좋게 활용하고 전력 소비를 감소시킨다. 결론 전술한 바와 같이, L-DNN은 신경망 시스템에 있어서 즉각적인(즉석) 학습을 제공할 수 있다. 역으로, 전통적인 DNN은 새로운 객체를 학습하기 위해 수천 회 또는 수백만 회의 반복적인 사이클을 종종 필요로 한다. 반복 사이 클 당 취한 단계의 크기가 클수록, 손실 함수의 경사가 실제 성능 증가로 이어질 가능성은 더 적다. 따라서, 이 러한 전통적인 DNN은 훈련 샘플마다 자신의 가중치에 작은 변화를 만든다. 이는 새로운 지식을 즉각적으로 추가하는 것을 매우 어렵게 만든다. 대조적으로, 고속 학습 신경망을 갖는 L-DNN은, 매우 적은 훈련 예시를 이용해 객체 표현을 안정적으로 학습할 수 있다. 일부 예에서, 하나의 훈련 예는 L-DNN에 대해 충분할 수 있다. L-DNN은 종래의 DNN에 더하여 고속 훈련 신경망을 사용하기 때문에, 전통적인 DNN을 성가시게 하는 \"치명적인 망각\"에 강하다. \"치명적인 망각\"에서, 새로운 입력을 DNN에 제공하면, DNN의 모든 가중치는 모든 샘플 프레젠 테이션과 조정되어, 새로운 입력을 학습할 시 과거 입력을 분류하는 방법을 DNN으로 하여금 \"망각하게\" 한다. 단순히 새로운 입력을 포함한 전체 입력 세트를 재학습함으로써 치명적 망각을 회피할 수 있지만, 재학습은 너 무나 오래 걸려서 실용적이지 않을 수 있다. 일부 기존 접근법은, 가중치의 중요도에 기반하여 가중치를 선택적 으로 동결하고 DNN의 서브네트워크를 훈련시키거나, 치명적인 망각을 피하기 위해 모듈형 접근법을 사용한다. 그러나, 이러한 접근법은 모두 느리고 DNN을 훈련하기 위해 다수의 반복 사이클을 필요로 한다. 대조적으로, L- DNN은 재훈련 없이 안정적인 고속 학습 용량을 달성하는 방법을 제공한다. L-DNN은 또한 단일 예시 및/또는 단 일 반복 사이클로 객체 표현을 안정적으로 학습하는 것을 용이하게 한다. 본 발명의 다양한 구현예가 설명되고 예시되었지만, 당업자는, 본원에서 설명된 바와 같은 기능 및/또는 그 결 과 및/또는 하나 이상의 장점을 수행하기 위한 다양한 다른 수단 및/또는 구조를 쉽게 상상할 것이며, 이러한 변형 및/또는 수정의 각각은 본원에 설명된 본 발명의 구현예의 범위 내에 있는 것으로 간주된다. 본 명세서에 기술된 모든 매개 변수, 치수, 재료 및 구성은 예시적인 것이며 실제 매개 변수, 치수, 재료 및/또는 구성은 본 발명의 교시가 사용되는 특정 응용(들)에 따라 달라질 것이라는 것을 의미한다. 당업자는 본원에서 기술된 특정 한 본 발명의 구현예와 많은 등가물을 일상적인 실험을 사용하여 인식하거나 확인할 수 있을 것이다. 따라서, 전술한 구현예는 단지 예로서 제시되고, 첨부된 청구범위 및 이에 등가인 범위 내에서, 본 발명의 구현예들이 구체적으로 기술되고 청구된 것과 다르게 실시될 수 있다는 것을 이해해야 한다. 본 개시의 발명의 구현예는 본 원에 기술된 각각의 개별적인 특징, 시스템, 물품, 재료, 키트 및/또는 방법에 관한 것이다. 또한, 이러한 특징, 시스템, 물품, 재료, 키트 및/또는 방법이 서로 일치하지 않는 경우, 둘 이상의 이러한 특징, 시스템, 물 품, 재료, 키트 및/또는 방법의 임의의 조합이 본 개시의 발명의 범위 내에 포함된다. 전술한 구현예들은 임의의 다양한 방식으로 구현될 수 있다. 예를 들어, 구현예는 하드웨어, 소프트웨어 또는 이들의 조합을 사용해 구현될 수 있다. 소프트웨어로 구현될 때, 소프트웨어 코드는 단일 컴퓨터에 제공되거나 다중 컴퓨터에 분산되어 있는지 여부에 관계없이 임의의 적합한 프로세서 또는 프로세서 모음에서 실행될 수 있 다. 또한, 컴퓨터는 랙 장착 컴퓨터, 데스크톱 컴퓨터, 랩톱 컴퓨터, 또는 태블릿 컴퓨터와 같은 다수의 형태로 구 현될 수 있음을 이해해야 한다. 또한, 컴퓨터는, 일반적으로 컴퓨터로 간주되지 않지만, PDA, 스마트폰, 또는 다른 임의의 적절한 휴대용 또는 고정된 전자 장치를 포함하는 적절한 처리 능력을 갖는 장치에 내장될 수 있다. 또한, 컴퓨터는 하나 이상의 입력 및 출력 장치를 가질 수 있다. 무엇보다 이들 장치는 사용자 인터페이스를 제 시하기 위해 사용될 수 있다. 사용자 인터페이스를 제공하기 위해 사용될 수 있는 출력 장치의 예는, 출력의 시 각적 프레젠테이션을 위한 프린터 또는 디스플레이 스크린이거나, 출력의 청각적 프레젠테이션을 위한 사운드 생성 장치 또는 스피커를 포함한다. 사용자 인터페이스에 사용될 수 있는 입력 장치의 예는 마우스, 터치 패드 및 디지털 태블릿과 같은 포인팅 장치 및 키보드를 포함한다. 다른 예로서, 컴퓨터는 음성 인식을 통하거나 다 른 청각 포맷으로 입력 정보를 수신할 수 있다. 이러한 컴퓨터는 임의의 적합한 형태로 하나 이상의 네트워크에 의해 상호 연결될 수 있고, 기업 네트워크, 및 인텔리전트 네트워크(IN) 또는 인터넷과 같이, 로컬 영역 네트워크 또는 광역 네트워크를 포함한다. 이러한 네 트워크는 임의의 적합한 기술에 기반할 수 있고 임의의 적절한 프로토콜에 따라 작동할 수 있고, 무선 네트워크, 유선 네트워크 또는 광섬유 네트워크를 포함할 수 있다."}
{"patent_id": "10-2019-7035963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "본원에서 요약된 다양한 방법 또는 프로세스는 다양한 운영 체제 또는 플랫폼 중 하나를 사용하는 하나 이상의 프로세서에서 실행가능한 소프트웨어로서 코딩될 수 있다. 이러한 소프트웨어는 다수의 적합한 프로그래밍 언어 및/또는 프로그래밍 툴 또는 스크립팅 툴 중 임의의 것을 사용해 작성될 수 있고, 또한 프레임워크 또는 가상 머신에서 실행되는 실행 가능한 기계 언어 코드 또는 중간 코드로 컴파일될 수 있다. 또한, 다양한 본 발명의 개념이 하나 이상의 방법으로서 구현될 수 있으며, 그 중 하나가 실시예로서 제공되었 다. 상기 방법의 일부로서 수행되는 작동은 임의의 적절한 방식으로 명령 받을 수 있다. 따라서, 구현예는 도시 된 것과 상이한 순서로 작동이 수행되도록 구성될 수 있으며, 예시적인 구현예에서 순차적인 작동으로 나타나더라도, 일부 작동을 동시에 수행하는 것을 포함할 수 있다. 본원에 언급된 모든 간행물, 특허 출원, 특허, 및 기타 참조문헌은 그 전체가 참고로 원용된다. 본원에 정의되고 사용된 모든 정의는, 사전적 정의, 참조로서 통합된 문서 내의 정의 및/또는 정의된 용어의 일 반적인 의미를 통제하는 것으로 이해해야 한다. 본원에서 사용된 \"하나\"는, 달리 명백히 나타내지 않는 한 \"적어도 하나\"라는 의미로 이해해야 한다. 본원에서 사용된 \"및/또는\"이라는 문구는, 본 명세서 및 청구범위 내에서, 접합된, 즉 어떤 경우에는 결합하여 존재하고 다른 경우에는 분리적으로 존재하는 요소, 중 \"둘 중 하나 또는 둘 다\"를 의미하는 것으로 이해해야 한다. \"및/또는\"으로 열거된 다중 요소는 동일한 방식, 즉, 접합된 요소 중 \"하나 이상의\"로 해석되어야 한다. \"및/또는\" 절에 의해 구체적으로 식별된 요소들, 구체적으로 식별된 요소와 관련이 있거나 관련이 없는 다른 요 소 이외의 다론 요소가 선택적으로 존재할 수 있다. 따라서, 비한정적인 예로서, \"포함하는\"과 같은 개방형 언 어와 함께 사용될 때, \"A 및/또는 B\"에 대한 언급은: 일 구현예에서 A만(선택적으로 B이외의 요소를 포함); 다 른 구현예에서, B만(선택적으로 A이외의 요소를 포함); 또 다른 구현예에서는 A 및 B 둘 다(선택적으로 다른 요 소를 포함); 등을 지칭할 수 있다. 본 명세서 및 청구범위에 있어서 본원에서 사용되는 바와 같이, \"또는\"은 위에 정의된 바와 같이 \"및/또는\"과 동일한 의미를 갖는 것으로 이해해야 한다. 예를 들어, 목록에서 물품을 분리할 때 \"또는\" 또는 \"및/또는\"은 포 괄적인 것, 즉, 적어도 하나를 포함하되, 하나를 초과하는 숫자 또는 요소 목록, 및, 선택적으로, 추가적인 목 록에 없는 물품 또한 포함하는 것으로 해석되어야 한다. 반대로, 예컨대 \"단지 하나의\" 또는 \"정확하게 하나 의\", 또는 청구범위에서 사용될 때, \"구성되는\"과 같이, 명확하게 지시된 용어들 만이, 숫자 또는 요소 목록에 서 정확히 하나의 요소를 포함하는 것을 지칭할 것이다. 일반적으로, 본원에서 사용되는 용어 \"또는\"은, 예컨대 \"어느 하나의,\" \"중 하나의,\" \"단지 하나의,\" 또는 \"정확히 하나의\" 와 같이 배타적인 용어가 앞에 올 때, 배타 적 대안(즉, \"하나 또는 다른 하나이되 둘 다는 아님\")을 나타내는 것으로 해석되어야 한다. 청구범위에서 사용 되는 경우, \"본질적으로 이루어지는\"은 특허법 분야에서 사용되는 바와 같이 통상적인 의미를 가질 것이다. 본 명세서 및 청구범위에 있어서 본원에서 사용되는 바와 같이, 하나 이상의 요소의 목록에 관하여 \"적어도 하 나의\"라는 어구는, 요소 목록 내의 임의의 하나 이상의 요소로부터 선택된 적어도 하나의 요소를 의미하되, 요 소 목록에 구체적으로 나열된 각 요소 및 모든 요소 중 적어도 하나를 반드시 포함하고, 요소 목록 내의 요소의 임의의 조합을 배제할 필요는 없다. 이러한 정의는, 또한, 구체적으로 식별된 요소 이외에 상응 요소가 구체적 으로 식별된 요소와 관련이 있는지 여부와 상관없이, 문구 \"적어도 하나\"가 지칭하는 요소의 목록 내에 선택적 으로 존재할 수 있게 한다. 따라서, 비한정적인 예로서, \"A 및 B 중 적어도 하나\"(또는, 등등하게 \"A 또는 B 중 적어도 하나,\" 또는, 동등하게 \"A 및/또는 B 중 적어도 하나\")는: 일 구현예에서, B가 없이, 적어도 하나의 A, 선택적으로는 둘 이상(및 선택적으로 B외의 요소를 포함함); 다른 구현예에서, A가 없이, 적어도 하나의 B, 선 택적으로 둘 이상(및 선택적으로 A외의 요소를 포함함); 또 다른 구현예에서, 적어도 하나의 A, 선택적으로 둘 이상, 및 적어도 하나의 B, 선택적으로 둘 이상(및 선택적으로 다른 요소를 포함함); 등을 지칭할 수 있다. 상기 명세서뿐만 아니라, 청구범위에서 \"포함하는\", \"갖는\", \"함유하는\", \"포함되는\", \"보유하는\", \"구성되는\" 등과 같은 전환구는, 개방형으로서, 즉, 포함하되 이에 한정되지 않음을 의미한다는 것을 이해해야 한다. \"구성 되는\" 및 \"본질적으로 구성되는\"의 전환구 만이, 미국 특허청 특허 심사 절차 매뉴얼 2111.03에 기술된 바와 같 이, 폐쇄형 또는 반 폐쇄형 전환구에 상응한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7a 도면7b 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2019-7035963", "section": "도면", "subsection": "도면설명", "item": 1, "content": "당업자는, 도면들이 주로 예시적인 목적을 위한 것이며 본원에 기술된 본 발명의 주제의 범위를 제한하려는 것 이 아님을 이해할 것이다. 도면은 반드시 일정한 비율은 아니며; 일부 경우에, 본원에 개시된 본 발명의 주제의 다양한 양태들은 도면에서 과장되거나 확대되어 상이한 특징의 이해를 용이하게 할 수 있다. 도면에서, 유사한 참조 부호는 일반적으로 유사한 특징(예, 기능적으로 유사한 요소 및/또는 구조적으로 유사한 요소)을 지칭한다. 도 1은 평생 심층 신경망(L-DNN)의 개요를 도시하고 이는 다수의 연산 에지에 관한 것으로서 데이터 스트림에 대해 개별적으로 작용하거나, P2P 또는 중개 연산 서버를 통해 연결된다. 도 2는 예시적인 L-DNN 아키텍처를 도시한다. 도 3은 신경망에서 알려지지 않은 개념의 구현을 도시한다. 도 4는 하나의 예시적인 구현으로서 VGG-16 기반 L-DNN 분류기를 도시한다.도 5는 불균일한 다중 스케일의 객체 검출을 도시한다. 도 6은 객체 세분화를 위한 마스크 R-CNN 기반 L-DNN을 도시한다. 도 7a는 적응형 공진 이론(ART) 신경망을 사용한 통합 및 융합을 도시한다. 도 7b는, 어떻게 국부적으로 모호한 정보, 예를 들어 낙타(제1 장면, 사막) 또는 개(제2 장면, 교외)의 픽셀화 된 이미지가, 객체 사이에서 학습된 과거 연관성과 장면에 관한 글로벌 정보에 의해 실마리를 찾는지 도시한다. 도 8은 드론 기반 산업 검사 사용 사례에 대한 L-DNN의 적용을 도시한다. 도 9는, 도 8의 드론 기반 산업 검사 사용 사례를, 일제히 작동하는 다수의 L-DNN 운반형 드론을 이용하는 상황 으로 확장한다. 도 10은 창고 재고 사용 사례에 대한 L-DNN의 적용을 도시한다. 도 11은 지식을 집합적으로 획득하고 공유하기 위해 L-DNN을 사용하는 다수의 스마트 장치를 도시한다. 도 12는, L-DNN이 데이터 센터 기반 애플리케이션에서 종래의 DNN을 대체하는 사례를 도시한다."}
