{"patent_id": "10-2021-0168289", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0080804", "출원번호": "10-2021-0168289", "발명의 명칭": "인공지능 기반의 사람 자세 추정 장치 및 방법", "출원인": "한국전자기술연구원", "발명자": "신사임"}}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "원본 영상에서 사람을 포함하는 영역(이하, '원본 사람 영상'이라 한다)을 추출하는 추출부;상기 추출부에서 추출되는 원본 사람 영상을 서로 다른 해상도를 갖도록 스케일링하여 다수의 타겟 사람 영상들을 생성하는 스케일링부; 및상기 스케일링부에서 생성되는 다수의 타겟 사람 영상들을 사람 자세 추정을 위해 사전에 학습된 인공지능 모델의 서로 다른 네트워크로 입력하여 사람 자세를 추정하는 자세 추정부;를 포함하는 인공지능 기반의 사람 자세 추정 장치."}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 스케일링부는,상기 인공지능 모델에 설정된 입력 영상 해상도에 기초하여 상기 다수의 타겟 사람 영상들을 생성하는 것을 특징으로 하는 인공지능 기반의 사람 자세 추정 장치."}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 스케일링부에서 생성되는 다수의 타겟 사람 영상들 중 하나 이상을 선별하여 참조 영상임을 의미하는 가이딩 채널을 추가하는 가이딩 채널 추가부;를 더 포함하고,상기 자세 추정부는, 상기 추가되는 가이딩 채널에 기초하여 상기 원본 사람 영상과 유사한 하나 이상의 타겟 사람 영상을 인지 및참조하여 사람 자세를 추정하는 것을 특징으로 하는 인공지능 기반의 사람 자세 추정 장치."}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 자세 추정부는, 인공지능 모델에 구축된 다수의 스템 네트워크들 중 기설정된 스템 네트워크로 상기 다수의 타겟 사람 영상들이입력되면, 상기 다수의 타겟 사람 영상들의 해상도를 다운 스케일링하면서 특징맵을 생성하고, 상기 생성된 특징맵들을 다수의 서브 네트워크들 중 해당하는 서브 네트워크로 입력하여 특징맵들의 해상도를 선택적으로 변경하거나 유지하면서 융합(fusion)하여 사람 자세를 추정하는 것을 특징으로 하는 인공지능 기반의 사람 자세 추정 장치."}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "(A) 전자장치가, 원본 영상에서 사람을 포함하는 영역(이하, '원본 사람 영상'이라 한다)을 추출하는 단계;공개특허 10-2023-0080804-3-(B) 상기 전자장치가, 상기 (A) 단계에서 추출되는 원본 사람 영상을 서로 다른 해상도를 갖도록 스케일링하여다수의 타겟 사람 영상들을 생성하는 단계; 및(C) 상기 전자장치가, 상기 (B) 단계에서 생성되는 다수의 타겟 사람 영상들을 사람 자세 추정을 위해 사전에학습된 인공지능 모델의 서로 다른 네트워크로 입력하여 사람 자세를 추정하는 단계;를 포함하는 인공지능 기반의 사람 자세 추출 방법."}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 (B) 단계는,상기 인공지능 모델에 설정된 입력 영상 해상도에 기초하여 상기 다수의 타겟 사람 영상들을 생성하는 것을 특징으로 하는 인공지능 기반의 사람 자세 추출 방법."}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 (B) 단계 이후, (D) 상기 전자장치가, 상기 (B) 단계에서 생성되는 다수의 타겟 사람 영상들 중 하나 이상을 선별하여 참조 영상임을 의미하는 가이딩 채널을 추가하는 단계;를 더 포함하고,상기 (C) 단계는, 상기 (D) 단계에서 추가되는 가이딩 채널에 기초하여 상기 원본 사람 영상과 유사한 하나 이상의 타겟 사람 영상을 인지 및 참조하여 사람 자세를 추정하는 것을 특징으로 하는 인공지능 기반의 사람 자세추출 방법."}
{"patent_id": "10-2021-0168289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 (C) 단계는, (C1) 상기 다수의 타겟 사람 영상들을 인공지능 모델에 구축된 다수의 스템 네트워크들 중 기설정된 스템 네트워크로 입력하는 단계;(C2) 상기 다수의 스템 네트워크들이 각각 타겟 사람 영상의 해상도를 다운 스케일링하면서 특징맵을 생성하고,상기 생성된 특징맵들을 다수의 서브 네트워크들 중 해당하는 서브 네트워크로 입력하는 단계; 및(C3) 상기 다수의 서브 네트워크들이 상기 (C2) 단계에서 입력되는 특징맵들의 해상도를 선택적으로 변경하거나유지하면서 융합(fusion)하여 사람 자세를 추정하는 단계;를 포함하는 것을 특징으로 하는 인공지능 기반의 사람 자세 추출 방법."}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 사람 자세 추정 장치 및 방법이 제공된다. 추출부는 원본 영상에서 사람을 포함하는 영역(이하, '원본 사람 영상'이라 한다)을 추출하고, 스케일링부는 추출부에서 추출되는 원본 사람 영상을 서로 다른 해상도를 갖도록 스케일링하여 다수의 타겟 사람 영상들을 생성하며, 자세 추정부는 스케일링부에서 생성되 는 다수의 타겟 사람 영상들을 사람 자세 추정을 위해 사전에 학습된 인공지능 모델의 서로 다른 네트워크로 입 력하여 사람 자세를 추정할 수 있다."}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 사람 자세 추정 장치 및 방법에 관한 것으로서, 보다 상세하게는, 다중 해상도의 영 상을 인공지능 모델에 입력하여 사람 자세를 추정할 수 있는 인공지능 기반의 사람 자세 추정 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "2D 사람 자세 추정은(2D human pose estimation) 비전 분야에서 많은 주목을 받아왔으며, 최근 인공지능 기반의 딥러닝 도입에 의해 성능은 크게 향상되었다. 사람 자세 추정은 감시 시스템, 자율주행 등 다양한 분야에 이용 되며, 행동 및 제스처 인식에 도움을 준다. 가장 많이 사용되는 자세 추정 데이터셋인 MS COCO와 MPII 데이터 셋은 고해상도 영상 학습 데이터가 많다. 이에 따라 기존의 인공지능 기반 사람 자세 추출 모델은 고해상도 영 상에서는 성능이 우수하나, 거리가 멀어 작게 촬영된 사람이나, 촬영 영상의 해상도가 낮은 경우에 성능이 급격 하게 하락하는 문제점이 있다. 선행 논문(Sun, Ke, et al. \"Deep high-resolution representation learning for human pose estimation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.)에서 제안된 기술은 학습 데이터셋 중 사람 영역을 고정된 이미지 크기로 변환하고, 이를 모델에 입력하여 학습한 것으로, 입력 이미지 크기는 테스트 데이터셋에서 평균적으로 잘 동작하는 것으로 설정한다. 그러나, 테스트 데이터셋 중 크기가 작은 이미지에 대해서는 낮은 성능을 보이는 문제점이 있다. 또한, 국내 공개특허 제10-2019-0034380호에서 제안된 기술은 입력된 영상에서 사람의 자세를 추정하고, 동작을 교정하는 과정을 포함하나, 해상도가 낮은 영상에 대해 강건하게 동작하도록 하는 부분은 고려하고 있지 않다. 그러나, 실제 산업 분야의 적용을 위해서는 가까이 있는 사람의 자세를 추정함과 동시에 멀리 있는 사람의 자세 를 추정하는 것이 유용하다. 따라서, 해상도가 낮은 영상에서 자세를 검출할 수 있는 모델이 필수적이다. 또한, 기존의 기술은 모든 크기의 이미지들을 고정된 한 개의 크기로 변환하여 인공지능 학습 모델에 입력한다. 이 과정에서, 저해상도 영상을 업 스케일링하는 경우 아티펙트가 발생하여 자세 추정 정확도가 낮아지고, 고해 상도 영상의 사이즈를 줄이는 경우 정보의 손실이 발생한다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허 제10-2019-0034380호"}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제점을 해결하기 위하여 본 발명이 이루고자 하는 기술적 과제는, 다양한 크기의 영상에서 강건하게 동작하고, 특히 작은 크기의 사람을 포함하는 영상이나 저해상도 영상에서 사람 자세 추정이 가능한 인공지능 기반의 사람 자세 추정 장치 및 방법을 제시하는 데 있다. 본 발명의 해결과제는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 해결과제들은 아래의 기 재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 기술적 과제를 해결하기 위한 수단으로서, 본 발명의 실시 예에 따르면, 인공지능 기반의 사람 자세 추 정 장치는, 원본 영상에서 사람을 포함하는 영역(이하, '원본 사람 영상'이라 한다)을 추출하는 추출부; 상기 추출부에서 추출되는 원본 사람 영상을 서로 다른 해상도를 갖도록 스케일링하여 다수의 타겟 사람 영상들을 생 성하는 스케일링부; 및 상기 스케일링부에서 생성되는 다수의 타겟 사람 영상들을 사람 자세 추정을 위해 사전 에 학습된 인공지능 모델의 서로 다른 네트워크로 입력하여 사람 자세를 추정하는 자세 추정부;를 포함할 수 있 다.상기 스케일링부는, 상기 인공지능 모델에 설정된 입력 영상 해상도에 기초하여 상기 다수의 타겟 사람 영상들 을 생성할 수 있다. 상기 스케일링부에서 생성되는 다수의 타겟 사람 영상들 중 하나 이상을 선별하여 참조 영상임을 의미하는 가이 딩 채널을 추가하는 가이딩 채널 추가부;를 더 포함하고, 상기 자세 추정부는, 상기 추가되는 가이딩 채널에 기 초하여 상기 원본 사람 영상과 유사한 하나 이상의 타겟 사람 영상을 인지 및 참조하여 사람 자세를 추정할 수 있다. 상기 자세 추정부는, 인공지능 모델에 구축된 다수의 스템 네트워크들 중 기설정된 스템 네트워크로 상기 다수 의 타겟 사람 영상들이 입력되면, 상기 다수의 타겟 사람 영상들의 해상도를 다운 스케일링하면서 특징맵을 생 성하고, 상기 생성된 특징맵들을 다수의 서브 네트워크들 중 해당하는 서브 네트워크로 입력하여 특징맵들의 해 상도를 선택적으로 변경하거나 유지하면서 융합(fusion)하여 사람 자세를 추정할 수 있다. 한편, 본 발명의 다른 실시 예에 따르면, 인공지능 기반의 사람 자세 추정 방법은, (A) 전자장치가, 원본 영상 에서 사람을 포함하는 영역(이하, '원본 사람 영상'이라 한다)을 추출하는 단계; (B) 상기 전자장치가, 상기 (A) 단계에서 추출되는 원본 사람 영상을 서로 다른 해상도를 갖도록 스케일링하여 다수의 타겟 사람 영상들을 생성하는 단계; 및 (C) 상기 전자장치가, 상기 (B) 단계에서 생성되는 다수의 타겟 사람 영상들을 사람 자세 추 정을 위해 사전에 학습된 인공지능 모델의 서로 다른 네트워크로 입력하여 사람 자세를 추정하는 단계;를 포함 할 수 있다. 상기 (B) 단계는, 상기 인공지능 모델에 설정된 입력 영상 해상도에 기초하여 상기 다수의 타겟 사람 영상들을 생성할 수 있다. 상기 (B) 단계 이후, (D) 상기 전자장치가, 상기 (B) 단계에서 생성되는 다수의 타겟 사람 영상들 중 하나 이상 을 선별하여 참조 영상임을 의미하는 가이딩 채널을 추가하는 단계;를 더 포함하고, 상기 (C) 단계는, 상기 (D) 단계에서 추가되는 가이딩 채널에 기초하여 상기 원본 사람 영상과 유사한 하나 이상의 타겟 사람 영상을 인지 및 참조하여 사람 자세를 추정할 수 있다. 상기 (C) 단계는, (C1) 상기 다수의 타겟 사람 영상들을 인공지능 모델에 구축된 다수의 스템 네트워크들 중 기 설정된 스템 네트워크로 입력하는 단계; (C2) 상기 다수의 스템 네트워크들이 각각 타겟 사람 영상의 해상도를 다운 스케일링하면서 특징맵을 생성하고, 상기 생성된 특징맵들을 다수의 서브 네트워크들 중 해당하는 서브 네 트워크로 입력하는 단계; 및 (C3) 상기 다수의 서브 네트워크들이 상기 (C2) 단계에서 입력되는 특징맵들의 해 상도를 선택적으로 변경하거나 유지하면서 융합(fusion)하여 사람 자세를 추정하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 다양한 해상도의 영상에서 강건하게 동작하여 우수한 자세 추정 성능을 제공하며, 특히, 작 은 크기의 사람을 포함하는 영상이나 저해상도 영상에서도 높은 자세 추정 성능을 제공하는 것이 가능하다. 또한, 본 발명에 따르면, 계산 비용이 많이 발생하는 Super Resolution 모듈의 추가 없이도, 다중 스케일 입력 특징들의 융합과 가이딩 채널을 통해 2D 사람 자세 추정 성능을 향상시킬 수 있다."}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상의 본 발명의 목적들, 다른 목적들, 특징들 및 이점들은 첨부된 도면과 관련된 이하의 바람직한 실시 예들 을 통해서 쉽게 이해될 것이다. 그러나 본 발명은 여기서 설명되는 실시 예들에 한정되지 않고 다른 형태로 구 체화될 수도 있다. 오히려, 여기서 소개되는 실시 예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당업자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 어떤 경우에는, 발명을 기술하는 데 있어서 흔히 알려졌으면서 발명과 크게 관련 없는 부분들은 본 발명을 설명 하는 데 있어 별 이유 없이 혼돈이 오는 것을 막기 위해 기술하지 않음을 미리 언급해 둔다. 본 명세서에서 제1, 제2 등의 용어가 구성요소들을 기술하기 위해서 사용된 경우, 이들 구성요소들이 이 같은 용어들에 의해서 한정되어서는 안 된다. 이들 용어들은 단지 어느 구성요소를 다른 구성요소와 구별시키기 위해 서 사용되었을 뿐이다. 또한, 어떤 구성요소가 구현됨에 있어서 특별한 언급이 없다면, 그 구성요소는 소프트웨어, 하드웨어, 또는 소 프트웨어 및 하드웨어 어떤 형태로도 구현될 수 있는 것으로 이해되어야 할 것이다. 또한, 본 명세서에서 사용된 용어는 실시 예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되 는 '포함한다(comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요소는 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 또한, 본 명세서에서 '부', '플랫폼', '장치' 등의 용어는 하드웨어 및 해당 하드웨어에 의해 구동되거나 하드 웨어를 구동하기 위한 소프트웨어의 기능적, 구조적 결합을 지칭하는 것으로 의도될 수 있다. 예를 들어, 여기 서 하드웨어는 CPU 또는 다른 프로세서(processor)를 포함하는 데이터 처리 기기일 수 있다. 또한, 하드웨어에 의해 구동되는 소프트웨어는 실행중인 프로세스, 객체(object), 실행파일(executable), 실행 스레드(thread of execution), 프로그램(program) 등을 지칭할 수 있다. 또한, 상기 용어들은 소정의 코드와 상기 소정의 코드가 수행되기 위한 하드웨어 리소스의 논리적인 단위를 의 미할 수 있으며, 반드시 물리적으로 연결된 코드를 의미하거나, 한 종류의 하드웨어를 의미하는 것이 아님은 본"}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "발명의 기술분야의 평균적 전문가에게는 용이하게 추론될 수 있다. 이하, 본 발명에서 실시하고자 하는 구체적인 기술내용에 대해 첨부도면을 참조하여 상세하게 설명하기로 한다. 2D 사람 자세 추정에 대한 연구는 크게 Bottom-up 방식과 Top-down 방식으로 나뉜다. Bottom-up 방법의 경우 입력 영상에 대해 관절 후보를 구한 뒤, 각 관절 간의 상관관계를 분석하여 사람의 자세 를 추정한다. Top-down 방식의 경우 입력 영상에서 사람을 먼저 검출한 뒤 검출된 사람을 포함하는 영역 (bounding box)에서 관절을 추정한다. 본 발명의 실시 예는 자세 추정에 더 높은 성능을 보이는 Top-down 방식 을 이용한다. 보다 자세히는, 본 발명의 실시 예는 Top-down 방식을 대표하는 HRNet의 구조를 기반으로 저해상도 영상에서도 높은 자세 추정 성능을 보이면서 모든 크기(즉, 모든 해상도)의 영상에 강건하게 동작할 수 있는 인공지능 모델 을 이용할 수 있다. 기존 모델의 네트워크들은 자세 추정을 위해 원본 영상을 하나의 고정된 크기로 스케일링하여 인공지능 모델의 입력으로 사용한다. 이러한 방법은 고해상도 영상을 저해상도로 스케일링하는 경우에는 지나친 정보 손실이 발 생하고, 저해상도 영상을 고해상도 영상으로 스케일링하는 경우에는 영상에 아티팩트(artifact)가 많이 생기게 되어 자세 추정 오류 가능성을 높이게 된다. 따라서, 본 발명의 실시 예에서는 원본 영상 중 사람을 포함하는 영역을 멀티 해상도로 스케일링하고, 스케일링 에 의해 생성되는 다수의 타겟 영상들을 자세 추정을 위한 인공지능 모델의 입력으로 사용할 수 있다. 또한, 본 발명의 실시 예는, 어떤 타겟 영상이 원본 영상의 해상도(즉, 크기)와 가장 유사한지를 인공지능 모델에 알 릴 수 있도록, 즉, 인공지능 모델의 네트워크에서 가장 유사한 타겟 영상을 인지 및 자세 추정에 참조할 수 있 도록 가이딩 정보를 제공할 수 있다. 이로써, 하나의 네트워크가 다양한 해상도의 영상에서도 강건하게 효과적으로 동작할 수 있다. 이를 위하여, 본 발명의 실시 예는 super-resolution 모듈과 같이 계산 비용이 많이 드는 모듈 없이 다수의 light convolution layers를 추가하여 2D 사람 자세 추정 성능을 향상시킬 수 있다. 도 1은 본 발명의 실시 예에 따른 인공지능 기반의 사람 자세 추정 장치를 도시한 블록도이고, 도 2는 다 중 해상도 입력 및 가이딩 채널이 인공지능 모델의 네트워크로 입력되어 출력 특징(feature)이 출력되는 동작을 보여주는 도면이다. 도 1을 참조하면, 본 발명의 실시 예에 따른 인공지능 기반의 사람 자세 추정 장치는 추출부, 스케일 링부, 채널 추가부 및 자세 추정부를 포함할 수 있다. 추출부는 원본 영상에서 사람을 포함하는 영역(이하, '원본 사람 영상'이라 한다, I)을 추출할 수 있다. 추출부는 입력되는 원본 영상을 분석하여 사람을 검출하고, 검출된 사람을 포함하도록 바운딩 박스를 설정 하여 크롭할 수 있다. 이하에서는 크롭된 바운딩 박스에 해당하는 영상을 원본 사람 영상(I)이라 한다. 원본 영상은 동영상 중 한 프레임이거나, 정지영상일 수 있다. 스케일링부는 추출부에서 추출되는 원본 사람 영상(I)을 서로 다른 해상도를 갖도록 스케일링하여 다 수의 타겟 사람 영상들(I1, In)을 생성할 수 있다. 자세히 설명하면, 스케일링부는 높이(h) Х 너비(w)로 이루어진 원본 사람 영상(I)을 다중 해상도 입력 영상인 타겟 사람 영상들(I1, I2, …, In, …, IN)로 스케일링 할 수 있다. 여기서, 스케일링된 영상들(I1, I2, …, In, …, IN)의 크기는 각각 (h1Хw1), (h2Хw2), …, (hNХ wN)이다. 타겟 사람 영상들(I1, I2, …, In, …, IN)은 원본 사람 영상(I)의 Bicubic Interpolation(고등차수 보간)에 의해 생성될 수 있다. 스케일링부는 인공지능 모델에 설정된 다수의 서로 다른 입력 영상 해상도에 기초하여 다수의 타겟 사람 영상들(I1, In)을 생성할 수 있다. 따라서, 타겟 사람 영상들(I1, In)의 해상도는 원본 사람 영상(I)의 해상도보다 작을 수도 있고 클 수도 있다. 도 2의 경우, 타겟 사람 영상(I1)의 해상도는 원본 사람 영상(I)보다 크고, 타겟 사람 영상들(In)의 해상도는 원 본 사람 영상(I)보다 작다. 스케일링부에서 스케일링할 해상도는 인공지능 모델의 구축하는 과정에서 다수의 데이터셋을 학습하면서 실험에 의해 최적의 값으로 정해질 수 있다. 따라서, 스케일링부는 인공지능 모델과 연동하여 인공지능 모델에 설정된 다수의 해상도를 사전에 확인하여 다수의 타겟 사람 영상들을 생성하거나, 사용자 인터페이스(미 도시)를 통해 사용자로부터 입력되는 해상도(즉, 인공지능 모델에 설정된 해상도)로 다수의 타겟 사람 영상들을 생성할 수도 있다. 채널 추가부는 스케일링부에서 생성되는 다수의 타겟 사람 영상들(I1, In) 중 원본 사람 영상(I)의 해 상도에 가장 근접하거나 사전에 정해진 해상도 범위에 속하는 하나 이상의 타겟 사람 영상을 선별하여 참조 영 상임을 의미하는 가이딩 채널을 추가할 수 있다. 가이딩 채널은 원본 사람 영상과 가장 유사한 크기의 타겟 사람 영상을 네트워크(또는 인공지능 모델)가 인지 및 참고하도록 추가되는 채널(CG1)과, 해당 타겟 사람 영상은 참고 영상이 아님을 의미하는 채널(CG0)을 포함할 수 있다. 따라서, 가이딩 채널(CG1)이 추가된 타겟 사람 영상은 네트워크에서 사람 자세 추정을 위한 참고 영상 으로 활용될 수 있다. 도 2를 참조하면, 하나의 타겟 사람 영상(I1)은 R채널(CR), G채널(CG), B 채널(CB)로 이루어진다. 채널 추가부 는 RGB 3개의 채널에 가이딩 채널(CG0 또는 CG1)을 추가할 수 있다. 가이딩 채널은 N>2인 경우, 2진값으 로 채워지는 채널로서, 타겟 사람 영상의 네번째 채널에 추가될 수 있다. 일 예로, 가이딩 채널(CG0)은 각 픽셀 마다 표시 인자 '0'이 표시되고, 가이딩 채널(CG1)에는 표시 인자 '1'이 표시된다. 자세히 설명하면, 채널 추가부는 타겟 사람 영상의 해상도가 사전에 정의된 범위에 해당하면 표시 인자 '1'을 가지는 가이딩 채널(CG1)을 생성한 후 추가하고, 범위를 벗어나면 표시 인자 '0'을 가지는 가이딩 채널(CG0)을 추가할 수 있다. 가이딩 채널을 추가하는 해상도 조건은 [표 1]을 참조하여 후술한다. 또는, 채널 추가부는 다수의 타겟 사람 영상들(I1, In) 각각의 해상도와 원본 사람 영상(I)의 해상도를 비 교하여, 해상도의 차이가 가장 적은 하나의 타겟 사람 영상(예를 들어, In)에게 표시 인자 '1'을 가지는 가이딩 채널(CG1)을 생성한 후 추가하고, 나머지 타겟 사람 영상에는 표시 인자 '0'을 가지는 가이딩 채널(CG0)을 추가 할 수 있다. 또는, 채널 추가부는 임계값 내에 있는 후보 타겟 사람 영상이 다수인 경우, 다수의 후보 타겟 사람 영상 들 중 사전에 정해진 개수(1 이상)만큼 가장 근접한 순서대로 타겟 사람 영상을 추출하여 표시 인자 '1'을 가지 는 가이딩 채널(CG1)을 추출된 타겟 사람 영상에 추가하고, 나머지 타겟 사람 영상에는 표시 인자 '0'을 가지는 가이딩 채널(CG0)을 추가할 수도 있다. 또한, 채널 추가부는 타겟 사람 영상(I1)의 해상도는 원본 사람 영상(I)보다 크고, 타겟 사람 영상들(In)의 해상도는 원본 사람 영상(I)보다 작으며, I1과 I의 해상도 차이와, In과 I의 해상도 차이가 동일한 경우에는, 원 본 사람 영상(I)이 기설정된 기준보다 큰 고해상도이면 타겟 사람 영상(I1)에 표시 인자 '1'을 가지는 가이딩 채널을 추가하고, 기준보다 작은 저해상도이면 타겟 사람 영상(In)에 표시 인자 '0'을 가지는 가이딩 채널을 추 가할 수도 있다. 상술한 설명에 의하면, 채널 추가부는 원본 사람 영상의 해상도에 따라 네트워크의 사람 추정에 선택적으 로 영향을 줄 수 있도록 다중 해상도 영상들을 유도하는 가이딩 채널을 추가할 수 있다. 이에 의해, 원본 사람 영상이 저해상도일 때, 네트워크는 열화가 거의 없는 작은 배율로 스케일된 타겟 사람 영상(또는 타겟 사람 영 상의 특징)을 더 참조하여 자세를 추정하도록 유도될 수 있다. 반면, 원본 사람 영상이 고해상도인 경우에는 정보 손실이 거의 없는 큰 크기의 타겟 사람 영상(또는 타겟 사람 영상의 특징)에 의해 영향을 받아 자세를 추 정하도록 유도될 수 있다. 상술한 채널 추가부의 동작은 생략될 수도 있으며, 생략 여부는 사용자에 의해 정해질 수 있다. 자세 추정부는 스케일링부에서 생성되는 다수의 타겟 사람 영상들을 사람 자세 추정을 위해 사전에 학습된 인공지능 모델의 서로 다른 네트워크로 입력하여 사람 자세를 추정할 수 있다. 또한, 자세 추정부는 채널 추가부에서 가이딩 채널이 타겟 사람 영상들에 추가된 경우, 가이딩 채널 에 기초하여 다수의 타겟 사람 영상들(I1, In) 중 원본 사람 영상(I)에 가장 근접한 하나 이상의 타겟 사람 영상 을 인지 및 참조하여 사람 자세를 추정할 수 있다. 또한, 자세 추정부는 인공지능 모델에 구축된 다수의 스템 네트워크들 중 기설정된 스템 네트워크로 다수 의 타겟 사람 영상들(I1, In)이 입력되면, 다수의 타겟 사람 영상들(I1, In)의 해상도를 다운 스케일링하면서 특 징맵을 생성하고, 생성된 특징맵들을 다수의 서브 네트워크들 중 해당하는 서브 네트워크로 입력하여 특징맵들 의 해상도를 선택적으로 변경하거나 유지하면서 융합(fusion)하여 사람 자세를 추정할 수 있다. 특징맵 또는 특징맵의 특징은 사람의 윤곽선, 형태, 명암, 색상 등 사람을 형상화하거나 자세 추정에 사용되는 정보를 포함 할 수 있다. 도 2를 참조하여 자세 추정부가 인공지능 모델을 이용하여 자세를 추정하는 동작을 자세히 설명한다. 도 2에 도시된 인공지능 모델은 다수의 스템(STEM) 네트워크들과 HRNet을 포함할 수 있다. 스템 네트워크는 타 겟 사람 영상(In)으로부터 영상 특징을 추출하는 최소 두 개의 strided convolution 레이어를 포함하고, HRNet 은 다수의 서브 네트워크들을 포함할 수 있다. 다중 해상도 영상들, 즉, 다수의 타겟 사람 영상들(I1, In)의 영 상 특징은 스템 네트워크를 통해 추출되어 사람의 관절 위치를 추정하는데 사용될 수 있다. HRNet은 다수의 서 브 네트워크들을 포함하며, n번째 서브 네트워크에서 추출되는 영상 특징은 (n-1)번째 서브 네트워크에서 다운 스케일된 특징들에 추가되어 다음 네트워크로 삽입될 수 있다. HRNet의 동작은 도 3을 참조하여 후술한다. 도 2에서, 타겟 사람 영상(I1)은 제1스템 네트워크(SN1)로 입력되고, 타겟 사람 영상(In)은 제n스템 네트워크 (SNn)로 입력된다. 제1스템 네트워크(SN1)는 입력된 타겟 사람 영상(I1)에서 특징을 추출하고, 추출된 타겟 사 람 영상(I1)의 특징은 HRNet의 제1서브 네트워크의 제1스테이지(S11)로 입력되어 다시 특징을 추출하고, 추출된특징은 컨볼루션 레이어에 의해 다운스케일링되거나 유지될 수 있다. 또한, 제n스템 네트워크(SNn)는 입력되는 타겟 사람 영상(In)에서 특징을 추출하고, 추출된 타겟 사람 영상(In) 의 특징은 제n서브 네트워크의 제1스테이지(Sn1)로 입력된다. 이 때, 상위 서브 네트워크(예를 들어, 제1서브 네트워크)의 중간 레이어로부터 출력되는 특징은 제n스템 네트워크에서 추출되는 특징과 융합되며, 각 특징의 차원을 일치시키기 위해 상위 서브 네트워크로부터의 특징맵은 다운스케일링된 후 융합될 수 있다. (n-1)번째 서브 네트워크로부터 출력되는 특징맵이 n번째 서브 네트워크의 입력으로 융합된다고 가정하면, Sn1의 입력 특징은 [수학식 1]과 같이 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2021-0168289", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[수학식 1]을 참조하면, stride=2는 (n-1)번째 서브 네트워크의 (n-1)번째 스테이지에서 출력되는 특징은 컨볼 루션 레이어에 의해 특징맵의 해상도가 50% 감소된 후, n번째 스템 네트워크에서 출력되는 특징과 융합되는 것 을 의미한다. 도 3은 본 발명의 실시 예에 따른 HRNet의 프레임워크를 도시한 도면이다. 도 3을 참조하면, 2D 자세 추정 네트워크에서 HRNet은 레이어들을 직렬과 병렬로 구성하여 고성능의 자세 추정 을 제공한다. HRNet에서 다수의 high-to-low subnetworks는 병렬로 연결되고, 각 high-to-low subnetwork에는 다수의 스테이지가 직렬로 연결된다. n번째 서브 네트워크의 k번째 스테이지는 Snk로 표시된다. 각 서브 네트워크는 서로 다른 해상도의 타겟 사람 영상을 입력받을 수 있다. 각 스테이지는 서로 다른 서브 네트워크들로부터 특징을 집계하는 multi-scale fusion process를 포함한다. Snk의 입력 특징은 S1(n+k-2), S2(n+k-2), …, S(n+k-2)1의 출력 특징을 집계할 수 있다. 예를 들어, S13, S22 및 S31에서 출력된 특징은 결합되어 스테이지 S23으로 삽입된다. Strided 컨볼루션 또는 업-샘플링은 통합할 특징맵들의 크기를 매치시키기 위해 사용된다. Snk의 입력 특징을 생성하기 위해, 본 발명의 실시 예에서는 Strided 컨볼루션에 의해 S(n-1)k의 출력 특징의 크기를 정해진 비율 (예를 들어, 50%)로 줄인 후 하위 서브 네트워크로 출력할 수 있다. 스테이지 S(n+1)(k-2)의 출력 특징의 크기는 최근접(nearest neighbor) 업샘플링과 1Х1 컨볼루션을 통해 2배가 된다. Sn(k-1)에서 특징맵은 크기 변경 없이 컨볼루션 레이어를 통과한다. Snk의 입력 특징은 동일한 크기의 특징맵들을 더하여 생성된다. 관절 위치를 회귀(regress)하기 위한 관절 개수에 대응하는 히트맵들(M)은 제1서브 네트워크의 출력 특징에서 획득될 수 있다. 실제값에 해당하는 히트맵들은 각 관절의 실측 픽셀 위치에서 1픽셀의 표준 편차를 가지는 2D 가우시안을 적용하여 생성될 수 있다. 또한, 출력 표현(output representation)은 실측 히트맵들에 근접하도록 평균제곱오차(MSE) 손실을 사용하도록 훈련될 수 있다. 상술한 동작에 의해, 자세 추정부는 다수의 스템 네트워크들과 HRNet을 포함하는 인공지능 모델에 다중 해 상도 영상들(I1, In)을 입력하여 사람 자세를 추정한 17개의 관절을 표시하는 17개의 히트맵들(M)을 출력하고, 17개의 히트맵들(M)로부터 자세 추정 결과를 보여주는 결과 영상을 출력할 수 있다. 도 4는 본 발명의 실시 예에 따른 다양한 인공지능 모델의 변형 구조를 도시한 예시도이다. 도 4의 (a) 내지 (c)를 참조하면, I1의 해상도는 모두 256Х192로 설정되어 있다. 또한, 하위 네트워크에는 낮 은 해상도(74Х48, 32Х24 또는 128Х96)로 조정된 I2 또는 I3이 삽입된다. 따라서, 인공지능 모델이 (a)의 구 조를 갖는 경우, 스케일링부는 원본 입력 영상을 각각 256Х192와 64Х48의 해상도를 가지는 타겟 사람 영 상들(I1, I2)로 스케일링한다. 자세 추정부는 원본 사람 영상(I)의 해상도에 따라서 도 4에 도시된 다수의 변형된 인공지능 모델들 중 하나로 구조를 변경하여 자세를 추정할 수도 있다. [표 1]은 도 4에 도시된 (a) 내지 (c)의 인공지능 모델에서 적용되는 가이딩 채널 조건을 보여준다. 표 1 I_n (height x width)Stem Output (height x width)Guiding Channel (condition) OURS-(a) (256Х192) 64Х48 0 (74Х48) 32Х24 1, if 96·96 < h · w 0, otherwise OURS-(b) (256Х192) 64Х48 0 (32Х24) 16Х12 1, if 96·96 < h · w 0, otherwise OURS-(c) (256Х192) 64Х48 0 (128Х96) 32Х24 1, if 64·64 < h · w < 128 ·128 0, otherwise (74Х48) 16Х12 1, if h · w < 64·640, otherwise 도 4의 (a) 및 [표 1]을 참조하면, 채널 추가부는 타겟 사람 영상(I2)의 해상도가 96Х96보다 작으므로, 표시 인자 '1'을 가지는 가이딩 채널을 타겟 사람 영상(I2)의 네번째 채널로서 생성 및 추가하여, 참조 영상임 을 표시할 수 있다. 또한, 타겟 사람 영상(I1)에는 표시 인자 '0'을 가지는 가이딩 채널을 추가하여 참조 영상 이 아님을 표시할 수 있다. [표 1]에 기재된 해상도 별 가이딩 채널 조건은 일 예로서, 인공지능 모델의 구조에 따라 또는 자세 추정 성능 에 따라서 변경가능하다. 도 5는 COCO 검증 세트의 영상들을 24Х18 사이즈로 스케일링한 결과를 보여주는 예시도이다. 도 5에서 기존 방식은 기존에 입력 영상을 고정된 하나의 크기로 스케일링하여 자세를 추정하는 방식을 의미하 고, 본 발명은 상술한 본 발명의 실시 예에 따라 다중 해상도 영상을 이용하여 자세를 추정하는 방식이고, 실제 값은 COCO 검증 세트에 포함된 실제 원본 영상에서 추정된 자세를 의미한다. 도 5를 참조하면, 본 발명의 실시 예에 따른 자세 추정은 기존 방식으로 추정된 기준선(Baseline)보다 더 정확 하게 관절 위치를 추정하고, 골격 역시 기준선에 비해 실제와 더 동일하거나 거의 유사한 자세를 표현한다. 도 6은 발명의 실시 예에 따른 인공지능 기반의 사람 자세 추출 방법을 도시한 흐름도이다. 도 6에 도시된 인공지능 기반의 사람 자세 추출 방법을 수행하는 전자장치는 도 1 내지 도 5를 참조하여 설명한 사람 자세 추정 장치일 수 있으므로 상세한 설명은 생략한다. 도 6을 참조하면, 전자장치는 입력되는 원본 영상에서 사람을 포함하는 원본 사람 영상을 추출할 수 있다 (S610). 전자장치는 S610단계에서 추출되는 원본 사람 영상을 서로 다른 해상도를 갖도록 스케일링하여 다수의 타겟 사 람 영상들을 생성할 수 있다(S620). 전자장치는 S620단계에서 생성되는 다수의 타겟 사람 영상들 중 원본 사람 영상의 해상도에 가장 근접하거나 사 전에 정해진 해상도 범위 내에 속하는 하나 이상의 타겟 사람 영상을 선별하여 참조 영상임을 의미하는 가이딩 채널 또는 참조 영상이 아님을 의미하는 가이딩 채널을 추가할 수 있다(S630). 전자장치는 가이딩 채널이 추가된 다수의 타겟 사람 영상들을 사람 자세 추정을 위해 사전에 학습된 인공지능 모델의 서로 다른 계층의 네트워크로 입력하여 사람 자세를 추정할 수 있다(S640). S640단계는, 인공지능 모델에 구축된 다수의 스템 네트워크들 중 기설정된 스템 네트워크로 다수의 타겟 사람 영상들이 입력되면, 다수의 타겟 사람 영상들의 해상도를 다운 스케일링하면서 특징맵을 생성하고, 생성된 특징 맵들을 다수의 서브 네트워크들 중 해당하는 서브 네트워크로 입력하여 특징맵들의 해상도를 선택적으로 변경하 거나 유지하면서 융합(fusion)하여 사람 자세를 추정할 수 있다.도 7은 본 발명의 실시 예에 따른 인공지능 기반 사람 자세 추정 방법을 하는 컴퓨팅 시스템을 보여주는 블록도 이다. 도 7을 참조하면, 컴퓨팅 시스템은 버스를 통해 연결되는 적어도 하나의 프로세서, 메모리 , 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치, 스토리지, 및 네트워크 인 터페이스를 포함할 수 있으며, 이는 도 6에서 설명한 전자장치 또는 도 1에서 설명한 사람 자세 추정 장치 일 수 있다. 프로세서는 중앙 처리 장치(CPU) 또는 메모리 및/또는 스토리지에 저장된 명령어들에 대한 처리 를 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 종류의 휘발성 또는 비휘발성 저 장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(Read Only Memory) 및 RAM(Random Access Memory)을 포함할 수 있다. 따라서, 본 명세서에 개시된 실시 예들과 관련하여 설명된 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM과 같은 저장 매체(즉, 메모리 및/또는 스토리지)에 상주할 수도 있다. 예시적인 저장 매체는 프로세서에 커플링되며, 그 프로세서는 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 저장 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 저장 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수도 있다. 다른 방법으로, 프로세서 및 저장 매체는 사용자 단말기 내에 개별 컴포넌트로서 상주할 수도 있다. 한편, 이상으로 본 발명의 기술적 사상을 예시하기 위한 바람직한 실시 예와 관련하여 설명하고 도시하였지만, 본 발명은 이와 같이 도시되고 설명된 그대로의 구성 및 작용에만 국한되는 것이 아니며, 기술적 사상의 범주를 일탈함이 없이 본 발명에 대해 다수의 변경 및 수정 가능함을 당업자들은 잘 이해할 수 있을 것이다. 따라서, 그러한 모든 적절한 변경 및 수정과 균등물들도 본 발명의 범위에 속하는 것으로 간주하여야 할 것이다. 따라 서, 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0168289", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 인공지능 기반의 사람 자세 추정 장치를 도시한 블록도, 도 2는 다중 해상도 입력 및 가이딩 채널이 인공지능 모델의 네트워크로 입력되어 출력 특징(feature)이 출력되 는 동작을 보여주는 도면, 도 3은 본 발명의 실시 예에 따른 HRNet의 프레임워크를 도시한 도면, 도 4는 본 발명의 실시 예에 따른 다양한 인공지능 모델의 변형 구조를 도시한 예시도,도 5는 COCO 검증 세트의 영상들을 24Х18 사이즈로 스케일링한 결과를 보여주는 예시도, 그리고, 도 6은 발명의 실시 예에 따른 인공지능 기반의 사람 자세 추출 방법을 도시한 흐름도이다."}
