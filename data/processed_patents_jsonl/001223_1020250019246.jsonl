{"patent_id": "10-2025-0019246", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0054754", "출원번호": "10-2025-0019246", "발명의 명칭": "외부지식을 이용한 자연어 처리 방법 및 장치", "출원인": "포티투닷 주식회사", "발명자": "임연수"}}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자연어 표현을 포함하는 입력 텍스트를 획득하는 단계;기생성된 외부지식(external knowledge) 데이터베이스를 참조하여 상기 입력 텍스트에 대한 외부지식 참조 정보를 생성하는 단계;상기 입력 텍스트 및 상기 외부지식 참조 정보를 기학습된 자연어 처리 모델에 입력하는 단계; 및상기 입력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 상기 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 상기 자연어 처리 모델의 출력을 획득하는 단계;를 포함하고,상기 외부지식 데이터베이스는 선택된 도메인(domain)에 대응되도록 선택되거나, 또는 상기 외부지식 데이터베이스 내에서 상기 참조의 대상이 되는 유형의 종류는 선택된 도메인에 대응되도록 설정되는, 외부지식을 이용한자연어 처리 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 외부지식 데이터베이스는 표현 및 상기 표현에 대한 유형으로 구성되는 복수개의 표현-유형 쌍을포함하고,상기 생성하는 단계는,상기 외부지식 데이터베이스를 참조하여 상기 표현-유형 쌍 중 적어도 하나를 상기 입력 텍스트에 매칭함으로써상기 외부지식 참조 정보를 생성하는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 표현에 대한 유형은, 상기 선택된 도메인에 대응되도록 설정되는 적어도 하나의 유형을 포함하는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 생성하는 단계는,상기 입력 텍스트를 복수개의 n-그램(n-gram)으로 분리하는 단계;상기 외부지식 데이터베이스에서 상기 복수개의 n-그램을 검색하고, 상기 검색의 결과에 기초하여 상기 표현-유형 쌍 중에서 적어도 하나의 대상 쌍을 선택하는 단계; 및대상 유형을 상기 입력 텍스트에 포함된 대상 표현에 매칭함으로써 상기 외부지식 참조 정보를 생성하는 단계;를 포함하되,상기 대상 쌍은 상기 대상 표현 및 상기 대상 유형으로 구성되는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 대상 쌍은 제1 쌍 및 제2 쌍을 포함하되, 상기 제1 쌍은 제1 표현 및 제1 유형으로 구성되고, 상기 제2 쌍공개특허 10-2025-0054754-3-은 제2 표현 및 제2 유형으로 구성되며,상기 제2 표현은 상기 제1 표현과 상이하되, 상기 제1 표현을 구성하는 모든 문자를 포함하고,상기 생성하는 단계는,소정의 기준에 기초하여 상기 제1 유형 및 상기 제2 유형 중 적어도 하나를 상기 제1 표현에 매칭함으로써 상기외부지식 참조 정보를 생성하는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 자연어 처리 모델은 모델 인코더, 모델 디코더 및 분류자(classifier)를 포함하고,상기 자연어 처리 모델의 출력을 획득하는 단계는,상기 입력 텍스트 및 상기 외부지식 참조 정보를 상기 모델 인코더에 입력하여, 상기 모델 인코더의 출력으로서언어모델 은닉상태(language model hidden state) 및 외부지식 임베딩(external knowledge embedding)을 획득하는 단계;상기 언어모델 은닉상태 및 상기 외부지식 임베딩을 상기 모델 디코더에 입력하여, 상기 모델 디코더의 출력으로서 디코더 은닉상태를 획득하는 단계; 및상기 디코더 은닉상태를 상기 분류자에 입력하여, 상기 분류자의 출력으로서 상기 자연어 처리 모델의 출력을획득하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 모델 인코더는 제1 처리부 및 제2 처리부를 포함하고,상기 제1 처리부는 상기 입력 텍스트를 토큰화(tokenize)하는 토큰화 레이어 및 상기 언어모델 은닉상태를 출력하는 언어모델 레이어를 포함하고,상기 제2 처리부는 상기 외부지식 참조 정보를 입력으로 하고 상기 외부지식 임베딩을 출력으로 하는 임베딩 레이어를 포함하는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서,상기 분류자는 상기 디코더 은닉상태에 기초하여 상기 의도 분류 정보를 생성하는 제1 분류자 및 상기 디코더은닉상태에 기초하여 상기 슬롯 태깅 정보를 생성하는 제2 분류자를 포함하는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 제2 분류자는 비자기회귀(non-autoregressive) 기법에 기반하여 상기 슬롯 태깅 정보를 생성하는, 방법."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "외부 장치와 통신을 수행하는 통신 모듈;적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써 동작하는 프로세서;를 포함하되,상기 프로세서는,공개특허 10-2025-0054754-4-자연어 표현을 포함하는 입력 텍스트를 획득하도록 상기 통신 모듈을 제어하고,기생성된 외부지식(external knowledge) 데이터베이스를 참조하여 상기 입력 텍스트에 대한 외부지식 참조 정보를 생성하고,상기 입력 텍스트 및 상기 외부지식 참조 정보를 기학습된 자연어 처리 모델에 입력하고,상기 입력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 상기 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 상기 자연어 처리 모델의 출력을 획득하고,상기 외부지식 데이터베이스는 선택된 도메인(domain)에 대응되도록 선택되거나, 또는 상기 외부지식 데이터베이스 내에서 상기 참조의 대상이 되는 유형의 종류는 선택된 도메인에 대응되도록 설정되는, 외부지식을 이용한자연어 처리 장치."}
{"patent_id": "10-2025-0019246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 따른 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 외부지식을 이용한 자연어 처리 방법 및 장치에 관한 것이다. 본 개시의 일 실시예에 따르면, 자연어 표현을 포함하는 입력 텍스트를 획득하는 단계; 기생성된 외부지식(external knowledge) 데이터베이스를 참조하 여 상기 입력 텍스트에 대한 외부지식 참조 정보를 생성하는 단계; 상기 입력 텍스트 및 상기 외부지식 참조 정 보를 기학습된 자연어 처리 모델에 입력하는 단계; 및 상기 입력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 상기 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 상기 자연어 처리 모델의 출력을 획득하는 단계를 포함하는, 외부지식을 이용한 자연어 처리 방법을 제공할 수 있다."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 외부지식을 이용한 자연어 처리 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 자연어 처리(NLP) 기술의 발전으로, 인간인 사용자와 인공지능 에이전트간 자연스러운 대화를 제공하는 서 비스가 가능하게 되었다. 이러한 대화형 인공지능 서비스는 챗봇(chat bot) 또는 음성 인식 비서 등으로 다양한 기술 분야와 다양한 서비스 분야에 활용되고 있다. 특히, 인공지능 에이전트를 이용하여 사용자의 특수한 요구를 만족시키는 것을 목적으로 하는 목적지향 대화시 스템(task-oriented dialogue system)의 중요성이 대두되고 있으며, 이러한 목적지향 대화시스템은 사용자의 입 력 텍스트에 대한 의도 분류(intent classification)와 슬롯 태깅(slot tagging)을 주요한 과업으로 한다. 종래 기술에 따른 조건부 무작위장(CRF, Conditional Random Field)에 기반한 시스템의 경우 슬롯 태깅 과업에 서 각 토큰에 대한 결과값을 순차적으로 추론함으로써 각 토큰 주변의 언어적 맥락을 고려하여 상대적으로 높은 정확도의 결과값을 얻을 수 있으나 연산 속도가 느리다는 문제점이 존재하였다. 또한, 종래 기술에 따른 비자기회귀(non-autoregressive) 기법에 기반한 시스템의 경우 상대적으로 빠른 연산 속도로 과업 수행이 가능하나 추론된 결과값의 정확도가 낮다는 문제점이 존재하였다. 즉, 의도 분류와 슬롯 태깅 과업을 수행하는 종래의 자연어 처리 모델은 정확도와 연산 속도가 반비례할 수밖에 없었으므로, 높은 정확도로 상기 과업들을 수행하면서도 상기 과업들의 수행을 위한 빠른 연산이 가능하도록 하 는 새로운 기술이 필요한 실정이다."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 외부지식을 이용한 자연어 처리 방법 및 장치를 제공한다. 본 개시가 해결하고자 하는 과제는 이상에 서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 개시의 다른 과제 및 장점들은 하기의 설명에 의해서 이 해될 수 있고, 본 개시의 실시 예에 의해보다 분명하게 이해될 것이다. 또한, 본 개시가 해결하고자 하는 과제 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 자연어 표현을 포함하는 입력 텍스트를 획득하는 단계; 기생성된 외부지식(external knowledge) 데이터베이스를 참조하여 상기 입력 텍스트에 대한 외부지식 참조 정보를 생성하는 단계; 상기 입력 텍스트 및 상기 외부지식 참조 정보를 기학습된 자연어 처리 모델에 입력하는 단계; 및 상기 입력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 상기 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 상기 자연어 처리 모델의 출력을 획득하는 단계를 포함하는, 외부지식을 이용한 자연어 처리 방법을 제공할 수 있다. 본 개시의 제2 측면은, 외부 장치와 통신을 수행하는 통신 모듈; 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행함으로써 동작하는 프로세서를 포함하되, 상기 프로세서는, 자연어 표현을 포함하는 입력 텍스트를 획득하도록 상기 통신 모듈을 제어하고, 기생성된 외부지식(external knowledge) 데이 터베이스를 참조하여 상기 입력 텍스트에 대한 외부지식 참조 정보를 생성하고, 상기 입력 텍스트 및 상기 외부 지식 참조 정보를 기학습된 자연어 처리 모델에 입력하고, 상기 입력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 상기 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 상기 자연어 처리 모델의 출력을 획득하는, 외부지식을 이용한 자연어 처리 장치를 제공할 수 있다. 본 개시의 제3 측면은, 본 개시의 제1 측면의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 개시의 과제 해결 수단에 의하면, 외부지식 데이터베이스를 참조함으로써 높은 정확도로 의도 분류 과업과 슬롯 태깅 과업을 수행할 수 있다. 또한, 본 개시의 과제 해결 수단에 의하면, 비자기회귀 기법에 기반하여 슬롯 태깅 정보를 생성하는 분류자를 이용함으로써 빠른 연산 속도로 슬롯 태깅 과업을 수행할 수 있다. 또한, 본 개시의 과제 해결 수단에 의하면, 외부지식 데이터베이스를 참조하고, 비자기회귀 기법에 기반하여 슬 롯 태깅 정보를 생성하는 분류자를 이용함으로써, 종래 기술에 따른 연산 속도와 정확도간 상충관계를 극복할 수 있다."}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시예들로 한정되는 것이 아니라, 서로 다 른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이"}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다.\"매커니즘\", \"요소\", \"수단\" 및 \"구성\"등과 같은 용어는 넓게 사용될 수 있으며, 기계적이 고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 사용자 단말, 자연어 처리 장치 및 외부지식 데이터베이스를 포함하는 시스템의 개략 적인 구성도이다. 도 1을 참조하면, 일 실시예에 따른 시스템은 사용자 단말, 자연어 처리 장치 및 외부지식 (external knowledge) 데이터베이스를 포함할 수 있다. 본 개시의 사용자 단말은 인공지능 대화 서비스를 이용하는 사용자의 단말로서, 일 실시예에 따른 사용자 단말은 사용자가 텍스트를 입력할 수 있도록 사용자에게 인터페이스를 제공하는 단말을 포함할 수 있다. 일 실시예에 따른 사용자 단말은 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 가전기기, 카메라가 탑재된 디바이 스 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있다. 또한, 사용자 단말은 통신 기능 및 데이터 프로 세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 디바이스일 수 있으나, 이에 한정되지 않는 다. 한편, 다른 일 실시예에 따르면, 도 1에 도시된 것과 달리 시스템은 사용자 단말을 포함하지 않을 수 있으며, 자연어 처리 장치는 사용자로부터 텍스트 입력을 직접 수신할 수 있다. 본 개시의 자연어 처리 장치는, 자연어 처리를 활용하는 각종 서비스, 인공지능 대화 서비스 또는 목적지 향 대화 서비스를 제공할 수 있는 웹 및/또는 앱을 관리하는 모든 종류의 서버를 의미할 수 있으며 각종 관리 플랫폼의 홈페이지 등을 관리하는 서버를 의미할 수 있다. 그러나, 이에 제한되지 않는다. 일 실시예에 따른 자연어 처리 장치는 차량 등에 탑재된 컴퓨팅 장치 등 이동성을 가진 모바일 전자 장치 를 포함할 수 있으며, 또는, 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱,미디어 플레이어, 내비게이션 및 기타 모바일 전자 장치 등으로 구현될 수 있다. 본 개시의 외부지식 데이터베이스는 자연어 처리 장치가 입력 텍스트에 대한 자연어 처리를 수행하는 과정에서 참조 가능한 외부지식 정보를 저장하는 데이터베이스이다. 일 실시예에 따른 외부지식 정보는 자연어 처리 장치의 관리 주체, 즉 인공지능 대화 서비스를 제공하는 서버 관리 주체 등에 의해 미리 생성될 수 있다. 외부지식 데이터베이스에 저장되는 정보의 구조 및 종류 등은 도 3 등을 참조하여 후술하도록 한다. 외부지식 데이터베이스는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read- only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플래시 메모리를 포함할 수 있다. 일 실시예에 따르면, 외부지식 데이터베이스는 도 1에 도시된 바와 같이 자연어 처리 장치의 외부에 서 자연어 처리 장치와 네트워크를 이용하여 통신을 수행함으로써 외부지식 정보를 제공하는 저장 매체를 포함할 수 있다. 예를 들어, 외부지식 데이터베이스는 자연어 처리 장치가 네트워크를 이용하여 접근 가능한 클라우드 서버일 수 있다. 한편, 다른 일 실시예에 따르면, 외부지식 데이터베이스는 도 1에 도시된 바와 달리 자연어 처리 장치 의 일부로서 포함되어 자연어 처리 장치로부터 직접 접근이 가능한 저장 매체를 포함할 수 있다. 도 1에 도시된 각각의 장치들은 상호간 및/또는 다른 장치와 네트워크를 통하여 통신할 수 있다. 네트워크는 서 로 다른 주체들이 서로 원활하게 통신을 할 수 있도록 하는 포괄적인 의미의 데이터 통신망이며, 유선 인터넷, 무선 인터넷 및 모바일 무선 통신망을 포함할 수 있다. 예를 들어, 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통 신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 포함할 수 있다. 또한, 무선 통신은 예를 들어, 무선 랜(Wi-Fi), 블루투스, 저전력 블루투스(Bluetooth low energy), 지그비(ZigBee), WFD(Wi-Fi Direct), UWB(ultra-wideband), 적외선 통신(IrDA, infrared Data Association), NFC(Near Field Communication) 등이 있을 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에 따르면, 사용자 단말은 사용자로부터 입력된 입력 텍스트를 네트워크를 통한 통신을 수행함으 로써 자연어 처리 장치로 전송할 수 있고, 자연어 처리 장치는 입력 텍스트를 획득할 수 있다. 한편, 다른 일 실시예에 따르면, 자연어 처리 장치는 사용자에 대한 자체적인 입력 인터페이스를 포함할 수 있으 며, 사용자로부터 직접 입력 텍스트를 입력 받을 수 있다. 또한, 일 실시예에 따르면, 자연어 처리 장치는 네트워크를 통한 통신을 수행함으로써 외부지식 데이터베 이스를 참조할 수 있다. 자연어 처리 장치는 기생성된 외부지식 데이터베이스를 참조하여 입력 텍스트에 대한 외부지식 참조 정보를 생성할 수 있다. 이때, 자연어 처리 장치는 네트워크를 통한 통신을 수행함으로써 외부지식 데이터베이스에 저장된 데이터의 일종인 대상 쌍을 획득할 수 있다. 또한, 일 실시예에 따르면, 자연어 처리 장치는 네트워크를 통한 통신을 수행함으로써 외부지식 데이터베 이스에서 입력 텍스트에 관련된 정보 검색을 수행할 수 있다. 예를 들어, 자연어 처리 장치는 외부지 식 데이터베이스에서 입력 텍스트에 대한 복수개의 n-그램을 검색할 수 있다. 또한, 일 실시예에 따르면, 자연어 처리 장치는 의도 분류 정보 및 슬롯 태깅 정보에 기초하여 생성되는 입력 텍스트에 대한 응답을, 네트워크를 통한 통신을 수행함으로써 사용자 단말로 전송할 수 있다. 이때, 사용자 단말은 입력 텍스트에 대한 응답을 사용자에게 표시할 수 있다. 한편, 다른 일 실시예에 따르면, 자연어 처리 장치는 자체적인 표시부를 포함할 수 있으며, 표시부를 통해 입력 텍스트에 대한 응답을 표시 할 수 있다. 도 2는 일 실시예에 따라 외부지식 데이터베이스를 참조하여 외부지식 참조 정보를 생성하는 과정을 설명하기 위한 예시적인 도면이다. 자연어 처리 장치는 자연어 표현을 포함하는 입력 텍스트를 획득할 수 있다. 본 개시에서 자연어 표 현은 사람의 의사소통에서 사용되는 언어로 이루어지는 표현이며, 일 실시예에 따른 자연어 표현은 단어 및 구 문 등의 표현을 포함할 수 있다. 도 1을 참조하여 상술한 바와 같이, 일 실시예에 따른 자연어 처리 장치는 사용자 단말과 네트워크를 통한 통신을 수행함으로써 입력 텍스트를 획득하거나, 사용자로부터 직접 입력 텍스트를 입력 받음으로써 입력 텍스트를 획득할 수 있다. 도 2를 참조하면, 자연어 처리 장치는 기생성된 외부지식 데이터베이스를 참조하여 입력 텍스트(20 1)에 대한 외부지식 참조 정보를 생성할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 외부지식 데이터베이스에서 입력 텍스트에 관련된 외 부지식 정보를 조회 또는 검색함으로써 외부지식 데이터베이스를 참조할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 외부지식 데이터베이스를 참조함으로써 외부지식 데이터베 이스에 저장된 외부지식 정보 중 입력 텍스트에 대한 응답을 생성하는 과정에서 이용될 수 있는 외부 지식 정보를 선택하여 획득할 수 있다. 본 개시의 외부지식 참조 정보는 입력 텍스트에 포함된 자연어 표현에 자연어 표현의 유형이 매칭된 정보를 의미한다. 일 실시예에 따르면, 외부지식 참조 정보는 입력 텍스트를 구성하는 각각의 문자에 있어서 자연어 표현에 대응되는 위치의 문자에 대하여 자연어 표현의 유형이 매칭된 정보를 포함할 수 있다. 도 3은 일 실시예에 따른 표현, 표현에 대한 유형 및 외부지식 데이터베이스에 포함된 표현-유형 쌍을 설명하기 위한 예시적인 도면이다. 도 3을 참조하면, 일 실시예에 따른 외부지식 데이터베이스는 표현 및 표현에 대한 유형으로 구 성되는 복수개의 표현-유형 쌍을 포함할 수 있다. 일 실시예에 따른 표현은 자연어 표현을 포함할 수 있으 며, 단어 및 구문을 포함할 수 있다. 예를 들어, 표현은 서울, 홍길동, 서울은행 등의 자연어 표현을 포함 할 수 있다. 일 실시예에 따른 표현에 대한 유형은 표현이 어떤 범주에 속하는지를 나타내는 분류를 포함할 수 있 다. 예를 들어, 표현에 대한 유형은 표현이 어떤 종류의 객체나 개념을 지시하는지를 분류하는데 이 용되는 레이블 또는 태그로서 설정될 수 있다. 한편, 특정한 분야 또는 전문 영역에 있어서 자연어 처리 과정에 필요한 정보와 정보의 특성이 상이할 수 있다. 일 실시예에 따른 외부지식 데이터베이스는 자연어 처리 장치가 이용되는 목적 또는 이용되는 분야에 따라 달리 생성될 수 있다. 즉, 외부지식 데이터베이스는 자연어 처리 장치가 해결하고자 하는 문제 영역인 도메인(domain)에 따라 달리 생성될 수 있다. 일 실시예에 따른 도메인은, 네비게이션, 지도 서비스, 예약 서비스, 의료기록 분석, 진료 대화 분석, 법률문서 분석, 주식시장 분석 및/또는 부동산 정보 분석 등 인공지능을 이용한 자연어 처리가 유용하게 이용될 수 있는 다양한 영역 중 적어도 하나를 포함할 수 있다. 한편, 일 실시예에 따르면 도메인은 입력 텍스트가 획득되기 전 미리 선택될 수 있다. 일 실시예에 따르면, 선택된 도메인에 기초하여 복수의 데이터베이스 중 자연어 처리 장치에 의해 이용되는 외부지식 데이터베이스가 선택될 수 있다. 다른 일 실시예에 따르면, 선택된 도메인에 기초하여 외부지식 데이터베이스 내에서 참조의 대상이 되는 유형이 설정될 수 있다. 예를 들어, 제1 도메인이 선택되는 경우, 지역명 및 기관명을 유형으로 하는 외부지식 정보가 참조의 대상이 되고, 제2 도메인이 선택되는 경우, 지역명 및 인물명을 유형으로 하는 외부지식 정보가 참조의 대상이 될 수 있다. 일 실시예에 따르면, 도메인에 따라서 외부지식 데이터베이스에 저장되는 표현 및 표현에 대한 유형 의 종류가 상이할 수 있으며, 도메인에 따라서 동일한 표현이더라도 상이한 유형에 매핑될 수 있다. 나아가, 자연어 처리 장치가 동일한 도메인에서 이용되는 경우에도, 외부지식 데이터베이스의 생성 주체에 따라 적절하게 이용될 수 있는 외부지식 정보가 상이하게 채택될 수 있으므로, 외부지식 데이터베이스 에 저장된 표현 및 표현에 대한 유형이 상이할 수 있으며, 동일한 표현이 상이한 유형에 매핑될 수 있다. 일 실시예에 따른 표현에 대한 유형은, 도메인에 기초하여 설정되는 적어도 하나의 유형을 포함할 수 있다. 예를 들어, 도메인이 네비게이션 또는 지도 서비스로 선택되는 경우, 표현에 대한 유형은 지역명 및/또는 기관명 등으로 설정될 수 있다.다른 예를 들어, 도메인이 예약 서비스로 선택되는 경우, 표현에 대한 유형은 지역명, 기관명 및/또는 인 물명 등으로 설정될 수 있다. 또 다른 예를 들어, 도메인이 의료 기록 분석 또는 진료 대화 분석으로 선택되는 경우, 표현에 대한 유형 은 인물명, 신체부위 및/또는 병명 등으로 설정될 수 있다. 외부지식 데이터베이스를 구성하는 일 실시예에 따른 표현에 대한 유형은, 지역명, 인물명 및 기관명 등 다양한 명사 유형 중 적어도 하나를 포함할 수 있다. 자연어 처리의 대상이 되는 입력 텍스트에는, 지 역명, 인물명 및 기관명 등의 명사 표현에 상대적으로 높은 중요도의 정보가 드러나는 경우가 다수 존재한다. 따라서, 표현에 대한 유형이 지역명, 인물명 및 기관명 등 다양한 명사 유형 중 적어도 하나를 포함함으로 써 자연어 처리 장치는 빠른 연산과 높은 정확도로 의도 분류 및/또는 슬롯 태깅 과업을 수행할 수 있다. 일 실시예에 따른 지역명은 특징 지역, 특정 장소 또는 특정 위치 표현에 대한 유형일 수 있다. 예를 들어, 지 역명을 유형으로 하는 표현은, 서울 및 부산 등의 도시의 명칭, 한강 및 남산 등의 지리적 영역의 명칭 및/또는 A 건물, B 회사 및 C 식당 등 특정 주소지에 위치하는 대상을 지칭하는 명칭 등을 포함할 수 있다. 다만, 이에 제한되지 않는다. 일 실시예에 따른 인물명은 특정 개인이나 특정 그룹의 실명, 별명, 예명 등 다양한 형태의 이름 표현에 대한 유형일 수 있다. 예를 들어, 인물명을 유형으로 하는 표현은 홍길동 및 존스미스 등 개인의 이름, BTS 및 비틀 즈와 같은 그룹의 이름 등을 포함할 수 있다. 다만, 이에 제한되지 않는다. 일 실시예에 따른 기관명은 특정 조직, 기업, 단체, 정부 기관 등 다양한 형태의 조직 기관의 명칭에 대한 유형 일 수 있다. 예를 들어, 기관명을 유형으로 하는 표현은 OO 자동차 및 OO 전자 등의 기업이나 조직의 명칭, OO 부 및 OO 청과 같은 정부 기관의 명칭 등을 포함할 수 있다. 다만, 이에 제한되지 않는다. 본 개시의 표현-유형 쌍은 외부지식 데이터베이스에 저장되는 외부지식 정보로서, 특정 표현이 어떠한 유 형에 대응되는지 여부를 지시하는 정보이다. 표현-유형 쌍이 외부지식 데이터베이스에 저장되는 구체적인 저장 구조는 종래의 기술 또는 향후 개발되는 기술에 따른 다양한 구조를 가질 수 있다. 예를 들어, 외부지식 데이터베이스에는 관계형 데이터베이스 구조, NoSQL 문서 기반 구조 및 키-값 데이터 베이스 구조 중 적어도 하나에 기반하여 표현-유형 쌍이 저장될 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따르면, 자연어 처리 장치는 외부지식 데이터베이스를 참조하여 외부지식 데이터베이스 에 저장된 표현-유형 쌍 중 적어도 하나를 입력 텍스트에 매칭함으로써 외부지식 참조 정보를 생성할 수 있다. 예를 들어, 자연어 처리 장치는 \"서울은행으로안내\"와 같은 입력 텍스트를 획득하고, 외부지식 데이 터베이스를 참조하여 \"서울은행-기관명\"과 같은 표현-유형 쌍을 선택 및 획득할 수 있다. 자연어 처리 장 치는 \"서울은행으로안내\"에 \"서울은행-기관명\"을 매칭함으로써 외부지식 참조 정보를 생성할 수 있다. 일 예로서, 자연어 처리 장치는 \"서\", \"울\", \"은\" 및 \"행\"에 기관명이라는 유형 정보가 부여되고, \"으\", \"로\", \"안\" 및 \"내\"에 유형 없음이라는 유형 정보가 부여된 외부지식 참조 정보를 생성할 수 있다. 도 4는 일 실시예에 따라 입력 텍스트를 복수개의 n-그램으로 분리하고, 외부지식 데이터베이스에서 복수개의 n-그램을 검색하는 과정을 설명하기 위한 예시적인 도면이다. 도 4를 참조하면, 일 실시예에 따르면, 자연어 처리 장치는 입력 텍스트를 복수개의 n-그램(n- gram)으로 분리할 수 있다. n-그램은, 입력 텍스트 등 문자 집합에서 연속된 n개 문자로 구성된 부분 집합으로 이해될 수 있다. 예를 들어, 입력 텍스트가\"서울은행\"인 경우, 자연어 처리 장치는 \"서울은행\"을 4-그램으로서 \"서울 은행\", 3-그램으로서 \"서울은\" 및 \"울은행\", 그리고 2-그램으로서 \"서울\", \"울은\", \"은행\"으로 분리할 수 있다. 자연어 처리 장치는 외부지식 데이터베이스에서 복수개의 n-그램을 검색하고, 검색의 결과에 기 초하여 표현-유형 쌍 중에서 적어도 하나의 대상 쌍을 선택할 수 있다. 예를 들어, 외부지식 데이터베이스가 도 3에 도시된 바와 같이 외부지식 정보를 저장하고 있고, 입력 텍스 트가 \"서울은행\"인 경우, 자연어 처리 장치는 외부지식 데이터베이스에서 \"서울은행\", \"서울은\", \"울은행\", \"서울\", \"울은\" 및 \"은행\"을 검색할 수 있다. 이때, 외부지식 데이터베이스에서 검색되는 결과는 \"서울은행\" 및 \"서울\"일 수 있으며, 자연어 처리 장치 는 외부지식 데이터베이스에 저장된 표현-유형 쌍 중에서 \"서울은행-기관명\"및 \"서울-지역명\"을 대상 쌍으로서 선택할 수 있다. 본 개시의 대상 쌍은 대상 표현 및 대상 유형으로 구성될 수 있다. 일 실시예에 따른 대상 표현은 입력 텍 스트에 포함된 표현인 동시에, 외부지식 데이터베이스에 저장된 표현을 포함할 수 있다. 일 실시예에 따른 대상 유형은 상기 대상 표현에 대한 유형을 포함할 수 있다. 상술한 대상 쌍의 예시에서, \"서울은행\" 및 \"서울\"은 대상 표현이며, 대상 표현 각각에 대한 유형인 \"기관 명\" 및 \"지역명\"은 대상 표현 각각에 대한 대상 유형으로 이해될 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 대상 유형을 입력 텍스트에 포함된 대상 표현에 매칭함으로 써 외부지식 참조 정보를 생성할 수 있다. 예를 들어, 자연어 처리 장치는 입력 텍스트를 구성 하는 문자 중, 제1 대상 표현인 \"서울은행\"에 대응되는 위치의 문자, 즉 \"서\", \"울\", \"은\" 및 \"행\"에 제1 대상 유형인 \"기관명\"을 매칭하고, 제2 대상 표현인 \"서울\"에 대응되는 위치의 문자, 즉 \"서\" 및 \"울\"에 제2 대상 유 형인 \"지역명\"을 매칭함으로써 외부지식 참조 정보를 생성할 수 있다. 도 5는 일 실시예에 따라 소정의 기준에 기초하여 유형을 표현에 매칭하는 과정을 설명하기 위한 예시적인 도면 이다. 일 실시예에 따르면, 대상 쌍은 제1 쌍 및 제2 쌍을 포함할 수 있고, 제1 쌍은 제1 표현 및 제1 유형으로 구성될 수 있으며, 제2 쌍은 제2 표현 및 제2 유형으로 구성될 수 있다. 일 실시예에 따르면, 제2 유형은 제1 유형과 동일하거나, 상이할 수 있다. 이때, 제1 표현 및 제2 표현은 대상 표현으로 이해될 수 있으며, 제1 유형 및 제2 유형은 대상 유형으로 이해될 수 있다. 일 실시예에 따르면, 제1 표현 및 제2 표현은 중복되는 문자를 포함할 수 있다. 일 실시예에 따른 제2 표현은 제1 표현과 상이할 수 있으며, 제1 표현을 구성하는 모든 문자를 포함할 수 있다. 예를 들어, 제1 쌍 및 제2 쌍 은 각각 \"서울-지역명\" 및 \"서울은행-기관명\"일 수 있다. 다른 예를 들어, 제1 쌍 및 제2 쌍은 각각 \"서울은행- 기관명\" 및 \"서울은행서울영업부-지역명\"일 수 있다. 자연어 처리 장치가 제1 유형 및 제2 유형 등의 대상 유형을 입력 텍스트에 포함된 제1 표현 및 제2 표현 등의 대상 표현에 매칭하는 과정에서, 제1 표현 및 제2 표현에 중복되어 포함된 문자에 대한 매칭 과정에 서 소정의 기준이 이용될 수 있다. 예를 들어, 제1 쌍 및 제2 쌍이 \"서울-지역명\", \"서울은행-기관명\"인 경우, 제1 표현 및 제2 표현에 중복되어 포함된 문자인 \"서울\"에 대상 유형을 매칭하는 과정에서, 소정의 기준이 이용될 수 있다. 다른 예를 들어, 제1 쌍 및 제2 쌍이 \"서울은행-기관명\", \"서울은행서울영업부-지역명\"인 경우, 제1 표현 및 제 2 표현에 중복되어 포함된 문자인 \"서울은행\"에 대상 유형을 매칭하는 과정에서 소정의 기준이 이용될 수 있다. 도 5를 참조하면, 자연어 처리 장치는 소정의 기준에 기초하여 제1 유형 및 제2 유형 중 적어도 하나를 제 1 표현에 매칭함으로써 외부지식 참조 정보를 생성할 수 있다. 한편, 도 5에 도시된 소정의 기준에 따른 외부정보 참조 정보(510, 520, 530, 540)는 도 2에 도시된 외부정보 참조 정보의 일 예시로 이해될 수 있 다. 다만, 소정의 기준은 도 5를 참조하여 후술되는 예시에 한정되지 않는다. 도 5에 도시된 제1 기준에 따른 외부정보 참조 정보 및 제2 기준에 따른 외부정보 참조 정보는 하나 의 문자에 하나의 유형만이 매칭되는 예시이며, 제3 기준에 따른 외부정보 참조 정보 및 제4 기준에 따른 외부정보 참조 정보는 하나의 문자에 하나의 유형뿐만 아니라 여러 유형이 매칭되는 예시이다. 아래의 예시들은, 제2 표현은 제1 표현과 상이하고 제1 표현을 구성하는 모든 문자를 포함한다는 가정 아래에서 설명되며, 아래의 예시들에서 제1 쌍, 제2 쌍, 제1 표현, 제2 표현, 제1 유형 및 제2 유형은 상대적인 표현으로 이해될 수 있다. 예를 들어, \"서울은행서울영업부\"와 \"서울\" 또는 서울은행서울영업부\"와 \"서울은행\"의 관계에서, \"서울은행서울 영업부\"는 제2 표현으로 이해되고 \"서울\" 및 \"서울은행\"은 제1 표현으로 이해될 수 있으며, \"서울은행\"과 \"서울\"의 관계에서 \"서울은행\"은 제2 표현으로 이해되고 \"서울\"은 제1 표현으로 이해될 수 있다.이하에서는, 자연어 처리 장치가 제1 기준에 따른 외부정보 참조 정보를 생성하는 과정에 관하여 설 명하도록 한다. 제1 기준은, 문자열의 길이가 긴 대상 표현부터, 짧은 대상 표현에 대한 매칭을 순차적으로 수행하며, 앞서 매 칭된 유형이 이후 매칭되는 유형과 상이한 경우, 이후 매칭되는 유형으로 앞서 매칭된 유형을 덮어씌우는 것일 수 있다. 예를 들어, 외부지식 데이터베이스가 도 3에 도시된 바와 같이 외부지식 정보를 저장하고 있고, 입력 텍스 트가 \"서울은행서울영업부\"인 경우, 대상 쌍은 \"서울-지역명\", \"서울은행-기관명\", \"서울은행서울영업부- 지역명\"으로 선택될 수 있다. 자연어 처리 장치는 대상 표현 \"서울은행서울영업부\"에 1차 매칭을 수행하여 각 문자에 대상 유형 \"지역명\"을 매칭할 수 있다. 이후, 자연어 처리 장치는 대상 표현 \"서울은행\"에 2차 매칭을 수행하여 \"서 울은행\"을 구성하는 각 문자에 대상 유형 \"기관명\"을 덮어씌울 수 있다. 이후, 자연어 처리 장치는 대상 표현 \"서울\"에 최종 매칭을 수행하여, \"서울\"을 구성하는 각 문자에 대상 유형 \"지역명\"을 덮어씌울 수 있다. 자연어 처리 장치는 1차 매칭, 2차 매칭 및 최종 매칭을 순차적으로 수행함으로써, 입력 텍스트인 \" 서울은행서울영업부\"를 구성하는 9개 문자 중, 3번 및 4번 위치에 대상 유형 \"기관명\"이 매칭되고, 나머지 위치 에 대상 유형 \"지역명\"이 매칭된 제1 기준에 따른 외부정보 참조 정보를 생성할 수 있다. 이하에서는, 자연어 처리 장치가 제2 기준에 따른 외부정보 참조 정보를 생성하는 과정에 관하여 설 명하도록 한다. 제2 기준은, 제1 유형 및 제2 유형 중, 문자열의 길이가 더 긴 대상 표현에 대한 대상 유형을 매칭하는 것일 수 있다. 예를 들어, 외부지식 데이터베이스가 도 3에 도시된 바와 같이 외부지식 정보를 저장하고 있고, 입력 텍스 트가 \"서울은행서울영업부\"인 경우, 자연어 처리 장치는 대상 표현인 \"서울\", \"서울은행\" 및 \"서울은 행서울영업부\"중 문자열의 길이가 가장 긴 대상 표현인 \"서울은행서울영업부\"에 대한 대상 유형 \"지역명\"을 \"서 울은행서울영업부\"를 구성하는 모든 문자에 매칭할 수 있다. 즉, 자연어 처리 장치는 입력 텍스트에 포함된 대상 표현\"서울은행\"에 대상 쌍 \"서울은행-기관명\"에 따른 대상 유형 \"기관명\"을 매칭하는 것이 아닌, 대상 쌍 \"서울은행서울영업부-지역명\"에 따른 대상 유형 \"지역 명\"을 매칭함으로써 입력 텍스트인\"서울은행서울영업부\"를 구성하는 모든 문자에 \"지역명\"이 매칭된 제2 기준에 따른 외부정보 참조 정보를 생성할 수 있다. 한편, 다른 예를 들어, 외부지식 데이터베이스가 도 3에 도시된 바와 같이 외부지식 정보를 저장하고 있고, 입력 텍스트가 \"서울은행\"인 경우, 자연어 처리 장치는 대상 표현인 \"서울\" 및 \"서울은행\" 중 문자열의 길이가 더 긴 대상 표현인 \"서울은행\"에 대한 대상 유형 \"기관명\"을 \"서울은행\"을 구성하는 모든 문자 에 매칭할 수 있다. 즉, 자연어 처리 장치는 입력 텍스트에 포함된 대상 표현 \"서울\"에 대상 쌍 \"서울-지역명\"에 따른 대 상 유형 \"지역명\"을 매칭하는 것이 아닌, \"서울은행-기관명\"에 따른 대상 유형 \"기관명\"을 매칭함으로써 입력 텍스트인 \"서울은행\"을 구성하는 모든 문자에 \"기관명\"이 매칭된 제2 기준에 따른 외부정보 참조 정보 를 생성할 수 있다. 이하에서는, 자연어 처리 장치가 제3 기준에 따른 외부정보 참조 정보를 생성하는 과정에 관하여 설 명하도록 한다. 제3 기준은, 제1 표현에 제1 유형 및 제2 유형을 모두 매칭하는 것일 수 있다. 예를 들어, 외부지식 데이터베이스가 도 3에 도시된 바와 같이 외부지식 정보를 저장하고 있고, 입력 텍스 트가 \"서울은행서울영업부\"인 경우, 대상 쌍은 \"서울-지역명\", \"서울은행-기관명\", \"서울은행서울영업부- 지역명\"으로 선택될 수 있다. 자연어 처리 장치는 대상 쌍 \"서울은행-기관명\"에 따라 대상 표현 \"서울은행\"에 대상 유형 \"기관명\"을 매 칭하고, 대상 쌍 \"서울-지역명\" 및 \"서울은행서울영업부\"에 따라 대상 표현 \"서울은행서울영업부\"에 대상 유형 \"지역명\"을 매칭할 수 있다.최종적으로, 자연어 처리 장치는 입력 텍스트인 \"서울은행서울영업부\"를 구성하는 9개 문자 중, 1번 내지 4번 위치에 대상 유형 \"지역명\" 및 \"기관명\"이 매칭되고, 나머지 위치에 대상 유형 \"지역명\"이 매칭된 제3 기준에 따른 외부정보 참조 정보를 생성할 수 있다. 한편, 다른 예를 들어, 외부지식 데이터베이스가 도 3에 도시된 바와 같이 외부지식 정보를 저장하고 있고, 입력 텍스트가 \"서울은행\"인 경우, 대상 쌍은 \"서울-지역명\" 및 \"서울은행-기관명\"으로 선택될 수 있다. 자연어 처리 장치는 대상 쌍 \"서울은행-기관명\"에 따라 대상 표현 \"서울은행\"에 대상 유형 \"기관명\"을 매 칭하고, 대상 쌍 \"서울-지역명\"에 따라 대상 표현 \"서울\"에 \"지역명\"을 매칭할 수 있다. 최종적으로, 자연어 처리 장치는 입력 텍스트인 \"서울은행\"을 구성하는 4개 문자 중, 1번 내지 2번 위치에 대상 유형 \"지역명\" 및 \"기관명\"이 매칭되고, 나머지 위치에 대상 유형 \"기관명\"이 매칭된 제3 기준에 따른 외부정보 참조 정보를 생성할 수 있다. 이하에서는, 자연어 처리 장치가 제4 기준에 따른 외부정보 참조 정보를 생성하는 과정에 관하여 설 명하도록 한다. 제4 기준은, 제1 표현에 제1 유형 및 제2 유형을 모두 매칭하되, 매칭의 횟수를 반영하여 매칭하는 것일 수 있 다. 즉, 제4 기준은 매칭의 빈도에 기반하여 문자별로 대상 유형 가중치를 부여하는 것으로 이해될 수 있다. 예를 들어, 외부지식 데이터베이스가 도 3에 도시된 바와 같이 외부지식 정보를 저장하고 있고, 입력 텍스 트가 \"서울은행서울영업부\"인 경우, 대상 쌍은 \"서울-지역명\", \"서울은행-기관명\", \"서울은행서울영업부- 지역명\"으로 선택될 수 있다. 자연어 처리 장치는 대상 쌍 \"서울-지역명\"에 따라 대상 표현 \"서울\" 위치에 대상 유형 \"지역명\" 매칭을 1 회 카운트하고, 대상 쌍 \"서울은행-기관명\"에 따라 대상 표현 \"서울은행\" 위치에 대상 유형 \"기관명\" 매칭을 1 회 카운트하고, 대상 쌍 \"서울은행서울영업부-지역명\"에 따라 대상 표현 \"서울은행서울영엉부\"에 대상 유형 \"지 역명\" 매칭을 1회 카운트할 수 있다. 최종적으로, 자연어 처리 장치는 입력 텍스트인 \"서울은행서울영업부\"를 구성하는 9개 문자 중, 1번 내지 2번 위치에 대상 유형 \"지역명\" 2회 및 \"기관명\" 1회가 매칭되고, 3번 내지 4번 위치에 대상 유형 \"지역명\" 1회 및 \"기관명\" 1회가 매칭되고, 5번 내지 6번 위치에 대상 유형 \"지역명\" 2회 및 \"기관명\" 0회가 매 칭되고, 나머지 위치에 대상 유형 \"지역명\" 1회 및 \"기관명\" 0회가 매칭된 제4 기준에 따른 외부정보 참조 정보 를 생성할 수 있다. 도 6은 일 실시예에 따른 자연어 처리 모델을 설명하기 위한 예시적인 도면이다. 도 6에 도시된 입력 텍스트 및 외부지식 참조 정보는 도 2에 도시된 입력 텍스트 및 외부지식 참조 정보에 대응될 수 있다. 도 6을 참조하면, 자연어 처리 장치는 입력 텍스트 및 외부지식 참조 정보를 기학습된 자연어 처리 모델에 입력하고, 자연어 처리 모델의 출력을 획득할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 입력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 자연어 처리 모델의 출력을 획득할 수 있다. 예를 들어, 자연어 처리 장치는 자연어 처리 모델에 입력 텍스트로 \"서울은행으로안내\"를 입력 하고, \"서울은행으로안내\"에 대한 외부지식 참조 정보를 입력할 수 있다. 이때, 자연어 처리 장치가 자연어 처리 모델로부터 획득한 의도 분류 정보는, 입력 텍스트가 \"길 찾기\"의 의도를 가지는 문장이라는 것을 나타낼 수 있다. 또한, 자연어 처리 장치가 자연어 처리 모델로부터 획득한 슬롯 태깅 정보는, 입력 텍스트(60 1)인 \"서울은행으로안내\"에서 \"서울은행\"을 구성하는 문자 또는 그 문자에 대응되는 토큰이 bank라는 클래스에 레이블링되는 것을 나타낼 수 있다. 한편, 일 실시예에 따른 슬롯 태깅 정보는 슬롯 시작 위치를 \"B-\"로, 슬롯 내부 위치를 \"I-\"로, 슬롯 외부 위치를 \"O\"로 표현하는 BIO 표현으로 구현될 수 있으나, 이에 한정되는 것은 아니다.일 실시예에 따른 자연어 처리 모델은 모델 인코더, 모델 디코더 및 분류자(classifier)를 포함할 수 있다. 일 실시예에 따르면, 모델 인코더, 모델 디코더 및 분류자 중 적어도 하나의 적어도 일부는, pre-net, CBHG 모듈, 오토인코더(Autoencoder), DNN(Deep Neural Network), CNN(convolutional neural network), RNN(Recurrent Neural Network), LSTM(Long Short-Term Memory Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등 다양한 인공 신경망 모델 중 적어도 하나 또는 둘 이상의 조합에 기초하여 구현될 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 입력 텍스트 및 외부지식 참조 정보를 모델 인코더 에 입력하여, 모델 인코더의 출력으로서 언어모델 은닉상태(language model hidden state) 및 외부지식 임베딩(external knowledge embedding)을 획득할 수 있다. 일 실시예에 따른 모델 인코더는 모델 인코더에 입력되는 고차원의 데이터를 저차원의 데이터로 변환 하여 출력할 수 있다. 이때, 모델 인코더의 출력은, 입력된 데이터의 특징을 나타낼 수 있으며, 모델 인코 더의 출력은 모델 디코더로 전달될 수 있다. 본 개시에서 은닉상태는 자연어 처리 모델의 특정 레이어 또는 특정 모듈의 출력으로서, 자연어 처리 모델의 최 종 출력이 아닌 출력을 의미한다. 일 실시예에 따른 은닉상태는 다음 레이어 또는 다음 모듈의 입력으로 이용되 며, 본 개시의 은닉상태는 언어모델 은닉상태 및 디코더 은닉상태를 포함한다. 또한, 본 개시에서 외부지식 임베딩은 외부지식 참조 정보로부터 추출된 임베딩이며, 일 실시예에 따 른 외부지식 임베딩은 외부지식 참조 정보의 유의미한 특징들이 저차원의 연속 벡터 공간에 표현될 수 있도록 변환된 임베딩을 포함할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 언어모델 은닉상태 및 외부지식 임베딩을 모델 디코더 에 입력하여, 모델 디코더의 출력으로서 디코더 은닉상태를 획득할 수 있다. 일 실시예에 따른 모델 디코더는 모델 인코더의 출력을 입력으로 획득하여 추가적으로 정보를 추출 또는 변환할 수 있다. 일 실시예에 따르면, 모델 디코더의 출력인 디코더 은닉상태는, 의도 분류 및 슬롯 태깅을 위한 입력 텍스트의 유의미한 특징을 나타내는 데이터를 포함할 수 있다. 자연어 처리 장치는 디코더 은닉상태를 분류자에 입력하여, 분류자의 출력으로서 자연어 처리 모델의 출력을 획득할 수 있다. 일 실시예에 따른 분류자는, 디코더 은닉상태로부터 입력 텍스 트의 의도 또는 목적을 분류함으로써 의도 분류 정보를 생성할 수 있으며, 디코더 은닉상태로부 터 입력 텍스트에 대하여 적어도 하나의 슬롯을 알맞은 클래스에 레이블링함으로써 슬롯 태깅 정보를 생성할 수 있다. 도 7은 일 실시예에 따른 자연어 처리 모델에 포함되는 모델 인코더를 설명하기 위한 예시적인 도면이다. 도 7을 참조하면, 일 실시예에 따른 모델 인코더는 제1 처리부 및 제2 처리부를 포함할 수 있다. 일 실시예에 따른 제1 처리부는 입력 텍스트를 토큰화(tokenize)하는 토큰화 레이어를 포 함할 수 있다. 일 실시예에 따른 토큰화 레이어는 입력 텍스트를 입력으로 하여, 입력 텍스트를 소정의 단위를 갖는 토큰으로 변환할 수 있다. 예를 들어, 토큰화 레이어는 입력 텍스트인 \"서울은행으로안내\"를 \" 서\", \"울\", \"은\", \"행\", \"으\", \"로\", \"안\" 및 \"내\"에 대응되는 개별적인 토큰으로 변환할 수 있다. 한편, 소정 의 단위는 하나의 글자에 한정되는 것은 아니다. 일 실시예에 따른 제1 처리부는 언어모델 은닉상태를 출력하는 언어모델 레이어를 포함할 수 있 다. 일 실시예에 따른 언어모델 레이어는 입력된 토큰 시퀀스에 대한 문맥적 정보를 포착 및 추출하도록 학습된 언어모델을 포함할 수 있다. 일 실시예에 따른 언어모델 레이어는 토큰화된 입력 텍스트의 문 맥적 정보의 포착 및 추출을 통해 언어모델 은닉상태를 출력할 수 있다. 한편, 일 실시예에 따른 제2 처리부는 외부지식 참조 정보를 입력으로 하고 외부지식 임베딩을 출력으로 하는 임베딩 레이어를 포함할 수 있다. 일 실시예에 따른 임베딩 레이어는 언어모델 은닉상태와 동일한 크기를 가지는 외부지식 임베딩(61 2)을 출력할 수 있다. 예를 들어, 언어모델 은닉상태와 외부지식 임베딩은 동일한 크기를 가지는 행렬(matrix)로 표현될 수 있다. 구체적 일 예로서, 언어모델 은닉상태 및 외부지식 임베딩은 행 또는 열 중 어느 하나가 토큰화된 입 력 텍스트의 총 토큰 수이고, 행 또는 열 중 나머지 하나가 기설정된 토큰별 벡터 사이즈인 행렬로 표현될 수 있다. 도 8은 일 실시예에 따른 자연어 처리 모델에 포함되는 모델 디코더 및 분류자를 설명하기 위한 예시적인 도면 이다. 도 8을 참조하면, 일 실시예에 따른 자연어 처리 장치는 언어모델 은닉상태 및 외부지식 임베딩(61 2)을 모델 디코더에 입력하여, 모델 디코더의 출력으로서 디코더 은닉상태를 획득할 수 있다. 일 실시예에 따른 모델 디코더는 트랜스포머 디코더(Transformer decoder)를 포함할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 언어모델 은닉상태 및 외부지식 임베딩를 결합 (concatenate)하여 모델 디코더에 입력할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 동일한 크기의 행렬인 언어모델 은닉상태 및 외부지식 임베딩을 행렬 결합하고, 행렬 결합의 결과를 모델 디 코더에 입력할 수 있다. 예를 들어, 자연어 처리 장치는 동일한 크기의 행렬인 언어모델 은닉상태 및 외부지식 임베딩을 행 또는 열 기준으로 이어 붙임으로써 행렬 결합을 수행할 수 있다. 한편, 일 실시예에 따른 분류자는 디코더 은닉상태에 기초하여 의도 분류 정보를 생성하는 제1 분류자 및 디코더 은닉상태에 기초하여 슬롯 태깅 정보를 생성하는 제2 분류자를 포함할 수 있다. 일 실시예에 따른 디코더 은닉상태는, 도 6을 참조하여 상술한 바와 같이, 언어모델 은닉상태 및 외 부지식 임베딩으로부터 의도 분류 및 슬롯 태깅을 위한 유의미한 특징이 추출 또는 변환된 데이터를 포함 할 수 있다. 일 실시예에 따른 제1 분류자는 문장 분류 과업의 적어도 일부를 수행할 수 있다. 일 실시예에 따른 제1 분류자는 디코더 은닉상태를 이용하여 입력 텍스트에 대응되는 목적 또는 의도를 분류함으로써 의도 분류 정보를 생성할 수 있다. 예를 들어, 입력 텍스트가 \"서울은행으로안내\"인 경우, 제1 분류자는 디코더 은닉상태가 나타내 는 입력 텍스트의 특징을 이용함으로써, 입력 텍스트의 목적 또는 의도를 \"길 찾기\"로 분류할 수 있 다. 또한, 일 실시예에 따른 제2 분류자는 시퀀스 레이블링 과업의 적어도 일부를 수행할 수 있다. 일 실시예 에 따른 제2 분류자는 디코더 은닉상태를 이용하여 입력 텍스트에 대한 적어도 하나의 슬롯을 알맞은 클래스에 레이블링함으로써 슬롯 태깅 정보를 생성할 수 있다. 예를 들어, 입력 텍스트가 \"서울은행으로안내\"인 경우, 제2 분류자는 디코더 은닉상태가 나타내 는 입력 텍스트의 특징을 이용함으로써, \"서울은행으로안내\"에서 \"서울은행\"을 구성하는 문자 또는 그 문 자에 대응되는 토큰에 bank라는 클래스를 레이블링할 수 있다. 도 9는 일 실시예에 따라 비자기회귀 기법에 기반하여 슬롯 태깅 정보를 생성하는 제2 분류자를 설명하기 위한 예시적인 도면이다. 제2 분류자는 입력 텍스트를 구성하는 각각의 문자 또는 그 문자에 대응되는 토큰에 알맞은 클래스를 레이블링할 수 있다. 일 실시예에 따르면, 제2 분류자는 특정 토큰에 대한 결과값을 추론할 때, 적어도 하 나의 주변 토큰에 대한 결과값을 참고할 수 있다. 예를 들어, 제2 분류자는 조건부 무작위장(CRF, Conditional Random Field)에 기반하는 분류자를 포함할 수 있다. 조건부 무작위장에 기반하여 슬롯 태깅 정보를 생성하는 경우, 제2 분류자는 각 토큰에 대한 결과값을 순 차적으로 추론함으로써 다른 토큰의 결과값을 참고할 수 있고, 각 토큰 주변의 언어적 맥락을 상대적으로 크게 고려할 수 있는 바, 상대적으로 높은 정확도의 결과값을 얻을 수 있다. 한편, 도 9를 참조하면, 일 실시예에 따른 제2 분류자는 비자기회귀(non-autoregressive) 기법에 기반하여 슬롯 태깅 정보를 생성할 수 있다. 일 실시예에 따른 비자기회귀 기법은 비자기회귀 디코딩을 포함할 수 있다. 일 실시예에 따르면, 제2 분류자는 각각의 토큰에 대한 결과값을 추론할 때, 다른 토큰에 대한 결과값을 참고하지 않고, 독립적인 추론을 수행할 수 있다. 예를 들어, 제2 분류자는 비자기회귀(non- autoregressive)에 기반하는 분류자를 포함할 수 있다. 비자기회귀에 기반하여 슬롯 태깅 정보를 생성하는 경우, 제2 분류자는 각 토큰에 대한 결과값을 다른 토큰에 대한 결과값과 독립적으로 추론할 수 있다. 일 실시예에 따른 제2 분류자는 디코더 은닉상태 이용하여 입력 텍스트에 대한 적어도 하나의 슬롯을 알맞은 클래스에 레이블링함으로써 슬롯 태깅 정보를 생성할 수 있다. 도 9에 도시된 디코더 은닉 상태 및 슬롯 태깅 정보는 도 6에 도시된 디코더 은닉상태 및 슬롯 태깅 정보 각각에 대한 예시로 이해될 수 있다. 일 실시예에 따라 비자기회귀에 기반하는 제2 분류자는, 디코더 은닉상태를 입력으로 획득하고, 입력 텍스트의 문자 또는 토큰 각각에 대응되는 디코더 은닉상태의 적어도 일부 각각을 병렬적으로 처리함 으로써 높은 연산 속도로 슬롯 태깅 정보를 생성할 수 있다. 한편, 디코더 은닉상태에는 외부지식 임베딩에 대한 모델 디코더의 처리 결과가 포함되는 바, 외부지식을 참조하지 않는 종래의 비자기회귀 기법과 비교하여 높은 정확도를 가지는 슬롯 태깅 정보를 생 성할 수 있다. 이를 통해, 자연어 처리 모델은 높은 정확도와 높은 연산 속도를 동시에 실현할 수 있다. 도 10은 외부지식을 이용하여 자연어를 처리하는 방법의 일 예시이다. 도 10을 참조하면, 단계 1010에서, 자연어 처리 장치는 자연어 표현을 포함하는 입력 텍스트를 획득할 수 있다. 단계 1020에서, 자연어 처리 장치는 기생성된 외부지식(external knowledge) 데이터베이스를 참조하여 입 력 텍스트에 대한 외부지식 참조 정보를 생성할 수 있다. 일 실시예에 따른 외부지식 데이터베이스는 표현 및 표현에 대한 유형으로 구성되는 복수개의 표현-유형 쌍을 포함할 수 있다. 이때, 자연어 처리 장치는 외부지식 데이터베이스를 참조하여 표현-유형 쌍 중 적어도 하 나를 입력 텍스트에 매칭함으로써 외부지식 참조 정보를 생성할 수 있다. 일 실시예에 따른 표현에 대한 유형은, 선택된 도메인(domain)에 기초하여 설정되는 적어도 하나의 유형을 포함 할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 입력 텍스트를 복수개의 n-그램(n-gram)으로 분리할 수 있다. 자 연어 처리 장치는 외부지식 데이터베이스에서 복수개의 n-그램을 검색하고, 검색의 결과에 기초하여 표현- 유형 쌍 중에서 적어도 하나의 대상 쌍을 선택할 수 있다. 이때, 대상 쌍은 대상 표현 및 대상 유형으로 구성될 수 있다. 자연어 처리 장치는 대상 유형을 입력 텍스트에 포함된 대상 표현에 매칭함으로써 외부지식 참조 정보를 생성할 수 있다. 일 실시예에 따르면, 대상 쌍은 제1 쌍 및 제2 쌍을 포함할 수 있고, 제1 쌍은 제1 표현 및 제1 유형으로 구성 될 수 있으며, 제2 쌍은 제2 표현 및 제2 유형으로 구성될 수 있다. 이때, 제2 표현은 제1 표현과 상이할 수 있 으며, 제1 표현을 구성하는 모든 문자를 포함할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 소정의 기준에 기초하여 제1 유형 및 제2 유형 중 적어도 하나를 제1 표현에 매칭함으로써 외부지식 참조 정보를 생성 할 수 있다. 단계 1030에서, 자연어 처리 장치는 입력 텍스트 및 외부지식 참조 정보를 기학습된 자연어 처리 모델에 입력할 수 있다. 단계 1040에서, 자연어 처리 장치는 입력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 자연어 처리 모델의 출력을 획득할 수 있다. 일 실시예에 따른 자연어 처리 모델은 모델 인코더, 모델 디코더 및 분류자(classifier)를 포함할 수 있다. 일 실시예에 따르면, 자연어 처리 장치는 입력 텍스트 및 외부지식 참조 정보를 모델 인코더에 입력하여, 모델 인코더의 출력으로서 언어모델 은닉상태(language model hidden state) 및 외부지식 임베딩(external knowledge embedding)을 획득할 수 있다. 자연어 처리 장치는 언어모델 은닉상태 및 외부지식 임베딩을 모 델 디코더에 입력하여, 모델 디코더의 출력으로서 디코더 은닉상태를 획득할 수 있다. 자연어 처리 장치는 디코더 은닉상태를 분류자에 입력하여, 분류자의 출력으로서 자연어 처리 모델의 출력을 획득할 수 있다. 일 실시예에 따른 모델 인코더는 제1 처리부 및 제2 처리부를 포함할 수 있다. 일 실시예에 따른 제1 처리부는 입력 텍스트를 토큰화(tokenize)하는 토큰화 레이어 및 언어모델 은닉상태를 출력하는 언어모델 레이어를 포함 할 수 있으며, 일 실시예에 따른 제2 처리부는 외부지식 참조 정보를 입력으로 하고 외부지식 임베딩을 출력으 로 하는 임베딩 레이어를 포함할 수 있다. 일 실시예에 따른 분류자는 디코더 은닉상태에 기초하여 의도 분류 정보를 생성하는 제1 분류자 및 디코더 은닉 상태에 기초하여 슬롯 태깅 정보를 생성하는 제2 분류자를 포함할 수 있다. 일 실시예에 따른 제2 분류자는 비자기회귀(non-autoregressive) 기법에 기반하여 슬롯 태깅 정보를 생성할 수 있다. 도 11은 일 실시예에 따른 자연어 처리 장치의 블록도이다. 한편, 도 11에 도시된 장치는 도 1에 도시된 자연어 처리 장치에 대응될 수 있다. 도 11을 참조하면, 장치는 통신 모듈, 프로세서 및 메모리를 포함할 수 있다. 도 11의 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 11에 도시된 구성요소들 외에 다른"}
{"patent_id": "10-2025-0019246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라면 이해할 수 있다. 통신 모듈은 장치가 사용자 단말, 외부지식 데이터베이스 및/또는 다른 외부 장치와 유 선/무선 통신을 하게 하는 적어도 하나의 구성 요소를 포함할 수 있다. 예를 들어, 통신 모듈은, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적어도 하나를 포함할 수 있다. 메모리는 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있다. 메모리는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플래시 메모리를 포함할 수 있다. 프로세서는 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 메모리에 저장 된 프로그램들을 실행함으로써, 통신 모듈, 메모리 등을 전반적으로 제어할 수 있다. 프로세서 는, 메모리에 저장된 프로그램들을 실행함으로써, 장치의 동작을 제어할 수 있다. 프로세서는 도 1 내지 도 10을 참조하여 상술한 장치의 동작 중 적어도 일부를 제어할 수 있다. 예를 들어, 프로세서는 자연어 표현을 포함하는 입력 텍스트를 획득하도록 상기 통신 모듈을 제어하고, 기생성된 외부지식(external knowledge) 데이터베이스를 참조하여 상기 입력 텍스트에 대한 외부지식 참조 정보 를 생성하고, 상기 입력 텍스트 및 상기 외부지식 참조 정보를 기학습된 자연어 처리 모델에 입력하고, 상기 입 력 텍스트에 대응되는 의도 분류(intent classification) 정보 및 상기 입력 텍스트에 대응되는 슬롯 태깅(slot tagging) 정보를 포함하는 상기 자연어 처리 모델의 출력을 획득할 수 있다. 한편, 프로세서가 동작하는 구체적인 예는 도 1 내지 도 10을 참조하여 상술한 바와 동일하다. 따라서, 이하에서는 프로세서의 동작에 대한 구체적인 설명은 생략한다. 프로세서는 ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예로, 장치는 이동성을 가지는 전자 장치일 수 있다. 예를 들어, 장치는 차량에 탑재된 컴 퓨팅 장치를 포함할 수 있다. 이때, '차량'은 자동차, 버스, 오토바이, 킥보드 또는 트럭과 같이 기관을 가지고 사람이나 물건을 이동시키기 위해 이용되는 모든 종류의 운송 수단을 의미할 수 있다. 다른 예를 들어, 장치 는 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 내 비게이션, 가 탑재된 디바이스 및 기타 모바일 전자 장치로 구현될 수 있다. 다른 실시예로, 장치는 차량 외부에 위치하는 서버일 수 있다. 서버는 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 또 다른 실시예로, 장치에서 수행되는 적어도 하나의 동작은 이동성을 가지는 전자 장치, 차량 내에 임베 디드 되는 전자 장치 및 차량 외부에 위치하는 서버 중 적어도 일부에 의해 수행될 수 있다. 본 개시에 따른 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 개시를 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 일 실시예에 따르면, 본 개시의 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 개시에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 개시에서 모든 예들 또는 예시적인 용어(예를 들어, 등등)의 사용은 단순히 본 개시를 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 개시의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 개시의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 개시의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2025-0019246", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 사용자 단말, 자연어 처리 장치 및 외부지식 데이터베이스를 포함하는 시스템의 개략 적인 구성도이다. 도 2는 일 실시예에 따라 외부지식 데이터베이스를 참조하여 외부지식 참조 정보를 생성하는 과정을 설명하기 위한 예시적인 도면이다. 도 3은 일 실시예에 따른 표현, 표현에 대한 유형 및 외부지식 데이터베이스에 포함된 표현-유형 쌍을 설명하기 위한 예시적인 도면이다. 도 4는 일 실시예에 따라 입력 텍스트를 복수개의 n-그램으로 분리하고, 외부지식 데이터베이스에서 복수개의 n-그램을 검색하는 과정을 설명하기 위한 예시적인 도면이다. 도 5는 일 실시예에 따라 소정의 기준에 기초하여 유형을 표현에 매칭하는 과정을 설명하기 위한 예시적인 도면 이다. 도 6은 일 실시예에 따른 자연어 처리 모델을 설명하기 위한 예시적인 도면이다. 도 7은 일 실시예에 따른 자연어 처리 모델에 포함되는 모델 인코더를 설명하기 위한 예시적인 도면이다. 도 8은 일 실시예에 따른 자연어 처리 모델에 포함되는 모델 디코더 및 분류자를 설명하기 위한 예시적인 도면 이다. 도 9는 일 실시예에 따라 비자기회귀 기법에 기반하여 슬롯 태깅 정보를 생성하는 제2 분류자를 설명하기 위한 예시적인 도면이다. 도 10은 외부지식을 이용하여 자연어를 처리하는 방법의 일 예시이다.도 11은 일 실시예에 따른 자연어 처리 장치의 블록도이다."}
