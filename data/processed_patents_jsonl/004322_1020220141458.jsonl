{"patent_id": "10-2022-0141458", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0060163", "출원번호": "10-2022-0141458", "발명의 명칭": "학습된 신경망을 통한 객체 세그멘테이션 정보의 획득 방법 및 이를 수행하는 서버 시스템", "출원인": "오지큐 주식회사", "발명자": "김경수"}}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에서 수행되는 학습된 신경망을 통한 객체 세그멘테이션 정보의 획득 방법에 있어서,대상 이미지를 인코더에 입력하여 상기 대상 이미지 내 적어도 일 객체의 특징이 축약된 특징맵을 출력하는 단계;상기 출력된 특징맵을 디코더에 입력하여 상기 객체의 특징이 확장된 세그멘테이션맵을 생성하는 단계; 및상기 세그멘테이션맵 내 검출된 객체의 에지를 기반으로 상기 이미지 내 불확실한 마스크를 정제(Refinement)하여 상기 객체 세그멘테이션 정보를 획득하는 단계를 포함하고, 상기 인코더는 객체의 라벨을 이용하여 상기 특징맵 내 객체의 영역을 활성화한 활성맵과 상기 활성맵으로부터픽셀 단위로 재구성된 재구성맵간의 차이를 손실로 학습된 것을 특징으로 하는 객체 세그멘테이션 정보의 획득방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 재구성맵은,상기 활성맵 내 픽셀 간 연관관계(Correlation)에 따라 미탐지(False Negative) 영역을 검출하여 제1 재구성맵을 생성하는 단계; 및상기 활성맵 내 픽셀 간 유사도(Affinity)에 따라 오탐지(False Positive) 영역을 검출하여 제2 재구성맵을 생성하는 단계로 재구성되는 것을 특징으로 하는 객체 세그멘테이션 정보의 획득 방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 디코더는 상기 세그멘테이션맵과 상기 제2 재구성맵의 픽셀 단위의 객체별 확률에 따라 필터링된 재구성세그멘테이션맵 간의 차이를 손실로 학습된 것을 특징으로 하는 객체 세그멘테이션 정보의 획득 방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 객체 세그멘테이션 정보를 획득하는 단계는,상기 세그멘테이션맵 내 픽셀 간 유사도에 따라 오탐지 영역을 검출하여 제2 세그멘테이션맵을 생성하는 단계를더 포함하고,상기 생성된 제2 세그멘테이션맵으로부터 상기 객체 세그멘테이션 정보를 획득하는 것을 특징으로 하는 객체 세그멘테이션 정보의 획득 방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 객체 세그멘테이션 정보를 획득하는 단계는,상기 제2 세그멘테이션맵의 픽셀 단위의 객체별 확률에 따라 필터링된 제3 세그멘테이션맵을 생성하는 단계를더 포함하고,상기 제3 세그멘테이션맵 내 불확실한 마스크를 상기 제2 세그멘테이션맵 내 검출된 객체의 에지를 기반으로 생공개특허 10-2024-0060163-3-성된 슈퍼픽셀을 이용하여 정제하는 것을 특징으로 하는 객체 세그멘테이션 정보의 획득 방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 2 항에 있어서,제1 및 제2 대상 이미지 내 각 객체 세그멘테이션 정보를 이용하여 객체가 합성된 합성 이미지를 생성하는 단계를 더 포함하는 것을 특징으로 하는 객체 세그멘테이션 정보의 획득 방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 특징맵을 출력하는 단계는,상기 인코더로 상기 합성 이미지 내 복수 객체의 특징이 축약된 합성 특징맵을 출력하되,상기 인코더는,상기 합성 이미지 내 제1 및 제2 객체의 라벨을 이용하여 상기 합성 특징맵 내 상기 제1 및 제2 객체의 영역을활성화한 제1 활성맵과, 상기 제1 대상 이미지 및 상기 제2 대상 이미지 각각의 활성맵으로부터 재구성된 재구성맵을 합성한 제2 합성맵 간의 차이를 손실로 학습된 것을 특징으로 하는 객체 세그멘테이션 정보의 획득방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 세그멘테이션맵을 생성하는 단계는,상기 디코더로 상기 합성 특징맵 내 객체의 특징이 확장된 합성 세그멘테이션맵을 생성하되상기 디코더는,상기 합성 세그멘테이션맵과 상기 제1 및 제2 대상 이미지에 대하여 각각 객체별 확률에 따라 필터링된 제3 재구성맵이 합성된 합성 재구성맵 간의 차이를 손실로 학습된 것을 특징으로 하는 객체 세그멘테이션 정보의 획득방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨팅 장치에서 수행되는 학습된 신경망을 통한 이미지 증강 방법에 있어서,복수의 대상 이미지를 입력 받는 단계;각각의 상기 대상 이미지를 인코더에 입력하여 상기 대상 이미지 내 적어도 일 객체의 특징이 축약된 특징맵을출력하는 단계;상기 출력된 특징맵을 디코더에 입력하여 상기 객체의 특징이 확장된 세그멘테이션맵을 생성하는 단계;상기 세그멘테이션맵 내 검출된 객체의 에지를 기반으로 상기 이미지 내 불확실한 마스크를 정제(Refinement)하여 상기 객체 세그멘테이션 정보를 획득하는 단계; 및상기 대상 이미지 내 각 객체 세그멘테이션 정보를 이용하여 객체가 합성된 합성 이미지를 생성하는 단계를 포함하고, 상기 인코더는 객체의 라벨을 이용하여 상기 특징맵 내 객체의 영역을 활성화한 활성맵과 상기 활성맵으로부터픽셀 단위로 재구성된 재구성맵간의 차이를 손실로 학습된 것을 특징으로 하는 이미지 증강 방법."}
{"patent_id": "10-2022-0141458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항 내지 제 8 항 중 어느 한 항에 따른 컴퓨팅 장치에서 수행되는 학습된 신경망을 통한 객체 세그멘테이션 정보의 획득 방법을 수행하는 프로그램이 저장된 컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 객체 세그멘테이션을 위한 방법에 관한 것으로 본 발명에 따른 컴퓨팅 장치에서 수행되는 학습된 신경 망을 통한 객체 세그멘테이션 정보의 획득 방법은 대상 이미지를 인코더에 입력하여 상기 대상 이미지 내 적어도 일 객체의 특징이 축약된 특징맵을 출력하는 단계; 상기 출력된 특징맵을 디코더에 입력하여 상기 객체의 특징이 (뒷면에 계속)"}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 객체 세그멘테이션을 위한 방법에 관한 것이다."}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술의 발달로 다양한 기술 분야에 인공지능이 적용하고 있다. 특히 입력된 이미지에 대한 픽셀 값들을 특징으로 수학적인 연산을 통해 객체를 추적하고, 추적된 객체를 분류 하기 위해 딥러닝 기반의 다양한 알고리즘들이 개발되고 있으며, 행렬로 정의되는 특징 값들에 대한 컨볼루션 연산을 수행하는 복수의 레이어들로 결합된 CNN(Convolution Neural Network) 신경망 모델들은 적용되는 도메인 에 따라 최적화되어 이용되고 있다. 구체적으로 객체의 분류와 함께 이미지 내에서 객체가 존재하는 위치를 바운딩박스 형태로 제공하는 검출기술과, 픽셀단위로 객체를 세분화하여 영역을 추출하는 세그멘테이션 기술로 발전되고 있다. 일예로 2015년 MIT의 논문(Learning Deep Features for Discriminative Localization, [Submitted on 14 Dec 2015], https://arxiv.org/abs/1512.04150)으로 CAM(Class Activation Maps)이라고 하는 알고리즘 은 컨볼루션 네트워크의 최종 출력인 특징맵을 이용하여 신경망 모델이 어떤 특징을 판단 시 중요한 요소로 이용하였는지를 히트맵 형태로 표시하며, 전체 이미지에 대한 개략적인 판단 요소를 제시함으로써 학습을 위한 라벨링 정보로 활용할 수 있도록 한다. 다만, CAM을 이용하여 객체의 픽셀 레벨의 세그멘테이션 결과를 약지도학습의 레이블 데이터로 생성하여 활용하 기 위해서는 보다 정밀한 구분 과정이 필요할 수 있으며 따라서 이에 대한 구체적인 방법이 제시될 필요가 있다."}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이상 본 발명은 객체 세그멘테이션을 위한 신경망의 구조를 제안하는 것을 목적으로 한다. 본 발명은 세그멘테이션을 위한 신경망의 구체적인 학습 방법을 제안하는 것을 목적으로 한다. 또한, 본 발명은 신경망의 출력을 이용하여 학습을 위한 세그멘테이션 데이터를 생성하는 방법을 제안하는 것을 목적으로 한다. 또한, 본 발명은 신경망의 목적에 따라 최적의 손실을 정의하는 방법을 제안하는 것을 목적으로 한다. 또한, 본 발명은 신경망의 세그멘테이션 데이터를 활용하여 복수의 이미지 내 객체의 정밀한 합성 방법을 제안 하는 것을 목적으로 한다. 또한, 본 발명은 신경망의 학습을 위한 양질의 데이터를 증강하는 방법을 제안하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 컴퓨팅 장치에서 수행되는 학습된 신경망을 통 한 객체 세그멘테이션 정보의 획득 방법은 대상 이미지를 인코더에 입력하여 상기 대상 이미지 내 적어도 일 객 체의 특징이 축약된 특징맵을 출력하는 단계; 상기 출력된 특징맵을 디코더에 입력하여 상기 객체의 특징이 확 장된 세그멘테이션맵을 생성하는 단계; 및 상기 세그멘테이션맵 내 검출된 객체의 에지를 기반으로 상기 이미지 내 불확실한 마스크를 정제(Refinement)하여 상기 객체 세그멘테이션 정보를 획득하는 단계를 포함하고, 상기 인코더는 객체의 라벨을 이용하여 상기 특징맵 내 객체의 영역을 활성화한 활성맵과 상기 활성맵으로부터 픽셀 단위로 재구성된 재구성맵간의 차이를 손실로 학습된 것이 바람직하다. 상기 재구성맵은, 상기 활성맵 내 픽셀 간 연관관계(Correlation)에 따라 미탐지(False Negative) 영역을 검출 하여 제1 재구성맵을 생성하는 단계; 및 상기 활성맵 내 픽셀 간 유사도(Affinity)에 따라 오탐지(False Positive) 영역을 검출하여 제2 재구성맵을 생성하는 단계로 재구성되는 것이 바람직하다. 상기 디코더는 상기 세그멘테이션맵과 상기 제2 재구성맵의 픽셀 단위의 객체별 확률에 따라 필터링된 재구성 세그멘테이션맵 간의 차이를 손실로 학습된 것이 바람직하다.상기 객체 세그멘테이션 정보를 획득하는 단계는, 상기 세그멘테이션맵 내 픽셀 간 유사도에 따라 오탐지 영역 을 검출하여 제2 세그멘테이션맵을 생성하는 단계를 더 포함하고, 상기 생성된 제2 세그멘테이션맵으로부터 상 기 객체 세그멘테이션 정보를 획득하는 것이 바람직하다. 상기 객체 세그멘테이션 정보를 획득하는 단계는, 상기 제2 세그멘테이션맵의 픽셀 단위의 객체별 확률에 따라 필터링된 제3 세그멘테이션맵을 생성하는 단계를 더 포함하고, 상기 제3 세그멘테이션맵 내 불확실한 마스크를 상기 제2 세그멘테이션맵 내 검출된 객체의 에지를 기반으로 생성된 슈퍼픽셀을 이용하여 정제하는 것이 바람직 하다. 제1 및 제2 대상 이미지 내 각 객체 세그멘테이션 정보를 이용하여 객체가 합성된 합성 이미지를 생성하는 단계 를 더 포함한다. 상기 특징맵을 출력하는 단계는, 상기 인코더로 상기 합성 이미지 내 복수 객체의 특징이 축약된 합성 특징맵을 출력하되, 상기 인코더는, 상기 합성 이미지 내 제1 및 제2 객체의 라벨을 이용하여 상기 합성 특징맵 내 상기 제1 및 제2 객체의 영역을 활성화한 제1 활성맵과, 상기 제1 대상 이미지 및 상기 제2 대상 이미지 각각의 활성 맵으로부터 재구성된 재구성맵을 합성한 제2 합성맵 간의 차이를 손실로 학습된 것이 바람직하다. 상기 세그멘테이션맵을 생성하는 단계는, 상기 디코더로 상기 합성 특징맵 내 객체의 특징이 확장된 합성 세그 멘테이션맵을 생성하되, 상기 디코더는, 상기 합성 세그멘테이션맵과 상기 제1 및 제2 대상 이미지에 대하여 각각 객체별 확률에 따라 필터링된 제3 재구성맵이 합성된 합성 재구성맵 간의 차이를 손실로 학습된 것이 바람 직하다. 상기 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 컴퓨팅 장치에서 수행되는 학습된 신경망을 통 한 이미지 증강 방법은 복수의 대상 이미지를 입력 받는 단계; 각각의 상기 대상 이미지를 인코더에 입력하여 상기 대상 이미지 내 적어도 일 객체의 특징이 축약된 특징맵을 출력하는 단계; 상기 출력된 특징맵을 디코더에 입력하여 상기 객체의 특징이 확장된 세그멘테이션맵을 생성하는 단계; 상기 세그멘테이션맵 내 검출된 객체의 에지를 기반으로 상기 이미지 내 불확실한 마스크를 정제(Refinement)하여 상기 객체 세그멘테이션 정보를 획득 하는 단계; 및 상기 대상 이미지 내 각 객체 세그멘테이션 정보를 이용하여 객체가 합성된 합성 이미지를 생성 하는 단계를 포함하고, 상기 인코더는 객체의 라벨을 이용하여 상기 특징맵 내 객체의 영역을 활성화한 활성맵 과 상기 활성맵으로부터 픽셀 단위로 재구성된 재구성맵간의 차이를 손실로 학습된 것이 바람직하다."}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 보다 정확한 객체 세그멘테이션 결과를 생성할 수 있다. 또한, 본 발명은 세그멘테이션 결과를 이용하여 세그멘테이션 모델의 학습을 위한 레이블링 시간을 기존 대비 단축시킬 수 있으며, 정확하고 빠르게 생성된 레이블을 이용하여 세그멘테이션 모델을 학습시킬 수 있다. 또한, 본 발명은 인코더와 디코더로 구성된 신경망 모델의 네트워크의 중간 출력들을 이용하여 인코더와 디코더 를 개별적으로 학습시킴으로써 보다 높은 성능의 향상을 이룰 수 있으며, 추가적인 리소스 없이 보다 정확한 세 그멘테이션 결과를 생성할 수 있다. 또한, 본 발명은 세그멘테이션 결과로 획득된 마스크를 이용하여 객체들을 합성함으로써 다양한 합성 (Synthetic) 이미지들을 생성할 수 있다."}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 내용은 단지 발명의 원리를 예시한다. 그러므로 당업자는 비록 본 명세서에 명확히 설명되거나 도시 되 지 않았지만 발명의 원리를 구현하고 발명의 개념과 범위에 포함된 다양한 장치를 발명할 수 있는 것이다. 또한, 본 명세서에 열거된 모든 조건부 용어 및 실시 예들은 원칙적으로, 발명의 개념이 이해되도록 하기 위한 목적으로만 명백히 의도되고, 이외같이 특별히 열거된 실시 예들 및 상태들에 제한적이지 않는 것으로 이해되어 야 한다. 상술한 목적, 특징 및 장점은 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해질 것이며, 그에"}
{"patent_id": "10-2022-0141458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 발명의 기술적 사상을 용이하게 실시할 수 있을 것 이다. 또한, 발명을 설명함에 있어서 발명과 관련된 공지 기술에 대한 구체적인 설명이 발명의 요지를 불필요하게 흐 릴 수 있다고 판단되는 경우에 그 상세한 설명을 생략하기로 한다. 이하에는 첨부한 도면을 참조하여 본 발명의 바람직한 실시 예에 대해 상세하게 설명한다. 이하, 도 1을 참조하여 본 실시예에 따른 신경망의 세그멘테이션(Segmentation) 과정을 보다 상세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 컴퓨팅 장치의 객체 세그멘테이션 방법을 나타내는 흐름도이다. 본 실시예에서 컴퓨팅 장치는 프로세서를 포함하는 단일 컴퓨터 또는 서버, 복수의 서버로 구성되는 서버 시스 템으로 구현될 수 있다. 따라서, 컴퓨팅 장치는 단일 프로세스 상에서 수신된 이미지로부터 세그멘테이션을 수행하는 것 외에 네트워크 통신이 가능한 형태로 구성될 수 있으며 클라우드 형태로 구현되어 다양한 촬영 장치에서 촬영된 영상들을 수신 하여 처리하는 것도 가능하다. 또한, 컴퓨팅 장치는 프로세서 외에 수집된 영상들을 이용하여 학습 데이터로 활용하거나 학습 데이터의 증강 (Augmentation)을 위해 클라우드 기반의 메모리 장치를 포함하여 구성될 수 있다. 예를 들어 본 실시예에 따른 컴퓨팅 장치는 종단에 설치되는 CCTV와 같은 카메라로부터 수신된 이미지로부터 직 접 세그멘테이션 정보를 획득하는 엣지 컴퓨터로 구현되어 세그멘테이션 과정을 수행할 수 있다. 또는 중앙의 서버로 구현되어 세그멘테이션을 수행하는 신경망의 학습 또는 추론을 위하여 수집된 이미지에 대한 배치단위의 처리를 수행하고, 추론 결과를 API 호출에 대한 응답 형태로 제공하는 것도 가능하다. 먼저 본 실시예에 따른 컴퓨팅 장치는 세그멘테이션을 위해 세그멘테이션 대상 이미지(I)를 입력 받는다(S10). 본 실시예에서 세그멘테이션은 이미지에 포함된 객체의 분류(Classification)와 함께 바운딩 박스 형태의 위치 검출(detection)에서 나아가 객체가 위치하는 영역을 픽셀 단위로 구분하는 것을 의미할 수 있다. 이미지 내 객체의 검출은 객체가 위치하는 영역을 좌표와 높이 및 크기로 결정되는 바운딩 박스 형태로 제공하 는 것으로 수행될 수 있으며, 검출 결과를 레이블로 이용하여 이미지를 학습에 이용할 수 있다. 다만, 바운딩 박스로 추출된 영역 내에는 학습에 불필요한 부분이 포함됨에 따른 오검출 문제가 발생할 수 있으 며 따라서 신경망의 학습 성능을 저하시키는 원인으로 작용할 수 있다. 따라서, 신경망의 학습 효과를 높이기 위해서는 보다 정밀한 검출이 필요하다. 또한 배경과 객체의 결합을 통한 다양한 합성 이미지의 생성을 위해서 는 보다 정밀하게 픽셀을 단위로 객체의 영역을 구분될 필요가 있다. 본 실시예에서 신경망의 세그멘테이션은 이미지를 픽셀 단위로 구분하되 정의된 클래스에 기초하여 분류하는 것으로 의미론적 세그멘테이션(Semantic Segmentation)을 목표로 하되, 동일 클래스에 대해서도 각각의 객체를 단 위로 구분하는 인스턴스(Instance) 세그멘테이션 정보를 획득하는 것도 가능하다. 본 실시예에서 입력되는 세그멘테이션 대상 이미지(I)는 카메라 장치를 통해 촬영된 것으로 목적에 따라 보다 신속한 추적을 위해 한 번에 넓은 영역을 촬영한 것일 수 있으며 대화면 이미지일 수도 있다. 대화면 이미지는 예를 들어 항공 사진 형태로 획득될 수 있으며, 예를 들어 드론이 비행 중에 촬영한 지상 영상 을 획득하고, 획득된 전체 영역에 비해 매우 작은 크기의 영역에 해당하는 객체를 보다 정밀하게 세그멘테이션 할 수 있다. 다음, 본 실시예에 따른 컴퓨팅 장치는 대상 이미지(I)를 인코더에 입력하여 대상 이미지(I) 내 적어도 일 객체의 특징이 축약된 특징맵을 출력한다(S20). 인코더는 일반적인 컨볼루션(Convolution) 연산을 수행하는 컨볼루션 네트워크로 구성될 수 있다. 컨볼루 션 네트워크는 복수의 컨볼루션 레이어들로 구성되며 컨볼루션 레이어들은 내부의 필터와 이미지의 픽셀 값들 간의 컨볼루션 연산을 채널 별로 수행함으로써 객체와 관련된 특징들이 강조되어 축약된 형태의 특징맵을 출력 할 수 있다. 이어서, 본 실시예에 따른 컴퓨팅 장치는 출력된 특징맵을 디코더에 입력하여 상기 객체의 특징이 확장된 세그멘테이션맵을 생성한다(S30). 구체적으로 디코더는 인코더에 대칭되는 형상으로 구현될 수 있으며 따라서 디컨볼루션(De- convolution)연산을 수행하는 디컨볼루션 네트워크로 구성될 수 있다. 즉, 디컨볼루션 네트워크 내 각각의 레이어들은 인코더의 출력인 특징맵을 입력으로 특징맵 내 특징 정보 들을 위치 정보를 유지하고, 원본 이미지의 크기에서 해당 특징들이 잘 표현될 수 있도록 확장시킨다. 대칭적인 구조에 따라 인코더의 최종 출력된 특징맵의 크기와 채널은 디코더의 입력에 따른 크기와 채널을 가질 수 있으며, 디코더 내부의 디컨볼루션 레이어를 거치면서 인코더의 출력을 통해 원본 이 미지 크기에서 특징들의 위치 정보들이 복원된 세그멘테이션맵이 출력될 수 있다. 본 실시예에 따른 인코더와 디코더로 구성된 신경망을 잘 학습시키기 위해서는 축약된 특징맵에서 나 타나는 특징 정보들과 디코더로 확장된 세그멘테이션맵에서 나타나는 특징 정보들에 대한 정확한 레이블이 필요 할 수 있다. 다만, 각각의 특징맵에 대한 정확한 레이블을 확보하기 위해서는 수기 형태의 레이블이 필요할 수 있으므로 보 다 효율적인 학습을 위해서 본 실시예에서는 추가적인 네트워크의 출력이나 처리를 통하여 생성된 이미지를 수 도(Pseudo) 레이블로 이용하여 의미 기반의 약지도 세그멘테이션(weakly-supervised semantic segmentation)을 통한 학습을 수행할 수 있다. 구체적인 학습 방법에 대해서는 도 2에 따른 신경망을 포함하는 학습 파이프라인을 참고하여 설명한다. 도 2는 본 발명의 일 실시예에 따른 학습 파이프라인의 구조를 나타내는 예시도이다. 도 2를 참고하면, 상술한 바와 같이 입력된 대상 이미지(I)를 입력으로 인코더는 특징맵을 생성하여 출력 하고, 특징맵은 디코더를 통해 세그멘테이션맵( ) 형태로 출력될 수 있다. 이때 학습을 위한 파이프라인은 인코더의 학습을 위한 제1 학습 파이프라인과 디코더의 학습을 위한 제2 학습 파이프라인으로 구분될 수 있다. 먼저 제1 학습 파이프라인에 대하여 설명하면, 인코더의 출력은 추가적인 레이어를 통해 활성맵( ) 형 태로 생성될 수 있다. 도 3을 참조하여 활성맵( ) 형태의 출력을 수행하는 네트워크 구조에 대하여 보다 상세히 설명하면, 상술한 바와 같이 인코더의 출력으로 최종 특징맵은 분류부에서 미리 결정된 채널과 크기에 따른 형태로 구 성될 수 있다. 바람직하게 최종 특징맵의 채널은 분류하고자 하는 클래스에 따라 결정될 수 있으며 특징맵은 채 널 별로 클래스 내 객체를 식별하는데 주요한 특징이 위치에 따라 강조된 매트릭스 형태로 구성된다. 이상의 컨볼루션 계층에서 출력된 특징맵은 전역 평균 풀링(GAP:Global Average Pooling) 레이어를 통해 평탄화 될 수 있다. 구체적으로 각 채널 별 특징맵의 값들의 평균을 전역 평균 풀링 레이어를 통해 하나의 벡터 값으로 산출할 수 있으며 따라서 채널 별 하나의 벡터로 구성된 1차원 배열을 획득할 수 있다. 다음 전역 평균 풀링 레이어의 출력은 분류하고자 하는 객체의 클래스 별로 정의된 가중치(W1, W2, … Wn)들과 연산된다. 각각의 가중치는 해당 클래스에서 각 채널의 중요도를 나타낼 수 있다. 가중치와 벡터 값의 연산은 활성화 함수로 소프트맥스의 입력으로 주어지게 되며 객체의 분류 결과를 확률 값 형태로 최종 출력할 수 있다. 본 실시예에서는 이상의 분류 결과에 따라 가장 높은 확률을 갖는 클래스를 레이블로 활용하여 활성맵을 생성한 다. 예를 들어 도 3에서 이미지 내의 객체가 비행기로 분류 결과(Y)가 출력된 경우, 이때의 결과를 이용하여 내부 연산 네트워크로 활성맵을 생성할 수 있다. 구체적으로 내부 연산 네트워크는 분류 결과가 비행기로 출력된 경우, 비행기의 판단에 이용된 가중치(W1, W2, … Wn)를 다시 각 가중치에 대응되는 풀링 전 채널 별 특징맵과 곱함으로써 특징맵의 어떠한 위치에 해당하는 픽 셀 값이 비행기의 판단에 영향을 미쳤는지를 확인할 수 있다. 따라서, 각 채널 별 특징맵을 가중치와 가중합함 으로써 2차원의 이미지와 같은 형태의 활성맵을 출력하고, 직관적으로 객체의 존재하는 위치와 객체의 특징의 중요도를 나타낼 수 있다. 최종적으로 각 채널별 특징맵에 가중치가 부여된 값들을 가중합하고 따라서 상대적으로 중요한 픽셀의 영역들이 강조됨으로써 객체의 위치에 대한 정보를 간접적으로 나타내는 히트맵 형태의 활성맵을 생성할 수 있다. 즉, 분류에 주요한 영향을 미친 픽셀은 그렇지 않은 픽셀에 비해 큰 값을 가지므로 이에 따라 강조된 색상을 가 질 수 있으며, 픽셀 값을 기초로 객체의 영역을 구분할 수 있따. 다만, 상술한 바와 같이 인코더의 특징맵으로부터 출력된 활성맵은 객체의 세밀한 위치정보까지 포함하기 는 어려우므로 추가적인 처리를 수행할 필요가 있으며 따라서 본 실시예에서는 반복적인 학습 과정 중에서에서 획득된 활성맵 내 객체의 영역을 보다 세밀하게 정제(Refinement)하여 재구성한 재구성맵을 이용하여 인코더 를 재귀적으로 학습시킨다. 구체적으로 도 4를 참고하면, 5번째 학습 주기(t=5)에서 획득된 활성맵을 재구성하여 생성된 재구성맵( )을 수도(Pseudo) 레이블로 활용하여 학습을 수행할 수 있다. 즉, 해당 주기에서 생성된 활성맵( ) 과 활성맵 ( ) 으로부터 재구성되어 생성된 재구성맵( ) 간의 차이를 손실로 정의함으로써 해당 손실이 적어지는 방 향으로 반복적인 학습을 수행하는 것을 통해 인코더 내부의 레이어들을 갱신할 수 있다. 이러한 학습 과정은 출력된 활성맵을 이용하여 생성된 재구성맵을 통한 갱신 과정으로 반복될 수 있으며 따라서, 30번째 학습 주기(t=30)에서 획득된 활성맵( ) 은 이전의 주기의 활성맵( ) 에 비하여 보다 상세한 세그멘테이션 결과를 생성할 수 있다. 이때의 반복 횟수 등은 미리 결정된 하이퍼파라미터에 따라 결정될 수 있다. 다음, 본 실시예에 따라 활성맵을 재구성하는 과정에 대하여 보다 상세히 설명한다. 도 5를 참고하면 재구성과정은 2단계의 과정으로 구분되어 수행될 수 있다. 먼저, 활성맵으로 표현된 객체의 영역정보를 확장하는 제1 재구성과정과 확장된 제1 재구성맵에서 보다 세밀한 영역으로 정제를 수행하는 제2 재구성과정으로 구분되어 수행될 수 있다.제1 재구성 과정에 대하여 먼저 설명하면, 본 실시예에서 제1 재구성 과정은 특징맵 내 픽셀 간의 유사도를 산 출하고, 산출된 유사도의 활성화 함수의 출력을 이용하여 유사도에 따라 영역이 확장된 재구성맵을 생성할 수 있다. 예를 들어 인코더의 특징맵으로부터 출력된 활성맵 내에서 객체의 영역으로 판단된 픽셀과 기준값 이상의 유사도를 갖는 픽셀에 대해서는 객체의 영역으로 포함하도록 확장할 수 있다. 구체적으로 제1 재구성(SCG, self-correlation map generating) 모듈은 특징맵 내 픽셀간의 유사도 및 비인접 픽셀간의 평균 유사도를 출력하고, 픽셀 단위의 유사도 비교를 통해 최대값을 유사도로 취하고, 유사도가 제1 임계값을 초과하는 경우 영역을 확장시키는 과정을 통해 제1 재구성맵( )을 생성할 수 있다. 구체적으로 미 탐지(False Negative) 영역을 검출하여 확장시킴으로써 제1 재구성맵을 생성한다. 따라서, 제1 재구성맵은 픽셀간의 유사도에 따라 활성맵에 비하여 확장된 객체의 영역을 포함한다. 이어서, 제1 재구성맵의 확장된 영역을 보다 세밀하게 정제하기 위한 제2 재구성을 수행한다. 제2 재구성 과정은 제2 재구성(PAMR, Pixel-adaptive mask refinement) 모듈에서 별도로 정의되는 유사도 행렬 (Affinity Matrix)를 통해 제1 재구성맵을 입력으로 재구성맵( ) 을 생성하되 산출되는 값들은 주변 색상 값 이 유사할수록 동일한 확률 값을 갖도록 보정하여 오탐지(False Positive) 영역을 제거하는 형태로 재구성맵 ( ) 을 생성할 수 있다. 이때 제1 재구성맵의 채널별로 영역의 제거과정이 수행되는 것도 가능하다. 이상 제1 학습 파이프라인은 출력된 활성맵으로부터 생성된 재구성맵을 수도 레이블로 인코더의 출력간 오 차를 감소시키는 방향으로 인코더 내부의 레이어를 갱신하는 방식으로 학습을 수행할 수 있다. 이어서 제2 학습파이프라인에 대하여 설명한다. 제2 학습파이프라인은 디코더의 출력을 통한 디코더의 학습 과정으로 디코더의 출력으로 세그멘 테이션맵에 대한 수도 레이블을 이용하여 학습을 수행할 수 있다. 즉, 학습된 인코더에서 정제된 특징맵은 디코더를 통해 영역에 대한 세밀한 세그멘테이션 정보로 출 력될 수 있다. 이때 세그멘테이션은 객체의 보다 정확한 구분을 위하여 수도 레이블로 제1 학습 파이프라인에서 생성된 재구성 맵을 이용할 수 있다. 구체적으로 재구성맵은 활성맵으로부터 생성된 형태로 세그멘테이션 정보로 변환하기 위 한 추가적인 과정을 수행한다. 도 6을 참고하면 본 실시예에서는 재구성맵( ) 에 대한 필터(CF, CertainFilter)를 통하여 특정 임계 확률 에 따른 세그멘테이션 정보로 재구성할 수 있다. 이상의 과정을 통해 생성된 재구성 세그멘테이션맵( ) 은 디코더에서 출력된 세그멘테이션맵( ) 의 수도 레이블로 활용된다. 따라서, 디코더는 출력값으로 세그멘테이션맵( ) 과 재구성 세그멘테이션맵( ) 간의 차이를 손실 로 정의함으로써 차이가 감소하는 방향으로 반복적인 학습을 수행할 수 있다. 이상의 과정으로 학습된 신경망을 통해 본 실시예에 따른 컴퓨팅 장치는 세그멘테이션 정보를 획득한다(S40). 본 실시예에서 세그멘테이션맵 내 검출된 객체의 에지를 기반으로 객체 세그멘테이션 정보를 획득한다. 도 7을 참고하면, 구체적으로 객체 세그멘테이션 정보를 획득하는 단계는, 세그멘테이션맵( ) 내 에지들을 검출함으로써 제3 세그멘테이션맵( )을 생성하고, 제3 세그멘테이션맵( )으로부터 객체와 배경을 구분한 객체 세그멘테이션 정보 를 획득할 수 있다. 이때, 객체 세그멘테이션 정보의 획득을 위하여 디코더의 출력인 세그멘테이션맵( )의 추가적인 처리가 가능하며 바람직하게는 상술한 재구성 과정 중 제2 재구성 과정을 통하여 세그멘테이션맵( )을 정밀하게 정 제할 수 있다. 도 8을 참고하면 픽셀 간 유사도 행렬의 연산에 따라 오탐지 영역을 검출하여 제거함으로써 제2 세그멘테이션맵 ( ) 을 생성하고, 제2 세그멘테이션맵( ) 의 픽셀 단위의 객체별 확률에 따라 필터링된 제3 세그멘테이션맵( )를 생성할 수 있다. 구체적으로 제2 세그멘테이션맵( ) 내 불확실한 마스크를 상기 제2 세그멘테이션맵( ) 내 검출된 객체 의 에지를 기반으로 생성된 슈퍼픽셀을 이용하여 정제함으로써 세그멘테이션 정보를 획득하는 제3 재구성 과정 (EP, EdgePrediction)을 통해 수행될 수 있다. 본 실시예에 따른 제3 재구성 과정에 대하여 도 9를 참고하여 설명한다. 도 9를 참고하면, 먼저 제3 재구성 과정은 입력된 이미지에 대하여 디코더의 출력인 세그멘테이션맵을 정 제한 제2 세그멘테이션맵( ) 으로부터 에지를 검출할 수 있다. 에지 검출은 종래의 기술(A Computational Approach to Edge Detection, Canny 1986) 에 따라 픽셀의 값의 변화량을 기초로 검출될 수 있으며 연속된 선 분의 형태로 구성된다. 이어서, 에지를 기초로 동일한 연결된 구성 요소에 속하는 픽셀을 함께 그룹화 하여 하나의 픽셀로 정의하는 슈 퍼 픽셀을 추출한다(Connected-component labeling (CCL)). 또한, 제2 세그멘테이션맵( ) 을 필터( ) 를 통해 임계 확률을 기준으로 확실한 영역을 정의하는 제1 마스크와 불확실한 영역을 정의하는 제2 마스크로 구분하며, 불확실한 영역을 슈퍼 픽셀을 기초로 제거하는 과정을 수행한다. 이상의 과정을 통해 제2 마스크에서 불확실한 영역들이 제거되고 남은 영역과 제1 마스크를 합산함으로써 객체 세그멘테이션 정보를 포함하는 제3 세그멘테이션맵( )을 생성할 수 있다. 다음, 컴퓨팅 장치는 제3 세그멘테이션맵( )으로부터 추출된 객체 세그멘테이션 정보를 이용하여 객체가 합 성된 합성 이미지를 생성한다. 다시 도 7을 참고하면 상술한 객체 세그멘테이션 정보의 추출과정은 복수의 대상 이미지(I)에 대하여 개별적으 로 수행될 수 있으며 따라서 각각의 객체 세그멘테이션 정보를 추출할 수 있다. 이후 추출된 객체 세그멘테이션 정보에 해당하는 이미지의 값을 합성 대상 이미지(I)의 특정 위치에 합성하거나, 또는 제3의 배경에 합성함으로써 새로운 합성 이미지를 생성할 수 있다. 이상 본 실시예에서는 개별적으로 학습한 인코더와 디코더 및 디코더의 출력을 통해 보다 정제 된 객체 세그멘테이션 정보를 추출함으로써 합성 이미지의 형태를 최대한 보전하며 이질감을 줄일 수 있다. 도 10을 참고하면, 본 실시예에서는 비행기와 말의 클래스에 해당하는 대상 이미지로부터 객체 세그멘테이션 정 보를 생성하고, 생성된 객체 세그멘테이션 정보를 합성하여 합성 세그멘테이션맵( )를 생성한다. 이어서 합성 세그멘테이션 정보에 대응되는 입력된 각각의 대상 이미지(I) 내 영역을 추출하여 합성함으로써 비 행기와 말이 합성된 합성 이미지( )를 생성할 수 있다. 나아가 본 실시예에서는 합성 이미지를 통한 인코더와 디코더의 상술한 학습 파이프라인을 재수행함 으로써 합성 과정에서의 신경망의 성능을 더욱 높일 수 있다. 도 11을 참고하면, 상술한 제1 및 제2 학습 파이프라인은 합성 이미지( )에 대하여 추가적인 학습을 수행하 되, 클래스는 각각의 대상 이미지(I)를 활용하여 말과 비행기에 대한 활성맵( )과 제2 재구성맵( )의 오차를 줄이도록 하는 인코더의 제1-1 학습 파이프라인과, 세그멘테이션맵( )과 세그멘테이션맵 ( )의 에지를 통한 슈퍼픽셀로부터 불확실 영역이 제거된 재구성 세그멘테이션맵( )의 오차를 줄이도록 디코더의 제2-1 학습 파이프라인을 수행함으로써 신경망의 성능을 더욱 항샹 시킬 수 있다. 이하 도 12를 참고하여 본 실시예에 따른 객체 세그멘테이션 정보의 획득 방법을 수행하는 컴퓨팅 장치로서 서 버의 구체적인 하드웨어 구현에 대하여 설명한다. 도 12를 참조하면, 본 발명의 몇몇 실시예들에서 서버는 컴퓨팅 장치의 형태로 구현될 수 있다. 서버(30 0)를 구성하는 각각의 모듈 중 하나 이상은 범용 컴퓨팅 프로세서 상에서 구현되며 따라서 프로세서(processor), 입출력 I/O, 메모리 (memory), 인터페이스(interface) 및 버스(314, bus)를 포함할 수 있다. 프로세서, 입출력 장치, 메모리 및/또는 인터페이스는 버스를 통하 여 서로 결합될 수 있다. 버스는 데이터들이 이동되는 통로(path)에 해당한다. 구체적으로, 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit), 마이크로프로세서, 디지털 신호 프로세스, 마이크로컨트롤 러, 어플리케이션 프로세서(AP, application processor) 및 이들과 유사한 기능을 수행할 수 있는 논리 소자들 중에서 적어도 하나를 포함할 수 있다. 입출력 장치는 키패드(keypad), 키보드, 터치스크린 및 디스플레이 장치 중 적어도 하나를 포함할 수 있다. 메모리 장치는 데이터 및/또는 프로그램 등을 저장할 수 있다. 인터페이스는 통신 네트워크로 데이터를 전송하거나 통신 네트워크로부터 데이터를 수신하는 기능을 수행 할 수 있다. 인터페이스는 유선 또는 무선 형태일 수 있다. 예컨대, 인터페이스는 안테나 또는 유무 선 트랜시버 등을 포함할 수 있다. 메모리 는 프로세서의 동작을 향상시키되, 개인정보의 보호를 위 한 휘발성의 동작 메모리로서, 고속의 디램 및/또는 에스램 등을 더 포함할 수도 있다. 또한, 메모리 내에는 여기에 설명된 일부 또는 모든 모듈의 기능을 제공하는 프로그래밍 및 데이터 구성을 저장한다. 예를 들어, 상술한 학습 방법의 선택된 양태들을 수행하도록 하는 로직을 포함할 수 있다. 메모리 에 저장된 상술한 학습 방법을 수행하는 각 단계를 포함하는 명령어들의 집합으로 프로그램 또는 어플리케이션을 로드하고 프로세서가 각 단계를 수행할 수 있도록 한다. 예를 들어, 대상 이미지(I)를 인코더 에 입력하여 상기 대상 이미지(I) 내 적어도 일 객체의 특징이 축약된 특징맵을 출력하는 동작, 상기 출력 된 특징맵을 디코더에 입력하여 상기 객체의 특징이 확장된 세그멘테이션맵을 생성하는 동작, 및 상기 세 그멘테이션맵 내 검출된 객체의 에지를 기반으로 상기 이미지 내 불확실한 마스크를 정제(Refinement)하여 상기 객체 세그멘테이션 정보를 획득하는 동작 등이 포함된 컴퓨터 프로그램이 프로세서에 의해 수행될 수 있다. 이상의 본 발명에 따르면 보다 정확한 객체 세그멘테이션 결과를 생성할 수 있다. 또한, 본 발명은 세그멘테이션 결과를 이용하여 레이블을 생성하고 신경망의 학습에 이용할 수 있다. 또한, 본 발명은 인코더와 디코더로 구성된 신경망 네트워크의 중간 출력들을 이용하여 인코더 와 디코더를 개별적으로 학습시킴으로써 보다 높은 성능의 향상을 이룰 수 있으며, 추가적인 리소스 없이 보다 정확한 세그멘테이션 결과를 생성할 수 있다. 또한, 본 발명은 세그멘테이션 결과로 획득된 마스크를 이용하여 객체들을 합성함으로써 다양한 합성 (Synthetic) 이미지들을 생성할 수 있다. 나아가, 여기에 설명되는 다양한 실시예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 여기에 설명되는 실시예는 ASICs (application specific integrated circuits), DSPs (digital signal processors), DSPDs (digital signal processing devices), PLDs (programmable logic devices), FPGAs (field programmable gate arrays, 프로세서(processors), 제어기(controllers), 마이크로 컨 트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적인 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시예들이 제어 모듈 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시예들은 별도의 소프트웨어 모 듈들로 구현될 수 있다. 상기 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 적절한 프로그램 언어로 씌여진 소프트웨어 어플리케이션으로 소프트웨어 코드가 구현될 수 있 다. 상기 소프트웨어 코드는 메모리 모듈에 저장되고, 제어모듈에 의해 실행될 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위 내에서 다양한 수정, 변경 및 치환이 가능할 것이다. 따라서, 본 발명에 개시된 실시 예 및 첨부된 도면들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명 하기 위한 것이고, 이러한 실시 예 및 첨부된 도면에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구 범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기 술 사상은 본 발명의 권리 범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0141458", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 프로세스를 나타내는 도이다. 도 2는 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 신경망의 동작 파이프라인을 나타내는 도이다. 도 3은 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 신경망의 세부 동작 파이프라인을 나타 내는 도이다. 도 4는 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 신경망의 학습 파이프라인을 나타내는 도이다. 도 5는 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 신경망의 제1 학습을 위한 수도 레이블의 생성 과정을 나타내는 도이다. 도 6은 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 신경망의 제2 학습을 위한 수도 레이블 의 생성 과정을 나타내는 도이다. 도 7은 본 발명의 일 실시예에 따른 복수의 대상 이미지에 대한 객체 세그멘테이션 정보를 획득하기 위한 신경 망의 동작 파이프라인을 나타내는 도이다. 도 8 내지 9는 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하기 위한 후처리 과정을 나타내는 도이다. 도 10은 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 통한 합성 이미지의 획득 과정을 나타내는 도이 다. 도 11는 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 신경망의 추가 학습 파이프라인을 나 타내는 도이다. 도 12는 본 발명의 일 실시예에 따른 객체 세그멘테이션 정보를 획득하는 방법을 수행하는 컴퓨팅 장치의 구현 을 나타내는 도이다."}
