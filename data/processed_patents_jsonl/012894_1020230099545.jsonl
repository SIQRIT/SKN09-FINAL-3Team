{"patent_id": "10-2023-0099545", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0085836", "출원번호": "10-2023-0099545", "발명의 명칭": "이종 내시경 간의 도메인 적응 기법 및 장치", "출원인": "순천향대학교 산학협력단", "발명자": "박준석"}}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이종 내시경 간의 도메인 적응 장치로서, 이종 내시경의 내시경 영상을 무작위로 수집하는 데이터 수집부; 상기 수집된 내시경 영상을 학습하여 기종에 따라 분류하는 내시경 기종 분류부; 상기 기종에 따라 분류된 내시경 영상을 기종 별로 영상특성을 학습하여 영상특성을 인식하는 특성인식부; 및상기 영상특성을 학습하여 내시경 기종 영상을 다른 기종의 특성을 갖도록 상호 변환하는 변환부;를 포함하는것을 특징으로 하는 이종 내시경 간의 도메인 적응 장치."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 데이터 수집부는,수집된 데이터를 규격화하고, 학습용 영상과 검증용 영상을 무작위로 분배하는 전처리부를 더 포함하는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 장치."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, EfficientNet과 같은 딥러닝 기반 분류 네트워크(Classification Network)을 기반으로 상기 내시경 기종 분류부는 수집된 내시경 영상에서 내시경 기종을 판별하고, 상기 특성인식부는 영상특성을 인식하기 위하여 내시경기종별로 분류된 내시경 영상을 독립적으로 학습하는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 장치."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 상기 변환부는 영상특성을 학습하여 상호 변환을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응기술을적용하여 특정 내시경 기종 영상을 적어도 하나 이상의 다른 내시경 기종의 영상특성을 갖도록 변환되도록 학습하는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 장치."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서, 상기 변환부는 CycleGAN과 같은 도메인 적응 기법(Domain Adaptation method)을 기반으로 하는 것을 특징으로하는 이종 내시경 간의 도메인 적응 장치."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "이종 내시경 간의 도메인 적응 기법로서, 공개특허 10-2024-0085836-3-데이터 수집부에서 이종 내시경의 내시경 영상을 무작위로 수집하는 제1단계; 전처리부가 수집된 데이터를 규격화하고, 학습용 영상과 검증용 영상을 무작위로 분배하는 제2단계; 내시경 기종 분류부가 상기 수집된 내시경 영상을 학습하여 기종에 따라 분류하는 제3단계; 특성인식부가 상기 기종에 따라 분류된 내시경 영상을 기종 별로 영상특성을 학습하여 영상특성을 인식하는 제4단계; 및변환부가 상기 영상특성을 학습하여 내시경 기종 영상을 다른 기종의 특성을 갖도록 상호 변환하는 제5단계;를포함하는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 기법."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서, 상기 제3단계에서, EfficientNet과 같은 딥러닝 기반 분류 네트워크 (Classification Network)를 기반으로 수집된 내시경 영상에서 내시경 기종을 판별하고, 상기 제4단계에서, EfficientNet과 같은 딥러닝 기반 분류 네트워크 (Classification Network)를 기반으로 영상특성을 인식하기 위하여 내시경 기종별로 분류된 내시경 영상을 독립적으로 학습하는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 기법."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 제5단계에서, CycleGAN과 같은 도메인 적응 기법(Domain Adaptation method)을 기반으로 영상특성을 학습하여 상호 변환을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응기술을 적용하여 특정 내시경 기종 영상을 적어도 하나 이상의 다른 내시경 기종의 영상특성을 갖도록 변환되도록 학습하는 것을 특징으로 하는 이종 내시경 간의 도메인적응 기법."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6항에 있어서, 상기 영상특성은 위식도 접합부인 것을 특징으로 하는 이종 내시경 간의 도메인 적응 기법."}
{"patent_id": "10-2023-0099545", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터에 의해 판독되어 실행되는 프로그램으로서, 제 6항 내지 제 9항 중 어느 한 항에 따른 기법을 실행시키는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 프로그램."}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이종 내시경 간의 도메인 적응 기법 및 장치에 대한 것으로, 후향적으로 수집한 내시경 영상을 무작위 추출하여 내시경 기종에 따라 분류하고 이를 바탕으로 개발한 딥러닝 기반의 인공지능이 내시경 기종별로 고유한 영상 특성을 인식할 수 있는지 확인하는 인공지능을 제안하고, 영상 특성을 학습하여 상호 변환을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응 기술을 활용하여 특정 내시경 기종의 영상을 다른 기종들의 특성을 갖도 록 변환함으로써 저하된 인공지능의 인식 능력을 개선하는 방법을 제시한다."}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이종 내시경 간의 도메인 적응 기법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 기반의 인공지능은 학습 자료의 성격에 영향을 많이 받는데, 인식 대상이 되는 영상에 분류 가능한 특성 이 의도된 바에 독립적으로 존재한다면 오류의 원인이 될 수 있다. 소화기 내시경 영상은 그 촬영 기종에 따라 독특한 세부 특성이 존재하는데, 소수의 기업이 독과점하는 소화기 내시경 시장을 고려하면 내시경 기종에 따른 영상 특성을 인공지능의 개발 단계에서부터 반영할 필요가 있다. 대규모의 내시경 영상을 바탕으로 학습한 기종별 영상 특성을 바탕으로 인공지능이 특정 내시경 영상의 촬영 기 종을 인식하고, 생성적 적대 신경망 기반의 도메인 적응 기술을 활용하여 내시경 기종의 고유 영상 특성을 상호 간에 변환을 가능하게 하여 내시경 기종에 따라 다양하게 존재하는 영상 특성에 의해서 저하될 수 있는 인공지 능의 인식 능력을 개선할 필요가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2023-0033237호 (특허문헌 0002) 대한민국 공개특허 제10-2022-0054228호 (특허문헌 0003) 대한민국 등록특허 10-2496672호"}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명은 상기와 같은 종래의 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 실시예에 따르면, 후향적으로 수집한 내시경 영상을 무작위 추출하여 내시경 기종에 따라 분류하고 이를 바탕으로 개발한 딥러닝 기반의 인공지능이 내시경 기종별로 고유한 영상 특성을 인식할 수 있는지 확인하는 인공지능을 제안하고, 영상 특성을 학습하여 상호 변환을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응 기술을 활용하여 특정 내 시경 기종의 영상을 다른 기종들의 특성을 갖도록 변환함으로써 저하된 인공지능의 인식 능력을 개선하는 방법 을 제시할 수 있는 이종 내시경 간의 도메인 적응 기법 및 장치를 제공하는데 그 목적이 있다. 본 발명의 실시예에 따르면, 근래에 IT 분야에서 각광받는 딥러닝 기반의 인공지능을 이용한 영상 인식 기술이 소화기 내시경의 독특한 시장 구조를 극복하고 안정된 성능을 확보하는 데 기여할 수 있는, 이종 내시경 간의 도메인 적응 기법 및 장치를 제공하는데 그 목적이 있다. 한편, 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하"}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "지 않은 또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "Olympus CV-260SL, CV290 (올림푸스, 일본)과 PENTAX EPK-i (펜탁스 메디칼, 일본)의 세 종류의 영상 처리 장 치와 기종별 전용 내시경으로 상부위장간 내시경 검사를 시행되었다. Olympus 사의 영상 처리 장치는 전체 출력 해상도가 고해상도 텔레비전 규격인 1920×1080픽셀까지 가능하지만, 실제 내시경 관찰 영역은 화면에서 우측으로 치우쳐진 1280×1024픽셀 안에서 표시된다. 그 외의 영역은 검사와 관련된 임상 정보를 표시하는 데 활용된다. PENTAX EPK-i 기종의 경우, 1280×1024픽셀의 영상 출력이 가능하며, 이를 모두 사용하여 내시경 관찰 영역을 표시한다. 각 영상 처리 장치에서 출력된 디지털 모니터 신호를 복제하여 Matrox VIO 7IA OA/G (매트록스, 미국)를 이용하 여 포착하고, 의료용 디지털 영상 규격(Digital imaging and communication in medicine, DICOM)에 맞춰 영상 저장전송시스템(Picture archiving and communication system, PACS)에 저장된 검사 정보 중에 내시경 관찰 영 역의 영상만을 무손실 압축 형식인 Portable Network Graphics (PNG)로 추출하여 인공지능의 학습에 사용하였다. 전체 영상에서 내시경 관찰 영역의 중심을 기점으로 그에 외접하는 원 반지름의 1.16배 크기의 정사각형 부분만 을 취하여 512×512픽셀로 크기를 조절한 뒤에 네 귀퉁이에서 70픽셀 점을 잇는 삼각형을 흑색으로 칠하여 팔각 형의 영상으로 규격을 통일하였다. 이 과정을 영상의 외적인 요인이 인공지능의 학습과 검증에 영향을 미치지 않도록 python 언어와 OpenCV 라이브 러리를 이용하여 영상의 색조, 선예도, 비율 등의 특성에는 변화가 없게 일괄 처리하였다(도 1 참고). 총 310,389장의 영상을 갖는 9,949개의 검사 증례가 수집되어 모두 익명화되었다. 본 발명의 제1목적은 이종 내시경 간의 도메인 적응 장치로서, 이종 내시경의 내시경 영상을 무작위로 수집하는 데이터 수집부; 상기 수집된 내시경 영상을 학습하여 기종에 따라 분류하는 내시경 기종 분류부; 상기 기종에 따라 분류된 내시경 영상을 기종 별로 영상특성을 학습하여 영상특성을 인식하는 특성인식부; 및상기 영상특성 을 학습하여 내시경 기종 영상을 다른 기종의 특성을 갖도록 상호 변환하는 변환부;를 포함하는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 장치로서 달성될 수 있다. 그리고 상기 데이터 수집부는, 수집된 데이터를 규격화하고, 학습용 영상과 검증용 영상을 무작위로 분배하는 전처리부를 더 포함하는 것을 특징으로 할 수 있다. 또한 EfficientNet과 같은 딥러닝 기반 분류 네트워크(Classification Network)을 기반으로 상기 내시경 기종 분류부는 수집된 내시경 영상에서 내시경 기종을 판별하고, 상기 특성인식부는 영상특성을 인식하기 위하여 내 시경 기종별로 분류된 내시경 영상을 독립적으로 학습하는 것을 특징으로 할 수 있다. 그리고 상기 변환부는 영상특성을 학습하여 상호 변환을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응 기술을 적용하여 특정 내시경 기종 영상을 적어도 하나 이상의 다른 내시경 기종의 영상특성을 갖도록 변환되도 록 학습하는 것을 특징으로 할 수 있다. 또한 상기 변환부는 CycleGAN과 같은 도메인 적응 기법(Domain Adaptation method)을 기반으로 하는 것을 특징 으로 할 수 있다. 본 발명의 제2목적은, 이종 내시경 간의 도메인 적응 기법로서, 데이터 수집부에서 이종 내시경의 내시경 영상 을 무작위로 수집하는 제1단계; 전처리부가 수집된 데이터를 규격화하고, 학습용 영상과 검증용 영상을 무작위 로 분배하는 제2단계; 내시경 기종 분류부가 상기 수집된 내시경 영상을 학습하여 기종에 따라 분류하는 제3단 계; 특성인식부가 상기 기종에 따라 분류된 내시경 영상을 기종 별로 영상특성을 학습하여 영상특성을 인식하는 제4단계; 및 변환부가 상기 영상특성을 학습하여 내시경 기종 영상을 다른 기종의 특성을 갖도록 상호 변환하는 제5단계;를 포함하는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 기법으로서 달성될 수 있다. 그리고 상기 제3단계에서, EfficientNet과 같은 딥러닝 기반 분류 네트워크 (Classification Network)를 기반 으로 수집된 내시경 영상에서 내시경 기종을 판별하고, 상기 제4단계에서, EfficientNet과 같은 딥러닝 기반 분 류 네트워크 (Classification Network)를 기반으로 영상특성을 인식하기 위하여 내시경 기종별로 분류된 내시경 영상을 독립적으로 학습하는 것을 특징으로 할 수 있다. 또한 상기 제5단계에서, CycleGAN과 같은 도메인 적응 기법(Domain Adaptation method)을 기반으로 영상특성을 학습하여 상호 변환을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응기술을 적용하여 특정 내시경 기종 영상을 적어도 하나 이상의 다른 내시경 기종의 영상특성을 갖도록 변환되도록 학습하는 것을 특징으로 할 수 있다. 그리고 상기 영상특성은 위식도 접합부인 것을 특징으로 할 수 있다. 본 발명의 제3목적은 컴퓨터에 의해 판독되어 실행되는 프로그램으로서, 앞서 언급한제 3목적에 따른 기법을 실 행시키는 것을 특징으로 하는 이종 내시경 간의 도메인 적응 프로그램으로서 달성될 수 있다."}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 이종 내시경 간의 도메인 적응 기법 및 장치에 따르면, 후향적으로 수집한 내시경 영 상을 무작위 추출하여 내시경 기종에 따라 분류하고 이를 바탕으로 개발한 딥러닝 기반의 인공지능이 내시경 기 종별로 고유한 영상 특성을 인식할 수 있는지 확인하는 인공지능을 제안하고, 영상 특성을 학습하여 상호 변환 을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응 기술을 활용하여 특정 내시경 기종의 영상을 다른 기 종들의 특성을 갖도록 변환함으로써 저하된 인공지능의 인식 능력을 개선하는 방법을 제시할 수 있다. 본 발명의 실시예에 따른 이종 내시경 간의 도메인 적응 기법 및 장치에 따르면, 근래에 IT 분야에서 각광받는 딥러닝 기반의 인공지능을 이용한 영상 인식 기술이 소화기 내시경의 독특한 시장 구조를 극복하고 안정된 성능 을 확보하는 데 기여할 수 있는 장점을 갖는다. 본 발명의 실시예에 따른 이종 내시경 간의 도메인 적응 기법 및 장치에 따르면, A사의 내시경에서 병증이나 접 합부를 인식하려고 할 때 데이터베이스의 부족 등의 이유로 성능 저하가 발생했을 때 좀 더 데이터베이스가 많 은 B 사의 내시경으로 학습된 모델을 바탕으로 A사의 내시경 영상을 B사의 내시경 영상으로 변환함으로써 인식 률의 저하를 최소화할 수 있고, 또한, 서로 다른 두 기종의 내시경 영상의 색감이나 화질 등을 일치시킴으로써 해당 내시경을 활용하는 의사들이 좀 더 익숙한 형태의 내시경 영상으로 변환해서 활용할 수 있는 효과를 갖는 다. 한편, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효"}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "과들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상의 본 발명의 목적들, 다른 목적들, 특징들 및 이점들은 첨부된 도면과 관련된 이하의 바람직한 실시예들을 통해서 쉽게 이해될 것이다. 그러나 본 발명은 여기서 설명되는 실시예들에 한정되지 않고 다른 형태로 구체화 될 수도 있다. 오히려, 여기서 소개되는 실시예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 통상의 기술자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 명세서에서, 어떤 구성요소가 다른 구성요소 상에 있다고 언급되는 경우에 그것은 다른 구성요소 상에 직접 형성될 수 있거나 또는 그들 사이에 제 3의 구성요소가 개재될 수도 있다는 것을 의미한다. 또한 도면들에 있어 서, 구성요소들의 두께는 기술적 내용의 효과적인 설명을 위해 과장된 것이다. 본 명세서에서 기술하는 실시예들은 본 발명의 이상적인 예시도인 단면도 및/또는 평면도들을 참고하여 설명될 것이다. 도면들에 있어서, 막 및 영역들의 두께는 기술적 내용의 효과적인 설명을 위해 과장된 것이다. 따라서제조 기술 및/또는 허용 오차 등에 의해 예시도의 형태가 변형될 수 있다. 따라서 본 발명의 실시예들은 도시된 특정 형태로 제한되는 것이 아니라 제조 공정에 따라 생성되는 형태의 변화도 포함하는 것이다. 예를 들면, 직 각으로 도시된 영역은 라운드지거나 소정 곡률을 가지는 형태일 수 있다. 따라서 도면에서 예시된 영역들은 속 성을 가지며, 도면에서 예시된 영역들의 모양은 소자의 영역의 특정 형태를 예시하기 위한 것이며 발명의 범주 를 제한하기 위한 것이 아니다. 본 명세서의 다양한 실시예들에서 제1, 제2 등의 용어가 다양한 구성요소들을 기술하기 위해서 사용되었지만, 이들 구성요소들이 이 같은 용어들에 의해서 한정되어서는 안 된다. 이들 용어 들은 단지 어느 구성요소를 다른 구성요소와 구별시키기 위해서 사용되었을 뿐이다. 여기에 설명되고 예시되는 실시예들은 그것의 상보적인 실시예들도 포함한다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '포함한다 (comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요소는 하나 이상의 다른 구성요소의 존재 또는 추 가를 배제하지 않는다. 아래의 특정 실시예들을 기술하는데 있어서, 여러 가지의 특정적인 내용들은 발명을 더 구체적으로 설명하고 이 해를 돕기 위해 작성되었다. 하지만 본 발명을 이해할 수 있을 정도로 이 분야의 지식을 갖고 있는 독자는 이러 한 여러 가지의 특정적인 내용들이 없어도 사용될 수 있다는 것을 인지할 수 있다. 어떤 경우에는, 발명을 기술 하는 데 있어서 흔히 알려졌으면서 발명과 크게 관련 없는 부분들은 본 발명을 설명하는데 있어 별 이유 없이 혼돈이 오는 것을 막기 위해 기술하지 않음을 미리 언급해 둔다. 본 발명의 실시예에 따르면, 서로 다른 기종의 내시경 영상들을 구분하는 딥러닝 기술, 하나(A)의 내시경으로 학습된 모델에 대해서 다른 내시경(B)의 영상을 다시 해당(A)의 내시경으로 도메인 변환한 후에 해당(A) 내시경 으로 학습된 모델에 적용함으로써 인식률을 향상시키는 기술, 도메인 적응을 통해서 식도와 위 간의 접합부를 인식하는 기술, 이종 내시경 간의 도메인 적응을 적용하기 위해서 수집된 영상을 같은 해상도와 컨텐츠를 갖도 록 정규화 시키는 기술의 특징을 포함한다. 다양한 내시경 기종들이 있을 때 현재는 각각의 내시경에 대해서 많은 양의 데이터베이스를 수집해야 하지만, 본 발명의 실시예에 따르면, 데이터베이스의 양이 충분한 내시경을 통해서 성능이 좋은 모델을 만들고, 다른 내 시경은 도메인 적응을 통해서 성능이 좋은 모델이 있는 내시경으로 영상을 변환하면 데이터베이스가 많지 않더 라도 인식률의 저하를 최소화할 수 있다. 먼저 본 발명의 실시예에 따른 이종 내시경 간의 도메인 적응 장치의 구성, 기능 및 적응방법에 대해 설명하도 록 한다. 본 발명의 실시예에 따른 이종 내시경 간의 도메인 적응 장치는, 데이터 수집부, 전처리부, 내시경 기종 분류부, 특성인식부, 변환부 등을 포함하여 구성될 수 있다. 본 발명의 실시예에 따른 데이터 수집부는 이종 내시경의 내시경 영상을 무작위로 수집한다. 또한 전처리부는 수집된 데이터를 규격화하고, 학습용 영상과 검증용 영상을 무작위로 분배하도록 구성된다. 그리고 본 발명의 실시예에 따른 내시경 기종분류부는, 상기 수집된 내시경 영상을 학습하여 기종에 따라 분류 한다. 내기경 기종 분류부는 EfficientNet과 같은 딥러닝 기반 분류 네트워크(Classification Network)을 기반 으로 수집된 내시경 영상에서 내시경 기종을 판별하도록 구성될 수 있다. 또한 특성인식부는 상기 기종에 따라 분류된 내시경 영상을 기종 별로 영상특성을 학습하여 영상특성을 인식하 도록 구성된다. 이러한 영상특성은 예를 들어 위식도 접합부일 수 있다. 특성인식부는 EfficientNet과 같은 딥러닝 기반 분류 네트워크(Classification Network)을 기반으로 영상특성을 인식하기 위하여 내시경 기종별로 분류된 내시경 영상을 독립적으로 학습할 수 있다. 본 발명의 실시예에 따른 변환부는 상기 영상특성을 학습하여 내시경 기종 영상을 다른 기종의 특성을 갖도록 상호 변환하도록 구성된다. 변환부는 영상특성을 학습하여 상호 변환을 가능하게 하는 생성적 적대 신경망 기반의 도메인 적응기술을 적용 하여 특정 내시경 기종 영상을 적어도 하나 이상의 다른 내시경 기종의 영상특성을 갖도록 변환되도록학습한다. 또한 본 발명의 실시예에 따른 변환부는 CycleGAN과 같은 도메인 적응 기법(Domain Adaptation method)을 기반 으로 할 수 있다. 이하에서는 본 발명의 실험예에 따른 실험방법과, 통계분석, 결과에 대해 설명하도록 한다. 1-A. 실험 방법 수집된 내시경 영상에서 색조에 인위적인 변화를 일으키는 색소나 협대역 영상, i-scan 등의 영상강화 기능이 사용된 것은 제외하였다. 이를 촬영에 사용된 세 내시경 기종인 Olympus CV-260SL, CV290, PENTAX EPK-i에 따 라서 각각 o260, o290, pEPK로 표식하여 분류하였다. 그 중에 하부 식도 영상의 편평 상피-원주 상피의 이행 경 계인 Z선이 확인되는 것을 세 전문의의 합의를 거쳐서 위식도 접합부 영상으로 별도 표식하였다. 이 과정이 정 확하게 이뤄질 수 있도록 Microsoft Excel과 내장된 기능인 Visual Basic for Application을 이용하였다(도 2 참고). Microsoft Excel을 이용하여 증례별로 위식도 접합부 영상과 나머지의 영상 수를 정리하고 이에 난수를 부여하 여 무작위 추출하여 영상의 규모가 비슷하고 중복된 증례가 없도록 인공지능의 학습용, 검증용 자료를 8:2 비율 로 배분하였다(도 3 참고). 이들을 바탕으로 영상에 촬영된 내시경 기종을 인식하는 것과 위식도 접합부 영상을 분별하는 것, 두 종류의 인공지능을 개발하였다(도 4 참고). 내시경 기종을 인식하는 인공지능은 훈련용으로 배 분된 전체 영상을 학습하였다. 위식도 접합부를 분별하는 인공지능은 내시경 기종별로 나눈 훈련용 영상을 독립 적으로 학습하여 각각에 최적화되었다. 두 인공지능 모두 효율성과 정확성이 검증된 EfficientNet-B0 모델을 기 반으로 개발되었다(도 5 참고). ImageNet을 이용한 사전 훈련으로 설정된 초기 변수들을 바탕으로 하는 Pytorch 기반의 EfficientNet에 입력되 는 영상의 크기는 224×224픽셀로 조정되었고, 확률적 경사하강법(Stochastic gradient descent)이 learning rate 0.05, momentum 0.9, weight decay 1e-4 설정 하에 사용되었다. 손실 함수로서 교차 엔트로피(Cross- entropy)를 이용하고, 검증용으로 분류된 영상 자료에 대해서 200 epochs 동안의 학습 중에 가장 높은 정확도를 보인 모델을 최종 선택하였다. CycleGAN 알고리즘도 영상 인식 인공지능의 훈련용으로 분류된 영상을 동일하게 이용하여 내시경 기종별 영상 특성을 학습하였다. 영상의 크기를 256×256픽셀로 조정하여 입력하였고, Adam optimizer를 learning rate 0.0002 로 적용하였다. 이를 바탕으로 검증용 영상 자료를 원본과 다른 두 개 기종의 특성을 갖도록 변환하였는 데, 영상 특성 변환을 검증할 기준이 없으므로 200 epochs를 학습한 결과를 최종 모델로 선택하였다. 변환된 영 상 모두를 재검토하여 인공지능의 위식도 접합부 인식 능력 검증을 위해 사용하는 것에 문제가 없는지 확인하였 다. 모든 연산은 8-gigabyte 메모리를 갖춘 NVIDIA RTX2080 (NVIDIA, 미국)이 설치된 컴퓨터에서 이루어졌다. 내시 경 기종을 판별하는 인공지능의 성능은 최대 softmax 값을 바탕으로 하는 top-1 정확도를 측정하였다. 위식도 접합부를 인식하는 인공지능은 확률 0.5를 임계값으로 정하여 성능을 평가하고, 이를 정성적으로 확인하기 위해 서 class activation map을 별도로 생성하여 개발 의도에 따라 위식도 접합부를 인식하는지 확인하였다. 1-B. 통계 분석 상부위장관 내시경 검사의 영상 중에 작은 비중을 차지하는 위식도 접합부를 인식 대상으로 하는 인공지능의 성 능 평가를 위해서 정확도(Accuracy)만을 사용하는 것은 분류 대상 간의 불균형을 반영하기 어렵다. 이를 보완하 기 위해서 다음과 같은 공식으로 계산되는 정밀도(Precision)와 재현율(Recall) 간의 조화 평균인 F1-점수를 함 께 제시하였으며, SPSS 프로그램(버전 26.0, IBM SPSS Statistics for Windows, IBM corp., 미국)으로 계산하 였다. 위식도 접합부를 인식하는 인공지능은 내시경 기종별로 분류된 검증용 영상에 대해서 각 내시경 기종에 특성화 된 세 인공지능의 ROC 곡선(Receiver operating characteristic curve) 간의 차이를 DeLong 시험법으로 비교하 였으며, MedCalc(버전 20.100, MedCalc Software Ltd., 벨기에) 프로그램을 사용하였다. 통계적 유의성은 P<0.05를 기준으로 판단하였다.2. 결과 총 57,105장의 영상을 포함하는 2,160개의 검사가 인공지능의 훈련과 검증을 위해서 무작위 추출되었다(표 1 참 고). 검사 대상자의 평균 연령은 54.7세였으며, 970명이 여성이었다. 831개의 검사가 Olympus CV-260L로 촬영되 었고, 19,037장의 검사 영상 중에 위식도 접합부 영상은 1,423장이었다. Olympus CV-290으로 촬영된 검사는 681 개였으며, 19,037장의 영상 중에 1,489장이 위식도 접합부 영상이었다. 648개의 PENTAX EPK-i로 촬영된 검사는 19,031장의 영상 중에 위식도 접합부 영상은 1,404장이었다. 추출된 검사의 위식도 접합부 영상 중에 605개의 검사에서 역류성 식도염 소견이 발견되었고, 38개의 검사에서 바렛식도가 14개의 검사에서 식도 정맥류가 확인 되었다. 촬영에 사용된 내시경 기종을 추측하는 인공지능은 PENTAX EPK-i와 다른 Olympus 기종을 오차 없이 구별할 수 있었다. o290 영상 중에 93장을 o260으로, o260 영상의 14장을 o290으로 인식하는 오류가 발생하였다. 이 인공 지능의 top-1 정확도를 계산하면 0.991이며, o260, o290, pEPK를 예측하는 F1-점수가 각각 0.986, 0.986, 1.000이었고, ROC 곡선의 아래면적(Area under receiver operating characteristic curve)은 각각 0.998, 0.999, 1.000이었다(도 6 참고). 위식도 접합부를 인식하는 인공지능은 특화되어 내시경 기종을 따라 AI-o260, AI-o290, AI-pEPK로 명명되었다. 이들의 인식 성능을 검증용 영상에서 확인한 결과, 모두 각각에 특화된 기종의 영상에서 가장 높은 정확도와 F1-점수를 보였다(표 2). AI-o260은 검증용 o260 영상에서 285장의 위식도 접합부 영상을 성공적으로 인식하여 정확도 0.988과 F1-점수 0.917을 보였다. AI-o290은 o290 영상에서 정확도 0.979, F1-점수 0.867을 보였고, AI-pEPK 는 pEPK 영상에서 정확도 0.986, F1-점수 0.906을 보였다. 인공지능들은 학습한 기종과 다른 종류의 내 시경 영상에서는 성능이 저하되었다. 그 AUROC를 비교한 결과는 o260 영상에서 AI-o260과 AI-o290를 비교한 경 우를 제외하고(도 7 참고), 다른 모든 경우에서 통계적으로 유의하였다(도 8, 9 참고). 발명에 참여한 세 전문의는 내시경 기종별로 3그룹으로 나눈 원본 영상들이 다른 두 기종의 영상 특성을 갖도록 변환된 후에도 영상의 표식 양상에 변화가 없는 것을 재차 확인하였다. 인공지능이 연구에서 의도한 바대로 편 평-원주 상피 경계를 인식하여 위식도 접합부를 구별함을 CAM 영상을 통해 확인하였다(도 10 참고). 인공지능은 각기 학습한 내시경 기종의 특성을 갖도록 변환된 영상에서 성능이 개선되었는데, AUROC의 향상이 모두 통계적 으로 유의하였다. o260 영상을 o290 특성을 갖도록 변환하면 AI-290의 AUROC가 0.0056 증가하였으며, pEPK 특성 을 갖도록 변환하면 AI-pEPK의 인식 성능이 0.0182 개선되었다(도 11 참고). o290 원본 영상을 o260, pEPK 특 성을 갖도록 변환하면 AI-o260과 AI-pEPK의 성능 향상은 각각 0.0134, 0.0299를 보였다(도 12 참고). pEPK 영 상에서의 AI-o260, AI-o290도 각각에 맞게 영상 특성을 변환하면 0.0215, 0.0616의 성능 향상이 있었다(도 13 참고). 표 1. 인공지능의 학습용, 검증용 자료로 분배된 검사 증례의 임상 양상 표 1"}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i 표 2. 위식도 접합부 인식 인공지능의 검증용 자료에 따른 성능 비교 표 2"}
{"patent_id": "10-2023-0099545", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; AI, artificial intelligence 도 1은 내시경 영상 수집과정 중의 규격화예시로서, 수집된 내시경 영상은 관찰 영역에 외접하는 원을(청색 기 준선) 중심으로 반지름의 1.16배 크기의 정사각형 부분(녹색 사각형)만을 취하여 512×512픽셀 크기로 규격화되 며, 그 과정은 Python 언어와 OpenCV 라이브러리를 이용하여 일괄 시행하였다(좌측부터 Olympus CV-260SL, CV- 290, PENTAX EPK-i 순). 도 2는 Microsoft Excel을 이용한 영상 표식 예시로서, 연구에 참여한 세 명의 전문의가 위식도 접합부 영상을 분류하고 결과를 검토하는 과정에 오류를 최소화하기 위해서 Microsoft Excel과 Visual Basic for Application 기능을 활용하여 자료를 표식하였다. 도 3은 인공지능의 학습용, 검증용 영상의 무작위 추출로서, 각 내시경 기종별로 위식도 접합부와 나머지로 분 류된 영상에 난수를 부여하여 증례를 바탕으로 3개의 기종 간에 영상 규모에 차이가 없도록 무작위 추출하였다. 연구에의 사용이 결정된 영상은 8:2로 배분되어 두 종류의 인공지능 개발에 각각 학습용과 검증용으로 사용되었 으며, cycleGAN을 이용한 영상 특성 변환 실험에도 활용되었다. 도 4는 본 발명의 실시예에 따른 모식도로서, 추출된 내시경 영상은 학습용과 검증용 목적에 따라 무작위 비율 8:2로 분배되었다. 학습용 자료를 이용하여 훈련된 인공지능의 성능을 검증용 자료와 이를 다른 두 종류의 내시경 영상 특성을 갖도록 cycleGAN을 이용하여 변환한 자료에 대해서 시험하였다. o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; EGJ, esophagogastric junction; GAN, generative adversarial network 도 5a 및 도 5b는 EfficientNet과 CycleGAN 알고리즘 구조를 도시한 것이다. 도 5a에 도시된 바와 같이, EfficientNet은 촬영에 사용된 내시경 기종을 판별하고 위식도 접합부를 인식하기 위해서 내시경 기종별로 분류된 영상을 독립적으로 학습하였다. 도 5b에 도시된 바와 같이, CycleGAN은 특정 내시경 기종 영상을 다른 두 내시경 기종의 영상 특성을 갖도록 변 환하도록 훈련되었다. MBConv, inverted linear BottleNeck layer with depth-wise separable convolution; BN, batch normalization; FC, fully connected layer; Conv, convolution; GAP, global average pooling; EGJ, esophagogastric junction; GAN, generative adversarial network 도 6은 촬영에 사용된 내시경 기종을 판별하는 인공지능의 성능을 도시한 것이다. 인공지능은 o260 데이터셋 중 93장의 영상을 Olympus CV-290으로 촬영한 것으로 o290 데이터셋 중 14장을 Olympus CV-260SL로 촬영한 것으로 판별하는 오류를 일으켰다. pEPK 데이터셋은 모두 PENTAX EPK-i로 촬영한 것으로 인식하는 데 성공했다. o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; AUROC, area under receiver operating characteristic curve 도 7은 o260 데이터셋에서 위식도 접합부 인식 인공지능 성능의 비교를 도시한 것이다. 검증용 o260 데이터셋에 서 인공지능의 위식도 접합부 인식 능력을 평가한 결과, 학습용 o260 데이터셋으로 훈련된 인공지능이 가장 높 은 인식 성능을 보였다(0.992, AI-o260, 파란 실선). o290 데이터셋을 학습한 인공지능은 성능이 0.991로 뒤쳐 졌지만(AI-o290, 녹색 점선), 통계적으로 유의한 차이는 없었다. 제조회사가 다른 EPK-i기종 영상을 바탕으로 구축된 인공지능의 성능이 가장 뒤쳐졌으며(0.969, AI-pEPK, 주황 점선), 그 차이가 통계적으로 유의했다. o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; AI, artificial intelligence; EGJ, esophagogastric junction; GAN, generative adversarial network 도 8은 o290 데이터셋에서 위식도 접합부 인식 인공지능 성능의 비교를 도시한 것이다. 검증용 o290 데이터셋에 서 인공지능의 위식도 접합부 인식 능력을 평가한 결과, 학습용 o290 데이터셋으로 훈련된 인공지능이 가장 높 은 인식 성능을 보였다(0.990, AI-o290, 녹색 점선). o260 데이터셋을 학습한 인공지능은 성능이 0.973으로 뒤 쳐졌으며(AI-o260 파란 실선), 통계적으로 유의한 차이가 있었다. 제조회사가 다른 EPK-i 기종 영상을 바탕으로 구축된 인공지능의 성능이 가장 뒤쳐졌으며(0.934, AI-pEPK, 주황 점선), 그 차이가 통계적으로 유의했다. o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; AI, artificial intelligence; EGJ, esophagogastric junction; GAN, generative adversarial network 도 9는 pEPK 데이터셋에서 위식도 접합부 인식 인공지능 성능의 비교를 도시한 것이다. 검증용 pEPK 데이터셋에 서 인공지능의 위식도 접합부 인식 능력을 평가한 결과, 학습용 pEPK 데이터셋으로 훈련된 인공지능이 가장 높 은 인식 성능을 보였다(0.992, AI-pEPK, 주황 점선). o260 데이터셋을 학습한 인공지능은 성능이 0.967로 뒤쳐 졌으며(AI-o260 파란 실선), 통계적으로 유의한 차이가 있었다. o290 기종 영상을 바탕으로 구축된 인공지능의 성능이 가장 뒤쳐졌으며(0.932, AI-o290, 녹색 점선), 그 차이가 통계적으로 유의했다. o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; AI, artificial intelligence; EGJ, esophagogastric junction; GAN, generative adversarial network 도 10은 위식도 접합부 영상을 인식하는 인공지능의 cycleGAN 변환과Class activation map 예시를 나타낸 것이다. 가장 좌측에 표기된 인공지능이 좌측 영상을 토대로 위식도 접합부를 인식하면, 우측의 색상 척도와 같이 위식 도 접합부의 가능성이 높아짐에 따라 밝은 파랑색으로 표시된다. 이렇게 생성된 CAM 영상을 원본에 중첩하여 우 측에 나열하였다. 가장 윗줄에 나열된 원본 영상에 대해서 cycleGAN을 이용한 변환 결과를 하단에 정렬하였다. 영상 중앙부에 위치한 편평-원주 상피 경계 주변으로 색상 경계가 지어지는 것으로 인공지능이 위식도 접합부를 의도한 방향으로 인식하는 것을 엿볼 수 있다.o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; CAM, class activation map; EGJ, esophagogastric junction; GAN, generative adversarial network 도 11은 학습한 영상의 특성을 갖도록 변환된 검증용 데이터에서의 인공지능 성능 향상(o260 데이터셋)을 나타 낸 것이다. 각 기종별 원본 영상을 학습한 위식도 접합부를 인식하는 인공지능은 다른 내시경 기종의 영상에서 인식 성능이 저하되고(점선으로 표시된 AI-o290, AI-pEPK), 인공지능이 학습한 영상의 특성을 갖도록 변환된 검증용 데이터 셋에서는 유의한 성능 향상을 보인다(실선으로 표기된 AI-o290, AI-pEPK). o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; AI, artificial intelligence; EGJ, esophagogastric junction; GAN, generative adversarial network 도 12는 학습한 영상의 특성을 갖도록 변환된 검증용 데이터에서의 인공지능 성능 향상(o290 데이터셋)을 나타 낸 것이다 각 기종별 원본 영상을 학습한 위식도 접합부를 인식하는 인공지능은 다른 내시경 기종의 영상에서 인식 성능이 저하되고(점선으로 표시된 AI-o260, AI-pEPK), 인공지능이 학습한 영상의 특성을 갖도록 변환된 검증용 데이터 셋에서는 유의한 성능 향상을 보인다(실선으로 표기된 AI-o260, AI-pEPK). o260, Olympus CV-260SL; o290, Olympus CV-290; pEPK, PENTAX EPK-i; AI, artificial intelligence; EGJ, esophagogastric junction; GAN, generative adversarial network 도 13은 학습한 영상의 특성을 갖도록 변환된 검증용 데이터에서의인공지능 성능 향상(pEPK 데이터셋)을 나타낸 것이다. 각 기종별 원본 영상을 학습한 위식도 접합부를 인식하는 인공지능은 다른 내시경 기종의 영상에서 인식 성능이 저하되고(점선으로 표시된 AI-o260, AI-o290), 인공지능이 학습한 영상의 특성을 갖도록 변환된 검증용 데이터 셋에서는 유의한 성능 향상을 보인다(실선으로 표기된 AI-o260, AI-o290). 또한, 상기와 같이 설명된 장치 및 방법은 상기 설명된 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것 이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조 합되어 구성될 수도 있다."}
{"patent_id": "10-2023-0099545", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 면의간단한설명본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명 의 상세한 설명과 함께 본 발명의 기술적 사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도 면에 기재된 사항에만 한정되어 해석 되어서는 아니 된다. 도 1은 내시경 영상 수집 과정 중의 규격화 예시, 도 2는 Microsoft Excel을 이용한 영상 표식 예시, 도 3은 인공지능의 학습용, 검증용 영상의 무작위 추출, 도 4는 본 발명의 실시예에 따른 모식도, 도 5a 및 도 5b는 EfficientNet과 CycleGAN 알고리즘 구조, 도 6은 촬영에 사용된 내시경 기종을 판별하는 인공지능의 성능, 도 7은 o260 데이터셋에서 위식도 접합부 인식 인공지능 성능의 비교, 도 8은 o290 데이터셋에서 위식도 접합부 인식 인공지능 성능의 비교, 도 9는 pEPK 데이터셋에서 위식도 접합부 인식 인공지능 성능의 비교, 도 10은 위식도 접합부 영상을 인식하는 인공지능의 cycleGAN 변환과 Class activation map 예시, 도 11은 학습한 영상의 특성을 갖도록 변환된 검증용 데이터에서의 인공지능 성능 향상(o260 데이터셋), 도 12는 학습한 영상의 특성을 갖도록 변환된 검증용 데이터에서의 인공지능 성능 향상(o290 데이터셋), 도 13은 학습한 영상의 특성을 갖도록 변환된 검증용 데이터에서의 인공지능 성능 향상(pEPK 데이터셋)을 나타 낸 것이다."}
