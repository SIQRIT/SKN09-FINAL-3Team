{"patent_id": "10-2020-0060251", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0143460", "출원번호": "10-2020-0060251", "발명의 명칭": "특징 추천 장치 및 그것의 특징 추천 방법", "출원인": "삼성에스디에스 주식회사", "발명자": "신재선"}}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "특징 추천 장치에 의해 수행되는 방법에 있어서,하나의 타겟 변수 및 복수의 특징 변수로 이루어진 데이터셋에 있어 상기 특징 변수 각각에 대한 결측치를 기설정된 상수(constant)로 변환하는 제1변환을 수행하는 단계;상기 제1변환에 의해 변경된 데이터셋을 이용하여 상기 복수의 특징 변수 중 중복성이 높은 특징 변수를 필터링하기 위한 적어도 하나의 알고리즘을 실행하는 단계; 및상기 적어도 하나의 알고리즘의 실행 결과에 기초하여 선택되는 소정 개수의 특징 변수를 추천 정보로 제공하는단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 적어도 하나의 알고리즘을 실행하는 단계는,상기 복수의 특징 변수의 상호 정보량을 측정 가능한 mRMR. JMIM, CMIM, 및 ICAP 알고리즘 중 적어도 하나를 실행하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 소정 개수의 특징 변수를 추천 정보로 제공하는 단계는,상기 적어도 하나의 알고리즘 실행에 의해 획득한 각 추천 순위들의 평균을 이용하여 상기 특징 변수 각각에 대한 추천 순위를 부여하는 단계; 및상기 추천 순위에 기초하여 상기 소정 개수의 특징 변수를 선택하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 추천 정보로 제공된 소정 개수의 특징 변수 각각에 대한 결측치를 기 설정된 상수 또는 임의의 값으로 변환하는 제2변환을 수행하는 단계; 상기 제2변환에 의해 변경된 데이터셋을 이용하여 상기 소정 개수의 특징 변수 중 상기 타겟 변수의 분류 또는예측과 관련하여 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 단계; 및상기 알고리즘의 실행 결과에 기초하여 최종 추천 정보를 제공하는 단계를 더 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 제2변환을 수행하는 단계는,공개특허 10-2021-0143460-2-상기 타겟 변수가 연속형 변수인 회귀 문제의 경우, 상기 소정 개수의 특징 변수 각각에 대한 결측치를 기 설정된 상수로 변환하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4항에 있어서,상기 제2변환을 수행하는 단계는,상기 타겟 변수가 범주형 변수인 분류 문제의 경우, 상기 소정 개수의 특징 변수 각각에 대한 결측치를 임의의값으로 변환하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 4항에 있어서,상기 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 단계는,상기 소정 개수의 특징 변수에 대해 상기 타겟 변수와의 관련성을 측정 가능한 랜덤 포레스트(Random Forest)알고리즘을 실행하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 4항에 있어서,상기 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 단계는,상기 소정 개수의 특징 변수 각각에 부여된 추천 순위에 기초하여 상기 소정 개수의 특징 변수 중 일부만을 사용하여 상기 알고리즘을 실행하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 4항에 있어서,상기 최종 추천 정보를 제공하는 단계는,상기 알고리즘의 실행에 의해 측정된 상기 특징 변수 각각의 중요도가 기 설정된 임계값보다 큰 특징 변수를 최종 추천 정보로 제공하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 4항에 있어서,상기 복수의 특징 변수 전체를 이용하여 적어도 하나의 머신러닝 알고리즘에 기초한 제1적합도 검증을 수행하는단계;상기 최종 추천 정보로 제공되는 특징 변수만을 이용하여 상기 적어도 하나의 머신러닝 알고리즘에 기초한 제2적합도 검증을 수행하는 단계; 및상기 제1적합도 검증과 상기 제2적합도 검증의 수행 결과를 비교함에 의해 상기 최종 추천 정보를 검증하는 단계를 포함하는,특징 추천 장치에 의해 수행되는 방법."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2021-0143460-3-하나 이상의 프로세서;외부장치와 통신하는 통신 인터페이스;상기 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리; 및상기 컴퓨터 프로그램을 저장하는 스토리지를 포함하되,상기 컴퓨터 프로그램은,하나의 타겟 변수 및 복수의 특징 변수로 이루어진 데이터셋에 있어 상기 특징 변수 각각에 대한 결측치를 기설정된 상수(constant)로 변환하는 제1변환을 수행하는 동작,상기 제1변환에 의해 변경된 데이터셋을 이용하여 상기 복수의 특징 변수 중 중복성이 높은 특징 변수를 필터링하기 위한 적어도 하나의 알고리즘을 실행하는 동작, 및상기 적어도 하나의 알고리즘의 실행 결과에 기초하여 선택되는 소정 개수의 특징 변수를 추천 정보로 제공하는동작을 수행하기 위한 인스트럭션들(instructions)을 포함하는,특징 추천 장치."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 적어도 하나의 알고리즘을 실행하는 동작은,상기 복수의 특징 변수의 상호 정보량을 측정 가능한 mRMR. JMIM, CMIM, 및 ICAP 알고리즘 중 적어도 하나를 실행하는 동작을 포함하는,특징 추천 장치."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11항에 있어서,상기 소정 개수의 특징 변수를 추천 정보로 제공하는 동작은,상기 적어도 하나의 알고리즘 실행에 의해 획득한 각 추천 순위들의 평균을 이용하여 상기 특징 변수 각각에 대한 추천 순위를 부여하는 동작, 및상기 추천 순위에 기초하여 상기 소정 개수의 특징 변수를 선택하는 동작을 포함하는,특징 추천 장치."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11항에 있어서,상기 컴퓨터 프로그램은,상기 추천 정보로 제공된 소정 개수의 특징 변수 각각에 대한 결측치를 기 설정된 상수 또는 임의의 값으로 변환하는 제2변환을 수행하는 동작, 상기 제2변환에 의해 변경된 데이터셋을 이용하여 상기 소정 개수의 특징 변수 중 상기 타겟 변수의 분류 또는예측과 관련하여 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 동작, 및상기 알고리즘의 실행 결과에 기초하여 최종 추천 정보를 제공하는 동작을 수행하기 위한 인스트럭션들(instructions)을 더 포함하는,특징 추천 장치."}
{"patent_id": "10-2020-0060251", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,공개특허 10-2021-0143460-4-상기 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 동작은,상기 소정 개수의 특징 변수에 대해 상기 타겟 변수와의 관련성을 측정 가능한 랜덤 포레스트(Random Forest)알고리즘을 실행하는 동작을 포함하는,특징 추천 장치."}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 특징 추천 장치에 의해 수행되는 방법은, 하나의 타겟 변수 및 복수의 특징 변수로 이루어진 데이터셋에 있어 특징 변수 각각에 대한 결측치를 기 설정된 상수로 변환하는 제1변환을 수행하는 단계; 제1변환에 의해 변경된 데이터셋을 이용하여 복수의 특징 변수 중 중복성이 높은 특징 변수를 필터링하기 위한 적어도 하나의 알고리즘을 실행하는 단계; 및 적어도 하나의 알고리즘의 실행 결과에 기초하여 선택되는 소 정 개수의 특징 변수를 추천 정보로 제공하는 단계를 포함한다."}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 특징 추천 장치 및 그것의 특징 추천 방법에 관한 것으로서, 보다 자세하게는, 결측치를 가지고 있는 데이터로부터 특징을 추출하기 위한 특징 추천 장치 및 그것의 특징 추천 방법에 관한 것이다."}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다양한 비즈니스 환경에서 발생하는 데이터로부터 의미 있는 정보를 얻어내기 위해, 통계 기법 및 인공지능 알 고리즘을 이용하여 데이터의 특징을 추출해내는 방법이 사용된다. 이 때, 실제 비즈니스 환경에서 발생 및 저장 되는 데이터들은 입력 오류, 무응답 등 여러 가지 요인으로 인해 적지 않은 결측치(missing value)가 발생하게 된다. 이러한 결측치는 데이터 분석을 위해 필요한 표본의 수를 감소시키거나, 잘못된 분석 결과를 초래하는 원인이 되기 때문에, 결측치의 특성 및 발생 빈도에 따라 적절한 처리를 해주는 과정이 요구된다. 기존에는 결측치가 있는 데이터를 분석하기 위해, 해당 데이터를 삭제하고 남은 데이터만을 사용하거나, 결측치 를 적당한 값으로 추정하여 치환하는 대치법(imputation of missing value)이 주로 사용되어 왔다. 그러나, 결측치가 있는 데이터를 전부 삭제하는 경우, 원본 데이터의 특징을 완전히 반영하지 못하고, 특징 추 출 후 결측치의 보정 결과에 예민하다는 단점이 있다. 또한, 결측치를 추정값으로 치환하는 방법의 경우, 결측 치의 비율을 고려하지 않고 특징을 추출하게 되므로 분석의 정확도가 떨어지는 문제점이 있다. 한편, 기존에는 결측치가 있는 데이터에 대한 특징 추출 방법으로서, 상관계수 분석, 카이제곱 검정 등과 같은 통계 기법을 이용하여 중복된 특징을 필터링하는 방법과, 그리디(Greedy) 알고리즘 기반으로 특정 모델에 대한 이상적인 변수의 조합을 찾는 방법, 또는 내장 메트릭(metric)을 이용하여 특징을 추천하는 임베디드 방법 등이 사용되어 왔다. 그러나, 이러한 방법들의 경우 결측치가 없는 데이터에 대해서만 특징 추출이 가능하여 실제 사용시 제한적이다. 또한, 특징 추출 시 한 가지 방법의 알고리즘에 의존하므로 정확도가 다소 떨어지거나 과적합의 가 능성, 또는 학습 시간이 오래 걸리는 등 알고리즘에 따른 단점이 존재한다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-0590538호(2006.06.09. 등록)"}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 결측치가 있는 데이터에 대해 결측치의 제거 없이도 타겟과 연관된 특징을 추출할 수 있는 특징 추천 장치 및 그것의 특징 추천 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 기술적 과제는, 결측치가 있는 데이터에 대해 상호 정보량에 기반한 다양한 알고리즘을 이용하여 특징을 추천할 수 있는 특징 추천 장치 및 그것의 특징 추천 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 기술적 과제는, 결측치에 대한 페널티(penalty) 적용을 통해 결측치의 보정 결과에 민감하지 않은 특징 추천 정보를 제공할 수 있는 특징 추천 장치 및 그것의 특징 추천 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 아래의 기재로부터 본 개시의 기술분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한, 본 발명의 일 실시예에 따른 특징 추천 장치에 의해 수행되는 방법은, 하나 의 타겟 변수 및 복수의 특징 변수로 이루어진 데이터셋에 있어 특징 변수 각각에 대한 결측치를 기 설정된 상 수(constant)로 변환하는 제1변환을 수행하는 단계; 제1변환에 의해 변경된 데이터셋을 이용하여 복수의 특징 변수 중 중복성이 높은 특징 변수를 필터링하기 위한 적어도 하나의 알고리즘을 실행하는 단계; 및 적어도 하나 의 알고리즘의 실행 결과에 기초하여 선택되는 소정 개수의 특징 변수를 추천 정보로 제공하는 단계를 포함한다. 일 실시예로서, 상기 적어도 하나의 알고리즘을 실행하는 단계는, 상기 복수의 특징 변수의 상호 정보량을 측정 가능한 mRMR. JMIM, CMIM, 및 ICAP 알고리즘 중 적어도 하나를 실행하는 단계를 포함할 수 있다. 일 실시예로서, 상기 소정 개수의 특징 변수를 추천 정보로 제공하는 단계는, 상기 적어도 하나의 알고리즘 실 행에 의해 획득한 각 추천 순위들의 평균을 이용하여 상기 특징 변수 각각에 대한 추천 순위를 부여하는 단계; 및 상기 추천 순위에 기초하여 상기 소정 개수의 특징 변수를 선택하는 단계를 포함할 수 있다. 일 실시예로서, 상기 추천 정보로 제공된 소정 개수의 특징 변수 각각에 대한 결측치를 기 설정된 상수 또는 임 의의 값으로 변환하는 제2변환을 수행하는 단계; 상기 제2변환에 의해 변경된 데이터셋을 이용하여 상기 소정 개수의 특징 변수 중 상기 타겟 변수의 분류 또는 예측과 관련하여 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 단계; 및 상기 알고리즘의 실행 결과에 기초하여 최종 추천 정보를 제공하는 단계를 더 포 함할 수 있다. 일 실시예로서, 상기 제2변환을 수행하는 단계는, 상기 타겟 변수가 연속형 변수인 회귀 문제의 경우, 상기 소 정 개수의 특징 변수 각각에 대한 결측치를 기 설정된 상수로 변환하는 단계를 포함할 수 있다. 일 실시예로서, 상기 제2변환을 수행하는 단계는, 상기 타겟 변수가 범주형 변수인 분류 문제의 경우, 상기 소 정 개수의 특징 변수 각각에 대한 결측치를 임의의 값으로 변환하는 단계를 포함할 수 있다. 일 실시예로서, 상기 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 단계는, 상기 소정 개수의 특징 변수에 대해 상기 타겟 변수와의 관련성을 측정 가능한 랜덤 포레스트(Random Forest) 알고리즘을 실행하 는 단계를 포함할 수 있다. 일 실시예로서, 상기 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 단계는, 상기 소정 개수의 특징 변수 각각에 부여된 추천 순위에 기초하여 상기 소정 개수의 특징 변수 중 일부만을 사용하여 상기 알고리 즘을 실행하는 단계를 포함할 수 있다. 일 실시예로서, 상기 최종 추천 정보를 제공하는 단계는, 상기 알고리즘의 실행에 의해 측정된 상기 특징 변수 각각의 중요도가 기 설정된 임계값보다 큰 특징 변수를 최종 추천 정보로 제공하는 단계를 포함할 수 있다. 일 실시예로서, 상기 복수의 특징 변수 전체를 이용하여 적어도 하나의 머신러닝 알고리즘에 기초한 제1적합도 검증을 수행하는 단계; 상기 최종 추천 정보로 제공되는 특징 변수만을 이용하여 상기 적어도 하나의 머신러닝 알고리즘에 기초한 제2적합도 검증을 수행하는 단계; 및 상기 제1적합도 검증과 상기 제2적합도 검증의 수행 결 과를 비교함에 의해 상기 최종 추천 정보를 검증하는 단계를 포함할 수 있다. 상기 기술적 과제를 해결하기 위한, 본 발명의 일 실시예에 따른 특징 추천 장치는, 하나 이상의 프로세서; 외 부장치와 통신하는 통신 인터페이스; 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리; 및 컴퓨터 프로그램을 저장하는 스토리지를 포함하되, 컴퓨터 프로그램은, 하나의 타겟 변수 및 복수의 특징 변 수로 이루어진 데이터셋에 있어 특징 변수 각각에 대한 결측치를 기 설정된 상수(constant)로 변환하는 제1변환 을 수행하는 동작, 제1변환에 의해 변경된 데이터셋을 이용하여 복수의 특징 변수 중 중복성이 높은 특징 변수 를 필터링하기 위한 적어도 하나의 알고리즘을 실행하는 동작, 및 적어도 하나의 알고리즘의 실행 결과에 기초 하여 선택되는 소정 개수의 특징 변수를 추천 정보로 제공하는 동작을 수행하기 위한 인스트럭션들 (instructions)을 포함한다.일 실시예로서, 상기 적어도 하나의 알고리즘을 실행하는 동작은, 상기 복수의 특징 변수의 상호 정보량을 측정 가능한 mRMR. JMIM, CMIM, 및 ICAP 알고리즘 중 적어도 하나를 실행하는 동작을 포함할 수 있다. 일 실시예로서, 상기 소정 개수의 특징 변수를 추천 정보로 제공하는 동작은, 상기 적어도 하나의 알고리즘 실 행에 의해 획득한 각 추천 순위들의 평균을 이용하여 상기 특징 변수 각각에 대한 추천 순위를 부여하는 동작, 및 상기 추천 순위에 기초하여 상기 소정 개수의 특징 변수를 선택하는 동작을 포함할 수 있다. 일 실시예로서, 상기 컴퓨터 프로그램은, 상기 추천 정보로 제공된 소정 개수의 특징 변수 각각에 대한 결측치 를 기 설정된 상수 또는 임의의 값으로 변환하는 제2변환을 수행하는 동작, 상기 제2변환에 의해 변경된 데이터 셋을 이용하여 상기 소정 개수의 특징 변수 중 상기 타겟 변수의 분류 또는 예측과 관련하여 중요도가 높은 특 징 변수를 추출하기 위한 알고리즘을 실행하는 동작, 및 상기 알고리즘의 실행 결과에 기초하여 최종 추천 정보 를 제공하는 동작을 수행하기 위한 인스트럭션들(instructions)을 더 포함할 수 있다. 일 실시예로서, 상기 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 동작은, 상기 소정 개수의 특징 변수에 대해 상기 타겟 변수와의 관련성을 측정 가능한 랜덤 포레스트(Random Forest) 알고리즘을 실행하 는 동작을 포함할 수 있다."}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 개시의 바람직한 실시 예들을 상세히 설명한다. 본 개시의 이점 및 특징, 그 리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 개시의 기술적 사상은 이하의 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구 현될 수 있으며, 단지 이하의 실시예들은 본 개시의 기술적 사상을 완전하도록 하고, 본 개시가 속하는 기술분 야에서 통상의 지식을 가진 자에게 본 개시의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 기술 적 사상은 청구항의 범주에 의해 정의될 뿐이다. 각 도면의 구성요소들에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시 되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련 된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세 한 설명은 생략한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있다. 또 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 개시를 제한하고자 하는 것은 아니 다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 또한, 본 개시의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는 (comprising)\"은 언급된 구성 요소, 단계, 동 작 및/또는 소자는 하나 이상의 다른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 이하, 본 개시의 몇몇 실시예들에 대하여 첨부된 도면에 따라 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 특징 추천 장치의 구성을 도시한 블록도이다. 도 1을 참조하면, 본 발명의 실시예에 따라 특징 추천 장치는 서버와 데이터베이스를 포함하고, 사용자 단말로부터 수신 되는 특징 추천 요청을 처리하여, 그 결과를 제공한다. 서버는 고정식 컴퓨팅 장치로서, 사용자 단말 및 데이터 저장부와 네트워크를 통해 연결된다. 서 버는 사용자 단말로부터 수신되는 특징 추천 요청에 대해, 데이터 저장부에 저장되어 있는 데이터 를 이용하여 특징 추천을 위한 분석을 수행한다. 서버는 통계 분석 및 인공지능 알고리즘을 실행 가능한 머신 러닝(Machine Learning) 전용 장치로 구현될 수 있다. 데이터 저장부는 특징 추천 장치와 네트워크로 연결되어 있는 별도의 외부 장치 또는 DB 서버로 구현 될 수 있고, 다양한 분야의 비즈니스 환경에서 발생되는 데이터를 저장할 수 있다. 이 때, 데이터 저장부에 저장되는 데이터는 적어도 하나의 연속형 변수와 범주형 변수로 이루어진 데이터셋 (data set)을 포함할 수 있다. 여기서, 연속형 변수 및 범주형 변수 각각은 특징 추천을 위한 데이터 분석 시 타겟 변수 또는 특징 변수로 사용될 수 있다. 또한, 데이터 저장부에 저장되는 데이터는 입력 오류, 무응답 등 여러 가지 요인으로 인해 발생되는 결측치 (missing value)를 포함할 수 있다. 서버는 일정 주기 단위로 데이터 저장부로부터 데이터를 전송받거나, 사용자 단말로부터 요청이 발생할 때마다 데이터 저장부로 필요한 데이터를 요청할 수도 있다. 서버는 데이터 저장부로부터 전송받은 데이터를 이용하여 특징 추천을 위한 분석을 수행하고, 이에 따 른 분석 결과를 사용자 단말로 제공할 수 있다. 데이터베이스는 서버가 데이터 저장부로부터 수신한 데이터를 구성하는 연속형 변수 및 범주형 변수와 관련된 변수 정보를 저장한다. 또한, 데이터베이스는 서버가 데이터 저장부로부터 수신한 데이터에 대한 특징을 추천하기 위해 생성하는 분석 모델에 관한 정보, 및 분석 모델의 학습 결과 에 기초하여 제공되는 특징 추천 정보를 저장한다. 데이터베이스는 특징 추천 장치에서 처리된 특징 추천을 위한 데이터 분석과 관련된 모든 정보를 저 장하는 DB 서버로 구현될 수 있다. 사용자 단말은 예컨대, 개인용 데스크탑 PC와 같은 고정식 컴퓨팅 장치, 스마트 폰, 태블릿 PC, 랩톱 PC, PDA, VR(Virtual Reality) 영상 장치, AR(Augmented Reality) 영상 장치 등과 같은 이동식 컴퓨팅 장치 중 어 느 하나일 수 있다. 사용자 단말는 특징 추천 장치의 서버로 데이터 저장부에 저장된 데이터 에 대한 특징 추천을 요청하고, 서버로부터 제공되는 특징 추천 결과를 이용하여 의사 결정을 하는 관리자 또는 직원의 단말기로 구현될 수 있다. 상기와 같이 본 발명의 실시예에 따른 특징 추천 장치의 구성에 의해, 결측치가 있는 데이터에 대해 결측 치의 제거 없이도 타겟과 연관된 특징을 추출할 수 있는 최적의 방법을 제공해줄 수 있다. 도 2는 도 1을 참조하여 설명한 특징 추천 장치의 하드웨어 구성을 도시한 구성도이다. 도시된 바와 같이, 특징 추천 장치의 서버는 컴퓨팅 장치로서, 하나 이상의 프로세서, 버스 , 네트워크 인터페이스, 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리와, 컴퓨터 프로그램를 저장하는 스토리지를 포함할 수 있다. 다만, 도 2에는 본 발명의"}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "실시예와 관련 있는 구성요소들 만이 도시되어 있다. 따라서, 본 발명이 속한 기술분야의 통상의 기술자라면 도 2에 도시된 구성요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 도 2에 도시된 특 징 추천 장치의 서버는 IaaS(Infrastructure-as-a-Service) 방식의 클라우드 서비스를 제공하는 서버팜(server farm)에 소속된 물리 서버 중 어느 하나를 가리킬 수 있다. 프로세서는 특징 추천 장치의 서버의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또한, 프로세서는 본 발명의 다양한 실시예들에 따른 방법/동작을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 특징 추천 장치의 서버는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예들에 따른 방법/동작들을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드(load) 할 수 있다. 예 를 들어, 컴퓨터 프로그램이 메모리에 로드 되면, 로직(또는 모듈)이 메모리 상에 구현될 수 있 다. 메모리의 예시는 RAM이 될 수 있으나, 이에 한정되는 것은 아니다. 버스는 특징 추천 장치의 서버의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스 (Address Bus), 데이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 네트워크 인터페이스는 특징 추천 장치의 서버의 유무선 인터넷 통신을 지원한다. 네트워크 인 터페이스는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 네트워크 인터페이스 는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 스토리지는 하나 이상의 컴퓨터 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알 려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 또한, 스토리지는 본 발명의 실시예에 따라 서버가 수행하는 특징 추천 방법에 의해 제공되는 특징 추천 정보를 저장할 수 있다. 컴퓨터 프로그램은 본 발명의 다양한 실시예들에 따른 방법/동작들이 구현된 하나 이상의 인스트럭션들 (instructions)을 포함할 수 있다. 예를 들어, 컴퓨터 프로그램은 하나의 타겟 변수 및 복수의 특징 변수 로 이루어진 데이터셋에 있어 상기 특징 변수 각각에 대한 결측치를 기 설정된 상수(constant)로 변환하는 제1 변환을 수행하는 동작, 상기 제1변환에 의해 변경된 데이터셋을 이용하여 상기 복수의 특징 변수 중 중복성이 높은 특징 변수를 필터링하기 위한 적어도 하나의 알고리즘을 실행하는 동작, 및 상기 적어도 하나의 알고리즘 의 실행 결과에 기초하여 선택되는 소정 개수의 특징 변수를 추천 정보로 제공하는 동작을 수행하기 위한 인스 트럭션들을 포함할 수 있다. 일 실시예로서, 적어도 하나의 알고리즘을 실행하는 동작은, 복수의 특징 변수의 상호 정보량을 측정 가능한 mRMR. JMIM, CMIM, 및 ICAP 알고리즘 중 적어도 하나를 실행하는 동작을 포함할 수 있다. 일 실시예로서, 소정 개수의 특징 변수를 추천 정보로 제공하는 동작은, 적어도 하나의 알고리즘 실행에 의해 획득한 각 추천 순위들의 평균을 이용하여 특징 변수 각각에 대한 추천 순위를 부여하는 동작, 및 추천 순위에 기초하여 소정 개수의 특징 변수를 선택하는 동작을 포함할 수 있다. 일 실시예로서, 상기 컴퓨터 프로그램은, 추천 정보로 제공된 소정 개수의 특징 변수 각각에 대한 결측치 를 기 설정된 상수 또는 임의의 값으로 변환하는 제2변환을 수행하는 동작, 제2변환에 의해 변경된 데이터셋을 이용하여 소정 개수의 특징 변수 중 타겟 변수의 분류 또는 예측과 관련하여 중요도가 높은 특징 변수를 추출하 기 위한 알고리즘을 실행하는 동작, 및 알고리즘의 실행 결과에 기초하여 최종 추천 정보를 제공하는 동작을 수 행하기 위한 인스트럭션들을 더 포함할 수 있다. 일 실시예로서, 제2변환을 수행하는 동작은, 타겟 변수가 연속형 변수인 회귀 문제의 경우, 소정 개수의 특징 변수 각각에 대한 결측치를 기 설정된 상수로 변환하는 동작을 포함할 수 있다. 또한, 제2변환을 수행하는 동작 은, 타겟 변수가 범주형 변수인 분류 문제의 경우, 소정 개수의 특징 변수 각각에 대한 결측치를 임의의 값으로 변환하는 동작을 포함할 수 있다. 일 실시예로서, 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 동작은, 소정 개수의 특징 변수 에 대해 타겟 변수와의 관련성을 측정 가능한 랜덤 포레스트 알고리즘을 실행하는 동작을 포함할 수 있다. 여기 서, 중요도가 높은 특징 변수를 추출하기 위한 알고리즘을 실행하는 동작은, 소정 개수의 특징 변수 각각에 부 여된 추천 순위에 기초하여 소정 개수의 특징 변수 중 일부만을 사용하여 알고리즘을 실행하는 동작을 포함할수 있다. 일 실시예로서, 최종 추천 정보를 제공하는 동작은, 알고리즘의 실행에 의해 측정된 특징 변수 각각의 중요도가 기 설정된 임계값보다 큰 특징 변수를 최종 추천 정보로 제공하는 동작을 포함할 수 있다. 컴퓨터 프로그램이 메모리에 로드 되면, 프로세서는 상기 하나 이상의 인스트럭션들을 실행시킴 으로써 본 발명의 다양한 실시예들에 따른 방법/동작들을 수행할 수 있다. 상기와 같이, 본 발명의 실시예에 따른 특징 추천 장치에 의하면, 결측치가 있는 데이터에 대해, 결측치의 제거 없이도 타겟과 연관된 적절한 특징을 추출할 수 있다. 또한, 결측치에 대한 페널티 적용을 통해 결측치의 보정 결과에 민감하지 않은 특징 추천 정보를 제공해줄 수 있다. 도 3은 본 발명의 일 실시예에 따른 특징 추천 방법을 설명하기 위한 순서도이다. 본 실시예에 따른 특징 추천 방법은 컴퓨팅 장치에 의하여 실행될 수 있고, 예컨대 특징 추천 장치에 의해 실행될 수 있다. 본 실시예에 따른 방법을 실행하는 상기 컴퓨팅 장치는 프로그램 개발 환경을 구비한 컴퓨팅 장치이거나, 응용 프로그램 실행 환경을 구비한 컴퓨팅 장치일 수 있다. 본 실시예에 따른 방법에 포함되는 일부 동작의 수행 주 체에 대한 기재가 생략될 수 있으며, 그러한 경우 그 주체는 상기 컴퓨팅 장치임을 유의한다. 도 3을 참조하면, 먼저, 동작 S31에서, 하나의 타겟 변수 및 복수의 특징 변수로 이루어진 데이터셋에 있어 특 징 변수 각각에 대한 결측치를 기 설정된 상수(constant)로 변환하는 제1변환이 수행된다. 여기서, 데이터셋은 앞서 도 1에서 설명한 특징 추천 장치의 서버가 사용자 단말의 요청에 따라 데이터 저장부로 요청하여 제공받는 데이터를 포함한다. 데이터셋은 하나의 타겟 변수(target variable)와, 하나의 타겟 변수와의 연관성을 분석하고자 하는 복수의 특징 변수(feature variable)들을 포함할 수 있다. 복 수의 특징 변수는 원본 데이터에 포함된 변수들을 가공하여 만든 합성 변수(synthetic variable)들을 포함할 수 있다. 데이터셋에 있어 타겟 변수와 복수의 특징 변수의 지정은 분석의 목적에 따라 사용자 단말의 사용자 에 의해 다르게 설정될 수 있다. 일 실시예로서, 타겟 변수 및 복수의 특징 변수는 연속형 변수(continuous variable) 또는 범주형 변수 (categorical variable)로 마련될 수 있다. 범주형 변수인 경우, 0 또는 1의 값을 가지는 이항 변수(binary variable) 또는 복수의 값으로 구분되는 멀티클래스 변수(multiclass variable)의 형태가 모두 가능하다. 동작 S31에 있어, 결측치를 상수로 채우는 방식인 제1변환을 통해, 결측치가 있는 특징에 대해 중복성 페널티 (redundancy penalty)를 적용할 수 있다. 즉, 결측치가 많은 특징 변수들 간의 중복성을 높여 이후 필터링 시 결측치가 많은 변수가 추천 특징으로 선택될 가능성을 줄일 수 있다. 다음으로, 동작 S32에서, 제1변환에 의해 변경된 데이터셋을 이용하여 복수의 특징 변수 중 중복성이 높은 특징 변수를 필터링하기 위한 적어도 하나의 알고리즘이 실행된다. 일 실시예로서, 동작 S32는, 복수의 특징 변수의 상호 정보량(mutual information)을 측정 가능한 mRMR. JMIM, CMIM, 및 ICAP 알고리즘 중 적어도 하나를 실행하는 동작을 포함할 수 있다. 여기서, 상호 정보량이란 두 확률 변수가 서로 어떤 관계를 가지고 있는지 나타내는 정보량을 의미하는 것으로, 두 확률 변수가 완전히 독립인 경 우 그 값은 0이 되고, 두 확률 변수가 서로 밀접한 관련이 있을 경우 그 값은 커지고, 역의 방향으로 관련이 있 을 경우 그 값은 작아지게 된다. 즉, 상호 정보량을 이용하여 두 확률 변수가 얼마나 밀접한 관련이 있는지를 계량화하여 판단할 수 있다. 즉, 동작 S32에서, 상기 알고리즘들을 실행하여 복수의 특징 변수들 간 상호 정보량을 측정하고, 상호 정보량이 큰 변수들을 중복성이 높은 변수로 판단하여 특징 변수 추천 시 필터링 되도록 할 수 있다. 동작 S32에서 상호 정보량을 측정할 수 있는 알고리즘 각각은 다음과 같은 방법이 적용된 것이다. mRMR(minimum redundancy-maximum relevancy criterion) 알고리즘의 경우, 타겟 변수와 관련성이 높으면서 선 택되는 특징 간 중복된 정보를 줄이는 방향으로 특징들을 선택하도록 한다. JMIM(joint mutual information maximization criterion) 알고리즘의 경우, 후보 특징(candidate feature)과 사전 선택된 특징들(pre-selected features) 간 공동 상호 정보량(joint mutual information)을 최대화함으로 써 특징들을 선택하도록 한다. CMIM(conditional mutual information maximization) 알고리즘은, 조건부 상호 정보량(conditional mutual information)에 기초하여 특징들을 선택하되, 사전 선택된 특징들과 유사한 특징들은 피하는 방식으로 특징들을 선택하도록 한다. ICAP 알고리즘은, 후보 특징과 사전 선택된 특징들 간 상호작용(interaction)이 중복되는 경우, 페널티 (penalty)를 적용하여 타겟과의 상호 정보량은 높고 사전 선택된 특징들과의 상호 정보량은 낮은 특징들을 선택 하도록 한다. 다음으로, 동작 S33에서, 적어도 하나의 알고리즘의 실행 결과에 기초하여 선택되는 소정 개수의 특징 변수가 추천 정보로 제공된다. 일 실시예로서, 동작 S33은, 동작 S32에서 적어도 하나의 알고리즘 실행에 의해 획득한 각 알고리즘별 추천 순 위들의 평균을 이용하여 특징 변수 각각에 대한 추천 순위를 부여하는 동작, 및 추천 순위에 기초하여 소정 개 수의 특징 변수를 선택하는 동작을 포함할 수 있다. 즉, 각 알고리즘을 실행하여 복수의 특징 변수 각각에 대한 추천 순위들이 제공되면, 각 알고리즘별로 제공된 특징 변수 각각에 대한 추천 순위들의 평균을 산출할 수 있다. 이 때, 산출된 각 특징 변수의 추천 순위 평균을 이용하여 특징 변수 각각에 대한 최종 추천 순위를 부여하고, 이를 기초로 최종 추천 순위가 높은 소정 개수의 특징 변수를 추천 특징으로 선택할 수 있다. 상기와 같은 실시예에 따라, 결측치가 있는 특징들 간의 중복성을 최대화하는 방식으로 페널티를 적용하고, 상 호 정보량에 기반한 다양한 알고리즘을 이용하여 중복성이 높은 특징들을 필터링함에 의해 좀더 정확한 특징 추 천 결과를 제공할 수 있다. 도 4는 본 발명의 다른 실시예에 따른 특징 추천 방법을 설명하기 위한 순서도이다. 본 실시예에 따른 특징 추 천 방법은 컴퓨팅 장치에 의하여 실행될 수 있고, 예컨대 특징 추천 장치에 의해 실행될 수 있다. 본 실시예에 따른 방법을 실행하는 상기 컴퓨팅 장치는 프로그램 개발 환경을 구비한 컴퓨팅 장치이거나, 응용 프로그램 실행 환경을 구비한 컴퓨팅 장치일 수 있다. 본 실시예에 따른 방법에 포함되는 일부 동작의 수행 주 체에 대한 기재가 생략될 수 있으며, 그러한 경우 그 주체는 상기 컴퓨팅 장치임을 유의한다. 도 4에서는 도 3에서 결측치가 있는 특징들에 대해 중복성 페널티를 적용한 이후 관련성 페널티를 추가적으로 적용하는 실시예를 설명하기로 한다. 도 4를 참조하면, 동작 S34에서, 동작 S33의 수행 결과에 따라 추천 정보로 제공된 소정 개수의 특징 변수 각각 에 대한 결측치를 기 설정된 상수 또는 임의의 값으로 변환하는 제2변환이 수행된다. 일 실시예로서, 동작 S34는, 타겟 변수가 연속형 변수인 회귀 문제의 경우, 소정 개수의 특징 변수 각각에 대한 결측치를 기 설정된 상수(constant)로 변환하는 동작을 포함할 수 있다. 또한, 동작 S34는, 타겟 변수가 범주형 변수인 분류 문제의 경우, 상기 소정 개수의 특징 변수 각각에 대한 결측치를 임의의 값(random values)으로 변 환하는 동작을 포함할 수 있다. 상기와 같이, 동작 S34에 있어, 결측치를 상수 또는 임의의 값으로 채우는 방식인 제2변환을 통해, 결측치가 있 는 특징에 대해 관련성 페널티(relevance penalty)를 적용할 수 있다. 즉, 결측치가 많은 특징 변수들과 타겟 변수와의 관련성을 낮춰 해당 특징 변수의 중요도를 낮추는 효과를 얻을 수 있다. 이에 따라, 결측치가 많은 변 수에 대해 타겟과의 관련성을 최소화하여 최종적인 추천 특징으로 선택될 가능성을 줄일 수 있다. 다음으로, 동작 S35에서, 제2변환에 의해 변경된 데이터셋을 이용하여, 앞서 제1변환에 의한 중복성 페널티 적 용에 따라 추천 정보로 제공되었던 소정 개수의 특징 변수 중 타겟 변수의 분류 또는 예측과 관련하여 중요도가 높은 특징 변수를 추출하기 위한 알고리즘이 실행된다. 일 실시예로서, 동작 S35는, 소정 개수의 특징 변수에 대해 타겟 변수와의 관련성을 측정 가능한 랜덤 포레스트 (Random Forest) 알고리즘을 실행하는 동작을 포함할 수 있다. 또한, 동작 S35의 수행 시 사용되는 알고리즘은, 랜덤 포레스트로 한정되지 않고, 서포트 벡터 머신(SVM, Support Vector Machine), 배깅 앙상블(Bagging Ensemble), 보팅 앙상블(Voting Ensemble), 그라디언트 부스팅(Gradient Boosting), 로지스틱 회귀(Logistic Regression) 등 다양한 머신러닝 기법을 사용하여 특징 변수와 타겟 변수와의 관련성을 측정할 수 있다. 랜덤 포레스트 알고리즘은, 검출, 분류, 회귀 분석 등에 사용되는 앙상블 학습 모델의 일종으로, 훈련 과정에서 구성한 다수의 결정 트리(decision tree)로부터 분류 또는 평균 예측치를 출력함으로써 동작한다. 랜덤 포레스 트는, 결정 트리가 가진 단점을 극복하기 위해 랜덤 노드 최적화(randomized node optimization, RNO)와 배깅(bootstrap aggregating, bagging)을 결합한 방법을 사용하여 상관관계가 없는 트리들로 포레스트를 구성함으로 써, 결과적으로 일반화(generalization) 성능을 향상시킬 수 있다. 또한, 랜덤 포레스트는, 과적합 (overfitting) 가능성이 낮아 일반화 관점에서 좋으며, 해석하기 쉬운 특징 변수별 중요도를 제공하여 특징 추 천 과정에서 매우 유용한 방법이다. 일 실시예로서, 동작 S35는, 소정 개수의 특징 변수 각각에 부여된 추천 순위에 기초하여 소정 개수의 특징 변 수 중 일부만을 사용하여 알고리즘을 실행하는 동작을 포함할 수 있다. 예를 들어, 랜덤 포레스트 알고리즘의 실행 시, 앞서 제1변환에 의한 중복성 페널티 적용에 따라 추천 정보로 제공되었던 소정 개수의 특징 변수를 모 두 사용하는 것이 아니라. 미리 설정한 값과 비교하여 소정 개수의 특징 변수 중 일부에 해당하는 K개의 특징 변수만을 제2변환에 의한 관련성 페널티를 적용한 이후, 랜덤 포레스트의 입력 데이터로 사용할 수 있다. 마지막으로, 동작 S36에서는, 동작 S35에서 수행된 알고리즘의 실행 결과에 기초하여 최종 추천 정보가 제공된 다. 여기서, 동작 S36은, 알고리즘의 실행에 의해 측정된 특징 변수 각각의 중요도가 기 설정된 임계값보다 큰 특징 변수를 최종 추천 정보로 제공하는 동작을 포함할 수 있다. 예로서, 랜덤 포레스트의 학습 결과를 통해 산 출되는 특징 변수 각각의 중요도(importance) 값이 0.0001보다 큰 특징 변수만을 최종 추천 변수로 선택할 수 있다. 일 실시예로서, 동작 S36의 수행에 따라 제공된 최종 추천 정보에 포함된 특징 변수들이 타겟 변수를 설명할 수 있는 최적의 변수 조합인지를 검증하는 동작이 추가적으로 수행될 수 있다. 일 실시예로서, 검증을 위한 동작으로서, 복수의 특징 변수 전체를 이용하여 적어도 하나의 머신러닝 알고리즘 에 기초한 제1적합도 검증을 수행하는 동작, 최종 추천 정보로 제공되는 특징 변수만을 이용하여 적어도 하나의 머신러닝 알고리즘에 기초한 제2적합도 검증을 수행하는 동작, 및 제1적합도 검증과 제2적합도 검증의 수행 결 과를 비교함에 의해 최종 추천 정보를 검증하는 동작이 수행될 수 있다. 이 때, 제1적합도 검증 및 제2적합도 검증에 있어, 예컨대 MSE(Mean Squared Error), RMSE(Root Mean Squared Error), MAE (Mean Absolute Error), R2 등의 지표가 사용될 수 있다. 상기와 같은 실시예에 따라, 결측치가 있는 특징들에 대해, 특징들 간 중복성을 최대화하고 타겟 변수와의 관련 성을 최소화하는 방식으로 페널티를 적용하고, 상호 정보량에 기반한 필터링 방법과 타겟 변수와의 관련성을 측 정하는 임베디드 방법을 이용하여 최적의 특징 변수의 조합을 추천 정보로 제공할 수 있다. 도 5는 도 3을 참조하여 설명한 특징 추천 방법에 있어 중복성 페널티를 적용하는 예이다. 도 5는 도 3의 동작 S31 내지 동작 S33에 대응하는 것으로, 중복성 페널티 적용에 의해 제공되는 특징 변수의 추천 결과의 예를 보 여준다. 도시된 예에서, 중복성 페널티 적용을 위해, 분석의 대상이 되는 데이터셋으로부터 타겟 변수를 제외한 모든 N 개의 특징 변수들이 입력 데이터로 사용된다. 중복성 페널티 적용 과정에 있어, 스텝 1은 동작 S31에 대응하는 단계로, N개의 특징 변수 각각에 대한 결측치를 상수값으로 채우는 동작이 수행되고, 이를 통해 결측치가 많은 특징들 간 중복성을 높여 필터링을 통 해 걸러질 확률을 높일 수 있다. 스텝 2는 동작 S32에 대응하는 단계로, N개의 특징 변수에 대해, 상호 정보량을 측정할 수 있는 mRMR. JMIM, CMIM, 및 ICAP 등의 알고리즘을 이용하여 중복성이 높은 특징 변수를 필터링하는 방법이 적용된다. 스텝 3는 동작 S33에 대응하는 단계로, 스텝 2에서 얻어진 각 알고리즘별 추천 순위들의 평균을 이용하여 특징 변수 각각에 대한 추천 순위가 부여될 수 있다. 이에 따라, 중복성 페널티 적용 과정에 의한 출력 데이터로서, N개의 특징 변수들 중 추천 순위가 높은 상위 M개의 특징 후보가 선택되어 제공될 수 있다. 도 6은 도 4를 참조하여 설명한 특징 추천 방법에 있어 관련성 페널티를 적용하는 예이다. 도 6은 도 4의 동작 S34 내지 동작 S36에 대응하는 것으로, 관련성 페널티 적용에 의해 제공되는 특징 변수의 최종 추천 결과의 예 를 보여준다. 도시된 예에서, 관련성 페널티 적용을 위해, 앞서 도 5의 중복성 페널티 적용 과정을 통해 선택된 추천 순 위가 높은 상위 M개의 특징 후보가 입력 데이터로 사용된다. 관련성 페널티 적용 과정에 있어, 스텝 1은 동작 S34에 대응하는 단계로, M개의 특징 후보 각각에 대한 결측치를 회귀 문제의 경우 상수값으로 채우고, 분류 문제의 경우 임의의 값(random values)으로 채우는 동작이 수행된다. 이를 통해 결측치가 많은 특징들과 타겟 변수와의 관련성을 낮춰 최종적인 추천 특징으로 선택될 가 능성을 줄일 수 있다. 스텝 2는 동작 S35에 대응하는 단계로, M개의 특징 후보 중 타겟 변수의 분류 또는 예측과 관련하여 중요도 가 높은 특징 변수를 추출하기 위한 임베디드 방법으로서, 예컨대 랜덤 포레스트(Random Forest)와 같은 머신러 닝 알고리즘이 사용될 수 있다. 일 실시예로서, 랜덤 포레스트 알고리즘을 적용하기 위한 특징 변수를 선정함에 있어, 소정의 선정 기준 (selection criteria)이 사용될 수 있다. 예로서, 중복성 페널티 적용을 통해 선택된 M개의 특징 후보 중, M이 25보다 작을 경우 모든 M개의 특징 후보에 대해 랜덤 포레스트 알고리즘을 적용하고, M이 25보다 클 경 우 25와 0.25*M 중에서 큰 값을 K로 하여 M개의 특징 후보 중 상위 K개의 특징 변수에 대해 랜덤 포레스트 알고리즘을 적용할 수 있다. 스텝 3는 동작 S36에 대응하는 단계로, 스텝 2에서 랜덤 포레스트와 같은 임베디드 방법을 통해 얻어진 특징 변 수 각각의 중요도(Importance) 값이 예컨대, 0.0001 이상인 특징 변수가 최종 특징 후보로 선택되어 제공될 수 있다. 도 7은 본 발명의 몇몇 실시예에 따른 결측치가 존재하는 데이터의 예를 도시한 것이다. 도시된 표는, 본 발명 의 실시예에 따른 특징 추천 방법을 적용할 수 있는 데이터셋의 예시이다. 도시된 예에서, 데이터셋은 하나의 타겟 변수(target)와 복수의 특징 변수(Var1, Var2, Var3, Var4, Var5, Var6, Var7, Var8, 쪋)를 포함한다. 도시된 데이터셋에서, 복수의 특징 변수의 대부분은 'null'로 표시되는 결 측치가 존재하고 있음을 알 수 있다. 예로서, 타겟 변수는 연속적인 값을 가지는 연속형 변수의 형태를 가지고, 복수의 특징 변수 각각은 연속형 변 수의 형태를 가지거나, 0 또는 1의 값을 가지는 이항 변수, 또는 복수의 값으로 구분되는 멀티클래스 변수와 같 은 범주형 변수의 형태를 가질 수 있다. 도 8은 본 발명의 몇몇 실시예에 따른 결측치가 있는 데이터에 대한 특징 추천 결과를 도시한 예이다. 도시된 표는, 본 발명의 실시예에 따른 특징 추천 방법에 의해 최종 추천 정보로 제공되는 특징 변수들의 예시이다. 일 실시예로서, 도 7의 데이터셋으로부터 결측치가 존재하는 복수의 특징 변수 각각에 대해, 결측치를 상수값으 로 채우는 중복성 페널티를 적용하고, 중복성이 높은 변수를 필터링하기 위한 적어도 하나의 알고리즘을 실행하 여 추천 순위가 높은 소정 개수의 특징 변수를 후보로 선택할 수 있다. 또한, 선택된 소정 개수의 특징 변수에 대해, 각각의 결측치를 상수 또는 임의의 값으로 채우는 관련성 페널티 를 적용하고, 타겟 변수와의 관련성이 높은 변수를 추출하기 위한 랜덤 포레스트 알고리즘을 실행할 수 있다. 이에 따라, 랜덤 포레스트의 실행 결과로부터 중요도가 높은 특정 변수를 최종 추천 후보로 선택할 수 있다. 도시된 표에서, 랜덤 포레스트의 실행 결과로부터 측정된 중요도 값이 0.0001보다 큰 상위 10개의 특징 변수들 이 최종 추천 특징으로 선택될 수 있다. 상기와 같이, 본 발명의 실시예에 따라, 결측치가 존재하는 특징들에 대해 중복성 페널티 및 관련성 페널티를 적용함에 의해 결측치의 보정 결과에 민감하지 않은 특징 추천 정보를 제공할 수 있다. 도 9 및 도 10은 본 발명의 몇몇 실시예에 따른 특징 추천 결과를 검증하는 예이다. 도 9 및 도 10은 도 3 및 도 4를 참조하여 설명한 특징 추천 방법에 있어, 최종 추천 정보에 포함된 특징 변수들을 검증하는 추가 동작에 관한 예이다. 도 9에 도시된 바와 같이, 최종적으로 선택된 특징 변수들이 타겟 변수를 설명할 수 있는 최적의 조합인지를 검 증하는 동작이 추가적으로 수행될 수 있다. 예로서, 먼저 복수의 특징 변수 전체와 최종 추천 정보에 포함된 특징 변수 각각에 대해 머신러닝 알고 리즘에 기초한 적합도 검증을 독립적으로 수행할 수 있다. 이 때 사용되는 머신러닝 알고리즘은 어느 하나의 모델로 제한되지 않고, 예컨대 선형회귀 모델, 의사결정 나무 모델, 랜덤 포레스트 모델 , 그라디언트 부스팅 모델 등 다양한 종류의 모델을 사용하여 실행될 수 있다. 일 실시예로서, 복수의 머신러닝 알고리즘에 기초한 적합도 검증을 수행하기 위해, 각 모델에서 사용되는 모든 파라미터들의 조합을 이용하여 각각의 모델을 실행할 수 있다. 예로서, 선형회귀 모델의 경우, elastic net과 regularization과 같은 파라미터를 이용한 36가지 조합에 대해 모델을 실행할 수 있다. 의사결정 나무 모델의 경우는, max depth와 같은 파라미터를 이용한 5가지 조합에 대해 모델을 실행할 수 있다. 마찬가지로, 랜덤 포레스트 모델의 경우, number of trees와 max depth와 같은 파라미터를 이용한 15가지 조합에 대해 모델을 실행할 수 있고, 그라디언트 부스팅 모델은 max iteration과 max depth와 같은 파라미터를 이용한 9가지 조합에 대해 모델을 실행할 수 있다. 상기와 같은 각 모델의 실행 과정을 통해 각 모델의 유효성 오류(validation error)를 기준으로 하여 최적의 모 델과 그에 대한 파라미터를 찾을 수 있다. 예로서, 복수의 특징 변수 전체에 대한 적합도 검증 결과로서 최적 모델 A가 제공되고, 최종 추천 정보 에 포함된 특징 변수에 대한 적합도 검증 결과로서, 최적 모델 B가 제공될 수 있다. 도 10을 참조하면, 복수의 특징 변수 전체에 대한 최적 모델 A와 최종 추천 정보에 포함된 특징 변수 에 대한 최적 모델 B 각각에 대해, 테스트 데이터를 이용하여 모델을 실행하고, 그로부터 검정 오류 (Test Error)를 획득할 수 있다. 일 실시예로서, 테스트 데이터를 이용하여 실행되는 각 모델로부터 획득되는 검정 오류로서, 예컨대 MSE(Mean Squared Error), RMSE(Root Mean Squared Error), MAE (Mean Absolute Error), R2 등의 지표가 제공될 수 있다. 여기서, MSE(Mean Squared Error)는 예측값과 실제값 간의 평균 제곱 차를 의미하고, RMSE(Root Mean Squared Error)는 MSE의 제곱근을 의미한다. MAE (Mean Absolute Error)는 예측값과 실제값 간의 평균 차를 의미하고, R2은 타겟 변수의 변동량 중에서 해당 모델로 설명 가능한 부분의 비율을 의미한다. 이와 같은 검정 오류의 측정값을 이용하여 모델을 평가함에 있어, MSE, RMSE, MAE는 그 값이 0에 가까울수록, R2는 그 값이 1에 가까울수록 모델이 잘 적합되고 있음을 의미한다. 예로서, 최적 모델 A에 대한 검정 오류의 측정값들과 최적 모델 B에 대한 검정 오류의 측 정값들을 비교해보면, MSE, RMSE, MAE의 값이 더 작고, R2의 값이 1에 더 가까운 최적 모델 B가 최적 모델 A에 비해 잘 적합되고 있음을 알 수 있다. 결과적으로, 최적 모델 B는 최종 추천 정보에 포함된 특징 변수로부터 얻어진 모델이므로, 본 발명의 실시예에 따라 추천된 특징 변수들의 조합이 전체 특징 변수를 모두 사용하는 경우와 비교하여 타겟 변수를 잘 설명 또는 예측할 수 있음을 알 수 있다. 상기와 같이, 본 발명의 실시예에 따른 특징 추천 방법에 의하면, 결측치가 있는 데이터에 대해 결측치의 제거 없이도 타겟과 연관된 최적의 특징 조합을 추출할 수 있다. 또한, 본 발명의 실시예에 의하면, 결측치에 대한 페널티 적용을 통해 결측치의 보정 결과에 민감하지 않은 특징 추천 정보를 제공할 수 있따. 지금까지 도 1 내지 도 10을 참조하여 본 발명의 다양한 실시예들 및 그 실시예들에 따른 효과들을 언급하였다. 본 발명의 기술적 사상에 따른 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효 과들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다. 지금까지 설명된 본 발명의 기술적 사상은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨터가 읽을 수 있는 코드로 구 현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매체(CD, DVD, 블루레이 디스 크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨터 구비 형 하드 디스크)일 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인터넷 등의 네트워크를 통 하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상기 다른 컴퓨팅 장치에 서 사용될 수 있다. 이상에서, 본 발명의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명 되었다고 해서, 본 발명의 기술적 사상이 반드시 이러한 실시예에 한정되는 것은 아니다. 즉, 본 발명의 목적 범위 안에서라면, 그 모든 구성요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 도면에서 동작들이 특정한 순서로 도시되어 있지만, 반드시 동작들이 도시된 특정한 순서로 또는 순차적 순서로 실행되어야만 하거나 또는 모든 도시 된 동작들이 실행되어야만 원하는 결과를 얻을 수 있는 것으로 이해되어서 는 안 된다. 특정 상황에서는, 멀티태스킹 및 병렬 처리가 유리할 수도 있다. 더욱이, 위에 설명한 실시예들에 서 다양한 구성들의 분리는 그러한 분리가 반드시 필요한 것으로 이해되어서는 안 되고, 설명된 프로그램 컴포 넌트들 및 시스템들은 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패키 지 될 수 있음을 이해하여야 한다."}
{"patent_id": "10-2020-0060251", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 본 발명이 다른 구체적인 형태로도 실시될 수 있다는 것을 이해할 수 있다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로 이해해야만 한다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명에 의해 정의되는 기술적 사상의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2020-0060251", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 특징 추천 장치의 구성을 도시한 블록도이다. 도 2는 도 1을 참조하여 설명한 특징 추천 장치의 하드웨어 구성을 도시한 구성도이다. 도 3은 본 발명의 일 실시예에 따른 특징 추천 방법을 설명하기 위한 순서도이다. 도 4는 본 발명의 다른 실시예에 따른 특징 추천 방법을 설명하기 위한 순서도이다. 도 5는 도 3을 참조하여 설명한 특징 추천 방법에 있어 중복성 페널티를 적용하는 예이다. 도 6은 도 4을 참조하여 설명한 특징 추천 방법에 있어 관련성 페널티를 적용하는 예이다. 도 7은 본 발명의 몇몇 실시예에 따른 결측치가 존재하는 데이터의 예를 도시한 것이다. 도 8은 본 발명의 몇몇 실시예에 따른 결측치가 있는 데이터에 대한 특징 추천 결과를 도시한 예이다. 도 9 및 도 10은 본 발명의 몇몇 실시예에 따른 특징 추천 결과를 검증하는 예이다."}
