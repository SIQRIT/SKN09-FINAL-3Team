{"patent_id": "10-2023-7019242", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0111208", "출원번호": "10-2023-7019242", "발명의 명칭": "출력들 사이에 금속 차폐가 있는 커패시터 기반 시냅스 네트워크 구조", "출원인": "인터내셔널 비지네스 머신즈 코포레이션", "발명자": "장, 첸"}}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 디바이스에 있어서, 상기 디바이스는:제1 복수의 시냅스 네트워크 커패시터들(synapse network capacitors) - 상기 제1 복수의 시냅스 네트워크 커패시터들의 시냅스 네트워크 캐패시터들은 제1 출력 단자(a first output terminal)를 공유함 -;제2 복수의 시냅스 네트워크 커패시터들 - 상기 제2 복수의 시냅스 네트워크 커패시터들의 시냅스 네트워크 캐패시터들은 제2 출력 단자를 공유함 -; 및상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치된 금속 차폐(a metal shielding)를 포함하는신경망 디바이스."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치된 금속 차폐는 접지 단자에 연결되는신경망 디바이스."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 금속 차폐는 상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치되어 상기 금속 차폐가 상기 제2 출력 단자로부터 상기 제1 출력 단자를 용량적으로 분리시키는(capacitively decouples)신경망 디바이스."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제1 복수의 시냅스 네트워크 커패시터들에서 상기 시냅스 네트워크 커패시터들 각각은 상기 제1 복수의 시냅스 네트워크 커패시터들의 다른 시냅스 네트워크 커패시터들 각각의 입력 단자로부터 독립된입력 단자를 포함하는신경망 디바이스."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 제2 복수의 시냅스 네트워크 커패시터들에서 상기 시냅스 네트워크 커패시터들 각각은 상기 제2 복수의 시냅스 네트워크 커패시터들의 다른 시냅스 네트워크 커패시터들 각각의 입력 단자로부터 독립된입력 단자를 포함하는신경망 디바이스."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 각각의 시냅스 네트워크 커패시터의 입력 단자는 상기 신경망 디바이스의 주어진 워드 라인을 통해 주소를 지정할 수 있고(addressable), 상기 제1 및 제2 복수의 시냅스 네트워크 커패시터들 각각은상기 신경망 디바이스의 주어진 비트 라인을 통해 추가로 주소를 지정할 수 있는신경망 디바이스."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 신경망 디바이스는 인공 지능 시스템의 일부(part)인신경망 디바이스. 공개특허 10-2023-0111208-3-청구항 8 방법에 있어서, 상기 방법은:제1 복수의 시냅스 네트워크 커패시터들을 형성하는 단계 - 상기 제1 복수의 시냅스 네트워크 커패시터들의 시냅스 네트워크 캐패시터들은 제1 출력 단자(a first output terminal)를 공유함 -;제2 복수의 시냅스 네트워크 커패시터를 형성하는 단계 - - 상기 제2 복수의 시냅스 네트워크 커패시터들의 시냅스 네트워크 캐패시터들은 제2 출력 단자를 공유함 -; 및상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치된 금속 차폐(a metal shielding)를 형성하는 단계를 포함하는방법."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 제1 출력 단자와 상기 제2 출력 단자 사이에 형성된 금속 차폐를 접지 단자에 연결하는단계를 더 포함하는방법."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 제1 출력 단자와 상기 제2 출력 단자 사이에 형성된 상기 금속 차폐를 상기 제2 출력 단자로부터 상기 제1 출력 단자를 용량적으로 분리시키는 방법."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 8항에 있어서, 상기 제1 복수의 시냅스 네트워크 커패시터들에서 상기 시냅스 네트워크 커패시터들 각각은상기 제1 복수의 시냅스 네트워크 커패시터들의 다른 시냅스 네트워크 커패시터들 각각의 입력 단자로부터 독립된 입력 단자를 포함하는방법."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제2 복수의 시냅스 네트워크 커패시터들에서 상기 시냅스 네트워크 커패시터들 각각은상기 제2 복수의 시냅스 네트워크 커패시터들의 다른 시냅스 네트워크 커패시터들 각각의 입력 단자로부터 독립된 입력 단자를 포함하는방법."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 방법은 상기 각각의 시냅스 네트워크 커패시터의 입력 단자는 상기 신경망 디바이스의 주어진 워드 라인을 통해 주소를 지정하는 단계 및 상기 제1 및 제2 복수의 시냅스 네트워크 커패시터들 각각은상기 신경망 디바이스의 주어진 비트 라인을 통해 추가로 주소를 지정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 신경망 디바이스는 인공 지능 시스템의 일부인방법."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "인공 지능 시스템에 있어서, 상기 시스템은:공개특허 10-2023-0111208-4-시냅스 엘리멘트들에 의해 작동 가능하게 결합된 뉴런 노드들(neuron nodes)의 다수의 층들을 가지는 신경망 구조를 포함하는 적어도 하나의 처리 디바이스를 포함하고, 상기 시냅스 엘리멘트들은 적어도 2개의 복수의 시냅스 엘리멘트들로 구성되며, 상기 적어도 2개의 복수의 시냅스 엘리멘트들은:제1 복수의 시냅스 엘리멘트들 - 상기 제1 복수의 시냅스 엘리멘트들의 시냅스 엘리멘트들은 제1 출력 단자를공유함 -;제2 복수의 시냅스 엘리멘트들 - 상기 제2 복수의 시냅스 엘리멘트들의 시냅스 엘리멘트들은 제2 출력 단자를공유함 -; 및상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치된 금속 차폐를 포함하는 시스템."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치된 금속 차폐는 접지 단자에 연결되는인공 지능 시스템."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 금속 차폐는 상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치되어 상기 제2 출력단자로부터 상기 제1 출력 단자를 분리시키는인공 지능 시스템."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 제1 복수의 시냅스 엘리멘트들에서 시냅스 엘리멘트들 각각은 상기 제1 복수의 시냅스엘리멘트들의 다른 시냅스 엘리멘트들 각각의 입력 단자로부터 독립된 입력 단자를 포함하는인공 지능 시스템."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 제2 복수의 시냅스 엘리멘트들에서 시냅스 엘리멘트들 각각은 상기 제2 복수의 시냅스엘리멘트들의 다른 시냅스 엘리멘트들 각각의 입력 단자로부터 독립된 입력 단자를 포함하는 인공 지능 시스템."}
{"patent_id": "10-2023-7019242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 상기 각각의 시냅스 엘리멘트의 입력 단자는 상기 적어도 하나의 처리 디바이스의 주어진 워드 라인을 통해 주소를 지정할 수 있고 상기 제1 및 제2 복수의 시냅스 엘리멘트들 각각은 상기 적어도 하나의처리 디바이스의 주어진 비트 라인을 통해 추가로 주소를 부여할 수 있는인공 지능 시스템."}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "신경망 디바이스는 제1 복수의 시냅스 네트워크 커패시터들을 포함하고, 상기 제1 복수의 시냅스 네트워크 커패 시터들의 시냅스 네트워크 커패시터들은 제1 출력 단자를 공유한다. 상기 신경망 디바이스는 제2 복수의 시냅스 네트워크 커패시터들을 더 포함하고, 상기 제2 복수의 시냅스 네트워크 커패시터들의 시냅스 네트워크 커패시터 들은 제2 출력 단자를 공유한다. 또한, 상기 신경망 디바이스는 상기 제1 출력 단자와 상기 제2 출력 단자 사이 에 배치된 금속 차폐를 포함한다. 상기 신경망 디바이스는 인공지능 시스템의 일부로 사용될 수 있다."}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "심층 신경망(a deep neural network, DNN)은 다수의 계층들(예: 입력 계층, 복수의 숨겨진 또는 중간 계층들, 및 출력 계층)으로 구성된 구조인 인공 신경망(an artificial neural network, ANN)의 한 예로서, 여 기서 계층들은 서로 다른 구성들에서 연결의 상대적 중요성(\"시냅스(synapses)\"를 나타냄)에 기반하여 가중된 커넥터들(connectors)에 의해 작동 가능하게 결합된 네트워크 노드들(network nodes)(\"뉴런들(neurons)\"을 나 타냄)로 구성된다. DNN은 많은 숨겨진 또는 중간 계층들(예: 대략 수십, 수백 또는 수천, 따라서 \"심층(deep)\" 이라는 용어가 사용됨)을 가지며 생물학적 인간(또는 동물) 두뇌의 의사 결정 기능을 모방하도록 설계되었다."}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이와 같이, DNN은 하나 또는 그 이상의 뉴로모픽(neuromorphic) 또는 신경망 디바이스에서 구현된 머신 또는 딥 러닝 알고리즘(machine or deep learning algorithms)을 포함하는 인공 지능 시스템을 포함하지만 이 에 제한되지 않는 많은 기술 영역에서 구현되었다. 신경망 기반 인공 지능 시스템들에 대한 애플리케이션들의 예들로는 이미지 또는 객체 인식이 포함되지만 이에 제한되지 않는다. 이미지 또는 객체 인식에서 콘볼루션 신 경망(a convolutional neural network, CNN)이라고 불리는 DNN의 유형이 사용된다(예: CNN은 하나 또는 그 이 상의 이미지 분류들을 생성하기 위해 수학적 콘볼루션 연산들을 수행한다)."}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "DNN(CNN 또는 모든 다른 형태의 ANN)을 구현하는 데 사용되는 기본 컴퓨팅 하드웨어에는 중앙 처리 장치 (a central processing unit, CPU), 그래픽 처리 장치(a graphics processing unit, GPU) 또는 표준 금속산화 물 반도체(complementary metal oxide semiconductor, CMOS) 논리를 기반으로 하는 주문형 집적회로(an application-specific integrated circuit, ASIC)가 포함될 수 있지만, 이에 제한되지 않는다. 저항-기반(예: 멤리스터들(memristors)) 네트워크들은 일반적으로 DNN의 시냅스들을 구현하는 데 사용되었다."}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예들은 출력들 사이에 금속 차폐가 있는 커패시터 기반 시냅스 네트워크 구조(a capacitor-based synapse network structure with metal shielding between outputs)를 제공한다. 일 예시적 실시예에서, 신경망 디바이스가 제공되고, 상기 디바이스는 제1 복수의 시냅스 네트워크 커패시터들 (synapse network capacitors)을 포함하고, 상기 제1 복수의 시냅스 네트워크 커패시터들의 시냅스 네트워크 캐 패시터들은 제1 출력 단자(a first output terminal)를 공유한다. 상기 디바이스는 제2 복수의 시냅스 네트워크 커패시터들을 더 포함하고, 상기 제2 복수의 시냅스 네트워크 커패시터들의 시냅스 네트워크 캐패시터들은 제2 출력 단자를 공유한다. 또한, 상기 디바이스는 상기 제1 출력 단자와 상기 제2 출력 단자 사이에 배치된 금속 차폐(a metal shielding)를 더 포함한다. 추가적인 예시적 실시예들은 금속 차폐된 출력들을 갖는 커패시터 기반 시냅스 네트워크가 있는 신경망 디바이스를 제조하는 방법 및 금속 차폐되는 출력들을 갖는 커패시터 기반 시냅스 네트워크를 갖는 신경망 디바 이스로 구성된 인공 지능 시스템의 형태로 각각 제공된다. 본 명세서에 기술된 실시예들의 이러한 및 다른 특징들과 장점들은 첨부된 도면들과 다음의 상세한 설명 으로부터 더욱 명백해질 것이다."}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "배경 섹션에서 위에서 언급한 바와 같이, DNN(CNN 또는 모든 ANN)을 구현하는데 사용되는 기본 컴퓨팅 하드웨어는 CPU, GPU, ASIC 등을 포함할 수 있지만 이에 제한되지 않는다. 예를 들어, 저항성 랜덤 액세스 메모 리(resistive random-access memory, ReRAM) 또는 상 변화 메모리(phase change memory, PCM) 디바이스들(크로 스-포인트 구조들(cross-point structures)이라고 함)은, 저항/전도가 시냅스를 나타내는데 사용되는, DNN과 관 련된 계산들을 수행하는 데 사용되었다. ReRAM은 데이터를 저장하기 위해 멤리스터(a memristor)라고 하는 유전 체 고체 재료의 전기 저항 변화를 사용하는 비휘발성 램의 한 유형(a type of non-volatile RAM)이다. PCM은 상 변화 재료(a phase change material)의 고전도 결정 상과 저전도 비정질 상 사이의 전기 저항 대비를 사용하여 데이터를 저장하는 비휘발성 램의 한 유형이다. DNN에서 시냅스를 구현하기 위한 상기의 저항-기반 접근법에 더하여 커패시터를 사용하여 시냅스를 나타 낼 수 있다는 것이 알려져 있다. 커패시터-기반 시냅스 네트워크(a capacitor-based synapse network)는 저항- 기반 시냅스 네트워크(a resistor-based synapse network)와 유사한 뉴런 연결 기능을 제공하지만 정적 전력 (static power)을 소비하지 않는다. 그러나, 커패시터-기반 시냅스가 있는 신경망의 한 가지 단점은 출력 노드 가 원하지 않는 결합 커패시턴스(unwanted coupling capacitance)를 통해 서로 상호 작용할 수 있다는 것이다. 기존의 커패시터-기반 시냅스 네트워크와 관련된 단점들과 예시적인 실시예들이 이러한 단점들과 다른 단점들을 어떻게 극복하는지를 더 설명하기 전에, 예시적인 실시예들이 구현될 수 있는 신경망 디바이스들의 세 트를 갖는 인공지능 시스템의 예시가 설명될 것이다. 특히, 도 1은 하나 또는 그 이상의 예시적인 실시예들이 구현될 수 있는 신경망 디바이스를 포함하 는 신경망 컴퓨팅 환경을 도시한다. 도시된 바와 같이, 신경망 디바이스는 신경망를 포함하고, 하나 또는 그 이상의 입력 신호들을 수신하고 하나 또는 그 이상의 출력 신호들을 생성한다. 단지 예로서, 이미지 또는 객체 인식 애플리케이션에서, 입력 신호(들)는 이미지를 포함할 수 있고, 신 경망 디바이스는 출력 신호(들)로서 하나 또는 그 이상의 이미지 분류 등을 생성하는 CNN을 구현한다. CNN은 시 냅스를 통해 연결된 뉴런의 컨볼루션 계층들(convolutional layers)을 사용하고, 이미지에서 특징을 추출하여 네트워크를 통해 처리한다. CNN의 마지막 계층은 입력 이미지와 관련된 계산된 분류를 제공하여 가중치 및 특징 탐지기(weights and feature detectors)로 훈련된 신경망(a trained neural network)을 생성한다. 그런 다음 훈련된 신경망은 타겟 이미지를 기반으로 실시간 이미지 인식에 사용된다. 따라서, 도 1에서, 신경망 디바이스는 신경망을 훈련시킨 다음, 이미지 또는 객체 인식을 위 해 훈련된 신경망을 사용하도록 구성된다. 하나의 간단한 예로서, CNN은 자동차의 이미지를 사용하여 훈련 될 수 있으며, 그런 다음 후속 이미지는 훈련된 CNN에 적용되어 어떤 후속 이미지들에 자동차가 포함되어 있는 지 확인할 수 있다. 도 1에 도시된 것과 같은 신경망 디바이스를 사용하는 이미지 인식은 엔지니어링 (engineering), 보안 및 의학을 포함하지만 이에 제한되지 않는 광범위한 응용 분야에서 사용될 수 있다. 다수 의 신경망 디바이스는 인공지능 시스템을 형성하기 위해 함께 사용될 수 있다. 또한, 일부 실시예들에서,단일 신경망 디바이스는 다수의 신경망들을 포함할 수 있다. 또한, 다수의 신경망 디바이스들을 갖는 일부 실시예들에서, 하나 또는 그 이상의 신경망 디바이스들은 단일 신경망를 가질 수 있는 반 면, 하나 또는 그 이상의 다른 신경망 디바이스들는 다수의 신경망들을 가질 수 있다. 도 2는 하나 또는 그 이상의 예시적인 실시예들이 구현될 수 있는 신경망 디바이스의 개략적인 회 로도를 도시한다. 신경망 디바이스은 도 1에서 신경망를 갖는 신경망 디바이스의 예시적인 구현 이라는 것을 이해해야 한다. 예시적인 실시예들의 상세한 설명과 관련된 신경망 디바이스 및 신경의 일부가 도 2에 도시되어 있다는 것을 이해해야 한다. 따라서, 신경망 디바이스 및 신경망은 도 2에 명시적으로 도시되지 않은 하나 또는 그 이상의 다른 컴포넌트들(components) 및 엘리멘트들(elements)을 가질 수 있다. 도시된 바와 같이, 신경망 디바이스은 복수의 워드 라인들(a plurality of word lines) (WL1, WL2, WL3, WL4, …, WLN)과 복수의 비트 라인들 (BL1, BL2, BL3, …, BLP)을 포함한다. 복수의 워 드라인들과 복수의 비트라인들은 직접 연결되는 것이 아니라, 각각의 교차점(즉, 워드라인과 비트라 인이 물리적으로 가까워지지만 물리적으로 연결되지 않는 물리적 위치)에서 그들 사이에 연결되는 시냅스 엘리 멘트들을 갖는다. 시냅스 엘리멘트들은 도 2에서 시냅스 엘리멘트들(231, 232, 233, 234, …, 23Q)로 표현된다. 각각의 비트 라인은 또한 도시된 바와 같이 적분기(an integrator) 및 임계값 검출기(a threshold detector)가 연결되어 있다. 복수의 시냅스 엘리멘트들(231, 232, 233, 234, …, 23Q), 적분기 및 임계값 검출기는 집합적으로 신경망 부분(예: 신경망 디바이스의 신경망의 일부)을 포함한 다. 각각의 신경망 부분은 하나 또는 그 이상의 입력 신호들에 응답하여 정전 용량을 변경하도록 구성된다. 또한, 각각의 개별 시냅스 엘리멘트(231, 232, 233, 234, …, 23Q)는 대응하는 워드 라인을 통해 주 소를 지정할 수 있고, 각각의 신경망 부분을 형성하는 복수의 시냅스 엘리멘트들은 해당하는 비트 라인을 통해 주소를 지정할 수 있는 것으로 이해해야 한다. 예시적인 실시예들에서, 신경망 부분은 하나 또는 그 이상의 반도체 디바이스들을 생산하기 위해 반도체 제조 기술을 사용하여 구현된다. 여기서 \"워드 라인\" 및 \"비 트 라인\"과 같은 메모리 디바이스 유형의 용어가 예시적으로 사용되지만, 이러한 제어 신호 라인은 각각의 개별 시냅스 요소에 액세스하는데 더 일반적으로 사용되며 모든 뉴모로픽(neuromorphic) 실시예에서 반드시 워드 라 인 및 비트 라인으로 언급되지 않을 수 있음을 이해해야 한다. 도 3은 포지티브 시냅스 네트워크(a positive synapse network)를 구현하기 위해 사용되는 단일 출력 커패시터-기반 구조(a single output capacitor-based structure)의 개략적인 회로도를 도시한다. 특히, 단일 출력 커패시터-기반 구조는 도 2의 신경망 부분에서 복수의 시냅스 엘리멘트들(231, 232, 233, 234, …, 23Q)의 예시이다. 도시된 바와 같이, 단일 출력 커패시터-기반 구조는 복수의 커패시터들(C1, C2, C3, …, Cn)을 포함하며, 각각의 커패시터는 (C1, C2, C3,…, Cn)에 대해 각각 입력 전압 소스(an input voltage source)(V1, V2, V3, …, Vn)에 결합된 제1 단자 및 단일 공통 출력(Vo)에 결합된 제2 단자를 갖는다. 입력들(V1, V2, V3, …, Vn)은 도 2의 워드(액세스) 라인들(WL1, WL2, WL3, …, WLN)에 대응하고, 출력(Vo)는 도 2의 도 2의 비트(액세스) 라인들(BL1, BL2, BL3, … 또는 BLP) 중 하나에 대응한다. 각 커패시터(C1, C2, C3, …, Cn)는 각각의 입력 전압(V1, V2, V3, …, Vn)에 따라 정전 용량을 여러 레벨들 중 하나로 조정할 수 있도록 구성된다. 단순하게 하기 위해서, 적분기 및 임계값 검출기는 도 3에 도시되지 않았지만, 적분기 은 각 커패시터(C1, C2, C3, …, Cn)의 정전용량 레벨을 나타내는 신호를 수신하고, 그로부터 혼합 신호(an integrated signal)를 생성한다는 것을 이해해야 한다. 그런 다음 혼합 신호는 임계값 검출기에서 주어진 임계값과 비교된다. 특히, 총 정전 용량(Ctot)은 다음과 같이 정의된다:"}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그리고, 따라서, 전압 출력(Vo)은 다음과 같이 정의된다. 출력(Vo)는 모든 입력 전압들의 선형 조합(a linear combination)임이 명백하다. 각 입력 전압(Vi)에 대 한 시냅스 값은 Ci/Ctot이다. 출력(Vo)는 주어진 임계값과 비교되며, 비교 결과에 기초하여, 신경망 부분에 의해 결정이 생성된다. 도 4는 네거티브 시냅스 네트워크(a negative synapse network)를 구현하기 위해 사용되는 단일 출력 커패시터-기반 구조의 개략적인 회로도를 도시한다. 특히, 단일 출력 커패시터-기반 구조은 도 2의 신경망 부분에서 복수의 시냅스 엘리멘트(231, 232, 233, 234, …, 23Q)의 또 다른 예시이다. 도시된 바와 같이, 단일 출력 커패시터-기반 구조는 복수의 커패시터들(C11, C12, C21, C22, …, Cn1, Cn2)를 포함하며, 각 커패시터는 복수의 커패시터들(C11, C12, C21, C22, …, Cn1, Cn2) 각각에 대한 입력 전압 소스(V1, -V1, V2, -V2, …, Vn, -Vn)에 결합된 제1 단지 및 단일 공통 출력(Vo)에 결합된 제2 단자를 갖는다. 각 커패시터(C11, C12, C21, C22, …, Cn1, Cn2)는 그것의 정전 용량이 각각의 입력 전압(V1, -V1, V2, -V2, …, Vn, -Vn)에 기초하여 여러 레벨 들 중 하나로 조정할 수 있도록 구성된다. 도면을 단순화하기 위해, 적분기 및 임계값 검출기는 도 4 에 도시되지 않았지만, 적분기는 각 커패시터(C11, C12, C21, C22, …, Cn1, Cn2)의 정전 용량 레벨을 나타내 는 신호를 수신하여 그에 따라 통합 신호(an integrated signal)를 생성한다는 것을 이해해야 한다. 상기 통합 신호는 임계값 검출기에서 주어진 임계값과 비교된다. 특히, 위의 방정식들 및 과 유사하게 정의된 다: 총 정전 용량은 다음과 같다."}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이고, 따라서, Vo는 다음과 같다:"}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "Ci1 < Ci2인 경우, 시냅스는 네거티브로 간주된다. 다시, (Vo)는 주어진 임계값과 비교되고, 비교 결과에 기반하여 신경망 부분에 의해 결정이 생성된다. 도 5는 시냅스 네트워크를 구현하는데 사용되는 다수의 출력 커패시터-기반 구조(a multiple output capacitor-based structure)에서 커플링 커패시턴스 문제(a coupling capacitance issue)의 개략적인 회 로도를 도시한다. 도시된 바와 같이, 다수의 출력 커패시터-기반 구조은 제1 복수의 커패시터들(C11, C21, C31, …, Cn1)과 제2 복수의 커패시터들(C12, C22, C32, …, Cn2)을 포함한다. 제1 복수의 커패시터들(C11, C21, C31, …, Cn1)의 각 커패시터는 각각 입력 전압 소스(V1, V2, V3, …, Vn)에 결합된 제1 단자 및 단일 공통 출력(Vo1)에 결합된 제2 단자를 갖는다. 제2 복수의 커패시터들(C12, C22, C32, …, Cn2)의 각각의 커패시터는 각각 입력 전압 소스(V1, V2, V3, …, Vn)에 결합된 제1 단자 및 단일 공통 출력(Vo2)에 결합된 제2 단자를 갖는다. 도 5의 2개의 복수의 커패시터들 각각은 도 3에 도시된 복수의 커패시터들과 동일하지만, 각각은 대안적으로 도 4에 도시된복수의 커패시터들과 동일하게 구성되거나, 일부 다른 구성일 수 있다. 요점은 전기장으로 인한 기생 정전 용량 결합 효과로 인해 다른 신호에 근접한 한 신호가 다른 신호에서 노이즈의 형태로 간섭을 일으킨다는 것이다. 따 라서, 도 5에 도시된 바와 같이, 출력(Vo1)은 출력(Vo2)를 간섭할 수 있으며, 그리고 역으로 마찬가지이다. 두 출력 사이의 기생 정전 용량 결합 효과는 결합 정전 용량 (Cx)로 표시된다. 결합 정전 용량 (Cx)의 존재로 인해 단일 공통 출력 (Vo1)과 (Vo2)는 서로 영향을 미치기 때문에 위의 방정식 또는 의 간단한 공식으로 정의할 수 없다. 단일 공통 출력(Vo1)과 (Vo2) 간의 이러한 원치 않는 결합 정전 용량은 통합(적분기) 및 임계값 검출(임계값 검출기) 단계에서 오류를 유발하여 전체 인공지능 알고리즘에서 잘못된 결정을 초래할 수 있 다는 점에서 신경망에 문제를 제기한다. 예시적인 실시예들은 출력들 사이에 금속 차폐(metal shielding)가 있는 구조를 제공함으로써 커패시터- 기반 시냅스 네트워크와 관련된 상기 및 다른 단점들을 극복한다. 도 6은 예시적인 실시예에 따른 시냅스 네트워크를 구현하기 위해 사용되는 출력들 사이에 금속 차폐가 있는 다수의 출력 커패시터-기반 구조의 아이소메트릭 구조 다이어그램(an isometric structural diagram)을 도시한다. 보다 구체적으로, 도시된 바와 같이, 다수의 출력 커패시터-기반 구조은 3개의 복수 의 커패시터들(602-1, 602-2 및 602-3)을 포함하고, 복수의 커패시터들 각각은 3개의 커패시터들을 포함하며, 각 커패시터는 으로 참조된다. 각 커패시터(단순화를 위해 도면의 상단 우측 코너에서의 커패시터에 의해 표현됨)는 제1 단자 및 제2 단자를 포함하며, 유전체은 두2개의 단자(612 및 614) 사이에 배치된다. 각 커패시터의 제1단자는 각각 입력 전압(V1, V2또는 V3)에 동작 가능하게 결합된다. 각 커 패시터의 제2단자는 출력 전압, 이 경우 (Vo3)에 동작 가능하게 결합된다(즉, 도시된 바와 같이, 동일 복수의 커패시터에서의 커패시터들은 동일 출력(Vo1, Vo2또는 Vo3)에 동작 가능하게 결합된다). 유전체는 이 산화하프늄(hafnium dioxide, HfO2), 이산화지르코늄(zirconium dioxide, ZrO2) 등뿐만 아니라 이들의 조합과 같은 고유전율 재료(a high-k material)이다. 또한, 각각의 복수의 커패시터들은 이와 관련된 금속 차폐를 갖는다. 예시적인 실시예들에서, 금속 차폐는 티타늄 질화물(titanium nitride, TiN), 텅스텐(tungsten, W), 구리(copper, Cu) 등뿐만 아 니라 이들의 조합과 같은 재료로 구성되지만 이에 제한되지 않는다. 예시적인 실시예들에서, 금속 차폐의 치수는 커패시터의 치수 스케일링에 따라 수 나노미터에서 수백 나노미터 범위일 수 있다. 도시된 바와 같이, 금속 차폐는 도시된 바와 같이 복수의 커패시터들 각각 사이에 배치된다. 이러한 방식으로 배치된 금 속 차폐는 인접한 출력으로부터 주어진 출력에 대한 간섭을 방지하는데, 예를 들어 출력들(Vo1)과 (Vo2)가 서로 용량적으로 분리되고, 출력들 (Vo2)와 (Vo3)도 서로 용량적으로 분리된다. 금속 차폐는 도 6에 도시된 예시적인 실시예에서 접지된다. 그러나, 금속 차폐는 총 정전 용량(Ctot)에 추가되며, 이에 관해서는 도 7 의 맥락에서 후술한다. 도 7은 예시적인 실시예에 따라 시냅스 네트워크를 구현하는데 사용되는 출력들 사이에 금속 차폐가 있 는 다수의 출력 커패시터-기반 구조의 개략적인 회로도를 도시한다. 다수의 출력 커패시터-기반 구조(70 0)는 도 5의 다수의 출력 커패시터-기반 구조과 유사하지만, 여기서 금속 차폐는 출력(Vo1)은 별도의 차폐 커패시턴스(Cx1)을 갖고 한편 출력(Vo2)은 별도의 차폐 커패시턴스(Cx2)를 갖도록 복수의 커패시터들(702-1 및 702-2) 사이에 도 6에 도시된 바와 같이 배치된다고 가정됨을 이해해야 한다. 따라서, 복수의 커패시터들(702-1)에 대한 예시로서, 총 정전용량(Ctot)는 이제 다음과 같이 정의된다:"}
{"patent_id": "10-2023-7019242", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "그리고, 따라서, 출력(Vo1)은 다음과 같다: 복수의 커패시터들(702-2)에 대한 총 정전 용량(Ctot) 및 출력(Vo2)은 각각 방정식와 과 동일 방식 으로 변화하지만, 정정 용량(Cx1) 대신 정정 용량(Cx2)를 추가한다. 도 8a는 예시적인 실시예에 따라 시냅스 네트워크를 구현하는데 사용되는 출력들 사이에 금속 차폐가 있 는 다수의 출력 커패시터-기반 구조를 제조하기 위한 방법의 흐름도를 도시한다. 방법은, 예를 들어, 도 1의 와 같은 신경망 디바이스를 제조하는 반도체 제조 공정의 일부로서 수행될 수 있음을 이해해야 한 다. 그러나, 대안적인 실시예들에서, 방법은 방법론의 단계들을 수행하도록 구성된 다른 제조 기술들에 의 해 수행될 수 있다. 단계는 적어도 2개의 복수의 커패시터들을 형성하고, 동일 복수의 커패시터들은 여러 개의 별도의 입력들(separate inputs)(예: 도 6 또는 도 7 참조)을 가지면서 하나의 공통 출력(a common output)을 공유한 다. 적어도 2개의 복수의 커패시터들의 반도체 제조는 다양한 방식으로 수행될 수 있다는 것이 이해해야 한다. 단지 예로서, 2019년 12월 10일에 발표된 미국 특허 제10,505,108호 \"멤캐패시터, 신경 디바이스, 및 신경망 디 바이스 (Memcapacitor, Neuro Device, and Neural Network Device)\"에 기술된 커패시터 제조 기술은 단계(80 2)에서 적어도 2개의 복수의 커패시터들을 제조하도록 개조될 수 있다. 단계는 본 명세서에 기술된 바와 같이 상기 적어도 2개의 복수의 커패시터들의 각 쌍의 출력들 사 이에 금속 차폐 계층을 형성한다. 적어도 하나의 반도체 제조 기반 실시예에서, 다수의 출력 커패시터-기반 구조(도 6의)를 참조하여, 도 8b는 복수의 커패시터들의 각 쌍의 출력들 사이에 금속 차폐 계층을 형성하기 위해 수행된 방법을 도시한다. 먼저, 단계에서, 커패시터 출력 단자 금속 라인들(capacitor output terminal metal lines)(Vo1, Vo2또는 Vo3)을 형성한다. 다음으로, 단계에서, 하이-k(고유전율) 유전체 재료가 형성되고 패턴화 (patterned)된다. 단계에서, 제1 층간 유전체(interlayer dielectric, ILD) 층이 형성되고, 화학적 기계 적 평탄화(chemical mechanical planarization, CMP) 동작이 적용된다. 다음으로, 단계에서, 트렌치들 (trenches)은 상기 제1 ILD층에 형성되고 금속은 차폐 금속 라인을 형성하기 위해 증착된다. 단계에서 제2 ILD 층이 형성되고 CMP가 적용된다. 단계에서, 비아 구조들이 하이-k 유전체 재료에 도달하도록 에칭 (etched)되고, 상기 비아 구조들은 금속화된다. 그 다음, 단계에서, 커패시터 입력 금속 라인들(the capacitor input metal lines)(V1, V2 또는 V3)이 형성된다. 도 8b의 제조 공정은 단지 하나의 예시일 뿐이며, 대안적인 실시예들은 출력들 사이에 금속 차폐가 있는 다수의 출력 커패시터-기반 구조를 형성하기 위해 추가적 인 또는 대안적인 제조 단계들 및 기술들을 고려하고, 그리고 서로 다른 단계들의 순서들에서도 고려한다. 도 8c는 예시적인 실시예에 따라 금속 차폐 출력이 있는 커패시터-기반 시냅스 네트워크를 가지는 하나 또는 그 이상의 신경망 디바이스가 있는 인공 지능 시스템의 블록도를 도시한다. 하나 또는 그 이상의 예 시적인 실시예들에서, 금속 차폐 출력을 갖는 커패시터-기반 시냅스 네트워크는 도 8a의 방법 및/또는 도 8b의 방법에 따라 제조될 수 있다. 도시된 바와 같이, 인공지능 시스템은 금속 차폐 출력을 갖는 커패시터-기반 시냅스 네트워크(82 4)를 갖는 하나 또는 그 이상의 신경망 디바이스들을 포함한다. 하나의 예시적인 실시예에서, 인공지능 시 스템의 금속 차폐 출력을 갖는 커패시터-기반 시냅스 네트워크를 갖는 하나 또는 그 이상의 신경망 디바이스들은 하나 또는 그 이상의 주문형 집적회로들(ASICs)에 의해 구현된다. ASIC들은 실행 가능한 프 로그램 코드(예: 명령 코드, 컴퓨터 프로그램 코드 등)로 프로그래밍되거나 특정 목적에 맞게 구성된 논리(예: 회로, 프로세서, 메모리 등)를 포함하는 특정 목적을 위해 맞춤화된 집적 회로(integrated circuit, IC) 칩들 또는 디바이스들이다. 이 예시적인 경우에서, 특정 목적은 인공지능 시스템(예: 머신 러닝 알고리즘(machinelearning algorithm))의 구현 및 실행이며, 보다 구체적으로는 신경망의 일부로 사용되는 시냅스 네트워크의 구 현이다. ASIC는 또한 시스템-온-칩(a system-on-chip, SoC)으로도 간주된다. 인공지능 시스템 및 그 일부는 하나 또는 그 이상의 멀티-코어 중앙 처리 장치들(multi-core central processing units, CPUs), 하나 또는 그 이상의 그래픽 처리 장치들(graphics processing units, GPUs) 및 하나 또는 그 이상의 필드 프로그램 가능 게이트 어레이들(field programmable gate arrays, FPGAs) 을 포함하는 기술과 같은 대체 회로/프로세서-기반 기술(alternative circuitry/processor-based technology) 로 실현될 수 있다는 것을 추가로 이해해야 한다. 일부 실시예들에서, 인공지능 시스템은 둘 또는 그 이상 의 회로/프로세서-기반 기술들(circuitry/processor-based technologies)(예: ASIC, CPU, GPU, FPGA 등)의 조 합으로 구현될 수 있다. 도 1 내지 도 8c에 도시된 기술들은, 또한 본 명세서에 기술된 바와 같이, 시스템을 제공하는 것을 포함 할 수 있으며, 여기서 시스템은 별개의 소프트웨어 모듈들(software modules)을 포함하고, 각각의 별개의 소프 트웨어 모듈은 구체적인 컴퓨터 판독 가능한 기록용 저장 매체에 구현된다. 예를 들어, 모든 모듈(또는 그 서브 세트(subset))은 동일한 매체에 있거나 각각 다른 매체에 있을 수 있다. 모듈은 도면 및/또는 여기에 설명된 컴 포넌트들 중 일부 또는 전부를 포함할 수 있다. 본 발명의 실시예에서, 상기 모듈들은, 예를 들어, 하드웨어 프 로세서 상에서 실행될 수 있다. 그런 다음 방법 단계는 전술한 바와 같이 하드웨어 프로세서에서 실행되는 시스 템의 별개의 소프트웨어 모듈을 사용하여 수행될 수 있다. 또한, 컴퓨터 프로그램 제품은 상기 별개의 소프트웨 어 모듈들을 갖는 시스템의 제공을 포함하여 본 명세서에 기술된 적어도 하나의 방법 단계를 수행하기 위해 실 행되도록 조정된 코드가 있는 구체적인 컴퓨터 판독 가능한 기록용 저장 매체를 포함할 수 있다. 추가로, 도 1 내지 도 8c에 도시된 기술들은, 데이터 처리 시스템에서 컴퓨터 판독 가능한 저장 매체에 저장된 컴퓨터 사용 가능한 프로그램 코드를 포함할 수 있는 컴퓨터 프로그램 제품을 통해 구현될 수 있으며, 상기 컴퓨터 사용 가능한 프로그램 코드는 원격 데이터 처리 시스템으로부터 네트워크를 통해 다운로드되었다. 또한, 본 발명의 실시예에서, 상기 컴퓨터 프로그램 제품은 서버 데이터 처리 시스템에서 컴퓨터 판독 가능한 저장 매체에 저장된 컴퓨터 사용 가능한 프로그램 코드를 포함할 수 있으며, 상기 컴퓨터 사용 가능한 프로그램 코드는 상기 원격 시스템과 함께 컴퓨터 판독 가능한 저장 매체에서 사용하기 위해 네트워크를 통해 원격 데이 터 처리 시스템으로 다운로드된다. 본 발명의 실시예 또는 그 엘리멘트들은 메모리 및 상기 메모리에 결합되어 예시적인 방법 단계들을 수 행하도록 구성된 적어도 하나의 프로세서를 포함하는 장치의 형태로 구현될 수 있다. 추가적으로, 본 발명의 실시예는 컴퓨터 또는 워크스테이션(workstation)에서 실행되는 소프트웨어를 사 용할 수 있다. 도 9를 참조하면, 그러한 구현은, 예를 들어, 프로세서, 메모리 및 예를 들어 디스플 레이(a display)과 키보드에 의해 형성된 입출력 인터페이스(an input/output interface)를 사용할 수 있다. 본 명세서에서 사용되는 \"프로세서\"라는 용어는, 예를 들어 멀티-코어 CPU, GPU, FPGA 및/또는 하나 또는 그 이상의 ASICs와 같은 다른 형태의 처리 회로를 포함하는 것과 같은 모든 처리 장치들을 포함하도록 의 도된다. 또한 \"프로세서\"라는 용어는 둘 이상의 개별 프로세서를 의미할 수 있다. \"메모리\"라는 용어는, 예를 들어RAM(랜덤 액세스 메모리(random access memory)), ROM(읽기 전용 기억장치(read only memory)), 고정 기억 장치(a fixed memory device)(예: 하드 드라이브(hard drive)), 이동식 기억 장치(a removable memory device)(예: 디스켓(diskette)), 플래시 메모리(a flash memory) 등과 같은 프로세서(예: CPU, GPU, FPGA, ASIC 등)와 관련된 메모리를 포함하도록 의도된다. 덧붙여, 본 명세서에서 사용되는 \"입출력 인터페이스\"라는 문구는, 예를 들어, 처리 장치에 데이터를 입력하기 위한 메커니즘(a mechanism)(예: 마우스)과 처리 장치와 관 련된 결과를 제공하기 위한 메커니즘(예: 프린터)을 포함하도록 의도되었다. 프로세서, 메모리 및 디 스플레이과 키보드과 같은 입출력 인터페이스는, 예를 들어, 데이터 처리 장치의 일부로서 버스 을 통해 상호 연결될 수 있다. 예를 들어 버스을 통한 적절한 상호 연결은 또한 컴퓨터 네트워크와 인터페이스하기 위해 제공될 수 있는 네트워크 카드와 같은 네트워크 인터페이스와 미디어와 인터페 이스하기 위해 제공될 수 있는 디스켓 또는 CD-ROM 드라이브와 같은 미디어 인터페이스에도 제공될 수 있 다. 따라서, 본 발명의 실시예들의 방법들을 수행하기 위한 명령들 또는 코드들을 포함하는 컴퓨터 소프트웨 어는, 본 명세서에 기술된 바와 같이, 연관된 기억 장치들(예: ROM, 고정 또는 이동식 메모리)에 저장될 수 있 으며, 사용할 준비가 되면, 부분적으로 또는 전체적으로(예: RAM으로) 로딩되고 CPU에 의해 구현된다. 이러한 소프트웨어에는 펌웨어(firmware), 상주 소프트웨어(resident software), 마이크로코드(microcode) 등이 포함될 수 있지만 이에 국한되지 않는다. 프로그램 코드를 저장 및/또는 실행하기에 적합한 데이터 처리 시스템은 시스템 버스을 통해 메모 리 엘리멘트들에 직접 또는 간접적으로 연결된 적어도 하나의 프로세서를 포함할 것이다. 상기 메모 리 엘리멘트들은 프로그램 코드의 실제 구현 중에 사용되는 로컬 메모리(local memory), 대용량 저장 장치(bulk storage) 및 구현 중에 대용량 저장 장치에서 코드를 검색해야 하는 횟수를 줄이기 위해 적어도 일부 프로그램 코드의 임시 저장소를 제공하는 캐시 메모리를 포함할 수 있다. 캐시 메모리(cache memories)를 포함할 수 있습 니다. 입력/출력 또는 I/O 장치들(키보드, 디스플레이, 포인팅 장치들(pointing devices) 등을 포 함하지만 이에 제한되지 않음)는 직접(예: 버스을 통해) 또는 중간 I/O 컨트롤러(intervening I/O controllers)(명확성을 위해 생략됨)를 통해 시스템에 연결될 수 있다. 네트워크 인터페이스(network interface)와 같은 네트워크 어댑터(network adapters)는 또한 개인 또는 공용 네트워크를 통해 데이터 처리 시스템이 다른 데이터 처리 시스템이나 원격 프린터 또는 저장 장치에 연결될 수 있도록 시스템에 연결될 수 있다. 모뎀(modems), 케이블 모뎀(cable modems) 및 이더넷 카드 (Ethernet cards)는 현재 사용 가능한 네트워크 어댑터의 유형들 중 일부에 불과하다. 특허 청구 범위를 포함하여 본 명세서에서 사용되는 \"서버\"는 서버 프로그램을 실행하는 물리적 데이터 처리 시스템(예: 도 9에 도시된 바와 같은 시스템)을 포함한다. 이러한 물리적 서버는 디스플레이 및 키보 드를 포함하거나 포함하지 않을 수 있음을 이해해야 한다. 본 발명은 통합의 모든 가능한 기술적 세부 수준에서 시스템, 방법 및/또는 컴퓨터 프로그램 제품일 수 있다. 컴퓨터 프로그램 제품은 프로세서가 본 발명의 실시예를 수행하도록 하기 위한 컴퓨터 판독 가능한 프로 그램 명령들을 포함하는 컴퓨터 판독 가능한 스토리지 매체를 포함할 수 있다. 컴퓨터 판독 가능한 스토리지 매체는 명령 실행 디바이스에 의해 사용하기 위한 명령을 보관 및 저장할 수 있는 유형의(tangible) 디바이스일 수 있다. 컴퓨터 판독 가능한 스토리지 매체는, 예를 들어, 전자 스토리 지 디바이스, 자기 스토리지 디바이스, 광 스토리지 디바이스, 전자기 스토리지 디바이스, 반도체 스토리지 디 바이스, 또는 전술한 임의의 적절한 조합일 수 있으나, 이에 한정되는 것은 아니다. 컴퓨터 판독 가능한 스토리 지 매체의 구체적인 예는 휴대용 컴퓨터 디스켓, 하드 디스크, 랜덤 액세스 메모리(RAM), 읽기 전용 메모리 (ROM), 소거 가능한 프로그램 가능 읽기 전용 메모리(EPROM 또는 플래시 메모리), 정적 랜덤 액세스 메모리 (SRAM), 휴대용 콤팩트 디스크 읽기 전용 메모리(CD-ROM), 디지털 다용도 디스크(DVD), 메모리 스틱(memory stick), 플로피 디스크, 펀치 카드 또는 명령이 기록된 그루브 내의 상승된 구조와 같은 기계적으로 인코딩된 디바이스, 및 전술한 모든 적절한 조합을 포함한다. 본 명세서에서 사용되는 컴퓨터 판독 가능한 스토리지 매체 는, 전파 또는 자유롭게 전파되는 다른 전자기파, 도파관 또는 다른 전송 매체를 통해 전파되는 전자기파(예를 들어, 광섬유 케이블을 통과하는 광 펄스) 또는 전선을 통해 전송되는 전기 신호와 같은 일시적인 신호 그 자체 로 해석되지 않는다. 본 명세서에 설명된 컴퓨터 판독 가능한 프로그램 명령들은 컴퓨터 판독 가능한 스토리지 매체로부터 각 각의 컴퓨팅/프로세싱 디바이스들로 다운로드 되거나, 네트워크, 예를 들어, 인터넷, 로컬 영역 네트워크, 광역 네트워크 및/또는 무선 네트워크를 통해 외부 컴퓨터 또는 외부 스토리지 디바이스로 다운로드될 수 있다. 네트 워크는 구리 전송 케이블, 광전송 섬유, 무선 전송, 라우터, 방화벽, 스위치, 게이트웨이 컴퓨터 및/또는 에지 서버들(edge servers)을 포함할 수 있다. 각 컴퓨팅/프로세싱 디바이스의 네트워크 어댑터 카드 또는 네트워크 인터페이스는 네트워크로부터 컴퓨터 판독 가능한 프로그램 명령을 수신하고, 각각의 컴퓨팅/프로세싱 디바이스 내의 컴퓨터 판독 가능한 스토리지 매체에 저장하기 위하여 컴퓨터 판독 가능한 프로그램 명령을 전달한다. 본 발명의 방법을 수행하기 위한 컴퓨터 판독 가능한 프로그램 명령은 어셈블러 명령, 명령-조합-아키텍 처(instruction-set-architecture : ISA) 명령, 머신 명령, 머신 종속 명령(machine dependent instructions), 마이크로코드, 펌웨어 명령, 조건 설정 데이터, 집적 회로용 구성 데이터, 또는 Smalltalk, C++ 등과 같은 객체 지향 프로그래밍 언어와 \"C\" 프로그래밍 언어 또는 유사한 프로그래밍 언어와 같은 절차적 프로그래밍 언어를 포함하여 하나 이상의 프로그래밍 언어의 조합으로 작성된 소스 코드 또는 객체 코드일 수 있다. 컴퓨터 판독 가능한 프로그램 명령들은 완전히 사용자의 컴퓨터에서, 부분적으로 사용자의 컴퓨터에서, 독립 실행형 소프트 웨어 패키지로, 부분적으로 사용자의 컴퓨터와 부분적으로 원격 컴퓨터에서, 또는 완전히 원격 컴퓨터나 서버에 서 실행될 수 있다. 후자의 시나리오에서, 원격 컴퓨터는 LAN(local area network) 또는 WAN(wide areanetwork)을 포함한 모든 유형의 네트워크를 통해 사용자의 컴퓨터에 연결될 수 있으며, 외부 컴퓨터(예를 들어, 인터넷 서비스 공급자를 이용한 인터넷)에 연결될 수 있다. 일부 실시예에서, 예를 들어, 프로그래머블 논리 회 로, 필드 프로그래머블 게이트 배열(FPGA) 또는 프로그래머블 논리 배열(PLA)을 포함하는 전자 회로는 본 발명 의 실시예를 수행하기 위해 전자 회로를 개인화할 목적으로 컴퓨터 판독 가능한 프로그램 명령들의 조건 정보를 이용함으로써 컴퓨터 판독 가능한 프로그램 명령들을 실행할 수 있다. 본 발명의 실시예들에 따른 방법, 장치(시스템) 및 컴퓨터 프로그램 제품의 흐름도들 및/또는 블록도들 을 참조하여 본 발명의 실시예들을 설명한다. 흐름도들 및/또는 블록도들의 각 블록, 및 흐름도 및/또는 블록도 들의 블록 조합은 컴퓨터 판독 가능한 프로그램 명령에 의해 구현될 수 있음을 이해해야 한다. 이들 컴퓨터 판독 가능한 프로그램 명령들은 컴퓨터의 프로세서, 또는 머신을 생산하는 다른 프로그램 가능한 데이터 처리 장치에 제공될 수 있으며, 컴퓨터의 프로세서 또는 다른 프로그램 가능한 데이터 처리 장치 를 통해 실행되는 명령은 흐름도 및/또는 블록도의 블록 또는 블록들에 지정된 기능/동작을 구현하기 위한 수단 을 생성한다. 이들 컴퓨터 판독 가능한 프로그램 명령들은 또한 컴퓨터, 프로그램 가능한 데이터 처리 장치 및/ 또는 다른 장치들이 특정한 방식으로 작동하도록 지시할 수 있는 컴퓨터 판독 가능한 스토리지 매체에 저장될 수 있으며, 명령들이 저장된 컴퓨터 판독 가능한 스토리지 매체는 흐름도 및/또는 블록도의 블록 또는 블록들에 지정된 기능/동작의 실시예를 구현하는 명령들을 포함하는 제조 물품을 포함한다. 컴퓨터 판독 가능한 프로그램 명령들은 또한 컴퓨터, 다른 프로그램 가능한 데이터 처리 장치 또는 다른 장치에 막대 되어 컴퓨터, 다른 프로그램 가능한 장치 또는 다른 장치상에서 수행되는 일련의 동작 단계들이 컴 퓨터에서 구현된 프로세스들을 생성하도록 할 수 있으며, 이로써 컴퓨터, 다른 프로그램 가능한 장치 또는 다른 디바이스에서 실행되는 명령은 흐름도 및/또는 블록도의 블록 또는 블록들에 지정된 기능들/동작들을 구현한다. 도면들에서 흐름도 및 블록도들은 본 발명의 다양한 실시예들에 따른 시스템, 방법 및 컴퓨터 프로그램 제품의 가능한 구현의 구조, 기능 및 동작을 도시하고 있다. 이와 관련하여, 흐름도 또는 블록도의 각 블록은 모듈, 벡터 또는 명령의 일부를 나타낼 수 있으며, 이는 지정된 논리 함수를 구현하기 위한 하나 이상의 실행 가능한 명령들을 포함한다. 일부 대체 구현에서는 블록에 표시된 기능이 도면에 표시된 순서대로 발생할 수 있 다. 예를 들어, 연속적으로 표시된 두 개의 블록은 실제로 한 단계로 수행될 수 있으며, 동시에, 실질적으로 동 시에, 부분적으로 또는 전체적으로 시간적으로 중첩되는 방식으로 실행되거나, 때때로 관련된 기능에 따라 역순 으로 블록들이 실행될 수 있다. 또한, 블록도 및/또는 흐름도의 각 블록, 및 블록도 및/또는 흐름도의 블록 조 합은 특정 기능을 수행하거나 특수 목적 하드웨어와 컴퓨터 명령의 조합을 수행하거나 작동하는 특수 목적 하드 웨어 기반 시스템에 의해 구현될 수 있다는 점에 유의해야 한다. 여기에 기술된 모든 방법들은 컴퓨터 판독 가능 저장 매체에 구현된 별개의 소프트웨어 모듈들을 포함하 는 시스템을 제공하는 추가 단계를 포함할 수 있고; 상기 모듈들은, 예를 들어 여기에 설명된 컴포넌트들 중 일 부 또는 전부를 포함할 수 있음에 주목해야한다. 상기 방법 단계들은, 전술한 바와 같이, 하드웨어 프로세서 에서 실행되는, 별개의 소프트웨어 모듈들 및/또는 상기 시스템의 서브모듈을 사용하여 수행될 수 있다. 또한, 컴퓨터 프로그램 제품은, 별개의 소프트웨어 모듈을 상기 시스템에 제공하는 것을 포함하여, 본 명세서에 기술된 적어도 하나의 방법 단계를 수행하도록 구현되게 구성된 코드를 갖는 컴퓨터 판독 가능 저장 매체를 포 함할 수 있다. 어느 경우든, 여기에 예시된 컴포넌트들은 하드웨어, 소프트웨어 또는 이들의 조합, 예를 들어 주문형 집적 회로(들)(ASICs), 기능 회로, 관련 메모리를 갖고, 적절하게 프로그래밍된 디지털 컴퓨터, 등의 다양한 형 태들로 구현될 수 있음을 이해해야 한다. 본 명세서에 제공된 본 발명의 기술적 사상들이 주어지면, 관련 기술 분야의 통상의 기술자는 본 발명의 컴포넌트들의 다른 구현을 고려할 수 있을 것이다. 본 발명은 클라우드 컴퓨팅에 대한 상세한 설명을 포함하지만, 여기에 인용된 기술적 사상의 구현은 클 라우드 컴퓨팅 환경에 제한되지 않는다는 것을 이해해야 한다. 오히려, 본 발명의 실시예는 현재 알려져 있거나 나중에 개발될 임의의 다른 유형의 컴퓨팅 환경과 함께 구현될 수 있다. 클라우드 컴퓨팅은, 최소한의 관리 노력 또는 서비스 제공자와의 상호작용으로 빠르게 제공되고 해제될 수 있는, 구성 가능한(configurable) 컴퓨팅 자원들(예를 들어, 네트워크들, 네트워크 대역폭, 서버들, 처리, 메모리, 스토리지, 애플리케이션들, 가상 머신들, 및 서비스들)의 공유 풀에 대한 편리한 주문형(on-demand) 네 트워크 액세스를 가능하게 하는 서비스 전달 모델이다. 이 클라우드 모델은 적어도 5가지의 특성 (characteristics), 적어도 3가지 서비스 모델(service models), 및 적어도 4가지 배치 모델(deploymentmodels)을 포함할 수 있다. 특성들은 다음과 같다: 주문형 셀프-서비스(On-demand self-service): 클라우드 소비자는, 서비스 제공자와의 인적 상호작용을 필요로 하지 않고 필요한 만큼 자동적으로, 서버 시간(server time) 및 네트워크 스토리지 같은 컴퓨팅 용량들 을 일방적으로 제공(provision)할 수 있다. 광역 네트워크 액세스(Broad network access): 혼성의 씬 또는 씩 클라이언트 플랫폼들(heterogeneous thin or thick client platforms)(예를 들어, 모바일폰들, 랩탑들, 및 PDA들)에 의한 사용을 장려하는 표준 메 커니즘들을 통해 액세스되는 기능들을 네트워크를 통해서 이용할 수 있다. 자원 풀링(Resource pooling): 제공자의 컴퓨팅 자원들은, 각기 다른 물리적 및 가상 자원들을 요구 (demand)에 따라 동적으로 할당 및 재할당하는, 멀티-테넌트 모델(a multi-tenant model)을 사용하는 다수의 소 비자들에게 서비스할 수 있도록 풀에 넣어둔다(pooled). 소비자는 일반적으로 제공된 자원들의 정확한 위치를 제어할 수 없거나 그에 대한 지식이 없지만 더 높은 추상 수준에서(예를 들어, 국가, 주, 또는 데이터센터) 위 치를 명시할 수 있다는 점에서 위치 독립성이 있다. 기민한 탄력성(Rapid elasticity): 용량들(capabilities)이 기민하게 탄력적으로 제공되어 (어떤 경우 엔 자동으로) 신속히 규모를 확장할 수도 있고(scale out) 그리고 탄력적으로 해제되어 신속히 규모를 축소할 수도 있다(scale in). 소비자에게 제공할 수 있는 가능성이 종종 무제한이고 언제든지 원하는 수량으로 구매할 수 있는 것처럼 보인다. 측정 가능한 서비스(Measured service): 클라우드 시스템들은 자원 사용을 자동으로 제어하고 최적화하 는데, 서비스의 유형(예를 들어, 스토리지, 처리, 대역폭, 및 활성 사용자 계정)에 적절한 추상화 수준에서(at some level of abstraction) 계측 기능을 이용하여서 그렇게 한다. 자원 사용량은 모니터 되고, 제어되고, 그리 고 보고될 수 있으며 이로써 이용하는 서비스의 제공자와 사용자 모두에게 투명성을 제공한다. 서비스 모델들(Service Models)은 다음과 같다: 소프트웨어 서비스(Software as a Service)(SaaS): 소비자에게 제공되는 서비스는 클라우드 하부구조 상 에서 실행되는 제공자의 애플리케이션들을 사용하게 해주는 것이다. 애플리케이션들은 웹 브라우저(예를 들어, 웹기반 이메일) 같은 씬(thin) 클라이언트 인터페이스를 통해 여러 클라이언트 장치들에서 액세스 가능하다. 소 비자는 네트워크, 서버들, 운영 체제들, 스토리지, 또는 개별 애플리케이션 능력들을 포함하는 하부 클라우드 하부구조를 관리하거나 제어하지 않는다. 단, 제한된 사용자-특정 애플리케이션 구성 세팅들은 예외로서 가능하 다. 플랫폼 서비스(Platform as a Service)(PaaS): 소비자에게 제공되는 서비스는 제공자에 의해 지원되는 프로그래밍 언어들 및 도구들을 이용하여 생성된 소비자-생성 또는 획득 애플리케이션들을 클라우드 하부구조에 배치하게 해주는 것이다. 소비자는 네트워크, 서버들, 운영 체제들, 또는 스토리지를 포함하는 하부 클라우드 하부구조를 관리하거나 제어하지 않는다. 그러나 배치된 애플리케이션들에 대해서 그리고 가능한 경우 애플리케 이션 호스팅 환경 구성들에 대해서 제어할 수 있다. 하부구조 서비스(Infrastructure as a Service)(IaaS): 소비자에게 제공되는 서비스는 처리, 스토리지, 네트워크, 및 기타 기본 컴퓨팅 자원들을 제공하여 주는 것이며, 여기서 소비자는 임의의 소프트웨어를 배치 및 실행할 수 있고, 이 소프트웨어에는 운영 체제들과 애플리케이션들이 포함될 수 있다. 소비자는 하부 클라우드 하부구조를 관리하거나 제어하지 않지만, 운영 체제들, 스토리지, 배치된 애플리케이션들, 및 가능한 경우 선택 된 네트워킹 컴포넌트들의 제한적인 제어(예를 들어, 호스트 방화벽들)에 대하여 제어할 수 있다. 배치 모델들(Deployment Models)은 다음과 같다: 사설 클라우드(Private cloud): 클라우드 하부구조는 오직 한 조직(an organization)을 위해서 운영되 고, 그 조직 또는 제3자에 의해 관리될 수 있으며 옥내(on-premises) 또는 옥외(off-premises)에 위치할 수 있 다. 커뮤니티 클라우드(Community cloud): 클라우드 하부구조는 여러 조직들에 의해 공유되고 관심사(예를 들어, 선교, 보안 요건, 정책, 및 규정 준수 심사)를 공유하는 특정 커뮤니티를 지원하며, 여러 조직들 또는 제 3자에 의해 관리될 수 있으며 옥내(on-premises) 또는 옥외(off-premises)에 위치할 수 있다. 공공 클라우드(Public cloud): 클라우드 하부구조는 일반 대중 또는 대규모 산업 그룹이 사용할 수 있으 며 클라우드 서비스들을 판매하는 조직에 의해 소유된다. 하이브리드 클라우드(Hybrid cloud): 클라우드 하부구조는 둘 또는 그 이상의 클라우드들(사설, 커뮤니 티, 또는 공공)이 혼합된 구성이며, 이들은 고유한 주체들로 있지만 데이터 및 애플리케이션 이식가능성 (portability)을 가능하게 해주는 표준화된 또는 소유권 있는 기술(예를 들어, 클라우드들 사이의 부하 균형을 위한 클라우드 버스팅(cloud bursting))에 의해 서로 결합되어 있다 클라우드 컴퓨팅 환경은 상태비보존(statelessness), 낮은 결합(low coupling), 모듈 방식 (modularity), 및 의미적 상호운용성(semantic interoperability)에 집중하는 서비스를 지향한다. 클라우드 컴 퓨팅의 중심에는 상호 연결된 노드들의 네트워크를 포함하는 하부구조가 있다. 이제 도10을 참조하면, 예시적인 클라우드 컴퓨팅 환경이 도시된다. 도시된 바와 같이, 클라우드 컴퓨팅 환경은 예를 들어 개인 휴대 정보 단말기(PDA) 또는 휴대폰(1054A), 데스크탑 컴퓨터(1054B), 랩 탑 컴퓨터(1054C), 및/또는 자동차용 컴퓨터 시스템(1054N)과 통신할 수 있는 것과 같이, 클라우드 소비자가 사 용하는 로컬 컴퓨팅 디바이스가 하나 또는 그 이상의 클라우드 컴퓨팅 노드들을 포함한다. 노드들 은 서로 통신할 수 있다. 그들은 여기에 기술된 바와 같은 사설, 커뮤니티, 공공, 또는 하이브리드 클라우드들 또는 이들의 조합 등의 하나 또는 그 이상의 네트워크들에서 물리적으로 또는 가상으로 그룹화될 수 있다(도시 되지 않음). 이것은 클라우드 소비자가 로컬 컴퓨팅 디바이스 상에 자원들을 유지할 필요가 없게 클라우드 컴퓨 팅 환경이 하부구조, 플랫폼들 및/또는 소프트웨어를 서비스로서 제공할 수 있게 해준다. 컴퓨팅 디바이 스들(1054A-N)의 유형들은 단지 예시의 목적으로 기술한 것이며 컴퓨팅 노드들과 클라우드 컴퓨팅 환경 은 모든 유형의 네트워크 및/또는 네트워크 주소지정가능 연결을 통해서 (예를 들어, 웹 브라우저를 사용 하여) 모든 유형의 컴퓨터화된 디바이스와 통신할 수 있다는 것을 이해해야 한다. 도 11을 이제 참조하면, 클라우드 컴퓨팅 환경(도 10)에 의해 제공된 기능 추상화 층들 세트가 도 시된다. 도 11에 도시된 컴포넌트들, 층들, 및 기능들은 단지 예시의 목적이며 본 발명의 바람직한 실시 예들은 이것에 한정되지 않는다는 것을 미리 이해해야 한다. 도시된 바와 같이, 다음의 층들과 그에 대응하는 기능들이 제공된다: 하드웨어 및 소프트웨어 층은 하드웨어 및 소프트웨어 컴포넌트들을 포함한다. 하드웨어 컴포넌트 들의 예들에는: 메인프레임들; RISC(Reduced Instruction Set Computer) 아키텍처 기반 서버들; 서버들; 블레이드 서버들; 스토리지 디바이스들; 그리고 네트워크 및 네트워킹 컴포넌트들 이 포함된다. 일부 실시 예들에서, 소프트웨어 컴포넌트들은 네트워크 애플리케이션 서버 소프트웨어 및 데이터베이스 소프트웨어를 포함한다. 가상화 층은 추상화 층을 제공하며 이로부터 다음의 가상 주체들의 예들이 제공될 수 있다: 가상 서버들; 가상 스토리지; 가상 사설 네트워크를 포함하는, 가상 네트워크들; 가상 애플리케이 션들 및 운영 체제들; 및 가상 클라이언트들. 한 예에서, 관리 층은 아래에 기술하는 기능들 을 제공한다. 자원 제공(Resource provisioning)은 클라우드 컴퓨팅 환경 내에서 작업들을 수행하는 데 이용되는 컴퓨팅 자원들 및 기타 자원들의 동적 조달을 제공한다. 계측 및 가격 책정(Metering and Pricing)은 자원들이 클라우드 컴퓨팅 환경 내에서 이용될 때 비용 추적, 및 이 자원들의 소비에 대한 요 금 청구 또는 송장을 제공한다. 한 예에서, 이들 자원들은 애플리케이션 소프트웨어 라이센스를 포함할 수 있다. 보안(Security)은 데이 터 및 기타 자원들에 대한 보호뿐 아니라 클라우드 소비자들과 작업들에 대한 신원 확인을 제공한다. 사용자 포 털(User portal)은 소비자들 및 시스템 관리자들에게 클라우드 컴퓨팅 환경에 대한 액세스를 제공한다. 서비스 수준 관리(Service level management)는 요구되는 서비스 수준이 충족되도록 클라우드 컴퓨팅 자 원 할당 및 관리를 제공한다. 서비스 수준 협약서(SLA) 기획 및 충족(planning and fulfillment)은 SLA 에 부합하는 예상되는 미래 요건에 맞는 클라우드 컴퓨팅 자원들의 사전-배치(pre-arrangement) 및 조달 (procurement)을 제공한다. 워크로드 층은 클라우드 컴퓨팅 환경이 이용될 수 있는 기능들의 예들을 제공한다. 이 층에서 제 공될 수 있는 워크로드들과 기능들의 예들은 다음을 포함한다: 맵핑 및 네비게이션; 소프트웨어 개발 및 라이프사이클 관리; 가상 교실 훈련 전달; 데이터 분석 처리; 트랜잭션 처리; 및, 본 발명의 하나 또는 그 이상의 실시예들에 따른, 인공 지능 앨고리듬 처리. 본 명세서에서 사용된 용어는 단지 특정 실시예를 설명하기 위한 것이며 본 발명을 제한하려는 의도가 아니다. 본 명세서에서 사용된 단수형은 문맥상 명백하게 다르게 나타내지 않는 한 복수형도 포함하는 것으로 의도된다. \"포함하다\" 및/또는 \"포함하는\"이라는 용어는 본 명세서에서 사용될 때 명시된 특징, 단계, 동작, 엘 리멘트 및/또는 컴포넌트의 존재를 명시하지만, 다른 기능, 단계, 동작, 엘리멘트, 컴포넌트 및/또는 이들의 그 룹 존재 또는 추가를 배제하지 않음이 더 이해될 것이다. 본 발명의 적어도 하나의 실시예는 모델 복원 로직의 복잡한 매뉴얼(예를 들어, 맞춤형) 개발을 대체하 는 프레임워크(예를 들어, 하나 이상의 프레임워크 구성의 집합)와 같은 유익한 효과를 제공할 수 있다. 본 명 세서에서 예시적으로 설명된 바와 같이, 상기 프레임워크는 실패 검출 컴포넌트 세트 및 연관된 모델 복원 파이 프라인으로 구성되고 인스턴스화된다. 일단 인스턴스화되면 프레임워크는 로그를 입력으로 사용하여 명시된 수 명 주기에 플러그되고 새 모델 버전에 대한 새 모델 아티팩트를 기존 수명 주기 파이프라인에 전달한다. 하나 이상의 예시적인 실시예에서, 프레임워크는 AI 애플리케이션의 엔드-투-엔드 개발 및 라이프사이클 관리를 위한 클라우드 기반 프레임워크 및 플랫폼이다. 본 발명의 다양한 실시예들에 대한 설명들은 예시의 목적들로 제시되었지만, 개시된 실시예들이 전부라 거나 또는 이들에 제한된다는 것을 의도하지는 않는다. 많은 수정들 및 변형들은 기술된 실시예들의 범위 및 정 신에서 벗어나지 않고 당 업계의 통상적인 기술을 가진 사람들에게 분명할 것이다. 여기서 사용된 용어는 실시 예들의 원리들, 시장에서 발견되는 기술들에 대한 실용적인 적용 또는 기술적 개선을 가장 잘 설명하기 위해, 또는 여기서 개시된 실시예들을 당 업계의 통상적인 기술을 가진 다른 사람들이 이해할 수 있도록 하기 위해 선 택되었다."}
{"patent_id": "10-2023-7019242", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 하나 또는 그 이상의 예시적인 실시예들이 구현될 수 있는 신경망 컴퓨팅 환경의 블록도를 도시 한다. 도 2는 하나 또는 그 이상의 예시적인 실시예들이 구현될 수 있는 신경망 디바이스의 개략적인 회로도를 도시한다. 도 3은 포지티브 시냅스 네트워크(a positive synapse network)를 구현하는데 사용되는 단일 출력 커패 시터-기반 구조(a single output capacitor-based structure)의 개략적인 회로도를 도시한다. 도 4는 네거티브 시냅스 네트워크(a negative synapse network)를 구현하는데 사용되는 단일 출력 커패 시터-기반 구조의 개략적인 회로도를 도시한다. 도 5는 시냅스 네트워크를 구현하는데 사용되는 다수의 출력 커패시터-기반 구조(a multiple output capacitor-based structure)에서 커플링 커패시턴스 문제(coupling capacitance issue)의 개략적인 회로도를 도시한다. 도 6은 예시적인 실시예에 따라 시냅스 네트워크를 구현하기 위해 사용되는 출력들 사이에 금속 차폐가 있는 다수의 출력 커패시터-기반 구조의 아이소메트릭 구조 다이어그램(an isometric structural diagram)을 도 시한다. 도 7은 예시적인 실시예에 따라 시냅스 네트워크를 구현하는데 사용되는 출력들 사이에 금속 차폐가 있 는 다수의 출력 커패시터-기반 구조의 개략적인 회로도를 도시한다. 도 8a는 예시적인 실시예에 따라 시냅스 네트워크를 구현하는데 사용되는 출력들 사이에 금속 차폐가 있 는 다수의 출력 커패시터-기반 구조를 제조하기 위한 방법론의 흐름도를 도시한다. 도 8b는 예시적인 실시예에 따라 시냅스 네트워크를 구현하는데 사용되는 출력들 사이에 금속 차폐가 있 는 다수의 출력 커패시터-기반 구조를 제조하기 위한 방법론의 다른 흐름도를 도시한다. 도 8c는 예시적인 실시예에 따라 금속 차폐 출력이 있는 커패시터-기반 시냅스 네트워크를 가지는 하나 또는 그 이상의 신경망 디바이스가 있는 인공 지능 시스템의 블록도를 도시한다. 도 9는 예시적인 실시예에 따라 예시적인 프로세서 시스템(an exemplary processor system)의 도면을 도시한다. 도 10은 예시적인 실시예에 따라 클라우드 컴퓨팅 환경(a cloud computing environment)의 도면을 도시 한다. 도 11은 예시적인 실시예에 따라 추상화 모델 계층의 도면을 도시한다."}
