{"patent_id": "10-2024-7021630", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0147658", "출원번호": "10-2024-7021630", "발명의 명칭": "정보 융합 방법과 장치, 데이터 통신 방법과 장치, 전자 기기 및 비휘발성 판독 가능 저장 매", "출원인": "아이이아이티 시스템즈 캄파니 리미티드", "발명자": "옌 루이동"}}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "분산형 훈련 시스템의 중앙 노드에 응용되는 정보 융합 방법으로서,금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 단계;각 상기 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 단계;상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 상기 글로벌 파라미터를 각 상기 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신하는 단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 것은,금번 라운드의 훈련에 참여하는 핵심 노드가 모두 기설정된 횟수의 반복 훈련 과정을 수행 완료했다라는 것을포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,각 상기 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하는 상기 단계는,상기 핵심 노드의 로컬 파라미터의 평균 파라미터를 산출하고, 각 상기 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 결정하며, 편차가 가장 작은 N개의 컴퓨팅 노드를 다음 라운드의 훈련에 참여하는핵심 노드로 선택하는 단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,각 상기 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 결정하는 상기 단계는,각 상기 컴퓨팅 노드가 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에반환하도록, 상기 평균 파라미터를 각 상기 컴퓨팅 노드에 송신하는 단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,훈련 모델을 복수의 훈련 서브 모델로 구획하고, 상기 훈련 서브 모델을 각 상기 컴퓨팅 노드에 할당하는 단계를 더 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,훈련 모델을 복수의 훈련 서브 모델로 구획하는 상기 단계는,수평 방향 또는 수직 방향에서 훈련 모델을 복수의 훈련 서브 모델로 구획하는 단계를 포함하는 정보 융합방법.공개특허 10-2024-0147658-3-청구항 7 제1항에 있어서,각 컴퓨팅 노드가 대응하는 훈련 샘플에 기반하여 반복 훈련 과정을 수행하도록, 복수의 훈련 샘플을 각 상기컴퓨팅 노드에 할당하는 단계를 더 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하는 상기 단계는,샘플링 방법에 기반하여 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하거나, 또는, 복수의 훈련 샘플을 데이터 차원에 따라 분할하여 각 상기 컴퓨팅 노드에 할당하는 단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,샘플링 방법에 기반하여 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하는 상기 단계는,복원 랜덤 샘플링 및/또는 로컬 스크램블링 샘플링 방식을 통해 상기 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하는 단계; 또는복원 랜덤 샘플링 및/또는 전체 스크램블링 샘플링 방식을 통해 상기 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하는 단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,복수의 훈련 샘플을 데이터 차원에 따라 분할하여 각 상기 컴퓨팅 노드에 할당하는 상기 단계는,각 훈련 샘플이 다차원 속성 또는 특징을 갖는 경우, 상이한 속성에 따라 상기 복수의 훈련 샘플을 분할하고,분할된 샘플 서브 세트를 대응된 컴퓨팅 노드에 할당하는 단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 상기 단계는,N개의 상기 핵심 노드의 로컬 파라미터의 평균값을 산출하고, 상기 평균값을 상기 글로벌 파라미터로 결정하는단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "분산형 훈련 시스템의 컴퓨팅 노드에 응용되는 데이터 통신 방법으로서,통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 단계;상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노드가 N개의핵심 노드의 로컬 파라미터를 융합하여 얻은 것인 단계;상기 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크를 실행하는 단계를 포함하는 데이터 통신 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 기설정된 압축 알고리즘은공개특허 10-2024-0147658-4-이고;x는 상기 로컬 파라미터이며, 는 x의 L2 놈(norm)이고, sign(x)는 x의 부호이며, d는 상기 로컬 파라미터의 차원이고, 이며, 는 x의 i번째 차원이고, C[x]는 압축된 로컬 파라미터인 데이터 통신 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 중앙 노드에 의해 송신된 평균 파라미터를 획득하고, 자신의 로컬 파라미터와 상기 평균 파라미터 사이의편차를 산출하여 상기 중앙 노드에 반환하는 단계를 더 포함하는 데이터 통신 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 상기 단계는, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료한 경우, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 단계를 포함하고;상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하는 상기 단계는, 상기 컴퓨팅 노드가 다음 라운드의 훈련에 참여하는 핵심 노드로 선택된 경우, 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하는 단계를 포함하며;중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크를 실행하는 상기 단계는, 상기 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에기반하여 다음 라운드의 훈련 태스크를 실행하는 단계를 포함하는 정보 융합 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,복수의 훈련 서브 모델의 일부 훈련 서브 모델을 획득하되, 상기 복수의 훈련 서브 모델은 상기 훈련 태스크와연관된 훈련 모델을 구획하여 얻은 서브 모델이고, 상기 복수의 훈련 서브 모델은 상기 분산형 훈련 시스템 중의 각 컴퓨팅 노드에 할당되는 단계; 및/또는복수의 훈련 샘플의 일부 훈련 샘플을 획득하되, 상기 복수의 훈련 샘플은 상기 훈련 태스크와 연관된 훈련 샘플이고, 상기 복수의 훈련 샘플은 각 상기 컴퓨팅 노드에 할당되며, 각 상기 컴퓨팅 노드는 대응하는 훈련 샘플에 기반하여 반복 훈련 과정을 수행하는 데 사용되는 단계를 더 포함하는 데이터 통신 방법."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "분산형 훈련 시스템의 중앙 노드에 응용되는 정보 융합 장치로서,금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 제1 획득 모듈;각 상기 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 융합 모듈;상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 상기 글로벌 파라미터를 각 상기 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신하는 송신 모듈을 포함하는 정보 융합 장치.공개특허 10-2024-0147658-5-청구항 18 분산형 훈련 시스템의 컴퓨팅 노드에 응용되는 데이터 통신 장치로서,통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 압축 모듈;상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노드가 N개의핵심 노드의 로컬 파라미터를 융합하여 얻은 것인 제2 획득 모듈;중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크를 실행하는 실행 모듈을 포함하는 데이터 통신 장치."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터 프로그램이 저장되는 메모리;상기 컴퓨터 프로그램을 실행할 경우, 제1항 내지 제11항 중 어느 한 항에 따른 정보 융합 방법 또는 제12항 내지 제16항 중 어느 한 항에 따른 데이터 통신 방법의 단계를 구현하는 프로세서를 포함하는 전자 기기."}
{"patent_id": "10-2024-7021630", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 프로그램이 저장되어 있는 컴퓨터 비휘발성 판독 가능 저장 매체로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제11항 중 어느 한 항에 따른 정보 융합 방법 또는 제12항 내지 제16항 중 어느 한 항에 따른 데이터 통신 방법의 단계가 구현되는 컴퓨터 비휘발성 판독가능 저장 매체."}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원의 실시예는 컴퓨터"}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 정보 융합 방법과 장치, 데이터 통신 방법과 장치, 전자 기기 및 컴 퓨터 비휘발성 판독 가능 저장 매체를 개시하며, 상기 정보 융합 방법은, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거 조건이 만족될 때, 분산형 훈련 시스 템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 단계; 각 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N 개의 핵심 노드를 선택하고, N개의 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 단계; 핵심 노드가 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 글로벌 파라미터를 각 컴퓨팅 노 드에 송신하고, 핵심 노드에 훈련 커맨드를 송신하는 단계를 포함한다. 본 출원의 실시예는 모델의 분산형 훈련 속도를 향상시킨다. 대 표 도 - 도3"}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2024-0147658 CPC특허분류 H04L 67/10 (2022.05) 발명자 자오 야치안 중국 산동 250000 진안 진안 이노베이션 존 차오샨 링 사우쓰 로드 넘버 801 이스트 사이드 오브 9 플 로어치우 지용 중국 산동 250000 진안 진안 이노베이션 존 차오샨 링 사우쓰 로드 넘버 801 이스트 사이드 오브 9 플 로어명 세 서 청구범위 청구항 1 분산형 훈련 시스템의 중앙 노드에 응용되는 정보 융합 방법으로서, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거 조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 단계; 각 상기 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 단계; 상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 상기 글로벌 파 라미터를 각 상기 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신하는 단계를 포함하는 정보 융 합 방법. 청구항 2 제1항에 있어서, 상기 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 것은, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 기설정된 횟수의 반복 훈련 과정을 수행 완료했다라는 것을 포함하는 정보 융합 방법. 청구항 3 제1항에 있어서, 각 상기 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하는 상기 단계는, 상기 핵심 노드의 로컬 파라미터의 평균 파라미터를 산출하고, 각 상기 컴퓨팅 노드의 로컬 파라미터와 상기 평 균 파라미터 사이의 편차를 결정하며, 편차가 가장 작은 N개의 컴퓨팅 노드를 다음 라운드의 훈련에 참여하는 핵심 노드로 선택하는 단계를 포함하는 정보 융합 방법. 청구항 4 제3항에 있어서, 각 상기 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 결정하는 상기 단계는, 각 상기 컴퓨팅 노드가 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에 반환하도록, 상기 평균 파라미터를 각 상기 컴퓨팅 노드에 송신하는 단계를 포함하는 정보 융합 방법. 청구항 5 제1항에 있어서, 훈련 모델을 복수의 훈련 서브 모델로 구획하고, 상기 훈련 서브 모델을 각 상기 컴퓨팅 노드에 할당하는 단계 를 더 포함하는 정보 융합 방법. 청구항 6 제5항에 있어서, 훈련 모델을 복수의 훈련 서브 모델로 구획하는 상기 단계는, 수평 방향 또는 수직 방향에서 훈련 모델을 복수의 훈련 서브 모델로 구획하는 단계를 포함하는 정보 융합 방법.청구항 7 제1항에 있어서, 각 컴퓨팅 노드가 대응하는 훈련 샘플에 기반하여 반복 훈련 과정을 수행하도록, 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하는 단계를 더 포함하는 정보 융합 방법. 청구항 8 제7항에 있어서, 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하는 상기 단계는, 샘플링 방법에 기반하여 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하거나, 또는, 복수의 훈련 샘플을 데 이터 차원에 따라 분할하여 각 상기 컴퓨팅 노드에 할당하는 단계를 포함하는 정보 융합 방법. 청구항 9 제8항에 있어서, 샘플링 방법에 기반하여 복수의 훈련 샘플을 각 상기 컴퓨팅 노드에 할당하는 상기 단계는, 복원 랜덤 샘플링 및/또는 로컬 스크램블링 샘플링 방식을 통해 상기 복수의 훈련 샘플을 각 상기 컴퓨팅 노드 에 할당하는 단계; 또는 복원 랜덤 샘플링 및/또는 전체 스크램블링 샘플링 방식을 통해 상기 복수의 훈련 샘플을 각 상기 컴퓨팅 노드 에 할당하는 단계를 포함하는 정보 융합 방법. 청구항 10 제8항에 있어서, 복수의 훈련 샘플을 데이터 차원에 따라 분할하여 각 상기 컴퓨팅 노드에 할당하는 상기 단계는, 각 훈련 샘플이 다차원 속성 또는 특징을 갖는 경우, 상이한 속성에 따라 상기 복수의 훈련 샘플을 분할하고, 분할된 샘플 서브 세트를 대응된 컴퓨팅 노드에 할당하는 단계를 포함하는 정보 융합 방법. 청구항 11 제1항에 있어서, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 상기 단계는, N개의 상기 핵심 노드의 로컬 파라미터의 평균값을 산출하고, 상기 평균값을 상기 글로벌 파라미터로 결정하는 단계를 포함하는 정보 융합 방법. 청구항 12 분산형 훈련 시스템의 컴퓨팅 노드에 응용되는 데이터 통신 방법으로서, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 단계; 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노드가 N개의 핵심 노드의 로컬 파라미터를 융합하여 얻은 것인 단계; 상기 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태 스크를 실행하는 단계를 포함하는 데이터 통신 방법. 청구항 13 제12항에 있어서, 상기 기설정된 압축 알고리즘은이고; x는 상기 로컬 파라미터이며, 는 x의 L2 놈(norm)이고, sign(x)는 x의 부호이며, d는 상기 로컬 파라미터 의 차원이고, 이며, 는 x의 i번째 차원이고, C[x]는 압축된 로컬 파라미터인 데이터 통 신 방법. 청구항 14 제12항에 있어서, 상기 중앙 노드에 의해 송신된 평균 파라미터를 획득하고, 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에 반환하는 단계를 더 포함하는 데이터 통신 방법. 청구항 15 제12항에 있어서, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 상기 단계는, 금번 라운드의 훈련에 참여하는 핵심 노 드가 모두 금번 라운드의 훈련 태스크를 실행 완료한 경우, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파 라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 단계를 포함하고; 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하는 상기 단계는, 상기 컴퓨팅 노드가 다음 라운드의 훈 련에 참여하는 핵심 노드로 선택된 경우, 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하는 단계를 포 함하며; 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크 를 실행하는 상기 단계는, 상기 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하는 단계를 포함하는 정보 융합 방법. 청구항 16 제12항에 있어서, 복수의 훈련 서브 모델의 일부 훈련 서브 모델을 획득하되, 상기 복수의 훈련 서브 모델은 상기 훈련 태스크와 연관된 훈련 모델을 구획하여 얻은 서브 모델이고, 상기 복수의 훈련 서브 모델은 상기 분산형 훈련 시스템 중 의 각 컴퓨팅 노드에 할당되는 단계; 및/또는 복수의 훈련 샘플의 일부 훈련 샘플을 획득하되, 상기 복수의 훈련 샘플은 상기 훈련 태스크와 연관된 훈련 샘 플이고, 상기 복수의 훈련 샘플은 각 상기 컴퓨팅 노드에 할당되며, 각 상기 컴퓨팅 노드는 대응하는 훈련 샘플 에 기반하여 반복 훈련 과정을 수행하는 데 사용되는 단계를 더 포함하는 데이터 통신 방법. 청구항 17 분산형 훈련 시스템의 중앙 노드에 응용되는 정보 융합 장치로서, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거 조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 제1 획득 모듈; 각 상기 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 융합 모듈; 상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 상기 글로벌 파 라미터를 각 상기 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신하는 송신 모듈을 포함하는 정 보 융합 장치.청구항 18 분산형 훈련 시스템의 컴퓨팅 노드에 응용되는 데이터 통신 장치로서, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 압축 모듈; 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노드가 N개의 핵심 노드의 로컬 파라미터를 융합하여 얻은 것인 제2 획득 모듈; 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크 를 실행하는 실행 모듈을 포함하는 데이터 통신 장치. 청구항 19 컴퓨터 프로그램이 저장되는 메모리; 상기 컴퓨터 프로그램을 실행할 경우, 제1항 내지 제11항 중 어느 한 항에 따른 정보 융합 방법 또는 제12항 내 지 제16항 중 어느 한 항에 따른 데이터 통신 방법의 단계를 구현하는 프로세서를 포함하는 전자 기기. 청구항 20 컴퓨터 프로그램이 저장되어 있는 컴퓨터 비휘발성 판독 가능 저장 매체로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제11항 중 어느 한 항에 따른 정보 융합 방 법 또는 제12항 내지 제16항 중 어느 한 항에 따른 데이터 통신 방법의 단계가 구현되는 컴퓨터 비휘발성 판독 가능 저장 매체. 발명의 설명 기 술 분 야 관련 출원의 상호 참조 본 출원은 2022년 7월 18일에 중국 특허청에 제출된, 출원번호가 202210838709.3이며, 발명의 명칭이 \"정보 융 합 방법과 장치, 데이터 통신 방법과 장치, 전자 기기 및 저장 매체\"인 중국 특허 출원의 우선권을 주장하는 바, 이의 모든 내용은 참조로서 본 출원에 원용된다."}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 3, "content": "본 출원은 컴퓨터 기술분야에 관한 것으로, 더 구체적으로는, 정보 융합 방법, 데이터 통신 방법, 정보 융합 장 치, 데이터 통신 장치, 전자 기기 및 비휘발성 판독 가능 저장 매체에 관한 것이다."}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과거에는 데이터와 하드웨어의 제한으로 인해 머신이 모델 훈련을 학습하는 주요한 경로는 획득할 수 있는 제한 된 샘플 기반 스탠드얼론 훈련이었다. 그러나, 최근에는 빅데이터, 인공지능, 고성능 컴퓨팅 및 인터넷 기술이 급속도로 발전하면서, 다양한 거대하고 복잡한 데이터와 모델이 생성되었고, 이는 머신 러닝, 딥 러닝 모델 훈 련이 점차 분산형 컴퓨팅 아키텍처 분야로 발전하도록 촉진하여, 인공지능 기술이 컴퓨터 비전, 자연어 처리, 언어 인식, 자율 주행 등 분야에서 획기적인 발전을 이루도록 하기 위한 핵심적인 척도가 되었다. 기존의 스탠 드얼론 훈련 방식에 비해, 분산형 훈련 기술은 다음과 같은 두 가지 뚜렷한 장점을 가지고 있다. 첫째, 분산형 훈련 기술에 의해 저장될 수 있는 데이터와 모델의 규모가 지속적으로 증가된다. 현 단계에서 분 산형 훈련 시스템은 복수의 컴퓨팅 노드로 함께 구성된 네트워크 또는 클러스터이고, 각각의 컴퓨팅 노드는 하 나의 호스트 또는 복수의 호스트로 구성될 수 있으며, 각 호스트마다 상대적으로 독립적인 저장 기기 또는 저장 유닛이 구비된다. 하나의 컴퓨팅 노드만 구비되는 스탠드얼론 훈련 방식에 비해, 분산형 시스템에 저장된 데이 터 및 모델은 규모가 크게 향상되고, 대규모 데이터세트가 100억개가 넘는 파라미터를 갖는 심층 신경망 모델의 훈련을 가능하도록 한다. 둘째, 분산형 훈련 기술은 훈련 시간이 지속적으로 감소된다. 분산형 훈련 시스템은 다양한 컴퓨팅 및 통신 아 키텍처를 통해 훈련 태스크의 실행 시간을 효과적으로 단축한다. 구체적으로, 분산형 훈련 시스템은 \"분할 정복\"이라는 아이디어를 기반으로 하는데, 우선, 훈련 대상인 심층 신경망 모델 또는 빅데이터세트를 모델병렬, 데이터 병렬 또는 혼합 병렬 방식으로 분할하여 대응된 컴퓨팅 노드에 할당하고; 그 다음, 각 컴퓨팅 노 드는 분할된 소규모 데이터 또는 서브 모델을 각각 개별적으로 훈련하여 로컬 또는 중간 훈련 결과를 생성하며; 마지막으로, 분산형 훈련 시스템은 모든 로컬 훈련 결과를 다시 특정 방식으로 집계하여 글로벌 결과를 얻고, 글로벌 훈련 결과를 출력한다. 상기 과정은 병렬 방식으로 동시에 진행되므로, 기존의 직렬 스탠드얼론 훈련 시 간을 크게 줄일 수 있다. 이와 같이, 분산형 훈련 방식은 빅데이터 시대의 핫이슈이자 핵심 기술이 되었고, 학계와 산업계에서는 모두 많 은 관련 연구와 실무 작업을 진행하였다. 대규모 파라미터 기반 심층 신경망 모델이 빅데이터세트에서의 고효율 적 훈련 문제를 해결하기 위해, 연구자들은 분산형 딥 러닝 모델 기반 노드 간 통신 훈련 방법을 중점적으로 탐 색하고 연구하고 있다. 종래의 관련 기술은 통신 아키텍처에 따라 중앙화 아키텍처 알고리즘 및 탈중앙화 아키 텍처 알고리즘으로 구분될 수 있고, 정보 동기화 방식에 따라 동기식 알고리즘 및 비동기식 알고리즘으로 구분 될 수 있다. 도 1에 도시된 바와 같이, 중앙화 아키텍처는 주로 분산형 훈련 시스템에 중앙 노드가 존재하는 것을 의미하고, 다른 컴퓨팅 노드와의 정보 인터랙션 및 글로벌 정보의 동기화와 업데이트를 담당한다. 중앙화 아키텍처에서는 파라미터 서버 아키텍처가 가장 전형적이다. 상기 아키텍처에는 주로 파라미터 서버(server)와 컴퓨팅 노드 (worker)의 두 가지 역할이 존재한다. 파라미터 서버는 컴퓨팅 노드로부터 송신된 기울기 또는 파라미터 등 정 보를 수집하고, 수집된 정보에 대해 글로벌 컴퓨팅 및 동기화를 수행하며, 획득한 글로벌 동기화 정보를 각 컴 퓨팅 노드에 반환하는 것을 담당한다. 컴퓨팅 노드는 파라미터 서버로부터 송신된 글로벌 정보를 수신한 다음 후속되는 반복 컴퓨팅을 수행하고, 새로 생성된 산출 결과를 파라미터 서버에 송신한다. 파라미터 서버와 컴퓨 팅 노드는 훈련 종료 조건에 도달할 때까지 상기 과정에 따라 반복적으로 수행한다. 반대로, 탈중앙화 아키텍처 에는 중앙 파라미터 서버와 유사한 노드가 존재하지 않고, 모든 컴퓨팅 노드는 \"동등한 상태\"이다. 상기 아키텍 처에는 컴퓨팅 노드라는 하나의 역할만 존재한다. 각각의 컴퓨팅 노드는 각자의 로컬 데이터 또는 로컬 모델 파 라미터만 파악하고, 각 라운드의 반복 훈련 과정에서는, 전문적인 중앙 노드를 통해 글로벌 정보의 인터랙션을 구현하는 것이 아니라, All-Reduce(전체 감소) 등 동작을 통해 글로벌 또는 로컬 정보의 통신과 융합을 구현한 다. 또한, 중앙화 아키텍처와 탈중앙화 아키텍처의 장단점을 비교 분석한 결과는 다음과 같다. 중앙화 아키텍처의 장점은, 우선, 각 컴퓨팅 노드 간에 직접적인 정보 인터랙션과 통신이 존재하지 않고, 컴퓨팅 노드는 중앙 파라 미터 서버 노드와만 통신하기에, 노드 간 훈련 과정이 상대적으로 독립적이다. 다시 말하면, 각 노드는 각자의 훈련 속도로 중앙 파라미터 서버 노드와 각각 통신을 수행하여, 비동기식 통신 전략을 우호적으로 지원할 수 있 고; 다음으로, 중앙 파라미터 서버가 글로벌 정보의 융합을 담당하고 글로벌 정보를 각 컴퓨팅 노드에 송신하기 때문에, 모델 훈련 정확도와 알고리즘의 수렴성이 충분히 보장되도록 한다. 마지막으로, 중앙화 아키텍처는 내 결함성이 우수하다. 새로운 노드가 추가되거나 제거되어도 이 노드의 변동은 다른 노드에 직접적인 영향을 미치 지 않는다. 단점은 중앙 파라미터 서버 노드에 \"통신 병목 현상\"이 쉽게 나타난다는 점이다. 중앙 파라미터 서 버 노드의 대역폭이 제한된 조건에서, 컴퓨팅 노드의 개수가 지속적으로 증가되고 모두 중앙 파라미터 서버 노 드와 통신함에 따라, 중앙 파라미터 서버 노드는 통신 병목 현상에 직면하게 된다. 탈중앙화 아키텍처의 장점은, 각 컴퓨팅 노드가 일반적으로 이웃 노드와만 정보 인터랙션과 통신을 수행하고, 글로벌 정보 기반 모델 의 계산량이 작으며 훈련 속도가 어느 정도 향상된다는 점이다. 단점은 중앙 노드의 글로벌 정보 동기화가 부족 하여 모델 훈련 정확도가 떨어지거나, 심지어 모델 훈련이 실패한다는 점이다. 동기식 알고리즘의 주요한 사상은, 분산형 훈련 시스템 중 하나의 컴퓨팅 노드가 현재 라운드의 반복을 완료할 때, 반드시 다른 컴퓨팅 노드가 현재 라운드의 반복 태스크를 완료할 때까지 기다려야만 다음 라운드의 훈련 반 복 태스크를 공동으로 처리할 수 있다는 것이다. 전형적인 동기식 알고리즘에는 일괄 동기식 병렬(bulk synchronous parallel, BSP) 알고리즘이 있다. 구체적으로, BSP 알고리즘에서는 어느 컴퓨팅 노드가 현재 반복 태스크를 완료한 후, 상이한 통신 토폴로지 논리를 통해 다른 컴퓨팅 노드와 모델 파라미터 또는 기울기 등 정 보를 동기화해야 한다. 그 다음, 이들은 동일한 \"시작점\"으로 다음 라운드의 반복 과정에 진입한다. 반복이 동 일한 시작점에서 진행되도록 보장하기 위해, BSP 알고리즘은 하나의 글로벌 동기화 장벽(synchronization barrier)을 도입하였다. 이의 작동 원리는 처리 능력이 강하고 반복 속도가 빠른 컴퓨팅 노드들이 모두 동기화 장벽에서 강제로 멈추도록 요구하고, 처리 능력이 약하고 반복 속도가 느린 다른 컴퓨팅 노드가 현재 라운드의 반복 태스크를 완료할 때까지 기다린 다음, 훈련 시스템이 다음 라운드의 반복 태스크를 실행하는 것이다. 동기 식 알고리즘의 장점은 각 컴퓨팅 노드 모델 파라미터의 일관성을 보장함으로써 알고리즘 수렴성 분석이 이론적 근거를 갖도록 보장하는 것이다. 동기식 알고리즘의 단점은 시스템 성능이 훈련 속도가 가장 느린 노드에 의해제한되는 것, 즉 드래그 효과가 존재한다는 점이다. 비동기식 알고리즘의 주요한 사상은, 시스템 중의 어느 컴퓨팅 노드가 현재 라운드의 반복을 완료한 후, 다른 컴퓨팅 노드를 기다릴 필요 없이 계속하여 다음 라운드의 반복을 수행할 수 있다는 것이다. 상기 알고리즘의 장 점은 동기식 알고리즘의 드래그 효과를 피하여 시스템 성능이 충분히 발휘된다는 것이다. 그러나, 비동기식 알 고리즘은 성능 차이가 큰 상이한 컴퓨팅 노드에 의해 새롭거나 오래된 제각각인 로컬 기울기 정보가 생성되어 중앙 노드에 의해 이용되기 때문에, 기울기가 시효성을 잃는 문제가 발생한다. 상술한 바와 같이, 현재에는 딥 러닝 모델 훈련 통신 문제에 대한 관련된 방법과 알고리즘이 존재하지만, 이들 은 알고리즘 논리가 복잡하고 계산량이 많아 알고리즘 성능이 제한되는 부족점이 있다. 딥 러닝 문제점에 대한 효과적인 해결 방안은 일반적으로 빅데이터세트와 빅모델의 지원에 의존한다. 그러나, 기존의 연구에 따르면 저 효율적인 통신 방식으로 신경망 모델을 훈련하는 데 최소 몇 주의 시간이 필요하므로, 시간에 민감한 태스크 시 나리오에 적용하기 어렵다는 것이 입증된 바가 있다."}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원의 실시예의 목적은, 모델의 분산형 훈련 속도를 향상시키고, 중앙 노드와 컴퓨팅 노드 간의 통신 오버 헤드를 감소시키는 정보 융합 방법, 데이터 통신 방법, 정보 융합 장치, 데이터 통신 장치 및 전자 기기와 컴퓨 터 비휘발성 판독 가능 저장 매체를 제공하는 것이다."}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위해, 본 출원의 실시예에서는 분산형 훈련 시스템의 중앙 노드에 응용되는 정보 융합 방 법으로서, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거 조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 단계; 각 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 단계; 상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 상기 글로벌 파 라미터를 각 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신하는 단계를 포함하는 정보 융합 방 법을 제공한다. 여기서, 상기 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라 는 것은, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 기설정된 횟수의 반복 훈련 과정을 수행 완료했다라는 것을 포함한다. 여기서, 각 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하는 상기 단계는, 상기 핵심 노드의 로컬 파라미터의 평균 파라미터를 산출하고, 각 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파 라미터 사이의 편차를 결정하며, 편차가 가장 작은 N개의 컴퓨팅 노드를 다음 라운드의 훈련에 참여하는 핵심 노드로 선택하는 단계를 포함한다. 여기서, 각 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 결정하는 상기 단계는, 각 컴퓨팅 노드가 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에 반환 하도록, 상기 평균 파라미터를 각 컴퓨팅 노드에 송신하는 단계를 포함한다. 여기서, 훈련 모델을 복수의 훈련 서브 모델로 구획하고, 상기 훈련 서브 모델을 각 컴퓨팅 노드에 할당하는 단 계를 더 포함한다. 여기서, 훈련 모델을 복수의 훈련 서브 모델로 구획하는 상기 단계는, 수평 방향 또는 수직 방향에서 훈련 모델을 복수의 훈련 서브 모델로 구획하는 단계를 포함한다. 여기서, 각 컴퓨팅 노드가 대응하는 훈련 샘플에 기반하여 반복 훈련 과정을 수행하도록, 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 단계를 더 포함한다. 여기서, 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 상기 단계는, 샘플링 방법에 기반하여 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하거나, 또는, 복수의 훈련 샘플을 데이터 차원에 따라 분할하여 각 컴퓨팅 노드에 할당하는 단계를 포함한다. 여기서, 샘플링 방법에 기반하여 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 상기 단계는, 복원 랜덤 샘플 링 및/또는 로컬 스크램블링 샘플링 방식을 통해 상기 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 단계; 또 는 복원 랜덤 샘플링 및/또는 전체 스크램블링 샘플링 방식을 통해 상기 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 단계를 포함한다. 여기서, 복수의 훈련 샘플을 데이터 차원에 따라 분할하여 각 컴퓨팅 노드에 할당하는 상기 단계는, 각 훈련 샘 플이 다차원 속성 또는 특징을 갖는 경우, 상이한 속성에 따라 상기 복수의 훈련 샘플을 분할하고, 분할된 샘플 서브 세트를 대응된 컴퓨팅 노드에 할당하는 단계를 포함한다. 여기서, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 상기 단계는, N개의 상기 핵심 노드의 로컬 파라미터의 평균값을 산출하고, 상기 평균값을 상기 글로벌 파라미터로 결정하는 단계를 포함 한다. 상기 목적을 달성하기 위해, 본 출원의 실시예에서는 분산형 훈련 시스템의 컴퓨팅 노드에 응용되는 데이터 통 신 방법으로서, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 상기 중앙 노드에 전송하는 단계; 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노드가 N개의 핵심 노드의 로컬 파라미터를 융합하여 얻은 것인 단계; 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크 를 실행하는 단계를 포함하는 데이터 통신 방법을 제공한다. 여기서, 상기 기설정된 압축 알고리즘은 이고; x는 상기 로컬 파라미터이며, 는 x의 L2 놈(norm)이고, sign(x)는 x의 부호이며, d는 상기 로컬 파라미터 의 차원이고, 이며, 는 x의 i번째 차원이고, C[x]는 압축된 로컬 파라미터이다. 여기서, 상기 중앙 노드에 의해 송신된 평균 파라미터를 획득하고, 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에 반환하는 단계를 더 포함한다. 여기서, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 상기 단계는, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료한 경우, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 중앙 노드에 전송하는 단계를 포함하고; 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하는 상기 단계는, 상기 컴퓨팅 노드가 다음 라운드의 훈 련에 참여하는 핵심 노드로 선택된 경우, 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하는 단계를 포 함하며; 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크를 실행하는 상기 단계는, 상기 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라 미터에 기반하여 다음 라운드의 훈련 태스크를 실행하는 단계를 포함한다. 여기서, 상기 방법은, 복수의 훈련 서브 모델의 일부 훈련 서브 모델을 획득하되, 상기 복수의 훈련 서브 모델 은 상기 훈련 태스크와 연관된 훈련 모델을 구획하여 얻은 서브 모델이고, 상기 복수의 훈련 서브 모델은 상기 분산형 훈련 시스템 중의 각 컴퓨팅 노드에 할당되는 단계; 및/또는 복수의 훈련 샘플의 일부 훈련 샘플을 획득하되, 상기 복수의 훈련 샘플은 상기 훈련 태스크와 연관된 훈련 샘플이고, 상기 복수의 훈련 샘플은 각 컴퓨팅 노드에 할당되며, 각 컴퓨팅 노드는 대응하는 훈련 샘플에 기반하여 반복 훈련 과정을 수행하는 데 사용되는 단 계를 더 포함한다. 상기 목적을 달성하기 위해, 본 출원의 실시예에서는 분산형 훈련 시스템의 중앙 노드에 응용되는 정보 융합 장 치로서, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거 조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 제1 획득 모듈; 각 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 융합 모듈; 상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 상기 글로벌 파 라미터를 각 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신하는 송신 모듈을 포함하는 정보 융 합 장치를 제공한다. 상기 목적을 달성하기 위해, 본 출원의 실시예에서는 분산형 훈련 시스템의 컴퓨팅 노드에 응용되는 데이터 통 신 장치로서, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 상기 중앙 노드에 전송하는 압축 모듈; 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노드가 N개의 핵심 노드의 로컬 파라미터를 융합하여 얻은 것인 제2 획득 모듈; 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크 를 실행하는 실행 모듈을 포함하는 데이터 통신 장치를 제공한다. 상기 목적을 달성하기 위해, 본 출원의 실시예에서는, 컴퓨터 프로그램이 저장되는 메모리; 상기 컴퓨터 프로그램을 실행할 경우, 상기 정보 융합 방법 또는 데이터 통신 방법의 단계를 구현하는 프로세서 를 포함하는 전자 기기를 제공한다. 상기 목적을 달성하기 위해, 본 출원의 실시예에서는, 컴퓨터 프로그램이 저장되어 있는 컴퓨터 비휘발성 판독 가능 저장 매체로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 상기 정보 융합 방법 또는 데이터 통신 방법의 단계가 구현되는 컴퓨터 비휘발성 판독 가능 저장 매체를 제공한다."}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원의 실시예에 따른 정보 융합 방법에 있어서, 중앙 노드는 N개의 핵심 노드만 선택하여 정보 융합을 수행 하므로, 융합되는 컴퓨팅 노드의 개수가 효과적으로 줄어들고, 다음 라운드의 훈련에서 N개의 핵심 노드만 선택 하여 훈련 태스크를 실행하며, 다른 컴퓨팅 노드는 훈련 태스크를 실행하지 않으므로, 모델의 분산형 훈련 속도 가 향상된다. 본 출원의 실시예에 따른 데이터 통신 방법에 있어서, 컴퓨팅 노드는 자신의 로컬 파라미터를 중앙 노드에 전송 하기 전에, 기설정된 압축 알고리즘에 기반하여 압축을 수행하므로, 중앙 노드와 컴퓨팅 노드 간의 통신량이 줄 어들고, 중앙 노드와 컴퓨팅 노드 간의 통신 오버헤드가 감소된다. 본 출원의 실시예에서는 상기 기술적 효과를 마찬가지로 달성할 수 있는 정보 융합 장치, 데이터 통신 장치 및 전자 기기와 컴퓨터 비휘발성 판독 가능 저장 매체를 더 개시한다. 위의 일반적인 설명과 후술되는 세부 사항에 대한 설명은 단지 예시적인 것이며, 본 출원의 실시예를 제한할 수 없음을 이해해야 한다."}
{"patent_id": "10-2024-7021630", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 출원의 실시예의 도면을 참조하면서 본 출원의 실시예의 기술적 해결수단을 명확하고 완전하게 설명하 기로 한다. 물론, 설명된 실시예는 본 출원의 전부의 실시예가 아니라 일부 실시예일 뿐이다. 본 출원의 실시예 에 기반하여, 당업자가 진보적 노력을 기울이지 않고 획득한 다른 실시예들은 모두 본 출원의 보호 범위에 속한 다. 이 밖에, 본 출원의 실시예에 있어서, \"제1\", \"제2\" 등은 유사한 객체를 구별하기 위한 것이고, 반드시 특 정된 순서 또는 선후 순서를 설명하는데 사용되는 것이 아니다. 본 출원의 실시예에 따른 파라미터 서버 아키텍처를 지향하는 분산형 노드 정보 융합 프레임워크 도면은, 도 2 에 도시된 바와 같이, 데이터/모델 구획 부재, 파라미터 서버 아키텍처 분산형 훈련 시스템 부재, 노드 선택과 데이터 압축 기술 부재 및 훈련 결과 출력 부재를 포함한다. 데이터/모델 구획 부재는 주로 처리 대상인 데이터세트와 모델의 입력 태스크를 완료한다. 여기서, 데이터 분할 모듈은 주로 데이터세트의 분할 태스크를 담당하며, 분할된 서브 데이터세트를 대응된 컴퓨팅 노드에 배포하고; 모델 분할 모듈은 주로 원시 대형 모델을 규모가 작은 여러 개의 서브 모델로 분할하는 것을 담당한다. 파라미터 서버 아키텍처 분산형 훈련 시스템 부재는 주로 실제 훈련 태스크를 완료하는 데 사용된다. 노드 선택과 데이터 압축 기술 부재는 전체 분산형 훈련 시스템 프레임워크의 핵심 기술이다. 여기서, 노드 선 택 모듈은 핵심 컴퓨팅 노드의 선택 태스크를 완료하고, 모든 컴퓨팅 노드의 정보 산출을 회피함으로써, 파라미 터 서버의 \"통신 병목 현상\" 문제를 효과적으로 완화하며; 데이터 압축 모듈은 데이터의 관점에서 통신량을 압 축하여 모델 훈련 속도를 향상시킨다. 예를 들어, 도 2에서 원시 분산형 훈련 시스템은 컴퓨팅 노드 1, 컴퓨팅 노드 2, 컴퓨팅 노드 3 및 파라미터 서버 노드를 포함하고, 노드 선택 모듈이 설계한 선택 방법을 통해, 조건에 부합되지 않는 컴퓨팅 노드 2가 제거된다. 따라서, 후속되는 반복 과정에서 실제로 산출에 참여하는 것은 컴퓨 팅 노드 1, 컴퓨팅 노드 3 및 파라미터 서버 노드뿐이다. 또한, 컴퓨팅 노드 1 및 컴퓨팅 노드 3의 통신 정보 (예컨대, 기울기, 모델 파라미터 등)에 대해 각각 데이터 압축 기술을 사용하여 통신량을 감소시킨다. 파라미터 서버 아키텍처에는 주로 worker 및 server의 두 가지 역할이 존재한다. worker가 주로 담당하는 것 중 하나는 로컬 데이터 샘플에 기반하여 로컬 훈련 태스크를 완료하는 것이고, 다른 하나는 클라이언트 인터페이스를 통해 server와 통신하는 것이다. server가 주로 담당하는 것 중 하나는 각 worker로부터 송신된 로컬 기울기를 집계 하거나 융합하는 것이고, 다른 하나는 글로벌 모델 파라미터를 업데이트하여 각 worker에 반환하는 것이다. 훈련 결과 출력 부재는 훈련 태스크의 글로벌 솔루션을 출력하고 가시화 방식으로 보여주는 것을 담당하여, 후 속되는 개선과 최적화를 용이하게 한다. 상술한 바와 같이, 각 부재는 자체 임무를 수행하고, 협력을 통해 다양하고 복잡한 훈련 태스크를 완료한다. 본 출원의 실시예에서는 모델의 분산형 훈련 속도를 향상시키는 정보 융합 방법을 개시한다. 도 3을 참조하면, 이는 예시적인 일 실시예에 따라 도시된 정보 융합 방법의 흐름도이고, 도 3에 도시된 바와 같이, 상기 방법은 하기 단계 S101~ S103을 포함한다.S101에서는, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거 조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득한다. 본 실시예는 분산형 훈련 시스템에 응용되고, 상기 분산형 훈련 시스템은 복수의 컴퓨팅 노드(worker) 및 1개의 중앙 노드(server)를 포함하며, 각각의 worker는 server와 양방향으로 연결되는데, 이는 데이터가 양방향으로 전달될 수 있음을 의미한다. 그러나, worker와 worker 사이는 직접적으로 연결되지 않는다. 각각의 worker는 모 두 server가 제공하는 글로벌 파라미터를 사용하여 각자의 훈련 태스크를 독립적으로 진행할 수 있다. 상세하게 는, 각각의 worker는 다음과 같은 두 가지 동작을 통해 server와 통신하는데, 하나는 worker가 server로부터 글 로벌 파라미터를 획득하는 PULL(풀)이고; 다른 하나는 worker가 server에 로컬 파라미터를 송신하는 PUSH(푸 시)이다. 본 실시예에서 실행 주체는 중앙 노드이다. 선택적인 실시예에 있어서, worker는 각자의 로컬 파라미터 를 server에 송신하고, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료한 경우, server는 각 worker의 로컬 파라미 터를 획득할 수 있다. 핵심 노드는 금번 라운드의 훈련이 수행되기 전에 중앙 노드가 모든 컴퓨팅 노드에서 선 택한 훈련에 참여하는 N개의 노드이고, N＝1이거나, N＝2이거나, N은 3 이상의 양의 정수이며; 선택적인 일 실 시형태로서, 상기 훈련에 참여하는 N개의 노드는 전체 컴퓨팅 노드의 일부 노드일 수 있다. 선택적으로, 통신 트리거 조건은 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 기설정된 횟수의 반복 훈련 과정을 수행 완료 한 것일 수 있다. 본 실시예에서는 기설정된 횟수에 대해 한정하지 않고, 예를 들어, 기설정된 횟수가 1이면, 반복이 완료될 때마다 worker와 server가 로컬 파라미터 동기화를 수행하고, 기설정된 횟수가 10이면, 각 worker가 각각 10번의 반복을 완료한 다음 server와 함께 로컬 파라미터 동기화를 수행하며, 기설정된 횟수가 T(총 반복 횟수)이면, 각 worker가 모든 반복을 완료한 후, 마지막에 server와 함께 로컬 파라미터 동기화를 수 행한다. S102에서는, 각 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는다. 본 단계에서는, 다음 라운드의 훈련을 위해 N개의 핵심 노드를 다시 선택하고, N개의 핵심 노드의 로컬 파라미 터를 융합하여 글로벌 파라미터를 얻으며, 즉 N개의 핵심 노드의 로컬 파라미터의 평균값을 산출하여 글로벌 파 라미터로 사용한다. 선택적인 일 실시형태로서, 각 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하는 상 기 단계는, 상기 핵심 노드의 로컬 파라미터의 평균 파라미터를 산출하고, 각 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 결정하며, 편차가 가장 작은 N개의 컴퓨팅 노드를 다음 라운드의 훈련에 참 여하는 핵심 노드로 선택하는 단계를 포함하고; 가능한 일 실시형태로서, 선택된 상기 N개의 컴퓨팅 노드는 상 기 각 컴퓨팅 노드의 일부 컴퓨팅 노드일 수 있다. 선택적인 실시예에 있어서, server는 하나의 평균 파라미터 를 산출하여 r번째 worker의 로컬 파라미터와 평균 파라미터 사이의 편차 를 결정하고, , , ...., , ..., 을 큰 것에서 작은 것 순으로 배열하고, 그 중에서 작은 편인 N개의 worker를 핵심 노드로 선택 한다. 가능한 일 실시형태로서, 각 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 결정하는 상기 단계는, 각 컴퓨팅 노드가 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드 에 반환하도록, 상기 평균 파라미터를 각 컴퓨팅 노드에 송신하는 단계를 포함한다. 선택적인 실시예에 있어서, server는 산출하여 얻은 평균 파라미터를 각 worker에 반환하고, 각 worker는 자신 의 로컬 파라미터와 평균 파라미터 사이의 편차를 산출하여 server에 반환한다. S103에서는, 상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 상 기 글로벌 파라미터를 각 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신한다. 본 단계에서는, 중앙 노드는 글로벌 파라미터를 각 컴퓨팅 노드에 송신하고, 컴퓨팅 노드는 자신의 로컬 파라미 터를 상기 글로벌 파라미터로 업데이트한다. 그러나, 핵심 노드만 다음 라운드의 훈련 태스크를 실행하고, 핵심노드로 선택되지 않은 다른 컴퓨팅 노드는 다음 라운드의 훈련 태스크를 실행하지 않으므로, 모델의 분산형 훈 련 속도가 향상된다. 파라미터 서버 아키텍처를 지향하는 분산형 노드 정보 융합 알고리즘의 입력은 총 반복 횟수 T, 학습률 , 초 기 모델 파라미터 x0, 반복 통신 트리거 조건 , 핵심 노드의 수량 N이고, 출력은 글로벌 수렴 모델 파라미터 xT이다. 실행 과정은 다음과 같다. for 반복 횟수 t＝0, 1, ..., T do 각각의 worker는 컴퓨팅 노드 훈련 함수 Worker_Training(t)를 병렬 수행하고; if 반복 횟수 t가 통신 트리거 조건 do를 만족하면 server는 서버 노드 훈련 함수 Server_Training(t)를 수행하고; end if end for Return 글로벌 수렴 모델 파라미터 xT 여기서, 컴퓨팅 노드 훈련 함수 Worker_Training(t)는 다음과 같이 정의될 수 있다. Function Worker_Training(t) r번째 worker가 1번의 랜덤 샘플링을 수행하여 1개의 훈련 샘플 을 획득한다고 가정하면; 상기 worker는 server로부터 최신 글로벌 파라미터 x를 PULL하고; 파라미터 x와 훈련 샘플 에 기반하여 로컬 랜덤 기울기 를 산출하며; worker는 로컬 파라미터 를 업데이트하고; worker는 기울기 압축 함수 Compress_gradient()를 호출하여 로 하며; worker는 를 server에 PUSH하고; end Function 파라미터 서버 노드 훈련 함수 Server_Training(t)는 다음과 같이 정의된다. Function Server_Training(t) 컴퓨팅 노드 선택 함수 Worker_Selction()를 호출하여 N개의 핵심 노드를 선택하여 글로벌 파라미터 정보 융합 과 동기화를 수행하며; 글로벌 모델 파라미터 정보 융합 을 산출하고; server는 상기 글로벌 파라미터를 각 worker에 송신하고; end Function 본 출원의 실시예에 따른 정보 융합 방법에서, 중앙 노드는 N개의 핵심 노드만 선택하여 정보 융합을 수행하므 로, 융합되는 컴퓨팅 노드의 개수가 효과적으로 줄어들고, 다음 라운드의 훈련에서 N개의 핵심 노드만 선택하여 훈련 태스크를 실행하며, 다른 컴퓨팅 노드는 훈련 태스크를 실행하지 않으므로, 모델의 분산형 훈련 속도가 향 상된다.딥 러닝 모델 훈련 태스크에 필요한 두 가지 전제가 데이터와 모델이라는 것을 이해할 수 있다. 딥 러닝 모델의 훈련은 고품질 데이터세트에 의존한다. 데이터/모델 구획 부재는 처리 대상인 데이터세트와 모델을 딥 러닝 훈 련 태스크의 입력으로 사용하고, 사용자 액세스 데이터 또는 모델을 위해 인터페이스를 제공하는 것을 담당한다. 일반적으로, 입력된 딥 러닝 모델/데이터세트는 규모가 엄청나게 크기 때문에 처리가 어렵다. 따라서 분할 정복 이라는 사상을 이용하여 원시 대규모 데이터세트 또는 모델을 분해함으로써 처리 과정이 상대적으로 용이해지도 록 한다. 상기 어셈블리는 데이터 분할 모듈(데이터 병렬이라고도 함) 및 모델 분할 모듈(모델 병렬이라고도 함)을 포함한다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 훈련 모델을 복수의 훈련 서브 모델로 구획하고, 상기 훈련 서브 모델을 각 컴퓨팅 노드에 할당하는 단계를 더 포함한다. 선택적인 실시예에 있어서, 만약 훈련 태스크 모델이 너무 크고 스탠드얼론 방식으로 저장될 수 없으면, 모델을 효과적으로 분할하여 훈련 태스크가 수행 가능해지도록 만들어야 한다. 모델 병렬은 모델 파라미터를 복수의 서 브 모델로 분할하고, 각 서브 모델은 상이한 컴퓨팅 노드에 할당된다. 주목할만 한 것은, 신경망 모델의 특수성, 즉 신경망 모델의 계층 구조로 인해, 모델 병렬을 응용하는 데 있어서 뚜렷한 장점이 있다. 신경망 모 델은 상이한 분할 방식에 따라 수평 분할과 수직 분할로 구분될 수 있으며, 즉 훈련 모델을 복수의 훈련 서브 모델로 구획하는 상기 단계는, 수평 방향 또는 수직 방향에서 훈련 모델을 복수의 훈련 서브 모델로 구획하는 단계를 포함한다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 각 컴퓨팅 노드가 대응하는 훈련 샘플에 기반하여 반복 훈련 과정을 수행하도록, 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 단계를 더 포함한다. 데이터 병렬은 병렬 컴퓨팅 환경에 놓인 복수의 프로세서(컴퓨팅 노드)의 세분화 데이터세트에 의존하여 분할 컴퓨팅을 구현한다. 데이터 병렬 알고리즘은 데이터를 상이한 병렬 컴퓨팅 노드에 분포시키는데 중점을 두고 있 고, 각 컴퓨팅 노드는 동일한 컴퓨팅 모델을 실행한다. 데이터 병렬 모드는 데이터세트의 상이한 분할 전략에 따라, 샘플 기반 데이터 병렬 및 샘플 차원 기반 데이터 병렬로 구분된다. 즉, 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 상기 단계는, 샘플링 방법에 기반하여 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하거나, 또는, 복수의 훈련 샘플을 데이터 차원에 따라 분할하여 각 컴퓨팅 노드에 할당하는 단계를 포함한다. 샘플 기 반 데이터 병렬은, 분산형 훈련 시스템 데이터세트에 복수의 데이터 샘플 및 복수의 컴퓨팅 노드가 포함된다고 가정하면, 복원 랜덤 샘플링과 로컬(글로벌) 스크램블링 샘플링의 두 가지 방식을 통해 이 샘플을 복수의 컴퓨 팅 노드에 할당한다. 샘플 차원 기반 데이터 병렬은, 데이터세트에 복수의 샘플이 포함되고 각각의 샘플이 다차 원 속성 또는 특징을 가지며, 분산형 훈련 시스템이 복수의 컴퓨팅 노드를 포함한다고 가정하면, 샘플 속성 차 원의 관점에서 복수의 샘플을 상이한 속성에 따라 분할하고, 분할된 샘플 서브 세트를 대응된 컴퓨팅 노드에 할 당한다. 또한, 일부 시나리오에서는 모델 분할 모듈과 데이터 분할 모듈을 동시에 사용함으로써, 데이터와 모델의 혼합 분할 전략을 생성한다. 데이터와 모델의 혼합 분할 전략(혼합 병렬)은, 이름에서 알 수 있듯이, 더 복잡한 모델 훈련 태스크에 응용될 수 있도록, 데이터 병렬 모드와 모델 병렬 모드를 동시에 결합하여, 한편으로는 데이터세 트를 분할하고 다른 한편으로는 모델도 분할하는 것이다. 본 출원의 실시예에서는 중앙 노드와 컴퓨팅 노드 간의 통신 오버헤드를 감소시키는 데이터 통신 방법을 개시한 다. 도 4를 참조하면, 이는 예시적인 일 실시예에 따라 도시된 데이터 통신 방법의 흐름도이고, 도 4에 도시된 바와 같이, 상기 방법은 하기 단계 S201~ S203을 포함한다. S201에서는, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 상기 중앙 노드에 전송한다. 본 실시예의 실행 주체는 분산형 훈련 시스템의 컴퓨팅 노드이고, 선택적인 실시예에 있어서, 컴퓨팅 노드는 자 신의 로컬 파라미터를 중앙 노드에 전송해야 한다. 실제 심층 신경망 모델 훈련 시나리오에 있어서, 연구에 따르면 기울기 계산 또는 통신이 총 GPU 훈련 시간의 94％ 이상을 차지하여 훈련 효율을 심각하게 제한하는 것으로 나타났다. 통신량을 줄이기 위해, 개선된 1-bit 압축 기술을 사용한다. 원시 1-bit 압축 기술은 다음과 같이 정의된다.C[*]가 압축 동작 연산을 나타내고, 이 벡터의 L1 놈 구하기 연산을 나타내며, 가 하나의 d 차원 실수 벡터를 나타내고, sign(x)가 벡터 x의 부호를 취함을 나타낸다고 가정하면, 벡터 x에 대해 1-bit 압 축 동작 을 수행하며; 상기 압축 과정에서는 통신량이 줄어들 수 있으나, 일부 상황에서는 오류 코드가 생성될 수 있다. 예를 들어, 벡터 x=[1, -2, 3] 및 벡터 y=[1, 2, 3]의 경우, C[x]=(|1|+|-2|+|3|)/3*(+); C[y]=(|1|+|2|+|3|)/3*(+); 상기 2개의 벡터 압축 결과는 동일하다. 다시 말해서, 상이한 벡터에 대해 원시 1-bit 압축을 사용한 결과가 동 일하므로, 이러한 압축이 오류 코드를 생성하게 되는 것은 자명하다. 반대로, 압축의 목표는 최대한 차별화되어 야 한다. 이를 위해, 본 실시예에서는 개선된 1-bit(비트) 압축 기술을 설계하여 상기 문제점을 방지한다. 개선 된 1-bit 압축 기술(즉 기설정된 압축 알고리즘)은 다음과 같다. ; 여기서, x는 상기 로컬 파라미터이며, 는 x의 L2 놈이고, sign(x)는 x의 부호이며, d는 상기 로컬 파라미 터의 차원이고, 이며, 는 x의 i번째 차원이고, C[x]는 압축된 로컬 파라미터이다. 개선된 수단과 원래의 수단 사이에는 주로 다음과 같은 두 가지 차이점이 존재한다. 하나는 λ 계수를 사용하여 오류 코드 문제를 방지하는 것이고; 다른 하나는 L2 놈을 사용하여 원시 L1 놈을 대체하는 것이며, 그 이유는 L2 놈의 수학적 특성이 더욱 우수하기 때문이다. 보다시피, 상기 기설정된 압축 알고리즘을 통해 원시 훈련 데 이터의 32bit 또는 16bit 데이터를 1bit로 압축할 수 있어 중앙 노드와 컴퓨팅 노드 간의 통신 오버헤드가 감소 된다. 선택적으로, 본 실시예는, 상기 중앙 노드에 의해 송신된 평균 파라미터를 획득하고, 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에 반환하는 단계를 더 포함한다. S202에서는, 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노 드가 N개의 핵심 노드의 로컬 파라미터를 융합하여 얻은 것이다. S203에서는, 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크를 실행한다. 본 출원의 실시예에 따른 데이터 통신 방법에서, 컴퓨팅 노드는 자신의 로컬 파라미터를 중앙 노드에 전송하기 전에, 기설정된 압축 알고리즘에 기반하여 압축을 수행하므로, 중앙 노드와 컴퓨팅 노드 간의 통신량이 줄어들 고, 중앙 노드와 컴퓨팅 노드 간의 통신 오버헤드가 감소된다. 이하, 본 출원의 실시예에 따른 정보 융합 장치를 설명하며, 아래에서 설명되는 정보 융합 장치와 위에서 설명 된 정보 융합 방법은 서로 참조될 수 있다. 도 5를 참조하면, 이는 예시적인 일 실시예에 따라 도시된 정보 융합 장치의 구조도이며, 도 5에 도시된 바와 같이, 상기 장치는, 금번 라운드의 훈련에 참여하는 핵심 노드가 모두 금번 라운드의 훈련 태스크를 실행 완료했다라는 통신 트리거 조건이 만족될 때, 상기 분산형 훈련 시스템 중 각 컴퓨팅 노드의 로컬 파라미터를 획득하는 제1 획득 모듈 ; 각 컴퓨팅 노드에서 다음 라운드의 훈련에 참여하는 N개의 핵심 노드를 선택하고, N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 융합 모듈; 상기 핵심 노드가 상기 글로벌 파라미터에 기반하여 다음 라운드의 훈련 태스크를 실행하도록, 글로벌 파라미터 를 각 컴퓨팅 노드에 송신하고 상기 핵심 노드에 훈련 커맨드를 송신하는 송신 모듈을 포함한다. 본 출원의 실시예에 따른 정보 융합 장치에서, 중앙 노드는 N개의 핵심 노드만 선택하여 정보 융합을 수행하므 로, 융합되는 컴퓨팅 노드의 개수가 효과적으로 줄어들고, 다음 라운드의 훈련에서 N개의 핵심 노드만 선택하여 훈련 태스크를 실행하며, 다른 컴퓨팅 노드는 훈련 태스크를 실행하지 않으므로, 모델의 분산형 훈련 속도가 향 상된다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 상기 통신 트리거 조건은 금번 라운드의 훈련에 참여하는 핵 심 노드가 모두 기설정된 횟수의 반복 훈련 과정을 수행 완료한 것이다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 상기 융합 모듈은, 상기 핵심 노드의 로컬 파라미터의 평균 파라미터를 산출하고, 각 컴퓨팅 노드의 로컬 파라미터와 상기 평균 파 라미터 사이의 편차를 결정하며, 편차가 가장 작은 N개의 컴퓨팅 노드를 다음 라운드의 훈련에 참여하는 핵심 노드로 선택하는 선택 유닛; N개의 상기 핵심 노드의 로컬 파라미터를 융합하여 글로벌 파라미터를 얻는 융합 유닛을 포함한다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 상기 선택 유닛은, 각 컴퓨팅 노드가 자신의 로컬 파라미터 와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에 반환하도록, 상기 핵심 노드의 로컬 파라미터 의 평균 파라미터를 산출하고, 상기 평균 파라미터를 각 컴퓨팅 노드에 송신하며, 편차가 가장 작은 N개의 컴퓨 팅 노드를 다음 라운드의 훈련에 참여하는 핵심 노드로 선택한다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 훈련 모델을 복수의 훈련 서브 모델로 구획하고, 상기 훈련 서브 모델을 각 컴퓨팅 노드에 할당하는 제1 할당 모듈을 더 포함한다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 상기 제1 할당 모듈은, 수평 방향 또는 수직 방향에서 훈련 모델을 복수의 훈련 서브 모델로 구획하고, 상기 훈련 서브 모델을 각 컴퓨팅 노드에 할당한다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 각 컴퓨팅 노드가 대응하는 훈련 샘플에 기반하여 반복 훈련 과정을 수행하도록, 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하는 제2 할당 모듈을 더 포함한다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 상기 제2 할당 모듈은, 샘플링 방법에 기반하여 복수의 훈련 샘플을 각 컴퓨팅 노드에 할당하거나, 또는, 복수의 훈련 샘플을 데이터 차원에 따라 분할하여 각 컴퓨팅 노드 에 할당한다. 이하, 본 출원의 실시예에 따른 데이터 통신 장치를 설명하며, 아래에서 설명되는 데이터 통신 장치와 위에서 설명된 데이터 통신 방법은 서로 참조될 수 있다. 도 6을 참조하면, 이는 예시적인 일 실시예에 따라 도시된 데이터 통신 장치의 구조도이며, 도 6에 도시된 바와 같이, 상기 장치는, 통신 트리거 조건이 만족될 때, 기설정된 압축 알고리즘에 기반하여 자신의 로컬 파라미터에 대해 압축 동작을 수행하고, 압축된 로컬 파라미터를 상기 중앙 노드에 전송하는 압축 모듈; 상기 중앙 노드에 의해 송신된 글로벌 파라미터를 획득하되, 상기 글로벌 파라미터는 상기 중앙 노드가 N개의 핵심 노드의 로컬 파라미터를 융합하여 얻은 것인 제2 획득 모듈; 중앙 노드에 의해 송신된 훈련 커맨드가 수신된 경우, 상기 글로벌 파라미터에 기반하여 대응하는 훈련 태스크 를 실행하는 실행 모듈을 포함한다. 본 출원의 실시예에 따른 데이터 통신 장치에서, 컴퓨팅 노드는 자신의 로컬 파라미터를 중앙 노드에 전송하기 전에, 기설정된 압축 알고리즘에 기반하여 압축을 수행하므로, 중앙 노드와 컴퓨팅 노드 간의 통신량이 줄어들 고, 중앙 노드와 컴퓨팅 노드 간의 통신 오버헤드가 감소된다.상기 실시예를 토대로, 선택적인 일 실시형태로서, 상기 기설정된 압축 알고리즘은 이고; x는 상기 로컬 파라미터이며, 는 x의 L2 놈이고, sign(x)는 x의 부호이며, d는 상기 로컬 파라미터의 차원 이고, 이며, 는 x의 i번째 차원이고, C[x]는 압축된 로컬 파라미터이다. 상기 실시예를 토대로, 선택적인 일 실시형태로서, 상기 중앙 노드에 의해 송신된 평균 파라미터를 획득하고, 자신의 로컬 파라미터와 상기 평균 파라미터 사이의 편차를 산출하여 상기 중앙 노드에 반환하는 컴퓨팅 모듈을 더 포함한다. 상기 실시예의 장치에 관하여, 각 모듈이 동작을 수행하는 선택적인 방식은 해당 방법에 관한 실시예에서 이미 상세하게 설명되었으므로, 여기서는 상세하게 설명하지 않는다. 상기 프로그램 모듈의 하드웨어 구현에 기반하여, 본 출원의 실시예에 따른 방법을 구현하기 위해, 본 출원의 실시예는 전자 기기를 더 제공한다. 도 7은 예시적인 일 실시예에 따라 도시된 전자 기기의 구조도이고, 도 7에 도시된 바와 같이, 전자 기기는, 네트워크 기기와 같은 다른 기기와 정보 인터랙션을 수행할 수 있는 통신 인터페이스; 통신 인터페이스에 연결되어 다른 기기와 정보 인터랙션을 수행하고, 컴퓨터 프로그램을 실행할 때, 상기 하 나 또는 복수의 기술적 해결수단에 따른 정보 융합 방법 또는 데이터 통신 방법을 수행하는 프로세서를 포함 한다. 상기 컴퓨터 프로그램은 메모리에 저장된다. 물론, 실제 응용 시, 전자 기기 중의 각 어셈블리는 버스 시스템에 의해 커플링된다. 버스 시스템은 이러 한 어셈블리들 사이의 연결 통신을 구현함을 이해할 수 있다. 버스 시스템은 데이터 버스를 포함하는 것 이 외에도, 전원 버스, 제어 버스 및 상태 신호 버스를 포함한다. 그러나 명확한 설명을 위해, 도 7에서는 각 버스 를 모두 버스 시스템으로 표시한다. 본 출원의 실시예에 따른 메모리는 다양한 유형의 데이터를 저장하여 전자 기기의 동작을 지원한다. 이러한 데이터의 예시로는, 전자 기기에서 구현되는 임의의 컴퓨터 프로그램을 포함한다. 메모리는 휘발성 메모리 또는 비휘발성 메모리일 수 있고, 휘발성 및 비휘발성 메모리를 모두 포함할 수도 있음을 이해할 수 있다. 여기서, 비휘발성 메모리는 판독 전용 메모리(ROM, Read Only Memory), 프로그램 가능 판독 전용 메모리(PROM, Programmable Read-Only Memory), 소거 가능 프로그램 가능 판독 전용 메모리(EPROM, Erasable Programmable Read-Only Memory), 전기적 소거 가능 프로그램 가능 판독 전용 메모리(EEPROM, Electrically Erasable Programmable Read-Only Memory), 강자성 랜덤 액세스 메모리(FRAM, ferromagnetic random access memory), 플래시 메모리(Flash Memory), 자기 표면 메모리, 광 디스크, 또는 판독 전용 콤팩트 디스크(CD-ROM, Compact Disc Read-Only Memory)일 수 있고; 자기 표면 메모리는 자기 디스크 메모리 또는 자 기 테이프 메모리일 수 있다. 휘발성 메모리는 외부 고속 캐시로 사용되는 랜덤 액세스 메모리(RAM, Random Access Memory)일 수 있다. 한정적이 아닌 예시적인 설명으로서, 정적 랜덤 액세스 메모리(SRAM, Static Random Access Memory), 동기식 정적 랜덤 액세스 메모리(SSRAM, Synchronous Static Random Access Memory), 동적 랜덤 액세스 메모리(DRAM, Dynamic Random Access Memory), 동기식 동적 랜덤 액세스 메모리(SDRAM, Synchronous Dynamic Random Access Memory), 2배속 데이터 레이트 동기식 동적 랜덤 액세스 메모리(DDRSDRAM, Double Data Rate Synchronous Dynamic Random Access Memory), 향상된 동기식 동적 랜덤 액세스 메모리 (ESDRAM, Enhanced Synchronous Dynamic Random Access Memor), 싱크링크 동적 랜덤 액세스 메모리(SLDRAM, SyncLink Dynamic Random Access Memory), 다이렉트 램버스 랜덤 액세스 메모리(DRRAM, Direct Rambus Random Access Memory)와 같은 많은 형태의 RAM을 사용할 수 있다. 본 출원의 실시예에 설명된 메모리는 이들 및 임 의의 다른 적합한 유형의 메모리를 포함하나 이에 제한되지 않는다. 본 출원의 실시예에서 개시된 상기 방법은 프로세서에 응용되거나, 또는 프로세서에 의해 구현될 수 있다. 프로세서는 신호 처리 능력을 갖는 하나의 집적 회로 칩일 수 있다. 구현 과정에서, 상기 방법의 각 단계들은 프로세서의 하드웨어의 집적 논리 회로 또는 소프트웨어 형태의 명령에 의해 완료될 수 있다. 상기프로세서는 범용 프로세서, DSP, 또는 다른 프로그램 가능 논리 소자, 개별 게이트 또는 트랜지스터 논리 소 자, 개별 하드웨어 어셈블리 등일 수 있다. 프로세서는 본 출원의 실시예에서 개시된 각 방법, 단계 및 논리 블록도를 구현하거나 수행할 수 있다. 범용 프로세서는 마이크로 프로세서 또는 임의의 통상적인 프로세서 등일 수 있다. 본 출원의 실시예에 개시된 방법의 단계와 결합하면, 하드웨어 디코딩 프로세서에 의해 직접 실행 완 료되거나, 또는 디코딩 프로세서의 하드웨어 및 소프트웨어 모듈의 조합에 의해 실행 완료될 수 있다. 소프트웨 어 모듈은 메모리에 위치하는 저장 매체에 위치할 수 있고, 프로세서는 메모리 중의 프로그램을 판독 한 후 하드웨어와 결합하여 전술한 방법의 단계들을 완료한다. 프로세서에 의해 상기 프로그램이 실행될 경우, 본 출원의 실시예의 각 방법의 상응한 프로세스가 구현되며, 간결함을 위해 여기서는 설명을 생략한다. 예시적인 실시예에 있어서, 본 출원의 실시예는 저장 매체, 즉 컴퓨터 비휘발성 판독 가능 저장 매체일 수 있는 컴퓨터 저장 매체를 더 제공하고, 예를 들어, 컴퓨터 프로그램이 저장된 메모리를 포함하며, 상기 컴퓨터 프 로그램은 프로세서에 의해 실행되어 전술한 정보 융합 방법 또는 데이터 통신 방법의 상기 단계를 완료할 수 있다. 컴퓨터 비휘발성 판독 가능 저장 매체는 FRAM, ROM, PROM, EPROM, EEPROM, Flash Memory, 자기 표면 메 모리, 광 디스크 또는 CD-ROM 등 메모리일 수 있다. 당업자라면, 상기 방법 실시예의 전부 또는 일부 단계의 구현은 프로그램 명령에 관련되는 하드웨어를 통해 완 료될 수 있고, 전술한 프로그램은 하나의 컴퓨터 판독 가능 저장 매체에 저장될 수 있으며, 상기 프로그램이 실 행될 경우, 상기 방법 실시예의 단계가 수행됨을 이해할 수 있다. 전술한 저장 매체는, 이동식 저장 장치, ROM, RAM, 자기 디스크 또는 광 디스크 등 프로그램 코드를 저장할 수 있는 다양한 매체를 포함한다. 또는, 본 출원의 실시예의 상기 집적된 유닛이 소프트웨어 기능 모듈의 형태로 구현되고 독립적인 제품으로 판 매되거나 사용될 경우, 하나의 컴퓨터 판독 가능 저장 매체에 저장될 수도 있다. 이러한 이해에 기반하면, 본 출원의 실시예의 기술적 해결수단은 본질적으로 또는 종래 기술에 대해 기여하는 부분은 소프트웨어 제품 형태 로 구현될 수 있고, 상기 컴퓨터 소프트웨어 제품은 하나의 전자 기기(개인용 컴퓨터, 서버 또는 네트워크 기기 등일 수 있음)가 본 출원의 각 실시예의 상기 방법의 전부 또는 일부를 수행하도록 하는 복수의 명령이 포함된 하나의 저장 매체에 저장된다. 전술한 저장 매체는 이동식 저장 장치, ROM, RAM, 자기 디스크 또는 광 디스크 등 프로그램 코드를 저장할 수 있는 다양한 매체를 포함한다. 이상은 본 출원의 바람직한 실시형태일 뿐이며, 본 출원의 실시예의 보호 범위는 이에 의해 한정되지 않고, 당 업자라면 본 출원의 실시예에 개시된 기술적 범위 내에서 변화 또는 대체를 용이하게 생각해낼 수 있으며, 이들 은 모두 본 출원의 실시예의 보호 범위에 포함되어야 한다. 따라서, 본 출원의 실시예의 보호 범위는 특허청구 범위의 보호 범위를 기준으로 하여야 한다."}
{"patent_id": "10-2024-7021630", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하, 본 출원의 실시예 또는 종래 기술의 기술적 해결수단을 보다 명확하게 설명하기 위해, 실시예 또는 종래 기술에 대한 설명에서 사용해야 하는 도면을 간단하게 설명하며, 아래의 설명에서 도면은 단지 본 출원의 일부실시예일 뿐이고, 당업자라면 진보적 노력을 기울이지 않고도 이러한 도면에 따라 다른 도면을 획득할 수 있다 는 것은 자명하다. 도면은 본 개시를 더 잘 이해할 수 있도록 하기 위해 제공되는 것으로, 명세서의 일부를 구 성하고, 아래의 선택적인 실시형태와 함께 본 출원을 해석하는 데 사용되지만, 본 출원을 한정하지 않는다. 도 면은 다음과 같다. 도 1은 중앙화 아키텍처와 탈중앙화 아키텍처의 모식도이다. 도 2는 예시적인 일 실시예에 따라 도시된 파라미터 서버 아키텍처를 지향하는 분산형 노드 정보 융합 프레임워 크의 도면이다. 도 3은 예시적인 일 실시예에 따라 도시된 정보 융합 방법의 흐름도이다. 도 4는 예시적인 일 실시예에 따라 도시된 데이터 통신 방법의 흐름도이다. 도 5는 예시적인 일 실시예에 따라 도시된 정보 융합 장치의 구조도이다. 도 6은 예시적인 일 실시예에 따라 도시된 데이터 통신 장치의 구조도이다. 도 7은 예시적인 일 실시예에 따라 도시된 전자 기기의 구조도이다."}
