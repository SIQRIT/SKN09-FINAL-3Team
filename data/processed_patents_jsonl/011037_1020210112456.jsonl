{"patent_id": "10-2021-0112456", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0030337", "출원번호": "10-2021-0112456", "발명의 명칭": "데이터 전처리를 통한 문헌내 화학물질 개체명 인식 방법 및 시스템", "출원인": "주식회사 엘지화학", "발명자": "신지혜"}}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습 문헌데이터의 각 문장에 포함된 토큰들에 대하여 개체명 표식 및 비개체명 표식을 하는 개체명 표식(labeling) 단계; 상기 개체명 표식단계를 거친 학습 문헌데이터의 각각의 문장들에 대하여 개체명 표식이 된 토큰을 찾는 문장별개체명 식별단계;상기 문장별 개체명 검색단계에서, 개체명이 하나도 발견되지 않은 문장에 대하여 비개체명문장 표식을 하는 비개체명 문장 검색 단계;상기 식별된 비개체명 표식된 비개체명 문장들을 n개씩(n은 소정의 자연수) 그룹핑하는 비개체명 문장 그룹핑단계;상기 n개의 비개체명 문장들로 구성된 각각의 비개체명 문장 그룹들에서, 적어도 하나 이상의 비개체명 문장을일부 삭제하는 비개체명 문장 일부삭제 단계;상기 적어도 하나 이상의 비개체명 문장이 삭제되고 남은 학습 문헌데이터를 개체명 인식 기계학습모델의 학습데이터 세트로 설정하는 학습데이터 세트 설정단계;를 포함하여 구성되는 개체명 인식 모델 생성에서의 학습데이터 획득 방법."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 개체명 표식단계는, 상기 학습 문헌데이터를 사용자 사전과 대비하여 사용자 사전에 포함된 개체명에 대하여 개체명 표식을 하는 사용자 사전 비교단계;를 포함하는 것;을 특징으로 하는 개체명 인식 모델 생성에서의 학습데이터 획득 방법."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 비개체명 문장 그룹핑 단계는, 상기 비개체명 문장들을 3개씩 그룹핑하며, 상기 비개체명 문장 일부삭제 단계는, 상기 3개씩 그룹핑된 각각의 비개체명 문장 그룹들 내에 포함된 하나의 문장을 각 그룹에서 삭제하는 것;을 특징으로 하는 개체명 인식 모델 생성에서의 학습데이터 획득 방법."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "소정의 학습문헌데이터에 포함된 각 문장의 각 단어에 대하여 개체명 표식과 비개체명 표식을 하여 기본 데이터셋을 구축하는 기본 데이터셋 구축 단계;공개특허 10-2023-0030337-3-상기 기본 데이터셋에서 비개체명으로만 구성된 비개체명 문장들 중 일부를 제거하는 기본 데이터셋 전처리 단계;상기 기본 데이터셋 전처리 단계를 통해 전처리된 기본 데이터셋을 학습데이터셋으로 학습하여 개체명 인식모델을 생성하는 개체명 인식 모델 학습단계; 를 포함하여 생성되는 화학 물질 개체명 인식 모델 생성방법."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 기본 데이터셋 전처리 단계는, 상기 기본 데이터셋 구축단계에서 구축된 기본 데이터셋에서 개체명이 하나도 발견되지 않은 문장을 검출하는비개체명 문장 검색 단계;상기 식별된 비개체명 표식된 비개체명 문장들을 n개씩(n은 소정의 자연수) 그룹핑하는 비개체명 문장 그룹핑단계;상기 n개의 비개체명 문장들로 구성된 각각의 비개체명 문장 그룹들에서, 적어도 하나 이상의 비개체명 문장을일부 삭제하는 비개체명 문장 일부삭제 단계;를 포함하여 구성되는 것을 특징으로 하는 화학 물질 개체명 인식 모델 생성방법."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "개체명을 인식하고자 하는 문장들이 포함된 학습 문헌데이터를 입력받는 입력부;상기 입력받은 학습 문헌데이터에 대하여 개체명이 포함되지 않은 비개체명 문장의 일부를 삭제하는 전처리를수행하는 전처리부;상기 전처리된 학습 문헌데이터를 학습하여 개체명을 인식하는 개체명 인식 모델을 생성하는 학습 및 모델 생성부;를 포함하여 구성되는 개체명 인식모델 생성장치."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 학습 및 모델 생성부는, 사전학습된 자연어 처리모델에 상기 학습 문헌데이터를 입력하여 학습을 수행하는 것;을 특징으로 하는 개체명 인식모델 생성장치."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 전처리부는, 비개체명 문장들을 소정의 갯수가 포함되도록 그룹핑하고, 각 그룹내의 비개체명 문장들중 일부를 삭제하는 전처리를 수행하는 것;을 특징으로 하는 개체명 인식모델 생성장치."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "기계학습을 위한 학습 문헌데이터 및 개체명을 인식하고자 하는 인식대상 텍스트를 입력받는 데이터 입출력부;공개특허 10-2023-0030337-4-상기 입력받은 학습 문헌데이터에 대하여 개체명이 포함되지 않은 비개체명 문장의 일부를 삭제하는 전처리를수행하여 학습데이터를 생성하는 전처리부;상기 학습데이터를 학습하여 개체명을 인식하는 개체명 인식 모델을 생성하는 학습 및 모델 생성부;사전 학습된 자연어 처리모델을 탑재한 메모리장치;인식대상 텍스트를 입력받아 개체명을 인식하는 개체명 인식부;를 포함하여 구성되며, 상기 학습 및 모델 생성부는, 상기 메모리장치에 탑재된 사전학습된 자연어 처리모델을 이용하여 상기 학습데이터를 학습하여 개체명 인식모델을 생성하며, 상기 메모리장치는,상기 생성된 개체명 인식모델을 저장하고, 상기 개체명 인식부에 제공하는 것; 을 특징으로 하는 개체명 인식 시스템."}
{"patent_id": "10-2021-0112456", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 전처리부는, 비개체명 문장들을 소정의 갯수가 포함되도록 그룹핑하고, 각 그룹내의 비개체명 문장들중 일부를 삭제하는 전처리를 수행하는 것;을 특징으로 하는 개체명 인식시스템."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 입력되는 텍스트에 포함된 개체명을 인식하기 위한 개체명 인식모델을 생성하는 방법 및 장치에 관한 것으로서, 개체명 인식 학습을 위하여 학습데이터를 전처리하는 데이터 전처리 방법을 제공한다. 본 발명에 따른 데이터 전처리 방법은, 학습용 문헌에 개체명 표식을 하고, 개체명 표식이 없는 비개체명 문장들 의 일부를 삭제처리한다."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 개체명 인식을 위한 인공지능 모델을 생성하기 위하여, 모델 학습과정에서, 개체명 인식 학습을 위한 학습데이터의 전처리방법 및 본 발명의 학습데이터 획득 방법에 따라 전처리된 학습데이터로 학습을 진행하여 생성한 개체명 인식모델에 관한 것이다."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "문헌데이터로부터 개체명을 인식하기 위한 다양한 기술들이 개발되어 왔다. 최근에는 BERT(Bidirectional Encoder Representations from Transformers) 모델의 활용도가 높아지고 있는데, BERT 모델은 대량의 원시데이 터를 사전학습(pre-training)하여 문헌데이터를 인식하는 것으로서, 소정의 사전학습된(pre-trained) BERT 모델 을 적용하여 개체명 인식을 하기 위해서는 개체명 태깅을 하도록 추가층(additional layer)을 상위층으로 구성 하고 개체명 인식을 학습시키는 파인튜닝(fine tuning) 과정이 필요하다. 이러한 파인튜닝 과정에서, 학습데이터세트를 사용하여 개체명 인식모델을 학습시키는데, 학습데이터에 포함된 불필요한 데이터 및 그로 인한 학습데이터 연산시 토큰 데이터의 대형화로 인하여 개체명 인식 성능이 떨어지고, 연산량이 증가하는 문제가 있었다. 선행기술문헌특허문헌 (특허문헌 0001) CN 2020-10738252 A"}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 개체명 인식 인공지능 모델을 학습함에 있어서, 상술한 문제점을 해결하고자 하는 것으로서, 학습데 이터를 보다 정교하게 정돈하고, 학습시 연산효율을 증대하는 학습데이터의 전처리 방법 및 그 방법을 활용한 개체명 인식 모델을 제공하고자 한다."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적 달성을 위하여, 본 발명은 학습 문헌데이터의 각 문장에 포함된 토큰들에 대하여 개체명 표식 및 비개체명 표식을 하는 개체명 표식 단계; 상기 개체명 표식단계를 거친 학습 문헌데이터의 각각의 문장들에 대 하여 개체명 표식이 된 토큰을 찾는 문장별 개체명 식별단계; 상기 문장별 개체명 검색단계에서, 개체명이 하나 도 발견되지 않은 문장에 대하여 비개체명문장 표식을 하는 비개체명 문장 검색 단계; 상기 식별된 비개체명 표 식된 비개체명 문장들을 n개씩(n은 소정의 자연수) 그룹핑하는 비개체명 문장 그룹핑 단계; 상기 n개의 비개체 명 문장들로 구성된 각각의 비개체명 문장 그룹들에서, 적어도 하나 이상의 비개체명 문장을 일부 삭제하는 비 개체명 문장 일부삭제 단계; 상기 적어도 하나 이상의 비개체명 문장이 삭제되고 남은 학습 문헌데이터를 개체 명 인식 기계학습모델의 학습데이터 세트로 설정하는 학습데이터 세트 설정단계;를 포함하여 구성되는 개체명 인식 모델 생성에서의 학습데이터 획득 방법을 제공한다. 이 때, 상기 개체명 표식단계는, 상기 학습 문헌데이터를 사용자 사전과 대비하여 사용자 사전에 포함된 개체명 에 대하여 개체명 표식을 하는 사용자 사전 비교단계;를 포함할 수 있다. 또한, 상술한 비개체명 문장 그룹핑 단계는, 비개체명 문장들을 3개씩 그룹핑하며, 상기 비개체명 문장 일부삭 제 단계는, 상기 3개씩 그룹핑된 각각의 비개체명 문장 그룹들 내에 포함된 하나의 문장을 각 그룹에서 삭제하 는 것;을 특징으로 한다. 또한, 본 발명은 텍스트내의 화학 물질 개체명을 인식하는 AI 모델을 제공하는데, 그 생성절차는 소정의 학습문 헌데이터에 포함된 각 문장의 각 단어에 대하여 개체명 표식과 비개체명 표식을 하여 기본 데이터셋을 구축하는 기본 데이터셋 구축 단계; 상기 기본 데이터셋에서 비개체명으로만 구성된 비개체명 문장들 중 일부를 제거하는 기본 데이터셋 전처리 단계; 상기 기본 데이터셋 전처리 단계를 통해 전처리된 기본 데이터셋을 학습데이터셋으 로 학습하여 개체명 인식모델을 생성하는 개체명 인식 모델 학습단계; 를 포함한다. 이때, 상기 기본 데이터셋 전처리 단계는, 상기 기본 데이터셋 구축단계에서 구축된 기본 데이터셋에서 개체명 이 하나도 발견되지 않은 문장을 검출하는 비개체명 문장 검색 단계; 상기 식별된 비개체명 표식된 비개체명 문 장들을 n개씩(n은 소정의 자연수) 그룹핑하는 비개체명 문장 그룹핑 단계; 상기 n개의 비개체명 문장들로 구성 된 각각의 비개체명 문장 그룹들에서, 적어도 하나 이상의 비개체명 문장을 일부 삭제하는 비개체명 문장 일부 삭제 단계;를 포함할 수 있다. 본 발명은 또한, 개체명을 인식하고자 하는 문장들이 포함된 학습 문헌데이터를 입력받는 입력부; 상기 입력받 은 학습 문헌데이터에 대하여 개체명이 포함되지 않은 비개체명 문장의 일부를 삭제하는 전처리를 수행하는 전 처리부; 상기 전처리된 학습 문헌데이터를 학습하여 개체명을 인식하는 개체명 인식 모델을 생성하는 학습 및 모델 생성부;를 포함하여 구성되는 개체명 인식모델 생성장치를 제공한다. 이때, 상기 학습 및 모델 생성부는, 사전학습된 자연어 처리모델에 상기 학습 문헌데이터를 입력하여 학습을 수 행하며, 상기 전처리부는, 비개체명 문장들을 소정의 갯수가 포함되도록 그룹핑하고, 각 그룹내의 비개체명 문 장들중 일부를 삭제하는 전처리를 수행한다. 본 발명은, 기계학습을 위한 학습 문헌데이터 및 개체명을 인식하고자 하는 인식대상 텍스트를 입력받는 데이터 입출력부; 상기 입력받은 학습 문헌데이터에 대하여 개체명이 포함되지 않은 비개체명 문장의 일부를 삭제하는전처리를 수행하여 학습데이터를 생성하는 전처리부; 상기 학습데이터를 학습하여 개체명을 인식하는 개체명 인 식 모델을 생성하는 학습 및 모델 생성부; 사전 학습된 자연어 처리모델을 탑재한 메모리장치; 인식대상 텍스트 를 입력받아 개체명을 인식하는 개체명 인식부;를 포함하는 개체명 인식 시스템을 제공하는데, 이때, 상기 학습 및 모델 생성부는, 상기 메모리장치에 탑재된 사전학습된 자연어 처리모델을 이용하여 상기 학습데이터를 학습 하여 개체명 인식모델을 생성하며, 상기 메모리장치는, 상기 생성된 개체명 인식모델을 저장하고, 상기 개체명 인식부에 제공한다. 또한, 상기 전처리부는, 비개체명 문장들을 소정의 갯수가 포함되도록 그룹핑하고, 각 그룹 내의 비개체명 문장들중 일부를 삭제하는 전처리를 수행한다."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 개체명 인식을 위한 기계학습을 수행함에 있어서, 학습용 데이터로부터 비개체명만으로 이루 어진 문장의 일부를 삭제하고 학습을 진행함으로써, 개체명 인식율을 높이고, 연산자원을 효율적으로 사용할 수 있는 효과를 가져온다."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시 예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면부호를 붙였다."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명에서, 학습 또는 훈련이라 함은 인공지능 기술분야에서 입력값에 대하여 소정의 출력값을 가지도록 하는 컴퓨터 알고리즘 또는 그러한 알고리즘이 신경망의 형태로 구현된 신경망을 학습시키는 것을 의미하며, 컴퓨터 연산장치에 의한 신경망 알고리즘을 수행하는 과정중의 하나를 말한다. 또한 본 발명에서 소정의'모델의 생성' 이라 함은 상기 학습되기 이전의 신경망 또는 그를 구현한 컴퓨터 알고리즘을 학습하여, 입력값에 대하여 원하 는 출력값을 생성하도록 학습이 완료된 컴퓨터 알고리즘을 생성하는 것을 의미한다."}
{"patent_id": "10-2021-0112456", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이하, 도면을 참조하여 본 발명에 대하여 상세하게 설명한다. 1. 본 발명에 따른 개체명 인식 방법 도 1은 본 발명에 따른 개체명 인식 방법의 블럭도이다. 도 1에 도시된 것과 같이, 본 발명이 개체명 인식 방법은 문헌 내에 포함된 개체명을 보다 효과적으로 인식하기 위하여, 개체명 인식모델의 학습을 위한 학습데이터세트를 전처리 하는 데에 그 기술적 특징이 있다. 본 발명에서의 학습데이터라 함은, 예를 들어 BERT(Bidirectional Encoder Representations from Transformers)와 같이 사전학습된(pre-trained) 언어모델에 추가층(additional layer)를 더하여 파인튜닝(fine tuning)을 하는 과정에서, 추가층에 의한 개체명 인식을 학습시키기 위한 학습데이터를 말한다. 1.1. 학습 문헌데이터의 제1 전처리(S100) 본 발명에서는, 종래기술과 달리 학습 문헌데이터를 전처리(pre-processing)하여 학습데이터로 사용하 는데, 그 첫번째 단계로서, 사전에 개체명에 대하여 개체명 표식(labeling)을 한 기본 데이터세트를 구축한 다. 이 때, 상기 학습 문헌데이터는 아무것도 처리되지 않은 원시 데이터(raw data)이며, 기본 데이터세트 는 포함된 각 문장의 각 단어들에 대하여 개체명 표식(labeling) 및 비개체명 표식(labeling)이 된 것이다. 본 발명에서의 학습 문헌데이터는 해당 분야의 특허, 논문 데이터로 구성될 수 있다. 예를 들어, 촉매 활성을 개선하는 공촉매(cocatalyst) 관련 물질의 개체명 인식모델을 생성하고자 하는 경우, 소정의 공촉매 (cocatalyst) 관련 특허, 논문을 학습 문헌데이터로 사용할 수 있다. 학습 문헌데이터의 제1 전처리단계(S100)는 학습 문헌데이터에 포함된 각 단어들에 대하여 개체명/비개체명 표 식 또는 BIO 태깅(tagging)을 하는 과정이며 이와 같은 식별/태깅 과정을 통하여 기본 데이터 세트가 획득 된다. 이와 같은 BIO 태깅의 구체적 내용은 공지의 BIO 태깅방식을 사용한다. 이와 같은 기본 데이터세트의 각 토큰들에 대한 개체명 표식 및 비개체명 표식은 공지의 BIO 태깅방식을 사용하 여 표식이 가능하다. 개체명 표식이라 함은 해당 토큰에 대하여 개체명으로 식별되도록 표식을 다는 과정이며, 개체명의 시작부분에 대해서는'B', 개체명의 내부 부분은 'I'로 태깅될 수 있으며, 개체명이 아닌 부분에 대해 서는 비개체명 표식을 다는데, BIO 태깅방식에서는 'O'로 태깅될 수 있다. 개체명 표식은 학습 문헌데이터를 사용자 사전과 대비하여 사용자 사전에 포함된 개체명에 대하여 개체명 표식 을 수행할 수 있다. 1.2. 제2 전처리(S200) 상기 기본 데이터세트에 대하여 제2 전처리를 수행하여 최종 학습 데이터세트를 획득한다. 제2 전처리과정은 기본 데이터세트에서, 비개체명으로만 구성된 문장들의 일부를 삭제처리하는 과정으로서, 도 2에 도시된 것과 같이, 개체명 식별, 비개체명 문장 식별, 비개체명 문장 그룹핑 및 삭제단계를 포함하여 구성 된다. 제2 전처리 과정을 거친 기본 데이터 세트에 대하여 최종 학습 데이터세트로 설정한다. 개체명 식별단계(S210) 상기 개체명이 표식된 기본 데이터세트로부터 각각의 문장들에 대하여 개체명 표식이 된 토큰을 찾는 단계 이다. 이 과정을 통하여 각 문장들에 개체명 표식 토큰들이 포함되었는지, 비개체명 표식 토큰들이 포함되었는 지를 식별한다. 상술한 것처럼, BIO 태깅 방식을 이용하여 개체명/비개체명을 태깅한 경우, 각 문장에서 태깅된 태그값을 식별하고 카운트한다. 비개체명문장 검색 단계(S220) 상기 개체명 식별단계를 거쳐, 문장내에 개체명 표식 토큰이 포함되지 않은 비개체명문장들을 검색하는 과정이 다. BIO 태깅을 진행한 경우, B, I 태깅 없이, 'O'로만 태깅된 문장을 검색하고 식별한다. 본 발명에서는 이를 비개체명문장 또는 'O'태깅 문장이라 칭한다. 그룹핑 및 삭제단계(S220) 상기 검색된 비개체명 문장들을 소정의 갯수만큼씩 그룹핑하고, 이들 중에서 적어도 하나 이상의 비개체명 문장 (들)을 기본 데이터세트에서 제거하는 단계이다. 그룹핑하는 갯수 및 그룹핑 내에서 삭제하는 삭제 문장 갯수는 사용자 지정상수이며, 비개체명 문장이 전부 삭제되지 않도록 각각의 그룹핑된 비개체명 문장 그룹에서 적어도 1개의 비개체명 문장은 남겨놓도록 설정될 수 있다. 그룹핑 및 삭제단계는 도 2(b)에 도시된 것과 같이, 그룹핑의 갯수를 설정하는 그룹핑 집합설정(S231), 설정된 그룹핑의 갯수만큼 비개체명 문장을 그룹핑하는 비개체명문장 그룹핑(S232), 삭제할 비개체명 문장을 설정하는 삭제대상설정(S233), 삭제대상 설정된 비개체명문장을 삭제처리(S234)하는 절차들로 구성될 수 있다. 그룹핑 집합설정(S231) 절차에서, 그룹핑의 갯수, 방법의 그룹핑 규칙을 설정할 수 있다. 설정값은 소정의 갯수, 순서(순차, 랜덤, 건너뛰기 등)로 설정하여 학습을 진행할 수 있으며, 본 발명의 실시예에서는 3개씩, 순 차적으로 그룹핑을 진행하였다. 비개체명문장 그룹핑(S232) 절차는 앞서 설정된 그룹핑 갯수, 순서에 따라 비개체명문장들을 그룹핑한다. 삭제대상설정(S233) 단계에서는 그룹핑된 비개체명문장들의 각 그룹에서, 삭제처리할 비개체명문장을 선택한다. 삭제대상설정(S233) 단계에서는 각각의 비개체명문장 그룹에서 삭제처리할 대상을 선택하는 삭제규칙을 정하여 삭제대상을 선택할 수 있는데, 삭제 순서(순차, 랜덤, 건너뛰기 등), 갯수 등을 설정할 수 있으며, 그룹내의 모든 비개체명문장을 삭제 선택하지는 않는다. 예를 들어, 3개씩 그룹핑 된 비개체명문장 그룹에서 가운데 비개체 명문장을 삭제 선택할 수 있다. 삭제처리(S234) 단계에서는 삭제대상설정(S233) 단계에서 설정된 규칙에 따라 각 비개체명문장 그룹에서 선택된 비개체명문장을 삭제처리한다. 삭제는 실제로 해당 비개체명 문장 데이터를 삭제처리하거나, 삭제문장으로 태깅 하여, 학습데이터로 사용되지 않도록 처리한다. 1.3. 모델 학습 단계(S300) 상기 제2 전처리 과정을 거쳐 적어도 각 비개체명 문장 그룹에서 전체 문장이 아닌 일부의 비개체명 문장이 삭 제되고 남은 문장들로 구성된 기본 데이터세트를 최종 학습 데이터세트로 설정하고, 이를 자연어 처리 모델 에 입력하여 학습을 수행하고 개체명 인식모델을 생성하는 단계이다. 본 발명의 실시예에서는 사전학습된(pre-trained) BERT(Bidirectional Encoder Representations from Transformers) 모델에 개체명을 태깅하는 추가층(additional layer)을 더하여 파인튜닝(fine-tuning)하는 학습 과정을 전제로 하였으며, 상기 제1, 제2 전처리 과정을 거친 최종 학습데이터세트를 입력하여 학습을 진행하고, 개체명 인식모델을 생성하였다. 1.4. 개체명 인식(S400) 및 결과의 출력(S500) 상기 생성된 개체명 인식모델에 인식대상 텍스트를 입력하여 인식대상 텍스트에 포함된 개체명을 인식하는 단계이다. 텍스트에서 개체명의 인식은 텍스트 상에 존재하는 개체명들을 인식하여 미리 정의된 분류 로 분류하여 출력하는 과정이다. 1.5. 생성 모델의 검증 상기 모델 학습 단계를 거쳐 생성된 학습모델에 대한 성능평가 결과를 도 3에 보인다. 모델의 전단으로는, 사전 학습된 BERT 모델, 또는 일반화학 분야에 특화되도록 사전학습된 BERT BERT 모델을 사 용하였으며, 실제 특허문헌을 상기 동일한 사전학습된 BERT 모델을 파인튜닝(fine-tuning)한 모델에 입력하여 개체명 인식의 정확도 테스트를 진행하였다. 비개체명 문장 그룹핑의 갯수는 3개로 설정하였으며, 삭제하는 비 개체명 문장의 갯수는 랜덤 갯수로 설정하여 다수의 모델을 테스트하였고, 그 중에서 테스트 정확도가 높은 모 델의 결과를 도 3에 표시하였다. 도 3의 제1 내지 제3 컬럼에 제시된 것과 같이, cocatalyst의 경우, 본 발명의 전처리 과정을 거치지 않은 문헌 데이터 또는 기본데이터세트을 그대로 학습데이터로 사용한 경우, 84.73%의 정확도를 보인 것에 비하여, 본 발명의 제2 전처리 과정까지 거친 학습 데이터세트를 적용하여 모델학습을 진행하여 생성한 개 체명 인식모델은 87.06%의 정확도를 보였다. 도 3의 제1 컬럼에 제시된 9가지의 물질군에 대하여 정확도의 평균값이, 종래의 방식의 경우 대략 39% 에서, 본 발명의 전처리 기술을 적용시 약 90%로 비약적으로 정확도가 상승하였다. 또한, 본 발명의 전처리 기술 적용시 입력되는 total token의 갯수가 학습시 32.5%, 인식 테스트시 18.5%로 감소하여 연산 효율성 역시 증대되었음을 알 수 있다. 2. 본 발명에 따른 개체명 인식 시스템 본 발명에 따른 개체명 인식 시스템을 설명한다. 도 4에 도시된 것처럼, 본 발명의 개체명 인식 시스템은 데이터 입력부, 제어부, 메모리장치 을 포함하여 구성된다. <실시예1> 2.1. 데이터 입/출력부 데이터 입/출력부는 학습문헌데이터, 인식대상텍스트 등을 입력받아 제어부에 전달하여, 제 어부가 학습문헌데이터의 전처리, 모델 학습 등을 수행하도록 한다. 2.2. 제어부 제어부는 메모리장치에 탑재되는 학습문헌데이터의 전처리 컴퓨터 프로그램 알고리즘을 불러와 학습 문헌데이터의 전처리과정을 수행한다. 또한 메모리장치에 탑재되는 사전학습된 BERT 모델에 전처리된 학습문헌데이터, 즉, 학습 데이터세트 를 입력하여 개체명 인식 모델을 생성하고, 인식대상텍스트 입력시 이를 개체명 인식모델에 입력하 여 인식대상텍스트의 개체명인식결과를 데이터 입출력부로 출력한다. 제어부는 메모리 장치에 탑재되는 전처리 수행 알고리즘을 읽어와 전치리과정을 수행하는 전처리부 과 학습데이터세트를 적용하여 개체명 인식모델을 생성하는 학습 및 모델 생성부, 인식대상 텍스트에 대하여 개체명 인식모델을 적용하여 개체명 인식결과를 출력하는 개체명 인식부를 구비 한다. 2.3. 메모리장치 메모리장치는 사전학습된 자연어 처리모델(예:BERT 모델)을 탑재하며, 상기 제어부에 의해 생성된 개 체명 인식모델을 저장한다. <실시예2> 본 발명의 개체명 인식 시스템의 다른 실시예로서, 도 5와 같이, 상술한 개체명 인식모델을 생성하는 개체 명 인식 모델 생성장치와 개체명 인식장치가 별도로 구성될 수 있으며, 개체명 인식 모델 생성장치 는 학습문헌데이터에 대하여 상기 전처리(S100, S200)를 수행하여, 사전학습된 자연어 처리모델(예: BERT 모델)에 입력하여 개체명 인식모델을 생성하고, 개체명 인식장치는 생성된 개체명 인식모델 을 탑재하고, 인식대상텍스트 입력시 개체명을 인식하여 출력(S500)하는 과정을 수행하도록 별개의 장치로 구성될 수 있다. 3. 본 발명에 따른 개체명 인식모델 본 발명은 또한, 상술한 개체명인식 방법의 절차에 따라 생성된 개체명 인식모델을 제공한다. 학습문헌데이터에 대하여, 상술한 제1, 제2 전처리 과정을 수행한 학습 데이터 세트를 학습데이터로 하 여 구축한 개체명 인식모델은, 위에서 도 4, 5를 들어 설명한 것과 같이, 개체명 인식시스템 또는 개 체명 인식장치는 생성된 개체명 인식모델을 탑재하여 입력되는 인식대상 텍스트에 대하여 개체명 인식을 수행하고 그 결과를 출력한다. 이와 같은 본 발명의 개체명 인식모델은 학습문헌데이터의 분야 및 종류에 따라, 그리고 앞서 설명한 제2 전처리 과정(S200)에서의 비개체명 문장의 그룹핑 및 삭제(S230)시 설정되는 그룹핑/삭제 규칙에 따라 생성 된 개체명 인식모델의 성능에 차이가 발생할 수 있는데, 본 발명에 따라 특정 분야의 개체명 인식모델 생성 을 위하여 특정 분야의 학습문헌데이터를 사용하고, 최적의 성능을 보이는 그룹핑/삭제 규칙을 선택적으로 적용 가능하다."}
{"patent_id": "10-2021-0112456", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 개체명 인식모델을 생성하고 인식 대상 텍스트에 대하여 개체명 인식결과를 출력하는 일 련의 과정을 보이는 절차도이다. 도 2는 본 발명에 따른 학습데이터의 전처리과정을 보이는 절차도이다. 도 3은 본 발명에 따라 생성한 개체명 인식모델의 성능시험의 결과를 보이는 데이터이다. 도 4는 본 발명에 따른 개체명 인식모델 생성 및 인식 시스템의 블럭도이다. 도 5는 본 발명에 따른 개체명 인식모델 생성장치 및 개체명 인식 장치의 블럭도이다."}
