{"patent_id": "10-2023-0121067", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0084439", "출원번호": "10-2023-0121067", "발명의 명칭": "혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "김진규"}}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "원형 신경망에서 n비트 부동 소수점을 이용하여 학습 연산을 수행하는 단계;양자화 신경망에서 m비트 부동 소수점 또는 고정 소수점을 이용하여 학습 연산을 수행하는 단계;상기 원형 신경망 내부의 인코더 블록 출력을 기초로 지식증류손실값을 계산하는 단계; 및상기 지식증류손실값을 더하여 상기 양자화 신경망의 전체 손실 함수를 생성하는 단계;를 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 n비트는 m비트 보다 큰 비트인 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 n비트는 32비트를 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 m비트는 16비트 및 8비트 중 적어도 하나를 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 양자화 신경망은 복수의 양자화 인코더 블록을 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 양자화 인코더 블록은 8비트 부동 소수점을 사용하는 행렬 곱셈의 연산을 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 양자화 인코더 블록은 32비트 부동소수점을 사용하는 GELU의 연산을 포함하는 혼합 정밀도 데이터 타입을위한 인공신경망 학습 방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 양자화 인코더 블록은 16비트 부동 소수점을 사용하는 레이어 정규화의 연산을 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법.공개특허 10-2024-0084439-3-청구항 9 제1항에 있어서,상기 인코더 블록은 레이어 정규화, 어텐션, MLP 또는 FFN, 덧셈기를 포함하는 혼합 정밀도 데이터 타입을 위한인공신경망 학습 방법."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공신경망 학습을 위한 제어 프로그램이 저장된 메모리; 및상기 메모리에 저장된 제어 프로그램을 실행하는 프로세서를 포함하고,상기 프로세서는,원형 신경망에서 n비트 부동 소수점을 이용하여 학습 연산을 수행하고, 양자화 신경망에서 m비트 부동 소수점또는 고정 소수점을 이용하여 학습 연산을 수행하고, 상기 원형 신경망 내부의 인코더 블록 출력을 기초로 지식증류손실값을 계산하고, 상기 지식증류손실값을 더하여 상기 양자화 신경망의 전체 손실 함수를 생성하는 혼합정밀도 데이터 타입을 위한 인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 n비트는 m비트 보다 큰 비트인 합 정밀도 데이터 타입을 위한 인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 n비트는 32비트를 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 m비트는 16비트 및 8비트 중 적어도 하나를 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 양자화 신경망은 복수의 양자화 인코더 블록을 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 양자화 인코더 블록은 8비트 부동 소수점을 사용하는 행렬 곱셈의 연산을 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 양자화 인코더 블록은 32비트 부동소수점을 사용하는 GELU의 연산을 포함하는 혼합 정밀도 데이터 타입을위한 인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,공개특허 10-2024-0084439-4-상기 양자화 인코더 블록은 16비트 부동 소수점을 사용하는 레이어 정규화의 연산을 포함하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 인코더 블록은 레이어 정규화, 어텐션, MLP 또는 FFN, 덧셈기를 포함하는 혼합 정밀도 데이터 타입을 위한인공신경망 학습 장치."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일실시예에 따른 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법은 원형 신경망에서 n비트 부 동 소수점을 이용하여 학습 연산을 수행하는 단계와, 양자화 신경망에서 m비트 부동 소수점 또는 고정 소수점을 이용하여 학습 연산을 수행하는 단계와, 상기 원형 신경망 내부의 인코더 블록 출력을 기초로 지식증류손실값을 계산하는 단계와, 상기 지식증류손실값을 더하여 상기 양자화 신경망의 전체 손실 함수를 생성하는 단계를 포함 할 수 있다."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법에 관한 것이다."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망은 2012년 AlexNet이 발표되면서 컨볼루션 뉴럴 네트워크(CNN)이 시각지능 분야에서 널리 활용되다 가 구글에서 2017년 어텐션(attention)을 이용한 트랜스포머 모델을 발표한 이래 다양한 분야에서 널리 활용되 고 있다. 인공 신경망은 주로 32-bit 부동 소수점(floating-point) 데이터 타입을 이용하여 학습을 진행한다. 학습이 완 료된 파라미터를 사용하여 추론 과정을 수행하는 경우에는 32-bit보다 작은 비트폭을 갖는 데이터 타입을 사용 하는 양자화 과정을 거친다. 양자화 과정을 통해 32-bit 부동 소수점 데이터는 16-bit 부동 소수점이나 8-bit 부동 소수점, 8-bit 고정 소수점 등의 낮은 비트폭의 데이터를 사용하게 된다. 이는 작은 비트 수를 갖는 데이 터가 신경망 처리 속도, 전력 소모 효율, 메모리 사용용량 측면에서 유리하기 때문이다. 본 발명의 수단을 설명하기 전에 KD 학습 방식에 관해 설명한다. KD 학습은 잘 학습된 큰 규모의 신경망 (Teacher Network: TN)와 학습할 작은 규모의 신경망(Student Network: SN)을 이용한다. 즉 잘 훈련된 TN 신경 망의 손실 함수를 이용하여 실제 사용할 SN 신경망을 학습하여 최적의 학습 파라미터를 얻고자 하는 것이다. 주 요 효과는 TN 신경망의 추론 성능에 가까운 작은 규모의 SN 신경망을 만들 수 있다는 것이다. 이는 신경망 압축 (Deep Learning Compression) 효과로 이어져서 유사한 추론 성능을 가지면서도 작은 규모의 가중치(weight)와 연산 규모(Flops)를 달성하게 된다. TN 신경망의 소프트맥스 손실함수의 soft decision 출력과 SN 신경망 손실함수의 soft decision 출력을 이용하 여 증류 손실(distillation loss)를 구하고 SN 신경망의 소프트맥스 손실함수의 hard decision 출력을 이용한 손실을 구하게 된다. 이렇게 구해진 2개의 손실 값을 결합하여 전체 손실 함수를 구한 후에 이를 이용하여 체인 (chain)규칙에 따른 역 전파 과정 (backward propagation)을 수행하여 SN의 앞단 레이어들의 가중치 업데이트를 구한후에 이를 이용하여 SN 신경망을 학습하는 방식이다. 종래 지식증류기법을 사용하는 트랜스포머 학습은 대개 전이학습(Transfer Learning)을 이용하여 수행된다. 전 이 학습이란 매우 데이터셋(dataset)을 이용하여 사전학습모델 (Pretrained model)의 학습 파라미터를 구하고, 이를 다시 재학습(Fine-tuning) 과정을 거쳐 최종 학습 파라미터를 구하는 방법이다 여기서 TN 신경망의 경우, 최종 학습 파라미터를 구한 결과이다. 예를 들어, 이미지 분류 테스크의 경우를 예를 들면 1 단계로 Image-21K 대용량 데이터셋을 이용하여 사전학습모델의 학습파라미터를 구하고 이를 다시 Image-1K 데이터셋을 이용하여 재학습하는 방식을 수행한다. 이러한 경우 신경망의 검출 정확도(Top-1 accuracy)가 향상되는 효과를 가진다고 알려져 있다."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 16-bit 혹은 8-bit로 낮은 정밀도를 갖는 데이터 타입으로 양자화 과정을 수행시에, 32-bit 대비 성능 감쇄가 최소화되면서 혼합 정밀도 데이터 타입을 복합적으로 사용하는 모델을 생성하는 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법 및 장치를 제공하는 것이다. 또한, 본 발명의 목적은 내부적으로 한 종류의 데이터 타입이 아니라 복수개의 다양한 데이터 타입이 혼재되어 사용되는 경우에 인코더 블록별로 지식증류기법을 이용한 손실함수를 사용하기 위한 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법 및 장치를 제공하는 것이다."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 실시예에 따른 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 방법은 원형 신 경망에서 n비트 부동 소수점을 이용하여 학습 연산을 수행하는 단계와, 양자화 신경망에서 m비트 부동 소수점 또는 고정 소수점을 이용하여 학습 연산을 수행하는 단계와, 상기 원형 신경망 내부의 인코더 블록 출력을 기초 로 지식증류손실값을 계산하는 단계와, 상기 지식증류손실값을 더하여 상기 양자화 신경망의 전체 손실 함수를 생성하는 단계를 포함할 수 있다. 상기 n비트는 m비트 보다 큰 비트일 수 있다. 상기 n비트는 32비트를 포함할 수 있다. 상기 m비트는 16비트 및 8비트 중 적어도 하나를 포함할 수 있다. 상기 양자화 신경망은 복수의 양자화 인코더 블록을 포함할 수 있다. 상기 양자화 인코더 블록은 8비트 부동 소수점을 사용하는 행렬 곱셈의 연산을 포함할 수 있다. 상기 양자화 인코더 블록은 32비트 부동소수점을 사용하는 GELU의 연산을 포함할 수 있다. 상기 양자화 인코더 블록은 16비트 부동 소수점을 사용하는 레이어 정규화의 연산을 포함할 수 있다. 상기 인코더 블록은 레이어 정규화, 어텐션, MLP 또는 FFN, 덧셈기를 포함할 수 있다. 또한, 상기한 목적을 달성하기 위한 실시예에 따른 혼합 정밀도 데이터 타입을 위한 인공신경망 학습 장치는 공 신경망 학습을 위한 제어 프로그램이 저장된 메모리; 및 상기 메모리에 저장된 제어 프로그램을 실행하는 프로 세서를 포함하고, 상기 프로세서는, 원형 신경망에서 n비트 부동 소수점을 이용하여 학습 연산을 수행하고, 양 자화 신경망에서 m비트 부동 소수점 또는 고정 소수점을 이용하여 학습 연산을 수행하고, 상기 원형 신경망 내 부의 인코더 블록 출력을 기초로 지식증류손실값을 계산하고, 상기 지식증류손실값을 더하여 상기 양자화 신경 망의 전체 손실 함수를 생성하는 할 수 있다. 상기 n비트는 m비트 보다 큰 비트일 수 있다. 상기 n비트는 32비트를 포함할 수 있다. 상기 m비트는 16비트 및 8비트 중 적어도 하나를 포함할 수 있다. 상기 양자화 신경망은 복수의 양자화 인코더 블록을 포함할 수 있다. 상기 양자화 인코더 블록은 8비트 부동 소수점을 사용하는 행렬 곱셈의 연산을 포함할 수 있다. 상기 양자화 인코더 블록은 32비트 부동소수점을 사용하는 GELU의 연산을 포함할 수 있다. 상기 양자화 인코더 블록은 16비트 부동 소수점을 사용하는 레이어 정규화의 연산을 포함할 수 있다. 상기 인코더 블록은 레이어 정규화, 어텐션, MLP 또는 FFN, 덧셈기를 포함할 수 있다."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예는 혼합 정밀도를 갖는 양자화 과정에서 32-bit 부동소수점에서 얻어지는 baseline 정확도를 유지하면서 신경망 내부는 16 혹은 8-bit 부동소수점이나 고정소수점으로 구성된 연산자(operator) 활용이 용이할 수 있다. 또한, 실시예는 혼합 정밀도 기반 양자화 학습(Quantization Aware Training with Mixed-precision data typ e)방식을 인코더나 디코더 블록별로 수행하기 때문에 학습 속도의 개선 효과가 증대될 수 있다. 또한, 실시예는 비트 수가 작은 혼합 정밀도를 갖는 신경망은 처리 속도가 빠른 매트릭스 연산이 가능해지고 메 모리 용량(memory footprint)가 적어지는 장점이 있기 때문에 추론처리 속도와 전력 사용 효율이 크게 개선할 수 있다."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다."}
{"patent_id": "10-2023-0121067", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 문서에서 \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A,B 또는 C 중 적어도 하나\", 및 \"A,B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구와 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 인공신경망은 기본적으로 32-bit 부동소수점을 이용하여 학습 파라미터와 특징 데이터를 표현하고 있다. 인공신경망의 추론 속도를 높이기 위해서는 16-bit, 8-bit, 4-bit 등의 낮은 정밀도를 갖는 부동 소수점이나 혹 은 고정 소수점 데이터 타입을 이용하여 학습 파라미터와 특징 데이터를 재 표현하는 과정인 양자화 과정이 필 요하다. 양자화를 수행하는 이유는 신경망을 처리하는 데이터가 작은 비트폭에 낮은 정밀도를 가질수록 내부 연산기의 복잡도가 낮아지고 처리속도가 향상되며 메모리 점유량이 낮아지는 효과가 존재한다. 그러나 인공신경망의 검출 정확도는 낮은 정밀도에서 상대적으로 검출 성능 저하를 발생시킴으로써 검출 성능과 처리 속도는 일반적으로 반 비례적인 관계를 가진다. 따라서 성능 차이를 최소화하면서도 데이터 정밀도를 낮추 는 방향으로 진행하는 것이 양자화의 목표가 된다. 양자화 방식은 2가지로 나누어질 수 있다. 32-bit 부동소수점 데이터 타입을 이용하여 학습을 수행한 후에 고정 된 파라미터와 특징 데이터에 대해 양자화 과정을 수행하는 PTQ(Post Training Quantization)과 처음에 학습을 시작할 때부터 양자화를 고려하여 재학습을 수행함으로써 파라미터와 특징 데이터를 양자화 비트에 적응되도록하는 QAT(Quantization Aware Training)로 나뉠 수 있다. 이외에도 양자화 대상 데이터에 따라 2가지로 나누어질 수 있다. 학습 파라미터에 대한 양자화만 수행할 수도 있고, 학습 파라미터와 특징 데이터 모두 양자화를 수행할 수도 있다. 예를 들어, 학습 파라미터만 양자화를 수 행하는 경우에는 학습 파라미터는 8-bit 고정 소수점 정수와 특징 데이터는 32-bit 부동 소수점을 사용할 수 있 다. 본 발명은 혼합 정밀도에서 양자화 과정에 활용하는 방법에 관한 것이다. 32-bit 부동 소수점을 이용하여 잘 학 습된 결과를 이용하여 혼합 정밀도가 적용된 신경망을 학습하는 방법이다. 도 1은 실시예에 따른 인공신경망 학습 방법을 나타낸 흐름도이다. 도 1을 참조하면, 실시예에 따른 인공신경망 학습 방법은 원형 신경망과 양자화 신경망에서 수행될 수 있다. 원형 신경망은 32-bit 학습 파라미터와 특징 데이터를 갖는 트랜스포머 신경망일 수 있다. 원형 신경망은 TN(Teacher Network) 신경망에 해당될 수 있다. 원형 신경망은 복수의 인코더 블록을 포함할 수 있다. 원형 신경망은 패치 임베딩을 수행하고(S101), 복수의 인코더 블록을 통해 연산을 수행하고(S101~S107), 행렬 곱셈(GEMM, S109) 및 소프트 맥스(S111) 연산을 수행할 수 있다. 양자화 신경망은 8-bit, 16-bit, 32-bit의 부동 소수점 사용하여 연산을 수행할 수 있다. 양자화 신경망은 SN(Student Network) 신경망에 해당될 수 있다. 양자화 신경망은 복수의 양자화 인코더 블록을 포함할 수 있다. 양자화 신경망은 패치 임베딩을 수행하고(S201), 복수의 양자화 인코더 블록을 통해 연산을 수행하고 (S203~S207), 행렬 곱셈(GEMM, S209), 소프트 맥스(S211) 및 경판정(Hard decision, S213) 과정을 수행하고 Ground Truth(S215)를 통해 전체 손실을 계산할 수 있다(S217). 양자화 인코더 블록은 행렬 곱셈, GELU, 레이어 정규화 연산을 수행할 수 있다. 행렬 곱셈은 8-bit 부동 소수점 을 사용할 수 있다. GELU는 32-bit 부동 소수점을 사용할 수 있다. 레이어 정규화는 16-bit 부동 소수점을 사용 할 수 있다. 즉, 내부 연산자(Operator)에 따라 사전에 대항 양자화 비트를 결정하여 구성될 수 있다. 양자화 학습을 수행한 양자화 신경망은 주어진 학습 이미지에 따른 손실 함수를 계산하여 역전파 과정을 수행한 다. 이는 본래의 학습 과정과 동일하게 동작한다. 역전파 과정을 수행하면서 원형 신경망의 각각의 블록 출력을 증류 손실(distillation loss)로 입력받게 된다. 그러면 원래의 손실 값과 증류 손실 값을 결합하여 이에 따른 전체 손실 함수를 계산하면서 역전파 과정을 수행하게 된다. 이 원리는 혼합 정밀도 데이터 타입으로 구성된 양 자화 신경망의 인코더 블록들이 원형 신경망의 32-bit 부동소수점으로 수행되는 인코더 블록들과 유사한 패턴을 갖는다면 양자화 네트워크의 학습 효과가 커진다는 것에서 기인한다. 따라서 2개 블록들의 유클리디언 거리 (Euclidean distance)를 계산하여 이를 손실 값으로 사용할 수 있다. 종래의 지식증류 기법과 상이한 점은 원형 신경망과 양자화 신경망의 구조 차이와 학습 방식이다. 본 발명에 따 른 양자화 신경망은 원형 신경망과 동일한 구조와 복잡도를 가지게 되며, 차이점은 내부에 사용되는 데이터 타 입이 원형 신경망에서 사용하는 32-bit 부동 소수점보다 작은 16-bit 혹은 8-bit 부동 소수점이나 고정 소수점 (integer)이라는 것이다. 또한 원형 신경망의 중간 인코더 블록의 출력을 이용하여 양자화 신경망도 유사한 데 이터 분포를 가지게끔 2개 출력의 차이를 이용하여 지식증류 손실 값을 계산하여 이를 원래의 손실 값에 더해주 어 전체 손실 함수를 생성하는 것이다. 도 2는 실시예에 따른 인코더 블록의 내부 구조를 나타낸 블록도이고, 도 3은 실시예에 따른 레이어 정규화를 나타낸 블록도이고, 도 4는 실시예에 따른 어텐션을 나타낸 블록도이고, 도 5는 실시예에 따른 스케일된 도트 프로덕션 어텐션을 나타낸 블록도이고, 도 6은 실시예에 따른 리니어를 나타낸 블록도이고, 도 7은 실시예에 따 른 MLP를 나타낸 블록도이다. 도 2를 참조하면, 실시예에 따른 인코더 블록은 레이어 정규화(Layer Normalization, 310), 어텐션 (Multi-head Self Attention, 320), 덧셈기(Adder, 330), MLP(Multi-Layer Perceptron, 340) 혹은 FFN (Feed Forward Network)를 포함할 수 있다. 여기서, 인코더 블록은 양자화 인코더 블록일 수 있다. 도 3에 도시된 바와 같이, 실시예에 따른 레이어 정규화는 Mean, Std Sub, Div, Mul 및 Add 연산을 포함 할 수 있다. 도 4에 도시된 바와 같이, 실시예에 따른 어텐션은 스케일된 도트 프로덕션 어텐션(Scaled Dot-Product Attention, 321), Linear, Concatenate를 포함할 수 있다. 도 5에 도시된 바와 같이, 실시예에 따른 스케일된 도트 프로덕션 어텐션은 MatMul, Scale, Softmax 연산 을 포함할 수 있다. 도 6에 도시된 바와 같이, 실시예에 따른 Linear는 MatMul, Add 연산을 포함할 수 있다. 도 7에 도시된 바와 같이, 실시예에 따른 MLP는 MatMul, Add, GELU 연산을 포함할 수 있다. 상기에서 도시된 바와 같이, 실시예에 따른 인코더 블록은 행렬 곱셈이 가장 많이 사용되고 있으며, 그 외에는 평균(mean)이나 표준편차(std)를 구하거나 덧셈, 곱셈, 뺄셈, 나눗셈 연산을 수행하게 된다. 특별한 연산자로는 GELU 라는 활성화 함수와 소프트맥스 함수가 존재할 수 있다. 본 발명에서 제시하는 혼합 정밀도를 갖는 연산자는 대부분의 연산을 수행하는 행렬 곱셈에 해당한다. 행렬 곱 셈이 16-bit 혹은 8-bit의 부동소수점 혹은 고정소수점 연산이 가능하도록 양자화되면 신경망 처리속도 및 전력 소모 효율성 측면에서 매우 유리해질 수 있다. 실시예에 따른 인공신경망 학습 장치는 컴퓨터 판독 가능한 기록매체와 같은 컴퓨터 시스템에서 구현될 수 있다. 도 8은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 블록도이다. 도 8을 참조하면, 실시예에 따른 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로 세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리 지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들을 실 행하는 반도체 장치일 수 있다. 프로세서는 일종의 중앙처리장치로서 인공신경망 학습 장치의 전체 동작 을 제어할 수 있다. 프로세서는 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 여기서, '프로세서 (processor)'는 예를 들어 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망라할 수 있으나, 이에 한정되는 것은 아 니다. 메모리는 실시예에 따른 인공신경망 학습 방법을 수행하기 위한 제어 프로그램 등 전반적인 동작을 위한 다양한 데이터가 저장될 수 있다. 구체적으로, 메모리에는 인공신경망 학습 장치에서 구동되는 다수의 응용 프 로그램, 인공신경망 학습 장치의 동작을 위한 데이터 및 명령어가 저장될 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 일 실시예에 따르면, 컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능한 기록 매체로서, 원형 신경망에서 n 비트 부동 소수점을 이용하여 학습 연산을 수행하는 동작과, 양자화 신경망에서 m비트 부동 소수점 또는 고정 소수점을 이용하여 학습 연산을 수행하는 동작과, 상기 원형 신경망 내부의 인코더 블록 출력을 기초로 지식증 류손실값을 계산하는 동작과, 상기 지식증류손실값을 더하여 상기 양자화 신경망의 전체 손실 함수를 생성하는 동작을 프로세서가 수행하도록 하기 위한 명령어를 포함할 수 있다. 일 실시예에 따르면 컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서, 원형 신경망에서 n 비트 부동 소수점을 이용하여 학습 연산을 수행하는 동작과, 양자화 신경망에서 m비트 부동 소수점 또는 고정 소수점을 이용하여 학습 연산을 수행하는 동작과, 상기 원형 신경망 내부의 인코더 블록 출력을 기초로 지식증 류손실값을 계산하는 동작과, 상기 지식증류손실값을 더하여 상기 양자화 신경망의 전체 손실 함수를 생성하는 동작을 프로세서가 수행하도록 하기 위한 명령어를 포함할 수 있다.본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, \" 필수적인\" \"중요하게\" 등과 같은 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다 고 할 것이다."}
{"patent_id": "10-2023-0121067", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 인공신경망 학습 방법을 나타낸 흐름도이다. 도 2는 실시예에 따른 인코더 블록의 내부 구조를 나타낸 블록도이다. 도 3은 실시예에 따른 레이어 정규화를 나타낸 블록도이다. 도 4는 실시예에 따른 어텐션을 나타낸 블록도이다. 도 5는 실시예에 따른 스케일된 도트 프로덕션 어텐션을 나타낸 블록도이다. 도 6은 실시예에 따른 리니어를 나타낸 블록도이다. 도 7은 실시예에 따른 MLP를 나타낸 블록도이다. 도 8은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 블록도이다."}
