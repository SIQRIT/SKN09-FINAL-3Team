{"patent_id": "10-2023-0060854", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0163799", "출원번호": "10-2023-0060854", "발명의 명칭": "딥러닝 기반으로 비식별 데이터로부터 낙상 사고 판별 방법 및 장치", "출원인": "주식회사 유니유니", "발명자": "한수연"}}
{"patent_id": "10-2023-0060854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "낙상 판별 방법으로서,딥러닝 기반으로 비식별 데이터를 이용해서 판별하는 방법."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 목적을 해결하기 위한 일 실시예에 따른 낙상 사고 판별 방법은, 딥러닝 기반으로 비식별 데이터를 이 용해서 낙상 여부를 추론하는 것이다"}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝 기반으로 비식별 데이터로부터 낙상 사고 판별 방법 및 장치에 관한 발명이다."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 요양병원 또는 병원 등에서 거동이 불편한 환자가 낙상하여 부상 또는 사망하는 사례가 빈번히 발생하고 있다. 즉, 거동이 불편한 환자의 관리가 소홀한 시간 및/또는 장소에서 낙상 사고가 발생하는 경우에, 사전에 대응이 미흡하거나, 신변파악과 신속한 조치가 이루어지지 않아 여러 위험요소에 노출되는 심각한 문제가 있었 다. 한편, 최근 사회안전망 구축을 위해 영상으로부터 신원 확인을 위한 신체 정보(biometry)를 획득하고, 행동을 분석하는 연구가 활발히 이루어지고 있다. 예를 들어, 촬영된 영상으로부터 얼굴, 걸음걸이, 키 등을 이용하여 대상의 신원을 확인하고, 영상 내 대상의 골격 정보 등의 신체적 특징에 기초하여, 대상의 현재 상태를 분석하 는 방법이 연구 개발되고 있다. 이에, 이러한 기술을 적용하여 환자를 감시할 수 있는 환자 감시 모니터링 시스 템의 도입을 시도하려는 움직임이 활발히 이루어지고 있다. 다만, 이러한 기술의 경우, 개인의 얼굴이나 신체 정보 등을 이용하기에, 개인정보가 노출될 수 있다는 문제가 있다."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예에 따라 해결하고자하는 과제는 상술한 문제를 해결하기 위한 것으로, 딥러닝을 이용해서 환자의 낙상 사고를 예측하거나 알림을 하되, 비식별 데이터를 이용함으로써 환자의 개인정보까지도 보호될 수 있도록 하는 기술을 제공하는 것을 포함한다."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따르면, 딥러닝을 이용해서 환자의 낙상 사고를 예측하거나 알림을 하되, 비식별 데이터를 이용함 으로써 환자의 개인정보까지도 보호될 수 있다. 예컨대, 그래픽 신경망 등을 이용해서 환자가 낙상할 것인지 여부 등이 추론될 수 있되, 이 때 이용되는 데이터 는 비식별 데이터 데이터일 수 있다."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1개의 유닛이 2개 이상의 하드웨어를 이용하여 실현되어도 되 고, 2개 이상의 유닛이 1개의 하드웨어에 의해 실현되어도 된다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술 된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 본 발명은 컴퓨터가 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있고, 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함 한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 낙상 판별 시스템을 설명하기 위한 개념도를 나타낸 것이다. 도 2는 도 1의 중앙 서버를 설명하기 위한 블록도이다. 도 1 및 도 2를 참조하면, 본 발명의 일 실시예에 따른 낙상 판별 시스템은 다수의 카메라 단말로부 터 획득되는 영상 정보를 기초로 병원 내외부 환경을 모니터링하고, 병원 내외에서 검출되는 객체의 상태를 모 니터링 하고, 객체의 낙상이 검출되면, 낙상 사고인지 여부를 판별하여, 즉각적인 대처를 수행하도록 구성된다. 여기서, 낙상 검출에는 비식별 데이터가 이용될 수 있다. 비식별 데이터란, 개인의 신원 정보 등이 포함되어 있 지 않는 또는 않도록 처리된 데이터를 지칭한다. 이러한 비식별 데이터에는 다양한 것들이 포함될 수 있다. 예 컨대, 적외선 카메라나 센서 등으로부터 획득된 데이터 또는 일반적인 카메라로부터 획득된 데이터에서 개인의 식별이 가능한 부분을 블러처리하거나 제거함으로써 획득된 데이터일 수 있으며, 다만 이에 한정되는 것은 아니다. 일 실시예에 따른 낙상 판별 시스템은 딥 러닝 알고리즘을 이용한 객체 인식 기술을 활용하여 카메라 단 말을 통해 입력되는 영상 데이터 내 검출되는 객체의 상태를 모니터링하도록 구성된다. 또한, 상기 낙상 판별 시스템은 도 1에 도시된 바와 같이 영상 데이터에 하나의 객체가 포함된 경우뿐만 아니라 영상 데이터 내 에 복수의 객체가 포함된 경우에도, 한번에 복수의 객체를 검출하고, 객체별 상태를 검출할 수 있다. 상기 낙상 판별 시스템은, 객체를 촬영하여 영상 데이터를 획득하도록 구성된 카메라 단말 및 상기 카메라 단말과 유무선으로 연결되어 상기 카메라 단말로부터 영상 데이터를 전송받도록 구성되고, 객 체를 검출하는 동시에, 객체의 상태를 검출하여, 병원 내외에서의 낙상사고 발생 여부를 판별하는 중앙 서버 를 포함한다. 다만, 이러한 도 1의 낙상 판별 시스템은, 본 발명의 일 실시예에 불과하므로, 도 1을 통하여 본 발명이 한정 해석되는 것은 아니다. 여기서, 병원은 대학 병원, 국공립 병원 등 대형 병원인 것을 전제로 하나, 이에 한정되지 않는다. 실내외에 CCTV 등의 카메라 단말을 갖고 있는 중소형 병원에서도 적용가능함은 자명하며, 낙상에 보다 민감한 요양 병원 등도 적용됨은 자명하다. 또한, 상기 낙상 판별 시스템이 적용되는 공간은 병원으로 한정되지 않는다. 예 를 들어, CCTV가 설치되어 관제가 가능한 백화점 등 큰 건물, 도로, 주택가 지역에서도 적용 가능함이 자명하다. 편의상 병원을 전제로 이하 설명한다. 또한, 객체는 모니터링 대상이되는 사람, 예를 들어, 일반인, 환자, 의사, 간호사, 직원 등을 포함한다. 도 1의 각 구성요소들은 일반적으로 네트워크(network, 10)를 통해 연결된다. 즉, 도 1에 도시된 바와 같이, 적 어도 하나의 카메라 단말은 네트워크를 통하여 중앙 서버와 연결될 수 있다. 여기서, 네트워크는, 복수의 카메라 단말 및 중앙 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능 한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는 RF, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5GPP(5th Generation Partnership Project) 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스 (Bluetooth) 네트워크, NFC 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 하기에서, 적어도 하나의 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명 하다 할 것이다. 또한, 각 구성요소가 단수 또는 복수로 구비되는 것은, 실시예에 따라 변경가능하다 할 것이다. 상기 적어도 하나의 카메라 단말은 병원 내외부에 배치되어 환경 정보를 실시간으로 촬영하는 수단이다. 이와 같은 카메라 단말는 고정초점렌즈 또는 가변초점렌즈가 갖추어질 수 있으며, 병원 내외부의 일정 지 역을 고정적으로 촬영하거나 또는 움직임이 감지된 경우, 움직임이 감지된 객체를 추적하여 촬영할 수 있다. 이 때, 카메라 단말은 고정초점렌즈 사용시 일정 지역 내로 촬영범위가 고정되며, 가변초점렌즈 사용시 일정 지역 내 촬영범위를 확대하여 조절할 수 있는 특징을 갖는다. 그리고 카메라 단말는 병원 내외부의 촬영된 영상을 상기 중앙 서버로 전달하여, 영상 내 검출된 객체의 상태를 모니터링하도록 한다. 한편, 카메라 단 말에는 IR 적외선 램프가 갖추어져 야간 촬영시에도 식별을 용이하게 할 수 있다. 이러한 카메라 단말 은 적외선을 이용해서 대상을 촬영하는 것일 수 있으며, 다만 이에 한정되는 것은 아니다. 상기 카메라 단말은 설치된 위치에서 객체를 촬영하도록 구성된다. 예를 들어, 상기 카메라 단말은, 일정 공간의 상부에 배치되어 일정 위치에서 이동 중이거나, 특정 위치를 유지하는 객체를 실시간으로 촬영함으 로써 객체와 객체의 상태가 포함된 영상 데이터를 획득하도록 구성된다. 구체적으로, 상기 카메라 단말은 1초에 다수의 프레임(이미지)을 처리 가능하도록 구성되어, 적어도 하나의 프레임이 포함된 영상 데이터를 획득 하도록 구성되며, 획득된 영상 데이터를 상기 카메라 단말과 연결된 상기 중앙 서버로 출력하도록 구 성된다. 예를 들어, 상기 영상 데이터는 동영상과 같이 사용자의 눈에 보여지게 되는 움직이는 영상의 데이터일 수 있다. 이 경우, 당해 영상 데이터에는 재생시간의 흐름에 따라 객체와 관련된 프레임뿐만 아니라 이동하는 객체가 존재하지 않는 프레임이 포함될 수 있다. 또는, 이와 달리, 객체와 관련된 영상 데이터만을 효과적으로 얻기 위하여, 상기 카메라 단말은 별도의 감지 센서 등을 통해 일정 영역에 감지되는 객체가 있을 때, 객 체를 촬영하여 모니터링하도록 구성될 수도 있다. 또한, 상기 카메라 단말은 선명한 영상 데이터를 획득하기 위하여, 자동 초점(Auto-focus) 기능, 자동 플 레쉬 기능을 포함하도록 구성될 수 있다. 또는, 상기 카메라 단말은 상기 중앙 서버로 전송된 영상 데이터 상에서 검출된 객체의 신뢰도를 기초로 초점을 맞추거나, 플레쉬를 터트리도록 구성될 수도 있다. 이에 따라, 상기 카메라 단말이 선명한 영상 데이터를 획득함에 있어, 설치된 공간으로부터의 영향을 최소화할 수 있으며, 영상 데이터 내에서 객체를 높은 신뢰도로 검출할 수 있다. 본 실시예에 따른 낙상 판별 시스템은 상기 카메라 단말이 일정 위치에 설치되어 객체를 촬영하도록 구성된 것을 예로 설명하였으나, 이에 한정되지 않는다. 예를 들어, 상기 카메라 단말은 미리 정해진 경로 를 따라 이동가능하도록 설계되거나, 촬영방향을 조절 가능하도록 설계되어, 객체를 추적하여 촬영한 영상 데이 터를 유무선으로 전송하도록 구성된 카메라를 포함하는 단말 장치일 수 있으며, 또는 카메라가 설치된 드론 등 으로 경로를 따라 이동하며 영상 데이터를 획득하도록 구성된 단말 장치일 수 있다. 또는, 스마트폰 등과 같이 카메라를 포함하는 사용자 단말 장치로서, 사용자에 의해 조작되는 핸드 헬드 방식의 단말 장치일 수도 있다. 또한, 상기 낙상 판별 시스템은, 하나의 카메라 단말로부터 획득된 영상 데이터로부터 특정 공간의 객체를 검출하는 것으로 설명하였으나, 이에 한정되지 않는다. 예를 들어, 상기 카메라 단말은 동일 공간 에서 객체를 여러 방향에서 촬영하도록 촬영방향을 달리하여 복수 개 설치될 수 있으며, 상기 낙상 판별 시스템 은 중앙 시스템으로서 하나의 객체의 상태를 파악함에 있어서 복수의 카메라 단말로부터 획득된 영상 데 이터들을 동시에 처리하도록 구성될 수 있다. 상기 중앙 서버는 상기 카메라 단말과 유무선으로 연결되어 상기 카메라 단말로부터 영상 데이 터를 전송받고, 상기 영상 데이터 상에서 객체를 검출하여 객체의 상태를 포함하는 특성을 파악하는 동시에, 객 체의 낙상을 판별하도록 구성된다. 이 때, 상기 중앙 서버는 낙상을 검출함에 있어 오류가 있는지 여부를 판정하고, 판정 결과에 따라 낙상 사고가 발생했음을 알리는 알림을 출력하도록 구성된다. 구체적으로, 상기 중앙 서버는 검출한 객체의 특성을 통해, 정상 상태와 이상 상태를 구분하고, 낙상 사고 유무를 판별함에 있어서, 이상 상태로부터 낙상이 검출된 경우, 낙상 사고로 판정하고, 정상 상태로부터 낙상이 검출된 경우, 오류라고 판정하도록 구성된다. 상기 정상 상태는 향후 객체의 상태가 일정 시간 유지되는 상태이 고, 이상 상태는 정상 상태가 아닌 상태로 낙상 사고가 발생한 객체의 전조 증상 내지 상태 데이터를 학습한 결 과에 의해 출력될 수 있다. 또한, 상기 중앙 서버는 정상 상태에서 낙상이 검출되어 오류라고 판별된 경우에도, 객체가 낙상 상태를 일정 시간 유지하는 경우, 낙상 사고로 판단하여 알림을 생성하고, 해당 낙상 사고 데이터는 학습 데이터로 활 용하여, 낙상 사고가 발생한 전조 증상의 특성을 파악하여, 객체의 이상 상태를 업데이트 학습하도록 구성한다. 즉, 상기 제2 상태의 검출이 일정 시간 지속되어 낙상 사고로 판정한 경우, 해당 낙상 사고 전후의 환자의 자세 및 동작을 포함하는 영상 데이터를 추가하여 상기 분석 모델을 업데이트할 수 있다. 이에 따라, 낙상 사고가 발 생할 수 있는 이상 상태를 학습함으로써 낙상이 발생할 전조 증상 또는 상태로부터 낙상 발생을 예측할 수 있어, 낙상 사고 판별에 있어, 오류를 최소화할 수 있다. 상기 중앙 서버는, 상기 카메라 단말과 연결되어 영상처리를 행할 수 있는 일련의 단말, 예를 들어, 스마트폰, 태블릿 PC, 이동 전화기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 카메라, 또는 웨어러블 장치 중 적어도 하나일 수 있다. 또 는, 텔레비전, DVD(digital video disk) 플레이어, 오디오, 셋톱 박스, 홈 오토메이션 컨트롤 패널, 보안 컨트 롤 패널, 미디어 박스(예: 삼성 HomeSyncTM, 애플 TVTM, 또는 구글 TVTM), 게임 콘솔(예: XboxTM, PlayStationTM), 또는 캠코더 중 적어도 하나일 수 있다. 또는, 방송 수신 기능뿐만 아니라 유무선 통신 장치 등이 추가되어, 수 기 방식의 입력 장치, 터치 스크린 또는 모션(motion) 인식 리모콘 등 보다 사용에 편리한 인터페이스 등을 지 원하는 Connected TV일 수 있다. 구체적으로, 상기 중앙 서버는, 상기 카메라 단말로부터 영상 데이터를 수신하는 통신부, 상기 카메라 단말로부터의 영상 데이터로부터 객체를 식별하고, 동영상 기반의 딥 네트워크를 적용하여 영상 데 이터에 포함된 인접한 프레임들로부터 객체의 상태 및 상태의 변화를 포함하는 특성 정보로부터 낙상을 검출하 도록 구성된 검출부, 상기 검출부에서 낙상이 검출되는 경우, 오류 검출인지 여부를 판단하는 낙상 사고 판정부, 최종적으로 낙상 사고가 발생하였다고 판정되는 되는 경우, 알림 신호를 출력하는 출력부 , 및 인공지능에 기반하여 낙상 사고로 판정된 영상데이터를 학습하도록 구성된 학습부를 포함하도록 구성된다. 상기 통신부는 외부 장치 또는 시스템과 데이터 통신을 수행하도록 구성된다. 상기 통신부는 유/무선 통신 모듈을 포함할 수 있으며, 유선 또는 무선 통신 기술을 이용하여 외부와 데이터 통신을 수행할 수 있다. 무선 통신 기술로는 WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access) 등이 이용될 수 있다. 무선 근거리 통신 기술로는 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(IrDA, infrared Data Association), UWB(Ultra Wideband), ZigBee 등이 이용될 수 있고, 유선 근거리 통신 기술로는 USB(Universal Serial Bus), IEEE 1394, 인텔사의 썬더볼트 등이 이용될 수 있다. 상기 통신부는 적어도 하나 이상의 카메라 단말로부터 위치별 영상 데이터를 수신한다. 위치별 영상 데이터는 공간 내 설치된 카메라 단말의 식별변호와 등록된 맵 정보를 기초하여, 맵 상의 위치별 영상 데 이터를 수신할 수 있다. 상기 영상 데이터들은 객체 식별 및 검출을 위해 검출부로 전송된다. 또한, 상기 통신부는 영상 데이터로부터 낙상 사고가 발생한 것으로 판정되면, 출력부에서 출력한 알림 신호를 응급 담당자의 단말에 전송하여 응급 담당자를 호출하도록 구성된다. 상기 알림 신호는, 객체의 식별 정보, 객체의 현재 상태 및 위치 정보를 포함할 수 있다. 상기 응급 담당자는, 예를 들어, 병원 내에서는 응급 담당자는 담당 의사, 간호사, 등 응급 훈련이 되어 있는 담당자일 수 있다. 상 기 통신부는 응급 담당자가 고정되어 있는 경우, 해당 응급 담당자에게 호출을 할 수 있으며, 또는, 객체 의 위치 정보로부터, 인접한 응급 담당자에게 호출을 할 수도 있다. 또한, 응급 상황 여부에 따라 즉각적인 조 치, 예를 들어 수술이 필요한 경우, 관련 응급 담당자를 모두 호출할 수 있다. 즉, 호출을 받는 응급 담당자는 복수일 수 있다. 상기 검출부는 딥 러닝 알고리즘을 이용하여 객체 및 객체의 특성을 검출하도록 구성된다. 예를 들어, 상 기 검출부는 상기 카메라 단말로부터 입력된 영상 데이터에 대해 일정 시간 간격으로 객체를 자동으 로 검출하고, 검출된 객체에 대해 딥 네트워크를 이용한 추적 기술을 적용함으로써 실시간 처리를 행하고, 객체 가 검색되는 영역을 최소화하는 방법을 적용하여 딥 네트워크를 설계하고 트레이닝하도록 구성될 수 있다. 상기 딥 네트워크는 DNN(Deep Neural Network) 기반의 딥 러닝 알고리즘에 따른 신경 회로망일 수 있으며, 해당 신경 회로망은 입력층(Input Layer), 하나 이상의 은닉층(Hidden Layers) 및 출력층(Output Layer)으로 구성된다. 여기서의, 상기 딥 네트워크는 DNN 이외의 다른 신경망이 적용될 수도 있으며, 일례로, CNN(Convolution Neural Network)이나 RNN(Recurrent Neural Network) 또는 이들이 조합된 신경망이 적용될 수도 있다. 이하, 상기 검출부에 대해, 도 3 및 도 4를 참조하여, 상세히 설명한다. 도 3은 도 2의 검출부를 설명하기 위한 블록도이다. 도 4는 도 2의 검출부에 의한 계층적 검출을 위한 설명하기 위한 예시도이다. 도 3 및 도 4를 참조하면, 상기 검출부는 입력된 영상 데이터 중 적어도 하나의 프레임으로부터 객체 및 객체의 특성을 검출하도록 구성된다. 예를 들어, 상기 검출부는 영상 데이터의 연속된 복수의 프레임 또는 이들로부터 랜덤으로 추출된 일정 개수 이상의 프레임에 대해, 동영상 기반의 딥 네트워크를 적용하여 객체를 검출할 수 있다. 이 경우, 인접하는 프레임들으로부터 검출되는 객체의 움직임을 추적할 수 있으며, 또한 프레 임별로 복수의 객체가 포함된 경우에도, 각 객체 별로 움직임을 추적할 수도 있다. 객체의 특성은, 객체의 상태, 및 낙상 발생 여부 등을 포함한다. 한편, 상기 검출부는 카메라 단말로부터 수신된 영상 데이 터를 지속적으로 모니터링하면서 객체 및 객체의 특성을 검출하도록 구성될 수 있으며, 또는 이와 달리, 영상 데이터 내에 객체가 존재하는 경우, 별도의 제어부 신호에 기초하여, 모니터링을 개시하도록 구성될 수도 있다. 또한, 도시되진 않았으나, 상기 카메라 단말로부터 획득된 영상 데이터는 상기 검출부에 입력되기 전, 그레이(Gray) 변환 및 평활화(Equalize) 처리 등이 되도록 구성될 수 있다. 여기서, 그레이 변환은 3채널 색상을 가진 이미지를 gray scale의 이미지로 바꾸는 것인데 이는 평활화 처리를 효과적으로 하기 위한 것이며, 평활화 처리는 조명 또는 플레쉬에 의해 이미지의 밝기 분포가 치우친 것을 넓은 영역에 거쳐 분포하도록 넓혀 주기 위한 것으로, 즉, 밝기 분포를 넓히기 위함이다. 이에 따라, 영상 데이터 내에서 객체를 높은 신뢰도로 검 출할 수 있다. 한편, 상기 영상 데이터에는 공지의 다양한 이미지 처리 기법 역시 적용될 수 있으며, 이에 대해 서는 자세한 설명을 생략한다. 아울러, 상기 영상 데이터는 상기 검출부에 입력되기 전에 처리되는 것을 예로 설명하였으나, 이에 한정되진 않는다. 예를 들어, 상기 검출부가 영상 데이터 내에서 객체를 검출한 이후, 객체 특성을 검출하기 위해서 해당 영상 데이터를 처리하도록 구성될 수도 있다. 구체적으로, 상기 검출부는 영상 데이터 내에 포함된 객체를 검출하는 객체 검출부, 검출된 객체의 상태를 검출하도록 구성된 이상 상태 검출부 및 객체의 동작을 기초로 해당 객체의 낙상을 검출하도록 구성된 낙상 검출부를 포함하도록 구성된다. 상기 객체 검출부는 딥 네트워크를 이용하여 상기 카메라 단말로부터 입력된 영상 데이터에 대해 자 동으로 객체를 검출하도록 구성되며, 검출된 객체의 위치 정보, 크기 정보, 그리고 검출의 신뢰도 값 등을 출력 하도록 구성될 수 있다. 아울러, 상기 객체 검출부는 상기 카메라 단말로부터 촬영되는 객체의 크기 를 사전에 모르기 때문에 영상 데이터에서 미리 설정된 스케일들 각각에서 객체 영역을 검색하면서 객체 존재 유무를 확인하여, 객체를 검출하도록 구성된다. 한편, 상기 객체 검출부는 객체가 검출되면, 객체가 검출 된 영역을 경계로 하는 형태로 표시할 수 있다. 여기서 경계 영역은 직사각형일 수 있으며, 다만 이에 한정되는 것은 아니다. 보다 구체적으로, 각 객체의 특징 위치를 지정할 수 있을 관심영역을 자동 설정한 후 핵심 점의 좌표 파악을 통해 절대 및 상대적 물체간 거리 파악 기술을 통해 이동 활동량등을 감지하함으로써, 낙상이 방지 될 수 있다. 상기 이상 상태 검출부는 검출된 객체의 상태를 검출하도록 구성된다. 상기 이상 상태 검출부는 낙상 사고 전후의 객체의 자세, 동작 등의 상태 정보를 학습한 분석 모델에 기초하여 객체의 상태가 이상 상태인지 여부를 검출하도록 구성된다. 예를 들어, 상기 이상 상태 검출부는 상기 분석 모델에 기초하여, 환자의 상 태 정보를 추출하도록 구성된다. 예를 들어, 객체의 신체에 대한 각 관절에 대응되는 좌표를 추출하고, 객체의 신체의 움직임 및 좌표의 위치를 추적하도록 구성된다. 구체적으로, 상기 이상 상태 검출부는 검출한 객체의 상태를 통해, 정상 상태와 이상 상태를 검출하도록 구성된다. 상기 정상 상태는 향후 일정 시간 내에 낙상이 발생하지 않을 확률이 일정 값보다 높은 상태이며, 이 상 상태는 정상 상태가 아닌 상태로 향후 일정 시간 내에 낙상이 발생할 확률이 일정 값보다 높은 상태를 의미 한다. 상기 일정 값은 신뢰도에 기초하여 설정될 수 있다. 즉, 본 실시예에 따른 이상 상태 검출부는 낙상 사고가 발생한 객체의 전후 상태를 학습한 분석 모델에 의해 낙상의 전조 증상 등의 이상 상태 여부를 판단할 수 있다. 즉, 상기 분석 모델은 불특정 다수의 객체별 자세, 동작 등의 특성과 낙상이 발생된 일정 시간 이전의 상태의 객체별 자세, 동작 등의 특성을 학습하여, 정상 상태에서의 공통된 특성 정보와 이상 상태에서의 공통된 특성 정보를 추출하거나, 또는 비교 등을 통하여 학습하도록 구성된다. 이 때, 학습 방법은 지도학습 (Supervised Learning) 또는 비지도 학습(Unsupervised Learning)일 수 있고, 비지도 학습의 경우, 자기 지도 학습(Self-Supervised Learning) 방법에 의할 수 있다. 예를 들어, 상기 분석 모델의 학습에 있어서, 객체의 상체의 중심 좌표값이 침상의 모서리 영역과 일정 거리 내 로 인접한 경우, 다수의 낙상이 발생된 공통적인 특성이 추출되는 경우, 상기 이상 상태 검출부는, 객체의 신체에 대한 각 관절에 대응되는 좌표 값을 기준으로 해당 조건이 충족될 경우, 낙상이 발생될 확률이 높다고 판단하여, 객체의 현 상태를 이상 상태로 판정할 수 있다. 구체적으로, 상기 이상 상태 검출부는 복수의 프레임들 각각에 대한 특성을 추출하여 특성 맵(feature map)들을 생성하고, 이들을 연산하여, 상기 각각의 프레임 영상들에서 객체의 상태에 있어서의 신체의 20개의 관절에 대해 각각의 좌표를 추론하도록 구성된다. 신체의 관절의 갯수는 한정되지 않는다. 또한, 상기 이상 상 태 검출부는 객체의 이상 상태를 검출함에 있어서, 객체의 주위 사물에 대해 미리 지정된 관절 정보를 추 가로 학습시킨 분석 모델에 기초할 수도 있다. 이 경우, 상기 분석 모델에 의해 침상의 네 각을 관절이 추출되 고, 객체의 신체 관절 정보와 침상의 네 각의 관절 정보의 조합을 통해, 객체의 이상 상태 여부를 판단할 수도 있다. 한편, 상기 특성 맵의 생성 및 연산은 컨볼루션 신경망(convolution neural network; CNN) 및/ 또는 순환 신경 망(recurrent neural network RNN)을 기반으로 구현되는 레이어, 정정 선형 유닛(rectified linear unit; RELU) 레이어, 풀링(pooling) 레이어, 바이어스 가산(bias add) 레이어, 소프트맥스(softmax) 레이어 등과 같 은 다양한 연산 레이어들을 포함하는 연산 모델에 의해 구현될 수 있다. 또는 전술한 각 객체의 낙상 가능성은 그래픽 기반의 신경망(GNN, GRAPHIC NEURAL NETWORK)에 기반해서 추론될 수 있다. 구체적으로, 객체의 각 신체 부위가 GNN에서의 각 노드로 표현되고, 각 노드가 링크로 연결됨으로써 표현될 수 있다. 그리고 이러한 GNN에서의 노드와 링크로 표현된 객체의 낙상 당시의 위치 내지 서로 간의 관계 등이 학습될 수 있다. 여기서, 인공 신경망(artificial neural network; ANN)이란 연결 선으로 연결된 많은 수의 인공 뉴런들을 사용 하여 생물학적인 시스템의 계산 능력을 모방하는 소프트웨어나 하드웨어로 구현된 연산 모델을 나타낸다. 상기 인공 신경망에서는 생물학적인 뉴런의 기능을 단순화시킨 인공 뉴런을 사용하게 된다. 그리고 연결 강도를 갖는연결 선을 통해 상호 연결시켜 인간의 인지 작용이나 학습 과정을 수행하게 된다. 즉, 상기 이상 상태 검출부 에서 이용되는 상기 연산 모델은 상기 인공 신경망을 이용하여 미리 학습된 상태의 연산 모델일 수 있다. 상기 낙상 검출부는 동영상 기반의 딥 네트워크를 적용하여 인접하는 복수의 프레임들 내에 검출된 낙상 동작의 환자의 상태 정보의 변화를 학습한 분석 모델에 기초하여 환자의 낙상을 검출하도록 구성된다. 즉, 각 프레임별 환자의 낙상 자세 및 동작 등을 포함하는 상태 정보의 변화를 검출하도록 구성된다. 예를 들어, 상기 낙상 검출부는 신체 상의 관절들 중, 분석의 대상이 되는 관절을 추출하고, 추출된 해당 관절의 좌표 이동 값 등을 이용하여 객체의 낙상을 동작을 분석하도록 구성될 수 있다. 예를 들어, 상기 낙상 검출부는 낙상 이 완료된 상태에서의 관절에 대한 미리 저장된 정보들, 예를 들어, 영상 데이터 내 검출된 객체의 시점(view point)에 따라, 낙상이 이루어진 상태에서 팔과 다리의 관절의 위치 정보가 동일 레벨 상에 존재하는 등의 위치 정보를 참조하여, 낙상이 발생되었는지 여부를 판단할 수 있다. 또한, 상기 낙상 검출부는 인접한 프레임들 내의 객체의 관절의 절대 위치 및 다른 관절과의 상대 위치 등 을 분석하고, 전후 프레임에서의 해당 관절의 이동 방향, 이동 속도, 이동한 궤적 등을 분석하여, 관련된 관절 의 이동 정보를 추출하도록 구성될 수 있다. 예를 들어, 상기 낙상 검출부는 상기 분석 모델에 기초하여, 객체의 신체에 대한 각 관절에 대응되는 좌표 를 추출하고, 객체의 신체의 움직임 및 좌표의 위치를 추적하도록 구성되며, 낙상 사고가 발생한 객체의 상태의 변화 데이터를 학습한 분석 모델에 의해 낙상의 발생 여부를 판단할 수 있다. 즉, 상기 분석 모델은 낙상 사고 가 발생된 불특정 다수의 객체별 자세, 동작 등의 변화 정보를 학습하여, 낙상의 공통된 특성 정보를 추출하도 록 구성된다. 이 때, 학습 방법은 마찬가지로, 지도학습 또는 비지도 학습일 수 있으며, 비지도 학습의 경우, 자기 지도 학습 방법에 의할 수 있다. 즉, 상기 낙상 검출부는 상기 분석 모델을 기초로, 객체의 분석의 대상이 되는 추출된 관절의 좌표 이동 값을 기준으로 낙상이 발생 여부를 판정할 수 있다. 예를 들어, 상기 낙상 검출부는 상기 이상 상태 검출 부와 마찬가지로, 복수의 프레임들 각각에 대한 특성을 추출하여 특성 맵(feature map)들을 생성하고, 이 들을 연산하여, 상기 각각의 프레임 영상들에서 객체의 동작에 있어서의 신체의 20개의 관절에 대해 각각의 좌 표의 변화를 추적하도록 구성된다. 한편, 상기 낙상 검출부는 객체의 낙상 동작을 분석하는 것을 예로 설명하였으나, 이에 한정되지 않는다. 예를 들어, 도 4에 도시된 바와 같이, 상기 낙상 검출부는 학습 데이터에 따라 객체의 상태나 동작을 분석 하여, 낙상 뿐만 아니라. 휴식(Resting), 침상에서 벗어남(Out-of-bed) 등의 객체의 세부 동작을 분석할 수 있 으며, 낙상에 있어서도, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen)으로 세분화하여 분석할 수 도 있다. 즉, 상기 낙상 검출부는 동작 분석에 따른 Action Classifier로서 기능할 수 있다. 이 때, 상기 낙상 검출부는, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen)가 모두 검출되는 것을 전제로 낙상을 검출할 수 있다. 다만, 이에 한정되지 않는다. 입력되는 영상 데이터로부터 실시간으로 객체 검출이 이루어는 경우, 객체가 이동 중에 카메라 단말의 상에 잡히기 시작하거나 또는 벗어나는 경우와 같이, 당해 영상 데이터 중 일부 프레임에는 당해 객체의 동작 일부분만이 포함될 수 있고, 이 경우 낙상이 이루어짐에 따라 객체가 이후 프레임 내에 포함 되지 않을 수도 있다. 이 경우, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen) 중 일부만 검출되 어도 낙상을 검출할 수 있다. 한편, 분석 모델의 학습은 경사하강법을 적용하여 선정된 횟수만큼 반복 될 수 있다. 학습은 인공신경망 기법, 의사결정 나무기법과 오토 머신러닝 기법 등의 학습구조가 선정될 수 있다. 상기 이상 상태 검출부과 상기 낙상 검출부에서 기초하는 분석 모델은 상기 중앙 서버에서 생성하거나, 별도의 학습 서버(미도시)에 서 생성될 수 있다. 이 경우, 통신을 통해 상기 중앙 서버와 연결되도록 구성될 수 있으며, 상기 학습 서 버는 중앙 서버에서 데이터를 가져올 수 있도록 원격 호출 기반으로 연결될 수 있다. 또한, 인공지능의 학습 방법으로는 의사결정 나무기법, 오토 머신러닝 기법이 적용될 수 있음은 자명하다. 구체 적으로, 상기 의사결정나무 기법에는 의사결정 나무(Decision Tree), 랜덤 포레스트(Random Forest), 그레디언 트 부스팅(Gradient Boosting) 등의 기법이 포함될 수 있다. 또한, 상기 오토 머신러닝 기법에는 인공신경망의 은닉층의 개수와 뉴런의 개수 등에 대한 하이퍼 파라미터를 인공지능이 자동으로 조정하는 기법, 의사결정나무 기법 및 인공신경망을 포함한 현존하는 인공지능 기법을 다층으로 연결하여 학습하는 스테킹(Stacking) 및 앙상 블(Ensemble) 기법, 또는 상기의 스테킹(Staking), 앙상블(Ensemble), 하이퍼 파라미터에 대한 자동 튜닝을 동시에 사용하는 기법이 포함될 수 있다. 특히, 상기 이상 상태 검출부과 상기 낙상 검출부에서 기초하는 분석 모델은 서로 다른 종류의 인공 지능 모델일 수 있다. 이 경우, 상기 이상 상태 검출부과 상기 낙상 검출부는 서로 다른 인공지능 모 델인 제1 분석 모델 및 제2 분석 모델에 각각 영상 데이터를 입력할 수 있다. 또한, 동일한 영상 데이터라도 어 떤 인공지능 모델을 이용하는지에 따라 검출 결과가 다를 수 있으므로, 검출하고자 하는 이상 상태와 낙상을 서 로 다른 인공지능 모델을 사용하기 때문에, 보다 정확한 검출 결과를 획득할 수 있고, 검출에 소요되는 시간을 최소화할 수 있다. 다만, 이에 한정되지 않는다. 상기 이상 상태 검출부과 상기 낙상 검출부에서 기 초하는 분석 모델은 서로 동일한 인공지능 모델일 수 있다. 한편, 본 실시예에 따른 검출부는 도 4에 도시된 바와 같이, 검출된 객체의 상태 정보와 낙상 여부에 대한 정보를 계층화하여 출력하도록 구성된다. 즉, 상위 레벨(High-level)에서는 정상 상태(normal)와 이상 상태 (abnormal)가 출력되고, 하위 레벨(Low-level)에서는 객체의 동작 분석에 따른 휴식(Resting), 침상에서 벗어남 (Out-of-bed), 낙상이 이루어지고 있는 상태(Falling)와 낙상이 이미 이루어진 상태(Fallen) 등으로 출력될 수 있다. 다만, 이에 한정되지 않는다. 또한, 본 실시예에 따른 검출부는 영상 데이터가 수신되면, 객체 검출부, 이상 상태 검출부 및 낙상 검출부가 각 검출 대상을 검출하는 것을 예로 설명하였으나, 이에 한정되지 않는다. 본 발명의 목적 인 낙상 검출의 오류를 최소화하기 위하여, 상기 이상 상태 검출부 및 상기 낙상 검출부는 상기 객체 검출부에서 객체의 검출이 이루어진 경우, 검출을 위한 동작을 개시하도록 구성될 수 있다. 한편, 이상 상 태 검출부 및 낙상 검출부는 동시에 또는 이시에 검출을 수행할 수 있다. 상기 낙상 사고 판정부는 상기 이상 상태 검출부 및 상기 낙상 검출부의 출력들에 기초하여, 낙 상 검출에 오류가 있는지 여부를 판단하여, 낙상 사고가 발생되었는지 여부를 판정하도록 구성된다. 상기 낙상 사고 판정부는 낙상 사고 발생시 출력부에서 알림 신호를 출력하는 것을 전제로, 낙상 검출 오류에 따른 불필요한 알림 신호 출력을 방지하는 것을 목적으로 한다. 예를 들어, 상기 낙상 사고 판정부는 상기 낙상 검출부에서 객체의 낙상이 검출되는 경우, 계층적으 로 상위에 있는 객체의 상태가 이상 상태가 아닌 정상 상태에서 낙상이 검출된 경우는, 낙상 검출에 오류가 있 다고 판정하도록 구성된다. 즉, 상기 낙상 사고 판정부는 낙상이 검출된 시점 이전의 일정 시간 내에 이상 상태가 검출되지 않은 경우, 또는 낙상이 검출된 시점에서의 객체의 상태가 이상 상태가 아닌 경우에는 상기 낙 상 검출부에서 낙상이 검출되어도 오류로 판정하도록 구성된다. 즉, 본 실시예에 따른 낙상 사고 판정부는 딥러닝에 기반하여 낙상이 전조되는 이상 상태가 학습된 분석 모델에 기초하여, 객체의 상태의 맥락에 따라 낙상을 예측하고, 그에 따라 실제 낙상이 검출된 경우, 낙상이 발 생되었다고 판정함으로써, 낙상 검출의 오류를 최소화할 수 있다. 한편, 상기 낙상 사고 판정부는 정상 상태에서 낙상이 검출되어 오류라고 판정한 경우에도, 객체가 낙상 상태를 일정 시간 유지하는 경우, 낙상 사고로 판정할 수 있다. 이 경우, 해당 데이터는 후술하는 학습부 에서 이상 상태 검출을 위한 분석 모델의 업데이트를 위한 학습 데이터로 활용하도록 구성된다. 즉, 상기 학습 부에서는 낙상 사고가 발생한 전조 증상의 특성을 파악하여, 객체의 이상 상태를 업데이트 학습하도록 구 성한다. 이에 따라, 낙상 사고가 발생할 수 있는 이상 상태를 학습함으로써 낙상이 발생할 전조 증상 또는 상태 로부터 낙상 발생을 예측할 수 있어, 낙상 사고 판별에 있어, 오류를 최소화할 수 있다. 또한, 상기 낙상 사고 판정부는 낙상 검출부에서 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태 (Fallen)으로 세분화하여 분석하는 경우, 이상 상태에서 낙상이 검출되고, 각 상태가 순차적으로 검출되는 경우 에 한해, 낙상을 최종 판정할 수 있다. 예를 들어, 영상 데이터에 객체가 검출되는 것을 전제로, 낙상 상태만 검출되고, 이전 단계에서 낙상이 이루어지고 있는 상태는 검출되지 않은 경우, 오류로 판정하도록 구성될 수 있 다. 또는, 상기 낙상 사고 판정부는 상기 낙상이 이루어지고 있는 상태(Falling)가 검출된 경우라도, 1초에 처 리되는 프레임의 수를 고려하여, 인접하는 2개 내외의 프레임에만 낙상이 이루어지고 있는 상태가 검출되는 경 우는, 낙차가 크지 않은 경우라고 판단하여, 낙상 사고로 최종 판정하지 않을 수 있다. 다만, 이 경우라도, 객 체의 식별이 추가되어, 객체가 중증 환자 또는 고령의 환자로 식별되는 경우, 객체의 성격에 따라 낙상 사고로 판정할 수도 있다. 또한, 상기 낙상 검출부에 의해 낙상이 검출된 경우라도, 낙상 상태(Fallen)가 인접하 는 다수의 프레임에서 유지되는 경우, 낙상 사고가 발생한 것으로 판정할 수 있다. 예를 들어, 10 프레임이 유지되면, 낙상 사고로 최종 판정할 수 있다. 즉, 상기 낙상 사고 판정부는 상기 검출부에서 검출된 데이터를 기초로 낙상 사고를 판정함에 있어서, 후처리로서, 검출의 오류를 판정하는 기능을 수행한다. 이에 따라, 낙상 검출의 오류를 최소화할 수 있 다. 이에 따라, 종래의 규칙 기반(Rule-based) 방식으로 영상 데이터 상에서 객체의 낙상을 검출하는 경우, 빈번하 게 발생되는 검출 오류에 의해 불필요한 자원이 낭비되는 문제가 있었으나, 본 발명의 일 실시예에 따른 낙상 판별 시스템은 객체의 낙상 검출에 있어 오류를 판정하도록 구성됨으로써, 검출의 오류를 최소화할 수 있 다. 또한, 당해 검출의 오류를 포함하는 영상 데이터는 별도의 학습 DB에 저장되며, 객체 검출의 분석 모델의 업데이트를 위한 데이터로 활용될 수 있다. 예를 들어, 당해 학습 DB에 저장된 영상 데이터는 후술하는 학습부 또는 별도로 구비된 학습 서버로 전송되도록 구성될 수 있다. 상기 출력부는 상기 낙상 사고 판정부에서 영상 데이터 내에 검출된 객체에 낙상 사고가 발생한 것으 로 판정되면, 알림 신호를 출력하도록 구성된다. 상기 알림 신호가 출력되면, 인접한 응급 담당자를 호출하고, 응급조치가 이루어질 수 있도록 지원할 수 있다. 예를 들어, 낙상 사고가 발생한 것으로 판정되면, 낙상이 발생된 카메라 단말의 설치 위치 정보와 맵(map) 정보를 기반으로 객체의 현재 위치 정보를 포함하는 응급 정보가 함께 응급 담당자에게 전송될 수 있다. 상기 응급 담당자는, 예를 들어, 병원 내에서는 응급 담당자는 담당 의사, 간호사, 등 응급 훈련이 되어 있는 담당자 일 수 있다. 상기 출력부는 응급 담당자가 고정되어 있는 경우, 해당 응급 담당자에게 호출을 할 수 있으 며, 또는, 낙상이 발생한 객체의 위치 정보로부터, 인접한 응급 담당자에게 호출을 할 수도 있다. 또한, 응급 상황에 따라 수술이 필요한 경우, 관련 응급 담당자를 모두 호출할 수 있다. 즉, 호출을 받는 응급 담당자는 복 수일 수 있다. 아울러, 해당 공간이 병원이 아닌 경우에는 낙상 사고가 발생되면, 상기 출력부는, 객체를 병원으로의 호 송을 위해 119 또는 인근 병원으로 신고를 할 수 있다. 본 실시예의 출력부는 낙상 사고가 발생되면, 응급 담당자의 알림을 위한 알림 신호를 출력하는 것을 예로 설명하였으나, 이에 한정하지 않는다. 예를 들어, 상기 출력부는 디스플레이, 스피커 등 다양한 수단으로 즉각적인 응급조치가 이루어질 수 있도록 지원할 수 있다. 도 5는 도 2의 학습부를 설명하기 위한 블록도이다. 도 2 내지 도 5를 참조하면, 상기 학습부는 딥 러닝에 기반하여 낙상과 관련된 불특정 다수의 영상 데이터 를 수집하고, 해당 영상 데이터를 학습하여 적어도 하나 이상의 분석 모델을 생성하고, 검출된 낙상의 영상 데 이터를 포함하는 추가의 영상 데이터가 수신되면, 지속적으로 상기 분석 모델을 업데이트하도록 구성된다. 상기 학습부는 데이터 수집부, 모델 생성부 및 모델 업데이트부를 포함한다. 상기 데이터 수집부은 분석 모델 생성을 위한 인공지능 학습을 위한 자료를 수집하도록 구성된다. 예를 들 어, 상기 데이터 수집부은 낙상과 관련된 불특정 다수의 영상 데이터를 수집하도록 구성된다. 상기 모델 생성부는 딥 러닝에 기반하여 불특정 다수의 객체별 낙상과 그 시점으로부터 일정 시간 전의 상 태가 포함된 영상 데이터를 학습하여 제1 분석 모델을 생성하도록 구성된다. 여기서의 제1 분석 모델은, 낙상이 발생된 공통의 전조 증상 등의 이상 상태에 대한 특성 정보를 추출하도록 구성된다. 즉, 상기 제1 분석 모델은 불특정 다수의 정상 상태에서의 객체별 자세, 동작 등의 상태 특성과 낙상이 발생된 일정 시간 이전의 이상 상 태에서의 객체별 자세, 동작 등의 상태 특성의 상관관계를 학습하여, 정상 상태에서의 공통된 특성 정보와 이상 상태에서의 공통된 특성 정보를 추출하거나, 또는 비교 등을 통하여 이상 상태의 특성 정보를 학습하도록 구성 된다. 이 때, 학습 방법은 지도학습(Supervised Learning) 또는 비지도 학습(Unsupervised Learning)일 수 있 고, 비지도 학습의 경우, 자기 지도 학습(Self-Supervised Learning) 방법에 의할 수 있다. 한편, 상기 모델 생성부는 딥 러닝에 기반하여, 주변 환경과의 관계에서 객체의 상태에 대한 특성 정보를 학습하도록 구성될 수 있다. 예를 들어, 객체 주변의 의자, 침상, 휠체어, 계단, 및 통로 등을 인식하고, 주변 환경의 특성 정보에 대한 객체의 상태에 대한 상대적인 특성 정보를 학습할 수 있다. 일례로, 주변 환경의 특성 추출을 위해, 주변 환경의 적어도 하나의 지점에 관절 정보를 부여하여, 이를 학습할 수 있으며, 이에 따라, 객 체의 상체의 중심 좌표값이 침상의 모서리 영역과 일정 거리 내로 인접한 경우, 다수의 낙상이 발생되는 공통적 인 특성을 추출할 수도 있다. 따라서, 상기 이상 상태 검출부는, 제1 분석 모델에 기초하여 수신된 영상데이터 내의 객체의 특성 정보가 추출된 공통적인 특성 정보와 일정 신뢰도 이상으로 일치하는 경우, 낙상이 발 생될 확률이 높다고 판단하여, 현재 상태를 이상 상태로 출력할 수 있으며, 이에 따라, 객체의 상태를 모니터링 하면서, 객체별 High-level의 상태를 검출할 수 있다. 또한, 상기 모델 생성부는 딥 러닝에 기반하여 낙상 시의 객체의 상태 변화 분석을 위해, 낙상이 포함된 영상 데이터를 학습하여 제2 분석 모델을 생성하도록 구성된다. 여기서의 제2 분석 모델은, 낙상 시의 객체의 특성 정보를 추출하도록 구성되며, 예를 들어, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen)의 특성 정보를 구분하여 추출하도록 구성될 수 있다. 즉, 상기 제2 분석 모델은 낙상 시의 불특정 다수의 객체별 자세, 동작 등의 상태 변화를 학습하여, 낙상이 이루어지고 있는 상태의 공통된 특성 정보와 낙상 상태의 공통 된 특성 정보를 학습하도록 구성된다. 이 때, 학습 방법은 지도학습(Supervised Learning) 또는 비지도 학습 (Unsupervised Learning)일 수 있고, 비지도 학습의 경우, 자기 지도 학습(Self-Supervised Learning) 방법에 의할 수 있다. 따라서, 상기 낙상 검출부는, 제2 분석 모델에 기초하여 수신된 영상 데이터 내의 객체의 특성 정보가 추 출된 낙상 시의 공통적인 특성 정보와 일정 신뢰도 이상으로 일치하는 경우, 낙상이 이루어지고 있거나, 낙상된 상태일 확률이 높다고 판단하여, 현재 상태를 낙상으로 출력할 수 있다. 한편, 상기 제2 분석 모델은 낙상이 포함된 영상 데이터를 학습하는 것을 예로 설명하였으나, 이에 한정되진 않 는다. 객체의 Low-level의 상태를 검출하기 위해, 정상 상태에서의 객체별 다양한 상태를 학습할 수 있다. 따라 서, 상기 제1 분석 모델의 학습과 마찬가지로, 주변 환경과의 관계에서 객체의 상태에 대한 특성 정보를 학습하 도록 구성될 수 있다. 이에 따라, 객체의 상태를 모니터링하면서, 객체별 Low-level의 상태를 검출할 수 있다. 또한, 인공지능의 학습 방법으로는 의사결정 나무기법, 오토 머신러닝 기법이 적용될 수 있음은 자명하다. 구체 적으로, 상기 의사결정나무 기법에는 의사결정 나무(Decision Tree), 랜덤 포레스트(Random Forest), 그레디언 트 부스팅(Gradient Boosting) 등의 기법이 포함될 수 있다. 또한, 상기 오토 머신러닝 기법에는 인공신경망의 은닉층의 개수와 뉴런의 개수 등에 대한 하이퍼 파라미터를 인공지능이 자동으로 조정하는 기법, 의사결정나무 기법 및 인공신경망을 포함한 현존하는 인공지능 기법을 다층으로 연결하여 학습하는 스테킹(Stacking) 및 앙상 블(Ensemble) 기법, 또는 상기의 스테킹(Staking), 앙상블(Ensemble), 하이퍼 파라미터에 대한 자동 튜닝을 동 시에 사용하는 기법이 포함될 수 있다. 데이터 학습 방법에 있어서도, 기계 학습(Machine Learning) 또는 지도 학습(Supervised Learning) 등 다양한 방법에 기초할 수 있으며, 머신 러닝을 수행함에 있어서 CNN, RNN, 이들의 조합 등 다양한 인공신경망 모델이 적용될 수 있다. 즉, 상기 이상 상태 검출부과 상기 낙상 검출부는 서로 다른 제1 분석 모델 및 제2 분석 모델에 각각 영상 데이터를 입력하여, 객체의 상태를 검출하도록 구성된다. 이 경우, 동일한 영상 데이터라도 어떤 인공지능 모델을 이용하는지에 따라 검출 결과가 다를 수 있으므로, 검출하고자 하는 이상 상태와 낙상을 서로 다른 인공 지능 모델을 사용하기 때문에, 보다 정확한 검출 결과를 획득할 수 있고, 검출에 소요되는 시간을 최소화할 수 있다. 다만, 이에 한정되진 않는다. 상기 제1 분석 모델과 제2 분석 모델은 동일한 분석 모델일 수 있다. 또한, 상기 모델 업데이트부는 상기 카메라 단말로부터 수신되는 영상 데이터를 누적하여 학습 DB에 저장하고, 이를 추가로 학습하여 분석 모델을 업데이트하도록 구성된다. 예를 들어, 상기 모델 업데이트부는 유의미한 영상 데이터가 추가되는 시점에, 분석 모델을 업데이트할 수 있으며, 다음 데이터의 학습 주기에 피드백하도록 구성된다. 예를 들어, 유의미한 특성을 분석하기 위해서 최소 로 필요한 데이터량을 지정하고, 수집된 영상 데이터가 최소로 필요한 데이터량을 충족하는 경우, 업데이트를 수행하도록 할 수 있다. 여기서, 유의미한 영상 데이터는 검출하고자 하는 객체의 상태, 예를 들어, 낙상이 포함된 영상 데이터이거나, 또는 검출의 오류가 포함된 영상 데이터일 수 있다. 예를 들어, 정상 상태에서 낙상이 검출되어 오류라고 판정 된 되었으나, 객체가 낙상 상태를 일정 시간 유지하는 경우, 해당 영상 데이터는 학습 데이터로 활용하여, 낙상 사고가 발생한 이상 상태 특성 추출을 위해 제2 분석 모델을 업데이트 학습하도록 구성한다. 이에 따라, 낙상 사고가 발생할 수 있는 이상 상태를 지속적으로 업데이트하여 학습함으로써 낙상이 발생할 전조 증상 또는 상태 로부터 낙상 발생을 예측할 수 있어, 낙상 사고 판별에 있어, 오류를 최소화할 수 있다. 한편, 본 실시예에서는 상기 중앙 서버가 학습부를 포함하는 것을 예로 설명하였으나, 이에 한정되지 않는다. 예를 들어, 별도의 학습 서버(미도시)에서 분석 모델을 생성하고, 모델을 업데이트할 수 있다. 이경우, 통신을 통해 상기 중앙 서버와 연결되도록 구성될 수 있으며, 상기 학습 서버는 중앙 서버에서 데이 터를 가져올 수 있도록 원격 호출 기반으로 연결될 수 있다. 본 실시예에 따른 중앙 서버의 구성들 중 적어도 하나 및 이들을 제어하기 위한 구성은 하드웨어 구성 (hardware component), 프로세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component) 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), FLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro- controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적인 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 특히, 상기 검출부는 인공 지능(AI; artificial intelligence)을 위한 전용 하 드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그 래픽 전용 프로세서(예: GPU)의 일부로 제작되어 상기 중앙 서버에 탑재될 수도 있다. 소프트웨어적인 구현에 의하면, 별도의 소프트웨어 모듈들로 구현될 수 있다. 상기 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있으며, 적절한 프로그램 언어로 쓰여진 소프트 웨어 어플리케이션으로 소프트웨어 코드가 구현될 수 있다. 상기 소프트웨어 코드는 중앙 서버의 메모리에 저장되고, 별도의 제어부에 의해 실행될 수 있다. 특히, 상기 검출부는 소프트웨어 모듈(또는, 인스트럭션 (instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능 한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또 는, 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 본 실시예에 따른 낙상 판별 시스템은 카메라 단말과 중앙 서버로 구현되는 것을 예로 설명하 였으나, 이에 한정되지 않는다. 예를 들어, 상기 낙상 판별 시스템은 하나의 객체 판독 단말로서 구현될 수 있으며, 이 때, 상기 객체 판독 단말은 카메라를 포함하며, 동시에 영상처리를 행할 수 있는 일련의 단말일 수 있으며, 예를 들어, 스마트폰, 태블릿 PC, 이동 전화기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 카메라, 또는 웨어러블 장치 중 적어도 하나일 수 있다. 또는, 텔레비전, DVD(digital video disk) 플레이어, 오디오, 셋톱 박스, 홈 오토메이션 컨트롤 패널, 보안 컨트롤 패널, 미디어 박스(예: 삼성 HomeSyncTM, 애플 TVTM, 또는 구글 TVTM), 게임 콘솔(예: XboxTM, PlayStationTM), 또는 캠코더 중 적어도 하나일 수 있다. 또는, 방송 수신 기능뿐만 아니라 유무선 통신 장치 등 이 추가되어, 수기 방식의 입력 장치, 터치 스크린 또는 모션(motion) 인식 리모콘 등 보다 사용에 편리한 인터 페이스 등을 지원하는 Connected TV일 수 있다. 본 발명의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의 의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 이하, 도 6을 참조하여, 본 발명의 일 실시예들에 따른 낙상 판별 방법을 상세하게 설명한다. 도 6은 본 발명의 일 실시예에 따른 낙상 사고 판별 방법을 설명하기 위한 플로우차트이다. 도 1 내지 도 6을 참조하면, 본 발명의 일 실시예에 따른 낙상 사고 판별 방법은 카메라 단말로부터 영상 데이터를 수신하는 단계(S100), 수신된 영상 데이터에서 객체를 검출하고, 객체의 이상 상태를 검출하는 단계 (S200), 객체의 낙상을 검출하는 단계(S300) 및 낙상 사고를 판정하는 단계(S400)를 포함한다. 영상 데이터를 수신하는 단계(S100)에서는, 적어도 하나 이상의 카메라 단말로부터 위치별 영상 데이터를 수신한다. 위치별 영상 데이터는 공간 내 설치된 카메라 단말의 식별변호와 등록된 맵 정보를 기초하여, 맵 상의 위치별 영상 데이터를 수신할 수 있다. 상기 영상 데이터들은 객체 식별 및 검출을 위해 검출부로 전송된다. 영상 데이터가 수신되면, 수신된 영상 데이터 중 적어도 하나의 프레임으로부터 객체 및 객체의 특성을 검출하 도록 구성된다. 예를 들어, 영상 데이터의 연속된 복수의 프레임 또는 이들로부터 랜덤으로 추출된 일정 개수 이상의 프레임에 대해, 동영상 기반의 딥 네트워크를 적용하여 객체를 검출할 수 있다. 이 경우, 인접하는 프레 임들으로부터 검출되는 객체의 움직임을 추적할 수 있으며, 또한 프레임별로 복수의 객체가 포함된 경우에도, 각 객체 별로 움직임을 추적할 수도 있다. 객체의 특성은, 객체의 상태, 및 낙상 발생 여부 등을 포함한다. 한 편, 카메라 단말로부터 수신된 영상 데이터를 지속적으로 모니터링하면서 객체 및 객체의 특성을 검출하도 록 구성될 수 있으며, 또는 이와 달리, 영상 데이터 내에 객체가 존재하는 경우, 별도의 제어부 신호에 기초하 여, 모니터링을 개시하도록 구성될 수도 있다. 영상 데이터에서 객체를 검출하고, 객체의 이상 상태를 검출하는 단계(S200)에서는, 딥 네트워크를 이용하여 상 기 카메라 단말로부터 입력된 영상 데이터에 대해 자동으로 객체를 검출하도록 구성되며, 검출된 객체의 위치 정보, 크기 정보, 그리고 검출의 신뢰도 값 등을 출력하도록 구성될 수 있다. 아울러, 상기 카메라 단말 로부터 촬영되는 객체의 크기를 사전에 모르기 때문에 영상 데이터에서 미리 설정된 스케일들 각각에서 객 체 영역을 검색하면서 객체 존재 유무를 확인하여, 객체를 검출하도록 구성된다. 한편, 상기 객체 검출부 는 객체가 검출되면, 객체가 검출된 영역을 경계로 하는 박스 형태로 표시할 수 있다. 해당 단계에서는 검출된 객체의 상태를 검출하도록 구성된다. 딥 러닝에 기반한 낙상 사고 전후의 객체의 자세, 동작 등의 상태 정보를 학습한 분석 모델에 기초하여 객체의 상태가 이상 상태인지 여부를 분석하도록 구성된다. 예를 들어, 상기 분석 모델에 기초하여, 객체의 신체에 대한 각 관절에 대응되는 좌표를 추출하고, 객체의 신체의 움직임 및 좌표의 위치를 추적하도록 구성된다. 구체적으로, 검출한 객체의 상태를 통해, 정상 상태와 이상 상태를 검출하도록 구성된다. 상기 정상 상태는 향 후 일정 시간 내에 낙상이 발생하지 않을 확률이 높은 상태이며, 이상 상태는 정상 상태가 아닌 상태로 향후 일 정 시간 내에 낙상이 발생할 가능성이 높은 상태를 의미한다. 즉, 본 실시예에서는 낙상 사고가 발생한 객체의 전후 상태를 학습한 분석 모델에 의해 낙상의 전조 증상 등의 이상 상태 여부를 판단할 수 있다. 즉, 상기 분석 모델은 불특정 다수의 객체별 자세, 동작 등의 특성과 낙상이 발생된 일정 시간 이전의 상태의 객체별 자세, 동 작 등의 특성을 학습하여, 정상 상태에서의 공통된 특성 정보와 이상 상태에서의 공통된 특성 정보를 추출하거 나, 또는 비교 등을 통하여 학습하도록 구성된다. 이 때, 학습 방법은 지도학습(Supervised Learning) 또는 비 지도 학습(Unsupervised Learning)일 수 있고, 비지도 학습의 경우, 자기 지도 학습(Self-Supervised Learning) 방법에 의할 수 있다. 예를 들어, 상기 분석 모델의 학습에 있어서, 객체의 상체의 중심 좌표값이 침상의 모서리 영역과 일정 거리 내 로 인접한 경우, 다수의 낙상이 발생된 공통적인 특성이 추출되는 경우, 객체의 신체에 대한 각 관절에 대응되 는 좌표 값을 기준으로 해당 조건이 충족될 경우, 낙상이 발생될 확률이 높다고 판단하여, 객체의 현 상태를 이 상 상태로 판정할 수 있다. 구체적으로, 이상 상태를 검출함에 있어서, 복수의 프레임들 각각에 대한 특성을 추출하여 특성 맵(feature map)들을 생성하고, 이들을 연산하여, 상기 각각의 프레임 영상들에서 객체의 상태에 있어서의 신체의 20개의 관절에 대해 각각의 좌표를 추론하도록 구성된다. 신체의 관절의 갯수는 한정되지 않는다. 또한, 상기 이상 상 태 검출부는 객체의 이상 상태를 검출함에 있어서, 객체의 주위 사물에 대해 미리 지정된 관절 정보를 추 가로 학습시킨 분석 모델에 기초할 수도 있다. 이 경우, 상기 분석 모델에 의해 침상의 네 각을 관절이 추출되 고, 객체의 신체 관절 정보와 침상의 네 각의 관절 정보의 조합을 통해, 객체의 이상 상태 여부를 판단할 수도 있다. 한편, 상기 특성 맵의 생성 및 연산은 컨볼루션 신경망(convolution neural network; CNN) 및/ 또는 순환 신경 망(recurrent neural network RNN)을 기반으로 구현되는 레이어, 정정 선형 유닛(rectified linear unit; RELU) 레이어, 풀링(pooling) 레이어, 바이어스 가산(bias add) 레이어, 소프트맥스(softmax) 레이어 등과 같 은 다양한 연산 레이어들을 포함하는 연산 모델에 의해 구현될 수 있다. 여기서, 인공 신경망(artificial neural network; ANN)이란 연결 선으로 연결된 많은 수의 인공 뉴런들을 사용 하여 생물학적인 시스템의 계산 능력을 모방하는 소프트웨어나 하드웨어로 구현된 연산 모델을 나타낸다. 상기 인공 신경망에서는 생물학적인 뉴런의 기능을 단순화시킨 인공 뉴런을 사용하게 된다. 그리고 연결 강도를 갖는 연결 선을 통해 상호 연결시켜 인간의 인지 작용이나 학습 과정을 수행하게 된다. 즉, 이용되는 상기 연산 모델 은 상기 인공 신경망을 이용하여 미리 학습된 상태의 연산 모델일 수 있다. 객체의 낙상을 검출하는 단계(S300)에서는, 동영상 기반의 딥 네트워크를 적용하여 인접하는 복수의 프레임들 내에 검출된 객체의 신체 상의 관절들 중, 분석의 대상이 되는 관절을 추출하고, 추출된 해당 관절의 좌표 이동 값 등을 이용하여 객체의 낙상을 동작을 분석하도록 구성될 수 있다. 예를 들어, 낙상이 완료된 상태에서의 관 절에 대한 미리 저장된 정보들, 예를 들어, 영상 데이터 내 검출된 객체의 시점(view point)에 따라, 낙상이 이 루어진 상태에서 팔과 다리의 관절의 위치 정보가 동일 레벨 상에 존재하는 등의 위치 정보를 참조하여, 낙상이 발생되었는지 여부를 판단할 수 있다. 또한, 해당 단계에서는 인접한 프레임들 내의 객체의 관절의 절대 위치 및 다른 관절과의 상대 위치 등을 분석 하고, 전후 프레임에서의 해당 관절의 이동 방향, 이동 속도, 이동한 궤적 등을 분석하여, 관련된 관절의 이동 정보를 추출하도록 구성될 수 있다. 예를 들어, 영상 데이터 내의 객체의 신체에 대한 각 관절에 대응되는 좌표를 추출하고, 객체의 신체의 움직임 및 좌표의 위치를 추적하도록 구성되며, 낙상 사고가 발생한 객체의 상태의 변화 데이터를 학습한 분석 모델에 의해 낙상의 발생 여부를 판단할 수 있다. 즉, 상기 분석 모델은 낙상 사고가 발생된 불특정 다수의 객체별 자 세, 동작 등의 변화 정보를 학습하여, 낙상의 공통된 특성 정보를 추출하도록 구성된다. 이 때, 학습 방법은 마 찬가지로, 지도학습 또는 비지도 학습일 수 있으며, 비지도 학습의 경우, 자기 지도 학습 방법에 의할 수 있다."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "즉, 상기 분석 모델을 기초로, 객체의 분석의 대상이 되는 추출된 관절의 좌표 이동 값을 기준으로 낙상이 발생 여부를 판정할 수 있다. 예를 들어, 상기 낙상 검출부는 상기 이상 상태 검출부와 마찬가지로, 복수 의 프레임들 각각에 대한 특성을 추출하여 특성 맵(feature map)들을 생성하고, 이들을 연산하여, 상기 각각의 프레임 영상들에서 객체의 동작에 있어서의 신체의 20개의 관절에 대해 각각의 좌표의 변화를 추적하도록 구성 된다. 한편, 낙상을 검출하는 단계는 객체의 낙상 동작을 분석하는 것을 예로 설명하였으나, 이에 한정되지 않는다. 예를 들어, 도 4에 도시된 바와 같이, 상기 낙상 검출부는 학습 데이터에 따라 객체의 상태나 동작을 분석 하여, 낙상 뿐만 아니라. 휴식(Resting), 침상에서 벗어남(Out-of-bed) 등의 객체의 세부 동작을 분석할 수 있 으며, 낙상에 있어서도, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen)으로 세분화하여 분석할 수 도 있다. 즉, 해당 단계에서는 동작 분석에 따른 Action Classifier로서 기능할 수 있다. 이 때, 낙상의 검출에 있어서도, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen)가 모두 검출되는 것을 전제로 낙상을 검 출할 수 있다. 다만, 이에 한정되지 않는다. 입력되는 영상 데이터로부터 실시간으로 객체 검출이 이루어는 경우, 객체가 이동 중에 카메라 단말의 상에 잡히기 시작하거나 또는 벗어나는 경우와 같이, 당해 영상 데이터 중 일부 프레임에는 당해 객체의 동작 일부분만이 포함될 수 있고, 이 경우 낙상이 이루어짐에 따라 객체가 이후 프레임 내에 포함 되지 않을 수도 있다. 이 경우, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen) 중 일부만 검출되 어도 낙상을 검출할 수 있다. 한편, 분석 모델의 학습은 경사하강법을 적용하여 선정된 횟수만큼 반복 될 수 있다. 학습은 인공신경망 기법, 의사결정 나무기법과 오토 머신러닝 기법 등의 학습구조가 선정될 수 있다. 상기 분석 모델은 상기 중앙 서버 에서 생성하거나, 별도의 학습 서버(미도시)에서 생성될 수 있다. 이 경우, 통신을 통해 상기 중앙 서버 와 연결되도록 구성될 수 있으며, 상기 학습 서버는 중앙 서버에서 데이터를 가져올 수 있도록 원격 호출 기반으로 연결될 수 있다. 또한, 인공지능의 학습 방법으로는 의사결정 나무기법, 오토 머신러닝 기법이 적용될 수 있음은 자명하다. 구체 적으로, 상기 의사결정나무 기법에는 의사결정 나무(Decision Tree), 랜덤 포레스트(Random Forest), 그레디언트 부스팅(Gradient Boosting) 등의 기법이 포함될 수 있다. 또한, 상기 오토 머신러닝 기법에는 인공신경망의 은닉층의 개수와 뉴런의 개수 등에 대한 하이퍼 파라미터를 인공지능이 자동으로 조정하는 기법, 의사결정나무 기법 및 인공신경망을 포함한 현존하는 인공지능 기법을 다층으로 연결하여 학습하는 스테킹(Stacking) 및 앙상 블(Ensemble) 기법, 또는 상기의 스테킹(Staking), 앙상블(Ensemble), 하이퍼 파라미터에 대한 자동 튜닝을 동 시에 사용하는 기법이 포함될 수 있다. 특히, 이상 상태의 검출과 낙상의 검출에 기초하는 분석 모델은 서로 다른 종류의 인공지능 모델일 수 있다. 이 경우, 서로 다른 인공지능 모델인 제1 분석 모델 및 제2 분석 모델에 각각 영상 데이터를 입력할 수 있다. 또한, 동일한 영상 데이터라도 어떤 인공지능 모델을 이용하는지에 따라 검출 결과가 다를 수 있으므로, 검출하 고자 하는 이상 상태와 낙상을 서로 다른 인공지능 모델을 사용하기 때문에, 보다 정확한 검출 결과를 획득할 수 있고, 검출에 소요되는 시간을 최소화할 수 있다. 상기 낙상 사고를 판정하는 단계(S400)에서는, 이상 상태의 검출 및 낙상 검출에 기초하여, 낙상 검출에 오류가 있는지 여부를 판단하여, 낙상 사고가 발생되었는지 여부를 판정하도록 구성된다. 낙상 사고 발생시 알림 신호 를 출력하는 것을 전제로, 낙상 검출 오류에 따른 불필요한 알림 신호 출력을 방지하는 것을 목적으로 한다. 예를 들어, 해당 단계에서는 객체의 낙상이 검출되는 경우, 계층적으로 상위에 있는 객체의 상태가 이상 상태인 경우(S400; YES), 낙상 사고로 판정하고(S500), 객체의 낙상에 대한 응급 담당자를 호출하며(S600), 낙상 사고 가 발생한 것으로 판정된 영상 데이터가 수신된 카메라 단말의 위치 정보를 맵(map) 정보에 기반하여 상기 응급 담당자에게 제공하도록 구성된다. 이와 달리, 이상 상태가 아닌 정상 상태에서 낙상이 검출된 경우(S400; NO)는, 낙상 검출에 오류가 있다고 판정 (S700)하도록 구성된다. 즉, 상기 낙상 사고 판정부는 낙상이 검출된 시점 이전의 일정 시간 내에 이상 상 태가 검출되지 않은 경우, 또는 낙상이 검출된 시점에서의 객체의 상태가 이상 상태가 아닌 경우에는 상기 낙상 검출부에서 낙상이 검출되어도 오류로 판정하도록 구성된다. 즉, 낙상 사고를 판정하는 단계는 딥러닝에 기반하여 낙상이 전조되는 이상 상태가 학습된 분석 모델에 기초하 여, 객체의 상태의 맥락에 따라 낙상을 예측하고, 그에 따라 실제 낙상이 검출된 경우, 낙상이 발생되었다고 판 정함으로써, 낙상 검출의 오류를 최소화할 수 있다. 한편, 낙상 사고를 판정하는 단계는 정상 상태에서 낙상이 검출되어 오류라고 판정한 경우에도, 객체가 낙상 상 태를 일정 시간 유지하는 경우, 낙상 사고로 판정할 수 있다. 이 경우, 해당 데이터는 후술하는 학습부에 서 이상 상태 검출을 위한 분석 모델의 업데이트를 위한 학습 데이터로 활용하도록 구성된다. 즉, 상기 학습부 에서는 낙상 사고가 발생한 전조 증상의 특성을 파악하여, 객체의 이상 상태를 업데이트 학습하도록 구성 한다. 이에 따라, 낙상 사고가 발생할 수 있는 이상 상태를 학습함으로써 낙상이 발생할 전조 증상 또는 상태로 부터 낙상 발생을 예측할 수 있어, 낙상 사고 판별에 있어, 오류를 최소화할 수 있다. 또한, 낙상 사고를 판정하는 단계는, 낙상이 이루어지고 있는 상태(Falling)와 낙상 상태(Fallen)으로 세분화하 여 분석하는 경우, 해당 상태가 순차적으로 검출되는 경우에 한해, 낙상을 최종 판정할 수 있다. 예를 들어, 영 상 데이터에 객체가 검출되는 것을 전제로, 낙상 상태만 검출되고, 이전 단계에서 낙상이 이루어지고 있는 상태 는 검출되지 않은 경우, 오류로 판정하도록 구성될 수 있다. 또는, 상기 낙상 사고를 판정하는 단계는, 상기 낙상이 이루어지고 있는 상태(Falling)가 검출된 경우라도, 1초 에 처리되는 프레임의 수를 고려하여, 인접하는 2개 내외의 프레임에만 낙상이 이루어지고 있는 상태가 검출되 는 경우는, 낙차가 크지 않은 경우라고 판단하여, 낙상 사고로 최종 판정하지 않을 수 있다. 다만, 이 경우라도, 객체의 식별이 추가되어, 객체가 중증 환자 또는 고령의 환자로 식별되는 경우, 객체의 성격에 따라 낙상 사고로 판정할 수도 있다. 또한, 상기 낙상 검출부에 의해 낙상이 검출된 경우라도, 낙상 상태 (Fallen)가 인접하는 다수의 프레임에서 유지되는 경우, 낙상 사고가 발생한 것으로 판정할 수 있다. 예를 들어, 10 프레임이 유지되면, 낙상 사고로 최종 판정할 수 있다. 즉, 해당 단계는 검출된 데이터를 기초로 낙상 사고를 판정함에 있어서, 후처리로서, 검출의 오류를 판정하는 기능을 수행한다. 이에 따라, 낙상 검출의 오류를 최소화할 수 있다. 이에 따라, 종래의 규칙 기반(Rule-based) 방식으로 영상 데이터 상에서 객체의 낙상을 검출하는 경우, 빈번하 게 발생되는 검출 오류에 의해 불필요한 자원이 낭비되는 문제가 있었으나, 본 발명의 일 실시예에 따른 낙상 판별 방법은 객체의 낙상 검출에 있어 오류를 판정하도록 구성됨으로써, 검출의 오류를 최소화할 수 있다. 또한, 당해 검출의 오류를 포함하는 영상 데이터는 별도의 학습 DB에 저장되며, 객체 검출의 분석 모델의 업데이트를 위한 데이터로 활용될 수 있다. 예를 들어, 당해 학습 DB에 저장된 영상 데이터는 후술하는 학습부 또는 별도로 구비된 학습 서버로 전송되도록 구성될 수 있다. 일 실시예에 따른 낙상 판별 방법은, 컴퓨터에 의해 실행되는 애플리케이션이나 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모 두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴 퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다."}
{"patent_id": "10-2023-0060854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2023-0060854", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 낙상 판별 시스템을 설명하기 위한 개념도를 나타낸 것이다. 도 2는 도 1의 중앙 서버를 설명하기 위한 블록도이다. 도 3은 도 2의 검출부를 설명하기 위한 블록도이다. 도 4는 도 2의 검출부에 의한 계층적 검출을 위한 설명하기 위한 예시도이다. 도 5는 도 2의 학습부를 설명하기 위한 블록도이다. 도 6은 본 발명의 일 실시예에 따른 낙상 사고 판별 방법을 설명하기 위한 플로우차트이다."}
