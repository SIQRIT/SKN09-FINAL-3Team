{"patent_id": "10-2024-0142375", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0037397", "출원번호": "10-2024-0142375", "발명의 명칭": "사각지대의 물체 정보 검출 장치 및 방법", "출원인": "한국생산기술연구원", "발명자": "윤종필"}}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "라이다 데이터 수신모듈;상기 라이다 데이터 수신모듈을 통해 수신된 라이다 데이터를 렌더링하여, 비사각지대 및 사각지대에 포함된 물체를 검출하기 위한 2차원 뎁스 맵 이미지를 생성하는 장면 재구성모듈; 및상기 장면 재구성모듈에서 생성한 2차원 뎁스 맵 이미지에서 비사각지대 및 사각지대 내 물체를 검출하고, 물체와의 거리 정보를 산출하는 물체 검출모듈;을 포함하는 것을 특징으로 하는 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 비사각지대 및 사각지대 내 물체가 검출되면, 자율주행 차량, 증강 현실 장치, 또는 로봇을 포함하는 지정된 애플리케이션 장치에 물체 회피를 위한 정보가포함된 회피기능 신호를 전달하는 회피기동 신호 출력모듈;을 더 포함하는 것을 특징으로 하는 사각지대의 물체정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 라이다 데이터 수신모듈은,제1 반사지점 및/또는 제2 반사지점을 통해 반사되는 1회 반사광 및 2회 반사광을 수신하는 것을 특징으로 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 사각지대는,상기 장면 재구성모듈을 통해, 1회 반사광 및 2회 반사광을 이용하여 물체를 검출할 수 있는 영역인 사각사이트(Blind sight)인 것을 특징으로 하는 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 장면 재구성모듈은,사각지대 내 물체까지 렌더링하기 위하여 2회 반사광 렌더링을 수행하며, 상기 2회 반사광 렌더링은, 상기 라이다 데이터에서 산출한 1회 반사광의 렌더링 및 2회 반사광의 렌더링을 수행하는 것을 특징으로 하는사각지대의 물체 정보 검출 장치.공개특허 10-2025-0037397-3-청구항 6 제 5항에 있어서,상기 1회 반사광의 렌더링은, 라이다 데이터가 제1 반사지점을 통해 1회 반사되어 곧바로 라이다 데이터 수신모듈에 수신되는 1회 반사광을렌더링하는 것이며,상기 2회 반사광의 렌더링은,라이다 데이터가 제1 반사지점에서 1회 반사된 후, 다시 제2 반사지점에서 2회 반사되어 라이다 데이터 수신모듈에 수신되는 2회 반사광을 렌더링하는 것을 의미하는 것을 특징으로 하는 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5항에 있어서,상기 장면 재구성모듈은,상기 2회 반사광에서 1차 광선과 2차 광선을 산출하고, 상기 1차 광선 및 상기 2차 광선의 렌더링을 각각 수행하는 것을 특징으로 하는 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 1차 광선은,제1 반사지점과 제2 반사지점 간의 거리에 해당하는 광선이며, 사각지대 내 물체로 인하여 발생하는 그림자의위치 정보를 포함하고,상기 2차 광선은,제2 반사지점과 라이다 데이터 수신모듈 간의 거리에 해당하는 광선인 것을 특징으로 하는 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7항에 있어서,상기 장면 재구성모듈은,상기 2회 반사광의 렌더링 시,사각지대 내 물체가 존재하는 경우, 1차 광선에 해당하는 부분에 그림자가 발생함에 따라 상기 그림자 부분에대한 2차 광선 및 1차 광선이 렌더링 되지 않는 것을 이용하여 사각지대 내 물체의 형상을 구축하며,상기 그림자는 포인트 클라우드 데이터가 검출되지 않는 지역인 것을 특징으로 하는 사각지대의 물체 정보 검출장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1항에 있어서,공개특허 10-2025-0037397-4-상기 장면 재구성모듈은,상기 라이다 데이터로부터 산출한 1회 반사광 렌더링 결과, 2회 반사광의 1차 광선과 2차 광선에 대한 렌더링결과, 및 상기 라이다 데이터로부터 생성한 뎁스 맵 이미지를 입력받아 3차원 사각지대가 포함된 3차원 장면으로 재구성하고,상기 3차원 사각지대가 포함된 3차원 장면에 포함된 3차원 뎁스 맵을, 카메라 매트릭스 변환을 통하여 뎁스 정보가 포함되어 있는 2차원 뎁스 맵 이미지로 변환하는 것을 특징으로 하는 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1항에 있어서,상기 장면 재구성모듈은,프로세서 또는 인공지능 모델로 구현되는 것을 특징으로 하는 사각지대의 물체 정보 검출 장치."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "라이다 데이터 수신모듈이 라이다 데이터를 수신하는 단계;장면 재구성모듈이 상기 라이다 데이터를 렌더링하여, 비사각지대 및 사각지대에 포함된 물체를 검출하기 위한2차원 뎁스 맵 이미지를 생성하는 단계; 및물체 검출모듈이 상기 2차원 뎁스 맵 이미지에서 비사각지대 및 사각지대 내 물체를 검출하고, 물체와의 거리정보를 산출하는 단계;를 포함하는 것을 특징으로 하는 사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 비사각지대 및 사각지대 내 물체를 검출하는 단계 이후,회피기동 신호 출력모듈이 자율주행 차량, 증강 현실 장치, 또는 로봇을 포함하는 지정된 애플리케이션 장치에물체 회피를 위한 정보가 포함된 회피기능 신호를 전달하는 단계;를 더 포함하는 것을 특징으로 하는 사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12항에 있어서,상기 라이다 데이터를 수신하는 단계에서,상기 라이다 데이터 수신모듈은,제1 반사지점 및/또는 제2 반사지점을 통해 반사되는 1회 반사광 및 2회 반사광을 수신하는 것을 특징으로 사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 12항에 있어서, 상기 사각지대는,상기 장면 재구성모듈을 통해, 1회 반사광 및 2회 반사광을 이용하여 물체를 검출할 수 있는 영역인 사각사이트공개특허 10-2025-0037397-5-(Blind sight)인 것을 특징으로 하는 사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 12항에 있어서,상기 라이다 데이터를 렌더링하는 단계에서,상기 장면 재구성모듈은,사각지대 내 물체까지 렌더링하기 위하여 2회 반사광 렌더링을 수행하며, 상기 2회 반사광 렌더링은, 상기 라이다 데이터에서 산출한 1회 반사광의 렌더링 및 2회 반사광의 렌더링을 수행하는 것을 특징으로 하는사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서,상기 1회 반사광의 렌더링은, 라이다 데이터가 제1 반사지점을 통해 1회 반사되어 곧바로 라이다 데이터 수신모듈에 수신되는 1회 반사광을렌더링하는 것이며,상기 2회 반사광의 렌더링은,라이다 데이터가 제1 반사지점에서 1회 반사된 후, 다시 제2 반사지점에서 2회 반사되어 라이다 데이터 수신모듈에 수신되는 2회 반사광을 렌더링하는 것을 의미하는 것을 특징으로 하는 사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 16항에 있어서,상기 라이다 데이터를 렌더링하는 단계에서,상기 장면 재구성모듈은,상기 2회 반사광에서 1차 광선과 2차 광선을 산출하고, 상기 1차 광선 및 상기 2차 광선의 렌더링을 각각 수행하는 것을 특징으로 하는 사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18항에 있어서, 상기 1차 광선은,제1 반사지점과 제2 반사지점 간의 거리에 해당하는 광선이며, 사각지대 내 물체로 인하여 발생하는 그림자의위치 정보를 포함하고,상기 2차 광선은,제2 반사지점과 라이다 데이터 수신모듈 간의 거리에 해당하는 광선인 것을 특징으로 하는 사각지대의 물체 정보 검출 방법.공개특허 10-2025-0037397-6-청구항 20 제 18항에 있어서,상기 2회 반사광의 렌더링 시, 사각지대 내 물체가 존재하는 경우, 상기 장면 재구성모듈은,1차 광선에 해당하는 부분에 그림자가 발생함에 따라 상기 그림자 부분에 대한 2차 광선 및 1차 광선이 렌더링되지 않는 것을 이용하여 사각지대 내 물체의 형상을 구축하며,상기 그림자는 포인트 클라우드 데이터가 검출되지 않는 지역인 것을 특징으로 하는 사각지대의 물체 정보 검출방법."}
{"patent_id": "10-2024-0142375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 12항에 있어서,2차원 뎁스 맵 이미지를 생성하는 단계에서,상기 장면 재구성모듈은,상기 라이다 데이터로부터 산출한 1회 반사광 렌더링 결과, 2회 반사광의 1차 광선과 2차 광선에 대한 렌더링결과, 및 상기 라이다 데이터로부터 생성한 뎁스 맵 이미지를 입력받아 3차원 사각지대가 포함된 3차원 장면으로 재구성하고,상기 3차원 사각지대가 포함된 3차원 장면에 포함된 3차원 뎁스 맵을, 카메라 매트릭스 변환을 통하여 뎁스 정보가 포함되어 있는 2차원 뎁스 맵 이미지로 변환하는 것을 특징으로 하는 사각지대의 물체 정보 검출 방법."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사각지대의 물체 정보 검출 장치에 관한 것으로, 라이다 데이터 수신모듈; 상기 라이다 데이터 수신모 듈을 통해 수신된 라이다 데이터를 이용하여, 비사각지대 및 사각지대에 포함된 물체를 렌더링하여 2차원 뎁스 맵 이미지를 생성하는 장면 재구성모듈; 및 상기 장면 재구성모듈에서 생성한 2차원 뎁스 맵 이미지에서 비사각 지대 및 사각지대 내 물체를 검출하고, 물체와의 거리 정보를 산출하는 물체 검출모듈;을 포함하는 것을 특징으 로 한다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사각지대에 존재하는 물체 및 물체와의 거리 정보를 검출할 수 있도록 하는, 사각지대의 물체 정보 검출 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "라이다(LIDAR)는 레이저 펄스(laser pulse)를 발사하고, 그 빛이 주위의 대상 물체에서 반사되어 돌아오는 것을 받아 물체까지의 거리 등을 측정함으로써 주변의 모습을 정밀하게 그려내는 장치이다. 라이다는 전통적 레이다 (RADAR)와 원리 측면에서는 동일하지만 사용하는 전자기파 파장이 다르기 때문에 실제 적용 분야와 이용 기술에 서 차이가 있다. 라이다 센서는 레이저 펄스를 물체나 표면에 조사하고 반사된 빛이 수신기(detector)로 돌아오는 시간을 비행시 간(ToF :Time of Flight), 주파수 변조 등의 기법을 통해 산출하여 거리(depth)를 측정하며, 자율주행 모빌리티, 공간 매핑, 건축 등의 분야들에서 고해상도 지도를 만들거나 장애물 감지 및 회피를 위한 환경 탐색 등에 사용된다. 라이다 센서는 대체로 레이저, 스캐너, 수신기, 위치 확인 시스템으로 이루어진다. 레이저는 용도에 따라 다른 파장을 갖는데, 대체로 600-1000nm 파장의 빛을 사용한다. 그러나 사람의 눈에 입히는 피해를 줄이기 위해 보다 긴 파장대의 빛을 사용하기도 한다. 스캐너는 주위를 재빠르게 훑어서 정보를 얻도록 하는 부분이다. 이를 위해 여러 가지 형태의 거울들이 응용되고 있다. 수신기는 돌아오는 빛을 감지하는 부분으로, 수신기가 가지는 빛에 대한 민감도는 라이다 센서의 성능을 좌우하 는 주요한 요인이다. 근본적으로 수신기는 광자를 감지하여 이를 증폭하는 역할을 한다. 위치 확인 시스템은 3차원 영상을 구현하기 위해서 수신기가 놓여 있는 위치 좌표와 방향을 확인하는 부분이다. 라이다 센서는 대상 물체까지의 거리뿐만 아니라 움직이는 속도와 방향, 온도, 주변의 대기 물질 분석 및 농도 측정 등에 쓰인다. 따라서 자외선, 가시광선, 근적외선 등을 사용하여 금속성인 아닌 바위나 구름, 빗방울, 에 어로졸 등을 감지할 수 있어서 기상 관측에 이용된다. 또한 지형을 정밀하게 그려내거나, 비행체의 착륙 유도나 자율 주행차량의 주변 인식 장치로 사용되기도 하며, 분자마다 잘 산란시키는 빛의 파장이 다른 현상을 이용하여 공기 중에 섞여 있는 기체의 화학적 조성을 알아내 는데 쓰이기도 한다. 최근 들어 라이다 센서는 3차원 영상을 구현하기 위해 필요한 정보를 습득하는 센서의 핵심 기술로 등장하였다. 라이다 센서를 항공기에 장착하고 비행하면서 레이저 펄스를 지표면에 발사해서 돌아오는 시간을 측정함으로써 반사 지점의 공간 위치를 분석하여 지형을 측량하면, 구조물에 따라 반사되어 돌아오는 시간이 다르므로 이로부 터 광학영상으로는 얻기 어려운 3차원 모델을 얻을 수 있다. 지상 라이다 센서는 여기에 GPS로 얻은 위치 좌표 를 결합하여 정밀한 데이터를 얻기도 한다. 이와 같은, 라이다 센서는 스마트시티를 위해서도 활발히 연구되고 있다. 종래에는 교통안전과 원만한 도로 주 행 환경을 확립하기 위해 기존의 도로 중 일부에는 CCTV 기반의 객체 인식 프로그램을 탑재한 감지 모델이 운영 되었다. 하지만 단순 객체의 존재 여부를 판단하는 수준에 머물러 있어 실질적으로 그 효용성은 크지 않았다. 게다가, 어린이 보호구역 혹은 사고 다발구역에서 일어나는 대부분의 교통사고가 갑작스레 출몰하는 어린이 혹 은 노약자임과 동시에 우천, 야간 등 운전자 부주의를 야기할 수 있는 열악한 상황임을 고려할 때 기존 CCTV 방 식의 객체 감지 시스템은 단점이 많았다. 따라서 라이다 센서의 3차원 교차공간에서 거리 및 위치 정보를 이용 하여 보행자 및 차량을 감지하고, 감지된 정보를 바탕으로 경고 또는 알림을 수행하여 교차로에서 안전을 확보 하며, 사고를 방지하는 등 스마트시티를 위한 다양한 기술이 필요한 실정이다. 사각지대 물체 검출(Blind Sight Detection) 기술은, 차량의 사각지대 혹은 골목길, 교차로 등에서 발생하는 사 각지대에 존재하는 다른 차량이나 장애물을, 비전 센서, 초음파센서, 혹은 통신 기반 기술을 통해 감지하여 사 고를 예방하는 기술이다. 사각지대 물체 검출에는 다양한 방식들이 존재한다. 가령, Radar 기반, 비전 카메라 기반, LiDAR 기반, 초음파센서 기반, UWB(Ultra Wide Band) 통신 기반, 및 복합 센서 기반 등의 다양한 방식으 로 사각지대의 물체를 검출한다. 3차원 장면 재구성(3D Scene Reconstruction) 기술은, 수십 장의 2차원 RGB 이미지 혹은 LiDAR 센서의 포인트 클라우드 데이터를 입력받고 딥러닝을 사용하여 색상 혹은 거리 정보를 예측하고 재구성하여 3차원 장면으로 렌 더링하는 과정을 의미하며, 주로 연속적이고 사실적인 고해상도 3차원 장면을 재구성하고 시각화하는데 사용된 다. 3차원 장면 재구성에는 다양한 방법들이 존재한다. 가령, Structure from Motion(SfM), Multi-View Stereo(MVS), Photogrammetry, Neural Radiance Fields(NeRF), Plenoptic volume element(Plenoxel), 및 3D Gaussian Splatting(3D-GS) 등의 다양한 방식으로 3차원 장면을 재구성할 수 있다. 그런에 기존의 3차원 장면 재구성 기술은 절대 깊이가 아닌 상대 깊이를 통해 3차원 장면 렌더링을 진행하기에 장면 내 물체 재구성에 있어 렌더링 정확도가 떨어지는 단점, 즉 상대 깊이를 사용하기에 부분적으로 형태가 원 본과 다르게 재구성되는 단점이 있다. 또한 기존의 라이다 센서는 여러 번 반사되는 빛을 검출하는 성능에 한계 점이 존재하는 단점, 즉 기존의 포토 다이오드(Photo Diode) 센서 기반 수신기(Detector)는 여러 번 반사되는 빛을 정확하게 검출하기 어려운 단점이 있다. 또한 UWB(Ultra Wide Band) 통신을 사용하는 사각지대 물체 검출 기술은 통신이 불안정해지거나, UWB 통신 단말기가 장착되지 않은 경우에는 물체 검출이 불가능한 단점이 있다. 또한 비전 센서를 사용하는 사각지대 물체 검출 기술의 경우 기존 기술들로는 사각지대 물체 검출에 한계가 있 으며, RGB 비전 카메라와 라이다가 융합된 복합 센서를 사용하는 경우 단가가 높아지는 문제점이 있다. 따라서 이러한 기존의 문제점들을 개선하면서 사각지대에 존재하는 물체의 종류 및 거리에 대한 정보를 검출할 수 있도록 하는 방법이 필요한 상황이다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "본 발명의 배경기술은 대한민국 등록특허 제10-2665635호(2024.05.08.)에 개시되어 있다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "발명의 내용"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위한 것으로서, 사각지대에 존재하는 물체 및 물체와의 거리 정보를 검출할 수 있도록 하는, 사각지대의 물체 정보 검출 장치 및 방법을 제공하는 데 그 목적이 있다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따른 사각지대의 물체 정보 검출 장치는, 라이다 데이터 수신모듈; 상기 라이다 데이터 수 신모듈을 통해 수신된 라이다 데이터를 렌더링하여, 비사각지대 및 사각지대에 포함된 물체를 검출하기 위한 2 차원 뎁스 맵 이미지를 생성하는 장면 재구성모듈; 및 상기 장면 재구성모듈에서 생성한 2차원 뎁스 맵 이미지 에서 비사각지대 및 사각지대 내 물체를 검출하고, 물체와의 거리 정보를 산출하는 물체 검출모듈;을 포함하는 것을 특징으로 한다. 본 발명에 있어서, 상기 비사각지대 및 사각지대 내 물체가 검출되면, 자율주행 차량, 증강 현실 장치, 또는 로 봇을 포함하는 지정된 애플리케이션 장치에 물체 회피를 위한 정보가 포함된 회피기능 신호를 전달하는 회피기 동 신호 출력모듈;을 더 포함하는 것을 특징으로 한다. 본 발명에 있어서, 상기 라이다 데이터 수신모듈은, 제1 반사지점 및/또는 제2 반사지점을 통해 반사되는 1회 반사광 및 2회 반사광을 수신하는 것을 특징으로 한다. 본 발명에 있어서, 상기 사각지대는, 상기 장면 재구성모듈을 통해, 1회 반사광 및 2회 반사광을 이용하여 물체 를 검출할 수 있는 영역인 사각사이트(Blind sight)인 것을 특징으로 한다. 본 발명에 있어서, 상기 장면 재구성모듈은, 사각지대 내 물체까지 렌더링하기 위하여 2회 반사광 렌더링을 수 행하며, 상기 2회 반사광 렌더링은, 상기 라이다 데이터에서 산출한 1회 반사광의 렌더링 및 2회 반사광의 렌더 링을 수행하는 것을 특징으로 한다. 본 발명에 있어서, 상기 1회 반사광의 렌더링은, 라이다 데이터가 제1 반사지점을 통해 1회 반사되어 곧바로 라 이다 데이터 수신모듈에 수신되는 1회 반사광을 렌더링하는 것이며, 상기 2회 반사광의 렌더링은, 라이다 데이 터가 제1 반사지점에서 1회 반사된 후, 다시 제2 반사지점에서 2회 반사되어 라이다 데이터 수신모듈에 수신되 는 2회 반사광을 렌더링하는 것을 의미하는 것을 특징으로 한다. 본 발명에 있어서, 상기 장면 재구성모듈은, 상기 2회 반사광에서 1차 광선과 2차 광선을 산출하고, 상기 1차 광선 및 상기 2차 광선의 렌더링을 각각 수행하는 것을 특징으로 한다. 본 발명에 있어서, 상기 1차 광선은, 제1 반사지점과 제2 반사지점 간의 거리에 해당하는 광선이며, 사각지대 내 물체로 인하여 발생하는 그림자의 위치 정보를 포함하고, 상기 2차 광선은, 제2 반사지점과 라이다 데이터 수신모듈 간의 거리에 해당하는 광선인 것을 특징으로 한다. 본 발명에 있어서, 상기 장면 재구성모듈은, 상기 2회 반사광의 렌더링 시, 사각지대 내 물체가 존재하는 경우, 1차 광선에 해당하는 부분에 그림자가 발생함에 따라 상기 그림자 부분에 대한 2차 광선 및 1차 광선이 렌더링 되지 않는 것을 이용하여 사각지대 내 물체의 형상을 구축하며, 상기 그림자는 포인트 클라우드 데이터가 검출 되지 않는 지역인 것을 특징으로 한다. 본 발명에 있어서, 상기 장면 재구성모듈은, 상기 라이다 데이터로부터 산출한 1회 반사광 렌더링 결과, 2회 반 사광의 1차 광선과 2차 광선에 대한 렌더링 결과, 및 상기 라이다 데이터로부터 생성한 뎁스 맵 이미지를 입력 받아 3차원 사각지대가 포함된 3차원 장면으로 재구성하고, 상기 3차원 사각지대가 포함된 3차원 장면에 포함된 3차원 뎁스 맵을, 카메라 매트릭스 변환을 통하여 뎁스 정보가 포함되어 있는 2차원 뎁스 맵 이미지로 변환하는 것을 특징으로 한다. 본 발명에 있어서, 상기 장면 재구성모듈은, 프로세서 또는 인공지능 모델로 구현되는 것을 특징으로 한다. 본 발명의 다른 측면에 따른 사각지대의 물체 정보 검출 방법은, 라이다 데이터 수신모듈이 라이다 데이터를 수 신하는 단계; 장면 재구성모듈이 상기 라이다 데이터를 렌더링하여, 비사각지대 및 사각지대에 포함된 물체를 검출하기 위한 2차원 뎁스 맵 이미지를 생성하는 단계; 및 물체 검출모듈이 상기 2차원 뎁스 맵 이미지에서 비사각지대 및 사각지대 내 물체를 검출하고, 물체와의 거리 정보를 산출하는 단계;를 포함하는 것을 특징으로 한 다. 본 발명에 있어서, 상기 비사각지대 및 사각지대 내 물체를 검출하는 단계 이후, 회피기동 신호 출력모듈이 자 율주행 차량, 증강 현실 장치, 또는 로봇을 포함하는 지정된 애플리케이션 장치에 물체 회피를 위한 정보가 포 함된 회피기능 신호를 전달하는 단계;를 더 포함하는 것을 특징으로 한다. 본 발명에 있어서, 상기 라이다 데이터를 수신하는 단계에서, 상기 라이다 데이터 수신모듈은, 제1 반사지점 및 /또는 제2 반사지점을 통해 반사되는 1회 반사광 및 2회 반사광을 수신하는 것을 특징으로 한다. 본 발명에 있어서, 상기 사각지대는, 상기 장면 재구성모듈을 통해, 1회 반사광 및 2회 반사광을 이용하여 물체 를 검출할 수 있는 영역인 사각사이트(Blind sight)인 것을 특징으로 한다. 본 발명에 있어서, 상기 라이다 데이터를 렌더링하는 단계에서, 상기 장면 재구성모듈은, 사각지대 내 물체까지 렌더링하기 위하여 2회 반사광 렌더링을 수행하며, 상기 2회 반사광 렌더링은, 상기 라이다 데이터에서 산출한 1회 반사광의 렌더링 및 2회 반사광의 렌더링을 수행하는 것을 특징으로 한다. 본 발명에 있어서, 상기 1회 반사광의 렌더링은, 라이다 데이터가 제1 반사지점을 통해 1회 반사되어 곧바로 라 이다 데이터 수신모듈에 수신되는 1회 반사광을 렌더링하는 것이며, 상기 2회 반사광의 렌더링은, 라이다 데이 터가 제1 반사지점에서 1회 반사된 후, 다시 제2 반사지점에서 2회 반사되어 라이다 데이터 수신모듈에 수신되 는 2회 반사광을 렌더링하는 것을 의미하는 것을 특징으로 한다. 본 발명에 있어서, 상기 라이다 데이터를 렌더링하는 단계에서, 상기 장면 재구성모듈은, 상기 2회 반사광에서 1차 광선과 2차 광선을 산출하고, 상기 1차 광선 및 상기 2차 광선의 렌더링을 각각 수행하는 것을 특징으로 한 다. 본 발명에 있어서, 상기 1차 광선은, 제1 반사지점과 제2 반사지점 간의 거리에 해당하는 광선이며, 사각지대 내 물체로 인하여 발생하는 그림자의 위치 정보를 포함하고, 상기 2차 광선은, 제2 반사지점과 라이다 데이터 수신모듈 간의 거리에 해당하는 광선인 것을 특징으로 한다. 본 발명에 있어서, 상기 2회 반사광의 렌더링 시, 사각지대 내 물체가 존재하는 경우, 상기 장면 재구성모듈은, 1차 광선에 해당하는 부분에 그림자가 발생함에 따라 상기 그림자 부분에 대한 2차 광선 및 1차 광선이 렌더링 되지 않는 것을 이용하여 사각지대 내 물체의 형상을 구축하며, 상기 그림자는 포인트 클라우드 데이터가 검출 되지 않는 지역인 것을 특징으로 한다. 본 발명에 있어서, 2차원 뎁스 맵 이미지를 생성하는 단계에서, 상기 장면 재구성모듈은, 상기 라이다 데이터로 부터 산출한 1회 반사광 렌더링 결과, 2회 반사광의 1차 광선과 2차 광선에 대한 렌더링 결과, 및 상기 라이다 데이터로부터 생성한 뎁스 맵 이미지를 입력받아 3차원 사각지대가 포함된 3차원 장면으로 재구성하고, 상기 3 차원 사각지대가 포함된 3차원 장면에 포함된 3차원 뎁스 맵을, 카메라 매트릭스 변환을 통하여 뎁스 정보가 포 함되어 있는 2차원 뎁스 맵 이미지로 변환하는 것을 특징으로 한다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 비사각지대 및 사각지대에 존재하는 물체의 종류 및 거리에 대한 정보를 검출할 수 있도록 한다. 본 발명은 비사각지대 및 사각지대 내 물체를 검출하고, 물체와의 거리 정보를 검출하여 지정된 애플리케이션 장치에 회피기능 신호를 출력할 수 있도록 한다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명에 따른 사각지대의 물체 정보 검출 장치 및 방법의 일 실시예를 설명한 다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시되어 있 을 수 있다. 또한, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자 의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대한 정의는 본 명세서 전반에 걸친 내용 을 토대로 내려져야 할 것이다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고, 도면에서 본 발명을 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면부호를 붙 였다. 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\" 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서는 아니 되 며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서, 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 발명의 가장 바람직한 일부 실시예에 불과할 뿐 이고 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다 양한 균등물과 변형예들이 있을 수 있음을 이해하여야 한다. 또한, 본 명세서에서 사용되는 경우 \"포함한다 (comprise, include)\" 및/또는 \"포함하는(comprising, including)\"은 언급한 형상들, 숫자, 단계, 동작, 부재, 요소 및/또는 이들 그룹의 존재를 특정하는 것이며, 하나 이상의 다른 형상, 숫자, 동작, 부재, 요소 및 /또는 그룹들의 존재 또는 부가를 배제하는 것이 아니다. 또한, 본 발명의 실시 예들을 기술할 때 “~할 수 있다”,” ~일 수 있다”는 “본 발명의 하나 이상의 실시 예”를 포함할 수 있다. 또한, 발명의 이해를 돕기 위하여, 첨부된 도면을 실제 축척대로 도시된 것이 아니라 일부 구성요소의 치수가 과장되게 도시될 수 있다. 또한, 서로 다른 실시예에서 동일한 구성요소에 대해서는 동일한 참조번호가 부여될 수 있다. 2개의 비교 대상이 ‘동일’하다는 언급은 ‘실질적으로 동일’한 것을 의미한다. 따라서 실질적 동일은 당업계 에서 낮은 수준으로 간주되는 편차, 예를 들어 5% 이내의 편차를 가지는 경우를 포함할 수 있다. 또한, 소정 영 역에서 어떠한 파라미터가 균일하다는 것은 평균적 관점에서 균일하다는 것을 의미할 수 있다. 비록 제1, 제2 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한 되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것으 로, 특별히 반대되는 기재가 없는 한, 제1 구성요소는 제2 구성요소일 수도 있음은 물론이다. 명세서 전체에서, 특별히 반대되는 기재가 없는 한, 각 구성요소는 단수일 수도 복수일 수도 있다. 구성요소의 “상부(또는 하부)” 또는 구성요소의 “상(또는 하)”에 임의의 구성이 배치된다는 것은, 임의의 구성이 상기 구성요소의 상면(또는 하면)에 접하여 배치되는 것 뿐만 아니라, 상기 구성요소와 상기 구성요소 상에(또는 하에) 배치된 임의의 구성 사이에 다른 구성이 개재될 수 있음을 의미할 수 있다. 또한 어떤 구성요소가 다른 구성요소에 “연결”, “결합” 또는 “접속”된다고 기재된 경우, 상기 구성요소들 은 서로 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성요소 사이에 다른 구성요소가 “개재”되거나, 각 구성요소가 다른 구성요소를 통해 “연결”, “결합” 또는 “접속”될 수도 있는 것으로 이해되어야 할 것이다. 또한, 어떤 부분이 다른 부분과 전기적으로 연결(electrically coupled)되어 있다고 할 때, 이는 직접적 으로 연결되어 있는 경우뿐만 아니라 그 중간에 다른 소자를 사이에 두고 연결되어 있는 경우도 포함한다. 도 1은 본 발명에 따른 실시예에서 사각지대와 사각사이트의 의미를 설명하기 위한 예시도이다. 도 1에 도시된 바와 같이, 본 실시예에서는 사각지대(Blind Space)와 사각사이트(Blind sight)를 구분한다. 사각지대(Blind Space)는 라이다(LiDAR) 혹은 카메라(Camera)를 1개의 지점에 설치하여 데이터를 획득하였을 때, 포인트 클라우드 데이터(Point cloud data)가 검출되지 않거나 육안으로 확인되지 않는 영역을 의미한다. 반면 사각사이트(Blind sight)는 사각지대(Blind Space) 내에서, 본 실시예에 따른 사각지대의 물체 정보 검출 장치를 이용하여, 물체(객체)를 검출할 수 있는 영역을 의미한다. 따라서 이하 본 실시예에서 사각지대라 함은 사각사이트(Blind sight)를 의미하는 것임에 유의한다. 도 2는 본 발명의 일 실시예에 따른 사각지대의 물체 정보 검출 장치의 개략적인 구성을 보인 예시도이고, 도 3 은 도 2에 있어서, 장면 재구성모듈의 보다 세부적인 구성을 보인 예시도이다. 도 2를 참조하면, 본 실시예에 따른 사각지대의 물체 정보 검출 장치는, 라이다 데이터 수신모듈, 장면 재 구성모듈, 물체 검출모듈, 및 회피기동 신호 출력모듈을 포함한다. 도 3을 참조하면, 장면 재구성모듈은 1회 반사광 산출모듈, 1회 반사광 렌더링모듈, 2회 반사광 산출모듈, 1차 광선 렌더링모듈, 2차 광선 렌더링모듈, 뎁스 맵 이미지 생성모듈, 3차원 장면 재구성모듈, 및 2차원 뎁스 맵 생성모듈을 포함한다. 라이다 데이터 수신모듈(예 : SPAD, Single Photon Avalanche Diode)은 라이다 데이터 송신모듈(도 4의 100 참조)을 통해 송신된 라이다 데이터(또는 라이다 신호)가 제1 반사지점 및(또는) 제2 반사지점을 통해 반사 되는 라이다 데이터(또는 라이다 신호)를 수신한다. 장면 재구성모듈은 인공지능모델을 이용하여 비사각지대 및 사각지대의 물체를 렌더링하여 장면을 재구성 한다. 장면 재구성모듈은 사각지대 물체까지 렌더링하기 위하여 2회 반사광 렌더링 기법(2-time reflection light)을 적용한다. 2회 반사광 렌더링 기법은 1회 반사광의 렌더링, 및 2회 반사광의 렌더링을 수행한다. 1회 반사광 산출모듈은 라이다 데이터에서 1회 반사광을 산출하고, 1회 반사광 렌더링모듈은 산출된 1회 반사광의 렌더링을 수행한다. 2회 반사광 산출모듈은 라이다 데이터에서 2회 반사광을 산출하고, 1차 광선 렌더링모듈 및 2차 광선 렌더링모듈은 산출된 1차 광선 및 2차 광선의 렌더링을 수행한다. 이 때 1회 반사광 산출모듈과 1회 반사광 렌더링모듈은 하나로 통합되어 구현될 수 있으며, 2회 반사 광 산출모듈과 1차 광선 렌더링모듈 및 2차 광선 렌더링모듈도 하나로 통합되어 구현될 수 있다. 이하 1회 반사광의 렌더링 및 2회 반사광의 렌더링 방법에 대해서 설명한다. 도 4는 도 2에 있어서, 1회 반사광의 렌더링 및 2회 반사광의 렌더링을 설명하기 위한 예시도이다. 도 4를 참조하면, 1회 반사광의 렌더링은, 라이다 데이터 송신모듈에서 출력된 라이다 데이터(또는 라이다 신호)가 제1 반사지점을 통해 1회 반사되어 곧바로 라이다 데이터 수신모듈에 수신되는 1회 반사광을 렌더 링하는 것을 의미한다. 2회 반사광의 렌더링은, 라이다 데이터 송신모듈에서 출력된 라이다 데이터(또는 라이다 신호)가 제1 반사 지점에서 1회 반사된 후, 다시 제2 반사지점에서 2회 반사되어 라이다 데이터 수신모듈(예 : SPAD)에 수신 되는 2회 반사광을 렌더링하는 것을 의미한다. 여기서 2회 반사광은, 1차 광선과 2차 광선으로 구분할 수 있으며, 1차 광선은 제1 반사지점과 제2 반사지점 간 의 거리에 해당하며, 2차 광선은 제2 반사지점과 라이다 데이터 수신모듈 간의 거리에 해당한다. 이 때 2회 반사광의 1차 광선은, 사각지대 내 물체로 인하여 발생하는 그림자의 위치 정보를 포함하고 있다. 1회 반사광은 라이다 데이터 수신모듈(예 : SPAD)을 통해 획득한 포인트 클라우드 데이터들을 사용하여 포 인트 클라우드 데이터 상에서 검출할 수 있으며, 배경 및 비사각지대에 존재하는 물체의 형상 구축에 사용되고, 2회 반사광은 사각지대(정확하게는 사각사이트(Blind sight))에 존재하여 포인트 클라우드 데이터 상에서는 검 출이 불가능한 사각사이트(Blind sight) 내에 존재하는 물체의 형상 구축에 사용된다. 렌더링 시 사각사이트(Blind sight) 내 물체가 존재하는 경우, 도 4의 (b)와 같이 1차 광선에 해당하는 부분에 그림자(즉, 포인트 클라우드 데이터가 검출되지 않는 지역)가 발생하며, 해당 그림자 부분에 대한 2차 광선 및 1차 광선이 렌더링 되지 않으며, 이와 같이 그림자 부분에서 2차 광선 및 1차 광선이 렌더링 되지 않은 것을 이 용하여 사각사이트(Blind sight) 내 물체의 형상을 구축한다. 이와 같은 2회 반사광 렌더링을 위하여, 1차 광선과 2차 광선을 각각 렌더링한다. 먼저 2회 반사광에서의 2차 광선은 다음 수학식 1을 통하여 렌더링된다. 수학식 1"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 1에서 는 센서의 위치를 의미하며, 는 카메라 행렬에 의해 결정된 방향을 의미한다. 그리고 2차 광선을 따라 샘플링된 포인트 들에서의 볼륨 밀도 출력(기본적인 NeRF 모델에서의 볼륨메트릭 렌더 링과 동일한 역할을 수행한다)은 수학식 2를 통해 계산된다. 수학식 2"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 2에서 이고 이다. 그리고 이며 두 샘플 사이의 거리를 의미한다. 2회 반사광 중 1차 광선은 다음 수학식 3을 통하여 렌더링된다. 수학식 3"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3에서 는 센서의 위치를 의미하고, 는 카메라 행렬에 의해 결정된 방향을 의미한다. 그리고 1차 광선을 렌더링할 때는 1차 광선이 그림자가 진 영역에 존재하는지 결정하기 위한 확률을 계산할 필 요가 있다. 해당 확률(즉, 1차 광선이 그림자가 진 영역에 존재하는지 결정하기 위한 확률)은 아래 수학식 4를 통하여 계산 된다.수학식 4"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "2회 반사광은 2차 광선을 렌더링하여 최종적인 ToF(Time of Flight)를 예측한다. 해당 ToF는 다음 수학식 5를 통하여 계산된다. 수학식 5"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 5에서 은 레이저( )과 가상 소스( ) 간의 거리를 의미하고, 는 상 소스( )와 가상 검출기( ) 간의 거리를 의미한다. 그리고 는 가상 검출기( )와 센서( ) 간의 거리를 의미하고 는 빛의 속도 ( )를 의미한다. 2회 반사광 학습에는 다음과 같은 3가지 손실(loss) 함수가 사용된다. 먼저 실제 측정 시간과 예측 시간 사이의 오차인 디스턴스 손실(Distance loss)이 있다. 이 디스펀스 손실 (Distance loss)은 아래의 수학식 6과 같다. 수학식 6"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 는 실제 측정된 시간을 의미하며 는 예측된 시간을 의미한다. 다음 그림자 유무를 판단하는 섀도우 손실(Shadow loss)이 있으며, 이는 아래의 수학식 7과 같다. 수학식 7"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "는 이진법으로 이루어진 그림자 유무에 대한 실제 측정값을 의미하고, 는 그림자 유무에 대한 예측값 을 의미한다. 마지막으로 디스턴스 손실(Distance loss)과 섀도우 손실(Shadow loss)의 가중치를 합하여 ToF 오차 및 그림자 유무 오차를 계산하고, 장면 구축에 있어 사각지대 내 물체에 대한 가중치를 산출하는 컴바인 손실(Combined loss)이 있다. 이 컨바인 손실(Combined loss)은 다음 수학식 8과 같다. 수학식 8 한편, 라이다 데이터 수신모듈(예 : SPAD)을 통해 수집된 포인트 클라우드 데이터에 있어서, 1회 반사광의 경우에는 일반적인 라이다(LiDAR) 센서와 동일한 방식으로 ToF가 계산되며 또한 렌더링이 이루어진다. 하지만 2회 반사광의 경우에는 상술한 바와 같이 1차 광선과 2차 광선으로 나누어져 렌더링된다. 1회 반사광과 2회 반사광의 경우, 라이다 데이터 수신모듈(예 : SPAD)에 검출된 신호의 강도 차이를 통하 여 구분된다. 예컨대 2회 반사광의 경우, 반사 횟수가 더 많기 때문에 라이다 데이터 수신모듈(예 : SPAD)에서 검출된 신호의 강도가 상대적으로 낮게 측정된다. 2회 반사광은 광선 추적(ray tracing) 과정을 통해 물리적으로 각 반사 지점 계산을 통해 추정될 수 있다. 이 때 각각의 반사방을 광선 방향과 거리를 기반으로 구분하며, 1회 반사광을 먼저 렌더링한 다음, 이 때 산출된 정보들을 기반으로 2회 반사광이 발생한 반사 지점들을 계산한다. 보다 구체적으로, 1회 반사광 렌더링을 통해 산출된 뎁스(depth) 값들을 이용해 제2 반사지점까지의 광선(ray) 의 방향을 계산하고, 그 광선의 방향 계산 결과를 사용하여 2회 반사광의 위치와 거리가 추적된다. 코드 상으로는 2회 반사광의 2차 광선에 대한 렌더링을 진행하여 1회 반사광 및 2차 광선에 대한 인텐시티 (intensity), 뎁스(depth) 및 트랜스미턴스(transmittance) 등에 대한 정보들을 획득한다. 여기서 얻어진 뎁스(depth)를 사용하여, 카메라(혹은 LiDAR)로부터 첫 번째 반사 지점까지의 거리를 계산한다. 그리고 2회 반사광에서의 두 번째 반사는 첫 번째 반사 이후 광선을 다시 추적하는 부분에서 이루어진다. 두 번 째 반사는 1차 광선 렌더링을 통해 계산되며, 해당 렌더링 함수에서 제1 반사지점으로부터 제2 반사지점까지의 거리를 계산한다. 이러한 1회 반사광 및 2회 반사광 렌더링을 위해서는 먼저 NeRF 모델을 통한 Depth 예측이 이루어져야 한다. 뎁스(Depth) 예측은, 가령 5m*5m*5m(W, D, H)인 정육면체 형태의 방에 토끼 모양의 물체가 있고, 라이다 데이터 수신모듈(예 : SPAD)의 설치 위치는 (2.5m, 0m, 1m)인 지점에 설치되어 있는 공간이 있다고 가정할 경우, 2회 반사광의 예측 ToF는 아래의 수학식 9를 통하여 계산된다. 수학식 9"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "수학식 9에서 은 레이저( )과 가상 소스( ) 간의 거리를 의미하고, 는 가상 소스( )와 가상 검출기 ( )간의 거리를 의미한다. 그리고 는 가상 검출기( )와 SPAD 센서( ) 간의 거리를 의미하고 는 빛의 속 도( )를 의미한다. 레이저( ), 가상 소스( ), 가상 검출기( ), SPAD 센서( )의 위치는 도 4 에 도시된 바와 같다. 또한 레이저( )와 SPAD 센서( )의 위치는 동일하다. 위에서 가정한 공간에 대하여 계산을 해볼 경우, 은 첫 번째 반사가 이루어지는 가상 소스( )와 레이저( ) 사이의 거리이고, 는 정육면체 공간의 크기를 5m*5m*5m로 가정하였으므로 5m로 고정이 된다. 만약 (0m, 2m, 1m), (0m, 2.5m, 1m), (0m, 3m, 1m) 총 3가지 포인트들이 있다고 가정하였을 때 각각의 포 인트들에 대하여 , , , 를 계산하면 아래의 수식과 같이 계산될 수 있다. 참고로 , , 계산에는 유클리드 거리 공식이 사용될 수 있다. 의 경우,"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "의 경우,"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "의 경우,"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "위와 같은 수식을 통해 각 포인트들에 대한 ToF의 계산이 이루어진다. 이하 렌더링 수학식에 대해서 설명한다. 2회 반사광에서의 1차 광선과 2차 광선은 각각 아래 수학식을 가진다. 수학식 10"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "수학식 11"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "여기서 는 카메라(혹은 LiDAR 센서)의 설치 위치(3차원 공간좌표)를 의미하고, 는 카메라(혹은 LiDAR 센서) 의 방향을 의미한다. 는 데이터를 통해 주어지며 는 알고리즘 내부에서 계산이 이루어진다. 는 아래와 같이 기본적인 NeRF(Neural Radiance Fields, 신경 방사망) 모델과 동일한 방식을 통해 계산된다. 먼저 카메라(혹은 LiDAR 센서)에 대한 내부 파라미터 행렬 와 외부 파라미터 행렬 [R|t]로 구성된다. 내부 파라미터 행렬 는 카메라 자체의 특성인 초점 거리, 센서 크기 등의 데이터들을 포함하고 있으며, 이 행 렬을 사용해 이미지 평면의 픽셀 좌표를 정규화된 3차원 공간의 방향으로 변환할 수 있다. 즉, 카메라 좌표계를 이미지 좌표계로 변환한다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "위 행렬에서 는 카메라 초점 거리(픽셀 단위)를 의미하며, 는 이미지 센서의 중심 좌표(이미지 평 면의 중심 위치)를 의미한다. 카메라 좌표계(3차원 좌표)( )를 이미지 좌표계로의 변환은 아래의 행렬식과 같은 과정을 통해 변환 된다."}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "여기에서 는 이미지 평면에서의 픽셀 좌표를 의미하고 는 Depth(카메라와의 거리)를 의미한다. 외부 파라미터 행렬[R|t]는 실제 세계 좌표계의 3차원 포인트를 카메라 좌표계로 변환하는데 사용된다. 여기서 R은 회전 행렬(Rotation matrix)로, 실제 세계 좌표계와 카메라 좌표계 간의 회전을 표현한다. t는 변환 벡터로, 카메라의 위치(실제 세계 좌표계에서의 위치)를 표현한다. 상술한 과정을 통하여 카메라(혹은 LiDAR 센서)의 방향을 표현하는 벡터 에 대한 계산이 이루어지게 된다. 한편, 2차 광선에 따라 샘플링된 포인트 들에서의 볼륨 밀도 출력은 아래 수학식 12를 통해 계산된다. 수학식 12"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "수학식 12에서 는 광선이 경로 에서 종료되는 depth 값을 의미하고 는 이전 point에서 현재 point 까지 광선이 도달할 확률(투과율)을 의미한다. 이는 광선이 중간에 소실되거나 막히지 않고 종료 지점에 도달할 확률을 의미하며 을 통하 여 계산된다. 여기서 는 광선이 현재 샘플링 포인트에서 종료될 확률을 의미하며 를 통하여 계산된다. 여 기에서 는 해당 포인트에서의 모델이 예측한 밀도로, 해당 포인트에서의 물체에 대한 밀집 정도를 의미한다. 그리고 는 샘플링 포인트에서의 시간을 의미하며, (즉, 해당 포인트에서의 뎁스(depth) 간격) 수 식을 통하여 계산한다. 한편, 1차 광선이 그림자에 있을 확률을 결정하는 것은 아래의 수학식 13과 같다. 수학식 13"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "수학식 13에서 는 특정 포인트 에서 광선이 종료(혹은 도달)할 확률을 의미하며, 해당 포인트의 밀도에 따라 결정된다. 밀도가 높을수록 광선이 그 포인트에서 멈추거나 흡수될 확률이 높다. 는 위에서 설명한 볼륨 밀도 출력에서 사용되는 수식을 통하여 계산된다. 는 해당 포인트 에서 광선이 계속 통과하고 진행할 확률을 의미한다. 즉, 포인트 에서 빛이 차단되지 않음을 의미한다. 는 여러 포인트( )을 통과하면서 발생하는 광선의 ‘전달도’를 계산하는 수식이다. 이는 1차 광선이 그림자 영역에 속하지 않을 확률을 계산하는 것이다. 따라서 이 전달도를 계산하는 수식은 1차 광선이 에서 로 가는 경로 상에서 얼마나 많은 포인트들이 빛을 차단하지 않고 통과할 수 있는지를 나타낸다. 전달도 값이 높을수록 해당 경로가 그림자 영역에 포함될 확률이 높아지고, 전달도 값이 낮을수록 그 림자 영역에 포함될 확률이 낮아진다. 상술한 바와 같이 라이다 데이터로부터 1회 반사광을 산출하여 렌더링이 수행되고, 2회 반사광을 산출하여 1차 광선과 2차 광선에 대한 렌더링이 수행되면, 각 렌더링 결과를 모두 합성하여 3차원 장면 재구성모듈에 출 력된다. 도 5는 도 3에 있어서, 라이다 데이터를 이용하여 재구성한 3차원 장면(즉, 3차원 장면 재구성 결과)을 보인 예 시도이다. 3차원 장면 재구성모듈은 1회 반사광 렌더링 결과, 2회 반사광의 1차 광선과 2차 광선에 대한 렌더링 결과, 및 뎁스 맵 이미지 생성모듈에서 생성된 뎁스 맵 이미지를 입력받아 3차원 장면으로 재구성한 결과 (즉, 3차원 사각지대가 포함된 장면)를 출력한다. 뎁스 맵 이미지 생성모듈은 라이다 데이터(예 : 주변 환경의 포인트 클라우드 데이터)를 2차원 뷰(view)로 변환하기 위해 좌표 변환과 깊이 정보 추출 과정을 수행한다. 이 때 뎁스 맵 이미지 생성모듈은 미리 지정 된 알고리즘을 통해 각 포인트의 깊이 값을 측정하고, 해당 값을 표준화하여 뎁스 맵에 적합한 형태로 변환한다. 또한, 필요 시 노이즈 필터링이나 데이터 보정 프로세스를 통해 정밀도를 향상시킬 수 있다. 뎁스 맵 이미지 생성모듈은 이와 같이 처리된 깊이(depth) 값을 이미지 형태로 매핑하여 2차원 뎁스 맵 이 미지를 생성한다. 이 때 뎁스 맵 이미지는 픽셀 단위로 깊이 정보를 표현하며, 이를 통해 사용자 또는 장치가 환경의 거리 정보를 직관적으로 파악할 수 있도록 한다. 2차원 뎁스 맵 생성모듈은 3차원 장면 재구성모듈에서 출력된 3차원 장면 재구성한 결과(즉, 3차원 사각지대가 포함된 장면)에 포함된 3차원 뎁스 맵(Depth map)을, 카메라 매트릭스(camera matrix) 변환을 통하 여 뎁스(Depth) 정보가 포함되어 있는 2차원 뎁스 맵(Depth map) 이미지로 변환한다. 참고로 카메라 매트릭스 변환은 3차원 장면 데이터를 카메라 매트릭스를 이용하여 2차원 평면으로 투영하는 작 업을 의미하며, 여기서 카메라 매트릭스는 내부 및 외부 파라미터를 포함하여 3차원 포인트를 2차원 좌표로 변 환하는 역할을 한다. 2차원 뎁스 맵 생성모듈은 카메라 매트릭스 변환을 통해 얻어진 2차원 좌표와 깊이 값을 바탕으로 2차원 뎁스 맵을 생성한다. 즉, 변환된 2차원 좌표 위치에 깊이 정보를 대응시켜 각 포인트에 깊이 값을할당함으로써, 깊이 정보를 포함하는 2차원 이미지 형태의 뎁스 맵을 생성한다. 이 때 변환된 2차원 뎁스 맵(Depth map) 이미지를 통하여 사각지대 내 물체 및 물체와의 거리 정보를 산출할 수 있다. 이 때 물체의 종류를 검출할 수도 있다. 이와 같이 2차원 뎁스 맵 생성 모듈은 3차원 장면 재구성 결과(즉, 3차원 사각지대가 포함된 장면)에서 추 출한 깊이 정보를 바탕으로 2차원 이미지로 변환하여 직관적이고 실용적인 뎁스 맵 이미지를 생성할 수 있다. 참고로 본 실시예에서 장면 재구성을 위하여 이용할 수 있는 인공지능 모델은, 예컨대 NeRF(Neural Radiance Fields, 신경 방사망) 모델, MLP(Multi Layer Perceptron, 다층 퍼셉트론) 모델, 및 트랜스퍼(Transformer) 모 델 등을 응용할 수 있으나, 이를 한정하는 것은 아니며, 필요에 따라 공개된 다른 인공지능 모델을 이용할 수도 있다. 물체 검출모듈은 장면 재구성모듈에서 출력된 2차원 뎁스 맵에서 비사각지대 및 사각지대 내 물체(정 확히는 사각사이트(Blind Sight) 내의 물체)를 검출하고, 뎁스(Depth) 정보를 분석하여 물체와의 거리 정보를 산출한다. 물체 검출모듈은 감지(Detection) 인공지능 모델을 사용할 수 있다. 이와 같이 비사각지대 및 사각지대 내 물체가 검출되면, 회피기동 신호 출력모듈은 자율주행 차량(또는 무 인 차량), 증강 현실 장치, 및 로봇 제어 등의 다양한 애플리케이션 장치에 회피기능 신호(즉, 검출된 물체를 회피하기 위한 정보)를 전달하거나, 검출된 정보를 단순히 전달함으로써 자율주행 차량(또는 무인 차량), 및 로 봇이 직접 회피기동을 수행할 수 있도록 한다. 이 때 도면에는 구체적으로 도시되어 있지 않지만, 장면 재구성모듈, 물체 검출모듈, 및 회피기동 신 호 출력모듈는, 프로세서를 이용하여 각각 구현되거나 통합하여 구현될 수 있으며, 기능별 인공지능 모델 을 각각 적용하거나 통합 적용하여 구현될 수 있다. 도 6은 본 발명의 일 실시예에 따른 사각지대의 물체 정보 검출 방법을 설명하기 위한 흐름도이고, 도 7은 도 6 에 있어서, 장면 재구성 과정을 보다 구체적으로 설명하기 위하여 보인 흐름도이다. 도 6을 참조하면, 프로세서(또는 인공지능 모델)(미도시)는 라이다 데이터 수신모듈(예 : SPAD)을 통해 라 이다 데이터를 수신한다(S100). 프로세서는 라이다 데이터 내의 포인트 클라우드 데이터를 기반으로 1회 반사광 및 2회 반사광을 산출한다. 프로세서는 라이다 데이터, 및 1회 반사광과 2회 반사광을 이용하여 비사각지대 및 사각지대의 물체를 렌더링하 여 장면(2차원 뎁스 맵 형태)을 재구성한다(S200). 프로세서는 라이다 데이터, 및 1회 반사광과 2회 반사광을 이용하여 재구성한 장면(2차원 뎁스 맵 형태)에서 비 사각지대 및 사각지대 내 물체(정확히는 사각사이트(Blind Sight) 내의 물체)를 검출하고, 뎁스(Depth) 정보를 분석하여 물체와의 거리 정보를 산출한다(S300). 이 때 물체의 종류를 검출할 수도 있다. 프로세서는 비사각지대 및 사각지대 내 물체가 검출되면, 지정된 애플리케이션 장치(예 : 자율주행 차량, 무인 차량, 증강 현실 장치, 로봇 등)에 회피기능 신호(즉, 검출된 물체를 회피하기 위한 정보)를 출력한다(S400). 도 7을 참조하여, 장면(2차원 뎁스 맵 형태)을 재구성하는 과정(S200)에 대해서 보다 구체적으로 설명한다. 프로세서는 수신된 라이다 데이터에서 1회 및 2회 반사광을 산출하고(S201), 산출된 1회 반사광의 렌더링을 수 행하며(S202), 2회 반사광에서 1차 광선 및 2차 광선을 산출하여 렌더링을 수행하고(S203), 아울러 라이다 데이 터(예 : 주변 환경의 포인트 클라우드 데이터)에서 좌표 변환과 깊이 정보 추출하여 2차원 뎁스 맵 이미지를 생 성한다(S204). 이 때 1회 반사광의 렌더링은, 라이다 데이터 송신모듈에서 출력된 라이다 데이터(또는 라이다 신호)가 제 1 반사지점을 통해 1회 반사되어 곧바로 라이다 데이터 수신모듈에 수신되는 1회 반사광을 렌더링하는 것 을 의미한다. 2회 반사광의 렌더링은, 라이다 데이터 송신모듈에서 출력된 라이다 데이터(또는 라이다 신 호)가 제1 반사지점에서 1회 반사된 후, 다시 제2 반사지점에서 2회 반사되어 라이다 데이터 수신모듈(예 : SPAD)에 수신되는 2회 반사광을 렌더링하는 것을 의미한다. 여기서 2회 반사광은, 1차 광선과 2차 광선으로 구분할 수 있으며, 1차 광선은 제1 반사지점과 제2 반사지점 간 의 거리에 해당하며, 2차 광선은 제2 반사지점과 라이다 데이터 수신모듈 간의 거리에 해당한다. 이 때 2 회 반사광의 1차 광선은, 사각지대 내 물체로 인하여 발생하는 그림자(즉, 포인트 클라우드 데이터가 검출되지 않는 지역)의 위치 정보를 포함하고 있다. 1회 반사광은 라이다 데이터 수신모듈(예 : SPAD)을 통해 획득한 포인트 클라우드 데이터들을 사용하여 포 인트 클라우드 데이터 상에서 검출할 수 있으며, 배경 및 비사각지대에 존재하는 물체의 형상 구축에 사용되고, 2회 반사광은 사각지대(정확하게는 사각사이트(Blind sight))에 존재하여 포인트 클라우드 데이터 상에서는 검 출이 불가능한 사각사이트(Blind sight) 내에 존재하는 물체의 형상 구축에 사용된다. 즉, 렌더링 시 사각사이 트(Blind sight) 내 물체가 존재하는 경우, 도 4의 (b)와 같이 1차 광선에 해당하는 부분에 그림자(즉, 포인트 클라우드 데이터가 검출되지 않는 지역)가 발생하며, 해당 그림자 부분에 대한 2차 광선 및 1차 광선이 렌더링 되지 않으며, 이와 같이 그림자 부분에서 2차 광선 및 1차 광선이 렌더링 되지 않은 것을 이용하여 사각사이트 (Blind sight) 내 물체의 형상을 구축한다. 프로세서는 1회 반사광 렌더링 결과, 2회 반사광의 1차 광선과 2차 광선에 대한 렌더링 결과, 및 S204 단계에서 라이다 데이터를 이용하여 생성된 뎁스 맵 이미지를 입력받아 3차원 장면(즉, 3차원 사각지대가 포함된 장면)으 로 재구성한다(S205). 프로세서는 3차원 장면 재구성 결과(즉, 3차원 사각지대가 포함된 장면)에 포함된 3차원 뎁스 맵(Depth map)을, 카메라 매트릭스(camera matrix) 변환을 통하여 뎁스(Depth) 정보가 포함되어 있는 2차원 뎁스 맵(Depth map) 이미지로 변환한다(S206). 이와 같이 라이다 데이터, 및 1회 반사광과 2회 반사광을 이용하여 최종적으로 2차원 뎁스 맵 이미지가 생성되 면, 프로세서는 최종적으로 생성된 2차원 뎁스 맵 이미지에서 비사각지대 및 사각지대 내 물체(정확히는 사각사 이트(Blind Sight) 내의 물체)를 검출하고, 뎁스(Depth) 정보를 분석하여 물체와의 거리 정보를 산출하여, 지정 된 애플리케이션 장치(예 : 자율주행 차량, 무인 차량, 증강 현실 장치, 로봇 등)에 회피기능 신호(즉, 검출된 물체를 회피하기 위한 정보)를 출력할 수 있다. 본 명세서에서 설명된 구현은, 예컨대, 방법 또는 프로세스, 장치, 소프트웨어 프로그램, 데이터 스트림 또는 신호로 구현될 수 있다. 단일 형태의 구현의 맥락에서만 논의(예컨대, 방법으로서만 논의)되었더라도, 논의된 특징의 구현은 또한 다른 형태(예컨대, 장치 또는 프로그램)로도 구현될 수 있다. 장치는 적절한 하드웨어, 소 프트웨어 및 펌웨어 등으로 구현될 수 있다. 방법은, 예컨대, 컴퓨터, 마이크로프로세서, 집적 회로 또는 프로 그래밍가능한 로직 디바이스 등을 포함하는 프로세싱 디바이스를 일반적으로 지칭하는 프로세서 등과 같은 장치 에서 구현될 수 있다. 프로세서는 또한 최종-사용자 사이에 정보의 통신을 용이하게 하는 컴퓨터, 셀 폰, 휴대 용/개인용 정보 단말기(personal digital assistant: \"PDA\") 및 다른 디바이스 등과 같은 통신 디바이스를 포 함한다. 이상에서 본 발명은 비록 한정된 실시예와 도면에 의해 설명되었으나, 본 발명은 이것에 의해 한정되지 않으며"}
{"patent_id": "10-2024-0142375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 본 발명의 기술 사상과 아래에 기재될 특허청구 범위의 균등 범위 내에서 다양한 수정 및 변형이 가능함은 물론이다."}
{"patent_id": "10-2024-0142375", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 실시예에서 사각지대와 사각사이트의 의미를 설명하기 위한 예시도이다. 도 2는 본 발명의 일 실시예에 따른 사각지대의 물체 정보 검출 장치의 개략적인 구성을 보인 예시도이다. 도 3은 도 2에 있어서, 장면 재구성모듈의 보다 세부적인 구성을 보인 예시도이다. 도 4는 도 2에 있어서, 1회 반사광의 렌더링 및 2회 반사광의 렌더링을 설명하기 위한 예시도이다.도 5는 도 3에 있어서, 라이다 데이터를 이용하여 재구성한 3차원 장면(즉, 3차원 장면 재구성 결과)을 보인 예 시도이다. 도 6은 본 발명의 일 실시예에 따른 사각지대의 물체 정보 검출 방법을 설명하기 위한 흐름도이다. 도 7은 도 6에 있어서, 장면 재구성 과정을 보다 구체적으로 설명하기 위하여 보인 흐름도이다."}
