{"patent_id": "10-2021-0049800", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0124594", "출원번호": "10-2021-0049800", "발명의 명칭": "고해상도 이미지를 지원하는 가상 피팅 방법", "출원인": "(주)내스타일", "발명자": "구교정"}}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치를 이용하여 원본 이미지에 피팅의상을 합성하는 가상 피팅 방법으로서, 원본 이미지로부터 세그먼테이션을 생성하는 단계;상기 원본 이미지에 기초하여 상기 피팅의상(c)을 변형하여 변형된 피팅의상을 생성하는 단계; 상기 세그먼테이션의 기존의상 영역 중 상기 변형된 피팅의상의 영역이 중첩되지 않는 비정렬 영역(Mmisalign)을 생성하는 단계; 및 상기 원본 이미지와 피팅의상을 포함하는 입력데이터를 이미지 합성 알고리즘에 입력하여 합성 이미지를 생성하는 단계;를 포함하는 것을 특징으로 하는, 컴퓨터 장치를 이용한 가상 피팅 방법."}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "체 1 항에 있어서, 상기 비정렬 영역을 생성하는 단계에서, 상기 세그먼테이션의 의상 영역과 상기 변형된 피팅의상 영역이 중첩되는 정렬 영역(Malign)을 생성하고, 상기 세그먼테이션의 의상 영역에서 상기 정렬 영역을 제외하여 상기 비정렬영역을 생성하는 것을 특징으로 하는, 컴퓨터 장치를 이용한 가상 피팅 방법."}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "체 2 항에 있어서, 상기 세그먼테이션은, 상기 원본 이미지를 세그먼트한 제1 세그먼테이션(S) 또는 상기 제1 세그먼테이션에서 기존의상 대신 피팅의상을 클래스로 포함시킨 제2 세그먼테이션()인 것을 특징으로 하는, 컴퓨터 장치를 이용한가상 피팅 방법."}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "체 3 항에 있어서, 상기 컴퓨터 장치가,상기 제1 세그먼테이션에서 상기 기존의상 영역을 제거하여 의상제거 세그먼테이션(Sa)을 생성하고, 상기 의상제거 세그먼테이션(Sa)과 상기 피팅의상을 포함하는 데이터를 이용하여 상기 제2 세그먼테이션()을 생성하는것을 특징으로 하는, 컴퓨터 장치를 이용한 가상 피팅 방법."}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 합성 이미지를 생성하는 단계에서, 상기 원본 이미지 또는 이 원본 이미지에서 상기 기존의상을 제거한 의상제거 이미지, 및 상기 변형된 피팅의상을 포함하는 제1 데이터 세트, 및 상기 비정렬 영역을 포함하는 제2 데이터 세트를 상기 이미지 합성 알고리즘의 입력 데이터로 사용하는 것을 특징으로 하는, 컴퓨터 장치를 이용한가상 피팅 방법."}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "체 5 항에 있어서, 상기 원본 이미지에서 신체의 특징점을 포함하는 포즈 정보(P)를 추출하고, 상기 포즈 정보(P)에 기초하여 상기원본 이미지에서 기설정된 소정 영역을 제거하여 상기 의상제거 이미지를 생성하는 것을 특징으로 하는, 컴퓨터장치를 이용한 가상 피팅 방법.공개특허 10-2022-0124594-3-청구항 7 체 5 항에 있어서, 상기 원본 이미지에서 신체의 특징점을 포함하는 포즈 정보(P)를 추출하고, 상기 포즈 정보(P)에 기초하여 상기원본 이미지에서 기설정된 소정 영역을 제거하고 상기 세그먼테이션의 클래스들 중 합성 이미지에서 유지해야할 기설정된 클래스의 이미지를 중첩하여 상기 의상제거 이미지를 생성하는 것을 특징으로 하는, 컴퓨터 장치를이용한 가상 피팅 방법."}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "체 5 항에 있어서,상기 이미지 합성 알고리즘은 컨볼루션과 업샘플링 연산을 포함하는 복수의 잔차블록(ResBlk)이 다단으로 연결된 디코더로 구성되고, 상기 제1 데이터 세트와 제2 데이터 세트가 상기 복수의 잔차블록의 각 잔차블록에 각각입력 데이터로서 입력되는 것을 특징으로 하는, 컴퓨터 장치를 이용한 가상 피팅 방법."}
{"patent_id": "10-2021-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "체1항 내지 제8항 중 어느 한 항에 따른 가상 피팅 방법을 실행시키기 위한 컴퓨터 프로그램이 기록된 컴퓨터판독가능 기록매체."}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 컴퓨터 장치를 이용하여 원본 이미지에 피팅의상을 합성하는 가상 피팅 방법에 관한 것으로, 일 실시 예에서, 원본 이미지로부터 세그먼테이션을 생성하는 단계; 상기 원본 이미지에 기초하여 상기 피팅의상(c)을 변 형하여 변형된 피팅의상을 생성하는 단계; 상기 세그먼테이션의 기존의상 영역 중 상기 변형된 피팅의상의 영역 이 중첩되지 않는 비정렬 영역(Mmisalign)을 생성하는 단계; 및 상기 원본 이미지와 피팅의상을 포함하는 입력데 이터를 이미지 합성 알고리즘에 입력하여 합성 이미지를 생성하는 단계;를 포함하는, 컴퓨터 장치를 이용한 가상 피팅 방법을 개시한다."}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨터를 이용한 가상 피팅 방법에 관한 것으로, 보다 상세하게는, 원본 이미지에 피팅 의상을 합성 한 합성 이미지를 생성하기 위한 가상 피팅 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "의류를 실제로 착용하기 전에 가상으로 의류를 착용한 이미지를 생성하여 사용자에게 보여주는 가상 피팅 기술 이 현재 널리 이용되고 있다. 그러나 기존의 가상 피팅 기술은 저해상도 데이터셋 위주로 가상피팅 하는 방법을 제시하고 있어서 1024x768 이상의 고해상도에서는 작은 오차에 의한 가상피팅 결과가 두드러지게 잘못된 합성으 로 이어지는 결과를 보이고 있다. 또한 가상 피팅 기술은 이미지 상의 모델에 의상을 합성하여 보여주기 때문에 의상이 배경에 자연스럽게 들어맞 지 못하여 어색하여 실제 소비자가 착용한 모습에 비해 부자연스러운 경우가 많으며, 따라서 소비자가 의상을 입었을 때의 모습을 정확히 예상하기 어려운 경우가 많다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허문헌1: 한국 공개특허 제2020-0038777호 (2020년 4월 14일 공개) (특허문헌 0002) 특허문헌2: 한국 공개특허 제2020-0139766호 (2020년 12월 14일 공개)"}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 이러한 문제점을 해결하기 위한 것으로 고해상도에서도 강건한 이미지를 생성함으로써 의상이 자연스 럽게 합성된 모습을 보여줄 수 있고 소비자가 실제 의상을 작용했을 때의 모습을 비교적 정확히 예측할 수 있도 록 하는 가상 피팅 방법 및 장치를 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 컴퓨터 장치를 이용하여 원본 이미지에 피팅의상을 합성하는 가상 피팅 방법으 로서, 원본 이미지로부터 세그먼테이션을 생성하는 단계; 상기 원본 이미지에 기초하여 상기 피팅의상(c)을 변 형하여 변형된 피팅의상을 생성하는 단계; 상기 세그먼테이션의 기존의상 영역 중 상기 변형된 피팅의상의 영역 이 중첩되지 않는 비정렬 영역(Mmisalign)을 생성하는 단계; 및 상기 원본 이미지와 피팅의상을 포함하는 입력 데이터를 이미지 합성 알고리즘에 입력하여 합성 이미지를 생성하는 단계;를 포함하는, 컴퓨터 장치를 이용한 가상 피팅 방법을 개시한다. 본 발명의 일 실시예에 따르면, 상기 가상 피팅 방법을 실행시키기 위한 컴퓨터 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 개시한다."}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 고해상도에서도 강건한 이미지를 생성할 수 있고 의상이 자연스럽게 합성된 합성 이미지를 생성할 수 있어 소비자가 실제 의상을 작용했을 때의 모습을 비교적 정확히 예측할 수 있도록 하는 기 술적 효과를 가진다."}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상의 본 발명의 목적들, 다른 목적들, 특징들 및 이점들은 첨부된 도면과 관련된 이하의 바람직한 실시예들을 통해서 쉽게 이해될 것이다. 그러나 본 발명은 여기서 설명되는 실시예들에 한정되지 않고 다른 형태로 구체화 될 수도 있다. 오히려, 여기서 소개되는 실시예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당업자 에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 명세서에서 제1, 제2 등의 용어가 구성요소들을 기술하기 위해서 사용된 경우, 이들 구성요소들이 이 같은 용어들에 의해서 한정되어서는 안된다. 이들 용어들은 단지 어느 구성요소를 다른 구성요소와 구별시키기 위해 서 사용되었을 뿐이다. 여기에 설명되고 예시되는 실시예들은 그것의 상보적인 실시예들도 포함한다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '~를 포 함한다', '~로 구성된다', 및 '~으로 이루어진다'라는 표현은 언급된 구성요소 외에 하나 이상의 다른 구성요소 의 존재 또는 추가를 배제하지 않는다. 본 명세서에서 용어 '소프트웨어'는 컴퓨터에서 하드웨어를 움직이는 기술을 의미하고, 용어 '하드웨어'는 컴퓨 터를 구성하는 유형의 장치나 기기(CPU, 메모리, 입력 장치, 출력 장치, 주변 장치 등)를 의미하고, 용어 '단계'는 소정의 목을 달성하기 위해 시계열로 연결된 일련의 처리 또는 조작을 의미하고, 용어 '컴퓨터 프로그 램', '프로그램', 또는 '알고리즘'은 컴퓨터로 처리하기에 합한 명령의 집합을 의미하고, 용어 '프로그램 기록 매체'는 프로그램을 설치하고 실행하거나 유통하기 위해 사용되는 프로그램을 기록한 컴퓨터로 읽을 수 있는 기 록매체를 의미한다. 본 명세서에서 발명의 구성요소를 지칭하기 위해 사용된 '~부', '~모듈', '~유닛', '~블록', '~보드' 등의 용어 는 적어도 하나의 기능이나 동작을 처리하는 물리적, 기능적, 또는 논리적 단위를 의미할 수 있고 이는 하나 이 상의 하드웨어나 소프트웨어 또는 펌웨어로 구현되거나 또는 하나 이상의 하드웨어, 소프트웨어, 및/또는 펌웨 어의 결합으로 구현될 수 있다. 본 명세서에서, '처리장치', '컴퓨터', '컴퓨팅 장치', '서버 장치', '서버'는 윈도우, 맥, 또는 리눅스와 같은 운영체제, 컴퓨터 프로세서, 메모리, 응용프로그램들, 기억장치(예를 들면, HDD, SDD), 및 모니터를 구비한 장 치로 구현될 수 있다. 컴퓨터는 예를 들면, 데스크톱 컴퓨터나 노트북, 모바일 단말기 등과 같은 장치일 수 있 으나 이들은 예시적인 것이며 이에 한정되는 것은 아니다. 모바일 단말기는 스마트폰, 태블릿 PC, 또는 PDA와 같은 모바일 무선통신기기 중 하나일 수 있다. 본 발명의 일 실시예에 따른 컴퓨터 장치는 \"원본 이미지\"와 \"피팅의상 이미지\"를 수신하고 이를 합성하여 \"합 성 이미지\" 또는 \"결과 이미지\"를 생성한다. 본 명세서에서 \"원본 이미지\"는 가상으로 의상을 입히려는 사람(모 델)의 전신 또는 일부가 표시된 이미지를 의미한다. 또한 본 명세서에서 \"피팅의상 이미지\"는 원본 이미지의 모 델에게 가상으로 입히려는 의상(피팅의상)을 포함하는 이미지를 의미한다. 피팅의상은 상의 및/또는 하의가 될 수 있다. 또한 본 명세서에서 \"기존의상\"은 피팅의상으로 대체되는 의상, 즉 원본 이미지의 모델이 입고 있는 의상 중 피 팅의상으로 대체되어야 할 의상을 의미한다. 예를 들어 원본 이미지에서 상의와 하의를 착용한 모델에 상의의 피팅의상을 가상으로 입히려는 경우, '기존의상'은 원본 이미지의 상의를 의미함을 이해할 것이다. 본 명세서에서 \"합성 이미지\" 또는 \"결과 이미지\"는 원본 이미지와 피팅의상 이미지를 수신하여 이를 합성한 이 미지로서, 원본 이미지의 사람에게 피팅 의상을 가상으로 입힌 모습이 표현된 이미지이다. 한편 본 명세서에서 사람(모델)의 신체나 의상을 지칭할 때 설명의 편의를 위해 '이미지'란 단어를 생략할 수 있다. 예컨대 본 명세서에 '사람', '상의', '하의', '피팅의상', '기존의상' 등은 실제의 사람이나 신체 일부 또는 실제 의상을 의미할 수도 있지만 해당 대상물(신체나 의상)이 표현된 이미지(이미지 파일) 또는 이미지의 일부 영역(픽셀)을 의미할 수 있음을 당업자는 충분히 이해할 것이다. 이하 도면을 참조하여 본 발명을 상세히 설명하도록 한다. 아래의 특정 실시예들을 기술하는데 있어서 여러 가 지의 특정적인 내용들은 발명을 더 구체적으로 설명하고 이해를 돕기 위해 작성되었다. 하지만 본 발명을 이해 할 수 있을 정도로 이 분야의 지식을 갖고 있는 독자는 이러한 여러 가지의 특정적인 내용들이 없어도 사용될 수 있다는 것을 인지할 수 있다. 또한 발명을 기술하는 데 있어서 공지 또는 주지관용 기술이면서 발명과 크게 관련 없는 부분들은 본 발명을 설명하는 데 있어 혼돈을 막기 위해 기술하지 않음을 미리 언급해 둔다. 도1은 일 실시예에 따른 가상 피팅 방법을 실행하는 시스템을 설명하는 블록도이다. 도1을 참조하면, 일 실시예에 따른 가상 피팅 방법은 컴퓨터 장치에서 실행될 수 있다. 컴퓨터 장치는 데스크탑 컴퓨터 또는 노트북 등 통상적인 범용 컴퓨터로 구현될 수 있고 스마트폰과 같은 모바일 단말기로 구 현될 수도 있다. 컴퓨터 장치는 도2 내지 도17을 참조하여 후술하는 가상 피팅 방법을 실행하기 위한 하나 이상의 응용 프로그램을 실행할 수 있다. 일 실시예에서 컴퓨터 장치는 사람(모델)의 전신 또는 일부(예컨대 상반신)의 이미지를 카메라 및/또는 사용자 단말기로부터 수신할 수 있다. 카메라는 컴퓨터 장치에 독립적인 카메라 장치일 수도 있고 컴퓨터 장치에 유선/무선으로 연결된 카메라일 수도 있다. 컴퓨터 장치가 스마트폰인 경우 카메라 는 이 컴퓨터 장치(즉 스마트폰)에 매립된 카메라일 수 있다. 사용자 단말기는 스마트폰과 같은 휴대용 장치일 수 있고, 예를 들어 사용자 단말기의 카메라로 사람을 촬영하고 이 촬영된 이미지를 유선 또는 무선으로 컴퓨터 장치로 전송할 수 있다. 일 실시예에서 컴퓨터 장치는 카메라 또는 사용자 단말기로부터 피사체(예컨대 사람)의 이미지 파 일을 수신한다. 이미지 파일은 컴퓨터로 읽을 수 있는 형태의 이미지 파일로서, 예를 들어 JPG, TIF 등의 확장 자를 갖는 이미지 파일일 수 있다. 컴퓨터 장치가 입력받은 사람의 전신 또는 일부의 이미지를 이하에서 “ 원본 이미지”라 칭하기로 한다. 또한 컴퓨터 장치는 원본 이미지의 사람에게 가상으로 입히려는 의상(이하 “피팅 의상”이라고 함)의 이미 지를 수신할 수 있다. 피팅 의상의 이미지도 카메라 또는 사용자 단말기 등의 외부 장치로부터 수신할 수 있다. 컴퓨터 장치는 원본 이미지와 피팅 의상 이미지를 합성하여 피팅 의상을 입고 있는 사람(모델)의 이미지(이 하 \"결과 이미지\" 또는 \"합성 이미지\"라고 함)를 출력할 수 있다. 일 실시예에서 컴퓨터 장치는 결과 이미지를 디스플레이를 통해 사용자에게 출력할 수 있다. 디스플레 이는 컴퓨터 장치에 독립적인 장치일 수도 있고, 예를 들어 컴퓨터 장치가 스마트폰인 경우 디스플 레이가 이 컴퓨터 장치(즉 스마트폰)에 매립된 디스플레이 일 수도 있다. 도2는 일 실시예에 따른 가상 피팅 시스템의 블록도이다. 도2를 참조하면, 일 실시예에서 컴퓨터 장치는 전처리부, 세그먼테이션부, 의상 변형부, 및 이미지 합성부를 포함할 수 있다. 여기서 전처리부, 세그먼테이션부, 의상 변형부, 및 이 미지 합성부의 각각은 원본 이미지 및/또는 피팅 의상 이미지를 처리하는 하나 이상의 프로그램, 딥러닝 알고리즘 등의 소프트웨어로 구현될 수 있고, 컴퓨터 장치의 저장장치(예컨대 SDD 또는 하드 디스크)에 저 장되어 있다가 메모리에 로딩되어 실행될 수 있다. 전처리부, 세그먼테이션부, 의상 변형부, 및 이미지 합성부의 각각의 동작에 대해 이하의 도면을 참조하여 후술하기로 한다. 도3은 일 실시예에 따른 전처리부의 동작을 설명하는 도면이고 도4는 전처리부의 동작을 설명하는 흐 름도이다. 전처리부는 원본 이미지에서 기존 의상을 제거하는 동작을 수행할 수 있다. 기존 의상이 제거된 상태에서 새로운 의상(즉, 피팅 의상)을 입힐 경우 자유롭게 입힐 수 있으므로 전처리부에서 기존 의상을 제거한다. 도3과 도4를 참조하면, 단계(S110)에서 전처리부는 원본 이미지(I)에서 포즈 정보(P)를 추출한다. 포즈 정 보(P)(또는 간단히 \"포즈(P)\"라고도 함)는 이미지에서 사람의 포즈의 특징점을 찾아내는 일반적인 포즈 추출 알 고리즘을 이용하여 추출될 수 있다. 도3의 도면에서 포즈(P) 이미지는 포즈 추출 알고리즘에서 찾은 특징점 및 이 특징점들을 연결한 선들을 나타낸다. 그 후 단계(S120)에서, 원본 이미지(I)로부터 제1 세그먼테이션(S)을 생성한다. 세그먼테이션(S)은 \"세그먼테이 션 맵\", \"시맨틱 이미지\", \"시맨틱 맵\" 등으로 불리기도 하며, 이미지에 있는 모든 픽셀을 미리 지정된 클래스 (class)로 분류하여 각 클래스에 대응하는 채널(channel) 이미지를 생성한 것이다. 예컨대 얼굴, 헤어, 상의, 하의, 팔, 배경 등이 각각 미리 지정된 클래스가 되고, 제1 세그먼테이션(S)은 이 클래스의 개수만큼의 채널로 이루어진 이미지 데이터이며, 도3에서는 편의상 각 클래스를 각기 다른 컬러로 표시하여 하나의 세그먼테이션 (S) 이미지로 도시하였다. 제1 세그먼테이션(S)의 생성을 위해, 딥러닝 알고리즘, 인공신경망 알고리즘, 인코더와 디코더로 연결된 이미지 생성 알고리즘 등 공지의 세그먼테이션 생성 알고리즘을 사용하여 제1 세그먼테이션(S)을 생성할 수 있다. 그 후 단계(S130)에서, 포즈(P)와 제1 세그먼테이션(S)에 기초하여 원본 이미지(I)에서 기존 의상(즉, 본 실시 예에서는 상의를 의미함)을 제거한다. 예를 들어, 우선 포즈(P)의 특징점들 중에서 양쪽 어깨 - 팔꿈치 - 손목 경로를 따라 특정 색(도면에서는 회색)을 브러쉬로 칠한다. 즉 원본 이미지에서 원형 모양의 브러쉬로 회색을 칠하여 기존 의상을 제거할 수 있다. 그 후 도5(a)에 도시한 것처럼, 포즈(P)의 특징점 정보에 기반하여, 양쪽 어깨와 골반을 기준으로 사각형 영역을 만들어서 이에 대응하는 원본 이미지의 영역에 회색을 칠하고, 도5(b)에 도시한 것처럼 목 포인트를 중심으로 하는 사각형 영역을 만들어서 이에 대응하는 원본 이미지의 영역에 회색을 칠하여, 원본 이미지에서 기존의상 및 그 주위 영역을 제거한다. 그 후 최후의 합성 이미지(결과 이미지)에서도 반드시 유지해야 할 클래스 영역(예컨대 얼굴 및 하의)이 있을 경우, 이 유지해야 할 클래스의 영역을 제1 세그먼테이션(S)에 기초하여 다시 원본 이미지와 동일하게 돌려놓고, 이에 따라 도5(c)에 도시한 것과 같이 기존의상이 제거된 이미지(이하 \"의상제거 이미지(Ia)\"라고도 함)를 얻는다. 의상제거 이미지(Ia)는 피팅 의상으로 대체할 기존 의상만 제거할 수도 있지만, 도5(c)에 도시한 것처럼, 피팅 의상이 들어갈 영역을 최대한 넓게 마련하기 위해, 팔과 어깨 부근까지도 모두 제거할 수도 있다. 의상제거 이미지(Ia)는 나중의 이미지 합성 단계에서 딥러닝 알고리즘에게 \"이 부분은 반드시 유지하라\"라는 정 보를 제공하기 위해 사용될 수 있다. 도6은 일 실시예에 따른 세그먼테이션부의 동작을 설명하는 도면이고 도7은 세그먼테이션부의 동작을 설명하는 흐름도이다. 세그먼테이션부는 입힐 옷(즉, 피팅 의상)에 맞는 새로운 세그먼테이션(이하 \"제2 세그먼테이션\"이라고도 함)을 생성하기 위한 기능 블록이며, 여기서 생성된 제2 세그먼테이션을 기준으로 이후 합성이 진행될 수 있다. 즉, 기존 의상의 정보를 완전히 없애고 피팅 의상의 형상을 반영한 세그먼테이션을 생 성하고 이를 이후의 합성에 사용함으로써 피팅 의상을 신체에 자유롭게 맞출 수 있다. 또한 포즈 정보를 함께 줘서 자세를 추정 가능하게 할 수 있다. 도7의 단계에서 원본 이미지(I)에서 포즈(P)를 추출하고 단계(S220)에서 제1 세그먼테이션(S)를 생성한다. 이 단계(S210,S220)는 도4의 단계(S120,S220)과 동일하며 이 단계(S120,S220)에서 생성된 포즈(P)와 제1 세그 먼테이션(S)을 이용하면 된다. 그 후 단계(S230)에서, 포즈(P)에 기초하여 제1 세그먼테이션(S)에서 의상을 제거하여 의상제거 세그먼테이션 (Sa)을 생성한다. 예를 들어 제1 세그먼테이션(S)에서 기존 의상에 해당하는 영역에 원형 모양의 브러쉬로 검은 색(배경을 의미)을 칠하여 기존 의상을 제거함으로써 의상제거 세그먼테이션(Sa)을 생성한다. 예컨대 제1 세그 먼테이션(S)에서 상의 부분(도6의 원본 이미지(I)에서 주황색)에 검은색을 칠하여 기존 의상을 제거한다. 또한 이 때 포즈(P)의 특징점들 중에서 양쪽 어깨 - 팔꿈치 - 손목 경로를 따라 검은색을 브러쉬로 칠하여 팔 영역도 제거하고, 그 후 합성 이미지(결과 이미지)에서 반드시 유지해야 할 클래스 영역(예컨대 얼굴 및 하의)을 제1 세그먼테이션(S)에 기초하여 다시 원본 이미지와 동일하게 돌려놓으며, 이에 따라 도6에 도시한 것과 같이 의상 과 팔의 영역이 제거된 의상제거 세그먼테이션(Sa)을 얻는다. 그 후 단계(S240)에서, 의상제거 세그먼테이션(Sa), 포즈(P), 및 피팅 의상(c)에 기초하여 제2 세그먼테이션 ()을 생성한다. 제2 세그먼테이션()의 생성은 딥러닝 알고리즘, 인공신경망 알고리즘 등 공지의 세그먼테이 션 생성 알고리즘을 사용할 수 있다. 제2 세그먼테이션()은 피팅 의상(c)이 반영된 세그먼테이션이며, 따라서 일 실시예에서 제2 세그먼테이션() 을 생성하기 위해, 원본 이미지에서 기존 의상이 제거된 의상제거 세그먼테이션(Sa), 및 포즈(P)와 피팅의상 (c)이 입력데이터로서 활용된다. 피팅 의상(c)은 제2 세그먼테이션()에 반영되어야 할 의상 정보를 주기 위해 입력되고, 의상제거 세그먼테이션(Sa)은 제2 세그먼테이션() 생성을 위한 기본 이미지로서 이용되고, 포즈(P) 는 피팅 의상(c)의 어느 부위가 어느 각도로 틀어지는지 등의 포즈 정보를 알려주기 위해 입력될 수 있다. 제2 세그먼테이션()은 예컨대 도6에 도시한 이미지와 같이 생성되고, 제1 세그먼테이션(S)과의 비교에서 알 수 있듯이, 제2 세그먼테이션()의 상의(주황색) 영역은 기존 의상이 아니라 피팅 의상과 유사한 영역을 갖게 됨을 이해할 것이다. 또한 제2 세그먼테이션()에서도 예컨대 얼굴, 헤어, 상의, 하의, 팔, 배경 등이 각각 미리 지 정된 클래스가 되고 제2 세그먼테이션()은 이 클래스의 개수만큼의 채널로 이루어진 이미지 데이터이며, 도6에 서는 편의상 각 클래스를 각기 다른 컬러로 표시하여 하나의 이미지로 나타내었음을 이해할 것이다. 의상제거 이미지(Ia), 의상제거 세그먼테이션(Sa), 및 제2 세그먼테이션()의 차이와 관련하여, 의상제거 이미 지(Ia)는 피팅 의상(c)이 크더라도 피팅 의상을 수용할 영역을 가능한 최대한 크게 만들기 위해, 원본 이미지에 서 삭제하는 영역이 비교적 많은 반면, 의상제거 세그먼테이션(Sa)은 세그먼테이션부에서 제2 세그먼테이 션()을 만들기 위한 입력 데이터로 사용하기 위한 것이며 기존 의상만 제거하면 되므로 많은 영역을 제거하지 않아도 된다. 그리고 제2 세그먼테이션()은 피팅 의상(c)이 반영된 세그먼테이션이며 의상 변형부와 이미지 합성부에서 사용될 수 있다. 도8은 일 실시예에 따른 의상 변형부의 동작을 설명하는 도면이고 도9는 의상 변형부의 동작을 설명 하는 흐름도이다. 의상 변형부는 원본 이미지의 사람의 포즈에 기초하여 피팅 의상을 변형하는 기능부이다. 도8과 도9를 참조하면, 우선 단계(S310)에서, 입력 데이터를 의상 변형을 수행하는 딥러닝 알고리즘에 입력하여 의상의 변형(와핑) 정도를 나타내는 출력변수(θ)를 생성한다. 일 실시예에서, 제2 세그먼테이션의 의상(클래스)을 나타내는 채널(c) 및 피팅 의상(c)을 입력 데이터로 사용할 수 있다. 이 경우, 피팅 의상(c) 은 와핑의 대상이 되는 데이터이고, 채널(c)은 변형되는 의상이 차지하는 영역을 설정하기 위한 데이터이다. 대안적으로, 도8에 도시한 것처럼 의상제거 이미지(Ia), 포즈(P), 및 제2 세그먼테이션의 의상(클래스)을 나타 내는 채널(c), 및 피팅 의상(c)을 딥러닝 알고리즘의 입력 데이터로서 사용할 수 있다. 이 경우 포즈(P)는 의 상의 어느 부위가 어느 각도로 틀어져서 변형되는지를 알려주기 위한 데이터로 사용되고 의상제거 이미지(Ia)는, 의상에 가려지지 않아야 할 부분의 정보를 주기 위해 사용될 수 있다. 예를 들어, 치마나 바지 등의 하의 때문에 피팅 의상(상의) 아래쪽이 제거되어야 하는데, 이 경우 단순히 피팅 의상을 사람의 포즈에 따 라 변형해야 할 뿐만 아니라 피팅 의상의 아래쪽 영역을 제거해야 하며, 따라서 이렇게 제거되어야 하는 부분까 지 반영하기 위해 의상제거 이미지(Ia)가 사용된다. 위와 같이 의상제거 이미지(Ia), 포즈(P), 및 제2 세그먼테이션의 의상(클래스)을 나타내는 채널(c)을 딥러닝 알고리즘의 인코더에 입력하고 또한 피팅 의상(c)을 별도의 딥러닝 알고리즘의 인코더에 입력 데이터 로서 입력하여 각각 다단의 컨볼루션 연산 및 다운샘플링이 이루어지고 그 후 각각의 결과를 결합(Concat)하여 디코딩하면 출력변수(θ)를 얻을 수 있다. 여기서 출력변수(θ)는 의상의 변형(와핑: warping)의 정도를 정의하 는 값이고, 출력변수(θ)와 피팅 의상(c)을 예컨대 공지의 와핑 알고리즘에 입력하여 변형된 의상(W)을 출 력할 수 있다. 상기와 같이 인코더와 디코더로 이루어진 딥러닝 알고리즘은 공지의 기계학습 알고리즘을 이용할 수 있으며 본 발명의 실시예에 맞는 학습 데이터로 적절히 학습하여 구현할 수 있다. 도10은 대안적 실시예에 따른 의상 변형부를 블록도로 개략적으로 도시하였다. 도10(a)의 실시예는 입력 데이터로서 의상제거 이미지(Ia)와 피팅 의상(c)을 사용한다. 예컨대 의상제거 이미지 (Ia)와 피팅 의상(c)을 각각 딥러닝 알고리즘의 인코더에 입력하여 출력변수(θ)를 생성하고, 출력변수(θ)에 기초하여 피팅 의상(c)을 와핑하여 변형된 피팅 의상(W)을 출력할 수 있다. 또 다른 대안적 실 시예에서, 의상제거 이미지(Ia) 대신 원본 이미지(I)를 사용할 수 있다. 도10(b)의 실시예는 입력 데이터로서 원본 이미지(I), 제1 세그먼테이션의 의상 클래스를 나타내는 채널(Sc), 및 피팅 의상(c)을 사용할 수 있다. 예를 들어, 원본 이미지(I)와 제1 세그먼테이션의 의상 클래스를 나타내는 채널(Sc) 및 피팅 의상(c)을 각각 딥러닝 알고리즘의 인코더에 입력하여 출력변수(θ)를 생성하고, 출력변 수(θ)에 기초하여 피팅 의상(c)을 와핑하여 변형된 피팅 의상(W)을 출력할 수 있다. 도10(c)의 실시예는 입력 데이터로서 원본 이미지(I), 제2 세그먼테이션의 의상 클래스를 나타내는 채널(c), 및 피팅 의상(c)을 사용할 수 있다. 예를 들어, 원본 이미지(I)와 제2 세그먼테이션의 의상 클래스를 나타내는 채널(c) 및 피팅 의상(c)을 각각 딥러닝 알고리즘의 인코더에 입력하여 출력변수(θ)를 생성하고, 출력변 수(θ)에 기초하여 피팅 의상(c)을 와핑하여 변형된 피팅 의상(W)을 출력할 수 있다. 도10(b)와 도10(c)의 또 다른 대안적 실시예에서, 원본 이미지(I) 대신 의상제거 이미지(Ia)를 사용할 수도 있다. 도11은 일 실시예에 따른 이미지 합성부의 동작을 설명하는 도면이고 도12는 이미지 합성부의 동작을 설명하는 흐름도이 다. 일 실시예에서, 제1 세그먼테이션(S) 또는 제2 세그먼테이션()의 의상 영역 중 피팅 의상(W)의 영역이 중첩되 지 않는 비정렬 영역(Mmisalign)을 생성하고, 이 비정렬 영역(Mmisalign), 원본 이미지(I) 또는 원본 이미지를 이미지 처리한 이미지(예컨대 Ia), 및 변형된 피팅 의상(W)을 이미지 합성 알고리즘에 입력 데이터로 입력하여 합성 이미지()를 생성할 수 있다. 이 때 비정렬 영역(Mmisalign)을 생성하기 위해, 예를 들어, 세그먼테이션(예컨대, 제1 세그먼테이션(S) 또는 제2 세그먼테이션() 중 하나)의 의상 영역과 상기 변형된 피팅 의상(W) 영역이 중첩되는 정렬 영역(Malign)을 우선 생성하고, 상기 세그먼테이션의 의상 영역에서 상기 정렬 영역(Malign)을 제외하여 비정렬 영역 (Mmisalign)을 생성할 수 있다. 이 때 사용되는 세그먼테이션은 제1 세그먼테이션(S) 또는 제2 세그먼테이션()일 수 있으며, 바람직하게는 제2 세그먼테이션()을 사용한다. 이 경우 도12의 단계(S410)와 같이, 제2 세그먼테이션()의 의상 영역의 채널 (c) 중 변형된 의상(W)이 커버하지 못하는 비정렬 영역(Mmisalign) 생성하고, 그 후 단계(S420)에서, 제1 데 이터 세트(Ia, P, W) 및 제2 데이터 세트(, Mmisalign)를 입력 데이터로서 이미지 합성 알고리즘에 입력하여 합성 이미지()를 생성할 수 있다. 이 때 비정렬 영역(Mmisalign)은 도13(a)에 도시한 것처럼 생성할 수 있다. 즉 제2 세그먼테이션()의 의상 영 역의 채널(c)과 변형된 피팅 의상(W) 영역이 중첩되는 부분을 정렬 영역(Malign)으로서 우선 생성하고, 제2 세그먼테이션()의 의상 영역 채널(c)에서 정렬 영역(Malign)을 제외한 영역을 비정렬 영역(Mmisalign)으로 정의할 수 있다. 한편 단계(S420)에서 이미지 합성 알고리즘에 입력되는 제1 데이터 세트는 의상제거 이미지(Ia), 포즈(P), 및 변형된 피팅 의상(W)을 포함하고, 제2 데이터 세트는 제2 세그먼테이션() 및 비정렬 영역(Mmisalign)을 포 함할 수 있다. 여기서 제1 데이터 세트는 가상 피팅의 결과물로서 출력하기 위해 합성해야 할 이미지를 제공한 다. 즉 기본적으로 원본 이미지(I) 및 변형된 피팅 의상(W)을 포함할 수 있으나, 바람직하게는, 원본 이미지 (I)에서 기존 의상(c)을 제거한 의상제거 이미지(Ia) 및 변형된 피팅 의상(W)을 입력 데이터로 할 수 있다. 이 때 의상제거 이미지(Ia)는 합성 이미지에서도 유지해야 할 영역을 지정하는 역할을 할 수 있다. 또한 본 발명의 일 실시예에서, 포즈(P)에 관한 정보도 제1 데이터 세트에 포함될 수 있다. 이 때 포즈(P) 정보는 피팅 의상을 원본 이미지에 합성시 피팅 의상의 텍스쳐를 생성할 때 포즈(P)를 참고하여 생성하도록 입력하는 것으로, 예컨 대 이미지 합성 알고리즘이 새로 생성해야 할 부분, 즉 비정렬 영역(Mmisalign)에 텍스쳐를 만들 때 포즈(P)를 참고하여 생성할 할 수 있다. 단계(S420)에서 이미지 합성 알고리즘에 입력되는 제2 데이터 세트는 텍스쳐를 유지해야 영역과 새로 생성 해야 할 영역에 관한 정보를 주는 역할을 한다. 일 실시예에서 제2 데이터 세트는 제2 세그먼테이션() 및 비정 렬 영역(Mmisalign)을 포함한다. 일 실시예에서 제2 데이터 세트를 이미지 합성 알고리즘에 입력할 때 도13(b)에 도시한 것처럼 제2 세그먼테이 션() 데이터를 분리되어 입력할 수 있다. 즉 제2 세그먼테이션()을 피팅 의상 영역(c)과 이 영역(c)을 제 외한 나머지 영역(_c)으로 분리하고 이렇게 분리된 제2 세그먼테이션() 데이터와 비정렬 영역(Mmisalign)을 이미지 합성 알고리즘에 입력할 수 있다. 제2 세그먼테이션()을 피팅 의상 영역(c)과 나머지 영역 (_c)으로 분리하여 입력하는 것은, 이미지 합성 알고리즘이 이렇게 입력 데이터를 개별적으로 입력받는 경우 피팅 의상을 합성할 영역을 보다 정확히 인식할 수 있기 때문이다. 그러나 대안적 실시예에서는 제2 세그 먼테이션()을 위와 같이 분리하지 않고 하나의 데이터로 입력할 수도 있음은 물론이다. 한편 도14와 도15(a)에 도시한 것처럼, 일 실시예에서 이미지 합성 알고리즘은 복수의 컨볼루션 연산 블록이 다 단으로 연결된 디코더로 구현될 수 있다. 도14의 실시예에서는 이미지 합성 알고리즘을 컨볼루션과 업샘플링 연 산을 포함하는 복수의 잔차블록(ResBlk)이 다단으로 연결된 디코더로 구성하였고, 이 때 제1 데이터 세트 와 제2 데이터 세트는 상기 복수의 잔차블록의 각 잔차블록마다 각각 입력 데이터로서 입력된다. 잔차블록(ResBlk) 알고리즘은 딥러닝 알고리즘의 학습시 최적화의 난이도를 낮추는 기법으로 공지된 기술이다. 즉 실제로 내재한 매핑(mapping) 결과값(예컨대, H)을 직접 학습하는 것이 어려우므로 입력값(x)과 결과값(H)을 차이, 즉 (F: F(x)=H(x)-x)를 학습의 잔차 부분으로 보고 이 부분을 학습하는 기법이며, 따라서 입력(x)이 컨볼 루션단으로 입력됨과 동시에 입력을 분기하여 곧바로 출력단에도 연결시키는 블록도로 표현한다. 본 발명의 일 실시예에서는 이러한 잔차블록(ResBlk)의 기법을 채용하여, 도15(b)에 도시한 것처럼 각각의 잔차 블록을 정렬인식 잔차블록(ALIAS ResBlk)으로 구성하였고, 각각의 정렬인식 잔차블록은 입력(hi)이 정렬인식 정규화단을 2번 거치는 경로와 1번 거치는 경로로 각각 입력된 후 그 결과를 합하여 출력(hi+1) 하는 구조로 구성된다. 이 때 제1 데이터 세트는 각각의 정렬인식 잔차블록의 입력단으로 입력되며, 제2 데이터 세트는 각각의 정렬인식 정규화에 입력될 수 있다. 또한 일 실시예에서 각각의 정렬인식 정규화는 공지의 SPADE(Spatially-Adaptive Denormalization) 알고 리즘의 배치 정규화(Batch Norm) 구조를 채용하여 본 발명에 적용한 것으로, 예를 들어 도16에 도시한 구조를 가질 수 있다. 일반적으로 배치 정규화(Batch Norm)는 딥러닝 알고리즘의 각 레이어(layer)마다 출력을 정규화 함으로써 출력값이 비선형성을 유지하도록 하여 알고리즘의 성능을 향상시키는 기법이며, 도16에 도시한 것처럼 세그먼테이션 맵을 각각 복수회 컨볼루션 연산한 결과에 따라 γ(스케일링 파라미터)와 β(쉬프트 파라미터)를 산출하고 이 값을 각 레이어의 출력값에 각각 곱하고 더하여서 다음 레이어로 출력하는 역할을 한다. 본 발명의 일 실시예에서 정렬인식 정규화는 이러한 정렬인식 정규화 블록에 제2 데이터 세트를 입력 데이터로서 입력한다. 즉 도16에 도시한 것처럼 피팅 의상 영역(c)과 나머지 영역(_c) 및 비정렬 영역 (Mmisalign)을 γ와 β를 생성하기 위한 컨볼루션 연산의 입력 데이터로 입력하고 γ와 β의 연산 앞단에 비정 렬 영역(Mmisalign)을 표준화하여 입력할 수 있다. 대안적 실시예에서, 이미지 합성부에 입력하는 제1 데이터 세트와 제2 데이터 세트의 일부 데이터를 변경 하거나 생략할 수도 있음은 물론이다. 예를 들어 도17은 예시적인 실시예에 따른 이미지 합성부의 동작을 블록도로 개략적으로 도시하였다. 도17(a)은 제1 데이터 세트에서 포즈(P)를 생략하고 제2 데이터 세트에서 제2 세그먼테이션() 대신 제1 세그 먼테이션(S)을 사용하는 실시예를 나타내었다. 도17(b)는 제1 데이터 세트에서 포즈(P)를 생략하고 변형된 피팅 의상(W) 대신 피팅의상(c)의 이미지를 사용하여 이미지를 합성하는 실시예를 나타내었다. 도17(c)는 제1 데이터 세트에서 의상제거 이미지(Ia) 대신 원본 이미지(I)를 사용하고 포즈(P)를 생략한 경우의 실시예를 나타내었다. 이와 같이 구체적 실시 형태에 따라 이미지 합성부에 입력하는 제1 데이터 세트와 제2 데이터 세트의 일부 데이터를 다양한 조합으로 변경하거나 생략하여 이미지를 합성할 수 있음을 이해할 것이다."}
{"patent_id": "10-2021-0049800", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도18은 일 실시예에 따른 본 발명의 효과를 설명하는 도면이다. 일반적으로 가상 피팅이 완성된 합성 이미지의 해상도가 커질수록 원본 이미지의 사람 영역과 변형된 피팅 의상 의 영역 사이에 어색한 부분이 많이 보이게 되는데, 본 발명에서는 상술한 것과 같이 비정렬 영역(Mmisalign)을 이미지 합성 이미지의 입력 데이터중 하나로 입력함으로써 이미지 합성 알고리즘이 비정렬 영역을 인식하 게 하고 이 비정렬 영역에 텍스쳐를 생성하여 채워 넣도록 함으로써 자연스러운 피팅 의상을 구현할 수 있다. 도18(a)는 종래기술에 따른 합성 이미지로서, 사람의 어깨 부분에 표시한 빨간색 영역이 비정렬 영역 (Mmisalign)에 해당하는데, 종래의 피팅 기술에서는 이미지 합성 알고리즘이 이 부분의 처리를 제대로 하지 못 하여 텍스쳐가 제대로 생성되지 않고 부자연스러운 출력을 나타내었다. 이에 반해 도18(b)는 본 발명의 일 실시예에 따른 합성 이미지로서, 이미지 합성 알고리즘이 빨간색의 비 정렬 영역(Mmisalign)을 인식하여 이 영역에 텍스쳐를 생성하여 채워 넣음으로써 종래에 비해 보다 자연스러운 출력 결과를 나타내었음을 확인할 수 있다. 이상과 같이 본 발명이 속하는 분야에서 통상의 지식을 가진 자라면 이러한 명세서의 기재로부터 다양한 수정 및 변형이 가능함을 이해할 수 있다. 그러므로 본 발명의 범위는 설명된 실시예에 국한되어 정해져서는 아니되 며 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2021-0049800", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 일 실시예에 따른 가상 피팅 방법을 실행하는 시스템을 설명하는 블록도, 도2는 일 실시예에 따른 가상 피팅 시스템의 블록도, 도3은 일 실시예에 따른 전처리부의 동작을 설명하는 도면,, 도4는 일 실시예에 따른 전처리부의 동작을 설명하는 흐름도, 도5는 일 실시예에 따른 의상제거 이미지(Ia) 생성 방법을 설명하는 도면, 도6은 일 실시예에 따른 세그먼테이션부의 동작을 설명하는 도면, 도7은 일 실시예에 따른 세그먼테이션부의 동작을 설명하는 흐름도, 도8은 일 실시예에 따른 의상 변형부의 동작을 설명하는 도면, 도9는 일 실시예에 따른 의상 변형부의 동작을 설명하는 흐름도, 도10은 대안적 실시예에 따른 의상 변형부를 설명하는 도면, 도11은 일 실시예에 따른 이미지 합성부의 동작을 설명하는 도면, 도12는 일 실시예에 따른 이미지 합성부의 동작을 설명하는 흐름도, 도13는 일 실시예에 따른 이미지 합성 알고리즘 입력 데이터를 설명하는 도면, 도14 내지 도16은 일 실시예에 따른 이미지 합성 알고리즘을 설명하는 도면, 도17은 대안적 실시예에 따른 이미지 합성부를 설명하는 도면,"}
{"patent_id": "10-2021-0049800", "section": "도면", "subsection": "도면설명", "item": 2, "content": "도18은 일 실시예에 따른 본 발명의 효과를 설명하는 도면이다."}
