{"patent_id": "10-2023-0117894", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0035346", "출원번호": "10-2023-0117894", "발명의 명칭": "맥락 정보 기반 감정 인식 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "한병옥"}}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "감정 인식 장치에서 수행되는 장단기 기억 기반 맥락인지 감정 인식 방법에 있어서,입력 영상으로부터 감정 인식 대상에 상응하는 정보를 검출하는 단계;상기 감정 인식 대상에 상응하는 정보에 기반하여 인식 대상 특징을 추출하는 단계;상기 입력 영상에 기반하여 맥락 특징을 추출하는 단계;단기 기억 메모리에 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 단계; 및장기 기억 메모리에 상기 맥락 특징을 저장하는 단계;를 포함하는 맥락 정보 기반 감정 인식 방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 장기 기억 메모리는상기 맥락 특징에 기반하여 생성된 맥락 텍스트 정보를 저장하는 것을 특징으로 하는 맥락 정보 기반 감정 인식방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 방법은상기 단기 기억 메모리 및 상기 장기 기억 메모리에 저장된 정보에 기반하여 상기 감정 인식 대상의 감정을 인식하는 단계를 더 포함하는 것을 특징으로 하는 맥락 정보 기반 감정 인식 방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 감정을 인식하는 단계는 상기 장기 기억 메모리에 저장된 상기 맥락 텍스트 정보를 입력으로 생성된 요약 맥락 정보를 이용하여 감정을인식하는 것을 특징으로 하는 맥락 정보 기반 감정 인식 방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 2에 있어서,상기 맥락 텍스트 정보는기학습된 언어 모델(Language Model)에 상기 맥락 특징을 입력하여 생성되는 것을 특징으로 하는 맥락 정보 기반 감정 인식 방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 감정 인식 대상에 상응하는 정보는감정 인식 대상의 얼굴 영역, 감정 인식 대상의 전신 영역 및 감전 인식 대상의 음성을 포함하는 것을 특징으로공개특허 10-2025-0035346-3-하는 맥락 정보 기반 감정 인식 방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 2에 있어서,상기 단기 기억 메모리는상기 입력 영상의 전체 프레임에 대하여 제1 빈도로 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 것을특징으로 하는 맥락 정보 기반 감정 인식 방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 장기 기억 메모리는상기 입력 영상의 전체 프레임에 대하여 상기 제1 빈도보다 낮은 제2 빈도로 상기 맥락 텍스트 정보를 저장하는것을 특징으로 하는 맥락 정보 기반 감정 인식 방법."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "입력 영상으로부터 감정 인식 대상에 상응하는 정보를 검출하는 대상 검출부;상기 감정 인식 대상에 상응하는 정보에 기반하여 인식 대상 특징을 추출하는 대상 특징 추출부;상기 입력 영상에 기반하여 맥락 특징을 추출하는 맥락 특징 추출부; 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 단기 기억 저장부; 및상기 맥락 특징을 저장하는 장기 기억 저장부;를 포함하는 맥락 정보 기반 감정 인식 장치."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 장기 기억 저장부는상기 맥락 특징에 기반하여 생성된 맥락 텍스트 정보를 저장하는 것을 특징으로 하는 맥락 정보 기반 감정 인식장치."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 장치는상기 단기 기억 저장부 및 상기 장기 기억 저장부에 저장된 정보에 기반하여 상기 감정 인식 대상의 감정을 인식하는 감정 인식부를 더 포함하는 것을 특징으로 하는 맥락 정보 기반 감정 인식 장치."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 감정 인식부는상기 장기 기억 저장부에 저장된 상기 맥락 텍스트 정보를 입력으로 생성된 요약 맥락 정보를 이용하여 감정을인식하는 것을 특징으로 하는 맥락 정보 기반 감정 인식 장치."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 10에 있어서,상기 맥락 텍스트 정보는공개특허 10-2025-0035346-4-기학습된 언어 모델(Language Model)에 상기 맥락 특징을 입력하여 생성되는 것을 특징으로 하는 맥락 정보 기반 감정 인식 장치."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 9에 있어서,상기 감정 인식 대상에 상응하는 정보는감정 인식 대상의 얼굴 영역, 감정 인식 대상의 전신 영역 및 감전 인식 대상의 음성을 포함하는 것을 특징으로하는 맥락 정보 기반 감정 인식 장치."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 10에 있어서,상기 단기 기억 저장부는상기 입력 영상의 전체 프레임에 대하여 제1 빈도로 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 것을특징으로 하는 맥락 정보 기반 감정 인식 장치."}
{"patent_id": "10-2023-0117894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 장기 기억 저장부는상기 입력 영상의 전체 프레임에 대하여 상기 제1 빈도보다 낮은 제2 빈도로 상기 맥락 텍스트 정보를 저장하는것을 특징으로 하는 맥락 정보 기반 감정 인식 장치."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 방법은 입력 영상으로부터 감정 인식 대상에 상응하는 정 보를 검출하는 단계; 상기 감정 인식 대상에 상응하는 정보에 기반하여 인식 대상 특징을 추출하는 단계; 상기 입력 영상에 기반하여 맥락 특징을 추출하는 단계; 단기 기억 메모리에 상기 인식 대상 특징 및 상기 맥락 특징 을 저장하는 단계; 및 장기 기억 메모리에 상기 맥락 특징을 저장하는 단계를 포함한다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 입력 영상을 분석하여 사람의 감정을 추정하는 기술에 관한 것이다. 구체적으로, 본 발명은 인공지능 신경망을 기반으로 입력 영상 내 사람의 감정을 추정하는 기술에 관한 것이다. 구체적으로, 본 발명은 입력 영상 내 맥락 정보를 이용하여 영상 내 사람의 감정을 추정하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 기반 자동화된 감정 인식 방법(automated emotion recognition method)은 사용자가 자발적으로 외부로 표 출하는 모습을 관찰/분석하여, 보이지 않는 내부 상태인 사용자의 감정을 분석하고 감정을 추론한다. 종래의 자동화된 감정인식 방법은 사람의 내부 감정 상태를 정확히 알아내기 위해, 사용자의 영상/음성 데이터 를 분석하여 표정/행동/어투/언어 특징을 추출하고 관련된 감정 어노테이션 정보와 함께 딥뉴럴네트워크(DNN)를 학습하여 감정을 알아내는 것에 주로 초점을 두고 있다. 하지만, 사람의 감정을 정확하게 이해하기 위해서는 사 용자의 외부 표출 특징(표정/행동/어투/언어)뿐만 아니라 사용자와 관련된 시간/공간적 맥락 특징 역시 고려되 어야 한다. 예를 들면, 주말을 쉬고 월요일에 복귀한 사무실에서는 사람들의 표정이 어두울 수 있으므로, 주기 적 맥락 정보가 필요할 수 있다. 병원에서의 환자들의 감정 상태는 다른 실내에서의 감정 상태와 다른 특징을 가질 수 있다. 일반적으로 사람들은 타인의 감정을 판단할 때 이러한 시공간적 맥락을 고려하여 감정을 알아내 곤 한다. 본 발명은 사람의 복잡한 내부 감정 상태를 정확히 이해하기 위한 장단기 기억 기반 맥락인지 감정인식 방법에 관한 것이다. 시간적 맥락을 고려하기 위해 장/단기 감정 기억 특징을 메모리에 저장하고, 필요시 사용자의 감 정 특징 정보와 함께 통합적 분석을 수행하여 감정인식을 수행한다.선행기술문헌 특허문헌 (특허문헌 0001) 국내 등록특허공보 제2398683호(발명의 명칭: 패러프레이징을 이용한 감정 사전 구축 및 이를 이용한 텍스트 상의 감정 구조 인식 시스템 및 방법)"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 맥락인지 감성 인식을 통해 보다 정확한 감정 인식 결과를 제공하는 것이다. 또한, 본 발명의 목적은 장단기 기억 메모리를 활용하여 효율적으로 맥락정보를 저장하고, 저장된 정보를 이용 하여 감정 인식을 수행하는 것이다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 방법은 입력 영상으로부터 감정 인식 대상에 상응하는 정보를 검출하는 단계; 상기 감정 인식 대상에 상응하는 정보에 기반하여 인식 대상 특징을 추출하는 단계; 상기 입력 영상에 기반하여 맥락 특징을 추출하는 단계; 단기 기억 메모리에 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 단계; 및 장기 기억 메모리에 상기 맥락 특징을 저장하는 단계를 포함 한다. 이때, 상기 장기 기억 메모리는 상기 맥락 특징에 기반하여 생성된 맥락 텍스트 정보를 저장할 수 있다. 이때, 상기 방법은 상기 단기 기억 메모리 및 상기 장기 기억 메모리에 저장된 정보에 기반하여 상기 감정 인식 대상의 감정을 인식하는 단계를 더 포함할 수 있다. 이때, 상기 감정을 인식하는 단계는 상기 장기 기억 메모리에 저장된 상기 맥락 텍스트 정보를 입력으로 생성된"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "요약 맥락 정보를 이용하여 감정을 인식할 수 있다. 이때, 상기 맥락 텍스트 정보는 기학습된 언어 모델(Language Model)에 상기 맥락 특징을 입력하여 생성될 수 있다. 이때, 상기 감정 인식 대상에 상응하는 정보는 감정 인식 대상의 얼굴 영역, 감정 인식 대상의 전신 영역 및 감 전 인식 대상의 음성을 포함할 수 있다. 이때, 상기 단기 기억 메모리는 상기 입력 영상의 전체 프레임에 대하여 제1 빈도로 상기 인식 대상 특징 및 상 기 맥락 특징을 저장할 수 있다. 이때, 상기 장기 기억 메모리는 상기 입력 영상의 전체 프레임에 대하여 상기 제1 빈도보다 낮은 제2 빈도로 상 기 맥락 텍스트 정보를 저장할 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 장치는 입력 영상으 로부터 감정 인식 대상에 상응하는 정보를 검출하는 대상 검출부; 상기 감정 인식 대상에 상응하는 정보에 기반 하여 인식 대상 특징을 추출하는 대상 특징 추출부; 상기 입력 영상에 기반하여 맥락 특징을 추출하는 맥락 특 징 추출부; 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 단기 기억 저장부; 및 상기 맥락 특징을 저장하 는 장기 기억 저장부를 포함한다. 이때, 상기 장기 기억 저장부는 상기 맥락 특징에 기반하여 생성된 맥락 텍스트 정보를 저장할 수 있다. 이때, 상기 장치는 상기 단기 기억 저장부 및 상기 장기 기억 저장부에 저장된 정보에 기반하여 상기 감정 인식 대상의 감정을 인식하는 감정 인식부를 더 포함할 수 있다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "이때, 상기 감정 인식부는 상기 장기 기억 저장부에 저장된 상기 맥락 텍스트 정보를 입력으로 생성된 요약 맥 락 정보를 이용하여 감정을 인식할 수 있다. 이때, 상기 맥락 텍스트 정보는 기학습된 언어 모델(Language Model)에 상기 맥락 특징을 입력하여 생성될 수 있다. 이때, 상기 감정 인식 대상에 상응하는 정보는 감정 인식 대상의 얼굴 영역, 감정 인식 대상의 전신 영역 및 감 전 인식 대상의 음성을 포함할 수 있다. 이때, 상기 단기 기억 저장부는 상기 입력 영상의 전체 프레임에 대하여 제1 빈도로 상기 인식 대상 특징 및 상 기 맥락 특징을 저장할 수 있다. 이때, 상기 장기 기억 저장부는 상기 입력 영상의 전체 프레임에 대하여 상기 제1 빈도보다 낮은 제2 빈도로 상 기 맥락 텍스트 정보를 저장할 수 있다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 맥락인지 감성 인식을 통해 보다 정확한 감정 인식 결과를 제공할 수 있다. 또한, 본 발명은 장단기 기억 메모리를 활용하여 효율적으로 맥락정보를 저장하고, 저장된 정보를 이용하여 감 정 인식을 수행할 수 있다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다. 본 명세서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함 께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 본 발명은 사용자의 감정 분석 및 추론을 위해 장기/단기 메모리를 활용하여 시공간적 맥락(context) 정보와 사 용자의 표정/행동 등의 정보 기반으로 사용자의 감정을 통합적으로 추론하는 시스템에 관한 것이다. 본 발명은 실시간 RGB 영상 촬영이 가능한 CCTV와 같은 카메라 장비와 해당 장비로부터 실시간 영상 분석이 가 능한 컴퓨터에서 동작할 수 있다. 컴퓨터는 프로그램이 동작하고 있는 동안의 단기 감정 정보를 저장할 RAM(Random Access Memory)과 같은 휘발성 메모리와 프로그램이 장기적으로 감정 정보를 저장할 하드디스크와 같은 비휘발성 스토리지를 포함할 수 있다. 본 발명은 고령자 장기 감정 모니터링, 장기 환자 감정 모니터링, 백화점 VIP 고객 감정 모니터링, 레스토랑 서 빙 로봇의 멤버십 손님 감정 모니터링 시스템 등과 같이 장기적 감정 상태 관찰이 필요한 응용에서 활용할 수 있다. 이때, 본 발명은 시간적 맥락 고려를 위한 장기 기억(long-term)과 단기 기억(short-term) 메모리의 개별 구성, 시공간적 감정 맥락 특징의 효과적 결합을 위한 비전 모델(Vision Model, VM)과 언어 모델(Language Model,"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "LM)의 활용에 관한 구성 및 장기적 감정 맥락 특징의 효율적 텍스트 저장/로그 확인/요약(압축)/추출을 위한 LM 활용에 관한 구성을 특징으로 한다. 도 1은 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 방법을 나타낸 흐름도이다. 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 방법은 컴퓨팅 디바이스와 같은 감정 인식 장치에서 수 행될 수 있다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 방법은 입력 영상으로부터 감정 인식 대상에 상응하는 정보를 검출하는 단계(S110), 상기 감정 인식 대상에 상응하는 정보에 기반하여 인식 대상 특 징을 추출하는 단계(S120), 상기 입력 영상에 기반하여 맥락 특징을 추출하는 단계(S130), 단기 기억 메모리에 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 단계(S140) 및 장기 기억 메모리에 상기 맥락 특징을 저장 하는 단계(S150)를 포함한다. 이때, 상기 장기 기억 메모리는 상기 맥락 특징에 기반하여 생성된 맥락 텍스트 정보를 저장할 수 있다. 이때, 도 1에는 도시되지 않았지만, 상기 방법은 상기 단기 기억 메모리 및 상기 장기 기억 메모리에 저장된 정 보에 기반하여 상기 감정 인식 대상의 감정을 인식하는 단계를 더 포함할 수 있다. 이때, 상기 감정을 인식하는 단계는 상기 장기 기억 메모리에 저장된 상기 맥락 텍스트 정보를 입력으로 생성된"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "요약 맥락 정보를 이용하여 감정을 인식할 수 있다. 이때, 상기 맥락 텍스트 정보는 기학습된 언어 모델(Language Model)에 상기 맥락 특징을 입력하여 생성될 수 있다. 이때, 상기 감정 인식 대상에 상응하는 정보는 감정 인식 대상의 얼굴 영역, 감정 인식 대상의 전신 영역 및 감 전 인식 대상의 음성을 포함할 수 있다. 이때, 상기 단기 기억 메모리는 상기 입력 영상의 전체 프레임에 대하여 제1 빈도로 상기 인식 대상 특징 및 상 기 맥락 특징을 저장할 수 있다. 이때, 상기 장기 기억 메모리는 상기 입력 영상의 전체 프레임에 대하여 상기 제1 빈도보다 낮은 제2 빈도로 상 기 맥락 텍스트 정보를 저장할 수 있다. 도 2는 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 시스템의 구성도이다. 도 2에 기재된 VM, EM, LM, LTM, STM 및 ER은 각각 vision model, emotion model, language model, long-term memory, short-term memory 및 emotion recognizer를 의미할 수 있다. 또한, 각각의 모듈은 인공지능 신경망에 상응할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 시스템(장치)은 실시간 촬영 영상의 한 프레임과 분석할 대상의 얼굴 영상(정지영상)을 입력받을 수 있다. 실시간 촬영 영상은 프레임별로 시스템에 입력되며, 사용자의 얼굴 영상은 감정 분석할 대상을 실시간 촬영 영상 내에서 찾기 위한 용도이다. 도 3은 전처리기(Pre-processor) 구성의 일 예이다. 도 2의 전처리기(Pre-processor)는 입력된 정보의 활용을 위한 전처리(Pre-processing)를 목적으로 한다. 도 3 을 참조하면, 본 발명의 일 실시예에 따른 방법에서 전처리기(Pre-processor)는 영상 내에서 휴먼 검출, 얼굴 검출, 신원 인식을 통해 사용자의 얼굴 영역과 전신 영역을 검출할 수 있다. 또 다른 실시예로, 사용자의 음성 정보를 사용가능 하도록 화자 분리/인식하여 사용자의 음성 정보만 추출할 수 있다. 또한, 전처리기는 의미를 추출하기 위한 텍스트 정보 추출을 수행할 수 있으며, 그 외 모달리티 기반의 입력 전처리도 수행 가능하다. 이때, 감정 모델(EM)은 전처기리(Pre-processor)로부터 전달받은 결과에 기반하여 사용자 외형 감정 특징을 추 출하는 모델이다. 감정 모델(EM)은 멀티 태스크(Multi-task) 모델로 다양한 입력을 감정 특징으로 추출하는 역 할을 수행한다. 일 실시예로, 감정 모델(EM)은 얼굴 표정 영상, 전신 행동 영상을 입력으로 받아서 감정 특징으로 변환할 수 있 다. 또 다른 실시예로, 감정 모델(EM)은 사용자의 음성/언어 정보를 감정 특징으로 변환할 수도 있다. 얼굴 표 정/전신 행동/음성/언어 등은 조합하여 사용 가능하며 그 외 사용자의 감정을 직접적으로 나타낼 수 있는 정보 입력도 가능하다. 도 4는 감정 모델(EM) 학습 실시예를 나타낸다. 도 4를 참조하면, 감정 모델에 대하여 표정 영상과 전신 행동 영상을 학습시킬 때에는 결과 도출을 위한 Fully- connected(FC) Layer를 붙이고, 입력 영상과 감정 어노테이션 쌍(pair) 기반으로 학습할 수 있으며, 학습 이후 에는 FC를 제거하고 활용할 수 있다. 다른 모달리티(음성, 언어)를 활용할 때에도 같은 방법으로 감정 모델(E M)을 학습할 수 있다. 감정 모델(EM)은 별도의 학습 없이 다양한 입력 모달리티로부터 감정 결과를 학습한 특징 추출기를 그대로 사용할 수도 있다. 비전 모델(VM) 은 실시간 촬영된 한 프레임을 전달받아서 영상 전체의 특징을 추출하기 위한 역할을 수행한다. 즉, 비전 모델(VM)은 공간 정보와 영상 내부에서의 사용자와 타인과의 관계, 상황 등을 나타내는 공간 맥락 특 징을 추출하기 위한 역할을 수행한다. 언어 모델(LM)은 영상 특징을 텍스트로 표현하는 역할을 수행하며, 비전 모델(VM)로부터 입력 받은 영상 특징을 활용하여 영상을 텍스트로 묘사하는 역할을 한다. 도 5는 비전 모델(VM) 및 언어 모델(LM)의 학습 실시예를 나타낸다. 도 5를 참조하면, 비전 모델(VM)과 언어 모델(LM)은 도 5와 같이 이미지 캡셔닝(image captioning)과 같은 태스 크에 기반하여 학습할 수 있다. 학습된 비전 모델(VM)로부터 영상내에서의 맥락 정보를 나타내는 특징을 추출하 고, 언어 모델(LM)을 통해 영상을 묘사한 텍스트를 추출할 수 있다. 비전 모델(VM)과 언어 모델(LM)은 사전 학 습된 이미지 캡셔닝 모델을 활용할 수 있다. 단기 기억 메모리(Short-term Memory, STM)는 비전 모델(VM)로부터 추출된 맥락 특징(context feature, 도 5의 image feature)와 감정 모델(EM)의 감정 특징(emotion feature)가 저장된다. 단기 기억 메모리(STM)은 사용자 파라메터에 따라 단기 기억할 기간(프레임 수, len)과 너무 많은 중복 정보 방지를 위한 스킵 기간(skip_len)을 지정할 수 있다. 즉, 현재 프레임=i, skip_len=1, len=4 일 때에는, 단기 기억 메모리(STM)에 i-3, i-2, i-1, i 번째 프레임의 맥락 특징(context feature)과 감정 특징(emotion feature)이 저장된다. 단기 기억 메모리 (STM)은 휘발성 메모리인 RAM 등에 데이터를 저장한다. 즉, 프로그램이 동작하고 있을 때 사용자 파라메터 (skip_len, len 등)에 기반하여 프레임별 감정 특징을 저장하고, 종료시에는 초기화된다. 장기 기억 메모리(Long-term Memory, LTM)는 단기 기억 메모리(STM)와 다르게 비휘발성 스토리지(HDD 등)에 비 전 모델-언어 모델(VM-LM)로부터 추출된 감정 묘사 텍스트들을 저장한다. 장기적으로 맥락 특징(context feature)을 일/월/연 단위로 저장하기 위해서는 프로그램이 동작할 컴퓨터의 저장 공간 크기를 고려해야만 한다. 영상에 나타난 맥락 정보를 적절히 표현하고, 저장 공간의 크기를 효율화하기 위해, 영상의 맥락 묘사 (description)한 문장을 프레임별로 문장(sentence) 또는 문단(paragraph)로 저장한다. 영상을 묘사한 문장으로 저장하면 다음과 같은 장점이 있다. 텍스트로 영상을 표현하기 때문에, 일/월/연 단위의 프레임별 감정 맥락 정보를 시맨틱 요소로 표현하여 저장 공간 압축의 효과를 얻을 수 있다. 또한, 사람이 장기 기억하는 감정 맥락 정보와 유사하게 언어를 활용하기 때 문에 적절하게 장기 감정 기억을 표현 가능하다. 또한, 텍스트로 맥락 정보를 저장하기에 사용자의 감정 정보로그 확인이 용이하다. 또한, 장기 감정 기억 문장을 꺼내서 시간적 맥락 정보를 활용할 때, 언어 모델(LM)을"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "활용하여 중요한 정보들로 구성된 요약 특징(summary feature)을 추출할 수 있다. 장기 기억 메모리(LTM) 또한 단기 기억 메모리(STM)와 같이 사용자 파라메터에 따라 장기 기억할 기간(len)과 스킵 기간(skip_len) 지정을 통해 저장할 맥락 정보의 밀도와 양을 결정할 수 있다. 예를 들어, skip_len=20, len=51, 현재 프레임=i 일 경우, LTM에 i-1000, i-980, …, i-40, i-20, I 프레임의 영상 묘사 문장들이 저장 되게 된다. 시간적 맥락을 프레임별로 저장한 텍스트 정보는 감정인식을 수행될 때 장기 기억 메모리(LTM)로부"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "터 추출되게 된다. 이때 장기간의 텍스트 정보를 모두 활용하기 보다는 사람과 같이 주요 정보만을 요약한 특징"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "을 활용하게 된다. 이는 언어 모델(LM)의 문서 요약 태스크를 통해 이루어지게 된다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 9, "content": "도 6은 문서 요약 태스크를 통해 언어 모델(LM)을 학습하는 방법을 나타낸다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "언어 모델(LM)은 문서 요약 태스크를 학습한 사전 학습 모델을 활용하는 것도 가능하다. 언어 모델(LM)은 비전"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "모델(VM)로부터 입력 받은 영상 특징을 텍스트로 표현하는 태스크와 문서 요약 태스크 처리가 가능해야만 한다. 언어 모델(LM)의 한가지 실시예로는 멀티 태스크 학습을 통해, 2가지 결과 출력이 가능하도록 헤드 두 개를 갖 는 DNN을 활용할 수 있다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "장기 기억 메모리(LTM)로부터 추출된 장기 기억 텍스트 정보는 언어 모델(LM)을 통해 장기 요약 특징(long-term"}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "summary feature)으로 요약된다. 요약된 장기 요약 특징(long-term summary feature)은 단기 기억 메모리(ST M)의 단기 기억 특징(short-term feature)과 함께 최종 단계인 ER(Emotion Recognizer)에 입력되며, 입력된 특 징 기반으로 감정 인식기(ER)는 최종 감정상태를 추론한다. 도 7은 감정 인식기(ER)의 학습 실시예를 나타낸다. 도 7을 참조하면, 감정 인식기(ER)를 학습시키기 위해 다른 모든 모델들을 freeze(학습되지 않도록 잠근 상태) 하고, 장/단기 기억 메모리(LTM/STM)의 사용자 파라메터를 고정하고 학습을 수행할 수 있다. 또한, 학습을 하기 위한 실시예로는, 감정 인식기(ER)를 제외한 다른 모델들을 미리 학습시켜 두고, 사용자가 파라메터를 설정한 후, 프로그램을 학습 모드로 일정 기간동안 구동시키면서 데이터와 감정 어노테이션을 수집 하면서 감정 인식기(ER)을 학습시킬 수 있다. 또 다른 실시예로는, 오프라인 모드로 데이터와 감정 어노테이션 을 모두 수집한 후에 한꺼번에 학습시킬 수도 있다. 이상에서 서술된 전처리기(Pre-processor), 비전 모델(VM), 언어 모델(LM), 감정 모델(EM), 감정 인식기(ER)는 DNN을 통해 학습하여 사용할 수 있으나, 다른 학습 가능한 형태의 알고리즘도 활용할 수 있다. 장기 기억 메모 리(LTM)는 프로그램 종료 이후에도 데이터 저장이 가능한 비휘발성 스토리지를 사용할 수 있다. 단기 기억 메모 리(STM)는 RAM과 같은 휘발성 스토리지를 활용해도 되지만 비휘발성 스토리지로도 사용 가능하다. 이때에는 단 기 기억 메모리(STM)의 로그 기록도 프로그램 종료 후에도 확인 가능하다. 도 8은 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 장치를 나타낸 블록도이다. 도 8을 참조하면, 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 장치는 입력 영상으로부터 감정 인식 대상에 상응하는 정보를 검출하는 대상 검출부, 상기 감정 인식 대상에 상응하는 정보에 기반하여 인식 대 상 특징을 추출하는 대상 특징 추출부, 상기 입력 영상에 기반하여 맥락 특징을 추출하는 맥락 특징 추출 부, 상기 인식 대상 특징 및 상기 맥락 특징을 저장하는 단기 기억 저장부 및 상기 맥락 특징을 저장 하는 장기 기억 저장부를 포함한다. 이때, 상기 장기 기억 저장부는 상기 맥락 특징에 기반하여 생성된 맥락 텍스트 정보를 저장할 수 있다. 이때, 상기 장치는 상기 단기 기억 저장부 및 상기 장기 기억 저장부에 저장된 정보에 기반하여 상기 감정 인식 대상의 감정을 인식하는 감정 인식부를 더 포함할 수 있다."}
{"patent_id": "10-2023-0117894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "이때, 상기 감정 인식부는 상기 장기 기억 저장부에 저장된 상기 맥락 텍스트 정보를 입력으로 생성된 요약 맥 락 정보를 이용하여 감정을 인식할 수 있다. 이때, 상기 맥락 텍스트 정보는 기학습된 언어 모델(Language Model)에 상기 맥락 특징을 입력하여 생성될 수 있다. 이때, 상기 감정 인식 대상에 상응하는 정보는 감정 인식 대상의 얼굴 영역, 감정 인식 대상의 전신 영역 및 감 전 인식 대상의 음성을 포함할 수 있다. 이때, 상기 단기 기억 저장부는 상기 입력 영상의 전체 프레임에 대하여 제1 빈도로 상기 인식 대상 특징 및 상기 맥락 특징을 저장할 수 있다. 이때, 상기 장기 기억 저장부는 상기 입력 영상의 전체 프레임에 대하여 상기 제1 빈도보다 낮은 제2 빈도 로 상기 맥락 텍스트 정보를 저장할 수 있다. 도 9는 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다. 실시예에 따른 맥락 정보 기반 감정 인식 장치는 컴퓨터로 읽을 수 있는 기록매체와 같은 컴퓨터 시스템 에서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들 을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “ 필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요 소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다 고 할 것이다."}
{"patent_id": "10-2023-0117894", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 방법을 나타낸 흐름도이다. 도 2는 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 시스템의 구성도이다. 도 3은 전처리기(Pre-processor) 구성의 일 예이다. 도 4는 감정 모델(EM) 학습 실시예를 나타낸다. 도 5는 비전 모델(VM) 및 언어 모델(LM)의 학습 실시예를 나타낸다."}
{"patent_id": "10-2023-0117894", "section": "도면", "subsection": "도면설명", "item": 2, "content": "도 6은 문서 요약 태스크를 통해 언어 모델(LM)을 학습하는 방법을 나타낸다. 도 7은 감정 인식기(ER)의 학습 실시예를 나타낸다. 도 8은 본 발명의 일 실시예에 따른 맥락 정보 기반 감정 인식 장치를 나타낸 블록도이다. 도 9는 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다."}
