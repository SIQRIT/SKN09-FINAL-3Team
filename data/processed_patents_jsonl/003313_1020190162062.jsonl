{"patent_id": "10-2019-0162062", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0071664", "출원번호": "10-2019-0162062", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "신기훈"}}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다른 복수의 소리 성분을 획득하고,사용자 방향 지정에 기초하여 상기 획득된 복수의 소리 성분 중 노이즈 방향의 소리 성분을 식별하고,상기 식별된 노이즈 방향의 소리 성분에 기초하여 상기 수신된 소리에 관한 사용자 음성 인식을 수행하는프로세서를 포함하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 획득된 복수의 소리 성분에서 상기 식별된 노이즈 방향의 소리 성분을 제거하고,상기 노이즈 방향의 소리 성분이 제거된 소리 성분에 기초하여 상기 사용자 음성 인식을 수행하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 사용자 방향 지정은 상기 노이즈 방향의 지정을 포함하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 사용자 방향 지정을 위한 사용자 입력을 수신하는 사용자 입력부를 더 포함하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 사용자 입력은 버튼 입력, 터치 입력 또는 제스처 입력 중 적어도 어느 하나를 포함하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 사용자 입력부는, 상기 사용자 입력의 수신 영역을 가지며,상기 마이크로폰은, 상기 수신 영역에 대하여 서로 다른 방향으로 배치되는 복수의 서브 마이크를 포함하고,상기 프로세서는, 상기 복수의 서브 마이크 중 상기 수신 영역에 수신되는 상기 사용자 입력의 위치에 대응하는서브 마이크의 방향에 기초하여 상기 노이즈 방향의 소리 성분을 식별하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,디스플레이를 더 포함하고,상기 프로세서는,상기 사용자 방향 지정을 위한 GUI를 상기 디스플레이에 표시하고,공개특허 10-2021-0071664-3-상기 GUI를 이용한 상기 사용자 입력에 기초하여 상기 노이즈 방향의 소리 성분을 식별하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,인터페이스부를 더 포함하고,상기 프로세서는,상기 인터페이스부를 통하여 외부장치로부터 상기 사용자 방향 지정에 관한 정보를 수신하고,상기 수신된 정보에 기초하여 상기 노이즈 방향의 소리 성분을 식별하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 소리 성분 중 상기 노이즈 방향의 소리 성분을 제외한 소리 성분 중 기 정의된 길이의 소리 성분을사용자 음성 성분으로 인식하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서상기 프로세서는, 상기 기 정의된 길이의 소리 성분 중 제1소리 성분보다 길이가 짧은 제2소리 성분을 상기 사용자 음성 성분으로 인식하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 프로세서는, 상기 마이크로폰의 위치 이동을 식별하고, 상기 마이크로폰의 위치 이동에 기초하여 상기 노이즈 방향의 소리 성분을 식별하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 프로세서는, 상기 마이크로폰의 위치 이동을 식별하고, 상기 사용자 방향 지정을 재입력하도록 사용자에게 안내하는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 프로세서는, 상기 마이크로폰을 통해 수신한 소리의 신호로부터 소리 성분을 획득하고,상기 사용자 방향 지정에 기초하여 상기 획득된 소리 성분이 사용자 음성 성분 또는 상기 노이즈 방향의 소리성분 중 어느 하나임을 식별하고,상기 식별된 사용자 음성 성분에 대하여 상기 사용자 음성 인식을 수행하고,상기 식별된 노이즈 방향의 소리 성분에 대하여 상기 사용자 음성 인식을 수행하지 않는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2021-0071664-4-제13항에 있어서,상기 사용자 음성 인식에 관한 처리 동작을 수행하는 음성 인식부를 더 포함하고,상기 프로세서는,상기 사용자 음성 성분은 상기 음성 인식부로 전송하고,상기 노이즈 방향의 소리 성분은 상기 음성 인식부로 전송하지 않는 전자장치."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자장치의 제어방법에 있어서,마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다른 복수의 소리 성분을 획득하는 단계;사용자 방향 지정에 기초하여 상기 획득된 복수의 소리 성분 중 노이즈 방향의 소리 성분을 식별하는 단계; 및상기 식별된 노이즈 방향의 소리 성분에 기초하여 상기 수신된 소리에 관한 사용자 음성 인식을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 사용자 음성 인식을 수행하는 단계는,상기 획득된 복수의 소리 성분에서 상기 식별된 노이즈 방향의 소리 성분을 제거하는 단계; 및상기 노이즈 방향의 소리 성분이 제거된 소리 성분에 기초하여 상기 사용자 음성 인식을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 사용자 방향 지정은 상기 노이즈 방향의 지정을 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,상기 노이즈 방향의 소리 성분을 식별하는 단계는, 서로 다른 방향으로 배치되는 복수의 서브 마이크 중 사용자입력의 수신 영역에 수신되는 상기 사용자 입력의 위치에 대응하는 서브 마이크의 방향에 기초하여, 상기 노이즈 방향의 소리 성분을 식별하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서,상기 마이크로폰을 통해 수신한 소리의 신호로부터 소리 성분을 획득하는 단계;상기 사용자 방향 지정에 기초하여 상기 획득된 소리 성분이 사용자 음성 성분 또는 상기 노이즈 방향의 소리성분 중 어느 하나임을 식별하는 단계; 및상기 식별된 사용자 음성 성분이 사용자 음성 성분인 경우에만 상기 사용자 음성 인식을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0162062", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된기록매체에 있어서, 상기 전자장치의 제어방법은, 마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다른 복수의 소리 성분을 획득하는 단계;공개특허 10-2021-0071664-5-사용자 방향 지정에 기초하여 상기 획득된 복수의 소리 성분 중 노이즈 방향의 소리 성분을 식별하는 단계; 및상기 식별된 노이즈 방향의 소리 성분에 기초하여 상기 수신된 소리에 관한 사용자 음성 인식을 수행하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된 기록매체."}
{"patent_id": "10-2019-0162062", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 전자장치에 있어서, 마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다른 복수의 소리 성분을 획득하고, 사용자 방향 지정에 기초하여 상기 획득된 복수의 소리 성분 중 노이즈 방향의 소 리 성분을 식별하고, 상기 식별된 노이즈 방향의 소리 성분에 기초하여 상기 수신된 소리에 관한 사용자 음성 인 식을 수행하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2019-0162062", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성인식기능을 수행하는 전자장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2019-0162062", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 전자장치의 음성 인식기능 사용 빈도수가 높아짐에 따라, 사용자 음성이 주변 환경에 존재하는 생활소음 등 여러 소리가 함께 입력된 경우, 입력된 소리 중에서 음성 인식 대상인 사용자 음성을 효과적으로 분리하는 기술이 요구되고 있다. 이 때, 사용자가 소음이 섞인 환경에서 발화하는 경우, 음성 인식 가능한 전자장치는 사 용자의 음성을 추출하기 위해 빔포밍(Beamforming) 기술을 이용한다. 빔포밍은 특정한 방향으로부터의 오디오 신호를 추출하고 나머지 방향으로부터의 오디오 성분을 제거하여, 공간 필터를 만드는 방식으로 작동한다. 복수 의 마이크로 구성된 마이크 어레이 시스템으로부터 복수의 음원의 방향을 자동으로 추적하고 이를 기반으로 GSS(Geometric Source Separation)와 같은 방향 기반 음원 분리 기술을 적용하여 시끄러운 주변 소음으로부터 특정 소리를 분리한다."}
{"patent_id": "10-2019-0162062", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 전자장치의 음성인식기능을 이용할 때, 획득한 소리에서 사용자 음성 인식의 정확도를 높일 수 있는 전자장치 및 그 제어방법을 제공하는 것이다."}
{"patent_id": "10-2019-0162062", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 전자장치에 있어서, 마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다 른 복수의 소리 성분을 획득하고, 사용자 방향 지정에 기초하여 상기 획득된 복수의 소리 성분 중 노이즈 방향 의 소리 성분을 식별하고, 상기 식별된 노이즈 방향의 소리 성분에 기초하여 상기 수신된 소리에 관한 사용자 음성 인식을 수행하는 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 획득된 복수의 소리 성분에서 상기 식별된 노이즈 방향의 소리 성분을 제거하고, 상기 노이즈 방향의 소리 성분이 제거된 소리 성분에 기초하여 상기 사용자 음성 인식을 수행할 수 있다. 상기 사용자 방향 지정은 상기 노이즈 방향의 지정을 포함할 수 있다. 본 발명의 일 실시예에 따른 전자장치는 상기 사용자 방향 지정을 위한 사용자 입력을 수신하는 사용자 입력부 를 더 포함할 수 있다. 상기 사용자 입력은 버튼 입력, 터치 입력 또는 제스처 입력 중 적어도 어느 하나를 포함할 수 있다. 상기 사용자 입력부는, 상기 사용자 입력의 수신 영역을 가질 수 있으며, 상기 마이크로폰은, 상기 수신 영역에 대하여 서로 다른 방향으로 배치되는 복수의 서브 마이크를 포함할 수 있고, 상기 프로세서는, 상기 복수의 서 브 마이크 중 상기 수신 영역에 수신되는 상기 사용자 입력의 위치에 대응하는 서브 마이크의 방향에 기초하여 상기 노이즈 방향의 소리 성분을 식별할 수 있다. 본 발명의 일 실시예에 따른 전자장치는 디스플레이를 더 포함할 수 있고, 상기 프로세서는, 상기 사용자 방향 지정을 위한 GUI를 상기 디스플레이에 표시하고, 상기 GUI를 이용한 상기 사용자 입력에 기초하여 상기 노이즈 방향의 소리 성분을 식별할 수 있다. 본 발명의 일 실시예에 따른 전자장치는 인터페이스부를 더 포함할 수 있고, 상기 프로세서는, 상기 인터페이스 부를 통하여 외부장치로부터 상기 사용자 방향 지정에 관한 정보를 수신하고, 상기 수신된 정보에 기초하여 상 기 노이즈 방향의 소리 성분을 식별할 수 있다.상기 프로세서는, 상기 복수의 소리 성분 중 상기 노이즈 방향의 소리 성분을 제외한 소리 성분 중 기 정의된 길이의 소리 성분을 사용자 음성 성분으로 인식할 수 있다. 상기 프로세서는, 상기 기 정의된 길이의 소리 성분 중 제1소리 성분보다 길이가 짧은 제2소리 성분을 상기 사 용자 음성 성분으로 인식할 수 있다. 상기 프로세서는, 상기 마이크로폰의 위치 이동을 식별하고, 상기 마이크로폰의 위치 이동에 기초하여 상기 노 이즈 방향의 소리 성분을 식별할 수 있다. 상기 프로세서는, 상기 마이크로폰의 위치 이동을 식별하고, 상기 사용자 방향 지정을 재입력하도록 사용자에게 안내할 수 있다. 상기 프로세서는, 상기 마이크로폰을 통해 수신한 소리의 신호로부터 소리 성분을 획득하고, 상기 사용자 방향 지정에 기초하여 상기 획득된 소리 성분이 사용자 음성 성분 또는 상기 노이즈 방향의 소리 성분 중 어느 하나 임을 식별하고, 상기 식별된 사용자 음성 성분에 대하여 상기 사용자 음성 인식을 수행하고, 상기 식별된 노이 즈 방향의 소리 성분에 대하여 상기 사용자 음성 인식을 수행하지 않을 수 있다. 본 발명의 일 실시예에 따른 전자장치는 상기 사용자 음성 인식에 관한 처리 동작을 수행하는 음성 인식부를 더 포함할 수 있고, 상기 프로세서는, 상기 사용자 음성 성분은 상기 음성 인식부로 전송하고, 상기 노이즈 방향의 소리 성분은 상기 음성 인식부로 전송하지 않을 수 있다. 본 발명의 일 실시예에 따른 전자장치의 제어방법에 있어서, 마이크로폰을 통해 수신한 소리의 신호로부터 방향 이 서로 다른 복수의 소리 성분을 획득하는 단계; 사용자 방향 지정에 기초하여 상기 획득된 복수의 소리 성분 중 노이즈 방향의 소리 성분을 식별하는 단계; 및 상기 식별된 노이즈 방향의 소리 성분에 기초하여 상기 수신 된 소리에 관한 사용자 음성 인식을 수행하는 단계를 포함할 수 있다. 상기 사용자 음성 인식을 수행하는 단계는, 상기 획득된 복수의 소리 성분에서 상기 식별된 노이즈 방향의 소리 성분을 제거하는 단계; 및 상기 노이즈 방향의 소리 성분이 제거된 소리 성분에 기초하여 상기 사용자 음성 인 식을 수행하는 단계를 포함할 수 있다. 상기 사용자 방향 지정은 상기 노이즈 방향의 지정을 포함할 수 있다. 상기 노이즈 방향의 소리 성분을 식별하는 단계는, 서로 다른 방향으로 배치되는 복수의 서브 마이크 중 사용자 입력의 수신 영역에 수신되는 상기 사용자 입력의 위치에 대응하는 서브 마이크의 방향에 기초하여, 상기 노이 즈 방향의 소리 성분을 식별하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따른 전자장치의 제어방법은 상기 마이크로폰을 통해 수신한 소리의 신호로부터 소리 성 분을 획득하는 단계; 상기 사용자 방향 지정에 기초하여 상기 획득된 소리 성분이 사용자 음성 성분 또는 상기 노이즈 방향의 소리 성분 중 어느 하나임을 식별하는 단계; 및 상기 식별된 사용자 음성 성분이 사용자 음성 성 분인 경우에만 상기 사용자 음성 인식을 수행하는 단계를 포함할 수 있다. 컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된 기록매체에 있어서, 상기 전자장치의 제어방법은, 마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다 른 복수의 소리 성분을 획득하는 단계; 사용자 방향 지정에 기초하여 상기 획득된 복수의 소리 성분 중 노이즈 방향의 소리 성분을 식별하는 단계; 및 상기 식별된 노이즈 방향의 소리 성분에 기초하여 상기 수신된 소리에 관한 사용자 음성 인식을 수행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0162062", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 서로 다른 방향으로부터 발생하는 소리를 수신한 경우, 특정 소리의 성분을 효과적으로 분리 또는 추 출할 수 있어, 음성 인식의 정확도를 높일 수 있다."}
{"patent_id": "10-2019-0162062", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 발명의 실시예들을 상세히 설명한다. 도면에서 동일한 참조번호 또는 부호 는 실질적으로 동일한 기능을 수행하는 구성요소를 지칭하며, 도면에서 각 구성요소의 크기는 설명의 명료성과 편의를 위해 과장되어 있을 수 있다. 다만, 본 발명의 기술적 사상과 그 핵심 구성 및 작용이 이하의 실시예에 설명된 구성 또는 작용으로만 한정되지는 않는다. 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명 을 생략하기로 한다. 본 발명의 실시예에서, 제1, 제2 등과 같이 서수를 포함하는 용어는 하나의 구성요소를 다른 구성요소로부터 구 별하는 목적으로만 사용되며, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 본 발명의 실시예에서, '구성되다', '포함하다', '가지다' 등의 용어는 하나 또는 그 이상의 다른 특징들 이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않 는 것으로 이해되어야 한다. 또한, 본 발명의 실시예에서, '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있으며, 적어 도 하나의 모듈로 일체화되어 구현될 수 있다. 또한, 본 발명의 실시예에서, 복수의 요소 중 적어도 하나(at least one)는, 복수의 요소 전부뿐만 아니라, 복수의 요소 중 나머지를 배제한 각 하나 혹은 이들의 조합 모두 를 지칭한다. 도 1은 본 발명의 일 실시예에 의한 전체 시스템을 도시한 도면이다. 도 1에 도시된 바와 같이, 전자장치 는 영상을 표시할 수 있는 디스플레이장치로 구현될 수 있다. 일 예로, 전자장치는 TV, 컴퓨터, 스마트 폰, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디바이스, 비디오 월, 전자액자 등을 포함할 수 있다. 또한, 전 자장치는 디스플레이를 구비하지 않는 AI어시스턴스기기(AI스피커 등), 블루투스 스피커, 셋탑박스 등의 영상처리장치, 냉장고, 세탁기 등의 생활가전, 컴퓨터본체와 같은 정보처리장치 등 다양한 종류의 장치로 구현 될 수 있다. 본 발명의 일 실시예에 따르면, 도 1에 도시된 바와 같이 사용공간에 전자장치와 사용자, 스피커 , 다수의 사람들이 존재한다고 가정한다. 사용자가 전자장치의 음성 인식 기능을 사용하는 경우, 전자장치가 수신한 소리에는 사용자의 음성과 스피커에서 나오는 소리 및/또는 다수의 사 람들의 소리가 섞여 있을 수 있다. 전자장치는 수신한 소리를 처리할 때, 어느 소리의 신호가 사용자 의 발화에 의한 신호인지 구별하기 어렵게 된다. 따라서 본 발명에서 사용자는 전자장치가 스피커 나 다수의 사람들로부터 나오는 소리를 노이즈로 인식하도록 이들의 방향을 지정하고, 전자장치(10 0)는 입력된 소리 신호 중 노이즈로 지정된 방향으로부터 오는 신호를 제거하여 인식한다. 따라서, 사용자가 스피커와 다수의 사람들이 있는 방향을 노이즈의 방향으로 지정하고 전자장치 의 음성 인식 기능을 사용하기 위해 발화한 경우, 스피커나 다수의 사람들로부터 나오는 소리 신호를 제거할 수 있으므로, 전자장치는 사용자의 발화 음성만을 인식하여 보다 정확한 음성 인식이 가능하다. 다만, 경우에 따라 사용자는 전자장치가 노이즈의 방향이 아닌 자신의 발화 방향을 인식하 도록 자신이 발화하는 방향을 지정할 수 있으며 어느 하나에 한정된 것은 아니다. 이하에서는 설명의 편의를 위 해, 사용자가 지정한 방향은 노이즈의 방향으로 한다. 도 2는 본 발명의 일 실시예에 의한 전자장치의 구성을 도시한 블록도이다. 도 2에 도시된 바와 같이, 전자장치는 인터페이스부를 포함할 수 있다. 인터페이스부는 유선 인 터페이스부를 포함할 수 있다. 유선 인터페이스부는 지상파/위성방송 등 방송규격에 따른 방송신호를 수신할 수 있는 안테나가 연결되거나, 케이블 방송 규격에 따른 방송신호를 수신할 수 있는 케이블이 연결될 수 있는 커넥터 또는 포트를 포함한다. 다른 예로서, 전자장치는 방송신호를 수신할 수 있는 안테나를 내장할 수도 있다. 유선 인터페이스부는 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, 컴포지트(composite) 비 디오, 컴포넌트(component) 비디오, 슈퍼 비디오(super video), SCART 등과 같이, 비디오 및/또는 오디오 전송 규격에 따른 커넥터 또는 포트 등을 포함할 수 있다. 유선 인터페이스부는 USB 포트 등과 같은 범용 데이 터 전송규격에 따른 커넥터 또는 포트 등을 포함할 수 있다. 유선 인터페이스부는 광 전송규격에 따라 광 게이블이 연결될 수 있는 커넥터 또는 포트 등을 포함할 수 있다. 유선 인터페이스부는 외부 마이크 또는 마이크를 구비한 외부 오디오기기가 연결되며, 오디오기기로부터 오디오 신호를 수신 또는 입력할 수 있는 커넥 터 또는 포트 등을 포함할 수 있다. 유선 인터페이스부는 헤드셋, 이어폰, 외부 스피커 등과 같은 오디오 기기가 연결되며, 오디오기기로 오디오 신호를 전송 또는 출력할 수 있는 커넥터 또는 포트 등을 포함할 수 있 다. 유선 인터페이스부는 이더넷 등과 같은 네트워크 전송규격에 따른 커넥터 또는 포트를 포함할 수 있다. 예컨대, 유선 인터페이스부는 라우터 또는 게이트웨이에 유선 접속된 랜카드 등으로 구현될 수 있다. 유선 인터페이스부는 상기 커넥터 또는 포트를 통해 셋탑박스, 광학미디어 재생장치와 같은 외부기기, 또 는 외부 디스플레이장치나, 스피커, 서버 등과 1:1 또는 1:N(N은 자연수) 방식으로 유선 접속됨으로써, 해당 외 부기기로부터 비디오/오디오 신호를 수신하거나 또는 해당 외부기기에 비디오/오디오 신호를 송신한다. 유선 인 터페이스부는, 비디오/오디오 신호를 각각 별개로 전송하는 커넥터 또는 포트를 포함할 수도 있다. 그리고, 본 실시예에 따르면 유선 인터페이스부는 전자장치에 내장되나, 동글(dongle) 또는 모듈 (module) 형태로 구현되어 전자장치의 커넥터에 착탈될 수도 있다. 인터페이스부는 무선 인터페이스부를 포함할 수 있다. 무선 인터페이스부는 전자장치의 구 현 형태에 대응하여 다양한 방식으로 구현될 수 있다. 예를 들면, 무선 인터페이스부는 통신방식으로 RF(radio frequency), 지그비(Zigbee), 블루투스(bluetooth), 와이파이(Wi-Fi), UWB(Ultra WideBand) 및 NFC(Near Field Communication) 등 무선통신을 사용할 수 있다. 무선 인터페이스부는 와이파이(Wi-Fi) 방 식에 따라서 AP와 무선통신을 수행하는 무선통신모듈이나, 블루투스 등과 같은 1대 1 다이렉트 무선통신을 수행 하는 무선통신모듈 등으로 구현될 수 있다. 무선 인터페이스부는 네트워크 상의 서버와 무선 통신함으로써, 서버와의 사이에 데이터 패킷을 송수신할 수 있다. 무선 인터페이스부는 적외선 통신규격에 따라 IR(Infrared) 신호를 송신 및/또는 수신할 수 있는 IR송신부 및/또는 IR수신부를 포함할 수 있다. 무선 인 터페이스부는 IR송신부 및/또는 IR수신부를 통해 리모컨 또는 다른 외부기기로부터 리모컨신호를 수신 또 는 입력하거나, 다른 외부기기로 리모컨신호를 전송 또는 출력할 수 있다. 다른 예로서, 전자장치는 와이 파이(Wi-Fi), 블루투스(bluetooth) 등 다른 방식의 무선 인터페이스부를 통해 리모컨 또는 다른 외부기기 와 리모컨신호를 송수신할 수 있다. 전자장치는 인터페이스부를 통해 수신하는 비디오/오디오신호가 방송신호인 경우, 수신된 방송신호를 채널 별로 튜닝하는 튜너(tuner)를 더 포함할 수 있다. 전자장치는 디스플레이부를 포함할 수 있다. 디스플레이부는 화면 상에 영상을 표시할 수 있는 디스플레이 패널을 포함한다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구 조로 마련된다. 디스플레이부는 디스플레이 패널의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는 데, 예를 들면 디스플레이 패널이 액정 방식이라면, 디스플레이부는 액정 디스플레이 패널과, 광을 공급하 는 백라이트유닛과, 액정 디스플레이 패널의 액정을 구동시키는 패널구동기판을 포함한다. 전자장치는 사용자입력부를 포함할 수 있다. 사용자입력부는 사용자의 입력을 수행하기 위해 마 련된 다양한 종류의 입력 인터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치의 종류에 따라 서 여러 가지 형태의 구성이 가능하며, 예컨대, 전자장치의 기계적 또는 전자적 버튼부, 전자장치와 분리된 리모트 컨트롤러, 전자장치와 연결된 외부기기에서의 입력부, 터치패드, 디스플레이부에 설치 된 터치스크린 등이 있다. 전자장치는 저장부를 포함할 수 있다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터가 로딩되며 전원이 제공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리 (memory)를 포함한다. 스토리지에는 플래시메모리(flash-memory), HDD(hard-disc drive), SSD(solid-statedrive) ROM(Read Only Memory) 등이 있으며, 메모리에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 전자장치는 마이크로폰을 포함할 수 있다. 마이크로폰은 사용자 음성을 비롯한 외부 환경의 소 리를 수집한다. 마이크로폰은 수집된 소리의 신호를 프로세서에 전달한다. 전자장치는 사용자 음성을 수집하는 마이크로폰을 구비하거나, 또는 인터페이스부를 통해 마이크로폰을 가진 리모트 컨 트롤러, 스마트폰 등의 외부장치로부터 음성신호를 수신할 수 있다. 외부장치에 리모트 컨트롤러 어플리케이션 을 설치하여 전자장치를 제어하거나 음성 인식 등의 기능을 수행할 수도 있다. 이와 같은 어플리케이션이 설치된 외부장치의 경우, 사용자 음성을 수신할 수 있으며, 외부장치는 전자장치와 Wi-Fi/BT 또는 적외선 등을 이용하여 데이터 송수신 및 제어가 가능한 바, 상기 통신 방식을 구현할 수 있는 복수의 인터페이스부 가 전자장치 내에 존재할 수 있다. 전자장치는 스피커를 포함할 수 있다. 스피커는 프로세서에 의해 처리되는 오디오 데이터 를 소리로 출력한다. 스피커는 어느 한 오디오 채널의 오디오 데이터에 대응하게 마련된 단위 스피커를 포 함하며, 복수 오디오 채널의 오디오 데이터에 각기 대응하도록 복수의 단위 스피커를 포함할 수 있다. 다른 실 시예로서, 스피커는 전자장치와 분리되어 마련될 수 있으며, 이 경우 전자장치는 오디오 데이터 를 인터페이스부를 통하여 스피커로 전달할 수 있다. 전자장치는 프로세서를 포함할 수 있다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버 퍼, 회로 등으로 구현되는 하나 이상의 하드웨어 프로세서를 포함하며, 설계 방식에 따라서는 SOC(system on chip)로 구현될 수도 있다. 프로세서는 전자장치가 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일러, 오디오 DSP(Digital Signal Processor), 앰프 등의 다양한 프로세스에 대응하는 모듈들을 포 함한다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현될 수 있다. 예를 들면, 디멀티플렉서, 디코더, 스케일러 등 영상처리와 관련된 모듈이 영상처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되 는 것이 가능하다. 프로세서는 마이크로폰 등에 의해 사용자 음성에 대한 음성신호를 획득하면, 음성신호를 음성데이터 로 변환할 수 있다. 이 때, 음성데이터는 음성신호를 텍스트 데이터로 변환하는 STT(Speech-to-Text) 처리 과정 을 통해 얻어진 텍스트 데이터일 수 있다. 프로세서는 음성데이터가 나타내는 커맨드를 식별하고, 식별된 커맨드에 따라서 동작을 수행한다. 음성데이터 처리 과정과, 커맨드 식별 및 수행 과정은, 전자장치에서 모두 실행될 수도 있다. 그러나, 이 경우에 전자장치에 필요한 시스템 부하 및 소요 저장용량이 상대적으 로 커지게 되므로, 적어도 일부의 과정은 네트워크를 통해 전자장치와 통신 가능하게 접속되는 적어도 하 나의 서버에 의해 수행될 수 있다. 본 발명에 따른 프로세서는 전자장치와 같은 기기(Machine)가 읽을 수 있는 저장 매체(Storage Medium)에 저장된 소프트웨어의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 전자장치와 같은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영 되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(Non-transitory) 저장매체 의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장매체가 실재(tangible)하는 장치이고, 신호(예컨대, 전 자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우 와 임시적으로 저장되는 경우를 구분하지 않는다. 한편, 프로세서는 마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다른 복수의 소리 성분 을 획득하고, 사용자가 지정한 노이즈 방향의 소리 성분에 기초하여 수신된 소리에 관한 사용자 음성 인식 을 수행하기 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능 (Artificial Intelligence) 알고리즘으로서 기계학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리 즘 중 적어도 하나를 이용하여 수행할 수 있다. 일 예로, 프로세서는 학습부 및 인식부의 기능을 함께 수행할 수 있다. 학습부는 학습된 신경망 네트워크 를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식(또는, 추론, 예측, 추정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다. 학습부는 신 경망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 일 예로, 학습부는 학습 데이터를 저장부 또는 외부로부터 획득할 수 있다. 학습 데이터는, 신경망 네트워크의 학습을 위해 이용되는 데이터일 수 있으며, 상기한 동작을 수행한 데이터를 학습데이터로 이용하여 신경망 네트워크를 학습시킬 수 있다.학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 일 예로, 학 습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적 절한 데이터의 형태로 가공할 수 있다. 학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설정된 신경망 네트워크를 생성할 수 있다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들로 구성될 수 있다. 복수의 신경망 네트워 크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네 트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네 트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득할 수 있다. 타겟 데이터는 저장부 또는 외부로부터 획득된 것일 수 있다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식 부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수 행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별할 수 있다. 일 예로, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하여 인식에 적절한 데 이터의 형태로 가공할 수 있다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네 트워크로부터 출력되는 출력값을 획득할 수 있다. 인식부는 출력값과 함께, 확률값 또는 신뢰도값을 획득할 수 있다. 일 예로, 본 발명에 따른 전자장치의 제어방법은 컴퓨터 프로그램 제품 (Computer Program Product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은, 앞서 설명한, 프로세서에 의해 실행되는 소프트웨어의 명령어들을 포함할 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨 터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예컨대, CD-ROM)의 형태로 배포되거나, 또는 어플리케이션 스토어(예컨대, 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예컨대, 스마트폰들) 간에 직접, 온라인 으로 배포(예컨대, 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저 장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 본 실시예에서는 전자장치 는 사용자의 발화를 보다 정확하게 인식하기 위해, 전자장치가 수신한 소리에서 스피커나 다수의 사람들로부터 발생하는 소리를 식별하여, 사용자 음성 인식을 수행하는 흐름도를 도시한다. 프로세서는 마이크로폰을 통해 수신한 소리의 신호로부터 방향이 서로 다른 복수의 소리 성분을 획득한다 (S310). 이 때, 마이크로폰은 전자장치에 내장된 마이크로폰일 수 있고, 전자장치와 연결된 외 부 마이크로폰일 수 있다. 프로세서은 마이크로폰을 통해 수신한 소리의 신호를 GSS(Geometric Source Separation) 등 음원 분리 기술을 이용하여 복수의 소리 성분으로 분리할 수 있다. GSS란 공간적 음원 분리 기 술로 음원 분리 기술 중 마이크로폰 배열을 이용하여 얻을 수 있는 공간적 정보를 이용하여 음원 신호를 분리해 내는 기술을 말한다. 사용자는 전자장치가 음원 분리 기술을 이용하여 획득한 방향이 서로 다른 복수의 소 리 성분 중 노이즈 방향의 성분을 식별할 수 있도록 스피커와 다수의 사람들의 방향을 지정할 수 있 다. 이 때, 사용자가 방향을 지정하는 시점은 어느 하나에 한정되지 않는다. 예컨대, 사용자는 전자장치의 음성 인식에 관한 초기 설정 시 주변에 설치된 외부기기의 방향을 노이즈로 지정할 수 있으며, 혹은 음성 인식 을 실행하기 전에 임의적으로 노이즈의 방향을 지정할 수 있다. 또한, 사용자의 집이나 회사 등 노이즈가 발생하는 전자기기의 위치가 고정되어 노이즈의 방향이 고정될 수 있는 경우, 프로세서는 사용자가 음성 인식이 실행되는 장소와 지정한 방향을 저장부에 저장하고, 음성 인식을 수행 할 때 이를 이용할 수 있다. 그 외에도 음식점과 같은 장소에서 음성 인식을 실행하는 경우, 일시적으로 노이즈의 방향을 지정할 수 있으며, 어느 실시예에 한정되지 않는다. 프로세서는 사용자가 방향을 지정한 경우, 획득된 복수의 소리 성분 중 노이즈 방향의 소리 성분을 사용자 방향 지정에 기초하여 식별한다(S320). 본 발명의 일 실시예에 따르면, 프로세서는 사용자 방향 지 정에 기초하여 복수의 소리 성분에서 사용자가 지정한 스피커와 다수의 사람들의 방향의 소리 성분을 구분하여 식별할 수 있다. 사용자 방향 지정에 기초한 소리 성분의 구분·식별에 대한 상세한 설명은 후술한다. 그리고 프로세서는 식별된 노이즈 방향의 소리 성분에 기초하여 수신된 소리에 관한 사용자 음성 인식을 수행한다(S330). 전자장치가 복수의 소리를 동시에 획득한 경우, 주변 음원의 방향을 파악하게 되 면, 특정 소리의 성분을 효과적으로 분리 또는 추출할 수 있다. 본 발명의 일 실시예에서는, 전자장치 주변에 노이즈가 있고 사용자가 이를 사전에 알 수 있는 경우 간단하게 해당 방향을 지정하여 전자장치가 지정된 방향에 기초하여 인식하고자 하는 소리를 효과적으로 인식할 수 있다. 도 4는 본 발명의 일 실시예에 따른 전자장치의 동작 모습을 도시한 도면이다. 도 4에서는 획득된 복수의 소리 성분 중 노이즈 방향의 소리 성분을 식별하기 위한 사용자의 방향 지정 모습을 도시한다. 본 개시된 마이크로폰 의 구현 형태는 다양할 수 있으며, 독립적인 장치로 구현될 수도 있고, 어떤 장치에 일 구성으로 마련되어 도 좋다. 또한, 마이크로폰은 전자장치에 마련되거나, 혹은 전자장치의 외부에 마련될 수도 있 다. 후자의 경우, 전자장치는 인터페이스부를 통하여 마이크로폰에 수신되는 소리의 정보를 수 신할 수 있다. 도 4에 도시된 마이크로폰은 전자장치의 사용 공간에 사용자의 조작이 가능한 곳 에 위치하며, 마이크로폰의 주위에 스피커 및 다수의 사람들이 존재한다고 가정한다. 본 발명의 일 실시예에 따르면, 마이크로폰은 예컨대, 원형으로 배열되는 복수의 서브 마이크로폰과, 사용자의 방향 지정을 수신하는 터치패널을 포함한다. 도 4에 도시된 복수의 서브 마이크로폰의 배열 형태는 본 개시의 하나의 예시에 불과하며, 다각형, 직선형 등 주위의 여러 방향에서 발생될 수 있는 소리 를 수집할 수 있도록 각 서브 마이크로폰이 여러 방향을 향하여 배치되는 것과 같이, 다양한 다른 형태로 도 배열될 수 있다. 터치패널은 사용자의 터치입력을 수신할 수 있는 수신영역을 구비한다. 터치패널(42 0)의 수신영역은 복수의 서브 마이크로폰의 배열 형태에 대응되도록 마련된다. 즉, 터치패널의 수신 영역은 복수의 서브 마이크로폰이 배열된 위치를 커버하도록 마련되며, 사용자가 발생된 소리의 방향을 인 식하고, 수신영역 중에서 소리의 방향에 대응하는 부분을 터치할 수 있도록 고려되어 설계된다. 한편, 터치패널 은 사용자의 방향지정 입력을 수신하기 위한 본 개개의 하나의 입력수단에 불과하며, 복수의 서브 마이크 로폰과 대응되도록 수신영역의 복수의 위치에 배열되는 복수의 버튼 등 다양한 다른 입력수단으로도 대체 될 수 있다. 본 발명의 일 실시예에 따르면, 전자장치의 프로세서는, 마이크로폰의 터치패널을 통해 사 용자 방향지정에 해당하는 터치입력의 정보를 수신한다. 프로세서는, 수신된 터치입력의 정보에 기초하여 노이즈 방향의 소리 성분을 식별한다. 노이즈 방향의 소리 성분을 식별하기 위하여, 우선, 프로세서는, 마이크로폰에 수신된 소리 중 특정 방향의 소리 성분을 분리하여 인식한다. 구체적으로, 프로세서는 마이크로폰이, 예컨대, 다수의 사람 들로부터 발생하는 소리를 수신하는 경우, 복수의 서브 마이크로폰 각각의 위치가 서로 다른 방향을 향하도록 배치됨을 고려하여, 각 서브 마이크로폰의 위치에서 수신된 소리 신호의 특성이 다수의 사람들 이 존재하는 방향에 따라 서로 다르게 나타남을 식별할 수 있다. 이 때, 프로세서는, 적어도 두 개의 서브 마이크로폰에 입력되는 소리의 시간차를 이용하여 계산하는 도달 방향 추적 방법(DOA; Direction Of Arrival) 등 여러 가지 방법을 이용하여 소리의 방향에 관한 정보를 획득할 수 있다. 프로세서는, 각 서브 마이크로폰에서 수신한 소리를 서로 다른 방향의 소리 성분으로 분리한 것을 분석하여, 비슷한 방향에서 특정 소리 성분이 두드러지게 나타남을 식별할 수 있다. 프로세서는, 특정 소리 성분이 복수의 서브 마이 크로폰에서 비슷한 방향으로 두드러지는 경우, 특정 소리 성분이 특정 방향으로부터 발생한다는 것을 인식 할 수 있다. 한편, 사용자는 스피커 및 다수의 사람들의 방향을 인식하고, 터치패널의 수신영역 중에서 스피커 및 다수의 사람들의 방향에 대응하는 두 위치(411, 412 참조)를 터치한다. 프로세서는는, 마이크로폰을 통해 터치패널의 수신영역의 두 위치(411, 412 참조)에 관한 터치 입력의 정보를 수신한다. 프로세서는 수신된 정보와, 기 정의된 복수의 서브 마이크로폰 및 터치패널 의 수신영역 간의 위치 대응 관계에 기초하여, 복수의 서브 마이크로폰 중 터치입력이 발생한 두 위 치에 대응하는 서브 마이크로폰(411, 412)을 식별한다. 이어, 프로세서는 식별된 서브 마이크로폰(411, 412)과, 앞서 언급된 복수의 특정 방향의 소리 성분 간의 상호 위치 대비를 수행한다. 즉, 프로세서는 복 수의 특정 방향의 소리 성분 중에서 서브 마이크로폰(411, 412)의 위치에 대응하는 방향의 소리 성분을 식별한 다. 프로세서는 서브 마이크로폰(411, 412)의 위치에 대응하는 방향으로부터 발생하는 소리 성분을 노이즈 방향의 소리 성분으로 식별할 수 있다. 본 발명의 일 실시예에 따르면, 복수의 서브 마이크로폰의 배열 및 개수에 따라 더 정확하게 방향 지정을 수행 할 수 있어 사용자 편의를 증대시킬 수 있다. 도 5는 본 발명의 일 실시예에 따른 전자장치의 동작 모습을 도시한 도면이다. 본 발명의 일 실시예에서는, 도 4의 마이크로폰에 터치 패널 등 사용자 입력부가 따로 구비되지 않은 경우, 마이크로폰과 연결 되고, 사용자가 방향을 지정할 수 있는 GUI(Graphic User Interface)를 디스플레이에 표시하는 전자장치 의 모습을 도시한다. 디스플레이에 표시된 GUI는 방향지정에 관한 사용자 입력을 수신할 수 있는 수 신영역을 구비한다. 본 발명의 일 실시예에 따른 GUI는 마이크로폰의 모습과 동일한 형상으로 이루어 지고, GUI의 수신영역은 복수의 서브 마이크로폰의 배열 형태에 대응되도록 마련된다. 따라서, 사용 자는 스피커 및 다수의 사람들의 방향에 대응하는 GUI의 수신영역의 위치(521, 522)을 선 택하여 노이즈의 방향을 지정할 수 있다. 프로세서는 GUI를 통해 사용자 방향지정에 해당하는 사용자 입력의 정보를 수신할 수 있다. 사용자가 GUI를 이용하여 방향을 지정하기 위한 사용자 입력은, 예컨대, 리모컨을 이용한 포인터 지정, 버튼 입력 또는 제스처 입력 등이 있으며 어느 하나에 한정되지 않는다. GUI에 표시된 복수의 서브 마이크로폰의 위치, 방향 등은 실제 복수의 서브 마이크로폰의 위치, 방향 에 대응되므로, 프로세서는 수신된 사용자 입력의 정보에 기초하여 노이즈 방향의 소리 성분을 식별할 수 있다. 본 발명의 일 실시예에 따르면, 마이크로폰에 터치패널과 같은 사용자 입력부가 따로 구비되지 않은 경우 라도, 사용자 입력부를 구비한 전자장치와 연결되어 사용자 입력을 수신할 수 있어 사용자 이용에 편의성 을 높일 수 있다. 도 6은 본 발명의 일 실시예에 따른 전자장치의 동작 모습을 도시한 도면이다. 도 6은 도 4 및 도 5와 달리 마 이크로폰이 전자장치에 내장된 경우를 도시한다. 도 6에 도시된 본 발명의 일 실시예에 따른 전자장치 는 하부에 두 개의 마이크로폰이 내장되어 있다. 전자장치는 사용자 방향 지정을 위한 사용자 입력을 수신하는 사용자 입력부를 더 포함할 수 있다. 본 발명의 일 실시예에 따르면, 예컨대, 사용공간에 사용자, 스피커, 및 다수의 사람들이 존재 하고, 전자장치의 두 개의 마이크로폰으로부터 소리를 수신할 수 있는 방사범위와 전자장치 의 하부 가로 테두리에 터치패널이 도시되어 있다. 터치패널은 사용자의 터치입력을 수신할 수 있는 수신영역을 구비한다. 본 실시예에서 터치패널의 수신영역은 소음의 방향에 대응되도록 마련된다. 본 발명의 일 실시예에 따르면, 전자장치의 프로세서는, 전자장치의 터치패널을 통해 사용 자 방향지정에 해당하는 터치입력의 정보를 수신할 수 있다. 사용자는 소음의 방향에 대응하는 터치패널 의 부분(621, 622)을 터치하여 지정할 수 있다. 이 후, 유효한 소리, 즉 사용자의 음성을 인식하는 방법은 상술한 도 4 및 도 5의 원리와 동일하다. 사용자 입력부는 도 5의 디스플레이에 표시된 GUI나 본 도면에 따른 터치패널 이외에도 조그 다이얼 과 같은 물리적 버튼으로 구현될 수 있다. 추가로 전자장치는 인터페이스부를 더 포함할 수 있고, 프 로세서는 인터페이스부를 통하여 외부장치, 예컨대, 전자장치와 분리된 리모트 컨트롤러, 전자 장치와 연결된 외부기기에서의 입력부 등을 통해 입력된 사용자 방향 지정에 관한 정보를 수신할 수 있다. 본 발명의 일 실시예에 따르면, 사용자는 다양한 방법으로 소리의 방향을 지정할 수 있으므로 사용자 편의 를 높여줄 수 있다. 도 7은 본 발명의 일 실시예에 따른 마이크로폰의 이동에 따른 동작 모습을 도시한 도면이다. 본 발명의 일 실 시예에 따른 마이크로폰은 전자장치에 내장된 마이크로폰이라고 가정한다. 전자장치가 스마트폰 등 이동 가능한 전자장치인 경우, 도 7에 도시된 바와 같이 사용자가 지정한 노이즈의 방향 또한 전자장치의 이동에 대응하여 바뀌어야 한다. 전자장치는 센서, 예컨대, 가속도 센서와 자이로 센서 등을 추가로 포함 할 수 있고, 이들을 통해 전자장치의 이동 시 이동 방향, 이동 거리, 이동 속도 등을 식별할 수 있다. 따라서, 프로세서는, 마이크로폰의 위치 이동을 식별하고, 마이크로폰의 위치 이동에 기초하여 노이즈 방 향의 소리 성분을 식별할 수 있다. 또는 프로세서는, 마이크로폰의 위치 이동을 식별하고, 사용자 방향 지 정을 재입력하도록 사용자에게 안내할 수 있다. 이는 전자장치에 외부 마이크로폰이 연결된 경우로서 마이크로 폰이 이동 가능한 경우에도 적용이 가능하며, 어느 하나에 한정되는 것은 아니다. 본 발명의 일 실시예에 따르 면, 동일한 장소에서 노이즈는 여전히 존재하나 사용자가 위치를 이동하는 경우에도 적용될 수 있으므로 사용자 편의를 높여줄 수 있다. 도 8은 본 실시예의 전자장치가 수행하는 동작의 흐름도를 도시한 도면이다. 본 발명의 일 실시예에 따르면, 전자장치는 사용자 음성 성분을 효과적으로 추출하기 위해서 사용자가 노이즈의 방향을 지정하는 것 외에 도, 획득한 음성 성분의 길이를 고려할 수 있다. 전자장치는 음성 인식 기능을 수행하기 위한 트리거 신호로써 Wake-Up Word(WUW) 를 인식하기 위한 인식 엔진과, 호출되고 난 후에 사용자 발화를 인식하기 위한 서버 음성 인식 엔진을 구비할 수 있다. 마이크로폰을 통해 소리를 수신한 경우, WUW 인식 엔진에 각 방향으로 분리된 소리를 입력하여 WUW가 들어 있는지를 파악한다. 하지만 분리된 모든 방향의 소리를 WUW 엔진에 순차적으로 입력하거나 멀티 스레트(Multi-Thread), 즉, 복수의 처리를 병행하여 WUW 인식 엔진을 구동할 경우 필요한 연산량이 가파르게 증가한다. 따라서 WUW나 음성 명령은 짧은 경우가 대부분이므로 획득한 음성 성분의 길이를 고려하여 사용자의 음성을 인식한다. 먼저 N개의 마이크로폰이 존재한다고 가정하면, N개의 마이크로폰으로부터 소리를 수신할 수 있다(S810). 프로 세서는 수신한 N개의 소리 신호를 방향이 서로 다른 K개의 소리 성분을 획득할 수 있다(S820). 이 때, 프 로세서는 상술한 바와 같이 방향이 서로 다른 소리 성분을 획득하기 위하여 GSS와 같은 음원 분리 기술을 이용할 수 있다. 전자장치 주변에 노이즈가 존재하는 경우, 사용자는 Q개의 노이즈의 방향을 지정할 수 있다. 다만, 본 실시예의 경우 사용자가 노이즈의 방향을 지정하지 않은 경우, 즉, Q가 0인 경우도 존재하는 것으로 가정한다. 사용자가 적어도 하나 이상의 노이즈의 방향을 지정한 경우(S830의 Yes; Q>0), 획득한 K개의 소리성분 중 사용자가 지정 한 Q개의 방향으로부터 오는 소리 성분을 제거하고, 남은 M개의 소리 성분을 획득할 수 있다(즉, M=K-Q)(S840). 따라서 M>1인 경우(S850의 Yes), 즉, 획득된 소리 성분이 2개 이상인 경우, M개의 소리 중 사용자의 음성 성분 의 방향을 결정하기 위해, 프로세서는 소리 성분을 길이 순으로 정렬할 수 있는 인식 대상 음원 방향 선정 (Target Direction Identification, TDI) 알고리즘을 적용할 수 있다. 다만, 남은 M개의 소리 성분은 사용 환 경에 따라 1개 일 수 있다. 이 경우 프로세서는 TDI 알고리즘을 이용하여 길이를 비교하는 과정을 수행하 지 않을 수 있다(S850의 No). 프로세서는 소리 성분이 복수인 경우, 복수의 소리 성분 중 기 정의된 길이 (Ls)보다 긴 소리 성분을 식별하고, 식별된 성분들을 TDI 알고리즘을 통해 길이 순으로 정렬할 수 있다(S860). 여기서 기 정의된 길이(Ls)는 검출된 소리 방향의 연속성이 사람의 자연스런 발화로 구분되기 위해 충족시켜야 하는 최소 길이이다. 정렬된 소리 성분들 중에서 프로세서는 가장 짧은 소리 성분을 사용자 음성 성분으로 인식할 수 있다(S870). 본 실시예에 따르면, 사용자의 노이즈 성분의 방향 지정을 통해 효과적으로 소리를 추출하고 길이까지 고려함으 로써 더욱 효과적으로 사용자의 음성 성분을 분리해 낼 수 있다. 도 9는 본 발명의 일 실시예에 따른 소리 성분 인식 모습을 도시한 도면이다. 본 도면은 TV 소리와 같은 지속적 인 소리가 발생되고 있는 환경에서, 시간에 따른 소리의 크기 및 그 주파수를 도시한 도면이다. 위의 그래프 에서 사용자가 5초부터 짧은 음성 명령어를 발화한다고 가정해본다. 프로세서는 TDI 알고리즘을 이용 하여 주변 TV 소음과 사용자 음성을 자동으로 추적하여 길이에 따라 순위를 정렬하고 이를 GSS를 이용하여 사용 자 음성만 추출한 결과를 아래 그래프에 나타내었다. 사용자가 발화하기 전에는 TV소리만 검출되다가, 5초 부터는 길이가 짧은 음성 명령어가 검출되므로, 프로세서(270는 이를 인식 대상의 소리로 인식하여 사용자 음성 만을 분리할 수 있다. 프로세서는, 소리의 크기나 길이가 지속적인 경우에는 TDI알고리즘으로만 인식 우선 순위를 식별할 수 있다. 다른 실시예로서, 프로세서는, 예컨대, 주변에 전화 통화를 하거나 잡담을 하는 경우와 같이 지속적이지 않은 소음이 존재하면, 이러한 소음과 사용자의 음성을 분리하는 기술을 포함하는 TDI 알고리즘에 기초하여 인식을 수행할 수도 있다. 도 10은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 본 발명의 일 실시예에서는 마이크로폰으로부터 수신한 소리가 하나의 소리 성분인 경우를 설명한다. 프로세서는, 마이크로폰 을 통해 수신한 소리의 신호로부터 소리 성분을 획득한다(S1010). 이 때, 프로세서는 사용자 방향 지 정에 기초하여 획득된 소리 성분이 사용자 음성 성분 또는 노이즈 방향의 소리 성분 중 어느 하나임을 식별할 수 있다(S1020). 만약, 획득된 소리 성분이 사용자 음성 성분인 경우(S1020의 Yes), 프로세서는 사용자 음성 성 분을 음성 인식부로 전송하고, 음성 인식을 수행할 수 있다. 이 때, 프로세서는 음성 인식부를 포함할 수 있고, 경우에 따라서 별도의 음성 인식부를 구비할 수 있으며 어느 하나에 한정된 것은 아니다. 만약, 획득한 소리 성 분이 노이즈 방향의 소리 성분인 경우(S1020의 No), 노이즈 방향의 소리 성분은 음성 인식부로 전송하지 않을 수 있다. 본 발명의 일 실시예에 따르면, 획득된 소리 성분이 사용자 음성 성분이 아닌 경우, 이를 음성 인식부로 전송하 지 않음으로써 불필요한 인식과정을 제거할 수 있으므로 효율적이다.부호의 설명 100: 전자장치 210: 인터페이스부 220: 디스플레이부 230: 사용자입력부 240: 저장부 250: 마이크로폰 260: 스피커 270: 프로세서"}
{"patent_id": "10-2019-0162062", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 의한 전체 시스템을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 의한 전자장치의 구성을 도시한 블록도이다. 도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다.도 4는 본 발명의 일 실시예에 따른 전자장치의 동작 모습을 도시한 도면이다. 도 5는 본 발명의 일 실시예에 따른 전자장치의 동작 모습을 도시한 도면이다. 도 6은 본 발명의 일 실시예에 따른 전자장치의 동작 모습을 도시한 도면이다. 도 7은 본 발명의 일 실시예에 따른 마이크로폰의 이동에 따른 동작 모습을 도시한 도면이다. 도 8은 본 실시예의 전자장치가 수행하는 동작의 흐름도를 도시한 도면이다. 도 9는 본 발명의 일 실시예에 따른 소리 성분 인식 모습을 도시한 도면이다. 도 10은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다."}
