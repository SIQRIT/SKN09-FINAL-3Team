{"patent_id": "10-2022-0153326", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0071621", "출원번호": "10-2022-0153326", "발명의 명칭": "인공지능 기반의 지도 정합장치 및 이를 이용하는 방법", "출원인": "주식회사 에이치포테크", "발명자": "김정환"}}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "포인트 클라우드 및 기준 위치점을 스캔하여 수집하는 스캔로봇;상기 포인트 클라우드 및 기준 위치점을 수신하고 엣지 영상데이터를 생성하는 데이터 전처리부;상기 엣지 영상데이터를 지도에 매핑하는 지도 정합부;지도학습을 위한 학습데이터를 생성하는 학습데이터 생성부; 및딥러닝 기반의 인공지능 모델인 정합 모듈부를 포함하는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 데이터 전처리부는 상기 포인트 클라우드 및 기준 위치점 수신하여 저장하는 데이터 수집부;상기 기준 위치점을 상기 포인트 클라우드에 매핑하는 위치 지정부; 및상기 포인트 클라우드에서 엣지를 추출하여 상기 엣지 영상데이터를 생성하는 엣지 생성부로 이루어지는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 지도 정합부는 상기 기준 위치점에 대응되는 지도를 검색하는 지도 선정부;상기 엣지 영상데이터와 상기 검색된 지도를 어핀(affine) 변환을 통해 매핑하는 어핀 변환부; 및상기 엣지 영상데이터가 상기 지도에 매핑되는 지를 판정하는 정합 판정부를 포함하는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 학습데이터 생성부는 상기 엣지 영상데이터 및 매핑된 지도를 동일 크기의 격자로 각각 분할한 엣지격자영상데이터 및 지도격자 영상데이터를 생성하는 격자분할부;상기 엣지격자 영상데이터와 상기 지도격자 영상데이터를 상기정합 판정부를 이용하여 정합도를 계산하여 일정임계치 이상의 격자만을 학습데이터로 선정하는 학습데이터 분리부;상기 선정된 학습데이터로 지정된 지도에서 하나의 격자에 대해 다양하게 회전각을 변화시켜 학습데이터를 생성하는 회전영상 생성부를 포함하는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 정합 모듈부는 엣지격자 영상데이터를 입력 받아 학습하는 엣지 합성곱 계층;지도격자 영상데이터를 입력받아 학습하는 지도 합성곱 계층; 상기 엣지 합성곱 계층 및 지도 합성곱 계층으로부터 출력되는 결과를 결합하여 생성되는 갭 계층; 및상기 갭 계층을 입력으로하는 전연결층으로 구성되는 인공지능 기반의 지도 정합장치.공개특허 10-2024-0071621-3-청구항 6 제4항에 있어서,상기 격자는 32x32, 64x64 또는 128x128 중 하나인 것을 특징으로 하는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 정합 모듈부의 출력값은 상기 엣지격자 영상데이터에 기준하여 상기 지도격자 영상데이터의 회전된 회전각을 0 내지 1로 정규화한 값인 것을 특징으로 하는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 정합 모듈부의 결과에 따라 정합 여부를 판정하고 이를 보정하는 정합 보정부를 더 포함하는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서,상기 회전각은 0도 내지 360도 범위 내인 것을 특징으로 하는 인공지능 기반의 지도 정합장치."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 기재된 인공지능 기반의 지도 정합장치를 사용하여 지도를 정합하는 학습방법에 있어서,데이터 전처리부에서 스캔로봇으로부터 포인트 클라우드 및 기준 위치점을 수신하고, 수신된 포인트 클라우드로부터 엣지를 추출하여 엣지 영상데이터를 생성하는 제1 단계;지도 정합부에서 어핀 변환을 통해 상기 엣지 영상데이터의 상기 기준 위치점에 대응되는 지도를 획득하는 제2단계;학습데이터 생성부에서 상기 엣지 영상데이터를 격자 형태로 분할하여 엣지격자 영상데이터를 생성하고, 상기엣지격자 영상데이터와 동일한 위치에 동일한 크기의 지도격자를 지도로부터 추출하는 제3 단계;상기 학습데이터 생성부에서 추출된 상기 지도격자를 복수의 회전각으로 회전하여 변환한 학습용 지도격자 영상데이터를 생성하는 제4 단계; 및 정합 모듈부에서 상기 엣지격자 영상데이터 및 상기 지도격자 영상데이터를 지도 학습하는 제5 단계로 이루어지는 인공지능 기반의 지도 정합을 위한 학습방법."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제9항 중 어느 한 항에 기재된 인공지능 기반의 지도 정합장치를 사용하여 지도를 정합하는 방법에있어서,데이터 전처리부에서 스캔로봇으로부터 포인트 클라우드 및 기준 위치점을 수신하고, 수신된 상기 포인트 클라우드의 기준 위치점에서 소정 크기의 격자를 생성한 후 엣지를 추출하여 엣지격자 영상데이터를 생성하는 제1단계;상기 기준 위치점에 해당하는 지도에서 소정 크기의 격자에 해당하는 지도격자 영상데이터를 추출하는 제2단계; 및 상기 엣지격자 영상데이터와 상기 지도격자 영상데이터를 정합 모듈부에 입력하여 정합될 회전각을 출력하는 제3 단계로 이루어지는 인공지능 기반의 지도 정합 방법."}
{"patent_id": "10-2022-0153326", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2024-0071621-4-제10항 또는 제11항의 방법을 수행하는 컴퓨터 판독 가능한 저장매체에 저장된 프로그램."}
{"patent_id": "10-2022-0153326", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 실내 측위용 지도 정합 장치 및 이를 이용하는 방법에 관한 것으로, 3차원 공간을 스 캔하여 포인트 클라우드 데이터 및 기준 위치점를 생성하는 스캔로봇, 스캔된 데이터 및 기준 위치점을 수신하고 전처리하는 데이터 전처리부, 전처리된 영상데이터를 지도에 매칭하는 지도 정합부, 지도학습을 위한 학습데이터 를 생성하는 학습데이터 생성부 및 딥러닝 기반의 인공지능 모델을 포함하는 지도 정합 장치 및 이를 이용하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0153326", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 지도 정합장치 및 이를 이용하는 방법에 관한 것으로, 보다 상세하게는 딥러닝 기반 의 인공지능 모델을 통해 3차원 공간으로부터 스캔하여 획득된 포인트 클라우드를 지도학습을 통해 지도에 자동 적으로 위치를 정합하는 지도 정합 장치 및 이를 이용하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0153326", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 공간정보 서비스의 적용 대상 영역이 실외 공간에서 실내 공간으로 급속하게 확대되어 가고 있다. 이러한 변화는 IT·모바일 등 첨단기술의 발달과 함께 다양한 분야와의 융복합을 통한 연계 활용으로 향후 실내 공간정 보의 다양한 서비스 수요를 요구하는데, 특히 지하 및 지상 쇼핑센터, 문화시설, 주거 및 사무공간이 모인 초대 형 복합단지가 늘어나면서 길찾기, 매장안내 등 실내지도 서비스의 수요가 증가하고 있다. 특히, 공간정보는 단순히 위치정보의 전달 수준을 넘어 인간의 실생활에 깊이 개입되어 생활의 일부로 인식되어 가고 있으며, 공간정보 기술은 다양한 정보를 제공하는 기술을 넘어 인간 개개인의 생활방식을 바꿔주는 생활 밀착형 기술로 발전하고 있다. 실내 공간 정보의 획득을 위해 라이다를 활용한 3D 스캔 방식을 활용하여 실내 공간 모델을 구축하는데, 반드시 실내 측위를 통해 실제 지도 정보에 정합할 필요가 있다. 실내 측위 기술에는, 라이다, GPS, 관성 센서, 카메라 등을 기반으로 한 다양한 방식이 있는데, 특히, 3차원 스 캔이 가능한 라이다를 통한 포인트 클라우드를 이용하여 공간 정보를 추출하는데 있어 포인트 클라우드의 데이 터량이 방대하고, 공간이 협소한 점 및 이동물체가 존재하는 제약 요소로 인해 실제 지도에 정합하는데 매우 어 려운 문제점이 발생한다. 또한, 종래에는 포인트 클라우드와 지도와의 정합을 위해 각각 3개의 지점을 정하여 어핀(affine) 변환을 통해 정합하였으나, 기준 점을 제외한 나머지 2개의 지점의 위치가 명확하게 특정되지 않은 경우 어핀 변환이 되지 않고, 그러다 보니 일일이 수작업으로 지도를 정합하는 번거로움이 발생한다. 특허문헌 1은 3차원 스캐닝을 통해 획득한 포인트 클라우드와 영상을 이용하여 정적인 배경의 3차원 모델을 생 성하는 입체 모델 생성 장치 및 방법에 관한 것으로, 3차원의 좌표 및 매쉬 모델을 생성한 후 이를 중첩하여 정 합하는 방법을 제안하고 있으나, 3차원 영상을 사전에 생성하기 어려운 문제점과 포인트 클라우드가 정확한 3차 원 모델을 생성하기 어려워 정확하게 정합되지 않는다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-1841668호"}
{"patent_id": "10-2022-0153326", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위하여, 본 발명에서는 3차원 공간을 스캔하는 스캔로봇으로부터 포인트 클라우 드를 획득하고, 획득된 데이터를 딥러닝 기반의 인공지능 학습을 통해 자동적으로 지도를 정합하는 인공지능 기 반의 지도 정합 장치방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0153326", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명에 따른 인공지능 기반의 지도 정합 장치는, 포인트 클라우드 및 기 준 위치점을 스캔하여 수집하는 스캔로봇; 상기 포인트 클라우드 및 기준 위치점을 수신하고 엣지 영상데이 터를 생성하는 데이터 전처리부; 상기 엣지 영상데이터를 지도에 매핑하는 지도 정합부; 지도학습을 위한 학습데이터를 생성하는 학습데이터 생성부; 및 딥러닝 기반의 인공지능 모델인 정합 모듈부를 포함하는 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 데이터 전처리부는 상기 포인트 클라우드 및 기준 위치점 수신하여 저장하는 데이터 수집부; 상기 기준 위치점을 상기 포인트 클라우드에 매핑하는 위치 지정부; 및 상기 포인트 클라우드에서 엣지를 추출하여 상기 엣지 영상데이터를 생성하는 엣지 생성 부로 이루어지는 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 지도 정합부는 상기 기준 위치점에 대응 되는 지도를 검색하는 지도 선정부; 상기 엣지 영상데이터와 상기 검색된 지도를 어핀(affine) 변환을 통 해 매핑하는 어핀 변환부; 및 상기 엣지 영상데이터가 상기 지도에 매핑되는 지를 판정하는 정합 판정부 를 포함하는 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 학습데이터 생성부는 상기 엣지 영상데이 터 및 매핑된 지도를 동일 크기의 격자로 각각 분할한 엣지격자 영상데이터 및 지도격자 영상데이터를 생성하는 격자분할부; 상기 엣지격자 영상데이터와 상기 지도격자 영상데이터를 상기정합 판정부를 이용하여 정합도를 계산하여 일정 임계치 이상의 격자만을 학습데이터로 선정하는 학습데이터 분리부; 상 기 선정된 학습데이터로 지정된 지도에서 하나의 격자에 대해 다양하게 회전각을 변화시켜 학습데이터를 생성하 는 회전영상 생성부를 포함하는 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 정합 모듈부는 엣지격자 영상데이터(41 1)를 입력 받아 학습하는 엣지 합성곱 계층; 지도격자 영상데이터를 입력받아 학습하는 지도 합성곱 계층; 상기 엣지 합성곱 계층 및 지도 합성곱 계층로부터 출력되는 결과를 결합하여 생성되는 갭 계층; 및 상기 갭 계층을 입력으로하는 전연결층으로 구성되는 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 격자는 32x32, 64x64 또는 128x128 중 하나인 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 정합 모듈부의 출력값은 상기 엣지격자 영상데이터에 기준하여 상기 지도격자 영상데이터의 회전된 회전각을 0 내지 1로 정규화한 값인 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 정합 모듈부의 결과에 따라 정합 여부를 판정하고 이를 보정하는 정합 보정부을 더 포함하는 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치에서, 상기 회전각은 0도 내지 360도 범위내 인 것을 특징 으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합을 위한 학습방법은, 데이터 전처리부에서 스캔로봇(2 0)으로부터 포인트 클라우드 및 기준 위치점을 수신하고, 수신된 포인트 클라우드로부터 엣지(edge)를 추출하여 엣지 영상데이터를 생성하는 제1 단계(S110); 지도 정합부에서 어핀(affine) 변환을 통해 상기 엣지 영상 데이터의 상기 기준 위치점에 대응되는 지도를 획득하는 제2 단계(S120); 학습데이터 생성부에서 상기 엣 지 영상데이터를 격자 형태로 분할하여 엣지격자 영상데이터를 생성하고, 상기 엣지격자 영상데이터와 동일한 위치에 동일한 크기의 지도격자를 지도로부터 추출하는 제3 단계(S130); 상기 학습데이터 생성부에서 추출 된 상기 지도격자를 복수의 회전각으로 회전하여 변환한 학습용 지도격자 영상데이터를 생성하는 제4 단계 (S140); 및 정합 모듈부에서 상기 엣지격자 영상데이터 및 상기 지도격자 영상데이터를 지도 학습하는 제5 단계(S150)로 이루어지는 것을 특징으로 한다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 방법, 데이터 전처리부에서 스캔로봇으로부터 포인트 클라우드 및 기준 위치점을 수신하고, 수신된 상기 포인트 클라우드의 기준 위치점에서 소정 크기의 격자를 생 성한 후 엣지를 추출하여 엣지격자 영상데이터를 생성하는 제1 단계(S210); 상기 기준 위치점에 해당하는 지도 에서 소정 크기의 격자에 해당하는 지도격자 영상데이터를 추출하는 제2 단계(S220); 및 상기 엣지격자 영상데 이터와 상기 지도격자 영상데이터를 정합 모듈부에 입력하여 정합될 회전각을 출력하는 제3 단계(S230)로 이루어지는 것을 특징으로 한다."}
{"patent_id": "10-2022-0153326", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이, 본 발명에 따른 인공지능 기반의 지도 정합 장치 및 이를 이용하는 방법에 의하면, 포인트 클라우드를 별도의 어핀 변환없이 학습된 인공지능 모델을 이용하여 자동적으로 지도에 정합할 수 있다 는 이점이 있다. 또한 본 발명에 따른 인공지능 기반의 지도 정합 장치 및 이를 이용하는 방법에 의하면, 포인트 클라우드로부터 엣지라는 경계 영역을 나타내는 특징만을 추출함으로 인해 실내공간에서 3차원 스캔으로 발생하는 노이즈에 효 과적으로 대처하여 정합할 수 있다는 장점이 있다."}
{"patent_id": "10-2022-0153326", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작 원리를 상세하게 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 어떤 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 발명에 따른 인공지능 기반의 지도 정합장치 및 이를 이용하는 방법에 관하여 첨부한 도면들을 참고하면서 이하에서 자세히 설명하기로 한다. 도 1은 본 발명의 바람직한 실시예에 따른 인공지능 기반의 지도 정합장치의 개략적인 구성도이다. 도 1에 도시된 바와 같이, 인공지능 기반의 지도 정합장치는 데이터 처리부, 지도 정합부, 학습 데이터 생성부, 정합 모듈부 및 정합 보정부로 이루어진다. 또한, 지도 정합장치는 3차원 공간을 스캔하여 생성되는 일종의 포인트 클라우드(point cloud)를 수신하는데, 이러한 포인트 클라우드는 3차원 스캐닝 수단을 구비한 스캔로봇에 의해 제공된다. 여기서, 스캔로봇은 미리 정해진 지역을 이동하면서 3차원 공간을 스캐닝하며 지정된 경로를 자율 주행할 수 있는 하나의 로봇일 수 있지만, 하나의 배낭 형태와 같이 사람에 의해 옮겨지면서 포인트 클라우드를 획득할 수 있다. 특히, 이동수단에 다양한 형태로 변경이 가능할 수 있으므로 이에 대해 제한하지 않는다. 이외에도, 스캔로봇은 2차원의 위치좌표를 획득하는 수단을 구비할 수 있다. 이러한 좌표는 지도에서 위치 를 매핑하기 위한 마커로 활용되는데, 위도와 경도 좌표일 수 있고, 상대적인 (x, y) 좌표로 표현될 수 있다. 다만, 스캔로봇은 3차원 스캐닝을 위해 라이다, 카메라, 초음파 등의 다양한 스캔 방법을 통해 가능하지만 이외에도 동일한 기능을 수행할 수 있다면 이에 제한을 두지 않는다. 또한, 본 발명에서는 실내 공간에서의 스캔 및 실내 지도를 정합하는 것으로 실시예를 개시하고 있으나, 실외 공간에서도 가능할 수 있으므로 이에 제한하지 않는다 도 1을 참조하면, 데이터 전처리부는 스캔로봇으로부터 포인트 클라우드, 좌표를 포함하는 기준 위치 점, 방향을 포함하는 스캔데이터를 수신하고, 수신된 스캔데이터를 지도에 정합하기 위해 포인트 클라우드를 전 처리하는 기능을 수행한다. 지도 정합부는 데이터 전처리부에 의해 전처리된 영상 데이터와 기준 위치점를 이용하여 지도 DB에서 지도 정보를 검색하여 어핀(affine) 변환을 통해 해당 지도 위에 포인트 클라우드를 정합하는 기능을 수행한다. 학습데이터 생성부는 어핀 변환없이 포인트 클라우드 및 지도를 자동 정합하기 위한 학습데이터를 생성하 는 모듈이다. 정합 모듈부는 전처리된 포인트 클라우드의 영상데이터 및 기준 위치점의 지도를 통해 자동으로 정합하기 위한 회전각도를 출력하는 2-단계 합성곱 신경망(CNN, Convolution Neural Network)으로 구성되는 딥러닝 모델 이다. 이하, 도면을 참조하여 각각의 구성을 자세히 설명하기로 한다. 정합 보정부는 정합 모듈부에서 출력되는 회전각도가 포인트 클라우드와 지도 간에 정확히 일치되는 지를 확인하고, 부정확할 경우 보정하는 기능을 수행한다. 지도 정보와 실제 공간 정보가 일치하지 않거나, 스 캔된 포인트 클라우드가 부정확하거나 또는 기준 위치점이 지도와 일치하지 않는 경우에는 정합에 오류가 발생 할 수 있으므로 이를 보완하거나 검증할 필요가 있다. 또한, 적어도 둘 이상의 기준 위치점을 선정하여 각각의 기준 위치점에 따라 회전각도가 임계치를 벗어나는 경 우는 정합 오류로 인식할 수 있다. 반면에 기준 임계치 범위에 있는 경우 평균을 통해 회전각도를 지정할 수도 있다. 도 2는 본 발명의 바람직한 실시예에 따른 스캔된 포인트 클라우드 및 지도에 기준 위치점을 표시한 도면으로, 강남역의 특정 지하상가 위치에서 스캔하여 예시한 것이다. 도 2(a)는 스캔로봇을 이용하여 생성한 포인트 클라우드 및 기준 위치점(p1)를 표시하고 있고, 도 2(b)는 기준 위치점(p1) 주변의 지도를 표시하고 있다. 여기서, 포인트 클라우드는 라이다(Lidar) 센서 등으로 수집된 데이터를 의미하는데, 센서들은 특정 물체에 빛/ 신호를 보내어 돌아오는 시간을 기록하여 빛/신호 당 거리 정보를 계산하여 하나의 포인트(점)를 생성한다. 특히, 3차원으로 스캔된 포인트 클라우드는 도2 (a)에 도시된 바와 같이, 불특정의 바닥이나, 천장, 벽 등의 다 양한 정보가 포함될 수 있다. 또한, 포인트 클라우드는 스캔로봇이 이동하면서 수집한 데이터이므로 상가 간의 분할 정보나 상가의 크기 등을 수집하는데 한계가 있어 이동 통로 및 장애물 정보가 주로 표현된다. 도 2(b)에 도시된 지도 정보는 벽(즉 칸막이) 정보 위주로 표현되어 있어, 이를 일치시키기 위해서는 포인트 클라 우드를 2차원 영상데이터로 전처리할 필요가 있다. 도 3은 본 발명의 바람직한 실시예에 따른 데이터 전처리부의 구성을 나타낸 도면이고, 도 4는 전처리된 포인트 클라우드의 영상데이터(이하 '엣지 영상데이터'이라 함)를 나타낸 도면이다. 도 3을 참조하면, 데이터 전처리부는 데이터 수집부, 위치 지정부 및 엣지 생성부로 구성 된다.데이터 수집부는 스캔로봇으로부터 수집된 포인트 클라우드, 기준 위치점, 이동한 방향 정보 등을 수 신한다. 또한 실시간으로 스캔로봇으로부터 데이터를 수신할 수 있지만, 지정된 시간 또는 지정된 공간을 이동한 후 한꺼번에 데이터를 수집할 수도 있다. 또한, 데이터수집부는 스캔로봇에 스캔이 누락된 지점이나 혹은 특정 지점으로 이동하게 하거나, 보다 정밀하게 스캔하도록 명령할 수도 있다. 위치 지정부는 도 2 (a)에 도시된 것처럼 포인트 클라우드에 기준 위치점을 표시하여 측위를 위한 하나의 마커로도 활용할 수 있다. 엣지(edge) 생성부는 포인트 클라우드를 구성하는 정보들 중에서 외곽선 정보를 추출하는 것으로, 지도에 정합하기 위해 불필요한 바닥이나 천장과 같은 정보를 제외시켜 2차원을 구성하는 경계 형상만을 분리하는 것을 특징으로 한다. 도 4는 엣지 생성부에 의해 포인트 클라우드에서 엣지 추출을 통해 외곽 경계가 표시된 엣지 영상데이터를 실시예로 도시하고 있다. 엣지 추출은 영상 안의 화소(pixel)값의 변화가 큰 부분을 검출하는 것으로, 영상처리 분야에서는 이미 공지된 기술이므로 자세한 설명을 생략한다. 또한, 엣지 생성부는 포인트 클라우드 전체를 엣지로 분리할 수도 있지만, 기준 위치점에서 소정의 격자 크기로 엣지 영상데이터를 생성할 수 있고, 이는 학습이 완료된 정합 모듈부에서 입력데이터로 바로 활용 될 수 있다. 도 5는 본 발명의 바람직한 실시예에 따른 지도 정합부의 구성도이고, 도 6은 본 발명의 바람직한 실시예 에 포인트 클라우드와 지도를 어핀 변환하여 정합한 도면이다. 도 5를 참조하면, 스캔로봇으로부터 수신된 위치정보에 해당하는 지도를 검색하여 선정하는 지도 정합부 는 지도 선정부, 엣지 영상데이터와 지도를 어핀(affine) 변환을 통해 정합하는 어핀 변환부 및 엣지 영상데이터가 지도에 정확히 매핑되는지를 판정하는 정합 판정부로 구성된다. 지도 선정부는 포인트 클라우드가 수집된 지점의 기준 위치점에 해당하는 지도를 지도 DB에서 검색하여 선 정하는 기능을 수행한다. 또한, 스캔로봇에 의해 포인트 클라우드가 수집된 이동한 거리 및 방향 정보를 기 초로 지도내에 범위를 제한하기도 하고, 지도의 축척을 포인트 클라우드에 일치시키는 지도의 크기를 변경하는 기능을 수행한다. 또한, 어핀 변환을 위해 기준 위치점 이외에 추가로 2개의 지점을 더 확보하여야 하고 이는 학습데이터 생성을 위한 용도로도 활용된다. 어핀 변환부는 포인트 클라우드 상에 3개의 기준점을 설정하고, 지도상에 동일한 3개의 기준점을 설정한 후 어핀 변환을 통해 3개 점을 매핑하고 이로 인한 회전각도를 산출하여 포인트 클라우드와 지도를 일치시킬 수 있다. 어핀 변환은 통상의 기술자라면 파이선의 OpenCV와 같은 도구를 이용하여 쉽게 변환할 수 있어 실시를 위 한 자세한 설명을 생략한다. 정합 판정부는 어핀 변환부에서 변환된 회전각도와 3개의 기준 위치점(p1,p2,p3)를 통해 포인트 클라 우드와 지도가 일치 정도를 판정하는 기능을 제공한다. 특히, 포인트 클라우드는 바닥이나 천장 혹은 벽의 반사영역에 다수의 포인트가 생성되므로 도 6에서 보듯이 바 닥(천장과는 구분이 안됨)에 집중되므로 지도의 통로에 개방된 통로와 일치 정도를 확인하면 충분하고, 이외에 도 엣지 영상데이터의 엣지와 지도의 선들과 비교하여 일치 정도를 확인할 수도 있다. 이러한 일치 정도는 수치를 갖는 정합도로 표현이 가능하고 소정의 임계치 이상일 경우 지도에 획득한 포인트 클라우드는 검색된 지도에 정합된 것으로 판정하고, 이들로부터 학습데이터를 생성한다. 본 발명에서 일치 여부 및 그 정합 정도를 확인하는 수단은 통상의 기술자 수준에서 쉽게 실시할 수 있는 것이 므로 자세한 설명을 생략한다. 도 7은 본 발명의 바람직한 실시예에 따른 학습데이터 생성부의 구성도이고, 도 8은 본 발명의 바람직한 실시예에 따른 엣지 영상데이터 및 지도를 격자로 구분한 도면이다. 또한 도 9는 본 발명의 바람직한 실시예에 따른 엣지격자 영상데이터와 이에 대응되는 지도상의 격자를 회전한 영상데이터를 표현한 도면이다. 이하 도 7 내지 도 9를 참조하여, 학습데이터를 생성하는 수단을 자세히 설명한다. 도 7에 도시된 바와 같이, 학습데이터 생성부는 격자 분할부, 학습데이터 분리부 및 회전영상 생성부 로 이루어지고, 생성된 학습데이터는 학습데이터 DB에 저장되고 정합 모듈부에 제공되어 지도 학습을 수행한다. 격자 분할부는 엣지 영상데이터를 격자형태로 분할하는 기능을 제공한다. 여기서 격자로 분할된 하나의 엣 지격자 영상데이터는 정합 모듈부의 입력 노드에 할당되는 것으로 32x32, 64x64 또는 128x128로 다양 하게 구성될 수 있고 이에 제한되지 않으나, 바람직하게는 32x32 로 구성된다. 도 8(a) 및 (b)는 엣지격자 영상데이터와 지도를 4x4 크기의 16개의 지도격자 영상데이터로 나눈 도 면을 예시하고 있다. 여기서, 일부 엣지격자 영상데이터들 중에는 스캔로봇에 의해 제대로 스캔되지 않은 영역이 존재하는데 이들 격자 영역은 학습데이터에서 제외시킨다. 즉, 도 8을 참조하여 설명하면, 격자 2,13,14는 스캔되지 않은 영역이고, 격자 15는 지도 정보에 표시되지 않은 영역이므로 임계값 이하의 정합도를 나타낼 것이므로 학습데이터에서 제외할 수 있다. 학습데이터 분리부에서는 이처럼 엣지격자 영상데이터와 지도격자 영상데이터를 정합 판정부 를 이용하여 정합도를 계산하여 일정 임계치 이상의 격자만을 지정할 수 있다. 회전영상 생성부는 학습데이터로 지정된 지도에서 하나의 격자에 대해 다양하게 회전각을 변화시켜 학습데 이터를 생성하는 기능을 수행한다. 도 9 (a)는 도 8에서 격자 6에 대한 엣지격자 영상데이터이고, 도 9 (b)는 지도상의 해당 격자 6을 0도에서 360도 사이를 16개로 회전각을 변화시켜 생성한 지도격자 데이터들을 예 시한 도면이다. 여기서 회전각은 지도학습을 위한 출력값으로 이용되고, 공지된 최소-최대(MinMax) 스케일링을 통해 0 내지 1사 이의 정규화된 값으로 변환된다. 예를 들면, 90도 회전은 0.25이고, 225도 회전은 0.625가 된다. 또한, 도 9(b)는 16개의 회전각에 따라 변환된 것이나, 이에 제한되는 것이 아니면 회전각의 수는 다양하게 변 경이 가능하다. 도 10은 본 발명의 바람직한 실시예에 따른 정합 모듈부의 구성을 나타낸 도면이며, 도 11은 본 발명의 바 람직한 실시예에 따른 엣지 합성곱 계층 및 엣지 갭 계층의 구조를 나타낸 도면이다. 도 10을 참조하면, 정합 모듈부는 신경망 기반의 학습 알고리즘으로 입력층, 은닉층 및 출력층의 다층구조 의 신경망을 갖는 딥러닝 모델을 응용하여 채택하고 있고, 이중에서 주로 이미지 데이터의 공간적 특징 및 위치 정보를 다룰 때 사용되는 합성곱 신경망(CNN, Convolution Nerual Network)을 사용하였다. 일반적으로 합성곱 신경망의 기본 모델은 이미지에 필터를 이용하여 다양한 합성곱을 연산하여 지역 특징(local feature)를 추출하는 합성곱 층(Convolution layer)과 공간정보를 유지하면서 데이터 크기를 줄이는 다운 샘플 링 기능을 담당하는 풀링 층(Pooling layer 혹은 subsampling layer) 및 최종적인 분류를 위한 전연결(fully- connected) 다층 신경망을 포함하는 것을 특징으로 한다. 또한, 합성곱 신경망은 일반 다층신경망보다 학습 파라미터의 크기를 최소화할 수 있고, 이로 인해 전연결 다층 신경망의 규모를 축소할 수 있어 빠른 시간 내에 학습이 가능한 구조로 설계가 가능하다. 도 10에 도시된 바와 같이, 정합 모듈부는 2-단계 합성곱 계층, 갭(GAP,Global Average Polling) 계 층 및 전연결 계층으로 구성되고, 다시 2-단계 합성곱 계층은 엣지 합성곱 계층 및 지도 합성곱 계층로 이루어진다. 또한, 엣지 합성곱 계층 및 지도 합성곱 계층은 각각 4개의 계층으로 구성 된다. 또한, 학습데이터는 엣지격자 영상데이터 및 지도격자 영상데이터로 구분되고, 각각은 엣지 합 성곱 계층 및 지도 합성곱 계층에 학습을 위해 입력된다. 여기서 지도격자 영상데이터는 엣지격 자 영상데이터를 다양한 회전각으로 변형시킨 데이터이다. 도 11을 참조하면, 엣지 합성곱 계층은 엣지 영상데이터로부터 생성된 엣지격자 영상데이터를 입력으 로하는 합성곱 계층으로, 엣지 합성곱 계층 은 4개의 층으로 구성되고 각 계층 별 필터의 개수를 4, 8, 16, 32개로 달리 적용한다. 또한, 각각의 합성곱 계층은 2차원 배열의 3x3 크기의 필터를 이용하고, 필터가 이동할 간격인 스트라이드 (stride)는 1로 세팅하고, 또한, 출력의 크기를 조정하기 위한 패딩(Padding)값도 0으로 세팅하여 엣지 영상데 이터와 크기는 동일한다. 풀링 연산으로, 2x2 필터의 크기로 설정된 영역에서 가장 큰 값을 대표값으로 추출하는 최대 풀링(Max Pooling) 기법을 이용하며, 이를 통해 엣지격자 영상데이터의 크기를 절반으로 축소시킨다. 여기서, 필터는 계층별로 필터의 크기를 3x3 뿐만 아니라 5x5 또는 2x2로 달리 적용할 수도 있고, 이에 제한을 두지 않고 다양하게 변경할 수 있다. 도 11에 도시된 바와 같이, 입력인 엣지격자 영상데이터는 32x32의 배열크기이며, 4개의 필터를 적용하여 4개층의 합성곱 특징맵을 생성한 후, 풀링 연산을 수행하면 16x16 배열의 특징맵이 구성된다. 이러한 과정을 반 복하면, 제2 계층에서는 16x16 배열크기의 8개층, 제3 계층에서는 8x8 배열 크기의 16개층, 마지막인 제4 계층 에서는 4x4 크기의 32개층의 특징맵이 구성된다. 도 10 및 11을 참조하면, 엣지 합성곱 계층과 지도 합성곱 계층의 각각의 제4 계층에서 생성된 4x4x32 개의 특징 정보를 포함하는 특징 맵은 바로 전연결 계층으로 연결하지 않고, 엣지 갭 계층 및 지도 갭 계층에 각각 연결된다. 이러한 갭 계층은 총 4x4x64 개의 특징 정보를 64개 크기로 축소하여 연산 횟수를 줄임과 동시에 필터에 들어 있는 특징 정보의 손실없이 처리할 수 있다. 상기의 갭은 각 층의 값인 4x4를 모두 더하여 평균을 취할 수도 있고, 단순히 합으로 처리할 수도 있어 이에 제 한하지 않지만 바람직하게는 평균을 취한다. 다시 도 10을 참조하면, 지도 합성곱 계층은 지도로부터 생성된 지도격자 영상데이터를 입력으로 하 는 합성곱 계층으로 엣지 합성곱 계층과 그 구조가 동일하므로 중복되는 설명은 생략한다. 여기서 지도격 자 영상데이터는 도 9(a)에 대응되는 9(b)의 회전각을 변화시킨 지도격자의 영상데이터가 입력된다. 한편, 갭 계층은 엣지 합성곱 계층 및 지도 합성곱 계층의 마지막 계층에 의해 생성된 각각 64 개의 특징을 결합하여 128개로 구성하고 이를 전연결층의 입력값으로 입력한다. 전연결층은 가중치 학습을 통해 분류를 수행하는 기능으로 128개의 입력되는 특징에 대해 1개의 출력값을 생성한다. 출력값의 범위는 앞서 언급한 0도 내지 360도의 회전각을 0 내지 1로 정규화된 값이고 이는 엣지지도 영상데이터와 이에 대응되는 지도격자 영상데이터와의 사전에 지정된 회전각이고 지도학습을 통해 전연결층의 각 노드의 가중치를 변화시킨다. 전연결층 내의 은닉층은 다양하게 구성될 수 있으나 바람직하게는 2개층의 은닉층으로 구성된다. 본 발명에서는 정합 모듈부는 파이토치(Pytorch)의 API를 사용하여 합성곱신경망 알고리즘을 구현하며, conv2d 및 MaxPool2d API를 통한 합성곱 연산을 지정된 계층 수만큼 반복적으로 수행하고, 합성곱 연산 결과를 AvgPool2d 및 전연결 계층 연산을 위한 Linear API를 수행할 수 있으며, 파이토치 API 가 아닌 다른 API 를 사용할 수 있으며, 이 기술 분야의 통상의 기술자의 기술 수준에서 필요에 따라 다양하게 변경 가능하므로 이에 제한하지 않는다. 도 12는 본 발명의 바람직한 실시예에 따른 기준 위치점과 격자를 표시한 엣지 영상데이터 및 지도를 나타낸 도 면으로, 스캔로봇으로부터 획득된 포인트 클라우드가 해당하는 지도에 정합되기 위한 회전각을 어핀 변환없 이 자동으로 도출하기 위한 학습된 정합 모듈부의 입력 격자를 예시하고 있다. 도 12 (a) 및 (b)에서처럼 기준 위치점(p1)에 해당하는 포인트 클라우드와 지도를 추출한 후, 각각 기준 위치점 (p1)를 나타내는 영역을 중심으로 32x32 크기의 기준 격자를 생성하고, 포인트 클라우드 격자에서 엣지를 추출 하여 하나의 엣지 영상데이터를 생성한다. 이때 엣지 영상데이터 및 지도 격자 영상데이터는 각각 엣지 합성곱 계층 및 지도 합성곱 계층에 입력되고, 최종적으로 엣지 영상데이터와 지도 격자의 영상데이터가 정 확히 정합되는 회전각을 출력한다. 도 13은 본 발명의 바람직한 실시예에 따른 지도 정합장치를 이용한 학습방법을 나타낸 순서도이고, 도 14는 본 발명의 바람직한 실시예에 따른 지도 정합장치를 이용한 지도 정합 방법을 나타낸 순서도이다. 도 13을 참조하면, 지도 정합장치를 이용한 학습 방법은 데이터 전처리부에서 스캔로봇으로부터 포인트 클라우드 및 기준 위치점을 수신하고, 수신된 포인트 클라우드로부터 엣지(edge)를 추출하여 엣지 영상 데이터를 생성하는 제1 단계(S110), 지도 정합부에서 어핀(affine) 변환을 통해 엣지 영상데이터의 기준 위치점에 대응되는 지도를 획득하는 제2 단계(S120), 학습데이터 생성부가 엣지 영상데이터를 격자형태로 분할하여 엣지격자 영상데이터를 생성하고, 엣지격자 영상데이터와 동일한 위치에 동일한 크기의 지도격자를 지 도로부터 추출하는 제3 단계(S130), 학습데이터 생성부에서 추출된 지도격자를 복수의 회전각으로 회전하 여 변환한 학습용 지도격자 영상데이터를 생성하는 제4 단계(S140) 및 정합 모듈부에서 엣지격자 영상데이터 및 지도격자 영상데이터를 지도 학습하는 제5 단계(S150)로 이루어진다. 제2 단계(S120)에서 어핀 변환을 위해 기준 위치점 이외에 엣지 영상데이터 및 지도에서 추가로 2개 지점을 더 지정한다. 특히, 제3 단계(S130)에서 추출되는 격자는 정합 판정부를 이용하여 정합도를 계산하여 일정 임계치 이상 의 격자만을 선정한다. 도 14를 참조하면, 지도 정합장치를 이용한 지도 정합 방법은 데이터 전처리부에서 스캔로봇으로 부터 포인트 클라우드 및 기준 위치점을 수신하고, 수신된 포인트 클라우드의 기준 위치점에서 소정의 크기의 격자를 생성한 후 엣지를 추출하여 엣지격자 영상데이터를 생성하는 제1 단계(S210), 기준 위치점에 해당하는 지도에서 소정 크기의 격자에 해당하는 지도격자 영상데이터를 추출하는 제2 단계(S220), 엣지격자 영상데이터 와 지도격자 영상데이터를 정합 모듈부에 입력하여 정합될 회전각을 출력하는 제3 단계(S230)로 이루어진 다. 또한, 제3 단계(S230)이후, 출력된 회전각을 이용하여 엣지격자 영상데이터와 지도격자 영상데이터간에 정합 판 정부를 이용하여 정합도를 계산하여 임계치를 벗어난 경우에 회전각을 보정하여 일치시키는 단계를 더 포 함할 수 있다. 지금까지 본 발명에 대해 구체적인 실시예들을 참고하여 설명하였다. 그러나, 본 발명이 속한 분야에서 통상의 지식을 가진 자라면 상기 내용을 바탕으로 본 발명의 범주내에서 다양한 응용 및 변형을 수행하는 것이 가능할 것이다."}
{"patent_id": "10-2022-0153326", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 바람직한 실시예에 따른 인공지능 기반의 지도 정합장치의 개략적인 구성도이다. 도 2는 본 발명의 바람직한 실시예에 따른 스캔된 포인트 클라우드 및 지도에 기준 위치점을 표시한 도면이다. 도 3은 본 발명의 바람직한 실시예에 따른 데이터 전처리부의 구성도이다. 도 4는 본 발명의 바람직한 실시예에 따른 포인트 클라우드의 엣지 영상데이터를 나타낸 도면이다. 도 5는 본 발명의 바람직한 실시예에 따른 지도 정합부의 구성도이다. 도 6은 본 발명의 바람직한 실시예에 포인트 클라우드와 지도를 어핀 변환하여 정합한 도면이다. 도 7은 본 발명의 바람직한 실시예에 따른 학습데이터 생성부의 구성도이다. 도 8은 본 발명의 바람직한 실시예에 따른 엣지 영상데이터 및 지도에 격자를 표시한 도면이다. 도 9는 본 발명의 바람직한 실시예에 따른 엣지격자 영상데이터와 이에 대응되는 지도상의 격자를 회전한 영상 데이터를 표현한 도면이다. 도 10은 본 발명의 바람직한 실시예에 따른 정합 모듈부의 구성도이다. 도 11은 본 발명의 바람직한 실시예에 따른 엣지격자 합성곱 계층 및 갭 계층의 구조를 나타낸 도면이다. 도 12는 본 발명의 바람직한 실시예에 따른 자동 정합을 위한 기준 위치점에 대응되는 엣지격자 영상데이터 및 지도격자 영상데이터를 나타낸 도면이다. 도 13은 본 발명의 바람직한 실시예에 따른 지도 정합장치를 이용한 학습과정을 나타낸 순서도이다. 도 14는 본 발명의 바람직한 실시예에 따른 지도 정합장치를 이용한 지도 정합 방법을 나타낸 순서도이다."}
