{"patent_id": "10-2022-7041706", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0028253", "출원번호": "10-2022-7041706", "발명의 명칭": "얼굴 이미지 처리 방법, 얼굴 이미지 처리 모델 훈련 방법, 장치, 디바이스, 저장 매체 및 프", "출원인": "텐센트 테크놀로지", "발명자": "허 커커"}}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치에 의해 수행되는 얼굴 이미지 처리 방법으로서,소스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하는 단계;상기 얼굴 이미지의 3차원 얼굴 이미지 특징 및 상기 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을획득하기 위해 상기 얼굴 이미지 및 상기 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하는 단계;3차원 융합 특징을 획득하기 위해 상기 3차원 얼굴 이미지 특징과 상기 3차원 얼굴 템플릿 이미지 특징을 융합하는 단계;초기 얼굴 교체 특징을 획득하기 위해 상기 얼굴 템플릿 이미지에 기초하여 상기 얼굴 이미지에 대해 얼굴 교체특징 추출을 수행하는 단계;타깃 얼굴 교체 특징을 획득하기 위해 상기 3차원 융합 특징에 기초하여 상기 초기 얼굴 교체 특징을 변환하는단계; 및교체 이후의 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 교체 특징에 기초하여 상기 얼굴 템플릿 이미지의 템플릿 얼굴을 상기 소스 얼굴로 교체하는 단계를 포함하는 얼굴 이미지 처리 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 3차원 융합 특징을 획득하기 위해 상기 3차원 얼굴 이미지 특징과 상기 3차원 얼굴 템플릿 이미지 특징을융합하는 단계는,상기 3차원 얼굴 이미지 특징으로부터 상기 얼굴 이미지의 소스 얼굴 아이덴티티(identity) 특징을 추출하는 단계;상기 3차원 얼굴 템플릿 이미지 특징으로부터 상기 얼굴 템플릿 이미지의 템플릿 얼굴 이미지 특징을 추출하는단계; 및상기 3차원 융합 특징을 획득하기 위해 상기 소스 얼굴 아이덴티티 특징과 상기 템플릿 얼굴 이미지 특징을 융합하는 단계를 포함하는, 얼굴 이미지 처리 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 초기 얼굴 교체 특징을 획득하기 위해 상기 얼굴 템플릿 이미지에 기초하여 상기 얼굴 이미지에 대해 얼굴교체 특징 추출을 수행하는 단계는, 상기 얼굴 템플릿 이미지의 제1 인코딩 특징을 획득하기 위해 상기 얼굴 템플릿 이미지를 인코딩하는 단계;상기 얼굴 이미지의 제2 인코딩 특징을 획득하기 위해 상기 얼굴 이미지를 인코딩하는 단계; 및상기 초기 얼굴 교체 특징을 획득하기 위해 상기 제2 인코딩 특징에 기초하여 상기 제1 인코딩 특징을 조정하는단계를 포함하는, 얼굴 이미지 처리 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2023-0028253-3-제1항에 있어서, 상기 타깃 얼굴 교체 특징을 획득하기 위해 상기 3차원 융합 특징에 기초하여 상기 초기 얼굴 교체 특징을 변환하는 단계는,제1 로직 연산 이후의 3차원 얼굴 이미지 특징을 획득하기 위해 상기 3차원 융합 특징에 대해 상기 제1 로직 연산을 수행하고, 제2 로직 연산 이후의 얼굴 교체 특징을 획득하기 위해 상기 초기 얼굴 교체 특징에 대해 상기제2 로직 연산을 수행하는 단계;제3 로직 연산 이후의 얼굴 교체 특징을 획득하기 위해 상기 초기 얼굴 교체 특징과 상기 제2 로직 연산 이후의얼굴 교체 특징에 대해 상기 제3 로직 연산을 수행하는 단계; 및상기 타깃 얼굴 교체 특징을 획득하기 위해 상기 제3 로직 연산 이후의 얼굴 교체 특징과 상기 제1 로직 연산이후의 3차원 얼굴 이미지 특징에 대해 제4 로직 연산을 수행하는 단계를 포함하는, 얼굴 이미지 처리 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 3차원 융합 특징은 적어도 2개의 서브 3차원 융합 특징들을 포함하고, 상기 서브 3차원 융합 특징들의 각각은 특징 차원에 대응하며,상기 제1 로직 연산 이후의 3차원 얼굴 이미지 특징을 획득하기 위해 상기 3차원 융합 특징에 대해 상기 제1 로직 연산을 수행하는 것은,상기 적어도 2개의 서브 3차원 융합 특징들의 표준 편차를 결정하고, 상기 표준 편차를 상기 제1 로직 연산 이후의 3차원 얼굴 이미지 특징으로 취하는 것을 포함하는, 얼굴 이미지 처리 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 3차원 융합 특징을 획득하기 위해 상기 3차원 얼굴 이미지 특징과 상기 3차원 얼굴 템플릿 이미지 특징을융합하는 단계는,얼굴 이미지 처리 모델을 사용하여, 상기 3차원 융합 특징을 획득하기 위해 상기 3차원 얼굴 이미지 특징과 상기 3차원 얼굴 템플릿 이미지 특징을 융합하는 단계를 포함하고,상기 초기 얼굴 교체 특징을 획득하기 위해 상기 얼굴 템플릿 이미지에 기초하여 상기 얼굴 이미지에 대해 얼굴교체 특징 추출을 수행하는 단계는,상기 얼굴 이미지 처리 모델을 사용하여, 상기 초기 얼굴 교체 특징을 획득하기 위해 상기 얼굴 템플릿 이미지에 기초하여 상기 얼굴 이미지에 대해 얼굴 교체 특징 추출을 수행하는 단계를 포함하며,상기 타깃 얼굴 교체 특징을 획득하기 위해 상기 3차원 융합 특징에 기초하여 상기 초기 얼굴 교체 특징을 변환하는 단계는,상기 얼굴 이미지 처리 모델을 사용하여, 상기 타깃 얼굴 교체 특징을 획득하기 위해 상기 3차원 융합 특징에기초하여 상기 초기 얼굴 교체 특징을 변환하는 단계를 포함하는, 얼굴 이미지 처리 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 공개특허 10-2023-0028253-4-상기 교체 이후의 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 교체 특징에 기초하여 상기 얼굴 템플릿 이미지의 템플릿 얼굴을 상기 소스 얼굴로 교체하는 단계는,상기 얼굴 이미지의 얼굴 특징을 획득하기 위해 상기 얼굴 이미지에 대해 특징 추출을 수행하는 단계; 및상기 교체 이후의 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 교체 특징과 상기 얼굴 이미지의 얼굴 특징에기초하여 상기 얼굴 템플릿 이미지의 템플릿 얼굴을 상기 소스 얼굴로 교체하는 단계를 포함하는, 얼굴 이미지 처리 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "컴퓨터 장치에 의해 수행되는 얼굴 이미지 처리 모델 훈련 방법으로서,얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈련 이미지 샘플 그룹을 획득하는 단계;얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 상기 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 상기 얼굴 이미지 샘플의 소스 얼굴로 교체하는 단계;상기 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 상기 예측된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하고, 상기 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 상기얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하는 단계;상기 예측된 얼굴 이미지와 상기 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 상기 예측된얼굴 이미지의 3차원 얼굴 윤곽 포인트와 상기 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이를획득하는 단계; 및상기 얼굴 윤곽 손실에 기초하여 상기 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트하는 단계를 포함하는 얼굴 이미지 처리 모델 훈련 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 상기 예측된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하는 것은,상기 예측된 얼굴 이미지의 3차원 예측된 얼굴 이미지 특징을 획득하기 위해 상기 예측된 얼굴 이미지에 대해 3차원 얼굴 모델링을 수행하는 것;상기 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 상기 3차원 예측된 얼굴 이미지 특징에 대해3차원 키 포인트 투영을 수행하는 것; 및상기 3차원 얼굴 키 포인트로부터 상기 3차원 얼굴 윤곽 포인트를 선택하는 것을 포함하는, 얼굴 이미지 처리 모델 훈련 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 상기 3차원 예측된 얼굴 이미지 특징에 대해3차원 키 포인트 투영을 수행하는 것은,상기 3차원 예측된 얼굴 이미지 특징으로부터 상기 예측된 얼굴 이미지의 예측된 얼굴 아이덴티티 특징 및 예측된 얼굴 표정 특징을 추출하는 것; 및미리 설정된 전달 파라미터를 사용하여, 상기 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 상기 예측된 얼굴 아이덴티티 특징 및 상기 예측된 얼굴 표정 특징에 대해 3차원 키 포인트 투영을 수행하는 것을 포함하는, 얼굴 이미지 처리 모델 훈련 방법.공개특허 10-2023-0028253-5-청구항 11 제8항에 있어서,상기 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 상기 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트사이의 차이를 획득하는 단계 후에, 상기 얼굴 이미지 처리 모델 훈련 방법은,상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 제1 손실을 획득하기 위해 상기 3차원 얼굴 윤곽 포인트 이외의 예측된 얼굴 이미지와 상기 얼굴 참조 이미지 샘플 사이의 차이를 획득하는 단계 ― 상기 제1손실은 상기 얼굴 윤곽 손실 이외의 손실을 포함함 ―;상기 얼굴 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 얼굴 특징 손실을 획득하는 단계; 및제2 손실을 획득하기 위해 상기 제1 손실과 상기 얼굴 특징 손실을 융합하는 단계를 더 포함하는 얼굴 이미지 처리 모델 훈련 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제1 손실은 픽셀 손실, 특징 손실 및 판별 손실을 포함하며,상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 제1 손실을 획득하기 위해 상기 3차원 얼굴 윤곽 포인트 이외의 예측된 얼굴 이미지와 상기 얼굴 참조 이미지 샘플 사이의 차이를 획득하는 단계는,상기 픽셀 손실을 획득하기 위해 상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 픽셀 차이를획득하는 단계;상기 특징 손실을 획득하기 위해 상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 특징 차이를획득하는 단계; 및상기 판별 손실을 획득하기 위해 상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 판별 차이를획득하는 단계를 포함하는, 얼굴 이미지 처리 모델 훈련 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 특징 손실은 3차원 특징 손실 및 2차원 특징 손실을 포함하며,상기 특징 손실을 획득하기 위해 상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 특징 차이를획득하는 단계는,상기 2차원 특징 손실을 획득하기 위해 상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 2차원특징 차이를 획득하는 단계;상기 3차원 특징 손실을 획득하기 위해 상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 3차원특징 차이를 획득하는 단계; 및상기 특징 손실을 획득하기 위해 상기 2차원 특징 손실과 상기 3차원 특징 손실을 융합하는 단계를 포함하는, 얼굴 이미지 처리 모델 훈련 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 판별 손실을 획득하기 위해 상기 얼굴 참조 이미지 샘플과 상기 예측된 얼굴 이미지 사이의 판별 차이를획득하는 단계는,스케일링된 얼굴 참조 이미지 샘플 및 스케일링된 예측된 얼굴 이미지를 획득하기 위해 상기 얼굴 참조 이미지공개특허 10-2023-0028253-6-샘플과 상기 예측된 얼굴 이미지를 각각 스케일링하는 단계;제1 판별 특징을 획득하기 위해 상기 스케일링된 얼굴 참조 이미지 샘플을 판별하고, 제2 식별 특징을 획득하기위해 상기 스케일링된 예측된 얼굴 이미지를 판별하는 단계; 및상기 제1 판별 특징 및 상기 제2 판별 특징에 기초하여 상기 판별 손실을 결정하는 단계를 포함하는, 얼굴 이미지 처리 모델 훈련 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 얼굴 윤곽 손실에 기초하여 상기 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트하는 단계는, 상기 얼굴 이미지 처리 모델의 모델 파라미터를 획득하는 단계;제3 손실을 획득하기 위해 상기 얼굴 윤곽 손실과 상기 제2 손실을 융합하는 단계; 및상기 제3 손실을 사용하여 상기 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트하는 단게를 포함하는, 얼굴 이미지 처리 모델 훈련 방법."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "얼굴 이미지 처리 장치로서,소스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하도록 구성된 제1 획득 유닛;상기 얼굴 이미지의 3차원 얼굴 이미지 특징 및 상기 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을획득하기 위해 상기 얼굴 이미지 및 상기 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하도록 구성된 3차원 얼굴 모델링 유닛;3차원 융합 특징을 획득하기 위해 상기 3차원 얼굴 이미지 특징과 상기 3차원 얼굴 템플릿 이미지 특징을 융합하도록 구성된 융합 유닛;초기 얼굴 교체 특징을 획득하기 위해 상기 얼굴 템플릿 이미지에 기초하여 상기 얼굴 이미지에 대해 얼굴 교체특징 추출을 수행하도록 구성된 특징 추출 유닛;타깃 얼굴 교체 특징을 획득하기 위해 상기 3차원 융합 특징에 기초하여 상기 초기 얼굴 교체 특징을 변환하도록 구성된 변환 유닛; 및교체 이후의 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 교체 특징에 기초하여 상기 얼굴 템플릿 이미지의 템플릿 얼굴을 상기 소스 얼굴로 교체하도록 구성된 제1 교체 유닛을 포함하는 얼굴 이미지 처리 장치."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "얼굴 이미지 처리 모델 훈련 장치로서,얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈련 이미지 샘플 그룹을 획득하도록 구성된 제2 획득 유닛;얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 상기 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 상기 얼굴 이미지 샘플의 소스 얼굴로 교체하도록 구성된 제2 교체 유닛;상기 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 상기 예측된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하고, 상기 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 상기얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하도록 구성된 3차원 얼굴 윤곽 포인트 검출유닛;상기 예측된 얼굴 이미지와 상기 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 상기 예측된얼굴 이미지의 3차원 얼굴 윤곽 포인트와 상기 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이를공개특허 10-2023-0028253-7-획득하도록 구성된 계산 유닛; 및상기 얼굴 윤곽 손실에 기초하여 상기 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트하도록 구성된 조정유닛을 포함하는 얼굴 이미지 처리 모델 훈련 장치."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터 장치로서,실행 가능한 명령어를 저장하도록 구성된 메모리; 및상기 메모리에 저장된 실행 가능한 명령어의 실행 동안 제1항 내지 제7항 중 어느 한 항에 따른 방법 또는 제8항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 구성된 프로세서를 포함하는 컴퓨터 장치."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터 판독 가능 저장 매체로서,컴퓨터 실행 가능 명령어를 포함하며,상기 컴퓨터 실행 가능 명령어는, 프로세서에 의해 실행될 때, 제1항 내지 제7항 중 어느 한 항에 따른 방법 또는 제8항 내지 제15항 중 어느 한 항에 따른 방법을 구현하는,컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7041706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 프로그램 제품으로서,컴퓨터 프로그램 또는 컴퓨터 실행 가능 명령어를 포함하며,상기 컴퓨터 프로그램 또는 컴퓨터 실행 가능 명령어는, 프로세서에 의해 실행될 때, 제1항 내지 제7항 중 어느한 항에 따른 방법 또는 제8항 내지 제15항 중 어느 한 항에 따른 방법을 구현하는,컴퓨터 프로그램 제품."}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 얼굴 이미지 처리 방법 및 얼굴 이미지 처리 모델 훈련 방법을 개시한다. 얼굴 이미지 처리 방법은, 소스 얼굴의 얼굴 이미지와 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하는 단계; 얼굴 이미지의 3차원 얼굴 이미 지 특징 및 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하는 단계; 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합하는 단계; 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출을 수행하는 단계; 타깃 얼굴 교체 특징을 획득하기 위해 3차 원 융합 특징에 기초하여 초기 얼굴 교체 특징을 변환하는 단계; 및 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징에 기초하여 얼굴 템플릿 이미지의 템플릿 얼굴을 소스 얼굴로 교체하는 단계를 포함한다."}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2021년 8월 20일에 출원된 중국 특허 출원 제202110963370.5호에 대한 우선권을 주장하며, 그 전체가 참조로서 본 명세서에 포함된다. 본 출원은 컴퓨터 기술 분야에 관한 것으로, 구체적으로는, 얼굴 이미지 처리 방법 및 장치, 얼굴 이미지 처리 모델 훈련 방법 및 장치, 디바이스, 저장 매체 및 프로그램 제품에 관한 것이다."}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술의 발달에 따라 영화 특수 효과 및 인터넷 소셜 네트워킹과 같은 애플리케이션에서, 얼굴 이미지에 있는 객 체의 스타일이 유지되는 경우, 객체의 얼굴을 다른 객체의 얼굴로 교체할 필요가 있다. 요구사항을 충족하기 위해, 얼굴 이미지가 처리되어야 한다. 관련 기술의 얼굴 이미지 처리 방법은 얼굴의 동일성을 유지하는 것만을 고려함으로써 얼굴 이미지 처리의 정확 도가 낮아진다. 본 출원의 실시예는 얼굴 이미지 처리의 정확도를 향상시키는 얼굴 이미지 처리 방법 및 장치, 얼굴 이미지 처 리 모델 훈련 방법 및 장치, 컴퓨터 장치, 컴퓨터 판독 가능 저장 매체, 및 컴퓨터 프로그램 제품을 제공한다.본 출원의 실시예는 컴퓨터 장치에 의해 수행되는 얼굴 이미지 처리 방법을 제공하며, 이 방법은, 소스 얼굴의 얼굴 이미지와 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하는 단계; 얼굴 이미지의 3차원 얼굴 이미지 특징 및 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위 해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하는 단계; 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합하는 단계; 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출 을 수행하는 단계; 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 초기 얼굴 교체 특징을 변환하는 단계; 및 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징에 기초하여 얼굴 템플릿 이미지의 템플릿 얼굴 을 소스 얼굴로 교체하는 단계를 포함한다. 본 출원의 실시예는 얼굴 이미지 처리 장치를 더 제공하며, 소스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하도록 구성된 제1 획득 유닛; 얼굴 이미지의 3차원 얼굴 이미지 특징 및 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위 해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하도록 구성된 3차원 얼굴 모델링 유닛; 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합하도록 구성 된 융합 유닛; 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출 을 수행하도록 구성된 특징 추출 유닛; 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 초기 얼굴 교체 특징을 변환하도록 구성된 변환 유닛; 및 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징에 기초하여 얼굴 템플릿 이미지의 템플릿 얼굴 을 소스 얼굴로 교체하도록 구성된 제1 교체 유닛을 포함한다. 본 출원의 실시예는 얼굴 이미지 처리 모델 훈련 방법을 더 제공하며, 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈련 이미지 샘플 그룹을 획 득하는 단계; 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플릿 얼 굴을 얼굴 이미지 샘플의 소스 얼굴로 교체하는 단계; 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포 인트 검출을 수행하고, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 얼굴 참조 이미지 샘 플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하는 단계; 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3 차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이를 획득하는 단계; 및 얼굴 윤곽 손실에 기초하여 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트하는 단계를 포함한다. 본 출원의 실시예는 얼굴 이미지 처리 모델 훈련 장치를 더 제공하며, 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈련 이미지 샘플 그룹을 획 득하도록 구성된 제2 획득 유닛; 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플릿 얼 굴을 얼굴 이미지 샘플의 소스 얼굴로 교체하도록 구성된 제2 교체 유닛; 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포 인트 검출을 수행하고, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 얼굴 참조 이미지 샘 플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하도록 구성된 3차원 얼굴 윤곽 포인트 검출 유닛; 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3 차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이를 획득하도록 구성된 계산 유닛; 및 얼굴 윤곽 손실에 기초하여 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트하도록 구성된 조정 유닛을 포함 한다. 본 출원의 실시예의 측면에 따르면, 컴퓨터 프로그램 제품 또는 컴퓨터 프로그램이 제공되며, 컴퓨터 프로그램 제품 또는 컴퓨터 프로그램은 컴퓨터 명령어를 포함하며, 컴퓨터 명령어는 컴퓨터 판독 가능 저장 매체에 저장 되고, 본 출원의 실시예에 따른 전술한 방법을 구현하기 위해 컴퓨터 장치의 프로세서는 컴퓨터 판독 가능 저장 매체로부터 컴퓨터 명령어를 읽고 컴퓨터 명령어를 실행한다. 본 출원의 실시예는 컴퓨터 판독 가능 저장 매체를 더 제공하며, 여기서 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능한 명령어를 저장하고, 컴퓨터 실행 가능한 명령어는, 프로세서에 의해 실행될 때, 본 출원의 실시예 에 따른 전술한 방법을 구현한다. 본 출원의 실시예는 컴퓨터 장치를 더 제공한다. 컴퓨터 장치는, 실행 가능한 명령어를 저장하도록 구성된 메모리; 및 메모리에 저장된 실행 가능한 명령어를 실행할 때 본 출원의 실시예에 따른 전술한 방법을 수행하도록 구성된 프로세서를 포함한다. 본 출원의 본 실시예는 다음과 같은 유익한 효과를 갖는다. 얼굴 이미지의 3차원 얼굴 이미지 특징과 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징은 3차원 얼굴 모델링을 통해 획득된다. 추출된 이미지 특징은 3차원 특징이므로, 얼굴 교체 전후의 일관된 얼굴 윤곽을 보장 하기 위해 얼굴 이미지에서 얼굴 윤곽, 즉 얼굴 형상 특징은 보존될 수 있다. 얼굴 교체 이후에 획득된 얼굴 이미지가 얼굴 이미지의 특징과 얼굴 템플릿 이미지의 특징을 가질 수 있도록, 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징은 3차원 융합 특징을 획득하기 위해 융합된다. 얼굴 교체 특징 추출은 초기 얼굴 교 체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 수행되고, 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 변환된다. 초기 얼굴 교체 특징이 3차원 얼 굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합하여 획득되는 3차원 융합 특징에 기초하여 변환되기 때문에, 변환을 통해 획득된 타깃 얼굴 교체 특징은 얼굴 윤곽 특징 및 얼굴 아이덴티티(identity) 특징을 포함 할 수 있다. 그 다음, 얼굴 템플릿 이미지의 템플릿 얼굴이 타깃 얼굴 교체 특징에 기초하여 소스 얼굴로 교체 된 후에 획득된 얼굴 이미지가 보다 자연스럽고 사실적인 디스플레이 효과를 얻을 수 있어서 얼굴 이미지 처리 의 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 실시예의 기술적 해결수단은 본 출원의 실시예의 첨부 도면을 참조하여 아래에서 명확하고 완전하게 설명된다. 그러나, 설명된 실시예는 단지 본 출원의 모든 실시예가 아니라 일부에 불과하다. 창의적인 노력 없이 본 출원의 실시예에 기초하여 당업자에 의해 획득된 다른 모든 실시예는 본 출원의 보호 범위에 속할 것이다. 다음 설명에서, 관련된 \"일부 실시예\"는 모든 가능한 실시예의 서브세트를 설명한다. 그러나, \"일부 실시예\"는 가능한 모든 실시예의 동일한 서브세트 또는 상이한 서브세트일 수 있으며, 충돌 없이 서로 결합될 수 있음이 이해될 수 있다. 본 출원의 실시예는 얼굴 이미지 처리 방법을 제공한다. 얼굴 이미지 처리 방법은 얼굴 이미지 처리 장치에 의 해 수행될 수 있다. 얼굴 이미지 처리 장치는 컴퓨터 장치에 통합될 수 있다. 컴퓨터 장치는 단말, 서버 등 중 적어도 하나를 포함할 수 있다. 일부 실시예에서, 본 출원의 본 실시예에 따른 얼굴 이미지 처리 방법을 더 잘 구현하기 위해, 이에 상응하여 본 출원의 실시예는 얼굴 이미지 처리 모델을 사용하여 본 출원의 본 실시예에 따른 얼굴 이미지 처리 방법을 수행하기 위해 얼굴 이미지 처리 모델 훈련 방법을 더 제공한다. 본 출원의 본 실시예에 따른 얼굴 이미지 처 리 모델 훈련 방법은 얼굴 이미지 처리 모델 훈련 장치에 의해 수행될 수 있다. 얼굴 이미지 처리 모델 훈련 장치는 컴퓨터 장치에 통합될 수 있다. 컴퓨터 장치는 단말 및 서버 중 적어도 하나를 포함할 수 있다. 단말은 스마트폰, 태블릿 컴퓨터, 노트북 컴퓨터, 개인용 컴퓨터(personal computer, PC), 스마트 가정, 웨어러 블 전자 장치, 가상 현실(virtual reality, VR)/증강 현실(augmented reality, AR) 장치, 차량 내 컴퓨터 등일 수 있다. 서버는 다수의 이기종 시스템 중 상호 연결된 서버 또는 백그라운드 서버일 수도 있거나, 또는 독립 된 물리적 서버일 수도 있거나, 또는 복수의 물리적 서버 또는 분산 시스템을 포함하는 서버 클러스터일 수도 있거나, 또는 클라우드 서비스, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 스토리지, 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 네임 서비스, 보안 서비스, 빅데이터, 인공지능 플 랫폼과 같은 기본 클라우드 컴퓨팅 서비스를 제공하는 클라우드 서버일 수 있다. 일부 실시예에서, 도 1에 도시된 바와 같이, 얼굴 이미지 처리 장치는 본 출원의 실시예에 따른 얼굴 이미지 처 리 방법을 구현하기 위해 단말 또는 서버와 같은 컴퓨터 장치에 통합될 수 있다. 예를 들어, 컴퓨터 장치는 소 스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하고, 얼굴 이미지의 3차원 얼굴 이미지 특 징 및 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미 지에 대해 3차원 얼굴 모델링을 수행하며, 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합하고, 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼 굴 이미지에 대해 얼굴 교체 특징 추출을 수행하며, 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 초기 얼굴 교체 특징을 변환하고, 변환 후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징에 기 초하여 얼굴 템플릿 이미지의 템플릿 얼굴을 소스 얼굴로 교체할 수 있다. 얼굴 이미지 처리 모델 훈련 장치는 본 출원의 실시예에 따른 얼굴 이미지 처리 모델 훈련 방법을 구현하기 위 해 단말 또는 서버와 같은 컴퓨터 장치에 통합될 수 있다. 예를 들어, 컴퓨터 장치는 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈련 이미지 샘플 그룹을 획득할 수 있고, 얼굴 이미 지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 얼굴 이미지 샘플의 소스 얼굴로 교체하며, 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하며, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인 트를 획득하기 위해 얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하고, 예측된 얼굴 이미 지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포 인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이를 획득하며, 얼굴 윤곽 손실에 기초하여 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트할 수 있다. 즉, 얼굴 이미지 처리 모델은 훈련된 얼굴 이 미지 처리 모델을 획득하기 위해 조정된다. 얼굴 이미지 처리 프로세스는 얼굴 템플릿 이미지에 있는 객체의 얼굴을 소스 이미지에 있는 객체의 얼굴로 교 체하는 것으로 볼 수 있으며, 얼굴 템플릿 이미지에서 얼굴 객체에 대한 얼굴을 변경하는 것으로 이해될 수 있 다. 예를 들어, 얼굴은 사람의 얼굴이고, 이른바 \"얼굴 바꾸기\"는 얼굴 템플릿 이미지의 사람 얼굴의 아이덴티티를 소스 이미지의 사람으로 변경함과 동시에, 포즈, 표정, 메이크업 및 배경과 같은 얼굴 템플릿 이미지의 사 람 얼굴 요소가 변경되지 않은 상태로 유지하는 것을 의미한다. 본 출원의 본 실시예에 따른 얼굴 이미지 처리 방법은 일반적으로 증명서 사진 제작, 영화 및 텔레비전 인물 사진 제작, 게임 캐릭터 디자인, 가상 이미지 및 개인 정보 보호와 같은 시나리오에 적용할 수 있다. 얼굴 이미지 처리 모델을 훈련시키는 프로세스는 얼굴 이미지 처리 모델이 복수의 훈련 이미지 샘플 그룹을 지"}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속적으로 학습할 수 있고 지속적으로 규칙을 요약하며, 마지막으로 얼굴 템플릿 이미지의 템플릿 얼굴을 얼굴 이미지의 소스 얼굴로 정확하게 교체할 수 있도록 복수의 훈련 이미지 그룹을 얼굴 이미지 처리 방법으로 입력 하는 것으로 간주될 수 있다. 본 출원의 실시예에 따른 이미지 처리 방법 및 얼굴 이미지 처리 모델 훈련 방법은 인공지능 분야의 컴퓨터 비 전 기술에 관한 것이다. 즉, 본 출원의 실시예에서, 인공지능의 컴퓨터 비전 기술을 사용하여 얼굴 템플릿 이 미지의 객체가 얼굴 이미지의 소스 객체로 교체될 수 있다. 본 출원의 본 실시예는 얼굴 이미지 처리 장치의 관점에서 설명될 것이다. 얼굴 이미지 처리 장치는 컴퓨터 장 치에 통합될 수 있다. 컴퓨터 장치는 서버일 수도 있거나, 또는 단말과 같은 장치일 수도 있다. 일부 실시예에서, 본 출원의 실시예에 따른 얼굴 이미지 처리 방법은 단말 또는 서버 단독으로 또는 단말과 서 버에 의해 함께 구현될 수 있다. 예를 들어, 얼굴 이미지 처리 방법은 서버 단독으로 구현된다. 도 2에 도시 된 바와 같이, 얼굴 이미지 처리 방법이 제공된다. 이 방법은 다음의 단계를 포함한다. 단계 101: 서버가 소스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획득한다. 얼굴 이미지는 소스 객체를 포함한다. 이른바 '소스 객체'는 얼굴 이미지에 포함된 객체일 수 있다. 예를 들 어, 얼굴 이미지가 사람 얼굴 이미지인 경우, 소스 객체는 사람의 얼굴 이미지에 대응하는 사람일 수 있다. 소 스 얼굴은 얼굴 객체 교체를 제공하는 얼굴 객체 소스이며, 템플릿 얼굴에 대응한다. 템플릿 얼굴은 교체될 얼 굴 객체 및 유지될 얼굴 배경과 같은 다른 요소를 포함한다. 예를 들어, 도 3에 도시된 바와 같이, 도 3에서 001은 얼굴 이미지일 수 있다, 도 3에서 002는 얼굴 템플릿 이 미지일 수 있으며, 도면에서 003은 교체 후의 얼굴 이미지일 수 있다. 도 1에서 알 수 있는 바와 같이, 얼굴 이미지의 얼굴 특징은 교체 후의 얼굴 이미지에 유지되고, 얼굴 템플릿 이미지의 포즈, 표정, 메이크업 및 배경과 같은 요소는 또한 유지된다. 얼굴 이미지 및 얼굴 템플릿 이미지는 다양한 방식으로 획득될 수 있다. 예를 들어, 얼굴 이미지와 얼굴 템플 릿 이미지가 직접 획득될 수 있거나, 또는 얼굴 이미지와 얼굴 템플릿 이미지는 얼굴 이미지와 얼굴 템플릿 이 미지의 수량이 많거나 메모리가 큰 경우 간접적으로 획득할 수 있으며, 구체적으로는 다음과 같다. 얼굴 이미지와 얼굴 템플릿 이미지를 직접적으로 획득 예를 들어, 사용자에 의해 업로드된 원래 얼굴 이미지와 원래 얼굴 이미지에 대응하는 이미지 처리 정보가 직접 수신될 수 있으며, 소스 얼굴의 얼굴 이미지와 템플릿 얼굴의 얼굴 템플릿 이미지는 이미지 처리 정보에 따라 원래 얼굴 이미지에서 선택되거나, 또는 이미지 데이터베이스 또는 네트워크로부터 얼굴 이미지 쌍이 획득하는 경우, 하나의 얼굴 이미지는 소스 얼굴의 얼굴 이미지로서 얼굴 이미지 쌍에서 무작위로 선택되거나, 얼굴 이미 지 쌍의 다른 얼굴 이미지는 얼굴 템플릿 이미지로 사용된다. 얼굴 이미지와 얼굴 템플릿 이미지를 간접적으로 획득 예를 들어, 단말에 의해 전송된 이미지 처리 요청이 수신될 수 있다. 이미지 처리 요청은 원래 얼굴 이미지의 저장 주소와 이미지 처리 정보를 포함한다. 원래 얼굴 이미지는 메모리, 캐시 또는 제3자 데이터베이스에서 획 득될 수 있거나, 또는 원래 얼굴의 얼굴 이미지와 템플릿 얼굴의 얼굴 템플릿 이미지는 이미지 처리 정보에 따 라 원본 얼굴 이미지에서 선택된다. 일부 실시예에서, 원래 얼굴 이미지가 성공적으로 획득된 후, 원래 얼굴 이미지가 성공적으로 획득되었음을 단 말에게 프롬프트하도록 단말에게 전송될 수 있다. 일부 실시예에서, 원래 얼굴 이미지가 성공적으로 획득된 후, 얼굴 이미지 및 얼굴 템플릿 이미지를 획득하기 위해 원래 얼굴 이미지가 전처리될 수 있다. 전처리는 다양한 방식으로 수행될 수 있다. 예를 들어, 원래 얼 굴 이미지의 크기는 미리 설정된 크기로 조정될 수 있거나, 또는 원래 얼굴 이미지의 얼굴 객체가 얼굴 키 포인 트 등록에 의해 원래 얼굴 이미지 내의 얼굴 객체가 통일된 위치에 정렬할 수 있다.단계 102: 얼굴 이미지의 3차원 얼굴 이미지 특징 및 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행한다. 3차원 얼굴 이미지 특징은 3차원 공간에서 얼굴 이미지의 특징을 지시하는 정보를 포함할 수 있다. 예를 들어, 얼굴 이미지에서 소스 얼굴의 얼굴 특징, 얼굴 윤곽, 텍스처(texture), 각도, 및 조도와 같은 정보가 3차원 얼 굴 이미지 특징을 통해 지시될 수 있다. 3차원 얼굴 템플릿 이미지 특징은 3차원 공간에서 얼굴 템플릿 이미지의 특성을 지시하는 특징을 포함할 수 있 다. 예를 들어, 3차원 얼굴 템플릿 이미지 특징은, 얼굴 템플릿 이미지에서 템플릿 얼굴의 표정 특징, 텍스처 특징, 각도 특징 및 조도 특징 중 적어도 하나를 포함할 수 있다. 일부 실시예에서, 3차원 얼굴 이미지 특징은 복수의(즉, 적어도 2개의) 특징을 포함할 수 있다. 특징은 공동으 로 3차원 얼굴 이미지 특징을 구성한다. 예를 들어, 3차원 얼굴 이미지 특징은 소스 얼굴 아이덴티티 특징, 얼 굴 윤곽 특징, 소스 얼굴 표현 특징, 소스 얼굴 텍스처 특징, 소스 얼굴 각도 특징, 소스 얼굴 조도 특징 등을 포함할 수 있다. 소스 얼굴 아이덴티티 특징은 3차원 얼굴 이미지에서 소스 얼굴의 아이덴티티를 지시할 수 있는 특징을 포함한 다. 예를 들어, 얼굴 이미지의 소스 얼굴은 아이덴티티 특징을 통해 다른 얼굴 이미지의 소스 얼굴과 구별될 수 있다. 즉, 얼굴 이미지가 타깃 객체의 얼굴을 포함하는 경우, 아이덴티티 특징은 타깃 객체를 식별할 수 있 고, 얼굴 이미지의 소스 얼굴은 아이덴티티 특징을 통해 알 수 있다. 소스 얼굴 표현 특징은 얼굴 이미지에서 소스 얼굴의 표현을 지시할 수 있는 특징을 포함한다. 소스 얼굴 텍스 처 특징은 얼굴 이미지의 텍스처를 지시할 수 있는 특징을 포함한다. 소스 얼굴 각도 특징은 얼굴 이미지에서 소스 얼굴의 각도를 지시할 수 있는 특징을 포함한다. 즉, 소스 얼굴 각도 특징은 얼굴 이미지에서 소스 얼굴 의 방향을 지시할 수 있다. 예를 들어, 소스 얼굴이 좌측 또는 우측을 보고 있는지 또는 정면을 향하고 있는지 여부는 각도 특징을 통해 알 수 있다. 소스 얼굴 조도 특징은 얼굴 이미지의 밝기를 지시할 수 있는 특징을 포 함한다. 일부 실시예에서, 3차원 얼굴 템플릿 이미지 특징은 또한 복수의 특징을 포함할 수 있다. 특징은 공동으로 3차 원 얼굴 템플릿 이미지 특징을 구성한다. 예를 들어, 3차원 얼굴 템플릿 이미지 특징은 템플릿 얼굴 아이덴티 티 특징, 템플릿 얼굴 표정 특징, 템플릿 얼굴 텍스처 특징, 템플릿 얼굴 각도 특징, 템플릿 얼굴 조도 특징 등 을 포함할 수 있다. 일부 실시예에서, 3차원 얼굴 템플릿 이미지 특징이 템플릿 얼굴 아이덴티티 특징, 템플릿 얼굴 표정 특징, 템 플릿 얼굴 텍스처 특징, 템플릿 얼굴 각도 특징, 및 템플릿 얼굴 조도 특징을 포함하는 경우, 템플릿 얼굴의 표 정, 텍스처, 각도 및 조도와 같은 정보가 유지될 수 있고 템플릿 얼굴의 아이덴티티는 얼굴 템플릿 이미지의 템 플릿 얼굴이 얼굴 이미지의 소스 얼굴과 교체되는 경우에 소스 얼굴의 아이덴티티로 교체될 수 있다. 예를 들 어, 도 3에 도시된 바와 같이, 얼굴 이미지의 캐릭터가 Zhang San이고 얼굴 템플릿 이미지의 캐릭터 가 Li Si라고 가정하면, 얼굴 교체에서 Li Si만 Zhang San으로 교체되지만, 얼굴 템플릿 이미지에서의 표 정, 텍스처, 각도 및 조도와 같은 Li Si의 정보는 여전히 유지된다. 일부 실시예에서, 3차원 얼굴 이미지 특징 및 3차원 얼굴 템플릿 이미지 특징은 다양한 형태로 표현될 수 있다. 예를 들어, 3차원 얼굴 이미지 특징 및 3차원 얼굴 템플릿 이미지 특징은 벡터일 수 있다. 다른 예에서, 3차원 얼굴 이미지 특징 및 3차원 얼굴 템플릿 이미지 특징은 행렬 등일 수 있다. 일부 실시예에서, 3차원 얼굴 모델링은 얼굴 이미지의 3차원 얼굴 이미지 특징과 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지를 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 다양한 방식으로 수행될 수 있 다. 예를 들어, 3차원 얼굴 모델링 모델은 얼굴 이미지의 3차원 얼굴 이미지 특징과 얼굴 템플릿 이미지의 3차원 얼 굴 템플릿 이미지를 획득하기 위해 3차원 얼굴 모델링 모델을 사용하여 얼굴 이미지 및 얼굴 템플릿 이미지 각 각에 대해 수행될 수 있다. 3차원 얼굴 모델링 모델은 이미지에 대해 3차원 모델링을 수행하고, 이미지의 3차원 특징을 획득하는 모델을 포 함할 수 있다. 예를 들어, 3차원 얼굴 모델링 모델은 합성곱 신경망(convolutional neural network, CNN), 심층 잔차 신경망 (residual network, ResNet), 3차원 얼굴 모퍼블 모델(three-dimensional face morphable model, 3DMM) 등 중적어도 하나를 포함할 수 있다. 다른 예에서, 얼굴 이미지 및 얼굴 템플릿 이미지는 소스 얼굴 및 템플릿 얼굴에 대해 얼굴 모델링을 수행하고 3DMM으로부터 얼굴 이미지의 복수의 소스 얼굴 특징과 얼굴 템플릿 이미지의 복수의 템플릿 얼굴 특징을 획득하 기 위해 3DMM을 사용하여 각각 회귀될 수 있다. 그런 다음, 복수의 소스 얼굴 특징은 3차원 얼굴 이미지 특징 을 획득하기 위해 융합될 수 있고, 복수의 템플릿 얼굴 특징은 3차원 얼굴 템플릿 이미지 특징을 획득하기 위해 융합될 수 있다. 단계 103: 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합 한다. 실제 응용에서, 교체 후의 얼굴 이미지가 얼굴 이미지의 특징및 얼굴 템플릿 이미지의 특징을 가질 수 있도록 3 차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징이 융합된다. 일부 실시예에서, 템플릿 얼굴의 표현, 텍스처, 각도 및 조도와 같은 정보가 유지될 수 있고 템플릿 얼굴의 아이덴티티는 얼굴 템플릿 이미지의 템플릿 얼굴이 얼굴 이미지의 소스 얼굴로 교체되는 경우에 소스 얼굴의 아 이덴티티로 교체될 수 있도록, 소스 얼굴 아이덴티티 특징과 템플릿 얼굴 이미지 특징은 3차원 융합 특징을 획 득하기 위해, 3차원 얼굴 이미지 특징으로부터 얼굴 이미지의 소스 얼굴 아이덴티티 특징을 추출하고, 3차원 얼굴 템플릿 이미지 특징으로부터 얼굴 템플릿 이미지의 템플릿 얼굴 이미지 특징을 추출하며, 3차원 얼굴 융합 특징을 획득하기 위해 소스 얼굴 아이덴티티 특징과 템플릿 얼굴 이미지 특징을 융합하는 방식 으로 융합될 수 있다. 소스 얼굴 아이덴티티 특징은 3차원 얼굴 이미지의 소스 얼굴의 아이덴티티를 나타낼 수 있는 특징을 포함한다. 템플릿 얼굴 이미지 특징은 템플릿 얼굴 표현 특징, 템플릿 얼굴 텍스처 특징, 템플릿 얼굴 각도 특징, 및 템플 릿 얼굴 조도 특징을 포함할 수 있다. 일부 실시예에서, 소스 얼굴 아이덴티티 특징 및 템플릿 얼굴 이미지 특징은 3차원 융합 특징을 획득하기 위해 다양한 방식으로 융합될 수 있다. 예를 들어, 소스 얼굴 아이덴티티 특징과 템플릿 얼굴 이미지 특징은 접합될 수 있다. 다른 예에서, 소스 얼굴 아이덴티티 특징 및 템플릿 얼굴 이미지 특징이 추가될 수 있다. 다른 예에서, 소스 얼굴 아이덴티티 특징 및 템플릿 얼굴 이미지 특징이 가중치화되고 합산될 수 있다. 일부 실시예에서, 소스 얼굴 아이덴티티 특징 및 템플릿 얼굴 이미지 특징은 3차원 융합 특징을 획득하기 위해 추가될 수 있다. 예를 들어, 소스 얼굴 아이덴티티 특징, 템플릿 얼굴 표정 특징, 템플릿 얼굴 텍스처 특징, 템플릿 얼굴 각도 특징 및 템플릿 얼굴 조도 특징은 3차원 융합 특징을 획득하기 위해 추가될 수 있다. 덧셈 과정은 다음의 수학 식에 의해 나타낼 수 있으며,"}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 심볼 는 소스 얼굴 아이덴티티 특징을 나타낼 수 있고, 심볼 는 템플 릿 얼굴 표정 특징을 나타낼 수 있으며, 심볼 는 템플릿 얼굴 텍스처 특징을 나타낼 수 있 고, 심볼 는 템플릿 얼굴 각도 특징을 나타낼 수 있으며, 심볼 는 를 나타낼 수 있다. 단계 104: 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출을 수행한다. 일부 실시예에서, 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하는 것은 3차원 공간의 관점에서 얼굴 이미지 및 얼굴 템플릿 이미지를 처리하는 것과 동일하다. 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출을 수행하는 것은 2차원 공간의 관점에서 얼굴 템플릿 이미지와 얼굴 이미지 를 처리하는 것과 동일하다. 얼굴 이미지와 얼굴 템플릿 이미지의 보다 많은 특징은 2차원 공간 및 3차원 공간의 관점에서 각각 획득될 수 있으므로, 얼굴 교체 처리에 대해 더 많은 정보가 사용될 수 있고, 얼굴 이미지 처리 방법의 정확도가 향상될 수 있다. 초기 얼굴 교체 특징은 얼굴 이미지와 얼굴 템플릿 이미지 사이의 매핑 관계를 형성하는 특징을 포함할 수 있다. 일부 실시예에서, 얼굴 교체 특징 추출은 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 다양한 방식으로 얼굴 이미지에 대해 수행될 수 있다. 예를 들어, 얼굴 교체 특징 추출은 초기 얼굴 교체 특징을 획득하기 위해 CNN 또는 적대적 생성 신경망 (generative adversarial network, GAN)과 같은 기계 학습 네트워크를 사용하여 얼굴 템플릿 이미지에 기초하 여 얼굴 이미지에 대해 수행될 수 있다. 딥러닝의 한 방법으로서, GAN은 일반적인 신경망과 다르다. GAN은 2개의 주요 네트워크로 형성되며, 그 중 하 나는 생성기 또는 생성기 네트워크이고, 다른 하나는 판별기 또는 판별기 네트워크이다. GAN의 핵심 로직은 생 성기와 판별기가 서로 겨루고 서로 경쟁한다는 것이다. 생성기는 컨텐츠를 생성하는 기능을 갖는 신경망일 수 있다. 예를 들어, 생성기는 픽처, 텍스트, 비디오 등을 생성할 수 있다. 판별기는 또한 판별기에 입력된 컨텐츠를 판별하는 기능을 갖는 신경망일 수 있다. 예를 들어, 픽처를 예로 들 면, 판별기의 목적은 판별기에 입력된 픽처가 생성기에 의해 생성된 픽처인지 아니면 실제 픽처인지의 여부를 판단하는 것이다. 생성기는 디코더 및 인코더를 포함할 수 있다. 인코더의 기능은 실제 데이터를 압축하고 고차원 데이터를 저차 원 데이터로 압축하는 것이다. 디코더의 기능은 압축된 데이터를 원시 데이터로 복원하는 것이다. 다른 예에서, 얼굴 교체 특징 추출은 초기 얼굴 교체 특징을 획득하기 위해 복수의 CNN에 의해 형성된 기계 학 습 네트워크를 사용하여 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 수행될 수 있다. 예를 들어, 얼굴 이미지 및 얼굴 템플릿 이미지는 복수의 CNN으로 형성된 기계 학습 네트워크로 입력될 수 있다. 그 다음, 기계 학습 네트워크는 얼굴 이미지의 해상도와 얼굴 템플릿 이미지의 해상도를 지속적으로 감 소시키고, 얼굴 이미지와 얼굴 템플릿 이미지를 은닉 공간의 초기 얼굴 교체 특징으로 인코딩할 수 있다. 은닉 공간은 기계 학습 네트워크의 구조에 의해 형성되는 공간을 포함한다. 예를 들어, 기계 학습 네트워크는 입력 계층, 출력 계층, 입력 계층과 출력 계층 사이에 여러 개의 컨볼루션 계층을 포함하므로, 여러 개의 컨볼 루션 계층이 은닉 공간을 구성할 수 있다. 일부 실시예에서, 얼굴 교체 특징 추출은 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여, 얼굴 템플릿 이미지의 제1 인코딩 특징을 획득하기 위해 얼굴 템플릿 이미지를 인코딩하고, 얼굴 이미지의 제2 인코딩 특징을 획득하기 위해 얼굴 이미지를 인코딩하며, 초기 얼굴 교체 특징을 획득하기 위해 제2 인코딩 특징에 기초하여 제1 인코딩 특징을 조정하는 방식으로 얼굴 이미지에 대해 수행될 수 있다. 단계 105: 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 초기 얼굴 교체 특징을 변환한다. 일부 실시예에서, 3차원 융합 특징은 3차원 공간에서 얼굴 이미지와 얼굴 템플릿 이미지 사이의 관계를 지시할 수 있는 반면, 초기 얼굴 교체 특징은 2차원 공간에서 얼굴 이미지와 얼굴 템플릿 이미지 사이의 관계를 지시할 수 있다. 얼굴 교체의 정확도를 향상시키기 위해, 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위 해 3차원 융합 특징에 기초하여 변환될 수 있다. 예를 들어, 3차원 융합 특징과 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위해 동일한 공간으로 매핑될 수 있다.일부 실시예에서, 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 다 양한 방식으로 변환될 수 있다. 예를 들어, 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초한 놈(norm)을 사용함으로써 변환될 수 있다. 예를 들어, 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초한 L1 놈 또는 L2 놈을 사용하여 변환될 수 있다. 일부 실시예에서, 초기 얼굴 교체 특징은 또한 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하 여, 제1 로직 연산 후에 3차원 얼굴 이미지 특징을 획득하기 위해 3차원 융합 특징에 대해 제1 로직 연산을 수행하 고, 제2 로직 연산 후에 얼굴 교체 특징을 획득하기 위해 초기 얼굴 교체 특징에 대해 제2 로직 연산을 수행하 며, 제3 로직 연산 후에 얼굴 교체 특징을 획득하기 위해 제2 로직 연산 후의 초기 얼굴 교체 특징 및 얼굴 교체 특 징에 대해 제3 로직 연산을 수행하고, 타깃 얼굴 교체 특징을 획득하기 위해 제3 로직 연산 후의 얼굴 교체 특징 및 제1 로직 연산 후의 3차원 얼굴 이미지 특징에 대해 제4 로직 연산을 수행하는 방식으로 변환될 수 있다. 제1 로직 연산 및 제2 로직 연산은 데이터의 평균, 데이터의 분산, 데이터의 표준 편차, 데이터의 공분산 등을 계산하는 것을 포함할 수 있다. 제3 로직 연산 및 제4 로직 연산은 덧셈, 뺄셈, 곱셈, 나눗셈 등에 의해 데이터를 처리하는 것을 포함할 수 있 다. 예를 들어, 제3 로직 연산 및 제4 로직 연산은 데이터의 분할을 포함할 수 있다. 다른 예에서, 제3 로직 연산 및 제4 로직 연산은 데이터의 뺄셈 등을 포함할 수 있다. 일부 실시예에서, 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초한 적응 인스턴스 정규화(adaptive instance normalization, AdaIN)에 의해 변환될 수 있다. AdaIN은 이미지 특징 변환을 실현하기 위해 3차원 융합 특징의 평균 및 분산을 초기 얼굴 교체 특징의 평균 및 분산에 정렬할 수 있는 방법이다. 예를 들어, AdaIN을 통해, 3차원 융합 특징의 평균 및 분산이 특징 교체를 실현하기 위해 초기 얼굴 교체 특징의 평균 및 분산에 정렬될 수 있다. 초기 얼굴 교체 특징은 타깃 얼굴 교체 특징을 획득하기 위해"}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "과 같이 3차원 융합 특징에 기초하여 AdaIN에 의해 변환될 수 있으며, 여기서 x는 초기 얼굴 교체 특징을 나타낼 수 있고, y는 3차원 융합 특징을 나타낼 수 있다. σ() 및 μ()는 각각 평균 및 표준 편차를 나타낼 수 있다. AdaIN(x,y)은 타깃 얼굴 교체 특징을 나타낼 수 있다. 일부 실시예에서, 로직 연산(덧셈, 뺄셈, 곱셈, 또는 나눗셈과 같음)은 로직 연산 후의 3차원 얼굴 이미지 특징 을 획득하기 위해 AdaIN에 따라 3차원 융합 특징에 대해 수행될 수 있고, 로직 연산은 로직 연산 후의 얼굴 교 체 특징을 획득하기 위해 초기 얼굴 교체 특징에 대해 수행될 수 있다. 예를 들어, 3차원 융합 특징의 평균 및 표준 편차와 초기 얼굴 교체 특징의 평균 및 표준 편차는 AdaIN에 따라 계산될 수 있다. 여기서, 3차원 융합 특징은 적어도 2개의 서브 3차원 융합 특징을 포함한다(예를 들어, 서브 3차원 융합 특징은 3차원 얼굴 아이덴티티 특징, 3차원 얼굴 표정 특징, 3차원 얼굴 텍스처 특징, 3차원 얼굴 각도 특징 및 얼굴 조도 특징). 각각의 서브 3차원 융합 특징은 특징 차원에 대응한다. 이에 상응하여, 제1 로직 연산은 제1 로 직 연산 후의 3차원 얼굴 이미지 특징을 획득하기 위해, 적어도 2개의 서브 3차원 융합 특징의 표준 편차를 결 정하고, 제1 로직 연산 후의 표준 편차를 3차원 얼굴 이미지 특징으로 취하는 방식으로 3차원 융합 특징에 대해 수행될 수 있다. 그 다음, 로직 연산 후의 얼굴 교체 특징을 획득하기 위해 AdaIN에 따라 초기 얼굴 교체 특징 및 제2 로직 연산 이후의 얼굴 교체 특징에 대해 로직 연산이 수행될 수 있다. 예를 들어, 초기 얼굴 교체 특징과 초기 얼굴 교 체 특징의 표준 편차를 뺀 후 연산 이후의 얼굴 교체 특징을 획득하기 위해 분할될 수 있다. 그 다음, 타깃 얼굴 교체 특징을 획득하기 위해 AdaIN에 따라 연산 후의 얼굴 교체 특징과 통계 후의 3차원 얼 굴 이미지 특징 대해 로직 연산이 수행될 수 있다. 예를 들어, 연산 이후의 템플릿 교체 특징과 통계 후의 3차 원 얼굴 이미지 특징의 평균을 곱한 다음 타깃 얼굴 교체 특징을 획득하기 위해 더해진다. 단계 106: 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징에 기초하여 얼굴 템플릿 이미지의 템 플릿 얼굴을 소스 얼굴로 교체한다. 일부 실시예에서, 얼굴 이미지 처리 방법의 정확도를 향상시키기 위해 교체 이후의 얼굴 이미지의 얼굴과 원래 얼굴 사이의 유사도를 향상시키기 위해, 특징 추출이 얼굴 이미지에 대해 수행되어 얼굴 이미지의 얼굴 특징을 획득할 수 있고, 그 다음, 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징 및 얼굴 이미지의 얼 굴 특징에 기초하여 얼굴 템플릿 이미지의 템플릿 얼굴이 소스 얼굴로 교체된다. 얼굴 이미지에 대해 특징 추출을 수행하는 것은 일부 데이터를 통해 얼굴 정보를 나타내는 것을 포함할 수 있다. 이러한 데이터는 얼굴 이미지의 얼굴 특징을 지시할 수 있다. 일부 실시예에서, 본 출원의 본 실시예의 얼굴 특징은 소스 얼굴의 기하학적 특징 또는 소스 얼굴의 표현 특징 일 수 있다. 기하학적 특징은 눈, 코 및 입과 같은 얼굴 특징들 사이의 기하학적 관계, 예를 들어 거리, 면적, 각도 등을 지칭할 수 있다. 소스 얼굴의 표현 특징은 얼굴 이미지의 계조 정보를 사용하여 일부 알고리즘을 통 해 추출된 전역 또는 로컬 특징이다. 일부 실시예에서, 특징 추출은 얼굴 이미지의 얼굴 특징을 획득하기 위해 다양한 방식으로 얼굴 이미지에 대해 수행될 수 있다. 예를 들어, 얼굴 특징이 소스 얼굴의 기하학적 특징인 경우, 얼굴 이미지의 위치가 얼굴 이미지 내의 얼굴 부위 키 포인트의 위치 정보를 획득하기 위해 생성될 수 있다. 그 다음, 얼굴 부위 키 포인트의 위치 정보 사이의 공간 차이가 각각 계산될 수 있고, 공간 차이는 얼굴 특징으로 사용된다. 다른 예로, 얼굴 특징이 소스 얼굴의 대표 특징인 경우, 얼굴 이미지의 컨볼루션 결과를 획득하기 위해 컨볼루 션 커널을 사용하여 얼굴 이미지에 대해 컨볼루션 추출이 수행될수 있고, 그 다음 얼굴 이미지의 컨볼루션 결과 가 얼굴 이미지를 획득하기 위해 회귀된다. 다른 예에서, 얼굴 특징을 추출할 수 있는 기계 학습 네트워크를 사용하여 얼굴 이미지에 대해 특징 추출이 수 행될 수도 있다. 예를 들어, 얼굴 이미지의 얼굴 특징을 획득하기 위해 CNN, 심층 신경망(deep neural network, DNN) 등을 사용하여 얼굴 이미지에 대해 특징 추출이 수행될 수 있다. 일부 실시예에서, 교체 이후의 얼굴 이미지를 획득하기 위해, 얼굴 템플릿 이미지의 템플릿 얼굴은 훈련된 얼굴 이미지 처리 모델을 사용하여 타깃 얼굴 교체 특징 및 얼굴 이미지의 얼굴 특징에 기초하여 소스 얼굴로 교체될 수 있다. 예를 들어, 얼굴 템플릿 이미지의 템플릿 얼굴은 GAN을 사용하여 타깃 얼굴 교체 특징과 얼굴 이미지 의 얼굴 특징에 기초하여 소스 얼굴로 교체되어 교체 이후의 얼굴 이미지를 획득할 수 있다. 일부 실시예에서, 훈련된 얼굴 이미지 처리 모델의 모델 구조는 3차원 얼굴 모델링 네트워크, 얼굴 특징 추출 네트워크, 및 GAN을 포함할 수 있다. GAN은 생성기와 판별기를 포함할 수 있다. 생성기는 인코더와 디코더를 포함한다. 3차원 얼굴 모델링 네트워크는 ResNet일 수 있다. 3차원 얼굴 모델링 네트워크는 얼굴 이미지의 3차원 얼굴 이 미지 특징과 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플 릿 이미지에 대해 3차원 얼굴 모델링을 수행하도록 구성될 수 있다. 또한, 3차원 얼굴 모델링 네트워크는 3차 원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합하도록 구성될 수도 있다. 얼굴 특징 추출 네트워크는 CNN일 수 있다. 얼굴 특징 추출 네트워크는 얼굴 특징을 획득하기 위해 얼굴 이미 지에 대해 특징 추출을 수행하도록 구성될 수 있다. 인코더는 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출을 수행할 수 있다. 디코더는 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징 및 얼굴 이미지의 얼굴 특징에 기초하 여 얼굴 템플릿 이미지의 템플릿 얼굴을 소스 얼굴로 교체할 수 있다. 예를 들어, 타깃 얼굴 교체 특징 및 얼 굴 이미지의 얼굴 특징은 디코딩 이후의 얼굴 교체 특징과 디코딩 이후의 얼굴 이미지를 획득하기 위해 디코더 를 사용하여 디코딩될 수 있다. 그 후, 디코딩 이후의 얼굴 교체 특징과 디코딩 이후의 얼굴 이미지는 융합 이후의 얼굴 특징을 획득하기 위해 융합된다. 그 다음, 융합 이후의 얼굴 특징은 융합 이후의 얼굴 특징의 확률 분포를 획득하기 위해 미리 설정된 확률 분포로 매핑될 수 있다. 또한, 교체 이후의 얼굴 이미지는 융합 이후 의 얼굴 특징의 확률 분포에 기초하여 생성된다. 미리 설정된 확률 분포 공간은 디코더에서의 수학적 공간이다. 미리 설정된 확률 분포 공간은 얼굴 이미지 처 리 모델을 훈련시키는 과정에서 일정하게 형성되는 공간으로, 특징에 따라 훈련 목적에 맞는 컨텐츠를 생성할 수 있다. 본 출원의 본 실시예에서, 얼굴 이미지 처리 모델은 3차원 얼굴 윤곽 포인트를 사용하여 훈련되어, 얼굴 이미지 에서 소스 얼굴의 얼굴 윤곽이 훈련된 얼굴 이미지 처리 모델을 통해 획득되는 교체 이후의 얼굴 이미지에서 유 지될 수 있으며, 얼굴 이미지 처리 효과가 보다 현실적이어서, 얼굴 이미지 처리의 정확도를 향상시킬 수 있다. 예를 들어, 도 4에 도시된 바와 같이, 도 4에서의 011은 얼굴 이미지일 수 있고, 도 4에서의 012는 얼굴 템플릿 이미지일 수 있으며, 도 4에서의 013은 관련 기술을 사용하여 획득된 교체 이후의 얼굴 이미지일 수 있고, 도 4 에서의 014는 훈련된 얼굴 이미지 처리 모델을 사용하여 획득된 교체 이후의 얼굴 이미지일 수 있다. 도 4에서 013과 014를 비교하면, 014의 얼굴이 011의 얼굴과 더 유사한 것이 명확하다. 본 출원의 실시예는 얼굴 이미지 처리 방법을 제공한다. 얼굴 이미지 처리 방법은, 소스 얼굴의 얼굴 이미지와 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하는 단계; 얼굴 이미지의 3차원 얼굴 이미지 특징 및 얼굴 템플릿 이 미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하는 단계; 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미 지 특징을 융합하는 단계; 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출을 수행하는 단계; 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 초기 얼굴 교체 특징을 변환하는 단계; 및 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징 및 얼굴 이미지의 얼굴 특징에 기초하여 얼굴 템플릿 이미지의 템플릿 얼굴을 소스 얼굴로 교체하는 단계를 포함한 다. 본 출원의 본 실시예에서, 2차원 공간 및 3차원 공간 관점에서 3차원 융합 특징 및 2차원 얼굴 특징과 조 합하여 얼굴 이미지 및 얼굴 템플릿 이미지의 더 많은 특징이 획득될 수 있어서, 얼굴 교체 처리에 대해 더 많 은 정보가 사용될 수 있고, 얼굴 이미지 처리 방법의 정확도가 향상된다. 본 출원의 실시예는 이에 상응하여 얼굴 이미지 처리 모델 훈련 방법을 더 제공한다. 그러면, 본 출원의 본 실 시예는 얼굴 이미지 처리 모델 훈련 장치의 관점에서 설명될 것이다. 얼굴 이미지 처리 모델 훈련 장치는 컴퓨 터 장치에 통합될 수 있다. 컴퓨터 장치는 서버일 수도 있거나, 또는 단말과 같은 장치일 수 있다. 일부 실시예에서, 본 출원의 본 실시예에 따른 얼굴 이미지 처리 모델 훈련 방법은 단말 또는 서버 단독으로 또 는 단말과 서버에 의해 함께 구현될 수 있다. 예를 들어, 얼굴 이미지 처리 모델 훈련 방법은 서버 단독으로 구현된다. 도 5에 도시된 바와 같이, 얼굴 이미지 처리 모델 훈련 방법이 제공되며, 다음의 단계를 포함한다. 단계 201: 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈련 이미지 샘플 그룹을 획득한다. 훈련 이미지 샘플 그룹은 미리 설정된 얼굴 이미지 처리 모델을 훈련하기 위해 사용되는 데이터를 포함한다. 일부 실시예에서, 훈련 이미지 샘플 그룹은 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플, 및 얼굴 참조 이미지 샘플을 포함한다. 얼굴 이미지 샘플은 얼굴 이미지에 대응할 수 있다. 얼굴 템플릿 이미지 샘플은 얼굴 템플릿 이미지에 대응할 수 있다. 얼굴 이미지 샘플은 또한 소스 얼굴을 포함하는 반면, 얼굴 템플릿 이미지 샘플은 템플릿 얼굴을 포 함한다. 예를 들어, 도 6에 도시된 바와 같이, 도 6에서의 015는 얼굴 이미지 샘플일 수 있고, 016은 얼굴 템 플릿 이미지 샘플일 수 있다. 얼굴 참조 이미지 샘플은 얼굴 이미지와 얼굴 템플릿 이미지 샘플을 합성함으로써 획득되는 참조 이미지를 포함 한다. 얼굴 참조 이미지 샘플은 얼굴 이미지 내의 소스 얼굴의 정보뿐만 아니라, 얼굴 템플릿 이미지 샘플 내 의 텍스처, 각도, 조도 및 표정과 같은 이미지 정보를 포함한다. 얼굴 참조 이미지 샘플은 교체 이후의 얼굴 이미지와 동일할 수 있으며, 차이점은 얼굴 참조 이미지 샘플이 인위적으로 합성된 점이다. 또한, 얼굴 참조 이미지 샘플은 이미지 처리 모델을 훈련시키는 과정에서 이미지 처리 모델에 대한 참조를 제공하여 훈련된 이미 지 처리 모델이 요구사항을 충족하는 컨텐츠를 생성할 수 있도록 하는 기능으로 개발자의 훈련 목적에 해당한다.일부 실시예에서, 훈련 이미지 샘플 그룹은 다양한 방식으로 획득될 수 있다. 예를 들어, 훈련 이미지 샘플 그 룹은 오픈 소스 웹사이트에서 직접 획득될 수 있다. 다른 예에서, 훈련 이미지 샘플 그룹은 얼굴 이미지 샘플 및 얼굴 템플릿 이미지 샘플을 수집하고, 얼굴 이미지 샘플 및 얼굴 템플릿 이미지 샘플을 얼굴 참조 이미지 샘 플로 합성함으로써 획득될 수 있다. 단계 202: 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 얼굴 이미지 샘플의 소스 얼굴로 교체한다. 예측된 얼굴 이미지는 얼굴 템플릿 이미지 샘플의 템플릿 얼굴이 얼굴 이미지 샘플의 소스 얼굴로 교체된 후에 획득된 이미지를 포함할 수 있다. 예를 들어, 도 6에 도시된 바와 같이, 도 6에서의 017은 예측된 얼굴 이미지 일 수 있다. 얼굴 이미지 처리 모델은 훈련 준비가 된 얼굴 이미지 처리 모델을 포함한다. 미리 설정된 얼굴 이미지 처리 모델의 구조는 단계 106에서 훈련된 얼굴 이미지 처리 모델과 동일하지만, 훈련 준비가 된 얼굴 이미지 처리 모델에 의해 생성된 예측된 얼굴 이미지는 훈련 목적을 충족시키지 않는다. 일부 실시예에서, 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 얼굴 이미지 샘플의 소스 얼굴로 교체하는 단계는, 얼굴 이미지 처리 모델을 사용하여, 얼굴 이미지 샘플의 3차원 얼굴 이미지 샘플 특징과 얼굴 템플릿 이미지 샘 플의 3차원 얼굴 템플릿 이미지 샘플 특징을 획득하기 위해 얼굴 이미지 샘플과 얼굴 템플릿 이미지 샘플에 대 해 3차원 얼굴 모델링을 수행하는 단계; 얼굴 이미지 처리 모델을 사용하여, 융합 이후의 3차원 얼굴 이미지 샘플 특징을 획득하기 위해 3차원 얼굴 이 미지 샘플 특징과 3차원 얼굴 템플릿 이미지 샘플 특징을 융합하는 단계; 얼굴 이미지 처리 모델을 사용하여, 초기 얼굴 교체 샘플 특징을 획득하기 위해 얼굴 템플릿 이미지 샘플에 기 초하여 얼굴 이미지 샘플에 대해 얼굴 교체 특징 추출을 수행하는 단계; 얼굴 이미지 처리 모델을 사용하여, 타깃 얼굴 교체 샘플 특징을 획득하기 위해 융합 이후의 3차원 얼굴 이미지 샘플 특징에 기초하여 초기 얼굴 교체 샘플 특징을 변환하는 단계; 및 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 샘플 특징 및 얼굴 이 미지 샘플의 얼굴 특징에 기초하여 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 얼굴 이미지 샘플의 소스 얼굴로 교체하는 단계를 포함한다. 예를 들어, 도 6에 도시된 바와 같이, 3차원 얼굴 모델링은 얼굴 이미지 샘플의 3차원 얼굴 이미지 샘플 특징 및 얼굴 템플릿 이미지 샘플의 3차원 얼굴 템플릿 이미지 샘플 특징을 획득하기 위해 얼굴 템플릿 이미지 샘플 및 얼굴 이미지 샘플에 대해 수행될 수 있다. 그 다음, 얼굴 이미지 처리 모델은 융합 이후의 3차원 얼굴 이미 지 샘플 특징을 획득하기 위해 3차원 얼굴 이미지 샘플 특징과 3차원 얼굴 템플릿 이미지 샘플 특징을 융합할 수 있다. 또한, 얼굴 이미지 처리 모델은 초기 얼굴 교체 샘플 특징을 획득하기 위해 얼굴 템플릿 이미지 샘플 에 기초하여 얼굴 이미지 샘플에 대해 얼굴 교체 특징 추출을 수행한다. 이후, 미리 설정된 얼굴 이미지 처리 모델은 AdaIN을 사용하여 초기 얼굴 교체 샘플 특징에 융합 이후의 3차원 얼굴 이미지 샘플 특징을 주입할 수 있다. 도 6에서의 3차원 특징은 융합 이후의 3차원 얼굴 이미지 샘플 특징을 포함할 수 있다. 단계 203: 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대해 3차원 얼 굴 윤곽 포인트 검출을 수행하고, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행한다. 3차원 얼굴 윤곽 포인트는 3차원 공간의 관점에서 이미지의 얼굴 윤곽을 설명하는 정보 포인트를 포함한다. 예 를 들어, 예측된 얼굴 이미지에서 예측된 얼굴의 윤곽 정보는 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 통해 알 수 있다. 다른 예로, 얼굴 참조 이미지 샘플의 얼굴 윤곽 정보는 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 통해 알 수 있다. 일부 실시예에서, 얼굴 이미지 처리의 정확도를 향상시키기 위해, 본 출원의 본 실시예에서, 얼굴 이미지 처리 모델은 3차원 얼굴 윤곽 포인트를 사용하여 훈련될 수 있다. 따라서, 3차원 얼굴 윤곽 포인트는 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대해 수행될 수 있고, 얼굴 참조 이미 지 샘플에 대한 3차원 얼굴 윤곽 포인트 검출은 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기위해 수행될 수 있다. 예를 들어, 예측된 얼굴 이미지는 3차원 공간에 투영될 수 있고, 3차원 공간은 예측된 얼굴 이미지의 3차원 얼 굴 윤곽 포인트를 위해 검색될 수 있다. 다른 예에서, 3차원 얼굴 모델링은 예측된 얼굴 이미지의 3차원 예측된 얼굴 이미지 특징을 획득하기 위해 예측 된 얼굴 이미지에 대해 수행될 수 있다. 3차원 키 포인트 투영은 예측된 얼굴 이미지의 3차원 얼굴 키 포인트 를 획득하기 위해 3차원 예측된 얼굴 이미지 특징에 대해 수행된다. 3차원 얼굴 윤곽 포인트는 3차원 얼굴 키 포인트에 기초하여 3차원 얼굴 키 포인트에서 선택된다. 3차원 예측된 얼굴 이미지 특징은 3차원 공간에서 예측된 얼굴 이미지의 특성을 지시할 수 있다. 예를 들어, 3 차원 예측된 얼굴 이미지 특징은 예측 얼굴 이미지에서 예측된 얼굴의 얼굴 특징, 얼굴 윤곽, 텍스처, 각도 및 조도와 같은 정보를 지시할 수 있다. 3차원 예측된 얼굴 이미지 특징은 복수의 특징을 포함할 수 있다. 특징은 공동으로 3차원 예측된 얼굴 이미지 특징을 구성한다. 예를 들어, 3차원 예측된 얼굴 이미지 특징은 예측된 얼굴 아이덴티티 특징, 예측된 얼굴 표 정 특징, 예측된 얼굴 텍스처 특징, 예측된 얼굴 각도 특징, 예측된 얼굴 조도 특징 등을 포함할 수 있다. 3차원 얼굴 키 포인트는 예측된 얼굴의 정보를 갖는 복수의 키 포인트, 예를 들어 예측된 얼굴의 특징을 지시하 기 위해 사용되는 모든 키 포인트를 포함한다. 일부 실시예에서, 도 6에 도시된 바와 같이, 3차원 얼굴 모델링은 도 6에서의 018과 같이 예측된 얼굴 이미지의 3차원 예측된 얼굴 이미지 특징을 획득하기 위해 예측된 얼굴 이미지에 대해 수행될 수 있다. 그 다음, 3차원 키 포인트 투영은 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 3차원 예측된 얼굴 이미지 특징 에 대해 수행된다. 그 후, 3차원 얼굴 윤곽 포인트가 도 6에서의 019와 같이 3차원 얼굴 키 포인트에 기초하여 3차원 얼굴 키 포인트에서 선택될 수 있다. 일부 실시예에서, 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 3차원 예측된 얼굴 이미지 특징 에 대해 투영 함수를 사용하여 3차원 키 포인트 투영이 수행될 수 있다. 예를 들어, 예측된 얼굴 이미지의 3차 원 얼굴 키 포인트를 획득하기 위해 다음의 수학식 result_3d_points = reconstruction_without_tex(result_3d_feature) 에 따라 3차원 예측된 얼굴 이미지 특징에 대해 3차원 키 포인트 투영이 수행되며, 여기서 result_3d_points는 3차원 얼굴 키 포인트일 수 있고, result_3d_feature는 3차원 예측된 얼굴 이미지 특징일 수 있으며, reconstruction_without_tex()는 투영 함수일 수 있다. 투영 함수는 다양한 유형의 함수일 수 있다. 예를 들어, 투영 함수는 개방형 그래픽 라이브러리(OpenGL)에서 glOrtho(), glFrustum(), gluPerspective() 등이 될 수 있다. 일부 실시예에서, 예측된 얼굴 이미지의 3차원 얼굴 키 포인트는 예측된 얼굴 아이덴티티 특징 및 예측된 얼굴 표정 특징에 기초하여 획득될 수 있다. 예를 들어, 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위 해 3차원 예측된 얼굴 이미지 특징에 대해 3차원 키 포인트 투영을 수행하는 단계는, 3차원 예측된 얼굴 이미지 특징으로부터 예측된 얼굴 이미지의 예측된 얼굴 아이덴티티 특징 및 예측된 얼굴 표 정 특징을 추출하는 단계; 및 미리 설정된 전달 파라미터를 사용하여, 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 예측된 얼굴 아이덴티티 특징 및 예측된 얼굴 표정 특징에 대해 3차원 키 포인트 투영을 수행하는 단계를 포함한다. 미리 설정된 전달 파라미터는 정보 전달을 실현할 수 있는 미리 설정된 파라미터를 포함한다. 일부 실시예에서, 3차원 키 포인트 투영은 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 다음의 수학식 result_3d_points = idBase * id_coeff + exBase * ex_coeff + meanshape 에 따라 예측된 얼굴 아이덴티티 특징 및 예측된 얼굴 표정 특징에 대해 수행될 수 있으며, 여기서 id_coeff는 예측된 얼굴 아이덴티티 특징일 수 있고, ex_coeff는 예측된 얼굴 표현 특징일 수 있으며, idBase, exBase 및 meanshape는 미리 설정된 전달 파라미터일 수 있다.일부 실시예에서, 3차원 얼굴 키 포인트가 획득된 후, 3차원 얼굴 키 포인트에 기초하여 3차원 얼굴 키 포인트 로부터 3차원 얼굴 윤곽 포인트가 선택될 수 있다. 예를 들어, 3차원 얼굴 키 포인트의 위치 정보가 획득될 수 있고, 그 다음 3차원 얼굴 키 포인트의 위치 정보에 기초하여 3차원 얼굴 키 포인트에서 3차원 얼굴 윤곽 포인트가 선택된다. 예를 들어, 에지 상에 위치 정보가 있는 3차원 얼굴 키 포인트가 3차원 얼굴 윤곽 포인트로 결정될 수 있다. 다른 예에서, 3차원 얼굴 윤곽 포인트는 3차원 얼굴 키 포인트의 출력 순서에 따라 선택될 수 있다. 일부 실시 예에서, 3차원 얼굴 키 포인트의 출력 순서는 미리 설정된 설정에 따라 지정된다. 예를 들어, 68개의 3차원 얼 굴 키 포인트가 제공되며, 그 중 처음 17개의 3차원 얼굴 키 포인트가 3차원 얼굴 윤곽 포인트이다. 따라서, 출력 순서가 처음 17개 위치에 있는 3차원 얼굴 키 포인트가 3차원 얼굴 윤곽 포인트로 결정될 수 있다. 단계 204: 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이를 획득한다. 일부 실시예에서, 3차원 얼굴 윤곽 포인트가 획득된 후, 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차 원 얼굴 윤곽 포인트 사이의 차이가 계산될 수 있다. 예를 들어, 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이가 계산될 수 있다. 다른 예에서, 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 코사 인 유사도가 계산될 수 있다. 예를 들어, 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이는 다음의 수학식 3d_point_loss = abs(gt_3d_OutlookPoint - result_3d_OutlookPoint) 에 따라 계산될 수 있으며, 여기서 gt_3d_OutlookPoint는 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트일 수 있고, result_3d_OutlookPoint는 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트일 수 있으며, 3d_point_loss는 얼굴 윤곽 손실일 수 있고, abs()는 절대값 값 심볼일 수 있다. 일부 실시예에서, 훈련된 얼굴 이미지 처리 모델이 요구사항을 충족하는 이미지를 생성할 수 있도록 훈련된 얼 굴 이미지 처리 모델의 성능을 향상시키기 위해, 손실은 복수의 다른 차원으로부터 계산될 수 있고, 미리 설정 된 얼굴 이미지 처리 모델은 얼굴 윤곽 손실 및 다른 차원의 손실을 사용하여 조정된다. 즉, 얼굴 이미지 처리 모델의 모델 파라미터는 얼굴 윤곽 손실 및 다른 차원의 손실과 함께 업데이트된다. 예를 들어, 도 6에 도시된 바와 같이, 미리 설정된 얼굴 이미지 처리 모델이 얼굴 윤곽 손실 외에 다른 손실을 사용하여 조정될 수 있도록 얼굴 이미지 샘플과 예측된 얼굴 이미지 사이의 얼굴 특징 손실이 계산될 수 있다. 예를 들어, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 제1 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 3차원 얼굴 윤곽 포인트 이외의 예측된 얼굴 이미지 사이의 차이가 계산된다. 제1 손실은 얼굴 윤곽 손 실 이외의 손실을 포함한다. 얼굴 이미지 샘플과 예측된 얼굴 이미지 사이의 얼굴 특징 손실이 계산되고, 제1 손실과 얼굴 특징 손실이 융합 되어 제2 손실을 획득한다. 이와 같이, 얼굴 이미지 처리 모델의 모델 파라미터는 제2 손실에 기초하여 업데이 트될 수 있다. 얼굴 윤곽 손실 이외의 손실은 다른 차원의 손실을 포함할 수 있다. 예를 들어, 다른 차원의 손실은 픽셀 손실, 특징 손실 및 판별 손실 중 적어도 하나를 포함할 수 있다. 픽셀 손실은 얼굴 참조 이미지 샘플 및 예측된 얼굴 이미지의 픽셀 레벨 손실을 포함할 수 있다. 특징 손실은 얼굴 참조 이미지 샘플 및 예측된 얼굴 이미지의 특징 레벨 손실을 포함할 수 있다. 예를 들어, 특징 손실은 얼굴 참조 이미지 샘플의 얼굴과 예측된 얼굴 이미지의 예측된 얼굴 사이의 차이를 지칭할 수 있다. 일부 실시예에서, 얼굴 이미지 처리 모델은 판별기를 포함한다. 판별기의 기능은 생성기에 의해 생성된 이미지 가 실제 이미지인지 여부를 판별하는 것이다. 따라서, 판별 손실은 판별기가 얼굴 참조 이미지 샘플과 예측된얼굴 이미지를 판별한 후에 생성된 정보를 포함할 수 있다. 일부 실시예에서, 제1 손실이 픽셀 손실, 특징 손실 및 판별 손실을 포함하는 경우, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 제1 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 3차원 얼굴 윤곽 포인트 이외의 예측된 얼굴 이미지 사이의 차이를 계산하는 단계는, 픽셀 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 픽셀 차이를 계산하는 단계; 특징 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 특징 차이를 계산하는 단계; 및 판별 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 판별 차이를 계산하는 단계를 포함한다. 일부 실시예에서, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 픽셀 차이가 계산되는 경우, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지의 픽셀 정보가 추출된 다음, 픽셀 정보 사이의 차이가 추출되어 픽셀 손실을 획득할 수 있다. 예를 들어, 색상 채널 상의 얼굴 참조 이미지 샘플의 값과 색상 채널 상의 예측된 얼굴 이미지의 값이 추출되어 감산된 후, 절대값이 계산되어 픽셀 손실을 획득할 수 있다. 예를 들어, 픽셀 손실은 다음의 수학식 Resconstructionloss = abs(result-gt_img) 에 의해 표현될 수 있으며, 여기서 result는 예측된 얼굴 이미지의 픽셀 정보일 수 있고, gt_img는 얼굴 참조 이미지 샘플의 픽셀 정보일 수 있으며, Resconstructionloss는 픽셀 손실일 수 있다. 일부 실시예에서, 특징 추출이 얼굴 이미지 처리 모델에서 3차원 공간 및 2차원 공간의 이미지에 대해 수행될 수 있으므로, 특징 손실은 2차원 특징 손실 및 3차원 특징 손실을 포함할 수 있다. 이에 상응하여, 특징 손실 을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 특징 차이를 계산하는 단계는, 2차원 특징 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 2차원 특징 차이를 계산 하는 단계; 3차원 특징 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 3차원 특징 차이를 계산 하는 단계; 및 특징 손실을 획득하기 위해 2차원 특징 손실과 3차원 특징 손실을 융합하는 단계를 포함할 수 있다. 2차원 특징 차이는 2차원 공간에서 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 특징 차이를 포함할 수 있다. 예를 들어, 2차원 특징 차이는 얼굴 참조 이미지 샘플의 이미지 특징과 예측된 얼굴 이미지의 이미지 특 징 사이의 차이를 포함할 수 있다. 3차원 특징 차이는 3차원 공간에서 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 특징 차이를 포함할 수 있다. 예를 들어, 3차원 특징 차이는 얼굴 참조 이미지 샘플의 3차원 얼굴 참조 이미지 샘플 특징과 예측된 얼 굴 이미지의 3차원 예측된 얼굴 이미지 특징 사이의 차이를 포함할 수 있다. 일부 실시예에서, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 2차원 특징 차이가 계산되는 경우, 얼굴 참조 이미지 샘플의 이미지 특징과 예측된 얼굴 이미지의 이미지 특징을 획득하기 위해 얼굴 참조 이미지 샘플 과 예측된 얼굴 이미지 각각에 대해 특징 추출이 수행될 수 있고, 그 다음 얼굴 참조 이미지 샘플의 이미지 특 징과 예측된 얼굴 이미지의 이미지 특징 사이의 차이가 계산된다. 예를 들어, 얼굴 참조 이미지 샘플의 이미지 특징 및 예측된 얼굴 이미지의 이미지 특징을 획득하기 위해 Alexnet를 사용하여 얼굴 참조 이미지 샘플 및 예측된 얼굴 이미지에 대해 특징 추출이 수행될 수 있다. Alexnet는 5개의 컨볼루션 계층과 3개의 완전 연결 계층으로 형성된다. 5개의 컨볼루션 계층은 이미지에 대한 특징 추출을 수행하도록 구성될 수 있으며, 정보 전달 관계에 있다. 예를 들어, 제1 컨볼루션 계층은 이미지에 서 특징을 추출한 후, 추출된 정보를 제2 컨볼루션 계층으로 전달할 수 있다. 그 다음, 제2 컨볼루션 계층은 제1 컨볼루션 계층에 의해 추출된 특징에서 특징을 연속적으로 추출하고, 추출된 특징을 제3 컨볼루션 계층으로 전달할 수 있다. 유추하여, 마지막으로, 제5 컨볼루션 계층은 추출된 특징을 완전 연결 계층으로 전달할 수 있다. 일부 실시예에서, 얼굴 참조 이미지 샘플의 이미지 특징과 예측된 얼굴 이미지의 이미지 특징 사이의 차이는 다 양한 방식으로 계산될 수 있다. 예를 들어, 얼굴 참조 이미지 샘플의 이미지 특징과 예측된 얼굴 이미지의 이미지 특징 사이의 차이는 학습된 지각 이미지 패치 유사도(learned perceptual image patch similarity, LPIPS) 메트릭을 사용하여 계산될 수 있다. 다른 예에서, 2차원 특징 손실은 차이를 계산함으로써 계산될 수 있다. 다른 예에서, 2차원 특징 손실 은 코사인 유사도 등을 사용하여 계산될 수 있다. 일부 실시예에서, Alexnet에 의해 이미지에 대해 특징 추출이 수행되는 경우, 각각의 컨볼루션 계층에서 얼굴 참조 이미지 샘플의 이미지 특징과 예측된 얼굴 이미지의 이미지 특징 사이의 차이가 계산될 수 있다. 예를 들어, gt_img_feal1, gt_img_feal2, gt_img_feal3 및 gt_img_feal4를 획득하기 위해 Alexnet에 의해 얼굴 참조 이미지 샘플에 대해 특징 추출이 수행된다. gt_img_feal1, gt_img_feal2, gt_img_feal3 및 gt_img_feal4 는 Alexnet에서 4개의 컨볼루션 계층에 의해서 출력되는 얼굴 참조 이미지 샘플의 특징을 지칭할 수 있다. 유사하게, result_feal1, result_feal2, result_feal3 및 result_feal4를 획득하기 위해 Alexnet에 의해 예측 된 얼굴 이미지에 대해 특징 추출이 수행될 수 있다. result_feal1, result_feal2, result_feal3 및 result_feal4는 Alexnet에서 4개의 컨볼루션 계층에 의해 출력되는 예측된 얼굴 이미지의 특징을 지칭할 수 있 다. 그 다음, 다음의 수학식"}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "따라 2차원 특징 손실이 계산될 수 있으며, 여기서 Two_loss는 2차원 특징 손실일 수 있다. 일부 실시예에서, 얼굴 참조 이미지 샘플의 3차원 얼굴 참조 이미지 샘플 특징 및 예측된 얼굴 이미지의 3차원 예측된 얼굴 이미지 특징을 획득하기 위해 얼굴 참조 이미지 샘플 및 예측된 얼굴 이미지에 대해 얼굴 모델링이 수행될 수 있고, 그 다음 3차원 얼굴 참조 이미지 샘플 특징과 3차원 예측된 얼굴 이미지 특징 사이의 차이가 계산될 수 있다. 일부 실시예에서, 3차원 얼굴 참조 이미지 샘플 특징과 3차원 예측된 얼굴 이미지 특징 사이의 차이는 또한 다 양한 방식으로 계산될 수 있다. 예를 들어, 3차원 특징 손실은 LPIPS를 사용하여 계산될 수 있다. 다른 예에 서, 3차원 특징 손실은 차이를 계산함으로써 계산될 수 있다. 다른 예에서, 3차원 특징 손실은 코사인 유사도 등을 사용하여 계산될 수 있다. 일부 실시예에서, 3차원 특징 손실은 다음의 수학식"}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "에 따라 계산될 수 있으며, 여기서 는 3차원 특징 손실을 나타낼 수 있고, 는 3차원 얼굴 참조 이미지 샘플 특징 을 나타낼 수 있으며, 는 3차원 예측된 얼굴 이미지 특징을 나타낼 수 있다. 일부 실시예에서, 2차원 특징 손실 및 3차원 특징 손실이 획득된 후, 2차원 특징 손실 및 3차원 특징 손실은 특 징 손실을 획득하기 위해 융합될 수 있다. 예를 들어, 2차원 특징 손실과 3차원 특징 손실은 특징 손실을 획득 하기 위해 더해질 수 있다. 다른 예에서, 2차원 특징 손실 및 3차원 특징 손실은 특징 손실을 획득하기 위해 가중치화된 다음 합산될 수 있다. 일부 실시예에서, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 판별 차이가 계산되는 경우, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지는 스케일링될 수 있고, 스케일링된 이미지는 판별기를 사용하여 판별되어 판 별 손실의 풍부함을 향상시킬 수 있다. 예를 들어, 적어도 하나의 스케일링된 얼굴 참조 이미지 샘플 및 적어도 하나의 스케일링된 예측된 얼굴 이미지를 획득하기 위해 얼굴 참조 이미지 샘플 및 예측된 얼굴 이미지가 각 각 스케일링된다. 적어도 하나의 스케일링된 얼굴 참조 이미지 샘플 및 적어도 하나의 스케일링된 예측된 얼굴 이미지는 스케일링 된 얼굴 참조 이미지 샘플의 제1 판별 특징 및 스케일링된 예측된 얼굴 이미지의 제2 판별 특징을 획득하기 위 해 각각 판별된다. 판별 손실은 제1 판별 특징 및 제2 판별 특징에 기초하여 계산된다. 스케일링은 이미지의 크기를 변경하는 것을 의미할 수 있다. 예를 들어, 이미지의 크기는 세로 256 × 가로 256이고, 이미지 크기가 스케일링을 통해 세로 128 × 가로 128로 변경될 수 있다. 예를 들어, 얼굴 참조 이미지 샘플의 원래 크기는 a이며, 이는 1/2a 크기의 얼굴 참조 이미지 샘플과 1/4a 크기 의 얼굴 참조 이미지 샘플을 획득하기 위해 스케일링될 수 있다. 유사하게, 예측된 얼굴 이미지의 원래 크기가 b라고 가정하면, 1/2b 크기의 예측된 얼굴 이미지와 1/4b 크기의 예측된 얼굴 이미지가 스케일링을 통해 획득될 수 있다. 그 다음, 적어도 하나의 스케일링된 얼굴 참조 이미지 샘플 및 적어도 하나의 스케일링된 예측된 얼굴 이미지가 각각 판별되어 스케일링된 얼굴 참조 이미지 샘플의 제1 판별 특징 및 스케일링된 예측된 얼굴 이미지의 제2 판 별 특징을 획득할 수 있다. 예를 들어, 원래 크기 a의 얼굴 참조 이미지 샘플, 1/2a 크기의 얼굴 참조 이미지 샘플, 1/4a 크기의 얼굴 참조 이미지 샘플이 판별기에 입력되어 판별 결과를 획득할 수 있다. 예를 들어, 원래 크기 a의 얼굴 참조 이미지 샘플, 1/2a 크기의 얼굴 참조 이미지 샘플 및 1/4a 크기의 얼굴 참 조 이미지 샘플이 판별기에 입력된 후, 획득되는 판별 결과는 각각 D(gt_img), D(gt_img_1/2) 및 D(gt_img_1/4)이다. 심볼 D()는 판별기의 판별 결과를 나타낼 수 있다. gt_img는 원래 크기가 a인 얼굴 참조 이미지 샘플을 지칭할 수 있고, gt_img_1/2는 1/2a 크기의 얼굴 참조 이미지 샘플을 지칭할 수 있으며, gt_img_1/4는 1/4a 크기의 얼굴 참조 이미지 샘플을 지칭할 수 있다. 일부 실시예에서, 판별 결과는 일반적으로 특징에 의해 표현된다. 예를 들어, D()는 일반적으로 0에서 1 사이 의 값이다. 판별 결과가 1인 경우, 이미지가 판별을 통과했음을 지시한다. 판별 결과가 0인 경우, 이미지가 판별에 실패했음을 지시한다. 예를 들어, 제1 판별 특징은 D(gt_img), D(gt_img_1/2), 및 D(gt_img_1/4)를 포함할 수 있다. 다른 예에서, 원래 크기가 b인 예측된 얼굴 이미지, 1/2b 크기의 예측된 얼굴 이미지 및 1/4b 크기의 예측된 얼 굴 이미지가 판별 결과를 획득하기 위해 판별기로 입력될 수 있다. 예를 들어, 원래 크기가 b인 예측된 얼굴 이미지, 1/2b 크기의 예측된 얼굴 이미지, 및 1/4b 크기의 예측된 얼 굴 이미지가 판별기에 입력된 후, 획득되는 판별 결과는 각각 D(result), D(result_1/2), 및 D(result_1/4)이 다. result는 원래 크기가 b인 예측된 얼굴 이미지를 지칭할 수 있고, result_1/2는 1/2b 크기의 예측된 얼굴 이미지를 지칭할 수 있으며, result_1/4는 1/4b 크기의 예측된 얼굴 이미지를 지칭할 수 있다. 제2 판별 특징은 판별기의 판별 결과를 포함할 수 있다. 예를 들어, 제2 판별 특징은 D(result), D(result_1/2), 및 D(result_1/4)를 포함할 수 있다. 일부 실시예에서, 판별 손실은 차이를 계산함으로써 계산될 수 있다. 다른 예로, 판별 손실은 코사인 유사도 등을 사용하여 계산될 수 있다. 일부 실시예에서, 판별 손실은 다음의 방식 D_loss = 1/3 * (-logD(gt_img) - logD(result) - logD(gt_img_1/2) - logD(result_1/2) - logD(gt_img_1/4) - logD(result_1/4)) 으로 계산될 수 있으며, 여기서 D_loss는 판별 손실일 수 있다. 일부 실시예에서, 예측된 얼굴 이미지에서 예측된 얼굴의 아이덴티티 특징을 얼굴 이미지 샘플에서 소스 얼굴의 아이덴티티 특징과 가능한 한 유사하게 만들기 위해, 얼굴 이미지 샘플과 예측된 얼굴 이미지 사이의 얼굴 특징 손실이 또한 계산될 수 있다. 예를 들어, 예측된 얼굴 이미지의 얼굴 특징 및 얼굴 이미지 샘플의 얼굴 특징을 획득하기 위해 예측된 얼굴 이 미지 및 얼굴 이미지 샘플에 대해 얼굴 특징 추출이 수행될 수 있다. 그 다음, 예측된 얼굴 이미지의 얼굴 특 징과 얼굴 이미지 샘플의 얼굴 특징 사이의 얼굴 특징 손실이 계산된다. 일부 실시예에서, 2차원 특징 손실은 차이를 계산함으로써 계산될 수 있다. 다른 예에서, 2차원 특징 손실은 코사인 유사도 등을 사용하여 계산될 수 있다. 일부 실시예에서, 2차원 특징 손실은 다음의 수학식"}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "에 따라 계산될 수 있으며, 여기서 idloss는 2차원 특징 손실일 수 있고, 는 예측된 얼굴 이미지의 얼굴 특징일 수 있으며, 는 얼굴 이미지 샘플의 얼굴 특징일 수 있다. cosinesimilarity는 코사인 유사도의 계산 방식일 수 있 으며, 여기서 cosinesimilarity는,"}
{"patent_id": "10-2022-7041706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "과 같이 표현될 수 있으며, 여기서 A와 B는 벡터일 수 있고, Ai는 벡터 A의 성분일 수 있으며, Bi는 벡터 B의 성분일 수 있고, i는 i번째 성 분을 지칭할 수 있으며, n은 벡터의 총 성분 수량을 지칭할 수 있다. 일부 실시예에서, 제1 손실 및 얼굴 특징 손실이 획득된 후, 제1 손실 및 얼굴 특징 손실은 제2 손실을 획득하 기 위해 융합될 수 있다. 예를 들어, 제1 손실과 얼굴 특징 손실은 제2 손실을 획득하기 위해 합산될 수 있다. 다른 예에서, 제1 손실과 얼굴 특징 손실은 제2 손실을 획득하기 위해 가중치화되고 합산될 수 있다. 단계 205: 얼굴 윤곽 손실에 기초하여 얼굴 이미지 처리 모델의 모델 파라미터를 업데이트한다. 일부 실시예에서, 얼굴 이미지 처리 모델의 모델 파라미터는 얼굴 윤곽 손실에 기초하여 업데이트될 수 있다. 즉, 얼굴 이미지 처리 모델은 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 조정된다. 예를 들어, 도 6에 도시된 바와 같이, 얼굴 윤곽 손실이 획득된 후, 얼굴 윤곽 손실을 사용하여 예측된 얼굴 이 미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트가 일치하도록 제한될 수 있 다. 예를 들어, 미리 설정된 얼굴 이미지 처리 모델의 모델 파라미터는 조정된 얼굴 이미지 처리 모델을 획득하기 위해 얼굴 윤곽 손실에 기초하여 조정될 수 있다. 그런 다음, 훈련 이미지 샘플 그룹을 사용하여 조정된 얼굴 이미지 처리 모델이 훈련된다. 얼굴 윤곽 손실 정보가 위의 반복 연산을 통해 일정 정도 미만이거나 요구사항 을 충족하는 경우, 훈련 목적이 달성되었음을 지시한다. 이 경우, 성능이 또한 요구사항을 충족하는 훈련된 이 미지 처리 모델이 또한 획득될 수 있다. 일부 실시예에서, 얼굴 윤곽 손실과 제2 손실은 또한 제3 손실을 획득하기 위해 융합될 수 있고, 그 다음 이미 지 처리 모델은 제3 손실을 사용하여 조정된다. 즉, 얼굴 이미지 처리 모델의 모델 파라미터는 훈련된 얼굴 이 미지 처리 모델을 획득하기 위해 제3 손실을 사용하여 업데이트된다. 예를 들어, 얼굴 이미지 처리 모델의 모 델 파라미터가 획득된다. 얼굴 윤곽 손실과 제2 손실은 제4 손실을 획득하기 위해 융합된다. 모델 파라미터는 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 제3 손실을 사용하여 조정된다. 예를 들어, 얼굴 윤곽 및 제2 손실은 제3 손실을 획득하기 위해 합산될 수 있다. 그런 다음, 미리 설정된 얼굴 이미지 처리 모델의 모델 파라미터는 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 제3 손실을 사용하여 조정 된다. 일부 실시예에서, 훈련 동안, 미리 설정된 얼굴 이미지 처리 모델은 얼굴 교체를 실현하는 방법을 학습한 후, 예를 들어 도 6에 도시된 바와 같이, 이미지의 3차원 특징을 예측하기 위해 3차원 특징을 학습할 수 있다. 본 출원의 본 실시예에서, 훈련 이미지 샘플 그룹이 획득될 수 있다. 훈련 이미지 샘플 그룹은 얼굴 이미지 샘 플, 얼굴 템플릿 이미지 샘플, 및 얼굴 참조 이미지 샘플을 포함한다. 얼굴 템플릿 이미지 샘플의 템플릿 얼굴 은 얼굴 이미지 처리 모델을 사용하여 예측된 얼굴 이미지를 획득하기 위해 얼굴 이미지 샘플의 소스 얼굴로 교 체된다. 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대해 3차원 얼 굴 윤곽 포인트 검출이 수행되고, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출이 수행된다. 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘 플의 3차원 얼굴 윤곽 포인트 사이의 차이가 계산된다. 얼굴 이미지 처리 모델은 훈련된 얼굴 이미지 처리 모 델을 획득하기 위해 얼굴 윤곽 손실에 기초하여 조정된다. 얼굴 이미지 처리 모델은 3차원 얼굴 윤곽 포인트를 사용하여 훈련되므로, 훈련된 얼굴 이미지 처리 모델을 사용하여 얼굴 템플릿 이미지의 템플릿 얼굴이 소스 얼 굴로 교체되는 경우, 소스 얼굴의 얼굴 윤곽이 교체 이후에 획득된 얼굴 이미지에서 유지될 수 있고, 얼굴 이미 지 처리 방법의 정확도가 향상된다. 또한, 본 출원의 본 실시예에서, 손실 정보는 복수의 상이한 차원에 대해 계산되고, 미리 설정된 얼굴 이미지 처리 모델은 복수의 차원에 대한 손실을 사용하여 조정되므로, 미리 설정된 얼굴 이미지 처리 모델이 복수 차원 에 대한 손실을 사용하여 상이한 차원의 파라미터를 조정할 수 있고, 훈련된 얼굴 이미지 처리 모델의 성능이 더 좋아질 수 있다. 전술한 실시예에서 설명된 방법에 따르면, 이하에서는 예시를 사용하여 상세한 설명을 추가로 제공한다. 본 출원의 본 실시예에서, 본 출원의 본 실시예에 따른 방법은 얼굴 이미지 처리 모델의 훈련이 컴퓨터 장치에 통합되는 예와 함께 소개된다. 일부 실시예에서, 도 7에 도시된 바와 같이, 얼굴 이미지 처리 모델 훈련 방법은 다음의 단계를 포함한다. 단계 301: 컴퓨터 장치가 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈 련 이미지 샘플 그룹을 획득한다. 예를 들어, 얼굴 이미지 샘플은 소스로서 표현될 수 있고, 얼굴 템플릿 이미지 샘플은 타깃으로서 표현될 수 있 으며, 얼굴 참조 이미지 샘플은 gt_img로서 표현될 수 있다. 단계 302: 컴퓨터 장치는 미리 설정된 얼굴 이미지 처리 모델을 사용하여 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 얼굴 이미지 샘플의 소스 얼굴로 교체한다. 예를 들어, 컴퓨터 장치는 소스 및 타깃을 미리 설정된 얼굴 이미지 처리 모델의 인코더에 입력할 수 있다. 인 코더는 소스의 해상도와 타깃의 해상도를 지속적으로 감소시키고, 은닉 공간에서 소스 및 타깃을 초기 얼굴 교 체 샘플 특징으로서 인코딩할 수 있다. 또한, 컴퓨터 장치는 소스의 얼굴 특징 source_id_feature를 획득하기 위해 얼굴 특징 추출 네트워크를 사용하 여 소스에 대한 특징 추출을 수행할 수 있다. 또한, 컴퓨터 장치는 얼굴 이미지 샘플의 3차원 얼굴 이미지 샘플 특징 및 얼굴 템플릿 이미지 샘플의 3차원 얼 굴 템플릿 이미지 샘플 특징을 획득하기 위해 소스 및 타겟에 대한 3차원 얼굴 모델링을 추가로 수행할 수 있다. 그런 다음, 컴퓨터 장치는, 미리 설정된 얼굴 이미지 처리 모델을 사용하여, 타깃 얼굴 교체 샘플 특징을 획득 하기 위해 융합 이후의 3차원 얼굴 이미지 샘플 특징에 기초하여 초기 얼굴 교체 샘플 특징을 변환할 수 있다. 그 후, 컴퓨터 장치는, 미리 설정된 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 샘플 특징과 얼굴 이미지 샘플의 얼굴 특징에 기초하여 얼굴 템플릿 이미지 샘플의 템플릿 얼굴 을 얼굴 이미지 샘플의 소스 얼굴로 교체할 수 있다. 그 결과로 예측된 얼굴 이미지가 표현될 수 있다. 단계 303: 컴퓨터 장치는 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하고, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행한다. 예를 들어, 컴퓨터 장치는 결과의 3차원 예측된 얼굴 이미지 특징(result_3d_feature로 표현될 수 있음)을 계산 할 수 있다. 그 다음, 컴퓨터 장치는 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 3차원 예측된 얼굴 이미 지 특징에 대해 3차원 키 포인트 투영을 수행할 수 있다. 예를 들어, 3차원 얼굴 키 포인트는 다음의 수학식 result_3d_points = reconstruction_without_tex(result_3d_feature) 에 의해 표현된다. 그 후, 컴퓨터 장치는 3차원 얼굴 키 포인트에 기초하여 3차원 얼굴 키 포인트로부터 3차원 얼굴 윤곽 포인트를 선택할 수 있다. 유사하게, 컴퓨터 장치는 gt_img의 3차원 얼굴 템플릿 이미지 샘플 특징(gt_3d_feature로 표현될 수 있음)을 계 산할 수 있다. 그 다음, 컴퓨터 장치는 얼굴 참조 이미지 샘플의 3차원 얼굴 키 포인트를 획득하기 위해 3차원 얼굴 템플릿 이 미지 샘플 특징에 대해 3차원 키 포인트 투영을 수행할 수 있다. 예를 들어, 3차원 얼굴 키 포인트는 다음의 수학식 gt_3d_points = reconstruction_without_tex(gt_3d_feature) 에 의해 표현되며, 여기서 gt_3d_points는 얼굴 참조 이미지 샘플의 3차원 얼굴 키 포인트일 수 있다. 단계 304: 컴퓨터 장치는 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이 를 계산한다. 예를 들어, 얼굴 윤곽 손실은 다음의 수학식 3d_point_loss = abs(gt_3d_OutlookPoint - result_3d_OutlookPoint) 에 따라 계산될 수 있다. 일부 실시예에서, 다른 손실이 또한 계산될 수 있고, 미리 설정된 얼굴 이미지 처리 모델은 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 얼굴 윤곽 손실 및 기타 손실을 함께 사용하여 조정된다. 예를 들어, 얼굴 특징 손실, 픽셀 손실, 특징 손실, 판별 손실 및 얼굴 윤곽 손실이 추가될 수 있다. 그런 다 음, 미리 설정된 얼굴 이미지 처리 모델은 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 합산에 의해 획득되 는 손실을 사용하여 조정된다. 단계 305: 컴퓨터 장치는 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 얼굴 윤곽 손실에 기초하여 얼굴 이미 지 처리 모델의 모델 파라미터를 조정한다. 본 출원의 본 실시예에서, 컴퓨터 장치는 훈련 이미지 샘플 그룹을 획득할 수 있다. 훈련 이미지 샘플 그룹은 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플, 및 얼굴 참조 이미지 샘플을 포함한다. 컴퓨터 장치는, 미리 설 정된 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플 릿 얼굴을 얼굴 이미지 샘플의 소스 얼굴로 교체할 수 있다. 컴퓨터 장치는 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측된 얼굴 이미지에 대한 3차원 얼굴 윤곽 포인트 검출을 수행하고, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트를 획득하기 위해 얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행할 수 있다. 컴퓨터 장치는 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인 트 사이의 차이를 계산한다. 컴퓨터 장치는 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 얼굴 윤곽 손실 정 보에 기초하여 미리 설정된 얼굴 이미지 처리 모델을 조정한다. 미리 설정된 얼굴 이미지 처리 모델은 3차원 얼굴 윤곽 포인트를 사용하여 훈련되므로, 훈련된 얼굴 이미지 처리 모델을 사용하여 얼굴 템플릿 이미지의 템플릿 얼굴이 소스 얼굴로 교체되는 경우, 소스 얼굴의 얼굴 윤곽이 교체 이후에 획득되는 얼굴 이미지에서 유지 될 수 있고, 얼굴 이미지 처리 방법의 정확도가 향상된다. 본 출원의 본 실시예에서, 본 출원의 본 실시예에 따른 방법은 얼굴 이미지 처리 모델의 훈련이 컴퓨터 장치에 통합되는 예와 함께 소개된다. 일부 실시예에서, 도 8에 도시된 바와 같이, 얼굴 이미지 처리 방법은 다음의 단계를 포함한다. 단계 401: 컴퓨터 장치는 소스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획득한다. 단계 402: 컴퓨터 장치는 얼굴 이미지의 3차원 얼굴 이미지 특징 및 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미지에 대한 3차원 얼굴 모델링을 수행한다. 단계 403: 컴퓨터 장치는 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미 지 특징을 융합한다. 단계 404: 컴퓨터 장치는 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대한 얼굴 교체 특징 추출을 수행한다. 단계 405: 컴퓨터 장치는 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 초기 얼굴 교체 특 징을 변환한다. 단계 406: 컴퓨터 장치는, 훈련된 얼굴 이미지 처리 모델을 사용하여, 교체 이후의 얼굴 이미지를 획득하기 위 해 타깃 얼굴 교체 특징 및 얼굴 이미지의 얼굴 특징에 기초하여 얼굴 템플릿 이미지의 템플릿 얼굴을 소스 얼 굴로 교체한다. 본 출원의 본 실시예에서, 컴퓨터 장치는 소스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획 득한다. 컴퓨터 장치는 얼굴 이미지의 3차원 얼굴 이미지 특징 및 얼굴 템플릿 이미지의 3차원 얼굴 템플릿 이 미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행한다. 컴퓨터 장치는 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합한다. 컴퓨터 장치는 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대해 얼굴 교체 특징 추출을 수행한다. 컴퓨터 장치는 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징 에 기초하여 초기 얼굴 교체 특징을 변환한다. 컴퓨터 장치는, 훈련된 얼굴 이미지 처리 모델을 사용하여, 교 체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징 및 얼굴 이미지의 얼굴 특징에 기초하여 얼굴 템 플릿 이미지의 템플릿 얼굴을 소스 얼굴로 교체한다. 본 출원의 본 실시예에서, 2차원 공간 및 3차원 공간의 관점에서 얼굴 이미지 및 얼굴 템플릿 이미지의 더 많은 특징이 각각 획득될 수 있으므로, 얼굴 교체 처리에 더 많은 정보가 사용될 수 있고, 얼굴 이미지 처리 방법의 정확도가 향상된다. 본 출원의 본 실시예에 따른 얼굴 이미지 처리 방법을 더 잘 구현하기 위해, 본 출원의 실시예는 얼굴 이미지 처리 장치를 추가로 제공한다. 얼굴 이미지 처리 장치는 컴퓨터 장치에 통합될 수 있다. 용어는 전술한 얼굴 이미지 처리 방법과 동일한 의미를 갖는다. 구체적인 구현 세부사항에 대해, 방법 실시예의 설명이 참조될 수 있다. 일부 실시예에서, 얼굴 이미지 처리 장치가 제공된다. 얼굴 이미지 처리 장치는 컴퓨터 장치에 통합될 수 있다. 도 9에 도시된 바와 같이, 얼굴 이미지 처리 장치는 제1 획득 유닛, 3차원 얼굴 모델링 유닛, 제1 융합 유닛, 특징 추출 유닛, 변환 유닛 및 제1 교체 유닛을 포함하며, 이들은 구체적 으로 다음과 같다. 제1 획득 유닛은 소스 얼굴의 얼굴 이미지 및 템플릿 얼굴의 얼굴 템플릿 이미지를 획득하도록 구성된다. 3차원 얼굴 모델링 유닛은 얼굴 이미지의 3차원 얼굴 이미지 특징 및 얼굴 템플릿 이미지의 3차원 얼굴 템 플릿 이미지 특징을 획득하기 위해 얼굴 이미지 및 얼굴 템플릿 이미지에 대해 3차원 얼굴 모델링을 수행하도록 구성된다. 제1 융합 유닛은 3차원 융합 특징을 획득하기 위해 3차원 얼굴 이미지 특징과 3차원 얼굴 템플릿 이미지 특징을 융합하도록 구성된다. 특징 추출 유닛은 초기 얼굴 교체 특징을 획득하기 위해 얼굴 템플릿 이미지에 기초하여 얼굴 이미지에 대 해 얼굴 교체 특징 추출을 수행하도록 구성된다.변환 유닛은 타깃 얼굴 교체 특징을 획득하기 위해 3차원 융합 특징에 기초하여 초기 얼굴 교체 특징을 변 환하도록 구성된다. 제1 교체 유닛은 교체 이후의 얼굴 이미지를 획득하기 위해 타깃 얼굴 교체 특징에 기초하여 얼굴 템플릿 이미지의 템플릿 얼굴을 소스 얼굴로 교체하도록 구성된다. 일부 실시예에서, 제1 융합 유닛은, 3차원 얼굴 이미지 특징으로부터 얼굴 이미지에 대응하는 소스 얼굴 아이덴티티 특징을 추출하도록 구성된 제1 추출 서브유닛; 3차원 얼굴 템플릿 이미지 특징으로부터 얼굴 템플릿 이미지에 대응하는 템플릿 얼굴 이미지 특징을 추출하도록 구성된 제2 추출 서브유닛; 및 3차원 융합 특징을 획득하기 위해 소스 얼굴 아이덴티티 특징 및 템플릿 얼굴 이미지 특징을 융합하도록 구성된 제1 융합 서브유닛을 포함한다. 일부 실시예에서, 특징 추출 유닛은, 얼굴 템플릿 이미지의 제1 인코딩 특징을 획득하기 위해 얼굴 템플릿 이미지를 인코딩하도록 구성된 제1 인코딩 서브유닛; 얼굴 이미지의 제2 인코딩 특징을 획득하기 위해 얼굴 이미지를 인코딩하도록 구성된 제2 인코딩 서브유닛; 및 초기 얼굴 교체 특징을 획득하기 위해 제2 인코딩 특징에 기초하여 제1 인코딩 특징을 조정하도록 구성된 제1 조정 서브유닛을 포함한다. 일부 실시예에서, 변환 유닛은, 제1 로직 연산 후의 3차원 얼굴 이미지 특징을 획득하기 위해 3차원 융합 특징에 대해 제1 로직 연산을 수행하 고, 제2 로직 연산 이후의 얼굴 교체 특징을 획득하기 위해 초기 얼굴 교체 특징에 대해 제2 로직 연산을 수행 하도록 구성된 제1 통계 서브유닛; 제3 로직 연산 이후의 얼굴 교체 특징을 획득하기 위해 초기 얼굴 교체 특징과 제2 로직 연산 이후의 얼굴 교체 특징에 대해 제3 로직 연산을 수행하도록 구성된 제2 통계 서브유닛; 및 타깃 얼굴 교체 특징을 획득하기 위해 제3 로직 연산 이후의 얼굴 교체 특징 및 제1 로직 연산 이후의 3차원 얼 굴 이미지 특징에 대해 제4 로직 연산을 수행하도록 구성된 로직 연산 처리 서브유닛을 포함한다. 전술한 유닛들은 독립적인 개체들로 구현될 수 있으며, 임의로 조합되고 동일한 개체 또는 복수의 개체로 구현 될 수 있다. 전술한 유닛들의 특정 구현에 대해, 전술한 방법 실시예가 참조될 수 있으므로, 세부사항은 여기 서 다시 설명되지 않는다. 상기의 얼굴 이미지 처리 장치를 통해 얼굴 이미지의 교체 정확도가 향상될 수 있다. 또한, 일부 실시예에서, 얼굴 이미지 처리 모델 훈련 장치가 더 제공된다. 얼굴 이미지 처리 모델 훈련 장치는 컴퓨터 장치에 통합될 수 있다. 용어들은 전술한 얼굴 이미지 처리 모델 훈련 방법과 동일한 의미를 갖는다. 구체적인 구현 세부사항에 대해, 방법 실시예의 설명이 참조될 수 있다. 일부 실시예에서, 얼굴 이미지 처리 모델 훈련 장치가 제공된다. 얼굴 이미지 처리 모델 훈련 장치는 컴퓨터 장치에 통합될 수 있다. 도 10에 도시된 바와 같이, 얼굴 이미지 처리 모델 훈련 장치는 제2 획득 유닛, 제2 교체 유닛, 3차원 얼굴 윤곽 포인트 검출 유닛, 계산 유닛 및 조정 유닛을 포함한다. 제2 획득 유닛은 얼굴 이미지 샘플, 얼굴 템플릿 이미지 샘플 및 얼굴 참조 이미지 샘플을 포함하는 훈련 이미지 샘플 그룹을 획득하도록 구성된다. 제2 교체 유닛은, 얼굴 이미지 처리 모델을 사용하여, 예측된 얼굴 이미지를 획득하기 위해 얼굴 템플릿 이미지 샘플의 템플릿 얼굴을 얼굴 이미지 샘플의 소스 얼굴로 교체하도록 구성된다. 3차원 얼굴 윤곽 포인트 검출 유닛은 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트를 획득하기 위해 예측 된 얼굴 이미지에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하고, 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포 인트를 획득하기 위해 얼굴 참조 이미지 샘플에 대해 3차원 얼굴 윤곽 포인트 검출을 수행하도록 구성된다.계산 유닛은 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 얼굴 윤곽 손실을 획득하기 위해 예측된 얼굴 이미지의 3차원 얼굴 윤곽 포인트와 얼굴 참조 이미지 샘플의 3차원 얼굴 윤곽 포인트 사이의 차이를 획득 하도록 구성된다. 조정 유닛은 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 얼굴 윤곽 손실에 기초하여 얼굴 이미지 처리 모델을 조정하도록 구성된다. 일부 실시예에서, 3차원 얼굴 윤곽 포인트 검출 유닛은, 예측된 얼굴 이미지의 3차원 예측된 얼굴 이미지 특징을 획득하기 위해 예측된 얼굴 이미지에 대해 3차원 얼굴 모델링을 수행하도록 구성된 3차원 얼굴 모델링 서브유닛; 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 3차원 예측된 얼굴 이미지 특징에 대해 3차원 키 포인트 투영을 수행하도록 구성된 3차원 키 포인트 투영 서브유닛; 및 3차원 얼굴 키 포인트에 기초하여 3차원 얼굴 키 포인트들로부터 3차원 얼굴 윤곽 포인트를 선택하도록 구성된 스크리닝(screening) 서브유닛을 포함한다. 일부 실시예에서, 3차원 키 포인트 투영 서브유닛은, 3차원 예측된 얼굴 이미지 특징으로부터 예측된 얼굴 이미지의 예측된 얼굴 아이덴티티 특징 및 예측된 얼굴 표 정 특징을 추출하도록 구성된 추출 모듈; 및 미리 설정된 전달 파라미터를 사용하여, 예측된 얼굴 이미지의 3차원 얼굴 키 포인트를 획득하기 위해 예측된 얼굴 아이덴티티 특징 및 예측된 얼굴 표정 특징에 대한 3차원 키 포인트 투영을 수행하도록 구성된 3차원 키 포인트 투영 모듈을 포함한다. 일부 실시예에서, 얼굴 이미지 처리 모델 훈련 장치는, 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 제1 손실을 획득하기 위해 3차원 얼굴 윤곽 포인트 이외의 예측된 얼굴 이미지와 얼굴 참조 이미지 샘플 사이의 차이를 계산하도록 구성된 제1 계산 유닛 ― 제1 손실은 얼굴 윤곽 손실 이외의 손실을 포함함 ―; 얼굴 이미지 샘플과 예측된 얼굴 이미지 사이의 얼굴 특징 손실을 계산하도록 구성된 제2 계산 유닛; 및 제2 손실을 획득하기 위해 제1 손실과 얼굴 특징 손실을 융합하도록 구성된 제2 융합 유닛을 더 포함한다. 일부 실시예에서, 제1 계산 유닛은, 픽셀 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 픽셀 차이를 계산하도록 구성 된 제1 계산 서브유닛; 특징 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 특징 차이를 계산하도록 구성 된 제2 계산 서브유닛; 판별 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 판별 차이를 계산하도록 구성 된 제2 계산 서브유닛을 포함한다. 일부 실시예에서, 제2 계산 서브유닛은, 2차원 특징 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 2차원 특징 차이를 계산 하도록 구성된 제1 계산 모듈; 3차원 특징 손실을 획득하기 위해 얼굴 참조 이미지 샘플과 예측된 얼굴 이미지 사이의 3차원 특징 차이를 계산 하도록 구성된 제3 계산 모듈; 특징 손실을 획득하기 위해 2차원 특징 손실과 3차원 특징 손실을 융합하도록 구성된 제1 융합 모듈을 포함한다. 일부 실시예에서, 제3 계산 서브유닛은, 적어도 하나의 스케일링된 얼굴 참조 이미지 샘플 및 적어도 하나의 스케일링된 예측된 얼굴 이미지를 획득하기 위해 얼굴 참조 이미지 샘플 및 예측된 얼굴 이미지를 각각 스케일링하도록 구성된 스케일링 모듈;스케일링된 얼굴 참조 이미지 샘플의 제1 판별 특징 및 스케일링된 예측된 얼굴 이미지의 제2 판별 특징을 획득 하기 위해 적어도 하나의 스케일링된 얼굴 참조 이미지 샘플 및 적어도 하나의 스케일링된 예측된 얼굴 이미지 를 각각 판별하도록 구성된 판별 모듈; 및 제1 판별 특징 및 제2 판별 특징에 기초하여 판별 손실을 계산하도록 구성된 제3 계산 모듈을 포함한다. 일부 실시예에서, 조정 유닛은, 훈련된 얼굴 이미지 처리 모델의 모델 파라미터를 획득하도록 구성된 획득 서브유닛; 제3 손실을 획득하기 위해 얼굴 윤곽 손실과 제2 손실을 융합하도록 구성된 제2 융합 서브유닛; 및 제3 손실을 사용하여, 훈련된 얼굴 이미지 처리 모델을 획득하기 위해 모델 파라미터를 조정하도록 구성된 파라 미터 조정 유닛을 포함한다. 본 출원의 실시예는 컴퓨터 장치를 더 제공한다. 컴퓨터 장치는 단말 또는 서버를 포함할 수 있다. 예를 들어, 단말은 모바일 전화, 태블릿 컴퓨터 등일 수 있다. 다른 예에서, 컴퓨터 장치는 서버 등일 수 있다. 도 11은 본 출원의 실시예에 따른 단말의 개략적인 구조도이다. 컴퓨터 장치는 하나 이상의 처리 코어를 포함하는 프로세서, 하나 이상의 컴퓨터 판독 가능 저장 매체를 포함하는 메모리, 전원 공급 장치 및 입력 유닛과 같은 구성요소를 포함할 수 있다. 도 11에 도시된 컴퓨터 장치의 구조가 컴퓨터 장치에 대한 제한을 구성하지 않음을 당업자라면 이해할 수 있다. 컴퓨터 장치는 도면에 도시된 것보다 많거나 적은 구성요소를 포함할 수 있거나, 또는 일부 구성요소가 결합될 수 있거 나, 또는 상이한 구성요소 배치가 사용될 수 있다. 여기서 프로세서는 컴퓨터 장치의 제어 센터이며, 다양한 인터페이스 및 라인을 사용하여 전체 컴퓨터 장치의 다 양한 부분을 연결한다. 메모리에 저장된 소프트웨어 프로그램 및/또는 모듈을 운용하거나 실행하고, 메모 리에 저장된 데이터를 호출하여, 프로세서는 컴퓨터 장치의 다양한 기능 및 데이터 처리를 수행함으로써, 컴퓨터 장치에 대한 전반적인 모니터링을 수행할 수 있다. 일부 실시예에서, 프로세서는 하나 이상의 처 리 코어를 포함할 수 있다. 바람직하게는, 프로세서는 애플리케이션 프로세서와 모뎀을 통합할 수 있다. 애플리케이션 프로세서는 주로 운영체제, 사용자 인터페이스, 애플리케이션 등을 처리한다. 모뎀은 주로 무선 통신을 처리한다. 모뎀 프로세서는 프로세서에 통합되지 않을 수 있음이 이해될 수 있다. 메모리는 소프트웨어 프로그램 및 모듈을 저장하도록 구성될 수 있다. 프로세서는 다양한 기능적 애 플리케이션 및 데이터 처리를 구현하기 위해 메모리에 저장된 소프트웨어 프로그램 및 모듈을 실행한다. 메모리는 주로 프로그램 저장 영역과 데이터 저장 영역을 포함할 수 있다. 프로그램 저장 영역은 운영체 제, 적어도 하나의 기능(예를 들어, 사운드 재생 기능 및 이미지 디스플레이 기능)에 필요한 애플리케이션 프로 그램 등을 저장할 수 있다. 데이터 저장 영역은 컴퓨터 장치의 사용에 따라 생성된 데이터를 저장할 수 있다. 또한, 메모리는 고속 RAM을 포함할 수 있고, 적어도 하나의 자기 디스크 저장 장치, 플래시 메모리, 또는 다른 휘발성 고체 상태 저장 장치와 같은 비휘발성 메모리를 더 포함할 수 있다. 이에 상응하여, 메모리 는 메모리 제어기를 더 포함할 수 있어서, 프로세서가 메모리에 액세스할 수 있다. 컴퓨터 장치는 구성요소에 전력을 공급하기 위한 전원을 더 포함한다. 예를 들어, 전원 공급 장치는 전원 관리 시스템을 사용하여 프로세서에 로컬로 연결되어, 전원 관리 시스템을 사용하여 충전, 방전, 소 비 전력 관리와 같은 기능을 구현할 수 있다. 전원 공급 장치는 하나 이상의 직류 또는 교류 전원 공급 장치, 재충전 시스템, 전원 고장 검출 회로, 전원 공급 장치 변환기 또는 인버터, 전원 공급 장치 상태 지시기, 및 임의의 다른 구성요소를 더 포함할 수 있다. 컴퓨터 장치는 입력 유닛을 더 포함할 수 있다. 입력 유닛은 입력 숫자 또는 문자 정보를 수신하고 사용자 설정 및 기능 제어와 관련된 키보드, 마우스, 조이스틱, 광학 또는 트랙볼 신호 입력을 생성하도록 구성 될 수 있다. 도면에는 도시되지 않았지만, 컴퓨터 장치는 디스플레이 유닛 등을 더 포함할 수 있다. 세부사항은 여기에서 다시 설명되지 않다. 본 실시예에서, 네트워크 장치의 프로세서는 다음 명령에 따라 하나 이상의 애플리 케이션 프로그램의 프로세스에 대응하는 실행 파일을 메모리로 로딩할 수 있다. 프로세서는 메모리 에 저장된 애플리케이션 프로그램을 실행하여 본 출원의 실시예의 얼굴 이미지 처리 방법 또는 얼굴 이미 지 처리 모델 훈련 방법을 구현할 수 있다.저장 매체에 저장된 컴퓨터 프로그램은 본 출원의 실시예에서 제공되는 임의의 얼굴 이미지 처리 방법의 단계를 수행할 수 있기 때문에, 컴퓨터 프로그램은 본 출원의 실시예의 임의의 얼굴 이미지 처리 방법에 의해 구현될 수 있는 유익한 효과를 구현할 수 있다. 자세한 내용은 전술한 실시예를 참조한다. 세부사항은 여기에서 다시 설명되지 않는다. 본 출원의 실시예에서 제공되는 얼굴 이미지 처리 방법 및 얼굴 이미지 처리 모델 훈련 방법은 위에서 상세히 설명되었다. 본 출원의 원리 및 구현은 본 명세서의 특정 예를 통해 설명되며, 실시예의 설명은 본 출원의 방 법 및 핵심 아이디어를 이해하는 데 도움이 될 뿐이다. 한편, 본 기술 분야의 통상의 지식을 가진 자는 본 출 원의 사상에 따라 특정 구현 및 응용 범위를 수정할 수 있다. 결론적으로, 명세서의 내용은 본 출원에 대한 제 한으로 해석되어서는 안 된다."}
{"patent_id": "10-2022-7041706", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 출원의 실시예에 따른 방법의 시나리오의 개략도이다. 도 2는 본 출원의 실시예에 따른 얼굴 이미지 처리 방법의 개략적인 흐름도이다. 도 3은 본 출원의 실시예에 따른 얼굴 이미지 처리 방법의 시나리오의 개략도이다. 도 4는 본 출원의 실시예에 따른 얼굴 이미지 처리 방법의 다른 시나리오의 개략도이다. 도 5는 본 출원의 실시예에 따른 얼굴 이미지 처리 모델 훈련 방법의 개략적인 흐름도이다. 도 6은 본 출원의 실시예에 따른 얼굴 이미지 처리 모델 훈련 방법의 시나리오의 개략도이다. 도 7은 본 출원의 실시예에 따른 얼굴 이미지 처리 방법의 다른 개략적인 흐름도이다. 도 8은 본 출원의 실시예에 따른 얼굴 이미지 처리 모델 훈련 방법의 다른 개략적인 흐름도이다. 도 9는 본 출원의 실시예에 따른 얼굴 이미지 처리 장치의 개략적인 구조도이다. 도 10은 본 출원의 실시예에 따른 얼굴 이미지 처리 모델 훈련 장치의 개략적인 구조도이다.도 11은 본 출원의 실시예에 따른 단말의 개략적인 구조도이다."}
