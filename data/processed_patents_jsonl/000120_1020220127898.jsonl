{"patent_id": "10-2022-0127898", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0048294", "출원번호": "10-2022-0127898", "발명의 명칭": "인공지능을 활용한 의료용 증강현실영상 제공 방법, 장치 및 시스템", "출원인": "서울대학교산학협력단", "발명자": "이혁재"}}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "수술 전 환자를 대상으로 촬영된 제1 의료 이미지를 획득하는 단계;수술 시 의료용 AR 장치를 통해 상기 환자의 신체 이미지를 획득하는 단계;상기 신체 이미지 속 자세정보를 추정하는 단계;제1 인공지능 모델을 기반으로 상기 제1 의료 이미지를 상기 추정된 자세정보에 따라 변형시킨 제2 의료 이미지를 획득하는 단계; 및제2 인공지능 모델을 기반으로 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 의료용 증강현실 영상을생성하는 단계를 포함하는, 인공지능을 활용한 의료용 증강현실영상 제공방법."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 의료용 증강현실 영상을 상기 의료용AR장치로 출력하는 단계를 더 포함하는, 인공지능을 활용한 의료용 증강현실영상 제공방법."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 제1 의료 이미지를 획득하는 단계는,X-ray 영상, 컴퓨터 단층촬영(CT: Computed Tomography) 영상, 자기공명영상(MRI: Magnetic ResonanceAngiography), PET, 초음파(Ultrasonic) 중 하나를 기반으로 상기 제1 의료 이미지를 획득하는, 인공지능을 활용한 의료용 증강현실영상 제공방법."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,의료 이미지를 입력으로 하고, 의료 이미지가 사람에 정합된 이미지를 레이블링(labeling)으로 하는 제1 훈련데이터 셋을 이용하여 상기 제2 인공지능 모델을 학습시키는 단계를 더 포함하는, 인공지능을 활용한 의료용 증강현실영상 제공방법."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 제2 인공지능 모델로서 Virtual try-on network의 TOM(Try-on module)을 전이 학습시키는 단계를 더 포함하되, 상기 제2 의료 이미지, 상기 제2 의료 이미지의 마스크, 및 신체 이미지를 포함하는 제2 훈련 데이터셋으로 학습시키는, 인공지능을 활용한 의료용 증강현실영상 제공방법."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 X-ray 영상 및 X-ray 영상이 정합된 신체 이미지에 기초하여 상기 제2 훈련 데이터 셋을 획득하는 단계는,상기 Virtual try-on network의 이미지 데이터 세트의 이미지 크기에 해당하는 픽셀과 동일한 픽셀로 상기 X-ray 영상을 조정하는 단계; 및상기 조정된 X-ray 영상에 폴리곤 라벨링 툴을 사용하여 상기 X-ray 영상의 마스크를 획득하는 단계;를 포함하공개특허 10-2024-0048294-3-는, 인공지능을 활용한 의료용 증강현실영상 제공방법."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "수술 전 환자를 대상으로 촬영된 제1 의료 이미지를 수술 시의 자세정보에 따라 변형시킨 제2 의료 이미지를 획득하는 제1 인공지능 모델, 및 상기 제2 의료 이미지를 수술 시 획득된 신체 이미지에 정합하는 제2 인공지능모델을 저장하는 메모리부;외부 장치와 정보를 송수신하는 통신부; 및상기 메모리 및 통신부를 제어하는 프로세서를 포함하고,상기 프로세서는,상기 제1 의료 이미지를 획득하고, 수술 시 의료용 AR 장치를 통해 신체 이미지를 획득하여 상기 신체 이미지를기반으로 상기 자세정보를 추정하며, 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 상기 의료용 AR 장치에 출력될 의료용 증강현실 영상을 생성하는, 인공지능을 활용한 의료용 증강현실영상 제공 장치."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 프로세서는,상기 의료용 증강현실 영상을 상기 의료용 AR 장치로 출력하는, 인공지능을 활용한 의료용 증강현실영상 제공장치."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 프로세서는,X-ray 영상, 컴퓨터 단층촬영(CT: Computed Tomography) 영상, 자기공명영상(MRI: Magnetic ResonanceAngiography) 중 하나에 기초하여 상기 제1 의료 이미지를 획득하는, 인공지능을 활용한 의료용 증강현실영상제공 장치."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7 항에 있어서,상기 프로세서는, 상기 제2 의료 이미지와 상기 신체 이미지의 일치 대응하는 부분을 정합시키는, 인공지능을 활용한 의료용 증강현실영상 제공 장치."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7 항에 있어서,상기 프로세서는,상기 제1 인공지능 모델을 상기 의료 이미지 및 상기 제2 의료 이미지가 정합된 영상을 훈련 데이터로 이용하여학습시키는, 인공지능을 활용한 의료용 증강현실영상 제공 장치."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 7 항에 있어서,상기 프로세서는,상기 제2 인공지능 모델로서 Virtual try-on network의 TOM(Try-on module)을 상기 제2 의료 이미지, 상기 제2의료 이미지의 마스크 및 신체 이미지를 포함하는 훈련 데이터 셋을 이용하여 전이 학습시키는, 인공지능을 활용한 의료용 증강현실영상 제공 장치.공개특허 10-2024-0048294-4-청구항 13 환자 신체의 실제 상과 의료용 증강현실 영상을 함께 출력하는 의료용 AR 장치;제1 인공지능 모델을 학습시키기 위한 제1 훈련 데이터셋 및 제2 인공지능 모델을 학습시키기 위한 제2 훈련 데이터셋을 제공하되- 상기 제1 인공지능 모델은 수술 전 환자를 대상으로 촬영된 제1 의료 이미지를 수술 시의자세정보에 따라 변형시킨 제2 의료 이미지를 획득하고, 상기 제2 인공지능 모델은 상기 제2 의료 이미지를 수술 시 획득된 신체 이미지에 정합하는- 이미지 제공 장치; 및수술 시 상기 의료용 AR 장치를 통해 신체 이미지를 획득하고 상기 신체 이미지를 기반으로 상기 자세정보를 추정하며, 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 상기 의료용 AR 장치에 출력될 의료용 증강현실영상을 생성하는 의료 이미지 정합장치를 포함하는, 인공지능을 활용한 의료용 증강현실영상 제공 시스템."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서,상기 컴퓨터 프로그램은, 프로세서에 의해 실행되면,수술 전 환자를 대상으로 촬영된 제1 의료 이미지를 획득하는 단계;수술 시 의료용 AR 장치를 통해 상기 환자의 신체 이미지를 획득하는 단계;상기 신체 이미지 속 자세정보를 추정하는 단계;제1 인공지능 모델을 기반으로 상기 제1 의료 이미지를 상기 추정된 자세정보에 따라 변형시킨 제2 의료 이미지를 획득하는 단계; 및제2 인공지능 모델을 기반으로 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 의료용 증강현실 영상을생성하는 단계를 포함하는 방법을 상기 프로세서가 수행하도록 하기 위한 명령어를 포함하는, 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2022-0127898", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터 판독 가능 기록매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은, 프로세서에 의해 실행되면,수술 전 환자를 대상으로 촬영된 제1 의료 이미지를 획득하는 단계;수술 시 의료용 AR 장치를 통해 상기 환자의 신체 이미지를 획득하는 단계;상기 신체 이미지 속 자세정보를 추정하는 단계;제1 인공지능 모델을 기반으로 상기 제1 의료 이미지를 상기 추정된 자세정보에 따라 변형시킨 제2 의료 이미지를 획득하는 단계; 및제2 인공지능 모델을 기반으로 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 의료용 증강현실 영상을생성하는 단계를 포함하는 방법을 상기 프로세서가 수행하도록 하기 위한 명령어를 포함하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 활용한 의료용 증강현실영상 제공 방법 및 장치에 관한 것으로, 더욱 상세하게는 인공지능 모델을 이용하여 수술 전 환자를 대상으로 촬영한 의료 이미지를 수술 시 환자의 자세정보에 따라 변경시켜, 이 를 수술 시 의료진에게 출력되는 환자의 신체 이미지에 정합하여 의료용 증강현실영상을 제공하는, 인공지능을 활용한 의료용 증강현실영상 제공 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 활용한 의료용 증강현실영상 제공 방법, 장치 및 시스템에 관한 것으로, 더욱 상세하게는 인공지능 모델을 이용하여 수술 전 환자를 대상으로 촬영한 의료 이미지를 수술 시 환자의 자세정보에 따라 변 경시켜, 이를 수술 시 의료진에게 출력되는 환자의 신체 이미지에 정합하여 의료용 증강현실영상을 제공하는, 인공지능을 활용한 의료용 증강현실영상 제공 방법, 장치 및 시스템에 관한 것이다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 증강현실 및 가상현실 기술의 발달로 가상 정보를 현실 세계로 부스팅하는 기술이 다양한 분야에 적용되고 있다. 특히, 의료분야에서는 환자 질병의 의학적 진단 및 원인 분석을 위해 AR기기를 이용한 수술에 X-ray, CT, MRI 데이터 등의 다양한 영상 정보가 활용되고 있다. 의료 분야에서는 X-ray, CT, MRI 등의 의료 이미지를 촬영하여 환자의 신체 이상이나 질병을 분석한다. 예를 들 어, 의료 이미지는 녹내장, 당뇨병성 망막병증, 뇌종양, 간질성 폐질환, 심장질환, 결핵과 같은 의학적 이상에 대한 정보를 포함할 수 있다. 이때, 의료 이미지에서 환부의 형태, 위치 및 구조 등은 치료 과정에서 의사의 주관적인 판단의 기준이 되는 정 보가 된다. 최근 AR/VR 기술의 발달로 의료 영상 정보는 의료 진단 및 환자 질병의 원인 분석을 위한 증강 현실(AR)에 활용 되고 있다. 그러나 아직까지 의료 영상의 형상, 위치 및 구조를 정합하기 위해서는 마킹 과정이 필요한데, 여기 서 사용되는 마커의 크기와 특성은 수술 환경에서 방해와 불편함을 유발한다. 이에, 수술 환경에서 증강현실 애플리케이션을 활용하기 위해, 마커를 사용하지 않으면서도, 환자의 신체와 의 료 이미지 정보를 정확히 일치시킬 수 있는 기술이 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2022-0030093호(2022.03.10) (특허문헌 0002) 대한민국 공개특허 제10-2021-0115451호(2021.09.27)"}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 상술한 바와 같은 문제점을 해결하기 위하여 제안된 것으로, 인공지능 모델을 이용하여 수술 전 촬영한 의료 이미지를 수술 시 환자의 자세정보에 따라 변경시켜, 수술 시 의료진에게 출력되는 환자의 신체 이미지에 정합하여 의료용 증강현실영상을 제공하는 방법, 장치 및 시스템을 제공하는데 목적이 있다. 본 발명의 목적은 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명의 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 방법 은, 수술 전 환자를 대상으로 촬영된 제1 의료 이미지를 획득하는 단계와, 수술 시 의료용 AR 장치를 통해 상기 환자의 신체 이미지를 획득하는 단계와, 상기 신체 이미지 속 자세정보를 추정하는 단계와, 제1 인공지능 모델 을 기반으로 상기 제1 의료 이미지를 상기 추정된 자세정보에 따라 변형시킨 제2 의료 이미지를 획득하는 단계 및 제2 인공지능 모델을 기반으로 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 의료용 증강현실 영상 을 생성하는 단계를 포함할 수 있다. 본 발명의 일 측면에 따른 인공지능을 활용한 의료용 증강현실영상 제공 장치는, 수술 전 환자를 대상으로 촬영 된 제1 의료 이미지를 수술 시의 자세정보에 따라 변형시킨 제2 의료 이미지를 획득하는 제1 인공지능 모델, 및 상기 제2 의료 이미지를 수술 시 획득된 신체 이미지에 정합하는 제2 인공지능 모델을 저장하는 메모리부와, 외 부 장치와 정보를 송수신하는 통신부 및 상기 메모리 및 통신부를 제어하는 프로세서를 포함하고, 상기 프로세 서는, 상기 제1 의료 이미지를 획득하고, 수술 시 의료용 AR 장치를 통해 신체 이미지를 획득하여 상기 신체 이 미지를 기반으로 상기 자세정보를 추정하며, 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 상기 의료용 AR 장치에 출력될 의료용 증강현실 영상을 생성할 수 있다. 본 발명의 일 측면에 따른 인공지능을 활용한 의료용 증강현실영상 제공 시스템은, 환자 신체의 실제 상과 의료 용 증강현실 영상을 함께 출력하는 의료용 AR 장치와, 제1 인공지능 모델을 학습시키기 위한 제1 훈련 데이터셋및 제2 인공지능 모델을 학습시키기 위한 제2 훈련 데이터셋을 제공하되- 상기 제1 인공지능 모델은 수술 전 환 자를 대상으로 촬영된 제1 의료 이미지를 수술 시의 자세정보에 따라 변형시킨 제2 의료 이미지를 획득하고, 상 기 제2 인공지능 모델은 상기 제2 의료 이미지를 수술 시 획득된 신체 이미지에 정합하는- 이미지 제공 장치 및 수술 시 상기 의료용 AR 장치를 통해 신체 이미지를 획득하고 상기 신체 이미지를 기반으로 상기 자세정보를 추 정하며, 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 상기 의료용 AR 장치에 출력될 의료용 증강현실 영상을 생성하는 의료 이미지 정합장치를 포함할 수 있다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 방법, 장치 및 시스템에 의하면, 수술 환경에서 증강현실 애플리케이션을 활용하기 위해, 마커를 사용하지 않으면서도, 환자의 신체와 의료 이미지 정 보를 정확히 일치시킬 수 있다. 아울러, 본 발명에 의하면, 증강현실 기술을 이용하여 수술 시 의료진에게 수술 전 촬영된 의료 이미지를 제공 함으로써, 수술 중 별도의 출력화면에 대한 지속적인 확인 없이도 의료진이 환자의 실제 환부와 함께 환부 영상 또는 환부에 대한 정보영상을 인식할 수 있는 효과가 있다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적 및 효과, 그리고 그것들을 달성하기 위한 기술적 구성들은 첨부되는 도면과 함께 상세하게 뒤에 설명이 되는 실시 예들을 참조하면 명확해질 것이다. 본 발명을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것 이다. 그리고 뒤에 설명되는 용어들은 본 발명에서의 구조, 역할 및 기능 등을 고려하여 정의된 용어들로서 이 는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있"}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다. 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 오로지 특허청구범위에 기재된 청구항의 범주에 의하여 정의될 뿐이다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하에서는 첨부한 도면을 참조하며, 본 발명의 바람직한 실시예들을 보다 상세하게 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 시스템의 개념도이다. 도 1을 참조하면, 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 시스템은, 의료용 AR 장치, 이미지 제공 장치 및 의료 이미지 정합장치를 포함할 수 있다. 도 1의 각 구성요소는, 네트워크(Network)를 통해 연결될 수 있다. 의료용 AR 장치, 이미지 제공 장치 및 의료 이미지 가상 정합장치 등과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예는 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long term evolution) 네트워크, WIMAX(World Interoperability for Microwave access) 네트워크, 인터넷, LAN, Wireless LAN, WAN, PAN, 블루투스 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 설명에 앞서 이하, 수술 전 촬영된 의료 이미지는 제1 의료 이미지로 명명하고, 수술 시 의료용 AR 장치를 통해 신체를 촬영한 영상은 신체 이미지이라 명명하며, 제1 의료 이미지가 신체 이미지 속 자세정보에 따라 변형된 영상은 제2 의료 이미지이라 명명하기로 한다. 먼저, 의료용 AR 장치는 의사, 의료진 등의 사용자에 장착되거나 미장착된 상태에서 증강현실 영상을 제공 할 수 있다. 의료용 AR 장치가 제공하는 증강현실 영상으로는 환자의 신체만을 직접적으로 출력하는 신체 이미지와 환자의 환부 상태에 관한 정보를 출력하는 환부 정보영상을 포함한다. 사용자는 의료용 AR 장치 너머로 볼 수 있는 환자 신체의 실제 상(像)과 의료용 AR 장치에서 제공되 는 의료용 증강현실 영상을 함께 볼 수 있다. 정확하게는, 의료용 AR 장치는 수술 전 촬영된 제1 의료 이미지를 수술 시 환자의 자세정보에 따라 변형시 킨 제2 의료 이미지를 수술 시 촬영된 신체 이미지에 정합하여 생성된 의료용 증강현실 영상을 제공할 수 있다. 이에 따라, 의료진은 환자의 환부의 실제 상과, 의료용 AR 장치가 아닌 다른 의료 장치로 촬영된 의료 이미지에 기초하여 생성된 의료용 증강현실 영상을 함께 볼 수 있다. 이에, 사용자는 환자 환부의 실제 상과 다른 의료 장치로 촬영된 의료 이미지에 기초한 증강현실 영상을 한번에 확인할 수 있어, 별도로 촬영된 의료 이미지를 확 인하기 위해 의료진이 시야를 돌려야 하는 불편을 생략할 수 있다. 여기서, 다른 의료 장치로 촬영된 의료 이미지는 X-ray 영상, 컴퓨터 단층촬영(CT: Computed Tomography) 영상, 자기공명영상(MRI: Magnetic Resonance Angiography), PET 및 초음파(Ultrasonic) 중 적어도 하나일 수 있다. 그리고, 의료용 AR 장치는 HMD(Head mount display), 스마트폰 VR, 홀로렌즈, 모바일 글래스, 태블릿 PC, 랩탑(Labtop) 및 PC 모니터 중 적어도 하나로 구비될 수 있으며, 이에 한정하지 않는다. 이미지 제공 장치는 의료 이미지 정합장치에 제1 훈련 데이터 셋 및 제2 훈련 데이터 셋을 제공할 수 있다. 구체적으로, 제1 훈련 데이터 셋은 의료 이미지, 정합됐을 때의 변형 의료 이미지(제2 의료 이미지)의 정답 이 미지 및 제2 의료 이미지가 정합된 신체 이미지에 대한 정답 레이블(Ground Truth Labels)을 포함할 수 있다. 일 예로, 이미지 제공 장치는 데이터베이스에 기존에 공개된 방대하고 다양한 종류의 신체 및 가상 정합 의료 이미지에 대한 훈련 데이터 셋을 저장할 수 있다. 여기서, 의료 이미지는 전술한 바와 같이 의료용 AR 장치 이외의 다른 의료 장치로 촬영된 의료 이미지인 X-ray 영상, 컴퓨터 단층촬영(CT: Computed Tomography) 영상, 자기공명영상(MRI: Magnetic Resonance Angiography) 중 적어도 하나일 수 있다. 제2 훈련 데이터 셋은 제2 의료 이미지 및 상기 제2 의료 이미지의 마스크 및 신체 이미지를 포함할 수 있다. 이때, Virtual try-on network의 이미지 데이터 세트의 이미지 크기에 해당하는 픽셀과 동일한 픽셀로 의료 이 미지를 조정할 수 있다. 그리고, 의료 이미지에 툴(폴리곤 라벨링 툴)을 사용하여 의료 이미지의 마스크를 획득 할 수 있다.각 훈련 데이터 셋을 이용하여 인공지능 모델을 학습시키는 방법에 대해서는 하기에서 서술하기로 한다. 이러한 이미지 제공 장치는 의료용 AR 장치와 통신하기 위한 통신모듈, 데이터를 처리하는 데이터 처 리부, 각종 데이터를 저장하고 있는 데이터베이스를 포함할 수 있다. 의료 이미지 정합장치는 별도의 클라우드 서버나 컴퓨팅 장치를 포함할 수 있다. 또한, 의료 이미지 정합 장치는 의료용 AR 장치의 프로세서 또는 이미지 제공 장치에 설치된 신경망 시스템일 수 있지만, 이하에서 의료 이미지 정합장치는 의료용 AR 장치 또는 이미지 제공 장치와 별도의 장 치로 설명한다. 도 2는 본 발명의 일 실시예에 따른 의료 이미지 정합장치의 구성을 도시하는 블록도이다. 도 2를 참조하면, 의료 이미지 정합장치는 통신부를 통하여 의료용 AR 장치로부터 환자 신체 이 미지, 가상 정합 의료 이미지를 수신하고, 이미지 제공 장치로부터 훈련 데이터 셋을 수신할 수 있다. 의료 이미지 정합장치는 훈련 데이터 셋을 이용하여 의료 이미지 가상 정합 딥러닝 모델을 구축하고, 환자 의 신체 이미지에 의료 이미지를 정합하여 의료용 증강현실영상을 제공할 수 있다. 즉, 본 발명은 딥 러닝 신경 망을 이용하여 의료 이미지를 환자의 신체 이미지에 가상으로 정합한 모습을 제공할 수 있다. 이를 위해, 의료 이미지 정합장치는 메모리부, 통신부 및 프로세서를 포함할 수 있다. 메모리부는 수술 전 촬영된 제1 의료 이미지를 수술 시의 자세정보에 따라 변형시킨 제2 의료 이미지를 획 득하는 제1 인공지능 모델, 및 제2 의료 이미지를 수술 시 획득된 신체 이미지에 정합하는 제2 인공지능 모델을 저장할 수 있다. 통신부는 외부 장치와 정보를 송수신할 수 있다. 프로세서는 먼저, 수술 전 의료용 AR 장치가 아닌 MRI, CT, X-ray와 같은 의료 장치로 환자를 촬영한 제1 의료 이미지를 획득한다. 그리고, 프로세서는 수술 시 의료용 AR 장치의 카메라를 통해 환자의 신체 이미지를 획득하여 상기 신체 이미지 속 자세정보를 추정하고, 제1 인공지능 모델 기반으로 제1 의료 이미지를 상기 추정된 자세정보에 따라 변형시킨 제2 의료 이미지를 획득한다. 다음으로, 프로세서는 제2 인공지능 모델 기반으로 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 의료용 증강현실 영상을 생성한다. < 인공지능 모델 학습 > 구체적으로, 프로세서는 먼저, 이미지 제공 장치로부터 제1 훈련 데이터 셋을 제공받아, 제1 훈련 데 이터 셋을 기반으로 제1 인공지능 모델을 학습시킬 수 있다. 제1 인공지능 모델은 의료 이미지의 특성을 유지하면서 환자의 자세정보에 맞게 의료 이미지를 변형할 수 있다. 여기서, 제1 인공지능 모델은 Geometric transformation 모델이라 할 수 있다. 특히, 제1 인공지능 모델은 의료 이미지의 자연스럽고 실제적인 변형을 위하여 의료 이미지를 원근적으로 변형 한 후 세부적으로 단계적으로 변형시킬 수 있다. 또한, 제1 인공지능 모델은 의료 이미지에 포함된 병변, 뼈, 장기 등 특징이 변형되지 않고 유지되도록 신경망 학습시 손실함수를 반영하여 실제 의료 이미지의 특성과 유사한 결과를 얻도록 한다. 여기서, 제1 인공지능 모델은 신체 일부를 제거한 이미지와 임의의 제1 의료 이미지를 조합하여 페이크 이미지 를 생성하는 생성자 네트워크, 자세정보를 통해 페이크 이미지와 신체 이미지를 판별하는 판별자 네트워크를 포 함하는 생성적 적대신경망(GAN: Generative Adversarial Networks)일 수 있다.프로세서는 GAN 기반으로 제1 의료 이미지 및 신체 이미지를 입력받고, 신체 이미지에서 신체 일부를 제거 하여 이미지를 가공하고, 신체 이미지의 자세정보를 추출하여 학습에 사용하도록 전처리 할 수 있다. 전술했듯이 여기서 제1 의료 이미지는 수술 전 환자를 대상으로 촬영된 X-ray 영상, 컴퓨터 단층촬영(CT: Computed Tomography) 영상, 자기공명영상(MRI: Magnetic Resonance Angiography) 중 적어도 하나로부터 획득 할 수 있고, 신체 이미지는 수술 시 의료용 AR 장치를 통해 획득할 수 있다. 구체적으로, GAN의 생성자는 랜덤 노이즈(Latent vector)를 통해 페이크 이미지를 만들고, 판별자는 실제 신체 이미지와, 신체 일부를 제거한 신체 이미지에 제1 의료 이미지를 조합한 페이크 이미지를 바탕으로 페이크 이미 지가 실제인지 아닌지 판별한다. 그리고, 판별한 확률을 바탕으로 로스(loss)를 계산해서 경사 하강법을 통해 생성자는 더 비슷하게 만들도록 학습하고, 판별자는 진짜 이미지를 분류하도록 학습한다. 이와 같이, 제1 인공지능 모델은 수술 시 환자의 신체 이미지와 거의 동일하도록 수술 전 촬영된 의료 이미지를 가공함으로써, 환자의 신체와 의료 이미지를 거의 정확히 일치시킬 수 있다. 그리고, 프로세서는 이미지 제공 장치로부터 제2 훈련 데이터 셋을 제공받아, 제2 훈련 데이터 셋을 기반으로 제2 인공지능 모델을 학습시킬 수 있다. 여기서, 제2 인공지능 모델은 도 4에 도시된 Virtual try-on network의 TOM(Try-on module)을 제2 훈련 데이터 셋을 이용하여 전이 학습시킨 모델일 수 있다. 여기서, TOM은 원래 Virtual try-on network의 최종 가상 피팅 이미지를 합성하기 위한 파이프 라인이다. 본 발명의 일 실시예에서, TOM은 도 5에 도시된 바와 같이, 환자의 신체 이미지로부터 세그멘테이션을 통한 자 세정보 이미지, 및 뒤틀린 의료 이미지(Warped X-ray Image , 제2 의료 이미지)를 입력으로 하고, 뒤틀린 의 료 이미지( )를 합성 마스크 (MO)를 사용하여 렌더링 이미지로 합성하여 최종 정합 결과 Final result Io를 생 성한다. Virtual try-on network에서 신체 형상 성분은 휴먼 파서(Human parser)를 통해 획득할 수 있다. 휴먼 파서의 결과에서 자세정보를 획득하기 위해 낮은 해상도로 다운 샘플링할 수 있다. 이러한 기술은 공지의 기술이므로 상세한 설명은 생략하기로 한다. TOM은 U-Net(6개의 2-스트라이드 다운샘플링 컨볼루션 레이어 및 6개의 업샘플링 레이어)을 사용하여 신체 이미 지를 렌더링하고(Rendered person IR), 컴포지션 마스크(Composition Mask MO)를 예측한다. U-Net은 보다 정확한 세분화를 위해 full convolutional 네트워크를 수정 및 확장하고, 업샘플링하는 동안 전역 정보에 로컬 정보를 제공하는 다운샘플링 경로와 업샘플링 경로 사이에 스킵 연결을 설계한다. 그런 다음, TOM은 렌더링된 사람 이미지(IR)와 뒤틀린 의료 이미지( , 제2 의료 이미지)를 합성 마스크(MO)를 사용하여 함께 합성한다. TOM의 손실함수는 이하 수학식과 같다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 첫 번째 항은 VGG 지각 손실이고, 두 번째 항은 If와 It 사이의 픽셀 단위 L1 손실이고, 세 번째 항은 합성 마스크와 천 마스크 간의 픽셀 단위 L1 손실이며, 이고, 여기서 θi(I)는 ImageNet에서 사전 훈련된 VGG19(K. Simonyan and A. Zisserman, \"Very Deep Convolutional Networks for Large-scale Image Recognition,\" arXiv Preprint arXiv: 1409.1556, 2014.)를 사용하여 시각적 인식 네트워크 θ에서 i 번째 레이어의 이미지 I의 피쳐 맵을 나타냅니다.< 의료용 증강현실 영상 생성 > 프로세서는 수술 시 의료용 AR 장치를 통해 획득한 신체 이미지 속 자세정보를 추정하고, 학습된 제1 인공지능 모델 기반으로 제1 의료 이미지(수술 전 획득된 의료 이미지)를 상기 추정된 자세정보에 따라 변형시 켜 제2 의료 이미지를 획득한다. 다음으로, 프로세서는 제2 인공지능 모델 기반으로 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 의료용 AR 장치를 통해 의료용 증강현실 영상을 출력시킨다. 이에, 의료용 AR 장치는 수술 시 볼 수 있는 환자의 실제 신체 상과, 수술 전 촬영된 의료 이미지에 기초 한 증강현실 영상을 한번에 출력할 수 있다. 도 7은 본 발명의 일 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공방법을 설명하기 위한 흐름도 이다. 도 1의 인공지능을 활용한 의료용 증강현실영상 제공 시스템과 실질적으로 동일한 구성에서 진행될 수 있다. 따라서, 도 1의 인공지능을 활용한 의료용 증강현실영상 제공 시스템과 동일한 구성요소는 동일한 도면부 호를 부여하고, 반복되는 설명은 생략한다. 또한, 본 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 방법은 머신러닝을 활용한 소프트웨어(어 플리케이션)에 의해 실행될 수 있다. 먼저, 수술 전 환자를 대상으로 촬영된 제1 의료 이미지를 획득할 수 있다(S110). 여기서, 제1 의료 이미지는 X-ray 영상, 컴퓨터 단층촬영(CT: Computed Tomography) 영상, 자기공명영상(MRI: Magnetic Resonance Angiography) 중 적어도 하나일 수 있다. 다음으로, 수술 시 의료용 AR 장치를 통해 상기 환자의 신체 이미지를 획득할 수 있다(S120). 여기서, 의료용 AR 장치는 HMD(Head mount display), 스마트폰 VR, 홀로렌즈, 모바일 글래스 중 적어도 하나로 구비될 수 있으며, 이에 한정하지 않는다. 이때, 차후 Virtual try-on network모델을 이용할 것을 대비하여, 의 료용 AR 장치를 통해 획득한 신체 이미지의 사이즈를 Virtual try-on network모델에서 입력하는 시착 대상 사람 이미지 사이즈와 동일하게 맞출 수 있다. 다음으로, 상기 신체 이미지 속 자세정보를 추정할 수 있다(S130). 이를 위해, 휴먼 파서(Human parser) 모델을 이용할 수 있다. 다음으로, 제1 인공지능 모델을 기반으로 상기 제1 의료 이미지를 상기 추정된 자세정보에 따라 변형시킨 제2 의료 이미지를 획득할 수 있다(S140). 여기서, 제1 인공지능 모델은 의료 이미지의 특성을 유지하면서 환자의 자세정보에 맞게 의료 이미지를 변형할 수 있다. 특히, 제1 인공지능 모델은 의료 이미지의 자연스럽고 실제적인 변형을 위하여 의료 이미지를 원근적 으로 변형한 후 세부적으로 단계적으로 변형시킬 수 있다. 또한, 제1 인공지능 모델은 의료 이미지에 포함된 병변, 뼈, 장기 등 특징이 변형되지 않고 유지되도록 신경망 학습시 손실함수를 반영하여 실제 의료 이미지의 특성과 유사한 결과를 얻도록 한다. 일 실시예로, 제1 인공지능 모델은 신체 일부를 제거한 이미지와 임의의 제1 의료 이미지를 조합하여 페이크 이 미지를 생성하는 생성자 네트워크, 자세정보를 통해 페이크 이미지와 신체 이미지를 판별하는 판별자 네트워크 를 포함하는 생성적 적대신경망(GAN: Generative Adversarial Networks)일 수 있다. 전술한 GAN을 통해 환자의 자세정보에 따라 뒤틀린 의료 이미지(제2 의료 이미지)를 획득할 수 있다. 다음으로, 제2 인공지능 모델을 기반으로 상기 제2 의료 이미지를 상기 신체 이미지에 정합하여 의료용 증강현 실 영상을 생성할 수 있다(S150). 제2 인공지능 모델은 도 4에 도시된 Virtual try-on network의 TOM(Try-on module)을 제2 훈련 데이터 셋을 이 용하여 전이 학습시킨 모델일 수 있다. 여기서, TOM은 원래 Virtual try-on network의 최종 가상 피팅 이미지를 합성하기 위한 파이프 라인이다. 본 발명의 일 실시예에서, TOM은 도 5에 도시된 바와 같이, 환자의 신체 이미지로부터 세그멘테이션을 통한 자 세정보 이미지, 및 뒤틀린 의료 이미지(Warped X-ray Image , 제2 의료 이미지)를 입력으로 하고, 뒤틀린 의 료 이미지( )를 합성 마스크 (MO)를 사용하여 렌더링 이미지로 합성하여 최종 정합 결과 Final result Io를 생 성한다. Virtual try-on network에서 신체 형상 성분은 휴먼 파서(Human parser)를 통해 획득할 수 있다. 휴먼 파서의 결과에서 자세정보를 획득하기 위해 낮은 해상도로 다운 샘플링할 수 있다. 이러한 기술은 공지의 기술이므로 상세한 설명은 생략하기로 한다. TOM은 U-Net(6개의 2-스트라이드 다운샘플링 컨볼루션 레이어 및 6개의 업샘플링 레이어)을 사용하여 신체 이미 지를 렌더링하고(Rendered person IR), 컴포지션 마스크(Composition Mask MO)를 예측한다. U-Net은 보다 정확한 세분화를 위해 full convolutional 네트워크를 수정 및 확장하고, 업샘플링하는 동안 전역 정보에 로컬 정보를 제공하는 다운샘플링 경로와 업샘플링 경로 사이에 스킵 연결을 설계한다. 그런 다음, TOM은 렌더링된 사람 이미지(IR)와 뒤틀린 의료 이미지( , 제2 의료 이미지)를 합성 마스크(MO)를 사용하여 함께 합성한다. 이와 같이, 제2 의료 이미지를 신체 이미지에 정합한 것에 기초하여 생성된 의료용 증강현실 영상을 의료용 AR 장치에 출력시킬 수 있다. 전술한 의료용 증강현실영상 제공 시스템은, 프로세서, 메모리, 사용자 입력장치, 프레젠테이션 장치 중 적어도 일부를 포함하는 컴퓨팅 장치에 의해 구현될 수 있다. 메모리는, 프로세서에 의해 실행되면 특정 태스크를 수행 할 수 있도록 코딩되어 있는 컴퓨터-판독가능 소프트웨어, 애플리케이션, 프로그램 모듈, 루틴, 인스트럭션 (instructions), 및/또는 데이터 등을 저장하는 매체이다. 프로세서는 메모리에 저장되어 있는 컴퓨터-판독가능 소프트웨어, 애플리케이션, 프로그램 모듈, 루틴, 인스트럭션, 및/또는 데이터 등을 판독하여 실행할 수 있다. 사용자 입력장치는 사용자로 하여금 프로세서에게 특정 태스크를 실행하도록 하는 명령을 입력하거나 특정 태스 크의 실행에 필요한 데이터를 입력하도록 하는 수단일 수 있다. 사용자 입력장치는 물리적인 또는 가상적인 키 보드나 키패드, 키버튼, 마우스, 조이스틱, 트랙볼, 터치-민감형 입력수단, 또는 마이크로폰 등을 포함할 수 있 다. 프레젠테이션 장치는 디스플레이, 프린터, 스피커, 또는 진동장치 등을 포함할 수 있다. 컴퓨팅 장치는 스마트폰, 태블릿, 랩탑, 데스크탑, 서버, 클라이언트 등의 다양한 장치를 포함할 수 있다. 컴퓨 팅 장치는 하나의 단일한 스탠드-얼론 장치일 수도 있고, 통신망을 통해 서로 협력하는 다수의 컴퓨팅 장치들로 이루어진 분산형 환경에서 동작하는 다수의 컴퓨팅 장치를 포함할 수 있다. 또한 전술한 의료용 증강현실영상 제공 방법은, 프로세서를 구비하고, 또한 프로세서에 의해 실행되면 에이전트 모델을 활용한 의료용 증강현실영상 제공 방법을 수행할 수 있도록 코딩된 컴퓨터 판독가능 소프트웨어, 애플리 케이션, 프로그램 모듈, 루틴, 인스트럭션, 및/또는 데이터 구조 등을 저장한 메모리를 구비하는 컴퓨팅 장치에 의해 실행될 수 있다. 상술한 본 실시예들은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 실시예들은 하드웨어, 펌웨어 (firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 실시예들에 따른 에이전트 모델을 활용한 영상 진단 방법은 하나 또는 그 이 상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays),프로세서, 컨트롤러, 마이크로 컨트롤러 또는 마이크로 프로세서 등에 의해 구현될 수 있다. 예를 들어, 실시예들에 따른 의료용 증강현실영상 제공 방법은 심층 신경망의 뉴런(neuron)과 시냅스(synapse) 가 반도체 소자들로 구현된 머신러닝 반도체 장치를 이용하여 구현될 수 있다. 이때 반도체 소자는 현재 사용하 는 반도체 소자들, 예를 들어 SRAM이나 DRAM, NAND 등일 수도 있고, 차세대 반도체 소자들, RRAM이나 STT MRAM, PRAM 등일 수도 있고, 이들의 조합일 수도 있다. 실시예들에 따른 의료용 증강현실영상 제공 방법을 머신러닝 반도체 장치를 이용하여 구현할 때, 에이전트 모델 을 소프트웨어로 학습한 결과(가중치)를 어레이로 배치된 시냅스 모방소자에 전사하거나 머신러닝 반도체 장치 에서 학습을 진행할 수도 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 실시예들에 따른 의료용 증강현실영상 제공 방법은 이상에서 설명 된 기능 또는 동작들을 수행하는 장치, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리 유닛에 저장되어 프로세서에 의해 구동될 수 있다. 메모리 유닛은 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 프로세서와 데이터를 주고 받을 수 있다. 또한, 위에서 설명한 \"시스템\", \"프로세서\", \"컨트롤러\", \"컴포넌트\", \"모듈\", \"인터페이스\", \"모델\", 또는 \"유 닛\" 등의 용어는 일반적으로 컴퓨터 관련 엔티티 하드웨어, 하드웨어와 소프트웨어의 조합, 소프트웨어 또는 실 행 중인 소프트웨어를 의미할 수 있다. 예를 들어, 전술한 구성요소는 프로세서에 의해서 구동되는 프로세스, 프로세서, 컨트롤러, 제어 프로세서, 개체, 실행 스레드, 프로그램 및/또는 컴퓨터일 수 있지만 이에 국한되지 않는다. 예를 들어, 컨트롤러 또는 프로세서에서 실행 중인 애플리케이션과 컨트롤러 또는 프로세서가 모두 구 성 요소가 될 수 있다. 하나 이상의 구성 요소가 프로세스 및/또는 실행 스레드 내에 있을 수 있으며, 구성 요 소들은 하나의 장치(예: 시스템, 컴퓨팅 디바이스 등)에 위치하거나 둘 이상의 장치에 분산되어 위치할 수 있다. 한편, 또 다른 실시예는 전술한 의료용 증강현실영상 제공 방법을 수행하는, 컴퓨터 기록매체에 저장되는 컴퓨 터 프로그램을 제공한다. 또한 또 다른 실시예는 전술한 캡슐 내시경 영상 판독 방법을 실현시키기 위한 프로그 램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공한다. 기록매체에 기록된 프로그램은 컴퓨터에서 읽히어 설치되고 실행됨으로써 전술한 단계들을 실행할 수 있다. 이 와 같이, 컴퓨터가 기록매체에 기록된 프로그램을 읽어 들여 프로그램으로 구현된 기능들을 실행시키기 위하여, 전술한 프로그램은 컴퓨터의 프로세서(CPU)가 컴퓨터의 장치 인터페이스(Interface)를 통해 읽힐 수 있는 C, C++, JAVA, Python, R, C#, 기계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 전술한 기능들을 정의한 함수 등과 관련된 기능적인 코드를 포함할 수 있고, 전술한 기능들을 컴 퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수도 있다. 또한, 이러한 코드는 전술한 기능들을 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 컴퓨터 의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조 되어야 하는지에 대한 메모리 참조 관련 코드를 더 포함할 수 있다. 또한, 컴퓨터의 프로세서가 전술한 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서 버 등과 통신이 필요한 경우, 코드는 컴퓨터의 프로세서가 컴퓨터의 통신 모듈을 이용하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야만 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는 지 등에 대한 통신 관련 코드를 더 포함할 수도 있다. 이상에서 전술한 바와 같은 프로그램을 기록한 컴퓨터로 읽힐 수 있는 기록매체는, 일 예로, ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 미디어 저장장치 등이 있다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고, 본 발명을 구현하기 위한 기능적인(Functional) 프로그램과 이와 관련된 코드 및 코드 세그먼트 등은,"}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "기록매체를 읽어서 프로그램을 실행시키는 컴퓨터의 시스템 환경 등을 고려하여, 본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론되거나 변경될 수도 있다. 도 6을 통해 설명된 의료용 증강현실영상 제공 방법은, 컴퓨터에 의해 실행되는 애플리케이션이나 프로그램 모 듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저 장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 전술한 의료용 증강현실영상 제공 방법은, 단말기에 기본적으로 설치된 애플리케이션(이는 단말기에 기본적으로 탑재된 플랫폼이나 운영체제 등에 포함된 프로그램을 포함할 수 있다)에 의해 실행될 수 있고, 사용자가 애플리 케이션 스토어 서버, 애플리케이션 또는 해당 서비스와 관련된 웹 서버 등의 애플리케이션 제공 서버를 통해 마 스터 단말기에 직접 설치한 애플리케이션(즉, 프로그램)에 의해 실행될 수도 있다. 이러한 의미에서, 전술한 의 료용 증강현실영상 제공 방법은 단말기에 기본적으로 설치되거나 사용자에 의해 직접 설치된 애플리케이션(즉, 프로그램)으로 구현되고 단말기에 등의 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다. 이상, 본 발명의 특정 실시예에 대하여 상술하였다. 그러나, 본 발명의 사상 및 범위는 이러한 특정 실시예에 한정되는 것이 아니라, 본 발명의 요지를 변경하지 않는 범위 내에서 다양하게 수정 및 변형이 가능하다는 것을 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 이해할 것이다."}
{"patent_id": "10-2022-0127898", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "따라서, 이상에서 기술한 실시예들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이므로, 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 하 며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다."}
{"patent_id": "10-2022-0127898", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 시스템의 개념도이다. 도 2는 본 발명의 일 실시예에 따른 의료 이미지 정합장치의 구성을 도시하는 블록도이다. 도 3은 본 발명의 일 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 시스템에서 이용하는 모델의 구조를 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 제2 인공지능 모델의 구조를 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따라 지도 학습된 TOM(Try-on model)의 구조를 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시예에 따른 의료용 AR 장치의 일 예를 도시한 도면이다. 도 7은 본 발명의 일 실시예에 따른 인공지능을 활용한 의료용 증강현실영상 제공 방법을 설명하기 위한 순서도 이다."}
