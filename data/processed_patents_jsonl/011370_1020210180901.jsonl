{"patent_id": "10-2021-0180901", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0022387", "출원번호": "10-2021-0180901", "발명의 명칭": "테스트 벤치 생성 방법, 테스트 벤치 생성 장치, 및 테스트 벤치 생성 시스템", "출원인": "주식회사 에너자이", "발명자": "권민수"}}
{"patent_id": "10-2021-0180901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습된 인공 지능 모델을 획득하여 컴퓨팅 환경에 따라 인공 지능 모델의 성능을 분석하는 서버가 테스트 벤치를 생성하는 방법에 있어서, 상기 방법은, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득하는 단계; 상기 제1 모델을, 상기 제1 언어와는 상이한 제2 언어를 채택하는 제2 머신 러닝 프레임워크를 이용하는 제2 모델로 변환하는 단계; 상기 제1 프로세싱 유닛과 상이한 유형인 제2 유형의 제2 프로세싱 유닛을 이용하는 제2 컴퓨팅 환경에서 상기제2 모델을 검증하는 단계; 및 상기 검증 결과에 기초하여 테스트 벤치를 생성하는 단계;를 포함하되,상기 제2 모델로 변환하는 단계는, 상기 제1 모델을 제3 언어를 이용하는 제1 그래프로 변환하는 단계; 및상기 제3 언어를 이용하고 상기 제2 머신 러닝 프레임워크와 관련된 제2 그래프를 획득하는 단계; 및상기 제1 그래프와 상기 제2 그래프에 기초하여 상기 제1 모델을 상기 제2 모델로 변환하는 단계;를 포함하는, 테스트 벤치 생성 방법."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원의 일 실시예에 따른 테스트 벤치 생성 방법은, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득하는 단계; 상기 제1 모델을, 상기 제1 언어와는 상이한 제2 언어를 채택하는 제2 머신 러닝 프레임워크를 이용하는 제2 모델로 변환하는 (뒷면에 계속)"}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 테스트 벤치 생성 방법, 테스트 벤치 생성 장치, 및 테스트 벤치 생성 시스템에 관한 것이다. 구체적 으로 본 출원은 머신 러닝 프레임워크별 인공 지능 모델의 성능 정보에 기초하여 인공 지능 모델을 검증하는 테 스트 벤치 생성 방법, 테스트 벤치 생성 장치, 및 테스트 벤치 생성 시스템에 관한 것이다."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능 기술이 발전하면서 다양한 산업 분야에 이용되기 위한 인공 지능 모델에 대한 연구와 개발이 증가되 고 있다. 인공 지능 모델은 학습되는 컴퓨팅 환경에 따라 적합한 머신러닝 프레임워크가 존재한다. 예컨대, 연 구 개발용 또는 서버용 그래픽 처리 장치(GPU)에서는 파이토치 프레임워크(Pytorch Framework)가 적합하며, 모 바일에서는 텐서플로우 프레임워크(Tensorflow Framework)가 안정성이 높은 것으로 알려져 있다. 다만, 종래에는 인공 지능 모델이 개발되면, 개발된 모델을 다양한 컴퓨팅 환경에 적용시키기 위하여, 개발자가 개발된 모델을 각 컴퓨팅 환경에 적합한 모델로 수작업으로 변환하고, 변환된 모델을 각 컴퓨팅 환경별로 수동 으로 검증하였다. 따라서, 개발된 모델을 사용자 간에 공유하거나 개발된 모델을 다양한 컴퓨팅 환경에 대하여 최적화하는 데 제약이 존재하였다. 이에, 인공 지능 모델을 컴퓨팅 환경별로 검증하는 과정을 하나의 파이프라인으로 표준화 및 자동화할 수 있는 테스트 벤치 생성 방법, 장치 및 시스템의 개발이 요구된다."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 일 과제는, 학습된 인공 지능 모델을 다양한 컴퓨팅 환경별로 검증하는 테스트 벤치 생성 방법, 테스트 벤치 생성 장치, 및 테스트 벤치 생성 시스템을 제공하는 것이다. 본 발명이 해결하고자 하는 일 과제는, 딥 러닝 모델의 성능과 크기를 고려하여 최적의 딥 러닝 모델을 설계하 는 테스트 벤치를 이용한 딥 러닝 모델 학습 방법, 딥 러닝 모델 학습 장치, 및 딥 러닝 모델 학습 시스템을 제 공하는 것이다. 본 발명이 해결하고자 하는 과제가 상술한 과제로 제한되는 것은 아니며, 언급되지 아니한 과제들은 본 명세서"}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "및 첨부된 도면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 출원의 일 실시예에 따른 테스트 벤치 생성 방법은, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득하는 단계; 상기 제1 모델을, 상기 제1 언어와는 상이한 제2 언어를 채택하는 제2 머신 러닝 프레임워크를 이용하는 제2 모델로 변환 하는 단계; 상기 제1 프로세싱 유닛과 상이한 유형인 제2 유형의 제2 프로세싱 유닛을 이용하는 제2 컴퓨팅 환 경에서 상기 제2 모델을 검증하는 단계; 및 상기 검증 결과에 기초하여 테스트 벤치를 생성하는 단계;를 포함할 수 있다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템은, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하 는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경을 갖는 전자 장치; 및 상기 전자 장치와 통신하는 송 수신부; 및 상기 전자 장치로부터 학습된 제1 모델을 획득하고 상기 제1 모델에 기초하여 테스트 벤치를 생성하 도록 구성된 프로세서;를 포함하는, 중앙 서버;를 포함하되, 상기 프로세서는, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득하 고, 상기 제1 모델을, 상기 제1 언어와는 상이한 제2 언어를 채택하는 제2 머신 러닝 프레임워크를 이용하는 제 2 모델로 변환하고, 상기 제1 프로세싱 유닛과 상이한 유형인 제2 유형의 제2 프로세싱 유닛을 이용하는 제2 컴 퓨팅 환경에서의 상기 제2 모델을 검증하고, 상기 검증 결과에 기초하여 테스트 벤치를 생성하도록 구성될 수 있다."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 발명의 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해결 수단들은 본"}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "명세서 및 첨부된 도면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원의 실시예에 따른 테스트 벤치 생성 방법, 장치 및 시스템에 의하면, 학습된 인공 지능 모델을 컴퓨팅 환경별로 테스트할 수 있다. 본 출원의 실시예에 따른 딥 러닝 모델 학습 방법, 장치 및 시스템에 의하면, 실제 딥 러닝 모델의 성능에 기초 하여 최적의 성능과 구조를 가지는 딥 러닝 모델을 설계할 수 있다."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과가 상술한 효과들로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도면"}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0180901", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 상술한 목적, 특징들 및 장점은 첨부된 도면과 관련된 다음의 상세한 설명을 통해 보다 분명해질 것 이다. 다만, 본 출원은 다양한 변경을 가할 수 있고 여러 가지 실시예들을 가질 수 있는 바, 이하에서는 특정 실시예들을 도면에 예시하고 이를 상세히 설명하고자 한다. 명세서 전체에 걸쳐서 동일한 참조번호들은 원칙적으로 동일한 구성요소들을 나타낸다. 또한, 각 실시예의 도면 에 나타나는 동일한 사상의 범위 내의 기능이 동일한 구성요소는 동일한 참조부호를 사용하여 설명하며, 이에 대한 중복되는 설명은 생략하기로 한다. 본 출원과 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 출원의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 이하의 실시예에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되 어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 이하의 실시예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타 난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타낸 것으로, 본 발명이 반드시 도시된 바에 한정되 지 않는다. 어떤 실시예가 달리 구현 가능한 경우에 특정한 프로세스의 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 프로세스가 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순 서로 진행될 수 있다. 이하의 실시예에서, 구성 요소 등이 연결되었다고 할 때, 구성 요소들이 직접적으로 연결된 경우뿐만 아니라 구 성요소들 중간에 구성 요소들이 개재되어 간접적으로 연결된 경우도 포함한다. 예컨대, 본 명세서에서 구성 요소 등이 전기적으로 연결되었다고 할 때, 구성 요소 등이 직접 전기적으로 연결 된 경우뿐만 아니라, 그 중간에 구성 요소 등이 개재되어 간접적으로 전기적 연결된 경우도 포함한다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 방법은, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득하는 단계; 상기 제1 모델을, 상기 제1 언어와는 상이한 제2 언어를 채택하는 제2 머신 러닝 프레임워크를 이용하는 제2 모델로 변환 하는 단계; 상기 제1 프로세싱 유닛과 상이한 유형인 제2 유형의 제2 프로세싱 유닛을 이용하는 제2 컴퓨팅 환 경에서 상기 제2 모델을 검증하는 단계; 및 상기 검증 결과에 기초하여 테스트 벤치를 생성하는 단계;를 포함할 수 있다. 본 출원의 일 실시예에 따르면, 상기 제2 모델로 변환하는 단계는, 상기 제1 모델을 상위 언어를 이용하는 제1 그래프로 변환하는 단계-상기 상위 언어는 상기 제1 언어와 상기 제2 언어의 상위 개념의 언어임-; 및 상기 상 위 언어를 이용하고 상기 제2 머신 러닝 프레임워크와 관련된 제2 그래프를 획득하는 단계; 및 상기 제1 그래프 와 상기 제2 그래프를 비교하여 상기 제1 모델을 상기 제2 모델로 변환하는 단계;를 포함할 수 있다. 본 출원의 일 실시예에 따르면, 상기 제2 모델을 검증하는 단계는, 테스트 코드를 획득하는 단계; 및 상기 테스 트 코드를 실행하여 상기 제2 모델의 성능을 검증하는 단계;를 포함할 수 있다. 본 출원의 일 실시예에 따르면, 상기 제2 모델의 성능은, 정확도(accuracy), 지연시간(latency), 메모리 사용량 (memory usage), 전력량, 실행 속도, 용량(footprint) 중 적어도 하나와 관련될 수 있다. 본 출원의 일 실시예에 따르면, 상기 테스트 벤치 생성 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽 을 수 있는 기록매체가 제공될 수 있다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템은, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하 는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경을 갖는 전자 장치; 및 상기 전자 장치와 통신하는 송 수신부; 및 상기 전자 장치로부터 학습된 제1 모델을 획득하고 상기 제1 모델에 기초하여 테스트 벤치를 생성하 도록 구성된 프로세서;를 포함하는, 중앙 서버;를 포함하되, 상기 프로세서는, 제1 유형의 제1 프로세싱 유닛 및 제1 언어를 채택하는 제1 머신 러닝 프레임워크를 이용하는 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득하 고, 상기 제1 모델을, 상기 제1 언어와는 상이한 제2 언어를 채택하는 제2 머신 러닝 프레임워크를 이용하는 제 2 모델로 변환하고, 상기 제1 프로세싱 유닛과 상이한 유형인 제2 유형의 제2 프로세싱 유닛을 이용하는 제2 컴 퓨팅 환경에서의 상기 제2 모델을 검증하고, 상기 검증 결과에 기초하여 테스트 벤치를 생성하도록 구성될 수 있다. 이하에서는 도 1 내지 도 6을 참고하여 본 출원의 테스트 벤치 생성 방법, 테스트 벤치 생성 장치 및 테스트 벤 치 생성 시스템에 관하여 설명한다. 또한, 도 7 내지 도 10을 참고하여 본 출원의 다른 실시예에 따라 생성된 테스트 벤치를 이용하여 딥 러닝 모델을 학습하는 방법, 장치 및 시스템에 대하여 설명한다. 도 1은 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템의 개략도이다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템은 중앙 서버(100, 혹은 테스트 벤치 생성 장치), 제1 하드웨어 및 제2 하드웨어를 포함할 수 있다. 이때, 제1 하드웨어는 제1 컴퓨팅 환경을 가지며, 제2 하드웨어는 제1 컴퓨팅 환경과는 일부 상이한 제2 컴퓨팅 환경을 가질 수 있다. 일반적으로 하드웨어(혹은 컴퓨팅 환경)에 따라 신경망 모델을 학습시키기 위한 적합한 머신 러닝 프레임워크가 상이할 수 있다. 예컨대, 연구 개발용 혹은 서버용 그래픽 처리 장치(Graphics Processing Unit, GPU)를 프로세 싱 유닛으로 이용하는 하드웨어에서는 파이토치 프레임워크(Pytorch Framework)를 이용하여 신경망 모델을 학습 시키는 것이 안정적일 수 있다. 다른 예로, 모바일 등에서 일반적으로 사용되는 어플리케이션 프로세서 (Application Processor, AP)를 프로세싱 유닛으로 이용하는 하드웨어에서는 텐서플로우 프레임워크(Tensorflow Framework)를 이용하여 신경망 모델을 학습시키는 것이 유용할 수 있다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템의 중앙 서버는 제1 하드웨어의 제1 컴퓨팅 환경에서 학습된 제1 모델을 제2 하드웨어의 제2 컴퓨팅 환경에 적합한 제2 모델로 변형하고, 제2 모델에 대한 검증을 수행하여 검증 결과에 기초하여 테스트 벤치를 생성할 수 있다. 본 출원의 일 실시예에 따라 생성 된 테스트 벤치는 대상 모델이 학습된 컴퓨팅 환경과 다른 컴퓨팅 환경에서의 대상 모델의 성능을 연산할 수 있 으며, 이를 통하여 다양한 컴퓨팅 환경에 최적화된 모델 개발의 효율성을 제고할 수 있다. 제1 하드웨어는 제1 컴퓨팅 환경을 가질 수 있다. 제1 컴퓨팅 환경은 제1 프로세싱 유닛 또는 제1 머신 러닝 프레임워크를 이용하여 연산을 수행하는 임의의 컴퓨 팅 환경을 포괄하는 의미일 수 있다. 또는 제1 컴퓨팅 환경은 제1 프로세싱 유닛이 탑재된 다양한 종류의 하드 웨어를 지칭하는 의미일 수 있다. 한편, 제1 프로세싱 유닛이 탑재된 하드웨어는 다양한 종류(예, 노트북, 데스 크톱, 모바일 등)의 전자 장치에 장착될 수 있으며, 이때, 제1 컴퓨팅 환경은 제1 프로세싱 유닛이 탑재된 하드 웨어를 포함하는 전자 장치를 지칭하는 의미일 수 있다. 제1 컴퓨터 환경에서는 제1 머신 러닝 프레임워크를 이용하여 제1 모델을 학습시킬 수 있다. 여기서 제1 머신 러닝 프레임워크는 후술할 제2 머신 러닝 프레임워크에서 사용되는 언어와 적어도 일부가 상이한 언어를 사용할 수 있다. 다시 말해, 제1 머신 러닝 프레임워크는 제1 언어를 채택하되, 후술할 제2 머신 러닝 프레임워크는 제 1 언어와는 적어도 일부가 상이한 제2 언어를 채택할 수 있다. 제1 하드웨어(혹은 제1 하드웨어를 포함하는 전자 장치)는 제1 하드웨어의 제1 컴퓨터 환경에서 학습 하여 획득된 제1 모델을 임의의 송수신부를 통하여 중앙 서버로 송신할 수 있다. 제2 하드웨어는 제2 컴퓨팅 환경을 가질 수 있다. 제2 컴퓨팅 환경은 제1 하드웨어의 제1 컴퓨팅 환 경은 일부가 상이할 수 있다. 제2 컴퓨팅 환경은 제1 프로세싱 유닛과는 상이한 제2 프로세싱 유닛 및 제2 머신러닝 프레임워크를 이용하여 연산을 수행하는 임의의 컴퓨팅 환경을 포괄하는 의미일 수 있다. 또는 제2 컴퓨팅 환경은 제2 프로세싱 유닛이 탑재된 다양한 종류의 하드웨어를 지칭하는 의미일 수 있다. 한편, 제2 프로세싱 유닛이 탑재된 하드웨어는 다 양한 종류(예, 노트북, 데스크톱, 모바일 등)의 전자 장치에 장착될 수 있으며, 이때, 제2 컴퓨팅 환경은 제2 프로세싱 유닛이 탑재된 하드웨어를 포함하는 전자 장치를 지칭하는 의미일 수 있다. 제2 컴퓨팅 환경에서는 제2 머신 러닝 프레임워크를 이용하여 신경망 모델을 학습시키는 것이 안정적일 수 있다. 여기서 제2 머신 러닝 프레임워크는 전술한 제1 머신 러닝 프레임워크에서 사용되는 언어와 적어도 일부 가 상이한 언어를 사용할 수 있다. 본 출원의 일 실시예에 따른 제2 하드웨어(혹은 제2 하드웨어를 포함하는 전자 장치)는 임의의 송수신부를 통하여 중앙 서버로부터 제2 모델을 수신할 수 있다. 여기서, 제2 모델은 제1 컴퓨팅 환경과 제2 컴퓨팅 환경의 차이를 고려하여 제1 모델이 변환된 모델일 수 있다. 또는 제2 모델은 제1 머신러닝 프레임워크의 언어 와 제2 머신러닝 프레임워크의 차이를 고려하여 제1 모델이 변환된 모델일 수 있다. 또한, 본 출원의 일 실시예 에 따른 제2 하드웨어는 제2 모델을 검증하는 동작을 수행할 수 있다. 또한, 제2 하드웨어(혹은 제2 하드웨어를 포함하는 전자 장치)는 제2 하드웨어의 제2 컴퓨팅 환경에서 검증된 제2 모델의 검증 결과를 임의의 송수신부를 통하여 중앙 서버로 송신할 수 있다. 본 출원의 일 실시예에 따른 중앙 서버, 제1 하드웨어를 포함하는 제1 전자 장치, 및 제2 하드웨어 를 포함하는 제2 전자 장치 각각은 송수신부, 메모리, 및 프로세서를 포함할 수 있다. 이하에서는 설명의 편의 상 송수신부, 메모리 및 프로세서에 대하여 중앙 서버를 중심으로 서술하나, 제1 전자 장치 및 제2 전자 장치에 대하여도 송수신부, 메모리 및 프로세서에 대한 설명이 유추적용될 수 있다. 중앙 서버의 송수신부는 제1 전자 장치 및/또는 제2 전자 장치를 포함한 임의의 외부 기기와 통신을 수행 할 수 있다. 예컨대, 중앙 서버는, 송수신부를 통해, 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득하고, 제2 컴퓨팅 환경을 가지는 제2 전자 장치에 제2 모델을 송신할 수 있다. 또한, 중앙 서버는, 송수신부를 통해, 제2 전자 장치로부터 제2 컴퓨팅 환경에서 검증된 제2 모델의 검증 결과를 획득할 수 있다. 중앙 서버는, 송수신부를 통해 네트워크에 접속하여 각종 데이터를 송수신할 수 있다. 송수신부는 크게 유 선 타입과 무선 타입을 포함할 수 있다. 유선 타입과 무선 타입은 각각의 장단점을 가지므로, 경우에 따라서 중 앙 서버에는 유선 타입과 무선 타입이 동시에 마련될 수도 있다. 여기서, 무선 타입의 경우에는 주로 와이 파이(Wi-Fi) 같은 WLAN(Wireless Local Area Network) 계열의 통신 방식을 이용할 수 있다. 또는, 무선 타입의 경우에는 셀룰러 통신, 예컨대, LTE, 5G 계열의 통신 방식을 이용할 수 있다. 다만, 무선 통신 프로토콜이 상술 한 예시에 제한되는 것은 아니며, 임의의 적절한 무선 타입의 통신 방식을 이용하는 것도 가능하다. 유선 타입 의 경우에는 LAN(Local Area Network)이나 USB(Universal Serial Bus) 통신이 대표적인 예이며 그 외의 다른 방식도 가능하다. 중앙 서버의 메모리는 각종 정보를 저장할 수 있다. 메모리에는 각종 데이터가 임시적으로 또는 반영구적 으로 저장될 수 있다. 메모리의 예로는 하드 디스크(HDD: Hard Disk Drive), SSD(Solid State Drive), 플래쉬 메모리(flash memory), 롬(ROM: Read-Only Memory), 램(RAM: Random Access Memory) 등이 있을 수 있다. 메모 리는 중앙 서버에 내장되는 형태나 탈부착 가능한 형태로 제공될 수 있다. 메모리에는 중앙 서버를 구동하기 위한 운용 프로그램(OS: Operating System)이나 중앙 서버의 각 구성을 동작시키기 위한 프로그 램을 비롯해 중앙 서버의 동작에 필요한 각종 데이터가 저장될 수 있다. 프로세서는 중앙 서버의 전반적인 동작을 제어할 수 있다. 예컨대, 프로세서는 후술할 제1 모델을 제2 모 델로 변환하는 동작, 제2 모델을 검증하는 동작, 검증 결과에 기초하여 테스트 벤치를 생성하는 동작, 테스트 벤치를 이용하여 딥 러닝 모델을 학습시키는 동작 등 중앙 서버의 전반적인 동작을 제어할 수 있다. 구체 적으로 프로세서는 메모리로부터 중앙 서버의 전반적인 동작을 위한 프로그램을 로딩하여 실행할 수 있다. 프로세서는 하드웨어나 소프트웨어 또는 이들의 조합에 따라 AP(Application Processor), CPU(Central Processing Unit), MCU(Microcontroller Unit)나 이와 유사한 장치로 구현될 수 있다. 이때, 하드웨어적으로는 전기적 신호를 처리하여 제어 기능을 수행하는 전자 회로 형태로 제공될 수 있으며, 소프트웨어적으로는 하드웨 어적 회로를 구동시키는 프로그램이나 코드 형태로 제공될 수 있다. 이하에서는 도 2 내지 도 6을 참고하여, 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템의 동작을 구 체적으로 서술한다. 종래에는 인공 지능 모델이 개발되면, 개발된 모델을 다양한 컴퓨팅 환경에 적용시키기 위하여, 개발자가 각 컴 퓨팅 환경에 적합한 모델로 개발된 모델을 수작업으로 변환하고, 변환된 모델을 각 컴퓨팅 환경별로 수동으로 검증하였다. 따라서, 개발된 모델을 사용자 간에 공유하거나 개발된 모델을 다양한 컴퓨팅 환경에 대하여 최적 화하는 데 제약이 존재하였다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템은 제1 컴퓨팅 환경에서 학습된 제1 모델의 제2 컴퓨 팅 환경에서의 성능을 검증하는 테스트 벤치를 생성할 수 있다. 본 출원의 일 실시예에 따르면, 테스트 벤치를 이용함으로써 개발된 인공 지능 모델을 사용자 간에 공유하거나 다양한 컴퓨팅 환경에 최적화할 수 있다. 도 2는 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템의 동작들을 나타낸 도면이다. 본 출원의 일 실시예에 따른 중앙 서버는 제1 컴퓨팅 환경에서 학습된 제1 모델을 획득할 수 있다. 예컨대, 중앙 서버는 제1 프로세싱 유닛이 탑재된 제1 하드웨어로부터 학습된 제1 모델을, 임의의 송수신부를 통하 여 획득할 수 있다. 본 출원의 일 실시예에 따른 중앙 서버는 제1 모델을 제2 모델로 변환하는 동작을 수행할 수 있다. 제2 모 델은 제2 컴퓨팅 환경을 갖는 제2 하드웨어에서 이용되는 제2 머신러닝 프레임워크에 적합하도록 변형된 인공 지능 모델일 수 있다. 구체적으로 중앙 서버는 제1 컴퓨팅 환경을 갖는 제1 하드웨어에서 이용되 는 제1 머신러닝 프레임워크에서 사용되는 언어와 제2 컴퓨팅 환경을 갖는 제2 하드웨어에서 이용되는 제2 머신러닝 프레임워크에서 사용되는 언어를 비교하여 제1 모델을 제2 모델로 변환할 수 있다. 제1 모델을 제2 모 델로 변환하는 동작에 대하여는 도 3 및 도 4에서 보다 구체적으로 서술한다. 본 출원의 일 실시예에 따른 제2 하드웨어를 포함하는 제2 전자 장치는 변환된 제2 모델을 획득할 수 있다. 구체적으로, 중앙 서버는 임의의 송수신부를 통하여 변환된 제2 모델을 제2 전자 장치로 송신할 수 있으며, 제2 전자 장치는 임의의 송수신부를 통하여 제2 모델을 수신할 수 있다. 본 출원의 일 실시예에 따른 제2 하드웨어는 변환된 제2 모델의 성능을 검증하는 동작을 수행할 수 있다. 예컨대, 제2 하드웨어는 제2 프로세싱 유닛이 탑재된 제2 하드웨어의 제2 컴퓨팅 환경에서의 변환된 제2 모델의 성능 정보를 연산할 수 있다. 여기서, 성능 정보란 업무(task)의 정확도, 지연 시간, 메모리 사용량, 전력량, 실행 속도, 용량(footprint) 등 인공 지능 모델의 성능과 관련된 임의의 정보를 포괄하는 의미 일 수 있다. 한편, 도 2에서는 제2 하드웨어(300, 혹은 제2 전자 장치)에서 변환된 제2 모델을 검증하는 것으로 도시하였으 나, 이는 설명의 편의를 위한 예시에 불과하며, 중앙 서버에서 제2 하드웨어의 제2 컴퓨팅 환경에 대 응되는 컴퓨팅 환경을 획득하고, 대응되는 컴퓨팅 환경 하에서 제2 모델을 검증하도록 구현될 수 있을 것이다. 본 출원의 일 실시예에 따른 중앙 서버는 제2 모델의 검증 결과를 획득할 수 있다. 또한, 중앙 서버 는 제2 모델의 검증 결과에 기초하여 테스트 벤치를 생성할 수 있다. 일 예로, 테스트 벤치는 제1 컴퓨팅 환경 에서의 제1 모델의 성능 정보와 제2 컴퓨팅 환경에서의 제2 모델의 성능 정보에 기초하여 생성될 수 있다. 구체 적으로, 제1 컴퓨팅 환경에서의 제1 모델의 성능 정보와 제2 컴퓨팅 환경에서의 제2 모델의 성능 정보의 차이에 기초하여 테스트 벤치가 생성될 수 있다. 한편, 도 2에서는 도시하지 않았지만, 본 출원의 일 실시예에 따른 중앙 서버는 검증 결과를 데이터베이스 에 저장하고, 쿼리 요청에 응답하여 검증 결과를 시각화하는 동작을 수행할 수 있다. 또한, 중앙 서버는임의의 출력부를 통하여 사용자에게 시각화된 결과를 디스플레이할 수 있다. 도 3을 참고한다. 도 3은 본 출원의 일 실시예에 따라 테스트 벤치를 생성하는 방법을 나타낸 순서도이다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 방법은 제1 머신 러닝 프레임워크를 이용하여 학습된 제1 모델을 획득하는 단계(S1100), 제1 모델을 제2 머신 러닝 프레임워크를 이용하는 제2 모델로 변환하는 단계(S1200), 제 2 모델을 검증하는 단계(S1300), 및 검증 결과에 기초하여 테스트 벤치를 생성하는 단계(S1400)를 포함할 수 있 다. 제1 머신 러닝 프레임워크를 이용하여 학습된 제1 모델을 획득하는 단계(S1100)에서는, 중앙 서버는 제1 머신 러닝 프레임워크를 이용하여 학습된 제1 모델을 획득할 수 있다. 구체적으로 중앙 서버는 제1 프로세 싱 유닛이 탑재되고 제1 컴퓨팅 환경을 갖는 제1 하드웨어와 제1 머신 러닝 프레임워크를 이용하여 학습된 제1 모델을 획득할 수 있다. 제1 모델을 제2 머신 러닝 프레임워크를 이용하는 제2 모델로 변환하는 단계(S1200)에서는, 중앙 서버는 제1 모델을 제1 컴퓨팅 환경과는 다른 제2 컴퓨팅 환경에서 이용되는 제2 머신 러닝 프레임워크와 관련된 제2 모델로 변환할 수 있다. 여기서, 제2 컴퓨팅 환경을 갖는 제2 하드웨어는 제1 프로세싱 유닛과는 상이한 제2 프로세싱 유닛이 탑재될 수 있다. 이때, 제1 프로세싱 유닛에서 이용되는 제1 머신 러닝 프레임워크에서의 연산 방식과 제2 프로세싱 유닛에서 이용되는 제2 머신 러닝 프레임워크에서의 연산 방식은 일부 상이할 수 있 다. 따라서, 중앙 서버는 제1 머신 러닝 프레임워크에서의 연산 방식과 제2 머신 러닝 프레임워크에서의 연산 방식을 비교하여 제1 모델을 제2 모델로 변환하는 동작을 수행할 수 있다. 예컨대, 중앙 서버는 제1 머신 러닝 프레임워크의 연산 언어와 제2 머신 러닝 프레임워크의 연산 언어를 비교하여 제1 모델을 제2 모델로 변환할 수 있다. 도 4를 참고한다. 도 4는 본 출원의 일 실시예에 따라 제1 모델을 제2 모델로 변환하는 단계를 구체화한 순서도 이다. 제1 모델을 제2 머신 러닝 프레임워크를 이용하는 제2 모델로 변환하는 단계(S1200)는 제1 모델을 상위 언어를 이용하는 제1 그래프로 변환하는 단계(S1210), 상위 언어를 이용하고 제2 머신 러닝 프레임워크와 관련된 제2 그래프를 획득하는 단계(S1220), 및 제1 그래프와 제2 그래프를 비교하여 제1 모델을 제2 모델로 변환하는 단계 (S1230)를 포함할 수 있다. 제1 모델을 상위 언어를 이용하는 제1 그래프로 변환하는 단계(S1210)에서는, 중앙 서버는 제1 모델을 상 위 언어를 이용하는 제1 그래프로 변환할 수 있다. 예컨대, 딥러닝 모델은 각각의 연산(예, 컨볼루션 (Convolution), 액티베이션(Activation) 등)들을 하나의 노드로 가지는 지시 비동기 그래프(directed async graph, DAG)라고 볼 수 있다. 다만, 제1 모델과 제2 모델은 연산 방식에 차이가 존재하기 때문에 변환을 위해서 는 그 연산 방식이나 연산 언어를 통일시켜줄 필요성이 존재한다. 따라서, 본 출원의 일 실시예에 따른 중앙 서 버는 제1 모델을 상위 언어를 이용하면서 추상화된 제1 그래프로 변환하도록 구현될 수 있다. 여기서 상위 언어는 제1 모델과 제2 모델의 연산 방식을 비교하기 위한 동일한 형태의 임의의 언어일 수 있다. 상위 언어를 이용하고 제2 머신 러닝 프레임워크와 관련된 제2 그래프를 획득하는 단계(S1220)에서, 중앙 서버 는 변환된 제1 그래프와 동일한 형태의 상위 언어를 이용하고, 제2 머신 러닝 프레임워크와 관련된 제2 그 래프를 획득할 수 있다. 여기서, 제2 그래프는 제2 머신 러닝 프레임워크를 이용하여 학습된 임의의 인공 지능 모델로부터 획득될 수 있다. 제1 그래프와 제2 그래프를 비교하여 제1 모델을 제2 모델로 변환하는 단계(S1230)에서, 중앙 서버는 제1 그래프와 제2 그래프를 비교하여 제1 머신 러닝 프레임워크를 이용하여 학습된 제1 모델을 제2 머신 러닝 프레 임워크의 연산 방식을 이용하는 제2 모델로 변환할 수 있다. 전술한 바와 같이 제1 그래프와 제2 그래프는 동일 한 형태의 언어이기 때문에, 중앙 서버는 제1 그래프와 제2 그래프의 차이 혹은 제1 그래프와 제2 그래프 의 상관관계에 기초하여 제1 모델을 제2 모델로 변환할 수 있다. 다시 도 3을 참고하면, 제2 모델을 검증하는 단계(S1300)에서는, 변환된 제2 모델의 제2 컴퓨팅 환경에서의 성 능이 검증될 수 있다. 구체적으로 제2 컴퓨팅 환경을 갖는 제2 하드웨어에서 제2 모델이 실행 및 테스트되 고 그 테스트 결과에 대한 정보(예, 성능 정보)가 획득될 수 있다. 이하에서는 제2 하드웨어(혹은 제2 하드웨어를 포함하는 제2 전자 장치)에서 제2 모델을 검증하는 것으로 설명하나, 이는 설명의 편의를 위한 예시에 불과하며, 제2 모델을 검증하는 동작은 제2 하드웨어의 제2 컴퓨팅 환경과 동일한 환경을 가지는 임의의 서버(예, 중앙 서버)에서도 수행되도록 구현될 수도 있다. 도 5를 참고한다. 도 5는 본 출원의 일 실시예에 따른 제2 모델을 검증하는 단계를 구체화한 순서도이다. 제2 모델을 검증하는 단계(S1300)는 테스트 코드를 획득하는 단계(S1310) 및 테스트 코드를 실행하여 제2 모델 의 성능을 검증하는 단계(S1320)를 포함할 수 있다. 테스트 코드를 획득하는 단계(S1310)에서는, 제2 하드웨어는 임의의 데이터베이스로부터 테스트 코드를 획 득할 수 있다. 여기서, 테스트 코드란 인공 신경 모델의 성능을 테스트할 수 있는 임의의 코드를 포괄하는 의미 일 수 있다. 한편, 도 5에서는 도시하지 않았으나, 제2 하드웨어는 도커 이미지, 도커 이미지에 공통적으 로 활용되는 코드, 테스트 데이터셋, 라이브러리 등을 획득하고, 이에 기초하여 제2 모델의 성능을 검증할 수 있다. 테스트 코드를 실행하여 제2 모델의 성능을 검증하는 단계(S1320)에서는, 제2 하드웨어는 변환된 제2 모델 및 테스트 코드에 기초하여 제2 모델을 검증할 수 있다. 예컨대, 제2 하드웨어는 변환된 제2 모델을 읽고, 테스트 코드를 실행하여 제2 모델의 성능을 검증할 수 있다. 또한, 제2 하드웨어는 제2 모델의 검증 결과 에 기초하여 제2 모델의 성능 정보(예, 업무(task)의 정확도, 지연 시간, 메모리 사용량, 전력량, 실행 속도 등)를 획득할 수 있다. 한편, 제2 하드웨어는 제2 모델의 검증 결과, 즉 제2 모델의 성능 정보를 임의의 송수신부를 통하여 중앙 서버로 송신할 수 있다. 다시 도 3을 참고하면, 본 출원의 일 실시예에 따른 테스트 벤치 생성 방법은 검증 결과에 기초하여 테스트 벤 치를 생성하는 단계(S1400)를 포함할 수 있다. 테스트 벤치를 생성하는 단계(S1400)에서는 중앙 서버는 제 2 모델의 제2 컴퓨팅 환경에서의 검증 결과에 기초하여 테스트 벤치를 생성할 수 있다. 예컨대, 중앙 서버(10 0)는 제1 컴퓨팅 환경에서의 제1 모델의 성능 정보와 제2 컴퓨팅 환경에서의 제2 모델의 성능 정보에 기초하여 테스트 벤치를 생성할 수 있다. 도 6은 본 출원의 일 실시예에 따라 시각화된 결과의 일 양상을 나타낸 도면이다. 중앙 서버는 제2 모델의 검증 결과를 데이터베이스에 저장하고, 쿼리 요청에 응답하여 검증 결과를 시각화 하는 동작을 수행할 수 있다. 또한, 중앙 서버는 임의의 출력부를 통하여 사용자에게 시각화된 결과를 디 스플레이할 수 있다. 일 예로, 중앙 서버는 제2 모델의 컴퓨팅 환경별 검증 결과를 비교하여 임의의 형식 으로 시각화를 수행할 수 있다. 예컨대, 중앙 서버는 제2 모델의 제1 컴퓨팅 환경에서의 성능 정보와 제2 모델의 제2 컴퓨팅 환경에서의 성능 정보를 테이블 형식으로 프로세싱할 수 있다. 구체적으로 중앙 서버 는 제2 모델의 제1 컴퓨팅 환경에서의 성능 정보(예, 지연 시간)과 제2 모델의 제2 컴퓨팅 환경에서의 성능정보 (예, 지연시간)을 테이블 형식으로 프로세싱하여 시각화할 수 있다. 또한, 중앙 서버는 제2 모델의 컴퓨 팅 환경별 검증 결과에 기초하여, 제2 모델의 컴퓨팅 환경별 성능 정보를 그래프 형식으로 프로세싱하고 시각화 할 수 있다. 도 6에서는 지연 시간을 중심으로 설명하였으나, 이는 예시에 불과하며, 중앙 서버는 지연시 간 이외의 업무의 정확성, 메모리 사용량, 전력량, 실행 속도, 용량(footprint) 등과 관련된 성능 정보에 대하 여도 시각화하도록 구현될 수 있다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템은 인공 지능 모델이 학습된 컴퓨팅 환경별(예컨대, 이용된 프로세싱 유닛별 또는 머신러닝 프레임워크별)로 인공 지능 모델의 성능 정보를 획득하고 저장할 수 있 다. 따라서, 사용자들은 테스트 벤치를 이용하여 자신의 개발한 모델의 다른 컴퓨팅 환경에서의 성능 정보를 용 이하게 확인하거나 예측할 수 있다. 따라서, 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템은 인공 지능 모델 개발의 효율성을 제공할 수 있다. 이하에서는 도 7 내지 도 10을 참고하여, 본 출원의 다른 실시예에 따라 테스트 벤치를 이용하여 딥 러닝 모델 을 업데이트(또는 학습)하는 내용을 구체적으로 서술한다. 도 7은 딥러닝 모델의 구조를 간략하게 모식화한 도면이다. 딥 러닝 모델의 설계를 학습을 통해 설계하는 것이 신경망 아키텍처 서치(Neural Architecture Search, NAS) 기술이다. 이때, 딥 러닝 모델을 구성하는 컨볼루션 레이어(convolution layer)이 가지는 커널(kernel)의 크기에 따라 모델의 성능이나 연산 속도가 달라질 수 있다. 예컨대, 커널의 크기가 클수록 모델의 성능은 높아질 수 있으나, 모델이 무거워지고 연산 속도가 느려질 수 있다. 반면, 커널의 크기가 작을수록 모델의 성능은 상대적으로 낮아질 수 있으나, 모델이 상대적으로 경량 화되고 연산 속도가 빨라질 수 있다. 이때, 모델의 성능과 모델의 경량화 정도(혹은 모델의 크기)의 트레이드 오프 관계에서 적절한 균형을 가지도록 딥 러닝 모델을 설계하는 것이 중요하며, 이를 학습을 통해 설계하는 것 이 신경망 아키텍처 서치(NAS) 기술인 것이다. 본 출원의 일 실시예에 따르면, 전술한 일 실시예에 따라 생성된 테스트 벤치를 이용하여 딥 러닝 모델의 구조 와 딥 러닝 모델의 노드의 가중치(혹은 파라미터)를 학습시킬 수 있다. 종래의 기술은 모델의 크기와 관련하여, 신경망에 들어가는 곱셉, 뎃셈의 개수를 계수한 파라미터(예, MAC 파라 미터) 또는 액티베이션(Activation)의 개수를 고려하여 딥 러닝 모델을 설계하였다. 다만, MAC 파라미터 또는 액티베이션의 개수 등은 신경망 모델의 메모리 사용량, 전력량 등에 대한 “간접적 지표”에 불과하여 신경망 모델의 실제 메모리 사용량, 실제 전력량 등이 반영된 딥 러닝 모델을 설계하지 못한다는 제약이 존재하였다. 본 출원의 일 실시예에 따른 딥 러닝 모델을 학습시키는 방법은 전술한 테스트 벤치를 이용하여 딥러닝 모델을 학습시킬 수 있다. 본 출원의 일 실시예에 따라 생성된 테스트 벤치는 컴퓨팅 환경별 모델의 성능 정보(예, 실 제 메모리 사용량, 실제 전력량. 업무(task)의 정확도, 실제 지연 시간, 실제 실행 속도 등)를 가지고 있기 때 문에, 직접적인 지표에 기초하여 딥 러닝 모델을 설계할 수 있다는 유리한 효과를 제공할 수 있다. 도 8을 참고한다. 도 8은 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 딥 러닝 모델을 학습시키는 방법 을 도시한 순서도이다. 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 딥 러닝 모델을 학습시키는 방법은 딥 러닝 모델 및 테스 트 벤치를 획득하는 단계(S2100), 미리 설정된 학습 목표에 기초하여 딥 러닝 모델을 학습하여 임시 모델을 획 득하는 단계(S2200), 테스트 벤치를 이용하여 임시 모델을 업데이트하는 단계(S2300), 및 최종 딥러닝 모델을 획득하는 단계(S2400)를 포함할 수 있다. 딥 러닝 모델 및 테스트 벤치를 획득하는 단계(S2100)에서는, 중앙 서버는, 딥 러닝 모델 및 테스트 벤치 를 획득할 수 있다. 테스트 벤치는 전술한 바와 같이 컴퓨팅 환경별(예, 머신 러닝 프레임워크별 혹은 프로세싱 유닛별) 모델의 성능 정보를 포함할 수 있다. 미리 설정된 학습 목표에 기초하여 딥 러닝 모델을 학습하여 임시 모델을 획득하는 단계(S2200)에서는, 중앙 서 버는 미리 설정된 학습 목표에 기초하여 딥 러닝 모델을 학습시킬 수 있다. 구체적으로 목표하는 모델의 성능의 정확도와 관련된 정보(예, 모델의 분류 에러율), 목표하는 모델의 크기(혹은 용량)와 관련된 정보 및/또 는 각 정보에 대한 학습에서의 비중에 대한 정보를 포함하는 학습 목표가 미리 설정될 수 있다. 예컨대, 제1 비 중의 모델의 분류 에러율과 제2 비중의 모델의 용량으로 딥 러닝 모델을 학습시키도록 학습 목표가 미리 설정될 수 있다. 중앙 서버는 미리 설정된 학습 목표에 기초하여 준비된 딥 러닝 모델을 학습시켜 임시 모델을 획득할 수 있다. 다만, 실제 컴퓨팅 환경별로 실제 메모리 사용량, 실행 속도, 전력 사용량 등 성능 정보가 다르기 때문에, 학습된 임시 모델(예컨대, 도 10의 제1 임시 모델 및 제2 임시 모델)은 타겟 컴퓨팅 환경에 최적이 아 닐 수 있다. 따라서, 본 출원의 일 실시예에 따른 딥 러닝 모델을 학습시키는 방법은 테스트 벤치를 이용하여 임시 모델을 업데이트하는 단계(S2300)를 포함할 수 있다. 테스트 벤치를 이용하여 임시 모델을 업데이트하는 단계(S2300)에 서는, 중앙 서버는, 테스트 벤치에 포함된 프로세싱 유닛 별 성능 정보 세트에 기초하여 임시 모델을 검증 하고, 임시 모델의 검증 결과에 기초하여 임시 모델을 업데이트하는 동작을 반복적으로 수행함으로써, 최종 딥러닝 모델을 획득할 수 있다. 도 9 및 도 10을 참고한다. 도 9는 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 임시 모델을 업데이트 하는 단계를 구체화한 순서도이다. 도 10은 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 임시 모델을 업데이트하는 일 양상을 도시한 도면이다. 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 임시 모델을 업데이트하는 단계(S2300)는 임시 모델을 테 스트 벤치로 입력하는 단계(S2310), 테스트 벤치의 프로세싱 유닛별 성능 정보 세트를 이용하여 임시 모델을 검 증하는 단계(S2320), 및 타겟 프로세싱 유닛의 성능 정보에 기초하여 임시 모델을 업데이트하는 단계(S2330)를 포함할 수 있다. 임시 모델을 테스트 벤치로 입력하는 단계(S2310)에서는, 중앙 서버는 임시 모델을 테스트 벤치로 입력할 수 있다. 테스트 벤치의 프로세싱 유닛별 성능 정보 세트를 이용하여 임시 모델을 검증하는 단계(S2320)에서는, 테스트 벤치는 프로세싱 유닛별 성능 정보 세트를 이용하여 입력된 임시 모델을 검증할 수 있다. 예컨대, 테스트 벤치 는 타겟 프로세싱 유닛을 포함하여 다양한 프로세싱 유닛별(혹은 컴퓨팅 환경별) 모델 검증 결과에 따른 성능 정보를 포함할 수 있다. 따라서, 테스트 벤치는 프로세싱 유닛별 성능 정보 세트를 이용하여 임시 모델의 성능 을 검증하고, 검증 결과를 피드백할 수 있다. 특히, 테스트 벤치는 최종 딥 러닝 모델이 사용될 타겟 프로세싱 유닛의 성능 정보에 기초하여 임시 모델을 검증할 수 있다. 보다 구체적으로 테스트 벤치는 임시 모델의 타겟 프로세싱 유닛에서의 대한 성능 정보를 출력할 수 있다. 타겟 프로세싱 유닛의 성능 정보에 기초하여 임시 모델을 업데이트하는 단계(S2330)에서는, 중앙 서버는 타겟 프로세싱 유닛에 대한 임시 모델의 검증 결과 및/또는 미리 설정된 학습 목표에 기초하여 임시 모델을 업 데이트하도록 구현될 수 있다. 예컨대, 중앙 서버는 테스트 벤치로부터 출력되는 타겟 프로세싱 유닛에 대 한 성능 정보에 기초하여 임시 모델을 업데이트할 수 있다. 또한, 상술한 테스트 벤치를 이용하여 임시 모델을 검증하고, 검증 결과에 따라 임시 모델을 추가적으로 업데이 트하는 과정이 반복적으로 수행될 수 있다. 이를 통하여 임시 모델이 미리 설정된 학습 목표에 최적인 구조 및 성능을 가지도록 학습될 수 있다. 다시 도 8을 참고하면, 최종 딥러닝 모델을 획득하는 단계(S2400)에서는, 중앙 서버는 학습 목표에 근접한 모델의 크기를 가지고 목표하는 정확도에 근접한 성능을 나타내는 최종 딥 러닝 모델을 획득할 수 있다. 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템은 컴퓨팅 환경별로 모델의 성능 정보(예, 업무(tas k)의 정확도, 지연 시간, 메모리 사용량, 전력량, 실행 속도 등)를 포함하는 테스트 벤치를 생성할 수 있으며, 테스트 벤치를 이용하여 컴퓨팅 환경별로 모델에 대한 테스트를 수행할 수 있어 모델 개발의 효율성을 제공할 수 있다. 또한, 본 출원의 다른 실시예에 따른 딥 러닝 모델을 시키는 방법에 따르면, 컴퓨팅 환경별 모델의 성능 정보를 포함하는 테스트 벤치를 이용하여 실제 컴퓨팅 환경에서의 모델의 성능 정보(예, 업무(task)의 정확도, 지연 시 간, 메모리 사용량, 전력량, 실행 속도 등)를 반영하여, 딥 러닝 모델을 설계할 수 있다. 상술한 중앙 서버의 다양한 동작들은 중앙 서버의 메모리에 저장될 수 있으며, 중앙 서버의 프 로세서는 메모리에 저장된 동작들을 수행하도록 제공될 수 있다. 이상에서 실시 형태들에 설명된 특징, 구조, 효과 등은 본 발명의 적어도 하나의 실시 형태에 포함되며, 반드시 하나의 실시 형태에만 한정되는 것은 아니다. 나아가, 각 실시 형태에서 예시된 특징, 구조, 효과 등은 실시 형 태들이 속하는 분야의 통상의 지식을 가지는 자에 의해 다른 실시 형태들에 대해서도 조합 또는 변형되어 실시 가능하다. 따라서 이러한 조합과 변형에 관계된 내용들은 본 발명의 범위에 포함되는 것으로 해석되어야 할 것 이다. 또한, 이상에서 실시 형태를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니며, 본 발명이 속하는 분야의 통상의 지식을 가진 자라면 본 실시 형태의 본질적인 특성을 벗어나지 않는 범위에서 이 상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 즉, 실시 형태에 구체적으로 나타난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0180901", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템의 개략도이다. 도 2는 본 출원의 일 실시예에 따른 테스트 벤치 생성 시스템의 동작들을 나타낸 도면이다.도 3은 본 출원의 일 실시예에 따라 테스트 벤치를 생성하는 방법을 나타낸 순서도이다. 도 4는 본 출원의 일 실시예에 따라 제1 모델을 제2 모델로 변환하는 단계를 구체화한 순서도이다. 도 5는 본 출원의 일 실시예에 따른 제2 모델을 검증하는 단계를 구체화한 순서도이다. 도 6은 본 출원의 일 실시예에 따라 시각화된 결과의 일 양상을 나타낸 도면이다. 도 7은 딥러닝 모델의 구조를 간략하게 모식화한 도면이다. 도 8은 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 딥 러닝 모델을 학습시키는 방법을 도시한 순서도 이다. 도 9는 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 임시 모델을 업데이트하는 단계를 구체화한 순서도 이다. 도 10은 본 출원의 일 실시예에 따른 테스트 벤치를 이용하여 임시 모델을 업데이트하는 일 양상을 도시한 도면 이다."}
