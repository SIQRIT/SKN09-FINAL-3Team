{"patent_id": "10-2021-0055573", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0148484", "출원번호": "10-2021-0055573", "발명의 명칭": "VR 공간에 대한 시지각 분석 시스템, 시지각 분석 방법 및 시지각 분석 방법을 실행시키도록", "출원인": "숭실대학교산학협력단", "발명자": "김주연"}}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "피검사자가 착용 가능하며, 상기 피검사자에게 360도 시청이 가능한 테스트 VR 영상을 표시하는 디스플레이 모듈;상기 테스트 VR 영상에서의 상기 피검사자의 시선 위치를 추적하는 시선 추적 모듈; 및상기 테스트 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할하고, 상기 시선 위치가 위치하는 하나의 단위영역을 결정하고, 상기 단위 영역 별로 상기 시선 위치가 머무른 시간인 주시 시간을 측정하고, 단위 영역 별주시 시간에 기초하여 상기 테스트 VR 영상에 대한 관심 영역을 분석하는 프로세서;를 포함하는 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 시선 추적 모듈은,상기 시선 위치를 1초당 미리 설정된 횟수만큼 획득하고,상기 프로세서는,상기 시선 위치가 획득될 때마다, 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하고,상기 시선 위치가 획득된 횟수를 상기 단위 영역 별로 카운트하고,상기 카운트된 횟수에 기초하여 상기 단위 영역 별 주시 시간을 측정하도록 구성되는, 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제1 기준시간 이상인 단위 영역을 제1 관심 영역으로 결정하도록 구성되는, 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 테스트 VR 영상 및 상기 제1 관심 영역을 합성하여 분석 결과 영상을 생성하도록 구성되는, 시지각 분석시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 프로세서는,상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제2 기준시간 이상이고, 제1 기준시간 미만인 단위영역을 제2 관심 영역으로 결정하도록 구성되는, 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2022-0148484-3-상기 프로세서는,피검사자가 여러 명 존재하는 경우, 각 피검사자 별로 상기 테스트 VR 영상에 대한 관심 영역을 분석하도록 구성되는, 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 피검사자의 속성 정보를 입력 변수로 하고, 상기 테스트 VR 영상에 대한 관심 영역을 출력 변수로 설정하여 인공지능 모델을 학습하도록 구성되는 인공지능 학습부;를 더 포함하고,상기 프로세서는,관심 장소에 방문하는 방문자들에 대한 데이터로부터 상기 방문자의 속성 정보를 추출하고,상기 방문자의 속성 정보를 기초로 상기 인공지능 모델을 통하여 상기 관심 장소를 표시하는 상기 테스트 VR 영상에 대한 관심 영역을 결정하도록 구성되는, 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는,기준 단위 영역에 인디케이터를 표시하도록 상기 디스플레이 모듈을 제어하고,상기 인디케이터가 표시될 때 상기 시선 위치가 위치하는 단위 영역이 상기 기준 단위 영역이 아니면, 상기 시선 위치가 측정되는 위치를 보정하도록 상기 시선 추적 모듈을 제어하는, 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,피검사자의 속성 정보를 입력 변수로 하고, 상기 테스트 VR 영상에 대한 관심 영역을 출력 변수로 설정하여 인공지능 모델을 학습하도록 구성되는 인공지능 학습부;를 더 포함하고,상기 시선 추적 모듈은,상기 시선 위치를 1초당 미리 설정된 횟수만큼 획득하고,상기 프로세서는,상기 시선 위치가 획득될 때마다, 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하고,상기 시선 위치가 획득된 횟수를 상기 단위 영역 별로 카운트하고,상기 카운트된 횟수에 기초하여 상기 단위 영역 별 주시 시간을 측정하고,기준 단위 영역에 인디케이터를 표시하도록 상기 디스플레이 모듈을 제어하고,상기 인디케이터가 표시될 때 상기 시선 위치가 위치하는 단위 영역이 상기 기준 단위 영역이 아니면, 상기 시선 위치가 측정되는 위치를 보정하도록 상기 시선 추적 모듈을 제어하고,상기 피검사자가 여러 명 존재하는 경우, 각 피검사자 별로 상기 테스트 VR 영상에 대한 관심 영역을 분석하고,관심 장소에 방문하는 방문자들에 대한 데이터로부터 상기 방문자의 속성 정보를 추출하고,상기 방문자의 속성 정보를 기초로 상기 인공지능 모델을 통하여 상기 관심 장소를 표시하는 상기 테스트 VR 영상에 대한 관심 영역을 결정하도록 구성되는, 시지각 분석 시스템."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "피검사자가 착용 가능한 디스플레이 모듈에 의해, 상기 피검사자에게 360도 시청이 가능한 테스트 VR 영상을 표시하는 단계;공개특허 10-2022-0148484-4-시선 추적 모듈에 의해, 상기 테스트 VR 영상에서의 상기 피검사자의 시선 위치를 추적하는 단계;상기 테스트 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할하는 단계;상기 시선 위치가 위치하는 하나의 단위 영역을 결정하는 단계;상기 단위 영역 별로 상기 시선 위치가 머무른 시간인 주시 시간을 측정하는 단계; 및단위 영역 별 주시 시간에 기초하여 상기 테스트 VR 영상에 대한 관심 영역을 분석하는 단계;를 포함하는, 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 주시 시간을 측정하는 단계는,상기 시선 추적 모듈에 의해, 상기 시선 위치를 1초당 미리 설정된 횟수만큼 획득하는 단계;상기 시선 위치가 획득될 때마다, 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하는 단계;상기 시선 위치가 획득된 횟수를 상기 단위 영역 별로 카운트하는 단계; 및상기 카운트된 횟수에 기초하여 상기 단위 영역 별 주시 시간을 측정하는 단계;를 포함하는 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제1 기준시간 이상인 단위 영역을 제1 관심 영역으로 결정하는 단계;를 더 포함하는, 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 테스트 VR 영상 및 상기 제1 관심 영역을 합성하여 분석 결과 영상을 생성하는 단계;를 더 포함하는 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제2 기준시간 이상이고, 제1 기준시간 미만인 단위영역을 제2 관심 영역으로 결정하는 단계;를 더 포함하는 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 피검사자가 여러 명 존재하는 경우, 각 피검사자 별로 상기 테스트 VR 영상에 대한 관심 영역을 분석하는단계;를 더 포함하는, 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,인공지능 학습부에 의해, 상기 피검사자의 속성 정보를 입력 변수로 하고, 상기 테스트 VR 영상에 대한 관심 영역을 출력 변수로 설정하여 인공지능 모델을 학습하는 단계;관심 장소에 방문하는 방문자들에 대한 데이터로부터 상기 방문자의 속성 정보를 추출하는 단계; 및상기 방문자의 속성 정보를 기초로 상기 인공지능 모델을 통하여 상기 관심 장소를 표시하는 상기 테스트 VR 영상에 대한 관심 영역을 결정하는 단계;를 더 포함하는, 시지각 분석 방법.공개특허 10-2022-0148484-5-청구항 17 제10항에 있어서,기준 단위 영역에 인디케이터를 표시하도록 상기 디스플레이 모듈을 제어하는 단계; 및상기 인디케이터가 표시될 때 상기 시선 위치가 위치하는 단위 영역이 상기 기준 단위 영역이 아니면, 상기 시선 위치가 측정되는 위치를 보정하도록 상기 시선 추적 모듈을 제어하는 단계;를 더 포함하는, 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 주시 시간을 측정하는 단계는,상기 시선 추적 모듈에 의해, 상기 시선 위치를 1초당 미리 설정된 횟수만큼 획득하는 단계;상기 시선 위치가 획득될 때마다, 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하는 단계;상기 시선 위치가 획득된 횟수를 상기 단위 영역 별로 카운트하는 단계; 및상기 카운트된 횟수에 기초하여 상기 단위 영역 별 주시 시간을 측정하는 단계;를 포함하고,기준 단위 영역에 인디케이터를 표시하도록 상기 디스플레이 모듈을 제어하는 단계;상기 인디케이터가 표시될 때 상기 시선 위치가 위치하는 단위 영역이 상기 기준 단위 영역이 아니면, 상기 시선 위치가 측정되는 위치를 보정하도록 상기 시선 추적 모듈을 제어하는 단계;상기 피검사자가 여러 명 존재하는 경우, 각 피검사자 별로 상기 테스트 VR 영상에 대한 관심 영역을 분석하는단계;인공지능 학습부에 의해, 상기 피검사자의 속성 정보를 입력 변수로 하고, 상기 테스트 VR 영상에 대한 관심 영역을 출력 변수로 설정하여 인공지능 모델을 학습하는 단계;관심 장소에 방문하는 방문자들에 대한 데이터로부터 상기 방문자의 속성 정보를 추출하는 단계; 및상기 방문자의 속성 정보를 기초로 상기 인공지능 모델을 통하여 상기 관심 장소를 표시하는 상기 테스트 VR 영상에 대한 관심 영역을 결정하는 단계;를 더 포함하는, 시지각 분석 방법."}
{"patent_id": "10-2021-0055573", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제10항 내지 제18항 중 어느 한 항의 시지각 분석 방법을 실행시키도록 컴퓨터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 발명의 일 측면에 의하면, 특정 장소가 촬영된 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할하고, 단위 영역 별로 피검사자의 시선이 머무른 시간을 측정하고, 측정된 시간에 기초하여 해당 VR 영상에 대한 피검 사자의 관심 영역을 분석할 수 있어서, 해당 특정 장소를 실제 방문하는 사람들의 주시 성향을 예측 및 분석하는 (뒷면에 계속)"}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 VR 공간을 이용하는 시지각 분석 시스템 및 방법에 관한 발명으로, 상세하게는 특정 장소의 VR 영상 에 대하여 피검사자의 시선을 추적하고, 추적된 시선 위치에 기초하여 피검사자가 관심을 가지는 영역을 분석할 수 있는 개인 인증 시스템 및 개인 인증 방법에 관한 것이다."}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 가상 현실 장치(Virtual Reality Device)를 이용하여 사용자에게 이미지를 제공하는 장치들이 개발되 고 있다. 가상 현실 기술은 조작된 감각 자극을 통해 사용자가 현실감을 느끼도록 하는 것으로 게임, 교육, 의 료, 저널리즘 등 많은 산업 영역에서 활용될 수 있다. 가상현실 영상 관련 기술이 발전하면서, 사용자는 다양한 장치를 이용하여 360도 영상을 시청할 수 있다. 360도 영상을 시청하는 사용자는 평면 영상을 시청할 때 보다 더 큰 몰입감을 느낄 수 있다.한편, VR 공간을 주시하는 VR 장치의 사용자에 대하여 사용자의 시선을 추적을 할 수 있는 기술은 종래에 있으 나, 단순한 시선 추적만으로는 VR 영상에 대한 사용자의 시각적인 인지 과정을 체계적으로 분석할 수 없다는 문 제가 있다."}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 발명의 일 측면에 의하면, 특정 장소가 촬영된 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할하고, 단위 영역 별로 피검사자의 시선이 머무른 시간을 측정하고, 측정된 시간에 기초하여 해당 VR 영상에 대한 피검사자의 관심 영역을 분석할 수 있어서, 해당 특정 장소를 실제 방문하는 사람들의 주시 성향을 예측 및 분석하는데 이용 가능한 분석 결과 영상을 생성하는 시지각 분석 시스템을 제공할 수 있다."}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시된 발명의 일 측면에 따른 시지각 분석 시스템은, 피검사자가 착용 가능하며, 상기 피검사자에게 360도 시 청이 가능한 테스트 VR 영상을 표시하는 디스플레이 모듈; 상기 테스트 VR 영상에서의 상기 피검사자의 시선 위 치를 추적하는 시선 추적 모듈; 및 상기 테스트 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할하고, 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하고, 상기 단위 영역 별로 상기 시선 위치가 머무른 시간인 주 시 시간을 측정하고, 단위 영역 별 주시 시간에 기초하여 상기 테스트 VR 영상에 대한 관심 영역을 분석하는 프 로세서;를 포함할 수 있다. 또한, 상기 시선 추적 모듈은, 상기 시선 위치를 1초당 미리 설정된 횟수만큼 획득하고, 상기 프로세서는, 상기 시선 위치가 획득될 때마다, 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하고, 상기 시선 위치가 획득 된 횟수를 상기 단위 영역 별로 카운트하고, 상기 카운트된 횟수에 기초하여 상기 단위 영역 별 주시 시간을 측 정하도록 구성될 수 있다. 또한, 상기 프로세서는, 상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제1 기준시간 이상인 단위 영역을 제1 관심 영역으로 결정하도록 구성될 수 있다. 또한, 상기 프로세서는, 상기 테스트 VR 영상 및 상기 제1 관심 영역을 합성하여 분석 결과 영상을 생성하도록 구성될 수 있다. 또한, 상기 프로세서는, 상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제2 기준시간 이상이고, 제1 기준시간 미만인 단위 영역을 제2 관심 영역으로 결정하도록 구성될 수 있다. 또한, 상기 프로세서는, 피검사자가 여러 명 존재하는 경우, 각 피검사자 별로 상기 테스트 VR 영상에 대한 관 심 영역을 분석하도록 구성될 수 있다. 또한, 상기 피검사자의 속성 정보를 입력 변수로 하고, 상기 테스트 VR 영상에 대한 관심 영역을 출력 변수로 설정하여 인공지능 모델을 학습하도록 구성되는 인공지능 학습부;를 더 포함하고, 상기 프로세서는, 관심 장소 에 방문하는 방문자들에 대한 데이터로부터 상기 방문자의 속성 정보를 추출하고, 상기 방문자의 속성 정보를 기초로 상기 인공지능 모델을 통하여 상기 관심 장소를 표시하는 상기 테스트 VR 영상에 대한 관심 영역을 결정 하도록 구성될 수 있다. 또한, 상기 프로세서는, 기준 단위 영역에 인디케이터를 표시하도록 상기 디스플레이 모듈을 제어하고, 상기 인 디케이터가 표시될 때 상기 시선 위치가 위치하는 단위 영역이 상기 기준 단위 영역이 아니면, 상기 시선 위치 가 측정되는 위치를 보정하도록 상기 시선 추적 모듈을 제어할 수 있다. 개시된 발명의 일 측면에 따른 시지각 분석 방법은, 피검사자가 착용 가능한 디스플레이 모듈에 의해, 상기 피 검사자에게 360도 시청이 가능한 테스트 VR 영상을 표시하는 단계; 시선 추적 모듈에 의해, 상기 테스트 VR 영 상에서의 상기 피검사자의 시선 위치를 추적하는 단계; 상기 테스트 VR 영상을 미리 설정된 복수개의 단위 영역 으로 분할하는 단계; 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하는 단계; 상기 단위 영역 별로 상기 시선 위치가 머무른 시간인 주시 시간을 측정하는 단계; 및 단위 영역 별 주시 시간에 기초하여 상기 테스트 VR 영상에 대한 관심 영역을 분석하는 단계;를 포함할 수 있다. 또한, 상기 주시 시간을 측정하는 단계는, 상기 시선 추적 모듈에 의해, 상기 시선 위치를 1초당 미리 설정된 횟수만큼 획득하는 단계; 상기 시선 위치가 획득될 때마다, 상기 시선 위치가 위치하는 하나의 단위 영역을 결정하는 단계; 상기 시선 위치가 획득된 횟수를 상기 단위 영역 별로 카운트하는 단계; 및 상기 카운트된 횟수에 기초하여 상기 단위 영역 별 주시 시간을 측정하는 단계;를 포함할 수 있다. 또한, 상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제1 기준시간 이상인 단위 영역을 제1 관심 영역으로 결정하는 단계;를 더 포함할 수 있다. 또한, 상기 테스트 VR 영상 및 상기 제1 관심 영역을 합성하여 분석 결과 영상을 생성하는 단계;를 더 포함할 수 있다. 또한, 상기 복수개의 단위 영역 중 상기 단위 영역 별 주시 시간이 제2 기준시간 이상이고, 제1 기준시간 미만 인 단위 영역을 제2 관심 영역으로 결정하는 단계;를 더 포함할 수 있다. 또한, 상기 피검사자가 여러 명 존재하는 경우, 각 피검사자 별로 상기 테스트 VR 영상에 대한 관심 영역을 분 석하는 단계;를 더 포함할 수 있다. 또한, 인공지능 학습부에 의해, 상기 피검사자의 속성 정보를 입력 변수로 하고, 상기 테스트 VR 영상에 대한 관심 영역을 출력 변수로 설정하여 인공지능 모델을 학습하는 단계; 관심 장소에 방문하는 방문자들에 대한 데 이터로부터 상기 방문자의 속성 정보를 추출하는 단계; 및 상기 방문자의 속성 정보를 기초로 상기 인공지능 모 델을 통하여 상기 관심 장소를 표시하는 상기 테스트 VR 영상에 대한 관심 영역을 결정하는 단계;를 더 포함할 수 있다. 또한, 기준 단위 영역에 인디케이터를 표시하도록 상기 디스플레이 모듈을 제어하는 단계; 및 상기 인디케이터 가 표시될 때 상기 시선 위치가 위치하는 단위 영역이 상기 기준 단위 영역이 아니면, 상기 시선 위치가 측정되 는 위치를 보정하도록 상기 시선 추적 모듈을 제어하는 단계;를 더 포함할 수 있다. 개시된 발명의 일 측면에 따른 컴퓨터 프로그램은, 상기 시지각 분석 방법을 실행시키도록 기록매체에 저장될 수 있다."}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 발명의 일 측면에 따르면, 특정 장소가 촬영된 VR 영상 및 피검사자의 관심 영역이 합성된 분석 결과 영 상을 생성하여, 해당 특정 장소에 대하여 방문자들이 관심을 가지는 영역을 예측 및 분석할 수 있다."}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 개시된 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생 략한다. 명세서에서 사용되는 '~부'라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '~부 '가 하나의 구성요소로 구현되거나, 하나의 '부 '가 복수의 구성요소들을 포함하는 것도 가능하 다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용되는 '~부'는 적어도 하나의 기능이나 동작을 처리하는 단위로서, 예를 들어 소프트웨어, FPGA 또는 하드웨어 구성요소를 의미할 수 있다. '~부'에서 제공하는 기능은 복수의 구성요소에 의해 분리되어 수행되거나, 다른 추가적인 구성요소와 통합될 수도 있다. 본 명세서의 '~부'는 반드시 소프트웨어 또는 하드웨 어에 한정되지 않으며, 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고, 하나 또는 그 이상의 프로세 서들을 재생시키도록 구성될 수도 있다. 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전 술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 개시된 발명의 작용 원리 및 실시예들에 대해 설명한다. 도 1은 일 실시예에 따른 시지각 분석 시스템을 도시한 도면이며, 도 2는 일 실시예에 따른 시지각 분석 시스템 의 구성도이다. 도 1 및 도2를 참조하면, 본 발명의 실시예에 따른 시지각 분석 시스템은, 디스플레이 모듈, 시선 추 적 모듈, 프로세서, 인공지능 학습부, 메모리를 포함할 수 있다. 디스플레이 모듈은 피검사자가 착용 가능하며, 피검사자에게 360도 시청이 가능한 테스트 VR 영 상을 표시할 수 있다. 테스트 VR 영상은 피검사자가 디스플레이 모듈을 통하여 360도 전방향으로 시청이 가능한 영상 이다. 구체적으로, 테스트 VR 영상은 특정한 장소의 특정 지점에서 360도 카메라를 설치하여 특정한 장소 의 전 방향을 촬영한 영상일 수 있다. 또한, 테스트 VR 영상은 영상의 움직임이 없는 사진일 수 있으나, 어느 특정 시간동안 촬영된 동영상일 수도 있다. 디스플레이 모듈은 피검사자의 머리에 착용 가능할 수 있으며, 피검사자에게 테스트 VR 영상 의 표시를 할 수 있는 디스플레이 패널이 마련될 수 있다. 하지만, 디스플레이 모듈이 반드시 이와 같은 형태로 한정되는 것은 아니며, 피검사자에게 360도 시청이 가능한 VR 영상을 제공할 수 있다면 어떠 한 형태여도 상관없다. 예를 들면, 디스플레이 모듈은 좌안과 우안에 대응하는 두 개의 화면을 표시하는 것도 가능할 수 있다. 디스플레이 모듈은 시선 추적 모듈 및 프로세서와 전기적으로 연결될 수 있다. 이때, 디스플레 이 모듈은 시선 추적 모듈 및 프로세서와 유선 또는 무선 통신망 방식을 통해 연결될 수 있다. 시선 추적 모듈은 테스트 VR 영상에서의 피검사자의 시선 위치를 추적할 수 있다. 시선 위치는 테스트 VR 영상에서 피검사자가 주시하고 있는 지점일 수 있다. 즉, 피검사자(30 0)는 테스트 VR 영상에서 관심 있는 영역을 주시하게 될 것이며, 이렇게 피검사자가 관심을 가지고 주시하고 있는 지점이 시선 위치일 수 있다. 시선 추적 모듈은 피검사자의 동공을 중심으로 카메라가 배치된 형태의 모듈일 수 있다. 구체적으로, 시선 추적 모듈의 카메라는 렌즈를 포함하고, 피검사자의 동공으로 빛을 조사하기 위한 조명부를 더 포함할 수 있다. 렌즈는 피검사자의 동공 부분의 촬영 영역을 조절할 수 있으며, 시선 추적 에 필요한 동공만을 촬영할 수 있는 조절이 가능한 줌 렌즈로 구성될 수 있다. 시선 추적 모듈의 카메라는 피검사자의 좌안 및 우안의 동공 중심을 통과하는 수직선상에 위치할 수 있으며, 홍채를 둘러싼 동공 중심은 사용자가 전방을 응시할 때의 위치가 될 수 있으며, 이 중심을 통과하는 수직선상에 시선 카메라의 렌즈가 위치할 수 있다. 한편, 전술한 바와 같이 시선 추적 모듈은 피검사자의 동공 부분을 촬영하는 방식일 수 있으나, 이와 같은 방식에 한정되는 것은 아니며, 피검사자의 시선을 추적할 수 있다면 어떠한 방식으로 시선 추적을 하 더라도 상관없다. 프로세서는 테스트 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할할 수 있다. 단위 영역은 미리 설정된 방식에 따라 분할된 테스트 VR 영상에서, 분할된 각각의 영역일 수 있다. 단위 영역을 나누는 방식은 도 3 및 도 4에서 후술하도록 한다. 프로세서는 시선 위치가 위치하는 하나의 단위 영역을 결정할 수 있다. 구체적으로, 시선 위치는 분할된 테스트 VR 영상에서 피검사자가 주시하고 있는 지점에 위치할 수 있다. 즉, 시선 위치는 복수개의 단위 영역 중 어느 하나의 단위 영역에 위치하게 되고, 시 선 추적 모듈은 피검사자의 시선이 테스트 VR 영상 위에서 어느 위치에 있는지 추적할 수 있으 며, 프로세서는 추적된 시선 위치가 어느 단위 영역에 있는지 판단하여 시선 위치가 위치 하는 하나의 단위 영역을 결정할 수 있다. 프로세서는 단위 영역 별로 시선 위치가 머무른 시간인 주시 시간을 측정할 수 있다. 즉, 프로 세서는 시선 위치가 어느 한 단위 영역에 위치한 시간을 측정할 수 있다. 프로세서는 단위 영역 별 주시 시간에 기초하여 테스트 VR 영상에 대한 관심 영역을 분석 할 수 있다. 관심 영역은 피검사자가 테스트 VR 영상에서 관심을 가지고 주시하는 영역일 수 있다. 즉, 프로세서는 시선 위치가 어느 단위 영역에 머무른 시간에 기초해서 해당 피검사자가 해당 테스트 VR 영상에 대하여 어느 영역에 관심을 가지는 지 분석할 수 있다. 이러한 분석 결과는 추후에 해당 테스트 VR 영상이 촬영된 장소에서 방문자들이 어느 곳에 관심을 가지고 주시하게 되는지 예측하는데 이용될 수 있다. 또한, 이러한 예측 결과는 해당 테스트 VR 영상이 촬영된 장소를 효과적으로 인테리어 하는데 도움이 될 수 있다. 테스트 VR 영상에 대한 관심 영역을 분석하는 구체적인 방법은 도 5내지 도 8을 통해서 후술한다. 프로세서는 피검사자가 여러 명 존재하는 경우, 각 피검사자 별로 테스트 VR 영상에 대한 관심 영역을 분석하도록 구성될 수 있다. 즉, 피검사자는 한 명이 아니라 복수 명 존재할 수 있으며, 본 발명의 실시예에 따른 시지각 분석은 복수 의 피검사자에 대하여 이루어질 수 있다. 이때, 복수의 피검사자에 대한 시지각 분석이 반드시 동시 에 이루어져야 하는 것은 아니며, 매 분석마다 각 피검사자에 대한 분석 결과를 메모리에 저장하는 방식으로 각 피검사자 별로 테스트 VR 영상을 분석할 수 있다. 인공지능 학습부는 피검사자의 속성 정보를 입력 변수로 하고, 테스트 VR 영상에 대한 관심 영 역을 출력 변수로 설정하여 인공지능 모델을 학습하도록 구성될 수 있다. 피검사자의 속성 정보는 해당 피검사자에 대한 다양한 속성을 나타내는 정보일 수 있다. 예를 들어, 피검사자의 속성 정보는 해당 피검사자의 성별, 나이, 관심 분야, 직업 등 다양한 속성에 대한 정보 일 수 있다. 이때, 인공지능 모델을 학습하는 것은 기계 학습(Machine Learning) 방식을 통한 학습일 수 있다. 기계 학습이란 다수의 파라미터로 구성된 모델을 이용하며, 주어진 데이터로 파라미터를 최적화하는 것을 의미 할 수 있다. 기계 학습은 학습 문제의 형태에 따라 지도 학습(supervised learning), 비지도 학습 (unsupervised learning) 및 강화 학습(reinforcement learning)을 포함할 수 있다. 지도 학습(supervised learning)은 입력과 출력 사이의 매핑을 학습하는 것이며, 입력과 출력 쌍이 데이터로 주어지는 경우에 적용할 수 있다. 비지도 학습(unsupervised learning)은 입력만 있고 출력은 없는 경우에 적용하며, 입력 사이의 규칙 성 등을 찾아낼 수 있다.인공지능 학습부는 기계 학습 방식뿐만 아니라 딥 러닝 방식을 통해서도 개인 인증을 수행할 수 있다. 인공지능 모델은 피검사자의 속성 정보를 입력 변수로 하고, 테스트 VR 영상에 대한 관심 영역 을 출력 변수로 설정한 모델일 수 있다. 인공지능 모델은 시지각 분석 시스템에 포함된 메모리에 저 장될 수 있다. 프로세서는 관심 장소에 방문하는 방문자들에 대한 데이터로부터 방문자의 속성 정보를 추출할 수 있다. 관심 장소는 검사자가 관심을 가지는 특정 장소일 수 있다. 구체적으로, 관심 장소는 검사자가 해당 장소에 방 문하는 방문자들이 어디를 주시하는지에 대해서 예측하고 싶은 장소일 수 있다. 방문자의 속성 정보는 해당 방문자에 대한 다양한 속성을 나타내는 정보일 수 있다. 예를 들어, 방문자의 속성 정보는 해당 방문자의 성별, 나이, 관심 분야, 직업 등 다양한 속성에 대한 정보일 수 있다. 방문자들에 대한 데이터는 다양한 방식으로 미리 수집하거나, 측정한 데이터일 수 있다. 프로세서는 방문자의 속성 정보를 기초로 인공지능 모델을 통하여 관심 장소를 표시하는 테스트 VR 영상 에 대한 관심 영역을 결정하도록 구성될 수 있다. 결과적으로, 피검사자가 관심 장소를 표시하는 테스트 VR 영상을 통한 관심 영역 분석 테스트를 직접 하지 않더라도, 관심 장소를 표시하는 테스트 VR 영상에 대한 관심 영역을 분석할 수 있다. 관 심 장소가 아닌 다른 장소를 표시한 테스트 VR 영상을 통한 분석 결과 및 방문자들에 대한 데이터를 통하 여, 관심 장소를 표시하는 테스트 VR 영상에 대한 관심 영역을 분석할 수 있는 것이다. 지금까지 설명된 본 발명의 실시예 및 앞으로 설명할 실시예에 따른 시지각 분석 방법은, 시선 추적 모듈, 프로세서, 인공지능 학습부에 의해 구동될 수 있는 프로그램의 형태로 구현될 수 있다. 여기서 프로그램은, 프로그램 명령, 데이터 파일 및 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 프로그램은 기계어 코드나 고급 언어 코드를 이용하여 설계 및 제작된 것일 수 있다. 프로그램은 상술한 부호 수정을 위한 방법을 구현하기 위하여 특별히 설계된 것일 수도 있고, 컴퓨터 소프트웨어 분야에서 통상의 기술 자에게 기 공지되어 사용 가능한 각종 함수나 정의를 이용하여 구현된 것일 수도 있다. 전술한 정보 표시 방법 을 구현하기 위한 프로그램은, 시선 추적 모듈, 프로세서, 인공지능 학습부에 의해 판독 가능한 기록매체에 기록될 수 있다. 이때, 기록매체는 메모리일 수 있다. 메모리는 전술한 동작 및 후술하는 동작을 수행하는 프로그램을 저장할 수 있으며, 메모리는 저장된 프로그램을 실행시킬 수 있다. 프로세서와 메모리가 복수인 경우에, 이들이 하나의 칩에 집적되는 것 도 가능하고, 물리적으로 분리된 위치에 마련되는 것도 가능하다. 메모리는 데이터를 일시적으로 기억하기 위한 S램(Static Random Access Memory, S-RAM), D랩(Dynamic Random Access Memory) 등의 휘발성 메모리를 포 함할 수 있다. 또한, 메모리는 제어 프로그램 및 제어 데이터를 장기간 저장하기 위한 롬(Read Only Memory), 이피롬(Erasable Programmable Read Only Memory: EPROM), 이이피롬(Electrically Erasable Programmable Read Only Memory: EEPROM) 등의 비휘발성 메모리를 포함할 수 있다. 프로세서는 각종 논리 회로와 연산 회로를 포함할 수 있으며, 메모리로부터 제공된 프로그램에 따라 데이터를 처리하고, 처리 결 과에 따라 제어 신호를 생성할 수 있다. 도 3은 일 실시예에 따른 테스트 VR 영상의 공간 개념을 도시한 도면이며, 도 4는 일 실시예에 따른 테스트 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할하는 것을 설명하기 위한 도면이다. 도 3을 참조하면, 테스트 VR 영상에 대한 3차원 공간은 수평 방향의 x·y와 수직방향의 z축으로 구성될 수 있다. 테스트 VR 영상을 3차원의 구면 좌표로 표현했을 때에도, 테스트 VR 영상이 미리 설정된 복수개의 단 위 영역으로 분할되는 것을 확인할 수 있다. 이때, 시선 위치가 테스트 VR 영상에서 움직이는 동선 및 시선 위치가 어느 단위 영역에 머무르면서 지나가는지도 확인할 수 있다. 한편, 테스트 VR 영상을 분석하여 시선 추적 데이터가 저장되는 과정에서는 도 4의 전개도 상에 저장되므 로 도 3의 x·y가 x값으로 저장되고, z축이 y값으로 저장될 수 있다. 한편, 이때 눈높이가 y값의 중심점이 될 수 있으나, 이에 한정되는 것은 아니다. 도 4를 참조하면, 테스트 VR 영상이 미리 설정된 복수개의 단위 영역으로 분할되는 방식을 확인할 수 있다. 이때, 분할된 테스트 VR 영상은 a행 내지 l행 중 어느 한 행에 위치하고, A열 내지 L열 중 어느 한 열에 위치한 단위 영역들로 이루어질 수 있다. 본 발명의 실시예에 따른 분할 방식은 도시된 바와 같이 12Х12 격자를 사용한 방식일 수 있다. 하지만, 이는 하나의 실시예일 뿐이며, 다른 격자를 이용하는 방식으로 테스트 VR 영상을 분할하더라도 문제없다. 예를 들어, 분할 방식은 6Х6 격자를 사용한 방식일 수도 있다. 도 5는 일 실시예에 따른 관심 영역을 결정하는 것을 설명하기 위한 도면이다. 도 5를 참조하면, 프로세서는 복수개의 단위 영역 중 단위 영역 별 주시 시간이 제1 기준시간 이상인 단위 영역을 제1 관심 영역으로 결정하도록 구성될 수 있다. 제1 관심 영역은, 피검사자가 제1 기준시간 이상 주시한 영역일 수 있다. 즉, 제1 관심 영역은 피검사자 가 어떠한 이유로 관심을 가지고 특정 시간 이상 주시한 영역이라고 분석될 수 있다. 제1 기준시간은 피검사자가 해당 영역을 주시하고, 해당 영역에 나타난 영상에 대하여 시각적으로 이해하 는데 필요한 시간일 수 있다. 즉, 제1 기준시간은 어떠한 대상에 대한 시각적 이해의 기준이 되는 시간일 수 있 다. 제1 기준시간은 0.3초일 수 있다. 즉, 이때 재1 관심 영역은 복수개의 단위 영역 중 피검사자가 0.3 초 이상 주시한 단위 영역일 수 있다. 도 5에서는 12Х12 격자에서 피검사자가 0.3초 이상 주시한 구 역을 확인할 수 있다. 한편, 제1 기준시간이 반드시 시각적 이해의 기준이 되는 시간이거나, 0.3초여야하는 것은 아니다. 프로세서는 테스트 VR 영상 및 제1 관심 영역을 합성하여 분석 결과 영상을 생성하도록 구성될 수 있다. 즉, 프로세서는 도 5에 도시된 바와 같이, 제1 관심 영역이 강조되어 테스트 VR 영상에 표시된 분석 결과 영상을 생성할 수 있다. 검사자는 이러한 분석 결과 영상을 통하여 피검사자가 테스트 VR 영상에서 어느 영역에 관심을 가지고 주시하였는지 확인할 수 있다. 도 6은 일 실시예에 따라 단위 영역 별 주시 시간을 측정하는 것을 설명하기 위한 도면이며, 도 7은 일 실시예 에 따라 분석된 주시 범위의 예시를 나타낸 도면이다. 도 6을 참조하면, 본 발명의 실시예에 따른 시지각 분석 시스템은 일정한 주기로 시선 위치를 획득할 수 있다. 즉, 시선 추적 모듈은 시선 위치를 1초당 미리 설정된 횟수만큼 획득할 수 있다. 예를 들어, 시선 추적 모듈은 시선 위치를 1초당 250번 획득할 수 있다. 즉 1/250초마다 한번 시선 위치를 획득할 수 있으나, 시선 위치를 획득하는 주기가 1/250초로 한정되는 것은 아니다. 이후부터는 시선 위치를 1초당 250번 획득하는 예시에 따라 설명한다. 프로세서는 시선 위치가 획득될 때마다, 시선 위치가 위치하는 하나의 단위 영역을 결정할 수 있다. 예를 들어, 프로세서는 시선 위치가 위치하는 하나의 단위 영역을 1초에 250번 결정할 수 있다. 프로세서는 시선 위치가 획득된 횟수를 단위 영역 별로 카운트할 수 있다. 예를 들어, d행의 B 열에 위치한 단위 영역에서 시선 위치는 352번 위치 정보가 획득되었을 수 있다. 프로세서는 카운트된 횟수에 기초하여 단위 영역 별 주시 시간을 측정할 수 있다. 구체적으로, 프로세서는 카운트된 횟수에 시선 위치를 획득하는 주기를 곱하여 단위 영역 별 주 시 시간을 측정할 수 있다. 예를 들어, d행의 B열에 위치한 단위 영역에서 시선 위치는 352번 위치 정보의 획득이 카운트되었고, 주기는 1/250초이므로, 해당 단위 영역에 대한 주시 시간은 352 Х 1/250초, 즉 1.408초일 수 있다. 결과적으로, 시선 추적 모듈이 일정한 주기로 시선 위치의 정보를 획득하면, 프로세서는 주기적 으로 획득된 시선 위치들이 어느 단위 영역에 몇 번 위치했는지 판단하고, 이에 기초하여 각 단위 영 역 별 주시 시간을 측정할 수 있다. 도 7을 참조하면, 피검사자가 특정 시간 이상 주시하여 우세하게 주시한 구역을 피검사자를 중심으로 표시할 수 있다. 예를 들어, 피검사자가 1초 이상 특정 구역을 주시하면 해당 구역을 우세하게 주시한 것으로 정의한 경우, 시선 위치가 250번 이상 획득된 단위 영역이 B열, C열, D열, E열, F열, G열, H열, I열이면 도시된 바 와 같은 240도의 피검사자가 우세하게 주시한 x축 구역을 나타낼 수 있다. 이때 마찬가지로, 시선 위치가 350번 이상 획득된 단위 영역들의 행들을 결정하고, 도시된 바와 같은 45도의 피검사자가 우세하게 주시한 y축 구역을 나타낼 수도 있다. 도 8은 일 실시예에 따른 관심 영역의 분석 결과의 예시를 도시한 도면이다. 도 8을 참조하면, 도8의 (a)는 피검사자가 0.1초 이상 주시한 관심 영역을 나타낸 것이며, 도8의 (b)는 피검사자가 0.2초 이상 주시한 관심 영역을 나타낸 것이고, 도8의 (c)는 피검사자가 0.3 초 이상 주시한 관심 영역을 나타낸 것일 수 있다. 즉, 본 발명에서는 주시 시간이 제1 기준시간 이상인 단위 영역에만 의미를 부여하는 것이 아니라, 단위 영역 별 주시시간이 제1 기준시간 미만, 제2 기준시간 이상인 단위 영역에도 의미를 부여하여 테스트 결과를 분석하는 것이 가능하다. 즉, 프로세서는 복수개의 단위 영역 중 단위 영역 별 주시 시간이 제2 기준시간 이상이고, 제1 기준시간 미만인 단위 영역을 제2 관심 영역으로 결정하도록 구성될 수 있다. 즉, 예를 들어 제1 기준시간이 0.3초이고, 제2 기준시간이 0.2초이면 제2 관심 영역은 복수개의 단위 영역 중 단위 영역 별 주시 시간이 0.2초 이상이고, 0.3초 미만인 단위 영역을 제2 관심 영역으로 결정할 수 있다. 반면, 제1 기준시간이 0.2초이고, 제2 기준시간이 0.1초이면 제2 관심 영역은 복수개의 단위 영역 중 단위 영역 별 주시 시간이 0.1초 이상이고, 0.2초 미만인 단위 영역을 제2 관심 영역으로 결정할 수도 있다. 제2 관심 영역은 피검사자가 테스트 VR 영상에 대하여 주의를 집중해서 본 영역 또는 의식적으로 주 시한 영역일 수 있다. 하지만, 이러한 제1 기준시간, 제2 기준시간, 제1 기준 영역 및 제2 기준 영역은 항상 그 시간 또는 의미가 정해져 있는 것이 아니며, 시지각 분석을 통한 테스트의 목적에 따라 다른 시간 또는 의미가 부여될 수도 있다. 한편, 도 8의 (a) 내지 (c)에 나타난 바와 같이 특정 기준 시간 이상 주시된 단위 영역이 무엇인지 판단하 면서, 특정 단위 영역에 대하여 몇 번 특정 기준 시간 이상 주시되었는지 판단하는 것도 가능할 수 있다. 예를 들어, 도 8의 (a)에서 d행 B열의 단위 영역은 피검사자가 한번 0.1초 이상 주시하고, 다른 단위 영역을 주시하다가 다시 d행 B열의 단위 영역을 주시하는 방식으로 총 4번 0.1초 이상 주시했을 수 있다. 또한, 더 8의 (c)에서 e행 H열의 단위 영역은 피검사자가 한번 0.3초 이상 주시하고, 다른 단위 영역 을 주시하다가 다시 e행 H열의 단위 영역을 주시하는 방식으로 총 2번 0.3초 이상 주시했을 수 있다. 프로세서는 전술한 바와 같이 피검사자가 특정한 단위 영역에 대하여 특정한 기준 시간 이상 주 시한 횟수를 판단하는 방식으로 테스트 VR 영상에 대한 관심 영역을 분석할 수 있다. 도 9는 일 실시예에 따른 시선 위치가 측정되는 위치를 보정하는 것을 도시한 도면이다. 전술한 실시예에 따라 시지각 분석을 하려면 시선 추적 모듈이 피검사자의 시선을 정확하게 추적할 수 있어야 한다. 만약, 시선 추적 모듈이 피검사자가 주시하는 영역이 아닌, 다른 영역을 피검사자의 시선 위치 가 위치한 영역이라고 판단하면 관심 영역을 분석하는데 오류가 발생할 수 있다. 예를 들어, 실제로 피검사자는 테스트 VR 영상에서 e행 H열을 주시하였으나. 시선 추적 모듈이 피검사자의 시선 위치가 f행 F열의 단위 영역에 위치한다고 판단하면, 항상 피검사자가 테 스트 VR 영상에서 주시하는 영역보다 좌측으로 두 열, 아래로 한 행 떨어진 영역을 관심 영역으로 판단하는 오류가 발생할 수 있다. 따라서, 본격적으로 테스트 VR 영상을 피검사자에게 표시하고, 시선 위치를 추적하기 전에, 시 선 추적 모듈이 제대로 시선 위치를 추적하는지 여부를 판단하고, 만약 오류가 있다면 이를 보정하는 것이 바람직할 수 있다. 도 9를 참조하면, 프로세서는 기준 단위 영역에 인디케이터를 표시하도록 디스플레이 모듈(11 0)을 제어할 수 있다. 구체적으로, 검사가 시작되기 전에, 피검사자는 아무것도 표시되지 않은 VR 영상을 디스플레이 모듈 을 통해 볼 수 있다. 이후, 디스플레이 모듈은 기준 단위 영역에 인디케이터를 표시할 수 있다. 기준 단위 영역은 복수개의 단위 영역 중 어느 하나의 단위 영역으로서, 임의로 결정되는 방식 으로 결정되거나, 미리 설정된 단위 영역일 수 있다. 인디케이터는 피검사자의 눈에 잘 띄는 색상 또는 모양의 표시자일 수 있다. 아무것도 표시되지 않던 디스플레이 모듈의 특정 위치에 인디케이터가 나타나면 피검사자는 무 의식적으로 해당 인디케이터를 주시하게 될 수 있다. 즉, 이때 피검사자는 무의식적으로 해당 인디케 이터가 위치한 기준 단위 영역을 주시할 수 있다. 이때, 만약 시선 추적 모듈이 정상적으로 피검사자의 시선을 추적한다면, 시선 위치는 기준 단 위 영역에서 추적될 것이다. 반면, 시선 위치가 기준 단위 영역에서 추적되지 않았다면, 시선 추적 모듈이 시선 위치를 정상적으로 추적하지 못하는 것일 수 있다. 예를 들어, 기준 단위 영역이 d행 H열의 단위 영역이고, 인디케이터가 d행 H열의 단위 영역 에 표시되었음에도, 시선 위치가 e열 F행의 단위 영역에서 추적된 경우 시선 추적 모듈이 시선 위치를 정상적으로 추적하지 못한 것일 수 있다. 프로세서는 인디케이터가 표시될 때 시선 위치가 위치하는 단위 영역이 기준 단위 영역 이 아니면, 시선 위치가 측정되는 위치를 보정하도록 시선 추적 모듈을 제어할 수 있다. 예를 들어, 인디케이터가 d행 H열의 단위 영역에 표시되었음에도 시선 위치가 e열 F행의 단위 영역에서 추적된 경우, 프로세서는 추적되는 시선 위치가 두 열 우측으로, 한 행 위로 변경될 수 있도록 시선 위치가 측정되는 위치를 보정할 수 있다. 이상에서 설명된 구성요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구성요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통 상의 지식을 가진 자에게 용이하게 이해될 것이다. 도 10은 일 실시예에 따른 시지각 분석 방법의 순서도이다. 이는 본 발명의 목적을 달성하기 위한 바람직한 실 시예일 뿐이며, 필요에 따라 일부 구성이 추가되거나 삭제될 수 있음은 물론이다. 도 10을 참조하면, 디스플레이 모듈은 테스트 VR 영상을 표시할 수 있다. 이때, 테스트 VR 영 상은 피검사자에게 360도 시청이 가능한 영상일 수 있다. 시선 위치 추적 모듈은 테스트 VR 영상에서의 피검사자의 시선 위치를 추적할 수 있다 . 즉, 시선 추적 모듈은 테스트 VR 영상 상에서 피검사자가 주시하고 있는 특정 위치를 추적할 수 있다. 프로세서는 테스트 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할할 수 있다. 이때, 본 발명의 실시예에 따른 분할 방식은 12Х12 격자를 사용한 방식일 수 있으나, 이는 하나의 실시예일 뿐 이며, 다른 격자를 이용하는 방식으로 테스트 VR 영상을 분할하더라도 문제없다. 프로세서는 시선 위치를 1초당 미리 설정된 횟수만큼 획득할 수 있다. 즉, 시선 추적 모듈 은 시선 위치를 1초당 미리 설정된 횟수만큼 획득할 수 있다. 프로세서는 시선 위치가 획득될 때마다 시선 위치가 위치하는 하나의 단위 영역을 결정할 수 있다. 즉, 프로세서는 시선 위치가 위치하는 하나의 단위 영역을 1초에 미리 설정된횟수만큼 결정할 수 있다. 프로세서는 시선 위치가 획득된 횟수를 단위 영역 별로 카운트할 수 있다. 프로세서는 카운트된 횟수에 기초하여 단위 영역별 주시 시간을 측정할 수 있다. 이때, 프로세 서는 카운트된 횟수에 시선 위치를 획득하는 주기를 곱하여 단위 영역 별 주시 시간을 측정할 수 있다. 프로세서는 단위 영역별 주시 시간에 기초하여 테스트 VR 영상에 대한 관심 영역을 분석할 수 있다. 예를 들어, 프로세서는 복수개의 단위 영역 중 단위 영역 별 주시 시간이 제1 기준시간 이상인 단위 영역을 제1 관심 영역으로 결정하고, 복수개의 단위 영역 중 단위 영역 별 주시 시간이 제2 기준시간 이상이고, 제1 기준시간 미만인 단위 영역을 제2 관심 영역으로 결정하도록 구성될 수 있다. 검사자는 테스트 목적에 따라 미리 제1 기준시간 및 제2 기준시간을 임의로 설정할 수 있다. 테스트 VR 영상에 대한 제1 관심 영역 및 제2 관심 영역의 위치 및 분포에 따라 테스트 목적에 맞는 시지 각 분석이 가능할 수 있다. 도 11은 또 다른 실시예에 따른 시지각 분석 방법의 순서도이다. 여러 명의 피검사자에 대하여 검사를 진행할 경우, 각 피검사자의 시선 위치를 추적할 때마다 개인차가 발생할 수 있다. 즉, 피검사자들이 테스트 VR 영상 상에서 동일한 위치를 주시하더라도, 개 인차에 의해서 시선 추적 모듈은 피검사자 별로 다른 지점을 시선 위치로 추적하는 문제가 생길 수 있다. 따라서, 피검사자 별로 테스트할 때마다, 시선 추적 모듈이 추적하는 시선 위치를 적 절하게 보정하는 것이 바람직할 수 있다. 도 11을 참조하면, 디스플레이 모듈은 기준 단위 영역에 인디케이터를 표시할 수 있다. 이때, 프로세서는 기준 단위 영역에 인디케이터가 표시되도록 디스플레이 모듈을 제어할 수 있다. 프로세서는 인디케이터가 표시될 때 시선 위치가 위치하는 단위 영역이 기준 단위 영역 인지 여부를 판단할 수 있다. 만약 인디케이터가 표시될 때 시선 위치가 위치하는 단위 영역이 기준 단위 영역이 아니면 (2002의 '아니오'), 프로세서는 시선 위치가 측정되는 위치를 보정하도록 시선 추적 모듈을 제 어할 수 있다. 이후, 시선 추적 모듈이 피검사자의 시선을 정확하게 추적하는 상태가 되면, 프로세서는 피검사 자 별로 테스트 VR 영상에 대한 관심 영역을 분석할 수 있다. 만약 인디케이터가 표시될 때 시선 위치가 위치하는 단위 영역이 기준 단위 영역이면(2002 의 '예'), 프로세서는 시선 위치가 측정되는 위치를 보정하지 않고 각 피검사자 별로 테스트 VR 영상에 대한 관심 영역을 분석할 수 있다. 전술한 시선 위치가 측정되는 위치의 보정 과정은 각 피검사자가 테스트를 진행할 때마다 진행될 수 있다. 결과적으로 각 피검사자의 개인차에도 불구하고, 시선 추적 모듈은 정확한 시선 위치를 측정할 수 있다. 인공지능 학습부는 피검사자의 속성 정보를 입력 변수로 하고, 테스트 VR 영상에 대한 관심 영 역을 출력 변수로 설정하여 인공지능 모델을 학습할 수 있다. 프로세서는 관심 장소에 방문하는 방문자들에 대한 데이터로부터 방문자의 속성 정보를 추출할 수 있다 . 예를 들어, 프로세서는 미리 수집되거나 측정된 데이터로부터 방문자들의 성별 정보, 나이 정보, 관심 분야 정보, 직업 정보 등 다양한 속성 정보를 추출할 수 있다. 프로세서는 방문자의 속성 정보를 기초로 인공지능 모델을 통하여 관심 장소를 표시하는 테스트 VR 영상 에 대한 관심 영역을 결정할 수 있다. 이때, 프로세서는 관심 장소를 표시하는 테스트 VR 영상 및 인공지능 모델을 통하여 결정된 관심 영역을 합성하여 분석 결과 영상을 생성할 수 있 다. 본 발명의 실시예에 따른 시지각 분석 시스템의 성능을 검증하기 위하여 별마당 도서관의 내부 공간을 대 상으로 HMD(Head Mounted Display) 기반 시선추적 장비를 착용한 피험자가 VR공간을 주시하는 과정에 대한 주시 특성을 분석하였다. 또한, 다음과 같은 순서로 사진 촬영 및 실험이 진행되었다. 우선, 개방감을 주는 대형공간으로서 별마당 도서관을 선정하여 360°카메라로 사진촬영을 하였다. 촬영된 사진 중에서 주시실험과정에서 불필요하게 피험자의 시선을 유도할 수 있는 요소가 가장 적은 이미지를 실험 대상으 로 선정하였다. 이후, 남자 피험자 1명씩 별도로 마련된 실험실에서 VR기기를 착용하여 시선추적 실험을 실시하였다. 마지막으로, 주시데이터는 250㎐로 저장되는데, 자체 개발한 프로그램을 통해 Raw Data의 코딩을 실시한 후에 주시특성별 분석 자료로 활용하였다. VR실험은 남자 대학생 24명을 대상으로 2018년 6월 7일~8일로 2일간 실시하였다. 시선추적 실험에서 목적성 문 구는 중요한 역할을 차지하는데, 목적성 문구로는 \"당신은 새로 만들어진 별마당 도서관을 견학하는 목적으로 코엑스 몰을 방문했습니다. 별마당 도서관 중앙에서 촬영된 3차원 이미지를 VR기기를 통해 보실 수 있습니다. 이 공간은 도서관 이외에 전시공간으로도 활용되고 있는데, 얼마나 실제 공간에 있는 것처럼 보이는지를 보시고 공간을 VR로 보는 것이 어떤지 나중에 평가해 주시기 바랍니다.\"를 제시하였다. 시선추적 실험은 실험실과 대기실을 두고 실시하는데 대기실에서 실험종료까지의 과정은 다음과 같다. 1. 대기실에서 보조원으로부터 실험 전반에 대한 안내와 목적 등에 대한 설명을 듣는다. 2. 보조원의 안내에 따라 실험실에 입장 및착석한 후에 조정자의 도움을 받아 HMD 헤드셋을 착용하고 장비와 피 험자간의 교정(calibration)을 실시한다. 3. 목적성 문구에 대한 안내 화면을 본 후에, 본 실험은 130초 동안 실시되었다. 주시데이터는 250㎐로 생성되 며, 1초에 250개의 주시데이터가 저장되었다. VR실험을 통해 획득한 Raw Data는 130초Х250=32,500개이지만, 분석 범위를 120초로 설정한 관계로 피험자별 30,000개의 데이터가 분석대상이다. 주시특성을 분석하기 위해서는 어떤 시간범위를 기준으로 삼는가 하는 것이 중요한데, 본 연구에서는 5초 범위로 시간구간을 설정하여 각 시간구간에 누적된 Fixation 횟수(횟수Х1/250=주 시시간)를 산출하였다. 즉 각 피험자를 대상으로 24개 시간구간별 Fixation 횟수를 구하고, 시간으로 환산하는 과정을 통해 주시특성을 분석하였다. 본 연구에서는 도 4에 도시된 바와 같이 12Х12격자를 사용하였으며 각 격자 구역별 주시시간이 분석대상이다. 구역별 시간을 구하기 위해, 2차 코딩을 통해 Fixation 데이터만 남겼다. 또한 피험자의 24개 시간구간별 우세 주시를 어떻게 다룰 것인가에 대한 사례 분석을 통해 분석 기준을 설정하였다. 전체 주시시간을 대상으로 도 6의 구역별 분포를 보면, 0.5초 이상 주시가 집중된 구역도 25개 구역이며 1초 이 상 주시가 집중된 구역도 7개 구역이다. 1초 이상 주시가 집중된 곳 7개 구역을 보면, 수평영역으로 d 내지 f영 역에 집중된 것을 알 수 있다. 눈높이가 y축의 fg구역의 경계라는 점을 고려한다면 h이하 구역은 눈보다 아래에 속하는 하부공간으로 고개를 숙인상태에서 VR을 주시하는 경우의 주시빈도가 된다. 도 6에서 1초 이상 주시한 구역을 공간 주시와 연계시켜 살펴보면 도 7의 상단의 평면 모식도로 설명이 가능하 다. 중심에 서 있는 피험자는 정면방향에 해당하는 FG의 중간 위치를 주시하면서 VR실험을 시작한다. x축 구역 의 우세 주시 구역은 좌측 뒤에 있는 B구역과 우측 옆에 있는 I구역 사이 영역을 중심으로 주시한 것을 알 수 있다. 이것을 3차원 공간개념도로 도식화시킨 것이 도 7의 하단 도면이다. 1개 구역의 수평 주시각도가 30°, 수직 주시각도는 15° 이므로 8개 구역의 240° 범위를 중점으로 주시한 구역으로 볼 수 있다. 상하 주시범위로 는 d 내지 f의 3개 구역의 45° 범위이다. 즉 분석 사례가 된 1번 피험자는 전체 120초의 주시시간동안 좌우로 240°, 상하로 45°의 범위에 있는 공간정보를 우세하게 주시한 것을 알 수 있다. 한편, 위에서는 각 구역별 1초 이상 우세하게 주시한 구역을 정리하였지만, 구역별 시간을 0.3초 이상의 '시각 적 이해'로 한정해서 정리한 것이 도 5의 상단의 도면이다. 도 6의 1초 이상에서 도 5의 0.3초 이상으로 정리할 경우, g열에 대한 우세주시가 높아진 것이 특징이다. 즉, 분석 기준 시간을 어떻게 설정하는가에 따라 우세 주 시 구역의 분포가 달라질 수 있다."}
{"patent_id": "10-2021-0055573", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 발명이 속하는 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 발명이 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서는 안 된다."}
{"patent_id": "10-2021-0055573", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 시지각 분석 시스템을 도시한 도면이다. 도 2는 일 실시예에 따른 시지각 분석 시스템의 구성도이다. 도 3은 일 실시예에 따른 테스트 VR 영상의 공간 개념을 도시한 도면이다. 도 4는 일 실시예에 따른 테스트 VR 영상을 미리 설정된 복수개의 단위 영역으로 분할하는 것을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 관심 영역을 결정하는 것을 설명하기 위한 도면이다. 도 6은 일 실시예에 따라 단위 영역 별 주시 시간을 측정하는 것을 설명하기 위한 도면이다. 도 7은 일 실시예에 따라 분석된 주시 범위의 예시를 나타낸 도면이다. 도 8은 일 실시예에 따른 관심 영역의 분석 결과의 예시를 도시한 도면이다. 도 9는 일 실시예에 따른 시선 위치가 측정되는 위치를 보정하는 것을 도시한 도면이다. 도 10은 일 실시예에 따른 시지각 분석 방법의 순서도이다. 도 11은 또 다른 실시예에 따른 시지각 분석 방법의 순서도이다."}
