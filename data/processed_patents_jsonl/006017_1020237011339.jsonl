{"patent_id": "10-2023-7011339", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0065287", "출원번호": "10-2023-7011339", "발명의 명칭": "차량용 AR 화면을 위한 시스템 및 차량용 AR 화면 서비스 제공 방법", "출원인": "엘지전자 주식회사", "발명자": "이진상"}}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "AR 화면이 표시되는 디스플레이 및 위치 정보를 획득하는 GPS 모듈을 포함하는 차량;상기 AR 화면을 위한 데이터를 상기 차량에 제공하는 제1 서버; 및상기 제1 서버로 광고 데이터를 제공하는 제2 서버;를 포함하고,상기 AR 화면은, 상기 광고 데이터에 기반한 제1 AR 컨텐츠가 표시되는 제1 영역; 및상기 위치 정보에 기반한 제2 AR 컨텐츠가 표시되는 제2 영역;을 포함하며,상기 제1 영역 및 상기 제2 영역은 상기 차량의 주행 구간을 따라 배치되는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 차량은, 상기 차량의 외부 영상을 촬영하는 촬영 장치;상기 AR 화면을 위한 데이터를 수신하고 상기 외부 영상을 송신하는 송수신부; 및 상기 AR 화면을 상기 디스플레이에 표시하기 위한 프로세서;를 더 포함하는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 서버는, 상기 외부 영상을 상기 차량으로부터 수신하고, 상기 외부 영상을 기초로 상기 차량의 주행 구간 중 미리 설정된 구간에 상기 제1 영역을 배치하되, 상기 제1 서버는,상기 외부 영상으로부터 상기 차량의 주행 구간에 대한 정보를 획득하는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제1 서버는, 상기 차량의 주행 구간 중 미리 설정된 구간에 상기 제1 영역을 배치하는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 제1 서버는, 상기 제1 영역이 배치된 구간을 제외한 나머지 구간에 상기 제2 영역을 배치하는 것인, 차량용 AR 화면을 위한시스템. 공개특허 10-2023-0065287-3-청구항 6 제1항에 있어서,상기 제2 서버는, 상기 차량으로부터 요청된 카테고리를 기초로 상기 광고 데이터를 상기 제1 서버에 제공하는 것인, 차량용 AR화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제1 서버는, 상기 차량으로부터 미리 설정된 조건에 따라 상기 제1 영역 또는 상기 제2 영역을 배치할 구간에 대한 정보를수신하는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 차량은, 상기 차량의 주행 구간 중 상기 제1 영역과 상기 제2 영역이 표시되지 않는 빈 구간을 감지하고, 상기 빈 구간에 대한 데이터를 상기 제1 서버로 전송하는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 제1 서버는, 상기 제2 서버로부터 상기 제1 영역을 배치할 지정 구간에 대한 정보를 수신하고, 상기 제1 영역은, 상기 지정 구간을 따라 배치되는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 제1 AR 컨텐츠는 AR Wall을 포함하고, 상기 제2 AR 컨텐츠는 POI(Point of Interest) 이미지를 포함하는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 제2 AR 컨텐츠는 POI(Point of Interest) 이미지를 포함하고, 상기 POI 이미지는,상기 차량이 상기 POI 이미지가 나타내는 지점까지 도착하기까지 예상되는 주행 난이도에 따라 변경되는 것인,차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 주행 난이도는, 거리, 예상 도착 시간, 예상 경과 시간, 유턴 횟수 및 도로 공사 유무 중 적어도 하나에 근거하여 예상되는 것인, 차량용 AR 화면을 위한 시스템.공개특허 10-2023-0065287-4-청구항 13 제11항에 있어서,상기 주행 난이도는, 상기 POI 이미지가 나타내는 지점의 주차 용이성에 근거하여 예상되는 것인, 차량용 AR 화면을 위한 시스템."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "차량으로부터 AR 화면 요청 데이터를 수신하는 단계;상기 차량으로부터 주행 데이터를 수신하는 단계;외부 서버로부터 광고 데이터를 수신하는 단계;상기 주행 데이터와 상기 광고 데이터에 기초하여 AR 화면에 대한 제1 데이터를 생성하는 단계; 및상기 제1 데이터를 상기 차량으로 전송하는 단계;를 포함하고, 상기 AR 화면은, 상기 광고 데이터에 기초한 제1 AR 컨텐츠가 표시되는 제1 영역; 및상기 위치 정보에 기초한 제2 AR 컨텐츠가 표시되는 제2 영역;을 포함하며,상기 제1 영역 및 상기 제2 영역은 상기 차량의 주행 구간을 따라 배치되는 것인, 차량용 AR 화면 서비스 제공방법."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제1 영역은, 상기 차량의 주행 구간 중 미리 설정된 구간에 배치되는 것인, 차량용 AR 화면 서비스 제공 방법."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 제2 영역은, 상기 제1 영역이 배치된 구간을 제외한 나머지 구간에 배치되는 것인, 차량용 AR 화면 서비스 제공 방법."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 차량으로부터 상기 제1 영역과 상기 제2 영역을 배치할 구간에 대한 정보를 수신하는 단계;를 더포함하되, 상기 정보는, 상기 차량의 주행 구간 중 상기 제1 영역과 상기 제2 영역이 표시되지 않는 빈 구간에 대한 정보인 것인, 차량용 AR 화면 서비스 제공 방법."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서, 상기 외부 서버로부터 상기 제1 영역을 배치할 지정 구간에 대한 정보를 수신하는 단계;를 더 포함하되, 상기 제1 영역은, 상기 지정 구간을 따라 배치되는 것인, 차량용 AR 화면 서비스 제공 방법.공개특허 10-2023-0065287-5-청구항 19 제14항에 있어서, 상기 제1 AR 컨텐츠는 AR Wall을 포함하고, 상기 제2 AR 컨텐츠는 POI(Point of Interest) 이미지를 포함하는 것인, 차량용 AR 화면 서비스 제공 방법."}
{"patent_id": "10-2023-7011339", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 제2 AR 컨텐츠는 POI(Point of Interest) 이미지를 포함하고, 상기 POI 이미지는,상기 차량이 상기 POI 이미지가 나타내는 지점까지 도착하기까지 예상되는 주행 난이도에 따라 변경되는 것인,차량용 AR 화면 서비스 제공 방법."}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "차량용 AR 화면을 위한 시스템 및 차량용 AR 화면 서비스 제공 방법이 개시된다. 본 명세서는 AR 화면이 표시되 는 디스플레이 및 위치 정보를 획득하는 GPS 모듈을 포함하는 차량, 상기 AR 화면을 위한 데이터를 상기 차량에 제공하는 제1 서버, 및 상기 제1 서버로 광고 데이터를 제공하는 제2 서버를 포함하고, 상기 AR 화면은 상기 광 고 데이터에 기반한 제1 AR 컨텐츠가 표시되는 제1 영역 및 상기 위치 정보에 기반한 제2 AR 컨텐츠가 표시되는 제2 영역을 포함하며, 상기 제1 영역 및 상기 제2 영역은 상기 차량의 주행 구간을 따라 배치될 수 있다."}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 차량용 AR 화면을 위한 시스템 및 차량용 AR 화면 서비스 제공 방법에 관한 것이다."}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자동차는 사용되는 원동기의 종류에 따라, 내연기관(internal combustion engine) 자동차, 외연기관(external combustion engine) 자동차, 가스터빈(gas turbine) 자동차 또는 전기자동차(electric vehicle) 등으로 분류될 수 있다. 최근 꾸준한 기술개발의 결과, 차량은 수많은 정보들을 증강 현실(Augmented Reality, 이하 AR로 기재함) 기술 을 사용하여 표현할 수 있다. 이와 같이 AR 이미지 등을 사용하여 차량의 디스플레이를 표시할 때, 차량이 주행 중인 구간에서 낭비되는 빈 공간들이 존재하고, 그동안 낭비되는 빈 공간들을 활용하기 위한 많은 연구가 있었 다. 특히, 낭비되는 빈 공간들에 광고를 표시하여 차량의 탑승자에게 다양한 광고를 효과적으로 제공할 수 있는 기 술이 필요하다."}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서는, 차량에 AR 화면을 제공하는 것을 목적으로 한다. 또한, 본 명세서는, 차량에 표시되는 AR 화면에 AR 컨텐츠를 활용하여 차량 탑승객에게 광고 서비스를 제공하는 것을 목적으로 한다. 또한, 본 명세서는, 차량에 표시되는 AR 화면에 AR 컨텐츠를 활용하여 광고뿐만 아니라 다양한 정보를 함께 제 공하는 것을 목적으로 한다. 또한, 본 명세서는 차량에 제공되는 서비스에 광고 서비스를 제공함으로써 탑승객이 보다 효과적으로 광고를 접 할 수 있도록 하는 시스템 및 서비스를 제안하는 것을 목적으로 한다. 또한, 본 명세서는 AR 화면에서 다양한 정보들을 나타낼 수 있는 POI 이미지들과 함께 AR 광고 컨텐츠들을 표시 할 수 있는 효과적인 시스템 및 서비스를 제안하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은"}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 이하의 발명의 상세한 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위하여, 본 명세서는, AR 화면이 표시되는 디스플레이 및 위치 정보를 획득하는 GPS 모 듈을 포함하는 차량, 상기 AR 화면을 위한 데이터를 상기 차량에 제공하는 제1 서버 및 상기 제1 서버로 광고 데이터를 제공하는 제2 서버를 포함하고, 상기 AR 화면은 상기 광고 데이터에 기반한 제1 AR 컨텐츠가 표시되는 제1 영역 및 상기 위치 정보에 기반한 제2 AR 컨텐츠가 표시되는 제2 영역을 포함하며, 상기 제1 영역 및 상기 제2 영역은 상기 차량의 주행 구간을 따라 배치될 수 있다. 또한, 상기 차량은 상기 차량의 외부 영상을 촬영하는 촬영 장치, 상기 AR 화면을 위한 데이터를 수신하고 상기 외부 영상을 송신하는 송수신부 및 상기 AR 화면을 상기 디스플레이에 표시하기 위한 프로세서를 더 포함할 수 있다. 이때, 상기 제1 서버는 상기 외부 영상을 상기 차량으로부터 수신하고, 상기 외부 영상을 기초로 상기 차량의 주행 구간 중 미리 설정된 구간에 상기 제1 영역을 배치하되, 상기 제1 서버는 상기 외부 영상으로부터 상기 차 량의 주행 구간에 대한 정보를 획득할 수 있다. 또한, 상기 제1 서버는 상기 차량의 주행 구간 중 미리 설정된 구간에 상기 제1 영역을 배치할 수 있다. 이때, 상기 제1 서버는 상기 제1 영역이 배치된 구간을 제외한 나머지 구간에 상기 제2 영역을 배치할 수 있다. 또한, 상기 제2 서버는 상기 차량으로부터 요청된 카테고리를 기초로 상기 광고 데이터를 상기 제1 서버에 제공 할 수 있다. 또한, 상기 제1 서버는 상기 차량으로부터 미리 설정된 조건에 따라 상기 제1 영역 또는 상기 제2 영역을 배치 할 구간에 대한 정보를 수신할 수 있다. 이때, 상기 차량은 상기 차량의 주행 구간 중 상기 제1 영역과 상기 제2 영역이 표시되지 않는 빈 구간을 감지 하고, 상기 빈 구간에 대한 데이터를 상기 제1 서버로 전송할 수 있다. 또한, 상기 제1 서버는 상기 제2 서버로부터 상기 제1 영역을 배치할 지정 구간에 대한 정보를 수신하고, 상기 제1 영역은 상기 지정 구간을 따라 배치될 수 있다. 또한, 상기 제1 AR 컨텐츠는 AR Wall을 포함하고, 상기 제2 AR 컨텐츠는 POI(Point of Interest)를 포함할 수 있다. 또한, 상기 제2 AR 컨텐츠는 POI(Point of Interest)를 포함하고, 상기 POI는 상기 차량이 상기 POI가 나타내 는 지점까지 도착하기까지 예상되는 주행 난이도에 따라 변경될 수 있다. 이때, 상기 주행 난이도는 거리, 예상 도착 시간, 예상 경과 시간, 유턴 횟수 및 도로 공사 유무 중 적어도 하 나에 근거하여 예상될 수 있다. 또한, 상기 주행 난이도는 상기 POI가 나타내는 지점의 주차 용이성에 근거하여 예상될 수 있다. 또한, 상술한 과제를 해결하기 위하여, 본 명세서는 차량으로부터 AR 화면 요청 데이터를 수신하는 단계, 상기 차량으로부터 주행 데이터를 수신하는 단계, 외부 서버로부터 광고 데이터를 수신하는 단계, 상기 주행 데이터 와 상기 광고 데이터에 기초하여 AR 화면에 대한 제1 데이터를 생성하는 단계 및 상기 제1 데이터를 상기 차량 으로 전송하는 단계를 포함하고, 상기 AR 화면은 상기 광고 데이터에 기초한 제1 AR 컨텐츠가 표시되는 제1 영 역 및 상기 위치 정보에 기초한 제2 AR 컨텐츠가 표시되는 제2 영역을 포함하며, 상기 제1 영역 및 상기 제2 영 역은 상기 차량의 주행 구간을 따라 배치될 수 있다. 또한, 상기 제1 영역은 상기 차량의 주행 구간 중 미리 설정된 구간에 배치될 수 있다. 또한, 상기 제2 영역은, 상기 제1 영역이 배치된 구간을 제외한 나머지 구간에 배치될 수 있다. 또한, 본 명세서는 상기 차량으로부터 상기 제1 영역과 상기 제2 영역을 배치할 구간에 대한 정보를 수신하는 단계를 더 포함하되, 상기 정보는 상기 차량의 주행 구간 중 상기 제1 영역과 상기 제2 영역이 표시되지 않는 빈 구간에 대한 정보일 수 있다. 또한, 본 명세서는 상기 외부 서버로부터 상기 제1 영역을 배치할 지정 구간에 대한 정보를 수신하는 단계를 더 포함하되, 상기 제1 영역은 상기 지정 구간을 따라 배치될 수 있다. 또한, 상기 제1 AR 컨텐츠는 AR Wall을 포함하고, 상기 제2 AR 컨텐츠는 POI(Point of Interest)를 포함할 수 있다. 이때, 상기 제2 AR 컨텐츠는 POI(Point of Interest)를 포함하고, 상기 POI는 상기 차량이 상기 POI가 나타내 는 지점까지 도착하기까지 예상되는 주행 난이도에 따라 변경될 수 있다."}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서는, 차량에 AR 화면을 제공할 수 있는 효과가 있다. 또한, 본 명세서는, 차량에 표시되는 AR 화면에 AR 컨텐츠를 활용하여 차량 탑승객에게 광고 서비스를 제공할 수 있는 효과가 있다. 또한, 본 명세서는, 차량에 표시되는 AR 화면에 AR 컨텐츠를 활용하여 광고뿐만 아니라 다양한 정보를 함께 제 공할 수 있는 효과가 있다. 또한, 본 명세서는 차량에 제공되는 서비스에 광고 서비스를 제공함으로써 탑승객이 보다 효과적으로 광고를 접 할 수 있도록 하는 시스템 및 서비스를 제공할 수 있는 효과가 있다. 또한, 본 명세서는 AR 화면에서 다양한 정보들을 나타낼 수 있는 POI 이미지들과 함께 AR 광고 컨텐츠들을 표시 할 수 있는 효과적인 시스템 및 서비스를 제공할 수 있는 효과가 있다. 본 명세서에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 명세서의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 주행 차량 외관 도 1은 본 발명의 실시예에 따른 차량을 도시한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 차량은, 도로나 선로 위를 주행하는 수송 수단으로 정의된다. 차량은, 자동차, 기차, 오토바이를 포함하는 개념이다. 차량은, 동력원으로서 엔진을 구비하는 내연기 관 차량, 동력원으로서 엔진과 전기 모터를 구비하는 하이브리드 차량, 동력원으로서 전기 모터를 구비하는 전 기 차량등을 모두 포함하는 개념일 수 있다. 차량은 개인이 소유한 차량일 수 있다. 차량은, 공유형 차 량일 수 있다. 차량은 자율 주행 차량일 수 있다. 차량의 구성 요소 도 2는 본 발명의 실시예에 따른 차량의 제어 블럭도이다. 도 2를 참조하면, 차량은, 사용자 인터페이스 장치, 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 구동 제어 장치, 자율 주행 장치, 센싱부 및 위치 데이터 생 성 장치를 포함할 수 있다. 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 구동 제어 장치, 자율 주행 장치, 센싱부 및 위치 데이터 생성 장치는 각각이전기적 신호를 생성하고, 상호간에 전기적 신호를 교환하는 전자 장치로 구현될 수 있다. 1) 사용자 인터페이스 장치 사용자 인터페이스 장치는, 차량과 사용자와의 소통을 위한 장치이다. 사용자 인터페이스 장치는, 사용자 입력을 수신하고, 사용자에게 차량에서 생성된 정보를 제공할 수 있다. 차량은, 사용자 인터페이스 장치를 통해, UI(User Interface) 또는 UX(User Experience)를 구현할 수 있다. 사용 자 인터페이스 장치는, 입력 장치, 출력 장치 및 사용자 모니터링 장치를 포함할 수 있다. 2) 오브젝트 검출 장치 오브젝트 검출 장치는, 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 오브젝트에 대한 정보는, 오브젝트의 존재 유무에 대한 정보, 오브젝트의 위치 정보, 차량과 오브젝트와의 거리 정보 및 차 량과 오브젝트와의 상대 속도 정보 중 적어도 어느 하나를 포함할 수 있다. 오브젝트 검출 장치는, 차 량 외부의 오브젝트를 검출할 수 있다. 오브젝트 검출 장치는, 차량 외부의 오브젝트를 검출할 수 있는 적어도 하나의 센서를 포함할 수 있다. 오브젝트 검출 장치는, 카메라, 레이다, 라이다, 초음파 센서 및 적외선 센서 중 적어도 하나를 포함할 수 있다. 오브젝트 검출 장치는, 센서에서 생성되는 센싱 신호에 기초하여 생성된 오브젝트에 대한 데이터를 차량에 포함된 적어도 하나의 전자 장치에 제공할 수 있다. 2.1) 카메라 카메라는 영상을 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 카메라는 적어도 하나의 렌즈, 적어도 하나의 이미지 센서 및 이미지 센서와 전기적으로 연결되어 수신되는 신호를 처리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 카메라는, 모노 카메라, 스테레오 카메라, AVM(Around View Monitoring) 카메라 중 적어도 어느 하나일 수 있다. 카메라는, 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오브젝트와의 거리 정보 또는 오브젝트와의 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 획득된 영상에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 핀 홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 스테레오 카메라에서 획득된 스테레오 영상에서 디스패러티(disparity) 정보를 기초로 오 브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 카메라는, 차량 외부를 촬영하기 위해 차량에서 FOV(field of view) 확보가 가능한 위치에 장착될 수 있다. 카 메라는, 차량 전방의 영상을 획득하기 위해, 차량의 실내에서, 프런트 윈드 쉴드에 근접하게 배치될 수 있다. 카메라는, 프런트 범퍼 또는 라디에이터 그릴 주변에 배치될 수 있다. 카메라는, 차량 후방의 영상을 획득하기 위해, 차량의 실내에서, 리어 글라스에 근접하게 배치될 수 있다. 카메라는, 리어 범퍼, 트렁크 또는 테일 게이 트 주변에 배치될 수 있다. 카메라는, 차량 측방의 영상을 획득하기 위해, 차량의 실내에서 사이드 윈도우 중 적어도 어느 하나에 근접하게 배치될 수 있다. 또는, 카메라는, 사이드 미러, 휀더 또는 도어 주변에 배치될 수 있다. 2.2) 레이다 레이다는 전파를 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 레이다는, 전자파 송신부, 전자파 수신부 및 전자파 송신부 및 전자파 수신부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리되 는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 레이다는 전파 발사 원리상 펄스 레이다(Pulse Radar) 방식 또는 연속파 레이다(Continuous Wave Radar) 방식으로 구현 될 수 있다. 레이다는 연속파 레이다 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keyong) 방식으로 구현될 수 있다. 레이다는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이다는, 차량의 전방, 후방 또는 측방에 위 치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 2.3) 라이다 라이다는, 레이저 광을 이용하여, 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 라이다는, 광 송신 부, 광 수신부 및 광 송신부 및 광 수신부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 라이다는, TOF(Timeof Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식 으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 차량 주변의 오브젝트 를 검출할 수 있다. 비구동식으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 차량을 기준으로 소정 범위 내에 위치하는 오브젝트를 검출할 수 있다. 차량은 복수의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 차량 의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 3) 통신 장치 통신 장치는, 차량 외부에 위치하는 디바이스와 신호를 교환할 수 있다. 통신 장치는, 인프라(예 를 들면, 서버, 방송국), 타 차량, 단말기 중 적어도 어느 하나와 신호를 교환할 수 있다. 통신 장치는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 또한, 통신 장치는, V2X(vehicle-to-everything) 통신 기술을 통하여 외부 디바이스와 신호를 교환할 수 있다. V2X 통신은 PC5 인터페이스 및/또는 Uu 인터페이스를 통해 제공될 수 있다. 한편, 차세대 무선 접속 기술을 새로운 RAT(new radio access technology) 또는 NR(new radio)이라 칭할 수 있 다. NR에서도 V2X(vehicle-to-everything) 통신이 지원될 수 있다. 5G NR은 LTE-A의 후속 기술로서, 고성능, 저지연, 고가용성 등의 특성을 가지는 새로운 Clean-slate 형태의 이 동 통신 시스템이다. 5G NR은 1GHz 미만의 저주파 대역에서부터 1GHz~10GHz의 중간 주파 대역, 24GHz 이상의 고 주파(밀리미터파) 대역 등 사용 가능한 모든 스펙트럼 자원을 활용할 수 있다. 설명을 명확하게 하기 위해, LTE-A 또는 5G NR을 위주로 기술하지만 본 발명의 기술적 사상이 이에 제한되는 것 은 아니다. 예를 들어, 통신 장치는 C-V2X(Cellular V2X) 기술을 기반으로 외부 디바이스와 신호를 교환할 수 있다. 예를 들어, C-V2X 기술은 LTE 기반의 사이드링크 통신 및/또는 NR 기반의 사이드링크 통신을 포함할 수 있다. 예를 들어, 통신 장치는 IEEE 802.11p PHY/MAC 계층 기술과 IEEE 1609 Network/Transport 계층 기술 기반의 DSRC(Dedicated Short Range Communications) 기술 또는 WAVE(Wireless Access in Vehicular Environment) 표 준을 기반으로 외부 디바이스와 신호를 교환할 수 있다. DSRC (또는 WAVE 표준) 기술은 차량 탑재 장치 간 혹은 노변 장치와 차량 탑재 장치 간의 단거리 전용 통신을 통해 ITS(Intelligent Transport System) 서비스를 제공 하기 위해 마련된 통신 규격이다. DSRC 기술은 5.9GHz 대역의 주파수를 사용할 수 있고, 3Mbps~27Mbps의 데이터 전송 속도를 가지는 통신 방식일 수 있다. IEEE 802.11p 기술은 IEEE 1609 기술과 결합되어 DSRC 기술 (혹은 WAVE 표준)을 지원할 수 있다. 본 발명의 통신 장치는 C-V2X 기술 또는 DSRC 기술 중 어느 하나만을 이용하여 외부 디바이스와 신호를 교환할 수 있다. 또는, 본 발명의 통신 장치는 C-V2X 기술 및 DSRC 기술을 하이브리드하여 외부 디바이스와 신호를 교 환할 수 있다. 4) 운전 조작 장치 운전 조작 장치는, 운전을 위한 사용자 입력을 수신하는 장치이다. 메뉴얼 모드인 경우, 차량은, 운전 조작 장치에 의해 제공되는 신호에 기초하여 운행될 수 있다. 운전 조작 장치는, 조향 입력 장치(예 를 들면, 스티어링 휠), 가속 입력 장치(예를 들면, 가속 페달) 및 브레이크 입력 장치(예를 들면, 브레이크 페 달)를 포함할 수 있다. 5) 메인 ECU 메인 ECU는, 차량 내에 구비되는 적어도 하나의 전자 장치의 전반적인 동작을 제어할 수 있다. 6) 구동 제어 장치 구동 제어 장치는, 차량내 각종 차량 구동 장치를 전기적으로 제어하는 장치이다. 구동 제어 장치 는, 파워 트레인 구동 제어 장치, 샤시 구동 제어 장치, 도어/윈도우 구동 제어 장치, 안전 장치 구동 제 어 장치, 램프 구동 제어 장치 및 공조 구동 제어 장치를 포함할 수 있다. 파워 트레인 구동 제어 장치는, 동력원 구동 제어 장치 및 변속기 구동 제어 장치를 포함할 수 있다. 샤시 구동 제어 장치는, 조향 구동 제어 장치, 브레이크 구동 제어 장치 및 서스펜션 구동 제어 장치를 포함할 수 있다. 한편, 안전 장치 구동 제어 장치는, 안전 벨트 제어를 위한 안전 벨트 구동 제어 장치를 포함할 수 있다. 구동 제어 장치는, 적어도 하나의 전자적 제어 장치(예를 들면, 제어 ECU(Electronic Control Unit))를 포함한다. 구종 제어 장치는, 자율 주행 장치에서 수신되는 신호에 기초하여, 차량 구동 장치를 제어할 수 있다. 예를 들면, 제어 장치는, 자율 주행 장치에서 수신되는 신호에 기초하여, 파워 트레인, 조향 장치 및 브레이크 장치를 제어할 수 있다. 7) 자율 주행 장치 자율 주행 장치는, 획득된 데이터에 기초하여, 자율 주행을 위한 패스를 생성할 수 있다. 자율 주행 장치 는, 생성된 경로를 따라 주행하기 위한 드라이빙 플랜을 생성 할 수 있다. 자율 주행 장치는, 드라이 빙 플랜에 따른 차량의 움직임을 제어하기 위한 신호를 생성할 수 있다. 자율 주행 장치는, 생성된 신호를 구동 제어 장치에 제공할 수 있다. 자율 주행 장치는, 적어도 하나의 ADAS(Advanced Driver Assistance System) 기능을 구현할 수 있다. ADAS는, 적응형 크루즈 컨트롤 시스템(ACC : Adaptive Cruise Control), 자동 비상 제동 시스템(AEB : Autonomous Emergency Braking), 전방 충돌 알림 시스템(FCW : Foward Collision Warning), 차선 유지 보조 시 스템(LKA : Lane Keeping Assist), 차선 변경 보조 시스템(LCA : Lane Change Assist), 타겟 추종 보조 시스템 (TFA : Target Following Assist), 사각 지대 감시 시스템(BSD : Blind Spot Detection), 적응형 하이빔 제어 시스템(HBA : High Beam Assist), 자동 주차 시스템(APS : Auto Parking System), 보행자 충돌 알림 시스템(PD collision warning system), 교통 신호 검출 시스템(TSR : Traffic Sign Recognition), 교통 신호 보조 시스템 (TSA : Trafffic Sign Assist), 나이트 비전 시스템(NV : Night Vision), 운전자 상태 모니터링 시스템(DSM : Driver Status Monitoring) 및 교통 정체 지원 시스템(TJA : Traffic Jam Assist) 중 적어도 어느 하나를 구현 할 수 있다. 자율 주행 장치는, 자율 주행 모드에서 수동 주행 모드로의 전환 동작 또는 수동 주행 모드에서 자율 주행 모드로의 전환 동작을 수행할 수 있다. 예를 들면, 자율 주행 장치는, 사용자 인터페이스 장치로부터 수신되는 신호에 기초하여, 차량의 모드를 자율 주행 모드에서 수동 주행 모드로 전환하거나 수동 주행 모 드에서 자율 주행 모드로 전환할 수 있다. 8) 센싱부 센싱부는, 차량의 상태를 센싱할 수 있다. 센싱부는, IMU(inertial measurement unit) 센서, 충돌 센서, 휠 센서(wheel sensor), 속도 센서, 경사 센서, 중량 감지 센서, 헤딩 센서(heading sensor), 포지션 모 듈(position module), 차량 전진/후진 센서, 배터리 센서, 연료 센서, 타이어 센서, 스티어링 센서, 온도 센서, 습도 센서, 초음파 센서, 조도 센서, 페달 포지션 센서 중 적어도 어느 하나를 포함할 수 있다. 한편, IMU(inertial measurement unit) 센서는, 가속도 센서, 자이로 센서, 자기 센서 중 하나 이상을 포함할 수 있 다. 센싱부는, 적어도 하나의 센서에서 생성되는 신호에 기초하여, 차량의 상태 데이터를 생성할 수 있다. 차 량 상태 데이터는, 차량 내부에 구비된 각종 센서에서 감지된 데이터를 기초로 생성된 정보일 수 있다. 센싱부 는, 차량 자세 데이터, 차량 모션 데이터, 차량 요(yaw) 데이터, 차량 롤(roll) 데이터, 차량 피치(pitch) 데이터, 차량 충돌 데이터, 차량 방향 데이터, 차량 각도 데이터, 차량 속도 데이터, 차량 가속도 데이터, 차량 기울기 데이터, 차량 전진/후진 데이터, 차량의 중량 데이터, 배터리 데이터, 연료 데이터, 타이어 공기압 데이 터, 차량 내부 온도 데이터, 차량 내부 습도 데이터, 스티어링 휠 회전 각도 데이터, 차량 외부 조도 데이터, 가속 페달에 가해지는 압력 데이터, 브레이크 페달에 가해지는 압력 데이터 등을 생성할 수 있다. 9) 위치 데이터 생성 장치 위치 데이터 생성 장치는, 차량의 위치 데이터를 생성할 수 있다. 위치 데이터 생성 장치는, GPS(Global Positioning System) 및 DGPS(Differential Global Positioning System) 중 적어도 어느 하나를 포 함할 수 있다. 위치 데이터 생성 장치는, GPS 및 DGPS 중 적어도 어느 하나에서 생성되는 신호에 기초하여 차량의 위치 데이터를 생성할 수 있다. 실시예에 따라, 위치 데이터 생성 장치는, 센싱부의IMU(Inertial Measurement Unit) 및 오브젝트 검출 장치의 카메라 중 적어도 어느 하나에 기초하여 위치 데이터를 보정할 수 있다. 위치 데이터 생성 장치는, GNSS(Global Navigation Satellite System)로 명명 될 수 있다. 차량은, 내부 통신 시스템을 포함할 수 있다. 차량에 포함되는 복수의 전자 장치는 내부 통신 시스 템을 매개로 신호를 교환할 수 있다. 신호에는 데이터가 포함될 수 있다. 내부 통신 시스템은, 적어도 하나의 통신 프로토콜(예를 들면, CAN, LIN, FlexRay, MOST, 이더넷)을 이용할 수 있다. 자율 주행 장치의 구성 요소 도 3은 본 발명의 실시예에 따른 자율 주행 장치의 제어 블럭도이다. 도 3을 참조하면, 자율 주행 장치는, 메모리, 프로세서, 인터페이스부 및 전원 공급부 를 포함할 수 있다. 메모리는, 프로세서와 전기적으로 연결된다. 메모리는 유닛에 대한 기본데이터, 유닛의 동작제 어를 위한 제어데이터, 입출력되는 데이터를 저장할 수 있다. 메모리는, 프로세서에서 처리된 데이터 를 저장할 수 있다. 메모리는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 중 적 어도 어느 하나로 구성될 수 있다. 메모리는 프로세서의 처리 또는 제어를 위한 프로그램 등, 자율 주행 장치 전반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 프로세서와 일체형 으로 구현될 수 있다. 실시예에 따라, 메모리는, 프로세서의 하위 구성으로 분류될 수 있다. 인터페이스부는, 차량 내에 구비되는 적어도 하나의 전자 장치와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 구동 제어 장치, 센싱부 및 위치 데이터 생성 장치 중 적어도 어느 하나와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 통신 모듈, 단자, 핀, 케이블, 포트, 회로, 소자 및 장 치 중 적어도 어느 하나로 구성될 수 있다. 전원 공급부는, 자율 주행 장치에 전원을 공급할 수 있다. 전원 공급부는, 차량에 포함된 파워 소스(예를 들면, 배터리)로부터 전원을 공급받아, 자율 주행 장치의 각 유닛에 전원을 공급할 수 있 다. 전원 공급부는, 메인 ECU로부터 제공되는 제어 신호에 따라 동작될 수 있다. 전원 공급부는, SMPS(switched-mode power supply)를 포함할 수 있다. 프로세서는, 메모리, 인터페이스부, 전원 공급부와 전기적으로 연결되어 신호를 교환할 수 있다. 프로세서는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro- controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이 용하여 구현될 수 있다. 프로세서는, 전원 공급부로부터 제공되는 전원에 의해 구동될 수 있다. 프로세서는, 전원 공급 부에 의해 전원이 공급되는 상태에서 데이터를 수신하고, 데이터를 처리하고, 신호를 생성하고, 신호를 제 공할 수 있다. 프로세서는, 인터페이스부를 통해, 차량 내 다른 전자 장치로부터 정보를 수신할 수 있다. 프로 세서는, 인터페이스부를 통해, 차량 내 다른 전자 장치로 제어 신호를 제공할 수 있다. 자율 주행 장치는, 적어도 하나의 인쇄 회로 기판(printed circuit board, PCB)을 포함할 수 있다. 메모 리, 인터페이스부, 전원 공급부 및 프로세서는, 인쇄 회로 기판에 전기적으로 연결될 수 있다. 자율 주행 장치의 동작 도 4는 본 발명의 실시예에 따른 자율 주행 차량의 신호 흐름도이다. 1) 수신 동작 도 4를 참조하면, 프로세서는, 수신 동작을 수행할 수 있다. 프로세서는, 인터페이스부를 통해, 오브젝트 검출 장치, 통신 장치, 센싱부 및 위치 데이터 생성 장치 중 적어도 어느 하나로부터, 데이터를 수신할 수 있다. 프로세서는, 오브젝트 검출 장치로부터, 오브젝트 데이터를 수신할 수 있다. 프로세서는, 통신 장치로부터, HD 맵 데이터를 수신할 수 있다. 프로세서는, 센싱부 로부터, 차량 상태 데이터를 수신할 수 있다. 프로세서는, 위치 데이터 생성 장치로부터 위치 데이터를 수신할 수 있다. 2) 처리/판단 동작 프로세서는, 처리/판단 동작을 수행할 수 있다. 프로세서는, 주행 상황 정보에 기초하여, 처리/판단 동작을 수행할 수 있다. 프로세서는, 오브젝트 데이터, HD 맵 데이터, 차량 상태 데이터 및 위치 데이터 중 적어도 어느 하나에 기초하여, 처리/판단 동작을 수행할 수 있다. 2.1) 드라이빙 플랜 데이터 생성 동작 프로세서는, 드라이빙 플랜 데이터(driving plan data)를 생성할 수 있다. 예를 들면, 프로세서는, 일렉트로닉 호라이즌 데이터(Electronic Horizon Data)를 생성할 수 있다. 일렉트로닉 호라이즌 데이터는, 차량 이 위치한 지점에서부터 호라이즌(horizon)까지 범위 내에서의 드라이빙 플랜 데이터로 이해될 수 있다. 호 라이즌은, 기 설정된 주행 경로를 기준으로, 차량이 위치한 지점에서 기설정된 거리 앞의 지점으로 이해될 수 있다. 호라이즌은, 기 설정된 주행 경로를 따라 차량이 위치한 지점에서부터 차량이 소정 시간 이후 에 도달할 수 있는 지점을 의미할 수 있다. 일렉트로닉 호라이즌 데이터는, 호라이즌 맵 데이터 및 호라이즌 패스 데이터를 포함할 수 있다. 2.1.1) 호라이즌 맵 데이터 호라이즌 맵 데이터는, 토폴로지 데이터(topology data), 도로 데이터, HD 맵 데이터 및 다이나믹 데이터 (dynamic data) 중 적어도 어느 하나를 포함할 수 있다. 실시예에 따라, 호라이즌 맵 데이터는, 복수의 레이어 를 포함할 수 있다. 예를 들면, 호라이즌 맵 데이터는, 토폴로지 데이터에 매칭되는 1 레이어, 도로 데이터에 매칭되는 제2 레이어, HD 맵 데이터에 매칭되는 제3 레이어 및 다이나믹 데이터에 매칭되는 제4 레이어를 포함 할 수 있다. 호라이즌 맵 데이터는, 스태이틱 오브젝트(static object) 데이터를 더 포함할 수 있다. 토폴로지 데이터는, 도로 중심을 연결해 만든 지도로 설명될 수 있다. 토폴로지 데이터는, 차량의 위치를 대략 적으로 표시하기에 알맞으며, 주로 운전자를 위한 내비게이션에서 사용하는 데이터의 형태일 수 있다. 토폴로지 데이터는, 차로에 대한 정보가 제외된 도로 정보에 대한 데이터로 이해될 수 있다. 토폴로지 데이터는, 통신 장 치를 통해, 외부 서버에서 수신된 데이터에 기초하여 생성될 수 있다. 토폴로지 데이터는, 차량에 구 비된 적어도 하나의 메모리에 저장된 데이터에 기초할 수 있다. 도로 데이터는, 도로의 경사 데이터, 도로의 곡률 데이터, 도로의 제한 속도 데이터 중 적어도 어느 하나를 포 함할 수 있다. 도로 데이터는, 추월 금지 구간 데이터를 더 포함할 수 있다. 도로 데이터는, 통신 장치를 통해, 외부 서버에서 수신된 데이터에 기초할 수 있다. 도로 데이터는, 오브젝트 검출 장치에서 생성된 데 이터에 기초할 수 있다. HD 맵 데이터는, 도로의 상세한 차선 단위의 토폴로지 정보, 각 차선의 연결 정보, 차량의 로컬라이제이션 (localization)을 위한 특징 정보(예를 들면, 교통 표지판, Lane Marking/속성, Road furniture 등)를 포함할 수 있다. HD 맵 데이터는, 통신 장치를 통해, 외부 서버에서 수신된 데이터에 기초할 수 있다. 다이나믹 데이터는, 도로상에서 발생될 수 있는 다양한 동적 정보를 포함할 수 있다. 예를 들면, 다이나믹 데이 터는, 공사 정보, 가변 속도 차로 정보, 노면 상태 정보, 트래픽 정보, 무빙 오브젝트 정보 등을 포함할 수 있 다. 다이나믹 데이터는, 통신 장치를 통해, 외부 서버에서 수신된 데이터에 기초할 수 있다. 다이나믹 데 이터는, 오브젝트 검출 장치에서 생성된 데이터에 기초할 수 있다. 프로세서는, 차량이 위치한 지점에서부터 호라이즌까지 범위 내에서의 맵 데이터를 제공할 수 있다. 2.1.2) 호라이즌 패스 데이터 호라이즌 패스 데이터는, 차량이 위치한 지점에서부터 호라이즌까지의 범위 내에서 차량이 취할 수 있 는 궤도로 설명될 수 있다. 호라이즌 패스 데이터는, 디시전 포인트(decision point)(예를 들면, 갈림길, 분기 점, 교차로 등)에서 어느 하나의 도로를 선택할 상대 확률을 나타내는 데이터를 포함할 수 있다. 상대 확률은, 최종 목적지까지 도착하는데 걸리는 시간에 기초하여 계산될 수 있다. 예를 들면, 디시전 포인트에서, 제1 도로 를 선택하는 경우 제2 도로를 선택하는 경우보다 최종 목적지에 도착하는데 걸리는 시간이 더 작은 경우, 제1도로를 선택할 확률은 제2 도로를 선택할 확률보다 더 높게 계산될 수 있다. 호라이즌 패스 데이터는, 메인 패스와 서브 패스를 포함할 수 있다. 메인 패스는, 선택될 상대적 확률이 높은 도로들을 연결한 궤도로 이해될 수 있다. 서브 패스는, 메인 패스 상의 적어도 하나의 디시전 포인트에서 분기 될 수 있다. 서브 패스는, 메인 패스 상의 적어도 하나의 디시전 포인트에서 선택될 상대적 확률이 낮은 적어도 어느 하나의 도로를 연결한 궤도로 이해될 수 있다. 3) 제어 신호 생성 동작 프로세서는, 제어 신호 생성 동작을 수행할 수 있다. 프로세서는, 일렉트로닉 호라이즌 데이터에 기 초하여, 제어 신호를 생성할 수 있다. 예를 들면, 프로세서는, 일렉트로닉 호라이즌 데이터에 기초하여, 파워트레인 제어 신호, 브라이크 장치 제어 신호 및 스티어링 장치 제어 신호 중 적어도 어느 하나를 생성할 수 있다. 프로세서는, 인터페이스부를 통해, 생성된 제어 신호를 구동 제어 장치에 전송할 수 있다. 구동 제어 장치는, 파워 트레인, 브레이크 장치 및 스티어링 장치 중 적어도 어느 하나에 제어 신호를 전송할 수 있다. 캐빈 도 5는 본 발명의 실시예에 따른 차량의 내부를 도시한 도면이다. 도 6은 본 발명의 실시예에 따른 차량용 캐빈 시스템을 설명하는데 참조되는 블럭도이다. 캐빈의 구성 요소 도 5 내지 도 6을 참조하면, 차량용 캐빈 시스템(이하, 캐빈 시스템)은 차량을 이용하는 사용자를 위 한 편의 시스템으로 정의될 수 있다. 캐빈 시스템은, 디스플레이 시스템, 카고 시스템, 시트 시 스템 및 페이 먼트 시스템을 포함하는 최상위 시스템으로 설명될 수 있다. 캐빈 시스템은, 메인 컨트롤러, 메모리, 인터페이스부, 전원 공급부, 입력 장치, 영상 장치, 통신 장치, 디스플레이 시스템, 카고 시스템, 시트 시스템 및 페이먼트 시스템을 포함할 수 있다. 실시예에 따라, 캐빈 시스템은, 본 명세서에서 설명되는 구성 요소외에 다른 구성 요소를 더 포 함하거나, 설명되는 구성 요소 중 일부를 포함하지 않을 수 있다. 1) 메인 컨트롤러 메인 컨트롤러는, 입력 장치, 통신 장치, 디스플레이 시스템, 카고 시스템, 시트 시 스템 및 페이먼트 시스템과 전기적으로 연결되어 신호를 교환할 수 있다. 메인 컨트롤러는, 입 력 장치, 통신 장치, 디스플레이 시스템, 카고 시스템, 시트 시스템 및 페이먼트 시 스템을 제어할 수 있다. 메인 컨트롤러는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨 트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적 어도 하나를 이용하여 구현될 수 있다. 메인 컨트롤러는, 적어도 하나의 서브 컨트롤러로 구성될 수 있다. 실시예에 따라, 메인 컨트롤러는, 복수의 서브 컨트롤러를 포함할 수 있다. 복수의 서브 컨트롤러는 각각이, 그루핑된 캐빈 시스템에 포함된 장치 및 시스템을 개별적으로 제어할 수 있다. 캐빈 시스템에 포함된 장치 및 시스템은, 기능별로 그루핑 되거나, 착좌 가능한 시트를 기준으로 그루핑될 수 있다. 메인 컨트롤러는, 적어도 하나의 프로세서를 포함할 수 있다. 도 6에는 메인 컨트롤러가 하나의 프로세서를 포함하는 것으로 예시되나, 메인 컨트롤러는, 복수의 프로세서를 포함할 수도 있다. 프로 세서는, 상술한 서브 컨트롤러 중 어느 하나로 분류될 수도 있다. 프로세서는, 통신 장치를 통해, 사용자 단말기로부터 신호, 정보 또는 데이터를 수신할 수 있다. 사 용자 단말기는, 캐빈 시스템에 신호, 정보 또는 데이터를 전송할 수 있다. 프로세서는, 영상 장치에 포함된 내부 카메라 및 외부 카메라 중 적어도 어느 하나에서 수신되는 영상 데 이터에 기초하여, 사용자를 특정할 수 있다. 프로세서는, 영상 데이터에 영상 처리 알고리즘을 적용하여 사용자를 특정할 수 있다. 예를 들면, 프로세서는, 사용자 단말기로부터 수신되는 정보와 영상 데이터를비교하여 사용자를 특정할 수 있다. 예를 들면, 정보는, 사용자의 경로 정보, 신체 정보, 동승자 정보, 짐 정보, 위치 정보, 선호하는 컨텐츠 정보, 선호하는 음식 정보, 장애 여부 정보 및 이용 이력 정보 중 적어도 어 느 하나를 포함할 수 있다. 메인 컨트롤러는, 인공지능 에이전트(artificial intelligence agent)를 포함할 수 있다. 인공지능 에이전트는, 입력 장치를 통해 획득된 데이터를 기초로 기계 학습(machine learning)을 수행할 수 있 다. 인공지능 에이전트는, 기계 학습된 결과에 기초하여, 디스플레이 시스템, 카고 시스템, 시 트 시스템 및 페이먼트 시스템 중 적어도 어느 하나를 제어할 수 있다. 2) 필수 구성 요소 메모리는, 메인 컨트롤러와 전기적으로 연결된다. 메모리는 유닛에 대한 기본데이터, 유닛의 동 작제어를 위한 제어데이터, 입출력되는 데이터를 저장할 수 있다. 메모리는, 메인 컨트롤러에서 처리 된 데이터를 저장할 수 있다. 메모리는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이 브 중 적어도 어느 하나로 구성될 수 있다. 메모리는 메인 컨트롤러의 처리 또는 제어를 위한 프로그 램 등, 캐빈 시스템 전반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 메인 컨트롤러 와 일체형으로 구현될 수 있다. 인터페이스부는, 차량 내에 구비되는 적어도 하나의 전자 장치와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 통신 모듈, 단자, 핀, 케이블, 포트, 회로, 소자 및 장치 중 적어도 어느 하나 로 구성될 수 있다. 전원 공급부는, 캐빈 시스템에 전원을 공급할 수 있다. 전원 공급부는, 차량에 포함된 파워 소스(예를 들면, 배터리)로부터 전원을 공급받아, 캐빈 시스템의 각 유닛에 전원을 공급할 수 있다. 전원 공급부는, 메인 컨트롤러로부터 제공되는 제어 신호에 따라 동작될 수 있다. 예를 들면, 전원 공급부 는, SMPS(switched-mode power supply)로 구현될 수 있다. 캐빈 시스템은, 적어도 하나의 인쇄 회로 기판(printed circuit board, PCB)을 포함할 수 있다. 메인 컨 트롤러, 메모리, 인터페이스부 및 전원 공급부는, 적어도 하나의 인쇄 회로 기판에 실장될 수 있다. 3) 입력 장치 입력 장치는, 사용자 입력을 수신할 수 있다. 입력 장치는, 사용자 입력을 전기적 신호로 전환할 수 있다. 입력 장치에 의해 전환된 전기적 신호는 제어 신호로 전환되어 디스플레이 시스템, 카고 시스 템, 시트 시스템 및 페이먼트 시스템 중 적어도 어느 하나에 제공될 수 있다. 메인 컨트롤러 또는 캐빈 시스템에 포함되는 적어도 하나의 프로세서는 입력 장치로부터 수신되는 전기적 신 호에 기초한 제어 신호를 생성할 수 있다. 입력 장치는, 터치 입력부, 제스쳐 입력부, 기계식 입력부 및 음성 입력부 중 적어도 어느 하나를 포함할 수 있다. 터치 입력부는, 사용자의 터치 입력을 전기적 신호로 전환할 수 있다. 터치 입력부는, 사용자의 터치 입력을 감지하기 위해 적어도 하나의 터치 센서를 포함할 수 있다. 실시예에 따라, 터치 입력부는 디스플레이 시스템에 포함되는 적어도 하나의 디스플레이 와 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한, 터치 스크린은, 캐빈 시스템과 사용자 사이의 입력 인터페이스 및 출력 인터페이스를 함께 제공할 수 있다. 제스쳐 입력부는, 사용자의 제스쳐 입력을 전기적 신호로 전환할 수 있다. 제스쳐 입력부는, 사용자의 제스쳐 입력을 감지하기 위한 적외선 센서 및 이미지 센서 중 적어도 어느 하나를 포함할 수 있다. 실 시예에 따라, 제스쳐 입력부는, 사용자의 3차원 제스쳐 입력을 감지할 수 있다. 이를 위해, 제스쳐 입력부는, 복수의 적외선 광을 출력하는 광출력부 또는 복수의 이미지 센서를 포함할 수 있다. 제스쳐 입력부는, TOF(Time of Flight) 방식, 구조광(Structured light) 방식 또는 디스패러티(Disparity) 방식을 통해 사용자의 3차원 제 스쳐 입력을 감지할 수 있다. 기계식 입력부는, 기계식 장치를 통한 사용자의 물리적인 입력(예를 들면, 누름 또는 회전)을 전기적 신호로 전환할 수 있다. 기계식 입력부는, 버튼, 돔 스위치(dome switch), 조그 휠 및 조 그 스위치 중 적어도 어느 하나를 포함할 수 있다. 한편, 제스쳐 입력부와 기계식 입력부는 일체형으로 형성될 수 있다. 예를 들면, 입력 장치는, 제스쳐 센서가 포함되고, 주변 구조물(예를 들면, 시트, 암레스트 및 도어 중 적어도 어느 하나)의 일부분에서 출납 가능하게 형성된 조그 다이얼 장치를 포함할 수 있다. 조그 다이 얼 장치가 주변 구조물과 평평한 상태를 이룬 경우, 조그 다이얼 장치는 제스쳐 입력부로 기능할 수 있다. 조그 다이얼 장치가 주변 구조물에 비해 돌출된 상태의 경우, 조그 다이얼 장치는 기계식 입력부로 기능할 수 있다.음성 입력부는, 사용자의 음성 입력을 전기적 신호로 전환할 수 있다. 음성 입력부는, 적어도 하나의 마이크로 폰을 포함할 수 있다. 음성 입력부는, 빔 포밍 마이크(Beam foaming MIC)를 포함할 수 있다. 4) 영상 장치 영상 장치는, 적어도 하나의 카메라를 포함할 수 있다. 영상 장치는, 내부 카메라 및 외부 카메라 중 적어도 어느 하나를 포함할 수 있다. 내부 카메라는, 캐빈 내의 영상을 촬영할 수 있다. 외부 카메라는, 차량 외부 영상을 촬영할 수 있다. 내부 카메라는, 캐빈 내의 영상을 획득할 수 있다. 영상 장치는, 적어도 하 나의 내부 카메라를 포함할 수 있다. 영상 장치는, 탑승 가능 인원에 대응되는 갯수의 카메라를 포함하는 것이 바람직하다. 영상 장치는, 내부 카메라에 의해 획득된 영상을 제공할 수 있다. 메인 컨트롤러 또는 캐빈 시스템에 포함되는 적어도 하나의 프로세서는, 내부 카메라에 의해 획득된 영상에 기초하여 사 용자의 모션을 검출하고, 검출된 모션에 기초하여 신호를 생성하여, 디스플레이 시스템, 카고 시스템 , 시트 시스템 및 페이먼트 시스템 중 적어도 어느 하나에 제공할 수 있다. 외부 카메라는, 차 량 외부 영상을 획득할 수 있다. 영상 장치는, 적어도 하나의 외부 카메라를 포함할 수 있다. 영상 장치 는, 탑승 도어에 대응되는 갯수의 카메라를 포함하는 것이 바람직하다. 영상 장치는, 외부 카메라에 의해 획득된 영상을 제공할 수 있다. 메인 컨트롤러 또는 캐빈 시스템에 포함되는 적어도 하나의 프 로세서는, 외부 카메라에 의해 획득된 영상에 기초하여 사용자 정보를 획득할 수 있다. 메인 컨트롤러 또 는 캐빈 시스템에 포함되는 적어도 하나의 프로세서는, 사용자 정보에 기초하여, 사용자를 인증하거나, 사 용자의 신체 정보(예를 들면, 신장 정보, 체중 정보 등), 사용자의 동승자 정보, 사용자의 짐 정보 등을 획득할 수 있다. 5) 통신 장치 통신 장치는, 외부 디바이스와 무선으로 신호를 교환할 수 있다. 통신 장치는, 네트워크 망을 통해 외부 디바이스와 신호를 교환하거나, 직접 외부 디바이스와 신호를 교환할 수 있다. 외부 디바이스는, 서버, 이 동 단말기 및 타 차량 중 적어도 어느 하나를 포함할 수 있다. 통신 장치는, 적어도 하나의 사용자 단말기 와 신호를 교환할 수 있다. 통신 장치는, 통신을 수행하기 위해 안테나, 적어도 하나의 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 실시예에 따라, 통 신 장치는, 복수의 통신 프로토콜을 이용할 수도 있다. 통신 장치는, 이동 단말기와의 거리에 따라 통신 프로토콜을 전환할 수 있다. 예를 들어, 통신 장치는 C-V2X(Cellular V2X) 기술을 기반으로 외부 디바이스와 신호를 교환할 수 있다. 예를 들어, C-V2X 기술은 LTE 기반의 사이드링크 통신 및/또는 NR 기반의 사이드링크 통신을 포함할 수 있다. 예를 들어, 통신 장치는 IEEE 802.11p PHY/MAC 계층 기술과 IEEE 1609 Network/Transport 계층 기술 기반의 DSRC(Dedicated Short Range Communications) 기술 또는 WAVE(Wireless Access in Vehicular Environment) 표 준을 기반으로 외부 디바이스와 신호를 교환할 수 있다. DSRC (또는 WAVE 표준) 기술은 차량 탑재 장치 간 혹은 노변 장치와 차량 탑재 장치 간의 단거리 전용 통신을 통해 ITS(Intelligent Transport System) 서비스를 제공 하기 위해 마련된 통신 규격이다. DSRC 기술은 5.9GHz 대역의 주파수를 사용할 수 있고, 3Mbps~27Mbps의 데이터 전송 속도를 가지는 통신 방식일 수 있다. IEEE 802.11p 기술은 IEEE 1609 기술과 결합되어 DSRC 기술 (혹은 WAVE 표준)을 지원할 수 있다. 본 발명의 통신 장치는 C-V2X 기술 또는 DSRC 기술 중 어느 하나만을 이용하여 외부 디바이스와 신호를 교환할 수 있다. 또는, 본 발명의 통신 장치는 C-V2X 기술 및 DSRC 기술을 하이브리드하여 외부 디바이스와 신호를 교 환할 수 있다. 6) 디스플레이 시스템 디스플레이 시스템은, 그래픽 객체를 표시할 수 있다. 디스플레이 시스템은, 적어도 하나의 디스플레 이 장치를 포함할 수 있다. 예를 들면, 디스플레이 시스템은, 공용으로 이용 가능한 제1 디스플레이 장치 와 개별 이용 가능한 제2 디스플레이 장치를 포함할 수 있다. 6.1) 공용 디스플레이 장치 제1 디스플레이 장치는, 시각적 컨텐츠를 출력하는 적어도 하나의 디스플레이를 포함할 수 있다. 제1 디스플레이 장치에 포함되는 디스플레이는, 평면 디스플레이. 곡면 디스플레이, 롤러블 디스플레이 및 플렉서블 디스플레이 중 적어도 어느 하나로 구현될 수 있다. 예를 들면, 제1 디스플레이 장치는, 시트후방에 위치하고, 캐빈 내로 출납 가능하게 형성된 제1 디스플레이 및 상기 제1 디스플레이를 이동시 키기 위한 제1 메카니즘를 포함할 수 있다. 제1 디스플레이는, 시트 메인 프레임에 형성된 슬롯에 출납 가 능하게 배치될 수 있다. 실시예에 따라, 제1 디스플레이 장치는, 플렉서블 영역 조절 메카니즘을 더 포함 할 수 있다. 제1 디스플레이는, 플렉서블하게 형성될 수 있고, 사용자의 위치에 따라, 제1 디스플레이의 플렉서 블 영역이 조절될 수 있다. 예를 들면, 제1 디스플레이 장치는, 캐빈내 천장에 위치하고, 롤러블 (rollable)하게 형성된 제2 디스플레이 및 상기 제2 디스플레이를 감거나 풀기 위한 제2 메카니즘을 포함할 수 있다. 제2 디스플레이는, 양면에 화면 출력이 가능하게 형성될 수 있다. 예를 들면, 제1 디스플레이 장치 는, 캐빈내 천장에 위치하고, 플렉서블(flexible)하게 형성된 제3 디스플레이 및 상기 제3 디스플레이를 휘거나 펴기위한 제3 메카니즘을 포함할 수 있다. 실시예에 따라, 디스플레이 시스템은, 제1 디스플레이 장치 및 제2 디스플레이 장치 중 적어도 어느 하나에 제어 신호를 제공하는 적어도 하나의 프로세서를 더 포함할 수 있다. 디스플레이 시스템에 포함되는 프로세서는, 메인 컨트롤러, 입력 장치, 영상 장치 및 통신 장치 중 적어도 어느 하나로부터 수신되는 신호에 기초하여 제어 신호를 생성할 수 있 다. 제1 디스플레이 장치에 포함되는 디스플레이의 표시 영역은, 제1 영역(411a) 및 제2 영역(411b)으로 구분 될 수 있다. 제1 영역(411a)은, 컨텐츠를 표시 영역으로 정의될 수 있다. 예를 들면, 제 1영역은, 엔터테 인먼트 컨텐츠(예를 들면, 영화, 스포츠, 쇼핑, 음악 등), 화상 회의, 음식 메뉴 및 증강 현실 화면에 대응하는 그래픽 객체 중 적어도 어느 하나를 표시할 수 있다. 제1 영역(411a)은, 차량의 주행 상황 정보에 대응하는 그래픽 객체를 표시할 수 있다. 주행 상황 정보는, 주행 상황 정보는, 차량 외부의 오브젝트 정보, 내비게이션 정보 및 차량 상태 정보 중 적어도 어느 하나를 포함할 수 있다. 차량 외부의 오브젝트 정보는, 오브젝트의 존 재 유무에 대한 정보, 오브젝트의 위치 정보, 차량과 오브젝트와의 거리 정보 및 차량과 오브젝트와의 상대 속도 정보를 포함할 수 있다. 내비게이션 정보는, 맵(map) 정보, 설정된 목적지 정보, 상기 목적지 설정 따른 경로 정보, 경로 상의 다양한 오브젝트에 대한 정보, 차선 정보 및 차량의 현재 위치 정보 중 적어도 어느 하나를 포함할 수 있다. 차량 상태 정보는, 차량의 자세 정보, 차량의 속도 정보, 차량의 기울기 정보, 차량의 중량 정보, 차량의 방향 정보, 차량의 배터리 정보, 차량의 연료 정보, 차량의 타이어 공기압 정보, 차량의 스 티어링 정보, 차량 실내 온도 정보, 차량 실내 습도 정보, 페달 포지션 정보 및 차량 엔진 온도 정보 등을 포함 할 수 있다. 제2 영역(411b)은, 사용자 인터페이스 영역으로 정의될 수 있다. 예를 들면, 제2 영역(411b)은, 인 공 지능 에이전트 화면을 출력할 수 있다. 실시예에 따라, 제2 영역(411b)은, 시트 프레임으로 구분되는 영역에 위치할 수 있다. 이경우, 사용자는, 복수의 시트 사이로 제2 영역(411b)에 표시되는 컨텐츠를 바라볼 수 있다. 실시예에 따라, 제1 디스플레이 장치는, 홀로그램 컨텐츠를 제공할 수 있다. 예를 들면, 제1 디스플레이 장치는, 복수의 사용자별로 홀로그램 컨텐츠를 제공하여 컨텐츠를 요청한 사용자만 해당 컨텐츠를 시청하 게 할 수 있다. 6.2) 개인용 디스플레이 장치 제2 디스플레이 장치는, 적어도 하나의 디스플레이을 포함할 수 있다. 제2 디스플레이 장치는, 개개의 탑승자만 디스플레이 내용을 확인할 수 있는 위치에 디스플레이을 제공할 수 있다. 예를 들면, 디 스플레이은, 시트의 암 레스트에 배치될 수 있다. 제2 디스플레이 장치는, 사용자의 개인 정보에 대 응되는 그래픽 객체를 표시할 수 있다. 제2 디스플레이 장치는, 탑승 가능 인원에 대응되는 갯수의 디스플 레이을 포함할 수 있다. 제2 디스플레이 장치는, 터치 센서와 상호 레이어 구조를 이루거나 일체형으 로 형성됨으로써, 터치 스크린을 구현할 수 있다. 제2 디스플레이 장치는, 시트 조정 또는 실내 온도 조정 의 사용자 입력을 수신하기 위한 그래픽 객체를 표시할 수 있다. 7) 카고 시스템 카고 시스템은, 사용자의 요청에 따라 상품을 사용자에게 제공할 수 있다. 카고 시스템은, 입력 장치 또는 통신 장치에 의해 생성되는 전기적 신호에 기초하여 동작될 수 있다. 카고 시스템은, 카 고 박스를 포함할 수 있다. 카고 박스는, 상품들이 적재된 상태로 시트 하단의 일 부분에 은닉될 수 있다. 사용 자 입력에 기초한 전기적 신호가 수신되는 경우, 카고 박스는, 캐빈으로 노출될 수 있다. 사용자는 노출된 카고 박스에 적재된 물품 중 필요한 상품을 선택할 수 있다. 카고 시스템은, 사용자 입력에 따른 카고 박스의 노출을 위해, 슬라이딩 무빙 메카니즘, 상품 팝업 메카니즘을 포함할 수 있다. 카고 시스템은은, 다양한 종류의 상품을 제공하기 위해 복수의 카고 박스를 포함할 수 있다. 카고 박스에는, 상품별로 제공 여부를 판단 하기 위한 무게 센서가 내장될 수 있다.8) 시트 시스템 시트 시스템은, 사용자에 맞춤형 시트를 사용자에게 제공할 수 있다. 시트 시스템은, 입력 장치 또는 통신 장치에 의해 생성되는 전기적 신호에 기초하여 동작될 수 있다. 시트 시스템은, 획득된 사 용자 신체 데이터에 기초하여, 시트의 적어도 하나의 요소를 조정할 수 있다. 시트 시스템은 사용자의 착 좌 여부를 판단하기 위한 사용자 감지 센서(예를 들면, 압력 센서)를 포함할 수 있다. 시트 시스템은, 복 수의 사용자가 각각 착좌할 수 있는 복수의 시트를 포함할 수 있다. 복수의 시트 중 어느 하나는 적어도 다른 하나와 마주보게 배치될 수 있다. 캐빈 내부의 적어도 두명의 사용자는 서로 마주보고 앉을 수 있다. 9) 페이먼트 시스템 페이먼트 시스템은, 결제 서비스를 사용자에게 제공할 수 있다. 페이먼트 시스템은, 입력 장치 또는 통신 장치에 의해 생성되는 전기적 신호에 기초하여 동작될 수 있다. 페이먼트 시스템은, 사용 자가 이용한 적어도 하나의 서비스에 대한 가격을 산정하고, 산정된 가격이 지불되도록 요청할 수 있다. 자율 주행 차량 이용 시나리오 도 7은 본 발명의 실시예에 따라 사용자의 이용 시나리오를 설명하는데 참조되는 도면이다. 1) 목적지 예측 시나리오 제1 시나리오(S111)는, 사용자의 목적지 예측 시나리오이다. 사용자 단말기는 캐빈 시스템과 연동 가능한 애플리케이션을 설치할 수 있다. 사용자 단말기는, 애플리케이션을 통해, 사용자의 컨텍스트추얼 정보(user's contextual information)를 기초로, 사용자의 목적지를 예측할 수 있다. 사용자 단말기는, 애플리케이션을 통해, 캐빈 내의 빈자리 정보를 제공할 수 있다. 2) 캐빈 인테리어 레이아웃 준비 시나리오 제2 시나리오(S112)는, 캐빈 인테리어 레이아웃 준비 시나리오이다. 캐빈 시스템은, 차량 외부에 위치 하는 사용자에 대한 데이터를 획득하기 위한 스캐닝 장치를 더 포함할 수 있다. 스캐닝 장치는, 사용자를 스캐 닝하여, 사용자의 신체 데이터 및 수하물 데이터를 획득할 수 있다. 사용자의 신체 데이터 및 수하물 데이터는, 레이아웃을 설정하는데 이용될 수 있다. 사용자의 신체 데이터는, 사용자 인증에 이용될 수 있다. 스캐닝 장치 는, 적어도 하나의 이미지 센서를 포함할 수 있다. 이미지 센서는, 가시광 대역 또는 적외선 대역의 광을 이용 하여 사용자 이미지를 획득할 수 있다. 시트 시스템은, 사용자의 신체 데이터 및 수하물 데이터 중 적어도 어느 하나에 기초하여, 캐빈 내 레이아 웃을 설정할 수 있다. 예를 들면, 시트 시스템은, 수하물 적재 공간 또는 카시트 설치 공간을 마련할 수 있다. 3) 사용자 환영 시나리오 제3 시나리오(S113)는, 사용자 환영 시나리오이다. 캐빈 시스템은, 적어도 하나의 가이드 라이트를 더 포 함할 수 있다. 가이드 라이트는, 캐빈 내 바닥에 배치될 수 있다. 캐빈 시스템은, 사용자의 탑승이 감지되 는 경우, 복수의 시트 중 기 설정된 시트에 사용자가 착석하도록 가이드 라이트를 출력할 수 있다. 예를 들면, 메인 컨트롤러는, 오픈된 도어에서부터 기 설정된 사용자 시트까지 시간에 따른 복수의 광원에 대한 순차 점등을 통해, 무빙 라이트를 구현할 수 있다. 4) 시트 조절 서비스 시나리오 제4 시나리오(S114)는, 시트 조절 서비스 시나리오이다. 시트 시스템은, 획득된 신체 정보에 기초하여, 사 용자와 매칭되는 시트의 적어도 하나의 요소를 조절할 수 있다. 5) 개인 컨텐츠 제공 시나리오 제5 시나리오(S115)는, 개인 컨텐츠 제공 시나리오이다. 디스플레이 시스템은, 입력 장치 또는 통신 장치를 통해, 사용자 개인 데이터를 수신할 수 있다. 디스플레이 시스템은, 사용자 개인 데이터에 대 응되는 컨텐츠를 제공할 수 있다. 6) 상품 제공 시나리오 제6 시나리오(S116)는, 상품 제공 시나리오이다. 카고 시스템은, 입력 장치 또는 통신 장치를 통해, 사용자 데이터를 수신할 수 있다. 사용자 데이터는, 사용자의 선호도 데이터 및 사용자의 목적지 데이터 등을 포함할 수 있다. 카고 시스템은, 사용자 데이터에 기초하여, 상품을 제공할 수 있다. 7) 페이먼트 시나리오 제7 시나리오(S117)는, 페이먼트 시나리오이다. 페이먼트 시스템은, 입력 장치, 통신 장치 및 카고 시스템 중 적어도 어느 하나로부터 가격 산정을 위한 데이터를 수신할 수 있다. 페이먼트 시스템 은, 수신된 데이터에 기초하여, 사용자의 차량 이용 가격을 산정할 수 있다. 페이먼트 시스템은, 산 정된 가격으로 사용자(예를 들면, 사용자의 이동 단말기)에 요금 지불을 요청할 수 있다. 8) 사용자의 디스플레이 시스템 제어 시나리오 제8 시나리오(S118)는, 사용자의 디스플레이 시스템 제어 시나리오이다. 입력 장치는, 적어도 어느 하나의 형태로 이루어진 사용자 입력을 수신하여, 전기적 신호로 전환할 수 있다. 디스플레이 시스템은, 전기적 신호에 기초하여, 표시되는 컨텐츠를 제어할 수 있다. 9) AI 에이전트 시나리오 제9 시나리오(S119)는, 복수의 사용자를 위한 멀티 채널 인공지능(artificial intelligence, AI) 에이전트 시 나리오이다. 인공 지능 에이전트는, 복수의 사용자 별로 사용자 입력을 구분할 수 있다. 인공 지능 에이전 트는, 복수의 사용자 개별 사용자 입력이 전환된 전기적 신호에 기초하여, 디스플레이 시스템, 카고 시스템, 시트 시스템 및 페이먼트 시스템 중 적어도 어느 하나를 제어할 수 있다. 10) 복수 사용자를 위한 멀티미디어 컨텐츠 제공 시나리오 제10 시나리오(S120)는, 복수의 사용자를 대상으로 하는 멀티미디어 컨텐츠 제공 시나리오이다. 디스플레이 시 스템은, 모든 사용자가 함께 시청할 수 있는 컨텐츠를 제공할 수 있다. 이경우, 디스플레이 시스템은, 시트별로 구비된 스피커를 통해, 동일한 사운드를 복수의 사용자 개별적으로 제공할 수 있다. 디스플레이 시스템은, 복수의 사용자가 개별적으로 시청할 수 있는 컨텐츠를 제공할 수 있다. 이경우, 디 스플레이 시스템는, 시트별로 구비된 스피커를 통해, 개별적 사운드를 제공할 수 있다. 11) 사용자 안전 확보 시나리오 제11 시나리오(S121)는, 사용자 안전 확보 시나리오이다. 사용자에게 위협이되는 차량 주변 오브젝트 정보를 획 득하는 경우, 메인 컨트롤러는, 디스플레이 시스템을 통해, 차량 주변 오브젝트에 대한 알람이 출력 되도록 제어할 수 있다. 12) 소지품 분실 예방 시나리오 제12 시나리오(S122)는, 사용자의 소지품 분실 예방 시나리오이다. 메인 컨트롤러는, 입력 장치를 통 해, 사용자의 소지품에 대한 데이터를 획득할 수 있다. 메인 컨트롤러는, 입력 장치를 통해, 사용자 의 움직임 데이터를 획득할 수 있다. 메인 컨트롤러는, 소지품에 대한 데이터 및 움직임 데이터에 기초하 여, 사용자가 소지품을 두고 하차 하는지 여부를 판단할 수 있다. 메인 컨트롤러는, 디스플레이 시스템 을 통해, 소지품에 관한 알람이 출력되도록 제어할 수 있다. 13) 하차 리포트 시나리오 제13 시나리오(S123)는, 하차 리포트 시나리오이다. 메인 컨트롤러는, 입력 장치를 통해, 사용자의 하차 데이터를 수신할 수 있다. 사용자 하차 이후, 메인 컨트롤러는, 통신 장치를 통해, 사용자의 이 동 단말기에 하차에 따른 리포트 데이터를 제공할 수 있다. 리포트 데이터는, 차량 전체 이용 요금 데이터 를 포함할 수 있다. V2X (Vehicle-to-Everything) 도 8은 본 명세서가 적용될 수 있는 V2X 통신의 예시이다. V2X 통신은 차량 사이의 통신(communication between vehicles)을 지칭하는 V2V(Vehicle-to-Vehicle), 차량과 eNB 또는 RSU(Road Side Unit) 사이의 통신을 지칭하는 V2I(Vehicle to Infrastructure), 차량 및 개인(보행자, 자전거 운전자, 차량 운전자 또는 승객)이 소지하고 있는 UE 간 통신을 지칭하는 V2P(Vehicle-to- Pedestrian), V2N(vehicle-to-network) 등 차량과 모든 개체들 간 통신을 포함한다.V2X 통신은 V2X 사이드링크 또는 NR V2X와 동일한 의미를 나타내거나 또는 V2X 사이드링크 또는 NR V2X를 포함 하는 보다 넓은 의미를 나타낼 수 있다. V2X 통신은 예를 들어, 전방 충돌 경고, 자동 주차 시스템, 협력 조정형 크루즈 컨트롤(Cooperative adaptive cruise control: CACC), 제어 상실 경고, 교통행렬 경고, 교통 취약자 안전 경고, 긴급 차량 경보, 굽은 도로 주행 시 속도 경고, 트래픽 흐름 제어 등 다양한 서비스에 적용 가능하다. V2X 통신은 PC5 인터페이스 및/또는 Uu 인터페이스를 통해 제공될 수 있다. 이 경우, V2X 통신을 지원하는 무 선 통신 시스템에는, 상기 차량과 모든 개체들 간의 통신을 지원하기 위한 특정 네트워크 개체(network entit y)들이 존재할 수 있다. 예를 들어, 상기 네트워크 개체는, BS(eNB), RSU(road side unit), UE, 또는 어플리케 이션 서버(application server)(예, 교통 안전 서버(traffic safety server)) 등일 수 있다. 또한, V2X 통신을 수행하는 UE는, 일반적인 휴대용 UE(handheld UE)뿐만 아니라, 차량 UE(V-UE(Vehicle UE)), 보행자 UE(pedestrian UE), BS 타입(eNB type)의 RSU, 또는 UE 타입(UE type)의 RSU, 통신 모듈을 구비한 로봇 등을 의미할 수 있다. V2X 통신은 UE들 간에 직접 수행되거나, 상기 네트워크 개체(들)를 통해 수행될 수 있다. 이러한 V2X 통신의 수 행 방식에 따라 V2X 동작 모드가 구분될 수 있다. V2X 통신은, 사업자(operator) 또는 제3자가 V2X가 지원되는 지역 내에서 UE 식별자를 트랙킹할 수 없도록, V2X 어플리케이션의 사용 시에 UE의 익명성(pseudonymity) 및 개인보호(privacy)를 지원할 것이 요구된다. V2X 통신에서 자주 사용되는 용어는 다음과 같이 정의된다. - RSU (Road Side Unit): RSU는 V2I 서비스를 사용하여 이동 차량과 전송/수신할 수 있는 V2X 서비스 가능 장 치이다. 또한, RSU는 V2X 어플리케이션을 지원하는 고정 인프라 엔터티로서, V2X 어플리케이션을 지원하는 다른 엔터티와 메시지를 교환할 수 있다. RSU는 기존 ITS 스펙에서 자주 사용되는 용어이며, 3GPP 스펙에 이 용어를 도입한 이유는 ITS 산업에서 문서를 더 쉽게 읽을 수 있도록 하기 위해서이다. RSU는 V2X 어플리케이션 로직을 BS(BS-타입 RSU라고 함) 또는 UE(UE-타입 RSU라고 함)의 기능과 결합하는 논리적 엔티티이다. - V2I 서비스: V2X 서비스의 일 타입으로, 한 쪽은 차량(vehicle)이고 다른 쪽은 기반시설(infrastructure)에 속하는 엔티티. - V2P 서비스: V2X 서비스의 일 타입으로, 한 쪽은 차량이고, 다른 쪽은 개인이 휴대하는 기기(예, 보행자, 자 전거 타는 사람, 운전자 또는 동승자가 휴대하는 휴대용 UE기). - V2X 서비스: 차량에 전송 또는 수신 장치가 관계된 3GPP 통신 서비스 타입. - V2X 가능(enabled) UE: V2X 서비스를 지원하는 UE. - V2V 서비스: V2X 서비스의 타입으로, 통신의 양쪽 모두 차량이다. - V2V 통신 범위: V2V 서비스에 참여하는 두 차량 간의 직접 통신 범위. V2X(Vehicle-to-Everything)라고 불리는 V2X 어플리케이션은 살핀 것처럼, 차량 대 차량 (V2V), 차량 대 인프라 (V2I), 차량 대 네트워크 (V2N), 차량 대 보행자 (V2P)의 4가지 타입이 있다. 도 9는 V2X가 사용되는 사이드링크에서의 자원 할당 방법을 예시한다. 사이드링크에서는 서로 다른 사이드링크 제어 채널(physical sidelink control channel, PSCCH)들이 주파수 도 메인에서 이격되어 할당되고 서로 다른 사이드링크 공유 채널(physical sidelink shared channel, PSSCH)들이 이격되어 할당될 수 있다. 또는, 서로 다른 PSCCH들이 주파수 도메인에서 연속하여 할당되고, PSSCH들도 주파수 도메인에서 연속하여 할당될 수도 있다. NR V2X 3GPP 릴리즈 14 및 15 동안 자동차 산업으로 3GPP 플랫폼을 확장하기 위해, LTE에서 V2V 및 V2X 서비스에 대한 지원이 소개되었다. 개선된(enhanced) V2X 사용 예(use case)에 대한 지원을 위한 요구사항(requirement)들은 크게 4개의 사용 예 그룹들로 정리된다. 차량 플래투닝 (vehicle Platooning)은 차량들이 함께 움직이는 플래툰(platoon)을 동적으로 형성할 수 있 게 한다. 플래툰의 모든 차량은 이 플래툰을 관리하기 위해 선두 차량으로부터 정보를 얻는다. 이러한 정보는 차량이 정상 방향보다 조화롭게 운전되고, 같은 방향으로 가고 함께 운행할 수 있게 한다. 확장된 센서(extended sensor)들은 차량, 도로 사이트 유닛(road site unit), 보행자 장치(pedestrian device) 및 V2X 어플리케이션 서버에서 로컬 센서 또는 동영상 이미지(live video image)를 통해 수집된 원시 (raw) 또는 처리된 데이터를 교환할 수 있게 한다. 차량은 자신의 센서가 감지할 수 있는 것 이상으로 환경에 대한 인식을 높일 수 있으며, 지역 상황을 보다 광범위하고 총체적으로 파악할 수 있다. 높은 데이터 전송 레이 트가 주요 특징 중 하나이다. 진화된 운전(advanced driving)은 반-자동 또는 완전-자동 운전을 가능하게 한다. 각 차량 및/또는 RSU는 로컬 센서에서 얻은 자체 인식 데이터를 근접 차량과 공유하고, 차량이 궤도(trajectory) 또는 기동(manoeuvr e)을 동기화 및 조정할 수 있게 한다. 각 차량은 근접 운전 차량과 운전 의도를 공유한다. 원격 운전(remote driving)은 원격 운전자 또는 V2X 어플리케이션이 스스로 또는 위험한 환경에 있는 원격 차량으로 주행 할 수 없는 승객을 위해 원격 차량을 운전할 수 있게 한다. 변동이 제한적이고, 대중 교통과 같 이 경로를 예측할 수 있는 경우, 클라우드 컴퓨팅을 기반으로 한 운전을 사용할 수 있다. 높은 신뢰성과 낮은 대기 시간이 주요 요구 사항이다. PC5를 통해 V2X 통신을 하기위한 식별자 각 단말은 하나 이상의 PC5를 통해 V2통신을 하기 위한 Layer-2 식별자를 갖는다. 이는 소스(source) Layer-2 ID 와 목적지(Destination) Layer-2 ID를 포함한다. 소스 및 목적지 Layer-2 ID는 Layer-2 프레임에 포함되며, Layer-2 프레임은 프레임상의 Layer-2의 소스 및 목 적지를 식별하는 PC5의 layer-2 링크를 통해 전송된다. 단말의 소스 및 목적지 Layer-2 ID 선택은 layer-2 링크의 PC5의 V2X 통신의 통신모드에 근거한다. 소스 Layer- 2 ID는 다른 통신모드간에 다를 수 있다. IP 기반의 V2X 통신이 허용되는 경우, 단말은 링크 로컬 IPv6 주소를 소스 IP 주소로 사용하도록 설정한다. 단 말은 중복주소 탐색을 위한 Neighbor Solicitation and Neighbor Advertisement 메시지를 보내지 않고도, PC5 의 V2X 통신을 위해 이 IP 주소를 사용할 수 있다. 일 단말이 현재 지리적 영역에서 지원되는 개인정보 보호가 요구되는 활성화 된 V2X application을 갖는다면, 소스 단말(예를 들어, 차량)이 추적당하거나 특정시간 동안만 다른 단말로부터 식별되기 위해, 소스 Layer-2 ID 는 시간이 지남에 따라 변경되고, 무작위화 될 수 있다. IP 기반의 V2X 통신의 경우, 소스 IP 주소도 시간이 지 남에 따라 변경되어야 하고, 무작위화 되어야 한다. 소스 단말의 식별자들의 변경은 PC5에 사용되는 계층에서 동기화되어야 한다. 즉, 어플리케이션 계층 식별자가 변경된다면, 소스 Layer-2 ID 와 소스 IP 주소의 변경도 요구된다. 브로드캐스트 모드(Broadcast mode) 도 10은 PC5를 이용한 V2X 통신의 브로드캐스트 모드에 대한 절차를 예시하는 도면이다. 1. 수신 단말은 브로드캐스트 수신을 위한 목적지(destination) Layer-2 ID를 결정한다. 목적지 Layer-2 ID는 수신을 위해, 수신 단말의 AS 계층으로 전달된다. 2. 송신 단말의 V2X application layer는 데이터 유닛을 제공하고, V2X 어플리케이션 요구사항(Application Requirements)을 제공할 수 있다. 3. 송신 단말은 브로드캐스트를 위한, 목적지 Layer-2 ID를 결정한다. 송신 단말은 소스(source) Layer-2 ID를 자체 할당한다. 4. 송신 단말이 전송하는 하나의 브로드캐스트 메시지는 소스 Layer-2 ID 와 목적지 Layer-2 ID를 이용하여, V2X 서비스 데이터를 전송한다. 차량용 AR 화면을 위한 시스템 이하, 본 명세서의 바람직한 제1 실시예에 따른, 차량용 AR 화면을 위한 시스템에 관하여 상세히 설명하면 다음 과 같다. 본 명세서에서 기술되는 차량은, 동력원으로서 엔진을 구비하는 내연기관 차량, 동력원으로서 엔진과 전기 모터 를 구비하는 하이브리드 차량, 동력원으로서 전기 모터를 구비하는 전기 차량 등을 모두 포함하는 개념일 수 있 다. 도 11은 본 명세서의 제1 실시예에 따른 차량용 AR 화면을 위한 시스템을 나타난 도면이고, 도 12는 본 명세서 의 제1 실시예에 따른 차량을 나타낸 도면이며, 도 13은 본 명세서의 제1 실시예에 따른 제1 서버를 나타낸 도 면이다. 도 11에 따르면, 본 명세서의 제1 실시예에 따른 차량용 AR 화면을 위한 시스템은 차량, 제1 서버 및 제2 서버를 포함할 수 있다. 차량은 상술한 자율 주행 장치를 포함한 차량일 수 있다. 또는, 차량은 상술한 캐빈일 수 있다. 제1 서버는 AR 화면을 생성하고, 생성된 AR 화면에 대한 데이터 를 차량으로 전송할 수 있다. 제2 서버는 서비스 제공자(Service Provider)일 수 있다. 또는, 제2 서 버는 서비스 제공자로부터 수신한 데이터들을 저장하고 제1 서버로 전송하는 서버일 수 있다. 또한, 제2 서버는 차량으로부터 AR 영상 또는 AR 이미지 중 적어도 하나의 유형을 수신하고, 수신한 유형에 대응되는 광고 데이터를 제1 서버로 전송할 수 있다. 또한, 제2 서버가 제공하는 광고 데이터는 다양한 회사 또는 다양한 분야에 대한 광고 데이터일 수 있다. 제2 서버가 제공하는 광고 데이터는 광고 대상이 되는 상품 또는 광고 대상이 되는 회사에 따라 카테고리 별로 분류될 수 있다. 사용자는 차량을 통하여 광고 데이터의 카테고리를 지정할 수 있다. 즉, 사용자는 모든 카테고리의 광고를 보기를 원할 수도 있지만, 사용자는 특정 카테고리의 광고만을 보기를 원할 수도 있다. 따라서, 사용자는 차량 을 통하여 특정 카테고리의 광고에 대한 광고 데이터만을 수신하도록 특정 카테고리를 지정할 수 있다. 사용자에 의하여 지정된 카테고리는 차량을 통하여 제2 서버로 전송될 수 있다. 즉, 차량은 제2 서버로 사용자에 의하여 지정된 카테고리를 요청할 수 있다. 제2 서버는 차량으로부터 요청된 카 테고리를 기초로 광고 데이터를 제1 서버에 제공할 수 있다. 그 결과, 차량은 사용자에 의하여 지정된 카테고리의 AR 영상 또는 AR 이미지를 포함하는 AR 화면을 표시할 수 있다. 도 12에 따르면, 본 명세서의 제1 실시예에 따른 차량은 촬영 장치, 송수신부, 프로세서 및 디스플레이를 포함할 수 있다. 촬영 장치는 AR 화면을 위한 외부 영상을 촬영하기 위한 카메라 등을 포함할 수 있다. 또한, 촬영 장치 는 상술한 자율 주행 장치의 오브젝트 검출 장치일 수 있다. 촬영 장치는, 차량에 탑 승한 탑승객의 관점에서, 외부를 촬영할 수 있다. 촬영 장치가 촬영한 영상 또는 이미지는 AR 화면을 구성 하기 위한 배경 영상 또는 배경 이미지가 될 수 있다. 송수신부는 상술한 V2X 통신 중에서 V2V 통신을 사용하기 위한 장치일 수 있다. 캐빈의 경우, 송수신 부는 상술한 통신 장치일 수 있다. 송수신부는 AR 화면을 위한 데이터를 제1 서버로부터 수신하고 촬영 장치에 의하여 촬영된 외부 영상을 제1 서버로 송신하는 구성일 수 있다. 또한, 송수신부는 차량과 제1 서버 또는 다른 서버간의 통신을 수행할 수 있다. 송수신부의 경우, 안테나를 통해 기지국 또는 통신 기능을 포함하는 차량과 정보의 송수신을 실행할 수 있다. 송수신부는, 도면에는 도시되지 않았으나, 변조부, 복조부, 신호 처리부 등을 포함할 수 있다. 송수신부가 사용하는 무선 통신은, 통신사들이 기존에 설치해둔 통신 시설과 그 통신 시설의 주파수를 사 용하는 무선 통신망을 사용한 통신을 말할 수 있다. 이때, 송수신부는 CDMA(code division multiple access), FDMA(frequency division multiple access), TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access), SC-FDMA(single carrier frequency division multiple access) 등과 같은 다양한 무선 통신 시스템에 사용될 수 있으며, 뿐만 아니라, 송수신부는 3GPP(3rd generation partnership project) LTE(long term evolution) 등에도 사용될 수 있다 또한, 송수신부는, 최근 상용화 중인 5G 통신뿐만 아니라, 추후 상용화가 예정되어 있는 6G 등도 사용할 수 있다. 다만, 본 명세서는 이와 같은 무선 통신 방식에 구애됨이 없이 기설치된 통신망을 활용할 수 있다.프로세서는 상술한 메인 ECU 또는 상술한 프로세서일 수 있다. 또한, 본 명세서의 제1 실시예에 따른 프로세서는 주행에 필요한 연산을 수행하지 않는 별도의 프로세서일 수 있다. 편의상, 차량용 AR 화면을 위한 시스템에서의 프로세서는 별도의 도면 부호를 활용하여 설명되나 이에 한정되지 않는다. 도 12에 따르면, 프로세서는, 연산을 수행하고 다른 장치를 제어할 수 있는 구성이다. 주로, 중앙 연산 장 치(CPU), 어플리케이션 프로세서(AP), 그래픽스 처리 장치(GPU) 등을 의미할 수 있다. 또한, CPU, AP 또는 GPU 는 그 내부에 하나 또는 그 이상의 코어들을 포함할 수 있으며, CPU, AP 또는 GPU는 작동 전압과 클락 신호를 이용하여 작동할 수 있다. 다만, CPU 또는 AP는 직렬 처리에 최적화된 몇 개의 코어로 구성된 반면, GPU는 병렬 처리용으로 설계된 수 천 개의 보다 소형이고 효율적인 코어로 구성될 수 있다. 프로세서는 AR 화면을 차 량의 디스플레이에 표시하기 위한 구성일 수 있다. 디스플레이는 내비게이션에 포함된 디스플레이거나 차량의 윈드쉴드에 부착된 디스플레이일 수 있다. 또한, 디스플레이는 윈드쉴드 전체를 구성할 수도 있다. 또한, 디스플레이는 상술한 사용자 인터페이스 장치를 구성할 수도 있으며, 상술한 바와 같이 캐빈에서는 다양한 위치에 활용되는 디스 플레이일 수도 있다. 도 13에 따르면, 본 명세서의 제1 실시예에 따른 제1 서버는 외부로부터 입력되는 데이터를 처리하기 위한 데이터 처리부, 차량 또는 다른 서버와 통신하기 위한 데이터 송수신부, 처리된 데이터를 저장하 기 위한 맵 스토리지, 처리된 데이터를 활용하여 AR 화면을 생성하는 AR 엔진(AR Engine, 620)을 포함할 수 있다. 데이터 처리부는 제2 서버로부터 수신한 광고 데이터를 광고 영상 또는 광고 이미지로 재구성할 수 있다. 데이터 처리부는 AR 화면을 생성하기 위하여 차량으로부터 수신한 주행 데이터를 처리할 수 있 다. 데이터 처리부는 내비게이션 화면을 생성하기 위하여 주행 데이터를 바탕으로 도착지까지의 경로 등을 연산할 수 있다. 또한, 데이터 처리부는 지도 정보, 다이나믹 정보, 차량 센서 정보, 과거 기록 정보 및 기타 주행 관련 정 보를 입력받을 수 있다. 지도 정보는 목적지까지의 경로 정보, 내비게이션 경로, 경로 안내 정보, 전방 도로 형상, 지도 속성 정보(도로 속성, 도로 종류, 차선 및/또는 도로의 폭, 도로의 곡률, 도로의 경사도, 제한 속도 등) 및 로컬 정보(랜드 마 크 정보, 교통 신호 정보 등)를 포함할 수 있다. 다이나믹 정보는 실시간 교통 정보, 사고 등의 이벤트 정보, 날씨 정보 및 V2X(V2V, V2I)와 관련된 정보를 포함 할 수 있다. 차량 센서 정보는 차량의 현재 위치 정보, 카메라 입력 정보 및 실시간 주변 상황 정보를 포함할 수 있다. 현재 위치 정보는 GPS 등으로 측정된 좌표 정보일 수 있다. 카메라 입력 정보는 ADAS 정보, 오브젝트 인식 정보 를 포함할 수 있다. 실시간 주변 상황 정보는 V2X(V2V, V2I)를 통하여 획득한 실시간 주변 상황 정보일 수 있다. 기타 주행 관련 정보는 차량의 현재 주행 모드 정보, 차량의 목적지 또는 경유지 정보, 차량이 목 적지나 경우지에 진입하였는지에 대한 정보, 차량의 주차장 진입 여부에 대한 정보 등을 포함할 수 있다. 또한, 데이터 처리부는 경로에 기반한 AR 화면에 표시될 데이터들을 생성하고 구성할 수 있다. AR 컨텐츠 가 표시될 수 있는 영역으로서 후술할 AR Wall, POI 이미지 등이 구성될 수 있다. POI 이미지는 아이콘이나 말"}
{"patent_id": "10-2023-7011339", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "풍성과 같은 POI 요약 정보를 포함할 수 있다. 또한, POI 이미지는 경로상에는 존재하지 않지만 차량 주행에 도 움이 될 수 있는 원거리 POI 정보를 포함할 수 있다. 또한, 데이터 처리부는 차량의 주행 속도에 기반하여 실시간으로 AR 화면에 노출될 POI 이미지의 개수 를 결정할 수 있다. 또한, 데이터 처리부는 사고 등의 이벤트 정보, 오브젝트 인식 정보 등을 통하여 차량 주행 중 위험 가능성을 계산하고 그에 따라 POI 이미지의 개수를 결정할 수 있다. 일 예로, 차량 주행 중 위험 가능성이 높은 경우, POI 이미지의 개수를 줄여 탑승자의 시야를 확보할 수 있다. 또한, 데이터 처리부는 트래픽으로 인하여 POI 이미지에 대한 시인성이 저하되는 경우(예를 들어 POI 이미 지 화질이 떨어지는 경우), POI 이미지가 표시되는 위치를 변경할 수 있다. 일 예로, 트래픽으로 인하여 화질이 떨어지는 POI 이미지는 디스플레이의 외곽에 위치하도록 배치될 수 있다. 또한, 데이터 처리부는 주행 속도, 날씨 정보 등을 고려하여 디스플레이에 표시되는 POI 이미지의 개수 또 는 위치를 조절할 수 있다. 다만, 뒷좌석에 위치한 디스플레이는 주행 속도, 날씨 정보 등과 상관없이 POI 이미 지를 표시할 수 있다. 일 예로, 차량의 주행 속도가 미리 설정된 속도를 초과하는 경우 디스플레이에 표시 되는 POI 이미지의 개수는 줄어들 수 있다. 또한, 차량이 주행 중인 위치의 날씨가 흐리거나 비가 오는 경 우, 디스플레이에 표시되는 POI 이미지의 개수는 줄어들 수 있다. 위 설명은 POI 이미지를 중심으로 설명되었으나 이는 하나의 예시이며, AR 컨텐츠로 대체되어 이해될 수 있다. 즉, POI 이미지로 설명되었으나, POI 이미지는 AR Wall, AR 영상 또는 AR 이미지로 대체되어 이해될 수 있으며, 이는 해당 분야의 통상의 기술자에게 자명하다. AR 엔진은 재구성된 광고 영상 또는 광고 이미지를 AR 영상 또는 AR 이미지로 하여 AR 화면을 생성할 수 있다. AR 엔진은 배경 영상 또는 배경 이미지를 활용한 제1 레이어, 광고 영상 또는 광고 이미지를 활용한 제2 레이어 및 교통 정보 또는 경로 안내 등이 표시되는 제3 레이어를 생성하고, 각각의 레이어를 중첩하여 AR 화면을 생성할 수 있다. AR 엔진에서 생성된 AR 화면은 차량의 디스플레이에 전송되고 차량 의 디스플레이에서 표시될 수 있다. 제1 서버는 차량의 주행 구간 중 미리 설정된 구간에 후술할 제1 영역(AR1) 및/또는 제2 영역(AR2)을 배치할 수 있다. 이때, 제1 서버는 제1 영역(AR1)이 배치된 구간을 제외한 나머지 구간에 제2 영역(AR2)을 배치할 수 있다. 제1 서버는 도 12의 촬영 장치로부터 외부 영상을 수신하고, 수신한 외부 영상을 기초로 차량의 주행 구간 중 미리 설정된 구간에 후술할 제1 영역(AR1) 및/또는 제2 영역(AR2)을 배치할 수 있다. 이때, 미리 설정된 구간이란 차량의 주행 구간 중 특정 지점에서부터 시작될 수 있다. 또한, 제1 서버는 수신한 외부 영상으로부터 차량의 주행 구간에 대한 정보를 획득할 수 있다. 도 14는 본 명세서의 제1 실시예에 따른 주행 구간에 따른 제1 영역 및 제2 영역을 나타낸 도면이다. 도 14에 따르면, 본 명세서의 차량은 현재 위치에서부터 목적지까지 경로를 외부로부터 수신할 수 있다. 해 당 경로를 차량의 주행 경로라고 할 수 있다. 차량이 주행 경로를 따라 이동하는 경우, 제1 서버 는 AR 화면을 생성하기 위한 시작 지점을 생성할 수 있다. 제1 서버는 시작 지점부터 AR 화면을 생성하고, 이를 제1 지점으로 이하 서술한다. 제1 지점은 임의로 설정되는 지점으로서 상황에 맞추어 변경될 수 있다. 제1 지점은 사용자가 미리 설정된 기준 에 의하여 생성될 수 있다. 제1 지점은 차량의 현재 위치를 기준으로 일정 거리 이격된 지점일 수 있다. 제 1 지점은 차량의 주행 경로 중에서 임의의 지점일 수 있다. 제1 지점은 차량의 주행 경로 중 방향이 변 경되는 지점일 수 있다. 일 예로, 차량은 목적지까지의 예상 경로를 수신할 수 있다. 차량은 교차로에서 좌회전(또는 우회전)하 라는 예상 경로를 수신할 수 있다. 제1 서버는 교차로까지의 거리에 따라, 교차로에서부터 좌회전(또는 우 회전)할 예정인 주행 경로에서부터 AR 화면을 표시할 수 있다. 따라서, 제1 서버는 교차로가 있는 지점을 제1 지점으로 지정할 수 있다. 도 14에 따르면, 제1 지점 이후 차량의 주행 경로는 제1 영역(AR1)과 제2 영역(AR2)을 포함할 수 있다. 제1 영역(AR1)은 광고 데이터에 기반한 제1 AR 컨텐츠가 표시되는 영역일 수 있다. 제1 AR 컨텐츠는 도 13의 데 이터 처리부에서 생성된 광고 영상 또는 광고 이미지를 포함할 수 있다. 제1 AR 컨텐츠는 제2 서버로부터 수신한 광고 데이터를 기초로 제1 서버에서 생성될 수 있다. 제1 AR 컨텐츠는 광고 영상 또는 광고 이미지 를 포함하는 AR Wall을 포함할 수 있다. AR Wall은 도로 주변에 위치한 벽(wall)의 형태로 이루어진 AR 영상 또 는 AR 이미지일 수 있다. AR Wall은 도로 주변에 위치한 건물들을 가리고 건물들 대신 광고 영상 또는 광고 이 미지를 표시하기 위한 영역을 의미할 수 있다. 쉽게 말해, AR Wall은 도로 주변에 생성된 가상의 게시판이고, 가상의 게시판에 AR 컨텐츠가 표시될 수 있다. 따라서, 차량의 탑승자는 주행에 방해가 되지 않는 선에서 광고에 쉽게 노출될 수 있다. 제1 영역(AR1)은 AR Wall이 출력 또는 표시될 수 있는 영역일 수 있다. 제1 영역(AR1)의 기준은 직진 구간의 길 이가 미리 설정된 길이 이상인 구간, 차량이 정차하는 구간, 차량의 주행 속도가 일정 속도 이상인 구 간 및 POI의 밀집도가 미리 설정된 밀집도보다 큰 구간 중 적어도 어느 하나의 구간을 제1 영역(AR1)으로 정의 할 수 있다. 제2 영역(AR2)은 위치 정보에 기반한 제2 AR 컨텐츠가 표시되는 영역일 수 있다. 제2 AR 컨텐츠는 POI 이미지 (IM2)를 포함할 수 있다. POI 이미지(IM2)는 특정 좌표에 위치한 대상과 관련된 상표, 정보 등을 포함할 수 있 다. 이때, 위치 정보는 차량의 위치 정보뿐만 아니라 제2 AR 컨텐츠가 나타낼 대상의 위치에 대한 정보를 포함할 수 있다. 도 14에 따르면, 제1 영역(AR1)과 제2 영역(AR2)은 차량의 주행 구간을 따라 배치될 수 있다. 제1 영역 (AR1)과 제2 영역(AR2)은 제1 지점 이후부터 차량의 주행 구간을 따라 배치될 수 있다. 제2 영역(AR2)에는 POI 이미지(IM2)가 표시될 수 있다. 제1 영역(AR1)과 제2 영역(AR2)은 번갈아 가며 배치될 수 있다. 일 예로, 제1 서버는 차량으로부터 외부 영상을 수신하고, 외부 영상 속 빈 공간을 정의할 수 있다. 제1 서버는 빈 공간에 AR 광고 또는 AR 이미지를 표시하도록 AR 화면을 구성할 수 있다. 제1 서버는 구성된 AR 화면을 차량에 전송하고, 차량은 AR 화면을 디스플레이에 표시할 수 있다. 일 예로, 차량은 외부 영상을 획득하고, 획득된 외부 영상 중 빈 공간을 정의할 수 있다. 차량은 특정 구간에 대한 빈 공간에 표시하기위한 AR 영상 또는 AR 이미지를 제1 서버에 요청할 수 있다. 제1 서버 는 요청에 따라 빈 공간에 표시할 AR 영상 또는 AR 이미지를 이용하여 AR 화면을 구성할 수 있다. 제1 서 버는 구성된 AR 화면을 차량에 전송하고, 차량은 AR 화면을 디스플레이에 표시할 수 있다. 이때, 일 예시들에 설명된 빈 공간은 상술한 제1 영역(AR1) 및 제2 영역(AR2)이 배치되지 않은 영역을 의미할 수 있다. 또는 일 예시들에 설명된 빈 공간은 상술한 제1 영역(AR1)만이 배치되지 않은 영역을 의미할 수 있다. 즉, 미리 제공되는 광고가 표시되지 않는 빈 공간에도 AR 광고를 효과적으로 표시하기 위함이다. 도 15 내지 도 20은 본 명세서의 제1 실시예에 따른 AR 화면의 일 예시를 나타낸 도면이다. 도 15 내지 도 20은 각각의 예시일 뿐이며, 해당 분야의 통상의 기술자들은 도 15 내지 도 20을 조합하여 다양 한 적용이 가능하며, 다양한 조합들 역시 본 명세서로부터 자명하게 유추됨이 명백하다. 도 15에 따르면, AR 화면은 복수의 AR 이미지들을 포함할 수 있다. 복수의 AR 이미지들은 제1 AR 컨텐츠(IM1), 경로 이미지(IM3) 및 안내 이미지(IM4)를 포함할 수 있다. 경로 이미지(IM3)는 차량이 현재 진행하고 있는 차선을 표시한 AR 이미지일 수 있다. 안내 이미지(IM4)는 교차로 등에서 차량이 가야할 방향을 표시한 AR 이미지일 수 있다. 위 이미지들은 AR 이미지일 수 있지만, 경우에 따라 일반 이미지일 수도 있다. 이는 사용자 의 설정값에 의하여 변경될 수 있다. 도 15에 따르면, 제1 AR 컨텐츠(IM1)는 AR Wall을 도로 좌우에 표시할 수 있다. AR Wall은 제2 서버로부 터 수신한 광고 데이터에 기반하여 생성된 광고 영상 또는 광고 이미지를 표시할 수 있다. 이때, 광고 영상 또 는 광고 이미지는 미리 설정된 크기로 표시될 수 있다. 이때, 제1 AR 컨텐츠(IM1)는 차량 주변의 다른 차량 들을 가리지 않도록 배치될 수 있다. 이때, 제1 AR 컨텐츠(IM1)는 차량 주변의 다른 차량들을 가리지 않되 도로 주변의 건물을 가리도록 배치될 수 있다. 도 16에 따르면, AR 화면은 복수의 AR 이미지들을 포함할 수 있다. 복수의 AR 이미지들은 제2 AR 컨텐츠를 포함 할 수 있다. 제2 AR 컨텐츠는 복수의 POI 이미지(IM2)를 포함할 수 있다. POI 이미지(IM2)들은 지정된 위치의 상표 이미지 또는 심볼 이미지를 포함할 수 있다. POI 이미지(IM2)들은 상표 이미지 또는 심볼 이미지 이외에도 다양한 이미지를 포함할 수 있다. 제2 AR 컨텐츠 역시 도로 좌우에 표시되거나 도로 좌우에 위치한 건물에 표시 될 수 있다. 도 17에 따르면, AR 화면은 복수의 AR 이미지들을 포함할 수 있다. 복수의 AR 이미지들은 POI 이미지(IM2), 상 기 POI 이미지(IM2)가 나타내는 위치에 대한 정보 이미지(IM5) 및 경로 이미지(IM3)를 포함할 수 있다. 일 예로, POI 이미지(IM2)가 나타내는 위치는 주차장인 경우, 정보 이미지(IM5)는 POI 이미지(IM2)가 나타내는 주차장과 관련된 정보를 표시할 수 있다. 주차장에 대한 정보 이미지(IM5)는 신용카드 결제 가부, 장애인 주차 가부, 전기 충전 가부 및 SUV/RV 차량 주차 가부에 대한 정보를 포함할 수 있다. 도 18에 따르면, AR 화면은 복수의 AR 이미지들을 포함할 수 있다. 복수의 AR 이미지들은 경로 이미지(IM3) 및 정보 이미지(IM5)를 포함할 수 있다. 이때, 경로 이미지(IM3)는 복수의 경로를 나타낼 수 있다. 복수의 경로는 각각의 경로의 목적지를 나타낸 이미지를 더 포함할 수 있다. 일 예로, 정보 이미지(IM5)는 AR 화면에 포함될 수 있는 건물 또는 상기 건물에 위치한 스토어 등에 대한 정보 를 포함할 수 있다. 정보 이미지(IM5)가 표시하는 정보가 음식점에 대한 정보인 경우, 방문자들의 리뷰, 평점들을 시각적으로 표시한 이미지를 포함할 수 있다. 도 19에 따르면, AR 화면은 복수의 AR 이미지들을 포함할 수 있다. 복수의 AR 이미지들은 복수의 POI 이미지 (IM2)들을 포함할 수 있다. 복수의 POI 이미지(IM2)들은 상표 이미지 또는 심볼 이미지를 포함할 수 있다. 일 예로, 차량의 주행 구간에 일정 높이의 중앙 분리대가 존재하는 경우, 차량은 오브젝트 검출 장치 등을 통하여 도로의 중앙 분리대를 검출하고, 복수의 POI 이미지(IM2)들은 중앙 분리대와 중첩되지 않도록 배치 될 수 있다. 즉, 복수의 POI 이미지(IM2)들은 중앙 분리대의 높이만큼 도로의 바닥과 이격되도록 배치될 수 있 다. 또한, 위 예시는 중앙 분리대를 기준으로 설명하나, 중앙 분리대 이외에도 일정 높이를 가지는 오브젝트가 검출 되는 경우에 동일한 알고리즘이 적용될 수 있다. 즉, 도로의 한쪽에 버스가 위치하는 경우, 복수의 POI 이미지 (IM2)들은 버스의 높이만큼 도로의 바닥과 이격되도록 배치될 수 있다. 즉, 복수의 POI 이미지(IM2)들은 버스와 중첩되지 않도록 배치될 수 있다. 도 20에 따르면, AR 화면은 복수의 AR 이미지들을 포함할 수 있다. 복수의 AR 이미지들은 복수의 POI 이미지 (IM2)들을 포함할 수 있다. 복수의 POI 이미지(IM2)들은 주행 난이도를 고려하여 다르게 표시될 수 있다. 일 예로, 제1 서버는 각각의 POI 이미지(IM2)들이 나타내는 좌표까지 차량의 예상 경로를 획득하고, 획득된 예상 경로에 따라 복수의 POI 이미지(IM2)들은 다르게 표시될 수 있다. 제1 서버는 목적지까지의 거리, 예상 도착 시간, U턴 횟수 등을 고려하여 주행 난이도를 획득할 수 있다. 도 20에 따르면, 제1 서버는 우측의 POI 이미지(IM2)가 나타내는 좌표까지의 주행 난이도를 획득할 수 있 다. 제1 서버는 좌측의 POI 이미지(IM2)가 나타내는 좌표까지의 주행 난이도를 획득할 수 있다. 이때, 좌 측의 POI 이미지(IM2)가 나타내는 좌표까지 차량이 도달하기 위해서는, 차량은 U턴이 가능한 지점까지 이동한 후, U턴하여 반대편으로 이동하여야 한다. 반대로, 우측의 POI 이미지(IM2)가 나타내는 좌표까지 차량 이 도달하기 위해서는, 차량은 일정거리 앞으로 이동하여야 한다. 결국, 거리, 도착 시간, U턴 횟수 등 을 고려할 때, 우측의 POI 이미지(IM2)가 나타내는 좌표까지의 주행 난이도가 더 낮고, 좌측의 POI 이미지(IM 2)가 나타내는 좌표까지의 주행 난이도가 더 높다. 따라서, 미리 설정된 기준에 따라 제1 서버는 2개의 POI 이미지(IM2)를 다르게 표현할 수 있다. 또한, 미리 설정된 기준에 따라 제1 서버는 2개의 POI 이미지 (IM2)의 색상을 다르게 표현하거나, 2개의 POI 이미지(IM2)의 크기를 다르게 표현하는 등, 제1 서버는 다 양한 방법을 통하여 POI 이미지(IM2)를 다르게 표현할 수 있다. 일 예로, 제1 서버는 POI까지의 거리, 도 착 예정 시간을 이용하여 주행 난이도를 상/하로 분류하고, 그에 따라 POI 이미지의 색상이나 크기 등을 변경하 여 표시할 수 있다. 또한, 차량은 사용자(운전자)의 주행 습관, 패턴 등을 학습할 수 있다. 주행 난이도는 학습된 사용자의 주 행 습관, 패턴 등을 기초로 분류될 수 있다. 일 예로, 사용자는 차량의 내비게이션에 목적지를 입력하고 경로를 탐색한다. 이 경우, 내비게이션은 목적 지에 따른 다양한 경로를 사용자에게 제안한다. 사용자는 다양한 경로 중 어느 하나를 선택할 수 있다. 차량 은 사용자가 다양한 경로 중 어느 하나를 선택하는 경로를 저장할 수 있다. 사용자가 선택하는 경로의 경향 은 통계에 의하여 도출될 수 있다. 즉, 사용자가 주로 최단 시간의 경로를 선택하는지 최단 거리의 경로를 선택 하는지 등은 통계로서 도출될 수 있다. 제1 서버는 통계로서 도출된 결과값을 차량으로부터 수신할 수 있다. 제1 서버는 수신된 결과값을 기초로 POI까지의 거리, 도착 예정 시간을 계산할 수 있다. 일 예로, 사용자는 다양한 POI 중 특정 속성을 가지는 POI를 선호할 수 있다. 사용자(운전자)가 여성인 경우, 사용자(운전자)는 다양한 POI 중 여성 전용 주차장이 있는 POI를 주로 선택할 수 있다. 차량은 사용자가 다 양한 POI 중 어느 하나를 선택하는 결과를 저장할 수 있다. 이는 통계로서 차량 등에 저장될 수 있다. 즉, 사용자(운전자)가 선택하는 POI의 경향은 통계에 의하여 도출될 수 있다. 따라서, 주행 난이도를 표시하는 경우, 제1 서버는 사용자(운전자)가 선택하는 POI에 대한 경향을 고려하여 주행 난이도를 표시할 수 있다. 제1 서버는 다양한 POI 중 여성 주차장을 포함하는 POI 이미지를 다른 POI 이미지와 다르게 (색상, 크기 등을) 구성할 수 있다. 위 예시들을 살펴본 결과 제1 서버가 사용자(운전자)의 행동 정보를 기초로 주행 난이도를 결정하는 경우, 사용자(운전자)의 운전 성향에 따라 주행 난이도는 다르게 계산될 수 있다. 따라서, 판단의 근거가 되는 행동 정보에 따라 가중치가 다르게 설정될 수 있다. 구체적인 실시예 1을 살펴보면 다음과 같다. 사용자(운전자)가 차량에 탑승하여 주행 중이라고 가정한다. 사용자가 주행 중인 위치의 근처의 카페를 가 려고 한다. 이 경우, 사용자는 AR 서비스를 통하여 근처 카페를 검색할 수 있다. 검색 결과, 2개의 카페(A 카페 및 B 카페)가 검색되는 경우 제1 서버는 각각의 카페에 대한 주행 난이도를 계산할 수 있다. 제1 서버는 A 카페에는 주차장이 없고 B 카페에는 주차장이 있다는 정보를 획득할 수 있 다. 이 경우, 제1 서버는 B 카페를 나타내는 POI 이미지를 밝게 표시하고 A 카페를 나타내는 POI 이미지를 어둡게 표시할 수 있다. 구체적인 실시예 2를 살펴보면 다음과 같다. 사용자(운전자)가 차량에 탑승하여 주행 중이라고 가정한다. 사용자가 주행 중인 위치의 근처의 카페를 가 려고 한다. 이 경우, 사용자는 AR 서비스를 통하여 근처 카페를 검색할 수 있다. 검색 결과, 2개의 카페(A 카페 및 B 카페)가 검색되는 경우 제1 서버는 각각의 카페에 대한 주행 난이도를 계산할 수 있다. 제1 서버는 사용자의 성향을 고려하여 주행 난이도를 계산할 수 있다. 사용자는 내비게이 션을 이용하여 목적지까지의 경로를 탐색하는 경우, 주로 최단 거리를 검색하는 성향이 존재하며 이러한 성향은 통계로서 도출될 수 있다. 이 경우, 제1 서버는 최단 거리를 중심으로 A 카페 및 B 카페까지의 주행 난이 도를 계산할 수 있다. 제1 서버는 차량의 현재 위치와 A 카페까지의 제1 최단 거리와, 차량의 현 재 위치와 B 카페까지의 제2 최단 거리를 비교할 수 있다. 비교 결과, 제2 최단 거리가 더 짧은 경우, 제1 서버 는 B 카페에 대한 주행 난이도가 더 낮은 것으로 판단하고, B 카페에 대한 POI 이미지를 밝게 표시하고, A 카페를 나타내는 POI 이미지를 어둡게 표시할 수 있다. 도 21 내지 도 23은 본 명세서에 따른 제1 실시예의 차량용 AR 화면을 위한 시스템을 위한 아키텍처를 나타낸 도면이다. 도 21에 따르면, 차량용 AR 화면을 위한 시스템을 위한 아키텍처는 External Service Platform, AR Service Platform 및 In-Car Sensor의 3가지로 분류될 수 있다. External Service Platform는 POI Info. Service 및 Building Entrance Geo Info. Service를 제공할 수 있다. POI Info. Service는 POI의 대상이 되는 지점의 이름, 상가 정보, 건물 위치(좌표 정보) 등을 포함할 수 있다. Building Entrance Geo Info. Service는 건물의 주자창이나 건물의 주차장에 들어갈 수 있는 입구의 위치(좌표 정보) 등을 포함할 수 있다. 또한, External Service Platform는 Advertiser를 통하여 광고 데이터를 제공하며, OEM Servers의 인증을 위하 여 AR Service Platform과 통신할 수 있다. 또한, External Service Platform는 Payment Service를 제공할 수 있다. AR Service Platform은 Cloud 및 AVN을 포함할 수 있다. Cloud는 Service & Ads Aggregator, Ads Manager, Auth. Manager, Commerce Manager, DB Manager, Personalized Manager, Policy Updater, Security 및 AR Service Cloud API를 포함할 수 있다. Service & Ads Aggregator는 External Service Platform와 연동되고 해당 서비스 내에서의 광고 정보들을 통합 할 수 있다. Service & Ads Aggregator는 Ads Manager로부터 광보 정보들을 수신할 수 있다. Ads Manager는 광 고 데이터를 저장하고 광고 결과를 관리할 수 있다. Service & Ads Aggregator는 통합된 광고 데이터를 AR Service Cloud API로 전송할 수 있다. AR Service Cloud API는 수신한 광고 데이터의 포맷을 Unified API 포맷 으로 변환할 수 있다. Auth. Manager는 OEM Servers의 인증을 위한 구성일 수 있다. Commerce Manager는 Payment Service를 제공받을 수 있다. DB Manager는 인증 정보, 서비스 정보 및 광고 정보들을 저장하고 관리할 수 있다. Security는 데이터 들의 암호화를 통한 보안을 위한 구성일 수 있다. AR Service Cloud API는 AVN의 Cloud Interface에 서비스, 광고 등을 제공할 수 있다. AVN은 Ads Monitoring을 통하여 사용자의 광고에 대한 피드백을 수신하고 Ads Manager로 전송할 수 있다. AVN은 CID - RSE Interaction Manager, Policy Manager, Driving Context를 포함할 수 있다. Ads Monitoring은 AR Engine으로부터 사용자의 터치 빈도, 사용자에 광고가 노출된 빈도 등에 대한 데이터를 수신할 수 있다. AR Engine은 AR Core, Display Manager, Touch Manager를 포함할 수 있다. AR Core은 AR 화면 생성을 위한 구 성이고, Display Manager 및 Touch Manager는 사용자에게 광고가 표시된 빈도나 사용자가 광고를 터치한 빈도 등을 관리할 수 있다. 또한, In-Car Sensor는 Navigation, Camera, ADAS, Gyro 등을 포함할 수 있다. 도 22에 따르면, AR Service Cloud에서 서비스를 통합하기 위한 아키텍처가 도시되어 있다. 즉, AR Service Cloud에서 광고 정보가 통합되며, AR 엔진에 제공하기 위한 서비스 API를 제공할 수 있다. 외부 서비스를 위한 OEM Cloud는 AR Service Cloud에 인증을 요청하고, 인증 정보를 확인할 수 있다. 도 22에 따르면, AR Service Cloud는 3rd party Service와 통신하고, Ads를 송수신할 수 있다. 또한, 3rd party Service, Ads를 통합하여 AVN의 AR Engine으로 전송할 수 있고, AVN의 AR Engine으로부터 피드백을 수신 할 수도 있다. OEM Cloud는 AVN의 AR Engine로부터 자동차 및/또는 사용자의 인증을 받을 수 있다. 즉, AR Service Cloud는 OEM Cloud와는 인증 정보만 연동하고, 외부 서비스와 광고를 직접 통합하여 API를 제공할 수 있다. 또한, AVN의 AR Engine은 OEM Cloud와 사용자 인증 정보 및 차량 정보 연동할 수 있고, AVN의 AR Engine 은 AR Service Cloud 내에 서비스 사용 정보를 수집하여 저장할 수 있다. 도 23에 따르면, AR Service Cloud에서 서비스를 통합하기 위한 아키텍처가 도시되어 있다. 즉, OEM Cloud는 3rd party Service와 통신하며, AR Service Cloud는 Ads를 송수신할 수 있다. 즉, 도 22와 달리 AR Service Cloud는 직접 외부 서비스와 광고를 통합하는 것이 아니라, OEM Cloud로부터 제공되는 서비스에 광고를 추가할 뿐이다. 또한, OEM Cloud에서 자체적으로 광고를 제공할 수도 있을 것이다. 차량용 AR 화면 서비스 제공 방법 이하, 상술한 내용들을 바탕으로 본 명세서의 바람직한 제2 실시예에 따른, 차량용 AR 화면 서비스 제공 방법에 관하여 상세히 설명하면 다음과 같다. 본 명세서의 바람직한 제2 실시예는 상술한 제1 실시예의 제1 서버의 관점에서 서술될 수 있으나 이에 한정되지 않는다. 또한, 본 명세서의 바람직한 제2 실시예는 상술한 제1 실시예의 제1 서버가 수행할 수 있는 동작일 수 있다. 이하, 본 명세서의 바람직한 제2 실시예 중 상술한 제1 실시예와 동일하거나 중복되는 내용은 편의상 생략되어 설명될 수 있다. 도 24는 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법의 일 예시를 나타낸 도면이다. 도 24에 따르면, 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법은 차량으로부터 AR 화면 요청 데이터를 수신하는 단계(S1100), 차량으로부터 주행 데이터를 수신하는 단계(S1200), 외부 서버로부터 광고 데이터를 수신하는 단계(S1300), 주행 데이터와 광고 데이터에 기초한 AR 화면을 생성하기 위한 제1 데이 터를 생성하는 단계(S1400) 및 제1 데이터를 차량으로 전송하는 단계(S1500)를 포함할 수 있다. AR 화면 요청 데이터는 차량에 탑승한 탑승객이 AR 화면을 요청하는 경우, 차량은 AR 화면을 표시하기 위하여 제1 서버에 AR 화면을 요청하는 메시지를 전송할 수 있다. 이 외에도 차량에 미리 설정된 조건 이 달성되면 AR 화면을 표시하기 위하여 차량은 제1 서버에 AR 화면을 요청하는 메시지를 전송할 수 있다. 주행 데이터는 차량이 주행 중에 획득한 모든 데이터를 의미할 수 있다. 주행 데이터는 상술한 촬영 장치 에서 획득된 영상 데이터 또는 이미지 데이터를 포함할 수 있다. 또한, 주행 데이터는 실시간으로 획득되 는 데이터를 포함할 수 있다. 즉, 주행 데이터는 차량의 속도 정보, 가속도 정보, 방향 정보, 현재 위치 정 보 등을 포함할 수 있다. 또한, 주행 데이터는 차량이 주행 중인 도로의 교통 상황, 차량이 주행 중인 곳의 날씨 상황 등을 포함할 수 있다. 광고 데이터는 외부 서버로부터 수신될 수 있다. 외부 서버는 상술한 제2 서버일 수 있다. 광고 데이터는 제2 서버에 저장되거나 제2 서버를 통하여 전달되는 데이터일 수 있다. 광고 데이터는 광고 영상 또 는 광고 이미지와 관련된 데이터일 수 있다. 제1 데이터는 주행 데이터와 광고 데이터에 기초한 AR 화면을 생성할 수 있다. 즉, 제1 데이터는 제1 서버(60 0)에서 차량으로 전송되고, 차량은 제1 데이터를 디스플레이에 표시할 수 있다. 제1 데이터가 디 스플레이에 표시되면, 광고 영상 또는 광고 이미지를 포함하는 AR 화면이 표시될 수 있다. 도 25는 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법의 일 예시를 보다 구체적으로 나타낸 도면이다. 도 25에 따르면, 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법은 제1 지점을 결정하는 단계 (S2100), 제1 지점을 기초로 다음 안내 구간을 결정하는 단계(S2200), 차량으로부터 다음 안내 구간에 대한 AR 화면 요청 데이터를 수신하는 단계(S2300), 차량으로부터 주행 데이터를 수신하는 단계(S2400), 외부 서 버로부터 광고 데이터를 수신하는 단계(S2500), 주행 데이터와 광고 데이터에 기초하여 AR 화면에 대한 제1 데 이터를 생성하는 단계(S2600) 및 제1 데이터를 차량으로 전송하는 단계(S2700)를 포함할 수 있다. 위 “결 정하다”는 “지정하다”, “선택하다”, “정의하다”, “획득하다”, “추출하다” 등으로 대체될 수 있다. 제1 지점은 상술한 제1 실시예의 제1 지점을 의미할 수 있다. 또한, 다음 안내 구간은 제1 지점을 기준으로부터 시작될 수 있다. AR 화면은 다음 안내 구간을 기초로 구성되며, 제1 서버는 다음 안내 구간 중 일부에 제1 영역(AR1)을 배치하고 다른 일부에 제2 영역(AR2)을 배치할 수 있다. 도 26은 본 명세서의 제2 실시예에 따른 광고 데이터를 수신하는 단계를 구체적으로 나타낸 도면이다. 도 26에 따르면, 광고 데이터를 수신하는 단계(S2500)는, 다음 안내 구간에 대응되는 (제1) 광고 데이터의 존재 여부를 체크하는 단계(S2510), 다음 안내 구간에 대응되는 (제1) 광고 데이터 존재하는 경우, 외부 서버로부터 (제1) 광고 데이터를 수신하는 단계(S2511)를 포함할 수 있다. 도 26에 따르면, 광고 데이터를 수신하는 단계(S2500)는, 다음 안내 구간에 대응되는 (제1) 광고 데이터의 존재 여부를 체크하는 단계(S2510), 다음 안내 구간에 대응되는 (제1) 광고 데이터 존재하는 경우, 다음 안내 구간 중 광고 가능 영역 추출하는 단계(S2521), 추출된 광고 가능 영역의 크기를 센싱하는 단계(S2522), 센싱된 크기 에 대응되는 제2 광고 데이터의 존재 여부를 체크하는 단계(S2523)를 포함할 수 있다. 또한, 광고 데이터를 수신하는 단계(S2500)는, 제2 광고 데이터 존재하는 경우, 외부 서버로부터 제2 광고 데이 터를 수신하는 단계(S2524)를 더 포함할 수 있다. 또한, 광고 데이터를 수신하는 단계(S2500)는, 제2 광고 데이 터 존재하지 않는 경우, 실시간 광고 경매 시스템에 광고 요청하는 단계(S2525) 및 경매 서버로부터 낙찰된 광 고에 대한 데이터를 수신하는 단계(S2526)를 더 포함할 수 있다. 즉, 실시간 광고가 표시될 수 있으며, 실시간 광고는 bidding (경매 방식) 시스템으로부터 선택된 광고를 포함할 수 있다. 도 27 내지 도 29는 본 명세서의 제2 실시예에 따른 AR 화면에 대한 제1 데이터를 생성하는 단계를 구체적으로 나타낸 도면이다. 도 27에 따르면, 본 명세서의 제2 실시예에 따른 AR 화면에 대한 제1 데이터를 생성하는 단계(S2600)는 AR 화면 요청 데이터에 기초하여 AR 화면의 구성을 메모리로부터 로딩하는 단계(S2610), 로딩된 AR 화면의 구성에 기초 하여 AR 화면 레이어를 생성하는 단계(S2611), 광고 데이터에 기초하여, AR 화면 레이어에 AR 이미지를 삽입하 는 단계(S2612), AR 화면 레이어를 다음 안내 구간을 나타내는 레이어에 중첩하는 단계(S2613) 및 AR 화면을 생 성하고, AR 화면에 대한 제1 데이터를 생성하는 단계(S2614)를 포함할 수 있다. 도 28에 따르면, 본 명세서의 제2 실시예에 따른 AR 화면에 대한 제1 데이터를 생성하는 단계(S2600)는 AR 화면 은 제1 영역(AR1) 및 제2 영역(AR2)을 포함하고, 제2 영역(AR2)에 표시될 POI 정보를 수신하는 단계(S2620), 수 신한 POI 정보에 대응되는 좌표까지의 주행 경로를 획득하는 단계(S2621), 획득한 주행 경로에 기초하여 주행 난이도를 획득하는 단계(S2622) 및 획득한 주행 난이도에 따라 POI를 다르게 표시하는 AR 화면을 생성하고, AR 화면에 대한 제1 데이터를 생성하는 단계(S2623)를 포함할 수 있다. 이때, 제1 데이터는 AR 화면에 대한 데이터일 수 있다. 디스플레이에 제1 데이터를 입력하면 AR 화면이 표 시될 수 있다. 도 29에 따르면, 본 명세서의 제2 실시예에 따른 AR 화면에 대한 제1 데이터를 생성하는 단계(S2600)는 AR 화면 은 제1 영역(AR1) 및 제2 영역(AR2)을 포함하고, 제1 영역(AR1)에 표시될 AR 이미지 정보를 수신하는 단계 (S2630), 수신한 AR 이미지 정보와 주행 데이터를 기초로 AR 표시 가능 영역 획득하는 단계(S2631), AR 표시 가 능 영역에서 AR 이미지를 재배치하는 단계(S2632)를 포함할 수 있다. 도 29에 따르면, 본 명세서의 제2 실시예에 따른 AR 화면에 대한 제1 데이터를 생성하는 단계(S2600)는 AR 이미 지를 재배치하는 단계(S2632) 이후, AR 이미지와 POI가 중첩하는 경우, 다시 AR 표시 가능 영역 획득하는 단계 (S2631)로 돌아갈 수 있다. 도 29에 따르면, 본 명세서의 제2 실시예에 따른 AR 화면에 대한 제1 데이터를 생성하는 단계(S2600)는 AR 이미 지를 재배치하는 단계(S2632) 이후, AR 이미지와 POI가 중첩하지 않는 경우, 재배치된 AR 이미지를 표시하는 AR 화면을 생성하고, AR 화면에 대한 제1 데이터를 생성하는 단계(S2623)를 더 포함할 수 있다. 도 30은 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법을 시스템의 관점에서 나타낸 도면이 다. 도 30에 따르면, 차량용 AR 화면 서비스 제공 방법은 차량, 제1 서버 및 제2 서버에서 각각 동작 을 수행할 수 있다. 차량은 제1 서버로 AR 화면을 요청하고, 주행 데이터를 획득하여 제1 서버로 전송할 수 있다 (S101). 제1 서버는 AR 화면 요청을 수신하면 AR 화면 구성을 메모리로부터 로딩할 수 있다(S102). 제2 서 버는 의뢰받은 광고에 대한 광고 데이터를 저장할 수 있다(S103). 제2 서버는 제1 서버로 광고 데이터를 전송할 수 있다(S104). 제1 서버는 광고 데이터를 기초로 AR 이미지(또는 AR 영상)를 생성할 수 있다(S105). 제1 서버는 주행 데이터를 기초로 AR 화면 구성에 AR 이미지를 배치하고(S106), AR 화면을 위 한 제1 데이터를 생성할 수 있다(S107). 제1 서버는 생성된 제1 데이터를 차량으로 전송할 수 있고 (S108), 차량은 제1 데이터를 기초로 AR 화면을 디스플레이에 표시할 수 있다(S109). 차량은 AR 화면이 표시된 디스플레이를 기초로 사용자가 입력한 명령을 카운팅할 수 있다. 즉, 차량은 특정 광고 에 대한 사용자의 피드백을 체크할 수 있다. 차량은 사용자의 피드백을 포함하는 광고 카운팅 데이터를 제2 서버로 전송할 수 있다(S110). 또한, 차량은 광고 카운팅 데이터를 제1 서버로도 전송할 수 있을 것이다. 또한, 이상에서 실시 예들을 중심으로 설명하였으나 이는 단지 예시일 뿐 본 명세서를 한정하는 것이 아니며, 본 명세서가 속하는 분야의 통상의 지식을 가진 자라면 본 실시 예의 본질적인 특성을 벗어나지 않는 범위에서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 예를 들어, 실시 예들에 구체적 으로 나타난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부한 청구 범위에서 규정하는 본 명세서의 범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30"}
{"patent_id": "10-2023-7011339", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 발명에 대한 실시 예를 제 공하고, 상세한 설명과 함께 본 발명의 기술적 특징을 설명한다. 도 1은 본 명세서 실시예에 따른 차량을 도시한 도면이다. 도 2는 본 명세서의 실시예에 따른 차량의 제어 블럭도이다. 도 3은 본 명세서의 실시예에 따른 자율 주행 장치의 제어 블럭도이다. 도 4는 본 명세서의 실시예에 따른 자율 주행 차량의 신호 흐름도이다. 도 5는 본 발명의 실시예에 따른 차량의 내부를 도시한 도면이다. 도 6은 본 발명의 실시예에 따른 차량용 캐빈 시스템을 설명하는데 참조되는 블럭도이다. 도 7은 본 발명의 실시예에 따라 사용자의 이용 시나리오를 설명하는데 참조되는 도면이다. 도 8은 본 명세서가 적용될 수 있는 V2X 통신의 예시이다. 도 9는 V2X가 사용되는 사이드링크에서의 자원 할당 방법을 예시한다. 도 10은 PC5를 이용한 V2X 통신의 브로드캐스트 모드에 대한 절차를 예시하는 도면이다. 도 11은 본 명세서의 제1 실시예에 따른 차량용 AR 화면을 위한 시스템을 나타난 도면이다. 도 12는 본 명세서의 제1 실시예에 따른 차량을 나타낸 도면이다. 도 13은 본 명세서의 제1 실시예에 따른 제1 서버를 나타낸 도면이다. 도 14는 본 명세서의 제1 실시예에 따른 주행 구간에 따른 제1 영역 및 제2 영역을 나타낸 도면이다. 도 15 내지 도 20은 본 명세서의 제1 실시예에 따른 AR 화면의 일 예시를 나타낸 도면이다. 도 21 내지 도 23은 본 명세서에 따른 제1 실시예의 차량용 AR 화면을 위한 시스템을 위한 아키텍처를 나타낸 도면이다. 도 24는 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법의 일 예시를 나타낸 도면이다. 도 25는 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법의 일 예시를 보다 구체적으로 나타낸 도면이다. 도 26은 본 명세서의 제2 실시예에 따른 광고 데이터를 수신하는 단계를 구체적으로 나타낸 도면이다. 도 27 내지 도 29는 본 명세서의 제2 실시예에 따른 AR 화면에 대한 제1 데이터를 생성하는 단계를 구체적으로 나타낸 도면이다. 도 30은 본 명세서의 제2 실시예에 따른 차량용 AR 화면 서비스 제공 방법을 시스템의 관점에서 나타낸 도면이 다."}
