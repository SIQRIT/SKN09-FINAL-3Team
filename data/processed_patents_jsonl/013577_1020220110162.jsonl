{"patent_id": "10-2022-0110162", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0030746", "출원번호": "10-2022-0110162", "발명의 명칭": "단일 영상 기반의 3차원 인체 형상 복원 및 실사 아바타 생성 방법", "출원인": "한국전자기술연구원", "발명자": "박민규"}}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에 있어서,복원된 3차원 인체 형상을 리깅하는 단계;를 더 포함하는 것을 특징으로 하는 3차원 인체 형상 복원 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,제1 예측단계는,전면 perspective 컬러 영상으로부터 양면 orthographical 법선 맵을 예측하는 제1-1 예측단계;를 포함하는 것을 특징으로 하는 3차원 인체 형상 복원 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,제1 예측단계는,단일 perspective 컬러 영상과 제1-1 예측단계에서 예측된 양면 orthographical 법선 맵으로부터 양면orthographical 컬러 영상을 예측하는 제1-2 예측단계;를 더 포함하는 것을 특징으로 하는 3차원 인체 형상 복원 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,제2 예측단계는,제1-1 예측단계에서 예측된 양면 orthographical 법선 맵과 제1-2 예측단계에서 예측된 양면 orthographical컬러 영상으로부터 양면 orthographical 깊이 맵을 예측하는 것을 특징으로 하는 3차원 인체 형상 복원 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,제2 예측단계를 수행하는 인공지능 모델은,제1-1 예측단계에서 예측된 양면 orthographical 법선 맵으로부터 특징을 추출하는 제1 인코더;제1-2 예측단계에서 예측된 양면 orthographical 컬러 영상으로부터 특징을 추출하는 제2 인코더; 및제1 인코더에 의해 추출된 특징과 제2 인코더에 의해 추출된 특징으로부터 양면 orthographical 깊이 맵을 생성하는 디코더;를 포함하는 것을 특징으로 하는 3차원 인체 형상 복원 방법.공개특허 10-2024-0030746-3-청구항 6"}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,리깅 단계는,인체의 단일 perspective 영상과 예측된 양면 orthographical 깊이 맵을 이용하여, SMPL 모델을 예측하는 단계;복원된 3차원 인체 형상을 SMPL 모델에 맞게 피팅하는 단계;SMPL 파라미터를 활용하여 복원되지 못한 영역을 생성하는 단계;를 포함하는 것을 특징으로 하는 3차원 인체 형상 복원 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,리깅 단계는,3차원 인체 형상을 T-pose로 변환하는 단계;변환된 3차원 인체 형상을 애니메이팅 하는 단계;를 더 포함하는 것을 특징으로 하는 3차원 인체 형상 복원 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서,제1 예측단계를 수행하는 인공지능 모델과 제2 예측단계를 수행하는 인공지능 모델은,3차원 모델 데이터들을 렌더링하여 생성한 학습 데이터셋을 이용하여 학습되는 것을 특징으로 하는 3차원 인체형상 복원 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인체의 단일 perspective 컬러 영상으로부터 orthographical 영상을 예측하는 제1 예측모델;예측된 orthographical 영상으로부터 깊이 맵을 예측하는 제2 예측모델;인체의 단일 perspective 영상과 예측된 깊이 맵을 이용하여, 3차원 인체 형상을 복원하는 복원부;를 포함하는것을 특징으로 하는 3차원 인체 형상 복원 시스템."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인체의 단일 perspective 컬러 영상으로부터 orthographical 영상을 예측하면서 인체의 단일 perspective 영상에 대한 깊이 맵을 예측하는 단계;인체의 단일 perspective 영상과 예측된 깊이 맵을 이용하여, 3차원 인체 형상을 복원하는 단계;공개특허 10-2024-0030746-4-복원된 3차원 인체 형상을 리깅하는 단계;를 포함하는 것을 특징으로 하는 3차원 아바타 생성 방법."}
{"patent_id": "10-2022-0110162", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "인체의 단일 perspective 컬러 영상으로부터 orthographical 영상을 예측하면서 인체의 단일 perspective 영상에 대한 깊이 맵을 예측하고, 인체의 단일 perspective 영상과 예측된 깊이 맵을 이용하여 3차원 인체 형상을복원하는 복원부;복원된 3차원 인체 형상을 리깅하는 리깅부;를 포함하는 것을 특징으로 하는 3차원 아바타 생성 시스템."}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "단일 영상 기반의 3차원 인체 형상 복원 및 실사 아바타 생성 방법이 제공된다. 본 발명의 실시예들에 따르면 단 일 영상 입력을 활용하여 전/후면의 orthographical 컬러, 법선, 깊이 영상을 예측하고 3차원 볼륨공간으로 변환 및 메쉬 생성을 통해 3차원 인체 형상 모델을 복원할 수 있게 된다. 또한 복원된 모델을 템플릿 모델에 맞춰 최 적화하고 모델 파라미터에 따라 리깅하여 자연스러운 움직임까지 가능하게 함으로써 여러 분야에서 활용도를 높 일 수 있게 된다."}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 활용한 3차원 영상 처리 기술에 관한 것으로, 더욱 상세하게는 입력 영상으로부터 3차원 인체 형상 모델을 복원하며, 복원된 모델을 정렬하고 리깅하여 변형 가능한 아바타를 생성하는 기술에 관한 것 이다."}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 다양한 3차원 모델 복원 방법과 더불어 자연스러운 움직임이 가능하도록 처리하는 기술에 대한 연구 개발 이 활발히 진행되고 있다. 그러나 데이터셋 획득, 학습 시간 및 복잡도 측면의 이슈 등과 같은 여러 문제로 고 품질의 3차원 모델 복원 연구는 여전히 어려우며, 구체적으로는 다음과 같은 이유에서이다. 첫째, 3차원 실제 데이터를 획득하기 어렵기 때문에 품질이 낮은 3차원 데이터나 기존에 제공되었던 SMPL과 같 은 가상의 데이터들을 활용해서 3차원 복원 학습을 진행하는데, 학습 데이터가 저품질이기 때문에 복원 성능 또 한 낮다. 그리고 SMPL 가상 데이터들은 헤어나 의상 같은 디테일이 없어서 인체의 형상과 체형 정도의 복원만이 가능할 뿐이다. 둘째, 3차원 볼륨 기반의 복원 방법에서 perspective 깊이 맵을 예측하여 영상을 복원하려면 perspective projection에서 발생하는 bias를 보정 해주는 작업이 추가적으로 필요하다. 하지만 일반적으로 카메라에서 획득 된 영상은 perspective 영상이기 때문에 이를 기반으로 복원을 진행하면, 복원된 모델의 얼굴이 정면을 응시하 지 않고 위쪽을 향하고 있는 등 부자연스러운 느낌을 받을 수 있다. 셋째, 3차원 모델 복원만으로는 다양한 분야에서 자연스러운 모델 활용이 제한이 있다. 모델 복원 이후에 객체 의 움직임 추가되어야 여러 분야에서의 활용성이 높아질 수 있는데 현재는 그렇지 못하다."}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 3차원 인체 형상 객체를 복원하여 움직일 수 있도록 함으로써 다양한 영역에서의 활용도를 높이기 위한 방안으로, 단일 영상 입력을 활 용하여 전/후면의 orthographical 컬러, 법선, 깊이 영상을 예측하고 3차원 볼륨공간으로 변환 및 메쉬 생성을 통해 3차원 인체 형상 모델을 복원하고, 복원된 모델을 템플릿 모델에 맞춰 최적화하고 모델 파라미터에 따라 리깅하여 동작이 가능하도록 하는 방법을 제공함에 있다."}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 3차원 인체 형상 복원 방법은, 인체의 단일 perspective 컬러 영상으로부터 orthographical 영상을 예측하는 제1 예측단계; 예측된 orthographical 영상으 로부터 깊이 맵을 예측하는 제2 예측단계; 인체의 단일 perspective 영상과 예측된 깊이 맵을 이용하여, 3차원 인체 형상을 복원하는 단계;를 포함한다. 제1 예측단계는, 전면 perspective 컬러 영상으로부터 양면 orthographical 법선 맵을 예측하는 제1-1 예측단계;를 포함할 수 있다. 제1 예측단계는, 단일 perspective 컬러 영상과 제1-1 예측단계에서 예측된 양면 orthographical 법선 맵으로부 터 양면 orthographical 컬러 영상을 예측하는 제1-2 예측단계;를 더 포함할 수 있다. 제2 예측단계는, 제1-1 예측단계에서 예측된 양면 orthographical 법선 맵과 제1-2 예측단계에서 예측된 양면 orthographical 컬러 영상으로부터 양면 orthographical 깊이 맵을 예측할 수 있다. 제2 예측단계를 수행하는 인공지능 모델은, 제1-1 예측단계에서 예측된 양면 orthographical 법선 맵으로부터 특징을 추출하는 제1 인코더; 제1-2 예측단계에서 예측된 양면 orthographical 컬러 영상으로부터 특징을 추출 하는 제2 인코더; 및 제1 인코더에 의해 추출된 특징과 제2 인코더에 의해 추출된 특징으로부터 양면 orthographical 깊이 맵을 생성하는 디코더;를 포함할 수 있다. 본 발명의 일 실시예에 따른 3차원 인체 형상 복원 방법은, 복원된 3차원 인체 형상을 리깅하는 단계;를 더 포 함할 수 있다. 리깅 단계는, 인체의 단일 perspective 영상과 예측된 양면 orthographical 깊이 맵을 이용하여, SMPL 모델을 예측하는 단계; 복원된 3차원 인체 형상을 SMPL 모델에 맞게 피팅하는 단계; SMPL 파라미터를 활용하여 복원되 지 못한 영역을 생성하는 단계;를 포함할 수 있다. 리깅 단계는, 3차원 인체 형상을 T-pose로 변환하는 단계; 변환된 3차원 인체 형상을 애니메이팅 하는 단계;를 더 포함할 수 있다. 제1 예측단계를 수행하는 인공지능 모델과 제2 예측단계를 수행하는 인공지능 모델은, 3차원 모델 데이터들을 렌더링하여 생성한 학습 데이터셋을 이용하여 학습될 수 있다. 본 발명의 다른 실시예에 따른 3차원 인체 형상 복원 시스템은, 인체의 단일 perspective 컬러 영상으로부터 orthographical 영상을 예측하는 제1 예측모델; 예측된 orthographical 영상으로부터 깊이 맵을 예측하는 제2 예측모델; 인체의 단일 perspective 영상과 예측된 깊이 맵을 이용하여, 3차원 인체 형상을 복원하는 복원부;를 포함한다. 본 발명의 다른 실시예에 따른 3차원 아바타 생성 방법은, 인체의 단일 perspective 컬러 영상으로부터 orthographical 영상을 예측하면서 인체의 단일 perspective 영상에 대한 깊이 맵을 예측하는 단계; 인체의 단 일 perspective 영상과 예측된 깊이 맵을 이용하여, 3차원 인체 형상을 복원하는 단계; 복원된 3차원 인체 형상 을 리깅하는 단계;를 포함한다. 본 발명의 다른 실시예에 따른 3차원 아바타 생성 시스템은, 인체의 단일 perspective 컬러 영상으로부터 orthographical 영상을 예측하면서 인체의 단일 perspective 영상에 대한 깊이 맵을 예측하고, 인체의 단일 perspective 영상과 예측된 깊이 맵을 이용하여 3차원 인체 형상을 복원하는 복원부; 복원된 3차원 인체 형상을 리깅하는 리깅부;를 포함한다."}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 단일 영상 입력을 활용하여 전/후면의 orthographical 컬러, 법선, 깊이 영상을 예측하고 3차원 볼륨공간으로 변환 및 메쉬 생성을 통해 3차원 인체 형상 모델을 복원 할 수 있게 된다. 또한 본 발명의 실시예들에 따르면, 복원된 모델을 템플릿 모델에 맞춰 최적화하고 모델 파라미터에 따라 리깅 하여 자연스러운 움직임까지 가능하게 함으로써 여러 분야에서 활용도를 높일 수 있게 된다."}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명의 실시예에서는 단일 전면 영상 기반의 3차원 인체 형상 복원 및 복원 형상으로부터 실사 아바타를 생 성하는 방법 및 시스템을 제시한다. 전/후면에 대해 직교 투영(orthographic projection)된 컬러 영상, 법선 영상, 깊이 맵 예측을 통해 3차원 인체 형상 모델을 복원하며, 복원된 모델에 대한 템플릿 모델 파라미터 추정을 통해 정렬하고 리깅하여 변형 가능한 아바타를 생성하는 기술이다. 생성된 실사 기반의 아바타는 패션, 게임, 의료 등 다양한 분야에서 개인을 표현 하는 아바타로 활용될 수 있다. 본 발명의 실시예에서는 3차원 인체 형상 복원 모델을 활용하여 전면 perspective 컬러 영상으로부터 양면(전면 /후면) orthographical 법선(normal) 영상, 양면 orthographical 컬러 영상을 예측한 후에, 예측된 영상들을 이용하여 양면 깊이 맵을 예측한다. 3차원 인체 형상 복원 모델의 학습을 위해, 3차원 모델 데이터들을 렌더링하여 학습 데이터셋를 생성한다. 사용 되는 3차원 모델 데이터는 100만 버텍스 이상으로 구성된 고품질의 데이터들로 하는 것이 좋으며, 도 1에는 이 3차원 데이터들을 예시하였다. 예시된 3차원 데이터들을 활용하여 모델 학습을 위한 데이터셋을 생성하는데, 데이터 렌더링 시에는 다양한 조 명 색상, 세기 그리고 각도 등을 적용하여, 전면 perspective 컬러 영상에 대한 orthographical 영상 복원을 위 해 양면 orthographical 법선 맵, 양면 orthographical 컬러 영상, 양면 orthographical 깊이 맵을 생성하여야 한다. ground truth 깊이 맵과 컬러 영상은 ray-tracing을 통해 얻어질 수 있으며, 카메라 방향(camera origin)으로 부터 각 픽셀 위치의 방향으로 ray를 쏜다. 그리고 mesh의 표면에 가장 가까이 교차하는 점과 가장 멀리 교차하 는 점을 찾아 영상들을 생성한다. 법선 은 깊이 맵을 통해 계산된다. 렌더링된 perspective 컬러 영상은 임의의 실내 배경 영상들과 합성하여 모델 학습의 입력으로 활용할 수 있다. 도 2는 배경이 합성된 입력 영상의 예를 보여준다. 앞서 생성된 학습 영상들을 활용하여 전/후면의 orthographical 컬러 영상, 법선 맵, 깊이 맵을 예측하기 위한 3차원 인체 형상 복원 모델의 구조는 도 3에 도시된 바와 같다. 3차원 인체 형상 복원 모델은 도시된 바와 같이 orthographical 법선 예측 모델, orthographical 영상 예 측 모델 및 orthographical 깊이 예측 모델을 포함하여 구성된다. orthographical 법선 예측 모델은 단면 perspective 컬러 영상을 분석하여 양면 orthographical 법선 맵 을 예측하도록 학습된 딥러닝 모델이다. orthographical 법선 예측 모델에 의해 입력되는 단면 perspective 컬러 영상으로부터 양면 orthographical 법선 맵이 예측된다. orthographical 영상 예측 모델은 단면 perspective 컬러 영상과 orthographical 법선 예측 모델에 의해 예측된 양면 orthographical 법선 맵을 분석하여 양면 orthographical 컬러 영상을 예측하도록 학습된 딥 러닝 모델이다. orthographical 영상 예측 모델에 의해, 입력되는 단면 perspective 컬러 영상과 양면 orthographical 법선 맵으로부터 양면 orthographical 컬러 영상이 예측된다.orthographical 깊이 예측 모델은 orthographical 법선 예측 모델에 의해 예측된 양면 orthographical 법선 맵과 orthographical 영상 예측 모델에 의해 예측된 양면 orthographical 컬러 영상 을 분석하여 양면 orthographical 깊이 맵을 예측하도록 학습된 딥러닝 모델이다. orthographical 깊이 예측 모 델에 의해 양면 orthographical 법선 맵과 양면 orthographical 컬러 영상으로부터 양면 orthographical 깊이 맵이 예측된다. 한편 orthographical 깊이 예측 모델은 도시된 바와 같이, 인코더-1, 인코더-2 및 디코더(13 3)를 포함하여 구성된다. 인코더-1은 양면 orthographical 법선 맵으로부터 특징을 추출하고, 인코더-2는 양면 orthographical 컬러 영상으로부터 특징을 추출한다. 디코더는 인코더들(131,132)에 의해 추출된 특징들로 부터 양면 orthographical 깊이 맵을 생성한다. 예측 순서는 실험의 결과로부터 비롯되었다. 모델 복원 방법을 실험하는 과정에서 앞선 정보 예측없이 직접적으 로 예측하게 되면 디테일 복원이 어려우며, 법선 맵 예측이 선행되었을 때, 복원 효율이 높아진다는 것을 알게 되었다. 이에 따라, 도 3에 제시된 복원 모델이 구성되었으며, 직접적으로 orthographical 영상을 예측함으로써 볼륨 변환 및 메쉬 복원 과정에서 발생할 수 있는 문제점을 해결할 수 있었다. 마칭 큐브 알고리즘과 같은 3차원 모델 복원 기법을 이용하면, 입력되는 전면 perspective 컬러 영상과 3차원 인체 형상 복원 모델에 의해 예측된 양면 orthographical 깊이 맵으로부터 3차원 인체 형상을 복원할 수 있다. 도 4는 카메라를 통해 실제 촬영된 영상을 활용해서 3차원 인체 형상 모델을 복원한 결과를 보여준다. 모델 복 원 결과와 같이 헤어나 얼굴 형상 옷 주름과 같은 디테일들이 자연스럽게 복원된 것을 확인할 수 있다. 도 5는 기존 접근 방법에 의한 복원 결과와 본 발명의 실시예에서 제시한 방법에 의한 복원 결과의 차이점을 보 여 준다. 도 5에서 네 번째 열에 제시된 모델이 본 발명의 실시예에 따른 방법을 활용하여 복원된 3차원 인체 형상이다. 컬러까지 포함된 객체의 결과를 보면 옷의 음영과 전체적인 형상들이 자연스럽게 복원된 것을 확인할 수 있다. 또한 기존 방법들(PIFU, PIFuHD, PaMIR)과 비교해 봤을 때, 법선 영상을 확인해 보면 옷과 헤어 얼굴 등의 다양한 부분에서 복원 성능의 차이를 확인할 수 있다. 복원된 3차원 인체 모델은 패션, 게임, 운동, 의료 등의 다양한 분야에서 활용될 수 있는데 고정된 객체만으로 는 의미 있는 활용이 어렵다. 의상 피팅, 운동 코칭, 게임 아바타만을 생각해 보아도 객체 리깅을 통한 자연스 러운 움직임이 필요하다는 것을 알 수 있다. 이에 따라 본 발명의 실시예에서는 3차원 인체 모델의 애니메이팅을 위해 3차원 인체 형상에 대한 리깅 방법을 제시한다. 구체적으로 SMPL 모델 예측, 정렬 및 리깅을 수행한다. 도 6은 본 발명의 다른 실시예에 따른 3차원 인체 모델의 리깅 방법을 나타낸 도면이다. 3차원 인체 모델 리깅을 위해, 전술한 3차원 인체 형상 복원 모델을 통해 3차원 인체 모델을 Mesh로 복원한다. 다음 전면 perspective 컬러 영상과 양면 orthographical 깊이 맵을 이용하여, SMPL 모델을 예측한다. SMPL 모델 예측을 통해 SMPL parameters를 얻을 수 있으며 해당 parameters와 vertices 그리고 camera parameters를 최적화함으로써 복원 모델을 예측된 SMPL 모델에 맞게 피팅할 수 있다. Mesh alignment를 보면 SMPL 모델에 맞게 피팅된 복원 모델을 확인할 수 있다. 정렬된 복원 모델은 SMPL 파라미 터를 활용하여 복원되지 못한 손 영역을 재생성하고 T-pose로 변환함으로써 Mesh animating이 가능해진다. 도 7은 위와 같은 과정을 통해 3차원 복원 모델을 애니메이팅하여 모션을 추가한 복원 모델의 결과를 보여준다. 도 8은 본 발명의 따른 실시예에 따른 실사 아바타 생성 시스템의 구성을 도시한 도면이다. 본 발명의 실시예에 따른 실사 아바타 생성 시스템은 도시된 바와 같이, 데이터 DB, 3차원 인체 형상 복원부 및 복원 형상 리깅부를 포함하여 구성된다. 데이터 DB는 전면 perspective 컬러 영상을 제공하거나 학습 데이터셋을 제공하기 위한 구성이다. 3차원 인 체 형상 복원부는 전술한 도 3에 제시된 복원 모델을 이용하여 전면 perspective 컬러 영상으로부터 3차원 인체 형상을 복원한다. 복원 형상 리깅부는 전술한 도 6에 제시된 리깅 방법에 따라 3차원 인체 형상에 대 한 리깅과 애니메이팅을 수행한다. 지금까지 단일 영상 기반의 3차원 인체 형상 복원을 통한 실사 아바타 생성 방법 및 시스템에 대해 바람직한 실 시예를 들어 상세히 설명하였다. 본 발명의 실시예에서는 복원 모델의 성능을 향상시킬 수 있는 자체 데이터셋(연령, 체형, 의상의 다양성이 존 재)을 이용하되, 각 고품질의 데이터는 다양한 입력에 대한 강건함을 위해 조명의 색상, 세기 그리고 회전을 다 르게 적용하여 수평 방향으로 렌더링하여 사용하였다. 또한 볼륨 기반의 3차원 모델 복원에서 발생할 수 있는 perspective 복원의 문제점을 해결하기 위해 orthographic 깊이 맵 예측 기반으로 설계하였는데, orthographic 영상은 위치에 영향을 받지 않고 같은 거리로 픽셀들을 표현해주기 때문에 복원된 모델이 휘어지지 않고 정면을 응시할 수 있다. 나아가 복원된 3차원 모델만으로는 여러 분야에서 아바타로 활용하는 것에 한계를 갖고 있으며, 모델에 대한 관 절 포인트를 따로 예측하지 않았기 때문에 움직임을 주는 것이 어렵다는 점에 착안하여, SMPL 모델 파라미터를 활용하여 모델 피팅을 수행하고 파라미터들을 활용하여 리깅을 수행하는 방법을 제시하였다. 이를 통해, 단일 전면 영상을 통해 3차원 인체 모델을 복원하되, 고품질의 자체 데이터셋을 렌더링하여 활용하 기 때문에 복원 성능을 높일 수 있으며, 복원된 3차원 모델의 리깅을 통해 자연스러운 움직임까지 가능하게 함 으로써 여러 분야에서 활용도를 높일 수 있게 된다. 한편, 본 실시예에 따른 장치와 방법의 기능을 수행하게 하는 컴퓨터 프로그램을 수록한 컴퓨터로 읽을 수 있는 기록매체에도 본 발명의 기술적 사상이 적용될 수 있음은 물론이다. 또한, 본 발명의 다양한 실시예에 따른 기 술적 사상은 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터로 읽을 수 있는 코드 형태로 구현될 수도 있다. 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터에 의해 읽을 수 있고 데이터를 저장할 수 있는 어떤 데이터 저장 장 치이더라도 가능하다. 예를 들어, 컴퓨터로 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광디스크, 하드 디스크 드라이브, 등이 될 수 있음은 물론이다. 또한, 컴퓨터로 읽을 수 있는 기록매체 에 저장된 컴퓨터로 읽을 수 있는 코드 또는 프로그램은 컴퓨터간에 연결된 네트워크를 통해 전송될 수도 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2022-0110162", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0110162", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 모델 학습을 위해 사용된 3차원 데이터, 도 2는 배경 합성을 통해 생성된 입력 영상 도 3은 3차원 인체 형상 복원 모델의 구조, 도 4는 실제 영상을 이용한 3차원 모델 복원 결과, 도 5는 기존 3차원 복원 방법들과의 비교, 도 6은 본 발명의 다른 실시예에 따른 3차원 모델 리깅 방법, 도 7은 3차원 복원 모델의 애니메이팅 결과, 도 8은 본 발명의 따른 실시예에 따른 실사 아바타 생성 시스템의 구성을 도시한 도면이다."}
