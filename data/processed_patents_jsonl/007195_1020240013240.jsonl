{"patent_id": "10-2024-0013240", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0054678", "출원번호": "10-2024-0013240", "발명의 명칭": "강화 학습 접근법을 이용한 학습 방법 및 장치", "출원인": "한양대학교 에리카산학협력단", "발명자": "이민식"}}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "둘 이상의 훈련 데이터 그룹의 확률 변수에 따른 확률 분포에 기초하여 제 1 훈련 데이터 그룹을 결정하고, 상기 제 1 훈련 데이터 그룹에 포함된 적어도 하나의 훈련 데이터를 라벨링된 학습 데이터로 전환하는 전환부;상기 라벨링된 학습 데이터를 인공지능 모델에 입력하여 학습을 수행하는 학습부; 및학습 결과를 보상 함수에 입력하여 상기 학습의 성공 여부와 관련된 보상값을 산출하고, 상기 보상값을 상기 확률 변수에 적용하여 추가 학습을 수행할 제 2 훈련 데이터 그룹을 결정하는 결정부를 포함하는 능동 학습 장치."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 전환부는,전체 훈련 데이터를 사전에 정의된 모델을 통해 상기 훈련 데이터의 적합도와 관련된 구실 손실을 산출하고, 상기 전체 훈련 데이터를 상기 산출된 구실 손실에 기초하여 상기 2이상의 훈련 데이터 그룹으로 분류하는 것을특징으로 하는 능동 학습 장치."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 확률 분포는,상기 2이상의 훈련 데이터 그룹의 베타 분포인 것을 특징으로 하는 능동 학습 장치."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 제 1 훈련 데이터 그룹 및 상기 제 2 훈련 데이터 그룹에 대한 결정은 상기 2이상의 훈련 데이터 그룹 중상기 베타 분포의 결과가 가장 높은 그룹인 것을 특징으로 하는 능동 학습 장치."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 전환부는,상기 제 1 훈련 데이터 그룹에 포함된 훈련 데이터의 불확실성을 산출하고, 상기 불확실성이 큰 훈련 데이터 가운데 N개(N은 1이상의 정수)의 훈련 데이터에 라벨링을 수행하는 것을 특징으로 하는 능동 학습 장치."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 학습부는,학습이 완료된 인공지능 모델에 학습 과정의 타당성과 관련된 검증 데이터에 기초하여 손실값을 산출하는 것을특징으로 하는 능동 학습 장치."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 결정부는,공개특허 10-2025-0054678-3-상기 손실값을 성공 또는 실패를 판별하는 베르누이 시행을 통해 상기 보상값을 출력하는 것을 특징으로 하는능동 학습 장치."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "둘 이상의 훈련 데이터 그룹의 확률 변수에 따른 확률 분포에 기초하여 제 1 훈련 데이터 그룹을 결정하고, 상기 제 1 훈련 데이터 그룹에 포함된 적어도 하나의 훈련 데이터를 라벨링된 학습 데이터로 전환하는 전환단계;상기 라벨링된 학습 데이터를 인공지능 모델에 입력하여 학습을 수행하는 학습단계; 및학습 결과를 보상 함수에 입력하여 상기 학습의 성공 여부와 관련된 보상값을 산출하고, 상기 보상값을 상기 확률 변수에 적용하여 추가 학습을 수행할 제 2 훈련 데이터 그룹을 결정하는 결정단계를 포함하는 능동 학습 방법."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 전환단계는,전체 훈련 데이터를 사전에 정의된 모델을 통해 상기 훈련 데이터의 적합도와 관련된 구실 손실을 산출하고, 상기 전체 훈련 데이터를 상기 산출된 구실 손실에 기초하여 상기 2이상의 훈련 데이터 그룹으로 분류하는 것을특징으로 하는 능동 학습 방법."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8 항에 있어서,상기 확률 분포는,상기 2이상의 훈련 데이터 그룹의 베타 분포인 것을 특징으로 하는 능동 학습 방법."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제 1 훈련 데이터 그룹 및 상기 제 2 훈련 데이터 그룹에 대한 결정은 상기 2이상의 훈련 데이터 그룹 중상기 베타 분포의 결과가 가장 높은 그룹인 것을 특징으로 하는 능동 학습 방법."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8 항에 있어서,상기 전환단계는,상기 제 1 훈련 데이터 그룹에 포함된 훈련 데이터의 불확실성을 산출하고, 상기 불확실성이 큰 훈련 데이터 가운데 N개(N은 1이상의 정수)의 훈련 데이터에 라벨링을 수행하는 것을 특징으로 하는 능동 학습 방법."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 8 항에 있어서,상기 학습단계는,학습이 완료된 인공지능 모델에 학습 과정의 타당성과 관련된 검증 데이터에 기초하여 손실값을 산출하는 것을특징으로 하는 능동 학습 방법."}
{"patent_id": "10-2024-0013240", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 결정단계는,상기 손실값을 성공 또는 실패를 판별하는 베르누이 시행을 통해 상기 보상값을 출력하는 것을 특징으로 하는공개특허 10-2025-0054678-4-능동 학습 방법."}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 실시예들에 의하면, 둘 이상의 훈련 데이터 그룹의 확률 변수에 따른 확률 분포에 기초하여 제 1 훈련 데이터 그룹을 결정하고, 상기 제 1 훈련 데이터 그룹에 포함된 적어도 하나의 훈련 데이터를 라벨링된 학습 데이터로 전환하고, 상기 라벨링된 학습 데이터를 인공지능 모델에 입력하여 학습을 수행하고, 학습 결과를 보상 함수에 입력하여 상기 학습의 성공 여부와 관련된 보상값을 산출하고, 상기 보상값을 상기 확률 변수에 적용하여 추가 학습을 수행할 제 2 훈련 데이터 그룹을 결정하는 것을 포함하는 능동 학습 방법 및 장치를 제공할 수 있다."}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 실시예들은 강화 학습 접근법을 이용한 능동 학습을 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능은 인간의 지능과 유사학 방식으로 반복적으로 학습을 수행하고, 학습 결과에 기초하여 판단을 수행하 는 분야이다. 인공지능은 머신러닝 및 딥러닝을 포함하는 광의의 개념으로, 머신러닝은 딥러닝을 포함하는 광의 의 개념으로 사용된다. 머신러닝은 특정 규칙과 논리에 따라 방대한 데이터를 분석한 뒤 이를 기반하여 예측치 를 제공하는 방식을, 딥러닝은 머신러닝의 일종으로 기계가 스스로 데이터를 분석/학습하고 특징을 추출하여 학 습/예측을 수행하는 개념을 가정한다. 즉, 머신러닝 중 기계가 스스로 특징을 추출하는 방식을 딥러닝으로 볼 수 있다. 딥러닝은 이미지 분류, 시맨틱 분할, 물체 감지, 포즈 추정 등 많은 컴퓨터 비전 작업에서 상당한 발전을 이뤘 다. 딥러닝의 부상과 더불어 이러한 발전을 가능하게 한 것은 ImageNet 및 MS-COCO(Microsoft Common Objects in Context) 와 같은 대규모 라벨링 된 데이터 세트의 존재 때문이었다. 일반적으로 라벨링된 데이터의 양이 많아질수록, 딥러닝 모델의 성능은 향상될 수 있다. 그러나 대량의 데이터 에 주석을 다는 것은 상당한 시간과 비용이 요구되는 문제가 있다."}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시예들은 강화 학습 접근법을 이용한 능동 학습을 위한 방법 및 장치를 제공할 수 있다."}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에서, 둘 이상의 훈련 데이터 그룹의 확률 변수에 따른 확률 분포에 기초하여 제 1 훈련 데이터 그룹을 결정하고, 제 1 훈련 데이터 그룹에 포함된 적어도 하나의 훈련 데이터를 라벨링된 학습 데이터로 전환하는 전 환부와 라벨링된 학습 데이터를 인공지능 모델에 입력하여 학습을 수행하는 학습부와 학습 결과를 보상 함수에 입력하여 상기 학습의 성공 여부와 관련된 보상값을 산출하고, 상기 보상값을 상기 확률 변수에 적용하여 추가 학습을 수행할 제 2 훈련 데이터 그룹을 결정하는 결정부를 포함하는 능동 학습 장치를 제공할 수 있다. 다른 측면에서, 둘 이상의 훈련 데이터 그룹의 확률 변수에 따른 확률 분포에 기초하여 제 1 훈련 데이터 그룹 을 결정하고, 제 1 훈련 데이터 그룹에 포함된 적어도 하나의 훈련 데이터를 라벨링된 학습 데이터로 전환하는 전환단계와 라벨링된 학습 데이터를 인공지능 모델에 입력하여 학습을 수행하는 학습단계와 학습 결과를 보상 함수에 입력하여 상기 학습의 성공 여부와 관련된 보상값을 산출하고, 상기 보상값을 상기 확률 변수에 적용하 여 추가 학습을 수행할 제 2 훈련 데이터 그룹을 결정하는 결정단계를 포함하는 능동 학습 방법을 제공할 수 있 다."}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 실시예들에 의하면, 강화 학습 접근법을 이용한 능동 학습을 위한 방법 및 장치를 제공할 수 있다."}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 참조하여 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가질 수 있다. 또한, 본 실시예들을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명 이 본 기술 사상의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략할 수 있다. 본 명세서 상 에서 언급된 \"포함한다\", \"갖는다\", \"이루어진다\" 등이 사용되는 경우 \"~만\"이 사용되지 않는 이상 다른 부분이 추가될 수 있다. 구성 요소를 단수로 표현한 경우에 특별한 명시적인 기재 사항이 없는 한 복수를 포함하는 경 우를 포함할 수 있다. 또한, 본 개시의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질, 차례, 순서 또는 개수 등이 한정되지 않는다. 구성 요소들의 위치 관계에 대한 설명에 있어서, 둘 이상의 구성 요소가 \"연결\", \"결합\" 또는 \"접속\" 등이 된다 고 기재된 경우, 둘 이상의 구성 요소가 직접적으로 \"연결\", \"결합\" 또는 \"접속\" 될 수 있지만, 둘 이상의 구성 요소와 다른 구성 요소가 더 \"개재\"되어 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 여 기서, 다른 구성 요소는 서로 \"연결\", \"결합\" 또는 \"접속\" 되는 둘 이상의 구성 요소 중 하나 이상에 포함될 수 도 있다. 구성 요소들이나, 동작 방법이나 제작 방법 등과 관련한 시간적 흐름 관계에 대한 설명에 있어서, 예를 들어, \"~후에\", \"~에 이어서\", \"~다음에\", \"~전에\" 등으로 시간적 선후 관계 또는 흐름적 선후 관계가 설명되는 경우, \"바로\" 또는 \"직접\"이 사용되지 않는 이상 연속적이지 않은 경우도 포함할 수 있다. 한편, 구성 요소에 대한 수치 또는 그 대응 정보(예: 레벨 등)가 언급된 경우, 별도의 명시적 기재가 없더라도, 수치 또는 그 대응 정보는 각종 요인(예: 공정상의 요인, 내부 또는 외부 충격, 노이즈 등)에 의해 발생할 수 있는 오차 범위를 포함하는 것으로 해석될 수 있다. 도 1은 본 실시예에 따라 강화 학습을 적용한 능동 학습 장치의 구성에 대한 도면이다. 도 1을 참조하면, 능동 학습 장치는 둘 이상의 훈련 데이터 그룹의 확률 변수에 따른 확률 분포에 기초하 여 제 1 훈련 데이터 그룹을 결정하고, 상기 제 1 훈련 데이터 그룹에 포함된 적어도 하나의 훈련 데이터를 라 벨링된 학습 데이터로 전환하는 전환부를 포함할 수 있다. 본 개시의 능동 학습 장치는 인공 지능 모델의 성능 향상을 위해서 데이터를 일괄로 학습하는 것이 아니라, 설정된 기준에 따라 훈련 데이터 그룹으로 나누어 분류하고, 훈련 데이터 내의 일부 데이터를 다시 라 벨링된 데이터로 추출하여, 해당 데이터에 기초하여 학습을 수행할 수 있다. 상술한대로 일반적으로 라벨링된 데이터의 양이 많아질수록, 딥러닝 모델의 성능은 향상될 수 있지만 대량의 데 이터에 주석을 다는 것은 상당한 시간과 상당한 시간과 비용이 요구되는 문제가 있다. 이를 해결하는 방안으로 선택적으로 데이터에 주석을 달아서 사용하는 능동 학습이 있다. 다만 주석을 달 데이터를 선택함에 있어서 효 율적이지 못하다는 문제가 있고, 이에 대한 방안으로 본 개시는 강화 학습을 통한 능동 학습을 제안한다. 강화 학습은 에이전트가 보상을 극대화하기 위해 특정 환경에서 취할 수 있는 최적의 행동을 선택하는 방법을 학습하는 방식이다. 일 예로, 전환부는 전체 훈련 데이터를 사전에 정의된 모델을 통해 상기 훈련 데이터의 적합도와 관련된 구실 손실을 산출하고, 상기 전체 훈련 데이터를 상기 산출된 구실 손실에 기초하여 상기 2이상의 훈련 데이터 그룹으로 분류할 수 있다. 전환부는 학습 대상이 되는 각 데이터에 대해 구실 손실을 산출하고, 산출된 구실 손실에 기초하여 전체 데이터를 내림차순으로 정렬한다. 전환부는 구실 손실이 큰 데이터를 기준으로 설정된 개수만큼 그룹을 지 어 분류할 수 있다. 구실 손실은 훈련 데이터로서의 적합도를 의미할 수 있다. 구실 손실의 산출은 미리 설정된 인공지능 모델에 각 훈련 데이터를 입력하여 출력된 값을 구실 손실로 보고, 구실 손실이 클수록 훈련 데이터로 적합도가 떨어진다 고 할 수 있다. 다른 예로, 전환부는 제 1 훈련 데이터 그룹을 결정하는데 사용되는 확률 분포로 상기 2이상의 훈련 데이 터 그룹의 베타 분포를 사용할 수 있다. 전환부는 분류된 각 그룹에 대한 베타 분포를 사용하여 Q값을 출력 할 수 있다. 또 다른 예로, 전환부는 있어서 2이상의 훈련 데이터 그룹 중 베타 분포의 결과가 가장 높은 그룹을 제 1 훈련 데이터 그룹으로 결정할 수 있다. 베타 분포는 어떤 시행이 있는 경우에 성공이 α번이고, 실패가 β번 관측된 사건에 대해서 이 시행의 성공 확 률을 모델링한 분포라고 할 수도 있다. 전환부는 각 훈련 데이터 그룹의 성공 또는 실패를 확률 변수로 하여 베타 분포의 결과값을 산출하고, 그 산출값이 가장 높은 그룹을 제 1 훈련 데이터 그룹으로 결정할 수 있다. 본 개시에서는 베타 분포를 통해 산출 되는 값을 Q값 또는 Q value라고 호칭 할 수 있다. 또 다른 예로, 전환부는 제 1 훈련 데이터 그룹에 포함된 훈련 데이터의 불확실성을 산출하고, 불확실성이 큰 훈련 데이터 가운데 N개(N은 1이상의 정수)의 훈련 데이터에 라벨링을 수행할 수 있다. 능동 학습 장치는 라벨링된 학습 데이터를 인공지능 모델에 입력하여 학습을 수행하는 학습부를 포함 할 수 있다. 일 예로, 학습부는 학습이 완료된 인공지능 모델에 학습 과정의 타당성과 관련된 검증 데이터에 기초하여 손실값을 산출할 수 있다. 학습 데이터는 인공지능 모델의 성능을 높이기 위해 사용되는 데이터라면, 검증 데이터는 학습이 완료된 인공지 능 모델의 학습 과정의 타당성을 확인하기 위해 사용되는 데이터이다. 학습 데이터 집합에는 유효한 데이터와 유효하지 않은 데이터가 함께 포함될 수 있으나, 검증 데이터는 유효한 데이터로 구성된다. 훈련 데이터에는 학 습 데이터, 검증 데이터 또는 테스트 데이터도 포함할 수 있다. 능동 학습 장치는 학습 결과를 보상 함수에 입력하여 상기 학습의 성공 여부와 관련된 보상값을 산출하고, 상기 보상값을 상기 확률 변수에 적용하여 추가 학습을 수행할 제 2 훈련 데이터 그룹을 결정하는 결정부 를 포함할 수 있다. 다른 예로, 결정부는 산출한 손실값을 이용하여 성공 또는 실패를 판별하는 베르누이 시행을 통해 상기 보 상값을 출력할 수 있다. 본 개시는 훈련 데이터 중 일부 데이터에 주석을 붙이는 라벨링 과정을 수행함에 있어서, 둘 이상의 훈련 데이 터 그룹을 순차적으로 선택하여 능동 학습을 수행하는 종래 방식과 달리, 능동 학습에 강화 학습을 적용하여, 보상함수를 통해 출력된 보상값을 베르누이 시행을 적용하여 산출된 결과값을 각 훈련 데이터 그룹에 적용하여 추가 학습을 수행할 다음 훈련 데이터 그룹을 선택하는 방안을 제안한다. 종래의 훈련 데이터 그룹을 순차적으로 선택하는 방식은 매 사이클마다 선택되는 훈련 데이터 그룹이 최적의 선 택이 아닐 수 있고, 순차적으로 선택되기 때문에 한번 선택된 훈련 데이터 그룹은 다시 선택되기 어렵다는 단점 이 있다. 이에 반해 본 개시의 강화 학습을 적용한 능동 학습 방식은 매 사이클마다 최적의 훈련 데이터 그룹을 선택할 수 있고, 한번 선택된 훈련 데이터 그룹이 가치있다고 판단되면 다시 선택할 수 있는 장점이 있다. 도 2 이하에서는 강화 학습을 적용한 능동 학습의 전체적인 과정을 구체적으로 살펴본다. 도 2는 본 실시예에 따라 능동 학습 알고리즘의 전체적인 과정에 대한 도면이다. 본 개시는 강화학습 접근법 중 하나인 discounted Thompson sampling(DTS)을 사용하여, 보상에 따라 훈련 데이 터 그룹을 선택하는 방법을 이용할 수 있다. Discounted Thompson Sampling은 MAB(Multi Arm Bandit)를 적용하는 알고리즘의 한 종류로서, MAB는 승률이 다 른 슬롯머신에서 최대의 수익을 낼 수 있는 슬롯머신을 선택하는 방법을 찾는 것에서 유래되었다. MAB가 적용되는 알고리즘에는 Greedy 알고리즘, UDB(Upper Confidence Bound) 알고리즘, DTS 알고리즘이 있고, DTS 알고리즘은 과거의 성과에 기반하여 현재 시행에 대한 성공 확률을 예측하는 모델이라고 할 수 있다. 특히 DTS 알고리즘은 성공에 대한 보상값을 확률 변수로 설정하고, 대상을 무작위로 선택하여 수행하는 반복 실험을 통해 보상값에 대한 기대값이 가장 높은 슬롯머신을 선택한다. 구체적으로 도 2를 참조하면, 능동 학습 장치는 주석이 달리지 않은 훈련 데이터들에 대해 구실 손실을 산 출하고, 산출된 구실 손실에 기초하여 훈련 데이터들을 정렬한다. 그리고 능동 학습 장치는 정렬된 훈련 데이터를 유사한 구실 손실을 가지는 훈련 데이터를 포함하는 그룹으로 분류한다. 일 예로, 능동 학습 장치는 유사한 구실 손실을 가지는 훈련 데이터를 포함하는 그룹을 각각 G1 그룹에서 Gn 그룹까지 분류할 수 있다. 능동 학습 장치는 각 그룹의 실험을 통한 성공 또는 실패 횟수를 산출하여 베타 분 포로 나타내고, 베타 분포에 대한 결과값을 산출할 수 있다. 본 개시에서는 베터 분포에 대한 결과 값을 Q 값이 라고 호칭할 수 있다. 능동 학습 장치는 각 그룹에 대해서 Q값이 가장 높은 데이터 그룹(Gi)을 선택할 수 있다. 본 개시의 능동 학습 장치는 선택한 Q값이 가장 높은 데이터 그룹 내에 각 데이터의 불확실성을 산출한다. 불확 실성은 선택된 그룹 내 데이터의 신뢰도에 대한 수치를 의미한다. 따라서 불확실성이 높으면 데이터에 대한 신 뢰도가 낮다는 것을 의미하고, 불확실성이 낮다는 것은 데이터에 대한 신뢰도가 높다는 것을 의미한다. 불확실 성이 산출되면 불확실성이 높은 데이터들을 뽑아 주석을 달고, 이들을 학습 데이터로 결정할 수 있다. 본 개시에 따라, 능동 학습 장치는 학습 데이터를 인공지능 모델에 입력하여 학습을 수행할 수 있다. 인공 지능 모델은 뉴럴 네트워크를 포함할 수 있다. 능동 학습 장치는 Q값이 가장 높은 데이터 그룹에서 선택된 학습 데이터를 통해 학습이 완료되면 검증 데이터에 기초하여 학습 과정에 대한 검증을 수행할 수 있다. 일 예로, 검증이 완료되면 능동 학습 장치는 검증에 대한 결과 값을 보상 함수에 입력하여 보상값을 산출할 수 있다. 보상값은 보상 값은 검증 데이터에 대한 현재 능동학습 단계와 이전 능동학습 단계의 평균 손실 차이에 기초하여 산출될 수 있다. 능동 학습 장치는 보상값이 산출되면 보상값에 대하여 베르누이 시행(Bernoulli trial)을 수행함으로써, 결과값을 도출한다. 능동 학습 장치는 결과값을 도출하면 각 훈련 데이터 그룹의 확률 변수에 반영한다. 확률 변수는 각 그룹이 수행한 실험의 성공 또는 실패를 나타내는 변수를 의미한다. 이러한 과정은 1회에 한하는 것이 아니고, 새로운 그룹을 선택하여, 반복적으로 수행될 수 있다. 과정에서 단계가 진행될수록 선택된 특정 훈련 데이터 그룹에서 라벨링된 데이터를 선택되고, 학습 데이터 또는 검증 데이터로 전환됨에 따라 데이터의 손실 문제가 발생될 수 있다. 이러한 손실 문제를 해결하기 위해 선택되 지 않은 그룹들의 확률 변수는 일정 비율로 감소될 수 있다. 불확실성 산출을 통해 라벨링하는 과정을 수식을 통해 좀더 구체적으로 살펴보면, 일 예로, 구실 손실 산출을 통해 훈련 데이터 그룹을 분류하고 나면, 반복적으로 훈련 데이터 그룹 내에 속한 데이터에 대해 라벨링을 수행하는 작업이 실행된다. 예를 들어, i번째 능동 학습 과정에서 그룹 Gi가 선택될 수 있다. 그룹 Gi가 선택되면, 그룹에 포함된 각 훈련 데이터에 대한 불확실성을 산출한다. 상술한대로 불확실성은 그룹 내에 포함된 각 훈련 데이터의 신뢰도에 대한 것으로서, 신뢰도가 낮은 훈련 데이터는 불확실성이 높고, 신뢰도가 높은 훈련 데이터는 불확실성이 낮다고 볼 수 있다. 수학식 1은 불확실성과 관련된 신뢰도를 산출 수식이다. 수학식 1"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "은 t-1 시점에서의 인공지능 모델의 가중치(weight)이다. X는 하나의 샘플로서 이미지 데이터를 의미하고, 는 샘플이 예측된 class probability 중 제일 큰 max값(제일 확신하는 class의 probability값, confidence score)을 의미할 수 있다. 각 사이클에서 이전 사이클의 유지 과제 학습자를 의미하는 을 사용하여 라벨이 지정되지 않은 각 Gi내 훈련 데이터에 대한 신뢰도를 산출한다. 신뢰도 산출을 통해 불확실 성이 높은 상위 K개의 데이터가 선택된다. 따라서 선택된 불확실성이 높은 상위 K개의 데이터에 라벨링이 수행 될 수 있다. 본 개시는, 종래에 사용되던 구실 손실을 이용해 데이터의 그룹을 나누어 각 능동 학습 단계마다 다른 그룹을 순차적으로 선택하는 방법을 사용하지 않고, 강화학습을 도입하여 자기지도 학습 결과에 의존하지 않고 좀 더 복합적으로 결과를 해석하여 사용하는 방식의 알고리즘을 제안한다. 도 3은 본 실시예에 따라 훈련 데이터의 일부를 라벨링하는 과정을 설명하기 위한 순서도이다. 본 개시는 전체 훈련 데이터에 대한 구실 손실을 산출하고(S300), 산출된 구실 손실에 기초하여 데이터를 정렬 하고(S310), 정렬된 데이터를 일정 개수에 따라 나누어 그룹으로 분류하고(S320), 각 그룹에 베타 분포 결과값 을 산출하고(S330), 베타 분포 결과값이 가장 높은 그룹 내 데이터 중 일부를 추출하여 라벨링을 수행한다 (S340). 구체적으로, 본 개시의 능동 학습 장치는 전체 훈련 데이터에 대한 구실 손실을 산출한다(S300). 구실 손실은 각 훈련 데이터가 훈련 데이터로서의 적합도를 수치화한 것이라고 할 수 있다. 구실 손실은 미리 설정된 모델에 각 훈련 데이터를 입력하여 출력된 결과에 기초하여 산출될 수 있다. 구실 손실이 높다는 것은 훈련 데이터로서 의 적합도가 떨어진다는 것을 의미할 수 있다. 다만, 구실 손실은 미리 설정된 모델을 통하는 것에 한하지 않고, 필요에 따라 다양한 방식으로 산출될 수 있다. 일 예로, 본 개시는 구실 손실 산출에 사용되는 모델을 라고 할 수 있고, 구실 작업 학습자라고 호칭할 수 있다. 는 샘플 데이터에 기초하여 학습이 사전에 수행된 인공지능 모델일 수 있다. 샘플 데이터는 0 °, 90°, 270°, 360°중 하나의 방향으로 회전된 이미지 데이터일 수 있다. 본 개시는 0°, 90°, 270°, 360 °는 방향 레이블이라고 호칭할 수도 있다. 구실 작업 학습자의 학습은 회전된 이미지가 정상 방향을 향하고 있 는지를 맞추는 과정일 수 있고, 이를 Po = Ωp(x)로 표현할 수 있다. Po는 샘플 이미지의 회전 각도가 0°인 회 전되지 않은 이미지일 확률을 의미할 수 있다. 구실 과제 학습자의 학습이 완료되면, 구실 과제 학습자를 활용 하여 라벨이 지정되지 않은 모든 훈련 샘플 xi에 대한 구실 손실을 산출한다. 수학식 2는 구실 손실을 산출하는 수식을 표현한다. 수학식 2"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 LCE는 교차 엔트로피 손실을 나타내며, 회전 연산자 g(-|o)는 방향 레이블 o를 기준으로 입력 이미지를 회전한 것을 의미한다. no는 이미지 샘플의 회전 각도의 개수를 의미한다. 네 개의 각도(0°, 90°, 270°, 360 °)로 회전이 가능하면 no는 4로 설정될 수 있다. θs는 모델 가중치를 의미한다. 구실 손실이 산출되면, 능동 학습 장치는 구실 손실에 기초하여 각 훈련 데이터를 내림차순으로 정렬한다 (S310). 능동 학습 장치는 정렬된 데이터를 N개의 그룹으로 나누어 각 그룹에 유사한 구실 손실을 가진 데이터 가 포함되도록 분류한다. N은 1이상의 정수이다. 그리고 N은 능동 학습이 수행되는 횟수를 의미할 수도 있다. 예를 들어, 능동 학습이 10회 동안 수행되는 경우 훈련 데이터는 10개의 그룹으로 분류될 수 있다. 구실 손실에 따른 내림차순 정렬은 훈련 데이터로서의 적합도가 유사한 데이터끼리 능동 학습을 수행함으로써, 인공지능 모 델의 성능을 향상시키기 위함이다. 전체 훈련 데이터가 정렬되면 능동 학습 장치는 전체 훈련 데이터를 그룹으로 분류한다(S320). 능동 학습 장치 는 구실 손실의 수치의 차이가 크지 않은 훈련 데이터의 각 그룹은 반복적인 강화 학습을 통해서 라벨링할 훈련 데이터를 결정하고, 결정한 학습 데이터를 반복 학습함으로써, 인공지능 모델의 성능을 향상시킬 수 있다. 그룹 별 훈련 데이터의 개수는 정해져 있지 않고, 필요한 데이터 그룹의 수에 기초하여 결정될 수 있다. 전체 훈련 데이터가 각 그룹으로 분류되면 능동 학습 장치는 각 그룹에 대한 확률 분포 결과값을 산출할 수 있 다(S330). 본 개시는 확률 분포 결과값을 베타 분포를 통해 산출할 것을 제안한다. 상술한대로 베타 분포는 성 공과 실패에 대한 확률 변수를 각각 Si, Fi로 두고 이에 대한 성공 확률을 모델링한 분포이다. 본 개시는 각 그 룹의 베타 분포를 통한 출력값을 Q값이라고 호칭할 수 있다. 능동 학습 장치는 Q값이 가장 큰 그룹을 라벨링할 데이터를 추출할 그룹으로 선택할 수 있다. 일 예로, 각 그룹을 Gi라고 하고, 각 그룹에 대한 성공을 Si와 실패를 Fi라고 할 수 있다. 최초에는 Si와 Fi는 0 으로 초기화될 수 있다. 수학식 3은 베타 분포의 결과값인 Q값을 산출하는 수식을 표현한다. 수학식 3"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "T는 능동 학습이 수행되는 횟수를 의미하고, i는 훈련 데이터 그룹의 인덱스로 정의될 수 있다. 능동 학습 장치 는 각 그룹에 대한 Q값을 산출한 후 가장 높은 Q값을 가진 그룹을 선택할 수 있다, Q값이 가장 큰 그룹이 선택되면, 능동 학습 장치는 라벨링할 훈련 데이터를 결정하기 위해 그룹 내 데이터의 불 확실성을 산출할 수 있다(S340). 각 데이터에 대한 불확실성이 산출되면, 능동 학습 장치는 불확실성이 높은 데이터에 대해서 설정된 개수만큼 라벨링을 수행할 수 있다. 본 개시는 라벨링의 수행과 주석을 붙이는 것에 대해 같은 의미로 사용될 수 있다. 라벨링된 훈련 데이터는 인공지능 모델의 성능 향상을 위한 학습 데이터로 활용될 수 있다. 다만, 학습 데이터 로 활용되는 것에 한하지 않고, 필요에 따라 라벨링된 훈련 데이터는 검증 데이터로 분류되어 활용될 수도 있다. 이러한 과정은 반복적으로 시행될 수 있고 본 개시는 이러한 반복 과정을 사이클이라 호칭할 수 있다. 수행되는 능동 학습의 사이클은 제한된 예산이 소진될 때까지 반복될 수 있다. 본 개시는 상술한 과정 중 데이터 그룹을 선택하고, 선택된 그룹의 데이터 중 일부를 라벨링하는 과정을 반복 수행함으로써, 상대적으로 적은 개수의 데이터를 라벨링하면서도 인공지능 모델의 성능을 향상시키기 위한 방안 으로서, 강화 학습을 통한 능동 학습 방법을 제안한다. 반복 수행되는 사이클의 횟수 결정과 관련하여, 능동 학습 장치는 총 학습량을 설정할 수 있다. 라벨링된 데이 터의 개수가 동일하더라도 사이클의 횟수가 많아지거나, 라벨링된 데이터의 개수가 적어지도록 데이터를 추출하 면 인공지능 모델의 성능이 떨어지는 문제가 발생될 수 있다. 따라서, 학습량은 사이클의 총 횟수와 1 사이클당 라벨링된 데이터의 포인트 수의 곱으로 정의될 수 있다. 여기에는 전체 훈련 데이터의 크기가 동일하거나, 배치 크기가 고정되어 있음을 가정한다. 또한, 반복 수행되는 사이클의 횟수 결정과 관련하여 사이클의 횟수를 크게 설정하면 데이터의 무결성을 검사하 는데 많은 계산 비용이 요구될 수 있다. 이를 위해 훈련 데이터 집합 내의 데이터들을 내림차순으로 정렬하고, 일정한 간격으로 데이터들을 선택하여 샘플 수를 줄일 수 있다. 예를 들어, 하나의 훈련 데이터 집합내의 하위 집합내에서 데이터를 선택할 수 있다. 불확실성은 주 작업 학습자를 사용하여 하위 집합의 데이터에 대해서만 계산될 수 있도록 한다. 이 방식은 그룹의 전체 데이터를 평가하는 것과 비교하여 계산 비용을 크게 줄일 수 있 다. 또한 이 접근 방식은 무작위로 샘플링할 때와 비교하여 성능이 크게 향상될 수 있다. 훈련 데이터 집합에서 데이터를 선택하는 간격은 현재 사이클에서 하위 집합에 속한 데이터의 개수가 필요한 샘플 수 보다 작아지는 경우를 제외하고는 10으로 설정될 수 있다. 다만 이는 하나의 예시로서 이에 한하지 않고 필요에 따라 간격은 다양하게 설정될 수 있다. 이전에 방문한 그룹을 다시 방문해야 하는 경우 그룹에 남아있는 데이터를 고려하고위에서 설명한 대로 간격별 샘플링을 수행할 수 있다. 도 4에서는 강화 학습을 통해 보상값을 산출하고, 보상값에 기초하여 추가적인 훈련 데이터 그룹을 선택하는 과 정을 구체적으로 설명한다. 도 4는 본 실시예에 따라 강화 학습을 통해 추가적인 훈련 데이터 그룹을 결정하는 과정을 설명하기 위한 순서 도이다. 도 4를 참조하면, 능동 학습 장치는 학습이 수행되고 나면 학습 결과를 보상함수에 입력하고(S400), 베르누이 시행을 통해 보상값을 산출하고(S410), 산출된 보상값에 기초하여 다음 학습이 수행될 훈련 데이터 그룹을 결정 한다(S420). 구체적으로, 능동 학습 장치는 훈련 데이터 중 일부에 대한 라벨링 작업이 수행되면, 능동 학습 장치는 라벨링 된 데이터를 학습 데이터 그룹에 추가하고, 라벨링된 데이터가 추가된 학습 데이터 그룹을 인공지능 모델에 입 력하여 학습을 수행한다. 인공지능 모델을 통한 학습이 완료되면 능동 학습 장치는 검증 데이터에 기초하여 학 습과정의 적합성을 판단하고, 출력되는 결과를 보상 함수에 입력한다(S400). 일 예로, 검증 데이터는 훈련 데이터에서 일정 비율로 선택된 라벨링된 데이터일 수 있고, 불확실성이 큰 순서 로 결정된 라벨링된 훈련 데이터 중에서 분류될 수도 있다. Discounted Thompson sampling(DTS)의 보상 함수에 관한 능동 학습이 시작되기 전, 능동 학습 장치는 라벨링되지 않은 전체 데이터에서 구실 손실에 대해 내림차순 으로 일정한 간격으로 샘플을 선택해 라벨을 붙일 수 있다. 수학식 4는 샘플에서 라벨링된 검증 데이터를 결정 하는 것을 표현하는 수식이다. 수학식 4"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "는 전체 능동 학습 예산의 일정 비율에 해당하는 V%에 해당하며 본 개시에서 검증 데이터로 사용될 수 있다. 는 모델 훈련에서 제외되지만 보상을 계산하고 다음 AL 사이클에서 사용할 최적의 모델 가중치를 선 택하는 데 사용될 수 있다. 라벨링된 검증 데이터에 대한 주 작업 학습자 의 평균 손실을 이라 하고, 이전 스텝 t-1과 현재 스텝 t 사이의 주 작업 학습자 의 손실 의 차이는 로 정의될 수 있다. 수학식 5는 보상값 을 산출하는 보상 함수를 표현하는 식이다. 수학식 5"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "Dt를 보상 함수로 직접 사용하면 단계가 진행될수록 보상의 규모가 감소하여 처음에는 성공만 있고 나중에는 실 패만 있는 상황이 발생하는 문제가 발생될 수 있다. 이 문제를 완화하기 위해 보상값 산출에 아래 수식이 함께 적용될 수도 있다. 수학식 6은 수학식 5의 보상함수를 보완하기 위한 수식이다.수학식 6"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 α는 각 변수의 단위가 다른 경우에 연산을 수행하기 위해 설정되는 하이퍼 파라미터이고 E1은 0으로 초 기화될 수 있다. 산출된 Et 및 Dt에 기초하여 보상값 는 로 설정될 수 있다. 이는 손실 차 이의 비율을 나타낸다. 이전에 비해 손실이 얼마나 감소했는지를 나타낸다. 분모에 지수 평균을 사용하여 계산 을 안정화할 수 있다. 비율이 높을수록 현재 주기 동안 손실이 크게 감소했음을 의미한다. 하지만 Et를 직접 사용하면 훈련 초기에는 Et의 가치가 매우 작아 보상이 적절하게 반영되지 않을 수 있다. 이 문제를 해결하기 위해 본 개시는 수정된 Et에 대한 산출식을 사용할 것을 제안한다. 수학식 7은 수정된 Et인 에 대한 산출식이다. 수학식 7"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "따라서 보상값은 수학식 8을 통해 산출될 수 있다. 수학식 8"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "또 다른 예로, 능동 학습 장치는 rt를 베르누이 시험의 확률로 사용해야 하기 때문에 Discounted Thompson sampling내에서 rt를 0과 1사이의 실수 범위로 설정한다. 수학식 9는 상술한 모든 조건이 고려된 최종 공식이다. 수학식 9는 ≥ 0일 때 아래 식처럼 표현될 수 있다. 수학식 9"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "a는 보상 함수의 전체 입력 스케일을 조정하는 데 사용되는 하이퍼파라미터이고, b는 rt의 임계값을 설정하는 데 사용되는 하이퍼파라미터이다. 예외적으로 가 0보다 작게 산출되는 경우에는 보상값은 상수로 처리된다. 예를 들어 가 0보다 작은 경우에 보상값 rt는 1로 설정될 수 있다. 다만 이는 하나의 예시일 뿐, 필요에 따라 예외로 처리되는 보상값은 다양하게 설정될 수 있다.보상값이 산출되면 다음 학습이 수행될 훈련 데이터 그룹을 결정한다(S420). 일 예로, 능동 학습 장치는 보상값이 산출되면 베르누이 시행을 통해 결과값을 도출한다. 시행이 성공하면 1이 되고, 실패하면 0으로 출력될 수 있다. 출력된 결과값은 선택된 훈련 데이터 그룹의 확률 변수로서 성공(Si)과 실패(Fi)가 각각 업데이트된다. 수학식 10 및 11은 선택된 그룹의 확률 변수를 업데이트 하는 수식을 표현한다. 수학식 10"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "수학식 11"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "선택되지 않은 그룹의 값도 업데이트 된다. 수학식 12 및 13은 선택되지 않은 그룹의 확률 변수를 업데이트 하는 수식을 표현한다. 수학식 12"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "수학식 13"}
{"patent_id": "10-2024-0013240", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "매개변수 는 할인 계수다. S와 F의 값이 업데이트된 후, 능동 학습 장치는 베타 분포에 기초하여 다음 라벨 링된 데이터를 도출하기 위한 훈련 데이터 그룹을 결정한다. 이 과정은 능동 학습 예산이 소진될 때까지 반복적 으로 계속될 수 있다. 도 5는 본 실시예에 따라 강화 학습을 적용한 능동 학습 방법을 설명하기 위한 순서도이다. 도 5를 참조하면, 능동 학습 방법는 둘 이상의 훈련 데이터 그룹의 확률 변수에 따른 확률 분포에 기초하여 제 1 훈련 데이터 그룹을 결정하고, 상기 제 1 훈련 데이터 그룹에 포함된 적어도 하나의 훈련 데이터를 라벨링된 학습 데이터로 전환하는 전환단계를 포함할 수 있다(S500). 본 개시의 능동 학습 방법은 인공 지능 모델의 성능 향상을 위해서 데이터를 일괄로 학습하는 것이 아니라, 설 정된 기준에 따라 훈련 데이터 그룹으로 나누어 분류하고, 훈련 데이터 내의 일부 데이터를 다시 라벨링된 데이 터로 추출하여, 해당 데이터에 기초하여 학습을 수행할 수 있다. 상술한대로 일반적으로 라벨링된 데이터의 양이 많아질수록, 딥러닝 모델의 성능은 향상될 수 있지만 대량의 데 이터에 주석을 다는 것은 상당한 시간과 상당한 시간과 비용이 요구되는 문제가 있다. 이를 해결하는 방안으로 선택적으로 데이터에 주석을 달아서 사용하는 능동 학습이 있다. 다만 주석을 달 데이터를 선택함에 있어서 효 율적이지 못하다는 문제가 있고, 이에 대한 방안으로 본 개시는 강화 학습을 통한 능동 학습을 제안한다. 강화 학습은 에이전트가 보상을 극대화하기 위해 특정 환경에서 취할 수 있는 최적의 행동을 선택하는 방법을 학습하는 방식이다. 일 예로, 전환단계는 전체 훈련 데이터를 사전에 정의된 모델을 통해 상기 훈련 데이터의 적합도와 관련된 구실 손실을 산출하고, 상기 전체 훈련 데이터를 상기 산출된 구실 손실에 기초하여 상기 2이상의 훈련 데이터 그룹 으로 분류할 수 있다. 전환단계는 학습 대상이 되는 각 데이터에 대해 구실 손실을 산출하고, 산출된 구실 손실에 기초하여 전체 데이 터를 내림차순으로 정렬한다. 전환단계는 구실 손실이 큰 데이터를 기준으로 설정된 개수만큼 그룹을 지어 분류 할 수 있다. 구실 손실은 훈련 데이터로서의 적합도를 의미할 수 있다. 구실 손실의 산출은 미리 설정된 인공지능 모델에 각 훈련 데이터를 입력하여 출력된 값을 구실 손실로 보고, 구실 손실이 클수록 훈련 데이터로 적합도가 떨어진다 고 할 수 있다. 다른 예로, 전환단계는 제 1 훈련 데이터 그룹을 결정하는데 사용되는 확률 분포로 상기 2이상의 훈련 데이터 그룹의 베타 분포를 사용할 수 있다. 전환단계는 분류된 각 그룹에 대한 베타 분포를 사용하여 Q값을 출력 할 수 있다. 또 다른 예로, 전환단계는 있어서 2이상의 훈련 데이터 그룹 중 베타 분포의 결과가 가장 높은 그룹을 제 1 훈 련 데이터 그룹으로 결정할 수 있다. 베타 분포는 어떤 시행이 있는 경우에 성공이 α번이고, 실패가 β번 관측된 사건에 대해서 이 시행의 성공 확 률을 모델링한 분포라고 할 수도 있다. 전환단계는 각 훈련 데이터 그룹의 성공 또는 실패를 확률 변수로 하여 베타 분포의 결과값을 산출하고, 그 산 출값이 가장 높은 그룹을 제 1 훈련 데이터 그룹으로 결정할 수 있다. 본 개시에서는 베타 분포를 통해 산출되 는 값을 Q값 또는 Q value라고 호칭 할 수 있다. 또 다른 예로, 전환단계는 제 1 훈련 데이터 그룹에 포함된 훈련 데이터의 불확실성을 산출하고, 불확실성이 큰 훈련 데이터 가운데 N개(N은 1이상의 정수)의 훈련 데이터에 라벨링을 수행할 수 있다. 능동 학습 방법은 라벨링된 학습 데이터를 인공지능 모델에 입력하여 학습을 수행하는 학습단계를 포함할 수 있 다(S510). 일 예로, 학습단계는 학습이 완료된 인공지능 모델에 학습 과정의 타당성과 관련된 검증 데이터에 기초하여 손 실값을 산출할 수 있다. 학습 데이터는 인공지능 모델의 성능을 높이기 위해 사용되는 데이터라면, 검증 데이터는 학습이 완료된 인공지 능 모델의 학습 과정의 타당성을 확인하기 위해 사용되는 데이터이다. 학습 데이터 집합에는 유효한 데이터와 유효하지 않은 데이터가 함께 포함될 수 있으나, 검증 데이터는 유효한 데이터로 구성된다. 훈련 데이터에는 학 습 데이터, 검증 데이터 또는 테스트 데이터도 포함될 수 있다. 능동 학습 방법은 학습 결과를 보상 함수에 입력하여 상기 학습의 성공 여부와 관련된 보상값을 산출하고, 상기 보상값을 상기 확률 변수에 적용하여 추가 학습을 수행할 제 2 훈련 데이터 그룹을 결정하는 결정단계를 포함할 수 있다(S520). 다른 예로, 결정단계는 산출한 손실값을 이용하여 성공 또는 실패를 판별하는 베르누이 시행을 통해 상기 보상 값을 출력할 수 있다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 기술 사상의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형 이 가능할 것이다. 또한, 본 실시예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 므로 이러한 실시예에 의하여 본 기술 사상의 범위가 한정되는 것은 아니다. 본 개시의 보호 범위는 아래의 청 구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개시의 권리 범위에 포함 되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2024-0013240", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 실시예에 따라 강화 학습을 적용한 능동 학습 장치의 구성에 대한 도면이다. 도 2는 본 실시예에 따라 능동 학습 알고리듬의 전체적인 과정에 대한 도면이다. 도 3은 본 실시예에 따라 훈련 데이터의 일부를 라벨링하는 과정을 설명하기 위한 순서도이다. 도 4는 본 실시예에 따라 강화 학습을 통해 추가적인 훈련 데이터 그룹을 결정하는 과정을 설명하기 위한 순서도이다. 도 5는 본 실시예에 따라 강화 학습을 적용한 능동 학습 방법을 설명하기 위한 순서도이다."}
