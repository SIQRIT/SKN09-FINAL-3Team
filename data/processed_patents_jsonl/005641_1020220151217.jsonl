{"patent_id": "10-2022-0151217", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0076418", "출원번호": "10-2022-0151217", "발명의 명칭": "병해충 감지를 위한 열화상 기반 농업용 드론", "출원인": "양승호", "발명자": "양승호"}}
{"patent_id": "10-2022-0151217", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "농장의 전체 구역을 촬영하는 거시적 카메라로부터 미리 설정된 주기에 따라 상기 농장의 전체 이미지인 제1 이미지 정보를 획득하는 단계;시간대 별로 획득된 상기 제1 이미지 정보를 통해 딥러닝 학습이 수행되도록 처리하는 단계;상기 제1 이미지 정보가 새로 획득되면, 상기 제1 이미지 정보를 통한 학습 결과를 기초로, 상기 농장에 이상구역이 있는지 여부를 판단하는 단계;상기 농장에서 제1 구역에 이상이 있는 것으로 판단되면, 상기 제1 구역을 촬영하는 미시적 카메라로부터 상기제1 구역에서 생장중인 식물의 이미지인 제2 이미지 정보를 획득하는 단계; 및 상기 제2 이미지 정보를 합성곱신경망 및 순환 신경망에 적용하여, 상기 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석하는 단계를 포함하는, 인공지능 기반 병충해 및 생육 감시 방법.상기 케메라(20)는 드론몸체부(A10) 프로펠러(A30)와 암(31)이 연결되기 위해 드론몸체부(A10)의 상부 중심에위치하는 중심부(A11), 통신부, 제어부로 구성된 드론(A1)에 있어서,상기 드론몸체부(A10) 상단에 드론(A1)에 장착시킨 배터리와 연결된 ±단자(제1단자라 칭함)를 형성하고, 상기제1단자(AA)는 일측을 전력선(BB)으로 연결하며 상기 전력선(BB) 단측은 ±단자(제2단자라 칭함)를 연결한것과,토지내부 상단의 길이 방향으로 길게 ±단자레일(단자레일이라 칭함)을 시설한 후 상기 제2단자(CC)를 상기 단자레일(DD)에 전기가 흐르도록 연결한 상태에서 상기 제2단자(CC)가 상기 단자레일(DD)에서 상기 단자레일(DD)의 길이 방향으로 슬라이드 이동할 수 있도록 하는 구성을 특징으로 하는 병해충 감지를 위한 열화상 기반 농업용 드론."}
{"patent_id": "10-2022-0151217", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 단자레일(DD)에 도르래(DD1)를 연결하되 상기 도르래(DD1) 상단은 상기 단자레일(DD)에 수평으로 슬라이드 되도록 연결하고 상기 도르래(DD1)의 로울러(DD2)에 케이블(FF) 타측을 경유시켜 상기 경유시킨 타측 끝단에 중량추(GG)를 연결하고 상기 케이블(FF) 일측은 배터리나 모터(h130a)에 전력을 인가하도록 드론몸체부(h110)의 제1단자(AA)에 연결한 구성을 특징으로 하는 병해충 감지를 위한 열화상 기반 농업용 드론."}
{"patent_id": "10-2022-0151217", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 병해충 감지를 위한 열화상 기반 농업용 드론에 관한 것으로서, 상세하게는 드론에 카메라를 탑재한 후 비행을 통해 농작물에 해당하는 식물의 영상을 수집하여 수집한 영상으로부터 식물의 병해충을 감지하는 기술 을 제공하고, 드론에 비행 항로(경로)를 벗어나지 않도록 함과 동시에 드론에 전력을 공급하는 장치를 제공한다."}
{"patent_id": "10-2022-0151217", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 병해충 감지를 위한 열화상 기반 농업용 드론에 관한 것으로서, 상세하게는 드론에 카메라를 탑재한 후 비행을 통해 농작물에 해당하는 식물의 영상을 수집하여 수집한 영상으로부터 식물의 병해충을 감지하는 기 술을 제공하고 드론에 비행 항로(경로)를 벗어나지 않도록 함과 동시에 드론에 전력을 공급하는 장치를 제공한 다."}
{"patent_id": "10-2022-0151217", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 드론은 사람이 타지 않고 무선전파의 유도에 의해서 비행하는 비행기나 헬리콥터 모양의 비행체로서, 처음에는 공군기나 고사포, 미사일의 연습사격에 적기 대신 표적 구실로 사용되었으며, 점차 무선 기술의 발달과 함께 정찰기로 개발되어 적의 내륙 깊숙이 침투하여 정찰, 감시의 용도로도 운용되었다. 이러한 드론은 최근 들어 수송목적에도 활용되는 등 활용 범위가 점차 넓어지고 있고, 활용 목적에 따라 다양한 크기와 성능을 가진 제품이 다양하게 개발되고 있으며, 초소형 드론은 물론 개인의 취미활동으로도 개발되어 상 품화되고 있다. 한편, 현재 농촌에서 수행되고 있는 농약 및 비료의 살포방식은 농약을 물에 희석시켜 분무기에 담아 농민이나 작업자가 직접 살포하거나 길다란 비닐봉지에 농약을 담아 양끝에서 비닐봉지를 잡고 살포하는 방식으로 수행되 고 있다. 본 발명자는 이러한 종래 드론에 영상을 수집하는 카메라를 장착하여 식물에 발생된 병충해를 감시하고자 한다. 사물인터넷의 발달이 농업분야에까지 파급되면서 정보통신기술과 농업이 융합된 스마트팜이 확산되고 있다. 스마트팜은 사람이 아닌 시스템이 온도, 습도, 이산화탄소(CO2)와 같은 환경 센서로부터 수집된 데이터를 분석 하여 환기시설 및 냉난방 시설 등을 제어로 식물의 적정한 생육 환경을 관리하는 방식이다. 스마트팜은 농장의 인건비를 감소시키고 식물의 생장을 돕고 생산량을 늘리는데 성공했지만 드넓은 온실에 해를 주는 병충해로 인한 식물의 손실을 완벽히 막아내지 못하는 문제가 있다. 이에 따라, 사람이 직접 육안으로 식물을 관찰하여 병충해를 진단하고 있으나 객관적인 정보를 얻기 어려우며, 곰팡균이나 바이러스와 같은 병균 및 작은 벌레에 의한 병충해를 감지하는데 어려움이 있다. 따라서, 스마트팜으로 운영되는 농장에서 병충해 및 생육 피해를 용이하고 효율적으로 감지하여, 병충해로 인한 식물의 손실을 방지하고자 하는 요구가 증대되고 있다."}
{"patent_id": "10-2022-0151217", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "종래의 문제점을 감안하여, 본 발명은 농장의 전체 구역을 촬영하는 거시적 카메라로부터 획득된 제1 이미지 정보를 통한 학습 결과를 기초로, 농장에 이상 구역이 있는지 여부를 판단하고, 이상 구역을 촬영하는 미시적 카메라로부터 획득된 제2 이미지 정보를 합성곱 신경망 및 순환 신경망에 적용하여, 이상 구역의 식물에서 발생 한 병충해 및 생육 피해에 대한 원인을 분석하는 인공지능 기반 병충해 및 생육 감시 방법을 제공하는 것을 그 목적으로 한다. 더 나가, 조도센서를 통해 설정값에 해당하는 햇빛이 식물에 조사되는 경우에만 식물의 영상을 수집함으로 미리 설정한 값과 비교하는 과제이다."}
{"patent_id": "10-2022-0151217", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "첨부도면 1내지 4에 의해 설명하면, 드론몸체부(A10)는 프로펠러(A30)와 암(A31)이 연결되기 위해 드론몸체부(A10)의 상부 중심에 위치하는 중심부 (A11), 통신부, 제어부로 구성된드론에 있어서, 상기 드론몸체부(A10) 상단에 드론(A1)에 장착시킨 배터리와 연결된 ±단자(제1단자라 칭함)를 형성하고, 상기 제1단자(AA)는 일측을 전력선(BB)으로 열결하며 상기 전력선(BB) 단측은 ±단자(제2단자라 칭함)를 연결한 것과, 토지 상단의 길이방향으로 길게 ±단자레일(단자레일이라 칭함)을 시설한 후 상기 제2단자(CC)를 상기 단자레일 (DD)에 전기가 흐르도록 연결한 상태에서 상기 제2단자(CC)가 상기 단자레일(DD)에서 상기 단자레일(DD)의 길이방향으로 슬라이드 이동할 수 있도록 하는 구성이다. 상기 단자레일(DD)에 도르래(DD1)를 연결하되 상기 도르래(DD1) 상단은 상기 단자레일(DD)에 수평으로 슬라이드 되도록 연결하고 상기 도르래(DD1)의 로울러(DD2)에 케이블(FF) 타측을 경유시켜 상기 경유시킨 타측 끝단에 중 량추(GG)를 연결하고 상기 케이블(FF) 일측은 배터리나 모터(h130a)에 전력을 인가하도록 드론몸체부(A10)의 제 1단자(AA)에 연결한 구성이다."}
{"patent_id": "10-2022-0151217", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 전력선(BB)은 단자레일(DD)을 따라 슬라이드 이동하므로 드론은 지속적으로 비행할 수 있는 효과 와 그리고 조도센서를 통해 설정값에 해당하는 햇빛이 식물에 조사되는 경우에만 식물의 영상을 수집함으로 미리 설정한 값과 비교가 용이하다."}
{"patent_id": "10-2022-0151217", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조한 본 발명의 설명은 특정한 실시 형태에 대해 한정되지 않으며, 다양한 변환을 가할 수 있고 여러가지 실시예를 가질 수 있다. 또한, 이하에서 설명하는 내용은 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 이하의 설명에서 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용되는 용어로서, 그 자체에 의미가 한정되지 아니하며, 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 명세서 전체에 걸쳐 사용되는 동일한 참조번호는 동일한 구성요소를 나타낸다. 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 이하에서 기재되는 \"포함하다\", \"구비하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것으로 해석되어야 하며, 하나 또는 그 이 상의 다른 특징들이나, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가 능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하, 본 발명의 실시예를 첨부한 도 1 내지 도 4를 참조하여 상세히 설명하기로 한다. 먼저, 다음은 드론에 전력을 공급하고자 한다. 하우스 천정주변에 전력이 공급되는 충전장치(미도시)를 마련하고 드론몸체부(A10)에 배터리(도3 참조)와 연결 된 ±단자를 노출시켜 배터리가 설정전력 이하 일 경우 상기 드론(A1)이 상기 충전장치에 착륙하여 배터리를 충 전하는 구성이다. 상기 드론의 비행은 미리 설정된 프로그램에 의해 제어부에서 비행을 진행하거나 관리자가 무선통신으로 조이스틱을 조작하여 비행한다. 이 비행방법은 일반적이 통상의 비행방법이다. 또 다른 구성은 다음과 같다. 상기 드론몸체부(A10) 상단에 드론(A1)에 장착시킨 배터리와 연결된 ±단자(제1단자라 칭함)를 형성하고, 상기 제1단자(AA)는 일측을 전력선(BB)으로 연결하며 상기 전력선(BB) 단측은 ±단자(제2단자라 칭함)를 연결한 것과, 토지 내부 상단의 길이 방향으로 길게 ±단자레일(단자레일이라 칭함)을 시설한 후 상기 제2단자(CC)를 상기 단 자레일(DD)에 전기가 흐르도록 연결한 상태에서, 상기 제2단자(CC)가 상기 단자레일(DD)에서 상기 단자레일(DD)의 길이 방향으로 슬라이드 이동할 수 있도록 하 는 구성이다. 상기 구성의 실시예를 살펴보면, 단자레일(DD)에 한전(태양전지 포함)으로부터 공급되는 전력을 인가하면 그 전 력은 상기 단자레일(DD)과 전력선(BB)을 경유하여 제어부(EE)의 제어신호에 따라 배터리에 인가되거나 모터 (A32)에 인가된다. 그 후 드론(A1)의 비행 신호에 따라 비행하는 과정으로 단자레일(DD)의 길이 방향을 왕복 비행하면 전력선(BB) 은 단자레일(DD)을 따라 슬라이드 이동하므로 드론(A1)은 지속적으로 비행할 수 있는 효과가 있다. 상기 전력선(BB)은 드론(A1)이 하우스의 폭방향으로 왕복 비행하면 상기 전력선(BB)이 연장되거나 축소되도록 상기 전력선(BB)을 코일케이블(BB1)을 이용한 것을 특징으로 한다.상기 코일케이블(BB1)은 인터넷을 통해 구매 가능한 제품이여서 다음, 구글 등에서 검색 가능하다. 상기 단자레일(DD)에 도르래(DD1)를 연결하되 상기 도르래(DD1) 상단은 상기 단자레일(DD)에 수평으로 슬라이드 되도록 연결하고 상기 도르래(DD1)의 로울러(DD2)에 케이블(FF) 타측을 경유시켜 상기 경유시킨 타측 끝단에 중 량추(GG)를 연결하고 상기 케이블(FF) 일측은 배터리나 모터(A32)에 전력을 인가하도록 드론몸체부(A10)의 제1 단자(AA)에 연결한 구성이다. 상기 중량추(GG)의 중량과 드론(A1)전체의 중량이 서로 동일하면 바란스가 유지된다. 그러면 드론 비행시 상기 드론(A1)의 모터(A32)를 정회전과 역회전을 반복하면서 비행해야 하고, 드론(A1)이 더 무거우면 일반적인 드론비행으로 비행하면 된다. 상기 중량추(GG)의 무게는 상기 드론(A1) 무게와 동일 유사하게 하여 중량의 바란스를 유지한 상태에서 드론 (A1)이 이륙 후 상승하거나 하강하면 상기 중량추(GG)가 반대로 승하강하면서 서로의 무게의 바란스가 유지된다. 이처럼 무게의 바란스가 유지되면 낮은 출력의 동력으로 드론이 승하강 비행을 할 수 있어 상기 드론(A1)에 중 량감이 있는 카메라를 장착하더라도 비행이 쉽게이루어 진다. 드론의 구성요소를 구체적으로 살펴보면 다음과 같다. 드론몸체부(A10)는 프로펠러(A30)와 암(A31)이 연결되기 위해 드론몸체부(A10)의 상부 중심에 위치하는 중심부 (A11)를 포함한다. 암(A31)은 상기 드론몸체부(A10)의 중심부(A11)를 중심으로 방사상으로 다수 개가 형성되되, 바람직하게는 8개 의 암이 동일한 간격 상으로 형성되어 중심부가 형성되 드론몸체부(A10)의 중심부(A11)를 중심으로 회전된다. 프로펠러(A30)는 상기 암(A31)의 단부에 형성되되 드론의 이륙과 착륙을 위한 동력을 발생시킨다. 즉 다수 개의 암(A31)의 단부에 프로펠러(A30)가 각각 형성되는 것이다. 드론은 호버링 상태를 유지한 할 수 있다. 이하 첨부된 도면을 참고하여 본 발명의 실시예를 상세히 설명하기로 한다. 도 5는 본 발명의 일 실시예에 따른 인공지능을 기반으로 병충해 및 생육을 감시하기 위한 시스템의 구성을 개 략적으로 나타낸 도면이다. 도 5를 참조하면, 본 발명의 일 실시예에 따른 시스템은 거시적 카메라, 미시적 카메라, 환경센서 및 감시장치를 포함할 수 있다. 거시적 카메라는 일반 촬영을 수행하는 카메라로 구현되어, 농장의 일 측면에 배치될 수 있으며, 농장의 전 체 구역을 촬영하고, 농장의 전체 구역을 촬영한 이미지인 제1 이미지 정보를 생성하여 감시장치로 전송할 수 있다. 거시적 카메라는 미리 설정된 주기에 따라 제1 이미지 정보를 생성할 수 있으며, 예를 들어, 10분에 한 번 씩 농장 전체 구역을 촬영하여 제1 이미지 정보를 생성할 수 있다. 여기서, 실시간으로 촬영을 수행하지 않고, 주기적으로 촬영을 수행하는 것은 식물이 단시간에 급격한 변화가 일어나지 않기 때문에 주기적으로 촬영을 수행함으로써, 정보의 양을 줄여 분석의 효율성을 높일 수 있다. 미시적 카메라는 근접 촬영을 수행하는 카메라로 구현되어, 농장의 구역 별로 각각 배치될 수 있다. 예를들어, 제1 구역에 배치되어 제1 구역을 담당하는 미시적 카메라는 제1 구역에서 생장중인 식물을 촬영 하고, 제1 구역의 식물을 촬영한 이미지인 제2 이미지 정보를 생성하여 감시장치로 전송할 수 있다. 미시적 카메라는 평상시에 제1 촬영 주기로 촬영을 수행하다가, 제1 이미지 정보를 통해 담당 구역에 이상 이 있는 것이 확인되면, 제1 촬영 주기보다 더 짧은 제2 촬영 주기로 촬영을 수행할 수 있다. 예를 들어, 미시적 카메라는 제1 구역을 1분에 한 번씩 촬영하고 있는데, 제1 구역에 이상이 있는 것으로 확인되면, 제1 구역을 10초에 한 번씩 촬영하는 것으로, 촬영 주기를 변경할 수 있다. 환경센서는 농장 내외에 설치되어, 대기의 온도, 습도, 토양의 수분, 토양 ph(산성도), CO2 등과 같이 식물 의 생육 환경에 영향을 주는 다양한 환경 요인을 측정하여 센서 정보를 생성할 수 있으며, 생성된 센서 정보를 감시장치로 전송할 수 있다. 감시장치는 거시적 카메라, 미시적 카메라 및 환경센서와 연결되어, 농장의 이미지 정보와 센 서 정보를 획득하여 수집할 수 있다. 감시장치는 농장의 이미지 정보 및 센서 정보를 모니터링 하여, 농장의 식물에 이상이 있는지 확인할 수 있 으며, 이상이 있는 것으로 확인되면, 이에 대한 원인을 분석하고, 분석 결과를 농장을 관리하는 관리자 단말기 로 제공할 수 있다. 구체적으로, 감시장치는 거시적 카메라로부터 획득된 제1 이미지 정보를 분석하여, 농장의 구역별 특징 정보를 추출할 수 있으며, 새로 추출된 특징 정보와 이전에 추출된 특징 정보를 비교하여 이상 현상이 있는지 여부를 판단할 수 있다. 감시장치는 제1 이미지 정보를 분석하여, 농장내 병충해 및 생육 피해가 발생한 것으로 판단되는 식물의 위 치 및 식물이 있는 구역을 파악할 수 있다. 감시장치는 제1 구역에 이상이 있는 것으로 판단되면, 제1 구역에서 생장중인 식물의 이미지인 제2 이미지 정보를 미시적 카메라로부터 획득할 수 있으며, 제2 이미지 정보를 통해 제1 구역에 대한 상세 모니터링을 수행할 수 있다. 감시장치는 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 때 인공지능 기법을 이용하여 판단 할 수 있으며, 다양한 식물의 피해 데이터가 축적될수록 원인분석 결과의 정확도가 높아질 수 있다. 감시장치는 농장 전체를 주기적으로 촬영한 제1 이미지 정보에 대해 딥러닝 학습을 수행하여, 농장의 이상 현상을 판단할 수 있도록 구축된 학습 네트워크와 연결되거나, 학습 네트워크를 포함하여 구현될 수 있다. 감시장치는 제1 구역에서 생장중인 식물을 주기적으로 촬영한 제2 이미지 정보에 대해 딥러닝 학습을 수행 하여, 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있도록 구축된 학습 네트워크와 연결되거나, 학습 네트워크를 포함하여 구현될 수 있다. 제1 이미지 정보를 분석하기 위한 학습 네트워크와 제2 이미지 정보를 분석하기 위한 학습 네트워크는 별도로 구분된 각각의 네트워크로 구현될 수 있고, 하나의 통합된 네트워크로 구현될 수 있으며, 여기에서, 학습 네트 워크는 딥러닝 기반의 네트워크로서, MLP(MultiLayer Processing, CNN(Convolution Neural Network), RNN(Recurrent Neural Network) 등 공지의 딥러닝 네트워크로 구현될 수 있고, 향후 개발될 다양한 인공지능 네 트워크를 통해 대체 구현될 수 있지만 어느 유형의 네트워크이든지 특별히 본 발명을 한정하는 것은 아니다. 도 6은 본 발명의 일 실시예에 따른 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석하는 과정을 순서 도로 나타낸 도면이다. 먼저, S201 단계에서, 감시장치는 농장의 전체 구역을 촬영하는 거시적 카메라로부터 미리 설정된 주기 에 따라 농장의 전체 이미지인 제1 이미지 정보를 획득할 수 있다. 예를 들어, 감시장치는 1분에 한 번씩 제1 이미지 정보를 획득할 수 있으며, 시간대 별로 획득된 제1 이미 지 정보를 수집할 수 있다. S202 단계에서, 감시장치는 시간대 별로 획득된 제1 이미지 정보를 통해 딥러닝 학습이 수행되도록 처리할 수 있다. 감시장치는 시간대 별로 획득되는 제1 이미지 정보를 분석하여, 제1 이미지 정보를 통해 농장의 이상 현상 을 판단할 수 있도록, 딥러닝 학습을 수행할 수 있다. 감시장치는 주기적으로 획득된 제1 이미지 정보에 대한 딥러닝 학습이 기준치 이상으로 수행된 상태에서, 제1 이미지 정보가 새로 획득되면, S203 단계에서, 제1 이미지 정보를 통한 학습 결과를 기초로, 농장에 이상 구역이 존재하는지 여부를 판단할 수 있다. S203 단계에서 농장에 이상 구역이 있는 것으로 판단되면, S204 단계에서, 감시 장치는 제2 이미지 정보를 획득할 수 있다. 구체적으로, 농장에서 제1 구역에 이상이 있는 것으로 판단되면, 감시장치는 제1 구역을 촬영하는 미시적 카메라로부터 제1 구역에서 생장중인 식물의 이미지인 제2 이미지 정보를 획득할 수 있다. S203 단계에서 농장에 이상 구역이 있지 않은 것으로 판단되면, 감시장치는 S201 단계를 다시 수행할 수 있 다. S205 단계에서, 감시장치는 제2 이미지 정보를 합성곱 신경망 및 순환 신경망에 적용하여, 제1 구역의 식물 에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있다. 감시장치는 제1 구역에서 생장중인 식물을 주기적으로 촬영한 제2 이미지 정보를 분석하여, 제2 이미지 정 보를 통해 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있도록, 딥러닝 학습을수행할 수 있다. 도 7은 본 발명의 일 실시예에 따른 제1 이미지 정보를 획득하는 과정을 순서도로 나타낸 도면이다. 먼저, S301 단계에서, 감시장치는 농장 내외에 설치된 환경센서로부터 센서 정보를 획득할 수 있다. S302 단계에서 감시장치는 센서 정보를 기초로, 농장에 병충해 및 생육 피해가 발생할 가능성이 있는지 여 부를 판단할 수 있다. 예를 들어, 감시장치는 센서 정보를 통해 농장의 온도를 확인하여, 확인된 온도가 기준범위 내에 있는 경우, 농장에 병충해 및 생육 피해가 발생할 가능성이 있지 않은 것으로 판단할 수 있으며, 확인된 온도가 기준 범위를 벗어나는 경우, 농장에 병충해 및 생육 피해가 발생할 가능성이 있는 것으로 판단할 수 있다. S302 단계에서 농장에 병충해 및 생육 피해가 발생할 가능성이 있는 것으로 판단되면, S303 단계에서, 감시장치 는 RGB 값의 다중 채널로 제1 이미지 정보를 획득할 수 있다. S302 단계에서 농장에 병충해 및 생육 피해가 발생할 가능성이 있지 않은 것으로 판단되면, S304 단계에서, 감 시장치는 그레이 스케일 값의 단일 채널로 제1 이미지 정보를 획득할 수 있다. 즉, 감시장치는 농장에 병충해 및 생육 피해가 발생할 가능성이 있지 않은 경우, 그레이 스케일 값의 단일 채널로 제1 이미지 정보를 획득하여 분석해야 하는 정보의 양을 줄일 수 있으며, 농장에 병충해 및 생육 피해가 발생할 가능성이 있는 경우, RGB 값의 다중 채널로 제1 이미지 정보를 획득하여, 상세 분석을 수행할 수 있다. 도 8은 본 발명의 일 실시예에 따른 식물에서 발생한 병충해 및 생육 피해가 복구되었는지 여부를 확인하는 과 정을 순서도로 나타낸 도면이다. 먼저, S401 단계에서, 감시장치는 제2 이미지 정보를 합성곱 신경망 및 순환 신경망에 적용하여, 제1 구역 의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있다. 예를 들어, 감시장치는 병충해 및 생육 피해에 대한 발생 원인을 토양 염류 피해, 병충해 피해, 생리장해 등으로 구분하여 분석할 수 있으며, 토양 염류 피해에는 염류피해에 의한 출하지연, 염류피해에 의한 잎마름 증 상 및 생육부진, 염류피해에 의한 황화 증상 및 생육 불균일, 염류 피해 등이 있으며, 병충해 피해에는 모잘록 병, 점무늬병, 탄저병, 잿빛곰팡이병, 뿌리썩음병, 균핵병, 가루깍지벌레, 달팽이류, 미국선녀벌레 등이 있으며, 생리 장해에는 영양제 과다사용에 따른 황증 발생, 고온으로 인해 발생된 줄기 열상 발생 등이 있다. S402 단계에서, 감시장치는 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인의 분석결과, 발 생 원인의 종류에 따라 RGB 값 중 어느 하나의 색으로 피해 여부의 구분이 가능한지 여부를 판단할 수 있다. S402 단계에서 어느 하나의 색으로 피해 여부의 구분이 가능한 것으로 판단되면, S403 단계에서, 감시장치 는 발생 원인의 종류에 따라 RGB 값 중 어느 하나인 제1 색상으로만 피해 여부의 구분이 가능한 경우, 제1 색상 의 채널로 제2 이미지 정보를 미리 설정된 주기에 따라 추가로 획득할 수 있다. S402 단계에서 어느 하나의 색으로 피해 여부의 구분이 가능하지 않은 것으로 판단되면, S404 단계에서, 감시장 치는 RGB 값의 다중 채널로 제2 이미지 정보를 미리 설정된 주기에 따라 추가로 획득할 수 있다. S405 단계에서, 감시장치는 획득된 제2 이미지 정보를 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해가 복구되었는지 여부를 확인할 수 있다. 감시장치는 발생 원인의 종류에 따라 제1 색상으로만 피해 여부의 구분이 가능한 경우, 제1 색상의 채널로 획득된 제2 이미지 정보를 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해가 복구되었는지 여부를 확 인할 수 있다. 예를 들어, 잿빛곰팡이병의 피해 여부가 붉은색으로 구분이 가능한데, 제1 구역의 식물에서 발생한 병충해 피해 가 잿빛곰팡이병으로 판단되면, 감시장치는 R 채널을 통해 제2 이미지 정보를 주기적으로 획득하여, R값만 가지고 있는 제2 이미지 정보를 기초로, 잿빛곰팡이병에 대한 피해가 복구되었는지 여부를 확인할 수 있다. 도 9는 본 발명의 일 실시예에 따른 복수의 구역으로 구획된 농장의 일부분을 나타낸 도면이다. 도 9를 참조하면, 농장은 제1 구역, 제2 구역, 제3 구역, 제4 구역, 제5 구역, 제6 구역, 제7 구역, 제8 구역, 제9 구역 등으로 구획될 수 있으며, 각각의 구역에는 미시적 카메라가 배치될 수 있다. 감시장치는 농장에서 제1 구역에 이상이 있는 것으로 판단되면, 제1 구역에서 생장중인 식물의 이미지인 제 2 이미지 정보를 획득하면서, 제1 구역과 인접한 구역에서 촬영된 이미지 정보를 추가로 더 획득할 수 있다. 예를 들어, 감시장치는 농장에서 제1 구역에 이상이 있는 것으로 판단되면, 제1 구역과 인접한 영역인 제2 구역, 제4 구역 및 제5 구역 각각에서 촬영된 이미지 정보를 더 획득할 수 있다. 감시장치는 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인의 분석결과, 발생 원인의 종류에 따라 제1 색상으로만 피해 여부의 구분이 가능한 경우, 제1 구역과 인접한 영역인 제2 구역을 촬영하는 미시적 카메라로부터 제2 구역에서 생장중인 식물의 이미지인 제3 이미지 정보를 제1 색상의 채널로 획득할 수 있 다. 감시장치는 제1 색상의 채널로 획득된 제3 이미지 정보를 기초로, 제1 구역의 생육 피해가 제2 구역의 식물에게 전염되었는지 여부를 판단할 수 있다. 예를 들어, 잿빛곰팡이병의 피해 여부가 붉은 색으로 구분이 가능한데, 제1 구역의 식물에서 발생한 병충해 피 해가 잿빛곰팡이병으로 판단되면, 감시장치는 제2 구역에서 생장중인 식물의 이미지를 R 채널을 통해 획득 하여, R 값만 가지고 있는 제3 이미지 정보를 기초로, 잿빛곰팡이병이 제2 구역의 식물에게 전염되었는지 여부 를 판단할 수 있다. 감시장치는 제1 구역의 식물에서 발생한 병충해 및 생육 피해가 제2 구역의 식물에게 전염된 것으로 판단되 면, 제2 구역과 인접한 다른 구역의 식물에게 피해가 전염되었는지 여부를 추가로 판단하여, 병충해 및 생육피 해에 대한 전염을 추적할 수 있다. 감시장치는 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인의 분석결과, 발생 원인의 종류에 따라 제1 구역의 환경 상태를 변화시키기 위한 제어값을 최대값으로 설정하고, 제1 구역과 인접한 영역인 제2 구역의 환경 상태를 변화시키기 위한 제어값을 중간값으로 설정하고, 농장에서 제1 구역 및 제2 구역을 제외한 나머지 구역의 환경 상태를 변화시키기 위한 제어값을 최소값으로 설정할 수 있다.예를 들어, 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인의 분석 결과, 제1 구역의 온도를 최 대 10도 낮춰야 추가 피해를 방지할 수 있는 경우, 감시장치는 제1 구역의 온도를 변화시키기 위한 제어값 을 10도 낮추기 위한 값으로 설정할 수 있으며, 제1 구역과 인접한 영역인 제2 구역의 온도를 변화시키기 위한 제어값을 5도 낮추기 위한 값으로 설정할 수 있으며, 제1 구역과 인접하지 않은 다른 구역의 온도를 변화시키기 위한 제어값을 1도 낮추기 위한 값으로 설정할 수 있다. 도 10은 본 발명의 일 실시예에 따른 합성곱 신경망 및 순환 신경망을 통해 식물에서 발생한 병충해 및 생육 피 해에 대한 원인을 분석하는 과정을 나타낸 도면이다. 먼저, 감시장치는 제1 구역에서 생장중인 식물을 주기적으로 촬영한 제2 이미지 정보에 대해 딥러닝 학습을 수행하여, 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있도록 구축된 학습 네트 워크와 연결되거나, 학습 네트워크를 포함하여 구현될 수 있다. 즉, 감시장치는 외부 장치를 통해 합성곱 신경망, 순환 신경망 등의 인공지능을 통한 딥러닝 학습을 수행할 수 있고, 외부장치 없이 자체적으로 딥러닝 학습을 수행할 수 있다. 감시장치는 제2 이미지 정보에 기초하여 제1 입력 신호를 생성할 수 있으며, 제1 입력 신호를 합 성곱 신경망에 입력할 수 있다. 여기서, 합성곱 신경망은 제1 구역에서 생장중인 식물에 발생할 수 있는 병충해 및 생육 피해에 대해 미리 학 습되어 있는 상태이며, 예를 들어, 주기적으로 획득된 제2 이미지 정보를 수집하고, 수집된 정보들을 비교하여, 제1 구역에서 생장중인 식물에 발생할 수 있는 병충해 및 생육 피해에 대한 학습을 수행할 수 있다. 감시장치는 제1 입력신호를 합성곱 신경망에 적용하여, 제1 입력신호의 입력으로 생성된 제1 출 력신호를 획득할 수 있다. 이때, 합성곱 신경망은 제1 구역에서 생장중인 식물의 병충해 및 생육 피해정보를 기초로 학습된 학습 결과와 제1 입력신호를 비교하여 제1 출력신호를 생성할 수 있다. 감시장치는 제1 출력신호를 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있으며, 제1 출력신호 뿐만 아니라 제1 구역에서 생장중인 식물의 종류, 상기 농장의 환경상태 및 유행중인 질병 정보를 더 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있다. 즉, 감시장치는 제1 구역에서 생장중인 식물의 종류를 확인하고, 확인된 식물의 종류별로 농장의 환경 상태 가 적합한지를 확인하고, 확인된 식물의 종류별로 현재 유행중인 질병이 있는지를 확인하여, 이에 대한 확인 결 과와 제1 출력신호를 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인을 분석할 수 있으며, 예를 들어, 제1 구역의 식물에서 발생한 병충해 및 생육 피해에 대한 원인이 토양 염류피해, 병해충피 해, 생리장해 중 어느 하나인 것으로 분석할 수 있다. 감시장치는 제1 입력신호의 생성 이후 새로 획득된 제2 이미지 정보에 기초하여 제2 입력신호를 생성할 수 있으며, 제2 입력신호 및 제1 출력신호를 순환 신경망에 입력할 수 있다. 여기서, 순환 신경망은 제1 구역에서 생장중인 식물에 발생할 수 있는 병충해 및 생육 피해에 대해 미리 학습 되어 있는 상태이며, 예를 들어 시간대 별로 획득된 제2 이미지 정보를 분석하여 시간의 흐름에 따라 변화하는 정보를 통해, 제1 구역에서 생장중인 식물에 발생할 수 있는 병충해 및 생육 피해에 대한 학습을 수행할 수 있다. 감시장치는 제2 입력신호 및 제1 출력신호를 순환 신경망에 적용하여, 제2 입력신호 및 제1 출력신호의 입력으로 생성된 제2 출력 신호를 획득할 수 있다. 이때, 순환 신경망은 제1 구역에서 생장중인 식물의 병충해 및 생육피해 정보를 기초로 학습된 학습 결과와 제 2 입력신호 및 제1 출력신호를 비교하여 제2 출력신호를 생성할 수 있다. 감시장치는 제2 출력신호를 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해가 복구된 것인 지를 분석할 수 있으며, 제2 출력신호 뿐만 아니라 제1 구역의 식물에서 발생한 병충해 및 생육 피해의 변 화 크기, 촬영시간 및 특이 정보를 더 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해가 복구된 것인 지를 분석할 수 있다. 즉, 감시장치는 제1 구역의 식물에서 발생한 병충해 및 생육 피해의 변화 크기를 확인하고, 시간대 별로 촬 영된 시간 및 변화 크기에 따라 발생하는 특이 정보를 분석할 수 있으며, 이에 대한 분석 결과와 제2 출력신호 를 기초로, 제1 구역의 식물에서 발생한 병충해 및 생육 피해가 얼마나 복구된 것인지를 분석할 수 있다. 그리고 식물의 무성여부를 감지하는 센서(조도센서 포함)와 제어부(a22)를 통해 카메라를 온/오프시켜 촬영을 할 수 있다. 이처럼 하게되면 응달이 지는 경우 촬영을 중단할 수 있다. 여기서 참고 시간대나 날씨에 따라 카메라로 수집한 영상이 제각각이여서 수집한 영상과 미리 설정한 영상 값과 비교할 수 없다. 그러므로 설정된 설정값의 빛이 작물에 조사되는 경우에만 카메라를 통해 작물의 영상을 수집한다. 상기 영상의 픽셀값을 통해 미리 설정한 픽셀값과 비교할 수 있다. 이러한 기술은 일반적이다. 본 발명에서 영상 이미지의 해상도에 따른 하나의 픽셀(화소, pixel [picture element])을 의미한다. 본 발명에서 이미지는 예를들어 식물잎에 진드기가 발생하는 경우 식물잎 이미지가 정상적인 식물잎의 이미지와 차이가 발생한다. 이러한 차인점을 통해 병충해 발생 여부를 판단한다. 구성을 살펴보면 다음과 같다. 드론에 조도센서(a21)를 구비하여 드론이 작물과 작물사이에 위치하여 전방으로 비행하는 도중 조도센서 (a21)를 통해 빛을 감지하여 작물에 조사되는 햇빛이 설정값에 해당하여 작물의 영상을 수집할 수 있는 것으로 판단하여 제어부(a22)는 스위치(a23) 통해 카메라를 온시켜 작물의 영상을 수집하고, 상기 드론이 작물과 작물사이에 위치하여 전방으로 비행하는 도중 조도센서(a21)를 통해 빛을 감지하여 작물에 조사되는 햇빛이 설정값 이하 이면 작물의 영상을 수집할 수 없는 것으로 판단하여 제어부(a22)와 스위치(a23)를 통해 카메라를 오프시켜 작물의 영상을 수집하여 통신부 (a24)를 통해 근거리에 있는 관리자측에 전송하는 구성이다. 조도센서란, 어두운 곳에서는 저항값이 증가하고 밝은 곳에서는 저항값이 낮아지는 원리다. 더 나가 조도센서에 대한 기술은 등록특허 10-1959530호, 공개번호 10-2018-0052246호에서 참고할 수 있다. 부호의 설명 1. 드론 20. 카메라 a21. 조도센서 a22. 제어부 a23. 스위치 a24. 통신부"}
{"patent_id": "10-2022-0151217", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 병해충 감지를 위한 열화상 기반 농업용 드론의 사시도와 실시도, 도 2,3은 본 발명의 실시예의 참고도, 도 4는 본 발명의 또 다른 설명도. 도 5는 본 발명의 일 실시예에 따른 인공지능을 기반으로 병충해 및 생육을 감시하기 위 한 시스템의 구성을 개략적으로 나타낸 도면이다. 도 6은 본 발명의 일 실시예에 따른 식물에서 발생한 병충해 및 생육 피해 에 대한 원인 을 분석하는 과정을 순서도로 나타낸 도면이다. 도 7은 본 발명의 일 실시예에 따른 제1 이미지 정보를 획득하는 과정을 순 서도로 나타 낸 도면이다. 도 8은 본 발명의 일 실시예에 따른 식물에서 발생한 병충해 및 생육 피해 가 복구되었는 지 여부를 확인하는 과정을 순서도로 나타낸 도면이다. 도 9는 본 발명의 일 실시예에 따른 복수의 구역으로 구획된 농장의 일부분 을 나타낸 도면이다. 도 10은 본 발명의 일 실시예에 따른 합성곱 신경망 및 순환 신경망을 통해 식물에서 발 생한 병충해 및 생육 피해에 대한 원인을 분석하는 과정 을 나타낸 도면이다."}
