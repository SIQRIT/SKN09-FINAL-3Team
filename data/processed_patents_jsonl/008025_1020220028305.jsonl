{"patent_id": "10-2022-0028305", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0130997", "출원번호": "10-2022-0028305", "발명의 명칭": "딥러닝의 객체 검출을 이용한 사고방지 모델을 이용하여 휴대 전자기기 사용자의 보행 사고를", "출원인": "(주)에리", "발명자": "김현석"}}
{"patent_id": "10-2022-0028305", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전면에 디스플레이가 배치되고 후면에는 카메라가 배치된 휴대 전자기기를 제어하는 방법에 있어서,상기 디스플레이를 통해 프리뷰 모드 선택 메뉴 및 백그라운드 모드 선택 메뉴가 표시되는 (a)단계; 및상기 (a)단계에서 상기 프리뷰 모드 선택 메뉴 또는 상기 백그라운드 모드 선택 메뉴가 선택되면 상기 카메라를통해 주변 영상을 획득하고, 획득된 영상을 보행 주의물 학습데이터를 바탕으로 학습된 인공신경망에 입력하여보행 주의물을 검출하는 (b)단계를 포함하고,상기 (b)단계는,상기 프리뷰 모드가 선택된 경우에는 상기 디스플레이를 통해 상기 카메라에 의해 획득된 주변 영상이 표시되면서 보행 주의물 검출이 이루어지는 프리뷰 모드를 실시하고, 상기 백그라운드 모드 선택 메뉴가 선택된 경우에는 상기 디스플레이에는 상기 카메라에 의해 획득된 주변 영상이 표시되지 않는 상태에서 보행 주의물의 검출과정이 이루어지는 백그라운드 모드를 실시하고,상기 (b)단계에서의 보행 주의물 검출에 대응하여 상기 디스플레이를 통해 보행주의 알림을 표시하는 (c)단계를더 포함하는 휴대 전자기기를 제어하는 방법."}
{"patent_id": "10-2022-0028305", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프리뷰 모드가 실시되는 중에 보행 주의물이 검출된 경우, 상기 디스플레이를 통해 표시되는 상기 주변 영상에 상기 보행 주의물을 표시하는 단계를 더 포함하는 휴대 전자기기를 제어하는 방법."}
{"patent_id": "10-2022-0028305", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 디스플레이를 통해, 위험분류 알림설정, 위험인식 설정, 위험요소 중복 안내 정지 및 위험요소 정보 저장중 적어도 하나에 대한 선택을 입력 받을 수 있는 화면을 표시하는 (d)단계를 더 포함하는 휴대 전자기기를 제어하는 방법."}
{"patent_id": "10-2022-0028305", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 위험요소 정보 저장이 선택된 경우, 상기 디스플레이릍 통해 상기 (b)단계에서 검출된 보행 주의물이 표시된 맵을 출력하는 단계를 더 포함하는 휴대 전자기기를 제어하는 방법."}
{"patent_id": "10-2022-0028305", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항 내지 제 4 항 중 어느 한 항에 기재된 방법을 휴대 전자기기에서 실행시키기 위한 프로그램을 기록한컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 휴대 전자기기를 제어하는 방법은, 상기 디스플레이를 통해 프리뷰 모드 선택 메뉴 및 백그라운드 모 드 선택 메뉴가 표시되는 (a)단계와, 상기 (a)단계에서 상기 프리뷰 모드 선택 메뉴 또는 상기 백그라운드 모드 선택 메뉴가 선택되면 상기 카메라를 통해 주변 영상을 획득하고, 획득된 영상을 보행 주의물 학습데이터를 바탕 (뒷면에 계속)"}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 휴대 전자기기를 이용한 보행주의 알림 방법 및 이러한 알림 방법을 실행시키기 위한 프로그램을 기 록한 컴퓨터 판독 가능한 기록 매체에 관한 것이다."}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대 사회에서는 스마트폰(smart phone)을 보면서 이동하는 사례가 증가하고 있다. 이런 결과로 스몸비(스마트 폰과 좀비의 단어가 합성된 신조어)라는 신조어가 발생할 정도이다. 또한, 스몸비에 대한 부작용으로 충돌, 추 락, 교통사고 등이 발생하고 있다. 이러한 사고를 방지하기 위한 여러 연구가 진행되고 있다. 예를 들어, 계단의 측면 가장자리에 램프를 설치하고, 계단의 진입 측에 패드 발판을 설치하여 보행자가 패드 발판을 밟는 경우 램프가 작동하여 보행자에 게 계단이 있음을 인식하게 하는 방식이 있다. 그런데, 이와 같은 방식은 보행자가 스마트폰에 집중하고 있는 경우 램프를 인지하지 못할 가능성이 있을 뿐만 아니라 설치 비용이 많이 드는 문제가 있다. 다른 예로, 사용자가 횡단보도에 이르렀을 때, 신호등 등에 설치된 장치에서 사용자에게 음성으로 횡단보도가 있다는 것을 알려주거나 램프 등으로 주의를 환기시키는 방식이 있다. 이러한 방식은 보행자가 현재 집중하고 있는 것(즉, 스마트론)으로부터 직접 주의 경보를 받는 것이 아니라, 관심 밖의 주변 대상을 통한 간접적 방식 으로 주의가 환기되는 것에 불과하기 때문에 스마트폰에 집중하면서 걷는 보행자로 인한 사고가 끊이지 않고 있 다."}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 휴대 전자기기의 사용자가 상기 휴대 전자기기의 전면에 표시된 화면을 보 면서 보행을 하는 과정에서 계단, 횡단보도, 신호등, 가로수, 인도 경계 등의 보행 주의물을 인식하지 못함으로 써 발생하는 안전사고를 예방하기 위한 휴대 전자기기의 제어방법과, 이러한 방법을 휴대 전자기기에서 실행시 키기 위한 프로그램을 기록한 컴퓨터 판독 가능한 기록 매체를 제공하는 것이다."}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 전면에 디스플레이가 배치되고 후면에는 카메라가 배치된 휴대 전자기기를 제어하는 방법에 관한 것 이다. 상기 휴대 전자기기를 제어하는 방법은, 상기 디스플레이를 통해 프리뷰 모드 선택 메뉴 및 백그라운드 모드 선택 메뉴가 표시되는 (a)단계와, 상기 (a)단계에서 상기 프리뷰 모드 선택 메뉴 또는 상기 백그라운드 모 드 선택 메뉴가 선택되면 상기 카메라를 통해 주변 영상을 획득하고, 획득된 영상을 보행 주의물 학습데이터를 바탕으로 학습된 인공신경망에 입력하여 보행 주의물을 검출하는 (b)단계를 포함하고, 상기 (b)단계는, 상기 프 리뷰 모드가 선택된 경우에는 상기 디스플레이를 통해 상기 카메라에 의해 획득된 주변 영상이 표시되면서 보행 주의물 검출이 이루어지는 프리뷰 모드를 실시하고, 상기 백그라운드 모드 선택 메뉴가 선택된 경우에는 상기 디스플레이에는 상기 카메라에 의해 획득된 주변 영상이 표시되지 않는 상태에서 보행 주의물의 검출 과정이 이 루어지는 백그라운드 모드를 실시하고, 상기 (b)단계에서의 보행 주의물 검출에 대응하여 상기 디스플레이를 통 해 보행주의 알림을 표시하는 (c)단계를 더 포함한다. 상기 휴대 전자기기를 제어하는 방법은, 상기 프리뷰 모드가 실시되는 중에 보행 주의물이 검출된 경우, 상기 디스플레이를 통해 표시되는 상기 주변 영상에 상기 보행 주의물을 표시하는 단계를 더 포함할 수 있다. 상기 휴대 전자기기를 제어하는 방법은, 상기 디스플레이를 통해, 위험분류 알림설정, 위험인식 설정, 위험요소 중복 안내 정지 및 위험요소 정보 저장 중 적어도 하나에 대한 선택을 입력 받을 수 있는 화면을 표시하는 (d) 단계를 더 포함할 수 있다. 상기 휴대 전자기기를 제어하는 방법은, 상기 위험요소 정보 저장이 선택된 경우, 상기 디스플레이릍 통해 상기 (b)단계에서 검출된 보행 주의물이 표시된 맵을 출력하는 단계를 더 포함할 수 있다. 본 발명의 다른 측면에 따르면, 본 발명은 상기 휴대전자 기기를 제어하는 방법을 휴대 전자기기에서 실행시키 기 위한 프로그램을 기록한 컴퓨터 판독 가능한 기록 매체에 관한 것이다."}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은, 사용자가 휴대 전자기기의 전면에 표시된 화면을 보면서 보행하는 중에도 카메라를 통해 주변의 보 행 주의물을 자동으로 검출하고 이를 사용자에게 알려주기 때문에 보행간의 안전사고를 예방할 수 있으며, 특히, 보행 주의물 검출이 기 학습된 인공신경망에 의해 매우 높은 정확도로 이루어지는 효과가 있다. 또한, 사용자가 휴대 전자기기를 통해 프리뷰 모드와 백그라운드 모드를 선택할 수 있어, 보행 주의물의 적극적 탐지(프리뷰 모드)할 수 있는 메뉴를 제공할 뿐만 아니라, 인터넷 기사를 보거나 SNS를 하는 등의 다른 작업을 하며 보행을 하는 중에는 백그라운드에서의 보행 주의물 탐지도 가능하여 사용 편의성이 향상되는 장점이 있다."}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2022-0028305", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 도 1은 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법에 적용되는 보행주의 알림시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른 제어방법이 적용되는 휴대 전자기기의 블록도이다. 도 1 내지 도 2를 참조하면, 본 발명의 일 실시예에 따른 보행주의 알림시스템은 휴대 전자기기와, 통신 망을 통해 휴대 전자기기와 통신하는 학습서버를 포함할 수 있다. 휴대 전자기기는, 휴대폰, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 디지털방송용 단말 기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 슬레이트 PC(slate PC), 태블릿 PC(tablet PC) 또는 울트라북(ultrabook) 등을 포함하는 개념일 수 있다. 휴대 전자기기는 프로세서, 메모리, 입력부, 통신부, 디스플레이, 카메라 및/또는 음향 출력부를 포함할 수 있다. 메모리는 프로세서의 동작을 위한 알고리즘, 어플리케이션 또는 프로그램을 저장할 수 있고, 입/출력되 는 데이터들(예를 들어, 폰북, 메시지, 정지영상, 동영상 등을 임시 저장할 수도 있다. 보행 주의물 검출을 위한 인공신경망이 메모리에 저장될 수 있다. 다만, 이에 한하지 않고, 상기 인공신경 망은 인터넷(internet) 상의 웹 스토리지(web storage)에 저장된 상태에서 전자기기와 연동될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마 이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램 (random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electricallyerasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 입력부는 사용자로부터 인가되는 휴대 전자기기의 동작 제어를 위한 제어명령에 대응하여 입력 데이터 를 발생시킨다. 입력부는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(정압/정전), 조그 휠, 조그 스위치 등으로 구성될 수 있다. 통신부는 통신망을 통해 정보를 송수신함으로써 통신망에 연결된 다른 기기(예를 들어, 학습서버 )와의 통신을 가능하게 하는 것이다. 통신부는 이동통신 모듈, 무선 인터넷 모듈 및 근거리 통신 모듈 중 적어도 하나를 포함할 수 있다. 디스플레이는 전자기기에서 처리되는 정보를 표시(출력)한다. 예를 들어, UI(User Interface) 또는 GUI(Graphic User Interface)가 디스플레이에 표시될 수 있다. 디스플레이는 전자기기의 전면을 구성할 수 있다. 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 이들 중 일부 디스플레이는 그를 통해 외부를 볼 수 있도록 투명형 또는 광투과형으로 구성될 수 있다. 이는 투 명 디스플레이라 호칭될 수 있는데, 상기 투명 디스플레이의 대표적인 예로는 TOLED(Transparant OLED) 등이 있 다. 카메라는 디지털 정지영상 또는 동영상을 획득하는 이미지 센서를 포함할 수 있으며, 상기 이미지 센서를 통해 획득된 영상은 메모리에 저장될 수 있다. 프로세서는 영상을 처리하여 디스플레이를 통해 표 시할 수 있다. 카메라는 전자기기의 후면을 구성할 수 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력할 수 있다. 음향 출력부는 전자기기에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음 등)과 관련된 음향 신 호를 출력하기도 한다. 특히, 음향 출력부는 인공신경망을 통해 보행 주의물이 검출된 경우, 사용자에게 이 를 알리는 알림음을 출력할 수 있다. 이러한 음향 출력부에는 리시버(receiver), 스피커(speaker), 버저 (buzzer) 등이 포함될 수 있다. 한편, 학습서버는 보행 주의물을 학습하는 머신러닝 디바이스이다. 학습서버는 인공신경망(Artificial Neural Network, ANN) 기반의 학습모델일 수 있다. 인공신경망은, 바람직하게는 합성곱 신경망(CNN: Convolutional Neural Network)이나, 반드시 이에 한정되어야 하는 것은 아니다. 이미 잘 알려진 것처럼 합성곱 신경망은 이미지 데이터 처리에 주로 사용되는 심층 신경망으 로, 컨볼루션(convolution)계층과 풀링(pooling) 계층을 이용하여 입력 데이터의 분향을 줄임으로서 복잡한 특 징을 추출할 수 있다. CNN은 입력 계층 다음에 컨볼루션, 렐루, 풀링 계층이 연결되고 이어서 완전연결(fully connected)계층이 이어 지고 최종적으로 소프트맥스 계층을 거쳐서 결과가 출력되는데, 컨볼루션 필터를 이미지의 각 부분에 순차적으 로 내적하기 때문에 가중치를 공유하고 입력 데이터의 크기를 줄일 수 있는 이점이 있다. CNN은 이미지 탐색 및 분류에 우수한 성능을 보이지만, 학습시에 자원을 많이 사용하는 점이 있다. 따라서, 연 산성능이 우수한 딥러닝머신, 예를 들어, 학습서버에서 동작하는 것은 무리가 없다. 그러나, 인공 신경망을 모바일 환경의 휴대 전자기기에 적용하기 위해서는 지원되는 자원의 제약으로 파라 미터(Parameter)를 줄여야 하므로 최소로 줄여야 적용이 가능하며, 성능도 유지해야 한다. 이러한 측면에서, 마지막 완전 연결 레이어(Fully Connected Layer: FC Layer)를 제외한 레이어 뒤에 비선형 배 치 표준 및 ReLU 또는 Leaky ReLU 함수가 적용된 모바일넷(Mobilenet) - CNN 모델을 적용하여 각 프레임별로 보 행 주의물을 검출하도록 구성될 수 있다. 도 3은 휴대 전자기기에서 보행주의 알림 어플리케이션이 구동되는 것을 보인 도면이다. 전자기기(10, 이하 스마트폰을 예로 듦)는 카메라를 통해 획득한 영상에서 인공 신경망 기반의 보행 주의물 을 검출하는 어플리케이션(또는, 앱)을 탑재하고 있으며, 이러한 어플리케이션은 메모리에 저장될 수 있다. 스마트폰의 전면에 배치된 디스플레이를 통해 화면이 출력되는 중에, 스마트폰의 후면에 배치된 카 메라에 의해 영상이 획득될 수 있다. 즉, 사용자가 상기 화면을 보면서 보행하는 중에 카메라는 사용자 주변의 영상을 획득하게 된다. 한손으로 스마트폰을 든 상태에서 고개를 숙여 화면을 보면서 보행하는 일반적인 형태를 고려할 시, 이때 카메라에 의해 획득되는 영상은 통상 보행자의 전방 바닥에서 획득된다고 할 수 있다. 프로세서는, 카메라에 의해 획득된 영상을 인공신경망에 입력하여 상기 영상으로부터 보행 주의물(예를 들어, 계단, 횡단보도, 신호등 가로수, 인도 경계 등)을 검출할 수 있다. 이러한 보행 주의물 검출 과정은 프로 세서에 의해 구동되는 프로그램의 백그라운드 프로세스(background process)에서 실시되며, 이때 워킹 프로 세스(working process 또는 foreground process)에서는 디스플레이에 소정의 화면을 표시하는 것에 할당될 수 있다. 여기서, 디스플레이에 표시되는 화면은 현재 구동중인 별도의 어플리케이션(예를 들어, 메신저, 웹브라우져, 게임 등)일 수 있다. 보행 주의물을 검출하기 위한 카메라의 동작은, 바람직하게는, 디스플레이에 소정의 화면이 표시된 상 태에서 사용자가 보행 중일 때에 이루어질 수 있다. 이때, 사용자의 보행을 감지하는 센서(미도시)가 더 구비될 수 있다. 상기 센서는 자이로, 가속도계 및 GPS 모듈 중 적어도 하나를 포함할 수 있다. 다르게는, 상기 센서는 사용자의 생체 신호를 감지하는 것일 수 있으며, 예를 들어, 인체의 지문, 동공 또는 안면을 인식하는 센서일 수 있다. 다르게는, 보행 주의물을 검출하기 위한 카메라의 동작은, 입력부를 통해 입력된 보행 주의물 감지 명 령에 따라 이루어질 수 있다. 예를 들어, 디스플레이에 표시되는 화면에 보행 주의물 감지 메뉴가 생성되고, 사용자가 상기 메뉴를 선택한 경우 보행 주의물 감지를 위한 카메라의 동작이 실시될 수 있다. 한편, 프로세서는 카메라에 의해 획득된 동영상으로부터 기 설정된 간격으로 이미지 프레임(image frame)을 추출하고, 이렇게 추출된 이미지를 CNN에 입력하여 보행 주의물을 검출할 수 있다. 프로세서는, 바람직하게는, 동영상으로부터 100ms마다 이미지 프레임을 추출하나 반드시 이에 한정되어야 하는 것은 아니다. 도 4는 보행주의 알림방법에서 보행 주의물 학습 과정을 도시한 순서도이다. 도 4를 참조하면, 본 발명의 일 실 시예에서 이루어지는 인공신경망의 학습은 보행 주의물 학습을 위한 마련된 다수의 이미지들을 CNN에 입력하기 위해 처리하는 전처리단계(S110)와, 전처리된 이미지를 CNN에 입력하여 보행 주의물을 학습하는 단계(S120)를 포함할 수 있다. 이러한, 보행 주의물 학습은 학습서버에서 수행될 수 있다. 먼저, 계단, 횡단보도, 가로수, 인도 경계 등의 보행 주의물이 표현된 다수의 이미지를 준비한다. 이러한 이미 지들은 직접 촬영하거나, 인터넷 사이트를 통해 수집할 수 있다. 이렇게 마련된 학습(learning) 또는 훈련(training) 이미지들에 바운딩 박스(bounding box) 작업을 진행한다. 이 과정은 준비된 이미지들에서 보행 주의물에 경계박스를 표시하고, 상기 경계박스가 지시하는 보행 주의물의 정보를 라벨링(labelling)하는 단계(S110)를 포함할 수 있다. 이러한 작업은 labellmg, CVAT, LabelMe, Labelbox, VoTT, imglab, YOLO Mark, PixelAnnotaionTool, OpenLabeling, imagetagger, Alturos.ImageAnnotation, DeepLabel, MedTagger, Turktools, Pixie, OpenLabeler, Anno-Mage, CATMAID, makesense.ai, LOST, annotorious, sloth 등의 공지된 어플리케이션을 이용하여 수동 또는 자동으로 이루어질 수 있다. 이렇게 전처리된 데이터는 인공신경망이 훈련하는 정답지(Ground true)로 활용될 수 있다. 학습단계(S120)는 S110단계에서 준비된 라벨링된 이미지들을 인공신경망에 입력하여 보행 주의물을 학습하는 단 계이다. 전술한 바와 같이 상기 인공신경망은 CNN일 수 있으나, 반드시 이에 한정되어야 하는 것은 아니며, 공 지된 다른 ANN도 가능하다. 도 6은 신경망의 학습 결과를 검증한 바운딩 박스 로스 그래프(bounding box loss graph)이다. 도 7은 신경망의 학습 결과를 검증한 클래스 정확도 그래프(class accuracy graph)이다. 신경망을 통과하고, 학습된 자료에 대한 검증으로 Bounding Box의 Loss와 Class에 대한 Accuracy는 각각 다른 수식을 적용했다. Bounding Box에 대한 것은 Mean Squared Error를 적용하였으며, Class에 대한 것은 Categorical Crossentropy를 적용했다. 도 6에서 보이는 바와 같이, Training Loss는 5.3이며, Validation Loss 103.1 이다. 이와 같은 이유는 Stair, Crosswalk이라는 전체 객체를 Bonding Box에 넣는 경우도 있고, 회전형 혹은 굴곡이 있는 계단의 경우 일부만 Bounding Box에 포함시켰기 때문이다. Training 곡선을 확인해 보면, 비교적 명확한 보행 주의물 구분 때문에 급속하게 Loss가 줄어드는 것을 확인할 수 있다. 그리고, 도 7을 참조하면, Class Accuracy는 Training시에 1에 수렴하고, Validation시에 0.978에 이르는 정확 도를 보이고 있다. 이러한 결과는 도 8을 통해서도 알 수 있다. 한편, S110단계에서의 학습 또는 훈련이 완료되면, 훈련결과를 스마트 폰으로 이식하여 보행 주의물 검출에 적 용할 수 있다. 휴대용 전자제품(특히, 스마트폰)은 아직 딥러닝 전용 머신에 비해서 전산능력(computing source)이나 자원(resource)가 부족하기 때문에 학습서버에서 학습된 결과를 바탕으로 보행 주의물 검출을 하게 된다. 특히, 스마트폰은 자원이 제한되어 있기 때문에 동시간에 이미지 인식과 표현을 하지 못하는 단점이 있다. 따라 서, 인공신경망을 이용한 보행 주의물 인식은 백그라운드에서 진행하고 사용자에게는 결과만 표현해 주는 방식 이 적합하다. 도 5는 보행주의 알림방법을 도시한 순서도이다. 도 5에 도시된 단계들은 휴대 전자기기에서 실시될 수 있 다. 구체적으로, 본 발명의 일 실시예에 따른 보행주의 알림방법은, 주변 영상 획득단계(S210), 보행 주의물 검 출 단계(S220), 판정 단계(S230), 경고 알림단계도면(S240)를 포함할 수 있다. 주변 영상 획득단계(S210)는, 휴대 전자기기의 전면에 구비된 디스플레이를 통해 화면이 표시되고 있는 상태에서 후면에 배치된 카메라를 통해 주변 영상을 획득하는 단계이다. 전술한 바와 같이, 디스플레이를 통한 화면의 표시는 포그라운드(foreground) 프로세스에서 이루어지고, 카 메라를 통한 주변 영상의 획득과 처리는 백그라운드 프로세스에서 이루어질 수 있다. S220단계에서는, S210단계에서 획득된 영상을 보행 주의물 학습데이터를 바탕으로 학습된 인공신경망에 입력하 여 보행 주의물을 검출한다. 상기 인공신경망은, 바람직하게는, CNN이며, 전술한 바와 같이 학습서버에서 학습된 결과를 바탕으로 구성된 것일 수 있다. 여기서, CNN에 기반한 이미지 검출 과정은, 전술한 학습서버에서 학습 또는 훈련 과정에서 보행 주의물을 분류(classification)하는 것과 실질적으로 동일한 방식으로 이루어질 수 있다. 구체적으로, S210단계에서 획득된 영상이 CNN의 입력으로 입력되고, 인공지능 기반의 분류 작업을 통해 인공신 경망의 출력으로써 얻어진 결과를 바탕으로 보행 주의물을 검출하게 된다.(S220) 이후, 보행 주의물이 검출된 것으로 판정(S230)되면, 전자기기의 사용자가 이를 인지할 수 있게 알리는 단 계가 실시될 수 있다.(S240) S230단계에서의 알림은 음향 출력부 및 디스플레이 중 적어도 하나를 통해 이루어질 수 있다. 보행 주 의물을 검출하는 과정에 보행자가 디스플레이의 화면에 집중하고 있는 상태에서 이루어지기 때문에 디스플 레이의 화면을 통해 보행 주의물이 발견되었음을 알리는 메시지를 출력하거나, 상기 보행 주의물의 이미지 가 표시되도록 하는 것이 바람직하다. 도 9는 모바일넷 표준 모델의 구조도(MobileNet Body Architecture)이다. 도 10은 보행 주의물 검출 모델의 구 조도이다. 도 9 내지 도 10을 참조하면, 본 발명의 일 실시예에 따른 보행 주의물 검출을 위한 인공신경망은 모바일에서도 사용 가능하도록 설계될 수 있으며, 이러한 측면에서 파라미터(Parameter)의 개수를 획기적으로 줄이는 동시에 성능이 저하되지 않아야 한다는 점을 전재로, 학계 및 재계에서 연구되고 있는 신경망을 채택하고 Transfer- Learning을 구현하였다. 보다 상세하게, '보행 주의물 검출을 위한 인공신경망'은 Google Inc.에서 발표한 모바일넷(Mobilenet v1) 표준 모델(도 9 참조.)을 구성하는 n개의 레이어(layer)에서 n-2번째부터 최종 n번째 레어어를 제거하였으며, n-3번 째 레이어의 결과를 이용하여 분류(classification)와 객체 탐지(object detection)을 수행하도록 구성된다. 여 기서, 분류는 Global average pooling Layer를 이용하며, 객체 탐지는 Convolutional Layer를 이용할 수 있다. 참고로, 도 9에 도시된 것은 표준규격에 해당하며, 실제 활용시에는 stride, filter shape, input size는 적절 하게 변경될 수 있다. 출원인은 여러가지 실험을 해본 결과 신경망에 입력되는 영상이 128*128*3인 경우 가장 빠른 학습이 이루어지고, 좋은 결과를 나온다는 것을 알 수 있었고, 이를 실시예에 적용하였다.도 9 내지 도 10에서 보이는 바와 같이, '보행 주의물 검출을 위한 인공신경망'은 모바일넷의 Average Pooling Layer, Fully Connected Layer, 그리고 Softmax Layer는 사용하지 않으며, 13번째 Convolutional Layer에서 나 온 결과가 공통으로 입력되는 분류기(classifier)와 객체 탐지기(object detector)를 포함할 수 있다. 여기서, 상기 분류기는 영상에서 검출된 보행 주의물을 분류하는 것으로써, 1개의 Average Pooling Layer와 적 어도 하나의 Dense Layer를 포함하며, Class 정보를 얻도록 구성될 수 있다. 실시예에서와 같이 Dense Layer는 바람직하게는 4개이나, 반드시 이에 한정되어야 하는 것은 아니다. 상기 객체 탐지기는 영상에서 보행 주의물을 탐지하는 것으로써 적어도 하나의 Convolutional Layer, 적어도 하 나의 Flatten Layer 및 적어도 하나의 Dense Layer를 포함하며, Bounding Box의 정보를 얻도록 구성될 수 있다. 실시예에서 Convolutional Layer, Flatten Layer 및 Dense Layer는 각각 1개씩이나, 반드시 이에 한정되 어야 하는 것은 아니다. 한편, 실재 학습시에는 모바일넷은 학습되지 않고, 신규로 추가한 분류/객체 탐지를 위한 레이어들만 학습을 진 행할 수 있다. 한편, 전술한 '보행 주의물 검출을 위한 인공신경망'을 휴대용 전자기기(예를 들어, 스마트폰)에 적용하기 위해 서 Tensorflow-lite가 이용될 수 있다. Tensorflow-lite는, 백그라운드 스레드(Background Thread)에서 카메 라에 의해 영상이 획득되는 동안 100ms단위로 이미지 프레임이 추출되고, 그 추출된 이미지를 탐지 스레드 (Detection Thread)로 보낼 수 있다. Detection Thread에서는 Tensorflow Lite에 기 저장되어 있는 학습데이 터(즉, 전술한 학습과정에서 학습된 것)를 바탕으로 보행 주의물을 판단할 수 있다. 도 11은 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법이 개념도이다. 도 12는 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법이 기록된 애플리케이션의 구성도이다. 도 13 내지 도 17은 본 발명의 일 실시예 에 따른 휴대 전자기기의 제어방법에 따라 디스플레이에 표시되는 화면들을 보인 것이다. 이하, 도 11 내지 도 17을 참조하여, 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법을 설명한다. 도 11을 참조하면, 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법은, 휴대 전자기기에 탑재된 앱 또는 애플리케이션(application, 이하, '보행 주의물 알림 앱'이라고 함.)을 구동함으로써 구현될 수 있다 . 애플리케이션이 구동되면 전술한 인공신경망을 통한 보행 주의물 검출이 실시되며, 이러한 보행 주의물 검 출은 백그라운드 모드(52a) 또는 프리뷰 모드(52b)로 실시될 수 있다. 사용자는 애플리케이션을 통해 제공 되는 선택 메뉴들을 통해 백그라운드 모드와 프리뷰 모드를 선택할 수 있다. 백그라운드 모드와 프리뷰 모드 중 어느 것이 선택되더라도, 카메라를 통해 주변 영상이 획득됨과 동시에, 앞서 설명한 인공신경망 모델을 바탕으로 한 보행 주의물 검출이 실시된다. 다만, 백그라운드 모드에서는, 카메 라에 의해 획득된 주변 영상이 디스플레이의 화면에는 출력되지 않으나, 프리뷰 모드에서는 출력되는 차이가 있다. 횡단보도와 같은 보행 주의물이 검출되는 경우, 디스플레이를 통해 경고, 즉, 보행주의 알림이 출력되 며, 이 경우, 디스플레이의 화면에는 팝업 형태의 알림창이 표시될 수 있다. 상기 알림창은 확인 메뉴를 포함하여 구성될 수 있으며, 사용자가 상기 확인 메뉴를 선택하는 경우, 상기 알림 창이 닫히고 다시 백그라운드 모드(55a)나 프리뷰 모드(55b)의 기본 화면이 디스플레이의 화면에 표시될 수 있다. 보행 주의물 알림 앱은 설정메뉴를 더 제공할 수 있으며, 이에 대해서는 도 12 내지 도 17을 참조하여 보다 상 세하게 후술하기로 한다. 사용자가 원격 서버로부터 보행 주의물 알림 앱을 다운로드하여 회원가입, 환경동의 등의 절차를 거쳐 앱 설치 를 완료한 후(301~304), 앱을 구동하면, 프로세서는 디스플레이에 메인 화면이 출력되도록 제어할 수 있다. 메인 화면은 프리뷰 모드 선택 메뉴(Preview mode, 401), 백그라운드 모드 선택 메뉴(Background mode, 402) 및 설정 모드 선택 메뉴(Setting mode, 403) 중 적어도 하나를 포함할 수 있다.프리뷰 모드가 선택되면, 프로세서는, 현재 카메라를 통해 획득되고 있는 영상을 표시한 화면 이 디스플레이를 통해 출력되도록 제어할 수 있다. 이때, 화면에는 백그라운드 모드로의 전환 명 령을 입력 받는 백그라운드 모드 선택 메뉴 및 설정 모드로의 전환 명령을 입력 받는 설정 모드 선택 메뉴 중 적어도 하나가 함께 표시될 수 있다. 프리뷰 모드가 실시되고 있는 중에, 프로세서는 보행 주의물 검출을 계속하여 실시할 수 있다(S210~S240). 이 과정에서 보행 주의물이 검출되는 경우, 프로세서는 화면에 출력되고 있는 획득 영상에 보행 주의물 식별표지가 표시되도록 제어할 수 있다. 화면에는 백그라운드 모드 선택 메뉴와 설정 모드 선택 메뉴 중 적어도 하나가 더 표시될 수 있 으며, 이들 모드 선택 메뉴(406, 407)는 메인 화면에 표시된 모드 선택 메뉴들(402, 403)과 실질적으로 같 은 것이다. 이후, 프로세서는 디스플레이를 통해 보행주의 알림(경고 메시지, 307)가 표시되도록 제어할 수 있다. 이때, 프로세서는 휴대 전자기기에 탑재된 스피커를 경고음이 출력되도록 제어하는 것도 가능하고, 다 르게는, 휴대 전자기기에 탑재된 햅틱 기능을 통해 진동 형태로 경고를 출력하는 것도 가능하다. 한편, 도면에서 보이는 바와 같이, 보행주의 알림이 표시된 화면에는 메인 화면(309/305)으로의 복귀를 위 한 선택 메뉴와 이전 화면(306, 308)으로의 복귀를 위한 선택 메뉴가 더 표시될 수 있다. 도 15를 참조하면, 메인 화면에서 백그라운드 모드 선택 메뉴가 선택되면, 카메라에 의해 획득된 주변 영상이 디스플레이에는 표시되지 않는 상태에서 보행 주의물의 검출 과정이 이루어지는 백그라운드 모 드가 실시된다. 화면에서 보이는 바와 같이, 백그라운드 모드가 실시되는 중에는 보행 주의물 알림 앱과 관련 없는 다른 화면, 즉, 화면 305 내지 309 이외의 다른 화면, 예를 들어, 휴대 전자기기에서 제공하는 기기의 바탕화면 이 표시될 수 있다. 상기 바탕화면에는 보행 주의물 알림 앱이 백그라운드에서 구동되고 있음을 알리는 알림창 이 표시될 수 있다. 백그라운드 모드가 실시되는 중에, 프로세서는 보행 주의물 검출(S210~ S240)을 계속하여 실시하며, 이 과 정에서 보행 주의물의 검출되는 경우, 프로세서는 디스플레이를 통해 보행주의 알림(경고 메시지, 31 2)가 표시되도록 제어할 수 있다. 이때, 프로세서는 휴대 전자기기에 탑재된 스피커를 경고음이 출력되 도록 제어하는 것도 가능하고, 다르게는, 휴대 전자기기에 탑재된 햅틱 기능을 통해 진동 형태로 경고를 출 력하는 것도 가능하다. 보행주의 알림이 표시된 화면에는 메인 화면(310/314)으로의 복귀를 위한 선택 메뉴와 이전 화면 (311/313)으로의 복귀를 위한 선택 메뉴가 더 표시될 수 있다. 도 16 내지 도 17을 참조하면, 메인 화면에서 설정 모드 선택 메뉴가 선택되면, 프로세서는 디스 플레이를 통해 각종 선택이나 설정들을 조정할 수 있는 메뉴들로 구성된 화면이 출력되도록 제어할 수 있다. 화면에는 주의물 알림 앱의 사용방법 출력을 선택하는 메뉴, 휴대 전자기기가 구동될 시 자 동으로 주의물 알림 앱이 실행되도록 설정하는 자동실행 설정 메뉴, 주의물 알림 앱 관련 알림을 수신할 것인지 선택하는 알림 수신 설정 메뉴, 주의물 알림 앱을 통해 알림을 제공하고자 하는 주의물(또는, 위험 요소)에 대한 설정을 입력을 위한 메뉴(318, 위험분류 알림 설정 메뉴)가 출력되도록 하는 명령을 입력 받는 위 험분류 알림 메뉴, 위험인식 설정 메뉴가 출력되도록 하는 명령을 입력 받는 위험인식 설정 메뉴 및 위험 요소(보행 주의물)를 중복하여 안내 것에 대한 중지 여부를 선택할 수 있는 위험 요소 중복 안내 정지 메뉴 중 적어도 하나가 표시될 수 있다. 위험분류 알림 설정 메뉴는 보행주의 알림 대상을 선택할 수 있는 메뉴를 제공하는 것일 수 있다. 실시예 에서는 계단과 횡단보도 중 적어도 하나를 선택할 수 있도록 구성되나 반드시 이에 한정되어야 하는 것은 아니 며, 학습을 통해 인식 가능한 다른 보행 주의물들을 선택할 수 있도록 구성되는 것도 가능하다. 위험인식 설정 메뉴는, 보행 주의 알림 또는 경고 알림단계(S240)가 사용자로부터 보행 주의물까지의 거리 를 고려하여 실행될 수 있도록, 알림단계(S240)의 실행 기준이 되는 거리, 즉, 알림 기준 거리를 설정하는 메뉴를 제공하는 것일 수 있다. 상기 알림 기준 거리는, S220 단계에서 검출된 보행 주의물이 디스플레이의 화면에서 차지하는 비율(예를 들어, 면적 비)을 바탕으로 정의되는 것일 수 있다. 즉, 같은 보행 주의물이라도 카메라로부터 거리가 가까 울수록 화면에서 차지하는 비율이 커진다는 원리를 이용한 것으로, 희망하는 알림 기준 거리에 대응하여 상기 비율(즉, 도 16의 '카메라 비율')을 미리 사용자가 설정할 수 있다. 이후, 프로세서는, S220단계에서 검출 된 보행 주의물로 사용자가 접근하는 과정에서 사용자 또는 카메라로부터 상기 보행 주의물까지의 거리가 설정된 알림 기준 거리에 이른 경우 알림단계(S240)가 실시되도록 제어할 수 있다. 실시예에서는, 위험인식 설정 메뉴를 통해 원거리(카메라 비율 20%), 중간 거리(카메라 비율 30%) 또는 근 접거리(카메라 비율 50%) 중 어느 하나로 상기 알림 기준 거리를 설정할 수 있도록 구성되나, 반드시 이에 한정 되어야 하는 것은 아니며, 선택 가능한 거리 종류나 거리 간격을 다르게 구성할 수도 있고, 카메라 비율을 사용 자가 임으로 입력할 수 있도록 구성되는 것도 가능하다. 더 나아가, 프로세서는 디스플레이를 통해 자동업데이트 설정 메뉴 및/또는 위험요소 정보 저장 메뉴가 표시되도록 제어할 수 있다. 특히, 위험요소 정보 저장 메뉴가 선택되는 경우, 프로세서는 보행 주의물(또는, 위험요소)이 검출된 위치를 메모리에 저장하고, 이렇게 저장된 위치 정보를 바탕으로 맵(323, 324) 상에 위험요소들을 표시할 수 있다. 이러한 과정은 보행 주의물의 검출이 있을 시 마다 자동으로 이루어질 수 있으며, 따라서 맵(323, 324)에는 그동안 검출된 보행 장애물들의 위치를 사용자에게 제공하는 기능을 하게 된다. 한편, 맵(323, 324)은 메모리에 기 저장된 것이며, 프로세서는 휴대 전자기기에 탑재된 GPS나 WiFi 디바이스를 바탕으로 현재 사용자의 위치정보를 획득하여 맵에 표시되도록 제어할 수 있다. 프로세서는 현 재 사용자의 위치 정보를 바탕으로, 현 위치 주변 지역에서 보행 주의물의 위치들이 표시된 맵(323, 324)이 표 시되도록 제어할 수 있다. 다르게는, 맵(323, 324)을 통해 사용자의 목적지와, 목적지까지 이르는 경로가 표시될 수 있으며, 이 경우, 프 로세서는, 기 저장된 보행 주의물들에 대한 정보를 바탕으로, 상기 경로 상에서 검출된 보행 주의물들이 맵 상에 표시되도록 제어할 수 있다. 이때, 맵(323, 324)상에는 보행 주의물의 위치뿐만 아니라, 보행 주의물의 종 류도 표시될 수 있다. 프로세서는 사용자의 터치 동작에 대응하여 맵(323, 324)을 이동, 축소, 확대시킬 수 있다. 이상에서 설명한 메뉴들은 디스플레이의 한 화면에 함께 표시될 수도 있으나, 실시예에서와 같이 디스플레 이의 물리적 면적보다 더 큰 영역에 메뉴들이 배치되고, 스크롤 방식의 표시 영역 이동을 통해 대응하는 메 뉴가 디스플레이에 표시되는 것도 가능함은 물론이다. 본 발명에 관한 컴퓨터 판독 가능한 기록 매체는, 상술한 현상 방법을 현상 장치에 실행시키기 위한 프로그램을 기록하고 있다. 본 명세서에 있어서, 컴퓨터 판독 가능한 기록 매체에는, 일시적이지 않은 유형의 매체 (nontransitory computer recording medium)(예를 들어, 각종 주기억 장치 또는 보조 기억 장치)나, 전파 신호 (transitory computer recording medium)(예를 들어, 네트워크를 통해 제공 가능한 데이터 신호)가 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17"}
{"patent_id": "10-2022-0028305", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법에 적용되는 보행주의 알림시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른 제어방법이 적용되는 휴대 전자기기의 블록도이다. 도 3은 휴대 전자기기에서 보행주의 알림 어플리케이션이 구동되는 것을 보인 도면이다. 도 4는 보행주의 알림방법에서 보행 주의물 학습 과정을 도시한 순서도이다. 도 5는 보행주의 알림방법을 도시한 순서도이다. 도 6은 신경망의 학습 결과를 검증한 바운딩 박스 로스 그래프(bounding box loss graph)이다. 도 7은 신경망의 학습 결과를 검증한 클래스 정확도 그래프(class accuracy graph)이다. 도 8은 인공신경망을 통해 보행 주의물을 검출한 결과들이다. 도 9는 모바일넷 표준 모델의 구조도(MobileNet Body Architecture)이다. 도 10은 보행 주의물 검출 모델의 구조도이다. 도 11은 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법이 개념도이다. 도 12는 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법이 기록된 애플리케이션의 구성도이다. 도 13 내지 도 17은 본 발명의 일 실시예에 따른 휴대 전자기기의 제어방법에 따라 디스플레이에 표시되는 화면 들을 보인 것이다."}
