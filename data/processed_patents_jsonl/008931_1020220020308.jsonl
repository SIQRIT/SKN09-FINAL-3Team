{"patent_id": "10-2022-0020308", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0123309", "출원번호": "10-2022-0020308", "발명의 명칭": "프루닝 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "김종석"}}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습된 인공 신경망의 가중치 중요도를 결정하는 단계;연산의 자원(resource)과 관련된 제한 조건을 수신하는 단계; 및상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대화할 수 있는 프루닝 마스크(pruningmask)를 결정하는 단계를 포함하는 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프루닝 마스크를 결정하는 단계는입력 채널의 프루닝 이진 벡터를 결정하는 단계; 및출력 채널의 스파셜(spartial) 프루닝 이진 벡터를 결정하는 단계를 포함하는, 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프루닝 마스크에 기초하여, 상기 인공 신경망을 프루닝하는 단계를 더 포함하는, 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프루닝된 상기 인공 신경망에 기초하여, 추론을 수행하는 단계를 더 포함하는, 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 프루닝하는 단계는결정된 입력 채널의 프루닝 이진 벡터에 기초하여, 입력 채널의 가중치들을 프루닝하는 단계; 및결정된 출력 채널의 스파셜 프루닝 이진 벡터에 기초하여, 출력 채널의 스파셜한 방향으로 가중치들을 프루닝하는 단계를 포함하는, 프루닝 방법.공개특허 10-2023-0123309-3-청구항 6 제1항에 있어서,상기 가중치 중요도를 결정하는 단계는상기 가중치 중요도를 입력 채널의 프루닝 이진 벡터 및 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하는 단계를 더 포함하고,상기 제한 조건을 수신하는 단계는상기 제한 조건을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도하나로 표현하는 단계를 더 포함하는, 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프루닝 마스크를 결정하는 단계는상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대화할 수 있는 최적화 식을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하는 단계를 포함하는, 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프루닝 마스크를 결정하는 단계는이진 벡터 최적화 알고리즘에 기초하여, 상기 최적화 식에 대응하는 상기 프루닝 마스크를 결정하는 단계를 포함하는, 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 가중치 중요도를 결정하는 단계는상기 인공 신경망의 가중치의 절대값 및 오차의 그래디언트(gradient) 절대값 중 적어도 하나에 기초하여, 상기가중치 중요도를 결정하는 단계를 포함하는, 프루닝 방법."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어와 결합되어 제1항 내지 제9항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2023-0123309-4-전자 장치에 있어서,메모리 및 프로세서를 포함하고,상기 메모리는 상기 프로세서에 의해 실행 가능한 인스트럭션들(instructions)을 저장하고,상기 인스트럭션들이 상기 프로세서에 의해 실행될 때, 상기 프로세서는 상기 전자 장치가학습된 인공 신경망의 가중치 중요도를 결정하고, 연산의 자원(resource)과 관련된 제한 조건을 수신하고,상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대화할 수 있는 프루닝 마스크(pruningmask)를 결정하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는 상기 전자 장치가입력 채널의 프루닝 이진 벡터를 결정하고,출력 채널의 스파셜 프루닝 이진 벡터를 결정하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 프로세서는 상기 전자 장치가입력 채널의 프루닝 이진 벡터를 결정하고,출력 채널의 스파셜 프루닝 이진 벡터를 결정하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는 상기 전자 장치가상기 프루닝된 상기 인공 신경망에 기초하여, 추론을 수행하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 프로세서는 상기 전자 장치가결정된 입력 채널의 프루닝 이진 벡터에 기초하여, 입력 채널의 가중치들을 프루닝하고,결정된 출력 채널의 스파셜 프루닝 이진 벡터에 기초하여, 출력 채널의 스파셜한 방향으로 가중치들을 프루닝하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,공개특허 10-2023-0123309-5-상기 프로세서는 상기 전자 장치가상기 가중치 중요도를 입력 채널의 프루닝 이진 벡터 및 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하고,상기 제한 조건을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도하나로 표현하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 프로세서는 상기 전자 장치가상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대화할 수 있는 최적화 식을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하도록 상기 전자장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는 상기 전자 장치가이진 벡터 최적화 알고리즘에 기초하여, 상기 최적화 식에 대응하는 상기 프루닝 마스크를 결정하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 프로세서는 상기 전자 장치가상기 인공 신경망의 가중치의 절대값 및 오차의 그래디언트(gradient) 절대값 중 적어도 하나에 기초하여, 상기가중치 중요도를 결정하도록 상기 전자 장치를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "프루닝 방법 및 장치가 개시된다. 일 실시예에 따른 프루닝 방법은 학습된 인공 신경망의 가중치 중요도를 결정 하는 단계, 연산의 자원(resource)과 관련된 제한 조건을 수신하는 단계 및 제한 조건 내에서, 인공 신경망의 가 중치 중요도를 최대화할 수 있는 프루닝 마스크(pruning mask)를 결정하는 단계를 포함한다."}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 프루닝 방법 및 장치에 관한 것으로, 보다 구체적으로는 인공 신경망의 사용가능한 자원을 최 대한 활용하는 컨볼루션 연산의 2D 필터 상의 구조적인 프루닝 방법에 관한 것이다."}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망(neural network)은 생물학적 뇌를 모델링한 컴퓨터 과학적 아키텍쳐(computational architectur e)를 참조한다. 최근 인공 신경망 기술이 발전함에 따라, 다양한 종류의 전자 시스템에서 인공 신경망 장치를 사용하여 입력 데이터를 분석하고 유효한 정보를 추출하는 연구가 활발히 진행되고 있다. 인공 신경망 장치는 복잡한 입력 데이터에 대한 많은 양의 연산을 필요로 한다. 한편, 인공 신경망의 학습 양이 증가함에 따라, 인공 신경망을 구성하는 연결성이 복잡해지고, 과거의 학습 데이터에 대하여 정확도가 증가하나 새로운 데이터에 대한 예측 값의 신뢰성이 저하되는 과적합(Over Fitting) 문제가 발생한다. 또한, 인공 신경망 의 복잡도가 증가하고, 이로 인하여, 메모리 할당량이 과도하게 증가함에 따라, 소형화 및 상용화에 있어서 문 제가 발생한다.따라서, 인공 신경망의 성능을 유지하면서 인공 신경망의 구현에 있어서 시스템 비용을 감소시키기 위한 압축 방법이 요구된다."}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 프루닝 방법은 학습된 인공 신경망의 가중치 중요도를 결정하는 단계; 연산의 자원(resourc e)과 관련된 제한 조건을 수신하는 단계; 및 상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대화할 수 있는 프루닝 마스크(pruning mask)를 결정하는 단계를 포함한다. 상기 프루닝 마스크를 결정하는 단계는 입력 채널의 프루닝 이진 벡터를 결정하는 단계; 및 출력 채널의 스파셜 (spartial) 프루닝 이진 벡터를 결정하는 단계를 포함할 수 있다. 일 실시예에 따른 프루닝 방법은 상기 프루닝 마스크에 기초하여, 상기 인공 신경망을 프루닝하는 단계를 더 포 함할 수 있다. 일 실시예에 따른 프루닝 방법은 상기 프루닝된 상기 인공 신경망에 기초하여, 추론을 수행하는 단계를 더 포함 할 수 있다. 상기 프루닝하는 단계는 결정된 입력 채널의 프루닝 이진 벡터에 기초하여, 입력 채널의 가중치들을 프루닝하는 단계; 및 결정된 출력 채널의 스파셜 프루닝 이진 벡터에 기초하여, 출력 채널의 스파셜한 방향으로 가중치들을 프루닝하는 단계를 포함할 수 있다. 일 실시예에 따른 프루닝 방법은 상기 가중치 중요도를 결정하는 단계는 상기 가중치 중요도를 입력 채널의 프 루닝 이진 벡터 및 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하는 단계를 더 포함하고, 상기 제한 조건을 수신하는 단계는 상기 제한 조건을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파 셜 프루닝 이진 벡터 중 적어도 하나로 표현하는 단계를 더 포함할 수 있다. 상기 프루닝 마스크를 결정하는 단계는 상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대 화할 수 있는 최적화 식을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하는 단계를 포함할 수 있다. 상기 프루닝 마스크를 결정하는 단계는 이진 벡터 최적화 알고리즘에 기초하여, 상기 최적화 식에 대응하는 상 기 프루닝 마스크를 결정하는 단계를 포함할 수 있다. 상기 가중치 중요도를 결정하는 단계는 상기 인공 신경망의 가중치의 절대값 및 오차의 그래디언트(gradient) 절대값 중 적어도 하나에 기초하여, 상기 가중치 중요도를 결정하는 단계를 포함할 수 있다. 일 실시예에 따른 전자 장치는 메모리 및 프로세서를 포함하고, 상기 메모리는 상기 프로세서에 의해 실행 가능 한 인스트럭션들(instructions)을 저장하고, 상기 인스트럭션들이 상기 프로세서에 의해 실행될 때, 상기 프로 세서는 상기 전자 장치가 학습된 인공 신경망의 가중치 중요도를 결정하고, 연산의 자원(resource)과 관련된 제 한 조건을 수신하고, 상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대화할 수 있는 프루 닝 마스크(pruning mask)를 결정하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 입력 채널의 프루닝 이진 벡터를 결정하고, 출력 채널의 스파셜 프루닝 이진 벡터를 결정하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 입력 채널의 프루닝 이진 벡터를 결정하고, 출력 채널의 스파셜 프루닝 이진 벡터를 결정하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 상기 프루닝된 상기 인공 신경망에 기초하여, 추론을 수행하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 결정된 입력 채널의 프루닝 이진 벡터에 기초하여, 입력 채널의 가중치들을 프루닝하고, 결정된 출력 채널의 스파셜 프루닝 이진 벡터에 기초하여, 출력 채널의 스파셜한 방향으로 가중치들을 프루닝하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 상기 가중치 중요도를 입력 채널의 프루닝 이진 벡터 및 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하고, 상기 제한 조건을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파셜 프루닝 이진 벡터 중 적어도 하나로 표현하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 상기 제한 조건 내에서, 상기 인공 신경망의 상기 가중치 중요도를 최대화할 수 있는 최적화 식을 상기 입력 채널의 프루닝 이진 벡터 및 상기 출력 채널의 스파셜 프루닝 이진 벡터 중 적 어도 하나로 표현하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 이진 벡터 최적화 알고리즘에 기초하여, 상기 최적화 식에 대응하는 상기 프 루닝 마스크를 결정하도록 상기 전자 장치를 제어할 수 있다. 상기 프로세서는 상기 전자 장치가 상기 인공 신경망의 가중치의 절대값 및 오차의 그래디언트(gradient) 절대 값 중 적어도 하나에 기초하여, 상기 가중치 중요도를 결정하도록 상기 전자 장치를 제어할 수 있다."}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면을 참 조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1은 일 실시예에 따른 인공 신경망에서 수행되는 연산을 설명하기 위한 도면이다. 인공 신경망이란 사람의 두뇌가 정보를 처리하는 방식을 모방한 연산 시스템이다. 심층 신경망(Deep Neural Network)은 인공 신경망을 구현하는 하나의 방식으로서, 복수의 레이어(layer)를 포함 할 수 있다. 예를 들어, 심층 신경망은 입력 데이터가 인가되는 입력 레이어(Input Layer), 학습을 바탕으로 입력 데이터에 기반한 예측을 통해 도출된 결과 값을 출력하는 출력 레이어(Output Layer) 및 입력 레이어와 출 력 레이어 사이에 다중의 은닉 레이어(Hidden Layer)을 포함한다. 심층 신경망은 정보를 처리하기 위해 이용되는 알고리즘에 따라, 컨볼루션 신경망(Convolutional Neural Network), 리커런트 신경망(Recurrent Neural Network) 등으로 분류된다. 인공 신경망을 학습하는 방식을 딥러닝(Deep Learning)이라 하며, 상술한 바와 같이 딥러닝에는 컨볼루션 신경 망, 리커런트 신경망 방식과 같이 다양한 알고리즘이 이용될 수 있다. 이 때, 인공 신경망을 학습한다는 것은 계층간 가중치 및 바이어스 또는 인접한 계층 중 서로 다른 레이어에 속 하는 복수의 뉴런들간의 가중치 및 바이어스를 결정하고 갱신하는 것을 나타낼 수 있다. 예를 들어, 복수의 계층적 구조 및 복수의 레이어들, 또는, 뉴런들 간의 가중치 및 바이어스를 총칭하여 인공 신경망의 연결성(connectivity)이라 할 수 있다. 따라서, 인공 신경망을 학습한다는 것은 연결성을 구축하고 학습하는 것을 나타낼 수 있다. 도 1을 참조하면, 인공 신경망은 입력 레이어, 히든 레이어들 및 출력 레이어를 포함하는 구조를 가지며, 수신되는 입력 데이터(예를 들어, I1 및 I1)를 기초로 연산을 수행하고, 수행 결과를 기초로 출력 데이터(예를 들어, O1 및 O1)를 생성할 수 있다. 인공 신경망은 앞서 설명된 바와 같이, 1개 이상의 히든 레이어들을 포함하는 DNN 또는 n-계층 인공 신경 망일 수 있다. 예를 들어, 도 1에 도시된 바와 같이, 인공 신경망은 입력 레이어(Layer 1), 1개의 히든 레이어들(Layer 1 및 Layer 3) 및 출력 레이어(Layer 4)를 포함하는 DNN일 수 있다. DNN은 Convolutional Neural Networks(CNN), Recurrent Neural Networks(RNN), Deep Belief Networks, Restricted Boltzman Machines 등을 포함할 수 있으나, 이에 제한되지 않는다. 예를 들어, 컨볼루션 신경망은 합성곱(Convolution) 연산을 사용하며, 예를 들어, 영상에서 객체, 얼굴, 장면을 인식하기 위해 패턴을 찾는데 유용하다. 컨볼루션 신경망은 영상의 특징을 추출하기 위하여 필터(filter)가 입력 영상의 픽셀 또는 데이터를 일정 간격 으로 순회하면서 합성곱 연산을 수행하고, 합성곱 연산의 결과를 이용하여 특징 맵(feature map) 또는 활성도 맵(activation map)을 생성할 수 있다. 여기서, '필터'는 예를 들어, 영상의 특징을 찾아내기 위한 공용 파라 미터 또는 가중치 파라미터들을 포함할 수 있다. 필터는 후술하는 '커널'이라고도 불릴 수 있다. 또한, 입력 영상에 필터를 적용할 때, 필터가 입력 영상의 픽셀 또는 데이터를 이동(또는 순회)하는 일정 간격은 '스트라이 드(stride)'라고 부를 수 있다. 예를 들어, 스트라이드가 '2'인 경우, 필터는 입력 영상의 픽셀 또는 데이터에 서 2칸씩 이동하면서 합성곱 연산을 수행할 수 있다. 이 경우, 스트라이드 파라미터 = 2라고 표현될 수 있다. '특징 맵'은 합성곱 연산을 통해 원 영상(original image)의 정보가 압축된 것으로서, 예를 들어, 행렬의 형태 로 표현될 수 있다. 또한, 활성도 맵은 특징 맵에 활성 함수(activation function)를 적용한 결과에 해당할 수 있다. 다시 말해, 활성도 맵은 컨볼루션 신경망에서 컨볼루션 연산을 수행하는 컨볼루션 레이어들의 최종 출력 결과에 해당할 수 있다. 컨볼루션 신경망에서 최종 출력되는 데이터의 형태(shape)는 예를 들어, 필터의 크기, 스트라이드(Stride), 패 딩(Padding)의 적용 여부, 및/또는 맥스 풀링(Max Pooling)의 크기 등에 따라서 변경될 수 있다. 컨볼루션 레 이어에서는 필터와 스트라이드의 작용으로 인해 특징 맵의 크기가 입력 데이터보다 작을 수 있다. '패딩'은 데이터의 외곽에 지정된 픽셀 수(예를 들어, '2')만큼 특정 값을 채워 넣는 것으로 이해될 수 있다. 예를 들어, 패딩이 '2'로 설정된 경우, 32 x 32의 크기를 갖는 데이터 외곽의 상, 하, 좌, 우에는 각각 2 픽셀 만큼 특정 값(예를 들어, '0')이 채워질 수 있다. 따라서, 패딩이 '2'로 설정된 경우, 최종적인 데이터의 크기 는 36 x 36 크기가 될 수 있다. 이 경우, '패딩 파라미터= 2'라고 표현될 수 있다. 이와 같이, 패딩을 통해컨볼루션 레이어의 출력 데이터의 사이즈가 조절될 수 있다. 예를 들어, 패딩을 사용하지 않는 경우, 데이터의 공간적 크기는 컨볼루션 레이어를 지날 때마다 작아지게 되므 로 데이터의 가장자리의 정보들이 사라질 수 있다. 패딩은 이와 같이 데이터의 가장자리의 정보가 사라지는 것 을 방지하거나, 또는 컨볼루션 레이어의 출력을 입력 데이터의 공간적 크기와 동일하게 맞춰 주기 위해 사용될 수 있다. 인공 신경망이 DNN 아키텍처로 구현된 경우 유효한 정보를 처리할 수 있는 보다 많은 레이어들을 포함하므 로, 인공 신경망은 싱글 레이어를 갖는 인공 신경망보다 복잡한 데이터 집합들을 처리할 수 있다. 한편, 인공 신경망은 4개의 레이어들을 포함하는 것으로 도시되어 있으나, 이는 예시에 불과할 뿐 인공 신경망 은 더 적거나 많은 레이어들을 포함하거나, 더 적거나 많은 채널들을 포함할 수 있다. 즉, 인공 신경망 은 도 1에 도시된 것과는 다른, 다양한 구조의 레이어들을 포함할 수 있다. 인공 신경망에 포함된 레이어들 각각은 복수의 채널들을 포함할 수 있다. 채널은 뉴런(neuron), 프로세싱 엘리먼트(Processing element, PE), 유닛(unit) 또는 이와 유사한 용어들로 알려진, 복수의 인공 노드 (artificial node)들에 해당될 수 있다. 예를 들어, 도 1에 도시된 바와 같이, Layer 1은 1개의 채널들(노드들), Layer 1 및 Layer 3 각각은 3개의 채널들을 포함할 수 있다. 다만, 이는 예시에 불과할 뿐 인 공 신경망에 포함된 레이어들 각각은 다양한 개수의 채널들(노드들)을 포함할 수 있다. 인공 신경망의 레이어들 각각에 포함된 채널들은 서로 연결되어 데이터를 처리할 수 있다. 예를 들어, 하 나의 채널은 다른 채널들로부터 데이터를 수신하여 연산할 수 있고, 연산 결과를 또 다른 채널들로 출력할 수 있다. 채널들 각각의 입력 및 출력 각각은 입력 액티베이션 및 출력 액티베이션이라고 지칭될 수 있다. 즉, 액티베이 션은 한 채널의 출력임과 동시에, 다음 레이어에 포함된 채널들의 입력에 해당되는 파라미터일 수 있다. 한편, 채널들 각각은 이전 레이어에 포함된 채널들로부터 수신된 액티베이션들 및 웨이트 및 바이어스에 기초하여 자 신의 액티베이션을 결정할 수 있다. 웨이트는 각 채널에서의 출력 액티베이션을 계산하기 위해 이용되는 파라 미터로서, 채널들 간의 연결관계에 할당되는 값일 수 있다. 채널들 각각은 입력을 수신하여 출력 액티베이션을 출력하는 연산 유닛(computational unit) 또는 프로세싱 엘 리먼트(processing element)에 의해 처리될 수 있고, 채널들 각각의 입력-출력은 매핑될 수 있다. 예를 들어, σ는 활성화 함수이고, 는 (i-1) 번째 레이어에 포함된 k 번째 노드로부터 i 번째 레이어에 포함된 j번째 노드로의 웨이트이며, 는 i 번째 레이어에 포함된 j 번째 노드의 바이어스(bias) 값이고, 는 i 번째 레이어 의 j 번째 노드의 액티베이션이라고 할 때, 액티베이션 는 다음과 같은 수학식 1을 따를 수 있다. 수학식 1"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 1에 도시된 바와 같이, 1번째 레이어(Layer 1)의 첫 번째 채널(CH 1)의 액티베이션은 로 표현될 수 있다. 또한, 은 수학식 1에 따라 의 값을 가질 수 있다. 다만, 앞서 설명한 수학식 1은 인공 신경망에서 데이터를 처리하기 위해 이용되는 액티베이션 및 웨이트 및 바이어스를 설명하기 위한 예시일 뿐, 이에 제한되지 않는다. 액티베이션은 이전 레이어로부터 수신된 액티 베이션들의 가중치 합(weighted sum)을 sigmoid 함수나 Rectified Linear Unit (ReLU) 함수 등의 액티베이션 함수에 통과시킴으로써 획득된 값일 수 있다.도 2a 및 도 2b는 뉴럴 네트워크의 프루닝(pruning)을 설명하기 위한 도면들이다. 도 2a에서, 뉴럴 네트워크는 프루닝이 수행되기 전 뉴럴 네트워크에 해당하고, 뉴럴 네트워크는 프루 닝이 수행된 후 뉴럴 네트워크에 해당한다. 구체적으로, 뉴럴 네트워크에서 인접한 두 개의 서로 다른 레이어들에 포함된 모든 2 개의 뉴런 조합들 간 에는 연결 관계가 형성되어 있다. 즉, 뉴럴 네트워크는 완전 연결된(fully-connected) 뉴럴 네트워크이므 로, 뉴럴 네트워크에 포함된 인접한 서로 다른 레이어들에 속한 임의의 두 개의 뉴런들 간의 연결 강도를 나타내는 웨이트들은 0보다 큰 값들일 수 있다. 이와 같이, 모든 인접 레이어들의 뉴런들 간의 연결성이 존재하 는 경우에는, 뉴럴 네트워크 전체의 복잡도가 증가될 수 있고, 이에 따라 뉴럴 네트워크의 예측 결과는 과적합 (over fitting)으로 인해 정확도, 신뢰도가 감소될 수 있다. 뉴럴 네트워크의 복잡도를 감소시키기 위하여, 뉴럴 네트워크에 대한 프루닝이 수행될 수 있다. 뉴럴 네트워크 프루닝은, 예를 들어 도 2a에 도시된 바와 같이, 뉴럴 네트워크에서 연결된 어느 노드들 간 의 웨이트가 소정 임계값 이하인 경우, 해당 노드들 간의 연결성을 약화 또는 제거하는 처리를 수행하는 것을 의미할 수 있다. 아래에서, 설명의 편의를 위해 '뉴럴 네트워크 프루닝'은 '프루닝'으로 지칭할 수 있다. 예를 들어, 뉴럴 네트워크에서 노드 1과 노드 2-3 간의 웨이트가 소정 임계값 이하인 경우, 프루닝은 뉴럴 네트워크에서 노드 1과 노드 2-3 간의 웨이트를 0으로 설정함으로써, 프루닝된 뉴럴 네트워크와 같이 노드 1과 노드 2-3 간의 연결성을 제거하는 처리이다. 마찬가지로, 프루닝된 뉴럴 네트워크에서는 뉴럴 네트워크에서의 일부 노드들 간의 연결성이 약화 또는 제거되었음이 예시되어 있다. 프루닝되기에 적절한 뉴럴 네트워크의 노드들의 결정을 위해, 뉴럴 네트워크의 각 레이어가 탐색될 수 있다. 이때, 뉴럴 네트워크의 추론 정확도, 즉 뉴럴 네트워크의 출력이 지나치게 감소되지 않는 선에서, 프루닝될 레 이어들, 웨이트들이 탐색되는 것이 바람직할 수 있다. 프루닝 프로세스가 수행되는 동안, 뉴럴 네트워크에 포함된 레이어들의 웨이트들 중에서 미리 정의된 웨이트 임 계값보다 작은 값을 갖는 뉴런들 간의 연결이 탐색될 수 있고, 이와 같은 웨이트를 갖는 뉴런들 간의 연결 관계 는 제거되거나, 약화될 수 있다. 도 2b를 참고하면, 뉴럴 네트워크에서 n번째 레이어의 k번째 커널인 KERNELn_k(n 및 k는 자연수)에 대하여 프루닝을 수행한 결과에 대해 도시되어 있다. 한편, 뉴럴 네트워크 프루닝을 위한 설정으로서, 예를 들어 웨이 트 임계값 τ는 0.5인 것으로 가정하였다. 프루닝되기 전 KERNELn_k은 다양한 값들의 웨이트들을 갖는다. 프루닝 프로세스에 의하여 KERNELn_k의 웨이트들 중 웨이트 임계값 (τ=0.5) 이하의 웨이트들은 모두 0으로 프루닝되고, 프루닝된 KERNELn_k가 생 성될 수 있다. 이와 같이, 프루닝된 KERNELn_k는 KERNELn_k에 비하여 인접한 노드들 간의 연결성을 약 화시켰고, 이로 인해 0 값을 갖는 웨이트들로 인하여 인접한 노드들 간의 연산량은 감소될 수 있다. 도 3a는 종래의 채널 프루닝 방법을 설명하기 위한 도면이다. 도 3a를 참조하면, 예를 들어, 인공 신경망의 해당 레이어에서 특징 맵의 크기는 K*K, 입력 채널의 수(Cin)는 6, 출력 채널의 수(Cout)는 5일 수 있다. 종래의 채널 프루닝 방법은 입력 채널 프루닝 이진 벡터 및 출력 채널 프루닝 이진 벡터에 기초하여 채널 단위 로 프루닝을 수행할 수 있다. 입력 채널 프루닝 이진 벡터는 입력 채널의 가중치의 프루닝 여부를 나타내는 이 진 벡터로 로 표현될 수 있다. 보다 구체적으로, 입력 채널을 프루닝하기로 결정하였다면 해당 채널에 대응하는 벡터값을 '0'으로 표현할 수 있고, 반대로 입력 채널을 프루닝하지 않기로 결정하였다면 해당 채널에 대응하는 벡터값을 '1'로 표현할 수 있다. 예를 들어, 도 3a의 경우 2번, 4번, 5번 입력 채널을 프루닝 하기로 결정하였다면, 입력 채널 프루닝 이진 벡터는 아래 수학식 2와 같이 표현할 수 있다.수학식 2"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "출력 채널 프루닝 이진 벡터는 출력 채널의 가중치의 프루닝 여부를 나타내는 이진 벡터로 로 표현될 수 있다. 보다 구체적으로, 출력 채널을 프루닝하기로 결정하였다면 해당 채널에 대응하는 벡터값을 '0'으로 표현할 수 있고, 반대로 출력 채널을 프루닝하지 않기로 결정하였다면 해당 채널에 대응하는 벡터값을 '1'으로 표현할 수 있다. 예를 들어, 도 3a의 경우 3번 출력 채널을 프루닝하기로 결정하였다면, 출력 채널 프 루닝 이진 벡터는 아래 수학식 3과 같이 표현할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "종래의 채널 프루닝 방법에 따르면, 채널 단위로 프루닝을 수행하기 때문에 정교한 프루닝 및 압축율에 있어서 한계가 있을 수 있다. 아래에서 상세히 설명하겠으나, 일 실시예에 따른 프루닝 방법은 출력 채널의 스파셜 (spartial)한 방향까지 프루닝을 수행하여 보다 정교한 프루닝을 수행할 수 있다. 도 3b는 일 실시예에 따른 프루닝 방법을 설명하기 위한 도면이다. 도 3b를 참조하면, 예를 들어, 인공 신경망의 해당 레이어에서 특징 맵의 크기는 K*K, 입력 채널의 수(Cin)는 6, 출력 채널의 수(Cout)는 5일 수 있다. 일 실시예에 따른 프루닝 방법은 입력 채널 프루닝 이진 벡터 및 출력 채널 스파셜 프루닝 이진 벡터에 기초하 여 채널 단위로 프루닝을 수행할 수 있다. 도 3a를 참조하여 설명한 입력 채널 프루닝 이진 벡터는 도 3b에도 적용될 수 있고, 중복된 내용은 생략할 수 있다. 도 3b의 경우 도 3a와 마찬가지로, 2번, 4번, 5번 입력 채널을 프루닝하기로 결정하였다면, 입력 채널 프루닝 이진 벡터는 수학식 1과 같이 표현할 수 있다. 출력 채널 스파셜 프루닝 이진 벡터는 출력 채널의 스파셜한 방향으로 가중치의 프루닝 여부를 나타내는 이진 벡터로 로 표현될 수 있다. 여기서, '출력 채널의 스파셜한 방향으로 가중치의 프루닝 여 부를 나타낸다'란 각각의 출력 채널 별로 특징 맵의 스파셜한 형태까지 반영하여 가중치의 프루닝 여부를 나타 내는 것을 의미할 수 있다. 종래에는 출력 채널 단위로 프루닝 여부를 결정하였다면, 일 실시예에 따른 프루닝은 이를 확장하여 출력 채널 의 특징 맵의 요소 단위로 프루닝할 수 있다. 예를 들어, 1번 출력 채널에서 특징 맵의 1, 3, 7, 9번 요소 (element)를 프루닝하기로 결정하였다면, 해당 요소에 대응하는 벡터값을 '0'으로 표현할 수 있고, 반대로 1번 출력 채널에서 특징 맵의 2, 4, 5, 6, 8번 요소(element) 프루닝하지 않기로 결정하였다면 해당 채널에 대응하 는 벡터값을 '1'로 표현할 수 있고, 이 때 출력 채널 스파셜 프루닝 이진 벡터는 아래 수학식 4와 같이 표현할 수 있다.수학식 4"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "마찬가지로, 2번 출력 채널에서 특징 맵의 1, 6, 8, 9번 요소(element)를 프루닝하기로 결정하였다면, 해당 요 소에 대응하는 벡터값을 '0'으로 표현할 수 있고, 반대로 1번 출력 채널에서 특징 맵의 2, 4, 5, 6, 8번 요소 (element) 프루닝하지 않기로 결정하였다면 해당 채널에 대응하는 벡터값을 '1'로 표현할 수 있고, 이 때 출력 채널 스파셜 프루닝 이진 벡터는 아래 수학식 5와 같이 표현할 수 있다. 수학식 5"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "일 실시예에 따른 입력 채널의 프루닝 이진 벡터와 출력 채널의 스파셜 프루닝 이진 벡터에 기초하여 프루닝 마 스크(pruning mask)를 결정할 수 있다. 일 실시예에 따른 프루닝 마스크는 해당 요소의 프루닝 여부를 나타내 는 이진 벡터로, 아래 수학식 6과 같이 표현할 수 있다. 수학식 6"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 5에 따르면, 특정 요소가 입력 채널의 프루닝 이진 벡터 및 출력 채널의 스파셜 프루닝 이진 벡터 중 적 어도 하나라도 '0'을 갖을 경우, 해당 요소는 프루닝될 수 있다. 반대로, 특정 요소가 입력 채널의 프루닝 이 진 벡터 및 출력 채널의 스파셜 프루닝 이진 벡터 모두 '1'일 경우에만 해당 요소가 프루닝되지 않을 수 있다. 도 4는 일 실시예에 따른 프루닝 방법을 설명하기 위한 순서도이다. 도 4의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 4에 도시된 다수의 동작은 병렬로 또는 동시 에 수행될 수 있다. 도 4의 하나 이상의 블록들 및 블록들의 조합은 특정 기능을 수행하는 특수 목적 하드웨어 기반 컴퓨터, 또는 특수 목적 하드웨어 및 컴퓨터 명령들의 조합에 의해 구현될 수 있다. 일 실시예에 따른 프루닝 장치는 사용자가 원하는 자원량 내에서 가중치의 자원을 최대화 하는 방향으로 프루닝 마스크를 최적화할 수 있다. 나아가, 프루닝 장치는 결정된 프루닝 마스크에 기초하여 프루닝 후 남아있는 가 중치들을 바탕으로 인공 신경망을 사용하는데 필요한 메모리량, 연산에 필요한 FLOPs 뿐만 아니라 예상 추론 시 간을 미리 예측할 수 있다. 도 4를 참조하면, 단계에서, 일 실시예에 따른 프루닝 장치는 학습된 인공 신경망의 가중치 중요도를 결정 한다. 일 실시예에 따른 프루닝 장치는 인공 신경망을 직접 학습하거나, 이미 학습된 인공 신경망을 수신할 수 있다. 이후, 일 실시예에 따른 프루닝 장치는 학습된 인공 신경망의 가중치 중요도를 결정할 수 있다. 예를 들어, 일 실시예에 따른 프루닝 장치는 가중치의 절대값이나 오차의 그래디언트(gradient) 절대값을 가중치의 중요도로 결정할 수 있다. 또는, 이후, 일 실시예에 따른 프루닝 장치는 이미 결정된 인공 신경망의 가중치 중요도를 수 신할 수도 있다. 단계에서, 일 실시예에 따른 프루닝 장치는 연산의 자원(resource)과 관련된 제한 조건을 수신한다. 일 실시예에 따른 자원과 관련된 제한 조건은 인공 신경망을 동작할 때 필요한 메모리량, FLOPs, 추론시간 등에 기초하여 결정될 수 있다. 예를 들어, 해당 인공 신경망은 미리 정해진 시간 내에 추론을 완료할 수 있어야 한다 면, 해당 추론시간이 제한 조건일 수 있다. 단계에서, 일 실시예에 따른 프루닝 장치는 제한 조건 내에서, 인공 신경망의 가중치 중요도를 최대화할 수 있는 프루닝 마스크를 결정할 수 있다. 도 3b를 참조하여 설명한 프루닝 마스크는 도 4에도 적용될 수 있고, 중복된 내용은 생략할 수 있다. 일 실시예에 따른 프루닝 장치는 제한 조건의 예상값을 입력 채널의 프루닝 이진 벡터의 크기 와 프루닝 마스크의 크기 의 선형 결합으로 표현할 수 있다. 인공 신경망 연산(예를 들어, 컨볼루션 연산)이 순차적 으로 연결되었다고 가정할때, 각 인공 신경망 연산의 가중치들은 로 표현될 수 있다. 가중치에 해당하는 가중치 중요도와 프루닝 마스크를 과 로 정의 할 수 있다. 이 때, 인공 신경망이 사용하는 제한 조건(예를 들어, 메모리량, FLOPs, 추론시간)은 아래 수학식 7과 같이 표현할 수 있다. 수학식 7"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 7에서, 번째 인공 신경망 연산의 특징 표현을 이라고 하면, 인공 신경망이 사용하는 자 원을 표현하기 위한 각 와 의 값은 아래 표1 과 같이 표현될 수 있다. 표 1 인공 신경망의 자원 인공 신경망의 크기 인공 신경망에 필요한 메모리량 FLOPs 일 실시예에 따른 프루닝 장치는 제한 조건 내에서, 인공 신경망의 가중치 중요도를 최대화할 수 있는 최적화 식을 아래 수학식 8과 같이 표현할 수 있다. 수학식 8"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "수학식 8은 아래 수학식 9의 조건을 만족해야 할 수 있다. 수학식 9"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "일 실시예에 따른 프루닝 장치는 이진 최적화 알고리즘에 기초하여 수학식 8, 9을 만족하는 프루닝 마스크를 결 정할 수 있다. 예를 들어, 일 실시예에 따른 프루닝 장치는 옵티마이저(optimizer)(예를 들어, 구로비 (Gurobi), cplex)에 기초하여 수학식 8, 9를 만족하는 프루닝 마스크를 결정하거나, 탐욕 알고리즘(greedy alforithm)에 기초하여 수학식 8, 9를 만족하는 프루닝 마스크를 결정할 수 있다. 일 실시예에 따른 프루닝 장치는 반복적인 임계값 조절없이 단 한 번에 남아있는 중요한 가중치들을 최대한 남 기게 되면서 사용자가 요구하는 조건들을 만족하는 프루닝 마스크를 한 번에 결정할 수 있다. 나아가, 일 실시예에 따른 프루닝 장치는 여러 그룹의 사이즈에 맞는 프루닝이 아니라 기존의 프레임 워크로 속 도 최적화가 쉬운 형태이면서 최대한 많이 프루닝이 가능하게 할 수 있다. 일 실시예에 따른 프루닝 장치는 결정된 프루닝 마스크에 기초하여 인공 신경망을 프루닝할 수 있다. 일 실시 예에 따른 프루닝 장치는 프루닝된 인공 신경망에 대한 추론을 수행할 수도 있고, 프루닝된 인공 신경망을 다른 전자 장치로 전달하고, 추론은 전자 장치에서 수행될 수도 있다. 도 5는 일 실시예에 따른 방법으로 프루닝된 가중치의 예시를 도시한 도면이다. 도 5를 참조하면, 일 실시예에 따른 방법으로 프루닝된 가중치에서 검은색이 프루닝되지 않는 영역이고 흰색이 프루닝된 영역일 수 있다. 도 6은 일 실시예에 따른 프루닝 장치의 하드웨어 구성을 도시한 블록도이다. 도 6을 참고하면, 프루닝 장치는 프로세서 및 메모리를 포함한다. 도 6에 도시된 프루닝 장치 에는 본 실시예들와 관련된 구성요소들만이 도시되어 있다. 따라서, 프루닝 장치에는 도 6에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음은 당업자에게 자명하다. 이하에서, 도 6의 프 루닝 장치는 전자 장치로 지칭될 수도 있다. 일 실시예에 따른 프루닝 장치는 뉴럴 네트워크에 대한 프루닝을 수행하는 컴퓨팅 디바이스에 해당된다. 예를 들어, 프루닝 장치는 PC(personal computer), 서버 디바이스, 모바일 디바이스 등에 해당될 수 있고, 나아가서 뉴럴 네트워크를 이용한 음성 인식, 영상 인식 등을 수행하는 자율주행 자동차, 로보틱스, 스마트폰, 태블릿 디바이스, AR(Augmented Reality) 디바이스, IoT(Internet of Things) 디바이스 등에 구비된 장치일 수 있으나, 이에 제한되지 않고 다양한 종류의 디바이스들에 해당될 수 있다. 프로세서는 프루닝 장치의 동작들을 제어하기 위한 전반적인 제어 기능들을 수행하는 하드웨어 구성 이다. 예를 들어, 프로세서는 프루닝 장치 내의 메모리에 저장된 프로그램들을 실행함으로써, 프루닝 장치를 전반적으로 제어할 수 있다. 프로세서는 프루닝 장치 내에 구비된 CPU(central processing unit), GPU(graphics processing unit), AP(application processor), NPU(neural processing unit) 등으로 구현될 수 있으나, 이에 제한되지 않는다. 메모리는 프로세서 내에서 처리되는 각종 뉴럴 네트워크 데이터들을 저장하는 하드웨어로서, 예를 들 어, 메모리는 뉴럴 네트워크에 대한 프루닝 데이터들, 뉴럴 네트워크에 입력될 데이터 세트들 등을 저장할 수 있다. 또한, 메모리는 프로세서에 의해 구동될 다양한 애플리케이션들, 예를 들어 뉴럴 네트워크 프루닝을 위한 애플리케이션, 뉴럴 네트워크 구동 애플리케이션, 드라이버 등을 저장할 수 있다. 메모리는 휘발성 메모리(volatile memory) 또는 불휘발성 메모리(nonvolatile memory) 중 적어도 하나를 포함할 수 있다. 불휘발성 메모리는 ROM (Read Only Memory), PROM (Programmable ROM), EPROM (Electrically Programmable ROM), EEPROM (Electrically Erasable and Programmable ROM), 플래시 메모리, PRAM (Phase- change RAM), MRAM (Magnetic RAM), RRAM (Resistive RAM), FRAM (Ferroelectric RAM) 등을 포함한다. 휘발성 메모리는 DRAM (Dynamic RAM), SRAM (Static RAM), SDRAM (Synchronous DRAM), PRAM (Phase-change RAM), MRAM (Magnetic RAM), RRAM (Resistive RAM), FeRAM (Ferroelectric RAM) 등을 포함한다. 나아가서, 메모리 는 HDD(Hard Disk Drive), SSD(Solid State Drive), CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital) 또는 Memory Stick 중 적어 도 하나를 포함할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0020308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2a 도면2b 도면3a 도면3b 도면4 도면5 도면6"}
{"patent_id": "10-2022-0020308", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인공 신경망에서 수행되는 연산을 설명하기 위한 도면이다. 도 2a 및 도 2b는 뉴럴 네트워크의 프루닝(pruning)을 설명하기 위한 도면들이다. 도 3a는 종래의 채널 프루닝 방법을 설명하기 위한 도면이다. 도 3b는 일 실시예에 따른 프루닝 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 프루닝 방법을 설명하기 위한 순서도이다. 도 5는 일 실시예에 따른 방법으로 프루닝된 가중치의 예시를 도시한 도면이다. 도 6은 일 실시예에 따른 프루닝 장치의 하드웨어 구성을 도시한 블록도이다."}
