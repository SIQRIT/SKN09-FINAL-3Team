{"patent_id": "10-2020-0097122", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0017068", "출원번호": "10-2020-0097122", "발명의 명칭": "인공지능 콘텐츠 자동 생성 및 변형 방법", "출원인": "한국전자기술연구원", "발명자": "정혜동"}}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 콘텐츠 자동 생성 및 변형 방법에 있어서,(a) 콘텐츠 생성을 위하여 사용자가 생성할 콘텐츠와 관련된 텍스트 및 이미지를 입력하는 단계;(b) 인공지능을 기반으로 하여 사용자가 입력한 텍스트 및 사용자가 입력한 이미지 데이터의 메타데이터를 분석하여 각각 텍스트 메타데이터 및 이미지 메타데이터로 기록하는 단계; 및(c) 기록된 메타데이터를 활용하여 동적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘텐츠 중 어느 하나 이상의창작물을 생성하는 단계;를 포함하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사용자가 입력한 이미지는,주요 객체 및 배경을 포함하는 정적 이미지, 사용자가 창작한 스케치 이미지 및 분위기를 변환할 삽화 이미지중 어느 하나 이상을 포함하며, 사용자가 사용자 단말의 입력 수단을 통해 입력하거나 상기 사용자 단말과 연동된 소셜 플랫폼 상에서 상기 사용자가 업로드 또는 다운로드한 이미지인 것을 특징으로 하는 콘텐츠 자동 생성및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 (b)단계는,상기 사용자가 입력한 텍스트에 대하여 인공지능을 기반으로 문장 분석, 여러 개의 복합 문장이 있는 문단분석, 문단 분석 중 가장 중요한 문장을 추출, 여러 문장을 복합적으로 분석하는 등 텍스트 분석하여 액션정보,객체정보, 배경정보, 글의 감성, 글의 분위기를 추출하여 메타데이터를 생성하여 소정의 양식에 따라 데이터베이스에 텍스트 메타데이터로 기록하는 텍스트 분석 단계; 및상기 사용자가 입력한 이미지에 대하여 인공지능을 기반으로 이미지의 배경과 전경을 분리하고, 이미지 내의 사람의 전신, 사람의 얼굴, 동물, 캐릭터 등을 이미지 분석하여 배경 및 전경 정보, 객체의 특징점을 추출하여 메타데이터를 생성하여 소정의 양식에 따라 데이터베이스에 이미지 메타데이터로 기록하는 이미지 분석 단계;를 포함하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 이미지 분석 단계는,상기 사용자가 입력한 이미지가 없는 경우에는 사용자 단말에 저장되거나 사용자 단말과 연동된 소셜 플랫폼 상에서 상기 사용자가 업로드한 이미지 또는 데이터베이스에 저장된 이미지 중 상기 텍스트 메타데이터와 관련된이미지를 검출하고, 검출된 이미지의 배경과 전경을 분리하고, 이미지 내의 사람의 전신, 사람의 얼굴, 동물,캐릭터 등을 이미지 분석하여 배경 및 전경 정보, 객체의 특징점을 추출하여 메타데이터를 생성하여 소정의 양식에 따라 데이터베이스에 이미지 메타데이터로 기록하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0017068-3-제1항에 있어서,상기 (c)단계는,사용자가 입력한 이미지가 주요 객체 및 배경을 포함하는 정적 이미지인 경우에는, 이미지 메타데이터 중 배경의 모션을 상기 배경의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 분위기에따라 움직이도록 동적 이미지로 변경하는 배경 모션 생성; 및이미지 메타데이터 중 객체의 신체 모션, 얼굴 표정 등을 상기 객체의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 액션 정보에 따라 움직이도록 동적 이미지로 변경하는 객체 모션 생성;중 어느 하나 이상을 거쳐 동적 콘텐츠를 생성하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 (c)단계는,사용자가 입력한 이미지가 사용자가 창작한 스케치 이미지인 경우에는, 이미지 메타데이터 중 스케치의 신체 모션, 얼굴 표정 등을 텍스트 메타데이터에서 나타난 분위기, 화풍에 따라변경하는 화풍변화; 및이미지 메타데이터 중 스케치의 일부의 색체를 텍스트 메타데이터 또는 사용자의 선택에 따라 변경하는 색체변화;중 어느 하나 이상을 거쳐 스케치 기반 이미지 콘텐츠를 생성하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 (c)단계는,사용자가 입력한 이미지가 분위기를 변환할 삽화 이미지인 경우에는, 이미지 메타데이터 중 배경 및 객체를 텍스트 메타데이터에서 나타난 분위기, 화풍에 따라 변경하는 화풍변화;및이미지 메타데이터 중 배경 및 객체의 그래픽 효과를 텍스트 메타데이터에서 나타난 분위기, 화풍에 따라 변경하는 그래픽 오버레이;중 어느 하나 이상을 거쳐 삽화 콘텐츠를 생성하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 (c)단계에서 생성된 창작물이 스케치 기반 이미지 콘텐츠 또는 삽화 콘텐츠인 경우에는,상기 (c)단계 이후, 상기 (b)단계 및 상기 (c)단계를 더 수행하되, 상기 (b)단계에서 상기 사용자가 입력한 이미지는 상기 생성된 창작물이고,상기 (c)단계는, 이미지 메타데이터 중 배경의 모션을 상기 배경의 일반적인 액션 또는 텍스트 메타데이터에서나타난 분위기에 따라 움직이도록 동적 이미지로 변경하는 배경 모션 생성; 및이미지 메타데이터 중 객체의 신체 모션, 얼굴 표정 등을 상기 객체의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 액션 정보에 따라 움직이도록 동적 이미지로 변경하는 객체 모션 생성;중 어느 하나 이상을 거쳐 동적 콘텐츠를 생성하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법.공개특허 10-2022-0017068-4-청구항 9 인공지능 콘텐츠 자동 생성 및 변형 방법에 있어서,(a) 콘텐츠 생성을 위하여 사용자가 생성할 콘텐츠와 관련된 텍스트 및 이미지를 입력하는 단계;(b) 인공지능을 기반으로 하여 사용자가 사용자 단말의 입력 수단을 통해 입력하거나 사용자 단말에 저장된 텍스트, 상기 사용자 단말과 연동된 소셜 플랫폼 상에서 상기 사용자 단말의 입력 수단을 통해 입력한 텍스트 또는 상기 사용자 단말과 연동된 소셜 플랫폼 상에서 상기 사용자가 업로드 또는 다운로드한 이미지 등에 포함된텍스트 및 사용자가 입력한 이미지 데이터의 메타데이터를 분석하여 각각 텍스트 메타데이터 및 이미지 메타데이터로 기록하는 단계; 및(c) 기록된 메타데이터를 활용하여 동적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘텐츠 중 어느 하나 이상의창작물을 생성하는 단계;를 포함하는 것을 특징으로 하는 콘텐츠 자동 생성 및 변형 방법."}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 콘텐츠 자동 생성 및 변형 방법이 제공된다. 최근 증가하고 있는 1인 콘텐츠를 생성하기 위해 사용자가 창작물을 제작함에 있어 별도의 전문가나 툴의 도움 없이도, 인공지능을 이용하여 이미지 및 텍스트에서 영상처 리 및 자연어를 처리하고 메타데이터를 추출 및 분석하여 동적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘텐츠 를 자동으로 생성 및 변형할 수 있도록 하기 위한 방법에 관한 것이다."}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 콘텐츠 자동 생성 및 변형 방법에 관한 것으로서, 더욱 상세하게는 사용자가 창작물을 제작 함에 있어 별도의 전문가나 툴의 도움 없이도, 인공지능을 이용하여 영상처리 및 자연어를 처리하고 메타데이터 를 추출 및 분석하여 콘텐츠를 자동으로 생성할 수 있도록 하기 위한 방법에 관한 것이다."}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과거에는 창작이 전문가의 영역으로 오랜 기간 동안 지속되어 왔으나 정보통신기술의 발전, 통신 성능의 향상, 콘텐츠 소비 문화의 변화 등으로 점치 개인의 영역으로 확대되고 있는 추세이다. 최근에는 창작의 방식이 사진, 동영상 등을 활용한 브이로그, 즉 비디오와 블로그의 결합이나, 웹툰, 이모티콘, 움직이는 그림 등 짧지만 위트 있고 함축적인 내용을 가진 콘텐츠로 확대되고 있으며 개인의 소재를 활용한 내 용을 공감하며 나누는 콘텐츠로 생산되고 있는 추세이다. 또한 다양한 소셜 네트워크 서비스(Social Network Service, SNS) 플랫폼의 확산으로 과거와 달리 1인 창작 영 역으로 확대되어 SNS 플랫폼을 통해 게임방송, 브이로그 등 누구나 콘텐츠의 생산자가 될 수 있는 시대가 도래 하였다. 그러나 콘텐츠 제작을 위해서는 사용자가 아이디어부터 스케치, 이미지 검색, 편집까지 모든 과정을 직접 거쳐 야 하며, 현재 콘텐츠, 특히 모션이 있는 동영상 제작을 위해서는 포토샵, 일러스트레이터, 프리미어 등 전문 편집기를 사용하거나, 이러한 전문 편집기를 사용할 수 있는 전문가에게 맡겨 수행해야 하는데, 이러한 분야에 대한 전문적 교육을 받지 않은 일반 사용자는 전문 편집기를 사용하기 어려우며 비용이 부담으로 다가올 수 있 다. 또한 전문 편집기를 활용한다 하더라도 최종 콘텐츠 제작에는 시간이 많이 소요되며, 특히 동영상의 경우에는 이미지 프레임을 각각 편집한 후 이어 붙여야 하기 때문에 작업량이 매우 많다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2019-0035502호"}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제점을 해결하기 위해 본 발명이 이루고자 하는 과제는, 콘텐츠 제작에 있어 특정 이미지와 텍스트를 입력하거나 SNS 플랫폼 상에 입력한 텍스트를 인공지능을 기반으로 하여 분석하여 이미지와 텍스트의 메타데이 터를 추출하고, 추출한 메타데이터를 통해 동적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘텐츠 등을 생성함 으로써 아이디어 수준에서부터 완성도 높은 콘텐츠를 자동으로 생성하여 비전문가들의 창작을 지원하고, 적은 비용과 시간으로 고품질의 콘텐츠를 제작할 수 있도록 하는 데 있다. 본 발명의 해결 과제는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 과제들은 아래의 기재 로부터 당업자가 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 기술적 과제를 해결하기 위한 수단으로서, 본 발명의 실시예에 따르면, 인공지능 콘텐츠 자동 생성 및 변형 방법은, (a) 콘텐츠 생성을 위하여 사용자가 생성할 콘텐츠와 관련된 텍스트 및 이미지를 입력하는 단계; (b) 인공지능을 기반으로 하여 사용자가 입력한 텍스트 및 사용자가 입력한 이미지 데이터의 메타데이터를 분석 하여 각각 텍스트 메타데이터 및 이미지 메타데이터로 기록하는 단계; 및 (c) 기록된 메타데이터를 활용하여 동 적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘텐츠 중 어느 하나 이상의 창작물을 생성하는 단계;를 포함한다. 상기 사용자가 입력한 이미지는, 주요 객체 및 배경을 포함하는 정적 이미지, 사용자가 창작한 스케치 이미지 및 분위기를 변환할 삽화 이미지 중 어느 하나 이상을 포함하며, 사용자가 사용자 단말의 입력 수단을 통해 입 력하거나 상기 사용자 단말과 연동된 소셜 플랫폼 상에서 상기 사용자가 업로드 또는 다운로드한 이미지다. 상기 (b)단계는, 상기 사용자가 입력한 텍스트에 대하여 인공지능을 기반으로 문장 분석, 여러 개의 복합 문장 이 있는 문단 분석, 문단 분석 중 가장 중요한 문장을 추출, 여러 문장을 복합적으로 분석하는 등 텍스트 분석 하여 액션정보, 객체정보, 배경정보, 글의 감성, 글의 분위기를 추출하여 메타데이터를 생성하여 소정의 양식에 따라 데이터베이스에 텍스트 메타데이터로 기록하는 텍스트 분석 단계; 및 상기 사용자가 입력한 이미지에 대하 여 인공지능을 기반으로 이미지의 배경과 전경을 분리하고, 이미지 내의 사람의 전신, 사람의 얼굴, 동물, 캐릭 터 등을 이미지 분석하여 배경 및 전경 정보, 객체의 특징점을 추출하여 메타데이터를 생성하여 소정의 양식에 따라 데이터베이스에 이미지 메타데이터로 기록하는 이미지 분석 단계;를 포함한다. 상기 이미지 분석 단계는, 상기 사용자가 입력한 이미지가 없는 경우에는 사용자 단말에 저장되거나 사용자 단 말과 연동된 소셜 플랫폼 상에서 상기 사용자가 업로드한 이미지 또는 데이터베이스에 저장된 이미지 중 상기 텍스트 메타데이터와 관련된 이미지를 검출하고, 검출된 이미지의 배경과 전경을 분리하고, 이미지 내의 사람의 전신, 사람의 얼굴, 동물, 캐릭터 등을 이미지 분석하여 배경 및 전경 정보, 객체의 특징점을 추출하여 메타데 이터를 생성하여 소정의 양식에 따라 데이터베이스에 이미지 메타데이터로 기록한다. 상기 (c)단계는, 사용자가 입력한 이미지가 주요 객체 및 배경을 포함하는 정적 이미지인 경우에는, 이미지 메 타데이터 중 배경의 모션을 상기 배경의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 분위기에 따라 움직 이도록 동적 이미지로 변경하는 배경 모션 생성; 및 이미지 메타데이터 중 객체의 신체 모션, 얼굴 표정 등을 상기 객체의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 액션 정보에 따라 움직이도록 동적 이미지로 변 경하는 객체 모션 생성; 중 어느 하나 이상을 거쳐 동적 콘텐츠를 생성한다. 상기 (c)단계는, 사용자가 입력한 이미지가 사용자가 창작한 스케치 이미지인 경우에는, 이미지 메타데이터 중 스케치의 신체 모션, 얼굴 표정 등을 텍스트 메타데이터에서 나타난 분위기, 화풍에 따라 변경하는 화풍변화; 및 이미지 메타데이터 중 스케치의 일부의 색체를 텍스트 메타데이터 또는 사용자의 선택에 따라 변경하는 색체 변화; 중 어느 하나 이상을 거쳐 스케치 기반 이미지 콘텐츠를 생성한다. 상기 (c)단계는, 사용자가 입력한 이미지가 분위기를 변환할 삽화 이미지인 경우에는, 이미지 메타데이터 중 배 경 및 객체를 텍스트 메타데이터에서 나타난 분위기, 화풍에 따라 변경하는 화풍변화; 및 이미지 메타데이터 중 배경 및 객체의 그래픽 효과를 텍스트 메타데이터에서 나타난 분위기, 화풍에 따라 변경하는 그래픽 오버레이; 중 어느 하나 이상을 거쳐 삽화 콘텐츠를 생성한다. 상기 (c)단계에서 생성된 창작물이 스케치 기반 이미지 콘텐츠 또는 삽화 콘텐츠인 경우에는, 상기 (c)단계 이 후, 상기 (b)단계 및 상기 (c)단계를 더 수행하되, 상기 (b)단계에서 상기 사용자가 입력한 이미지는 상기 생성 된 창작물이고, 상기 (c)단계는, 이미지 메타데이터 중 배경의 모션을 상기 배경의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 분위기에 따라 움직이도록 동적 이미지로 변경하는 배경 모션 생성; 및 이미지 메타데이터 중 객체의 신체 모션, 얼굴 표정 등을 상기 객체의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 액션 정보에 따라 움직이도록 동적 이미지로 변경하는 객체 모션 생성; 중 어느 하나 이상을 거쳐 동적 콘텐츠를 생 성한다. 한편, 본 발명의 다른 실시예에 따르면, 인공지능 콘텐츠 자동 생성 및 변형 방법은, (a) 콘텐츠 생성을 위하여 사용자가 생성할 콘텐츠와 관련된 텍스트 및 이미지를 입력하는 단계; (b) 인공지능을 기반으로 하여 사용자가 사용자 단말의 입력 수단을 통해 입력하거나 사용자 단말에 저장된 텍스트, 상기 사용자 단말과 연동된 소셜 플 랫폼 상에서 상기 사용자 단말의 입력 수단을 통해 입력한 텍스트 또는 상기 사용자 단말과 연동된 소셜 플랫폼 상에서 상기 사용자가 업로드 또는 다운로드한 이미지 등에 포함된 텍스트 및 사용자가 입력한 이미지 데이터의 메타데이터를 분석하여 각각 텍스트 메타데이터 및 이미지 메타데이터로 기록하는 단계; 및 (c) 기록된 메타데 이터를 활용하여 동적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘텐츠 중 어느 하나 이상의 창작물을 생성하 는 단계;를 포함한다."}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 콘텐츠 제작에 있어 특정 이미지와 텍스트를 입력하거나 SNS 플랫폼 상에 입력한 텍스트를 인공지능을 기반으로 하여 분석하여 이미지와 텍스트의 메타데이터를 추출하고, 추출한 메타데이터를 통해 동적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘텐츠 등을 생성함으로써 아이디어 수준에서부터 완성도 높은 콘텐츠를 자동으로 생성하 여 비전문가들의 창작을 지원하고, 적은 비용과 시간으로 고품질의 콘텐츠를 제작할 수 있다."}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상의 본 발명의 목적들, 다른 목적들, 특징들 및 이점들은 첨부된 도면과 관련된 이하의 바람직한 실시 예들 을 통해서 쉽게 이해될 것이다. 그러나 본 발명은 여기서 설명되는 실시 예들에 한정되지 않고 다른 형태로 구 체화될 수도 있다. 오히려 여기서 소개되는 실시 예들은 개시된 내용이 철저하고 완전해질 수 있도록, 그리고 당업자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 명세서에서 제1, 제2 등의 용어가 구성요소들을 기술하기 위해서 사용된 경우, 이들 구성요소들이 이 같은 용어들에 의해서 한정되어서는 안 된다. 이들 용어들은 단지 어느 구성요소를 다른 구성요소와 구별시키기 위해 서 사용되었을 뿐이다. 여기에 설명되고 예시되는 실시 예들은 그것의 상보적인 실시 예들도 포함한다. 또한, 어떤 엘리먼트, 구성요소, 장치, 또는 시스템이 프로그램 또는 소프트웨어로 이루어진 구성요소를 포함한 다고 언급되는 경우, 명시적인 언급이 없더라도, 그 엘리먼트, 구성요소, 장치, 또는 시스템은 그 프로그램 또 는 소프트웨어가 실행 또는 동작하는데 필요한 하드웨어(예를 들면, 메모리, CPU 등)나 다른 프로그램 또는 소프트웨어(예를 들면 운영체제나 하드웨어를 구동하는데 필요한 드라이버 등)를 포함하는 것으로 이해되어야 할 것이다. 또한 본 명세서에서 사용된 용어는 실시 예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '포함한 다(comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요소는 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 또한, 본 명세서에 기재된 '…부', '…기', '모듈' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위 를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, '일', '하나' 및 '그' 등의 관사는 본 발명을 기술하는 문맥에 있어서 본 명세서에 달리 지시되거나 문맥에 의 해 분명하게 반박되지 않는 한, 단수 및 복수 모두를 포함하는 의미로 사용될 수 있다. 아래의 특정 실시 예들을 기술하는 데 있어서, 여러 가지의 특정적인 내용들은 발명을 더 구체적으로 설명하고 이해를 돕기 위해 작성되었다. 하지만 본 발명을 이해할 수 있을 정도로 이 분야의 지식을 갖고 있는 독자는 이 러한 여러 가지의 특정적인 내용이 없어도 사용될 수 있다는 것을 인지할 수 있다. 어떤 경우에는, 발명을 기술하는 데 있어서 흔히 알려졌으면서 발명과 크게 관련 없는 부분들은 본 발명을 설명 하는 데 있어 별 이유 없이 혼돈이 오는 것을 막기 위해 기술하지 않음을 미리 언급해 둔다. 이하, 본 발명에서 실시하고자 하는 구체적인 기술 내용에 대해 첨부도면을 참조하여 상세하게 설명하기로 한다. 도 1은 본 발명의 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 주요 기능을 나타낸 예시도이다. 도 1을 참조하면, 본 발명의 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법은, AI를 기반으로 하여 텍 스트 및 이미지의 메타데이터를 분석하여 AI를 기반으로 자동 저작 기능을 가지는 것을 주된 내용으로 한다. 여기서 메타데이터의 분석은, 텍스트 분석을 기반으로 메타데이터 추출하여 객체/배경 정보, 액션 정보, 글의 감성/분위기 등 메타데이터를 추출하며, 영상 또는 이미지 내의 주요 객체의 키포인트 추출은 이미지로부터 AI 을 통하여 인간의 신체 모션이나, 얼굴 표정, 동물의 모션 등의 키포인트를 추출한다. 또한, 자동 저작 기능은 크게 동적 콘텐츠 자동 생성, 스케치 기반 캐릭터 자동 생성, 감정 기반 삽화 자동 변 환의 세 가지로 나뉠 수 있다. 여기서 동적 콘텐츠 자동 생성은, 이미지에서 배경을 선택하여 뉴럴넷 기반 예측을 통해 배경 모션의 시퀀스를 생성하여 배경이 움직이는 동적 콘텐츠를 생성할 수 있으며, 이미지에서 인간, 동물 등의 객체를 선택하여 뉴럴 넷 기반 예측을 통해 객체 액션의 시퀀스를 생성하여 객체가 움직이는 동적 콘텐츠를 생성할 수 있다. 또한 배경과 객체가 모두 움직이는 동적 콘텐츠도 물론 생성할 수 있다. 여기서 스케치 기반 캐릭터 자동 생성은, 사용자가 창작한 스케치를 입력하면 뉴럴넷 기반 변환을 통해 캐릭터 모델, 비슷한 실사 등을 생성할 수 있다. 여기서 감정기반 삽화 자동 변환은, 입력된 이미지를 입력된 텍스트에서 검출된 글의 분위기에 따라 뉴럴넷 기 반 변환하여 분위기에 적합한 화풍으로 변경할 수 있고, 입력된 이미지를 입력된 텍스트에서 검출된 글의 분위 기에 따라 뉴럴넷 기반 효과 선정 및 overlay(오버레이)를 통해 분위기에 적합한 그래픽 효과로 이미지를 변경 할 수 있다. 이하 본 발명의 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법에 대한 실시예를 나타낸다. 도 2는 본 발명의 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도이다. 도 2를 참조하면, 본 발명의 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법은 사용자가 텍스트 및 이 미지를 입력하는 단계(S100), 인공지능 기반 메타데이터 분석 및 기록하는 단계(S200), 창작물 생성하는 단계 (S300)를 포함한다. 여기서 입력하는 단계(S100)는, 콘텐츠 생성을 위해 생성할 콘텐츠와 관련된 텍스트와 이미지를 사용자가 입력 한다. 여기서 사용자가 입력한 텍스트는 사용자가 사용자 단말의 입력 수단을 통해 직접 입력하거나 사용자 단말에 저 장된 텍스트, 이러한 사용자 단말과 연동된 SNS 등 소셜 플랫폼 상에서 상기 사용자 단말의 입력 수단을 통해 입력한 텍스트일 수 있고, 또는 이러한 사용자 단말과 연동된 SNS 등 소셜 플랫폼 상에서 사용자가 업로드 또는 다운로드 한 이미지 등에 포함된 텍스트일 수 있다. 따라서 이러한 텍스트는 사용자 등이 작성한 블로그의 글, 메신저 대화에 사용된 문장, e-book에 포함된 글 등 이 될 수 있다. 여기서 사용자가 입력한 이미지는, 동적 콘텐츠를 생성하기 위해 주요 객체 및 배경을 포함하는 정적 이미지, 스케치 기반 이미지 콘텐츠를 생성하기 위해 사용자가 창작한 스케치 이미지, 삽화 콘텐츠를 생성하기 위해 분 위기를 변환할 삽화 이미지 중 어느 하나 이상일 수 있다. 이러한 이미지 또한 사용자가 사용자 단말의 입력 수단을 통해 직접 입력하거나 사용자 단말에 저장된 이미지, 이러한 사용자 단말과 연동된 SNS 등 소셜 플랫폼 상에서 사용자가 업로드 또는 다운로드 한 이미지 등이 포함 될 수 있다. 따라서 이러한 이미지는 사용자 단말에 저장된 사진 등이 될 수 있다. 도 3은 본 발명의 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도이다. 도 3은, 도 2의 메타데이터 분석 및 기록하는 단계(S200)를 세분화하여 설명한다. 여기서 메타데이터 분석 및 기록하는 단계(S200)는, 인공지능을 기반으로 하여 사용자가 입력한 텍스트 및 사용 자가 입력한 이미지 데이터의 메타데이터를 분석하여 각각 텍스트 메타데이터 및 이미지 메타데이터로 기록한다. 여기서 메타데이터 분석 및 기록하는 단계(S200)는, 텍스트의 메타데이터를 분석하는 텍스트 분석 단계(S221), 이미지의 메타데이터를 분석하는 이미지 분석 단계(S222)를 포함할 수 있다. 여기서 텍스트 분석 단계(S221)에서는, 사용자가 입력한 텍스트에 대하여 인공지능을 기반으로 문장 분석, 여러 개의 복합 문장이 있는 문단 분석, 문단 분석 중 가장 중요한 문장을 추출, 여러 문장을 복합적으로 분석하는 등 텍스트 분석을 통해 액션정보, 객체정보, 배경정보, 글의 감성, 글의 분위기를 추출하여 메타데이터를 생성 할 수 있다. 여기서 이미지 분석 단계(S222)에서는, 사용자가 입력한 이미지에 대하여 인공지능을 기반으로 이미지의 배경과 전경을 분리하고, 이미지 내의 사람의 전신, 사람의 얼굴, 동물, 캐릭터, 스케치, 삽화 등을 이미지 분석하여 배경 및 전경 정보, 객체의 특징점을 추출하여 메타데이터를 생성할 수 있다. 여기서 객체의 특징점은 신체의 모션, 포즈나 얼굴의 표정, 얼굴 내 눈, 코, 입의 모양 등이 될 수 있다. 다만 메타데이터 분석 및 기록 단계(S200)에서는 입력하는 단계(S100)에서 사용자가 입력한 데이터 중 이미지 데이터가 존재하는지 먼저 확인하여(S210), 입력된 데이터 중 입력된 이미지가 있는 경우에는 인공지능 기반 텍 스트/이미지 메타데이터 분석 단계(S220), 즉 텍스트 분석 단계(S221) 및 이미지 분석 단계(S222)는 그대로 진 행된다. 다만, 입력된 이미지가 없는 경우에는 인공지능을 기반으로 하여 입력된 텍스트의 메타데이터를 먼저 분석하고 (S211), 분석 결과 도출된 객체 및 배경 정보에 따라 데이터베이스에서 입력된 텍스트에 맞는 이미지를 검색하 여 저장하고(S212), 검색하여 저장된 이미지를 사용자가 입력한 이미지로 보아 인공지능 기반 텍스트/이미지 메 타데이터 분석 단계(S220), 즉 텍스트 분석 단계(S221) 및 이미지 분석 단계(S222)가 진행된다. 즉, 텍스트 분석 단계(S221)는 이미지 유무와 무관하게 진행되고, 이미지 분석 단계(S222)는 이미지가 없으면 텍스트 분석 단계(S221)에서 분석된 메타데이터 결과에 따라 데이터베이스에서 로드된 이미지를 기준으로 진행 된다. 여기서 데이터베이스에는 저작권의 문제가 없는 이미지를 수집하여야 할 것이다. 여기서 데이터베이스에 수집되어 있는 객체, 배경, 분위기 등 정보가 태깅되어 있을 수 있다. 여기서 텍스트 분석 단계(S221) 및 이미지 분석 단계(S222)에서는 생성된 메타데이터를 소정의 양식에 따라 데 이터베이스에 각각 텍스트 메타데이터 및 이미지 메타데이터로 기록할 수 있다.도 4는 본 발명의 동적 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도이 다. 도 4는, 도 3의 창작물 생성하는 단계(S300)를 세분화하여 설명한다. 도 4는, 창작물 중 동적 콘텐츠를 생성하는 경우를 나타낸다. 도 4를 참조하면, 메타데이터 분석 단계(S200)에서 분석된 메타데이터에 따라 이미지를 기초로 하여 동영상을 생성(S300)한다. 먼저, 이미지 메타데이터를 기준으로 배경과 객체를 분리한다. 여기서 배경은 이미지 메타데이터 중 전경 분리 정보, 객체/배경 정보에 따라 분리될 수 있다. 여기서 분리된 배경의 모션은 해당 배경의 일반적인 액션 또는 텍스트 메타데이터에서 나타난 액션 정보, 글의 감성, 글의 분위기에 따라 움직이도록 동적 이미지로 변경되어 배경 모션 동영상(배경 모션)을 생성한다(S311). 여기서 객체는 이미지 메타데이터 중 액션 정보, 특징점 정보에 따라 분리될 수 있다. 여기서 분리된 객체의 신체 모션, 얼굴 표정 등은 상기 객체의 일반적인 액션 또는 텍스트 메타데이터에서 나타 난 액션 정보, 글의 감성, 글의 분위기에 따라 움직이도록 동적 이미지로 변경되어 객체 모션 동영상(객체 모션)을 생성한다(S312). 이러한 배경 모션 생성(S311) 및 객체 모션 생성(S312)은 둘 다 수행될 수도 있고 둘 중 하나만 수행될 수도 있 다. 이러한 생성 과정을 거쳐 이미지로부터 동적 콘텐츠를 생성(S313)할 수 있다. 이에 따라 메신저 또는 e-book 등에서 분석하는 글에 맞는 동적 영상을 생성하고자 하는 경우 텍스트 메타데이 터에 나타난 글의 객체, 글의 배경, 액션 정보 등을 통하여 모션 동영상을 생성할 수 있다. 예를 들어, 메신저에서 “오늘 줄넘기를 했다”고 입력(S100)하면 텍스트로부터 “줄넘기”라는 액션 정보를 추 출하여 텍스트 메타데이터로 기록(S211)하고, 사용자의 휴대폰 저장 공간에 있는 사용자의 사진을 불러와(S212) 줄넘기 모션을 하는 동영상을 생성(S313)할 수 있다. 또한 예를 들어, 동화책(e-book)(S100)에서 동화책 그림(이미지)과 내용(텍스트)을 각각 추출하고, 텍스트로부 터 객체 정보를 추출(S220)하여 그림 내 해당 객체가 움직이는 동영상을 생성(S313)할 수 있다. 도 5는 본 발명의 스케치 기반 이미지 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도이다. 도 5는, 도 3의 창작물 생성하는 단계(S300)를 세분화하여 설명한다. 도 5는, 창작물 중 스케치 기반 이미지 콘텐츠를 생성하는 경우를 나타낸다. 도 5를 참조하면, 메타데이터 분석 단계(S200)에서 분석된 메타데이터에 따라 스케치 이미지를 기초로 하여 스 케치 기반 이미지를 생성한다(S320). 본 발명의 실시예에서는 이미지를 입력하지 않는 경우에 텍스트 메타데이터를 기초로 데이터베이스로부터 이미 지를 로드하는 단계(S212)를 보통 포함하나, 도 5를 참조하면, 스케치 기반 이미지 생성에 있어서는 이러한 단 계를 생략할 수 있다. 이는 스케치 기반 이미지 생성을 위해서는 사용자의 스케치 이미지가 입력되는 것이 보통일 것이기 때문이다. 다만 스케치 기반 이미지 생성에 있어서도 이미지를 입력하지 않는 경우의 단계(S211, S212)를 완전히 배제하는 것은 아니다. 사용자의 스케치를 입력 받아 글의 객체정보 등과 융합하여 이미지 또는 캐릭터로 변경할 수 있다. 도 5를 참조하면, 사용자가 입력한 이미지가 사용자가 창작한 스케치 이미지인 경우에는, 인공지능 기반 메타데 이터 분석 및 기록 단계(S200) 이후에 이미지 메타데이터 중 스케치의 신체 모션, 얼굴 표정, 눈코입의 모양 등 을 참조하여, 사용자가 선택한 화풍 또는 텍스트 메타데이터에서 나타난 분위기, 화풍 등에 따라 이미지를 변경 하는 화풍변화(S321)가 이루어질 수 있다.또한 인공지능 기반 메타데이터 분석 및 기록 단계(S200) 이후에 이미지 메타데이터 중 스케치의 일부의 색체를 사용자가 선택한 색체 또는 텍스트 메타데이터에서 나타난 내용에 따라 색체를 변경하는 색체변화(S322)가 이루 어질 수 있다. 이러한 화풍변화(S321) 및 색체변화(S322)는 둘 다 수행될 수도 있고 둘 중 하나만 수행될 수도 있다. 이러한 생성 과정을 거쳐 스케치 이미지로부터 스케치 기반 이미지 콘텐츠를 생성(S323)할 수 있다. 여기서 생성되는 스케치 기반 이미지 콘텐츠는 스케치와 관련된 객체 이미지로서 이미지는 실사와 유사하거나, 카툰화된 이미지 등 여러 화풍의 이미지일 수 있고, 사용자가 일부분에 색을 선택하여 원하는 색을 입힌 이미지 를 생성할 수 있다. 또한 원하는 그림체를 사용자가 선택하거나 텍스트로부터 검출한 글의 분위기로부터 자동 선택되어 반영될 수 있으며, 스케치가 어떤 객체에 대한 것인지 텍스트로부터 유추하여 더욱 정확한 변경이 가능하다. 도 6은 본 발명의 삽화 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도이 다. 도 6은, 도 3의 창작물 생성하는 단계(S300)를 세분화하여 설명한다. 도 6는, 창작물 중 삽화 콘텐츠를 생성하는 경우를 나타낸다. 도 6을 참조하면, 메타데이터 분석 단계(S200)에서 분석된 메타데이터에 따라 삽화 이미지를 기초로 하여 삽화 콘텐츠를 생성한다(S330). 이를 통해 블로그 글 등에 맞는 이미지를 추가하고자 할 경우에는 사용자가 입력한 이미지 또는 데이터베이스에 서 로드한 이미지를 텍스트 메타데이터 중 글의 감성에 맞게 화풍을 변경하거나 그래픽 효과를 추가할 수 있다. 도 6을 참조하면, 사용자가 입력한 이미지가 분위기를 변환할 삽화 이미지인 경우에는, 인공지능 기반 메타데이 터 분석 및 기록 단계(S200) 이후에 이미지 메타데이터 중 삽화 이미지의 배경 및 객체를 사용자가 선택한 화풍 또는 텍스트 메타데이터에서 나타난 분위기, 화풍 등에 따라 이미지를 변경하는 화풍변화(S331)가 이루어질 수 있다. 또한 인공지능 기반 메타데이터 분석 및 기록 단계(S200) 이후에 이미지 메타데이터 중 삽화 이미지의 배경 및 객체의 그래픽 효과를 사용자가 선택한 그래픽 효과 또는 텍스트 메타데이터에서 나타난 분위기, 화풍, 전경 분 리 정보 등에 따라 변경하는 그래픽 오버레이(S332)가 이루어질 수 있다. 이러한 화풍변화(S331) 및 그래픽 오버레이(S332)는 둘 다 수행될 수도 있고 둘 중 하나만 수행될 수도 있다. 이러한 생성 과정을 거쳐 삽화 이미지로부터 변경된 삽화 콘텐츠를 생성(S333)할 수 있다. 이처럼 텍스트로부터 글의 분위기를 검출하여 이미지의 화풍을 분위기에 맞게 변경되는 감정 기반 삽화 자동 변 환(S331)이 이루어진다. 이 때, 이미지는 사용자가 입력한 이미지 또는 텍스트로부터 검출한 배경/객체 정보로부터 데이터베이스를 검색 하여 불러온 이미지가 될 수 있다. 삽화의 동적 그래픽 효과를 감정에 맞게 선택하여 이미지 전체 또는 주요 객체에 오버레이 할 수 있다(S332). 또한, 창작물 생성 단계(S300)에 있어서, 동적 콘텐츠 자동 생성(S310), 스케치 기반 이미지 자동 생성(S320), 감정 기반 삽화 자동 변환(S330)은 순차적으로 연결될 수 있다. 즉, 스케치로 이미지를 생성한 뒤 객체에 모션을 입혀 움직이는 이미지를 생성할 수 있다. 또한 삽화의 화풍을 변경하고 삽화 배경에 흐르는 듯한 효과를 주는 동영상을 생성할 수 있다. 도 7은 본 발명의 스케치 기반 동적 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방 법의 순서도이다. 도 7은 도 5에서 생성된 스케치 기반 이미지에 대해서 다시 텍스트 및 이미지 메타데이터를 분석하여 스케치 기 반 동적 콘텐츠를 생성하는 경우에 대한 것이다. 도 7을 참조하면, 스케치 이미지 및 텍스트 메타데이터를 통해 스케치 기반 이미지를 자동 생성(S320)한 이후 텍스트 및 스케치 기반 이미지의 메타데이터를 다시 분석하여(S410) 배경 및 객체에 모션을 부여하고(S411, S412), 스케치 기반 동적 콘텐츠를 생성(S413)할 수 있다. 여기서 메타데이터를 다시 분석하는 단계(S410)는, 인공지능 기반하여 메타데이터 분석 및 기록하는 단계(S20 0)와 동일하게 이루어지며, 다만 사용자가 입력한 이미지 대신 이 전 단계에서 생성된 스케치 기반 이미지 콘텐 츠에 대한 메타데이터가 분석된다. 여기서 스케치 기반 동적 콘텐츠를 생성하는 단계(S413)는 동적 콘텐츠를 생성하는 단계(S310)와 동일하게 이루 어지며, 스케치 기반 이미지 콘텐츠의 배경 모션 동영상을 생성(S411)하고, 객체 모션 동영상을 생성(S412)할 수 있다. 여기서 배경 모션 동영상 생성(S411)은 동적 콘텐츠 생성 단계(S310)에서의 배경 모션 동영상 생성(S311)과 동 일하게 수행된다. 여기서 객체 모션 동영상 생성(S412)은 동적 콘텐츠 생성 단계(S310)에서의 객체 모션 동영상 생성(S312)과 동 일하게 수행된다. 그 결과 스케치 기반 동적 콘텐츠가 생성된다(S413). 여기서, 스케치 기반 이미지에 대해 이미지 메타데이터만 분석하거나(S410) 다시 텍스트 및 이미지 메타데이터 분석(S410)을 거치지 않고 이전에 저장된 메타데이터를 가지로 배경 모션(S411) 및/또는 객체 모션(S412)을 생 성하여 스케치 기반 동적 콘텐츠를 생성할 수도 있다(S413). 도 8은 본 발명의 동적 삽화 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순 서도이다. 도 8은 도 6에서 생성된 삽화 이미지에 대해서 다시 텍스트 및 이미지 메타데이터를 분석하여 동적 삽화 콘텐츠 를 생성하는 경우에 대한 것이다. 도 8을 참조하면, 삽화 이미지 및 텍스트 메타데이터를 통해 변경된 삽화 이미지를 자동 생성(S333)한 이후 텍 스트 및 삽화 이미지의 메타데이터를 다시 분석하여(S420) 배경 및 객체에 모션을 부여하고(S421, S422), 동적 삽화 콘텐츠를 생성(S423)할 수 있다. 여기서 메타데이터를 다시 분석하는 단계(S420)는, 인공지능 기반하여 메타데이터 분석 및 기록하는 단계(S20 0)와 동일하게 이루어지며, 다만 사용자가 입력한 이미지 대신 이 전 단계에서 생성된 삽화 이미지 콘텐츠에 대 한 메타데이터가 분석된다. 여기서 동적 삽화 콘텐츠를 생성하는 단계(S423)는 동적 콘텐츠를 생성하는 단계(S310)와 동일하게 이루어지며, 삽화 이미지 콘텐츠의 배경 모션 동영상을 생성(S421)하고, 객체 모션 동영상을 생성(S422)할 수 있다. 여기서 배경 모션 동영상 생성(S421)은 동적 콘텐츠 생성 단계(S310)에서의 배경 모션 동영상 생성(S311)과 동 일하게 수행된다. 여기서 객체 모션 동영상 생성(S422)은 동적 콘텐츠 생성 단계(S310)에서의 객체 모션 동영상 생성(S312)과 동 일하게 수행된다. 그 결과 동적 삽화 콘텐츠가 생성된다(S423). 이 외에도 동적 콘텐츠 자동 생성(S310), 스케치 기반 이미지 자동 생성(S320), 감정 기반 삽화 자동 변환 (S330)은 순차적으로 연결되어 최종 창작물을 생성할 수 있다. 여기서, 삽화 콘텐츠에 대해 이미지 메타데이터만 분석하거나(S420) 다시 텍스트 및 이미지 메타데이터 분석 (S420)을 거치지 않고 이전에 저장된 메타데이터를 가지로 배경 모션(S421) 및/또는 객체 모션(S422)을 생성하 여 동적 삽화 콘텐츠를 생성할 수도 있다(S423). 이후 사용자는 사용자의 편집을 통해 세부 보정이 가능하다. 여기서 사용자는 타임라인, 다중레이어 기능 등을 사용하여 동적 콘텐츠, 스케치 기반 이미지 콘텐츠, 삽화 콘 텐츠 등을 보정할 수 있다. 여기서 사용자는 생성된 동적 콘텐츠에 대해서 서비스 제공 서버에서 제공하는 타임라인, 다중 레이어 등의 기 능을 사용 하여 배경 모션 및 객체 모션의 움직임 요소의 추가, 삭제, 변경은 물론이고, 별도 이미지 또는 텍스트 등의 새로운 요소의 추가, 배경의 삭제, 객체의 전부 또는 일부의 삭제 등 편집을 가하여 최종 저작물을 생 성할 수 있다. 여기서 사용자는 생성된 동적 콘텐츠에 대해 보정 없이 최종 저작물로 확정할 수도 있다. 이후 생성한 저작물을 SNS 등에 바로 업로드 하거나 메신저로 전송할 수 있도록 연동할 수 있다. 여기서 저작물을 업로드하기 용이한 형태로 저장할 수 있다. 여기서 최종 저작물을 사용자 단말과 연동된 소셜 플랫폼 등에 업로드하기 용이한 형태로 저장하고, 상기 최종 저작물을 상기 소셜 플랫폼 등에 바로 업로드 하거나 메신저로 전송할 수 있도록 사용자 단말을 네트워크에 연 동하는 것을 포함할 수 있다. 여기서 사용자는 최종 저작물을 SNS등을 통하여 배포하여 사용할 수 있다. 여기서 이러한 각 단계는 사용자의 PC 등에 설치되어 동작하거나 웹기반으로 동작할 수도 있다. 사용자의 PC에서 또는 모바일에서 동작 할 수도 있다. 이상, 본 발명의 실시 예는 상술한 장치 및/또는 운용방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실 시 예의 구성에 대응하는 기능을 실현하기 위한 프로그램, 그 프로그램이 기록된 기록 매체 등을 통해 구현될"}
{"patent_id": "10-2020-0097122", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수도 있으며, 이러한 구현은 앞서 설명한 실시 예의 기재로부터 본 발명이 속하는 기술분야의 전문가라면 쉽게 구현할 수 있는 것이다. 이상에서 본 발명의 실시 예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이 에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변 형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2020-0097122", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 주요 기능을 나타낸 예시도, 도 2는 본 발명의 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도, 도 3은 본 발명의 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도, 도 4는 본 발명의 동적 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도, 도 5는 본 발명의 스케치 기반 이미지 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도, 도 6은 본 발명의 삽화 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순서도, 도 7은 본 발명의 스케치 기반 동적 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방 법의 순서도, 도 8은 본 발명의 동적 삽화 콘텐츠 생성하는 일 실시예에 의한 인공지능 콘텐츠 자동 생성 및 변형 방법의 순 서도이다."}
