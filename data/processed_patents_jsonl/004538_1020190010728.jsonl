{"patent_id": "10-2019-0010728", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0101486", "출원번호": "10-2019-0010728", "발명의 명칭": "인공지능 이동 로봇 및 이의 제어 방법", "출원인": "엘지전자 주식회사", "발명자": "주형국"}}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "본체;상기 본체를 이동시키는 구동부;상기 본체의 주변을 촬영하여 상기 본체의 주행 영역에 대한 영상 정보를 생성하는 촬영부;상기 주행 영역에 설치된 감시 수단과 통신하여 상기 감시 수단의 촬영 정보를 전송받는 통신부; 및상기 구동부를 제어하여 상기 본체의 주행을 제어하고, 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단하는 제어부;를 포함하고,상기 제어부는,상기 주행 영역을 감시하여 주행하는 감시 모드가 설정된 경우,상기 촬영 정보를 근거로 감시 대상 영역을 설정하여, 상기 감시 대상 영역을 감시하도록 상기 본체의 주행 및상기 촬영부의 촬영 중 하나 이상을 제어하여 상기 주행 영역을 감시하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 촬영부는,상기 본체의 후측 상부에 구비되어 상기 본체의 주행 방향을 촬영하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 통신부는,하나 이상의 감시 수단과 통신하여, 상기 감시 수단 각각으로부터 촬영 정보를 전송받는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 감시 모드는,상기 주행 영역을 주행하는 중 상기 감시 대상 영역의 주변을 주행 및 촬영하여 집중 감시하는 모드인 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 감시 모드는,주행 시간대에 따라 상기 감시 대상 영역의 주행을 달리하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 감시 모드는,공개특허 10-2020-0101486-3-기설정된 기준 시간대에 주행하는 경우,상기 이동 로봇의 외부에 상기 감시 모드에 따른 주행 중임을 나타내는 시각 표시를 표시하며 상기 감시 대상영역의 주변을 주행하도록 설정된 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 제어부는,상기 기준 시간대에 상기 주행 경로를 주행하는 경우,상기 본체의 주행 및 상기 촬영부의 촬영 외의 동작을 제한하며 상기 감시 대상 영역의 주변을 주행하도록 제어하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 제어부는,상기 촬영 정보를 근거로 상기 감시 수단의 촬영 영역을 판단하여, 상기 촬영 영역을 근거로 상기 감시 대상 영역을 설정하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 제어부는,상기 주행 영역 중 상기 촬영 영역을 제외한 영역을 상기 감시 대상 영역으로 설정하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 제어부는,상기 주행 영역 중 상기 감시 대상 영역을 기설정된 감시 기준에 따라 주행 및 촬영하도록 상기 본체의 주행 및상기 촬영부의 촬영을 제어하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항에 있어서,상기 제어부는, 상기 감시 대상 영역에서 위치가 변화되는 대상물을 인식한 경우, 인식 결과에 대한 알림 정보를 생성하여, 상기 알림 정보를 상기 통신부와 통신하는 통신 대상 수단에 전송하는것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1 항에 있어서,상기 제어부는,상기 촬영 정보 및 상기 감시 모드의 수행 결과를 근거로 상기 주행 영역의 감시 정보를 생성하여, 상기 감시정보를 상기 통신부와 통신하는 통신 대상 수단 및 상기 감시 수단에 전송하는 것을 특징으로 하는 이동 로봇."}
{"patent_id": "10-2019-0010728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2020-0101486-4-본체;상기 본체를 이동시키는 구동부;상기 본체의 주변을 촬영하여 상기 본체의 주행 영역에 대한 영상 정보를 생성하는 촬영부;상기 주행 영역에 설치된 감시 수단과 통신하여 상기 감시 수단의 촬영 정보를 전송받는 통신부; 및상기 구동부를 제어하여 상기 본체의 주행을 제어하고, 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단하는 제어부;를 포함하는 이동 로봇의 제어 방법에 있어서,상기 감시 수단으로부터 상기 촬영 정보를 전송받는 단계;상기 촬영 정보를 근거로 감시 대상 영역을 설정하는 단계;상기 감시 대상 영역의 주변을 주행 및 촬영하여 감시하는 단계; 및상기 촬영 정보 및 감시 결과에 따라 상기 주행 영역의 감시 정보를 생성하는 단계;를 포함하는 것을 특징으로하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서는 주행 영역을 감시하는 감시 수단으로부터 제공받은 촬영 정보를 근거로 감시 대상 영역을 설정하여, 상기 감시 대상 영역을 감시하도록 본체의 주행 및 촬영부의 촬영 중 하나 이상을 제어하여 상기 주행 영역을 감 시하는 인공지능 이동 로봇 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 주행 영역을 자율주행하는 이동 로봇 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 이동 로봇은 사용자의 조작 없이도 소정 구역을 스스로 주행하면서 자동으로 소정의 동작을 수행하 는 기기이다. 이동 로봇은 구역 내에 설치된 장애물을 감지하여 장애물에 접근하거나 회피하여 동작을 수행한다. 이러한 이동 로봇은 영역을 주행하면서 청소를 수행하는 청소로봇은 물론 영역의 바닥면의 잔디를 깎는 이동 로 봇이 포함될 수 있다. 일반적으로 이동 로봇 장치는 사용자가 탑승하여 사용자의 운전에 따라 이동하면서 바닥 의 잔디를 깎거나 풀을 제초하는 승용형 장치와, 사용자가 수동으로 끌거나 밀어서 이동하면서 잔디를 깎는 워 크비하인드타입 또는 핸드타입의 장치가 있다. 이러한 이동 로봇 장치는 사용자의 직접적인 조작에 의해 이동하 며 잔디를 깎는 것으로 사용자의 직접 장치를 작동해야하는 번거로움이 있다. 그에 따라 이동 로봇에 잔디를 깎 을 수 있는 수단을 구비한 이동 로봇형의 이동 로봇 장치가 연구되고 있다. 이러한 잔디 깎기용 이동 로봇(잔디 깎기)의 경우 실내가 아닌 실외에서 동작하므로, 실내 환경을 주행하는 이 동 로봇에 비해 넓은 영역을 주행하게 된다. 실내의 경우 지면이 단조롭고, 주행에 영향을 주는 지형/지물 등의 요인이 한정적이나, 실외의 경우 열린 공간이므로 주행에 영향을 주는 요인이 다양하고, 또한 지형의 영향을 많 이 받게 된다. 이러한 실외 환경을 주행하는 이동 로봇은, 주행 영역을 자율주행하며 주행 영역의 상태를 감시 할 수 있는데, 이를테면 주행 영역을 침입하는 침입자를 감시하거나, 주행 영역 상의 구조물의 소손 등을 감시 할 수 있다. 그러나, 넓은 영역으로 이루어진 실외 환경의 특성상 감시를 위한 이동 로봇의 감시 경로의 설정이 이루어지기 어려웠으며, 이로 인해 실외 환경의 감시 자체가 효과적으로 이루어지기 어려운 한계가 있었다. 한편, 한국 공개특허 10-2018-0098891(공개일: 2018년09월05일)(이하, 선행문헌이라 칭한다)에는 실내 공간 내 에서 특정 위치를 감시하도록 주행하는 이동 로봇이 개시되어있는데, 이러한 선행문헌에 개시된 이동 로봇은 실 내 환경을 주행하는 이동 로봇에 제한되어, 야외 환경을 주행하는 잔디 깎기용 이동 로봇에 적용되기에는 무리 가 있었다. 즉, 선행문헌은 야외 환경에 따른 요인 및 제약이 고려되지 않아, 야외 환경 상의 구조물을 고려한 주행 제어는 제시하지 못하였다. 결과적으로, 종래의 잔디 깎기용 이동 로봇 기술에서는 넓은 야외 환경 중 침입의 우려가 높은 영역을 적절하게 감시하는 기술이 제안되지 못하였으며, 이로 인해 주행 영역의 안전성 및 보안성이 보장되지 못하는 한계가 있 었다. 또한, 이동 로봇 기술 전반에서도 이러한 한계를 개선할 수 있는 기술 또한 제안되지 못하여, 동적 장애 물에 의한 제약을 해결하지 못하였다."}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 상술한 바와 같은 종래기술의 한계를 개선하는 것을 과제로 한다. 구체적으로는, 주행 영역을 감시하는 감시 수단과 연동하여 주행 영역을 감시할 수 있는 이동 로봇 및 이의 제 어 방법을 제공하고자 한다. 또한, 침입의 우려가 높은 감시 수단의 사각 영역을 효과적으로 감지할 수 있는 이동 로봇 및 이의 제어 방법을 제공하고자 한다. 아울러, 주행 영역 전반에 대한 공백 없는 감시가 이루어질 수 있는 이동 로봇 및 이의 제어 방법을 제공하고자 한다."}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 바와 같은 과제를 해결하기 위한 본 발명에 따른 이동 로봇 및 이의 제어 방법은, 주행 영역 상에 설치 된 타 감시 수단과의 통신을 통해 주행 영역을 감시하도록 제어하는 것을 해결 수단으로 한다. 구체적으로는, 인공지능 기술을 활용/적용하여 상기 주행 영역을 감시하는 모드로 동작, 또는 상기 주행 영역을 감시하는 모드로 주행 제어가 이루어지는 경우, 상기 주행 영역을 감시하는 타 감시 수단과 통신하여 상기 감시 수단의 촬영 정보를 전송받고, 이를 근거로 감시 대상 영역을 설정하여, 상기 감시 대상 영역을 감시하도록 주 행 및 촬영하게 된다. 즉, 본 발명에 따른 이동 로봇 및 이의 제어 방법은, 감시 수단으로부터 제공받은 촬영 정보를 근거로 감시 대 상 영역을 설정하여, 상기 감시 대상 영역을 감시하도록 상기 본체의 주행 및 상기 촬영부의 촬영 중 하나 이상 을 제어하여 상기 주행 영역을 감시하는 것을 해결 수단으로 한다. 이와 같은 해결 수단을 통해 본 발명에 따른 이동 로봇 및 이의 제어 방법은, 감시 수단의 사각 지대에 대한 감 시가 이루어지며 주행 영역을 효율적으로 감시하게 됨으로써, 상술한 바와 같은 과제를 해결하게 된다. 상기와 같은 기술적 특징은, 이동 로봇을 제어하는 제어 수단, 이동 로봇 및 이동 로봇을 제어하는 방법 및 이 동 로봇의 영역 감시 방법/영역 감시를 위한 제어 방법, 또는 인공지능을 적용한 이동 로봇, 인공지능을 활용하 여 영역을 감시하는 방법 등으로 실시될 수 있으며, 본 명세서는 상기와 같은 기술적 특징을 과제 해결 수단으 로 하는 이동 로봇 및 이의 제어 방법의 실시 예를 제공한다. 상기와 같은 기술적 특징을 과제 해결 수단으로 하는 본 발명에 따른 이동 로봇은, 본체, 상기 본체를 이동시키 는 구동부, 상기 본체의 주변을 촬영하여 상기 본체의 주행 영역에 대한 영상 정보를 생성하는 촬영부, 상기 주 행 영역에 설치된 감시 수단과 통신하여 상기 감시 수단의 촬영 정보를 전송받는 통신부 및 상기 구동부를 제어 하여 상기 본체의 주행을 제어하고, 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단하는 제어부를 포함 하고, 상기 제어부는, 상기 주행 영역을 감시하여 주행하는 감시 모드가 설정된 경우, 상기 촬영 정보를 근거로 감시 대상 영역을 설정하여, 상기 감시 대상 영역을 감시하도록 상기 본체의 주행 및 상기 촬영부의 촬영 중 하 나 이상을 제어하여 상기 주행 영역을 감시한다. 또한, 상기와 같은 기술적 특징을 과제 해결 수단으로 하는 본 발명에 따른 이동 로봇의 제어 방법은, 본체, 상 기 본체를 이동시키는 구동부, 상기 본체의 주변을 촬영하여 상기 본체의 주행 영역에 대한 영상 정보를 생성하 는 촬영부, 상기 주행 영역에 설치된 감시 수단과 통신하여 상기 감시 수단의 촬영 정보를 전송받는 통신부 및 상기 구동부를 제어하여 상기 본체의 주행을 제어하고, 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단 하는 제어부를 포함하는 이동 로봇의 제어 방법으로, 상기 감시 수단으로부터 상기 촬영 정보를 전송받는 단계, 상기 촬영 정보를 근거로 감시 대상 영역을 설정하는 단계, 상기 감시 대상 영역의 주변을 주행 및 촬영하여 감 시하는 단계 및 상기 촬영 정보 및 감시 결과에 따라 상기 주행 영역의 감시 정보를 생성하는 단계를 포함한다."}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 이동 로봇 및 이의 제어 방법은, 주행 영역 상에 설치된 타 감시 수단과의 통신을 통해 주행 영 역을 감시하도록 제어함으로써, 침입의 우려가 있는 특정 영역을 집중 감시할 수 있는 효과가 있다. 또한, 본 발명에 따른 이동 로봇 및 이의 제어 방법은, 침입의 우려가 높은 감시 수단의 사각 영역을 효과적으 로 감지할 수 있으며, 주행 영역 전반에 대한 공백 없는 감시가 이루어질 수 있는 효과가 있다.아울러, 본 발명에 따른 이동 로봇 및 이의 제어 방법은, 주기적인 감시가 이루어지기 어려운 주행 영역을 간편 하게 감시할 수 있으며, 주행 영역의 안전성 및 보안성을 증대시킬 수 있는 효과가 있다. 결과적으로, 본 발명에 따른 이동 로봇 및 이의 제어 방법은, 종래기술의 한계를 개선함은 물론, 인공지능을 활 용/적용한 잔디 깎기용 이동 로봇 기술 분야의 정확성, 신뢰성, 안정성, 적용성, 효율성, 효용성 및 활용성을 증대시킬 수 있게 되는 효과가 있다."}
{"patent_id": "10-2019-0010728", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 첨부된 도면을 참조하여 본 발명에 따른 이동 로봇 및 이의 제어 방법의 실시 예들을 상세히 설명 하되, 도면 부호에 관계없이 동일하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 명세서에 개시된 기술을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시 된 기술의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 기술의 사상을 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 그 기술의 사상이 제한되 는 것으로 해석되어서는 아니 됨을 유의해야 한다. 이하, 본 발명에 따른 이동 로봇(이하, 로봇이라 칭한다)의 실시 형태를 설명한다. 상기 로봇은, 자율주행이 가능한 로봇, 잔디 깎기 이동 로봇, 잔디 깎기 로봇, 잔디 깎기 장치, 또는 잔디 깎기 용 이동 로봇을 의미할 수 있다. 상기 로봇은, 도 1a에 도시된 바와 같이, 본체, 상기 본체를 이동시키는 구동부, 상기 본체 의 주변을 촬영하여 상기 본체의 주행 영역에 대한 영상 정보를 생성하는 촬영부, 상기 주행 영역에 설치된 감시 수단과 통신하여 상기 감시 수단의 촬영 정보를 전송받는 통신부 및 상기 구동부 를 제어하여 상기 본체의 주행을 제어하고, 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단하는 제어부를 포함한다. 상기 제어부는, 상기 본체의 현재 위치를 판단하여, 상기 주행 영역 내를 주행하도록 상기 구동 부를 제어하여 상기 본체의 주행을 제어하고, 상기 본체가 상기 주행 영역을 주행하는 중 상 기 촬영부가 상기 본체의 주변을 촬영하도록 제어하여, 상기 촬영부에서 생성된 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단할 수 있다.이와 같이 상기 본체, 상기 구동부, 상기 촬영부, 상기 통신부 및 상기 제어부를 포함하는 상기 로봇에서 상기 제어부는, 상기 주행 영역을 감시하여 주행하는 감시 모드가 설정된 경우, 상기 주행 영역을 감시하여 주행하는 감시 모드가 설정된 경우, 상기 촬영 정보를 근거로 감시 대상 영역 을 설정하여, 상기 감시 대상 영역을 감시하도록 상기 본체의 주행 및 상기 촬영부의 촬영 중 하나 이 상을 제어하여 상기 주행 영역을 감시한다. 즉, 상기 로봇은, 상기 감시 모드가 설정된 경우, 상기 제어부가 상기 감시 대상 영역을 감시하도록 주행을 제어하는 것을 특징으로 한다. 상기 로봇은, 도 1b 및 1c에 도시된 바와 같이 이동이 가능하도록 마련되어서, 잔디를 절삭할 수 있는 상 기 본체를 포함하는 자율주행 로봇일 수 있다. 상기 본체는 상기 로봇의 외관을 형성하고, 상기 로봇의 주행 및 잔디 절삭 등의 동작이 수행되는 하나 이상의 수단이 구비된다. 상기 본체에는 상기 본체를 원하는 방향으로 이동시키고, 회전시킬 수 있는 상기 구동부가 마련된다. 상기 구동부는 복 수 개의 회전 가능한 구동 바퀴를 포함할 수 있고, 각각의 바퀴는 개별적으로 회전될 수 있어서, 상기 본체(1 0)가 원하는 방향으로 회전될 수 있다. 보다 구체적으로 상기 구동부는 적어도 하나의 주 구동 바퀴(11a)와, 보조 바퀴(11b)를 포함할 수 있다. 예를 들어, 상기 본체는 두개의 주 구동 바퀴(11a)를 포함 할 수 있으며, 상기 주 구동 바퀴는 상기 본체의 후방 저면에 설치될 수 있다. 상기 로봇은, 도 2에 도시된 바와 같은 주행 영역 내에서 스스로 주행할 수 있다. 상기 로봇은 주행 중에 특정 동작을 수행할 수 있다. 여기서, 상기 특정 동작은, 상기 주행 영역 내의 잔디를 절삭하 는 동작일 수 있다. 상기 주행 영역은 상기 로봇의 주행 및 동작 대상에 해당하는 영역으로, 소정의 실외/야외 영역이 상기 주행 영역으로 형성될 수 있다. 이를테면, 상기 로봇이 잔디를 절삭하기 위 한 정원, 마당 등이 상기 주행 영역으로 형성될 수 있다. 상기 주행 영역에는 상기 로봇의 구 동 전원이 충전되는 충전 장치가 설치될 수 있으며, 상기 로봇은 상기 주행 영역 내에 설치된 상기 충전 장치에 도킹하여 구동 전원을 충전하게 될 수 있다. 상기 주행 영역은 도 2에 도시된 바와 같이 일정한 경계 영역으로 형성될 수 있다. 상기 경계 영역 은, 상기 주행 영역과 외부 영역의 경계선에 해당되어, 상기 로봇이 상기 경계 영역 내에서 상기 외부 영역을 벗어나지 않도록 주행하게 될 수 있다. 이 경우, 상기 경계 영역 은 폐곡선 또는 폐루프로 형성될 수 있다. 또한, 이 경우에 상기 경계 영역은 폐곡선 또는 폐루프로 형성 되는 와이어에 의해 정의될 수 있다. 상기 와이어는 임의의 영역에 설치될 수 있으며, 상기 로봇 은 설치된 와이어에 의해 형성되는 폐곡선의 주행 영역 내에서 주행할 수 있다. 상기 주행 영역에는 또한, 도 2에 도시된 바와 같이 하나 이상의 송출기가 배치될 수 있다. 상기 송 출기는, 상기 로봇이 위치 정보를 판단하기 위한 신호를 송출하는 신호 발생 수단으로, 상기 주행 영 역 내에 분산 배치되어 설치될 수 있다. 상기 로봇은 상기 송출기에서 송출된 신호를 수신하여, 수신 결과를 근거로 현재 위치를 판단하거나, 상기 주행 영역에 대한 위치 정보를 판단할 수 있다. 이 경우, 상기 로봇은 상기 신호를 수신하는 수신부를 통해 상기 신호를 수신할 수 있다. 상기 송출 기는, 바람직하게는 상기 주행 영역에서 상기 경계 영역의 근방에 배치될 수 있다. 이 경우, 상기 로봇은 상기 경계 영역의 근방에 배치된 상기 송출기의 배치 위치를 근거로 상기 경계 영 역을 판단하게 될 수 있다. 도 2에 도시된 바와 같은 상기 주행 영역을 주행하며 잔디를 절삭하는 상기 로봇은, 도 3a에 도시된 바와 같은 주행 원리에 동작할 수 있고, 도 3b에 도시된 바와 같은 위치 판단을 위한 장치 간의 신호 흐름이 이 루어질 수 있다. 상기 로봇은 도 3a에 도시된 바와 같이 소정 영역을 이동하는 단말과 통신하며, 상기 단말로부 터 수신한 데이터를 바탕으로 상기 단말의 위치를 추종하며 주행할 수 있다. 상기 로봇은, 상기 단말 로부터 수신되거나 또는 상기 단말을 추종하여 주행하는 중에 수집되는 위치 정보를 근거로 소정 영 역에 가상의 경계를 설정하고, 경계에 의해 형성되는 내부 영역을 상기 주행 영역으로 설정할 수 있다. 상기 로봇은, 상기 경계 영역 및 상기 주행 영역이 설정되면, 상기 경계 영역을 벗어나 지 않도록 상기 주행 영역 내를 주행할 수 있다. 경우에 따라 상기 단말은 상기 경계 영역을 설정하여 상기 로봇에 전송할 수 있다. 상기 단말은 영역을 변경하거나 확장하는 경우, 변경된 정보 를 상기 로봇에 전송하여, 상기 로봇이 새로운 영역에서 주행하도록 할 수 있다. 또한, 상기 단말 은 상기 로봇으로부터 수신되는 데이터를 화면에 표시하여 상기 로봇의 동작을 모니터링할 수있다. 상기 로봇 또는 상기 단말은, 위치 정보를 수신하여 현재 위치를 판단할 수 있다. 상기 로봇 및 상기 단말은 상기 주행 영역에 배치된 상기 송출기로부터 송신되는 위치 정보, 또는 GPS위성 을 이용한 GPS신호를 바탕으로 현재 위치를 판단할 수 있다. 상기 로봇 및 상기 단말은, 바람직 하게는 3개의 송출기로부터 전송되는 신호를 수신하여 신호를 비교함으로써 현재 위치를 판단할 수 있다. 즉, 상기 송출기는, 바람직하게는 상기 주행 영역에 3개 이상이 배치될 수 있다. 상기 로봇은 상기 주행 영역 내의 어느 하나의 지점을 기준 위치로 설정한 후, 이동 중 위치를 좌표 로 산출한다. 예를 들어 초기 시작 위치, 상기 충전 장치의 위치를 기준 위치로 설정할 수 있고, 또한, 상 기 송출기 중 어느 하나의 위치를 기준 위치로 하여 상기 주행 영역에 대한 좌표를 산출할 수 있다. 또한, 상기 로봇은 매 동작 시, 초기 위치를 기준 위치로 설정한 후, 주행하며 위치를 판단할 수도 있다. 상기 로봇은 기준 위치를 기준으로, 상기 구동 바퀴의 회전수, 회전 속도, 상기 본체의 회전 방향 등을 바탕으로 주행 거리를 연산하고, 이에 따라 상기 주행 영역 내에서의 현재 위치를 판단할 수 있다. 상기 로봇은 상기 GPS위성을 이용하여 위치를 판단하는 경우라도, 어느 하나의 지점을 기준 위치로 하여 위치를 판단할 수 있다. 상기 로봇은, 도 3에 도시된 바와 같이, 상기 송출기 또는 상기 GPS위성에서 송신되는 위치 정 보를 근거로 현재 위치를 판단할 수 있다. 상기 위치 정보는, GPS 신호, 초음파 신호, 적외선 신호, 전자기 신 호 또는 UWB(Ultra Wide Band) 신호의 형태로 전송될 수 있다. 상기 송출기에서 송신되는 신호는, 바람직 하게는 UWB(Ultra Wide Band) 신호일 수 있다. 이에 따라 상기 로봇은, 상기 송출기에서 송신된 UWB(Ultra Wide Band) 신호를 수신하여, 이를 근거로 현재 위치를 판단하게 될 수 있다. 이와 같이 동작하는 상기 로봇은, 도 4에 도시된 바와 같이, 상기 본체, 상기 구동부, 상기 촬영 부, 상기 통신부 및 상기 제어부를 포함하여, 상기 감시 모드가 설정된 경우, 상기 촬영 정보를 근 거로 설정된 상기 감시 대상 영역을 감시하도록 상기 주행 영역을 주행할 수 있다. 상기 로봇은 또 한, 출력부, 저장부, 센싱부, 수신부, 입력부, 장애물 감지부 및 제초부 중 하나 이상을 더 포함할 수 있다. 상기 구동부는, 상기 본체의 하부에 구비되는 구동 바퀴로, 회전 구동하여 상기 본체를 이동시킬 수 있다. 즉, 상기 구동부는, 상기 본체가 상기 주행 영역을 주행하도록 구동하게 될 수 있다. 상기 구동부는, 적어도 하나의 구동모터를 포함하여 상기 로봇이 주행하도록 상기 본체를 이동시 킬 수 있다. 이를테면, 좌륜을 회전시키는 좌륜 구동모터와 우륜을 회전시키는 우륜 구동모터를 포함할 수 있다. 상기 구동부는, 구동 결과에 대한 정보를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 구동부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하 게 될 수 있다. 즉, 상기 구동부는 상기 제어부에 의해 제어될 수 있다. 상기 촬영부는, 상기 본체의 주변을 촬영하는 카메라일 수 있다. 상기 촬영부는, 상기 본체의 전방을 촬영하여 상기 본체의 주변, 상기 주행 영역 상에 존재하는 장애물을 감지할 수 있다. 상기 촬영부는 디지털 카메라로, 이미지센서(미도시)와 영상처리부(미도시)를 포함할 수 있다. 이미지 센서는 광 학 영상(image)을 전기적 신호로 변환하는 장치로, 다수개의 광 다이오드(photo diode)가 집적된 칩으로 구성되 며, 광 다이오드로는 픽셀(pixel)을 예로 들 수 있다. 렌즈를 통과한 광에 의해 칩에 맺힌 영상에 의해 각각의 픽셀들에 전하가 축적되며, 픽셀에 축적된 전하들은 전기적 신호(예를들어, 전압)로 변환된다. 이미지 센서로는 CCD(Charge Coupled Device), CMOS(Complementary Metal Oxide Semiconductor) 등이 잘 알려져 있다. 또한, 상 기 촬영부는 촬영된 결과를 영상 처리하여, 상기 영상 정보를 생성하는 영상처리부(DSP)를 포함할 수 있다. 상기 촬영부는, 촬영 결과를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 촬영부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하게 될 수 있다. 즉, 상기 촬영부는 상기 제어부에 의해 제어될 수 있다. 상기 통신부는, 상기 로봇과 통신하는 하나 이상의 통신 대상 수단과 통신할 수 있다. 상기 통신부 는, 무선 통신 방식으로 상기 송출기 및 상기 단말과 통신할 수 있다. 상기 통신부는 또한, 소정의 네트워크에 연결되어 외부의 서버 또는 상기 로봇을 제어하는 상기 단말과 통신할 수 있다. 상기 단말과 통신하는 경우 상기 통신부는, 생성되는 지도를 상기 단말로 전송하고, 상기 단말로부터 명령을 수신하며, 상기 로봇의 동작 상태에 대한 데이터를 상기 단말로 전송할 수 있다. 상기 통신부는 지그비, 블루투스 등의 근거리 무선 통신뿐 아니라, 와이파이, 와이브로 등의 통신모듈을 포 함하여 데이터를 송수신할 수 있다. 상기 통신부는, 통신 결과에 대한 정보를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 통신부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하 게 될 수 있다. 즉, 상기 통신부는 상기 제어부에 의해 제어될 수 있다. 상기 출력부는, 상기 로봇의 상태에 관한 정보를 음성의 형태로 출력하는 출력수단으로, 이를테면 스 피커를 포함할 수 있다. 상기 출력부는 상기 로봇의 동작 중 이벤트 발생 시, 상기 이벤트에 관한 알 람을 출력할 수 있다. 예를 들면, 상기 로봇의 구동 전원이 소진되거나, 상기 로봇에 충격이 가해지 거나, 상기 주행 영역 상에서 사고가 발생할 시, 사용자에게 이에 대한 정보가 전달되도록 알람 음성을 출력하게 될 수 있다. 상기 출력부는, 동작 상태에 대한 정보를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 출력부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하 게 될 수 있다. 즉, 상기 출력부는 상기 제어부에 의해 제어될 수 있다. 상기 저장부는, 마이크로 프로세서(micro processor)에 의해 읽힐 수 있는 데이터를 저장하는 저장수단으로, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치를 포함할 수 있다. 상기 저장부에는, 수신되는 신호가 저장되고, 장애물을 판단하기 위한 기준 데이터가 저장되며, 감지된 장애물에 대한 장애물 정보가 저장될 수 있 다. 또한, 상기 저장부에는 상기 로봇의 동작을 제어하기 위한 제어 데이터, 상기 로봇의 동작 모드에 따른 데이터, 수집되는 위치 정보, 상기 주행 영역 및 그 경계에 대한 정보가 저장될 수 있 다. 상기 센싱부는, 상기 본체의 자세 및 동작에 대한 정보를 센싱하는 하나 이상의 센서를 포함할 수 있다. 상기 센싱부는, 상기 본체의 움직임을 감지하는 기울기 센서 및 상기 구동부의 구동 속도를 감지하는 속도 센서 중 하나 이상을 포함할 수 있다. 상기 기울기 센서는, 상기 본체의 자세 정보를 센싱하 는 센서일 수 있다. 상기 기울기 센서는, 상기 본체의 전, 후, 좌, 우 방향으로 기울어지는 경우, 기울어진 방향과 각도를 산출하여 상기 본체의 자세 정보를 센싱할 수 있다. 상기 기울기 센서는 틸트 센서, 가속도 센서 등이 사용될 수 있고, 가속도 센서의 경우 자이로식, 관성식, 실리콘 반도체식 중 어느 것이나 적용 가능 하다. 또한, 그 외에 상기 본체의 움직임을 감지할 수 있는 다양한 센서 또는 장치가 사용될 수 있을 것이다. 상기 속도 센서는, 상기 구동부에 구비된 구동 바퀴의 구동 속도를 센싱하는 센서일 수 있다. 상기 속 도 센서는, 상기 구동 바퀴가 회전하는 경우, 상기 구동 바퀴의 회전을 감지하여 구동 속도를 센싱할 수 있다. 상기 센싱부는, 센싱 결과에 대한 정보를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 센싱부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하 게 될 수 있다. 즉, 상기 센싱부는 상기 제어부에 의해 제어될 수 있다. 상기 수신부는, 위치 정보를 송수신하기 위한 복수의 센서모듈을 포함할 수 있다. 상기 수신부는, 상기 송출기로부터 상기 신호를 수신하는 위치 센서 모듈을 포함할 수 있다. 상기 위치 센서 모듈은, 상기 송출 기로 신호를 송신할 수도 있다. 상기 송출기가 초음파, UWB(Ultra Wide Band), 적외선 중 어느 하나 의 방식으로 신호를 송신하는 경우, 상기 수신부는, 그에 대응하여 초음파, UWB, 적외선신호를 송수신하는 센서모듈이 구비될 수 있다. 상기 수신부는, 바람직하게는 UWB 센서를 포함할 수 있다. 참고로, UWB 무선기 술은 무선 반송파(RF carrier)를 사용하지 않고, 기저역(Baseband)에서 수 GHz 이상의 매우 넓은 주파수 역을 사용하는 것을 의미한다. UWB 무선기술은 수 나노 혹은 수 피코 초의 매우 좁은 펄스를 사용한다. 이와 같은 UWB 센서에서 방출되는 펄스는 수 나노 혹은 수 피코이므로, 관통성이 좋고, 그에 따라 주변에 장애물이 존재하 더라도 다른 UWB 센서에서 방출하는 매우 짧은 펄스를 수신할 수 있다. 상기 로봇이 상기 단말을 추종하여 주행하는 경우, 상기 단말과 상기 로봇은 각각 UWB 센 서를 포함하여, 상기 UWB 센서를 통해 상호 간에 UWB 신호를 송수신할 수 있다. 상기 단말은 구비되는 UWB 센서를 통해 UWB 신호를 송출하고, 상기 로봇은 UWB 센서를 통해 수신되는 UWB 신호를 바탕으로 상기 단말 의 위치를 판단하여, 상기 단말을 추종하여 이동할 수 있다. 이 경우, 상기 단말은 송신측, 상 기 로봇은 수신측으로 동작하게 된다. 상기 송출기가 UWB 센서를 구비하여 신호를 송출하는 경우, 상기 로봇 또는 상기 단말은 구비되는 UWB 센서를 통해 상기 송출기에서 송신된 신호를 수신할 수 있다. 이때 상기 송출기의 신호 방식과 상기 로봇 및 상기 단말의 신호 방식은 동일하거나 또는 상이할 수 있다. 상기 수신부는, 복수의 UWB 센서를 포함할 수 있다. 상기 수신부에 두 개의 UWB 센서가 포함되는 경우, 예를 들어 상기 본체의 좌측과 우측에 각각 구비되어, 각각 신호를 수신함으로써, 수신되는 복수의 신호를 비교하여 정확한 위치 산출이 이루어질 수 있다. 예를 들어, 상기 로봇과 상기 송출기 또는 상기 단 말의 위치에 따라, 좌측의 센서와 우측의 센서에서 측정되는 거리가 상이한 경우, 이를 바탕으로 상기 로 봇과 상기 송출기 또는 상기 단말의 상대적 위치, 상기 로봇의 방향을 판단하게 될 수 있 다. 상기 수신부는 또한, GPS위성으로부터 GPS신호를 송수신하는 GPS 모듈을 더 포함할 수 있다. 상기 수신부는, 신호의 수신 결과를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 수신부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하게 될 수 있다. 즉, 상기 수신부는 상기 제어부에 의해 제어될 수 있다. 상기 입력부는, 적어도 하나의 버튼, 스위치, 터치패드 등의 입력 수단과, 디스플레이부 등의 출력 수단을 포함하여 사용자 명령을 입력받고, 상기 로봇의 동작 상태를 출력할 수 있다. 예를 들면, 상기 디스플레이 부를 통해 상기 감시 모드의 수행에 대한 명령이 입력되고, 상기 감시 모드의 수행에 대한 상태를 출력할 수 있 다. 상기 입력부는, 상기 디스플레이부를 통해 상기 로봇의 상태를 표시하고, 상기 로봇의 제어 조작 이 이루어지는 제어 화면을 표시할 수 있다. 상기 제어 화면은, 상기 로봇의 구동 상태가 표시 출력되고, 사용자로부터 상기 로봇의 구동 조작에 대한 명령이 입력되는 사용자 인터페이스 화면을 의미할 수 있다. 상기 제어 화면은, 상기 제어부의 제어를 통해 상기 디스플레이부에 표시되고, 상기 제어 화면 상의 표시 및 입력된 명령 등이 상기 제어부에 의해 제어될 수 있다. 상기 입력부는, 동작 상태에 대한 정보를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 입력부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하 게 될 수 있다. 즉, 상기 입력부는 상기 제어부에 의해 제어될 수 있다. 상기 장애물 감지부는, 복수의 센서를 포함하여 주행방향에 존재하는 장애물을 감지한다. 상기 장애물 감지 부는 레이저, 초음파, 적외선, 3D센서 중 적어도 하나를 이용하여 상기 본체의 전방, 즉 주행 방향의 장애물을 감지할 수 있다. 상기 장애물 감지부는 또한, 상기 본체의 배면에 설치되어 낭떠러지를 감지 하는, 낭떠러지 감지센서를 더 포함할 수 있다. 상기 장애물 감지부는, 감지 결과에 대한 정보를 상기 제어부에 전달하고, 상기 제어부로부터 동작 에 대한 제어 명령을 전달받을 수 있다. 상기 장애물 감지부는, 상기 제어부로부터 전달받은 제어 명령 에 따라 동작하게 될 수 있다. 즉, 상기 장애물 감지부는 상기 제어부에 의해 제어될 수 있다. 상기 제초부는, 주행 중 바닥면의 잔디를 깎는다. 상기 제초부는 잔디를 깎기 위한 브러쉬 또는 칼날이 구비되어 회전을 통해 바닥의 잔디를 깎게 될 수 있다. 상기 제초부는, 동작 결과에 대한 정보를 상기 제어부에 전달하고, 상기 제어부로부터 동작에 대한 제어 명령을 전달받을 수 있다. 상기 제초부는, 상기 제어부로부터 전달받은 제어 명령에 따라 동작하 게 될 수 있다. 즉, 상기 제초부는 상기 제어부에 의해 제어될 수 있다. 상기 제어부는, 중앙 처리 장치를 포함하여 상기 로봇의 전반적인 동작 제어를 수행할 수 있다. 상기 제어부는 상기 본체, 상기 구동부 및 상기 촬영부를 통해, 상기 주행 영역을 주행하는 중 상기 주행 영역의 상태를 판단하여 상기 본체의 주행을 제어하고, 상기 통신부, 상기 출력부 , 상기 저장부, 상기 센싱부, 상기 수신부, 상기 입력부, 상기 장애물 감지부 및 상기 제초부를 통해 상기 로봇의 기능/동작이 수행되도록 제어할 수 있다. 상기 제어부는, 데이터의 입출력을 제어하고, 설정에 따라 상기 본체가 주행하도록 상기 구동부를 제어할 수 있다. 상기 제어부는 상기 구동부를 제어하여 좌륜 구동모터와 우륜 구동모터의 작동을 독립 적으로 제어함으로써, 상기 본체가 직진 또는 회전하여 주행하도록 제어할 수 있다.상기 제어부는, 상기 단말로부터 수신되는 위치 정보 또는 상기 송출기로부터 수신한 신호를 근 거로 판단한 위치 정보를 바탕으로 상기 주행 영역에 대한 경계를 설정할 수 있다. 상기 제어부 는 또한, 주행 중 자체 수집한 위치 정보를 근거로 상기 주행 영역에 대한 경계를 설정할 수도 있다. 상기 제어부는 설정되는 경계에 의해 형성되는 영역 중 어느 일 영역을 상기 주행 영역 으로 설정할 수 있다. 상기 제어부는 불연속적인 위치 정보를 선 또는 곡선으로 연결하여 폐루프(closed loop) 형태로 경계를 설정하고, 내부 영역을 상기 주행 영역으로 설정할 수 있다. 상기 제어부(2 0)는 상기 주행 영역 및 그에 따른 경계가 설정되면, 상기 주행 영역 내에서 주행하며 설정 된 경계를 벗어나지 않도록 상기 본체의 주행을 제어할 수 있다. 상기 제어부는 수신되는 위치 정보를 바탕으로 현재 위치를 판단하고, 판단한 현재 위치가 상기 주행 영역 내에 위치하도록 상기 구동 부를 제어하여 상기 본체의 주행을 제어할 수 있다. 또한, 상기 제어부는, 상기 촬영부 및 상기 장애물 감지부 중 하나 이상에 의해 입력되는 장애물 정보에 따라, 장애물을 회피하여 주행하도록 상기 본체의 주행을 제어할 수 있다. 이 경우 상기 제어부(2 0)는, 상기 장애물 정보를 상기 주행 영역에 대한 기저장된 영역 정보에 반영하여 상기 주행 영역 을 수정하게 될 수 있다. 도 4에 도시된 바와 같은 구성으로 이루어진 상기 로봇은, 상기 감시 모드가 설정된 경우, 상기 제어부 가 상기 감시 수단으로부터 전송받은 상기 촬영 정보를 근거로 상기 감시 대상 영역을 설정하여, 상기 감시 대상 영역을 감시하도록 상기 본체의 주행 및 상기 촬영부의 촬영 중 하나 이상을 제어하여 상기 주행 영역을 감시하게 될 수 있다. 상기 로봇은, 상기 주행 영역을 주행하면서 설정된 동작을 수행하게 될 수 있다. 이를테면, 도 5에 도시된 바와 같은 상기 주행 영역을 주행하면서 상기 주행 영역의 바닥면에 존재하는 잔디를 절삭 하게 될 수 있다. 상기 로봇에서 상기 본체는, 상기 구동부의 구동을 통해 주행하게 될 수 있다. 상기 본체는 상기 구동부가 구동하여 상기 본체를 이동시키게 됨으로써 주행하게 될 수 있다. 상기 로봇에서 상기 구동부는, 구동 바퀴의 구동을 통해 상기 본체를 이동시킬 수 있다. 상기 구 동부는 상기 구동 바퀴의 구동에 의해 상기 본체를 이동시킴으로써, 상기 본체의 주행을 수행하게 될 수 있다. 상기 로봇에서 상기 촬영부는, 구비된 위치에서 상기 본체의 주변을 촬영하여, 촬영 결과에 따른 영상 정보를 생성할 수 있다. 상기 촬영부는, 상기 본체의 후측 상부에 구비될 수 있다. 이처럼 상기 촬영부가 상기 본체의 후측 상부에 구비됨으로써, 상기 본체의 주행 및 절삭 동작으로 인해 발생되 는 이물질이 상기 촬영부를 오염시키는 것을 방지하게 될 수 있다. 상기 촬영부는, 상기 본체의 주 행 방향을 촬영할 수 있다. 즉, 상기 촬영부는, 상기 본체가 주행하게 되는 상기 본체의 전방을 촬 영하게 될 수 있다. 이에 따라, 상기 본체가 주행하게 되는 전방의 상태를 촬영하게 될 수 있다. 상기 촬영 부는, 상기 본체가 상기 주행 영역을 주행하는 중, 상기 본체의 주변을 실시간으로 촬영하여 상기 영상 정보를 생성할 수 있다. 또한, 상기 촬영부는, 촬영 결과를 상기 제어부에 실시간으로 전달 할 수 있다. 이에 따라, 상기 제어부가 상기 주행 영역의 실시간 상태를 판단하게 될 수 있다. 상기 로봇에서 상기 통신부는, 상기 로봇의 통신 대상 수단과 통신할 수 있다. 상기 통신부 는, 상기 로봇과 통신하는 하나 이상의 통신 대상 수단과의 통신을 수행할 수 있다. 여기서, 상기 통신 대 상 수단은, 적어도 상기 감시 수단을 포함할 수 있다. 상기 감시 수단(C)은, 설치된 위치에서 일정 영역을 촬영 하여 감시하는 감시 카메라일 수 있다. 이를테면, CCTV(Closed Circuit Television), 또는 블랙박스 등일 수 있다. 상기 감시 수단(C)은, 도 5에 도시된 바와 같이, 상기 주행 영역 상에 하나 이상(C1 내지 C3)이 설 치될 수 있다. 상기 감시 수단은, 상기 주행 영역 상에 복수로 설치되되, 복수의 감시 수단 각각이 서로 다른 위치에 설치되어, 각각의 위치에서 해당 영역을 촬영하여 감시할 수 있다. 상기 감시 수단은, 설치된 위치 에서 해당 영역을 촬영한 영상 결과를 촬영 정보로 저장할 수 있다. 상기 감시 수단은, 상기 감시 수단을 제어 하는 외부의 제어 수단과 통신하여, 상기 촬영 정보를 상기 제어 수단에 전송할 수 있다. 여기서, 상기 제어 수 단은, 상기 로봇과 통신하는 상기 통신 대상 수단 중 하나일 수 있다. 상기 제어 수단은 또한, 상기 로봇 일 수도 있다. 즉, 상기 감시 수단은, 상기 로봇과 통신할 수 있다. 상기 감시 수단(C)은, 해당 영역 을 실시간을 감시하여, 감시한 결과를 상기 통신부에 전송할 수 있다. 상기 통신부는, 도 6에 도시된 바와 같이, 하나 이상의 감시 수단(C1 내지 C3)과 통신하여, 상기 감시 수단(C1 내지 C3) 각각으로부터 촬영 정보를 전송받을 수 있다. 상기 통신부는 또한, 상기 감시 수단(C1 내지 C3)에 상기 로봇에 관한 정보, 이를테면 상기 감시 모드에 따른 감시 정보를 전송할 수도 있다. 즉, 상기 통신부는, 상기 감시 수단(C1 내 지 C3) 각각과 데이터를 송수신할 수 있다. 상기 로봇에서 상기 제어부는, 상기 주행 영역을 주행하도록 상기 구동부를 제어하여 상기 본체의 주행을 제어하고, 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단하여 상기 주행 영 역을 감시할 수 있다. 상기 제어부는, 상기 통신부 또는 상기 입력부를 통해 상기 주행 영역 을 감시하여 주행하는 상기 감시 모드의 수행에 대한 명령이 입력된 경우, 상기 로봇의 동작 모드를 상기 감시 모드로 설정하여, 상기 감시 모드에 따라 상기 본체의 주행 및 상기 촬영부의 촬영 중 하나 이상을 제어할 수 있다. 상기 제어부는, 상기 감시 모드가 설정된 경우, 상기 감시 수단(C)으로부터 전송받은 상기 촬영 정보를 근 거로 상기 주행 영역 상에서 감시 대상 영역(SZ)을 설정하여, 상기 감시 대상 영역(SZ)을 감시하도록 상 기 본체의 주행 및 상기 촬영부의 촬영 중 하나 이상을 제어할 수 있다. 상기 감시 모드는, 상기 로봇의 동작 모드 중 하나로, 상기 제어부가 상기 로봇의 동작을 제어하 는 모드일 수 있다. 상기 감시 모드는, 상기 주행 영역을 주행하는 중 상기 감시 대상 영역(SZ)의 주변을 주행 및 촬영하여 집중 감시하는 모드일 수 있다. 상기 제어부는, 상기 감시 모드에 따라 상기 로봇의 동작을 제어하는 경우, 상기 감시 대상 영역(SZ)을 집중 감시하도록 상기 본체의 주행 및 상기 촬영부 의 촬영 중 하나 이상을 제어할 수 있다. 즉, 상기 감시 모드는, 상기 주행 영역 중 상기 감시 대상 영역 (SZ)을 집중 감시하며 주행하는 모드일 수 있다. 여기서, 상기 집중 감시는, 상기 감시 대상 영역(SZ)을 특정 기준에 따라 감시하는 것을 의미할 수 있다. 이를 테면, 상기 주행 영역 중 상기 감시 대상 영역(SZ)에 대한 감시 시간, 감시 방법, 감시 범위 중 하나 이 상에 가중치를 부여하여 감시하게 되는 것을 의미할 수 있다. 상기 집중 감시는 또한, 상기 주행 영역 중 상기 감시 대상 영역(SZ)만을 감시하는 것을 의미할 수도 있다. 상기 감시 모드는, 주행 시간대에 따라 상기 감시 대상 영역(SZ)의 주행 방법을 달리할 수 있다. 즉, 상기 감시 모드는, 상기 주행 시간대에 따라 다르게 수행될 수 있다. 이를테면, 제1 시간대에 수행되는 경우 제1 모드로 수행되고, 제2 시간대에 수행되는 경우 제2 모드로 수행될 수 있다. 여기서, 상기 주행 시간대 및 주행 모드는, 상기 로봇이 사용되는 환경에 따라 기설정될 수 있다. 구체적인 예를 들면, 상기 제1 시간대는 일출시간부 터 일몰시간까지, 상기 제2 시간대는 일몰시간부터 일몰시간까지로 설정되고, 상기 제1 모드는, 상기 로븟(10 0)의 시각 표시가 제한되고, 상기 제2 모드는, 상기 로봇의 시각 표시가 활성화되도록 설정될 수 있다. 상 기 감시 모드는, 기설정된 기준 시간대에 주행하는 경우, 상기 로봇의 외부에 상기 감시 모드에 따른 주행 중임을 나타내는 시각 표시를 표시하며 상기 감시 대상 영역(SZ)을 주행하도록 설정될 수 있다. 여기서, 상기 기준 시간대는, 야간 시간대에 해당할 수 있다. 이에 따라, 상기 기준 시간대에 주행하는 경우, 상기 로봇(10 0)의 주행이 인지될 수 있도록 상기 시각 표시를 표시하며 상기 감시 대상 영역(SZ)을 주행하도록 설정될 수 있 다. 상기 제어부는, 상기 기준 시간대에 상기 감시 모드로 상기 감시 대상 영역(SZ)을 주행하는 경우, 상기 본체의 주행 및 상기 촬영부의 촬영 외의 동작을 제한하며 상기 감시 대상 영역(SZ)을 주행 및 촬영하 도록 제어할 수 있다. 즉, 상기 제어부는, 상기 로봇이 상기 기준 시간대에 상기 감시 모드에 따라 동 작하는 경우, 상기 본체의 주행 및 상기 촬영부의 촬영 외의 동작을 제한하며 주행하도록 상기 로봇 을 제어하게 될 수 있다. 이를테면, 야간 시간대에는 상기 제초부의 제초 동작을 제한하고, 상기 본체 의 주행 및 상기 촬영부의 촬영 동작만 수행되도록 제어하게 될 수 있다. 상기 제어부는, 상기 촬영 정보를 근거로 상기 감시 수단(C)의 촬영 영역(Z)을 판단하여, 상기 촬영 영역 (Z)을 근거로 상기 감시 대상 영역(SZ)을 설정할 수 있다. 상기 촬영 영역(Z)은, 도 7에 도시된 바와 같이, 상 기 주행 영역 중 상기 감시 수단(C)이 촬영하여 감시하는 영역을 의미할 수 있다. 상기 제어부는, 상 기 감시 수단(C) 각각의 촬영 정보를 근거로 상기 감시 수단(C) 각각의 촬영 영역(Z)을 판단하여, 판단한 각각 의 촬영 영역(Z)을 근거로 상기 감시 대상 영역(SZ)을 설정할 수 있다. 이를테면, 제1 감시 수단(C1), 제2 감시 수단(C2) 및 제3 감시 수단(C3) 각각으로부터 전송받은 촬영 정보를 근거로 상기 제1 감시 수단(C1)의 제1 촬영 영역(Z1), 상기 제2 감시 수단(C2)의 제2 촬영 영역(Z2) 및 상기 제3 감시 수단(C3)의 제3 촬영 영역(Z3) 각각 을 판단하여, 판단한 상기 제1 촬영 영역(Z1), 상기 제2 촬영 영역(Z2) 및 상기 제3 촬영 영역(Z3)을 근거로 상 기 감시 대상 영역(SZ)을 설정하게 될 수 있다. 상기 제어부는, 상기 주행 영역 중 상기 촬영 영역 (Z)을 제외한 영역을 상기 감시 대상 영역(SZ)으로 설정할 수 있다. 즉, 상기 감시 대상 영역(SZ)은, 상기 감시수단(C)이 촬영하는 영역 외의 영역일 수 있다. 이를테면, 도 7에 도시된 바와 같이 상기 제1 내지 제3 촬영 영 역(Z1, Z2 및 Z3)에 해당되지 않는 상기 감시 수단(C)의 위치(C1, C2 및 C3)일 수 있다. 이에 따라 상기 제어부 는, 상기 감시 모드로 제어할 시, 상기 촬영 영역(Z)을 근거로 상기 주행 영역 중 상기 촬영 영역 (Z)에 해당되지 않는 사각 영역을 판단하여, 판단한 사각 영역을 상기 감시 대상 영역(SZ)으로 설정하게 되고, 상기 감시 수단(C)의 사각 영역에 해당하는 상기 감시 대상 영역(SZ)을 감시하도록 제어하게 될 수 있다. 상기 제어부는, 상기 주행 영역 중 상기 감시 대상 영역(SZ)을 기설정된 감시 기준에 따라 주행 및 촬영하도록 상기 본체의 주행 및 상기 촬영부의 촬영을 제어할 수 있다. 즉, 상기 로봇은, 상기 감시 모드로 동작할 시, 상기 감시 기준에 따라 상기 감시 대상 영역(SZ)의 주변을 주행 및 촬영하며 상기 감시 대상 영역(SZ)을 집중 감시하게 될 수 있다. 상기 감시 기준은, 상기 감시 대상 영역(SZ)을 집중 감시하는 기준 일 수 있다. 상기 감시 기준은, 상기 감시 대상 영역(SZ)을 집중 감시하도록 상기 감시 대상 영역(SZ)의 주변을 주행 및 촬영하는 기준일 수 있다. 상기 감시 기준은, 상기 감시 대상 영역(SZ)의 주변을 기설정된 주행 패턴으로 주행하도록 설정될 수 있다. 상 기 주행 패턴은, 상기 감시 대상 영역(SZ)의 주변을 주행하는 패턴일 수 있다. 이를테면, 상기 감시 대상 영역 (SZ)의 주변을 회전하거나, 상기 감시 대상 영역(SZ)의 주변을 반복하여 주행하는 패턴일 수 있다. 이에 따라, 상기 제어부는, 상기 본체가 상기 감시 대상 영역(SZ)의 주변에서 상기 주행 패턴에 따라 주행하도록 제어하게 될 수 있다. 상기 감시 기준은 또한, 상기 감시 대상 영역(SZ)의 주변을 기설정된 촬영 패턴으로 촬영하도록 설정될 수 있다. 상기 촬영 패턴은, 상기 감시 대상 영역(SZ)의 주변을 촬영하는 패턴일 수 있다. 이를테면, 상기 감시 대 상 영역(SZ)의 주위를 촬영하거나, 상기 감시 대상 영역(SZ)의 주변을 반복 촬영하는 패턴일 수 있다. 이에 따 라, 상기 제어부는, 상기 본체가 상기 감시 대상 영역(SZ)의 주변을 상기 촬영 패턴에 따라 촬영하도록 제어하게 될 수 있다. 이와 같이 상기 감시 모드가 설정된 경우, 상기 감시 대상 영역(SZ)을 감시하도록 상기 본체의 주행 및 상 기 촬영부의 촬영 중 하나 이상을 제어하여 상기 주행 영역을 감시하는 상기 제어부는, 도 8에 도시된 바와 같이 상기 촬영 영역(Z)에 해당되지 않는 영역을 상기 감시 대상 영역(SZ)으로 설정하여, 상기 주 행 영역 중 상기 감시 수단(C)이 감시하지 못하는 영역을 감시하게 될 수 있다. 이와 같은 상기 감시 모드는, 상기 제어부에 의해 상기 주행 영역 상의 구조물의 사용 패턴 및 상기 주행 영역 상에 거주하는 사용자 정보 중 하나 이상이 반영되어 설정이 변경될 수 있다. 이를테면, 상기 제어부가 상기 촬영 정보를 근거로 상기 사용 패턴을 분석한 결과 및 상기 사용자 정보를 분석한 결과 중 하나 이상에 따라 상기 감시 대상 영역(SZ)의 설정을 변경하거나, 상기 감시 기준의 설정을 변경하게 될 수 있 다. 예를 들면, 상기 로봇의 사용자에 의해 사용이 빈번하게 이루어지는 구조물의 경우, 상기 감시 대상 영역(SZ)의 설정에서 제외시키거나, 상기 감시 기준에 따른 감시 대상에서 제외시키게 될 수 있다. 이처럼 상기 제어부는, 상기 사용 패턴 및 상기 사용자 정보 중 하나 이상을 근거로 상기 로봇의 사용 환경에 대한 정보를 학습하여, 학습 결과에 따라 상기 감시 모드의 설정을 변경하거나, 상기 감시 모드의 수행을 변경하게 될 수 있다. 즉, 상기 로봇은, 상기 제어부를 통한 인공지능 제어가 이루어지게 될 수 있다. 이처럼 상기 감시 모드가 설정된 경우, 상기 감시 대상 영역(SZ)을 감시하도록 제어하여 상기 주행 영역 을 감시하는 상기 제어부는, 상기 촬영 정보 및 상기 감시 모드의 수행 결과를 근거로 상기 주행 영역 의 감시 정보를 생성하여, 상기 감시 정보를 상기 통신부와 통신하는 통신 대상 수단 및 상기 감시 수단(C)에 전송할 수 있다. 여기서, 상기 통신 대상 수단은, 사용자의 단말 등일 수 있다. 즉, 상기 제어 부는, 상기 감시 수단(C)이 감시하지 못하는 상기 감시 대상 영역(SZ)을 감시한 결과 및 상기 촬영 정보를 근거로 상기 주행 영역에 대한 감시 정보를 생성하여, 상기 통신부를 통해 상기 로봇의 사용자 에게 상기 감시 모드의 감시 결과에 대한 정보를 제공하게 될 수 있다. 또한, 상기 감시 정보를 상기 감시 수단 (C)에 제공하여, 상기 감시 수단(C)이 상기 감시 정보를 근거로 상기 주행 영역을 감시하도록 하게 될 수 있다. 상기 제어부는, 도 9에 도시된 바와 같이, 상기 감시 수단(C)이 상기 촬영 영역(Z)을 촬영한 촬영 정보 및 상기 감시 대상 영역(SZ)을 감시한 상기 수행 결과를 근거로 상기 주행 영역에 대한 상기 감시 정보를 생 성할 수 있다. 즉, 상기 제어부는, 상기 촬영 영역(Z)을 촬영한 상기 촬영 정보 및 상기 촬영 영역(Z) 외에 해당되는 상기 감시 대상 영역(SZ)을 촬영한 상기 수행 결과를 근거로 상기 주행 영역 전체에 대한 감시 정보를 생성하게 될 수 있다.상기 제어부는 또한, 상기 감시 대상 영역(SZ)에서 위치가 변화되는 대상물을 인식한 경우, 인식 결과에 대 한 알림 정보를 생성하여, 상기 알림 정보를 상기 단말에 전송할 수 있다. 즉, 상기 제어부는, 상기 감시 모드에 따라 상기 주행 영역을 감시한 경우, 상기 통신부를 통해 상기 로봇의 사용자에게 인식 결과에 대한 정보를 제공하게 될 수 있다. 이를테면, 상기 감시 대상 영역(SZ)에 외부인이 침입한 경우, 상기 감시 대상 영역(SZ)의 주변에서 외부인의 위치 변화를 인식하여 상기 통신부를 통해 상기 로봇의 사용자에게 인식 결과에 대한 정보를 제공하게 될 수 있다. 상기 로봇은 또한, 외부로 음성을 출력하는 상기 출력부를 더 포함하되, 상기 제어부는, 상기 감 시 대상 영역(SZ)에서 위치가 변화되는 대상물을 인식한 경우, 인식 결과에 대한 알람 신호를 생성하여, 상기 출력부를 통해 상기 알람 신호에 따른 음성을 출력할 수 있다. 이를테면, 외부인의 침입을 알리는 경보음을 출력하게 될 수 있다. 즉, 상기 제어부는, 상기 감시 대상 영역(SZ)의 주변에서 침입의 가능성이 있는 위치 가 변화되는 대상물을 인식한 경우, 상기 출력부를 통해 외부인의 침입을 알리는 경보음을 발생하게 될 수 있다. 상기 로봇은 또한, 상기 주행 영역을 감시한 이력 정보가 저장되는 상기 저장부를 더 포함하고, 상기 제어부는, 상기 주행 영역을 감시한 결과에 대한 감시 정보를 생성하여 상기 저장부에 저장 할 수 있다. 상기 제어부는, 상기 감시 정보를 상기 저장부에 기저장된 상기 이력 정보에 저장하여, 상 기 이력 정보를 업데이트할 수 있다. 즉, 상기 제어부는, 상기 감시 정보를 상기 이력 정보에 저장함으로써, 상기 주행 영역에 대한 감시 데이터를 축적하게 될 수 있다. 이처럼 상기 감시 정보를 생 성하여 상기 저장부에 저장하는 상기 제어부는, 상기 감시 정보를 상기 이력 정보와 비교하여, 비교 결 과에 따라 상기 주행 영역의 상태 변화를 감지할 수 있다. 이 경우, 상기 제어부는, 상기 상태 변화 를 감지한 결과를 상기 이력 정보에 더 저장할 수 있으며, 상기 상태 변화를 감지한 결과를 상기 통신부를 통해 상기 로봇의 사용자에게 제공하게 될 수도 있다. 상술한 바와 같은 상기 로봇은, 하술할 상기 이동 로봇의 제어 방법(이하 ,제어 방법이라 칭한다)이 적용 되어 실시될 수 있다. 상기 제어 방법은, 도 1a 내지 도 1c에 도시된 바와 같은 이동 로봇을 제어하기 위한 방법으로, 앞서 설명 한 상기 로봇에 적용될 수 있으며, 또한 앞서 설명한 상기 로봇 이외에도 적용될 수 있다. 상기 제어 방법은, 상기 본체, 상기 본체를 이동시키는 상기 구동부, 상기 본체의 주변을 촬영 하여 상기 본체의 주행 영역에 대한 영상 정보를 생성하는 상기 촬영부, 상기 주행 영역에 설치된 감시 수단과 통신하여 상기 감시 수단(C)의 촬영 정보를 전송받는 상기 통신부 및 상기 구동부 를 제어하여 상기 본체의 주행을 제어하고, 상기 영상 정보를 근거로 상기 주행 영역의 상태를 판단 하는 상기 제어부를 포함하는 상기 로봇의 제어 방법으로, 상기 주행 영역을 감시하여 주행하는 감시 모드의 수행 방법일 수 있다. 상기 제어 방법은, 상기 제어부가 상기 감시 모드에 따라 상기 로봇의 동작을 제어하여 상기 감시 모 드를 수행하는 방법일 수 있다. 상기 제어 방법은, 상기 제어부에서 수행되는 제어 방법일 수 있다. 상기 제어 방법은, 도 10에 도시된 바와 같이, 상기 감시 수단(C)으로부터 상기 촬영 정보를 전송받는 단계 (S10), 상기 촬영 정보를 근거로 감시 대상 영역(SZ)을 설정하는 단계(S20), 상기 감시 대상 영역(SZ)의 주변을 주행 및 촬영하여 감시하는 단계(S30) 및 상기 촬영 정보 및 감시 결과에 따라 상기 주행 영역의 감시 정 보를 생성하는 단계(S40)를 포함한다. 즉, 상기 로봇은, 상기 전송받는 단계(S10), 상기 설정하는 단계(S20), 상기 감시하는 단계(S30) 및 상기 생성하는 단계(S40) 순으로 상기 감시 모드를 수행하게 될 수 있다. 상기 전송받는 단계(S10)는, 상기 감시 모드가 상기 로봇에 설정되어, 상기 통신부가 상기 감시 수단 (C)으로부터 상기 촬영 정보를 전송받는 단계일 수 있다. 상기 전송받는 단계(S10)는, 상기 감시 수단(C) 각각으로부터 상기 촬영 정보를 전송받을 수 있다. 상기 설정하는 단계(S20)는, 상기 전송받는 단계(S10)에서 상기 감시 수단(C)으로부터 전송받은 상기 촬영 정보 를 근거로 상기 제어부가 상기 주행 영역 상에서 상기 감시 대상 영역(SZ)을 설정하는 단계일 수 있 다. 상기 설정하는 단계(S20)는, 상기 촬영 정보를 근거로 상기 감시 수단(C)의 촬영 영역(Z)을 판단하여, 상기 촬 영 영역(Z)을 근거로 상기 감시 대상 영역(SZ)을 설정할 수 있다. 상기 설정하는 단계(S20)는, 상기 감시 수단(C) 각각의 촬영 정보를 근거로 상기 감시 수단(C) 각각의 촬영 영 역(Z)을 판단하여, 판단한 각각의 촬영 영역(Z)을 근거로 상기 감시 대상 영역(SZ)을 설정할 수 있다. 상기 설정하는 단계(S20)는, 상기 주행 영역 중 상기 촬영 영역(Z)을 제외한 영역을 상기 감시 대상 영역 (SZ)으로 설정할 수 있다. 상기 감시하는 단계(S30)는, 상기 설정하는 단계(S20)에서 설정한 상기 감시 대상 영역(SZ)을 집중 감시하도록 상기 제어부가 상기 본체의 주행 및 상기 촬영부의 촬영을 제어하는 단계일 수 있다. 상기 감시하는 단계(S30)는, 상기 주행 영역 중 상기 감시 대상 영역(SZ)을 기설정된 감시 기준에 따라 주행 및 촬영하도록 상기 본체의 주행 및 상기 촬영부의 촬영을 제어할 수 있다. 상기 감시하는 단계(S30)는, 상기 감시 대상 영역(SZ)의 주변을 기설정된 주행 패턴으로 주행하도록 제어하여 상기 감시 대상 영역(SZ)을 집중 감시할 수 있다. 상기 감시하는 단계(S30)는, 상기 감시 대상 영역(SZ)의 주변을 기설정된 촬영 패턴으로 촬영하도록 제어하여 상기 감시 대상 영역(SZ)을 집중 감시할 수 있다. 상기 생성하는 단계(S40)는, 상기 감시하는 단계(S30)에서 감시한 결과를 근거로 상기 제어부가 상기 감시 정보를 생성하는 단계일 수 있다. 상기 생성하는 단계(S40)는, 상기 촬영 정보 및 상기 감시 모드의 수행 결과를 근거로 상기 주행 영역의 감시 정보를 생성하여, 상기 감시 정보를 상기 통신부와 통신하는 통신 대상 수단 및 상기 감시 수단(C)에 전송할 수 있다. 상기 전송받는 단계(S10), 상기 설정하는 단계(S20), 상기 감시하는 단계(S30) 및 상기 생성하는 단계(S40)를 포함하는 상기 제어 방법은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하 다. 컴퓨터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기 록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 또한, 상기 컴퓨터는 상기 제어부를 포함할 수도 있다. 상술한 바와 같은 본 발명에 따른 이동 로봇 및 이의 제어 방법은, 이동 로봇의 제어수단, 이동 로봇 시스템, 이동 로봇의 제어시스템, 이동 로봇을 제어하는 방법, 이동 로봇의 영역 감시 방법 및 이동 로봇의 영역 감시 제어 방법 등에 적용되어 실시될 수 있다. 특히, 이동 로봇을 제어하는 인공지능, 인공지능을 적용/활용한 이동 로봇의 제어 수단, 제어 방법, 또는 인공지능을 적용/활용한 이동 로봇 등에 유용하게 적용되어 실시될 수 있다. 그러나 본 명세서에 개시된 기술은 이에 한정되지 않고, 상기 기술의 기술적 사상이 적용될 수 있는 모든 이동 로봇, 이동 로봇을 제어하는 제어 수단, 이동 로봇 시스템, 이동 로봇을 제어하기 위한 방법 등에도 적용 되어 실시될 수 있다. 지금까지 본 발명에 따른 구체적인 실시 예에 관하여 설명하였으나, 본 발명의 범위에서 벗어나지 않는 한도 내 에서는 여러 가지 변형이 가능함은 물론이다. 그러므로, 본 발명의 범위는 설명된 실시 예에 국한되어 정해져서 는 안 되며, 후술하는 특허청구의 범위뿐 아니라 이 특허 청구의 범위와 균등한 것들에 의해 정해져야 한다. 이상과 같이 본 발명은 비록 한정된 실시 예와 도면에 의해 설명되었으나, 본 발명은 상기의 실시 예에 한정되 는 것은 아니며, 이는 본 발명이 속하는 분야에서 통상의 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형이 가능하다. 따라서, 본 발명 사상은 아래에 기재된 특허청구범위에 의해서만 파악되어야 하고, 이의 균등 또는 등가적 변형 모두는 본 발명 사상의 범주에 속한다고 할 것이다. 부호의 설명10: 본체 11: 구동부 12: 촬영부 13: 통신부 20: 제어부 100: 이동 로봇 200: 송출기 300: 단말기 400: GPS 위성 1000: 주행 영역"}
{"patent_id": "10-2019-0010728", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 발명에 따른 이동 로봇의 일 실시 예를 나타낸 구성도 a. 도 1b는 본 발명에 따른 이동 로봇의 일 실시 예를 나타낸 구성도 b. 도 1c는 본 발명에 따른 이동 로봇의 일 실시 예를 나타낸 구성도 c. 도 2는 본 발명에 따른 이동 로봇의 주행 영역의 일 실시 예를 나타낸 개념도. 도 3a는 본 발명에 따른 이동 로봇의 주행 원리를 나타낸 개념도. 도 3b는 본 발명에 따른 이동 로봇의 위치 판단을 위한 장치 간의 신호 흐름을 나타낸 개념도. 도 4는 본 발명에 따른 이동 로봇의 구체적인 구성을 나타낸 구성도. 도 5는 본 발명에 따른 이동 로봇의 실시 예에 따른 주행 영역의 주행 예시를 나타낸 예시도. 도 6은 본 발명에 따른 이동 로봇의 실시 예에 따른 통신부의 통신 관계를 나타낸 개념도. 도 7은 본 발명에 따른 이동 로봇의 실시 예에 따른 촬영 영역의 예시를 나타낸 예시도. 도 8은 본 발명에 따른 이동 로봇의 실시 예에 따른 감시 대상 영역 설정의 개념을 나타낸 개념도. 도 9는 본 발명에 따른 이동 로봇의 실시 예에 따른 감시 정보의 생성 개념을 나타낸 개념도. 도 10은 본 발명에 따른 이동 로봇의 제어 방법의 순서를 나타낸 순서도."}
