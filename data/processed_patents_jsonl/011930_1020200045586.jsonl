{"patent_id": "10-2020-0045586", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0127558", "출원번호": "10-2020-0045586", "발명의 명칭": "멀티 에이전트 기반 유무인 협업 시스템 및 방법", "출원인": "한국전자통신연구원", "발명자": "이창은"}}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이웃하는 자율 주행 로봇과의 메쉬 네트워크를 형성하고, 상황 인식 및 공간맵 정보 생성을 위한 시각 정보를획득하며, 실시간 위치 정보를 생성하기 위해 이웃하는 자율 주행 로봇과의 거리 정보를 획득하는 복수의 자율주행 로봇; 상기 자율 주행 로봇들로부터 수집되는 시각 정보와 위치 정보 및 거리정보로부터 협업 대상의 위치 측위 정보,표적 인식 정보 및 공간맵 정보를 구축하고, 생성된 공간맵 정보와 자율 주행 로봇의 위치 정보를 이용하여 전장 상황인식, 위협 판단 및 지휘 결심 지원 정보를 제공하는 협업 에이전트; 및 상기 협업 에이전트를 통해 구축된 협업 대상의 위치 측위 정보, 표적 인식 정보 및 공간맵 정보를 착용자에게표시하는 복수의 스마트 헬멧을 포함하는 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 자율 주행 로봇은, 영상 정보를 획득하는 카메라; 레이저를 통해 물체 정보를 획득하는 라이다; 열 정보를 통해 물체의 열화상 정보를 획득하는 열화상 센서; 움직임 정보를 획득하는 관성 측정기; 무선 네트워크 통신을 통해 이웃하는 자율 주행 로봇과 동적 Ad-hoc Mesh 네트워크를 구성하고, 상기 획득된 복수의 정보들을 매칭된 상기 스마트 헬멧에 전송하는 무선 통신부; 및 인지 대상물 및 공간을 이루는 벽과의 거리를 측정하는 레이저 거리 측정기를 포함하는 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 상기 자율 주행 로봇은, 매칭된 스마트 헬멧과 UWB 통신을 통해 일정 거리 내에서 구동하는 것인 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 자율 주행 로봇은, 상기 매칭된 스마트 헬멧을 따라 자율 주행하고, HR(Human-Robot-Interface) 상호 작용을 통해 착용자의 지역상황인식, 위협 판단 및 지휘 결심을 지원하기 위한 정보를 제공하는 것인 멀티 에이전트 기반 유무인 협업 시스템. 공개특허 10-2021-0127558-3-청구항 5 제 1항에 있어서, 상기 자율 주행 로봇은, 이웃하는 자율 주행 로봇과 WPAN(Wired Personal Area Network) 기반 Ad-hoc Mesh 네트워크 자율 구성 관리를수행하는 것인 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서, 상기 자율 주행 로봇은, 이웃하는 자율 주행 로봇들간의 전파 신호 세기(RSSI) 및 링크 정보(Link Quality Information)와 같은 물리적신호를 분석하는 실시간 전파 채널 분석부; 이웃하는 자율 주행 로봇들간의 Mesh 네트워크 링크상의 트래픽을 실시간으로 분석하는 네트워크 리소스관리부; 및 상기 실시간 전파 채널 분석부와 상기 네트워크 리소스 관리부를 통해 분석한 정보를 이용하여 전파 단절 없는통신 링크를 유지시키는 네트워크 토폴로지 라우팅부를 포함하는 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서, 상기 협업 에이전트는, 상기 자율 주행 로봇을 통해 획득한 다양한 객체 및 자세 정보를 처리하여 지형/지물/표적을 인식 및 분류하고,임무 목적별 인식맵을 제작을 위한 LRF 기반 Point Cloud를 생성하는 시각 및 센싱 지능 처리부; 상기 자율 주행 로봇의 카메라를 활용한 V-SLAM(Visual-SLAM) 기능, LRF 기반 Point Cloud 기능을 융합하여 실시간으로 임무 환경의 공간 맵을 생성하는 기능과 UWB 통신을 이용하여 불규칙한 동선을 갖는 전투원들의 위치측위를 위해 상기 자율 주행 로봇들간의 순차적 연속 협업 측위 기능을 제공하는 위치 및 공간 지능 처리부; 및 상기 자율 주행 로봇의 표적 및 환경을 탐사하고, Seamless Connection을 위한 Dynamic Ad-hoc Mesh 네트워크구성하고, 전투원들의 실시간 위치 측위를 위한 상기 자율 주행 로봇들간의 협업 측위에 따라 경로 계획을 자율설정하며, 로봇 주행 시 멀티모달 기반 장애물(Obstacle)을 회피하기 위한 정보를 제공하는 운동 및 주행 지능처리부를 포함하는 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 협업 에이전트는, 지능 처리에 따른 협업 계획을 생성하고, 이웃하는 협업 에이전트들에게 협업 가능 지식/기기 검색 및 가용성여부 검토를 요청 후 응답된 결과를 기반으로 최적 협업 조합을 생성하여 협업 요청을 하며, 협업 요청을 받으면 상호간 분산 지식 협업을 수행하는 것인 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2021-0127558-4-제 7항에 있어서, 상기 협업 에이전트는, Complicated situation recognition, C-SLAM 및 self-negotiator을 이용하는 것인 멀티 에이전트 기반 유무인협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7항에 있어서, 상기 관리 에이전트는, 상기 자율 주행 로봇들로부터 다양한 멀티모달 기반 상황 및 환경 데이터를 수집하는 멀티 모달 객체 데이터 분석부; 및 상황 및 환경 데이터에 대응하는 목표 지점(Goal State)에 매핑되는 미션 모델이 있는지 여부를 자원관리 및 상황추론부를 통해 지식 맵으로부터 검색한 후 미션내 다중 태스크들이 무결하고 안전한지를 검사하며 개별 태스크들에 대한 행동 계획을 플래닝 하기 위해 멀티 태스크 Sequence를 최적 행동 계획부에 전달하면, 태스크를 분석하고 해당 태스크를 수행할 최적의 기기 및 지식의 조합을 구성하는 최적 행동 계획부를 포함하는 협업 에이전트간 협업/협상부를 포함하는 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서, 상기 관리 에이전트는, Cost Benefit 모델(비용 이익 모델) 기반으로 기기 및 지식의 조합을 통해 구성하는 것인 멀티 에이전트 기반유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서, 상기 최적 행동 계획부는 생성한 최적 협상 결과를 기반으로, 행동 태스크 Sequence들을 정제/분할/할당을 통해 분산 협업 공간상에 위치하고 있는 협업 에이전트들에게 관련 태스크를 전달하는 것인 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서, 상기 최적 행동 계획부는, 초지능형 네트워크의 지식/기기 검색, 연결 프로토콜을 통해 관련 테스크를 전달하는 것인 멀티 에이전트 기반유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10항에 있어서, 전달되는 멀티 태스크 플래닝 순서(Sequence)를 이용한 전역 상황 인지 모니터링을 통해 목표 지점(Goal State)에 맞는 답이 충족한지 여부를 협업형 판단/추론/모델을 통해 검증하며 불 충족 시, 순환 동작 구조를공개특허 10-2021-0127558-5-갖도록, 상기 협업 에이전트간 협업/협상부에게 미션 재플래닝 요청하는 자율 협업 판단 및 전역 상황 인지부를더 포함하는 것인 멀티 에이전트 기반 유무인 협업 시스템."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "협업 에이전트내 위치/공간 지능을 제공하는 로봇들간의 무선 통신 기반 순차적 연속 협업 측위 방법에 있어서, 위치 측위 정보가 포함된 정보를 송수신하여 복수의 로봇들이 한 개의 클러스터를 형성하면서 순차적으로 이동하는 단계; 클러스터를 형성한 로봇들 중 위치 측위 정보가 없는 영역으로 이동한 임의의 로봇으로부터 위치 측위 정보가없는 정보가 수신되는 지를 판단하는 단계; 상기 판단 단계에서 임의의 로봇으로부터 위치 측위 정보가 없는 정보가 수신되면, 위치 측위가 되지 않는 이동위치에서 나머지 위치 측위 정보를 가지고 있는 상기 자율 주행 로봇들과 TWR(Two-Way-Ranging) 방식을 통해 거리를 측정하는 단계; 및 측정된 거리를 기반으로 위치를 측정하는 단계를 포함하는 멀티 에이전트 기반 유무인 협업 방법."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15항에 있어서, 상기 위치를 측정하는 단계는, 위치 정보를 알고 있는 로봇 중 측위 기준이 되는 모바일 앵커의 위치 오차를 산출하는 단계; 및 산출된 앵커의 위치 오차를 이용하여 위치를 새롭게 구하고자 하는 로봇의 위치 오차를 산출하여 누적하는 단계를 포함하는 협업 측위 기반 순차적 위치 계산 메커니즘을 사용하는 것인 멀티 에이전트 기반 유무인 협업방법."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서, 상기 위치를 측정하는 단계는, 워크페이스(Workspace)를 이루는 복수개의 로봇으로 구성된 측위망에 대하여 목적지가 Workspace를 벗어난 경우이면, 한번에 Workspace로부터 벗어나면서 이동하는 것이 아닌 일정 범위 나누어 이동하면서 중간 노드들을 일정 유효 범위까지 넓혀(d가 증가) 가면서 이동하는 것인 멀티 에이전트 기반 유무인 협업 방법."}
{"patent_id": "10-2020-0045586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 15항에 있어서, 상기 위치를 측정하는 단계는, 각 로봇이 모든 앵커 노드들의 위치도 새롭게 계산하여 전체적으로 측위 오차를보정하는 Full-mesh 기반 협업 측위 알고리즘을 이용하는 것인 멀티 에이전트 기반 유무인 협업 방법."}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 멀티 에이전트 기반 유무인 협업 시스템에 관한 것으로, 이웃하는 자율 주행 로봇과의 메쉬 네트워크 를 형성하고, 상황 인식 및 공간맵 정보 생성을 위한 시각 정보를 획득하며, 실시간 위치 정보를 생성하기 위해 이웃하는 자율 주행 로봇과의 거리 정보를 획득하는 복수의 자율 주행 로봇; 상기 자율 주행 로봇들로부터 수집 되는 시각 정보와 위치 정보 및 거리정보로부터 협업 대상의 위치 측위 정보, 표적 인식 정보 및 공간맵 정보를 구축하고, 생성된 공간맵 정보와 자율 주행 로봇의 위치 정보를 이용하여 전장 상황인식, 위협 판단 및 지휘 결 심 지원 정보를 제공하는 협업 에이전트; 및 상기 협업 에이전트를 통해 구축된 협업 대상의 위치 측위 정보, 표 적 인식 정보 및 공간맵 정보를 착용자에게 표시하는 복수의 스마트 헬멧을 포함한다."}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티 에이전트 기반 유무인 협업 시스템 및 방법에 관한 것으로, 더욱 상세하게는 사전정보 없이 처 음 진입하는 건물이나 지하벙커, GNSS-denied 환경, 전투원들의 불규칙적이고 동적인 움직임으로 열악한 품질의 변형된 전장 공간 조건에서 전투병들의 인지증강을 위한 유무인 협업 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래의 기술에 따른 끊임없는 통신 연결성을 제공하는 분리가능한 모듈형 재난구조 뱀 로봇 및 그 구동 방법은 도 1과 같이 비정형 환경(예: 건물 붕괴 현장, 상하수도관, 동굴, 생화학 오염지역)에서 인명탐지 및 환경 탐사 임무를 수행하는 모듈형 재난구조 뱀 로봇에 관한 것이다. 종래 뱀 로봇은 주행능력과 통신 능력을 모두 보유한 단위 뱀 로봇 모듈들을 이용하여 머리부를 구성하는 뱀 로 봇 모듈의 카메라 영상 데이터를 몸통부를 구성하는 뱀 로봇 모듈(2 내지 n)들을 차례로 분리하여 다중 이동 형 중계 모듈로 변환하여 원격 관제 센터로 영상 정보를 끊임없이 전송하기 위한 Seamless 실시간 통신 연결성 을 제공하는 것을 주요 특징으로 한다. 기존 발명은 one to one sequential ad-hoc 네트워크 구성을 통해 머리부의 영상 정보를 인공지능 기반 메타정 보(객체인식, 위협분석 등) 처리 없이 몸통 모듈들을 일렬로 무선 네트워크를 형성하여 원격 관제 센터로 영상 정보를 전달하고, 원격 관제 센터에서는 유인이 수동으로 원격 모니터링 하는 것을 주요 특징으로 하고 있으나, 소방 방재 현장에 투입된 소방대원에게 실시간 HRI 기반 유무인 협업을 통해 재난 상황인식, 판단 및 지휘 결심 지원기능 부재인 점과 뱀 로봇들의 탐사 공간에 대한 공간정보 생성 및 위치 정보를 생성할 수 없는 점, 고용량 영상 정보를 Ad-hoc 네트워크 다중 hop을 통해 원격 관제 센터로 전송하는데 있어서 한계점을 가진다는 점에서 실 운용상에 많은 문제점이 있다. 즉, 종래의 기술은 재난현장에서 무인 시스템들만의 단독 운용으로 인해 소방대원들에게 협업 운용이 불가한 점 과 탐사 공간에 대한 공간정보 생성, 위치 정보를 생성할 수 없는 점으로 인해 실 운용상 많은 한계점을 가지는 문제점이 있다."}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래 문제점을 해결하기 위한 것으로, 협업 에이전트 기반 무인 협업 시스템을 통한 작전지역의 공간 정보 생성 및 위협을 분석하고, 초지능 네트워크를 통한 ad-hoc mesh 네트워킹 구성 및 상대 위치 측위를 제공 하며, Potential Field 기반 무인 협업 시스템과 전투병들이 착용하고 있는 스마트 헬멧의 HRI(Human-Robot- Interface) 기반 유무인 상호작용을 통해 전장 상황에서 전투병의 인지적 부담을 경감하고, 전장 상황인식, 위 협 판단 및 지휘 결심을 지원할 수 있는 협업 에이전트 기반 유무인 협업 시스템 및 방법을 제공하고자 한다. 본 발명의 목적은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로 부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 시스템은 이웃하는 자 율 주행 로봇과의 메쉬 네트워크를 형성하고, 상황 인식 및 공간맵 정보 생성을 위한 시각 정보를 획득하며, 실 시간 위치 정보를 생성하기 위해 이웃하는 자율 주행 로봇과의 거리 정보를 획득하는 복수의 자율 주행 로봇; 상기 자율 주행 로봇들로부터 수집되는 시각 정보와 위치 정보 및 거리정보로부터 협업 대상의 위치 측위 정보, 표적 인식 정보(시각지능) 및 공간맵 정보를 구축하고, 생성된 공간맵 정보와 자율 주행 로봇의 위치 정보를 이 용하여 전장 상황인식, 위협 판단 및 지휘 결심 지원 정보를 제공하는 협업 에이전트; 및 상기 협업 에이전트를 통해 구축된 협업 대상의 위치 측위 정보, 표적 인식 정보 및 공간맵 정보를 착용자에게 표시하는 복수의 스마 트 헬멧을 포함한다. 상기 자율 주행 로봇은, 영상 정보를 획득하는 카메라; 레이저를 통해 물체 정보를 획득하는 라이다; 열 정보를 통해 물체의 열화상 정보를 획득하는 열화상 센서; 움직임 정보를 획득하는 관성 측정기; 무선 네트워크 통신을 통해 이웃하는 자율 주행 로봇과 동적 Ad-hoc Mesh 네트워크를 구성하고, 상기 획득된 복수의 정보들을 매칭된 상기 스마트 헬멧에 전송하는 무선 통신부; 및 인지 대상물 및 공간을 이루는 벽과의 거리를 측정하는 레이저 거리 측정기를 포함한다. 상기 자율 주행 로봇은, 매칭된 스마트 헬멧과 UWB 통신을 통해 일정 거리 내에서 구동하는 것이 바람직하다. 상기 자율 주행 로봇은, 상기 매칭된 스마트 헬멧을 따라 자율 주행하고, HR(Human-Robot-Interface) 상호 작용 을 통해 착용자의 지역 상황인식, 위협 판단 및 지휘 결심을 지원하기 위한 정보를 제공할 수 있다. 상기 자율 주행 로봇은, 이웃하는 자율 주행 로봇과 WPAN(Wired Personal Area Network) 기반 Ad-hoc Mesh 네 트워크 자율 구성 관리를 수행할 수 있다. 상기 자율 주행 로봇은, 이웃하는 자율 주행 로봇들간의 전파 신호 세기(RSSI) 및 링크 정보(Link Quality Information)와 같은 물리적 신호를 분석하는 실시간 전파 채널 분석부; 이웃하는 자율 주행 로봇들간의 Mesh 네트워크 링크상의 트래픽을 실시간으로 분석하는 네트워크 리소스 관리부; 및 상기 실시간 전파 채널 분석부와 상기 네트워크 리소스 관리부를 통해 분석한 정보를 이용하여 전파 단절 없는 통신 링크를 유지시키는 네트워크 토폴로지 라우팅부를 포함한다. 상기 협업 에이전트는, 상기 자율 주행 로봇을 통해 획득한 다양한 객체 및 자세 정보를 처리하여 지형/지물/표 적을 인식 및 분류하고, 임무 목적별 인식맵을 제작을 위한 LRF 기반 Point Cloud를 생성하는 시각 및 센싱 지 능 처리부; 상기 자율 주행 로봇의 카메라를 활용한 V-SLAM(Visual-SLAM) 기능, LRF 기반 Point Cloud 기능을 융합하여 실시간으로 임무 환경의 공간 맵을 생성하는 기능과 UWB 통신을 이용하여 불규칙한 동선을 갖는 전투 원들의 위치 측위를 위해 상기 자율 주행 로봇들간의 순차적 연속 협업 측위 기능을 제공하는 위치 및 공간 지 능 처리부; 및 상기 자율 주행 로봇의 표적 및 환경을 탐사하고, Seamless Connection을 위한 Dynamic Ad-hoc Mesh 네트워크 구성하고, 전투원들의 실시간 위치 측위를 위한 상기 자율 주행 로봇들간의 협업 측위에 따라 경 로 계획을 자율 설정하며, 로봇 주행 시 멀티모달 기반 장애물(Obstacle)을 회피하기 위한 정보를 제공하는 운 동 및 주행 지능 처리부를 포함한다. 상기 협업 에이전트는, 지능 처리에 따른 협업 계획을 생성하고, 이웃하는 협업 에이전트들에게 협업 가능 지식 /기기 검색 및 가용성 여부 검토를 요청 후 응답된 결과를 기반으로 최적 협업 조합을 생성하여 협업 요청을 하 며, 협업 요청을 받으면 상호간 분산 지식 협업을 수행한다. 상기 협업 에이전트는, Complicated situation recognition, C-SLAM 및 self-negotiator을 이용하는 것이 바람 직하다. 상기 관리 에이전트는, 상기 자율 주행 로봇들로부터 다양한 멀티모달 기반 상황 및 환경 데이터를 수집하는 멀 티 모달 객체 데이터 분석부; 및 상황 및 환경 데이터에 대응하는 목표 지점(Goal State)에 매핑되는 미션 모델 이 있는지 여부를 자원관리 및 상황추론부를 통해 지식 맵으로부터 검색한 후 미션내 다중 태스크들이 무결하고 안전한지를 검사하며 개별 태스크들에 대한 행동 계획을 플래닝 하기 위해 멀티 태스크 Sequence를 최적 행동 계획부에 전달하면, 태스크를 분석하고 해당 태스크를 수행할 최적의 기기 및 지식의 조합을 구성하는 최적 행 동 계획부를 포함한다. 상기 관리 에이전트는, Cost Benefit 모델(비용 이익 모델) 기반으로 기기 및 지식의 조합을 통해 구성할 수 있 다. 상기 최적 행동 계획부는 생성한 최적 협상 결과를 기반으로, 행동 태스크 Sequence들을 정제/분할/할당을 통해 분산 협업 공간상에 위치하고 있는 협업 에이전트들에게 관련 태스크를 전달할 수 있다. 상기 최적 행동 계획부는, 초지능형 네트워크의 지식/기기 검색, 연결 프로토콜을 통해 관련 테스크를 전달할 수 있다. 전달되는 멀티 태스크 플래닝 순서(Sequence)를 이용한 전역 상황 인지 모니터링을 통해 목표 지점(Goal Stat e)에 맞는 답이 충족한지 여부를 협업형 판단/추론/모델을 통해 검증하며 불 충족 시, 순환 동작 구조를 갖도록, 상기 협업 에이전트간 협업/협상부에게 미션 재플래닝 요청하는 자율 협업 판단 및 전역 상황 인지부를 더 포함한다. 그리고 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 방법은 협업 에이전트내 위치/공간 지능을 제공하는 로봇들간의 무선 통신 기반 순차적 연속 협업 측위 방법에 있어서, 위치 측위 정보가 포함된 정보를 송수신하여 복수의 로봇들이 한 개의 클러스터를 형성하면서 순차적으로 이동하는 단계; 클러스터를 형성한 로 봇들 중 위치 측위 정보가 없는 영역으로 이동한 임의의 로봇으로부터 위치 측위 정보가 없는 정보가 수신되는 지를 판단하는 단계; 상기 판단 단계에서 임의의 로봇으로부터 위치 측위 정보가 없는 정보가 수신되면, 위치 측위가 되지 않는 이동 위치에서 나머지 위치 측위 정보를 가지고 있는 상기 자율 주행 로봇들과 TWR(Two-Way-Ranging) 방식을 통해 거리를 측정하는 단계; 및 측정된 거리를 기반으로 위치를 측정하는 단계를 포함한다. 상기 위치를 측정하는 단계는, 위치 정보를 알고 있는 로봇 중 측위 기준이 되는 모바일 앵커의 위치 오차를 산 출하는 단계; 및 산출된 앵커의 위치 오차를 이용하여 위치를 새롭게 구하고자 하는 로봇의 위치 오차를 산출하 여 누적하는 단계를 포함하는 협업 측위 기반 순차적 위치 계산 메커니즘을 사용할 수 있다. 그리고, 상기 위치를 측정하는 단계는, 워크페이스(Workspace)를 이루는 복수개의 로봇으로 구성된 측위망에 대 하여 목적지가 Workspace를 벗어난 경우이면, 한번에 Workspace로부터 벗어나면서 이동하는 것이 아닌 일정 범 위 나누어 이동하면서 중간 노드들을 일정 유효 범위까지 넓혀(d가 증가) 가면서 이동할 수 있다. 한편, 상기 위치를 측정하는 단계는, 각 로봇이 모든 앵커 노드들의 위치도 새롭게 계산하여 전체적으로 측위 오차를 보정하는 Full-mesh 기반 협업 측위 알고리즘을 이용할 수 있다."}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 협업 에이전트 기반으로 유무인 협업 방법을 통해 전투병들에게 전장 상황인식, 위협 판단 및 지휘 결심을 지원하고 비인프라 환경에서의 전투원들에게 Ad Hoc 네트워크 기반의 확고한 연결성 과 공간정보를 제공하며, 실시간 위치 정보를 제공하는데 있어서 오차를 최소화할 수 있는 새로운 협업 측위 방 법론을 제공하여 전투원의 생존력 및 전투력 강화시킬 수 있는 효과가 있다."}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 한편, 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다(comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성소자, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성소자, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 도 2는 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 시스템을 설명하기 위한 기능블록도이다. 도 2에 도시된 바와 같이, 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 시스템은 복수의 자율 주행 자율 주행 로봇, 협업 에이전트 및 복수의 스마트 헬멧을 포함한다. 복수의 자율 주행 자율 주행 로봇은 이웃하는 자율 주행 로봇과의 메쉬 네트워크를 형성하고, 상황 인식 및 공간맵 정보 생성을 위한 시각 정보를 획득하며, 실시간 위치 정보를 생성하기 위해 이웃하는 자율 주 행 로봇과의 거리 정보를 획득한다. 협업 에이전트은 상기 자율 주행 로봇들로부터 수집되는 시각 정보와 위치 정보 및 거리정보로부터 협업 대상의 위치 측위 정보, 표적 인식 정보(시각지능) 및 공간맵 정보를 구축하고, 생성된 공간맵 정보와 자 율 주행 로봇의 위치 정보를 이용하여 전장 상황인식, 위협 판단 및 지휘 결심 지원 정보를 제공한다. 이 러한 협업 에이전트는 각 자율 주행 로봇내에 형성되거나 스마트 헬멧에 구비될 수 있다. 복수의 스마트 헬멧은 상기 협업 에이전트를 통해 구축된 협업 대상의 위치 측위 정보, 표적 인식 정보 및 공간맵 정보를 착용자에게 표시한다. 본 발명의 일 실시예에 따르면, 도 3에 도시된 바와 같이, 멀티 에이전트를 기반으로 유무인 협업 방법을 통해 전투병에게 현장 상황인식, 위협 판단 및 지휘 결심을 지원하고, 비인프라 환경에서의 착용자들에게 Ad Hoc 네 트워크 기반의 확고한 연결성과 공간정보를 제공하고, 실시간 위치 정보를 제공하는데 있어서 오차를 최소화할 수 있는 협업 측위 방법론을 제공하고, 착용자의 생존력 및 전투력을 강화시킬 수 있는 효과가 있다. 한편, 본 발명의 일 실시예에 따른 자율 주행 로봇은 볼 타입으로, 통신 가능 영역인 포텐셜 필드 (Potential Field) 내에서 매칭된 스마트 헬멧을 따라 자율 주행하고, HR(Human-Robot-Interface) 상호 작용을 통해 착용자의 지역 상황인식, 위협 판단 및 지휘 결심을 지원하기 위한 정보를 제공한다. 이를 위해, 상기 자율 주행 로봇은 도 4에 도시된 바와 같이, 카메라, 라이다, 열화상 센서 와 같이 대상물의 영상 정보 또는 지역 및 공간을 인식하기 위한 센싱 장치와 로봇의 움직임 정보를 획득하기 위한 관성 측정기, 이웃하는 자율 주행 로봇 및 스마트 헬멧과의 통신을 수행하기 위 한 무선 통신기를 포함하고, 레이저 거리 측정기가 더 포함될 수 있다. 카메라는 영상 정보를 촬영하여 착용자에게 시각적 정보를 제공하고, 라이다는 IMU(Inertial Measurement Unit)을 이용하여 레이저를 통해 물체 정보를 획득하며, 열화상 센서는 열 정보를 통해 물체 의 열화상 정보를 획득한다. 관성 측정기는 자율 주행 로봇의 움직임 정보를 획득한다. 무선 통신기는 이웃하는 자율 주행 로봇과 동적 Ad-hoc Mesh 네트워크를 구성하고, UWB(Ultra Wide Band, 이하, “UWB”라함) 통신을 통해 상기 획득된 복수의 정보들을 매칭된 상기 스마트 헬멧에 전송한다. 무선 통신기는 UWB이 이용되는 것이 바람직하나, WLAN(wireless LAN), Bluetooth, HDR WPAN, UWB, ZigBee, Impulse Radio, 60GHz WPAN, Binary-CDMA, 무선 USB 기술 및 무선 HDMI 기술 등이 이용될 수도 있다. 레이저 거리 측정기는 인지 대상물 및 공간을 이루는 벽과의 거리를 측정한다. 이러한 상기 자율 주행 로봇은 매칭된 스마트 헬멧과 UWB 통신을 통해 일정 거리 내에서 구동하는 것 이 바람직하다. 또한, 상기 자율 주행 로봇은, 이웃하는 자율 주행 로봇과 WPAN(Wired Personal Area Network) 기반 Ad-hoc Mesh 네트워크 자율 구성 관리를 수행하는 것이 바람직하다. 이러한 본 발명의 일 실시예에 따르면, 비정형/비인프라 전장환경에서 전투병의 생존성, 전투력, 연결성을 강화 할 수 있도록 개벌 전투원 간에 실시간 공간 정보를 공유하고 연결성을 보장할 수 있는 효과가 있다.그리고 상기 자율 주행 로봇은 도 5에 도시된 바와 같이, 실시간 전파 채널 분석부, 네트워크 리소스 관리부 및 네트워크 토폴로지 라이팅부를 포함한다. 실시간 전파 채널 분석부는 이웃하는 자율 주행 로봇들간의 전파 신호 세기(RSSI) 및 링크 정보(Link Quality Information)와 같은 물리적 신호를 분석한다. 네트워크 리소스 관리부는 이웃하는 자율 주행 로봇들간의 Mesh 네트워크 링크상의 트래픽을 실시간 으로 분석한다. 네트워크 토폴로지 라우팅부는 상기 실시간 전파 채널 분석부와 상기 네트워크 리소스 관리부를 통해 분석 한 정보를 이용하여 전파 단절 없는 통신 링크를 유지시킨다. 본 발명에 따르면, 상기와 같은 자율 주행 로봇을 통해, 이웃 로봇들간 전파 차단 없이 최적의 통신 링크를 유 지할 수 있도록 지원할 수 있고, 특정 링크에 과부하 되지 않도록 실시간 모니터링을 수행할 수 있는 효과가 있 다. 한편 상기 협업 에이전트는 도 6에 도시된 바와 같이, 시각 및 센싱 지능 처리부, 위치 및 공간 지능 처리부 및 운동 및 주행 지능 처리부를 포함한다. 도 7은 본 발명의 일 실시예에 따른 협업 에이전트를 설명하기 위한 구성블록도이다. 시각 및 센싱 지능 처리부는 상기 자율 주행 로봇을 통해 획득한 다양한 객체 및 자세 정보를 처리하 여 지형/지물/표적을 인식 및 분류하고, 임무 목적별 인식맵을 제작을 위한 LRF 기반 Point Cloud를 생성한다. 그리고 위치 및 공간 지능 처리부는 상기 자율 주행 로봇의 카메라인 RGB-D 센서를 활용한 V- SLAM(Visual-SLAM) 기능, LRF 기반 Point Cloud 기능을 융합하여 실시간으로 임무 환경의 공간 맵을 생성하는 기능과, UWB 통신 기술을 이용하여 불규칙한 동선을 갖는 전투원들의 위치 측위를 위한 볼타입 자율 주행 로봇 들간의 순차적 연속 협업 측위 기능을 제공한다. 또한, 운동 및 주행 지능 처리부는 상기 자율 주행 로봇의 표적 및 환경 탐사 임무, Seamless Connection을 위한 Dynamic Ad-hoc Mesh 네트워크 구성 임무, 전투원들의 실시간 위치 측위를 위한 볼타입 자율 주행 로봇들간의 협업 측위 임무에 따라 경로 계획을 자율 설정하며 자율 주행 로봇 주행 시 멀티모 달 기반 장애물(Obstacle)을 회피하는 기능을 제공한다. 그리고, 상기 협업 에이전트는 임무에 따른 협업 계획을 생성하고 이웃하는 협업 에이전트들에게 협업 가 능 지식/기기 검색 및 가용성 여부 검토를 요청 후 응답된 결과를 기반으로 최적 협업 조합을 생성하여 협업 요 청을 하며, 협업 요청을 받으면 상호간 분산 지식 협업을 통해 임무를 수행한다. 이러한 상기 협업 에이전트는 Complicated situation recognition, C-SLAM 및 self-negotiator와 같은 판단 지능 처리부를 통해 체계, 전장, 자원 및 전술에 대한 정보를 제공할 수 있다. 한편, 상기 협업 에이전트는 지휘관의 지휘 결심을 지원하기 위해, 수집된 정보를 융합하여 인공지능 딥러 닝 기반 전역 상황 인지 및 C-SLAM 기술을 통한 단위 공간맵들을 병합한 지휘결심 정보를 지휘관이 착용한 스마 트 헬멧과 연동된 자율 주행 로봇을 통해 지휘관에게 제공한다. 이를 위해, 협업 에이전트는 도 8에 도시된 바와 같이, 전체 시스템의 Supervisor 역할을 수행할 수 있도 록, 멀티 모달 객체 데이터 분석부, 협업 에이전트간 협업/협상부 및 자율 협업 판단 및 전역 상황 인지부를 포함한다. 도 9는 본 발명의 일 실시예에서 협업 에이전트의 관리 에이전트 기능을 설명하기 위한 참고도이다. 멀티 모달 객체 데이터 분석부는 상기 자율 주행 로봇들로부터 다양한 멀티모달 기반 상황 및 환경 데이터를 수집한다. 그리고, 협업 에이전트간 협업/협상부는 상황 및 환경 데이터에 대응하는 Goal State에 매핑되는 미션 모 델이 있는지 여부를 자원관리 및 상황추론부를 통해 지식 맵을 통해 검색한 후 미션내 다중 태스크들이 무 결하고 안전한지를 검사하며 개별 태스크들에 대한 행동 계획을 플래닝 하기 위해 멀티 태스크 Sequence를 최적행동 계획부에 전달하여 태스크를 분석하고 해당 태스크를 수행할 최적의 기기 및 지식의 조합을 구성한다. 이러한 상기 관리 에이전트는 Cost Benefit 모델(비용 이익 모델) 기반으로 비용이 가장 적게 들면서 이익을 최 대화할 수 있는 기기 및 지식의 조합을 통해 구성하는 것이 바람직하다. 한편, 상기 최적 행동 계획부는 생성한 최적 협상 결과를 기반으로 행동 태스크 Sequence들을 정제/분할/ 할당을 통해 분산 협업 공간상에 위치하고 있는 협업 에이전트들에게 관련 태스크를 자율 주행 로봇들을 통해 형성된 초지능형 네트워크의 지식/기기 검색, 연결 프로토콜을 통해 각 스마트 헬멧 착용자에게 전달 할 수 있다. 그리고 자율 협업 판단 및 전역 상황 인지부는 전달되는 멀티 태스크 플래닝 순서(Sequence)를 이용한 전 역 상황 인지 모니터링을 통해 목표 지점(Goal State)에 맞는 답이 충족한지 여부를 협업형 판단/추론/모델을 통해 검증하며, 불 충족 시, 순환 동작 구조를 갖도록, 협업 에이전트간 협업/협상부에게 미션 재플래닝 요청한 다. 도 10은 본 발명의 특징에 따른 전투병 협업 에이전트내 위치/공간 지능 처리부가 제공하는 자율 주행 로봇들 간의 UWB 통신 기반 순차적 연속 협업 측위 절차를 나타낸 순서도이다. 이하, 하기에서는 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 방법에 대하여 도 10을 참조하 여 설명하기로 한다. 먼저, 위치 측위 정보가 포함된 정보를 송수신하여 복수의 자율 주행 로봇들이 한 개의 클러스터를 형성하 면서 순차적으로 이동한다(S1010). 그리고, 클러스터를 형성한 자율 주행 로봇들 중 위치 측위 정보가 없는 영역으로 이동한 임의의 자율 주 행 로봇으로부터 위치 측위 정보가 없는 정보가 수신되는 지를 판단한다(S1020). 여기서, 상기 판단 단계(S1020)에서 임의의 자율 주행 로봇으로부터 위치 측위 정보가 없는 정보가 수신되 면{YES}, 위치 측위가 되지 않는 이동 위치에서 나머지 위치 측위 정보를 가지고 있는 상기 자율 주행 로봇 들과 TWR(Two-Way-Ranging) 방식을 통해 거리를 측정한다(S1030). 이어서, 측정된 거리를 기반으로 위치를 측정한다(S1040). 즉, 도 11a에 도시된 바와 같이, 자율 주행 로봇(100, node1 내지 node5)들이 GPS 장치로부터 위치 정보를 얻은 후 도 11b에 도시된 바와 같이 새로운 또 다른 자율 주행 로봇(100, node5)이 새로운 유효 거리상의 위치(GPS 음영 지역)로 이동하면, 도 11c에 도시된 바와 같이 GPS 음영 지역에 위치한 로봇(100, node5)은 위치 정보 확 인이 가능한 자율 주행 로봇(100, node1 내지 node4)와의 TWR 통신을 통해 위치 정보를 산출한다. 이후, 도 11d 에 도시된 바와 같이 새로운 또 다른 자율 주행 로봇(100, node1)이 새로운 유효 거리상의 위치(GPS 음영 지 역)로 이동하면, 자율 주행 로봇(100, node1)은 이웃하는 자율 주행 로봇(100, node2 내지 node5)와 TWR 통신 을 통해 위치 정보를 산출하는 방식으로, 순차적으로 반복하면서 협업 측위를 진행한다. 도 12는 본 발명의 일 실시예에서 TWR 기반의 협업 측위 기법을 계속적으로 이용할 때의 협업 측위 오차 공분산 을 산출하는 예를 나타낸 도면이다. 도 12에 도시된 바와 같이, 상기 위치를 측정하는 단계(S1040)는 측위 기준이 되는 모바일 앵커(위치 정보를 알 고 있는 자율 주행 로봇들)의 위치 오차를 산출하고, 산출된 앵커의 위치 오차를 이용하여 위치를 구하게 되는 새로운 모바일 태그(위치 정보를 새롭게 구하고자 하는 볼 타입 자율 주행 로봇)의 위치 오차를 누적하는 협업 측위 기반 순차적 위치 계산 메커니즘을 사용하는 것이 바람직하다. 도 13은 본 발명의 일 실시예에서 협업 측위 오차 공분산을 최소화할 수 있는 편대 이동 formation Scheme을 나 타낸 참고도이다. 상기 위치를 측정하는 단계(S1040)는 복수개의 앵커(1, 2, 3, 4)로 구성된 워크페이스(Workspace)내 위치한 앵 커의 목적지가 먼 곳이라면, 도 13a에 도시된 바와 같이 한번에 Workspace로부터 벗어나면서 이동하는 것이 아닌 도 13b에 도시된 바와 같이, 일정 범위 나누어 순차적으로 이동한다. 먼저, 앵커가 앵커의 위치로 이동하고, 앵커은 앵커의 위치로 이동하여 새로운 워크페이스를 형성 한 후 앵커가 목적지로 이동함으로써, 통신 네트워크의 연속성을 유지하면서 이동이 가능하다. 이때, 중 간 노드(3, 4)들은 일정 유효 범위까지 넓혀(d가 증가) 가면서 이동하는 것이 바람직하다. 도 14a 및 도 14b는 본 발명에서의 협업 측위 오차 공분산을 최소화할 수 있도록 하는 Full Mesh 기반 협업 측 위 방법을 나타낸 참고도이다. 상기 위치를 측정하는 단계(S1040)는 각 자율 주행 로봇이 모든 앵커 노드들의 위치도 새롭게 계산하여 전 체적으로 측위 오차를 보정하는 Full-mesh 기반 협업 측위 알고리즘을 이용할 수 있다. 즉, 도 14a에 도시된 바와 같이, 새로운 위치에 앵커가 위치하면, 앵커는 workspace를 형성하는 이웃 앵 커(2 ~ 5)들과의 통신을 통해 위치 측위를 검출한다. 이 때, Full Mesh 기반 협업 측위 방법은 도 14b에 도시된 바와 같이, workspace를 형성하는 다른 앵커(2 ~5) 또한 협업 측위를 수행한다. 이와 같은 Full Mesh 기반 협업 측위 방법을 이용할 경우, 각 앵커들의 계산량은 증가될 수 있으나, 각 앵커의 위치 측위 정확도가 높아지는 효과가 있다. 참고로, 본 발명의 실시예에 따른 구성 요소들은 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)와 같은 하드웨어 형태로 구현될 수 있으며, 소정의 역할들을 수행할 수 있다. 그렇지만 '구성 요소들'은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니며, 각 구성 요소는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 구성 요소는 소프트웨어 구성 요소들, 객체지향 소프트웨어 구성 요소들, 클래스 구성 요소 들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로 그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테 이블들, 어레이들 및 변수들을 포함한다. 구성 요소들과 해당 구성 요소들 안에서 제공되는 기능은 더 작은 수의 구성 요소들로 결합되거나 추가적인 구 성 요소들로 더 분리될 수 있다. 이 때, 처리 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행 될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가 능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설명된 기능들 을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터를 이용하거나 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터를 이용하거나 컴퓨터 판독 가능 메모리에 저장된 인 스트럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계 들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장 비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가 능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다.이 때, 본 실시예에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA또는 ASIC과 같은 하드웨어 구성요소를 의미하며, '~부'는 어떤 역할들을 수행한다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아 니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재 생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성 요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저 들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공 되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 이상, 본 발명의 구성에 대하여 첨부 도면을 참조하여 상세히 설명하였으나, 이는 예시에 불과한 것으로서, 본"}
{"patent_id": "10-2020-0045586", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "발명이 속하는 기술분야에 통상의 지식을 가진자라면 본 발명의 기술적 사상의 범위 내에서 다양한 변형과 변경 이 가능함은 물론이다. 따라서 본 발명의 보호 범위는 전술한 실시예에 국한되어서는 아니되며 이하의 특허청구 범위의 기재에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2020-0045586", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래 분리가능한 모듈형 재난구조 뱀 로봇 및 그 구동 방법을 나타낸 참고도. 도 2는 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 시스템을 설명하기 위한 기능블록도. 도 3은 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 시스템의 연결 구조를 설명하기 위한 참고 도. 도 4는 도 2의 자율 주행 로봇의 구성 중 센싱장치 및 통신 구성을 설명하기 위한 기능블록도. 도 5는 도 2의 자율 주행 로봇의 구성 중 네트워크 연결 및 관리에 필요한 구성을 설명하기 위한 기능블록도. 도 6은 도 2의 협업 에이전트의 구성을 설명하기 위한 기능블록도. 도 7은 도 2의 협업 에이전트 기능을 설명하기 위한 참고도. 도 8은 도 2의 협업 에이전트의 기능 중 자율 협업 판단 및 전역 상황 인지 기능을 처리하기 위한 기능블록도. 도 9는 도 2의 협업 에이전트의 기능을 설명하기 위한 참고도. 도 10은 본 발명의 일 실시예에 따른 멀티 에이전트 기반 유무인 협업 방법을 설명하기 위한 순서도. 도 11a 내지 도 11d는 본 발명의 일 실시예에서 자율 주행 로봇의 위치 측위 방법을 설명하기 위한 참고도. 도 12는 본 발명의 일 실시예에서 TWR 기반의 협업 측위 기법을 계속적으로 이용할 때의 협업 측위 오차 공분산 을 산출하는 예를 나타낸 도면. 도 13은 본 발명의 일 실시예에서 협업 측위 오차 공분산을 최소화할 수 있는 편대 이동 formation Scheme을 나 타낸 참고도. 도 14는 본 발명에서의 협업 측위 오차 공분산을 최소화할 수 있도록 하는 Full Mesh 기반 협업 측위 방법을 나 타낸 참고도이다."}
