{"patent_id": "10-2021-7034789", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0002326", "출원번호": "10-2021-7034789", "발명의 명칭": "분산 시스템에서 사용자 선호도에 대해 최적화하기 위한 맞춤화된 출력", "출원인": "마이크로소프트 테크놀로지 라이센싱, 엘엘씨", "발명자": "요시오카 다쿠야"}}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 구현 방법(computer-implemented method)에 있어서, 지능형 회의(intelligent meeting)에 관련된 복수의 분산 디바이스로부터 오디오 스트림들을 수신하는 단계; 상기 복수의 분산 디바이스 중의 분산 디바이스에 대응하는 사용자를 식별하는 단계; 상기 사용자의 선호 언어를 결정하는 단계; 하드웨어 프로세서에 의해, 상기 수신된 오디오 스트림들로부터 녹취록(transcript)을 생성하는 단계;번역된 녹취록을 형성하기 위해 상기 녹취록을 상기 사용자의 상기 선호 언어로 번역하는 단계; 및 상기 번역된 녹취록을 상기 분산 디바이스에 제공하는 단계를 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 번역된 녹취록을 제공하는 단계는 번역된 텍스트와 함께 상기 녹취록을 제공하는 단계를 포함하는 것인,컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 번역된 녹취록을 제공하는 단계는 상기 번역된 녹취록의 텍스트를 음성(speech)으로 변환하는 단계를 포함하는 것인, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 번역된 녹취록을 제공하는 단계는 상기 녹취록의 각각의 번역된 발화(utterance)에 대해 화자(speaker) 신원을 제공하는 단계를 포함하는 것인, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 사용자의 선호 언어를 결정하는 단계는 상기 사용자가 상기 선호 언어를 나타내기 위해 이전에 수립된 사용자 선호도에 액세스하는 단계를 포함하는 것인, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 지능형 회의는 애드혹 회의(ad-hoc meeting)이고, 상기 방법은,상기 오디오 스트림들이 상기 애드혹 회의로부터의 사운드를 나타낸다고 결정하기 위해 상기 오디오 스트림들을비교하는 단계; 및 상기 오디오 스트림들이 상기 애드혹 회의로부터의 사운드를 나타낸다고 비교 결정하는 것에 응답하여 상기 오디오 스트림들을 프로세싱하기 위해 회의 인스턴스를 생성하는 단계를 더 포함하는 것인, 컴퓨터 구현 방법.공개특허 10-2022-0002326-3-청구항 7 제1항에 있어서,상기 수신된 오디오 스트림에 대해 연속적인 음성 분리를 수행하여 동시에 말하는 상이한 화자들로부터의 음성을 별개의 오디오 채널들로 분리하는 단계를 더 포함하고, 상기 녹취록을 생성하는 단계는 상기 분리된 오디오채널들에 기초하는 것인, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 사용자를 식별하는 단계는, 상기 사용자를 캡처하는 비디오 신호를 수신하는 단계; 및 상기 사용자를 식별하기 위해 상기 사용자의 저장된 이미지를 상기 비디오 신호와 매칭하는 단계를 포함하는 것인, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 사용자를 식별하는 단계는, 상기 사용자의 저장된 음성 시그너처(voice signature)를 상기 오디오 스트림들로부터의 음성과 매칭하는 단계를 포함하는 것인, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 사용자를 식별하는 단계는,상기 분산 디바이스와 연관된 사용자 식별자를 획득하는 단계를 포함하는 것인, 컴퓨터 구현 방법."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "기계 판독가능 매체에 있어서,기계의 하나 이상의 하드웨어 프로세서에 의해 실행될 때 상기 기계로 하여금 제1항 내지 제10항 중 어느 한 항의 상기 방법을 수행하게 하는 명령어를 저장하는 기계 판독가능 매체."}
{"patent_id": "10-2021-7034789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "디바이스에 있어서, 하나 이상의 하드웨어 프로세서; 및 상기 프로세서에 결합되고, 상기 하나 이상의 하드웨어 프로세서에 의해 실행될 때 상기 하나 이상의 하드웨어프로세서로 하여금 제1항 내지 제10항 중 어느 한 항의 상기 방법을 수행하게 하는 프로그램이 저장된 메모리디바이스를 포함하는, 디바이스."}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "분산 시스템에서 사용자 선호도에 기초하여 맞춤화된 출력을 제공하기 위한 시스템 및 방법이 제공된다. 예시적 인 실시예에서, 회의 서버 또는 시스템은 지능형 회의에 관련된 복수의 분산 디바이스로부터 오디오 스트림을 수 신한다. 회의 시스템은 복수의 분산 디바이스 중 하나의 분산 디바이스에 대응하는 사용자를 식별하고 사용자의 선호 언어를 결정한다. 수신된 오디오 스트림으로부터의 녹취록이 생성된다. 회의 시스템은 녹취록을 사용자의 선호 언어로 번역하여 번역된 녹취록을 형성한다. 번역된 녹취록은 사용자의 분산 디바이스에 제공된다."}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사전에 계획된 회의는 회의 전에 또는 회의 시작 시 설정되는 하나 이상의 회의 도구를 사용하여 대화를 녹음하 고 화자 귀속 녹취록(speaker attributed transcript)을 생성할 수 있다. 그러한 기존의 회의 도구는 회의 테이 블 상에 놓인 디바이스의 상이한 측부들 상에 복수의 고정 스피커를 갖는 이러한 디바이스를 포함할 수 있다. 이 디바이스는 탑(tower) 또는 원뿔 형상을 가질 수 있으며 회의에서 사람들을 식별하고 추적하는 데 사용될 할 수 있는 비디오 카메라를 갖거나 이와 연관될 수 있다. 음성 대 텍스트 알고리즘(speech-to-text algorithms)을사용하여 녹취록을 생성할 수 있다. 오디오 빔형성(beamforming)은, 녹취록에서 음성을 귀속할(attribute) 참석 자의 비디오와 함께 고정된 화자(speakers)의 알려진 위치와 함께 사용될 수 있다."}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래의 설명에서는, 그 일부를 형성하고, 실시될 수 있는 특정 실시예들이 예시로서 도시되는 첨부 도면들을 참 조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있도록 충분히 상세하게 설명되며, 다른 실시예가 이용될 수 있고, 본 발명의 범위를 벗어나지 않고 구조적, 논리적 및 전기적 변경이 이루어질 수 있음을 이해해야 한다. 따라서, 예시적인 실시예에 대한 다음의 설명은 제한된 의미로 받아들여져서는 안 되며, 본 발명의 범위 는 첨부된 청구항들에 의해 정의된다. 본 명세서에 설명된 기능 또는 알고리즘은 일 실시예에서 소프트웨어로 구현될 수 있다. 소프트웨어는 예를 들 어, 로컬 또는 네트워크로 접속된 하나 이상의 비일시적 메모리 또는 다른 유형의 하드웨어 기반 저장 디바이스 와 같은 컴퓨터 판독 가능 매체 또는 컴퓨터 판독 가능 저장 디바이스에 저장된 컴퓨터 실행 가능 명령어를 포 함할 수 있다. 또한, 이러한 기능은 소프트웨어, 하드웨어, 펌웨어 또는 이들의 조합일 수 있는 모듈에 대응한 다. 다수의 기능은 원하는 대로 하나 이상의 모듈에서 수행될 수 있으며, 설명된 실시예는 단지 예일 뿐이다. 소프트웨어는 디지털 신호 프로세서, ASIC, 마이크로프로세서, 또는 예를 들어, 개인용 컴퓨터, 서버 또는 기타 컴퓨터 시스템과 같은 컴퓨터 시스템에서 작동하는 다른 유형의 프로세서에서 실행되어, 이러한 컴퓨터 시스템 을 특별히 프로그래밍된 기계로 전환시킬 수 있다. 기능은 예를 들어, 소프트웨어, 하드웨어, 펌웨어 등을 사용하여 작업을 수행하도록 구성될 수 있다. 예를 들어, \"~로 구성된\"이라는 문구는 연관된 기능을 구현하기 위한 하드웨어 요소의 논리 회로 구조를 지칭할 수 있다. \"~로 구성된\"이라는 문구는 또한 펌웨어 또는 소프트웨어의 연관된 기능의 코딩 설계를 구현하기 위한 하 드웨어 요소의 논리 회로 구조를 지칭할 수 있다. \"모듈\"이라는 용어는 임의의 적절한 하드웨어(예컨대, 특히, 프로세서), 소프트웨어(예컨대, 특히, 애플리케이션), 펌웨어, 또는 하드웨어, 소프트웨어 및 펌웨어의 임의의 조합을 사용하여 구현될 수 있다. 용어 \"논리\"는 작업(task)을 수행하기 위한 임의의 기능을 포괄한다. 예를 들 어, 흐름도에서 예시된 각 동작은 이 동작을 수행하기 위한 논리에 대응한다. 소프트웨어, 하드웨어, 펌웨어 등 을 사용하여 동작이 수행될 수 있다. \"컴포넌트\", \"시스템\" 등의 용어는 컴퓨터 관련 엔티티, 하드웨어 및 실행 중인 소프트웨어, 펌웨어 또는 이들의 조합을 지칭할 수 있다. 컴포넌트는 프로세서 상에서 실행되는 프로세스, 객체, 실행 파일(executable), 프로그램, 함수, 서브루틴, 컴퓨터, 또는 소프트웨어와 하드웨어의 조합일 수 있 다. \"프로세서\"라는 용어는 예를 들어, 컴퓨터 시스템의 프로세싱 유닛과 같은 하드웨어 컴포넌트를 지칭할 수 있다. 더욱이, 청구된 요지(subject matter)는 개시된 요지를 구현하도록 컴퓨팅 디바이스를 제어하는 소프트웨어, 펌 웨어, 하드웨어, 또는 이것들의 임의의 조합을 생성하기 위해 표준 프로그래밍 및 엔지니어링 기법들을 사용하 여 방법, 장치, 또는 제조 물품으로서 구현될 수도 있다. 본 명세서에서 사용된 \"제조 물품\"이란 용어는 임의의 컴퓨터 판독가능 저장 디바이스 또는 매체로부터 액세스 가능한 컴퓨터 프로그램을 포괄하는 것으로 의도된다. 사용자라고 하는 개인은 언제든지 대화나 회의를 시작할 수 있다. 회의가 스케줄링되어 있는 경우, 대화를 녹음 하고 나중에 참조할 수 있도록 대화의 녹취록을 생성하기 위한 준비가 이루어질 수 있다. 그러나, 애드혹 회의 에는 일반적으로 그러한 준비가 수반되지 않다. 회의를 중단하거나 그렇지 않으면, 대화를 녹음하고 녹취록이 작성되게 준비하는 방법을 설정하는 데 시간을 할애하는 것은 주의를 산만하게 하거나 회의 중에는 이와 같은 준비가 생각되지 못할 수 있다. 또한 애드혹 회의는 종종 회의실 밖에서 열린다. 이러한 경우, 회의용으로 특별 히 설계된 녹음 디바이스를 사용할 수 없다. 대화 중에, 대화의 오디오는 분산 디바이스라고 하는, 사용자가 휴대하고 있는 디바이스에 의해 캡처될 수 있다. 예시적인 실시예에서, 캡처된 오디오 신호는 무선 채널을 통해 회의 시스템으로 송신되어 다수의 사용자 가 회의라고 하는 대화를 하고 있음을 인식하며, 이런 회의는 계획되었거나 계획되지 않았을 수 있다. 회의가 계획되지 않은 경우, 이 회의를 애드혹 회의라고 한다. 회의가 검출되었거나 다른 방식으로 준비된 것에 응답해서, 회의 시스템에서 회의 인스턴스가 생성되어 말하고 있는 사용자로부터의 음성을 인식하고 회의의 녹취록을 생성한다. 다수의 분산 디바이스로부터의 다수의 음성 신호가 별도의 오디오 채널로서 수신되어 녹취록을 생성하는 데 사용된다. 분산 디바이스는 개인 사용자 디바이 스(예컨대, 스마트폰)뿐만 아니라 디지털 어시스턴트, 카메라, 및 대화 범위 내에서 오디오 및/또는 비디오를 수신할 수 있는 임의의 유형의 디바이스를 포함한 다른 디바이스를 포함할 수 있다. 일부 실시예에서, 회의 애플리케이션을 통해 단일 디바이스 상의 버튼을 한 번 눌러 회의가 생성될 수 있다. 다 른 디바이스 및 디바이스를 가진 사용자는 회의 애플리케이션을 통해 자신들의 사용자 디바이스 상에 표시된 버 튼을 누르거나, 사용되지 않는 동안 모집되어(예컨대, 회의실에 있는 기존 회의 디바이스) 회의에 참여할 수 있 다. 회의 참가자는 음성 지문에 의해, 참여 디바이스의 소유자임에 의해, 얼굴 인식에 의해, 또는 (원격 참가자를 위해) 임의의 시점에서 자신들의 디바이스 상의 회의 애플리케이션을 통해 사용자를 수동으로 추가함으로써 추론될 수 있다. 회의가 성립될 수 있는 방법은 여러 가지가 있다. 일부 실시예에서, 예를 들어, 스마트폰과 같은 분산 디바이스 는 각각의 사용자와 연관되고 디바이스 상의 마이크로부터 수신된 오디오를 회의 시스템 또는 서버로 스트리밍 하는 데 사용되는 회의 애플리케이션을 포함한다. 주변 디바이스에서 수신된 오디오는 주변 소음 및/또는 디바 이스 근처에서 생성된 임의의 사운드의 결합에 기초하는 오디오 시그너처(audio signature)를 가질 것이다. 2개 의 사용자 디바이스가 각각의 오디오 스트림(오디오 채널)을 통해 유사한 오디오 시그너처를 제공하는 것에 대 한 응답으로, 회의 시스템은 회의가 발생하고 있을 수 있음을 인식하고 수신된 오디오를 프로세싱하기 위해 회 의 인스턴스를 생성한다. 사용자는 자신의 회의 애플리케이션을 통해 회의에 참여하라고 프롬프트(prompt)될 수 있다. 대안적으로, 예를 들어, 위치 정보, 이전 상호작용, 캘린더 정보, 또는 최근 이메일 상호작용과 같은 다 른 정보를 사용하여 두 사용자 모두 또는 세 번째 사용자가 회의 인스턴스에 추가되어야 함을 확인(confirm)할 수 있다. 추가 실시예에서, 오디오 워터마크는 하나 이상의 사용자 디바이스에 의해 생성된다. 오디오 워터마크는 오디오 시그너처를 포함하거나 오디오 시그너처가 별도로 검출될 수 있다. 오디오 워터마크는 예를 들어, 20Khz 이상과 같이 사용자의 정상적인 가청 범위를 초과하는 주파수를 갖는 사운드 패턴일 수 있거나, 대화에 방해가 되지 않 도록 사용자의 주의를 끌지 않는(inconspicuous) 사운드일 수도 있다. 추가 실시예에서, 워터마크는 완전히 들 을 수 있고 인식할 수 있다. 워터마크는 일부 실시예에서 회의 인스턴스가 대화 동안 생성되는 것을 보장하고자 하는 사용자에 의해 송신되도록 선택될 수 있다. 워터마크는 범위 내의 분산 디바이스에 의해 수신되고 자동으 로 또는 선택적으로 회의 인스턴스에 추가된다. 워터마크 사운드 범위 내에 있는 디바이스는 추가 오디오 채널 로서 회의 인스턴스에 추가된 자신의 오디오 스트림을 가질 수도 있다. 일부 실시예에서, 회의 코드가 생성되어 다른 사용자들에게 송신되어 그들을 계획된 회의 또는 애드혹 회의에 추가한다. 회의 코드는 스케줄링된 회의 전에 선택되어 회의 초대에 사용할 수도 있다. 회의 시스템은 사용자 디바이스로부터 회의 코드를 수신하면 이러한 사용자 디바이스로부터의 오디오 스트림을 일단 인스턴스화된 회 의에 추가한다. 예시적인 실시예는 분산 시스템에서 사용자 선호도에 기초하여 맞춤화된 출력을 제공하기 위한 시스템 및 방법 을 제공한다. 예시적인 실시예에서, 회의 서버 또는 시스템은 지능형 회의에 관련된 복수의 분산 디바이스로부 터 오디오 스트림을 수신한다. 회의 시스템은 복수의 분산 디바이스 중 하나의 분산 디바이스에 대응하는 사용 자를 식별하고 사용자의 선호 언어를 결정한다. 회의가 발생하면 수신된 오디오 스트림으로부터의 녹취록이 생 성된다. 회의 시스템은 녹취록을 사용자의 선호 언어로 번역하여 번역된 녹취록을 형성한다. 번역된 녹취록은 사용자의 분산 디바이스에 제공된다. 예시적인 실시예에서, 번역된 녹취록은 회의가 발생하고 있음에 따라 실시 간으로(또는 거의 실시간으로) 제공된다. 번역된 녹취록은 텍스트를 통해 제공되거나(예컨대, 사용자의 디바이 스 상에 표시됨), (예컨대, 스피커, 보청기, 이어폰을 통해) 오디오로서 출력될 수 있다. 일부 실시예에서, 번 역 대신에 또는 번역에 추가하여, 원본 녹취록, 번역된 녹취록, 또는 번역된 음성 오디오에 다른 유형의 변환이 적용될 수 있다. 도 1은 다수의 사용자 간의 회의의 사시도이다. 제1 사용자는 음성을 포함하는 오디오를 캡처하기 위 한 마이크를 포함하는 제1 디바이스를 갖는다. 제2 사용자는 또한 음성을 포함하는 오디오를 캡처할 수 있는 제2 디바이스를 갖는다. 사용자들은 하나의 예시적인 회의에서 테이블에 앉을 수 있다. 제1 및 제2 디바이스(115, 125)(\"다수의 분산 디바이스\" 또는 \"복수의 분산 디바이스\"로도 지칭됨)는 녹취록의 프로세싱 및 생성을 위해 캡처된 오디오를 회의 서버로 송신한다. 회의는 계획되지 않았기 때문에 애드혹 으로 진행될 수 있다. 예를 들어, 사용자들은 휴식 시간에 서로 마주쳤거나 복도에서 우연히 서로 만나 자신들 이 작업 중인 프로젝트에 대해 대화하기로 결정할 수 있다. 회의 애플리케이션(\"회의 앱\"이라고도 함)은 제1 디 바이스 및 제2 디바이스 모두에서 실행될 수 있다. 회의 앱은 회의 서버에 오디오를 제공하기 위해 사용될 수 있다. 회의 서버는 두 디바이스 모두가, 유사한 오디오 시그너처를 갖는 오디오, 유사한 오디오 워터마크, 두 디 바이스에 의해 제공되는 유사한 회의 코드, 또는 사용자들 간의 진행 중인 토론을 나타내는 다른 정보를 송신하 고 있음을 검출한다. 이에 응답하여, 회의 서버는 수신된 오디오를 프로세싱하고 녹취록을 생성하기 위해 회의 인스턴스를 생성한다.다양한 실시예에서, 워터마크는 약 20kHz인, 또는 그렇지 않으면 회의에 대응하는 회의 인스턴스 또는 회 의 코드를 식별하는 들리지 않거나, 주의를 끌지 않거나, 방해가 되지 않는, 단지 사람의 가청 범위를 초과하는 에너지를 갖는 임의의 유형의 사운드일 수 있다. 워터마크는 추가 실시예에서 회의 인스턴스의 회의 코드 또는 다른 식별을 인코딩하는 사운드일 수 있다. 회의는 계획된 것이든 애드혹으로든 두 명보다 많은 사람들을 포함할 수 있다. 제3 디바이스를 가진 제3 사용자도 회의에 참여할 수 있다. 제3 디바이스는 또한 분산 회의 서버에 오디오를 제 공한다. 오디오는 처음 2명의 사용자/디바이스가 회의에 관련되어 있음을 인식하기 위해 설명된 동일한 메 커니즘 중 하나 이상에 의해 회의에 관련된 것으로 인식된다. 분산 디바이스의 소유자/사용자는 회의 서버에 의해 인식되도록 앱을 통해 자신을 등록할 수 있다. 사용자 는 회의 서버가 사용자와 들어오는 음성 사운드를 연관시키는 것을 돕기 위해 음성 엄지 손가락 지문 (voice thumbprint) 또는 음성 지문으로 지칭되는 음성 프로파일을 갖거나 생성할 수 있다. 임의의 사람이 회의 에 참여하는 경우, 회의 서버는 그 사람이 알려지지 않은 것을 인식하고 이미 회의에 참여하고 있는 하나 이상의 사용자에게 그 사람의 이름을 프롬프트한다. 대안적으로, 회의 서버는 프로파일을 가진 사람 을 매칭하기 위해 회의에서 알려진 사용자와 연관된 조직의 데이터베이스를 검색한다. 그 사람이 알려지지 않았 거나 다른 방식으로 식별되는 경우, 생성된 녹취록에서 예를 들어, 화자 1, 화자 2 등과 같은 라벨이나 태그로 그 사람이 식별되므로 나중에 그 사람의 이름이 지정될 경우 녹취록을 더 쉽게 수정할 수 있게 한다. 임의의 사 용자는 회의 중 또는 회의 후에 언제든지 화자 라벨에 이름을 지정할 수 있다. 이미 회의에 참여한 사람의 알려 지거나 자주 연락하는 콘택(contacts)은 이 사람을 식별하는 프로세스를 최적화하기 위해 이 사람을 처음 확인 (check)하는 데 사용되는 풀/데이터베이스(pool/database)를 줄이는 데 사용될 수 있다. 예를 들어, 디지털 어시스턴트 또는 전용 회의 디바이스와 같이 회의의 오디오 또는 시각적 범 위 내에 있는 추가 디바이스가 있을 수 있으며, 이 둘 다가 테이블에 도시되지만, 회의의 오디오 범 위 내 임의의 곳에 있을 수 있다. 이러한 추가 디바이스는 분산 회의 서버에 접속될 수 있고 회의 서버 에서 실행되는 회의 인스턴스의 오디오 및 음성-텍스트 프로세싱 능력을 더욱 향상시키기 위한 프로세싱을 위해 자신의 오디오 스트림을 회의 인스턴스에 추가할 수 있다. 그러한 추가 디바이스는 회의 서버에 의해 검출될 수 있고 전술한 바와 같이 회의에 추가될 수 있거나 회의에 추가하기 위한 옵션으로서 사용자들 중 한 명 이상에게 제시될 수 있다. 비디오 카메라 또는 다른 이미지 캡처링 디바이스는 회의(또는 회의의 일부)를 포함하는 시야를 가질 수 있다. 회의 서버는 카메라가 회의 근처에 있다는 것을 인식하고 사용자 중 한 명 이상 에게 표시(indication)를 제공할 수 있으며, 카메라로부터 정보를 획득하고 회의 인스턴스에 정보를 제공 하여 녹취록의 프로세싱 및 제공(provision)을 더 향상시키기 위한 옵션을 제공한다. 예를 들어, 카메라는 어느 사용자가 말하고 있는지를 검출하거나, 적어도 사용자가 임의의 특정 시점에서 말하고 있을 가능성이 있는 정보를 제공하는 데 사용될 수 있다. 도 2는 회의에서 사용하기 위한 사용자 디바이스의 블록도이다. 회의에 참여하는 다른 디바이스는 유사한 컴포넌트 세트를 가질 수 있다. 디바이스는 적어도 하나의 마이크 및 메모리에 저장되는 회의 앱을 실행하기 위한 프로세서를 포함한다. 트랜시버는 카메라로부터의 오디오 및/또는 비 디오를 분산된 회의 서버로 스트리밍하는 데 사용된다. 사용자 디바이스는 또한 예를 들어, 그 일부 가 도시된 터치 스크린과 같은 디스플레이 스크린을 가질 수 있다. 회의에 참여할 수 있는 디바이스는 캘린더 항목, 현재 위치, NFC(전화기를 함께 매우 가까이 가져오기), 블루투 스® 광고, 및 회의 코드, 또는 회의와 연관되어 생성될 수 있는 다른 코드를 통한 직접 초대를 통해 식별 될 수 있다. 회의 서버는 다수의 회의 인스턴스를 통해 동시에 여러 회의를 프로세싱하고 있을 수 있다. 각각의 회의 인스턴스는 예를 들어, 회의 코드와 같은 회의 식별자, 오디오를 스트리밍하고 있는 디바이스의 식별, (사용자 연관 디바이스를 통해) 회의에 참여하거나, 그렇지 않으면 안면 인식, 음성 인식, 또는 사용자를 인식하는 다른 수단에 의해 회의 서버에 의해 인식되는 사용자의 식별을 포함할 수 있다. 도 3은 연관된 분산 디바이스를 갖는 2명의 사용자 사이의 지능형 회의를 개시하는 방법을 예시하는 흐름 도이다. 동작에서, 오디오 워터마크는 제1 분산 디바이스와 연관된 마이크를 통해 제1 분산 디바이스에서 수신된다. 일 실시예에서, 오디오 워터마크는 회의 동안 제2 분산 디바이스와 연관된 화자에 의해 송신된다.수신된 오디오 워터마크에 대응하는 데이터는 동작에서 제1 분산 디바이스를 통해 분산 디바이스 회의 서 버로 송신된다. 일부 실시예에서, 수신된 오디오 워터마크는 먼저 디지털 형태로 변환되며, 이는 단순히 오디오 워터마크를 사운드의 디지털 표현으로 직접 변환하거나, 오디오 워터마크를 방출(emit)한 회의 또는 제2 분산 디바이스를 식별하는 데이터를 획득하기 위해 오디오 워터마크를 디코딩하는 것을 포함할 수 있다. 동작에서, 분산 회의 서버로부터, 제1 분산 디바이스가 분산 디바이스 회의 서버 상의 회의 인스턴스에 받 아들여졌다(accept)는 표시가 수신된다. 제1 분산 디바이스는 동작에서 수신된 표시에 응답하여 분산 디바이스 회의 서버 상의 회의 인스턴스에 회 의의 오디오를 스트리밍한다. 수신된 표시는 사용할 통신 채널을 식별하는 정보를 포함할 수 있거나, 오디오 스 트림은 오디오 스트림을 올바른 회의 인스턴스로 안내(direct)하기 위해 회의 서버가 사용하는 스트리밍 디바이 스를 간단히 식별할 수 있다. 도 4는 회의 코드를 사용하여 지능형 회의에 분산 디바이스를 추가하는 방법을 도시하는 흐름도이다. 일부 실시예에서, 회의 코드는 방법에서 논의된 바와 같이 워터마크로 인코딩된다. 동작에서, 제1 분산 사 용자 디바이스에 의해 사용자들 간의 회의를 위한 회의 코드가 수신되거나 생성된다. 제1 분산 사용자 디바이스 는 회의 인스턴스를 실행하는 회의 서버로부터 코드를 수신할 수 있거나, 제1 분산 사용자 디바이스는 제1 분산 사용자 디바이스에서 실행되는 회의 앱을 통해 회의 코드를 생성한다. 이 코드는 동작에서 제2 분산 사용자 디바이스로 송신된다. 이 코드는 이메일, 텍스트 또는 데이터를 전자 적으로 송신하는 다른 수단을 통해 송신될 수 있거나, 또는 가청 신호(오디오 워터마크)로서 인코딩되어 예를 들어, 제1 분산 사용자 디바이스와 같은 사용자 디바이스들 중 하나의 스피커를 통해 나머지 참여 디바이스에 음향적으로 송신될 수 있다. 제2 분산 사용자 디바이스는 회의 코드를 회의 서버 회의 인스턴스에 제공하고, 이에 의해 회의 코드는 동작 에서 적어도 하나의 제2 분산 사용자 디바이스를 식별하는 데 사용된다. 제2 분산 사용자 디바이스는 동작 에서 제1 및 제2 분산 사용자 디바이스 모두로부터 회의 서버 회의 인스턴스로 오디오를 스트리밍한다. 회의는 다수의 사용자 또는 다수의 사용자 디바이스 간의 애드혹 회의일 수 있으며 회의 코드는 애드혹 회의가 시작된 후에 생성된다. 또한, 회의에 참여하고 있는 연관된 사용자 디바이스가 없는 사용자가 또한 있을 수 있 다는 것에 주목한다. 사용자와 연관되지 않은 다른 사용자 디바이스 및 디바이스들은 디바이스의 검출된 위치에 기초해 식별될 수 있다. 그러한 디바이스로부터의 데이터는 사용자(들)에게 다른 주변 디바이스 목록을 제공함 으로써 회의 인스턴스에 추가된 자신의 데이터 스트림을 가질 수 있고 회의 인스턴스에 추가할 앱의 사용자 인 터페이스를 통해 그러한 디바이스의 선택을 허용한다. 회의에 참여하고 있을 수 있는 디바이스는 캘린더 항목, 현재 위치, NFC(전화기들을 함께 매우 가까이 가져오기), 블루투스 광고 및 직접 초대를 통해 식별될 수 있다. 추가 실시예에서, 회의는 다수의 사용자 또는 다수의 사용자 디바이스 간의 계획된 회의이고 회의 코드는 계획 된 회의가 시작되기 전에 생성된다. 회의 코드는 각각의 사용자 디바이스로 송신되고 대응 앱에 의해 회의 동안 이러한 디바이스로부터의 데이터 스트림을 추가하기 위해 회의 서버 회의 인스턴스에 디바이스를 식별하는 데 사용될 수 있다. 도 5는 지능형 회의에 추가 디바이스를 추가하는 컴퓨터 구현 방법이다. 동작에서, 회의 서버는 분산 디바이스 그룹으로부터 오디오 스트림을 수신하고, 여기서 오디오 스트림은 2명 이상의 사용자의 회의 동안 이 러한 분산 디바이스 그룹에 의해 검출된 음성을 포함한다. 회의 서버는 추가 또는 새로운 분산 디바이스로부터 회의에 대응하는 회의 정보를 동작에서 수신한다. 새 로운 디바이스는 방금 회의에 참여한 사용자의 사용자 디바이스일 수 있거나, 새로운 디바이스는 회의실에 있거 나 그렇지 않으면 지능형 회의의 범위 내에 있는 디바이스일 수 있다. 동작에서, 추가 분산 디바이스가 회의 서버 회의 인스턴스에 추가된다. 추가 분산 디바이스의 추가에 대한 응답으로 동작에서 추가 분산 디바이스로부터 정보 스트림이 수신된다. 도 6은 애드혹 회의가 발생하고 있음을 검출하는 컴퓨터 구현 방법을 도시하는 흐름도이다. 동작에서, 오디오 스트림은 2명의 사용자 간의 애드혹 회의 동안 검출된 오디오를 스트리밍하는 적어도 2 개의 분산 디바이스로부터 회의 서버에서 수신된다. 오디오 스트림들이 애드혹 회의로부터의 사운드를 나타낸다고 결정하기 위해 동작에서 오디오 스트림들이 비교된다. 오디오 스트림들은 예를 들어, 두 신호 간의 정규화된 상호 상관 계수를 계산함으로써 비교될 수 있다. 결과가 미리 결정된 문턱값을 초과하는 경우 오디오 스트림은 동일한 애드혹 회의에서 유래한 것일 가능성 이 가장 크다. 선택된 문턱값은 0과 1 사이의 숫자일 수 있으며 상이한 환경들에서 다수의 회의 시나리오 동안 수행된 테스트에 기초해 경험적으로 선택될 수 있다. 위음성(false negatives) 및 위양성(false positives)의 원하는 균형을 얻기 위해 선택이 수행될 수 있다. 스트림들이 동일한 회의에서 유래했다는 다른 표시는 디바이 스들의 위치가 동일하다는 것을 포함한다. 추가적인 표시는 과거에 다수의 상호 작용을 가졌던 사용자, 동일한 조직에 있는 사용자, 및 사용자가 만날 가능성이 있는 다른 표시를 포함한다. 오디오 스트림으로부터 생성된 텍 스트를 비교하여 추가 검증이 얻어질 수 있다. 스트림이 성공적으로 비교되면, 회의 ID/코드가 생성되어 더 많은 참가자를 추가하는 데 사용될 수 있다. 추가 디바이스가 이미 회의에 있는 오디오 스트림과 성공적으로 비교되는 오디오를 스트리밍하는 것에 대한 응답으로 다른 참가자가 추가될 수 있다. 디바이스가 추가되면, 디바이스는 예를 들어, 핑(ping)과 같이, 회의 참여를 나 타내는 신호를 생성할 수 있다. 회의 서버는, 오디오 스트림이 애드혹 회의로부터의 사운드를 나타낸다고 결정하는 것에 응답하여 오디오 스트 림을 프로세싱하기 위해 동작에서 회의 인스턴스를 생성한다. 일부 실시예에서, 사용자들은, 자신들의 각 각의 디바이스로부터의 오디오 스트림이 회의 인스턴스에 추가되기 전에 인증된다. 인증은 회의 앱으로부터의 사용자 확인(user confirmation), 캘린더 정보, 조직도, 회의 코드의 사용, 이미 회의에 참여하고 있는 사용자 와의 콘택/관계 정도, 및 다른 인증 수단에 기초할 수 있다. 동작에서, 오디오 스트림은 애드혹 회의의 녹취록을 생성하도록 프로세싱된다. 일 실시예에서, 회의 서버 는 디바이스 및/또는 연관된 사용자가 회의를 떠났을 때를 검출하고 회의 인스턴스로부터, 그 디바이스로 부터의 오디오 스트림/채널을 제거한다. 어떤 디바이스와 연관된 참가자가 회의를 떠날 때, 회의 서버는 회의에서 이 디바이스와 연관된 오디오 신호의 부재를 검출하고 회의로부터 이 디바이스를 제거한다. 대안은, 사용자 회의 앱을 통해 떠나는 것을 시그널링하는 것, 회의 앱을 닫는 것, 디바이스 위치가 더 이상 회의 위치 근처에 있지 않다고 검출하는 것, 디바이스로부터의 비디오 스트림에서의 대응 오디오 워터마크의 부재를 검출 하는 것, 디바이스에 의해 수신된 오디오 시그너처가 더 이상 다른 디바이스 오디오 스트림의 오디오 시그너처 와 매칭되지 않는다고 검출하는 것, 또는 비디오 신호로부터의 이미지에 대한 이미지 인식을 수행하여 사용자가 회의가 진행 중인 회의실 또는 영역을 떠나고 있거나 떠났다고 검출하는 것을 포함한다. 유사하게, 회의 인스턴 스는 단일 사용자가 남아 있거나 단일 사용자 디바이스가 남아 있는 것에 대한 응답으로 종료될 수 있다. 도 7은 대응하는 사용자가 회의를 떠나는 것에 응답하여, 사용자 디바이스 및 다른 디바이스의 오디오 채널을 제거하는 컴퓨터 구현 방법을 예시하는 흐름도이다. 동작에서, 분산 디바이스 회의로부터 오디오를 수신하는 분산 디바이스 그룹으로부터 수신된 대응하는 다수의 오디오 채널 상의 다수의 오디오 신호가 회의 서 버 인스턴스에 의해 프로세싱된다. 회의 서버 인스턴스는 위에서 논의된 바와 같이, 분산 디바이스의 그룹 중의 제1 디바이스와 연관된 제1 사용자가 분산 디바이스 회의를 떠났음을 검출하기 위해 동작에서 사용된다. 동작에서, 응답으로 회의 서버 인스턴스에 의해 프로세싱되고 있는 다수의 오디오 채널로부터 제1 분산 디 바이스의 오디오 채널이 제거된다. 도 8은, 디바이스를 인증하고, 회의 서버 인스턴스에 의해 프로세싱되고 있는 오디오 채널에 이 디바이스로부터 의 오디오 스트림을 추가하기 위한, 컴퓨터 구현 방법을 예시하는 흐름도이다. 방법은 회의 동안 다수의 사용자로부터 음성을 수신하는 다수의 분산 디바이스로부터의 오디오 스트림을 회의 서버에서 수신함으로써 동 작에서 시작한다. 수신된 오디오 스트림은 오디오 스트림에 포함된 음성에 기초하여 녹취록을 생성하기 위 해 회의 서버에서 실행되는 회의 인스턴스를 통해 동작에서 프로세싱된다. 동작에서, 제1 추가 사용자와 연관된 제1 추가 분산 디바이스로부터 정보가 회의 서버에서 수신되며, 이 정보는 사용자들 간의 회의에 대응한다. 이 정보는 사용자의 디바이스를 추가하라는 요청에 대응할 수 있거나, 그러한 디바이스로부터의 오디오 스트림이 워터마크 또는 오디오 시그너처를 포함한다는 표시(noting)에 의한 암시적 요청일 수 있다. 동작에서, 제1 추가 분산 디바이스 또는 연관된 사용자가 인증되거나 그렇지 않으면 회의에 참여하도록 인 가된다. 참가자는 음성 지문, 회의 주최자 수락, 회의 코드 및/또는 새 코드 사용, 참가자 디바이스의 검출된 위치, 디바이스 ID 및/또는 연관된 사용자 ID와 인가된 목록의 비교, 조직 구성원 확인(check), 주최자에 의한 수락을 요구하는 비공개 회의 플래그(closed meeting flag) 사용, 또는 전술된 것들의 하나 이상의 조합에 기초 해 회의에 참가하도록 인가될 수 있다. 방법은 또한 회의에 참여하기 위해 처음 두 개의 디바이스에 적용 될 수 있으며, 예를 들어, 회의의 시야를 갖는 비디오 카메라 또는 회의실에 있는 회의 도우미 유형(meetingassistant type)의 디바이스와 같이 사용자와 직접 연관되지 않은 디바이스에도 적용될 수 있다. 추가 분산 디바이스 또는 연관된 사용자의 인증에 응답하여, 동작에서 제1 추가 분산 디바이스는 회의 인 스턴스에 추가된 자신의 오디오 스트림을 갖는다. 일부 실시예에서, 원격 참가자는 예를 들어, 마이크로소프트 스카이프(Skype) 또는 팀즈(Teams), 전화 연결 (telephone dial-in), 또는 임의의 다른 원격 회의 애플리케이션과 같은 통신 플랫폼을 통해 회의에 접속될 수 있다. 스카이프와 같은 원격 회의 플랫폼이 사용되는 경우 미리 송신된 링크를 따라 회의에 참여할 수 있다. 전 화 연결의 경우, 고유한 전화번호 또는 예를 들어, 회의 코드와 같은 액세스 코드가 공유될 수 있다. 원격 오디 오 채널이 회의용 서버에 접속되면, 원격 오디오 채널은 회의 영역으로부터의 오디오 스트림과 유사한 방식으로 프로세싱된다. 화자 ID는 로그인 프로세스(sign-in process)에 기초해 알려진다. 오디오 스트림은 단일 사용자/ 화자를 위한 것일 수 있는데, 이는 스피커폰이 다수의 원격 사용자와 함께 사용되지 않는 한 음성 분리가 필요 하지 않는 것을 의미한다. 스피커폰에 의해 재생되고 있고 회의에서 근처에 분산된 디바이스에 의해 검출되는 오디오는 그러한 근처에 있는 분산된 디바이스의 오디오 스트림으로부터 취소될 수 있다. 도 9는 다수의 사용자 간의 회의에 대한 녹취록을 생성하기 위한 시스템의 고수준 블록 흐름도이다. 사용 자 각각은 회의에서 다양한 사용자들에 의한 음성을 포함하여 오디오를 캡처하고, 캡처된 오디오를 각각 오디오 채널(916, 918, 및 920)을 통해 오디오 신호로서, 적어도 회의 녹취록기를 포함하는 회의 서버에 제공하기 위해 마이크가 장착된 연관된(분산된) 디바이스(910, 912, 914)를 가질 수 있다. 상이한 디바이스들은 약간 상 이한 클록 주기들과 프로세싱 대기 시간의 상이한 양들을 가질 수 있다. 또한, 각 디바이스 대 서버 접속 채널 은 고유한 대기 시간을 가질 수 있다. 따라서, 오디오 채널(916, 918, 및 920)로부터의 오디오 신호는 반드시 동기화될 필요는 없다. 회의 녹취록기는 음성 인식 모듈 또는 기능 외에 동기화 모듈 또는 기능을 포함한다. 일 실시예에 따라, 오디오 채널(916, 918, 및 920)로부터의 오디오 신호는 먼저 동기화되고 그 다음 인식되어 각 채널과 연관된 텍 스트가 생성된다. 그런 다음, 인식 출력은 (융합부에 의해) 융합되거나 다른 방식으로 프로세싱되어 녹취 록을 생성한다. 그 다음, 녹취록은 사용자에게 다시 제공될 수 있다. 다른 실시예에서, 오디오 채널 (916, 918, 및 920)로부터의 오디오 신호는 음성 인식 전에 융합된다. 융합 후 얻어진 오디오 신호가 인식되어 단일 버전의 텍스트가 생성된다. 일부 실시예에서, 녹취록은 매우 적은 지연으로 제공될 수 있다. 다양한 실시예에서, 화자 식별과 관련하여 사용되는 텍스트로의 오디오 신호의 변환 및 화자를 식별하기 위해 구분되는(diarized) 녹취록의 생성은 회의 서버에 의해 제공된다. 회의 서버에 의해 수행되는 기능은 동기화, 인식, 융합, 및 구분(diarization) 기능들을 포함한다. 이러한 기능이 도 9에서 특정 순서로 도시되어 있지만, 상이한 실시예들에서, 기능들은 다양한 순서들로 수행될 수 있다. 예를 들어, 융합은 인식 이전에 수행 될 수 있으며, 또한 후술되는 바와 같이 다양한 다른 지점들(points)에서 수행될 수 있다. 도 10은 일반적으로 분산 디바이스로부터의 오디오 스트림을 포함하는, 방법에서의 정보의 회의 서버 프 로세싱을 예시하는 상세한 블록 흐름도이다. 다수의 오디오 데이터 스트림은 다수의 분산 디바이스로부터 수신된다. 스트림은 데이터 패킷의 M개의 독립적인 시퀀스를 포함한다. m번째 시퀀스의 각 패킷은 m번째 디바이 스에 의해 캡처된 디지털화된 오디오 신호의 세그먼트를 포함한다. 수신된 패킷이 언팩(unpack)되고 패킷으로부 터 데이터가 재형성되어 다중 채널 신호를 생성한다. 다중 채널 신호는 {[x0(t), ..., XM-1(t)]; t=0, 1, ...}와 같이 나타낼 수 있다. 다중 채널 신호에서 상이한 채널들의 디지털화된 신호는 동기화되지 않을 가능성이 높은데, 그 이유는 많은 분 산 디바이스가 디지털 신호 프로세싱 차이, 디바이스 내 소프트웨어 지연 차이, 및 신호 송신 속도 차이의 영향 을 받기 때문이다. 이러한 모든 차이점이 합산되어, 상이한 디바이스로부터의 정보를 통합하여 정확한 녹취록을 생성하기 어렵게 만들 수 있다. 스트림 동기화 모듈은 다중 채널 신호를 수신하고 채널들 중 하나를 기준 채널로서 선택한다. 일반성을 잃지 않고, 첫 번째 채널이 기준 채널로서 사용될 수 있다. 기준 채널의 경우, 출 력은 입력과 동일한다(즉, y0(t) = x0(t)). m번째 채널(0 < m < M)의 경우, xm(t)와 x0(t) 사이의 오정렬 분량이 추정되고 수정되어 ym(t)를 생성한다. 비기준(non reference) 채널 신호에 대해 슬라이딩 윈도우를 사용하여 두 신호 사이의 정규화된 상호 상관 계수 를 계산하고 최대 계수 값을 제공하는 지연을 선택하여 오정렬의 정도가 추정될 수 있다. 이것은 기준 채널과 다른 채널들 각각 사이에서 상호 상관 분석이 개별적으로 수행되는 음향 신호 세그먼트를 임시로 저장하는 버퍼 를 사용하여 구현될 수 있다. 정규화된 상호 상관 대신 두 신호 간의 정렬 정도를 측정하는 임의의 스코어 함수가 사용될 수 있다. 일 실시예에서, 인접한 동기화 주기들 간의 관계가 고려된다. 오정렬은 디바이스/채널 종속 오프셋과 디바이스 종속 클록 드리프트의 두 가지 요인으로 인해 야기된다. 두 디바이스가 동시에 음향 이벤트를 캡처하는 경우에 도, 개별 디바이스에 의해 캡처된 신호는 디지털 신호 프로세싱 차이, 디바이스 내 소프트웨어 지연 차이, 신호 송신 속도 차이 등으로 인해 상이한 시간들에 회의 서버에 도착할 수 있다. 이것은 디바이스/채널 종속 오프셋 이다. 또한, 제조 변동성으로 인해 상이한 디바이스들은 불가피하게 약간 상이한 클록들을 가진다. 따라서 두 디바이스가 예를 들어, 16kHz 샘플링 속도를 지원한다고 주장하더라도, 이러한 디바이스들에 의해 기록된 신호 들은 100% 정렬되지는 않고 시간이 지남에 따라 불일치 양이 선형적으로 증가한다. 이것은 디바이스 종속 클록 드리프트이다. 디바이스/채널 종속 오프셋 및 디바이스 종속 클록 드리프트는 S 및 D로서 표시된다. k번째 동기 화 주기의 시간차는 S + kD로 표시된다. 따라서 S 및 D의 추정치는 오정렬 정도 S + kD에 대한 강력한 추정치를 제공한다. 오정렬의 양은 상술된 교차 상관을 이용하여 오정렬을 주기적으로 검출하고 이러한 검출된 오정렬을 정정함으로 써 정정될 수 있다. 또한 측정된 오정렬의 양을 줄이기 위해, 전역 오프셋(global offset)(디바이스/채널 종속) 및 디바이스 종속 클록 드리프트를 계산하여 오정렬 정도를 추정한다. 전역 오프셋은 교차 상관에 의해 오정렬 을 측정하고 정정하기 전에 전역 오정렬을 정정하는 데 사용될 수 있다. 전역 오프셋은 시간에 따라 측정된 오 정렬의 평균으로 결정될 수 있으며 이 디바이스의 클록 드리프트의 결과일 가능성이 높다. 따라서 오정렬의 정 도는 일 실시예에 따라 기준 채널과의 차이를 단순히 설명함으로써 추정되고 정정된다. 스트림 동기화는 예를 들어, 30초마다와 같이 다양한 간격으로 수행될 수 있다. 네트워크 대기 시간이 변경될 수 있으므로 30초보다 작거나 큰 다른 간격이 추가 실시예에서 사용될 수 있다. 스트림 동기화 모듈은 빔형성 모듈에 다중 채널 동기화된 신호 {[y0(t), ..., yM-1(t)]; t=0, 1, ...}을 제공한다. 빔형성 모듈은 중복된 음성을 분리하는 기능을 한다. 중복 음성은 회의에서 두 사람이 동시에 말할 때 발생한다. 음성을 인식하고 음성을 텍스트로 변환하기 전에, 먼저 음성이 별도의 채널들로 분리 된다. 따라서 M-채널 입력의 경우, 출력은 N-채널이며 N-채널 빔형성된 신호 {[z0(t), ..., ZN-1(t)]; t=0, 1, ... }라고 한다. 스트림 동기화 모듈은 입력 정보의 다양성을 유지하기 위해 다수의 출력이 생성되는 제1 융합 지점의 역할을 한다. 음성이 중첩되지 않는 경우, 이러한 융합은 선택 사항이다. 도 11은 지능형 회의 동안 다수의 분산 디바이스로부터 수신된 다수의 오디오 채널을 동기화하는 컴퓨터 구현 방법을 나타내는 흐름도이다. 동작에서, 스트리밍된 음성을 나타내는 오디오 신호는 다수의 분산 디바이스로부터 수신되어 다수의 오디오 채널을 생성한다. 오디오 채널들 중 하나의 선택된 채널은 동작 에서 기준 채널로서 지정된다. 기준 채널이 지정되면, 나머지 오디오 채널 각각에 대해 다음과 같은 동작이 수행된다. 동작에서, 기준 채널과의 시간의 차이가 결정된다. 나머지 오디오 채널 각각의 시간은 동작에서 대응 시간차의 함수로 나 머지 오디오 채널을 기준 채널과 정렬시켜 정정된다. 이것은 단순히 관련 없는(extraneous) 샘플을 삭제(drop) 하거나, 0을 뒤에 추가하거나, 리샘플링 기술을 사용하여 수행될 수 있다. 방법은 예를 들어, 30초마다와 같이 나머지 오디오 채널의 타이밍을 정정하기 위해 주기적으로 수행될 수 있다. 일 실시예에서, 방법은 적어도 분산 디바이스들에서 상이한 클록들에 의해 야기된 전역 오프셋을 정정하기 위한 추가 동작들을 포함한다. 동작에서, 나머지 오디오 채널들 각각에 대해 전역 오프셋이 결 정된다. 그런 다음, 나머지 오디오 채널은 결정된 시간 차이에 대해 각각의 나머지 오디오 채널을 정정하기 전 에 각각의 대응하는 나머지 오디오 채널 전역 오프셋에 의해 동작에서 정정된다. 음향 빔형성 또는 간단히 빔형성은 예를 들어, 다중 채널 오디오 신호에서 배경 잡음과 같은 원치 않는 사운드 를 줄여 대상(target) 음성을 향상시키는 기술이다. 빔형성은 예를 들어, 음성 인식 및 화자 구분(speaker diarization)과 같은 다운스트림 음성 프로세싱의 정확도를 향상시킬 수 있다. 서로에 대한 정확한 위치가 알려지지 않은 다수의 분산 디바이스로부터 스트리밍된 오디오와의 지능적인 회의의 경우, 예를 들어, 지연 및 합(delay-and-sum) 빔형성, 초지향성 빔형성, 및 차동 빔형성과 같은 기존의 빔형성 알고리즘은 작동하지 않다. 이러한 알고리즘은 분산 디바이스에서 사용할 수 없는 마이크 디바이스 배열에 대한 사전 지식에 의존한다. 일 실시예에서, 지오매트리 애그노스틱 빔형성(geometry-agnostic beamforming) 또는 블라인드 빔형성(blind beamforming)이라고 하는 접근 방식이 분산 녹음 디바이스에 대해 빔형성을 수행하는 데 사용된다. M개의 오디 오 채널에 대응하는 M개의 마이크 디바이스가 주어지면, 음성 및 배경 잡음의 M차원 공간 공분산 행렬이 직접 추정된다. 행렬은 각각 음성 및 잡음의 공간적 통계를 캡처한다. 음향 빔을 형성하기 위해, M차원 공간 공분산 행렬이 반전된다. 기존의 지오메트리 기반 빔형성이든 블라인드 빔형성이든 빔형성 접근 방식의 단점은, 일반적으로 정보 스트림 의 수를 M에서 하나로 줄인다는 것인데, 이는 다운스트림 모듈이 공간적으로 분산된 디바이스에 의해 제공되는 음향 다양성을 활용할 수 없음을 의미한다. M개의 빔형성된 신호를 생성하고 음향 다양성을 유지하기 위해, 리 브-원-아웃(leave-one-out) 접근 방식을 취할 수 있다. 이 접근 방식을 사용하면, 마이크 2-M으로 빔형성을 수 행하여 첫 번째 출력 신호가 생성된다. 두 번째 출력 신호는 마이크 1-M 및 3-M으로 생성된다. 이것은 M번 반복 되어 M개의 상이한 출력 신호가 얻어질 수 있다. 각 빔형성에 대해, (M-1)차원 공간적 공분산 행렬이 계산되고 반전되는데, 이는 계산이 매우 까다롭다. 다행히도, 원래 M차원 역행렬로부터 모든 (M-1) 차원 역행렬을 유도함 으로써 계산 비용이 크게 감소될 수 있다. 일부 실시예에서, 빔형성 모듈은 상이한 사용자들의 중첩된 음성 신호를 분리하도록 구성될 수 있다. 이 렇게 하면 음성 인식 및 화자 귀속(attribution)이 더 정확해질 수 있다. 일 실시예에서, 분산형 마이크 녹음 시스템에 대한 연속 음성 분리는 순열 불변 트레이닝 또는 예를 들어, 딥 클러스터링(deep clustering) 또는 어 트랙터 네트워크(attractor network)와 같은 그 변형을 사용하여 트레이닝되는 신경망을 통해 수행된다. 잠재적 으로 계산을 절약하기 위해, 중첩 검출을 사용하여 각 기간 동안 음성 분리 신경망이 실행되어야 하는지 여부를 결정할 수 있다. 선택된 기간 동안 중첩되는 음성이 검출되지 않으면, 신경망이 실행되지 않아, 프로세싱 자원 을 절약하고 실시간으로 더 빠르게 녹취록이 생성되게 할 수 있다. 음성 분리 신경망 모델은 입력 마이크의 수가 임의적이고 시간에 따라 변할 수 있는 분산형 마이크 녹음 시스템 에 대해 연속 음성 분리를 수행하기 위해 실행된다. 이 모델은 두 개의 연속적인 음성 스트림을 출력한다. 활성 화자가 한 명 있으면, 출력 스트림들 중 하나는 무음(silent)인 반면, 두 화자 사이에 중첩된 음성이 있으면, 각 화자는 별개의 출력 스트림을 차지할 것이다."}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예시적인 실시예에서, 음성 분리 신경망 모델은 3개의 서브모듈, 즉, 로컬 관찰자, 전역 요약자, 및 마스크 재 구성기(mask reconstructor)를 포함한다. 다중 채널 입력은 이 3개의 서브모듈에 의해 순차적으로 프로세싱된다. 첫째, 동일한 로컬 관찰자가 각 입력 마이크에 적용된다. 로컬 관찰자는 각 마이크 입력을 고차 원 표현으로 매핑하는 적층형 어텐션 계층들(stacked attention layers)의 세트를 포함하며, 여기서 각 채널은 모든 다른 채널로부터의 정보를 교차 비교하고 이를 추출한다. 자기 어텐션(self attention)과 피드포워드 어텐 션(feedforward attention)인 두 가지 유형의 어텐션이 구현된다."}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다음으로, 전역 요약기가 적용되어 각 관찰자의 정보를 요약하여 다른 입력 채널에 걸쳐 전역 표현을 형성한다."}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전역 요약기에 대한 두 가지 옵션 - 평균 풀링 및 순열 불변 정렬 알고리즘 - 이 고려되며, 여기서 각 채널의"}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "표현은 자신들의 로컬 순열 및 전역 순열을 정렬시키기 위해 순열 불변 손실과 비교된다. 요약 계층이 없는 경 우 네트워크는 채널별 음성 분리 네트워크로 축소되며, 여기서 각 채널은 자신의 고유한 분리를 갖다(즉, 채널 들 간에 전역 분리 동의(global separation agreement)가 없음). 마지막으로, 마스크 재구성기는 임의의 시간에 대해 동시에 두 개의 마스크 출력을 정렬시킨다. 마스크 재구성"}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "기는 장단기 기억 네트워크의 스택을 포함하고 각 시점에서 요약으로부터 최종 2개 채널 출력을 생성한다. 마스크 재구성기로부터 2채널 출력을 얻은 후, 재구성된 마스크와 깨끗한 기준(clean reference) 사이에 순열 불변 트레이닝 목적 함수가 적용되며, 여기서 각 순열 쌍의 출력과 깨끗한 기준의 유클리드 거리가 먼저 측정된 다음, 최소 거리와 대응 순열이 선택되어 신경망을 갱신한다. 네트워크는 시뮬레이션된 다중 채널 데이터로 트레이닝되며, 입력 채널의 수는 각 샘플에 대해 무작위로 선택된 다(예컨대, 2개 내지 10개의 채널). 리브리 음성 데이터 세트(Libri speech dataset)는 시뮬레이션에서 소스 데 이터로서 적용된다. 각 시뮬레이션된 문장에서, 두 명의 무작위 사용자/화자로부터 두 개의 발화(utterances)가 먼저 선택된다. 그런 다음 각 발화는 임의의 방 및 위치 설정을 갖는 이미지 방법으로부터 실내 임펄스 응답 (room impulse responses)을 사용하여 실내 음향 시뮬레이션으로 프로세싱된다. 음성 분리의 한 변형은 단지 녹음된 음성에서 중첩 영역을 검출하기 위해 작업이 축소되는 음성 중첩 검출이다. 알고리즘은 네트워크가 N개의 채널을 입력으로 수신하고 두 개의 채널을 출력으로 연속적으로 출력하는 유사한 방식으로 동작한다. 중첩 검출기에서, 네트워크는 마스크를 출력하지 않는다. 대신, 네트워크는 2개의 1차원 표시기 기능을 출력하며, 여기서 1은 해당 채널에 한 명의 활성 화자가 있음을 의미하고 0은 침묵을 의미한다. 따 라서 두 명의 활성 화자가 있는 경우, 두 개의 출력 스트림은 각각 1을 출력으로서 가질 것이다. 하나의 활성 화자가 있는 경우, 하나의 임의의 채널은 출력으로 1을 갖고 다른 채널은 0을 가질 것이다. 네트워크는 또한 네 트워크의 출력(즉, 표시기 기능)과 참조 표시기 사이에서 순열 불변 트레이닝 목표로 트레이닝된다. 도 12는 분산 디바이스 지능형 회의에서 중첩된 음성을 분리하는 컴퓨터 구현 방법을 나타내는 흐름도이다. 동 작에서, 음성을 나타내는 오디오 신호는 대응하는 다수의 분산 디바이스로부터 송신된 스트리밍 오디오에 대응하는 다수의 오디오 채널을 통해 수신된다. 동작에서 수신된 오디오 신호에 대해 연속적인 음성 분리가 수행되어 동시에 말하는 상이한 화자들로부터 의 음성을 별도의 오디오 채널로 분리한다. 일 실시예에서, 동작에서의 음성 분리는 트레이닝된 신경망 모델에 의해 수행된다. 신경망 모델은 순열 불변 트레이닝 또는 그 변형을 사용하여 트레이닝된다. 동작에서, 음성 인식 및 녹취록 생성을 위해 분리된 오디오 채널이 제공된다. 일 실시예에서, 동작(123 0)은 고정된 수의 개별 출력 채널을 제공한다. 마이크 입력의 수가 다양할 수 있고 출력의 수는 미리 고정되어 있기 때문에, 수용될 수 있는 오디오 채널 수가 제한된 경우가 있을 수 있으며, 이는 다수의 중첩된 화자가 있 는 각 오디오 채널에 대해 각 화자가 별도의 오디오 채널을 생성하기 때문이다. 따라서 출력 오디오 채널의 수 가 제한되면, 모든 채널이 분리된 화자를 갖지는 않을 수 있다. 도 10의 빔형성 모듈의 N개의 상이한 출력들은 일련의 세논 사후 확률(senone posterior probabilitie s)을 생성하는 N개의 음향 모델(1025 및 1030)에 제공된다. 이러한 모델은 잘 알려져 있으며 일반적으로 신경망 기반이다. 분산 디바이스 및/또는 빔형성기 출력으로부터의 다수의 오디오 채널 각각에 대해 음향 모델을 사용 하면 각 세논에 대해 N개의 스코어를 제공한다. 세논에 대한 스코어를 포함하는 스코어는 음향 모델 스코어 융합 모듈에 제공된다. 개별 입력 채널의 오 디오는 통상적으로 일련의 세논 및 이들의 사후 확률을 제공하도록 프로세싱될 수 있다. 결과는 다수의 음성 인 식(speech recognition; SR) 디코더(1040, 1045)에 결과를 적용하기 전에 모델 스코어 융합 모듈을 사용 하여 결합된다. 스코어 융합 모듈은 다수의 정보 소스를 결합하는 제2 융합 포인트로서 동작하고, 동시에 입력 정보의 다양성을 유지하기 위해 다수의 출력을 생성한다. 2-단계 프로세스에는 2개의 다른 신경망(또는 분 류기), 즉, 바닐라 맛 음향 모델(vanilla-flavor acoustic model)과 새롭고 더 표적화된(targeted) 음향 모델 을 수반한다. 출력은 1x 세논 수의 시퀀스이다. 스코어 융합 모듈은 음향 모델(신경망)의 마지막 계층의 출력을 입력으로 사용한다는 점에 유의한다. 추가 실시예에서, 스코어 융합 모듈은 마지막 계층 이전의 임의의 계층의 출력을 사용할 수 있다. 입력의 크기는 출력의 크기와 다를 수 있다. 음향 모델 스코어 융합 모듈로부터의 세논의 시퀀스는 SR 디코더(1040 및 1045)에 제공되며, SR 디코더 (1040 및 1045) 각각은 표준 음성 인식 프로세싱을 활용하여 세논의 각 세그먼트에 대해 단어들의 n-최상 목록 (n-best list)을 제공한다. 각 단어에 대해 시작 시간과 지속 시간이 제공된다. 음성 활동 검출, 화자 변경 검 출, 고정 간격, 또는 일부 다른 적절한 방법에 기초하여 세그먼트화가 수행될 수 있다. 리스코어링(rescoring) 은 단어 가설의 더 나은 n-최상 목록을 생성하기 위해 디코더 출력에 대한 신경망 언어 모델(neural network language model; NNLM)을 사용하여 수행될 수 있다. 다수의 화자 구분 모듈(1050, 1055)은 SR 디코더 모듈(1040, 1045)의 출력을 각 세그먼트에 대한 N-최상 목록으 로서 수신한다. 일 구현에서, 최상위 단어 시퀀스 가설(top word sequence hypothesis)만이 사용된다. 제1 동작 은 고정된 간격으로 예를 들어, d-벡터(화자 검증을 위한 심층 신경망의 은닉층(hidden layer) 활성화)와 같은 화자 임베딩(speaker embeddings)을 추출한다. 제2 동작은 단어 시퀀스를 화자 동종 서브세그먼트로 분해 (factorize)한다. 이것은 임베딩 기능을 사용하여 응집 클러스터링(agglomerative clustering), 베이지안 정보 기준(Bayesian Information Criterion; BIC), 또는 다른 방법의 변형으로 수행될 수 있다. 제3 동작은 서브세그먼트의 화자 임 베딩들의 근접도(예컨대, 코사인 유사도, 음의 유클리드 거리)와 각 후보 화자의 근접도를 비교하여 위에서 얻 어진 각 서브세그먼트에 화자 식별자를 할당한다. 결과 출력은 상위 SR 가설의 각각의 인식된 단어에 화자 라벨 을 할당한 것이다. 가설 결합 모듈은 입력으로서 N개의 SR 디코더 모듈(1040, 1045)(예컨대, 빔형성된 오디오 채널)로부터의 n-최상의 리스트, 및 예를 들어, 빔형성된/분리된 오디오 채널과 같은 N개의 소스로부터의 화자 인식 출력을 수 신한다. 가설 결합 모듈은 각 채널로부터의 n-최상 스코어를 스케일링 및 정규화함으로써 이들을 프로세싱하고 이에 따라 발화 수준 사후 확률을 계산한다. n-최상 가설은 단어 혼동 네트워크(word confusion networks)에 정렬된다. 주어진 단어 가설에 대해 발화 수준 사후 확률을 추가하여 단어 수준 사후 확률이 얻어 진다. 각 채널로부터의 화자 인식 출력은 화자와 단어 라벨이 교대로 있는 혼동 네트워크로서 포맷된다 (formatted). 단어 라벨은 1-최상 인식 가설에서 유래하는 반면, 화자 라벨은 음성 세그먼트와 매칭되는 1-최상 또는 n-최상 화자 모델을 나타낸다. 화자 가설에 대한 사후 확률은 정규화된 화자 모델 가능성을 나타낸다. 단 어 가설의 사후 확률(posteriors)은 최종 단어 인식에 영향을 미치지 않도록 대략 100배 단위(two orders of magnitude)로 축소되어 단어 라벨과 화자 라벨의 적절한 정렬에만 영향을 준다. 따라서 각 채널로부터 얻어진 혼동 네트워크(confusion networks)는 온라인 프로세싱 제약 조건에 따라, 동일한 시간 윈도우를 커버하기 위해 필요에 따라 절단(truncate) 및/또는 접속(concatenate)된다. 출력은 단어 및 화자 가설과 자신의 사후 확률을 모두 인코딩하는 혼동 네트워크(CN)를 포함한다. 단어 및 화자 혼동 네트워크는 정렬된 노드들 간의 시간 불일치에 대한 패널티뿐만 아니라 최소 편집 거리 기준 에 따라 정렬된다. 이것은 화자와 단어 가설을 단일 네트워크로 효과적으로 병합하여, 매칭되는 라벨들의 사후 확률들을 합산한다. 원하는 경우, 각 위치에서 최고 사후 확률 라벨을 선택함으로써 결합된 CN에서 최고 화자와 단어 가설이 판독된다. 단어 혼동 네트워크는 음성 디코더가 출력하는 내용에 따라 n-최상 목록 대신 단어 격자 로부터 구축될 수 있다. 결합 모듈의 출력은 회의의 화자-귀속 녹취록의 생성을 위한 텍스트 및 화자 식별을 생성하기 위해 후기 융합(late fusion)이라고 하는 제3 융합의 결과이다. 빔형성 모듈 및 음향 모델 스코어 융합 모듈 각각에서 처음 2개의 융합 단계는 다양한 실시예에서 선택적이라는 점에 유의한다. 일부 실시예에서, 빔형성 또 는 음성 분리 없이 하나 이상의 오디오 채널이 음향 모델 스코어링 모듈에 직접 제공될 수 있다. 그 다음, 음성 인식은 SR 디코더를 통해 하나 이상의 오디오 채널에 대해 수행되고, 이어서 화자 구분 모듈 이 수행되며, 출력은 결합 모듈에 직접 제공된다. 오디오 스트림은 지오매트리 애그노스틱 빔형성 또는 연속적 음성 분리에 의해 디지털 오디오 스트림의 동기화 후 조기에 융합될 수 있다. 입력 정보 다양성을 유지하기 위해 다수의 출력이 생성될 수 있다. 후기 융합은 화 자 정보 및 다양한 모델 가설을 활용하기(leverage) 위해 음향 모델 스코어 수준 및/또는 텍스트 수준/구분 수 준에서 수행될 수 있다. 일 실시예에서, 하나의 단어 또는 두 단어에 대한 후기 융합은 고정된 시간 윈도우를 사용하여 수행된다. 일 실시예에서, 시간 윈도우는 현저한 오디오 이벤트에 대응하고, 예를 들어, 2초로 고정될 수 있다. 이러한 시간 윈도우는 대기 시간이 짧은 실시간(또는 실시간에 가까운) 녹취록을 제공할 수 있도록 상 당히 짧게 선택된다. 일 실시예에서, 실시간 녹취록은 짧은 단어 시퀀스에 기초하여 생성된다. 데이터의 후기 융합은 구문을 생성하 기 위해 병렬로 프로세싱되고 있는, 다수의 오디오 채널에 대한 음성 인식에 의해 수행된다. 다수의 오디오 채 널로부터 유도된 구문이 실시간으로 결합된다. 일 실시예에서, 대략 2초의 음성이 가설 결합 모듈에서 결 합된다. 따라서, 오디오 스트림은 수신되는 대로 프로세싱된다. 2초의 비중첩 슬라이딩 윈도우가 오디오 스트림 을 프로세싱하는 데 사용되어, 회의 시스템 녹취록 생성의 대기 시간을 0에 가깝게 줄인다. 개별 음성 인식 디코더는 일부 결과를 계속해서 출력하고, 가설 결합 모듈에 기초하여 결과가 즉시 프로 세싱된다. 스트림 동기화 모듈에서 개별 시스템들의 정렬을 위한 특별한 조항(special provision)이 제공 되며, 그렇지 않으면 최종 결과는 (오정렬로 인한) 동일한 이벤트의 다수의 인스턴스를 포함할 수 있다. 후처리 단계는 신호 및/또는 음성 인식 출력 정렬에 관계없이 존재할 수 있는 임의의 중복을 제거한다. 정렬은 단어 수 준 또는 신호의 샘플 수준에서 수행될 수 있다. 또한, 음성 인식 디코더에 의해 상이한 버전들의 오디오가 수신 된다는 점에 유의한다. 각 SR 디코더는 다른 소리를 들을 수 있다. SR 결과(후기 융합)와 짧은 대기 시간을 결 합하여 매우 정확한 녹취록이 생성된다. 모든 SR은 신뢰 수준으로 한두 단어를 출력한다. 예를 들어, 2초와 같 은 시간은 몇 가지 현저한 출력을 얻을 수 있을 만큼 충분히 긴데, 즉, 어느 정도 신뢰를 가지고 인식될 수 있 는 한두 개의 단어를 가진 출력이다. 예를 들어, 2초와 같은 고정된 시간 윈도우가 더 잘 작동하는 것으로 나타 났다. 시간이 너무 짧으면, 현저한 이벤트가 없고, 시간이 너무 길면 대기 시간이 길어지고 녹취록이 지연되어 회의 중 녹취록의 활용도가 떨어진다. 이 접근 방식의 또 다른 버전은 모든 스트림이 높은 신뢰도로 음성을 포함하지 않거나 높은 신뢰도로 단일 단어 가설을 갖는, 오디오 스트림의 시점을 기다리는 것이다. 그런 곳에서, 가설 공간은 단일 가설로 좁혀 질(pinched) 수 있으며, 이는 부정확한 단어 세그먼트화의 결과로 인한 정확도의 손실 없이 결합을 수행할 수 있게 한다.녹취록은 1080에 표시된 출력에 기초해 한 명 이상의 회의 참가자에게 제공된다. 회의 시스템의 출력에 기초해 단일 회의 녹취록이 제공된다. 녹취록은 개별 발화와 예를 들어, 슬라이드나 그림의 사진과 같은 연관된 매체로 구성된다. 각 발화에는 범용 타임스탬프, 귀속된 화자, 연관된 텍스트, 및/또는 연관된 오디오 세그먼트가 할당 되며, 여기에서 오디오는 모든 참여하는 클라이언트의 동기화된 입력 스트림으로부터 추출된다. 예를 들어, 이미지, 메모, 및 다른 추상 객체(abstract objects)와 같은 추가 미디어 또는 콘텐츠는 타임스탬프 를 통해 녹취록과 인라인(inline)으로 연관되거나(예컨대, 화이트보드의 사진이 시간 t에 캡처되고 업로드됨), 특정 타임스탬프 없이 전체 회의에 연관될 수 있다(예컨대, 회의 후에 파일이 업로드되고 이 회의 인스턴스와 연관됨). 모든 참석자는 회의 및 연관된 데이터로의 액세스를 가질 수 있다. 애드혹 회의는 회의를 생성한 엔티 티에 의해 설정된 권한에 따라 회의 소유자, 모든 참석자, 또는 모든 사람에 의해 보여지고 수정될 수 있다. 예"}
{"patent_id": "10-2021-7034789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "를 들어, 회의 요약, 동작 항목 식별, 및 주제 모델링과 같은 추가 서비스는 녹취록 및 다른 연관된 회의 데이 터를 사용하여 제공될 수 있다. 도 13은 프로세싱 동안 다수의 선택된 지점에서 오디오 스트림을 융합하는 컴퓨터 구현 방법을 예시하는 흐름도이다. 오디오 스트림은 회의 중에 복수의 분산 디바이스에 의해 녹음된다. 방법은 동작을 수행하는 하나 이상의 프로세서에 의해 수행된다. 동작은 하나 이상의 프로세서에서 실행되는 대응하는 음성 인식 시스템에 의해 각 오디오 스트림에 대한 음성 인식을 수행하여, 각각의 오디오 스트림에 대한 가설로서 발화 수 준의 사후 확률을 생성한다. 동작에서 가설들은 연관된 단어 수준 사후 확률을 갖는 단어 혼동 네트워크 로서 정렬되고 포맷된다. 동작은 화자 귀속 단어 가설의 스트림을 생성하는 화자 식별 알고리즘을 실행하 여 각 오디오 스트림에 대해 화자 인식을 수행한다. 화자 가설은 동작에서 혼동 네트워크로서 각 오디오 스트림에 대해 연관된 사후 화자 라벨 사후 확률 및 화자 귀속 가설로 포맷된다. 동작은 사후 확률을 병 합하고 단어와 화자 라벨을 정렬시키기 위해 모든 오디오 스트림으로부터의 단어 및 화자 혼동 네트워크들을 서 로 정렬시킨다. 가장 높은 사후 확률을 갖는 단어 및 화자 라벨의 시퀀스를 판독함으로써 동작에서 최상 의 화자 귀속 단어 녹취록이 생성된다. 일 실시예에서, 가능하게는 사후 확률 없이도 각 스트림으로부터 단일 단어 가설만이 생성되고 모든 스트림 중 에서 간단한 투표(voting)가 사용되는 경우 특별한 근사 버전이 획득된다. 방법의 동작들은 오디오 스트림에 적용된 연속적인 시간 윈도우에 대해 수행되어 실시간으로 화자 귀속 단어 인식 가설을 생성할 수 있도록 프로세싱이 점진적으로 수행될 수 있다. 입력 가설은 각 오디오 스트림에 대해 생성된 단어 가설과 연관된 시간 표시(time marks)에 기초해 모든 오디오 스트림에 적용되는 공통 시간 윈 도우로 시간상 잘린다(truncated). 입력 화자 및/또는 단어 가설 스트림은 K < N인 N개의 오디오 스트림들 중 K개의 융합을 통해 입력 오디오 스트 림의 다수의 부분적 결합에서 유래할 수 있다. 대안적으로, 입력 화자 및/또는 단어 가설 스트림은 상이한 오디 오 스트림들로부터 아니라 N개의 오디오 스트림들 중 K개에 적용된 음향 모델의 다수의 부분적 결합으로부터 유 래하며, 이 오디오 스트림들은 차례로(in turn) 원시 오디오 신호 또는 오디오 신호의 융합에서 발생할 수 있다. 또 다른 실시예에서, 입력 가설은 각 오디오 스트림에 대해 생성된 단어 가설과 연관된 시간 표시에 기초하여 모든 오디오 스트림에 적용되는 공통 시간 윈도우에 대해 시간상 잘린다. N개의 원시 오디오 신호들 중 K개의 결합 또는 오디오 신호들의 융합은 오디오 품질 기준에 기초해 그리고/또는 분산 디바이스에 대한 화자의 상대 적 위치에 기초할 수 있다. 일 실시예에서, 입력 화자 및/또는 단어 가설 스트림은 K < N인 N개의 오디오 스트림들 중 K개의 오디오 스트림 들의 융합을 통해 입력 오디오 스트림의 다수의 부분적 결합으로부터 유래한다. N개의 음향 모델 출력들 중 K개 의 결합은 입력 신호의 오디오 품질 기준 및/또는 분산 디바이스에 대한 화자의 상대적 위치에 기초할 수 있다. 대안적으로, 입력 화자 및/또는 단어 가설 스트림은 K < N인 N개의 오디오 스트림들 중 K개에 적용된 음향 모델 의 다수의 부분적 결합에서 유래할 수 있으며, 이 오디오 스트림들은 차례로 원시 오디오 스트림 또는 오디오 스트림의 융합에서 비롯된다. 또 다른 실시예에서, 다수의 음향 모델의 출력은 K < N인 N개의 오디오 스트림들 중 K개에 적용될 수 있으며, 이 오디오 스트림들은 차례로 원시 오디오 스트림 또는 M개의 음성 인식 디코더에 대한 입력으로서 결합되는 오디오 스트림의 융합으로부터 발생한다. 도 14a 및 14b는 예시적인 주변 캡처 디바이스를 도시한다. 일 실시예에서, 주변 캡처 디바이스는 이 디바이스의 상단에 있고 디바이스에 대해 위로 향하는 어안 카메라(fisheye camera, 1411)를 갖는 원통형이다. 마이크 어레이는 카메라 아래에서 이 디바이스에 결합되고 360°에서 오디오 를 캡처하기 위해 실린더 주위에 배치된다. 도 14a의 디바이스는 축척에 맞게 그려지지 않을 수 있다는 점에 유 의해야 한다. 최적의 360° 비전(예컨대, 비디오 또는 정지 이미지)을 캡처하기 위해, 어안 카메라가 바닥 또는 테이블 표면에 가까이 있는 것이 바람직할 수 있다. 실시예에서, 이 디바이스는 카메라 아래의 사 각지대를 피하기 위해 짧고 쪼그리고 있을(squat) 수 있다. 실시예에서, 어안 카메라는 마이크 어레이에 매우 근접하게 배치될 수 있다. 캡처 디바이스는 분산 디바이스 회의에서 오디오 및 비디오를 캡처할 때 분산 디바이스와 함께 사용될 수 있다. 디바이스 자체가 분산 디바이스들 중 하나일 수 있다. 음성과 연관된 사용자의 식별은 일 실시예에 서 캡처 디바이스에 의해 단독으로 수행될 수 있거나, 캡처 디바이스로부터 수집된 정보 스트림은 다양한 실시예에서 화자 귀속 녹취록을 생성하기 위해 다른 분산 디바이스로부터 수집된 정보 스트림과 함께 사 용될 수 있다. 도 14b에 도시된 예에서, 7개의 마이크(1423A 내지 1423A)가 마이크 어레이에 포함된다. 도시된 바와 같 이, 6개의 마이크(1423A 내지 1423F)는 평면에서 디바이스 주위에 그리고 디바이스의 중심으로부터 다소간 등거 리에 배치되고, 제7 마이크(1423G)는 중앙에 배치된다. 이 디바이스는 예를 들어, 가벼운 천, 그릴(grille) 또 는 메쉬와 같은 오디오 투과성 재료로 제조될 수 있으며, 마이크는 어안 카메라 또는 디바이스 의 다른 구조적 부분에 의해 차단되지 않으므로, 사운드가 차단되지 않는다는 것이 이해될 것이다. 일 실시예에서, 어안 카메라는 디바이스의 베이스로부터 대략 30cm일 수 있고, 마이크 어레이는 베 이스 위에 대략 15cm에 부착될 수 있다. 동작 중일 때, 디바이스는 환경에서 바닥 또는 테이블 위에 비치되거나 부착될 수 있다. 디바이스가 바닥에 더 가깝게 배치됨에 따라 360° 수평 시야 (horizontal field of view; HFOV)는 더 많은 환경을 포함할 수 있다. 어안 카메라는 일반적으로 위를 향하도록 디바이스에 부착되므로 천장이 시야에 있을 수 있다. 디바이스의 다른 형상, 크기 또는 구성 및 어안 카메라 및 마이크 어레이의 배치가 유사하고 다양한 결과를 제공하기 위한 일부 적응 으로 구현될 수 있음을 이해할 것이다. 일 실시예에서, 오디오 캡처를 위한 음향 파라미터는 마이크의 사양에 따라 변한다. 실시예에 대한 음향 사양의 예는 아래 표 1에 보여 진다. 실시예에서, 음향 파라미터는 마이크뿐만 아니라 전체 오디오 서브시스템(예컨대, 캡처된 펄스 코드 변조(pulse code modulation; PCM) 데이터)에 적용된다. 캡처된 오디오는 AI 애플리케이션에 서 사용하기에 적절한 음성 인식 정확도를 생성할 수 있다. 당업자는 본 개시의 이점과 함께 다양한 음향 파라 미터가 음성 인식 정확도를 달성하기 위해 활용될 수 있고 표 1의 예시적인 파라미터가 예시를 위한 것임을 이 해할 것이다. 표 1 감도 (1kHz 94dB SPL) -26 +-≤0.1 dB FS 전력 공급 및 디지털 필터 잡음을 포함한 신호-잡음비 (SNR)≥64 dB A 주파수 응답 50 -＞16kHz (+/-3 dB) 전체 고조파 왜곡 ≤1% (105 dB SPL) ≤5% (115 dB SPL) 지향성 무지향성(50->16kHz에 대해 ≤1 dB 감도 차이) 마이크들간 변화량 50->16kHz에 대해 ≤1 dB 감도 차이 수명 최대 SPL ≥ 160 dB, 최대 충격 ≥ 10,000g, 온도 범위 -40℃ 내지 +80℃에서 성능의 영구 손실이 없음 음향 파라미터의 예 도 15는 일 실시예에 따른 마이크 어레이의 예시적인 배치를 도시한다. 실시예에서, 이 디바이스는 동일 한 평면에 배치된 7개의 마이크를 포함한다. 6개의 마이크(1523A 내지 1523F)는 중심점에서 약 4.25cm 떨어진 평면에 원형 패턴 또는 육각형 패턴으로 배치된다. 제7 마이크(1523G)는 중앙에 배치된다. 실시예에서, 7개의 마이크의 구성은 유사한 사양의 마이크를 포함한다. 마이크들이 서로 다를 때 오디오를 정규화하거나 조정하기 위해 마이크 어레이로부터 수신된 오디오 데이터의 추가 프로세싱이 필요할 수 있음을 이해할 것이다. 예시적인구현에서, 마이크 어레이는 위쪽을 향하는 포트(ports)를 갖는 7개의 디지털 마이크로전자기계 시스템 (microelectromechanical system; MEMS) 마이크를 포함할 수 있다. 마이크가 예를 들어, 회로 기판이나 디바이 스 케이스와 같은 흡음 또는 차단 컴포넌트에 의해 방해받지 않을 때 더 나은 성능이 나타날 수 있음이 이해될 것이다. 일 실시예에서, 유사한 마이크는 디바이스(미도시)에서 동일한 클록 소스를 사용하여 클로킹된다(clocked). 오 디오의 클로킹 또는 타임스탬핑은 시청각 데이터의 동기화 및 융합을 지원할 수 있다. 주변 캡처 디바이스는 모든 마이크 신호를 16비트 16kHz PCM 데이터로 데시메이션할 수 있다. 이러한 맥락에서 데시메이션은 신호의 샘플링 속도를 줄이는 프로세스이다. 자동 음성 인식을 위해서는 8kHz보다 높은 주파수 대 역이 필요하지 않을 수 있다. 따라서 16kHz의 샘플링 속도가 적절할 수 있다. 데시메이션은 필요한 정확도를 손 상시키지 않으면서 비트 레이트를 줄인다. 실시예에서, 캡처 디바이스는 추가 비트 깊이 및 샘플링 주파수를 지 원할 수 있다. 실시예에서, 캡처 디바이스는 드라이버 복잡성을 줄이고 안정성을 개선하기 위해 데이터 폭 및 샘플링 주파수를 변경하는 것을 허용하지 않을 수 있다. 마이크는 진동과 소음을 줄이기 위해 예를 들어, 고무 개스킷과 같은 임의의 적절한 기계적 감쇠 메커니즘을 사용하여 장착될 수 있다. 마이크 어레이에 더 많거나 더 적은 마이크가 존재할 수 있다는 것이 이해될 것이다. 그러나 더 적은 수의 마이 크는 화자 위치의 어떤 불확실성을 유발할 수 있다. 추가 마이크는 오디오의 확실성 또는 해상도를 높일 수 있 지만 하드웨어 및 계산의 추가 복잡성을 희생한다. 일 실시예에서, 오디오 스피커는 사용자에 대한 오디오 피드백을 위해 디바이스의 바닥 또는 베이스에 위치한다. 오디오 스피커는 피드백 발표에 사용되거나 AI 애플리케이션의 필수 부분이 될 수 있다. 예를 들어, 회의 관리를 위한 AI 애플리케이션에서, 사용자는 회의록을 참석자에게 다시 읽어달라고 요청할 수 있다. 이 디 바이스의 통합 스피커는 피드백을 제공하거나 동작 지침 또는 명령을 요청한다. 음성 명령을 이해하지 못하는 경우 오디오 스피커를 통해 명령 반복 요청이 재생될 수 있다. 음향 피드백을 줄이기 위해 오디오 스피커가 마 이크 어레이와 반대 방향을 향할 수 있다. 오디오 스피커를 통해 재생되는 오디오는 추가적인 동기화된 마이크 채널로서 루프백(loop back)될 수 있다. 도 14b를 다시 참조하면, 일 실시예에서, 어안 카메라는 360° HFOV, 및 수평축 위로 적어도 95° 수직 시야(vertical field of view; VFOV), 그리고 수평축 아래로 95° VFOV를 수신하여, 190° VFOV, 또는 대략 200° 대각선 시야(diagonal field of view; DFOV)를 생성한다. 실제로, 캡처 디바이스는 바닥의 테이블 에 배치될 수 있으므로 표면 아래의 수직 뷰가 필요하지 않다. 따라서, 여기에서 논의할 때 VFOV는 디바이스의 수평 베이스 평면 위의 뷰를 나타내기 위해 대략 95°로서 식별된다. 일 실시예에서, 어안 카메라는 12 메가픽셀(megapixels; MP)의 (예컨대, 4K 해상도를 제공함) 하나의 어 안 센서를 포함한다. 카메라 렌즈는 광학 중심이 이미지 센서의 중심과 정렬되고 광축이 이미지 센서에 수직이 되도록 이미지 센서에 대해 장착될 수 있다. 마이크 어레이에 대한 카메라 렌즈의 상대적인 위치는 고정되고 알 려져 있을 수 있다. 특히, 광 중심은 마이크 어레이에 수직인 광축으로 마이크 어레이의 중심과 정렬될 수 있다. 도 16은 위에서 설명된 바와 같은 주변 캡처 디바이스 및 클라우드 서버로 지칭되는 회의 서버를 갖는 AI 시스템을 예시한다. 예에서, 사용자는 AI 애플리케이션과 상호작용한다. AI 애플리 케이션은 클라우드 서버 또는 로컬 디바이스(미도시)에 상주할 수 있음이 이해될 것이다. 시청각 데이터는 AI 캡처 디바이스에 의해 360°로 캡처될 수 있다. 위에서 논의된 바와 같이, 캡처 디바이스 는 360° HFOV 및 대략 95° VFOV를 제공하는 어안 카메라를 포함할 수 있다. 캡처 디바이스 는 또한 360°에서 오디오를 캡처하기 위한 마이크 어레이를 포함할 수 있다. 카메라에 의해 수신된 이미지 및 비디오 스트림의 비디오 압축은 이 디바이스 상의 프로세서에 의 해 수행될 수 있다. 비디오 모드, 압축 프로토콜 및 기준은 사용자가 선택할 수 있는 소프트웨어 컨트롤로 제어 될 수 있다. 압축 외에도 시청각 데이터는 암호화로 보호되어, 인가되지 않은 사람이 데이터를 얻지 못하도록 할 수 있다. 실시예에서, 압축은 이 디바이스의 회로에 의해 수행되고 소프트웨어 스위치에 의해 제어될 수 있다. 전처리(예컨대, 이미지 콘텐츠에 기초한 이미지의 크로핑(cropping), 또는 잡음 감소)는 압축 전에 프로세서에 의해 실행되는 로직에 의해 수행될 수 있다. 실시예에서, 전처리는 디바이스에 결합된 스피커(161 2)에 의해 야기되는 피드백, 잡음, 및 에코를 줄이기 위한 음향 에코 제거(acoustic echo cancellation; AEC)를 포함할 수 있다. 실시예에서, 키워드 스포팅(keyword spotting; KWS)을 위한 로컬 프로세스는 주변 캡처 디바이스에 대한 디바이 스 명령을 청취하기 위해, 예를 들어, 디바이스를 깨우거나 끄기 위해 포함될 수 있다. 로컬 KWS는 정밀도에 비 해 리콜을(recall versus precision) 선호할 수 있으며 감소된 마이크 어레이(예컨대, 전체 어레이가 아닌 2개 의 마이크)에 기초할 수 있다. 디바이스에서 AEC가 수행될 때, 화자 오디오를 포함하는 음향 채널은 센서 융합을 수행하기 위해 모델로 송신될 필요가 없을 수 있다. 압축된 시청각 데이터는 송신 유닛에 의해 클라우드 서버로 송신될 수 있다. 송신 유닛은 예를 들어, 이더넷 접속과 같은 유선 통신을 위한 네트워크 인터페이스 카 드; 예를 들어, WiFi®, 블루투스®, NFC와 같은 무선 프로토콜을 사용하는 무선 트랜시버; 또는 다른 통신 수단 중 하나 이상을 포함할 수 있다. 실시예에서, 오디오 피드백은 무선 채널들 중 하나를 통해 이 디바이스로 송신 될 수 있다. 클라우드 서버는 AI 애플리케이션에 대한 센서 융합을 수행할 수 있다. 따라서, 송신 유닛을 통해 클라우드로 송신하는 대역폭을 줄이기 위해 압축이 수행될 수 있다. 도 17은 녹취록을 생성하는 데 사용하기 위해 네트워크를 통해 회의 서버로 송신되는 오디오 스트림의 수를 줄 이는 컴퓨터 구현 방법을 나타내는 흐름도이다. 방법은 동작에서 다수의 사용자의 회의로부 터 음성을 검출하는 복수(예컨대, 3개 이상)의 마이크로부터 다수의 오디오 채널을 수신함으로써 시작된다. 동 작에서, 능동 화자의 방향이 추정된다. 동작에서 1차 마이크와 2차 마이크에 대응하는 두 개의 채 널을 선택하기 위해 음성 언믹싱 모델(speech unmixing model)이 사용되거나 융합된 오디오 채널에 대응할 수 있다. 2개의 선택된 채널은 지능형 회의 녹취록의 생성을 위해 동작에서 회의 서버로 송신된다. 회의 서 버로 송신되는 데이터의 양을 줄임으로써 대역폭이 보존된다. 선택된 데이터는 거의 틀림없이 최상의 데이터이 므로 정확도가 손실되는 경우는 거의 없다. 일 실시예에서, 마이크는 고정된 구성의 디바이스에 의해 지원된다. 고정된 구성은 다수의 사용자를 포함하도록 구성된 시야를 갖는 카메라를 포함할 수 있다. 음원의 위치 파악(localize)은 카메라로부터의 오디오 및 비디오 채널에 대해 트레이닝된 모델을 실행하여 수행될 수 있다. 예를 들어, 한 사용자가 카메라가 있는 랩톱 컴퓨터 를 사용하고 있는 경우, 랩톱은 오디오 채널과 비디오 채널을 모두 제공할 수 있다. 오디오 채널은 기준 오디오 채널에 대해 동기화될 수 있고, 비디오 채널을 동기화하기 위해 동일한 시차가 사용될 수 있다. 비디오 채널에 서 이미지 인식을 사용하여 녹취록 생성 시 구분(diarization)을 위해 화자로서의 사용자를 식별할 수 있다. 추 가 실시예에서, 랩톱 컴퓨터는 사용자가 말하고 있다고 결정하고 사용자를 화자로서 식별하는 태그를 오디오 채 널에 제공하기 위해 이미지 프로세싱을 수행한다. 그러면, 랩톱에서 비디오 채널을 송신할 필요 없이 태그가 구 분에 사용될 수 있다. 추가 실시예에서, 마이크는 다수의 분산 디바이스와 연관된다. 분산 디바이스는 다수의 사용자와 각각 연관된 무선 디바이스를 포함할 수 있다. 분산 디바이스들 중 적어도 하나는 사용자들 중 적어도 한 사람의 비디오를 제공하는 카메라를 포함할 수 있다. 또 다른 실시예에서, 마이크는 고정된 구성으로 지원되는 마이크 및 사용자와 연관된 분산 디바이스와 연관되는 마이크를 포함한다. 이 방법은 고정된 위치에서 마이크를 지원하는 디바이스 또는 오디오의 다수의 채널을 수신 하는 에지 디바이스 중 하나 이상에 의해 수행될 수 있다. 음성 혼합 해제 모델(speech unmixing model)은 에지 디바이스에서 실행될 수 있다. 추가 실시예에서, 클라이언트 측 프로세싱(분산 디바이스, 주변 캡처 디바이스 및/또는 에지 서버 중 하나 이상 에서의 프로세싱)은, 회의 서버에 필요한 계산 리소스를 줄이고 분산 디바이스로부터의 분산 회의 정보 스트림 을 프로세싱하는 데 사용되는 네트워크 대역폭의 양을 줄이는 데 사용된다. 상술한 바와 같이 네트워크를 통해 회의 서버로 송신되는 스트림의 수의 감소에 더하여, 빔형성이 클라이언트 측에서 수행될 수 있을 뿐만 아니라 오디오 워터마크 및 회의 코드의 생성도 수행될 수 있다. 추가 실시예에서, 모델 크기는 클라이언트 측에서 더 잘 실행되도록 감소되고 양자화될 수 있다. 목적 함수는 클라이언트 크기에서 더 잘 실행되도록 수정될 수도 있 다. 음성 마스크를 출력하는 대신, 그에 상응하는 적은 계산으로 음원 위치 파악이 사용될 수 있다. 오디오 채널과 비디오 채널 모두는 구분된 녹취록 생성을 위해 사용자에게 음성을 귀속(attribute)시키는 데 사 용될 수 있다. 시청각 구분 접근 방식을 사용하면 음성 식별, 음원 위치 파악, 얼굴 추적/식별, 및 분산 센서로 부터의 시각적 활성 화자 검출을 결합하여 강력한 구분을 달성할 수 있다.도 18은 더 나은 화자 식별을 제공하기 위해 분산 디바이스로부터의 비디오 및 오디오 채널, 시청각 데이터 모 두를 사용하기 위한 컴퓨터 구현 방법을 나타내는 흐름도이다. 방법은 동작에서 지능형 회의 에 포함된 다수의 분산 디바이스 세트로부터 회의 서버 상에서 정보 스트림을 수신함으로써 시작된다. 동작 에서, 적어도 2개의 정보 스트림에서 적어도 2명의 사용자에 의한 음성을 나타내는 오디오 신호가 수신된 다. 동작에서, 정보 스트림 내의, 적어도 하나의 사용자의 적어도 하나의 비디오 신호가 수신된다. 수신 된 오디오 및 비디오 신호는 동작에서 수신된 오디오 및 비디오 신호의 함수로서 수신된 오디오 신호 내 의 음성을 특정 사용자와 연관시키는 데 사용된다. 지능형 회의의 녹취록은 음성과 연관된 사용자의 표시와 함 께 동작에서 생성된다. 일 실시예에서, 다수의 분산 디바이스는 지능형 회의에서 사용자와 연관된 모바일 무선 디바이스이다. 모바일 무선 디바이스는 적어도 하나의 비디오 신호를 제공하는 마이크 및 카메라를 포함할 수 있다. 추가 실시예에서, 다수의 분산 디바이스는 고정 구성으로 지원되는 다수의 마이크를 갖는 디바이스를 포함하고, 각각의 마이크는 수신된 오디오 신호들 중 하나를 제공한다. 이 디바이스는 지능형 회의에 다수의 사용자를 포함하고 적어도 하 나의 비디오 신호를 제공하도록 구성된, 시야를 갖는 카메라를 포함할 수 있다. 일 실시예에서, 특정 사용자를 음성과 연관시키기 위해 수신된 오디오 신호와 비디오 신호에 대해 융합 모델이 사용된다. 실시예에서, 시청각 데이터는 회의 서버에 의해 분석될 수 있다. 시청각 데이터는 네트워크를 통해 회의 서버로 송신되기 전에 먼저 압축될 수 있다. 또 다른 실시예에서, 융합 모델은 통합 시스템으로서 캡처 디 바이스에 결합된다. 여기에서의 논의는 제한이 아니라 설명 목적으로 회의 서버에 대해 설명한다. 회의 서버는 필요에 따라 데이터를 압축 해제, 디코딩 또는 해독한다. 시청각 데이터는 예를 들어, 오디오 방향; 이미지에서의 화자 위치; 화자 움직임; 음성 시그너처; 얼굴 시그너처; 제스처; 및/또는 물체와 같은 - 하지만, 이에 제한되지는 않음 - 시청각 데이터 내의 특징을 식별하거나 추론하기 위해 LSTM 모델을 사용하는 AI 애플리케이션에 의해 융합 및 분석될 수 있다. 예를 들어, AI 애플리케이션에는 음성 인식 또는 얼굴 인식이 필요하다. LSTM 모델은 센서 데이터를 사용하여 AI 애플리케이션에 특정한 데이터로 트레이닝될 수 있다. 실시 예에서, 위에서 논의된 바와 같이 하나보다 많은 모델 또는 분석 엔진이 사용될 수 있다. 실시예에서, 음성이 식별될 수 있고, 비디오 데이터를 이용한 제스처 인식이 수행될 수 있다. LSTM 모델은 식별 된 음성 및 인식된 제스처를 사용하여 데이터의 가능한 융합을 제공하고 가능한 결과를 AI 애플리케이션에 송신 할 수 있다. 예에서, 음성 명령과 결합된 제스처는 AI 애플리케이션에 특정 제어 명령을 제공한다. 예에서, 비 디오 데이터의 분석은 시선(eye gaze)을 나타내거나 사용자가 보고 있는 곳을 추론하기 위해 눈 움직임을 추적 한다. 시선 분석은 AI 애플리케이션에 대한 제어 명령이 될 수 있으며, 오디오 데이터와의 융합에 따라 다를 수 있다. 실시예에서, LSTM 모델은 특정 AI 애플리케이션에 대해 트레이닝되고 융합된 데이터에 기초하여 그 애플리케이 션에 대한 제어 또는 명령을 제공한다. 또 다른 실시예에서, LSTM 모델은 더 일반적일 수 있고, 입력의 추가 프 로세싱 및 해석을 위해 예를 들어, 화자 ID와 환경 내 위치를 갖는 각 화자에 대한 오디오 스트림과, 비디오 스 트림과 같은 가능한 상관 데이터를 AI 애플리케이션에 제공할 수 있다. 이 예에서 AI 애플리케이션은 오디오 및 비디오 스트림 입력을 사용하여 적절한 명령을 유도(derive)하거나 동작을 수행한다. 일 실시예는 12MP 센서를 가진 어안 카메라를 활용한다. 또 다른 실시예는 3차원(three dimensional; 3D) 또는 깊이 정보를 제공하기 위한 적외선(infrared; IR) 또는 다른 깊이 센서를 포함한다. 전체 HFOV를 커버할 수 있 는 깊이 센서가 충분하지 않은 경우 깊이 정보가 360°로 이용가능하지 않을 수 있다. 캡처 디바이스의 변형은 광범위한 사용자가 수용할 수 있는(acceptable) 다양한 가격대를 수용하거나 다른 응용을 위해 제공될 수 있다. 예를 들어, 깊이 센서 또는 고해상도 센서를 포함하면 선택된 AI 애플리케이션에 필요한 것 이상으로 디바이스 의 비용이나 복잡성이 증가할 수 있다. 도 19는 예시적인 실시예에 따른 사용자 선호도에 기초하여 출력을 맞춤화하기 위한 컴퓨터 구현 방법을 나타내는 흐름도이다. 방법의 동작은 위에서 설명된 컴포넌트를 사용하여 회의 서버 또는 시스템(예컨대, 회의 서버)에 의해 수행된다. 따라서, 방법은 회의 서버를 참조하여 예로서 설명된다. 그러나, 방법 의 동작 중 적어도 일부는 다양한 다른 하드웨어 구성에 배치될 수 있거나 네트워크 환경의 다른 곳에 상 주하는 유사한 컴포넌트에 의해 수행될 수 있다는 것을 이해해야 한다. 따라서, 방법은 회의 서버로 제한 되는 것으로 의도되지 않는다. 동작에서, 회의 서버는 복수의 분산 디바이스로부터 오디오 스트림을 수신한다. 예시적인 실시예에서, 오 디오 스트림은 2명 이상의 사용자의 회의 동안 복수의 분산 디바이스 중 하나 이상에 의해 검출된 음성을 포함 한다. 일부 실시예에서, 회의는 애드혹 회의이다. 이러한 실시예에서, 서버는 수신된 오디오 스트림에 대해 블 라인드 빔형성 또는 연속적인 음성 분리를 수행하여 음성을 배경 잡음 또는 동시에 말하는 상이한 화자들로부터 분리된 오디오 채널로 분리할 수 있다. 경우에 따라, 오디오 스트림들을 비교하여 오디오 스트림이 (동일한) 애 드혹 회의의 사운드를 나타낸다고 결정한다. 그런 다음, 애드혹 회의에서 유래한 것으로 식별된 오디오 스트림 을 프로세싱하기 위해 회의 인스턴스가 생성된다. 동작에서, 분산 디바이스들 중 하나의 사용자의 신원이 회의 서버에 의해 식별된다. 일 실시예에서, 사용 자는 회의와 연관된 카메라(예컨대, 카메라, 카메라)에 의해 캡처된 비디오 신호에 기초하여 식별된 다. 비디오 신호는 회의 서버로 송신된다. 회의 서버는 비디오 신호로부터의 사용자의 이미지를 알려진(예컨대, 등록된) 사용자의 저장된 이미지와 비교하여 매칭(match)을 결정한다. 저장된 이미지가 비디오 신호에서 캡처된 사용자 이미지와 매칭되면 사용자가 식별된다. 일 실시예에서, 사용자의 이미지는 저장되거나 사용자의 사용자 프로파일과 연관된다. 대안적인 실시예에서, 사용자는 음성 시그너처에 기초하여 식별된다. 이 실시예에서, 오디오 스트림으로부터의 음성은 파싱되거나 구분되어 알려진 사용자의 저장된 음성 시그너처와 비교된다. 저장된 음성 시그너처가 오디 오 스트림의 파싱된/구분된 음성과 매칭되면 사용자가 식별된다. 일 실시예에서, 사용자의 음성 시그너처는 저 장되거나 사용자의 사용자 프로파일과 연관된다. 동작에서, 식별된 사용자의 언어 선호도가 결정된다. 일부 실시예에서, 식별된 사용자의 사용자 프로파일 이 액세스된다. 사용자 프로파일은 적어도 사용자의 언어에 대한 미리 결정된 선호도를 포함한다. 일부 경우에 는, 미리 결정된 선호도가 사용자에 의해 수립된다(예컨대, 명시적으로 표시됨). 다른 경우에, 미리 결정된 선 호도는 사용자와 연관된 디바이스(예컨대, 휴대폰 또는 랩톱과 같은 분산 디바이스)의 디바이스 구성에 기초하 여 결정된다. 예를 들어, 이 디바이스는 영어 또는 중국어로 기능하도록 구성될 수 있다. 동작에서, 회의 서버는 상술된 바와 같이 녹취록을 생성한다. 예시적인 실시예에서, 오디오 스트림으로부 터의 음성은 텍스트 기반 녹취록 또는 디지털 녹취록을 생성하기 위해 텍스트로 변환된다. 일 실시예에서, 위에 서 논의된 바와 같이, 실시간 녹취록은 짧은 단어 시퀀스에 기초하여 생성된다. 일부 실시예에서, 데이터의 후 기 융합은 구문을 생성하기 위해 병렬로 프로세싱되고 있는 다수의 오디오 채널에 대한 음성 인식에 의해 수행 될 수 있다. 다수의 여러 오디오 채널로부터 유도된 구문은 실시간 또는 거의 실시간으로 결합된다. 일 실시예 에서, 대략 2초의 음성이 결합된다. 결과적으로, 오디오 스트림은 기본적으로 수신되는 대로 프로세싱된다. 몇 초(예컨대, 2초)의 겹치지 않는 슬라이딩 윈도우가 오디오 스트림을 프로세싱하는 데 사용되어 녹취록 생성을 위한 대기 시간을 줄인다. 동작에서, 회의 서버는 사용자의 언어 선호도에 따라 녹취록을 번역한다. 일부 실시예에서, 회의 서버는 동작으로부터 생성된 녹취록을 취하고 생성된 녹취록의 텍스트를 선호하는 언어의 텍스트로 번역한다. 다 른 실시예에서, 회의 서버는 동작으로부터 생성된 녹취록을 취하고 생성된 녹취록을 선호하는 언어의 음 성으로 변환한다. 또한, 일부 실시예는 텍스트 번역 및 음성 번역 모두를 수행할 수 있다. 예시적인 실시예에서, 녹취록으로부터의 각각의 번역된 발화에 대한 사용자(예컨대, 화자) 신원이 번역된 녹취록과 함께 제공된다. 일부 경우에 사용자 ID는 분산 디바이스와 연관된 사용자 식별자로부터 얻어진다. 동작에서, 번역된 녹취록은 사용자의 디바이스(예컨대, 분산 디바이스)로 제공된다. 일부 실시예에서, 이 디바이스는 사용자로부터 오디오를 캡처하는 데 사용되는 동일한 디바이스를 포함한다. 번역된 녹취록은 예를 들어, 이 디바이스의 디스플레이 디바이스(예컨대, 화면)에 표시되는 텍스트로서, 또는 텍스트 대 음성 변환 (text-to-speech)을 사용하여 화자 디바이스(예컨대, 이어폰, 보청기 또는 스피커)를 통한 음성 오디오로서 제 공될 수 있다. 일부 실시예에서, 구분 결과(diarization results)가 또한 제공될 수 있다. 도 19의 방법이 특정 순서의 동작들을 갖는 것으로 설명되지만, 대안적인 실시예는 다른 순서의 동작들로 방법을 수행할 수 있다. 예를 들어, 사용자를 식별하는 것(동작) 및 언어 선호도를 결정하는 것(동 작)은 녹취록이 생성된(동작) 후 또는 그 동안에, 그리고 녹취록을 번역하기(동작) 전에 발 생할 수 있다. 도 20은 예시적인 실시예에 따라 다수의 분산 디바이스, 에지 디바이스 및 클라우드 기반 디바이스를 통해 지능 형 회의 처리를 구현 및 관리하고 방법 및 알고리즘을 수행하기 위한 컴퓨터 시스템의 블록 개략도이다. 모든 컴포넌트가 다양한 실시예에서 사용될 필요는 없다.컴퓨터 형태의 하나의 예시적인 컴퓨팅 디바이스는 프로세싱 유닛, 메모리, 착탈식 저장소 , 및 비착탈식 저장소를 포함한다. 예시적인 컴퓨팅 디바이스가 컴퓨터로서 예시되고 설명되 지만, 컴퓨팅 디바이스는 상이한 실시예에서 상이한 형태들일 수 있다. 예를 들어, 컴퓨팅 디바이스는 그 대신 에 스마트폰, 태블릿, 스마트워치, 또는 도 20과 관련하여 예시되고 설명된 것과 동일하거나 유사한 요소를 포 함하는 다른 컴퓨팅 디바이스일 수 있다. 예를 들어, 스마트폰, 태블릿, 스마트 워치와 같은 디바이스는 일반적 으로 모바일 디바이스, 분산 디바이스 또는 사용자 장비로 통칭된다. 다양한 데이터 저장 요소가 컴퓨터의 일부로서 예시되어 있지만, 저장 디바이스는 또한 또는 대안적으로 예를 들어, 인터넷, 서버 기반 저장소 또는 스마트 저장 디바이스(smart storage device; SSD)와 같은, 네트워 크를 통해 액세스 가능한 클라우드 기반 저장소를 포함할 수 있다. 또한, SSD는, 파서가 실행될 수 있는 프로세 서를 포함할 수 있으므로 SSD와 주 메모리 사이의 I/O 채널을 통해 파싱되고 필터링된 데이터를 송신할 수 있다. 메모리는 휘발성 메모리 및 비휘발성 메모리를 포함할 수 있다. 컴퓨터는 예를 들어, 휘발성 메모리 및 비휘발성 메모리, 착탈식 저장소 및 비착탈식 저장소와 같은 다양한 컴퓨터 판독 가능 매체를 포함할 수 있다 - 또는 이러한 다양한 컴퓨터 판독 가능 매체를 포함하는 컴퓨팅 환경 에 액세스할 수 있다 -. 컴퓨터 저장소는 RAM(random access memory), ROM(read only memory), EPROM(erasable programmable read-only memory) 또는 EEPROM(electrically erasable programmable read-only memory), 플래 시 메모리 또는 다른 메모리 기술, CD ROM(compact disc read-only memory), DVD(Digital Versatile Disk) 또 는 다른 광디스크 저장 디바이스, 자기 카세트, 자기 테이프, 자기 디스크 저장소 또는 다른 자기 저장 디바이 스, 또는 컴퓨터 판독 가능 명령어를 저장할 수 있는 임의 다른 매체를 포함한다. 컴퓨터는 입력 인터페이스, 출력 인터페이스, 및 통신 인터페이스를 포함하는 컴퓨팅 환경을 포함하거나 이에 대한 액세스를 가질 수 있다. 출력 인터페이스는 또한 입력 디바이스로서 기능할 수 있는 예를 들어, 터치스크린과 같은 디스플레이 디바이스를 포함할 수 있다. 입력 인터페이스는 터치 스크린, 터치패드, 마우스, 키보드, 카메라, 하나 이상의 디바이스 특유 버튼, 컴퓨터 내부에 통합되거나 유선 또는 무선 데이터 접속을 통해 결합된 하나 이상의 센서, 및 다른 입력 디바이스 중 하나 이상을 포함할 수 있다. 컴퓨터는 예를 들어, 데이터베이스 서버와 같은 하나 이상의 원격 컴퓨터에 접속하기 위해 통신 접속 을 사용하는 네트워크 환경에서 동작할 수 있다. 원격 컴퓨터는 개인용 컴퓨터(personal computer; PC), 서버, 라우터, 네트워크 PC, 피어 디바이스 또는 다른 공통 데이터 흐름 네트워크 스위치 등을 포함할 수 있다. 통신 접속은 LAN(Local Area Network), WAN(Wide Area Network), 셀룰러, Wi-Fi, 블루투스, 또는 다른 네트워크를 포함할 수 있다. 일 실시예에 따르면, 컴퓨터의 다양한 컴포넌트는 시스템 버스와 접속된다. 컴퓨터 판독가능 매체에 저장된 컴퓨터 판독가능 명령어는 예를 들어, 프로그램과 같은 컴퓨터의 프로세싱 유닛에 의해 실행가능하다. 일부 실시예에서 프로그램은 회의 앱 및 회의 서버를 구현하 기 위한 하나 이상의 방법뿐만 아니라 여기에 설명된 모듈, 방법 및 알고리즘을 구현하기 위한 소프트웨어를 포 함한다. 하드 드라이브, CD-ROM, 및 RAM은 예를 들어, 저장 디바이스와 같은 비일시적 컴퓨터 판독 가능 디바이 스를 포함하는 물품의 일부 예이다. 컴퓨터 판독 가능 저장 디바이스라는 용어는 반송파가 너무 일시적인 것으 로 간주되는 한 반송파를 포함하지 않는다. 저장소는 예를 들어, SAN(storage area network)과 같은 네트워크 저장소도 포함될 수 있다. 작업 공간 관리자와 함께 컴퓨터 프로그램은 프로세싱 유닛이 여 기에 설명된 하나 이상의 방법 또는 알고리즘을 수행하게 하는 데 사용될 수 있다. 실행가능 명령어 및 기계 저장 매체 본 문서에 사용된 용어 \"기계 저장 매체\", \"디바이스 저장 매체\", \"컴퓨터 저장 매체\", \"컴퓨터 판독 가능 저장 매체\", \"컴퓨터 판독 가능 저장 디바이스\"(집합적으로 \"기계 저장 매체\"라고 함)는 동일한 것을 의미하며 본 개 시에서 혼용될 수 있다. 이 용어는 실행 가능한 명령어 및/또는 데이터를 저장하는 단일 또는 다수의 저장 디바 이스 및/또는 매체(예컨대, 중앙 집중식 또는 분산형 데이터베이스 및/또는 연관 캐시 및 서버)는 물론 다수의 저장 장치 또는 디바이스를 포함하는 클라우드 기반 저장 시스템 또는 저장 네트워크를 지칭한다. 따라서 용어 는 솔리드 스테이트 메모리와, 프로세서 내부 또는 외부 메모리를 포함한 광학 및 자기 매체를 포함하지만 이에 국한되지 않다. 기계-저장 매체, 컴퓨터-저장 매체, 및/또는 디바이스-저장 매체의 특정 예는, 예를 들어, 반도 체 메모리 디바이스, 예를 들어, EPROM(erasable programmable read-only memory), EEPROM(electrically erasable programmable read-only memory), FPGA 및 플래시 메모리 디바이스; 예를 들어, 내장 하드 디스크 및 착탈식 디스크와 같은 자기 디스크; 광자기 디스크; 및 CD-ROM 및 DVD-ROM 디스크를 포함하는, 비휘발성 메모리를 포함한다. 기계 저장 매체, 컴퓨터 저장 매체 및 디바이스 저장 매체라는 용어는 반송파, 변조된 데이터 신 호 및 기타 이러한 매체를, 이러한 매체가 너무 일시적인 것으로 간주되는 범위에서 특별히 제외한다. 다른 이 러한 매체는 아래에서 논의되는 \"신호 매체\"라는 용어로 또한 다루어진다. 이러한 맥락에서 기계-저장 매체는 비일시적이다. 신호 매체 \"신호 매체\" 또는 \"송신 매체\"라는 용어는 변조된 데이터 신호, 반송파 등의 임의의 형태를 포함하는 것으로 간 주된다. \"변조된 데이터 신호\"라는 용어는 신호의 정보를 인코딩하는 그러한 상황에서 자신의 하나 이상의 특성 이 설정되거나 변경된 신호를 의미한다. 컴퓨터 판독 가능 매체 \"기계 판독 가능 매체\", \"컴퓨터 판독 가능 매체\" 및 \"디바이스 판독 가능 매체\"라는 용어는 동일한 것을 의미 하며 본 개시에서 상호 교환 가능하게 사용될 수 있다. 이 용어는 기계 저장 매체와 신호 매체를 모두 포함하도 록 정의된다. 따라서, 이 용어는 저장 디바이스/매체 및 반송파/변조된 데이터 신호 모두를 포함한다. 예시들 예시 1은 분산 시스템에서 사용자 선호도에 기초해 맞춤화된 출력을 제공하기 위한 컴퓨터 구현 방법이다. 이 방법은, 지능형 회의에 관련된 복수의 분산 디바이스로부터 오디오 스트림들을 수신하는 단계; 복수의 분산 디 바이스 중의 분산 디바이스에 대응하는 사용자를 식별하는 단계; 사용자의 선호 언어를 결정하는 단계; 하드웨 어 프로세서에 의해, 수신된 오디오 스트림으로부터 녹취록을 생성하는 단계; 번역된 녹취록을 형성하기 위해 녹취록을 사용자의 선호 언어로 번역하는 단계; 및 번역된 녹취록을 분산 디바이스에 제공하는 단계를 포함한다. 예시 2에서, 예시 1의 요지(subject matter)는, 번역된 녹취록을 제공하는 단계가 번역된 텍스트와 함께 녹취록 을 제공하는 단계를 포함하는 것을 선택적으로 포함할 수 있다. 예시 3에서, 예시 1 내지 2의 요지는 번역된 녹취록을 제공하는 단계가 번역된 녹취록의 텍스트를 음성으로 변 환하는 단계를 포함하는 것을 선택적으로 포함할 수 있다. 예시 4에서, 예시 1 내지 3의 요지는 번역된 녹취록을 제공하는 단계가 녹취록의 각 번역된 발화에 대해 화자 신원을 제공하는 단계를 포함하는 것을 선택적으로 포함할 수 있다. 예시 5에서, 예시 1 내지 4의 요지는 사용자의 선호 언어를 결정하는 단계가, 사용자가 선호 언어를 나타내기 위해 이전에 수립된 사용자 사용자 선호도에 액세스하는 단계를 포함하는 것을 선택적으로 포함할 수 있다. 예시 6에서, 예시 1 내지 5의 요지는, 지능형 회의가 애드혹 회의(ad-hoc meeting)이고, 방법이, 오디오 스트림 들이 애드혹 회의로부터의 사운드를 나타낸다고 결정하기 위해 오디오 스트림들을 비교하는 단계; 및 오디오 스 트림들이 애드혹 회의로부터의 사운드를 나타낸다고 비교 결정하는 것에 응답하여 오디오 스트림들을 프로세싱 하기 위해 회의 인스턴스를 생성하는 단계를 더 포함하는 것을 선택적으로 포함할 수 있다. 예시 7에서, 예시 1 내지 6의 요지는, 수신된 오디오 스트림에 대해 연속적인 음성 분리를 수행하여 동시에 말 하는 상이한 화자들로부터의 음성을 별개의 오디오 채널들로 분리하는 단계를 선택적으로 포함할 수 있고, 녹취 록을 생성하는 단계는 분리된 오디오 채널들에 기초한다. 예시 8에서, 예시 1 내지 7의 요지는, 사용자를 식별하는 단계가 사용자를 캡처하는 비디오 신호를 수신하는 단 계; 및 사용자를 식별하기 위해 사용자의 저장된 이미지를 비디오 신호와 매칭하는 단계를 포함하는 것을 선택 적으로 포함할 수 있다. 예시 9에서, 예시 1 내지 8의 요지는, 사용자를 식별하는 단계가 사용자의 저장된 음성 시그너처를 오디오 스트 림으로부터의 음성과 매칭하는 단계를 포함하는 것을 선택적으로 포함할 수 있다. 예시 10에서, 예시 1 내지 9의 요지는, 사용자를 식별하는 단계가 분산 디바이스와 연관된 사용자 식별자를 획 득하는 단계를 포함하는 것을 선택적으로 포함할 수 있다. 예시 11은 분산 시스템에서 사용자 선호도에 기초해 맞춤화된 출력을 제공하기 위한 기계 저장 매체이다. 기계 판독가능 저장 디바이스는 하나 이상의 프로세서가, 지능형 회의에 관련된 복수의 분산 디바이스로부터 오디오 스트림들을 수신하는 동작; 복수의 분산 디바이스 중의 분산 디바이스에 대응하는 사용자를 식별하는 동작; 사용자의 선호 언어를 결정하는 동작; 수신된 오디오 스트림으로부터 녹취록을 생성하는 동작; 번역된 녹취록을 형성하기 위해 녹취록을 사용자의 선호 언어로 번역하는 동작; 및 번역된 녹취록을 분산 디바이스에 제공하는 동작을 포함하는 동작들을 수행하게 구성한다. 예시 12에서, 예시 11의 요지는, 번역된 녹취록을 제공하는 동작이 번역된 텍스트와 함께 녹취록을 제공하는 동 작을 포함하는 것을 선택적으로 포함할 수 있다. 예시 13에서, 예시 11 내지 12의 요지는 번역된 녹취록을 제공하는 동작이 번역된 녹취록의 텍스트를 음성으로 변환하는 동작을 포함하는 것을 선택적으로 포함할 수 있다. 예시 14에서, 예시 11 내지 13의 요지는 번역된 녹취록을 제공하는 동작이 녹취록의 각 번역된 발화에 대해 화 자 신원을 제공하는 동작을 포함하는 것을 선택적으로 포함할 수 있다. 예시 15에서, 예시 11 내지 14의 요지는 사용자의 선호 언어를 결정하는 동작이, 사용자가 선호 언어를 나타내 기 위해 이전에 수립된 사용자 선호도에 액세스하는 동작을 포함하는 것을 선택적으로 포함할 수 있다. 예시 16에서, 예시 11 내지 15의 요지는, 지능형 회의가 애드혹 회의이고, 방법이, 오디오 스트림들이 애드혹 회의로부터의 사운드를 나타낸다고 결정하기 위해 오디오 스트림들을 비교하는 동작; 및 오디오 스트림들이 애 드혹 회의로부터의 사운드를 나타낸다고 비교 결정하는 것에 응답하여 오디오 스트림들을 프로세싱하기 위해 회 의 인스턴스를 생성하는 동작을 더 포함하는 것을 선택적으로 포함할 수 있다. 예시 17에서, 예시 11 내지 16의 요지는, 동작들이 수신된 오디오 스트림들에 대해 연속적인 음성 분리를 수행 하여 동시에 말하는 상이한 화자들로부터의 음성을 별개의 오디오 채널들로 분리하는 동작을 더 포함하는 것을 선택적으로 포함할 수 있고, 녹취록을 생성하는 동작은 분리된 오디오 채널들에 기초한다. 예시 18에서, 예시 11 내지 17의 요지는, 사용자를 식별하는 동작이 사용자를 캡처하는 비디오 신호를 수신하는 동작; 및 사용자를 식별하기 위해 사용자의 저장된 이미지를 비디오 신호와 매칭하는 동작을 포함하는 것을 선 택적으로 포함할 수 있다. 예시 19에서, 예시 11 내지 18의 요지는, 사용자를 식별하는 동작이 사용자의 저장된 음성 시그너처를 오디오 스트림으로부터의 음성과 매칭하는 동작을 포함하는 것을 선택적으로 포함할 수 있다. 예시 20은 분산 시스템에서 사용자 선호도에 기초해 맞춤화된 출력을 제공하기 위한 디바이스이다. 이 시스템은 하나 이상의 프로세서와, 하나 이상의 하드웨어 프로세서에 의해 실행될 때, 하나 이상의 하드웨어 프로세서로 하여금, 지능형 회의에 관련된 복수의 분산 디바이스로부터 오디오 스트림들을 수신하는 동작; 복수의 분산 디 바이스 중의 하나의 분산 디바이스에 대응하는 사용자를 식별하는 동작; 사용자의 선호 언어를 결정하는 동작; 수신된 오디오 스트림으로부터 녹취록을 생성하는 동작; 번역된 녹취록을 형성하기 위해 녹취록을 사용자의 선 호 언어로 번역하는 동작; 및 번역된 녹취록을 분산 디바이스에 제공하는 동작을 포함하는 동작들을 수행하게 하는 명령어들을 저장한 저장 디바이스를 포함한다. 일부 실시예들이 위에서 상세히 설명되었지만, 다른 수정이 가능하다. 예를 들어, 도면에 묘사된 논리 흐름은 원하는 결과를 얻기 위해 도시된 특정 순서 또는 순차적 순서를 요구하지 않는다. 설명된 흐름에서 다른 단계가 제공되거나 단계가 제거될 수 있으며, 설명된 시스템에 다른 컴포넌트가 추가되거나 설명된 시스템으로부터 제 거될 수 있다. 다른 실시예는 다음 청구항들의 범위 내에 있을 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14a 도면14b 도면15 도면16 도면17 도면18 도면19 도면20"}
{"patent_id": "10-2021-7034789", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 예시적 실시예에 따른 다수의 사용자들 간의 회의의 사시도이다. 도 2는 예시적인 실시예에 따른 회의에서 사용하기 위한 사용자 디바이스의 블록도이다. 도 3은 예시적인 실시예에 따른 연관된 분산 디바이스(distributed devices)를 사용해 2명의 사용자 간의 지능 형 회의를 개시(initiate)하는 컴퓨터 구현 방법(computer-implemented method)을 도시하는 흐름도이다. 도 4는 예시적인 실시예에 따른 회의 코드(conference code)를 사용하여 지능형 회의에 분산 디바이스를 추가하 는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 5는 예시적인 실시예에 따른 지능형 회의에 디바이스를 더 추가하는 컴퓨터 구현 방법을 도시하는 흐름도이 다. 도 6은 예시적인 실시예에 따라 애드혹(ad-hoc) 회의가 발생하고 있음을 검출하는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 7은 예시적인 실시예에 따른, 사용자가 회의를 떠나는 것에 응답하여 사용자 디바이스 및 다른 디바이스로부 터 오디오 채널을 제거하는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 8은 예시적인 실시예에 따른 회의 서버 인스턴스(meeting server instance)에 의해 프로세싱되는 오디오 채 널에 디바이스로부터의 오디오 스트림을 추가하기 위해 이 디바이스를 인증하는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 9는 예시적인 실시예에 따른 다수의 사용자 간의 회의에 대해 녹취록을 생성하기 위한 시스템의 고수준 블록 흐름도이다. 도 10은 예시적인 실시예에 따른 분산 디바이스로부터의 오디오 스트림을 포함하는 정보의 분산 회의 서버 프로 세싱을 도시하는 상세한 블록 흐름도이다. 도 11은 예시적인 실시예에 따른 지능형 회의 동안 다수의 분산 디바이스로부터 수신된 다수의 오디오 채널을 동기화하는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 12는 예시적인 실시예에 따른 분산 디바이스 지능형 회의에서 중첩된 음성을 분리하는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 13은 예시적인 실시예에 따른 프로세싱 동안 다수의 선택된 지점(points)에서 오디오 스트림을 융합(fuse)하 는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 14a 및 도 14b는 예시적인 실시예에 따른 예시적인 주변 캡처 디바이스(ambient capture device)를 도시한다. 도 15는 예시적인 실시예에 따른 마이크 어레이의 예시적인 배치를 도시한다. 도 16은 예시적인 실시예에 따른 주변 캡처 디바이스를 갖는 인공 지능(artificial intelligence; AI) 시스템을 도시한다. 도 17은 예시적인 실시예에 따라 녹취록을 생성하는 데 사용하기 위해 네트워크를 통해 회의 서버로 송신되는 오디오 스트림의 수를 감소시키는 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 18은 예시적인 실시예에 따라 더 나은 화자 식별을 제공하기 위해 분산 디바이스로부터의 비디오 채널 및 오 디오 채널, 시청각 데이터 모두를 사용하기 위한 컴퓨터 구현 방법을 도시하는 흐름도이다. 도 19는 예시적인 실시예에 따른 사용자 선호도에 기초하여 출력을 맞춤화하기 위한 컴퓨터 구현 방법을 도시하 는 흐름도이다. 도 20은 하나 이상의 예시적인 실시예를 구현하기 위한 컴퓨터 시스템의 블록 개략도이다."}
