{"patent_id": "10-2023-0140474", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0056589", "출원번호": "10-2023-0140474", "발명의 명칭": "자율 주행 차량의 객체 인식 방법 및 그 장치", "출원인": "삼성전자주식회사", "발명자": "조준호"}}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자율 주행 차량에 있어서,인스트럭션을 저장하는 메모리;비주얼 프롬프트(visual prompt)들의 학습을 수행하고 송신하는 서버 및 주행 정보를 제공하는 네트워크와 통신하는 통신부; 및상기 자율 주행 차량의 주행 환경에 대한 데이터들을 이용하여 주변 환경을 인식하고,상기 서버로부터 수신된 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 학습된 비주얼 프롬프트를 대상비주얼 프롬프트로 결정하고,미리 결정된 연산 방법을 이용하여 상기 자율 주행 차량의 주행 영상에 상기 대상 비주얼 프롬프트를 합성한 영상을 생성하고,상기 합성한 영상을 인공 신경망 모델에 입력하여 객체 인식을 수행하는 프로세서를 포함하는, 자율 주행 차량."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 미리 결정된 연산 방법은상기 대상 비주얼 프롬프트를 상기 주행 영상에 더하는 덧셈 연산 방법 및 연접(concat) 연산 방법 중 적어도하나를 포함하는, 자율 주행 차량."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는상기 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 상기 학습된 비주얼 프롬프트들을 복수로 선택하고,선택된 상기 학습된 비주얼 프롬프트들 각각에 가중치를 부여하여 상기 주행 영상에 합성하는, 자율 주행 차량."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 주행 환경에 대한 데이터들은상기 자율 주행 차량에 포함된 센서들로부터 획득한 데이터, 카메라들로부터 획득한 상기 주행 영상 및 상기 자율 주행 차량이 통신부를 통하여 획득한 상기 주행 정보 중 적어도 하나를 포함하는, 자율 주행 차량."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0056589-3-제1항에 있어서,상기 프로세서는상기 자율 주행 차량의 주행 환경에 대한 데이터들을 획득하고, 상기 데이터들에 기초하여, 미리 결정된 기준에따라 그룹화하여 상기 비주얼 프롬프트를 생성하고, 상기 비주얼 프롬프트 및 상기 자율 주행 차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트를 학습하여 상기 학습된 비주얼 프롬프트를 생성하는, 자율 주행 차량."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 주행 정보는상기 자율 주행 차량이 주행하는 위치에 따른 기상 예보, 교통 환경, 교통 법규 및 신호 체계 중 적어도 하나를포함하는, 자율 주행 차량."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "서버에 있어서,자율 주행 차량으로부터 주행 환경에 대한 데이터들을 수신하고,상기 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하여 비주얼 프롬프트(visual prompt)들을생성하고,상기 비주얼 프롬프트들 및 상기 자율 주행 차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트들의 변화량(gradient)을 업데이트하고,상기 업데이트 결과에 따라 상기 비주얼 프롬프트들을 학습하고, 학습된 비주얼 프롬프트들을 상기 자율 주행차량으로 송신하는, 서버."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 미리 결정된 기준은상기 데이터의 종류에 따라 카테고리 별로 그룹화하는 기준을 포함하고,상기 카테고리는상기 자율 주행 차량의 주행 시간, 상기 자율 주행 차량의 주변 날씨 및 상기 자율 주행 차량의 위치 중 적어도하나를 포함하는, 서버"}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 서버는상기 비주얼 프롬프트들을 상기 카테고리에 따라 라벨링(labeling)하는, 서버.공개특허 10-2025-0056589-4-청구항 10 제7항에 있어서,상기 서버는상기 자율 주행 차량으로부터 수신한 객체 인식 결과의 불확실성이 임계 값 이상일 경우 상기 주행 환경을 신규환경으로 판단하고, Test-time adaptation 기법을 적용하여 상기 비주얼 프롬프트들의 변화량을 업데이트하는,서버."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 서버는상기 서버에 저장된 기준 비주얼 프롬프트와 상기 비주얼 프롬프트들 각각을 비교하여, 상기 변화량에 따라 상기 비주얼 프롬프트들 각각의 파라미터들을 튜닝하고, 상기 각각의 파라미터들을 상기 비주얼 프롬프트들 각각에 저장하는, 서버."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "자율 주행 차량의 제어 방법에 있어서,상기 자율 주행 차량의 주행 환경에 대한 데이터들을 이용하여 주변 환경을 인식하는 단계;서버로부터 수신한 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 학습된 비주얼 프롬프트를 대상 비주얼 프롬프트로 결정하는 단계;미리 결정된 연산 방법을 이용하여 상기 자율 주행 차량의 주행 영상에 상기 대상 비주얼 프롬프트를 합성한 영상을 생성하는 단계; 및상기 합성한 영상을 인공 신경망 모델에 입력하여 객체 인식을 수행하는 단계를 포함하는, 자율 주행 차량의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 미리 결정된 연산 방법은상기 대상 비주얼 프롬프트를 상기 주행 영상에 더하는 덧셈 연산 방법 및 연접(concat) 연산 방법 중 적어도하나를 포함하는, 자율 주행 차량의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 합성한 영상을 생성하는 단계는상기 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 상기 학습된 비주얼 프롬프트들을 복수로 선택하는단계; 및선택된 상기 학습된 비주얼 프롬프트들 각각에 가중치를 부여하여 상기 주행 영상에 합성하는 단계, 자율 주행차량의 제어 방법.공개특허 10-2025-0056589-5-청구항 15 제12항에 있어서,상기 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하여 상기 비주얼 프롬프트를 생성하는 단계; 및상기 비주얼 프롬프트 및 상기 자율 주행 차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트를 학습하여 상기학습된 비주얼 프롬프트를 생성하는 단계를 포함하는, 자율 주행 차량의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "서버의 제어 방법에 있어서,자율 주행 차량으로부터 주행 환경에 대한 데이터들을 수신하는 단계;상기 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하여 비주얼 프롬프트(visual prompt)들을 생성하는단계;상기 비주얼 프롬프트들 및 상기 자율 주행 차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트들의 변화량(gradient)을 업데이트하는 단계; 및상기 업데이트 결과에 따라 상기 비주얼 프롬프트들을 학습하고, 학습된 비주얼 프롬프트들을 상기 자율 주행차량으로 송신하는 단계를 포함하는, 서버의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 미리 결정된 기준은상기 데이터의 종류에 따라 카테고리 별로 그룹화하는 기준을 포함하고,상기 카테고리는상기 자율 주행 차량의 주행 시간, 상기 자율 주행 차량의 주변 날씨 및 상기 자율 주행 차량의 위치 중 적어도하나를 포함하는, 서버의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 비주얼 프롬프트들을 생성하는 단계는상기 비주얼 프롬프트들을 상기 카테고리에 따라 라벨링(labeling)하는, 서버의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서,공개특허 10-2025-0056589-6-상기 자율 주행 차량으로부터 수신한 객체 인식 결과의 불확실성이 임계 값 이상일 경우 상기 주행 환경을 신규환경으로 판단하고, Test-time adaptation 기법을 적용하여 상기 비주얼 프롬프트들의 변화량을 업데이트하는단계를 더 포함하는, 서버의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항에 있어서,상기 비주얼 프롬프트들의 변화량을 업데이트하는 단계는상기 서버에 저장된 기준 비주얼 프롬프트와 상기 비주얼 프롬프트들 각각을 비교하여, 상기 변화량에 따라 상기 비주얼 프롬프트들 각각의 파라미터들을 튜닝하고, 상기 각각의 파라미터들을 상기 비주얼 프롬프트들 각각에 저장하는 단계를 포함하는, 서버의 제어 방법."}
{"patent_id": "10-2023-0140474", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "아래의 개시는 자율 주행 차량의 객체 인식 방법 및 그 장치에 관한 것으로, 자율 주행 차량은 인스트럭션을 저 장하는 메모리, 비주얼 프롬프트(visual prompt)들의 학습을 수행하고 송신하는 서버 및 주행 정보를 제공하는 네트워크와 통신하는 통신부 및 자율 주행 차량의 주행 환경에 대한 데이터들을 이용하여 주변 환경을 인식하고, 서버로부터 수신된 학습된 비주얼 프롬프트들 중 데이터들에 적합한 학습된 비주얼 프롬프트를 대상 비주얼 프롬 프트로 결정하고, 미리 결정된 연산 방법을 이용하여 자율 주행 차량의 주행 영상에 대상 비주얼 프롬프트를 합 성한 영상을 생성하고, 합성한 영상을 인공 신경망 모델에 입력하여 객체 인식을 수행하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2023-0140474", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 개시는 자율 주행 차량의 객체 인식 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0140474", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근의 자율 주행 차량의 상용화에 있어서 ODD(Opreational Design Domain)은 주간의 맑은 날 고속도로이다. 하지만, 실제 자율 주행 차량이 주행하는 도로에는 야간, 악천후, 터널 같이 특수한 주행 환경이 주어질 수 있 다. 자율 주행 차량의 주변 환경은 빠르게 변하나, 차량의 특성상 객체 인식에 있어서 빠른 연산과 높은 정확 도를 요구한다. 따라서, 자율 주행 차량의 한정된 연산량 하에서 특이 환경 조건에서도 객체 인식 성능을 높이 는 방법이 요구된다."}
{"patent_id": "10-2023-0140474", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 자율 주행 차량은 인스트럭션을 저장하는 메모리, 비주얼 프롬프트(visual prompt)들의 학습 을 수행하고 송신하는 서버 및 주행 정보를 제공하는 네트워크와 통신하는 통신부 및 상기 자율 주행 차량의 주 행 환경에 대한 데이터들을 이용하여 주변 환경을 인식하고, 상기 서버로부터 수신된 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 학습된 비주얼 프롬프트를 대상 비주얼 프롬프트로 결정하고, 미리 결정된 연산 방 법을 이용하여 상기 자율 주행 차량의 주행 영상에 상기 대상 비주얼 프롬프트를 합성한 영상을 생성하고, 상기 합성한 영상을 인공 신경망 모델에 입력하여 객체 인식을 수행하는 프로세서를 포함할 수 있다. 상기 미리 결정된 연산 방법은 상기 대상 비주얼 프롬프트를 상기 주행 영상에 더하는 덧셈 연산 방법 및 연접 (concat) 연산 방법 중 적어도 하나를 포함할 수 있다. 상기 프로세서는 상기 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 상기 학습된 비주얼 프롬프트들을 복수로 선택하고, 선택된 상기 학습된 비주얼 프롬프트들 각각에 가중치를 부여하여 상기 주행 영상에 합성할 수 있다. 상기 주행 환경에 대한 데이터들은 상기 자율 주행 차량에 포함된 센서들로부터 획득한 데이터, 카메라들로부터 획득한 상기 주행 영상 및 상기 자율 주행 차량이 통신부를 통하여 획득한 상기 주행 정보 중 적어도 하나를 포 함할 수 있다. 상기 프로세서는 상기 자율 주행 차량의 주행 환경에 대한 데이터들을 획득하고, 상기 데이터들에 기초하여, 미 리 결정된 기준에 따라 그룹화하여 상기 비주얼 프롬프트를 생성하고, 상기 비주얼 프롬프트 및 상기 자율 주행차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트를 학습하여 상기 학습된 비주얼 프롬프트를 생성할 수 있 다. 상기 주행 정보는 상기 자율 주행 차량이 주행하는 위치에 따른 기상 예보, 교통 환경, 교통 법규 및 신호 체계 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 서버는 자율 주행 차량으로부터 주행 환경에 대한 데이터들을 수신하고, 상기 데이터들에 기 초하여, 미리 결정된 기준에 따라 그룹화하여 비주얼 프롬프트(visual prompt)들을 생성하고,상기 비주얼 프롬 프트들 및 상기 자율 주행 차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트들의 변화량(gradient)을 업데이 트하고, 상기 업데이트 결과에 따라 상기 비주얼 프롬프트들을 학습하고, 학습된 비주얼 프롬프트들을 상기 자 율 주행 차량으로 송신할 수 있다. 상기 미리 결정된 기준은 상기 데이터의 종류에 따라 카테고리 별로 그룹화하는 기준을 포함할 수 있고, 상기 카테고리는 상기 자율 주행 차량의 주행 시간, 상기 자율 주행 차량의 주변 날씨 및 상기 자율 주행 차량의 위 치 중 적어도 하나를 포함할 수 있다. 상기 서버는 상기 비주얼 프롬프트들을 상기 카테고리에 따라 라벨링(labeling)할 수 있다. 상기 서버는 상기 자율 주행 차량으로부터 수신한 객체 인식 결과의 불확실성이 임계 값 이상일 경우 상기 주행 환경을 신규 환경으로 판단하고, Test-time adaptation 기법을 적용하여 상기 비주얼 프롬프트들의 변화량을 업 데이트할 수 있다. 상기 서버는 상기 서버에 저장된 기준 비주얼 프롬프트와 상기 비주얼 프롬프트들 각각을 비교하여, 상기 변화 량에 따라 상기 비주얼 프롬프트들 각각의 파라미터들을 튜닝하고, 상기 각각의 파라미터들을 상기 비주얼 프롬 프트들 각각에 저장할 수 있다. 일 실시예에 따른 자율 주행 차량의 제어 방법은 상기 자율 주행 차량의 주행 환경에 대한 데이터들을 이용하여 주변 환경을 인식하는 단계, 서버로부터 수신한 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 학습된 비주얼 프롬프트를 대상 비주얼 프롬프트로 결정하는 단계, 미리 결정된 연산 방법을 이용하여 상기 자율 주행 차량의 주행 영상에 상기 대상 비주얼 프롬프트를 합성한 영상을 생성하는 단계 및 상기 합성한 영상을 인공 신 경망 모델에 입력하여 객체 인식을 수행하는 단계를 포함할 수 있다. 상기 미리 결정된 연산 방법은 상기 대상 비주얼 프롬프트를 상기 주행 영상에 더하는 덧셈 연산 방법 및 연접 (concat) 연산 방법 중 적어도 하나를 포함할 수 있다. 상기 합성한 영상을 생성하는 단계는 상기 학습된 비주얼 프롬프트들 중 상기 데이터들에 적합한 상기 학습된 비주얼 프롬프트들을 복수로 선택하는 단계 및 선택된 상기 학습된 비주얼 프롬프트들 각각에 가중치를 부여하 여 상기 주행 영상에 합성하는 단계를 포함할 수 있다. 상기 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하여 상기 비주얼 프롬프트를 생성하는 단계 및 상 기 비주얼 프롬프트 및 상기 자율 주행 차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트를 학습하여 상기 학습된 비주얼 프롬프트를 생성하는 단계를 포함할 수 있다. 일 실시예에 따른 서버의 제어 방법은 자율 주행 차량으로부터 주행 환경에 대한 데이터들을 수신하는 단계, 상 기 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하여 비주얼 프롬프트(visual prompt)들을 생성하는 단계, 상기 비주얼 프롬프트들 및 상기 자율 주행 차량의 주행 영상에 기초하여, 상기 비주얼 프롬프트들의 변 화량(gradient)을 업데이트하는 단계 및 상기 업데이트 결과에 따라 상기 비주얼 프롬프트들을 학습하고, 학습 된 비주얼 프롬프트들을 상기 자율 주행 차량으로 송신하는 단계를 포함할 수 있다. 상기 미리 결정된 기준은 상기 데이터의 종류에 따라 카테고리 별로 그룹화하는 기준을 포함할 수 있고, 상기 카테고리는 상기 자율 주행 차량의 주행 시간, 상기 자율 주행 차량의 주변 날씨 및 상기 자율 주행 차량의 위 치 중 적어도 하나를 포함할 수 있다. 상기 비주얼 프롬프트들을 생성하는 단계는 상기 비주얼 프롬프트들을 상기 카테고리에 따라 라벨링(labeling) 할 수 있다. 상기 자율 주행 차량으로부터 수신한 객체 인식 결과의 불확실성이 임계 값 이상일 경우 상기 주행 환경을 신규 환경으로 판단하고, Test-time adaptation 기법을 적용하여 상기 비주얼 프롬프트들의 변화량을 업데이트하는 단계를 더 포함할 수 있다.상기 비주얼 프롬프트들의 변화량을 업데이트하는 단계는 상기 서버에 저장된 기준 비주얼 프롬프트와 상기 비 주얼 프롬프트들 각각을 비교하여, 상기 변화량에 따라 상기 비주얼 프롬프트들 각각의 파라미터들을 튜닝하고, 상기 각각의 파라미터들을 상기 비주얼 프롬프트들 각각에 저장하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0140474", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에 대한 특정한 구조적 또는 기능적 설명들은 단지 예시를 위한 목적으로 개시된 것으로서, 다양한 형 태로 변경되어 구현될 수 있다. 따라서, 실제 구현되는 형태는 개시된 특정 실시예로만 한정되는 것이 아니며, 본 명세서의 범위는 실시예들로 설명한 기술적 사상에 포함되는 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 해석되어야 한다. 예를 들어, 제1 구성요소는 제2 구성요소로 명 명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들 을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면들을 참조하여 상세하게 설명한다. 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부여하고, 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 일 실시예에 따른 자율 주행 차량의 객체 인식을 설명하기 위한 블록도이다. 도 1의 하나 이상의 블록들 및 블록들의 조합은 특정 기능을 수행하는 특수 목적 하드웨어 기반 컴퓨터, 또는 특수 목적 하드웨어 및 컴퓨터 명령들의 조합에 의해 구현될 수 있다.도 1을 참조하면, 일 실시예에 따른 자율 주행 차량은 카메라, 센서, 통신부 및 프로 세서(예: 도 9의 프로세서)를 포함할 수 있다. 도 1에 프로세서가 구체적으로 도시되진 않았지만, 프로세서는 자율 주행 차량에서 객체 인식을 수행하기 위한 일련의 동작들을 수행할 수 있다. 자율 주행 차량은 센서를 통해 주행 환경에 대한 데이터를 획득할 수 있다. 자율 주행 차량은 주행을 위해 수많은 센서를 탑재할 수 있다. 자율 주행 자동차에 탑재된 센서의 예시는 후술하는 도 3을 참조하여 설명될 수 있다. 자율 주행 차량은 통신부를 통해 외부 네트워크로부터 주행 정보를 수신할 수 있다. 예를 들어, 자 율 주행 차량은 기상청 API, 일출/일몰 API 등으로부터 현재 위치의 날씨, 주/야간에 대한 정보를 수신할 수 있다. 또한, 자율 주행 차량이 통신부를 통해 획득한 주행 정보는 자율 주행 차량이 주행하 고 있는 지역, 국가에 따른 신호 체계, 교통 법규, 교통 환경 및 기상 예보 등을 포함할 수 있다. 주행 정보는 기재된 실시예로 한정되는 것은 아니고, 자율 주행 차량은 통상의 기술자가 자율 주행 차량이 수신할 수 있을 것으로 생각되는 주행 정보를 수신할 수 있다. 자율 주행 차량은 상술한 센서 및 통신부를 통해 주야, 날씨, 장소, 시간 등 주행 환경에 대한 데이터를 획득할 수 있다. 프로세서는 주행 환경에 대한 데이터들을 이용하여 주변 환경을 인식할 수 있 다. 또한, 자율 주행 차량은 CAN 통신(Controller Area Network)을 통해 차량의 현재 속도, 카메라 캘리브레이션(Calibration) 값 등도 환경 인식에 대한 데이터로 활용할 수 있다. CAN 통신이란, 차량 내에서 호스트 컴퓨터 없이 마이크로 컨트롤러나 장치들이 서로 통신하기 위해 설계된 표준 통신 규격이다. 자율 주행 차량은 차량에 부착된 하나 이상의 카메라를 통해 자율 주행 차량의 주행 영상을 획 득할 수 있다. 카메라들은 부착된 위치에 따라, 서로 다른 주행 영상을 촬영할 수 있다. 자율 주행 차 량은 카메라들로부터 획득한 주행 영상을 서버로 전송할 수 있고, 프로세서를 통해 객체 인식을 수행하기 위해 이용할 수도 있다. 프로세서는 센서 및 통신부를 통해 획득한 정보를 표 1과 같은 데이터 세트로 분류할 수 있다. 표 1 카테고리 환경 시간 daytime, night, dawn/dusk 날씨 rainy, snowy, clear, overcast, partly cloudy, foggy 위치 tunnel, residential, parking lot, city street, gas stations, highway, 표 1을 참조하면, 프로세서는 획득한 데이터를 시간, 날씨 및 위치로 분류하였다. 다만, 프로세서의 데이터 분류는 표 1과 같이 한정되는 것은 아니고, 자율 주행 차량의 속도 등을 활용할 수도 있다.일 실시 예에 따른 자율 주행 차량은 서버로부터 학습된 비주얼 프롬프트를 수신할 수 있다. 학습된 비주얼 프롬프트는 서버에서 생성될 수 있다. 비주얼 프롬프트를 학습하는 과정은 후술하는 서버의 동작을 통해 설명될 수 있다. 일 실시예에 따른 서버는 자율 주행 차량으로부터 주행 환경에 대한 데이터들을 수신할 수 있다. 서버는 주행 환경에 대한 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하여 비주얼 프롬프트들 을 생성할 수 있다. 서버는 주행 환경에 대한 데이터들을 전술한 표 1과 같은 형태로 수신할 수도 있으 나, 자율 주행 차량으로부터 수신한 데이터들을 미리 결정된 기준에 따라 그룹화할 수도 있다. 미리 결정된 기준이란, 자율 주행 차량으로부터 수신한 데이터들의 종류에 따라 카테고리별로 그룹화하는 기준을 의미할 수 있다. 카테고리란, 자율 주행 차량의 주행 시간, 자율 주행 차량의 주변 날씨 및 자율 주행 차량의 위치 등 데이터가 의미하는 것대로 분류하는 기준을 의미할 수 있다. 미리 결정된 기준 및 카테고리는 기재된 실시예로 한정되는 것은 아니고, 통상의 기술자가 데이터를 분류할 때 사용하는 방법 비주얼 프롬프트는 입력 영상과 같은 차원의 텐서(tensor) 형태거나 패딩(padding) 부분만 학습 가능 (learnable)한 형태거나, 패치(patch) 형태로 학습 가능한 형태 등 다양한 형태를 가질 수 있다. 예를 들어, 비주얼 프롬프트는 합연산이 가능하고 교환 법치이 성립하는 텐서일 수 있다. 비주얼 프롬프트는 입력 연상과 같은 차원의 텐서일 수 있고, 영역을 제한시켜 패딩, 또는 특정 패치 부분만 학습시킬 수 있다. 별개로, 형태 와 상관없이 비주얼 프름프트들 사이에 교환 법칙이 성립하는 합연산이 가능하다면 미분 가능한 함수를 거쳐 입력 영상이 더해질 수 있다. 따라서, 손실함수에서 계산된 변화량(gradient)는 비주얼 프롬프트까지 역전파되어 학습 가능할 수 있다. 후술하는 비주얼 프롬프트들은 하나의 데이터(예: _time-daytime, _weather-rainy, _location-highway)만을 이용하여 생성된 것으로 설명하나, 이는 설명의 편의를 위한 예시적인 것일 뿐이고, 여러 개의 데이터가 합성되어 생성된 비주얼 프롬프트일 수 있다. 비주얼 프롬프트의 학습은 기존 객체 인식 모델의 학습과 달리, 객체 인식 모델의 파라미터를 튜닝하지 않고, 자율 주행 차량의 주행 영상(I)에 덧셈 연산이 수행되거나 연접(concat) 연산이 수행되는 비주얼 프롬프 트의 변화량(gradient)을 업데이트하여 학습될 수 있다. 서버는 비주얼 프롬프트를 학습을 통해 카테고리 별로 분류된 데이터들에 기초하여, 비주얼 프롬프트들을 라벨링(labeling)할 수 있다. 예를 들어, 서버가 낮 시간 대, 맑은 날씨 및 고속 도로의 주행 영상과 주행 영상에 해당하는 데이터들 을 수신했다고 가정한다. 이 경우, 서버는 자율 주행 차량으로부터 시간 카테고리의 daytime 데이터, 날씨 카테고리의 clear 데이터 및 위치 카테고리의 highway 데이터를 수신할 수 있다. 서버는 수 신한 데이터에 기초하여, 제1 비주얼 프롬프트 _time-daytime, 제2 비주얼 프롬프트 _weather-clear 및 제3 비주얼 프롬프트 _location-highway를 생성할 수 있다. 서버는 생성된 제1 비주얼 프롬프트, 제2 비주 얼 프롬프트 및 제3 비주얼 프롬프트 각각을 기준 비주얼 프롬프트와 비교하여, 변화량(gradient)을 측정하고, 업데이트 할 수 있다. 서버는 변화량에 기초하여, 제1 비주얼 프롬프트, 제2 비주얼 프롬프트 및 제3 비 주얼 프롬프트의 파라미터들을 튜닝하고, 튜닝된 파라미터들을 각각의 비주얼 프롬프트들에 저장할 수 있다 서버는 업데이트 결과 튜닝된 파라미터들이 저장된 학습된 비주얼 프롬프트들을 자율 주행 차량으로 송신할 수 있다. 학습된 비주얼 프롬프트들은 기재된 실시예로 한정되는 것은 아니고, 자율 주행 차량으로부터 수신한 데이 터들에 따라 달라질 수 있다. 자율 주행 차량은 통신부를 통해 서버로부터 학습된 비주얼 프롬프트들을 수신할 수 있다. 프 로세서는 수신된 학습된 비주얼 프롬프트들 중 주행 환경에 대한 데이터들에 적합한 학습된 비주얼 프롬 프트를 대상 비주얼 프롬프트로 결정할 수 있다. 예를 들어, 자율 주행 차량이 제1 비주얼 프롬프트, 제2 비주얼 프롬프트 및 제3 비주얼 프롬프트가 포함된 학습된 비주얼 프롬프트들을 수신하였다고 가정한다. 이 때, 자율 주행 차량이 주행 환경에 대한 데이터를 획득할 수 있다. 획득한 데이터가 낮 시간이라는 데이 터라면, 프로세서는 비주얼 프롬프트 모듈을 통해 제1 비주얼 프롬프트를 대상 비주얼 프롬프트로 결정할 수 있다. 비주얼 프롬프트 모듈은 프로세서에 내장된 것으로서, 서버로부터 수신한 학습된 비주얼 프롬프트를 저장할 수 있고, 주행 환경에 대한 데이터들로부터 학습된 비주얼 프롬프트를 대상 비주얼 프롬프트로 결정하 는 동작을 수행할 수 있다. 용어 \"모듈\"은, 예를 들면, 하드웨어, 소프트웨어 또는 펌웨어(firmware) 중 하나 또는 둘 이상의 조합을 포함하는 단위(unit)를 의미할 수 있다. \"모듈\"은, 예를 들면, 유닛(unit), 로직 (logic), 논리 블록(logical block), 부품(component), 또는 회로(circuit) 등의 용어와 바꾸어 사용 (interchangeably use)될 수 있다. \"모듈\"은, 일체로 구성된 부품의 최소 단위 또는 그 일부가 될 수 있다. \"모 듈\"은 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수도 있다. \"모듈\"은 기계적으로 또 는 전자적으로 구현될 수 있다. 예를 들면,\"모듈\"은, 알려졌거나 앞으로 개발될, 어떤 동작들을 수행하는 ASIC(application-specific integrated circuit) 칩, FPGAs(field-programmable gate arrays) 또는 프로그램 가능 논리 장치(programmable-logic device) 중 적어도 하나를 포함할 수 있다. 프로세서는 미리 결정된 연산 방법을 이용하여 자율 주행 차량의 주행 영상에 대상 비주얼 프롬프트 를 합성한 영상을 생성할 수 있다. 미리 결정된 연산 방법은 대상 프롬프트와 주행 영상을 덧셈 연산으로 합성 한 영상일 수 있다. 또한, 프로세서는 연접 연산 방법을 수행할 수도 있다. 후술하는 도 5에서 미리 결정 된 연산 방법에 대해 상세히 설명될 수 있다. 프로세서는 합성한 영상을 인공 신경망 모델(예: 객체 인식 모델)에 입력하여, 합성한 영상에서 객체 인식 을 수행할 수 있다. 상술한 방법은 객체 인식 모델은 유지하고 비주얼 프롬프트를 학습 및 튜닝하는 것으로 객 체 인식 모델의 웨이트(weight)는 서버와 자율 주행 차량에서 공유되고 학습된 비주얼 프롬프트만 서 버에서 자율 주행 차량으로 전송될 수 있다. 학습된 비주얼 프롬프트는 각 해당 환경에 대응하므로 객체 인식 모델은 학습된 비주얼 프롬프트가 주행 영상에 합성된 영상에 따라 적합한 객체 인식 추론 동작을 할 수 있다. 예를 들어, 객체 인식 모델은 비가 오는 주행 상황에서 해당되는 학습된 비주얼 프롬프트를 주행 영상에 합성하여 추론하는 것일 수 있다. 일반적으로, 자율 주행 차량의 주행 환경은 복합적인 요소들이 작용하는 환경일 수 있다. 따라서, 프로 세서는 다양한 학습된 비주얼 프롬프트들을 함께 주행 영상에 합성하여 객체 인식 모델의 성능을 향상시 킬 수 있다. 또한, 프로세서는 학습된 비주얼 프롬프트들을 주행 영상에 합성함에 있어서, 각각의 학습 된 비주얼 프롬프트들 마다 가중치를 다르게 부여하여 합성할 수 있다. 일 실시예에 따른 프로세서는 학습된 비주얼 프롬프트들 중 데이터들에 적합한 학습된 비주얼 프롬프트들 을 복수로 선택하고, 선택된 학습된 비주얼 프롬프트들 각각에 가중치를 부여하여 주행 영상에 합성할 수 있다. 예를 들어, 가중치는 프로세서가 객체 인식을 수행할 때 중요하게 고려되어야 하는 요소일 수 있다. 예를 들어, 낮 시간의 맑은 날의 고속도로보다는 낮 시간의 비오는 날의 고속도로에서 객체 인식을 수행할 때 성능 저하가 발생할 수 있으므로, 비오는 날에 대한 학습된 비주얼 프롬프트에 보다 높은 가중치를 부여하여 복합 합 성 영상을 생성할 수 있다. 도 2는 일 실시예에 따른 자율 주행 차량의 프로세서의 동작을 설명하기 위한 흐름도이다. 도 2의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 2에 도시된 다수의 동작은 병렬로 또는 동시 에 수행될 수 있다. 도 1을 참조한 설명은, 도 2에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 단계에서, 일 실시예에 따른 프로세서는 자율 주행 차량으 주행 환경에 대한 데이터들을 이용 하여, 주변 환경을 인식할 수 있다. 주행 환경에 대한 데이터들은 자율 주행 차량에 포함된 센서들로부터 획득한 데이터, 카메라들 로부터 획득한 주행 영상 및 자율 주행 차량이 통신부를 통하여 획득한 주행 정보 중 적어도 하나를 포함할 수 있다. 주행 정보는 자율 주행 차량이 주행하는 위치에 따른 기상 예보, 교통 환경, 교통 법규 및 신호 체계 중 하나를 포함할 수 있다. 예를 들어, 국가마다 좌측 통행/ 우측 통행에 관한 규칙이 있고, 국 가마다 표지판의 다양함, 차량들의 형태가 다양하다. 또한, 바이크가 많은 국가와 트럭이 많은 국가가 존재할 수 있고, 국가마다 차선의 폭, 형태도 달라질 수 있다. 즉, 주행 정보는 교통에 대한 포괄적인 정보를 의미할 수 있다. 단계에서, 일 실시예에 따른 프로세서는 서버로부터 수신된 학습된 비주얼 프롬프트들 중 데이 터들에 적합한 학습된 비주얼 프롬프트를 대상 비주얼 프롬프트로 결정할 수 있다. 단계에서, 일 실시예에 따른 프로세서는 미리 결정된 연산 방법을 이용하여 자율 주행 차량의 주행 영상에 대상 비주얼 프롬프트를 합성한 영상을 생성할 수 있다. 미리 결정된 연산 방법은 대상 비주얼 프롬프트를 주행 영상에 더하는 덧셈 연산 방법 및 연접 연산 방법 중 적 어도 하나를 포함할 수 있다. 단계에서, 일 실시예에 따른 프로세서는 합성한 영상을 인공 신경망 모델에 입력하여 객체 인식을 수 행할 수 있다. 프로세서는 학습된 비주얼 프롬프트들 중 데이터들에 적합한 학습된 비주얼 프롬프트들을 복수로 선택하고, 선택된 학습된 비주얼 프롬프트들 각각에 가중치를 부여하여 주행 영상에 합성할 수 있다. 도 3은 일 실시예에 따른 서버의 동작을 설명하기 위한 흐름도이다. 도 3의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 3에 도시된 다수의 동작은 병렬로 또는 동시 에 수행될 수 있다. 도 1 및 도 2를 참조한 설명은, 도 3에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 단계에서, 일 실시예에 따른 서버는 자율 주행 차량으로부터 주행 환경에 대한 데이터들을 수 신할 수 있다. 단계에서, 일 실시예에 따른 서버는 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하여 비주 얼 프롬프트들을 생성할 수 있다. 미리 결정된 기준은 데이터의 종류에 따라 카테고리 별로 그룹화 하는 기준을 포함할 수 있다. 카테고리는 자 율 주행 차량의 주행 시간, 자율 주행 차량의 주변 날씨 및 자율 주행 차량의 위치 중 적어도 하나를 포함할 수 있다. 서버는 비주얼 프롬프트들을 카테고리에 따라 라벨링(labeling)할 수 있다. 단계에서, 일 실시예에 따른 서버는 비주얼 프롬프트들 및 자율 주행 차량의 주행 영상에 기초 하여, 비주얼 프롬프트들의 변화량을 업데이트할 수 있다. 서버는 자율 주행 차량으로부터 수신한 객체 인식 결과의 불확실성이 임계 값 이상일 경우 주행 환 경을 신규 환경으로 판단하고, Test-time adaptation 기법을 적용하여 비주얼 프롬프트들의 변화량을 업데이트 할 수 있다. 예를 들어, 자율 주행 차량이 비주얼 프롬프트를 학습해 본 적 없는 새로운 환경 조건을 인식하였으나 객 체 인식 모델의 인식 결과에 대한 불확실성이 임계 값 이상이면, 해당 조건에서 데이터 취득 및 라벨링이 어려 울 수 있다. 이 때, Test-time adaptation 기법은 자율 주행 차량이 신규 환경 조건(예: 다른 국가, 생 소한 지리환경)에서의 test-time 영상들 및 데이터들을 확보하여 서버로 전송하고, 서버는 수신한 test-time 영상에 대한 어노테이션(annotation)이 없으므로, 해당 영상들에 대해서 self-supervised 학습을 수 행할 수 있다. self-supervised 학습은 self-supervised learning은 라벨링되지 않은 데이터들로부터 좋은 representation을 얻고자하는 학습방식으로 representation learning의 일종이다. 라벨 없이 입력 내에서 타 겟으로 쓰일만 한 것을 자체적으로 정해서 모델을 학습한다. 따라서, self-supervised learning은 pretext task라고 부르기도 한다. self-supervised 학습은 하나의 데이터 샘플 내에서 한 파트를 통해서 다른 파트를 예측하는 방법(intra-sample prediction) 및 배치(batch) 내의 데이터 샘플들 사이의 관계를 예측하는 방법 (inter-sample prediction) 중 적어도 하나의 방법으로 수행될 수 있다. 따라서, 서버는 신규 환경 조건 에 대한 영상들 및 데이터들에서 비주얼 프롬프트를 생성하여 라벨링하고 학습할 수 있고, 기존에 존재하던 다 른 주행 환경 조건에서 기 학습된 비주얼 프롬프트와 비교하여 신규 환경 조건에 대한 비주얼 프롬프트를 라벨 링하고 학습할 수 있다. 신규 환경 조건에 대한 비주얼 프롬프트를 생성하면, 서버는 신규 환경 조건에 대한 학습된 비주얼 프롬프트를 생성하여, 자율 주행 자동차로 전송할 수 있다. 단계에서, 일 실시예에 따른 서버는 업데이트 결과에 따라 비주얼 프롬프트들을 학습하고, 학습된 비 주얼 프롬프트들을 자율 주행 차량으로 송신할 수 있다. 서버는 저장된 기준 비주얼 프롬프트와 비주얼 프롬프트들 각각을 비교하여, 변화량에 따라 비주얼 프롬프 트들 각각의 파라미터들을 튜닝하고, 각각의 파라미터들을 비주얼 프롬프트들 각각에 저장할 수 있다. 전술한 방법들에서 서버가 비주얼 프롬프트를 학습하는 것으로 서술했으나, 자율 주행 차량에 프로세 서에 전술한 방법들을 수행할 수 있는 SOC(system on chip) 및/또는 GPU가 탑재된다면, 서버와 통신 하지 않고도 프로세서 자체적으로 수행할 수 있다. 따라서, 일 실시예에 따른 프로세서는 자율 주행 차량의 주행 환경에 대한 데이터들을 획득하고, 데이터들에 기초하여, 미리 결정된 기준에 따라 그룹화하 여 비주얼 프롬프트를 생성하고, 비주얼 프롬프트 및 자율 주행 차량의 주행 영상에 기초하여, 비주얼 프 롬프트를 학습하여 학습된 비주얼 프롬프트를 생성할 수 있다. 도 4는 일 실시예에 따른 자율 주행 자동차에 탑재된 센서들을 개략적으로 도시한 것이다. 도 3을 참조하면, 자율 주행 차량의 엔진 및 변속기에는 압력 센서, 유량 센서, 가속도 센서, 온도 센서, 자이로 센서 및 조향각 센서를 포함할 수 있다. 자율 주행 차량의 친환경 장치는 배기가스 센서, 매연감 지 센서 및 산소 센서를 포함할 수 있다. 자율 주행 장치의 편의성 장치는 빛 감지 센서, 적외선 센서, 우적센서 및 이미지 센서를 포함할 수 있다. 자율 주행 장치의 실내 환경은 온도/습도 센서, 가스 센서 및 Air Quality 센서를 포함할 수 있다. 자율 주행 장치의 텔레매틱스는 위성 항법 장치(GPS), 내비게이션 및 무선 통 신을 포함할 수 있다. 자율 주행 장치의 예방/안전 장치는 충돌방지 센서, 이미지 센서, 초음파 센서, Laser Rader 센서, 에어백 센서 및 TPMS 센서를 포함할 수 있다. 자율 주행 장치의 조향/현가 장치는 가속도 센서, 차고 센서, 조향각 센서, 각속도 센서, 중력 센서 및 토크 센서를 포함할 수 있다. 이외에도 자율 주행 차량에는 통상의 기술자가 자율 주행 차량에 탑재될 수 있는 센서로 생각할 수 있는 것들을 포함할 수 있고, 기재된 실시예로 한정되는 것은 아니다. 또한, 각 센서들의 기능은 그 명칭으로부터 통상의 기술자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략될 수 있다. 일 실시예에 따른 프로세서는 전술한 자율 주행 차량에 포함된 센서로부터 획득한 데이터들을 가공하여 객체 인식 모델의 입력으로 활용할 수 있다. 도 5는 일 실시예에 따른 비주얼 프롬프트를 설명하기 위해 개략적으로 도시한 도면이다. 도 1 내지 도 4를 참조한 설명은, 도 5에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 일 실시예에 따른 프로세서는 대상 비주얼 프롬프트와 주행 영상을 합성한 영상을 생성할 수 있다. 프로세서는 미리 결정된 연산 방법을 이용하여 자율 주행 차량의 주행 영상에 대상 비주얼 프롬프트를 합성한 영상을 생성할 수 있다. 미리 결정된 방법은 대상 프롬프트와 주행 영상 을 덧셈 연산으로 합성한 영상일 수 있다. 덧셈 연산의 경우 대상 비주얼 프롬프트를 주행 영상에 입히는 방식으로 수행될 수 있다. 블록들은 튜닝된 파라미터들이 비주얼 프롬프트에 저장된 모습을 시각 화 한 것이다. 프로세서는 연접 연산 방법을 수행할 수도 있다. 연접 연산은 대상 비주얼 프롬프트와 주행 영상 에 대하여 채널 방향으로 연산을 수행하는 것일 수 있다. 프로세서는 대상 비주얼 프롬프트와 주행 영상의 차원(dimension)이 다른 경우에도 적용할 수 있다. 예를 들어, 입력 영상(예: 주행 영상)의 크기는 C'HW(Channel Height Width) 이고, 대상 비주얼 프롬프트의 크기는 CHW로 가정하여, 채널 방향 크기가 다르다고 가정한다. 또한, 객체 인식 모델의 입력 의 크기가 CHW의 기반이라고 가정한다. 입력 영상과 대상 비주얼 프롬프트의 연접 연산 결과에 따른 합성 한 영상의 채널 크기는 C'+C이 될 수 있다. 프로세서가 객체 인식을 수행하기 위해 합성한 영상 의 채널 크기를 객체 인식 모델의 기반 입력의 채널 크기(C)로 변환해야 하므로, 1X1 CONV를 수행하는 학 습이 선행되어야 한다. 따라서, 서버 또는 프로세서는 1X1 CONV 연산을 객체 인식 모델에 합성한 영 상을 입력하기 전에 수행할 수 있다. 프로세서는 주행 영상에 대해 비주얼 프롬프트를 더하여 주는 방식외에도, Convolution 연산이 수행되는 각 피쳐 레벨(feature level)에도 해당 크기의 피처 프롬프트를 생성하여 더해줄 수 있다. 예를 들어, Conv1 (예를 들어, 첫 번째 Convolution Layer를 의미한다) 및 Conv2가 수행된 이후, Conv2 연산을 지난 인공 신경망 모델의 피처에도 해당 크기의 피처 프롬프트를 삽입하여 객체 인식을 수행할 수 있다. 즉, 임의의 N 번째 Layer의 피처 맵에도 피처 프롬프트를 생성하여 더하는 연산을 수행할 수 있다. 도 6 내지 도 8은 일 실시예에 따른 복합 합성 영상을 설명하기 위한 개략적인 도면이다. 도 1 내지 도 5를 참조한 설명은, 도 6 내지 도 8에도 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있 다. 도 6을 참조하면, 자율 주행 차량의 프로세서는 비오는 고속도로에서 주행할 때 객체 인식을 수행하 기 위해 주행 영상에 학습된 비주얼 프롬프트들을 각각 합성하여 복수의 합성 영상들(611,621)을 생성할 수 있 다. 즉, 프로세서는 주행 영상에 제4 비주얼 프롬프트 _weather-rainy를 합성한 영상을 생성하고, 주행 영상에 제5 비주얼 프롬프트 _location-highway를 합성한 영상을 생성할 수있다. 프로세서는 합성 영상들(611,621)을 객체 인식 모델에 입력으로 사용하여, 객체 인식을 수행할 수 있다. 프로세서는 합성 영상들(611,621)을 입력으로 사용할 때, 각각의 합성 영상들(611,621)의 중요도에 따라 가중치를 부여하여 객체 인식을 수행할 수 있다. 합성 영상들은 기재된 실시예처럼 두 개로 한정되는 것 은 아니고, 동시에 혹은 병렬적으로 세 개 이상 합성되어 객체 인식 모델에 입력될 수 있다. 도 7을 참조하면, 자율 주행 차량이 비오는 야간의 시내를 주행하고 있다고 가정한다. 이 때, 자율 주행 차량의 카메라는 비오는 야간의 시내의 주행 영상을 촬영할 수 있고, 자율 주행 차량의 센 서 및 통신부는 비오는 야간의 시내의 주행 환경에 대한 데이터들을 수집할 수 있다. 자율 주행 차 량은 주행 환경에 대한 데이터들을 서버로 전송할 수 있다. 서버는 수신한 데이터에 기초하여, 학습된 비주얼 프롬프트들을 생성할 수 있다. 이 때, 학습된 비주얼 프롬프트들은 제6 비주얼 프롬프트 _time-night, 제7 비주얼 프롬프트 _weather-rainy 및 제8 비주얼 프롬프트 _location-urban일 수 있다. 자율 주행 차량의 프로세서는 학습된 비주얼 프롬프트들과 주행 영상을 합성하여 복 합 합성 영상을 생성할 수 있다. 프로세서가 복합 합성 영상을 생성할 때, 각각의 학습된 비주 얼 프롬프트마다 가중치를 다르게 부여할 수 있다. 예를 들어, 비오는 야간의 시내에서 자율 주행 차량이 주행하는데 가장 방해될 만한 요소에 가중치를 높게 부여할 수 있다. 일반적으로, 차량의 주행에 있어서 \"비\"는 주행 환경 및 객체 인식에 있어서 악영향을 미치는 요소이므로, 가중치를 높게 부여하여, 객체 인식의 정확도를 향상시킬 수 있다. 다음으로, \"시내\"는 차량의 주 행 및 객체 인식에 있어서 다양한 변수가 존재하는 환경이므로 가중치를 높게 부여할 수 있다. 프로세서 는 가중치를 부여하여 학습된 비주얼 프롬프트를 합성한 복합 합성 영상에 기초하여, 객체 인식을 수행할 수 있다. 다만, 학습된 비주얼 프롬프트들의 합성에 기재된 실시예처럼 세 개만 사용 할 수 있는 것은 아니고, 두 개 혹은 그 이상이 합성될 수 있다. 도 8을 참조하면, 프로세서는 주행 영상들(810,820)에 비주얼 프롬프트들을 합성하여 복합 합성 영상 (811,821)을 생성할 수 있다. 도 9는 일 실시 예에 따른 전자 장치의 블록도이다. 도 9를 참조하면, 일 실시예에 따른 전자 장치(예: 도 1의 자율 주행 차량 및 서버)는 프로세서 , 메모리, 및 출력 장치(예: 디스플레이)를 포함할 수 있다. 프로세서, 메모리, 및 출력 장치는 통신 버스를 통해 서로 연결될 수 있다. 전술한 과정에서, 설명의 편의를 위해 프로세 서는 자율 주행 차량에 포함된 것으로 서술했으나, 서버도 서버의 동작을 위해 전술한 적어도 하나의 방법 또는 적어도 하나 방법에 대응되는 알고리즘을 수행하기 위한 프로세서를 포함할 수 있다. 출력 장치는 프로세서에 의해 제공된 자율 주행에 관련한 상태 및 조작에 관한 사용자 입력을 수신하 는 사용자 인터페이스와 함께를 표시할 수 있다. 메모리는 프로세서에 의해 수행되는 객체 인식 모델, 센서 및 통신부로부터 획득한 데이터들 및 비주 얼 프롬프트들을 저장할 수 있다. 이 밖에도, 메모리는 상술한 프로세서의 처리 과정에서 생성되는 다양한 정보들을 저장할 수 있다. 이 밖에도, 메모리는 각종 데이터와 프로그램 등을 저장할 수 있다. 메모리는 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 메모리는 하드 디스크 등과 같은 대용량 저장 매체를 구비하여 각종 데이터를 저장할 수 있다. 또한, 프로세서는 도 1 내지 도 8을 통해 전술한 적어도 하나의 방법 또는 적어도 하나의 방법에 대응되는 알고리즘을 수행할 수 있다. 전술한 과정에서, 프로세서는 자율 주행 차량에 포함된 것으로 서술했 으나, 서버도 서버의 동작을 위해 전술한 적어도 하나의 방법 또는 적어도 하나 방밥에 대응되는 알고리즘 을 수행하기 위한 프로세서를 포함할 수 있다. 프로세서는 목적하는 동작들(desired operations)을 실행시키기 위한 물리적인 구조를 갖는 회로를 가지는 하드웨어로 구현된 데이터 처리 장치일 수 있다. 예를 들어, 목적하는 동작들은 프로그램에 포함된 코드(code) 또는 인스트럭션들(instructions)을 포함할 수 있다. 프로세서는 예를 들어, CPU(Central Processing Unit), GPU(Graphics Processing Unit), 또는 NPU(Neural network Processing Unit)으로 구성될 수 있다. 예를 들어, 하드웨어로 구현된 전자 장치는 마이크로프로 세서(microprocessor), 중앙 처리 장치(central processing unit), 프로세서 코어(processor core), 멀티-코어 프로세서(multi-core processor), 멀티프로세서(multiprocessor), ASIC(Application-Specific IntegratedCircuit), FPGA(Field Programmable Gate Array)를 포함할 수 있다. 프로세서는 프로그램을 실행하고, 전자 장치를 제어할 수 있다. 프로세서에 의하여 실행되는 프로그램 코드는 메모리에 저장될 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2023-0140474", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0140474", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2023-0140474", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 자율 주행 차량의 객체 인식을 설명하기 위한 블록도이다. 도 2는 일 실시예에 따른 자율 주행 차량의 프로세서의 동작을 설명하기 위한 흐름도이다. 도 3은 일 실시예에 따른 서버의 동작을 설명하기 위한 흐름도이다. 도 4는 일 실시예에 따른 자율 주행 자동차에 탑재된 센서들을 개략적으로 도시한 것이다. 도 5는 일 실시예에 따른 비주얼 프롬프트를 설명하기 위해 개략적으로 도시한 도면이다. 도 6 내지 도 8은 일 실시예에 따른 복합 합성 영상을 설명하기 위한 개략적인 도면이다. 도 9는 일 실시 예에 따른 전자 장치의 블록도이다."}
