{"patent_id": "10-2018-0005820", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0087711", "출원번호": "10-2018-0005820", "발명의 명칭": "영상 전처리 방법, 장치 및 컴퓨터 프로그램", "출원인": "오드컨셉 주식회사", "발명자": "정태영"}}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "임의의 영상을 처리하는 방법에 있어서,상기 영상을 하나 이상의 프레임을 포함하는 장면(scene) 단위로 구분하는 단계;상기 장면에서 기 설정된 기준에 따른 검색 대상 프레임을 선정하는 단계;상기 검색 대상 프레임에서 기 설정된 주제와 관련된 객체를 식별하는 단계;상기 객체에 대응되는 이미지 또는 객체 정보 중 적어도 하나를 검색하여 상기 객체에 검색 결과를 맵핑하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영상을 장면 단위로 구분하는 단계는상기 프레임의 컬러 스펙트럼을 식별하는 단계;연속하는 제1 프레임과 제2 프레임 사이의 상기 컬러 스펙트럼의 변화가 기 설정된 임계값 이상이면, 상기 제1프레임과 상기 제2 프레임의 장면을 구분하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 영상을 장면 단위로 구분하는 단계는상기 프레임에서 임의의 객체로 추정되는 특징 정보를 탐지하는 단계;제1 프레임에 포함된 제1 특징 정보가 연속하는 제2 프레임에 포함되는지 여부를 판단하는 단계;상기 제2 프레임에 상기 제1 특징 정보가 포함되어 있지 않으면 상기 제1 프레임과 상기 제2 프레임의 장면을구분하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 영상을 장면 단위로 구분하는 단계는연속하는 제1 프레임과 제2 프레임의 매칭율을 연산하는 단계;상기 매칭율이 기 설정된 값 미만이면 상기 제1 프레임과 상기 제2 프레임의 장면을 구분하는 단계를 포함하는영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 공개특허 10-2019-0087711-3-상기 영상을 장면 단위로 구분하는 단계는상기 프레임의 주파수 스펙트럼을 식별하는 단계;연속하는 제1 프레임과 제2 프레임 사이의 상기 주파수 스펙트럼의 변화가 기 설정된 임계값 이상이면, 상기 제1 프레임과 상기 제2 프레임의 장면을 구분하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 영상을 장면 단위로 구분하는 단계는상기 프레임 각각을 기 설정된 크기의 하나 이상의 영역으로 분할하는 단계;상기 영역 별로 컬러 스펙트럼 또는 주파수 스펙트럼을 식별하는 단계;연속하는 제1 프레임과 제2 프레임에 있어서 서로 대응되는 영역의 상기 컬러 스펙트럼의 차이 또는 상기 주파수 스펙트럼의 차이를 연산하는 단계;상기 영역 별로 연산된 차이의 절대값을 합산하는 단계;상기 합산한 결과 값이 기 설정된 임계값 이상이면, 상기 제1 프레임과 상기 제2 프레임의 장면을 구분하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 영상을 장면 단위로 구분하는 단계는상기 프레임 각각을 기 설정된 크기의 하나 이상의 영역으로 분할하는 단계;연속하는 제1 프레임과 제2 프레임에 있어서 서로 대응되는 영역별 매칭율을 연산하는 단계;상기 매칭율의 평균이 기 설정된 값 미만이면, 상기 제1 프레임과 상기 제2 프레임의 장면을 구분하는 단계를포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 검색 대상 프레임을 선정하는 단계는상기 프레임에서 블러 영역을 식별하는 단계;상기 블러 영역이 상기 프레임에서 차지하는 비중을 연산하는 단계;제1 장면에 포함되는 하나 이상의 프레임 중 상기 블러 영역의 비중이 가장 낮은 프레임을 상기 제1 장면의 검색 대상 프레임으로 선정하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 블러 영역을 식별하는 단계는상기 프레임에서 로컬 디스크립터가 추출되지 않는 영역을 블러 영역으로 식별하는 단계를 포함하는 영상 처리방법.공개특허 10-2019-0087711-4-청구항 10 제1항에 있어서, 상기 검색 대상 프레임을 선정하는 단계는상기 프레임에서 특징 정보를 추출하는 단계;제1 장면에 포함되는 하나 이상의 프레임 중 추출된 특징 정보가 가장 많이 포함된 프레임을 상기 제1 장면의검색 대상 프레임으로 선정하는 단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 이용한 전자 장치의 객체 정보 제공 방법에 있어서, 제1항 내지 제10항 중 어느 한 항의 방법을 이용하여 처리된 영상을 재생하는 단계;사용자로부터 기 설정된 선택 명령을 입력받으면, 상기 선택 명령이 입력된 시점의 프레임을 획득하는 단계;상기 프레임에 포함된 객체에 맵핑된 객체 정보를 화면에 표시하는 단계를 포함하는 객체 정보 제공 방법."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 이용하여 객체 정보를 제공하는 장치에 있어서,제1항 내지 제10항 중 어느 한 항의 방법을 이용하여 처리된 영상을 출력하는 출력부;사용자로부터 기 설정된 선택 명령을 입력받는 입력부;상기 영상에서 상기 선택 명령이 입력된 시점의 프레임을 획득하고, 상기 프레임에 포함된 객체를 식별하는 제어부를 포함하며,상기 출력부는 상기 식별된 객체에 맵핑된 객체 정보를 출력하는 객체 정보 제공 장치."}
{"patent_id": "10-2018-0005820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제10항의 방법 중 어느 한 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능 매체에 저장된 영상처리 응용 프로그램."}
{"patent_id": "10-2018-0005820", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 영상 전처리 방법, 장치 및 컴퓨터 프로그램에 관한 것이다. 본 발명은 임의의 영상을 처리하는 방법 에 있어서, 상기 영상을 하나 이상의 프레임을 포함하는 장면(scene) 단위로 구분하는 단계, 상기 장면에서 기 설정된 기준에 따른 검색 대상 프레임을 선정하는 단계, 상기 검색 대상 프레임에서 기 설정된 주제와 관련된 객 체를 식별하는 단계, 상기 객체에 대응되는 이미지 또는 객체 정보 중 적어도 하나를 검색하여 상기 객체에 검색 결과를 맵핑하는 단계를 포함하는 것을 일 특징으로 한다. 본 발명에 의하면 객체 기반 이미지 검색의 효율성을 극대화하고, 영상 처리에 사용되는 리소스를 최소화할 수 있다."}
{"patent_id": "10-2018-0005820", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 전처리 방법, 장치 및 컴퓨터 프로그램에 관한 것으로, 보다 자세하게는 영상에 포함된 객체의 검색을 용이하게 하기 위한 영상 전처리 방법, 장치 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2018-0005820", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지, 비디오 등 멀티미디어 서비스의 수요가 증가하고 휴대용 멀티미디어 기기가 보편적으로 보급되면서 방 대한 양의 멀티미디어 데이터를 관리하고 소비자가 원하는 컨텐츠를 빠르고 정확하게 찾아내 제공하는 효율적인 멀티미디어 검색 시스템의 필요성도 커지고 있다. 종래에는 영상에 포함된 상품 객체와 유사 상품 정보를 제공하는 서비스에서 이미지 검색을 수행하기 보다는 영 상 내 상품 객체를 관리자가 별도로 정의하고 이를 포함하는 영상을 제공하는 방식을 더 많이 사용하였다. 이러 한 방식은 특정 영상에 포함된 객체 중 관리자가 지정한 객체에 대해서만 유사 상품의 확인이 가능하다는 점에 서 소비자의 니즈를 충족시키는 데 한계가 있다. 다만, 영상에 포함된 상품 객체에 대해 일일이 검색을 수행하려면 데이터 처리량이 너무 방대해지는 문제가 있 다. 또한 영상은 하나 이상의 프레임(이미지)으로 이루어져있으며, 각 프레임은 복수의 객체를 포함하기 때문에 수많은 객체 중 어떤 객체를 쿼리 이미지로 정의할 것인지에 대한 문제도 있다. 영상에 포함된 객체를 식별하기 위한 기술로 한국공개특허 제10-2008-0078217호 (발명의 명칭: 영상에 포함된 객체 색인 방법과 그 색인 정보를 이용한부가 서비스 방법 및 그 영상 처리 장치, 공개일: 2008.08.27.)이 있다. 위 선행문헌은 특정 영상에 포함된 객체의 인식을 위해 영상에 포함된 객체의 상대적인 위치를 관리하고 저장하기 위한 가상의 프레임과 셀을 관리함으로써, 표시 장치 상에서 시청자가 지정한 위치의 객체를 정확하게 판단할 수 있도록 하는 방법을 제공하고 있다. 그러나 위 선행문헌은 객체를 식별하는 방법 중 하나를 개시하고 있을 뿐, 검색을 효율적으로 수행하기 위해 영 상 처리에 요구되는 리소스를 줄이는 문제에 대해서는 인식하고 있지 않다. 따라서 영상 처리에 요구되는 리소 스를 최소화하고 검색 정확도 및 효율성을 높일 수 있는 방안이 요구된다."}
{"patent_id": "10-2018-0005820", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위한 것으로서, 영상에 포함된 객체 중 검색이 필요한 객체를 빠르고 정확 하게 식별하는 것을 일 목적으로 한다. 또한 본 발명은 객체 기반 이미지 검색의 효율성을 극대화하고, 영상 처리에 사용되는 리소스를 최소화할 수 있 는 영상 처리 방법을 제공하는 것을 다른 목적으로 한다. 또한 본 발명은 영상을 시청하는 소비자가 필요로 하는 정보를 정확하게 제공하고, 영상 제공자 중심의 정보 제 공이 아니라 사용자 중심의 정보 제공이 이루어질 수 있도록 영상을 처리하는 것을 다른 목적으로 한다."}
{"patent_id": "10-2018-0005820", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이러한 목적을 달성하기 위한 본 발명은 임의의 영상을 처리하는 방법에 있어서, 상기 영상을 하나 이상의 프레 임을 포함하는 장면(scene) 단위로 구분하는 단계, 상기 장면에서 기 설정된 기준에 따른 검색 대상 프레임을 선정하는 단계, 상기 검색 대상 프레임에서 기 설정된 주제와 관련된 객체를 식별하는 단계, 상기 객체에 대응 되는 이미지 또는 객체 정보 중 적어도 하나를 검색하여 상기 객체에 검색 결과를 맵핑하는 단계를 포함하는 것 을 일 특징으로 한다."}
{"patent_id": "10-2018-0005820", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 바와 같은 본 발명에 의하면, 영상에 포함된 객체 중 검색이 필요한 객체를 빠르고 정확하게 식별할 수 있다. 또한 본 발명에 의하면 객체 기반 이미지 검색의 효율성을 극대화하고, 영상 처리에 사용되는 리소스를 최소화 할 수 있다. 또한 본 발명에 의하면 영상을 시청하는 소비자가 필요로 하는 정보를 정확하게 제공할 수 있으며, 영상 제공자 중심의 정보 제공이 아니라 사용자 중심의 정보 제공이 가능하다."}
{"patent_id": "10-2018-0005820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한 목적, 특징 및 장점은 첨부된 도면을 참조하여 상세하게 후술되며, 이에 따라 본 발명이 속하는 기술 분 야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 본 발명을 설명함 에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 상세한 설명을 생략한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시 예를 상세히 설명하기로 한다. 도면에서 동일한 참조부호는 동일 또는 유사한 구성요소를 가리키는 것으로 사용되며, 명세서 및 특허청구의 범위에 기재된 모든 조합은 임의의 방식으로 조합될 수 있다. 그리고 다른 식으로 규정하 지 않는 한, 단수에 대한 언급은 하나 이상을 포함할 수 있고, 단수 표현에 대한 언급은 또한 복수 표현을 포함 할 수 있음이 이해되어야 한다. 도 1은 본 발명의 일 실시 예에 따른 객체 정보 제공 장치를 설명하기 위한 블록도이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 객체 정보 제공 장치는 영상 재생부, 입력부, 객체 식별부, 출 력부를 포함한다. 객체 정보 제공 장치는 컴퓨터, 노트북, 또는 태블릿, 스마트폰과 같은 휴대용 단말기일 수 있다. 나아가 객체 정보 제공 장치는 유무선 네트워크를 이용해 서버로부터 데이터를 수신하고 사용자 입력에 따라 수신 된 데이터를 제어, 관리 또는 출력하는 단말로, 인공지능 스피커, 셋톱박스(Set-Top Box)의 형태로 구현될 수 있다. 통신부는 서버로부터 본 발명의 일 실시 예에 따른 영상 처리 방법을 이용하여 처리된 영상을 수신할 수 있다. 출력부는 본 발명의 일 실시 예에 따른 영상 처리 방법을 이용하여 처리된 영상을 디스플레이 모듈(미도시)로 출력할 수 있다. 출력부가 출력하는 영상은 통신부로부터 수신한 것일 수 있으나 데 이터베이스(미도시)에 미리 저장된 것일 수 있다. 만약 객체 정보 제공 장치 내에서 본 발명의 일 실시 예에 따 른 영상 처리가 이루어진 경우, 출력부는 영상 처리 장치로부터 처리된 영상을 수신하여 출력할 수 있다. 본 발명의 일 실시 예에 따른 영상 처리 방법에 대한 자세한 설명은 도 3 내지 도 11을 이용하여 후술하기로 한 다. 본 발명의 일 실시 예에 따라 처리된 영상에는 영상 내에 포함되어 있는 객체들에 대한 정보가 맵핑되어 있 는데, 출력부는 사용자 설정에 따라서 영상을 재생하면서 객체 정보를 함께 표시할 수도 있고, 오리지널 영상을 재생하다가 사용자 입력이 수신되었을 때 맵핑된 객체 정보를 표시할 수 있다. 출력부는 디스플레 이 모듈로 전송되는 영상을 편집 및 관리하며, 이하에서는 사용자 입력이 수신되었을 때 객체 정보를 표시하는 경우의 일 실시 예를 설명한다. 입력부는 사용자로부터 기 설정된 선택 명령을 입력받는다. 입력부는 사용자로부터 정보를 입력받기 위한 것으로서, 입력부는 기계식 (mechanical) 입력수단(또는, 메커니컬 키, 예를 들어, 이동 단말기(10 0)의 전·후면 또는 측면에 위치하는 버튼, 돔 스위치(dome switch), 조그 휠, 조그 스위치 등) 및 터치식 입력 수단을 포함할 수 있다. 일 예로서, 터치식 입력수단은, 소프트웨어적인 처리를 통해 터치스크린에 표시되는 가 상 키(virtual key), 소프트 키(soft key) 또는 비주얼 키(visual key)로 이루어지거나, 상기 터치스크린 이외 의 부분에 배치되는 터치 키(touch key)로 이루어질 수 있다. 한편, 상기 가상키 또는 비주얼 키는, 다양한 형 태를 가지면서 터치스크린 상에 표시되는 것이 가능하며, 예를 들어, 그래픽(graphic), 텍스트(text), 아이콘(icon), 비디오(video) 또는 이들의 조합으로 이루어질 수 있다. 또한 입력부는 외부의 음향 신호를 전기적인 음성 데이터로 처리하는 마이크로폰일 수 있다. 마이크로폰으 로 객체 정보 제공 장치를 활성화시키는 음성 또는 기 설정된 음성 명령이 입력되면 입력부는 선택 명령이 수신된 것으로 판단할 수 있다. 예를 들어, 객체 정보 제공 장치의 닉네임이 ‘테리’이고, ‘하이 테리’라는 음성이 입력되면 객체 정보 제공 장치가 활성화되도록 설정될 수 있다. 만일 활성화 음성을 선 택 명령으로 설정한 경우, 영상 출력 중 사용자의 ‘하이 테리’라는 음성이 입력부를 통해 수신되면, 제 어부는 입력된 시점의 프레임을 캡처하는 선택 명령이 수신된 것으로 판단하여 해당 시점의 프레임을 캡쳐 할 수 있다. 또한 입력부는 카메라 모듈을 포함할 수 있다. 이 경우 기 설정된 선택 명령은 카메라 모듈을 통해 인식되 는 사용자 제스처일 수 있으며, 카메라 모듈을 통해 미리 설정된 제스처가 인식되면 제어부는 이를 선택 명령으로 인지할 수 있다. 제어부는 영상에서 선택 명령이 입력된 시점의 프레임을 획득하고, 획득한 프레임에 포함된 객체를 식별할 수 있다. 프레임은 디스플레이 장치에 출력되고 있는 영상의 스크린샷일 수 있으며, 선택 명령이 입력된 시점의 전후 기 설정된 범위 내에 포함되는 다수의 프레임 중 하나 일 수 있다. 이 경우, 입력 시점을 중심으로 일정 범위 내의 프레임 중 어느 하나를 선택하는 것은, 후술하는 검색 대상 프레임의 선정 방법과 유사할 수 있다. 제어부는 사용자 선택 입력에 대응되는 프레임으로부터 객체를 식별하면, 해당 객체에 맵핑된 객체 정보를 확인하여 출력부로 전송할 수 있다. 출력부는 확인된 객체 정보를 출력할 수 있는데, 디스플레이 장 치를 통해 표시되는 방식에는 특별한 제한이 없다. 도 2는 본 발명의 일 실시 예에 따른 전자 장치의 객체 정보 제공 방법을 설명하기 위한 순서도이다. 도 2를 참 조하면, 먼저 본 발명의 일 실시 예에 따른 영상 처리가 이루어진다(S1000). 영상 처리는 서버에서 이루어질 수 있으며, 전자 장치 내에서 이루어질 수도 있다. 영상 처리가 서버에서 이루어진 경우, 전자 장치는 서버로부터 처리된 영상을 수신하여 이를 재생할 수 있다. 단계 1000에 대한 자세한 설명은 도 3을 통해 후술한다. 전자 장치는 처리된 영상을 재생하며(S2000), 사용자로부터 기 설정된 선택 명령을 입력받으면 선택 명령이 입 력된 시점의 프레임을 획득할 수 있다(S4000). 그리고 프레임에 포함된 객체에 맵핑된 객체 정보를 화면에 표시 할 수 있다(S5000). 객체 정보는 처리된 영상에 포함되는 것으로, 단계 3000에서 사용자 요청에 대응되는 선택 명령이 입력되면 화면에 표시될 수 있다. 다른 실시 예로, 전자 장치는 처리된 영상을 재생하면서 사용자의 선택 명령과 무관하게 각 객체에 맵핑된 객체 정보를 함께 표시할 수도 있다. 도 3은 본 발명의 일 실시 예에 따른 전자 장치의 영상 처리 방법을 설명하기 위한 순서도이다. 이하에서는 설 명의 편의를 위하여 서버가 영상을 처리하는 실시 예를 중심으로 설명한다. 도 3을 참조하면, 서버는 객체 정보를 제공하기 위해 영상을 처리함에 있어서, 영상을 하나 이상의 프레임을 포 함하는 장면(scene) 단위로 구분할 수 있다(S100). 도 4를 참조하여 영상을 장면 단위로 구분하는 단계 100의 일 실시 예를 살펴본다. 장면(Scene)은 유사한 주제 또는 사건과 관련된 영상의 일 단위로, 사전적으로는 영화, 연극, 문학 작품의 한 정경을 의미한다. 본 명세서 에서 영상을 구분하는 장면 단위 역시 하나의 사건 또는 주제와 관련된 하나 이상의 프레임을 의미하는 것으로 이해될 수 있다. 즉, 일 장면은 공간 또는 인물의 변화가 급격하지 않아, 영상 내에 포함되는 객체가 (움직이는 것을 제외하) 프레임 내에서 큰 변화없이 유지될 수 있다. 본 발명은 영상을 장면 단위로 구분하고, 장면 중 어 느 하나의 프레임만을 선택하여 이미지 분석에 활용함으로써 분석해야 하는 데이터 량을 현저히 줄인다. 예를 들어, 프레임 단위로 객체를 트래킹(tracking)하는 경우, 너무 많은 리소스를 소모하게 되는 문제가 있다. 일반적으로 영상은 초당 20~60개 정도의 프레임을 사용하며, 초당 프레임 수(FPS: Frame Per Second)는 전자 장 치의 성능이 개선되면서 점점 증가하는 추세에 있다. 초당 50개의 프레임이 사용된다고 하면, 10분짜리 영상은 3만개의 프레임으로 이루어진다. 프레임 단위의 객체 트래킹은 3만개 프레임 각각에 어떤 객체들이 포함되어 있 는지를 일일이 분석해야 하는 것을 의미하므로, 기계 학습을 이용하여 프레임 내 객체의 특징을 분석하더라도 처리 용량이 너무 커지는 문제가 있다. 따라서 서버는 다음과 같은 방식으로 영상을 장면 단위로 구분함으로써처리 용량을 줄이고 처리 속도를 높일 수 있다. 서버는 단계 100에서 프레임의 컬러 스펙트럼을 식별하고(S113), 연속하는 제1 프레임과 제2 프레임 사이의 컬 러 스펙트럼의 변화가 기 설정된 임계값 이상인지 여부를 판단하여(S115) 컬러 스펙트럼의 변화가 기 설정된 임 계값 이상이면, 제1 프레임과 제2 프레임의 장면을 구분할 수 있다(S117). 만약 연속하는 두 프레임 간 컬러 스 펙트럼의 변화가 없다면, 다음 프레임에 대하여 단계 115의 판단을 다시 수행할 수 있다. 단계 100의 또 다른 실시 예로, 서버는 프레임에서 임의의 객체로 추정되는 특징 정보를 탐지(detect)하고, 제1 프레임에 포함된 제1 특징 정보가 연속하는 제2 프레임에 포함되는지 여부를 판단할 수 있다. 서버는 제2 프레 임에 제1 특징 정보가 포함되어 있지 않으면 제1 프레임과 제2 프레임의 장면을 구분할 수 있다. 즉, 임의의 객 체로 추정되는 특징 정보가 포함되어 있는 프레임들을 일 장면으로 설정하되, 특정 프레임에서 해당 특징 정보 가 더 이상 포함되지 않으면, 그 프레임부터 다른 장면으로 구분할 수 있다. 탐지(detect)는 인식(recognition) 내지 식별(identify)와는 상이한 개념으로, 객체의 이미지 내 존재 여부를 찾기 위한 것이라는 점에서 객체가 어떤 객체인지 식별하는 인식보다는 한 단계 낮은 수준의 작업이라고 할 수 있다. 보다 구체적으로, 임의의 객 체로 추정되는 특징 정보의 탐지는 객체(object)와 배경 간 경계 등을 이용하여 물체인지 아닌지 구분하거나 글 로벌 디스크립터를 이용할 수 있다. 단계 100의 또 다른 실시 예로, 도 5를 참조하면, 서버는 연속하는 제1 프레임과 제2 프레임의 매칭율을 연산하 고(S133), 매칭율이 기 설정된 값 미만인지 여부를 판단할 수 있다(S135). 매칭율은 두 프레임 간 이미지의 매 칭 정도를 나타내는 지표로, 배경이 중복된다든지, 프레임에 포함된 인물이 동일한 경우에는 매칭율이 높아질 수 있다. 예를 들어, 영화나 드라마와 같은 영상에서 같은 인물이 동일한 공간 안에서 벌이는 사건과 관련된 연속되는 프 레임들은 인물과 공간이 매칭되기 때문에 매칭율이 매우 높게 나타날 것이며, 따라서 위 프레임들은 동일한 장 면으로 분류될 수 있다. 서버는 단계 135에서의 판단 결과 매칭율이 기 설정된 값 미만이면 제1 프레임과 제2 프레임의 장면을 구분할 수 있다. 즉, 영상에 표시되는 공간이 변화되었다든지 등장 인물이 변화되는 경우에는 연속되는 프레임 간 매칭율이 현저하게 떨어지므로, 서버는 이러한 경우 장면 전환이 이루어진 것으로 판단하여 각 프레임의 장면을 구분할 수 있으며 제1 프레임은 제1 장면에 제2 프레임은 제2 장면으로 설정될 수 있다. 단계 100의 또 다른 실시 예로, 도 6을 참조하면, 서버는 각 프레임의 주파수 스펙트럼을 식별하고(S153), 연속 하는 제1 프레임과 제2 프레임 사이의 상기 주파수 스펙트럼의 변화가 기 설정된 임계값 이상이면(S155), 상기 제1 프레임과 상기 제2 프레임의 장면을 구분할 수 있다(S157). 단계 153에서 서버는 DCT(Discrete Cosine Transform), DST(Discrete Sine Transform), DFT(Discrete Fourier Transform), MDCT(Modified DCT, Modulated Lapped Transform) 등을 이용하여 각 프레임의 주파수 스펙트럼을 식별할 수 있다. 주파수 스펙트럼 은 프레임에 포함되는 이미지의 주파수 성분의 분포를 나타내는 것으로, 낮은 주파수 영역에는 전체적인 이미지 의 윤곽에 대한 정보를 나타내고 높은 주파수 영역에는 이미지의 세밀한 부분에 대한 정보를 나타내는 것으로 이해될 수 있다. 단계 155에서의 주파수 스펙트럼의 변화는 성분 별 크기 비교를 통해 측정 가능하다. 단계 100의 또 다른 실시 예로, 도 7을 참조하면, 서버는 프레임 각각을 기 설정된 크기의 하나 이상의 영역으 로 분할하고(S171), 영역 별로 컬러 스펙트럼 또는 주파수 스펙트럼을 식별할 수 있다(S173). 서버는 연속하는 제1 프레임과 제2 프레임에 있어서 대응되는 영역의 컬러 스펙트럼의 차이 또는 주파수 스펙트럼의 차이를 연산 하고(S175), 영역 별 차이의 절대값을 합산한다(S177). 그리고 합산한 결과 값이 기 설정된 임계값 이상이면, 제1 프레임과 제2 프레임의 장면을 구분할 수 있다. 또 다른 실시 예로, 도 8에 도시된 바와 같이 프레임 각각을 기 설정된 크기의 하나 이상의 영역으로 분할하고 (S183), 연속하는 제1 프레임과 제2 프레임에 있어서 대응되는 영역별 매칭율을 연산하고(S185), 상기 매칭율의 평균이 기 설정된 값 미만이면, 상기 제1 프레임과 상기 제2 프레임의 장면을 구분할 수 있다(S187). 도 7 및 도 8을 참고하여 상술한 예시와 같이 프레임을 하나 이상의 영역으로 분할하여, 전후 프레임을 영역 별 로 비교하면 프레임이 전체적으로는 비슷한데 부분적으로 차이가 많은 경우를 찾아낼 수 있다. 즉, 전술할 두 개 실시 예에 따르면 좀 더 세분화된 장면 구분이 가능하다. 단계 100의 다음 단계에서 서버는 장면에서 기 설정된 기준에 따른 검색 대상 프레임을 선정할 수 있다(S200). 본 명세서에서 검색 대상 프레임은 객체 기반 검색을 수행하기 위한 대상 객체를 포함하는 프레임을 의미하는 것으로 이해될 수 있다. 즉 본 발명의 일 실시 예에서 서버는 영상에 포함된 모든 프레임의 객체를 트래킹하고 분석하는 것이 아니라, 검색 대상 프레임을 지정하고, 검색 대상 프레임에 포함된 객체만 분석함으로써 리소스를 줄일 수 있다. 서버는 모든 프레임을 분석하는 것이 아니기 때문에 가장 검색 정확도를 높일 수 있는 객체를 추출하고자 하며, 따라서 단계 200에서 객체 기반 검색 시 가장 정확도 높은 검색 결과를 얻을 수 있는 프레임 을 검색 대상 프레임으로 선정할 수 있다. 일 예로 도 9를 참조하면, 서버는 검색 대상 프레임을 선정함에 있어서, 프레임에서 블러 영역을 식별하고 (S213), 블러 영역이 프레임에서 차지하는 비중을 연산할 수 있다(S215). 그리고 서버는 제1 장면에 포함되는 하나 이상의 프레임 중 블러 영역의 비중이 가장 낮은 프레임을 제1 장면의 검색 대상 프레임으로 선정할 수 있 다(S217). 블러 영역은 영상에서 흐릿하게 표시되는 영역으로 객체 검출이 불가능하거나 객체 기반 이미지 검색 의 정확도를 떨어뜨릴 수 있다. 블러 영역에는 객체성을 불분명하게 하는 픽셀이 다수 혼합될 수 있으며, 이러 한 픽셀은 객체를 검출하거나 분석함에 있어서 오류를 발생시킨다. 따라서 서버는 블러 영역의 비중이 가장 낮 은 프레임을 각 장면의 검색 대상 프레임으로 선정함으로써 이후 객체 검출 및 분석, 객체 기반 이미지 검색의 정확도를 높일 수 있도록 한다. 본 발명의 일 실시 예에서 서버는 프레임에서 로컬 디스크립터가 추출되지 않는 영역을 블러 영역으로 식별함으 로써 블러 영역을 검출할 수 있다. 로컬 디스크립터는 객체 이미지의 핵심 부분을 나타내는 특징 벡터로, SIFT, SURF, LBP, BRISK, MSER, FREAK 등 다양한 방식으로 추출 가능하다. 로컬 디스크립터는 객체 이미지 전체를 설 명하는 글로벌 디스크립터와 구별되며, 객체 인식과 같은 상위 수준의 응용 프로그램에서 사용되는 개념으로 본 명세서에서 로컬 디스크립터는 통상의 기술자에게 통용되는 의미로 사용되었다. 검색 대상 프레임을 선정하는 단계 200의 다른 실시 예로, 도 10을 참조하면, 서버는 프레임에서 프레임에서 특 징 정보를 추출하고(S233), 제1 장면에 포함되는 하나 이상의 프레임 중 추출된 특징 정보가 가장 많은 프레임 을 제1 장면의 검색 대상 프레임으로 선정할 수 있다(S235). 특징 정보는 글로벌 디스크립터와 로컬 디스크립터 를 모두 포함하는 개념으로, 객체의 윤곽, 형태, 텍스처 또는 특정 객체를 인식할 수 있는 특징점, 특징 벡터를 포함할 수 있다. 즉, 서버는 객체를 인식할 정도는 아니나, 객체가 존재한다는 것을 탐지할 수 있는 수준의 특징 정보를 추출하 고 특징 정보를 가장 많이 포함하고 있는 프레임을 검색 대상으로 지정할 수 있다. 그 결과 서버는 단계 300에 서 장면 별로 특징 정보를 가장 많이 포함하는 프레임을 이용하여 객체 기반 이미지 검색을 실시할 수 있으며, 모든 프레임에서 객체를 추출하지 않고도 누락되는 객체를 최소화하고, 높은 정확도로 객체를 검출, 활용할 수 있다. 단계 300에서 서버는 검색 대상 프레임에서 기 설정된 주제와 관련된 객체를 식별할 수 있다. 객체의 식별은 객 체의 특징 정보를 추출하는 동작을 통해 이루어질 수 있다. 본 단계에서 서버는 이전 단계(S100, S200)에서 이 루어진 객체의 탐지보다 보다 상세하게 객체를 식별할 수 있다. 즉, 객체 식별 알고리즘에 있어서 보다 정확도 높은 알고리즘을 사용할 수 있으며, 따라서 검색 대상 프레임에서 누락되는 객체가 없도록 객체를 추출한다. 예를 들어, 드라마 영상을 처리하는 경우를 가정하자. 서버는 단계 100에서 드라마 영상에서 부엌에서 이루어지 는 하나 이상의 프레임을 일 장면으로 구분할 수 있으며, 단계 200에서 기 설정된 기준에 따른 검색 대상 프레 임을 선정할 수 있다. 도 11이 단계 200에서 선정된 검색 대상 프레임인 경우, 도 11의 프레임은 부엌에서 이루어지는 장면 중 블러 영역의 비중이 가장 낮아 검색 대상 프레임으로 선정된 것일 수 있으며, 해당 장면 중 탐지되는 객체의 수가 가 장 많아 선정된 것일 수 있다. 도 11의 검색 대상 프레임에는 냄비(K10, K40), 냉장고(K20, K30) 등의 주방 가 전/기구과 관련된 객체가 포함되어 있으며, 상의(C10), 치마(C20), 원피스(C30)와 같은 의류 관련 객체도 포함 되어 있다. 단계 300에서 서버는 상기 객체들(K10 내지 K40, C10 내지 C30)을 검색 대상 프레임에서 식별한다. 이 때 서버는 기 설정된 주제와 관련된 객체를 식별할 수 있다. 도 11에 도시된 바와 같이 검색 대상 프레임 내 에는 무수히 많은 객체들이 탐지될 수 있는데, 서버는 기 설정된 주제와 관련된 객체를 식별함으로써 필요한 정 보만 추출할 수 있따. 예를 들어, 미리 설정된 주제가 의류인 경우 서버는 검색 대상 프레임에서 의류와 관련된 객체만 식별할 수 있으며, 이 경우 상의(C10), 치마(C20), 원피스(C30) 등을 식별할 수 있다. 만일 미리 설정된 주제가 주방 가전/기구인 경우에는 K10, K20, K30, K40을 식별할 것이다. 여기서 ‘주제’는 객체를 구별하는 카테고리를 의미하는 것으로, 사용자 설정에 따라 임의의 객체를 정의하는 카테고리는 상위 개념일 수도 있고, 하위 개념일 수도 있다. 예를 들어, 주제는 의류와 같은 상위 개념으로 설정될 수도 있으나, 치마, 원피스, 티 셔츠와 같은 하위 개념으로 설정될 수도 있다. 주제를 설정하는 주체는 서버를 관리하는 관리자일 수도 있으며, 사용자일 수 있다. 주제가 사용자에 의해 정해 지는 경우, 서버는 사용자 단말로부터 주제에 대한 정보를 수신하고, 수신된 주제 정보에 따라 검색 대상 프레 임에서 객체를 식별할 수 있다. 다음으로 서버는 단계 400에서 식별된 객체에 대응되는 이미지 또는 객체 정보 중 적어도 하나를 검색하고, 단 계 500에서 객체에 검색 결과를 맵핑할 수 있다. 예를 들어, 의류와 관련된 객체가 식별된 경우, 서버는 이미지 데이터베이스에서 식별된 상의(C10)과 유사한 이미지를 검색하여 상의(C10)에 대응되는 이미지를 획득할 수 있 다. 또한 서버는 데이터베이스에서 상의(C10)와 관련된 객체 정보, 즉 검은색에 흰색 사선 무늬가 프린팅 되어 있는 상의와 관련된 광고 이미지 및/또는 영상, 가격, 브랜드 이름명 구입 가능 온라인/오프라인 매장 등의 객 체 정보를 획득할 수 있다. 이 때 데이터베이스는 미리 생성되어 서버 내에 포함될 수도 있으나, 웹페이지 등을 크롤링하여 실시간으로 데이터베이스가 실시간 유사 이미지 검색을 통해 구축되는 것일 수 있으며, 서버가 외부 에 구축된 데이터베이스를 이용하여 검색을 수행할 수도 있다. 검색 결과, 즉 상기 식별된 객체에 대응되는 이미지, 객체에 대응되는 상품 정보(가격, 브랜드명, 상품명, 상 품 코드, 상품 종류, 상품 특징, 구매처 등), 광고 텍스트, 광고 영상, 광고 이미지 등은 식별된 객체에 맵핑될 수 있으며, 이렇게 맵핑된 검색 결과는 영상 재생 시, 영상에 인접한 레이어에 표시되거나, 영상 내 또는 영상 의 상위 레이어에 표시될 수 있다. 또는 영상 재생 시 사용자 요청에 대응하여 검색 결과가 표시될 수도 있다. 본 명세서에서 생략된 일부 실시 예는 그 실시 주체가 동일한 경우 동일하게 적용 가능하다. 또한, 전술한 본 발명은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 있어 본 발명의 기술적 사상을 벗어나지 않 는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로 전술한 실시 예 및 첨부된 도면에 의해 한정되는 것이 아니다."}
{"patent_id": "10-2018-0005820", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 객체 정보 제공 장치를 설명하기 위한 블록도, 도 2는 본 발명의 일 실시 예에 따른 객체 정보 제공 방법을 설명하기 위한 순서도, 도 3은 본 발명의 일 실시 예에 따른 영상 처리 방법을 설명하기 위한 순서도, 도 4 내지 8은 본 발명의 일 실시 예에 따른 영상의 장면 단위 구분 방법을 설명하기 위한 순서도, 도 9는 본 발명의 일 실시 예에 따른 검색 대상 프레임 선정 방법을 설명하기 위한 순서도, 도 10은 본 발명의 다른 실시 예에 따른 검색 대상 프레임 선정 방법을 설명하기 위한 순서도, 도 11은 본 발명의 일 실시 예에 따라 영상에서 식별되는 객체를 도시한 도면이다."}
