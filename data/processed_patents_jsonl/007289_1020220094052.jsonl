{"patent_id": "10-2022-0094052", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0016032", "출원번호": "10-2022-0094052", "발명의 명칭": "음성 인식 기능을 위한 전처리 모델 구축 시스템 및 전처리 모델 구축 방법", "출원인": "현대자동차주식회사", "발명자": "이용혁"}}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "타겟 음성 인식 모델을 이용하여, 학습용 음성 데이터에 대한 음성 인식률을 획득하는 학습 데이터 준비부;상기 학습용 음성 데이터에서 노이즈가 제거된 클린 음성 데이터에 대한 상기 타겟 음성 인식 모델의 예상 인식률을 추정하는 인식률 예측 모델; 및상기 학습용 음성 데이터를 전처리하여 상기 클린 음성 데이터를 획득하고, 상기 예상 인식률과 최대 인식률 간의 차이에 해당하는 인식률 손실을 바탕으로, 상기 음성 전처리 모델을 업데이트하는 음성 전처리 모델;을 포함하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 학습 데이터 준비부는노이즈가 없는 발화 정답에 노이즈 및 룸 임펄스 응답 정보를 믹싱하여 상기 학습용 음성 데이터를 생성하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 학습 데이터 준비부는복수의 공간에 대응하는 복수의 학습용 음성 데이터를 생성하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 학습 데이터 준비부는상기 타겟 음성 인식 모델이 상기 학습용 음성 데이터를 학습한 학습 결과와 상기 발화 정답 간의 차이를 계산하여 학습용 음성 인식률을 획득하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 인식률 예측 모델은상기 학습용 음성데이터를 학습하여, 상기 타겟 음성 인식 모델에 대한 예상 음성인식률을 산출하고, 상기 타겟음성 인식 모델에 대한 학습용 상기 음성 인식률을 바탕으로, 상기 인식률 예측 모델을 업데이트 하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템.공개특허 10-2024-0016032-3-청구항 6 제 5 항에 있어서,상기 인식률 예측 모델은 상기 학습용 음성 데이터의 예상 음성 인식률과 상기 타겟 음성 인식 모델을 이용하여 획득된 상기 학습용 음성인식률 간의 차이를 계산하여 인식률 편차를 획득하고, 상기 인식률 편차를 바탕으로 업데이트를 수행하는 것을특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 인식률 예측 모델은 상기 인식률 편차를 줄이는 방향으로 상기 업데이트를 수행하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 음성 전처리 모델은인공지능 기반으로 상기 학습용 음성 데이터의 음성 특징을 학습하고, 학습된 상기 음성 특징을향상시킴으로써, 상기 클린 음성 데이터를 획득하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 음성 전처리 모델은후속 전처리 과정에서 상기 예상 인식률을 높일 수 있도록 업데이트를 수행하는 것을 특징으로 하는 음성 인식기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 15 항에 있어서,상기 음성 전처리 모델은 상기 인식률 예측 모델의 업데이트가 진행되지 않는 상태에서 업데이트를 수행하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델 구축 시스템."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "타겟 음성 인식 모델을 이용하여, 학습용 음성 데이터에 대한 음성 인식률을 획득하는 단계;음성 전처리 모델을 이용하여, 상기 학습용 음성 데이터를 전처리하여 노이즈가 제거된 클린 음성 데이터 획득하는 단계;인식률 예측 모델을 이용하여, 상기 클린 음성 데이터의 예상 인식률을 추정하는 단계; 및공개특허 10-2024-0016032-4-상기 예상 인식률과 최대 인식률 간의 차이에 해당하는 인식률 손실을 바탕으로, 상기 음성 전처리 모델을 업데이트하는 단계;를 포함하는 음성 인식 기능을 위한 전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,타겟 음성 인식 모델을 이용하여, 상기 음성 인식률을 획득하는 단계는 노이즈가 없는 발화 정답에 노이즈 및 룸 임펄스 응답 정보를 믹싱하여 상기 학습용 음성 데이터를 생성하는 단계를 포함하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 학습용 음성 데이터를 생성하는 단계는복수의 공간에 대응하는 복수의 학습용 음성 데이터를 생성하는 단계를 포함하는 것을 특징으로 하는 음성 인식기능을 위한 전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12 항에 있어서,타겟 음성 인식 모델을 이용하여, 상기 음성 인식률을 획득하는 단계는상기 타겟 음성 인식 모델이 상기 학습용 음성 데이터를 학습한 학습 결과와 상기 발화 정답 간의 차이를 계산하여 학습용 음성 인식률을 획득하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 인식률 예측 모델이 상기 학습용 음성데이터를 학습하여, 상기 타겟 음성 인식 모델에 대한 예상 음성인식률을 산출하는 단계; 및상기 타겟 음성 인식 모델에 대한 상기 학습용 음성인식률을 바탕으로, 상기 인식률 예측 모델을 업데이트 하는단계를 더 포함하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 인식률 예측 모델을 업데이트 하는 단계는상기 학습용 음성 데이터의 예상 음성 인식률과 상기 타겟 음성 인식 모델을 이용하여 획득된 상기 학습용 음성인식률 간의 차이를 계산하여 인식률 편차를 획득하는 단계; 및상기 인식률 편차를 상기 인식률 예측 모델에 역전파하는 단계;를 포함하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델의 구축 방법.공개특허 10-2024-0016032-5-청구항 17 제 16 항에 있어서,상기 인식률 예측 모델을 업데이트 하는 단계는, 상기 인식률 편차를 줄이는 방향으로 수행되는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델의 구축방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 11 항에 있어서,음성 전처리 모델을 이용하여, 상기 학습용 음성 데이터를 전처리하여 노이즈가 제거된 클린 음성 데이터 획득하는 단계는인공지능 기반으로 상기 학습용 음성 데이터의 음성 특징을 학습하고, 학습된 상기 음성 특징을 향상시키는 단계를 포함하는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 11 항에 있어서,상기 음성 전처리 모델을 업데이트 하는 단계는 후속 전처리 과정에서 상기 예상 인식률을 높일 수 있도록 진행되는 것을 특징으로 하는 음성 인식 기능을 위한전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 15 항에 있어서,상기 음성 전처리 모델을 업데이트 하는 단계는 상기 인식률 예측 모델의 업데이트가 진행되지 않는 상태에서수행되는 것을 특징으로 하는 음성 인식 기능을 위한 전처리 모델의 구축 방법."}
{"patent_id": "10-2022-0094052", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 음성 인식 기능을 위한 전처리 모델 구축 시스템 및 전처리 모델 구축 방법에 관한 것으로, 타겟 음성 인식 모델을 이용하여, 학습용 음성 데이터에 대한 음성 인식률을 획득하는 학습 데이터 준비부, 학습용 음성 데 이터에서 노이즈가 제거된 클린 음성 데이터에 대한 타겟 음성 인식 모델의 예상 인식률을 추정하는 인식률 예측 모델 및 학습용 음성 데이터를 전처리하여 클린 음성 데이터를 획득하고, 예상 인식률과 최대 인식률 간의 차이 에 해당하는 인식률 손실을 바탕으로 음성 전처리 모델을 업데이트하는 음성 전처리 모델을 포함할 수 있다."}
{"patent_id": "10-2022-0094052", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 인식 기능을 위한 전처리 모델 구축 시스템 및 전처리 모델 구축 방법에 관한 것으로, 전처리 모델의 성능을 향상시킬 수 있는 기술에 관한 것이다."}
{"patent_id": "10-2022-0094052", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사용자의 제어에 의해서 동작하는 전자기기들은 사용자가 제어 동작을 수행할 수 있는 사용자 인터페이스를 제 공한다. 사용자 인터페이스는 전자기기 자체의 기능 및 동작을 직접 컨트롤하는 방식에서 점차적으로 사용자들 의 물리적 힘을 적게 요구하면서 직관적인 동작으로 전자기기를 제어할 수 있는 방향으로 개발되고 있다. 근래에는 사용자의 음성을 파악하고 이를 바탕으로 특정 동작을 수행하는 음성인식 기능을 기반으로 동작하는 음성인식 기반의 기기들이 늘어나고 있다. 음성으로 표현되는 언어는 자연인에게 가장 자연스러운 의사소통 수 단이기 때문에 음성인식 기반의 기기들은 매우 직관적이며 사용이 편리한 장점이 있다. 음성인식 기능은 음성 인식률을 높이기 위해서 음성 신호에서 노이즈를 제거하는 전처리 과정을 진행한다. 음성 인식 모델은 널리 알려진 모델을 이용하는 데에 반해서, 음성 신호의 전처리 과정은 음성 인식 모델과는 별도로 진행되는 것이 일반적이다. 따라서, 음성인식에서 노이즈를 제거하여 자연인인 사용자가 듣기에 깨끗한 음성일지라도 공지된 음성 인식 모델은 클린 음성에 대한 인식률이 저하되는 경향이 나타나고 있다. 따라서, 다양한 음성 인식 모델에 적용되어도 음성 인식률을 높일 수 있는 음성 전처리 과정이 요구되고 있다."}
{"patent_id": "10-2022-0094052", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시 예는 다양한 음성 인식 모델에 적용될 수 있는 음성 인식 기능을 위한 전처리 모델 구축 시스템 및 전처리 모델 구축 방법을 제공하기 위한 것이다. 또한, 본 발명의 실시 예는 보다 높은 음성 인식률을 보장할 수 있는 음성 인식 기능을 위한 전처리 모델 구축 시스템 및 전처리 모델 구축 방법을 제공하기 위한 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0094052", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 의한 음성 인식 기능을 위한 전처리 모델 구축 시스템은 타겟 음성 인식 모델을 이용하여, 학습용 음성 데이터에 대한 음성 인식률을 획득하는 학습 데이터 준비부, 학습용 음성 데이터에서 노이즈가 제 거된 클린 음성 데이터에 대한 타겟 음성 인식 모델의 예상 인식률을 추정하는 인식률 예측 모델 및 학습용 음 성 데이터를 전처리하여 클린 음성 데이터를 획득하고, 예상 인식률과 최대 인식률 간의 차이에 해당하는 인식 률 손실을 바탕으로 음성 전처리 모델을 업데이트하는 음성 전처리 모델을 포함할 수 있다. 실시 예에 의하면, 상기 학습 데이터 준비부는 노이즈가 없는 발화 정답에 노이즈 및 룸 임펄스 응답 정보를 믹 싱하여 상기 학습용 음성 데이터를 생성할 수 있다. 실시 예에 의하면, 상기 학습 데이터 준비부는 복수의 공간에 대응하는 복수의 학습용 음성 데이터를 생성할 수 있다. 실시 예에 의하면, 상기 학습 데이터 준비부는 상기 타겟 음성 인식 모델이 상기 학습용 음성 데이터를 학습한 학습 결과와 상기 발화 정답 간의 차이를 계산하여 학습용 음성 인식률을 획득할 수 있다. 실시 예에 의하면, 상기 인식률 예측 모델은 상기 학습용 음성데이터를 학습하여, 상기 타겟 음성 인식 모델에 대한 예상 음성인식률을 산출하고, 상기 타겟 음성 인식 모델에 대한 학습용 상기 음성 인식률을 바탕으로, 상 기 인식률 예측 모델을 업데이트 할 수 있다. 실시 예에 의하면, 상기 인식률 예측 모델은 상기 학습용 음성 데이터의 예상 음성 인식률과 상기 타겟 음성 인 식 모델을 이용하여 획득된 상기 학습용 음성 인식률 간의 차이를 계산하여 인식률 편차를 획득하고, 상기 인식 률 편차를 바탕으로 업데이트를 수행할 수 있다. 실시 예에 의하면, 상기 인식률 예측 모델은 상기 인식률 편차를 줄이는 방향으로 상기 업데이트를 수행할 수 있다. 실시 예에 의하면, 상기 음성 전처리 모델은 인공지능 기반으로 상기 학습용 음성 데이터의 음성 특징을 학습하 고, 학습된 상기 음성 특징을 향상시킴으로써, 상기 클린 음성 데이터를 획득할 수 있다. 실시 예에 의하면, 상기 음성 전처리 모델은 후속 전처리 과정에서 상기 예상 인식률을 높일 수 있도록 업데이 트를 수행할 수 있다. 실시 예에 의하면, 상기 음성 전처리 모델은 상기 인식률 예측 모델의 업데이트가 진행되지 않는 상태에서 업데 이트를 수행할 수 있다. 본 발명의 실시 예에 의한 음성 인식 기능을 위한 전처리 모델의 구축 방법은 타겟 음성 인식 모델을 이용하여, 학습용 음성 데이터에 대한 음성 인식률을 획득하는 단계, 음성 전처리 모델을 이용하여, 상기 학습용 음성 데 이터를 전처리하여 노이즈가 제거된 클린 음성 데이터 획득하는 단계, 인식률 예측 모델을 이용하여, 상기 클린 음성 데이터의 예상 인식률을 추정하는 단계, 및 상기 예상 인식률과 최대 인식률 간의 차이에 해당하는 인식률 손실을 바탕으로, 상기 음성 전처리 모델을 업데이트하는 단계를 포함할 수 있다. 실시 예에 의하면, 타겟 음성 인식 모델을 이용하여, 상기 음성 인식률을 획득하는 단계는 노이즈가 없는 발화 정답에 노이즈 및 룸 임펄스 응답 정보를 믹싱하여 상기 학습용 음성 데이터를 생성하는 단계를 포함할 수있다. 실시 예에 의하면, 상기 학습용 음성 데이터를 생성하는 단계는 복수의 공간에 대응하는 복수의 학습용 음성 데 이터를 생성하는 단계를 포함할 수 있다. 실시 예에 의하면, 타겟 음성 인식 모델을 이용하여, 상기 음성 인식률을 획득하는 단계는 상기 타겟 음성 인식 모델이 상기 학습용 음성 데이터를 학습한 학습 결과와 상기 발화 정답 간의 차이를 계산하여 학습용 음성 인식 률을 획득할 수 있다. 실시 예에 의하면, 상기 인식률 예측 모델이 상기 학습용 음성데이터를 학습하여, 상기 타겟 음성 인식 모델에 대한 예상 음성인식률을 산출하는 단계 및 상기 타겟 음성 인식 모델에 대한 상기 학습용 음성인식률을 바탕으 로, 상기 인식률 예측 모델을 업데이트 하는 단계를 더 포함할 수 있다. 실시 예에 의하면, 상기 인식률 예측 모델을 업데이트 하는 단계는 상기 학습용 음성 데이터의 예상 음성 인식 률과 상기 타겟 음성 인식 모델을 이용하여 획득된 상기 학습용 음성 인식률 간의 차이를 계산하여 인식률 편차 를 획득하는 단계 및 상기 인식률 편차를 상기 인식률 예측 모델에 역전파하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 인식률 예측 모델을 업데이트 하는 단계는, 상기 인식률 편차를 줄이는 방향으로 수행 될 수 있다. 실시 예에 의하면, 음성 전처리 모델을 이용하여, 상기 학습용 음성 데이터를 전처리하여 노이즈가 제거된 클린 음성 데이터 획득하는 단계는 인공지능 기반으로 상기 학습용 음성 데이터의 음성 특징을 학습하고, 학습된 상 기 음성 특징을 향상시키는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 음성 전처리 모델을 업데이트 하는 단계는 후속 전처리 과정에서 상기 예상 인식률을 높일 수 있도록 진행될 수 있다. 실시 예에 의하면, 상기 음성 전처리 모델을 업데이트 하는 단계는 상기 인식률 예측 모델의 업데이트가 진행되 지 않는 상태에서 수행될 수 있다."}
{"patent_id": "10-2022-0094052", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 의한 음성 인식 기능을 위한 전처리 모델 구축 시스템 및 전처리 모델 구축 방법은 공지된 타겟 음성 인식 모델의 예상 음성 인식률을 추종하도록 음성 전처리 모델을 업데이트하기 때문에, 다양한 음성 인식 모델에 적용될 수 있다. 또한, 본 발명의 실시 예에 의한 음성 인식 기능을 위한 전처리 모델 구축 시스템 및 전처리 모델 구축 방법은 클린 음성데이터를 학습하는 타겟 음성 인식 모델의 음성 인식률을 높일 수 있는 경향으로 음성 전처리 모델이 업데이트되기 때문에, 사용자의 청취 수준을 기반으로 음성 전처리를 수행하는 것보다 음성 인식률을 높일 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2022-0094052", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한 다. 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소 의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용 어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들 은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 도 1 내지 도 8를 참조하여, 본 발명의 실시 예들을 구체적으로 설명하기로 한다. 도 1은 본 발명의 실시 예에 의한 음식 인식을 위한 전처리 모델 구축 시스템의 구성을 나타내는 도면이다. 도 1을 참조하면, 본 발명의 실시 예에 의한 전처리 모델 구축 시스템은 학습 데이터 준비부, 인식 률 예측 모델, 및 음성 전처리 모델을 포함할 수 있다. 도 1에 도시된 전처리 모델 구축 시스템은 음성 인식 시스템의 전처리 과정을 수행하는 음성 전처리 모델의 전처리 성능 향상을 위한 구성들일 수 있 다. 학습 데이터 준비부는 데이터 구축부를 이용하여, 학습용 음성데이터(TData)를 생성하고, 학습용 음 성데이터(TData)에 대한 음성 인식률을 획득할 수 있다. 인식률 예측 모델는 학습 데이터 준비부가 생성한 학습용 음성데이터(TData)를 입력받아 인공지능 학 습을 수행함으로써, 학습용 음성데이터(TData)에 대한 예상 음성 인식률을 추론할 수 있다. 인식률 예측 모델 는 학습용 음성데이터(TData)에 대한 예상 음성 인식률과 학습용 음성데이터(TData)의 음성 인식률 간의 차이를 바탕으로, 예상 음성 인식률을 높일 수 있도록 업데이트될 수 있다. 또한, 인식률 예측 모델은 음성 전처리 모델이 출력한 클린 음성데이터를 입력받아 인공지능 학습을 수행함으로써, 클린 음성데이터에 대한 예상 음성 인식률을 추론할 수 있다. 인식률 예측 모델은 클린 음 성데이터에 대한 예상 음성 인식률을 음성 전처리 모델에 제공할 수 있다. 클린 음성데이터에 대한 예상 음성 인식률은 음성 전처리 모델의 업데이트 과정에서 활용될 수 있다. 이를 위해서, 인식률 예측 모델은 제1 음성 특징 추출부, 음성 특징 분석부, 및 음성 인식률 추 론부를 포함할 수 있다. 제1 음성 특징 추출부, 음성 특징 분석부, 및 음성 인식률 추론부 의 구체적인 동작은 후술하기로 한다. 음성 전처리 모델은 외부로부터 NON-PTT 방식으로 수신된 음향 신호에서 부가 잡음 신호를 분리하고, 발화 자가 발화하는 음성 구간을 구분할 수 있다. 음성 전처리 모델은 학습 데이터 준비부가 출력한 학습용 음성데이터(TData)를 전처리하여 클린 음성 데이터를 획득할 수 있다. 음성 전처리 모델은 인식률 예측 모델이 클린 음성데이터에 대한 예상 음성 인식률을 입력받고, 클린 음성데이터에 대한 예상 음성 인식률을 바탕으로 업데이트를 진행할 수 있다. 음성 전처리 모델은 클린 음성데이터에 대한 예상 음성 인식률과 최대 음성 인식률 간의 차이를 인식률 손실로 판단하고, 인식률 손실이 줄어드는 방향으로 업데이트를 진행할 수 있다. 이를 위해서 음성 전처리 모델은 제2 음성 특징 추출부, 및 음성 향상부를 포함할 수 있다. 제 2 음성 특징 추출부, 및 음성 향상부의 구체적인 동작은 후술하기로 한다. 인식률 예측 모델 및 음성 전처리 모델은 인공지능 프로세서를 저장하기 위한 메모리(미도시)를 구비 할 수 있다. 메모리는 하드 디스크 드라이브, 플래시 메모리, EEPROM(Electrically erasable programmable read-only memory), SRAM(Static RAM), FRAM (Ferro-electric RAM), PRAM (Phase-change RAM), MRAM(Magnetic RAM), DRAM(Dynamic Random Access Memory), SDRAM(Synchronous Dynamic Random Access Memory), DDR- SDRAM(Double Date Rate-SDRAM) 중에서 적어도 어느 하나 또는 둘 이상의 조합으로 구성될 수 있다.메모리에 포함되는 인공지능(artificial intelligence; 이하, AI) 프로세서는 미리 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 음성 인식을 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데이터를 주고 받을 수 있다. 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신(RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함할 수 있다. 음성 전처리 모델을 포함하는 음성 인식 시스템은 차량 또는 전자 장치에 탑재될 수 있다. 전자 장치는 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 서 버, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 스피커 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있다. 학습 데이터 준비부 및 인식률 예측 모델는 음성 인식 시스템에 포함되는 구성이거나, 음성 인식 시 스템과는 분리되는 구성일 수 있다. 예를 들어, 학습 데이터 준비부 및 인식률 예측 모델는 음성 인 식 시스템과는 별개의 서버의 일부 구성으로 구현될 수 있다. 음성 전처리 모델은 무선 통신을 이용하여 서버에 구비된 학습 데이터 준비부 및 인식률 예측 모델 와 통신할 수 있다. 음성 전처리 모델은 이동 통신을 위한 기술 표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division MultiAccess), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-DataOnly), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink PacketAccess), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등)에 따라 구축된 이동 통신망 상에서 기지국, 외부의 단 말, 센터 중 적어도 하나와 무선 신호를 송수신할 수 있다. 무선 신호는 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형태의 데이터를 포함할 수 있다. 도 2는 본 발명의 실시 예에 의한 전처리 모델 구축 방법을 나타내는 순서도이다. 도 1 및 도 2를 참조하여, 본 발명의 실시 예에 의한 전처리 모델 구축 방법을 살펴보면 다음과 같다. S210에서, 학습 데이터 준비부는 타겟 음성 인식 모델을 이용하여, 학습용 음성데이터에 대한 음성 인식률 을 획득할 수 있다. 타겟 음성 인식 모델은 음성 신호를 수신하고, 수신된 음성 신호에서 특징 백터를 추출하여 음성을 인식할 수 있다. 타겟 음성 인식 모델은 공지된 음성 인식 모델일 수 있다. 학습용 음성데이터는 클린 발화에 노이즈가 포함된 음성데이터를 지칭할 수 있다. 학습용 음성데이터는 다양한 공간의 특징을 포함하도록, 복수의 공간에서 수집된 음성을 바탕으로 생성될 수 있다. S220에서, 음성 전처리 모델은 학습용 음성데이터를 전처리하여 노이즈가 제거된 클린 음성데이터 획득할 수 있다. 이를 위해서 음성 전처리 모델은 인공지능 기반으로 학습용 음성 데이터의 음성 특징을 학습하고, 학습된 음성 특징을 향상시키는 단계를 포함할 수 있다. S230에서, 인식률 예측 모델은 클린 음성데이터의 예상 인식률을 추정할 수 있다. S240에서, 음성 전처리 모델은 예상 인식률과 최대 인식률 간의 차이에 해당하는 인식률 손실을 바탕으로 업데이트를 진행할 수 있다. 최대 인식률은 음성 전처리 모델이 클린 음성데이터를 오차없이 완벽하게 인식한 상태를 의미하고, 백분율 로 환산하였을 경우 100%의 수치로 표현될 수 있다. 음성 전처리 모델의 업데이트는 예상 인식률을 높이는 방향으로 진행될 수 있다. 따라서, 음성 전처리 모 델의 후속 학습에 의한 예상 인식률과 최대 인식률 간의 차이는 줄어들 수 있다.상술한 바와 같이, 본 발명의 실시 예에 의한 음성 전처리 모델은 인식률 예측 모델의 결과를 추종하 여 업데이트를 진행할 수 있다. 즉, 본 발명의 실시 예에 의하면, 음성 전처리 모델은 클린 음성데이터를 학습하는 타겟 음성 인식 모델의 음성 인식률을 높일 수 있는 경향으로 업데이트될 수 있다. 따라서, 본 발명 의 실시 예에 의하면, 단순히 클린 음성데이터의 노이즈 제거 수준이 좋을지라도 타겟 음성 인식 모델의 음성 인식률이 저하되는 문제점을 개선할 수 있다. 이하, 본 발명의 실시 예에 의한 음성 전처리 모델의 업데이트 과정의 세부 절차들을 구체적으로 살펴보면 다음과 같다. 도 3은 본 발명의 실시 예에 의한 학습용 음성데이터의 음성 인식률을 획득하는 방법을 설명하는 도면이다. 즉, 도 3은 학습 데이터 준비부의 동작을 나타내고 있다. 도 4 및 도 5는 학습용 음성데이터의 생성과정을 설 명하는 도면이고, 도 6은 룸 임펄스 응답 정보를 설명하는 도면이다. 도 3 내지 도 6을 참조하여, 본 발명의 실시 예에 의한 학습용 음성데이터의 음식 인식률을 획득하는 방법을 살 펴보면 다음과 같다. 학습 데이터 준비부는 노이즈, 클린 발화, 및 룸 임펄스 응답(Room Impulse Response; RIR) 정보를 믹싱 (mixing)하여 학습용 음성데이터를 생성할 수 있다. 학습용 음성데이터(TData)는 다양한 공간에서 취득된 정보에 기초하여 생성될 수 있다. 이를 위해서, 도 4에서 와 같이, 이동형 로봇은 미리 정해진 경로 또는 임의의 경로를 따라서 이동할 수 있다(S410). 이동형 로봇 은 특정 공간에 위치할 때마다 노이즈를 획득할 수 있다(S420). 특정 공간은 미리 지정된 공간일 수 있고, 또는 일정 시간 마다 이동형 로봇이 위치하는 공간일 수 있다. 또한, 이동형 로봇은 특정 공간에 위치할 때마다 룸 임펄스 응답 정보를 획득할 수 있다(S430). 도 6에서와 같이, 청취자가 룸 임펄스 음원으로부터 전달받은 음향은 직접음, 초기 반사음 및 후기 잔향음으로 구분될 수 있다. 직접음은 임펄스 음원으로부터 청취자에게 바로 전달되는 음을 의미할 수 있다. 직접음이 임펄스 음원으로부터 청취자에게 전달되는 시간을 초기 지연이라고 정의될 수 있다. 반사음은 임펄스 음원에서 발생한 소리들이 벽면이나 천정과 같은 반사면에 반사되어 직접음보다 상대 적으로 길어진 경로를 경유하여 청취자에게 전달되는 음을 의미할 수 있다. 직접음이 전달되고 나서 약 50 ∼80ms 사이에 전달되는 반사음은 초기 반사음으로 정의될 수 있다. 초기 반사음은 직접음이 도달한 후 빠른 시간 내에 전달되기 때문에 음향의 방향감을 변화시키지 않으 면서 직접음을 보강하여 음량감을 향상시키고, 입체음향의 공간감을 잘 표현할 수 있다. 후기 잔향은 직접음이 발생하고 약 80ms 이후에 나타나는 반사음으로 여러 경로를 통해 전달되는 반사 음이 중첩된 것일 수 있다. 반사 때 반사면에서 에너지의 일부가 흡수되어 잔향의 크기는 일반적으로 지수 함수적으로 줄어들 수 있다. 도 4에 도시된 실시 예는 이동형 로봇이 학습용 음성데이터(TData)를 생성하는 실시 예를 설명하고 있지만, 학습용 음성데이터(TData)의 생성 수단은 이에 한정되지 않을 수 있다. 예를 들어, 특정 공간 마다 학습용 음 성데이터(TData)를 취득하는 수집부(미도시)가 설치될 수 있고, 이동형 로봇은 특정 공간을 경유하면서 수집 부로부터 학습용 음성데이터(TData)를 전달받을 수 있다. 학습 데이터 준비부는 학습용 음성데이터(TData)에서 발화 정답을 추출할 수 있다. 발화 정답은 클린 발 화의 텍스트일 수 있다. 예를 들어, 학습용 음성데이터(TData)가 \"내비게이션을 동작시켜\"라는 텍스트를 낭독 한 클린 발화일 경우, 발화 정답은 \"내비게이션을 동작시켜\"라는 텍스트일 수 있다. 도 3에서 타겟 음성 인식 모델은 학습용 음성데이터(TData)를 입력받아, 학습용 음성데이터를 인식한 결과를 도 출할 수 있다. 학습 데이터 준비부는 학습용 음성데이터(TData)의 발화 정답과 타겟 음성 인식 모델의 인식 결과의 차이 를 바탕으로 학습용 음성 인식률(TData_R)을 획득할 수 있다. 학습용 음성 인식률(TData_R)을 획득하기 위해서 발화 정답과 타겟 음성 인식 모델의 인식 결과는 음소 단위 또는 음절 단위로 비교될 수 있다. 예를 들어, 발화 정답이\"내, 비, 게, 이, 션, 을, 동, 작, 시, 켜\"라는 10개의 음절이며, 타겟 음성 인식 모델 의 인식 결과가 \"내, 비, 게, 이, 션, 을, 등, 작, 시, 켜\"라는 10개의 음절일 수 있다. 타겟 음성 인식 모델 의 인식 결과는 \"동\"을 \"등\"으로 잘못 인식한 것 이외에는 9개의 음절에 대해서는 올바르게 인식한 결과일 수 있다. 학습 데이터 준비부는 10개의 음절에 대해서 9개의 음절을 정답으로 인식할 경우, 학습용 음성 인식률을 90(%)로 계산할 수 있다. 이와 같은 방식으로, 학습 데이터 준비부는 복수의 학습용 음성데이터(TData) 및 이와 매칭되는 학습용 음 성 인식률(TData_R)을 메모리에 저장할 수 있다. 다음의 [표 1]은 학습용 음성데이터들(TData)과 매칭되는 학 습용 음성 인식률(TData_R)의 일례를 나타내는 표이다. 표 1 학습용 음성데이터 학습용 음성 인식률(%) TData1 90 TData2 85 TData3 100 학습용 음성데이터들(TData1, TData2, TData3)은 동일한 클린 발화에 대해서 서로 다른 공간에서 획득된 것일 수 있다. 또는 학습용 음성데이터들(TData1, TData2, TData3)은 동일한 공간에서 서로 다른 클린 발화에 대해 서 획득된 것일 수 있다.도 7은 인식률 예측 모델의 업데이트 방법을 설명하는 도면이다. 도 7을 참조하면, 본 발명의 실시 예에 의한 인식률 예측 모델은 학습용 음성데이터를 수신하여 학습할 수 있다. 이를 위해서, 인식률 예측 모델은 제1 음성 특징 추출부, 음성 특징 분석부 및 음성 인식률 추 론부를 포함할 수 있다. 제1 음성 특징 추출부는 음성 신호에서 음성 특징을 추출할 수 있다. 제1 음성 특징 추출부는 음향 신호에서 시간 에너지(Time Energy), 주파수 에너지(Frequency Energy), LPC(Linear Predictive Coding)를 바 탕으로 음성 특징을 추출할 수 있다. 또는, 제1 음성 특징 추출부는 멜 주파수 셉스트랄 계수(MFCC, Mel Frequency Cepstral Coefficient)를 바탕으로 음성 특징을 추출할 수 있다. 또는 제1 음성 특징 추출부 는 신경망(Neural Network) 기반의 임베딩 벡터(Embedding vector)를 이용하여 음성 특징을 추출할 수 있다. 음성 특징 분석부는 추출된 음성 특징을 분석할 수 있다. 음성 특징 분석부는 정규화 레이어 (Normalization layer), 합성곱 레이어(Convolution layer), 순환 신경망(Recurrent Neural Network), 완전 연 결 레이어(Fully connected layer) 중에서 적어도 어느 하나를 이용할 수 있다. 음성 인식률 추론부는 음성 특징 분석부의 분석 결과를 바탕으로 음성 인식률을 추론하여 예상 음성 인식률(TData_ER)을 획득할 수 있다. 전처리 모델 구축 시스템은 예상 음성 인식률(TData_ER)과 타겟 음성 인식 모델에 대한 학습용 음성 인식 률(TData_R) 간의 차이를 계산하여, 인식률 편차(loss1)를 획득할 수 있다. 인식률 편차(loss1)는 인식률 예측 모델로 역전파(back propagation)될 수 있다. 인식률 예측 모델은 인식률 편차(loss1)를 바탕으로 업데이트를 진행할 수 있다. 인식률 예측 모델 의 업데이트는 인식률 편차(loss1)의 크기를 최소로 할 수 있는 방향으로 수행될 수 있다. 즉, 인식률 예측 모 델은 인식률의 정확도가 타겟 음성 인식 모델의 인식률을 추종하도록 업데이트될 수 있다. 도 7에 도시된 인식률 예측 모델을 업데이트 하는 절차는 후술하는 음성 전처리 모델의 업데이트 기간 이외의 기간에서 수행될 수 있다. 도 8은 음성 전처리 모델의 업데이트 방법을 설명하는 도면이다. 도 8은 도 2에 도시된 전처리 모델 구축 방법 의 구체적인 실시 예에 해당할 수 있다. 도 8을 참조하면, 음성 전처리 모델은 학습용 음성데이터(TData)를 입력받아서, 학습용 음성데이터(TDat a)에서 노이즈가 제거된 클린 음성데이터(CData)를 획득할 수 있다. 이를 위해서, 음성 전처리 모델은 제 2 음성 특징 추출부, 및 음성 향상부를 포함할 수 있다. 제2 음성 특징 추출부는 음성 신호에서 음성 특징을 추출할 수 있다. 제2 음성 특징 추출부는 음향 신호에서 시간 에너지(Time Energy), 주파수 에너지(Frequency Energy), LPC(Linear Predictive Coding)를 바 탕으로 음성 특징을 추출할 수 있다. 또는, 제2 음성 특징 추출부는 멜 주파수 셉스트랄 계수(MFCC, Mel Frequency Cepstral Coefficient)를 바탕으로 음성 특징을 추출할 수 있다. 또는 제2 음성 특징 추출부 는 신경망(Neural Network) 기반의 임베딩 벡터(Embedding vector)를 이용하여 음성 특징을 추출할 수 있다. 음성 향상부는 추출된 음성 특징의 품질을 향상시킬 수 있다. 음성 향상부는 정규화 레이어 (Normalization layer), 합성곱 레이어(Convolution layer), 순환 신경망(Recurrent Neural Network), 완전 연 결 레이어(Fully connected layer) 중에서 적어도 어느 하나를 이용할 수 있다. 인식률 예측 모델은 클린 음성데이터(CData)를 수신하고, 클린 음성데이터(CData)를 학습할 수 있다. 학 습 결과를 바탕으로, 인식률 예측 모델은 클린 음성데이터에 대한 예상 인식률(CData_ER)을 추정할 수 있 다. 전처리 모델 구축 시스템은 클린 음성데이터(CData)의 예상 인식률(CData_ER)과 최대 인식률 간의 차이를 계산하여 인식률 손실(loss2)을 계산할 수 있다. 최대 인식률은 오차가 없이 클린 발화를 인식한 것으로 100(%)로 설정될 수 있다. 인식률 손실(loss2)은 음성 전처리 모델에 역전파될 수 있다. 음성 전처리 모델은 인식률 손실(loss2)을 바탕으로 업데이트를 진행할 수 있다. 음성 전처리 모델 은 인식률 손실(loss2)이 최소가 되는 방향으로 업데이트를 진행할 수 있다. 살펴본 바와 같이, 전처리 모델 구축 시스템은 노이즈를 제거한 정도를 바탕으로 음성 전처리 모델 을 평가하거나 음성 전처리 모델의 업데이트를 진행하는 것이 아니라, 클린 음성데이터(CData)를 바탕으로 음성 인식 기능을 이용하였을 경우의 인식률 정확도를 추종할 수 있다. 인식률 예측 모델은 음성 인식 서 비스가 수행되는 타겟 음성 인식 모델의 인식률을 추종하기 때문에, 타겟 음성 인식 모델의 음성 인식률을 높일 수 있다. 도 8에 도시된 음성 전처리 모델의 업데이트 절차는 인식률 예측 모델이 업데이트를 진행하는 않는 상태에 서 수행될 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위 에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2022-0094052", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 의한 음식 인식을 위한 전처리 모델 구축 시스템의 구성을 나타내는 도면이다. 도 2는 본 발명의 실시 예에 의한 전처리 모델 구축 방법을 나타내는 순서도이다. 도 3은 본 발명의 실시 예에 의한 학습용 음성데이터의 음성 인식률을 획득하는 방법을 설명하는 도면이다. 도 4 및 도 5는 학습용 음성데이터의 생성과정을 설명하는 도면이다. 도 6은 룸 임펄스 응답 정보를 설명하는 도면이다. 도 7은 인식률 예측 모델의 업데이트 방법을 설명하는 도면이다. 도 8은 음성 전처리 모델의 업데이트 방법을 설명하는 도면이다."}
