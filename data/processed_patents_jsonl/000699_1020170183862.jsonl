{"patent_id": "10-2017-0183862", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0081371", "출원번호": "10-2017-0183862", "발명의 명칭": "기판, 인공 신경망 구현 장치 및 방법", "출원인": "(주)제이엘케이인스펙션", "발명자": "김원태"}}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "처리부; 및복수의 입력 핀을 포함하고,상기 복수의 입력 핀은,입력 블록을 연결하기 위한 입력 핀, 신경 블록을 연결하기 위한 입력 핀 및 출력 블록을 연결하기 위한 입력핀 중 적어도 하나를 포함하는 기판."}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 처리부는,저항 또는 전압을 측정함으로써 상기 입력 핀에 연결된 블록을 식별하는 기판."}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 처리부는 메모리를 포함하고,상기 처리부는,상기 식별된 블록에 대응하는 정보를 상기 메모리로부터 독출하는 기판."}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 처리부는,상기 독출된 블록 정보를 이용하여 인공 신경망을 구현하고,상기 출력 블록이 연결된 입력 핀으로 상기 인공 신경망의 분석 결과에 관한 정보를 출력하는 기판."}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 신경 블록을 연결하기 위한 입력 핀은,뉴런 블록을 연결하기 위한 입력 핀 및 활성화 함수 블록을 연결하기 위한 입력 핀 중 적어도 하나를 포함하는기판."}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "적어도 하나의 입력 블록;적어도 하나의 신경 블록;적어도 하나의 출력 블록; 및기판을 포함하고,상기 기판은,공개특허 10-2019-0081371-3-처리부; 및상기 입력 블록을 연결하기 위한 입력 핀, 상기 신경 블록을 연결하기 위한 입력 핀 및 상기 출력 블록을 연결하기 위한 입력 핀 중 적어도 하나를 포함하는 인공 신경망 구현 장치."}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "기판에 연결된 적어도 하나의 블록을 식별하는 단계;식별된 적어도 하나의 블록에 기초하여 인공 신경망을 생성하는 단계; 및상기 생성된 인공 신경망에 관한 정보를 출력하는 단계를 포함하는 인공 신경망 구현 방법."}
{"patent_id": "10-2017-0183862", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "프로그램을 기록한 컴퓨터 판독 가능한 기록 매체로서,상기 프로그램은,기판에 연결된 적어도 하나의 블록을 식별하는 단계;식별된 적어도 하나의 블록에 기초하여 인공 신경망을 생성하는 단계; 및상기 생성된 인공 신경망에 관한 정보를 출력하는 단계를 수행하는 컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망 구현 방법 및 장치가 제공된다. 본 개시의 인공 신경망 구현 장치는 적어도 하나의 입력 블록, 적어 도 하나의 신경 블록, 적어도 하나의 출력 블록, 및 기판을 포함하고, 상기 기판은, 처리부 및 상기 입력 블록을 연결하기 위한 입력 핀, 상기 신경 블록을 연결하기 위한 입력 핀 및 상기 출력 블록을 연결하기 위한 입력 핀 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 신경망 구현 장치 및 방법에 관한 것이다. 보다 구체적으로, 본 개시는 복수의 블록들을 전기적 으로 연결시키는 기판 및 복수의 블록에 기반한 인공 신경망 구현 장치, 방법 및 본 개시의 인공 신경망 생성 방법을 실행하기 위한 프로그램을 기록한 컴퓨터로 판독 가능한 기록 매체에 관한 것이다."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간의 신경구조를 모사하여 개발된 인공 신경망(artificial neural network)은 인공지능 분야 중 딥 러닝의 기 반을 이루는 모델로서 인공지능 기술 발전에 있어 주도적인 역할을 한 인공지능 모델이다. 기존의 논리/규칙 기 반 모델은 현실 세계의 모든 문제를 명확히 정의하기 어렵고 세상의 모든 상황과 지식을 알려줄 수 없기 때문에 그 적용 범위에 한계가 있다. 따라서, 최근 기존의 논리/규칙 기반 모델을 적용하기 어려운 분야에 인공 신경망 기술이 적용되어 인공지능 기반 시스템의 성능과 확장성을 크게 향상시키고 있다. 한편, 인공 신경망은 인공지능에 특화된 프로그램과 수식으로 구현될 수 있는데, 프로그래밍 언어를 기반으로 추상적으로 구현된 인공 신경망의 구조와 학습 과정을 직관적으로 파악하기 어렵다는 문제가 있다. 따라서, 학 습의 방법이나 알고리즘 동작 방법에 대한 개념과 구조를 쉽게 교육할 수 있는 인공 신경망에 특화된 하드웨어 학습 시스템의 개발이 필요한 실정이다."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는, 인공 신경망 구현 장치에 이용될 수 있는 기판을 제공하는 것이다. 본 개시의 다른 기술적 과제는, 인공 신경망 구현 장치 및 방법을 제공하는 것이다. 본 개시의 또 다른 기술적 과제는, 복수의 블록 및 블록들을 전기적으로 연결시키는 기판에 기반한 인공 신경망 생성 장치 및 방법을 제공하는 것이다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 양상에 따르면, 처리부 및 복수의 입력 핀을 포함하고, 상기 복수의 입력 핀은, 입력 블록을 연결 하기 위한 입력 핀, 신경 블록을 연결하기 위한 입력 핀 및 출력 블록을 연결하기 위한 입력 핀 중 적어도 하나 를 포함하는 기판이 제공될 수 있다. 본 개시의 다른 양상에 따르면, 적어도 하나의 입력 블록, 적어도 하나의 신경 블록, 적어도 하나의 출력 블록 및 기판을 포함하고, 상기 기판은, 처리부 및 상기 입력 블록을 연결하기 위한 입력 핀, 상기 신경 블록을 연결 하기 위한 입력 핀 및 상기 출력 블록을 연결하기 위한 입력 핀 중 적어도 하나를 포함하는 인공 신경망 구현 장치가 제공될 수 있다. 본 개시의 또 다른 양상에 따르면, 기판에 연결된 적어도 하나의 블록을 식별하는 단계, 식별된 적어도 하나의 블록에 기초하여 인공 신경망을 생성하는 단계, 및 상기 생성된 인공 신경망에 관한 정보를 출력하는 단계를 포 함하는 인공 신경망 구현 방법이 제공될 수 있다. 본 개시의 또 다른 양상에 따르면, 본 개시의 인공 신경망 구현 방법을 실행하기 위한 프로그램을 기록한 컴퓨 터로 판독 가능한 기록 매체가 제공될 수 있다."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 인공 신경망 구현 장치에 이용될 수 있는 기판이 제공될 수 있다. 또한, 본 개시에 따르면, 인공 신경망 구현 장치 및 방법이 제공될 수 있다. 또한, 본 개시에 따르면, 복수의 블록 및 블록들을 전기적으로 연결시키는 기판에 기반한 인공 신경망 생성 장 치 및 방법이 제공될 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결관계뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또한어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용되 며, 특별히 언급되지 않는 한 구성요소들간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범위 내에서 일 실시 예에서의 제1 구성요소는 다른 실시 예에서 제2 구성요소라고 칭할 수도 있고, 마찬가지로 일 실시 예에서의 제2 구성요소를 다른 실시 예에서 제1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들을 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시 예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 이하, 첨부한 도면을 참조하여 본 개시의 실시 예들에 대해서 설명한다. 도 1은 본 개시의 일 실시 예에 따른 인공 신경망의 일반적인 구조를 설명하기 위한 도면이다. 인공지능 기술은 컴퓨터에게 데이터를 학습시켜 마치 사람처럼 스스로 의사결정을 할 수 있게 한다. 인공 신경 망은 생물학의 신경망에서 영감을 얻은 수학적 모델로서, 시냅스의 결합으로 네트워크를 형성한 인공 뉴런이 학 습을 통해 시냅스의 결합 세기를 변화시킴으로써 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경망은 일반적으로 입력층(input layer), 은닉층(hidden layer) 및 출력층(output layer)로 구성되어 있으며 각 층에 포함된 뉴런들이 가중치를 통해 연결될 수 있다. 가중치와 뉴런값의 선형 결합과 비선형 활성화 함수를 통해 인공 신경망은 복잡한 함수를 근사화할 수 있는 형태를 가질 수 있다. 인공 신경망 학습의 목적은 출력층 에서 계산된 출력과 실제 출력의 값 차이를 최소화 시키는 가중치를 찾는데 있다. 심층 신경망(deep neural network)은 입력층과 출력층 사이에 여러 개의 은닉층들로 이루어진 인공 신경망을 의 미할 수 있다. 많은 은닉층을 이용함으로써 복잡한 비선형 관계들을 모델링할 수 있으며, 이처럼 층의 개수를 늘림으로써 고도화된 추상화가 가능한 신경망 구조를 딥러닝(deep learning)이라고 부른다. 딥러닝은 매우 방대 한 양의 데이터를 학습하여, 새로운 데이터가 입력될 경우 학습 결과를 바탕으로 확률적으로 가장 높은 답을 선 택할 수 있다. 따라서, 딥러닝은 입력에 따라 적응적으로 동작할 수 있으며, 데이터에 기초하여 모델을 학습하 는 과정에서 특성인자를 자동으로 찾아낼 수 있다. 본 개시의 일 실시 예에 따르면, 딥러닝 기반의 모델은 완전 합성곱 신경망(완전 컨볼루션 뉴럴 네트워크, fully convolutional neural network), 합성곱 신경망(컨볼루션 뉴럴 네트워크, convolutional neural network), 순환 신경망(회귀 뉴럴 네트워크, recurrent neural network), 제한 볼츠만 머신(restricted Boltzmann machine, RBM) 및 심층 신뢰 신경망(deep belief neural network, DBN) 중 적어도 하나를 포함할 수 있으나, 이에 제한되지 않는다. 또는, 딥러닝 이외의 머신 러닝 방법도 포함할 수 있다. 또는 딥러닝과 머신 러 닝을 결합한 하이브리드 형태의 모델도 포함할 수 있다. 예컨대, 딥러닝 기반의 모델을 적용하여 입력 데이터 (예컨대, 입력 영상)의 특징을 추출하고, 상기 추출된 특징에 기초하여 입력 데이터를 분류하거나 인식할 때는 머신 러닝 기반의 모델을 적용할 수도 있다. 머신 러닝 기반의 모델은 서포트 벡터 머신(Support Vector Machine, SVM), 에이다부스트(AdaBoost) 등을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 딥러닝 기반의 모델을 학습하는 방법은 지도 학습(supervised learning), 비지도 학습(unsupervised learning) 또는 강화 학습(reinforcement learning) 중 적어도 하나를 포함할 수 있으나, 이에 제한되지 않는다. 지도 학습은 일련의 학습 데이터와 그에 상응하는 레이블(label, 목 표 출력값)을 이용하여 학습이 이루어지며, 지도 학습에 기초한 신경망 모델은 훈련용 데이터(training data)로 부터 함수를 추론해내는 형태의 모델일 수 있다. 지도 학습은 일련의 학습 데이터와 그에 상응하는 목표 출력 값을 수신하고, 입력되는 데이터에 대한 실제 출력 값과 목표 출력 값을 비교하는 학습을 통해 오류를 찾아내고, 해당 결과를 근거로 모델을 수정하게 된다. 지도 학습은 결과물의 형태에 따라 다시 회귀 (regression), 분류(classification), 검출(detection), 시멘틱 세그멘테이션(semantic segmentation) 등으로 구분될 수 있다. 지도 학습을 통해 도출된 함수는 다시 새로운 결과값을 예측하는데 사용될 수 있다. 이처럼,지도 학습에 기초한 신경망 모델은 수많은 학습 데이터의 학습을 통해, 신경망 모델의 파라미터를 최적화하게 된다. 도 1을 참조하면, 일 실시예에 따른 인공 신경망은 입력층, 은닉층, 출력층 및 가중치를 포함할 수 있다. 예컨대, 도 1은 입력층의 크기가 3, 은닉층 및 출력층의 크기가 각각 2인 인공 신경망의 구조를 나타낸다. 구체적으로, 은닉층에 포함된 뉴런들(h1, h2)은 입력층에 포함된 뉴런들 (x1, x2, x3)과 가중치에 포함된 개별 가중치(w11, w12, w21, w22, w31, w32)와의 선형 결합으로 연결될 수 있 다. 출력층에 포함된 뉴런들(y1, y2)은 은닉층에 포함된 뉴런들(h1, h2)과 가중치에 포함된 개별 가중치와의 선형 결합으로 연결될 수 있다. 그리고, 인공 신경망은 출력층에서 계산된 출력과 실제 출력의 값 차이를 최소화 시키는 가중치를 찾을 수 있다. 도 2는 본 개시의 일 실시 예에 따른 인공 신경망의 단층 퍼셉트론의 구조를 나타내는 도면이다. 단층 퍼셉트론은 입력 벡터를 두 부류로 구분하는 선형 분류기이다. 도 2에 도시된 단층 퍼셉트론은, 입력층 에 포함된 뉴런(x1, x2, x3), 가중치(w1, w2, w3, 230), 바이어스(미도시), 순입력함수(net input function, 240), 활성함수(activation function, 250) 및 임계값 등을 포함할 수 있다. 예컨대, 도 2는 은닉층 없이 입력층의 크기가 3, 출력층의 크기가 1인 인공 신경망의 구조를 나타낸다. 예컨대, 학습 연산 또는 가중치 갱신은 아래의 수학식 1에 의해 수행될 수 있다. 수학식 1"}
{"patent_id": "10-2017-0183862", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1을 참조하면, 출력층 뉴런의 출력값과 목표값의 차이가 허용오차보다 크면 출력층 뉴런의 가 중치를 조절할 수 있다. 예컨대, 실제값 y의 활성함수 반환값(f(y))과 예측값 y'의 활성함수 반환값(f(y'))이 다를 경우, 입력층의 뉴런에 부가되는 가중치를 갱신할 수 있다. 도 3은 본 개시의 일 실시 예에 따른 인공 신경망의 퍼셉트론 구조와 인공 신경망 구현 장치의 구성의 대응관계 를 설명하기 위한 도면이다. 본 개시에 따를 때, 인공 신경망 구현 장치는 블록 형태로 구현된 입력 요소들을 직접 연결하거나, 입력 요소들 을 전기적으로 연결시킬 수 있는 기판에 체결시킴으로써 인공 신경망 구조를 구현할 수 있다. 예컨대, 인공 신 경망 구현 장치는 전원 공급을 받을 수 있는 블록들을 기판에 꽂고 뺌으로써 인공 신경망 구조를 구현할 수 있 다. 또한 기판은 각각의 블록이 해당 위치에 독립적으로 체결될 수 있도록 미리 회로적으로 구현되어 있을 수 있다. 상기 기판은 마이크로 콘트롤러 및/또는 마이크로 프로세서 등의 처리부를 구비한 것으로서, 본 개시에 따른 블록이 전기적으로 연결될 수 있는 기판을 포함할 수 있다. 본 개시에 따르면, 인공지능 기술의 개념과 활용 방법을 쉽게 학습할 수 있도록 특화된 시스템을 구현함으로써, 프로그래밍 초심자에게도 4차 산업 혁명의 주역인 인공지능 기술에 대한 교육을 보다 쉽고 원활하게 제공할 수 있다. 도 3을 참고하면, 인공 신경망 구현 장치는 입력 블록, 뉴런 블록, 활성화 함수 블록, 출 력 블록 및/또는 블록이 전기적으로 연결될 수 있는 미도시의 기판을 포함할 수 있다. 상기 기판은 마이크 로 콘트롤러 및/또는 마이크로 프로세서 등의 처리부를 구비할 수 있다. 다만, 이는 본 실시예를 설명하기 위해 필요한 일부 구성요소만을 도시한 것일 뿐, 인공 신경망 구현 장치에 포함된 구성요소가 전술한 예에 한정 되는 것은 아니다. 예컨대, 둘 이상의 구성부가 하나의 구성부 내에서 구현될 수도 있고, 하나의 구성부에서 실 행되는 동작이 분할되어 둘 이상의 구성부에서 실행되도록 구현될 수도 있다. 또한, 일부 구성부가 생략되거나부가적인 구성부가 추가될 수도 있다. 뉴런 블록 및/또는 활성화 함수 블록을 포함하여, 신경 블록 으로 통칭할 수 있다. 인공 신경망 구현 장치는 인공지능 기술의 개념과 학습 및 분류 구조를 하드웨어로 구현할 수 있다. 예컨 대 도 3을 참조하면, 인공 신경망 구현 장치는 인공지능 기술의 기초가 되는 퍼셉트론 구조를 하드웨어로 구현할 수 있다. 구체적으로 인공 신경망 구현 장치는 입력의 종류, 출력의 종류 또는 신경망 구조의 파라 미터(뉴런의 수, 뉴런 층의 수, 활성화 함수의 종류) 등을 결정함으로써, 퍼셉트론 구조를 하드웨어로 구현할 수 있다. 입력 블록은 퍼셉트론 구조에서의 입력 벡터를 하드웨어 형태의 블록으로 구현한 것일 수 있다. 신경 블록은 퍼셉트론 구조에서의 입력과 출력을 제외한 인공 신경망의 구조를 하드웨어 형태의 블록으로 구현 한 것일 수 있다. 예컨대, 뉴런 블록은 퍼셉트론 구조에서의 뉴런의 정보, 즉 뉴런의 층 또는 층마다 의 뉴런의 수를 하드웨어 형태의 블록으로 구현한 것일 수 있다. 활성화 함수 블록은 퍼셉트론 구조에서의 활성화 함수를 하드웨어 형태의 블록으로 구현한 것일 수 있다. 출력 블록은 퍼셉트론 구조에서의 학 습 결과 및/또는 분석 결과를 출력하기 위한 것으로서, 하드웨어 형태의 블록으로 구현한 것일 수 있다. 예컨대, 출력 블록은 결과에 대한 에러율, 손실 함수(loss function) 등의 학습 결과 및/또는 분석 결과에 대한 다양한 인터랙션을 제공할 수 있는 영상 표시 장치 및/또는 음성 출력 장치 등으로 구현될 수 있다. 도 4는 본 개시의 일 실시 예에 따른 인공 신경망 구현 장치의 구조를 설명하기 위한 도면이다. 도 4의 인공 신 경망 구현 장치는 도 3의 인공 신경망 구현 장치의 일 실시 예이다. 또한, 도 5는 본 개시의 일 실시 예에 따른 다양한 블록의 외관 및 내부 구조를 예시적으로 나타낸 도면이다. 인공 신경망 구현 장치의 구조 및 동작과 관련하여 도 4 및 도 5를 참조하여 보다 구체적으로 후술한다. 도 4를 참조하면, 인공 신경망 구현 장치는 입력 블록, 신경 블록, 출력 블록 및/또는 기 판을 포함할 수 있다. 입력 블록은 입력 데이터의 카테고리 정보에 따라 복수의 블록들을 포함할 수 있다. 예컨대, 각각의 입력 블록은 블록 내부 저항을 달리함으로써 데이터의 카테고리 정보에 대응되는 ID를 가질 수 있다. 입력 블록(41 0)이 기판에 연결되면, 기판에 포함된 처리부(마이크로 콘트롤러 또는 마이크로 프로세서)는 해당 입 력 블록의 ID를 인식하고, 메모리에 저장되어 있는 특징 벡터(feature vector, x[1] 내지 x[n])를 호출할 수 있다. 상기 메모리는 처리부 내에 구비될 수 있다. 한편, 각각의 입력 블록은 카테고리 정보에 따라 서 로 다른 블록 내부 저항을 가질 수 있고, 또한 블록들 간에 직렬 연결이 가능한 구조를 가질 수 있다. 블록들 간의 연결은 전원(Vcc)과 접지(GND)만 연결되도록 구성될 수 있다. 내부 저항(R)은 처리부의 전극(예컨대, 아날 로그 핀)에 연결될 수 있고, 블록 당 하나의 입력 핀을 사용할 수 있다. i 개의 입력 블록을 직렬 연결할 경우, 도 4에 도시된 바와 같이, 입력 블록은 i 개의 입력 핀을 가질 수 있다. 입력 블록은 해당하는 데이 터를 내부에 저장할 수도 있고, 저항을 통해 입력 블록의 ID만이 식별되도록 구성될 수도 있다. 입력 블록 이 기판에 연결되면, 내부에 저장된 데이터가 직접 이용될 수도 있고, 식별된 ID에 대응하는 정보가 메모리(예컨대, 처리부 내의 메모리)로부터 독출되어 이용될 수도 있다. 상기 저장된 데이터 또는 독출된 데이 터는 학습용 데이터로 활용될 수도 있고, 분류용 데이터로 활용될 수도 있다. 도 5의 (a)에 도시된 바와 같이, 입력 블록의 외관에는 해당 입력 블록에 대한 정보가 표시될 수 있 다. 입력 블록이 토끼에 대한 데이터를 포함하고 있는 블록일 경우, 그 외관에 토끼 그림을 표시함으 로써, 사용자가 직관적으로 해당 입력 블록이 토끼에 대한 데이터를 포함하고 있는 블록임을 인지할 수 있 다. 입력 블록의 내부 구조는 전술한 바와 같이, 전원(Vcc), 접지(GND), 저항(Rm) 및 입력 핀(Am)을 포함 할 수 있다. 상기 m은 1 내지 i 중 하나일 수 있다. 도 5를 참조하여 설명한 입력 블록의 외관 및 내부 구조는 하나의 실시 예에 불과하며 이에 한정되지 않는 다. 예컨대, 하나의 입력 핀 대신 둘 이상의 입력 핀을 포함할 수 있으며, 내부의 회로 구성도 도 5에 도시된 것과 상이할 수 있다. 신경 블록은 뉴런 블록 및/또는 활성화 함수 블록을 포함할 수 있다. 뉴런 블록과 활성화 함수 블록은 인공 신경망 모델을 구축하는데 이용될 수 있다. 뉴런 블록을 임의로 연결함으로써, 뉴 런 층의 개수 및/또는 각 층의 뉴런의 수를 결정할 수 있다. 뉴런 블록은 동일한 내부 저항을 가지고있고, 다른 종류의 블록들의 내부 저항과 겹치지 않는다. 하나의 뉴런 층의 뉴런 블록은 처리부에 있는 하 나의 아날로그 핀(예컨대, 도 4의 Ai+1)에 직렬로 연결될 수 있다. 처리부는 뉴런 블록의 내부 저항의 직렬 연결에 따른 전압의 변화를 측정하여 연결된 뉴런 블록의 개수를 인식할 수 있다. 새로운 뉴런 층은 새로운 아 날로그 핀(예컨대, 도 4의 Ai+2)에 연결될 수 있다. 처리부는 아날로그 핀의 수를 통해 뉴런의 층 수를 인식할 수 있다. 예컨대, 도 4에 도시된 예에서, 뉴런 층에 대한 아날로그 핀은 Ai+1과 Ai+2이므로, 처리부는 뉴런의 층 수가 2임을 인식할 수 있다. 또한, 각 핀의 전압을 통해 내부 저항을 측정할 수 있으며, 그에 따라 각 층의 뉴 런의 수를 인식할 수 있다. 도 4를 참조하여 설명하면, 기판의 아날로그 핀 Ai+1 및 Ai+2은 각각 서로 다른 뉴런 층을 의미하며, Node1_1 내지 Node1_m은 Ai+1단이 나타내는 뉴런 층에서의 노드의 개수(뉴런의 수)를 의미하 고, Node2_1 내지 Node2_n은 Ai+2단이 나타내는 뉴런 층에서의 노드의 개수(뉴런의 수)를 의미할 수 있다. 전체 뉴 런의 층수 및 각 측에서의 뉴런의 수 등을 포함하는 파라미터들은 인공 신경망 모델의 구축에 활용될 수 있다. 도 5의 (b)에 도시된 바와 같이, 뉴런 블록의 외관에는 해당 블록에 대한 정보가 표시될 수 있다. 블 록이 뉴런 블록일 경우, 그 외관에 뉴런 그림을 표시함으로써, 사용자가 직관적으로 해당 블록이 뉴 런 블록임을 인지할 수 있다. 뉴런 블록의 내부 구조는 전원(Vcc), 접지(GND), 저항 및 입력 핀(Ai+1)을 포함할 수 있다. 전술한 바 와 같이, 뉴런 블록에 대해서는 동일 저항이 이용될 수 있다. 도 5를 참조하여 설명한 뉴런 블록의 외관 및 내부 구조는 하나의 실시 예에 불과하며 이에 한정되지 않는 다. 예컨대, 하나의 입력 핀 대신 둘 이상의 입력 핀을 포함할 수 있으며, 내부의 회로 구성도 도 5에 도시된 것과 상이할 수 있다. 또한, 동일 저항 대신 상이한 저항을 적용함으로써 다양한 종류의 뉴런 블록을 이용 할 수도 있다. 활성화 함수 블록은 Sigmoid 함수, ReLu 함수, tanh 함수 등 인공 신경망 구조에서 이용되는 활성화 함수 들에 관한 블록일 수 있다. 인공 신경망 모델에서 활성화 함수는 일반적으로 하나의 함수만 이용되기 때문에 기 판의 하나의 아날로그 핀 Ai+3에 하나의 블록이 연결될 수 있다. 또한, 활성화 함수 블록의 내부 저항은 다 른 종류의 블록들의 내부 저항과 겹치지 않도록 결정될 수 있다. 예컨대, 복수의 뉴런 블록을 직렬 연결한 전체 저항과 활성화 함수 블록의 저항이 구별될 수 있도록 결정될 수 있다. 도 5의 (c)에 도시된 바와 같이, 활성화 함수 블록의 외관에는 해당 블록에 대한 정보가 표시될 수 있다. 블록이 활성화 함수 블록일 경우, 그 외관에 활성화 함수에 관한 그림을 표시함으로써, 사용자가 직 관적으로 해당 블록이 활성화 함수 블록임을 인지할 수 있다. 활성화 함수 블록의 내부 구조는 전원(Vcc), 접지(GND), 저항(Rk) 및 입력 핀(Ai+3)을 포함할 수 있다. 저항은 활성화 함수의 종류에 따라 상이할 수 있다. 처리부는 입력 핀(Ai+3)에 연결된 저항을 측정하여 해당 활 성화 함수를 식별할 수 있다. 기판에 연결된 뉴런 층의 아날로그 핀이 Ai+1 및 Ai+2이므로, 본 실시 예에서 는 활성화 함수 블록의 입력 핀을 Ai+3으로 표시하였으나, 이에 한정되지 않으며, 뉴런 층의 수에 따라 입 력 핀을 지시하는 부호는 달라질 수 있다. 도 5를 참조하여 설명한 활성화 함수 블록의 외관 및 내부 구조는 하나의 실시 예에 불과하며 이에 한정되 지 않는다. 예컨대, 하나의 입력 핀 대신 둘 이상의 입력 핀을 포함할 수 있으며, 내부의 회로 구성도 도 5에 도시된 것과 상이할 수 있다. 출력 블록은 영상 표시 장치나 음성 출력 장치 등을 포함할 수 있으며, 예컨대, 디스플레이, 스피커 또는 모터일 수 있으나, 이에 제한되지 않으며, 학습 결과나 분류 결과 등을 사용자에게 알려주고 또한 다양한 인터 랙션을 수행할 수 있는 장치를 포함할 수 있다. 출력 블록은 디스플레이, 스피커 등, 출력 장치의 종류에 따라 핀의 수나 입력 방식이 상이할 수 있다. 기판은 각각의 블록들에게 전원을 공급하고 각 블록들을 전기적으로 서로 연결시킬 수 있다. 기판은 마이크로 콘트롤러 또는 마이크로 프로세서 등을 포함할 수 있으며, 입출력 데이터의 처리, 인공 신경망의 학습 및 처리 결과 등에 대한 데이터를 제어하고 저장할 수 있다. 마이크로 콘트롤러는 운영체제(Operating System, OS)에 기반하지 않는 제어부를 의미하며, 예컨대, 마이크로 콘트롤러의 일 실시 예로서 아두이노가 사용될 수 있다. 마이크로 프로세서는 OS가 탑재된 제어부를 의미하며, 예컨대, 마이크로 프로세서의 일 실시 예로서 라즈베리파이가 사용될 수 있다. 도 6은 본 개시의 일 실시 예에 따른 인공 신경망 구현 방법을 설명하기 위한 도면이다. S610 단계에서, 처리부는 기판에 연결된 적어도 하나의 블록을 식별할 수 있다. 블록을 식별하는 방법은 도 3 내지 도 5를 참조하여 설명한 바와 동일하다. 즉, 블록의 식별은 블록의 ID를 식별함으로써, 수행될 수 있 으며, 블록의 ID는 블록에 자체적으로 저장된 ID 정보 또는 저항이나 전압의 측정에 의해 식별될 수 있다. S620 단계에서, 처리부는 식별된 블록에 기초하여 인공 신경망을 생성할 수 있다. 인공 신경망의 생성에 필요한 각종 데이터의 획득은 도 3 내지 도 5를 참조하여 설명한 바와 동일하다. 즉, 식별된 블록에 대한 정보를 블록 자체에 저장된 정보의 독출에 의해 획득할 수도 있고, 식별된 블록의 정보를 메모리로부터 독출하여 획득할 수 도 있다. S630 단계에서, 생성된 인공 신경망에 기반한 각종 결과를 출력할 수 있다. 출력될 수 있는 결과는 예컨대, 학 습 결과, 분류 결과 등이며, 도 3 내지 도 5를 참조하여 설명한 바와 동일하다. 출력 결과는 디스플레이, 스피 커 또는 모터 등을 통해 사용자에게 제공되고, 사용자는 제공된 출력 결과에 대해 다양한 인터랙션을 수행할 수 있다. 상기 설명된 실시 예에서, 처리부는 기판에 연결된 입력 블록의 ID를 인식함으로써, 메모리에 저장되어 있는 특 징 벡터를 호출할 수 있는 것으로 설명하였다. 그러나, 이는 입력 블록에만 한정되는 것은 아니다. 예컨대, 입 력 블록뿐만 아니라 뉴런 블록, 활성화 함수 블록, 출력 블록의 전부 또는 일부는 단지 ID에 관한 정보만을 포 함하고 있을 뿐이며, 처리부는 블록이 기판에 연결되면, ID를 식별하고, 그에 대응하는 데이터, 동작, 처리 등 은 메모리에 저장되어 있는 데이터, 동작, 처리 등을 호출하여 수행할 수 있다. 상기 설명된 실시 예에서, 다양한 블록의 구분은 블록의 형태를 통해 수행되도록 구성할 수 있다. 예컨대, 기판 에 꼽는 부분의 홈의 다양화, 블록 내 자체 저항값을 통한 ID 부여, 꼽는 위치의 구분 등을 통해 블록을 구분할 수 있다. 구분 대상 블록은 학습용 블록과 분류용 블록 등일 수 있다. 또는 구분 대상 블록은 입력 블록, 뉴런 블록, 활성화 함수 블록, 출력 블록 등일 수 있다. 상기 블록의 ID의 식별은 하나의 블록의 저항, 복수 개로 연결된 블록들의 전체 저항 등의 측정에 의해 수행될 수도 있고, 저항과는 관계없이 고유 번호 등의 식별 정보가 블록에 저장되어 있고, 이를 판독함으로써, 해당 블 록의 ID를 식별할 수도 있다. 본 개시의 예시적인 방법들은 설명의 명확성을 위해서 동작의 시리즈로 표현되어 있지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 또는 상이한 순서로 수행될 수도 있 다. 본 개시에 따른 방법을 구현하기 위해서, 예시하는 단계에 추가적으로 다른 단계를 포함하거나, 일부의 단 계를 제외하고 나머지 단계를 포함하거나, 또는 일부의 단계를 제외하고 추가적인 다른 단계를 포함할 수도 있 다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다."}
{"patent_id": "10-2017-0183862", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 인공 신경망의 일반적인 구조를 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 인공 신경망의 단층 퍼셉트론의 구조를 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 인공 신경망의 퍼셉트론 구조와 인공 신경망 구현 장치의 구성의 대응관계 를 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 인공 신경망 구현 장치의 구조를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 블록의 외관 및 내부 구조를 예시적으로 나타낸 도면이다. 도 6은 본 개시의 일 실시 예에 따른 인공 신경망 구현 방법을 설명하기 위한 도면이다."}
