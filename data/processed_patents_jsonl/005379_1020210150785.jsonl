{"patent_id": "10-2021-0150785", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0065025", "출원번호": "10-2021-0150785", "발명의 명칭": "문장을 교정하는 장치, 방법 및 컴퓨터 프로그램", "출원인": "주식회사 케이티", "발명자": "윤용욱"}}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "문장을 교정하는 장치에 있어서, 교정 대상에 해당하는 전체 문장 및 상기 전체 문장 중 교정이 필요한 어절 범위 정보를 입력받는 입력부;상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중적어도 하나에 대한 교정 후보 단어를 생성하는 교정 후보 생성부;상기 교정 후보 단어를 이용하여 교정 후보 네트워크를 생성하는 네트워크 생성부;상기 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출하는 교정 단어열 도출부; 및상기 최종 교정 단어열에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 교정부를 포함하는 문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 교정 후보 생성부는 상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 상기 치환 교정, 상기 삭제 교정 및 상기 신규 단어 추가 교정 중 적어도 하나의 교정을 진행할 경우에 대한 언어 모델 기반의 확률을계산하는 것인, 문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 어절 범위 정보에 포함된 k번째 단어를 치환 교정해야 하는 경우, 상기 교정 후보 생성부는 제 1 언어 모델(masked Language Model)을 통해 상기 전체 문장의 각 단어의 위치에서기구축된 어휘 사전의 각 단어가 출현할 단어 출현 확률을 계산하고, 상기 계산된 각 단어의 단어 출현 확률에 기초하여 상기 k번째 단어를 치환할 치환 후보 단어를 추출하는 것인,문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 어절 범위 정보에 포함된 k번째 단어를 상기 삭제 교정해야 하는 경우, 상기 교정 후보 생성부는 제 2 언어 모델(Left-context Language Model)을 통해 상기 k번째 단어가 출현할 제1 단어 출현 확률 및 상기 어절 범위 정보에 포함된 k+1번째 단어가 출현할 제 2 단어 출현 확률을 계산하고,상기 제 1 단어 출현 확률 및 상기 제 2 단어 출현 확률 간 비교에 기초하여 상기 교정 후보 단어를 생성하는것인, 문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0065025-3-제 4 항에 있어서, 상기 교정 후보 생성부는 제 3 언어 모델(Right-context Language Model)을 통해 상기 k번째 단어가 출현할 제3 단어 출현 확률 및 상기 어절 범위 정보에 포함된 k-1번째 단어가 출현할 제 4 단어 출현 확률을 계산하고,상기 제 3 단어 출현 확률 및 상기 제 4 단어 출현 확률 간 비교에 기초하여 상기 교정 후보 단어를 생성하는것인, 문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 어절 범위 정보에 포함된 k번째 단어의 이전 위치에 상기 신규 단어 추가 교정해야 하는 경우, 상기 교정 후보 생성부는 제 2 언어 모델을 통해 상기 k번째 단어가 출현할 제 1 단어 출현 확률 및 상기 k번째단어의 이전 위치에 추가할 신규 단어가 출현할 제 2 단어 출현 확률을 계산하고, 상기 제 1 단어 출현 확률 및상기 제 2 단어 출현 확률 간의 비교 결과와 제 3 언어 모델을 통해 계산된 상기 k번째 단어가 출현할 제 3 단어 출현 확률에 기초하여 상기 교정 후보 단어를 생성하는 것인, 문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 네트워크 생성부는 상기 교정 후보 단어에 포함된 복수의 후보 단어 및 상기 복수의 후보 단어 각각에 대한 단어 출현 확률을 매칭하여 상기 교정 후보 네트워크를 생성하는 것인, 문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 교정부는 상기 최종 교정 단어열에 포함된 후보 단어 및 단어 출현 확률에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 것인, 문장 교정 장치."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "문장 교정 장치에 의해 수행되는 문장을 교정하는 방법에 있어서, 교정 대상에 해당하는 전체 문장 및 상기 전체 문장 중 교정이 필요한 어절 범위 정보를 입력받는 단계;상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중적어도 하나에 대한 교정 후보 단어를 생성하는 단계;상기 교정 후보 단어를 이용하여 교정 후보 네트워크를 생성하는 단계;상기 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출하는 단계; 및상기 최종 교정 단어열에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 단계를 포함하는 문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 교정 후보 단어를 생성하는 단계는공개특허 10-2023-0065025-4-상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 상기 치환 교정, 상기 삭제 교정 및 상기 신규 단어 추가 교정 중 적어도 하나의 교정을 진행할 경우에 대한 언어 모델 기반의 확률을 계산하는 단계를 포함하는것인, 문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9 항에 있어서, 상기 교정 후보 단어를 생성하는 단계는상기 어절 범위 정보에 포함된 k번째 단어를 치환 교정해야 하는 경우, 제 1 언어 모델(masked Language Model)을 통해 상기 전체 문장의 각 단어의 위치에서 기구축된 어휘 사전의 각단어가 출현할 단어 출현 확률을 계산하는 단계 및상기 계산된 각 단어의 단어 출현 확률에 기초하여 상기 k번째 단어를 치환할 치환 후보 단어를 추출하는 단계를 포함하는 것인, 문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9 항에 있어서, 상기 교정 후보 단어를 생성하는 단계는상기 어절 범위 정보에 포함된 k번째 단어를 상기 삭제 교정해야 하는 경우, 제 2 언어 모델(Left-context Language Model)을 통해 상기 k번째 단어가 출현할 제 1 단어 출현 확률 및 상기어절 범위 정보에 포함된 k+1번째 단어가 출현할 제 2 단어 출현 확률을 계산하는 단계 및상기 제 1 단어 출현 확률 및 상기 제 2 단어 출현 확률 간 비교에 기초하여 상기 교정 후보 단어를 생성하는단계를 포함하는 것인, 문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 교정 후보 단어를 생성하는 단계는제 3 언어 모델(Right-context Language Model)을 통해 상기 k번째 단어가 출현할 제 3 단어 출현 확률 및 상기 어절 범위 정보에 포함된 k-1번째 단어가 출현할 제 4 단어 출현 확률을 계산하는 단계; 및상기 제 3 단어 출현 확률 및 상기 제 4 단어 출현 확률 간 비교에 기초하여 상기 교정 후보 단어를 생성하는단계를 포함하는 것인, 문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서, 상기 교정 후보 단어를 생성하는 단계는상기 어절 범위 정보에 포함된 k번째 단어의 이전 위치에 상기 신규 단어 추가 교정해야 하는 경우, 제 2 언어 모델을 통해 상기 k번째 단어가 출현할 제 1 단어 출현 확률 및 상기 k번째 단어의 이전 위치에 추가할 신규 단어가 출현할 제 2 단어 출현 확률을 계산하는 단계 및상기 제 1 단어 출현 확률 및 상기 제 2 단어 출현 확률 간의 비교 결과와 제 3 언어 모델을 통해 계산된 상기k번째 단어가 출현할 제 3 단어 출현 확률에 기초하여 상기 교정 후보 단어를 생성하는 단계를 포함하는 것인,공개특허 10-2023-0065025-5-문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9 항에 있어서, 상기 교정 후보 네트워크를 생성하는 단계는상기 교정 후보 단어에 포함된 복수의 후보 단어 및 상기 복수의 후보 단어 각각에 대한 단어 출현 확률을 매칭하여 상기 교정 후보 네트워크를 생성하는 단계를 포함하는 것인, 문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서, 상기 교정하는 단계는상기 최종 교정 단어열에 포함된 후보 단어 및 단어 출현 확률에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 포함하는 것인, 문장 교정 방법."}
{"patent_id": "10-2021-0150785", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "문장을 교정하는 명령어들의 시퀀스를 포함하는 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우,교정 대상에 해당하는 전체 문장 및 상기 전체 문장 중 교정이 필요한 어절 범위 정보를 입력받고,상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중적어도 하나에 대한 교정 후보 단어를 생성하고,상기 교정 후보 단어를 이용하여 교정 후보 네트워크를 생성하고,상기 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출하고,상기 최종 교정 단어열에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 명령어들의시퀀스를 포함하는, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "문장을 교정하는 장치는 교정 대상에 해당하는 전체 문장 및 전체 문장 중 교정이 필요한 어절 범위 정보를 입력 받는 입력부, 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중 적어도 하나에 대한 교정 후보 단어를 생성하는 교정 후보 생성부, 교정 후보 단어를 이용하여 교정 후 보 네트워크를 생성하는 네트워크 생성부, 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출하는 교정 단 어열 도출부 및 최종 교정 단어열에 기초하여 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 교정부를 포함할 수 있다."}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 문장을 교정하는 장치, 방법 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "대다수의 한국인이 영어 작문을 할 때, 문법에 맞지 않는 문장을 작성하거나 표현이 어색한 문장을 작성하는 경 우가 많다. 최근에는 인공지능(Artificial Intelligence) 학습 기술을 이용한 작문 교정 방법들이 많이 제안되고 있다. 이러한 기존의 작문 교정 방법은 주로 문법이 틀린 오류문장과 이에 대응하는 정답문장으로 이루어진 다량의 학 습 데이터에 기초하여 학습된 교정학습모델을 통해 사용자가 입력한 대상 문장을 교정한다. 또한, 기존의 작문 교정 방법은 사용자가 틀리기 쉬운 철자 오류나 문법 오류 등의 예제를 사전 형태의 미리 구축하고, 이를 이용 하여 사용자가 입력한 대상 문장에서 표제어를 검출하여 교정한다. 이와 같은 작문 교정 방법은 교정학습모델을 통해 영어 문장에 포함된 철자 오류, 문법 오류 등을 검출하고 이 를 교정하는 기능을 제공하지만, 교정학습모델에 훈련시키지 않은 표현이나, 지식 사전에 포함되지 않은 철자 오류 등은 교정하지 못하는 단점이 있다. 또한, 교정학습모델의 학습에 필요한 오류-정답 문장 쌍을 구축하는 작업을 언어 전문가가 직접 수행해야 하기 때문에 훈련 데이터를 구축하는데 상당한 시간과 비용이 든다. 또한, 영어 문장을 구성하는 경우의 수는 무한대에 가까울 만큼 다양하기 때문에 학습자가 작성할 오류 문장의 유형도 많아질 수 밖에 없고, 여기에 대응하는 정답 문장을 빠짐없이 구축하기는 불가능에 가깝기 때문에 완전 한 형태의 오류 교정 기능을 기대하기는 힘든 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 제2008-0039009호 (2008.05.07. 공개)"}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 교정 대상의 전체 문장 중 교정이 필요한 어 절 범위에 포함된 단어에 대하여 치환, 삭제, 추가 중 적어도 하나에 대한 교정 후보 단어를 생성하고, 교정 후 보 단어를 이용한 교정 후보 네트워크에 기초하여 어절 범위 정보에 포함된 단어를 교정하고자 한다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 제 1 측면에 따른 문장을 교정하는 장치는 교정 대상에 해당하는 전체 문장 및 상기 전체 문장 중 교정이 필요한 어절 범위 정보를 입력받는 입력부; 상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중 적어 도 하나에 대한 교정 후보 단어를 생성하는 교정 후보 생성부; 상기 교정 후보 단어를 이용하여 교정 후보 네트 워크를 생성하는 네트워크 생성부; 상기 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출하는 교정 단 어열 도출부; 및 상기 최종 교정 단어열에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정 하는 교정부를 포함할 수 있다. 본 발명의 제 2 측면에 따른 문장 교정 장치에 의해 수행되는 문장을 교정하는 방법은 교정 대상에 해당하는 전 체 문장 및 상기 전체 문장 중 교정이 필요한 어절 범위 정보를 입력받는 단계; 상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중 적어도 하나에 대한 교정 후보 단어를 생성하는 단계; 상기 교정 후보 단어를 이용하여 교정 후보 네트워크를 생성하는 단계; 상기 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출하는 단계; 및 상기 최종 교정 단어열에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 단계를 포함할 수 있다. 본 발명의 제 3 측면에 따른 문장을 교정하는 명령어들의 시퀀스를 포함하는 컴퓨터 판독가능 기록매체에 저장 된 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우, 교정 대상에 해당하는 전체 문장 및 상기 전체 문장 중 교정이 필요한 어절 범위 정보를 입력받고, 상기 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중 적어도 하나에 대한 교정 후보 단어를 생성하고, 상기 교정 후보 단어를 이용하여 교정 후보 네트워크를 생성하고, 상기 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도 출하고, 상기 최종 교정 단어열에 기초하여 상기 어절 범위 정보에 포함된 적어도 하나의 단어를 교정하는 명령 어들의 시퀀스를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본 발명을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 기재된 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 본 발명은 교정 대상의 전체 문장 중 교정이 필요한 어절 범위에 포함된 단어에 대하여 치환, 삭제, 추가 중 적어도 하나에 대한 교정 후보 단어를 생성하고, 교정 후보 단어를 이용한 교정 후보 네트워크에 기초하여 어절 범위 정보에 포함된 단어를 교정할 수 있다. 이를 통해, 본 발명은 학습자가 작문이나 회화를 하면서 범하기 쉬운 철자나 문법오류를 손쉽게 교정할 수 있다. 또한, 본 발명은 형식적인 문법 오류뿐만 아니라 표현상의 어색한 부분을 자연스러운 표현으로 교정할 수 있다. 또한, 본 발명은 문장 전체를 전부 교정하는 것이 아니라 사용자가 지정한 부분에 대해서만 교정을 수행하므로 원래 사용자가 입력한 문장의 의미는 보존하면서 문법의 오류나 어색한 표현만을 한정시켜 교정할 수 있다. 또한, 본 발명은 단어의 치환뿐 아니라 교정후 단어가 삭제되어야 하는 경우 또는, 특정 위치에 새로운 단어가 추가되어야 하는 경우까지 다양한 케이스의 교정이 가능하다. 또한, 본 발명은 기존의 교정학습모델의 학습을 위해 많은 양의 훈련 데이터를 구축하거나, 교정학습모델을 학 습시킬 필요가 없기 때문에 저비용으로 기구축된 언어 모델을 통해 문법 및 표현 등을 교정할 수 있다."}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 본 명세서에 있어서 단말 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말 또는 디 바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말 또는 디바이스에서 수행될 수도 있다. 이하, 첨부된 구성도 또는 처리 흐름도를 참고하여, 본 발명의 실시를 위한 구체적인 내용을 설명하도록 한다. 언어 모델(Language Model, LM)은 인간의 언어로 작성된 문장을 구성하는 단어들간의 출현 확률을 계산하는 수 학적 모델이다. 이러한 언어 모델은 Masked LM(이하, 제 1 언어 모델), Left-context LM(이하, 제 2 언어 모 델) 및 Right-context LM(이하, 제 3 언어 모델)을 포함할 수 있다. 하나의 영어 문장이 n개의 단어로 이루어져 있다고 하고, w_k는 문장내 k-번째 나타난 단어라고 하자. 문장집합 내에서 임의의 문장의 출현 확률은 [수학식 1]과 같이 나타낼 수 있다. [수학식 1] P(w_1, w_2, ... , w_k, ... , w_n-1, w_n) 제 2 언어 모델은 첫 단어부터 시작하여 k-1 번째 단어가 출현했을 때, 그 다음 단어인 k번째 단어 w_k가 문장 내에서 나타날 확률(수학식 2)을 출력하는 모델이다. [수학식 2] P(w_k | w_1, w_2, ... , w_(k-1)) 제 1 언어 모델은 한 문장 내 여러 단어 중에 한 단어를 맞추는 괄호 넣기 게임과 유사하다. 다음의 제 1 문장 을 예로 들어 보자. 제 1 문장: The man went to ( A ) store. He bought a gallon ( B ) milk. 제 1 문장의 의미를 가장 잘 살리려면 A, B 괄호에 들어갈 단어로는 'grocery'와 'of'가 될 것이다. 이와 같이, 제 1 언어 모델은 제 2 언어 모델처럼 좌측에 이미 나타난 단어만을 참조하는 것이 아니라 문장 전 체에 나타난 단어를 참조하여 괄호에 들어갈 단어의 출현 확률을 계산한다. 제 1 언어 모델은 단어가 속한 문장뿐 아니라, 그 이전 문장의 컨텍스트와 그 이후 문장의 컨텍스트도 함께 고 려하여 훈련된다. 하지만, 컨텍스트가 커지면 계산비용이 증가하므로 일정 범위의 컨텍스트로 참조 범위를 제한하게 된다. n개의 단어로 구성된 문장 W가 있고 n-1개의 단어가 주어졌을 때, 제 1 언어 모델에서 k번째 순서에 나올 단어 w_k가 w일 출현 확률은 [수학식 3]과 같이 정의될 수 있다. [수학식 3] f(k, ,w, W) = p(w_k=w | w_1, w_2, ... , w_(k-1), w_(k+1), ..., w_n), k=1..n 여기서 w는 전체 어휘집합의 단어이다. 잠시 도 1a를 참조하여 제 1 언어 모델의 구축 과정을 설명하기로 한다. 도 1a를 참조하면, 제 1 언어 모델은 BERT(Bidirectional Encoder Representations from Transformers) 모델을 원형으로 하여 훈련된다. 언어 모델 구축 서버는 대용량의 원시문장(즉, 다양한 도메인에서 문법에 잘 맞고 표현이 깨끗한 문장들)을 수집한다. 이어서, 언어 모델 구축 서버는 대용량의 원시문장을 구성하는 원시 단어와 기호에 대한 정제 과정을 거친 후 단어를 기설정된 기준에 맞게 선별한 후 코드화하여 어휘 집합을 구축한다. 이어서, 언어 모델 구축 서버는 원시문장 내에 단어 중에서 마스킹(masking)할 단어를 임의로 선정하고, 선정된 단어를 원래 철자가 아닌 기설정된 기호(예컨대, 'MASKED')로 일괄 치환한다. 이어서, 언어 모델 구축 서버는 치환된 문장 집합을 대상으 로 문장 내 단어간 확률을 비지도 심층 신경망을 통해 훈련한다. 이어서, 언어 모델 구축 서버는 마스킹된 단 어들에 대하여 어휘 집합에 전체 단어 기준으로 계산된 출현 단어 확률(즉, 정답 단어 확률)을 제 1 언어 모델 에 최종적으로 추가한다. 한편, 제 2 언어 모델 및 제 3 언어 모델의 훈련은 GPT(Generative Pre-trained Transformer) 언어모델의 훈련 방법에 기초한다. 도 1b 및 1c를 함께 참조하여 제 2 언어 모델 및 제 3 언어 모델의 구축 과정을 설명하기로 한다. 도 1b 및 1c를 참조하면, 언어 모델 구축 서버는 대용량 원시문장으로부터 문장을 하나씩 가져와서훈련 데이터 형태로 가공한다. 예를 들어 원시문장이 'Since capital punishment was abolished, the crime rate has increased.'라 가정하면, 언어 모델 구축 서버는 제 2 언어 모델 구축의 경우, 제 1 테이블 에 도시된 바와 같이 좌측 방향으로 훈련 데이터를 단어 개수만큼 확장시키고, 제 3 언어 모델 구축의 경우, 제 2 테이블에 도시된 바와 같이 우측 방향으로 훈련 데이터를 단어 개수만큼 확장시킨다. 이어서, 언어 모델 구축 서버는 심층 신경망 네트워크를 통해 제 1 테이블에 포함된 좌측 컨텍스트에 해당 하는 어절에 대한 임베딩 값을 계산한다. 이어서, 언어 모델 구축 서버는 좌측 컨텍스트에 해당하는 어절에 대한 임베딩 값에 기초하여 대상 단어가 출현 할 확률을 계산한다. 여기서, 대상 단어의 출현 확률은 [수학식 4]를 통해 계산된다. [수학식 4] p(w_k|Left_context(w_k)) = softmax(Embedding(Left_context(w_k))) 여기서, Embedding(ㆍ)은 심층 신경망에서 w_k(대상 단어)의 Left-context(좌측 컨텍스트)에 해당하는 단어들의 최종 출력 노드가 가지고 있는 값을 곱한 값이다. [수학식 4]를 통해 계산된 값이 가장 큰 대상 노드가 후보 훈련 결과가 된다. 언어 모델 구축 서버는 후보 단어의 소프트맥스(softmax) 값과 정답 단어의 소프트맥스 값 간의 차이가 최소화 되도록 심층 네트워크의 연결 파라미터 값을 최적화시키면서 제 2 언어 모델을 학습시킨다. 언어 모델 구축 서버는 심층 신경망 네트워크를 통해 제 2 테이블에 포함된 우측 컨텍스트에 해당하는 어절 에 대한 임베딩 값을 계산한다. 이어서, 언어 모델 구축 서버는 우측 컨텍스트에 해당하는 어절에 대한 임베딩 값에 기초하여 대상 단어가 출현 할 확률을 계산한다. 여기서, 대상 단어의 출현 확률은 [수학식 5]를 통해 계산된다. [수학식 5] p(w_k|Right_context(w_k)) = softmax(Embedding(Right_context(w_k))) 여기서, Embedding(ㆍ)은 심층 신경망에서 w_k(대상 단어)의 Right-context(우측 컨텍스트)에 해당하는 단어들 의 최종 출력 노드가 가지고 있는 값을 곱한 값이다. [수학식 5]를 통해 계산된 값이 가장 큰 대상 노드가 후보 훈련 결과가 된다. 언어 모델 구축 서버는 후보 단어의 소프트맥스(softmax) 값과 정답 단어의 소프트맥스 값 간의 차이가 최소화 되도록 심층 네트워크의 연결 파라미터 값을 최적화시키면서 제 3 언어 모델을 학습시킨다. 한편, 인간의 언어는 유한개의 단어로 이루어진 어휘집합을 기준으로 어휘집합에 속한 단어들의 연속된 조합으 로 구성된다. 한국어, 영어 등의 언어에 따라 약간의 차이는 있지만 어휘집합은 보통 10만개 정도로 구성되어 있고, 자주 사용하는 어휘의 집합은 단어 수가 만 개를 넘지 않는다. 그러나, 인간이 구사하는 언어 문장을 자 세히 살펴보면, 단어들이 무작위로 나열되어 있는 것이 아니고, 구성 단어 간 출현 양상이 일종의 패턴을 가지 고 나타남을 확인할 수 있다. 다음 두 문장을 예를 들어 본다. 제 2 문장: I go to school. (나는 학교에 다닌다.) 제 3 문장: School from I goes. (학교로부터 나는 가다.) 인간이 언어를 구사할 때는 제 2 문장과 같이 어떤 정해진 규칙 내지는 패턴으로 단어를 조합하여 의사를 표현 한다. 제 3 문장은 제 2 문장에서 사용한 단어들의 순서를 바꾼 문장이지만 문장의 표현이 매우 어색하다. 이는, 제 2 외국어를 처음 배우는 학습자가 범하기 쉬운 실수와 매우 유사하다고 할 수 있다. 제 2 문장은 언어 모델을 매우 잘 반영한 예라고 할 수 있고, 제 3 문장은 언어 모델과 무관한 문장 구성이 될 것이다. 언어 모델을 통해 제 2 문장의 \"to school\"과 제 3 문장의 \"school from\"의 구(phrase)를 비교해 보자. 언어 모델에서는 'to school'의 출현 확률이 'school from'의 출현 확률보다 높게 나타난다. 언어 모델은 각 단어 조합의 출현 확률에 기초하여 자연스러운 문장 구성을 반영하게끔 훈련된다. 이와 마찬가지로 'I go'의 출현 확률이 'I goes'의 출현 확률보다 높을 것으로 유추할 수 있으며, 이를 이용하면 영어에서 나타나는 주어- 동사 간 일치라는 문법 교정문제를 해결할 수 있다. 철자가 틀린 단어가 문장에 포함된 경우, 해당 단어는 언어 모델상에서 낮은 출현확률을 갖게 되기 때문에 그에 해당하는 정답 언어를 찾기 위해서 한정된 수의 어휘집합의 단어들의 출현 확률을 비교하여 정답 후보를 추정할 수 있다. 문법이나 철자 오류가 아닌 표현상의 어색한 부분도 언어 모델을 이용하여 해결할 수 있다. 다음 문장을 예로 들어 본다. 제 4 문장: Since capital punishment was abandoned, the crime rate has increased. 제 4 문장은 철자 오류나 문법 오류가 없지만 번역해 보면, '극형제도가 버려진 뒤, 범죄율이 증가했다'란 뜻으 로 표현이 매끄럽지 못하다. 제 4 문장을 구성하는 단어 중 'abandoned'를 'abolished'로 바꾸면 '극형제도가 폐지된 뒤, 범죄율이 증가했다'란 뜻으로 좀더 자연스러운 표현으로 변경된다. 이는 언어 모델 상에서 'abandoned'의 출현 확률이 'abolished'의 출현 확률보다 낮은 값을 갖기 때문이다. 본 발명은 기구축된 언어 모델(제 1 언어 모델, 제 2 언어 모델, 제 3 언어 모델)을 이용하여 영어 문장의 문법 을 교정하고, 어색한 표현을 정상적인 표현으로 교정하는 방법을 제안한다. 도 2는 본 발명의 일 실시예에 따른, 문장 교정 장치의 블록도이다. 도 2를 참조하면, 문장 교정 장치는 입력부, 교정 후보 생성부, 네트워크 생성부, 교정 단 어열 도출부 및 교정부를 포함할 수 있다. 다만, 도 2에 도시된 문장 교정 장치는 본 발명의 하나의 구현 예에 불과하며, 도 2에 도시된 구성요소들을 기초로 하여 여러 가지 변형이 가능하다. 본 발명에서 사용되는 제 1 언어 모델(masked Language Model)은 단어 치환에 사용되는 언어 모델이고, 본 발명 에서 사용되는 제 2 언어 모델(Left-context Language Model) 및 제 3 언어 모델(Right-context Language Model)은 단어의 삭제 및 추가에 사용되는 언어 모델이다. 입력부는 교정 대상에 해당하는 전체 문장 및 전체 문장 중 교정이 필요한 어절 범위 정보를 입력받을 수 있다. 예를 들어, 도 3을 참조하면, 입력부는 사용자로부터 전체 문장에 해당되는 'My offer has declined'에서 교정이 필요한 어절 범위 정보에 해당하는 'has declined'를 지정받을 수 있다. 이 때, 교 정이 필요한 어절 범위 정보를 제외한 문장의 나머지 어절들은 전체 문장의 구성을 위한 컨텍스트 정보로 만 활용되고 교정대상에서 제외될 수 있다. 보통 영어 작문시 주어나 목적어 등의 명사형 어절들은 사용자가 틀리는 경우가 거의 없고 대부분 동사의 활용 이나 전치사구 등의 표현에서 개선이 필요한 부분이 많다. 사용자가 지정한 교정이 필요한 어절 범위에 한정하 여 교정함으로써 좀 더 정교한 교정 결과(205, 'has declined' -> 'has been declined')를 제공할 수 있다. 교정 후보 생성부는 교정이 필요한 어절 범위 정보에 대하여 전처리 작업(예컨대, 문장 단위의 분절, 문장 내 단어 분리, 특수문자의 치환 등)을 수행할 수 있다. 교정 후보 생성부는 전체 문장을 구성하는 각 원시 단어에 대하여 기구축된 제 1 언어 모델이 사용하는 단 어 코드로 각 원시 단어를 매핑할 수 있다. 이는 이후, 각 원시 단어에 매핑된 단어 코드의 출현확률정보(제 1 언어 모델에 저장된 출현확률정보)를 이용하기 위해서이다. 교정 후보 생성부는 교정이 필요한 어절 범위 정보를 구성하는 각 원시 단어에 대하여 교정 후보 단어를 생성할 수 있다. 예를 들어, 도 3을 참조하면, 사용자가 입력한 전체 문장이 'My offer has declined'이고, 교정이 필요한 어절 범위 정보를 'has declined'로 지정하였다고 가정하자. 이 때, 교정이 필요한 어절 범위 정보를 구성하는 각 원시 단어(이하, 교정 대상 단어로 명칭함)를 'w_1, w_2, w_3, … , w_n' 으로 표시하자. 교정 대상 단어가 교 정이 된다면, 치환 교정(예컨대, 단어_A -> 단어_B), 삭제 교정(예컨대, 단어_A -> null) 및 신규 단어 추가 교 정(예컨대, 단어_A -> 단어_B 단어_A)으로 교정이 이루어질 수 있다. 'My offer has declined'의 경우, 교정 대상의 어절 범위 정보인 'has declined'가 교정 후 'has been declined'가 되었고, 이는 신규 단어가 추 가하는 교정이 수행되었음을 확인할 수 있다. 신규 단어 추가 교정의 경우, 단어의 수가 많아지면 제 1 언어 모델의 계산수가 기하급수적으로 증가하므로 본 발명에서는 입력된 전체 문장의 어절 시작부분과 단어의 사이사이 그리고 어절 끝부분에 하나의 단어가 발생한 다고 가정한다. 이하에서는 도 4를 참조하여 함께 설명하기로 한다. 도 4는 문장의 원시 단어와 신규 단어가 추가될 부분을 심 볼로 나타낸 문장 심볼이다. 도 4를 참조하면 전체 문장(W)에 대한 문장 심볼에서 w_1, ... ,w_n은 교정 대상의 어절 범위이고, W_m은 교정 대상의 어절 범위 이전의 문장 처음부터의 어절 범위이고, W_N은 교정 대상의 어절 범위 이후 문장 끝까지의 어절 부분을 나타낸다. <l_j>는 교정결과 신규 단어가 들어갈 후보 위치를 가리킨다. 우선 각 원시 단어 위치에 대하여 삭제가 일어나는 경우, 치환이 일어나는 경우, 기존 원시 단어에 대해 신규 단어 추가가 일어나는 경우에 대하여 언어 모델을 기반으로 확률을 계산할 수 있다. 구체적으로, 교정 후보 생성부는 교정 대상의 어절 범위 정보에 포함된 적어도 하나의 원시 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중 적어도 하나에 대한 교정 후보 단어를 생성할 수 있다. 교정 후보 생성부는 교정 대상의 어절 범위 정보에 포함된 적어도 하나의 원시 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중 적어도 하나의 교정을 진행할 경우에 대한 언어 모델 기반의 확률을 계산 할 수 있다. 교정 대상의 어절 범위 정보에 포함된 k번째 단어를 치환 교정해야 하는 경우, 교정 후보 생성부는 제 1 언어 모델을 통해 전체 문장의 각 원시 단어의 위치에서 기구축된 어휘 사전의 각 단어가 출현할 단어 출현 확 률을 계산하고, 계산된 각 단어의 단어 출현 확률에 기초하여 k번째 원시 단어를 치환할 치환 후보 단어를 추출 할 수 있다. 교정 후보 생성부는 제 1 언어 모델을 이용하여 전체 문장의 각 원시 단어 위치(k)에서 어휘집합(V)의 각 단어들(w)이 출현할 단어 출현 확률 f(k, w, W)을 계산할 수 있다. 이 때, 가장 높은 출현 확률을 갖는 단어를 w_<top-1> 단어라고 하면, 해당 단어의 단어 출현 확률은 [수학식 6]에 의하여 계산된다. [수학식 6] w_<top-1> ="}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "교정 후보 생성부는 [수학식 6]을 이용하여 두번째로 가장 높은 출현 확률을 갖는 w_<top-2> 단어를 추출 할 수 있다. 이 때, w_<top-2> 단어는 어휘집합에서 w_<top-1>에 해당하는 단어를 제외한 나머지 단어들에 대 한 출현 확률로부터 결정될 수 있다. 이와 같은 방식으로 교정 후보 생성부는 어휘집합으로부터 k번째 원시 단어를 치환할 top-K 개의 치환 후 보 단어(즉, 교정 후보 단어)를 추출할 수 있다. 만일 교정되기 이전의 원시단어(w_k)가 [수학식 6]을 통해 계산된 w_<top-x> 단어 중 하나와 동일하다면 원시 단어가 올바른 표현에 속할 가능성이 높다고 볼 수 있다. 한편, 교정 대상의 어절 범위 정보에 포함된 k번째 원시 단어를 삭제 교정해야 하는 경우, 교정 후보 생성부 는 제 2 언어 모델을 통해 k번째 원시 단어가 출현할 제 1 단어 출현 확률 및 어절 범위 정보에 포함된 k+1번째 원시 단어가 출현할 제 2 단어 출현 확률을 계산하고, 제 1 단어 출현 확률 및 제 2 단어 출현 확률 간 비교에 기초하여 교정 후보 단어를 생성할 수 있다. 여기서, 제 2 언어 모델을 이용한 단어 출현 확률(g)은 [수학식 7]과 같이 정의될 수 있다. [수학식 7] g(k, w, W) = p(w_k=w | w_1, w_2, … , w_(k-1)), k=1..n 교정 후보 생성부는 k번째 원시 단어가 출현할 제 1 단어 출현 확률 및 k+1번째 원시 단어가 출현할 제 2 단어 출현 확률 간의 차이값이 기설정된 임계치보다 큰 경우, 교정 대상의 어절 범위 정보에서 k번째 원시 단어 를 삭제하고, k번째 원시 단어를 대체할 교정 후보 단어를 생성할 수 있다 즉, 교정 대상의 어절 범위 정보에 포함된 제 1 원시 단어 w_k가 교정 후 삭제되는 경우는 해당 원시 단어 w_k 바로 다음에 출현하는 제 2 원시 단어인 w_(k+1)가 w_(k-1) 다음에 나오는 경우일 것이고, 제 2 원시 단어의 단 어 출현 확률은 [수학식 7]에서 g(k, w_(k+1), W)로 계산될 수 있다. 이 때, [수학식 8]과 같이, 제 2 원시 단 어의 단어 출현 확률이 제 1 원시 단어의 단어 출현 확률인 g(k, w_k, W)보다 크다면 교정 후 제 1 원시 단어 w_k가 삭제될 가능성이 커진다. [수학식 8] g(k, w_(k+1), W) - g(k, w_k, W) > 기설정된 임계치 교정 후보 생성부는 제 3 언어 모델을 통해 k번째 원시 단어가 출현할 제 3 단어 출현 확률 및 어절 범위 정보에 포함된 k-1번째 원시 단어가 출현할 제 4 단어 출현 확률을 계산하고, 제 3 단어 출현 확률 및 제 4 단 어 출현 확률 간 비교에 기초하여 교정 후보 단어를 생성할 수 있다. 여기서, 제 3 언어 모델을 이용한 단어 출현 확률(h)은 [수학식 9]와 같이 정의될 수 있다. [수학식 9] h(k, w, W) = p(w_k=w | w_(k+1), w_(k+2), … , w_n), k=1..n 교정 후보 생성부는 k번째 원시 단어가 출현할 제 3 단어 출현 확률 및 k-1번째 원시 단어가 출현할 제 4 단어 출현 확률 간의 차이값이 기설정된 임계치보다 큰 경우, 교정 대상의 어절 범위 정보에서 k번째 원시 단어 를 삭제하고, k번째 원시 단어를 대체할 교정 후보 단어를 생성할 수 있다. 즉, 교정 대상의 어절 범위 정보에 포함된 제 1 원시 단어 w_k가 교정 후 삭제되는 경우는 해당 원시 단어 w_k 바로 이전에 출현하는 제 3 원시 단어인 w_(k-1)가 w_(k+1) 이전에 나오는 경우일 것이고, 제 3 원시 단어의 단 어 출현 확률은 [수학식 9]에서 h(k, w_(k-1), W)로 계산될 수 있다. 이 때, [수학식 10]과 같이, 제 3 원시 단어의 단어 출현 확률이 제 1 원시 단어의 단어 출현 확률인 h(k, w_k, W)보다 크다면 교정 후 제 1 원시 단어 w_k가 삭제될 가능성이 커진다. [수학식 10] h(k, w_(k-1), W) - h(k, w_k, W) > 기설정된 임계치 교정 후보 생성부는 [수학식 8] 및 [수학식 10]를 동시에 만족하는 경우, 교정 대상의 어절 범위 정보에서 k번째 원시 단어를 삭제하고, k번째 원시 단어를 대체할 교정 후보 단어를 생성할 수 있다. 이 때, k번째 원시 단어는 삭제되었다고 추정하고, k번째 원시 단어는 기정의된 기호(예컨대, 또는 Del)로 치환될 수 있다. 교정 후보 생성부는 k번째 단어 교정 후보를 Del로 치환하고 그 확률값도 g(k, w_(k+1), W)와 h(k, w_(k- 1), W) 중에서 큰 값으로 선정할 수 있다. 한편, 어절 범위 정보에 포함된 k번째 원시 단어의 이전 위치에 신규 단어 추가 교정해야 하는 경우, 교정 후보 생성부는 제 2 언어 모델을 통해 k번째 원시 단어가 출현할 제 1 단어 출현 확률 및 k번째 원시 단어의 이 전 위치에 추가할 신규 단어가 출현할 제 2 단어 출현 확률을 계산하고, 제 1 단어 출현 확률 및 제 2 단어 출 현 확률 간의 비교 결과와 제 3 언어 모델을 통해 계산된 k번째 원시 단어가 출현할 제 3 단어 출현 확률에 기 초하여 교정 후보 단어를 생성할 수 있다. 도 4에서 단어 위치 w_i 위치 앞에, 즉 <l_i>에 교정 후 신규 단어 a가 추가되는 경우를 가정해보면, 교정 후보 생성부는 제 2 언어 모델의 g(k, a, W), a≠w_k, 를 계산하여 [수학식 11]의 조건을 만족하는지 를 체크하고, 제 3 언어 모델을 통해 w_k가 교정 후 가장 높은 단어 출현 확률을 가지게 되는 단어인지를 [수학 식 12]의 조건을 만족하는지 여부를 통해 확인할 수 있다. [수학식 11] g(k, a, W) - g(k, w_k, W) > 기설정된 임계치, a≠w_k [수학식 12] w_k =="}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "교정 후보 생성부는 [수학식 11] 및 [수학식 12]를 동시에 만족하는 경우, <l_k>위치에 신규 단어 a를 삽 입하도록 신규 단어 a를 교정 후보 단어로 선정할 수 있다. 이 때, 신규 단어 a의 단어출현확률은 g(k, a, W) 이다. 네트워크 생성부는 교정 후보 단어를 이용하여 교정 후보 네트워크를 생성할 수 있다. 예를 들어, 도 5를 참조하면, 네트워크 생성부는 교정 후보 단어를 top-K x J 형태의 배열로 표현함으로써 교정 후보 네트워 크를 생성할 수 있다. 네트워크 생성부는 교정 후보 단어에 포함된 복수의 후보 단어 및 복수의 후보 단어 각각에 대한 단어 출 현 확률을 매칭하여 교정 후보 네트워크를 생성할 수 있다. 교정 단어열 도출부는 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출할 수 있다. 교정 단어열 도출부는 교정 후보 네트워크에 대하여 최적 경로를 계산하여 최종 교정 단어열을 도출할 수 있다. 예를 들어, 도 5를 참조하면, 교정 후보 네트워크는 K x J 의 2차원 배열로 표현되고, 교정대상 단어열의 t번째 단어위치의 열벡터 w_(i, t)는 t번째 위치에서의 단어 치환 후보 버퍼에 해당된다. 첫 단어 t=1부터 시작하여 t=J까지 시간 단계별로 경로를 찾아가면서 최종 교정 단어열이 도출될 수 있다. 각 경로 탐색 단계 t마다 단어 w_i,t 에 대하여 K개의 교정 후보 단어와 단어 출현 확률을 배열에 저장될 수 있다. 단어 출현 확률이 큰 순서 로 정렬되어 저장될 수 있다. 교정 후보 네트워크에서 최적의 교정 후보열이 (w_(3,1), w_(1,2), w_(2,3), … w_(3,J)) 라 하면, 해당 단어열은 Beam Search 알고리듬을 이용하여 계산된다. Beam의 크기는 단어치환 버퍼 사이즈인 top-K를 디폴트로 하며, 5을 넘지 않도록 한다. 교정부는 최종 교정 단어열에 포함된 후보 단어 및 단어 출현 확률에 기초하여 어절 범위 정보에 포함된 적어도 하나의 단어를 교정할 수 있다. 예를 들어, 도 3을 다시 참조하면, 교정부는 교정대상의 어절 범위 정보의 처음 단어부터 시작하여 하나씩 교정된 단어를 출력할 수 있다. 단순 치환 교정의 경우, 치환된 단어로 변경하여 출력하고, 삭제 교정의 경우, 기설정된 특수기호 'DEL'로 치환하여 출력하고, 신규 단어가 추가되는 경우, 신규 단어가 추가된 기존 원래 단 어를 포함하여 출력할 수 있다. 한편, 당업자라면, 입력부, 교정 후보 생성부, 네트워크 생성부, 교정 단어열 도출부 및 교정부 각각이 분리되어 구현되거나, 이 중 하나 이상이 통합되어 구현될 수 있음을 충분히 이해할 것이다. 도 6은 본 발명의 일 실시예에 따른, 문장 교정 방법을 나타낸 흐름도이다. 도 6을 참조하면, 단계 S601에서 문장 교정 장치는 교정 대상에 해당하는 전체 문장 및 전체 문장 중 교정 이 필요한 어절 범위 정보를 입력받을 수 있다. 단계 S603에서 문장 교정 장치는 어절 범위 정보에 포함된 적어도 하나의 단어에 대하여 치환 교정, 삭제 교정 및 신규 단어 추가 교정 중 적어도 하나에 대한 교정 후보 단어를 생성할 수 있다. 단계 S605에서 문장 교정 장치는 교정 후보 단어를 이용하여 교정 후보 네트워크를 생성할 수 있다. 단계 S607에서 문장 교정 장치는 교정 후보 네트워크에 기초하여 최종 교정 단어열을 도출할 수 있다. 단계 S609에서 문장 교정 장치는 최종 교정 단어열에 기초하여 어절 범위 정보에 포함된 적어도 하나의 단 어를 교정할 수 있다. 상술한 설명에서, 단계 S601 내지 S609는 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적 은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본 발명의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의 의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이 터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다."}
{"patent_id": "10-2021-0150785", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2021-0150785", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 내지 1c는 본 발명에 이용되는 복수의 언어 모델을 설명하기 위한 도면이다. 도 2는 본 발명의 일 실시예에 따른, 문장 교정 장치의 블록도이다. 도 3은 본 발명의 일 실시예에 따른, 문장을 교정 방법을 설명하기 위한 도면이다. 도 4은 본 발명의 일 실시예에 따른, 치환 교정, 삭제 교정 및 신규 단어 추가 교정하는 방법을 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른, 교정 후보 네트워크를 이용하여 문장을 교정하는 방법을 설명하기 위한 도 면이다. 도 6은 본 발명의 일 실시예에 따른, 문장 교정 방법을 나타낸 흐름도이다."}
