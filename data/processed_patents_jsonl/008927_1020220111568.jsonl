{"patent_id": "10-2022-0111568", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0032507", "출원번호": "10-2022-0111568", "발명의 명칭": "지상전투 보조를 위한 엣지 AI를 사용하는 모바일 전투 유닛", "출원인": "국방과학연구소", "발명자": "박병훈"}}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 동작 방법으로서,제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보, 및 제2전투 유닛에 포함된 카메라를 통해 획득된제2이미지 정보를 획득하는 단계;상기 제1이미지 정보 및 상기 제2이미지 정보를 통합하여 통합 이미지 정보를 생성하는 단계;상기 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성하는 단계;상기 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는 단계; 및상기 전술에 관한 정보를 제공하는 단계를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,제3전투 유닛에 포함된 센서로부터 측정된 생체 신호를 획득하는 단계; 및상기 생체 신호를 기초로 상기 제3전투 유닛을 장착한 병사의 생체 정보를 확인하는 단계를 더 포함하고,상기 확인하는 단계는,상기 전장 맵 및 상기 생체 정보를 상기 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는 단계를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,제4전투 유닛에 포함된 gps 센서로부터 측정된 전장의 위치에 관한 정보를 획득하는 단계; 및상기 위치에 관한 정보를 기초로 상기 전장의 지형도를 확인하는 단계를 더 포함하고,상기 전장 맵을 생성하는 단계는,상기 통합 이미지 내의 객체의 배치에 관한 정보를 확인하는 단계; 및상기 객체의 배치에 관한 정보를 기초로 상기 지형도에 상기 객체를 배치하여 상기 전장 맵을 생성하는 단계를포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 전술에 관한 정보는,전투 유닛을 장착한 적어도 하나의 병사의 이동 경로에 관한 정보, 및 상기 병사의 전술 행동을 지시하는 정보를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 전자 장치는 중앙 시스템에 포함되고,상기 제공하는 단계는,공개특허 10-2024-0032507-3-상기 전술에 관한 정보를 적어도 하나의 전투 유닛에게 제공하는 단계를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 전자 장치는 중앙 시스템에 포함되고,상기 인공지능 모델에 관한 정보를 적어도 하나의 전투 유닛에게 제공하는 단계를 더 포함하고,상기 적어도 하나의 전투 유닛은,상기 인공지능 모델에 관한 정보를 이용하여 전장 맵에 대응되는 전술에 관한 정보를 확인하고, 상기 전술에 관한 정보를 다른 적어도 하나의 전투 유닛에게 제공하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 전자 장치가 적어도 하나의 전투 유닛에 포함되고,중앙 시스템으로부터 상기 인공지능 모델에 관한 정보를 전송받는 단계;상기 인공지능 모델에 관한 정보를 이용하여 상기 인공지능 모델의 버전 정보를 확인하는 단계; 및상기 인공지능 모델의 버전 정보를 기초로 상기 중앙 시스템에게 상기 인공지능 모델의 업데이트에 관한 요청정보를 전송하는 단계를 더 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서,상기 센서는,뇌파 측정 센서, CCD(Charge-Coupled Device) 센서, 펄스 센서, 호흡 측정 센서, 및 온도 센서 중 적어도 하나를 포함하고,상기 생체 신호는,뇌파에 관한 신호, 응시 패턴에 관한 신호, 심박수에 관한 신호, 호흡에 관한 신호, 및 체온에 관한 신호 중 적어도 하나를 포함하고,상기 생체 정보는,상기 병사의 육체적 상태에 관한 정보 및 상기 병사의 정신적 상태에 관한 정보를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 적어도 하나의 전투 유닛은,다른 적어도 하나의 전투 유닛과의 거리에 관한 정보를 확인하고, 상기 거리에 관한 정보를 기초로 상기 다른적어도 하나의 전투 유닛 중 최인접 전투 유닛에게 상기 전술에 관한 정보를 제공하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 전자 장치가 특정 전투 유닛에 포함되고,상기 전자 장치와 통신이 가능한 적어도 하나의 전투 유닛을 확인하는 단계; 및상기 적어도 하나의 전투 유닛 각각의 리소스 정보를 획득하는 단계를 더 포함하고,상기 전장 맵을 생성하는 단계는,공개특허 10-2024-0032507-4-상기 특정 전투 유닛의 리소스 및 상기 적어도 하나의 전투 유닛 각각의 리소스 중 적어도 일부를 기초로, 전장맵을 생성하는 단계를 포함하고,상기 전술에 관한 정보를 확인하는 단계는,상기 특정 전투 유닛의 리소스 및 상기 적어도 하나의 전투 유닛 각각의 리소스 중 적어도 일부를 기초로, 상기전장 맵을 상기 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는 단계를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 특정 전투 유닛의 리소스 정보 및 상기 적어도 하나의 전투 유닛 각각의 리소스 정보를 기초로, 상기 특정전투 유닛과 상기 적어도 하나의 전투 유닛을 제1그룹 및 제2그룹으로 분류하는 단계를 더 포함하고,상기 전장 맵을 생성하는 단계는,상기 제1그룹의 리소스를 기초로, 전장 맵을 생성하는 단계를 포함하고,상기 전술에 관한 정보를 확인하는 단계는,상기 제2그룹의 리소스를 기초로, 상기 전장 맵을 상기 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는단계를 포함하는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 특정 전투 유닛은,상기 전자 장치와 통신이 가능한 적어도 하나의 전투 유닛의 순위에 관한 정보에 기초하여 결정되고,상기 순위에 관한 정보는,상기 적어도 하나의 전투 유닛을 장착한 각각의 병사의 계급에 따라 결정되는, 동작 방법."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써, 제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보,및 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보를 획득하고,상기 제1이미지 정보 및 상기 제2이미지 정보를 통합하여 통합 이미지 정보를 생성하고,상기 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성하고,상기 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인하고, 및상기 전술에 관한 정보를 제공하는 프로세서를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0111568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "전자 장치의 동작 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 비일시적 기록매체로서,상기 동작 방법은,제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보, 및 제2전투 유닛에 포함된 카메라를 통해 획득된제2이미지 정보를 획득하는 단계;상기 제1이미지 정보 및 상기 제2이미지 정보를 통합하여 통합 이미지 정보를 생성하는 단계;상기 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성하는 단계;상기 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는 단계; 및공개특허 10-2024-0032507-5-상기 전술에 관한 정보를 제공하는 단계를 포함하는, 비일시적 기록매체."}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1전투 유닛에 포함된 카메라르 통해 획득된 제1이미지 정보, 및 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보를 획득하는 단계; 제1이미지 정보 및 제2이미지 정보를 통합하여 통합 이미지 정보를 생성하는 단계; 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성하는 단계; 전장 맵을 인공지능 모델에 입 력하여 전술에 관한 정보를 확인하는 단계; 및 전술에 관한 정보를 제공하는 단계를 포함하는 전술을 제공하기 위한 전자 장치의 동작 방법을 제공한다."}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 지상전투 보조를 위한 엣지 AI를 사용하는 모바일 전투 유닛, 및 중앙 시스템에 관한 것이다. 또한, 본 개시는 전술을 제공하기 위한 전자 장치 및 그의 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대의 전쟁은 IT 기술의 비약적인 발전으로 인해 전장의 다양한 데이터를 수집하고 이를 근거로 보다 정확하고 효율적인 공격이나 방어 수단을 수립하는 전자전(電子戰)의 양상을 보이고 있다. 전자전에서 빠르고 정확한 대 응을 하기 위해서는 인공지능이 필수적으로 요구될 수 있다. 인공지능은 사전에 학습된 모델을 이용하여 새로운 데이터들이 입력되면 데이터 분석을 통해 모델에 설정된 기능에 따라 특정 결과를 도출하는 방식으로 작동하게 된다. 이러한 방식은 사람이 어떠한 정보(즉, 데이터)를 접하고 판단하여 특정 행위를 하는 과정과 유사하므로 인공지능이라고 지칭된다. 인공지능을 이용하면 주변 환경의 정보들을 분석하여 해당 환경에 적합한 행동을 추 천할 수 있는 결심 지원 시스템을 구현할 수 있다."}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은 지상전투 보조를 위한 엣지 AI를 사용하는 모바일 전투 유닛, 및 중앙 시스템을 개시하고자 한다. 또한, 개시된 실시예들은 전술을 제공하기 위한 전자 장치 및 그의 동작 방법을 개시하고자 한다. 본 실 시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 이하의 실시예들로부 터 또 다른 기술적 과제들이 유추될 수 있다."}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 전자 장치의 동작 방법으로서, 제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보, 및 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보를 획득하는 단계; 제1이미지 정보 및 제2이미 지 정보를 통합하여 통합 이미지 정보를 생성하는 단계; 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성하는 단계; 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는 단계; 및 전술에 관한 정보를 제공하는 단계를 포함하는 동작 방법이 제공될 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 제3전투 유닛에 포함된 센서로부터 측정된 생체 신호를 획득하 는 단계; 및 생체 신호를 기초로 제3전투 유닛을 장착한 병사의 생체 정보를 확인하는 단계를 더 포함하고, 확 인하는 단계는, 전장 맵 및 생체 정보를 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는 단계를 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 제4전투 유닛에 포함된 gps 센서로부터 측정된 전장의 위치에 관한 정보를 획득하는 단계; 및 위치에 관한 정보를 기초로 전장의 지형도를 확인하는 단계를 더 포함하고, 전 장 맵을 생성하는 단계는, 통합 이미지 내의 객체의 배치에 관한 정보를 확인하는 단계; 및 객체의 배치에 관한 정보를 기초로 지형도에 객체를 배치하여 전장 맵을 생성하는 단계를 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 전술에 관한 정보는, 전투 유닛을 장착한 적어도 하나의 병사 의 이동 경로에 관한 정보, 및 병사의 전술 행동을 지시하는 정보를 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 전자 장치는 중앙 시스템에 포함되고, 제공하는 단계는, 전술 에 관한 정보를 적어도 하나의 전투 유닛에게 제공하는 단계를 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 전자 장치는 중앙 시스템에 포함되고, 인공지능 모델에 관한 정보를 적어도 하나의 전투 유닛에게 제공하는 단계를 더 포함하고, 적어도 하나의 전투 유닛은, 인공지능 모델 에 관한 정보를 이용하여 전장 맵에 대응되는 전술에 관한 정보를 확인하고, 전술에 관한 정보를 다른 적어도 하나의 전투 유닛에게 제공할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 전자 장치가 적어도 하나의 전투 유닛에 포함되고, 중앙 시스 템으로부터 인공지능 모델에 관한 정보를 전송받는 단계; 인공지능 모델에 관한 정보를 이용하여 인공지능 모델 의 버전 정보를 확인하는 단계; 및 인공지능 모델의 버전 정보를 기초로 중앙 시스템에게 인공지능 모델의 업데 이트에 관한 요청 정보를 전송하는 단계를 더 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 센서는, 뇌파 측정 센서, CCD(Charge-Coupled Device) 센서, 펄스 센서, 호흡 측정 센서, 및 온도 센서 중 적어도 하나를 포함하고, 생체 신호는, 뇌파에 관한 신호, 응시 패턴에 관한 신호, 심박수에 관한 신호, 호흡에 관한 신호, 및 체온에 관한 신호 중 적어도 하나를 포함하고, 생체 정보는, 병사의 육체적 상태에 관한 정보 및 병사의 정신적 상태에 관한 정보를 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 적어도 하나의 전투 유닛은, 다른 적어도 하나의 전투 유닛과 의 거리에 관한 정보를 확인하고, 거리에 관한 정보를 기초로 다른 적어도 하나의 전투 유닛 중 최인접 전투 유 닛에게 전술에 관한 정보를 제공할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 전자 장치가 특정 전투 유닛에 포함되고, 전자 장치와 통신이 가능한 적어도 하나의 전투 유닛을 확인하는 단계; 및 적어도 하나의 전투 유닛 각각의 리소스 정보를 획득하는 단계를 더 포함하고, 전장 맵을 생성하는 단계는, 특정 전투 유닛의 리소스 및 적어도 하나의 전투 유닛 각각의 리소스 중 적어도 일부를 기초로, 전장 맵을 생성하는 단계를 포함하고, 전술에 관한 정보를 확인하는 단계는, 특정 전투 유닛의 리소스 및 적어도 하나의 전투 유닛 각각의 리소스 중 적어도 일부를 기초로, 전장 맵을 인공 지능 모델에 입력하여 전술에 관한 정보를 확인는 단계를 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 특정 전투 유닛의 리소스 정보 및 적어도 하나의 전투 유닛 각 각의 리소스 정보를 기초로, 특정 전투 유닛과 적어도 하나의 전투 유닛을 제1그룹 및 제2그룹으로 분류하는 단 계를 더 포함하고, 전장 맵을 생성하는 단계는, 제1그룹의 리소스를 기초로, 전장 맵을 생성하는 단계를 포함하 고, 전술에 관한 정보를 확인하는 단계는, 제2그룹의 리소스를 기초로, 전장 맵을 인공지능 모델에 입력하여 전 술에 관한 정보를 확인하는 단계를 포함할 수 있다. 일 실시예에 따른 전자 장치의 동작 방법으로서, 특정 전투 유닛은, 전자 장치와 통신이 가능한 적어도 하나의 전투 유닛의 순위에 관한 정보에 기초하여 결정되고, 순위에 관한 정보는, 적어도 하나의 전투 유닛을 장착한 각각의 병사의 계급에 따라 결정될 수 있다. 일 실시예에 따른 전자 장치로서, 적어도 하나의 프로그램이 저장된 메모리; 및 적어도 하나의 프로그램을 실행 함으로써, 제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보, 및 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보를 획득하고, 제1이미지 정보 및 제2이미지 정보를 통합하여 통합 이미지 정보를 생 성하고, 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성하고, 전장 맵을 인공지능 모델에 입력 하여 전술에 관한 정보를 확인하고, 및 전술에 관한 정보를 제공하는 프로세서를 포함하는 전자 장치가 제공될 수 있다. 일 실시예에 따른 전자 장치의 동작 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 비일시적 기록매체로서, 동작 방법은, 제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보, 및 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보를 획득하는 단계; 제1이미지 정보 및 제2이미지 정보를 통합하여 통합 이미지 정보를 생성하는 단계; 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성하는 단계; 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인하는 단계; 및 전술에 관한 정보 를 제공하는 단계를 포함하는 비일시적 기록매체가 제공될 수 있다."}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 전자 장치는 전투 유닛에 포함된 카메라를 통해 획득된 이미지 정보를 기초로 전장 맵을 생 성하고, 생성된 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인하고 제공할 수 있다. 전자 장치 는 전장 주변의 환경을 파악할 수 있고, 전장 주변 환경에 관한 정보를 인공지능을 이용하여 분석하고 시뮬레이 션을 통해 해당 전장에서 최선의 전술에 관한 정보를 제공할 수 있다. 전자 장치는 자체적인 데이터 수집과 분 석 기능을 갖추고 있어 중앙 시스템과 통신이 두절되는 경우에도 독자적으로 인공지능 기능을 수행할 수 있다. 전자 장치는 전장의 주변 환경뿐만 아니라 전술을 수행할 병사의 생체 정보(병사의 신체적, 정신적 상태)를 고 려하므로, 주변 환경만 고려하는 경우보다 해당 전장 상황에 보다 적합한 전술을 제공할 수 있다."}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\" 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"..부\", \"..모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서 기재된 \"a, b, 및 c 중 적어도 하나\"의 표현은, 'a 단독', 'b 단독', 'c 단독', 'a 및 b', 'a 및 c', 'b 및 c', 또는 'a,b,c 모두'를 포괄할 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 본 개시는 전장(battlefield)에서 발생하는 각종 정보를 바탕으로 작전을 수행하는 초지능전 상황에서, 병사들 이 휴대하거나 장착한 모바일 전투 유닛을 이용하여 전장 환경에서 생성되는 다양한 데이터를 수집하고 분석하 여 전투를 보조하기 위한 인공지능 시스템 및 방법에 관한 것이다. 본 개시는 지휘관(현장 지휘관 또는 후방의 지휘관)이 전장의 상황을 파악할 수 있도록 현장의 정보를 제공하여 전장 상황을 인식할 수 있도록 하고, 인공 지능 분석을 통해 가장 효과적인 전술을 추천받아 지휘관의 의사결정을 도와주는 지휘결심체계를 구현할 수 있 다. 또한, 본 개시는 전투 현장의 불가항력적인 상황(예를 들어, 통신망이 단절되거나 시스템에 장애가 발생한 경우)에도 대응할 수 있도록, 자체 인공지능을 탑재한 전투 유닛이 독자적으로 또는 인접 전투 유닛과의 피어 투 피어(peer-to-peer) 통신을 통해 현장의 지휘관에게 최선의 전술을 제공해주는 인공지능 기반 전투운용시스 템을 구현할 수 있다. 도 1은 본 개시에 따른 전자 장치를 나타낸다. 전자 장치는 프로세서 및 메모리를 포함한다. 도 1에 도시된 전자 장치에는 본 실시예들과 관련된 구성요소들 만이 도시되어 있다. 따라서, 전자 장치에는 도 1에 도시된 구성요소들 외에 다른 범용"}
{"patent_id": "10-2022-0111568", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "적인 구성요소들이 더 포함될 수 있음은 당해 기술분야의 통상의 기술자에게 자명하다. 전자 장치는 병사가 수행해야 하는 전술에 관한 정보를 제공할 수 있다. 구체적으로, 전자 장치는 각 각의 전투 유닛을 장착한 병사의 이동 경로에 관한 정보를 제공할 수 있고, 병사의 전술 행동을 지시하는 정보 를 제공할 수 있다. 예를 들어, 전자 장치는 제1전투 유닛을 장착한 병사의 이동 경로에 관한 정보를 제공 할 수 있고, 제1전투 유닛을 장착한 병사가 '교전'을 수행하도록 지시하는 정보를 제공할 수 있다. 다른 예시로 서, 전자 장치는 제2전투 유닛을 장착한 병사의 이동 경로에 관한 정보를 제공할 수 있고, 제2전투 유닛을 장착한 병사가'회피'를 수행하도록 지시하는 정보를 제공할 수 있다. 병사의 전술 행동은 예를 들어, '교전', '회피', '정찰', '지원', '무시' 등을 포함할 수 있으나 이에 제한되지 않는다. 전자 장치는 중앙 시스템, 및 적어도 하나의 전투 유닛 중 적어도 하나에 포함될 수 있다. 일 실시예에 따라 전자 장치가 중 앙 시스템에 포함된 경우, 전자 장치는 중앙 시스템의 동작을 제어할 수 있다. 예를 들어, 전자 장치(10 0)는 전술에 관한 정보를 적어도 하나의 전투 유닛에게 제공할 수 있다. 다른 실시예에 따라 전자 장치가 전투 유닛에 포함된 경우, 전자 장치는 전투 유닛의 동작을 제어할 수 있다. 예를 들어, 전자 장치가 제1 전투 유닛에 포함된 경우, 전자 장치는 제2전투 유닛에게 전술에 관한 정보를 제공할 수 있다. 프로세서는 전자 장치의 전반적인 기능들을 제어하는 역할을 한다. 예를 들어, 프로세서는 전자 장치 내의 메모리에 저장된 프로그램들을 실행함으로써, 전자 장치를 전반적으로 제어한다. 프 로세서는 전자 장치 내에 구비된 CPU(central processing unit), GPU(graphics processing unit), AP(application processor) 등으로 구현될 수 있으나, 이에 제한되지 않는다. 메모리는 전자 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 메모리는 전자 장치에서 처리된 데이터들 및 처리될 데이터들을 저장할 수 있다. 또한, 메모리는 전자 장치에 의해 구동될 애플리케이션들, 드라이버들 등을 저장할 수 있다. 메모리는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스 토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플래시 메모리를 포함할 수 있다. 프로세서는 전투 유닛에 포함된 카메라를 통해 주변 환경에 관한 이미지 정보를 획득할 수 있다. 구체적으 로 프로세서는 제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보를 획득할 수 있고, 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보를 획득할 수 있다. 일 실시예에 따라, 전투 유닛은 마이크 를 포함할 수 있다. 프로세서는 전투 유닛에 포함된 마이크를 통해 획득된 음향 정보를 시각화하여 이미지 정보를 획득할 수 있다. 예를 들어, 프로세서는 제1전투 유닛에 포함된 마이크를 통해 획득한 음향 정보를 시각화하여 주변 환경에 관한 제1이미지 정보를 획득할 수 있고, 제2전투 유닛에 포함된 마이크를 통해 획득한 음향 정보를 시각화하여 주변 환경에 관한 제2이미지 정보를 획득할 수 있다. 전투 유닛에는 카메라와 마이크뿐 만 아니라 각종 센서가 포함될 수 있고, 프로세서는 센서를 통해 획득된 전장의 주변 환경에 관한 센싱 정 보를 획득할 수 있다. 일 실시예에 따라, 프로세서는 통합 이미지 정보를 생성할 수 있다. 구체적으로, 프로세서는 제1이미 지 정보와 제2이미지 정보를 통합하여 통합 이미지 정보를 생성할 수 있다. 다른 예시로서, 프로세서는 제 1이미지 정보, 제2이미지 정보, 및 제3이미지 정보를 통합하여 통합 이미지 정보를 생성할 수 있다. 일 실시예 에 따라, 프로세서는 통합 이미지 정보를 기초로 전장 맵을 생성할 수 있다. 구체적으로, 프로세서는 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성할 수 있다. 통합 이미지 정보를 생성하는 과정 과 전장 맵을 생성하는 과정은 이하 도 2에서 상세히 설명될 것이다. 일 실시예에 따라, 프로세서는 전술에 관한 정보를 확인할 수 있다. 일 실시예에 따라, 프로세서는 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인할 수 있다. 다시 말해, 프로세서는 전장 맵 을 인공지능 모델에 입력하여 출력된 정보를 전술에 관한 정보로서 확인할 수 있다. 다른 실시예에 따라, 프로 세서는 병사의 생체 정보 및 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인할 수 있다. 전 술에 관한 정보를 확인하는 과정은 이하 도 3 및 도 4에서 상세히 설명될 것이다. 일 실시예에 따라, 인공지능 모델은 특정 전장에 관한 전장 맵에 기초하여 특정 전장에서 병사들이 수행해야 하 는 전술에 관한 정보를 출력하도록 훈련된 인공지능 모델일 수 있다. 인공지능 모델은 ANN(Artificial Neural Network), DNN(Deep Neural Network), CNN(Convolution Neural Network) 등 다양한 구조의 신경망을 포함할 수 있다. 다른 실시예에 따라, 인공지능 모델은 특정 전장에 관한 전장 맵과 특정 전장의 병사의 생체 정보에 기초 하여 특정 전장에서 병사들이 수행해야 하는 전술에 관한 정보를 출력하도록 훈련된 인공지능 모델일 수 있다. 일 실시예에 따라, 프로세서는 인공지능 모델을 훈련시킬 수 있다. 구체적으로 프로세서는 복수의 전 장 각각에 관한 전장 맵을 인공지능 모델의 입력 정보로써 획득하고, 복수의 전장 각각에서 병사가 수행해야 하 는 전술에 관한 정보를 입력 정보에 대한 타겟 정보로써 획득하고, 입력 정보와 타겟 정보를 기초로 인공지능 모델을 훈련시킬 수 있다. 다른 실시예에 따라, 프로세서는 복수의 전장 각각에 관한 전장 맵과 복수의 전 장 각각의 병사의 생체 정보를 인공지능 모델의 입력 정보로써 획득하고, 복수의 전장 각각에서 병사가 수행해 야 하는 전술에 관한 정보를 입력 정보에 대한 타겟 정보로써 획득하고, 입력 정보와 타겟 정보를 기초로 인공 지능 모델을 훈련시킬 수 있다. 일 실시예에 따라, 프로세서는 인공지능 모델을 재학습시킬 수 있다. 프로세서는, 전투 유닛에 포함된 카메라가 기 설정된 시간 경과 후 획득한 이미지 정보를 획득하여 이미지 정 보를 기초로 전장 맵을 생성하고, 입력 정보인 전장 맵과 입력 정보에 대응되는 타겟 정보인 지휘관이 결정한 전술에 관한 정보를 기초로 인공지능 모델을 재학습시킬 수 있다. 일 실시예에 따라, 프로세서는 통신부를 이용하여 전술에 관한 정보를 제공할 수 있다. 다른 실시예에 따 라, 프로세서는 통신부를 이용하여 인공지능 모델에 관한 정보를 제공할 수 있다. 전자 장치가 중앙 시스템에 포함되고, 프로세서는 통신부를 통해 전술에 관한 정보와 인공지능 모델에 관한 정보를 적어도 하나의 전투 유닛에게 제공할 수 있다. 전자 장치가 적어도 하나의 전투 유닛에 포함되고, 프로세서 는 통신부를 이용하여 다른 전투 유닛에게 전술에 관한 정보를 제공할 수 있다. 도 2는 프로세서가 전장 맵을 생성하는 일 실시예를 나타낸다. 프로세서는 전장에 투입된 병사들이 장착한 모바일 전투 유닛(이하 '전투 유닛')을 통해 전송받은 정보들을 취합하여 전장 맵을 생성할 수 있다. 프로세서 는 전장의 주변 환경에 관한 다양한 정보를 분석하여 전장 맵을 생성할 수 있으나 이하에서는 이미지 정보 를 이용하는 실시예에 관해 설명한다. 일 실시예에 따라, 프로세서는 전투 유닛에 포함된 카메라를 통해 획득된 이미지 정보를 획득할 수 있다. 도 2를 참조하면, 프로세서는 제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보, 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보, 및 제3전투 유닛에 포함된 카메라를 통해 획득된 제 3이미지 정보를 획득할 수 있다. 일 실시예에 따라, 프로세서는 제1이미지 정보, 제2이미지 정보, 및 제3이미지 정보를 통 합하여 통합 이미지 정보를 생성할 수 있다. 구체적으로, 프로세서는 제1전투 유닛, 제2전투 유닛, 및 제3전투 유닛의 위치 정보를 확인하고, 각각의 전투 유닛의 위치 정보를 기초로 제1이미지 정보, 제2이 미지 정보, 및 제3이미지 정보를 통합하여 통합 이미지 정보를 생성할 수 있다. 예를 들어, 도 2를 참조하면 제1전투 유닛의 위치는 왼쪽이고, 제2전투 유닛의 위치는 중앙이고, 제3전투 유닛의 위치는 오른 쪽이므로, 제1이미지 정보를 왼쪽에 배치하고, 제2이미지 정보를 중앙에 배치하고, 제3이미지 정보를 오른쪽에 배치하여 보정 전 통합 이미지 정보를 생성할 수 있다. 프로세서는 보정 전 통합 이미지 정보에 서 제1이미지 정보, 제2이미지 정보, 및 제3이미지 정보 간의 중복되는 영역을 보정(또는, 삭제)하여 통합 이미 지 정보를 생성할 수 있다. 도 2에서는 3개의 이미지 정보를 이용하여 통합 이미지 정보를 생성하는 것으로 도시되었지만, 이미지 정보의 개수는 이에 제한되지 않는다. 도 2를 참조하면, 프로세서는 전장 맵을 생성할 수 있다. 구체적으로 프로세서는 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성할 수 있다. 프로세서는 객체 인식 기능을 이 용하여 통합 이미지 정보 내의 객체를 분석할 수 있다. 예를 들어, 프로세서는 적군의 인적 자원(예 를 들어, 병사 등) 및 물적 자원(예를 들어, 탱크 등), 아군의 인적 자원 및 물적 자원, 나무, 시설물 등의 객 체를 분석할 수 있다. 프로세서는 객체를 분석하여 통합 이미지 정보 내의 객체의 배치에 관한 정보 를 확인할 수 있다. 구체적으로 프로세서는 이미지 내 객체의 원근에 따른 거리 산정 기술을 이용하여 객 체의 배치에 관한 정보를 확인할 수 있다. 일 실시예에 따라, 프로세서는 전장의 위치에 관한 정보를 획득 할 수 있다. 구체적으로, 프로세서는 전투 유닛에 포함된 gps 센서로부터 측정된 전장의 위치에 관한 정보 를 획득할 수 있다. 프로세서는 전장의 위치에 관한 정보를 기초로 전장의 지형도를 확인할 수 있다. 예를 들어, 프로세서는 메모리에 저장된 지형도들 중에서 gps 센서를 통해 측정된 전장의 위치와 일치하는 지역의 지형도를 전장의 지형도로서 확인할 수 있다. 일 실시예에 따라, 프로세서는 객체의 배치에 관한 정보를 기초로 지형도에 객체를 배치하여 전장 맵을 생성할 수 있다. 프로세서는 전장 현장의 지형도 에 파악된 아군과 적군의 무기, 병력 등을 배치하여 전장 맵을 생성할 수 있다. 도 2를 참조하면, 프로세서 는 전장의 지형도에 통합 이미지 내의 객체(병사, 탱크, 및 나무)를 배치하여 전장 맵을 생성할 수 있다. 전장 맵은 전장의 지형, 적군의 병력과 무기체계의 배치, 아군의 병력과 무기체계의 배치를 나타내는 작 전도이므로, 프로세서는 전술에 관한 정보를 도출하기 위한 기본 자료로서 전장 맵을 이용할 수 있다. 도 3은 프로세서가 주변 환경에 관한 센싱 정보 및 생체 신호를 획득하는 일 실시예를 나타낸다. 프로세서(11 0)는 전투 유닛을 제어할 수 있고, 모바일 전투 유닛 내부 혹은 외부에 연결된 각종 센서들을 이용할 수 있다. 일 실시예에 따라, 프로세서는 전투 유닛에 포함된 카메라를 통해 획득된 이미지 정보를 획득할 수 있다.도 3을 참조하면, 프로세서는 주변 환경에 관한 센싱 정보를 획득할 수 있다. 구체적으로, 프로세서 는 전장 주변 환경에 관한 이미지 정보, 음향 정보, 위치 정보, 및 기온 정보를 획득할 수 있다. 예를 들어, 프 로세서는 전투 유닛에 포함된 카메라를 통해 획득된 이미지 정보를 획득할 수 있다. 다른 예시로서, 프로 세서는 전투 유닛에 포함된 마이크를 통해 획득된 음향 정보를 획득할 수 있다. 예를 들어, 프로세서(11 0)는 물적 자원에 관한 음향 정보(예를 들어, 탱크의 운전 소리에 관한 정보, 드론 운행 소리에 관한 정보, 또 는 대포 소리에 관한 정보)를 획득할 수 있다. 일 실시예에 따라, 프로세서는 음향 정보를 기초로 적의 물 적 자원의 종류에 관한 정보, 피아식별을 위한 정보, 및 음원의 위치에 관한 정보를 획득할 수 있다. 예를 들어, 프로세서는 음향 정보를 통해 분석한 물적 자원이 드론이 아닌 탱크라고 판단할 수 있고, 음향 정보 를 통해 파악된 탱크가 적군의 탱크라고 판단할 수 있고, 적군 탱크의 위치를 확인할 수 있다. 일 실시예에 따 라, 프로세서는 음향 정보를 기반으로 전장 맵을 생성할 수 있다. 예를 들어, 프로세서는 지형도에 물적 자원(예를 들어, 탱크)을 배치하여 전장 맵을 생성할 수 있고, 전장 맵에 배치된 물적 자원의 종류와 피아 를 별도로 표시할 수 있다. 예를 들어, 프로세서는 물적 자원이 탱크에 해당하는 경우 정사각형으로 표시 할 수 있고, 드론에 해당하는 경우 원형으로 표시할 수 있고, 적군의 물적 자원인 경우 붉은색으로 표시할 수 있고 아군의 물적 자원인 경우 푸른색으로 표시할 수 있다. 물적 자원의 종류와 피아의 표시는 전술한 예시에 제한되지 않고 기타 다양한 방법으로 표시될 수 있다. 일 실시예에 따라, 프로세서는 위치 정보와 기온 정 보를 기초로 전장의 위치와 기온이 표시된 이미지 정보를 획득할 수 있다. 프로세서는 이미지 정보, 음향 정보, 위치 정보, 및 기온 정보 등을 분석하여 전장의 전반적인 상황을 인식할 수 있다. 일 실시예에 따라, 프로세서는 병사의 생체 신호를 획득할 수 있다. 구체적으로, 프로세서는 전투 유 닛에 포함된 센서로부터 측정된 해당 전투 유닛을 장착한 병사의 생체 신호를 획득할 수 있다. 도 3을 참조하면, 프로세서는 뇌파 센서로부터 측정된 병사의 뇌파에 관한 신호를 획득할 수 있고, CCD(Charge- Coupled Device) 센서로부터 측정된 병사의 응시 패턴에 관한 신호를 획득할 수 있고, 펄스 센서로부터 측정된 병사의 심박수에 관한 신호를 획득할 수 있다. 프로세서는 호흡 측정 센서로부터 병사의 호흡에 관한 신호 를 획득할 수 있고, 온도 센서로부터 측정된 병사의 체온에 관한 신호를 획득할 수 있고, 자이로 센서로부터 측 정된 병사의 자세에 관한 신호를 획득할 수 있고, 가속도 센서로부터 측정된 병사의 움직임에 관한 신호를 획득 할 수 있다. 각종 센서들로부터 수집된 정보들은 병사의 신체 상태, 활력 징후, 및 부상 여부와 같은 육체적 상 태에 관한 정보는 물론 공황이나 스트레스 등과 같은 정신적 상태에 관한 정보를 확인하는데 사용될 수 있다. 일 실시예에 따라, 프로세서는 병사의 생체 신호를 기초로 전투 유닛을 장착한 병사의 생체 정보를 확인할 수 있다. 병사의 생체 정보는 해당 병사의 육체적 상태에 관한 정보 및 해당 병사의 정신적 상태에 관한 정보 중 적어도 하나를 포함할 수 있다. 예를 들어, 프로세서는 전투 유닛을 장착한 병사의 부상 정도(예를 들 어, 정상, 경미상, 경상, 중상, 사망 등)를 확인할 수 있다. 다른 예시로서, 프로세서는 전투 유닛을 장착 한 병사의 정신 이상 정도(예를 들어, 정상, 스트레스, 공황, 발작 등)를 확인할 수 있다. 일 실시예에 따라, 프로세서는 기 설정된 기준에 따라 병사의 육체적 상태 및 정신적 상태를 확인할 수 있다. 예를 들어, 프 로세서는 병사의 심박수가 60~100인 경우 정신적 상태가 '정상'이라고 판단할 수 있고, 심박수가 100~120 인 경우 병사의 정신적 상태가 '스트레스'라고 판단할 수 있고, 심박수가 120~140인 경우 병사의 정신적 상태가 '공황'이라고 판단할 수 있다. 다른 예시로서, 프로세서는 병사의 체온이 36도~37도인 경우 육체적 상태가 '정상'이라고 판단할 수 있고, 병사의 체온이 37도~38도인 경우 육체적 상태가 '경미상'이라고 판단할 수 있고, 병사의 체온이 38도~39도인 경우 육체적 상태가 '중상'이라고 판단할 수 있다. 기 설정된 기준은 전술한 기준에 제한되지 않고 전장 상황에 따라 다양하게 설정될 수 있다. 프로세서는 생체 정보(병사의 육체적 상태에 관한 정보, 및 병사의 정신적 상태에 관한 정보)를 인공지능 모델에 입력하여 병사가 수행해야 하는 전술에 관 한 정보를 확인할 수 있다. 예를 들어, 프로세서가 인공지능 모델에 병사의 육체적 상태를'중상'이라고 입 력하고 병사의 정신적 상태를 '공황'이라고 입력하는 경우, 인공지능 모델은'회피'를 수행하도록 지시하는 정보 를 출력하고, 프로세서는 '회피'를 수행하도록 지시하는 정보를 전술에 관한 정보로서 확인할 수 있다. 다 른 예시로서, 프로세서가 인공지능 모델에 병사의 육체적 상태를 '경미상'이라고 입력하고 병사의 정신적 상태를 '정상'이라고 입력하는 경우, 인공지능 모델은 '교전'을 수행하도록 지시하는 정보를 출력하고, 프로세 서는 '교전'을 수행하도록 지시하는 정보를 전술에 관한 정보로서 확인할 수 있다. 이처럼 병사의 육체적 상태에 관한 정보와 정신적 상태에 관한 정보는 병사가 수행할 전술을 결정할 때 중요한 데이터로서 고려될 수 있다. 전투 유닛 내부 혹은 외부에 연결된 센서들은 도 3에서 전술한 센서들로 제한되지 않고, 병사의 생체 신 호를 측정하기 위한 기타 센서, 및 전장 주변 환경을 센싱하기 위한 기타 센서를 포함할 수 있다.도 4는 일 실시예에 따른 전투 유닛들과 중앙 시스템의 개략도를 나타낸다. 도 4를 참조하면, 410은 적어도 하 나의 전투 유닛을 나타내고, 420은 중앙 시스템의 서비스 어플리케이션을 나타내고, 430은 중앙 시스템을 나타 낸다. 전투 유닛은 각각의 병사가 장착하고 있는 기기를 의미할 수 있다. 전투 유닛은 비디오, 오디 오, 위치, 온도 등의 IoT 센서를 자체적으로 탑재하거나, 외부에 독립적으로 존재하는 각각의 센서와 유/무선 방식으로 연결될 수 있다. 다만, 센서들의 위치는 병사의 신체 범위 밖을 벗어나지 않을 수 있다. 일 실시예에 따라, 전투 유닛은 각종 센서를 통해 데이터를 직접 획득하여 중앙 시스템으로 전송할 수 있다. 다른 실시예에 따라, 전투 유닛은 각종 센서를 통해 획득한 데이터를 자체적으로 탑재한 인공지능 모델에 입력 하여 전투 유닛을 장착한 병사가 수행해야 하는 전술에 관한 정보를 추론할 수 있다. 긴박한 전시 상황에서 네 트워크 부하를 감소시키고 프로세스 과정을 빠르게 처리하기 위해, 전투 유닛은 별도로 추론 기능을 수행 하지 않고 전투 유닛이 획득한 데이터만을 중앙 시스템에게 전송하는 것으로 기능을 한정할 수 있다. 이 경우, 전투 유닛은 수집되는 이미지 정보, 음향 정보, 및 위치 정보 등의 다양한 데이터를 전처리한 결 과만을 중앙 시스템으로 전송할 수 있다. 중앙 시스템은 전투 유닛이 전송하는 데이터를 획득하여 DB(데이터베이스)에 저장하고, 저장된 데이터를 이용하여 인공지능 모델을 학습시키거나 추론을 수행할 수 있다. 일 실시예에 따라, 중앙 시스템 내 서비스 어플리케이션에서는 DB에 저장된 데이터를 이용하여 전장 맵(Map)을 생성할 수 있다. 구체적으로, 중앙 시스템은 DB로부터 제1이미지 정보와 제2이미지 정보를 획득 하고, 서비스 어플리케이션에서는 획득된 제1이미지 정보와 제2이미지 정보를 통합하여 통합 이미지 정보 를 생성하고, 생성된 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성할 수 있다. 일 실시예에 따라, 중앙 시스템 내 서비스 어플리케이션에서는 전장 맵을 인공지능 모델에 입력하여 병사가 수행 해야 하는 전술에 관한 정보를 확인할 수 있다. 다른 실시예에 따라, 중앙 시스템 내 서비스 어플리케이션 에서는 전장 맵과 병사의 생체 정보를 인공지능 모델에 함께 입력하여 병사가 수행해야 하는 전술에 관한 정보를 확인할 수 있다. 중앙 시스템은 서비스 어플리케이션에서 확인한 전술에 관한 정보를 지휘관 에게 제공할 수 있다. 지휘관은 전투 유닛을 장착한 개별 병사(현장 지휘관)일 수 있고, 외부의 별도 인원 (후방 지휘관)일 수 있다. 중앙 시스템은 다수의 전술을 지휘관에게 제공할 수 있고, 지휘관은 이들 중 한 가지를 선택하거나 다수의 전술을 혼합하여 작전을 결심할 수 있다. 일 실시예에 따라, 중앙 시스템은 전투 유닛으로부터 수집된 데이터를 이용하여 인공지능 모델을 재 학습시킴으로써 인공지능 모델을 개선할 수 있다. 중앙 시스템은 전투 유닛이 향상된 추론 기능을 수 행할 수 있도록 개선된 인공지능 모델을 전투 유닛에게 전송할 수 있다. 일 실시예에 따라, 전투 유닛 은 중앙 시스템으로부터 제공받은 인공지능 모델을 이용하여 전장 맵에 대응되는 전술에 관한 정보를 확인 하고, 확인한 전술에 관한 정보를 다른 전투 유닛에게 제공할 수 있다. 일 실시예에 따라, 전투 유닛은 중 앙 시스템으로부터 인공지능 모델에 관한 정보를 전송받고, 인공지능 모델에 관한 정보를 이용하여 전송받 은 인공지능 모델의 버전 정보를 확인할 수 있다. 전투 유닛이 전송받은 인공지능 모델이 구버전인 경우 전투 유닛은 중앙 시스템에게 인공지능 모델의 업데이트에 관한 요청 정보를 전송할 수 있다. 중앙 시스템이 전투 유닛으로부터 인공지능 모델의 업데이트에 관한 요청 정보를 전송받는 경우, 중앙 시 스템은 전투 유닛에게 개선된 인공지능 모델을 다시 전송할 수 있다. 도 5는 다른 실시예에 따른 전투 유닛들과 중앙 시스템의 개략도를 나타낸다. 도 5를 참조하면, 현장의 전투 유 닛들은 기본적으로 중앙 시스템과의 직접적인 통신(예를 들어, 적색 화살표)을 통해 전장의 정보를 전송한다. 전투 유닛들은 피어 투 피어(Peer-to-Peer) 방식으로 전투 유닛들간의 통신(예를 들어, 청색 화살표)을 통해 데 이터나 특정 정보를 송수신할 수 있다. 다시 말해, 전투 유닛들은 중앙 시스템과 단절되는 경우에도 분산형 네 트워크를 구성하여 데이터나 특정 정보의 효율적인 처리가 가능할 수 있다. 일 실시예에 따라, 전투 유닛은 다 른 적어도 하나의 전투 유닛과의 거리에 관한 정보를 확인하고, 다른 전투 유닛과의 거리에 관한 정보를 기초로 전술에 관한 정보를 제공할 수 있다. 특히 전투 유닛을 장착한 병사들이 넓게 분산되어 있는 경우, 최인접 병사 가 장착한 전투 유닛을 통해 릴레이식으로 전술에 관한 정보를 전달하거나 교환할 수 있다. 전투 유닛들 간의 피어 투 피어 방식의 통신을 이용하면, 중앙 시스템과 통신이 두절된 경우에도 전투 유닛끼리 인공지능 모델을 업데이트하거나 내부 프로그램을 복구할 수 있다. 전투 유닛은 자체적으로 데이터의 수집이 가능하며 수집한 데이터를 분석하고 추론할 수 있는 중량형 엣지 AI 인공지능 모델을 탑재할 수 있다. 따라서, 중앙 시스템과의 통신이 단절된 경우, 전투 유닛은 자체 인공지능 모 델을 활성화하고 주변의 다른 전투 유닛과의 연동을 통해 중앙 시스템의 본래 목적인 병사가 수행해야 하는 전술에 관한 정보를 확인할 수 있다. 도 5를 참조하면, 제1전투 유닛은 제2전투 유닛에 포함된 카메라를 통해 획 득된 제2이미지 정보와 제3전투 유닛에 포함된 카메라를 통해 획득된 제3이미지 정보를 획득할 수 있다. 제1전 투 유닛은 제2이미지 정보와 제3이미지 정보를 통합하여 통합 이미지 정보를 생성하고, 생성된 통합 이미지 정 보에 대한 객체 인식을 기반으로 전장 맵을 생성할 수 있다. 이어서, 제1전투 유닛은 생성한 전장 맵을 제1전투 유닛에 자체적으로 탑재된 인공지능 모델에 입력하여 제1전투 유닛, 제2전투 유닛, 및 제3전투 유닛을 장착한 각각의 병사들이 수행해야 하는 전술에 관한 정보를 확인할 수 있다. 제1전투 유닛은 확인한 전술에 관한 정보 를 제2전투 유닛, 제3전투 유닛, 및 제N전투 유닛 각각에게 제공할 수 있다. 다시 말해, 도 5의 전투 유닛들(제 1전투 유닛, 제2전투 유닛... 제N전투 유닛)은 중앙 시스템의 모든 기능을 자체적으로 수행할 수 있다. 전투 유 닛은 전투 유닛을 장착한 병사에게 전술에 관한 정보를 제공할 수 있다. 현장의 지휘관(도 5의 제4전투 유닛을 장착한 병사)은 제4전투 유닛에게 제공받은 전술에 관한 정보에 기반하여 최종적으로 전술을 결정하고 수행할 수 있다. 도 6은 전투 유닛이 동작하는 일 실시예를 나타낸다. 일 실시예에 따라, 중앙 시스템과 각각의 전투 유닛 들은 통신 네트워크를 통해 개별적으로 연결될 수 있다. 도 6을 참조하면, 중앙 시스템은 제1전투 유닛 , 제2전투 유닛 ... 및 제n전투 유닛과 개별적으로 연결된다. 전투 유닛간에는 중앙 시스템과 연결된 통신 네트워크와 상이한 대역폭을 이용하여 클러스터링(중앙 시스템과 연결된 통신 네트워크와 별개 네트워크)을 구 성할 수 있다. 일 실시예에 따라, 전투 유닛은 엣지 코디네이터를 포함할 수 있고, 프로세서는 엣지 코디 네이터의 동작을 제어할 수 있다. 엣지 코디네이터는 종합적인 전투 유닛의 기기정보를 관리하는 기능과 전투 유닛에게 특정 동작을 수행하도록 명령하는 잡-스케줄러(Job Scheduler) 기능을 수행할 수 있다. 예를 들어, 엣 지 코디네이터는 개별 전투 유닛의 통신 상태를 확인할 수 있고, 전투 유닛 자체의 동작 상태를 파악할 수 있고, 전투 유닛 내에 탑재된 인공지능 모델의 버전과 업데이트 여부를 확인할 수 있고, 전투 유닛의 리소스 사 용 현황을 확인할 수 있다. 일 실시예에 따라, 중앙 시스템과 전투 유닛 간의 통신이 정상적으로 이루어지는 경우, 엣지 코디네이터는 기본적인 전투 유닛의 기능을 관리할 수 있다. 예를 들어, 엣지 코디네이터는 제5전투 유닛의 외부 센서로 부터 수집하는 데이터를 수집하는 기능을 관리할 수 있고, 제5전투 유닛이 인공지능 모델을 이용하여 전술에 관 한 정보를 생성하는 기능을 관리할 수 있고, 제5전투 유닛이 다른 전투 유닛(예를 들어, 제4전투 유닛)에게 전 술에 관한 정보를 제공하는 기능을 관리할 수 있다. 다른 실시에에 따라, 중앙 시스템과 전투 유닛 간의 통신이 단절되는 경우, 엣지 코디네이터는 통신이 가 능한 다른 전투 유닛들을 탐색하여 엣지 클러스터링(또는, 클러스터링)을 구성할 수 있다. 도 6을 참조하면, 특 정 전투 유닛(예를 들어, 제5전투 유닛)에 포함된 엣지 코디네이터는 제5전투 유닛과 통신이 가능한 제1전 투 유닛, 제2전투 유닛, 제3전투 유닛, 제4전투 유닛, 제6전투 유닛 ... 및 제n전투 유닛을 확인하고, 제5전투 유닛과 확인된 전투 유닛들 간에 클러스터링을 구성할 수 있다. 일 실시예에 따라, 특정 전투 유닛은 전투 유닛 들의 순위에 관한 정보에 기초하여 결정될 수 있다. 예를 들어, 제5전투 유닛이 1순위인 경우, 제5전투 유닛에 포함된 엣지 코디네이터가 전투 유닛들 간에 클러스터링을 구성할 수 있다. 이 경우, 엣지 코디네이터 를 마스터 엣지 코디네이터로 지칭할 수 있다. 일 실시예에 따라, 전투 유닛들의 순위에 관한 정보는 전투 유닛을 장착한 각각의 병사의 계급에 따라 결정될 수 있다. 예를 들어, 제5전투 유닛을 장착한 병사의 계급이 제일 높은 경우, 제5전투 유닛을 전투 유닛들 중 제1순위로 결정할 수 있다. 제4전투 유닛을 장착한 병사의 계 급이 제5전투 유닛을 장착한 병사의 계급의 다음으로 높은 경우, 제4전투 유닛을 전투 유닛들 중 제2순위로 결 정할 수 있다. 마스터 엣지 코디네이터를 포함하는 전투 유닛을 장착한 병사가 사망하거나, 마스터 엣지 코디네 이터가 포함된 전투 유닛이 고장나는 등의 돌발 상황이 발생하는 경우, 차순위의 병사가 장착한 전투 유닛에 포 함된 엣지 코디네이터를 마스터 엣지 코디네이터로 결정할 수 있다. 예를 들어, 제5전투 유닛을 장착한 병사(즉, 계급이 1순위인 병사)가 사망하는 경우, 제4전투 유닛(즉, 계급이 2순위인 병사가 장착한 전투 유닛) 에 포함된 엣지 코디네이터를 마스터 엣지 코디네이터로 결정할 수 있다. 이 경우, 제4전투 유닛에 포함된 엣지 코디네이터가 전투 유닛들 간의 클러스터링을 구성할 수 있다. 마스터 엣지 코디네이터를 포함하는 전투 유닛은 클러스터링 내의 전투 유닛들 전체를 관리하는 중앙 시스템의 역할을 수행할 수 있다. 다시 말해, 마스터 엣지 코디네이터를 포함하는 전투 유닛은 중앙 시스템처럼 각각의 전투 유닛에서 수집, 분석된 정보를 전송받아 전장 상황을 분석할 수 있다. 예를 들어, 620이 마스터 엣지 코디네이터인 경우, 제5전투 유닛은 제1전투 유닛, 제2 전투 유닛, 제3전투 유닛, 제4전투 유닛, 제6전투 유닛... 및 제n전투 유닛으로부터 수집된 정보를 획득하여 전 장 맵을 생성하고, 전투 유닛을 장착한 병사가 수행해야 하는 전술에 관한 정보를 확인할 수 있다. 마스터 엣지코디네이터는 클러스터링 내의 전투 유닛의 상태 정보를 바탕으로 전투 유닛에게 업무를 할당할 수 있다. 전투 유닛은 휴대성이 우선시되므로, 최소한의 사양을 갖는 하드웨어로 구성될 수 있다. 따라서, 전투 유닛은 중앙 시스템 대비 열화된 성능을 가질 수 있다. 이를 보완하기 위해, 마스터 엣지 코디네이터는 전투 유닛들 간에 엣 지 클러스터링을 구성하고, 각각의 전투 유닛의 리소스에 관한 정보를 확인하여 전투 유닛의 추론 기능을 분산 배분할 수 있다. 전투 유닛의 추론 기능이란, 중앙 시스템에서 전장 맵을 생성하는 기능과 전장 맵에 대응되는 전술에 관한 정보를 확인하는 기능을 의미할 수 있다. 일 실시예에 따라, 마스터 엣지 코디네이터는 마스터 엣지 코디네이터를 포함하는 전투 유닛을 제외한 클러스터 링 내의 전투 유닛 각각의 리소스 정보(예를 들어, 메모리, CPU, GPU 등)를 획득할 수 있다. 도 6을 참조하면, 620은 제5전투 유닛을 제외한 제1전투 유닛, 제2전투 유닛, 제3전투 유닛, 제4전투 유닛, 제6전투 유닛 ... 및 제n전투 유닛 각각의 리소스 정보를 획득할 수 있다. 제5전투 유닛(마스터 엣지 코디네이터를 포함하는 전투 유 닛)은 획득한 리소스 정보를 기초로, 전체 전투 유닛들의 리소스 중 적어도 일부를 이용하여 전장 맵을 생성할 수 있다. 예를 들어, 제5전투 유닛은 제1전투 유닛, 제2전투 유닛, 및 제5전투 유닛의 리소스만을 기초로 전장 맵을 생성할 수 있다. 다른 예시로서, 제5전투 유닛은 모든 전투 유닛들의 리소스를 기초로 전장 맵을 생성할 수 있다. 제5전투 유닛(마스터 엣지 코디네이터를 포함하는 전투 유닛)은 획득한 리소스 정보를 기초로, 전체 전투 유닛들의 리소스 중 적어도 일부를 이용하여 전술에 관한 정보를 확인할 수 있다. 예를 들어, 제5전투 유 닛은 제1전투 유닛, 제2전투 유닛, 및 제4전투 유닛의 리소스만을 기초로 전술에 관한 정보를 확인할 수 있다. 다른 예시로서, 제5전투 유닛은 모든 전투 유닛들의 리소스를 기초로 전술에 관한 정보를 확인할 수 있다. 일 실시예에 따라, 마스터 엣지 코디네이터를 포함하는 전투 유닛은 클러스터링 내 전체 전투 유닛들의 리소스 정보를 기초로, 클러스터링 내 전투 유닛을 제1그룹 및 제2그룹으로 분류할 수 있다. 도 6을 참조하면, 620이 마스터 엣지 코디네이터인 경우, 제5전투 유닛은 제1전투 유닛 내지 제4전투 유닛을 제1그룹으로 분류하고, 제5 전투 유닛 내지 제n전투 유닛을 제2그룹으로 분류할 수 있다. 일 실시예에 따라, 마스터 엣지 코디네이터를 포 함하는 전투 유닛은, 제1그룹의 리소스를 기초로 전장 맵을 생성할 수 있고, 제2그룹의 리소스를 기초로 전술에 관한 정보를 생성할 수 있다. 예를 들어, 제5전투 유닛은, 제1전투 유닛 내지 제4전투 유닛의 리소스를 기초로 전장 맵을 생성할 수 있고, 제5전투 유닛 내지 제n전투 유닛의 리소스를 기초로 전술에 관한 정보를 생성할 수 있다. 이처럼 본 개시는 중앙 시스템과의 통신이 단절된 경우에도, 클러스터링 내 각각의 전투 유닛의 리소스를 하나의 리소스로 통합하여 하나의 전투 유닛처럼 추론 기능을 일괄적으로 수행하거나, 클러스터링 내 각각의 전 투 유닛의 리소스를 효율적으로 분배하여 병렬적으로 추론 기능을 수행함으로써 부족한 하드웨어 자원을 보완하 고 신속한 결과 도출이 가능할 수 있다. 도 7은 프로세서가 동작하는 일 실시예를 나타낸다. 보통 전술을 결정하기 위한 고려요소로서 기존 전술, 적, 지형, 기상, 시간, 민간요소가 고려될 수 있다. 그리고 전술을 수행하기 단계는 전장 상황과 기존의 전술을 평 가하고 새로운 전술 도입할지 여부를 검토하는 '상황 판단'단계(S700 내지 S720 단계), 도출된 대응 방책 중 최 종적으로 병사가 수행할 방책(즉, 전술)을 선정하는 '결심'단계(S730 내지 S750 단계), 및 전술을 하달하고 전 술이 제대로 수행되는지 여부를 확인하며 병사를 감독하는 '대응'단계(S760 내지 S790)로 구성될 수 있다. S700 단계에서, 프로세서는 기존의 전술(즉, 임무 또는 작전 목표)을 확인할 수 있다. 프로세서는 기 존의 전술을 전투 유닛을 장착한 병사에게 제공할 수 있고, 병사는 기존 전술을 수행할 수 있다. S710 단계에서, 프로세서는 전장 상황을 수집할 수 있다. 프로세서는 다양한 수집 장치들을 복합적으 로 이용하여 전장 환경의 각종 데이터를 수집할 수 있다. 예를 들어, 프로세서는 전투 유닛에 포함된 카메 라를 통해 획득된 이미지 정보를 획득할 수 있고, 이동식 지휘소에 포함된 카메라를 통해 획득된 이미지 정보를 획득할 수 있다. 다른 예시로서, 프로세서는 드론 센서가 획득한 이미지 정보를 획득할 수 있고, 현장 설 치형 센서가 획득한 이미지 정보를 획득할 수 있다. 각종 수집 장치들을 통해 수집한 데이터는 병사의 생체 신 호(예를 들어, 전투 유닛에 포함된 센서로부터 측정된 병사의 뇌파, 응시 패턴, 심박수, 호흡, 체온에 관한 신 호)와 주변 환경의 센싱 정보(예를 들어, 이미지 정보, 음향 정보, 위치 정보, 및 기온 정보)를 포함할 수 있다. 프로세서는 각종 센서로부터 수집한 병사의 생체 신호를 기초로 병사의 생체 정보를 확인할 수 있다. S720 단계에서, 프로세서는 전장 맵을 생성할 수 있다. 구체적으로, 프로세서는 S710 단계에서 획득 한 이미지 정보를 기초로 전장 맵을 생성할 수 있다. 프로세서는 전투 유닛에 포함된 카메라를 통해 획득 된 제1이미지 정보와 드론 센서를 통해 획득한 제2이미지 정보를 통합하여 통합 이미지 정보를 생성하고, 통합이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성할 수 있다. S730 단계에서, 프로세서는 인공지능 전투 시뮬레이션 모델을 이용하여 병사가 수행해야 하는 전술에 관한 정보를 확인할 수 있다. 일 실시예에 따라, 프로세서는 전장 맵을 인공지능 전투 시뮬레이션 모델에 입력 하여 전술에 관한 정보를 확인할 수 있다. 다른 실시예에 따라, 프로세서는 전장 맵과 병사의 생체 정보를 인공지능 전투 시뮬레이션 모델에 입력하여 전술에 관한 정보를 확인할 수 있다. 프로세서는 전장의 주변 환경(예를 들어, 전장 맵) 뿐만 아니라, 병사의 개별 상태(예를 들어, 병사의 생체 정보)를 함께 고려하므로, 위급한 상황에서 보다 적합한 전술 제공이 가능할 수 있다. S740 및 S750 단계에서, 프로세서는 병사가 수행해야 하는 전술에 관한 정보를 제공할 수 있다. 프로세서 는 전술에 관한 정보를 전투 유닛을 장착한 병사(예를 들어, 현장 지휘관)에게 제공하거나 후방의 지휘관 에게 제공할 수 있다. 전술에 관한 정보는 복수의 전술을 포함할 수 있으므로, 지휘관은 최종 대응 방책을 결심 할 수 있다. S760 단계에서, 전투 유닛을 장착한 병사는 작전(즉, 전술 또는 방책)을 수행할 수 있다. 기존의 전술과 새로운 전술이 동일한 경우, 병사는 기존의 전술을 그대로 수행할 수 있다. S760 단계에서 제공받은 전술이 S700 단계 에서 확인한 전술과 상이한 경우, 병사는 새로운 전술을 수행할 수 있다. S770 단계에서, 프로세서는 계속적으로 병사들의 전술 수행을 모니터링할 수 있다. 병사들이 전술을 수행 하는 과정에서, 전장의 환경이 변화할 수 있으므로 프로세서는 데이터 수집 센서들을 통해 계속적으로 전 장의 정보를 획득할 수 있다. S780 단계에서, 전장의 상황이 변화하는 경우 프로세서는 S730 단계 내지 S770 단계를 다시 수행할 수 있 다. 전장의 상황이 변화하지 않는 경우, S790 단계로 나아갈 수 있다. S790 단계에서, 프로세서는 병사가 수행한 작전을 평가할 수 있다. 병사가 수행한 작전이 해당 전장 환경 에 적합하지 않은 작전이라고 판단된 경우, 프로세서는 인공지능 전투 시뮬레이션 모델을 재학습시킬 수 있다. 도 8은 전자 장치가 동작하는 일 실시예를 나타낸다. 도 8의 동작 방법의 각 단계는 도 1의 전자 장치에 의해 수행될 수 있으므로, 도 8과 중복되는 내용에 대 해서는 설명을 생략한다. S810 단계에서, 전자 장치는 제1전투 유닛에 포함된 카메라를 통해 획득된 제1이미지 정보, 및 제2전투 유닛에 포함된 카메라를 통해 획득된 제2이미지 정보를 획득할 수 있다. 전자 장치는 제3전투 유닛에 포함된 센서로부 터 측정된 생체 신호를 획득할 수 있다. S820 단계에서, 전자 장치는 제1이미지 정보 및 제2이미지 정보를 통합하여 통합 이미지 정보를 생성할 수 있다. S830 단계에서, 전자 장치는 통합 이미지 정보에 대한 객체 인식을 기반으로 전장 맵을 생성할 수 있다. 전자 장치는 제4전투 유닛에 포함된 gps 센서로부터 측정된 전장의 위치에 관한 정보를 획득하고, 위치에 관한 정보 를 기초로 전장의 지형도를 확인할 수 있다. 전자 장치는 통합 이미지 내의 객체의 배치에 관한 정보를 확인하 고, 객체의 배치에 관한 정보를 기초로 지형도에 객체를 배치하여 전장 맵을 생성할 수 있다. S840 단계에서, 전자 장치는 전장 맵을 인공지능 모델에 입력하여 전술에 관한 정보를 확인할 수 있다. 다른 실 시예에 따라, 전자 장치는 생체 신호를 기초로 제3전투 유닛을 장착한 병사의 생체 정보를 확인하고, 전장 맵 및 제3전투 유닛을 장착한 병사의 생체 정보를 인공지능 모델에 입력하여 전술에 관한 정보를 확인할 수 있다. 전술에 관한 정보는 전투 유닛을 장착한 적어도 하나의 병사의 이동 경로에 관한 정보, 및 병사의 전술 행동을 지시하는 정보를 포함할 수 있다. S850 단계에서, 전자 장치는 전술에 관한 정보를 제공할 수 있다. 일 실시예에 따라, 전자 장치가 중앙 시스템 에 포함된 경우, 전자 장치는 전술에 관한 정보와 인공지능 모델에 관한 정보를 적어도 하나의 전투 유닛에게 제공할 수 있다. 일 실시예에 따라, 적어도 하나의 전투 유닛은 인공지능 모델에 관한 정보를 이용하여 전장 맵에 대응되는 전술 에 관한 정보를 확인하고, 확인된 전술에 관한 정보를 다른 적어도 하나의 전투 유닛에게 제공할 수 있다. 적어 도 하나의 전투 유닛은 다른 적어도 하나의 전투 유닛과의 거리에 관한 정보를 확인하고, 확인된 거리에 관한 정보를 기초로 다른 적어도 하나의 전투 유닛 중 최인접 전투 유닛에게 전술에 관한 정보를 제공할 수 있다. 전술한 실시예들에 따른 전자 장치는, 프로세서, 프로그램 데이터를 저장하고 실행하는 메모리, 디스크 드라이 브와 같은 영구 저장부(permanent storage), 외부 장치와 통신하는 통신 포트, 터치 패널, 키(key), 버튼 등과 같은 사용자 인터페이스 장치 등을 포함할 수 있다. 소프트웨어 모듈 또는 알고리즘으로 구현되는 방법들은 상 기 프로세서상에서 실행 가능한 컴퓨터가 읽을 수 있는 코드들 또는 프로그램 명령들로서 컴퓨터가 읽을 수 있 는 기록 매체 상에 저장될 수 있다. 여기서 컴퓨터가 읽을 수 있는 기록 매체로 마그네틱 저장 매체(예컨대, ROM(read-only memory), RAM(random-Access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판독 매체(예 컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있는 기록 매 체는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실 행될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 본 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들은 특정 기능들을 실행하는 다양한 개수의 하드웨어 또는/및 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 실시예는 하나 이상의 마이크로프로세서들의 제어 또는 다른 제어 장치들에 의해서 다양한 기능들을 실행할 수 있는, 메 모리, 프로세싱, 로직(logic), 룩 업 테이블(look-up table) 등과 같은 직접 회로 구성들을 채용할 수 있다. 구 성 요소들이 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행될 수 있는 것과 유사하게, 본 실시 예는 데 이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있 다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 실시 예 는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. “매커니즘 ”, “요소”, “수단”, “구성”과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한 정되는 것은 아니다. 상기 용어는 프로세서 등과 연계하여 소프트웨어의 일련의 처리들(routines)의 의미를 포 함할 수 있다. 전술한 실시예들은 일 예시일 뿐 후술하는 청구항들의 범위 내에서 다른 실시예들이 구현될 수 있다."}
{"patent_id": "10-2022-0111568", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 전자 장치를 나타낸다. 도 2는 프로세서가 전장 맵을 생성하는 일 실시예를 나타낸다. 도 3은 프로세서가 생체 신호 및 주변 환경에 관한 센싱 정보를 획득하는 일 실시예를 나타낸다. 도 4는 일 실시예에 따른 전투 유닛들과 중앙 시스템의 개략도를 나타낸다. 도 5는 다른 실시예에 따른 전투 유닛들과 중앙 시스템의 개략도를 나타낸다. 도 6은 전투 유닛이 동작하는 일 실시예를 나타낸다. 도 7은 프로세서가 동작하는 일 실시예를 나타낸다. 도 8은 전자 장치가 동작하는 일 실시예를 나타낸다."}
