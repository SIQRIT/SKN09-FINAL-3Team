{"patent_id": "10-2023-0092577", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0012383", "출원번호": "10-2023-0092577", "발명의 명칭": "딥 러닝 아키텍처를 사용한 객체 검출 방법 및 장치", "출원인": "인천대학교 산학협력단", "발명자": "전광길"}}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(A) 폐 CT 스캔 이미지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집하는 데이터 수집 단계;(B) 상기 폐 CT 스캔 이미지의 품질을 향상시키기 위한 데이터 전처리 단계;(C) 상기 폐 CT 스캔 이미지의 다양성을 향상시키기 위해 데이터 수를 증가시키는 데이터 변조(augmentation)단계; (D) 딥 러닝 모델의 검색 공간을 좁히기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나누는 이미지 분할 단계;(E) 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용하여 상기 딥 러닝 모델을 학습시키는 학습 단계;및(F) 학습된 딥러닝 모델에 임의의 폐 CT 스캔 이미지를 입력하여 폐 결절을 검출하고, 검출한 이미지를 세 가지로 분류하는 검출 및 분류 단계;를 포함하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 데이터 전처리 단계에서는, 상기 폐 CT 스캔 이미지를 로드하고, 복셀(voxel)로 변환하는 좌표 변환 단계;산출한 데이터의 평균 및 표준 편차를 이용하여 상기 폐 CT 스캔 이미지의 크기를 다시 조절하는 데이터 스케일링(data scaling)단계; 및상기 폐 CT 스캔 이미지의 픽셀 값을 폐 CT 스캔 HU(Houndsfield Units) 값으로 변환하는 정규화 단계;를 더 포함하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 데이터 변조 단계에서는,노이즈 증강, 색깔 증강 및 공간 증강을 포함하는 것을 특징으로 하는, 딥 러닝 아키텍처를 사용한 객체 검출방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 학습 단계에서는,학습된 모델의 가중치를 사용하는 전이 학습 접근법을 채택하고, 상기 딥 러닝 모델의 일반화 성능을 탐색하는것을 특징으로 하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 정규화 단계에서는, 을 기반으로 계산되고, 여기서, CT 스캔 HU(Houndsfield Units)값은 컴퓨터 단층촬영 이미지의 밀도 분석을 위한 흡수 계수로, 체내로투입한 조영제에 대한 신체의 각 구성별 흡수율이 다른 것을 수치화 한 것을 특징으로 하는, 딥 러닝 아키텍처공개특허 10-2025-0012383-3-를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 좌표 변환 단계에서는, 을 기반으로 계산되고,여기서, voxel이란 2D 이미지를 구성하는 최소 단위인 pixel(picture element)을 3D로 확장한 것을 나타내고,하나의 voxel은 pixel spacing 만큼의 가로와 세로의 길이를 가지는 것을 의미하는, 딥 러닝 아키텍처를 사용한객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서, 상기 전이 학습 접근법에서는, 학습을 위한 분류 작업으로 VGG-16, ResNet-50, MobileNet의 딥 러닝 아키텍쳐를 활용하는 것을 특징으로 하는,딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 학습 단계에서는,학습을 위한 분류 작업이 종료되면, 상기 폐 CT 스캔 이미지에서 폐 결절의 위치를 파악하고, 무결절, 양성 및악성 세 단계로의 식별을 위한 위한 딥 러닝 아키텍처로 Faster R-CNN, SSD, YOLOv3를 활용하는 것을 특징으로하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 Faster R-CNN은, 감지된 앵커를 세분화하기 위해 좁은 네트워크(small network)가 적용될 수 있고, 앵커 병변을 결정하는 손실함수는 에 기반하여 계산되고, 여기서, 는 classification loss와 regression loss 사이에 가중치를 조절해주는 매개변수, i는 하나의앵커, pi는 분류를 통해서 얻은 앵커가 객체일 확률, ti는 바운딩 박스 회귀(regression)를 통해서 얻은 박스조정 값 벡터, pi*와 ti*은 바운딩 박스의 실제 좌표를 나타내기 위한 ground truth 라벨을 의미하는, 딥 러닝아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, pi값이 1이면 감지된 앵커는 결절으로 분류되었음을 나타내는 포지티브 클래스와 연관될 수 있고, 반대로 pi값이 0이면 감지된 앵커는 결절으로 분류되지 않았음을 나타내는 네거티브 클래스를 설명할 수 있는 것을 특징으로 하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2025-0012383-4-제8항에 있어서, 상기 SSD를 사용하는 경우, 손실 함수는 을 기반으로 계산되고, 여기서, x는 매칭 지표, c는 다양한 클래스의 신뢰도, l은 예측상자(predicted box)의 매개변수, g는 실측 상자(ground truth box)의 매개변수, N은 매칭된 디폴트 박스(default box)의 수, 는 손실 함수에 대해 안정화가중치, 는 신뢰도에 대한 손실(confidence loss), 은 예측된 경계 상자 위치 및 크기의 오류로인한 손실(localization loss)을 나타내는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 는,을 기반으로 계산되고, 상기 는, 기반으로 계산되며, 여기서, 는 클래스 p에 대하여 i번째 디폴트 박스(default box)와 j번째 참 경계 박스(ground truth box)가매칭되는지에 대한 지표, c는 서로 다른 결절에 대한 신뢰도를 나타내고, 값이 1과 0일 수 있는 것을 특징으로 하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 는, 를 기반으로 계산하고, 여기서, cx 및 cy는 분류해야 하는 class의 객체 중심 좌표, w, h는 이미지 너비와 높이, 는 클래스 p의 i번째 디폴트 박스(default box)와 j번째 참 경계 박스(ground truth box)가 매칭되는지 여부를 나타내고,는 smooth L1 손실함수를 의미하고, 공개특허 10-2025-0012383-5-여기서, 값과 관련하여, m이 각 cx, cy, w, h인 경우에는 이미지 너비의 비율로 계산하고,는 이미지 높이의 비율로 계산하며, 이미지 너비와 이미지 높이는 , 와 같이 로그 스케일을 적용하는 것을특징으로 하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 YOLOv3를 사용하는 경우의 손실 함수 는을 기반으로 계산되고, 여기서, 는 예측 상자의 객체가 속한 범주를 결정하여 배경 영역을 구별하는데 도움이 되는 classificationloss와 예측 바운딩 박스에 객체가 포함된 경우에만 적용되는 box regression loss 사이에 가중치를 조절해주는매개변수이고, 는 상기 바운딩 박스에서 객체의 탐지 여부에 따라 달라지는 매개변수로 객체의 탐지여부에 따라 1 또는 0을 대입하며, 객체가 탐지되는 경우 실제 데이터 와 예측 데이터를 매개변수로 바운딩 박스의 위치와 크기를 나타내는 것을 특징으로 하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,의 바운딩 박스 회귀손실 값 은을 기반으로 계산하고, 여기서, IOU(Interest of Union)는 같은 클래스로 분류되는 복수의 객체가 겹치는 비율을 나타내고 , 는 예측 상자의 객체가 속한 범주를 결정하여 배경 영역을 구별하는데 도움이 되는 classification loss와 예측 바운공개특허 10-2025-0012383-6-딩 박스에 객체가 포함된 경우에만 적용되는 box regression loss 사이에 가중치를 조절해주는 매개변수이고,와 는 i번째 그리드 셀(grid cell)에서의 컨피던스 값(confidence value)의 실제 데이터와 예측 데이터,은 i번째 그리드 셀과 j번째 바운딩 박스(bounding box)에서 감지된 결절을 나타내는 매개변수인 것을 특징으로 하는, 딥 러닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "(A) 폐 CT 스캔 이미지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집하는 데이터 수집부;(B) 상기 폐 CT 스캔 이미지의 품질을 향상시키기 위한 데이터 전처리부;(C) 상기 폐 CT 스캔 이미지의 다양성을 향상시키기 위해 데이터 수를 증가시키는 데이터변조(augmentation)부; (D) 딥 러닝 모델의 검색 공간을 좁히기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나누는 이미지 분할부;(E) 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용하여 상기 딥 러닝 모델을 학습시키는 학습부; 및(F) 학습된 딥러닝 모델에 임의의 폐 CT 스캔 이미지를 입력하여 폐 결절을 검출하고, 검출한 이미지를 세 가지로 분류하는 검출 및 분류부;를 포함하는, 딥 러닝 아키텍처를 사용한 객체 검출 장치."}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "폐 CT 스캔 이미지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집하는 데이터 수집 단계;상기 폐 CT 스캔 이미지의 품질을 향상시키기 위한 데이터 전처리 단계; 상기 폐 CT 스캔 이미지의 다양성을 향상시키기 위해 데이터 수를 증가시키는 데이터 변조(augmentation) 단계; 딥 러닝 모델의 검색 공간을 좁히기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나누는 이미지 분할 단계; 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용하여 상기 딥 러닝 모델을 학습시키는 학습 단계; 및 학습된 딥러닝 모델에 임의의 폐 CT 스캔 이미 지를 입력하여 폐 결절을 검출하고, 검출한 이미지를 세 가지로 분류하는 검출 및 분류 단계;를 포함하는, 딥 러 닝 아키텍처를 사용한 객체 검출 방법."}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 폐 CT 스캔 이미지로부터 폐 결절 검출을 위한 딥 러닝 아키텍처에 관한 것이다."}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근의 생물의학 이미징 기술의 발전은 의료 분야와 생물의학계에 엄청난 기회를 제공했다. 그러나 이미지와 같 은 건강 관련 데이터를 대량으로 수집, 측정, 분석하는 것은 의료 전문가에게 힘들고 시간이 많이 걸리는 작업 이다. 이와 관련하여 인공지능 응용(기계 및 딥러닝 시스템 포함)은 폐암과 같은 다양한 전염병 및 암성 질병의 조기 진단에 도움이 될 수 있다. 폐암은 뚜렷한 초기 증상이 없을 수 있기 때문에 의료 전문가가 폐 결절을 조 기에 분류하고 발견할 수 있도록 컴퓨터 지원 탐지(CAD) 시스템을 개발하는 것이 필수적이다. 또한, 일반적으로 작은 폐 결절을 식별하기 위해 전체 폐를 검사해야 하며 각 환자에 대해 많은 이미지를 생성 해야 한다. 혈관 및 기관지와 같은 상관관계가 없는 조직을 제거하여 이러한 큰 이미지를 검사하고 많은 수의 CT 스캔에서 결절을 식별하는 것은 의료 전문가에게 어려운 작업이다. 비정상적이고 크고 무서운 이미지 수로 인한 의료 전문가의 피로감, 주의 산만 및 혼란은 오진으로 이어지기 쉽다. 따라서 폐 결절 모니터링 및 스크리 닝을 위한 효과적인 자동화된 컴퓨터 시스템을 생산하는 것이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2018-0152514 A"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "위와 같은 문제를 해결하기 위하여, 본 발명에서는 CT 영상에서 폐 결절의 양성과 악성을 분류하고 검출하여, 폐암 진단의 문제점을 분석을 위한 폐 결절을 분류 딥러닝 시스템을 도입하였다. 학습 및 탐지 목적으로 Faster-RCNN, YOLOv3 및 SSD를 포함한 새로운 최신 탐지 아키텍처를 사용하였고, 그 결과 FPR(False Positive Rate)이 감소하고 정확도가 향상되었음을 확인할 수 있다."}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 의한 폐 결절 검출 방법은, 딥 러닝 아키텍처를 사용한 객체 검출 방법에 있어서, (A) 폐 CT 스캔 이미지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집하는 데이터 수집 단계; (B) 상기 폐 CT 스캔 이미지의 품질을 향상시키기 위한 데이터 전처리 단계; (C) 상기 폐 CT 스캔 이미지의 다양성을 향상시키기 위해 데이터 수를 증가시키는 데이터 변조(augmentation) 단계; (D) 딥 러 닝 모델의 검색 공간을 좁히기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나누는 이미지 분할 단계; (E) 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용하여 상기 딥 러닝 모델을 훈련시키는 학습 단계; 및 (F) 학습된 딥러닝 모델에 임의의 폐 CT 스캔 이미지를 입력하여 폐 결절을 검출하고, 검출한 이미지를 세 가지로 분류하는 검출 및 분류 단계;를 포함할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 데이터 전처리 단계에서는, 상기 폐 CT 스캔 이미지를 로드하고, 복셀(voxel)로 변환하는 좌표 변환 단계; 산출한 데이터의 평균 및 표준 편차를 이용하여 상기 폐 CT 스캔 이미지의 크기를 다시 조절하는 데이터 스케일링(data scaling)단계; 및 상기 폐 CT 스캔 이미지의 픽셀 값을 폐 CT 스캔 HU(Houndsfield Units) 값으로 변환하는 정규화 단계;를 더 포함할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 데이터 변조 단계에서는, 노이즈 증강, 색깔 증강 및 공간 증강을 포함할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 학습 단계에서는, 학습된 모델의 가중치를 사용하는 전 이 학습 접근법을 채택하고, 상기 딥 러닝 모델의 일반화 성능을 탐색할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 정규화 단계에서는,"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "을 기반으로 계산되고, 여기서, CT 스캔 HU(Houndsfield Units)값은 컴퓨터 단층촬영 이미지의 밀도 분석을 위한 흡수 계수로, 체내로 투입한 조영제에 대한 신체의 각 구성별 흡수율이 다른 것을 수치화 한 것을 특징으로 할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 좌표 변환 단계에서는, 을 기반으로 계산되고, 여기서, voxel이란 2D 이미지를 구성하는 최소 단위인 pixel(picture element)을 3D로 확장한 것을 나타내고, 하나의 voxel은 pixel spacing 만큼의 가로와 세로의 길이를 가지는 것을 의미할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 전이 학습 접근법에서는, 학습을 위한 분류 작업으로 VGG-16, ResNet-50, MobileNet의 딥 러닝 아키텍쳐를 활용할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 학습 단계에서는, 학습을 위한 분류 작업이 종료되면, 상기 폐 CT 스캔 이미지에서 폐 결절의 위치를 파악하고, 무결절, 양성 및 악성 세 단계로의 식별을 위한 위한 딥 러닝 아키텍처로 Faster R-CNN, SSD, YOLOv3를 활용할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 Faster R-CNN은, 감지된 앵커를 세분화하기 위해 좁은 네트워크(small network)가 적용될 수 있고, 앵커 병변을 결정하는 손실 함수는 에 기반하여 계산되고, 여기서, 는 classification loss와 regression loss 사이에 가중치를 조절해주는 매개변수, i는 하나의 앵커, pi는 분류를 통해서 얻은 앵커가 객체일 확률, ti는 바운딩 박스 회귀(regression)를 통해서 얻은 박스 조정 값 벡터, pi*와 ti*은 바운딩 박스의 실제 좌표를 나타내기 위한 ground truth 라벨을 의미할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 pi값이 1이면 감지된 앵커는 결절으로 분류되었음을 나 타내는 포지티브 클래스와 연관될 수 있고, 반대로 pi값이 0이면 감지된 앵커는 결절으로 분류되지 않았음을 나 타내는 네거티브 클래스를 설명할 수 있는 것을 특징으로 할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법은, 상기 SSD를 사용하는 경우, 손실 함수는"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "을 기반으로 계산되고, 여기서, x는 매칭 지표, c는 다양한 클래스의 신뢰도, l은 예측상자(predicted box)의 매개변수, g는 실측 상자 (ground truth box)의 매개변수, N은 매칭된 디폴트 박스(default box)의 수, 는 손실 함수에 대해 안정화 가중치, 는 신뢰도에 대한 손실(confidence loss), 은 예측된 경계 상자 위치 및 크기의 오류로 인한 손실(localization loss)을 나타낼 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 는,"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "을 기반으로 계산되고, 상기 는,"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 5, "content": "기반으로 계산되며, 여기서, 는 클래스 p에 대하여 i번째 디폴트 박스(default box)와 j번째 참 경계 박스(ground truth box)가 매칭되는지에 대한 지표, c는 서로 다른 결절에 대한 신뢰도를 나타내고, 값이 1과 0일 수 있는 것을 특징으 로 할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 는,"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 6, "content": "를 기반으로 계산하고, 여기서, cx 및 cy는 분류해야 하는 class의 객체 중심 좌표, w, h는 이미지 너비와 높이, 는 클래스 p의 i 번째 디폴트 박스(default box)와 j번째 참 경계 박스(ground truth box)가 매칭되는지 여부를 나타내고, 는 smooth L1 손실함수를 의미하고, 여기서, 값과 관련하여, m이 각 cx, cy, w, h인 경우에 는 이미지 너비의 비율로 계산하고, 는 이미지 높이의 비율로 계산하며, 이미지 너비와 이미지 높이는 , 와 같이 로그 스케일을 적용하는 것을 특징으로 할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 상기 YOLOv3를 사용하는 경우의 손실 함수 는"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 7, "content": "을 기반으로 계산되고, 여기서, 는 예측 상자의 객체가 속한 범주를 결정하여 배경 영역을 구별하는데 도움이 되는 classification loss와 예측 바운딩 박스에 객체가 포함된 경우에만 적용되는 box regression loss 사이에 가중치를 조절해주는 매개변수이고, 는 상기 바운딩 박스에서 객체의 탐지 여부에 따라 달라지는 매개변수로 객체의 탐지여 부에 따라 1 또는 0을 대입하며, 객체가 탐지되는 경우 실제 데이터 와 예측 데이터 를 매개변수로 바운딩 박스의 위치와 크기를 나타내는 것을 특징으로 할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 방법 중 의 바운딩 박스 회귀손실 값 은"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 8, "content": "을 기반으로 계산하고, 여기서, IOU(Interest of Union)는 같은 클래스로 분류되는 복수의 객체가 겹치는 비율을 나타내고 , 는 예 측 상자의 객체가 속한 범주를 결정하여 배경 영역을 구별하는데 도움이 되는 classification loss와 예측 바운 딩 박스에 객체가 포함된 경우에만 적용되는 box regression loss 사이에 가중치를 조절해주는 매개변수이고, 와 는 i번째 그리드 셀(grid cell)에서의 컨피던스 값(confidence value)의 실제 데이터와 예측 데이터, 은 i번째 그리드 셀과 j번째 바운딩 박스(bounding box)에서 감지된 결절을 나타내는 매개변수인 것 을 특징으로 할 수 있다. 본 발명의 일 실시예에 의한 폐 결절 검출 장치는, 딥 러닝 아키텍처를 사용한 객체 검출 장치에 있어서, (A) 폐 CT 스캔 이미지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집하는 데이터 수집부; (B) 상기 폐 CT 스캔 이미지의 품질을 향상시키기 위한 데이터 전처리부; (C) 상기 폐 CT 스캔 이미지의 다양성을 향상시 키기 위해 데이터 수를 증가시키는 데이터 변조(augmentation)부; (D) 딥 러닝 모델의 검색 공간을 좁히기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나누는 이미지 분할부; (E) 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용하여 상기 딥 러닝 모델을 학습시키는 학습부; 및 (F) 학습된 딥러닝 모델에 임의의 폐 CT 스캔 이미지를 입력하여 폐 결절을 검출하고, 검출한 이미지를 세 가지로 분류하는 검출 및 분류부;를 포함할 수 있다."}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "의료 전문가가 폐 결절을 조기에 발견할 수 있도록 딥러닝 등의 시스템을 활용하여 컴퓨터 지원 탐지(CAD) 시스 템을 개발하고, CT 스캔에서 폐 결절을 분류 및 검출하기 위한 자동화된 딥러닝 기반 시스템을 도입할 수 있다. FPR(False Positive Rate)을 감소시키고, 분류 구조의 정확도 및 평균 탐지 정확도가 개선시킬 수 있다."}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적, 특정한 장점들 및 신규한 특징들은 첨부된 도면들과 연관되어지는 이하의 상세한 설명과 바람 직한 실시예들로부터 더욱 명백해질 것이다. 이때, 각각의 도면에서 동일한 구성요소는 가능한 동일한 부호로 나타낸다. 또한, 이미 공지된 기능 및/또는 구성에 대한 상세한 설명은 생략한다. 이하에 개시된 내용은, 다양한 실시 예에 따른 동작을 이해하는데 필요한 부분을 중점적으로 설명하며, 그 설명 의 요지를 흐릴 수 있는 요소들에 대한 설명은 생략한다. 또한 도면의 일부 구성요소는 과장되거나 생략되거나 또는 개략적으로 도시될 수 있다. 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니며, 따라서 각각의 도면에 그려진 구성요소들의 상대적인 크기나 간격에 의해 여기에 기재되는 내용들이 제한되는 것은 아 니다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시 예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 또한, 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어 들에 의해 한정되는 것은 아니며, 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 이하에서는, 첨부된 도면들을 참조하여, 본 발명의 일 실시예에 의한 딥 러닝 아키텍처를 사용한 객체 검출 방 법 및 장치에 대해 설명하기로 한다. 본 발명의 딥 러닝 아키텍처를 사용한 객체 검출 방법의 흐름도는 도 1에 나와 있다. 본 발명의 딥 러닝 아키텍처를 사용한 객체 검출 방법에는 다음과 같은 주요 단계가 있다. (A) 폐 CT 스캔 이미 지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집하는 데이터 수집 단계(단계 S102); (B) 상기 폐 CT 스캔 이미지의 품질을 향상시키기 위한 데이터 전처리 단계(단계 S106); (C) 상기 폐 CT 스캔 이미지의 다양성을 향상시키기 위해 데이터 수를 증가시키는 데이터 변조(augmentation) 단계(단계 S108); (D) 딥 러닝 모델의 검색 공간을 좁히기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나누는 이미지 분할 단계(단계 S110); (E) 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용하여 상기 딥 러닝 모델을 학습시키는 학습 단계(단계 S112); 및 (F) 학습된 딥러닝 모델에 임의의 폐 CT 스캔 이미지를 입력하여 폐 결절을 검출하고, 검 출한 이미지를 세 가지로 분류하는 검출 및 분류 단계(단계 S114);를 포함할 수 있다. 도 3은 본 발명의 일 실시 예에 따른 딥 러닝 아키텍처를 사용한 객체 검출 장치의 구성을 나타내는 도면이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 딥 러닝 아키텍처를 사용한 객체 검출 장치는 (A) 폐 CT 스 캔 이미지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집하는 데이터 수집부; (B) 상기 폐CT 스캔 이미지의 품질을 향상시키기 위한 데이터 전처리부; (C) 상기 폐 CT 스캔 이미지의 다양성을 향상 시키기 위해 데이터 수를 증가시키는 데이터 변조(augmentation)부; (D) 딥 러닝 모델의 검색 공간을 좁히 기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나누는 이미지 분할부; (E) 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용하여 상기 딥 러닝 모델을 학습시키는 학습부; 및 (F) 학습된 딥러닝 모 델에 임의의 폐 CT 스캔 이미지를 입력하여 폐 결절을 검출하고, 검출한 이미지를 세 가지로 분류하는 검출 및 분류부;를 포함할 수 있다. < 데이터 수집 단계 > 도 1을 참조하면, 단계 S102에서는, 데이터 수집부에서는 폐 CT 스캔 이미지의 데이터 세트로부터 결절의 위치와 특징에 대한 정보를 수집할 수 있다. 본 발명의 일 실시예에 의해, LIDC-IDRI 데이터베이스에서 수집한 데이터셋을 적용할 수 있다. 총 1018건의 폐 암 사례로 구성된 공개적으로 이용 가능한 LIDC-IDRI 데이터 세트를 활용할 수 있다. 도 1을 참조하면, 단계 S104에서는, CT 스캔 이미지와 각 결절의 위치 및 크기에 대한 정보를 XML 파일에서 읽 을 수 있다. 모든 사례에는 임상 흉부 CT 스캔과 숙련된 흉부 방사선 전문의 4명의 보고서가 포함된 XML 파일이 포함될 수 있다. 상기 XML 파일에는 결절에 관한 다양한 특징을 포함할 수 있다. 특히, 에지 맵은 결절 위치, 즉 결절 경계의 픽 셀 위치를 나타낼 수 있다. 이러한 결과는 이미지의 위상 차를 이용한 방법을 사용하여 얻을 수 있다. 일반적으로 맹검 판독 단계라고도 하는 첫 번째 단계는 다른 방사선 전문의가 개별적으로 모든 CT 스캔을 검사 할 수 있다. 병변은 세 가지 등급(비결절≥3mm, 결절≥3mm 및 결절<3mm) 중 하나로 분류될 수 있다. 비맹검 판독 단계라고 하는 두 번째 단계에서는 모든 방사선 전문의가 자신의 마크와 주석이 달린 다른 마크를 개별적으로 검사하여 최종 결론을 제공할 수 있다. 제한된 동의 없이 모든 CT 스캔에서 모든 폐 결절을 효과적 으로 인식하는 것을 목표로 할 수 있다. 상기 결절은 주석이 달린 결절로써 1에서 5까지 등급이 매겨져 각각 양성 및 악성의 극단을 나타낼 수 있다. 0 등급은 사용할 수 없는 분석을 나타내며 무시할 수 있다. 상기 결절은 최소 3명의 전문가가 진단한 폐 결절을 검사하고 진단된 결절에 대한 주석 클래스의 중앙값을 추정 하며 중앙값이 3 미만이면 양성, 3 초과이면 악성으로 사용할 수 있다. < 전처리 단계 > 도 1을 참조하면, 단계 S106에서는, 데이터 전처리부에서는 폐 CT 스캔 이미지의 품질을 향상시키기 위한 데이터를 전처리할 수 있다. 상기 데이터 세트에는 다양한 부적절한 이미지가 포함되어 있으므로 필터링 단계를 수행하고 결절 및 비결절 이 미지 샘플에 대한 데이터 세트의 균형을 맞추는 관련 없는 이미지를 제거할 수 있다. 좌표 변환 단계 본 발명의 일 실시예에 의해, 결절의 위치는 복셀 좌표로 변환할 수 있다. 상기 결절의 각 위치는 월드 좌표계(world coordinate system)에서 결정되지만, CT 스캔에서 결절을 찾고 식별 하기 위해 복셀 좌표를 사용할 수 있다. 또한, 월드 좌표를 입력으로 사용하고 모든 위치를 다음과 같이 데이터 세트와 함께 제공된 필수 복셀 좌표로 변환하는 함수가 적용될 수 있다.수학식 1"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, voxel이란 2D 이미지를 구성하는 최소 단위인 pixel(picture element)을 3D로 확장한 것을 나타내고, 하나의 voxel은 pixel spacing 만큼의 가로와 세로의 길이를 가지는 것을 의미할 수 있다. 데이터 스케일링 단계 본 발명의 일 실시예에 의해, 수집된 이미지는 평균 및 표준편차를 사용하여 다시 스케일링될 수 있다. 정규화 단계 본 발명의 일 실시예에 의해, CT 스캔 이미지에서 추출한 데이터는 다양한 조직과 기관을 식별하기 위해 여러 대역의 주파수로 다른 신체 부위를 표현하는 X선 빔으로부터 확보할 수 있다. 상기 CT 스캔 이미지 데이터는 물질의 밀도나 빈도가 클수록 커지며 HU 단위로 측정될 수 있다. 폐 CT 값의 범 위는 -600 HU 부터 -450 HU 까지일 수 있다. 혈액은 13 HU 부터 32 HU 까지의 범위 내, 체지방은 -20 HU 부터 -10 HU 까지의 범위 내에 있을 수 있다. 또한, 공기, 뼈 및 물을 포함하는 경우도 원시 CT 이미지로 간주될 수 있다. 예를 들어 사람 뼈의 CT 값은 약 1,000 HU이고 공기는 약 -1,000 HU이며 물은 약 0 HU이다. 한편, CT 스캔 HU 값의 범위는 0에서 3000까지이므로 딥 러닝 아키텍처에 대한 기울기가 소실되고 폭주하는 (gradient vanishing and exploding) 문제가 발생할 수 있다. 이는 본 발명의 아키텍처 시작 레이어에 도달할 때 가중치를 업데이트하기 위해 그래디언트가 적용될 때 발생할 수 있다. 결과적으로 초기 레이어의 가중치를 변경하지 않으므로 효율적으로 학습되지 않을 수 있다. 본 발명의 일 실시예에 의해, CT 스캔 이미지에서 추출한 데이터의 픽셀 값을 HU(Hounsfield 단위)로 변환하여 정규화될 수 있다. 수학식 2와 같이, 입력 값을 정규화하면 횟수를 결정하기가 더 쉬워지므로 어려움이 해결되고 학습 프로세스가 가속화될 수 있다. 먼저 최소 HUmin 500, 최대 HUmax를 1000으로 입력할 수 있다. 수학식 2"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, CT 스캔 HU(Houndsfield Units)값은 컴퓨터 단층촬영 이미지의 밀도 분석을 위한 흡수 계수로, 체내로 투입한 조영제에 대한 신체의 각 구성별 흡수율이 다른 것을 수치화 할 수 있다. 도 4a는 샘플 CT에 대한 HU의 CT 값 히스토그램 스캔 슬라이스를 나타낸다. 도 4a와 같이 ≤ 1, 000HU > 500HU의 값으로 선명한 이미지를 얻고 0-1 범위로 정규화하고, 불필요하거나 관련 없는 샘플 이미지를 임계값으로 필터링할 수 있다. 도 4b와 도 4c에 제시된 명확한 폐 결절이 있는 CT 스캔을 얻을 수 있다. 도 4b는 샘플 CT에 대한 2D 축 슬라이스를 나타낸다. 도 4c는 샘플 CT에 대한 폐 결절 이미지를 나타낸다. 그 후 선택된 슬라이스가 전처리되고, 개발된 시스템은 CT 스캔의 각 결절에 대한 정보가 포함된 xml 파일을 읽 을 수 있다. 앞서 논의한 바와 같이 0에서 4까지의 악성 종양 점수와 같은 많은 특성을 가지고 있을 수 있다. 가장자리 맵은 결절 위치를 픽셀 단위로 나타내며 일반적으로 결절의 경계 픽셀 정보를 나타낼 수 있다. 수학식 3에 기반하여, 결절의 무게 중심(Ncentriod)를 계산할 수 있다. 수학식 3"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 결절의 무게 중심을 나타내고, 각 n에 대한 위치 수에 따라 x, y 및 z의 모든 위치 i의 합으로 독립적으로 계산될 수 있다. < 데이터 변조 단계 > 도 1을 참조하면, 단계 S108에서는, 데이터 변조(augmentation)부에서는 폐 CT 스캔 이미지의 다양성을 향 상시키기 위해 데이터 수를 증가시킬 수 있다. 본 발명의 일 실시예에 의해, 전처리 후 데이터 증가를 수행하여 데이터 세트의 이질성과 시스템 성능을 높일 수 있다. 본 발명의 일 실시예에 의해, 미러링, 회전, 크기 조정, 색상 확대(대비, 밝기 및 감마 조정) 및 노이즈 확대를 포함하는 공간 데이터 확대와 같은 광범위한 데이터 확대를 수행할 수 있다. < 이미지 분할 단계 > 도 1을 참조하면, 단계 S110에서는, 이미지 분할부에서는 딥 러닝 모델의 검색 공간을 좁히기 위해 상기 폐 CT 스캔 이미지를 다양한 패치사이즈로 나눌 수 있다. 본 발명의 일 실시예에 의해, 딥 러닝 아키텍처의 경우 검색 공간이 크기 때문에 입력 CT 스캔을 자르고 512 × 512 × depth에서 64 × 64의 패치를 추출할 수 있다. 잘라낸 이미지 패치는 학습 및 테스트 샘플로 나눌 수 있 다. < 학습 단계 > 도 1을 참조하면, 단계 S112에서는, 학습부에서는 전처리한 상기 폐 CT 스캔 이미지의 데이터 세트를 활용 하여 상기 딥 러닝 모델을 학습시킬 수 있다. 상기 데이터 세트는 학습 및 테스트 세트에 대해 70%와 30%의 비율로 무작위로 분할될 수 있다. 도 1을 참조하면, 결절이 아닌 이미지(양성 및 악성)에서 폐 결절 이미지를 분류하기 위해 세 가지 분류 구조를 사용할 수 있다. 이러한 아키텍처는 이미지 특징 추출에도 적용될 수 있다. VGG-16 도 5에서는, VGG-16의 일반 아키텍처를 나타낸다. 본 발명의 일 실시예에 의해, VGG-16을 분류를 위한 기본 아키텍처로 사용할 수 있다. ImageNet 데이터 세트에 서 학습된 간단하고 일반적으로 사용되는 컨볼루션 신경망으로, 이 아키텍처는 1억 3,800만 개의 매개변수가 있 는 16개의 레이어로 매우 깊을 수 있다. 본 발명의 일 실시예에 의해, 학습하는 동안 고정 크기 224 × 224 이미지를 사용할 수 있고, 모든 픽셀에서 트 레이닝 데이터 세트에 대해 추정된 평균값을 뺄 수 있다. 입력 이미지는 3×3 필터가 있는 컨벌루션 레이어 블록에 제공될 수 있다. 입력 채널의 선형 변환으로도 정의되는 하나의 구성인 1 × 1 컨볼루션 필터를 제외하고 몇 가지 매개변수를 사 용하여 더 많은 비선형성을 가질 수 있다. 컨볼루션 레이어의 입력은 스트라이드(stride)이고, 공간 패딩은 3×3 컨볼루션 레이어에 대해 1픽셀로 만들어 질 수 있다. 컨볼루션 레이어 이후에 공간 연출이 저장되도록 할 수 있다. 컨벌루션 레이어를 지원하고 공간 풀링에 도움이 되는 5개의 최대 풀링 레이어를 둘 수 있다. 최대 풀링은 2 × 2 픽셀 창에서 스트라이드(stride) 2로 수행될 수 있다. 3개의 완전 연결 레이어가 컨볼루션 레이어 덩어리를 지원할 수 있다. 도 5를 참조하면, 각각의 레이어는 서로 다른 깊이를 가질 수 있다. 가장 마지막 레이어는 softmax 레이어일 수 있다. 레즈넷-50 도 6에서는, Resnet50의 일반 네트워크 아키텍처를 나타낸다. 본 발명의 일 실시예에 의해, 분류 목적으로 사용되는 두 번째 컨볼루션 신경망 아키텍처는 Resnet-50일 수 있 다. 2,600만 개의 매개변수가 있는 50개의 심층 레이어가 있을 수 있다. 아키텍처는 잔차에서 특징을 학습하고, 스킵 커넥션(skip connection)을 사용하여 컨볼루션 레이어를 통해 데이 터를 제공할 수 있다. Resnet은 n번째 레이어의 입력을 (n+x)번째 레이어에 결합하여 추가 레이어를 축적하고 광범위한 신경망을 구축 할 수 있다. 네트워크에는 48개의 컨볼루션 레이어, 하나의 최대 풀링 레이어 및 하나의 평균 풀링 레이어가 있 을 수 있다. 컨볼루션 레이어의 커널 크기는 7×7이며, 64개의 서로 다른 커널과 스트라이드 크기가 2인 최대 풀링이 있을 수 있다. 후속 컨볼루션 블록에는 1×1,256 커널로 지원되는 3×3,64 커널이 있을 수 있다. 또한, 레이어를 총 3번 반복하여 최종적으로 9개의 레이어를 제공할 수 있다 모바일 넷 도 7은 모바일넷(MobileNet)의 일반 아키텍처를 나타낸다. 본 발명의 일 실시예에 의해, 2개의 글로벌 하이퍼 파라미터, 해상도 및 너비 승수(width multiplier)가 있어 조건에 따라 효율성 또는 대기 시간 사이의 절충이 가능할 수 있다. 기본적으로 더 작은 패턴을 생성하기 위해 이전 네트워크에 적용되었던 기존 레이어가 아닌 깊이별 레이어라는 분리 가능한 컨볼루션을 적용할 수 있다. 모든 깊이별 분리 가능 컨볼루션 레이어는 포인트별 및 깊이별 컨볼루션 레이어로 구성될 수 있다. 이러한 컨볼 루션을 별도의 레이어로 평가하면 총 28개의 레이어가 있을 수 있다. 일반 아키텍처는 하이퍼파라미터(예: width multiplier)를 조정하여 수정할 수 있는 420만 개의 파라미터로 구 성될 수 있다. 본 발명의 일 실시예에 의해, 결절 위치 파악 및 양성 및 악성 식별을 위해 Faster R-CNN, SSD 및 YOLOv3를 실 행할 수 있다. Faster-RCNN 도 2를 참고하면, 검출 목적으로 Faster R-CNN을 실행할 수 있다. 도 8은 결절 감지를 위해 학습되고 테스트된 Faster-RCNN의 일반 네트워크 아키텍처를 나타낸다. 본 발명의 일 실시예에 의해, 첫 번째 단계는 RPN(Region Proposal Network)을 사용하여 결절 병변에 대한 영역 앵커(anchor)를 생성하고, 두 번째 단계는 검출된 앵커 영역 정보를 적용하는 분류(예: 양성 및 악성)를 수행할 수 있다. 검출기 모델의 출력은 신뢰도 점수 및 클래스 레이블 값과 함께 좌표, 높이 및 너비 정보를 포함하는 직사각형 검출 경계 상자일 수 있다. 도 8을 참고하면, 제시된 전체 방법은 원칙적으로 세 단계로 구성될 수 있다. 입력 이미지의 특징은 컨볼루션 레이어를 통해 추출되고 추가로 특징 맵 생성에 활용될 수 있다. 본 발명의 일 실시예에 의해, 슬라이딩 윈도우(sliding window) 접근법은 고정 병변 또는 영역 경계 상자를 생 성하는 데 사용되며 결절을 지정하기 위해 추가로 세분화될 수 있다. 또한, 감지된 앵커를 세분화하기 위해 좁은 네트워크(small network)가 적용되고 가장 원하는 앵커 병변을 결정 하는 손실 함수가 다음과 같이 추정될 수 있다. 수학식 4에 기반하여, 손실함수가 계산될 수 있다. 수학식 4"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 classification loss와 regression loss 사이에 가중치를 조절해주는 매개변수, i는 하나의 앵커, pi는 분류를 통해서 얻은 앵커가 객체일 확률, ti는 바운딩 박스 회귀(regression)를 통해서 얻은 박스 조정 값 벡터, pi*와 ti*은 바운딩 박스의 실제 좌표를 나타내기 위한 ground truth 라벨을 의미할 수 있다. 관심 영역(ROI)은 학습된 RPN을 사용하여 컨볼루션 기능 맵을 통해 얻을 수 있다. ROI 풀 레이어를 사용하여 특 징 맵이 추출되면, 분류 및 회귀 함수를 모두 포함하는 손실 함수가 결정될 수 있다. SSD 도 9에서는, 결절 감지를 위해 학습되고 테스트된 SSD의 일반 아키텍처를 나타낸다. 본 발명의 일 실시예에 의해, 여기에는 1 × 1 스트라이드(stride)의 점별 컨볼루션 레이어가 지원하는 3 × 3 깊이별 컨볼루션 레이어가 포함될 수 있다. 검출기 모델은 결절 특징을 추출한 다음 컨볼루션 필터를 적용하여 특정 결절을 식별하고 찾을 수 있다. 현재 분류 및 지역화 회귀에 다른 기능 맵이 적용될 수 있다. 도 9를 참고하면, 기본 상자 모음은 기능 맵의 모든 블록에 대해 정의될 수 있다. 모든 기능 맵에 대해 네 가지 크기의 예상 경계 상자를 제공할 수 있다. 특징 맵에서 감지된 모든 위치에 대해 다양한 종횡비와 크기를 가진 k 경계 상자의 수를 얻을 수 있다. 수학식 5에 기반하여 손실 함수를 결정할 수 있다. 수학식 5"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, x는 매칭 지표, c는 다양한 클래스의 신뢰도, l은 예측상자(predicted box)의 매개변수, g는 실측 상자 (ground truth box)의 매개변수, N은 매칭된 디폴트 박스(default box)의 수, 는 손실 함수에 대해 안정화 가중치, 는 신뢰도에 대한 손실(confidence loss), 은 예측된 경계 상자 위치 및 크기의 오류로 인한 손실(localization loss)을 나타낼 수 있다. 수학식 6에 기반하여 를 계산할 수 있다. 수학식 6"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, 는 클래스 p에 대하여 i번째 디폴트 박스(default box)와 j번째 참 경계 박스(ground truth box)가 매칭되는지에 대한 지표, c는 서로 다른 결절에 대한 신뢰도를 나타내고, 값이 1과 0일 수 있는 것을 특징으 로 할 수 있다. 수학식 7에 기반하여 를 계산할 수 있다. 수학식 7"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 는 클래스 p에 대하여 i번째 디폴트 박스(default box)와 j번째 참 경계 박스(ground truth box)가 매칭되는지에 대한 지표, c는 서로 다른 결절에 대한 신뢰도를 나타내고, 값이 1과 0일 수 있다. 수학식 8에 기반하여, 를 계산할 수 있다. 수학식 8"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "를 기반으로 계산하고, 여기서, cx 및 cy는 분류해야 하는 class의 객체 중심 좌표, w, h는 이미지 너비와 높이, 는 클래스 p의 i 번째 디폴트 박스(default box)와 j번째 참 경계 박스(ground truth box)가 매칭되는지 여부를 나타내고, 는 smooth L1 손실함수를 의미하고, 여기서, 값과 관련하여, m이 각 cx, cy, w, h인 경우에 는 이미지 너비의 비율로 계산하고, 는 이미지 높이의 비율로 계산하며, 이미지 너비와 이미지 높이는 , 와 같이 로그 스케일을 적용하는 것을 특징으로 할 수 있다. YOLOv3 도 10에서는, 결절 감지를 위해 학습되고 테스트된 YOLOv3의 일반 네트워크 아키텍처를 나타낸다. 도 10을 참조하면, 폐 결절 데이터 세트를 사용하여 학습될 수 있다. SSD로서 YOLOv3는 또한 전체 입력 CT 스캔에 대해 동일한 경계 상자와 결절 클래스의 확률을 예측하는 1단계 아 키텍처일 수 있다. 컨볼루션 레이어는 입력 이미지의 특성을 추출하는 데 사용되며, FC(Fully Connected layer)는 클래스 확률 및 예측을 식별하는 데 사용될 수 있다. 일반 아키텍처는 그리드 셀(grid cell)로 정의되는 영역으로 분할될 수 있다. 결절 감지를 위해 클래스의 확률 및 경계 상자의 예측과 관련이 있다. 이미지에서 감지된 결절의 중심은 이러한 그리드 셀에 의해 예측된 대로 셀 내부에 있거나 그렇지 않을 수 있다. 폐 결절 검출을 위해 관련 영역 또는 병변이 결정될 수 있다. 신뢰 값 은 감지된 경계 상자(bounding box)를 얻는 데 사용될 수 있다. 식별된 폐 결절 경계 상자에 대해 회귀 및 분류를 포함한 두 가지 기능을 결합한 손실 함수가 정의될 수 있다. 수학식 9에 기반하여 손실함수 가 계산될 수 있다. 수학식 9"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "을 기반으로 계산되고, 여기서, 는 예측 상자의 객체가 속한 범주를 결정하여 배경 영역을 구별하는데 도움이 되는 classification loss와 예측 바운딩 박스에 객체가 포함된 경우에만 적용되는 box regression loss 사이에 가중치를 조절해주는 매개변수이고, 는 상기 바운딩 박스에서 객체의 탐지 여부에 따라 달라지는 매개변수로 객체의 탐지여 부에 따라 1 또는 0을 대입하며, 객체가 탐지되는 경우 실제 데이터 와 예측 데이터 를 매개변수로 바운딩 박스의 위치와 크기를 나타내는 것을 특징으로 할 수 있다. 수학식 10에서는 의 바운딩 박스 회귀손실 값 를 계산할 수 있다. 수학식 10"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "여기서, IOU(Interest of Union)는 같은 클래스로 분류되는 복수의 객체가 겹치는 비율을 나타내고 , 는 예 측 상자의 객체가 속한 범주를 결정하여 배경 영역을 구별하는데 도움이 되는 classification loss와 예측 바운 딩 박스에 객체가 포함된 경우에만 적용되는 box regression loss 사이에 가중치를 조절해주는 매개변수이고, 와 는 i번째 그리드 셀(grid cell)에서의 컨피던스 값(confidence value)의 실제 데이터와 예측 데이터, 은 i번째 그리드 셀과 j번째 바운딩 박스(bounding box)에서 감지된 결절을 나타내는 매개변수인 것 을 특징으로 할 수 있다. 테스트 수행 본 발명의 일 실시예에 의해, NVIDIA DIGITS(Deep Learning GPU Training System)를 사용하고, 네트워크를 정 의하고, 데이터 증강을 구현하고, NVIDIA GeForce GTX 1080 GPU가 장착된 Intel i5 시스템을 활용하여 학습 및 테스트를 수행할 수 있다. 모든 아키텍처의 학습 시간은 약 6시간일 수 있다. 도 11 및 도 12에서는 아키텍처의 학습 및 테스트 관찰 결과를 나타낸다. 학습은 100 epoch 동안 수행될 수 있다. 도 11에서는, 학습 및 테스트 중 10번째 에포크에서 손실이 감소하고 있음을 알 수 있고, Faster-RCNN의 학습 및 테스트 손실은 각각 0.6% 및 0.5%, SSD는 0.45% 및 0.4%, YOLO는 각각 0.45% 및 0.3%임을 확인할 수 있다. 도 11에서는, 초기 20번째 에포크 이후 학습 및 테스트 정확도가 향상되었음을 알 수 있고, Faster-RCNN의 학습 및 테스트 정확도는 각각 0.86 및 0.84, SSD는 0.87 및 0.9, YOLOv3는 각각 0.92 및 0.94임을 확인할 수 있다. < 검출 및 분류 단계 > 도 1을 참조하면, 단계 S114에서는, 검출 및 분류부에서는 학습된 딥러닝 모델에 임의의 폐 CT 스캔 이미 지를 입력하여 폐 결절을 검출하고, 검출한 이미지를 세 가지로 분류할 수 있다. 도 1을 참고하면, 분류 작업 이후 CT 스캔 이미지에서 폐 결절의 검출 및 위치 파악을 위해 딥 러닝 아키텍처를 사용할 수 있다. 도 13 및 도 14에서는 딥러닝 기반 자동화 시스템의 분류 및 탐지 결과를 확인할 수 있다. 도 13에서는, 양성 폐 결절의 분류 결과를 확인할 수 있다. 결절 크기가 다른 다양한 CT 스캔 이미지를 정확하 게 분류함을 알 수 있다. 도 13에서는, 검출 결과를 확인할 수 있다. 첫 번째 열에는 원본 테스트 이미지가 표시되고 두 번째 열에는 Faster-RCNN의 결과가 표시될 수 있다. CT 영상에서 다양한 크기의 양성결절을 감지하여 모델이 좋은 결과를 내 는 것을 볼 수 있다. 마찬가지로 다음 두 열에는 SSD 및 YOLOv3 감지기의 결과가 표시될 수 있다. Faster- RCNN과 비교하여 다양한 크기의 양성 폐 결절에 대해 보다 정밀한 bounding box를 검출하여 좋은 결과를 내는 것을 알 수 있다. 도 14에서는, 악성 폐 CT 스캔과 폐 결절의 분류 및 검출 결과를 확인할 수 있다. 도 13에서는, 양성에서 악성 폐 CT 스캔을 분류하여 딥 러닝 아키텍처가 우수한 결과를 제공한다는 결과에서 알 수 있다. 하지만 결절 특징이 대부분 악성 결절과 유사하기 때문에 어렵지만, 딥러닝 아키텍처가 자동으로 더 강력한 특징을 선택하고 악성 결절과 양성 결절의 CT 스캔을 분류할 수 있다. CT 스캔의 결절도 노란색 경계 상자에 있을 수 있다. 또한 Faster-RCNN에 비해 YOLOv3와 SSD의 성능이 더 우수함을 결과에서 확인할 수 있다. 성능 평가 True Positive(T P), True Negative(T N), False Positive(F P) 및 False Negative(F N)와 같은 다양한 매개 변수를 사용하여 평가될 수 있다. Precision, Recall, Accuracy, TPR(True Positive Rate) 및 FPR(False Positive Rate)은 이러한 매개변수를 사 용하여 계산될 수 있다. 표준 편차와 평균은 평균 Precision, Recall 및 Accuracy를 결정하는 데 사용될 수 있다. 도 15에서는, 다양한 딥 러닝 기반 아키텍처의 분류 정확도를 나타낸다. Non-Nodule, Benign 및 Malignant CT 스캔 이미지에 대해 딥 러닝 아키텍처가 좋은 결과를 제공하는 것을 볼 수 있다. VGG-16의 분류 정확도는 0.93, 0.92 및 0.93이고 Resnet50은 0.94, 0.94 및 0.95인 반면 Mobilenet은 비결절, 양성 및 악성 이미지에 대해 각각 0.95, 0.95 및 0.95이다. 도 16에서는, 다양한 매개변수를 사용하여 검출기 모델의 성능을 확인할 수 있다. 모든 모델이 양성 및 악성 폐 결절 모두에 대해 좋은 결과를 제공한다는 것을 알 수 있다. 세 가지 다른 아키텍처에 대한 TPR, 정확도, 정밀 도 및 재현율이 그림에 나와 있다. Faster-RCNN의 TPR, Accuracy, Precision 및 Recall 값은 0.91, 0.93, 0.89, 0.70이고 SSD는 0.92, 0.94, 0.9 및 0.75를 달성한 반면 YOLOv3는 각각 0.93, 0.94, 0.91 및 0.89를 생성했다. 표 1"}
{"patent_id": "10-2023-0092577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "표 1에서는 분류 및 기본 아키텍처가 다른 탐지 모델의 전체 성능 결과를 볼 수 있다. Faster-RCNN(VGG-16)의 정확도는 0.90, Faster-RCNN(Resnet50)은 0.91, Faster-RCNN(Mobilenet)은 0.91, SSD(VGG 16)는 0.92, SSD(Resnet50)는 0.925, SSD(Mobilenet)는 0.94임을 확인할 수 있다. 정확도는 다른 모델, 즉 YOLOv3(VGG-16) 0.93, YOLOv3(Resnet50) 0.935, YOLOv3(Mobilenet) 0.94에 비해 더 정 확할 수 있다. 다양한 딥 러닝 모델에 대해 0.2에서 0.06 사이의 필터링 단계로 인해 FPR도 감소할 수 있다. Faster-RCNN의 TPR 값은 VGG 16, Resnet 및 Mobilenet에서 0.91, 0.92 및 0.92일 수 있다. SSD 및 YOLOv3 모델은 VGG-16, Resnet 및 Mobilenet에서 각각 0.92, 0.93, 0.93 및 0.93, 0.935 및 0.94의 TPR 을 달성할 수 있다. 본 발명에서는 딥러닝 기반 시스템을 활용하여 폐암 또는 폐암의 원인을 분석하기 위해 CT 스캔에서 양성 및 악 성의 분류 및 검출을 수행할 수 있다. 개발된 시스템은 VGG-16, Resnet 101 및 Mobilenetv3와 같은 폐 결절 분류를 위한 다양한 기본 아키텍처를 조사 할 수 있다. 또한 탐지 목적으로 Faster-RCNN, YOLOv3 및 SSD를 포함한 새로운 딥 러닝 탐지기를 사용할 수 있다. 학습은 공개적으로 사용 가능한 벤치마크 LIDC-IDRI 데이터 세트를 사용하여 수행될 수 있다. 시스템의 성능을 향상시키기 위해 필요한 전처리가 수행되고 데이터 세트에서 불필요한 샘플/이미지를 제거하기 위한 필터링 단 계가 도입될 수 있다. 그 결과 모든 딥러닝 모델이 우수한 분류 및 탐지 정확도를 달성했다. 테스트 결과 FPR이 감소하고 정확도가 향 상되는 것으로 나타났고, 분류 구조의 평균 정확도는 0.92~0.95이며, 평균 탐지 정확도는 0.93~0.94이다."}
{"patent_id": "10-2023-0092577", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 의한 딥 러닝 아키텍처를 사용한 객체 검출 방법 흐름도 도 2는 생의학 응용과 관련된 생의학 연구의 관심 분야 변화도 도 3은 본 발명의 일 실시예에 의한 딥 러닝 아키텍처를 사용한 객체 검출 장치 도 4a는 샘플 CT에 대한 HU의 CT 값 히스토그램 스캔 슬라이스 도 4b는 샘플 CT에 대한 2D 축 슬라이스 도 4c는 샘플 CT에 대한 폐 결절 이미지 도 5는 VGG-16의 일반 아키텍처 도 6은 Resnet50의 일반 네트워크 아키텍처 도 7은 모바일넷의 일반 아키텍처 도 8은 결절 감지를 위해 학습되고 테스트된 Faster-RCNN의 일반 네트워크 아키텍처도 9는 결절 감지를 위해 학습되고 테스트된 SSD의 일반 아키텍처 도 10은 결절 감지를 위해 학습되고 테스트된 YOLOv3의 일반 네트워크 아키텍처 도 11은 LIDC-IDRI 데이터 셋에서 학습되고 테스트된 탐지 아키텍쳐의 학습횟수 별 손실 도 12는 LIDC-IDRI 데이터 셋에서 학습되고 테스트된 탐지 아키텍쳐의 학습횟수 별 정확도 도 13은 양성 폐 결절에 대하여 딥 러닝 아키텍쳐의 분류 및 탐지 결과 도 14는 악성 폐 결절에 대하여 딥 러닝 아키텍쳐의 분류 및 탐지 결과 도 15는 LIDC-IDRI 데이터 셋에서 학습되고 테스트된 탐지 아키텍쳐의 분류 정확도 도 16은 딥 러닝 기반 검출기의 평균 TPR, 정확도, 정밀도 및 재현율"}
