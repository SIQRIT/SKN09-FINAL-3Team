{"patent_id": "10-2023-0094984", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0014628", "출원번호": "10-2023-0094984", "발명의 명칭": "인공지능을 기반으로 한 오브젝트 배치 장치 및 방법", "출원인": "클라바타", "발명자": "정지한"}}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "오브젝트 배치 장치로서,제1 이미지가 저장된 메모리; 및상기 오브젝트의 배치와 관련된 동작을 제어하는 프로세서를 포함하고,상기 프로세서는,상기 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 상기 제2 이미지로부터 오브젝트를 추출하고,상기 제2 이미지에 포함되는 오브젝트의 클래스를 분류하고,상기 오브젝트의 클래스를 분류한 결과 및 상기 제2 이미지에 포함되는 오브젝트의 개수를 기반으로 하여, 상기오브젝트를 대상 공간에 배치하고,상기 제2 이미지로부터 상기 오브젝트의 종류 및 색상 정보를 추출하고, 상기 오브젝트의 종류 및 색상 정보에대응하는 콜라주 이미지를 생성하고,상기 콜라주 이미지를 상기 오브젝트가 배치된 상기 대상 공간의 배경 이미지로 결정하는,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프로세서는,상기 오브젝트를 추출 시에, 상기 제1 이미지 내의 복수의 구성을 영역 별로 분류하고, 상기 제1 이미지로부터 선택된 하나 이상의 영역 이외의 다른 영역을 배경으로 판단하고,상기 배경으로 판단된 영역에 배경 제거 알고리즘을 적용하여 상기 배경으로 판단된 영역이 제거된 제2 이미지를 생성하고,상기 제2 이미지에 포함되는 상기 하나 이상의 선택된 영역을 오브젝트로 결정하는,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 프로세서는,상기 오브젝트의 클래스를 분류시에, 이미지를 입력으로 하여 이미지의 클래스를 분류하도록 미리 훈련된 제1심층신경망 모델을 이용하여 상기 제2 이미지의 클래스를 분류하고,상기 제1 심층신경망 모델은,이미지를 입력으로 하고, 상기 이미지의 클래스를 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된모델인,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,공개특허 10-2025-0014628-3-상기 프로세서는,상기 오브젝트를 대상 공간에 배치 시에, 상기 오브젝트의 클래스 분류 결과를 로딩하고,기설정된 클래스별 배치 규칙을 로딩하고,상기 오브젝트의 클래스 분류 결과에 상기 배치 규칙을 적용하여 상기 오브젝트를 대상 공간에 배치하는,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 프로세서는,상기 오브젝트를 대상 공간에 배치 시에, 어느 한 클래스 분류 결과에 대응하는 복수개의 오브젝트가 존재함에따라, 상기 복수개의 오브젝트에 배치 우선 순위 알고리즘을 적용하여, 상기 복수개의 오브젝트에 대한 우선 순위를 결정하고,상기 우선 순위를 결정한 결과 중 최 우선 순위로 결정된 어느 한 오브젝트에 상기 배치 규칙을 적용하여 대상공간에 배치하는,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 프로세서는,상기 우선 순위를 결정 시에, 사용자의 상품 구매 정보를 이용하여 사용자의 선호도를 예측하도록 훈련된 제2심층신경망 모델을 이용하여 상기 복수개의 오브젝트에 대응하는 사용자의 선호도를 예측하고,상기 선호도를 예측한 결과를 내림차순으로 정렬하여 상기 복수개의 오브젝트에 대한 우선 순위를 결정하고,상기 제2 심층신경망 모델은,사용자의 성별, 나이, 지역, 관심사, 이전 구매 기록 중 하나 이상을 포함하는 사용자 프로파일 정보와, 사용자가 선택한 상품 이미지의 카테고리, 스타일, 색상, 크기 및 브랜드 중 하나 이상을 포함하는 이미지 정보와, 사용자의 웹 페이지 방문 기록, 상품 검색 기록, 장바구니에 담은 상품 및 구매 내역 중 하나 이상을 포함하는 사용자 행동 패턴을 포함하는 사용자의 상품 구매 정보를 입력으로 하고, 선호도 점수를 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델인,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항에 있어서,상기 프로세서는,상기 최 우선 순위로 결정된 어느 한 오브젝트에 상기 배치 규칙을 적용하여 대상 공간에 배치하기 전에, 사용자로부터 배치 불허 신호가 수신됨에 따라, 상기 우선 순위를 결정한 결과 중 차선 순위로 결정된 다른 한 오브젝트를 대상 공간에 배치하는,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 프로세서는,상기 콜라주 이미지를 생성 시에, 상기 제2 이미지로부터 상기 오브젝트가 포함된 영역을 추출하고,공개특허 10-2025-0014628-4-상기 영역에 포함되는 오브젝트의 종류 및 색상 정보를 추출하고,상기 오브젝트의 종류 및 색상 정보를 입력으로 하여 배경 이미지를 생성하도록 미리 훈련된 제3 심층신경망 모델을 이용하여 상기 영역에 포함되는 오브젝트의 종류 및 색상 정보에 대응하는 배경 이미지를 생성하고,상기 배경 이미지를 상기 콜라주 이미지로 결정하고,상기 제3 심층신경망 모델은,오브젝트의 종류 및 색상 정보를 입력으로 하고, 배경 이미지를 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델인,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 프로세서는,상기 오브젝트의 종류 및 색상 정보를 추출 시에, 이미지를 입력으로 하여 상기 이미지에 포함되는 오브젝트의종류 및 색상을 예측하도록 미리 훈련된 제4 심층신경망 모델을 이용하여 상기 제2 이미지에 포함되는 오브젝트의 종류 및 색상 정보를 예측하고,상기 제4 심층신경망 모델은,이미지를 입력으로 하고, 상기 이미지에 포함된 오브젝트의 종류 및 색상을 레이블로 하는 훈련데이터에 의해지도학습 방식으로 훈련된 모델인,오브젝트 배치 장치."}
{"patent_id": "10-2023-0094984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "오브젝트 배치 장치의 프로세서에 의해 수행되는 오브젝트 배치 방법으로서,제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 상기 제2 이미지로부터 오브젝트를 추출하는 단계;상기 제2 이미지에 포함되는 오브젝트의 클래스를 분류하는 단계;상기 오브젝트의 클래스를 분류한 결과 및 상기 제2 이미지에 포함되는 오브젝트의 개수를 기반으로 하여, 상기오브젝트를 대상 공간에 배치하는 단계;상기 제2 이미지로부터 상기 오브젝트의 종류 및 색상 정보를 추출하고, 상기 오브젝트의 종류 및 색상 정보에대응하는 콜라주 이미지를 생성하는 단계; 및상기 콜라주 이미지를 상기 오브젝트가 배치된 상기 대상 공간의 배경 이미지로 결정하는 단계를 포함하는,오브젝트 배치 방법."}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 인공지능을 기반으로 하여 2D 및 3D 공간 내에 상품과 관련한 오브젝트를 자동으로 배치하는 장치 및 방법에 관한 것이다. 본 개시의 일 실시 예에 따른 인공지능을 기반으로 한 오브젝트 배치 장치는 제1 이미지가 저장된 메모리 및 오 (뒷면에 계속)"}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능을 기반으로 하여 2D 및 3D 공간 내에 상품과 관련한 오브젝트를 자동으로 배치하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 이미지 작업 기술은 이미지 인식, 검색, 생성, 편집 등의 과정을 포함하고 있으며, 이미지 작업은 컴퓨 터 프로그램 및 웹기반 온라인 툴들을 통해 간소화되고 발전되어 왔다. 하지만 이러한 기술은 이미지 작업의 자동화 측면에서는 아직 한계가 있다. 국내 공개특허공보 제10-2014-0067252호(2014.06.05)에는 복수의 아이템을 공간 내에 자동으로 배치하는 방법을 소개하고 있다. 그러나 이는 이미지의 크기와 비율을 고려하여 단순히 콜라주 이미지를 생성하는 것에 그치고있다. 쇼핑 분야에서는 다양한 상품을 한눈에 보여주기 위해 여러 상품 오브젝트를 조화롭게 배치하는 것이 필 요하며, 3D 공간에서의 상품 정보 제공에 대한 기술도 부족한 상황이다."}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 개시의 도출을 위해 보유하고 있었거나, 본 개시의 도출 과정에서 습득한 기술 정보로서, 반드시 본 개시의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허공보 제10-2014-0067252호(2014.06.05)"}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 과제는, 인공지능 알고리즘을 활용하여 이미지 내 상품을 제거한 배경 제거, 배경 제거된 상품들 의 조합 배치 및 이에 적합한 배경을 생성하는데 있다. 본 개시가 해결하고자 하는 과제는 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 개시의 다른 과 제 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시 예에 의해보다 분명하게 이해될 것이다. 또한, 본 개시가 해결하고자 하는 과제 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 인공지능을 기반으로 한 오브젝트 배치 장치는 제1 이미지가 저장된 메모리 및 오 브젝트의 배치와 관련된 동작을 제어하는 프로세서를 포함하고, 프로세서는, 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 제2 이미지로부터 오브젝트를 추출하고, 제2 이미지에 포함되는 오브젝트의 클래스를 분류하고, 오브젝트의 클래스를 분류한 결과 및 제2 이미지에 포함되는 오브젝트의 개수를 기반으로 하여, 오브 젝트를 대상 공간에 배치하고, 제2 이미지로부터 오브젝트의 종류 및 색상 정보를 추출하고, 오브젝트의 종류 및 색상 정보에 대응하는 콜라주 이미지를 생성하고, 콜라주 이미지를 오브젝트가 배치된 대상 공간의 배경 이 미지로 결정할 수 있다. 본 개시의 일 실시 예에 따른 인공지능을 기반으로 한 오브젝트 배치 방법은 오브젝트 배치 장치의 프로세서에 의해 수행되는 오브젝트 배치 방법으로서, 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 제2 이미지 로부터 오브젝트를 추출하는 단계와, 제2 이미지에 포함되는 오브젝트의 클래스를 분류하는 단계와, 오브젝트의 클래스를 분류한 결과 및 제2 이미지에 포함되는 오브젝트의 개수를 기반으로 하여, 오브젝트를 대상 공간에 배 치하는 단계와, 제2 이미지로부터 오브젝트의 종류 및 색상 정보를 추출하고, 오브젝트의 종류 및 색상 정보에 대응하는 콜라주 이미지를 생성하는 단계와, 콜라주 이미지를 오브젝트가 배치된 대상 공간의 배경 이미지로 결 정하는 단계를 포함할 수 있다. 이 외에도, 본 개시를 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 의하면, 디자이너에 의해 수작업으로 진행되던 상품 기반의 콜라주 이미지 생성 작업을 자동화하여 프로세스 자동화 및 인력비 절감에 따른 비용 감소 효과를 창출할 수 있다. 또한, 디자이너의 작업을 대폭 축소하여 시간과 비용을 절감할 수 있고, 비전문가도 높은 품질의 콜라주 이미지 를 생성할 수 있다. 또한, 쇼핑 분야에서 여러 상품 오브젝트를 조화롭게 배치하여 시각적으로 효과적인 쇼핑 콘텐츠를 만들 수 있 다. 또한, 3D 공간에서 상품 정보를 적절히 배치하여 고객들에게 효과적으로 전달할 수 있다. 본 개시의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 개시는 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 개시의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 개시의 개시가 완전하도록 하며, 본 개"}
{"patent_id": "10-2023-0094984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시가 속하는 기술분야에서 통상의 지식을 가진 자에게 개시의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 개시를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포 함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 상기 용어들에 의해 한정되 어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 또한, 본 출원서에서, \"부\"는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로세 서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 이하, 본 개시에 따른 실시 예들을 첨부된 도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설 명함에 있어, 동일하거나 대응하는 구성 요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하 기로 한다. 이하의 실시 예에서, 제1, 제2 등의 용어는 한정적인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별 하는 목적으로 사용되었다 이하의 실시 예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시 예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징을 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 어떤 실시 예가 달리 구현 가능한 경우에 특정한 공정 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 공정이 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순서로 진행 될 수 있다. 도 1은 본 개시에 따른 인공지능을 기반으로 한 오브젝트 배치 환경의 예시도이다. 도 1을 참조하면, 인공지능 을 기반으로 한 오브젝트 배치 환경은 오브젝트 배치 장치, 사용자 단말기 및 네트워크를 포 함할 수 있다. 오브젝트 배치 장치는 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 제2 이미지로부터 오브젝 트를 추출할 수 있다. 여기서 제1 이미지는 하나 이상의 오브젝트 및 배경을 포함할 수 있다. 또한 임의의 이 미지에서 오브젝트는 구체적으로 인식 가능한 물체, 물건 또는 개체를 의미할 수 있다. 일반적으로 오브젝트는 이미지에서 주요한 시각적인 요소로 간주되며 배경과 구분될 수 있다. 본 개시에서 제1 이미지는 상품이 포함되는 이미지이고, 오브젝트는 제품, 상품 또는 상품의 일부로 표현될 수 있다. 오브젝트는 제1 이미지 내에서 다양한 형태와 특성을 가질 수 있다. 예를 들어, 의류 상점과 관련된 이 미지로서의 제1 이미지에서, 오브젝트는 옷, 신발, 가방 등 패션 아이템이 될 수 있다. 식품점과 관련된 이미 지로서의 제1 이미지에서, 오브젝트는 음식, 음료, 식재료 등의 아이템이 될 수 있다. 이와 같이 이미지 내에 서 오브젝트를 정의하는 것은 해당 이미지의 컨텍스트와 주제에 따라 달라질 수 있다. 오브젝트 배치 장치는 하나 이상의 오브젝트와 배경이 포함된 제1 이미지로부터 배경을 제거한 제2 이미지 를 생성하고, 제2 이미지로부터 오브젝트를 추출하기 위해, 인공지능 기반의 오픈소스 알고리즘으로서의 Segment Anything을 적용할 수 있다. Segment Anything은 이미지 인코딩, 프롬프트 인코딩, 마스크 디코딩을 통해 상품 오브젝트를 선택하고 배경을 제거하는 기술로서, 상세한 내용은 후술하기로 한다. 오브젝트 배치 장치는 제2 이미지에 포함되는 오브젝트의 클래스를 분류할 수 있다. 여기서 클래스라 함 은, 상품 이미지 즉, 제1 이미지 또는 제2 이미지에서 카테고리로서 상품을 그룹화 하는데 사용되는 범주일 수 있다. 클래스는 일반적으로 상품의 특성이나 용도에 따라 지정될 수 있다. 예를 들어, 의류 카테고리의 클래 스는 티셔츠, 바지, 원피스 등과 같이 의류 아이템을 식별하는데 이용될 수 있다. 또한 전자제품 카테고리에서 는 스마트폰, 노트북, TV 등과 같은 전자기기를 식별하는데 사용될 수 있다. 본 개시에 따른 클래스는 해당 상 품 즉, 오브젝트가 어떤 유형이며, 어떤 범주에 속하는지를 나타낼 수 있다. 본 개시에서 오브젝트 배치 장치는 제2 이미지에 포함되는 오브젝트의 클래스를 분류하기 위해 인공지능 기반의 오픈소스 알고리즘으로서의 Detic을 적용할 수 있다. Detic은 이미지 데이터를 입력으로 받아 각 상품 (오브젝트)의 특징을 학습하고, 이를 기반으로 상품(오브젝트)을 다양한 클래스로 분류하는 기술로서, 상세한 내용은 후술하기로 한다. 오브젝트 배치 장치는 오브젝트의 클래스를 분류한 결과 및 제2 이미지에 포함되는 오브젝트의 개수를 기 반으로 하여, 오브젝트를 대상 공간에 배치할 수 있다. 오브젝트 배치 장치는 각 클래스에 대해 해당 클래스에 속하는 오브젝트의 개수를 고려하여 배치 위치와 방향을 결정하고, 제2 이미지에 있는 오브젝트들 간의 상대적인 위치와 배치 패턴을 고려하여, 오브젝트를 대상 공간에 배치할 수 있다. 본 개시에서 대상 공간은 2D 및 3D 대상 공간 중 하나 이상을 포함할 수 있다. 오브젝트 배치 장치는 2D 대상 공간에 오브젝트를 배치하기 위해, 2D 대상 공간의 크기와 비율을 고려하여 오브젝트의 배치 영역을 결정하고, 각 오브젝트의 크기, 형태, 위치, 방향 등을 고려하여 배치할 수 있다. 오 브젝트 배치 장치는 겹치지 않도록 오브젝트들을 배치하고, 대상 공간 내에 고르게 분포되도록 조정할 수 있으며, 필요에 따라 오브젝트 간의 간격, 정렬, 그룹화 등을 조절하여 배치를 최적화할 수 있다. 오브젝트 배치 장치는 3D 대상 공간에 오브젝트를 배치하기 위해, 대상 공간의 크기, 형상, 재질 등을 고 려하여 오브젝트의 배치 영역을 설정하고, 각 오브젝트의 크기, 형태, 위치, 방향, 회전 등을 고려하여 3D 공간 상에 배치할 수 있다. 오브젝트 배치 장치는 충돌을 피하기 위해 오브젝트들 간의 거리와 간격을 유지하 며 배치할 수 있다. 오브젝트 배치 장치는 오브젝트의 시각적인 조화와 전체적인 레이아웃을 고려하여 배 치를 조정하고 최적화할 수 있다. 본 개시에서 오브젝트의 대상 공간 배치는 기저장된 클래스별 배치 규칙을 적용하여 자동화될 수 있다. 여기서 배치 규칙은 오브젝트의 특성과 사용자의 요구에 따라 다르며, 예를 들어, 클래스 특성, 클래스 간 상호 작용, 사용자 요구 사항, 디자인 원칙에 따라 달라질 수 있다. 클래스 특성에 따른 배치 규칙은 각 클래스의 특성을 고려하여 오브젝트의 배치를 조정할 수 있다. 예를 들어, 큰 오브젝트는 대상 공간의 중앙에 배치하고 작은 오브젝트는 주변에 배치할 수 있다. 또는 특정 클래스는 특 정 위치 또는 방향에 배치되도록 규칙을 설정할 수 있다. 클래스 간 상호작용에 따른 배치 규칙은 서로 다른 클래스의 오브젝트들 사이의 상호작용을 고려하여 배치할 수 있다. 상호작용은 오브젝트 간의 거리, 방향, 연관성 등을 고려하여 조정될 수 있다. 예를 들어, 관련된 상품 들을 함께 배치하거나 유사한 카테고리의 오브젝트들을 근접하게 배치할 수 있다. 사용자 요구 사항에 따른 배치 규칙은 사용자의 요구에 따라 오브젝트의 배치를 조정할 수 있다. 사용자가 특 정 오브젝트를 중요하게 생각한다면, 해당 오브젝트를 눈에 띄게 배치할 수 있다. 또는 사용자가 선호하는 스 타일이나 조합을 고려하여 오브젝트를 배치할 수 있다. 디자인 원칙에 따른 배치 규칙은 디자인 원칙을 활용하여 오브젝트의 배치를 조정할 수 있다. 대상 공간 내에 서 균형, 조화, 대칭 등을 고려하여 오브젝트를 배치하고, 시각적인 효과를 극대화할 수 있다. 이러한 클래스별 배치 규칙을 적용함으로써, 오브젝트의 배치를 조화롭게 조정하고, 공간의 효율성과 사용자의 관점에서 만족도를 높일 수 있다. 오브젝트 배치 장치는 제2 이미지로부터 오브젝트의 종류 및 색상 정보를 추출하고, 오브젝트의 종류 및 색상 정보에 대응하는 콜라주 이미지를 생성할 수 있다. 오브젝트 배치 장치는 콜라주 이미지를 오브젝트 가 배치된 대상 공간의 배경 이미지로 결정할 수 있다. 여기서 콜라주 이미지라 함은, 여러 개의 이미지 또는 그래픽 요소들을 조합하여 생성된 새로운 이미지를 포함 할 수 있다. 콜라주 이미지는 각각의 이미지나 그래픽 요소들을 겹쳐서 배치하거나 자르고 붙여서 새로운 형태 를 만들어내는 과정을 거칠 수 있다. 이렇게 조합된 이미지들은 다양한 크기, 모양, 색상, 질감 등을 가지며, 창의적인 아이디어와 디자인 감각에 따라 다양한 스타일과 표현 방법을 가질 수 있다. 콜라주 이미지는 일상적 인 사물이나 풍경, 인물 등을 비롯하여 추상적인 형상이나 패턴 등을 포함할 수 있으며, 다양한 주제나 컨셉에 맞게 구성될 수 있다. 또한, 다른 이미지와의 조합이나 배경과의 대조를 통해 시각적인 대비와 조화를 표현할 수도 있다. 본 개시에서 오브젝트 배치 장치는 콜라주 이미지를 생성하기 위해 Stable Diffusion 알고리즘을 적용할 수 있다. Stable Diffusion 알고리즘은 이미지 분할, 오브젝트 분류, 색상 추출, 콜라주 이미지 생성 등의 단 계를 거쳐 콜라주 이미지를 생성하는 기술로서, 상세한 내용은 후술하기로 한다. 본 실시 예에서, 오브젝트 배치 장치는 서버 형태로 독립적으로 존재하거나, 오브젝트 배치 장치가 제공하는 자동 오브젝트 배치 기능을 어플리케이션 형태로 구현하여 사용자 단말기에 탑재할 수 있다. 사용자 단말기는 오브젝트 배치 장치가 제공하는 오브젝트 배치 어플리케이션 및/또는 오브젝트 배치 사이트에 접속하여 오브젝트 배치 서비스를 받을 수 있다. 이러한 사용자 단말기는 컴퓨팅 장치(미도시)의 기능을 수행할 수 있는 통신 단말기를 포함할 수 있으며, 사용자가 조작하는 데스크 탑 컴퓨터, 스마트폰, 노트북 이외에, 태블릿 PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 사용자 단말기는 통 신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 단말기 일 수 있다. 이러한 사용자 단말기는 상술한 내용에 제한되지 아니하며, 웹 브라우징이 가능한 단말기는 제한 없이 차 용될 수 있다. 네트워크는 오브젝트 배치 장치 및 사용자 단말기를 연결하는 역할을 수행할 수 있다. 이러한 네트워크는 예컨대 LAN(local area network), WAN(wide area network), MAN(metropolitan area network), ISDN(integrated service digital network) 등의 유선 네트워크나, WLAN(wireless LAN), CDMA(code-division multiple access), 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 개시의 범위가 이에 한정되는 것은 아니다. 또한 네트워크는 근거리 통신 및/또는 원거리 통신을 이용하여 정보를 송수 신할 수 있다. 여기서, 근거리 통신은 Bluetooth, RFID(radio frequency identification), IrDA(infrared data association), UWB(ultra-wideband), ZigBee, Wi-Fi 기술을 포함할 수 있고, 원거리 통신은 CDMA(code- division multiple access), FDMA(frequency-division multiple access), TDMA(time-division multiple access), OFDMA(orthogonal frequency-division multiple access), SC-FDMA(single carrier frequency- division multiple access) 기술을 포함할 수 있다. 네트워크는 허브, 브리지, 라우터, 스위치와 같은 네트워크 요소들의 연결을 포함할 수 있다. 네트워크 는 인터넷과 같은 공용 네트워크 및 안전한 기업 사설 네트워크와 같은 사설 네트워크를 비롯한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 네트워크에의 액세스는 하나 이상 의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다. 더 나아가 네트워크는 CAN(controller area network) 통신, V2I(vehicle to infrastructure, 차량 대 도 로 인프라) 통신, V2X(vehicle to everything) 통신, 웨이브(wireless access in vehicular environment) 통신 기술과, 사물 등 분산된 구성 요소들 간에 정보를 주고받아 처리하는 IoT(Internet of Things, 사물인터넷) 망 및/또는 5G 통신을 지원할 수 있다. 도 2는 본 개시에 따른 오브젝트 배치 장치의 구성을 개략적으로 설명하기 위하여 도시한 블록도이다. 이하의 설명에서 도 1에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 2를 참조하면, 오브젝트 배치 장치는 통신부, 저장 매체, 프로그램 저장부, 데이터베이스, 오브젝트 배치 관리부 및 제어부를 포함할 수 있다. 통신부는 네트워크와 연동하여 오브젝트 배치 장치 및 사용자 단말기 간의 송수신 신호를 패킷 데이터 형태로 제공하는 데 필요한 통신 인터페이스를 제공할 수 있다. 나아가, 통신부는 사용자 단 말기로부터 소정의 정보 요청 신호를 수신하는 역할을 할 수 있고 오브젝트 배치 관리부가 처리한 정 보를 사용자 단말기로 전송하는 역할을 수행할 수 있다. 여기서, 통신 인터페이스라 함은, 오브젝트 배치 장치와 사용자 단말기를 연결하는 역할을 수행하는 매개체로써, 사용자 단말기가 오브젝트 배치 장치에 접속한 후 정보를 송수신할 수 있도록 접속 경로를 제공하는 경로를 포함할 수 있다. 또한 통신부 는 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신하기 위해 필요한 하드웨어 및 소프트웨어를 포함하는 장치일 수 있다. 저장 매체는 제어부가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행한다. 여기 서, 저장 매체는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage media) 를 포함할 수 있으나, 본 개시의 범위가 이에 한정되는 것은 아니다. 이러한 저장 매체는 내장 메모리 및 /또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD. CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 프로그램 저장부는 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 제2 이미지로부터 오브젝트를 추출하는 작업, 제2 이미지에 포함되는 오브젝트의 클래스를 분류하는 작업, 오브젝트의 클래스를 분류한 결과 및 제2 이미지에 포함되는 오브젝트의 개수를 기반으로 하여, 오브젝트를 대상 공간에 배치하는 작업, 제2 이미 지로부터 오브젝트의 종류 및 색상 정보를 추출하고, 오브젝트의 종류 및 색상 정보에 대응하는 콜라주 이미지 를 생성하는 작업, 콜라주 이미지를 오브젝트가 배치된 대상 공간의 배경 이미지로 결정하는 작업 등을 수행하 는 제어 소프트웨어를 탑재하고 있다. 데이터베이스는 오브젝트 배치를 위해 필요한 정보를 저장하는 관리 데이터베이스를 포함할 수 있다. 예 를 들어, 관리 데이터베이스에는 배경을 제거하고 오브젝트를 추출하기 위한 인공지능 기반의 오픈소스 알고리 즘으로서의 Segment Anything이 저장될 수 있다. 또한 관리 데이터베이스에는 오브젝트의 클래스를 분류하기 위한 인공지능 기반의 오픈소스 알고리즘으로서의 Detic이 저장될 수 있다. 또한 관리 데이터베이스에는 오브 젝트 배치를 위해 적용하는 클래스별 배치 규칙이 저장될 수 있다. 여기서 클래스별 배치 규칙은 2D 대상 공간 및 3D 대상 공간에 따라 다르게 적용될 수 있다. 또한 관리 데이터베이스에는 콜라주 이미지를 생성하기 위해 Stable Diffusion 알고리즘이 저장될 수 있다. 또한 관리 데이터베이스에는 오브젝트 배치를 위한 각종 인공지 능 알고리즘이 저장될 수 있다. 또한 데이터베이스는 오브젝트 배치 서비스를 제공받을 사용자의 정보를 저장하는 유저 데이터베이스를 포 함할 수 있다. 여기서, 사용자의 정보는 사용자의 이름, 소속, 인적 사항, 성별, 나이, 연락처, 이메일, 주소, 이미지 등 사용자에 대한 기본적인 정보와, 아이디(ID) (또는 이메일) 및 패스워드(password) 등 사용자의 인증 (로그인)에 대한 정보, 접속 국가, 접속 위치, 접속에 이용한 장치에 대한 정보, 접속된 네트워크 환경 등 접속 과 관련된 정보 등을 포함할 수 있다. 또한 유저 데이터베이스에는 사용자의 고유정보와, 오브젝트 배치 어플리케이션 또는 오브젝트 배치 사이트에 접속한 사용자가 제공받은 정보 및/또는 카테고리 이력, 사용자가 설정한 환경 설정 정보, 사용자가 이용한 자 원 사용량 정보, 사용자의 자원 사용량에 대응한 과금 및 결제 정보가 저장될 수 있다.오브젝트 배치 관리부는 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 제2 이미지로부터 오브 젝트를 추출할 수 있다. 오브젝트 배치 관리부는 제2 이미지에 포함되는 오브젝트의 클래스를 분류할 수 있다. 오브젝트 배치 관리부는 오브젝트의 클래스를 분류한 결과 및 제2 이미지에 포함되는 오브젝트의 개수를 기반으로 하여, 오브젝트를 대상 공간에 배치할 수 있다. 오브젝트 배치 관리부는 제2 이미지로부 터 오브젝트의 종류 및 색상 정보를 추출하고, 오브젝트의 종류 및 색상 정보에 대응하는 콜라주 이미지를 생성 할 수 있다. 오브젝트 배치 관리부는 콜라주 이미지를 오브젝트가 배치된 대상 공간의 배경 이미지로 결 정할 수 있다. 제어부는 일종의 중앙처리장치로서 프로그램 저장부에 탑재된 제어 소프트웨어를 구동하여 오브젝트 배치 장치 전체의 동작을 제어할 수 있다. 제어부는 프로세서(processor)와 같이 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 여기서, '프로세서(processor)'는, 예를 들어 프로그램 내에 포 함된 코드 또는 명령어로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프 로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티 프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망라할 수 있으나, 본 개시의 범위가 이에 한정되는 것은 아니다. 도 3은 도 2의 오브젝트 배치 장치 중 오브젝트 배치 관리부의 구성을 개략적으로 설명하기 위하여 도시한 블록 도이고, 도 4 내지 도 16은 본 개시에 따른 인공지능을 기반으로 한 오브젝트 배치를 설명하는 예시도이다. 이 하의 설명에서 도 1 및 도 2에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 3 내지 도 16을 참조하면, 오브젝트 배치 관리부는 추출부, 분류부, 배치부, 생성부, 결정부를 포함할 수 있다. 추출부는 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 제2 이미지로부터 오브젝트를 추출할 수 있다. 추출부는 제1 이미지 내의 복수의 구성을 영역 별로 분류할 수 있다. 추출부는 제1 이미지로부터 사 용자에 의해 선택된 하나 이상의 영역을 인식하고, 선택된 영역 이외의 다른 영역을 배경으로 판단할 수 있다. 추출부는 배경으로 판단된 영역에 배경 제거 알고리즘을 적용하여 배경으로 판단된 영역이 제거된 제2 이 미지를 생성할 수 있다. 추출부는 제2 이미지에 포함되는 하나 이상의 선택된 영역을 오브젝트로 결정할 수 있다. 도 4는 추출부가 제1 이미지로부터 배경을 제거하고 오브젝트를 추출하는 도면을 도시하고 있다. 401은 추출부로 입력되는 제1 이미지를 도시하고 있고, 402는 제1 이미지로부터 사용자에 의한 영역 선택을 도시 하고 있고, 403은 배경 제거 알고리즘을 도시하고 있고, 404는 배경 제거 알고리즘을 통해 추출된 오브젝트를 도시하고 있다. 도 5는 도 4의 403에 도시된 배경 제거 알고리즘을 설명하고 있다. 도 5의 501을 참조하면, 배경 제거 알고리 즘인 인공지능 기반의 오픈소스 알고리즘으로서의 Segment Anything을 도시하고 있다. Segment Anything 알고 리즘은 인공지능을 기반으로 하며, 이미지 내에서 상품 오브젝트를 선택하고 배경을 제거하는 과정을 수행할 수 있다. Segment Anything은 먼저 이미지를 입력으로 받고, 이미지를 인코딩하여 이미지 임베딩을 생성할 수 있다. 이후, 사용자가 지정한 포인트, 박스 또는 텍스트와 같은 프롬프트를 입력으로 받아 프롬프트를 인코딩 할 수 있다. 인코딩된 프롬프트와 이미지 임베딩은 마스크 디코더로 전달되어, 오브젝트의 세그멘테이션 마스 크를 예측할 수 있다. 이 마스크는 이미지 내에서 오브젝트와 배경을 구분하는 데 사용될 수 있다. 도 5의 502에는 Segment Anything 알고리즘에 의해 녹색점에서 생성된 유효한 마스크의 예시를 도시하고 있다. 분류부는 제2 이미지에 포함되는 오브젝트의 클래스를 분류할 수 있다. 분류부는 이미지를 입력으로 하여 이미지의 클래스를 분류하도록 미리 훈련된 제1 심층신경망 모델을 이용하여 제2 이미지의 클래스를 분류 할 수 있다. 여기서, 제1 심층신경망 모델은, 이미지를 입력으로 하고, 이미지의 클래스를 레이블로 하는 훈련 데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. 분류부는 훈련데이터를 이용하여 초기에 설정된 제1 심층신경망 모델을 지도학습 방식으로 훈련할 수 있다. 여기서, 초기에 설정된 제1 심층신경망 모델은 입력 이미지의 클래스를 분류할 수 있는 모델로 구성되기 위해 설계된 초기 모델로서 파라미터 값들은 임의의 초기값으로 설정되어 있는 상태이다. 초기 모델은 상술한 훈련데이터를 통해 훈련되면서 파라미터 값들이 최적화되어 입력 이미지의 클래스를 정확히 분류할 수 있는 클래스 분류 모델로 완성될 수 있다. 도 6은 분류부가 제2 이미지로부터 오브젝트의 클래스를 분류하는 도면을 도시하고 있다. 601은 분류부 로 입력되는 제2 이미지를 도시하고 있고, 602는 클래스 분류 알고리즘을 도시하고 있고, 603는 클래스 분 류 알고리즘에 의해 분류된 오브젝트의 클래스를 도시하고 있다. 604는 602에 도시된 클래스 분류 알고리즘인 Detic을 설명하고 있다. 본 개시의 다른 실시 예에 따른 Detic 알고리즘은 상품 이미지에서 클래스를 분류하기 위한 기술로, 딥러닝 모델을 활용할 수 있다. Detic 알고리즘은 이미지 데이터를 입력으로 받아 각 상품의 특 징을 학습하고, 이를 기반으로 상품을 다양한 클래스로 분류할 수 있다. Detic 알고리즘은 일반적으로 컨볼루 션 신경망(convolutional neural network, CNN) 아키텍처를 사용하여 이미지 특징을 추출하고, 이를 분류 모델 에 전달하여 클래스를 결정할 수 있다. 학습 단계에서는 대규모의 레이블된 상품 이미지 데이터셋을 사용하여 모델을 훈련시킬 수 있다. 이때, 이미지의 특징과 클래스 간의 관계를 학습하여 모델이 상품을 올바르게 식별 하고 분류할 수 있다. 훈련된 DETIC 모델은 새로운 상품 이미지를 입력으로 받아 클래스를 예측하는데, 입력 이미지를 전처리하여 모델에 입력하고, 모델은 이미지의 특징을 추출하고 클래스를 할당할 수 있다. 이를 통해 DETIC은 상품 이미지에서 다양한 클래스를 식별하고 분류할 수 있는 강력한 도구가 될 수 있다. 배치부는 오브젝트의 클래스를 분류한 결과 및 제2 이미지에 포함되는 오브젝트의 개수를 기반으로 하여, 오브젝트를 대상 공간에 배치할 수 있다. 배치부는 기설정된 클래스별 배치 규칙을 로딩하여 오브젝트를 대상 공간에 배치할 수 있다. 여기서 클래스별 배치 규칙은, 단일 오브젝트 또는 복수개의 오브젝트에 따라, 그리고 대상 공간이 2D 또는 3D에 따라 다르게 적용될 수 있다. 배치부는 분류부로부터 오브젝트의 클래스 분류 결과를 로딩하고, 데이터베이스로부터 기설정된 클래스별 배치 규칙을 로딩할 수 있다. 배치부는 오브젝트의 클래스 분류 결과에 배치 규칙을 적용하여 오브젝트를 대상 공간에 배치할 수 있다. 배치부는 어느 한 클래스 분류 결과에 대응하는 복수개의 오브젝트가 존재함에 따라, 복수개의 오브젝트에 배치 우선 순위 알고리즘을 적용하여, 복수개의 오브젝트에 대한 우선 순위를 결정할 수 있다. 배치부는 우선 순위를 결정한 결과 중 최 우선 순위로 결정된 어느 한 오브젝트에 배치 규칙을 적용하여 대상 공간에 배 치할 수 있다. 본 개시에서 배치부는 우선 순위를 결정 시에, 사용자의 상품 구매 정보를 이용하여 사용자의 선호도를 예 측하도록 훈련된 제2 심층신경망 모델을 이용하여 복수개의 오브젝트에 대응하는 사용자의 선호도를 예측할 수 있다. 배치부는 선호도를 예측한 결과를 내림차순으로 정렬하여 복수개의 오브젝트에 대한 우선 순위를 결정할 수 있다. 본 개시에서 제2 심층신경망 모델은, 사용자의 성별, 나이, 지역, 관심사, 이전 구매 기록 중 하나 이상을 포함 하는 사용자 프로파일 정보와, 사용자가 선택한 상품 이미지의 카테고리, 스타일, 색상, 크기 및 브랜드 중 하 나 이상을 포함하는 이미지 정보와, 사용자의 웹 페이지 방문 기록, 상품 검색 기록, 장바구니에 담은 상품 및 구매 내역 중 하나 이상을 포함하는 사용자 행동 패턴을 포함하는 사용자의 상품 구매 정보를 입력으로 하고, 선호도 점수를 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. 배치부는 훈련데이터를 이용하여 초기에 설정된 제2 심층신경망 모델을 지도학습 방식으로 훈련할 수 있다. 여기서, 초기에 설정된 제2 심층신경망 모델은 사용자의 상품 구매 정보를 이용하여 사용자의 선호도를 예측하는 모델로 구성되기 위해 설계된 초기 모델로서 파라미터 값들은 임의의 초기값으로 설정되어 있는 상태 이다. 초기 모델은 상술한 훈련데이터를 통해 훈련되면서 파라미터 값들이 최적화되어 사용자의 상품 구매 정 보를 이용하여 사용자의 선호도를 정확하게 예측할 수 있는 선호도 예측 모델로 완성될 수 있다. 배치부는 최 우선 순위로 결정된 어느 한 오브젝트에 배치 규칙을 적용하여 대상 공간에 배치하기 전에, 사용자로부터 배치 불허 신호가 수신됨에 따라, 우선 순위를 결정한 결과 중 차선 순위로 결정된 다른 한 오브 젝트를 대상 공간에 배치할 수 있다. 본 개시에서 클래스별 배치 규칙은 Rule-base를 기반으로 할 수 있다. Rule-base를 기반으로 한 배치 규칙에 의해 오브젝트를 배치하는 방법은 클래스 정의, 우선순위 결정, 충돌 처리, 공간 제약 고려, 배치 알고리즘 적 용, 최적화 및 조정의 단계를 포함할 수 있다. 먼저 클래스 정의 단계는, 각 클래스에 대해 배치 규칙을 정의 할 수 있다. 예를 들어 클래스 A는 대상 공간의 중앙 상단에 위치하도록 하고, 클래스 B는 대상 공간의 중앙 하단에 위치하도록 정의할 수 있다. 다음에 우선 순위 결정 단계는, 각 클래스에 우선 순위를 부여할 수 있다. 이는 클래스별로 배치되는 오브젝트의 중요도를 나타낼 수 있다. 여기서 오브젝트의 중요도는 상술한 바와 같이 사용자의 선호도에 따라 결정될 수 있다. 높은 우선순위를 가진 클래스를 다른 클래스보다 먼저 배치할 수 있다. 다음에 충돌 처리 단계는, 오브젝트가 겹치는 경우 충돌을 처리하는 방법을 정의할 수 있다. 예를 들어, 겹치는 오브젝트를 상대적으로 약간 이동시켜 충돌을 피하게 할 수 있다. 다음에 공간 제약의 고려 단계 는, 대상 공간의 크기와 형태를 고려하여 오브젝트의 배치를 조정할 수 있다. 이는 오브젝트가 대상 공간을 벗 어나지 않도록 보장하는 역할을 할 수 있다. 배치 알고리즘 적용 단계는, 상술한 바와 같이 정의한 규칙을 적 용하여 각 클래스별로 오브젝트를 배치할 수 있다. 예를 들어, 우선순위에 따라 클래스를 순서대로 처리하며, 해당 클래스에 속하는 오브젝트를 대상 공간 내에 배치시킬 수 있다. 최적화 및 조정 단계는, 배치된 오브젝트 의 위치 및 배치 결과를 최적화하고 조정할 수 있다. 이는 시각적인 조합성과 균형을 고려하여 오브젝트의 배 치를 미세 조정하는 것을 의미할 수 있다. 도 7 내지 도 12는 배치부가 2D 대상 공간 내에서 클래스별 배치 규칙을 적용하여 오브젝트를 배치한 예시 도이다. 도 7의 701 내지 705와, 도 8의 801 내지 812와, 도9의 901 내지 906을 참조하면, 주어진 2D 대상 공간의 사이 즈 및 오브젝트의 개수에 따라 오브젝트를 배치한 예를 도시하고 있다. 주어진 2D 대상 공간의 사이즈 및 오브 젝트의 개수에 따라 오브젝트를 배치하는 방법은, 2D 대상 공간을 동일한 크기의 그리드로 분할하고, 오브젝트 를 각 그리드 셀에 균등하게 배치할 수 있다. 이 방법은 오브젝트 간의 간격을 일정하게 유지하면서 공간을 최 대한 활용할 수 있다. 또는 오브젝트를 대상 공간의 중앙에 배치할 수 있다. 이 방법은 오브젝트를 중심으로 시선이 집중되고, 중앙을 기준으로 균형을 이룰 수 있다. 또는 오브젝트의 중요도에 따라 배치 순서를 결정하 여 배치할 수 있다. 먼저 중요한 오브젝트를 배치한 후 나머지 공간에 다른 오브젝트를 배치할 수 있다. 여기 서 오브젝트의 중도는 상술한 사용자 선호도를 포함할 수 있다. 이를 통해 주요한 오브젝트가 시각적으로 두드 러지게 표현될 수 있다. 또는 오브젝트의 크기를 고려하여 배치할 수 있다. 크기가 큰 오브젝트를 중심으로 배치하고, 작은 오브젝트를 주변에 배치하는 방식으로, 시각적인 다양성과 균형을 제공할 수 있다. 또는 오브 젝트 간의 상호작용을 고려하여 배치할 수 있다. 상호작용을 표현하기 위해 오브젝트들을 겹쳐서 배치하거나 서로를 둘러싸는 형태로 배치할 수 있다. 도 10의 1001 내지 1012를 참조하면, 주어진 2D 대상 공간의 비율 및 오브젝트의 개수에 따라 오브젝트를 배치 한 예를 도시하고 있다. 주어진 2D 대상 공간의 비율 및 오브젝트의 개수에 따라 오브젝트를 배치하는 방법은, 대상 공간의 가로와 세로 비율을 유지하면서 오브젝트를 배치할 수 있다. 비율을 유지하는 것은 시각적인 균형 을 유지하는 데 도움이 될 수 있다. 또는 대상 공간을 그리드로 분할하고 오브젝트를 그리드 셀에 배치할 수 있다. 이를 통해 오브젝트 간의 간격을 일정하게 유지하고 균형을 이룰 수 있다. 또는 오브젝트를 가능한 한 많이 2D 대상 공간에 밀집시켜 배치할 수 있다. 이를 통해 최대한 많은 오브젝트를 표현할 수 있다. 또는 오 브젝트를 대상 공간의 중앙에 배치할 수 있다. 이는 오브젝트를 중심으로 시선이 집중되고, 중앙을 기준으로 균 형을 이룰 수 있다. 또는 오브젝트의 크기를 고려하여 배치할 수 있다. 크기가 큰 오브젝트를 중앙에 배치하 고, 작은 오브젝트를 주변에 배치할 수 있다. 도 11의 1101 내지 1112를 참조하면, 동일 카테고리의 오브젝트가 복수개인 경우에 지정된 2D 대상 공간에 오브 젝트를 배치한 예를 도시하고 있다. 동일 카테고리의 오브젝트가 복수개인 경우에 지정된 2D 대상 공간에 오브 젝트를 배치하는 방법은, 오브젝트 사이의 간격을 지정하고 오브젝트의 간격을 유지하면서 배치할 수 있다. 이 를 통해 오브젝트가 서로 겹치지 않고 균형 있게 배치될 수 있다. 또는 오브젝트를 가로 또는 세로 방향으로 정렬하여 배치할 수 있다. 이를 통해 오브젝트들이 일렬로 나열되어 시선을 집중시키고 규칙적인 패턴을 만들 어낼 수 있다. 또는 오브젝트를 그룹으로 묶어 배치할 수 있다. 동일한 카테고리의 오브젝트들을 함께 배치하 여 시각적인 유사성과 연관성을 강조할 수 있다. 또는 오브젝트를 랜덤하게 배치할 수 있다. 이를 통해 다양 한 배치 패턴을 생성하고 흥미로운 시각적 효과를 얻을 수 있다. 또는 오브젝트를 대상 공간의 중앙에 배치할 수 있다. 이는 오브젝트를 중심으로 시선이 집중되고, 중앙을 기준으로 균형을 이룰 수 있다. 도 12의 1201 내지 1215를 참조하면, 다른 카테고리의 오브젝트가 복수개인 경우에 지정된 2D 대상 공간에 오브 젝트를 배치한 예를 도시하고 있다. 다른 카테고리의 오브젝트가 복수개인 경우에 지정된 2D 대상 공간에 오브 젝트를 배치하는 방법은, 각 카테고리의 오브젝트를 서로 다른 영역에 할당할 수 있다. 이를 통해 각 카테고리 의 오브젝트들이 시각적으로 구분되고 혼동이 없도록 배치할 수 있다. 또는 다른 카테고리의 오브젝트들을 조 화롭게 배치할 수 있다. 크기, 색상, 형태 등을 고려하여 시각적으로 일관성 있고 조화로운 배치를 구성할 수 있다. 또는 다른 카테고리의 오브젝트들이 겹치지 않도록 배치할 수 있다. 이를 통해 각 오브젝트들이 명확하 게 보여지고 시각적인 혼돈을 방지할 수 있다. 또는 2D 대상 공간의 배경을 활용하여 오브젝트들을 배치할 수 있다. 배경의 색상이나 패턴을 고려하여 오브젝트들과 조화롭게 배치할 수 있다. 또는 사용자의 시선을 고려하여 오브젝트들을 배치할 수 있다. 중요한 오브젝트를 중심으로 배치하거나 시선을 유도하는 방식으로 배치할 수 있다. 도 13 내지 도 15는 배치부가 3D 대상 공간 내에서 클래스별 배치 규칙을 적용하여 오브젝트를 배치한 예 시도이다. 도 13의 1301 내지 1303을 참조하면, 그라운드를 포함한 3D 오픈 대상 공간 내에서 오브젝트를 배치한 예를 도 시하고 있다. 그라운드를 포함한 3D 오픈 대상 공간 내에서 오브젝트를 배치하는 방법은, 3D 대상 공간을 적절 한 크기로 분할하여 각 영역에 오브젝트를 배치할 수 있다. 이를 통해 오브젝트들이 서로 겹치지 않고, 각자의 공간을 차지할 수 있다. 본 개시에서 3D 대상 공간을 적절한 크기로 분할하는 방법은, 3D 공간을 균등한 크기 의 그리드 셀로 분할하거나, 일정한 크기의 볼륨으로 분할하거나, 3D 공간을 상위공간과 하위공간으로 분할하거 나 특정 영역을 기준으로 공간을 분할할 수 있다. 또는 각 오브젝트의 위치를 조정하여 시각적인 조화와 균형 을 이루도록 배치할 수 있다. 크기, 높이, 방향 등을 고려하여 오브젝트들을 조정하고, 공간을 균형 있게 채울 수 있다. 또는 오브젝트들이 서로 충돌하지 않도록 배치할 수 있다. 또한, 임의의 규칙에 따라 오브젝트들을 배치할 수 있다. 예를 들어, 비슷한 카테고리의 오브젝트를 함께 배치하거나, 특정 규칙에 따라 배치 순서를 정할 수 있다. 또는 오브젝트의 시각적인 효과를 고려하여 배치할 수 있다. 조명, 그림자, 반사 등을 활용하 여 오브젝트들이 더욱 현실적이고 입체적으로 보이도록 배치할 수 있다. 도 14의 1401 내지 1403을 참조하면, 동일 카테고리의 오브젝트가 복수개인 경우에 3D 대상 공간에 오브젝트를 배치한 예를 도시하고 있다. 동일 카테고리의 오브젝트가 복수개인 경우에 3D 대상 공간에 오브젝트를 배치하 는 방법은, 오브젝트들을 3D 공간의 중앙에 배치할 수 있다. 이는 오브젝트를 공간의 중심에 집중시켜 균형적 인 배치를 얻을 수 있다. 또는 오브젝트들을 겹치지 않도록 배치할 수 있다. 이를 위해 오브젝트의 크기와 형 상을 고려하여 간격을 조정할 수 있다. 이렇게 함으로써 각 오브젝트가 독립적으로 존재하며 시각적으로 분리 될 수 있다. 또는 동일한 카테고리의 오브젝트들을 그룹으로 배치할 수 있다. 이는 시각적으로 유사한 오브젝 트들을 함께 배치하여 연관성을 강조할 수 있다. 그룹 간의 간격을 조절하여 각 그룹을 구분 짓는 것이 중요할 수 있다. 또는 오브젝트들을 랜덤으로 배치할 수 있다. 이는 자연스러운 느낌을 주고 오브젝트의 위치를 다양 하게 분포시킬 수 있다. 랜덤 배치를 사용할 경우 겹치지 않도록 충돌 감지 알고리즘을 적용하여 충돌을 방지 할 수 있다. 도 15의 1501 내지 1506을 참조하면, 다른 카테고리의 오브젝트가 복수개인 경우에 3D 대상 공간에 오브젝트를 배치한 예를 도시하고 있다. 다른 카테고리의 오브젝트가 복수개인 경우에 3D 대상 공간에 오브젝트를 배치하 는 방법은, 각 카테고리의 오브젝트들을 서로 분리된 위치에 배치할 수 있다. 이를 통해 각 카테고리의 오브젝 트들이 시각적으로 분리되고 독립적으로 존재함을 나타낼 수 있다. 또는 서로 다른 카테고리의 오브젝트들을 상호작용하도록 배치할 수 있다. 예를 들어, 오브젝트들이 서로를 둘러싸거나 상호작용하는 모습을 보여줄 수 있다. 이는 시각적인 흥미와 다양성을 제공할 수 있다. 또는 카테고리 간의 계층을 고려하여 오브젝트를 배치 할 수 있다. 예를 들어, 큰 오브젝트가 전체 공간을 차지하고 작은 오브젝트들이 그 주변에 배치되는 형태를 취할 수 있다. 이는 시각적인 균형과 계층 구조를 강조할 수 있다. 또는 각 카테고리의 오브젝트들을 특정 테 마에 따라 배치할 수 있다. 예를 들어, 해변 테마에서는 해변 관련 오브젝트들을 중심으로 배치할 수 있다. 이는 특정 분위기나 환경을 재현하는 데 도움을 줄 수 있다. 도 3으로 돌아와서, 생성부는 제2 이미지로부터 오브젝트의 종류 및 색상 정보를 추출하고, 오브젝트의 종 류 및 색상 정보에 대응하는 콜라주 이미지를 생성할 수 있다. 생성부는 제2 이미지로부터 오브젝트가 포함된 영역을 추출할 수 있다. 생성부는 영역에 포함되는 오브젝트의 종류 및 색상 정보를 추출할 수 있다. 생성부는 오브젝트의 종류 및 색상 정보를 추출할 수 있다. 생성부는 오브젝트의 종류 및 색상 정보를 이용하여 배경 이미지를 생성하고, 배경 이미지를 콜라 주 이미지로 결정할 수 있다. 생성부는 오브젝트의 종류 및 색상 정보를 입력으로 하여 배경 이미지를 생성하도록 미리 훈련된 제3 심층 신경망 모델을 이용하여 영역에 포함되는 오브젝트의 종류 및 색상 정보에 대응하는 배경 이미지를 생성할 수 있다. 여기서, 제3 심층신경망 모델은, 오브젝트의 종류 및 색상 정보를 입력으로 하고, 배경 이미지를 레이블 로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. 생성부는 훈련데이터를 이용하여 초기에 설정된 제3 심층신경망 모델을 지도학습 방식으로 훈련할 수 있다. 여기서, 초기에 설정된 제3 심층신경망 모델은 오브젝트의 종류 및 색상 정보를 입력으로 하여 배경 이미지를 생성하는 모델로 구성되기 위해 설계된 초기 모델로서 파라미터 값들은 임의의 초기값으로 설정되어 있 는 상태이다. 초기 모델은 상술한 훈련데이터를 통해 훈련되면서 파라미터 값들이 최적화되어 오브젝트의 종류 및 색상 정보를 입력으로 하여 배경 이미지를 생성할 수 있는 배경 이미지 생성 모델로 완성될 수 있다. 또한 본 개시에서 생성부는 오브젝트의 종류 및 색상 정보를 추출 시에, 이미지를 입력으로 하여 이미지에 포함되는 오브젝트의 종류 및 색상을 예측하도록 미리 훈련된 제4 심층신경망 모델을 이용하여 제2 이미지에 포 함되는 오브젝트의 종류 및 색상 정보를 예측할 수 있다. 여기서, 제4 심층신경망 모델은, 이미지를 입력으로 하고, 이미지에 포함된 오브젝트의 종류 및 색상을 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. 생성부는 훈련데이터를 이용하여 초기에 설정된 제4 심층신경망 모델을 지도학습 방식으로 훈련할 수 있다. 여기서, 초기에 설정된 제4 심층신경망 모델은 이미지를 입력으로 하여 이미지에 포함되는 오브젝트의 종류 및 색상을 예측하는 모델로 구성되기 위해 설계된 초기 모델로서 파라미터 값들은 임의의 초기값으로 설정 되어 있는 상태이다. 초기 모델은 상술한 훈련데이터를 통해 훈련되면서 파라미터 값들이 최적화되어 이미지를 입력으로 하여 이미지에 포함되는 오브젝트의 종류 및 색상을 정확하게 예측할 수 있는 오브젝트의 종류 및 색 상 예측 모델로 완성될 수 있다. 본 개시에서 생성부는 Stable Diffusion 알고리즘을 적용할 수 있다. 도 16에는 Stable Diffusion 알고 리즘을 이용하여 생성된 콜라주 이미지가 도시되어 있다. Stable Diffusion은 이미지 분할 알고리즘을 사용하 여 입력 이미지를 오브젝트 단위로 분할할 수 있다. 이 과정에서 각 오브젝트의 경계가 추출되고, 오브젝트의 픽셀 영역이 분리될 수 있다. 다음에 분할된 오브젝트 영역을 기반으로 딥러닝 분류 모델을 사용하여 오브젝트 의 종류를 분류할 수 있다. 모델은 이미 학습된 분류기로, 각 오브젝트를 해당하는 카테고리로 분류할 수 있다. 다음에 각 오브젝트의 픽셀 영역에서 색상 정보를 추출할 수 있다. 이를 위해 통계적인 방법이 사용되 며, 주요한 색상 또는 색상 팔레트를 추출하여 오브젝트의 색상을 특정할 수 있다. 다음에 오브젝트의 종류와 색상 정보를 기반으로 콜라주 이미지를 생성할 수 있다. 이 과정에서 오브젝트들이 배치되는 위치와 크기를 결 정하고, 각 오브젝트의 색상이 조합되어 콜라주 이미지를 형성할 수 있다. 결정부는 생성부가 생성한 콜라주 이미지를 오브젝트가 배치된 대상 공간의 배경 이미지로 결정할 수 있다. 도 17은 본 개시의 다른 실시 예에 따른 오브젝트 배치 장치의 구성을 개략적으로 설명하기 위하여 도시한 블록 도이다. 이하의 설명에서 도 1 내지 도 16에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 도 17 를 참조하면, 다른 실시 예에 따른 오브젝트 배치 장치는 프로세서와 메모리를 포함할 수 있다. 본 실시 예에서, 프로세서는 도 2 및 도 3에 개시된 통신부, 저장 매체, 프로그램 저장부, 데이터베이스, 오브젝트 배치 관리부 및 제어부가 수행하는 기능을 처리할 수 있다. 이러한 프로세서는 오브젝트 배치 장치 전체의 동작을 제어할 수 있다. 여기서, '프로세서 (processor)'는, 예를 들어 프로그램 내에 포함된 코드 또는 명령어로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로세서, 중앙처리장치, 프로세서 코어, 멀티프로세서, ASIC, FPGA 등 의 처리 장치를 망라할 수 있으나, 본 개시의 범위가 이에 한정되는 것은 아니다. 메모리는 프로세서와 동작 가능하게 연결되고, 프로세서에서 수행되는 동작과 연관하여 적어도 하나의 코드를 저장할 수 있다. 또한, 메모리는 프로세서가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행할 수 있으며, 데이터베이스로 구축된 데이터를 포함할 수 있다. 본 개시에서 후술하는 청구범위에 개시된 프로 세서의 동작을 위해, 메모리에는 제1 이미지가 저장될 수 있다. 본 개시에서, 메모리는 자기 저장 매체 또는 플래시 저장 매체를 포함할 수 있으나, 본 개시의 범위가 이에 한정되는 것은 아니다. 이러한 메모리는 내장 메모리 및/또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발 성 메모리, OTPROM, PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD, CF 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, xD 카드, 또는 메모리 스 틱 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 도 18은 본 개시에 따른 인공지능을 기반으로 한 오브젝트 배치 방법을 설명하기 위한 흐름도이다. 이하의 설 명에서 도 1 내지 도 17에 대한 설명과 중복되는 부분은 그 설명을 생략하기로 한다. 본 실시 예에 따른 인공지능을 기반으로 한 오브젝트 배치 방법은 오브젝트 배치 장치가 주변 구성 요소들의 도움을 받아 프로세 서에서 수행한다고 가정하고 설명하기로 한다. 도 18을 참조하면, S1810단계에서, 프로세서는 제1 이미지로부터 배경을 제거한 제2 이미지를 생성하고, 제2 이미지로부터 오브젝트를 추출할 수 있다. 프로세서는 오브젝트를 추출 시에, 제1 이미지 내의 복수 의 구성을 영역 별로 분류할 수 있다. 프로세서는 제1 이미지로부터 선택된 하나 이상의 영역 이외의 다 른 영역을 배경으로 판단할 수 있다. 프로세서는 배경으로 판단된 영역에 배경 제거 알고리즘을 적용하여 배경으로 판단된 영역이 제거된 제2 이미지를 생성할 수 있다. 프로세서는 제2 이미지에 포함되는 하나 이상의 선택된 영역을 오브젝트로 결정할 수 있다. S1820단계에서, 프로세서는 제2 이미지에 포함되는 오브젝트의 클래스를 분류할 수 있다. 프로세서 는 오브젝트의 클래스를 분류 시에, 이미지를 입력으로 하여 이미지의 클래스를 분류하도록 미리 훈련된 제1 심 층신경망 모델을 이용하여 제2 이미지의 클래스를 분류할 수 있다. 여기서, 제1 심층신경망 모델은, 이미지를 입력으로 하고, 이미지의 클래스를 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. S1830단계에서, 프로세서는 오브젝트의 클래스를 분류한 결과 및 제2 이미지에 포함되는 오브젝트의 개수 를 기반으로 하여, 오브젝트를 대상 공간에 배치할 수 있다. 프로세서는 오브젝트를 대상 공간에 배치 시 에, 오브젝트의 클래스 분류 결과 및 기설정된 클래스별 배치 규칙을 로딩할 수 있다. 프로세서는 오브젝 트의 클래스 분류 결과에 배치 규칙을 적용하여 오브젝트를 대상 공간에 배치할 수 있다. 프로세서는 오 브젝트를 대상 공간에 배치 시에, 어느 한 클래스 분류 결과에 대응하는 복수개의 오브젝트가 존재함에 따라, 복수개의 오브젝트에 배치 우선 순위 알고리즘을 적용하여, 복수개의 오브젝트에 대한 우선 순위를 결정할 수 있다. 프로세서는 우선 순위를 결정한 결과 중 최 우선 순위로 결정된 어느 한 오브젝트에 배치 규칙을 적용하여 대상 공간에 배치할 수 있다. 프로세서는 우선 순위를 결정 시에, 사용자의 상품 구매 정보를 이용하여 사용자의 선호도를 예측하도록 훈련된 제2 심층신경망 모델을 이용하여 복수개의 오브젝트에 대응하는 사용자의 선호도를 예측할 수 있다. 프로세서는 선호도를 예측한 결과를 내림차순으로 정렬하여 복수개의 오브젝트에 대한 우선 순위를 결정하는 단계를 포함할 수 있다. 여기서 제2 심층신경망 모델은, 사용자의 성별, 나이, 지역, 관심사, 이전 구매 기록 중 하나 이상을 포함하는 사용자 프로파일 정보와, 사용자가 선택한 상품 이미지의 카테고리, 스타일, 색상, 크기 및 브랜드 중 하나 이상을 포함하는 이미지 정보와, 사용자의 웹 페이지 방문 기록, 상품 검색 기록, 장바구니에 담은 상품 및 구매 내역 중 하나 이상을 포함하는 사용자 행동 패턴을 포함하는 사용자의 상품 구매 정보를 입력으로 하고, 선호도 점수를 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. 프로세서는 최 우선 순위로 결정된 어느 한 오브젝트에 배치 규칙을 적용하여 대상 공간에 배치하기 전에, 사용자로부터 배치 불허 신호가 수신됨에 따라, 우선 순위를 결정 한 결과 중 차선 순위로 결정된 다른 한 오브젝트를 대상 공간에 배치할 수 있다. S1840단계에서, 프로세서는 제2 이미지로부터 오브젝트의 종류 및 색상 정보를 추출하고, 오브젝트의 종류 및 색상 정보에 대응하는 콜라주 이미지를 생성할 수 있다. 프로세서는 콜라주 이미지를 생성 시에, 제2 이미지로부터 오브젝트가 포함된 영역을 추출할 수 있다. 프로세서는 영역에 포함되는 오브젝트의 종류 및 색상 정보를 추출할 수 있다. 프로세서는 오브젝트의 종류 및 색상 정보를 입력으로 하여 배경 이미지 를 생성하도록 미리 훈련된 제3 심층신경망 모델을 이용하여 영역에 포함되는 오브젝트의 종류 및 색상 정보에 대응하는 배경 이미지를 생성할 수 있다. 프로세서는 배경 이미지를 콜라주 이미지로 결정할 수 있다. 여기서, 제3 심층신경망 모델은, 오브젝트의 종류 및 색상 정보를 입력으로 하고, 배경 이미지를 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. 프로세서는 오브젝트의 종류 및 색상 정보 를 추출 시에, 이미지를 입력으로 하여 이미지에 포함되는 오브젝트의 종류 및 색상을 예측하도록 미리 훈련된 제4 심층신경망 모델을 이용하여 제2 이미지에 포함되는 오브젝트의 종류 및 색상 정보를 예측할 수 있다. 여 기서 제4 심층신경망 모델은, 이미지를 입력으로 하고, 이미지에 포함된 오브젝트의 종류 및 색상을 레이블로 하는 훈련데이터에 의해 지도학습 방식으로 훈련된 모델일 수 있다. S1850단계에서, 프로세서는 콜라주 이미지를 오브젝트가 배치된 대상 공간의 배경 이미지로 결정할 수 있 다. 이상 설명된 본 개시에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체,플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 개시를 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 개시의 명세서(특히 특허청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 개시에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 개시를 포함하는 것으로서(이에 반하는 기재가 없다면), 개시의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 본 개시에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 개시에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 개시를 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 개시의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물 의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 개시의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위 뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 개시의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2023-0094984", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 인공지능을 기반으로 한 오브젝트 배치 환경의 예시도이다. 도 2는 본 개시에 따른 오브젝트 배치 장치의 구성을 개략적으로 설명하기 위하여 도시한 블록도이다. 도 3은 도 2의 오브젝트 배치 장치 중 오브젝트 배치 관리부의 구성을 개략적으로 설명하기 위하여 도시한 블록 도이다. 도 4 내지 도 16은 본 개시에 따른 인공지능을 기반으로 한 오브젝트 배치를 설명하는 예시도이다. 도 17은 본 개시의 다른 실시 예에 따른 오브젝트 배치 장치의 구성을 개략적으로 설명하기 위하여 도시한 블록 도이다. 도 18은 본 개시에 따른 인공지능을 기반으로 한 오브젝트 배치 방법을 설명하기 위한 흐름도이다."}
