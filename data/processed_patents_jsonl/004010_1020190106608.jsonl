{"patent_id": "10-2019-0106608", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0026176", "출원번호": "10-2019-0106608", "발명의 명칭": "딥 러닝을 위한 라벨링 이미지 생성 방법", "출원인": "이래에이엠에스 주식회사", "발명자": "이현재"}}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "분석 대상으로 지정된 관심 영역과 그 이외의 영역인 배경 영역을 포함하는 영상 이미지를 획득하는 단계;상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계;상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계; 및상기 배경 영역의 라벨링 이미지에 상기 객체 영역의 라벨링 이미지를 합성하는 단계를 포함하는 딥 러닝을 위한 라벨링 이미지 생성 방법."}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계는,상기 영상 이미지에서 엣지를 검출하는 단계;상기 검출된 엣지 정보를 이용하여 상기 배경 영역의 경계면에 대한 꼭지점 정보를 획득하는 단계; 및상기 꼭지점 정보를 이용하여 상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계를 포함하는 것을 특징으로하는 딥 러닝을 위한 라벨링 이미지 생성 방법."}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 엣지를 검출하는 단계는 캐니(Canny) 검출법에 의해 수행되는 것을 특징으로 하는 딥 러닝을 위한 라벨링 이미지 생성 방법."}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계는,상기 영상 이미지에서 객체를 검출하는 단계;상기 검출된 객체 정보를 이용하여 상기 객체 영역의 경계면에 대한 꼭지점 정보를 획득하는 단계; 및상기 꼭지점 정보를 이용하여 상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계를 포함하는 것을 특징으로하는 딥 러닝을 위한 라벨링 이미지 생성 방법."}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 객체를 검출하는 단계는 합성곱 신경망(Convolutional Neural Network) 알고리즘에 의해수행되는 것을 특징으로 하는 딥 러닝을 위한 라벨링 이미지 생성 방법."}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 꼭지점 정보를 획득하는 단계는 상기 객체 정보 및 상기 엣지 정보를 이용하여 수행되는것을 특징으로 하는 딥 러닝을 위한 라벨링 이미지 생성 방법."}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 객체 영역은 사람, 자동차, 오토바이, 자전거, 전동보드 중에서 적어도 한 가지를 포함하는 것을 특징으로 하는 딥 러닝을 위한 라벨링 이미지 생성 방법."}
{"patent_id": "10-2019-0106608", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계와 상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계는 동시에 수행되는 것을 특징으로 하는 딥 러닝을 위한 라벨링 이미지 생성 방법.공개특허 10-2021-0026176-3-"}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 예시적인 실시예들에 따른 딥 러닝을 위한 라벨링 이미지 생성 방법은, 분석 대상으로 지정된 관심 영 역과 그 이외의 영역인 배경 영역을 포함하는 영상 이미지를 획득하고, 배경 영역에 대한 라벨링 이미지를 생성 하고, 객체 영역에 대한 라벨링 이미지를 생성하고, 그리고 배경 영역의 라벨링 이미지에 객체 영역의 라벨링 이 미지를 합성하여 딥 러닝을 위한 라벨링 이미지를 생성한다."}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥 러닝을 위한 라벨링 이미지 생성 방법에 관한 것으로, 보다 상세하게는 이미지 세그멘테이션 학습 에 사용되는 데이터를 만들기 위한 라벨링 이미지 생성 방법에 관한 것이다."}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥 러닝(Deep Learning)은 컴퓨터가 방대한 양의 데이터를 학습하여, 새로운 데이터가 입력될 경우 학습 결과를 바탕으로 확률적으로 가장 높은 답을 선택하도록 하는 기술이다. 딥 러닝 기술은 사람이 모든 판단 기준을 정해 주지 않더라도 컴퓨터가 스스로 인지, 추론, 및 판단을 할 수 있기 때문에 다양한 산업 분야에서 널리 이용되고 있다. 특히, 자율 주행 분야에서 딥 러닝에 대한 연구가 활발한데, 합성곱 신경망(Convolutional Neural Network, CNN)을 이용한 이미지 처리 기술이 그 대표적인 예이다. 이 기술은 미리 라벨링된 이미지 데이터를 제공하여 인 공지능이 스스로 학습하도록 함으로써 자율 주행 시 주변 환경을 인지하고 판단할 수 있도록 하는 자율 주행의 핵심 기술이다. 그런데, 상기 합성곱 신경망을 이용한 인공지능 알고리즘의 정확도를 높이기 위해서는, 라벨링이 정확히 된 데 이터를 제공하는 것이 가장 중요하다. 라벨링은 이미지를 유사한 특징을 가진 영역들로 구분하는 작업으로, 픽 셀 수가 많고 경계면이 불분명한 이미지는 라벨링에 많은 시간과 노력이 요구된다. 라벨링을 위한 다양한 기법들이 제시되었는데, 슈퍼픽셀(super-pixel)을 이용하는 방법과 다각형(polygon)을 이 용하는 방법이 대표적이다. 슈퍼픽셀은 같은 정보를 가진 픽셀의 집합을 의미하는데, 명암 대비가 크고 객체가 없는 이미지에 대해서는 우수한 라벨링 성능을 보여주지만, 주행상황과 같은 악조건 하에서는 객체의 윤곽선을 정확하게 표현하지 못하는 문제가 있다. 반면, 다각형을 이용하는 방법은 사용자가 직접 지정한 꼭지점을 이용 해 유사한 영상을 검출하는 방법인데, 정확도는 높으나 라벨링에 소요되는 시간이 길고 사용자에게 극심한 피로 감을 준다는 문제가 있다."}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 과제는 이미지에서 배경과 객체를 서로 다른 방법으로 라벨링한 이후 이들을 합성함으로써 정확도 높 은 라벨링 이미지를 빠른 시간에 생성할 수 있는 라벨링 이미지 생성 방법을 제공하는 것이다. 다만, 본 발명이 해결하고자 하는 과제가 상술한 과제에 한정되는 것은 아니며, 본 발명의 사상 및 영역으로부 터 벗어나지 않는 범위 내에서 다양하게 확장될 수 있을 것이다."}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 본 발명의 과제를 달성하기 위하여, 예시적인 실시예들에 따른 딥 러닝을 위한 라벨링 이미지 생성 방법 은, 분석 대상으로 지정된 관심 영역과 그 이외의 영역인 배경 영역을 포함하는 영상 이미지를 획득하는 단계, 상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계, 상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계, 및 상기 배경 영역의 라벨링 이미지에 상기 객체 영역의 라벨링 이미지를 합성하는 단계를 포함한다. 예시적인 실시예들에 있어서, 상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계는, 상기 영상 이미지에서 엣지를 검출하는 단계, 상기 검출된 엣지 정보를 이용하여 상기 배경 영역의 경계면에 대한 꼭지점 정보를 획득 하는 단계, 및 상기 꼭지점 정보를 이용하여 상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계를 포함할 수 있다. 예시적인 실시예들에 있어서, 상기 엣지를 검출하는 단계는 캐니(Canny) 검출법에 의해 수행될 수 있다. 예시적인 실시예들에 있어서, 상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계는, 상기 영상 이미지에서 객체를 검출하는 단계, 상기 검출된 객체 정보를 이용하여 상기 객체 영역의 경계면에 대한 꼭지점 정보를 획득 하는 단계, 및 상기 꼭지점 정보를 이용하여 상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계를 포함할수 있다. 예시적인 실시예들에 있어서, 상기 객체를 검출하는 단계는 합성곱 신경망(Convolutional Neural Network) 알고 리즘에 의해 수행될 수 있다.ㅊ 예시적인 실시예들에 있어서, 상기 꼭지점 정보를 획득하는 단계는 상기 객체 정보 및 상기 엣지 정보를 이용하 여 수행될 수 있다. 예시적인 실시예들에 있어서, 상기 객체 영역은 사람, 자동차, 오토바이, 자전거, 전동보드 중에서 적어도 한 가지를 포함할 수 있다. 예시적인 실시예들에 있어서, 상기 배경 영역에 대한 라벨링 이미지를 생성하는 단계와 상기 객체 영역에 대한 라벨링 이미지를 생성하는 단계는 동시에 수행될 수 있다."}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 예시적인 실시예들에 따른 딥 러닝을 위한 라벨링 이미지 생성 방법은, 배경 영역과 객체 영역을 나 누고 각 영역에 적합한 방법으로 라벨링 작업을 수행한 이후 이들을 합성함으로써 보다 정확한 라벨링 이미지를 빠르게 획득할 수 있다. 특히, 배경 영역 라벨링 작업에서는 객체 영역을 신경 쓸 필요가 없어 작업 속도를 향상시킬 수 있고, 객체 영 역 라벨링 작업에서는 화면 확대 등 다양한 후처리가 가능하기 때문에 라벨링 결과물의 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본문에 개시되어 있는 본 발명의 실시예들에 대해서, 특정한 구조적 내지 기능적 설명들은 단지 본 발명의 실시 예를 설명하기 위한 목적으로 예시된 것으로, 본 발명의 실시예들은 다양한 형태로 실시될 수 있으며 본문에 설 명된 실시예들에 한정되는 것으로 해석되어서는 아니 된다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는바, 특정 실시예들을 도면에 예시하고 본 문에 상세하게 설명하고자 한다. 그러나 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로 사용될 수 있다. 예를 들어, 본 발명의 권리 범위로부터 이탈되지 않은 채 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다.본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이"}
{"patent_id": "10-2019-0106608", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미이다. 일반적으로 사 용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미인 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 도면상의 동일 한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 먼저 도 1을 참조로 딥 러닝을 위한 라벨링 이미지 생성 장치에 대하여 설명하기로 한다. 도 1은 예시적인 실시 예들에 따른 라벨링 이미지 생성 장치를 나타내는 블록도이다. 도 1을 참조하면, 딥 러닝을 위한 라벨링 이미지 생성 장치는 입력부, 엣지 검출부, 객체 검출부 , 표시부, 및 라벨링부를 포함할 수 있다. 이때, 상기 라벨링 이미지 생성 장치는 컴퓨팅 장치 일 수 있으며, 프로세서, 메모리, 입출력 장치 등을 포함할 수 있다. 입력부는 외부로부터 라벨링 이미지 생성을 위한 원본 이미지를 입력 받거나 또는 작업 데이터, 예를 들면, 각 상의 꼭지점에 관한 데이터를 입력 받을 수 있다. 엣지 검출부는 상기 입력 받은 이미지에서 각 상의 엣 지(edge)를 검출하는 알고리즘을 포함할 수 있고, 객체 검출부는 상기 입력 받은 이미지에서 객체를 구분하 는 알고리즘을 포함할 수 있다. 표시부는 상기 검출된 엣지 정보 및 상기 객체 정보를 사용자에게 전달할 수 있는 디스플레이 등일 수 있다. 또한, 라벨링부는 입력부를 통해 획득한 데이터를 이용하여 이미지 에 포함된 배경 및 객체에 대한 라벨링 작업을 수행할 수 있다. 이하에서는 도 1의 라벨링 이미지 생성 장치를 이용하여 딥 러닝을 위한 라벨링 이미지를 생성하는 방법에 대하 여 보다 상세하게 설명하기로 한다. 도 2는 본 발명에 따른 딥 러닝을 위한 라벨링 이미지 생성 방법의 단계들을 설명하기 위한 순서도이다. 도 3은 라벨링 이미지를 생성하기 위해 입력되는 영상 이미지의 예를 나타내는 도면이다. 도 4는 도 3에서 배경 영역의 엣지를 검출한 이미지를 나타내는 도면이다. 도 5는 도 3에서 객체 영역의 위치를 검출한 이미지를 나타내는 도 면이다. 도 6은 도 5의 객체 영역을 라벨링한 이미지를 나타내는 도면이다. 도 7은 배경 영역과 객체 영역을 합 성하고, 이를 채색하여 라벨링한 이미지를 나타내는 도면이다. 도 2 내지 도 7을 참조하면, 예시적인 실시예들에 따른 딥 러닝을 위한 라벨링 이미지 생성 방법은, 주어진 영 상 이미지(S100)로부터 배경 영역만 라벨링된 이미지를 획득하고(S200), 객체 영역만 라벨링된 이미지를 획득하 고(S300), 이후 상기 두 가지 이미지를 합성하여(S400) 최종 라벨링 이미지를 생성한다(S500). 구체적으로, 영상 이미지를 획득한다(S100). 상기 영상 이미지는 딥 러닝에 사용하기 위한 이미지로서, 예를 들면, 자율 주행의 합성곱 신경망 학습을 위한 주행 환경에 관한 이미지일 수 있다. 이 경우, 상기 이미지는 사람, 자동차, 오토바이, 자전거, 전동보드 등과 같이 자율 주행 환경에서 분석이 필요한 대상으로 지정된 '객체 영역'과 그 이외의 영역인 하늘, 도로, 건물 등 과 같은 '배경 영역'으로 구분될 수 있으며, 상기 객체 영역은 필요에 따라 적절하게 선택될 수 있다. 상기 이 미지를 가공하여 딥 러닝을 위한 라벨링 이미지를 생성하기 위해서는, 배경 영역뿐만 아니라 객체 영역에 대해 서도 정확한 라벨링이 요구된다. 그런데 종래의 기술, 예를 들면, 슈퍼픽셀을 이용한 라벨링 이미지 생성 방법의 경우 배경 영역과 객체 영역이 혼재된 이미지에 대해서는 라벨링 정확도가 떨어지고 작업 시간도 많이 소요된다는 문제가 있다. 이러한 문제점 을 해결하기 위하여, 본 발명에서는 배경 영역과 객체 영역을 따로 라벨링 한 이후 이들을 하나로 합성함으로써 라벨링 이미지의 정확도를 높이고 작업 속도도 향상시키고자 한다. 먼저, 배경 영역에 대한 라벨링 작업을 수행한다(S200). 구체적으로, 상기 획득한 영상 이미지로부터 각 상의 경계인 엣지(edge)를 검출한다(S210). 상기 엣지 검출 단계는 상의 경계면에서 밝기가 변하는 성질을 이용하여 엣지를 검출하는 것으로서, 소벨 (Sobel) 검출법, 프리윗(Prewitt) 검출법, 로버츠(Roberts) 검출법, 컴퍼스(Compass) 검출법, 라플라시안 (Laplacian) 검출법, 캐니(Canny) 검출법 등 다양한 검출 알고리즘이 사용될 수 있다. 예를 들어, 캐니 검출법 은 2차 미분 마스크를 이용한 엣지 검출법의 일종으로, 잡음을 제거하여 신뢰도 높은 엣지를 검출할 수 있다. 검출된 엣지 정보를 이용하여 배경 영역에 대한 라벨링 작업을 수행한다(S220). 캐니 검출법과 같은 알고리즘을 이용해 검출된 엣지 정보만으로 라벨링 작업을 수행할 수도 있으나 그 정확도가 100%는 아니다. 따라서, 자율 주행과 같이 안전이 필수적인 분야에서는 반드시 인간에 의한 검토가 병행되어야 한다. 본 발명에서는, 표시부가 검출된 엣지 정보를 작업자에게 제공하고, 작업자는 상기 엣지 정보들 중에서 배 경 영역에 대해서만 선택적으로 라벨링 작업을 수행할 수 있다. 예를 들면, 상기 검출된 엣지 정보를 가이드로 활용하여, 작업자는 경계면의 꼭지점을 보다 쉽고 빠르게 선택할 수 있다. 상기 선택된 배경 영역의 꼭지점 정 보는 입력부를 통해 라벨링부로 제공되고, 라벨링부는 획득한 꼭지점 정보를 이용하여 보다 정확한 라벨링 이미지를 생성할 수 있다. 한편, 상기 엣지 검출 단계(S210)에서는 배경 영역뿐 아니라 객체 영역에 존재하는 모든 상에 대한 엣지가 함께 검출될 수 있다. 그러나 상기 배경 영역에 대한 라벨링 단계(S220)에서는 배경 영역에 대해서만 라벨링 작업을 수행하면 되기 때문에, 작업 속도 및 배경 영역의 라벨링 정확도를 향상시킬 수 있다. 이어서 객체 영역에 대한 라벨링 작업을 수행한다(S300). 구체적으로, 상기 획득한 영상 이미지로부터 객체 영역을 검출한다(S310). 상기 객체 영역 검출 단계는 영상 이미지에서 관심 영역(Region Of Interest, ROI)을 검출하는 것으로, 관심 영 역에 대한 후보 영역을 찾고 학습된 모델을 이용하여 그 후보 영역에 대한 객체의 종류와 위치를 예측할 수 있 다. 예를 들면, 에이다부스트(Adaboost) 알고리즘, 템플릿 매칭(Template Matching) 알고리즘, 합성곱 신경망 (Convolutional Neural Network, CNN) 알고리즘 등 다양한 검출 알고리즘이 사용될 수 있다. 검출된 객체 영역 정보를 이용하여 객체 영역에 대한 라벨링 작업을 수행한다(S320). 상기 CNN 알고리즘을 이용해 검출된 객체 정보만으로 라벨링 작업을 수행할 수도 있으나, 정확도를 높이기 위해 서는 인간에 의한 검토가 병행될 필요가 있다. 특히, 주행 상태의 도로 이미지와 같이 객체의 크기가 작거나 여 러 객체가 겹쳐있는 경우에는 CNN 알고리즘이 객체를 정확하게 인식하지 못할 수 있다. 본 발명에서는, 표시부가 검출된 객체 정보 및 엣지 정보를 작업자에게 제공할 수 있고, 작업자는 상기 객 체 정보 및 엣지 정보를 이용하여 객체 영역에 대한 라벨링 작업을 수행할 수 있다. 예를 들면, 상기 검출된 객 체의 위치 정보를 가이드로 활용하여, 작업자는 경계면의 꼭지점을 보다 쉽고 빠르게 선택할 수 있다. 또한, 작 업자는 화면을 확대하거나 또는 상기 엣지 검출 단계(S210)에서 획득한 엣지 정보를 함께 고려할 수 있기 때문 에, 작업 속도 및 객체 영역의 라벨링 정확도를 향상시킬 수 있다. 상기 선택된 꼭지점 정보는 입력부를 통해 라벨링부로 제공되고, 라벨링부는 획득한 꼭지점 정보를 이용하여 보다 정확한 객체 영역의 라벨링 이미지를 생성할 수 있다. 한편, 객체 영역에 대한 라벨링 이미지를 생성하는 단계(S300)는 배경 영역에 대한 라벨링 이미지를 생성하는 단계(S200) 이후에 수행되는 것으로 설명하였으나, 본 발명이 이에 제한되는 것은 아니며 그 순서가 달라지거나 또는 동시에 수행될 수도 있다. 예를 들면, 표시부가 두 개 이상의 디스플레이 장치를 포함하고, 상기 디스 플레이 장치에 검출된 엣지 정보(S210)와 객체 정보(S310)가 각각 표시되고, 두 명 이상의 작업자가 배경 영역 과 객체 영역을 나누어 동시에 작업을 수행할 수 있다. 마지막으로, 라벨링부는 배경 영역이 라벨링된 이미지에 객체 영역이 라벨링된 이미지를 합성함으로써 (S400), 딥 러닝을 위한 학습용 라벨링 이미지를 생성한다(S500). 상술한 바와 같이, 본 발명에 따른 딥 러닝을 위한 라벨링 이미지 생성 방법은, 배경 영역과 객체 영역을 나누 어 라벨링 작업을 수행한 이후 이들을 합성함으로써 보다 빠르게 정확한 라벨링 이미지를 생성할 수 있다. 특히, 배경 영역 라벨링 작업에서는 객체 영역을 신경 쓸 필요가 없어 작업 속도가 향상될 수 있고, 객체 영역 라벨링 작업에서는 화면 확대 등 다양한 후처리가 가능하기 때문에 라벨링 결과물의 정확도를 향상시킬 수 있다. 이상에서는 본 발명의 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구 의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변 경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2019-0106608", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 예시적인 실시예들에 따른 라벨링 이미지 생성 장치를 나타내는 블록도이다. 도 2는 본 발명에 따른 딥 러닝을 위한 라벨링 이미지 생성 방법의 단계들을 설명하기 위한 순서도이다. 도 3은 라벨링 이미지를 생성하기 위해 입력되는 영상 이미지의 예를 나타내는 도면이다. 도 4는 도 3에서 배경 영역의 엣지를 검출한 이미지를 나타내는 도면이다. 도 5는 도 3에서 객체 영역의 위치를 검출한 이미지를 나타내는 도면이다. 도 6은 도 5의 객체 영역을 라벨링한 이미지를 나타내는 도면이다. 도 7은 배경 영역과 객체 영역을 합성하고, 이를 채색하여 라벨링한 이미지를 나타내는 도면이다."}
