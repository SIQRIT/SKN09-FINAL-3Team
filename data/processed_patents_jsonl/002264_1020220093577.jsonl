{"patent_id": "10-2022-0093577", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0015836", "출원번호": "10-2022-0093577", "발명의 명칭": "중첩된 객체를 분리하기 위한 방법 및 장치", "출원인": "(주)트루엔", "발명자": "표성백"}}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,입력 영상을 획득하는 카메라 모듈;메모리;및상기 카메라 모듈 및 상기 메모리와 작동적으로 연결된 프로세서를 포함하고,상기 프로세서는상기 입력 영상으로부터 사람의 머리(head) 상단부터 사람의 어깨선에 대응하는 머리 객체(object)를 포함하는복수의 바운딩 박스(bounding box)들을 생성하고, 복수의 바운딩 박스 들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 상기 복수의바운딩 박스(bounding box)들 중 상기 머리 객체에 대응하는 적어도 하나의 바운딩 박스 를 결정하고,상기 입력 영상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수의 바운딩 박스(boundingbox)들을 생성하고, 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 상기 복수의 바운딩 박스(bounding box)들 중 상기 사람 객체에 대응하는 적어도 하나의 바운딩 박스를 결정하며,하나의 사람 객체에 대응하는 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출되는 것에기반하여 상기 바운딩 박스를 상기 메모리 상에 저장하고,상기 메모리 상에 저장된 바운딩 박스 내에는 하나의 사람 객체가 아닌 복수의 머리 객체들의 수만큼의 사람 객체들이 위치하는 것으로 결정하는 전자 장치."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 프로세서는상기 메모리 상에 저장된 바운딩 박스의 영역 내 포함된 제 1 머리 객체 및 제 2 머리 객체에 대해, 상기 제 1머리 객체는 제 1 사람에 대응하는 것으로 결정하고, 상기 제 2 머리 객체는 제 2 사람에 대응하는 것으로 결정하는 전자 장치."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 프로세서는상기 제 1 머리 객체의 바운딩 박스의 상단 y축 좌표 정보와 상기 메모리 상에 저장된 바운딩 박스의 하단 y축좌표 정보에 기반하여 상기 제 1 사람의 세로 길이를 결정하고, 상기 제 1 머리 객체의 좌측 및 우측의 x축 좌표 정보에 기반하여 제 1 사람의 가로 길이를 결정하며,상기 제 2 머리 객체의 바운딩 박스의 상단 y축 좌표 정보와 상기 메모리 상에 저장된 바운딩 박스의 하단 y축좌표 정보에 기반하여 상기 제 2 사람의 세로 길이를 결정하고, 상기 제 2 머리 객체의 좌측 및 우측의 x축 좌표 정보에 기반하여 제 2 사람의 가로 길이를 결정하는 전자 장치.공개특허 10-2024-0015836-3-청구항 4 제 1항에 있어서,상기 객체 검출 모델은 비 최대치 억제(NMS) 기법 및 머리(head) 객체에 대한 복수의 바운딩 박스 들의 IoU(intersection over union)를 기반으로, 머리(head) 객체에 대응하는 바운딩 박스를 결정하며,상기 머리 객체에 대응하는 바운딩 박스 는 사람의 머리 상단부터 사람의 어깨선까지 해당하는 영역을 포함하는 전자 장치."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 프로세서는상기 복수의 바운딩 박스 간 서로 겹치는 부분이 사전에 설정된 제 1 수준을 초과함에 기반하여, 복수의 바운딩박스 들을 하나의 물체인 것으로 결정하고, 상기 복수의 바운딩 박스 간 서로 겹치는 부분이 사전에 설정된 제 1 수준 미만인 것에 기반하여, 복수의 바운딩 박스들을 둘 이상의 물체인 것으로 결정하는 전자 장치."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "전자 장치의 사람 객체 검출 방법에 있어서,입력 영상으로부터 사람의 머리(head) 상단부터 사람의 어깨선에 대응하는 머리 객체(object)를 포함하는 복수의 바운딩 박스(bounding box)를 생성하는 동작; 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 상기 복수의 바운딩 박스(bounding box) 중 상기 머리 객체에 대응하는 적어도 하나의 바운딩 박스를 결정하는 동작;상기 입력 영상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수의 바운딩 박스(boundingbox)를 생성하는 동작;복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 상기 복수의 바운딩 박스(bounding box) 중 상기 사람 객체에 대응하는 적어도 하나의 바운딩 박스를 결정하는 동작;하나의 사람 객체에 대응하는 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출되는 것에기반하여 상기 바운딩 박스를 메모리 상에 저장하는 동작;및 상기 메모리 상에 저장된 바운딩 박스 내에는 하나의 사람 객체가 아닌 복수의 머리 객체들의 수만큼의 사람 객체들이 위치하는 것으로 결정하는 동작을 포함하는 방법."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 메모리 상에 저장된 바운딩 박스 내에는 하나의 사람 객체가 아닌 복수의 머리 객체들의 수만큼의 사람 객체들이 위치하는 것으로 결정하는 동작은상기 메모리 상에 저장된 바운딩 박스의 영역 내 포함된 제 1 머리 객체 및 제 2 머리 객체에 대해, 상기 제 1머리 객체는 제 1 사람에 대한 정보인 것으로 결정하는 동작;및공개특허 10-2024-0015836-4-상기 제 2 머리 객체는 제 2 사람에 대한 정보인 것으로 결정하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 제 1 머리 객체의 바운딩 박스의 상단 y축 좌표 정보와 상기 메모리 상에 저장된 바운딩 박스의 하단 y축좌표 정보에 기반하여 상기 제 1 사람의 세로 길이를 결정하고, 상기 제 1 머리 객체의 좌측 및 우측의 x축 좌표 정보에 기반하여 제 1 사람의 가로 길이를 결정하는 동작;및상기 제 2 머리 객체의 바운딩 박스의 상단 y축 좌표 정보와 상기 메모리 상에 저장된 바운딩 박스의 하단 y축좌표 정보에 기반하여 상기 제 2 사람의 세로 길이를 결정하고, 상기 제 2 머리 객체의 좌측 및 우측의 x축 좌표 정보에 기반하여 제 2 사람의 가로 길이를 결정하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6항에 있어서,상기 객체 검출 모델은 비 최대치 억제(NMS) 기법 및 머리(head) 객체에 대한 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 머리(head) 객체에 대응하는 바운딩 박스를 결정하며, 상기 머리 객체에 대응하는 바운딩 박스는 사람의 머리 상단부터 사람의 어깨선까지 해당하는 영역을 포함하는 방법."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 객체 검출 모델을 이용하여 복수의 머리 객체를 각각 구분하여 검출하는 동작은상기 복수의 바운딩 박스 간 서로 겹치는 부분이 사전에 설정된 제 1 수준을 초과함에 기반하여, 복수의 바운딩박스들을 하나의 물체인 것으로 결정하는 동작;및상기 복수의 바운딩 박스 간 서로 겹치는 부분이 사전에 설정된 제 1 수준 미만인 것에 기반하여, 복수의 바운딩 박스들을 둘 이상의 물체인 것으로 결정하는 동작을 더 포함하는 방법."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서,입력 영상을 획득하는 카메라 모듈;메모리;및상기 카메라 모듈 및 상기 메모리와 작동적으로 연결된 프로세서를 포함하고,상기 프로세서는상기 입력 영상으로부터 사람의 머리(head) 상단부터 사람의 어깨선에 대응하는 머리 객체(object)를 포함하는복수의 바운딩 박스(bounding box)들을 생성하고, 복수의 바운딩 박스 들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 상기 복수의바운딩 박스(bounding box)들 중 상기 머리 객체에 대응하는 적어도 하나의 헤드 박스(head bounding box)를 결정하고,공개특허 10-2024-0015836-5-상기 입력 영상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수의 바운딩 박스(boundingbox)들을 생성하고, 상기 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 상기 복수의 바운딩 박스(bounding box)들 중 IoU가 가장 높은 제 1 바운딩 박스의 정보를 상기 메모리 상의 제 1 영역에저장하고, 상기 제 1 바운딩 박스 외에 나머지 바운딩 박스들의 정보를 상기 메모리 상의 상기 제 1 영역이 아닌 다른 제 2 영역에 저장하며,상기 제 1 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출되는 것에 기반하여 상기 메모리 상의 상기 제 2 영역에 저장된 나머지 바운딩 박스들에 대해 비 최대치 억제(NMS) 기법을 실행하고, 상기 헤드 박스(head bounding box)를 기준으로 IoU를 계산하며,상기 제 2 영역 상에서 사전에 설정된 수준을 초과하는 IoU를 갖는 바운딩 박스가 검출되지 않는 것에 대응하여상기 제 1 바운딩 박스의 정보에 기반하여 상기 입력 영상 내 사람의 위치, 수, 크기 중 적어도 어느 하나를 결정하는 전자 장치."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 프로세서는상기 제 2 영역 상에서 사전에 설정된 수준을 초과하는 IoU를 갖는 제 2 바운딩 박스가 검출되는 것에 대응하여상기 메모리로부터 상기 제 2 바운딩 박스의 정보를 수신하고,수신된 상기 제 2 바운딩 박스의 정보에 기반하여 상기 입력 영상 내 사람의 위치, 수, 크기 중 적어도 어느 하나를 결정하는 전자 장치."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11항에 있어서,상기 제 1 바운딩 박스의 정보는 가로 길이, 세로 길이, x축 좌표 정보 및 y축 좌표 정보를 포함하고,상기 프로세서는 상기 헤드 박스의 상단 y축 좌표 정보와 상기 제 1 바운딩 박스의 하단 y축 좌표 정보에 기반하여 영상 내 사람의 세로 길이를 결정하고,상기 헤드 박스의 좌측 및 우측의 x축 좌표 정보에 기반하여 영상 내 사람의 가로 길이를 결정하는 전자 장치."}
{"patent_id": "10-2022-0093577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12항에 있어서,상기 제 2 바운딩 박스의 정보는 가로 길이, 세로 길이, x축 좌표 정보 및 y축 좌표 정보를 포함하고,상기 프로세서는 상기 헤드 박스의 상단 y축 좌표 정보와 상기 제 2 바운딩 박스의 하단 y축 좌표 정보에 기반하여 영상 내 사람의 세로 길이를 결정하고,제 2 바운딩 박스의 좌측 및 우측의 x축 좌표 정보에 기반하여 영상 내 사람의 가로 길이를 결정하는 전자장치."}
{"patent_id": "10-2022-0093577", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예들에 따른 전자 장치는 입력 영상을 획득하는 카메라 모듈, 메모리 및 카메라 모듈 및 메모리와 작 동적으로 연결된 프로세서를 포함할 수 있다. 프로세서는 입력 영상으로부터 사람의 머리(head) 상단부터 사람의 어깨선에 대응하는 머리 객체(object)를 포함하는 복수의 바운딩 박스(bounding box)를 생성할 수 있다. 프로세 (뒷면에 계속)"}
{"patent_id": "10-2022-0093577", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서는 영상객체 탐지를 수행하는 전자 장치 및 방법에 관한 것이다. 구체적으로 전자 장치는 비디오 영상에 포함되는 복수의 이미지를 대상으로 머신 러닝을 수행하고, 이를 기반으로 이미지에 포함되는 객체 중 사람을탐지할 수 있다."}
{"patent_id": "10-2022-0093577", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상으로부터 객체를 인식하는 기술은 영상 처리나 패턴 인식, 컴퓨터 비전과 신경망 같은 다양한 분야에 걸쳐 서 활발히 연구되고 있고, 상업적, 법적으로 수많은 응용분야를 가지고 있다. 법규 위반, 범죄자 추적 및 방범 환경과 같이 사람 인식이 필요한 다양한 분야에서 CCTV(closed-circuit television)가 이용될 수 있다. 근래 방범 환경에 관한 수요가 증가하면서 CCTV 및 이를 이용한 사물 인식용 장 치의 활용도가 높아지고 있다. CCTV 영상 속에서 원하는 객체, 예를 들어 사람이나 자동차 번호판 등을 보다 정확하게 인식하기 위해 머신 러 닝 기술을 사용하고 있다. 본 발명의 배경이 되는 기술은 대한민국 공개특허공보 제10-2021-0081852호(2019.12.24)에 개시되어 있다. 또한, 본 발명의 배경이 되는 기술은 대한민국 공개특허공보 제10-2020-0036079호(2018.09.18)에 개시되어 있다."}
{"patent_id": "10-2022-0093577", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "컴퓨터 비전에서의 객체 인식이란, 한 영상과 모델 데이터베이스가 주어졌을 때, 영상 내의 객체와 가장 유사한 모델을 데이터베이스에서 검색해 내는 일련의 과정을 의미할 수 있다. 그러나, 동일한 객체라 하더라도 각각의 영상에 서는 객체의 크기, 방향, 위치, 포즈 등이 다르게 나타날 수 있고, 또한 한 영상 내에 여러 개의 객체가 포함되어 있거나 아니면 해당 객체가 다른 객체에 의해 가려져 그 일부분만 볼 수 있는 경우 복수의 객체들을 분리하여 인식하기가 어려울 수 있다. 특히, 방범 환경에서, 사람으로 인식되는 객체가 다른 사물 또는 다른 사람과 중첩되는 경우, 복수의 객체들을 분리하여 인식하기가 어려울 수 있고, 목표로 하는 사람을 계속하여 추적하기 어려울 수 있다."}
{"patent_id": "10-2022-0093577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예들에 따른 전자 장치는 입력 영상을 획득하는 카메라 모듈, 메모리 및 카메라 모듈 및 메모리와 작동적으로 연결된 프로세서를 포함할 수 있다. 프로세서는 입력 영상으로부터 사람의 머리(head) 상단부터 사 람의 어깨선에 대응하는 머리 객체(object)를 포함하는 복수의 바운딩 박스(bounding box)를 생성할 수 있다. 프로세서는 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복 수의 바운딩 박스(bounding box) 중 머리 객체에 대응하는 적어도 하나의 바운딩 박스를 결정할 수 있다. 프로 세서는 입력 영상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수의 바운딩 박스(bounding box)를 생성하고, 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하 여 복수의 바운딩 박스(bounding box) 중 사람 객체에 대응하는 적어도 하나의 바운딩 박스를 결정할 수 있다. 프로세서는 하나의 사람 객체에 대응하는 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출 되는 것에 기반하여 바운딩 박스를 메모리 상에 저장하고, 메모리 상에 저장된 바운딩 박스 내에는 하나의 사람 객체가 아닌 복수의 머리 객체들의 수만큼의 사람 객체들이 위치하는 것으로 결정할 수 있다. 다양한 실시예들에 따른 전자 장치의 사람 객체 검출 방법은 입력 영상으로부터 사람의 머리(head) 상단부터 사 람의 어깨선에 대응하는 머리 객체(object)를 포함하는 복수의 바운딩 박스(bounding box)를 생성하는 동작, 복 수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복수의 바운딩 박 스(bounding box) 중 머리 객체에 대응하는 적어도 하나의 바운딩 박스를 결정하는 동작을 포함할 수 있다. 전 자 장치의 사람 객체 검출 방법은 입력 영상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수 의 바운딩 박스(bounding box)를 생성하는 동작 및 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복수의 바운딩 박스(bounding box) 중 사람 객체에 대응하는 적어도 하나의 바운딩 박스를 결정하는 동작을 포함할 수 있다. 전자 장치의 사람 객체 검출 방법은 하나의 사람 객체에 대 응하는 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출되는 것에 기반하여 바운딩 박스를 메모리 상에 저장하는 동작 및 메모리 상에 저장된 바운딩 박스 내에는 하나의 사람 객체가 아닌 복수의 머리 객체들의 수만큼의 사람 객체들이 위치하는 것으로 결정하는 동작을 포함할 수 있다."}
{"patent_id": "10-2022-0093577", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 문서의 다양한 실시예들에 따르면, 하나의 객체에 대해 얻어지는 복수의 후보 바운딩 박스(bounding box)들 로부터 머리 영역을 기반으로 정확하게 객체가 위치하는 영역 및 객체의 수를 결정할 수 있다. 일 실시예에 따르면, 사람 객체를 인식할 수 있도록 학습의 대상이 되는 머리 영역을 다르게 설정하여 추가적인 메모리나 연산을 필요로 하지 않고 중첩된 두 사람을 정확하게 구분해낼 수 있다. 일 실시예에 따르면, 사람 객체를 인식하는 머리 영역에 사람의 머리 형상 뿐 아니라 어깨선까지의 영역을 추가 하여 영상에 위치하는 다른 사물(예: 공, 가방 등)을 사람의 형상으로 잘못 인식하는 것을 방지할 수 있다. 일 실시예에 따르면, 사람 객체를 인식하는 영역을 머리부터 어깨선까지의 영역으로 한정하기 때문에, 사람의 전신을 기준으로 사람 객체를 인식하는 경우와 비교하여 중첩되어 있는 사람을 상대적으로 더 정확하게 구분해 낼 수 있다."}
{"patent_id": "10-2022-0093577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1a는 전자 장치에서 합성곱 신경망 모델(convolutional neural network, CNN) 기반 인간 객체 탐지 방법을 도시한 것이다. 전자 장치는 CNN과 같은 딥 러닝 기술을 이용하여 객체를 탐지할 수 있다. 객체는 이미지 내에 포함된 사람, 자 동차, 동물, 식물 등을 의미할 수 있으나, 이에 한정되는 것은 아니다. 비교 실시예에 따른 전자 장치는 이미지 센서를 이용하여 특정 공간에 대한 이미지를 생성할 수 있다. 일반적인 전자 장치는 생성된 이미지의 픽셀값에 기초하여 바운딩 박스(bounding box)(101, 103, 105)를 생성할 수 있다. 도 1a에 도시되는 전자 장치는 하나의 객체에 대해 얻어지는 복수의 바운딩 박스(101, 103, 105)로부터 객체가 위치하는 영역을 결정할 수 있다. 바운딩 박스는 생성된 이미지의 픽셀값에 기초하여, 객체가 위치하는 영 역을 포함시키도록 구성될 수 있다. 도 1a에 도시된 전자 장치는 바운딩 박스가 객체와 일대일로 대응하는 것으로 결정할 수 있다. 서로 다른 객체 에 대응하는 바운딩 박스들(101, 103, 105)은 객체들이 가까이 존재하는 경우, 서로 중첩되는 영역을 가질 수 있다. 서로 다른 객체에 대응하는 바운딩 박스들(101, 103, 105)은 서로 중첩되면, 전자 장치 내에서 측정되는 단위 영역 당 바운딩 박스의 개수가 증가할 수 있다.도 1a에 도시된 전자 장치는 특정한 물체의 종류(예: 사람 또는 자동차)에 대응하는 복수의 바운딩 박스들을 메 모리 상에 저장할 수 있다. 바운딩 박스의 크기는 특정한 물체가 일반적으로 차지하는 영역의 크기와 대응될 수 있다. 비교 실시예에 따른 전자 장치는 바운딩 박스의 크기 및 이미지 상의 픽셀 정보를 기반으로 물체의 종류 (class)를 결정할 수 있다. 비교 실시예에 따른 전자 장치는 복수의 바운딩 박스들 간 겹쳐진 면적의 비율(IOU: intersection over union)에 기반하여 중복되는 바운딩 박스를 제거할 수 있다. 비교 실시예에 따른 전자 장치 는 제거되지 않은 바운딩 박스에 기반하여 객체의 수 및 객체가 위치한 영역을 인식할 수 있다. 일 실시예에 따르면, 프로세서는 복수의 바운딩 박스들 각각에 대한 신뢰도(confidence) 점수에 기초한 비최대 값 억제(Non-Maximum Suppression, NMS) 알고리즘을 이용하여 복수의 바운딩 박스 중 중복되는 바운딩 박스를 제거할 수 있다. 프로세서는 신뢰도(confidence) 점수가 설정된 수준 미만인 바운딩 박스를 제거할 수 있다. 동일한 종류(class)의 바운딩 박스에 대해, 예상 점수(predict score)가 상대적으로 높은 바운딩 박스는 상대적 으로 높은 신뢰도(confidence) 점수를 얻을 수 있다. 예상 점수(predict score)는 바운딩 박스 와 바운딩 박스 가 겹쳐진 면적의 비율에 비례하여 결정될 수 있다. 예를 들어, 특정한 물체의 종류(예: 사람 또는 자동차)에 대응하는 바운딩 박스와 바운딩 박스가 일정 수준(예: 약 90%)을 초과하여 중복되는 경우, 프로세서는 바 운딩 박스에 상대적으로 높은 예상 점수(predict score)를 부여할 수 있다. 예상 점수(predict score)는 복수의 바운딩 박스들이 겹쳐진 면적의 비율(IOU: intersection over union)에 기반하여 결정될 수 있다. 프로 세서는 예상 점수(predict score)에 기반하여 바운딩 박스가 특정한 물체를 지시하는 것으로 결정할 수 있 다. 또한, 프로세서는 바운딩 박스가 위치하는 영역 상에 물체가 위치하는 것으로 결정할 수 있다. 복수의 객체가 이미지 상에 존재하는 경우, 바운딩 박스와 바운딩 박스가 겹쳐진 면적의 비율(IOU: intersection over union)에 기반하여 물체의 종류 및 위치를 결정하는 방법은 한계를 가질 수 있다. 이러한 한 계는 이하 도 1b에서 설명될 것이다. 도 1b는 이미지에 복수의 객체가 포함된 경우 발생할 수 있는 문제를 설명하는 도면이다. 도 1b는, 전자 장치가, 제 1 사람에 대응하는 제 1 물체 및 제 2 사람에 대응하는 제 2 물체가 겹쳐 져 있는 이미지에 대해 객체 인식을 하는 경우를 도시한다. 도 1b에 따른 전자 장치는 프로세서의 제어 하에, 바운딩 박스에 기반하여 물체의 종류 및 위치를 결정할 수 있 다. 도 1b에 따른 전자 장치는 이미지 센서를 통해 획득한 이미지 상에서 제 1 물체에 대응하는 바운딩 박 스를 표시할 수 있다. 도 1b에 따른 전자 장치는 이미지 센서를 통해 획득한 이미지 상에서 제 1 물체에 대응하는 바운딩 박스를 생성할 수 있다. 도 1b에 따른 전자 장치는 이미지 상의 픽셀 정보에 기반하여, 이미지 상에서 표시되는 물체가 '사람'이라고 결정할 수 있다. 도 1b에 따른 전자 장치는 메모리 상에서 '사람' 에 대 응되는 바운딩 박스를 인식하고, 인식된 바운딩 박스에 기반하여 이미지 센서에서 획득된 이미지 상에 바운딩 박스를 표시할 수 있다. 도 1b에 따른 전자 장치는 바운딩 박스의 크기 및 위치에 기반하여 제 1 물체의 위치 및 종류를 결정할 수 있다. 도 1b에 따른 전자 장치는 복수의 바운딩 박스들 각각에 대한 신뢰도 점수에 기초한 비최대값 억제(non- maximum suppression, NMS) 알고리즘을 이용하여 복수의 바운딩 박스들 중 중복되는 바운딩 박스를 제거할 수 있다. 제 1 물체 및 제 2 물체가 일정 수준을 초과하여 겹쳐진 상태에서, 도 1b에 따른 전자 장치는 이미지 상의 제 2 물체를 구분하기 어려울 수 있다. 동일한 종류(class)의 바운딩 박스들에 대해, 예상 점 수(predict score)가 상대적으로 높은 바운딩 박스는 상대적으로 높은 신뢰도(confidence) 점수를 얻을 수 있다. 예상 점수(predict score)는 복수의 바운딩 박스들과 물체가 겹쳐진 면적의 비율에 비례하여 결정될 수 있다. 제 2 물체에 대응하는 바운딩 박스는 이미지 상의'사람'의 형상을 포함하는 수준의 크기를 가질 수 있다. 제 2 물체에 대응하는 바운딩 박스 가 이미지 상의'사람의 전신'을 포함하는 수준의 크기를 갖는 경우, 제 2 물체에 대응하는 바운딩 박스의 영역은 제 1 물체에 대응하는 바운딩 박스의 영역과 일정 부분 중 복될 수 있다. 도 1b에 따른 전자 장치는 제 2 물체에 대응하는 바운딩 박스의 영역이 제 1 물체에 대응하는 바운딩 박스의 영역과 임계값을 초과하여 중첩됨에 기반하여 제 1 물체와 제 2 물체를 하나 의 물체인 것으로 결정할 수 있다. 도 1b에 따른 전자 장치는 제 2 물체에 대응하는 바운딩 박스의 영역이 제 1 물체에 대응하는 바운딩 박스의 영역과 임계값을 초과하여 중첩됨에 기반하여 제 2 물체와 대응 하는 바운딩 박스를 제거할 수 있다. 복수의 사람들이 이미지 상에 존재함에도 불구하고, 제 1 물체와 제 2 물체를 하나의 물체인 것으로 결정하는 경우, 도 1b에 따른 전자 장치는 제 1 물체에 대응하는 바운딩 박스를 생성하고, 제 2 물체에 대응하는 바운딩 박스를 생성하지 않을 수 있다. 전자 장치는 제 2 물 체에 대응하는 물체를 인식하기 어려울 수 있다. 제 1 물체와 대응하는 바운딩 박스는 제 1 물체 의 전신을 기준으로 표시될 수 있다. 또는 제 1 물체와 대응하는 바운딩 박스는 제 1 물체의 머 리를 기준으로 표시될 수 있다. 바운딩 박스가 제 1 물체의 전신을 기준으로 표시되는 경우, 상대적으로 크기가 작은 머리를 기준으로 표시되는 경우에 비해 복수의 바운딩 박스들(110, 120) 간 중복되는 부분이 상대 적으로 많이 생성될 수 있다. 도 1b에 따른 전자 장치는 제 1 물체의 바운딩 박스와 제 2 물체의 바운딩 박스가 중복되는 상황에서 임계 값을 상대적으로 높게 조절하여 물체를 구분할 수도 있다. 도 1b에 따른 전자 장치는 임계값이 상대적으로 높게 설정되는 경우, 임계값이 낮게 설정되는 경우 삭제 처리하였을 바운딩 박스들을 삭제하지 않을 수 있다. 전자 장치는 삭제되지 않은 복수의 바운딩 박스들에 기반하여 복수의 물체들이 존재하는 것으로 결정할 수 있다. 그러나 임계값을 상대적으로 높게 설정하는 경우, 도 1b에 따른 전자 장치는 하나의 물체가 촬영된 상황에서 복 수의 물체들이 존재하는 것으로 잘못 결정할 수 있다. 예를 들어, 도 2의 상황에서, 전자 장치는 임계값을 상대 적으로 높게 설정하여 제 1 물체와 제 2 물체를 다른 물체인 것으로 결정할 수 있다. 그러나, 도 1b에 따른 전자 장치는 임계값을 상대적으로 높게 설정함으로 인하여 하나의 제 1 물체에 대해 복수의 물체들이 존재하는 것으로 잘못 결정할 수 있다. 임계값이 상대적으로 높게 설정되는 경우, 전자 장치는 하나의 물체에 대응하는 복수의 바운딩 박스들이 중첩되는 부분이 일정 수준을 초과하여야 하나의 물체가 존재 하는 것으로 결정할 수 있다. 전자 장치는 임계값이 높게 설정될수록 하나의 물체에 대응하는 복수의 바운딩 박 스들이 상대적으로 높은 비율로 중복되어야 바운딩 박스들 중 일부를 삭제할 수 있다. 복수의 바운딩 박스들은 중복되는 부분이 일정한 상황에서, 임계값이 낮게 설정되었으면 삭제될 수 있으나, 임계값이 높게 설정된 상황 에서는 삭제되지 않을 수 있다. 전자 장치는 실제로는 하나의 물체가 촬영된 상황에서 제거되지 않은 바운딩 박 스들에 기반하여 복수의 물체들이 있는 것으로 잘못 결정할 수 있다. 또는 전자 장치는 제거되지 않은 바운딩 박스들에 기반하여 실제 물체의 수보다 더 많은 물체들이 있는 것으로 잘못 결정할 수 있다. 도 1b에 따른 전자 장치는 제거되지 않은 복수의 바운딩 박스들에 기반하여, 복수의 물체들이 존재하는 것으로 결정할 수 있다. 도 1b에 따른 전자 장치는 하나의 물체가 존재하는 상황에서, 임계값이 높게 설정됨으로 인해 복수의 물체들이 존재하는 것으로 잘못 인식할 수 있다. 도 1b에 따른 전자 장치는 하나의 물체가 존재하는 상황에서 복수의 물체들이 존재하는 것으로 잘못 인식하는 것을 방지하기 위하여, 임계값을 상대적으로 낮게 설정시킬 수 있다. 도 1b에 따른 전자 장치는 임계값을 상대 적으로 낮게 설정하여, 하나의 제 1 물체에 대해 복수의 물체들인 것으로 잘못 인식할 확률을 감소시킬 수 있다. 그러나 도 1b에 따른 전자 장치는 임계값을 상대적으로 낮게 설정할 경우, 앞의 실시예처럼, 사전에 설정 된 수준을 초과하여 겹쳐진 제 1 물체 및 제 2 물체를 하나의 물체로 오인식할 수 있다. 임계값이 낮 게 설정될수록 하나의 물체에 대응하는 복수의 바운딩 박스들이 중첩되어 이미지 상에서 제거될 확률이 올라갈 수 있다. 복수의 바운딩 박스들은 임계값이 상대적으로 높게 설정되었으면, 이미지 상에서 제거되지 않을 수 있 으나 임계값이 상대적으로 낮게 설정된 상황에서 제거될 수 있다. 도 1b에 따른 전자 장치는 제거된 바운딩 박 스를 제외하고, 하나의 물체가 존재하는 것으로 결정할 수 있다. 도 1b에 따른 전자 장치는 복수의 물체들이 존 재하는 상황에서, 임계값이 낮게 설정됨으로 인해 바운딩 박스를 삭제하고, 하나의 물체가 존재하는 것으로 잘 못 인식할 수 있다. 도 1b에 따른 전자 장치는 임계값을 상대적으로 높게 설정하는 경우, 하나의 물체를 복수의 물체로 오인식하는 문제를 가질 수 있다. 도 1b에 따른 전자 장치는 임계값을 상대적으로 낮게 설정하는 경우, 복수의 물체(예: 제 1 물체 및 제 2 물체)를 하나의 물체로 오인식하는 문제를 가질 수 있다. 도 1b에 따른 전자 장치는 오인식 문제를 해결하기 위해 전자 장치가 임계값을 가변적으로 변경시킬 수 있다. 물체들을 가장 잘 구별할 수 있는 임계값은 이미지 상의 물체가 등장하는 상황에 기반하여 다르게 결정될 수 있 다. 도 1b에 따른 전자 장치는 물체가 등장하는 상황이 다양하기 때문에 임계값을 가변적으로 변경시키더라도 오인식을 발생시키지 않는 임계값을 결정하기는 어려울 수 있다. 도 1b에 따른 전자 장치는 결정된 임계값에 따 라 여전히 물체들을 잘못 인식할 가능성이 있다. 본 문서의 다양한 실시예들에 따른 전자 장치는 물체에 대응하는 바운딩 박스의 영역 크기를 사람 객체의 머리 또는 몸통과는 다르게 설정할 수 있다. 다양한 실시예들에 따른 전자 장치는 다르게 설정된 영역 크기를 갖는 바운딩 박스를 이용하여 학습을 수행할 수 있다. 다양한 실시예들에 따른 전자 장치는 바운딩 박스의 별도의 영역 크기를 기반으로 복수의 물체들이 중복되어 있는 상태에서, 오인식 없이 물체들을 구별해낼 수 있다. 이하 도 3에서는 다양한 실시예들에 따른 전자 장치의 객체 인식 방법에 대해 설명될 것이다. 도 2는 다양한 실시예들에 따른 전자 장치의 구성을 블록도로 도시한 것이다. 도 2를 참조하면, 전자 장치는 카메라 모듈, 메모리 및/또는 프로세서를 포함할 수 있다. 프로세서는 카메라 모듈 및/또는 메모리와 전기적 또는 작동적(operatively)으로 연결될 수 있 다. 다양한 실시예에 따르면, 카메라 모듈은 정지 영상 및/또는 동영상을 촬영할 수 있다. 일 실시예에 따르면, 카메라 모듈은 하나 이상의 렌즈들, 이미지 센서들, 이미지 시그널 프로세서들을 포함할 수 있다. 일 실시예에 따르면, 카메라 모듈은 예를 들면, 전자 장치가 설치된 도로 위, 주차장 내부와 같은 전 자 장치의 주위 환경으로부터 입사된 광을 전기적 신호로 변환하여 이미지 데이터(예: 제1이미지)를 생성 할 수 있다. 다양한 실시예에 따르면, 메모리는 전자 장치의 적어도 하나의 구성요소(예: 프로세서)에 의하 여 사용되는 다양한 데이터를 저장할 수 있다. 메모리는 디지털 데이터들을 일시적 또는 영구적으로 저장 하기 위한 것으로서 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 메모리는 프로세서에 의 하여 수행될 수 있는 다양한 인스트럭션(instruction)을 저장할 수 있다. 이와 같은 인스트럭션들은 프로세서 에 의하여 인식되고 실행될 수 있는 논리 연산, 데이터 입출력 등의 제어 명령을 포함할 수 있다. 일 실시 예에 따르면, 메모리는 소프트웨어로서 프로그램을 저장할 수 있고, 프로그램은 하나 이상의 알고리즘으로 구현된 모델을 포함할 수 있다. 메모리가 저장할 수 있는 데이터의 종류 및/또는 양에 대하여는 한정됨이 없을 것이나, 본 문서에서는 다양한 실시예들에 따른 사람을 인식하는 프로세서의 동작과 관련된 메모리의 구성 및 기능에 대하여만 설명하기로 한다. 일 실시예에 따르면, 메모리는 객체 검출 모델을 저장할 수 있다. 객체 검출 모델은, 딥러닝 기반의 알고 리즘을 이용하여 학습된 모델일 수 있다. 예를 들면, 객체 검출 모델은 합성곱 신경망(CNN: convolution neural network) 알고리즘에 기초하여 입력된 이미지 내에서 객체들이 존재하는 영역을 검출하도록 학습된 모델일 수 있다. 일 실시예에 따르면, 객체 검출 모델은 객체 이미지 데이터를 이용하여 학습된 모델일 수 있다. 객체 검 출 모델은 메모리에 저장되어 전자 장치의 프로세서로 하여금 정해진 연산을 수행하도록 하는 인스트럭션을 포함할 수 있다. 객체는 이미지 내에 포함된 사람, 자동차, 동물, 식물 등을 의미할 수 있으나, 이에 한정되는 것은 아니다. 이하에서는 객체는 이미지 내에 포함된 사람을 의미하는 용어로 사용될 수 있다. 객체 검출은 이미지 내에 포함된 객체 주변을 둘러싸는 바운딩 박스를 이용하여 이미지 내에 포함된 객체를 검 출하는 동작을 의미할 수 있다. 일 실시예에 따르면, 메모리는 판별 모델을 저장할 수 있다. 판별 모델은, 인공지능 알고리즘을 이용하여 생성된 모델일 수 있다. 판별 모델은, 딥러닝 기반의 알고리즘을 이용하여 학습된 모델일 수 있다. 예를 들면, 판별 모델은 합성곱 신경망(CNN: convolution neural network) 알고리즘에 기초하여 객체(예: 사람)를 확인하도 록 학습된 모델일 수 있다. 일 실시예에 따르면, 판별 모델은 사람의 전체적인 형상, 사람의 머리, 사람의 머리 및 어깨를 포함하는 부분별 이미지와 연계된 메타데이터(metadata)를 입력 받아 학습된 모델일 수 있다. 메타데 이터는 특정한 목적을 위해 만들어진 데이터 또는 특정한 목적을 위해 수집된 데이터를 의미할 수 있다. 판별 모델은 메모리에 저장되어 전자 장치의 프로세서로 하여금 정해진 연산을 수행하도록 하는 인스 트럭션을 포함할 수 있다. 판별 모델은, CNN 알고리즘에 기초하여 학습된 모델로서, 복수의 convolution 레이어 를 포함할 수 있다. 각각의 레이어는 복수개의 convolution 필터를 포함하고, 각각의 필터는 이미지의 특성값에 가중치를 부여할 수 있다. 일 실시예에 따르면, 판별 모델은, 미리 정의된 손실 함수(loss function)를 이용한 방식으로 학습된 모델일 수 있다. 일 실시예에 따르면, 메모리는 OCR 모델을 저장할 수 있다. OCR 모델은 CNN(convolution neural network) 알고리즘을 기초로 입력된 이미지와 대응되는 문자 데이터를 출력하도록 학습된 모델일 수 있다. OCR 모델은 메 모리에 저장되어 전자 장치의 프로세서로 하여금 정해진 연산을 수행하도록 하는 인스트럭션을 포함할 수 있다. 일 실시예에 따르면, 프로세서는 메모리에 저장된 프로그램을 실행하여 전자 장치의 적어도 하 나의 다른 구성 요소(예: 카메라 모듈)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 일 실시예에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 프로세서는 다른 구성요소(예: 카메 라 모듈)로부터 수신된 데이터를 휘발성 메모리(예: 메모리)에 저장하고, 휘발성 메모리에 저장된 데 이터를 처리하고, 결과 데이터를 비휘발성 메모리에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 인 공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델(예: 번호판 검출 모델, 판별 모 델, OCR 모델)은 기계 학습(예: CNN 알고리즘에 기초한 딥러닝)을 통해 생성될 수 있다. 프로세서가 수행 할 수 있는 동작, 연산 및 데이터 처리의 종류 및/또는 양에 대하여는 한정됨이 없을 것이나, 본 문서에서는 다 양한 실시예들에 따른 전자 장치가 촬영한 이미지로부터 객체(예: 사람)의 수 및 위치를 인식하는 동작과 관련된 프로세서의 구성 및 기능에 대하여만 설명하기로 한다. 다양한 실시예에 따르면, 프로세서는 카메라 모듈을 제어하여 제1이미지를 획득할 수 있다. 프로세서 는 적어도 하나의 사람을 촬영할 수 있다. 일 실시예에 따르면, 전자 장치는 노면, 인도와 같은 사람 이 이동 및 정지할 수 있는 공간에 설치될 수 있다. 이는 일 예시일 뿐 전자 장치가 설치될 수 있는 장소 는 이것으로 한정되는 것은 아니다. 일 실시예에 따르면, 전자 장치는 사람이 이동 및 정지할 수 있는 공간에 설치 되어, 하나 이상의 사람이 촬영된 이미지(예: 제1이미지)를 촬영할 수 있다. 사람이 촬영된 이미지는, 정지 화상 이미지 및/또는 복수의 정지 화상 이미지가 연속적으로 촬영된 동영상 이미지를 포함할 수 있다. 일 실시예에 따르면, 제1이미지는 단 일한 정지된 화상 이미지일 수 있다. 일 실시예에 따르면, 전자 장치는 방범용 CCTV(closed circuit television)일 수 있다. 프로세서는 카메라 모듈을 이용하여, 전자 장치가 설치된 주변 환경의 영상(예: 제1이미지)을 지속적 및/또는 일시적으로 촬영할 수 있다. 다양한 실시예에 따르면, 프로세서는 제 1 영역을 검출할 수 있다. 일 실시예에 따르면, 프로세서는 제 1 이미지에서 제 1 영역을 검출할 수 있다. 제 1 이미지는 전자 장치를 이용하여 촬영된 이미지를 의미 할 수 있다. 제 1 영역은, 제 1 이미지 내에 표시된 사람을 포함하는 적어도 하나의 영역일 수 있다. 또는 제 1 영역은 제 1 이미지 내에서 사람이 위치하는 영역을 의미할 수 있다. 일 실시예에 따르면, 프로세서는 메 모리에 저장된 객체 검출 모델을 이용하여 제 1 이미지에서 제 1 영역을 검출할 수 있다. 일 실시예에 따 르면, 객체 검출 모델은, 딥러닝 기반의 알고리즘을 이용하여 학습된 모델일 수 있다. 예를 들면, 객체 검출 모 델은 합성곱 신경망(CNN: convolution neural network) 알고리즘에 기초하여 입력된 이미지 내에서 객체가 위치 하는 영역(예: 제 1 영역)을 검출하도록 학습된 모델일 수 있다. 일 실시예에 따르면, 객체 검출 모델은 객체 이미지 데이터를 이용하여 학습된 모델일 수 있다. 일 실시예에 따르면, 프로세서는 검출된 제 1 영역의 크기 및/또는 위치에 대한 데이터를 생성할 수 있고, 생성된 데이터를 일시적으로 메모리에 저장할 수 있 다. 다양한 실시예에 따르면, 프로세서는 사람이 위치하는 영역 중 제 2 영역에 대응하는 제 2 이미지를 획득 할 수 있다. 예를 들어, 제 1 영역은 사람의 전신을 포함하는 영역 또는 사람이 위치하는 영역을 의미할 수 있 다. 제 2 영역은 사람의 전신이 아닌 그 일부(예: 머리부터 어깨선)를 포함하는 영역을 의미할 수 있다. 제 2 이미지는, 판별 모델에 입력하기 위한 이미지 데이터일 수 있다. 일 실시예에 따르면, 제 2 이미지는 사람의 신 체 일부에 대응하는 이미지일 수 있다. 프로세서는 제 1 이미지의 전체 영역을 이용하는 대신 제 1 이미지 의 일부 영역을 이용하여 상대적으로 더 빠르고 정확하게 사람의 수 및 위치를 결정할 수 있다. 일 실시예에 따 르면, 프로세서는 제 2 영역을 선택하고, 제 2 영역에 대응하는 제 2 이미지를 획득할 수 있다. 제 2 영역 은 사람의 전신이 아닌 그 일부(예: 머리부터 어깨선)를 포함하는 영역을 의미할 수 있다. 일 실시예에 따르면, 제 2 영역은 제 1 영역 내에 포함될 수 있다. 일 실시예에 따르면, 제 2 영역은 제 1 영역의 크기 및/또는 위치 에 기초하여 생성될 수 있다. 도 1a에 따른 전자 장치는 사람의 머리부터 목까지 해당하는 영역에 대응하는 바운딩 박스를 생성할 수 있다. 도 1a에 따른 전자 장치는 생성된 바운딩 박스를 제 2 영역으로 설정할 수 있다. 제 2 영역은 사람의 머리부터 목까지 해당하는 영역을 의미할 수 있다. 사람의 머리부터 목까지 해당하는 영역은 헤드 박스(head bounding box)로 지칭될 수 있다. 도 1a에 따른 전자 장치는 헤드 박스(head bounding box)를 생성함에 기반하여 헤드 박 스에 대응하는 사람 객체가 존재함을 지시하는 정보를 획득할 수 있다. 다만, 전자 장치는 객체 검출 모델의 특 성 상 둥근 형태의 객체 검출 시 헤드 박스(head bounding box)를 생성할 수 있다. 예를 들어, 이미지 상에서 사람 및 축구공이 함께 인식되는 상황에서, 도 1a에 따른 전자 장치는 축구공에 대응하는 헤드 박스(head bounding box)를 생성할 수 있다. 도 1a에 따른 전자 장치는 사람의 머리에 대응하는 헤드 박스(head bounding box)외에 축구공에 대응하는 헤드 박스(head bounding box)에 기반하여 복수의 사람들이 존재하는 것으로 잘못결정할 수 있다. 본 문서의 다양한 실시예들에 따른 전자 장치는 사람의 머리부터 목까지 해당하는 영역이 아닌 사람의 머 리부터 어깨선까지 해당하는 영역을 헤드 박스(head bounding box)로 정의하고, 제 2 영역으로 설정할 수 있다. 전자 장치는 객체 검출 모델에 제 2 영역에 대응하는 데이터를 제공하여 학습을 진행할 수 있다. 객체 검 출 모델은 사람의 머리부터 어깨선까지 해당하는 영역에 기반하여 학습을 수행하고, 사람 객체를 검출할 수 있 다. 객체 검출 모델의 특성 상 둥근 형태의 객체를 기준으로 학습하는 경우 촬영된 이미지 상에서 둥근 형태의 객체가 상대적으로 많이 감지될 수 있어서 헤드 박스(head bounding box)를 상대적으로 많이 생성할 수 있다. 즉, 둥근 형태의 객체를 기준으로 학습하는 경우 생성된 헤드 박스(head bounding box)는 실제 사람과 대응할 확률이 상대적으로 낮을 수 있다. 생성된 헤드 박스(head bounding box)는 다른 물체와 대응할 확률이 상대적으 로 높을 수 있다. 객체 검출 모델은 사람의 머리부터 어깨선까지 해당하는 영역을 기준으로 학습하는 경우, 촬영된 이미지 상에서 사람의 머리부터 어깨선까지 대응하는 형태의 객체를 상대적으로 적게 감지할 수 있다. 객체 검출 모델은 헤드 박스(head bounding box)를 상대적으로 적게 생성할 수 있다. 즉, 생성된 헤드 박스(head bounding box)는 실 제 사람과 대응할 확률이 높을 수 있다. 전자 장치는 헤드 박스(head bounding box)에 기반하여 둥근 형태 의 객체를 기준으로 학습하는 경우 와 비교하여 상대적으로 정확하게 사람의 위치 및 수를 결정할 수 있다. 다양한 실시예에 따르면, 프로세서는 사람의 머리부터 어깨선까지 해당하는 영역을 헤드 박스(head bounding box)로 정의한 판별 모델을 이용하여 제 1 이미지에 포함된 객체(사람)의 수 및 위치를 확인할 수 있 다. 제 1 이미지는 전자 장치를 이용하여 촬영된 이미지를 의미할 수 있다. 일 실시예에 따르면, 프로세서 는 제 2 이미지를 이용하여 객체(사람)의 수 및 위치를 확인할 수 있다. 제 2 이미지는 사람의 신체 일부 에 대응하는 이미지일 수 있다. 판별 모델은, 인공지능 알고리즘을 이용하여 생성된 모델일 수 있다. 판별 모델 은, 딥러닝 기반의 알고리즘을 이용하여 학습된 모델일 수 있다. 예를 들면, 판별 모델은 합성곱 신경망(CNN: convolution neural network) 알고리즘에 기초하여 객체(사람)의 수 및 위치를 확인하도록 학습된 모델일 수 있 다. 일 실시예에 따르면, 판별 모델은 사람의 전체적인 형상, 사람의 머리, 사람의 머리 및 어깨를 포함하는 부 분별 이미지와 연계된 메타데이터(metadata)를 입력 받아 학습된 모델일 수 있다. 일 실시예에 따르면, 프로세 서는 메모리에 저장된 판별 모델을 이용하여 제 1 이미지의 적어도 일부 영역에 해당하는 이미지(예: 제 2 이미지)가 사람에 대응하는지 여부를 확인할 수 있다. 프로세서는 판별 모델에 제 2 이미지를 입력하 여 사람의 수 및 위치를 확인할 수 있다. 일 실시예에 따르면, 프로세서는 사람의 형체를 인식하기 위하여 제 1 이미지 또는 제 1 이미지에 포함된 제 1 영역에 해당하는 이미지를 전처리 할 수 있다. 전처리는 예를 들면, 회색조(grey scale) 변환, 이미지 경 계 필터링(image filtering), 이진화(binarization) 처리를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 메모리에 전처리를 위한 알고리즘 및/또는 인스트럭션을 저장할 수 있다. 일 실시예에 따르면, 프로세서는 검출된 제 1 영역 내의 사람의 형체를 인식 후, 사람이 존재하는 영역(예: 제 1 영역) 내 헤드 박스가 존재하는 영역(예: 제 2 영역)의 수를 인식할 수 있다. 헤드 박스는 도 1a 의 바운딩 박스 중 특정한 물체에 대응하는 바운딩 박스를 의미할 수 있다. 프로세서는 사람의 머리 상단 부터 사람의 어깨선까지 잘라낸 물체에 기반하여 헤드 박스를 생성할 수 있다. 일 실시예에 따르면, 프로세서 는 사람의 형체가 존재하는 지 여부에 관한 정보, 사람의 형체와 대응되는 제 1 영역 상에 헤드 박스가 존 재하는 지 여부에 관한 정보 및 사람의 형체와 대응되는 제 1 영역 상에 복수의 제 2 영역이 존재하는 지 여부 에 관한 정보 중 적어도 일부를 포함하는 객체 인식 정보를 생성하고, 메모리에 저장할 수 있다 일 실시예 에 따르면, 프로세서는 객체 인식 정보를 생성하고 외부 장치로 전송할 수 있다. 전자 장치는 외부 장치(예: 서버)와 통신적으로(communicatively) 연결될 수 있다. 전자 장치 는 외부 장치와 유선 통신 네트워크를 통해 연결될 수 있다. 일 실시예에 따르면, 전자 장치는 외부 장치로부터 명령 및/또는 데이터를 수신하거나, 외부 장치로 명령 및/또는 데이터를 전송할 수 있다. 예를 들어, 외부 장치는 전자 장치가 촬영한 영상 데이터(예: 제1이미지) 및 객체 인식 정보를 전자 장치로부터 수신할 수 있다. 외부 장치는 전자 장치를 적어도 부분적으로 제어할 수 있다. 일 실시예에 따르면, 전자 장치는 카메라 모듈을 제어하여 적어도 하나의 오브젝트(예: 사람)를 포함하는 특정 영역(예: 전신 영역, 머리부터 목까지의 영역 또는 머리부터 어깨선까지의 영역)을 촬영할 수 있고, 촬영 된 영상을 인코딩하여 외부 장치로 스트리밍 전송할 수 있다. 외부 장치는 전자 장치로부터 수 신한 데이터를 외부 장치에 포함된 저장소(예: 스토리지)에 저장할 수 있다.프로세서는 카메라 모듈을 이용하여 특정 공간에 대한 이미지를 생성할 수 있다. 프로세서는 생 성된 이미지의 픽셀값에 기초하여 바운딩 박스를 생성할 수 있다. 프로세서는 생성된 이미지 내에 존재하 는 복수의 객체들에 대응하는 바운딩 박스들이 표시된 출력 이미지를 생성할 수 있다. 이하에서는 '객체'는 이 미지 내에 포함된 사람을 의미하는 용어로 사용되나 사람에 한정되는 것은 아닐 수 있다. 도 3a는 비교 실시예에 따른 전자 장치가 사람을 인식하는 상황을 도시한 것이다. 도 3b는 다양한 실시예들에 따른 전자 장치가 사람을 인식하는 상황을 도시한 것이다. 도 1a 및 도 1b에 따른 전자 장치는 프로세서의 제어 하에, 사람 객체에 대한 복수의 바운딩 박스들을 생성할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 카메라 모듈에 의해 촬영된 이미지를 배경으로, 생성된 바운딩 박 스를 표시할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 NMS에 기반하여, 복수의 객체박스들 중 일정 수준을 초과하여 중복되는 바운딩 박스들을 제거할 수 있다. 이는 도 1a 및 도 1b에서 설명된 바 있다. 그림 310에서, 도 1a 및 도 1b에 따른 전자 장치는 제 1 객체에 대응하는 제 1 바운딩 박스, 제 2 객체에 대응하는 제 2 바운딩 박스 및 제 3 객체에 대응하는 제 3 바운딩 박스를 이미지 상에서 인식할 수 있다. 이 때 도 1a 및 도 1b에 따른 전자 장치는 제 1 바운딩 박스, 제 2 바운딩 박스 및 제 3 바운 딩 박스 외에도 수많은 바운딩 박스를 이미지 상에서 인식한 상태일 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 객체를 정확하게 인식하기 위해 NMS에 기반하여 중복되는 바운딩 박스를 제거할 수 있다. NMS에 기반하 여 중복되는 바운딩 박스를 제거하는 과정에서, 도 1a 및 도 1b에 따른 전자 장치는 중복되는 영역이 기 설정된 수준을 초과하는 제 1 바운딩 박스 및 제 2 바운딩 박스를 검출할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 중복되는 영역이 기 설정된 수준을 초과하는 제 1 바운딩 박스 및 제 2 바운딩 박스를 하나의 객체에 대한 바운딩 박스로 인식하고 복수의 바운딩 박스들 중 하나의 바운딩 박스를 제거할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 제 1 객체에 대한 제 1 바운딩 박스 및 제 3 객체에 대한 제 3 바운딩 박스만을 이미지 상에 표시할 수 있다. 그림 320에서, 비교 실시예에 따른 전자 장치는 제 1 객체에 대한 제 1 바운딩 박스 및 제 3 객체에 대한 제 3 바운딩 박스가 표시된 것에 기반하여, 이미지 상에 두 명의 사람(예: 제 1 객체 및 제 3 객체)이 존 재한다고 결정할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 상대적으로 중복되는 영역이 적은 제 3 바운딩 박스에 기반하여 제 3 객체를 다른 물체와 구분하여 인식할 수 있다. 그러나 도 1a 및 도 1b에 따른 전자 장치는 제 1 바운딩 박스 및 제 2 바운딩 박스의 중첩되는 영역이 상대적으로 많아 제 1 객체 및 제 2 객체를 구분하여 인식하기 어려울 수 있다. 도 3b에 따르면, 다양한 실시예들에 따른 전자 장치(예: 도 2의 전자 장치)는 프로세서(예: 도 2의 프로세 서)의 제어 하에, 사람 객체에 대한 복수의 바운딩 박스들을 생성할 수 있다. 그림 330에서, 프로세서는 사람 객체에 대한 복수의 바운딩 박스들을 생성할 수 있다. 프로세서는 제 1 사람의 전신에 대응하는 제 1 바운딩 박스(332a) 및 제 1 사람의 머리부터 어깨선에 대응하는 제 2 바운딩 박 스(332b)를 이미지 상에 표시할 수 있다. 프로세서는 제 2 사람의 전신에 대응하는 제 3 바운딩 박스 (334a) 및 제 2 사람의 머리부터 어깨선에 대응하는 제 4 바운딩 박스(334b)를 이미지 상에 표시할 수 있다. 프 로세서는 제 3 사람의 전신에 대응하는 제 5 바운딩 박스(336a) 및 제 3 사람의 머리부터 어깨선에 대응하 는 제 6 바운딩 박스(336b)를 이미지 상에 표시할 수 있다. 전자 장치는 프로세서의 제어 하에, 객체를 정확하게 인식하기 위해 NMS에 기반하여 중복되는 바운딩 박스를 제거할 수 있다. 앞선 도 3a의 실시예처럼, 프로세서는 제 1 사람의 전신에 대응하는 제 1 바운딩 박스(332a) 및 제 2 사람의 전신에 대응하는 제 3 바운딩 박스(334a)가 기 설정된 제 1 수준(예: 약 70%)을 초 과하여 중복됨에 대응하여 하나의 객체가 존재하는 것으로 결정할 수 있다. 기 설정된 제 1 수준은 일 예시일 뿐 이것으로 한정되는 것은 아닐 수 있다. 프로세서는 제 1 사람의 머리부터 어깨선에 대응하는 제 2 바운 딩 박스(332b) 및 제 2 사람의 머리부터 어깨선에 대응하는 제 4 바운딩 박스(334b)에 기반하여 객체의 수 및 위치를 결정할 수 있다. 제 1 바운딩 박스(332a) 및 제 3 바운딩 박스(334a)는 사람의 전신을 포함하기 때문에 이미지 내에서 차지하는 영역이 크고, 중복되는 영역도 상대적으로 크게 형성될 수 있다. 그러나 제 2 바운딩 박스(332b) 및 제 4 바운딩 박스(334b)는 사람의 전신이 아닌 머리부터 어깨선에 대응하는 영역을 대상으로 하여, 상대적으로 바운딩 박스가 이미지 내에서 차지하는 영역이 작을 수 있다. 또한, 제 1 바운딩 박스(332a) 및 제 3 바운딩 박스(334a)와 비교하여 제 2 바운딩 박스(332b) 및 제 4 바운딩 박스(334b) 상에서 중복되는 영역은 상대적으로 작거나 존재하지 않을 수 있다. 프로세서는 제 2 바운딩 박스 (332b) 및 제 4 바운딩 박스(334b) 상에서 중복되는 영역이 사전에 설정된 제 1 수준 미만인 것을 확인함에 대 응하여 이미지 상에 복수의 사람들이 존재하는 것으로 결정할 수 있다. 도 4a 및 도 4b는 다양한 실시예들에 따른 전자 장치가 이미지 또는 영상에서 사람의 수 및 위치를 인식하는 상 황을 도시한 것이다. 도 1a 및 도 1b에 따른 전자 장치는 이미지 상에서 사람에 대한 복수의 바운딩 박스들을 생성할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 도 1b에서 설명된 NMS에 기반하여, 복수의 객체박스들 중 일정 수준을 초과하여 중복되는 객체박스들을 제거할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 제 1 사람의 머리부터 어깨선까지 의 바운딩 박스 및 제 2 사람의 머리부터 어깨선까지의 바운딩 박스를 이미지 상에 표시할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 제 1 사람의 전신에 대한 바운딩 박스 및 제 2 사람의 전신에 대한 바운딩 박스의 중복되는 영역이 일정 수준을 초과함에 기반하여 하나의 바운딩 박스만을 이미지 상에 표시할 수 있다. 도 1a 및 도 1b에 따른 전자 장치는 하나의 바운딩 박스만 표시되는 것에 기반하여 이미지 상에서 사람(또는 객체)이 1명 존재하는 것으로 결정할 수 있다. 다양한 실시예들에 따른 전자 장치(예: 도 2 의 전자 장치)는 프로세서(예: 도 2의 프로세서)의 제어 하에, 제 1 사람의 머리부터 어깨선까지의 영역에 대응하는 바운딩 박스 및 제 2 사람의 머리부터 어깨선 까지의 영역에 대응하는 바운딩 박스를 기반으로 이미지 상에서 적어도 2명의 사람이 존재하는 것으로 결 정할 수 있다. 프로세서는 사람이 아닌 물체에 대응하는 바운딩 박스에 대해, 이미지의 픽셀값에 기 초하여, 객체의 종류, 위치 및 수를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 제 1 사람의 머리부터 어깨선까지의 영역에 대응하는 바운딩 박스 의 y축 상단의 좌표 및 사람의 전신을 포함하는 영역과 대응하는 하나의 바운딩 박스의 y축 하단의 좌표를 기반으로 제 1 사람의 위치를 결정할 수 있다. 프로세서는 제 1 사람의 머리부터 어깨선까지의 영역에 대 응하는 바운딩 박스 의 y축 상단의 좌표 및 사람의 전신을 포함하는 영역과 대응하는 하나의 바운딩 박스 의 y축 하단의 좌표를 기반으로 제 1 사람의 세로 길이를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 제 1 사람의 머리부터 어깨선까지의 영역에 대응하는 바운딩 박스의 x축 좌표를 기반으로 제 1 사람의 가로 길이를 결정할 수 있다. 프로세서는 결정된 제 1 사람의 세로 길이 및 제 1 사람의 가로 길이를 기반으로 이미지 상에서 제 1 사람의 위치를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 제 2 사람의 머리부터 어깨선까지의 영역에 대응하는 바운딩 박스 의 y축 상단의 좌표 및 사람의 전신을 포함하는 영역에 대응하는 하나의 바운딩 박스의 y축 하단의 좌표를 기반으로 제 2 사람의 위치를 결정할 수 있다. 프로세서는 제 2 사람의 머리부터 어깨선까지의 영역에 대 응하는 바운딩 박스 의 y축 상단의 좌표 및 사람의 전신을 포함하는 영역에 대응하는 하나의 바운딩 박스 의 y축 하단의 좌표를 기반으로 제 1 사람의 세로 길이를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 제 2 사람의 머리부터 어깨선까지의 영역에 대응하는 바운딩 박스의 x축 좌표를 기반으로 제 2 사람의 가로 길이를 결정할 수 있다. 프로세서는 결정된 제 2 사람의 세로 길이 및 제 2 사람의 가로 길이를 기반으로 이미지 상에서 제 2 사람의 위치를 결정할 수 있다. 도 4b에 따르면, 프로세서는 제 1 사람의 머리부터 어깨선까지의 영역에 대응하는 바운딩 박스 및 제 2 사람의 머리부터 어깨선까지의 영역에 대응하는 바운딩 박스의 y축 상단 좌표에 기반하여 복수의 사람들 의 상단부 위치를 결정할 수 있다. 프로세서는 사람의 전신과 대응하는 하나의 바운딩 박스의 y축 하단 좌표에 기반하여 복수의 사람들 의 하단부 위치를 결정할 수 있다. 그림 402에서, 특정 영역의 y축 상단부의 좌표가 실제로 제 1 사람의 하단부 위치와 대응될 수 있다. 그러 나, 프로세서는 y축 상단부의 좌표가 아닌 y축 하단부의 좌표를 기반으로 제 1 사람의 하단부 위치를 결정 할 수 있다. 프로세서는 제 1 사람의 하단부 위치에 대하여, 특정 영역의 y축 길이만큼 오차를 가질 수 있다. 프로세서는 이러한 오차에도 불구하고 그림 402 상에서 사람의 수 및 위치를 그림 401과 비교하 여 정확하게 결정할 수 있다. 다양한 실시예들에 따른 전자 장치는 특정 영역의 y축 길이만큼의 오차에도 불구하고, 도 1a에 따른 전자 장치와 비교하여 정확하게 이미지 상에서 사람의 수를 결정할 수 있다. 또한, 다양한 실시예들에 따른 전 자 장치는 특정 영역의 y축 길이만큼의 오차에도 불구하고, 도 1a에 따른 전자 장치와 비교하여 정확 하게 이미지 상의 사람의 위치를 결정할 수 있다. 다양한 실시예들에 따른 전자 장치는 사람의 머리에 해 당하는 위치부터 사람의 목에 해당하는 위치에 대응하는 바운딩 박스(또는 헤드 박스)가 아닌, 사람의 머리에 해당하는 위치부터 사람의 어깨선에 해당하는 위치에 대응하는 바운딩 박스를 이용하여 이미지 상에서 사람의 수를 정확하게 결정할 수 있다. 도 5a 및 도 5c는 다양한 실시예들에 따른 전자 장치의 객체 인식 방법을 순서도로 도시한 것이다. 도 5b 및 도 5d는 다양한 실시예들에 따른 전자 장치의 객체 인식 상황을 도시한 것이다. 도시된 방법은 앞서 도 1a 내지 도 4b를 통해 설명한 전자 장치(예: 도 2의 전자 장치)에 의해 실행 될 수 있으며, 앞서 설명한 바 있는 기술적 특징은 이하에서 생략하기로 한다. 동작 510에서, 전자 장치는 적어도 하나의 객체가 포함된 이미지 또는 영상을 입력 받을 수 있다. 동작 520에서, 전자 장치는 이미지 또는 영상 내 검출된 물체가 person class에 대응하는지 결정할 수 있 다. 동작 522에서, 전자 장치는 검출된 물체가 사람 클래스(person class)가 아닌 것으로 결정됨에 기반하 여 greedy NMS를 적용할 수 있다. 사람 클래스(person class)의 객체는 사람으로 분류될 수 있는 모양 및 크기 를 가진 객체를 의미할 수 있다. greedy NMS는 복수의 객체들에 대해 복수의 bbox(bounding box)를 생성하고, 복수의 bbox들 중 일정 수준을 초과하여 영역이 중복되는 bbox는 신뢰도가 가장 높은 1개의 bbox만 남기고 나머 지 bbox들은 삭제하는 방식을 의미할 수 있다. bbox는 도 1a 및 도 1b에서 설명된 바운딩 박스를 의미할 수 있 다. NMS는 비최대값 억제(Non-Maximum Suppression)를 의미할 수 있다. NMS 방식은 앞선 도 1b에서 설명된 바 있다. 동일한 종류(class)의 바운딩 박스에 대해, 예상 점수(predict score)가 상대적으로 높은 바운딩 박스는 상대적으로 높은 신뢰도(confidence)를 얻을 수 있다. 예상 점수(predict score)는 바운딩 박스 와 바운딩 박스 가 겹쳐진 면적의 비율에 비례하여 결정될 수 있다. 동작 524에서, 전자 장치는 person bbox list를 복사할 수 있다. person bbox에 해당하는 객체는 사람으 로 확정된 것은 아닐 수 있다. bbox는 도 1a의 바운딩 박스를 의미할 수 있다. person bbox는 사람 객체에 대응 하는 바운딩 박스를 의미할 수 있다. person bbox에 대응하는 객체는 사람으로 분류될 수 있는 모양 및 크기를 가진 객체로서 사람으로 분류될 수 있는 후보를 의미할 수 있다. 동작 526에서, 전자 장치는 복사된 person bbox list에 greedy NMS를 적용할 수 있다. 이후, 전자 장치 는 greedy NMS가 적용된 person bbox의 정보를 메모리(예: 도 2의 메모리) 상에 저장할 수 있다. 동작 528에서, 전자 장치는 person bbox들의 목록 중에서, head bbox를 2개 이상 포함하고 있는 person bbox를 삭제할 수 있다. head bbox는 사람의 머리부터 어깨선 까지의 영역에 대응하는 바운딩 박스를 의미할 수 있다. head bbox는 사람의 머리 형상부터 어깨 형상까지의 영역을 포함할 수 있다. 전자 장치는 head bbox 를 2개 이상 포함하는 person bbox는 정상적인 하나의 사람 객체가 아닐 확률이 상대적으로 높은 것으로 결정할 수 있다. 전자 장치는 head bbox를 2개 이상 포함하는 person bbox를 삭제하고, 나머지 person bbox 내에 서 사람 객체에 대응하는 person bbox를 결정할 수 있다. 동작 530에서, 전자 장치는 head bbox가 person bbox 내부에 위치하는지 결정할 수 있다. 전자 장치(20 0)는 head bbox가 person bbox 내부에 위치함에 기반하여 이를 case 3로 분류할 수 있다. 전자 장치는 head bbox가 person bbox 내부에 위치하지 않음에 기반하여 동작 535에서, head bbox가 삭제 된 person bbox 내부에 위치하고 있었는지 결정할 수 있다. 전자 장치는 head bbox가 삭제된 person bbox 내부에 위치함에 기반하여 이를 case 2로 분류할 수 있다. 전자 장치는 head bbox가 삭제된 person bbox 내부에 위치하지 않음에 기반하여 이를 case 1로 분류할 수 있다. 도 5b 는 다양한 실시예들에 따른 전자 장치의 객체 인식 상황을 도시한 것이다. 도 5b에서, head bbox를 2개 이상 포함하는 person bbox는 빨간색 박스로 표시될 수 있다. 도 5b에서, head bbox를 1개만 포함하는 person bbox는 초록색 박스(551, 552 및 553)로 표시될 수 있다. 빨간색 박스 는 2개 이상의 head bbox들에 대응하는 복수의 초록색 박스들(551, 552)을 포함할 수 있다. 또는 빨간색 박스는 case 2처럼 2개 이상의 head bbox들을 포함하지만, 개 이상의 head bbox들에 대응하는 초록색 박스 는 포함하지 않을 수도 있다. 초록색 박스 중 일부(551, 552)는 빨간색 박스에 포함될 수도 있고, 일부는 빨간색 박스와 별도로 따로 표시될 수도 있다. 일 실시예에 따르면, case 1은 head bbox가 person bbox나 삭제된 person bbox의 내부에 위치하지 않는 상황을 의미할 수 있다. case 2는 head bbox가 삭제된 person bbox의 내부에 위치하는 상황을 의미할 수 있다. case 3는 head bbox가 삭제되지 않은 person bbox의 내부에 위치하는 상황을 의미할 수 있다. 일 실시예에 따르면, 전자 장치는 case 1에 대해 head bbox는 찾았으나, person bbox를 찾지 못한 것으로 결정할 수 있다. 전자 장치는 case 1에 대해 head bbox에 대응하는 person bbox가 존재하지 않음에 기반하여 사람 객체가 존재하지 않는 것으로 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 case 3에 대해 person bbox가 삭제되었는지 여부에 관계 없이 head bbox에 대응하는 person bbox가 존재하는 것으로 결정할 수 있다. case 3에서 전자 장치는 head bbox에 대응하는 person bbox에 대해 greedy NMS를 적용하고, 적용 결과에 기반하여 head bbox에 대응하는 사 람 객체가 존재하는 것으로 결정할 수 있다. case 3에서 전자 장치는 head bbox의 수에 기반하여 사 람 객체의 수를 결정할 수 있다. 예를 들어, 전자 장치는 case 3에서 1개의 head bbox가 감지됨에 대 응하여 하나의 사람 객체가 감지된 것으로 결정할 수 있다. 전자 장치는 case 3에서 2개의 head bbox 가 감지됨에 대응하여 두 명의 사람 객체가 감지된 것으로 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 case 2에 대해 head bbox는 찾았으나, person bbox가 복수의 head bbox들을 포함하는 것으로 결정할 수 있다. 전자 장치는 case 2에서, head bbox를 포함하지만, head bbox에 대응하는 person bbox의 수가 부족하여 사람 객체의 수를 결정하기 어려울 수 있다. case 2에서 사 람 객체의 수를 결정하는 과정에 대해서는 도 5c 및 도 5d에서 설명될 것이다. 도 5c는 앞선 case 2에서 전자 장치가 사람 객체의 수를 결정하는 과정을 순서도로 도시한 것이다. 도 5d는 case 2에서 전자 장치가 사람 객체의 수를 결정하는 상황을 도시한 것이다. 동작 550에서, 전자 장치는 head bbox 및 삭제된 person bbox에 대한 정보를 기반으로 새로운 person bbox에 대한 정보를 생성할 수 있다. 동작 560에서, 전자 장치는 삭제된 person bbox 내에 위치하는 복수의 head bbox들이 x좌표를 기준으로 일 정 수준을 초과하여 중복되는지 결정할 수 있다. 전자 장치는 삭제된 person bbox 내에 위치하는 복수의 head bbox들이 x좌표를 기준으로 일정 수준을 초과하여 중복되지 않는 것으로 결정함에 기반하여 동작 562에서, head bbox 수만큼의 사람 객체가 존재하는 것으로 결정할 수 있다. 즉, 전자 장치는 복수의 head bbox들이 x좌표를 기준으로 일정 수준을 초과하여 중복되지 않으면, head bbox들이 일정 부분 중복되더라도 하나의 객체 가 아닌 것으로 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 삭제된 person bbox 내에 위치하는 복수의 head bbox들이 x좌표를 기준 으로 일정 수준을 초과하여 중복되는 것으로 결정함에 기반하여 동작 570에서, 삭제된 person bbox 내에 위치하 는 복수의 head bbox들이 y좌표를 기준으로 일정 수준을 초과하여 중복되는지 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 삭제된 person bbox 내에 위치하는 복수의 head bbox들이 y좌표를 기준 으로 일정 수준을 초과하여 중복되지 않는 것으로 결정함에 기반하여 동작 572에서, head bbox 수에 대응하는 사람 객체가 존재하는 것으로 결정할 수 있다. 전자 장치는 head bbox들이 y좌표를 기준으로 일정 수준을 초과하여 중복되지 않으면, head bbox들이 일정 부분 중복되어 존재하더라도 하나의 객체가 아닌 것으로 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 삭제된 person bbox 내에 위치하는 복수의 head bbox들이 y좌표를 기준 으로 일정 수준을 초과하여 중복되는 것으로 결정함에 기반하여 복수의 head bbox들이 하나의 사람 객체를 지시 하는 것으로 결정할 수 있다. 도 5d는 case 1, case 2 및 case 3에 대한 객체 인식 결과를 도시한 것이다. 도 5d에 따르면, 전자 장치는 case 1에 대하여, head bbox가 잘못 인식된 결정하고, 이미지 상에 head bbox에 대응하는 사람 객체가 존재하지 않는 것으로 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 case 3 중 그림 상에서 왼쪽 case(543-1)에 대해, 2개의 head bbox들에 대응하는 2명의 사람 객체가 존재하는 것으로 결정할 수 있다. 전자 장치는 case 3 중 그림상에서 오른쪽 case(543-1)에 대해, 1개의 head bbox에 대응하는 1명의 사람 객체가 존재하는 것으로 결정할 수 있다. 일 실시예에 따르면, 전자 장치는 case 2에 대해 2개의 head bbox들에 대응하는 person bbox를 메모 리상에서 찾을 수 있다. 전자 장치는 앞선 도 5a의 동작 526에서, 복사된 person bbox list를 이용 하여 2개의 head bbox들에 대응하는 person bbox를 찾을 수 있다. 전자 장치는 2개의 head bbox들에 대응 하는 제 1 person bbox(542-a) 및 제 2 person bbox(542-b)에 기반하여 2명의 사람 객체가 존재하는 것으로 결 정할 수 있다. 그림 5d에서, 전자 장치는 제 1 person bbox(542-a)에 대응하는 head bbox와 제 2 person bbox(542-b)에 대응하는 head bbox들이 x좌표를 기준으로 일정 수준을 초과하여 중복되지 않는 것에 기반하여 2 개의 head bbox들에 대응하는 2명의 사람 객체가 존재하는 것으로 결정할 수 있다. 도 1a에 따른 전자 장치는, 사람의 머리 부분만을 head bbox의 영역으로 설정하여, 도 5d에 표시되는 다른 물체 들(예: 자전거 바퀴, 가방, 신발 등)을 사람 객체의 형상으로 잘못 인식할 수 있다. 도 1a에 따른 전자 장치는 사람의 전신을 person bbox의 영역으로 설정하여 case 3(543-1)나 case 2의 상황에서, 사람들이 일정 수 준을 초과하여 겹쳐있는 상황에서 하나의 사람만 존재하는 것으로 잘못 결정할 수 있다. 본 문서의 다양한 실시예들에 따른 전자 장치는 사람의 머리 부분이나 전신이 아닌 사람의 머리끝부터 어 깨선까지 대응하는 영역을 head bbox로 지정하고, 이러한 head bbox를 기반으로 학습 모델의 학습을 진행시켜 상대적으로 더 정확하게 중첩된 복수의 사람들을 구별할 수 있다. 다양한 실시예들에 따른 전자 장치는 입력 영상을 획득하는 카메라 모듈, 메모리 및 카메라 모듈 및 메모리와 작동적으로 연결된 프로세서를 포함할 수 있다. 프로세서는 입력 영상으로부터 사람의 머리(head) 상단부터 사 람의 어깨선에 대응하는 머리 객체(object)를 포함하는 복수의 바운딩 박스(bounding box)를 생성할 수 있다. 프로세서는 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복 수의 바운딩 박스(bounding box) 중 머리 객체에 대응하는 적어도 하나의 바운딩 박스를 결정할 수 있다. 프로 세서는 입력 영상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수의 바운딩 박스(bounding box)를 생성하고, 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하 여 복수의 바운딩 박스(bounding box) 중 사람 객체에 대응하는 적어도 하나의 바운딩 박스를 결정할 수 있다. 프로세서는 하나의 사람 객체에 대응하는 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출 되는 것에 기반하여 바운딩 박스를 메모리 상에 저장하고, 메모리 상에 저장된 바운딩 박스 내에는 하나의 사람 객체가 아닌 복수의 머리 객체들의 수만큼의 사람 객체들이 위치하는 것으로 결정할 수 있다. 일 실시예에 따르면, 프로세서는 제 1 머리 객체의 바운딩 박스의 상단 y축 좌표 정보와 메모리 상에 저장된 바 운딩 박스의 하단 y축 좌표 정보에 기반하여 제 1 사람의 세로 길이를 결정하고, 제 1 머리 객체의 좌측 및 우 측의 x축 좌표 정보에 기반하여 제 1 사람의 가로 길이를 결정할 수 있다. 프로세서는 제 2 머리 객체의 바운딩 박스의 상단 y축 좌표 정보와 메모리 상에 저장된 바운딩 박스의 하단 y축 좌표 정보에 기반하여 제 2 사람의 세로 길이를 결정하고, 제 2 머리 객체의 좌측 및 우측의 x축 좌표 정보에 기반하여 제 2 사람의 가로 길이를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 메모리 상에 저장된 바운딩 박스의 영역 내 포함된 제 1 머리 객체 및 제 2 머 리 객체에 대해, 제 1 머리 객체는 제 1 사람에 대응하는 것으로 결정하고, 제 2 머리 객체는 제 2 사람에 대응 하는 것으로 결정할 수 있다. 일 실시예에 따르면, 객체 검출 모델은 비 최대치 억제(NMS) 기법 및 머리(head) 객체에 대한 복수의 바운딩 박 스들의 IoU(intersection over union)를 기반으로, 머리(head) 객체에 대응하는 바운딩 박스를 결정할 수 있다. 머리 객체에 대응하는 바운딩 박스는 사람의 머리 상단부터 사람의 어깨선까지 해당하는 영역을 포함할 수 있다. 일 실시예에 따르면, 프로세서는 복수의 바운딩 박스 간 서로 겹치는 부분이 사전에 설정된 제 1 수준을 초과함 에 기반하여, 복수의 바운딩 박스들을 하나의 물체인 것으로 결정하고, 복수의 바운딩 박스 간 서로 겹치는 부 분이 사전에 설정된 제 1 수준 미만인 것에 기반하여, 복수의 바운딩 박스들을 둘 이상의 물체인 것으로 결정할 수 있다. 다양한 실시예들에 따른 전자 장치의 사람 객체 검출 방법은 입력 영상으로부터 사람의 머리(head) 상단부터 사 람의 어깨선에 대응하는 머리 객체(object)를 포함하는 복수의 바운딩 박스(bounding box)를 생성하는 동작, 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복수의 바운딩 박 스(bounding box) 중 머리 객체에 대응하는 적어도 하나의 바운딩 박스를 결정하는 동작을 포함할 수 있다. 전 자 장치의 사람 객체 검출 방법은 입력 영상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수 의 바운딩 박스(bounding box)를 생성하는 동작 및 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복수의 바운딩 박스(bounding box) 중 사람 객체에 대응하는 적어도 하나 의 바운딩 박스를 결정하는 동작을 포함할 수 있다. 전자 장치의 사람 객체 검출 방법은 하나의 사람 객체에 대 응하는 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출되는 것에 기반하여 바운딩 박스를 메모리 상에 저장하는 동작 및 메모리 상에 저장된 바운딩 박스 내에는 하나의 사람 객체가 아닌 복수의 머리 객체들의 수만큼의 사람 객체들이 위치하는 것으로 결정하는 동작을 포함할 수 있다. 일 실시예에 따르면, 전자 장치의 사람 객체 검출 방법은 메모리 상에 저장된 바운딩 박스의 영역 내 포함된 제 1 머리 객체 및 제 2 머리 객체에 대해, 제 1 머리 객체는 제 1 사람에 대한 정보인 것으로 결정하는 동작 및 제 2 머리 객체는 제 2 사람에 대한 정보인 것으로 결정하는 동작을 더 포함할 수 있다. 일 실시예에 따르면, 전자 장치의 사람 객체 검출 방법은 제 1 머리 객체의 바운딩 박스의 상단 y축 좌표 정보 와 메모리 상에 저장된 바운딩 박스의 하단 y축 좌표 정보에 기반하여 제 1 사람의 세로 길이를 결정하고, 제 1 머리 객체의 좌측 및 우측의 x축 좌표 정보에 기반하여 제 1 사람의 가로 길이를 결정하는 동작 및 제 2 머리 객체의 바운딩 박스의 상단 y축 좌표 정보와 메모리 상에 저장된 바운딩 박스의 하단 y축 좌표 정보에 기반하여 제 2 사람의 세로 길이를 결정하고, 제 2 머리 객체의 좌측 및 우측의 x축 좌표 정보에 기반하여 제 2 사람의 가로 길이를 결정하는 동작을 더 포함할 수 있다. 일 실시예에 따르면, 객체 검출 모델을 이용하여 복수의 머리 객체를 각각 구분하여 검출하는 동작은 복수의 바 운딩 박스 간 서로 겹치는 부분이 사전에 설정된 제 1 수준을 초과함에 기반하여, 복수의 바운딩 박스들을 하나 의 물체인 것으로 결정하는 동작 및 복수의 바운딩 박스 간 서로 겹치는 부분이 사전에 설정된 제 1 수준 미만 인 것에 기반하여, 복수의 바운딩 박스들을 둘 이상의 물체인 것으로 결정하는 동작을 더 포함할 수 있다. 일 실시예에 따르면, 프로세서는 입력 영상으로부터 사람의 머리(head) 상단부터 사람의 어깨선에 대응하는 머 리 객체(object)를 포함하는 복수의 바운딩 박스(bounding box)들을 생성하고, 복수의 바운딩 박스 들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복수의 바운딩 박스(bounding box)들 중 머리 객체에 대응하는 적어도 하나의 헤드 박스(head bounding box)를 결정할 수 있다. 프로세서는 입력 영 상으로부터 사람의 전신(body)에 대응하는 사람 객체를 포함하는 복수의 바운딩 박스(bounding box)들을 생성하 고, 복수의 바운딩 박스들의 IoU(intersection over union)를 기반으로, 객체 검출 모델을 이용하여 복수의 바 운딩 박스(bounding box)들 중 IoU가 가장 높은 제 1 바운딩 박스의 정보를 메모리 상의 제 1 영역에 저장하고, 제 1 바운딩 박스 외에 나머지 바운딩 박스들의 정보를 메모리 상의 제 1 영역이 아닌 다른 제 2 영역에 저장하 며, 제 1 바운딩 박스(bounding box)의 영역 내에서 복수의 머리 객체들이 검출되는 것에 기반하여 메모리 상의 제 2 영역에 저장된 나머지 바운딩 박스들에 대해 비 최대치 억제(NMS) 기법을 실행하고, 헤드 박스(head bounding box)를 기준으로 IoU를 계산할 수 있다. 프로세서는 제 2 영역 상에서 사전에 설정된 수준을 초과하는 IoU를 갖는 바운딩 박스가 검출되지 않는 것에 대응하여 제 1 바운딩 박스의 정보에 기반하여 입력 영상 내 사 람의 위치, 수, 크기 중 적어도 어느 하나를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 제 2 영역 상에서 사전에 설정된 수준을 초과하는 IoU를 갖는 제 2 바운딩 박 스가 검출되는 것에 대응하여 메모리로부터 제 2 바운딩 박스의 정보를 수신하고,수신된 제 2 바운딩 박스의 정 보에 기반하여 입력 영상 내 사람의 위치, 수, 크기 중 적어도 어느 하나를 결정할 수 있다. 일 실시예에 따르면, 제 1 바운딩 박스의 정보는 가로 길이, 세로 길이, x축 좌표 정보 및 y축 좌표 정보를 포 함할 수 있다. 프로세서는 헤드 박스의 상단 y축 좌표 정보와 제 1 바운딩 박스의 하단 y축 좌표 정보에 기반하 여 영상 내 사람의 세로 길이를 결정하고, 헤드 박스의 좌측 및 우측의 x축 좌표 정보에 기반하여 영상 내 사람 의 가로 길이를 결정할 수 있다. 일 실시예에 따르면, 제 2 바운딩 박스의 정보는 가로 길이, 세로 길이, x축 좌표 정보 및 y축 좌표 정보를 포 함할 수 있다. 프로세서는 헤드 박스의 상단 y축 좌표 정보와 제 2 바운딩 박스의 하단 y축 좌표 정보에 기반하 여 영상 내 사람의 세로 길이를 결정하고,제 2 바운딩 박스의 좌측 및 우측의 x축 좌표 정보에 기반하여 영상 내 사람의 가로 길이를 결정할 수 있다.도면 도면1a 도면1b 도면2 도면3a 도면3b 도면4a 도면4b 도면5a 도면5b 도면5c 도면5d"}
{"patent_id": "10-2022-0093577", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 전자 장치에서 합성곱 신경망 모델(convolutional neural network, CNN) 기반 인간 객체 탐지 방법을 도시한 것이다. 도 1b는 이미지에 복수의 객체가 포함된 경우 발생할 수 있는 문제를 설명하는 도면이다. 도 2는 다양한 실시예들에 따른 전자 장치의 구성을 블록도로 도시한 것이다. 도 3a는 비교 실시예에 따른 전자 장치가 사람을 인식하는 상황을 도시한 것이다. 도 3b는 다양한 실시예들에 따른 전자 장치가 사람을 인식하는 상황을 도시한 것이다. 도 4a 및 도 4b는 다양한 실시예들에 따른 전자 장치가 이미지 또는 영상에서 사람의 수 및 위치를 인식하는 상 황을 도시한 것이다. 도 5a 및 도 5c는 다양한 실시예들에 따른 전자 장치의 객체 인식 방법을 순서도로 도시한 것이다. 도 5b 및 도 5d는 다양한 실시예들에 따른 전자 장치의 객체 인식 상황을 도시한 것이다."}
