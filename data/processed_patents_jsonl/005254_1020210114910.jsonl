{"patent_id": "10-2021-0114910", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0033199", "출원번호": "10-2021-0114910", "발명의 명칭": "병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법", "출원인": "주식회사 엠티에스컴퍼니", "발명자": "정희원"}}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하는 단계;(b) 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하는 단계;(c) 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하는 단계; (d) 상기 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조해 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성하는 단계; 및(e) 제2 병변진단모델을 통해 상기 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력하는 단계;를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 (b)는,상기 병변분포도 정보 및 환자의 속성 정보 중 적어도 하나를 참조해 상기 제1 병변오브젝트를 검출하기 위한상기 최적의 위치를 판별하는 단계;를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 (b)는,상기 제1 병변오브젝트의 종류, 위치, 및 크기 중 적어도 하나에 기초해 상기 병변분포도 정보를 참조하기 위한전략을 결정하는 단계; 및상기 전략에 기초해 상기 병변분포도 정보를 참조하는 단계;를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 상기 (b)의 상기 전략은 탐색 방향, 탐색 간격, 및 탐색 색상 중 어느 하나의 정보를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,공개특허 10-2023-0033199-3-상기 (d)는,상기 제1 병변오브젝트의 종류, 위치, 및 크기 중 적어도 하나에 기초해 상기 병변분포도 정보를 참조하기 위한전략을 결정하는 단계; 및상기 전략에 기초해 상기 병변분포도 정보를 참조하는 단계;를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서, 상기 (d)의 상기 전략은 탐색 방향, 탐색 간격, 및 탐색 색상 중 어느 하나의 정보를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,상기 제1 병변오브젝트와 관련된 진단 정보는 상기 제1 병변오브젝트의 검출 정보, 제1 검출 확률 정보, 및 제1좌표 정보 중 적어도 하나를 포함하고, 상기 제2 병변오브젝트와 관련된 진단 정보는 상기 제2 병변오브젝트의검출 정보, 제2 검출 확률 정보, 및 제2 좌표 정보 중 적어도 하나를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서, 상기 제1 병변진단모델은 제1 학습용 패치이미지를 이용한 학습을 통해 생성되는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서, 상기 제1 병변진단모델은 상기 제1 학습용 패치이미지를 YOLO(You Only Look Once), SSD(Single Shot Multiboxdetection), Centernet, Cornernet, RetinaNet, ExtremeNet, RefineDet 중 적어도 하나를 학습시켜 생성되는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1항에 있어서,상기 제2 병변진단모델은 제2 학습용 패치이미지를 이용한 학습을 통해 생성되는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서, 공개특허 10-2023-0033199-4-상기 제2 병변진단모델은 상기 제2 학습용 패치이미지를 fast-CNN(Convolutional Neural Network), mask-RCNN,VGGNet, GoogLeNet, R(Region)- CNN, Faster R(Faster Region)-CNN, DenseNet 중 적어도 하나를 학습시켜 생성되는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1항에 있어서, (f) 상기 제2 패치이미지에 대한 진단 완료 플래그를 설정하는 단계;를 더 포함하는, 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "(a) 원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하는 단계;(b) 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하는 단계;(c) 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하는 단계;(d) 상기 제1 병변오브젝트와 관련된 진단 정보 출력 결과 상기 제1 병변오브젝트가 검출된 것인지 여부를 판단하는 단계; 및(e) 상기 판단에 기초해 상기 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성할 것인지 여부를 결정하는 단계;를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 (d)에서 상기 제1 병변오브젝트가 검출된 것으로 판단되면, 상기 (e)는 상기 제1 병변오브젝트에 대응하는상기 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 상기 제2 패치이미지를 생성할 것으로 결정하고, 상기 (d)에서 상기 제1 병변오브젝트가 검출되지 않은 것으로 판단되면, 상기 (e)는 상기 제1 패치이미지에 대한 진단 완료 플래그를 설정할 것으로 결정하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,(f) 제2 병변진단모델을 통해 상기 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력하는 단계;를 더 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1 병변진단모델과 제2 병변진단모델을 저장하는 메모리; 및공개특허 10-2023-0033199-5-원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하고, 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하며, 상기 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하고, 상기 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성하며, 제2 병변진단모델을 통해 상기제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력하는 프로세서;를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치."}
{"patent_id": "10-2021-0114910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1 병변진단모델과 제2 병변진단모델을 저장하는 메모리; 및원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하고, 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하며, 상기 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하고, 상기 제1 병변오브젝트와 관련된 진단 정보출력 결과 상기 제1 병변오브젝트가 검출된 것인지 여부를 판단하며, 상기 판단에 기초해 상기 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성할 것인지 여부를 결정하는 프로세서;를 포함하는,병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치."}
{"patent_id": "10-2021-0114910", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법은, 원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하는 단계; 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위 한 최적의 위치를 판별하는 단계; 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하는 단계; 상기 제1 병변오브젝트에 대응하는 병변분포도 정 보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성하는 단계; 및 제2 병변진단모델을 통해 상기 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2021-0114910", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법에 관한 것으로, 보다 구체적으로 복수의 인공 지능 기반의 병변진단모델을 이용해 병변 진단의 속도와 함께 정밀도를 향상시키기 위 한 방법을 제공하기 위한, 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법에 관 한 것이다."}
{"patent_id": "10-2021-0114910", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "병리학 또는 병리과에서 수행하는 주요한 업무 중 하나는 환자의 생체이미지를 판독하여 특정 질병에 대한 상태 또는 징후를 판단하는 진단을 수행하는 일이다. 이러한 진단은 오랜 기간 숙련된 의료인의 경험과 지식에 의해 의존되는 방식이다. 최근에는 기계학습의 발달로 인해 이미지를 인식하거나 분류하는 등의 업무를 컴퓨터 시스템에 의해 자동화하고 자 하는 시도가 활발히 이루어지고 있다. 특히 기계학습의 일종인 뉴럴 네트워크(예컨대, 컨벌루션 뉴럴 네트워 크(Convolution neural network, CNN)를 이용한 딥러닝 방식)를 이용하여 숙련된 의료인이 수행하던 진단을 자 동화하기 위한 시도가 이루어지고 있다. 한편, 전체 슬라이드 영상(WSI, Whole Slide Image)은 수십억 개 이상의 픽셀로 구성되어 용량이 매우 크고 이 에 따라 전체 슬라이드 영상 자체로 병리를 진단하는 데 어려움이 있다는 문제가 있다. 이에 따라, 최근에는 생체이미지를 이용하는 뉴럴 네트워크를 통한 질병의 진단은 생체이미지의 조각 즉, 패치 (patch, 또는 타일(tile)이라고도 함)을 이용한다. 즉, 해당 타일에 대해 숙련된 의료인은 특정 질병의 상태(예 컨대, 암이 발현되었는지 여부)를 어노테이션(annotaion)하고, 이러한 어노테이션된 다수의 타일들을 트레이닝 데이터로 이용하여 뉴럴 네트워크를 학습하게 된다. 이때 상기 뉴럴 네트워크는 컨볼루션 뉴렬 네트워크가 이용 될 수 있다. 하지만, 이러한 방식의 경우 학습된 뉴럴 네트워크는 해당 타일의 이미지 특징만으로 해당 타일의 질병의 상태 를 판단하게 되는데, 실제로는 특정 질병에 대해 특정 생체조직의 상태를 판단할 때에는 상기 특정 생체조직 자 체 뿐만 아니라 상기 특정 생체조직의 주변 조직의 현황(예컨대, 모양, 특정 패턴이 존재하는지 등)까지 같이고려되어야 하는 경우가 발생한다."}
{"patent_id": "10-2021-0114910", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 필요성을 고려하여 도출된 것으로, 병변을 검출하고자 하는 대상 패치뿐 아니라 주변 패치까 지 고려하여 병변 진단의 정밀도를 향상시키고자 하는 데에 그 목적이 있다. 더불어, 병변을 검출하고자 하는 대상 패치의 위치를 먼저 판별하여 이미지 전체를 대상으로 진단하는 것이 아 닌 필요한 부분의 패치부터 선별하여 진단하도록 함으로써 병변 진단의 속도를 향상시키고자 하는 데에 그 목적 이 있다."}
{"patent_id": "10-2021-0114910", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법은, (a) 원본이미 지가 소정의 크기로 분할된 패치이미지들을 획득하는 단계; (b) 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하는 단계; (c) 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하는 단계; (d) 상기 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성하는 단계; 및 (e) 제 2 병변진단모델을 통해 상기 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력하는 단계;를 포함할 수 있다. 상기 (b)는, 상기 병변분포도 정보 및 환자의 속성 정보 중 적어도 하나를 참조해 상기 제1 병변오브젝트를 검 출하기 위한 상기 최적의 위치를 판별하는 단계;를 포함할 수 있다. 상기 (b)는, 상기 제1 병변오브젝트의 종류, 위치, 및 크기 중 적어도 하나에 기초해 상기 병변분포도 정보를 참조하기 위한 전략을 결정하는 단계; 및 상기 전략에 기초해 상기 병변분포도 정보를 참조하는 단계;를 포함할 수 있다. 상기 (b)의 상기 전략은 탐색 방향, 탐색 간격, 및 탐색 색상 중 어느 하나의 정보를 포함할 수 있다. 상기 (d)는, 상기 제1 병변오브젝트의 종류, 위치, 및 크기 중 적어도 하나에 기초해 상기 병변분포도 정보를 참조하기 위한 전략을 결정하는 단계; 및 상기 전략에 기초해 상기 병변분포도 정보를 참조하는 단계;를 포함할 수 있다. 상기 (d)의 상기 전략은 탐색 방향, 탐색 간격, 및 탐색 색상 중 어느 하나의 정보를 포함할 수 있다. 상기 제1 병변오브젝트와 관련된 진단 정보는 상기 제1 병변오브젝트의 검출 정보, 제1 검출 확률 정보, 및 제1 좌표 정보 중 적어도 하나를 포함하고, 상기 제2 병변오브젝트와 관련된 진단 정보는 상기 제2 병변오브젝트의 검출 정보, 제2 검출 확률 정보, 및 제2 좌표 정보 중 적어도 하나를 포함할 수 있다. 상기 제1 병변진단모델은 제1 학습용 패치이미지를 이용한 학습을 통해 생성될 수 있다. 상기 제1 병변진단모델은 상기 제1 학습용 패치이미지를 YOLO(You Only Look Once), SSD(Single Shot Multibox detection), Centernet, Cornernet, RetinaNet, ExtremeNet, RefineDet 중 적어도 하나를 학습시켜 생성될 수 있다. 상기 제2 병변진단모델은 제2 학습용 패치이미지를 이용한 학습을 통해 생성될 수 있다. 상기 제2 병변진단모델은 상기 제2 학습용 패치이미지를 fast-CNN(Convolutional Neural Network), mask-RCNN, VGGNet, GoogLeNet, R(Region)- CNN, Faster R(Faster Region)-CNN, DenseNet 중 적어도 하나를 학습시켜 생 성될 수 있다. 상기 제2 패치이미지에 대한 진단 완료 플래그를 설정하는 단계;를 더 포함할 수 있다. 다른 실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법은 원본이미 지가 소정의 크기로 분할된 패치이미지들을 획득하는 단계; 상기 패치이미지들로부터 제1 병변오브젝트를 검출 하기 위한 최적의 위치를 판별하는 단계; 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미 지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하는 단계; 상기 제1 병변오브젝트와 관련된 진단 정보 출력 결과 상기 제1 병변오브젝트가 검출된 것인지 여부를 판단하는 단계; 및 상기 판단에 기초해 상기 제 1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성할 것인지 여부를 결정하는 단계;를 포함할 수 있다. 상기 (d)에서 상기 제1 병변오브젝트가 검출된 것으로 판단되면, 상기 (e)는 상기 제1 병변오브젝트에 대응하는 상기 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 상기 제2 패치이미지를 생성할 것으로 결정하고, 상기 (d)에서 상기 제1 병변오브젝트가 검출되지 않은 것으로 판단되면, 상기 (e)는 상기 제1 패치이미지에 대 한 진단 완료 플래그를 설정할 것으로 결정할 수 있다. (f) 제2 병변진단모델을 통해 상기 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력하는 단 계;를 더 포함할 수 있다. 실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치는 제1 병변진단모 델과 제2 병변진단모델을 저장하는 메모리; 및 원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하고, 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하며, 상기 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하 고, 상기 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미 지를 생성하며, 제2 병변진단모델을 통해 상기 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력하는 프로세서;를 포함할 수 있다. 실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치는 제1 병변진단모 델과 제2 병변진단모델을 저장하는 메모리; 및 원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하고, 상기 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하며, 상기 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하 고, 상기 제1 병변오브젝트와 관련된 진단 정보 출력 결과 상기 제1 병변오브젝트가 검출된 것인지 여부를 판단 하며, 상기 판단에 기초해 상기 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지 보다 큰 제2 패치이미지를 생성할 것인지 여부를 결정하는 프로세서;를 포함할 수 있다."}
{"patent_id": "10-2021-0114910", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 병변을 검출하고자 하는 대상 패치 뿐 아니라 주변 패치까지 고려하여 병변 진단의 정밀도를 향상시킬 수 있게 된다. 더불어, 병변을 검출하고자 하는 대상 패치의 위치를 먼저 판별하여 이미지 전체를 대상으로 진단하는 것이 아 닌 필요한 부분의 패치부터 선별하여 진단하도록 함으로써 병변 진단의 속도를 향상시킬 수 있게 된다."}
{"patent_id": "10-2021-0114910", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시 예로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미 로서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모 든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하 거나 유사한 기능을 지칭한다. 도 1은 실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치의 블록 도이다. 도 1에 도시한 바와 같이, 실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치는 프로세서와 메모리를 포함할 수 있다. 메모리는 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치의 동작에 필요 한 각종 프로그램 및 데이터 등을 저장할 수 있다. 실시예에 따르면 메모리는 패치이미지, 병변오브젝트, 병변분포도 정보, 학습용 패치이미지 등을 저장할 수 있다. 실시예에 따른 메모리는 제1 병변진단모델/제2 병변진단모델을 저장할 수 있다. 실시예에 따르면, 제1 병변진단모델/제2 병변진단모델은 제1 학습용 패치이미지/제2 학습용 패치이미지 를 신경망 모델에 입력시키는 학습을 통해 획득된 인공지능에 기반한 모델일 수 있다. 프로세서는 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치의 전반적인 동작을 제어할 수 있다. 구체적으로, 프로세서는 원본이미지가 소정의 크기로 분할된 패치이미지들을 획득하고, 상기 패치이미지들 로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별하고, 제1 병변진단모델을 통해 상기 최적의 위치에 대응하는 제1 패치이미지로부터 상기 제1 병변오브젝트와 관련된 진단 정보를 출력하며, 상기 제1 병변 오브젝트에 대응하는 병변분포도 정보를 참조하여 상기 제1 패치이미지보다 큰 제2 패치이미지를 생성하고, 제2 병변진단모델을 통해 상기 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출력할 수 있다. 실시예에 따르면, 프로세서는 제1 병변진단모델/제2 병변진단모델을 이용해 제1 병변오브젝트와 관 련된 진단 정보/제2 병변오브젝트와 관련된 진단 정보가 출력되도록 할 수 있다. 실시예에 따르면, 프로세서는 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장 치의 내부에 구비된 제1 병변진단모델/제2 병변진단모델을 이용해 제1 병변오브젝트와 관련된 진단 정보/제2 병변오브젝트와 관련된 진단 정보가 출력되도록 할 수 있다. 이 때, 일 실시예에 따르면 프로세서(1 0)와 제1 병변진단모델/제2 병변진단모델은 서로 별개의 IC로 구현될 수 있으며, 다른 실시예에 따르면 프로세서와 제1 병변진단모델/제2 병변진단모델이 하나의 IC 칩내에 구비될 수 있다. 다른 실시예에 따르면, 프로세서는 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진 단 장치의 외부에 배치된 제1 병변진단모델/제2 병변진단모델을 이용해 제1 병변오브젝트와 관련된 진단 정보/제2 병변오브젝트와 관련된 진단 정보가 출력되도록 할 수 있다. 이 때, 프로세서는 외부에 배치 된 제1 병변진단모델/제2 병변진단모델에 제1 패치이미지/제2 패치이미지를 전달하고, 제1 병변진단모 델/제2 병변진단모델로부터 출력된 제1 병변오브젝트와 관련된 진단 정보/제2 병변오브젝트와 관련된 진단 정보를 수신할 수 있다. 실시예에 따르면, 프로세서 및/또는 제1 병변진단모델/제2 병변진단모델은 소프트웨어 모듈로 구현 되거나 적어도 하나의 하드웨어 칩 형태로 제작되어 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기 반의 병변 진단 장치에 탑재될 수 있다. 예를 들어, NPU(Neural Processing Unit)와 같은 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작되거나, 기존의 범용 프로세서(예: CPU 또는 Application Processor) 또는 그래픽 전용 프로세서(예: GPU(Graphic Processing Unit) 또는 VPU(Visual Processing Unit))의 일부로 제작되어 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단장치에 탑재될 수 있다. [실시 형태 1] 도 2 내지 도 4는 실시 형태 1에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법을 설명하는 순서도이고, 도 7 내지 도 9는 도 2 내지 도 4의 방법을 설명하기 위해 참조되는 도면이다. 도 2 내지 도 4를 참조하면, 프로세서는 원본이미지가 소정의 크기로 분할된 패치이미지들을 획득할 수 있 다(s210). 실시예에 따르면, 원본이미지는 고용량의 이미지로 구성되고 패치이미지는 저용량의 이미지로 구성될 수 있다. 예를 들어, 원본이미지는 디지털 병리 이미지를 나타내는 전체 슬라이드 영상(WSI, Whole Slide Image)일 수 있 으나, 본 발명의 권리범위는 이에 제한되지 않는다. 본 발명에서 패치이미지는 원본이미지가 사용자가 임의로 지정한 단위 크기(ex> 픽셀)로 슬라이싱 처리된 것으 로, 하나의 원본이미지는 복수의 패치이미지들을 포함할 수 있다. 그리고, 복수의 패치이미지들 각각은 원본이 미지를 기준으로 하여 슬라이싱 처리된 순차적 좌표 정보를 가질 수 있다. 예를 들어, 도 7을 참조하면, 원본이미지가 분할된 패치이미지들 각각이 이미지풀(pool)을 형성한 것을 알 수 있으며, 이미지풀은 메모리에 저장될 수 있다. 실시예에 따르면, 분할된 패치이미지들 각각은 병렬 구조로 이미지풀을 형성할 수 있다. 실시예에 따르면, 프로세서는 패치이미지들 각각을 메모리로부터 독출하거나 실시간 원본이미지를 슬라 이싱처리하여 획득할 수 있다. 프로세서는 패치이미지들로부터 제1 병변오브젝트를 검출하기 위한 최적의 위치를 판별할 수 있다(s220). 전술한 바와 같이, 고용량의 원본이미지는 저용량의 패치이미지들로 구성되어 있고, 원본이미지를 기준으로 전 부 진단하는 것이 아닌 패치이미지들을 기준으로 일부 선별하여 진단하도록 할 필요가 있으므로, 이를 고려하여 패치이미지들 중 어떤 패치이미지부터 진단되도록 할 지 순서를 결정하는 것이 중요하다. 즉, 원본이미지상의 어떤 위치에 있는 패치이미지부터 진단되도록 할 지 순서를 결정하고, 해당 위치에 있는 패치이미지부터 제1 병 변진단모델에 입력되도록 하기 위하여 프로세서는 패치이미지들로부터 제1 병변오브젝트를 검출하기 위 한 최적의 위치를 판별할 수 있다. 실시예에 따르면, 프로세서는 제1 병변오브젝트에 대응하는 병변분포도 정보 및 환자의 속성 정보 중 적어 도 하나를 참조해 최적의 위치를 판별할 수 있다. 참고로 본 발명에서, 제1 병변오브젝트는 패치이미지들로부터 최초로 검출 대상이 되도록 설정된 것일 수 있다. 실시예에 따르면, 병변분포도 정보는 패치이미지 상에서 분포하는 병변오브젝트의 확률적 통계 정보를 의미할 수 있다. 즉, 병변오브젝트의 종류, 위치, 크기, 방향, 간격, 및 색상 중 적어도 하나의 속성이 조합되어 생성 된 확률적 통계 정보를 의미할 수 있다. 실시예에 따르면, 병변분포도 정보는 병변오브젝트마다 각각의 자체 속성값을 가지도록 구현할 수 있다. 실시예에 따르면, 병변오브젝트의 속성값은 임의의 패치이미지를 기준으로 한 상대적인 값으로 기록될 수 있다. 실시예에 따르면, 임의의 패치이미지는 병변오브젝트가 이미 검출된 이미지일 수 있다. 예를 들어, 임의의 패치이미지를 기준으로 한 상대적 위치, 상대적 크기, 상대적 방향, 상대적 간격, 상대적 색 상, 임의의 패치이미지와 검출 대상이 되는 병변오브젝트가 동종인지 여부 등의 정보가 각각의 병변오브젝트에 대응되어 기록될 수 있다. 실시예에 따르면, 임의의 패치이미지를 기준으로 한 병변오브젝트가 복수 개 인 경우, 각 병변오브젝트마다 대 응되는 대표 속성값을 대응시켜 병변분포도 정보에 포함시킬 수 있다. 또한, 임의의 패치이미지에 대응하여 대 표 속성값을 가지는 각각의 병변오브젝트의 위치도 병변분포도 정보에 포함시켜 기록할 수 있다. 예를 들어, 임의의 패치이미지(A)의 위치를 기준으로 한 이웃 병변오브젝트가 복수 개(B1 내지 B3)인 경우, 임 의의 패치이미지(A)는 B1 병변오브젝트 내지 B3 병변오브젝트 각각에 대한 상대적 속성값을 모두 가질 수 있다.그리고, B1 병변오브젝트에 대해서는, 임의의 패치이미지(A)를 기준으로 한 상대적 속성값 중 '상대적 방향 정 보'가 통계적 확률에 기반한 대표값이 되도록 기록될 수 있다. 즉, B1 병변오브젝트가 임의의 패치이미지(A)를 기준으로 하여 가장 '상대적 방향 정보'가 유사한 속성값을 가지는 것을 의미할 수 있다. 참고로, 여기서 상대 적 방향 정보가 가장 유사함은, 동일 간격으로 이격된 복수의 병변오브젝트 중 기 설정된 특정 방향(예> 상/하/ 좌/우 등)과 가장 방향성이 유사한 위치에 해당 병변오브젝트가 위치한 것을 의미할 수 있다. 이 경우, 상대적 방향 정보'가 가장 유사한 속성값을 가지는 것으로 판단되는 B1 병변오브젝트의 위치를 병변분포도 정보에 포함 시켜 기록할 수 있다. 한편, B2 병변오브젝트에 대해서는, 임의의 패치이미지(A)를 기준으로 한 상대적 속성값 중 '상대적 간격 정 보'가 통계적 확률에 기반한 대표값이 되도록 기록될 수 있다. 즉, B2 병변오브젝트가 패치이미지(A)를 기준으 로 하여 가장 '상대적 간격 정보'가 유사한 속성값을 가지는 것을 의미할 수 있다. 참고로, 여기서 상대적 간격 정보가 가장 유사함은, 동일 방향에 위치한 복수의 병변오브젝트 중 기 설정된 특정 간격(예> 소정의 행(row) 만큼 이격) 내에 해당 병변오브젝트가 위치한 것을 의미할 수 있다. 이 경우, '상대적 간격 정보'가 가장 유사 한 속성값을 가지는 것으로 판단되는 B2 병변오브젝트의 위치를 병변분포도 정보에 포함시켜 기록할 수 있다. 또 한편, B3 병변오브젝트에 대해서는, 임의의 패치이미지(A)를 기준으로 한 상대적 속성값 중 '상대적 색상 정 보'가 통계적 확률에 기반한 대표값이 되도록 기록될 수 있다. 즉, B3 병변오브젝트가 임의의 패치이미지(A)를 기준으로 하여 가장 '상대적 색상 정보'가 유사한 속성값을 가지는 것을 의미할 수 있다. 참고로, 여기서 상대 적 색상 정보가 가장 유사함은, 동일 방향 및/또는 간격에 위치한 복수의 병변오브젝트 중 기 설정된 특정 색상 (예> 제1 병변오브젝트의 색상)과 가장 유사한 색상을 B3 병변오브젝트가 가지는 것을 의미할 수 있다. 이 경우, '상대적 색상 정보'가 가장 유사한 속성값을 가지는 것으로 판단되는 B3 병변오브젝트의 위치를 병변분포 도 정보에 포함시켜 기록할 수 있다. 실시예에 따르면, 환자의 속성 정보는 환자의 나이, 성별, 신장, 체중, 인종, 환자 ID, 이름, 생년월일, 병명 등의 개인 식별 정보를 포함할 수 있다. 이하, 제1 병변오브젝트에 대응하는 병변분포도 정보 및 환자의 속성 정보 중 적어도 하나를 참조해 제1 병변오 브젝트를 검출하기 위한 최적의 위치를 결정하는 과정을 도 3을 참조하여 구체적으로 설명한다. 실시예에 따르면, 프로세서는 병변분포도 정보를 참조해 제1 병변오브젝트를 검출하기 위한 최적의 위치를 결정할 수 있다. 프로세서는 먼저, 현재 패치이미지의 위치를 결정할 수 있다(s221). 그리고, 제1 병변오브젝트의 종류, 위치, 및 크기 중 적어도 하나의 속성에 기초해 병변분포도 정보를 참조할 수 있다. 구체적으로, 제1 병변오브젝트의 종류, 위치, 및 크기 중 적어도 하나의 속성에 기초해 병변분포도 정보를 참조 하기 위한 전략을 결정하고(s222), 해당 전략에 기초해 병변분포도 정보를 참조할 수 있다. 실시예에 따르면, 소정의 전략은 탐색 방향, 탐색 간격, 및 탐색 색상 중 적어도 하나의 정보를 포함할 수 있다. 즉, 현재 패치이미지의 위치로부터 상기 최적의 위치를 결정하기 위해 프로세서가 현재 피치이미지의 위치 를 기준으로 어떤 방향으로/어떤 간격으로/어떤 색상을 탐색할 것인지에 대한 전략을 결정할 수 있다. 예를 들어, 제1 병변오브젝트가 3cm2인 자궁암인 경우, 프로세서는 '탐색 방향'이 최우선 평가 기준으로 된 전략을 결정할 수 있다(s223). 반면, 제1 병변오브젝트가 4cm2 전립선암으로 설정된 경우, 프로세서는 '탐색 간격'이 최우선 평가 기준으로 된 전략을 결정할 수 있다(s225). 또는, 제1 병변오브젝트가 5cm2 위암으로 설정 된 경우, 프로세서는 '탐색 색상'이 최우선 평가 기준으로 된 전략을 결정할 수 있다(s227). 다만, 이는 일 례이며, 다른 평가 기준이 최우선 평가 기준으로 된 전략을 결정하는 경우에도 본 발명이 동일/유사하게 적용될 수 있다. 프로세서는 결정된 전략에 기초해 메모리에 기록된 병변분포도 정보를 참조할 수 있다. 실시예에 따르면, 프로세서는 병변분포도 정보를 참조하여 제1 병변오브젝트를 검출하기 위한 위치를 결정 할 수 있다. 예를 들어, s223과 같이 '탐색 방향'이 최우선 평가 기준으로 된 전략을 결정한 경우, '탐색 방향'에 기초해 병 변분포도 정보를 참조할 수 있다(s224). 실시예에 따르면, 프로세서는 현재 패치이미지를 기준으로 기 설정된 특정 방향(예> 상/하/좌/우 등)과 가 장 방향성이 유사한 위치를 제1 병변오브젝트를 검출하기 위한 위치로 결정할 수 있다. 참고로, 여기서 기 설정 된 특정 방향은 통계 처리에 의해 반복 학습되어 획득된 결과일 수 있다. 또는, s225와 같이 '탐색 간격'을 최우선 평가 기준으로 된 전략으로 결정한 경우, '탐색 간격'에 기초해 병변 분포도 정보를 참조할 수 있다(s226). 실시예에 따르면, 프로세서는 현재 패치이미지를 기준으로 기 설정된 특정 간격(예> 소정의 행(row)만큼 이 격/평균거리/최대거리/최소거리/최적거리)과 가장 유사한 간격에 대응하는 위치를 제1 병변오브젝트를 검출하기 위한 위치로 결정할 수 있다. 참고로, 여기서 기 설정된 특정 간격은 통계 처리에 의해 반복 학습되어 획득된 결과일 수 있다. 또는, s227과 같이 '탐색 색상'이 최우선 평가 기준으로 된 전략을 결정한 경우, '탐색 색상'에 기초해 병변분 포도 정보를 참조할 수 있다(s228). 실시예에 따르면, 프로세서는 현재 패치이미지를 기준으로 기 설정된 특정 색상과 가장 유사한 색상에 대응 하는 위치를 제1 병변오브젝트를 검출하기 위한 위치로 결정할 수 있다. 참고로, 여기서 기 설정된 특정 색상은 제1 패치이미지와 동일/유사한 범위라고 판단되도록 통계 처리에 의해 반복 학습되어 획득된 결과일 수 있다. 한편, 프로세서는 병변분포도 정보를 참조하기 위한 별도의 전략을 결정하지 못한 경우, 랜덤 탐색하여 최 적의 위치를 결정할 수 있다(s229). 즉, 해당 제1 병변오브젝트의 속성을 고려한 전략 결정이 적합하지 않다고 판단하는 경우, 랜덤 탐색 방식을 이용할 수 있다. 실시예에 따르면, 프로세서는 메모리에 기록된 병변분포도 정보 및 환자의 속성 정보를 함께 참조해 제 1 병변오브젝트를 검출하기 위한 최적의 위치를 결정할 수 있다(s229-1). 예를 들어, 제1 병변오브젝트가 '자궁암' 이라고 하더라도, 환자가 20대 여성인 경우 자궁암의 속성과 60대 여 성인 경우 자궁암의 속성이 상이할 수 있으므로, 이를 함께 고려해 최적의 위치를 결정할 수 있다. 즉, 만일, 제1 병변오브젝트를 20대 여성의 3cm2인 크기를 가지는 자궁암으로 설정하고, 탐색 방향에 기초해 결정된 B1 병 변오브젝트가 상기 속성과 동일/유사한 것을 보이는 것으로 판단하면 B1 병변오브젝트의 위치를 최적의 위치로 결정할 수 있다. 반면, 제1 병변오브젝트가 '전립선암' 이라고 하더라도, 환자가 20대 남성인 경우 전립선암의 속성과 60대 남성 인 경우 전립선암의 속성이 상이할 수 있으므로, 이를 함께 고려해 최적의 위치를 결정할 수 있다. 즉, 만일, 제1 병변오브젝트를 20대 남성의 4cm2인 크기를 가지는 전립선암으로 설정하고, 탐색 간격에 기초해 결정된 B2 병변오브젝트가 상기 속성과 동일/유사한 것을 보이는 것으로 판단하면 B2 병변오브젝트의 위치를 최적의 위치 로 결정할 수 있다. 한편, 제1 병변오브젝트가 '위암' 이라고 하더라도, 환자가 20대인 경우 위암의 속성과 60대인 경우 위암의 속 성이 상이할 수 있으므로, 이를 함께 고려해 최적의 위치를 결정할 수 있다. 즉, 만일, 제1 병변오브젝트를 20 대 환자의 5cm2인 크기를 가지는 위암으로 설정하고, 탐색 색상에 기초해 결정된 B3 병변오브젝트가 상기 속성과 동일/유사한 것을 보이는 것으로 판단하면 B3 병변오브젝트의 위치를 최적의 위치로 결정할 수 있다. 프로세서는 제1 병변진단모델을 통해 최적의 위치에 대응하는 제1 패치이미지로부터 제1 병변오브젝트 와 관련된 진단 정보를 출력할 수 있다(s230). 프로세서는 전체 패치이미지들 중 s220 결과 판별된 최적의 위치에 대응하는 제1 패치이미지를 선별할 수 있다. 그리고, 프로세서는 해당 제1 패치이미지부터 순차적으로 제1 병변진단모델로 입력시킬 수 있다. 실시예에 따르면, 이미지풀에 형성된 복수의 제1 패치이미지는 각각 병렬 구조로 형성되어 순차적으로 제1 병변 진단모델에 입력될 수 있다. 실시예에 따르면, 제1 병변오브젝트와 관련된 진단 정보는 제1 병변오브젝트의 검출 정보, 제1 검출 확률 정보, 및 제1 좌표 정보 중 적어도 하나를 포함할 수 있다. 그리고, 제1 병변오브젝트의 검출 정보는 병변의 종류, 병변오브젝트의 크기, 위치, 불규칙 정도, 세포핵과 세포질의 비율 정보 등을 포함할 수 있다. 프로세서는 제1 학습용 패치이미지를 입력데이터로 하고 제1 학습용 병변오브젝트와 관련된 진단 정보를 출 력데이터로 하는 학습을 통해 제1 병변진단모델을 획득할 수 있으며, 이러한 학습 과정에 대해서는 도 6을 참조하여 후술한다. 실시예에 따르면, 제1 병변진단모델은 오브젝트 검출 시 위치 선택과정(localization)과 분류과정 (localization)이 동시에 이루어지는 1-stage detector 방식의 신경망 모델을 학습시킬 수 있다. 실시예에 따르면, 제1 병변진단모델은 제1 학습용 패치이미지를 YOLO(You Only Look Once), SSD(Single Shot Multibox detection), Centernet, Cornernet, RetinaNet, ExtremeNet, RefineDet중 적어도 하나의 신경 망 모델을 학습시켜 생성될 수 있다. YOLO는 입력이미지를 구성하는 그리드 영역에 해당하는 바운딩 박스와 클래스 확률맵 등을 이용해 검출 속도를 향상시킨 모델이다. SSD는 이미지 특징을 다양한 위치의 레이어들에서 추출하여 검출부와 분류기를 적용한 모델 이다. Cornernet은 쌍으로 된 특징점 추출과 예측 모듈, 히트맵, 바운딩 박스의 위치 파악을 위한 오프셋, 동일 오브젝트인지 판단할 수 있는 임베딩 등을 적용해 오브젝트를 검출하는 방식이다. Centernet은 Cornernet과 유 사하나 하나의 특징점(중심점) 추출과 오브젝트의 사이즈, 오프셋을 출력값으로 예측하여 오브젝트를 검출하는 방식을 적용한 모델이다. 다만, 이는 일례이며, 1-stage detector 방식의 다른 어떠한 신경망 모델인 경우에도 본 발명의 제1 병변진단모델에 동일/유사하게 적용될 수 있다. 본 발명의 경우 상기 신경망 모델을 이용한 학습을 통해 보다 빠른 진단을 하기 위한 제1 병변진단모델을 획득할 수 있다. 프로세서는 제1 패치이미지로부터 검출된 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 제1 패 치이미지보다 큰 제2 패치이미지를 생성할 수 있다(s240). 이에 대해서는, 도 4를 참조하여 상세하게 설명한다. 제1 패치이미지는 크기가 작으므로 해당 패치이미지의 경계에 위치한 병변오브젝트는 제대로 검출되지 않을 수 있게 된다. 따라서, 이를 개선하기 위해 제1 패치이미지로부터 병변오브젝트가 검출된 경우, 제1 패치이미지를 중심으로 한 새로운 영역에 포함된 병변오브젝트까지 함께 검출하기 위하여 제2 패치이미지를 설정하여 다시 검 출할 필요가 있다. 본 발명에 따르면, 이러한 과정을 통해 병변 진단에 대한 정밀도가 향상되게 된다. 즉, 본 발명의 제2 패치이미지는 제1 패치이미지를 포함하여 생성된 영역으로 정의될 수 있다. 참고로, 도 8을 예시하면, 도 7의 이미지풀에 포함된 각 패치이미지들보다 크기가 큰 제2 패치이미지가 형성된 것을 알 수 있다. 구체적으로, 제1 병변오브젝트의 종류, 위치, 및 크기 중 적어도 하나의 속성에 기초해 병변분포도 정보를 참조 하기 위한 전략을 결정하고(s241), 해당 전략에 기초해 병변분포도 정보를 참조할 수 있다. 실시예에 따르면, 전략은 탐색 방향, 탐색 간격, 및 탐색 색상 중 적어도 하나의 정보를 포함할 수 있다. 즉, 제1 패치이미지로부터 제2 패치이미지를 생성하기 위해 프로세서가 제1 패치이미지를 기준으로 어떤 방 향으로/어떤 간격으로/어떤 색상을 탐색할 것인지에 대한 전략을 결정할 수 있다. 예를 들어, 제1 병변오브젝트가 3cm2인 자궁암인 경우, 프로세서는 '탐색 방향'이 최우선 평가 기준으로 된 전략을 결정할 수 있다(s242). 반면, 제1 병변오브젝트가 4cm2 전립선암으로 설정된 경우, 프로세서는 '탐색 간격'이 최우선 평가 기준으로 된 전략을 결정할 수 있다(s244). 또는, 제1 병변오브젝트가 5cm2 위암으로 설정 된 경우, 프로세서는 '탐색 색상'이 최우선 평가 기준으로 된 전략을 결정할 수 있다(s246). 다만, 이는 일 례이며, 다른 평가 기준이 최우선 평가 기준으로 된 전략을 결정하는 경우에도 본 발명이 동일/유사하게 적용될 수 있다. 프로세서는 결정된 전략에 기초해 메모리에 기록된 병변분포도 정보를 참조할 수 있다. 예를 들어, s242와 같이 '탐색 방향'이 최우선 평가 기준으로 된 전략을 결정한 경우, '탐색 방향'에 기초해 병 변분포도 정보를 참조하고, 해당 병변분포도 정보로부터 확인된 패치이미지를 제2 패치이미지로 결정할 수 있다 (s243). 실시예에 따르면, 프로세서는 제1 패치이미지를 기준으로 기 설정된 특정 방향(예> 상/하/좌/우 등)과 가장 방향성이 유사한 위치에 있는 병변오브젝트를 포함한 영역에 대응하는 이미지를 제2 패치이미지로 결정할 수 있 다. 참고로, 여기서 기 설정된 특정 방향은 통계 처리에 의해 반복 학습되어 획득된 결과일 수 있다. 또는, s244와 같이 '탐색 간격'을 최우선 평가 기준으로 된 전략으로 결정한 경우, '탐색 간격'에 기초해 병변 분포도 정보를 참조하고, 해당 병변분포도 정보로부터 확인된 패치이미지를 제2 패치이미지로 결정할 수 있다 (s245). 실시예에 따르면, 프로세서는 제1 패치이미지를 기준으로 기 설정된 특정 간격(예> 소정의 행(row)만큼 이 격)과 가장 유사한 간격 내에 있는 병변오브젝트를 포함한 영역에 대응하는 이미지를 제2 패치이미지로 결정할 수 있다. 참고로, 여기서 기 설정된 특정 간격은 통계 처리에 의해 반복 학습되어 획득된 결과일 수 있다. 또는, s246과 같이 '탐색 색상'이 최우선 평가 기준으로 된 전략을 결정한 경우, '탐색 색상'에 기초해 병변분 포도 정보를 참조하고, 해당 병변분포도 정보로부터 확인된 패치이미지를 제2 패치이미지로 결정할 수 있다 (s247). 실시예에 따르면, 프로세서는 제1 패치이미지를 기준으로 기 설정된 특정 색상과 가장 유사한 색상을 가지 는 병변오브젝트를 포함한 영역에 대응하는 이미지를 제2 패치이미지로 결정할 수 있다. 참고로, 여기서 기 설 정된 특정 색상은 제1 패치이미지와 동일/유사한 범위라고 판단되도록 통계 처리에 의해 반복 학습되어 획득된 결과일 수 있다. 한편, 프로세서는 병변분포도 정보를 참조하기 위한 별도의 전략을 결정하지 못한 경우, 디폴트 패치이미지 를 제2 패치이미지로 결정할 수 있다(s248). 즉, 해당 제1 병변오브젝트의 속성을 고려한 전략 결정이 적합하지 않다고 판단하는 경우, 메모리에 기 저 장된 디폴트 패치이미지를 제2 패치이미지로 결정할 수 있다. 프로세서는 제2 병변진단모델을 통해 제2 패치이미지로부터 제2 병변오브젝트와 관련된 진단 정보를 출 력할 수 있다(s250). 실시예에 따르면, 제2 병변오브젝트와 관련된 진단 정보는 제2 병변오브젝트의 검출 정보, 제2 검출 확률 정보, 및 제2 좌표 정보 중 적어도 하나를 포함할 수 있다. 그리고, 제2 병변오브젝트의 검출 정보는 병변의 종류, 병 변오브젝트의 크기, 위치, 불규칙 정도, 세포핵과 세포질의 비율 정보 등을 포함할 수 있다. 프로세서는 제2 학습용 패치이미지를 입력데이터로 하고 제2 학습용 병변오브젝트와 관련된 진단 정보를 출 력데이터로 하는 학습을 통해 제2 병변진단모델을 획득할 수 있으며, 이러한 학습 과정에 대해서는 도 6을 참조하여 후술한다. 실시예에 따르면, 제2 병변진단모델은 오브젝트 검출 시, 위치 선택과정(localization)과 분류과정 (localization)이 순차적으로 별도의 단계로 이루어지는 2-stage detector 방식의 신경망 모델을 학습시킬 수 있다. 실시예에 따르면, 제2 병변진단모델은 제2 학습용 패치이미지를 fast-CNN(Convolutional Neural Network), mask-RCNN, VGGNet, GoogLeNet, R(Region)- CNN, Faster R(Faster Region)-CNN, DenseNet 중 적어도 하나를 이용해 학습시켜 적어도 하나의 신경망 모델을 이용해 학습시켜 생성될 수 있다. R-CNN은 Selective Search와 CNN의 결합한 방법으로써 일반적인 CNN 방식보다 빠르게 사물 인식 가능하다. Faster R-CNN은 첫 번째 모듈에서 입력 이미지의 중요한 정보가 압축된 Feature를 계산하고, 두 번째 모듈 Region Proposal Network(RPN)으로 입력 이미지에서 object가 있을만한 영역(region)을 제안하며 마지막 모듈 object를 판별할 수 있다. mask-RCNN은 Faster R-CNN과 바이너리 마스크(binary mask)를 접목하여 분할된 이미 지를 마스킹하는 모델이다. 다만, 이는 일례이며, 2-stage detector 방식의 다른 어떠한 신경망 모델인 경우에도 본 발명의 제2 병변진단모 델에 동일/유사하게 적용될 수 있다. 본 발명의 경우 상기 신경망 모델을 이용한 학습을 통해 보다 정확한 진단을 하기 위한 제2 병변진단모델을 획득할 수 있다. 한편, 프로세서는 s250에서 제2 병변오브젝트와 관련된 진단 정보를 출력한 다음, 제2 패치이미지에 대한 진단 완료 플래그를 설정할 수 있다(미도시).실시예에 따르면, 진단 완료 플래그는 진단 완료 정보를 기록해두고, 추후 다시 동일 제2 패치이미지에 대해서 는 검출을 수행하지 않기 위해 설정될 수 있다. 프로세서는 진단 완료 플래그를 설정한 후, 다시 다른 패치이미지들에 대하여 s220 내지 s250을 반복하여 수행할 수 있다. 예를 들어, 도 9는 이미지풀에서 제2 패치이미지에 대응하는 영역에 대하여 진단 완료 플래그가 설정되고 해당 영역에 포함된 패치들은 이미지풀에서 삭제된 것을 나타낸다. 실시예에 따르면, 제1 좌표 정보 및/또는 제2 좌표 정보는 각각 단독/조합 되어 원본이미지 상의 좌표 정보로 변환된 후 해당 변환된 좌표 정보를 기초로 디스플레이부(미도시)를 통해 출력될 수 있다. 이로서, 사용자는 디 스플레이부(미도시)에 표기된 병변의 위치를 확인할 수 있게 된다. [실시 형태 2] 도 5는 실시 형태 2에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법을 설 명하는 순서도이다. 실시 형태 2의 경우 특별하게 기술하지 않는 내용에 대해서는 실시 형태 1의 내용이 동일/유사하게 적용될 수 있다. 도 5의 s310, s320, s330, s350, s370은 각각 도 2의 s210, s220, s230, s240, s250의 내용이 동일/유사하게 적용될 수 있다. 도 5의 경우, 실시예에 따르면, 프로세서는 s330에서 제1 병변오브젝트와 관련된 진단 정보를 출력한 다음, 제1 병변오브젝트와 관련된 진단 정보를 참조해 제1 병변오브젝트가 검출되었는지 여부를 판단할 수 있다 (s340). 즉, 제1 병변오브젝트와 관련된 진단 정보는 제1 병변오브젝트에 대한 검출 여부 판단 정보를 더 포함 할 수 있다. 그리고, 해당 판단 결과에 기초해 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 제1 패치이미지보다 큰 제2 패치이미지를 생성할 것인지 여부를 결정할 수 있다. 구체적으로, 만일 프로세서가 제1 병변오브젝트가 검출된 것으로 판단하면, 제1 병변오브젝트에 대응하는 병변분포도 정보를 참조하여 제1 패치이미지보다 큰 제2 패치이미지를 생성할 것으로 결정할 수 있다(s350). 한편, 만일 프로세서가 제1 병변오브젝트가 검출되지 않은 것으로 판단하면, 제1 패치이미지에 대한 진단 완료 플래그를 설정할 것으로 결정할 수 있다(s360). 실시예에 따르면, 진단 완료 플래그는 진단 완료 정보를 기록해두고, 추후 다시 동일 제1 패치이미지에 대해서 는 검출을 수행하지 않기 위해 설정될 수 있다. 프로세서는 진단 완료 플래그를 설정한 후, 다시 다른 패치이미지들에 대하여 s320 내지 s340을 반복하여 수행할 수 있다. 한편, 프로세서는 s370에서 제2 병변오브젝트와 관련된 진단 정보를 출력한 다음, 제2 패치이미지에 대한 진단 완료 플래그를 설정할 수 있다(s380). 실시예에 따르면, 진단 완료 플래그는 진단 완료 정보를 기록해두고, 추후 다시 동일 제2 패치이미지에 대해서 는 검출을 수행하지 않기 위해 설정될 수 있다. 프로세서는 진단 완료 플래그를 설정한 후, 다시 다른 패치이미지들에 대하여 s320 내지 s380을 반복하여 수행할 수 있다. 예를 들어, 도 9는 이미지풀에서 제2 패치이미지에 대응하는 영역에 대하여 진단 완료 플래그가 설정되고 해당 영역에 포함된 패치들은 이미지풀에서 삭제된 것을 나타낸다. 도 6은 실시예에 따른 제1 병변진단모델/제2 병변진단모델 생성을 위해 프로세서가 신경망 모델을 기초로 학습하는 과정을 설명하는 블록도이다. 프로세서는 제1 학습용 패치이미지/제2 학습용 패치이미지를 입력받아 신경망 모델을 학습시켜 제1 병변진 단모델/제2 병변진단모델을 획득할 수 있으며, 이를 위하여 데이터 획득부, 전처리부, 학습 데이터 선택부, 신경망 학습부, 및 신경망 평가부를 포함할 수 있다. 구체적으로, 데이터 획득부는 제1 학습용 패치이미지/제2 학습용 패치이미지를 획득할 수 있다. 실시예에 따르면, 제1 학습용 패치이미지/제2 학습용 패치이미지는 각각 제1 학습용 병변오브젝트와 관련된 진 단 정보/제2 학습용 병변오브젝트와 관련된 진단 정보가 라벨링되어 학습 데이터로 준비될 수 있다. 데이터 획득부는 제1 학습용 패치이미지/제2 학습용 패치이미지를 생성하여 메모리에 저장한 후, 메모 리로부터 독출하거나 실시간 생성하여 획득할 수 있다. 데이터 획득부는 제1 학습용 패치이미지/제2 학습용 패치이미지로 데이터 셋트를 구성하여 신경망 모델(NM, Neural Network Model)에 입력시켜 학습이 수행되도록 할 수 있다. 전처리부는 획득된 제1 학습용 패치이미지/제2 학습용 패치이미지를 전처리할 수 있다. 전처리부는 제1 학습용 패치이미지/제2 학습용 패치이미지가 이용되기 적합한 형태로 가공하여 전처리를 수 행할 수 있다. 학습 데이터 선택부는 전처리된 데이터 중 학습에 필요한 데이터를 선택할 수 있다. 신경망 모델 학습부는 제1 학습용 패치이미지/제2 학습용 패치이미지를 학습 데이터로 신경망 모델(NM)에 입력시켜 어떻게 제1 병변오브젝트와 관련된 진단 정보/제2 병변오브젝트와 관련된 진단 정보를 산출할 수 있을 지에 관한 기준을 학습할 수 있다. 신경망 모델 학습부는 제1 학습용 패치이미지/제2 학습용 패치이미지를 입력데이터로 신경망 모델(NM)에 입 력시켜, 제1 학습용 병변오브젝트와 관련된 진단 정보/제2 학습용 병변오브젝트와 관련된 진단 정보를 출력데이 터로 출력시키는 과정을 통해 신경망 모델(NM)을 학습시킬 수 있다. 실시예에 따르면, 신경망 모델(NM)은 YOLO(You Only Look Once), SSD(Single Shot Multibox detection), Centernet, Cornernet, RetinaNet, ExtremeNet, RefineDet, fast-CNN(Convolutional Neural Network), mask- RCNN, VGGNet, GoogLeNet, R(Region)- CNN, Faster R(Faster Region)-CNN, DenseNet 등을 이용할 수 있으나, 본 발명이 이에 제한되지 않는다. 신경망 모델(NM)에서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션 (convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 신경망 모델(NM)은 복수의 신경망 레이어들로 구성될 수 있고, 각 레이어는 복수의 가중치들을 가지고 있으며, 이전 레이어의 연산 결과와 복수의 가중치의 연산을 통해 현 레이어의 연산을 수행할 수 있다. 신경망 모델 학습부는 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법 (gradientdescent)을 포함하는 학습 알고리즘 등을 이용하여 신경망 모델(NM)을 학습시킬 수 있다. 실시예에 따르면, 신경망 모델 학습부는 제1 학습용 패치이미지/제2 학습용 패치이미지를 입력데이터로 하 는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 실시예에 따르면, 신경망 모델 학습부는 제1 학습용 패치이미지/제2 학습용 패치이미지에 기초하여 어떻게 제1 학습용 병변오브젝트와 관련된 진단 정보/제2 학습용 병변오브젝트와 관련된 진단 정보를 출력 정보로 결정 할지의 판단을 위한 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 신경망 모델 학습부는 신경망 모델(NM)을 통해 출력되는 결과의 정확도를 높이기 위해, 입력데이터에 근거 해 출력 레이어에서 입력 레이어 방향으로 기계 학습을 반복적으로 수행하며 출력 결과의 정확도가 높아지도록 가중치값들을 수정할 수 있다. 신경망 모델 평가부는 신경망 모델(NM)에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 인식 결과 가 소정의 기준을 만족하지 못하는 경우, 신경망 모델 학습부를 통해 다시 학습하도록 할 수 있다. 이 때, 평가 데이터는 신경망 모델을 평가하기 위해 기 설정된 데이터일 수 있다. 이상에서 실시예들에 설명된 특징, 구조, 효과 등은 본 발명의 하나의 실시예에 포함되며, 반드시 하나의 실시 예에만 한정되는 것은 아니다. 나아가, 각 실시예에서 예시된 특징, 구조, 효과 등은 실시예들이 속하는 분야의 통상의 지식을 가지는 자에 의해 다른 실시예들에 대해서도 조합 또는 변형되어 실시 가능하다. 따라서 이러한조합과 변형에 관계된 내용들은 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다. 또한, 이상에서 실시예를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니며, 본 발 명이 속하는 분야의 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성을 벗어나지 않는 범위에서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 예를 들어, 실시예에 구체적으로 나타 난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0114910", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 장치의 블록도 이다. 도 2 내지 도 4는 실시 형태 1에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법을 설명하는 순서도이고, 도 7 내지 도 9는 도 2 내지 도 4의 방법을 설명하기 위해 참조되는 도면이다. 도 5는 실시 형태 2에 따른 병변 진단 속도와 정밀도를 향상시키기 위한 인공 지능 기반의 병변 진단 방법을 설 명하는 순서도이다. 도 6은 실시예에 따른 제1 병변진단모델/제2 병변진단모델 생성을 위해 프로세서가 신경망 모델을 기초로 학습 하는 과정을 설명하는 블록도이다."}
