{"patent_id": "10-2021-0027610", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0123975", "출원번호": "10-2021-0027610", "발명의 명칭": "인공지능 학습 장치 및 방법", "출원인": "연세대학교 산학협력단", "발명자": "김시호"}}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "상태 데이터와 보상 데이터가 인가되면, 기설정된 액터 데이터에 따라 액션 데이터를 출력하는 에이전트 모듈; 상기 에이전트 모듈로부터 액션 데이터가 인가되면, 기설정된 환경 데이터에 따라 인가된 액션 데이터에 대응하여 상태 데이터와 보상 데이터를 업데이트 하는 환경 모듈; 및 상기 에이전트 모듈 및 상기 환경 모듈에 미리 설정되거나 업데이트 되는 데이터 중 적어도 하나를 인가받아 기지정된 화면으로 구성하여 출력하고, 사용자에 의해 상기 에이전트 모듈 및 상기 환경 모듈에 미리 설정되거나업데이트되는 데이터 중 적어도 하나의 데이터를 변경하기 위한 변경 데이터가 설정되어 인가되면, 인가된 변경데이터에 대응하는 데이터를 변경 데이터로 대체하는 환경 변경 모듈을 포함하는 인공지능 학습 장치."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 환경 변경 모듈은 상기 변경 데이터의 종류에 따라 기지정된 차원을 확인하고, 상기 변경 데이터의 차원이 기지정된 차원과 상이하면, 상기 변경 데이터의 차원이 기지정된 차원이 되도록 변환하여, 상기 에이전트 모듈 또는 상기 환경 모듈로 인가하는 인공지능 학습 장치."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 환경 변경 모듈은 상기 변경 데이터의 차원이 기지정된 차원이 되도록 제로 패딩 기법에 따라 변환하는 인공지능 학습 장치."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 환경 변경 모듈은 상기 에이전트 모듈 및 상기 환경 모듈로부터 미리 설정되거나 업데이트 되는 데이터가 저장된 메모리 어드레스를 인가받아, 메모리에서 미리 설정되거나 업데이트 되는 데이터를 획득하는 인공지능 학습 장치."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 환경 변경 모듈은 상기 변경 데이터가 인가되면, 상기 메모리에 변경 데이터를 저장하고, 저장된 변경 데이터의 메모리 어드레스를 상기 에이전트 모듈 또는 상기 환경 모듈로 인가하는 인공지능 학습 장치."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "인공 지능 에이전트 모듈을 학습시키기 위한 컴퓨팅 장치에서 수행되는 방법으로서, 상기 에이전트 모듈과 상기 에이전트 모듈이 액션 데이터를 출력할 수 있도록 상태 데이터와 보상 데이터를 제공하는 환경 모듈을 구동시키기 위한 데이터를 설정하는 단계; 설정된 데이터에 따라 상기 에이전트 모듈과 상기 환경 모듈을 구동하여 강화 학습을 수행하는 단계; 및 강화 학습 중 사용자에 의해 상기 에이전트 모듈 및 상기 환경 모듈에 미리 설정되거나 업데이트되는 데이터 중적어도 하나의 데이터를 변경하기 위한 변경 데이터가 설정되어 인가되면, 인가된 변경 데이터에 대응하는 데이터를 변경 데이터로 대체하는 단계를 포함하는 인공지능 학습 방법."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 변경 데이터로 대체하는 단계는 공개특허 10-2022-0123975-3-변경 데이터가 설정되어 인가되면, 인가된 상기 변경 데이터의 종류에 따라 기지정된 차원을 확인하는 단계; 상기 변경 데이터의 차원이 기지정된 차원과 상이하면, 상기 변경 데이터의 차원이 기지정된 차원이 되도록 변환하는 단계; 및 변환된 변경 데이터를 상기 에이전트 모듈 또는 상기 환경 모듈로 인가하는 단계를 포함하는 인공지능 학습 방법."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 변환하는 단계는 상기 변경 데이터의 차원이 기지정된 차원이 되도록 제로 패딩 기법에 따라 변환하는 인공지능 학습 방법."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 데이터를 설정하는 단계는 상기 에이전트 모듈 및 상기 환경 모듈로부터 미리 설정되거나 업데이트 되는 데이터가 저장된 메모리 어드레스를 인가는 단계; 및 메모리에서 미리 설정되거나 업데이트 되는 데이터를 획득하는 인공지능 학습 방법."}
{"patent_id": "10-2021-0027610", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 변경 데이터로 대체하는 단계는 상기 변경 데이터가 인가되면, 상기 메모리에 변경 데이터를 저장하는 단계; 및 저장된 변경 데이터의 메모리 어드레스를 상기 에이전트 모듈 또는 상기 환경 모듈로 인가하는 단계를 포함하는인공지능 학습 방법."}
{"patent_id": "10-2021-0027610", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 상태 데이터와 보상 데이터가 인가되면, 기설정된 액터 데이터에 따라 액션 데이터를 출력하는 에이전 트 모듈, 에이전트 모듈로부터 액션 데이터가 인가되면, 기설정된 환경 데이터에 따라 인가된 액션 데이터에 대 응하여 상태 데이터와 보상 데이터를 업데이트 하는 환경 모듈 및 에이전트 모듈 및 환경 모듈에 미리 설정되거 (뒷면에 계속)"}
{"patent_id": "10-2021-0027610", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 학습 장치 및 방법에 관한 것으로, 강화 학습에 기반하는 학습 수행 중 액터, 액션, 보상 및 상태 등을 신규하게 변경할 수 있는 인공지능 학습 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0027610", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "강화학습은 현재의 상태(State)에서 어떤 액션(Action)을 취하는 것이 최적인지를 학습하는 기법으로, 강화 학 습에서는 액션을 취할 때마다 환경(Environment)의 상태 변화에 따른 보상(Reward)이 주어지며 이러한 보상을 최대화하는 방향으로 학습이 진행된다. 도 1은 강화 학습에 기반한 인공지능 학습 방법의 개념을 설명하기 위한 도면이다. 도 1을 참조하면, 강화 학습에서는 학습 대상이 되는 에이전트 모듈과 에이전트 모듈을 학습시키기 위한 환경 모듈로 구성될 수 있다. 에이전트 모듈은 환경 모듈로부터 현재 상태(S(t))와 이전 액션(A(t-1))에 대한 보상(R(t))이 주어지 면, 현재 상태(S(t))에서 보상(R(t))이 더 증가되도록 액션(A(t))을 결정한다. 그리고 환경 모듈은 에이 전트 모듈에서 결정한 액션(A(t))에 따라 상태(S(t))를 다음 상태(S(t+1))로 업데이트하고, 업데이트된 상 태(S(t+1))에 따른 보상(R(t+1))을 판단한다. 이와 같이 강화 학습에서는 에이전트 모듈이 선택하는 액션에 따라 변화되는 상태와 보상을 지속적으로 반 복하여 반영함으로써, 이후 더 나은 액션을 선택하도록 학습되는 학습 기법을 일컫는다. 그러나 기존의 강화 학습에서는 초기 액터와 초기 환경, 초기 상태, 초기 보상 등과 같은 초기 데이터가 설정된 이후로는 반복되는 강화 학습에 의해 초기 설정된 데이터가 반복적으로 업데이트될 뿐, 새로운 데이터를 입력할 수 있는 수단이 제공되지 않았다. 이에 기존에는 강화 학습 도중에 데이터가 완전히 새로운 데이터로 변경될 수 없었다. 만일 새로운 데이터로 강화 학습을 수행하기 위해서는 이전 수행하던 강화 학습을 종료시켜 학습된내용을 모두 초기화한 이후 다시 새로운 데이터를 초기 데이터로 인가하여 새로이 강화 학습을 수행해야 하였다. 특히 새로이 설정하고자 하는 데이터의 차원(dimension 또는 차수)가 이전 설정되거나 업데이트된 데이터와 상 이한 경우에는 차원의 차이로 인해 설정하고자 하는 데이터를 입력할 수 있는 방법이 없었다는 한계가 있다. 그러나 최근 강화 학습 기법이 적용되는 분야가 다양해짐에 따라 강화 학습 중인 에이전트 모듈과 환경 모듈에 다른 차원의 데이터로 변경하고자 하는 요구가 증대되고 있다. 일 예로 에이전트 모듈의 액터가 8개의 다 리를 갖는 거미 로봇이고, 강화 학습 기법에 따라 거미 로봇의 동작을 학습시키는 경우를 가정하면, 기존에는 에이전트 모듈이 액터인 거미 로봇에 설정된 8개의 다리를 주변 환경에 따라 최적으로 구동하는 액션만을 학습하게 된다. 그러나 다양한 환경 요인에 의해 8개의 다리 중 하나 또는 그 이상의 다리가 구동 불능인 상태 가 발생할 수도 있으며, 이 경우 기존의 강화 학습 방식으로 학습된 거미 로봇은 7개 또는 그 이하의 다리를 구 동할 수 없게 되는 문제가 발생하게 된다. 즉 강화 학습된 에이전트 모듈이 차원의 변화에 대처하지 못하는 한 계가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록 특허 제10-2079745호 (2020.02.14 등록)"}
{"patent_id": "10-2021-0027610", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 강화 학습 중에 각종 데이터를 다양하게 변화시킬 수 있는 인공지능 학습 장치 및 방법을 제 공하는데 있다. 본 발명의 다른 목적은 초기 설정값과 다른 설정값으로도 강화 학습을 계속 수행할 수 있도록 하는 인공지능 학 습 장치 및 방법을 제공하는데 있다."}
{"patent_id": "10-2021-0027610", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 인공지능 학습 장치는 상태 데이터와 보상 데이터가 인 가되면, 기설정된 액터 데이터에 따라 액션 데이터를 출력하는 에이전트 모듈; 상기 에이전트 모듈로부터 액션 데이터가 인가되면, 기설정된 환경 데이터에 따라 인가된 액션 데이터에 대응하여 상태 데이터와 보상 데이터를 업데이트 하는 환경 모듈; 및 상기 에이전트 모듈 및 상기 환경 모듈에 미리 설정되거나 업데이트 되는 데이터 중 적어도 하나를 인가받아 기지정된 화면으로 구성하여 출력하고, 사용자에 의해 상기 에이전트 모듈 및 상기 환경 모듈에 미리 설정되거나 업데이트되는 데이터 중 적어도 하나의 데이터를 변경하기 위한 변경 데이터가 설 정되어 인가되면, 인가된 변경 데이터에 대응하는 데이터를 변경 데이터로 대체하는 환경 변경 모듈을 포함한다. 상기 환경 변경 모듈은 상기 변경 데이터의 종류에 따라 기지정된 차원을 확인하고, 상기 변경 데이터의 차원이 기지정된 차원과 상이하면, 상기 변경 데이터의 차원이 기지정된 차원이 되도록 변환하여, 상기 에이전트 모듈 또는 상기 환경 모듈로 인가할 수 있다. 상기 환경 변경 모듈은 상기 변경 데이터의 차원이 기지정된 차원이 되도록 제로 패딩 기법에 따라 변환할 수 있다. 상기 환경 변경 모듈은 상기 에이전트 모듈 및 상기 환경 모듈로부터 미리 설정되거나 업데이트 되는 데이터가 저장된 메모리 어드레스를 인가받아, 메모리에서 미리 설정되거나 업데이트 되는 데이터를 획득할 수 있다. 상기 환경 변경 모듈은 상기 변경 데이터가 인가되면, 상기 메모리에 변경 데이터를 저장하고, 저장된 변경 데 이터의 메모리 어드레스를 상기 에이전트 모듈 또는 상기 환경 모듈로 인가할 수 있다. 상기 목적을 달성하기 위한 본 발명의 다른 실시예에 따른 인공지능 학습 방법은 상기 에이전트 모듈과 상기 에 이전트 모듈이 액션 데이터를 출력할 수 있도록 상태 데이터와 보상 데이터를 제공하는 환경 모듈을 구동시키기위한 데이터를 설정하는 단계; 설정된 데이터에 따라 상기 에이전트 모듈과 상기 환경 모듈을 구동하여 강화 학 습을 수행하는 단계; 및 강화 학습 중 사용자에 의해 상기 에이전트 모듈 및 상기 환경 모듈에 미리 설정되거나 업데이트되는 데이터 중 적어도 하나의 데이터를 변경하기 위한 변경 데이터가 설정되어 인가되면, 인가된 변경 데이터에 대응하는 데이터를 변경 데이터로 대체하는 단계를 포함한다."}
{"patent_id": "10-2021-0027610", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "따라서, 본 발명의 실시예에 따른 인공지능 학습 장치 및 방법은 강화 학습 중에 액터, 액션, 보상 및 상태 등 을 다양하게 변화시킬 수 있을 뿐만 아니라, 다른 차원의 값으로 변화시킬 수 있도록 하여, 각종 예기치 못한 환경 변화에도 유연하게 대응할 수 있도록 학습시킬 수 있다."}
{"patent_id": "10-2021-0027610", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명과 본 발명의 동작상의 이점 및 본 발명의 실시에 의하여 달성되는 목적을 충분히 이해하기 위해서는 본 발명의 바람직한 실시예를 예시하는 첨부 도면 및 첨부 도면에 기재된 내용을 참조하여야만 한다. 이하, 첨부한 도면을 참조하여 본 발명의 바람직한 실시예를 설명함으로써, 본 발명을 상세히 설명한다. 그러 나, 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 설명하는 실시예에 한정되는 것이 아니다. 그리고, 본 발명을 명확하게 설명하기 위하여 설명과 관계없는 부분은 생략되며, 도면의 동일한 참조부호는 동일한 부재 임을 나타낸다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기 재된 \"...부\", \"...기\", \"모듈\", \"블록\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 도 2는 본 발명의 일 실시예에 따른 인공지능 학습 장치로 구현될 수 있는 컴퓨팅 장치의 예를 나타낸다. 도 2를 참조하면, 본 발명의 일 실시 예에 따른 컴퓨팅 장치는 프로세서 메모리 및 통신부를 포 함할 수 있다. 프로세서는 MPU(micro processing unit), CPU(central processing unit)등으로 구현되어 인공지능 학습 장치로서 동작할 수 있다. 메모리는 프로세서에서 동작을 수행하기 위한 각종 데이터를 저장하여, 프로세서로 저장된 데이터를 전달하거나, 프로세서에서 인가되는 데이터를 저장한다. 여기서는 예시 로서 메모리를 프로세서와 별도의 구성 요소로 표시하였으나, 메모리는 프로세서에 포함되 어 구성될 수도 있다. 일 예로 메모리는 프로세서 내에 포함되는 캐시 메모리로 구현될 수도 있다. 통신부는 외부의 장치 또는 프로세서 외부에 구현되는 모듈 등과 통신을 수행하여 외부로 데이터를 전송하거나 외부의 데이터를 인가받아 프로세서로 전달할 수 있다. 도 3은 본 발명의 일 실시예에 따른 인공지능 학습 장치의 개략적 구조를 나타낸다. 도 3을 참조하면, 본 실시예에 따른 인공지능 학습 장치는 도 1과 마찬가지로 에이전트 모듈과 환경 모듈 을 포함한다. 다만 본 실시예에 따른 인공지능 학습 장치는 환경 변경 모듈을 더 포함한다. 여기서 에이전트 모듈과 환경 모듈 및 환경 변경 모듈은 도 2의 프로세서 내의 하드웨어로 구현되거나, 프로세서에서 실행되는 소프트웨어 모듈로 구현될 수 있다. 에이전트 모듈은 강화 학습 대상으로서, 환경 모듈로부터 현재 상태(S(t))와 이전 액션(A(t-1))에 대 한 보상(R(t))이 주어지면, 현재 상태(S(t))에서 보상(R(t))이 더 증가되도록 액션(A(t))을 결정하여 환경 모듈 로 출력한다. 에이전트 모듈은 메모리에 저장된 액터 데이터를 인가받고, 인가된 액터 데이터 를 기반으로 현재 상태(S(t))와 보상(R(t))에 대응하는 액션(A(t))을 결정할 수 있다. 여기서 결정된 액션 (A(t))은 메모리에 저장된다. 또한 에이전트 모듈은 현재 상태(S(t))와 보상(R(t))에 대한 데이터 또한 환경 모듈로부터 직접 인가받는 것이 아니라, 환경 모듈이 메모리에 저장한 상태(S(t))와 보상(R(t))을 읽어와서 액션(A(t))을 결정할 수 있다. 그리고 환경 모듈은 에이전트 모듈이 메모리에 저장한 액션(A(t))을 읽어 확인하고, 확인된 액 션(A(t))에 따라 상태(S(t))를 다음 상태(S(t+1))로 업데이트하여 메모리에 저장한다. 또한 업데이트된 상태(S(t+1))에 따른 보상(R(t+1))을 판단하여 메모리에 저장한다. 이때, 환경 모듈은 액션(A(t))에 대한 보상을 즉시 반영하지 않고, 지연하여 반영할 수도 있다. 환경 변경 모듈은 항시 구동될 수도 있으나, 사용자의 요청에 응답하여 구동되는 것이 바람직하다. 환경 변경 모듈은 에이전트 모듈과 환경 모듈로부터 액터(actor), 환경, 상태(S(t)), 보상(R(t)) 등 의 다양한 데이터를 획득할 수 있다. 이때, 환경 변경 모듈은 에이전트 모듈과 환경 모듈로부 터 직접 데이터를 획득할 수도 있으나, 메모리에 저장한 데이터를 획득할 수도 있다. 그리고 환경 변경 모듈은 획득된 데이터를 기지정된 방식으로 출력하여 사용자에게 표시한다. 환경 변경 모듈은 도 2의 통신부를 통해 디스플레이 장치(미도시)로 획득한 데이터가 출력되도록 하거나 다른 컴퓨팅 장치로 획득한 데이터를 전송하여 출력할 수도 있다. 그리고 사용자로부터 변경 데이터가 인가되면, 환경 변경 모듈은 인가된 변경 데이터를 에이전트 모듈 과 환경 모듈로 인가하여, 액터, 환경, 상태(S(t)), 보상(R(t))등을 변경시킨다. 이때에도 환경 변 경 모듈은 에이전트 모듈과 환경 모듈로 변경 데이터를 직접 전달하여 변경시킬 수도 있으나, 인가된 변경 데이터를 메모리에 저장하고, 변경 데이터가 저장된 메모리 주소를 에이전트 모듈과 환 경 모듈로 전달함으로써, 에이전트 모듈과 환경 모듈이 인가된 메모리 주소에 따라 변경 데이터 를 획득하도록 할 수도 있다. 도 4는 도 3의 인공지능 학습 장치에서 환경 변경 모듈의 상세 구성의 일 예를 나타내고, 도 5는 환경 변경 인 터페이스의 일 예를 나타내며, 도 6 및 도 7은 도 3의 데이터 설정부가 차원이 변경되어 인가된 데이터를 처리 하는 방식을 설명하기 위한 도면이다. 도 4를 참조하면, 환경 변경 모듈은 데이터 획득부, 인터페이스 제공부, 데이터 설정부 및 데이터 변경부를 포함할 수 있다. 데이터 획득부는 에이전트 모듈과 환경 모듈로부터 각종 데이터를 인가받아 인터페이스 제공부 로 전달한다. 데이터 획득부는 환경 변경 모듈이 구동되거나, 통신부를 통해 사용자 명령 으로 데이터 요청이 인가되면, 액터, 환경, 상태(S(t)), 보상(R(t)) 등의 다양한 데이터를 획득하여 인터페이스 제공부로 전달할 수 있다. 이때 데이터 획득부는 에이전트 모듈과 환경 모듈로부터 직접 데이터를 인가받을 수도 있으나, 에이전트 모듈과 환경 모듈에 의해 메모리에 저장된 데이터를 인가받을 수도 있다. 그리고 데이터 획득부는 통신부를 통해 사용자가 설정한 변경 데이터를 인가받아 데이터 설정부(43 0)로 전달한다. 또는 데이터 획득부는 인가된 변경 데이터를 메모리에 전달하여 저장할 수 있다. 인터페이스 제공부는 데이터 획득부에서 획득한 각종 데이터를 인가받아 기지정된 형식으로 데이터 변경 화면을 구성하여 통신부로 전달할 수 있다. 인터페이스 제공부는 사용자가 데이터를 용이하게 인식할 수 있는 다양한 형태로 데이터 변경 화면을 구성할 수 있다. 여기서 데이터 변경 화면은 현재 데이터를 사용자에게 표시할 뿐만 아니라 사용자가 변경 데이터를 입력할 수 있도록 일 예로 도 5와 같은 화면을 구성될 수 있다. 또한 외부의 장치가 직접 변경 화면을 구성할 수 있는 경우, 인터페이스 제공부는 생략될 수도 있다. 데이터 설정부는 데이터 획득부로부터 변경 데이터를 인가받아, 에이전트 모듈과 환경 모듈 이 처리할 수 있는 형식으로 변환 설정한다. 여기서는 일 예로 액터, 환경, 상태(S(t)), 보상(R(t))에 대 한 데이터를 변경할 수 있는 데이터인 것으로 가정하였으므로, 데이터 설정부는 일 예로 액터 설정부 , 상태 설정부, 환경 설정부, 및 보상 설정부를 포함할 수 있다. 그러나 변경할 수 있는 변경 데이터의 종류에 따라 데이터 설정부의 구성은 다양하게 조절될 수 있다. 그리고 액터 설정부, 상태 설정부, 환경 설정부, 및 보상 설정부 각각은 인가된 변경 데이터에서 대응하는 변경 데이 터를 인가받아 기지정된 형식으로 변환한다. 특히 각 종류별 변경 데이터의 차원을 기지정된 차원이 되도록 변 환할 수 있다. 예로서 액터 설정부는 기존에 액터 데이터가 거미 로봇의 8개의 다리 각각에 대한 8차원으 로 구성되는 반면, 액터 변경 데이터가 7개의 다리를 갖는 거미 로봇에 대응하여 7차원으로 구성되는 경우, 7차 원의 액터 변경 데이터를 8차원으로 변환하여 출력할 수 있다. 도 6의 (a)와 (b)는 각각 상태 데이터(S)와 액션 데이터(A)의 차원을 변환하는 방법의 일 예를 나타낸다. 도 6 에 도시된 바와 같이, 데이터 설정부에는 각 종류별 데이터에서 설정될 수 있는 최대 차원 크기(여기서는 일 예로 5)가 미리 지정되며, 변경 데이터가 인가되면, 인가된 변경 데이터의 종류에 따라 지정된 최대 차원 크 기로 변경 데이터의 차원을 변환한다. 이때, 최대 차원 크기보다 작은 크기의 변경 데이터는 부족한 차원을 0 으로 채울 수 있다. 즉 제로 패딩 기법을 적용하여 변경 데이터의 차원을 통일시킬 수 있다. 다만 각 데이터의 종류에 따라 최대 차원 크기는 서로 상이할 수 있다. 비록 도 6에서는 상태 데이터(S)와 액 션 데이터(A)가 모두 5차원인 경우를 가정하였으나, 상태 데이터(S)는 3차원인 반면, 액션 데이터(A)는 7차원으 로 설정될 수도 있다. 이에 각 데이터 종류에 따라 서로 다르게 설정되는 차원으로 변경 데이터를 변환할 수 있도록 도 4에서는 데이터 설정부가 액터 설정부, 상태 설정부, 환경 설정부, 및 보상 설 정부를 포함하는 것으로 도시하였다. 한편, 데이터 설정부는 인가된 변경 데이터의 차원을 직접 변경하지 않고 메모리 주소를 이용하는 간접 접 근 방식을 이용할 수도 있다. 도 6에 도시된 바와 같이, 변경 데이터의 차원을 변환하는 것은 에이전트 모듈 과 환경 모듈이 변화하는 가변 차원의 입력을 인가받지 못하도록 구성되기 때문이다. 그러나 에이전 트 모듈과 환경 모듈이 데이터를 직접 인가받지 않고, 메모리에 저장된 데이터를 인가받도록 구 성된다면, 에이전트 모듈과 환경 모듈은 항시 동일한 형식의 메모리 주소를 획득하여 다양한 차원의 변경 데이터를 획득할 수 있다. 도 7에서도 도 6에서와 마찬가지로 상태 데이터(S)와 액션 데이터(A)가 다양한 차원의 변경 데이터로 인가되는 경우를 도시하였다. 그러나 도 7에서는 에이전트 모듈과 환경 모듈이 변경 데이터를 직접 인가받지 않고, 변경 데이터의 메모리 주소를 인가받는 방식으로 구현됨에 따라 에이전트 모듈과 환경 모듈에 는 변경 데이터의 차원에 무관하게 항시 동일 형식의 메모리 주소가 인가될 수 있다. 그리고 에이전트 모듈 과 환경 모듈은 인가된 메모리 주소를 기반으로 다양한 차원의 변경 데이터를 읽어올 수 있다. 여기 서는 이와 같이 메모리 주소를 활용하는 방식을 간접 접근 방식이라 한다. 간접 접근 방식에서 일 예로 액터 설정부는 데이터 획득부가 메모리에 저장한 메모리 주소를 확 인하고, 확인된 메모리 주소를 데이터 변경부로 전달할 수 있다. 한편, 데이터 변경부는 데이터 설정부에서 변환된 변경 데이터를 에이전트 모듈과 환경 모듈 로 직접 전달할 수 있다. 또는 데이터 설정부에서 확인된 메모리 주소를 에이전트 모듈과 환경 모듈로 전달할 수 있다. 환경 변경 모듈은 이전까지 수행한 강화 학습에 의해 획득된 데이터 전체를 사용자가 설정한 변경 데이터 에 따라 대체할 수도 있다. 다만 이 경우, 이전까지 강화 학습을 수행한 학습 결과가 모두 소실된다. 그러나 사용자는 일부 종류의 데이터만을 지정하여 변경 데이터로 변경할 수도 있다. 이 경우에는 변경 데이터로 변경 된 데이터 이외에는 이전까지 수행된 강화 학습에 의해 업데이트된 데이터가 그대로 유지될 수 있다. 따라서 결과적으로 이전 강화 학습이 수행된 학습 내용을 그대로 보존하면서 추가적으로 변경된 데이터에 대한 학습이 더 수행될 수 있게 된다. 또한 데이터를 변경 데이터로 대체하는 시점이 지정될 필요가 없다. 즉 수행되던 강 화 학습이 완전히 종료되지 않은 상태에서도 언제든지 데이터를 변경 데이터로 대체할 수 있어, 에이전트를 다 양한 조건 환경에서 강화 학습시킬 수 있다. 도 8은 본 발명의 일 실시예에 따른 인공지능 학습 방법을 나타낸다. 도 2 내지 도 7을 참조하여, 도 8의 인공지능 학습 방법을 설명하면, 우선 에이전트 모듈과 환경 모듈 을 강화 학습시키기 위한 초기 데이터를 설정한다(S10). 그리고 설정된 데이터에 따라 에이전트 모듈과 환경 모듈에 대해 기지정된 방식으로 강화 학습을 수행한다(S20). 이후 환경 변경 모듈이 구동되 는지 판별한다(S30). 또는 환경 변경 모듈이 구동된 상태에서 데이터 요청이 인가되는지 판별할 수도 있다. 환경 변경 모듈이 구동되거나, 데이터 요청이 인가되면, 현재까지 강화 학습에 의해 업데이트된 데이터를 획득 하여 출력한다(S40). 여기서 데이터는 에이전트 모듈과 환경 모듈로부터 직접 획득하거나, 에이전트 모듈과 환경 모듈이 메모리에 저장한 데이터를 읽어서 획득할 수 있다. 또한 출력되는 데이터는 통 신부를 통해 사용자에게 기지정된 형식의 화면으로 표출될 수 있다. 그리고 사용자가 설정한 변경 데이터가 입력되는지 판별한다(S50). 만일 변경 데이터가 입력되면, 입력된 변경 데이터의 차원이 기지정된 차원인지 판별한다(S60). 여기서 기지정된 차원은 각 데이터의 종류에 따라 설정될 수 있는 최대 차원일 수 있다. 만일 변경 데이터의 차원이 기지정된 차원이 아니면, 인가된 변경 데이터의 차 원이 기지정된 차원이 되도록 변환한다(S70). 이때 차원 변환은 일 예로제로 패딩 기법으로 수행할 수 있다. 그리고 차원 변환된 변경 데이터를 에이전트 모듈과 환경 모듈로 인가하여 적용할 수 있다(S80). 그러나 에이전트 모듈과 환경 모듈이 메모리에 저장된 데이터를 참조하여 구동하도록 구성된 경 우, 변경 데이터가 입력되면(S50), 변경 데이터를 메모리에 저장하고, 변경 데이터가 저장된 메모리 주소 를 확인한다. 그리고 확인된 메모리 주소를 에이전트 모듈과 환경 모듈로 인가하여 적용할 수도 있 다(S80). 본 발명에 따른 방법은 컴퓨터에서 실행시키기 위한 매체에 저장된 컴퓨터 프로그램으로 구현될 수 있다. 여기 서 컴퓨터 판독가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 또한 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분 리형 매체를 모두 포함하며, ROM(판독 전용 메모리), RAM(랜덤 액세스 메모리), CD(컴팩트 디스크)-ROM, DVD(디 지털 비디오 디스크)-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장장치 등을 포함할 수 있다. 본 발명은 도면에 도시된 실시예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0027610", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 강화 학습에 기반한 인공지능 학습 방법의 개념을 설명하기 위한 도면이다. 도 2는 본 발명의 일 실시예에 따른 인공지능 학습 장치로 구현될 수 있는 컴퓨팅 장치의 예를 나타낸다. 도 3은 본 발명의 일 실시예에 따른 인공지능 학습 장치의 개략적 구조를 나타낸다. 도 4는 도 3의 인공지능 학습 장치에서 환경 변경 모듈의 상세 구성의 일 예를 나타낸다. 도 5는 환경 변경 인터페이스의 일 예를 나타낸다. 도 6 및 도 7은 도 3의 데이터 설정부가 차원이 변경되어 인가된 데이터를 처리하는 방식을 설명하기 위한 도면 이다. 도 8은 본 발명의 일 실시예에 따른 인공지능 학습 방법을 나타낸다."}
