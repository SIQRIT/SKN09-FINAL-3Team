{"patent_id": "10-2024-0013427", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0032820", "출원번호": "10-2024-0013427", "발명의 명칭": "이머시브 스크린을 위한 디스플레이 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "강근석"}}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이 장치에 있어서,통신 인터페이스;디스플레이;하나 이상의 명령어(instruction)를 저장하는 메모리; 및 하나 이상의 프로세서;를 포함하고,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 소스 장치로부터 수신된 컨텐츠에 기초하여 영상을 표시하도록 상기 디스플레이를 제어하고,외부 장치와의 통신을 위한 네트워크 상태가 제1 상태이면, 상기 컨텐츠에 대응되는 제1 영상 데이터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하도록 제어하고, 상기 네트워크 상태가 제2 상태이면, 상기 제1 영상 데이터의 특징 정보 및 상기 제1 영상 데이터에 기초하여변환된 제2 영상 데이터 중 적어도 하나를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하도록제어하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 네트워크의 가용 대역폭(Bandwidth)이 기 설정된 값 이상이면, 상기 제1 영상 데이터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하도록 제어하고, 상기 네트워크의 상기 가용 대역폭이 상기 기 설정된 값 미만이면, 상기 제1 영상 데이터의 특징 정보 및 상기제2 영상 데이터 중 적어도 하나를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하도록 제어하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 디스플레이 장치에서 획득한 네트워크 상태 정보 및 상기 소스 장치로부터 수신한 네트워크 상태 정보 중적어도 하나에 기초하여 상기 네트워크 상태가 상기 제1 상태 또는 상기 제2 상태인지 식별하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 제1 영상 데이터에 포함된 각 씬(scene)에 대응되는 특징 정보를 획득하여 상기 통신 인터페이스를 통해상기 외부 장치로 전송하도록 제어하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2025-0032820-3-상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 네트워크 상태가 제1 상태이면, 상기 디스플레이의 외부 영역에 상기 제1 영상 데이터에 기초한 제1 그래픽 이미지 출력에 대응한 정보를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하도록 제어하고,상기 네트워크 상태가 제2 상태이면, 상기 디스플레이의 외부 영역에 상기 제1 영상 데이터의 특징 정보 및 상기 제2 영상 데이터 중 적어도 하나에 기초한 제2 그래픽 이미지 출력에 대응한 정보를 상기 통신 인터페이스를통해 상기 외부 장치로 전송하도록 제어하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제1 그래픽 이미지 및 상기 제2 그래픽 이미지는, 상기 디스플레이에 표시된 영상에 대한 이머시브(immersive) 스크린 효과를 제공하기 위한 그래픽 이미지인, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 네트워크 상태가 상기 제1 상태이면, 상기 컨텐츠에 포함된 제1 오디오 데이터를 상기 통신 인터페이스를통해 상기 외부 장치로 전송하도록 제어하고,상기 네트워크 상태가 제2 상태이면, 상기 제1 오디오 데이터의 특징 정보 및 상기 제1 오디오 데이터에 기초하여 변환된 제2 오디오 데이터 중 적어도 하나를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하도록 제어하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 외부 장치가 상기 제1 영상 데이터에 기초하여 획득한 제1 특징 정보로부터 인공 지능 모델을 통해 제1 그래픽 이미지를 획득하여 출력하도록 상기 통신 인터페이스를 통해 상기 외부 장치로 상기 제1 영상 데이터를 전송하도록 제어하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 외부 장치가 상기 제1 영상 데이터의 제2 특징 정보 및 상기 제2 영상 데이터 중 적어도 하나로부터 상기인공 지능 모델을 통해 제2 그래픽 이미지를 획득하여 출력하도록 상기 통신 인터페이스를 통해 상기 외부 장치로 상기 제1 영상 데이터의 제2 특징 정보 및 상기 제1 영상 데이터에 기초하여 변환된 제2 영상 데이터 중 적어도 하나를 전송하도록 제어하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써,상기 제1 영상 데이터, 제1 영상 데이터의 특징 정보 및 제2 영상 데이터 중 적어도 하나와 상기 외부 장치의출력 상태에 기초하여 상기 인공 지능 모델로부터 상기 외부 장치의 출력 상태에 대응되는 그래픽 이미지를 획득하여 출력하도록 상기 제1 영상 데이터, 상기 제1 영상 데이터의 특징 정보 및 상기 제2 영상 데이터 중 적어도 하나를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하도록 제어하고,공개특허 10-2025-0032820-4-상기 외부 장치의 출력 상태는, 시청 상태, 이머시브 앰비언트 상태 및 3D 상태 중 적어도 하나를 포함하는, 디스플레이 장치."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "디스플레이 장치의 제어 방법에 있어서,소스 장치로부터 수신된 컨텐츠에 기초하여 영상을 표시하는 단계;외부 장치와의 통신을 위한 네트워크 상태가 제1 상태이면, 상기 컨텐츠에 대응되는 제1 영상 데이터를 상기 외부 장치로 전송하는 단계; 및 상기 네트워크 상태가 제2 상태이면, 상기 제1 영상 데이터의 특징 정보 및 상기 제1 영상 데이터에 기초하여변환된 제2 영상 데이터 중 적어도 하나를 상기 외부 장치로 전송하는 단계;를 포함하는 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 네트워크의 가용 대역폭(Bandwidth)이 기 설정된 값 이상이면, 상기 제1 영상 데이터를 상기 외부 장치로전송하는 단계; 및 상기 네트워크의 상기 가용 대역폭이 상기 기 설정된 값 미만이면, 상기 제1 영상 데이터의 특징 정보 및 상기제2 영상 데이터 중 적어도 하나를 상기 외부 장치로 전송하는 단계;를 포함하는 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 디스플레이 장치에서 획득한 네트워크 상태 정보 및 상기 소스 장치로부터 수신한 네트워크 상태 정보 중적어도 하나에 기초하여 상기 네트워크 상태가 상기 제1 상태 또는 상기 제2 상태인지 식별하는 단계;를 포함하는 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 제1 영상 데이터에 포함된 각 씬(scene)에 대응되는 특징 정보를 획득하여 상기 외부 장치로 전송하는 단계;를 더 포함하는 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 네트워크 상태가 제1 상태이면, 상기 디스플레이 장치의 외부 영역에 상기 제1 영상 데이터에 기초한 제1그래픽 이미지를 출력에 대응한 정보를 상기 외부 장치로 전송하거나, 상기 네트워크 상태가 제2 상태이면, 상기 디스플레이 장치의 외부 영역에 상기 제1 영상 데이터의 특징 정보및 상기 제2 영상 데이터 중 적어도 하나에 기초한 제2 그래픽 이미지 출력에 대응한 정보를 상기 외부 장치로전송하는 단계;를 더 포함하는 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 제1 그래픽 이미지 및 상기 제2 그래픽 이미지는, 상기 디스플레이 장치에 표시된 영상에 대한 이머시브(immersive) 스크린 효과를 제공하기 위한 그래픽 이미지인, 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2025-0032820-5-제11항에 있어서,상기 네트워크 상태가 상기 제1 상태이면, 상기 컨텐츠에 포함된 제1 오디오 데이터를 상기 외부 장치로 전송하는 단계; 및상기 네트워크 상태가 제2 상태이면, 상기 제1 오디오 데이터의 특징 정보 및 상기 제1 오디오 데이터에 기초하여 변환된 제2 오디오 데이터 중 적어도 하나를 상기 외부 장치로 전송하는 단계; 를 포함하는 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 11항에 있어서, 상기 외부 장치가 상기 제1 영상 데이터에 기초하여 획득한 제1 특징 정보로부터 인공 지능 모델을 통해 제1 그래픽 이미지를 획득하여 출력하도록 상기 외부 장치로 상기 제1 영상 데이터를 전송하는 단계; 를 포함하는 디스플레이 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18항에 있어서,상기 제1 영상 데이터, 상기 제1 영상 데이터의 특징 정보 및 상기 제2 영상 데이터 중 적어도 하나와 및 상기외부 장치의 출력 상태에 기초하여 상기 인공 지능 모델로부터 상기 외부 장치의 출력 상태에 대응되는 그래픽이미지를 획득하여 출력하도록 상기 제1 영상 데이터, 상기 제1 영상 데이터의 특징 정보 및 제2 영상 데이터중 적어도 하나를 상기 외부 장치로 전송하는 단계;를 포함하고,상기 외부 장치의 출력 상태는, 시청 상태, 이머시브 앰비언트 상태 및 3D 상태 중 적어도 하나를 포함하는, 영상 출력 장치의 제어 방법."}
{"patent_id": "10-2024-0013427", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "디스플레이 장치의 프로세서에 의해 실행되는 경우 상기 디스플레이 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는 비일시적 컴퓨터 판독가능 기록매체에 있어서, 상기 동작은,소스 장치로부터 수신된 컨텐츠에 기초하여 영상을 표시하는 단계;외부 장치와의 통신을 위한 네트워크 상태가 제1 상태이면, 상기 컨텐츠에 대응되는 제1 영상 데이터를 상기 외부 장치로 전송하는 단계; 및 상기 네트워크 상태가 제2 상태이면, 상기 제1 영상 데이터의 특징 정보 및 상기 제1 영상 데이터에 기초하여변환된 제2 영상 데이터 중 적어도 하나를 상기 외부 장치로 전송하는 단계;를 포함하는 비일시적 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2024-0013427", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디스플레이 장치가 개시된다. 디스플레이 장치는, 통신 인터페이스, 디스플레이, 하나 이상의 명령어를 저장하는 메모리 및 하나 이상의 프로세서를 포함하고, 하나 이상의 프로세서는 하나 이상의 명령어를 실행함으로써, 소스 장치로부터 수신된 컨텐츠에 기초하여 영상을 표시하도록 디스플레이를 제어하고, 외부 장치와의 통신을 위한 네 트워크 상태가 제1 상태이면, 컨텐츠에 대응되는 제1 영상 데이터를 통신 인터페이스를 통해 외부 장치로 전송하 고, 네트워크 상태가 제2 상태이면, 제1 영상 데이터의 특징 정보 및 제1 영상 데이터에 기초하여 변환된 제2 영 상 데이터 중 적어도 하나를 통신 인터페이스를 통해 외부 장치로 전송할 수 있다."}
{"patent_id": "10-2024-0013427", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디스플레이 장치 및 그 제어 방법에 관한 것으로, 보다 상세하게는 영상 출력 장치와 연결되어 이머 시브 스크린(Immersive screen)을 구현할 수 있는 디스플레이 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2024-0013427", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 디스플레이 장치를 조명 장치 또는 프로젝터와 연결하여 디스플레이 장치에 표시되고 있는 영상에 대응되 는 조명 효과나 이미지를 디스플레이 장치의 주변부에 출력시켜 사용자가 영상에 더 몰입할 수 있도록 하는 기 술이 늘어나고 있다. 다만, 프로젝터가 실시간으로 스트리밍되는 영상 컨텐츠에 대응되는 그래픽 효과를 디스플레이 장치의 외부 영 역에 발생시키기 위해서는 용량이 큰 영상신호를 수신하여 이를 실시간으로 분석하고 그에 대응되는 그래픽 효 과를 식별하는 과정이 필요하다. 따라서, 네트워크 상태가 양호하지 않은 경우(예를 들어, 가용 대역폭이 제한 되는 경우)에는 원본 영상신호를 실시간으로 수신하여 이를 분석하는 것이 매우 어려워질 수 있었다.따라서, 네트워크 상태를 실시간으로 모니터링하여 영상신호를 분석하는 주체가 되는 디바이스를 필요에 따라 변경할 수 있는 기술에 대한 필요성이 대두되어 왔다."}
{"patent_id": "10-2024-0013427", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 적어도 하나의 실시 예에 따른 디스플레이 장치는, 통신 인터페이스, 디스플레이, 메모리 및 하나 이 상의 프로세서를 포함하고, 상기 하나 이상의 프로세서는, 상기 하나 이상의 명령어를 실행함으로써, 소스 장치 로부터 수신된 컨텐츠에 기초하여 영상을 표시하도록 상기 디스플레이를 제어하고, 외부 장치와의 통신을 위한 네트워크 상태가 제1 상태이면, 상기 컨텐츠에 대응되는 제1 영상 데이터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하고, 상기 네트워크 상태가 제2 상태이면, 상기 제1 영상 데이터의 특징 정보 및 상기 제1 영 상 데이터에 기초하여 변환된 제2 영상 데이터 중 적어도 하나를 상기 통신 인터페이스를 통해 상기 외부 장치 로 전송할 수 있다.. 본 개시의 적어도 하나의 실시 예에 따른 디스플레이 장치의 제어 방법은, 소스 장치로부터 수신된 컨텐츠에 기 초하여 영상을 표시하는 단계, 외부 장치와의 통신을 위한 네트워크 상태가 제1 상태이면, 상기 컨텐츠에 대응 되는 제1 영상 데이터를 상기 외부 장치로 전송하는 단계 및 상기 네트워크 상태가 제2 상태이면, 상기 제1 영 상 데이터의 특징 정보 및 상기 제1 영상 데이터에 기초하여 변환된 제2 영상 데이터 중 적어도 하나를 상기 외 부 장치로 전송하는 단계를 포함할 수 있다. 본 개시의 적어도 하나의 일 실시 예에 따른 디스플레이 장치의 제어 방법을 실행하는 프로그램을 포함하는 컴 퓨터 판독 가능 기록매체에 있어서, 상기 디스플레이 장치의 제어 방법은, 소스 장치로부터 수신된 컨텐츠에 기 초하여 영상을 표시하는 단계, 외부 장치와의 통신을 위한 네트워크 상태가 제1 상태이면, 상기 컨텐츠에 대응 되는 제1 영상 데이터를 상기 외부 장치로 전송하는 단계 및 상기 네트워크 상태가 제2 상태이면, 상기 제1 영 상 데이터의 특징 정보 및 상기 제1 영상 데이터에 기초하여 변환된 제2 영상 데이터 중 적어도 하나를 상기 외 부 장치로 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0013427", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도면에 예 시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하려는 것 이 아니며, 본 개시의 실시 예의 다양한 변경(modifications), 균등물(equivalents), 및/또는 대체물 (alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유 사한 참조 부호가 사용될 수 있다. 본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위하여 제공되는 것이다. 본 개시에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 권리범위를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직 접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트 웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 실시 예에 있어서 '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 혹은 복수의 '부'는 특정 한 하드웨어로 구현될 필요가 있는 '모듈' 혹은 '부'를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하 나의 프로세서로 구현될 수 있다. 한편, 도면에서의 다양한 요소와 영역은 개략적으로 그려진 것이다. 따라서, 본 발명의 기술적 사상은 첨부한 도면에 그려진 상대적인 크기나 간격에 의해 제한되지 않는다. 이하에서는 첨부한 도면을 참고하여 본 개시에 따른 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 도 1은 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치 및 영상 출력 장치의 동작을 설명하기 위한 도 면이다. 도 1에 따르면, 디스플레이 장치는 영상 출력 장치와 연결될 수 있으며, 영상 출력 장치는 디스 플레이 장치의 외부 영역에 그래픽 이미지를 출력할 수 있다.디스플레이 장치는 외부 소스 장치로부터 수신된 컨텐츠에 기초하여 영상을 표시하는 장치일 수 있다. 도 1에서 디스플레이 장치가 TV로 도시 되었지만, 이는 하나의 예시에 불과하고 태블릿 PC, 비디오 월(video wall), LFD(large format display), Digital Signage(디지털 간판), DID(Digital Information Display) 등 영 상 디스플레이 기능을 갖춘 장치로 구현될 수 있다. 여기서, 외부 소스 장치는 디스플레이 장치에 대해 컨텐츠를 송신할 수 있고, 외부 소스 장치는 PC, 랩탑 PC, 스마트폰, 태블릿 PC, 셋탑박스, 미디어 플레이어, 게임기 등 다양한 장치로 구현될 수 있다. 영상 출력 장치는 디스플레이 장치가 수신한 컨텐츠에 대응되는 그래픽 이미지를 디스플레이 장치 의 외부 영역에 출력할 수 있다. 도 1에서 영상 출력 장치는 그래픽 이미지를 투사하는 프로젝터(또 는, 프로젝터 디스플레이)로 도시 되었지만, 이에 한정되는 것은 아니며, TV, 비디오 월(video wall), LFD(large format display), Digital Signage(디지털 간판), DID(Digital Information Display) 등과 같이 영 상을 출력할 수 있는 기능을 갖춘 장치로 구현될 수 있다. 또한, 도 1에서는 영상 출력 장치가 소형 프로젝터로 도시되었지만, 이는 하나의 예시에 불과하며 영상 출 력 장치은 고정식, 거치식 또는 이동식 프로젝터로 구현될 수도 있다. 여기서, 이동식 프로젝터란 이동형 부재를 가지고 있는 프로젝터로 사용자가 원하는 위치로 프로젝터를 자유롭게 이동시킬 수 있는 프로젝터를 의 미한다. 또한, 영상 출력 장치는 도 1에 도시된 바와 같이 디스플레이 장치로부터 원거리에 위치할 수 있으나, 이는 하나의 예시에 불과하며, 디스플레이 장치의 뒷면에 일체형으로 부착되거나, 디스플레이 장 치로부터 근거리에 위치하는 테이블 또는 벽면에 위치하거나, 디스플레이 장치의 액세서리(예를 들어, 스피커 등)에 위치할 수도 있다. 본 개시의 일 실시 예에 따라, 디스플레이 장치 및 영상 출력 장치는 사용자에게 이머시브 스크린 (Immersive screen)을 제공할 수 있다. 여기서, 이머시브 스크린이란 사용자가 컨텐츠에 더 깊이 몰입할 수 있 도록 디스플레이되는 이미지를 의미할 수 있다. 예를 들어, 이머시브 스크린은 디스플레이 장치에 출력되 는 이미지 및 영상 출력 장치에 의해 디스플레이 장치의 외부 영역에 출력되는 그래픽 이미지가 결합 된 이미지를 포함할 수 있다. 이머시브 스크린은 'Multi-Screen', 'Expanded Screen', 'Comprehensive Screen', 'Integrated Screen' 이라는 용어로 대체될 수도 있지만, 본 설명에서는 이머시브 스크린으로 통칭하 도록 한다. 도 1에 도시된 바와 같이, 영상 출력 장치는 디스플레이 장치로부터 영상 신호를 수신하여 영상 신호 에 대응되는 그래픽 이미지를 출력할 수 있다. 이때, 디스플레이 장치는 네트워크 상태를 식별하여 영상 출력 장치에 대해 영상 신호 및 오디오 신호를 그대로 송신할 것인지, 다운스케일링한 영상 신호 및 오디 오 신호를 송신할 것인지 또는 영상 신호 및 오디오 신호의 특징 정보만을 송신할 것인지 여부를 결정할 수 있 다. 본 개시에 따른 디스플레이 장치는 네트워크 상태를 식별하여 영상 출력 장치로 식별된 네트워크 상태에 대응되는 신호를 송신하기 때문에 네트워크 상태가 양호하지 않은 경우(예를 들어, 네트워크의 가용 대 역폭이 제한되는 경우)에도 영상 출력 장치가 그래픽 이미지를 출력하기 위해 필수적인 정보만을 수신하여 컨텐츠에 대응되는 그래픽 이미지를 실시간으로 출력할 수 있다. 이하에서는, 본 개시의 다양한 실시 예에 따른 디스플레이 장치의 동작에 대해 설명하도록 한다. 도 2는 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치의 구성을 설명하기 위한 블록도이다. 도 2에 따르면, 디스플레이 장치는 메모리, 통신 인터페이스, 디스플레이 및 프로세서 를 포함할 수 있다. 메모리는 디스플레이 장치에서 사용되는 각종 프로그램이나 데이터, 명령어 등을 저장할 수 있다. 그 밖에, 메모리는 본 개시의 다양한 실시 예에 따라 다양한 정보들을 저장할 수 있다. 본 개시의 일 예에 따른 메모리는 하나 이상의 프로세서에 포함된 롬(ROM)(예를 들어, EEPROM(electrically erasable programmable read-only memory)), 램(RAM) 등의 내부 메모리로 구현되거나, 하 나 이상의 프로세서와 별도의 메모리로 구현될 수도 있다. 이 경우, 메모리는 데이터 저장 용도에 따 라 디스플레이 장치에 임베디드된 메모리 형태로 구현되거나, 디스플레이 장치에 탈부착이 가능한 메 모리 형태로 구현될 수도 있다. 예를 들어, 디스플레이 장치의 구동을 위한 데이터의 경우 디스플레이 장 치에 임베디드된 메모리에 저장되고, 디스플레이 장치의 확장 기능을 위한 데이터의 경우 디스플레이장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 디스플레이 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 디스플레 이 장치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결 가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 통신 인터페이스는 디스플레이 장치가 외부 소스 장치 또는 영상 출력 장치 등의 외부 장치들과 통신하기 위한 구성이다. 통신 인터페이스는 적어도 하나의 무선 통신 모듈, 적어도 하나의 유선 통신 모듈 등을 포함할 수 있다. 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태로 구현될 수 있다. 무선 통신 모듈은 Wi-Fi 모듈, 블루투스 모 듈, 적외선 통신 모듈 또는 기타 통신 모듈 중 적어도 하나의 모듈을 포함할 수 있다. 이 밖에, 통신 인터페이 스는 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격 에 따라 통신을 수행하는 적어도 하나의 통신 칩을 포함할 수 있다. 유선 통신 모듈은 예를 들어, LAN(Local Area Network) 모듈, 이더넷 모듈, 페어 케이블, 동축 케이블, 광섬유 케이블 또는 UWB(Ultra Wide-Band) 모듈 중 적어도 하나를 포함할 수 있다. 통신 인터페이스는 이와 같이 다양한 형태로 구현될 수 있으며, 외부 장치들 과 통신을 수행함으로써, 다양한 신호를 송수신할 수 있다. 디스플레이는 다양한 컨텐츠를 표시하기 위한 구성을 의미한다. 디스플레이는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함하는 디스플레 이로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플 레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형태의 디스플레이 로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한 편, 디스플레이은 터치 센서와 결합된 터치 스크린, 플렉시블 디스플레이(flexible display), 롤러블 디스 플레이(rollable display), 3차원 디스플레이(3D display), 복수의 디스플레이 모듈이 물리적으로 연결된 디스 플레이 등으로 구현될 수 있다. 하나 이상의 프로세서는 전자 장치의 동작을 전반적으로 제어한다. 구체적으로, 하나 이상의 프로세 서는 전자 장치의 각 구성과 연결되어 전자 장치의 동작을 전반적으로 제어할 수 있다. 예를 들 어, 하나 이상의 프로세서는 메모리, 통신 인터페이스 및 디스플레이와 동작적으로 (operatively) 연결될 수 있다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 하나 이상의 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션(instruction)을 실행함으로써, 다양한 실시 예에 따른 전자 장치의 동작을 수행할 수 있다. 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), NPU (Neural Processing Unit), 하드웨어 가속기 또는 머신 러닝 가속기 중 하나 이상을 포함할 수 있다. 하나 이상의 프로 세서는 전자 장치의 다른 구성요소 중 하나 또는 임의의 조합을 제어할 수 있으며, 통신에 관한 동작 또는 데이터 처리를 수행할 수 있다. 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 프로그램 또는 명령 어(instruction)을 실행할 수 있다. 예를 들어, 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 명령어를 실행함으로써, 본 개시의 하나 이상의 실시 예에 따른 방법을 수행할 수 있다. 본 개시의 하나 이상의 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의해 수행될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 하나 이상의 실시 예에 따른 방 법에 의해 제 1 동작, 제 2 동작, 제 3 동작이 수행될 때, 제 1 동작, 제 2 동작, 및 제 3 동작 모두 제 1 프로세서에 의해 수행될 수도 있고, 제 1 동작 및 제 2 동작은 제 1 프로세서(예를 들어, 범용 프로세서)에 의해 수 행되고 제 3 동작은 제 2 프로세서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 하나 이상의 프로세서는 하나의 코어를 포함하는 단일 코어 프로세서(single core processor)로 구현될 수 도 있고, 복수의 코어(예를 들어, 동종 멀티 코어 또는 이종 멀티 코어)를 포함하는 하나 이상의 멀티 코어 프 로세서(multicore processor)로 구현될 수도 있다. 하나 이상의 프로세서가 멀티 코어 프로세서로 구현되 는 경우, 멀티 코어 프로세서에 포함된 복수의 코어 각각은 캐시 메모리, 온 칩(On-chip) 메모리와 같은 프로세 서 내부 메모리를 포함할 수 있으며, 복수의 코어에 의해 공유되는 공통 캐시가 멀티 코어 프로세서에 포함될 수 있다. 또한, 멀티 코어 프로세서에 포함된 복수의 코어 각각(또는 복수의 코어 중 일부)은 독립적으로 본 개 시의 하나 이상의 실시 예에 따른 방법을 구현하기 위한 프로그램 명령을 판독하여 수행할 수도 있고, 복수의 코어 전체(또는 일부)가 연계되어 본 개시의 하나 이상의 실시 예에 따른 방법을 구현하기 위한 프로그램 명령 을 판독하여 수행할 수도 있다. 본 개시의 하나 이상의 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 멀티 코어 프로세 서에 포함된 복수의 코어 중 하나의 코어에 의해 수행될 수도 있고, 복수의 코어에 의해 수행될 수도 있다. 예 를 들어, 하나 이상의 실시 예에 따른 방법에 의해 제 1 동작, 제 2 동작, 및 제 3 동작이 수행될 때, 제 1 동 작, 제2 동작, 및 제3 동작 모두 멀티 코어 프로세서에 포함된 제 1 코어에 의해 수행될 수도 있고, 제 1 동작 및 제 2 동작은 멀티 코어 프로세서에 포함된 제 1 코어에 의해 수행되고 제 3 동작은 멀티 코어 프로세서에 포 함된 제 2 코어에 의해 수행될 수도 있다. 본 개시의 실시 예들에서, 프로세서는 하나 이상의 프로세서 및 기타 전자 부품들이 집적된 시스템 온 칩(SoC), 단일 코어 프로세서, 멀티 코어 프로세서, 또는 단일 코어 프로세서 또는 멀티 코어 프로세서에 포함된 코어를 의미할 수 있으며, 여기서 코어는 CPU, GPU, APU, MIC, DSP, NPU, 하드웨어 가속기 또는 기계 학습 가속기 등으 로 구현될 수 있으나, 본 개시의 실시 예들이 이에 한정되는 것은 아니다. 이하에서는 설명의 편의를 위하여 하 나 이상의 프로세서를 프로세서로 명명하도록 한다. 프로세서는 외부 소스 장치로부터 수신한 컨텐츠에 기초하여 영상을 표시하도록 디스플레이를 제어할 수 있다. 여기서, 외부 소스 장치로부터 수신한 컨텐츠는 영상 신호와 오디오 신호를 포함할 수 있다. 프로세서 는 외부 소스 장치와 통신 인터페이스를 통해 연결될 수 있고, 통신 인터페이스를 통해서 컨텐 츠를 수신할 수 있다. 예를 들어, 프로세서는 블루투스 모듈을 이용해 블루투스 통신 방식으로 외부 소스 장치와 연결될 수 있으 며, 블루투스 통신 채널을 통해 외부 소스 장치로부터 영상 신호 및 오디오 신호를 수신할 수 있다. 블루투스 통신 방식을 통한 연결 방식은 하나의 예시에 불과하며, 프로세서는 상술한 다양한 종류의 통신 인터페이 스를 통해 외부 소스 장치와 연결될 수 있음은 물론이다. 일 예에 따라 외부 소스 장치 및 외부 영상 출력 장치와의 통신 방식은 동일 또는 상이할 수 있으나, 이하에서 는 설명의 편의를 위하여 통신 인터페이스를 통해 외부 소스 장치 및 외부 영상 출력 장치와 통신을 수행 하는 것으로 설명하도록 한다. 일 실시 예에 따르면, 프로세서는 외부 영상 출력 장치(예를 들어, 도 1, 200)와 통신을 수행하는 통신 인 터페이스를 통해 연결된 네트워크 상태가 제1 상태로 식별되면, 수신한 컨텐츠에 대응되는 제1 영상 데이 터를 통신 인터페이스를 통해 영상 출력 장치로 전송할 수 있다. 여기서, \"네트워크 상태\"는 네트워크의 가용 대역폭, 패킷 손실률, 패킷의 Round-trip time(RTT), 패킷의 Delay-Gradient, RSSI 정보, 통신 채널 정보, 링크 스피드 정보, 채널 간섭 정보 또는 재시도 레이트 정보 등에 기초하여 결정될 수 있다. 또한, \"네트워크 상태\"는 \"제1 상태\" 및 \"제2 상태\"를 포함할 수 있다. \"제1 상태\"는 네트워크 상태가 양호하여 프로세서가 영상 출력 장치에 대해 용량이 큰 영상 신호 또는 오디오 신호 를 전송할 수 있는 상태를 의미할 수 있다. 반대로, \"제2 상태\"는 \"제1 상태\"보다 네트워크 상태가 양호하지 않 아 큰 용량의 영상 신호 또는 오디오 신호를 전송하기에 적합하지 않은 상태를 의미할 수 있다. 예를 들어, 프 로세서는 네트워크의 가용 대역폭이 30Mbps 이상인 경우에는 네트워크가 \"제1 상태\"에 있다고 식별할 수 있고 네트워크의 가용 대역폭이 30Mbps 미만인 경우에는 네트워크가 \"제2 상태\"에 있다고 식별할 수 있다. 또한, 프로세서는 패킷의 RTT가 30ms 미만인 경우에는 네트워크가 \"제1 상태\"에 있다고 식별할 수 있고, 패킷의 RTT가 30ms 이상인 경우에는 네트워크가 \"제2 상태\"에 있다고 식별할 수도 있다. 상술한 설명에서 30Mbps, 30ms 라는 임의의 수치를 예시로 하여 설명했지만, 이는 하나의 예시에 불과하며 네트 워크의 요구 사항에 따라 임의의 값을 가질 수 있음은 물론이다. 상술한 설명에서는 네트워크의 가용 대역폭 및 패킷의 RTT에 기초하여 네트워크 상태를 식별하는 방법만을 설명 하였지만, 이는 하나의 예시에 불과하고 패킷의 Delay-Gradient, RSSI 정보, 통신 채널 정보, 링크 스피드 정보, 채널 간섭 정보 또는 재시도 레이트 정보 등 다양한 정보에 기초하여 네트워크의 상태를 식별할 수 있음 은 물론이다. 일 예로, \"제1 영상 데이터\"란 프로세서가 외부 소스 장치로부터 수신한 영상 신호를 의미할 수 있다. 예 를 들어, \"프로세서가 영상 출력 장치에 제1 영상 데이터를 전송한다\"는 것은 프로세서가 외부 소스 장치로부터 수신한 영상 신호의 세부적인 사항과 품질을 그대로 유지하여 영상 출력 장치에 제공한다 는 것을 의미할 수 있다. \"제1 영상 데이터\"는 \"제1 영상 신호\"라는 용어에 의해 대체될 수 있는 등 동일/유사 한 개념의 다양한 용어에 의해 대체될 수 있다. 일 예로, \"제2 영상 데이터\"란 프로세서가 제1 영상 데이터에 기초하여 변환환 영상 데이터를 의미할 수 있다. 예를 들어, 제2 영상 데이터는 프로세서가 외부 소스 장치로부터 수신한 영상 신호를 다운 스케일링 한 영상 신호를 의미할 수 있다, 또는, \"제2 영상 데이터\"는 외부 소스 장치로부터 수신한 원본 영상 신호의 데 이터 용량을 감소시키기 위하여 상대적으로 낮은 해상도 또는 낮은 품질로 변환하여 생성한 영상 신호를 포함할 수 있다. 예를 들어, \"프로세서가 영상 출력 장치에 제2 영상 데이터를 전송한다\"는 것은 프로세서가 외 부 소스 장치로부터 수신한 영상 신호의 품질을 그대로 유지하지 않고 상대적으로 낮은 품질로 전송한다는 것을 의미할 수 있다. \"제2 영상 데이터\"는 \"제2 영상 신호\"라는 용어에 의해 대체될 수 있는 등 동일/유사한 개념의 다양한 용어에 의해 대체될 수 있다. 일 실시 예에 따르면, 프로세서는 영상 출력 장치와 통신을 수행하는 통신 인터페이스를 통해 연결된 네트워크 상태가 제2 상태로 식별되면, 제1 영상 데이터의 특징 정보 및 제2 영상 데이터 중 적어도 하 나를 통신 인터페이스를 통해 영상 출력 장치로 전송할 수 있다. 예를 들어, 프로세서는 네트워 크 상태가 제2 상태로 식별되면, 제1 영상 데이터의 특징 정보만을 영상 출력 장치로 전송하거나, 제2 영 상 데이터만을 영상 출력 장치로 전송하거나, 제1 영상 데이터의 특징 정보와 제2 영상 데이터를 모두 영 상 출력 장치에 전송할 수도 있다. 여기서, \"제1 영상 데이터의 특징 정보\"란, 프로세서가 제1 영상 데이터에 기초하여 각 씬(Scene)별로 특 징을 추출하여 생성한 정보를 의미할 수 있다. 예를 들어, 씬은 영화 등의 컨텐츠 제작자에 의하여 구분되어진 시나리오 상의 동일한 공간에 대응되는 복수의 영상 프레임 구간일 수 있다. 다만, 이에 한정되는 것은 아니며, 동일한 공간에 대응되는 복수의 영상 프레임 구간이라도 영상의 밝기, 색상 등에 따라 상이한 씬으로 구분될 수 있다. 예를 들어, \"제1 영상 데이터의 특징 정보\"는 제1 영상 데이터에 포함된 복수의 씬 각각에 대응되는 특징 정보 를 포함할 수 있다. 구체적으로, 제1 영상 데이터의 특징 정보는 복수의 씬 각각의 색상 정보, 주요 오브젝트 정보, 콘트라스트 정보, 휘도 정보, 에지 정보, 텍스처 정보 등 다양한 정보를 포함할 수 있다. 일 예에 따라, 프로세서는 '씬A'로부터 특징 정보를 추출하기 위해 '씬A'를 구성하는 복수의 영상 프레임 각각에 대한 이미지 분석을 수행할 수 있다. 예를 들어, 프로세서는 복수의 영상 프레임 중 첫번째 프레임에 대한 이미지 분석을 하기 위해, 첫번째 프 레임에 포함된 픽셀들의 픽셀 값(예를 들어, 계조 값)들을 식별하고, 식별된 픽셀 값에 기초하여 해당 프레임의 대표 픽셀 값을 식별할 수 있다. 예를 들어, 대표 픽셀 값은 픽셀들의 평균 값, 가장 많은 비율을 차지하는 픽 셀 값 등 해당 프레임의 메인 픽셀 값으로 결정될 수 있다. 예를 들어, 프로세서는 첫번째 프레임에서 에지를 검출하여 오브젝트를 식별할 수 있다. 예를 들어, 프로 세서는 유사 범위의 픽셀 값들이 연속적으로 이어지는 픽셀들을 연결시켜 에지 부분을 검출할 수 있고, 에 지로 둘러 싸인 영역이 식별되면 에지의 형상에 기초하여 그 에지가 표현하는 오브젝트를 식별할 수도 있다. 일 예에 따라 프로세서는 상술한 방법에 의해 '씬A'를 구성하는 메인 색상에 대한 정보 및 메인 오브젝트 에 대한 정보를 획득할 수 있다. 상술한 프로세서의 씬 분석 방법은 하나의 예시에 불과하며, 프로세서 는 다양한 인공 지능 모델을 이용하여 영상 신호의 특징 정보를 추출할 수 있는 등 영상 신호에 대한 다양한 분석 방법에 의해 특징 정보를 추출할 수 있음은 물론이다. 예를 들어, 프로세서는 객체 인식(object recognition), 객체 검출(object detection), 객체 트래킹(tracking) 또는 이미지 세그멘테이션(image segmentation) 중 적어도 하나에 기초하여 프레임에 포함된 오브젝트를 식별할 수 있다. 예를 들어, 프로세서 는 필요에 따라 프레임에 포함된 객체들을 종류 별로 구분하여 추출하는 시맨틱 세그멘테이션(semantic segmentation), 같은 종류의 객체라도 객체별로 구분하여 객체를 인식하는 인스턴스 세그멘테이션(instance segmentation), 영상에 포함된 객체 검출 시, 검출된 객체를 포함하는 사각형 형태의 바운딩 박스(bounding box) 등의 기술을 이용하여 객체를 검출할 수 있다. 일 실시 예에 따르면, 프로세서는 영상 출력 장치와 통신을 수행하는 통신 인터페이스의 네트워 크의 가용 대역폭이 기 설정된 값 이상인 것으로 식별되면, 제 1 영상 신호를 통신 인터페이스를 통해 영 상 출력 장치로 전송할 수 있다. 일 실시 예에 따르면, 프로세서는 네트워크의 가용 대역폭이 기 설정된 값 미만인 것으로 식별되면, 제1 영상 데이터의 특징 정보 및 제2 영상 데이터 중 적어도 하나를 통신 인터페이스를 통해 영상 출력 장치 로 전송할 수 있다. 여기서 \"기 설정된 값\"은 제1 영상 데이터를 영상 출력 장치로 지연 없이 전송하기 위해 필요한 가용 대역 폭 값을 의미할 수 있다. 기 설정된 값은 제1 영상 데이터의 종류에 따라 상이한 값을 가질 수 있다. 예를 들어, 제1 영상 데이터가 4K UHD 해상도의 영상인 경우 25Mbps가 기 설정된 값이 될 수 있으며, HD(1080P)의 해 상도의 영상이라면 5Mbps가 기 설정된 값이 될 수도 있다. 또한 제1 영상 데이터가 요구하는 비트 전송률 또는 프레임 속도가 클수록 더 큰 값이 기 설정된 값으로 설정될 수도 있는 등 제1 영상 데이터가 권장하는 사항에 따라 기 설정된 값은 다양한 값으로 설정될 수 있다. 일 실시 예에 따르면, 프로세서는 통신 인터페이스의 네트워크의 가용 대역폭이 기 설정된 값 이상인 지 여부를 식별하기 위해 네트워크 상태를 직접 모니터링하여 네트워크의 상태 정보를 획득하거나 외부 소스 장 치로부터 네트워크의 상태 정보를 획득할 수도 있다. 네트워크 상태를 식별하는 방법에 대한 설명은 후술하는 도 3에 대한 설명 부분에서 자세히 설명하도록 한다. 도 3a 및 도 3b는 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치 및 영상 출력 장치의 동작을 설명하 기 위한 도면이다. 도 3a 및 도 3b에 따르면, 디스플레이 장치 또는 외부 소스 장치는 네트워크 상태를 모니터링하여 네 트워크의 상태 정보를 획득할 수 있고, 디스플레이 장치, 영상 출력 장치 및 외부 소스 장치는 네트워크의 상태에 따라 영상 신호 및/또는 오디오 신호를 송수신하는 장치를 변경할 수 있다. 여기서, \"네트워크의 상태 정보\"는 네트워크의 가용 Bandwidth, 패킷 손실률, 패킷의 Round-Trip Time, 패킷의 Delay-Gradient, RSSI(Received signal strength indicator) 정보, 통신 채널 정보, 링크 스피드 정보, 채널 간섭 정보 또는 재시도 레이트 정보 중 적어도 하나를 포함할 수 있다. 즉, 네트워크 상태 정보는 네트워크의 혼잡, 거리, 전송 속도에 따라 영향을 받는 다양한 네트워크 관련 정보가 될 수 있다. 일 예에 따라 디스플레이 장치, 영상 출력 장치 및 외부 소스 장치가 모두 동일한 통신 방식(예 를 들어, Wi-Fi 통신 방식)으로 연결될 수 있다. 외부 소스 장치는 Wi-Fi 네트워크를 통해 디스플레이 장 치에 영상 신호 및 오디오 신호를 전송하고, 프로세서도 Wi-Fi 네트워크를 통해 영상 출력 장치(20 0)에 영상 신호 및 오디오 신호를 전송할 수 있다. 프로세서는 영상 신호 및 오디오 신호를 송수신하면서 Wi-Fi 네트워크 상태를 모니터링할 수 있다. 예를 들어, 프로세서는 Wi-Fi 네트워크의 가용 대역폭, 패킷 손실률, 패킷의 Round-Trip Time, 패킷의 Delay-Gradient, RSSI(Received signal strength indicator) 등의 네 트워크의 상태 정보를 획득할 수 있다. 마찬가지로, 외부 소스 장치도 Wi-Fi 네트워크를 모니터링할 수 있 으며 상술한 바와 같은 네트워크의 상태 정보를 디스플레이 장치로 전송할 수 있다. 일 예에 따라 디스플레이 장치, 영상 출력 장치 및 외부 소스 장치가 서로 상이한 통신 방식으 로 연결될 수도 있다. 예를 들어, 외부 소스 장치와 디스플레이 장치는 블루투스 통신 방식을 통해 연결되어 영상 신호를 송수신하고, 디스플레이 장치와 영상 출력 장치는 Wi-Fi 통신 방식을 통해 연 결되어 영상 신호를 송수신할 수 있다. 이 경우, 디스플레이 장치는 영상 출력 장치와 Wi-Fi 네트워 크를 통해 연결되어 있어 프로세서는 Wi-Fi 네트워크를 모니터링하여 네트워크의 상태 정보를 획득할 수 있는 반면, 외부 소스 장치는 블루투스 네트워크를 통해 연결되어 있으므로, Wi-Fi 네트워크를 직접 모니 터링할 수는 없다. 따라서, 프로세서는 네트워크 상태를 직접 모니터링하는 것만으로 네트워크의 상태 정보를 획득할 수 있다. 상술한 방법에 의해, 프로세서는 프로세서가 직접 네트워크 상태를 모니터링하여 획득한 네트워크의 상태 정보 또는 상기 외부 소스 장치로부터 획득한 네트워크의 상태 정보에 기초하여 네트워크 상태가 제1 상태인지 또는 제2 상태인지 여부를 식별할 수 있다. 도 3a에 도시된 바와 같이, 외부 소스 장치는 디스플레이 장치와 구성한 네트워크(예를 들어, Wi-Fi 네트워크)를 통해서 디스플레이 장치로 영상 신호를 전송하고, 디스플레이 장치는 영상 출력 장치 와 구성한 네트워크를 통해서 영상 출력 장치로 영상 신호 또는 영상 신호의 특징 정보를 전송할 수 있다. 상술한 방법에 의해 디스플레이 장치는 영상 출력 장치와 구성한 네트워크의 상태를 식별할 수 있고, 식별한 네트워크 상태가 제1 상태인 경우, 디스플레이 장치는 디스플레이 장치의 외부 영역에 제1 영상 데이터에 기초한 제1 그래픽 이미지를 출력하기 위한 제어 신호를 영상 출력 장치에 전송할 수 있다. 또한, 디스플레이 장치는 식별된 네트워크 상태가 제2 상태인 경우, 디스플레이 장치의 외부 영역에 제1 영상 데이터의 특징 정보 및 제2 영상 데이터 중 적어도 하나에 기초한 제2 그래픽 이미지를 출력하 기 위한 제어 신호를 영상 출력 장치로 전송할 수 있다. 다만, 경우에 따라서는 제어 신호가 영상 출력 장 치에 전송되지 않더라도 제1 영상 데이터, 1 영상 신호의 특징 정보 및 제2 영상 데이터 중 적어도 하나가 영상 출력 장치로 전송되는 이벤트가 제어 신호의 기능을 대신할 수도 있다. 도 3b에 도시된 바와 같이, 외부 소스 장치는 디스플레이 장치 및 영상 출력 장치 각각과 네트 워크를 구성할 수도 있다. 일 예에 따라, 디스플레이 장치가 영상 출력 장치와 구성한 네트워크의 가 용 대역폭이 매우 제한되어 영상 신호 또는 특징 정보를 전송하기 어려울 수 있다. 이 경우, 외부 소스 장치 는 영상 출력 장치와 직접 네트워크를 구성하고, 네트워크를 통해 영상 신호 또는 특징 정보를 영상 출력 장치로 전송할 수도 있다. 상술한 방법에 의해, 외부 소스 장치는 네트워크의 상태를 식별할 수 있고, 외부 소스 장치와 영상 출력 장치 사이에서 구성된 네트워크의 상태가 제1 상태인 경우, 외부 소스 장치는 영상 출력 장치로 제1 영상 데이터에 기초한 제1 그래픽 이미지를 출력하기 위한 제어 신호를 영상 출력 장치에 전송할 수 있다. 또한, 외부 소스 장치는 식별된 네트워크 상태가 제2 상태 인 경우, 디스플레이 장치의 외부 영역에 제1 영상 데이터의 특징 정보 및 제2 영상 데이터 중 적어도 하 나에 기초한 제2 그래픽 이미지를 출력하기 위한 제어 신호를 영상 출력 장치로 전송할 수 있다. 다만, 경 우에 따라서는 제어 신호가 영상 출력 장치에 전송되지 않더라도 제1 영상 데이터, 1 영상 신호의 특징 정 보 및 제2 영상 데이터 중 적어도 하나가 영상 출력 장치로 전송되는 이벤트가 제어 신호의 기능을 대신할 수도 있다. 상술한 설명에서는 Wi-Fi 네트워크, 블루투스 네트워크만을 예시하였지만, 이는 하나의 예시에 불과하고, 디스 플레이 장치, 영상 출력 장치 및 외부 소스 장치는 지그비, 3G, 3GPP, LTE, LTE-A, 4G, 5G 등 다양한 통신 방식에 따라 구성된 네트워크를 통해 연결될 수 있음은 물론이다. 상술한 설명에서는, 디스플레이 장치 또는 외부 소스 장치가 네트워크의 상태를 식별하여, 식별된 네 트워크 상태에 대응되는 동작을 수행할 수 있다는 것만을 설명하였지만, 이에 한정되지 않고 디스플레이 장치 , 영상 출력 장치 및 외부 소스 장치는 각 장치의 성능을 분석하여 각 장치들이 각 장치들의 성 능에 대응되는 동작을 수행할 수도 있다. 예를 들어, 각 장치에 내장된 cpu의 점유율을 분석하여, cpu 점유율이 가장 낮은 장치가 영상 신호로부터 특징 정보를 추출하도록 제어할 수 있다. 구체적으로, 디스플레이 장치(10 0)의 cpu 점유율이 70%, 영상 출력 장치의 cpu 점유율이 20%, 외부 소스 장치의 cpu 점유율이 50%라 면, 영상 출력 장치가 수신한 영상 신호로부터 특징 정보를 추출하도록 제어될 수도 있다. \"제1 그래픽 이미지\" 및 \"제2 그래픽 이미지\"는 영상 출력 장치가 이머시브 스크린 효과를 사용자에게 제 공하기 위해 디스플레이 장치의 외부 영역에 출력하는 이미지들을 의미할 수 있는 바, 이에 대해서는 후술 하는 도 4, 도 5에서 자세히 설명하도록 한다. 도 4, 5는 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치의 동작을 설명하기 위한 도면이다. 도 4에 따르면, 동작 401에서, 디스플레이 장치는 영상 출력 장치와의 통신을 수행하는 통신 인터페 이스의 네트워크 상태를 식별하기 위해 네트워크 모니터링을 수행할 수 있다. 예를 들어, 디스플레이 장치 는 영상 출력 장치와의 통신을 위해 구성한 네트워크의 가용 대역폭, 네트워크의 패킷 손실률, 패킷 의 Round-Trip Time 등의 네트워크의 상태 정보를 획득함으로써 네트워크 상태를 모니터링할 수 있다.동작 402에서, 디스플레이 장치는 네트워크 상태를 제1 상태로 식별되면(, 동작 403에서, 제1 영상 데이터 를 영상 출력 장치로 전송할 수 있다. 예를 들어, 디스플레이 장치는 네트워크의 가용 대역폭이 기 설정된 값 이상인 경우 네트워크 상태를 제1 상태로 식별할 수 있다. 동작 403에서, 디스플레이 장치는 디스플레이의 외부 영역에 제1 영상 데이터에 기초한 제1 그래픽 이미지 출력에 대응한 정보를 영상 출력 장치로 전송할 수 있다.여기서, \"제1 그래픽 이미지 출력에 대응 한 정보\"란 디스플레이의 외부 영역에 제1 그래픽 이미지를 출력하기 위해 영상 출력 장치와 같은 외 부 장치에 전송하는 신호를 의미할 수 있다. 예를 들어, \"제1 그래픽 이미지 출력에 대응한 정보\"는 제1 그래픽 이미지를 디스플레이의 외부 영역에 출력하라는 제어 신호를 포함할 수 있다. 동작 404에서, 영상 출력 장치는 제1 영상 데이터 및 제어 신호가 수신되면, 동작 405에서 제1 그래픽 이 미지를 디스플레이 장치의 외부 영역에 출력할 수 있다. 다만, 경우에 따라서는 제어 신호는 제1 영상 데 이터에 포함되어 영상 출력 장치로 전송되거나, 영상 출력 장치로 전송되지 않을 수 있다. 예를 들어, 영산 출력 장치는 제1 영상 데이터가 수신되는 이벤트에 기초하여 제1 그래픽 이미지를 디스플레이 장치의 외부 영역에 출력할 수도 있다. 여기서, \"제1 그래픽 이미지\"는 영상 출력 장치가 제1 영상 데이터에 기초하여 생성한 그래픽 이미지를 의 미할 수 있다. 일 실시 예로, 제1 그래픽 이미지는 영상 신호의 특징 정보를 입력 받아 특징 정보에 대응되는 그래픽 효과(예를 들어, 블러 효과) 및/또는 그래픽 오브젝트(예를 들어, 물방울)을 출력하도록 학습된 인공지 능 모델에 의해 생성된 그래픽 이미지를 포함할 수 있다. 또 다른 실시 예로, 제1 그래픽 이미지는 영상 신호 및 영상 신호의 특징 정보를 함께 입력 받아 영상 신호 및 특징 정보에 대응되는 그래픽 효과 및/또는 그래픽 오브젝트를 출력하도록 학습된 인공지능 모델에 의해 생성된 그래픽 이미지를 포함할 수 있다. 예를 들어, 디스플레이 장치의 외부 영역은 디스플레이 장치의 주변 영역, 상부 영역, 하부 영역, 좌 측 영역 또는 우측 영역 중 적어도 하나를 포함할 수 있다. 여기서, 디스플레이 장치의 주변 영역이란, 도 1로 돌아가서, 디스플레이 장치에 구비된 베젤 외부 영역을 둘러싸면서 디스플레이 장치와 동일한 형 태로 형성된 영역을 의미할 수 있다. 일 예에 따르면, 제1 그래픽 이미지 및/또는 제2 그래픽 이미지는 디스플레이 장치에 구비된 디스플레이 의 외부 영역에 표시될 수 있다. 이 경우, 프로세서는 디스플레이의 크기보다 확장된 크기(또는 해상도)의 투사 영상을 생성할 수 있다. 예를 들어 프로세서는 디스플레이에 대응되는 영역에 대해서 는 알파 블렌딩(alpha blending) 처리를 수행하고, 나머지 영역에 제1 그래픽 이미지 및/또는 제2 그래픽 이미 지를 포함시켜 투사 영상을 생성할 수 있다. 여기서, 알파 블렌딩이란 이미지 위에 또 다른 이미지를 오버레이 할 때 마치 투명하게 비치는 효과를 내기 위해 색상 값 RGB에 A(Alpha)라는 새로운 값을 할당하여 백그라운드 RGB 값과 그 위의 RGB 값을 혼합하여 표시하는 방법을 의미한다. 예를 들어, Alpha 값은 0~255 값 또는 0.0~1.0 값으로 구분되며, 0은 완전 투명(completely transparent), 그 반대인 255(또는 1.0 등 제일 높은 값)은 완전 불투명(fully opaque)한 것을 의미할 수 있다. 또는 0은 완전 불 투명, 그 반대인 255(또는 1.0 등 제일 높은 값)은 완전 투명한 것을 의미할 수 있다. 예를 들어, Alpha 값에 8 비트가 할당되어 0~255 까지 값을 표현할 수 있다고 할 때 해당 값이 클수록 해당 픽셀의 비율이 높아지고 낮을 수록 비율이 낮아질 수 있다. 예를 들어, 디스플레이에 대응되는 영역의 투명도를 증가시킴에 따라 후단에 제공되는 디스플레이에 표시되는 영상은 유지되고 디스플레이의 외부 영역에만 제1 그래픽 이미지 및 /또는 제2 그래픽 이미지가 제공될 수 있게 된다. 또 다른 실시 예에 따르면, 제1 그래픽 이미지 및/또는 제2 그래픽 이미지는 디스플레이 장치에 구비된 디 스플레이 영역 및 디스플레이의 외부 영역 모두에 표시될 수 있다. 이 경우, 프로세서는 디스플 레이에 표시되고 있는 컨텐츠에 대응되는 그래픽 효과(예를 들어, 블러 효과) 및/또는 그래픽 오브젝트(예 를 들어, 물방울)이 포함된 제1 그래픽 이미지 및/또는 제2 그래픽 이미지를 제공할 수 있다. 이때, 프로세서 는 디스플레이 영역 및 베젤 외부 영역을 일정 두께로 둘러싸고 있는 영역을 포함하는 영역에 제1 그 래픽 이미지 및/또는 제2 그래픽 이미지를 출력하여, 디스플레이에 표시되고 있는 컨텐츠의 이미지와 제1 그래픽 이미지 및/또는 제2 그래픽 이미지를 오버레이할 수 있다. 제1 그래픽 이미지 및/또는 제2 그래픽 이미 지가 디스플레이에 표시되고 있는 컨텐츠의 이미지와 오버레이되어 사용자는 디스플레이의 외부 영역 에만 제1 그래픽 이미지 및/또는 제2 그래픽 이미지가 제공될 때보다 더 몰입감 있게 컨텐츠를 플레이할 수도 있다.도 5에 따르면, 동작 406에서, 디스플레이 장치는 영상 출력 장치와의 통신을 수행하는 통신 인터페 이스의 네트워크 상태를 식별하기 위해 네트워크 모니터링을 수행할 수 있다. 동작 407에서, 디스플레이 장치는 네트워크 상태가 제2 상태로 식별되면, 동작 408에서, 제1 영상 데이터 로부터 특징 정보를 획득하거나 제2 영상신호를 획득할 수 있다. 예를 들어, 디스플레이 장치는 네트워크 의 가용 대역폭이 기 설정된 값 미만이면, 네트워크 상태를 제2 상태로 식별할 수 있다. 도 2에서 설명한 바와 같이, 특징 정보란 제1 영상 데이터에 포함된 복수의 씬 각각에 대응되는 특징 정보를 의 미할 수 있고, 제2 영상 데이터란 제1 영상 데이터를 낮은 해상도 또는 낮은 품질로 다운스케일링하여 생성한 영상 신호를 의미할 수 있다. 동작 409에서, 디스플레이 장치는 제1 영상 데이터로부터 획득된 특징 정보 및 제2 영상 데이터 중 적어도 하나를 영상 출력 장치로 전송하고 동작 410에서 특징 정보 및 제2 영상 데이터 중 적어도 하나에 기초한 제2 그래픽 이미지 출력에 대응한 정보를 전송할 수 있다. 여기서, \"특징 정보 및 제2 영상 데이터 중 적어도 하나에 기초한 제2 그래픽 이미지 출력에 대응한 정보\"란 디스플레이의 외부 영역에 제2 그래픽 이미지를 출력하기 위해 영상 출력 장치와 같은 외부 장치에 전송하는 신호를 의미할 수 있다. 예를 들어, \"특징 정 보 및 제2 영상 데이터 중 적어도 하나에 기초한 제2 그래픽 이미지 출력에 대응한 정보\"는 제2 그래픽 이미지 를 디스플레이의 외부 영역에 출력하라는 제어 신호를 포함할 수 있다. 동작 411에서, 영상 출력 장치는 제2 그래픽 이미지를 디스플레이 장치의 외부 영역에 출력할 수 있 다. 여기서, \"제2 그래픽 이미지\"는 영상 출력 장치가 특징 정보 및 제2 그래픽 이미지 중 적어도 하나에 기초 하여 생성한 그래픽 이미지를 의미할 수 있다. 일 실시 예로, 제2 그래픽 이미지는 영상 신호의 특징 정보를 입 력 받아 특징 정보에 대응되는 그래픽 효과(예를 들어, 블러 효과) 및/또는 그래픽 오브젝트(예를 들어, 물방울)을 출력하도록 학습된 인공지능 모델에 의해 생성된 그래픽 이미지를 포함할 수 있다. 또 다른 실시 예 로, 제2 그래픽 이미지는 다운스케일링한 영상 신호와 영상 신호의 특징 정보를 함께 입력 받아 다운스케일링한 영상 신호와 특징 정보에 대응되는 그래픽 효과 및/또는 그래픽 오브젝트를 출력하도록 학습된 인공지능 모델에 의해 생성된 그래픽 이미지를 포함할 수도 있다. 상술한 설명에서는, 제1 그래픽 이미지, 제2 그래픽 이미지가 모두 학습된 인공지능 모델에 의해 생성된다고 설 명했지만 이는 하나의 예시에 불과하며, 영상 신호 또는 영상 신호의 특징 정보에 대응되는 그래픽 효과 및/또 는 그래픽 오브젝트는 기 정의된 필터에 의해 생성될 수도 있음은 물론이다. 여기서, 기 정의된 필터는 영상 신 호 또는 특징 정보가 영상 출력 장치에 수신되기 전에 디스플레이 장치의 특성, 사용자가 선택한 시 청 모드, 컨텐츠의 종류에 맞는 그래픽 효과들을 사전에 정의하여 저장할 수 있다. 예를 들어, 컨텐츠의 종류가 '축구 경기'라면, 기 정의된 필터는 실제 축구장에서 축구를 관람하는 것과 같은 이머시브 스크린을 구현하기 위해 수신된 영상을 크기가 확대된 영상으로 출력하기 위한 리사이징(resizing)효과를 발생시킬 수 있다. 또한 기 정의된 필터는 디스플레이 장치의 크기를 감지하여 디스플레이 주변부에 블러(blur)효과를 발생시키거 나 물방울 등의 그래픽 오브젝트를 발생시킬 수도 있는 등 다양한 그래픽 효과를 발생시킬 수도 있다. 또한, 상술한 설명에서는 프로세서가 영상 신호, 특징 정보 또는 제어 신호만을 영상 출력 장치로 전 송한다고 설명했지만, 프로세서는 디스플레이 장치 및 영상 출력 장치의 시간 정보를 동기화하 여 동일한 시간 기준을 공유하도록 함으로써, 같은 타이밍에 서로 대응되는 영상 및 오디오를 출력시킬 수 있다. 예를 들어, 프로세서는 각 영상 프레임 및 오디오 프레임을 영상 출력 장치의 출력과 동기화하 여 출력하기 위한 Timestamp를 포함한 패킷도 함께 전송할 수 있고 영상 출력 장치가 디스플레이 장치 로 Timestamp를 포함한 패킷을 전송할 수도 있다. 예를 들어, 각 영상 프레임 및 오디오 프레임의 일 영역 에 Timestamp를 포함시켜 전송할 수 있다. 예를 들어, 디스플레이 장치가 Network time protocol(NTP) 서버 장치가 될 수 있고 영상 출력 장치(20 0)가 NTP 클라이언트 장치가 될 수 있다. 디스플레이 장치는 매우 정밀한 시간 정보를 제공하는 상위 NTP 서버와 연결될 수 있다. 디스플레이 장치는 영상 출력 장치와의 동기화를 위해 Request 패킷과 Reply 패킷을 서로 교환할 수 있다. 구체적으로, 영상 출력 장치는 Reference Timestamp, Origin Timestamp, Receive Timestamp 등을 포함하는 Request 패킷을 디스플레이 장치로 전송할 수 있고, 디스플레이 장치 는 이에 응답하여 상술한 Timestamp를 포함하는 Reply 패킷을 영상 출력 장치로 전송할 수 있다. 영 상 출력 장치는 디스플레이 장치로부터 수신한 Reply 패킷, 패킷이 수신되기까지 걸린 시간 등에 기초하여 디스플레이 장치와의 동기화를 수행할 수 있다. 상술한 NTP를 이용한 두 장치 사이의 동기화 방법은 하나의 예시에 불과하며, Precision Time Protocol(PTP)을 이용한 두 장치 사이의 동기화 방법, GPS 수신기를 통해 GPS 신호를 수신하여 시간 정보를 획득하는 방법 등 다 양한 방법을 통해 디스플레이 장치 및 영상 출력 장치의 시간 정보를 동기화할 수 있다. 또한, 도 4 및 도 5는 프로세서가 제1 영상 데이터 또는 제2 영상 데이터를 전송할 수 있다는 것만을 도시 하고 있지만, 프로세서는 제1 오디오 데이터 또는 제2 오디오 데이터를 영상 출력 장치로 전송할 수 도 있다. 구체적으로, 도 4로 돌아가서, 디스플레이 장치는 네트워크 상태가 제1 상태로 식별되면, 제1 오디오 데이 터를 영상 출력 장치로 전송할 수 있다. 여기서 \"제1 오디오 데이터\"란 프로세서가 외부 소스 장치 로부터 수신한 오디오 신호를 의미할 수 있다. 즉, \"프로세서가 영상 출력 장치에 제1 오디오 데이터를 전송한다\"는 것은 프로세서가 외부 소스 장치로부터 수신한 오디오 신호의 세부적인 사항과 품질을 그대로 유지하여 영상 출력 장치에 제공한다는 것을 의미할 수 있다. \"제1 오디오 데이터\"는 \"제1 오디오 신호\"라는 용어에 의해 대체될 수 있는 등 동일/유사한 개념의 다양한 용어에 의해 대체될 수 있다. 또한, 도 5로 돌아가서, 디스플레이 장치는 네트워크 상태가 제2 상태로 식별되면 제1 오디오 데이터의 특 징 정보 및 제2 오디오 데이터 중 적어도 하나를 영상 출력 장치로 전송할 수 있다. 여기서 \"제2 오디오 데이터\"란 프로세서가 제1 오디오 데이터에 기초하여 변환한 오디오 데이터를 의미할 수 있다. 예를 들어, 제2 오디오 데이터는 프로세서가 외부 소스 장치로부터 수신한 오디오 신호를 다운 스케일링한 오디오 신호를 의미할 수 있다. 즉, \"제2 오디오 데이터\"는 외부 소스 장치로부터 수신한 원본 오디 오 신호를 낮은 샘플링 레이트 또는 낮은 음질로 축소하여 생성한 오디오 신호를 포함할 수 있다. 따라서, \"프로세서가 영상 출력 장치에 제2 오디오 데이터를 전송한다\"는 것은 프로세서가 외부 소스 장치로부터 수신한 영상 신호의 세부적인 사항과 품질을 그대로 유지하지 않고 필수적인 사항들만 남긴 낮 은 품질의 오디오 신호로 축소시켜 전송한다는 것을 의미할 수 있다. \"제2 오디오 데이터\"는 \"제2 오디오 신 호\"라는 용어에 의해 대체될 수 있는 등 동일/유사한 개념의 다양한 용어에 의해 대체될 수 있다. 여기서, \"제1 오디오 데이터의 특징 정보\"란, 프로세서가 제1 오디오 데이터에 기초하여 각 씬(Scene)별로 특징을 추출하여 생성한 정보를 의미할 수 있다. 구체적으로, 제1 오디오 데이터의 특징 정보는 복수의 씬 각각 을 구성하고 있는 오디오 신호의 주파수, 볼륨, 비트 등의 다양한 정보를 포함할 수 있다. 영상 출력 장치는 오디오 신호 및 오디오 신호의 특징 정보에 기초하여서도 제1 그래픽 이미지 또는 제2 그래픽 이미지를 출력할 수 있는 바, 이에 대한 설명은 후술하는 도 6 내지 도 9에 대한 설명에서 자세히 설명 하도록 한다. 한편, 도 4 및 도 5에서는 설명의 편의상 모든 단계에 대해 순서를 맵핑하였지만, 순서에 관계가 없거나 병렬적 으로 수행 가능한 단계 등의 순서를 해당 순서에 반드시 한정되는 것은 아님은 물론이다. 도 6은 본 개시의 하나 이상의 실시 예에 따른 영상 출력 장치의 구성을 설명하기 위한 블록도이다. 도 6에 따르면 영상 출력 장치는 메모리, 통신 인터페이스, 영상 투사부 및 프로세서(24 0)를 포함할 수 있다. 메모리는 영상 출력 장치에서 사용되는 각종 프로그램이나 데이터, 명령어 등을 저장할 수 있다. 그 밖에, 메모리는 본 개시의 다양한 실시 예에 따라 다양한 정보와 사전 학습된 인공지능 모델을 저장할 수 도 있다. 통신 인터페이스는 디스플레이 장치를 포함한 다른 전자 장치와의 통신을 위한 구성이다. 통신 인터 페이스에 대한 자세한 설명은 도 2에 대한 설명 부분과 중복되므로, 중복되는 부분은 생략하기로 한다. 영상 투사부는 영상을 표현하기 위한 광을 외부로 투사하여 이미지를 투사면에 출력하는 기능을 수행할 수 있다. 여기서, 투사면은 이미지가 출력되는 물리적 공간의 일부이거나 별도의 투사면일 수 있다. 영상 투사부 는 램프, LED, 레이저 중 적어도 하나의 광원, 프로젝션 렌즈, 반사체 등 다양한 세부 구성을 포함할 수 있다. 영상 투사부는 다양한 투사 방식(예를 들어, CRT(cathode-ray tube) 방식, LCD(Liquid Crystal Display) 방식, DLP(Digital Light Processing) 방식, 레이저 방식 등) 중 하나로 영상을 투사할 수 있다. 영상 투사부 는 적어도 하나의 광원을 포함할 수 있다. 영상 투사부는 사용자의 설정 등에 따라 4:3 화면비, 5:4 화면비, 16:9 와이드 화면비로 이미지를 출력할 수 있고, 화면비에 따라 WVGA(854*480), SVGA(800*600), XGA(1024*768), WXGA(1280*720), WXGA(1280*800), SXGA(1280*1024), UXGA(1600*1200), Full HD(1920*1080) 등의 다양한 해상도로 이미지를 투사할 수도 있다. 영상 투사부는 프로세서의 제어에 의해 투사 이미지를 조절하기 위한 다양한 기능을 수행할 수 있다. 예를 들어, 영상 투사부는 줌 기능, 렌즈 시프트 기능 등을 수행할 수도 있다. 프로세서는 영상 출력 장치의 전반적인 동작을 제어한다. 구체적으로 프로세서는 메모리, 통신 인터페이스, 영상 투사부와 연결되어, 메모리에 저장된 적어도 하나의 명령어 또는 프로그 램을 실행함으로써, 영상 출력 장치의 동작을 전반적으로 제어할 수 있다. 상술한 부분에서 영상 출력 장치의 동작으로 설명되었던 다양한 동작들은 프로세서의 제어를 통해 수 행될 수 있다. 예를 들어, 영상 출력 장치가 디스플레이 장치의 외부 영역에 제1 그래픽 이미지를 출력하는 동작은 프로세서가 동작의 주체가 되어 수행될 수 있다. 구체적으로, 프로세서는 제1 그래픽 이미지를 디스 플레이 장치의 외부 영역에 출력하도록 영상 투사부를 제어할 수 있다. 프로세서는 통신 인터페이스을 통해 디스플레이 장치로부터 제1 영상 데이터가 수신되면, 제1 영상 데이터를 분석하여 제1 영상 데이터의 제1 특징 정보를 획득하고, 획득된 제1 특징 정보를 학습된 인공 지 능 모델에 입력하여 제1 그래픽 이미지를 획득할 수 있다. 또는, 프로세서는 통신 인터페이스를 통해 디스플레이 장치로부터 제1 영상 데이터의 제2 특징 정보 및 제2 영상 데이터 중 적어도 하나가 수신되면, 제2 특징 정보 또는 제2 영상 데이터 중 적어도 하나를 학습된 인공지능 모델에 입력하여 제2 그래픽 이미지를 획득할 수 있다. 여기서, \"제1 영상 데이터의 제1 특징 정보\"는 프로세서가 제1 영상 데이터에 기초하여 영상에 포함된 복 수의 씬 각각에 대응되는 특징 정보를 추출하여 획득한 정보를 의미할 수 있다. 반대로, \"제1 영상 데이터의 제 2 특징 정보\"는 디스플레이 장치가 영상 출력 장치의 프로세서로 전송한 제1 영상 데이터의 특 징 정보를 의미할 수 있다.또한, 학습된 인공지능 모델을 이용하여 제1 그래픽 이미지 또는 제2 그래픽 이미지 를 획득하는 방법은 후술하는 도 7, 8에 대한 설명 부분에서 자세히 설명하도록 한다. 도 7, 8은 본 개시의 하나 이상의 실시 예에 따른 영상 출력 장치의 그래픽 이미지 생성 방법을 설명하기 위한 도면이다. 도 7에 따르면, 프로세서는 디스플레이 장치로부터 제1 영상 데이터 및/또는 제1 오디오 데이터가 수 신되면, 제1 영상 데이터 및/또는 제1 오디오 데이터를 분석하여 제1 영상 데이터의 제1 특징 정보 및/또는 제1 오디오 데이터의 제1 특징 정보를 추출할 수 있다. \"제1 영상 데이터의 제1 특징 정보\"는 제1 영상 데이터 를 구성하는 복수의 씬 각각에 대응되는 컬러 정보, 주요 오브젝트 정보, 콘트라스트 정보 등 다양한 정보를 포 함할 수 있고, \"제1 오디오 데이터의 제1 특징 정보\"는 제1 오디오 데이터의 주파수, 볼륨, 비트 등의 다양한 정보를 포함할 수 있다. 이어서, 프로세서는 제1 영상 데이터의 제1 특징 정보 및/또는 제1 오디오 데이터의 제1 특징 정보를 기 정의된 필터 및 학습된 인공지능 모델 중 적어도 하나에 입력하여 제1 그래픽 이미지를 획득할 수 있다. 학습된 인공지능 모델은 영상의 특징 정보 및/또는 오디오의 특징 정보를 입력 받아 입력 받은 데이터에 대응되는 그래픽 효과 또는 그래픽 오브젝트 중 적어도 하나를 출력하도록 학습된 인공지능 모델을 의미할 수 있다. 예를 들어, 사용자가 디스플레이 장치를 통해 시청하는 컨텐츠가 축구 경기인 경우, 프로세서는 축구 경기에 대한 영상 신호 및 오디오 신호를 수신할 수 있고, 수신한 영상 신호 및 오디오 신호로부터 추출한 특징 정보를 학습된 인공 지능 모델에 입력할 수 있다. 학습된 인공지능 모델은 추출한 특징 정보에 기초하여 주요 이벤트(예를 들어, 골 장면)을 식별할 수 있다. 예를 들어, 학습된 인공지능 모델은 오디오 신호의 특징 정보 중 볼륨 정보 및 주파수 정보에 기초하여 해설자의 음성 볼륨이 갑자기 증가하거나 해설자의 음성을 인식하여 \"골\"이라는 단어를 감지할 수도 있으 며, 영상 신호의 특징 정보에 기초하여 \"골대의 그물\"이 흔들리고 있다는 것을 감지할 수도 있고, 이러한 변화 를 감지하여 골 장면을 식별할 수 있다. 학습된 인공지능 모델은 영상 신호 및 오디오 신호의 특징 정보에 기초하여 주요 이벤트가 감지되면, 감지 된 주요 이벤트에 대응되는 그래픽 효과를 식별할 수 있다. 예를 들어, 골 장면이 감지되면 관객들이 열광하는 이미지를 디스플레이 장치의 외부 영역에 출력하도록 그래픽 효과를 생성할 수 있고, 영화 속에서 총을 쏘 는 장면이 감지되면 혈흔이 주변으로 튄 것과 같은 이미지를 디스플레이 장치의 외부 영역에 출력하도록 그래픽 효과를 생성할 수도 있다. 상술한 바와 같이 프로세서가 추출한 제1 영상 데이터의 제1 특징 정보 및/또는 제1 오디오 데이터의 제1 특징 정보를 입력 받아 그에 대응되는 그래픽 효과를 생성하는 인공 지능 모델을 \"학습된 제1 인공 지능 모델\" 로 정의하기로 한다. 프로세서는 학습된 제1 인공 지능 모델 뿐만 아니라 기 정의된 필터에 의해서도 간단한 그래픽 효과 를 발생시킬 수 있다. 다만, 기 정의된 필터에 대한 설명은 상술한 도 4 및 도 5에 대한 설명 부분에서 이 미 언급한 바, 중복되는 부분은 생략하도록 한다. 도 8에 따르면, 프로세서는 디스플레이 장치로부터 제1 영상 데이터의 제2 특징 정보 및/또는 제1 오 디오 데이터의 제2 특징 정보가 수신되면, 제1 영상 데이터의 제2 특징 정보 및/또는 제1 오디오 데이터의 제2 특징 정보를 기 정의된 필터 및 학습된 인공지능 모델 중 적어도 하나에 입력하여 제2 그래픽 이미지 를 획득할 수 있다. \"제1 영상 데이터의 제2 특징 정보\"는 디스플레이 장치가 제1 영상 데이터에 기초하여 추출한 특징 정보를 의미할 수 있으며, 제1 영상 데이터를 구성하는 복수의 씬 각각에 대응되는 컬러 정보, 주요 오브젝트 정보, 콘 트라스트 정보 등 다양한 정보를 포함할 수 있고, \"제1 오디오 데이터의 제2 특징 정보\"도 디스플레이 장치 가 제1 오디오 데이터에 기초하여 추출한 특징 정보를 의미할 수 있으며, 제1 오디오 데이터의 주파수, 볼 륨, 비트 등의 다양한 정보를 포함할 수 있다. 도 8에 도시된 바와 같이, 디스플레이 장치로부터 추출된 특징 정보를 수신하기 때문에 프로세서는 특징 정보를 추출하지 않아도 된다. 학습된 인공지능 모델은 제1 영상 데이터의 제2 특징 정보 및/또는 제1 오디오 데이터의 제2 특징 정보에 기초하여 그에 대응되는 제2 그래픽 이미지를 획득할 수 있다. 상술한 바와 같이 제1 영상 데이터의 제2 특징 정보 및/또는 제1 오디오 데이터의 제2 특징 정보를 입력 받아 그에 대응되는 제2 그래픽 이미지를 출력하는 인공지능 모델을 \"학습된 제2 인공 지능 모델\"로 정의하기로 한다. 학습된 제2 인공 지능 모델이 제2 그래픽 이미지를 획득하는 방법은 학습된 제1 인공 지능 모델이 제1 그래픽 이미지를 획득하는 방법 과 동일한 바, 이에 대한 자세한 설명은 생략하기로 한다. 또한, 프로세서는 디스플레이 장치로부터 제2 영상 데이터 및/또는 제2 오디오 데이터가 수신되면, 제2 영상 데이터 및/또는 제2 오디오 데이터를 학습된 인공지능 모델에 입력하여 제2 그래픽 이미지 를 획득할 수도 있다. 제2 영상 데이터 및/또는 제2 오디오 데이터를 입력 받아 그에 대응되는 제2 그래픽 이미지를 출력하는 인 공지능 모델을 \"학습된 제3 인공 지능 모델\"로 정의하기로 한다. 제1 그래픽 이미지는 원본 영상 신호 및/또는 원본 오디오 신호로부터 프로세서가 추출한 특징 정보 에 기초하여 인공지능 모델이 생성한 이미지인 반면, 제2 그래픽 이미지는 네트워크 상태가 제2 상태인 경 우(양호하지 않은 경우)일 때, 디스플레이 장치가 원본 영상 신호 및/또는 원본 오디오 신호로부터 필요한 특징만을 추출하여 생성한 작은 용량의 특징 정보 또는 다운스케일링된 영상 신호 및/또는 오디오 신호에 기초 하여 인공지능 모델이 생성한 이미지일 수 있다. 따라서, 제1 그래픽 이미지가 제2 그래픽 이미지보다 더 풍부 한 그래픽 효과를 제공할 수 있고, 더 몰입감 있는 스크린 경험을 사용자에게 제공할 수 있다. 상술한 설명에서는 설명의 편의를 위해 학습된 인공 지능 모델에 입력되는 데이터의 종류에 따라 각각 '제1, 제 2, 제3 인공 지능 모델'로 정의했지만, 하나의 인공지능 모델이 영상/오디오 신호, 영상/오디오의 특징 정보, 다운 스케일링된 영상/오디오 신호들을 모두 입력 받을 수도 있음은 물론이다. 상술한 인공 지능 모델은 영상 출력 장치의 메모리가 저장할 수 있고, 인공 지능 모델의 동작은 외부 서버에 의해 수행될 수도 있음은 물론이다. 상술한 설명에서는 설명의 편의를 위해 프로세서가 제1 영상 데이터, 제2 영상 데이터, 제1 영상 데이터의 특징 정보를 인공지능 모델에 입력하는 실시 예를 개별적으로 설명하였지만, 이는 하나의 예시에 불과하며 제2 영상 데이터 및 제1 영상 데이터의 특징 정보를 동시에 인공 지능 모델에 입력할 수도 있는 등, 프로세서 는 상술한 실시 예들을 조합한 동작을 수행할 수도 있음은 물론이다. 상술한 인공 지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복 수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연 산을 통해 신경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공 지능 모델 의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공 지능 모델에서 획득한 로스 (loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 9, 10은 본 개시의 하나 이상의 실시 예에 따른 영상 출력 장치의 이미지 출력 방법을 설명하기 위한 도면이 다. 도 9에 따르면, 프로세서는 사용자가 플레이하고 있는 컨텐츠에 대응되는 그래픽 효과가 포함된 그래픽 이 미지를 디스플레이 장치의 외부 영역에 출력할 수 있다. 예를 들어, 도 9에 도시된 바와 같이 프로세서는 컨텐츠의 영상 및 오디오를 분석하여 컨텐츠 내에서 발생 하고 있는 주요 이벤트를 식별할 수 있다. 구체적으로, 프로세서는 인공지능 모델을 이용하여 영상 내 주 요 오브젝트인 총이 흔들리거나 총 주변에 탄피가 식별되는 등 주요 오브젝트의 움직임을 식별하여 총알이 발사 되었다는 주요 이벤트의 발생을 감지할 수 있다. 또는, 프로세서는 오디오 신호의 주파수 및 볼륨을 분석 하여 일정한 주파수의 오디오 신호가 지속되다가 그와 상이한 주파수의 오디오 신호가 나타나거나 갑자기 큰 볼 륨의 오디오 신호가 나타나는 것을 감지한 것에 기초하여 총알이 발사되었다는 주요 이벤트의 발생을 감지할 수 있다. 프로세서는 총알이 발사되었다는 이벤트가 감지되면 사용자가 컨텐츠에 더 몰입할 수 있도록 디스플레이 장치의 외부 영역에 혈흔이 튄 것과 같은 그래픽 효과가 포함된 그래픽 이미지를 출력하도록 영상 투 사부를 제어할 수 있다. 도 9는 주요 이벤트의 발생을 감지하여 그에 대응되는 그래픽 효과가 포함된 그래픽 이미지가 출력된 것만 을 도시하고 있지만, 이는 하나의 예시에 불과하며 컨텐츠의 특징 정보에 기초하여 디스플레이 장치의 외 부 영역에 컨텐츠에 대응되는 컬러의 조명 효과를 발생시키는 등 다양한 그래픽 효과가 포함된 그래픽 이미지를 출력할 수도 있음은 물론이다. 도 10에 따르면, 영상 출력 장치는 출력 모드 정보에 따라 상이한 그래픽 이미지(620, 630, 640)를 상이한 영역에 출력할 수 있다. 여기서, 출력 모드 정보란 영상 출력 장치에 사전 저장되어 있는 프로세서가 이미지를 출력하는 방식 에 대한 정보를 의미할 수 있다. 예를 들어, 출력 모드 정보는 시청 모드(Watching mode), 이머시브 앰비언트 모드(Immersive ambient mode), 3D 모드(3D mode)를 포함할 수 있다. 또한, \"출력 모드\"는 \"출력 상태\"라는 용 어에 의해 대체될 수 있다. 따라서, 상술한 시청 모드, 이머시브 앰비언트 모드 및 3D 모드는 각각 시청 상태, 이머시브 앰비언트 상태, 3D 상태라는 용어에 의해 대체될 수 있다. 설명의 편의를 위해 본 설명에서는 \"출력 상태\"라는 용어 대신 \"출력 모드\"라는 용어로 명명하기로 한다. 프로세서는 사용자의 입력을 받아 출력 모드를 결정할 수 있으며, 수신한 컨텐츠의 종류에 따라 그에 대응 되는 출력 모드를 결정할 수도 있다. 일 실시 예로, 디스플레이 장치가 디스플레이하려는 컨텐츠가 16:9의 비율을 갖는 해상도의 영화 컨텐츠였 다면, 프로세서는 영화 컨텐츠라는 정보에 기초하여 시청 모드를 출력 모드로 결정할 수 있다. 프로세서 는 영화 컨텐츠의 영상 신호와 시청 모드라는 출력 모드 정보를 인공 지능 모델에 입력하여 그에 대응되는 그래픽 이미지를 획득할 수 있다. 시청 모드에 대응되는 그래픽 이미지는 도 10에 도시된 바와 같이21:9의 비율을 갖는 해상도의 이미지가 디스플레이 장치 및 디스플레이 장치의 외부 영역을 통해 표 시되도록 하는 그래픽 이미지일 수 있다. 다만 이는 하나의 예시에 불과하고, 시청 모드에 대응되는 그래픽 이 미지는 특정 비율을 갖는 해상도의 이미지로 한정되지 않고, 사용자가 더 몰입감 있게 컨텐츠를 즐길 수 있도록 원본 이미지보다 더 넓은 화면을 제공하는 다양한 이미지를 포함할 수 있다. 또 다른 실시 예로, 디스플레이 장치가 디스플레이하려는 컨텐츠가 음악 컨텐츠인 경우에는 프로세서(24 0)는 음악 컨텐츠라는 정보에 기초하여 이머시브 앰비언트 모드를 출력 모드로 결정할 수 있다. 프로세서 는 음악 컨텐츠의 영상 신호, 오디오 신호 및 이머시브 앰비언트 모드라는 출력 모드 정보를 인공 지능 모델에 입력하여 그에 대응되는 그래픽 이미지을 획득할 수 있다. 이머시브 앰비언트 모드에 대응되는 그래픽 이 미지는 도 10에 도시된 바와 같이 디스플레이 장치의 외부 영역에 영상 신호 또는 오디오 신호의 특 징에 대응되는 그래픽 효과 출력함으로써 구현될 수 있다. 또 다른 실시 예로, 디스플레이 장치가 디스플레이하려는 컨텐츠가 3D 게임인 경우에는, 프로세서는 3D 게임 컨텐츠라는 정보에 기초하여 3D 모드를 출력 모드로 결정할 수 있다. 프로세서는 게임 컨텐츠의 영상 신호, 오디오 신호 및 3D 모드라는 출력 모드 정보를 인공 지능 모델에 입력하여 그에 대응되는 그래픽 이 미지를 획득할 수 있다. 3D 모드에 대응되는 그래픽 이미지는 도 10에 도시된 바와 같이 디스플레이 장치의 전면부 바닥면에 게임 컨텐츠의 영상 신호 및 오디오 신호의 특징에 대응되는 그래픽 효과를 출력 함으로써 구현될 수 있다. 상술한 도 1 내지 도 10에 대한 설명에서는 모두 디스플레이 장치와 영상 출력 장치가 직접 통신하는 실시 예만을 설명했지만, 디스플레이 장치 및 영상 출력 장치는 외부 서버와 연동되어 상술한 도 1 내지 도 10에 대한 설명에서 설명한 동작들을 수행할 수도 있다. 예를 들어, 외부 서버는 디스플레이 장치에 영상 신호 및 오디오 신호를 제공하여 영상 및 오디오를 출력 하도록 제어할 수 있고, 동시에 외부 서버는 영상 출력 장치에 영상 신호 및 오디오 신호를 제공하여 그에 대응되는 그래픽 이미지를 디스플레이 장치를 향해 출력하도록 제어할 수 있다. 도 11은 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 11에 따르면, 동작 1110에서, 디스플레이 장치는 외부 소스 장치로부터 수신된 컨텐츠에 기초하여 영상 을 표시할 수 있다. 동작 1120에서, 디스플레이 장치는 네트워크 상태를 식별할 수 있다. 여기서, 네트워크 상태란 디스플레이 장치가 영상 출력 장치와의 통신을 수행하기 위해 구성한 네트워크의 상태를 의미할 수 있다. 네트워 크 상태는 네트워크의 가용 대역폭, 패킷 손실률, 패킷의 Round-trip time(RTT), 패킷의 Delay-Gradient, RSSI 정보, 통신 채널 정보, 링크 스피드 정보, 채널 간섭 정보 또는 재시도 레이트 정보 등에 기초하여 결정될 수 있다. 동작 1130에서, 디스플레이 장치는 네트워크 상태가 제1 상태로 식별되면, 제1 영상 데이터를 외부 영상 출력 장치로 전송할 수 있다. 예를 들어, 디스플레이 장치는 네트워크의 가용 대역폭이 기 설정된 값 이상 으로 식별되면 제1 영상 데이터를 외부 영상 출력 장치로 전송할 수 있다. 동작 1140에서, 디스플레이 장치는 제1 그래픽 이미지를 출력하기 위한 제어 신호를 외부 영상 출력 장치 로 전송할 수 있다. 예를 들어, 디스플레이 장치는 디스플레이 장치의 외부 영역에 제1 영상 데 이터에 기초한 제1 그래픽 이미지를 출력하기 위한 제어 신호를 전송할 수 있다. 동작 1150에서, 디스플레이 장치는 네트워크 상태가 제2 상태로 식별되면, 제1 영상 데이터의 특징 정보 또는 제2 영상 데이터를 외부 영상 출력 장치로 전송할 수 있다. 예를 들어, 디스플레이 장치는 네트 워크의 가용 대역폭이 기 설정된 값 미만으로 식별되면 제1 영상 데이터의 특징 정보 또는 제2 영상 데이터를 외부 영상 출력 장치로 전송할 수 있다. 동작 1160에서, 디스플레이 장치는 제2 그래픽 이미지를 출력하기 위한 제어 신호를 외부 영상 출력 장치 로 전송할 수 있다. 예를 들어, 디스플레이 장치는 디스플레이 장치의 외부 영역에 제1 영상 데 이터의 특징 정보 및 제2 영상 데이터 중 적어도 하나에 기초한 제2 그래픽 이미지를 출력하기 위한 제어 신호 를 전송할 수 있다. 도 11에서 설명한 각종 방법들은 도 2에서 도시한 구성을 가지는 디스플레이 장치에 의해 수행될 수 있으나 반 드시 이에 한정되는 것은 아니며, 다양한 구성을 가지는 디스플레이 장치에 의해 수행 될 수도 있다. 한편, 도 11에서는 설명의 편의상 모든 단계에 대해 순서를 맵핑하였지만, 순서에 관계가 없거나 병렬적으로 수 행 가능한 단계 등의 순서를 해당 순서에 반드시 한정되는 것은 아님은 물론이다. 본 개시의 다양한 실시 예들은 각 실시 예 별로 디스플레이 장치 뿐 아니라, 디스플레이 기능을 포함하는 모든 유형의 전자 장치에 적용되어 구현될 수 있으며, 각 실시 예들은 전체 또는 부분적으로 서로 조합되어 하나의 장치에 적용될 수도 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트 웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 전자 장치의 프로세싱 동작을 수행하기 위한 컴퓨터 명 령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 설정 방법들을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2024-0013427", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2024-0013427", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치 및 영상 출력 장치의 동작을 설명하기 위한 도 면이다. 도 2는 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치의 구성을 설명하기 위한 블록도이다. 도 3a 및 도 3b는 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치 및 영상 출력 장치의 동작을 설명하 기 위한 도면이다. 도 4, 5은 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치의 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 하나 이상의 실시 예에 따른 영상 출력 장치의 구성을 설명하기 위한 블록도이다. 도 7, 8은 본 개시의 하나 이상의 실시 예에 따른 영상 출력 장치의 그래픽 이미지 생성 방법을 설명하기 위한 도면이다. 도 9, 10 은 본 개시의 하나 이상의 실시 예에 따른 영상 출력 장치의 이미지 출력 방법을 설명하기 위한 도면 이다. 도 11은 본 개시의 하나 이상의 실시 예에 따른 디스플레이 장치의 제어 방법을 설명하기 위한 흐름도이다."}
