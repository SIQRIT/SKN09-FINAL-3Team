{"patent_id": "10-2021-0174744", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0086275", "출원번호": "10-2021-0174744", "발명의 명칭": "5G 통신시스템에의 응용을 고려한 딥러닝 가속기에서 global buffer에 대한 접근을 최소화하", "출원인": "한양대학교 산학협력단", "발명자": "최승원"}}
{"patent_id": "10-2021-0174744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "5G 통신시스템에의 응용을 고려한 딥러닝 가속기에서 global buffer에 대한 접근을 최소화하기 위해 재정렬된연산 시퀀스를 기반으로 local register file을 사용하는 방법."}
{"patent_id": "10-2021-0174744", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "데이터 이동에 많은 에너지가 소비되는 딥러닝 가속기의 문제를 해결하기 위한 방법을 제공한다. 상기 방법은 Local buffer를 통해 딥러닝 가속기 내의 데이터 재사용을 최대화함으로써, 에너지 소모가 큰 Global buffer로부 터 중복된 데이터 접근을 줄이는 것을 특징으로 한다. 또한, 이를 위해 연산의 순서는 특정 규칙에 의해 재정렬 되어 진행된다."}
{"patent_id": "10-2021-0174744", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 5G 통신시스템에의 응용을 고려한 딥러닝 가속기에서 global buffer에 대한 접근을 최소화하기 위해 재정렬된 연산 시퀀스를 기반으로 local register file을 사용하는 방법에 관한 것이다."}
{"patent_id": "10-2021-0174744", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 전용 가속기는 딥러닝 애플리케이션을 처리하기 위한 성능을 높이기 위해 프로세서에 추가적으로 탑재되 는 하드웨어를 의미한다. 딥러닝 애플리케이션을 위해서는 많은 Convolution 연산을 필요로 한다. 해당 Convolution 연산은 input data와 weight의 곱셈 및 누적 연산을 수행하는 것이다. 따라서 이러한 많은 Convolution 연산을 최대한 빠르게 처리하기 위해 곱셈과 누석연산을 할 수 있는 많은 컴퓨팅 유닛 탑재하는 전 용 가속기를 사용한다. 하지만, 이전에 사용되었던 딥러닝 가속기들은 컴퓨팅 파워에 중점을 두었기 때문에, 베터리를 사용하는 모바일 디바이스에서는 파워 소모가 높아지는 문제가 두드러지게 되었다. 따라서 파워 소모를 낮추기 위한 방향으로 가 속기의 연구가 진행되었고, 딥러닝 가속기의 대부분의 파워가 데이터 이동에서 발생함이 밝혀져, 높은 파워 문 제의 해결책으로 데이터 재사용을 높이는 방법들이 적용되기 시작했다. Convolution 연산은 중첩된 loop 문의 형태로 나타낼 수 있기 때문에, 동일한 데이터를 가지고 반복적인 연산이 일어나기 때문에 이러한 데이터들을 재사용함으로써 데이터의 이동량을 줄이는 것이다. 정확하게는, 중첩된 loop 문을 풀어써 input data 혹은 weight의 값을 고정시킴으로써, 반복적으로 필요로 하는 데이터를 1번의 읽 기 과정을 통해 여러 번 재사용하는 것이다. 기존의 딥러닝 가속기는 weight-stationary, input-stationary, 그리고 output-stationary 등 다양한 방법으로 데이터 재사용을 활용하고 있지만, 여전히 동일한 데이터에 대한 반복적인 Global buffer 접근이 필요하다는 문 제점이 있다."}
{"patent_id": "10-2021-0174744", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 문제점을 해결하기 위해 도출된 것으로, 본 발명의 목적은 5G 통신시스템에의 응 용을 고려한 딥러닝 가속기에서 global buffer에 대한 접근을 최소화하기 위해 재정렬된 연산 시퀀스를 기반으 로 local register file을 사용하는 방법을 제공하는데 있다."}
{"patent_id": "10-2021-0174744", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 측면에 따른 딥러닝 가속기에서 글로벌 버퍼에 대한 접근을 최 소화하기 위해 재정렬된 컨볼루션 연산을 기반으로 로컬 버퍼를 사용하는 방법은, 그 동작 방법으로서 다음의 5 스텝들(five steps)을 포함한다. Step 1) 2-D MAC array상에서 사용되는 temporal data reuse factor에 따라 연산 순서를 변경한다. Step 2) 변경된 연산순서에 따른 하나의 input data block 내의 중복된 데이터 패턴을 Register를 활용하여 재 사용한다. Step 3) 모든 input data block에 대한 연산을 할 때, input data block들 간의 중복된 데이터들도 또한 register를 통해 재사용한다. Step 4) Step 2)와 Step 3)에서 사용되는 register의 수를 최소화하기 위해서 해당 register를 공유해서 사용 한다. Step 5) 변경된 연산순서에 따라 Register를 활용하여 중복된 데이터들을 재사용하며 모든 convolutional operation을 완료한다."}
{"patent_id": "10-2021-0174744", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 상술한 바와 같은 본 발명에 따른 Rearrangement of convolutional operation의 연산 순서 에 따라 기존의 큰 Global buffer로부터 중복된 데이터 읽기 과정을 생략하고 Register를 활용하며 필요한 중복 된 데이터를 재사용하여 global buffer의 접근을 최소화하고 낮은 수준의 메모리 계층의 접근을 최대한 이용하 여 데이터를 읽는 과정에서 필요한 파워 소모를 최소화할 수 있다. 또한, 본 발명에 의하면, 딥러닝 가속기 하드웨어 설계 분야에서 딥러닝 전용 가속기를 탑재한 프로세서에 적용 할 수 있고, 또한 인공지능(AI) 전용 엣지 디바이스에 적용이 예상된다."}
{"patent_id": "10-2021-0174744", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어 야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용하였다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는 데 사용될 수 있지만, 상기 구성요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있 고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. \"및/또는\"이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 본 발명에 따른 바람직한 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 본 발명의 구체적인 방법은 다음 여러 단계로 이루어져 있으며 각 상세 설명은 아래에 단계별로 설명되어 있다. 1) 2-D MAC array상에서 사용되는 temporal data reuse factor에 따라 연산 순서를 변경한다. 2-D MAC array 상에서 weight를 재사용하기 위해서 temporal data reuse할 때에 reuse factor (P)에 따라 정해 지는 하나의 연산 단위를 ‘1 input data block’이라고 한다. 만약 temporal data reuse 16이고 Weight의 dimension을 3x3 이라고 한다면, 도 1과 같이 모든 weight pixel들과 곱해지는 ‘1 input data block’의 크기 가 정해진다. 즉, 도 1에서, Weight pixel들에 대해서 temporal data reuse를 사용하기 위해서 각 weight pixel당 temporal data reuse factor의 크기만큼 연속된 input data pixel들과 먼저 곱해줌으로써 weight의 재사용을 높일 수 있 다. 이 때, temporal data reuse factor에 의해 모든 weight pixel들과 곱해지는 input data pixel들이 정해지 는데, 이를 1 input data block이라고 한다. 이와 같은 연산 단위로 나머지 convolutional operation을 수행할 때에, 진행되는 연산 순서는 도 2와 같이 진 행된다. 즉, 하나의 input data block에 대해서 연산이 끝난 뒤, 바로 오른쪽의 input data pixel들에 대해서 연산하지 않고, 바로 아래 1칸 밑의 input data pixel들에 대해서 새로운 input data block의 연산을 진행한다. 이는 연산에 사용되는 input data의 중복된 영역의 규칙성을 확보하여 재사용에 용의하게하기 위함이다. 설명을 위해 temporal data reuse facotr는 P로 기술하며, Weight의 dimension을 NxN 이라고 표현한다. 2) 변경된 연산순서에 따른 하나의 input data block 내의 중복된 데이터 패턴을 Register를 활용하여 재사용한 다. 도 1과 같이 하나의 input data block의 연산에 사용되는 input data가 같은 row 상에 존재하는 연속된 weight pixel들 사이에서 (P - 1)개 만큼 중복되므로 이를 register에 저장하여 다시 사용함으로써 global buffer의 접 근을 줄인다. 이 때, 사용되는 register의 개수는 temporal data reuse factor (P)의 크기만큼 사용하면 도 3과 같이 필요한 만큼 재사용할 수 있다. 즉, 도 3에 나타낸 것과 같이, 하나의 input data block에 대해서 연산을 할 때에 중복되는 input data pixel 들을 register에 저장함으로써 재사용할 수 있다. 각 row별로 연속된 weight pixel들 간에 (P-1)개의 input data pixel들이 중복되므로, 처음 읽어온 P개의 input data pixel들을 register에 저장하여, 다음 weight pixel과 연산을 할 때에, 이전에 읽어온 15개의 input data는 register로부터 읽어 와서 연산한다. 나머지 하나 의 새로운 input data pixel에 대해서만 global buffer로부터 데이터를 새롭게 읽어온다. 따라서 register에 저장해둔 (P-1)개의 데이터로 인해 다음의 weight pixel과의 연산을 위해서 필요한 P개의 input data pixel 중 오직 새로운 1개의 데이터만 Global buffer로부터 새롭게 읽어오면 된다.3) 모든 input data block에 대한 연산을 할 때, input data block들 간의 중복된 데이터들도 또한 register를 통해 재사용한다. 위의 1)에 의해 변경된 convolutional operation 순서의 연산이 진행됨에 따라, 연속된 input data block들 간 에 사용되는 Input data가 도 4와 같이 (P-1)*(P+N-1)개씩 겹치게 된다. 따라서 2)의 과정을 통해 하나의 input data block 중에 (P-1)개의 row 만큼의 데이터를 저장하기 위한 reigster를 사용한다. 즉, 도 4에 나타낸 것과 같이, 해당 연산순서로 연산을 진행할 때에, 연속된 2개의 input data block들 간에도 중복되는 input data pixel들이 존재한다. 따라서 이전의 input data block의 (P-1)개 row에 해당하는 input data pixel들을 register를 활용한다면, 데이터 재사용할 수 있기 때문에 global buffer의 중복된 접근을 줄일 수 있다. 따라서, 바로 다음의 input data block에서 필요한 input data는 도 5와 같이 오직 마지막 row에 대해서만 필요 하며, 이 또한 위의 2)의 과정을 통해 읽어오게 된다. 다시 말해서, 연속된 두개의 input data block 간에 중복된 input data pixel들로 인한 global buffer를 줄이 기 위해서, 현재의 input data block의 마지막 (P-1) row에 해당하는 input data pixel들을 register에 저장하 고, 다음 input data block의 처음 (P-1) row에 해당하는 데이터에 대한 연산을 할 때 재사용한다. 4) 위의 2)와 3)에서 사용되는 register의 수를 최소화하기 위해서 해당 register를 공유해서 사용한다. 실제로 위의 3)을 위해 사용되는 register는 위의 2)에서 사용되는 register의 데이터를 모두 포함하고 있으므 로, 위의 3)에서 정의한 register를 위의 2)와 3)의 순서에 맞춰서 사용하면 convolutional operation 간에 사 용되는 input data에 대해서 중복된 사용은 모두 register를 통해 이루어지므로, global buffer의 접근을 최소 화해준다. 5) 변경된 연산순서에 따라 Register를 활용하여 중복된 데이터들을 재사용하며 모든 convolutional operation 을 완료한다. 즉, 도 6과 같이 나머지 연산을 모두 수행하고, 만약 마지막 column 부분이 온전한 직사각형의 형태의 input data block이 형성되지 않을 때에는, 중복되는 input data pixel들의 패턴이 일정하지 않으므로 재사용하기 위 한 컨트롤 로직이 복잡해질 수 있기 때문에, 해당 경우에 대해서만 예외적으로 반복적으로 global buffer를 통 해 데이터를 사용한다. 다시 말해서, 최소 연산 단위를 input data block에 대해서 나누고, 해당 연산 단위에 대해서 연산 순서를 아래 로 진행하고 나머지 오른쪽의 남아있는 input data pixel들에 대해서도 동일하게 연산을 수행한다. 다만, 오른 쪽에 남아 있는 input data pixel들이 input data block의 크기만큼 존재하지 않을 때에는, register를 통해 data reuse를 사용하지 않고, 필요한 데이터를 매번 global buffer로부터 읽어 와서 연산을 수행한다. 도 7은 본 발명의 또 다른 실시예에 따른 5G 통신시스템에의 응용을 고려한 딥러닝 가속기에서 global buffer에 대한 접근을 최소화하기 위해 재정렬된 연산 시퀀스를 기반으로 local register file을 사용하는 방법(이하 간 략히 '로컬 레지스터 파일 사용 방법')을 구현하는 로컬 레지스터 파일 사용 장치의 주요 구성에 대한 개략적인 블록도이다. 도 7을 참조하면, 로컬 레지스터 파일 사용 장치는, 컴퓨팅 장치의 일종으로서, 적어도 하나의 프로세서 (processor, 110) 및 적어도 하나의 프로세서가 일련의 단계들을 수행하도록 지시하는 명령어들 (instructions)을 저장하는 메모리(memory, 120)를 포함할 수 있다. 또한, 로컬 레지스터 파일 사용 장치는, 유선, 무선 또는 유무선 네트워크를 통해 외부 장치들과 통신을 수행하는 송수신 장치(transceiver, 130)를 포함할 수 있다. 또한, 로컬 레지스터 파일 사용 장치는 입력 인터페이스 장치나 출력 인터페이스 장치나 입출력 인터페이스 장치와, 저장 장치를 더 포함할 수 있 다. 데이터 재사용 장치에 포함되는 각각의 구성 요소들은 버스(bus)에 의해 서로 연결되어 신호 및 데이터를 주고받을 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU), 그래픽 처리 장치(graphics processing unit, GPU), 또는 본 발명의 실시예들에 따른 방법들이 수행되는 전용의 프로세서를 포함할 수 있다. 메모리 및 저장 장치 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 형성될 수 있다. 예를 들어, 메모리는 읽기 전용 메모리(read only memory, ROM) 및 랜덤 액세스 메모리(random access memory, RAM) 중에서 적어도 어느 하나로 구성될 수 있다. 또한, 전술한 프로세서는 전자적으로 연결되는 메모리에 저장되는 명령어들이나 이 명령어들에 의해 구현되는 프로그램이나 소프트웨어 모듈들을 탑재하고, 상기의 명령어들에 의해, 본 발명의 방법을 구현하는 일 련의 단계들을 수행할 수 있다. 또한, 전술한 본 발명의 실시예에 따른 방법의 동작은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있 는 프로그램 또는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어 분산 방식으로 컴퓨터로 읽을 수 있는 프로그램 또는 코드가 저장 되고 실행될 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 프로그램 명령은 컴파일러 (compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 발명의 일부 측면들은 장치의 문맥에서 설명되었으나, 그것은 상응하는 방법에 따른 설명 또한 나타낼 수 있 고, 구성부(unit) 또는 장치는 방법 단계 또는 방법 단계의 특징에 상응할 수 있다. 이와 유사하게, 방법의 문 맥에서 설명된 측면들은 또한 상응하는 블록 또는 구성부 또는 이에 상응하는 기능을 수행하는 장치의 특징으로 나타낼 수 있다. 방법 단계들의 몇몇 또는 전부는 예를 들어, 마이크로프로세서, 프로그램 가능한 컴퓨터 또는 전자 회로와 같은 하드웨어 장치에 의해(또는 이용하여) 수행될 수 있다. 몇몇의 실시예에서, 가장 중요한 방법 단계들의 하나 이상은 이와 같은 장치에 의해 수행될 수 있다. 실시예들에서, 프로그램 가능한 로직 장치 예를 들어, 필드 프로그래머블 게이트 어레이(field programmable gate array, FPGA)가 여기서 설명된 방법들의 기능의 일부 또는 전부를 수행하기 위해 사용될 수 있다. 실시예 들에서, 필드 프로그래머블 게이트 어레이는 여기서 설명된 방법들 중 하나를 수행하기 위한 마이크로프로세서 와 함께 작동할 수 있다. 일반적으로, 방법들은 어떤 하드웨어 장치에 의해 수행되는 것이 바람직하다. 이상 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 청구범위 에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2021-0174744", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 실시예의 방법에 채용할 수 있는 1 input data block를 설명하기 위한 도면이다. 도 2는 도 1에서 정의한 input data block에 대해서, input data block의 연산 진행 순서를 설명하기 위한 예 시도이다. 도 3은 도 1에서 정의한 input data block 내의 중복된 데이터 패턴을 Register를 활용하여 재사용하는 과정을 설명하기 위한 예시도이다. 도 4는 도 3의 재사용 과정에서 연산순서로 연산을 진행할 때에, 연속된 2개의 input data block들 간에도 중복 되는 input data pixel들이 존재하는 경우의 데이터 재사용을 설명하기 위한 예시도이다. 도 5는 도 4의 재사용 과정에서 바로 다음의 input data block에서 필요로 하는 경우의 데이터 재사용 과정을 설명하기 위한 예시도이다. 도 6은 본 실시예의 방법의 변경된 연산순서에 따라 Register를 활용하여 중복된 데이터를 재사용하며 모든 convolutional operation을 완료하는 과정을 설명하기 위한 예시도이다. 도 7은 본 실시예의 방법을 채용할 수 있는 장치의 주요 구성에 대한 블록도이다."}
