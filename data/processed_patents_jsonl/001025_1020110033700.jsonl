{"patent_id": "10-2011-0033700", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2012-0116134", "출원번호": "10-2011-0033700", "발명의 명칭": "지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치 및 그 동작 방법", "출원인": "한국전자통신연구원", "발명자": "김현"}}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하고, 상기 유저 인터페이스 화면상에 사용자행동을 촬영하는 카메라가 장착되는 입력프로젝터;상기 사용자 행동에 따른 사용자 명령을 인식하고, 상기 사용자 명령에 따른 서비스와 콘텐츠를 생성하도록 제어하는 메인보드; 및상기 생성된 콘텐츠를 출력하는 출력프로젝터를 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 출력프로젝터는,상기 사용자 행동을 추적하는 카메라가 장착되는 것을 특징으로 하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 메인보드는,상기 유저 인터페이스 화면상에 손가락 제스처에 따른 사용자 명령을 인식하고, 상기 사용자 명령에 따른 콘텐츠를 생성하도록 제어하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 메인보드는상기 카메라로부터 이미지 정보를 수신하여 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 검출, 물체 정보를 인지하도록 제어하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 사용자 음성을 입력받는 마이크로폰을 더 포함하되,상기 메인보드는상기 사용자 음성에 따른 사용자 정보 및 사용자 명령을 인식하도록 제어하는 지능형 로봇 특성을 갖는 휴대형컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 메인보드는상기 사용자 명령을 네트워크로 연결된 본체로 전송하고, 상기 본체로부터 사용자 명령에 따른 콘텐츠를 수신하도록 제어하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,공개특허 10-2012-0116134-3-상기 프로젝터와 상기 카메라의 하단에 구비되어 수직 회전하는 수직운동모터; 상기 수직운동모터의 하단에 구비되어 상기 프로젝터와 상기 카메라의 수평 회전하는 하는 수평운동모터; 및상기 수평운동모터의 하단에 구비되어 상기 프로젝터와 상기 카메라 전체를 회전하는 전체회전모터를 더 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로젝터의 하단에 카메라가 각각 장착되는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보, 환경 내 장치 정보, 에이전트 상태 관련 정보를 온톨로지(Ontology) 기반으로 저장하는 지식베이스를 더 포함하되,상기 메인보드는질의 요청 시 상기 정보를 제공하도록 제어하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 메인보드는로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정하여 상기 현재 상태에 맞는 관련 응용/서비스를 능동적으로 제공하도록 제어하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하고, 상기 유저 인터페이스 화면상에 사용자행동을 촬영하는 카메라가 장착되는 입력프로젝터;상기 사용자 행동에 따른 사용자 명령을 인식하여 네트워크로 연결된 본체로부터 사용자 명령에 따른 서비스와콘텐츠를 수신하도록 제어하는 메인보드; 및 상기 생성된 콘텐츠를 출력하는 출력프로젝터를 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 메인보드는상기 유저 인터페이스 화면상에 손가락 제스처에 따른 사용자 명령을 인식하고, 상기 사용자 명령에 따른 서비스와 콘텐츠를 수신하도록 제어하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 메인보드는상기 카메라로부터 이미지 정보를 수신하여 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 검출, 물체 정보를 인지하여 네트워크로 연결된 본체로부터 사용자 명령에 따른 서비스와 콘텐츠를 수신하도록 제어하는 지능형로봇 특성을 갖는 휴대형 컴퓨터 장치."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "유저 인터페이스화면, 서비스 및 콘텐츠 출력을 위한 화면을 제공하는 프로젝터화면 제공단계;공개특허 10-2012-0116134-4-상기 유저 인터페이스화면상에 사용자 행동에 따른 사용자 명령을 인식하는 사용자 명령인식단계; 및상기 사용자 명령에 따른 서비스와 콘텐츠를 출력하는 프로젝터화면 출력단계를 포함하는 지능형 로봇 특성을갖는 휴대형 컴퓨터 작동방법."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 사용자 행동을 추적하는 사용자 추적단계; 를 더 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 사용자의 이동상태를 감지하는 이동상태 감지단계; 및상기 사용자의 이동에 따른 위치를 보정하는 위치보정단계를 더 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 카메라로부터 이미지 정보를 수신하여 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 검출, 물체 정보를 인지하는 이미지 정보 인지단계를 더 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서,사용자 음성에 따른 사용자 정보 및 사용자 명령을 인식하는 음성인식단계를 더 포함하는 지능형 로봇 특성을갖는 휴대형 컴퓨터 작동방법."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서,상기 사용자 명령을 네트워크로 연결된 서버로 전송하고, 상기 서버로부터 사용자 명령에 따른 서비스와 콘텐츠를 수신하는 데이터 송수신단계를 더 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항에 있어서,사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보, 환경 내 장치 정보, 에이전트 상태 관련 정보를 온톨로지(Ontology) 기반으로 저장하는 지식베이스 저장단계; 및질의 요청 시 상기 정보를 제공하는 정보제공단계를 더 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법."}
{"patent_id": "10-2011-0033700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제14항에 있어서,로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정하여 상기 현재 상태에 맞는 관련 응용/서비스를 능동적으로 제공하는 행동패턴 학습단계를 더 포함하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법.명 세 서기 술 분 야공개특허 10-2012-0116134-5-본 발명은 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치 및 그 동작 방법에 관한 것으로서, 더욱 상세하게는 프 [0001]로젝터, 카메라, 마이크로폰, 터치 센서 등의 입출력 장치와 사용자 음성, 제스처 및 터치 기반의 멀티모달 인터렉션을 제공하여 보다 향상된 사용자 입출력과 지능화된 기능을 제공하는 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치 및 그 동작 방법에 관한 것이다.배 경 기 술최근 네트워크, 컴퓨터, 통신 및 가전 등의 융복합 화와 개인화, 지능화 등의 추세에 따라 우리 생활 환경에는 [0002]기존의 PC(Personal Computer)와는 다른 형태의 새로운 컴퓨터 장치가 나타나고 있다.일반적으로 컴퓨터는 키보드, 마우스, 화면 등으로 구비되어 입력에 의한 명령을 연산 처리하는 기능을 수행하 [0003]였으나, 최근에는 터치 패널, 카메라, 프로젝트 화면 등 사용자 명령을 입력하고 표시하는 다양한 인터페이스가결합한 사용자 중심의 컴퓨터 제품이 빠르게 등장하고 있다.애플(APPLE)은 태블릿 컴퓨터 형태의 9.7인치 IPS 패널에 멀티 터치 스크린을 이용한 휴대용 멀티미디어 단말을 [0004]출시하였으며, Microsoft는 직접 손으로 디지털 정보를 조작할 수 있는 Surface Computing Project와 테이블탑이라는 개념의 컴퓨터를 출시하였다.또한, Microsoft는 최근 카메라와 센서 장치를 이용하여 사용자의 움직임, 제스처 및 음성인식을 통해 사용자의 [0005]명령을 인식하는 인터페이스 장치를 개발하였다.그리고 MIT Media Lab은 프로젝터를 화면과 카메라를 이용한 Sixth Sense와 LuminAr을 개발하였다. [0006]발명의 내용해결하려는 과제따라서, 본 발명에서는 좀 더 진일보한 기능, 다양한 센서와 장치로 구성되어 지능형 개인 서비스 로봇의 특성 [0007]을 갖는 새로운 형태의 컴퓨터 장치로서 (1) 카메라/프로젝터를 이용한 입출력 인터랙션, (2) 영상/음성/터치등 다중 센서를 이용한 사용자 지각 (Perception) 기능, (3) 사용자 및 환경 상황인지 및 (4) 사용자와의 지속적 관계를 이용한 성장 및 자율행위 기능을 제공하는 데에 그 목적이 있다.또한, 본 발명은 상기한 바와 같이 다양한 센서와 장치로 구성되어 지능형 개인 서비스 로봇의 특성을 갖는 새 [0008]로운 형태의 컴퓨터 장치에 관한 것으로서, 프로젝터, 카메라, 마이크로폰, 터치센서 기반의 입출력 장치와 사용자 음성, 제스처, 터치 기반의 멀티모달 인터랙션을 제공함으로써 더욱 자연스러운 사용자 입출력을 제공하는데에 그 목적이 있다.또한, 본 발명의 다른 목적은 사용자 위치를 인식하고, 사용자 얼굴을 인식하고 추적하며, 주변 소리에 반응하 [0009]는 데에 있다.또한, 본 발명의 다른 목적은 사용자가 있는 위치에서 활성화된 기기들을 감지하고, 네트워크를 통해 그 기기를 [0010]동적으로 연결하는 데에 있다.또한, 본 발명의 다른 목적은 누가, 언제, 어디서 어떤 작업을 수행했는지에 대한 정보를 구축하여 사용자의 장 [0011]치 활용패턴을 학습함으로써, 사용자에게 보다 능동적인 서비스를 제공하는 데에 있다.과제의 해결 수단본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 사용자 입력을 위한 유저 인터페이스 [0012](User Interface) 화면을 제공하고, 상기 유저 인터페이스 화면 상에 사용자 행동을 촬영하는 카메라가 장착되는 입력 프로젝터와, 상기 사용자 행동에 따른 사용자 음성 및 제스처 명령을 인식하고, 상기 사용자 명령에 따른 서비스와 콘텐츠를 생성하도록 제어하는 메인보드 및 상기 생성된 콘텐츠를 출력하는 출력 프로젝터를 포함할 수 있다.상기 출력프로젝터는, 상기 사용자 행동을 추적하는 카메라가 장착되는 것이 바람직하다. [0013]바람직하게, 상기 메인보드는, 상기 유저 인터페이스 화면상에 손가락 제스처에 따른 사용자 명령을 인식하고, [0014]상기 사용자 명령에 따른 서비스와 콘텐츠를 생성하도록 제어할 수 있다.바람직하게, 상기 메인보드는, 상기 카메라로부터 이미지 정보를 수신하여 주변 움직임 검출, 얼굴 검출, 얼굴 [0015]공개특허 10-2012-0116134-6-인식, 손가락 검출, 물체 정보를 인지하도록 제어할 수 있다.바람직하게, 사용자 음성을 입력받는 마이크로폰을 더 포함하되, 상기 메인보드는, 상기 사용자 음성에 따른 사 [0016]용자 정보 및 사용자 명령을 인식하도록 제어할 수 있다.바람직하게, 상기 메인보드는, 상기 사용자 명령을 수신하는 센서 정보는 네트워크로 연결된 서버에 전송하고, [0017]상기 서버로부터 인지 프로세싱을 수행하며, 그 결과에 따른 서비스와 콘텐츠를 수신할 수 있다.바람직하게, 상기 프로젝터와 상기 카메라의 하단에 구비되어 수직 회전하는 수직운동모터와, 상기 수직운동모 [0018]터의 하단에 구비되어 상기 프로젝터와 상기 카메라의 수평 회전하는 하는 수평운동모터 및 상기 수평운동모터의 하단에 구비되어 상기 프로젝터와 상기 카메라 전체를 회전하는 전체회전모터를 포함할 수 있다.바람직하게, 상기 프로젝터의 하단에 카메라를 각각 장착할 수 있다. [0019]바람직하게, 사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보, 환경 내 장치 정보, 에이 [0020]전트 상태 관련 정보를 온톨로지(Ontology) 기반으로 저장하는 지식베이스를 포함하되, 상기 메인보드는 질의요청 시 상기 정보를 제공하도록 제어할 수 있다.바람직하게, 상기 메인보드는, 로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정하여 [0021]상기 현재 상태에 맞는 관련 서비스와 콘텐츠를 능동적으로 추천할 수 있다. 본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법은 유저 인터페이스화면, 서비스 및 [0022]콘텐츠 출력을 위한 화면을 제공하는 프로젝터 화면 제공단계와, 상기 유저 인터페이스 화면 상에 사용자 행동에 따른 사용자 명령을 인식하는 사용자 명령인식단계 및 상기 사용자 명령에 따른 서비스와 콘텐츠를 출력하는프로젝터 화면 출력 단계를 포함한다.바람직하게, 본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법은 상기 사용자 행동을 [0023]추적하는 사용자 추적단계를 포함할 수 있다.바람직하게, 본 발명의 실시 예에 따른 지능형 로봇 특성을 휴대형 컴퓨터 작동방법은 상기 사용자의 이동상태 [0024]를 감지하는 이동상태 감지단계와 상기 사용자의 이동에 따른 위치를 보정하는 위치보정단계를 포함할 수 있다.바람직하게, 상기 카메라로부터 이미지 정보를 수신하여 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 [0025]검출, 물체 정보를 인지하는 이미지 정보 인지단계를 포함할 수 있다.바람직하게, 사용자 음성에 따른 사용자 정보 및 사용자 명령을 인식하는 음성인식단계를 포함할 수 있다. [0026]바람직하게, 상기 사용자 명령을 수신하는 센서 정보는 네트워크로 연결된 서버로 전송하고, 상기 서버로부터 [0027]인지 프로세싱을 수행하며, 그 결과에 따른 서비스와 콘텐츠를 수신하는 데이터 송수신단계를 포함할 수 있다.바람직하게, 사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보, 환경 내 장치 정보, 에이 [0028]전트 상태 관련 정보를 온톨로지(Ontology) 기반으로 저장하는 지식베이스 저장단계와, 질의 요청 시 상기 정보를 제공하는 정보제공단계를 포함할 수 있다.바람직하게, 로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정하여 상기 현재 상태에 [0029]맞는 관련 응용/서비스를 능동적으로 제공하는 행동패턴 학습단계를 포함할 수 있다.발명의 효과본 발명은 다음과 같은 효과가 있다. [0030]첫째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 주변 환경과 인터랙션하고 있으며, 특히 사람을 찾고, 사 [0031]용자가 누구인지를 인식보고, 얼굴을 추적하며, 필요 시 인터랙션 기능을 수행하여 사용자 명령을 수행한다.둘째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 언제 어디서나 컴퓨팅 환경을 제공한다. 즉 프로젝터를 [0032]이용하여 거실, 주방, 책상 등 어떤 공간이든 Table Top 형태의 입출력 환경을 제공하고 사용자는 손가락 제스처, 음성 또는 터치 등을 이용하여 컴퓨터와 인터랙션할 수 있다. 셋째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 사용자의 명시적 요청뿐만 아니라 사용자와 물리환경의 [0033]상황을 이해하여 이에 맞게 서비스를 제공한다.넷째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 물리세계와 가상세계를 연결하는 역할을 한다. 즉 카메라 [0034]공개특허 10-2012-0116134-7-를 통해 실제 사물을 인식하고, 그 사물에 대한 정보를 가상공간상으로부터 얻어와 프로젝터를 이용해 이를 투영함으로써 물리적 사물에 디지털 정보를 증강할 수 있다.도면의 간단한 설명도 1은 본 발명의 일 실시예에 따른 로봇 컴퓨터를 도시한 블록도이다. [0035]도 2는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 도면이다.도 3은 본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 블록도이다.도 4는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 소프트웨어 구성도이다.도 5는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 동작 매커니즘을 보여주는흐름도이다.도 6은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 이동형 컴퓨터 휴대형 컴퓨터 장치에 대한 처리흐름도이다.도 7은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 사용자 이동에 따른 위치보정에 대한 처리 흐름도이다.발명을 실시하기 위한 구체적인 내용이하의 실시예들은 본 발명의 구성요소들과 특징들을 소정 형태로 결합한 것들이다. 각 구성요소 또는 특징은 [0036]별도의 명시적 언급이 없는 한 선택적인 것으로 고려될 수 있다. 각 구성요소 또는 특징은 다른 구성요소나 특징과 결합하지 않은 형태로 실시될 수 있다. 또한, 일부 구성요소들 및/또는 특징들을 결합하여 본 발명의 실시예를 구성할 수도 있다. 본 발명의 실시예들에서 설명되는 동작들의 순서는 변경될 수 있다. 어느 실시예의 일부 구성이나 특징은 다른 실시예에 포함될 수 있고, 또는 다른 실시예의 대응하는 구성 또는 특징과 교체될 수있다.본 발명의 실시예들은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 발명의 실시예들은 하드웨어, 펌웨어 [0037](firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 하나 또는 그 이상의 ASICs(application [0038]specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processingdevices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서, 콘트롤러,마이크로 콘트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다.펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 이상에서 설명된 기능 또는 동작 [0039]들을 수행하는 모듈, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리 유닛에 저장되어프로세서에 의해 구동될 수 있다. 상기 메모리 유닛은 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된다양한 수단에 의해 상기 프로세서와 데이터를 주고 받을 수 있다.이하의 설명에서 사용되는 특정(特定) 용어들은 본 발명의 이해를 돕기 위해서 제공된 것이며, 이러한 특정 용 [0040]어의 사용은 본 발명의 기술적 사상을 벗어나지 않는 범위에서 다른 형태로 변경될 수 있다.이하, 첨부된 도면들을 참조하여, 본 발명에 따른 실시예들에 대하여 상세하게 설명하기로 한다. [0041]도 1은 본 발명의 일 실시예에 따른 로봇 컴퓨터를 도시한 블록도이다. [0042]이하 도1을 참조하여 설명을 개시한다. [0043]본 발명에서 제안하는 로봇 컴퓨터는 본체 (Control Unit)(10)와 에이전트 단말(Agent Unit)(100)로 구성된다. [0044]본체(10)는 중앙처리장치이며, 단말의 Brain Server 역할을 한다. 본체 (Control Unit)은 미래의 우리 생활환경 [0045]이 스마트 공간이 된다는 점을 고려하여, 그 공간 내 자원 또는 장치를 관리하는 서버 (예: 홈서버, IPTV 세탑박스 등)에 연결된다. 에이전트 단말 (Agent Unit)(100)은 사용자가 들고 어디든지 이동할 수 있는 단말로서,본체와 네트워크로 연결되며, 사용자와의 인터랙션을 담당한다.이하에서는 그 언급을 생략하겠으나, 본 발명에 따른 네트워크는 본체(10)와 에이전트 단말(100)을 연계하고, [0046]TCP/IP 프로토클의 유선 인터넷 망, 왑(WAP) 프로토콜의 무선 인터넷망 및 유/무선통신망 등을 이용하여 구축할공개특허 10-2012-0116134-8-수 있다.도 2는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 도면이다. [0047]도 3은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 블록도이다. [0048]이하 도 2 및 도 3을 참조하여 설명을 개시한다. [0049]도2를 참조하면, 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 에이전트 단말에 [0050]관한 것으로서 프로젝터(110), 카메라(120), 메인보드(130), 마이크로폰(140), 5 모터(150), 조도센서(160),터치패드(170), 스테레오 스피커(180) 및 배터리(190)를 포함한다.프로젝터(110)는 유저인터페이스(user interface)화면, 서비스 및 콘텐츠 화면을 제공하며, 유저인터페이스 화 [0051]면은 GUI(Graphic User Interface) 기반으로 제공되거나 입체영상 방식의 3D 영상 등을 채용할 수 있다.그리고 프로젝터(110)는 사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하고, 사용자 행동을 [0052]촬영하는 카메라(120)를 장착할 수 있다.본 발명의 실시예에 따른 프로젝터(110)는 사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하 [0053]는 입력 프로젝트(111)와 상기 생성된 콘텐츠를 출력하는 출력 프로젝터(113)로 분리할 수 있다.또한, 입력프로젝터(111)는 사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하고, 유저 인터 [0054]페이스 화면상에 사용자 행동을 촬영하는 카메라를 장착할 수 있다.그리고 상기 출력프로젝터(113)는 사용자 행동을 추적하는 카메라를 장착할 수 있다. [0055]또한 프로젝터(110)는 입력/출력 프로젝터(111,113)로 분리하였으나, 일체형으로 구비되어 입력/출력 화면을 일 [0056]체형으로 구비할 수 있다.그리고 프로젝터(110)는 프로젝트/카메라 2쌍으로 구비될 수 있으며, 입력/출력 프로젝터(111,113)의 하단에 각 [0057]각 장착될 수 있다.구체적으로 도 2를 참조하면, 입력/출력 프로젝터(111,113)로 분리된 2개의 프로젝트가 구비되고, 각각의 프로 [0058]젝트의 하단에 카메라(120)가 장착된다.그리고 카메라(120)의 위치는 프로젝터(110)의 하단에 장착되는 것으로 설정하였으나, 측면 등에 구비되는 구조 [0059]로 변경할 수 있다.또한, 프로젝터(110)로 출력된 GUI 화면에 손가락 제스처(Gesture)를 이용한 사용자 명령으로 인터랙션 하며, [0060]입력 프로젝터(111)에 하단에 부착된 카메라(120)는 출력된 GUI 화면과 손가락 제스처를 인식한다.여기서, 입력 프로젝터(111)/카메라(120) 한 쌍이 바닥면에 GUI 화면을 제공할 때 또 다른 한 쌍의 출력 프로젝 [0061]터(113)는 벽면에 콘텐츠 화면을 제공할 수 있다. 상기 프로젝트(110)는 FPGA(field programmable gatearray)(115)를 이용하여 데이터를 전송하는 것으로 설정할 수 있으나, 이에 한정된 것은 아니다.또한, 카메라(120)는 손가락 제스처(Gesture)를 감지하기 위한 입력장치로 구비될 수 있으며, 상황에 따라 사용 [0062]자 인식, 장소, 주변의 사물인식 등을 위한 입력장치로 사용될 수 있다. 그리고 카메라(120)는 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 검출 및 물체 인식 등을 인지하기 위한 [0063]이미지 정보를 생성할 수 있다.본 실시예에 따른 이미지 정보는 자신의 주변에 움직임이 있는지 (움직임 검출, Motion Detection), 사람 얼굴 [0064]이 있는지 (얼굴 검출, Face Detection), 그 사람이 누구인지 (얼굴 인식, Face Recognition), 사용자의 손가락이 어떤 위치에서 어떤 제스처로 움직이는지 (손가락 검출, Finger Tip Detection), 자기 앞에 자기가 알고있는 물체가 있는지 (물체 인식, Object Detection) 등을 인지하도록 제공된다.또한, 카메라(120)는 USB(Universal Serial Bus)로 착탈 가능하게 구비될 수 있으며, 다양하게 변경할 수 있다. [0065]또한, 메인보드(130)는 프로젝터(110)와 카메라(120)를 연결/제어하며, 네트워크로 연결된 본체와 통신하도록 [0066]네트워크를 제어한다.여기서 네트워크는 에이전트 단말과 본체 사이의 네트워크 통신을 담당하는 원격 객체 호출 방식이며, 즉, 클라 [0067]이언트 프로그램에서 원격 객체에 대한 참조 (reference)를 얻고, 그 객체가 마치 클라이언트 자신의 객체인 것공개특허 10-2012-0116134-9-처럼 함수를 호출할 수 있도록 지원한다. 이를 위해 본 실시예에 따른 네트워크는 클라이언트 측에서는 전달할 데이터를 이질적인 환경에 무관하도록 표 [0068]준화된 방식으로 묶어서(marshaling) 메시지를 전송하고, 서버 측에서는 전달된 메시지를 풀어서(unmarshaling) 데이터를 얻고, 원격 객체를 활성화한 후 호출하고 그 결과를 다시 같은 방법으로 클라이언트측에 전달하는 일련의 작업들을 지원한다.또한 메인보드(130)는 주제어보드(Main Control Board)(133)와 각종센서, 모터, LED 등의 주변장치를 연결하는 [0069]주변장치제어보드(Peripheral Device Controller)(135)를 포함할 수 있다.주제어보드(133)는 프로세서, 메모리, 하드디스크, 그래픽처리기, USB포트, 통신모뎀, BUS 등을 포함하여, 지능 [0070]형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 프로세싱(processing) 제어 기능을 수행한다.그리고 메인보드(130)는 음성인식, 합성 및 사운드 재생 등을 위한 음성처리를 수행하는 사운드제어보드(Sound [0071]Control Board)를 포함할 수 있다.또한, 메인보드(130)는 하나의 주제어보드에서 모두 처리할 수 있으며, 제어보드로 추가하여 확장할 수 있다. [0072]구체적으로, 본 실시예에 따른 메인보드(130)는 사운드제어보드의 기능을 주제어보드에서 그 역할을 대체할 수 [0073]있으며, 또한 영상처리보드를 별도로 구비할 수 있다. 또한, 마이크로폰(140)은 음성을 통한 사용자 정보와 사용자 명령이 입력된다. [0074]입력된 음성을 포함하는 소리 정보는 어디에서 소리가 나는지 (음원 추적, Sound Source Localization), 어떤 [0075]말을 했는지 (음성 인식, Voice Recognition) 등을 인지하도록 제공된다.상기 5 모터(150)는 상기 프로젝터(110), 카메라(120) 및 로봇동작을 위한 동력을 제공한다. [0076]구체적으로 상기 5 모터(150)는 수직운동모터(151), 수평운동모터(153), 전체회전운동모터(155) 및 다리회전모 [0077]터(157)를 포함한다.여기서 수직운동모터(151)는 프로젝터(110)와 카메라(120)의 하단에 구비되어 수직 회전 동력을 제공하고, 상기 [0078]수평운동모터(153)는 상기 수직운동모터(151)의 하단에 구비되어 프로젝터(110)와 카메라(120)의 수평 회전 동력을 제공하고, 상기 전체회전운동모터(155)는 상기 수평운동모터(153)의 하단에 구비되어 프로젝터(110)와 카메라(120) 전체 회전 동력을 제공하고, 상기 다리회전모터(157)는 로봇의 자율 동작을 위한 동력을 제공하도록구비된다.또한 조도센서(160)는 외부 밝기를 감지하여 주변환경이 얼마나 밝거나 어두운 상태를 감지한다. [0079]상기 터치 센서(170)는 접촉을 통한 사용자 명령을 입력하기 위한 장치로 구비되며, 터치 센서(170)로부터 입력 [0080]되는 정보를 통해 사용자 입력명령을 인지할 수 있다.상기 스테레오 스피커(180)는 외부로 음성을 제공하며, 음성 신호를 전송하는 스피커 앰프(183)와 연결되어 있 [0081]다.상기 배터리(190)는 로봇의 동력원을 제공하도록 구비된다. [0082]그리고 무선통신을 위한 와이파이(Wi-Fi) 무선랜(191), USB 메모리, SD 카드(193), 주변 상황에 따른 자신의 상 [0083]태를 표현하는 LED(195)를 포함할 수 있다.도 4는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 소프트웨어 구성도이다. [0084]이하 도 4를 참조하여, 본 발명에서 제안하는 로봇 컴퓨터의 소프트웨어 구조도를 이용하여 설명한다. [0085]본 발명에서 소프트웨어는 장치 시스템 (Device Subsystem)(310), 통신 시스템 (Communication [0086]Subsystem)(320), 지각 시스템 (Perception Subsystem)(330), 지식처리 시스템(Knowledge ProcessingSubsystem)(340), 자율행위 시스템 (Autonomous Behavior Subsystem)(350), 작업수행 시스템 (TaskSystem)(360), 행위 시스템 (Behavior Subsystem)(370) 및 이벤트 처리 시스템 (Event Delivery System)(380)을 포함한다.장치 시스템(Device Subsystem)(310)은 에이전트 단말 측에 설치되며, 에이전트 단말의 센서 및 액츄에이터를 [0087]포함하는 물리적 하드웨어 장치를 소프트웨어적 논리장치로 추상화한 장치 모듈들로 구성된다. 공개특허 10-2012-0116134-10-그리고 본 실시예에 따른 장치 시스템(310)은 물리 장치로부터의 정보를 획득하여, 지각 시스템 모듈들로 전달 [0088]하거나 행위 시스템으로부터의 동작제어 정보를 받아 물리장치에 전달한다. 장치 시스템(310)은 카메라, 마이크로폰, 터치 센서, 조도센서 등의 센서장치 모듈(311)과 프로젝터, 스테레오 [0089]스피커, 모터, LED 등의 동작장치 모듈(313)을 포함한다. 통신 시스템(320)은 에이전트 단말과 본체 사이의 네트워크 통신을 담당하는 원격 객체 호출 방식의 통신 프레 [0090]임워크 기능을 수행한다.즉, 통신 시스템(320)은 클라이언트 프로그램에서 원격 객체에 대한 참조 (reference)를 얻고, 해당 객체가 마 [0091]치 클라이언트 자신의 객체인 것처럼 함수를 호출할 수 있도록 지원한다. 이를 위해 통신 시스템(320)은 클라이언트 측에서는 전달할 데이터를 이질적인 환경에 무관하도록 표준화된 방 [0092]식으로 묶어서(marshaling) 메시지를 전송하고, 서버 측에서는 전달된 메시지를 풀어서 (unmarshaling) 데이터를 얻고, 원격 객체를 활성화한 후 호출하고 그 결과를 다시 같은 방법으로 클라이언트 측에 전달하는 일련의작업들을 지원한다.지각 시스템(330)은 센서장치 모듈로부터 네트워크를 통해 전달된 정보를 기반으로 사용자 및 환경의 상황을 지 [0093]각하는 지각 모듈(331)을 포함한다.본 실시예에서 지각 시스템(330)은 카메라 센서 모듈로부터 전달된 이미지 정보로부터 자신의 주변에 움직임이 [0094]있는지 (움직임 검출, Motion Detection), 사람 얼굴이 있는지 (얼굴 검출, Face Detection), 그 사람이 누구인지 (얼굴 인식, Face Recognition), 사용자의 손가락이 어떤 위치에서 어떤 제스처로 움직이는지 (손가락 검출, Finger Tip Detection), 자기 앞에 자기가 알고 있는 물체가 있는지 (물체 인식, Object Detection) 등을인지한다. 또한, 본 실시예에서 지각 시스템(330)은 마이크로폰으로부터의 소리 정보로부터 어디에서 소리가 나는지 (음원 [0095]추적, Sound Source Localization), 어떤 말을 했는지 (음성 인식, Voice Recognition) 등을 인지한다. 그 밖에도 접촉센서로부터의 정보를 통해 사용자가 어떤 명령을 내렸는지를 인식하고, 조도센서로부터 주변환경이 얼마나 밝거나 어두운지를 인식한다. 그리고 센서 장치의 모듈의 연결관계는 영상이 획득될 때 움직임 검출, 물체 검출, 얼굴 검출 등이 활성화되며, [0096]얼굴 검출이 될 때, 얼굴 인식이 되는 동작을 수행한다.지식 처리 시스템(340)은 지각 모듈로부터의 정보를 상위 수준의 사용자 및 환경 지식으로 저장 관리하며, 응용 [0097]에서 관련 정보를 요청할 때 이를 제공하는 역할을 하며, 지식베이스 (Knowledge base)(343)와 지식 처리 프로세서(Knowledge Processor)(341)를 포함한다.지식베이스 (Knowledge base)(343)는 사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보 [0098](거실, 부엌, 침실 등), 환경 내 장치 정보 및 에이전트 상태 관련 정보 등이 온톨로지(Ontology)와 규칙을 기반으로 저장/관리된다. 이들 정보는 타 시스템 모듈이나 응용에서 관련 정보에 대한 질의 요청 시 지식 처리 프로세서(Knowledge Processor)(341)를 통해 그 정보를 제공한다. 자율행위 시스템(350)은 사용자가 로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정함 [0099]으로써, 그 상황에 맞는 관련 응용/서비스를 능동적으로 제공하는 역할을 하며, 사용자 행동패턴 학습엔진(351), 동기유발모듈(352) 및 자율행위선택 모듈(353)을 포함한다.사용자 행동패턴 학습엔진(351)은 누가 언제 어디에서 어떤 일을 수행했는지에 대한 정보를 축적하고 학습한다. [0100]동기유발모듈(352)에서는 자신이 어떤 시점에 어떤 일을 해야 하는지에 대한 동기(Drive)를 처리한다. 사람에게말을 건내고 싶다든지 (Social Drive), 쉬고 싶다든지 (Fatigue Drive) 등의 항목이 동기가 될 수 있다. 그리고 사용자 행동패턴 학습엔진(351)은 추정된 사용자의 현재 상태와 자신의 동기유발에 의해 작업 목표가 설 [0101]정되면, 자율행위선택 모듈(353)은 그 목표를 달성하기 위한 작업을 선택할 수 있다.또한, 강화학습엔진(355)은 사용자에 대한 자율행위를 사용자가 긍정적으로 받아들이는지를 부정적으로 받아들 [0102]이는지에 대한 피드백을 학습하여 점진적으로 진화해 가는 형태를 판단할 수 있다.또한, 작업 수행 시스템(360)은 로봇 컴퓨터의 전체 시스템의 동작을 제어하기 위한 모듈이며, 작업/응용 수행 [0103]엔진(361)과 작업모드 제어모듈(363)을 포함한다.공개특허 10-2012-0116134-11-로봇 컴퓨터는 모드(Mode)라고 하는 상태(State)를 기반으로 작업모드제어모듈(363)을 통해 제어된다. [0104]모드는 시스템 모드와 응용 모드로 구분할 수 있으며, 시스템 모드는 사용자의 요청에 의한 응용 실행이 없을 [0105]때, 시스템 내부적으로 수행되는 모드이며, 응용모드는 실제 응용이 수행될 때의 작업 모드 (Work Mode)로 정의할 수 있다.시스템 모드는 다시 수면 모드(Sleep Mode), 아이들 모드(Idle Mode), 관찰모드(Observation Mode), 대화 모드 [0106](Interaction Mode) 등으로 구분할 수 있다. 로봇 컴퓨터에 전원이 ON 되면, 아이들 모드(Idle Mode)로 들어오게 되며, 환경 내 어떤 변화가 있는지를 감지 [0107]하고 있는 상태이다. 아이들 모드(Idle Mode)는 영상에 의한 움직임 검출, 소리에 의한 음원 검출, 터치 센서등이 활성화되어 사용자나 환경에 어떤 변화가 있는지를 감지한다. 그리고 로봇 컴퓨터는 아이들 모드에서 작동시간이 경과하거나 수면모드에 대한 동기유발이 일어나면 [0108](A)(Timeexpired, Gotosleepcalled, Selfmotivated), 수면모드(Sleep Mode)로 진입한다.한편, 로봇 컴퓨터는 아이들 모드에 있다가 주변에 사람이 검출/인식되거나 자율행위의 동기유발이 일어나면 [0109](B)(Motiondetected, Sounddetected, Voicedetected, Touched, Selfmotivated), 관찰 모드(Observation Mode)로 진입한다. 관찰 모드는 어떤 사용자가 어디에 있는지를 지속적으로 관찰하고 있는 상태이다. 본 실시예에서 관찰 모드는 [0110]사람이 로봇 컴퓨터를 부르거나 또는 자신의 동기유발에 의해 사람에게 말을 걸고 싶을 때(C)(Usercallreceived, Selfmotivated), 대화 모드(Interaction Mode)로 진입한다. 로봇 컴퓨터는 대화 모드에서 시간이 경과하거나 자신의 동기유발이 일어나면(D)(Timeexpired, Selfmotivated) [0111]상기 아이들 모드로 진입한다.한편, 대화 모드는 사용자의 명령을 받아들이고 간단한 대화를 통해 사용자에게 응대한다. 대화 모드 동작 중에 [0112]사용자가 임의의 응용 수행을 명시적으로 요청하거나 자율행위의 동기유발에 의해 응용 수행을 추천하고 이를수락한 경우(E)(Usercommonreceived), 시스템 모드는 작업 모드(Work Mode)로 전환된다. 이 때는 시스템의 대부분 자원을 응용에게 할당할 수 있다.여기서 로봇 컴퓨터는수면 모드를 요청하거나 자율행위의 동기 유발이 일어나면(F)(Gotosleepcalled, [0113]Selfmotivated), 수면 모드로 진입한다.또한 로봇 컴퓨터는 작업 모드에서 수면모드를 요청하면(G)(Gotosleepcalled), 수면모드로 진입할 수 있다. [0114]다음으로 로봇 컴퓨터는 수면 모드에서 터치입력과 활성 동기유발이 일어나면(I)(Wakeuptouched, [0115]Selfmotivated) 아이들 모드로 진입할 수 있다.상기 행위 시스템(370)은 로봇 컴퓨터의 다양한 단위 행위를 관리하고 시스템이나 응용에서 요청 시 이를 수행 [0116]하는 역할을 수행하는 행위모듈(371)을 포함하며, 행위는 사용자 추적 관련 행위, 대화 관련 행위, 프로젝터/카메라 제어 관련 행위, 미디어 재생 관련 행위, 상태 표현 관련 행위들로 구성되며, 일반 개발자가 자신의 응용에 필요한 새로운 행위를 정의하여 활용할 수도 있다. 이벤트 처리 시스템(380)은 물리적으로 분산된 시스템들이 생성하는 다양한 이벤트를 관리하고, 각 시스템 모듈 [0117]들 간의 메시지 교환을 통한 정보 전달을 담당한다. 특히, 이벤트 처리 시스템(380)은 지각 시스템으로부터 전달되는 센싱 이벤트를 지식처리 시스템, 자율행위 시 [0118]스템 및 작업 수행 시스템에게 배포하여 상황변화를 인지할 수 있도록 하며, 상황 모델을 갱신하도록 한다. 또한 자율행위 시스템의 동기유발에 의한 자율행위 수행 이벤트를 작업 수행 시스템에 전달하여, 미리 프로그램되어 있지 않은 자율행위를 수행하도록 할 수 있다.도 5는 본 발명의 일실시예에 따른 지능형 로봇 특징을 갖는 휴대형 컴퓨터 장치의 동작 매커니즘을 설명한 도 [0119]면이다.이하 도 5를 참조하여, 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 동작 매커 [0120]니즘을 설명한다.도 5는 본 발명의 일실시예에 따른 지능형 로봇 특징을 갖는 휴대용 컴퓨터 장치의 동작 매커니즘을 설명한 도 [0121]공개특허 10-2012-0116134-12-면이다.처음 시스템 전원을 켜면, 아이들 모드(Idle Mode) 단계를 시작한다. (S410) S410 단계는, 환경 내 어떤 변화가 [0122]있는지를 감지하고 있는 상태이다. 영상에 의한 움직임 검출, 소리에 의한 음원 검출, 터치 센서 등이 활성화되어 사용자나 환경에 어떤 변화가 있는지를 감지한다. 다음으로, S410 단계에서, 주변에 사람이 검출/인식되거나 자율행위의 동기유발이 일어나면, 관찰모드 [0123](Observation Mode)로 진입한다. (S420)S420 단계의 관찰모드는 어떤 사용자가 어디에 있는지를 지속적으로 관찰하고 있는 상태이다. [0124]그리고 S420 단계에서, 사람이 로봇 컴퓨터를 부르거나 또는 자신의 동기유발에 의해 사람에게 말을 걸고 싶을 [0125]때, 대화모드(Interaction Mode)로 진입한다(S430). 대화 모드에서는 사용자의 명령을 받아들이고 간단한 대화를 통해 사용자에게 응대한다. S430 단계 중에 사용자가 임의의 응용 수행을 명시적으로 요청하거나 자율행위의 동기유발에 의해 응용 수행을 [0126]추천하고 이를 수락한 경우, 시스템 모드는 작업 모드(Work Mode)로 전환된다. (S440) S440 단계에서, 시스템의대부분 자원을 응용에게 넘겨주게 된다. 한편, S410 단계에서 일정 시간에 대한 환경 변화가 존재하지 않거나, S440 단계에서 작업 중지를 요청하면 수 [0127]면모드(Sleep Mode)로 전환된다. (S450)도 6은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치에 대한 처리 흐름도이다. [0128]이하, 도 6을 참조하여 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치에 대한 동작방법을 설명한다. [0129]우선, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 사용자 입력을 위한 프로젝터 화면을 제공한다(S510). [0130]S510 단계 이후, 휴대형 컴퓨터 장치는 프로젝터 화면상에 사용자 행동에 따른 입력 명령을 인식한다(S530). [0131]S530 단계에서 휴대형 컴퓨터 장치는 카메라 센서 모듈로부터 전달된 이미지 정보로부터 자신의 주변에 움직임 [0132]이 있는지 (움직임 검출, Motion Detection), 사람 얼굴이 있는지 (얼굴 검출, Face Detection), 그 사람이 누구인지 (얼굴 인식, Face Recognition), 사용자의 손가락이 어떤 위치에서 어떤 제스처로 움직이는지 (손가락검출, Finger Tip Detection), 자기 앞에 자기가 알고 있는 물체가 있는지 (물체 인식, Object Detection) 등을 인지한다. 또한, 휴대형 컴퓨터 장치는 소리 정보로부터 어디에서 소리가 나는지 (음원 추적, Sound Source [0133]Localization), 어떤 말을 했는지 (음성 인식, Voice Recognition) 등을 인지한다. 그 밖에도 접촉센서로부터의 정보를 통해 사용자가 어떤 명령을 내렸는지를 인식하고, 조도센서로부터 주변환경이 얼마나 밝거나 어두운지를 인식한다. 그리고 휴대형 컴퓨터 장치는 영상이 획득될 때 움직임 검출, 물체 검출, 얼굴 검출 등이 활성화되며, 얼굴 검 [0134]출이 될 때, 얼굴 인식이 되는 동작을 수행한다.S530 단계에서 휴대형 컴퓨터 장치는 사용자 행동에 따른 입력 명령을 인식한 후, 입력 명령에 따른 서비스와 [0135]콘텐츠를 출력한다. (S550)S530 단계에서 휴대형 컴퓨터 장치는 입력 명령에 따른 서비스와 콘텐츠뿐만 아니라 물체 인식, 소리 정보, 접 [0136]촉센서로 통해 입력된 명령 등에 따른 서비스와 콘텐츠를 검색하고 출력할 수 있다.구체적으로 휴대형 컴퓨터 장치가 \"스팸(SPAM)\"에 대한 물체를 인식하는 경우, 이에 따른 추천요리, 소비자 취 [0137]향 등에 대한 정보를 프로젝터를 통해 출력할 수 있다.또한, 휴대형 컴퓨터 장치는 스팸에 대한 검색기능을 제공할 수 있다. [0138]도 7은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 사용자 이동에 따른 위치 [0139]보정에 대한 처리 흐름도이다.이하 도 7을 참조하여 사용자 이동에 따른 위치 보정에 대한 처리 방법을 설명한다. [0140]공개특허 10-2012-0116134-13-휴대형 컴퓨터 장치는 사용자의 이동상태를 감지하고,(S610), 이동 여부를 판단한다. (S620) [0141]S620 단계에서, 사용자가 이동하는 경우, 상기 휴대형 컴퓨터 장치는 영상을 획득하기 위해 위치를 보정한다. [0142](S630)S630 단계에서 휴대형 컴퓨터 장치는 위치 보정을 통한 영상정보를 획득하고, 사용자의 행동에 따른 입력 명령 [0143]을 인식한다. (S640).본 발명은 본 발명의 정신 및 필수적 특징을 벗어나지 않는 범위에서 다른 특정한 형태로 구체화될 수 있다. 따 [0144]라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가 적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다. 또한, 특허청구범위에서 명시적인 인용 관계가 있지 않은 청구항들을 결합하여 실시예를 구성하거나 출원 후의 보정에 의해 새로운 청구항으로 포함할 수 있다.산업상 이용가능성본 발명의 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치 및 그 동작 방법은, 주변 환경과 인터랙션 하여 사람을 [0145]찾고, 사용자를 인식하고, 얼굴을 따라다니며, 필요 시 대화할 수 있는 로봇 컴퓨터 등에 적용할 수 있으며, 이에 따라 인공지능이 부가된 로봇 기술 분야에는 어디든 적용가능하다.부호의 설명10 : 본체 [0146]110 : 프로젝터 120 : 카메라130 : 메인보드 140 : 마이크로폰150 : 5 모터 160 : 조도센서170 : 터치센서 180 : 스테레오 스피커190 : 배터리도면도면1공개특허 10-2012-0116134-14-도면2도면3공개특허 10-2012-0116134-15-도면4도면5공개특허 10-2012-0116134-16-도면6도면7공개특허 10-2012-0116134-17-"}
{"patent_id": "10-2011-0033700", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는, 사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하고, 상기 유저 인터페이스화면상에 사용자 행동을 촬영하는 카메라가 장착되는 입력프 로젝터, 사용자 행동에 따른 사용자 명령을 인식하고, 사용자 명령에 따른 서비스와 콘텐츠를 생성하는 메인보드 및 생성된 콘텐츠를 출력하는 출력프로젝터를 포함한다."}
{"patent_id": "10-2011-0033700", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치 및 그 동작 방법에 관한 것으로서, 더욱 상세하게는 프 로젝터, 카메라, 마이크로폰, 터치 센서 등의 입출력 장치와 사용자 음성, 제스처 및 터치 기반의 멀티모달 인 터렉션을 제공하여 보다 향상된 사용자 입출력과 지능화된 기능을 제공하는 지능형 로봇 특성을 갖는 휴대형 컴 퓨터 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2011-0033700", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 네트워크, 컴퓨터, 통신 및 가전 등의 융복합 화와 개인화, 지능화 등의 추세에 따라 우리 생활 환경에는 기존의 PC(Personal Computer)와는 다른 형태의 새로운 컴퓨터 장치가 나타나고 있다. 일반적으로 컴퓨터는 키보드, 마우스, 화면 등으로 구비되어 입력에 의한 명령을 연산 처리하는 기능을 수행하 였으나, 최근에는 터치 패널, 카메라, 프로젝트 화면 등 사용자 명령을 입력하고 표시하는 다양한 인터페이스가 결합한 사용자 중심의 컴퓨터 제품이 빠르게 등장하고 있다. 애플(APPLE)은 태블릿 컴퓨터 형태의 9.7인치 IPS 패널에 멀티 터치 스크린을 이용한 휴대용 멀티미디어 단말을 출시하였으며, Microsoft는 직접 손으로 디지털 정보를 조작할 수 있는 Surface Computing Project와 테이블 탑이라는 개념의 컴퓨터를 출시하였다. 또한, Microsoft는 최근 카메라와 센서 장치를 이용하여 사용자의 움직임, 제스처 및 음성인식을 통해 사용자의 명령을 인식하는 인터페이스 장치를 개발하였다. 그리고 MIT Media Lab은 프로젝터를 화면과 카메라를 이용한 Sixth Sense와 LuminAr을 개발하였다."}
{"patent_id": "10-2011-0033700", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명에서는 좀 더 진일보한 기능, 다양한 센서와 장치로 구성되어 지능형 개인 서비스 로봇의 특성 을 갖는 새로운 형태의 컴퓨터 장치로서 카메라/프로젝터를 이용한 입출력 인터랙션, 영상/음성/터치 등 다중 센서를 이용한 사용자 지각 (Perception) 기능, 사용자 및 환경 상황인지 및 사용자와의 지속 적 관계를 이용한 성장 및 자율행위 기능을 제공하는 데에 그 목적이 있다. 또한, 본 발명은 상기한 바와 같이 다양한 센서와 장치로 구성되어 지능형 개인 서비스 로봇의 특성을 갖는 새 로운 형태의 컴퓨터 장치에 관한 것으로서, 프로젝터, 카메라, 마이크로폰, 터치센서 기반의 입출력 장치와 사 용자 음성, 제스처, 터치 기반의 멀티모달 인터랙션을 제공함으로써 더욱 자연스러운 사용자 입출력을 제공하는 데에 그 목적이 있다. 또한, 본 발명의 다른 목적은 사용자 위치를 인식하고, 사용자 얼굴을 인식하고 추적하며, 주변 소리에 반응하 는 데에 있다. 또한, 본 발명의 다른 목적은 사용자가 있는 위치에서 활성화된 기기들을 감지하고, 네트워크를 통해 그 기기를 동적으로 연결하는 데에 있다. 또한, 본 발명의 다른 목적은 누가, 언제, 어디서 어떤 작업을 수행했는지에 대한 정보를 구축하여 사용자의 장 치 활용패턴을 학습함으로써, 사용자에게 보다 능동적인 서비스를 제공하는 데에 있다."}
{"patent_id": "10-2011-0033700", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 사용자 입력을 위한 유저 인터페이스 (User Interface) 화면을 제공하고, 상기 유저 인터페이스 화면 상에 사용자 행동을 촬영하는 카메라가 장착되 는 입력 프로젝터와, 상기 사용자 행동에 따른 사용자 음성 및 제스처 명령을 인식하고, 상기 사용자 명령에 따 른 서비스와 콘텐츠를 생성하도록 제어하는 메인보드 및 상기 생성된 콘텐츠를 출력하는 출력 프로젝터를 포함 할 수 있다. 상기 출력프로젝터는, 상기 사용자 행동을 추적하는 카메라가 장착되는 것이 바람직하다. 바람직하게, 상기 메인보드는, 상기 유저 인터페이스 화면상에 손가락 제스처에 따른 사용자 명령을 인식하고, 상기 사용자 명령에 따른 서비스와 콘텐츠를 생성하도록 제어할 수 있다. 바람직하게, 상기 메인보드는, 상기 카메라로부터 이미지 정보를 수신하여 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 검출, 물체 정보를 인지하도록 제어할 수 있다. 바람직하게, 사용자 음성을 입력받는 마이크로폰을 더 포함하되, 상기 메인보드는, 상기 사용자 음성에 따른 사 용자 정보 및 사용자 명령을 인식하도록 제어할 수 있다. 바람직하게, 상기 메인보드는, 상기 사용자 명령을 수신하는 센서 정보는 네트워크로 연결된 서버에 전송하고, 상기 서버로부터 인지 프로세싱을 수행하며, 그 결과에 따른 서비스와 콘텐츠를 수신할 수 있다. 바람직하게, 상기 프로젝터와 상기 카메라의 하단에 구비되어 수직 회전하는 수직운동모터와, 상기 수직운동모 터의 하단에 구비되어 상기 프로젝터와 상기 카메라의 수평 회전하는 하는 수평운동모터 및 상기 수평운동모터 의 하단에 구비되어 상기 프로젝터와 상기 카메라 전체를 회전하는 전체회전모터를 포함할 수 있다. 바람직하게, 상기 프로젝터의 하단에 카메라를 각각 장착할 수 있다. 바람직하게, 사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보, 환경 내 장치 정보, 에이 전트 상태 관련 정보를 온톨로지(Ontology) 기반으로 저장하는 지식베이스를 포함하되, 상기 메인보드는 질의 요청 시 상기 정보를 제공하도록 제어할 수 있다. 바람직하게, 상기 메인보드는, 로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정하여 상기 현재 상태에 맞는 관련 서비스와 콘텐츠를 능동적으로 추천할 수 있다. 본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법은 유저 인터페이스화면, 서비스 및 콘텐츠 출력을 위한 화면을 제공하는 프로젝터 화면 제공단계와, 상기 유저 인터페이스 화면 상에 사용자 행동 에 따른 사용자 명령을 인식하는 사용자 명령인식단계 및 상기 사용자 명령에 따른 서비스와 콘텐츠를 출력하는 프로젝터 화면 출력 단계를 포함한다. 바람직하게, 본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 작동방법은 상기 사용자 행동을 추적하는 사용자 추적단계를 포함할 수 있다. 바람직하게, 본 발명의 실시 예에 따른 지능형 로봇 특성을 휴대형 컴퓨터 작동방법은 상기 사용자의 이동상태 를 감지하는 이동상태 감지단계와 상기 사용자의 이동에 따른 위치를 보정하는 위치보정단계를 포함할 수 있다. 바람직하게, 상기 카메라로부터 이미지 정보를 수신하여 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 검출, 물체 정보를 인지하는 이미지 정보 인지단계를 포함할 수 있다. 바람직하게, 사용자 음성에 따른 사용자 정보 및 사용자 명령을 인식하는 음성인식단계를 포함할 수 있다. 바람직하게, 상기 사용자 명령을 수신하는 센서 정보는 네트워크로 연결된 서버로 전송하고, 상기 서버로부터 인지 프로세싱을 수행하며, 그 결과에 따른 서비스와 콘텐츠를 수신하는 데이터 송수신단계를 포함할 수 있다. 바람직하게, 사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보, 환경 내 장치 정보, 에이 전트 상태 관련 정보를 온톨로지(Ontology) 기반으로 저장하는 지식베이스 저장단계와, 질의 요청 시 상기 정보 를 제공하는 정보제공단계를 포함할 수 있다. 바람직하게, 로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정하여 상기 현재 상태에 맞는 관련 응용/서비스를 능동적으로 제공하는 행동패턴 학습단계를 포함할 수 있다."}
{"patent_id": "10-2011-0033700", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 다음과 같은 효과가 있다. 첫째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 주변 환경과 인터랙션하고 있으며, 특히 사람을 찾고, 사 용자가 누구인지를 인식보고, 얼굴을 추적하며, 필요 시 인터랙션 기능을 수행하여 사용자 명령을 수행한다. 둘째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 언제 어디서나 컴퓨팅 환경을 제공한다. 즉 프로젝터를 이용하여 거실, 주방, 책상 등 어떤 공간이든 Table Top 형태의 입출력 환경을 제공하고 사용자는 손가락 제스 처, 음성 또는 터치 등을 이용하여 컴퓨터와 인터랙션할 수 있다. 셋째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 사용자의 명시적 요청뿐만 아니라 사용자와 물리환경의 상황을 이해하여 이에 맞게 서비스를 제공한다. 넷째, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 물리세계와 가상세계를 연결하는 역할을 한다. 즉 카메라 를 통해 실제 사물을 인식하고, 그 사물에 대한 정보를 가상공간상으로부터 얻어와 프로젝터를 이용해 이를 투 영함으로써 물리적 사물에 디지털 정보를 증강할 수 있다."}
{"patent_id": "10-2011-0033700", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 실시예들은 본 발명의 구성요소들과 특징들을 소정 형태로 결합한 것들이다. 각 구성요소 또는 특징은 별도의 명시적 언급이 없는 한 선택적인 것으로 고려될 수 있다. 각 구성요소 또는 특징은 다른 구성요소나 특 징과 결합하지 않은 형태로 실시될 수 있다. 또한, 일부 구성요소들 및/또는 특징들을 결합하여 본 발명의 실시 예를 구성할 수도 있다. 본 발명의 실시예들에서 설명되는 동작들의 순서는 변경될 수 있다. 어느 실시예의 일 부 구성이나 특징은 다른 실시예에 포함될 수 있고, 또는 다른 실시예의 대응하는 구성 또는 특징과 교체될 수 있다. 본 발명의 실시예들은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 발명의 실시예들은 하드웨어, 펌웨어 (firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 하나 또는 그 이상의 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서, 콘트롤러, 마이크로 콘트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 이상에서 설명된 기능 또는 동작 들을 수행하는 모듈, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리 유닛에 저장되어 프로세서에 의해 구동될 수 있다. 상기 메모리 유닛은 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 상기 프로세서와 데이터를 주고 받을 수 있다. 이하의 설명에서 사용되는 특정(特定) 용어들은 본 발명의 이해를 돕기 위해서 제공된 것이며, 이러한 특정 용 어의 사용은 본 발명의 기술적 사상을 벗어나지 않는 범위에서 다른 형태로 변경될 수 있다. 이하, 첨부된 도면들을 참조하여, 본 발명에 따른 실시예들에 대하여 상세하게 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 로봇 컴퓨터를 도시한 블록도이다. 이하 도1을 참조하여 설명을 개시한다. 본 발명에서 제안하는 로봇 컴퓨터는 본체 (Control Unit)와 에이전트 단말(Agent Unit)로 구성된다. 본체는 중앙처리장치이며, 단말의 Brain Server 역할을 한다. 본체 (Control Unit)은 미래의 우리 생활환경 이 스마트 공간이 된다는 점을 고려하여, 그 공간 내 자원 또는 장치를 관리하는 서버 (예: 홈서버, IPTV 세탑 박스 등)에 연결된다. 에이전트 단말 (Agent Unit)은 사용자가 들고 어디든지 이동할 수 있는 단말로서, 본체와 네트워크로 연결되며, 사용자와의 인터랙션을 담당한다. 이하에서는 그 언급을 생략하겠으나, 본 발명에 따른 네트워크는 본체와 에이전트 단말을 연계하고, TCP/IP 프로토클의 유선 인터넷 망, 왑(WAP) 프로토콜의 무선 인터넷망 및 유/무선통신망 등을 이용하여 구축할수 있다. 도 2는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 도면이다. 도 3은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 블록도이다. 이하 도 2 및 도 3을 참조하여 설명을 개시한다. 도2를 참조하면, 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 에이전트 단말에 관한 것으로서 프로젝터, 카메라, 메인보드, 마이크로폰, 5 모터, 조도센서, 터치패드, 스테레오 스피커 및 배터리를 포함한다. 프로젝터는 유저인터페이스(user interface)화면, 서비스 및 콘텐츠 화면을 제공하며, 유저인터페이스 화 면은 GUI(Graphic User Interface) 기반으로 제공되거나 입체영상 방식의 3D 영상 등을 채용할 수 있다. 그리고 프로젝터는 사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하고, 사용자 행동을 촬영하는 카메라를 장착할 수 있다. 본 발명의 실시예에 따른 프로젝터는 사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하 는 입력 프로젝트와 상기 생성된 콘텐츠를 출력하는 출력 프로젝터로 분리할 수 있다. 또한, 입력프로젝터는 사용자 입력을 위한 유저 인터페이스(User Interface) 화면을 제공하고, 유저 인터 페이스 화면상에 사용자 행동을 촬영하는 카메라를 장착할 수 있다. 그리고 상기 출력프로젝터는 사용자 행동을 추적하는 카메라를 장착할 수 있다. 또한 프로젝터는 입력/출력 프로젝터(111,113)로 분리하였으나, 일체형으로 구비되어 입력/출력 화면을 일 체형으로 구비할 수 있다. 그리고 프로젝터는 프로젝트/카메라 2쌍으로 구비될 수 있으며, 입력/출력 프로젝터(111,113)의 하단에 각 각 장착될 수 있다. 구체적으로 도 2를 참조하면, 입력/출력 프로젝터(111,113)로 분리된 2개의 프로젝트가 구비되고, 각각의 프로 젝트의 하단에 카메라가 장착된다. 그리고 카메라의 위치는 프로젝터의 하단에 장착되는 것으로 설정하였으나, 측면 등에 구비되는 구조 로 변경할 수 있다. 또한, 프로젝터로 출력된 GUI 화면에 손가락 제스처(Gesture)를 이용한 사용자 명령으로 인터랙션 하며, 입력 프로젝터에 하단에 부착된 카메라는 출력된 GUI 화면과 손가락 제스처를 인식한다. 여기서, 입력 프로젝터/카메라 한 쌍이 바닥면에 GUI 화면을 제공할 때 또 다른 한 쌍의 출력 프로젝 터는 벽면에 콘텐츠 화면을 제공할 수 있다. 상기 프로젝트는 FPGA(field programmable gate array)를 이용하여 데이터를 전송하는 것으로 설정할 수 있으나, 이에 한정된 것은 아니다. 또한, 카메라는 손가락 제스처(Gesture)를 감지하기 위한 입력장치로 구비될 수 있으며, 상황에 따라 사용 자 인식, 장소, 주변의 사물인식 등을 위한 입력장치로 사용될 수 있다. 그리고 카메라는 주변 움직임 검출, 얼굴 검출, 얼굴 인식, 손가락 검출 및 물체 인식 등을 인지하기 위한 이미지 정보를 생성할 수 있다. 본 실시예에 따른 이미지 정보는 자신의 주변에 움직임이 있는지 (움직임 검출, Motion Detection), 사람 얼굴 이 있는지 (얼굴 검출, Face Detection), 그 사람이 누구인지 (얼굴 인식, Face Recognition), 사용자의 손가 락이 어떤 위치에서 어떤 제스처로 움직이는지 (손가락 검출, Finger Tip Detection), 자기 앞에 자기가 알고 있는 물체가 있는지 (물체 인식, Object Detection) 등을 인지하도록 제공된다. 또한, 카메라는 USB(Universal Serial Bus)로 착탈 가능하게 구비될 수 있으며, 다양하게 변경할 수 있다. 또한, 메인보드는 프로젝터와 카메라를 연결/제어하며, 네트워크로 연결된 본체와 통신하도록 네트워크를 제어한다. 여기서 네트워크는 에이전트 단말과 본체 사이의 네트워크 통신을 담당하는 원격 객체 호출 방식이며, 즉, 클라 이언트 프로그램에서 원격 객체에 대한 참조 (reference)를 얻고, 그 객체가 마치 클라이언트 자신의 객체인 것처럼 함수를 호출할 수 있도록 지원한다. 이를 위해 본 실시예에 따른 네트워크는 클라이언트 측에서는 전달할 데이터를 이질적인 환경에 무관하도록 표 준화된 방식으로 묶어서(marshaling) 메시지를 전송하고, 서버 측에서는 전달된 메시지를 풀어서 (unmarshaling) 데이터를 얻고, 원격 객체를 활성화한 후 호출하고 그 결과를 다시 같은 방법으로 클라이언트 측에 전달하는 일련의 작업들을 지원한다. 또한 메인보드는 주제어보드(Main Control Board)와 각종센서, 모터, LED 등의 주변장치를 연결하는 주변장치제어보드(Peripheral Device Controller)를 포함할 수 있다. 주제어보드는 프로세서, 메모리, 하드디스크, 그래픽처리기, USB포트, 통신모뎀, BUS 등을 포함하여, 지능 형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 프로세싱(processing) 제어 기능을 수행한다. 그리고 메인보드는 음성인식, 합성 및 사운드 재생 등을 위한 음성처리를 수행하는 사운드제어보드(Sound Control Board)를 포함할 수 있다. 또한, 메인보드는 하나의 주제어보드에서 모두 처리할 수 있으며, 제어보드로 추가하여 확장할 수 있다. 구체적으로, 본 실시예에 따른 메인보드는 사운드제어보드의 기능을 주제어보드에서 그 역할을 대체할 수 있으며, 또한 영상처리보드를 별도로 구비할 수 있다. 또한, 마이크로폰은 음성을 통한 사용자 정보와 사용자 명령이 입력된다. 입력된 음성을 포함하는 소리 정보는 어디에서 소리가 나는지 (음원 추적, Sound Source Localization), 어떤 말을 했는지 (음성 인식, Voice Recognition) 등을 인지하도록 제공된다. 상기 5 모터는 상기 프로젝터, 카메라 및 로봇동작을 위한 동력을 제공한다. 구체적으로 상기 5 모터는 수직운동모터, 수평운동모터, 전체회전운동모터 및 다리회전모 터를 포함한다. 여기서 수직운동모터는 프로젝터와 카메라의 하단에 구비되어 수직 회전 동력을 제공하고, 상기 수평운동모터는 상기 수직운동모터의 하단에 구비되어 프로젝터와 카메라의 수평 회전 동 력을 제공하고, 상기 전체회전운동모터는 상기 수평운동모터의 하단에 구비되어 프로젝터와 카 메라 전체 회전 동력을 제공하고, 상기 다리회전모터는 로봇의 자율 동작을 위한 동력을 제공하도록 구비된다. 또한 조도센서는 외부 밝기를 감지하여 주변환경이 얼마나 밝거나 어두운 상태를 감지한다. 상기 터치 센서는 접촉을 통한 사용자 명령을 입력하기 위한 장치로 구비되며, 터치 센서로부터 입력 되는 정보를 통해 사용자 입력명령을 인지할 수 있다. 상기 스테레오 스피커는 외부로 음성을 제공하며, 음성 신호를 전송하는 스피커 앰프와 연결되어 있 다. 상기 배터리는 로봇의 동력원을 제공하도록 구비된다. 그리고 무선통신을 위한 와이파이(Wi-Fi) 무선랜, USB 메모리, SD 카드, 주변 상황에 따른 자신의 상 태를 표현하는 LED를 포함할 수 있다. 도 4는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 소프트웨어 구성도이다. 이하 도 4를 참조하여, 본 발명에서 제안하는 로봇 컴퓨터의 소프트웨어 구조도를 이용하여 설명한다. 본 발명에서 소프트웨어는 장치 시스템 (Device Subsystem), 통신 시스템 (Communication Subsystem), 지각 시스템 (Perception Subsystem), 지식처리 시스템(Knowledge Processing Subsystem), 자율행위 시스템 (Autonomous Behavior Subsystem), 작업수행 시스템 (Task System), 행위 시스템 (Behavior Subsystem) 및 이벤트 처리 시스템 (Event Delivery System) 을 포함한다. 장치 시스템(Device Subsystem)은 에이전트 단말 측에 설치되며, 에이전트 단말의 센서 및 액츄에이터를 포함하는 물리적 하드웨어 장치를 소프트웨어적 논리장치로 추상화한 장치 모듈들로 구성된다. 그리고 본 실시예에 따른 장치 시스템은 물리 장치로부터의 정보를 획득하여, 지각 시스템 모듈들로 전달 하거나 행위 시스템으로부터의 동작제어 정보를 받아 물리장치에 전달한다. 장치 시스템은 카메라, 마이크로폰, 터치 센서, 조도센서 등의 센서장치 모듈과 프로젝터, 스테레오 스피커, 모터, LED 등의 동작장치 모듈을 포함한다. 통신 시스템은 에이전트 단말과 본체 사이의 네트워크 통신을 담당하는 원격 객체 호출 방식의 통신 프레 임워크 기능을 수행한다. 즉, 통신 시스템은 클라이언트 프로그램에서 원격 객체에 대한 참조 (reference)를 얻고, 해당 객체가 마 치 클라이언트 자신의 객체인 것처럼 함수를 호출할 수 있도록 지원한다. 이를 위해 통신 시스템은 클라이언트 측에서는 전달할 데이터를 이질적인 환경에 무관하도록 표준화된 방 식으로 묶어서(marshaling) 메시지를 전송하고, 서버 측에서는 전달된 메시지를 풀어서 (unmarshaling) 데이터 를 얻고, 원격 객체를 활성화한 후 호출하고 그 결과를 다시 같은 방법으로 클라이언트 측에 전달하는 일련의 작업들을 지원한다. 지각 시스템은 센서장치 모듈로부터 네트워크를 통해 전달된 정보를 기반으로 사용자 및 환경의 상황을 지 각하는 지각 모듈을 포함한다. 본 실시예에서 지각 시스템은 카메라 센서 모듈로부터 전달된 이미지 정보로부터 자신의 주변에 움직임이 있는지 (움직임 검출, Motion Detection), 사람 얼굴이 있는지 (얼굴 검출, Face Detection), 그 사람이 누구 인지 (얼굴 인식, Face Recognition), 사용자의 손가락이 어떤 위치에서 어떤 제스처로 움직이는지 (손가락 검 출, Finger Tip Detection), 자기 앞에 자기가 알고 있는 물체가 있는지 (물체 인식, Object Detection) 등을 인지한다. 또한, 본 실시예에서 지각 시스템은 마이크로폰으로부터의 소리 정보로부터 어디에서 소리가 나는지 (음원 추적, Sound Source Localization), 어떤 말을 했는지 (음성 인식, Voice Recognition) 등을 인지한다. 그 밖 에도 접촉센서로부터의 정보를 통해 사용자가 어떤 명령을 내렸는지를 인식하고, 조도센서로부터 주변환경이 얼 마나 밝거나 어두운지를 인식한다. 그리고 센서 장치의 모듈의 연결관계는 영상이 획득될 때 움직임 검출, 물체 검출, 얼굴 검출 등이 활성화되며, 얼굴 검출이 될 때, 얼굴 인식이 되는 동작을 수행한다. 지식 처리 시스템은 지각 모듈로부터의 정보를 상위 수준의 사용자 및 환경 지식으로 저장 관리하며, 응용 에서 관련 정보를 요청할 때 이를 제공하는 역할을 하며, 지식베이스 (Knowledge base)와 지식 처리 프로 세서(Knowledge Processor)를 포함한다. 지식베이스 (Knowledge base)는 사용자에 대한 기본적인 정보, 공간에 대한 기하학적 정보 및 의미 정보 (거실, 부엌, 침실 등), 환경 내 장치 정보 및 에이전트 상태 관련 정보 등이 온톨로지(Ontology)와 규칙을 기 반으로 저장/관리된다. 이들 정보는 타 시스템 모듈이나 응용에서 관련 정보에 대한 질의 요청 시 지식 처리 프 로세서(Knowledge Processor)를 통해 그 정보를 제공한다. 자율행위 시스템은 사용자가 로봇 컴퓨터를 활용하는 행동패턴을 학습하고, 사용자의 현재 상태를 추정함 으로써, 그 상황에 맞는 관련 응용/서비스를 능동적으로 제공하는 역할을 하며, 사용자 행동패턴 학습엔진 , 동기유발모듈 및 자율행위선택 모듈을 포함한다. 사용자 행동패턴 학습엔진은 누가 언제 어디에서 어떤 일을 수행했는지에 대한 정보를 축적하고 학습한다. 동기유발모듈에서는 자신이 어떤 시점에 어떤 일을 해야 하는지에 대한 동기(Drive)를 처리한다. 사람에게 말을 건내고 싶다든지 (Social Drive), 쉬고 싶다든지 (Fatigue Drive) 등의 항목이 동기가 될 수 있다. 그리고 사용자 행동패턴 학습엔진은 추정된 사용자의 현재 상태와 자신의 동기유발에 의해 작업 목표가 설 정되면, 자율행위선택 모듈은 그 목표를 달성하기 위한 작업을 선택할 수 있다. 또한, 강화학습엔진은 사용자에 대한 자율행위를 사용자가 긍정적으로 받아들이는지를 부정적으로 받아들 이는지에 대한 피드백을 학습하여 점진적으로 진화해 가는 형태를 판단할 수 있다. 또한, 작업 수행 시스템은 로봇 컴퓨터의 전체 시스템의 동작을 제어하기 위한 모듈이며, 작업/응용 수행 엔진과 작업모드 제어모듈을 포함한다.로봇 컴퓨터는 모드(Mode)라고 하는 상태(State)를 기반으로 작업모드제어모듈을 통해 제어된다. 모드는 시스템 모드와 응용 모드로 구분할 수 있으며, 시스템 모드는 사용자의 요청에 의한 응용 실행이 없을 때, 시스템 내부적으로 수행되는 모드이며, 응용모드는 실제 응용이 수행될 때의 작업 모드 (Work Mode)로 정의 할 수 있다. 시스템 모드는 다시 수면 모드(Sleep Mode), 아이들 모드(Idle Mode), 관찰모드(Observation Mode), 대화 모드 (Interaction Mode) 등으로 구분할 수 있다. 로봇 컴퓨터에 전원이 ON 되면, 아이들 모드(Idle Mode)로 들어오게 되며, 환경 내 어떤 변화가 있는지를 감지 하고 있는 상태이다. 아이들 모드(Idle Mode)는 영상에 의한 움직임 검출, 소리에 의한 음원 검출, 터치 센서 등이 활성화되어 사용자나 환경에 어떤 변화가 있는지를 감지한다. 그리고 로봇 컴퓨터는 아이들 모드에서 작동시간이 경과하거나 수면모드에 대한 동기유발이 일어나면 (A)(Timeexpired, Gotosleepcalled, Selfmotivated), 수면모드(Sleep Mode)로 진입한다. 한편, 로봇 컴퓨터는 아이들 모드에 있다가 주변에 사람이 검출/인식되거나 자율행위의 동기유발이 일어나면 (B)(Motiondetected, Sounddetected, Voicedetected, Touched, Selfmotivated), 관찰 모드(Observation Mod e)로 진입한다. 관찰 모드는 어떤 사용자가 어디에 있는지를 지속적으로 관찰하고 있는 상태이다. 본 실시예에서 관찰 모드는 사람이 로봇 컴퓨터를 부르거나 또는 자신의 동기유발에 의해 사람에게 말을 걸고 싶을 때 (C)(Usercallreceived, Selfmotivated), 대화 모드(Interaction Mode)로 진입한다. 로봇 컴퓨터는 대화 모드에서 시간이 경과하거나 자신의 동기유발이 일어나면(D)(Timeexpired, Selfmotivated) 상기 아이들 모드로 진입한다. 한편, 대화 모드는 사용자의 명령을 받아들이고 간단한 대화를 통해 사용자에게 응대한다. 대화 모드 동작 중에 사용자가 임의의 응용 수행을 명시적으로 요청하거나 자율행위의 동기유발에 의해 응용 수행을 추천하고 이를 수락한 경우(E)(Usercommonreceived), 시스템 모드는 작업 모드(Work Mode)로 전환된다. 이 때는 시스템의 대 부분 자원을 응용에게 할당할 수 있다. 여기서 로봇 컴퓨터는수면 모드를 요청하거나 자율행위의 동기 유발이 일어나면(F)(Gotosleepcalled, Selfmotivated), 수면 모드로 진입한다. 또한 로봇 컴퓨터는 작업 모드에서 수면모드를 요청하면(G)(Gotosleepcalled), 수면모드로 진입할 수 있다. 다음으로 로봇 컴퓨터는 수면 모드에서 터치입력과 활성 동기유발이 일어나면(I)(Wakeuptouched, Selfmotivated) 아이들 모드로 진입할 수 있다. 상기 행위 시스템은 로봇 컴퓨터의 다양한 단위 행위를 관리하고 시스템이나 응용에서 요청 시 이를 수행 하는 역할을 수행하는 행위모듈을 포함하며, 행위는 사용자 추적 관련 행위, 대화 관련 행위, 프로젝터/카 메라 제어 관련 행위, 미디어 재생 관련 행위, 상태 표현 관련 행위들로 구성되며, 일반 개발자가 자신의 응용 에 필요한 새로운 행위를 정의하여 활용할 수도 있다. 이벤트 처리 시스템은 물리적으로 분산된 시스템들이 생성하는 다양한 이벤트를 관리하고, 각 시스템 모듈 들 간의 메시지 교환을 통한 정보 전달을 담당한다. 특히, 이벤트 처리 시스템은 지각 시스템으로부터 전달되는 센싱 이벤트를 지식처리 시스템, 자율행위 시 스템 및 작업 수행 시스템에게 배포하여 상황변화를 인지할 수 있도록 하며, 상황 모델을 갱신하도록 한다. 또 한 자율행위 시스템의 동기유발에 의한 자율행위 수행 이벤트를 작업 수행 시스템에 전달하여, 미리 프로그램되 어 있지 않은 자율행위를 수행하도록 할 수 있다. 도 5는 본 발명의 일실시예에 따른 지능형 로봇 특징을 갖는 휴대형 컴퓨터 장치의 동작 매커니즘을 설명한 도 면이다. 이하 도 5를 참조하여, 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 동작 매커 니즘을 설명한다. 도 5는 본 발명의 일실시예에 따른 지능형 로봇 특징을 갖는 휴대용 컴퓨터 장치의 동작 매커니즘을 설명한 도 면이다. 처음 시스템 전원을 켜면, 아이들 모드(Idle Mode) 단계를 시작한다. (S410) S410 단계는, 환경 내 어떤 변화가 있는지를 감지하고 있는 상태이다. 영상에 의한 움직임 검출, 소리에 의한 음원 검출, 터치 센서 등이 활성화되 어 사용자나 환경에 어떤 변화가 있는지를 감지한다. 다음으로, S410 단계에서, 주변에 사람이 검출/인식되거나 자율행위의 동기유발이 일어나면, 관찰모드 (Observation Mode)로 진입한다. (S420) S420 단계의 관찰모드는 어떤 사용자가 어디에 있는지를 지속적으로 관찰하고 있는 상태이다. 그리고 S420 단계에서, 사람이 로봇 컴퓨터를 부르거나 또는 자신의 동기유발에 의해 사람에게 말을 걸고 싶을 때, 대화모드(Interaction Mode)로 진입한다(S430). 대화 모드에서는 사용자의 명령을 받아들이고 간단한 대화 를 통해 사용자에게 응대한다. S430 단계 중에 사용자가 임의의 응용 수행을 명시적으로 요청하거나 자율행위의 동기유발에 의해 응용 수행을 추천하고 이를 수락한 경우, 시스템 모드는 작업 모드(Work Mode)로 전환된다. (S440) S440 단계에서, 시스템의 대부분 자원을 응용에게 넘겨주게 된다. 한편, S410 단계에서 일정 시간에 대한 환경 변화가 존재하지 않거나, S440 단계에서 작업 중지를 요청하면 수 면모드(Sleep Mode)로 전환된다. (S450) 도 6은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치에 대한 처리 흐름도이다. 이하, 도 6을 참조하여 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치에 대한 동작방법을 설명한다. 우선, 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치는 사용자 입력을 위한 프로젝터 화면을 제공한다(S510). S510 단계 이후, 휴대형 컴퓨터 장치는 프로젝터 화면상에 사용자 행동에 따른 입력 명령을 인식한다(S530). S530 단계에서 휴대형 컴퓨터 장치는 카메라 센서 모듈로부터 전달된 이미지 정보로부터 자신의 주변에 움직임 이 있는지 (움직임 검출, Motion Detection), 사람 얼굴이 있는지 (얼굴 검출, Face Detection), 그 사람이 누 구인지 (얼굴 인식, Face Recognition), 사용자의 손가락이 어떤 위치에서 어떤 제스처로 움직이는지 (손가락 검출, Finger Tip Detection), 자기 앞에 자기가 알고 있는 물체가 있는지 (물체 인식, Object Detection) 등 을 인지한다. 또한, 휴대형 컴퓨터 장치는 소리 정보로부터 어디에서 소리가 나는지 (음원 추적, Sound Source Localization), 어떤 말을 했는지 (음성 인식, Voice Recognition) 등을 인지한다. 그 밖에도 접촉센서로부터 의 정보를 통해 사용자가 어떤 명령을 내렸는지를 인식하고, 조도센서로부터 주변환경이 얼마나 밝거나 어두운 지를 인식한다. 그리고 휴대형 컴퓨터 장치는 영상이 획득될 때 움직임 검출, 물체 검출, 얼굴 검출 등이 활성화되며, 얼굴 검 출이 될 때, 얼굴 인식이 되는 동작을 수행한다. S530 단계에서 휴대형 컴퓨터 장치는 사용자 행동에 따른 입력 명령을 인식한 후, 입력 명령에 따른 서비스와 콘텐츠를 출력한다. (S550) S530 단계에서 휴대형 컴퓨터 장치는 입력 명령에 따른 서비스와 콘텐츠뿐만 아니라 물체 인식, 소리 정보, 접 촉센서로 통해 입력된 명령 등에 따른 서비스와 콘텐츠를 검색하고 출력할 수 있다. 구체적으로 휴대형 컴퓨터 장치가 \"스팸(SPAM)\"에 대한 물체를 인식하는 경우, 이에 따른 추천요리, 소비자 취 향 등에 대한 정보를 프로젝터를 통해 출력할 수 있다. 또한, 휴대형 컴퓨터 장치는 스팸에 대한 검색기능을 제공할 수 있다. 도 7은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 사용자 이동에 따른 위치 보정에 대한 처리 흐름도이다. 이하 도 7을 참조하여 사용자 이동에 따른 위치 보정에 대한 처리 방법을 설명한다. 휴대형 컴퓨터 장치는 사용자의 이동상태를 감지하고,(S610), 이동 여부를 판단한다. (S620) S620 단계에서, 사용자가 이동하는 경우, 상기 휴대형 컴퓨터 장치는 영상을 획득하기 위해 위치를 보정한다. (S630) S630 단계에서 휴대형 컴퓨터 장치는 위치 보정을 통한 영상정보를 획득하고, 사용자의 행동에 따른 입력 명령 을 인식한다. (S640). 본 발명은 본 발명의 정신 및 필수적 특징을 벗어나지 않는 범위에서 다른 특정한 형태로 구체화될 수 있다. 따 라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가 적 범위 내에서 의 모든 변경은 본 발명의 범위에 포함된다. 또한, 특허청구범위에서 명시적인 인용 관계가 있지 않은 청구항들 을 결합하여 실시예를 구성하거나 출원 후의 보정에 의해 새로운 청구항으로 포함할 수 있다. 산업상 이용가능성 본 발명의 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치 및 그 동작 방법은, 주변 환경과 인터랙션 하여 사람을 찾고, 사용자를 인식하고, 얼굴을 따라다니며, 필요 시 대화할 수 있는 로봇 컴퓨터 등에 적용할 수 있으며, 이 에 따라 인공지능이 부가된 로봇 기술 분야에는 어디든 적용가능하다."}
{"patent_id": "10-2011-0033700", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 로봇 컴퓨터를 도시한 블록도이다. 도 2는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 도면이다. 도 3은 본 발명의 실시 예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치를 도시한 블록도이다. 도 4는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 소프트웨어 구성도이다. 도 5는 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 동작 매커니즘을 보여주는 흐름도이다. 도 6은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 이동형 컴퓨터 휴대형 컴퓨터 장치에 대한 처리 흐름도이다. 도 7은 본 발명의 일 실시예에 따른 지능형 로봇 특성을 갖는 휴대형 컴퓨터 장치의 사용자 이동에 따른 위치 보정에 대한 처리 흐름도이다."}
