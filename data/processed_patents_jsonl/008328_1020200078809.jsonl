{"patent_id": "10-2020-0078809", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0000758", "출원번호": "10-2020-0078809", "발명의 명칭": "영상 검출 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "안영춘"}}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 검출 장치에 있어서, 영상을 출력하는 디스플레이;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 뉴럴 네트워크를 이용하여 상기 디스플레이에서 출력하는 제1 영상으로부터 부가 정보 영역을 검출하고,상기 부가 정보 영역으로부터 상기 부가 정보 영역의 스타일 정보를 획득하고,상기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 상기 디스플레이에서 출력하는 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을검출하는, 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여 상기 뉴럴 네트워크를 업데이트하고, 상기 업데이트된 뉴럴 네트워크를 이용하여 상기 제2 영상으로부터 상기 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는, 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 뉴럴 네트워크 프로세서를 더 포함하고,상기 뉴럴 네트워크 프로세서는 상기 스타일 정보에 기초하여 새로운 스타일 정보를 갖는 부가 정보 영역을 생성하고, 상기 새로운 스타일 정보를 갖는 부가 정보 영역이 포함된 영상을 학습하여 신규 영상을 출력하는 모델을 획득하는, 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서, 컴퓨팅 장치와 통신하는 통신부를 더 포함하고,상기 통신부는 상기 스타일 정보를 상기 컴퓨팅 장치로 전송하고, 상기 컴퓨팅 장치로부터, 상기 모델을 수신하는 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 부가 정보 영역으로부터텍스트 정보 및 컬러 정보를 획득하고, 상기 텍스트 정보 및 상기 컬러 정보로부터 상기 스타일 정보를 획득하는, 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 스타일 정보는 상기 영상에서의 부가 정보 영역의 위치, 부가 정보 영역의 배경 색상,부가 정보 영역의 배경 텍스쳐, 부가 정보 영역에 포함된 텍스트들의 레이아웃, 텍스트 종류, 텍스트 폰트, 텍스트 색상, 텍스트 텍스쳐 중 적어도 하나를 포함하는, 영상 검출 장치.공개특허 10-2022-0000758-3-청구항 7 제5 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 텍스트 정보로부터 상기제1 영상을 인식하는 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 부가 정보 영역으로부터텍스트 영역을 추출하고, 상기 텍스트 영역에서 텍스트를 인식하고, 상기 인식된 텍스트를 종류 별로 분류하여상기 텍스트 정보를 획득하는 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 부가 정보 영역에서 특징 맵을 추출하고, 상기 특징 맵을 분석하여 상기 텍스트 영역을 추출하는, 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 채널 명, 채널 번호, 타이틀,재생 시간, 기타 정보 중 적어도 하나의 종류로 상기 텍스트를 분류하는, 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8 항에 있어서, 상기 텍스트를 인식하는 것은 상기 텍스트 영역에서 숫자, 단어, 단어의 랭귀지, 폰트 중 적어도 하나를 인식하는 것을 포함하는, 영상 검출 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "컴퓨팅 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 적어도 하나의 뉴럴 네트워크를 이용하여, 영상에 포함된 부가 정보 영역으로부터 획득된 스타일 정보를 이용하여 새로운 스타일 정보를 갖는 부가 정보 영역을 생성하고, 상기 새로운 스타일 정보를 갖는 부가 정보 영역이 포함된 영상을 학습하여 신규 영상을 출력하는모델을 획득하는, 컴퓨팅 장치."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "영상 검출 방법에 있어서, 제1 영상으로부터, 뉴럴 네트워크를 이용하여 부가 정보 영역을 검출하는 단계;상기 부가 정보 영역으로부터 상기 부가 정보 영역의 스타일 정보를 획득하는 단계; 및상기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는 단계를 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서, 상기 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는 단계는상기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여 상기 뉴럴 네트워크를 업데이트하는 단계; 및상기 업데이트된 뉴럴 네트워크를 이용하여 상기 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는 단계를 포함하는, 영상 검출 방법. 공개특허 10-2022-0000758-4-청구항 15 제14 항에 있어서, 상기 스타일 정보에 기초하여 새로운 스타일 정보를 갖는 부가 정보 영역을 생성하는 단계;및상기 새로운 스타일 정보를 갖는 부가 정보 영역이 포함된 영상을 학습하여 신규 영상을 출력하는 모델을 획득하는 단계를 더 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14 항에 있어서, 상기 스타일 정보를 컴퓨팅 장치로 전송하는 단계; 및상기 컴퓨팅 장치로부터 상기 모델을 수신하는 단계를 더 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13 항에 있어서, 상기 스타일 정보를 획득하는 단계는 상기 부가 정보 영역으로부터 텍스트 정보 및 컬러 정보를 획득하는 단계; 및상기 텍스트 정보 및 상기 컬러 정보로부터 상기 스타일 정보를 획득하는 단계를 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서, 상기 스타일 정보는 영상에서의 부가 정보 영역의 위치, 부가 정보 영역의 레이아웃, 텍스트의 위치, 텍스트의 종류, 텍스트의 폰트, 부가 정보 영역의 배경 색상 및 텍스트의 색상 중 적어도 하나를 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17 항에 있어서, 상기 텍스트 정보로부터 상기 영상을 인식하는 단계를 더 포함하는 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17 항에 있어서, 상기 텍스트 정보를 획득하는 단계는상기 부가 정보 영역으로부터 텍스트 영역을 추출하는 단계;상기 텍스트 영역에서 텍스트를 인식하는 단계; 및상기 인식된 텍스트를 종류 별로 분류하는 단계를 포함하는 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20 항에 있어서, 상기 텍스트 영역을 추출하는 단계는상기 부가 정보 영역에서 특징 맵을 추출하는 단계; 및상기 특징 맵을 분석하여 상기 텍스트 영역을 추출하는 단계를 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20 항에 있어서, 상기 인식된 텍스트를 종류 별로 분류하는 단계는 채널 명, 채널 번호, 타이틀, 기타 정보중 적어도 하나의 종류로 상기 텍스트를 분류하는 단계를 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20 항에 있어서, 상기 텍스트를 인식하는 단계는 상기 텍스트 영역에서 숫자, 단어, 단어의 랭귀지, 폰트 중적어도 하나를 인식하는 단계를 포함하는, 영상 검출 방법."}
{"patent_id": "10-2020-0078809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제1 영상으로부터, 뉴럴 네트워크를 이용하여 부가 정보 영역을 검출하는 단계;공개특허 10-2022-0000758-5-상기 부가 정보 영역으로부터 상기 부가 정보 영역의 스타일 정보를 획득하는 단계; 및상기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는 단계를 포함하는, 영상 검출 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 영상 검출 장치에 대한 것으로, 영상을 출력하는 디스플레이, 하나 이상의 인스트럭션을 저장하는 메 모리 및 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세서는 하나 이상의 인 스트럭션을 실행함으로써, 뉴럴 네트워크를 이용하여 디스플레이에서 출력하는 제1 영상으로부터 부가 정보 영역 을 검출하고, 부가 정보 영역으로부터 부가 정보 영역의 스타일 정보를 획득하고, 스타일 정보에 기초하여 생성 된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 디스플레이에서 출력하는 제2 영상으 로부터 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출할 수 있다."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시 예들은 영상 검출 장치 및 그 동작 방법에 관한 것으로서, 보다 상세하게는, 영상에 포함된 부가 정보 영역의 스타일 정보를 이용하여 다른 스타일 정보를 갖는 부가 정보 영역을 포함한 영상에서도 부가 정보 영역을 검출할 수 있는 영상 검출 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "추천 시스템(recommender system)이란 사용자에게 영화나 콘텐트, 상품(item) 등을 추천하는 시스템이다. 추천 이나 광고를 하려는 마케팅 담당자는 사람들이 방송국에서 제공하거나 온라인 비디오 컨텐츠 제공 서버가 제공 하는 프로그램의 소비 이력 등을 기반으로 사용자에게 새로운 콘텐트나 아이템을 추천하거나, 수많은 사람들 중 적합한 잠재 고객을 선택하여 맞춤형 광고 등을 수행하게 된다. 인공지능(Artificial Intelligence, 이하, AI) 시스템은 기계가 스스로 학습(training)하고 판단하며 목적하는 결과를 도출하거나 목적하는 동작을 수행하는 시스템이다."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시 예들은 인공지능 모델을 이용하여 영상으로부터 부가 정보 영역을 검출하는 영상 검출 장치 및 그 동작 방법을 제공하기 위한 것이다. 다양한 실시 예들은 부가 정보 영역으로부터 스타일 정보를 획득하는 영상 검출 장치 및 그 동작 방법을 제공하 기 위한 것이다. 다양한 실시 예들은 획득된 스타일 정보로부터 새로운 스타일 정보를 생성하고 이를 학습한 모델을 이용하여, 이전과 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는 영상 검출 장치 및 그 동작 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시 예에 따른 영상 검출 장치 장치는 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상 기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 뉴럴 네트워크를 이용하여 상기 디스플레이에서 출력하는 제1 영상으로부터 부가 정보 영역을 검 출하고, 상기 부가 정보 영역으로부터 상기 부가 정보 영역의 스타일 정보를 획득하고, 상기 스타일 정보에 기 초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 상기 디스플레이에서 출 력하는 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 스타일 정보에 기초하여 생 성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여 상기 뉴럴 네트워크를 업데이트하고, 상기 업데이트된 뉴럴 네트워크를 이용하여 상기 제2 영상으로부터 상기 다른 스타일 정보를 갖 는 부가 정보 영역을 검출할 수 있다. 실시 예에서, 상기 영상 검출 장치는 뉴럴 네트워크 프로세서를 더 포함하고, 상기 뉴럴 네트워크 프로세서는 상기 스타일 정보에 기초하여 새로운 스타일 정보를 갖는 부가 정보 영역을 생성하고, 상기 새로운 스타일 정보 를 갖는 부가 정보 영역이 포함된 영상을 학습하여 신규 영상을 출력하는 모델을 획득할 수 있다. 실시 예에서, 상기 영상 검출 장치는 컴퓨팅 장치와 통신하는 통신부를 더 포함하고, 상기 통신부는 상기 스타 일 정보를 상기 컴퓨팅 장치로 전송하고, 상기 컴퓨팅 장치로부터, 상기 모델을 수신할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 부가 정보 영역으로부터 텍 스트 정보 및 컬러 정보를 획득하고, 상기 텍스트 정보 및 상기 컬러 정보로부터 상기 스타일 정보를 획득할 수 있다. 실시 예에서, 상기 스타일 정보는 상기 영상에서의 부가 정보 영역의 위치, 부가 정보 영역의 배경 색상, 부가 정보 영역의 배경 텍스쳐, 부가 정보 영역에 포함된 텍스트들의 레이아웃, 텍스트 종류, 텍스트 폰트, 텍스트 색상, 텍스트 텍스쳐 중 적어도 하나를 포함할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 텍스트 정보로부터 상기 제1 영상을 인식할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 부가 정보 영역으로부터 텍 스트 영역을 추출하고, 상기 텍스트 영역에서 텍스트를 인식하고, 상기 인식된 텍스트를 종류 별로 분류하여 상 기 텍스트 정보를 획득할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 부가 정보 영역에서 특징 맵 을 추출하고, 상기 특징 맵을 분석하여 상기 텍스트 영역을 추출할 수 있다. 실시 예에서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 채널 명, 채널 번호, 타이틀, 재 생 시간, 기타 정보 중 적어도 하나의 종류로 상기 텍스트를 분류할 수 있다. 실시 예에서, 상기 텍스트를 인식하는 것은 상기 텍스트 영역에서 숫자, 단어, 단어의 랭귀지, 폰트 중 적어도 하나를 인식하는 것을 포함할 수 있다. 실시 예에 따른 컴퓨팅 장치는, 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으 로써, 적어도 하나의 뉴럴 네트워크를 이용하여, 영상에 포함된 부가 정보 영역으로부터 획득된 스타일 정보를 이용하여 새로운 스타일 정보를 갖는 부가 정보 영역을 생성하고, 상기 새로운 스타일 정보를 갖는 부가 정보 영역이 포함된 영상을 학습하여 신규 영상을 출력하는 모델을 획득할 수 있다. 실시 예에 따른 영상 검출 방법은 제1 영상으로부터, 뉴럴 네트워크를 이용하여 부가 정보 영역을 검출하는 단 계, 상기 부가 정보 영역으로부터 상기 부가 정보 영역의 스타일 정보를 획득하는 단계 및 상기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는 단계를 포함할 수 있다. 실시 예에 따른 컴퓨터로 판독 가능한 기록 매체는 제1 영상으로부터, 뉴럴 네트워크를 이용하여 부가 정보 영 역을 검출하는 단계, 상기 부가 정보 영역으로부터 상기 부가 정보 영역의 스타일 정보를 획득하는 단계 및 상 기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역을 검출하는 단계를 포함하는, 영상 검출 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체일 수 있다."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시 예에 따른 영상 검출 장치 및 방법은 인공지능 모델을 이용하여 영상으로부터 부가 정보 영역을 검출할 수 있다. 실시 예에 따른 영상 검출 장치 및 방법은 부가 정보 영역으로부터 스타일 정보를 획득할 수 있다. 실시 예에 따른 영상 검출 장치 및 방법은 획득된 스타일 정보로부터 새로운 스타일 정보를 생성하고 이를 학습 한 모델을 이용하여, 이전과 다른 스타일 정보를 갖는 부가 정보 영역을 검출할 수 있다."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기 재된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아 니다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"실시 예에서\" 등의 어구는 반드시 모두 동일한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구 현될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정 의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로 그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으 로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으 며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 명세서에서 “사용자”라는 용어는 영상 검출 장치나 컴퓨팅 장치를 이용하여 영상 검출 장치나 컴퓨팅 장치의 기능 또는 동작을 제어하거나 영상 검출 장치를 기능에 따라 이용하는 사람을 의미하며, 시청자, 관리자 또는 설치 기사를 포함할 수 있다. 또한, 명세서에서 “소비자”라는 용어는 영상 검출 장치를 용도에 맞게 이 용하는 사용자를 의미할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 실시 예에 따라 영상 검출 장치가 영상에서 부가 정보 영역을 검출하는 것을 설명하기 위한 도면이 다. 도 1을 참조하면, 영상 검출 장치는 통신망을 통해 컴퓨팅 장치와 통신할 수 있다. 영상 검출 장치는 컴퓨팅 장치와 유선 또는 무선으로 통신할 수 있는, 다양한 형태의 전자 장치로 구현될 수 있 다. 실시 예에서, 영상 검출 장치는 영상 표시 장치일 수 있다. 영상 표시 장치는 TV일 수 있으나, 이에 한정 되지 않으며, 디스플레이를 포함하는 전자 장치로 구현될 수 있다. 예를 들어, 영상 표시 장치는 데스크탑, 스 마트 폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 화상전화기, 전자북 리더기(e-book reader), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 디지털 카메라, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 캠코더, 네비게이션, 웨어러블 장치 (wearable device), 스마트 와치(smart watch), 홈네트워크 시스템, 보안 시스템, 의료 장치 중 적어도 하나를 포함할 수 있다. 영상 검출 장치는 고정형 또는 이동형일 수 있으며, 디지털 방송 수신이 가능한 디지털 방송 수신기일 수 있다. 영상 검출 장치는 평면(flat) 디스플레이 장치뿐만 아니라, 곡률을 가지는 화면인 곡면(curved) 디스플레 이 장치 또는 곡률을 조정 가능한 가변형(flexible) 디스플레이 장치로 구현될 수 있다. 영상 검출 장치의 출력 해상도는 예를 들어, HD(High Definition), Full HD, Ultra HD, 또는 Ultra HD 보다 더 선명한 해상도를 포함할 수 있다. 영상 검출 장치는 소스 장치(미도시)와 연결될 수 있다. 소스 장치는 PC(personal computer), DVD 플레이 어, 비디오 게임기, 셋탑박스(set-top box), AV 리시버, 케이블 수신 장치나 위성 방송 수신 장치, OTT(Over The Top) 서비스 제공자나 IPTV(Internet Protocol Television) 서비스 제공자로부터 컨텐츠를 받는 인터넷 수 신 장치 중 적어도 하나를 포함할 수 있다. OTT 서비스 제공자나 IPTV 서비스 제공자는 광대역 연결 상에서 인 터넷 프로토콜을 사용하여 소비자에게 디지털 텔레비전 서비스를 제공할 수 있다. 이를 통해 소비자는 실시간 방송을 수신하여 이용할 수 있다. 또한, 이들 서비스 제공자는 VOD 서비스를 제공하여 소비자가 원하는 시간에 원하는 컨텐트를 스트리밍 혹은 다운로드 방식으로 수신하여 이용하도록 할 수 있다. 이하, 소비자에게 컨텐트 를 제공하는 지상파 방송국이나 케이블 방송국, 또는 OTT 서비스 제공자, IPTV 서비스 제공자를 컨텐트 프로바 이더라고 부르기로 한다. 영상 검출 장치는 소스 장치로부터 컨텐트를 받아 출력할 수 있다. 실시 예에서, 컨텐트는, 컨텐트 프로 바이더들이 제공하는 텔레비전 프로그램이나 VOD 서비스를 통한 각종 영화나 드라마 등의 아이템을 포함할 수 있으며, 비디오 신호, 오디오 신호, 텍스트 신호 중 하나 이상을 포함할 수 있다. 영상 검출 장치는 소정 시간마다 영상 검출 장치의 화면을 통해 사용자에게 출력되는 화면을 캡쳐할 수 있다. 영상 검출 장치는 캡쳐된 영상을 분석하여 사용자가 시청하는 컨텐트에 대한 정보를 획득할 수 있다. 사용자가 시청하는 컨텐트에 대한 정보들은 다른 서버(미도시)에서 수집되어 사용자의 컨텐트 소비 성향 이나 선호도 등을 파악하는데 사용될 수 있고, 추천이나 광고 서비스 등에 활용될 수 있다. 영상 검출 장치는 영상 검출 장치에 포함된 사용자 인터페이스를 통해 사용자의 제어 명령을 수신할 수 있다. 사용자 인터페이스는 영상 검출 장치에 버튼이나 키패드 형태로 부착되어 있을 수 있다. 영상 검 출 장치의 디스플레이부가 터치스크린으로 구현되는 경우 사용자 인터페이스 또한 터치스크린으로 구현될수 있고 이 경우 사용자의 손가락이나 입력 펜 등으로 제어 명령을 수신할 수 있다. 또는 영상 검출 장치 는 영상 검출 장치와 분리되어 있는 제어 장치(미도시)에 의해 제어될 수 있으며, 제어 장치는 리모컨 또 는 휴대폰과 같이 영상 검출 장치를 제어하기 위한 다양한 형태의 장치로 구현될 수 있다. 제어 장치는 적 외선(infrared) 또는 블루투스(bluetooth)를 포함하는 근거리 통신을 이용하여 영상 검출 장치를 제어할 수 있다. 제어 장치는 구비된 키나 버튼, 터치 패드(touchpad), 사용자의 음성 수신이 가능한 마이크(미도시), 및 제어 장치의 모션 인식이 가능한 센서(미도시) 중 적어도 하나를 이용하여 영상 검출 장치의 기능을 제 어할 수 있다. 제어 장치는 영상 검출 장치의 전원을 온(on)시키거나 오프(off)시키기 위한 전원 온/오프 버튼을 포함할 수 있다. 또한, 제어 장치는 사용자 입력에 의해 영상 검출 장치의 채널 변경, 음량 조정, 지상파 방송/케 이블 방송/위성 방송 선택, 또는 환경 설정(setting)을 할 수 있다. 또한, 제어 장치는 포인팅 장치일 수도 있 다. 예를 들어, 제어 장치는, 특정 키 입력을 수신하는 경우에 포인팅 장치로 동작할 수 있다. 사용자가 사용자 인터페이스 또는 제어 장치를 이용하여 영상 검출 장치에서 출력되는 채널이나 프로그램 등을 변경하는 경우, 영상 검출 장치의 화면에는 변경된 채널이나 프로그램에 대한 정보가 소정 시간 동안 출력될 수 있다. 즉, 채널이 변경될 때, 영상 검출 장치는 변경된 채널의 프로그램을 출력함과 동시에 해 당 채널 또는 해당 채널에서 출력되는 프로그램을 설명하는 정보를 프로그램과 함께 영상에 포함시켜 출력할 수 있다. 이하, 채널이나 프로그램을 설명하는 정보를 부가 정보라고 부르기로 한다. 부가 정보는 채널 번호, 채널 명, 콘텐트의 타이틀, 해당 컨텐트의 전체 재생 시간, 또는 전체 재생 시간 중 콘텐트가 이미 재생된 시간 및 남은 시간을 표시하는 정보, 기타 해당 콘텐트에 등장하는 출연자 정보, 콘텐트의 장르 중 적어도 하나를 포함 할 수 있다. 복수 개의 부가 정보들이 포함된 영역을 부가 정보 영역이라 부르기로 한다. 사용자는 채널이나 프로그램 등이 바뀔 때, 콘텐트와 함께 출력되는 부가 정보 영역을 이용하여, 바뀐 채널의 채널 명이나 프로그램 타이틀 등을 파악할 수 있고, 현재 출력되는 컨텐트의 전체 재생 시간 및 컨텐트가 얼마 나 진행되었는지 등을 쉽게 파악할 수 있다. 도 1을 참조하면, 영상 검출 장치는 사용자의 채널 변경 요청에 따라 제1 영상을 출력할 수 있다. 제 1 영상은 변경된 채널에서 출력되는 컨텐트와 함께 제1 부가 정보 영역을 포함할 수 있다. 제1 부가 정보 영역은 채널 이름, 채널 번호, 컨텐트의 타이틀, 재생 시간, 기타 부가 정보 중 적어도 하나를 포함할 수 있다. 영상 검출 장치는 소정 시간, 예컨대 0.5초마다 영상 검출 장치의 화면을 통해 사용자에게 출력되는 RGB 이미지를 캡쳐하고 이로부터 사용자의 시청 경향 등을 파악할 수 있다. 실시 예에서, 영상 검출 장치는 캡쳐한 이미지로부터 부가 정보 영역을 검출할 수 있다. 즉, 위 실시 예에 서, 영상 검출 장치는 소정 시간 간격으로, 현재 화면에 출력되어 캡쳐된 제1 영상으로부터 제1 부가 정보 영역을 검출할 수 있다. 실시 예에서, 영상 검출 장치는 적어도 하나의 뉴럴 네트워크를 이용하여 이미지로부터 부가 정보 영역을 검출할 수 있다. 적어도 하나의 뉴럴 네트워크는 입력 영상으로부터 제1 부가 정보 영역과 같거나 유사한 스타일을 갖는 부가 정보 영역을 검출하도록 학습된 뉴럴 네트워크일 수 있다. 예컨대, 뉴럴 네트워크는 지도형 학습(supervised learning) 방법으로 소정의 데이터셋(dataset)을 학습하여 훈련된 뉴럴 네트워크일 수 있다. 뉴럴 네트워크는 학습한 데이터셋과 같거나 유사한 부가 정보 영역을 검출할 수 있다. 영상 검출 장치가 이용하는 뉴럴 네트워크는 제1 스타일 정보를 갖는 부가 정보 영역을 검출하도록 학습되어 있기 때문에, 영상에 제1 스타일 정보와 유사하지 않은 제2 스타일 정보를 갖는 부가 정보 영역이 포함된 경우, 제2 스타일 정보를 갖는 부가 정보 영역을 인식하지 못한다. 컨텐트 프로바이더들은 소정 주기마다, 또는 특별한 시즌, 예컨대 크리스마스와 같은 시기에는, 영상과 함께 출 력되는 부가 정보 영역을 새로운 스타일로 바꾸는 경우가 있다. 예컨대, 컨텐트 프로바이더가 부가 정보 영역의 스타일을 도 1의 제2 부가 정보 영역과 같이 변경했다고 가정한다. 제2 부가 정보 영역은 제1 부가 정보 영역과는 채널 명, 채널 번호, 타이틀 등이 출력되는 위치가 다르고 부가 정보 영역에 포함된 배경 색상 및 텍스트의 폰트 등이 다르다. 이 경우, 기존의 부가 정보 영역의 스타일을 학습한 뉴럴 네트워크는 영상 에서 제2 부가 정보 영역을 인식하여 검출할 수 없다. 실시 예에서, 영상 검출 장치는 1 영상으로부터 제1 부가 정보 영역을 검출한 후, 제1 부가 정 보 영역을 이용하여 학습 데이터를 생성할 수 있다. 이를 위해 영상 검출 장치는 검출된 제1 부가 정보 영역으로부터 제1 부가 정보 영역의 스타일 정보를 획득할 수 있다. 설명의 편의를 위해, 제1 부 가 정보 영역의 스타일 정보를 제1 스타일 정보로 칭하고, 제2 부가 정보 영역의 스타일 정보를 제2 스타일 정보로 칭하기로 한다. 스타일 정보는 부가 정보 영역의 전체적인 모양이나 느낌, 구성 등을 의미할 수 있다. 스타일 정보는 부가 정보 영역 전체, 또는 부가 정보 영역에 포함된 배경 및 텍스트가 갖는 질감, 색감, 분위기, 콘트라스트, 광택 또는 색의 3요소인 명도(Intensity), 색도(Hue), 채도(Saturation) 등에 대한 정보를 포함할 수 있다. 또한, 스타일 정보는 영상에서의 부가 정보 영역의 배치나 위치, 부가 정보 영역에 포함된 텍스트들의 배치나 위치, 텍스트의 종류나 폰트 중 적어도 하나를 포함할 수 있다. 영상 검출 장치는 제1 스타일 정보를 획득한 후 이를 통신망을 통해 컴퓨팅 장치로 전송할 수 있다. 컴퓨팅 장치는 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재되거나, 또는 칩 형태나 전자 장치 형태로 서버에 포함될 수 있다. 또는 컴퓨팅 장치는 소프트웨어 모듈로 구현될 수도 있다. 실시 예에서, 컴퓨팅 장치는 영상 검출 장치로부터 스타일 정보를 수집하고, 이를 기반으로 새로운 스타일 정보를 생성할 수 있다. 컴퓨팅 장치는 새로운 스타일 정보를 갖는 부가 정보 영역을 일반 콘텐트 와 합성하여 새로운 영상을 생성할 수 있다. 컴퓨팅 장치는 새로운 영상으로부터 부가 정보 영역을 검출하도록 모델을 학습시킬 수 있다. 컴퓨팅 장치는 학습된 모델을 통신망을 통해 영상 검출 장치로 전송 할 수 있다. 영상 검출 장치는 통신망을 통해 컴퓨팅 장치로부터 모델을 수신하고, 수신한 모델을 이용하여 원래의 뉴럴 네트워크를 업데이트할 수 있다. 전술한 바와 같이, 영상 검출 장치가 이용하는 뉴럴 네트워크는 기 학습한 형태와 같거나 유사한 스타일의 부가 정보 영역만을 검출할 수 있다. 뉴럴 네트워크가 새로운 스타일의 부가 정보 영역을 인식하도록 하기 위해 서는 인식하고자 하는 새로운 영상을 뉴럴 네트워크가 재 학습하도록 하여야 한다. 이를 위해서는 뉴럴 네트워 크가 학습할 추가 데이터를 레이블링, 어노테이션(annotation), 태깅하는 과정 등이 필요하다. 실시 예에서는 영상 검출 장치가 이러한 번거로운 과정을 수행할 필요 없이, 통신망을 통해 컴퓨팅 장치로부터 신규 모델을 수신하여 원래의 뉴럴 네트워크를 간단히 업데이트할 수 있다. 영상 검출 장치는 업데이트된 뉴럴 네트워크를 이용하여 제1 스타일 정보와는 다른 스타일 정보를 갖는 부 가 정보 영역을 검출할 수 있다. 위 예에서, 컨텐트 프로바이더가 도 1의 제2 부가 정보 영역과 같이 부가 정보 영역의 스타일을 바꾼 경우, 영상 검출 장치는 업데이트된 뉴럴 네트워크를 이용함으로써 현재 출력 되는 제2 영상에서 제2 스타일 정보를 갖는 제2 부가 정보 영역을 검출할 수 있다. 이와 같이, 실시 예에 의하면, 영상 검출 장치는 검출된 부가 정보 영역의 스타일 정보를 획득하고 이를 학습 데이터로 이용되도록 할 수 있다. 실시 예에 의하면, 영상 검출 장치는 검출하고자 하는 부가 정보 영역의 스타일이 바뀌어도 추가적인 학습 없이 업데이트된 뉴럴 네트워크를 이용하여 부가 정보 영역을 검출할 수 있다. 도 2는 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 2를 참조하면, 영상 검출 장치는 프로세서, 메모리, 및 디스플레이를 포함할 수 있다. 실시 예에서, 영상 검출 장치는 영상으로부터 부가 정보 영역을 검출하고, 그로부터 새로운 부가 정보 영 역 검출을 위한 학습 데이터를 생성할 수 있는 전자 장치일 수 있다. 실시 예에 따른 디스플레이는 컨텐트 프로바이더들이 제공하는 컨텐트를 화면에 표시할 수 있다. 디스플레 이는 실시간으로 수신되는 방송 프로그램을 화면에 출력하거나 또는 스트리밍이나 다운로드를 하여 수신된 VOD 서비스의 프로그램 등을 화면에 출력할 수 있다. 실시 예에서, 디스플레이는 사용자로부터의 채널 변경 요청에 상응하여, 변경된 채널의 컨텐트를 출력함과 동시에 해당 컨텐트에 대한 부가 정보 영역을 소정 시간 동안 출력할 수 있다. 디스플레이가 터치 스크린으로 구현되는 경우, 디스플레이는 출력 장치 이외에 사용자 인터페이스와 같은 입력 장치로 사용될 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display),박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드 (organic light-emitting diode), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전 기 영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고, 영상 검출 장치 의 구현 형태에 따라, 영상 검출 장치는 디스플레이를 둘 이상 포함할 수 있다. 실시 예에 따른 메모리는, 적어도 하나의 인스트럭션을 저장할 수 있다. 메모리는 프로세서가 실행하는 적어도 하나의 프로그램을 저장하고 있을 수 있다. 메모리에는 적어도 하나의 뉴럴 네트워크 및/ 또는 기 정의된 동작 규칙이나 AI 모델이 저장될 수 있다. 또한 메모리는 영상 검출 장치로 입력되거 나 영상 검출 장치로부터 출력되는 데이터를 저장할 수 있다. 실시 예에서, 메모리는 영상 검출 장치가 검출한 부가 정보 영역에 대한 정보를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 프로세서는 영상 검출 장치의 전반적인 동작을 제어한다. 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 영상 검출 장치가 기능하도록 제어할 수 있다. 실시 예에서, 영상 검출 장치는 인공지능(Artificial Intelligence, AI) 기술을 이용할 수 있다. AI 기술 은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성될 수 있다. AI 기술은 알고리즘을 활용하여 구 현될 수 있다. 여기서, AI 기술을 구현하기 위한 알고리즘 또는 알고리즘의 집합을 신경망(Neural Network, 뉴 럴 네트워크)이라 한다. 신경망은 입력 데이터를 입력 받고, 분석 및 분류를 위한 연산을 수행하여, 결과 데이 터를 출력할 수 있다. 이와 같이 신경망이 입력 데이터에 대응되는 결과 데이터를 정확하게 출력하기 위해서는, 신경망을 트레이닝 시킬 필요가 있다. 여기서,‘트레이닝(training)’은 신경망으로 다양한 데이터들을 입력시 키고, 입력된 데이터들을 분석하는 방법, 입력된 데이터들을 분류하는 방법, 및/또는 입력된 데이터들에서 결과 데이터 생성에 필요한 특징을 추출하는 방법 등을 신경망이 스스로 발견 또는 터득할 수 있도록 신경망을 훈련 시키는 것을 의미할 수 있다. 신경망을 훈련시킨다는 것은 다수의 학습 데이터들에 학습 알고리즘을 적용함으로 써, 원하는 특성의 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 실시 예에서 인공지능이 수행되는 영 상 검출 장치 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 여기서, 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨데, 로봇)를 훈련시켜 소정 의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학 습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 실시 예에서의 학습 알고리즘은 명시한 경우를 제외하고 전 술한 예에 한정되지 않는다. 신경망을 통하여 입력 데이터에 대응되는 출력 데이터를 출력하도록 하는 알고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리즘의 집합을 실행하는 하드웨어를 ‘AI 모델’(또는, ‘인공지능 모델’)이 라 칭할 수 있다. 프로세서는, 기 정의된 동작 규칙 또는 AI 모델에 따라, 입력 데이터를 처리할 수 있다. 기 정의된 동작 규칙 또는 AI 모델은 특정한 알고리즘을 이용하여 만들어진 것일 수 있다. 또한 AI 모델은 특정한 알고리즘이 학습된 것일 수 있다. 프로세서는 AI 모델을 통하여 입력 데이터에 대응되는 출력 데이터를 생성할 수 있 다. 실시 예에서, 프로세서는 AI 모델을 적어도 하나 저장하고 있을 수 있다. 실시 예에서 프로세서는 복 수 개의 AI 모델들을 이용하여 입력 영상으로부터 출력 데이터를 생성할 수 있다. 실시 예에서, 프로세서 가 아닌 메모리가 전술한 AI 모델들을 저장하고 있을 수도 있다. 실시 예에서, 프로세서가 이용하는 신경망, 즉, 뉴럴 네트워크는 영상으로부터 여러 종류의 클래스들을 검 출하도록 학습된 뉴럴 네트워크일 수 있다. 디스플레이가 출력하는 영상은 해당 채널에서 출력되는 콘텐트 외에도, 썸네일 영역, 로고 영역, 부가 정보 영역 중 하나 이상의 클래스를 더 포함할 수 있다. 썸네일 영역은 영상에 포함된 다른 영상을 의미할 수 있다. 로고 영역은 해당 채널이나 프로그램 명을 표시하거나, 특정 프로 그램이나 채널, 관련 제품 등을 광고하기 위한 시각 디자인 등을 의미할 수 있다. 썸네일 영역이나 로고 영역은부가 정보 영역에 포함될 수도 있고, 또는 부가 정보 영역과는 별개로 영상에 포함되어 있을 수도 있다. 프로세서는 디스플레이를 통해 출력되는 영상을 소정 시간마다 캡쳐하고 이로부터 여러 종류의 클래 스들을 검출할 수 있다. 프로세서는 뉴럴 네트워크를 이용하여 영상에서 기 학습한 것과 같거나 유사한 형 태나 스타일을 갖는 클래스들을 검출할 수 있다. 프로세서는 영상으로부터 부가 정보 영역을 검출할 수 있다. 프로세서는 영상으로부터 기 학습한 스 타일과 같거나 유사한 형태나 스타일을 갖는 부가 정보 영역을 검출할 수 있다. 부가 정보 영역은 텍스트와 텍스트 외의 배경으로 분리될 수 있다. 프로세서는 부가 정보 영역에서 텍스트 정보를 획득할 수 있다. 텍스트 정보는 텍스트의 종류 및 그 위치 정보를 포함할 수 있다. 이를 위해 프로세서 는 부가 정보 영역을 다른 클래스들과 분리한 후 분리된 부가 정보 영역에서 엣지(edge)를 검출하고 특징 맵을 추출하여, 부가 정보 영역에 포함된 텍스트 영역을 추출할 수 있다. 텍스트 영역은 텍스트가 포함된 박스 형태의 영역을 의미할 수 있다. 프로세서는 텍스트 영역에 대해 OCR를 수행하여 해당 텍스트를 인식할 수 있다. 텍스트를 인식한다는 것은 텍스트 영역에서 숫자, 단어, 단어의 랭귀지, 폰트 중 적어도 하나를 인식하는 것을 의미할 수 있다. 프로세서는 텍스트를 종류 별로 분류할 수 있다. 텍스트는 채널 명, 채널 번호, 타이틀, 재생 시간, 기타 정보 중 적어도 하나의 종류로 분류될 수 있다. 프로세서는 종류 별로 분류된 텍스트를 그 위치와 함께 메 모리에 저장할 수 있다. 프로세서는 부가 정보 영역에서 컬러 정보를 획득할 수 있다. 컬러 정보는 부가 정보 영역의 텍스트 및 배 경의 컬러 특징을 나타내는 정보일 수 있다. 컬러 특징은 색상이나 텍스쳐, 투명도 등을 포함할 수 있다. 컬러 정보는 부가 정보 영역 전체의 컬러 특징, 배경의 컬러 특징, 텍스트의 컬러 특징, 배경과 텍스트의 색상 이나 텍스쳐, 투명도의 대비 정도와 같은 상대적인 컬러 특징 중 적어도 하나를 포함할 수 있다. 프로세서는 텍스트 정보와 컬러 정보를 결합하여 스타일 정보를 획득할 수 있다. 스타일 정보는 영상에서 차지하는 부가 정보 영역의 위치나 배치, 부가 정보 영역 내의 배경 색상, 배경의 텍스쳐, 배경의 투명도, 배경 의 컬러 히스토그램, 부가 정보 영역 내의 텍스트들의 레이아웃, 텍스트 종류, 텍스트 폰트, 텍스트 색상, 텍스 트 텍스쳐, 텍스트의 투명도, 텍스트의 컬러 히스토그램 중 적어도 하나를 포함할 수 있다. 프로세서는 획득한 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모델을 이용하여, 영상에 포함된 새로운 스타일을 갖는 부가 정보 영역을 검출할 수 있다. 실시 예에서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행하여, 전술한 동작들이 수 행되도록 제어할 수 있다. 이 경우, 메모리는 프로세서에 의해서 실행 가능한 하나 이상의 인스트럭 션을 저장하고 있을 수 있다. 실시 예에서, 프로세서는 프로세서의 내부에 구비되는 메모리(미도시)에 하나 이상의 인스트럭션을 저장하고, 내부에 구비되는 메모리에 저장된 하나 이상의 인스트럭션을 실행하여 전술한 동작들이 수행되도록 제어할 수 있다. 즉, 프로세서는 프로세서의 내부에 구비되는 내부 메모리 또는 메모리에 저장 된 적어도 하나의 인스트럭션 또는 프로그램을 실행하여 소정 동작을 수행할 수 있다. 도 3은 실시 예에 따라 화면에 출력되는 영상으로부터 스타일 정보를 획득하는 영상 검출 장치의 기능을 수행하는 스타일 정보 생성 모듈을 설명하기 위한 블록도이다. 도 3을 참조하면, 스타일 정보 생성 모듈은 부가 정보 영역 검출 모듈, 텍스트 정보 획득 모듈, 컬러 정보 획득 모듈, 및 스타일 정보 획득 모듈을 포함할 수 있다. 스타일 정보 생성 모듈은 디스플레이를 통해 출력되는 화면이 캡쳐된 영상을 입력 받고, 입력된 영상에서 부가 정보 영역을 검출하고, 검출된 부가 정보 영역의 스타일 정보를 획득하는 기능을 수행할 수 있다. 부가 정보 영역 검출 모듈은 입력된 영상으로부터 여러 종류의 클래스들을 검출할 수 있도록 동작될 수 있 는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함할 수 있다. 부가 정보 영역 검출 모듈은 입력 영 상에 포함된 콘텐트, 썸네일 영역, 로고 영역, 부가 정보 영역 중 하나 이상의 클래스를 검출할 수 있다. 부가 정보 영역 검출 모듈은 뉴럴 네트워크를 이용하여 영상으로부터 부가 정보 영역을 검출할 수 있다. 부가 정보 영역 검출 모듈은 기 학습한 스타일과 같거나 유사한 스타일을 갖는 부가 정보 영역을 영상으로부터 검출할 수 있다. 부가 정보 영역 검출 모듈는 검출된 부가 정보 영역을 영상에서 분리하고 이를 텍스 트 정보 획득 모듈 및 컬러 정보 획득 모듈로 보낸다. 텍스트 정보 획득 모듈은 부가 정보 영역에서 텍스트 정보를 획득할 수 있는 적절한 로직, 회로, 인터페이 스, 및/또는 코드를 포함할 수 있다. 텍스트 정보 획득 모듈은 부가 정보 영역에서 엣지(edge)를 검출할 수 있다. 엣지는 텍스트의 엣지이거나 노이즈의 엣지 모두를 포함할 수 있다. 텍스트 정보 획득 모듈은 엣지를 검출한 후 부가 정보 영역에 대해 adaptive thresholding, morphology 연산 등과 같은 영상 처리 기술을 적용하여 부가 정보 영역에 포함된 노이즈를 단계적으로 제거할 수 있다. adaptive thresholding은 영상에서 픽셀 값이 문턱 값(thesholding value)보다 큰 경우와 작은 경우에 각각 서 로 다른 값을 할당하여 이미지를 처리하는 기술로, 영상의 서로 다른 영역에 적용되는 문턱 값을 다르게 적용하 여 노이즈가 최소화되도록 하여 이미지를 처리하는 기법이다. 텍스트 정보 획득 모듈은 부가 정보 영역에 대해 영역 별로 적응적으로 문턱 값을 적용하여 배경과 텍스트를 분리할 수 있다. 텍스트 정보 획득 모듈은 배경과 텍스트가 분리된 후, morphology 연산을 수행할 수 있다. morphology 연 산은 노이즈를 제거하고 특징을 추출하는데 사용되는 기술이다. 텍스트 정보 획득 모듈은 morphology 연산 을 수행하여 부가 정보 영역에서 노이즈를 제거하여 부가 정보 영역에서 텍스트의 특징을 나타내는 특징 맵을 획득할 수 있다. 특징 맵은 부가 정보 영역에서 노이즈가 제거된 형태일 수 있다. 텍스트 정보 획득 모듈는 특징 맵에 대해 horizontal&vertical profiling을 수행할 수 있다. 노이지한 엣 지 정보가 필터링된 엣지 정보 안에는 텍스트의 엣지 정보가 들어 있다. 텍스트 정보 획득 모듈은 텍스트 영역의 위치를 알기 위해서 세로 축으로 각 라인을 프로파일링해서 컴포넌트가 있는 위치를 찾고, 가로 축으로 프로젝션을 수행하여 스페이스를 검출하여 단어 단위를 구분할 수 있다. 이후, 텍스트 정보 획득 모듈은 connected component 분석을 수행할 수 있다. 텍스트 정보 획득 모듈(32 0)은 물체를 구성하는 연결된 픽셀들을 찾고, 픽셀들이 구성하는 윤곽선 간의 관계를 구하고, 서로 다른 물체를 서로 다른 색상 등으로 구별하며, 텍스트가 포함된 영역을 검출할 수 있다. 텍스트가 포함된 영역, 즉 텍스트 영역은 텍스트를 둘러싼, 원이나 타원, 사각형 박스 등과 같은 형태를 갖는 영역일 수 있다. 텍스트 정보 획득 모듈은 텍스트 영역의 위치 정보를 추출할 수 있다. 텍스트 정보 획득 모듈은 텍스트 영역에 OCR(Optical Character Recognition, 광학 문자 인식)을 수행하 여 해당 텍스트가 숫자인지, 단어인지, 또 단어인 경우 어떤 언어의 단어인지, 단어의 폰트가 어떤지 중 적어도 하나를 인식할 수 있다. OCR은 인쇄물 또는 사진 상의 글자와 이미지를 디지털 데이터로 변환해주는 자동인식기 술로, 문자나 숫자의 영상을 컴퓨터가 편집 가능한 문자코드 등의 형식으로 변환할 수 있다. 텍스트 정보 획득 모듈은 인식된 단어를 종류 별로 분류할 수 있다. 텍스트 정보 획득 모듈은 Dictionary를 기반으로 Context 룰을 활용하여 인식된 단어에서 의미 있는 정보들을 추출하여 해당 텍스트를 종 류 별로 분류 할 수 있다. 텍스트의 종류는 채널 명, 채널 번호, 타이틀, 재생 시간, 타이틀 장르, 출연자, 기 타 다양한 부가 정보 중 적어도 하나를 포함할 수 있다. 텍스트 정보 획득 모듈은 텍스트 영역의 위치 정보를 가지고 있고, 그 위치에서 검출된 텍스트가 무엇인지 등을 알 수 있으므로, 각 위치 별로 인식한 텍스트를 종류 별로 분류하여 텍스트 정보를 획득할 수 있다. 컬러 정보 획득 모듈은 부가 정보 영역으로부터 컬러 정보를 획득하는 기능을 수행할 수 있는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함할 수 있다. 부가 정보 영역은 텍스트와 텍스트 외의 배경으로 분리될 수 있다. 컬러 정보 획득 모듈은 부가 정보 영역 에 포함된 텍스트와 배경의 컬러 정보를 획득할 수 있다. 컬러 정보는 텍스트 및 배경 각각의 컬러 특징 및/또 는 텍스트와 배경 간의 컬러 특징을 나타내는 정보일 수 있다. 컬러 정보는 텍스트 및 배경의 색상 분포를 나타 내는 컬러 히스토그램, 컬러 모멘트, 컬러 코히어런스 벡터 등을 포함할 수 있다. 또한 컬러 정보는 텍스트 및 배경의 질감, 색상의 투명도 등과 같은 정보를 포함할 수 있다. 또한 컬러 정보는 배경 대비 텍스트의 컬러 분 포나 색 대비 등과 같은 특성 등을 포함할 수 있다. 스타일 정보 획득 모듈은 텍스트 정보와 컬러 정보로부터 스타일 정보를 획득하는 기능을 수행할 수 있는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함할 수 있다. 스타일 정보 획득 모듈은 텍스트 정보 획득 모듈이 획득한 텍스트 정보와 컬러 정보 획득 모듈이 획득한 컬러 정보를 결합하여 스타일 정보를 획득할 수 있다. 스타일 정보는 영상에서 차지하는 부가 정보 영역의 전체적인 모양이나 느낌, 스타일의 특징을 나타내는 정보로, 영상에서의 부가 정보 영역의 위치나 배치, 부가 정보 영역 내의 텍스트들의 레이아웃 등과 같은 위치 정보를 포함할 수 있다. 또한 스타일 정보는 부가 정보 영역 내의 배경 색상, 배경의 텍스쳐, 배경의 투명도, 배경의 컬러 히스토그램과 같이 배경에 대한 특징 정보를 포함할 수 있다. 또한 스타일 정보는 부가 정보 영역에 포함된 텍스트의 종류나 폰트, 각 텍스트들의 색상, 텍스트 텍스쳐, 텍스 트의 투명도, 텍스트의 컬러 히스토그램 등과 같이 각각의 텍스트 별 스타일 특징 정보를 포함할 수 있다. 스타일 정보 획득 모듈은 추출된 하나 이상의 특징에 대응하는 특징 벡터를 출력할 수 있다. 도 4 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 4의 영상 검출 장치는 프로세서, 메모리, 디스플레이 및 통신부를 포함할 수 있다. 도 4의 영상 검출 장치는 도 2의 영상 검출 장치를 포함하는 장치일 수 있다. 이하, 도 4의 영 상 검출 장치에 포함된 프로세서, 메모리 및 디스플레이는 도 2의 영상 검출 장치에 포함된 프로세서, 메모리, 및 디스플레이와 수행하는 기능이 동일하며, 이에 대한 중복 설명은 생략하기로 한다. 프로세서는 영상 검출 장치의 전반적인 동작을 제어한다. 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 뉴럴 네트워크를 이용하여 디스플레이에서 출력하는 제1 영상으로 부터 부가 정보 영역을 검출하고, 부가 정보 영역으로부터 부가 정보 영역의 스타일 정보를 획득할 수 있다. 실시 예에 따른 통신부는 프로세서의 제어에 따라서 유무선의 네트워크를 통하여 연결되는 외부 장치 와 통신을 수행하여 신호를 송수신할 수 있다. 통신부는 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모 듈, 방송 수신 모듈 등과 같은 적어도 하나의 통신 모듈을 포함할 수 있다. 통신 모듈은 방송 수신을 수행하는 튜너, 블루투스, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), CDMA, WCDMA 등과 같은 통신 규격을 따르는 네트워크를 통하여 데이터 송수신을 수행할 수 있는 통신 모듈을 포함할 수 있다. 실시 예에서, 통신부는 외부의 컴퓨팅 장치와 데이터를 송수신할 수 있다. 컴퓨팅 장치는 영상 검출 장치로부터 스타일 정보를 수신하고, 이를 기반으로 새로운 스타일 정보를 생성 할 수 있는 전자 장치일 수 있다. 컴퓨팅 장치는 새로운 스타일 정보를 갖는 부가 정보 영역을 일반 콘텐트와 합성하여 새로운 영상을 생성하고, 새로운 영상으로부터 부가 정보 영역을 검출하도록 모델을 학습시킬 수 있다. 컴퓨팅 장치는 학습된 모델을 통신부를 통해 영상 검출 장치로 전송할 수 있다. 실시 예에서, 통신부는 컴퓨팅 장치로부터 학습된 모델을 수신할 수 있다. 프로세서는 수신한 모델을 이용하여 뉴럴 네트워크를 업데이트할 수 있다. 프로세서는 업데이트된 뉴럴 네트워크를 이용하여, 이후, 디스플레이에서 제2 영상을 출력할 때, 제2 영상으로부터 이전 스타일 정보와 다른 스타일 정보를 갖는 부 가 정보 영역을 검출할 수 있다. 도 5는 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 5를 참조하면, 도 5의 영상 검출 장치는 프로세서, 메모리, 디스플레이, 통신부 및 뉴럴 네트워크 프로세서를 포함할 수 있다. 도 5의 영상 검출 장치에 포함된 프로세서, 메모리, 디스플레이 및 통신부는 도 4의 영상 검출 장치에 포함된 프로세서, 메모리, 디스플레이 및 통신부와 수행하는 기능 이 동일하며, 이에 대한 중복 설명은 생략하기로 한다. 도 5에 도시된 영상 검출 장치는 도 4에 도시된 영상 검출 장치에 비하여 뉴럴 네트워크 프로세서 을 더 포함할 수 있다. 즉, 도 5의 영상 검출 장치는 도 4의 영상 검출 장치와 달리, 컴퓨팅 장 치가 수행하는 기능을 뉴럴 네트워크 프로세서가 수행할 수 있다. 프로세서는 영상 검출 장치의 전반적인 동작을 제어한다. 프로세서는 메모리에 저장된 하 나 이상의 인스트럭션을 실행함으로써, 영상 검출 장치가 기능하도록 제어할 수 있다. 실시 예에서, 뉴럴 네트워크 프로세서는 뉴럴 네트워크를 통한 연산을 수행할 수 있다. 뉴럴 네트워크 프 로세서는 하나 이상의 인스트럭션을 실행하여 뉴럴 네트워크를 통한 연산이 수행되도록 할 수 있다. 뉴럴 네트워크 프로세서는 프로세서가 획득한 제1 스타일 정보를 학습 데이터로 이용하여 새로운 스 타일 정보를 생성할 수 있다. 뉴럴 네트워크 프로세서는 제1 스타일 정보로부터 부가 정보 영역의 스타일 특성을 획득할 수 있다. 뉴럴 네트워크 프로세서는 획득한 스타일 특성을 이용하여 오버롤한 정보부터 세 밀한 정보까지 획득하고 이들을 합성하여 새로운 스타일 특성을 갖는 이미지를 생성할 수 있다. 뉴럴 네트워크 프로세서는 새로운 스타일을 갖는 부가 정보 영역 이미지를 일반 컨텐트 영역과 합성하여 전체 이미지를 생성하고, 이를 모델의 신규 학습 데이터로 이용하여 모델을 학습시킬 수 있다. 프로세서는 뉴럴 네트워크 프로세서가 생성한 학습 모델로, 기존에 이용하던 뉴럴 네트워크를 업데이 트할 수 있다. 프로세서는 업데이트된 뉴럴 네트워크를 이용하여, 제1 스타일 정보와는 다른 제2 스타일 정보를 갖는 부가 정보 영역을 포함하는 제2 영상으로부터 제2 스타일 정보를 갖는 부가 정보 영역을 검출할 수 있다. 또는 뉴럴 네트워크 프로세서가 학습 모델을 이용하여, 영상으로부터 새로운 스타일의 부가 정보 영역을 검출하는 기능을 수행할 수도 있다. 도 6은 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 6을 참조하면, 영상 검출 장치는 제어 부, 메모리, 디스플레이, 통신부 외에, 튜너부, 감지부, 입/출력부, 비디 오 처리부, 오디오 처리부, 오디오 출력부 및 유저 인터페이스를 더 포함할 수 있다. 도 6의 영상 검출 장치는 도 4의 영상 검출 장치의 구성 요소를 포함할 수 있다. 따라서, 제어부 , 메모리, 디스플레이 및 통신부에 대하여, 도 4에서 설명한 내용과 중복되는 설명은 생략 한다. 또한, 도 6에서는 프로세서 대신 제어부라는 용어를 사용하였으나, 도 6의 제어부는 도 4 의 프로세서와 수행하는 기능이 동일하므로, 동일 부호 410를 이용하여 표기하였다. 튜너부는 유선 또는 무선으로 수신되는 방송 컨텐츠 등을 증폭(amplification), 혼합(mixing), 공진 (resonance)등을 통하여 많은 전파 성분 중에서 영상 검출 장치에서 수신하고자 하는 채널의 주파수만을 튜닝(tuning)시켜 선택할 수 있다. 튜너부를 통해 수신된 컨텐츠는 디코딩(decoding, 예를 들어, 오디오 디코딩, 비디오 디코딩 또는 부가 정보 디코딩)되어 오디오, 비디오 및/또는 부가 정보로 분리된다. 분리된 오 디오, 비디오 및/또는 부가 정보는 제어부의 제어에 의해 메모리에 저장될 수 있다. 통신부는 제어부의 제어에 의해 영상 검출 장치를 외부 장치나 서버와 연결할 수 있다. 영상 검 출 장치는 통신부를 통해 외부 장치나 서버 등으로부터 영상 검출 장치가 필요로 하는 프로그램 이나 어플리케이션(application)을 다운로드하거나 또는 웹 브라우징을 할 수 있다. 실시 예에서, 통신부 는 외부의 컴퓨팅 장치로 제어부가 획득한 스타일 정보를 전송하고, 컴퓨팅 장치로부터 신규 데이터를 학 습한 뉴럴 네트워크 모델을 수신할 수 있다. 통신부는 영상 검출 장치의 성능 및 구조에 대응하여 무선 랜, 블루투스, 및 유선 이더넷 (Ethernet) 중 하나를 포함할 수 있다. 또한, 통신부는 무선랜, 블루투스, 및 유선 이더 넷(Ethernet)의 조합을 포함할 수 있다. 통신부는 제어부의 제어에 의해 리모컨 등과 같은 제어 장치(미도시)를 통한 제어 신호를 수신할 수 있다. 제어 신호는 블루투스 타입, RF 신호 타입 또는 와이파이 타 입으로 구현될 수 있다. 통신부는 블루투스 외에 다른 근거리 통신(예를 들어, NFC(near field communication, 미도시), BLE(bluetooth low energy, 미도시)를 더 포함할 수 있다. 실시 예에 따라, 통신부 는 블루투스나 BLE와 같은 근거리 통신을 통하여 외부 장치 등과 연결 신호를 송수신할 수도 있다. 감지부는 사용자의 음성, 사용자의 영상, 또는 사용자의 인터랙션을 감지하며, 마이크, 카메라부 , 및 광 수신부를 포함할 수 있다. 마이크는 사용자의 발화(utterance)된 음성을 수신할 수 있 고 수신된 음성을 전기 신호로 변환하여 제어부로 출력할 수 있다. 카메라부는 센서(미도시) 및 렌즈(미도시)를 포함하고, 화면에 맺힌 이미지를 촬영할 수 있다. 광 수신부는, 광 신호(제어 신호를 포함)를 수신할 수 있다. 광 수신부는 리모컨이나 핸드폰 등과 같 은 제어 장치(미도시)로부터 사용자 입력(예를 들어, 터치, 눌림, 터치 제스처, 음성, 또는 모션)에 대응되는 광 신호를 수신할 수 있다. 수신된 광 신호로부터 제어부의 제어에 의해 제어 신호가 추출될 수 있다. 입/출력부는 제어부의 제어에 의해 컨텐트 프로바이더들이 제공하는 외부의 데이터베이스나 서버 등 으로부터 비디오(예를 들어, 동영상 신호나 정지 영상 신호 등), 오디오(예를 들어, 음성 신호나, 음악 신호 등) 및 부가 정보(예를 들어, 컨텐츠에 대한 설명이나 컨텐츠 타이틀, 컨텐츠 저장 위치) 등을 수신할 수 있다. 여기서 부가 정보는 컨텐트에 대한 메타데이터를 포함할 수 있다. 입/출력부는 HDMI 포트(High-Definition Multimedia Interface port, 641), 컴포넌트 잭(component jack, 642), PC 포트(PC port, 643), 및 USB 포트(USB port, 644) 중 하나를 포함할 수 있다. 입/출력부는 HDMI 포트, 컴포넌트 잭, PC 포트, 및 USB 포트의 조합을 포함할 수 있다. 비디오 처리부는, 디스플레이에 의해 표시될 영상 데이터를 처리하며, 영상 데이터에 대한 디코딩, 렌더링, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 및 해상도 변환 등과 같은 다양한 영상 처리 동작을 수 행할 수 있다. 오디오 처리부는 오디오 데이터에 대한 처리를 수행한다. 오디오 처리부에서는 오디오 데이터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 오디오 출력부는 제어부의 제어에 의해 튜너부를 통해 수신된 컨텐츠에 포함된 오디오, 통신부 또는 입/출력부를 통해 입력되는 오디오, 메모리에 저장된 오디오를 출력할 수 있다. 오디오 출력부는 스피커, 헤드폰 출력 단자 또는 S/PDIF(Sony/Philips Digital Interface: 출력 단자 중 적어도 하나를 포함할 수 있다. 실시 예에 따른 유저 인터페이스는 영상 검출 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 유저 인터페이스는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch), 음성 인식을 위한 마이크, 모션을 센싱하는 모션 감지 센서 등을 포함하는 다양한 형태의 사용자 입력 디바이스를 포함할 수 있으나 이에 제한되 지 않는다. 또한, 영상 검출 장치가 원격 제어 장치(remote controller)(미도시)에 의해서 조작되는 경우, 유저 인터페이스는 원격 제어 장치로부터 수신되는 제어 신호를 수신할 수도 있을 것이다. 실시 예에 따라, 사용자는 유저 인터페이스를 통하여 영상 검출 장치를 제어하여 영상 검출 장치 의 여러 기능들이 수행되도록 할 수 있다. 사용자는 유저 인터페이스를 이용하여 영상 검출 장치 로 특정 컨텐트를 선택하거나 채널을 변경할 수 있다. 도 7은 실시 예에 따라, 부가 정보 영역의 스타일 정보를 이용하여 새로운 스타일 정보를 갖는 부가 정보 영역 을 생성하는 이미지 생성 모델을 설명하기 위한 도면이다. 실시 예에서, 도 7의 이미지 생성 모델은 도 1의 컴퓨팅 장치나 도 5의 뉴럴 네트워크 프로세서(55 0)에 포함될 수 있다. 도 7을 참조하면, 이미지 생성 모델은 웨이트 생성부 및 이미지 생성부를 포함할 수 있다. 실시 예에서, 이미지 생성 모델은 Style-based GAN(Generative Adversarial Network)일 수 있다. Style- based GAN은 이미지를 스타일의 조합으로 보고, generator의 각 레이어(layer) 마다 스타일 정보를 입히는 방식 으로 이미지를 합성하는 모델이다. 도 7에서, 웨이트 생성부는 래턴 벡터(latent vector, 730)와 특징 벡터를 입력 받을 수 있다. 래턴 벡터는 단순하게 균등 분포(Uniform Distribution)나 정규 분포(Normal Distribution)에서 무작위로 추출 된 값이다. 래턴 벡터가 존재하는 공간을 잠재 공간(Latent Space)이라고 부른다. 잠재 공간의 크기는 임의로 결정될 수 있고, 예를 들어, 100차원으로 결정될 수 있다. 잠재 공간의 크기에는 제한이 없으나 나타내려고 하 는 대상의 정보를 충분히 담을 수 있을 만큼은 커야 한다. 특징 벡터는 영상 검출 장치가 획득한 스타일 정보에 대응하는 벡터일 수 있다. 웨이트 생성부는 매핑 네트워크(mapping network)를 포함할 수 있다. 매핑 네트워크는 비선형으로, 특징들 사이의 편중된 상관관계를 줄여 줄 수 있다. 매핑 네트워크는 복수 개의 레이어들을 포함할 수 있다. 각 레이어 들은 적어도 하나의 노드로 표현될 수 있고, 계층 간 노드들은 엣지로 연결된다. 노드들은 이전 및 이후의 레이 어들에 포함된 노드들과 완전 연결(Fully Connected)되어 있을 수 있다. 웨이트 생성부는 입력된 정보를 매핑 네트워크에 통과시켜 중간 벡터를 획득할 수 있다. 중간 벡터는 스타 일 특징을 담고 있는 웨이트일 수 있다. 웨이트 생성부는 래턴 벡터와 특징 벡터를 연결 (concatenation)시켜 특징 벡터에 대응하는 스타일 특징을 갖는 웨이트를 획득할 수 있다. 예를 들어, 스타일 정보로부터 추출된 특징 벡터가 검정색을 나타내는 컬러 정보에 대응하는 특징에 관한 것이면, 웨이 트 생성부는 이러한 검정색의 색상 정보 특징을 갖는 중간 벡터를 생성할 수 있다. 예를 들어, 스타일 정 보로부터 추출된 특징 벡터가 특정한 폰트를 갖는 텍스트의 윤곽을 나타내는 에지 정보에 대응하는 특징에 관한 것이면, 웨이트 생성부는 이러한 윤곽 에지 정보의 특징을 갖는 중간 벡터를 생성할 수 있다. 웨이트 생성부는 생성한 중간 벡터를 이미지 생성부로 보낸다. 이미지 생성부는 복수의 레이어들을 포함하여 각 레이어 마다 스타일 정보를 입히는 방식으로 이미지를 합 성하는 모델이다. 이미지 생성부는 텐서(tensor)를 입력 받을 수 있다. 텐서는 딥러닝 모델의 정보를 담고 있는 데이터 스트 럭쳐일 수 있다. 텐서는 학습 데이터들의 스타일이 반영되지 않은 베이스 이미지로, 평균적인 이미지를 표현하 는 정보일 수 있다. 실시 예에서, 텐서는 기본 스타일을 갖는 부가 정보 영역의 레이아웃을 의미할 수 있다. 이미지 생성부에는 4X4X512의 텐서로 시작해서 1024X1024X3으로 끝나는 복수 개의 레이어들을 포함할 수 있다. 각 레이어들은 컨벌루션, 업샘플링을 통해 다음 레이어로 연결될 수 있다. 이미지 생성부는 각 컨벌 루션 레이어 이후마다 Adaptive Instance Normalization (AdaIN)을 통해 스타일을 입힐 수 있다. 중간 벡터, 즉, 웨이트는 이미지 생성부에 입력되어, 이미지 생성부에 포함된 모든 레이어들에 대한 스타일을 표현하도록 학습될 수 있다. 웨이트는 이미지 생성부의 각각의 레이어들로 입력될 수 있다. 계층 의 깊이가 얕을수록 이미지의 하위 레벨 특징, 즉, coarse한 특징들이 추출되고, 계층의 깊이가 깊어질수록 디 테일한 상위 레벨 특징이 추출될 수 있다. 이미지 생성부는 하위 레벨부터 상위 레벨에서 획득한 특징들을 적절히 결합하여 결과 이미지를 획득할 수 있다. 결과 이미지는 새로운 스타일의 부가 정보 영역 이미지일 수 있다. 이미지 생성부는 각 레이어 마다 랜덤 노이즈를 추가하여 이미지를 더욱 디테일하고 다양하게 생성할 수 있다. 이와 같이, 실시 예에 의하면, 컴퓨팅 장치나 뉴럴 네트워크 프로세서는 이미지 생성 모델을 이용하 여 영상 검출 장치가 획득한 스타일 정보를 학습 데이터로 이용하여, 새로운 스타일 정보를 갖는 부가 정 보 영역을 생성할 수 있다. 도 8은 실시 예에 따라 뉴럴 네트워크(neural network)가 입력 데이터로부터 부가 정보 영역을 검출하는 방법을 학습하는 것을 설명하기 위한 도면이다. 도 8을 참조하면, 뉴럴 네트워크는 학습 데이터를 획득하고 이를 입력 값으로 하여 학습 모델을 획득 할 수 있다. 뉴럴 네트워크는 복수의 학습 데이터가 입력된 것에 응답하여, 복수의 학습 데이터로부터 부 가 정보 영역을 검출하는 방법을 학습할 수 있으며, 학습된 결과에 기초하여 학습 모델을 생성할 수 있다. 실시 예에서, 학습 데이터는 다양한 컨텐트 프로바이더들이 제공하는, 채널이 변경될 때 컨텐트와 함께 출력되 는 부가 정보 영역의 이미지 등을 포함할 수 있다. 또한, 실시 예에서, 학습 데이터는 영상 검출 장치에서 획득된 스타일 정보를 이용하여 생성될 수 있다. 예컨대, 학습 데이터는 도 7에서 설명한 이미지 생성 모델에 의해 생성된, 새로운 스타일 정보를 갖는 부가 정 보 영역을 이용하여 획득된 이미지로부터 획득될 수 있다. 새로운 스타일 정보를 갖는 부가 정보 영역은 일반적인 컨텐트 영역과 합성되어 하나의 이미지로 생성될 수 있 다. 뉴럴 네트워크는 새로운 스타일의 부가 정보 영역을 포함하는 이미지를 학습 데이터로 이용할 수 있다. 실시 예에서, 학습 데이터는 복수의 영상 검출 장치들로부터 획득된 복수의 스타일 정보로부터 생성된, 다양하 고 새로운 스타일의 부가 정보 영역들이 컨텐트와 함께 포함되어 생성된 이미지를 포함할 수 있다. 여기서, 학습 모델은 뉴럴 네트워크를 통하여 목적하는 결과를 획득될 수 있도록 하는, 학습된 뉴럴 네트워크 자체가 될 수 있다. 구체적으로, 부가 정보 영역 검출을 위하여, 복수의 학습 이미지를 이용하여 뉴럴 네트워크를 훈련(training)하여, 뉴럴 네트워크를 형성하는 복수개의 노드(node)들 각각에 적용되는 복수개의 가중치(weight)의 값을 설정할 수 있다. 여기서, 가중치는 뉴럴 네트워크의 각 노드들 간의 연결 강도를 의미할 수 있다. 가중치 값은 반복적인 학습을 통하여 최적화될 수 있으며, 결과의 정확도가 소정의 신 뢰도를 만족할 때까지 반복적으로 수정될 수 있다. 학습 모델은 최종적으로 설정된 가중치 값들에 의해서 형성된 뉴럴 네트워크가 될 수 있다. 일부 실시 예에 따르면, 하나 이상의 뉴럴 네트워크를 이용하여 이미지로부터 부가 정보 영역을 검출하는 방법을 학습하는 동작은, 사전에 수행될 수 있다. 또한, 복수의 학습 이미지 중 일부가 변경됨에 따라, 학습 모 델이 업데이트될 수 있다. 즉, 사용자가 영상 검출 장치를 통해 컨텐트를 시청함에 따라, 시청한 컨 텐트로부터 추출된 부가 정보 영역의 스타일 정보로부터 생성된 새로운 스타일 정보를 갖는 이미지를 학습 이미 지로 사용될 수 있다. 또한, 소정의 주기 단위로, 새로운 학습 이미지가 사용될 수 있다. 새로운 학습 이미지가 추가되면, 하나 이상의 뉴럴 네트워크는 이미지로부터 부가 정보 영역을 검출하는 방법을 다시 학습할 수 있으며, 이에 따라 학습 모델이 업데이트될 수 있다. 하나 이상의 뉴럴 네트워크를 이용하여 이미지로부터 부가 정보 영역을 검출하는 방법을 학습하는 동작은, 컴퓨팅 장치에서 수행될 수 있다. 예를 들어, 하나 이상의 뉴럴 네트워크를 이용하여 이미지로부터 부가 정보 영역을 검출하는 방법을 학습하는 동작은, 상대적으로 복잡한 연산량을 필요로 할 수 있다. 이에 따 라, 외부의 컴퓨팅 장치가 학습하는 동작을 수행하고, 영상 검출 장치는 외부 컴퓨팅 장치로부 터 학습 모델을 수신함으로써, 영상 검출 장치에서 수행되어야 하는 연산량을 줄일 수 있다. 영상 검 출 장치는, 학습 모델을 외부 서버로부터 수신하여 메모리에 저장하고, 저장된 학습 모델을 이 용하여 이미지로부터 부가 정보 영역을 검출할 수 있다. 또한, 본 개시의 다른 실시 예에서, 도 5의 영상 검출 장치는 뉴럴 네트워크를 통한 학습 동작을 수 행하는 별도의 전용 프로세서인 뉴럴 네트워크 프로세서를 포함할 수 있다. 그리고, 뉴럴 네트워크 프로세 서는 뉴럴 네트워크를 통한 학습을 수행하여, 학습 모델을 결정할 수 있으며, 결정된 학습 모델 을 통하여 부가 정보 영역 검출을 수행할 수 있을 것이다. 도 9는 실시 예에 따라 부가 정보 영역 검출을 수행하는 뉴럴 네트워크를 설명하기 위한 일 도면이다. 도 9는, 실시 예에서 이용되는 뉴럴 네트워크를 예시적으로 도시한다. 컴퓨팅 장치, 또는 뉴럴 네트워크 프로세서는 CNN(Convolution Neural Network), DCNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 신경망(미도시) 등을 이용하여, 출력 데이터를 생성할 수 있다. DCNN, 및 캡스넷 또한 CNN 기반의 신경망일 수 있다. CNN 기반 신경망은 이미지에 포함되는 정보들끼리의 상관 관계가 지역적(local)한 경우, 특정 지역만을 비추는 필터의 개념을 도입하고 이 필터 내에서의 정보들을 컨볼루션(convolution)하여 출력 데이터를 생성할 수 있다. 도 9는 CNN 기반의 신경망을 도시한다. 구체적으로, 도 9는 복수개의 계층들을 포함하여 복수의 심도 (depth)를 갖는 DCNN(Deep Convolution Neural Network)을 도시한다. 컴퓨팅 장치는 CNN 기반의 신 경망을 통하여 영상에서 부가 정보 영역을 객체로 인식하고 그 결과를 출력할 수 있다. 실시 예에서, CNN 기반의 신경망의 입력층(input layer)으로 새로운 스타일 정보를 갖는 부가 정보 영역이 포함된 이미지가 입력될 수 있다. CNN 기반의 신경망은 컨볼루션 계층(convolution layer)과 풀링 계층(pooling layer)이 번갈아 가면서 배치되며, 각 계층 필터(filter)의 심도(depth)는 왼쪽에서 오른쪽으로 갈수록 증가하게 된다. 또한, CNN 기반의 신경망의 최종 단은 완전 연결 계층(fully connected layer)로 형성될 수 있다. 컨볼루션 계층(convolution layer)은 컨볼루션 연산에 따라서 생성되는 데이터들의 계층이며, 풀링 계층 (pooling layer)은 서브 샘플링(subsampling) 또는 풀링이라는 연산을 통하여 데이터의 숫자 또는 크기를 줄이 기 위한 계층이다. 컨볼루션 계층(convolution layer)과 풀링 계층(pooling layer)을 통과하면서, 입력된 이미 지의 특징을 나타내는 데이터들이 생성되게 된다. 그리고, 이러한 컨볼루션 계층 및 풀링 계층을 통과하여 생성 된 데이터들을 완전 연결 계층(fully connected layer)으로 형성되는 숨겨진 계층(hidden layer)을 통하여 특 징들로부터 인식되는 객체에 대한 결과 데이터를 출력할 수 있다. 예를 들어, CNN 기반의 신경망은 입력층(input layer), 제1 컨볼루션 계층(convolution layer), 제1 풀링 계층(pooling layer), 제2 컨볼루션 계층(convolution layer), 제2 풀링 계 층(pooling layer), 숨겨진 계층(hidden layer) 및 출력 계층(output layer)을 포함할 수 있다. 여기서, 컨볼루션 계층 및 풀링 계층의 심도(depth)는 가변될 수 있으며, 숨겨진 계층(hidden layer)의 심도도 가변될 수 있다. 또한, 컨볼루션 계층 및 풀링 계층의 심도(depth)가 깊어질수록 보다 정확한 출력 데이 터가 획득될 수 있다. 이는 컨볼루션 계층 및 풀링 계층의 심도(depth)가 깊어질수록 입력된 이미지의 특징들을 나타내는 정보들이 더욱 구체적인 형태를 가지기 때문에 해당 특징들로부터 인식되는 객체 또한 보다 정확히 인 식될 수 있기 때문이다. 또한, 신경망의 심도 및 형태는 결과의 정확도, 결과의 신뢰도, 프로세서의 연산처리 속도 및 용량 등을 고려하여 매우 다양하게 설계될 수 있다. 도 10은 실시 예에 따른 스타일 정보 획득 방법을 도시한 순서도이다. 도 10을 참조하면, 영상 검출 장치는 디스플레이를 통해 출력되는 제1 영상을 캡쳐하고, 캡쳐된 제1 영상 으로부터 부가 정보 영역을 검출할 수 있다(단계 1010). 화면에 출력되는 영상에는 콘텐트 영역, 썸네일 영역, 로고 영역, 부가 정보 영역 중 적어도 하나의 클래스가 포함될 수 있다. 영상 검출 장치는 영상으로부터 여러 종류의 클래스들을 분류하도록 학습된 뉴럴 네트워 크를 이용하여 영상으로부터 기 학습한 것과 유사한 형태나 스타일을 갖는 클래스들을 검출할 수 있다. 영상 검출 장치는 부가 정보 영역을 다른 클래스들과 분리한 후 부가 정보 영역에서 텍스트 영역을 추출할 수 있다. 영상 검출 장치는 텍스트 영역에 대해 OCR를 수행하여 숫자, 단어, 단어의 랭귀지, 폰트 등을 인 식할 수 있다. 영상 검출 장치는 인식된 텍스트를 종류 별로 분류할 수 있다. 텍스트의 종류는 채널 명, 채널 번호, 타이틀, 재생 시간, 기타 정보 중 적어도 하나를 포함할 수 있다. 영상 검출 장치는 인식된 텍 스트의 종류 및 위치를 포함하는 텍스트 정보를 획득할 수 있다(단계 1020). 영상 검출 장치는 부가 정보 영역으로부터 컬러 정보를 획득할 수 있다(단계 1030). 부가 정보 영역은 텍 스트와 텍스트 외의 배경으로 분리될 수 있다. 컬러 정보는 텍스트 및 배경의 컬러나 스타일 특징을 나타내는 정보일 수 있다. 영상 검출 장치는 텍스트 정보와 컬러 정보를 결합하여 스타일 정보를 획득할 수 있다(단계 1040). 스타일 정보는 영상에서 차지하는 부가 정보 영역의 위치나 배치, 부가 정보 영역 내의 배경 색상, 배경의 텍스쳐, 배 경의 투명도, 배경의 컬러 히스토그램, 부가 정보 영역 내의 텍스트들의 레이아웃, 텍스트 종류, 텍스트 폰트, 텍스트 색상, 텍스트 텍스쳐, 텍스트의 투명도, 텍스트의 컬러 히스토그램 중 적어도 하나를 포함할 수 있다. 획득된 스타일 정보는 이미지 생성 모델의 입력 데이터로 입력될 수 있다. 이미지 생성 모델은 스타일 정보를 입력 받고 이로부터 특징을 추출할 수 있다. 이미지 생성 모델은 추출한 특징을 이용하여 새로운 스타일을 갖는 부가 정보 영역 이미지를 생성할 수 있다. 이미지 생성 모델이 생성한 새로운 스타일을 갖는 부가 정보 영역 이미지는 일반 컨텐트 이미지와 결합되어 완 성된 이미지 형태가 될 수 있다. 완성된 이미지는 뉴럴 네트워크의 학습 데이터로 이용되어 부가 정보 영역을 검출하는 모델을 학습시키는 데 사용될 수 있다. 영상 검출 장치는 학습된 모델을 이용하여 제1 영상과는 다른 스타일 정보를 갖는 부가 정보 영역을 포함 한 제2 영상에서, 다른 스타일 정보를 갖는 부가 정보 영역을 검출할 수 있다. 도 11은 실시 예에 따라 영상 검출 장치가 컴퓨팅 장치로부터 모델을 수신하여 부가 정보 영역을 검 출하는 방법을 설명하는 순서도이다. 도 11을 참조하면, 영상 검출 장치는 뉴럴 네트워크를 이용하여, 제1 영상에서 부가 정보 영역을 검출할 수 있다(단계 1110). 영상 검출 장치는 부가 정보 영역으로부터 텍스트 정보 및 컬러 정보를 획득하고 이로부터 부가 정보 영역 의 스타일 정보를 획득할 수 있다(단계 1120). 영상 검출 장치는 획득한 스타일 정보를 컴퓨팅 장치 로 전송할 수 있다(단계 1130). 컴퓨팅 장치는 적어도 하나의 뉴럴 네트워크를 이용하여 입력된 이미지로부터 새로운 이미지를 생성할 수 있다. 컴퓨팅 장치는 영상 검출 장치로부터 전송된 스타일 정보로부터 새로운 스타일 정보를 갖는 부 가 정보 영역 이미지를 획득할 수 있다(단계 1140). 실시 예에서, 컴퓨팅 장치는 Style-based GAN(Generative Adversarial Network)을 이용하여 새로운 이미지를 생성할 수 있다. 컴퓨팅 장치는 스타 일 정보에 대응하는 특징 벡터를 매핑 네트워크에 통과시켜 스타일 특징을 담고 있는 중간 벡터를 획득할 수 있 다. 컴퓨팅 장치는 중간 벡터를 하위 레벨부터 상위 레벨의 레이어들에 각각 입력시키고 각각의 레이어들 로부터 서로 다른 특징들을 획득할 수 있다. 컴퓨팅 장치는 각 레벨에서 획득한 특징들을 적절히 결합하여, 새로운 스타일 정보를 갖는 부가 정보 영역의 이미지를 획득할 수 있다. 컴퓨팅 장치는 새로운 스타일 정보를 갖는 부가 정보 영역을 일반 컨텐트 영역과 결합하여 영상 검출 장치 가 출력하는 형태의 이미지를 획득할 수 있다(단계 1150).컴퓨팅 장치는 적어도 하나의 뉴럴 네트워크를 이용하여, 생성된 영상을 모델의 학습 데이터로 이용할 수 있다. 컴퓨팅 장치는 생성된 영상을 학습 데이터로 입력 받고, 입력된 이미지들을 분류 및 분석하여 특징 을 추출하고, 이로부터 이미지에서 부가 정보 영역을 검출하도록 모델을 학습시킬 수 있다(단계 1160). 컴퓨팅 장치는 학습된 모델을 영상 검출 장치로 전송할 수 있다(단계 1170). 영상 검출 장치는 소정 주기마다, 또는 컴퓨팅 장치가 모델을 새로 학습할 때마다, 컴퓨팅 장치(13 0)로부터 학습된 모델을 수신할 수 있다. 영상 검출 장치는 컴퓨팅 장치로부터 수신한 모델을 이용하여, 기존에 이용하던 뉴럴 네트워크를 업 데이트할 수 있다(단계 1180). 이후, 영상 검출 장치는 기존의 제1 영상과는 다른 스타일의 부가 정보 영역을 갖는 제2 영상이 입력되면, 업데이트된 뉴럴 네트워크를 이용하여, 제2 영상으로부터 다른 스타일 정보를 갖는 부가 정보 영역을 검출할 수 있다(단계 1190). 도 12는 실시 예에 따른 컴퓨팅 장치의 구성을 나타내는 블록도이다. 도 12를 참조하면, 컴퓨팅 장치는 데이터 학습부 및 데이터 인식부를 포함할 수 있다. 데이터 학습부는 영상으로부터 부가 정보 영역을 인식하기 위한 기준을 학습할 수 있다. 데이터 학습부 는 영상으로부터 부가 정보 영역을 검출하기 위해 이미지의 어떤 정보를 이용하는지에 관한 기준을 학습 할 수 있다. 또한, 데이터 학습부는 이미지의 정보를 이용하여 부가 정보 영역을 어떻게 인식하는지에 관 한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 데이터를 획득하고, 획득된 데이터를 후술할 데이터 인식 모델에 적용할 수 있다. 데이터 학습부는 소정 스타일 정보를 갖는 부가 정보 영역이 포함된 이미지를 학습에 이용할 데이터로 이용할 수 있다. 데이터 학습부는 이미지에서 부가 정보 영역의 특징이 나 위치, 배치 등을 검출하는 기준 등을 학습할 수 있다. 데이터 인식부는 학습에 의한 기 설정된 기준에 따라 이미지로부터 부가 정보 영역 등의 클래스를 인식하 고, 인식된 결과를 출력할 수 있다. 데이터 인식부는 학습된 데이터 인식 모델을 이용하여, 소정의 이미 지로부터 부가 정보 영역을 인식할 수 있다. 이미지를 입력 값으로 하여 데이터 인식 모델에 의해 출력된 결과 값은, 데이터 인식 모델을 업데이트하는데 이용될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로 세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각 종 전자 장치에 탑재될 수도 있다. 이 경우, 데이터 학습부 및 데이터 인식부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 하나는 전 자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부 는 유선 또는 무선으로 통신하여, 데이터 학습부가 구축한 모델 정보를 데이터 인식부로 제 공할 수도 있고, 데이터 인식부로 입력된 데이터가 추가 학습 데이터로서 데이터 학습부로 제공될 수도 있다. 한편, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이 터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션(instruction)을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판 독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또 는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 13은 실시 예에 따른 데이터 학습부의 블록도이다. 도 13을 참조하면, 실시 예에 따른 데이터 학습부는 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부를 포함할 수 있다.데이터 획득부는 영상으로부터 부가 정보 영역을 검출하기 위한 학습을 위해 필요한 데이터를 획득할 수 있다. 데이터 획득부는 네트워크를 통해 컴퓨팅 장치에 연결된 적어도 하나의 소셜 네트워크 서버 (social network server), 클라우드 서버(cloud server) 등의 외부 서버나, 데이터베이스로부터 데이터를 획득 할 수 있다. 데이터 획득부는 컨텐트 프로바이더들이 제공하는 데이터를 획득할 수 있다. 전처리부는 영상으로부터 부가 정보를 검출하기 위한 학습에 데이터가 이용될 수 있도록, 획득된 데이터 를 전처리할 수 있다. 전처리부는 후술할 모델 학습부가 영상으로부터 부가 정보 영역을 인식하는 학습을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 예를 들어, 전처리부는, 획득한 데이터 중 중복 데이터를 제거하거나, 가능성이 희박한 데이터를 제거하고, 각 데이터를 벡터화하는 등과 같이 데이터를 기 설정된 포맷으로 가공할 수 있으나, 이에 한정되지 않는다. 학습 데이터 선택부는 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 모델 학습부에 제공될 수 있다. 학습 데이터 선택부는 영상으로부터 부가 정보를 검출하기 위한 기 설정된 기준에 따라, 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 또한, 학습 데이터 선택 부는 후술할 모델 학습부에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 모델 학습부는, 영상으로부터 부가 정보를 검출하기 위해 어떤 학습 데이터를 이용해야 하는지에 대한 기 준을 학습할 수 있다. 모델 학습부는, 영상으로부터 부가 정보를 검출하는데 이용되는 영상 속성들의 종 류, 개수, 수준 등을 학습할 수 있다. 또한, 모델 학습부는, 영상으로부터 부가 정보를 검출하기 위해 이용되는 데이터 인식 모델을 학습 데이 터를 이용하여 학습시킬 수 있다. 이 경우, 데이터 인식 모델은 미리 구축된 모델일 수 있다. 예를 들어, 데이 터 인식 모델은 기본 학습 데이터를 입력 받아 미리 구축된 모델일 수 있다. 데이터 인식 모델은, 인식 모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 데이터 인식 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 데이터 인식 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 다양한 실시 예에 따르면, 모델 학습부는 미리 구축된 데이터 인식 모델이 복수 개가 존재하는 경우, 입 력된 학습 데이터와 기본 학습 데이터의 관련성이 큰 데이터 인식 모델을 학습할 데이터 인식 모델로 결정할 수 있다. 이 경우, 기본 학습 데이터는 데이터의 타입 별로 기 분류되어 있을 수 있으며, 데이터 인식 모델은 데이 터의 타입 별로 미리 구축되어 있을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이터 내의 오 브젝트의 종류 등과 같은 다양한 기준으로 기 분류되어 있을 수 있다. 또한, 모델 학습부는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부는, 예를 들어, 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning) 을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부는, 예를 들어, 별다른 지도 없이 사용 자의 상태를 판단하기 위해 필요한 데이터의 종류를 스스로 학습함으로써, 사용자의 상태를 판단하기 위한 기준 을 발견하는 비지도 학습(unsupervised learning)을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부는, 예를 들어, 학습에 따라 사용자의 상태를 판단한 결과가 올바른지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 데이터 인식 모델이 학습되면, 모델 학습부는 학습된 데이터 인식 모델을 저장할 수 있다. 이 경우, 모델 학습부는 학습된 데이터 인식 모델을 메모리에 저장할 수 있다. 또는, 모델 학습부는 학습된 데이터 인식 모델을 후술할 데이터 인식부를 포함하는 장치의 메모리에 저장할 수 있다. 또는, 모 델 학습부는 학습된 데이터 인식 모델을 전자 장치와 유선 또는 무선 네트워크로 연결되는 서버의 메모리 에 저장할 수도 있다. 이 경우, 학습된 데이터 인식 모델이 저장되는 메모리는, 예를 들면, 장치의 적어도 하나의 다른 구성요소에 관 계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수도 있다. 프로그램은, 예를 들면, 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플리케이 션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다.모델 평가부는 데이터 인식 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 인식 결과가 소 정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데 이터는 데이터 인식 모델을 평가하기 위한 기 설정된 데이터일 수 있다. 예를 들어, 모델 평가부는 평가 데이터에 대한 학습된 데이터 인식 모델의 인식 결과 중에서, 인식 결과 가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 데이터 인식 모델이 총 1000개의 평가 데이터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 인식 결과를 출력하는 경우, 모델 평 가부는 학습된 데이터 인식 모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 데이터 인식 모델이 복수 개가 존재하는 경우, 모델 평가부는 각각의 학습된 데이터 인식 모델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 데이터 인식 모델로서 결정할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부는 평가 점수가 높 은 순으로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 데이터 인식 모델로서 결정할 수 있다. 한편, 데이터 학습부 내의 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습 부 및 모델 평가부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑 재될 수 있다. 예를 들어, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨 어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 실시 예 에서, 전자 장치는 컴퓨팅 장치나 영상 검출 장치 등을 포함할 수 있다. 예를 들어, 데이터 획득부 , 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 일부는 영상 검출 장치에 포함되고 나머지 일부는 컴퓨팅 장치에 포함될 수 있다. 또한, 이 중 일부는 전자 장치 에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부, 전처리부, 학습 데이터 선택부, 모델 학습부 및 모델 평가부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부, 전처리부, 학습 데이 터 선택부, 모델 학습부 및 모델 평가부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭 션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가 능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경 우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머 지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 14은 실시 예에 따른 데이터 인식부의 구성을 나타내는 블록도이다. 도 14를 참조하면, 일부 실시 예에 따른 데이터 인식부는 데이터 획득부, 전처리부, 데이터 선택부, 인식 결과 제공부 및 모델 갱신부를 포함할 수 있다. 데이터 획득부는 영상으로부터 부가 정보 영역을 검출하는데 필요한 데이터를 획득할 수 있다. 전처리부 는 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리부는 후술할 인 식 결과 제공부가 영상으로부터 부가 정보 영역을 검출하기 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 데이터 선택부는 전처리된 데이터 중에서 영상으로부터 부가 정보 영역을 검출하기 위해 필요한 데이터를 선택할 수 있다. 선택된 데이터는 인식 결과 제공부에게 제공될 수 있다. 데이터 선택부는 영상으 로부터 부가 정보 영역을 검출하기 위한 기 설정된 기준에 따라, 전처리된 데이터 중에서 일부 또는 전부를 선 택할 수 있다. 인식 결과 제공부는 선택된 데이터를 데이터 인식 모델에 적용하여 영상으로부터 부가 정보 영역을 검출 할 수 있다. 인식 결과 제공부는 데이터의 인식 목적에 따른 인식 결과를 제공할 수 있다. 인식 결과 제 공부는 데이터 선택부에 의해 선택된 데이터를 입력 값으로 이용함으로써, 선택된 데이터를 데이터인식 모델에 적용할 수 있다. 또한, 인식 결과는 데이터 인식 모델에 의해 결정될 수 있다. 인식 결과 제공부 는, 영상으로부터 부가 정보 영역을 나타내는 식별 정보를 제공할 수 있다. 모델 갱신부는 인식 결과 제공부에 의해 제공되는 인식 결과에 대한 평가에 기초하여, 데이터 인식 모델이 갱신되도록 할 수 있다. 예를 들어, 모델 갱신부는 인식 결과 제공부에 의해 제공되는 인식 결과를 모델 학습부에게 제공함으로써, 모델 학습부가 데이터 인식 모델을 갱신하도록 할 수 있다. 한편, 데이터 인식부 내의 데이터 획득부, 전처리부, 데이터 선택부, 인식 결과 제공 부 및 모델 갱신부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑 재될 수 있다. 예를 들어, 데이터 획득부, 전처리부, 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨 어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부, 전처리부, 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부, 전처리부, 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부, 전처리부, 데이터 선택부, 인식 결과 제공부 및 모델 갱신부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부, 전처리부, 데이터 선 택부, 인식 결과 제공부 및 모델 갱신부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭 션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가 능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경 우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머 지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 일부 실시 예에 따른 컴퓨팅 장치 및 그 동작 방법은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모 두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저 장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 전술한 본 개시의 실시 예에 따른 영상 검출 방법은 뉴럴 네트워크를 이용하여 현재 출력하는 제1 영상으 로부터 부가 정보 영역을 검출하는 단계, 상기 부가 정보 영역으로부터 상기 부가 정보 영역의 스타일 정보를 획득하는 단계 및 상기 스타일 정보에 기초하여 생성된 새로운 스타일 정보를 갖는 부가 정보 영역을 학습한 모 델을 이용하여, 현재 출력하는 제2 영상으로부터 상기 스타일 정보와 다른 스타일 정보를 갖는 부가 정보 영역 을 검출하는 단계를 포함하는, 영상 검출 방법을 수행하는 컴퓨터 프로그램이 저장된 기록매체를 포함하는 컴퓨 터 프로그램 제품으로 구현될 수 있다."}
{"patent_id": "10-2020-0078809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 설명은 예시를 위한 것이며, 발명이 속하는 기술분야의 통상의 지식을 가진 자는 발명의 기술적 사상이 나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한 다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14"}
{"patent_id": "10-2020-0078809", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시 예에 따라 영상 검출 장치가 영상에서 부가 정보 영역을 검출하는 것을 설명하기 위한 도면이 다. 도 2는 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 3은 실시 예에 따라 화면에 출력되는 영상으로부터 스타일 정보를 획득하는 영상 검출 장치의 기능을수행하는 스타일 정보 생성 모듈을 설명하기 위한 블록도이다. 도 4 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 5는 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 6은 실시 예에 따른 영상 검출 장치의 내부 블록도이다. 도 7은 실시 예에 따라, 부가 정보 영역의 스타일 정보를 이용하여 새로운 스타일 정보를 갖는 부가 정보 영역 을 생성하는 이미지 생성 모델을 설명하기 위한 도면이다. 도 8은 실시 예에 따라 뉴럴 네트워크(neural network)가 입력 데이터로부터 부가 정보 영역을 검출하는 방법을 학습하는 것을 설명하기 위한 도면이다. 도 9는 실시 예에 따라 부가 정보 영역 검출을 수행하는 뉴럴 네트워크를 설명하기 위한 일 도면이다. 도 10은 실시 예에 따른 스타일 정보 획득 방법을 도시한 순서도이다. 도 11은 실시 예에 따라 영상 검출 장치가 컴퓨팅 장치로부터 모델을 수신하여 부가 정보 영역을 검 출하는 방법을 설명하는 순서도이다. 도 12는 실시 예에 따른 컴퓨팅 장치의 구성을 나타내는 블록도이다. 도 13은 실시 예에 따른 데이터 학습부의 블록도이다. 도 14은 실시 예에 따른 데이터 인식부의 구성을 나타내는 블록도이다."}
