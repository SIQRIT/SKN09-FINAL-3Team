{"patent_id": "10-2021-0118995", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0036301", "출원번호": "10-2021-0118995", "발명의 명칭": "YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템 및 그 방법", "출원인": "순천향대학교 산학협력단", "발명자": "조정호"}}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "CNN 기반의 YOLO 객체 탐지 알고리즘을 이용하여 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-heldtrash) 객체 및 버려진 쓰레기(ground-trash) 객체로 분류하여 각 객체의 경계상자를 탐지하는 단계;상기 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간 경계상자의 이동 경로를 실시간으로 추적하는 단계;상기 추적되는 경계상자의 이동 경로에 따라 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash)객체 간의 경계상자의 겹침 영역 넓이 및 이동 거리를 연산하는 단계; 및 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역넓이 변화 또는 이동 거리 변화를 검출하여 변화 값에 대응하여 쓰레기 투기로 판단하는 단계;를 포함하는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 방법."}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 각 객체의 경계상자를 탐지하는 단계는,반사율 및 거리 정보를 포함하는 PCD(Point Cloud Data)와 영상 데이터에 기초하여 객체를 사람(person), 사람이 들고 있는 쓰레기(hand-held trash) 및 버려진 쓰레기(ground-trash)로 분류하여 YOLO 기반의 객체 탐지 학습을 각각 수행하는 단계; PCD와 영상 데이터에 기초하여 학습된 각각의 객체 탐지 모델에서의 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 경계상자와 신뢰도 점수를 예측하는 단계; 및 객체 탐지 결과를 융합하기 위해 경계상자의 좌표를 각각 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 신뢰도 점수를 기반으로 가중평균을 통해 최종경계상자를 결정하는 단계를 포함하는 것을 특징으로 하는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 방법."}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 쓰레기 투기로 판단하는 단계에서,상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역넓이가 기 설정 값 이하로 감소되면 쓰레기 투기로 판단하는 것을 특징으로 하는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 방법."}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 쓰레기 투기로 판단하는 단계에서,상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 이동 거리공개특허 10-2023-0036301-3-가 기 설정된 값 이상이면 쓰레기 투기로 판단하는 것을 특징으로 하는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 방법."}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "CNN 기반의 YOLO 객체 탐지 알고리즘을 이용하여 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-heldtrash) 객체 및 버려진 쓰레기(ground-trash) 객체로 분류하여 각 객체의 경계상자를 탐지하는 객체 탐지부;상기 객체 탐지부에서 탐지되는 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간 경계상자의 이동 경로를 실시간으로 추적하는 추적부;상기 추적부에서 추적되는 경계상자의 이동 경로에 따라 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 및 이동 거리를 연산하는 연산부; 및 상기 연산부에서 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 변화 또는 이동 거리 변화를 검출하여 변화 값에 대응하여 쓰레기 투기로 판단하는 판단부;를 포함하는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템."}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 객체 탐지부는,카메라로부터 반사율 및 거리 정보를 포함하는 PCD(Point Cloud Data)와 영상 데이터에 기초하여 객체를 사람(person), 사람이 들고 있는 쓰레기(hand-held trash) 및 버려진 쓰레기(ground-trash)로 분류하여 YOLO 기반의 객체 탐지 학습을 각각 수행하는 학습부; PCD와 영상 데이터에 기초하여 학습된 각각의 객체 탐지 모델에서의 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 경계상자와 신뢰도 점수를 예측하는 예측부; 및 객체 탐지 결과를 융합하기 위해 경계상자의 좌표를 각각 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 신뢰도 점수를 기반으로 가중평균을 통해 최종경계상자를 결정하는 결정부;를 포함하는 것을 특징으로 하는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시시스템."}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 판단부에서,상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역넓이가 기 설정 값 이하로 감소되면 쓰레기 투기로 판단하는 것을 특징으로 하는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템."}
{"patent_id": "10-2021-0118995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5 항에 있어서,상기 판단부에서,상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 이동 거리가 기 설정된 값 이상이면 쓰레기 투기로 판단하는 것을 특징으로 하는 YOLO기반 객체탐지를 통한 쓰레기 무단공개특허 10-2023-0036301-4-투기 감시 시스템."}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 방법은, CNN 기반의 YOLO 객체 탐 지 알고리즘을 이용하여 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기 (ground-trash) 객체로 분류하여 각 객체의 경계상자를 탐지하는 단계; 상기 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간 경계상자의 이동 경로를 실시간으로 추적하는 단계; 상기 추적되는 경계 상자의 이동 경로에 따라 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 및 이동 거리를 연산하는 단계; 및 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기 (hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 변화 또는 이동 거리 변화를 검출하여 변화 값에 대응 하여 쓰레기 투기로 판단하는 단계;를 포함하는 점에 그 특징이 있다."}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템 및 그 방법에 관한 것으로, 특히 쓰레기 무 단투기 감시를 위해 복잡도가 낮은 CNN 기반의 객체 탐지 모델을 적용함으로써 연산량이 감소하여 시스템 구축 을 간소화할 수 있는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에는, 폐기물관리법이 제정되어 실행됨에 따라, 쓰레기를 버릴 때에는 지정된 종량제 봉투에 쓰레기를 담아 서 지정된 장소에 버리도록 되어 있다. 그러나 여전히 일부 사람들은 쓰레기를 버릴 때 지정된 종량제 봉투를 이용하고 있지 않으며, 미지정된 장소에 무단으로 쓰레기를 버리는 경우가 상당히 많은 실정이다. 이로 인해, 쓰레기를 수거하여 처리하거나 관리하는데 비용이 많이 소요될 뿐만 아니라 주변 이웃 사람들에게 많은 피해를 주게 되는 문제점이 있다. 이러한 문제점을 해결하기 위하여 종래에는 쓰레기 상습 불법투기 지역에 쓰레기를 무단으로 투기하지 말라는 경고문구가 게재된 안내판을 부착하였으나, 경고문구를 무시한 채 쓰레기를 무단으로 투기하는 경우가 빈번하게 발생되었다. 또한, 쓰레기 무단 투기를 방지하고자 CCTV를 이용하여 쓰레기를 무단 투기하고 있는 사람에게 경고문구와 CCTV 를 통해 촬영된 투기 영상을 함께 보여줄 수 있게 됨으로써, 쓰레기를 무단 투기하고 있는 사람의 경각심을 일 깨울 수 있도록 제공하였다. 최근에는 인공지능 기술을 접목한 CCTV 녹화 영상을 딥러닝으로 분석하는 기술을 통해 쓰레기 투기를 감시하는 것도 제안되고 있다. 이러한 딥러닝 기반의 이미지 데이터 분류, 특정 객체 탐지를 위해 공간적 특징을 추출하는 CNN(Convolutional Neural Network), 시계열 데이터에서 시간에 따른 변화를 시간적 특징으로 추출하는 RNN(Recurrent Neural Network)으로 결합한 CRNN을 활용하여 영상에서 투기 행위를 감지하였다. CRNN 은 연속된 프레임으로 구성된 영상 데이터에서 일정 간격의 프레임을 시간 순서에 따라 추출하여 CNN을 통 해 공간적 특징을 추출하고, 추출된 특징을 RNN에 입력하여 시간 변화에 따른 움직임 패턴을 분석하게 된다. CRNN은 딥러닝 기술 이전의 컴퓨터 비전 기반 알고리즘 대비 향상된 행동 인식 성능을 가지지만, 모델의 복잡성 과 긴 데이터 처리 시간으로 인해 CCTV와 직접 연결된 임베디드 시스템에서 실시간으로 운용되기에는 한계가 있 다. CRNN을 적용하여 쓰레기 투기를 감지하기 위해서는 관제 센터의 고사양 서버 PC로 다수의 CCTV 영상을 전송해야 하며 영상 데이터의 높은 용량으로 인해 추가적인 서버 구축 비용이 발생되는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국특허출원 제10-2020-0060677 호"}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 쓰레기 무단투기 감시를 위해 복잡도가 낮은 CNN 기반의 객체 탐지 모델을 적용함으로써 연산량이 감 소하여 시스템 구축을 간소화할 수 있는 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템 및 그 방법을 제공하는 것을 목적으로 한다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기 술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 일 실시 예에 따른 YOLO기반 객체탐지를 통 한 쓰레기 무단투기 감시 방법은, CNN 기반의 YOLO 객체 탐지 알고리즘을 이용하여 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체로 분류하여 각 객체의 경계상자 를 탐지하는 단계; 상기 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간 경계상자의 이동 경로를 실시간으로 추적하는 단계; 상기 추적되는 경계상자의 이동 경로에 따라 사람(person) 객체와 사람 이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 및 이동 거리를 연산하는 단계; 및 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 변화 또는 이동 거리 변화를 검출하여 변화 값에 대응하여 쓰레기 투기로 판단하는 단계;를 포함하는 점에 그 특징이 있다. 여기서, 특히 상기 각 객체의 경계상자를 탐지하는 단계는, 반사율 및 거리 정보를 포함하는 PCD(Point Cloud Data)와 영상 데이터에 기초하여 객체를 사람(person), 사람이 들고 있는 쓰레기(hand-held trash) 및 버려진 쓰레기(ground-trash)로 분류하여 YOLO 기반의 객체 탐지 학습을 각각 수행하는 단계; PCD와 영상 데이터에 기 초하여 학습된 각각의 객체 탐지 모델에서의 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객 체 및 버려진 쓰레기(ground-trash) 객체에 대한 경계상자와 신뢰도 점수를 예측하는 단계; 및 객체 탐지 결과 를 융합하기 위해 경계상자의 좌표를 각각 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 신뢰도 점수를 기반으로 가중평균을 통해 최종 경계상자를 결정하 는 단계를 포함하는 점에 그 특징이 있다. 여기서, 특히 상기 쓰레기 투기로 판단하는 단계에서, 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레 기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이가 기 설정 값 이하로 감소되면 쓰레기 투기로 판단 하는 점에 그 특징이 있다. 여기서, 특히 상기 쓰레기 투기로 판단하는 단계에서, 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레 기(hand-held trash) 객체 간의 경계상자의 이동 거리가 기 설정된 값 이상이면 쓰레기 투기로 판단하는 점에 그 특징이 있다. 또한, 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 일 실시 예에 따른 YOLO기반 객체탐 지를 통한 쓰레기 무단투기 감시 시스템은, CNN 기반의 YOLO 객체 탐지 알고리즘을 이용하여 사람(person) 객 체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체로 분류하여 각 객체 의 경계상자를 탐지하는 객체 탐지부; 상기 객체 탐지부에서 탐지되는 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간 경계상자의 이동 경로를 실시간으로 추적하는 추적부; 상기 추적부에서 추적 되는 경계상자의 이동 경로에 따라 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 및 이동 거리를 연산하는 연산부; 및 상기 연산부에서 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 변화 또는 이동 거리 변화를 검출하여 변화 값에 대응하여 쓰레기 투기로 판단하는 판단부;를 포함하는 점에 그 특징이 있다. 여기서, 특히 상기 객체 탐지부는, 카메라로부터 반사율 및 거리 정보를 포함하는 PCD(Point Cloud Data)와 영 상 데이터에 기초하여 객체를 사람(person), 사람이 들고 있는 쓰레기(hand-held trash) 및 버려진 쓰레기 (ground-trash)로 분류하여 YOLO 기반의 객체 탐지 학습을 각각 수행하는 학습부; PCD와 영상 데이터에 기초하 여 학습된 각각의 객체 탐지 모델에서의 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 경계상자와 신뢰도 점수를 예측하는 예측부; 및 객체 탐지 결과를 융합하기 위해 경계상자의 좌표를 각각 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및버려진 쓰레기(ground-trash) 객체에 대한 신뢰도 점수를 기반으로 가중평균을 통해 최종 경계상자를 결정하는 결정부;를 포함하는 점에 그 특징이 있다. 여기서, 특히 상기 판단부에서, 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이가 기 설정 값 이하로 감소되면 쓰레기 투기로 판단하는 점에 그 특징이 있다. 여기서, 특히 상기 판단부에서, 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 이동 거리가 기 설정된 값 이상이면 쓰레기 투기로 판단하는 점에 그 특징이 있다."}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 쓰레기 무단투기 감시를 위해 복잡도가 낮은 CNN 기 반의 객체 탐지 모델을 적용함으로써 연산량이 감소하여 시스템 구축을 간소화할 수 있다."}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해 도면에서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한, 도면 을 참고하여 설명하면서, 같은 명칭으로 나타낸 구성일지라도 도면에 따라 도면 번호가 달라질 수 있고, 도면 번호는 설명의 편의를 위해 기재된 것에 불과하고 해당 도면 번호에 의해 각 구성의 개념, 특징, 기능 또는 효 과가 제한 해석되는 것은 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 본 명세서에 있어서 '부(部)' 또는 '모듈'이란, 하드웨어 또는 소프트웨어에 의해 실현되는 유닛(unit), 양방을 이용하여 실현되는 유닛을 포함하며, 하나의 유닛이 둘 이상의 하드웨어를 이용하여 실현되어도 되고, 둘 이상 의 유닛이 하나의 하드웨어에 의해 실현되어도 된다. 도 1은 본 발명의 일 실시예에 따른 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템의 구성을 개략적으 로 도시한 도면이고, 도 2는 상기 도 1의 객체 탐지부의 구성을 개략적으로 도시한 도면이다. 도 1에 도시된 바와 같이, 본 발명에 따른 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템은, CCTV 카메라, 객체 탐지부, 추적부, 연산부 및 판단부를 포함하여 구성된다. 카메라는 일반적인CCTV RGB 카메라로 기본적으로 사람의 시각과 유사하게 사물의 형태와 색상을 인식하여 객체 탐지 성능에 적합할 수 있다. 여기서, 카메라는 사물로부터 반사된 가시광선을 영상 데이터로 나타내 기 때문에 조명, 날씨, 사물의 잘림 등의 외부환경적 요인에 취약하고, 카메라를 통해 탐지한 객체의 정확한 3 차원 거리 정보를 획득하기에는 어려움이 있기 때문에 객체 탐지의 성능을 높이기 위해 라이다(Light Detection And Ranging; LiDAR)(미도시)를 카메라와 함께 사용한다. 상기 객체 탐지부는 CNN 기반의 YOLO 객체 탐지 알고리즘을 이용하여 사람(person) 객체, 사람이 들고 있 는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체로 분류하여 각 객체의 경계상자를 탐지 한다. 보다 구체적으로, 상기 객체 탐지부의 구성에 대해 설명하기로 한다. 도 2에 도시된 바와 같이, 상기 객체 탐지부는 학습부, 예측부 및 결정부로 구성될 수 있 다. 상기 학습부는 카메라로부터 반사율 및 거리 정보를 포함하는 PCD(Point Cloud Data)와 영상 데이터에 기 초하여 객체를 사람(person), 사람이 들고 있는 쓰레기(hand-held trash) 및 버려진 쓰레기(ground-trash)로 분류하여 YOLO 기반의 객체 탐지 학습을 각각 수행하게 된다. 보다 구체적으로, 상기 학습부는 RGB 카메라의 시야각과 동일한 전면뷰로 투영하는 변환과정을 통해 PCD의 차원과 좌표계를 영상 데이터와 같은 2차원 픽셀 좌표계로 변환하는 전처리 수행 후, 영상 데이터, 깊이 맵, 반 사율 맵으로 분류된 데이터에 기초하여 각각의 객체 탐지 모델을 통해 학습을 수행한다. 본 발명의 실시예에 따른 YOLO는 입력된 이미지 내부의 객체에 대한 경계상자의 예측과 분류를 동시에 실행한다. YOLO에 입력되는 영상 데이터는 해상도에 따라 격자 구역으로 나뉘고 CNN 구조의 신경망을 통해 특징 이 추출되며, 완전 연결 노드를 통해 예측 텐서가 출력된다. 상기 예측부는 PCD와 영상 데이터에 기초하여 학습된 각각의 객체 탐지 모델에서의 사람(person) 객체, 사 람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 경계상자와 신뢰도 점수를 예측하게 된다. 다시 말해, 상기 예측부는 학습된 각각의 객체 탐지 모델의 객체 탐지 결과는 경계상자의 기하학적 정보와 탐지된 객체가 실제값과 일치하는지 정도를 나타내는 신뢰도를 반영하여 객체가 분류된 확률의 신뢰도 점수를 예측한다. 상기 결정부는 객체 탐지 결과를 융합하기 위해 경계상자의 좌표를 각각 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 신뢰도 점수를 기반으로 가중 평균을 통해 최종 경계상자를 결정하게 된다. 여기서, 상기 결정부는 각각의 객체 탐지 모델에서의 객체에 대한 경계상자들의 신뢰도 점수에 따라 가중 된 평균값을 갖고, 각각의 경계상자의 기하학적 정보만을 기초로 하여 하나의 경계상자로 융합하게 된다. 한편, 상기 추적부는 상기 객체 탐지부에서 탐지되는 사람(person) 객체와 사람이 들고 있는 쓰레기(hand- held trash) 객체 간 경계상자의 이동 경로를 실시간으로 추적하게 된다. 상기 연산부는 상기 추적부에서 추적되는 경계상자의 이동 경로에 따라 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 및 이동 거리를 연산하게 된다. 상기 판단부은 상기 연산부에서 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 변화 또는 이동 거리 변화를 검출하여 변화 값에 대응하여 쓰레기 투기로 판단하게 된다. 보다 구체적으로, 상기 판단부에서, 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이가 기 설정 값 이하로 감소되면 쓰레기 투기로 판단하게 된다. 또한, 상기 판단부에서 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 이동 거리가 기 설정된 값 이상이면 쓰레기 투기로 판단하게 된다. 한편, 도 3은 YOLO기반 객체탐지를 통한 쓰레기 무단투기 알고리즘의 간략한 처리 블록도를 도시한 도면이고, 도 4는 본 발명의 일 실시예에 따른 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 방법의 순서를 개략적으로 도시한 도면이고, 도 5는 상기 도 4의 객체 탐지 단계의 순서를 개략적으로 도시한 도면이고, 도 6은 상기 도 4 의 객체 클래스 분류를 나타내는 도면이고, 도 7은 상기 도 4의 객체 탐지 결과를 나타내는 도면이다. 먼저, 도 3 및 도 4에 도시된 바와 같이, 본 발명의 일 실시 예에 따른 YOLO기반 객체탐지를 통한 쓰레기 무단 투기 감시 방법은, 먼저, 상기 객체 탐지부에서 CNN 기반의 YOLO 객체 탐지 알고리즘을 이용하여 사람 (person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체로 분류 하여 각 객체의 경계상자를 탐지하는 단계를 수행하게 된다(S410). 여기서, 상기 각 객체의 경계상자를 탐지하는 단계는 도 5를 참조하여 3단계로 나누어 상세히 설명하기로 한다. 먼저, 도 5에 도시된 바와 같이, 상기 학습부에서 상기 반사율 및 거리 정보를 포함하는 PCD(Point Cloud Data)와 영상 데이터에 기초하여 객체를 사람(person), 사람이 들고 있는 쓰레기(hand-held trash) 및 버려진 쓰레기(ground-trash)로 분류하여 YOLO 기반의 객체 탐지 학습을 각각 수행하는 단계를 수행한다(S411). 여기서, 도 6을 참조하면, 각 객체 클래스가 사람(person), 사람이 들고 있는 쓰레기(hand-held trash) 및 버려 진 쓰레기(ground-trash)로 분류되는 예시를 보여주고 있다. 보다 구체적으로, 본 발명의 YOLO는 입력된 이미지 내부의 객체에 대한 경계상자의 예측과 분류를 동시에 실행 하는 통합탐지(Unified Detection)를 특징으로 한다. 상기 예측부에서 YOLO에 입력되는 영상 데이터는 해 상도에 따라 (SⅹS ) 개의 격자 셀로 나누며 각 셀은 탐지된 객체의 클래스, 경계상자, 신뢰도(Confidence score, Sconf는 ) 정보로 구성된 예측 텐서(Prediction Tensor)로 매핑되며 각 셀은 B개의 경계상자와 해당 경계 상자의 정확도를 나타내는 Sconf는를 예측하게 된다. 그리고, PCD와 영상 데이터에 기초하여 학습된 각각의 객체 탐지 모델에서의 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 경계상자와 신뢰도 점수를 예 측하는 단계를 수행한다(S412). 즉, 학습된 각각의 객체 탐지 모델의 객체 탐지 결과는 경계상자의 기하학적 정 보와 탐지된 객체가 실제값과 일치하는지 정도를 나타내는 신뢰도를 반영하여 객체가 분류된 확률의 신뢰도 점 수를 예측한다. 보다 구체적으로, 각각의 셀이 예측한 경계상자는 (x, y, w, h, Sconf)의 5가지 정보를 포함한다. (x, y) 는 픽 셀 좌표계 기준 중심좌표, (w, h)는 경계상자의 기하학적 폭과 높이, Sconf는 하기 수식 [1]과 같이 경계상자에 객체가 포함될 확률인 Pr(Object)와 경계상자가 얼마나 정확하게 경계상자를 예측했는지를 나타내는 실제값(Ground-truth)과와 교차영역의 상대적인 넓이(Intersection of union;IOU)인 와 의 곱을 의미한다. 수식 [1]"}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "즉, 셀이 예측한 경계상자에 객체가 포함되지 않는다면, Pr(Object)= 0 이 되고, 이상적으로 객체가 확실하게 포함되면 Pr(Object)= 1 이 되어 예측한 경계상자와 실제값이 모두 겹치는 최적의 Sconf 를 가지게 된다. 또한, 각 셀은 경계상자에 포함된 객체의 클래스가 학습된 C개의 객체 중 어떤 클래스인지를 의미하는 조건부 확률, Pclass 를 하기 식 [2] 와 같이 예측하며 경계상자에 객체가 포함되었다는 가정하에 해당 객체의 클래스를 예측하기 위한 조건부 확률을 의미한다. 수식 [2]"}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "즉, 각각의 셀이 예측한 경계상자는 (x, y, w, h, Sconf)의 5가지 정보를 포함하는 B 개의 경계상자와 C개의 Pclass 를 예측하며, (SⅹS )의 크기와 (Bⅹ5+C)의 길이를 가지는 벡터인 예측 텐서로 변환한다. 그 다음, 상기 결정부에서 객체 탐지 결과를 융합하기 위해 경계상자의 좌표를 각각 사람(person) 객체, 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground-trash) 객체에 대한 신뢰도 점수를 기반으로 가중평균을 통해 최종 경계상자를 결정하는 단계를 수행한다(S413). 보다 구체적으로, 예측 텐서는 하기 수식 [3] 과 같이 경계상자에 객체가 포함되는 확률인 Sconf 와 포함된 객체 의 단일 클래스에 대한 조건부 확률 Pclass 를 곱하여 객체 분류하기 위한 class specific confidence score(CSconf ) 로 확장되어 객체를 탐지하게 된다. 수식 [3]"}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "즉, CSconf 는 경계상자에 특정 클래스의 객체가 포함될 확률과 예측된 경계상자의 Pclass 가 실제값과 일치하는 확 률을 의미하며 최종적으로 가장 높은 CSconf 를 가진 예측 텐서의 클래스와 경계상자가 해당 셀의 탐지 결과로 선정하게 된다.그 다음, 상기 추적부에서 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간 경계 상자의 이동 경로를 실시간으로 추적하는 단계를 수행하게 된다(S420). 여기서, 도 7에 도시된 바와 같이, 상기 결정된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체의 경계상자의 움직임을 추적하여 두 객체 사이의 이동 경로를 추적하게 된다. 이어서, 상기 연산부에서 추적되는 경계상자의 이동 경로에 따라 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이 및 이동 거리를 연산하는 단계를 수행하게 된다 (S430). 보다 구체적으로, 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기 (ground-trash) 객체의 각 경계상자의 넓이는 다르며, 이들의 이동 경로에 따라 겹침 영역의 넓이 및 이동 거리 가 달라지게 된다. 즉, 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체의 경계상자에서 겹침 영역은 사람이 들고 있는 쓰레기(hand-held trash) 객체의 영역 크기에 해당된다. 그러나, 사람이 들고 있 는 쓰레기를 버렸다면 그 겹침 영역은 쓰레기 객체의 경계상자만큼의 크기를 뺀 겹침 영역의 넓이로 달라지게 된다. 그리고, 상기 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground- trash) 객체 간의 이동 거리를 연산하게 된다. 즉, 각 객체 간의 이동 벡터 값을 연산하게 되는데 만약 사람이 들고 있는 쓰레기가 투기 되었다면 들고 있는 쓰레기 객체의 이동 거리는 사람 객체의 이동 거리와 달라지게 된 다. 따라서, 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 및 버려진 쓰레기(ground- trash) 객체의 경계상자의 넓이 및 이동 거리를 연산하게 된다. 마지막으로, 상기 판단부에서 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객 체 간의 경계상자의 겹침 영역 넓이 변화 또는 이동 거리 변화를 검출하여 변화 값에 대응하여 쓰레기 투기로 판단하는 단계를 수행하게 된다(S440). 보다 구체적으로, 상기 쓰레기 투기로 판단하는 단계에서, 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand-held trash) 객체 간의 경계상자의 겹침 영역 넓이가 기 설정 값 이하로 감소되면 쓰레기 투기로 판단하게 된다. 즉, 상기 기 설정값은 버려진 쓰레기의 경계상자의 넓이가 될 수 있으며, 설정된 버려진 쓰레기 경계상자만큼의 넓이가 감소되었다면 쓰레기 투기로 판단할 수 있다. 또한, 상기 쓰레기 투기로 판단하는 단계에서 상기 연산된 사람(person) 객체와 사람이 들고 있는 쓰레기(hand- held trash) 객체 간의 경계상자의 이동 거리가 기 설정된 값 이상이면 쓰레기 투기로 판단하게 된다. 즉, 상기 연산된 각 객체 간의 이동 벡터 값에서 만약 사람이 들고 있는 쓰레기가 투기 되었다면 들고 있는 쓰 레기 객체의 이동 거리는 사람 객체의 이동 거리와 달라지게 된다. 이때, 기 설정 값이 쓰레기의 객체의 이동 거리 변화로 설정될 수 있다. 따라서, 본 발명의 YOLO 기반의 각 객체 간의 경계상자를 탐지하여 이들의 경계상자 간의 겹침 영역 및 이동 거 리 간의 변화에 따라 쓰레기 투기를 판단하여 모델의 복잡성 및 연산량을 줄이면서도 보다 높은 인식 성능을 제 공할 수 있게 된다."}
{"patent_id": "10-2021-0118995", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2021-0118995", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 시스템의 구성을 개략적으 로 도시한 도면이다. 도 2는 상기 도 1의 객체 탐지부의 구성을 개략적으로 도시한 도면이다. 도 3은 YOLO기반 객체탐지를 통한 쓰레기 무단투기 알고리즘의 간략한 처리 블록도를 도시한 도면이다. 도 4는 본 발명의 일 실시예에 따른 YOLO기반 객체탐지를 통한 쓰레기 무단투기 감시 방법의 순서를 개략적으로 도시한 도면이다. 도 5는 상기 도 4의 객체 탐지 단계의 순서를 개략적으로 도시한 도면이다. 도 6은 상기 도 4의 객체 클래스 분류를 나타내는 도면이다. 도 7은 상기 도 4의 객체 탐지 결과를 나타내는 도면이다."}
