{"patent_id": "10-2022-0067944", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0167826", "출원번호": "10-2022-0067944", "발명의 명칭": "메타휴먼 아바타 생성장치 및 방법", "출원인": "(주)스마트큐브", "발명자": "하태원"}}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 얼굴이 포함된 영상정보 중 I프레임을 기반으로 얼굴 영역을 검출하는 얼굴영역 검출부;상기 검출된 얼굴 영역에 대한 얼굴 특징점을 검출하고, 상기 검출된 얼굴 특징점을 학습된 생성모델에 적용하여 상기 사용자와 관련된 3차원 아바타를 생성하는 아바타 생성부;상기 영상정보 중 P프레임을 기반으로 상기 사용자의 움직임 벡터를 산출하고, 상기 산출된 움직임 벡터를 이용하여 모션 특징벡터를 검출하는 움직임 검출부; 및상기 3차원 아바타에 상기 모션 특징벡터를 매핑하여 상기 사용자의 움직임이 반영된 3차원 능동형 아바타를 생성하는 능동형 아바타 생성부;를 포함하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 아바타 생성부는,상기 생성모델에 포함된 두 개의 신경망 모델을 경쟁시켜 상기 3차원 아바타의 생성을 위한 학습을 하는 학습모듈;상기 얼굴 영역에 포함된 적어도 하나의 얼굴 요소를 특정하고, 상기 특정된 얼굴 요소의 위치, 좌우대칭, 크기및 생김새 중 적어도 하나의 얼굴 특징점을 검출하는 특징점 검출모듈; 및상기 얼굴 특징점 및 기 저장된 3차원 후보 얼굴에 대한 정보를 상기 학습된 생성모델에 적용하여 3차원 아바타의 얼굴 외형 및 골격을 생성하는 아바타 생성모듈;을 포함하는 것을 특징으로 하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 특징점 검출모듈은,상기 얼굴 요소에 대한 깊이 지도(depth map)을 생성하고, 상기 생성된 깊이 지도를 기반으로 얼굴의 특징부위를 추정하여 상기 얼굴 특징점을 검출하는 것을 특징으로 하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2항에 있어서,상기 아바타 생성모듈은,상기 얼굴 영역에 대한 윤곽선, 표면상태 및 피부색을 기반으로 기 저장된 3차원 후보군 얼굴 중 상기 사용자의얼굴과 가장 유사도가 높은 얼굴을 검출하여 상기 3차원 후보 얼굴로 설정하는 것을 특징으로 하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 아바타 생성모듈은,상기 윤곽선을 이용하여 둥근형, 달걀형, 역삼각형, 긴형, 각진형 및 다이아몬드형 중 어느 하나의 얼굴형을 검공개특허 10-2023-0167826-3-출하고, 상기 표면 상태를 이용하여 피부 거칠기, 기미, 주근깨, 여드름, 점, 흉터 및 잡티 중 적어도 하나의피부 특징을 검출하며, 상기 검출된 얼굴형, 피부 특징 및 상기 피부색을 결합한 얼굴과 상기 3차원 후보군 얼굴을 비교하여 상기 3차원 후보 얼굴로 설정하는 것을 특징으로 하는 메타 휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 움직임 검출부는,상기 움직임 벡터를 이용하여 상기 사용자의 움직임을 보상하고, 상기 움직임이 보상된 부분에 대한 깊이 지도를 생성하며, 상기 생성된 깊이 지도를 기반으로 움직임 특징을 추정하여 상기 모션 특징벡터를 검출하는 것을특징으로 하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,상기 움직임 검출부는,상기 움직임 벡터를 통해 동일한 움직임이 반복적으로 검출되면 해당 움직임을 상기 사용자의 습관이라고 판단하고, 상기 판단된 습관과 관련된 움직임이 상기 모션 특징벡터에 포함되도록 제어하는 것을 특징으로 하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 능동형 아바타 생성부는,상기 습관이 반복되는 패턴을 추정하고, 상기 추정된 패턴이 발생되면 해당 습관과 관련된 움직임을 상기 3차원능동형 아바타에 반영하는 것을 특징으로 하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 습관과 관련된 움직임은,주기적으로 사용자의 머리를 흔드는 움직임, 주기적으로 손가락으로 머리를 만지는 움직임, 주기적으로 얼굴 표정이 변경되는 움직임 및 기 설정된 단어 발화 시, 얼굴 표정이 변경되는 움직임 중 적어도 하나를 포함하는 것을 특징으로 하는 메타휴먼 아바타 생성장치."}
{"patent_id": "10-2022-0067944", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "아바타 생성장치가 사용자의 얼굴이 포함된 영상정보 중 I프레임을 기반으로 얼굴 영역을 검출하는 단계;상기 아바타 생성장치가 상기 검출된 얼굴 영역에 대한 얼굴 특징점을 검출하고, 상기 검출된 얼굴 특징점을 학습된 생성모델에 적용하여 상기 사용자와 관련된 3차원 아바타를 생성하는 단계;상기 아바타 생성장치가 상기 영상정보 중 P프레임을 기반으로 상기 사용자의 움직임 벡터를 산출하고, 상기 산출된 움직임 벡터를 이용하여 모션 특징벡터를 검출하는 단계; 및상기 아바타 생성장치가 상기 3차원 아바타에 상기 모션 특징벡터를 매핑하여 상기 사용자의 움직임이 반영된 3차원 능동형 아바타를 생성하는 단계;를 포함하는 메타휴먼 아바타 생성방법."}
{"patent_id": "10-2022-0067944", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "메타휴먼 아바타 생성장치 및 방법이 개시된다. 메타휴먼 아바타 생성장치는 사용자의 얼굴이 포함된 영상정보 중 I프레임을 기반으로 얼굴 영역을 검출하는 얼굴영역 검출부, 검출된 얼굴 영역에 대한 얼굴 특징점을 검출하 고, 검출된 얼굴 특징점을 학습된 생성모델에 적용하여 사용자와 관련된 3차원 아바타를 생성하는 아바타 생성부, 영상정보 중 P프레임을 기반으로 사용자의 움직임 벡터를 산출하고, 산출된 움직임 벡터를 이용하여 모 션 특징벡터를 검출하는 움직임 검출부 및 3차원 아바타에 모션 특징벡터를 매핑하여 사용자의 움직임이 반영된 3차원 능동형 아바타를 생성하는 능동형 아바타 생성부를 포함한다."}
{"patent_id": "10-2022-0067944", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 아바타 생성장치에 관한 것으로, 더욱 상세하게는 사용자의 생김새, 표정 및 포즈에 대한 특징을 표 현하는 3차원 능동형 아바타를 생성하는 메타휴먼 아바타 생성장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0067944", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "메타버스(metaverse)는 가상, 초월(meta), 세계, 우주(universe)의 합성어로 3차원 가상세계를 의미한다. 메타 버스의 엄밀한 정의는 현실 세계와 같은 사회적, 경제적 활동이 통용되는 3차원 가상공간이라 말할 수 있다. 특히 비대면 활동 수요가 급증하면서 원격 미팅 서비스, 원격 교육 서비스, 원격 의료 서비스, 원격 상거래 서 비스 등을 통한 현실 세계의 사회적 경제적 활동과 관련된 원격 서비스에 대한 연구가 주목받고 있다. 한편 3차원 가상공간에서는 사용자와 똑같은 실사 아바타를 이용하여 실제 공간에서 상호 교감을 하는 듯한 현 장갑과 몰입감을 제공할 수 있어야 한다. 즉 3차원 가상공간 서비스를 실현하는 핵심기술은 실사 아바타 생성기 술이다. 메타버스 환경에서 실사 아바타를 이용하여 사용자의 상태를 얼마나 현실감있게 복원하는지는 핵심적인 문제이 다. 그 중에서 얼굴은 사람의 캐릭터를 나타내는 제일 중요한 부분으로써, 다양한 연구를 통해 현실감 있는 3차 원 얼굴을 표현하기 위한 연구가 진행되고 있는 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-1815995호(2018.02.21.)"}
{"patent_id": "10-2022-0067944", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 사용자의 얼굴 특징점과 모션 특징벡터를 기반으로 사용자의 생김새, 표정, 제스처, 포즈 및 습관을 반영한 3차원 능동형 아바타를 생성하는 메타휴먼 아바타 생성장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0067944", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위해 본 발명에 따른 메타휴먼 아바타 생성장치는 사용자의 얼굴이 포함된 영상정보 중 I 프레임을 기반으로 얼굴 영역을 검출하는 얼굴영역 검출부, 상기 검출된 얼굴 영역에 대한 얼굴 특징점을 검출 하고, 상기 검출된 얼굴 특징점을 학습된 생성모델에 적용하여 상기 사용자와 관련된 3차원 아바타를 생성하는 아바타 생성부, 상기 영상정보 중 P프레임을 기반으로 상기 사용자의 움직임 벡터를 산출하고, 상기 산출된 움 직임 벡터를 이용하여 모션 특징벡터를 검출하는 움직임 검출부 및 상기 3차원 아바타에 상기 모션 특징벡터를 매핑하여 상기 사용자의 움직임이 반영된 3차원 능동형 아바타를 생성하는 능동형 아바타 생성부를 포함한다. 또한 상기 아바타 생성부는, 상기 생성모델에 포함된 두 개의 신경망 모델을 경쟁시켜 상기 3차원 아바타의 생 성을 위한 학습을 하는 학습모듈, 상기 얼굴 영역에 포함된 적어도 하나의 얼굴 요소를 특정하고, 상기 특정된 얼굴 요소의 위치, 좌우대칭, 크기 및 생김새 중 적어도 하나의 얼굴 특징점을 검출하는 특징점 검출모듈 및 상 기 얼굴 특징점 및 기 저장된 3차원 후보 얼굴에 대한 정보를 상기 학습된 생성모델에 적용하여 3차원 아바타의 얼굴 외형 및 골격을 생성하는 아바타 생성모듈을 포함하는 것을 특징으로 한다. 또한 상기 특징점 검출모듈은, 상기 얼굴 요소에 대한 깊이 지도(depth map)을 생성하고, 상기 생성된 깊이 지 도를 기반으로 얼굴의 특징부위를 추정하여 상기 얼굴 특징점을 검출하는 것을 특징으로 한다. 또한 상기 아바타 생성모듈은, 상기 얼굴 영역에 대한 윤곽선, 표면상태 및 피부색을 기반으로 기 저장된 3차원 후보군 얼굴 중 상기 사용자의 얼굴과 가장 유사도가 높은 얼굴을 검출하여 상기 3차원 후보 얼굴로 설정하는 것을 특징으로 한다. 또한 상기 아바타 생성모듈은, 상기 윤곽선을 이용하여 둥근형, 달걀형, 역삼각형, 긴형, 각진형 및 다이아몬드 형 중 어느 하나의 얼굴형을 검출하고, 상기 표면 상태를 이용하여 피부 거칠기, 기미, 주근깨, 여드름, 점, 흉 터 및 잡티 중 적어도 하나의 피부 특징을 검출하며, 상기 검출된 얼굴형, 피부 특징 및 상기 피부색을 결합한얼굴과 상기 3차원 후보군 얼굴을 비교하여 상기 3차원 후보 얼굴로 설정하는 것을 특징으로 한다. 또한 상기 움직임 검출부는, 상기 움직임 벡터를 이용하여 상기 사용자의 움직임을 보상하고, 상기 움직임이 보 상된 부분에 대한 깊이 지도를 생성하며, 상기 생성된 깊이 지도를 기반으로 움직임 특징을 추정하여 상기 모션 특징벡터를 검출하는 것을 특징으로 한다. 또한 상기 움직임 검출부는, 상기 움직임 벡터를 통해 동일한 움직임이 반복적으로 검출되면 해당 움직임을 상 기 사용자의 습관이라고 판단하고, 상기 판단된 습관과 관련된 움직임이 상기 모션 특징벡터에 포함되도록 제어 하는 것을 특징으로 한다. 또한 상기 능동형 아바타 생성부는, 상기 습관이 반복되는 패턴을 추정하고, 상기 추정된 패턴이 발생되면 해당 습관과 관련된 움직임을 상기 3차원 능동형 아바타에 반영하는 것을 특징으로 한다. 또한 상기 습관과 관련된 움직임은, 주기적으로 사용자의 머리를 흔드는 움직임, 주기적으로 손가락으로 머리를 만지는 움직임, 주기적으로 얼굴 표정이 변경되는 움직임 및 기 설정된 단어 발화 시, 얼굴 표정이 변경되는 움 직임 중 적어도 하나를 포함하는 것을 특징으로 한다. 본 발명에 따른 메타휴먼 아바타 생성방법은 아바타 생성장치가 사용자의 얼굴이 포함된 영상정보 중 I프레임을 기반으로 얼굴 영역을 검출하는 단계, 상기 아바타 생성장치가 상기 검출된 얼굴 영역에 대한 얼굴 특징점을 검 출하고, 상기 검출된 얼굴 특징점을 학습된 생성모델에 적용하여 상기 사용자와 관련된 3차원 아바타를 생성하 는 단계, 상기 아바타 생성장치가 상기 영상정보 중 P프레임을 기반으로 상기 사용자의 움직임 벡터를 산출하고, 상기 산출된 움직임 벡터를 이용하여 모션 특징벡터를 검출하는 단계 및 상기 아바타 생성장치가 상 기 3차원 아바타에 상기 모션 특징벡터를 매핑하여 상기 사용자의 움직임이 반영된 3차원 능동형 아바타를 생성 하는 단계를 포함한다."}
{"patent_id": "10-2022-0067944", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 사용자의 얼굴이 포함된 영상정보에서 얼굴 영역에 대한 얼굴 특징점을 검출하고, 검출된 얼굴 특징점 및 기 저장된 3차원 후보 얼굴을 이용하여 3차원 아바타를 생성하며, 생성된 3차원 아바타 에 사용자의 움직임 벡터를 통해 산출된 모션 특징벡터를 매핑하여 3차원 능동형 아바타를 생성함으로써, 사용 자의 얼굴 특징을 정확히 표현하면서도 빠르게 아바타를 생성할 수 있다. 이를 통해 사용자는 자신의 생김새, 표정, 제스처, 포즈 및 습관이 반영된 사용자 맞춤형 아바타를 메타버스 플 랫폼에 적용하여 다양한 원격 서비스를 수행할 수 있다. 특히 사용자는 직접적인 영상 노출을 하지 않으면서도 타사용자에게 실제 사용자와 원격 서비스를 진행하는 효 과를 줌으로써, 아바타에 의해 진행되는 원격 서비스에서의 현실감에 대한 거부감을 최소화할 수 있다."}
{"patent_id": "10-2022-0067944", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서 및 도면(이하 '본 명세서')에서, 동일한 구성요소에 대해서 중복된 설명은 생략한다. 또한 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어' 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존 재할 수도 있다고 이해되어야 할 것이다. 반면에 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '직접 연결 되어' 있다거나 '직접 접속되어' 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되 어야 할 것이다. 또한, 본 명세서에서 사용되는 용어는 단지 특정한 실시예를 설명하기 위해 사용되는 것으로써, 본 발명을 한정 하려는 의도로 사용되는 것이 아니다. 또한 본 명세서에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 또한 본 명세서에서, '포함하다' 또는 '가지다' 등의 용어는 명세서에 기재된 특징, 숫자, 단계, 동작, 구성요 소, 부품, 또는 이들을 조합한 것이 존재함을 지정하려는 것일 뿐, 하나 또는 그 이상의 다른 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이 해되어야 할 것이다. 또한 본 명세서에서, '및/또는' 이라는 용어는 복수의 기재된 항목들의 조합 또는 복수의 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서, 'A 또는 B'는, 'A', 'B', 또는 'A와 B 모두'를 포함할 수 있다. 또한 본 명세서에서, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략될 것 이다. 도 1은 본 발명의 실시예에 따른 아바타 생성장치를 설명하기 위한 블록도이고, 도 2는 본 발명의 실시예에 따 른 아바타 생성부를 설명하기 위한 블록도이며, 도 3은 본 발명의 실시예에 따른 생성모델의 학습과정을 설명하 기 위한 도면이고, 도 4는 본 발명의 실시예에 따른 얼굴영역을 검출하는 과정을 설명하기 위한 도면이며, 도 5 는 본 발명의 실시예에 따른 얼굴영역의 특징점을 검출하는 과정을 설명하기 위한 도면이고, 도 6은 본 발명의 실시예에 따른 아바타를 생성하는 과정을 설명하기 위한 도면이며, 도 7은 본 발명의 실시예에 따른 움직임을 보상하는 과정을 설명하기 위한 도면이고, 도 8은 본 발명의 실시예에 따른 능동형 아바타를 설명하기 위한 도 면이다. 여기서 도 4의 (a)는 사용자의 얼굴이 포함된 영상정보를 나타내는 도면이고, (b)는 영상정보에서 검출된 얼굴 영역을 나타내는 도면이다. 도 5의 (a)는 영상정보에서 검출된 얼굴 영역을 나타내는 도면이고, (b)는 얼굴 특 징점을 나타내는 도면이다. 도 6의 (a)는 얼굴 특징점을 나타내는 도면이고, (b)는 3차원 아바타를 나타내는 도 면이다. 도 7의 (a)는 사용자의 얼굴이 포함된 영상정보의 이전 프레임을 나타내는 도면이고, (b)는 사용자의 얼굴이 포함된 영상정보의 현재 프레임을 나타내는 도면이며, (c)는 이전 프레임의 깊이 지도를 나타낸 도면이 고, (d)는 움직임이 보상된 현재 프레임의 깊이 지도를 나타낸 도면이다. 도 1 내지 도 8을 참조하면, 아바타 생성장치는 사용자의 얼굴 특징점과 모션 특징벡터를 기반으로 사용자 의 생김새, 표정 및 포즈를 반영한 3차원 능동형 아바타를 생성한다. 아바타 생성장치는 얼굴영역 검출부 , 아바타 생성부, 움직임 검출부 및 능동형 아바타 생성부를 포함하고, 입력부 및 저장부 를 더 포함할 수 있다. 입력부는 사용자의 얼굴이 포함된 영상정보가 입력된다. 여기서 영상정보는 스마트폰, 웹캠 등과 같은 카메 라를 포함하는 전자장치를 통해 촬영된 정보로써, 360도 방향에서 촬영된 영상정보가 아닌 일 방향에서 촬영된 영상정보일 수 있다. 바람직하게는 영상정보는 일방향에서 촬영되되, 사용자의 머리가 좌우로 이동되는 영상정 보일 수 있다. 얼굴영역 검출부는 영상정보 중 I프레임을 기반으로 얼굴 영역을 검출한다. I프레임은 인프라 프레임(Infra frame)의 약자로써, 키 프레임에 해당한다. 얼굴영역 검출부는 I프레임에서 경계박스(boundary box)(A)를 통해 얼굴 영역을 검출한다. 이때 얼굴영역 검출부는 I프레임의 배경과 사용자를 구분하고, 구분된 배경을 필터링한 후, 조명 조건을 추정하여 정확하게 얼굴 영역을 검출할 수 있다. 얼굴영역 검출부는 검출된 얼굴 영역이 하나인 경우, 해당 얼굴 영역에 타겟 얼굴이 포함되어 있는지 판단하고, 타겟 얼굴이 포함되어 있지 않 으면 영상정보를 재입력받아 얼굴 영역을 재검출할 수 있다. 또한 검출된 얼굴 영역이 복수개인 경우, 얼굴영역 검출부는 복수의 얼굴 영역 중 어느 하나에 타겟 얼굴이 포함되어 있는지 판단하고, 하나의 얼굴 영역에 타 겟 얼굴이 포함되어 있으면 해당 얼굴 영역을 검출하고, 모든 얼굴 영역에 타겟 얼굴이 포함되어 있지 않으면 영상정보를 재입력받아 얼굴 영역을 재검출할 수 있다. 여기서 타겟 얼굴은 사용자 얼굴일 수 있다. 아바타 생성부는 검출된 얼굴 영역에 대한 얼굴 특징점을 검출하고, 검출된 얼굴 특징점을 학습된 생성모델 에 적용하여 3차원 아바타를 생성한다. 이를 위해 아바타 생성부는 학습모듈, 특징점 검출모듈 및 아바타 생성모듈를 포함한다. 학습모듈은 생성모델에 포함된 두 개의 신경망 모델을 경쟁시켜 3차원 아바타의 생성을 위한 학습을 한다. 두 개의 신경망 모델은 생성자(Generator) 및 감별자(Discriminator)이다. 생성자는 실제 영상정보를 학습하고, 학습된 결과를 기반으로 거짓 영상정보를 생성한다. 이때 생성자는 실제에 가까운 거짓 영상정보를 생성하는데 목적을 가지고 있다. 감별자는 생성자가 출력한 영상정보가 실제인지 거짓인지 판별하도록 학습한다. 감별자는 판별된 결과가 실제 영상정보인 경우 1로 출력하고, 거짓 영상정보인 경우 0으로 출력할 수 있다. 즉 감별자는 생성자의 거짓 영상정보를 판별하는데 목적을 가지고 있다. 이와 같이 생성자 및 감별자는 사용자가 정답을 알 려주지 않아도 경쟁 과정 속에서 스스로 학습하는 구조를 가지고 있다. 바람직하게는 생성모델은 생성적 적대 신경망(Generative Adversarial Network, GAN)일 수 있으나, 이에 한정하지 않는다. 특징점 검출모듈은 얼굴 영역에 포함된 적어도 하나의 얼굴 요소를 특정한다. 얼굴 요소는 눈썹, 눈, 코, 입 등을 포함할 수 있다. 특징점 검출모듈은 특정된 얼굴 요소에 대한 깊이 지도(depth map)를 생성한다. 특징점 검출모듈은 생성된 깊이 지도를 기반으로 얼굴의 특징부위를 추정하여 얼굴 특징점(B)을 검출한다. 얼굴 특징점은 동공 중심, 양 콧구멍 중앙, 입 중앙 등의 위치, 좌우대칭, 크기, 생김새 중 적어도 하나에 대한 특징을 점들로 표현한 것을 의미한다. 상세하게는 특징점 검출모듈은 깊이 지도에 포함된 깊이정보를 이용하여 얼굴 요소의 길이를 산출하고, 산 출된 길이를 기 설정된 기준과 비교하여 차이값을 산출한다. 특징점 검출모듈은 산출된 차이값이 기 설정된 오차 범위를 벗어나면 특징부위를 선정하고, 선정된 특징부위 중 차이값을 기반으로 얼굴 특징점을 검출할 수 있다. 여기서 기 설정된 기준은 일반적인 사람의 얼굴 요소별 평균 길이를 나타낸 수치일 수 있다. 또한 특징점 검출모듈은 첫 프레임에서 추출된 특징점을 기준으로 연속되는 프레임에 대해 반복적으로 가버(Gabor) 웨이 블릿 변환값과 상관계수를 비교하여 변하는 위치를 추적함으로써, 얼굴 특징점을 검출할 수 있다. 아바타 생성모듈은 검출된 얼굴 특징점을 학습된 생성모델에 적용하여 3차원 아바타를 생성한다. 생성모델 은 학습모듈에서 학습된 인공지능 모델로써, 가상의 3차원 아바타를 생성할 수 있다. 상세하게는 아바타 생성모듈은 얼굴 특징점 및 기 저장된 3차원 후보 얼굴에 대한 정보를 학습된 생성모델 에 적용하여 3차원 아바타의 얼굴 외형 및 골격을 생성한다. 이때 아바타 생성모듈은 얼굴 영역의 윤곽선, 표면상태 및 피부색을 기반으로 기 저장된 3차원 후보군 얼굴 중 사용자의 얼굴과 가장 유사도가 높은 얼굴을 검출하여 3차원 후보 얼굴로 설정할 수 있다. 즉 아바타 생성모듈는 얼굴 영역의 윤곽선을 이용하여 둥근형, 달걀형, 역삼각형, 긴형, 각진형 및 다이아몬드형 중 어느 하나의 얼굴형을 검출하고, 표면 상태를 이 용하여 피부 거칠기(건성, 중성, 지성 등), 기미, 주근깨, 여드름, 점, 흉터 및 잡티 중 적어도 하나의 피부 특 징을 검출한다. 아바타 생성모듈는 검출된 얼굴형, 피부 특징 및 피부색을 결합한 얼굴과 3차원 후보군 얼 굴을 비교하여 가장 유사도가 높은 얼굴인 3차원 후보 얼굴을 설정할 수 있다. 여기서 3차원 후보군 얼굴은 다 양한 사람들의 얼굴 생김새를 평균화한 얼굴 정보를 데이터베이스한 정보로써, 저장부에 기 저장될 수 있다. 이와 같이 아바타 생성모듈은 사용자의 영상정보를 학습된 생성모델에 적용하지 않고, 얼굴 특징점 및 3차 원 후보 얼굴을 학습된 생성모델에 적용함으로써, 영상정보를 통해 생성된 3차원 아바타와 생김새에서 큰 차이 가 없는 3차원 아바타를 보다 빠른 속도로 생성할 수 있다. 즉 아바타 생성모듈은 기본적인 3차원 아바타의 틀을 3차원 후보 얼굴로 대체한 후, 3차원 후보 얼굴에 얼굴 특징점을 매핑시켜 3차원 아바타를 생성하기 때문 에 기존에 360도 방향의 사용자 얼굴과 관련된 영상정보 없이도 사용자의 얼굴에 가까운 아바타를 빠르게 생성 할 수 있다. 한편 아바타 생성모듈는 생성모델 중 생성자를 이용하여 3차원 아바타를 생성할 수 있으며, 생성자의 입력정보는 얼굴 특징점 및 3차원 후보 얼굴에 대한 정보일 수 있다. 움직임 검출부는 영상정보 중 P프레임을 기반으로 사용자의 움직임 벡터를 산출한다. P프레임은 이전 (Previous) 또는 예측(Predicted) 프레임의 약자로써, 이전에 나온 키프레임의 정보를 기반으로 구성된 프레임 이다. 움직임 검출부는 이전 프레임과 현재 프레임 간의 움직임 변화를 통해 움직임 벡터를 산출할 수 있다. 즉 움직임 검출부는 시간축에 연속적인 이미지에서 각 픽셀의 위치를 추적하는 광학 흐름(optical flow)을 기반으로 움직임 벡터를 산출할 수 있다. 이때 움직임 검출부는 다양한 알고리즘을 이용하여 움직 임 벡터를 산출할 수 있으며, 바람직하게는 Lucas-Kanade 알고리즘, FlowNet 딥러닝 네트워크 등을 이용할 수 있다. FolwNet 딥러닝 네트워크는 컨볼루션층(convolution layer)를 통해 특징(feature)을 검출하고, 리파인 (refine)하여 광학 흐름 지도를 예측하는 방식으로써, 입력값으로 연속된 두 장의 영상정보가 입력되고, 예측된 값과 정답 영상을 비교하여 학습하는 방식이다. 움직임 검출부는 산출된 움직임 벡터를 이용하여 모션 특징 벡터를 검출한다. 모션 특징벡터는 움직임 벡터 중 기 설정된 기준 이상의 크기를 가지는 벡터로써, 미세한 움 직임이 아닌 큰 동작 또는 표정에 대한 움직임을 나타내는 벡터일 수 있다. 여기서 기 설정된 기준은 각 신체 요소(입, 눈, 눈썹, 코, 손, 머리 등)별로 크기가 다를 수 있다. 상세하게는 움직임 검출부는 움직임 벡터를 이용하여 사용자의 움직임을 보상하고, 움직임이 보상된 부분에 대한 깊이 지도를 생성한다. 움직임 검출부는 생성된 깊이 지도를 기반으로 움직임 특징을 추정하여 모션 특징벡터를 검출할 수 있다. 이때 움직임 검출부는 움직임 벡터를 통해 동일한 움직임이 반복적으로 검출되 면 해당 움직임을 사용자의 습관이라고 판단하고, 판단된 습관과 관련된 움직임이 모션 특징벡터에 포함되도록 제어할 수 있다. 여기서 움직임 검출부는 움직임 벡터 중 기 설정된 기준 이상의 크기를 아니더라도 동일한 움직임이 반복적으로 검출되면 해당 움직임을 습관이라고 판단할 수 있다. 습관은 임의의 시간마다 무의식 중에 하는 행동(예를 들면 손동작, 얼굴 표정, 머리 이동 등), 임의의 단어 발화시 무의식 중에 하는 행동 등일 수 있으나, 이에 한정하지 않는다. 예를 들어 주기적으로 머리를 살짝 흔드는 움직임(도 8), 주기적으로 손가락으 로 머리를 만지는 움직임, 주기적으로 얼굴 표정이 변경되는 움직임 및 기 설정된 단어를 발화 시, 얼굴 표정이 변경되는 움직임(예를 들면 입꼬리를 올리는 움직임, 눈을 찡그리는 움직임, 눈썹이 올라가는 움직임 등) 중 적 어도 하나가 습관에 포함될 수 있다. 또한 움직임은 얼굴 근육, 머리 움직임, 표정, 제스처(gesture), 포즈 (pose) 등을 포함하는 의미를 가진다. 능동형 아바타 생성부는 3차원 아바타에 모션 특징벡터를 매핑하여 사용자의 움직임이 반영된 3차원 능동형 아바타를 생성한다. 이때 능동형 아바타 생성부는 얼굴 특징점 및 모션 특징벡터를 이용하여 범프맵(bump map)을 생성하고, 생성된 범프맵을 3차원 능동형 아바타에 반영하여 아바타에 입체감과 현실감을 추가할 수 있 다. 능동형 아바타 생성부는 모션 특징벡터를 이용하여 얼굴 근육, 머리 움직임, 표정, 제스처 및 포즈 중 적어 도 하나를 3차원 능동형 아바타에 반영할 수 있다. 또한 능동형 아바타 생성부는 습관과 관련된 움직임이 발생되는 패턴을 추정하고, 추정된 패턴이 발생되면 해당 습관과 관련된 움직임을 3차원 능동형 아바타에 반영 할 수 있다. 예를 들어 능동형 아바타 생성부는 X 습관과 관련된 움직임이 일정 시간마다 발생된다고 추정 하면 해당 시간마다 X 습관과 관련된 움직임이 3차원 능동형 아바타에 나타나도록 애니메이션으로 표현할 수 있 다. 또한 능동형 아바타 생성부는 Y 습관과 관련된 움직임이 '학습'이라는 단어를 발화할 때마다 발생된다 고 추정하면 해당 단어를 발화할 때 Y 습관과 관련된 움직임이 3차원 능동형 아바타에 나타나도록 애니메이션으 로 표현할 수 있다. 저장부는 아바타 생성장치를 구동하기 위한 프로그램 또는 알고리즘이 저장된다. 저장부는 사용자 얼굴 이 포함된 영상정보가 저장된다. 저장부는 각 사용자별 얼굴 특징점과 모션 특징벡터가 저장된다. 저장부 는 각 사용자별 3차원 아바타와 3차원 능동형 아바타가 저장된다. 또한 저장부는 3차원 아바타를 생성 하기 위한 3차원 후보군 얼굴과 관련된 정보가 저장된다. 저장부는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타 입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(Random Access Memory, RAM), SRAM(Static Random Access Memory), 롬(Read-Only Memory, ROM), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기메모리, 자기 디스크 및 광디스크 중 적어도 하나의 저장매체를 포 함할 수 있다. 도 9는 본 발명의 실시예에 따른 아바타 생성방법을 설명하기 위한 순서도이다. 도 1 및 도 9를 참조하면, 아바타 생성방법은 사용자의 얼굴이 포함된 영상정보에서 얼굴 영역에 대한 얼굴 특 징점을 검출하고, 검출된 얼굴 특징점을 이용하여 3차원 아바타를 생성하며, 생성된 3차원 아바타에 사용자의 움직임 벡터를 통해 산출된 모션 특징벡터를 매핑하여 3차원 능동형 아바타를 생성할 수 있다. 즉 아바타 생성 방법은 사용자가 자신의 생김새, 표정, 제스처, 포즈 및 습관이 반영된 사용자 맞춤형 아바타를 메타버스 플랫 폼에 적용하여 다양한 원격 서비스를 수행할 수 있도록 지원한다. 특히 아바타 생성방법은 사용자가 직접적인 영상 노출을 하지 않으면서도 타사용자에게 실제 사용자와 원격 서비스를 진행하는 효과를 줌으로써, 아바타에 의해 진행되는 원격 서비스에서의 현실감에 대한 거부감을 최소화할 수 있다. S110 단계에서, 아바타 생성장치는 영상정보를 입력받는다. 여기서 영상정보는 사용자의 얼굴이 포함된 정 보로써, 스마트폰, 웹캠 등과 같은 카메라를 포함하는 전자장치를 통해 촬영된 정보일 수 있다. 이때 영상정보 는 360도 방향에서 촬영된 영상정보가 아닌 일 방향에서 촬영된 영상정보일 수 있다. S120 단계에서, 아바타 생성장치는 영상정보가 I프레임인지 P프레임인지 판단한다. I프레임은 인프라 (Infra) 프레임의 약자로써, 키 프레임에 해당하고, P프레임은 이전(Previous) 또는 예측(Predicted) 프레임의 약자로써, 이전에 나온 키프레임의 정보를 기반으로 구성된 프레임이다. 아바타 생성장치는 I프레임이면 S140 단계를 수행하고, P프레임이면 S170 단계를 수행한다. S130 단계에서, 아바타 생성장치는 얼굴 영역을 검출한다. 아바타 생성장치는 I프레임에서 경계박스 를 통해 얼굴 영역을 검출한다. 이때 얼굴영역 검출부는 I프레임의 배경과 사용자를 구분하고, 구분된 배경 을 필터링한 후, 조명 조건을 추정하여 정확하게 얼굴 영역을 검출할 수 있다. S140 단계에서, 아바타 생성장치는 얼굴 영역에 타겟 얼굴이 포함되어 있는지 판단한다. 여기서 타겟 얼굴 은 사용자 얼굴일 수 있다. 아바타 생성장치는 얼굴 영역에 타겟 얼굴이 포함되어 있으면 S150 단계를 수 행하고, 포함되어 있지 않으면 S110 단계로 분기한다. S150 단계에서, 아바타 생성장치는 얼굴 특징점을 검출한다. 아바타 생성장치는 얼굴 영역에 포함된 적어도 하나의 얼굴 요소를 특정한다. 얼굴 요소는 눈썹, 눈, 코, 입 등을 포함할 수 있다. 아바타 생성장치 는 특정된 얼굴 요소에 대한 깊이 지도를 생성한다. 아바타 생성장치는 생성된 깊이 지도를 기반으로 얼굴의 특징부위를 추정하여 얼굴 특징점을 검출한다. S160 단계에서, 아바타 생성장치는 3차원 아바타를 생성한다. 아바타 생성장치는 검출된 얼굴 특징점 을 학습된 생성모델에 적용하여 3차원 아바타를 생성한다. 아바타 생성장치는 얼굴 특징점 및 기 저장된 3 차원 후보 얼굴에 대한 정보를 학습된 생성모델에 적용하여 3차원 아바타의 얼굴 외형 및 골격을 생성한다. 이 때 아바타 생성장치는 얼굴 영역의 윤곽선, 표면상태 및 피부색을 기반으로 기 저장된 3차원 후보군 얼굴 중 사용자의 얼굴과 가장 유사도가 높은 얼굴을 검출하여 3차원 후보 얼굴로 설정할 수 있다. S170 단계에서, 아바타 생성장치는 움직임 벡터를 산출한다. 아바타 생성장치는 영상정보 중 P프레임 을 기반으로 사용자의 움직임 벡터를 산출한다. 즉 아바타 생성장치는 이전 프레임과 현재 프레임 간의 움 직임 변화를 통해 움직임 벡터를 산출할 수 있다. S180 단계에서, 아바타 생성장치는 모션 특징벡터를 검출한다. 아바타 생성장치는 움직임 벡터를 이 용하여 사용자의 움직임을 보상하고, 움직임이 보상된 부분에 대한 깊이 지도를 생성한다. 아바타 생성장치 는 생성된 깊이 지도를 기반으로 움직임 특징을 추정하여 모션 특징벡터를 검출할 수 있다. S190 단계에서, 아바타 생성장치는 3차원 능동형 아바타를 생성한다. 아바타 생성장치는 3차원 아바 타에 모션 특징벡터를 매핑하여 사용자의 움직임이 반영된 3차원 능동형 아바타를 생성한다. 이때 아바타 생성 장치는 얼굴 특징점 및 모션 특징벡터를 이용하여 범프맵(bump map)을 생성하고, 생성된 범프맵을 3차원 능동형 아바타에 반영하여 아바타에 입체감과 현실감을 추가할 수 있다. 도 10은 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다. 도 10을 참조하면, 컴퓨팅 장치(TN100)는 본 명세서에서 기술된 장치(예, 아바타 생성장치 등) 일 수 있다. 컴 퓨팅 장치(TN100)는 적어도 하나의 프로세서(TN110), 송수신 장치(TN120), 및 메모리(TN130)를 포함할 수 있다. 또한, 컴퓨팅 장치(TN100)는 저장 장치(TN140), 입력 인터페이스 장치(TN150), 출력 인터페이스 장치(TN160) 등 을 더 포함할 수 있다. 컴퓨팅 장치(TN100)에 포함된 구성 요소들은 버스(bus)(TN170)에 의해 연결되어 서로통신을 수행할 수 있다. 프로세서(TN110)는 메모리(TN130) 및 저장 장치(TN140) 중에서 적어도 하나에 저장된 프로그램 명령(program command)을 실행할 수 있다. 프로세서(TN110)는 중앙 처리 장치(CPU: central processing unit), 그래픽 처리 장치(GPU: graphics processing unit), 또는 본 발명의 실시예에 따른 방법들이 수행되는 전용의 프로세서를 의 미할 수 있다. 프로세서(TN110)는 본 발명의 실시예와 관련하여 기술된 절차, 기능, 및 방법 등을 구현하도록 구성될 수 있다. 프로세서(TN110)는 컴퓨팅 장치(TN100)의 각 구성 요소를 제어할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 프로세서(TN110)의 동작과 관련된 다양한 정보를 저장할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 구 성될 수 있다. 예를 들어, 메모리(TN130)는 읽기 전용 메모리(ROM: read only memory) 및 랜덤 액세스 메모리 (RAM: random access memory) 중에서 적어도 하나로 구성될 수 있다. 송수신 장치(TN120)는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 송수신 장치(TN120)는 네트워크 에 연결되어 통신을 수행할 수 있다. 한편, 본 발명의 실시예는 지금까지 설명한 장치 및/또는 방법을 통해서만 구현되는 것은 아니며, 본 발명의 실 시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있으며, 이러한 구현은 상술한 실시예의 기재로부터 본 발명이 속하는 기술 분야의 통상의 기술자라면 쉽게 구 현할 수 있는 것이다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 통상의 기술자의 여러 변형 및 개량 형태 또 한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2022-0067944", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 아바타 생성장치를 설명하기 위한 블록도이다. 도 2는 본 발명의 실시예에 따른 아바타 생성부를 설명하기 위한 블록도이다. 도 3은 본 발명의 실시예에 따른 생성모델의 학습과정을 설명하기 위한 도면이다. 도 4는 본 발명의 실시예에 따른 얼굴영역을 검출하는 과정을 설명하기 위한 도면이다. 도 5는 본 발명의 실시예에 따른 얼굴영역의 특징점을 검출하는 과정을 설명하기 위한 도면이다. 도 6은 본 발명의 실시예에 따른 아바타를 생성하는 과정을 설명하기 위한 도면이다. 도 7은 본 발명의 실시예에 따른 움직임을 보상하는 과정을 설명하기 위한 도면이다. 도 8은 본 발명의 실시예에 따른 능동형 아바타를 설명하기 위한 도면이다. 도 9는 본 발명의 실시예에 따른 아바타 생성방법을 설명하기 위한 순서도이다. 도 10은 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다."}
