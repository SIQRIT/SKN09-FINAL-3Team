{"patent_id": "10-2019-0130391", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0126024", "출원번호": "10-2019-0130391", "발명의 명칭": "교통 사고 처리 장치 및 교통 사고 처리 방법", "출원인": "엘지전자 주식회사", "발명자": "이한성"}}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서가, 자율 주행 차량의 상황에 대한 데이터를 획득하는 단계;적어도 하나의 프로세서가, 상기 데이터에 기초하여, 상기 자율 주행 차량의 사고의 발생 여부를 판단하는단계; 및적어도 하나의 프로세서가, 인공 지능 알고리즘을 이용해, 상기 사고의 책임 소재를 판단하는 단계;를 포함하는교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 데이터를 획득하는 단계는,적어도 하나의 프로세서가, 상기 자율 주행 차량에 구비되는 적어도 하나의 전자 장치로부터 제1 데이터를 획득하는 단계;적어도 하나의 프로세서가, 상기 자율 주행 차량 주변에 위치하는 타 차량에 구비되는 적어도 하나의 전자 장치로부터 제2 데이터를 획득하는 단계; 및적어도 하나의 프로세서가, 상기 자율 주행 차량 주변에 위치하는 적어도 하나의 로드 사이드 유닛(road sideunit, RSU)으로부터 제3 데이터를 획득하는 단계;를 포함하는 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 책임 소재를 판단하는 단계는,적어도 하나의 프로세서가, 상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여, 상기 사고 발생 시점의 상황을 시뮬레이션으로 재구성하는 단계;를 포함하는 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 재구성하는 단계는,적어도 하나의 프로세서가, 맵에 상기 자율 주행 차량 및 상기 자율 주행 차량의 주변 오브젝트를 시간 순으로맵핑하는 단계;를 포함하고,상기 자율 주행 차량의 주변 오브젝트에 대한 정보는,상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여 생성되는 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항에 있어서,상기 재구성하는 단계는,적어도 하나의 프로세서가, 상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여, 상기 자율 주행 차량의 이미지를 기준으로 하는 탑뷰 이미지를 생성하는 단계;를 포함하고,상기 탑뷰 이미지는,공개특허 10-2019-0126024-3-상기 자율 주행 차량의 조향 바퀴의 자세 이미지가 포함되는 동영상인 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 책임 소재를 판단하는 단계는,적어도 하나의 프로세서가, 상기 인공 지능 알고리즘에 상기 자율 주행 차량의 상황에 대한 데이터 및 교통 법규 데이터를 입력하여 머신 러닝한 결과에 기초하여, 상기 사고의 책임 소재를 판단하는 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 책임 소재를 판단하는 단계는,적어도 하나의 프로세서가, 상기 인공 지능 알고리즘에 과거 교통 사고 히스토리 데이터를 더 입력하여 머신 러닝한 결과에 기초하여, 상기 사고의 책임 소재를 판단하는 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,적어도 하나의 프로세서가, 상기 사고 발생 이후의 2차 사고에 대한 방지 루틴을 실행하는 단계;를 더 포함하는교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 2차 사고 방지 루틴을 실행하는 단계는,적어도 하나의 프로세서가, 상기 사고 발생 이후, 상기 자율 주행 차량의 이동 가능 여부를 판단하는 단계;적어도 하나의 프로세서가, 상기 자율 주행 차량의 회피 이동 경로를 생성하는 단계; 및적어도 하나의 프로세서가, 상기 회피 이동 경로를 따라 상기 자율 주행 차량이 주행하도록 제어 신호를 제공하는 단계;를 포함하는 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 2차 사고 방지 루틴을 실행하는 단계는,적어도 하나의 프로세서가, 상기 자율 주행 차량에 후행하는 타 차량과의 충돌 예측 시간을 계산하는 단계; 및적어도 하나의 프로세서가, 상기 충돌 예측 시간과 사고 지점에서 상기 회피 이동 경로에 따른 자율 주행 차량의 회피 시간을 비교하는 단계;를 포함하고,상기 제어 신호를 제공하는 단계는,적어도 하나의 프로세서가, 상기 회피 시간이 상기 충돌 예측 시간 이상인 경우, 상기 제어 신호를 제공하는 교통 사고 처리 방법."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "자율 주행 차량의 상황에 대한 데이터를 획득하고,상기 데이터에 기초하여, 상기 자율 주행 차량의 사고의 발생 여부를 판단하고, 인공 지능 알고리즘을 이용해, 상기 사고의 책임 소재를 판단하는 프로세서;를 포함하는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2019-0126024-4-제 11항에 있어서,상기 프로세서는,상기 자율 주행 차량에 구비되는 적어도 하나의 전자 장치로부터 제1 데이터를 획득하고,상기 자율 주행 차량 주변에 위치하는 타 차량에 구비되는 적어도 하나의 전자 장치로부터 제2 데이터를 획득하고,상기 자율 주행 차량 주변에 위치하는 적어도 하나의 로드 사이드 유닛(road side unit, RSU)으로부터 제3 데이터를 획득하는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 프로세서는,상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여, 상기 사고 발생 시점의 상황을 시뮬레이션으로 재구성하는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 프로세서는,맵에 상기 자율 주행 차량 및 상기 자율 주행 차량의 주변 오브젝트를 시간 순으로 맵핑하고,상기 자율 주행 차량의 주변 오브젝트에 대한 정보는,상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여 생성되는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13항에 있어서,상기 프로세서는,상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여, 상기 자율 주행 차량의 이미지를 기준으로 하는 탑뷰 이미지를 생성하고, 상기 탑뷰 이미지는,상기 자율 주행 차량의 조향 바퀴의 자세 이미지가 포함되는 동영상인 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11항에 있어서,상기 프로세서는,상기 인공 지능 알고리즘에 상기 자율 주행 차량의 상황에 대한 데이터와 교통 법규 데이터를 입력하여 출력된머신 러닝한 결과에 기초하여, 상기 사고의 책임 소재를 판단하는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서,상기 프로세서는,상기 인공 지능 알고리즘에 과거 교통 사고 히스토리 데이터를 더 입력하여 머신 러닝한 결과에 기초하여, 상기사고의 책임 소재를 판단하는 교통 사고 처리 장치.공개특허 10-2019-0126024-5-청구항 18 제 11항에 있어서,상기 프로세서는,상기 사고 발생 이후의 2차 사고에 대한 방지 루틴을 실행하는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18항에 있어서,상기 프로세서는,상기 사고 발생 이후, 상기 자율 주행 차량의 이동 가능 여부를 판단하고,상기 자율 주행 차량의 회피 이동 경로를 생성하고,상기 회피 이동 경로를 따라 상기 자율 주행 차량이 주행하도록 제어 신호를 제공하는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19항에 있어서,상기 프로세서는,상기 자율 주행 차량에 후행하는 타 차량과의 충돌 예측 시간을 계산하고,상기 충돌 예측 시간과 사고 지점에서 상기 회피 이동 경로에 따른 자율 주행 차량의 회피 시간을 비교하고,상기 회피 시간이 상기 충돌 예측 시간 이상인 경우, 상기 제어 신호를 제공하는 교통 사고 처리 장치."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 적어도 하나의 프로세서가, 자율 주행 차량의 상황에 대한 데이터를 획득하는 단계; 적어도 하나의 프 로세서가, 상기 데이터에 기초하여, 상기 자율 주행 차량의 사고의 발생 여부를 판단하는 단계; 및 적어도 하나 의 프로세서가, 인공 지능 알고리즘을 이용해, 상기 사고의 책임 소재를 판단하는 단계;를 포함하는 교통 사고 처리 방법에 관한 것이다. 교통 사고 처리 장치는 자율 주행 차량의 교통 사고를 처리할 수 있다. 자율 주행 차 량은 로봇과 연동될 수 있다. 교통 사고 처리 장치는, 인공 지능(artificial intelligence, AI) 알고리즘을 이 용해 구현될 수 있다. 교통 사고 처리 장치는, 증강 현실 (augmented reality, AR) 컨텐츠를 생성할 수 있다."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 교통 사고 처리 장치 및 교통 사고 처리 방법에 관한 것이다."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "차량은 탑승하는 사용자가 원하는 방향으로 이동시키는 장치이다. 대표적으로 자동차를 예를 들 수 있다. 자율 주행 차량은 인간의 운전 조작 없이 자동으로 주행할 수 있는 차량을 의미한다. 센서의 오작동 등의 이유로 자율 주행 차량에도 사고가 발생될 수 있다. 자율 주행 차량 간에 사고가 발생된 경 우, 사고의 책임 소재가 어디에 있는지 판단할 필요가 있다."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여, 자율 주행 차량의 교통 사고의 책임 소재를 판단하는 교통 사고 처리 장치 및 교통 사고 처리 방법을 제공하는데 목적이 있다. 본 발명의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재 로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 실시예에 따른 교통 사고 처리 방법은, 적어도 하나의 프로세서가, 자 율 주행 차량의 상황에 대한 데이터를 획득하는 단계; 적어도 하나의 프로세서가, 상기 데이터에 기초하여, 상 기 자율 주행 차량의 사고의 발생 여부를 판단하는 단계; 및 적어도 하나의 프로세서가, 인공 지능 알고리즘을 이용해, 상기 사고의 책임 소재를 판단하는 단계;를 포함한다.본 발명의 실시예에 다른 교통 사고 처리 장치는, 자율 주행 차량의 상황에 대한 데이터를 획득하고, 상기 데이 터에 기초하여, 상기 자율 주행 차량의 사고의 발생 여부를 판단하고, 인공 지능 알고리즘을 이용해, 상기 사고 의 책임 소재를 판단하는 프로세서;를 포함한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 다음과 같은 효과가 하나 혹은 그 이상 있다. 첫째, 자율 주행 자동차의 이해 관계자들에게 안전하고 편리한 사고 처리 서비스를 제공하는 효과가 있다. 둘째, 사고 처리 과정에서 발생되는 2차 사고를 방지하고 교통 체증 개선 효과가 있다."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0130391", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 실시예에 따른 차량을 도시한 도면이다. 도 1을 참조하면, 시스템은, 사용자에게 차량을 제공할 수 있다. 시스템은, 교통 사고 처리 장치, 적어도 하나의 로드 사이드 유닛 및 적어도 하나의 차량을 포함할 수 있다. 교통 사고 처리 장치는, 적어도 하나의 서버로 구현될 수 있다. 교통 사고 처리 장치는, 자율 주행 차량 의 교통 사고 발생시, 교통 사고 처리를 수행할 수 있다. 본 명세서에서는, 교통 사고 처리 장치는, 차량과는 별물인 전자 장치로 설명하나, 차량 내부에 포함되는 전자 장치일 수도 있다. 이경우, 각각의 차량은, 교통 사고 처리 장치를 포함할 수 있다. 로드 사이드 유닛(road side unit, RSU)은, 차량이 주행하는 도로 주변에 배치되는 구조물로 이해될 수 있다. 로드 사이드 유닛은, 자율 주행 차량 및 교통 사고 처리 장치 중 적어도 어느 하나와 통신을 수행할 수 있다. 로드 사이드 유닛은, 도로의 상황을 센싱하는 센싱 장치를 구비할 수 있다. 차량은, 수동 주행 차량 및 자율 주행 차량 중 적어도 어느 하나일 수 있다. 차량은, 도로나 선로 위를 달리는 수송 수단으로 정의된다. 차량은, 자동차, 기차, 오토바이를 포함하는 개념이다. 차량은, 동력 원으로서 엔진을 구비하는 내연기관 차량, 동력원으로서 엔진과 전기 모터를 구비하는 하이브리드 차량, 동력원 으로서 전기 모터를 구비하는 전기 차량등을 모두 포함하는 개념일 수 있다. 차량에는 전자 장치가 포함될 수 있다. 전자 장치는, 교통 사고 처리 장치와의 인터렉션을 위 해 차량에 구비될 수 있다. 한편, 차량은, 적어도 하나의 로봇(robot)과 상호 작용할 수 있다. 로봇은, 자력으로 주행이 가능한 이동 로봇(Autonomous Mobile Robot, AMR)일 수 있다. 이동 로봇은, 스스로 이동이 가능하여 이동이 자유롭고, 주행 중 장애물 등을 피하기 위한 다수의 센서가 구비되어 장애물을 피해 주행할 수 있다. 이동 로봇은, 비행 장치를 구비하는 비행형 로봇(예를 들면, 드론)일 수 있다. 이동 로봇은, 적어도 하나의 바퀴를 구비하고, 바퀴의 회전 을 통해 이동되는 바퀴형 로봇일 수 있다. 이동 로봇은, 적어도 하나의 다리를 구비하고, 다리를 이용해 이동되 는 다리식 로봇일 수 있다. 로봇은 차량 사용자의 편의를 보완하는 장치로 기능할 수 있다. 예를 들면, 로봇은, 차량에 적재된 짐 을 사용자의 최종 목적지까지 이동하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용 자에게 최종 목적지까지 길을 안내하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용 자를 최종 목적지까지 수송하는 기능을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 로봇과 통신을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇에 차량에 포함되는 적어도 하나의 전자 장치에서 처리한 데 이터를 제공할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 오브젝트 데이터, HD 맵 데이 터, 차량 상태 데이터, 차량 위치 데이터 및 드라이빙 플랜 데이터 중 적어도 어느 하나를 로봇에 제공할 수 있 다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터, 로봇에서 처리된 데이터를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇에서 생성된 센싱 데이터, 오브젝트 데이터, 로봇 상태 데이터, 로봇 위치 데이터 및 로봇의 이동 플랜 데이터 중 적어도 어느 하나를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터 수신된 데이터에 더 기초하여, 제어 신호를 생성할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 오브젝트 검출 장치에 생성된 오브젝트 에 대한 정보와 로봇에 의해 생성된 오브젝트에 대한 정보를 비교하고, 비교 결과에 기초하여, 제어 신호를 생 성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 차량의 이동 경로와 로봇의 이동 경로간의 간 섭이 발생되지 않도록, 제어 신호를 생성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능(artificial intelligence, AI)를 구현하는 소프트웨어 모듈 또는 하드웨어 모듈(이하, 인공 지능 모듈)을 포함할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치 는, 획득되는 데이터를 인공 지능 모듈에 입력(input)하고, 인공 지능 모듈에서 출력(output)되는 데이터를 이 용할 수 있다. 인공 지능 모듈은, 적어도 하나의 인공 신경망(artificial neural network, ANN)을 이용하여, 입력되는 데이터 에 대한 기계 학습(machine learning)을 수행할 수 있다. 인공 지능 모듈은, 입력되는 데이터에 대한 기계 학습 을 통해, 드라이빙 플랜 데이터를 출력할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능 모듈에서 출력되는 데이터에 기초하여, 제어 신호를 생 성할 수 있다. 실시예에 따라, 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 외부 장치로부터, 인공 지능에 의해 처리된 데이터를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능에 의해처리된 데이터에 기초하여, 제어 신호를 생성할 수 있다. 도 2는 본 발명의 실시예에 따른 차량의 제어 블럭도이다. 도 2를 참조하면, 차량은, 차량용 전자 장치, 사용자 인터페이스 장치, 오브젝트 검출 장치 , 통신 장치, 운전 조작 장치, 메인 ECU, 차량 구동 장치, 주행 시스템, 센싱 부 및 위치 데이터 생성 장치를 포함할 수 있다. 차량용 전자 장치는, 통신 장치를 통해, 교통 사고 처리 장치와 신호, 정보 또는 데이터를 교환할 수 있다. 차량용 전자 장치는, 교통 사고 처리 장치에서 수신되는 신호, 정보 또는 데이터를 차량 내 다른 전자 장치에 제공할 수 있다. 사용자 인터페이스 장치는, 차량과 사용자와의 소통을 위한 장치이다. 사용자 인터페이스 장치는, 사용자 입력을 수신하고, 사용자에게 차량에서 생성된 정보를 제공할 수 있다. 차량은, 사용자 인터페이스 장치를 통해, UI(User Interface) 또는 UX(User Experience)를 구현할 수 있다. 오브젝트 검출 장치는, 차량 외부의 오브젝트를 검출할 수 있다. 오브젝트 검출 장치는, 차량 외부의 오브젝트를 검출할 수 있는 적어도 하나의 센서를 포함할 수 있다. 오브젝트 검출 장치는, 카 메라, 레이다, 라이다, 초음파 센서 및 적외선 센서 중 적어도 하나를 포함할 수 있다. 오브젝트 검출 장치 는, 센서에서 생성되는 센싱 신호에 기초하여 생성된 오브젝트에 대한 데이터를 차량에 포함된 적어도 하 나의 전자 장치에 제공할 수 있다. 카메라는 영상을 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 카메라는 적어도 하나의 렌즈, 적어도 하나의 이미지 센서 및 이미지 센서와 전기적으로 연결되어 수신되는 신호를 처리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 카메라는, 모노 카메라, 스테레오 카메라, AVM(Around View Monitoring) 카메라 중 적어도 어느 하나일 수 있다. 카메라는, 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오브젝트와의 거리 정보 또는 오브젝트와의 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 획득된 영상에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 핀 홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 스테레오 카메라에서 획득된 스테레오 영상에서 디스패러티(disparity) 정보를 기초로 오 브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 카메라는, 차량 외부를 촬영하기 위해 차량에서 FOV(field of view) 확보가 가능한 위치에 장착될 수 있다. 카 메라는, 차량 전방의 영상을 획득하기 위해, 차량의 실내에서, 프런트 윈드 쉴드에 근접하게 배치될 수 있다. 카메라는, 프런트 범퍼 또는 라디에이터 그릴 주변에 배치될 수 있다. 카메라는, 차량 후방의 영상을 획득하기 위해, 차량의 실내에서, 리어 글라스에 근접하게 배치될 수 있다. 카메라는, 리어 범퍼, 트렁크 또는 테일 게이 트 주변에 배치될 수 있다. 카메라는, 차량 측방의 영상을 획득하기 위해, 차량의 실내에서 사이드 윈도우 중 적어도 어느 하나에 근접하게 배치될 수 있다. 또는, 카메라는, 사이드 미러, 휀더 또는 도어 주변에 배치될 수 있다. 레이다는 전파를 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 레이다는, 전자파 송신부, 전자파 수신부 및 전자파 송신부 및 전자파 수신부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리되 는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 레이다는 전파 발사 원리상 펄스 레이다(Pulse Radar) 방식 또는 연속파 레이다(Continuous Wave Radar) 방식으로 구현 될 수 있다. 레이다는 연속파 레이다 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keyong) 방식으로 구현될 수 있다. 레이다는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이다는, 차량의 전방, 후방 또는 측방에 위 치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 라이다는, 레이저 광을 이용하여, 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 라이다는, 광 송신 부, 광 수신부 및 광 송신부 및 광 수신부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식 으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 차량 주변의 오브젝트를 검출할 수 있다. 비구동식으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 차량을 기준으로 소정 범위 내에 위치하는 오브젝트를 검출할 수 있다. 차량은 복수의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 차량 의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 통신 장치는, 차량 외부에 위치하는 디바이스와 신호를 교환할 수 있다. 통신 장치는, 인프라(예 를 들면, 서버, 방송국) 및 타 차량 중 적어도 어느 하나와 신호를 교환할 수 있다. 통신 장치는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 통신 장치는, 5G(예를 들면, 뉴 라디오(new radio, NR)) 방식을 이용하여, 차량 외부에 위치하는 디바 이스와 통신할 수 있다. 통신 장치는, 5G 방식을 이용하여, V2X(V2V, V2D, V2P,V2N) 통신을 구현할 수 있 다. 운전 조작 장치는, 운전을 위한 사용자 입력을 수신하는 장치이다. 메뉴얼 모드인 경우, 차량은, 운전 조작 장치에 의해 제공되는 신호에 기초하여 운행될 수 있다. 운전 조작 장치는, 조향 입력 장치(예 를 들면, 스티어링 휠), 가속 입력 장치(예를 들면, 가속 페달) 및 브레이크 입력 장치(예를 들면, 브레이크 페 달)를 포함할 수 있다. 메인 ECU는, 차량 내에 구비되는 적어도 하나의 전자 장치의 전반적인 동작을 제어할 수 있다. 구동 제어 장치는, 차량내 각종 차량 구동 장치를 전기적으로 제어하는 장치이다. 구동 제어 장치 는, 파워 트레인 구동 제어 장치, 샤시 구동 제어 장치, 도어/윈도우 구동 제어 장치, 안전 장치 구동 제 어 장치, 램프 구동 제어 장치 및 공조 구동 제어 장치를 포함할 수 있다. 파워 트레인 구동 제어 장치는, 동력 원 구동 제어 장치 및 변속기 구동 제어 장치를 포함할 수 있다. 샤시 구동 제어 장치는, 조향 구동 제어 장치, 브레이크 구동 제어 장치 및 서스펜션 구동 제어 장치를 포함할 수 있다. 한편, 안전 장치 구동 제어 장치는, 안전 벨트 제어를 위한 안전 벨트 구동 제어 장치를 포함할 수 있다. 차량 구동 제어 장치는, 제어 ECU(Electronic Control Unit)로 명명될 수 있다. 주행 시스템는, 오브젝트 검출 장치에서 수신한 오브젝트에 대한 데이터에 기초하여, 차량의 움 직임을 제어하거나, 사용자에게 정보를 출력하기 위한 신호를 생성할 수 있다. 주행 시스템는, 생성된 신 호를, 사용자 인터페이스 장치, 메인 ECU 및 차량 구동 장치 중 적어도 어느 하나에 제공할 수 있다. 주행 시스템은, ADAS를 포함하는 개념일 수 있다. ADAS는, 적응형 크루즈 컨트롤 시스템(ACC : Adaptive Cruise Control), 자동 비상 제동 시스템(AEB : Autonomous Emergency Braking), 전방 충돌 알림 시 스템(FCW : Foward Collision Warning), 차선 유지 보조 시스템(LKA : Lane Keeping Assist), 차선 변경 보조 시스템(LCA : Lane Change Assist), 타겟 추종 보조 시스템(TFA : Target Following Assist), 사각 지대 감시 시스템(BSD : Blind Spot Detection), 적응형 하이빔 제어 시스템(HBA : High Beam Assist), 자동 주차 시스템 (APS : Auto Parking System), 보행자 충돌 알림 시스템(PD collision warning system), 교통 신호 검출 시스 템(TSR : Traffic Sign Recognition), 교통 신호 보조 시스템(TSA : Trafffic Sign Assist), 나이트 비전 시스 템(NV : Night Vision), 운전자 상태 모니터링 시스템(DSM : Driver Status Monitoring) 및 교통 정체 지원 시 스템(TJA : Traffic Jam Assist) 중 적어도 어느 하나를 구현할 수 있다. 주행 시스템은, 자율 주행 ECU(Electronic Control Unit)를 포함할 수 있다. 자율 주행 ECU는, 차량 내 다른 전자 장치들 중 적어도 어느 하나로부터 수신되는 데이터에 기초하여, 자율 주행 경로를 설정할 수 있 다. 자율 주행 ECU는, 사용자 인터페이스 장치, 오브젝트 검출 장치, 통신 장치, 센싱부 및 위치 데이터 생성 장치 중 적어도 어느 하나로부터 수신되는 데이터에 기초하여, 자율 주행 경로를 설 정할 수 있다. 자율 주행 ECU는, 자율 주행 경로를 따라 차량이 주행하도록 제어 신호를 생성할 수 있다. 자율 주행 ECU에서 생성된 제어 신호는, 메인 ECU 및 차량 구동 장치 중 적어도 어느 하나로 제공될 수 있다. 센싱부는, 차량의 상태를 센싱할 수 있다. 센싱부는, IMU(inertial navigation unit) 센서, 충돌 센 서, 휠 센서(wheel sensor), 속도 센서, 경사 센서, 중량 감지 센서, 헤딩 센서(heading sensor), 포지션 모듈(position module), 차량 전진/후진 센서, 배터리 센서, 연료 센서, 타이어 센서, 핸들 회전에 의한 스티어링 센서, 차량 내부 온도 센서, 차량 내부 습도 센서, 초음파 센서, 조도 센서, 가속 페달 포지션 센서 및 브레이 크 페달 포지션 센서 중 적어도 어느 하나를 포함할 수 있다. 한편, IMU(inertial navigation unit) 센서는, 가속도 센서, 자이로 센서, 자기 센서 중 하나 이상을 포함할 수 있다. 센싱부는, 적어도 하나의 센서에서 생성되는 신호에 기초하여, 차량의 상태 데이터를 생성할 수 있다. 센 싱부는, 차량 자세 정보, 차량 모션 정보, 차량 요(yaw) 정보, 차량 롤(roll) 정보, 차량 피치(pitch) 정 보, 차량 충돌 정보, 차량 방향 정보, 차량 각도 정보, 차량 속도 정보, 차량 가속도 정보, 차량 기울기 정보, 차량 전진/후진 정보, 배터리 정보, 연료 정보, 타이어 정보, 차량 램프 정보, 차량 내부 온도 정보, 차량 내부 습도 정보, 스티어링 휠 회전 각도, 차량 외부 조도, 가속 페달에 가해지는 압력, 브레이크 페달에 가해지는 압 력 등에 대한 센싱 신호를 획득할 수 있다. 센싱부는, 그 외, 가속페달센서, 압력센서, 엔진 회전 속도 센서(engine speed sensor), 공기 유량 센서 (AFS), 흡기 온도 센서(ATS), 수온 센서(WTS), 스로틀 위치 센서(TPS), TDC 센서, 크랭크각 센서(CAS), 등을 더 포함할 수 있다. 센싱부는, 센싱 데이터를 기초로, 차량 상태 정보를 생성할 수 있다. 차량 상태 정보는, 차량 내부에 구비 된 각종 센서에서 감지된 데이터를 기초로 생성된 정보일 수 있다. 예를 들면, 차량 상태 정보는, 차량의 자세 정보, 차량의 속도 정보, 차량의 기울기 정보, 차량의 중량 정보, 차량의 방향 정보, 차량의 배터리 정보, 차량의 연료 정보, 차량의 타이어 공기압 정보, 차량의 스티어링 정보, 차량 실내 온도 정보, 차량 실내 습도 정보, 페달 포지션 정보 및 차량 엔진 온도 정보 등을 포함할 수 있다. 한편, 센싱부는, 텐션 센서를 포함할 수 있다. 텐션 센서는, 안전 벨트의 텐션 상태에 기초하여 센싱 신호를 생 성할 수 있다. 위치 데이터 생성 장치는, 차량의 위치 데이터를 생성할 수 있다. 위치 데이터 생성 장치는, GPS(Global Positioning System) 및 DGPS(Differential Global Positioning System) 중 적어도 어느 하나를 포 함할 수 있다. 위치 데이터 생성 장치는, GPS 및 DGPS 중 적어도 어느 하나에서 생성되는 신호에 기초하여 차량의 위치 데이터를 생성할 수 있다. 실시예에 따라, 위치 데이터 생성 장치는, 센싱부의 IMU(Inertial Measurement Unit) 및 오브젝트 검출 장치의 카메라 중 적어도 어느 하나에 기초하여 위치 데이터를 보정할 수 있다. 위치 데이터 생성 장치는, 위치 측위 장치로 명명될 수 있다. 위치 데이터 생성 장치는, GNSS(Global Navigation Satellite System)로 명명될 수 있다. 차량은, 내부 통신 시스템을 포함할 수 있다. 차량에 포함되는 복수의 전자 장치는 내부 통신 시스 템을 매개로 신호를 교환할 수 있다. 신호에는 데이터가 포함될 수 있다. 내부 통신 시스템은, 적어도 하나의 통신 프로토콜(예를 들면, CAN, LIN, FlexRay, MOST, 이더넷)을 이용할 수 있다. 도 3은 본 발명의 실시예에 따른 전자 장치의 제어 블럭도이다. 도 3을 참조하면, 교통 사고 처리 장치는, 통신 장치, 메모리, 프로세서, 인터페이스부 및 전원 공급부를 포함할 수 있다. 통신 장치는, 차량 및 차량 외부 통신 장치와 신호를 교환할 수 있다. 차량 외부 통신 장치는 로드 사 이드 유닛 및 외부 서버를 포함할 수 있다. 통신 장치는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 통신 장치는, 5G(예를 들면, 뉴 라디오(new radio, NR)) 방식을 이용하여, 차량 및 로드 사이드 유닛 과 차량 외부 통신 장치와 통신할 수 있다. 이하 본 발명의 실시예에 따른 차량 외부 통신 장치는, 로드 사 이드 유닛을 기반으로 설명될 수 있다. 메모리는, 프로세서와 전기적으로 연결된다. 메모리는 유닛에 대한 기본데이터, 유닛의 동작제 어를 위한 제어데이터, 입출력되는 데이터를 저장할 수 있다. 메모리는, 프로세서에서 처리된 데이터 를 저장할 수 있다. 메모리는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 중 적 어도 어느 하나로 구성될 수 있다. 메모리는 프로세서의 처리 또는 제어를 위한 프로그램 등, 교통사고 처리 장치 전반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 프로세서와 일체 형으로 구현될 수 있다. 실시예에 따라, 메모리는, 프로세서의 하위 구성으로 분류될 수 있다. 인터페이스부는, 차량 내에 구비되는 적어도 하나의 전자 장치와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 사용자 인터페이스 장치, 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 차량 구동 장치, 주행 시스템, 센싱부 및 위치 데이터 생성 장치 중 적어도 어느 하나와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 통신 모듈, 단자, 핀, 케이블, 포트, 회로, 소자 및 장치 중 적어도 어느 하나로 구성될 수 있다. 전원 공급부는, 교통 사고 처리 장치에 전원을 공급할 수 있다. 전원 공급부는, 차량에 포함 된 파워 소스(예를 들면, 배터리)로부터 전원을 공급받아, 교통 사고 처리 장치의 각 유닛에 전원을 공급할 수 있다. 전원 공급부는, 메인 ECU로부터 제공되는 제어 신호에 따라 동작될 수 있다. 전원 공급부 는, SMPS(switched-mode power supply)로 구현될 수 있다. 프로세서는, 메모리, 인터페이스부, 전원 공급부와 전기적으로 연결되어 신호를 교환할 수 있다. 프로세서는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro- controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이 용하여 구현될 수 있다. 프로세서는, 전원 공급부로부터 제공되는 전원에 의해 구동될 수 있다. 프로세서는, 전원 공급 부에 의해 전원이 공급되는 상태에서 데이터를 수신하고, 데이터를 처리하고, 신호를 생성하고, 신호를 제 공할 수 있다. 프로세서는, 인터페이스부를 통해, 차량 내 다른 전자 장치로부터 정보를 수신할 수 있다. 프로 세서는, 인터페이스부를 통해, 차량 내 다른 전자 장치로 제어 신호를 제공할 수 있다. 프로세서는, 자율 주행 차량의 상황에 대한 데이터를 획득할 수 있다. 프로세서는, 자율 주행 차 량에 구비되는 적어도 하나의 전자 장치로부터 제1 데이터를 획득할 수 있다. 예를 들면, 프로세서는, 자율 주행 차량에 구비되는 오브젝트 검출 장치 및 센싱부 중 적어도 어느 하나로부터 제1 데이 터를 획득할 수 있다. 제1 데이터는, 자율 주행 차량의 위치 정보, 속도 정보, 헤딩 정보, 가속도 정보, 감 속도 정보, 조향 정보, 브레이크 정보, 충격량 정보 중 적어도 어느 하나를 포함할 수 있다. 제1 데이터는, 자 율 주행 차량 주변의 오브젝트에 대한 데이터일 수 있다. 프로세서는, 자율 주행 차량 주변에 위치하 는 타 차량에 구비되는 적어도 하나의 전자 장치로부터 제2 데이터를 획득할 수 있다. 타 차량은, 타 자율 주행 차량일 수 있다. 예를 들면, 프로세서는, 타 자율 주행 차량에 구비되는 오브젝트 검출 장치 및 센싱부 중 적어도 어느 하나로부터 제2 데이터를 획득할 수 있다. 제2 데이터는, 자율 주행 차량이 센싱된 센싱 데이 터를 포함할 수 있다. 제2 데이터는, 타 자율 주행 차량의 위치 정보, 속도 정보, 헤딩 정보, 가속도 정보, 감 속도 정보, 조향 정보, 브레이크 정보, 충격량 정보 중 적어도 어느 하나를 포함할 수 있다. 프로세서는, 자율 주행 차량 주변에 위치하는 적어도 하나의 외부 통신 장치로부터 제3 데이터를 획득 할 수 있다. 제3 데이터는, 로드 사이드 유닛이 획득한 차량이 센싱된 센싱 데이터일 수 있다. 제3 데이 터는, 외부 서버가 로드 사이드 유닛으로부터 획득한 차량이 센싱된 센싱 데이터일 수 있다. 프로세서는, 자율 주행 차량 주변에 위치하는 적어도 하나의 로드 사이드 유닛으로부터 제3 데이터 를 획득할 수 있다. 제3 데이터는, 자율 주행 차량이 센싱된 센싱 데이터(예를 들면, 영상 데이터), 신호등 데이터, 지도 데이터 중 적어도 어느 하나를 포함할 수 있다. 프로세서는, 자율 주행 차량의 상황에 대한 데이터에 기초하여, 자율 주행 차량의 사고 발생 여부를 판단할 수 있다. 프로세서는, 자율 주행 차량으로부터 획득된 제1 데이터, 타 자율 주행 차량으로부터 획득된 제2 데이터 및 로드 사이드 유닛으로부터 획득된 제3 데이터 중 적어도 어느 하나에 기초하여, 자율 주 행 차량의 사고 발생 여부를 판단할 수 있다. 예를 들면, 자율 주행 차량의 속도 정보, 가속도 정보, 감속도 정보, 브레이크 정보, 충격량 정보와 타 자율 주행 차량이나 로드 사이드 유닛으로부터 획득된 영상 데 이터에 기초하여, 자율 주행 차량의 사고 발생 여부를 판단할 수 있다. 프로세서는, 인공 지능 알고리즘을 이용해, 사고의 책임 소재를 판단할 수 있다. 프로세서는, 자율 주행 차량으로부터 획득된 제1 데이터, 타 자율 주행 차량으로부터 획득된 제2 데이 터 및 로드 사이드 유닛으로부터 획득된 제3 데이터 중 적어도 어느 하나에 기초하여, 사고 발생 시점의 상황을 시뮬레이션으로 재구성할 수 있다. 예를 들면, 프로세서는, 자율 주행 차량으로부터 획득된 영상 데이터, 타 자율 주행 차량으로부터 획 득된 영상 데이터 및 로드 사이드 유닛으로부터 획득된 영상 데이터를 합성하고 편집하여, 사고 발생 시점의 상 황을 시뮬레이션으로 재구성할 수 있다. 예를 들면, 프로세서는, 맵에 자율 주행 차량 및 자율 주행 차량의 주변 오브젝트를 시간순으로 맵핑 할 수 있다. 프로세서는, 자율 주행 차량 및 자율 주행 차량의 주변 오브젝트의 맵핑을 통해, 사고 발 생 시점의 상황을 시뮬레이션으로 재구성할 수 있다. 한편, 자율 주행 차량의 주변 오브젝트에 대한 정보는, 자율 주행 차량으로부터 획득된 제1 데이터, 타 자율 주행 차량으로부터 획득된 제2 데이터 및 로 드 사이드 유닛으로부터 획득된 제3 데이터 중 적어도 어느 하나에 기초하여 생성될 수 있다. 예를 들면, 프로세서는, 자율 주행 차량으로부터 획득된 제1 데이터, 타 자율 주행 차량으로부터 획득 된 제2 데이터 및 로드 사이드 유닛으로부터 획득된 제3 데이터 중 적어도 어느 하나에 기초하여, 자율 주행 차 량의 이미지를 기준으로 하는 탑뷰 이미지를 생성할 수 있다. 프로세서는, 탑뷰 이미지를 생성함으로 써, 사고 발생 시점의 상황을 시뮬레이션으로 재구성할 수 있다. 탑뷰 이미지는, 자율 주행 차량의 조향 바퀴의 자세 이미지가 포함되는 동영상일 수 있다. 프로세서는, 인공 지능(artificial intelligence, AI) 알고리즘에 자율 주행 차량의 상황에 대한 데 이터와 교통 법류 데이터를 입력하여 머신 러닝(machine learning)한 결과에 기초하여, 사고 책임 소재를 판단 할 수 있다. 프로세서는, 인공 지능 알고리즘에 과거 교통 사고 히스토리 데이터를 더 입력하여 머신 러닝 한 결과에 기초하여, 사고 책임 소재를 판단할 수 있다. 인공 지능 알고리즘은, 적어도 하나의 인공 신경망(artificial neural network, ANN)을 이용하여, 입력되는 데 이터에 대한 기계 학습(machine learning)을 수행할 수 있다. 프로세서는, 사고 발생 이후의 2차 사고에 대한 방지 루틴을 실행할 수 있다. 프로세서는, 사고 발생 이후, 자율 주행 차량의 이동 가능 여부를 판단할 수 있다. 프로세서는, 자율 주행 차량이 이동 가능하다고 판단되는 경우, 자율 주행 차량의 회피 경로를 생성할 수 있다. 프 로세서는, 회피 경로를 따라 자율 주행 차량이 주행하도록 제어 신호를 제공할 수 있다. 프로세서는, 자율 주행 차량에 후행하는 타 차량과의 충돌 예측 시간을 계산할 수 있다. 프로세서 는, 충돌 예측 시간과 사고 지점에서 회피 이동 경로에 따른 자율 주행 차량의 회피 시간을 비교할 수 있다. 프로세서는, 회피 시간이 충돌 예측 시간 이상인 경우, 회피 경로를 따라 자율 주행 차량이 주 행하도록 제어 신호를 제공할 수 있다. 교통 사고 처리 장치는, 적어도 하나의 인쇄 회로 기판(printed circuit board, PCB)을 포함할 수 있다. 메 모리, 인터페이스부, 전원 공급부 및 프로세서는, 인쇄 회로 기판에 전기적으로 연결될 수 있다. 도 4는 본 발명의 실시예에 따른 교통 사고 처리 방법(S400)을 설명하는데 참조되는 도면이다. 도 4를 참조하면, 프로세서는, 자율 주행 차량의 상황에 대한 데이터를 획득할 수 있다(S410). 데이터 를 획득 하는 단계(S410)는, 적어도 하나의 프로세서가, 자율 주행 차량에 구비되는 적어도 하나의 전 자 장치로부터 제1 데이터를 획득하는 단계, 적어도 하나의 프로세서가, 자율 주행 차량 주변에 위치 하는 타 차량에 구비되는 적어도 하나의 전자 장치로부터 제2 데이터를 획득하는 단계 및 적어도 하나의 프로세 서가, 자율 주행 차량 주변에 위치하는 적어도 하나의 로드 사이드 유닛으로부터 제3 데이터를 획득하는 단계를 포함할 수 있다. 프로세서는, 자율 주행 차량의 상황에 대한 데이터에 기초하여, 자율 주행 차량의 사고의 발생 여 부를 판단할 수 있다(S420). 자율 주행 차량에 사고가 발생한 것으로 판단되는 경우, 프로세서는, 인공 지능 알고리즘을 이용해, 사고의 책임 소재를 판단할 수 있다(S430). 책임 소재를 판단하는 단계(S430)는, 적어도 하나의 프로세서가, 자율 주행 차량으로부터 획득된 제1 데이터, 타 자율 주행 차량으로부터 획득된 제2 데이터 및 로드 사이드 유닛으로부터 획득된 제3 데이터 중 적 어도 어느 하나에 기초하여, 사고 발생 시점의 상황을 시뮬레이션으로 재구성하는 단계를 포함할 수 있다. 예를 들면, 재구성하는 단계는, 적어도 하나의 프로세서가, 맵에 자율 주행 차량 및 자율 주행 차량의 주변 오브젝트를 시간 순으로 맵핑하는 단계를 포함할 수 있다. 이경우, 자율 주행 차량의 주변 오브젝트에 대한 정보는, 상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여 생성될 수 있다. 예를 들면, 재구성하는 단계는, 적어도 하나의 프로세서가, 상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터 중 적어도 어느 하나에 기초하여, 자율 주행 차량의 이미지를 기준으로하는 탑뷰 이미 지를 생성하는 단계를 포함할 수 있다. 여기서, 탑뷰 이미지는, 자율 주행 차량의 조향 바퀴의 자세 이미지 가 포함되는 동영상일 수 있다. 책임 소재를 판단하는 단계(S430)는, 적어도 하나의 프로세서가, 인공 지능 알고리즘에 자율 주행 차량 의 상황에 대한 데이터 및 교통 법규 데이터를 입력하여 머신 런닝한 결과에 기초하여, 사고의 책임 소재를 판단할 수 있다. 책임 소재를 판단하는 단계(S430)는, 적어도 하나의 프로세서가, 인공 지능 알고리즘에 과거 교통 사고 히스토리 데이터를 더 입력하여 머신 러닝한 결과에 기초하여, 사고의 책임 소재를 판단할 수 있다. 자율 주행 차량에 사고가 발생한 것으로 판단되는 경우, 프로세서는, 상기 사고 발생 이후의 2차 사고 에 대한 방지 루틴을 실행할 수 있다(S430). 2차 사고 방지 루틴을 실행하는 단계(S430)는, 적어도 하나의 프로세서가, 사고 발생 이후, 자율 주행 차 량의 이동 가능 여부를 판단하는 단계, 적어도 하나의 프로세서가, 자율 주행 차량의 회피 이동 경로를 생성하는 단계 및 적어도 하나의 프로세서가, 회피 이동 경로를 따라 자율 주행 차량이 주행하 도록 제어 신호를 제공하는 단계를 포함할 수 있다. 2차 사고 방지 루틴을 실행하는 단계(S430)는, 적어도 하나의 프로세서가, 자율 주행 차량에 후행하는 타 차량과의 충돌 예측 시간을 계산하는 단계, 적어도 하나의 프로세서가, 충돌 예측 시간과 사고 지점에 서 회피 이동 경로에 따른 자율 주행 차량의 회피 시간을 비교하는 단계를 포함할 수 있다. 이때, 제어 신 호를 제공하는 단계는, 적어도 하나의 프로세서가, 상기 회피 시간이 상기 출돌 예측 시간 이상인 경우, 상기 제어 신호를 제공할 수 있다. 도 5 내지 도 8은 본 발명의 실시예에 따른 교통 사고 처리 방법을 설명하는데 참조되는 도면이다. 도 5 내지 도 8은, 차량에 교통 사고 처리 장치가 포함되는 경우의 플로우 차트를 예시한다. 도 5를 참조하면, 프로세서는, 차량에 의해 수집된 사고 데이터가 충분한지 판단할 수 있다(S510). 차 량의 수집 데이터의 충분 여부는, 사고 직전 일정 시간 동안의 차량 및 주변 오브젝트의 이동 궤적, 신 호등 정보 등 수집 여부로 판단될 수 있다. S510 단계에서 충분하다고 판단되는 경우, 프로세서는, 차량 이 수집한 사고 데이터를 서버로 전송하고, 2차 사고 방지 루틴을 실행할 수 있다(S520). S520 단계에서 충분하지 않다고 판단되는 경우, 프로세서는, 추가 데이터 수집이 가능한지 판단할 수 있다(S530). S530 단계에서 수집 가능하다고 판단되는 경우, 프로세서는, 타 차량 또는 로드 사이드 유닛으로부터 데이터를 추가 수집하고, 2차 사고 방지 루틴을 실행할 수 있다(S540). 프로세서는, 데이터 추가 수집 완료 후, 데 이터를 서버로 전송하고, 2차 사고 방지 루틴을 실행할 수 있다(S550). 프로세서는, 사고의 책임 소재를 판단할 수 있다(S560). 책임 소재에 대한 판단은, 수집된 사고 데이터를 서버에 저장된 과거의 사고 책임 소재 판정 사례와 매칭하여 이루어질 수 있다. S560 단계에서, 사고의 책임 소 재 판단이 가능한 경우, 프로세서는, 책임소재 판단 결과를 사고 이해관계자들에게 제공하고, 사고 처리를 할 수 있다(S570). S560 단계에서, 프로세서는, 사고의 책임 소재 판단이 불가능한 경우, 보험사 직원을 호출할 수 있다(S580). 호출된 보험사 직원은 이후의 사고 처리를 수행할 수 있다. 도 6을 참조하면, 프로세서는, 수집된 사고 데이터가 충분한지 판단할 수 있다(S605). S605 단계에서, 충 분하지 않다고 판단되는 경우, 프로세서는, 타 차량이 존재하는지 판단할 수 있다(S610). S610 단계에서, 타 차량이 존재하는 것으로 판단되는 경우, 프로세서는, 타 차량이 소정 조건에 만족하는지 판단할 수 있 다(S615). 예를 들면, 프로세서는, 타 차량이 차량 소정 반경 이내에 위치하는지 판단할 수 있다. S615 단 계에서, 타 차량이 소정 조건을 만족하지 않는 것으로 판단되는 경우, 프로세서는, 2차 사고 방지를 위해 서버로부터 후방 차량의 현재 위치 도달 시점, 안전 지역까지의 주행 가능 영역, 추가 취득이 필요한 데이터를 수신할 수 있다(S620). 프로세서는, 영역 내 도달시점 내에 필요 데이터를 수집 가능하도록하는 이동 경로를 산출하고, 경로에 따라 차량을 이동시킬 수 있다(S625). 프로세서는, 차량 이동시, 이동 궤적 을 포함하는 센서 데이터를 스트리밍 전송할 수 있다(S630). 프로세서는, 사고 데이터를 수집하고 사고 현 장으로부터 차량 이동을 추적할 수 있다. 프로세서는, 차량의 정차 상태를 유지하고, 2차 사고 가능성 에 대비하여 타 차량 접근 방향 및 회피 방향에 대한 모니터링을 활성화할 수 있다(S635). S605 단계에서 수집된 데이터가 충분하다고 판단되는 경우, 프로세서는, 수집된 사고 데이터로 산출된 사 고 상황과 서버 저장소의 기존 사고 상황을 매칭할 수 있다(S650). 프로세서는, 사고 지역, 파손 영역, 사고 전 조작 등의 일치도가 일정 수준 이상인 경우 실시간으로 사고 상황에 관한 내용을 산출하고, 산출 내용을 전송할 수 있다(S655). 프로세서는, 사고 당사자들이 산출된 내용에 납득하는지 판단할 수 있다 (S660). S660 단곙 계에서 납득하는 것으로 판단되는 경우, 프로세서는, 자율 주행 기능이 유지 가능한지 판단할 수 있다(S665). S665 단계에서 자율 주행 기능이 유지 가능하다고 판단되는 경우, 프로세서는, 차 량 사고 피해 상황에 따라 목적지를 자동 설정하고, 목적지를 차량을 이동시킬 수 있다. 여기서, 자동 설정 된 목적지는, 기존 목적지, 정비소 및 대피소 중 적어도 어느 하나일 수 있다. S665 단계에서 자율 주행이 기능 이 유지 불가능하다고 판단되는 경우, 안전 지역(예를 들면, 갓길)을 설정하고, 해당 지역으로 차량이 이동하도 록 제어 신호를 제공할 수 있다(S675). 한편, S660 단계에서 사고 당사자들이 산출된 내용에 납득하지 못하는 경우, 프로세서는, 사고 파악, 증거 수집, 피해 정산 등의 작업을 위한 응급 서비스 차량 또는 보험사 직원을 호출할 수 있다(S680). 응급 서비스 차량 또는 보험사 직원이 도착 대기할 수 있다(S685). 프로세서는, 타 차량이 존재하는지 판단할 수 있다 (S690). 타 차량이 존재하는 것으로 판단되는 경우, 프로세서는, S615 단계로 이동할 수 있다. 타 차량이 존재하지 않는 것으로 판단되는 경우, 프로세서는, S685 단계로 이동할 수 있다. 한편, S610 단계에서, 타 차량이 존재하지 않는 것으로 판단되는 경우, 프로세서는, S680 단계로 이동할 수 있다. 한편, S615 단계에서, 타 차량이 소정 조건을 만족하는 것으로 판단되는 경우, 프로세서는, 타 차량에 추 가 데이터 취득을 위한 요청 신호를 전송할 수 있다. 프로세서는, 추가 데이터에 대한 수신 완료 여부를 판단할 수 있다(S645). S645 단계에서, 추가 데이터가 수신 완료되는 것으로 판단되는 경우, 프로세서는, S650 단계로 이동할 수 있다. 도 7을 참조하면, 프로세서는, 차량 정보 및 차량 주변 오브젝트 정보를 제1 데이터 베이스에 일정 주기로 기록할 수 있다(S710). 제1 데이터 베이스는, 메모리의 하위 구성으로 분류될 수 있다. 차량 정보는, 차량의 포지션(position), 속도(speed), 헤딩(heading), 가속도(acceleration)등 차량의 움직임 상태 관련 정보로 설명될 수 있다. 오브젝트 정보는, 차량, 이륜차, 보행자, 장애물 등 센서를 이용하여 검출 및 추 적되는 차량 주변의 물체들의 포지션(position), 속도(speed), 헤딩(heading), 가속도(acceleration)등 오브젝 트의 움직임 상태 관련 정보로 설졍될 수 있다. 프로세서는, 차량 주변 영상 정보를 제2 데이터 베이스 에 일정 주기로 기록할 수 있다(S720). 제2 데이터 베이스는, 메모리의 하위 구성으로 분류될 수 있다. 프로세서는, 신호등이 있는 경우, 카메라 또는 V2X로부터의 정보를 이용하여 신호등 정보를 제3 데이터 베이스에 일정 주기로 기록할 수 있다(S730). 제3 데이터 베이스는, 메모리의 하위 구성 으로 분류될 수 있다. 프로세서는, 사고가 발생되었는지 판단할 수 있다(S740). 사고가 발생된 것으로 판단되는 경우, 프로세서 는, 사고 발생 직전 일정 시간 동안 차량/객체 정보, 주변 영상 정보, 신호등 정보 등을 이용하여 시간순 으로 위치 등을 매핑하여 사고를 시뮬레이션으로 재구성할 수 있다(S750). 프로세서는, 지도 데이터 베이 스에서 지도 데이터를 수신하고, 지도 데이터에 각종 정보를 반영하여 사고를 시뮬레이션으로 재구성할 수 있다. 프로세서는, 사고의 책임 소재를 판단할 수 있다(S760). 프로세서는, 교통 법류 데이터 베이스 에서 교통 법류를 수신하고, 교통 법규를 참조하여 사고의 책임 소재를 판단할 수 있다. 프로세서는, 사고 책임 소재 판단 결과를 해당 사고 이해관계자들에게 전송할 수 있다(S770). 도 8을 참조하면, 프로세서는, 사고 발생 이후, 비상등을 턴 온(turn on)할 수 있다(S810). 실시예에 따라, 프로세서는, 삼각대 또는 불꽃신호기 등을 자동으로 설치할 수 있다. 프로세서는, V2X 통신을 통해, 외부 장치(예를 들면, 서버, 타 차량, 사용자 단말기)와 데이터 송수신을 지속할 수 있다(S820). 프로세 서는, 후행하는 차량의 TTC(Time To Collision), 데이터 송수신 잔여 시간, 회피 시간을 주기적으로 추정 할 수 있다. TTC는, 타 차량이 차량을 충돌하기까지 걸리는 예상 시간으로 설명될 수 있다. 데이터 송수신 잔여 시간은, 사고 관련 데이터를 타 차량 또는 로드 사이드 유닛으로부터 수신하거나, 서버로 전송 완료하는데 걸리는 예상 잔여 시간으로 설명될 수 있다. 회피 시간은, 충돌이 예상되는 차량을 피할 수 있도록 차량을 이동시키 는데 걸리는 시간으로 설명될 수 있다. 회피 시간은, 차량이 여유있게 피할 수 있도록, 여분의 시간이 더 부여 될 수 있다. 프로세서는, TTC가 데이터 송수신 잔여 시간과 회피 시간의 합 이하인지 판단할 수 있다(S840). TTC가 데 이터 송수신 잔여 시간과 회피 시간의 합 이하인 것으로 판단되는 경우, 프로세서는, TTC가 회피 시간 이 하인지 판단할 수 있다(S850). 프로세서는, 후행 차량의 제동 상황에 따라 TTC는 가변적으므로, TTC의 값 을 계속 모니터링하면서 데이터 송수신을 계속할 수 있다. S850 단계에서, TTC가 회피 시간 이하인 것으로 판단 되는 경우, 프로세서는, 긴급으로 차량을 회피시킬 수 있다(S860). 프로세서는, 차량 이동시, 이동 궤적으로 파포함하는 센서 데이터를 스트리밍 전송할 수 있다. 사고가 발생한 경우, 사고차량은 사고와 관련한 차량정보를 서버로 송신할 수 있다. 서버는 보험사 서버, 혹은 차량업체 서버일 수 있다. 상기 사고 관련 차량 정보에는 차량의 충돌위치, 충돌세기, 차량의 구동부 센싱 정보, 차량 주변환경을 센싱하는 센싱정보 (전방 카메라, 블랙박스, Radar, Lidar 등), V2X를 통해 획득한 주변 차량이 센싱한 센싱정보 중 하나 이상을 포함할 수 있다. 서버는 각 사고차량의 사고 발생 일정 시점 이전, 이후를 포함하는 데이터를 획득하고, 획득한 데이터를 기 반으로 과실 비율을 계산할 수 있다. 과실 비율은 상기 획득한 데이터, 교통법규 데이터, 사고DB 중 하나 이상을 기반으로 서버에 위치한 인공지능 알고리즘이 학습한 결과에 기초하여 결정될 수 있고, 상기 결정된 과실 비율과 관련한 정보를 각 사고 차량으로 송신할 수 있다. 차량은 서버로부터 수신받은 과실 비율 정보를 차량 내 위치한 출력부를 통해 제공할 수 있다. 사고 DB정보는 보험사 또는 관련 정보를 수집하는 기관에서 생성된 정보일 수 있다. 사고 DB는 타 차 량의 사고 이력정보를 포함하고 있을 수 있고, 사고 이력 정보에는 과실 비율이 포함되어 있을 수 있다. 예를 들어, 사고가 발생한 경우, 서버는 사고DB에서 획득한 타 차량의 사고 이력정보를 기반으로, 발생된 사고 정보와 유사한 타 차량의 사고 이력정보가 있는지 확인할 수 있다. 상기 차량 내 위치한 출력부는 디스플레이(Head up display, 계기판, Center Information Display)이거나 음성 출력부일 수 있다. 사고 당사자는 상기 차량 내 출력부를 통해 제공된 과실 비율에 대해서 납득하는지를 선택할 수 있다. 과실 비 율을 납득한다고 선택한 경우, 보험사에 사고 당사자가 과실 비율을 확인하였다는 정보를 전송할 수 있고, 보험 사는 상기 전송받은 정보를 기반으로 보험금액을 책정할 수 있다. 사고 당사자가 과실 비율을 납득하지 않는다 고 선택한 경우, 이를 기반으로 추가 안내정보를 제공할 수 있다. 보험사 직원을 호출하여 사고 위치로 직접 방 문하도록 요청할 수도 있고, 주변 차량이나 객체로부터 정보를 더 수집 후 2차 학습을 통해 과실 비율을 재 제 공할 수도 있다. 서버는 과실 비율을 산출 시, 과실 비율 산출을 위한 데이터가 충분하지 않은 경우, 각 사고차량의 사고 발 생 일정 시점 이전, 이후를 포함하는 주변 환경 데이터를 더 획득하고, 획득한 데이터를 기반으로 과실 비율을 계산할 수 있다. 여기서 주변 환경 데이터는 사고 발생 일정 시점, 이후 주변 차량이 획득한 센서정보, 혹은 주 변 센싱장치(CCTV, RSU 등)에서 획득한 센서정보일 수 있다. 예를 들면, 보험사 서버가 계산한 과실 비율 정보를 사고 차량으로 송신하면, 차량은 보험사 서버로부터 수신받 은 정보를 차량의 인스트루먼트 패널에 구비되는 CID(Center Information display)에 출력할 수 있다. CID는 터치 입력부와 일체로 형성되거나, 터치 입력부와 상호 레이어 구조를 이룸으로써, 터치 스크린을 구현할 수 있 고, 제스처 입력부나 음성입력부를 더 구비할 수도 있다. CID에 출력된 정보는 차량의 과실 비율을 납득하는지 를 문의하는 정보일 수 있으며, 사고 당사자는 과실 비율 납득 여부에 대한 선택 값을 CID의 터치입력부를 통해 입력할 수 있다. 차량의 사고타입은 크게 사고 발생 시, 차량 간 사고의 경우, 차량과 기물 간 사고의 경우, 차량과 보행자 간의 사고로 구분될 수 있고, 차량 간 사고 시 각 차의 책임 비율, 그리고 사고 차량이 자율주행 차량인 경우, 운전 자의 제어권 비율에 따른 사람-차량 간 책임 비율이 달라질 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(SiliconDisk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 또한, 상기 컴퓨터는 프로세서 또는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예 시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2019-0130391", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 시스템을 설명하는데 참조되는 도면이다. 도 2는 본 발명의 실시예에 따른 차량의 제어 블럭도이다. 도 3은 본 발명의 실시예에 따른 교통 사고 처리 장치를 설명하는데 참조되는 도면이다. 도 4 내지 도 8은 본 발명의 실시예에 따른 교통 사고 처리 방법을 설명하는데 참조되는 도면이다."}
