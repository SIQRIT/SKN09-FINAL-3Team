{"patent_id": "10-2021-0163588", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0076536", "출원번호": "10-2021-0163588", "발명의 명칭": "인공 신경망의 양자화 기법을 구현하기 위한 장치의 동작 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "장준우"}}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 신경망의 양자화 기법을 구현하기 위한 장치의 동작 방법에 있어서,M 차원의 제1 벡터에 해당하는 입력 데이터를 획득하는 단계;M 차원의 제2 벡터에 해당하는 가중치 파라미터를 획득하는 단계;미리 정해진 양자화 기법을 이용하여, 상기 입력 데이터를 N 개 계층의 제1 비트열들로 인코딩하는 단계;상기 양자화 기법을 이용하여, 상기 가중치 파라미터를 N개 계층의 제2 비트열들로 인코딩하는 단계;상기 제1 비트열들의 계층들과 상기 제2 비트열들의 계층들 간 가능한 조합들 각각에 대응하여, 해당하는 제1비트열 및 해당하는 제2 비트열을 BNN 연산기에 인가하는 단계;상기 BNN 연산기로부터, 상기 조합들 각각에 해당하는 BNN 연산 결과가 해당하는 비트 수만큼 시프트 되어 누적된 결과에 기반하여 출력되는 내적 연산 결과를 획득하는 단계; 및상기 양자화 기법을 이용하여, 상기 내적 연산 결과를 양자화하는 단계를 포함하는장치의 동작 방법."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 해당하는 제1 비트열 및 해당하는 제2 비트열을 BNN 연산기에 인가하는 단계는,상기 BNN 연산기를 통해 상기 제1 비트열들 중 하나의 계층 및 상기 제2 비트열들 중 하나의 계층을 교차하여XNOR 연산을 수행하는 단계; 및상기 XNOR 연산된 결과들 각각에 Popcount를 수행하는 단계를 포함하는,장치의 동작 방법."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 해당하는 비트 수는, 상기 BNN 연산 결과를 위해 계산되는 해당 제1 비트열들의 계층들과 제2 비트열들의 계층들에 따라서 결정되는,장치의 동작 방법."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 미리 정해진 양자화 기법은,공개특허 10-2023-0076536-3-0을 양자화 레벨에서 배제하고, 적어도 하나의 양수 양자화 레벨과 적어도 하나의 음수 양자화 레벨이 완전히대칭을 이루는,장치의 동작 방법."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 입력 데이터 및 상기 가중치 파라미터는,하기 수학식에 기초하여 양자화되는,장치의 동작 방법.수학식:vbar = clamp(round (v/s + 0.5) - 0.5, - 2b-1 + 0.5, 2b-1 - 0.5) 여기서, v는 상기 가중치 파라미터 또는 상기 입력 데이터고, s는 상기 양자화 기법의 양자화 구간을 결정하기위한 스텝 사이즈이고, b는 미리 정해진 양자화 비트 수임"}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 가중치 파라미터는,양자화 인식 훈련(quantization-aware training)을 통해 학습되어 결정되는,장치의 동작 방법."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 양자화된 내적 연산 결과를 다음 노드로 전달하는 단계를 더 포함하는,장치의 동작 방법."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "하드웨어와 결합되어 제1항 내지 제7항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공 신경망의 양자화 기법을 구현하기 위한 장치에 있어서,복수의 레지스터들;적어도 하나의 XNOR 연산기;적어도 하나의 팝카운터(Popcounter);공개특허 10-2023-0076536-4-적어도 하나의 시프터; 및적어도 하나의 누산기(accumulator)를 포함하고,상기 레지스터들은, 미리 정해진 양자화 기법을 이용하여 M 차원의 제1 벡터에 해당하는 입력 데이터 및 M 차원의 제2 벡터에 해당하는 가중치 파라미터가 N개 계층으로 인코딩 된 제1 비트열들 및 제2 비트열들을 저장하고,상기 제1 비트열들의 계층들과 상기 제2 비트열들의 계층들 간 가능한 조합들 각각에 대응하여,해당하는 XNOR 연산기는, 해당하는 제1 비트열 및 해당하는 제2 비트열 간 XNOR 연산을 수행하고,해당하는 팝카운터는, 상기 XNOR 연산 결과에 Popcount 연산을 적용하며,해당하는 시프터는, 해당하는 조합에 대응하는 비트 수만큼 상기 Popcount 연산 결과를 시프트하고,해당하는 누산기는, 상기 조합들의 시프트 된 Popcount 연산 결과들을 누적 연산하며,상기 누적 연산 결과에 기초하여, 상기 입력 데이터와 상기 가중치 파라미터 간 내적 연산 결과가 출력되는장치."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 XNOR 연산기는,상기 제1 비트열들 중 하나의 계층 및 상기 제2 비트열들 중 하나의 계층을 교차하여 XNOR 연산을 수행하는,장치."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 팝카운터는,상기 XNOR 연산된 결과들 각각에 Popcount를 수행하는,장치."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 해당하는 비트 수는, 상기 BNN 연산 결과를 위해 계산되는 해당 제1 비트열들의 계층들과 제2 비트열들의 계층들에 따라서 결정되는,장치."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 미리 정해진 양자화 기법은,0을 양자화 레벨에서 배제하고, 적어도 하나의 양수 양자화 레벨과 적어도 하나의 음수 양자화 레벨이 완전히공개특허 10-2023-0076536-5-대칭을 이루는,장치."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 입력 데이터 및 상기 가중치 파라미터는,하기 수학식에 기초하여 양자화되는,장치.수학식:vbar = clamp(round (v/s + 0.5) - 0.5, - 2b-1 + 0.5, 2b-1 - 0.5) 여기서, v는 상기 가중치 파라미터 또는 상기 입력 데이터고, s는 상기 양자화 기법의 양자화 구간을 결정하기위한 스텝 사이즈이고, b는 미리 정해진 양자화 비트 수임"}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 가중치 파라미터는,양자화 인식 훈련(quantization-aware training)을 통해 학습되어 결정되는,장치."}
{"patent_id": "10-2021-0163588", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 누적 연산 결과는, 상기 미리 정해진 양자화 기법을 통해 양자화되어 다음 노드로 전달되는,장치."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예는, 인공 신경망의 양자화 기법을 구현하기 위한 장치의 동작 방법 및 해당 장치에 대한 것이다. 실시예에 따른 장치의 동작 방법은, M 차원의 제1 벡터에 해당하는 입력 데이터를 획득하는 단계; M 차원의 제2 벡터에 해 당하는 가중치 파라미터를 획득하는 단계; 미리 정해진 양자화 기법을 이용하여, 입력 데이터를 N 개 계층의 제1 비트열들로 인코딩하는 단계; 양자화 기법을 이용하여, 가중치 파라미터를 N개 계층의 제2 비트열들로 인코딩하 는 단계; 제1 비트열들의 계층들과 제2 비트열들의 계층들 간 가능한 조합들 각각에 대응하여, 해당하는 제1 비 트열 및 해당하는 제2 비트열을 BNN 연산기에 인가하는 단계; BNN 연산기로부터, 조합들 각각에 해당하는 BNN 연 산 결과가 해당하는 비트 수만큼 시프트 되어 누적된 결과에 기반하여 출력되는 내적 연산 결과를 획득하는 단계; 및 양자화 기법을 이용하여, 내적 연산 결과를 양자화하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예는, 인공 신경망의 양자화 기법을 구현하기 위한 장치의 동작 방법 및 해당 장치에 관한 것이다."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 분야에서 연산량을 줄이면서 전력 효율성을 향상시키는 방법 중 하나가 양자화(quantization) 기술이 다. 양자화는, 정확하고 세밀한 단위로 표현한 입력값을 보다 단순화한 단위의 값으로 변환하는 다양한 기술을 포괄적으로 의미하는 용어이다. 양자화 기술은 정보를 표현하는 데 필요한 비트의 수를 줄이기 위한 것이다. 일반적으로 인공 신경망은 활성 노드, 노드 간의 연결, 각 연결과 관련한 가중치 매개변수(weight parameter)로 구성되는데, 여기서 양자화되는 대상은 가중치 매개변수와 활성 노드 연산. 신경망을 하드웨어에서 진행하면 곱 셈 및 덧셈 연산을 수백만 회 실행한다. 만약 양자화된 매개변수로 저비트(lower-bit)의 수학 연산을 수행하고, 신경망의 중간 계산값도 함께 양자화한 다면, 연산 속도는 빨라지고 성능도 향상된다. 더불어, 인공 신경망을 양자화하게 되면, 메모리 액세스를 줄이고 연산 효율성도 높일 수 있으므로 전력 효율성도 향상될 수 있다. 그러나, 양자화로 인해 인공 신경망의 정확도가 떨어질 수 있다. 이에, 정확도에 영향을 주지 않으면서 연산 효율 및 전력 효율이 높아 지도록 양자화 기술이 발전하고 있다. 이와 관련하여 국제특허 WO2020/248424(Method for determining quantization parameters in neural network and related products)에서는 인공 신경망에서 양자화 파라미터를 결정하는 방법을 제시한다."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예에 따른 발명은, 양수 및 음수 각각에 균등한 양자화 파라미터를 제공하며, 0을 중심으로 대칭 구조를 가 지는 양자화 방법을 제공하고자 한다. 더불어, 이러한 양자화 방법을 구현하기 위한 소프트웨어 및 하드웨어의 동작 방법과 구성을 제공하고자 한다."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "인공 신경망의 양자화 기법을 구현하기 위한 장치의 동작 방법에 있어서, M 차원의 제1 벡터에 해당하는 입력 데이터를 획득하는 단계; M 차원의 제2 벡터에 해당하는 가중치 파라미터를 획득하는 단계; 미리 정해진 양자화 기법을 이용하여, 상기 입력 데이터를 N 개 계층의 제1 비트열들로 인코딩하는 단계; 상기 양자화 기법을 이용 하여, 상기 가중치 파라미터를 N개 계층의 제2 비트열들로 인코딩하는 단계; 상기 제1 비트열들의 계층들과 상 기 제2 비트열들의 계층들 간 가능한 조합들 각각에 대응하여, 해당하는 제1 비트열 및 해당하는 제2 비트열을 BNN 연산기에 인가하는 단계; 상기 BNN 연산기로부터, 상기 조합들 각각에 해당하는 BNN 연산 결과가 해당하는 비트 수만큼 시프트 되어 누적된 결과에 기반하여 출력되는 내적 연산 결과를 획득하는 단계; 및 상기 양자화 기법을 이용하여, 상기 내적 연산 결과를 양자화하는 단계를 포함하는, 장치의 동작 방법이 제공될 수 있다. 상기 해당하는 제1 비트열 및 해당하는 제2 비트열을 BNN 연산기에 인가하는 단계는, 상기 BNN 연산기를 통해 상기 제1 비트열들 중 하나의 계층 및 상기 제2 비트열들 중 하나의 계층을 교차하여 XNOR 연산을 수행하는 단 계; 및 상기 XNOR 연산된 결과들 각각에 Popcount를 수행하는 단계를 포함할 수 있다. 상기 해당하는 비트 수는, 상기 BNN 연산 결과를 위해 계산되는 해당 제1 비트열들의 계층들과 제2 비트열들의 계층들에 따라서 결정될 수 있다. 상기 미리 정해진 양자화 기법은, 0을 양자화 레벨에서 배제하고, 적어도 하나의 양수 양자화 레벨과 적어도 하 나의 음수 양자화 레벨이 완전히 대칭을 이룰 수 있다. 상기 입력 데이터 및 상기 가중치 파라미터는, 하기 수학식에 기초하여 양자화될 수 있다. 수학식: vbar = clamp(round (v/s + 0.5) - 0.5, - 2b-1 + 0.5, 2b-1 - 0.5) -여기서, v는 상기 가중치 파라미터 또는 상기 입력 데이터고, s는 상기 양자화 기법의 양자화 구간을 결정하기 위한 스텝 사이즈이고, b는 미리 정해진 양자화 비트 수임- 상기 가중치 파라미터는, 양자화 인식 훈련(quantization-aware training)을 통해 학습되어 결정될 수 있다. 상기 양자화된 내적 연산 결과를 다음 노드로 전달하는 단계를 더 포함할 수 있다. 인공 신경망의 양자화 기법을 구현하기 위한 장치에 있어서, 복수의 레지스터들; 적어도 하나의 XNOR 연산기; 적어도 하나의 팝카운터(Popcounter); 적어도 하나의 시프터; 및 적어도 하나의 누산기(accumulator)를 포함하 고, 상기 레지스터들은, 미리 정해진 양자화 기법을 이용하여 M 차원의 제1 벡터에 해당하는 입력 데이터 및 M 차원의 제2 벡터에 해당하는 가중치 파라미터가 N개 계층으로 인코딩 된 제1 비트열들 및 제2 비트열들을 저장 하고, 상기 제1 비트열들의 계층들과 상기 제2 비트열들의 계층들 간 가능한 조합들 각각에 대응하여, 해당하는 XNOR 연산기는, 해당하는 제1 비트열 및 해당하는 제2 비트열 간 XNOR 연산을 수행하고, 해당하는 팝카운터는,상기 XNOR 연산 결과에 Popcount 연산을 적용하며, 해당하는 시프터는, 해당하는 조합에 대응하는 비트 수만큼 상기 Popcount 연산 결과를 시프트하고, 해당하는 누산기는, 상기 조합들의 시프트 된 Popcount 연산 결과들을 누적 연산하며, 상기 누적 연산 결과에 기초하여, 상기 입력 데이터와 상기 가중치 파라미터 간 내적 연산 결과 가 출력되는, 장치가 제공될 수 있다."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 따른 발명은, 양수 및 음수 각각에 균등한 양자화 파라미터를 제공하며, 0을 중심으로 대칭 구조를 가 지는 양자화 방법을 제공할 수 있다. 더불어, 이러한 양자화 방법을 구현하기 위한 소프트웨어 및 하드웨어의 동작 방법과 구성을 제공할 수 있다."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면을 참조하여 실시예들을 상세하게 설명한다. 그러나, 실시예들에는 다양한 변경이 가해 질 수 있어서 특허출원의 권리 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 실시예들에 대한 모든 변경, 균등물 내지 대체물이 권리 범위에 포함되는 것으로 이해되어야 한다. 실시예에서 사용한 용어는 단지 설명을 목적으로 사용된 것으로, 한정하려는 의도로 해석되어서는 안된다. 단 수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조부호를 부여 하고 이에 대한 중복되는 설명은 생략하기로 한다. 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적 인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 실시 예의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 어느 하나의 실시 예에 포함된 구성요소와, 공통적인 기능을 포함하는 구성요소는, 다른 실시 예에서 동일한 명 칭을 사용하여 설명하기로 한다. 반대되는 기재가 없는 이상, 어느 하나의 실시 예에 기재한 설명은 다른 실시예에도 적용될 수 있으며, 중복되는 범위에서 구체적인 설명은 생략하기로 한다. 인공 신경망의 가중치 파라미터를 양자화하기 위해서 일반적으로 [-2(b-1), 2(b-1)-1]에 매핑되는 대칭 양자화기를 사용할 수 있다. 여기서, b는 양자화 비트 수이다. 양자화된 인공 신경망(Quantized neural network, QNN)은 3비트 이내의 정밀도가 낮은 양자화 시에 성능 저하가 발생한다. 일반적인 양자화 방식은 양수 및 음수 양자화 수준을 동일하지 않게 할당하는데(예컨대, -1, 0, 1, 2 등), 양수 및 음수의 비대칭으로 인해 정밀도가 낮은 양 자화 수준에서 오류 및 성능 저하가 발생할 수 있다. 인공 신경망의 구현 시 해당 노드와 그 연결망의 모델은 추론과 학습에서 가중치의 곱셈 값을 합산하여 하나의 뉴런에 전달하는 수많은 MAC(multiplier-accumulator) 연산들과 활성화 함수에서의 곱셈을 통해 이루어진다. MAC 연산들은 인공 신경망의 크기에 비례하여 그 크기가 결정되며, 또한, MAC에 필요한 피연산자의 데이터와 출 력 데이터는 인공 신경망이 구현되는 메모리에 저장된다. 인공신경망 구현에서는 MAC 연산기와 메모리가 하드웨어 형태로 존재한다. 좁은 의미로는 이들 MAC 연산과 메 모리가 하드웨어로 매핑되어 병렬 형태로 구현되는 것을 인공 신경망의 하드웨어 형태 구현이라고 볼 수 있으나, MAC 연산에 사용되는 곱셈기와 덧셈기의 효율을 높이거나 메모리의 사용량을 줄일 수 있다. 한편, BNN(Binary Neural Network, 이진 신경망)은 심층 신경망(Quantized neural networks, QNN)의 메모리 및 계산 비용을 높이기 위한 방법으로 제시되는 개념이다. 이진 신경망은 파라미터의 값을 +1 및 -1로 양자화하여 1bit만으로 표현할 수 있으나 예측 정확도는 상대적으로 낮다. 이진 신경망의 하드웨어는, 논리 연산인 XNOR 연산을 통해 곱셈을 구현할 수 있으며 레지스터 내의 1로 설정된 비트의 수를 알 수 있는 Pop-Count 명령을 통해 누적 덧셈을 구현할 수 있다. 이진 신경망은 실수나 정수 곱 셈, 덧셈이 필요하지 않게 됨으로 연산 속도를 개선할 수 있다. 또한 기존 32Bit에서 1Bit로 줄어들기 때문에 이론적으로 메모리 대역폭이 32배 증가하게 된다. 이진 신경망은 입력과 가중치를 모두 1Bit로 변환 후 XNOR 연산을 한다. XNOR 연산 결과에 근사 값을 곱하여 32Bit에서 1Bit로의 변환으로 인한 손실을 보정할 수 있다. 실시예에 따라, BNN 하드웨어에서 비트 연산을 사용하여 심층 신경망에 대해 효율적인 하드웨어를 구현이 가능 한 양자화 방법을 제공하고자 한다. 일반적인 선형 양자화(Conventional Linear Quantization, CLQ)의 파라미터 레벨은 비트 수에 따라 [-2^(b-1), 2^(b-1)-1]으로 표현될 수 있다. 예컨대, 2비트 인 경우, {-2, -1, 0, 1}으로 표현될 수 있다. 또는, 양극과 음극 사이의 비대칭을 반대로 결정할 수도 있다. Reduced Symmetric Quantization(RSQ)의 경우, 양자화 파라미터를 실시예의 수준에 대비하여 하나 덜 사용하여 L=-2b*?*1+1 및 U=2b-1*?*1 수준으로 예컨대 {-1, 0, 1}로 양자화를 수행하며, 0을 기준으로 완벽한 대칭을 이 룰 수 있다. 이러한 양자화 방법은 양자화 수준이 적어져 성능이 저하될 수 있다. Extended Symmetric Quantization(ESQ)는 하나 이상의 양자화 수준을 사용하여 0을 대칭으로 이루는 형태를 보 이며, 2bit 이상을 요구될 수 있다. L=-2b*?*1 및 U=2b-1 수준으로 양자화되며, 예를 들어, {-2, *?*1, 0, 1, 2}로 양자화될 수 있다. Non-Uniform Symmetric Quantization(NSQ)는 2b 양자화 레벨이 0을 포함하지 않는 대칭 형태를 포함하며, 예컨 대 {-2, -1, 1, 2}로 양자화하는 방법을 제시하나 양자화 레벨 간의 간격이 동일하지 않다. 실시예에 따른 양자화 방법은 파라미터 간에 균일한 구간을 가지면서 양수면과 음수면 사이의 대칭 구조를 가지 고 0을 양자화 레벨로 포함하지 않도록 할 수 있다. 즉, 0을 양자화 레벨에서 배제하고, 양수의 양자화 레벨들 과 음수 양자화 레벨들이 서로 완전히 대칭 구조를 가질 수 있다. 예컨대, {-1.5, -0.5, 0.5, 1.5}와 같이 분 수 레벨로 양자화될 수 있고, {-3, -1, 1, 3}과 같이 정수로 양자화 하기 위해 2로 양자화 구간을 위한 스텝 사 이즈가 결정될 수 있다. 실시예에서, 인공 신경망의 학습 시, 파라미터 및 파라미터의 양자화 구간에 대해 함께 훈련이 이루어질 수 있 다. 실시예에 따른 학습 방법은 선형 양자화를 위해 개발된 다양한 훈련 방법이 적용될 수 있다. 양자화된 파라미터에 대한 학습을 위해 양자화 인식 훈련이 적용될 수 있다. 예를 들어, LSQ와 동일한 방식으로 양자화 구 간이 훈련될 수 있다. 실시예에서, 이러한 대칭 형태의 양자화 파라미터를 학습하기 위해 아래의 수학식 1과 같은 미분 공식을 이용할 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "경사 하강법을 사용하여 양자화 구간의 스텝 사이즈 s를 최적하기 위해 상기의 수학식 1과 같은 미분 공식을 사 용할 수 있다. 여기서, v는 입력 값이고, Qn은 양자화 구간의 최소 값의 절대값이고, Qp는 양자화 구간의 최대 값을 의미한다. 경사 하강법은 실함수의 기울기 변화를 통해 손실 함수를 줄이는 방법으로, 초기 시점에 대한 기울기를 구하여 기울기의 반대 방향으로 이동하는 과정을 통해 기울기를 수렴시키는 것으로 오차를 줄이는 과정을 포함할 수 있 다. 실시예에서, 수렴시킨 손실 기울기를 계산할 수 있다. 스텝 사이즈의 기울기는 기울기의 스케일링과 유사 하게 로 스케일링될 수 있다. 여기서, g는 스텝 사이즈의 스케일링이고, Nw는 양자화 파라미터의 수이고, p는 비트 폭(bit-width)를 의미한다. 실시예에서, 가중치는 로 초기화될 수 있다. 여기서, <.>은 분포의 평균에 대해 표기하는 방 법으로 사용될 수 있다. 실시예에서, 훈련을 통해 획득한 양자화 방법은 아래의 수학식 3과 같이 나타낼 수 있다. [수학식 3]"}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, clip() 함수는, clip(리스트, 최소값, 최대값)으로 나타내고, 리스트 안에 있는 값들을 최소값과 최대 값 사이의 값들로 변환시킨 array를 리턴할 수 있고, clip(x; a; b) = min(max(x; a); b)로 나타낼 수 있다. v는 임의의 입력 값이고, s는 스텝 사이즈를 의미한다. 앞서 훈련을 통해 Q= 2b-1-0.5로 결정될 수 있고, b는 양자화 밀도, 즉 미리 정해진 비트 수를 의미한다. v는 정수가 아니며, 그럼에도 불구하고 실시예에 따른 b비 트의 양자화 방법을 통해 보다 정확히 표현될 수 있다. 는 b비트 하드웨어에서 계산된 값을 나타내고, 는 훈련 목적으로 정의되고 사용되는 v의 축소 버전에 해당한다. 실시예에 따른 양자화 장치는 입력 분포의 양수 및 음수에 대해 동일하게 표현될 수 있다. 일실시예에서, 양자화 방법은 효율적인 하드웨어 및 소프트웨어로 구현될 수 있다. 해당 사항에 대해서는 이후 자세히 설명하도록 한다. 도 1은 실시예에 따른 양자화 방법이 적용되는 양자화 파라미터에 대한 그래프이다. 도 1(a)는 일반적인 선형 양자화 방법과 실시예에 따른 양자화 방법에 따른 결과를 도시하며, 도 1(b)는 실시예 에 따른 양자화 파라미터의 스텝 사이즈에 대한 기울기를 도시한 그래프이다. 도 1(a)의 그래프는 2bit의 데이터를 양자화한 실시예에 대한 것이다. 도 1(a)에 도시된 바와 같이, 동일한 스 텝 사이즈를 가지는 선형 양자화 방법에 대해서 0 주변의 값을 양자화한 결과에 있어서 차이가 있으며, 실시예에 따르면 0을 기준으로 상방 및 하방의 간격이 동일한 형태로 양자화가 가능하다. 입력이 정수인 곳을 제외하 고, 모든 입력 값에 대해서 반올림 연산자를 적용할 수 있다. 실시예에 따른 그래프는 앞서 설명된 경사 하강법을 통해 최적화된 스텝 사이즈에 의해 결정된 양자화 구간에 기초하여 도시되어 있다. 도 1(b)에 도시된 바에 따르면, 실시예에 따른 양자화 방법에 의해 양자화 구간 내에 포함되는 입력 값에 대해서 일정한 기울기 내에서 양자화 결과를 획득할 수 있다. 실시예에 따른 양자화 방법은, 낮은 비트의 양자화된 가중치, 예컨대 3비트 이하에서 최대 엔트로피에 가까운 효율의 하드웨어 및 소프트웨어로 구현될 수 있다. 대표적으로 이진 신경망이 있다. 이진 신경망은 앞서 기재한 바와 같이, 기존 인공신경망의 속도를 대폭적으로 상승시키고 인공신경망 모델의 메모리 용량을 대폭 줄일 수 있다는 점에서 획기적인 방식이나, 기존의 부동소수 점인 웨이트와 활성화 함수를 -1과 1로 표현하기 때문에 정보의 손실이 발생한다는 단점이 있다. 이러한 정보 손실은 결과적으로 정확도 저하로 이어지며, 사물을 인식하거나 물건을 탐지하는 데 있어 성능 저하를 가져올 수 있다. 실시예에의 양자화 방법은 이진 신경망 하드웨어에 효율적으로 매핑될 수 있다. 이진 신경망을 통해 이진 가중 치, 예컨대 +1 및 -1의 가중치 파라미터가 적용될 수 있다. 이러한 가중치 파라미터를 적용함으로써 하드웨어 로 구현 시 곱셈기를 제거할 수 있고, 신경망 구조를 간소화함으로써 빠른 연산 속도를 제공할 수 있다. 도 2는 실시예에서, 2비트로 양자화된 양자화 구간의 확률 분포를 설명하기 위한 도면이다. 도 2(a)는 실시예에서, 양자화 레벨에 따른 구간의 정규 분포를 나타낸 그래프이다. 도 2(a)의 x축은 양자화 레벨을 표시하며, y축은 실제 데이터 별로 확률 분포를 나타낸다. 실시예에서, 가우시 간 분포와 유사하게 나타날 수 있다. 실시예에 따른 양자화 방법은 양자화를 통해 양자화 레벨에 따른 효율을 최대화하는 데에 유용하게 적용될 수 있다. 데이터가 양자화될 때, 양자화 레벨마다 매핑되는 데이터가 가능한 한 균일하게 분포되어야 하는 경우, 높은 양 자화 효율을 제공할 수 있으며, 또는 양자화 레벨의 분포가 데이터 분포, 예컨대 가우시안 분포와 유사하게 이 루어지는 경우 높은 양자화 효율을 제공할 수 있다. 실시예에 따른 양자화 방법은 상기의 두 가지 조건에 모두 부합하는 것이다. 예컨대, 실시예에 따라 2 bit로 양자화 하는 경우, 일반적으로 임계값 {-1; 0; 1}를 기준으로 상기의 두 가지 조건을 충족할 수 있다. 실시예에서, 도 2(a)와 같이 데이터는 양자화 수준에 걸쳐 균일하게 분포되며, 동시에 양자화 레벨 또한 가우시 안 분포에 따른다. 여기서, 도 2(a)의 가우시안 분포는 X~N(0; 1)에서 P(0 ≤ X ≤ s) = 0:25로 나타나는 표준 정규 분포의 CDF를 따르는 것으로 가정할 수 있다. 도 2(b), (c)는 실시예에서, CLQ와 실시예 각각에 실제 데이터가 매핑되는 결과를 도시한 그래프이다. 도 2(b)는 CLQ로 학습되어 결정된 양자화 레벨에 실제 데이터가 매핑되는 확률에 관한 것이며, 도 2(c)는 실시 예에 따른 방법으로 학습되어 결정된 양자화 레벨에 실제 데이터가 매핑되는 확률을 도시한 것이다. 도 2(b)에 의하면, 양자화 레벨이 (-2, -1, 0. 1)에 해당하여 각 양자화 레벨에 따른 매핑 확률이 적게는 10%, 많게는 40% 가까이 나타나 양자화 효율이 좋다 평가할 수 없으나, 도 2(c)에 의하면, 양자화 레벨 -1.5, -0.5, 0.5, 1.5 각각에 대해서 25% 전후로 매핑 확률이 비교적 균등하게 나타나는 것을 확인할 수 있다. 이러한 양자화 방법을 하드웨어로 구현하는 방법에 대해서 자세히 설명하도록 한다. 도 3은 실시예에서, 인공 신경망의 양자화 기법을 구현하기 위한 장치의 동작 방법의 흐름도이다. 단계에서 장치는, 입력 데이터 및 가중치 파라미터를 획득한다. 실시예에서, 인공 신경망을 이루는 하나 이상의 노드들에서 한 사이클의 노드에 해당하는 동작을 수행할 수 있 다. 해당 노드로 입력되는 입력 데이터 및 가중치 파라미터는 각각 M 차원으로 가정할 수 있다. 입력 데이터 및 가중치 파라미터는 각각 M 차원의 제1 벡터 및 제2 벡터로 나타낼 수 있다. 입력 데이터는 이 전 노드의 출력 데이터에 해당할 수 있다. 단계에서 장치는, 미리 정해진 양자화 기법을 이용하여 입력 데이터와 가중치 파라미터를 각각 N개의 계층 을 가지는 비트열들로 인코딩한다. 실시예에서, 입력 데이터의 인코딩된 비트열을 제1 비트열, 가중치 파라미터의 인코딩된 비트열을 제2 비트열이 라 지칭하도록 한다. 미리 정해진 양자화 기법은 앞서 도 1 및 2를 이용하여 설명된 양자화 기법을 이용할 수 있다. 입력 데이터 및 양자화 파라미터를 N 개의 비트열로 각각 인코딩할 수 있다. 실시예에서, 이진 신경망에서는 이진 인코딩 시, 일반적인 2' complement 방법 대신 0을 -1로 해석할 수 있다. 예를 들어, 010=-1, 1, -1로 인코딩하고, 해당 입력은 -(2^2)+(2^1)-(2^0)=-3으로 표현될 수 있다. 실시예에서, 양자화 레벨 수에 따라 인코딩되는 비트열의 수가 결정될 수 있다. 예를 들어, 양자화 레벨이 4개 인 경우, 입력 데이터 및 가중치 파라미 각각은 2개의 비트열로 인코딩될 수 있고, 양자화 레벨이 8인 경우 3개 의 비트열로 인코딩될 수 있다. 실시예에 따른 예시는 도 4를 참조하여 설명하도록 한다. 도 4는 실시예에서, 입력 데이터 및 가중치 파라미터의 예시를 이용한 장치의 동작을 설명하기 위한 도면이다. 실시예에서, {3, -1, 3, -3, 1, 3, 3, 3}은 입력 데이터며, {-1, -1, 3, 3, -3, 3, -3, 3}은 가중치 파라미터 에 해당한다. 각각 8차원의 데이터이다. 입력 데이터 {3, -1, 3, -3, 1, 3, 3, 3} 값을 이진수로 인코딩하면 {11, 01, 11, 00, 10, 11, 11, 11}로 나타낼 수 있으며, 자릿수에 따라 vH={1, 0, 1, 0, 1, 1, 1, 1}, vL={1, 1, 1, 0, 0, 1, 1, 1}의 상위 비트열 및 하위 비트열로 나누어 표현될 수 있다. 마찬가지로, 가중치 파라미터 {-1, -1, 3, 3, -3, 3, -3, 3}를 인코딩하면 {01, 01, 11, 11, 00, 11, 00, 11}로 표현될 수 있고, 자릿수에 따라 xH={0, 0, 1, 1, 0, 1, 0, 1}, xL={1, 1, 1, 1, 0, 1, 0, 1}로 표현될 수 있다. 이러한 인코딩 방식은 3 bit의 경우에도 확장될 수 있으며, 3 bit의 경우에는 입력 데이터와 가중치 파라미터가 3개의 비트열로 표현될 수 있다. 다시 도 3으로 돌아가, 단계에서 장치는, 제1 비트열들의 계층들과 제2 비트열들의 계층들 간 가능한 조합 들 각각에 대응하여, 해당하는 제1 비트열 및 해당하는 제2 비트열을 BNN 연산기에 인가한다. 단계에서 장치는, BNN 연산기로부터, 조합들 각각에 해당하는 BNN 연산 결과가 해당하는 비트 수만큼 시프 트 되어 누적된 결과에 기반하여 출력되는 내적 연산 결과를 획득한다. 인코딩된 비트열들 각각을 구성하는 비트열들 계층 간 가능한 조합들에 대해 BNN 연산기를 통해 XNOR 연산 및 Popcount를 수행한 연산 결과를 획득할 수 있다. 실시예에서, 장치는 MAC 연산을 수행하기 위해서 BNN 연산기 의 XNOR-Popcount 방식을 적용할 수 있다. 이러한 하드웨어 구현은 부호 확장을 위한 추가 비트를 제거하는 데 에 용이하다. 자세하게는, 복수 개의 BNN 연산기의 병렬 연결과 시프터(shifter) 및 누산기(accumulator)을 이 용하여 해당 양자화 방법을 구현하기 위한 하드웨어를 제공할 수 있다. 이하에서는, 2bit의 이진 데이터의 MAC 연산을 상기의 BNN 연산기의 하드웨어로 유도하는 수학식에 대해 설명하 도록 한다. 2bit 이진수 x = x1 x0은 정수를 나타내며, X = 2*(-1)^x1 + (-1)^x0로 표현될 수 있다. 2bit 이진수 y = y1 y0은 정수를 나타내며, Y = 2*(-1)^y1 + (-1)^y0로 표현될 수 있다. 이러한 X와 Y의 곱은 XY = 4*(-1)^(x1+y1) + 2*(-1)^(x0+y1) + 2*(-1)^(x1+y0) + (-1)^(x0+y0)로 나타낼 수 있 다. 한편, 1bit의 이진수 x, y, z = xnor(x, y)의 경우 Z = (-1)^z, X = (-1)^x, Y = (-1)^y이므로 XY = - Z로 나 타낼 수 있다. 해당 식을 풀어서 계산하면 XY = (-1)^(x+y) = (-1)^xor(x, y) = (-1)^[1+xnor(x, y)] = -1*(-1)^xnor(x, y) = - Z로 나타나고, 또한 실시예에 따른 양자화 인코딩에서 Z = 2*z-1이며, 결국 X Y = 1 - 2z = 1 - 2 xnor(x,y)로 표현될 수 있 다. 정리하면, X Y는 다음과 같이 XNOR-Popcount를 이용하여 다시 나타낼 수 있다. XY = 4*(1-2xnor(x1, y1)) + 2*(1-2xnor(x0, y1)) + 2*(1-2xnor(x1, y0)) + (1-2xnor(x0, y0)) = 9 - 8xnor(x1, y1) - 4(xnor(x0, y1) + xnor(x1, y0)) - 2 xnor(x0, y0) 따라서, 2 bit의 XY 곱은 4개의 XNOR 연산, 3개의 시프트 연산(2bit) 및 4개의 더하기 연산을 사용하여 계산될 수 있다. 여기서, 상수 항을 바이어스(Bias) 항으로 결합하고 모든 항을 2로 나눔으로써 추가적으로 단순화될 수 있다. 이 경우 4개의 XNOR, 2개의 시프터 및 3개의 추가만 필요하게 된다. 즉, N bit의 양자화 기법은 N2번의 1bit 이진 신경망의 병렬 또는 직렬 연결을 이용하여 구현될 수 있다. 실시예에 따른 양자화 인코딩은 2bit 내적에 더 효율적이며, 양자화 시 2bit x 2bit 곱셈과 1bit x 2bit 곱셈을 XNOR-popcount의 이진 신경망 하드웨어에서 추가 하드웨어(예: 부호 있는 또는 부호 없는 곱셈기)를 추가하지 않고도 수행할 수 있다. 실시예에서는, 병렬로 연결된 이진 신경망 하드웨어를 통해 입력된 입력 데이터의 비트열들 중 하나의 비트열 및 가중치 파라미터의 비트열들 중 하나의 비트열을 교차하면서 XNOR 연산을 수행하고, XNOR 연산된 결과들 각 각에 Popcount를 수행할 수 있다. 실시예에서, XNOR 연산 및 Popcount된 결과 값들 각각에 미리 정해진 bit 만큼 시프트를 수행할 수 있다. 예컨 대, 연산되는 비트열 계층에 따라서 시프트 수가 결정될 수 있다. 이하에서는, 도 4를 이용하여 실시예에 따른 하드웨어를 통해 연산이 실행되는 실시예를 설명하도록 한다. 실시예에서는, 입력 데이터의 상위 비트열 및 하위 비트열, 그리고 가중치 파라미터의 상위 비트열 및 하위 비 트열을 교차하여 각각에 XNOR-Popcount를 수행할 수 있다. 예컨대, vH, xH에 해당하는 상위 비트열 간의 XNOR 연산을 수행하면 {1, 0, 0, 1, 1, 0, 1, 0}을 획득할 수 있 고, 해당 비트열에 popcount를 수행하여 {0, 0, 0, 0, 0, 1, 0, 0}을 획득할 수 있다. 실시예에서, 상기의 설 명된 바에 의하면, 상위 비트열 간의 연산에 대해서 2만큼 시프트하도록 설정될 수 있다. 이에 {0, 0, 0, 1, 0, 0, 0, 0}을 획득할 수 있다. 또한, vH과 xL 및 vL과 xH의 XNOR 연산을 통해서 각각 {0, 1, 0, 1, 1, 0, 1, 0} 및 {1, 1, 0, 1, 0, 0, 1, 0}을 획득할 수 있고, 각각의 비트열에 대해 popcount를 통해 동일하게 {0, 0, 0, 0, 0, 1, 0, 0}를 획득하며, 1만큼 시프트하도록 설정되어 {0, 0, 0, 0, 1, 0, 0, 0}이 산출될 수 있다. xL와 vL의 XNOR 연산을 통해 {0, 0, 0, 1, 0, 0, 1, 0}을 획득할 수 있고, 해당 비트열에 대해서 popcount를 수행하여 {0, 0, 0, 0, 0, 0, 1, 0}을 획득하며, 해당 비트열에 대해서는 시프트가 적용되지 않는다. 일실시예에 있어서, 각 비트열에 대해서 XNOR-Popcount 및 미리 정해진 만큼의 시프트가 수행된 비트열에 대해 서 누적 연산을 수행할 수 있다. 도 4의 예를 들면, {0, 0, 0, 1, 0, 0, 0, 0}, {0, 0, 0, 0, 1, 0, 0, 0}, {0, 0, 0, 0, 1, 0, 0, 0} 및 {0, 0, 0, 0, 0, 0, 1, 0}이 누산기(accumulator)를 통해 누적될 수 있다. 이에, {0, 0, 1, 0, 0, 0, 1, 0}이 최종적으로 출력될 수 있다. 실시예에 따른 3bit의 데이터를 XNOR-Popcount하는 실시예에 대해서도 유사한 방식으로 유도되어 XNOR 연산기, popcounter를 포함하는 이진 신경망과 시프터 및 누산기를 통해 구현될 수 있다. 예컨대, 32번 즉, 9번의 이진 신경망 하드웨어이 이용될 수 있다. 실시예에서, 1 bit의 경우는 이진 신경망과 동일하므로, XNOR-Popcount의 이진 신경망 하드웨어를 통해 계산이 가능하다. 실시예에서, 도 4의 출력으로 산출된 비트열 {0, 0, 1, 0, 0, 0, 1, 0}을 x라 하면, 2x-64의 값을 계산함으로써 최종 연산 결과가 출력될 수 있다. 여기서, 64는 입력 데이터와 가중치 파라미터의 차원으로부터 도출될 수 있 다. {0, 0, 1, 0, 0, 0, 1, 0}를 십진수로 나타내면 34이며, 34x2-64=4로 최종 출력은 4로 계산될 수 있다.실시예에서 장치는, 내적 연산 결과를 미리 정해진 양자화 기법을 통해 양자화한다. 실시예에서, 인공 신경망을 이루는 노드는 다음 노드로 결과 값을 전달하기 위해 양자화를 수행할 수 있다. 실 시예에 따른 양자화 레벨은 {-3, -1, 1, 3}에 해당하며, 최종 출력 4는 3으로 양자화될 수 있다. 양자화 결과는 다음 노드로 전달될 수 있다. 도 5는 일 실시예에서, 양자화를 위한 장치를 설명하기 위한 블록도이다. 도 5을 참조하면, 복수의 레지스터 XNOR 연산기 팝카운터(Popcounter, 530), 시프터(Shifter, 540) 및 누산기(accumulator, 550)을 포함하는 장치가 제공될 수 있다. 일 실시예에 따른 장치는 프로세서, 메모리 및 통신 인터페이스를 더 포함할 수 있다. 프로세서, 메모리 및 통신 인터페이스는 통신 버스를 통해 서로 통신할 수 있다. 일 실시예에 따른 프로세서에 의해 인코더, XNOR 연산기, 팝카운터(Popcounter, 530), 시프터 (Shifter, 540) 및 누산기(accumulator, 550)의 동작이 제어될 수 있다. 실시예에서, XNOR 연산기 및 팝 카운터(Popcounter, 530)는 이진 신경망을 통해 구현될 수 있다. 실시예에 따른 레지스터들는, 미리 정해진 양자화 기법을 이용하여 M 차원의 제1 벡터에 해당하는 입력 데 이터 및 M 차원의 제2 벡터에 해당하는 가중치 파라미터가 N개 계층으로 인코딩 된 제1 비트열들 및 제2 비트열 들을 저장할 수 있다. XNOR 연산기 및 팝카운터는, 해당하는 제1 비트열 및 해당하는 제2 비트열 간 XNOR 연산을 수행하고 XNOR 연산 결과에 Popcount 연산을 수행할 수 있다. 실시예에서, 병렬로 연결된 BNN 연산기로 입력된 입력 데이터의 비트열들 중 하나의 비트열 및 가중치 파라미터 의 비트열들 중 하나의 비트열을 교차하면서 모든 조합에 대해 XNOR 연산을 수행하고, XNOR 연산된 결과들 각각 에 Popcount를 수행할 수 있다. 시프터는, XNOR 연산 및 Popcount된 결과 값들 각각에 해당하는 bit 만큼 시프트를 수행할 수 있으며, 누 산기는, 시프트가 완료된 결과 값들을 누적하여 합산할 수 있다. 실시예에서, 장치는 누적 연산 결과에 기초하여 입력 데이터와 가중치 파라미터 간 내적 연산 결과를 제공 할 수 있다. 장치는 입출력 장치(미도시)를 통하여 외부 장치(예를 들어, 퍼스널 컴퓨터 또는 네트워크)에 연결되고, 데이터를 교환할 수 있다. 장치는 스마트 폰, 태블릿 컴퓨터, 랩톱 컴퓨터, 데스크톱 컴퓨터, 텔레비전, 웨어러블 장치, 보안 시스템, 스마트 홈 시스템 등 다양한 컴퓨팅 장치 및/또는 시스템에 탑재될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다."}
{"patent_id": "10-2021-0163588", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2021-0163588", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 양자화 방법이 적용되는 양자화 파라미터에 대한 그래프이다. 도 2는 실시예에서, 양자화 레벨에 따른 구간의 매핑 확률에 대해 설명하기 위한 그래프이다. 도 3은 실시예에서, 인공 신경망의 양자화 기법을 구현하기 위한 장치의 동작 방법의 흐름도이다. 도 4는 실시예에서, 데이터 및 양자화 파라미터의 예시를 이용한 장치의 동작을 설명하기 위한 도면이다. 도 5는 실시예에서, 인공 신경망의 양자화 기법을 구현하기 위한 장치의 구성을 설명하기 위한 블록도이다."}
