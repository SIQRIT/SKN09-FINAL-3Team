{"patent_id": "10-2022-0111692", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0032555", "출원번호": "10-2022-0111692", "발명의 명칭": "인공지능 시스템 및 그 인공지능 시스템의 응답 방법", "출원인": "주식회사 케이티", "발명자": "신선호"}}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 시스템에 있어서,호출 데이터를 수신하고, 해당 호출 데이터의 빈도수를 소정 수의 카운터들의 배열을 이용하여 기록하며, 해당호출 데이터의 빈도수를 기초로 상기 호출 데이터를 인공지능 모델 또는 응답 캐시 중 하나로 전달하는 호출 필터링부;상기 호출 필터링부로부터 전달되는 호출 데이터에 대응하는 응답 데이터를 출력하는 인공지능 모델; 및호출 데이터, 응답 데이터 및 호출 건수를 기록하는 캐싱 테이블을 포함하고, 상기 호출 필터링부로부터 전달되는 호출 데이터에 대응하는 응답 데이터를 상기 캐싱 테이블에서 검색하여 출력하는 응답 캐시를 포함하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 호출 필터링부는,호출 데이터를 서로 다른 소정 수의 해시 함수로 연산한 각 값들에 대응하는 카운터들을 선택하고, 그 중 가장작은 카운터의 값을 증가시키는 방식으로 빈도수를 기록하는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 가장 작은 카운터의 값이 캐싱 임계값 보다 작은 경우, 상기 호출 필터링부는, 호출 데이터를 상기 인공지능 모델로 전달하는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 가장 작은 카운터의 값이 캐싱 임계값과 같은 경우, 상기 호출 필터링부는, 호출 데이터를 상기 인공지능 모델로 전달하고,상기 응답 캐시는, 해당 호출 데이터 및 이에 대응하는 응답 데이터와, 상기 호출 건수로서 상기 가장 작은 카운터의 값을 상기 캐싱 테이블에 기록하는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 가장 작은 카운터의 값이 캐싱 임계값 보다 큰 경우,상기 호출 필터링부는, 호출 데이터를 상기 응답 캐시로 전달하고,상기 응답 캐시는, 상기 캐싱 테이블에서 상기 호출 필터링부로부터 전달된 호출 데이터에 대응하는 호출 건수를 증가시키는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 응답 캐시는,공개특허 10-2024-0032555-3-상기 캐싱 테이블이 모두 채워진 경우, 상기 캐싱 테이블에서 삭제 임계값 이하의 호출 건수에 해당하는 데이터를 삭제하고, 상기 삭제 임계값을 증가시키는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 응답 캐시는,상기 캐싱 테이블이 소정 시간 동안 소정 % 이상 비어 있는 경우, 상기 삭제 임계값을 감소시키는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,초기화시,상기 응답 캐시는, 상기 캐싱 테이블에서 호출 건수가 하위 소정 % 내에 해당하는 데이터를 삭제하고 남은 데이터의 호출 건수를 상기 삭제 임계값으로 변경하며,상기 호출 필터링부는, 상기 소정 수의 카운터의 값을 모두 0으로 초기화한 후, 상기 남은 데이터에 대응하는카운터의 값을 상기 삭제 임계값으로 기록하는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능 시스템의 응답 방법에 있어서,호출 데이터를 수신하는 단계;수신된 호출 데이터의 빈도수를 소정 수의 카운터들의 배열을 이용하여 기록하는 단계; 및해당 호출 데이터의 빈도수를 기초로 상기 호출 데이터에 대한 응답 데이터를 인공지능 모델 또는, 응답 캐시중 하나를 이용하여 출력하되, 상기 응답 캐시는 호출 데이터, 응답 데이터 및 호출 건수를 기록하는 캐싱 테이블을 포함하는, 출력하는 단계를 포함하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 기록하는 단계는,호출 데이터를 서로 다른 소정 수의 해시 함수로 연산한 각 값들에 대응하는 카운터들을 선택하는 단계; 및선택된 카운터 중 중 가장 작은 카운터의 값을 증가시키는 단계를 포함하는 것을 특징으로 하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 출력하는 단계는,상기 가장 작은 카운터의 값이 캐싱 임계값 보다 작은 경우, 상기 인공지능 모델을 이용하여 응답 데이터를 출력하는 것을 특징으로 하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 출력하는 단계는,상기 가장 작은 카운터의 값이 캐싱 임계값과 같은 경우, 상기 인공지능 모델을 이용하여 응답 데이터를 출력하는 단계; 및해당 호출 데이터 및 이에 대응하는 응답 데이터와, 호출 건수를 상기 응답 캐시의 캐싱 테이블에 기록하되, 상공개특허 10-2024-0032555-4-기 호출 건수로서 상기 가장 작은 카운터의 값을 기록하는 단계를 포함하는 것을 특징으로 하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 출력하는 단계는,상기 가장 작은 카운터의 값이 캐싱 임계값 보다 큰 경우,해당 호출 데이터에 대응하는 응답 데이터를 상기 캐싱 테이블에서 검색하여 출력하는 단계; 및상기 캐싱 테이블에서 해당 호출 데이터에 대응하는 호출 건수를 증가시키는 단계를 포함하는 것을 특징으로 하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 캐싱 테이블이 모두 채워진 경우, 상기 캐싱 테이블에서 삭제 임계값 이하의 호출 건수에 해당하는 데이터를 삭제하고, 상기 삭제 임계값을 증가시키는 단계를 더 포함하는 것을 특징으로 하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 캐싱 테이블이 소정 시간 동안 소정 % 이상 비어 있는 경우, 상기 삭제 임계값을 감소시키는 단계를 더 포함하는 것을 특징으로 하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 캐싱 테이블에서 호출 건수가 하위 소정 % 내에 해당하는 데이터를 삭제하고 남은 데이터의 호출 건수를상기 삭제 임계값으로 변경하는 단계; 및상기 소정 수의 카운터의 값을 모두 0으로 초기화한 후, 상기 남은 데이터에 대응하는 카운터의 값을 상기 삭제임계값으로 기록하는 단계를 더 포함하는 것을 특징으로 하는 응답 방법."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "자주 사용되는 호출 데이터와 응답 데이터를 적은 메모리 사용으로 효율적으로 선별 및 캐싱하여 호출에 응답하 는 인공지능 시스템 및 인공지능 응답 방법이 개시된다. 일 측면에 따른 인공지능 시스템은, 호출 데이터를 수신 하고, 해당 호출 데이터의 빈도수를 소정 수의 카운터들의 배열을 이용하여 기록하며, 해당 호출 데이터의 빈도 수를 기초로 상기 호출 데이터를 인공지능 모델 또는 응답 캐시 중 하나로 전달하는 호출 필터링부; 상기 호출 필터링부로부터 전달되는 호출 데이터에 대응하는 응답 데이터를 출력하는 인공지능 모델; 및 호출 데이터, 응답 데이터 및 호출 건수를 기록하는 캐싱 테이블을 포함하고, 상기 호출 필터링부로부터 전달되는 호출 데이터에 대 응하는 응답 데이터를 상기 캐싱 테이블에서 검색하여 출력하는 응답 캐시를 포함한다."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 시스템 및 인공지능 응답 방법에 관한 것으로, 보다 구체적으로 자주 사용되는 응답 데이터 를 캐싱하여 호출에 응답하는 인공지능 시스템 및 인공지능 응답 방법에 관한 것이다."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 모델에 사용되는 뉴럴 네트워크는 연산량이 많아 고가의 GPU를 포함한 여러 많은 리소스가 사용된다. 최근 인공지능 모델의 사이즈가 커지는 경향에 따라 더 많은 리소스가 필요하다. 인공지능 모델이 사용되는 서 비스 이용량도 증가하면서 인공지능 모델 호출 건수가 리소스의 한계를 뛰어 넘고 있다. 인공지능 모델의 필요 연산량과 사용량이 모두 증가하면서 그와 비례하게 하드웨어 리소스를 계속 증설해야 하 지만 그렇지 못해 인공지능 모델 호출 구간이 서비스 전체에서 병목 구간이 된다. 인공지능 모델을 호출할 때 입력되는 데이터가 같으면 응답도 동일한 모델들이 있다. 예를 들면, 텍스트 문장을 음성으로 출력하는 음성 합성 모델 등이다. 음성 합성 모델에 '안녕하세요'라는 텍스트로 100번 호출을 하면, 100번 모두 똑같은 '안녕하세요'라는 음성이 응답된다. 인공지능 기반 서비스를 운용할 때 인공지능 모델을 호출하는 데이터의 분포는 지프의 법칙을 따른다. 캐싱 알 고리즘을 적용하면 인공지능 모델 호출을 비약적으로 감소시킬 수 있다. 이는 하드웨어 리소스를 효과적으로 사 용할 수 있게 하기 때문에 막대한 비용 절감을 달성할 수 있다.인공지능 모델 호출에 효과적인 캐싱을 적용하기 위해 해결해야 할 문제는 다음과 같다. 모든 응답을 캐시에 저 장할 수 없기 때문에 빈도수가 높은 모델 요청을 선별해야 한다. 그러기 위해서는 호출되는 데이터의 빈도수를 측정해야 한다. 이 경우 {데이터 : 빈도수} 페어를 기록해야 하는데 인공지능 모델에 입력되는 데이터의 경우의 수가 무한대에 가까워 메모리 용량 문제, 검색 문제 등 때문에 불가능하다. 마찬가지의 이유로 전통적인 캐싱 알고리즘(LRU, LFU, FIFO 등)도 사용할 수 없다."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위해 제안된 것으로, 자주 사용되는 호출 데이터와 응답 데이터를 적은 메 모리 사용으로 효율적으로 선별 및 캐싱하여 호출에 응답하는 인공지능 시스템 및 인공지능 응답 방법을 제공하 는데 그 목적이 있다."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 따른 인공지능 시스템은, 호출 데이터를 수신하고, 해당 호출 데이터의 빈도수를 소정 수의 카운터들 의 배열을 이용하여 기록하며, 해당 호출 데이터의 빈도수를 기초로 상기 호출 데이터를 인공지능 모델 또는 응 답 캐시 중 하나로 전달하는 호출 필터링부; 상기 호출 필터링부로부터 전달되는 호출 데이터에 대응하는 응답 데이터를 출력하는 인공지능 모델; 및 호출 데이터, 응답 데이터 및 호출 건수를 기록하는 캐싱 테이블을 포함 하고, 상기 호출 필터링부로부터 전달되는 호출 데이터에 대응하는 응답 데이터를 상기 캐싱 테이블에서 검색하 여 출력하는 응답 캐시를 포함한다. 상기 호출 필터링부는, 호출 데이터를 서로 다른 소정 수의 해시 함수로 연산한 각 값들에 대응하는 카운터들을 선택하고, 그 중 가장 작은 카운터의 값을 증가시키는 방식으로 빈도수를 기록할 수 있다. 상기 가장 작은 카운터의 값이 캐싱 임계값 보다 작은 경우, 상기 호출 필터링부는, 호출 데이터를 상기 인공지 능 모델로 전달할 수 있다. 상기 가장 작은 카운터의 값이 캐싱 임계값과 같은 경우, 상기 호출 필터링부는, 호출 데이터를 상기 인공지능 모델로 전달하고, 상기 응답 캐시는, 해당 호출 데이터 및 이에 대응하는 응답 데이터와, 상기 호출 건수로서 상기 가장 작은 카운터의 값을 상기 캐싱 테이블에 기록할 수 있다. 상기 가장 작은 카운터의 값이 캐싱 임계값 보다 큰 경우, 상기 호출 필터링부는, 호출 데이터를 상기 응답 캐 시로 전달하고, 상기 응답 캐시는, 상기 캐싱 테이블에서 상기 호출 필터링부로부터 전달된 호출 데이터에 대응 하는 호출 건수를 증가시킬 수 있다. 상기 응답 캐시는, 상기 캐싱 테이블이 모두 채워진 경우, 상기 캐싱 테이블에서 삭제 임계값 이하의 호출 건수 에 해당하는 데이터를 삭제하고, 상기 삭제 임계값을 증가시킬 수 있다. 상기 응답 캐시는, 상기 캐싱 테이블이 소정 시간 동안 소정 % 이상 비어 있는 경우, 상기 삭제 임계값을 감소 시킬 수 있다. 초기화시, 상기 응답 캐시는, 상기 캐싱 테이블에서 호출 건수가 하위 소정 % 내에 해당하는 데이터를 삭제하고 남은 데이터의 호출 건수를 상기 삭제 임계값으로 변경하며, 상기 호출 필터링부는, 상기 소정 수의 카운터의 값을 모두 0으로 초기화한 후, 상기 남은 데이터에 대응하는 카운터의 값을 상기 삭제 임계값으로 기록할 수 있 다. 일 측면에 따른 인공지능 시스템의 응답 방법은, 호출 데이터를 수신하는 단계; 수신된 호출 데이터의 빈도수를 소정 수의 카운터들의 배열을 이용하여 기록하는 단계; 및 해당 호출 데이터의 빈도수를 기초로 상기 호출 데이 터에 대한 응답 데이터를 인공지능 모델 또는, 응답 캐시 중 하나를 이용하여 출력하되, 상기 응답 캐시는 호출 데이터, 응답 데이터 및 호출 건수를 기록하는 캐싱 테이블을 포함하는, 출력하는 단계를 포함한다. 상기 기록하는 단계는, 호출 데이터를 서로 다른 소정 수의 해시 함수로 연산한 각 값들에 대응하는 카운터들을 선택하는 단계; 및 선택된 카운터 중 중 가장 작은 카운터의 값을 증가시키는 단계를 포함할 수 있다. 상기 출력하는 단계는, 상기 가장 작은 카운터의 값이 캐싱 임계값 보다 작은 경우, 상기 인공지능 모델을 이용 하여 응답 데이터를 출력할 수 있다.상기 출력하는 단계는, 상기 가장 작은 카운터의 값이 캐싱 임계값과 같은 경우, 상기 인공지능 모델을 이용하 여 응답 데이터를 출력하는 단계; 및 해당 호출 데이터 및 이에 대응하는 응답 데이터와, 호출 건수를 상기 응 답 캐시의 캐싱 테이블에 기록하되, 상기 호출 건수로서 상기 가장 작은 카운터의 값을 기록하는 단계를 포함할 수 있다. 상기 출력하는 단계는, 상기 가장 작은 카운터의 값이 캐싱 임계값 보다 큰 경우, 해당 호출 데이터에 대응하는 응답 데이터를 상기 캐싱 테이블에서 검색하여 출력하는 단계; 및 상기 캐싱 테이블에서 해당 호출 데이터에 대 응하는 호출 건수를 증가시키는 단계를 포함할 수 있다. 상기 응답 방법은, 상기 캐싱 테이블이 모두 채워진 경우, 상기 캐싱 테이블에서 삭제 임계값 이하의 호출 건수 에 해당하는 데이터를 삭제하고, 상기 삭제 임계값을 증가시키는 단계를 더 포함할 수 있다. 상기 응답 방법은, 상기 캐싱 테이블이 소정 시간 동안 소정 % 이상 비어 있는 경우, 상기 삭제 임계값을 감소 시키는 단계를 더 포함할 수 있다. 상기 응답 방법은, 상기 캐싱 테이블에서 호출 건수가 하위 소정 % 내에 해당하는 데이터를 삭제하고 남은 데이 터의 호출 건수를 상기 삭제 임계값으로 변경하는 단계; 및 상기 소정 수의 카운터의 값을 모두 0으로 초기화한 후, 상기 남은 데이터에 대응하는 카운터의 값을 상기 삭제 임계값으로 기록하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은, 소정 수의 카운터를 공유하여 호출 데이터들의 빈도수를 기록하여 캐싱 여부를 결정함으로써, 각 호 출 데이터마다 전용 카운터를 이용할 때보다 메모리 사용량을 현저하게 줄일 수 있다. 본 발명은, 삭제 임계값을 가변하면서 응답 캐시의 캐싱 테이블에서 자주 호출되지 않는 데이터를 삭제하여 캐 싱 테이블의 빈 공간을 적절히 유지하면서 자주 호출되지 않는 데이터들을 삭제할 수 있다. 본 발명은, 초기화시, 인공지능 모델로 호출이 집중되는 것을 방지하면서, 응답 데이터의 캐싱 미스를 줄일 수 있다."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로 서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시예를 설명함 에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단 되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이해할 수 있도 록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사 상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는목적으로만 사용된다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 인공지능 시스템의 구성을 나타낸 도면이다. 도 1을 참조하면, 본 실시예에 따른 인공지능 시스템은, 호출 필터링부, 인공지능 모델 및 응답 캐시를 포함한다. 인공지능 시 스템은, 메모리, 하나 이상의 프로세서(CPU), 주변 인터페이스, 입출력(I/O) 서브시스템, 디스플레이 장치, 입 력 장치 및 통신 회로를 포함할 수 있다. 인공지능 시스템의 호출 필터링부, 인공지능 모델 및 응답 캐시은, 프로그램으로 구현되어 메모리에 저장되고 적어도 하나의 프로세서에 의해 실행될 수 있고, 하드 웨어와 소프트웨어의 조합으로 구현되어 동작할 수 있다. 호출 필터링부는, 호출 데이터를 수신한다. 호출 데이터는 음성 또는 텍스트일 수 있으나 여기에 제한되지 않는다. 호출 필터링부는, 호출 데이터의 빈도수를 m(m은 자연수)개의 카운터들의 배열을 이용하여 기록한 다. 여기서 카운터는 정수 카운터일 수 있다. 즉, 각 카운터는 0으로 초기화된 상태에서 1씩 값을 증가시키거나 감소시킬 수 있다. 호출 필터링부는, 서로 다른 k(k는 자연수)개의 해시 함수를 이용하여 호출 데이터의 빈도수를 기록할 카 운터 k개를 선택할 수 있다. 여기서 k는 m보다 작은 자연수일 수 있고, 서로 다른 k개의 해시 함수 각각은 호출 데이터를 입력받아 1~m의 자연수 중 하나의 값을 출력할 수 있다. 예를 들어, 각 해시 함수는 해시 연산 값을 m 으로 나눈 값을 출력할 수 있다. 호출 필터링부는 호출 데이터를 입력받은 k개의 해시 함수의 출력 값에 해당하는 순서의 카운터를 해당 호출 데이터의 빈도수를 기록할 카운터로 선택할 수 있다. 호출 필터링부는, 호출 데이터의 빈도수를 기록할 k개의 카운터를 선택한 후, 해당 선택된 k개의 카운터 중 가장 작은 카운터 값을 '1'만큼 증가시킨다. 즉, 무조건 선택된 k개의 카운터의 값을 모두 '1'만큼 증가시키 는 것이 아닌, 선택된 k개의 카운터 중 가장 작은 카운터 값만을 '1'만큼 증가시킨다. 도 2는 본 발명의 일 실시예에 따른 m개의 카운터들의 배열에 호출 데이터의 빈도수를 기록하는 과정을 설명하 는 도면이다. 도 2의 (a)는 초기화 상태의 m개의 카운터들의 배열로서, 각 카운터의 값은 '0'으로 기록되어 있 다. 이 상태에서 예를 들어 '안녕하세요'라는 호출 데이터가 호출 필터링부로 수신되었을 때, 호출 필터링 부는 k개의 해시 함수에 '안녕하세요'를 입력하고 각 해시 함수에서 출력되는 k개의 자연수에 해당하는 순 서의 카운터의 값을 '1'만큼 증가시킨다. 예를 들어, k는 3이고, 3개의 해시 함수에 '안녕하세요'를 입력했을 때, 3개의 해시 함수에서 3, 5, 7이 출력되 었다면, 3번째, 5번째 및 7번째 카운터의 값 중 가장 작은 값만 '1'만큼 증가시킨다. 도 2의 (a)와 같은 초기화 상태에서는 모든 카운터의 값이 '0'이므로, 3번째, 5번째 및 7번째 카운터의 값이 모두 '0'으로 동일하므로, 도 2의 (b)에 도시된 바와 같이, 3번째, 5번째 및 7번째 카운터의 값을 모두 '1'만큼 증가시킨다. 도 3은 본 발명의 다른 실시예에 따른 m개의 카운터들의 배열에 호출 데이터의 빈도수를 기록하는 과정을 설명 하는 도면이다. 도 3의 (a)에 도시된 바와 같이, m개의 카운터의 값이 기록되어 있는 상태에서, 상술한 예와 같 이 '안녕하세요'라는 호출 데이터가 호출 필터링부로 수신되고, 3개의 해시 함수에서 3, 5 및 7이 출력되 면, 호출 데이터의 빈도수를 기록할 카운터로서 3번째, 5번째 및 7번째 카운터가 선택된다. 3번째, 5번째 및 7 번째 카운터의 값은 각각 8, 6 및 9이고, 이 중 가장 작은 값은 5번째 카운터의 값 6이므로, 도 3의 (b)에 도시 된 바와 같이, 해당 5번째 카운터의 값만 '1'만큼 증가되어 7로 업데이트된다. 도 3의 (b)의 상태에서, '감사합니다'라는 호출 데이터가 호출 필터링부로 수신되고, 3개의 해시 함수에서 2, 3 및 4가 출력되면, 호출 데이터의 빈도수를 기록할 카운터로서 2번째, 3번째 및 4번째 카운터가 선택된다. 2번째, 3번째 및 4번째 카운터의 값은 각각 0, 8, 2이고, 이 중 가장 작은 값은 2번째 카운터의 값 0이므로, 도 3의 (c)에 도시된 바와 같이, 해당 2번째 카운터의 값만 '1'만큼 증가되어 1로 업데이트된다. k개의 해시 함수는 1~m의 자연수 중 하나의 값을 출력하므로 서로 다른 호출 데이터에 대해 k개의 해시 함수의 출력 값은 일부 중복될 수 있다. 상술한 예에서, '안녕하세요'와 '감사합니다'는 서로 다른 호출 데이터이지만, '안녕하세요'와 '감사합니다'를 각각 3개의 해시 함수에 입력했을 때, 하나의 해시 함수의 출력 값은 동일한 3 을 출력한다. 그러나 해시 함수의 특성상 서로 다른 호출 데이터에 대해 k개의 해시 함수가 모두 동일한 값을 출력할 수는 없다. 이로부터 알 수 있는 바와 같이, 본 발명은, 호출 데이터들의 빈도수를 기록하는데 있어서 m 개의 카운터를 공유함으로써, 메모리 사용량을 줄인다. 호출 필터링부는, 수신된 호출 데이터에 대해 선택된 k개의 카운터 중 가장 작은 카운터의 값을 '1'만큼 증가시킨 후, 증가된 가장 작은 카운터의 값이 캐싱 임계값 보다 작은 경우, 해당 호출 데이터를 인공지능 모델 로 전달한다. 예를 들어, 캐싱 임계값이 7이라고 가정할 때, 도 2의 (b)의 예에서, 선택된 3번째, 5번째 및 7번째 카운터의 증가된 값은 모두 1이고, 모두 캐싱 임계값 7 보다 작으므로, 호출 데이터를 인공지능 모델 로 전달한다. 이 경우, 인공지능 모델이 호출 데이터에 대해 응답 데이터를 출력한다. 호출 필터링부는, 상기 증가된 가장 작은 카운터의 값이 캐싱 임계값과 같은 경우, 일단 호출 데이터를 인 공지능 모델로 전달하고, 응답 캐시에 해당 호출 데이터가 등록되도록 응답 캐시로 상기 증가된 가장 작은 카운터의 값을 전달하고, 인공지능 모델에게 응답 캐시로 응답 결과를 전송하도록 요청한 다. 이 경우, 인공지능 모델이 호출 데이터에 대해 응답 데이터를 출력한다. 캐싱 임계값이 7이라고 가정 할 때, 도 3의 (b)의 예에서, 선택된 3번째, 5번째 및 7번째 카운터 중 5번째 카운터의 값이 1만큼 증가되어 7 이고, 해당 7은 캐싱 임계값과 같으므로, 호출 필터링부는, 호출 데이터를 인공지능 모델로 전달하고, 응답 캐시에 해당 호출 데이터가 등록되도록 응답 캐시로 상기 증가된 가장 작은 카운터의 값인 7을 전달한다. 호출 필터링부는, 상기 증가된 가장 작은 카운터의 값이 캐싱 임계값 보다 큰 경우, 해당 호출 데이터를 인공지능 모델로 전달하지 않고, 응답 캐시로 전달한다. 이 경우, 응답 데이터의 출력은 인공지능 모 델이 아닌, 응답 캐시에서 이루어진다. 응답 캐시는, 미리 정의된 크기의 캐싱 테이블을 포함한다. 즉, 미리 정의된 크기의 메모리(또는 디스크) 를 사용한다. 응답 캐시는, 상기 캐싱 테이블에, 캐싱 대상의 호출 데이터와 이에 대응하는 응답 데이터, 그리고 호출 건수를 저장한다. 구체적으로, 응답 캐시는, 호출 필터링부로부터 특정 호출 데이터에 대해 선택된 카운터들의 값 중 가장 작은 카운터의 값(이 값은 해당 호출 이벤트에 따라 1만큼 증가된 값임)을 수신하고, 인공지능 모델 로부터 해당 특정 호출 데이터에 대한 응답 결과가 수신되면, 상기 캐싱 테이블에 해당 특정 호출 데이터와 응 답 데이터를 기록하고, 상기 가장 작은 카운터의 값을 호출 건수로서 기록한다. 도 4는 본 발명의 일 실시예에 따른 캐싱 테이블의 예이다. 응답 캐시는, 호출 필터링부로부터 호출 데이터를 수신하는 경우, 상기 캐싱 테이블에서 그 수신된 호출 데이터에 대응하는 응답 데이터를 검색하고, 검색된 응답 데이터를 출력한다. 이때, 응답 캐시는, 상 기 캐싱 테이블에서 해당 호출 데이터에 대응하는 호출 건수를 1만큼 증가시킨다. 매우 낮은 확률이지만, 긍정 오류가 발생하여 캐싱 테이블에 응답 데이터가 없는 경우가 있다. 이 경우 응답 캐시는 인공지능 모델 로 응답 데이터의 출력을 요청한다. 앞서 설명한 바와 같이, 캐싱 테이블은 미리 정의된 크기를 갖는다. 즉, 캐싱 테이블에 저장할 수 있는 데이터 의 수는 한정된다. 따라서, 캐싱 테이블에서 자주 호출되지 않는 데이터를 삭제하여 메모리 용량을 확보할 필요 가 있다. 이를 위해 응답 캐시는, 삭제 임계값을 설정하고, 삭제 임계값과 캐싱 테이블 내의 호출 건수들 을 비교하여, 삭제 임계값 이하의 호출 건수에 해당하는 행 데이터를 삭제한다. 예를 들어, 삭제 임계값이 5라 면, 5 이하의 호출 건수에 해당하는 행 데이터를 삭제한다. 초기에 설정되는 삭제 임계값은 1 보다 큰 것이 바 람직하다. 삭제 임계값이 1인 경우, 삭제할 데이터가 없을 수 있기 때문이다. 응답 캐시는, 삭제 임계값을 기초로 캐싱 테이블을 정리한 후, 삭제 임계값을 증가시킨다. 예를 들어, 1만 큼 증가시킨다. 삭제 임계값을 고정할 경우, 최근 자주 호출되지 않지만 과거에 호출이 많았던 데이터들이 캐싱 테이블에 그대로 남을 수 있으므로, 삭제 임계값을 증가시킨다. 다만, 응답 캐시는, 일정한 시간(예, 1시 간) 동안 캐싱 테이블이 소정 비율(예, 50%) 이상 비어 있는 경우, 삭제 임계값을 예를 들어 1만큼 감소시킨다. 이와 같이 삭제 임계값을 변경함으로써 캐싱 테이블의 빈 공간을 적절히 유지하면서 자주 호출되지 않는 데이터 들을 삭제할 수 있다. 응답 캐시에서 관리하는 캐싱 테이블과 호출 필터링부에서 관리하는 m개의 카운터들을 초기화할 필요 가 있다. m개의 모든 카운터의 값을 0으로 초기화하고 캐싱 테이블의 데이터를 모두 삭제하여 비우는 방법을 고 려할 수 있지만, 이 경우 의미 있는 호출 데이터와 응답 데이터가 캐싱 테이블에 채워질 때까지 시간이 소요되 고, 인공지능 모델로 호출이 집중되어 효율적이지 않다. 따라서, 다음과 같이 m개의 카운터들과 캐싱 테이 블을 초기화하는 것이 바람직하다. 먼저, 응답 캐시는, 캐싱 테이블에서 호출 건수가 하위 소정 %(예, 50%) 내에 속하는 행들의 데이터를 삭 제하고 남은 행들의 데이터의 호출 건수를 삭제 임계값으로 변경한다. 그리고, 호출 필터링부는, m개의 카 운터의 값을 모두 0으로 초기화한 후, 상기 캐싱 테이블에 남은 행들의 데이터 중 호출 데이터들을 k개의 해시 함수로 연산하여 얻은 자연수들에 해당하는 순서의 카운터들의 값을 상기 삭제 임계값으로 기록한다. 여기서 k 개의 해시 함수는, 호출 필터링부가 호출 데이터를 수신하였을 때 m개의 카운터 중에서 호출 데이터의 빈 도수를 기록할 카운터를 선택할 때 사용한 k개의 해시 함수와 동일하다. 이와 같이, 초기화할 때 및 호출 데이터의 빈도수를 기록할 때, k개의 동일한 해시 함수를 사용하고, 캐싱 테이 블의 호출 건수 및 카운터들의 값을 삭제 임계값으로 동일하게 기록하기 때문에, 초기화 후에도, 캐싱 테이블에 남은 행들에 기록된 호출 데이터들의 호출 건수와, m개의 카운터의 동일 호출 데이터들에 대한 카운터의 값이 동일해져, 캐싱 테이블의 카운터 값과 캐싱 테이블의 호출 건수의 동기화가 유지된다. 도 5는 본 발명의 일 실시예에 따른 인공지능 응답 방법을 설명하는 흐름도이다. 도 5를 참조한 방법은 인공지 능 시스템의 프로세서에 의해 수행되거나, 하드웨어/소프트웨어의 조합으로 수행될 수 있다. 도 5를 참조하면, 단계 S501에서, 인공지능 시스템은, m개의 카운터 각각의 값을 0으로 초기화한다. 이때, 카운 터는 0을 최소값으로 하여 1씩 증가하거나 감소할 수 있는 정수 카운터인 것으로 설명한다. 단계 S502에서, 인 공지능 시스템은, 호출 데이터를 수신한다. 호출 데이터는 음성 또는 텍스트일 수 있다. 단계 S503에서, 인공지능 시스템은, 서로 다른 k(k는 자연수)개의 해시 함수를 이용하여 호출 데이터의 빈도수 를 기록할 카운터 k개를 선택한다. 여기서 k는 m보다 작은 자연수일 수 있고, 서로 다른 k개의 해시 함수 각각 은 호출 데이터를 입력받아 1~m의 자연수 중 하나의 값을 출력할 수 있다. 예를 들어, 각 해시 함수는 해시 연 산 값을 m으로 나눈 값을 출력할 수 있다. 인공지능 시스템은, 호출 데이터를 입력받은 k개의 해시 함수의 출력 값에 해당하는 순서의 카운터를 해당 호출 데이터의 빈도수를 기록할 카운터로 선택할 수 있다. 단계 S504에서, 인공지능 시스템은, 선택된 k개의 카운터 중 가장 작은 카운터의 값을 '1'만큼 증가시킨다. 즉, 무조건 선택된 k개의 카운터의 값을 모두 '1'만큼 증가시키는 것이 아닌, 선택된 k개의 카운터 중 가장 작은 카 운터의 값만을 '1'만큼 증가시킨다. 단계 S505에서, 인공지능 시스템은, 상기 증가된 가장 작은 카운터의 값과 캐싱 임계값을 비교한다. 상기 증가된 가장 작은 카운터의 값이 캐싱 임계값 보다 작은 경우, 단계 S506에서, 인공지능 시스템은, 인공지 능 모델을 이용하여 응답 데이터를 출력한다. 상기 증가된 가장 작은 카운터의 값이 캐싱 임계값과 같은 경우, 단계 S507에서, 인공지능 시스템은, 일단 인공 지능 모델을 이용하여 응답 데이터를 출력한다. 그리고 단계 S508에서, 인공지능 시스템은, 응답 캐시 의 캐싱 테이블에 해당 호출 데이터, 응답 데이터, 그리고 호출 건수를 기록한다. 이때, 인공지능 시스템 은, 호출 건수로서 상기 증가된 가장 작은 카운터의 값을 기록한다. 상기 증가된 가장 작은 카운터의 값이 캐싱 임계값과 같은 경우, 단계 S509에서, 인공지능 시스템은, 응답 캐시 의 캐싱 테이블에서 해당 호출 데이터에 대응하는 응답 데이터를 검색하여 출력한다. 그리고 단계 S510에 서, 인공지능 시스템은, 캐싱 테이블에서 해당 호출 데이터에 대응하는 호출 건수를 1만큼 증가시킨다. 도 6은 본 발명의 일 실시예에 따른 캐싱 테이블을 관리하는 방법을 설명하는 흐름도이다. 도 6을 참조한 방법 은 인공지능 시스템의 프로세서에 의해 수행되거나, 하드웨어/소프트웨어의 조합으로 수행될 수 있다. 도 6을 참조하면, 단계 S601에서, 인공지능 시스템은, 삭제 임계값을 설정한다. 초기에 설정되는 삭제 임계값은 1 보다 큰 것이 바람직하다. 삭제 임계값이 1인 경우, 삭제할 데이터가 없을 수 있기 때문이다. 단계 S602에서, 인공지능 시스템은, 응답 캐시의 캐싱 테이블에서 삭제 임계값 이하의 호출 건수에 해당하는 행 데이터를 삭제한다. 예를 들어, 삭제 임계값이 5라면, 5 이하의 호출 건수에 해당하는 행 데이터를 삭제한다. 단계 S603에서, 인공지능 시스템은, 삭제 임계값을 1만큼 증가시킨다. 기존 삭제 임계값이 5이면, 1만큼 증가시 켜 6으로 설정한다. 단계 S604에서, 인공지능 시스템은, 일정한 시간(예, 1시간) 동안 캐싱 테이블이 소정 비율(예, 50%) 이상 비어 있는지 확인한다. 일정한 시간 동안 캐싱 테이블이 소정 비율 이상 비어 있는 경우, 단계 S605에서, 인공지능 시스템은 삭제 임계 값을 1만큼 감소시킨다. 예를 들어, 삭제 임계값이 6이라면, 1만큼 감소시켜 5로 설정한다. 이와 같이 삭제 임 계값을 변경함으로써 캐싱 테이블의 빈 공간을 적절히 유지하면서 자주 호출되지 않는 데이터들을 삭제할 수 있 다. 캐싱 테이블은 미리 정의된 크기를 갖는다. 즉, 캐싱 테이블에 저장할 수 있는 데이터의 수는 한정된다. 도 6을 참조한 캐싱 테이블의 관리 방법에 따르면, 캐싱 테이블에서 자주 호출되지 않는 데이터를 삭제하여 메모리 용 량을 확보할 수 있다. 도 7은 본 발명의 일 실시예에 따른 m개의 카운터 및 캐싱 테이블을 초기화하는 방법을 설명하는 흐름도이다. 도 7을 참조한 방법은 인공지능 시스템의 프로세서에 의해 수행되거나, 하드웨어/소프트웨어의 조합으로 수행될 수 있다. 도 7을 참조하면, 단계 S701에서, 인공지능 시스템은, 캐싱 테이블에서 호출 건수가 하위 소정 % 내에 속하는 행들의 데이터를 삭제한다. 단계 S702에서, 인공지능 시스템은, 캐싱 테이블의 남은 행들의 데이터의 호출 건수 를 삭제 임계값으로 변경한다. 단계 S703에서, 인공지능 시스템은, m개의 카운터의 값을 모두 0으로 초기화한다. 그리고 단계 S704에서, 인공 지능 시스템은, 상기 캐싱 테이블의 남은 행들의 데이터 중 호출 데이터들을 k개의 해시 함수로 연산하여 얻은 자연수들에 해당하는 순서의 카운터들을 선택한다. 여기서 k개의 해시 함수는, 인공지능 시스템에 호출 데이터 가 수신되었을 때 m개의 카운터 중에서 호출 데이터의 빈도수를 기록할 카운터를 선택할 때 사용한 k개의 해시 함수와 동일하다. 단계 S705에서, 인공지능 시스템은, 상기 단계 S705에서 선택된 카운터들의 값을 상기 삭제 임계값으로 기록한 다. 초기화시 m개의 모든 카운터의 값을 0으로 초기화하고 캐싱 테이블의 데이터를 모두 삭제하여 비우는 방법을 고 려할 수 있지만, 이 경우 의미 있는 호출 데이터와 응답 데이터가 캐싱 테이블에 채워질 때까지 시간이 소요되 고, 인공지능 모델로 호출이 집중되어 효율적이지 않다. 따라서, 도 7을 참조하여 설명한 방법으로 초기화 할 경우, 인공지능 모델로 호출이 집중되는 것을 방지하면서, 응답 데이터의 캐싱 미스를 줄일 수 있다. 본 명세서는 많은 특징을 포함하는 반면, 그러한 특징은 본 발명의 범위 또는 특허청구범위를 제한하는 것으로 해석되어서는 안 된다. 또한, 본 명세서에서 개별적인 실시예에서 설명된 특징들은 단일 실시예에서 결합되어 구현될 수 있다. 반대로, 본 명세서에서 단일 실시예에서 설명된 다양한 특징들은 개별적으로 다양한 실시예에 서 구현되거나, 적절히 결합되어 구현될 수 있다. 도면에서 동작들이 특정한 순서로 설명되었으나, 그러한 동작들이 도시된 바와 같은 특정한 순서로 수행되는 것으로, 또는 일련의 연속된 순서, 또는 원하는 결과를 얻기 위해 모든 설명된 동작이 수행되는 것으로 이해되어 서는 안 된다. 특정 환경에서 멀티태스킹 및 병렬 프로세싱이 유리할 수 있다. 아울러, 상술한 실시예에서 다양 한 시스템 구성요소의 구분은 모든 실시예에서 그러한 구분을 요구하지 않는 것으로 이해되어야 한다. 상술한 프로그램 구성요소 및 시스템은 일반적으로 단일 소프트웨어 제품 또는 멀티플 소프트웨어 제품에 패키지로 구 현될 수 있다. 상술한 바와 같은 본 발명의 방법은 프로그램으로 구현되어 컴퓨터로 읽을 수 있는 형태로 기록매체(시디롬, 램, 롬, 플로피 디스크, 하드 디스크, 광자기 디스크 등)에 저장될 수 있다. 이러한 과정은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있으므로 더 이상 상세히 설명하지 않기로 한다."}
{"patent_id": "10-2022-0111692", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서 설명한 본 발명은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 있어 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로 전술한 실시예 및 첨부된 도면 에 의해 한정되는 것이 아니다."}
{"patent_id": "10-2022-0111692", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 시스템의 구성을 나타낸 도면이다. 도 2는 본 발명의 일 실시예에 따른 m개의 카운터들의 배열에 호출 데이터의 빈도수를 기록하는 과정을 설명하 는 도면이다. 도 3은 본 발명의 다른 실시예에 따른 m개의 카운터들의 배열에 호출 데이터의 빈도수를 기록하는 과정을 설명 하는 도면이다. 도 4는 본 발명의 일 실시예에 따른 캐싱 테이블의 예이다. 도 5는 본 발명의 일 실시예에 따른 인공지능 응답 방법을 설명하는 흐름도이다. 도 6은 본 발명의 일 실시예에 따른 캐싱 테이블을 관리하는 방법을 설명하는 흐름도이다. 도 7은 본 발명의 일 실시예에 따른 m개의 카운터 및 캐싱 테이블을 초기화하는 방법을 설명하는 흐름도이다."}
