{"patent_id": "10-2024-7001470", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0065063", "출원번호": "10-2024-7001470", "발명의 명칭": "무선 통신 시스템에서 메타렌즈 인공지능 시스템에 기초하여 신호를 송수신하는 방법 및 장치", "출원인": "엘지전자 주식회사", "발명자": "오재기"}}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "무선 통신 시스템에서 기지국 동작 방법에 있어서,제 1 단말로부터 사용자 인식 정보를 수신하는 단계;상기 획득된 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하는 단계; 및상기 획득한 제어 값을 상기 제 1 단말 및 제 2 단말로 전송하는 단계;를 포함하는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 획득되는 상기 제어 값은 상기 메타렌즈 특성인자에 기초하여 코드북 기반으로 결정되는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 메타렌즈 특성인자는 메타렌즈 요소들 각각에 기초하여 초점 위치 정보, 초점 거리 정보 및 곡률 반경 정보 중 적어도 어느 하나에 기초하여 결정되는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 초점 위치 정보, 상기 초점 거리 정보 및 상기 곡률 반경 정보는 양자화에 기초하여 각각의 인덱스로 표현되고,상기 제어 값은 상기 각각의 인덱스에 기초하여 도출되는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 사용자 인식 정보는 사용자 방향 정보, 사용자 거리 정보 및 사용자 상태 정보 중 적어도 어느 하나 이상을 포함하는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 제 1 단말은 영상 입력 기능을 구비한 단말이고, 상기 영상 입력 기능에 기초하여 상기 사용자 인식 정보를 획득하는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 제 1 단말은 제 1 단말의 위치 정보를 획득하고, 상기 제 1 단말의 위치 정보를 상기 사용자 인식 정보와함께 상기 기지국으로 전달하고,상기 기지국은 상기 제 1 단말의 위치 정보를 더 고려하여 상기 제어 값을 도출하는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2024-0065063-3-제 1 항에 있어서,상기 제 2 단말은 영상 출력 기능을 구비한 단말인, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 기지국은 서버 및 엑세스 포인트(access point) 중 적어도 어느 하나의 기능을 포함하는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 기지국은 메타렌즈 인공지능 시스템을 구비하고,상기 메타렌즈 인공지능 시스템은 학습모델에 기초하여 학습을 수행하되, 상기 획득된 사용자 인식 정보는 상기학습모델의 입력이고, 상기 제어 값은 상기 학습모델의 출력인, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 학습모델은 강화학습에 기초하여 동작하고,상기 강화학습은 상기 획득한 사용자 인식 정보 및 상기 제어 값에 기초하여 상태 정보 및 보상 정보를 입력으로 사용하고, 상기 제어 값에 대응되는 행동 정보를 출력하는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 학습모델은 톰슨 샘플링에 기초하여 동작하고,상기 톰슨 샘플링은 상기 획득한 사용자 인식 정보 및 상기 제어 값에 기초하여 α 및 β 파라미터를 갖는 보상정보에 기초하여 학습을 수행하는, 기지국 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "무선 통신 시스템에서 단말 동작 방법에 있어서,기지국으로 사용자 인식 정보를 전송하는 단계; 및상기 전달된 사용자 인식 정보에 기초하여 상기 기지국에 의해 도출된 제어 값을 수신하는 단계;를 포함하는,단말 동작 방법."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "무선 통신 시스템의 기지국에 있어서,송수신기; 및상기 송수신기와 연결된 프로세서를 포함하고,상기 프로세서는,상기 송수신기를 이용하여 제 1 단말로부터 사용자 인식 정보를 수신하고,상기 획득된 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하고, 및상기 송수신기를 이용하여 상기 획득한 제어 값을 상기 제 1 단말 및 제 2 단말로 전송하는, 기지국."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "무선 통신 시스템의 단말에 있어서,공개특허 10-2024-0065063-4-송수신기; 및상기 송수신기와 연결된 프로세서를 포함하고,상기 프로세서는,상기 송수신기를 이용하여 기지국으로 사용자 인식 정보를 전송하고,상기 송수신기를 이용하여 상기 전달된 사용자 인식 정보에 기초하여 상기 기지국에 의해 도출된 제어 값을 수신하는, 단말."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "적어도 하나의 메모리 및 상기 적어도 하나의 메모리들과 기능적으로 연결되어 있는 적어도 하나의 프로세서를포함하는 장치에 있어서,상기 적어도 하나의 프로세서는 상기 장치가,제 1 단말로부터 사용자 인식 정보를 수신하고,상기 획득된 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하고, 및상기 획득한 제어 값을 상기 제 1 단말 및 제 2 단말로 전송하도록 제어하는, 장치."}
{"patent_id": "10-2024-7001470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "적어도 하나의 명령어(instructions)을 저장하는 비-일시적인(non-transitory) 컴퓨터 판독 가능 매체(computer-readable medium)에 있어서, 프로세서에 의해 실행 가능한(executable) 상기 적어도 하나의 명령어를 포함하며,상기 적어도 하나의 명령어는,제 1 단말로부터 사용자 인식 정보를 수신하고,상기 획득된 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하고, 및상기 획득한 제어 값을 상기 제 1 단말 및 제 2 단말로 전송하도록 제어하는, 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에서는 무선 통신 시스템에서 기지국 동작 방법을 제공할 수 있다. 이때, 기지국 동작 방법은 제 1 단말 로부터 사용자 인식 정보를 획득하는 단계, 획득된 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 수신하는 단계 및 획득한 제어 값을 제 1 단말 및 제 2 단말로 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하의 설명은 무선 통신 시스템에 대한 것으로, 무선 통신 시스템에서 메타렌즈 인공지능 시스템에 기초하여 신호를 송수신하는 방법 및 장치에 대한 것이다. 특히, 사용자 기반의 영상 입출력 장치를 고려하여 메타렌즈 인공지능 시스템을 제공하는 방법 및 장치에 대한 것이다."}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무선 접속 시스템이 음성이나 데이터 등과 같은 다양한 종류의 통신 서비스를 제공하기 위해 광범위하게 전개되 고 있다. 일반적으로 무선 접속 시스템은 가용한 시스템 자원(대역폭, 전송 파워 등)을 공유하여 다중 사용자와 의 통신을 지원할 수 있는 다중 접속(multiple access) 시스템이다. 다중 접속 시스템의 예들로는 CDMA(code division multiple access) 시스템, FDMA(frequency division multiple access) 시스템, TDMA(time division multiple access) 시스템, OFDMA(orthogonal frequency division multiple access) 시스템, SC-FDMA(single carrier frequency division multiple access) 시스템 등이 있다. 특히, 많은 통신 기기들이 큰 통신 용량을 요구하게 됨에 따라 기존 RAT (radio access technology)에 비해 향 상된 모바일 브로드밴드(enhanced mobile broadband, eMBB) 통신 기술이 제안되고 있다. 또한 다수의 기기 및 사물들을 연결하여 언제 어디서나 다양한 서비스를 제공하는 매시브 MTC (Machine Type Communications) 뿐만 아니라 신뢰성 (reliability) 및 지연(latency) 민감한 서비스/UE를 고려한 통신 시스템이 제안되고 있다. 이를"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "위한 다양한 기술 구성들이 제안되고 있다.발명의 내용"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 무선 통신 시스템에서 메타렌즈 인공지능 시스템에 기초하여 신호를 송수신하는 방법 및 장치에 대한 것이다. 본 개시는 무선 통신 시스템에서 사용자 기반 영상 입출력 장치를 고려하여 메타렌즈 인공지능 시스템을 제공하 는 방법 및 장치에 대한 것이다. 본 개시는 무선 통신 시스템에서 사용자 관련 입력 정보를 획득하고, 이에 기초하여 메타렌즈 인공지능 시스템 에서 학습을 통해 영상 입출력 장치를 제어하는 방법에 대한 것이다. 본 개시는 무선 통신 시스템에서 연합학습에 기초하여 메타렌즈 인공지능 시스템을 제어하는 방법에 대한 것이다. 본 개시에서 이루고자 하는 기술적 목적들은 이상에서 언급한 사항들로 제한되지 않으며, 언급하지 않은 또 다"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "른 기술적 과제들은 이하 설명할 본 개시의 실시 예들로부터 본 개시의 기술 구성이 적용되는 기술분야에서 통 상의 지식을 가진 자에 의해 고려될 수 있다."}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 예로서, 무선 통신 시스템에서 기지국 동작 방법에 있어서, 제 1 단말로부터 사용자 인식 정보를 수신하는 단계, 획득된 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하는 단계 및 획득한 제어 값을 제 1 단말 및 제 2 단말로 전송하는 단계를 포함할 수 있다. 또한, 본 개시의 일 예로서, 무선 통신 시스템에서 단말 동작 방법에 있어서, 기지국으로 사용자 인식 정보를 전송하는 단계 및 전달된 사용자 인식 정보에 기초하여 기지국에 의해 도출된 제어 값을 수신하는 단계를 포함 할 수 있다. 또한, 본 개시의 일 예로서, 무선 통신 시스템의 기지국에 있어서, 송수신기 및 송수신기와 연결된 프로세서를 포함하고, 프로세서는, 송수신기를 이용하여 제 1 단말로부터 사용자 인식 정보를 수신하고, 획득된 사용자 인 식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하고, 및 송수신기를 이용하여 획득한 제어 값을 제 1 단말 및 제 2 단말로 전송할 수 있다. 또한, 본 개시의 일 예로서, 송수신기 및 송수신기와 연결된 프로세서를 포함하고, 프로세서는, 송수신기를 이 용하여 기지국으로 사용자 인식 정보를 전송하고, 송수신기를 이용하여 전달된 사용자 인식 정보에 기초하여 기 지국에 의해 도출된 제어 값을 수신할 수 있다. 또한, 본 개시의 일 예로서, 적어도 하나의 메모리 및 적어도 하나의 메모리들과 기능적으로 연결되어 있는 적 어도 하나의 프로세서를 포함하는 장치에 있어서, 적어도 하나의 프로세서는 장치가, 제 1 단말로부터 사용자 인식 정보를 수신하고, 획득된 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하고, 및 획득한 제어 값을 제 1 단말 및 제 2 단말로 전송하도록 제어할 수 있다. 또한, 본 개시의 일 예로서, 적어도 하나의 명령어(instructions)을 저장하는 비-일시적인(non-transitory) 컴 퓨터 판독 가능 매체(computer-readable medium)에 있어서, 프로세서에 의해 실행 가능한(executable) 적어도 하나의 명령어를 포함하며, 적어도 하나의 명령어는, 제 1 단말로부터 사용자 인식 정보를 수신하고, 획득된 사 용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득하고, 및 획득한 제어 값을 제 1 단말 및 제 2 단말로 전송하도록 제어할 수 있다. 다음의 사항들은 상술한 기지국, 단말, 장치 및 컴퓨터 기록 매체에 공통으로 적용될 수 있다. 또한, 본 개시의 일 예로서, 획득되는 제어 값은 메타렌즈 특성인자에 기초하여 코드북 기반으로 결정될 수 있 다. 또한, 본 개시의 일 예로서, 메타렌즈 특성인자는 메타렌즈 요소들 각각에 기초하여 초점 위치 정보, 초점 거리 정보 및 곡률 반경 정보 중 적어도 어느 하나에 기초하여 결정될 수 있다. 또한, 본 개시의 일 예로서, 초점 위치 정보, 초점 거리 정보 및 곡률 반경 정보는 양자화에 기초하여 각각의 인덱스로 표현되고, 제어 값은 각각의 인덱스에 기초하여 도출될 수 있다. 또한, 본 개시의 일 예로서, 사용자 인식 정보는 사용자 방향 정보, 사용자 거리 정보 및 사용자 상태 정보 중 적어도 어느 하나 이상을 포함할 수 있다. 또한, 본 개시의 일 예로서, 제 1 단말은 영상 입력 기능을 구비한 단말이고, 영상 입력 기능에 기초하여 사용 자 인식 정보를 획득할 수 있다. 또한, 본 개시의 일 예로서, 제 1 단말은 제 1 단말의 위치 정보를 획득하고, 제 1 단말의 위치 정보를 사용자 인식 정보와 함께 기지국으로 전달하고, 기지국은 제 1 단말의 위치 정보를 더 고려하여 제어 값을 도출할 수 있다. 또한, 본 개시의 일 예로서, 제 2 단말은 영상 출력 기능을 구비한 단말일 수 있다. 또한, 본 개시의 일 예로서, 기지국은 서버 및 엑세스 포인트(access point) 중 적어도 어느 하나의 기능을 포 함할 수 있다. 또한, 본 개시의 일 예로서, 기지국은 메타렌즈 인공지능 시스템을 구비하고, 메타렌즈 인공지능 시스템은 학습 모델에 기초하여 학습을 수행하되, 획득된 사용자 인식 정보는 학습모델의 입력이고, 제어 값은 학습모델의 출 력일 수 있다. 또한, 본 개시의 일 예로서, 학습모델은 강화학습에 기초하여 동작하고, 강화학습은 획득한 사용자 인식 정보 및 제어 값에 기초하여 상태 정보 및 보상 정보를 입력으로 사용하고, 제어 값에 대응되는 행동 정보를 출력할 수 있다. 또한, 본 개시의 일 예로서, 학습모델은 톰슨 샘플링에 기초하여 동작하고, 톰슨 샘플링은 획득한 사용자 인식 정보 및 제어 값에 기초하여 α 및 β 파라미터를 갖는 보상 정보에 기초하여 학습을 수행할 수 있다."}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 기초한 실시예들에 의해 하기와 같은 효과가 있을 수 있다. 본 개시에 기초한 실시예들에서 메타렌즈 인공지능 시스템에 기초하여 신호를 송수신하는 방법을 제공할 수 있 다. 본 개시에 기초한 실시예들에서 사용자 기반 영상 입출력 장치를 고려하여 메타렌즈 인공지능 시스템을 제공할 수 있다. 본 개시에 기초한 실시예들에서 사용자 관련 입력 정보를 획득하고, 이에 기초하여 메타렌즈 인공지능 시스템에 서 학습을 통해 영상 입출력 장치를 제어할 수 있다. 본 개시에 기초한 실시예들에서 연합학습에 기초하여 메타렌즈 인공지능 시스템을 제어하는 방법을 제공할 수 있다. 본 개시의 실시 예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "다른 효과들은 이하의 본 개시의 실시 예들에 대한 기재로부터 본 개시의 기술 구성이 적용되는 기술분야에서 통상의 지식을 가진 자에게 명확하게 도출되고 이해될 수 있다. 즉, 본 개시에서 서술하는 구성을 실시함에 따른 의도하지 않은 효과들 역시 본 개시의 실시 예들로부터 당해"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "기술분야의 통상의 지식을 가진 자에 의해 도출될 수 있다."}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 실시 예들은 본 개시의 구성요소들과 특징들을 소정 형태로 결합한 것들이다. 각 구성요소 또는 특징은 별도의 명시적 언급이 없는 한 선택적인 것으로 고려될 수 있다. 각 구성요소 또는 특징은 다른 구성요소나 특 징과 결합되지 않은 형태로 실시될 수 있다. 또한, 일부 구성요소들 및/또는 특징들을 결합하여 본 개시의 실시예를 구성할 수도 있다. 본 개시의 실시 예들에서 설명되는 동작들의 순서는 변경될 수 있다. 어느 실시 예의 일부 구성이나 특징은 다른 실시 예에 포함될 수 있고, 또는 다른 실시 예의 대응하는 구성 또는 특징과 교체될 수 있다. 도면에 대한 설명에서, 본 개시의 요지를 흐릴 수 있는 절차 또는 단계 등은 기술하지 않았으며, 당업자의 수준 에서 이해할 수 있을 정도의 절차 또는 단계는 또한 기술하지 아니하였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함(comprising 또는 including)\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미 한다. 또한, 명세서에 기재된 \"...부\", \"...기\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, \"일(a 또는 an)\", \"하나(one)\", \"그(the)\" 및 유사 관련어는 본 개시를 기술하는 문맥에 있어서(특히, 이하의 청구항의 문맥에서) 본 명세서에 달리 지시되거나 문맥에 의해 분명하게 반박되지 않는 한, 단수 및 복수 모두 를 포함하는 의미로 사용될 수 있다. 본 명세서에서 본 개시의 실시예들은 기지국과 이동국 간의 데이터 송수신 관계를 중심으로 설명되었다. 여기서, 기지국은 이동국과 직접적으로 통신을 수행하는 네트워크의 종단 노드(terminal node)로서의 의미가 있 다. 본 문서에서 기지국에 의해 수행되는 것으로 설명된 특정 동작은 경우에 따라서는 기지국의 상위 노드 (upper node)에 의해 수행될 수도 있다. 즉, 기지국을 포함하는 다수의 네트워크 노드들(network nodes)로 이루어지는 네트워크에서 이동국과의 통신을 위해 수행되는 다양한 동작들은 기지국 또는 기지국 이외의 다른 네트워크 노드들에 의해 수행될 수 있다. 이때, '기지국'은 고정국(fixed station), Node B, eNB(eNode B), gNB(gNode B), ng-eNB, 발전된 기지국 (advanced base station, ABS) 또는 억세스 포인트(access point) 등의 용어에 의해 대체될 수 있다. 또한, 본 개시의 실시 예들에서 단말(terminal)은 사용자 기기(user equipment, UE), 이동국(mobile station, MS), 가입자국(subscriber station, SS), 이동 가입자 단말(mobile subscriber station, MSS), 이동 단말 (mobile terminal) 또는 발전된 이동 단말(advanced mobile station, AMS) 등의 용어로 대체될 수 있다. 또한, 송신단은 데이터 서비스 또는 음성 서비스를 제공하는 고정 및/또는 이동 노드를 말하고, 수신단은 데이 터 서비스 또는 음성 서비스를 수신하는 고정 및/또는 이동 노드를 의미한다. 따라서, 상향링크의 경우, 이동국 이 송신단이 되고, 기지국이 수신단이 될 수 있다. 마찬가지로, 하향링크의 경우, 이동국이 수신단이 되고, 기 지국이 송신단이 될 수 있다. 본 개시의 실시 예들은 무선 접속 시스템들인 IEEE 802.xx 시스템, 3GPP(3rd Generation Partnership Project) 시스템, 3GPP LTE(Long Term Evolution) 시스템, 3GPP 5G(5th generation) NR(New Radio) 시스템 및 3GPP2 시 스템 중 적어도 하나에 개시된 표준 문서들에 의해 뒷받침될 수 있으며, 특히, 본 개시의 실시 예들은 3GPP TS(technical specification) 38.211, 3GPP TS 38.212, 3GPP TS 38.213, 3GPP TS 38.321 및 3GPP TS 38.331 문서들에 의해 뒷받침 될 수 있다. 또한, 본 개시의 실시 예들은 다른 무선 접속 시스템에도 적용될 수 있으며, 상술한 시스템으로 한정되는 것은 아니다. 일 예로, 3GPP 5G NR 시스템 이후에 적용되는 시스템에 대해서도 적용 가능할 수 있으며, 특정 시스템 에 한정되지 않는다. 즉, 본 개시의 실시 예들 중 설명하지 않은 자명한 단계들 또는 부분들은 상기 문서들을 참조하여 설명될 수 있 다. 또한, 본 문서에서 개시하고 있는 모든 용어들은 상기 표준 문서에 의해 설명될 수 있다. 이하, 본 개시에 따른 바람직한 실시 형태를 첨부된 도면을 참조하여 상세하게 설명한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시 형태를 설명하고자 하는 것이며, 본 개시의 기술 구성이 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 또한, 본 개시의 실시 예들에서 사용되는 특정 용어들은 본 개시의 이해를 돕기 위해서 제공된 것이며, 이러한 특정 용어의 사용은 본 개시의 기술적 사상을 벗어나지 않는 범위에서 다른 형태로 변경될 수 있다. 이하의 기술은 CDMA(code division multiple access), FDMA(frequency division multiple access), TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access), SC-FDMA(single carrier frequency division multiple access) 등과 같은 다양한 무선 접속 시스템에 적용될 수 있다.하기에서는 이하 설명을 명확하게 하기 위해, 3GPP 통신 시스템(e.g.(예, LTE, NR 등)을 기반으로 설명하지만 본 발명의 기술적 사상이 이에 제한되는 것은 아니다. LTE는 3GPP TS 36.xxx Release 8 이후의 기술을 의미할 수 있다. 세부적으로, 3GPP TS 36.xxx Release 10 이후의 LTE 기술은 LTE-A로 지칭되고, 3GPP TS 36.xxx Release 13 이후의 LTE 기술은 LTE-A pro로 지칭될 수 있다. 3GPP NR은 TS 38.xxx Release 15 이후의 기술을 의미할 수 있다. 3GPP 6G는 TS Release 17 및/또는 Release 18 이후의 기술을 의미할 수 있다. \"xxx\"는 표준 문서 세부 번호를 의미한다. LTE/NR/6G는 3GPP 시스템으로 통칭될 수 있다."}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 개시에 사용된 배경기술, 용어, 약어 등에 관해서는 본 발명 이전에 공개된 표준 문서에 기재된 사항을 참조 할 수 있다. 일 예로, 36.xxx 및 38.xxx 표준 문서를 참조할 수 있다. 본 개시에 적용 가능한 통신 시스템 이로 제한되는 것은 아니지만, 본 문서에 개시된 본 개시의 다양한 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들은 기기들 간에 무선 통신/연결(예, 5G)을 필요로 하는 다양한 분야에 적용될 수 있다. 이하, 도면을 참조하여 보다 구체적으로 예시한다. 이하의 도면/설명에서 동일한 도면 부호는 다르게 기술하지 않는 한, 동일하거나 대응되는 하드웨어 블록, 소프트웨어 블록 또는 기능 블록을 예시할 수 있다. 도 1은 본 개시에 적용되는 통신 시스템 예시를 도시한 도면이다. 도 1을 참조하면, 본 개시에 적용되는 통신 시스템은 무선 기기, 기지국 및 네트워크를 포함한다. 여기서, 무선 기기는 무선 접속 기술(예, 5G NR, LTE)을 이용하여 통신을 수행하는 기기를 의미하며, 통신/무선/5G 기기 로 지칭될 수 있다. 이로 제한되는 것은 아니지만, 무선 기기는 로봇(100a), 차량(100b-1, 100b-2), XR(extended reality) 기기(100c), 휴대 기기(hand-held device)(100d), 가전(home appliance)(100e), IoT(Internet of Thing) 기기(100f), AI(artificial intelligence) 기기/서버(100g)를 포함할 수 있다. 예를 들어, 차량은 무선 통신 기능이 구비된 차량, 자율 주행 차량, 차량간 통신을 수행할 수 있는 차량 등을 포함할 수 있다. 여기서, 차량(100b-1, 100b-2)은 UAV(unmanned aerial vehicle)(예, 드론)를 포함할 수 있다. XR 기 기(100c)는 AR(augmented reality)/VR(virtual reality)/MR(mixed reality) 기기를 포함하며, HMD(head- mounted device), 차량에 구비된 HUD(head-up display), 텔레비전, 스마트폰, 컴퓨터, 웨어러블 디바이스, 가 전 기기, 디지털 사이니지(signage), 차량, 로봇 등의 형태로 구현될 수 있다. 휴대 기기(100d)는 스마트폰, 스 마트패드, 웨어러블 기기(예, 스마트워치, 스마트글래스), 컴퓨터(예, 노트북 등) 등을 포함할 수 있다. 가전 (100e)은 TV, 냉장고, 세탁기 등을 포함할 수 있다. IoT 기기(100f)는 센서, 스마트 미터 등을 포함할 수 있다. 예를 들어, 기지국, 네트워크는 무선 기기로도 구현될 수 있으며, 특정 무선 기기(120a)는 다른 무선 기기에게 기지국/네트워크 노드로 동작할 수도 있다. 무선 기기(100a~100f)는 기지국을 통해 네트워크와 연결될 수 있다. 무선 기기(100a~100f)에는 AI 기술이 적용될 수 있으며, 무선 기기(100a~100f)는 네트워크를 통해 AI 서버(100g)와 연결될 수 있다. 네 트워크는 3G 네트워크, 4G(예, LTE) 네트워크 또는 5G(예, NR) 네트워크 등을 이용하여 구성될 수 있다. 무선 기기(100a~100f)는 기지국/네트워크를 통해 서로 통신할 수도 있지만, 기지국/네트워크 를 통하지 않고 직접 통신(예, 사이드링크 통신(sidelink communication))할 수도 있다. 예를 들어, 차량 들(100b-1, 100b-2)은 직접 통신(예, V2V(vehicle to vehicle)/V2X(vehicle to everything) communication)을 할 수 있다. 또한, IoT 기기(100f)(예, 센서)는 다른 IoT 기기(예, 센서) 또는 다른 무선 기기(100a~100f)와 직접 통신을 할 수 있다. 본 개시에 적용 가능한 통신 시스템 도 2는 본 개시에 적용될 수 있는 무선 기기의 예시를 도시한 도면이다. 도 2를 참조하면, 제1 무선 기기(200a)와 제2 무선 기기(200b)는 다양한 무선 접속 기술(예, LTE, NR)을 통해 무선 신호를 송수신할 수 있다. 여기서, {제1 무선 기기(200a), 제2 무선 기기(200b)}은 도 1의 {무선 기기 (100x), 기지국} 및/또는 {무선 기기(100x), 무선 기기(100x)}에 대응할 수 있다. 제1 무선 기기(200a)는 하나 이상의 프로세서(202a) 및 하나 이상의 메모리(204a)를 포함하며, 추가적으로 하나 이상의 송수신기(206a) 및/또는 하나 이상의 안테나(208a)을 더 포함할 수 있다. 프로세서(202a)는 메모리 (204a) 및/또는 송수신기(206a)를 제어하며, 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순 서도들을 구현하도록 구성될 수 있다. 예를 들어, 프로세서(202a)는 메모리(204a) 내의 정보를 처리하여 제1 정 보/신호를 생성한 뒤, 송수신기(206a)을 통해 제1 정보/신호를 포함하는 무선 신호를 전송할 수 있다. 또한, 프로세서(202a)는 송수신기(206a)를 통해 제2 정보/신호를 포함하는 무선 신호를 수신한 뒤, 제2 정보/신호의 신 호 처리로부터 얻은 정보를 메모리(204a)에 저장할 수 있다. 메모리(204a)는 프로세서(202a)와 연결될 수 있고, 프로세서(202a)의 동작과 관련한 다양한 정보를 저장할 수 있다. 예를 들어, 메모리(204a)는 프로세서(202a)에 의해 제어되는 프로세스들 중 일부 또는 전부를 수행하거나, 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들을 수행하기 위한 명령들을 포함하는 소프트웨어 코드를 저장할 수 있다. 여기서, 프로세 서(202a)와 메모리(204a)는 무선 통신 기술(예, LTE, NR)을 구현하도록 설계된 통신 모뎀/회로/칩의 일부일 수 있다. 송수신기(206a)는 프로세서(202a)와 연결될 수 있고, 하나 이상의 안테나(208a)를 통해 무선 신호를 송신 및/또는 수신할 수 있다. 송수신기(206a)는 송신기 및/또는 수신기를 포함할 수 있다. 송수신기(206a)는 RF(radio frequency) 유닛과 혼용될 수 있다. 본 개시에서 무선 기기는 통신 모뎀/회로/칩을 의미할 수도 있다. 제2 무선 기기(200b)는 하나 이상의 프로세서(202b), 하나 이상의 메모리(204b)를 포함하며, 추가적으로 하나 이상의 송수신기(206b) 및/또는 하나 이상의 안테나(208b)를 더 포함할 수 있다. 프로세서(202b)는 메모리 (204b) 및/또는 송수신기(206b)를 제어하며, 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순 서도들을 구현하도록 구성될 수 있다. 예를 들어, 프로세서(202b)는 메모리(204b) 내의 정보를 처리하여 제3 정 보/신호를 생성한 뒤, 송수신기(206b)를 통해 제3 정보/신호를 포함하는 무선 신호를 전송할 수 있다. 또한, 프 로세서(202b)는 송수신기(206b)를 통해 제4 정보/신호를 포함하는 무선 신호를 수신한 뒤, 제4 정보/신호의 신 호 처리로부터 얻은 정보를 메모리(204b)에 저장할 수 있다. 메모리(204b)는 프로세서(202b)와 연결될 수 있고, 프로세서(202b)의 동작과 관련한 다양한 정보를 저장할 수 있다. 예를 들어, 메모리(204b)는 프로세서(202b)에 의해 제어되는 프로세스들 중 일부 또는 전부를 수행하거나, 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들을 수행하기 위한 명령들을 포함하는 소프트웨어 코드를 저장할 수 있다. 여기서, 프로세 서(202b)와 메모리(204b)는 무선 통신 기술(예, LTE, NR)을 구현하도록 설계된 통신 모뎀/회로/칩의 일부일 수 있다. 송수신기(206b)는 프로세서(202b)와 연결될 수 있고, 하나 이상의 안테나(208b)를 통해 무선 신호를 송신 및/또는 수신할 수 있다. 송수신기(206b)는 송신기 및/또는 수신기를 포함할 수 있다 송수신기(206b)는 RF 유닛 과 혼용될 수 있다. 본 개시에서 무선 기기는 통신 모뎀/회로/칩을 의미할 수도 있다. 이하, 무선 기기(200a, 200b)의 하드웨어 요소에 대해 보다 구체적으로 설명한다. 이로 제한되는 것은 아니지만, 하나 이상의 프로토콜 계층이 하나 이상의 프로세서(202a, 202b)에 의해 구현될 수 있다. 예를 들어, 하나 이상의 프로세서(202a, 202b)는 하나 이상의 계층(예, PHY(physical), MAC(media access control), RLC(radio link control), PDCP(packet data convergence protocol), RRC(radio resource control), SDAP(service data adaptation protocol)와 같은 기능적 계층)을 구현할 수 있다. 하나 이상의 프로세서(202a, 202b)는 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들에 따라 하나 이상의 PDU(Protocol Data Unit) 및/또는 하나 이상의 SDU(service data unit)를 생성할 수 있다. 하나 이상의 프로세 서(202a, 202b)는 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들에 따라 메시지, 제어 정보, 데이터 또는 정보를 생성할 수 있다. 하나 이상의 프로세서(202a, 202b)는 본 문서에 개시된 기능, 절차, 제안 및/또는 방법에 따라 PDU, SDU, 메시지, 제어정보, 데이터 또는 정보를 포함하는 신호(예, 베이스밴드 신 호)를 생성하여, 하나 이상의 송수신기(206a, 206b)에게 제공할 수 있다. 하나 이상의 프로세서(202a, 202b)는 하나 이상의 송수신기(206a, 206b)로부터 신호(예, 베이스밴드 신호)를 수신할 수 있고, 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들에 따라 PDU, SDU, 메시지, 제어정보, 데이터 또는 정보를 획득할 수 있다. 하나 이상의 프로세서(202a, 202b)는 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 또는 마이크로 컴퓨터로 지칭될 수 있다. 하나 이상의 프로세서(202a, 202b)는 하드웨어, 펌웨어, 소프트웨어, 또는 이들의 조합에 의해 구현될 수 있다. 일 예로, 하나 이상의 ASIC(application specific integrated circuit), 하나 이상의 DSP(digital signal processor), 하나 이상의 DSPD(digital signal processing device), 하나 이상의 PLD(programmable logic device) 또는 하나 이상의 FPGA(field programmable gate arrays)가 하나 이상의 프로 세서(202a, 202b)에 포함될 수 있다. 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들은 펌웨어 또는 소프트웨어를 사용하여 구현될 수 있고, 펌웨어 또는 소프트웨어는 모듈, 절차, 기능 등을 포함하 도록 구현될 수 있다. 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도들은 수행하도록 설 정된 펌웨어 또는 소프트웨어는 하나 이상의 프로세서(202a, 202b)에 포함되거나, 하나 이상의 메모리(204a, 204b)에 저장되어 하나 이상의 프로세서(202a, 202b)에 의해 구동될 수 있다. 본 문서에 개시된 설명, 기능, 절 차, 제안, 방법 및/또는 동작 순서도들은 코드, 명령어 및/또는 명령어의 집합 형태로 펌웨어 또는 소프트웨어 를 사용하여 구현될 수 있다. 하나 이상의 메모리(204a, 204b)는 하나 이상의 프로세서(202a, 202b)와 연결될 수 있고, 다양한 형태의 데이터, 신호, 메시지, 정보, 프로그램, 코드, 지시 및/또는 명령을 저장할 수 있다. 하나 이상의 메모리(204a, 204b)는 ROM(read only memory), RAM(random access memory), EPROM(erasable programmable read only memory), 플래시 메모리, 하드 드라이브, 레지스터, 캐쉬 메모리, 컴퓨터 판독 저장 매체 및/또는 이들의 조합 으로 구성될 수 있다. 하나 이상의 메모리(204a, 204b)는 하나 이상의 프로세서(202a, 202b)의 내부 및/또는 외 부에 위치할 수 있다. 또한, 하나 이상의 메모리(204a, 204b)는 유선 또는 무선 연결과 같은 다양한 기술을 통 해 하나 이상의 프로세서(202a, 202b)와 연결될 수 있다. 하나 이상의 송수신기(206a, 206b)는 하나 이상의 다른 장치에게 본 문서의 방법들 및/또는 동작 순서도 등에서 언급되는 사용자 데이터, 제어 정보, 무선 신호/채널 등을 전송할 수 있다. 하나 이상의 송수신기(206a, 206b) 는 하나 이상의 다른 장치로부터 본 문서에 개시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도 등에서 언급되는 사용자 데이터, 제어 정보, 무선 신호/채널 등을 수신할 수 있다. 예를 들어, 하나 이상의 송수신기 (206a, 206b)는 하나 이상의 프로세서(202a, 202b)와 연결될 수 있고, 무선 신호를 송수신할 수 있다. 예를 들 어, 하나 이상의 프로세서(202a, 202b)는 하나 이상의 송수신기(206a, 206b)가 하나 이상의 다른 장치에게 사용 자 데이터, 제어 정보 또는 무선 신호를 전송하도록 제어할 수 있다. 또한, 하나 이상의 프로세서(202a, 202b) 는 하나 이상의 송수신기(206a, 206b)가 하나 이상의 다른 장치로부터 사용자 데이터, 제어 정보 또는 무선 신 호를 수신하도록 제어할 수 있다. 또한, 하나 이상의 송수신기(206a, 206b)는 하나 이상의 안테나(208a, 208b) 와 연결될 수 있고, 하나 이상의 송수신기(206a, 206b)는 하나 이상의 안테나(208a, 208b)를 통해 본 문서에 개 시된 설명, 기능, 절차, 제안, 방법 및/또는 동작 순서도 등에서 언급되는 사용자 데이터, 제어 정보, 무선 신 호/채널 등을 송수신하도록 설정될 수 있다. 본 문서에서, 하나 이상의 안테나는 복수의 물리 안테나이거나, 복 수의 논리 안테나(예, 안테나 포트)일 수 있다. 하나 이상의 송수신기(206a, 206b)는 수신된 사용자 데이터, 제 어 정보, 무선 신호/채널 등을 하나 이상의 프로세서(202a, 202b)를 이용하여 처리하기 위해, 수신된 무선 신호 /채널 등을 RF 밴드 신호에서 베이스밴드 신호로 변환(Convert)할 수 있다. 하나 이상의 송수신기(206a, 206b) 는 하나 이상의 프로세서(202a, 202b)를 이용하여 처리된 사용자 데이터, 제어 정보, 무선 신호/채널 등을 베이 스밴드 신호에서 RF 밴드 신호로 변환할 수 있다. 이를 위하여, 하나 이상의 송수신기(206a, 206b)는 (아날로그) 오실레이터 및/또는 필터를 포함할 수 있다. 본 개시에 적용 가능한 무선 기기 구조 도 3은 본 개시에 적용되는 무선 기기의 다른 예시를 도시한 도면이다. 도 3을 참조하면, 무선 기기는 도 2의 무선 기기(200a, 200b)에 대응하며, 다양한 요소(element), 성분 (component), 유닛/부(unit), 및/또는 모듈(module)로 구성될 수 있다. 예를 들어, 무선 기기는 통신부 , 제어부, 메모리부 및 추가 요소를 포함할 수 있다. 통신부는 통신 회로 및 송수신 기(들)을 포함할 수 있다. 예를 들어, 통신 회로는 도 2의 하나 이상의 프로세서(202a, 202b) 및/또 는 하나 이상의 메모리(204a, 204b)를 포함할 수 있다. 예를 들어, 송수신기(들)는 도 2의 하나 이상의 송 수신기(206a, 206b) 및/또는 하나 이상의 안테나(208a, 208b)을 포함할 수 있다. 제어부는 통신부, 메모리부 및 추가 요소와 전기적으로 연결되며 무선 기기의 제반 동작을 제어한다. 예를 들어, 제어 부는 메모리부에 저장된 프로그램/코드/명령/정보에 기반하여 무선 기기의 전기적/기계적 동작을 제 어할 수 있다. 또한, 제어부는 메모리부에 저장된 정보를 통신부을 통해 외부(예, 다른 통신 기 기)로 무선/유선 인터페이스를 통해 전송하거나, 통신부를 통해 외부(예, 다른 통신 기기)로부터 무선/유 선 인터페이스를 통해 수신된 정보를 메모리부에 저장할 수 있다. 추가 요소는 무선 기기의 종류에 따라 다양하게 구성될 수 있다. 예를 들어, 추가 요소는 파워 유닛/ 배터리, 입출력부(input/output unit), 구동부 및 컴퓨팅부 중 적어도 하나를 포함할 수 있다. 이로 제한되는 것은 아니지만, 무선 기기는 로봇(도 1, 100a), 차량(도 1, 100b-1, 100b-2), XR 기기(도 1, 100c), 휴대 기기(도 1, 100d), 가전(도 1, 100e), IoT 기기(도 1, 100f), 디지털 방송용 단말, 홀로그램 장치, 공공 안전 장치, MTC 장치, 의료 장치, 핀테크 장치(또는 금융 장치), 보안 장치, 기후/환경 장치, AI 서버/기기(도 1, 140), 기지국(도 1, 120), 네트워크 노드 등의 형태로 구현될 수 있다. 무선 기기는 사용-예/서비스에 따라 이 동 가능하거나 고정된 장소에서 사용될 수 있다. 도 3에서 무선 기기 내의 다양한 요소, 성분, 유닛/부, 및/또는 모듈은 전체가 유선 인터페이스를 통해 상 호 연결되거나, 적어도 일부가 통신부를 통해 무선으로 연결될 수 있다. 예를 들어, 무선 기기 내에 서 제어부와 통신부는 유선으로 연결되며, 제어부와 제1 유닛(예, 130, 140)은 통신부를통해 무선으로 연결될 수 있다. 또한, 무선 기기 내의 각 요소, 성분, 유닛/부, 및/또는 모듈은 하나 이상 의 요소를 더 포함할 수 있다. 예를 들어, 제어부는 하나 이상의 프로세서 집합으로 구성될 수 있다. 예를 들어, 제어부는 통신 제어 프로세서, 어플리케이션 프로세서(application processor), ECU(electronic control unit), 그래픽 처리 프로세서, 메모리 제어 프로세서 등의 집합으로 구성될 수 있다. 다른 예로, 메모 리부는 RAM, DRAM(dynamic RAM), ROM, 플래시 메모리(flash memory), 휘발성 메모리(volatile memory), 비-휘발성 메모리(non-volatile memory) 및/또는 이들의 조합으로 구성될 수 있다. 도 4는 본 개시에 적용되는 AI 기기의 예시를 도시한 도면이다. 일 예로, AI 기기는 TV, 프로젝터, 스마트폰, PC, 노트북, 디지털방송용 단말기, 태블릿 PC, 웨어러블 장치, 셋톱박스(STB), 라디오, 세탁기, 냉장고, 디지털 사이니지, 로봇, 차량 등과 같은, 고정형 기기 또는 이동 가능한 기기 등으로 구현될 수 있다. 도 4를 참조하면, AI 기기는 통신부, 제어부, 메모리부, 입/출력부(640a/640b), 러닝 프 로세서부(640c) 및 센서부(640d)를 포함할 수 있다. 블록 910~930/940a~940d는 각각 도 3의 블록 310~330/340 에 대응할 수 있다. 통신부는 유무선 통신 기술을 이용하여 다른 AI 기기(예, 도 1, 100x, 120, 140)나 AI 서버(도 1, 140) 등의 외부 기기들과 유무선 신호(예, 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등)를 송수신할 수 있다. 이를 위해, 통신부는 메모리부 내의 정보를 외부 기기로 전송하거나, 외부 기기로부터 수신된 신호를 메모리부로 전달할 수 있다. 제어부는 데이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하여, AI 기기의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 제어부는 AI 기기의 구 성 요소들을 제어하여 결정된 동작을 수행할 수 있다. 예를 들어, 제어부는 러닝 프로세서부(640c) 또는 메모리부의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 적어도 하나의 실행 가능한 동작 중 예측되 는 동작이나, 바람직한 것으로 판단되는 동작을 실행하도록 AI 기기의 구성 요소들을 제어할 수 있다. 또 한, 제어부는 AI 장치의 동작 내용이나 동작에 대한 사용자의 피드백 등을 포함하는 이력 정보를 수 집하여 메모리부 또는 러닝 프로세서부(640c)에 저장하거나, AI 서버(도 1, 140) 등의 외부 장치에 전송할 수 있다. 수집된 이력 정보는 학습 모델을 갱신하는데 이용될 수 있다. 메모리부는 AI 기기의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 예를 들어, 메모리부 는 입력부(640a)로부터 얻은 데이터, 통신부로부터 얻은 데이터, 러닝 프로세서부(640c)의 출력 데이터, 및 센싱부로부터 얻은 데이터를 저장할 수 있다. 또한, 메모리부는 제어부의 동작/실행에 필요 한 제어 정보 및/또는 소프트웨어 코드를 저장할 수 있다. 입력부(640a)는 AI 기기의 외부로부터 다양한 종류의 데이터를 획득할 수 있다. 예를 들어, 입력부는 모델 학습을 위한 학습 데이터, 및 학습 모델이 적용될 입력 데이터 등을 획득할 수 있다. 입력부(640a)는 카메 라, 마이크로폰 및/또는 사용자 입력부 등을 포함할 수 있다. 출력부(640b)는 시각, 청각 또는 촉각 등과 관련 된 출력을 발생시킬 수 있다. 출력부(640b)는 디스플레이부, 스피커 및/또는 햅틱 모듈 등을 포함할 수 있다. 센싱부는 다양한 센서들을 이용하여 AI 기기의 내부 정보, AI 기기의 주변 환경 정보 및 사용자 정보 중 적어도 하나를 얻을 수 있다. 센싱부는 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰 및/또는 레이더 등을 포함할 수 있다. 러닝 프로세서부(640c)는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 러닝 프로 세서부(640c)는 AI 서버(도 1, 140)의 러닝 프로세서부와 함께 AI 프로세싱을 수행할 수 있다. 러닝 프로세서부 (640c)는 통신부를 통해 외부 기기로부터 수신된 정보, 및/또는 메모리부에 저장된 정보를 처리할 수 있다. 또한, 러닝 프로세서부(940c)의 출력 값은 통신부를 통해 외부 기기로 전송되거나/되고, 메모리부 에 저장될 수 있다. 6G 통신 시스템 6G (무선통신) 시스템은 (i) 디바이스 당 매우 높은 데이터 속도, (ii) 매우 많은 수의 연결된 디바이스들, (iii) 글로벌 연결성(global connectivity), (iv) 매우 낮은 지연, (v) 배터리-프리(battery-free) IoT 디바이 스들의 에너지 소비를 낮추고, (vi) 초고신뢰성 연결, (vii) 머신 러닝 능력을 가지는 연결된 지능 등에 목적이 있다. 6G 시스템의 비젼은 “intelligent connectivity”, “deep connectivity”, “holographic connectivity”, “ubiquitous connectivity”와 같은 4가지 측면일 수 있으며, 6G 시스템은 하기 표 1과 같은요구 사항을 만족시킬 수 있다. 즉, 표 1은 6G 시스템의 요구 사항을 나타낸 표이다. 표 1"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때, 6G 시스템은 향상된 모바일 브로드밴드(enhanced mobile broadband, eMBB), 초-저지연 통신(ultra- reliable low latency communications, URLLC), mMTC (massive machine type communications), AI 통합 통신 (AI integrated communication), 촉각 인터넷(tactile internet), 높은 스루풋(high throughput), 높은 네트워 크 능력(high network capacity), 높은 에너지 효율(high energy efficiency), 낮은 백홀 및 접근 네트워크 혼 잡(low backhaul and access network congestion) 및 향상된 데이터 보안(enhanced data security)과 같은 핵 심 요소(key factor)들을 가질 수 있다. 인공 지능(artificial Intelligence, AI) 6G 시스템에 가장 중요하며, 새로 도입될 기술은 AI이다. 4G 시스템에는 AI가 관여하지 않았다. 5G 시스템은 부 분 또는 매우 제한된 AI를 지원할 것이다. 그러나, 6G 시스템은 완전히 자동화를 위해 AI가 지원될 것이다. 머 신 러닝의 발전은 6G에서 실시간 통신을 위해 보다 지능적인 네트워크를 만들 것이다. 통신에 AI를 도입하면 실 시간 데이터 전송이 간소화되고 향상될 수 있다. AI는 수많은 분석을 사용하여 복잡한 대상 작업이 수행되는 방 식을 결정할 수 있다. 즉, AI는 효율성을 높이고 처리 지연을 줄일 수 있다. 핸드 오버, 네트워크 선택, 자원 스케줄링과 같은 시간 소모적인 작업은 AI를 사용함으로써 즉시 수행될 수 있 다. AI는 M2M, 기계-대-인간 및 인간-대-기계 통신에서도 중요한 역할을 할 수 있다. 또한, AI는 BCI(brain computer interface)에서 신속한 통신이 될 수 있다. AI 기반 통신 시스템은 메타 물질, 지능형 구조, 지능형 네트워크, 지능형 장치, 지능형 인지 라디오(radio), 자체 유지 무선 네트워크 및 머신 러닝에 의해 지원될 수 있다. 최근 AI를 무선 통신 시스템과 통합하려고 하는 시도들이 나타나고 있으나, 이는 어플리케이션 계층 (application layer), 네트워크 계층(network layer) 특히, 딥 러닝은 무선 자원 관리 및 할당(wireless resource management and allocation) 분야에 집중되어 왔다. 그러나, 이러한 연구는 점점 MAC 계층 및 물리 계층으로 발전하고 있으며, 특히 물리계층에서 딥 러닝을 무선 전송(wireless transmission)과 결합하고자 하는 시도들이 나타나고 있다. AI 기반의 물리계층 전송은, 근본적인 신호 처리 및 통신 메커니즘에 있어서, 전통적 인 통신 프레임워크가 아니라 AI 드라이버에 기초한 신호 처리 및 통신 메커니즘을 적용하는 것을 의미한다. 예 를 들어, 딥러닝 기반의 채널 코딩 및 디코딩(channel coding and decoding), 딥러닝 기반의 신호 추정 (estimation) 및 검출(detection), 딥러닝 기반의 MIMO(multiple input multiple output) 매커니즘 (mechanism), AI 기반의 자원 스케줄링(scheduling) 및 할당(allocation) 등을 포함할 수 있다. 또한, 머신 러닝은 채널 추정 및 채널 트래킹을 위해 사용될 수 있으며, DL(downlink)의 물리 계층(physical layer)에서 전력 할당(power allocation), 간섭 제거(interference cancellation) 등에 사용될 수 있다. 또한, 머신 러닝은 MIMO 시스템에서 안테나 선택, 전력 제어(power control), 심볼 검출(symbol detection) 등에도 사용될 수 있다. 그러나 물리계층에서의 전송을 위한 DNN의 적용은 아래와 같은 문제점이 있을 수 있다. 딥러닝 기반의 AI 알고리즘은 훈련 파라미터를 최적화하기 위해 수많은 훈련 데이터가 필요하다. 그러나 특정 채널 환경에서의 데이터를 훈련 데이터로 획득하는데 있어서의 한계로 인해, 오프라인 상에서 많은 훈련 데이터를 사용한다. 이는 특정 채널 환경에서 훈련 데이터에 대한 정적 훈련(static training)은, 무선 채널의 동적 특성 및 다이버시티(diversity) 사이에 모순(contradiction)이 생길 수 있다. 또한, 현재 딥 러닝은 주로 실제 신호(real signal)을 대상으로 한다. 그러나, 무선 통신의 물리 계층의 신호들 은 복소 신호(complex signal)이다. 무선 통신 신호의 특성을 매칭시키기 위해 복소(complex) 도메인 신호의 검 출하는 신경망(neural network)에 대한 연구가 더 필요하다. 이하, 머신 러닝에 대해 보다 구체적으로 살펴본다. 머신 러닝은 사람이 할 수 있거나 혹은 하기 어려운 작업을 대신해낼 수 있는 기계를 만들어 내기 위해 기계를 학습시키는 일련의 동작을 의미한다. 머신 러닝을 위해서는 데이터와 러닝 모델이 필요하다. 머신 러닝에서 데 이터의 학습 방법은 크게 3가지 즉, 지도 학습(supervised learning), 비지도 학습(unsupervised learning) 그 리고 강화 학습(reinforcement learning)으로 구분될 수 있다. 신경망 학습은 출력의 오류를 최소화하기 위한 것이다. 신경망 학습은 반복적으로 학습 데이터를 신경망에 입력 시키고 학습 데이터에 대한 신경망의 출력과 타겟의 에러를 계산하고, 에러를 줄이기 위한 방향으로 신경망의 에러를 신경망의 출력 레이어에서부터 입력 레이어 방향으로 역전파(backpropagation) 하여 신경망의 각 노드의 가중치를 업데이트하는 과정이다. 지도 학습은 학습 데이터에 정답이 라벨링된 학습 데이터를 사용하며 비지도 학습은 학습 데이터에 정답이 라벨 링되어 있지 않을 수 있다. 즉, 예를 들어 데이터 분류에 관한 지도 학습의 경우의 학습 데이터는 학습 데이터 각각에 카테고리가 라벨링된 데이터 일 수 있다. 라벨링된 학습 데이터가 신경망에 입력되고 신경망의 출력(카 테고리)과 학습 데이터의 라벨을 비교하여 오차(error)가 계산될 수 있다. 계산된 오차는 신경망에서 역방향(즉, 출력 레이어에서 입력 레이어 방향)으로 역전파 되며, 역전파에 따라 신경망의 각 레이어의 각 노드 들의 연결 가중치가 업데이트 될 수 있다. 업데이트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따 라 변화량이 결정될 수 있다. 입력 데이터에 대한 신경망의 계산과 에러의 역전파는 학습 사이클(epoch)을 구성 할 수 있다. 학습률은 신경망의 학습 사이클의 반복 횟수에 따라 상이하게 적용될 수 있다. 예를 들어, 신경망 의 학습 초기에는 높은 학습률을 사용하여 신경망이 빠르게 일정 수준의 성능을 확보하도록 하여 효율성을 높이 고, 학습 후기에는 낮은 학습률을 사용하여 정확도를 높일 수 있다 데이터의 특징에 따라 학습 방법은 달라질 수 있다. 예를 들어, 통신 시스템 상에서 송신단에서 전송한 데이터 를 수신단에서 정확하게 예측하는 것을 목적으로 하는 경우, 비지도 학습 또는 강화 학습 보다는 지도 학습을 이용하여 학습을 수행하는 것이 바람직하다. 러닝 모델은 인간의 뇌에 해당하는 것으로서, 가장 기본적인 선형 모델을 생각할 수 있으나, 인공 신경망 (artificial neural networks)와 같은 복잡성이 높은 신경망 구조를 러닝 모델로 사용하는 머신 러닝의 패러다 임을 딥러닝(deep learning)이라 한다. 학습(learning) 방식으로 사용하는 신경망 코어(neural network cord)는 크게 심층 신경망(deep neural networks, DNN), 합성곱 신경망(convolutional deep neural networks, CNN), 순환 신경망(recurrent boltzmann machine, RNN) 방식이 있으며, 이러한 러닝 모델이 적용될 수 있다. 하기에서는 상술한 바에 기초하여 인공지능 또는 connected intelligence에 기초하여 영상 입력장치(e.g. 카메 라)와 영상 출력장치를 메타렌즈를 통해서 유기적으로 동작시키는 방법에 대해 서술한다. 일 예로, 영상 입력장 치 및 영상 출력장치는 다양한 환경에서 연합학습을 통해 인공지능 시스템을 효과적으로 적용할 수 있으며, 하 기에서는 이에 대해 서술한다. 일 예로, 하기에서 서술하는 용어로써 OIS(Optical Image Stabilizer)는 영상 이 미지 안정화 장치를 의미할 수 있다. 일 예로, OIS는 카메라의 손떨림 방지 기능일 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 일 예로, 연합학습(Federated Learning)은 데이터 샘플을 교환하지 않고 로컬 데이터 샘플을 보유하는 여러 장치 또는 서버에서 알고리즘을 훈련시키는 학습 방식을 의미할 수 있다. 이때, 연합학습 방식은 복수 개의 장치가 데이터를 공유하지 않고, 공통의 강력한 기계 학습 모델을 구축 할 수 있다. 따라서, 연합학습은 데이터 개인 정보 보호, 데이터 보안, 데이터 액세스 권한 및 이기종 데이터 액세스와 같은 중요한 문제를 해결할 수 있다. 또한, 일 예로, 연합학습을 위한 동작으로 복수 개의 장치들은 로컬 데이터 샘플에 대한 로컬 모델을 학습할 수 있다. 그 후, 복수 개의 장치들 각각은 학습된 로컬 모델에 기초하여 로컬 모델의 파라미터(e.g. 딥 뉴럴 네트 워크의 가중치, 정보)를 기지국 또는 서버로 전달할 수 있다. 이때, 기지국 또는 서버는 글로벌 모델을 업데이 트하고, 업데이트된 글로벌 모델을 복수 개의 장치들 각각으로 다시 전달할 수 있다. 이때, 일 예로, 에어콤프(AirComp, Over the Air Computing) 방식은 로컬 모델들의 파라미터가 동일한 무선 자원에 기초하여 기지국 또 는 서버로 전송되는 방식일 수 있다. 즉, 기지국 또는 서버에는 글로벌 모델이 존재하고, 복수 개의 장치들 각 각에는 로컬 모델들이 존재할 수 있다. 이때, 상술한 모델들을 전송하기 위한 다양한 통신 방법(유/무선포함)으 로 연결되어 복수 개의 장치와 기지국 또는 서버가 유기적으로 동작할 수 있다. 또한, 일 예로, 상술한 방식은 영상 입력장치 및 영상 출력장치에도 동일하게 적용될 수 있으며, 이에 대해서는 하기에서 서술한다. 일 예로, 도 5는 본 개시의 일 실시예에 따라 연합학습을 나타낸 도면이다. 도 5를 참조하면, 이동통신 시스템 에서 분산형 인공지능 학습을 효율화 하는 방법이 제공될 수 있다. 복수 개의 단말에 대한 데이터가 분산되어 존재하는 경우, 중앙집중형 학습 방법은 단말들이 각각의 데이터를 기지국으로 전달하고, 기지국에서 학습이 수 행되는 방식일 수 있다. 다만, 단말들의 데이터를 기지국 또는 서버로 보내는 중앙집중형 학습은 데이터 보안에 한계가 존재할 수 있다. 따라서, 사용자의 데이터를 보내지 않는 분산 학습 방식으로 무선 연합학습 방식이 필 요할 수 있다. 이때, 무선 연합학습 방식은 단말들의 데이터 각각을 기지국으로 전송하는 대신에 각각의 단말들 이 개별 학습을 진행하면서 로컬 모델 업데이트를 기지국으로 전송하는 방식일 수 있다. 이때, 기지국은 복수 개의 단말들로부터 수신한 로컬 모델 업데이트에 기초하여 로컬 모델 업데이트들의 합쳐진 값을 각각의 단말들 로 전송할 수 있다. 이때, 상술한 절차는 지속적으로 반복될 수 있으며, 단말들의 연합으로 분산 학습이 진행될 수 있다. 여기서, 로컬 모델의 사이즈는 큰 경우가 많기 때문에 학습에 참여하는 단말들이 독립된 무선 자원으로 로컬 모 델에 대한 정보를 업링크 채널로 전송하는 경우, 무선 자원 손실은 커질 수 있다. 따라서, 단말들이 같은 무선 자원을 활용하여 업링크로 로컬 순시 모델을 보내고 무선 상에서 자동으로 합쳐지는 무선 계산(Aircomp) 방식이 사용될 수 있다. 일 예로, 무선 계산(Aircomp) 방식은 각각의 단말들이 보낸 로컬 모델들을 동일한 크기로 합치기 위해서 무선 채널의 역에 비례하는 가중치를 인가하여 전송하는 방식일 수 있다. 구체적인 일 예로, 새로운 통신 시스템에 연합 학습(Federated Learning)의 모델 파라미터가 적용될 수 있다. 연합 학습(Federated Learning)은 개인의 프라이버시 보호, 분산 처리를 통한 기지국의 로드감소 및 기지국과 단말과의 트래픽을 감소시키는 경우 중 어느 하나에 적용될 수 있다. 다만, 이에 한정되는 것은 아닐 수 있다. 이때, 일 예로, 로컬 모델 파라미터(e.g. 딥 뉴럴 네트워크의 가중치, 정보)의 트래픽은 무선 통신환경에서 많 은 부담을 줄 수 있으며, 이를 고려하여 상술한 로컬 모델 파라미터의 압축 또는 에어콤프(Aircomp(Over the Air Computing))를 통해 트래픽을 감소시킬 수 있다. 다만, 통신 시스템에서 무선통신 환경은 다양할 수 있다. 또한, 통신시스템에서 학습이 필요한 단말 수가 다양 하게 설정될 수 있다. 여기서, 통신 시스템에는 상술한 환경을 고려하여 고정적인 특정 기술이 아닌 유동적인 운영 방법 및 시스템이 필요할 수 있다. 이를 통해, 통신 시스템의 자원 효율성을 증대시킬 수 있다. 일 예로, 에어콤프(Aircomp)를 통한 연합 학습(Federated Learning) 방식은 단말 모델 파라미터를 합치는 방식일 수 있다. 에어콤프 방식에 기초하여 전송이 수행되는 경우, 무선 통신 채널은 중첩(superposition) 성질에 기초하 여 신호 전송을 수행하므로 전송 효율을 높일 수 있고, 기지국의 로드를 줄일 수 있다. 또한, 단말들은 동일한 통신채널을 공유할 수 있다. 따라서, 단말들이 다수 존재하는 경우, 전송 효율은 높아질 수 있다. 상술한 점을 고려하여, 단말 모델 파라미터 압축을 통한 연합 학습(Federated Learning) 방식은 각 단말이 파라 미터의 특성을 고려하여 데이터에 대한 압축을 수행하여 기지국에 전송하는 방식일 수 있다. 따라서, 기지국이 연합 학습 방식에 기초하여 신호를 수신하는 경우, 기지국은 수신한 신호에 기초하여 압축을 풀고, 수집된 파라 미터를 합산하는 동작을 수행할 필요성이 있으며, 기지국의 로드는 증가할 수 있다. 또한, 일 예로, 각 단말 수 별로 통신채널을 할당해야 되기 때문에, 사용 단말의 수에 비례하여 통신 트래픽이 증가할 수 있다. 따라서, 단 말들이 다수 존재하는 경우, 압축을 통한 방식은 효율성을 감소시킬 수 있다. 일 예로, 연합 학습(Federated Learning) 방식에서 단말과 기지국간 가중치 시그널링 방법을 고정적으로 사용하 는 경우, 효율성은 무선 환경에 기초하여 다를 수 있다. 일 예로, 효율성은 특정 환경에서 높을 수 있으나, 그 반대의 경우에는 오히려 효율성이 저해될 수 있다. 무선 환경은 유동적으로 변화할 수 있으므로 유동적으로 변 동되는 무선 환경을 인식하고, 인식된 무선 환경에 기초한 기술이 선택될 필요성이 있다. 하기에서는 무선 환경 의 효율성을 높이기 위해 상술한 바에 기초한 동작에 대해 서술한다. 일 예로, 각각의 단말은 연합 학습(Federated Learning) 방식에 기초하여 학습한 모델의 파라미터(e.g. 딥 뉴럴 네트워크의 가중치, 정보)를 기지국으로 전달할 수 있다. 각각의 단말들은 압축한 파라미터를 전달하고, 기지국은 하기 수학식 1에 기초하여 글로벌 모델을 업데이트할 수 있다. 여기서, c는 정보 압축 및 변조 처리일 수 있 고, d는 복조 및 정보 복원 처리일 수 있다. 그 후, 기지국은 업데이트된 글로벌 모델을 각각의 단말로 전달할 수 있다. [수학식 1]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "보다 상세하게는, 각각의 단말은 모델 파라미터의 양을 최소화하는 방법에 기초하여 압축을 진행할 수 있다. 일 예로, 압축은 가중치 가지치기, 양자화 및 가중치 공유 중 적어도 어느 하나에 기초하여 수행될 수 있다. 또한, 일 예로, 압축은 다른 방법에 기초하여 수행될 수 있으며, 상술한 실시예로 한정되지 않는다. 여기서, 기존 신 경망에 기초하여 압축을 수행하는 경우, 가중치(Weights) 중 실제 추론을 위해 필요한 값은 작은 값들에 대한 내성을 가질 수 있다. 즉, 실제 추론을 위해 필요한 가중치 값은 작은 값들에 대해서는 영향이 작을 수 있다. 상술한 점을 고려하여, 가중치 가지치기는 작은 가중치 값을 모두 0으로 설정할 수 있다. 이를 통해, 신경망은 네트워크 모델 크기를 줄일 수 있다. 또한, 일 예로, 양자화(Quantization)는 특정 비트 수로 데이터를 줄여서 계산하는 방식일 수 있다. 즉, 데이터는 특정 양자화된 값으로만 표현될 수 있다. 또한, 일 예로, 가중치 공유 는 가중치 값들을 근사값(e.g. 코드북)에 기초하여 조정하고, 이를 공유하도록 하는 방식일 수 있다. 여기서, 네트워크에서 신호가 전송되는 경우, 해당 정보는 코드북과 그 값에 대한 인덱스만이 공유될 수 있다. 상술한 방법 중 어느 하나에 기초하여 각각의 단말은 데이터에 대한 압축을 수행할 수 있으며, 압축된 정보를 기지국으로 전송할 수 있다. 이때, 기지국은 압축된 를 각각의 단말로부터 수신하고, 수신한 정보에 대한 압축을 해제하여 글로벌 모델의 파라미터를 계산하고 업데이트할 수 있다. 여기서, 각각의 단말은 개별적인 특성을 갖는 로컬모델 파라미터를 설정할 수 있다. 따라서, 각각의 단말이 압 축을 수행하는 경우, 압축 효율은 단말마다 상이할 수 있다. 또한, 일 예로, 각각의 단말은 서로 상이한 하드웨 어 리소스를 가질 수 있다. 여기서, 압축 효율은 하드웨어 리소스에 영향을 받을 수 있다. 따라서, 각각의 단말 마다 압축효율이 상이할 수 있다. 구체적인 일 예로, 단말이 8비트로 양자화를 수행하는 경우, 64비트 연산 처리 기능이 구비된 단말은 높은 압축 효율을 얻을 수 있다. 반면, 16비트 연산 처리 기능이 구비된 단말은 압축 효율이 작을 수 있다. 또한, 일 예로, 단말이 저사양의 하드웨어를 구비하는 경우, 단말은 많은 압축 로드를 받을 수 있다. 따라서, 상술한 단 말은 간단한 압축기법을 사용하는 것이 유리할 수 있다. 일 예로, IoT(Internet of Thing) 단말이나 저전력 단 말들은 비교적 저사양의 하드웨어를 구비할 수 있는바, 간단한 압축 기법을 사용할 수 있다. 반면, AI에 기초하 여 동작하는 단말이나 대용량의 데이터를 처리하는 단말은 고사양의 하드웨어를 구비할 수 있는바, 복잡한 압축 기법을 사용하여 압축 효율을 높일 수 있다. 즉, 단말별로 상이한 압축 방법이 사용될 수 있으며, 각각에 맞는 압축방법을 사용하는 것이 필요할 수 있다. 상술한 점을 고려하여, 각각의 단말은 로컬모델 파라미터의 개별적인 특성과 하드웨어 리소스에 적합한 압축방 식을 사용할 수 있다. 이때, 단말들은 기지국으로 압축 방법에 대한 정보를 전달할 필요성이 있다. 기지국은 단 말로부터 수신한 정보에 기초하여 각각의 단말로부터 수신한 압축된 데이터와 모델 파라미터를 복원할 수 있다. 일 예로, 기지국과 단말이 반사판을 통해 통신을 수행하는 경우로써 상술한 에어콤프 방식의 연합학습이 수행되 는 경우를 고려할 수 있다. 복수 개의 반사판이 존재하는 스마트 통신 환경에서 에어 콤프를 적용하는 경우, 복 수 개의 단말들의 신호 전체가 반사판에 모두 전달되는 형태로 구성되어 최적화가 복잡할 수 있다. 따라서, 시 그널링 처리가 어려워질 수 있다. 또한, 효율적인 프로토콜과 최적화 방식에 기초하여 반사판을 통해 에어콤프 연합학습을 효율적으로 수행하는 방법이 필요할 수 있으며, 하기에서는 이를 위한 방법에 대해 서술한다. 일 예로, 도 5를 참조하면, 업링크 자원을 효율적으로 사용하기 위해 복수 개의 단말들(520, 530, 540)이 기지 국으로 로컬 모델 업데이트 정보를 전달하는 경우, 단말들(520, 530, 540)은 동일한 무선자원을 사용해 무 선상에서 글로벌 모델이 계산되는 방법을 통해 기지국으로 로컬 모델 업데이트 정보를 전달할 수 있으며, 이는 상술한 바와 같다. 일 예로, 도 5에서 복수 개의 단말들(520, 530, 540)은 AI에 기초하여 자율 주행을 수 행하는 차량이나, 스마트 디바이스 또는 그 밖의 장치일 수 있으며, 상술한 실시예로 한정되지 않는다. 일 예로, 연합학습은 하기 3단계로 구분되어 진행될 수 있다. 이때, 업데이트 값이 일정 값으로 수렴할 때까지 하기 3단계가 순차적으로 반복될 수 있다. 여기서, 첫 번째 단계는 각 단말들(520, 530, 540)은 자신의 데이터를 이용해 이전에 수신한 글로벌 모델 ( )을 업데이트하고, 로컬 모델()을 생성할 수 있다. 일 예로, 초기 글로벌 모델은 학습되지 않 은 초기 신경망일 수 있으나, 이에 한정되는 것은 아닐 수 있다. 이때, 로컬 모델에 기초하여 업데이트를 수행 할 수 있다. 일 예로, 하기 수학식 2는 Stochastic gradient 방법에 기초하여 업데이트가 수행되는 경우일 수 있으나, 해당 방법을 한정되는 것은 아닐 수 있다. [수학식 2]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "다음으로, 두 번째 단계는 각각의 단말들(520, 530, 540)은 업데이트한 로컬 모델()을 기지국에게 동일한 무선 자원을 통해 전달할 수 있다. 여기서, 일 예로, 기지국은 서버 또는 클라우드 서버와 연결될 수 있다. 일 예로, 설명의 편의를 위해 기지국이 서버 역할을 하는 경우에 기초하여 서술하지만, 이에 한 정되는 것은 아닐 수 있다. 일 예로, 기지국은 복수 개의 단말들로부터 수신한 로컬 모델들을 합치기 위해 서버로 글로벌 모델을 전달할 수 있으며, 상술한 실시예로 한정되지 않는다. 마지막으로, 세 번째 단계는 하기 수학식 3에 기초하여 무선 상에서 로컬 모델들이 합쳐진 글로벌 모델이 기지 국에 의해 수신되고, 업데이트를 수행할 수 있다. 그 후, 기지국은 업데이트된 정보에 기초하여 k 시 간에서 글로벌 모델을 복수 개의 단말들(520, 530, 540)에게 전달할 수 있다. 일 예로, 상술한 3단계는 글로벌 모델의 값이 수렴되거나 주어진 횟수에 기초하여 반복적으로 수행될 수 있다. [수학식 3]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "상술한 바와 같이, 연합학습에 기초하여 데이터 처리가 수행될 수 있다. 이때, 일 예로, 도 6은 본 개시의 일 실시예에 있어서 영상입출력 장치를 나타낸 도면이다. 도 6을 참조하면, 영상 입출력 장치는 영상 입력을 획득 할 수 있다. 이때, 영상입력 장치(e.g. 카메라)는 렌즈를 통해서 영상의 특성을 변경할 수 있다. 일 예로, 고체 렌즈(e.g. 유리, 플라스틱)의 기계적인 움직임을 통해서 줌(Zoom)이나 광각, 오토 포커스(Auto Focus) 및 OIS 등의 기능 중 적어도 어느 하나 이상이 수행될 수 있으며, 영상입력 장치는 도 6과 같이 망원과 광각으로 동작 하는 3군 렌즈의 움직임에 기초하여 영상 특성을 변경할 수 있다. 구체적인 일 예로, 도 6의 3군 줌렌즈는 다중 줌 군렌즈 방식일 수 있다. 이때, 첫 번째 렌즈(L_1)와 두 번째 렌즈(L_2)가 근접하고 세번 째 렌즈(L_3)의 간 격이 멀어지면 광학계의 초점거리는 짦아질 수 있다.(광각), 반면, 첫 번째 렌즈와 두 번째 렌즈가 멀고, 두 번 째와 세 번째 렌즈가 근접하면 광학계의 초점거리는 길어질 수 있다.(망원) 따라서, 첫번째 렌즈(L_1)와 세번째 렌즈(L_3) 사이에 위치를 변화시키는 경우, 초점거리는 위치에 비례해서 연속적으로 변경될 수 있다. 일 예로, 도 6은 위에서부터 차례로 광각에서 망원을 표시할 수 있다. 또한, 일 예로, 도 7은 본 개시의 실시예에 따라 OIS 원리를 나타낸 도면이다. 도 7을 참조하면, 손떨림 등으로 인하여 발생한 카메라의 기울임(틸트) 현상을 렌 즈의 기계적인 움직임을 통해서 보상할 수 있으며, 상술한 바에 기초하여 영상입력 장치는 영상의 특성을 변경 할 수 있다. 또한, 일 예로, 도 8은 본 개시의 일 실시예에 따라 메타렌즈 구조를 나타낸 도면이다. 일 예로, 렌즈들은 유리 나 유리와 비슷한 재료로 구성될 수 있다. 이때, 렌즈들은 유리를 정확하게 곡면으로 매끈하게 연마해서 빛을 선명하게 모아야, 더욱 정확하고 뚜렷한 이미지를 얻을 수 있으므로 상술한 재질에 기초하여 구성될 수 있다. 다만, 곡면을 연마하는 비용이 높을 수 있으며, 곡면 특성이 렌즈 제작시 고정되므로 공간상에서 많은 제약이 존재할 수 있다. 이때, 일 예로, 메타렌즈는 유리렌즈와 비슷한 특성을 메타표면을 이용하여 구현하는 기술일 수 있다. 이때, 영상의 초점거리는 메타렌즈를 통해서 다양하게 조정될 수 있다. 일 예로, 도 8(a)을 참조하면, 메타렌즈는 물질의 표면을 인공적인 작고 정밀하게 패턴화된 구조로 만들고, 각 요소(Element)들에서 굴절률(유 전율과 투자율의 식)을 조절하여 초점의 거리나 위치를 변화시킬 수 있다. 일 예로, 도 8(a)는 PGMS(Phase Gradient MetaSurface)로 구현된 고정된 구조의 메타렌즈일 수 있으나, 메타렌즈 구조는 이에 한정되는 것은 아 닐 수 있다. 일 예로, 메타렌즈는 구면파를 평면파로 변경하여 빛의 방향성을 제어할 수 있다. 보다 상세하게는, 도 8(b)를 참조하면, 메타렌즈를 통해서 구면파를 평면파로 변경하여 빛의 방향성을 줄 수 있 다. 이때, 도 8(b)를 참조하면 구면파의 파면과 메타렌즈의 위상천이가 결합하여 전달되는 파면은 평면파의 형 태를 가질 수 있으며, 이에 한정되는 것은 아닐 수 있다. 즉, 메타렌즈는 기존 고정된 렌즈와 상이하게 각 요소(Element)들의 파라미터를 제어하여 초점거리 및 그 밖의 영상 특성을 변경시킬 수 있으며, 이에 대해서는 하기에서 서술한다. 일 예로, 하기에서는 특성(e.g. 크기, 모양, 용도, 화각)이 고정되는 영상장치와 기계적인 렌즈 조절을 통해 특 성을 바꿀 수 있는 출력장치에 메타렌즈를 적용하는 방법에 대해 서술한다. 이때, 일 예로, 메타렌즈는 영상 입 출력 장치에 가변적인 특성을 부여할 수 있으며, 제어기를 통해서 입출력을 통합적 또는 유기적으로 제어 가능 할 수 있다. 또한, 일 예로, 상술한 바와 같이 특성이 가변되는 영상장치는 사용자 단말의 위치에 기초하여 제 어될 수 있으며, 이에 대한 정보를 활용하여 인공 지능 학습(e.g. 연합학습)을 수행할 수 있다. 즉, 각각의 단말들은 기지국 또는 서버와 통신을 수행하여 단말들의 위치 정보를 기반으로 연합학습을 통해 영 상장치의 특성을 가변하도록 함으로써 환경을 고려하여 영상장치를 제어할 수 있다. 여기서, 각각의 단말은 사 용자에 의해 사용되는 장치일 수 있다. 일 예로, 사용자의 위치 정보는 단말의 위치 정보로 인지될 있으며, 이 에 기초하여 메타렌즈 인공시스템이 제어될 수 있다. 또한, 일 예로, 서버는 기지국 또는 액세스 포인트(access point, AP)와 연결되어 동작하는 장치일 수 있으며, 단말로부터 위치 기반 파라미터 정보를 수신하고, 이에 기 초하여 연합학습을 통해 글로벌 모델을 업데이트시키는 장치일 수 있다. 즉, 연합학습을 고려하여 글로벌 모델 을 업데이트시키는 장치는 서버, 기지국 또는 액세스 포인트 등 단말과 통신을 수행하는 장치를 지칭할 수 있으 며, 특정 형태로 한정되는 것은 아닐 수 있다. 다만, 하기에서는 설명의 편의를 위해 기지국을 중심으로 서술한 다. 일 예로, 도 9는 본 개시의 일 실시예에 따라 사용자 기반의 영상 입출력을 위한 메타렌즈를 제어하는 인공지능 시스템을 나타낸 도면이다. 도 9를 참조하면, TOF(Time of Flight) 카메라를 통해서 사용자의 위치 및 거 리를 인지할 수 있다. 이때, TOF 카메라는 화각이 작기 때문에 모든 영역을 검출하는데 한계가 존재할 수 있다. 따라서, 메타렌즈를 통해서 순차적으로 화각의 방향(초점방향)를 조절하여 광각의 효과를 나타낼 수 있다. 이때, 메타렌즈 제어기는 사용자 정보를 얻기 위해서 순차적으로 방향벡터를 선택하고, Agent(인공지 능, 910)은 방향벡터와 TOF 이미지를 통해서 사용자의 방향이나 거리를 인지할 수 있다. 일 예로, 인공지 능은 기지국에 구현되거나 기지국과 연결된 장치 또는 클라우드일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 이때, 인공지능은 사용자 인지 이미지를 기반으로 영상 출력장치의 메타렌즈를 제어하는 값 을 메타렌즈 제어기로 전달할 수 있다. 여기서, 제어 값은 사용자의 위치에 따라 초점거리와 초점방향 및 곡률반경을 가지는 코드북의 형태로 구현될 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 또 다른 일 예로 , 인공지능 또는 기지국은 TOF 카메라 대신 사용자가 구비한 단말로부터 위치정보를 수신하여 동작하는 것도 가능할 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 상술한 바에 기초하여 메타렌즈가 제어되는 경우, 메타렌즈의 각 요소별 위상이 조절될 수 있다. 보다 상세하게 는, 도 10은 본 개시의 일 실시예에 따라 메타렌즈를 제어하는 방법을 나타낸 도면이다. 도 10(a)를 참조하면, 메타렌즈가 광원의 조향성을 조절할 수 있다. 이때, 메타렌즈의 각 메타 원소(meta-atom, 또는 요소)의 위상을 조절함으로써 구면파가 파면이 조향성을 가지도록 조절할 수 있다. 일 예로, 도 10(a)를 참조하면, 메타렌즈의 위상변화가 오른쪽으로 치우칠수록 통과된 파면이 오른쪽으로 기울어질 수 있으며, 상술한 방법을 통해 제어될 수 있다. 또한, 도 10(b)는 메타렌즈가 영상의 곡률을 조절하는 방법을 나타낸 도면이다. 도 10(b)를 참조하면, 영상의 곡률을 조절함으로써 사용자는 커브드 모니터와 같은 입체감을 가질 수 있다. 일 예로, 메타렌즈를 통해 영상의 커브드 모니터 형태를 갖도록 하기 위해서는 빛의 방향성뿐만 아니라 시야의 가장자리 위치의 영상을 확 대하여서 사용자의 눈의 위치와 영상까지의 거리를 같게 설정할 필요성이 있다. 구체적인 일 예로, 도 11 및 도 12는 본 개시의 일 실시예에 따라 커브드와 플랫 영상출력의 시청거리 비교를 나타낸 도면이다. 이때, 도 11 및 도 12를 참조하면, 메타렌즈는 화면의 위치별로 확대 또는 축소 영역이 달라 지기 때문에 한 개가 아니라 복수 개의 중첩이 필요할 수 있으며, 커브드의 곡률 반경에 기초하여 제어될 수 있 다. 일 예로, 곡률반경이 클수록 휘어짐은 적을 수 있다. 보다 구체적인 일 예로, 곡률반경 1800R은 반경이 180cm 가지는 휘어짐 정도를 나타낼 수 있으나, 이는 하나의 일 예일 뿐, 상술한 실시예로 한정되지 않는다. 도 13은 본 개시의 일 실시예에 따라, 메타렌즈 제어 방법을 나타낸 도면이다. 도 13을 참조하면, 메타렌즈 인 공지능 시스템은 사용자 인식부와 메타렌즈 특성 예측부를 포함할 수 있다. 또한, 메타렌즈 인공지능 시스템은 다른 구성을 더 포함할 수 있으며, 상술한 실시예로 한정되지 않는다. 이때, 메타렌즈인공지능 시스템은 현재 설정된 메타렌즈 특성 값에 기초하여 카메라로부터 영상을 통해 사용자를 인식할 수 있다. 일 예로, 메타렌즈 인공지능 시스템의 사용자 인식부는 사용자 관련 정보를 추출하여 메 타렌즈 특성 예측부로 전달할 수 있다. 이때 사용자 관련 정보는 사용자 방향 정보, 거리 정보 및 상태 정보 중 적어도 어느 하나 이상을 포함할 수 있으며, 특정 정보 형태로 한정되지 않는다. 또한 , 일 예로, 메타렌즈 인공지능 시스템은 사용자가 구비한 단말로부터 사용자 관련 추가 정보를 더 획득하여 메타렌즈 제어부로 전달할 수 있다. 일 예로, 단말은 사용자가 인증을 완료하여 사용하는 단말 일 수 있으며, 사용자가 소지하고 있을 수 있다. 또 다른 일 예로, 단말은 영상 입출력 장치와 연관된 장치 (e.g. 리모콘)일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 여기서, 단말은 단말의 위치 정보 및 그 밖의 사용자 관련 추가 정보를 인공지능 시스템으로 전달할 수 있으며, 이를 활용할 수 있다. 그 후, 메타렌즈 특성 예측부는 사용자 인식정보에 기초하여 코드북으로 저장된 메타렌즈 제어 값을 선택 하고, 선택된 제어 값을 메타렌즈 제어기으로 전달할 수 있다. 이때, 메타렌즈 제어기 내의 영상 입력장치 및 영상 출력장치는 코드북에 대응하는 획득한 제어 값에 기초하여 메타렌즈를 제어할 수 있다. 이때, 메타렌즈 인공지능 시스템은 통신에 기초하여 동작할 수 있으며, 데이터 부담이 존재할 수 있다. 상술한 점을 고려하여, 일 예로, 인공지능 시스템의 사용자 인식부는 실제 영상을 획득하는 장치 (e.g. 카메라)에 구현되고, 메타렌즈 특성 예측부는 기지국 또는 서버에 구현될 수 있으며, 분산하여 학 습 및 예측을 수행할 수 있다. 일 예로, 도 14은 본 개시의 일 실시예에 따라 분산 학습 인공지능 시스템의 동작을 나타낸 도면이다. 도 14를 참조하면, 기지국(또는 서버, 1410)와 영상 입력장치 및 영상 출력장치는 상호 간의 통신을 통해 데이터를 교환할 수 있다. 일 예로, 영상 입력장치로써 카메라의 메타렌즈 제어기는 메타렌즈의 조향성을 변경하여 입력받은 영상을 통해서 사용자 관련 정보를 인지할 수 있다. 일 예로, 카메라는 OIS의 렌즈 틸트 기 능처럼 메타렌즈의 조향성을 변경하여 입력받는 영상을 제어할 수 있으나, 이에 한정되는 것은 아닐 수 있다. 이때, 사용자 관련 정보는 사용자의 방향, 거리 및 상태(시야 각도) 정보 중 적어도 어느 하나 이를 포함할 수 있으며, 상술한 실시예로 한정되지 않는다. 여기서, 상술한 바처럼 영상 입력장치는 인공지능 사용자 인 식부를 구비하고, 이에 기초하여 사용자 관련 정보를 도출할 수 있다. 그 후, 영상 입력장치는 도출한 사 용자 관련 정보(또는 사용자 인식 정보를 기지국(또는 서버, 1410)로 전달할 수 있다. 이때, 일 예로, 기지국 (또는 서버, 1410)는 상술한 인공지능 시스템의 인공지능 메타렌즈 특성 예측부를 구비할 수 있으며, 이를 통해 메타렌즈 특성인자(또는 메타렌즈 파라미터)를 도출(또는 예측)할 수 있다. 이때, 일 예로, 메타렌즈 특성인자 는 사용자의 방향, 거리 등의 위치정보에 따라 메타렌즈의 다양한 패턴을 가지고 있는 코드북의 인덱스로 정의 될 수 있다. 또 다른 일 예로, 기지국은 사용자가 소지한 단말로부터 위치 정보 및 사용자 관련 추가 정 보를 더 획득할 수 있다. 이때, 인공지능 메타렌즈 특성 예측부는 단말로부터 획득한 정보를 더 이용하여 메타 렌즈 특성인자를 도출할 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 이때, 일 예로, 코드북의 인덱스 형태인 메타렌즈의 특성인자는 , , 및 중 적어도 어느 하나 를 사용할 수 있다. 이때, 및 는 각각 초점위치(Focal Point) x좌표 및 y좌표일 수 있다. 또한, 은 초점거리(Focal Length)이고, 는 곡률반경일 수 있다. 또한, 일 예로, 메타렌즈의 특성인자는 다른 파라 미터를 더 포함할 수 있으며, 상술한 파라미터로 한정되는 것은 아닐 수 있다. 이때, 일 예로, 메타렌즈의 특성 인자에 기초하여 사용자의 방향 및 거리가 표현될 수 있으며, 상술한 값 각각은 x, y, l 및 c로, 해당 값들은 인덱스로 양자화될 수 있다. 이때, 기지국(또는 서버, 1410)는 인공지능 메타렌즈 특성 예측부에 기초하여 관련 메타렌즈 제어 값을 생성할 수 있다. 이때, 생성된 메타렌즈 제어 값은 각각 영상 입력장치 및 영상 출력 장치로 전달될 수 있다. 이를 통해, 사용자 기반의 영상 입출력을 메타렌즈를 통해서 구현할 수 있다. 또 한, 일 예로, 영상 입력장치는 사용자의 움직임을 인지하고 추적하면서 관련 정보를 메타렌즈 특성 예측 부에 전달하여 메타렌즈 특성 예측부의 메타렌즈 특성인지에 기초하여 메타렌즈 제어 값을 지속적으로 업데이트 할 수 있다. 이때, 영상 입력장치는 일정 주기에 기초하여 모든 방향을 순차적으로 탐색하면서 기 설정된 공간에 대한 전체 상황을 인지할 수 있다. 즉, 영상 입력장치는 주기적으로 영상 정보를 획득하여 사용자 관련 정보를 추출하고, 이를 기지국으로 전달하여 메타렌즈 특성인자 관련 제어 값을 주기적으로 업데이 트함으로써, 사용자 인지 기반 제어를 수행할 수 있다. 구체적인 일 예로, 영상 입력장치(e.g. 카메라)와 메타렌즈 제어를 통한 인공지능 시스템에서 영상 출력장치는 실내 TV인 경우를 고려할 수 있다. 이때, 영상 입력장치는 사용자 관련 정보를 획득할 수 있으며, 이는 상술한 바와 같다. 또한, 일 예로, TV 리모컨은 상술한 단말일 수 있으며, 리모컨의 위치를 통해서 간접적으로 사용자 의 위치를 측정할 수 있다. 일 예로, 블루투스, WIFI 및 그 밖의 근거리 통신망을 통해 리모컨을 사용하는 경우, 사용자의 거리 및 방향은 리모컨으로부터의 TV 수신파워나 TV 배열안테나의 AoA(Arrival of Angle)를 측 정하여 TV 로부터 리모컨까지의 거리 및 방향을 인지함으로써 측정될 수 있다. 또 다른 일 예로, 적외선을 사용 하는 리모컨의 경우, 사용자의 거리 및 방향은 WIFI 센싱을 통해 대상 검출(Object Detection)을 수행하여 TV에 대한 리모컨의 상대적 위치를 인지할 수 있으며, 이를 통해 사용자의 거리 및 방향을 인지할 수 있다. 또 다른 일 예로, 사전에 위치정보를 가지고 있는 리모컨의 경우, 전원 인가 또는 추가 시그널링으로 TV에 위치 정보를 전달할 수 있으며, 특정 실시예로 한정되지 않는다. 여기서, 일 예로, 상술한 리모컨 또는 단말을 통해 사용자 거리 및 방향 정보를 기지국(또는 서버)로 전달함으 로써 사용자 인식부를 대체할 수 있으나, 이에 한정되는 것은 아닐 수 있다. 구체적인 일 예로, 도 15는 본 개시의 일 실시예에 따라 인공지능 시스템에 기초하여 메타렌즈를 제어하는 방법 을 나타낸 도면이다. 도 15를 참조하면, 리모콘 및 영상출력장가 구비될 수 있다. 이때, 리모콘 은 서버 또는 엑세스 포인트(access point, AP)와 통신을 수행하는 장치일 수 있다. 또 다른 일 예로, 리 모콘은 사용자 단말일 수 있다. 일 예로, 단말은 리모컨의 기능을 대신할 수 있으며, 영상 출력장 치 또는 서버나 AP와의 인증을 통해 동작하는 장치일 수 있다. 즉, 설명의 편의를 위해 리모콘을 기준으로 서술하지만, 이에 한정되지 않고 단말 및 그 밖의 장치를 통해 수행될 수 있으며, 특정 형태로 한정되 지 않는다. 또한, 일 예로, 영상 출력장치는 TV나 그 밖의 영상을 출력하는 장치일 수 있다. 또한, 일 예 로, 영상 출력장치는 서버나 AP를 구비한 장치일 수 있다. 즉, 영상 출력장치는 서버 또는 AP와 결 합된 형태일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 또 다른 일 예로, 상술한 리모컨 또는 단말과 통신을 수행하는 별도의 기지국(또는 서버)가 존재하고, 영상 출력장치는 이에 기초하여 제어되는 장치 일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 일 예로, 도 15를 참조하면, 리모컨이 턴온되는 경우, 리모컨은 사용자 간섭인식정보를 영상 출력 장치로 전달할 수 있다. 이때, 사용자 간섭인식정보는 영상 출력장치와의 방향 및 거리 정보일 수 있다. 또한, 일 예로, 사용자 관련 다른 인식 정보를 더 포함할 수 있으며, 특정 형태로 한정되지 않는다. 그 후, 영상 출력장치는 사용자 간섭인식정보에 기초하여 사용자를 인식하고, 이에 대한 정보를 인공지능 메타렌즈 특성 예측부에 전달하여 코드북 형식의 메타렌즈 특성인자의 인덱스(또는 제어 값)를 도출할 수 있다. 그 후, 제어 값은 메타렌즈 제어기로 전달되고, 이에 기초하여 영상 출력장치는 영상을 출력할 수 있으며, 이는 도 14와 같을 수 있다. 또한, 일 예로, 상술한 동작은 리모컨의 시그널링에 기초하여 반복 될 수 있다. 일 예로, 리모컨이 턴온되면 상술한 동작이 수행될 수 있다. 또한, 일 예로, 리모컨은 기 설정된 주기에 기초하여 시그널링을 영상 출력장치로 전달하고, 주기적으로 상술한 동작을 수행할 수 있다. 또 다른 일 예로, 리모컨은 이벤트 트리거링(e.g. 사용자의 리모컨 인풋)에 기초하여 상술한 동작 을 수행할 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 또한, 일 예로, 도 16은 본 개시의 일 실시예에 따라, 메타렌즈에 기초하여 영상 입출력을 제어하는 방법을 나 타낸 순서도이다. 도 16을 참조하면, 사용자 기반의 영상 입출력을 위한 메타렌즈 인공지능 시스템의 동작은 사 용자 인식 단계, 사용자 추적반복 단계 및 주기적 순차단계를 포함할 수 있다. 일 예로, 사용자 인식 단계는 순 차적으로 메타렌즈의 조향성을 변경하여 입력받은 영상을 통해서 사용자의 방향, 거리 및 상태(시야 각도, 움직 임) 중 적어도 어느 하나의 정보를 인지하는 단계일 수 있다.(S1610) 이때, 일 예로, 화각 제약이 있는 카메라 (특히 적외선카메라)를 기계적인 장치에 도움없이 광각의 효과를 낼 수 있으며, 특정 형태로 한정되는 것은 아 닐 수 있다. 인공지능 사용자 인식부는 대상 검색(Object Detection)이나 특징 추출 중 적어도 어느 하나를 통 해 사용자 인식 정보를 인지할 수 있으며, 특정 형태로 한정되지 않는다. 다음으로, 사용자 추적반복 단계는 사용자의 위치를 지속적으로 추적하여 영상 입출력장치의 메타렌즈 제어를 변경하는 단계일 수 있다. 일 예로, 영상 입력장치는 기지국(또는 서버)으로 사용자 인식 정보를 전달하고 (S1620), 기지국(또는 서버)는 사용자 인식정보를 기반으로 예측한 특성인자를 영상 입출력 장치에 전달할 수 있다.(S1630) 그 후, 영상 입출력 장치의 메타렌즈 제어기는 전달받은 메타렌즈 특성인자에 해당하는 제어 값을 생성하거나 코드북을 참조하여 설정을 수행할 수 있으며, 설정 값을 도출할 수 있다.(S1640) 이때, 설정 값이 수렴하는지 여부에 기초하여 수렴하지 않으면 사용자 추적반복 단계가 반복될 수 있다. 반면, 설정 값이 수렴하 면 주기적 순차탐색 단계를 수행할 수 있다. 또 다른 일 예로, 사용자 추적반복 단계는 N번 수행될 수 있으며,N번 수행 후에 주기적 순차탐색 단계가 수행될 수 있다. 이때, 일 예로, 메타렌즈 코드북의 최적의 값은 사용자 인식정보에 기초하여 도출되기 때문에 MAB AI나 강화학습을 사용할 수 있으며, 지도학습으로 구현이 가능할 수 있다. 일 예로, 상술한 학습이 수행되는 경우, 사용자의 위치추적이 불가능하거나 일정 시간이 필요할 수 있으 며, 특정 형태로 한정되는 것은 아닐 수 있다. 그 후, 주기적 순차탐색은 일정 주기로 수행하여 사용자나 환경 을 전체적으로 재 검색할 때 사용될 수 있다. 일 예로, 사용자 위치 추적이 불가능하거나 일정횟수 이후로 전 방향을 순차적으로 탐색을 수행하기 위해 주기적 순차 탐색 단계가 수행될 수 있다.(S1650) 또한, 일 예로, 도 17 및 도 18은 본 개시의 일 실시예에 따라 사용자 인식부에서 대상을 검출하는 방법을 나타 낸 도면이다. 메타렌즈 제어를 위한 인공지능 시스템은 인공지능 사용자 인식부와 메타렌즈 특성 예측부를 포함 할 수 있다. 이때, 인공지능 사용자 인식부는 대상 검출(Object Detection)의 형태로 정확도 및 실시간성 확보 가 필요할 수 있다. 따라서, 인공지능 사용자 인식부는 1-Stage Detector가 적당할 수 있으며, 1-Stage Detector는 특징을 추출하는 Convolution layer와 영역과 분류를 하는 Full connected Layer 로 구분되고, 이 는 도 17과 같을 수 있다. 도 17을 참조하면, 사용자 인식부에서 사용하는 대상 검출 구조로 카메라(TOF)부터 얻은 영상의 특징은 Convolution Layer를 통해서 추출될 수 있다. 그 후, 추출된 특징은 Feature Maps으로 구성될 수 있으며, Feature Maps은 사물의 위치 및 크기 좌표(x, y, w, h)를 예측하는 Bounding Box Regression 부분과 사물을 분 류하는 Multi-class Classification로 구분되어 도출될 수 있다. 다만, 이는 하나의 일 예일 뿐, 상술한 실시예 로 한정되지 않는다. 또한, 일 예로, 도 18을 참조하면, Object Detection(YOLO)의 Feature Map 구조는 전체 Grid수 S*S개별 및 B개의 Box좌표별로 Objectness Score와 Class Score가 도출될 수 있으며, 각각은 대상 (object)가 존재할 확률과 대상이 해당 class에 속할 확률을 나타낼 수 있다. 여기서, 일 예로, 상술한 바에 기 초하여 loss function은 하기 수학식 4와 같을 수 있다. [수학식 4]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이때, 는 coordinates(x,y,w,h)에 대한 loss와 다른 loss들과의 균형을 위한 균형 파라미터(balancing parameter)이고, 는 대상이 있는 box와 없는 box간에 균형을 위한 균형 파라미터(balancing parameter)일 수 있다. 일 예로, 이미지 내의 대상이 있는 셀보다 대상이 없는 셀이 더 많을 수 있으며, 이를 고려하여 상술 한 파라미터가 사용될 수 있다. 일 예로, 수학식 4에서 첫째 줄과 둘째 줄은 grid cell i의 predictor bounding box j에 대한 x, y, w, h의 loss를 표현한 것일 수 있다. 여기서, 각각 중심점 좌표와 가로세로의 크기를 나타낼 수 있다. 둘째 줄에서는 큰 box로 인해 생기는 큰 편차를 보완하기 위해 제곱근을 취할 수 있다. 또한, 세번 째 줄은 대 상이 존재하는 grid cell i의 predictor bounding box j에 대해, confidence score의 loss를 계산한 것일 수 있다.(=1) 반면, 네번째 줄은 대상이 존재하지 않는 grid cell i의 bounding box j에 대해, confidence score의 loss를 계산( =0)한 것일 수 있다. 마지막으로 다섯 번째줄은 대상이 존재하는 grid cell i에대해, conditional class probability의 loss 계산한 것일 수 있다. 일 예로, Correct class c에 대해서는 =1일 수 있고, 그렇지 않으면 =0일 수 있다. 또한, 일 예로, 대상 검출에 추가로 사용자의 시야각도 도 추가로 추출하여 사용자 인식 정보로 사용할 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 또한, 일 예로, 도 19는 본 개시의 일 실시예에 따라 최종 입출력을 나타내고 있다. 일 예로, 도 19(a)를 참조 하면, 카메라로부터 영상과 영상추출시 메타렌즈 제어 값을 통해서 최종적으로 사용자의 인지정보(방향, 거리, 시선방향, 이동성)가 추출될 수 있으며, 이는 상술한 바와 같다. 또한, 메타렌즈 특성 예측부는 사용자 인식부 처럼 지도학습으로 구현이 가능하지만, 강화학습으로도 구현이 가능할 수 있다. 보다 상세하게는, 도 19(b)를 참조하면, 지도학습을 사용한 메타렌즈 제어 시스템 구조는 사용자의 인지정보(방 향, 거리, 시선방향, 이동성)를 통해 메타렌즈의 특성함수인 초점위치, 거리 및 곡률반경을 예측할 수 있으며, 이는 도 19(b)와 같을 수 있다. 도 20은 본 개시의 일 실시예에 따라, 강화학습 (또는 MAB)을 사용한 메타렌즈 제어 시스템 구조를 나타낸 도면 이다. 일 예로, 강화학습은 2개의 입력과 1개의 출력으로 구성될 수 있으나, 이에 한정되는 것은 아닐 수 있다. 일 예로, 강화학습에는 상태(State)와 보상(Reward)이 입력으로 사용되고, 출력으로 Agent는 행동(Action)을 선 택할 수 있다. 이때, 상태는 MAB에서는 사용되지 않을 수 있다. 또한, 행동(Action)은 메타렌즈 제어가 되어 사 용자 기반의 최적의 영상을 제공하는 동작일 수 있다. 메타렌즈 제어 인공지능 시스템은 환경으로부터 행동 (Action)에 대한 보상 값과 변경된 상태정보를 얻어서 학습에 사용하고, 또다시 행동을 선택하는 일을 반복하여 상술한 바와 같이 최적의 제어 값을 도출할 수 있다. 도 21은 본 개시의 일 실시예에 따라, 강화학습을 사용한 메타렌즈 제어 시스템 블록도를 나타낸 도면이다. 도 21을 참조하면, 강화학습 기반 인공지능은 강화학습 모델을 구비할 수 있다. 이때, 강화학습 모델 은 학습부와 예측부로 되어 있고, 학습과 동시에 다음 행동을 예측할 수 있다. 여기서, 상태 (State)인자로는 사용자의 인식정보(방향, 거리, 시야방향, 이동성) 등이 사용될 수 있으며, 하기 수학식 5와 같을 수 있다. [수학식 5]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이때, 행동(Action)은 인공지능이 선택하는 메타렌즈 제어 값 생성을 위한 특성인자로 이산형 값이거나 연속적 인 값일 수 있다. 일 예로, 연속적인 값은 메타렌즈 제어 값 생성기의 입력 값으로 사용하고, 이산적인 값은 기 공유된 코드북의 인덱스로 사용될 수 있으며, 행동은 하기 수학식 6과 같을 수 있다. [수학식 6]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "또한, 일 예로, 강화학습에서 보상은 학습을 위해서 필수적인 요소일 수 있다. 일 예로, 사용자 인지정보를 통 해서 반응을 예측할 수 있으며, 사용자의 호감도나 집중도를 수치화하여 보상으로 사용할 수 있다. 즉, 사용자 피드백 정보가 보상 정보일 수 있다. 다만, 보상 정보는 특정 형태로 한정되는 것은 아니고, 다양한 형태일 수 있다. 일 예로, 보상 정보는 하기 수학식 7과 같이 도출될 수 있다. [수학식 7]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "또한, 일 예로, 상술한 연속적인 값을 예측하는 강화학습으로는 DDPG(Deep Deterministic Policy Gradient)가 사용될 수 있다. DDPG는 Policy gradient와 DQN의 장점을 모두 가질 수 있다. 즉, DDPG는 안정적이고, 연속공간 에서 사용이 가능할 수 있다. 또한, 일 예로, 결정론적인(Deterministic) Policy를 사용하기 때문에 빠르게 수 렴이 가능하며, 가벼운 알고리즘일 수 있다. 일 예로, 도 22는 본 개시의 일 실시예에 따라, DDPG를 사용한 강화학습을 나타내고 있다. 도 22를 참조하면, DDPG를 사용한 강화학습은 Actor-Critic 알고리즘과 DQN 알고리즘의 특징을 모두 담고 있다. Actor 네트워크와Critic네트워크를 통해 각각 Q(Value Action Function)와 행동(Action)을 예측할 수 있다. 또한, Critic네트워 크는 Experience Replay Memory를 사용하여 TD-Error(Temporal Difference)를 줄이는 방향으로 학습될 수 있으 며, 학습된 Critic네트워크는 Policy Gradient 계산 및 학습에 사용될 수 있다. 또한, Target Policy는 Deterministic이기 때문에 π 대신 μ 를 통해서 Bellman equation 을 표현할 수 있으 며, 수학식 8과 같을 수 있다. [수학식 8]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이때, 상태(State)와 행동(Action)은 각각 와 이고, ~ E는 환경(Environment)으로 추출된 값일 수 있다. 여기서, 는 policy μ를 위한 action-value function이고, γ는 discount factor이며, r은 보상값(Rewar d)일 수 있다. 또한, Critic Network의 Weight를 각각 로 표현하고, 다양한 확률분포를 가진 행동 policy를 β라고 할 때, Critic Network의 Loss는 하기 수학식 9와 같을 수 있다. [수학식 9]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "수학식 9에서 기대 값은 Relay Buffer R에 저장된 Transitions (, ,)을 Minibatching 하여 평균값 을 취함으로서 표현될 수 있으며, 수학식 10과 같을 수 있다. [수학식 10]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "또한, 는 TD(Temporal Differnece) 가 되며 Critic Network는 TD Error를 줄이는 방향으로 학 습될 수 있다. 이때, Actor Network는 기대 보상 값(Expected Return)을 최대화하는 방향으로 Policy를 업데이 트할 수 있으며, 수학식 11과 같을 수 있다. [수학식 11]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "또한, 기대 값은 하기 수학식 12와 같이 Relay Buffer를 사용하여 근사화 될 수 있다. [수학식 12]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "또한, 일 예로, DDPG는 Off-policy 모델로서 Exploration을 추가하는 것이 용이할 수 있다. 일 예로, Exploration policy는 노이즈 분포를 추가하여 생성할 수 있으며, 수학식 13과 같을 수 있다. [수학식 13] 여기서, 정규분포의 분산 을 이용하여 Exploration의 율을 조절할 수 있으며, 상술한 decaying e-greedy 나 UCB를 이용하여 Adaptive하게 조절이 가능할 수 있다. 또 다른 일 예로, 이산적 값의 예측은 선택형 인공지능을 통해서 구현될 수 있다. 일 예로, 도 23은 본 개시의 일 실시예에 따라 톰슨 샘플링(Thompson Sampling)을 사용한 선택인공지능 (MAB AI, 2310) 시스템을 나타내고 있다. 일 예로, 톰슨 샘플링을 사용한 선택인공지능 (MAB AI, 2310)은 크게 학습부와 선택부로 구분될 수 있다. 일 예로, 학습부에서는 보상 값(Reward)에 기초하여 직전 행동 i에 대한 톰슨 샘플링 파라미터 (α, β)를 갱신 할 수 있으며, 보상에 따른 샘플링 파라미터 (α, β)는 수학식 14와 같을 수 있다. [수학식 14]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "이때, 는 기준이 되는 보상 값으로써, 단말에서 IRS 성능 측정기의 보상 형태에 따라 상이할 수 있으며, 특 정 형태로 한정되는 것은 아닐 수 있다. 톰슨 샘플링 선택부에서는 누적된 α , β를 베타 분포(Beta Distribution)에 적용하여 샘플링 한 값 중 가장 큰 값을 가지는 메타렌즈 제어 파라미터 인덱스를 선택할 수 있다. 이때, 선택한 {, , , }는 메타렌즈 제어 값 생성기로 전달될 수 있다. 또한, 렌즈의 특성 을 나타내는 인덱스{, , , }는 개별적으로 선택하는 방식을 사용할 수 있다. 또한, = (, , , )와 같이 통합된 새로운 인덱스 를 사용하여 선택하는 방식도 사용될 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 일 예로, 베타 분포는 하기 수학식 15와 같을 수 있다. [수학식 15]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "또한, 일 예로, 메타렌즈 제어 값 생성기는 렌즈의 특성인자 ,, , 를 통해서 메타렌즈의 제어 값을 생성할 있다. ,, 은 각각 초점의 위치와 거리를 나타내는 인자이고, 는 커브드 형태의 영상 출력장치를 지원하기 위한 인자일 수 있다. 일 예로, 메타렌즈 제어기 내의 메타렌즈 제어 값 생성기는 각 특성인자들을 통해서 메타렌즈 제어 값을 생성하 는 것으로 관련 인자에 기초하여 메타렌즈의 크기나 층의 개수 및 그 밖의 설정을 미리 계산된 코드북에 기초하 여 동작하도록 제어할 수 있다. 보다 상세하게는, 도 24는 본 개시의 일 실시예에 따라, 메타렌즈 제어기의 구조를 나타낸 도면이다. 메타렌즈 제어기는 인공지능 메타렌즈 특성인자 예측부로부터 메타렌즈 제어 값 생성을 위한 파라미터(,, , )와 현재 영상 입출력장치의 설치된 메타렌즈의 규격(크기, 제어 Element 수, 메타렌즈 층) 정보를 획 득할 수 있다. 또한, 일 예로, 메타렌즈 제어기는 추가 정보를 더 획득할 수 있으며, 특정 형태로 한정되 는 것은 아닐 수 있다. 그 후, 메타렌즈 제어 값 생성부는 메타렌즈 제어 값의 코드북을 참조하여 제어 값을 생성할 수 있다. 또 다른 일 예로, 메타렌즈 제어 값 생성부는 인공지능을 활용하여 N개 층의 메타 렌즈 구동기에 필요한 제어 값을 생성할 수 있으며, 이에 기초하여 메타렌즈 층별로 구동기가 메타렌즈를 제어 할 수 있다. 이때, L번째 메타렌즈 구동기에서 출력하는 값은 수학식 16과 같을 수 있으며, 수학식 16에서 θ는 각 소자별 위상천이 값일 수 있다. [수학식 16]"}
{"patent_id": "10-2024-7001470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "이때, 일 예로, 초점위치를 나타내는 , 는 OIS와 원리와 마찬가지로 렌즈의 틸트의 방향과 틸트 각도 를 나타내는 인자일 수 있다. 일 예로, 도 25(a)를 참조하면, 도 25(a)에서 AA'의 거리는 일 수 있다. 또한, 일 예로, 도 25(b)를 참조하면, 렌즈의 지향성은 메타렌즈 패턴에 따른 조향성 변경원리를 이용 할 수 있다. 보다 상세하게는, 메타렌즈의 위상천이가 되는 곡선을 초점위치(,)와 비례하게 변경하여 제어 값을 생성할 수 있다. 또한, 일 예로, 초점거리를 나타내는 은 광각 또는 망원을 나타내는 것으로 줌의 역할과 관계된 특성인자일 수 있다. 일 예로, 메타렌즈에는 줌 구성 원리가 적용될 수 있으며, 메타렌즈의 곡률(위상천이의 기울기)를 조 절함으로써 메타렌즈 위치 자체를 기계적으로 변경하는 것과 동일한 효과를 가져올 수 있다. 구체적인 일 예로, 도 26(a)는 3군 줌렌즈 방식에서 메타렌즈의 곡률을 이용하여 광각과 망원의 효과를 내는 방 법을 나타낸 도면이다. 도 26(a)를 참조하면, 초점거리를 나타내는 과 반비례하여 중간 오목렌즈의 곡률을 조절하도록 메타렌즈의 제어 값을 생성할 수 있다. 또한, 일 예로, 커브드 영상출력 효과를 나타내기 위해서 곡률반경 를 사용할 수 있다. 이때, 곡률반경 는 커브드 형태의 정도를 표시하는 인자로 곡률 반경이 클수록 완만한 커브드 영상출력이 이루어질 수 있다. 일 예로, 커브드 영상출력을 위한 메타렌즈 제어값을 생성하기 위해서는 중심점(가운데)으로부터 수평(x축 좌표)로 부터 멀어질수록 줌의 정도가 비례하여 적용될 필요성이 있다. 따라서, 초점거리()를 통한 메타렌즈 제어는 화면 전체의 균일한 줌 효과를 사용하지만, 커브드 영상출력은 원점이 포함된 중심선에서 x축 수평방향으로 다 르게 줌 효과가 적용될 필요성이 있다. 일 예로, 도 26(b)는 메타렌즈 곡률변경에 따른 커브드 영상 출력장치와 각 위치별 배율을 나타낸 도면이다. 도 26(b)를 참조하면, 메타렌즈 줌배율을 위치에 따르게 적용된 렌즈 적용 값을 사용해야 할 수 있다. 따라서, 기본적인 3군줌렌즈외에 추가적인 메타렌즈의 층이 필요할 수 있다. 또 다른 일 예로, 도 27은 본 개시의 일 실시예에 따라 다양한 영상 입출력 장치들의 연합학습을 통해 동작하는 시스템을 나타낸 도면이다. 일 예로, 도 27을 참조하면, 연합학습은 기지국을 통해서 AirComp로 동작이 가능한 경우일 수 있다. 이때, 영상 입출력 장치들은 실내 또는 실외에 존재할 수 있다. 일 예로, 영상 입출력 장치는 다양한 위치 및 거리에 기지국으로 자신의 로컬 모델 정보를 전달하고, 기지국은 전달받은 로컬 모델 정보에 기 초하여 글로벌 모델 정보를 업데이트하여 각각의 단말들에게 제공할 수 있다. 이때, 각각의 단말들은 영상 입출 력 장치일 수 있다. 일 예로, 연합학습은 다양한 위치와 거리에서의 영상 입력장치(카메라)등을 통해서 영상 입 출력 장치의 제어가 제대로 동작하는지를 확인하는 용도로 사용될 수 있으며, 이를 통해 새로운 서비스 창출을 수행할 수 있다. 도 28은 본 개시의 일 실시예에 따라 기지국 동작 방법을 나타낸 도면이다. 도 28을 참조하면, 기지국은 제 1 단말로부터 사용자 인식 정보를 수신할 수 있다.(S2810) 이때, 기지국은 단말과 통신을 수행하는 장치일 수 있 다. 또 다른 일 예로, 기지국은 상술한 서버나 엑세스 포인트일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 또한, 일 예로, 제 1 단말은 영상 입력장치일 수 있다. 또 다른 일 예로, 제 1 단말은 영상 입력 기능을 구비한 장치일 수 있으며, 특정 형태로 한정되지 않는다. 또한, 일 예로, 제 2 단말은 영상 출력 장치일 수 있 다. 또 다른 일 예로, 제 2 단말은 영상 출력 기능을 구비한 장치일 수 있으며, 특정 형태로 한정되지 않는다. 또한, 일 예로, 제 1 단말과 제 2 단말은 하나의 장치에 구현될 수 있으며, 특정 형태로 한정되지 않는다. 기지국이 제 1 단말로부터 사용자 인식 정보를 수신한 경우, 기지국은 사용자 인식 정보를 이용하여 메타렌즈 특성인자에 기초하여 제어 값을 획득할 수 있다.(S2820) 그 후, 기지국은 획득한 제어 값을 제 1 단말 및 제 2 단말로 전송할 수 있다.(S2830) 이때, 일 예로, 제어 값은 메타렌즈 특성인자에 기초하여 코드북 기반으로 결정 될 수 있다. 여기서, 메타렌즈 특성인자는 메타렌즈 요소들 각각에 기초하여 초점 위치 정보, 초점 거리 정보 및 곡률 반경 정보 중 적어도 어느 하나에 기초하여 결정될 수 있다. 또한, 초점 위치 정보, 초점 거리 정보 및 곡률 반경 정보는 양자화에 기초하여 각각의 인덱스로 표현되고, 제어 값은 각각의 인덱스에 기초하여 도출될 수 있으며, 이는 상술한 바와 같다. 또한, 일 예로, 사용자 인식 정보는 사용자 방향 정보, 사용자 거리 정보 및 사용자 상태 정보 중 적어도 어느 하나 이상을 포함할 수 있으며, 이는 상술한 바와 같다. 이때, 일 예로, 제 1 단말은 제 1 단말의 위치 정보를 획득하고, 제 1 단말의 위치 정보를 사용자 인식 정보와 함께 기지국으로 전달할 수 있다. 기지국은 제 1 단말의 위치 정보를 더 고려하여 제어 값을 도출할 수 있으며, 이는 상술한 바와 같다. 또한, 일 예로, 기지국은 메타렌즈 인공지능 시스템을 구비하고, 메타렌즈 인공지능 시스템은 학습모델에 기초 하여 학습을 수행할 수 있다. 이때, 획득된 사용자 인식 정보는 학습모델의 입력이고, 제어 값은 학습모델의 출 력일 수 있다. 구체적인 일 예로, 학습모델은 강화학습에 기초하여 동작하고, 강화학습은 획득한 사용자 인식 정보 및 제어 값에 기초하여 상태 정보 및 보상 정보를 입력으로 사용할 수 있다. 또한, 제어 값에 대응되는 행 동 정보를 출력할 수 있으며, 이는 상술한 바와 같다. 또 다른 일 예로, 학습모델은 톰슨 샘플링에 기초하여 동작하고, 톰슨 샘플링은 획득한 사용자 인식 정보 및 제 어 값에 기초하여 α 및 β 파라미터를 갖는 보상 정보에 기초하여 학습을 수행할 수 있으며, 이는 상술한 바와 같다. 도 29는 본 개시의 일 실시예에 따라 단말의 동작 방법을 나타낸 순서도이다. 도 29를 참조하면, 단말은 기지국 으로 사용자 인식 정보를 전송할 수 있다.(S2910) 이때, 단말은 도 28의 제 1 단말일 수 있다. 또한, 일 예로, 단말은 제 1 단말 및 제 2 단말이 함께 구현된 장치일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 그 후, 단말은 전달된 사용자 인식 정보에 기초하여 기지국에 의해 도출된 제어 값을 수신할 수 있다.(S2920) 이때, 일 예로, 제어 값은 메타렌즈 특성인자에 기초하여 코드북 기반으로 결정될 수 있다. 여기서, 메타렌즈 특성인자는 메타렌즈 요소들 각각에 기초하여 초점 위치 정보, 초점 거리 정보 및 곡률 반경 정보 중 적어도 어 느 하나에 기초하여 결정될 수 있다. 또한, 초점 위치 정보, 초점 거리 정보 및 곡률 반경 정보는 양자화에 기 초하여 각각의 인덱스로 표현되고, 제어 값은 각각의 인덱스에 기초하여 도출될 수 있으며, 이는 상술한 바와 같다. 또한, 일 예로, 사용자 인식 정보는 사용자 방향 정보, 사용자 거리 정보 및 사용자 상태 정보 중 적어도 어느 하나 이상을 포함할 수 있으며, 이는 상술한 바와 같다. 이때, 일 예로, 제 1 단말은 제 1 단말의 위치 정 보를 획득하고, 제 1 단말의 위치 정보를 사용자 인식 정보와 함께 기지국으로 전달할 수 있다. 기지국은 제 1 단말의 위치 정보를 더 고려하여 제어 값을 도출할 수 있으며, 이는 상술한 바와 같다. 또한, 일 예로, 기지국은 메타렌즈 인공지능 시스템을 구비하고, 메타렌즈 인공지능 시스템은 학습모델에 기초 하여 학습을 수행할 수 있다. 이때, 획득된 사용자 인식 정보는 학습모델의 입력이고, 제어 값은 학습모델의 출 력일 수 있다. 구체적인 일 예로, 학습모델은 강화학습에 기초하여 동작하고, 강화학습은 획득한 사용자 인식 정보 및 제어 값에 기초하여 상태 정보 및 보상 정보를 입력으로 사용할 수 있다. 또한, 제어 값에 대응되는 행 동 정보를 출력할 수 있으며, 이는 상술한 바와 같다. 또 다른 일 예로, 학습모델은 톰슨 샘플링에 기초하여 동작하고, 톰슨 샘플링은 획득한 사용자 인식 정보 및 제 어 값에 기초하여 α 및 β 파라미터를 갖는 보상 정보에 기초하여 학습을 수행할 수 있으며, 이는 상술한 바와 같다. 상기 설명한 제안 방식에 대한 일례들 또한 본 개시의 구현 방법들 중 하나로 포함될 수 있으므로, 일종의 제안 방식들로 간주될 수 있음은 명백한 사실이다. 또한, 상기 설명한 제안 방식들은 독립적으로 구현될 수도 있지만, 일부 제안 방식들의 조합 (또는 병합) 형태로 구현될 수도 있다. 상기 제안 방법들의 적용 여부 정보 (또는 상기 제안 방법들의 규칙들에 대한 정보)는 기지국이 단말에게 사전에 정의된 시그널 (예: 물리 계층 시 그널 또는 상위 계층 시그널)을 통해서 알려주도록 규칙이 정의될 수 가 있다. 본 개시는 본 개시에서 서술하는 기술적 아이디어 및 필수적 특징을 벗어나지 않는 범위에서 다른 특정한 형태 로 구체화될 수 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 개시의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 개시의 등가적 범위 내에서의 모든 변경은 본 개시의 범위에 포함된다. 또한, 특허청구범위에서 명시적인 인용 관계가 있지 않은 청구항들을 결합하여 실시 예를 구성하거나 출원 후의 보정에 의해 새로운 청구항으로 포함할 수 있 다. 산업상 이용가능성 본 개시의 실시 예들은 다양한 무선접속 시스템에 적용될 수 있다. 다양한 무선접속 시스템들의 일례로서, 3GPP(3rd Generation Partnership Project) 또는 3GPP2 시스템 등이 있다. 본 개시의 실시 예들은 상기 다양한 무선접속 시스템뿐 아니라, 상기 다양한 무선접속 시스템을 응용한 모든 기 술 분야에 적용될 수 있다. 나아가, 제안한 방법은 초고주파 대역을 이용하는 mmWave, THz 통신 시스템에도 적 용될 수 있다. 추가적으로, 본 개시의 실시예들은 자유 주행 차량, 드론 등 다양한 애플리케이션에도 적용될 수 있다."}
{"patent_id": "10-2024-7001470", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하에 첨부되는 도면들은 본 개시에 관한 이해를 돕기 위한 것으로, 상세한 설명과 함께 본 개시에 대한 실시 예들을 제공할 수 있다. 다만, 본 개시의 기술적 특징이 특정 도면에 한정되는 것은 아니며, 각 도면에서 개시 하는 특징들은 서로 조합되어 새로운 실시 예로 구성될 수 있다. 각 도면에서의 참조 번호(reference numeral s)들은 구조적 구성요소(structural elements)를 의미할 수 있다. 도 1은 본 개시의 일 실시예에 따라 통신 시스템 예시를 나타낸 도면이다. 도 2는 본 개시의 일 실시예에 따라 무선 기기의 예시를 나타낸 도면이다.도 3은 본 개시의 일 실시예에 따라 무선 기기의 다른 예시를 나타낸 도면이다. 도 4는 본 개시의 일 실시예에 따라 AI(Artificial Intelligence)의 예시를 나타낸 도면이다. 도 5는 본 개시의 일 실시예에 따라 연합학습을 나타낸 도면이다. 도 6은 본 개시의 일 실시예에 있어서 영상입출력 장치를 나타낸 도면이다. 도 7은 본 개시의 실시예에 따라 OIS 원리를 나타낸 도면이다. 도 8은 본 개시의 일 실시예에 따라 메타렌즈 구조를 나타낸 도면이다. 도 9는 본 개시의 일 실시예에 따라 사용자 기반의 영상 입출력을 위한 메타렌즈를 제어하는 인공지능 시스템을 나타낸 도면이다. 도 10은 본 개시의 일 실시예에 따라 메타렌즈를 제어하는 방법을 나타낸 도면이다. 도 11은 본 개시의 일 실시예에 따라 커브드와 플랫 영상출력의 시청거리 비교를 나타낸 도면이다. 도 12는 본 개시의 일 실시예에 따라 커브드와 플랫 영상출력의 시청거리 비교를 나타낸 도면이다. 도 13은 본 개시의 일 실시예에 따라 메타렌즈 제어 방법을 나타낸 도면이다. 도 14은 본 개시의 일 실시예에 따라 분산 학습 인공지능 시스템의 동작을 나타낸 도면이다. 도 15는 본 개시의 일 실시예에 따라 인공지능 시스템에 기초하여 메타렌즈를 제어하는 방법을 나타낸 도면이다. 도 16은 본 개시의 일 실시예에 따라 메타렌즈에 기초하여 영상 입출력을 제어하는 방법을 나타낸 순서도이다. 도 17은 본 개시의 일 실시예에 따라 사용자 인식부에서 대상을 검출하는 방법을 나타낸 도면이다. 도 18은 본 개시의 일 실시예에 따라 사용자 인식부에서 대상을 검출하는 방법을 나타낸 도면이다. 도 19는 본 개시의 일 실시예에 따라 최종 입출력을 나타낸 도면이다. 도 20은 본 개시의 일 실시예에 따라, 강화학습 (또는 MAB)을 사용한 메타렌즈 제어 시스템 구조를 나타낸 도면 이다. 도 21은 본 개시의 일 실시예에 따라 강화학습을 사용한 메타렌즈 제어 시스템 블록도를 나타낸 도면이다. 도 22는 본 개시의 일 실시예에 따라 DDPG를 사용한 강화학습을 나타낸 도면이다. 도 23은 본 개시의 일 실시예에 따라 톰슨 샘플링(Thompson Sampling)을 사용한 선택인공지능 (MAB AI, 2310) 시스템을 나타낸 도면이다. 도 24는 본 개시의 일 실시예에 따라 메타렌즈 제어기의 구조를 나타낸 도면이다. 도 25는 본 개시의 일 실시예에 따라 초점 위치에 기초하여 메타렌즈 제어 값을 생성하는 방법을 나타낸 도면이 다. 도 26은 본 개시의 일 실시예에 따라 메타렌즈 곡률변경에 기초하여 줌 렌즈 및 커브드를 구현하는 방법을 나타 낸 도면이다. 도 27은 본 개시의 일 실시예에 따라 다양한 영상 입출력 장치들의 연합학습을 통해 동작하는 시스템을 나타낸 도면이다. 도 28은 본 개시의 일 실시예에 따라 기지국 동작 방법을 나타낸 도면이다. 도 29는 본 개시의 일 실시예에 따라 단말의 동작 방법을 나타낸 순서도이다."}
