{"patent_id": "10-2023-0035788", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0141432", "출원번호": "10-2023-0035788", "발명의 명칭": "태스크 병렬 처리 방법 및 시스템", "출원인": "리벨리온 주식회사", "발명자": "김현호"}}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해서 수행되는, 태스크 병렬 처리 방법에 있어서,제1 인스트럭션(instruction)과 연관된 제1 태스크(task)를 수행하는 단계;상기 제1 인스트럭션이 버스트 로드 인스트럭션인지 여부를 판정하는 단계;상기 제1 인스트럭션이 버스트 로드 인스트럭션으로 판정된 것에 응답하여, 제2 인스트럭션을 획득하는 단계;및상기 획득된 제2 인스트럭션과 연관된 제2 태스크를 수행하는 단계를 포함하고, 상기 제1 태스크와 상기 제2 태스크는 병렬적으로 수행되는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2 인스트럭션은 버스트 로드 인스트럭션이고, 상기 제2 인스트럭션의 버스트 크기(size)와 상기 제1 인스트럭션의 버스트 크기 간의 차이는 임계범위 이내이고, 상기 제2 태스크를 수행하는 단계는,상기 제2 인스트럭션의 버스트 크기에 기초하여, 복수의 리퀘스트를 생성하는 단계를 포함하는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제2 태스크는, 상기 복수의 리퀘스트 생성과 연관된 복수의 인스트럭션 및 상기 복수의 리퀘스트 실행과연관된 복수의 인스트럭션이 포함된 파이프라인 구조로 생성되는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 복수의 리퀘스트를 생성하는 단계는,상기 제2 인스트럭션과 연관된 목적지를 식별하는 단계; 및복수의 리퀘스트 큐 중에서, 상기 식별된 목적지와 연관된 리퀘스트 큐에 상기 생성된 복수의 리퀘스트를 저장하는 단계를 포함하는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0141432-3-제4항에 있어서,상기 복수의 리퀘스트를 생성하는 단계 이후에, 복수의 저장 영역 중에서, 상기 식별된 목적지와 연관된 저장 영역을 식별하는 단계; 및상기 목적지와 연관된 리퀘스트 큐에 저장된 리퀘스트를 기초하여 이슈(issue)된 데이터를 상기 식별된 저장 영역에 저장하는 단계를 더 포함하는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제2 태스크는, 상기 제1 태스크가 개시된 주기로부터 미리 결정된 주기 이후에 시작되는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제2 태스크를 수행하는 단계 이후에,제3 인스트럭션을 획득하는 단계; 및상기 획득된 제3 인스트럭션과 연관된 제3 태스크를 수행하는 단계를 더 포함하고, 상기 제1 태스크와 상기 제3 태스크는 병렬적으로 수행되는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제3 인스트럭션을 획득하는 단계는, 상기 제1 인스트럭션 및 상기 제2 인스트럭션 각각과 목적지가 상이한 버스트 로드 인스트럭션이 대기 중이라는판정에 응답하여, 상기 대기 중인 버스트 로드 인스트럭션을 상기 제3 인스트럭션으로 결정하는 단계; 상기 결정된 제3 인스트럭션을 페치(fetch)하는 단계; 및상기 페치된 제3 인스트럭션을 디코딩하는 단계를 포함하는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 제1 인스트럭션, 상기 제2 인스트럭션 및 상기 제3 인스트럭션의 각각은 서로 목적지가 상이한 인스트럭션인, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,공개특허 10-2024-0141432-4-상기 제2 태스크와 상기 제3 태스크는, 캐시(cache)에 기록된 데이터를 변경(modulate)시키기 위한 제4 태스크가 수행되기 전에 시작되는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 제2 태스크를 수행하는 단계 이후에,캐시에 데이터가 기록(write)된 것에 응답하여, 상기 기록된 데이터를 변경시키기 위한 제4 태스크를 수행하는단계를 더 포함하고,상기 제2 태스크와 상기 제4 태스크는 병렬적으로 수행되는, 태스크 병렬 처리 방법."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "프로세싱 시스템으로서,적어도 하나의 인스트럭션과 연관된 데이터를 저장하는 메모리; 및상기 메모리로의 액세스 오퍼레이션(access operation)을 수행하도록 구성된 적어도 하나의 로드 유닛(loadunit)를 포함하고,상기 로드 유닛은, 버스트 로드 인스트럭션과 연관된 제1 태스크가 수행되는 것에 응답하여 추가적인 제2 태스크를 수행하되, 상기 제1 태스크와 상기 제2 태스크를 병렬적으로 수행하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 로드 유닛은, 상기 제1 태스크가 버스트 로드 인스트럭션과 연관된 태스크인 것에 응답하여, 상기 제2 태스크와 연관된 인스트럭션을 페치하고, 상기 페치된 제2 태스크와 연관된 인스트럭션을 디코딩하도록 구성된,프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 제2 태스크는 버스트 로드 인스트럭션과 연관된 태스크이고, 상기 제1 태스크와 연관된 버스트 로드 인스트럭션의 제1 크기와 상기 제2 태스크와 연관된 버스트 로드 인스트럭션의 제2 크기 간의 차이는 임계범위 이내이고, 상기 로드 유닛은, 상기 제2 크기에 기초하여, 복수의 리퀘스트를 생성하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제2 태스크는, 상기 복수의 리퀘스트 생성과 연관된 복수의 인스트럭션 및 상기 복수의 리퀘스트 실행과연관된 복수의 인스트럭션이 포함된 파이프라인 구조로 생성되는, 프로세싱 시스템.공개특허 10-2024-0141432-5-청구항 16 제14항에 있어서,상기 로드 유닛은, 상기 제2 태스크와 연관된 목적지를 식별하고, 복수의 리퀘스트 큐 중에서 상기 식별된 목적지와 연관된 리퀘스트 큐에 상기 생성된 복수의 리퀘스트를 저장하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 로드 유닛은, 복수의 저장 영역 중에서, 상기 식별된 목적지와 연관된 저장 영역을 식별하고, 상기 목적지와 연관된 리퀘스트 큐에 저장된 리퀘스트를 기초하여 이슈(issue)된 데이터를 상기 식별된 저장 영역에 저장하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 로드 유닛은, 인스트럭션을 추가적으로 획득하고, 상기 획득된 인스트럭션과 연관된 제3 태스크를 수행하되, 상기 제3 태스크를 상기 제1 태스크와 병렬적으로 수행하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 로드 유닛은, 캐시에 기록된 데이터를 변경하기 위한 제4 태스크를 수행하기 전에 상기 제2 태스크와 상기제3 태스크를 시작하도록 구성되는, 프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 로드 유닛은, 캐시에 데이터가 기록된 것에 응답하여, 상기 기록된 데이터를 변경하기 위한 제4 태스크를수행하도록 구성된, 프로세싱 시스템."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 적어도 하나의 프로세서에 의해 수행되는 태스크 병렬 처리 방법이 제공된다. 이 방법은, 제1 인스트 럭션(instruction)과 연관된 제1 태스크(task)를 수행하는 단계, 제1 인스트럭션이 버스트 로드 인스트럭션인지 여부를 판정하는 단계, 제1 인스트럭션이 버스트 로드 인스트럭션으로 판정된 것에 응답하여, 제2 인스트럭션을 획득하는 단계 및 획득된 제2 인스트럭션과 연관된 제2 태스크를 수행하는 단계를 포함하고, 제1 태스크와 제2 태스크는 병렬적으로 수행될 수 있다."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 태스크를 병렬적으로 처리하는 방법에 관한 것으로, 구체적으로, 인스트럭션(instruction) 기반으로 동작하는 프로세싱 시스템에서 태스크를 병렬적으로 처리하기 위한 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인스트럭션 기반으로 동작하는 프로세싱 시스템은 데이터를 로드(load)한 후, 로드된 데이터를 기초로 실행/연 산된 결과를 지정된 목적지로 전송한다. 인스트럭션 기반으로 동작하는 프로세싱 시스템의 스루풋(throughpu t)을 증가시키기 위하여, 파이프라인(pipeline)이 이용되기도 한다. 파이프라인은 데이터를 연속적으로 처리하 여, 프로세싱 시스템의 성능을 향상시키기 위한 기법이다. 그런데 파이프라인 구조의 복수의 버스트 로드 인스트럭션이 페치(fetch)되는 경우, 프로세싱 시스템은 복수의 주기 동안에, 버스트 로드 인스트럭션과 연관된 복수의 데이터를 로드해야 된다. 버스트 로드 인스트럭션 (instruction)과 관련된 모든 데이터에 대한 로드가 완료되기 전까지, 프로세싱 시스템이 버스트 로드 인스트럭션과 연관된 후속 프로세스(가령, 변경 연산 프로세스)를 처리하지 못하고 대기하는 스톨(stall)이 발생될 수 있다. 스톨이 발생한 경우, 프로세싱 시스템의 스루풋이 저하될 수 있다."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상기와 같은 문제점을 해결하기 위한 태스크 병렬 처리 방법, 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램, 컴퓨터 판독 가능한 기록 매체 및 장치(시스템)를 제공한다."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 방법, 장치(시스템) 및/또는 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램을 포함한 다양한 방식으로 구현될 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서에 의해서 수행되는 태스크 병렬 처리 방법은, 제1 인스 트럭션과 연관된 제1 태스크(task)를 수행하는 단계, 제1 인스트럭션이 버스트 로드 인스트럭션인지 여부를 판 정하는 단계, 제1 인스트럭션이 버스트 로드 인스트럭션으로 판정된 것에 응답하여, 제2 인스트럭션을 획득하는 단계 및 획득된 제2 인스트럭션과 연관된 제2 태스크를 수행하는 단계를 포함하고, 제1 태스크와 제2 태스크는 병렬적으로 수행될 수 있다. 또한, 제2 인스트럭션은 버스트 로드 인스트럭션이고, 제2 인스트럭션의 버스트 크기(size)와 제1 인스트럭션의 버스트 크기 간의 차이는 임계범위 이내이고, 제2 태스크를 수행하는 단계는, 제2 인스트럭션의 버스트 크기에 기초하여, 복수의 리퀘스트를 생성하는 단계를 포함할 수 있다. 또한, 제2 태스크는 복수의 리퀘스트 생성과 연관된 복수의 인스트럭션 및 복수의 리퀘스트 실행과 연관된 복수 의 인스트럭션이 포함된 파이프라인 구조로 생성될 수 있다. 또한, 복수의 리퀘스트를 생성하는 단계는, 제2 인스트럭션과 연관된 목적지를 식별하는 단계 및 복수의 리퀘스 트 큐 중에서, 식별된 목적지와 연관된 리퀘스트 큐에 생성된 복수의 리퀘스트를 저장하는 단계를 포함할 수 있 다. 또한, 태스크 병렬 처리 방법은 복수의 리퀘스트를 생성하는 단계 이후에, 복수의 저장 영역 중에서, 식별된 목 적지와 연관된 저장 영역을 식별하는 단계 및 목적지와 연관된 리퀘스트 큐에 저장된 리퀘스트를 기초하여 이슈 (issue)된 데이터를 식별된 저장 영역에 저장하는 단계를 더 포함할 수 있다. 또한, 제2 태스크는, 제1 태스크가 개시된 주기로부터 미리 결정된 주기 이후에 시작될 수 있다. 또한, 태스크 병렬 처리 방법은 제2 태스크를 수행하는 단계 이후에, 제3 인스트럭션을 획득하는 단계 및 획득 된 제3 인스트럭션과 연관된 제3 태스크를 수행하는 단계를 더 포함하고, 제1 태스크와 제3 태스크는 병렬적으 로 수행될 수 있다. 또한, 제3 인스트럭션을 획득하는 단계는, 제1 인스트럭션 및 제2 인스트럭션 각각과 목적지가 상이한 버스트 로드 인스트럭션이 대기 중이라는 판정에 응답하여, 대기 중인 버스트 로드 인스트럭션을 제3 인스트럭션으로 결정하는 단계, 결정된 제3 인스트럭션을 페치(fetch)하는 단계 및 페치된 제3 인스트럭션을 디코딩하는 단계를 포함할 수 있다. 또한, 제1 인스트럭션, 제2 인스트럭션 및 제3 인스트럭션의 각각은 서로 목적지가 상이한 인스트럭션일 수 있 다. 또한, 제2 태스크와 제3 태스크는, 캐시(cache)에 기록된 데이터를 변경(modulate)시키기 위한 제4 태스크가 수 행되기 전에 시작될 수 있다. 또한, 태스크 병렬 처리 방법은 제2 태스크를 수행하는 단계 이후에, 캐시에 데이터가 기록(write)된 것에 응답 하여, 기록된 데이터를 변경시키기 위한 제4 태스크를 수행하는 단계를 더 포함하고, 제2 태스크와 제4 태스크 는 병렬적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면 프로세싱 시스템은, 적어도 하나의 인스트럭션과 연관된 데이터를 저장하는 메모 리 및 메모리로의 액세스 오퍼레이션(access operation)을 수행하도록 구성된 적어도 하나의 로드 유닛(load unit)를 포함하고, 로드 유닛은, 버스트 로드 인스트럭션과 연관된 제1 태스크가 수행되는 것에 응답하여 추가적인 제2 태스크를 수행하되, 제1 태스크와 제2 태스크를 병렬적으로 수행하도록 구성될 수 있다."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예에 따르면, 복수의 태스크가 병렬적으로 처리되어, 프로세싱 시스템의 스루풋이 대폭 향 상될 수 있다. 본 개시의 일부 실시예에 따르면, 버스트 로드 인스트럭션과 연관된 제1 태스크가 수행되는 경우, 제1 태스크의 목적지과 상이한 목적지를 가지는 제2 태스크가 추가적으로 수행되어, 프로세싱 시스템에서 발생되는 스톨 (stall)이 최소화되거나 제거될 수 있다. 본 개시의 일부 실시예에 따르면, 버스트 로드 인스트럭션의 크기(size)의 임계범위 이내의 크기 차이를 가지는 추가적인 버스트 로드 인스트럭션이 병렬적으로 수행되어, 프로세싱 시스템의 성능(performance)이 극대화될 수 있다. 본 개시의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 다른 효과들은 청구범위의 기재로부"}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자('통상의 기술자'라 함)에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예 들의 설명에 있어서, 동일하거나 대응되는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나, 구성 요소에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나, 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 통상의 기술 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서, 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어 가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또한, 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체 에서 어떤 부분이 어떤 구성요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 '모듈' 또는 '부'라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, '모 듈' 또는 '부'는 어떤 역할들을 수행한다. 그렇지만, '모듈' 또는 '부'는 소프트웨어 또는 하드웨어에 한정되 는 의미는 아니다. '모듈' 또는 '부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서, '모듈' 또는 '부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이 크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 또는 변수들 중 적어도 하나를 포 함할 수 있다. 구성요소들과 '모듈' 또는 '부'들은 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '모듈' 또는 '부'들로 결합되거나 추가적인 구성요소들과 '모듈' 또는 '부'들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면, '모듈' 또는 '부'는 프로세서 및 메모리로 구현될 수 있고, 회로(circuit, circuitry)로 구현될 수 있다. '회로(circuit, circuitry)'와 같은 용어는 하드웨어 상의 회로를 의미하기도 하지만 소프트웨어 상의 회로를 의미할 수도 있다. '프로세서'는 범용 프로세서, 중앙 처리 장치(CPU), 마이크 로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크로제어기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서, '프로세서'는 주문형 반도체(ASIC), 프로그램가능 로직 디바이스(PLD), 필드 프로그램가 능 게이트 어레이(FPGA) 등을 지칭할 수도 있다. '프로세서'는, 예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있다. 또한, '메모리'는 전자 정보 를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한다. '메모리'는 임의 액세스 메모리 (RAM), 판독-전용 메모리(ROM), 비-휘발성 임의 액세스 메모리(NVRAM), 프로그램가능 판독-전용 메모리(PROM), 소거-프로그램가능 판독 전용 메모리(EPROM), 전기적으로 소거가능 PROM(EEPROM), 플래쉬 메모리, 자기 또는 마 킹 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체의 다양한 유형들을 지칭할 수도 있다. 프 로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기록할 수 있다면 메모리는 프로세서와 전자 통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서와 전자 통신 상태에 있다. 본 개시에서, '복수의 A의 각각' 또는 '복수의 A 각각'은 복수의 A에 포함된 모든 구성 요소의 각각을 지칭하거 나, 복수의 A에 포함된 일부 구성 요소의 각각을 지칭할 수 있다. 또한, 이하의 실시예들에서 사용되는 제1, 제2, A, B, (a), (b) 등의 용어는 어떤 구성요소를 다른 구성요소와 구별하기 위해 사용되는 것일 뿐, 그 용어에 의해 해당 구성요소의 본질이나 차례 또는 순서 등이 한정되지는 않는다. 또한, 이하의 실시예들에서, 어떤 구성요소가 다른 구성요소에 '연결', '결합' 또는 '접속'된다고 기재된 경우, 그 구성요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성요소 사이에 또 다른 구성요소가 '연결', '결합' 또는 '접속'될 수도 있다고 이해되어야 한다. 또한, 이하의 실시예들에서 사용되는 '포함한다(comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요 소, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제 하지 않는다. 본 개시의 다양한 실시예들을 설명하기에 앞서, 사용되는 용어에 대하여 설명하기로 하기로 한다. 본 개시의 실시예들에서, '인스트럭션(instruction)'은 프로세싱 시스템에 의해 실행되는 적어도 하나의 명령어 일 수 있다. 예컨대, 인스트럭션은 기계어(assembly language) 기반의 명령어일 수 있다. 본 개시의 실시예들에서, '태스크(task)'는 적어도 하나의 인스트럭션에 기초하여 수행되는 작업 단위일 수 있 다. 예컨대, 프로세싱 시스템은 적어도 하나의 인스트럭션에 기초하여 태스크를 수행할 수 있다. 태스크가 수행되는 것은 데이터를 로드하는 것, 로드된 데이터를 실행하는 것, 실행 결과를 저장하는 것 또는 저장된 결과 를 목적지로 전송하는 것 중에서 적어도 하나를 포함할 수 있다. 이하, 본 개시의 다양한 실시예들에 대하여 첨부된 도면에 따라 상세하게 설명한다. 도 1은 본 개시의 일 실시예에 따른, 프로세싱 시스템을 설명하기 위한 블록도이다. 도 1을 참조하면, 본 개시 의 일 실시예에 따른 프로세싱 시스템은 프로세싱 장치, 호스트 시스템(HS) 및 호스트 인터페이스(HIO)를 포 함할 수 있다. 프로세싱 장치는 인스트럭션 기반의 연산을 수행하는 장치일 수 있다. 프로세싱 장치는 뉴럴 프로세싱 장치(NPU, neural processing unit), 그래픽 프로세싱 장치(GPU, graphics processing unit), 중앙 처리 장치 (CPU, central processing unit) 및 그 외의 다른 종류의 프로세싱 장치를 포함할 수 있다. 프로세싱 장치 가 뉴럴 프로세싱 유닛을 포함하는 경우, 프로세싱 장치는 인공 신경망을 이용하여 연산을 수행하는 장치 일 수 있다. 가령, 프로세싱 장치는 딥 러닝(deep learning) 연산 작업을 수행하는 것에 특화된 장치일 수 있다. 호스트 시스템(HS)은 프로세싱 장치에 연산 작업을 지시하고, 연산 작업의 결과를 회수하는 시스템일 수 있 다. 호스트 인터페이스(HIO)는 프로세싱 장치와 호스트 시스템(HS) 사이에서 데이터 및 컨트롤 신호를 전송할 수 있다. 호스트 인터페이스(HIO)는 예를 들어, 호스트 시스템(HS)의 커맨드 및 데이터를 프로세싱 장치로 전 달할 수 있고, 이에 따라 프로세싱 장치가 연산 작업을 수행할 수 있다. 프로세싱 장치는 연산 작업을 완료하면 이에 대한 결과를 인터럽트 요청을 통해서 호스트 시스템(HS)으로 전달할 수 있다. 호스트 인터페이 스(HIO)는 예를 들어, PCIe(PCI Express)일 수 있으나, 이에 제한되는 것은 아니다. 도 2는 본 개시의 일 실시예에 따른, 도 1의 뉴럴 프로세싱 장치를 세부적으로 설명하기 위한 블록도이다. 도 2를 참조하면, 프로세싱 장치는 코어 SoC, 오프 칩 메모리, 비휘발성 메모리 인터페이스 및 휘발성 메모리 인터페이스를 포함할 수 있다. 도 2는 프로세싱 장치의 일 예시일 뿐, 프로세싱 장치 의 필수적 구성만을 도시한 것이 아니며, 프로세싱 장치의 모든 구성을 도시한 것이 아니므로, 도시된 구 성 중 적어도 일부가 생략되고/되거나, 다른 구성이 더 포함될 수 있다. 코어 SoC는 적어도 하나의 프로세서를 포함하는 시스템 온 칩(System on Chip) 장치일 수 있다. 일 실시예 에 따르면, 코어 SoC는 연산 작업을 수행하기 위한 태스크를 분배/관리하고, 메모리 할당을 관리할 수 있다. 코어 SoC는 인공지능 연산 유닛으로 가속기(Accelerator)를 포함할 수 있다. 예를 들어, 코어 SoC는 인공지능 응용 프로그램을 위한 매트릭스 연산에 특화된 하나 이상의 처리 장치 및/또는 뉴럴 프로세 서를 포함할 수 있다. 다른 예로서, 코어 SoC는 CPU(Central Processing Unit)나 GPU(Graphics Processing Unit), GPU(graphics processing unit), FPGA(field programmable gate array) 또는 ASIC(application-specific integrated circuit) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 도 1에서 코어 SoC는 단일 칩인 것처럼 도시되어 있으나, 이는 설명의 편의를 위한 것일 뿐 이에 한정되지 않는다. 예를 들어, 코어 SoC는 별도의 단일 혹은 복수의 칩으로 구현될 수도 있고, 시스템 상에 결합된 SoC(System on Chip)의 일부로 구현될 수도 있다. 코어 SoC는 별도의 외부 인터페이스(예를 들어, 호스트 인터페이스 등)를 통해서 다른 외부의 연산 유닛들 과 데이터를 교환할 수 있다. 또한, 코어 SoC는 비휘발성 메모리 인터페이스 및 휘발성 메모리 인터페 이스를 통해서 각각 비휘발성 메모리 및 휘발성 메모리와 연결될 수 있다. 오프 칩 메모리는 코어 SoC의 칩 외부에 배치된 메모리일 수 있다. 오프 칩 메모리는 인스트럭션 과 연관된 데이터가 저장되거나 로딩되는 장치일 수 있다. 오프 칩 메모리는 비휘발성 메모리 및 휘발 성 메모리를 포함할 수 있다. 비휘발성 메모리는 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 메모리일 수 있다. 비휘발성 메 모리는 예를 들어, ROM(Read-Only Memory), PROM(Programmable Read-Only Memory), EAROM(Erasable Alterable ROM), EPROM(Erasable Programmable Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory)(예를 들어, 낸드 플래시 메모리(NAND Flash memory), 노어 플래시 메모리(NOR Flash memory)), UVEPROM(Ultra-Violet Erasable Programmable Read-Only Memory), FeRAM(FerroelectricRandom Access Memory), MRAM(Magnetoresistive Random Access Memory), PRAM(Phase-change Random Access Memory), SONOS(silicon-oxide-nitride-oxide-silicon), RRAM(Resistive Random Access Memory), NRAM(Nanotube Random Access Memory), 마그네틱 컴퓨터 기억 장치(예를 들면, 하드 디스크, 디스켓 드라이브, 마그네틱 테이프), 광디스크 드라이브 및 3D 크로스포인트 메모리(3D XPoint memory) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 휘발성 메모리는 비휘발성 메모리와 달리, 저장된 정보를 유지하기 위해서 전력을 지속적으로 필요로 하는 메모리일 수 있다. 휘발성 메모리는 예를 들어, DRAM(Dynamic Random Access Memory), SRAM(Static Random Access Memory), SDRAM(Synchronous Dynamic Random Access Memory) 및 DDR SDRAM(Double Data Rate SDRAM) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 비휘발성 메모리 인터페이스는 예를 들어, PATA(Parallel Advanced Technology Attachment), SCSI(Small Computer System Interface), SAS(Serial Attached SCSI), SATA(Serial Advanced Technology Attachment) 및 PCIe(PCI Express) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 휘발성 메모리 인터페이스는 예를 들어, SDR(Single Data Rate), DDR(Double Data Rate), QDR(Quad Data Rate), 및 XDR(eXtreme Data Rate, Octal Data Rate) 중 적어도 하나일 수 있다. 단, 본 실시예가 이에 제한 되는 것은 아니다. 도 3은 본 개시의 일 실시예에 따른, 도 1의 코어 SoC를 세부적으로 설명하기 위한 블록도이다. 도 3에 도 시된 바와 같이, 코어 SoC는 로드 유닛, 태스크 컨트롤러 및 온 칩 버퍼를 포함할 수 있다. 외부 인터페이스는 컨트롤 버스 및 데이터 버스를 포함할 수 있다. 외부 인터페이스는 도 2의 비휘발성 메모리 인터페이스 및/또는 휘발성 메모리 인터페이스에 포함될 수 있다. 일 실시예에 따르면, 컨트롤 버스는 제어 신호를 전달하는 버스이고, 데이터 버스는 입력 데이터 및 출력 데이터 를 전달하는 버스일 수 있다. 컨트롤 버스는 태스크 컨트롤러에게 로드와 연관된 제어 신호를 전송 할 수 있다. 추가적으로 또는 이와 달리, 컨트롤러에게 스토어(store)와 연관된 제어 신호를 전송할 수 있다. 제어 신호는 오프 칩 메모리에 로드된 데이터에 기초하여 태스크 컨트롤러로 전송될 수 있고, 호스트 시스템으로부터 수신되어 태스크 컨트롤러로 전송될 수 있다. 태스크 컨트롤러는 태스크를 제어하기 위한 모듈일 수 있다. 예를 들어, 태스크 컨트롤러는 연산에 필요한 태스크를 생성 또는 분배하기 위한 모듈일 수 있다. 태스크 컨트롤러는 작업 로드와 연관된 제어 신호를 수신하면, 로드 유닛으로 인스트럭션을 전송할 수 있다. 예컨대, 태스크 컨트롤러는 적어도 하나의 로드 인스트럭션 또는 대기 로드 인스트럭션 중 적어도 하나를 전송할 수 있다. 또한, 태스크 컨트롤러 는 데이터 변경과 연관된 제어 신호를 수신하면, 로드 유닛으로 데이터 변경과 연관된 인스트럭션을 전송할 수 있다. 여기서, 데이터 변경과 연관된 인스트럭션은 데이터를 병합(merge), 셔플(shuffle)하는 인스 트럭션 등과 연관될 수 있다. 가령, 데이터 변경과 연관된 인스트럭션은 인공 신경망의 매트릭스 연산과 연관 될 수 있다. 로드 유닛은 메모리로의 액세스 오퍼레이션(access operation)을 수행하도록 구성될 수 있다. 일 실 시예에 따르면, 로드 유닛은 태스크 컨트롤러로부터 수신된 로드 인스트럭션 또는 대기 로드 인스트 럭션 중 적어도 하나에 기초하여 로드와 연관된 태스크를 수행할 수 있다. 여기서, 로드 인스트럭션은 코어 SoC이 현재 실행하고 있는 작업에 대한 프로그램이나 데이터에 대한 인스트럭션을 지칭하고, 대기 로드 인 스트럭션은 코어 SoC이 다음에 실행할 작업에 대한 프로그램이나 데이터에 대한 인스트럭션을 지칭할 수 있 다. 대기 로드 인스트럭션은 복수 개일 수 있다. 로드 인스트럭션 및 대기 로드 인스트럭션 각각에 대한 예시는 하기와 같을 수 있다. Dscrptr{src, dst, burst size, #burst} 여기서, src는 소스 즉, 로드할 데이터의 주소를 지칭하고, dst는 데스티네이션 즉, 데이터를 전송할 목적지 주 소를 지칭할 수 있다. burst size는 버스트 사이즈 즉, 분할 크기를 지칭하고, #burst는 버스트 넘버 즉, 분할 개수를 지칭할 수 있다. 여기서, 버스트 사이즈와 버스트 넘버는 인스트럭션이 버스트 로드 인스트럭션인 경우에 이용될 수 있다. 일 실시예에 따르면, 태스크 컨트롤러는 복수의 인스트럭션을 로드 유닛으로 전송할 수 있다. 예컨 대, 태스크 컨트롤러는 복수의 버스트 로드 인스트럭션을 버스트 넘버 순서에 따라 순차적으로 로드 유닛 으로 전송할 수 있다. 이때, 복수의 버스트 로드 인스트럭션 중에서 일부 또는 전부는, 대기 로드 인스트 럭션으로서 로드 유닛으로 전송될 수 있다. 일 실시예에 따르면, 로드 유닛은 태스크 컨트롤러로부터 수신된 인스트럭션을 페치하고, 페치된 인 스트럭션을 디코딩한 후, 디코딩된 데이터에 기초하여 인스트럭션을 실행할 수 있다. 로드 유닛은 대기 로드 인스트럭션이 복수 개인 경우, 우선순위에 기초하여 대기 로드 인스트럭션을 순차적으로 처리할 수 있다. 일 실시예에 따르면, 로드 유닛은 적어도 하나의 인스트럭션을 페치, 디코딩 및/또는 실행함으로써, 적어 도 하나의 인스트럭션과 연관된 태스크를 수행할 수 있다. 또한, 로드 유닛은 매트릭스 연산과 같은 변경 연산을 통해서 데이터를 변경하고, 변경된 데이터를 결과로서 온 칩 버퍼에 저장할 수 있다. 예컨대, 로 드 유닛은 데이터 변경과 연관된 인스트럭션을 태스크 컨트롤러로부터 수신하고, 캐시에 기록(writ e)된 데이터를 추출할 수 있다. 그리고 나서, 로드 유닛은 추출된 데이터를 변경하고, 변경된 데이터를 온 칩 버퍼에 저장할 수 있다. 로드 유닛은 제1 인스트럭션을 페치하고 디코딩함으로써, 제1 인스트럭션과 연관된 제1 태스크를 수행할 수 있다. 일 실시예에 따르면, 로드 유닛은 제1 태스크를 수행하는 도중에, 제1 인스트럭션이 버스트 로 드 인스트럭션인 경우 대기 중인 제2 인스트럭션을 획득하고, 획득된 제2 인스트럭션과 연관된 제2 태스크를 수 행할 수 있다. 여기서, 대기 중인 제2 인스트럭션은 대기 로드 인스트럭션일 수 있다. 일 실시예에 따르면, 로드 유닛은 제1 태스크와 제2 태스크를 병렬적으로 수행하도록 제어할 수 있다. 즉, 로드 유닛은 제1 인스트럭션이 버스트 로드 인스트럭션으로 판정된 경우에, 제1 태스크를 수행하는 도 중에 발생되는 스톨(stall)을 예방하고자, 제1 인스트럭션과 목적지가 상이한 제2 인스트럭션을 획득하여 제2 인스트럭션과 연관된 제2 태스크를 병렬적으로 수행할 수 있다. 여기서, 제2 인스트럭션은 버스트 로드 인스트 럭션일 수 있으며, 태스크 컨트롤러로부터 수신될 수 있다. 일 실시예에 따르면, 로드 유닛은 제1 인스트럭션이 미리 결정된 임계치 이상의 버스트 크기를 가지는 버 스트 로드 인스트럭션인 경우, 추가적인 제2 태스크를 병렬적으로 수행할 수 있다. 즉, 로드 유닛은 버스 트 제1 태스크와 연관된 제1 인스트럭션이 버스트 로드 인스트럭션이라도, 제1 인스트럭션의 버스트 크기가 임 계치 미만이면, 병렬적으로 수행되는 추가적인 태스크를 수행하지 않고, 제1 태스크만을 수행할 수 있다. 도 4를 참조하여, 버스트 로드 인스트럭션과 연관된 태스크가 수행되는 경우에 스톨(stall)이 발생되는 경우를 설명하기로 한다. 도 4는 버스트 로드 인스트럭션과 연관된 태스크가 수행되는 과정에서 발생되는 스톨을 설명하기 위한 도면이다. 도 4에 예시된 제1 태스크(task_1)는 캐시 데이터 로드와 연관된 태스크(이하, '로드 태스크'로 지 칭함)이고, 제2 태스크(task_2) 내지 제m 태스크(task_m)는 데이터 변경과 연관된 태스크(이하, '데이터 변경 태스크'로 지칭함)이고, 제m+1 태스크(task_m+1) 내지 제n 태스크(task_n)는 변경된 데이터를 전송하기 위한 태 스크(이하, '전송 태스크'로 지칭함)일 수 있다. 데이터 변경 태스크(task_2 내지 task_m)의 개수와 전송 태스 크(task_m+1 내지 task_n)의 개수는 동일할 수 있다. 도 4에서는 데이터 변경 태스크(task_2 내지 task_m)의 개수는 M개(여기서, M은 자연수임)이고, 전송 태스크(task_m+1 내지 task_n)의 개수가 N(여기서, N은 자연수 임)개인 것으로 예시되어 있다. 또한, 데이터 변경 태스크(task_2 내지 task_m)의 개수(M)와 전송 태스크 (task_m+1 내지 task_n)의 개수(N)은 서로 상이할 수 있다. 각각의 태스크는 복수의 인스트럭션을 포함하는 파 이프라인 구조로 생성될 수 있다. 또한, 도 4에 예시된 T1, T2 및 T3의 각각은 복수의 주기(cycle)를 포함하는 작업 시간과 연관될 수 있다. 데이터 변경 태스크(task_2 내지 task_m)는 병합(merge), 셔플(shuffle) 등과 같이 데이터를 변경하는 것과 연 관된 태스크일 수 있다. 예컨대, 데이터 변경 태스크(task_2 내지 task_m)는 인공 신경망의 매트릭스 연산과 연관된 태스크일 수 있다. 일 실시예에 따르면, 데이터 변경 태스크(task_2 내지 task_m)는 데이터를 변경하기 위한 인스트럭션이 획득될 때에 수행될 수 있다. 즉, 데이터 변경과 연관된 인스트럭션이 태스크 컨트롤러로부 터 수신되어 페치(fetch)되는 경우에 데이터 변경 태스크(task_2 내지 task_m)가 수행될 수 있다. 일 실시예에 따르면, 변경 대상이 되는 데이터는 캐시로부터 획득될 수 있다. 도 4에 예시된 바와 같이, 데이터 로드와 연관된 제1 태스크(task_1)가 수행될 수 있다. 제1 태스크(task_1)는 복수의 버스트 로드 인스트럭션이 순차적으로 페치(fetch)되고 디코딩됨으로써 개시될 수 있다. 도 4에 예시된 T1 동안에, 복수의 버스트 로드 인스트럭션이 이슈되고, 이슈된 데이터에 기초하여 리퀘스트가 큐에 저장될 수 있다. 복수의 버스트 로드 인스트럭션과 연관된 복수의 리퀘스트가 큐에 저장되고 난 후에, T2 동안에 리퀘스트에 기초하여 데이터를 읽는데 필요한 대기 시간이 발생할 수 있다. 여기서, 대기 시간은 인스 트럭션에 포함된 소스 주소를 기초로 메모리에 접근하여 필요 데이터를 획득하는데 필요한 대기 시간일 수 있다. 또한, T3 동안에 리퀘스트에 기초한 실행 결과와 연관된 데이터가 캐시에 기록(write)될 수 있다. 만약, 버스트 로드 인스트럭션의 사이즈가 '8'인 경우(예를 들어, 버스트 로드 인스트럭션이 8개인 경우), 로드 와 연관된 연산 결과가 캐시에 기록되기까지 24 주기(cycle)가 필요할 수 있다. 캐시로부터 획득된 데이터를 기초로, 데이터 변경을 수행하기 위한 제2 태스크(task_2)가 대기 중인 경우에(즉, 데이터 변경을 위한 인스트럭션과 연관된 리퀘스트가 큐에 저장된 경우에), 데이터 변경을 실행하기 위한 인스 트럭션(E1 및 E2)은 지연될 수 있다. 도 4에 예시된 바와 같이, 첫 번째 버스트 로드 인스트럭션과 연관된 실 행 결과와 연관된 데이터가 캐시에 기록된 후에, 캐시로부터 획득된 데이터에 기초하여 제2 태스크(task_2)와 연관된 인스트럭션(E1 및 E2)이 실행될 수 있다. 즉, 제2 태스크(task_2)와 연관된 리퀘스트가 큐에 저장되더 라도, 캐시에 데이터가 기록되지 않은 경우 제2 태스크(task_2)와 연관된 인스트럭션(E1, E2)은 대기 상태가 될 수 있다. 제1 태스크(task_1)에 포함된 WB1 인스트럭션이 완료되어 캐시에 데이터가 기록된 후에, 제2 태스크(task_2)와 연관된 제1 인스트럭션(E1)과 제2 인스트럭션(E2)이 순차적으로 실행될 수 있다. 여기서, 제1 인스트럭션(E1) 은 캐시로부터 추출한 데이터를 변경하기 위한 인스트럭션이고, 제2 인스트럭션(E2)은 변경된 데이터를 기록하 기 위한 인스트럭션일 수 있다. 한편, WB2 인스트럭션이 완료되어 캐시에 데이터가 기록된 이후에, 또 다른 데이터 변경 태스크와 연관된 제3 태스크(task_3)가 수행될 수 있다. 또한, 데이터 변경 결과를 목적지로 전송하기 위한 복수의 태스크(task_m+1 내지 task_n) 중 적어도 하나는, 데 이터 변경과 연관된 복수의 태스크(task_2 내지 task_m) 중 적어도 하나가 완료되어만 수행될 수 있다. 도 4를 예를 들어 설명하면, 제1 버스트 로드 인스트럭션에 기초하여 캐시에 기록된 데이터를 변경하기 위한 제2 태스 크(task_2)가 완료된 후에, 변경된 데이터를 목적지로 전송하기 위한 제m+1 태스크(task_m+1)가 수행될 수 있다. 전송 관련 태스크(task_m+1 내지 task_n)에 포함된 제3 인스트럭션(E3)은 변경 결과를 목적지로 전송하 는 것과 연관된 인스트럭션일 수 있다. 도 4에 예시된 바와 같이, 데이터 로드와 연관된 제1 태스크(task_1)에서 실행과 연관된 태스크가 진행되기 전 까지는 데이터 변경과 연관된 태스크(task_2 내지 task_m) 및 데이터 전송과 연관된 태스크(task_m+1 내지 task_n)는 대기 상태가 된다. 즉, 제1 태스크(task_1)에 종속되어 데이터 변경과 연관된 태스크(task_2 내지 task_m)에 수행되고, 데이터 변경과 연관된 태스크(task_2 내지 task_m)과 연관되어 데이터 전송과 연관된 태스 크(task_m+1 내지 task_n)가 수행될 수 있다. 이에 따라, 제1 태스크(task_1)의 작업 시간이 증가할수록, 후속 되는 태스크(task_2 내지 task_n)의 대기 상태가 늘어나, 프로세싱 시스템에서 스톨이 발생할 수 있다. 이렇게 버스트 로드 인스트럭션은 스톨(stall)을 발생시킬 수 있고, 스톨이 발생되면 프로세싱 시스템의 성능이 저하될 수 있다. 따라서, 병렬적으로 태스크를 처리하기 위한 인스트럭션 구조 및 이러한 인스트럭션 구조를 처리하기 위한 프로세싱 시스템이 필요하다. 도 5는 본 개시의 일 실시예에 따른, 복수의 태스크를 병렬적으로 처리하는 로드 유닛을 설명하기 위한 개 요도이다. 도 5에 예시된 로드 유닛은 도 3에 예시된 로드 유닛과 대응될 수 있다. 로드 유닛(50 0)은 데이터 수신, 데이터 변경 및 데이터 전송을 병렬적으로 수행할 수 있다. 로드 유닛은 회로로 구현 또는 구성될 수 있다. 로드 유닛은 로드 유닛 회로라고 명명될 수도 있다. 일 실시예에 따르면, 로드 유닛은 수신된 데이터를 로드하기 위한 로드 태스크 및 로드된 데이터에 변경하 기 위한 데이터 변경 태스크를 병렬적으로 수행할 수 있다. 즉, 로드 유닛은 로드 태스크를 수행하는 도 중에 병렬적으로 데이터 변경 태스크를 수행할 수 있다. 추가적으로, 로드 유닛는 로드 태스크 및/또는 데이터 변경 태스크를 수행하는 도중에, 데이터 변경 태스크에 기초하여 변경된 데이터를 목적지로 전송하는 전 송 태스크를 병렬적으로 수행할 수 있다. 몇몇 실시예에서는, 로드 유닛은 서로 목적지가 상이한 복수의 태스크를 병렬적으로 수행할 수 있다. 일 실시예에 따르면, 로드 유닛은 특정 태스크를 수행하기 시작하면, 특정 태스크와 연관된 인스트럭션이 버스트 로드 인스트럭션인지 여부를 판정할 수 있다. 로드 유닛은 특정 태스크와 연관된 인스트럭션이 버 스트 로드 인스트럭션인 것으로 판정되면, 추가적인 태스크를 수행하되, 추가적인 태스크와 이미 진행중인 태스 크를 병렬적으로 수행할 수 있다. 도 6은 본 개시의 일 실시예에 따른, 로드 유닛의 세부 구성을 나타내는 블록도이다. 도 6에 예시된 바와 같이, 로드 유닛은 페치 처리 모듈, 복수의 리퀘스트 큐, 캐시, 리퀘스트 생성 모듈, 리퀘스트 처리 모듈 및 모듈레이션 모듈을 포함할 수 있다. 페치 처리 모듈은 태스크 컨트롤러로부터 수신된 인스트럭션을 페치하고 디코딩한 후, 수신된 인스트럭션 과 연관된 시그널을 생성하여 리퀘스트 생성 모듈로 전송할 수 있다. 몇몇 실시예에 따르면, 페치 처리 모듈은 태스크 컨트롤러로부터 복수의 인스트럭션을 수신할 수 있고, 수신된 복수의 로드 인스트럭션을 순 차적으로 페치하여 디코딩한 후, 복수의 시그널을 생성할 수 있다. 태스크 컨트롤러부터 수신된 복수의 인스트 럭션에는, 대기 로드 인스트럭션이 포함될 수 있다. 복수의 리퀘스트 큐는 적어도 하나의 리퀘스트를 선입선출 데이터 구조로 저장할 수 있다. 리퀘스트 큐 에 저장된 리퀘스트가 이슈(issue)될 수 있다. 여기서, 이슈는 리퀘스트와 연관된 데이터가 지정된 목적 지로 전송되는 것일 수 있다. 여기서, 목적지는 메모리, 레지스터, 버퍼, 캐시, 큐, 호스트 시스템 등 중에서 적어도 하나와 연관될 수 있다. 복수의 리퀘스트 큐는 서로 상이한 목적지와 연관될 수 있다. 예컨대, 제1 목적지와 연관된 리퀘스트는 제1 리퀘스트 큐에 저장되고, 제2 목적지와 연관된 리퀘스트는 제2 리퀘스트 큐에 저장될 수 있다. 목적지에 기초하여 리퀘스트 큐가 구분됨에 따라, 목적지가 상이한 복수의 태스크가 병렬적이면서 독립적으로 수행 될 수 있다. 캐시는 고속으로 접근 가능한 저장 수단으로서, 로드 태스크와 연관된 실행 결과 데이터를 저장할 수 있다. 캐시는 적어도 하나의 레지스터를 포함할 수 있다. 리퀘스트 생성 모듈은 페치 처리 모듈로부터 수신된 시그널을 기초로 리퀘스트를 생성하고, 생성된 리퀘스트를 리퀘스트 큐에 저장할 수 있다. 리퀘스트에는 로드할 데이터가 저장된 메모리 주소 및 데이터 를 전송한 목적지 주소가 포함될 수 있다. 추가적으로, 리퀘스트에는 버스트 사이즈 및 버스트 넘버가 포함될 수 있다. 리퀘스트 생성 모듈은 수신된 시그널과 연관된 목적지(즉, 인스트럭션에 포함된 목적지)를 식별하고, 복수 의 리퀘스트 큐 중에서 식별된 목적지와 연관된 리퀘스트 큐에 생성된 리퀘스트를 저장할 수 있다. 일 실 시예에 따르면, 리퀘스트 생성 모듈은 LRF(Local Register File)을 기초로 엔트리(entry) 주소를 계산하 고, 리퀘스트 큐에 포함된 복수의 엔트리 중에서, 계산된 엔트리 주소와 연관된 저장 공간에 생성된 리퀘스트를 저장할 수 있다. 여기서, 엔트리는 리퀘스트 큐에 할당된 전체 저장 영역에 포함되는 서브 저장 영역과 연관될 수 있다. 예컨대, 리퀘스트 큐는 100개의 서브 저장 영역에 해당하는 엔트리로 분할되고, 각각의 엔트리에 주 소가 할당될 수 있다. 엔트리의 주소가 이용되어 리퀘스트 큐에 포함된 서브 저장 영역이 예약되고 재사용될 수 있다. 리퀘스트 처리 모듈은 우선순위에 기초하여 리퀘스트 큐에 저장된 리퀘스트를 순차적으로 추출하고, 추출된 복수의 리퀘스트와 연관된 복수의 인스트럭션을 실행할 수 있다. 예컨대, 리퀘스트 처리 모듈은 리퀘스트 큐에 저장된 리퀘스트에 포함된 소스 주소를 기초로, 데이터를 로드하고 로드된 데이터에 기초하 여 실행된 결과(예컨대, 연산 결과)를 캐시에 기록할 수 있다. 모듈레이션 모듈은 캐시에 기록된 데이터를 기초하여, 데이터를 변경하는 연산을 수행하고, 연산 결 과에 따라 변경된 데이터를 목적지와 연관된 제2 저장 영역(610_1 내지 610_n)으로 전송할 수 있다. 여기서, 데이터를 변경하는 것은, 캐시에 저장된 적어도 하나의 데이터를 병합(merge), 셔플(shuffle), 분할 (divide)하는 것 등을 지칭할 수 있다. 예컨대, 데이터를 변경하는 것은, 인공 신경망의 매트릭스 연산과 연관 될 수 있다. 일 실시예에 따르면, 모듈레이션 모듈은 변경 대상이 되는 적어도 하나의 데이터를 캐시로부터 추출 하여, 추출된 적어도 하나의 데이터를 변경한 후, 변경된 데이터를 별도의 제1 저장 영역(미도시)에 저장할 수 있다. 여기서, 별도의 제1 저장 영역은 데이터 변경을 위해서 할당된 전용 영역으로서, 트랜즈포즈 레지스터 파일(transpose register file)을 포함할 수 있다. 모듈레이션 모듈은 제1 저장 영역에 포함된 데이터를 목적지와 연관된 제2 저장 영역(610_1 내지 610_n)으 로 전송할 수 있다. 일 실시예에 따르면, 모듈레이션 모듈은 변경된 데이터와 연관된 목적지(즉, 태스크 와 연관된 목적지)를 식별하고, 식별된 목적지와 연관된 제2 저장 영역(610_1 내지 610_n)으로 변경된 데이터를 전송할 수 있다. 즉, 모듈레이션 모듈은 제1 저장 영역에 포함된 데이터를 이슈하여, 이슈된 데이터가 목 적지와 연관된 제2 저장 영역(610_1 내지 610_n)에 저장되도록 제어할 수 있다. 일 실시예에 따르면, 목적지와 연관된 제2 저장 영역(610_1 내지 610_n)에 포함된 복수의 엔트리(entry) 중에서, 변경된 데이터가 저장되는 엔 트리가 결정되고, 변경된 데이터가 결정된 엔트리와 연관된 저장 공간에 저장되도록 제어될 수 있다. 엔트리 결정을 위해, 다음 순번의 엔트리 주소를 결정하기 위한 참조 데이터(예컨대, 메타 데이터 등)가 로드 유닛 에 저장될 수 있다. 모듈레이션 모듈은 참조 데이터에 기초하여 변경된 데이터를 저장하는 엔트리 주소를 결정할 수 있다. 일 실시예에 따르면, 제2 저장 영역(610_1 내지 610_n)은 서로 상이한 목적지로 구분될 수 있으며, 또한 선입선 출 구조로 데이터를 저장할 수 있다. 예컨대, 제2 저장 영역(610_1 내지 610_n)의 일부 또는 전부는 코어 시스 템에 포함된 온 칩 버퍼에 포함될 수 있다. 다른 예로서, 제2 저장 영역(610_1 내지 610_n)의 일부 또는 전부 는 호스트 시스템에 포함될 수 있다. 일 실시예에 따르면, 리퀘스트 생성 모듈은 페치 처리 모듈로부터 수신한 시그널이 버스트 로드 인스 트럭션과 연관된 시그널인지 여부를 판정하여, 시그널이 버스트 로드 인스트럭션과 연관된 시그널인 것으로 판 정된 경우, 병렬 처리 루틴을 수행하는 것으로 결정할 수 있다. 일 실시예에 따르면, 리퀘스트 생성 모듈(54 0)은 버스트 로드 인스트럭션의 크기가 미리 결정된 임계치를 초과하는 경우에 병렬 처리 루틴을 수행하는 것으 로 결정할 수 있다. 리퀘스트 생성 모듈은 병렬 처리 루틴을 수행하기로 결정한 경우, 병렬 처리를 위한 인스트럭션 페치를 페 치 처리 모듈로 요청하고, 제1 태스크를 수행할 수 있다. 제1 태스크와 연관된 복수의 리퀘스트가 리퀘스 트 큐에 저장됨에 따라, 제1 태스크와 연관된 인스트럭션이 이슈되고, 제1 태스크와 연관된 데이터에 대한 변경이 수행될 수 있다. 페치 처리 모듈은 병렬 처리를 위한 인스트럭션 페치를 수신하는 것에 응답하여, 버스트 로드 인스트럭션 과 목적지가 상이하고 버스트 로드 인스트럭션의 크기와 임계범위 이내의 크기를 가지는 적어도 하나의 버스트 로드 인스트럭션을 획득할 수 있다. 그 후, 페치 처리 모듈은 획득된 버스트 로드 인스트럭션을 페치하고 디코딩한 후, 추가적인 시그널을 생성하여 리퀘스트 생성 모듈로 전송할 수 있다. 예컨대, 리퀘스트 생성 모듈은 버스트 로드 인스트럭션과 목적지가 상이하고 버스트 로드 인스트럭션의 크기와 임계범위 이내의 크기를 가지는 버스트 로드 인스트럭션이 n개(여기서, n은 자연수임)인 경우, n개에 상응하는 시그널을 리퀘스 트 생성 모듈로 전송할 수 있다. 여기서, n개에 상응하는 시그널은 동일한 버스트 로드 인스트럭션과 연 관된 시그널일 수 있으며, 버스트 로드 인스트럭션의 크기에 따라 시그널 개수가 결정될 수 있다. 리퀘스트 생성 모듈은 추가적인 시그널에 기초하여 적어도 하나의 추가적인 태스크를 병렬적으로 수행할 수 있다. 일 실시예에 따르면, 리퀘스트 생성 모듈은 수신된 시그널에 기초하여 복수의 리퀘스트를 생성 하고, 생성된 리퀘스트를 리퀘스트 큐에 저장할 수 있다. 여기서, 리퀘스트 큐에 저장된 복수의 리 퀘스트는 추가적인 태스크와 연관될 수 있다. 추가적인 태스크와 연관된 리퀘스트가 리퀘스트 큐에 저장됨에 따라, 리퀘스트 처리 모듈은 추가적인 태스크와 연관된 리퀘스트를 리퀘스트 큐로부터 추출한 후, 추출된 리퀘스트에 기초하여 추가적인 태스크 와 연관된 쓰기 단계(write back stage)를 수행할 수 있다. 한편, 추가적인 태스크는 복수 개일 수 있다. 예컨대, 세 개 이상의 태스크와 연관된 복수의 리퀘스트가 리퀘 스트 큐에 저장될 수 있다. 가령, 제1 태스크와 연관된 적어도 하나의 리퀘스트 큐가 제1 리퀘스트 큐에 저장되고, 제2 태스크와 연관된 적어도 하나의 리퀘스트 큐가 제2 리퀘스트 큐에 저장되고, 제3 태스크와 연관 된 적어도 하나의 리퀘스트 큐가 제3 리퀘스트 큐에 저장될 수 있다. 여기서, 제1 태스크, 제2 태스크, 제3 태 스크의 각각은 목적지가 상이할 수 있으며, 제1 태스크, 제2 태스크 및 제3 태스크는 버스트 로드 인스트럭션과 연관될 수 있다. 이 경우, 로드 유닛은 제1 내지 제3 리퀘스트 큐에 저장된 복수의 리퀘스트에 기초하여, 제1 태스크, 제2 태스크 및 제3 태스크를 서로 병렬적으로 처리할 수 있다. 상술한 바와 같이, 로드 유닛은 수행중인 태스크와 연관된 인스트럭션이 버스트 로드 인스트럭션인 경우에, 또 다른 버스트 로드 인스트럭션과 연관된 추가 태스크를 수행하되, 복수의 태스크를 병렬적으로 수행할 수 있다. 도 7 및 도 8를 참조하여, 본 개시의 일 실시예에 따라 복수의 태스크가 병렬적으로 수행되는 방법을 설명하기 로 한다. 도 7은 본 개시의 일 실시예에 따른, 복수의 태스크가 병렬적으로 수행되는 것을 예시하는 타이밍 도면이다. 도 7에 예시된 바와 같이, IS는 메모리로부터 획득된 인스트럭션이 페치되고 디코딩된 후, 디코딩된 데이터에 기초하여 시그널이 생성되는 것과 연관된 인스트럭션일 수 있다. 예컨대, IS는 도 6의 페치 처리 모듈을 통해 서 시그널이 생성되어 리퀘스트 생성 모듈로 전달되는 것과 연관될 수 있다. BST는 버스트 로드 인스트럭션과 연관된 것일 수 있다. 버스트 로드 인스트럭션과 수행되는 경우, 버스트 로드 와 연관된 리퀘스트가 생성되어, 리퀘스트 큐에 저장될 수 있다. 예컨대, BST는 도 6에 예시된 리퀘스트 생성 모듈에 의해서 수행되는 인스트럭션일 수 있다. REQ는 리퀘스트 큐에 저장된 리퀘스트와 연관된 인스트럭션이 이슈되는 인스트럭션일 수 있다. REQ는 도 6에 예시된 리퀘스트 처리 모듈에 의해서 수행되는 인스트럭션일 수 있다. 또한, M1 내지 MN은 리퀘스트에 기 초하여 데이터를 읽을 때 발생되는 대기 시간과 연관된 인스트럭션일 수 있다. WB는 연산 결과가 캐시에 기록 된 것과 연관된 인스트럭션일 수 있다. M1 내지 MN 및 WB는 도 6에 예시된 리퀘스트 처리 모듈에 의해서 수행되는 인스트럭션일 수 있다. E1은 데이터 변경을 실행하기 위한 인스트럭션일 수 있고, E2는 E1에 의해서 변경된 데이터를 별도의 저장 영역 에 기록하기 위한 인스트럭션일 수 있다. 또한, E3은 변경된 데이터를 지정된 목적지로 전송하기 위한 인스트 럭션일 수 있다. E1, E2 및 E3는 도 6에 예시된 모듈레이션 모듈에 의해서 수행되는 인스트럭션일 수 있 다. 도 7에서 하나의 인스트럭션은 하나의 주기(cycle)에 수행될 수 있다. 또한, 제1 태스크(task_1), 제2 태스크 (task_2) 및 제3 태스크(task_3)는 버스트 로드 인스트럭션과 연관된 태스크일 수 있다. 여기서, 제1 태스크 (task_1), 제2 태스크(task_2) 및 제3 태스크(task_3)의 각각은 목적지가 서로 상이할 수 있고, 이에 따라 제1 태스크(task_1), 제2 태스크(task_2) 및 제3 태스크(task_3) 각각과 연관된 리퀘스트는 서로 상이한 리퀘스트 큐에 저장될 수 있다. 일 실시예에 따르면, 제1 태스크(task_1)와 연관된 버스트 로드 인스트럭션의 버스트 크기와 제2 태스크 (task_2)/제3 태스크(task_3)와 연관된 버스트 로드 인스트럭션의 버스트 크기 간의 차이는 임계범위 이내일 수 있다. 가령, 제2 태스크(task_2)/제3 태스크(task_3)와 연관된 버스트 로드 인스트럭션의 버스트 크기는 제1 태스크(task_1)와 연관된 버스트 로드 인스트럭션의 버스트 크기 이상일 수 있다. 제4 태스크(task_4) 내지 제m 태스크(task_m)는 데이터 변경과 연관된 태스크일 수 있다. 또한, 제m+1 태스크 (task_m+1) 내지 제n 태스크(task_n)는 데이터 전송과 연관된 태스크일 수 있다. 도 7에 예시된 바와 같이, 제1 태스크(task_1)가 수행되는 도중에, 제2 태스크(task_2)와 제3 태스크(task_3)가 병렬적으로 수행될 수 있다. 일 실시예에 따르면, 제2 태스크(task_2)는 제1 태스크(task_1)가 개시된 주기로 부터 미리 결정된 주기 이후에 시작될 수 있다. 즉, 로드 유닛은 제2 태스크(task_2)의 시작 시점을 제1 태스 크(task_1)의 시작 시점을 기초로 하여 결정할 수 있다. 일 실시예에 따르면, 제2 태스크(task_2) 및/또는 제3 태스크(task_3)는, 데이터 변경과 연관된 제4 태스크(task_4) 내지 제m 태스크(task_m) 보다 앞서서 개시될 수 있다. 도 7에서는 제2 태스크(task_2)는 제1 태스크(task_1)가 시작된 주기로부터 바로 다음 주기에 시작되는 것으로 예시되어 있다. 유사하게, 제3 태스크(task_3)는 제1 태스크(task_1) 또는 제2 태스크(task_2)가 개시된 주기 로부터 미리 결정된 주기 이후에 시작될 수 있다. 도 7에 예시된 바와 같이, 제2 태스크(task_2)는 제1 태스크 (task_1)의 IS가 종료된 다음 주기에 시작될 수 있고, 제3 태스크(task_3)는 제2 태스크(task_2)의 IS가 종료된 다음 주기에 시작될 수 있다. 제1 태스크(task_1)는 버스트 로드 인스트럭션과 연관된 태스크이고, 이에 따라 제1 태스크와 연관된 데이터가 캐시에 기록되기 전까지(즉, WB 관련 인스트럭션이 수행되기 전까지), 데이터 변경과 연관된 제4 태스크 (task_4) 내지 제m 태스크(task_m)가 대기되어야 한다. 이러한 대기 시간 동안에도 로드 유닛을 동작시키기 위 하여, 추가적인 태스크인 제2 태스크(task_2)와 제3 태스크(task_3)가 수행될 수 있다. 이 경우, 제1 태스크 (task_1), 제2 태스크(task_2) 및 제3 태스크(task_3)의 각각은 병렬적으로 수행될 수 있다. 도 7에 예시된 바와 같이, 제2 태스크(task_2)와 제3 태스크(task_3)가 수행되는 도중에, 데이터 변경과 연관된 제4 태스크(task_4) 내지 제m 태스크(task_m)가 병렬적으로 수행되고, 데이터 전송과 연관된 제m+1 태스크 (task_m+1) 내지 제n 태스크(task_n)가 병렬적으로 수행될 수 있다. 이렇듯, 복수의 버스트 로드 인스트럭션과 연관된 복수의 태스크가 병렬적으로 수행됨으로써, 로드 유닛이 동작 하지 않은 휴지(idle) 시간이 최소화되고, 이에 따라 프로세싱 시스템의 스톨이 최소화되거나 방지될 수 있다. 한편, 메모리에 대기 중인 버스트 로드 인스트럭션의 개수에 기초하여, 보다 많은 개수의 태스크가 로드 유닛에 서 병렬적으로 수행될 수 있다. 도 8은 본 개시의 일 실시예에 따른, 복수의 태스크가 병렬적으로 수행되는 것을 예시하는 타이밍 도면이다. 도 8을 참조하면, 제1 태스크(task_1) 내지 제4 태스크(task_4)는 버스트 로드 인스트럭션과 연관된 태스크일 수 있다. 여기서, 제1 태스크(task_1) 내지 제4 태스크(task_4)의 각각은 목적지가 서로 상이할 수 있다. 제2 태스크(task_2) 내지 제4 태스크(task_4)의 각각과 연관된 버스트 로드 인스트럭션은, 제1 태스크(task_1)와 연 관된 버스트 로드 인스트럭션의 버스트 크기와 비교하여, 임계범위 이내에 해당하는 버스트 크기를 가질 수 있 다. 제5 태스크(task_5) 내지 제m 태스크(task_m)는 데이터 변경과 연관된 태스크일 수 있다. 또한, 제m+1 태스크 (task_m+1) 내지 제n 태스크(task_n)는 데이터 전송과 연관된 태스크일 수 있다. 도 8에 예시된 바와 같이, 제1 태스크(task_1)가 수행된 후, 제2 태스크(task_2) 내지 제4 태스크(task_4)가 병 렬적으로 수행될 수 있다. 도 7과 도 8을 비교하면, 도 7에는 버스트 로드 인스트럭션과 연관된 한 개의 태스 크(task_4)가 추가된 것으로 예시되어 있다. 도 8에 예시된 바와 같이, 제2 태스크(task_2) 내지 제4 태스크(task_4)가 수행되는 도중에, 데이터 변경과 연 관된 제5 태스크(task_6) 내지 제m 태스크(task_m)가 병렬적으로 수행되고, 데이터 전송과 연관된 제m+1 태스크 (task_m+1) 내지 제n 태스크(task_n)가 병렬적으로 수행될 수 있다. 일 실시예에 따르면, 추가적인 로드 태스 크와 연관된 제2 태스크(task_2) 내지 제4 태스크(task_4)는, 데이터 변경과 연관된 제5 태스크(task_4) 내지 제m 태스크(task_m) 보다 앞서서 개시될 수 있다. 도 9는 본 개시의 일 실시예에 따른, 로드 유닛의 성능 증가를 정량적으로 나타낸 도면이다. 도 9에서 Nb는 병 렬적인 태스크를 수행하지 않은 경우에 로드 유닛에서 발생하는 휴지(idle) 시간일 수 있다. 도 9에 예시된 바 와 같이, 복수의 버스트 로드 인스트럭션과 연관된 복수의 태스크 병렬적으로 수행되는 경우에, 로드 유닛은 (Nb + Nc + Na) 동안에 추가적인 작업이 수행될 수 있어, 프로세싱 시스템의 성능이 대폭 향상될 수 있다. 도 10은 본 개시의 일 실시예에 따른, 태스크 병렬 처리 방법을 설명하기 위한 흐름도이다. 도 10에 도 시된 방법은, 본 개시의 목적을 달성하기 위한 일 실시예일 뿐이며, 필요에 따라 일부 단계가 추가되거나 삭제 될 수 있음은 물론이다. 또한, 도 10에 도시된 방법은, 코어 SoC에 포함된 적어도 하나의 프로세서에 의해서 수행될 수 있다. 예컨대, 도 10에 도시된 방법은, 코어 SoC에 포함된 로드 유닛과 연관된 프로세서에 의해서 수행될 수 있다. 설명의 편의를 위해서 도 3에 도시된 코어 SoC에 포함된 프로세서에 의해서, 도 10에 도시된 각 단계가 수행되는 것으로 설명하기로 한다. 프로세서는 제1 인스트럭션과 연관된 제1 태스크를 수행할 수 있다(S1010). 제1 태스크가 수행되면, 프로세서는 제1 인스트럭션이 버스트 로드 인스트럭션인지 여부를 판정할 수 있다 (S1020). 제1 인스트럭션이 버스트 로드 인스트럭션으로 판정된 것에 응답하여, 프로세서는 제2 인스트럭션을 획득할 수 있다(S1030). 일 실시예에 따르면, 제1 태스크 및/또는 제2 태스크는 복수의 리퀘스트 생성과 연관된 복수의 인스트럭션 및 복수의 리퀘스트 실행과 연관된 복수의 인스트럭션이 포함된 파이프라인 구조로 생성될 수 있다. 여기서, 리퀘스트 생성과 연관된 인스트럭션은, 도 7 및 도 8에서 BST로 예시되어 있고, 리퀘스트 실행과 연관 된 인스트럭션은 도 7 및 도 8에서 WB로 예시되어 있다. 그 후, 프로세서는 획득된 제2 인스트럭션과 연관된 제2 태스크를 수행할 수 있다(S1040). 이때, 프로세서는 제1 태스크와 제2 태스크를 병렬적으로 수행할 수 있다. 일 실시예에 따르면, 획득된 제2 인스트럭션은 버스트 로드 인스트럭션이고, 제2 인스트럭션의 버스트 크기와 제1 인스트럭션의 버스트 크기 간의 차이는 임계범위 이 내일 수 있다. 이 경우, 프로세서는 제2 인스트럭션의 버스트 크기에 기초하여, 복수의 리퀘스트를 생성할 수 있다. 일 실시예에 따르면, 프로세서는 제2 인스트럭션과 연관된 목적지를 식별하고, 복수의 리퀘스트 큐 중에서, 식별된 목적지와 연관된 리퀘스트 큐에 생성된 복수의 리퀘스트를 저장할 수 있다. 이어서, 프로세서는 복 수의 저장 영역 중에서, 식별된 목적지와 연관된 저장 영역을 식별하고, 목적지와 연관된 리퀘스트 큐에 저장된 리퀘스트를 기초하여 이슈(issue)된 데이터를 식별된 저장 영역에 저장할 수 있다. 일 실시예에 따르면, 제2 태스크는 제1 태스크가 개시된 주기로부터 미리 결정된 주기 이후에 시작될 수 있다. 즉, 프로세서는 제1 태스크가 시작된 후에, 미리 결정된 시점에 제2 태스크를 시작하도록 구성될 수 있다. 제2 태스크를 수행한 이후에, 프로세서는 제3 인스트럭션을 획득하고, 획득된 제3 인스트럭션과 연관된 제3 태 스크를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 제1 태스크, 제2 태스크 및 제3 태스크의 각각을 병 렬적으로 수행할 수 있다. 프로세서는 제1 인스트럭션 및 제2 인스트럭션의 각각과 목적지가 상이한 버스트 로 드 인스트럭션이 대기 중이라는 판정에 응답하여, 대기 중인 버스트 로드 인스트럭션을 제3 인스트럭션으로 결 정할 수 있다. 예컨대, 프로세서는 버스트 로드 인스트럭션과 연관된 대기 로드 인스트럭션이 획득되는 경우에, 대기 로드 인스트럭션을 제3 인스트럭션으로 결정할 수 있다. 또한, 프로세서는 결정된 제3 인스트럭션을 페치하고, 페치된 제3 인스트럭션을 디코딩하는 것을 통해서 제3 태 스크를 시작할 수 있다. 일 실시예에 따르면, 제1 인스트럭션, 제2 인스트럭션 및 제3 인스트럭션의 각각은 서 로 목적지가 상이한 인스트럭션일 수 있다. 일 실시예에 따르면, 제2 태스크 및 제3 태스크는, 캐시에 기록된 데이터를 변경시키기 위한 제4 태스크가 수행 되기 전에 시작되도록 제어될 수 있다. 일 실시예에 따르면, 프로세서는 캐시에 데이터가 기록(write)된 것에 응답하여, 기록된 데이터를 변경시키기 위한 제4 태스크를 수행할 수 있다. 이때, 프로세서는 제2 태스크와 제4 태스크를 병렬적으로 수행되도록 제어 할 수 있다. 상술한 흐름도 및 상술한 설명은 일 예시일 뿐이며, 일부 실시예에서는 다르게 구현될 수 있다. 예를 들어, 일 부 실시예에서는 각 단계의 순서가 바뀌거나, 일부 단계가 반복 수행되거나, 일부 단계가 생략되거나, 일부 단 계가 추가될 수 있다. 상술한 방법은 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램으로 제공될 수 있다. 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하 는 것일수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록 수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수 도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD 와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체 의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 본 개시의 방법, 동작 또는 기법들은 다양한 수단에 의해 구현될 수도 있다. 예를 들어, 이러한 기법들은 하드 웨어, 펌웨어, 소프트웨어, 또는 이들의 조합으로 구현될 수도 있다. 본원의 개시와 연계하여 설명된 다양한 예시적인 논리적 블록들, 모듈들, 회로들, 및 알고리즘 단계들은 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양자 의 조합들로 구현될 수도 있음을 통상의 기술자들은 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호 대 체를 명확하게 설명하기 위해, 다양한 예시적인 구성요소들, 블록들, 모듈들, 회로들, 및 단계들이 그들의 기능 적 관점에서 일반적으로 위에서 설명되었다. 그러한 기능이 하드웨어로서 구현되는지 또는 소프트웨어로서 구 현되는 지의 여부는, 특정 애플리케이션 및 전체 시스템에 부과되는 설계 요구사항들에 따라 달라진다. 통상의 기술자들은 각각의 특정 애플리케이션을 위해 다양한 방식들로 설명된 기능을 구현할 수도 있으나, 그러한 구현 들은 본 개시의 범위로부터 벗어나게 하는 것으로 해석되어서는 안된다. 하드웨어 구현에서, 기법들을 수행하는 데 이용되는 프로세싱 유닛들은, 하나 이상의 ASIC들, DSP들, 디지털 신 호 프로세싱 디바이스들(digital signal processing devices; DSPD들), 프로그램가능 논리 디바이스들 (programmable logic devices; PLD들), 필드 프로그램가능 게이트 어레이들(field programmable gate arrays; FPGA들), 프로세서들, 제어기들, 마이크로제어기들, 마이크로프로세서들, 전자 디바이스들, 본 개시에 설명된 기능들을 수행하도록 설계된 다른 전자 유닛들, 컴퓨터, 또는 이들의 조합 내에서 구현될 수도 있다. 따라서, 본 개시와 연계하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 및 회로들은 범용 프로세서, DSP, ASIC, FPGA나 다른 프로그램 가능 논리 디바이스, 이산 게이트나 트랜지스터 로직, 이산 하드웨어 컴포넌트들,또는 본원에 설명된 기능들을 수행하도록 설계된 것들의 임의의 조합으로 구현되거나 수행될 수도 있다. 범용 프로세서는 마이크로프로세서일 수도 있지만, 대안으로, 프로세서는 임의의 종래의 프로세서, 제어기, 마이크로 제어기, 또는 상태 머신일 수도 있다. 프로세서는 또한, 컴퓨팅 디바이스들의 조합, 예를 들면, DSP와 마이크 로프로세서, 복수의 마이크로프로세서들, DSP 코어와 연계한 하나 이상의 마이크로프로세서들, 또는 임의의 다 른 구성의 조합으로서 구현될 수도 있다. 펌웨어 및/또는 소프트웨어 구현에 있어서, 기법들은 랜덤 액세스 메모리(random access memory; RAM), 판독 전 용 메모리(read-only memory; ROM), 비휘발성 RAM(non-volatile random access memory; NVRAM), PROM(programmable read-only memory), EPROM(erasable programmable read-only memory), EEPROM(electrically erasable PROM), 플래시 메모리, 컴팩트 디스크(compact disc; CD), 자기 또는 마킹 데이 터 스토리지 디바이스 등과 같은 컴퓨터 판독가능 매체 상에 저장된 명령들로서 구현될 수도 있다. 명령들은 하나 이상의 프로세서들에 의해 실행 가능할 수도 있고, 프로세서(들)로 하여금 본 개시에 설명된 기능의 특정 양태들을 수행하게 할 수도 있다. 소프트웨어로 구현되는 경우, 상술된 기법들은 하나 이상의 명령들 또는 코드로서 컴퓨터 판독 가능한 매체 상 에 저장되거나 또는 컴퓨터 판독 가능한 매체를 통해 전송될 수도 있다. 컴퓨터 판독가능 매체들은 한 장소에 서 다른 장소로 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하여 컴퓨터 저장 매체들 및 통신 매체들 양자를 포함한다. 저장 매체들은 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체들일 수도 있다. 비제한적인 예로서, 이러한 컴퓨터 판독가능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 광학 디스크 스토리지, 자기 디스크 스토리지 또는 다른 자기 스토리지 디바이스들, 또는 소망의 프로그램 코드를 명령들 또 는 데이터 구조들의 형태로 이송 또는 저장하기 위해 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 또한, 임의의 접속이 컴퓨터 판독가능 매체로 적절히 칭해진다. 예를 들어, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선, 디지털 가입자 회선 (DSL), 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들을 사용하여 웹사이트, 서버, 또는 다른 원격 소스로부터 전송되면, 동축 케 이블, 광섬유 케이블, 연선, 디지털 가입자 회선, 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들은 매 체의 정의 내에 포함된다. 본원에서 사용된 디스크(disk) 와 디스크(disc)는, CD, 레이저 디스크, 광 디스크, DVD(digital versatile disc), 플로피디스크, 및 블루레이 디스크를 포함하며, 여기서 디스크들(disks)은 보통 자기적으로 데이터를 재생하고, 반면 디스크들(discs)은 레이저를 이용하여 광학적으로 데이터를 재생한다. 위 의 조합들도 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 소프트웨어 모듈은, RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터들, 하드 디스크, 이동식 디스크, CD-ROM, 또는 공지된 임의의 다른 형태의 저장 매체 내에 상주할 수도 있다. 예시적인 저장 매체는, 프로세서가 저장 매체로부터 정보를 판독하거나 저장 매체에 정보를 기록할 수 있도록, 프로세서 에 연결될 수 있다. 대안으로, 저장 매체는 프로세서에 통합될 수도 있다. 프로세서와 저장 매체는 ASIC 내에 존재할 수도 있다. ASIC은 유저 단말 내에 존재할 수도 있다. 대안으로, 프로세서와 저장 매체는 유저 단말에 서 개별 구성요소들로서 존재할 수도 있다. 이상 설명된 실시예들이 하나 이상의 독립형 컴퓨터 시스템에서 현재 개시된 주제의 양태들을 활용하는 것으로 기술되었으나, 본 개시는 이에 한정되지 않고, 네트워크나 분산 컴퓨팅 환경과 같은 임의의 컴퓨팅 환경과 연계 하여 구현될 수도 있다. 또 나아가, 본 개시에서 주제의 양상들은 복수의 프로세싱 칩들이나 장치들에서 구현 될 수도 있고, 스토리지는 복수의 장치들에 걸쳐 유사하게 영향을 받게 될 수도 있다. 이러한 장치들은 PC들, 네트워크 서버들, 및 휴대용 장치들을 포함할 수도 있다."}
{"patent_id": "10-2023-0035788", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 개시의 발명이 속하는 기술분야의 통상 의 기술자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있 다. 또한, 그러한 변형 및 변경은 본 명세서에 첨부된 특허청구의 범위 내에 속하는 것으로 생각되어야 한다."}
{"patent_id": "10-2023-0035788", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예들은, 이하 설명하는 첨부 도면들을 참조하여 설명될 것이며, 여기서 유사한 참조 번호는 유사 한 요소들을 나타내지만, 이에 한정되지는 않는다. 도 1은 본 개시의 일 실시예에 따른, 프로세싱 시스템을 설명하기 위한 블록도이다. 도 2는 본 개시의 일 실시예에 따른, 도 1의 뉴럴 프로세싱 장치를 세부적으로 설명하기 위한 블록도이다. 도 3은 본 개시의 일 실시예에 따른, 도 1의 코어 SoC를 세부적으로 설명하기 위한 블록도이다. 도 4는 버스트 로드 인스트럭션과 연관된 태스크가 수행되는 과정에서 발생되는 스톨을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른, 복수의 태스크를 병렬적으로 처리하는 로드 유닛을 설명하기 위한 개요도 이다. 도 6은 본 개시의 일 실시예에 따른, 로드 유닛의 세부 구성을 나타내는 블록도이다. 도 7 및 도 8은 본 개시의 일 실시예에 따른, 복수의 태스크가 병렬적으로 수행되는 것을 예시하는 타이밍 도면 이다. 도 9는 본 개시의 일 실시예에 따른, 로드 유닛의 성능 증가를 정량적으로 나타낸 도면이다. 도 10은 본 개시의 일 실시예에 따른, 태스크 병렬 처리 방법을 설명하기 위한 흐름도이다."}
