{"patent_id": "10-2022-0005655", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0043653", "출원번호": "10-2022-0005655", "발명의 명칭": "스테레오 카메라 입력 기반의 손 관절 3D 위치 추정 방법 및 손 관절 3D 위치 추정 시스템", "출원인": "고려대학교 세종산학협력단", "발명자": "조현중"}}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 스테레오 이미지 입력부에 의해, 제1 카메라에 의해 획득된 제1 이미지 및 제2 카메라에 의해 획득된 제2이미지를 입력받는 단계;(b) 이미지 특징 추출부에 의해, 딥러닝 모델을 이용하여 제1 이미지로부터 제1 특징을 추출하고, 제2 이미지로부터 제2 특징을 추출하는 단계;(c) 스테레오 어텐션 블록부에 의해, 제1 특징 및 제2 특징을 기초로, 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 생성하는 단계; 및(d) 손 관절 3D 위치 결정부에 의해, 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 기초로 스테레오 딥러닝모델을 이용하여 손 관절 3D 위치를 결정하는 단계를 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,히트맵 블록부에 의해, 상기 제1 특징을 기초로 제1 관절 2D 위치 맵을 출력하고, 상기 제2 특징을 기초로 제2관절 2D 위치 맵을 출력하는 단계를 더 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 (c) 단계는:상기 스테레오 어텐션 블록부에 의해, 상기 제1 특징 및 상기 제2 특징을 결합하여 결합 특징을 생성하는 단계;및상기 스테레오 어텐션 블록부에 의해, 상기 결합 특징을 기초로 성분들이 0이상 1이하의 값인 마스크 맵을 생성하는 단계를 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 (c) 단계는,상기 스테레오 어텐션 블록부에 의해, 상기 마스크 맵 및 상기 제1 관절 2D 위치 맵을 기초로 상기 제1 관절 2D위치 정보를 생성하고, 상기 마스크 맵 및 상기 제2 관절 2D 위치 맵을 기초로 상기 제2 관절 2D 위치 정보를생성하는 단계를 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 (c) 단계는,상기 스테레오 어텐션 블록부에 의해, 상기 결합 특징을 기초로 동일 관절 시차 정보를 생성하는 단계를 포함하고,상기 (d) 단계는,상기 손 관절 3D 위치 결정부에 의해, 상기 제1 관절 2D 위치 정보, 상기 제2 관절 2D 위치 정보, 상기 동일 관절 시차 정보를 기초로 상기 손 관절 3D 위치를 결정하는 단계를 포함하는 스테레오 카메라 입력 기반의 관절공개특허 10-2023-0043653-3-위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 동일 관절 시차 정보를 생성하는 단계는,상기 스테레오 어텐션 블록부에 의해, 상기 제1 이미지 및 상기 제2 이미지의 동일 객체에 대한 상기 제1 이미지에서의 좌표 및 상기 제2 이미지에서의 좌표를 기초로 상기 동일 관절 시차 정보를 생성하는 단계를 포함하는스테레오 카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 스테레오 이미지 입력부에 의해, 복수의 학습용 이미지쌍을 입력받는 단계;상기 스테레오 어텐션 블록부에 의해, 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 생성하는 단계; 및인공지능 학습부에 의해, 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 기초로 상기 스테레오 딥러닝 모델을 학습하는 단계를 더 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 스테레오 딥러닝 모델을 학습하는 단계는:상기 인공지능 학습부에 의해, 생성된 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 학습용 이미지쌍의 기준관절 2D 위치 정보를 기초로 제1 손실 함수를 연산하는 단계;상기 인공지능 학습부에 의해, 생성된 상기 학습용 이미지쌍의 동일 관절 시차 정보 및 학습용 이미지쌍의 기준동일 관절 시차 정보를 기초로 제2 손실 함수를 연산하는 단계;상기 인공지능 학습부에 의해, 생성된 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 상기 학습용 이미지쌍의2D 관절 위치를 반대쪽 이미지에 투영하여 생성된 투영 위치 정보를 기초로 제3 손실 함수를 연산하는 단계; 및상기 인공지능 학습부에 의해, 상기 제1 손실 함수, 상기 제2 손실 함수, 상기 제3 손실 함수를 기초로 통합 손실 함수를 연산하고, 상기 통합 손실 함수가 감소하도록 상기 스테레오 딥러닝 모델을 학습하는 단계를 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,변경 학습용 이미지 생성부에 의해, 입력된 학습용 이미지의 밝기를 변경하여 복수의 변경 학습용 이미지를 생성하는 단계; 및학습용 데이터 생성부에 의해, 각각의 상기 변경 학습용 이미지마다 관절 위치 정보를 생성하고, 복수의 변경학습용 이미지들의 관절 위치 정보를 비교하면서 복수의 변경 학습용 이미지의 관절 위치 정보들의 차이값을 줄이는 방식으로 기준 관절 2D 위치 정보 및 기준 동일 관절 시차 정보를 산출하는 단계를 더 포함하는 스테레오카메라 입력 기반의 관절 위치 추정 방법."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항의 스테레오 카메라 입력 기반의 관절 위치 추정 방법을 실행시키도록 컴퓨터로판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 카메라에 의해 획득된 제1 이미지 및 제2 카메라에 의해 획득된 제2 이미지를 입력받도록 구성되는 스테레공개특허 10-2023-0043653-4-오 이미지 입력부;딥러닝 모델을 이용하여 제1 이미지로부터 제1 특징을 추출하고, 제2 이미지로부터 제2 특징을 추출하도록 구성되는 이미지 특징 추출부;제1 특징 및 제2 특징을 기초로, 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 생성하도록 구성되는 스테레오 어텐션 블록부; 및제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 기초로 스테레오 딥러닝 모델을 이용하여 손 관절 3D 위치를결정하도록 구성되는 손 관절 3D 위치 결정부를 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제1 특징을 기초로 제1 관절 2D 위치 맵을 출력하고, 상기 제2 특징을 기초로 제2 관절 2D 위치 맵을 출력하도록 구성되는 히트맵 블록부를 더 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 스테레오 어텐션 블록부는:상기 제1 특징 및 상기 제2 특징을 결합하여 결합 특징을 생성하고; 그리고상기 결합 특징을 기초로 성분들이 0이상 1이하의 값인 마스크 맵을 생성하도록 구성되는, 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 스테레오 어텐션 블록부는:상기 마스크 맵 및 상기 제1 관절 2D 위치 맵을 기초로 상기 제1 관절 2D 위치 정보를 생성하고; 그리고상기 마스크 맵 및 상기 제2 관절 2D 위치 맵을 기초로 상기 제2 관절 2D 위치 정보를 생성하도록 구성되는 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 스테레오 어텐션 블록부는, 상기 결합 특징을 기초로 동일 관절 시차 정보를 생성하도록 구성되고,상기 손 관절 3D 위치 결정부는,상기 제1 관절 2D 위치 정보, 상기 제2 관절 2D 위치 정보, 상기 동일 관절 시차 정보를 기초로 상기 손 관절3D 위치를 결정하도록 구성되는 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 스테레오 어텐션 블록부는,상기 제1 이미지 및 상기 제2 이미지의 동일 객체에 대한 상기 제1 이미지에서의 좌표 및 상기 제2 이미지에서의 좌표를 기초로 상기 동일 관절 시차 정보를 생성하도록 구성되는 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,공개특허 10-2023-0043653-5-상기 스테레오 이미지 입력부는,복수의 학습용 이미지쌍을 입력받도록 구성되고,상기 스테레오 어텐션 블록부는,상기 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 생성하도록 구성되고,상기 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 기초로 상기 스테레오 딥러닝 모델을 학습하도록 구성되는 인공지능 학습부를 더 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 인공지능 학습부는:생성된 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 학습용 이미지쌍의 기준 관절 2D 위치 정보를 기초로 제1손실 함수를 연산하고;생성된 상기 학습용 이미지쌍의 동일 관절 시차 정보 및 학습용 이미지쌍의 기준 동일 관절 시차 정보를 기초로제2 손실 함수를 연산하고;생성된 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 상기 학습용 이미지쌍의 2D 관절 위치를 반대쪽 이미지에투영하여 생성된 투영 위치 정보를 기초로 제3 손실 함수를 연산하고; 그리고상기 제1 손실 함수, 상기 제2 손실 함수, 상기 제3 손실 함수를 기초로 통합 손실 함수를 연산하고, 상기 통합손실 함수가 감소하도록 상기 스테레오 딥러닝 모델을 학습하도록 구성되는, 스테레오 카메라 입력 기반의 관절위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,입력된 학습용 이미지의 밝기를 변경하여 복수의 변경 학습용 이미지를 생성하도록 구성되는 변경 학습용 이미지 생성부; 및각각의 상기 변경 학습용 이미지마다 관절 위치 정보를 생성하고, 복수의 변경 학습용 이미지들의 관절 위치 정보를 비교하면서 복수의 변경 학습용 이미지의 관절 위치 정보들의 차이값을 줄이는 방식으로 기준 관절 2D 위치 정보 및 기준 동일 관절 시차 정보를 산출하도록 구성되는 학습용 데이터 생성부를 더 포함하는 스테레오 카메라 입력 기반의 관절 위치 추정 시스템."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 발명의 일 실시예에 따른 스테레오 카메라 입력 기반의 관절 위치 추정 방법은, (a) 스테레오 이미지 입 력부에 의해, 제1 카메라에 의해 획득된 제1 이미지 및 제2 카메라에 의해 획득된 제2 이미지를 입력받는 단계; (b) 이미지 특징 추출부에 의해, 딥러닝 모델을 이용하여 제1 이미지로부터 제1 특징을 추출하고, 제2 이미지로 부터 제2 특징을 추출하는 단계; (c) 스테레오 어텐션 블록부에 의해, 제1 특징 및 제2 특징을 기초로, 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 생성하는 단계; 및 (d) 손 관절 3D 위치 결정부에 의해, 제1 관절 2D 위 치 정보, 제2 관절 2D 위치 정보를 기초로 스테레오 딥러닝 모델을 이용하여 손 관절 3D 위치를 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 스테레오 카메라로부터 입력 받은 이미지를 기초로 손 관절의 3D 위치를 추정할 수 있는 손 관절 3D 위치 추정 방법 및 손 관절 3D 위치 추정 시스템에 관한 것이다."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다양한 종류의 웨어러블 카메라들이 판매됨에 따라, 이를 활용한 재활치료, 의료 시뮬레이션 교육, 생활패턴 분 석, AR 응용 프로그램과 같은 다양한 VR/AR기반의 기술들이 소개되었다. 이러한 웨어러블 카메라기반의 응용 기 술은 사용자가 기기를 착용한 상태이기 때문에 사용자중심의 시선을 기반으로 상호작용을 하게 된다. 상호작용 시 가장 유용한 입력 도구는 손으로 자유로운 상호작용을 위해서는 손의 자세 추정이 필수적이다. 손의 자세 추정의 종류로는 절대 위치 추정과 상대 위치 추정이 있는데, 절대 위치 추정은 원점이 카메라로, 카 메라 위치를 기준으로 손 관절의 위치를 추정한다. 이에 반해 상대 위치 추정은 원점이 손 관절 중 하나이며, 해당 관절의 위치로부터 상대적인 손 관절의 위치를 추정한다. 즉, 절대 위치 추정은 사용자의 손과 카메라간의 위치를 알고 있으므로 손의 위치를 활용하여 다양한 상호작용을 제공할 수 있는 장점이 있다. 절대 위치 추정을 위해서는 깊이 정보를 얻는 것이 필수적이다. 깊이 정보를 얻기 위해서는 RGBD 카메라를 사용 하거나 Stereo 카메라를 사용하는 방법이 있다. RGBD 카메라는 적외선 패턴을 방사하고 이를 기반으로 깊이 정 보를 얻게 된다. 그러나, 이러한 방법은 다른 빛에 간섭을 받아 부정확한 정보를 얻게 될 수 있으며, 적외선 패 턴을 방사하기 때문에 전력을 많이 소모한다는 단점이 있다. 이에 반해 Stereo 카메라는 두 카메라의 시차를 이 용하여 깊이 정보를 획득하기 때문에 빛의 간섭이나 추가적인 전력 소모가 없다는 장점이 있다. 그러나, 현재 stereo 카메라를 기반으로 하는 손 관절 절대 위치 추정 기술은 한계가 있다. 첫째, 기존 딥러닝 기반의 기술은 stereo 카메라의 기하학적인 정보를 학습에 사용하지 않는다. stereo 카메라 기반의 딥러닝 알고 리즘을 제안하였지만, 손의 관절 위치에 대한 정보만을 학습하고 기하학적인 정보를 학습에 활용하지 않는다. 둘째, 현재 기술은 몇 가지 가정을 기반으로 손 관절 절대 위치를 추정한다. 손이 다른 객체보다 제일 앞에 나 와 있다는 가정을 사용한다. 이러한 가정은 자유로운 사용을 제한하게 된다. 셋째, 딥러닝 모델 학습을 위해서 는 데이터셋(이미지와 정답지 쌍)이 필요한데, 현재는 정답지를 생성을 수작업으로 진행한다. 이러한 방법은 데 이터셋이 많아질수록 시간이 많이 들고, 정확도가 부정확할 수 있다는 한계가 있다."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래의 손 관절 위치 추정 방법보다 정확하게 손 관절의 3D 위치를 추정할 수 있는 손 관절 3D 위치 추정 방법 및 손 관절 3D 위치 추정 시스템을 제공하기 위한 것이다. 또한, 본 발명은 정확한 손 자세 추정을 특별한 가정없이 수행함으로써, 스테레오 카메라 기반의 웨어러블 환경 에서 사용자가 작업의 종류에 제한받지 않는 다양한 작업이 가능한 손 관절 3D 위치 추정 방법 및 손 관절 3D 위치 추정 시스템을 제공하기 위한 것이다. 또한, 본 발명은 손 관절 3D 위치 추정에 이용되는 기계학습 모델을 학습하는데 필요한 데이터 수집을 정확하고 빠르게 수행할 수 있고, 데이터 수집에 드는 비용을 줄일 수 있는 손 관절 3D 위치 추정 방법 및 손 관절 3D 위 치 추정 시스템을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시된 발명의 일 측면에 따른 스테레오 카메라 입력 기반의 관절 위치 추정 방법은, (a) 스테레오 이미지 입력 부에 의해, 제1 카메라에 의해 획득된 제1 이미지 및 제2 카메라에 의해 획득된 제2 이미지를 입력받는 단계; (b) 이미지 특징 추출부에 의해, 딥러닝 모델을 이용하여 제1 이미지로부터 제1 특징을 추출하고, 제2 이미지로 부터 제2 특징을 추출하는 단계; (c) 스테레오 어텐션 블록부에 의해, 제1 특징 및 제2 특징을 기초로, 제1 관 절 2D 위치 정보, 제2 관절 2D 위치 정보를 생성하는 단계; 및 (d) 손 관절 3D 위치 결정부에 의해, 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 기초로 스테레오 딥러닝 모델을 이용하여 손 관절 3D 위치를 결정하는 단계를 포함할 수 있다. 또한, 히트맵 블록부에 의해, 상기 제1 특징을 기초로 제1 관절 2D 위치 맵을 출력하고, 상기 제2 특징을 기초 로 제2 관절 2D 위치 맵을 출력하는 단계를 더 포함할 수 있다. 또한, 상기 (c) 단계는: 상기 스테레오 어텐션 블록부에 의해, 상기 제1 특징 및 상기 제2 특징을 결합하여 결 합 특징을 생성하는 단계; 및 상기 스테레오 어텐션 블록부에 의해, 상기 결합 특징을 기초로 성분들이 0이상 1 이하의 값인 마스크 맵을 생성하는 단계를 포함할 수 있다. 또한, 상기 (c) 단계는, 상기 스테레오 어텐션 블록부에 의해, 상기 마스크 맵 및 상기 제1 관절 2D 위치 맵을 기초로 상기 제1 관절 2D 위치 정보를 생성하고, 상기 마스크 맵 및 상기 제2 관절 2D 위치 맵을 기초로 상기 제2 관절 2D 위치 정보를 생성하는 단계를 포함할 수 있다. 또한, 상기 (c) 단계는, 상기 스테레오 어텐션 블록부에 의해, 상기 결합 특징을 기초로 동일 관절 시차 정보를 생성하는 단계를 포함하고, 상기 (d) 단계는, 상기 손 관절 3D 위치 결정부에 의해, 상기 제1 관절 2D 위치 정 보, 상기 제2 관절 2D 위치 정보, 상기 동일 관절 시차 정보를 기초로 상기 손 관절 3D 위치를 결정하는 단계를 포함할 수 있다. 또한, 상기 동일 관절 시차 정보를 생성하는 단계는, 상기 스테레오 어텐션 블록부에 의해, 상기 제1 이미지 및 상기 제2 이미지의 동일 객체에 대한 상기 제1 이미지에서의 좌표 및 상기 제2 이미지에서의 좌표를 기초로 상 기 동일 관절 시차 정보를 생성하는 단계를 포함할 수 있다.또한, 상기 스테레오 이미지 입력부에 의해, 복수의 학습용 이미지쌍을 입력받는 단계; 상기 스테레오 어텐션 블록부에 의해, 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 생성하는 단계; 및 인공 지능 학습부에 의해, 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 기초로 상기 스테레 오 딥러닝 모델을 학습하는 단계를 더 포함할 수 있다. 또한, 상기 스테레오 딥러닝 모델을 학습하는 단계는: 상기 인공지능 학습부에 의해, 생성된 상기 학습용 이미 지쌍의 관절 2D 위치 정보 및 학습용 이미지쌍의 기준 관절 2D 위치 정보를 기초로 제1 손실 함수를 연산하는 단계; 상기 인공지능 학습부에 의해, 생성된 상기 학습용 이미지쌍의 동일 관절 시차 정보 및 학습용 이미지쌍 의 기준 동일 관절 시차 정보를 기초로 제2 손실 함수를 연산하는 단계; 상기 인공지능 학습부에 의해, 생성된 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 상기 학습용 이미지쌍의 2D 관절 위치를 반대쪽 이미지에 투영하 여 생성된 투영 위치 정보를 기초로 제3 손실 함수를 연산하는 단계; 및 상기 인공지능 학습부에 의해, 상기 제 1 손실 함수, 상기 제2 손실 함수, 상기 제3 손실 함수를 기초로 통합 손실 함수를 연산하고, 상기 통합 손실 함수가 감소하도록 상기 스테레오 딥러닝 모델을 학습하는 단계를 포함할 수 있다. 또한, 변경 학습용 이미지 생성부에 의해, 입력된 학습용 이미지의 밝기를 변경하여 복수의 변경 학습용 이미지 를 생성하는 단계; 및 학습용 데이터 생성부에 의해, 각각의 상기 변경 학습용 이미지마다 관절 위치 정보를 생 성하고, 복수의 변경 학습용 이미지들의 관절 위치 정보를 비교하면서 변경 학습용 이미지의 관절 위치 정보들 의 차이값을 줄이는 방식으로 기준 동일 관절 시차 정보를 산출하는 단계를 더 포함할 수 있다. 개시된 발명의 일 측면에 따른 컴퓨터 프로그램은, 상기 스테레오 카메라 입력 기반의 관절 위치 추정 방법을 실행시키도록 컴퓨터로 판독 가능한 기록매체에 저장될 수 있다. 개시된 발명의 일 측면에 따른 스테레오 카메라 입력 기반의 관절 위치 추정 시스템은, 제1 카메라에 의해 획득 된 제1 이미지 및 제2 카메라에 의해 획득된 제2 이미지를 입력받도록 구성되는 스테레오 이미지 입력부; 딥러 닝 모델을 이용하여 제1 이미지로부터 제1 특징을 추출하고, 제2 이미지로부터 제2 특징을 추출하도록 구성되는 이미지 특징 추출부; 제1 특징 및 제2 특징을 기초로, 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 생성하 도록 구성되는 스테레오 어텐션 블록부; 및 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 기초로 스테레오 딥러닝 모델을 이용하여 손 관절 3D 위치를 결정하도록 구성되는 손 관절 3D 위치 결정부를 포함할 수 있다. 또한, 상기 제1 특징을 기초로 제1 관절 2D 위치 맵을 출력하고, 상기 제2 특징을 기초로 제2 관절 2D 위치 맵 을 출력하도록 구성되는 히트맵 블록부를 더 포함할 수 있다. 또한, 상기 스테레오 어텐션 블록부는: 상기 제1 특징 및 상기 제2 특징을 결합하여 결합 특징을 생성하고; 그 리고 상기 결합 특징을 기초로 성분들이 0이상 1이하의 값인 마스크 맵을 생성하도록 구성될 수 있다. 또한, 상기 스테레오 어텐션 블록부는: 상기 마스크 맵 및 상기 제1 관절 2D 위치 맵을 기초로 상기 제1 관절 2D 위치 정보를 생성하고; 그리고 상기 마스크 맵 및 상기 제2 관절 2D 위치 맵을 기초로 상기 제2 관절 2D 위 치 정보를 생성하도록 구성될 수 있다. 또한, 상기 스테레오 어텐션 블록부는, 상기 결합 특징을 기초로 동일 관절 시차 정보를 생성하도록 구성되고, 상기 손 관절 3D 위치 결정부는, 상기 제1 관절 2D 위치 정보, 상기 제2 관절 2D 위치 정보, 상기 동일 관절 시 차 정보를 기초로 상기 손 관절 3D 위치를 결정하도록 구성될 수 있다. 또한, 상기 스테레오 어텐션 블록부는, 상기 제1 이미지 및 상기 제2 이미지의 동일 객체에 대한 상기 제1 이미 지에서의 좌표 및 상기 제2 이미지에서의 좌표를 기초로 상기 동일 관절 시차 정보를 생성하도록 구성될 수 있 다. 또한, 상기 스테레오 이미지 입력부는, 복수의 학습용 이미지쌍을 입력받도록 구성되고, 상기 스테레오 어텐션 블록부는, 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 생성하도록 구성되고, 상기 학 습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 기초로 상기 스테레오 딥러닝 모델을 학습하도록 구성되는 인공지능 학습부를 더 포함할 수 있다. 또한, 상기 인공지능 학습부는: 생성된 상기 학습용 이미지쌍의 관절 2D 위치 정보 및 학습용 이미지쌍의 기준 관절 2D 위치 정보를 기초로 제1 손실 함수를 연산하고; 생성된 상기 학습용 이미지쌍의 동일 관절 시차 정보 및 학습용 이미지쌍의 기준 동일 관절 시차 정보를 기초로 제2 손실 함수를 연산하고; 생성된 상기 학습용 이미 지쌍의 관절 2D 위치 정보 및 상기 학습용 이미지쌍의 2D 관절 위치를 반대쪽 이미지에 투영하여 생성된 투영 위치 정보를 기초로 제3 손실 함수를 연산하고; 그리고 상기 제1 손실 함수, 상기 제2 손실 함수, 상기 제3 손실 함수를 기초로 통합 손실 함수를 연산하고, 상기 통합 손실 함수가 감소하도록 상기 스테레오 딥러닝 모델을 학습할 수 있다. 또한, 입력된 학습용 이미지의 밝기를 변경하여 복수의 변경 학습용 이미지를 생성하도록 구성되는 변경 학습용 이미지 생성부; 및 각각의 상기 변경 학습용 이미지마다 관절 위치 정보를 생성하고, 복수의 변경 학습용 이미 지들의 관절 위치 정보를 비교하면서 변경 학습용 이미지의 관절 위치 정보들의 차이값을 줄이는 방식으로 기준 동일 관절 시차 정보를 산출하도록 구성되는 학습용 데이터 생성부를 더 포함할 수 있다."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 발명의 일 측면에 따르면, 종래의 손 관절 위치 추정 방법보다 정확하게 손 관절의 3D 위치를 추정할 수 있다. 또한, 본 발명의 실시예에 의하면, 정확한 손 자세 추정을 특별한 가정없이 수행함으로써, 스테레오 카메라 기 반의 웨어러블 환경에서 사용자가 작업의 종류에 제한받지 않는 다양한 작업을 할 수 있다. 마지막으로, 본 발명의 실시예에 의하면, 손 관절 3D 위치 추정에 이용되는 기계학습 모델을 학습하는데 필요한 데이터 수집을 정확하고 빠르게 수행할 수 있고, 데이터 수집에 드는 비용을 줄일 수 있다."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 개시된 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생 략한다. 명세서에서 사용되는 '~부'라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따 라 복수의 '~부'가 하나의 구성요소로 구현되거나, 하나의 '~부'가 복수의 구성요소들을 포함하는 것도 가능하 다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전 술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 개시된 발명의 작용 원리 및 실시예들에 대해 설명한다. 도 1은 일 실시예에 따른 관절 추정 시스템의 구성도이며, 도 2는 일 실시예에 따른 관절 위치 추정 과정을 설 명하기 위한 도면이다.도 1 및 도 2를 참조하면, 본 발명의 실시예에 따른 관절 위치 추정 시스템은 스테레오 이미지 입력부 , 이미지 특징 추출부, 스테레오 어텐션 블록부, 손 관절 3D 위치 결정부, 히트맵 블록부 , 인공지능 학습부 및 메모리를 포함할 수 있다. 웨어러블 기기는 사람이 눈에 안경처럼 착용 가능한 기기일 수 있다. 웨어러블 기기는 제1 카메라 및 제2 카메라를 포함할 수 있다. 제1 카메라 및 제2 카메라는 각각 사용자의 좌측 안구 및 우측 안구 부근에 하나씩 위치할 수 있다. 즉, 제1 카메라 및 제2 카메라는 각각 사람의 좌측 안 구 및 우측 안구가 바라보는 위치에서 이미지 정보를 획득할 수 있다. 스테레오 이미지 입력부는 제1 카메라에 의해 획득된 제1 이미지 및 제2 카메라에 의해 획 득된 제2 이미지를 입력받을 수 있다. 제1 이미지는 제1 카메라가 사용자의 좌측 안구 부근에서 획득한 이미지(Left image)이고, 제2 이미 지는 제2 카메라가 사용자의 우측 안구 부근에서 획득한 이미지(Right image)일 수 있으나, 이에 한 정되는 것은 아니다. 즉, 반대로 제1 이미지가 사용자의 우측 안구 부근에서 획득한 이미지이고 제2 이미 지가 사용자의 좌측 안구 부근에서 획득한 이미지일수도 있다. 또한 제1 카메라 및 제2 카메라 가 좌우가 아닌 상하로 배치된 경우 제1 이미지 및 제2 이미지는 상대적으로 좌측에서 획득된 이미지 및 우측에서 획득된 이미지가 아니라 각각 상대적으로 상단 또는 하단에서 획득된 이미지일 수 있다. 정리하면, 제1 이미지 및 제2 이미지는 특정 시점에 특정 위치, 특정 영역 또는 동일 대상을 두 대의 카메라가 각각 다른 위치에서 촬영하여 획득한 이미지들일 수 있다. 스테레오 이미지 입력부는 제1 카메라 및 제2 카메라로부터 무선으로 제1 이미지 및 제2 이미지를 수신할 수 있다. 이때, 스테레오 이미지 입력부가 웨어러블 기기와 무선으로 통신하는 방식은 와이파이(Wifi), LTE, 4G, 5G 등 어떠한 방식이라도 상관없다. 또한, 스테레오 이미지 입력부는 웨 어러블 기기로부터 유선 통신 방식으로 제1 이미지 및 제2 이미지를 수신할 수도 있다. 한편, 스테레오 이미지 입력부는 제1 이미지에서 제1 영역 이미지를 추출하고, 제2 이미지에서 제2 영역 이미지를 추출할 수 있다. 제1 영역 이미지와 제2 영역 이미지는 각각 제1 이미지 또는 제2 이미 지에서 사용자의 손이 위치한 영역이 바운딩 박스(bounding box)의 형태로 추출된 이미지(Cropped image) 일 수 있다. 사용자의 손이 위치한 영역을 탐지하는 것은 객체 탐지 딥러닝 모델, 예를 들면 YOLOv3를 활용하는 방식일 수 있으나, 이에 한정되는 것은 아니다. 이미지 특징 추출부는 이미지로부터 특징(feature)을 추출할 수 있다. 어떤 특정한 이미지의 특징은 해당 이미지에 대한 다양한 특성을 나타내는 정보일 수 있다. 예를 들어, 특정한 이미지의 특징은 해당 이미지의 각 픽셀 단위에서의 색상, 명도, 경계 등에 대한 정보일 수 있으나 이에 한정되는 것은 아니다. 이미지 특징 추출부는 딥러닝 모델을 이용하여 제1 이미지로부터 제1 특징을 추출하고, 제 2 이미지로부터 제2 특징을 추출할 수 있다. 이때, 이미지 특징 추출부는 제1 영역 이미지로부 터 제1 특징을 추출하고, 제2 이미지로부터 제2 특징을 추출할 수 있다. 즉, 제1 특징은 제1 이미지의 특징이고, 제2 특징은 제2 이미지의 특징일 수 있다. 딥러닝 기반의 객체 검출 기술은 이미지로부터 추출되는 특징(feature)을 데이터를 기반으로 미리 학습된 딥러 닝 모델을 이용할 수 있다. 이때, 이미지로부터 특징을 추출하는 방식을 학습하기 위해 여러 단계의 컨볼 루션 계층(convolution layer)을 쌓은 CNN(Convolutional Neural Networks) 구조가 활용될 수 있으나 이에 한 정되는 것은 아니다. 스테레오 어텐션 블록부는 제1 특징 및 제2 특징을 기초로, 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보를 생성할 수 있다. 제1 관절 2D 위치 정보는 촬영된 손의 관절들이 평면적인 제1 이미지 상에서 위치한 평면 좌표 값에 관련된 정보일 수 있다. 제2 관절 2D 위치 정보는 촬영된 손의 관절들이 평면적인 제2 이미지 상에서 위치한 평면 좌표 값에 관련된 정보일 수 있다. 이때, 동일한 손에 대해서 관절 위치 정보를 생성했다고 하더라 도 제1 카메라 및 제2 카메라의 위치 차이 때문에 제1 이미지 및 제2 이미지 상에서의 관 절들의 평면 좌표 값은 서로 다를 수 있다. 손 관절 3D 위치 결정부는 제1 관절 2D 위치 정보 및 제2 관절 2D 위치 정보를 기초로 스테레오 딥러닝 모델을 이용하여 손 관절 3D 위치(Absolute 3D hand pose)를 결정할 수 있다. 스테레오 딥러닝 모델은 기계학습 방식으로 학습된 인공지능 모델일 수 있다. 손 관절 3D 위치는 촬영된 손의 관절들이 입체적인 3차원 공간에서 위치한 입체 좌표 값에 관련된 정보일 수 있다. 스테레오 이미지 입력부, 이미지 특징 추출부, 스테레오 어텐션 블록부, 손 관절 3D 위치 결정 부, 히트맵 블록부, 인공지능 학습부는 관절 위치 추정 시스템에 포함된 복수개의 프로세 서 중 어느 하나의 프로세서를 포함할 수 있다. 또한, 지금까지 설명된 본 발명의 실시예 및 앞으로 설명할 실 시예에 따른 관절 위치 추정 방법은, 프로세서에 의해 구동될 수 있는 프로그램의 형태로 구현될 수 있다. 여기서 프로그램은, 프로그램 명령, 데이터 파일 및 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 프로그램은 기계어 코드나 고급 언어 코드를 이용하여 설계 및 제작된 것일 수 있다. 프로그램은 상술한 부호 수정을 위한 방법을 구현하기 위하여 특별히 설계된 것일 수도 있고, 컴퓨터 소프트웨어 분야에서 통상의 기술 자에게 기 공지되어 사용 가능한 각종 함수나 정의를 이용하여 구현된 것일 수도 있다. 전술한 정보 표시 방법 을 구현하기 위한 프로그램은, 프로세서에 의해 판독 가능한 기록매체에 기록될 수 있다. 이때, 기록매체는 메 모리일 수 있다. 메모리는 전술한 동작 및 후술하는 동작을 수행하는 프로그램을 저장할 수 있으며, 메모리는 저장된 프로그램을 실행시킬 수 있다. 프로세서와 메모리가 복수인 경우에, 이들이 하나의 칩에 집적되는 것도 가 능하고, 물리적으로 분리된 위치에 마련되는 것도 가능하다. 메모리는 데이터를 일시적으로 기억하기 위한 S램(Static Random Access Memory, S-RAM), D랩(Dynamic Random Access Memory) 등의 휘발성 메모리를 포함할 수 있다. 또한, 메모리는 제어 프로그램 및 제어 데이터를 장기간 저장하기 위한 롬(Read Only Memory), 이피롬(Erasable Programmable Read Only Memory: EPROM), 이이피롬(Electrically Erasable Programmable Read Only Memory: EEPROM) 등의 비휘발성 메모리를 포함할 수 있다. 프로세서는 각종 논리 회로와 연산 회로를 포함할 수 있으며, 메모리로부터 제공된 프로그램에 따라 데이 터를 처리하고, 처리 결과에 따라 제어 신호를 생성할 수 있다. 도 3은 일 실시예에 따른 손 관절 3D 위치를 결정하는 과정을 도시한 도면이며, 도 4는 일 실시예에 따른 스테 레오 어텐션 블록부의 동작을 설명하기 위한 도면이다. 도 3을 참조하면, 제1 이미지(Left image) 및 제2 이미지(Right image)를 기초로 제1 특징(XL) 및 제2 특징(XR)이 추출되고, 제1 특징을 기초로 제1 관절 2D 위치 맵(M2,L)이 생성되고, 제2 특징을 기초로 제2 관절 2D 위치 맵(M2,R)이 생성되는 것을 확인할 수 있다. 또한, 제1 특징, 제2 특징, 제1 관절 2D 위치 맵 및 제2 관절 2D 위치 맵을 기초로 제1 관절 2D 위치 정보(2D left Keypoints), 제2 관절 2D 위치 정보(2D right Keypoints) 및 동일 관절 시차 정보(Disparities)가 생성되는 것을 확인할 수 있다. 히트맵 블록부는 제1 특징을 기초로 제1 관절 2D 위치 맵을 출력하고, 제2 특징을 기초로 제2 관절 2D 위치 맵을 출력할 수 있다. 제1 관절 2D 위치 맵은 제1 이미지에 찍힌 손의 관절들의 좌표 정보를 나타내는 특징 맵일 수 있다. 제2 관절 2D 위치 맵은 제2 이미지에 찍힌 손의 관절들의 좌표 정보를 나타내는 특징 맵일 수 있다. 정리하면, 히트맵 블록부는 제1 특징을 기초로 제1 이미지에서 손의 관절이 있을 것으로 예상되 는 위치에 관한 특징 맵을 출력하고, 제2 특징을 기초로 제2 이미지에서 손의 관절이 있을 것으로 예 상되는 위치에 관한 특징 맵을 출력할 수 있다. 도 3 및 도 4를 참조하면, 스테레오 어텐션 블록부는 제1 특징 및 제2 특징을 결합하여 결합 특 징을 생성할 수 있다. 즉, 결합 특징은 제1 이미지에 관련된 정보와 제2 이미지에 관련된 정보가 전부 포함되어 있는 특징일 수 있다. 이때, 결합 특징이 생성되는 과정은 디컨볼루션 (Deconvolution) 과정으로 인해 특징의 크기가 커지는 과정이 포함될 수 있다. 스테레오 어텐션 블록부는 결합 특징을 기초로 성분들이 0이상 1이하의 값인 마스크 맵(A(XL) 및 A(XR))을 생성할 수 있다. 마스크 맵은 결합 특징의 성분들이 0이상 1이하의 값을 가지도록 스 케일링하여 생성되는 맵일 수 있다. 정리하면, 결합 특징의 각 성분들은 1을 초과하는 값일 수 있으나, 스 테레오 어텐션 블록부가 결합 특징을 스케일링하여 각 성분의 값이 0과 1사이의 값인 마스크(attention mask)를 생성할 수 있다. 스테레오 어텐션 블록부는 마스크 맵 및 제1 관절 2D 위치 맵을 기초로 제1 관절 2D 위치 정보 를 생성하고, 마스크 맵 및 제2 관절 2D 위치 맵을 기초로 제2 관절 2D 위치 정보를 생성 할 수 있다. 구체적으로, 스테레오 어텐션 블록부는 제1 이미지에 대한 특징 맵과 마스크 맵을 곱한 값에 제 1 이미지에 대한 특징 맵을 더한 값을 제1 관절 2D 위치 정보로 결정하고, 제2 이미지에 대한 특징 맵과 마스크 맵을 곱한 값에 제2 이미지에 대한 특징 맵을 더한 값을 제2 관절 2D 위치 정보 로 결정할 수 있다. [방정식 1]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[방정식 1]을 참조하면, M'2,R은 제2 관절 2D 위치 정보이고, A(C(XR,XL))은 마스크맵이고, M2,R(XR)은 제2 관절 2D 위치 맵일 수 있다. 이때, 제2 이미지에 대한 특징 맵인 제2 관절 2D 위치 맵과 마 스크 맵을 곱한 값에 제2 관절 2D 위치 맵을 더하여 제2 관절 2D 위치 정보를 계산할 수 있으며, 제1 관절 2D 위치 정보도 동일한 방식으로 계산할 수 있다. 제1 관절 위치 2D 정보 및 제2 관절 위치 정보는 히트 맵(heat map)일 수 있다. 즉, 전술한 방식으로 스테레오 어텐션 블록부는 두 종류의 히트 맵을 생성할 수 있다. 히트 맵은 손 관절의 상대적인 위치 추정을 위한 맵일 수 있다. 구체적으로, 스테레오 어텐션 블록부는 제1 이미지에 대한 마스크 맵 및 제1 관절 2D 위치 맵 을 기초로 제1 이미지에 대한 히트 맵(M'2,L)을 생성하고, 제2 이미지에 대한 마스크 맵 및 제2 관절 2D 위치 맵을 기초로 제2 이미지에 대한 히트 맵(M'2,R)을 생성할 수 있다. 히트 맵은 이차원 맵(2D map)으로 표현될 수 있다. 스테레오 어텐션 블록부는 관절의 개수만큼 제1 이미지 에 대한 히트 맵을 생성할 수 있으며, 관절의 개수만큼 제2 이미지에 대한 히트 맵을 생성할 수 있다. 예를 들어, 추정할 관절이 21개이면, 제1 이미지에 대한 21개의 이차원 맵 및 제2 이미지에 대 한 21개의 이차원 맵이 만들어질 수 있다. 각 이차원 맵에는 해당 위치에 관절이 있을 확률에 정보를 갖고 있다. 스테레오 어텐션 블록부는 결합 특징을 기초로 동일 관절 시차 맵(D)을 생성할 수 있다. 동일 관절 시차 맵 역시 관절 개수만큼 맵이 만들어질 수 있다. 일 실시예에 의하면, 전술한 방식으로 획득된 히트 맵에는 soft-argmax와 같은 계산법을 적용하고, 계산 결과 확률 값이 아닌 실제 추정 값을 얻을 수 있다. 이때, 손 관절의 2D 좌표는 히트 맵 상에서 동일한 위치로 표현 될 수 있다. 스테레오 어텐션 블록부는 결합 특징을 기초로 동일 관절 시차 정보(D)를 생성할 수 있다. 동일 관절 시차 정보는 두 개의 스테레오 이미지의 시차 추정에 이용되는 정보로서 깊이 정보를 생성할 때 이용 될 수 있다. 이러한 동일 관절 시차 정보 또한 관절의 개수만큼 맵이 생성될 수 있다. 도 5는 일 실시예에 따른 동일 관절 시차 정보를 설명하기 위한 도면이다. 도 5를 참조하면, 두 개의 스테레오 이미지의 시차 추정을 위해서는 또 다른 이차원 맵(2D disparity map)을 이 용할 수 있다. 스테레오 어텐션 블록부는 제1 이미지 및 제2 이미지의 동일 객체에 대한 제1 이미지에서 의 좌표 및 제2 이미지에서의 좌표를 기초로 동일 관절 시차 정보를 생성할 수 있다. 즉, 스테레오 어텐션 블록부는 양안시차(두 이미지에서 보이는 객체의 위치 차이)를 사용하여 이차원 맵(2D disparity map)을 생성할 수 있다.[방정식 2]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "구체적으로, x 축에는 uL 위치 값을, y 축에는 uR 값을 사용할 수 있다. 예를 들어, (uL, vL)이 (2,3)이고 (uR, vR)이 (4,5)이면 이차원 맵(2D disparity map)에서는 (2,4)로 표현된다. 이렇게 계산한 값을 기초로 상대 시차( )를 계산한다. 상대 시차는 상대적으로 크기를 줄인 시차를 의미하고, [방정식 2]를 통하여 계산될 수 있다. 여기에서 wb와 는 임의의 값일 수 있다. 다시 도 3 및 도 4를 참조하면, 손 관절 3D 위치 결정부는 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보 및 동일 관절 시차 정보를 기초로 손 관절 3D 위치를 결정할 수 있다. 구체적으로, 손 관절 3D 위치 결정부는 상대적인 관절 위치에 관한 정보인 제1 관절 2D 위치 정보 및 제2 관절 2D 위치 정보를 기초로, [방정식 3], [방정식 4] 및 [방정식 5]를 통해 절대적인 3D 관절 위치에 관한 정보를 생성할 수 있다. [방정식 3]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[방정식 3]을 참조하면, 는 원점이 원 이미지의 오른쪽 상단인 관절 위치이고, 는 원점이 손 영역탐지로 인해 잘린 이미지 오른쪽 상단으로 조정된 위치일 수 있다. [방정식 4]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[방정식 4]를 참조하면 상대 시차( ) 스테레오 이미지의 상대 시차 계산에 이용된 wb와 값을 그대로 사용하 여 절대 시차( )를 계산할 수 있다. 이후, 손 관절 3D 위치 결정부는 생성된 절대적인 3D 관절 위치에 관한 정보와 절대 시차 값을 이용하여 절대 관절 위치, 즉 손 관절 3D 위치를 구할 수 있다. 이 때 절대적인 손 관절 3D 위치의 차원은 3차원으로서, 기존 (x,y)에 깊이 차원이 추가된 것일 수 있다. 전술한 손 관절 3D 위치를 구하는 과정은 스테레오 비전에서 일반적으로 사용하는 3차원 위치 복원 방법을 사용하는 것일 수 있다. [방정식 5]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "[방정식 5]를 참조하면, 여기에서 와 는 초점 거리(focal length)이고 와 는 주점(pricipal point), B는 제1 카메라와 제2 카메라 사이의 거리 차일 수 있다. 전술한 모든 과정을 거치면, 손 관절 3D 위치 결정부는 최종적으로 오른쪽, 왼쪽 이미지에 대한 3차원 절 대 관절 위치를 결정할 수 있다. 이때, 손 관절 3D 위치 결정부는 총 2개의 값을 얻게 되므로 둘의 평균 값을 계산하여 하나의 3차원의 손 관절 3D 위치를 알아낼 수 있다. 한편, 손 관절 3D 위치를 알아내는 방법은 손 관절 3D 위치 결정부가 스테레오 딥러닝 모델을 이용하 여 손 관절 3D 위치를 결정하는 것일 수 있다. 따라서, 일 실시예에 의해 손 관절 3D 위치를 결정하기 위해서는 미리 학습용 이미지를 기초로 기계학습을 통해 스테레오 딥러닝 모델을 학습하는 과정이 필요하다.다시 도 1을 참조하면, 스테레오 이미지 입력부는 복수의 학습용 이미지를 입력받을 수 있다. 이때, 스테 레오 이미지 입력부는 어느 동일한 대상이나 동일한 배경을 제1 카메라 및 제2 카메라가 각각 촬영한 학습용 이미지쌍을 입력받을 수 있다. 스테레오 어텐션 블록부는 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 생성할 수 있다. 이때, 스테레오 어텐션 블록부는 학습 단계가 아니라 일반적인 제1 이미지 및 제2 이미지 에 대한 손 관절 3D 위치를 알아내는 방식과 동일한 방식으로 한 쌍의 학습용 이미지에 대한 관절 2D 위치 정보 및 동일 관절 시차 정보를 생성할 수 있다. 인공지능 학습부는 학습용 이미지쌍의 관절 2D 위치 정보 및 동일 관절 시차 정보를 기초로 스테레오 딥러닝 모델을 학습할 수 있다. 인공지능 학습부는 제1 손실 함수, 제2 손실 함수 및 제3 손실함수를 연산하고, 3개의 손실 함수를 기초로 스테레오 딥러닝 모델을 학습할 수 있다. 인공지능 학습부는 생성된 학습용 이미지쌍의 관절 2D 위치 정보 및 학습용 이미지쌍의 기준 관절 2D 위치 정보를 기초로 제1 손실 함수를 연산할 수 있다. [방정식 6]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "[방정식 6]을 참조하면, 제1 손실 함수( )는 추정된 학습용 이미지쌍의 상대적인 2D 관절 위치와 미리 정 해진 학습용 이미지쌍의 정답 상대 2D 관절 위치의 차이를 최소화하는데 이용되는 손실 함수임을 알 수 있다. 이때, 2D 관절 위치는 2D 픽셀 좌표일 수 있다. 여기에서 는 추정된 j번째 관절의 상대적인 위치이고, 는 그와 대응되는 j번째 관절의 상대적인 위치의 정답 값일 수 있다. 은 로 구성될 수 있다. 인공지능 학습부는 생성된 학습용 이미지쌍의 동일 관절 시차 정보 및 학습용 이미지쌍의 기준 동일 관절 시차 정보를 기초로 제2 손실 함수를 연산할 수 있다 [방정식 7]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "[방정식 7]을 참조하면, 제2 손실 함수( )는 추정된 상대 시차와 정답 상대 시차의 차이를 최소화하는데 이용되는 손실 함수임을 알 수 있다. 은 j번째 상대 관절의 시차이고, 은 그에 대응되는 정답 시차일 수 있다. 인공지능 학습부는 생성된 학습용 이미지쌍의 관절 2D 위치 정보 및 학습용 이미지쌍의 2D 관절 위치를 반 대쪽 이미지에 투영하여 생성된 투영 위치 정보를 기초로 제3 손실 함수를 연산할 수 있다. [방정식 8]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "[방정식 8]을 참조하면, 제3 손실 함수( )는 좌측 이미지에서 추정한 3D 관절 위치를 우측 이미지로 투영 했을 때의 차이를 최소화는데 이용되는 손실 함수일 수 있다. 만약 제대로 3D 관절 위치의 추정을 했다면 좌측 이미지에서 추정한 관절 위치를 우측 이미지로 투영했을 때 차이는 0이 되어야 한다. 여기에서 와 은 투영행렬로서 각각 좌측 이미지에서 우측으로 투영을 하고, 우측 이미지에서 좌측으로 투영을 하는데 이용되는 행렬 일 수 있다. 와 는 j번째 왼쪽, 오른쪽 절대 손 관절 위치일 수 있다. 인공지능 학습부는 제1 손실 함수, 제2 손실 함수 및 제3 손실 함수를 기초로 통합 손실 함수를 연산할 수 있다. [방정식 9]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "[방정식 9]를 참조하면, 통합 손실 함수( )는 임의의 값(α,β 또는 γ)이 각각 곱해진 제1 손실 함수, 제 2 손실 함수 및 제3 손실 함수를 합해서 구해질 수 있다. 인공지능 학습부는 반복적인 기계 학습(Machine Learning)을 통해 통합 손실 함수가 감소하도록 스테레오 딥러닝 모델을 학습할 수 있다. 미리 학습된 스테레오 딥러닝 모델은 메모리에 저장될 수 있다. 기계 학습이란 다수의 파라미터로 구성된 모델을 이용하며, 주어진 데이터로 파라미터를 최적화하는 것을 의미 할 수 있다. 기계 학습은 학습 문제의 형태에 따라 지도 학습(supervised learning), 비지도 학습 (unsupervised learning), 강화 학습(reinforcement learning)을 포함할 수 있다. 지도 학습(supervised learning)은 입력과 출력 사이의 매핑을 학습하는 것이며, 입력과 출력 쌍이 데이터로 주어지는 경우에 적용할 수 있다. 비지도 학습(unsupervised learning)은 입력만 있고 출력은 없는 경우에 적용하며, 입력 사이의 규칙 성 등을 찾아낼 수 있다. 다만, 일 실시예에 따른 기계 학습이 반드시 전술한 학습 방식으로 한정되는 것은 아 니다. 기계학습부는 다양한 방식으로 스테레오 딥러닝 모델을 학습할 수 있다. 예를 들어, 기계학습부는 복수의 학습용 이미지로부터 추출되는 특징(feature)을 딥러닝 기반의 학습방법으로 학습할 수 있다. 이때, 이미지로부 터 3D 손 관절 위치에 관련된 특징을 추출하는 방법을 학습하기 위해 여러 단계의 컨볼루션 계층(convolution layer)을 쌓은 CNN(Convolutional Neural Networks) 구조가 활용될 수 있으나, 기계학습부의 학습방법이 반드 시 CNN 구조를 활용하는 방법으로 한정되는 것은 아니다. 한편, 전술한 방식대로 기계학습을 진행하기 위해서는 각각의 학습용 이미지 쌍마다 관절의 상대적인 위치의 정 답 값 및 정답 시차가 기준으로서 미리 정해져 있을 필요가 있다. 도 6은 일 실시예에 따른 학습용 데이터를 생성하는 과정을 설명하기 위한 도면이다. 도 6을 참조하면, 학습용 이미지가 입력되면 먼저 3D 손 관절 위치 후보 데이터들이 생성될 수 있다. 3D 손 관 절 위치 후보 데이터 생성을 위해서 좌측 이미지 및 우측 이미지의 2D 손 관절 위치를 추정한 다음 이를 3D로 변환하는 작업이 수행될 수 있다. 2D 손 관절 위치 추정을 위해서 빛을 조절하며 여러 개의 후보군을 생성하는 방법을 사용할 수 있다. 이때, 후보군 개수는 임의로 정할 수 있다. 관절 위치 추정 시스템은 변경 학습용 이미지 생성부 및 학습용 데이터 생성부를 더 포함할 수 있다. 변경 학습용 이미지 생성부는 입력된 학습용 이미지의 밝기를 변경하여 복수의 변경 학습용 이미지를 생성할 수 있다. 즉, 어느 한 학습용 이미지쌍에 대해서 밝기만 다른 복수개의 변경 학습용 이미지가 생성될 수 있다. 학습용 데이터 생성부는 각각의 변경 학습용 이미지마다 관절 위치 정보를 생성할 수 있다. 학습용 데이터 생성부는 복수의 변경 학습용 이미지의 관절 위치 정보를 기반으로 최적의 관절 위치를 추정할 수 있다. 학습용 데이터 생성부는 최적의 관절 위치의 추정을 위해 [방정식 10]과 같이 각 변경 이미지의 관절 위치 정보와 기준이 되는 변경 이미지의 관절 위치 정보의 차이를 계산할 수 있다. 이때 기준이 되는 변경 이미 지는 복수의 변경 이미지 중에서 임의로 선택될 수 있다. [방정식 10] [방정식 11]"}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "학습용 데이터 생성부는 계산된 관절 위치 정보의 차이를 기초로 [방정식 11]에 나타난 바와 같이 최적화 알고 리즘을 통해 어느 한 학습용 이미지쌍의 최적의 관절 위치들( )을 결정할 수 있다. 즉, 학습용 데이터 생성부는 복수의 변경 학습용 이미지들의 관절 위치 정보를 비교하면서 복수의 변경 학습용 이미지의 관절 위치 정보들의 차이값을 줄이는 방식으로 기계학습 과정에 필요한 정답 값인 기준 관절 2D 위치 정보 및 기준 동일 관절 시차 정보를 산출할 수 있다. 도 7은 일 실시예에 따른 관절 위치 추정 방법의 순서도이다. 이는 본 발명의 목적을 달성하기 위한 바람직한 실시예일 뿐이며, 필요에 따라 일부 구성이 추가되거나 삭제될 수 있음은 물론이다. 도 7을 참조하면, 스테레오 이미지 입력부는 제1 카메라에 의해 획득된 제1 이미지 및 제2 카메 라에 의해 획득된 제2 이미지를 입력받을 수 있다. 이미지 특징 추출부는 딥러닝 모델을 이용하여 제1 이미지로부터 제1 특징을 추출하고, 제 2 이미지로부터 제2 특징을 추출할 수 있다. 히트맵 블록부는 제1 특징을 기초로 제1 관절 2D 위치 맵을 출력하고, 제2 특징을 기초로 제2 관절 2D 위치 맵을 출력할 수 있다. 스테레오 어텐션 블록부는 제1 특징 및 제2 특징을 기초로 결합 특징을 생성하고, 결합 특 징을 기초로 마스크 맵을 생성할 수 있다. 스테레오 어텐션 블록부는 마스크 맵 및 제1 관절 2D 위치 맵을 기초로 제1 관절 2D 위치 정보 를 생성하고, 마스크 맵 및 제2 관절 2D 위치 맵을 기초로 제2 관절 2D 위치 정보를 생성 할 수 있다. 스테레오 어텐션 블록부는 결합 특징을 기초로 동일 관절 시차 정보를 생성할 수 있다. 손 관절 3D 위치 결정부는 제1 관절 2D 위치 정보, 제2 관절 2D 위치 정보, 동일 관절 시차 정 보를 기초로 손 관절 3D 위치를 결정할 수 있다. 본 발명의 실시예에 따른 관절 위치 추정 방법의 성능을 검증하기 위하여, 한 쌍의 스테레오 카메라를 이용하여 획득된 이미지를 기초로 실험을 진행하였다. 도 8은 일 실시예에 따른 관절 위치 추정 방법이 종래의 관절 위치 추정 방식에 비해 개선된 정도를 나타낸 그 래프이다. 도 8을 참조하면, 일 실시예에 따른 관절 위치 추정 방법(StreoNet, StereoDMap)이 다른 종래의 방법(ResNet, AttentionNet, baseline 등)보다 더 오류가 덜 발생하는 것을 확인할 수 있다. 구체적으로, 도시된 각 그래프의 x축 값(Error thresold)은 실제 정답의 3D 손 관절 위치와 추정된 3D 손 관절 위치 사이의 차이를 나타낸다. 또한, y축은 각 3D 손 관절 위치 사이의 차이 발생 빈도, 즉 각 에러 정도에 대 한 발생 빈도를 나타낸다. 예를 들어, 관절 위치 추정 방법(StreoNet)에 의하면 10mm이하의 에러가 발생한 빈도 는 약 30%이지만, 종래의 방법은 10mm이하의 에러가 발생한 빈도가 15%보다 낮음을 확인할 수 있다. 정리하면, 일 실시예에 따른 관절 위치 추정 방법(StreoNet, StereoDMap)이 종래의 방법보다 더 정답 및 추정된 3D 손 관절 위치 사이의 차이가 적게 발생함을 확인할 수 있다."}
{"patent_id": "10-2022-0005655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 발명이 속하는 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 발명이 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다.부호의 설명 100: 관절 위치 추정 시스템 110: 스테레오 이미지 입력부 120: 이미지 특징 추출부 130: 스테레오 어텐션 블록부 140: 손 관절 3D 위치 결정부 150: 히트맵 블록부 160: 인공지능 학습부 170: 메모리 171: 딥러닝 모델 172: 스테레오 딥러닝 모델 200: 웨어러블 기기 201: 제1 카메라 202: 제2 카메라 301: 제1 이미지 302: 제2 이미지 401: 제1 특징 402: 제2 특징 403: 결합 특징 501: 제1 관절 2D 위치 맵 502: 제2 관절 2D 위치 맵 503: 마스크 맵 601: 제1 관절 2D 위치 정보 602: 제2 관절 2D 위치 정보 603: 동일 관절 시차 정보도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2022-0005655", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 관절 추정 시스템의 구성도이다. 도 2는 일 실시예에 따른 관절 위치 추정 과정을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 손 관절 3D 위치를 결정하는 과정을 도시한 도면이다. 도 4는 일 실시예에 따른 스테레오 어텐션 블록부의 동작을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 동일 관절 시차 정보를 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 학습용 데이터를 생성하는 과정을 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 관절 위치 추정 방법의 순서도이다. 도 8은 일 실시예에 따른 관절 위치 추정 방법이 종래의 관절 위치 추정 방식에 비해 개선된 정도를 나타낸 그 래프이다."}
