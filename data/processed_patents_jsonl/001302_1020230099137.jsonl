{"patent_id": "10-2023-0099137", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0017995", "출원번호": "10-2023-0099137", "발명의 명칭": "3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법", "출원인": "알바이오텍 주식회사", "발명자": "김정현"}}
{"patent_id": "10-2023-0099137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "3~4대의 깊이 카메라를 설치하고 캘리브레이션 하는 제1단계; 상기 각 카메라를 통해 환자의 보행을 동시에 촬영하는 제2단계;상기 각 카메라에서 측정한 3차원 데이터를 정합하는 제3단계;볼류메트릭(Volumetric) 데이터 취득과 골격 키 포인트(Skeleton Key point)를 추출하는 제4단계;상기 볼류메트릭 데이터와 골격 키 포인트 추출을 기반으로 디지털 트윈을 구현하는 제5단계; 3D 관절 데이터를 추출하는 제6단계; 및상기 3D 관절 데이터에서 보행에 대한 데이터를 추출하는 제7단계;를 포함하는 것을 특징으로 하는 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법."}
{"patent_id": "10-2023-0099137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1단계에서 깊이 카메라의 설치위치와 카메라의 각도를 월드 스페이스에 동기화시키는 단계를 더 포함하는 것을 특징으로 하는 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법."}
{"patent_id": "10-2023-0099137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제7단계에서 3D 관절 데이터를 추출하여 환자의 보행 특성, 운동 패턴, 균형 등을 평가하여 환자의 움직임과 기능을 평가하고, 장애나 이상을 감지하거나 치료 계획을 수립하는 것을 특징으로 하는 3차원 영상데이터를활용한 인공지능 기반 보행 파라미터 추출방법."}
{"patent_id": "10-2023-0099137", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제7단계에서 3D 관절 데이터를 분석하여 환자의 보행 속도, 보행 패턴, 균형 문제, 대칭성 등을 평가하여환자의 운동 기능 평가와 치료나 재활 프로그램에 적합 개입을 설계하는 것을 특징으로 하는 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법."}
{"patent_id": "10-2023-0099137", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법에 관한 것으로, 3~4대의 깊이 카메 라를 설치하고 캘리브레이션 하는 제1단계; 상기 각 카메라를 통해 환자의 보행을 동시에 촬영하는 제2단계; 상 기 각 카메라에서 측정한 3차원 데이터를 정합하는 제3단계; 볼류메트릭(Volumetric) 데이터 취득과 골격 키 포 인트(Skeleton Key point)를 추출하는 제4단계; 상기 볼류메트릭 데이터와 골격 키 포인트 추출을 기반으로 디지 털 트윈을 구현하는 제5단계; 3D 관절 데이터를 추출하는 제6단계; 및 상기 3D 관절 데이터에서 보행에 대한 데 이터를 추출하는 제7단계;를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0099137", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법에 관한 것으로, 더욱 상세하게는 여러 대의 깊이 카메라를 통해 3D 관절 데이터를 취득하여 인공지능 기반 보행 파라미터를 추출하는 방법에 관 한 것이다."}
{"patent_id": "10-2023-0099137", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 3차원 영상 기반의 보행 및 운동 분석 장비를 이용하여 근골격계, 신경계 질환 환자들을 대상으로 운동 능력을 측정하고 있다. 그러나 이러한 3차원 영상 기반의 보행 및 운동 분석 장비는 고가의 장비를 여러 대 조합하여 움직임을 측정하 는 방법으로 다수의 카메라를 설치하는 넓은 공간이 필요하며 인체의 각 관절부위마다 영상측정 전 마커 부착을 위한 전문 인력 투입이 요구되는 등 운동능력 분석에 많은 비용과 시간이 소요되는 문제점이 있었다.선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허공보 제10-2023-0018556호(2023.02.07)"}
{"patent_id": "10-2023-0099137", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위한 본 발명의 목적은 좁은 공간 안에서 보행의 형태에 따라 여러 대의 깊이 카메라를 설치하여 보행 분석 및 파라미터를 추출할 수 있는 3차원 영상데이터를 활용한 인공지능 기반 보행 파 라미터 추출방법을 제공하는 데 있다."}
{"patent_id": "10-2023-0099137", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명에 따른 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추 출방법은 3~4대의 깊이 카메라를 설치하고 캘리브레이션 하는 제1단계; 상기 각 카메라를 통해 환자의 보행을 동시에 촬영하는 제2단계; 상기 각 카메라에서 측정한 3차원 데이터를 정합하는 제3단계; 볼류메트릭 (Volumetric) 데이터 취득과 골격 키 포인트(Skeleton Key point)를 추출하는 제4단계; 상기 볼류메트릭 데이터 와 골격 키 포인트 추출을 기반으로 디지털 트윈을 구현하는 제5단계; 3D 관절 데이터를 추출하는 제6단계; 및 상기 3D 관절 데이터에서 보행에 대한 데이터를 추출하는 제7단계;를 포함하는 것을 특징으로 한다. 상기 제1단계에서 깊이 카메라의 설치위치와 카메라의 각도를 월드 스페이스에 동기화시키는 단계를 더 포함하 는 것을 특징으로 한다. 상기 제7단계에서 3D 관절 데이터를 추출하여 환자의 보행 특성, 운동 패턴, 균형 등을 평가하여 환자의 움직임 과 기능을 평가하고, 장애나 이상을 감지하거나 치료 계획을 수립하는 것을 특징으로 한다. 상기 제7단계에서 3D 관절 데이터를 분석하여 환자의 보행 속도, 보행 패턴, 균형 문제, 대칭성 등을 평가하여 환자의 운동 기능 평가와 치료나 재활 프로그램에 적합 개입을 설계하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0099137", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 좁은 공간 안에서도 여러 대의 깊이 카메라를 배치하여 보행 분석 및 파라미터를 효율적으로 추출할 수 있어 설치 및 운영 비용을 줄일 수 있다. 또한, 본 발명에 따르면 보행 파라미터 추출하여 재활 및 의료 분야에서 다양한 용도로 활용이 가능하며 질환의 진단 및 중증도 분류에 대한 활용 폭이 확대될 수 있다."}
{"patent_id": "10-2023-0099137", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그러면 본 발명에 따른 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법의 바람직한 실시예에 대하여 자세히 설명하기로 한다. 도 1은 본 발명에 따른 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출 방법을 나타낸 흐름도이 다. 도 1을 참조하면, 본 발명에 따른 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출방법은, 먼저 여러 대(바람직하게는 3~4대)의 깊이(Depth) 카메라를 적절한 위치에 설치하고 캘리브레이션(Calibration)한다 (S100). 이때, 깊이 카메라의 설치위치와 카메라의 각도를 월드 스페이스에 동기화 시킨다. 즉, 각 카메라에서 주는 3차원 데이터 값의 기준 좌표는 카메라가 되므로 각각의 카메라에서 나오는 3차원 데이터를 병합을 해야 하기 때문에 각각 설치된 카메라의 위치와 회전 값으로 캘리브레이션을 진행한다. 이어서, 각 깊이 카메라를 통해 환자의 보행을 동시에 촬영한다(S200). 이때, 각 카메라는 환자의 신체를 3차원 공간에서 캡처하여 깊이 맵 형태로 저장할 수 있다. 상기 S200단계에서 환자의 보행 경로와 관절 동작을 최대한 정확하게 촬영하는 것이 중요하다. 이를 위해 각 카 메라를 컨트롤하고 정확한 측정을 위해 지정 위치에 측정 대상(머리, 허리, 발 등 주요 신체)을 위치시키고, 일 정시간 신체 움직임을 체크하여 움직임이 없으면 보행을 시작하면서 촬영한다. 이어서, 각 카메라에서 측정한 3차원 데이터를 ICP(Iterative Closest Point) 알고리즘을 통해 정합하고 (S300), 볼류메트릭(Volumetric) 데이터 취득과 골격 키 포인트(Skeleton Key point)를 추출한다(S400). 다음으로, 상기 환자의 볼류메트릭(Volumetric) 데이터 취득과 골격 키 포인트(Skeleton Key point) 추출을 기 반으로 디지털 트윈을 구현한다(S500). 여기서, 상기 골격 키 포인트 추출은 사전에 학습된 딥 러닝 모델을 사 용하거나 컨볼루션 신경망(CNN)이나 리커런트 신경망(RNN)을 활용할 수 있다. 다음에, 환자의 3D 관절 데이터를 추출한다(S600). 여기서, 3D 관절 데이터는 관절 위치 추출을 위한 알고리즘 또는 딥러닝 기반의 인공지능 모델을 사용할 수 있다. 한편, 3D 관절 데이터 값은 깊이 카메라에서 얻기 때문에 외부 환경적인 요인과 측정대상자의 옷, 신발 등의 상 태에 따라 오차가 생길 수 있다. 이러한 오차는 다음 행동을 예측하는 알고리즘을 통해 보정할 수 있다. 일예로서, 보행이라는 특정 행동은 비교적 정확한 예측이 가능하다. 그 이유는 앞으로 나아가는 보행이므로 뒤 로 발의 위치가 예상 범위를 벗어날 수 없고, Gait cycle 주기도 비교적 느리기 때문에 30fps의 속도로 손실 없 이 충분한 데이터를 받을 수 있으며, 시작점에서 다음 Step의 위치 또한 범위가 작기 때문이다. 또한, 측정 환 경 상 순차 예측이 가능하다. 순차 예측은 어떠한 값들의 열(sequence)이 주어졌을 때 그 다음에 나올 값을 찾 는 문제이다. 즉, 순차예측을 이용하여 패턴(pattern)을 인식하는 것이 가능하다. 보행이라 함은 시작 위치에 왼/오른발이 교차로 앞으로 나아가는 과정이고, 시작 지점에서 왼/오른발이 어느 위치에 지면과 닿을지 예상이 가능하며, 이는 기준 데이터와의 비교와 동시에 3D 관절 데이터에서 기준 값을 초과하거나 미달하는 범위를 지 정할 수가 있다. 다음에, 상기 환자의 3D 관절 데이터에서 보행에 대한 데이터를 추출한다(S700). 여기서, 3D 관절 데이터 추출 을 위한 알고리즘 또는 딥러닝 기반의 인공지능 모델을 사용할 수 있다. 일예로서, 보행주기의 1Step을 추출하기 위한 프로세스는 시작지점에서 측정대상자는 두발이 지면에 닿아 있는 상태이므로 3D 조인트 데이터 중 L/R 발목 데이터의 높이 값을 저장한 후 어플리케이션에서 시작신호가 호출되 면, 처음에 저장한 발목의 높이 값과 매 프레임 새로 들어오는 발목의 높이 값을 비교한다. 왼쪽 또는 오른쪽 발의 높이 변화가 생긴 쪽이 Step을 시작한 발이다. Step을 시작한 발목이 초기에 저장한 발목의 높이 값와 일 치한 값이 들어온다면 지면에 닿았다고 판단한다. 더불어, Stance Phase, Swing Phase, Velocity, Cadence, Initial double support, Single support, Terminal double support, Hip joint angle, Knee joint angle, Ankle joint angle 등을 추출한다. 상기 S700단계에서 3D 관절 데이터를 인공지능으로 추출하여 환자의 보행 특성, 운동 패턴, 균형 등을 평가할 수 있다. 이를 통해 신체의 움직임과 기능을 평가하고, 장애나 이상을 감지하거나 치료 계획을 수립하는 데 활 용할 수 있다. 또한, 분석된 3D 관절 데이터를 해석하여 환자의 보행에 대한 정보를 도출할 수 있다. 예를 들면, 보행 속도, 보행 패턴, 균형 문제, 대칭성 등의 요소를 평가할 수 있다. 이를 통해 환자의 운동 기능을 평가하고, 치료나 재활 프로그램에 적합한 개입을 설계할 수 있다. 위와 같이, 본 발명은 여러 대의 깊이 카메라로 촬영된 환자의 3D 관절 데이터를 분석하여 환자의 보행과 운동 기능을 평가하고, 치료 및 재활에 활용할 수 있어, 임상, 운동 생리학, 재활 의학 등 다양한 분야에서 활용될 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2023-0099137", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 3차원 영상데이터를 활용한 인공지능 기반 보행 파라미터 추출 방법을 나타낸 흐름도이 다."}
