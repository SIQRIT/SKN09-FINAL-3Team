{"patent_id": "10-2023-0076437", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0176133", "출원번호": "10-2023-0076437", "발명의 명칭": "인공 지능 기반의 도로 상태 평가 클라우드 및 그의 운영 방법", "출원인": "주식회사 도우닷존", "발명자": "윤해범"}}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 기반의 도로 상태 평가 클라우드로서,통신부; 메모리; 및차량에 탑재된 카메라를 통해 시계열 기반으로 도로를 촬영한 이미지를 상기 통신부를 통해 획득하고, 적어도하나의 코어를 포함하는 프로세서를 포함하며,상기 프로세서는,상기 획득된 촬영 이미지를 전처리하는 전처리 모듈;상기 전처리된 촬영 이미지에 포함된 콘크리트 슬래브의 이음선에 기초하여 스티칭 기법을 통해 상기 전처리된촬영 이미지를 결합하는 이미지 결합 모듈;상기 결합된 촬영 이미지에서 분할된 콘크리트 슬래브의 적어도 일부에 대한 도로의 손상 여부를 결정하는 손상여부 결정 모듈; 및상기 통신부를 통해, 상기 결정된 도로의 손상 여부에 대한 정보를 관련 단말에 제공하고, 상기 관련 단말의 피드백을 수신하는 경우, 상기 수신된 관련 단말의 피드백에 기초하여 상기 결정된 도로의 손상 여부를 업데이트하는 업데이트 모듈을 포함하는, 도로 상태 평가 클라우드."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 전처리 모듈은,상기 획득된 촬영 영상의 촬영 방향과 지면이 형성한 각도가 수직이 되도록 상기 획득된 촬영 영상을 가공하도록 구성되는, 도로 상태 평가 클라우드."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 이미지 결합 모듈은,콘크리트 슬래브를 하나 이상 포함하도록 상기 전처리된 촬영 이미지를 복수 개씩 스티칭 기법을 통해 1차 결합하고, 상기 1차 결합된 촬영 이미지 간 중첩된 영역에 기초하여 상기 1차 결합된 촬영 이미지를 2차 결합하도록구성되는, 도로 상태 평가 클라우드."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 2차 결합된 촬영 이미지에 위치 정보를 동기화하도록 구성되는, 도로 상태 평가 클라우드."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 손상 여부 결정 모듈은,미리 학습된 도로 손상 결정 모델을 이용하여, 도로의 손상 여부를 결정하도록 구성되는, 도로 상태 평가 클라우드.공개특허 10-2024-0176133-3-청구항 6 제5항에 있어서,상기 프로세서는,상기 콘크리트 슬래브의 건전성 지수(SH)를 아래 [식 1]에 기초하여 산출하도록 구성되는, 도로 상태 평가 클라우드[식 1]SH = A/B,(여기서, A는 현재 콘크리트 슬래브의 면적 및 B는 콘크리트 포장 시공 시의 콘크리트 슬래브의 면적임)."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "인공 지능 기반의 도로 상태 평가 클라우드의 운영 방법으로서,차량에 탑재된 카메라를 통해 시계열 기반으로 도로를 촬영한 이미지를 획득하는 단계;상기 획득된 촬영 이미지를 전처리하는 단계;상기 전처리된 촬영 이미지에 포함된 콘크리트 슬래브의 이음선에 기초하여 스티칭 기법을 통해 상기 전처리된촬영 이미지를 결합하는 단계;상기 결합된 촬영 이미지에서 분할된 콘크리트 슬래브의 적어도 일부에 대한 도로의 손상 여부를 결정하는단계;상기 결정된 도로의 손상 여부에 대한 정보를 관련 단말에 제공하고, 상기 관련 단말의 피드백을 수신하는단계; 및상기 수신된 관련 단말의 피드백에 기초하여 상기 결정된 도로의 손상 여부를 업데이트하는 단계를 포함하는,운영 방법."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 전처리하는 단계는,상기 획득된 촬영 영상의 촬영 방향과 지면이 형성한 각도가 수직이 되도록 상기 획득된 촬영 영상을 가공하는단계를 포함하는, 운영 방법."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 결합하는 단계는,콘크리트 슬래브를 하나 이상 포함하도록 상기 전처리된 촬영 이미지를 복수 개씩 스티칭 기법을 통해 1차 결합하는 단계; 및상기 1차 결합된 촬영 이미지 간 중첩된 영역에 기초하여 상기 1차 결합된 촬영 이미지를 2차 결합하는 단계를포함하는, 운영 방법."}
{"patent_id": "10-2023-0076437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 2차 결합하는 단계 이후에,상기 2차 결합된 촬영 이미지에 위치 정보를 동기화하는 단계를 더 포함하고,상기 도로의 손상 여부를 결정하는 단계는,공개특허 10-2024-0176133-4-미리 학습된 도로 손상 결정 모델을 이용하여, 도로의 손상 여부를 결정하는 단계를 포함하는, 운영 방법."}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능 기반의 도로 상태 평가 클라우드가 제공된다. 본 클라우드는 통신부, 메모리 및 차량에 탑재된 카메라 를 통해 시계열 기반으로 도로를 촬영한 이미지를 통신부를 통해 획득하고, 적어도 하나의 코어를 포함하는 프로 세서를 포함한다. 프로세서는, 전처리 모듈, 이미지 결합 모듈, 손상 여부 결정 모듈 및 업데이트 모듈을 포함한 다. 본 클라우드가 제공됨으로써, 사용자 편의가 제고될 수 있다."}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 서비스를 제공하는 클라우드 시스템에 관한 것이다. 보다 상세하게는, 본 개시는 인공 지능 기반의 도로 상태 평가 클라우드 및 그의 운영 방법에 관한 것이다."}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 도로의 손상은 차량 운전자의 안전과 직결될 수 있으므로 정확하고 신속하게 모니터링 되어야 할 것이다. 크랙 (crack), 스폴링(spalling), 포트홀(pot hole) 등은 도로 손상의 대표적인 예로써, 크랙은 도로의 갈라진 틈을 나타내고, 스폴링은 표면 균열이 있는 곳에 하중이 가해져 표면이 서서히 박리되는 것을 나타내며, 포트홀은 도 로 포장의 공용시에 포장 표면에 생기는 국부적인 홀을 나타낸다. 포트홀은 아스팔트 바인더 골재의 점착력이 침투한 수분에 의해 약화되어 발생될 수 있다. 포트홀은 도로의 공용 수명을 감소시킬 뿐만 아니라 차량 파손 및 교통사고 유발의 원인이 될 수 있다. 특히, 고속도로의 경우 포트홀과 같은 도로의 심각한 포장 손상으로 인 한 위험은 더욱 증가될 수 밖에 없다. 도로관리기관에 소속된 인원에 의해 긴급 보수가 필요한 포장 손상이 육안으로 점검되고 있으나, 인적 자원의 육안 점검에 의한 관리체계는 고비용을 수반하면서도 도로 손상을 조기에 발견하기에는 역부족이다. 이에, 도로를 촬영한 이미지를 자동 수집하고 자동 수집된 촬영 이미지를 인공 지능 기반으로 분석하여 도로 상 태를 평가하는 방법이 인적 자원의 점검 이외에도 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-2202572호(등록일: 2021.01.07.)"}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 개시된 실시예는 인공 지능 기반으로 도로 손상을 자동 인식하는 도로 상태 평가 클라우드 시스템을 제공하는데 그 목적이 있다. 또한, 본 개시에 개시된 실시예는 고가의 라인 카메라를 사용하지 않고 일반 디지털 카메라를 사용하더라도 도 로 손상 인식에 불리함이 없도록, 촬영 영상을 가공하는 방법을 제공하는데 그 목적이 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시에 따른 인공 지능 기반의 도로 상태 평가 클라우드의 운영 방법은, 차량에 탑재된 카메라를 통해 시계열 기반으로 도로를 촬영한 이미지를 획득하는 단계; 상기 획득된 촬 영 이미지를 전처리하는 단계; 상기 전처리된 촬영 이미지에 포함된 콘크리트 슬래브의 이음선에 기초하여 스티 칭 기법을 통해 상기 전처리된 촬영 이미지를 결합하는 단계; 상기 결합된 촬영 이미지에서 분할된 콘크리트 슬 래브의 적어도 일부에 대한 도로의 손상 여부를 결정하는 단계; 상기 결정된 도로의 손상 여부에 대한 정보를 관련 단말에 제공하고, 상기 관련 단말의 피드백을 수신하는 단계; 및 상기 수신된 관련 단말의 피드백에 기초 하여 상기 결정된 도로의 손상 여부를 업데이트하는 단계를 포함할 수 있다.상기 전처리하는 단계는, 상기 획득된 촬영 영상의 촬영 방향과 지면이 형성한 각도가 수직이 되도록 상기 획득 된 촬영 영상을 가공하는 단계를 포함할 수 있다. 상기 결합하는 단계는, 콘크리트 슬래브를 하나 이상 포함하도록 상기 전처리된 촬영 이미지를 복수 개씩 스티 칭 기법을 통해 1차 결합하는 단계; 및 상기 1차 결합된 촬영 이미지 간 중첩된 영역에 기초하여 상기 1차 결합 된 촬영 이미지를 2차 결합하는 단계를 포함할 수 있다. 상기 인공 지능 기반의 도로 상태 평가 클라우드의 운영 방법은, 상기 2차 결합하는 단계 이후에, 상기 2차 결 합된 촬영 이미지에 위치 정보를 동기화하는 단계를 더 포함할 수 있다. 상기 도로의 손상 여부를 결정하는 단계는, 미리 학습된 도로 손상 결정 모델을 이용하여, 도로의 손상 여부를 결정하는 단계를 포함할 수 있다. 상기 인공 지능 기반의 도로 상태 평가 클라우드의 운영 방법은, 상기 콘크리트 슬래브의 건전성 지수(SH)를 아 래 [식 1]에 기초하여 산출하는 단계를 더 포함할 수 있다. [식 1] SH = A/B, 여기서, A는 현재 콘크리트 슬래브의 면적 및 B는 콘크리트 포장 시공 시의 콘크리트 슬래브의 면적 일 수 있다. 상술한 기술적 과제를 달성하기 위한 본 개시에 따른 인공 지능 기반의 도로 상태 평가 클라우드는, 통신부; 메 모리; 및 차량에 탑재된 카메라를 통해 시계열 기반으로 도로를 촬영한 이미지를 상기 통신부를 통해 획득하고, 적어도 하나의 코어를 포함하는 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 획득된 촬영 이미지를 전처리하는 전처리 모듈; 상기 전처리된 촬영 이미지에 포함된 콘 크리트 슬래브의 이음선에 기초하여 스티칭 기법을 통해 상기 전처리된 촬영 이미지를 결합하는 이미지 결합 모 듈; 상기 결합된 촬영 이미지에서 분할된 콘크리트 슬래브의 적어도 일부에 대한 도로의 손상 여부를 결정하는 손상 여부 결정 모듈; 및 상기 통신부를 통해, 상기 결정된 도로의 손상 여부에 대한 정보를 관련 단말에 제공 하고, 상기 관련 단말의 피드백을 수신하는 경우, 상기 수신된 관련 단말의 피드백에 기초하여 상기 결정된 도 로의 손상 여부를 업데이트하는 업데이트 모듈을 포함할 수 있다. 상기 전처리 모듈은, 상기 획득된 촬영 영상의 촬영 방향과 지면이 형성한 각도가 수직이 되도록 상기 획득된 촬영 영상을 가공하도록 구성될 수 있다. 상기 이미지 결합 모듈은, 콘크리트 슬래브를 하나 이상 포함하도록 상기 전처리된 촬영 이미지를 복수 개씩 스 티칭 기법을 통해 1차 결합하고, 상기 1차 결합된 촬영 이미지 간 중첩된 영역에 기초하여 상기 1차 결합된 촬 영 이미지를 2차 결합하도록 구성될 수 있다. 상기 프로세서는 상기 2차 결합된 촬영 이미지에 위치 정보를 동기화할 수 있다. 상기 손상 여부 결정 모듈은, 미리 학습된 도로 손상 결정 모델을 이용하여, 도로의 손상 여부를 결정하도록 구 성될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프 로그램이 더 제공될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 인공 지능 기반으로 도로 손상을 자동 분석 및 인식하는 시스템이 제공됨으로써 신속하게 도로 손상이 파악될 수 있고, 사용자 편의가 제고될 수 있으며, 일반 디지털 카메라를 통해 촬영된 이미지일지라도 영상 처리를 통해 도로 손상 파악에 효율적으로 사용될 수 있으므로, 비용 절감의 효과가 기대될 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명하"}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실 시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 인공 지능 기반의 도로 상태 평가 클라우드'는 클라우드 시스템뿐만 아니라 연 산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들로 구현될 수 있다. 예를 들어, 본 개시에 따른 본 개시에 따른 인공 지능 기반의 도로 상태 평가 클라우드는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 개시에 따른 인공 지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공 지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공 지능 전 용 프로세서인 경우, 인공 지능 전용 프로세서는, 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계 될 수 있다. 기 정의된 동작 규칙 또는 인공 지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공 지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으 로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공 지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공 지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서 버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습 (reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공 지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공 지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공 지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공 지능 구조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하, 첨부된 도면을 참조하여 본 개시의 실시예 를 상세하게 설명한다. 도 1은 본 개시에 따른 도로 상태를 평가하기 위해 선행적으로 도로 촬영 이미지를 수집하기 위한 방법을 개략 적으로 설명하기 위한 도면이다. 도 1에 따르면, 도로는 차량(CA)이 주행하는 차선뿐만 아니라 주변 다양한 오브젝트(가령, 중앙 분리대 등)를 포함할 수 있으나, 이하 본 명세서에서는, 도로를 차량(CA)이 주행하는 차선을 중심으로 설명하 기로 하며, 콘크리트 포장된 것으로 가정하여 설명하기로 한다. 참고로, 콘크리트 포장은 무근 콘크리트 포장과 철근 콘크리트 포장으로 구분될 수 있는데, 무근 콘크리트 포장 의 경우 철근이나 철골 등으로 보강하지 않은 콘크리트이고, 슬래브(slab)가 횡방향 또는 종방향의 이음선 에 의해 구분될 수 있으며, 철근 콘크리트 포장의 경우 인장력에 강한 철근을 넣어 보강 성형한 콘크리트이며, 하나의 큰 슬래브로 이루어져 이음에 의해 구분되지 않는다. 본 명세서에 개시된 도로는 무근 콘크리트 포 장된 도로라고 상정하여 기술하기로 한다. 도로는 중앙 분리대에 의해 구분되어 진행 방향을 기준으로 두개 차선(10a, 10b)을 예시적으로 포 함하며, 차량(CA)이 1차선(40a) 상에서 주행하고 있는 것으로 설명하기로 한다. 차량(CA)에는 도로 손상을 탐지 하기 위한 카메라(CA1)가 탑재될 수 있으며, 카메라(CA1)는 차량(CA)의 후방에 배치될 수 있으나, 실시예에 따 라 전방 또는 측방에 배치될 수도 있다. 도로는 하나 이상의 콘크리트 슬래브를 포함할 수 있으며, 하나의 콘크리트 슬래브는 종방향 이음선(V01, V02, V03) 및 횡방향 이음선(H01, H02)이 형성하는 내부 영역일 수 있다. 차량(CA)은 카메라(CA1)을 통해 주행하는 도로를 촬영할 수 있다. 여기서, 카메라(CA1)는 디지털 카메라일 수 있으나, 실시예가 이에 한정되는 것은 아니다. 또한, 촬영 이미지는 정지 영상을 기준으로 설명하나, 동영상 일 수도 있다. 도로 상에는 다양한 평가 영역이 있을 수 있는데, 가령, 크랙(crack), 조인트(joint), 크랙 실(crack seal), 패치(patch), 마커(marker), 맨홀(manhole) 등이 도로에 위치할 수 있다. 차량(CA)은 주행 중에 제1 도로 손상 영역(30-1)을 촬영할 수 있다. 실시예에서, 차량(CA)은 영상 검지 방식을 이용하여 제1 도로 손상 영역(30-1) 및 제2 도로 손상 영역(30-2)을 동시에 탐지할 수도 있다. 도 2는 본 개시에 따른 도로 상태 평가 시스템을 개략적으로 설명하기 위한 도면이다. 도로 상태 평가 시스템은 도로의 콘크리트 포장 상태를 평가하기 위한 시스템이며, 이해 당사자 간의 원 격 품질 관리를 위한 시스템이며, 도로 상태 평가 시스템은 도로 상태 평가 클라우드, QC 단말 , QA 단말 및 고객 단말을 포함할 수 있다. 도로 상태 평가 클라우드는 스토리지, 서버, 가상화 모듈/시스템, 운영체제, 미들웨어, 런타임 모듈, 데이 터 및 애플리케이션 등을 모두 구비할 수 있다. 이에, 클라이언트 단에서는 서비스 애플리케이션만 구비하면, 클라우드 시스템이 제공하는 다양한 기능을 이용할 수 있으며, 사용량에 따라 과금될 수 있다. 도로 상태 평가 클라우드는 SaaS(Server as a software) 기반으로 구현될 수 있으나, 실시예가 이에 한정되는 것은 아니다.도로 상태 평가 클라우드는 플래너(planner)의 기능을 수행할 수 있는데, 플래너는 인공 지능 기반으로 구 현될 수 있으며, 플래너는 계약 조건, 계약금액, 납금일 및 방법, 고객 어카운트 생성 등 도로자동평가 계약에 관한 내용을 담당하는 CP(contractual planner) 및 과제 목적에 맞는 자동 평가를 위한 도로상태평가 시방규정, preprocessing 방법, 도로손상종류, AI 모델 선정 등 기술에 관한 내용을 담당하는 TP(technical planner)를 포함할 수 있다. 실시예에서, 도로 상태 평가 클라우드는 플래너의 기능을 수행하는 단말과 통신하는 형태 로 구현될 수도 있다. 도로 상태 평가 클라우드는 시계열적으로 촬영된 도로 영상에서 도로의 손상 여부를 자동으로 결정할 수 있으며, 인공 지능 기반의 알고리즘을 이용할 수 있고, 도로의 손상 여부에 대한 정보를 QC 단말, QA 단말 및 고객 단말 등에 제공할 수 있다. QC 단말은 도로평가 프로젝트의 품질 관리를 위해 도로 상태 평가 클라우드로부터 도로 손상에 대한 정보를 수신할 수 있으며, 도로 손상 여부를 구비된 디스플레이에 출력할 수 있다. QC 단말은 도로 상태 평가 클라우드에 의해 판단된 도로 손상 여부를 검수 및 수정하는 사용자(labeler)에 대응하는 단말일 수 있다. QA 단말은 QC 단말 또는 도로 상태 평가 클라우드로부터 도로 손상에 대한 정보를 수신할 수 있 으며, 도로평가 프로젝트를 수행 시 고객이 기술적인 내용에 대한 이해가 부족하거나, 인원 및 시간의 부족으로 품질관리 프로세스에 고객의 적극적인 참여가 어려운 경우에, 고객의 대리인으로서 고객의 입장에서 labeler가 수행한 결과물에 대해 검수를 수행함으로써 품질보증(quality assurance)을 수행하기 위한 단말일 수 있다. 고객 단말은 도로 평가 프로젝트를 의뢰한 고객에 대응하는 단말일 수 있으며, 최종적으로 특정 도로의 손 상 여부에 대한 정보를 수신할 수 있다. 서술한 바와 같이, 도로 상태 평가 클라우드는 인공 지능 기반으로 도로 촬영 이미지에서 도로 손상 여부 를 1차적으로 결정하고, 다양한 이해 관계인(200~400)의 확인을 통해 도로 손상 여부에 대한 결정의 정확도가 향상될 수 있다. 도 3은 본 개시에 따른 인공 지능 기반의 도로 상태 평가 클라우드의 구성을 나타내는 블록도이다. 도 3을 참고하면, 본 개시에 따른 도로 상태 평가 클라우드는 통신부, 입력부, 디스플레이 , 메모리 및 적어도 하나의 프로세서를 포함할 수 있다. 다만, 도 3에 도시된 구성요소들은 본 개시에 따른 도로 상태 평가 클라우드를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설 명되는 도로 상태 평가 클라우드는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 상기 구성요소들 중 통신부는 외부 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으 며, 예를 들어, 방송 수신 모듈, 유선통신 모듈, 무선통신 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 입력부는 영상 정보(또는 신호), 오디오 정보(또는 신호), 데이터, 또는 사용자로부터 입력되는 정보의 입 력을 위한 것으로서, 적어도 하나의 카메라, 적어도 하나의 마이크로폰 및 사용자 입력부 중 적어도 하나를 포 함할 수 있다. 입력부에서 수집한 음성 데이터나 이미지 데이터는 분석되어 사용자의 제어명령으로 처리될 수 있다. 디스플레이는 도로 상태 평가 클라우드에서 처리되는 정보를 표시(출력)한다. 예를 들어, 디스플레이 는 도로 상태 평가 클라우드에서 구동되는 응용 프로그램(일 예로, 어플리케이션)의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 메모리는 도로 상태 평가 클라우드의 다양한 기능을 지원하는 데이터와, 제어부의 동작을 위한 프로 그램을 저장할 수 있고, 입/출력되는 데이터들(예를 들어, 음악 파일, 정지영상, 동영상 등)을 저장할 있고, 도 로 상태 평가 클라우드에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션 (application)), 본 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어 도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 이러한, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입 (Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM),SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리는 도로 상태 평가 클라우드와 는 분리되어 있으나, 유선 또는 무선으로 연결된 데이터베이스가 될 수도 있으며, 데이터 베이스 시스템으로 구 현될 수도 있다. 프로세서는 적어도 하나의 코어를 포함하며, 도로 상태 평가 클라우드 내의 구성요소들의 동작을 제 어하기 위한 알고리즘 또는 알고리즘을 재현한 프로그램에 대한 데이터를 저장하는 메모리, 및 메모리에 저장된 데이터를 이용하여 전술한 동작을 수행하는 적어도 하나의 프로세서(미도시)로 구현될 수 있다. 이때, 메모리와 프로세서는 각각 별개의 칩으로 구현될 수 있다. 또는, 메모리와 프로세서는 단일 칩으로 구현될 수도 있다. 프로세서는 차량에 탑재된 카메라를 통해 시계열 기반으로 도로를 촬영한 이미지를 통신부를 통해 획 득할 수 있다. 프로세서는 획득된 촬영 이미지를 전처리하는 전처리 모듈, 전처리된 촬영 이미지에 포함된 콘크리트 슬래브의 이음선에 기초하여 스티칭 기법을 통해 전처리된 촬영 이미지를 결합하는 이미지 결 합 모듈, 결합된 촬영 이미지에서 분할된 콘크리트 슬래브의 적어도 일부에 대한 도로의 손상 여부를 결정 하는 손상 여부 결정 모듈 및 통신부를 통해, 결정된 도로의 손상 여부에 대한 정보를 관련 단말에 제공하고, 관련 단말의 피드백을 수신하는 경우, 수신된 관련 단말의 피드백에 기초하여 결정된 도로의 손상 여 부를 업데이트하는 업데이트 모듈을 포함할 수 있다. 또한, 프로세서는 이하의 도 4 내지 도 12에서 설명되는 본 개시에 따른 다양한 실시 예들을 도로 상태 평 가 클라우드 상에서 구현하기 위하여, 위에서 살펴본 구성요소들을 중 어느 하나 또는 복수를 조합하여 제 어할 수 있다. 도 3에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구 성 요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상 의 지식을 가진 자에게 용이하게 이해될 것이다. 한편, 도 3에서 도시된 각각의 구성요소는 소프트웨어 및/또는 Field Programmable Gate Array(FPGA) 및 주문 형 반도체(ASIC, Application Specific Integrated Circuit)와 같은 하드웨어 구성요소를 의미한다. 도 4는 본 개시에 따른 도로 상태 평가 클라우드의 운영 방법을 설명하기 위한 시퀀스도이고, 도 5(a) 내 지 도 12는 본 개시에 따른 도로 상태 평가 클라우드의 프로세싱을 설명하기 위한 도면인데, 도 4를 설명 하면서 필요한 부분에서 함께 참조하기로 한다. 도로 상태 평가 클라우드의 운영 방법은 도로 상태 평가 클라우드의 프로세서에 의해 수행될 수 있으며, 프로세서는 상술한 바와 같이 전처리 모듈, 이미지 결합 모듈, 손상 여부 결정 모듈 및 업데이트 모듈 등을 포함할 수 있다. 먼저, 프로세서는 차량에 탑재된 카메라를 통해 시계열 기반으로 도로를 촬영한 이미지를 통신부를 통해 획득할 수 있다(S310). 촬영 이미지는 차량에 탑재된 디지털 카메라를 이용하여 초당 프레임 출력수에 따라 소정 주기로 수집될 수 있 으며, 일련의 정지 영상이 시간순으로 나열된 이미지일 수 있다. 실시예에서, 촬영 이미지는 동영상으로 촬영될 수도 있다. S310 단계 이후, 전처리 모듈은 획득된 촬영 이미지를 전처리할 수 있다(S320). 도 5(a) 및 도 5(b)를 참조하여 설명하기로 하는데, 도 5(a) 및 도 5(b)는 본 개시에 따른 디지털 카메라를 통 해 촬영한 이미지를 전처리하는 과정을 설명하기 위한 도면들이다. 도 5(a)에서, 프로세서가 획득한 도로의 촬영 이미지의 경우, 촬영 방향과 지면이 형성한 각도가 수직이 아닐 수 있는데, 고비용의 라인 카메라가 사용되지 않았기 때문이다. 이에, 전처리 모듈은 전처리 전의 제1 이미지(P1a)를 제2 이미지(P1b)로 변환할 수 있다. 전처리 모듈 은 도로 상태를 평가하기 위한 도로에서 사각형(Re)을 생성할 수 있는데, 사각형(Re)은 제1 내지 제4 포인 트(R1)(R1a~R1d)로 형성된 사각형이다. 전처리 모듈은 촬영 시점을 보정하여, 제1 이미지(P1a)의 촬영 방향과 지면이 형성한 각도가 수직이 되도 록, 제1 이미지(P1a)를 제2 이미지(P1b)로 변환(가공)할 수 있다. 즉, 전처리 모듈은 원근 왜곡이 발생된촬영 이미지를 평면 이미지로 변환하기 위해 앵글 보정을 수행할 수 있다. S320 단계 이후, 이미지 결합 모듈은 전처리된 촬영 이미지에 포함된 콘크리트 슬래브의 이음선에 기초하 여 스티칭 기법을 통해 전처리된 촬영 이미지를 결합할 수 있다(S330). 참고로, 콘크리트 슬래브(slab)는 횡방향 및 종방향의 이음선 내부의 영역이며, 무근 콘트리트에서 필수적이라 할 수 있다. 이미지 결합 모듈은 도로의 전처리된 시계열적 촬영 이미지(정지 영상)를 소정 사이즈로 그룹 화하여 1차 가공(1차 결합)한 후, 그룹화된 1차 가공 이미지끼리 다시 2차 가공(2차 결합)할 수 있다. 스티칭 기법은 이미지를 바느질로 꼬매듯이 연결하는 기법이라 할 수 있다. 도 6(a) 내지 도 7(b)를 참고하여 설명하기로 한다. 도 6(a) 내지 도 6(d)는 본 개시에 따른 스티칭 기법을 통 해 촬영 이미지를 1차 결합하는 과정을 설명하기 위한 도면들이고, 도 7(a) 및 도 7(b)는 본 개시에 따른 스티 칭 기법을 통해 촬영 이미지를 2차 결합하는 과정을 설명하기 위한 도면들이다. 도 6(a) 및 도 6(b)를 참고하면, 이미지 결합 모듈은 전처리된 제1 이미지(P2a) 및 제1 이미지(P2a)의 다 음 이미지를 합성하여 제2 이미지(P2b)를 생성할 수 있는데, 제2 이미지(P2b)는 스티칭 기법에 따라 복수의 이 미지가 결합(combining)된 이미지일 수 있다. 여기서, 이미지 결합 모듈은 하나 이상의 큰크리트 슬래브 (가령, 610)가 포함되게 할 수 있다. 하나의 콘크리트 슬래브는 종방향 이음선(V1, V2) 및 횡방향 이음선 (H1, H2)가 형성하는 내부 영역일 수 있다. 이미지 결합 모듈은 도 6(a) 내지 6(d)에 도시된 바와 같이, 콘크리트 슬래브가 여러 개 포함되도록 스티 칭 기법에 의해 촬영 이미지를 결합할 수 있다. 이미지 결합 모듈은 1차 스티칭을 수행할 때, 미리 설정된 콘크리트 슬래브의 개수에 따라 이미지 결합 개 수를 결정할 수 있다. 이미지 결합 모듈은 복수 개의 전처리된 촬영 이미지를 그룹화하여 1차 결합 이미지 를 생성하고, 1차 결합 이미지끼리 다시 스티칭 기법에 의해 2차 결합할 수 있다. 도 7(a)를 참고하면, 이미지 결합 모듈은 1차 결합된 촬영 이미지 간 중첩된 영역에 기초하여 스티칭 기법 을 통해 2차 결합할 수 있다. 이미지 결합 모듈은 1차 스티칭 결합 이미지를 생성할 때부터, 인접한 1차 스티칭 결합 이미지끼리 중첩된 영역을 포함하도록 생성할 수 있는데, 이미지 결합의 정확도를 높이기 위한 방법이다. 도 7(a)에서, 이미지 결합 모듈은 제4 슬래브(S4)와 제5 슬래브(S5)를 결할할 떄, 제4 슬래브(S4)의 일부 와 제5 슬래브(S5)의 일부가 서로 중첩되게 제1 스티칭 이미지(P3)(P3a,P3b)를 매칭하여 생성할 수 있다. 이미지 결합 모듈은 중첩 영역을 생성할 때, 중첩 영역 내에 횡방향 이음선(가령, S4b)이 공통적으로 하나 포함되게 생성할 수 있다. 즉, 이미지 결합 모듈은 제1 스티칭 이미지(P3a)의 제4 슬래브(S4)의 하단 횡방 향 이음선(S4b)이 제2 스티칭 이미지(P3b)의 상단 횡방향 이음선(S5a)과 중복되게, 중첩 영역을 생성할 수 있다. 만약, 도 7(b)에 도시된 바와 같이, 이미지 결합 모듈은 중첩 영역(L2a 부터 L2b)에 하단 횡방향 이음선 (S20b)이 공유되지 않는 경우, 이를 오류로 파악한 후, 중첩선(L2a)을 선 슬래브(S20)의 하단 횡방향 이음선 (S20b)보다 높게 설정할 수 있으며, 중첩선(L2b)을 하단 횡방향 이음선(S21b)보다 낮게 설정할 수 있다. 이에 따라, 이미지 간의 연결 정확도가 향상될 수 있으며, 중첩선의 배치도 점검될 수 있다. 프로세서는 2차 결합된 촬영 이미지에 위치 정보를 동기화할 수 있는데, 도 8을 참고하여 설명하기로 한다. 도 8은 본 개시에 따른 위치 정보를 촬영 이미지에 대응하는 과정을 설명하기 위한 도면이다. 프로세서는 2차 결합된 촬영 이미지(P6)에서 위치 정보를 차선의 중앙 부위에 매칭할 수 있다. 프로세서 는 GPS 정보의 위치 정보 간의 오차가 있으므로, 차선 중앙에 위치 정보(G1)(G1a~G1c)를 매핑할 수 있다. 실시예에서, 프로세서는 도로의 손상 부위가 소정 개수 이상이거나, 도로의 손상 부위가 위치 정보 사이에 여러 개 있는 것으로 결정한 경우, 해당 도로의 손상 부위가 위치 정보 사이에 하나씩 특정되도록 해당 도로의 위치 정보를 촘촘하게 매핑할 수 있다. 즉, 프로세서는 제1 위치 정보와 제2 위치 정보 사이에 하나의 손 상 부위가 배치되도록 위치 정보를 도로에 매핑할 수 있다. S330 단계 이후, 손상 여부 결정 모듈은 미리 학습된 도로 손상 결정 모델을 이용하여, 도로의 손상 여부 를 결정할 수 있는데, 도 9를 참고하여 설명하기로 한다. 도 9는 본 개시에 따른 인공 지능 기반으로 도로의 손상 여부를 결정하기 위한 모델을 설명하기 위한 도면이다. 해당 모델은 입력단계(S91), 특징 정보 추출 단계(S93), 손상 정보 수치화 단계(S95), 분류 단계(S97) 및 오브 젝트 특정 단계(S99)로 진행될 수 있다. 먼저, 입력단계(S91)에서, 모델은 서로 다른 스케일의 영상을 입력받을 수 있다. 가령, 특정 도로의 동일 위치 에 대해 스케일을 달리하여 확대를 많이 한 순으로(제1 스케일 영상이 가장 많이 확대), 입력 영상을 수집할 수 있다. 특징 정보 추출 단계(S93)에서, 모델은 컨볼루션 연산, 맥스 풀링 연산 등을 통해 특징 정보를 스케일 별로 추 출할 수 있다. 손상 정보 수치화 단계(S95)에서, 모델은 어텐션 모듈을 통해 각 스케일에서 추출된 특징 정보에서, 각 채널 및 공간 분포에 대해, 0 내지 1 의 스코어를 할당할 수 있다. 이에 따라, 각 이미지의 특징들이 보다 명확하게 추 출될 수 있다. 분류 단계(S97) 및 오브젝트 특정 단계(S99)에서, 모델은 분류기(가령, deep CNN classifier)를 이용하여, 도로 에 손상 영역이 있는지 결정할 수 있다. 상기 모델은 레이블에 기초하여 자동으로 학습될 수 있으며, 소정의 목표치에 도달하기까지 학습될 수 있으며, 추후 품질 성능 체크에서 점검된 정보도 모델에 반영될 수 있다. 실시예에서, 상술한 도 9에 도시된 모델이 아닌, 손상 여부 결정 모듈은 미리 학습된 도로 손상 결정 모델 (가령, Mask RCNN)을 적용할 수 있다. 여기서, Mask R-CNN은 객체 탐지(Object Detection)와 인스턴스 분할 (Instance Segmentation)을 수행하는 딥러닝 알고리즘이며, Mask R-CNN은 Faster R-CNN 알고리즘을 기반으로 하며, 입력 이미지에서 객체의 경계 상자(Bounding Box)를 찾는 객체 탐지 작업을 수행하고, 각 객체에 대해 픽 셀 단위로 인스턴스 분할을 수행할 수 있습니다. 이를 통해 객체가 어디에 있는지뿐만 아니라, 각 객체의 픽셀 단위로 정확한 마스크를 생성하여 객체의 윤곽을 추출할 수 있다. 이는 객체의 위치와 동시에 객체의 모양과 구 조를 파악하는 것을 가능하게 한다. 손상 여부 결정 모듈은 Mask RCNN 모델을 이용하여, 도 9에 도시된 알고리즘보다 semantic segmentation 에 기초하여, 콘크리트 슬래브의 면적을 보다 정확하게 산출할 수 있다. 도 10은 본 개시에 따른 인공 지능 기반으로 도로의 손상 형태를 결정한 결과를 나타낸다. 도 10을 참고하면, 손상 여부 결정 모듈은 각각의 스케일 별((a)~(c))로, 도로 상의 다양한 평가 영역(가 령, 크랙(crack), 조인트(joint), 크랙 실(crack seal), 패치(patch), 마커(marker), 맨홀(manhole) 등)을 특 정할 수 있으며, 디스플레이 또는 외부 관련 단말에 평가 영역에 대한 정보를 제공할 수 있다. 프로세서는 손상 종류 별로 픽셀 레벨 세그먼테이션에 기초하여 현재 특정된 도로의 면적 상에서 손상 종 류 별 점유율을 산출할 수 있다. 프로세서는 손상부위의 넓이(M)를 아래의 [식 1]에 따라 산출할 수 있다. [식 1] M = Pa * Re, 여기서, Pa 는 미리 학습된 도로 손상 결정 모델이 자동 분석한 손상 부위의 픽셀수이며, Re 는 카메라의 픽셀 해상도일 수 있다. 또한, 프로세서는 아래의 [식 2]에 따라 콘크리트 슬래브의 넓이(Ma)를 산출할 수 있다. [식 2] Ma = Pb * Re, 여기서, Pb는 미리 학습된 도로 손상 결정 모델이 자동 분석한 슬래브 내의 콘크리트 및 기타 세그멘트의 총 픽 셀수이며, Re 는 카메라의 픽셀 해상도일 수 있다. 프로세서는 특정된 도로 전체 영역에서 손상 부위의 비율을 산출할 수 있으며, 슬래브 각각의 손상 부위의 비율을 산출할 수 있다.프로세서는 도로의 노화도를 분석할 수 있는데, 콘크리트 슬래브의 건전성 지수(SH)를 아래 [식 3]에 기초 하여 산출할 수 있다. [식 3] SH = A/B, 여기서, A는 현재 콘크리트 슬래브의 면적 및 B는 콘크리트 포장 시공 시의 콘크리트 슬래브의 면적일 수 있다. 프로세서는 콘크리트 포장의 손상과 보수가 진행될수록 슬래브의 건전성이 100% 에서 점점 작아지게 되며, 슬래브 넓이가 작아질수로 단위면적 당 교통 하중의 응력이 커지게 되므로 도로 손상이 더욱 가속화될 수 있음 을 파악할 수 있다. 프로세서는, 상기 콘크리트 슬래브의 건정성 지수(SH) 이외에도, 슬래브 당 균열도, 슬래브 당 스폴링 (spalling), 슬래브 당 라벨링 (ravelling), 슬래브 당 펀치아웃 (punch-out), 슬래브 당 팝아웃 (pop-out) 및 슬래브 당 펌핑 (pumping) 등의 손상도를 정량화 할 수 있다. 다만, 상기 콘크리트 슬래브의 건정성 지수(SH)가 다른 손상도와 비교했을 때, 슬래브 면적 당 손상도를 나타낼 수 있다. 슬래브 면적 당 손상도의 장점은 일반적으로 콘크리트 포장의 유지보수에서 슬래브를 기준으로 수행되 므로 슬래브 상태에 대한 보다 정확한 지수가 제공될 수 있다. S340 단계 이후, 프로세서는 결정된 도로 손상 여부에 대한 정보를 관련 단말에 제공하고, 관련 단말의 피 드백을 수신할 수 있고(S350), 수신된 관련 단말의 피드백에 기초하여 상기 결정된 도로의 손상 여부를 업데이 트할 수 있다(S360). 도 11 및 도 12에 도시된 화면의 경우, 도로 상태 평가 클라우드의 디스플레이에 표시되거나 관련 단 말에 제공되는 화면일 수 있다. 도 11은 본 개시에 따른 인공 지능 기반으로 도로의 손상 여부를 출력하는 화면 을 설명하기 위한 도면이고, 도 12는 본 개시에 따른 도로의 손상 여부 결정의 정확도를 높이기 위한 방법을 설 명하기 위한 도면이다. 도로 상태 평가 클라우드의 프로세서는 도로 손상 영역을 디스플레이할 때, 손상 부위 및 슬래브의 이음선을 구분하여 다른 색상으로 출력할 수 있다. 또한, 프로세서는 평가된 손상 종류 별로 서로 다른 색 상으로 매핑하여 디스플레이할 수 있다. 프로세서는 인공 지능 기반의 도로 손상 결정 모델을 이용하여, 도로의 특정 영역에 대해 1차 평가한 후, QC 단말, QA 단말, 고객 단말 순으로 도로 손상에 대한 결정이 정확한지 평가할 수 있다. 프로세서는 QA 단말이 특정 영상(P7a)의 손상에 대한 평가가 잘못된 것으로 결정한 경우, 해당 결정 정보를 통신부를 통해 QA 단말로부터 수신할 수 있다. 프로세서는 해당 특정 영상(P7a)의 손상 여부를 다시 결정한 후, 다시 해당 결정 정보를 통신부를 통해 QA 단말로 제공할 수 있다. 황색의 숫 자 표시는 QA 단말에 의해 반려된 횟수를 나타낼 수 있다. 즉, 프로세서는 QC 단말, QA 단말 및 고객 단말 순으로 평가의 정확도 여부를 의뢰하면, 이에 대한 피드백을 수신할 수 있다. 이때, QA 단말이 QC 단말의 결정을 번복할 경우, 먼저 결정한 QC 단말의 결정도 보류되어, 보류 표시('빨간 엑스표')가 디스플레이될 수 있으며, 보류표시는 QA 단말 또는 고객 단말의 동의 커맨드 가 수신되어야 비로소 정상 표시(녹색)로 변경될 수 있다. 여기서, 고객 단말, QA 단말 및 QC 단말 순으로 결정 권한이 작아질 수 있다. 가령, QA 단말 이 손상 결정이 정확하다고 평가해도 고객 단말이 부정하는 경우, 고객 단말의 결정이 반영될 수 있다. 프로세서는 관련 단말(200~400)의 피드백에 기초하여, 손상 결정 모델의 파라미터를 업데이트할 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플"}
{"patent_id": "10-2023-0076437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다. 이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2023-0076437", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 본 개시에 따른 도로 상태를 평가하기 위해 선행적으로 도로 촬영 이미지를 수집하기 위 한 방법을 개략적으로 설명하기 위한 도면이다. 도 2는 본 개시에 따른 도로 상태 평가 시스템을 개략적으로 설명하기 위한 도면이다. 도 3은 본 개시에 따른 인공 지능 기반의 도로 상태 평가 클라우드의 구성을 나타내는 블록도이다. 도 4는 본 개시에 따른 인공 지능 기반의 도로 상태 평가 클라우드의 운영 방법을 설명하기 위한 시퀀스도이다. 도 5(a) 및 도 5(b)는 본 개시에 따른 디지털 카메라를 통해 촬영한 이미지를 전처리하는 과정을 설명하기 위한 도면들이다. 도 6(a) 내지 도 6(d)는 본 개시에 따른 스티칭 기법을 통해 촬영 이미지를 1차 결합하는 과정을 설명하기 위한 도면들이다. 도 7(a) 및 도 7(b)는 본 개시에 따른 스티칭 기법을 통해 촬영 이미지를 2차 결합하는 과정을 설명하기 위한 도면들이다. 도 8은 본 개시에 따른 위치 정보를 촬영 이미지에 대응하는 과정을 설명하기 위한 도면이다. 도 9는 본 개시에 따른 인공 지능 기반으로 도로의 손상 여부를 결정하기 위한 모델을 설명하기 위한 도면이다. 도 10은 본 개시에 따른 인공 지능 기반으로 도로의 손상 형태를 결정한 결과를 나타낸다. 도 11은 본 개시에 따른 인공 지능 기반으로 도로의 손상 여부를 출력하는 화면을 설명하기 위한 도면이다. 도 12는 본 개시에 따른 도로의 손상 여부 결정의 정확도를 높이기 위한 방법을 설명하기 위한 도면이다."}
