{"patent_id": "10-2022-0110131", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0030729", "출원번호": "10-2022-0110131", "발명의 명칭": "딥 러닝 기반 농작물 객체 검출 시스템", "출원인": "대한민국", "발명자": "이상희"}}
{"patent_id": "10-2022-0110131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 장치에 의해 촬영된 실시간 이미지에 등장하는 복수의 객체를 추적 대상 객체 또는 하나 이상의 비추적대상 객체로 분류하는 분류부;상기 실시간 이미지의 전, 후 프레임에서 각각 등장하는 복수의 객체에 대한 두 거리값(distance)을 산출하고,상기 두 거리값에 기초하여 상기 추적 대상 객체를 판별하여 추적 대상 객체별 고유 ID를 부여하는 추적부; 및상기 고유 ID가 부여된 추적 대상 객체의 개수를 산출하는 카운팅부를 포함하는 딥 러닝 기반 농작물 객체 검출 시스템."}
{"patent_id": "10-2022-0110131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 분류부는,상기 실시간 이미지를 S X S(S은 1 이상의 자연수) 그리드로 분할하는 분할모듈;분할된 각 그리드 셀의 바운딩 박스와 컨피던스 스코어를 예측하는 예측모듈; 및,복수의 분할된 그리드를 결합하되, NMS(Non-maximum Suppression) 과정을 통해 상기 바운딩 박스의 위치를 조정하여 객체의 종류를 판별하는 판별모듈을 포함하는 딥 러닝 기반 농작물 객체 검출 시스템."}
{"patent_id": "10-2022-0110131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 추적부는,상기 전, 후 프레임에 각각 등장하는 복수의 객체에 대한 제1 및 제2 객체정보를 추출하는 추출모듈;필터를 이용하여 제1 객체정보에 따라 예상되는 후 프레임에서의 추정 객체정보를 산출하고, 상기 추정 객체정보와 제2 객체정보간의 제1 거리값을 산출하는 제1 거리산출모듈;상기 전, 후 프레임에 각각 등장하는 복수의 객체의 특징값을 이용하여 제2 거리값을 산출하는 제2 거리산출모듈; 및상기 제1 및 제2 거리값을 합산한 결과값이 임계값을 이상인 객체를 동일 객체로 판별 및 추적하는 추적모듈을 포함하는 딥 러닝 기반 농작물 객체 검출 시스템."}
{"patent_id": "10-2022-0110131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 필터는,칼만 필터(kalman filter) 인 딥 러닝 기반 농작물 객체 검출 시스템."}
{"patent_id": "10-2022-0110131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 제1 및 제2 거리값은,각각 마하라노비스 거리(Mahalanobis distance) 및 코사인 거리(Cosine distance)인 딥 러닝 기반 농작물 객체공개특허 10-2024-0030729-3-검출 시스템."}
{"patent_id": "10-2022-0110131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 결과값은, 이하의 수학식,에 의해 산출되는 것인, 딥 러닝 기반 농작물 객체 검출 시스템(단, c는 결과값, dm은 마하라노비스 거리, dc는코사인 거리, λ는 하이퍼 파라미터)."}
{"patent_id": "10-2022-0110131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 실시간 이미지는, 이미지내 각 객체가 외부로 이송되는 방향에 따른 카운팅 라인이 설정되고,상기 카운팅부는,상기 실시간 이미지에서 상기 추적 대상 객체에 대응하는 바운딩 박스의 중심점이 상기 카운팅 라인을 통과할때, 객체의 개수를 가산하는 것인, 딥 러닝 기반 농작물 객체 검출 시스템."}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 모니터링 시스템을 개시한다. 보다 상세하게는, 본 발명은 딥 러닝에 기반한 이미지 내 객체 검출 알 고리즘을 이용하여 농작물의 수확량을 높은 정확도로 자동 측정할 수 있는 딥 러닝 기반 농작물 객체 검출 시스 템에 관한 것이다. 본 발명의 실시예에 따르면, 감자와 이물질을 판별하는 제1 알고리즘 및 객체를 추적하고 개수를 카운팅하는 제2 알고리즘을 이용하여 실시간 이미지를 분석함으로써, 시스템의 설치 공간의 제약을 받지 않으며, 간단한 구조로 구축 비용이 낮은 반면, 높은 정확도로 감자 수확량을 자동 측정할 수 있는 모니티링 시스템을 제공할 수 있는 효과가 있다."}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 모니터링 시스템에 관한 것으로, 특히 딥 러닝에 기반한 이미지 내 객체 검출 알고리즘을 이용하여 농작물의 수확량을 높은 정확도로 자동 측정할 수 있는 딥 러닝 기반 농작물 객체 검출 시스템에 관한 것이다."}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "감자는 쌀, 밀, 옥수수와 더불어 세계 4대 식량자원 중 하나로서, 국내 재배면적은 2020년 23,599 ha, 생산량은 553,194 ton에 달하는 주요 밭작물로 국내 농가 소득에 크게 기여하고 있다. 그러, 농촌인구 감소와 고령화로 인해 인건비는 지속적으로 상승하여 생산비는 증가하고 있으며, FTA 등 시장개 방 가속화로 값싼 농산물이 유입되고 있어 국내산 밭작물의 경쟁력 확보가 필요하다. 이에 대한 대안으로 투입 자재를 절감하여 생산비는 줄이면서 생산성은 증가시킬 수 있는 정밀농업(Precision Agriculture)의 중요성이 대두되고 있다. 정밀농업은 포장(圃場) 내 토양의 특성, 작물의 생육 및 수확량 등을 측정하고 탑재된 GPS(Global Positioning System)의 위치정보와 결합하여 포장 내 공간변이를 파악함으로써 위치별 특성에 맞춰 투입자원을 낮추는 동시 에 생산성은 높일 수 있는 농업을 가리킨다. 포장 내 수확량 변이 정보는 당해 연도 재배결과 및 다음 연도 계획 수립을 위한 기초적이며, 필수적인 정보로 중요성이 높다. 수확량 측정을 위해 로드셀(Load Cell), 기계시각(Machine Vision), 포토센서(Photosensor)를 활용한 방법 등이 연구되었으며, 미국, 유럽 및 일본 등에서는 콤바인에 로드셀을 부착하여 수확량을 측정하는 시스템이 실용화되어 사용되고 있다. 기계시각을 활용한 수확량 측정 방법은, 종래 가장 많이 사용되고 있는 로드셀을 사용한 방법과 대비하여 볼 때 공간의 제약을 받지 않고, 비교적 간단하게 시스템을 구성할 수 있어 적용 범위가 넓은 방법으로 알려져 있다. Larsson은 CCD카메라(Charge-Coupled Device Camera)를 컨베이어벨트 끝단에 설치하여 투영면적의 픽셀 수 분석을 통해 떨어지는 감자의 크기를 측정하였으며, Hofstee와 Molema는 라인 스캔 카메라를 설치하여 2D 정보를 기반으로 하는 대량 추정법을 개발하였다. 또한, Yaowei Long은 스테레오비전을 이용하여 2차 원 감자 영상에 깊이정보를 더해 체적을 측정하였다. 또한, Lee는 포장에 굴취된 감자의 영상을 획득하고 획득된 영상에서 감자를 검출하여 회귀식을 통해 무게를 추정하였다.그러나, 전술한 기계시각을 활용한 수확량 측정 방법에서는 연속적으로 촬영되는 영상에서 겹치는 동일한 감자 를 제거해야 하며, 경계 부분에 위치하여 잘린 감자를 제외하는 문제점이 있다. 이러한 문제를 해결하기 위해, 최근 산업에서 폭넓게 활용되고 있는 인공지능(Artificial Intelligence)의 활용 이 대안이 될 수 있다. 객체검출(Object Detection)에 활용되는 인공신경망으로는 RCNN(Region with Convolutional Network), Fast RCNN, Faster RCNN 방식이 있다. 이러한 R-CNN 계열의 검출 방법들은 영상에서 물체가 있을 법한 추측되는 후보를 뽑고(Region proposal), 이후 검출기를 통하여 물체를 분류(Classificatio n)하는 두 개의 네트워크로 구성된 검출기(2-stage detector)로 구성된다. 전술한 방식에 따르면, 정확도가 높다는 장점은 있으나, 여전히 처리 속도에 한계가 있어 수확 작업 중 컨베이 어에서 이송되는 감자를 실시간으로 검출하는 데 한계가 있다. 또한, 기존 2-stage detector에서 Region proposal 단계를 제거하고 한 번에 객체를 탐지하는 방식(1-stage detector)이 제안되었으나, 이는 Localization 및 Classification이 동시에 이루어짐에 따라 속도는 매우 빠르 지만, 정확도에 있어서 2-stage detector에 비해 다소 낮은 단점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2021-0140895호(공개일자: 2021.11.23.)"}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위해 안출된 것으로, 본 발명은 컨베이어 이송 속도를 고려하여 1-stage detector 중 하나인 YOLOv5를 사용해 객체를 판별 및 추적하고, 최종적으로 감자의 개수를 세는 시스템을 설계 함으로써, 실제 감자 수확기에서 이송되는 영상을 활용하여 농작물 수확량을 모니터링하는 데 과제가 있다."}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 과제를 해결하기 위해, 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템은, 카메라 장치 에 의해 촬영된 실시간 이미지에 등장하는 복수의 객체를 추적 대상 객체 또는 하나 이상의 비추적 대상 객체로 분류하는 분류부, 상기 실시간 이미지의 전, 후 프레임에서 각각 등장하는 복수의 객체에 대한 두 거리값 (distance)을 산출하고, 상기 두 거리값에 기초하여 상기 추적 대상 객체를 판별하여 추적 대상 객체별 고유 ID 를 부여하는 추적부 및, 상기 고유 ID가 부여된 추적 대상 객체의 개수를 산출하는 카운팅부를 포함할 수 있다. 상기 분류부는, 상기 실시간 이미지를 S X S(S은 1 이상의 자연수) 그리드로 분할하는 분할모듈, 분할된 각 그 리드 셀의 바운딩 박스와 컨피던스 스코어를 예측하는 예측모듈 및, 복수의 분할된 그리드를 결합하되, NMS(Non-maximum Suppression) 과정을 통해 상기 바운딩 박스의 위치를 조정하여 객체의 종류를 판별하는 판별 모듈을 포함할 수 있다. 상기 추적부는, 상기 전, 후 프레임에 각각 등장하는 복수의 객체에 대한 제1 및 제2 객체정보를 추출하는 추출 모듈, 필터를 이용하여 제1 객체정보에 따라 예상되는 후 프레임에서의 추정 객체정보를 산출하고, 상기 추정 객체정보와 제2 객체정보간의 제1 거리값을 산출하는 제1 거리산출모듈, 상기 전, 후 프레임에 각각 등장하는 복수의 객체의 특징값을 이용하여 제2 거리값을 산출하는 제2 거리산출모듈 및, 상기 제1 및 제2 거리값을 합산 한 결과값이 임계값을 이상인 객체를 동일 객체로 판별 및 추적하는 추적모듈을 포함할 수 있다. 상기 필터는, 칼만 필터(kalman filter)일 수 있다. 상기 제1 및 제2 거리값은, 각각 마하라노비스 거리(Mahalanobis distance) 및 코사인 거리(Cosine distance) 일 수 있다.상기 결과값은, 이하의 수학식,"}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "에 의해 산출될 수 있다(단, c는 결과값, dm은 마하라노비스 거리, dc는 코사인 거리, λ는 하이퍼 파라미터). 상기 실시간 이미지는, 이미지내 각 객체가 외부로 이송되는 방향에 따른 카운팅 라인이 설정되고, 상기 카운팅 부는, 상기 실시간 이미지에서 상기 추적 대상 객체에 대응하는 바운딩 박스의 중심점이 상기 카운팅 라인을 통 과할 때, 객체의 개수를 가산할 수 있다."}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 감자와 이물질을 판별하는 제1 알고리즘 및 객체를 추적하고 개수를 카운팅하는 제 2 알고리즘을 이용하여 실시간 이미지를 분석함으로써, 시스템의 설치 공간의 제약을 받지 않으며, 간단한 구조 로 구축 비용이 낮은 반면, 높은 정확도로 감자 수확량을 자동 측정할 수 있는 모니티링 시스템을 제공할 수 있 는 효과가 있다."}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "상기한 바와 같은 본 발명을 첨부된 도면들과 실시예들을 통해 상세히 설명하도록 한다. 본 발명에서 사용되는 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려 는 의도가 아님을 유의해야 한다. 또한, 본 발명에서 사용되는 기술적 용어는 본 발명에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술적 용어일 때에 는, 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에서 사용 되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하며, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 본 발명에서, \"구성된다\" 또는 \"포함한다\" 등의 용어는 발명에 기재된 여러 구성 요소들, 또는 여러 단계를 반 드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 또한, 본 발명에서 사용되는 제1, 제2 등과 같이 서수를 포함하는 용어는 구성 요소들을 설명하는데 사용될 수 있지만, 구성 요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일 하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 발명의 사상을 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 발명의 사상이 제한되는 것으로 해석되어서는 아니 됨을 유의해야 한다. 또한, 본 발명의 실시예에서는, 분류를 위한 딥 러닝 모델로서, YOLOv5(You Only Look Once)를 이용하고, 그 학 습 모델의 학습을 위한 학습 데이터를 입력받았다. 이러한 학습 데이터(ldata)로서, 2021년 11월 18일 가을감자 를 대상으로 경상남도 고령에 위치한 감자 재배 포장에서 획득한 영상을 이용하고 있으며, 이러한 학습 데이터 (ldata)에서 감자의 품종은 수미이고, 파종 후 약 100일이 경과한 포장에서 획득한 이미지이며, 영상 획득 시 영상 크기는 1090 X 1080 pixels, FPS는 24이다. 그리고, 촬영한 영상에서는 각 프레임의 이미지를 추출하였고, 이 중 감자가 온전히 컨베이어 내에 위치한 이미 지만을 따로 선별하여 구성한 9,906개의 학습데이터가 이용되었다. 도 1은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템에서 이용된 학습데이터의 라벨링 영역 이미지를 예시한 도면이고, 도 2는 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템에서 객체 분류 이미지를 예시한 도면이다. 도 1 및 도 2를 참조하면, 이미지 하단에 위치한 톤백 부분은 Detect 작업 시 제외됨에 따라, 본 발명의 실시예 에서는 컨베이어 부분만을 잘라낸 라벨링 영역(Labeling area)에서 라벨링 작업을 수행하였다. 뿐만 아니라, 본 발명의 실시예에서는 라벨링 작업시, 공지된 툴인 'Ybat(YOLO Bbox Annotation Tool)'을 사용 하여 감자(a), 흙 잔해(b), 줄기(c) 및, 작업자 손(d)의 4가지로 분류하였다. 그리고, 본 발명의 실시예에서는, 추가적인 학습 데이터의 확보를 위해 python의 albumentation library를 사용 하여 Equalization, Flip(Horzontal, Vertical), Rotate, Brightness Contrast, Gaussian Blur, CLAHE, Gaussian Noise, HSV, Down scale, Sharpen, Random Gamma 기법에 가중치를 랜덤으로 주고 10세트씩 데이터를 증폭하였다. 추가적으로 모든 기법이 랜덤으로 적용된 데이터 10세트를 포함하여 전체 데이터를 227,838개로 증 폭하였다. 아울러, 본 발명의 실시예에서는, 학습에 사용된 PC 사양으로, CPU는 AMD의 Ryzen 9 5950X 16 Core, GPU는 NVIDIA Geforce RTX 3090 2개, RAM은 128GB, OS는 Windows10 pro 64bit가 사용되었으며, Python-Pytorch를 사 용하여 전체 데이터를 8:2 비율로 Train과 Valid로 랜덤하게 나누고 batch-size는 64로 300회 학습을 수행하였 다. 이하, 도면을 참조하여 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템을 상세히 설명한다. 도 3은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 전체 구조를 나타낸 도면이다. 이하 의 설명에서 본 발명의 딥 러닝 기반 농작물 객체 검출 시스템 및 이를 이루는 각 구성부는 공지의 마이크로프 로세서에 의해 실행가능한 컴퓨터 프로그램으로 구현될 수 있고, 읽고 쓰기가 가능한 기록매체에 기록될 수 있 다. 이하의 설명에서 본 발명의 실시예에 따른 농작물 객체 검출 시스템은, 작업 현장에서 수확된 농작물이 이송되 는 실시간 영상을 이용하여 그 수확량을 AI 기술에 기반하여 자동으로 계산하는 시스템으로서, 농작물 중 감자 를 모니터링 대상으로 하며, 특히 수확량 산출을 위해 감자 수확기의 수집부 상단에 2차 이송 컨베이어 끝단에 카메라 장치를 설치하고 작업자의 1차 선별 이후의 영상을 실시간으로 촬영한 이미지를 이용한 예를 통해 본 발 명의 기술적 사상을 설명하나, 모니터링 대상이 특정 작물에 한정되는 것은 아니다. 또한, 감자 수확기는 감자를 굴취하여 이물질을 분리하고, 500kg 톤백에 수집하는 장치일 수 있다. 그리고, 본 발명의 농작물 객체 검출 시스템은 카메라 장치로부터 실시간으로 영상을 입력받고, 딥 러닝을 활용 하여 감자 객체와 이물질을 분류하고, 분류된 감자 객체에는 고유의 ID를 부여하여 객체를 추적한다. 또한, 이 후 각 객체가 영상 내 특정 위치에 도달하였을 때 객체를 카운팅하는 것을 특징으로 한다.이를 위한 구성으로서, 도 3을 참조하면 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템 은, 카메라 장치에 의해 촬영된 실시간 이미지에 등장하는 복수의 객체를 추적 대상 객체 또는 하나 이상의 비추적 대상 객체로 분류하는 분류부, 실시간 이미지의 전, 후 프레임에서 각각 등장하는 복수의 객체에 대한 두 거리값(distance)을 산출하고, 두 거리값에 기초하여 추적 대상 객체를 판별하여 추적 대상 객체별 고 유 ID를 부여하는 추적부 및, 고유 ID가 부여된 추적 대상 객체의 개수를 산출하는 카운팅부를 포함 할 수 있다. 분류부는 카메라 장치로부터 실시간으로 촬영된 감자 이미지(img)를 입력받아 등장하는 객체의 종류별 로 분류할 수 있다. 특히 본 발명의 실시예에 따르면, 농작물 중, 감자를 분류하기 위해 공지의 알고리즘인 YOLOv5가 이용될 수 있다. 객체는 도 2에 도시된 바와 같이 4 종류로 분류될 수 있고 각 객체에는 바운딩 박스 (bounding box)가 설정되어 이후 프레임부터 추적이 가능하게 된다. 이러한 기능을 수행하기 위해, 분류부(11 0)는 각 기능을 세분화한 복수의 모듈로 구성될 수 있다. 추적부는 분류부에 의해 분류된 4 종류의 객체 중, 감자 객체를 판단하고, 이미지 내 감자 객체의 이 동을 추적할 수 있다. 특히, 본 발명의 실시예에 따르면, 동일 감자 객체에 대한 중복 산정 문제를 최소화하기 위해 감자 객체 별 중복되지 않는 고유 ID를 부여할 수 있고, 감자 객체의 정확한 추적을 위하여 공지의 SORT 알고리즘이 이용될 수 있다. 바람직하게는, SORT 알고리즘에 신경망 네트워크인 CNN을 결합한 DeepCNN이 이용될 수 있다. 이러한 기능을 수행하기 위해, 추적부는 각 기능을 세분화한 복수의 모듈로 구성될 수 있다. 카운팅부는 추적중인 감자 객체가 톤백 부분으로 이송되는 시점에 감자 개수를 카운팅할 수 있다. 이를 위 해, 이미지 내 영역에는 카운팅 라인(Counting Line)이 정의되어 있고, 카운팅부는 카운팅 라인을 벗어나 는 객체 중, 고유 ID가 부여된 감자 객체의 개수를 계산할 수 있다. 전술한 구조에 따라, 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템은, 감자 수확기에 설치된 카메라 장치로부터 실시간으로 수확된 감자의 이송 상태를 촬영한 실시간 이미지에 대하여 딥러닝 알고리즘을 통해 감자와 타 객체를 분류하고, 분류된 객체의 추적하여 최종적으로 감자의 개수를 카운팅함으로써, 단순한 구조로 수백톤에 이르는 감자 수확량을 자동으로 산출할 수 있다. 이하, 도면을 참조하여 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템에 포함되는 각 구성부 를 상세히 설명한다. 도 4는 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 분류부를 나타낸 도면이다. 도 4를 참조하면, 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 분류부는, 실시간 이 미지(img)를 S X S(S은 1 이상의 자연수) 그리드로 분할하는 분할모듈, 분할된 각 그리드 셀의 바운딩 박 스와 컨피던스 스코어를 예측하는 예측모듈, 복수의 분할된 그리드를 결합하되, NMS(Non-maximum Suppression) 과정을 통해 바운딩 박스의 위치를 조정하여 객체의 종류를 판별하는 판별모듈을 포함할 수 있다. 분할모듈은 학습 모델인 YOLOv5에서 학습을 진행하는 모듈로서, 실시간 입력되는 이미지(img)를 S X S의 그리드로 분할하고, 분할된 영역에 대하여 여러 박스로 태깅하게 된다. 예측모듈은 분할된 각 그리드 셀의 바운딩 박스와 컨피던스 스코어를 예측한다. 여기서, 컴피던스 스코어 는 알고리즘이 검출한 것에 대하여 얼마나 정확한지를 알려주는 값으로서, 예를 들어 컨피던스 스코어가 0.99라 면 알고리즘은 검출된 객체가 검출해야 하는 대상과 거의 똑같다고 판단하는 것으로 볼 수 있다. 판별모듈은 바운딩 박스의 위치를 조정하여 객체의 종류를 전술한 4 종류 중 어느 하나로 판별할 수 있고, 판별결과(img')를 후술하는 추적부에 전달할 수 있다. 여기서, 판별모듈은 각 그리드를 결합하는 과정에서 NMS(Non-maximum Suppression) 작업을 수행함으로써, 바운딩 박스 위치를 조정하여 최종적으로 감자 객체를 추 론하게 된다. 이하, 도면을 참조하여 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 추적부의 구조를 상 세히 설명한다. 도 5는 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 추적부를 나타낸 도면이다. 도 5를 참조하면, 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 추적부는, 컨베이어 를 따라 이송되는 감자의 수를 세기 위해 각 감자에 고유 ID를 부여하고, 이를 추적할 수 있다.이를 위해, 추적부는 식별된 각 객체에 고유ID를 부여할 수 있으며, 감자가 이송되는 동안, 즉, 실시간 이 미지에서 감자 객체의 위치가 변화하는 동안 객체에 부여된 고유ID가 변경되는 것을 방지하기 위해, 칼만 필터 (Kalman filter)를 이용한 추적 알고리즘으로서 SORT 알고리즘을 이용할 수 있다. 특히, 본 발명의 실시예에서 는 칼만 필터(Kalman filter)와 헝가리안(Hungarian 알고리즘)을 사용하여 이미지내 객체를 추적할 수 있고, 기 존 SORT 알고리즘에 CNN을 추가하여 정확도는 개선한 DeepSORT 알고리즘이 적용될 수 있다. 이를 위한 구성으로서, 추적부는 입력되는 이미지의 전, 후 프레임에 각각 등장하는 복수의 객체에 대한 제1 및 제2 객체정보를 추출하는 추출모듈, 필터를 이용하여 제1 객체정보에 따라 예상되는 후 프레임에서 의 추정 객체정보를 산출하고, 추정 객체정보와 제2 객체정보간의 제1 거리값을 산출하는 제1 거리산출모듈 , 전, 후 프레임에 각각 등장하는 복수의 객체의 특징값을 이용하여 제2 거리값을 산출하는 제2 거리산출 모듈 및, 제1 및 제2 거리값을 합산한 결과값이 임계값을 이상인 객체를 동일 객체로 판별 및 추적하는 추 적모듈을 포함할 수 있다. 추출모듈은 객체가 분류된 이미지(img')에 대하여, 이미지(img')를 이루는 N(N은 자연수)번째 프레임과, N+1번째 프레임을 서로 비교하여 각 프레임에 등장하는 객체들에 대한 객체정보를 추출할 수 있다. 제1 거리산출모듈은 전, 후 프레임간 등장하는 객체간의 동일성을 판단하는 요건으로서, 마하라노비스 거 리(Mahalanobis distance)를 산출할 수 있다. N(N은 자연수)번째 프레임에 대하여 칼만 필터(Kalman filter)를 사용함에 따라 프레임 내 등장하는 하나 이상의 객체의 현재 객체정보 추정할 수 있고, 그 추정된 객체정보와, N(N은 자연수)번째 프레임내 등장하는 하나 이상의 객체에 대한 객체정보간의 마하라노비스 거리값을 구할할 수 있다. 제2 거리산출모듈은 N 프레임과 N+1프레임에 등장하는 객체의 특징값을 이용하여 코사인 거리(Cosine distance)를 산출할 수 있다. 추적모듈은 마하라노비스 거리값 및 코사인 거리값을 합산한 결과값이 임계값을 이상인 경우, 두 프레임에 서 모두 등장하는 해당 객체를 동일 객체로 판별할 수 있다. 추적모듈은 제1 및 제2 거리값을 합산한 결과값에 대하여, 이하의 수학식 1에 의해 산출할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, c는 결과값, dm은 마하라노비스 거리, dc는 코사인 거리, λ는 하이퍼 파라미터를 가리킨다. 이에 따라, 추적모듈은 결과값(c)이 임계값 이상인 객체에 대하여, 동일 객체로 판단하고 고유ID를 부여할 수 있다. 도 6은 딥 러닝 기반 농작물 객체 검출 시스템에 설정된 카운팅 라인 및 엔드 라인을 예시한 도면으로서, 추적 부에 의해 고유ID를 갖는 감자 객체의 라운딩 박스를 이용하여 객체의 중심 좌표가 이미지 내 미리 정해둔 카운팅 라인(Counting Line)을 통과하는 경우, 시스템은 카운팅 작업을 수행할 수 있다. 또한, 감자의 개체들은 유사한 모양들이 상당히 많이 존재할 수 있으며, 서로 다른 감자 객체에 동일한 고유ID 가 부여되는 상황을 방지하기 위해 별도의 엔드 라인(End Line)이 설정될 수 있다. 시스템은 엔드 라인(End Line)을 통과하는 고유ID는 검출하지 않을 수 있다. 이하, 도면을 참조하여 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템을 실제 구현하고, 그 평가결과를 통해 본 발명의 기술적 사상을 상세히 설명한다. 도 7은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 평과결과에 대한 이미지 및 데이터를 나타낸 도면이다. 본 발명의 농작물 객체 검출 시스템은, Python 언어를 통해 구현될 수 있고, 시스템은 영상부와 작업기록부를 더 포함할 수 있다.도 7을 참조하면, 객체 검출 시스템의 영상부를 예시한 것으로, 영상부가 제공하는 메인 윈도우는 2개의 탭으로 구성되고, 연결된 카메라 장치 또는 녹화된 비디오 이미지를 입력으로 받아 첫 번째 탭 영역에 실시간 영상을 송출함에 따라 화면상에 표시한다(a). 이때, 송출되는 영상에는 YOLOv5 훈련 모델을 통해 감자가 검출될 때, 감자 객체에 바운딩 박스가 중첩되어 표 시됨에 따라, 사용자는 감자의 검출 유무를 실시간으로 확인할 수 있다. 이후, 검출된 감자 객체가 노란색으로 표시된 카운팅 라인(Counting Line)에 도달할 때, 메인 윈도우 아래 서브 윈도우 영역으로 검출된 객체들의 모습을 표시된다. 또한, 메인 윈도우의 우측으로는 객체 검출 시스템의 기록 부가 표시된다. 기록부는 크게 3부분으로 구분될 수 있으며, 메인 윈도우 우측 상단에는 초당 수확된 감자의 개 수가 표시되고, 하단에는 시간에 따라 수확된 감자의 수가 그래프로 표시된다. 메인 윈도우의 2번째 탭의 테이 블은 전술한 정보 및 누적 개수를 테이블 형태로 기록되도록 구성된다(b). 도 8은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 학습 모델의 평가시 관심영역에서의 각 객체의 분류 결과에 이미지를 예시한 도면이다. 도 8을 참조하면, 관심 영역에서 각 객체의 분류 결과를 보여주고 있으며, 이에 대한 평가과정은 다음과 같다. 먼저, 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 학습 모델의 평가는 정밀도 (precision), 재현율(recall), mAP(mean Average Precision) 및 F1 Score의 평가지표를 사용하여 수행되었다. 여기서, 정밀도는 이하의 수학식 2에 의해 산출된다. 수학식 2"}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "또한, 재현율은 이하의 수학식 3에 의해 산출된다. 수학식 3"}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, True Positive는 학습모델이 포지티브 클래스를 올바르게 예측한 결과를 나타내고, False Positive는 모델이 포지티브 클래스를 잘못 예측한 결과를 나타낸다. 또한, True Negative는 모델이 네가티브 클래스를 올 바르게 예측한 결과를 나타내고, False Negative는 모델이 네가티브 클래스를 잘못 예측한 결과를 나타낸다. 그리고, 데이터 클래스 간 불균형이 심할 때 사용되는 지표인 F1 Score는 정밀도와 재현율의 조화평균으로, 이 하의 수학식 4에 의해 산출된다. 수학식 4"}
{"patent_id": "10-2022-0110131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이에 따라, 평가 결과에 따르면, 이하의 표 1에 나타난 바와 같이 학습 횟수(epoch)의 증가에 따라 모든 평가지 수가 증가함을 알 수 있다. 300회 학습시 정밀도, 재현율, mAP 및 F1 Score는 각각 0.9997, 0.9994, 0.9872,0.9996으로 계산되었다. 표 1 Epoch Rresion Recall mAP F1 Score 1 0.8608 0.7793 0.5770 0.8180 100 0.9959 0.9966 0.9692 0.9827 200 0.9968 0.9979 0.9796 0.9974 300 0.9997 0.9994 0.9872 0.9996 여기서, 컴퓨터 비전 분야에서 지표로 사용되는 mAP는 평가지표 중 하나로써, IoU(Intersection of Union) Threshold를 0.5에서 0.05씩 증가시켜 0.95까지 계산된 값들의 평균값을 사용한다. 평가에 사용된 영상데이터는 학습데이터를 추출한 원본 영상과 실험실 내 실시간 영상을 사용한 것이다. 상기한 설명에 많은 사항이 구체적으로 기재되어 있으나 이것은 발명의 범위를 한정하는 것이라기보다 바람직한 실시예의 예시로서 해석되어야 한다. 따라서, 발명은 설명된 실시예에 의하여 정할 것이 아니고 특허청구범위와 특허청구범위에 균등한 것에 의하여 정하여져야 한다."}
{"patent_id": "10-2022-0110131", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템에서 이용된 학습데이터의 라벨링 영역 이미지를 예시한 도면이다. 도 2는 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템에서 객체 분류 이미지를 예시한 도면이 다. 도 3은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 전체 구조를 나타낸 도면이다. 도 4는 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 분류부를 나타낸 도면이다. 도 5는 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 추적부를 나타낸 도면이다. 도 6은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템에 설정된 카운팅 라인 및 엔드 라인을 예시한 도면이다. 도 7은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 평과결과에 대한 이미지 및 데이터를 나타낸 도면이다. 도 8은 본 발명의 실시예에 따른 딥 러닝 기반 농작물 객체 검출 시스템의 학습 모델의 평가시 관심영역에서의 각 객체의 분류 결과에 이미지를 예시한 도면이다."}
