{"patent_id": "10-2021-0163003", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0076243", "출원번호": "10-2021-0163003", "발명의 명칭": "산업현장의 안전사고 예방방법 및 그 장치", "출원인": "심용수", "발명자": "심용수"}}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "실제공간을 촬영하여 가상공간을 생성하는 단계; 상기 실제공간에 대한 3차원 모델과 상기 가상공간을 비교하여 상기 3차원 모델과 상기 가상공간 사이에 차이가존재하는 영역을 파악하는 단계; 및상기 차이가 존재하는 영역을 제시하는 단계;를 포함하는 것을 특징으로 하는 산업현장의 안전사고 예방방법."}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 제시하는 단계는,기 정의된 위험요소판단알고리즘을 이용하여 상기 차이가 존재하는 영역이 위험요소인지 파악하는 단계;를 포함하는 것을 특징으로 하는 산업현장의 안전사고 예방방법."}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 상기 제시하는 단계는,상기 차이가 존재하는 영역에 나타나는 객체의 종류를 인공지능모델을 이용하여 인식하는 단계; 및상기 인식한 객체의 종류가 위험요소인지 파악하는 단계;를 더 포함하는 것을 특징으로 하는 산업현장의 안전사고 예방방법."}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 제시하는 단계는,위험요소 처리결과리스트를 저장하는 데이터베이스를 참조하여 상기 차이가 존재하는 영역의 객체가 이전에 파악된 위험요소 처리결과리스트에 존재하는지 파악하는 단계; 및상기 위험요소 처리결과리스트에 저장된 상기 객체에 대한 처리방법에 따라 상기 객체가 처리되지 않았다면 위험요소로 제시하는 단계;를 포함하는 것을 특징으로 하는 산업현장의 안전사고 예방방법."}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "실제공간을 촬영하여 가상공간을 생성하는 가상공간생성부;상기 실제공간에 대한 3차원 모델과 상기 가상공간을 비교하여 상기 3차원 모델과 상기 가상공간 사이에 차이가존재하는 영역을 파악하는 비교부; 및상기 차이가 존재하는 영역을 제시하는 위험요소제시부;를 포함하는 것을 특징으로 하는 안전사고예방장치."}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서, 상기 위험요소제시부는,기 정의된 위험요소판단알고리즘을 이용하여 상기 차이가 존재하는 영역이 위험요소인지 파악하는 것을 특징으로 하는 안전사고예방장치."}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5항에 있어서, 상기 위험요소제시부는,상기 차이가 존재하는 영역에 나타나는 객체의 종류를 인공지능모델을 이용하여 인식하고, 상기 인식한 객체의종류가 위험요소인지 파악하는 것을 특징으로 하는 안전사고예방장치.공개특허 10-2023-0076243-3-청구항 8 제 5항에 있어서, 상기 위험요소제시부는,위험요소 처리결과리스트를 저장하는 데이터베이스를 참조하여 상기 차이가 존재하는 영역의 객체가 이전에 파악된 위험요소 처리결과리스트에 존재하는지 파악하고, 상기 위험요소 처리결과리스트에 저장된 상기 객체에 대한 처리방법에 따라 상기 객체가 처리되지 않았다면 위험요소로 제시하는 것을 특징으로 하는안전사고예방장치."}
{"patent_id": "10-2021-0163003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항 내지 제 4항 중 어느 한 항에 기재된 방법을 수행하기 위한 컴퓨터 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2021-0163003", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "산업현장의 안전사고 예방방법 및 그 장치가 개시된다. 안전사고예방장치는 실제공간을 촬영하여 가상공간을 생 성하고, 실제공간에 대한 3차원 모델과 가상공간을 비교하여 3차원 모델과 가상공간 사이에 차이가 존재하는 영 역을 파악하고, 차이가 존재하는 영역을 위험요소로 제시한다."}
{"patent_id": "10-2021-0163003", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시 예는 산업현장의 안전사고를 예방하는 방법 및 그 장치에 관한 것으로, 보다 상세하게는 안전사 고 예방을 위하여 위험요소를 파악하여 사전에 제공하는 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2021-0163003", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "건설현장, 물류현장, 공장 등 다양한 산업현장은 늘 안전사고에 노출되어 있다. 물건 등을 잘못된 곳에 적재하 거나, 부주의한 건설장비의 이동 등으로 인해 사고가 발생할 수 있다. 안전사고 관리자가 메뉴얼을 기반으로 각 산업현장을 점검할 수 있으나 이는 점검시점에서의 위험요소의 감지일 뿐 실시간 변화하는 산업현장의 위험요소 를 파악하기는 어렵다. 특히 건설현장의 경우 다양한 자재가 적재되고 이동되는 등 현장상황이 늘 변화하므로 근로자 등이 안전사고의 위험요소를 정확하게 구분하여 실시간 조치하는데 한계가 있다."}
{"patent_id": "10-2021-0163003", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시 예가 이루고자 하는 기술적 과제는, 산업현장의 안전사고 예방을 위하여 위험요소를 파악하여 제공하는 방법 및 그 장치를 제공하는 데 있다."}
{"patent_id": "10-2021-0163003", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기의 기술적 과제를 달성하기 위한, 본 발명의 실시 예에 따른 산업현장의 안전사고 예방방법의 일 예는, 실 제공간을 촬영하여 가상공간을 생성하는 단계; 상기 실제공간에 대한 3차원 모델과 상기 가상공간을 비교하여 상기 3차원 모델과 상기 가상공간 사이에 차이가 존재하는 영역을 파악하는 단계; 및 상기 차이가 존재하는 영 역을 제시하는 단계;를 포함한다. 상기의 기술적 과제를 달성하기 위한, 본 발명의 실시 예에 따른 안전사고예방장치의 일 예는, 실제공간을 촬영 하여 가상공간을 생성하는 가상공간생성부; 상기 실제공간에 대한 3차원 모델과 상기 가상공간을 비교하여 상기 3차원 모델과 상기 가상공간 사이에 차이가 존재하는 영역을 파악하는 비교부; 및 상기 차이가 존재하는 영역을 제시하는 위험요소제시부;를 포함한다."}
{"patent_id": "10-2021-0163003", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 산업현장의 안전사고 위험요소를 파악하여 담당자 등에게 알려줄 수 있다. 다른 실시 예로, 깊이카메라와 라이다를 이용하여 가상공간을 실제공간과 오차없이 생성하여 3차원 모델과 가상공간 의 차이 영역의 위험요소를 정확하게 판단할 수 있다."}
{"patent_id": "10-2021-0163003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면들을 참조하여 본 발명의 실시 예에 따른 산업현장의 안전사고 예방방법 및 그 장치에 대 해 상세히 살펴본다. 도 1은 본 발명의 실시 예에 따른 산업현장의 안전사고를 예방할 수 있는 장치의 일 예를 도시한 도면이다. 도 1을 참조하면, 안전사고예방장치는 적어도 하나 이상의 촬영장치로부터 수집한 산업현장 촬영데이 터를 기초로 위험요소 등을 파악하여 사용자단말에 제공한다. 촬영장치는 실시 예에 다양한 기기로 구현될 수 있다. 예를 들어, 촬영장치는 깊이카메라(depth camera)와 라이다(LiDAR, Light Detection and Ranging)를 함께 포함하거나, 깊이카메라만을 포함하거나, 라이 다만을 포함하거나, 또는 일반카메라와 라이다를 함께 포함할 수 있다. 즉, 촬영장치는 3차원의 가상공간 (또는 가상객체)을 생성하기 위하여 현실 공간을 촬영하는 기기이다. 깊이카메라만을 이용하여 3차원 가상공간 (또는 가상객체)을 생성하는 경우에 카메라 렌즈의 왜곡(distortion)으로 인해 3차원 가상공간(또는 가상객체) 이 왜곡되므로 현실의 객체와 오차없는 정확한 3차원 가상공간(또는 가상객체)을 생성하기 위하여 깊이카메라와 라이다를 함께 이용할 수 있으며, 이에 대해서는 도 8 이하에서 다시 살펴본다. 촬영장치는 산업현장의 근로자나 관리자 등 산업현장에 위치한 사용자들이 소지하거나 착용하는 형태로 구 현될 수 있다. 예를 들어, 촬영장치는 스마트폰이나 AR(Augmented Reality) 글래스, HMD(Head mounted Display) 등의 일부로 구현될 수 있다. 다른 실시 예로, 촬영장치는 산업현장의 지정된 장소에 설치된 기 기(예를 들어, CCTV와 같이 각 산업현장을 고정된 위치에서 촬영하는 형태)일 수 있다. 또는 고정된 촬영장치와 사용자가 소지 또는 착용한 촬영장치가 모두 본 실시 예에 적요될 수 있다. 본 실시 예가 적용되는 산업현장은 건설현장, 물류현장, 공장 등 다양하며 특정한 장소로 한정되는 것은 아니다. 또한 본 실시 예는 이해를 돕기 위하여 산업현장이라는 용어를 사용하고 있으나, 산업현장은 안전사고 가 발생할 수 있는 장소이면 모두 해당할 수 있다. 예를 들어, 본 실시 예는 일반가정이나 직장 등에서도 안전 사고 예방의 목적으로 사용될 수 있으며 이 경우 산업현장은 일반가정이나 직장 등으로 해석될 수 있다. 다만 이하에서는 설명의 편의를 위하여 산업현장이 시공 중인 건설현장인 경우를 가정하여 설명한다. 사용자단말은 안전사고예방장치로부터 안전사고 예방을 위한 관련 정보를 수신한다. 사용자단말은 기 지정된 관리자 등의 단말일 수 있다. 사용자단말은 일반컴퓨터, 테블릿PC, 스마트폰 등 통신이 가능한 다 양한 종류의 단말일 수 있다. 도 2는 본 발명의 실시 예에 따른 안전사고 예방방법의 일 예를 도시한 도면이다. 도 2를 참조하면, 안전사고예방장치는 일정 공간(예를 들어, 아파트 시공 현장에서 특정 동/호수의 공간 등)을 촬영하여 가상공간(또는 가상객체)을 생성한다. 일 실시 예로, 안정사고예방장치는 깊이카메라 로 촬영하여 얻은 영상프레임과 라이다로 측정하여 얻은 측정프레임을 포함하는 촬영데이터를 이용하여 일정 공 간을 가상공간(또는 가상객체)으로 생성할 수 있다. 일 실시 예로, 안전사고예방장치는 촬영데이터에서 배경과 객체를 구분하여 공간 내 존재하는 적어도 하나 이상의 객체에 대한 가상객체를 생성할 수 있다. 다른 실시 예로, 안전사고예방장치는 촬영데이터에서 배경과 객체를 모두 포함하는 가상공간을 생성할 수 있다. 객체는 건물의 상하수도관, 벽면, 창문 등이나 각종 물건(건설장비나 각종 자재 등), 동식물이나 사람, 바닥이 나 벽 등의 구멍 등 다양할 수 있다. 예를 들어, 도 3과 같이 촬영데이터에 동물이 촬영되면, 안전사고예방장치 는 동물에 대한 가상객체를 생성할 수 있다. 촬영 공간에서 배경과 객체는 상대적인 개념으로 실내 공간의 벽 등도 객체로 파악될 수 있으며, 실외 공간의 바닥면도 객체로 파악될 수 있다. 따라서 이하에서 가상공간이라고 함은 적어도 하나 이상의 가상객체가 존재하는 공간이라고 정의하며, 실시 예에 따라 일반적으로 배경으로 인식 되는 벽이나 천장, 바닥면 등을 객체로 포함하거나 포함하지 않을 수 있다. 안전사고예방장치는 촬영 공간에 대하여 기 정의된 3차원 모델과 촬영데이터를 이용하여 생성한 가상 공간을 비교하여 차이나는 영역을 파악한다. 실제 공간에 대한 3차원 모델은 다양한 형태로 미리 정 의되어 있을 수 있다. 예를 들어, 3차원 모델은 건물의 3차원 설계 도면(캐드 도면 등)을 토대로 만들어질 수 있다. 본 실시 예에서, 가상공간에는 3차원 모델에 존재하지 않는 구멍과 물건이 존재한다. 또한, 건설 현장의 시공 단계에서 시설물을 아직 설치하지 않아 가상공간에는 3차원 모델에 존재하는 시설물이 존재하지 않을 수도 있다. 가상공간과 3차원 모델에서 차이나는 영역은 모두 위험요소 가 아닐 수 있다. 가상공간과 3차원 모델을 중첩하여 차이나는 부분을 파악하기 위하여 가상공간이 3차원 모델의 어느 부분에 해당하는지 알아야 한다. 예를 들어, 아파트에 대한 설계 도면을 기초로 3차원 모델이 생성되고, 가상공간은 아파트 시공단계에서 특정 동/호수의 공간일 수 있다. 가상공간과 맵핑되는 3차원 모델9230)의 영역을 사용자가 직접 지정하거나 자동으로 맵핑되도록 할 수 있다. 예를 들어, 안전사고예방장치는 3차원 모델에서 가상공간과 맵핑되는 영역이 어느 곳인지 사용자로부터 직접 선택받을 수 있다. 다른 예로, 촬영 장치가 GPS(Global Positioning System)를 포함하는 경우에, 안전사고예방장치는 촬영데이터의 GPS 정보 를 기반으로 가상공간이 3차원 모델의 어느 영역에 해당하는지 파악할 수 있다. 또 다른 실시 예로, 실내 공간에서 촬영이 이루어지는 경우에 GPS 등으로 위치를 파악하는 것이 불가능하므로 촬영장치는 각 공간에 부여된 공간식별정보를 사용자로부터 입력받거나 또는 각 공간의 일측에 위치한 태그를 태깅하여 태그의 공간식 별정보와 함께 촬영데이터를 저장할 수 있다. 안전사고예방장치는 촬영데이터와 함께 저장된 공간식별정보 를 기초로 3차원 모델의 대응하는 영역을 파악하고 가상공간과 비교할 수 있다. 안전사고예방장치는 3차원 모델과 가상공간의 차이나는 영역(210,220)을 사용자단말로 제공하여 사용자가 위험요소 여부를 시각적으로 확인할 수 있게 제공할 수 있다. 다만, 건설 현장 등에서 촬영되는 공간 의 개수는 매우 많으므로, 차이나는 영역을 모두 사용자단말로 제시하여 사용자가 일일이 위험요소를 구분하는 것은 비효율적일 수 있다. 안전사고예방장치는 위험요소 여부를 자동으로 파악할 수 있는 방법을 포함할 수 있으며 이에 대한 예가 도 3 내지 도 5에 도시되어 있다. 도 3은 본 발명의 실시 예에 따른 위험요소 파악 방법의 일 예를 도시한 도면이다. 도 3을 참조하면, 안전사고예방장치는 위험요소를 미리 정의하고 있을 수 있다. 예를 들어, 산업현장이 가 연성 물질을 다루는 공장이면, 위험요소로 난로나 히터 등의 가열기구를 미리 정의할 수 있다. 안전사고예방장 치는 산업현장을 촬영하여 만든 가상공간과 산업현장에 대하여 미리 정의된 3차원 모델을 비교하여 차이나 는 영역)을 파악하고, 차이나는 영역에 존재하는 가상객체(300,310)의 종류를 식별하여 미리 정의된 위험요소 객체인지 파악할 수 있다. 가상객체가 미리 정의된 위험요소로 파악되면, 안전사고예방장치는 이를 사용자 단말에 메시지 등의 형태로 알려줄 수 있다. 차이나는 영역의 가상객체(300,310)의 종류를 식별하는데 종래의 다양한 인공지능모델이 사용될 수 있다. 3차원 이미지에서 객체 종류를 식별하는 인공지능모델 그 자체는 이미 널리 알려진 기술이므로 이에 대한 상세한 설명은 생략한다. 다른 실시 예로, 3차원 모델과 가상공간의 차이나는 영역에 존재하는 가상객체(300,310)가 위험요소가 아닐 수 있다. 예를 들어, 지나가는 고양이가 촬영되거나 지나가는 근로자 등이 촬영되면 고양이나 사람 등의 가상객체 가 가상공간에 존재할 수 있다. 따라서 안전사고예방장치는 위험요소 객체 종류와 함께 위험요소가 아닌 객체 종류도 함께 정의할 수 있다. 3차원 모델과 가상공간의 차이나는 영역에 존재하는 가상객체가 미리 정의된 위험요소가 아닌 객체 리스트(예를 들어, 고양이나 개 등의 동물 등)에 존재하는 객체이면, 안전사고예방장치 는 해당 가상객체가 위험요소가 아니라고 판단할 수 있다. 도 4는 본 발명의 실시 예에 따른 가상공간의 가상객체를 식별하여 위험요소 여부를 파악하는 방법의 일 예를 도시한 도면이다. 도 4를 참조하면, 안전사고예방장치는 가상공간과 3차원 모델 사이의 차이나는 영역의 3차원 이미지 (즉, 3차원 데이터)를 인공지능모델에 입력하여 해당 영역의 객체의 종류가 무엇인지 인식할 수 있다. 인공지능모델은 미리 정의된 객체의 종류를 식별하도록 훈련된 모델이다. 인공지능모델은 CNN(Convolutional Neural Network) 등 다양한 모델로 구현될 수 있으며, 객체의 종류를 인식하는 종래의 다양 한 인공지능모델이 본 실시 예에 적용될 수 있다. 실시 예에 따라 식별할 객체의 종류가 많은 경우 복수의 인공 지능모델이 사용될 수 있다. 안전사고예방장치는 위험요소판단알고리즘을 이용하여 인식 객체가 위험요소인지 판단한다 . 예를 들어, 위험요소판단알고리즘은 미리 정의된 위험요소 객체 리스트 및/또는 위험요소가 아닌 객체 리스트를 포함하고, 식별된 객체의 종류가가 각 리스트에 존재하는지 파악할 수 있다. 다른 실시 예로, 위험요소판단알고리즘은 객체 종류별 위험요소판단기준을 정의하고 있을 수 있다. 예를 들어, 도 2와 같이 인식된 객체가 근로자이면, 위험요소판단알고리즘은 근로자의 헬맷 착용 여부를 파악하 는 알고리즘일 수 있다. 3차원 이미지로 표시되는 근로자의 가상객체에서 헬맷의 존재 여부를 파악하는 다양한 알고리즘이 본 실시 예에 적용될 수 있다. 이 외에도 위험요소판단알고리즘은 실시 예에 따라 다양한 판단기준 을 설정할 수 있으며 어느 하나의 예로 한정되는 것은 아니다. 도 5는 본 발명의 실시 예에 따른 위험요소의 처리 결과 리스트를 이용하여 위험요소 여부를 파악하는 방법의 일 예를 도시한 도면이다. 도 5를 참조하면, 안전사고예방장치는 위험요소 처리결과리스트를 포함할 수 있다. 데이터베이스에 저장된 위험요소 처리결과리스트는 이전에 파악된 위험요소의 처리방법 등을 포함한다. 예를 들어, 도 2의 예에서, 안전사고예방장치는 3차원 모델과 가상공간을 비교하여 차이나는 두 곳의 영역(210,220)을 모두 위험요소로 판단할 수 있다. 안전사고예방장치는 위험요소에 대한 처리방법을 사용자로부터 입력받을 수 있다. 도 2의 예에서 바닥에 존재하는 구멍의 제1 위험요소의 처리방법으로 구멍제거(즉, 구멍 매움)가 설 정되고, 바닥에 존재하는 물건의 제2 위험요소의 처리방법으로 동일 공간 내에서 모서리로 이동이 설정될 수 있다. 안전사고예방장치는 이후 동일 공간의 촬영데이터를 기초로 가상공간을 생성하고 3차원 모델과 비교하여 다시 차이나는 영역을 파악할 수 있다. 안전사고예방장치는 차이나는 영역의 객체가 위험요소 처리결 과리스트에 존재하는지 파악한다. 차이나는 영역이 이전과 동일하게 구멍과 물건이면, 안전사고 예방장치는 위험요소 처리결과리스트에 저장된 객체에 대한 처리방법에 따라 객체가 처리되지 않았다 면 위험요소로 제시한다. 예를 들어, 이전에 제1 위험요소로 파악된 구멍이 그대로 존재하고 제1 위험요소 가 위험요소 처리결과리스트에 정의된 방법으로 처리되지 않았다면, 안전사고예방장치는 제1 위험요 소가 그대로 존재함을 사용자단말로 제공할 수 있다. 또는 이전에 제2 위험요소로 파악된 물건이 존재하나위험요소 처리방법리스트에 설정된 방법으로 정해진 위치로 이동되었다면, 안전사고예방장치는 물건 이 설정된 방법으로 처리되었으므로 해당 물건을 위험요소로 파악하지 않는다. 즉, 가상공간과 3차원 모델의 차 이나는 영역으로 구멍과 물건이 존재하나, 물건은 위험요소처리방법에 따라 처리되었으므로, 안전사고예방 장치는 구멍만을 위험요소로 파악하여 제공할 수 있다. 도 6은 본 발명의 실시 예에 따른 안전사고 예방방법의 일 예를 도시한 흐름도이다. 도 6을 참조하면, 안전사고예방장치는 촬영장치를 이용한 촬영데이터를 기반으로 적어도 하나 이상의 객체 를 포함하는 가상공간을 생성한다(S600). 안전사고예방장치는 촬영장치가 촬영한 공간에 대하며 미리 정의된 3차원 모델과 가상공간을 비교하여 차 이나는 영역을 파악한다(S610). 본 실시 예의 비교는 2차원 이미지의 단순 비교가 아니라 3차원 모델과 3차원 데이터인 가상공간의 비교이다. 안전사고예방장치는 차이나는 영역을 사용자 단말로 그대로 제공하거나, 차이나는 영역이 위험요소인지 파 악하여 위험요소인 경우에만 사용자 단말로 제공할 수 있다(S620). 가상공간과 3차원 모델의 차이나는 영역이 위험요소인지 파악하는 방법의 예가 도 3 내지 도 5에 도시되어 있다. 도 7은 본 발명의 실시 예에 따른 안전사고예방장치의 일 예의 구성을 도시한 도면이다. 도 7을 참조하면, 안전사고예방장치는 가상공간생성부, 비교부 및 위험요소제시부를 포함 한다. 일 실시 예로, 안전사고예방장치는 메모리, 프로세서 및 입출력장치를 포함하는 컴퓨팅 장치로 구현 될 수 있다. 이 경우 본 실시 예의 각 구성은 소프트웨어로 구현되어 메모리에 탑재된 후 프로세서에 의해 수행 될 수 있다. 가상공간생성부는 실제공간을 촬영하여 가상공간을 생성한다. 가상공간생성부는 실제 공간을 오차없 이 정확하게 가상공간으로 생성할 수 있도록 깊이카메라와 라이다를 함께 이용하여 가상객체를 생성할 수 있으 며, 이에 대해서는 도 8 이하에서 다시 살펴본다. 비교부는 실제공간에 대한 3차원 모델과 가상공간을 비교하여 3차원 모델과 가상공간 사이에 차이가 존재 하는 영역을 파악한다. 가상공간과 3차원 모델의 비교 예가 도 2에 도시되어 있다. 위험요소제시부는 3차원 모델과 가상공간의 차이가 존재하는 영역을 제시한다. 일 실시 예로, 위험요소제 시부는 기 정의된 위험요소판단알고리즘을 이용하여 차이가 존재하는 영역이 위험요소인지 파악할 수 있다. 다른 실시 예로, 위험요소제시부는 차이가 존재하는 영역에 나타나는 객체의 종류를 인공지능모델을 이용하여 인식하고, 인식한 객체의 종류가 위험요소인지 파악할 수 있다. 또 다른 실시 예로 위험요소제시부 는 위험요소 처리결과리스트를 저장하는 데이터베이스를 참조하여 차이가 존재하는 영역의 객체가 이전에 파악된 위험요소 처리결과리스트에 존재하는지 파악하고, 데이터베이스에 저장된 위험요소의 처리방법에 따라 객체가 처리되지 않았다면 위험요소로 제시할 수 있다. 도 8은 본 발명의 실시 예에 따른 가상공간의 객체 생성을 위한 시스템의 개략적인 구성의 일 예를 도시한 도면 이다. 도 8을 참조하면, 촬영장치는 깊이카메라와 라이다를 포함한다. 깊이카메라는 객체가 존재하는 일정 공간을 촬영하여 각 픽셀의 깊이값을 함께 제공하는 카메라이다. 본 실시 예에서 객체라고 함은 가상공간에 생성하고자 하는 대상체를 의미한다. 예를 들어, 객체는 건물의 각종 구조물(예를 들어, 하수도관, 기둥, 벽면 등)이나 각종 물건(옷장, 싱크대, 의자, 신발 등) 또는 동식물 등 다양할 수 있으며 특정 한 종류로 한정되는 것은 아니다. 깊이카메라 그 자체는 이미 널리 알려진 기술이며, 종래의 다양한 종류 의 깊이카메라가 본 실시 예에 사용될 수 있다. 본 실시 예에서, 깊이카메라는 정지영상 또는 동영상 을 촬영할 수 있다. 다만, 이하에서는 설명의 편의를 위하여 깊이카메라가 동영상을 촬영하는 경우를 위주로 설 명한다. 깊이카메라로 촬영하여 얻은 각 픽셀의 깊이값을 포함하는 사진데이터를 영상프레임이라고 한다. 즉, 동영상은 초당 일정 개수의 영상프레임으로 구성된다. 라이다는 레이저를 일정 공간에 발사하고 공간의 각 포인트(즉, 반사지점)에서 되돌아오는 신호를 측정하 여 일정 공간의 복수의 포인트에 대한 거리값을 출력한다. 라이다가 일정 시점에 일정 공간에 대하여 측정 한 복수 개의 포인트에 대한 거리값으로 구성된 데이터를 측정프레임이라고 한다. 라이다가 측정하는 복수 개의 지점, 즉, 측정프레임의 해상도는 라이다에 따라 상이할 수 있다. 라이다 그 자체는 이미 널리알려진 기술이며, 종래의 다양한 라이다가 본 실시 예에 사용될 수 있다. 촬영장치는 깊이카메라와 라이다를 동시에 구동하여 일정 공간의 객체를 촬영하고 측정한 다. 다양한 실시 예에서, 촬영장치의 '촬영' 또는 촬영장치의 '측정'이라는 표현은 깊이카메라의 촬 영과 라이다의 측정이 동시에 이루어지는 것으로 해석될 수 있다. 깊이카메라가 초당 생성하는 영상 프레임의 개수와 라이다가 초당 생성하는 측정프레임의 개수는 실시 예에 따라 동일하거나 서로 다를 수 있다. 또한, 영상프레임의 해상도와 측정프레임의 해상도는 실시 예에 따라 동일하거나 서로 다를 수 있다. 다 만 깊이카메라와 라이다는 동시에 구동하여 일정 공간에 대한 영상프레임과 측정프레임을 생성하므로 동일 시간축에 각각 맵핑되어 동기화될 수 있다. 가상객체생성장치는 깊이카메라로 촬영하여 얻은 영상프레임과 라이다로 측정하여 얻은 측정프 레임을 함께 이용하여 현실 세계의 객체에 대한 가상공간의 객체(즉, 디지털 트윈)를 생성한다. 도 1 내지 도 7은 가상객체생성장치가 안전사고예방장치장치의 일부로 구현된 경우를 가정하여 설명하였으나, 가상객체생성장치는 안전사고예방장치와 별개의 장치로 구현될 수 있다. 가상객체생성장치는 촬영장치와 유선 또는 무선 통신망(예를 들어, WebRTC 등)을 통해 연결되어 촬영 장치가 생성하는 영상프레임과 측정프레임을 실시간 수신할 수 있다. 다른 실시 예로, 가상객체생성장치 는 촬영장치가 일정시간 동안 촬영하고 측정하여 생성한 영상프레임과 측정프레임을 촬영 완료 후 저 장매체(예를 들어, USB(Univesal Serial Bus)를 통해 전달받거나, 촬영 완료 후 촬영장치와 유선 또는 무 선 통신망(예를 들어, 근거리 통신망 등)으로 연결하여 수신할 수 있다. 가상객체생성장치는 가상공간의 객체 생성 결과를 사용자가 확인할 수 있도록 사용자 단말에 제공할 수 있다. 다른 실시 예로, 촬영장치와 가상객체생성장치는 하나의 장치로 구현될 수 있다. 예를 들어, 촬영장 치와 가상객체장치는 AR(augumented reality) 글래스, HMD(Head Mounded Display) 또는 웨어러블 디 바이스 등 증강현실 또는 가상현실을 표시하는 다양한 기기의 일부로 구현될 수 있다. 또 다른 실시 예로, 촬영 장치는 AR 글래스 또는 HMD, 웨어러블 디바이스의 일부로 구현되고, 촬영장치는 실시간 촬영 및 측정 한 영상프레임과 측정프레임을 유선 또는 무선 통신망으로 연결된 가상객체생성장치로 전송하고, 촬영장치 가 구현된 AR 글래스, HMD 등은 가상객체생성장치로부터 가상객체를 수신하여 증강현실 또는 가상현실에 가상객체를 표시할 수 있다. 사용자는 실시간 생성되는 가상객체를 증강현실 또는 가상현실을 통해 바로 확인할 수 있다. 가상공간의 객체를 생성하는 구체적인 방법에 대해서는 도 9 이하에서 다시 살펴본다. 도 9는 본 발명의 실시 예에 따른 촬영장치의 촬영방법의 일 예를 도시한 도면이다. 도 8 및 도 9를 참조하면, 촬영장치는 하나의 객체를 연속 촬영하거나 복수의 객체(900,910)를 연속 촬영할 수 있다. 또는 촬영장치는 여러 공간에 위치하는 동일 종류 또는 서로 다른 종류의 객체를 연속 촬 영할 수도 있다. 즉, 촬영장치가 촬영하여 얻은 영상프레임과 측정프레임에는 사용자가 원하는 적어도 하 나 이상의 객체(900,910)가 시간축을 기준으로 여러 시점에 존재할 수 있다. 본 실시 예는 설명의 편의를 위하 여 영상프레임의 예를 도시하고 있다. 예를 들어, 사용자가 건물 시공 단계에서 건물의 여러 곳을 돌아다니며 하수도관을 촬영한다고 가정하자. 이 경 우 사용자가 촬영장치로 건물의 A 공간에서 하수도관을 촬영하고 B 공간으로 이동하여 하수도관을 촬영할 수 있다. A 공간과 B 공간으로 이동할 때 촬영장치는 계속하여 촬영상태로 유지되거나 이동시 꺼진 상태일 수 있다. A 공간과 B 공간에서 촬영된 영상프레임과 측정프레임에는 하수도관이라는 동일 종류의 객체가 존재한다. 다른 예로, 각 공간에서 촬영된 영상프레임과 측정프레임에는 복수 개의 객체(900,910)가 함께 촬영될 수 있다. A 공간에서 촬영된 영상프레임과 측정프레임에는 객체a와 객체b가 존재하고, B 공간에서 촬영된 영상프레임과 측정프레임에는 객체a와 객체c가 존재할 수 있다. 가상객체생성장치는 영상프레임과 측정프레임을 객체 단위로 구분할 수 있다. 가상객체생성장치는 영 상프레임과 측정프레임에서 동일 객체가 존재하는 영상프레임과 측정프레임에 동일한 식별정보(또는 인덱스)를 부여할 수 있다. 예를 들어, 제1 객체가 존재하는 복수의 영상프레임(920,922,924)에 모두 제1 식별정보 (또는 제1 인덱스, 이하 식별정보라고 함)를 부여하고, 제2 객체가 존재하는 복수의 영상프레임 (930,932,934)에 제2 식별정보를 부여할 수 있다. 객체가 존재하지 않는 영상프레임(940,942)은 아무런 식별정 보를 부여하지 않거나 또는 제3 식별정보를 부여할 수 있다. 본 실시 예에서 시간축에 따라 배열되는 영상프레 임이 세 개의 그룹, 즉, A, B, C로 구분될 수 있다. 다른 실시 예로 영상프레임과 측정프레임에 복수의 객체가 존재하면, 하나의 영상프레임과 측정프레임에 각 객체에 해당하는 식별정보가 부여될 수 있다.즉 하나의 영상프레임과 측정프레임에 복수의 식별정보가 부여될 수 있다. 다른 실시 예로, 촬영장치가 깊이카메라와 라이다를 동시에 구동하여 촬영하므로, 깊이카메라 가 생성하는 영상프레임과 라이다가 측정하는 측정프레임은 시간이 동기화될 수 있다. 따라서 가상객체생 성장치는 영상프레임에 대해서만 동일 객체가 존재하는지 파악하여 동일 객체가 존재하는 영상프레임의 시 구간을 파악하여 그 시구간 동안의 영상프레임에 동일 식별정보를 부여하고, 또한 영상프레임에 대하여 파악된 시구간 동안 생성된 측정프레임에 대해서도 동일 객체가 존재하는 구간으로 간주하여 동일 식별정보를 부여할 수 있다. 가상객체생성장치는 종래의 다양한 영상인식알고리즘을 이용하여 영상프레임에 존재하는 객체의 동일 여부 를 파악할 수 있다. 예를 들어, 가상객체생성장치는 영상인식알고리즘의 일 예로 인공지능모델을 이용할 수 있다. 영상 내 객체의 동일 여부를 파악하는 방법 그 자체는 이미 널리 알려진 기술이므로 이에 대한 상세한 설명은 생략한다. 도 10은 본 발명의 실시 예에 따른 가상공간의 객체를 생성하는 방법의 일 예를 도시한 흐름도이다. 도 10을 참조하면, 가상객체생성장치는 일정 공간을 깊이카메라로 촬영하여 얻은 영상프레임에서 제1 배경 영역과 제1 객체영역을 구분한다(S1000). 가상객체생성장치는 동일한 객체가 촬영된 복수의 영상프레임에 대하여 배경과 객체를 구분할 수 있다. 예를 들어, 도 9와 같이 동일 객체가 존재하는 적어도 하나 이상의 영상 프레임(예를 들어, 920,922,924의 A 그룹)에 대하여 각각 배경과 객체를 구분할 수 있다. 다른 실시 예로, 영상 프레임에 복수의 객체가 존재하는 경우에 가상객체생성장치는 배경과 복수의 객체를 각각 구분할 수 있다. 영상프레임에서 배경과 객체를 구분하는 방법의 일 예에 대해서는 도 11에서 다시 살펴본다. 가상객체생성장치는 일정 공간을 라이다로 측정하여 얻은 측정프레임에서 제2 배경영역과 제2 객체영역을 구분한다(S1010). 가상객체생성장치는 동일한 객체가 측정된 복수의 측정프레임에 대하여 배경과 객체를 구분할 수 있다. 예를 들어, 도 10과 같이 동일 식별정보가 부여된 복수의 측정프레임에 대하여 배경과 객체를 구분할 수 있다. 다른 실시 예로, 측정프레임에 복수의 객체가 존재하는 경우에 가상객체생성장치는 배경과 복 수의 객체를 각각 구분할 수 있다. 측정프레임에서 배경과 객체를 구분하는 방법의 예가 도 11에 도시되어 있다. 깊이카메라와 라이다는 도 8에 도시된 바와 같이 촬영장치 내에서 일정 거리 이격되어 위치하며, 따라서 영상프레임과 측정프레임의 촬영각도는 서로 다르다. 또한 영상프레임과 측정프레임의 해상도 등도 서로 다를 수 있으므로, 영상프레임의 각 픽셀과 측정프레임의 각 포인트의 위치도 일대일(1:1, scale) 맵 핑(mapping)되지 않을 수 있다. 이러한 차이를 가지는 영상프레임과 측정프레임을 맵핑시키기 위하여 본 실시 예는 격자공간을 이용한다. 구체적으로, 가상객체생성장치는 기 정의된 크기의 격자를 포함하는 제1 격자공간에 영상프레임에서 구분 한 제1 객체영역의 픽셀을 깊이값에 따라 배치하고(S1020), 또한 기 정의된 크기의 격자를 포함하는 제2 격자공 간에 측정프레임에서 구분한 제2 객체영역의 포인트를 거리값에 따라 배치한다(S1020). 영상프레임과 측정프레 임이 동일 공간을 촬영하여 얻은 데이터이므로, 제1 객체영역과 제2 객체영역에 존재하는 객체는 동일 객체이다. 제1 격자공간과 제2 격자공간은 가상공간 내 동일한 크기의 격자를 가지는 공간이다. 격자공간의 일 예가 도 12에 도시되어 있다. 가상객체생성장치는 제1 격자공간의 픽셀의 깊이값을 제2 격자공간의 포인트의 거리값을 기준으로 보정한 다(S1030). 동일한 크기의 격자공간에 제1 객체영역의 픽셀과 제2 객체영역의 포인트가 존재하므로, 제1 격자공 간과 제2 격자공간의 위치, 방향, 크기 등을 서로 일치시키면 제2 격자공간의 각 포인트와 제1 격자공간의 각 픽셀을 맵핑시킬 수 있다. 격자공간의 격자단위로 픽셀의 깊이값을 포인트의 거리값을 이용하여 보정하는 구체 적인 방법에 대해 도 14에 다시 살펴본다. 가상객체생성장치는 깊이값이 보정된 픽셀을 기준으로 표면정보가 존재하는 가상공간의 객체(즉, 가상객체)를 생성한다(S1040). 가상객체생성장치는 동일 식별정보가 부여된 복수의 영상프레임에 존재하는 객체의 픽셀 깊이값을 동일 식별정보가 부여된 복수의 측정프레임에 존재하는 객체의 포인트 거리값으로 보정한 후 복수의 영상프레임의 보정된 픽셀을 이용하여 가상객체를 생성할 수 있다. 즉, 다양한 각도와 위치에서 촬영 된 객체의 영상프레임의 픽셀 깊이값을 보정하여 가상객체를 생성할 수 있다. 가상객체생성장치는 다양한 종류의 3차원 모델링 알고리즘을 이용하여 3차원 가상 객체를 생성할 수 있다. 예를 들어, 가상객체생성장치는 깊이값을 가진 픽셀을 이용하여 표면정보를 가지는 3차원 객체를 인공지능모델로 생성할 수 있다. 다른 실시 예로, 픽셀 전체를 이용하여 3차원 모델링을 수행하는 경우 그 연산량이 많 은 단점이 존재하므로, 가상객체생성장치는 객체를 구성하는 픽셀 중 모서리와 꼭짓점(vertex) 등을 나타 내는 포인트 클라우드를 추출하고, 포인트 클라우드를 3차원 모델링 알고리즘에 입력하여 가상 객체를 생성할 수 있다. 포인트 클라우드를 이용하여 가상객체를 생성하는 예에 대해서는 도 15에서 다시 살펴본다. 측정프레 임의 각 포인트의 거리값을 기준으로 가상객체를 생성할 수도 있으나, 일반적으로 측정프레임의 해상도가 영상 프레임보다 해상도보다 낮으므로, 측정프레임을 통해 가상객체를 생성할 경우 객체의 모서리 등이 뭉개져 표현 될 수 있어 본 실시 예는 상대적으로 해상도가 높은 영상프레임의 픽셀의 거리값을 이용하여 가상 객체를 생성 한다. 도 11은 본 발명의 실시 예에 따른 영상프레임과 측정프레임의 배경과 객체를 구분하는 방법의 일 예를 도시한 도면이다. 도 11을 참조하면, 영상프레임의 배경과 객체를 구분하는 제1 인공지능모델과, 측정프레임의 배경과 객체 를 구분하는 제2 인공지능모델이 존재한다. 각 인공지능모델(1100,1110)은 미리 구축된 학습데이터를 이 용하여 훈련된 모델로 CNN(Convolutional Neural Network) 등으로 구현될 수 있다. 인공지능모델의 학습 및 생 성 과정 그 자체는 이미 널리 알려진 기술이므로 이에 대한 설명은 생략한다. 제1 인공지능모델은 영상프레임을 입력받으면 영상프레임에서 배경과 객체를 구분하도록 머신러닝을 통해 생성된 모델이다. 예를 들어, 제1 인공지능모델이 의자를 인식하도록 학습된 인공지능모델이면, 제1 인공 지능모델은 영상프레임에서 의자가 존재하는 영역(즉, 영상프레임 내 의자영역의 픽셀들)을 구분할 수 있 다. 제2 인공지능모델은 측정프레임을 입력받으면 측정프레임에서 배경과 객체를 구분하도록 머신러닝을 통해 생성된 모델이다. 예를 들어, 제1 인공지능모델이 의자를 인식하도록 학습된 인공지능모델이면, 제2 인공 지능모델은 측정프레임에서 의자가 존재하는 영역(즉, 측정프레임 내 의자에 해당하는 포인트들)을 구분 할 수 있다. 도 12는 본 발명의 실시 예에 따른 격자공간의 일 예를 도시한 도면이다. 도 12를 참조하면, 격자공간은 가상공간 내 영역을 일정 크기의 단위격자로 구분한 공간이다. 예를 들어, 격자공간은 가로, 세로 및 높이가 각각 d1,d2,d3인 단위격자로 구성되는 공간일 수 있다. 실 시 예에 따라, d1,d2,d3는 모두 동일한 크기(예를 들어, 1mm)이거나 서로 다른 크기일 수 있다. 도 13은 본 발명의 실시 예에 따른 영상프레임에서 구분한 객체를 격자공간에 표시한 일 예를 도시한 도면이다. 도 13을 참조하면, 가상객체생성장치는 영상프레임에 구분한 객체영역의 픽셀을 그 깊이값을 이용하여 격 자공간에 표시할 수 있다. 본 실시 예는 이해를 돕기 위하여 픽셀들을 개략적으로 도시하고 있다. 가상객체생성장치는 영상프레임 내 객체의 픽셀을 격자공간에 맵핑하여 격자공간 내 각 픽셀의 3차 원 좌표값(또는 픽셀의 벡터값 등)을 파악할 수 있다. 즉, 격자공간에서 기 정의된 지점을 기준점(0,0,0 또는 X,Y,Z)으로 객체의 각 픽셀의 3차원 좌표값을 생성할 수 있다. 이와 같은 방법으로, 가상객체생성장치는 측정프레임 내 객체를 나타내는 포인트들을 격자공간에 맵핑할 수 있다. 측정프레임 내 객체의 포인트를 격자공간에 표시하면 이 또한 도 13과 비슷한 모양으로 표시될 수 있 다. 도 14는 본 발명의 실시 예에 따른 객체의 픽셀의 깊이값을 보정하는 방법의 일 예를 도시한 도면이다. 도 14를 참조하면, 영상프레임의 객체가 맵핑된 제1 격자공간의 어느 하나의 제1 격자와 측정프레임의 객 체가 맵핑된 제2 격자공간에서 제1 격자와 대응되는 위치는 제2 격자를 각각 도시하고 있다. 본 실 시 예에서, 영상프레임의 객체의 픽셀이 맵핑된 제1 격자공간과 측정프레임의 객체의 포인트가 맵핑된 제2 격자 공간은 위치, 방향, 크기 등이 먼저 정합되어 있다고 가정한다. 또한 본 실시 예는 설명의 편의를 위하여 제1 격자와 제2 격자에 각각 하나의 픽셀과 포인트가 존재하는 예를 도시하고 있으나, 하 나의 격자(1400,1410)에는 복수의 픽셀 또는 복수의 포인트가 존재할 수 있다. 또한 제1 격자와 제2 격자 에 존재하는 픽셀과 포인트의 개수는 동일하거나 서로 다를 수 있다. 가상객체생성장치는 제2 격자의 포인트의 거리값을 기초로 제1 격자의 픽셀의 깊 이값을 보정한다. 라이다가 측정한 포인트의 거리값이 보다 정확하므로 가상객체생성장치는 포인트의 거리값을 기준으로 픽셀의 깊이값을 보정한다. 예를 들어, 제1 격자의 픽셀의 격자공간에서의 좌표값과 제2 격자의 포인트의 좌표값이 서로 상이하면, 가상객체생성장치는 제1 격자의 픽셀을 제2 격자의 포인트의 좌표값에 따라 보정한다. 영상프레임과 측정프레임의 해상도가 서로 다를 수 있으므로, 제1 격자의 픽셀과 제2 격자의 포인 트가 가리키는 위치가 서로 일대일 맵핑되지 않을 수 있다. 따라서 제2 격자 내에 존재하는 복수의 포인 트 또는 제2 격자의 상하좌우 등에 존재하는 주변 격자에 존재하는 복수의 포인트를 이용하여 각 포인트 사이에 존재하는 값들을 보간법(interpolation) 등을 통해 파악하여 픽셀의 좌표값에 해당하는 포인트의 좌표값 에 대한 거리값을 파악할 수 있다. 그리고 보간을 통해 생성된 포인트의 거리값을 이용하여 제1 격자의 픽셀의 좌표값을 보정할 수 있다. 도 15는 본 발명의 실시 예에 따른 3차원 가상 객체를 생성하는 방법의 일 예를 도시한 도면이다. 도 15를 참조하면, 가상객체생성장치는 포인트 클라우드를 3차원 모델링 알고리즘에 입력하여 표면정보를 포함하는 3차원 가상 객체를 생성할 수 있다. 포인트 클라우드는 객체의 꼭짓점과 모서리 등 객체를 정의할 수 있는 주요지점을 나타내는 지점으로 구성될 수 있다. 깊이카메라가 촬영한 영상프레임에서 포 인트 클라우드를 추출하는 종래의 다양한 방법이 본 실시 예에 적용될 수 있다. 포인트 클라우드를 추출하는 방 법 그 자체는 이미 널리 알려진 기술이므로 이에 대한 추가적인 설명은 생략한다. 가상객체생성장치는 영상프레임에서 추출한 객체를 격자공간에 맵핑하고, 격자공간에 맵핑된 각 픽셀의 거 리값(또는 좌표값)을 도 14와 같은 방법으로 보정한다. 그리고 보정된 각 픽셀의 거리값(또는 좌표값)에서 3차 원 가상 객체의 생성에 사용할 포인트 클라우드를 추출한다. 도 13의 객체에 대한 포인트 클라우드를 추출한 예 가 도 16에 도시되어 있다. 가상객체생성장치는 3차원 모델링 알고리즘으로 머신러닝 등의 인공지능 모델을 이용할 수 있다. 포인트 클라우드를 기반으로 3차원 객체를 생성하는 종래의 다양한 알고리즘이 본 실시 예에 적용될 수 있다. 포인트 클라우드를 이용한 3차원 객체 생성 방법 그 자체는 이미 널리 알려진 기술이므로 이에 대한 상세한 설명은 생략한다. 도 16은 본 발명의 실시 예에 따른 3차원 가상 객체 생성을 위한 포인트 클라우드를 추출한 일 예를 도시한 도 면이다. 도 16을 참조하면, 의자에 대한 포인트 클라우드의 추출 예가 도시되어 있다. 포인트 클라우드를 추출하는 종래의 다양한 방법이 본 실시 예에 적용될 수 있다. 다른 실시 예로, 동일한 식별번호가 부여된 복수 의 영상프레임, 즉 동일 객체를 촬영한 복수의 영상프레임에서 픽셀의 깊이값을 보정한 후 각각 포인트 클라우 드를 추출하여 3차원 가상객체를 생성할 수 있다. 도 17은 본 발명의 실시 예에 따른 3차원 가상 객체의 생성 예를 도시한 도면이다. 도 17을 참조하면, 가상객체 생성장치는 포인트 클라우드를 이용하여 표면정보를 포함하는 가상객체를 생성할 수 있다. 도 18은 본 발명의 실시 예에 다른 가상객체생성장치의 일 예의 구성을 도시한 도면이다. 도 18을 참조하면, 가상객체생성장치는 제1 객체추출부, 제2 객체추출부, 제1 격자배치부 , 제2 격자배치부, 보정부 및 객체생성부를 포함한다. 일 실시 예로, 가상객체생성장 치는 메모리, 프로세서, 입출력장치 등을 포함하는 컴퓨팅 장치 또는 서버, 클라우드 시스템 등으로 구현 될 수 있으며, 이 경우 각 구성은 소프트웨어 구현되어 메모리에 탑재된 후 프로세서에 의해 수행될 수 있다. 제1 객체추출부는 일정 공간을 깊이카메라로 촬영하여 얻은 영상프레임에서 제1 배경영역과 제1 객체영역 을 구분한다. 제2 객체추출부는 상기 일정 공간을 라이다로 측정하여 얻은 측정프레임에서 제2 배경영역 과 제2 객체영역을 구분한다. 배경과 객체의 구분은 인공지능모델을 이용하여 수행할 수 있으며 이에 대한 예가 도 11에 도시되어 있다. 제1 격자배치부는 기 정의된 크기의 격자를 포함하는 제1 격자공간에 상기 제1 객체영역의 픽셀을 깊이값 에 따라 배치한다. 제2 격자배치부는 기 정의된 크기의 격자를 포함하는 제2 격자공간에 상기 제2 객체영 역의 포인트를 거리값에 따라 배치한다. 격자공간의 예가 도 12에 도시되어 있고, 격자공간에 영상프레임으로부 터 추출한 객체의 픽셀들을 맵핑한 예가 도 13에 도시되어 있다. 보정부는 제1 격자공간의 픽셀의 깊이값을 상기 제2 격자공간의 포인트의 거리값을 기준으로 보정한다. 격자공간의 비교를 통해 보정하는 방법의 일 예가 도 14에 도시되어 있다. 객체생성부는 깊이값이 보정된 픽셀을 기준으로 표면정보가 존재하는 가상 객체를 생성한다 . 객체생성부 는 픽셀 전체를 이용하여 3차원 가상공간의 객체를 생성할 수 있다. 그러나 이 경우 연산량이많아지므로, 객체생성부는 포인트 클라우드를 생성하여 가상객체를 생성할 수 있으며, 이에 대한 예가 도 15 내지 도 17에 도시되어 있다. 본 발명의 각 실시 예는 또한 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것 이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모 든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, SSD, 광데이터 저장장치 등이 있다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어 분 산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 이제까지 본 발명에 대하여 그 바람직한 실시 예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현 될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시 예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내 에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0163003", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 산업현장의 안전사고를 예방할 수 있는 장치의 일 예를 도시한 도면, 도 2는 본 발명의 실시 예에 따른 안전사고 예방방법의 일 예를 도시한 도면, 도 3은 본 발명의 실시 예에 따른 위험요소 파악 방법의 일 예를 도시한 도면, 도 4는 본 발명의 실시 예에 따른 가상공간의 가상객체를 식별하여 위험요소 여부를 파악하는 방법의 일 예를 도시한 도면, 도 5는 본 발명의 실시 예에 따른 위험요소의 처리 결과 리스트를 이용하여 위험요소 여부를 파악하는 방법의 일 예를 도시한 도면, 도 6은 본 발명의 실시 예에 따른 안전사고 예방방법의 일 예를 도시한 흐름도, 도 7은 본 발명의 실시 예에 따른 안전사고예방장치의 일 예의 구성을 도시한 도면, 도 8은 본 발명의 실시 예에 따른 가상공간의 객체 생성을 위한 시스템의 개략적인 구성의 일 예를 도시한 도면, 도 9는 본 발명의 실시 예에 따른 촬영장치의 촬영방법의 일 예를 도시한 도면, 도 10은 본 발명의 실시 예에 따른 가상공간의 객체를 생성하는 방법의 일 예를 도시한 흐름도, 도 11은 본 발명의 실시 예에 따른 영상프레임과 측정프레임의 배경과 객체를 구분하는 방법의 일 예를 도시한 도면, 도 12는 본 발명의 실시 예에 따른 격자공간의 일 예를 도시한 도면, 도 13은 본 발명의 실시 예에 따른 영상프레임에서 구분한 객체를 격자공간에 표시한 일 예를 도시한 도면, 도 14는 본 발명의 실시 예에 따른 객체의 픽셀의 깊이값을 보정하는 방법의 일 예를 도시한 도면, 도 15는 본 발명의 실시 예에 따른 3차원 가상 객체를 생성하는 방법의 일 예를 도시한 도면, 도 16은 본 발명의 실시 예에 따른 3차원 가상 객체 생성을 위한 포인트 클라우드를 추출한 일 예를 도시한 도 면, 도 17은 본 발명의 실시 예에 따른 3차원 가상 객체의 생성 예를 도시한 도면, 그리고, 도 18은 본 발명의 실시 예에 다른 가상객체생성장치의 일 예의 구성을 도시한 도면이다."}
