{"patent_id": "10-2023-0174859", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0093348", "출원번호": "10-2023-0174859", "발명의 명칭": "특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치 및 그 방법", "출원인": "주식회사 에이비에이치", "발명자": "한아람"}}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치에 있어서,동영상 파일로부터 카메라 정보를 추출하는 카메라 정보 추출 모듈;상기 동영상 파일로부터 선택된 적어도 하나의 프레임에 대한 특징점 추출을 수행하는 특징점 추출 모듈;상기 특징점 추출 모듈로부터 상기 적어도 하나의 프레임에 대한 중복 특징점을 추적하는 특징점 매칭 모듈;상기 특징점 매칭 모듈의 결과를 기반으로 카메라의 위치를 추적하는 카메라 위치 추적 모듈;상기 카메라의 위치를 기반으로 삼각 측량을 이용하여 상기 적어도 하나의 프레임에 대한 Point Cloud 데이터를생성하는 Point Cloud 생성 모듈;상기 Point Cloud 데이터를 3D 형태의 파일로 변환하는 Mesh 변환 모듈;상기 Mesh 변환 모듈로부터 변환된 파일의 폴리곤 수량을 최적화하는 Mesh 최적화 모듈; 및상기 Mesh 최적화 모듈로부터 최적화가 수행된 파일에 대한 색상 및 표현 질감을 구성하는 텍스쳐 맵 구성 모듈을 포함하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 특징점 추출 모듈은:상기 적어도 하나의 프레임에 대한 RoI(Region of Interest)를 추출하고,상기 RoI에 대하여 적어도 하나의 특징점 추출 알고리즘을 적용하고,상기 적어도 하나의 특징점 추출 알고리즘을 적용한 결과 값을 도출하고,상기 결과 값을 기반으로 선택된 특징점 추출 알고리즘 및 설정 값을 제안하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 특징점 추출 모듈은 RPN(Region Proposal Network) 모델을 통해 상기 RoI를 도출하는 것을 특징으로 하는전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 적어도 하나의 특징점 추출 알고리즘은 SIFT(Scale Invariant Feature Transform) 알고리즘, AKAZE 알고리즘 및 DSPSIFT 알고리즘 중 적어도 하나를 포함하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 적어도 하나의 특징점 추출 알고리즘을 적용한 결과 값은 기술자(descriptor) 및 특징 벡터(featurevector) 중 적어도 일부를 포함하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0093348-3-제5 항에 있어서,상기 특징점 추출 모듈은:상기 기술자 및 특징 벡터를 기반으로 기술자 밀도, 기술자 정합도 및 기대 연산 시간 중 적어도 일부를 도출하고,상기 기술자 밀도, 상기 기술자 정합도 및 기대 연산 시간 중 적어도 일부를 기반으로 상기 특징점 추출 알고리즘 및 상기 설정 값을 선택하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5 항에 있어서,상기 특징점 추출 모듈은 상기 기술자 밀도 및 상기 기술자 정합도를 곱한 값의 수치가 높은 알고리즘을 최고품질 기대 알고리즘으로 선택하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5 항에 있어서,상기 특징점 추출 모듈은 상기 기대 연산 시간이 가장 짧은 알고리즘을 최단 시간 기대 알고리즘으로 선택하는것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "장치에 의해 수행되는, 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 방법에 있어서,동영상 파일로부터 카메라 정보를 추출하는 단계;상기 동영상 파일로부터 선택된 적어도 하나의 프레임에 대한 특징점 추출을 수행하는 단계;상기 특징점 추출 모듈로부터 상기 적어도 하나의 프레임에 대한 중복 특징점을 추적하는 단계;상기 특징점 매칭 모듈의 결과를 기반으로 카메라의 위치를 추적하는 단계;상기 카메라의 위치를 기반으로 삼각 측량을 이용하여 상기 적어도 하나의 프레임에 대한 Point Cloud 데이터를생성하는 단계;상기 Point Cloud 데이터를 3D 형태의 파일로 변환하는 단계;상기 Mesh 변환 모듈로부터 변환된 파일의 폴리곤 수량을 최적화하는 단계; 및상기 Mesh 최적화 모듈로부터 최적화가 수행된 파일에 대한 색상 및 표현 질감을 구성하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 하나 이상의 프로세서에서 실행되는 경우, 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하기 위하여 이하의 동작들을 수행하도록하며, 상기 동작들은:동영상 파일로부터 카메라 정보를 추출하는 동작;상기 동영상 파일로부터 선택된 적어도 하나의 프레임에 대한 특징점 추출을 수행하는 동작;상기 특징점 추출 모듈로부터 상기 적어도 하나의 프레임에 대한 중복 특징점을 추적하는 동작;상기 특징점 매칭 모듈의 결과를 기반으로 카메라의 위치를 추적하는 동작;상기 카메라의 위치를 기반으로 삼각 측량을 이용하여 상기 적어도 하나의 프레임에 대한 Point Cloud 데이터를생성하는 동작;상기 Point Cloud 데이터를 3D 형태의 파일로 변환하는 동작;공개특허 10-2024-0093348-4-상기 Mesh 변환 모듈로부터 변환된 파일의 폴리곤 수량을 최적화하는 동작; 및상기 Mesh 최적화 모듈로부터 최적화가 수행된 파일에 대한 색상 및 표현 질감을 구성하는 동작을 포함하는 것을 특징으로 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치 및 그 방법에 관한 것으로, 본 개 시의 실시 예에 따른 전자 장치는 동영상 파일로부터 카메라 정보를 추출하는 카메라 정보 추출 모듈, 상기 동영 상 파일로부터 선택된 적어도 하나의 프레임에 대한 특징점 추출을 수행하는 특징점 추출 모듈, 상기 특징점 추 (뒷면에 계속)"}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 포토그래매트리(photogrammetry) 기술에 관한 것으로, 보다 상세하게는, 특징점 추출 알고리즘을 기 반으로 3D 모델링을 수행하는 전자 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "포토그래매트리(photogrammetry) 기술은 사진 측량법으로 알려져 있으며, 2차원 이미지 데이터로부터 3차원의 기하학적 데이터를 추출하는 기술을 의미한다. 기술을 발전에 따라, 인공지능 모델의 발전 및 특징점 추출 알고 리즘의 다양화에 따라 포토그래매트리 기술의 성능은 점차 향상되어 왔으나, 데이터 분석 및 활용 과정에서의 어려움으로 인하여 실질적으로 일반인이 해당 기술을 3D 모델링에 적용하기에 어려움이 있다. 구체적으로, 동영상을 이용한 3D 모델링은 동영상으로부터 모델링을 위한 적절한 프레임을 추출하고, 주변 환경 및 피사체의 특성에 따라 적절하게 물체 표면으로부터 특징점을 추출할 수 있는 특징점 추출 알고리즘을 선택하 고, 특징점 추출 알고리즘의 세부 파라미터의 조정하기 위한 전문가 수준의 기술 활용을 요구한다. 특히, 특징 점 추출 알고리즘은 다양한 종류가 존재하며, 각 알고리즘 별로 특징점을 추출하는 방식이 상이하여 피사체 별 로 특징점 추출 알고리즘의 선택 및 그에 대한 설정을 달리하여야 하는 어려움이 있다. 관련하여, 한국 등록 특허 10-1538014B1 및 10-21601965B1 등을 참조할 수 있다."}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 개시된 실시 예는 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치 및 그 방법을 제공하는데 그 목적이 있다. 본 개시에 개시된 실시 예는 분석을 통해 최적화된 특징점 추출 알고리즘을 제안하고, 제안된 특징점 추출 알고 리즘을 기반으로 3D 모델링을 수행하는 전자 장치 및 그 방법을 제공하는데 그 목적이 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시에 따른 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치는 동영상 파일로부터 카메라 정보를 추출하는 카메라 정보 추출 모듈, 상기 동영상 파일로부터 선택 된 적어도 하나의 프레임에 대한 특징점 추출을 수행하는 특징점 추출 모듈, 상기 특징점 추출 모듈로부터 상기 적어도 하나의 프레임에 대한 중복 특징점을 추적하는 특징점 매칭 모듈, 상기 특징점 매칭 모듈의 결과를 기반 으로 카메라의 위치를 추적하는 카메라 위치 추적 모듈, 상기 카메라의 위치를 기반으로 삼각 측량을 이용하여 상기 적어도 하나의 프레임에 대한 Point Cloud 데이터를 생성하는 Point Cloud 생성 모듈, 상기 Point Cloud 데이터를 3D 형태의 파일로 변환하는 Mesh 변환 모듈, 상기 Mesh 변환 모듈로부터 변환된 파일의 폴리곤 수량을 최적화하는 Mesh 최적화 모듈 및 상기 Mesh 최적화 모듈로부터 최적화가 수행된 파일에 대한 색상 및 표현 질감 을 구성하는 텍스쳐 맵 구성 모듈을 포함할 수 있다. 또한, 상기 특징점 추출 모듈은 상기 적어도 하나의 프레임에 대한 RoI(Region of Interest)를 추출하고, 상기 RoI에 대하여 적어도 하나의 특징점 추출 알고리즘을 적용하고, 상기 적어도 하나의 특징점 추출 알고리즘을 적 용한 결과 값을 도출하고, 상기 결과 값을 기반으로 선택된 특징점 추출 알고리즘 및 설정 값을 제안할 수 있다. 또한, 상기 특징점 추출 모듈은 RPN(Region Proposal Network) 모델을 통해 상기 RoI를 도출할 수 있다. 또한, 상기 적어도 하나의 특징점 추출 알고리즘은 SIFT(Scale Invariant Feature Transform) 알고리즘, AKAZE 알고리즘 및 DSPSIFT 알고리즘 중 적어도 하나를 포함할 수 있다. 또한, 상기 적어도 하나의 특징점 추출 알고리즘을 적용한 결과 값은 기술자(descriptor) 및 특징 벡터(feature vector) 중 적어도 일부를 포함할 수 있다. 또한, 상기 특징점 추출 모듈은 상기 기술자 및 특징 벡터를 기반으로 기술자 밀도, 기술자 정합도 및 기대 연 산 시간 중 적어도 일부를 도출하고, 상기 기술자 밀도, 상기 기술자 정합도 및 기대 연산 시간 중 적어도 일부 를 기반으로 상기 특징점 추출 알고리즘 및 상기 설정 값을 선택할 수 있다. 또한, 상기 특징점 추출 모듈은 상기 기술자 밀도 및 상기 기술자 정합도를 곱한 값의 수치가 높은 알고리즘을 최고 품질 기대 알고리즘으로 선택할 수 있다. 또한, 상기 특징점 추출 모듈은 상기 기대 연산 시간이 가장 짧은 알고리즘을 최단 시간 기대 알고리즘으로 선 택할 수 있다. 본 개시의 일 실시 예에 따른 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 방법은 동영상 파일로부 터 카메라 정보를 추출하는 단계, 상기 동영상 파일로부터 선택된 적어도 하나의 프레임에 대한 특징점 추출을 수행하는 단계, 상기 특징점 추출 모듈로부터 상기 적어도 하나의 프레임에 대한 중복 특징점을 추적하는 단계, 상기 특징점 매칭 모듈의 결과를 기반으로 카메라의 위치를 추적하는 단계, 상기 카메라의 위치를 기반으로 삼 각 측량을 이용하여 상기 적어도 하나의 프레임에 대한 Point Cloud 데이터를 생성하는 단계, 상기 Point Cloud 데이터를 3D 형태의 파일로 변환하는 단계, 상기 Mesh 변환 모듈로부터 변환된 파일의 폴리곤 수량을 최적화하 는 단계 및 상기 Mesh 최적화 모듈로부터 최적화가 수행된 파일에 대한 색상 및 표현 질감을 구성하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그 램은 하나 이상의 프로세서에서 실행되는 경우, 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하기 위하여 이하의 동작들을 수행하도록 하며, 상기 동작들은 동영상 파일로부터 카메라 정보를 추출하는 동작, 상기 동영 상 파일로부터 선택된 적어도 하나의 프레임에 대한 특징점 추출을 수행하는 동작, 상기 특징점 추출 모듈로부 터 상기 적어도 하나의 프레임에 대한 중복 특징점을 추적하는 동작, 상기 특징점 매칭 모듈의 결과를 기반으로 카메라의 위치를 추적하는 동작, 상기 카메라의 위치를 기반으로 삼각 측량을 이용하여 상기 적어도 하나의 프 레임에 대한 Point Cloud 데이터를 생성하는 동작, 상기 Point Cloud 데이터를 3D 형태의 파일로 변환하는 동작, 상기 Mesh 변환 모듈로부터 변환된 파일의 폴리곤 수량을 최적화하는 동작 및 상기 Mesh 최적화 모듈로부 터 최적화가 수행된 파일에 대한 색상 및 표현 질감을 구성하는 동작을 포함할 수 있다."}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 최적화된 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행함으 로써, 3D 모델링 구현의 완성도를 향상시킬 수 있다. 본 개시의 전술한 과제 해결 수단에 의하면, 특징점을 추출하기 위한 세부적인 설정에 대한 최적화를 수행함으 로써, 사용자 편의성을 향상시킬 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 장치'는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들 이 모두 포함된다. 예를 들어, 본 개시에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련데이터로서 입력데이터와 출력데이터가 같이 제공됨으로써 문제(입력데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출력데 이터 없이 입력데이터만 제공되어 문제(입력데이터)의 해답(출력데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴 럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과 (output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하, 첨부된 도면을 참조하여 본 개시의 실시예를 상세하게 설명한다. 도 1은 본 개시의 실시 예에 따른 포토그래매트리 시스템을 설명하기 위한 블록도이다. 도 1을 참조하면, 본 개시의 일 실시 예에 따른 포토그래매트리 시스템은 제1 데이터베이스, 포토그래 매트리 장치 및 제2 데이터베이스를 포함할 수 있다. 실시 예에서, 제1 데이터베이스는 3D 모델 링의 대상이 되는 적어도 하나의 동영상 파일을 저장할 수 있으며, 제1 데이터베이스에 저장된 적어도 하 나의 동영상 파일은 포토그래매트리 장치를 통하여 모델링될 수 있다. 본 명세서에서, 포토그래매트리 장치는 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치 로 명명될 수 있다. 실시 예에서, 제1 데이터베이스에 저장된 동영상 파일으로부터 선택된 프레임(frame) 에 대하여 특징점 알고리즘 간 성능 비교를 통하여 최적의 알고리즘 및 설정 값을 선택하고, 이를 제안할 수 있 다. 포토그래매트리 장치의 구체적인 구성 및 동작은 후술할 도 2 내지 도 8을 통하여 상세히 설명한다. 포토그래매트리 장치를 통하여 생성된 3D 모델링 파일은 제2 데이터베이스에 저장될 수 있다. 본 개시의 실시 예에 따른 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치는 최적화된 특징 점 추출 알고리즘을 기반으로 3D 모델링을 수행함으로써, 3D 모델링 구현의 완성도를 향상시킬 수 있다. 또한, 특징점을 추출하기 위한 세부적인 설정에 대한 최적화를 수행함으로써, 사용자 편의성을 향상시킬 수 있다. 도 2는 본 개시의 실시 예에 따라 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치의 구 성을 설명하기 위한 블록도이다. 도 2를 참조하면, 본 개시의 실시 예에 따르면, 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치는 카메라 정보 추출 모듈, 특징점 추출 모듈, 특징점 매칭 모듈, 카메라 위치 추적 모듈, Point Cloud 생성 모듈, Mesh 변환 모듈, Mesh 최적화 모듈 및 텍스쳐맵 구성 모듈 을 포함할 수 있다. 본 개시의 실시 예에 따른 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치는 제1 데이 터베이스(110, 도 1 참조)로부터 동영상 파일을 획득할 수 있다. 카메라 정보 추출 모듈은 획득한 동영상 파일의 메타데이터를 기반으로 동영상 파일과 관련된 카메라 정보를 추출할 수 있다. 한편, 특징점 추출 모듛 은 획득한 동영상 파일으로부터 선택된 프레임에 대한 특징점 추출을 수행할 수 있다. 특징점 추출 모듈 에 대한 구체적인 구성 및 동작은 후술할 도 3을 통하여 상세히 설명한다. 실시 예에서, 특징점 매칭 모듈은 특징점 추출 모듈로부터 추출된 특징점들을 기반으로 프레임 별로 서로 동일한 특징점을 추적하고, 카메라 위치 추적 모듈을 통하여 카메라의 위치 정보를 추적할 수 있다.Point Cloud 생성 모듈은 카메라 위치 정보를 기반으로 삼각 측량을 통하여 Point Cloud 데이터를 생성할 수 있다. Point Cloud 데이터는 산점도 형태의 점 데이터일 수 있다. 한편, 실시 예에서, Mesh 변환 모듈은 Point Cloud 데이터를 3D 형태의 파일로 변환하기 위하여 Mesh 변환 을 수행할 수 있다. Mesh 최적화 모듈은 Mesh 변환이 수행된 파일의 폴리곤 수량을 최적화하여 용량을 압 축할 수 있다. 텍스처 맵 구성 모듈은 Mesh 최적화가 수행된 파일에 대한 실제 색상 및 표현 질감을 구성 할 수 있고, 이를 기반으로 3D 모델링 파일을 생성할 수 있다. 도 3은 본 개시의 실시 예에 따른 특징점 추출 모듈(122, 도 1 참조)을 설명하기 위한 블록도이다. 도 3을 참조하면, 본 개시의 실시 예에 따른 특징점 추출 모듈은 RoI(Region of Interest) 추출부, 추출 결과 분석부 및 최적 설정 제안부를 포함할 수 있다. 실시 예에서, RoI 추출부는 제1 데이터베이스(110, 도 1 참조)로부터 획득한 동영상 파일으로부터 선택된 프레임에 대하여 관심 영역(이하, RoI)를 추출할 수 있다. RoI 추출부는 RPN(Region Proposal Network) 모델을 기반으로 RoI를 추출할 수 있으며, RPN 모델은 컨볼루션 레이어(convolution layer)를 기반으로 구성될 수 있다. RoI 추출부로부터 추출된 RoI를 포함하는 이미지에 대하여 특징점 추출 알고리즘이 적용될 수 있 으며, 이를 통해 기술자(descriptor) 및 특징 벡터(feature vector)가 추출될 수 있다. 예로서, 특징점 추출 알 고리즘은 SIFT(Scale Invariant Feature Transform) 알고리즘, AKAZE 알고리즘 및 DSPSIFT 알고리즘 중 적어도 하나를 포함할 수 있다. 추출 결과 분석부는 RoI 추출부를 통해 추출된 기술자 및 특징 벡터에 대한 분석을 수행할 수 있다. 구체적으로, 추출 결과 분석부는 기술자 밀도, 기술자 정합도 및 기대 연산 시간을 분석할 수 있다. 이 떄, 기술자 정합도 및 기대 연산 시간은 RoI에 대하여 적용된 특징점 추출 알고리즘의 세부 설정에 따라 남은 특징점 성분의 수량 및 기술자 매칭 가능 여부에 따라 결정될 수 있다. 추출 결과 분석부는 RoI를 포함하 는 이미지에 대하여, 각 알고리즘 별 결과를 기반으로 표준화된 기술자 밀도를 산출할 수 있다. 기술자 밀도는 아래 수학식 1을 통하여 도출될 수 있다. 수학식 1에서, 기술자 밀도의 단위는 픽셀당 특징점 수량이다. 수학식 1"}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "또한, 추출 결과 분석부는 추출된 기술자에 대한 군집화(clustering)를 수행하고, 각 군집에 대한 기술자 가 균일하게 산출되었는지 검증할 수 있다. 추출 결과 분석부는 군집화 과정에서 각 군집에 포함되는 특징 점이 다른 이미지에 대해서도 검출되었는지 확인하고, 다른 이미지에 대하여 중복하여 검출된 특징점의 비율을 각 군집의 분산 값과 곱하여 기술자 정합도를 산출할 수 있다. 또한, 추출 결과 분석부는 기술자 밀도, 기술자 정합도 및 원본 데이터 볼륨을 기반으로 가용 연산 자원에 따른 기대 연산 시간을 산출할 수 있다. 이 때, 연산 자원의 최적화를 위하여 연산 필요 RoI 크기에 이미지 수 량 및 정합 기술자 수량을 곱하여 대략적인 시간 복잡도를 산출하며, 이를 가용 연산 자원으로 나눈 임의의 값 을 실제 연산 시간과 매칭하여 최적화를 수행할 수 있다. 실시 예에서, 실제 시간 복잡도는 선형 회귀(linear regression)를 통하여 기술자 추출 알고리즘 특징에 대응하여 산출될 수 있다. 최적 설정 제안부는 추출 결과 분석부의 결과 및 특징별 추출 알고리즘 별 메타데이터에 대한 데이터 화를 수행할 수 있다. 최적 설정 제안부는 기술자 밀도, 기술자 정합도 및 기대 연산 시간을 기반으로 특 징점 추출 알고리즘을 제안할 수 있다. 최적 설정 제안부는 (기술자 밀도)*(기술자 정합도)의 수치가 높은 알고리즘을 최고 품질 기대 알고리즘으로 제안할 수 있으며, 기대 연산 시간이 가장 짧은 알고리즘을 최단 시간 기대 알고리즘으로 제안할 수 있다. 특징점 추출 모듈(122, 도 2 참조)은 제안된 알고리즘에 대한 사용자 입력 에 대응하는 특징점 추출 알고리즘 또는 최적 설정 제안부로부터 선택된 특징점 추출 알고리즘을 기반으로 해당 이미지에 대한 특징점을 추출할 수 있다. 본 개시의 실시 예에 따르면, 특정 피사체에 대하여 충분한 수의 특징점을 추출할 수 있는 특징점 추출 알고리 즘을 기반으로 특징점을 추출할 수 있으며, RoI 내에서 다양한 특징점 추출 알고리즘을 반복적으로 수행하고,이에 대한 분석을 통해 최적의 파라미터를 제안함으로써, 사용자 편의성을 향상시킬 수 있다. 도 4는 본 개시의 실시 예에 따른 RoI(Region of Interest) 추출부의 동작을 설명하기 위한 도면이다. 도 4에 도시된 바와 같이, 본 개시의 실시 예에 따르면, 상술한 바와 같이 RPN 모델을 이용하여 특정 영역을 추 출할 수 있으며, Bounding box 형태로 해당 영역의 주 촬영 대상, 주 촬영 대상이 아닌 배경 및 촬영 대상의 전 경을 분리할 수 있다. 또한, 분리된 특정 영역에 대해서만 특징점 추출 알고리즘을 적용함으로써, 연산 시간을 단축하고, 특징점 추출 수준의 품질을 향상시킬 수 있다. 도 5는 본 개시의 실시 예에 따른 특징점 추출 예시를 제시하기 위한 도면이다. 도 5에 도시된 바와 같이, 본 개시의 실시 예에 따르면, 동영상 파일로부터 획득된 특정 프레임에 대하여 추출 된 RoI 영역에 대한 특징점 추출이 수행될 수 있다. 실시 예에 따르면, RoI 영역을 포함하는 이미지에 대하여 복수의 특징점 추출 알고리즘들이 적용되고, 이에 대한 결과 값을 기반으로 최적의 특징점 추출 알고리즘을 제 안함으로써, 해당 이미지에 대한 별도의 파라미터 설정없이 최적의 특징점 추출을 수행할 수 있다. 도 6은 본 개시의 실시 예에 따라 특징점 추출 알고리즘의 설정에 따른 특징점 축소의 예시를 제시하기 위한 도 면이다. 도 6에 도시된 바와 같이, 본 개시의 실시 예에 따르면, 제안된 최적의 특징점 추출 알고리즘을 기반으로 세부 설정이 적용될 수 있으며, 세부 설정에 따라 낮은 대비 극점을 제거하고, 에지 성분을 제거하는 등 3D 모델링을 위한 최적의 특징점만을 추출할 수 있다. 이에 따라, 모델링에 불필요한 특징점을 배제함으로써, 연산 시간의 단축을 도모할 수 있다. 도 7은 본 개시의 실시 예에 따른 특징점 매칭 모듈(123, 도 2 참조)의 동작을 설명하기 위한 도면이다. 도 7에 도시된 바와 같이, 본 개시의 실시 예에 따른 특징점 매칭 모듈은 특징점 추출 모듈(122, 도 2 참 조)로부터 도출된 결과를 기반으로 특징점들을 군집화하고, 각 군집에 포함되는 특징점이 다른 이미지에 대하여 도 검출되었는지 검증할 수 있다. 복수의 이미지들에 포함되는 특징점의 비율을 기반으로 기술자 정합도가 산출 될 수 있다. 도 8은 본 개시의 실시 예에 따라 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 방법을 설명하기 위 한 순서도이다. S810 단계에서, 본 개시의 실시 예에 따른 전자 장치는 제1 데이터베이스(110, 도 1 참조)로부터 획득한 동영상 파일의 메타데이터를 기반으로 카메라 정보를 추출할 수 있다. S820 단계에서, 본 개시의 실시 예에 따른 전자 장치는 제1 데이터베이스로부터 획득한 동영상 파일로부터 선택된 프레임에 대한 RoI 추출하고, RoI에 대하여 복수의 특징점 추출 알고리즘을 적용하고, 특징점 추출 알고리즘 적용 결과를 기반으로 제안 알고리즘 및 설정 값을 도출하여, 도출된 알고리즘 및 설정 값을 기반으로 이미지에 대한 특징점을 추출할 수 있다. S830 단계에서, 본 개시의 실시 예에 따른 전자 장치는 추출된 특징점들을 기반으로 프레임 별로 서로 동일한 특징점을 추적하고, S840 단계에서, 카메라의 위치 정보를 추적할 수 있다. S850 단계에서, 본 개시의 실시 예 에 따른 전자 장치는 카메라 위치 정보를 기반으로 삼각 측량을 통하여 Point Cloud 데이터를 생성할 수 있다. S860 단계에서, 본 개시의 실시 예에 따른 전자 장치는 Point Cloud 데이터를 3D 형태의 파일로 변환하기 위하 여 Mesh 변환을 수행하고, Mesh 변환이 수행된 파일의 폴리곤 수량을 최적화하여 용량을 압축할 수 있다. S870 단계에서, 본 개시의 실시 예에 따른 전자 장치는 Mesh 최적화가 수행된 파일에 대한 실제 색상 및 표현 질감을 구성할 수 있고, 이를 기반으로 3D 모델링 파일을 생성할 수 있으며, 생성된 3D 모델링 파일은 제2 데이터베이 스(130, 도 1 참조)에 저장될 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2023-0174859", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2023-0174859", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시 예에 따른 포토그래매트리 시스템을 설명하기 위한 블록도이다. 도 2는 본 개시의 실시 예에 따라 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 전자 장치의 구성을 설명하기 위한 블록도이다. 도 3은 본 개시의 실시 예에 따른 특징점 추출 모듈을 설명하기 위한 블록도이다. 도 4는 본 개시의 실시 예에 따른 RoI(Region of Interest) 추출부의 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 실시 예에 따른 특징점 추출 예시를 제시하기 위한 도면이다. 도 6은 본 개시의 실시 예에 따라 특징점 추출 알고리즘의 설정에 따른 특징점 축소의 예시를 제시하기 위한 도면이다. 도 7은 본 개시의 실시 예에 따른 특징점 매칭 모듈의 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 실시 예에 따라 특징점 추출 알고리즘을 기반으로 3D 모델링을 수행하는 방법을 설명하기 위 한 순서도이다."}
