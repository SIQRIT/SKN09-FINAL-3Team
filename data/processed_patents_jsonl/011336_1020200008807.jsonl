{"patent_id": "10-2020-0008807", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0094936", "출원번호": "10-2020-0008807", "발명의 명칭": "심층 인공 신경망을 이용한 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법", "출원인": "광운대학교 산학협력단", "발명자": "안창범"}}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 학습용 풀 데이터로부터 생성한 학습용 압축 센싱 데이터로부터 학습용 초기 영상을 생성하는 단계;(b) 상기 학습용 풀 데이터로부터 생성한 학습용 기준 영상과 상기 학습용 초기 영상의 차이인 학습용 오차 영상을 생성하는 단계;(c) 상기 학습용 초기 영상을 슬라이싱하여 얻어진 제1 학습용 t-y 평면 영상과 상기 학습용 오차 영상을 슬라이싱하여 얻어진 제2 학습용 t-y 평면 영상으로 심층 인공 신경망을 학습시키는 단계;(d) 대상체로부터 획득한 대상체 압축 센싱 데이터로부터 대상체 초기 영상을 생성하는 단계;(e) 상기 대상체 초기 영상을 슬라이싱하여 얻어진 제1 대상체 t-y 평면 영상을 상기 (c) 단계에서 학습된 상기심층 인공 신경망에 제공하여 제2 대상체 t-y 평면 영상을 생성하는 단계; 및(f) 상기 제2 대상체 t-y 평면 영상으로부터 얻어진 대상체 오차 영상과 상기 대상체 초기 영상으로부터 추정대상체 영상을 생성하는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 (a) 단계는(a-1) 상기 학습용 압축 센싱 데이터를 선형 보간하는 단계; 및(a-2) 상기 보간된 상기 학습용 압축 센싱 데이터를 2차원 푸리에 변환하여 상기 학습용 초기 영상을 생성하는단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 학습용 기준 영상, 상기 학습용 초기 영상 및 상기 학습용 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로표시되는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 (c) 단계는(c-1) x=x0일 때 z=z0 단면에 대한 상기 학습용 초기 영상을 슬라이싱하여 학습용 t-y 평면 초기 영상을 생성하는 단계;(c-2) x=x0일 때 z=z0 단면에 대한 상기 학습용 오차 영상을 슬라이싱하여 학습용 t-y 평면 오차 영상을 생성하는 단계;(c-3) 상기 (c-1) 단계에서 생성된 상기 학습용 t-y 평면 초기 영상과 상기 (c-2) 단계에서 생성된 상기 학습용t-y 평면 오차 영상을 각각 정규화하는 단계;(c-4) 각 x 값에 대해 상기 (c-1) 내지 (c-3) 단계를 반복하는 단계;(c-5) 각 z 값에 대해 상기 (c-1) 내지 (c-4) 단계를 반복하여 상기 학습용 t-y 평면 초기 영상 및 상기 학습용공개특허 10-2021-0094936-3-t-y 평면 오차 영상으로부터 상기 제1 학습용 t-y 평면 영상 및 상기 제2 학습용 t-y 평면 영상을 각각 생성하는 단계; 및(c-6) 상기 제1 학습용 t-y 평면 영상 및 상기 제2 학습용 t-y 평면 영상으로 상기 심층 인공 신경망을 학습시키는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 (c-6) 단계는 상기 제1 학습용 t-y 평면 영상과 제2 학습용 t-y 평면 영상을 각각 입력과 타겟으로 하여수행되는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 (c-3) 단계는(c-3-1) 상기 학습용 t-y 평면 초기 영상을 식 에 따라 정규화하는 단계; 및(c-3-2) 상기 학습용 t-y 평면 오차 영상을 식 에 따라 정규화하는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법(단, I(x0, y, z0, t)는 상기 학습용 t-y 평면 초기 영상, E(x0, y, z0, t)는 상기 학습용 t-y 평면 오차 영상, i(x0, y, z0, t) 및 e(x0, y, z0, t)는 각각 정규화된 학습용 t-y 평면 초기 영상 및 정규화된 학습용 t-y 평면 오차 영상, MAX는 상기 학습용 초기 영상의 최대값)."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 (d) 단계는(d-1) 상기 대상체 압축 센싱 데이터를 선형 보간하는 단계; 및(d-2) 상기 보간된 상기 대상체 압축 센싱 데이터를 2차원 푸리에 변환하여 대상체 초기 영상을 생성하는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 대상체 초기 영상 및 상기 대상체 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시되는 것을 특징으로하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 (e) 단계는(e-1) x=x0일 때 z=z0 단면에 대한 상기 대상체 초기 영상을 슬라이싱하여 대상체 t-y 평면 초기 영상을 생성하는 단계;(e-2) 상기 (e-1) 단계에서 생성된 상기 대상체 t-y 평면 초기 영상을 정규화하는 단계;(e-3) 각 x 값에 대해 상기 (e-1) 및 (e-2) 단계를 반복하는 단계;(e-4) 각 z 값에 대해 상기 (e-1) 내지 (e-3) 단계를 반복하여 정규화된 상기 대상체 t-y 평면 초기 영상으로부공개특허 10-2021-0094936-4-터 제1 대상체 t-y 평면 영상을 생성하는 단계;(e-5) 상기 제1 대상체 t-y 평면 영상을 상기 심층 인공 신경망에 제공하여 제2 대상체 t-y 평면 영상을 생성하는 단계; 및(e-6) 상기 제2 대상체 t-y 평면 영상을 역정규화하여 상기 대상체 오차 영상을 생성하는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 (e-2) 단계는 상기 대상체 t-y 평면 초기 영상을 식 에 따라 정규화하는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법(단, I(x0, y, z0, t)는 상기 대상체 t-y 평면 초기 영상, i(x0, y, z0, t)는 정규화된 대상체 t-y 평면 초기 영상, MAX는 상기 학습용 초기 영상의 최대값)."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 (e-6) 단계는 상기 제2 대상체 t-y 평면 영상을 식 에 따라 역정규화하여 상기 정규화된 제2 대상체 t-y 평면 영상을 생성하는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법(단, e(x, y, z, t)는 상기 제2 대상체 t-y 평면 영상, 는 상기 대상체 오차 영상, MAX는 상기 학습용 초기 영상의 최대값)."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 (f) 단계는 상기 대상체 오차 영상과 상기 대상체 초기 영상을 합산하여 상기 대상체 영상을 생성하는 단계를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 방법."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "학습용 풀 데이터; 상기 학습용 풀 데이터로부터 추출된 학습용 압축 센싱 데이터; 및 대상체로부터 획득한 대상체 압축 센싱 데이터;를 생성하는 영상 데이터 생성부;상기 학습용 풀 데이터로부터 학습용 기준 영상을 생성하는 기준 영상 생성부;상기 학습용 압축 센싱 데이터와 상기 대상체 압축 센싱 데이터로부터 학습용 초기 영상과 대상체 초기 영상을각각 생성하는 초기 영상 생성부;상기 학습용 기준 영상과 상기 학습용 초기 영상의 차이인 학습용 오차 영상을 생성하고; 상기 학습용 초기 영상과 상기 학습용 오차 영상을 슬라이싱하여 제1 학습용 t-y 평면 영상과 제2 학습용 t-y 평면 영상을 각각 생성하며; 상기 제1 학습용 t-y 평면 영상과 상기 제2 학습용 t-y 평면 영상을 심층 인공 신경망에 제공하여 상기심층 인공 신경망을 학습시키며; 상기 대상체 초기 영상을 슬라이싱하여 얻어진 제1 대상체 t-y 평면 영상을 학습된 상기 심층 인공 신경망에 제공하고 상기 심층 인공 신경망으로부터 제2 대상체 t-y 평면 영상을 수신하며;상기 제2 대상체 t-y 평면 영상으로부터 대상체 오차 영상을 생성하는 영상 처리부; 및상기 대상체 오차 영상과 상기 대상체 초기 영상으로부터 대상체 영상을 생성하는 대상체 영상 생성부를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 초기 영상 생성부는 상기 학습용 압축 센싱 데이터를 선형 보간하는 선형 보간부; 및공개특허 10-2021-0094936-5-상기 보간된 상기 학습용 압축 센싱 데이터를 2차원 푸리에 변환하여 상기 학습용 초기 영상을 생성하는 2D FFT부를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 학습용 기준 영상, 상기 학습용 초기 영상 및 상기 학습용 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로표시되는 것을 특징으로 하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 영상 처리부는상기 학습용 기준 영상과 상기 학습용 초기 영상의 차이인 학습용 오차 영상을 생성하는 오차 영상 생성부;각 x 값 및 각 z 값에 대해 상기 학습용 초기 영상 및 상기 학습용 오차 영상을 슬라이싱하여 학습용 t-y 평면초기 영상 및 학습용 t-y 평면 오차 영상을 각각 생성하는 t-y 평면 생성부; 및상기 t-y 평면 생성부가 생성한 학습용 t-y 평면 초기 영상 및 학습용 t-y 평면 오차 영상을 각각 정규화하여상기 제1 학습용 t-y 평면 영상 및 상기 제2 학습용 t-y 평면 영상을 각각 생성하는 정규화/역정규화부를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 정규화/역정규화부는 상기 학습용 t-y 평면 초기 영상을 식 에 따라 정규화하고,상기 학습용 t-y 평면 오차 영상을 식 에 따라 정규화하는 것을 특징으로 하는자기 공명 영상 생성 시스템(단, I(x0, y, z0, t)는 상기 학습용 t-y 평면 초기 영상, E(x, y, z, t)는 상기 학습용 t-y 평면 오차 영상, i(x, y, z, t)는 정규화된 상기 학습용 t-y 평면 초기 영상, e(x, y, z, t)는 정규화된상기 학습용 t-y 평면 오차 영상, MAX는 상기 학습용 초기 영상의 최대값)."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 초기 영상 생성부는 상기 대상체 압축 센싱 데이터를 선형 보간하는 선형 보간부; 및상기 보간된 상기 대상체 압축 센싱 데이터를 2D FFT하여 대상체 초기 영상을 생성하는 2D FFT부를 포함하는 것을 특징으로 하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,상기 대상체 초기 영상 및 상기 대상체 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시되는 것을 특징으로하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항에 있어서,상기 t-y 평면 생성부는 각 x 값 및 각 z 값에 대해 상기 대상체 초기 영상을 슬라이싱하여 대상체 t-y 평면 초공개특허 10-2021-0094936-6-기 영상을 생성하며,상기 정규화/역정규화부는 상기 대상체 t-y 평면 초기 영상을 정규화하여 얻어진 상기 제1 대상체 t-y 평면 영상을 상기 심층 인공 신경망에 제공하고, 상기 심층 인공 신경망이 생성한 상기 제2 대상체 t-y 평면 영상을 역정규화하며,상기 오차 영상 생성부는 상기 정규화/역정규화부가 역정규화한 상기 제2 대상체 t-y 평면 영상으로부터 상기대상체 오차 영상을 생성하는 것을 특징으로 하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 정규화/역정규화부는 각 x 값 및 각 z 값에 대해 상기 제2 대상체 t-y 평면 영상을 식에 따라 역정규화하는 것을 특징으로 하는 자기 공명 영상 생성 방법(단,e(x, y, z, t)는 상기 제2 대상체 t-y 평면 영상, 는 정규화된 제2 대상체 t-y 평면 영상, MAX는 상기 학습용 초기 영상의 최대값)."}
{"patent_id": "10-2020-0008807", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제13항에 있어서,상기 대상체 영상 생성부는 상기 대상체 오차 영상과 상기 대상체 초기 영상을 합산하여 상기 대상체 영상을 생성하는 것을 특징으로 하는 자기 공명 영상 생성 시스템."}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 심층 인공 신경망을 이용하여 나이키스트 레이트보다 낮은 샘플링 레이트로 획득한 데이터로부터 높은 공간 해상도와 시간 해상도를 가지는 고품질의 자기 공명 영상을 재구성하는 자기 공명 영상 생성 시스템 및 자 기 공명 영상 생성 방법에 관한 것이다. 본 발명에 따른 자기 공명 영상 생성 방법은 (a) 학습용 풀 데이터로부 (뒷면에 계속)"}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 심층 인공 신경망을 이용한 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법에 관한 것으로, 특히 심층 인공 신경망(Deep Artificial Neural Network)을 이용하여 나이키스트 레이트(Nyquist rate)보다 낮은 샘플링 레이트(Sampling Rate)로 획득한 데이터로부터 높은 공간 해상도와 시간 해상도를 가지 는 고품질의 자기 공명 영상을 재구성하는 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법에 관한 것 이다. 본 발명은 과학기술정보통신부의 개인기초연구(과기정통부)(R&D) 사업(과제명: 알고리즘과 데이터 기반 하이브리드 의학 영상 시스템, 과제 번호: 1711091305, 세부 과제 번호: 2019R1A2C2005660, 발주기관: 한국연구 재단)의 연구 결과로 도출되었다."}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자기 공명 영상 장치를 이용하여 움직이는 장기의 동영상을 획득하기 위해서는 연속적인 고속 영상을 생성하는 것이 필요하다. 연속적인 고속 영상을 생성하기 위해서는 높은 경사자장과 빠른 변화율을 갖는 경사자장 증폭기 등을 구비한 고사양의 자기 공명 영상 장치가 필요하다. 고사양의 자기 공명 영상 장치는 고가이며, 고속의 높 은 경사자장 변화로 인한 큰 와류를 유발하여 인체의 말초신경을 자극할 수 있다는 문제가 있다. 이러한 문제점을 극복하기 위하여, 나이키스트 레이트(Nyquist rate)보다 낮은 샘플링 레이트로 취득한 데이터 (압축 센싱 데이터)를 영상 처리하여 연속적인 고속 영상을 생성하는 압축 센싱 방법이 제안되었다. 압축 센싱 방법은 연속적인 고속 영상을 생성하기 위하여 비선형 방정식을 이용한다. 그러나, 비선형 방정식을 이용하는 경우, 계산량이 많아 임상에 적용하기 어렵다는 문제가 있다. 이러한 문제를 해결하기 위하여 인공 지능(Artificial Intelligence)을 이용하여 압축 센싱 데이터로부터 연속 적인 고속 영상을 재구성하는 방법이 제안되었다. 인공 지능은 비선형 방정식에 비해 빠른 속도로 연속적인 고 속 영상을 재구성할 수 있다. 그러나, 인공 지능을 이용하여 연속적인 고속 영상을 재구성하는 방법은 재구성된 영상의 공간 해상도를 향상시킬 수 있을 뿐이며, 시간 해상도의 개선에는 한계가 있다. 선행기술문헌 특허문헌(특허문헌 0001) 등록특허 제10-1274612호 비특허문헌 (비특허문헌 0001) 비특허 문헌 1: Jocic Marko, \"Deep Learning Tutorial for Kaggle Ultrasound Nerve Segmentation competition, using Keras,\" (https://github.com/jocicmarko/ultrasound-nerve-segmentation/) (비특허문헌 0002) 비특허 문헌 2: Olaf Ronneberger,?Philipp Fischer,?Thomas Brox, \"U-Net: Convolutional Networks for Biomedical Image Segmentation,\" arXiv:1505.04597 (https://arxiv.org/abs/1505.04597)."}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 심층 인공 신경망을 이용하여 나이키스트 레이트보다 낮은 샘플링 레이트로 획득한 데이터로부터 높 은 공간 해상도와 시간 해상도를 가지는 고품질의 자기 공명 영상을 재구성하는 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법을 제공하는 것을 그 목적으로 한다."}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 자기 공명 영상 생성 방법은 (a) 학습용 풀 데이터로부터 생성한 학습용 압축 센싱 데이터로부 터 학습용 초기 영상을 생성하는 단계; (b) 상기 학습용 풀 데이터로부터 생성한 학습용 기준 영상과 상기 학습 용 초기 영상의 차이인 학습용 오차 영상을 생성하는 단계; (c) 상기 학습용 초기 영상을 슬라이싱하여 얻어진 제1 학습용 t-y 평면 영상과 상기 학습용 오차 영상을 슬라이싱하여 얻어진 제2 학습용 t-y 평면 영상으로 심층 인공 신경망을 학습시키는 단계; (d) 대상체로부터 획득한 대상체 압축 센싱 데이터로부터 대상체 초기 영상을 생성하는 단계; (e) 상기 대상체 초기 영상을 슬라이싱하여 얻어진 제1 대상체 t-y 평면 영상을 상기 (c) 단계 에서 학습된 상기 심층 인공 신경망에 제공하여 제2 대상체 t-y 평면 영상을 생성하는 단계; 및 (f) 상기 제2 대상체 t-y 평면 영상으로부터 얻어진 대상체 오차 영상과 상기 대상체 초기 영상으로부터 추정 대상체 영상을 생성하는 단계를 포함하는 것을 특징으로 한다. 상기 (a) 단계는 (a-1) 상기 학습용 압축 센싱 데이터를 선형 보간하는 단계; 및 (a-2) 상기 보간된 상기 학습 용 압축 센싱 데이터를 2차원 푸리에 변환하여 상기 학습용 초기 영상을 생성하는 단계를 포함할 수 있다. 상기 학습용 기준 영상, 상기 학습용 초기 영상 및 상기 학습용 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시될 수 있다. 상기 (c) 단계는 (c-1) x=x0일 때 z=z0 단면에 대한 상기 학습용 초기 영상을 슬라이싱하여 학습용 t-y 평면 초 기 영상을 생성하는 단계; (c-2) x=x0일 때 z=z0 단면에 대한 상기 학습용 오차 영상을 슬라이싱하여 학습용 t-y 평면 오차 영상을 생성하는 단계; (c-3) 상기 (c-1) 단계에서 생성된 상기 학습용 t-y 평면 초기 영상과 상기 (c-2) 단계에서 생성된 상기 학습용 t-y 평면 오차 영상을 각각 정규화하는 단계; (c-4) 각 x 값에 대해 상기 (c-1) 내지 (c-3) 단계를 반복하는 단계; (c-5) 각 z 값에 대해 상기 (c-1) 내지 (c-4) 단계를 반복하여 상기 학습용 t-y 평면 초기 영상 및 상기 학습용 t-y 평면 오차 영상으로부터 상기 제1 학습용 t-y 평면 영상 및 상 기 제2 학습용 t-y 평면 영상을 각각 생성하는 단계; 및 (c-6) 상기 제1 학습용 t-y 평면 영상 및 상기 제2 학 습용 t-y 평면 영상으로 상기 심층 인공 신경망을 학습시키는 단계를 포함할 수 있다. 상기 (c-6) 단계는 상기 제1 학습용 t-y 평면 영상과 제2 학습용 t-y 평면 영상을 각각 입력과 타겟으로 하여 수행될 수 있다. 상기 (c-3) 단계는 (c-3-1) 상기 학습용 t-y 평면 초기 영상을 식 에 따라 정규화 하는 단계; 및 (c-3-2) 상기 학습용 t-y 평면 오차 영상을 식 에 따라 정규화하는 단계를 포함할 수 있다(단, I(x0, y, z0, t)는 상기 학습용 t-y 평면 초기 영상, E(x0, y, z0, t)는 상기 학 습용 t-y 평면 오차 영상, i(x0, y, z0, t) 및 e(x0, y, z0, t)는 각각 정규화된 학습용 t-y 평면 초기 영상 및 정 규화된 학습용 t-y 평면 오차 영상, MAX는 상기 학습용 초기 영상의 최대값). 상기 (d) 단계는 (d-1) 상기 대상체 압축 센싱 데이터를 선형 보간하는 단계; 및 (d-2) 상기 보간된 상기 대상 체 압축 센싱 데이터를 2차원 푸리에 변환하여 대상체 초기 영상을 생성하는 단계를 포함할 수 있다. 상기 대상체 초기 영상 및 상기 대상체 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시될 수 있다. 상기 (e) 단계는 (e-1) x=x0일 때 z=z0 단면에 대한 상기 대상체 초기 영상을 슬라이싱하여 대상체 t-y 평면 초 기 영상을 생성하는 단계; (e-2) 상기 (e-1) 단계에서 생성된 상기 대상체 t-y 평면 초기 영상을 정규화하는 단 계; (e-3) 각 x 값에 대해 상기 (e-1) 및 (e-2) 단계를 반복하는 단계; (e-4) 각 z 값에 대해 상기 (e-1) 내지 (e-3) 단계를 반복하여 정규화된 상기 대상체 t-y 평면 초기 영상으로부터 제1 대상체 t-y 평면 영상을 생성하 는 단계; (e-5) 상기 제1 대상체 t-y 평면 영상을 상기 심층 인공 신경망에 제공하여 제2 대상체 t-y 평면 영상 을 생성하는 단계; 및 (e-6) 상기 제2 대상체 t-y 평면 영상을 역정규화하여 상기 대상체 오차 영상을 생성하는 단계를 포함할 수 있다. 상기 (e-2) 단계는 상기 대상체 t-y 평면 초기 영상을 식 에 따라 정규화하는 단계 를 포함할 수 있다(단, I(x0, y, z0, t)는 상기 대상체 t-y 평면 초기 영상, i(x0, y, z0, t)는 정규화된 대상체 t- y 평면 초기 영상, MAX는 상기 학습용 초기 영상의 최대값). 상기 (e-6) 단계는 상기 제2 대상체 t-y 평면 영상을 식 에 따라 역정규 화하여 상기 정규화된 제2 대상체 t-y 평면 영상을 생성하는 단계를 포함할 수 있다(단, e(x, y, z, t)는 상기 제2 대상체 t-y 평면 영상, 는 상기 대상체 오차 영상, MAX는 상기 학습용 초기 영상의 최대값). 상기 (f) 단계는 상기 대상체 오차 영상과 상기 대상체 초기 영상을 합산하여 상기 대상체 영상을 생성하는 단 계를 포함할 수 있다. 본 발명에 따른 자기 공명 영상 생성 시스템은 학습용 풀 데이터; 상기 학습용 풀 데이터로부터 추출된 학습용 압축 센싱 데이터; 및 대상체로부터 획득한 대상체 압축 센싱 데이터;를 생성하는 영상 데이터 생성부; 상기 학 습용 풀 데이터로부터 학습용 기준 영상을 생성하는 기준 영상 생성부; 상기 학습용 압축 센싱 데이터와 상기 대상체 압축 센싱 데이터로부터 학습용 초기 영상과 대상체 초기 영상을 각각 생성하는 초기 영상 생성부; 상기 학습용 기준 영상과 상기 학습용 초기 영상의 차이인 학습용 오차 영상을 생성하고; 상기 학습용 초기 영상과 상기 학습용 오차 영상을 슬라이싱하여 제1 학습용 t-y 평면 영상과 제2 학습용 t-y 평면 영상을 각각 생성하며; 상기 제1 학습용 t-y 평면 영상과 상기 제2 학습용 t-y 평면 영상을 심층 인공 신경망에 제공하여 상 기 심층 인공 신경망을 학습시키며; 상기 대상체 초기 영상을 슬라이싱하여 얻어진 제1 대상체 t-y 평면 영상을 학습된 상기 심층 인공 신경망에 제공하고 상기 심층 인공 신경망으로부터 제2 대상체 t-y 평면 영상을 수신하 며; 상기 제2 대상체 t-y 평면 영상으로부터 대상체 오차 영상을 생성하는 영상 처리부; 및 상기 대상체 오차 영상과 상기 대상체 초기 영상으로부터 대상체 영상을 생성하는 대상체 영상 생성부를 포함하는 것을 특징으로 한다. 상기 초기 영상 생성부는 상기 학습용 압축 센싱 데이터를 선형 보간하는 선형 보간부; 및 상기 보간된 상기 학 습용 압축 센싱 데이터를 2차원 푸리에 변환하여 상기 학습용 초기 영상을 생성하는 2D FFT부를 포함할 수 있다. 상기 학습용 기준 영상, 상기 학습용 초기 영상 및 상기 학습용 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시될 수 있다. 상기 영상 처리부는 상기 학습용 기준 영상과 상기 학습용 초기 영상의 차이인 학습용 오차 영상을 생성하는 오 차 영상 생성부; 각 x 값 및 각 z 값에 대해 상기 학습용 초기 영상 및 상기 학습용 오차 영상을 슬라이싱하여 학습용 t-y 평면 초기 영상 및 학습용 t-y 평면 오차 영상을 각각 생성하는 t-y 평면 생성부; 및 상기 t-y 평면 생성부가 생성한 학습용 t-y 평면 초기 영상 및 학습용 t-y 평면 오차 영상을 각각 정규화하여 상기 제1 학습용 t-y 평면 영상 및 상기 제2 학습용 t-y 평면 영상을 각각 생성하는 정규화/역정규화부를 포함할 수 있다.상기 정규화/역정규화부는 상기 학습용 t-y 평면 초기 영상을 식 에 따라 정규화하고, 상기 학습용 t-y 평면 오차 영상을 식 에 따라 정규화할 수 있다(단, I(x0, y, z0, t)는 상기 학습용 t-y 평면 초기 영상, E(x, y, z, t)는 상기 학습용 t-y 평면 오차 영상, i(x, y, z, t)는 정규 화된 상기 학습용 t-y 평면 초기 영상, e(x, y, z, t)는 정규화된 상기 학습용 t-y 평면 오차 영상, MAX는 상기 학습용 초기 영상의 최대값). 상기 초기 영상 생성부는 상기 대상체 압축 센싱 데이터를 선형 보간하는 선형 보간부; 및 상기 보간된 상기 대 상체 압축 센싱 데이터를 2D FFT하여 대상체 초기 영상을 생성하는 2D FFT부를 포함할 수 있다. 상기 대상체 초기 영상 및 상기 대상체 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시될 수 있다. 상기 t-y 평면 생성부는 각 x 값 및 각 z 값에 대해 상기 대상체 초기 영상을 슬라이싱하여 대상체 t-y 평면 초 기 영상을 생성하며, 상기 정규화/역정규화부는 상기 대상체 t-y 평면 초기 영상을 정규화하여 얻어진 상기 제1 대상체 t-y 평면 영상을 상기 심층 인공 신경망에 제공하고, 상기 심층 인공 신경망이 생성한 상기 제2 대상체 t-y 평면 영상을 역정규화하며, 상기 오차 영상 생성부는 상기 정규화/역정규화부가 역정규화한 상기 제2 대상 체 t-y 평면 영상으로부터 상기 대상체 오차 영상을 생성할 수 있다. 상기 정규화/역정규화부는 각 x 값 및 각 z 값에 대해 상기 제2 대상체 t-y 평면 영상을 식 에 따라 역정규화할 수 있다(단, e(x, y, z, t)는 상기 제2 대상체 t-y 평면 영상, 는 정규화된 제2 대상체 t-y 평면 영상, MAX는 상기 학습용 초기 영상의 최대값). 상기 대상체 영상 생성부는 상기 대상체 오차 영상과 상기 대상체 초기 영상을 합산하여 상기 대상체 영상을 생 성할 수 있다."}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법에는 다음 과 같은 장점이 있다. 나이키스트 레이트보다 낮은 샘플링 레이트로 획득한 데이터를 이용하므로 고사양의 자기 공명 영상 장치를 이용하지 않더라고 고품질의 자기 공명 영상을 얻을 수 있다. 심층 인공 신경망을 t-y 평면 영상으로 학습시킴으로써 x-y 평면 영상에 비해 높은 공간 해상도와 시간 해 상도를 가지는 고품질의 자기 공명 영상을 재구성할 수 있다."}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 첨부된 도면을 참조하여, 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법에 대해 상세히 설명한다. 먼저, 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 시스템을 도 1 내지 도 9를 참조하여 상 세히 설명한다. 도 1은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 시스템을 도시한 블록도이다. 도 1을 참조하면, 본 발명에 따른 자기 공명 영상 생성 시스템은 제어부, 영상 데이터 생성부, 기준 영상 생성부, 초기 영상 생성부, 영상 처리부, 대상체 영상 생성부 및 심층 인공 신 경망을 포함한다. 제어부는 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법을 수행하기 위해 영상 데 이터 생성부, 기준 영상 생성부, 초기 영상 생성부, 영상 처리부, 대상체 영상 생성부 및 심층 인공 신경망을 제어한다. 영상 데이터 생성부는 자기 공명 영상 장치로서 학습용 풀 데이터; 학습용 풀 데이터로부터 추출된 학습용 압축 센싱 데이터; 및 대상체로부터 획득한 대상체 압축 센싱 데이터;를 생성한다. 이하에서는, 도 2를 참조하여 영상 데이터 생성부에 대해 보다 상세히 설명한다. 도 2는 본 발명에 따른 영상 데이터 생성부를 도시한 블록도이다. 도 2를 참조하면, 영상 데이터 생성부는 제어부(110a), 경사 증폭기(110b), RF 증폭기(110c), 수신기 (110d), 경사 자장 코일(110e), 어레이 RF 코일(110f) 및 자석(110g)을 포함한다. 또한, 영상 데이터 생성부 는 대상체의 심장 박동을 검출하여 제어부(110a)에 전송하는 심장 박동 검출부(미도시)를 더 포함할 수 있 다. 자석(110g)은 주 자장을 발생시킨다. 경사 자장 코일(110e), 어레이 RF 코일(110f) 및 자석(110g)은 검사할 대 상체(예를 들면, 심장)가 수용되는 공간 내에 설치된다. 제어부(110a)는 경사 자장 코일(110e)과 어레이 RF 코일(110f)에 전류가 인가되도록 경사 증폭기(110b)와 RF 증 폭기(110c)를 각각 제어한다. 경사 증폭기(110b)는 경사 자장 코일(110e)에 전류를 인가한다. 경사 자장 코일(110e)에 전류가 인가되면, 경사 자장 코일(110e)은 x-축, y-축, 및 z-축 방향으로 경사자장을 발생시킨다. RF 증폭기(110c)는 어레이 RF 코일(110f)에 전류를 인가한다. 어레이 RF 코일(110f)에 전류가 인가되면, 어레이 RF 코일(110f)는 RF 펄스를 발생시킨다. 또한, 대상체가 상기 RF 펄스에 의해 여기되면, 대상체로부터 자기 공 명 신호가 발생되고, 어레이 RF 코일(110f)은 이를 수신하여 수신기(110d)로 전송한다. 수신기(110d)는 어레이 RF 코일(110f)이 전송한 자기 공명 신호를 제어부(110a)로 전송한다. 제어부(110a)는 수신한 자기 공명 신호로부터 필요에 따라 학습용 풀 데이터, 학습용 압축 센싱 데이터 및 대상 체 압축 센싱 데이터를 생성한다.이하에서는, 영상 데이터 생성부가 자기 공명 신호를 수신하기 위해 사용하는 펄스 시퀀스에 대해 상세히 설명한다. 도 3은 영상 데이터 생성부가 자기 공명 신호를 획득하기 위하여 사용하는 펄스 시퀀스를 도시한 도면이다. 도 3을 참조하면, RF 펄스는 단면 선택 경사자계(slice selection gradient)에 의해 선택된 2차원 단면에 존재하는 수소 원자의 숙임각을 결정하여 여기한다. 그리고 선택된 단면의 2차원 영상정보를 얻기 위하 여 미리 계산된 크기와 폭으로 위상 부호화 경사자장(phase encoding gradient)과 주파수부호화 경사자장 (frequency encoding gradient)(205, 206)을 가하여 이차원 자기 공명 신호를 얻는다. 이하에서는, 영상 데이터 생성부가 생성하는 영상 데이터에 대해 상세히 설명한다. 도 5는 대상체를 개략적으로 도시한 도면이다. 본 발명에 따르면, 촬영의 대상이 되는 대상체는 심장과 같이 움 직임(심장 박동)이 있는 장기이다. 설명의 편의를 위하여, 도 5에 대상체를 직육면체로 표현하였다. MRI는 대상체의 단면을 촬영하는 장치이다. 따라서, 도 5에 도시된 것과 같이 대상체를 z 단면으로 구분하여 촬 영한다. 도 5에 도시된 바와 같이, 설명의 편의를 위하여 대상체를 z0 평면 내지 z11 평면(12개의 평면)으로 구 분한다. 그러나, 평면의 개수는 이에 국한되지 않는다. 심장과 같이 박동하는 장기는 시간에 따라 형상에 변동이 생긴다. 즉, 도 5에 도시된 각 x-y 평면(주파수 대역 에서는 kx-ky)에 시간에 따라 변동이 생긴다(단, z 축 방향으로는 움직임이 없다고 가정한다). 따라서, 대상체 로부터 획득되는 데이터가 시간에 따라 변화한다. 도 6은 대상체를 촬영하여 얻어진 데이터를 시간에 따라 개략적으로 도시한 도면이다. 도 6을 참조하면, 대상체의 시간에 따른 움직임(예를 들면, 심장 박동)으로 인하여, t0 내지 t15의 각 t에서 z0 평면에 대해서 서로 다른 데이터가 생성된다. 마찬가지로, z1 평면 내지 z11 평면 각각에 대해서도 각 t에서 데 이터가 생성된다. t0 내지 t15의 각 t에서 생성된 z0 평면에 대한 데이터를 이미지로 변환하여 연속적으로 재생하 면, 대상체의 z0 평면의 변화를 관찰할 수 있는 동영상을 생성할 수 있다. 즉, t0 내지 t15의 각 t에서 생성된 z 평면에 대한 데이터를 이미지로 변환하여 연속적으로 재생하면, 대상체의 z 평면의 변화를 관찰할 수 있는 동영 상을 생성할 수 있다. 도 6에는 t0 내지 t15의 각 t에서 각 z 평면에 대한 16개의 데이터를 생성하는 예가 도시되어 있으나, 데이터의 개수는 이에 국한되지 않는다. 예를 들어, 각 z 평면에 대한 데이터의 개수는 부드러운 동영상을 생성하는데 필 요한 개수인 24 내지 30개일 수 있다. 이하에서는, 영상 데이터 생성부가 생성하는 각 데이터에 대해 설명한다. 도 7a는 풀 샘플링된 데이터를 개략적으로 도시한 도면으로, 도 6에 도시된 복수개의 데이터 중 하나일 수 있다. 도 7a에 도시된 바와 같이, 영상 데이터 생성부는 라인 형태의 데이터(라인 데이터)를 생성하고, 이 를 합쳐 하나의 데이터를 생성한다. 예를 들어, 하나의 데이터는 256개의 라인 데이터로 구성될 수 있다. 여기 서, \"풀 샘플링\"(full sampling)은 누락 없이 소정 개수의 라인 데이터(예를 들면, 256개)를 모두 생성하고 이 를 합쳐 하나의 데이터를 생성하는 것을 의미한다. 풀 샘플링된 데이터를 이미지로 변환하면 화질이 우수하여 장기를 관찰하고 진단하는데 유리하지만, 풀 샘플링 된 데이터를 생성하려면 많은 양의 라인 데이터가 필요하므로 오랜 시간이 소요된다. 특히, 심장과 같이 움직이 는 장기를 촬영하는 경우에는 z 축 방향의 움직임을 최소화하기 위하여 호흡을 중단해야 하는데, 호흡을 중단할 수 있는 시간은 매우 제한적이므로, 풀 샘플링된 데이터를 생성하려면 더욱 오랜 시간이 소요된다. 도 7b는 언더 샘플링된 데이터를 개략적으로 도시한 도면이다. 영상 데이터 생성부가 라인 데이터를 생성 한다는 점에서는 도 7a에 도시된 풀 샘플링된 데이터와 동일하지만, 라인 데이터의 개수는 풀 샘플링된 데이터 의 그것보다 작다. 예를 들어, 영상 데이터 생성부는 256개의 라인 데이터를 생성하지 않고 일부분이 생략 된 32개의 라인으로 이미지를 구성할 수 있다. 따라서, 언더 샘플링된 데이터 내에는 데이터가 존재하지 않는 부분이 있다. 언더 샘플링된 데이터는 풀 샘플링된 데이터에 비해 적은 양의 데이터를 필요로 하므로 상대적으로 짧은 시간에 생성할 수 있다. 그러나, 이미지로 변환하는 경우 풀 샘플링된 데이터에 비해 화질이 좋지 않아 장기를 관찰하 고 진단하는데 불리하다. 특히, 심장과 같이 움직이는 장기를 촬영하는 경우 호흡을 중단할 수 있는 시간이 매 우 제한적인 점을 고려하면, 풀 샘플링된 데이터에 비해 언더 샘플링된 데이터를 생성하는 것이 훨씬 용이하다. 이와 같이 영상 데이터 생성부가 언더 샘플링된 데이터를 생성하는 것을 \"압축 센싱\"이라 한다. 압축 센싱 은 소정의 압축비에 따라 수행된다. 예를 들어, 압축비가 4이면 1/4만 샘플링한다. 이러한 언더 샘플링된 데이터의 단점을 보완하기 위하여, 선형 보간(linear interpolation)을 수행한다. 도 7b의 언더 샘플링된 데이터를 보간하여 얻이진 데이터가 도 7c에 개략적으로 도시되어 있다. 선형 보간은 데이터가 없는 부분을 이웃하는 데이터를 이용하여 채워 넣는 것이다. 선형 보간을 하면, 언더 샘 플링된 데이터로부터 얻어진 이미지의 화질은 향상되지만, 풀 샘플링된 데이터로부터 얻어진 이미지의 그것에는 미치지 못한다. 이하에서는, 풀 샘플링된 데이터를 \"풀 데이터\"(full data)라 하고, 언더 샘플링된 데이터를 \"압축 센싱 데이터\"(compressed sensing data)라 한다. 본 발명은 심층 인공 신경망을 이용하여 위 문제점을 해결한다. 심층 인공 신경망은 인공 지능(Artificial Intelligence)이다. 따라서, 소정의 학습 데이터로 학습을 시키면 이를 기초로 소정의 출력물을 제공한다. 본 발명에서는, 풀 데이터로부터 얻어진 이미지를 이용하여 심층 인공 신경망을 학습시키고, 압축 센싱 데이터로부 터 얻어진 이미지를 심층 인공 신경망에 입력하여 추정된 영상을 얻는다. 따라서, 본 발명은 다음과 같은 세가지 데이터를 필요로 한다. 학습용 풀 데이터 심층 인공 신경망을 학습시키기 위하여 영상 데이터 생성부가 생성한 풀 데이터이다. 학습용 풀 데이터는 누락된 부분 없이 모든 라인 데이터를 포함한다. 즉, 학습용 풀 데이터는 도 6에 도시된 복수개의 데이터 각각 에 누락된 부분 없는 것을 의미한다. 통상적으로 학습용 풀 데이터는 피험자로부터 얻어진다. 즉, 환자가 아닌 피험자로부터 얻는 풀 데이터이다. 학습용 풀 데이터는 심층 인공 신경망을 학습시키기 위해 반드시 필요한 데 이터이므로 영상 데이터 생성부가 일정 수 이상의 피험자를 이용하여 생성한다. 학습용 압축 센싱 데이터 학습용 압축 센싱 데이터는 학습용 풀 데이터에서 의도적으로 일부 라인 데이터를 제거한 것이다. 예를 들어, 학습용 풀 데이터로부터 생성되는 데이터에 포함된 복수개의 라인 데이터 중 일부를 제거하여 생성한다. 일부 라인 데이터를 제거하는 이유는 실제로 영상을 얻고자 하는 대상체로부터 획득한 압축 센싱 데이터와 동일한 환 경으로 심층 인공 신경망을 학습시키기 위함이다. 즉, 학습용 압축 센싱 데이터는 학습용 풀 데이터로부터 일부 데이터를 추출하여 생성하며, 촬영하고자 하는 대상체로부터 획득한 대상체 압축 센싱 데이터를 모사하는데 이 용된다. 학습용 압축 센싱 데이터는 기본적으로 도 6에 도시된 복수개의 데이터 각각에 누락된 라인 데이터가 존재하는 것이라 할 수 있다. 대상체 압축 센싱 데이터 대상체 압축 센싱 데이터는 실제 촬영하고자 하는 대상체로부터 얻어진 데이터로 풀 데이터에 비해 일부 라인 데이터가 부족한 데이터이다. 즉, 환자의 장기를 압축 센싱에 의해 촬영하여 얻어진 데이터이다. 즉, 대상체 압축 센싱 데이터는 촬영하고자 하는 대상체로부터 획득한 데이터로, 도 6에 도시된 복수개의 데이 터 각각에 누락된 라인 데이터가 존재하는 것이라 할 수 있다. 다시 도 1을 참조하면, 기준 영상 생성부는 학습용 풀 데이터로부터 학습용 기준 영상을 생성한다. 구체적 으로는, 기준 영상 생성부는 학습용 풀 데이터를 2차원 푸리에 변환(2D Fast Fourier Transform: 2D FF T)하여 학습용 기준 영상을 생성한다. 학습용 기준 영상은 심층 인공 신경망을 학습시키는데 사용되는 영상으로 누락된 데이터가 없어 상대적으 로 우수한 화질을 가진다. 초기 영상 생성부는 학습용 압축 센싱 데이터와 대상체 압축 센싱 데이터로부터 학습용 초기 영상과 대상 체 초기 영상을 각각 생성한다. 학습용 압축 센싱 데이터와 대상체 압축 센싱 데이터는 풀 데이터에 비해 누락된 데이터가 존재하므로, 상대적으로 열등한 화질을 가진다. 구체적으로는, 초기 영상 생성부는 학습용 압축 센싱 데이터를 학습용 초기 영상으로 변환한다. 또한, 초 기 영상 생성부는 대상체 압축 센싱 데이터로부터 대상체 초기 영상을 각각 생성한다. 이를 위해 초기 영상 생성부는 도 4에 도시된 선형 보간부(130a) 및 2D FFT부(130b)를 포함한다. 선형 보간부(130a)는 학습용 압축 센싱 데이터를 선형 보간한다. 구체적으로는, 학습용 압축 센싱 데이터에서 누락된 라인 데이터를 선형 보간에 의해 보충한다. 예를 들어, 선형 보간부(130a)는 누락된 라인 데이터와 인접 한 라인 데이터를 참조하여, 선형 보간을 수행한다. 즉, 학습용 압축 센싱 데이터는 선형 보간을 거치면서 누락 된 라인 데이터가 모두 채워진다. 예를 들어, 학습용 압축 센싱 데이터가 32개의 라인 데이터를 포함하면, 이를 선형 보간하여 256개의 라인 데이터를 생성한다. 2D FFT부(130b)는 보간된 학습용 압축 센싱 데이터를 2차원 푸리에 변환하여 학습용 초기 영상을 생성한다. 학 습용 압축 센싱 데이터는 주파수 도메인의 데이터이므로 이를 2차원 푸리에 변환하면, 이미지가 얻어진다. 예를 들어, 도 6에 도시된 복수의 데이터 각각을 2차원 푸리에 변환하면, 복수의 이미지가 얻어진다. 또한, 선형 보간부(130a) 및 2D FFT부(130b)는 대상체 압축 센싱 데이터에 대해서도 동일한 과정을 수행한다. 구체적으로는, 선형 보간부(130a)는 대상체 압축 센싱 데이터를 선형 보간하며, 2D FFT부(130b)는 보간된 대상 체 압축 센싱 데이터를 2차원 푸리에 변환하여 대상체 초기 영상을 생성한다. 마찬가지로, 대상체 압축 센싱 데 이터는 주파수 도메인의 데이터이므로 이를 2차원 푸리에 변환하면, 이미지가 얻어진다. 영상 처리부는 기준 영상 생성부와 초기 영상 생성부가 생성한 영상을 처리하여 심층 인공 신경 망에 제공한다. 구체적으로는, 영상 처리부는 t-y 평면 생성부(140b), 정규화/역정규화부(140c) 및 오차 영상 생성부 (140a)를 포함한다. 오차 영상 생성부(140a)는 학습용 기준 영상과 학습용 초기 영상의 차이인 학습용 오차 영상을 생성하여 t-y 평 면 생성부(140b)에 전송한다. 즉, 오차 영상 생성부(140a)는 학습용 오차 영상(=[학습용 기준 영상]-[학습용 초 기 영상])을 생성하여 t-y 평면 생성부(140b)에 제공한다. t-y 평면 생성부(140b)는 각 x 값 및 z 값에 대해 학습용 초기 영상 및 학습용 오차 영상을 슬라이싱하여 각각 제1 학습용 t-y 평면 영상 및 제2 학습용 t-y 평면 영상을 생성한다. 이하에서는, 도 8 내지 도 10를 참조하여 이에 대해 상세히 설명한다. 도 8은 도 6에 도시된 복수의 데이터를 이미지로 변환한 도면이며, 도 9는 도 8의 이미지 중 소정의 z 값에 대 한 이미지를 시간(t)에 따라 나열한 도면이다. 도 6에 도시된 복수의 데이터는 기준 영상 생성부 또는 초기 영상 생성부에 의해 1:1로 도 8에 도시 된 이미지로 변환된다. 구체적으로는, 학습용 풀 데이터는 기준 영상 생성부에 의해 학습용 기준 영상으로 변환되며, 학습용 압축 센싱 데이터와 대상체 압축 센싱 데이터는 초기 영상 생성부에 의해 각각 학습용 초기 영상과 대상체 초기 영상으로 변환된다. 설명의 편의를 위하여, 도 9는 z=z0에서의 이미지 16개를 시간(t)에 따라 나열한 것으로 하고, 각 이미지는 256 개의 라인(x0 내지 x255)로 구성되는 것으로 한다. 학습용 기준 영상, 학습용 초기 영상 및 대상체 초기 영상은 모두 도 9에 도시된 형태로 처리된다. t-y 평면 생성부(140b)는 학습용 초기 영상의 모든 z 단면의 모든 x에 대해 학습용 초기 영상을 슬라이싱하여 제1 학습용 t-y 평면 영상을 생성한다. 예를 들면, t-y 평면 생성부(140b)는 도 9에 도시된 영상(여기서는 학습 용 초기 영상)을 도 10과 같이 x0, x1, x2, ···, x253, x254, x255에 대해 슬라이싱한다. 또한, t-y 평면 생성부 (140b)는 학습용 초기 영상의 다른 z 단면(z=z1, z2, z3, ···, z9, z10, z11)과 각 z 단면의 모든 x 값에 대해 도 10과 같이 학습용 초기 영상을 슬라이싱한다. 모든 z 단면의 모든 x에 대해 학습용 초기 영상을 슬라이싱하 면, 제1 학습용 t-y 평면 영상이 얻어진다. 또한, t-y 평면 생성부(140b)는 학습용 오차 영상의 모든 z 단면의 모든 x에 대해 학습용 오차 영상을 슬라이싱 하여 제2 학습용 t-y 평면 영상을 생성한다. 예를 들면, t-y 평면 생성부(140b)는 도 9에 도시된 영상(여기서는 학습용 오차 영상)을 도 10과 같이 x0, x1, x2, ···, x253, x254, x255에 대해 슬라이싱한다. 또한, t-y 평면 생성부(140b)는 학습용 오차 영상의 다른 z 단면(z=z1, z2, z3, ···, z9, z10, z11)과 각 z 단면의 모든 x 값에 대해 도 10과 같이 학습용 오차 영상을 슬라이싱한다. 모든 z 단면의 모든 x에 대해 학습용 오차 영상을 슬라이 싱하면, 제2 학습용 t-y 평면 영상이 얻어진다. 또한, t-y 평면 생성부(140b)는 대상체 초기 영상의 모든 z 단면의 모든 x에 대해 대상체 초기 영상을 슬라이싱 하여 제1 대상체 t-y 평면 영상을 생성한다. 예를 들면, t-y 평면 생성부(140b)는 도 9에 도시된 영상(여기서는 대상체 초기 영상)을 도 10과 같이 x0, x1, x2, ···, x253, x254, x255에 대해 슬라이싱한다. 또한, t-y 평면 생 성부(140b)는 대상체 초기 영상의 다른 z 단면(z=z1, z2, z3, ···, z253, z254, z255)과 각 z 단면의 모든 x 값 에 대해 도 10과 같이 대상체 초기 영상을 슬라이싱한다. 모든 z 단면의 모든 x에 대해 대상체 초기 영상을 슬 라이싱하면, 제1 대상체 t-y 평면 영상이 얻어진다. 정규화/역정규화부(140c)는 제1 학습용 t-y 평면 영상, 제2 학습용 t-y 평면 영상 및 제1 대상체 t-y 평면 영상 을 각각 정규화하여 심층 인공 신경망에 제공한다(이에 대해서는 후술한다). 또한, 정규화/역정규화부(140c)는 심층 인공 신경망이 생성한 추정된 오차 t-y 평면 영상을 역정규화하여 오차 영상 생성부(140a)에 전송한다(이에 대해서는 후술한다). 오차 영상 생성부(140a)는 정규화/역정규화부(140c)가 역정규화한 추정된 제2 대상체 t-y 평면 영상으로부터 대 상체 오차 영상을 생성한다. 대상체 영상 생성부는 대상체 초기 영상과 심층 인공 신경망으로부터 수신한 대상체 오차 영상으로부 터 대상체 영상을 생성한다. 구체적으로는, 대상체 영상 생성부는 대상체 오차 영상과 대상체 초기 영상을 합산하여 대상체 영상을 생성한다. 심층 인공 신경망은 U-Net인 것이 바람직하다. 예를 들어, 본 발명에 따르면, 심층 인공 신경망은 비 특허문헌 2에서 개시된 U-Net을 변형한 형태이다. U-Net은 여러 계층의 컨볼루션 신경망 (Convolutional Neural Network: CNN)으로 구성되고, 전체적인 모양이 'U' 형상이다. t-y 평면을 생성하는 이유는 심층 인공 신경망에 의해 공간 해상도(y 축)와 시간 해상도(t 축)를 개선할 수 있기 때문이다. 즉, x-y 평면을 이용하는 종래 기술인 비특허 문헌 2의 영상 단면 (x-y 평면) 심층 신경망은 시간 축이 배제됨으로써 시간 해상도(y)의 개선에 한계를 보인다. 학습용 초기 영상과 학습용 오차 영상으로 심층 인공 신경망을 학습시키는 이유는 다음과 같다. 먼저, 본 발명의 최종 목표는 심층 인공 신경망에 압축 센싱된 데이터만 제공하더라도 풀 데이터에 가장 근접한 결과를 얻는 것이다. 즉, 누락된 데이터를 보간하여 얻어진 영상을 심층 인공 신경망에 제공하면. 심층 인공 신경망이 학습된 내용을 이용하여 풀 데이터로부터 생성된 영상에 근접한 영상을 출력하는 것이다. 특히 대상체인 환자로부터는 압축 센싱 데이터만 획득할 수 있으므로 환자로부터 실제로 얻어지는 영상은 누락 된 데이터를 보간하여 얻어진 영상뿐이다. 즉, 심층 인공 신경망에는 누락된 데이터를 보간하여 얻어진 영 상만 제공할 수 있다. 따라서, 최상의 결과를 얻기 위해서는 실제 적용되는 데이터를 모사하여 심층 인공 신경 망을 학습시켜야 한다. 즉, 압축 센싱 데이터로부터 풀 데이터를 얻는 방식으로 심층 인공 신경망을 학습시켜야 한다. 따라서, 본 발명에서는 학습용 데이터로서 풀 데이터와, 이 풀 데이터로부터 추출한 압축 센싱 데이터를 이용한 다. 구체적으로는, 대상체 압축 센싱 데이터를 모사하기 위해 학습용 풀 데이터(=학습용 기준 영상)의 일부를 제거하고 이를 선형 보간하여 학습용 압축 센싱 데이터(=학습용 초기 영상)를 생성한다. 심층 인공 신경망의 학습에는 학습용 초기 영상과 학습용 오차 영상(=학습용 기준 영상-학습용 초기 영 상)을 이용한다. 여기서, 학습용 오차 영상을 이용하는 이유는 심층 인공 신경망에 학습용 초기 영상과 학 습용 오차 영상을 제공하여 학습시키는 것이 학습용 초기 영상과 학습용 기준 영상을 제공하여 학습시키는 것보 다 보다 나은 결과를 보여 주기 때문이다. 즉, 심층 인공 신경망을 학습용 초기 영상과 학습용 오차 영상 으로 학습시키고, 심층 인공 신경망에 대상체 초기 영상을 제공하여 대상체 오차 영상을 얻는 것이 가장 우수한 결과를 보여주기 때문이다. 심층 인공 신경망을 학습용 초기 영상과 학습용 기준 영상으로 학습시 키면 심층 인공 신경망은 학습용 기준 영상에 대응되는 대상체 영상을 출력한다. 그런데, 이러한 경우보다 심층 인공 신경망을 학습용 초기 영상과 학습용 오차 영상으로 학습시키고 심층 인공 신경망이 학습용 오차 영상에 대응되는 대상체 오차 영상을 출력하는 경우가 더 우수한 결과를 보여준다. 대상체 오차 영상만 획득하면 대상체 영상은 대상체 초기 영상으로부터 용이하게 획득할 수 있으므로, 심층 인공 신경망이 대 상체 오차 영상을 출력하는 방법을 채택하였다. 이하에서는, 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법에 대해 도 11 내지 도 16을 참조하여 상세히 설명한다. 도 11은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법을 도시한 흐름도이다. 도 11을 참조하면, 도 1 및 도 2에 도시된 영상 데이터 생성부를 통해 학습용 풀 데이터 및 학습용 압축 센싱 데이터를 생성한다(S100). 학습용 풀 데이터와 학습용 압축 센싱 데이터를 생성하는 방법은 상술하였으므 로 이에 대한 설명은 생략한다. 다음에는, 도 1에 도시된 기준 영상 생성부를 통해 학습용 풀 데이터로부터 학습용 기준 영상을 생성한다 (S200). 학습용 풀 데이터로부터 학습용 기준 영상을 생성하는 방법은 상술하였으므로 이에 대한 설명은 생략한 다. 다음에는, 도 1에 도시된 초기 영상 생성부를 통해 학습용 압축 센싱 데이터로부터 학습용 초기 영상을 생 성한다(S300). 학습용 압축 센싱 데이터로부터 학습용 초기 영상을 생성하는 방법을 도 12을 참조하여 상세히 설명한다. 먼저, 도 4에 도시된 선형 보간부(S130a)를 통해 학습용 압축 센싱 데이터를 선형 보간한다(S310). 학습용 풀 데이터로부터 학습용 압축 센싱 데이터를 생성하고, 이를 다시 보간하는 이유는 학습에 필요한 데이터 또는 영 상을 생성하는 과정을 대상체 초기 영상을 생성하는 과정과 동일하게 하기 위함이다. 환언하면, 대상체 초기 영 상이 생성되는 방식과 학습에 필요한 데이터 또는 영상이 생성되는 방식이 동일해야 심층 인공 신경망으로부터 정확한 추정 영상을 얻을 수 있기 때문이다. 다음에는, 도 4에 도시된 2D FFT부(130b)를 통해 보간된 학습용 압축 센싱 데이터를 2차원 푸리에 변환하여 학 습용 초기 영상을 생성한다(S320). 다시 도 11을 참조하면, 도 1의 오차 영상 생성부(S140c)를 통해, S200 단계에서 생성한 학습용 기준 영상과 S300 단계에서 생성한 학습용 초기 영상의 차이인 학습용 오차 영상을 생성한다(S400). 즉, 학습용 오차 영상은 학습용 기준 영상에서 학습용 초기 영상을 뺀 차이다. 다음에는, 학습용 초기 영상을 슬라이싱하여 얻어진 제1 학습용 t-y 평면 영상과 학습용 오차 영상을 슬라이싱 하여 얻어진 제2 학습용 t-y 평면 영상으로 심층 인공 신경망을 학습시킨다(S500). 이하에서는, 도 13을 참조하여, S500 단계에 대해 상세히 설명한다. 도 13은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법의 S500 단계를 도시한 흐름도이 다. 학습용 기준 영상, 학습용 초기 영상 및 학습용 오차 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시된다. 여기에 서 주파수 부호를 x축 경사자장 코일에, 위상 부호를 y축 경사자장 코일에, 단면 선택을 z축 경사자장 코일에 인가하였다고 가정한다. t는 시간을 나타낸다. 즉, t는 심장 박동에 따른 심장의 움직임을 의미한다고 할 수 있 다. 도 13을 참조하면, 먼저, x와 z를 고정(예를 들면, x=x0, z=z0)하고, 학습용 초기 영상을 t-y 평면에 대해 슬라 이싱하여 도 10에 도시된 x0에 대한 학습용 t-y 평면 초기 영상을 생성한다(S510).즉, x=x0일 때 z=z0 단면의 학 습용 초기 영상을 슬라이싱하여 학습용 t-y 평면 초기 영상을 생성한다. 다음에는, S510 단계와 마찬가지로, x=x0일 때 z=z0 단면의 학습용 오차 영상을 슬라이싱하여 학습용 t-y 평면 오차 영상을 생성한다(S520). 다음에는, S510 단계에서 생성된 학습용 t-y 평면 초기 영상과 S520 단계에서 생성된 학습용 t-y 평면 오차 영 상을 각각 정규화한다(S530). 구체적으로는, 도 14에 도시된 바와 같이, 도 1의 정규화/역정규화부(140c)는 학 습용 초기 영상을 슬라이싱하여 얻어진 학습용 t-y 평면 초기 영상을 아래의 수학식 1에 따라 정규화 한다 (S530a).수학식 1"}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 도 1에 도시된 정규화/역정규화부(140c)는 학습용 t-y 평면 오차 영상을 수학식 2에 따라 정규화한다 (S530b). 수학식 2"}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, I(x0, y, z0, t)는 상기 학습용 초기 영상을 슬라이싱하여 얻어진 상기 학습용 t-y 평면 초기 영상, E(x0, y, z0, t)는 상기 학습용 오차 영상을 슬라이싱하여 얻어진 학습용 t-y 평면 오차 영상, i(x0, y, z0, t) 및 e(x0, y, z0, t)는 각각 정규화된 학습용 t-y 평면 초기 영상 및 학습용 t-y 평면 오차 영상, MAX는 상기 학습용 초기 영상의 최대값을 나타낸다. 다음에는, 각 x 값에 대해 S510 단계 내지 S530 단계를 반복한다(S540). 예를 들어, x=x0일 때 z=z0 단면에 대 해 S510 내지 S530 단계를 수행한 것과 마찬가지로, z를 고정(예를 들면, z=z0)하고 x=x1, x2, ···, x253, x254, x255에 대해 S510 내지 S530 단계를 수행한다. 즉, z=z0 단면에서 모든 x 값에 대해 S510 내지 S530 단계를 수행한다. 여기서, 수학식 1 및 수학식 2의 x0 대신 x=x1, x2, ···, x253, x254, x255이다. S540 단계를 수행하면, z=z0 단면에 대해 x=x0, x1, x2, ···, x253, x254, x255에서의 학습용 t-y 평면 초기 영 상 및 학습용 t-y 평면 오차 영상이 얻어진다(도 10 참조). 다음에는, 각 z 값에 대해 S510 단계 내지 S540 단계를 반복한다(S550). 예를 들어, z=z1로 고정하고 x=x1, x2, ···, x253, x254, x255에 대해 S510 내지 S530 단계를 수행하고, z=z2로 고정하고 x=x1, x2, ···, x253, x254, x255에 대해 S510 내지 S530 단계를 수행하고, z=z3로 고정하고 x=x1, x2, ···, x253, x254, x255에 대해 S510 내 지 S530 단계를 수행한다. 즉, 여기서, 수학식 1 및 수학식 2의 z0 대신 z=z1, z2, ···, z10, z11이다. S550 단계를 수행하면, 각 z 값에 대해 도 10에 도시된 학습용 t-y 평면 초기 영상 및 학습용 t-y 평면 오차 영 상이 얻어진다. 도 10의 예에 따르면, z0 내지 z11 각각에 대해 256개의 학습용 t-y 평면 초기 영상 및 학습용 t-y 평면 오차 영상이 각각 얻어진다. 이하에서는, 학습용 t-y 평면 초기 영상을 슬라이싱 및 정규화하여 얻어 진 복수의 t-y 평면 영상을 제1 학습용 t-y 평면 영상이라 하고, 학습용 t-y 평면 오차 영상을 슬라이싱 및 정 규화하여 얻어진 복수의 t-y 평면 영상을 제2 학습용 t-y 평면 영상이라 한다. 다음에는, 도 13에 도시된 바와 같이, S550 단계에서 얻어진 제1 학습용 t-y 평면 영상과 제2 학습용 t-y 평면 영상으로 도 1에 도시된 심층 인공 신경망을 학습시킨다(S560). 즉 , 제1 학습용 t-y 평면 영상과 제2 학 습용 t-y 평면 영상은 각각 입력과 타겟으로 심층 인공 신경망에 제공된다. 여기서, \"타겟\"은 \"입력\"에 대해 심 층 인경 신경망이 목표하는 출력이다. 여기서, 심층 인공 신경망의 학습은 비특허문헌 1 에 제시된 텐서 플로우 기반의 케라스를 이용할 수 있다. 학 습에 사용된 프로그램이나 가중치 조절 방법은 비특허 문헌 1에 기술되어 있으므로 상세한 설명은 생략한다. 다시 도 11을 참조하면, 도 1 및 도 2에 도시된 영상 데이터 생성부를 구동하여 대상체 압축 센싱 데이터 를 생성한다(S600). 대상체 압축 센싱 데이터를 생성하는 방법은 상술하였으므로 이에 대한 설명은 생략한다. 다음에는, S600 단계에서 획득한 대상체 압축 센싱 데이터로부터 대상체 초기 영상을 생성한다(S700). 대상체 압축 센싱 데이터로부터 대상체 초기 영상을 생성하는 방법을 도 15을 참조하여 상세히 설명한다. 도 15를 참조하면, 먼저, 도 4에 도시된 선형 보간부(S130a)를 통해 대상체 압축 센싱 데이터를 선형 보간한다 (S710). 다음에는, 도 4에 도시된 2D FFT부(130b)를 통해 보간된 학습용 압축 센싱 데이터를 2차원 푸리에 변환하여 대 상체 초기 영상을 생성한다(S720). 다시 도 11을 참조하면, 다음에는, S500 단계에서 학습된 심층 인공 신경망을 이용하여 대상체 오차 영상을 생 성한다(S800). 이하에서는, S800 단계를 도 16을 참조하여 상세히 설명한다. 먼저, 대상체 초기 영상은 각각 (x,y,z,t)의 사차원 좌표로 표시된다. 여기에서 주파수 부호를 x축 경사자장 코 일에, 위상 부호를 y축 경사자장 코일에, 단면 선택을 z축 경사자장 코일에 인가하였다고 가정한다. t는 시간을 나타낸다. 즉, t는 심장 박동에 따른 심장의 움직임을 의미한다고 할 수 있다. 도 16은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법의 S800 단계를 도시한 흐름도이 다. 도 16을 참조하면, 먼저, x와 z를 고정(예를 들면, x=x0, z=z0)하고, 대상체 초기 영상을 t-y 평면에 대해 슬라 이싱하여 도 10에 도시된 x0에 대한 대상체 t-y 평면 영상을 생성한다(S810).즉, x=x0일 때 z=z0 단면의 대상체 초기 영상을 슬라이싱하여 대상체 t-y 평면 영상을 생성한다 다음에는, 도 1에 도시된 정규화/역정규화부(140c)가 S810 단계에서 생성된 대상체 t-y 평면 영상을 아래의 수 학식 3에 따라 정규화 한다(S820). 수학식 3"}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, I(x0, y, z0, t)는 상기 대상체 t-y 평면 영상, i(x0, y, z0, t)는 정규화된 대상체 t-y 평면 영상, MAX는 상기 대상체 초기 영상의 최대값을 나타낸다. 다음에는, 각 x 값에 대해 S810 단계 및 S820 단계를 반복한다(S730). 예를 들어, x=x0일 때 z=z0 단면에 대해 S810 단계 및 S820 단계를 수행한 것과 마찬가지로, z를 고정(예를 들면, z=z0)하고 x=x1, x2, ···, x253, x254, x255에 대해 S810 단계 및 S820 단계를 수행한다. 즉, z=z0 단면에서 모든 x 값에 대해 S810 단계 및 S820 단계를 수행한다. 여기서, 수학식 1 및 수학식 2의 x0 대신 x=x1, x2, ···, x253, x254, x255이다. S830 단계를 수행하면, z=z0 단면에 대해 x=x0, x1, x2, ···, x253, x254, x255에서의 대상체 t-y 평면 영상이 얻어진다(도 10 참조). 다음에는, 각 z 값에 대해 S810 단계 내지 S830 단계를 반복한다(S840). 예를 들어, z=z1로 고정하고 x=x1, x2, ···, x253, x254, x255에 대해 S810 단계 및 S820 단계를 수행하고, z=z2로 고정하고 x=x1, x2, ···, x253, x254, x255에 대해 S810 단계 및 S820 단계를 수행하고, z=z3로 고정하고 x=x1, x2, ···, x253, x254, x255에 대해 S810 단계 및 S820 단계를 수행한다. 즉, 수학식 1 및 수학식 2의 z0 대신 z=z1, z2, ···, z10, z11이다. S840 단계를 수행하면, 각 z 값에 대해 도 10에 도시된 대상체 t-y 평면 영상이 얻어진다. 도 10의 예에 따르면, z0 내지 z11 각각에 대해 256개의 대상체 t-y 평면 영상이 각각 얻어진다. 이하에서는, 모든 x 값 및 모 든 z 값에 대해 대상체 t-y 평면 영상을 슬라이싱 및 정규화하여 얻어진 복수의 t-y 평면 영상을 제1 대상체 t- y 평면 영상이라 한다. 다음에는, 제1 대상체 t-y 평면 영상을 도 1에 도시된 심층 인공 신경망에 제공하여 제2 대상체 t-y 평면 영상을 생성한다(S850). 즉, 심층 인공 신경망은 정규화된 제1 대상체 t-y 평면 영상이 입력되면, 학습된 내용 (예를 들면, 가중치)에 따라 제2 대상체 t-y 평면 영상을 생성한다.심층 인공 신경망에 입력된 제1 대상체 t-y 평면 영상은 도 10에 도시된 각 z 값에 따른 영상이다(예를 들 어, z0, z1, ···, z10, z11에 대해 x=x0, x1, ···, x254, x255에서의 영상). 따라서, 출력되는 제2 대상체 t- y 평면 영상도 동일한 형태이다. 또한, 심층 인공 신경망은 학습용 기준 영상을 슬라이싱하여 얻어진 제1 학습용 t-y 평면 영상과 학습용 오차 영상을 슬라이싱하여 얻어진 제2 학습용 t-y 평면 영상을 각각 입력과 타겟으로 하여 학습되었으므로, 심 층 인공 신경망이 출력하는 제2 대상체 t-y 평면 영상은 추정된 오차 영상에 해당된다. 다음에는, 제2 대상체 t-y 평면 영상을 아래의 수학식 4에 따라 역정규화한다(S860). S850 단계에서 심층 인공 신경망에 입력되는 제1 대상체 t-y 평면 영상은 정규화된 영상이므로 심층 인공 신경망으로부터 출력 되는 제2 대상체 t-y 평면 영상도 정규화된 영상이다. 따라서, 도 1에 도시된 정규화/역정규화부(140c)는 아래 의 수학식 4에 따라 이를 역정규화한다. 수학식 4"}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, e(x, y, z, t)는 제2 대상체 t-y 평면 영상, 는 역정규화된 제2 대상체 t-y 평면 영상, MAX는 상기 학습용 초기 영상의 최대값을 나타낸다. 모든 z 값 및 모든 x 값에 대해 제2 대상체 t-y 평면 영상을 역정규화하면 도 8에 도시된 형태의 대상체 오차 영상이 얻어진다. 다시 도 11을 참조하면, 대상체 오차 영상과 대상체 초기 영상으로부터 대상체 영상을 생성한다(S900). 구체적 으로는, 대상체 오차 영상과 대상체 초기 영상을 합산하여 추정 대상체 영상을 생성한다. 오차 영상은 초기 영상과 기준 영창의 차이이므로 오차 영상과 초기 영상을 합산하면 기준 영상이 된다. 따라서, 대상체 오차 영상과 대상체 초기 영상을 합산하면 기준 영상에 대응되는 추정된 대상체 영상을 얻을 수 있다. 추정된 대상체 영상은 누락된 데이터가 없는 풀 데이터에 대응하는 영상이다. 본 발명에 따른 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법의 성능을 아래와 같이 검증하였다. 먼저, 본 발명에 따른 자기 공명 영상 생성 시스템 및 자기 공명 영상 생성 방법의 성능을 검증하기 위하여 다 음과 같이 테스트 데이터를 구성하였다. 피험자 #1 ~ 피험자 #4로부터 획득한 풀 데이터 및 학습용 압축 센싱 데이터로부터 상술한 방법에 따라 학 습용 기준 영상과 학습용 초기 영상을 생성하였다. 피험자 #5 ~ 피험자 #8로부터 획득한 풀 데이터 및 테스트용 압축 센싱 데이터로부터 상술한 방법에 따라 테스트용 기준 영상과 테스트용 초기 영상을 생성하였다. 압축비에 따른 성능을 검증하기 위하여 압축비를 각각 2, 3, 4로 설정하였다. 테스트 데이터에 대해 선형 보간만 하는 경우, x-y 평면에 대해 본 발명에 따른 방법을 적용한 경우, t-y 평면에 대해 본 발명에 따른 방법을 적용한 경우를 각각 검증하였다. 정량적인 평가를 위하여 아래의 수학식 5로 표시되는 정규화 평균 제곱 오차(Normalized Mean Square Error: NMSE)를 구하였다. 수학식 5"}
{"patent_id": "10-2020-0008807", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기에서 는 본 발명에 따라 얻어진 추정된 테스트용 영상이며, 는 테스트용 기준 영상이다. 수학식 5의 대괄호는 테스트에 참여한 피험자의 평균 제곱 오차를 나타내고, 이들의 산술 평균을 전체 테스트 데이터의 평균 제곱 오차로 정의하였다. Nsub는 테스트에 참여한 지원자 수이며, 본 테스트 데이터에서는 Nsub=4 (피험자 #5 ~ 피험자 #8)이다. 표 1 영상 추정 방법 압축비=2 압축비=3 압축비=4 선형 보간 2.00 3.34 4.35 x-y 평면(심층 인공 신경망) 1.89 3.03 3.93 t-y 평면(심층 인공 신경망 1.63 2.59 3.30 [단위:10-3] 표 1에서 알 수 있는 바와 같이, 심층 인공 신경망을 사용한 영상 재구성 방법들이 선형 보간보다 훨씬 낮은 평 균 제곱 오차를 보인다. 특히, 본 발명에 따른 t-y 평면을 이용하는 경우, 압축비 2, 3, 4에 대해서 선형 보간 보다 22% 이상 낮은 평균 제곱 오차를 보이고, x-y 평면을 이용하는 경우보다 15% 이상 낮은 평균 제곱 오차를 보인다. 도 17은 압축비가 4일 때 다양한 영상 추정 방법에 의해 재구성한 영상에 포함된 이미지이다. (a)는 풀 데이터 로부터 얻어진 이미지, (b)는 선형 보간하여 얻어진 이미지, (c)는 x-y 평면으로 학습된 심층 신경망으로 재구 성한 이미지, (d)는 t-y 평면으로 학습된 심층 신경망으로 재구성한 이미지이다. 각 이미지 아래에는 풀 데이터 로부터 얻어진 이미지와의 차이를 도시하였다. 도 17에서 알 수 있는 바와 같이, t-y 평면으로 학습된 심층 신경망으로 재구성한 이미지인 (d)는 다른 재구성 방법으로 얻은 이미지에 비해 공간 해상도나 시간 해상도가 우수하고 (a)에 근접함을 알 수 있다. 특히, (d)의 오차가 가장 작다는 것을 알 수 있다."}
{"patent_id": "10-2020-0008807", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 시스템을 도시한 블록도. 도 2는 본 발명에 따른 영상 데이터 생성부를 도시한 블록도. 도 3은 영상 데이터 생성부가 자기 공명 신호를 획득하기 위하여 사용하는 펄스 시퀀스를 도시한 도면. 도 4는 본 발명에 따른 초기 영상 생성부를 도시한 블록도. 도 5는 촬영 대상체를 개략적으로 도시한 도면. 도 6은 대상체를 촬영하여 얻어진 데이터를 시간에 따라 개략적으로 도시한 도면. 도 7a는 풀 샘플링된 데이터를 개략적으로 도시한 도면. 도 7b는 언더 샘플링된 데이터를 개략적으로 도시한 도면. 도 7c는 도 7b의 언더 샘플링된 데이터를 보간하여 얻어진 데이터를 개략적으로 도시한 도면. 도 8은 도 6에 도시된 복수의 데이터를 이미지로 변환한 도면. 도 9는 도 8의 이미지 중 z=z0에서의 이미지를 시간(t)에 따라 나열한 도면.도 10은 슬라이싱된 t-y 평면을 도시한 도면. 도 11은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법을 도시한 흐름도. 도 12는 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법의 S300 단계를 도시한 흐름도. 도 13은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법의 S500 단계를 도시한 흐름도. 도 14는 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법의 S530 단계를 도시한 흐름도. 도 15는 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법의 S700 단계를 도시한 흐름도. 도 16은 본 발명에 따른 심층 인공 신경망을 이용한 자기 공명 영상 생성 방법의 S800 단계를 도시한 흐름도. 도 17은 압축비가 4일 때 추정된 영상을 비교한 도면."}
