{"patent_id": "10-2021-0053988", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0143105", "출원번호": "10-2021-0053988", "발명의 명칭": "비디오 컨텐츠로부터 음악 데이터를 검출하는 장치 및 그의 제어방법", "출원인": "주식회사 코클리어닷에이아이", "발명자": "한윤창"}}
{"patent_id": "10-2021-0053988", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오 스트림과 오디오 스트림을 포함하는 비디오 컨텐츠를 입력받는 단계;상기 오디오 스트림으로부터 음악 데이터를 검출하는 단계; 및상기 오디오 스트림에서 검출된 상기 음악 데이터가 제거되도록, 상기 오디오 스트림을 필터링하는 단계;를 포함하고,상기 오디오 스트림으로부터 음악 데이터를 검출하는 단계는,상기 오디오 스트림을 음악 데이터와 음성 데이터로 분리하기 위한 분리과정과, 상기 오디오 스트림으로부터 음악 데이터가 존재하는 구간을 검출하기 위한 검출과정을 포함하며,상기 분리과정은 미리 학습된 제1 인공지능 모델에 의해 수행되고,상기 제1 인공지능 모델은,딥러닝 또는 머신 러닝을 수행하는 인공신경망으로 구성되어, 음악(music) 또는 음성(voice)으로 식별된 트레이닝 데이터를 이용하여 학습을 수행하고,학습결과에 근거하여 상기 오디오 스트림의 미리 설정된 단위 구간마다 음악 데이터에 해당될 확률과, 음성 데이터에 해당될 확률을 출력하는 것을 특징으로 하는 데이터 처리 방법."}
{"patent_id": "10-2021-0053988", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 검출과정은 미리 학습된 제2 인공지능 모델에 의해 수행되고,상기 제2 인공지능 모델은,음악의 포함 여부가 미리 식별된 트레이닝 데이터를 이용하여 학습하도록 구성된 것을 특징으로 하는 데이터 처리 방법."}
{"patent_id": "10-2021-0053988", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 오디오 스트림을 필터링하는 단계는,미리 저장된 저작물 데이터베이스를 이용하여, 검출된 상기 음악 데이터가 저작물인지 여부를 판단하는 과정과,검출된 상기 음악 데이터의 저작물 여부에 따라, 상기 오디오 스트림을 필터링하는 과정을 포함하는 것을 특징으로 하는 데이터 처리 방법."}
{"patent_id": "10-2021-0053988", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,검출된 상기 음악 데이터를, 상기 음악 데이터와 다른 대체음악 데이터로 변경하는 단계를 더 포함하는 것을 특징으로 하는 데이터 처리 방법.공개특허 10-2021-0143105-3-"}
{"patent_id": "10-2021-0053988", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 데이터 처리 방법은, 비디오 스트림과 오디오 스트림을 포함하는 비디오 컨텐츠를 입력받는 단계 와, 상기 오디오 스트림으로부터 음악 데이터를 검출하는 단계 및 상기 오디오 스트림에서 검출된 상기 음악 데 이터가 제거되도록, 상기 오디오 스트림을 필터링하는 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0053988", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음악과 음성이 혼합된 오디오 데이터의 처리 방법에 관한 것이다."}
{"patent_id": "10-2021-0053988", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음원 분리 기술은 다양한 소리로 구성된 오디오 스트림을 특정한 기준에 따라 복수의 오디오 데이터로 구분하는 것이다. 예를 들어, 음원 분리 기술은 스테레오 음악에서 가수의 목소리만을 추출하거나, 하나의 마이크로 녹음 된 둘 이상의 오디오 신호를 각각 분리하기 위해 사용될 수 있다. 또한, 차량, 휴대폰 등의 소음 제거에도 이용 될 수 있다. 최근, 음원 분리 기술에 인공 지능을 도입하는 방법들이 소개되고 있다. 대표적으로, 사전에 트레이닝 된 음성, 잡음 패턴이나 통계적인 데이터 정보를 이용하여 음성을 분리를 수행하는 방식이 있다. 이러한 방식은 급격히 변화하는 잡음 환경에서도 음성 분리가 가능할 수 있다. 한편, 비디오 컨텐츠 시장이 성장하면서, 비디오 컨텐츠에 포함된 데이터의 저작권과 관련된 문제점이 야기되고 있다. 특히, 비디오 컨텐츠에 저작권자의 허락을 받지 않은 음악이 포함되어 있는 경우, 해당 비디오 컨텐츠의 유통이 제한되는 문제가 발생함에 따라, 비디오 컨텐츠에서 저작물 데이터를 분리시키는 요구가 증가하고 있다. 즉, 비디오 컨텐츠에 저작물 데이터가 포함되어 있는지 여부를 확인하거나, 저작물 데이터를 원본 비디오 컨텐 츠로부터 분리 또는 제거하거나, 해당 저작물 데이터를 라이센스-프리 데이터로 변경하는 작업이 필요한 실정이 다. 하지만 종래의 영상 편집 과정에 따르면, 위와 같은 작업들을 편집자가 직접 비디오를 플레이하면서 확인해야하 는 번거로움이 있다. 최근 동영상 플랫폼에서 처리되는 데이터의 양을 고려할 때, 사용자가 수동으로 저작물 데 이터를 검열하는 종래의 방법으로는 충분한 양의 비디오 컨텐츠를 검열하기 어려운 문제점이 발생한다."}
{"patent_id": "10-2021-0053988", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 기술적 과제는, 임의의 오디오 스트림으로부터 음악 데이터를 추출할 수 있는 데이터 처리장치 및 그 의 제어방법을 제공하는 것이다. 또한, 본 발명의 기술적 과제는, 별도의 레이블(label)이나, 오디오 데이터의 구분을 나타내는 태그 또는 로그 정보를 포함하지 않는 임의의 오디오 스트림으로부터, 인공지능 모델을 이용하여 음악 데이터의 존재 여부를 판 단할 수 있는 데이터 처리장치 및 그의 제어방법을 제공하는 것이다. 또한, 본 발명의 기술적 과제는, 오디오 스트림과 비디오 스트림으로 구성되는 비디오 컨텐츠의 원본 파일로부 터, 음악 데이터를 검출하고, 검출된 음악 데이터를 원본 파일로부터 제거할 수 있는 데이터 처리장치 및 그의 제어방법을 제공하는 것이다. 또한, 본 발명의 기술적 과제는, 인공지능 모델을 이용하여 오디오 스트림 내에 음악 데이터의 존재 여부와, 음 악 데이터가 존재하는 시간 영역을 검출할 수 있는 데이터 처리장치 및 그의 제어방법을 제공하는 것이다. 또한, 본 발명의 기술적 과제는, 오디오 스트림 내에 저작물에 해당하는 음악 데이터가 포함되어 있는지 여부를 판단할 수 있는 데이터 처리장치 및 그의 제어방법을 제공하는 것이다."}
{"patent_id": "10-2021-0053988", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위하여, 본 발명은 비디오 스트림과 오디오 스트림을 포함하는 비디오 컨텐츠를 입력받 는 단계; 상기 오디오 스트림으로부터 음악 데이터를 검출하는 단계; 및 상기 오디오 스트림에서 검출된 상기 음악 데이터가 제거되도록, 상기 오디오 스트림을 필터링하는 단계;를 포함하는 데이터 처리 방법을 제공한다."}
{"patent_id": "10-2021-0053988", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사용자가 비디오 컨텐츠를 직접 스캔하지 않아도, 비디오 컨텐츠 내에 포함된 음악 데이터를 검출할 수 있으므로, 비디오 컨텐츠 편집을 수행하는 사용자의 편의를 향상시킬 수 있는 장점이 있다. 또한, 방대한 양의 비디오 컨텐츠에 대해 빠른 시간 내에 음악 데이터를 검출할 수 있으므로, 영상 편집에 소요 되는 비용을 획기적으로 감소시킬 수 있다. 아울러, 본 발명에 따르면, 데이터 처리장치가 입력된 비디오 컨텐츠에 포함된 저작물에 대응되는 음악 데이터 를 삭제하거나, 대체음악으로 치환하므로, 비디오 컨텐츠의 소유자 또는 유통자의 편의가 향상될 수 있다."}
{"patent_id": "10-2021-0053988", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 본 명세서에서 사용되는 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 명세서에 개시된 기술의 사상을 한정하려는 의 도가 아님을 유의해야 한다. 먼저, 도 1에는 본 발명에 따른 데이터 처리 방법과 관련된 개념도가 도시된다. 이하에서 비디오 컨텐츠는 오디오 스트림과 비디오 스트림을 포함하는 동영상 파일로 정의된다. 또한, 오디오 스트림은 음악 데이터 또는/및 비음악 데이터로 구성될 수 있다. 상술한 \"음악\"이라는 용어는, 리듬 (예컨대, 템포, 박자 (meter), 및 조음 (articulation)), 음높이 (pitch) (예컨대, 멜로디와 하모니), 셈여림 (dynamics) (예컨대, 사운드 또는 음표의 볼륨) 등 중 하나 이상의 엘리먼 트들에 의해 특징화될 수도 있고 악기들의 사운드들, 음성들 등을 포함할 수도 있는 임의의 유형의 사운드를 지 칭할 수도 있다. 덧붙여서, 본원에서의 \"저작물\"이란 용어가 고유한 또는 독특한 음악 저작물 (musical work) 또는 작곡물 (composition) 을 지칭할 수 있고 노래, 튠 (tune) 등과 같은 사운드 또는 오디오 형태로 이러한 음악 저작물 또는 작곡물의 창작물 또는 재현물을 포함할 수도 있다. 게다가, \"오디오 스트림\"이란 용어는 복수 의 음악 작품들, 환경 사운드들, 스피치, 잡음 등을 포함할 수도 있는 사운드 스트림의 하나 이상의 부분들을 나타내는 하나 이상의 전기적 신호들 또는 데이터의 시퀀스를 지칭할 수도 있다. 도 1을 참조하면, 본 발명에 따른 데이터 처리장치는, 비디오 컨텐츠에 포함된 오디오 스트림을 스캔하여, 상기 오디오 스트림에 음악 데이터가 포함되어있는지 여부를 판별할 수 있다. 구체적으로, 데이터 처리장치는 외부서버 또는 데이터 처리장치에 탑재된 인공지능 모델을 이용하여, 오디오 스트림에 음악 데이터가 포함되어 있는지 여부를 판별할 수 있다. 이때, 인공지능 모델은 딥 러닝 또는 머신 러닝을 수행하는 인공신경망으로 구성될 수 있다. 도 2는 본 발명의 일 실시예에 따른 데이터 처리장치를 나타내는 블록도이다. 도 2를 참조하면, 본 발명의 데이 터 처리장치는, 입력부, 출력부, 메모리, 통신부, 제어부 및 전원공급부 로 구성될 수 있다. 보다 구체적으로, 상기 구성요소들 중 통신부는, 데이터 처리장치와 무선 통신 시스템 사이, 데이터 처리장치와 다른 데이터 처리장치 사이, 또는 데이터 처리장치와 외부서버 사이의 무선 통신을 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 또한, 상기 통신부는, 데이터 처리장치를 하나 이상의 네트워크에 연결하는 하나 이상의 모듈을 포함할 수 있다. 입력부는, 영상 신호 입력을 위한 카메라 또는 영상 입력부, 오디오 신호 입력을 위한 마이크로폰 (microphone), 또는 오디오 입력부, 사용자로부터 정보를 입력받기 위한 사용자 입력부(예를 들어, 터치키 (touch key), 푸시키(mechanical key) 등)를 포함할 수 있다. 입력부에서 수집한 음성 데이터나 이미지 데이터는 분석되어 사용자의 제어명령으로 처리될 수 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이부, 음향 출력부, 햅팁 모듈, 광 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이부는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 데이터 처리장치와 사용자 사이의 입력 인터페이스를 제공하는 사용자 입력장치로써 기능함과 동시에, 데이터 처리장치와 사 용자 사이의 출력 인터페이스를 제공할 수 있다. 메모리는 데이터 처리장치의 다양한 기능을 지원하는 데이터를 저장한다. 메모리는 데이터 처리 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 데이터 처리장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 또한 이러한 응용 프로그램 중 적어도 일부는, 데이터 처리장치의 기본적인 기능(예를 들어, 전화 착신, 발신 기능, 메시지 수신, 발신 기능)을 위하여 출고 당 시부터 데이터 처리장치상에 존재할 수 있다. 한편, 응용 프로그램은, 메모리에 저장되고, 데이터 처 리장치 상에 설치되어, 제어부에 의하여 상기 전자기기 제어장치의 동작(또는 기능)을 수행하도록 구 동될 수 있다. 제어부는 상기 응용 프로그램과 관련된 동작 외에도, 통상적으로 데이터 처리장치의 전반적인 동작을 제어한다. 제어부는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리 하거나 메모리에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 또한, 제어부는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 도 2과 함께 살펴본 구성요소들 중 적어도 일부를 제어할 수 있다. 나아가, 제어부는 상기 응용 프로그램의 구동을 위하여, 데이터 처리장 치에 포함된 구성요소들 중 적어도 둘 이상을 서로 조합하여 동작시킬 수 있다. 전원공급부는 제어부의 제어 하에서, 외부의 전원, 내부의 전원을 인가받아 데이터 처리장치에 포함된 각 구성요소들에 전원을 공급한다. 이러한 전원공급부는 배터리를 포함하며, 상기 배터리는 내장형 배터리 또는 교체가능한 형태의 배터리가 될 수 있다. 상기 각 구성요소들 중 적어도 일부는, 이하에서 설명되는 다양한 실시 예들에 따른 전자기기 제어장치의 동작, 제어, 또는 제어방법을 구현하기 위하여 서로 협력하여 동작할 수 있다. 또한, 상기 전자기기 제어장치의 동작, 제어, 또는 제어방법은 상기 메모리에 저장된 적어도 하나의 응용 프로그램의 구동에 의하여 전자기기 제 어장치 상에서 구현될 수 있다. 일 예에서, 데이터 처리장치는 별도의 단말기 형태로 구현될 수도 있다. 즉, 데스트탑 컴퓨터, 디지털 TV 등의 단말기 일 수도 있으며, 이동 가능한 휴대폰, 노트북, PDA, 태블릿 PC, 노트북, 웨어러블 디바이스 등의 이동 단말기 형태로 구현될 수도 있다. 이하 도 3 및 도 4와 관련하여, 본 발명에서 제안하는 인공지능 기반의 음악 데이터 필터링 방법이 설명된다. 먼저, 입력부는 오디오 스트림 및 비디오 스트림 중 적어도 하나를 포함하는 비디오 컨텐츠와 관련된 정보 를 입력 받을 수 있다(S300). 입력부는 오디오 스트림과 관련된 정보를 입력 받을 수도 있다. 또한, 통신부는 오디오 스트림 및 비디오 스트림 중 적어도 하나를 포함하는 비디오 컨텐츠와 관련된 정보 를 외부 서버 또는 외부 단말기로부터 수신할 수 있다. 즉, 비디오 컨텐츠 또는 오디오 스트림은, 사용자에 의해 직접 업로드된 파일일 수도 있고, 외부 서버로부터 수 신한 것일 수도 있다. 제어부는 입력된 비디오 컨텐츠에 포함된 오디오 스트림으로부터 음악 데이터를 검출할 수 있다(S301). 도 4에 도시된 바와 같이, 상기 음악 데이터를 검출하는 단계(S301)는, 오디오 스트림을 음악 데이터와 음성 데이 터로 분리하는 과정(S311)과, 상기 오디오 스트림으로부터 음악 데이터가 존재하는 구간을 검출하는 과정(S32 1)을 포함할 수 있다. 구체적으로, 오디오 스트림을 음악 데이터와 음성 데이터로 분리하는 과정(S311)은, 미리 학습된 인공지능 모델 에 의해 수행될 수 있다. 즉, 제어부는 인공지능 모델을 이용하여, 입력된 오디오 스트림을 음악 데이터와 음성 데이터로 구분할 수 있다. 예를 들어 상기 인공지능 모델은, 오디오 스트림을 입력 받으며, 입력된 오디오 스트림의 미리 설정된 단위 구 간마다 음악 데이터에 해당될 확률과, 음성 데이터에 해당될 확률을 각각 출력할 수 있다. 즉, 제어부는 인공지능 모델의 출력을 이용하여, 입력된 오디오 스트림의 단위 구간마다, 상기 단위 구간의 오디오가 음악 데이터 또는 음성 데이터에 해당하는지 여부를 판별할 수 있다. 이때, 제어부는 오디오 스트림의 물리적 특성이나, 비디오 컨텐츠의 물리적 특성에 근거하여, 상기 단위 구간을 가변적으로 설정할 수 있다. 아울러, 제어부는 입력부에 인가된 사용자 입력에 근거하여, 단 위 구간을 가변적으로 설정할 수도 있다. 예를 들어, 상기 사용자 입력은 정확도, 성능 및 처리 속도 중 적어도 하나와 관련된 것일 수 있다. 다른 예에서, 상기 인공지능 모델은 입력된 오디오 스트림의 시퀀스에 따라 가변적인 에너지 분포도를 출력할 수도 있다. 이때, 에너지 분포도는 오디오 스트림의 일부분이 음악일 확률 및/또는 음성일 확률과 관련될 수 있 다. 다른 실시예로서, 제어부는 제1 인공지능 모델을 이용하여, 입력된 오디오 스트림을 음악 데이터와 비음악 데이터로 구분하고, 상기 구분된 비음악 데이터를 제3 인공지능 모델을 이용하여 음성 데이터와 비음성 데이터 로 구분할 수 있다. 이때, 비음성 데이터란 노크소리, 동물 울음소리와 같이 인간의 음성에 해당하지 않는 오디오 데이터를 의미한 다. 아울러, 제1 인공지능 모델은 음악 여부를 검출하기 위한 인공 신경망이고, 제3 인공지능 모델은 입력된 오 디오가 어떤 환경음인지 판별하기 위한 인공 신경망일 수 있다. 물론, 필요에 따라서 제1 및 제3 인공지능 모델이 통합되어 구성될 수도 있으며, 이 경우 통합된 인공지능 모델 은, 오디오 입력에 대해 음악이 포함된 복수의 클래스 또는 레이블에 대응되는 확률 값을 출력할 수 있다. 다음으로, 제어부는 대상 구간을 순차적으로 시프트(shift)시키면서, 상기 대상 구간에 음악이 포함되어 있는지 여부를 판별할 수 있다. 예를 들어, 상기 대상 구간의 길이는 1초로 설정될 수 있다. 또한, 제어부는 현재 구간과 이전 구간이 중 첩되도록 대상 구간을 0.5초씩 시프트시키면서, 대상 구간에 음악이 포함되어 있는지 여부를 판별할 수 있다. 상술한 분리 과정(S311)과 비교하여, 검출 과정(S321)은, 음성과 음악이 동시에 존재하는 구간을 감지할 수 있 는 점에서 차이가 있다. 또한, 제어부는 분리 과정(S311)을 수행하는데 이용되는 제1 인공지능 모델과 상 이한 제2 인공지능 모델을 이용하여, 검출 과정(S321)을 수행할 수 있다. 예를 들어, 분리 과정(S311)에 이용되는 제1 인공지능 모델은, 음악 데이터와 음성 데이터로 레이블링 (labeling)된 트레이닝 데이터를 이용하여 학습을 수행하도록 구성될 수 있다. 이와 달리, 검출 과정(S321)에 이용되는 제2 인공지능 모델은, 음악이 포함된 데이터와, 음악이 포함되지 않은 데이터로 레이블링된 트레이닝 데이터를 이용하여 학습을 수행하도록 구성될 수 있다. 보다 구체적으로, 검출 과정(S321)에 이용되는 제2 인공지능 모델은, 음악이 포함된 비중이 기준치 이상인 데이터와, 음악이 포함된 비 중이 기준치 이하인 데이터와, 음악이 전혀 포함되어 있지 않은 데이터로 레이블링된 트레이닝 데이터를 이용하 여 학습을 수행하도록 구성될 수 있다. 상술한 바와 같이, 제어부는 분리 과정(S311)의 수행 결과 및 검출 과정(S321)의 수행 결과 중 적어도 하 나를 이용하여, 오디오 스트림으로부터 음악 데이터를 검출할 수 있다. 한편, 제어부는 분리 과정(S311)의 정확도가 기준치 이상인 경우, 검출 과정(S321)을 생략할 수도 있다. 일 실시예에서, 제어부는 입력된 오디오 스트림 중, 분리 과정(S311)을 통해 음악으로 구분된 일부분에 대 해서만 상기 검출 과정(S321)을 수행할 수도 있다. 다른 실시예에서, 제어부는 입력된 오디오 스트림 중, 분리 과정(S311)을 통해 출력된 단위 구간 별 확률 에 근거하여, 상기 검출 과정(S321)을 수행할 대상을 결정할 수 있다. 다른 실시예에서, 제어부는 분리 과정(S311)과 마찬가지로, 입력된 오디오 스트림 전체에 대해 상기 검출 과정(S321)을 수행할 수도 있다. 한편, 제어부는 분리과정(S311) 및 검출과정(S321) 중 적어도 하나를 이용하여 오디오 스트림의 단위구간 별로 음악 데이터인지 여부를 검출한 후, 검출결과의 구간 연속성에 근거하여, 오디오 스트림의 일부분을 음악 데이터로 검출할 수 있다. 아울러, 제어부는 검출된 음악 데이터의 변주 양상을 검출하고, 검출된 변주 양상에 근거하여, 하나의 음 악 데이터를 복수의 음악 데이터로 분리시킬 수도 있다. 예를 들어, 서로 다른 음악이 연속적으로 스트리밍되어하나의 음악 데이터로 검출된 경우에, 제어부는 음악 데이터의 변주 양상을 모니터링함으로써, 상기 음악 데이터를 복수 개로 분리시킬 수 있다. 상술한 바와 같이 음악 데이터가 검출(S301)되면, 제어부는 상기 검출된음악 데이터가 오디오 스트림으로 부터 제거되도록, 상기 오디오 스트림에 대해 필터링을 수행할 수 있다(S302). 구체적으로, 제어부는 오디오 스트림 중 음악 데이터로 검출된 일부분을 삭제시킬 수 있다. 다른 예로서, 제어부는 오디오 스트림 중 음악 데이터로 검출된 일부분을, 상기 음악 데이터와 다른 대체 음악 데이터로 변경시킬 수 있다. 일 실시예에서, 제어부는 검출된 음악 데이터가 저작물에 해당하는지 여부를 판단하고, 판단결과에 따라 상기 필터링 단계(S302)를 수행할 수 있다. 즉, 제어부는 음악 데이터가 검출되더라도, 상기 검출된 음악 데이터가 저작물에 해당하지 않으면, 필터링 대상에서 제외할 수 있다. 오디오 스트림으로부터 복수의 서로 다 른 음악 데이터가 검출되는 경우에, 제어부는 각각의 음악 데이터에 대해 저작물 여부를 판단할 수 있다. 필터링 단계(S302)가 수행됨에 있어서 저작물인지 여부를 고려하기 위해, 데이터 처리장치의 메모리는 저 작물과 관련된 정보로 구성되는 저작물 데이터베이스를 저장할 수 있다. 즉, 제어부는 메모리에 미리 저장 된 저작물 데이터베이스를 이용하여, 검출된 상기 음악 데이터가 저작물인지 여부를 판단할 수 있다. 아울러, 제어부는 검출된 음악 데이터가 저작물인 것으로 판단되면, 상기 음악 데이터가 제거되도록 오디오 스트림 을 필터링할 수 있다. 한편, 제어부는 검출된 음악 데이터의 특성을 고려하여, 대체음악 데이터를 결정할 수 있다. 예를 들어, 상기 특성은, 장르, 분위기, 조성, 템포, 볼륨 및 음원 길이 중 적어도 하나와 관련될 수 있다. 일 실시예에서, 제어부는 제4 인공지능 모델을 이용하여, 검출된 음악 데이터의 장르 및/또는 분위기와 관 련된 정보를 분석하고, 분석결과에 근거하여 대체음악 데이터를 선택할 수 있다. 즉, 제어부는 음악의 장르나, 분위기를 분석하기 위해 설계된 제4 인공지능 모델을 이용하여, 검출된 음악 데이터의 장르 및 분위기 중 적어도 하나와 관련된 정보를 검출할 수 있다. 특히, 제4 인공지능 모델은 음악이 어떤 장르인지, 또는 어떤 분위기인지 레이블링된 트레이닝 데이터에 의해 학습을 수행하도록 구성될 수 있다. 이때, 제4 인공지능 모델에 의해 획득된 정보는 피쳐 벡터(Feature vector)의 형태로 구성될 수 있다. 아울러, 제어부는 대체음악 후보군의 피쳐벡터와 검출된 음악 데이터의 피쳐벡터를 비교하여, 검출된 음악 데이터와 대체음악 후보군 사이의 유사도를 산출할 수 있다. 또한, 제어부는 산출된 유사도에 근거하여, 복수의 대체음악 데이터 중 어느 하나를 선택하여, 검출된 음악데이터를 선택된 대체음악 데이터로 변경시킬 수 있다. 다른 실시예에서, 제어부는 검출된 음악 데이터의 볼륨 크기에 근거하여, 대체음악 데이터에 대한 변환을 수행할 수 있다. 구체적으로, 제어부는 검출된 음악 데이터에 대해, 재설정된 단위구간 별로 에너지 레벨 을 산출할 수 있다. 예를 들어, 제어부는 분리과정(S311)에서 적용된 제1 단위구간보다 더 짧은 구간으로 제2 단위구간을 설정하고, 상기 제2 단위구간마다 검출된 음악 데이터의 에너지 레벨을 산출할 수 있다. 일 예 에서, 제2 단위구간은 0.2초일 수 있다. 제어부는 산출된 에너지 레벨로 구성된 벡터에 의해 정의되는 로우패스필터를 대체음악 데이터에 적용하고, 기존 음악 데이터를 상기 적용결과로 변경시킬 수 있다. 한편, 제어부는 검출된 음악 데이터와 대응되는 비디오 스트림의 일부분을 분석하고, 분석결과에 근거하여 대체음악 데이터를 결정할 수도 있다. 구체적으로, 제어부는 상기 비디오 스트림의 일부분에 대해 영상 인식을 수행하여, 적어도 하나의 객체를 인식할 수 있으며, 인식된 객체의 특성에 근거하여 대체음악 데이터를 결정할 수 있다. 이때, 객체의 특성은, 객체의 수, 객체 별 레이블 및 객체의 이동 속도 중 적어도 하나를 포함할 수 있다. 또한, 제어부는 상기 일부분의 영역 별 색상과, 색상 변화 정도를 분석하여, 대체음악 데이터를 결정할 수 있다. 아울러, 제어부는 필터링 단계(S302)가 수행된 후, 필터링된 오디오 스트림을 출력할 수 있다(S303). 본 발명에 따른 데이터 처리장치는 필터링된 오디오 스트림을 포함한 비디오 컨텐츠를 메모리에 저장된 파 일 형식으로 출력할 수도 있고, 디스플레이에 직접 출력시킬 수도 있다. 한편, 데이터 처리장치는 외부 서 버 또는 외부 단말기로 필터링된 오디오 스트림을 전송할 수도 있다. 예를 들어, 본 발명에 따른 데이터 처리장치는 동영상 스트리밍 플랫폼의 서버에 탑재될 수 있다. 이 경우, 사용자가 해당 플랫폼에 비디오 컨텐츠를 업로드하면, 데이터 처리장치는 업로드된 비디오 컨텐츠에 대해 필터링 단계(S302)를 수행한 후, 필터링 결과가 플랫폼 상에서 출력되도독 플랫폼 제어장치로 필터링 결과 를 전송할 수 있다. 다른 예에서, 제어부는 원본 오디오 스트림에서 검출된 음악 데이터를 삭제하여, 변경된 오디오 스트림을 포함하는 비디오 컨텐츠가 출력되도록 출력부를 제어할 수 있다. 아울러, 제어부는 원본 오디오 스트 림에서 음악 데이터가 삭제된 구간과 관련된 정보를 변경된 비디오 컨텐츠와 함께 출력할 수 있다. 예를 들어, 변경된 비디오 컨텐츠 파일과 별도의 텍스트 파일이 출력될 수 있다. 다른 예에서, 제어부는 동영상 플랫폼에서 제공하는 로그를 이용하여, 음악 데이터가 삭제된 구간과 관련된 정보를 출력하고, 상기 플 랫폼 상에서 변경된 비디오 컨텐츠가 출력되도록 제어할 수도 있다. 다른 실시예에서, 제어부는 원본 비디오 컨텐츠가 검출된 음악 데이터가 존재하는 구간을 기준으로 파싱 (parsing)되어, 복수의 비디오 컨텐츠로 출력되도록 출력부를 제어할 수 있다. 본 발명에 따르면, 사용자가 비디오 컨텐츠를 직접 스캔하지 않아도, 비디오 컨텐츠 내에 포함된 음악 데이터를 검출할 수 있으므로, 비디오 컨텐츠 편집을 수행하는 사용자의 편의를 향상시킬 수 있는 장점이 있다. 또한, 방대한 양의 비디오 컨텐츠에 대해 빠른 시간 내에 음악 데이터를 검출할 수 있으므로, 영상 편집에 소요 되는 비용을 획기적으로 감소시킬 수 있다. 아울러, 본 발명에 따르면, 데이터 처리장치가 입력된 비디오 컨텐츠에 포함된 저작물에 대응되는 음악 데이터 를 삭제하거나, 대체음악으로 치환하므로, 비디오 컨텐츠의 소유자 또는 유통자의 편의가 향상될 수 있다."}
{"patent_id": "10-2021-0053988", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 데이터 처리 방법과 관련된 개념도이다. 도 2는 본 발명에 따른 데이터 처리장치의 구성요소를 나타낸 블록도이다. 도 3은 본 발명에 따른 데이터 처리 방법의 일 실시예를 나타낸 흐름도이다. 도 4는 본 발명에 따른 데이터 처리 방법의 일 실시예를 나타낸 흐름도이다."}
