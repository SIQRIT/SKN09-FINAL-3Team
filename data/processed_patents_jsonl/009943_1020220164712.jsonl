{"patent_id": "10-2022-0164712", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0081663", "출원번호": "10-2022-0164712", "발명의 명칭": "실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는", "출원인": "주식회사 안지온", "발명자": "홍충기"}}
{"patent_id": "10-2022-0164712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나 이상의 CCTV로부터 실시간 촬영된 영상 프레임을 수집한 후, 데이터 셋으로 그룹화하는 영상정보수집부;상기 영상 프레임 내의 실측정보를 3D 가상공간으로 모델링하는 3D 가상화 모델링부;상기 영상 프레임을 기 설정된 픽셀 단위로 분할 한 후, 분할된 픽셀 내의 오브젝트를 정적 객체 및 동적 객체로 분류하는 객체 인식 및 분류부;상기 가상공간 내의 3D 모델링 객체와 상기 객체 인식 및 분류부에서 분류된 정적 객체 및 동적 객체를 맵핑한후, 상기 3D 모델링 객체의 조도 및 색상을 상기 영상 프레임의 정적 객체의 픽셀값 및 동적 객체의 픽셀값 변화에 따라 보정하는 3D 모델링 객체효과 처리부; 및3D 가상현실 공간정보 내에 지리정보, 조도 및 색상이 보정된 정적 객체 및 동적 객체가 융합된 3D 가상화 맵을생성하는 3D 가상화 맵 생성부를 포함하는 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템."}
{"patent_id": "10-2022-0164712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 3D 가상화 모델링부는상기 3D 가상공간의 가상좌표를 상기 영상 프레임의 절대좌표값으로 대체 또는 반영하는 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템."}
{"patent_id": "10-2022-0164712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 3D 모델링 객체효과 처리부는상기 영상 프레임의 실측정보와 90% 이상 일치되도록 상기 3D 모델링 객체의 조도값 및 색상값을 기 설정된 주기로 보정하는 것을 특징으로 하는 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템."}
{"patent_id": "10-2022-0164712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 3D 가상화 모델링부는상기 실측정보와 동일한 크기로 3D 모델링 객체를 생성하는 것을 특징으로 하는 실시간 CCTV 영상을 절대좌표기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템."}
{"patent_id": "10-2022-0164712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2024-0081663-3-상기 3D 가상화 맵 생성부는모델링된 3D 가상공간과 맵핑되는 영상 프레임을 오버랩하여 상기 3D 가상화 맵을 생성하는 것을 특징으로 하는실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템."}
{"patent_id": "10-2022-0164712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "적어도 하나 이상의 CCTV로부터 실시간 촬영된 영상 프레임을 수집한 후, 데이터 셋으로 그룹화하는 단계;상기 영상 프레임 내의 실측정보를 3D 가상공간으로 모델링하는 단계;상기 영상 프레임을 기 설정된 픽셀 단위로 분할 한 후, 분할된 픽셀 내의 오브젝트를 정적 객체 및 동적 객체로 분류하는 단계;상기 가상공간 내의 3D 모델링 객체와 상기 객체 인식 및 분류부에서 분류된 정적 객체 및 동적 객체를 맵핑한후, 상기 3D 모델링 객체의 조도 및 색상을 상기 영상 프레임의 정적 객체의 픽셀값 및 동적 객체의 픽셀값 변화에 따라 보정하는 단계; 및3D 가상현실 공간정보 내에 지리정보, 조도 및 색상이 보정된 정적 객체 및 동적 객체가 융합된 3D 가상화 맵을생성하는 단계를 포함하는 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를지원하는 방법."}
{"patent_id": "10-2022-0164712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 보정하는 단계는영상 프레임의 실측정보와 90% 이상 일치되도록 상기 3D 모델링 객체의 조도값 및 색상값을 기 설정된 주기로보정하는 단계를 포함하는 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를지원하는 방법."}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템은 적어도 하나 이상의 CCTV로부터 실시간 촬영된 영상 프레임을 수집한 후, 데이터 셋으로 그룹 화하는 영상정보 수집부; 상기 영상 프레임 내의 실측정보를 3D 가상공간으로 모델링하는 3D 가상화 모델링부; (뒷면에 계속)"}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 실시간 CCTV 영상을 절대좌표 기반으로 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시 스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트시티를 바라보는 시각에 따라 다양한 정의가 존재할 수 있으나 일반적으로 도시공간에 정보통신 융합기술 과 친환경기술 등을 적용하여 행정·교통·물류·방범방재·에너지·환경·물관리·주거·복지 등의 도시기능을 효율화하고 일자리를 창출하는 도시로 볼 수 있다. 기존 U-City가 가지고 있던 한계를 보완하여 기존 도시까지 포괄하고 있으며, 동시에 도시의 관리 및 운영과 산업 진흥까지 범위를 확대하였다. U-City에서 스마트시티로 진화하는 변화의 과정 속에는 4차 산업혁명이라는 예측할 수 없는 미래사회의 도래에 대한 국가차원의 대응의지가 내포되어 있다. 인공지능(AI), 빅데이터(Bigdata), 사물인터넷(IoT), 디지털트윈 (DTS), 자율자동차, 3D 프린팅, 블록체인 등 변화를 주도하는 다양한 첨단기술은 스마트시티의 성공을 지원하는 주요한 요소이다. 그리고 정보통신기술(ICT)의 발달에 따라 생산자와 소비자의 경계가 사라지며 무한히 생산· 소비되는 데이터 역시 스마트시티를 지탱하는 영양분이다. 이러한 기술과 데이터는 독립적으로 존재하나 현실세 계에 구현될 스마트시티에서는 복합적으로 작용될 수밖에 없다. 이러한 상호작용이 가능하도록 다양한 기술과 방대한 데이터를 융복합될 수 있는 기반이 필요하다. 따라서 다양한 정보와 기술의 융복합을 가능하게 하는 공간정보의 중요성이 날로 높아지고 있다. 개별 기술 및 데이터의 연결을 중시하는 U-City에서 공간정보의 역할은 제한적이었으나 연결을 넘어 융복합을 통한 초연결을지향하는 스마트시티 사회에서 공간정보가 가지는 역할은 단순 인프라 이상의 의미를 지니고 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) Nguyen D., Meixner G.: Comparison User Engagement of Gamified and Non-gamified Augmented Reality Assembly Training Advances in Agile and User-Centred Software Engineering. pp. 142- 152. Springer International Publishing"}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 종래의 문제점을 해결할 수 있는 실시간 CCTV 영상을 절대좌표 기반으로 가 상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템 및 방법을 제공하는 데 그 목적이 있다."}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템은 적어도 하나 이상의 CCTV로부터 실시간 촬영된 영상 프레임을 수집한 후, 데이터 셋으로 그룹화하는 영상정보 수집부; 상기 영상 프레임 내의 실측정보를 3D 가상공간으로 모 델링하는 3D 가상화 모델링부; 상기 영상 프레임을 기 설정된 픽셀 단위로 분할 한 후, 분할된 픽셀 내의 오브 젝트를 정적 객체 및 동적 객체로 분류하는 객체 인식 및 분류부; 상기 가상공간 내의 3D 모델링 객체와 상기 객체 인식 및 분류부에서 분류된 정적 객체 및 동적 객체를 맵핑한 후, 상기 3D 모델링 객체의 조도 및 색상을 상기 영상 프레임의 정적 객체의 픽셀값 및 동적 객체의 픽셀값 변화에 따라 보정하는 3D 모델링 객체효과 처리 부; 및 3D 가상현실 공간정보 내에 지리정보, 조도 및 색상이 보정된 정적 객체 및 동적 객체가 융합된 3D 가상 화 맵을 생성하는 3D 가상화 맵 생성부를 포함한다. 일 실시예에서, 상기 3D 가상화 모델링부는 상기 3D 가상공간의 가상좌표를 상기 영상 프레임의 절대좌표값으로 대체 또는 반영하는 것을 특징으로 한다. 일 실시예에서, 상기 3D 모델링 객체효과 처리부는 영상 프레임의 실측정보와 90% 이상 일치되도록 상기 3D 모 델링 객체의 조도값 및 색상값을 기 설정된 주기로 보정하는 것을 특징으로 한다. 일 실시예에서, 상기 3D 가상화 모델링부는 상기 실측정보와 동일한 크기로 3D 모델링 객체를 생성하는 것을 특 징으로 하는 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스 템. 일 실시예에서, 상기 3D 가상화 맵 생성부는 모델링된 3D 가상공간과 맵핑되는 영상 프레임을 오버랩하여 상기 3D 가상화 맵을 생성하는 것을 특징으로 한다. 상기 과제를 해결하기 위한 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 방법은 적어도 하나 이상의 CCTV로부터 실시간 촬영된 영상 프레임을 수 집한 후, 데이터 셋으로 그룹화하는 단계; 상기 영상 프레임 내의 실측정보를 3D 가상공간으로 모델링하는 단계; 상기 영상 프레임을 기 설정된 픽셀 단위로 분할 한 후, 분할된 픽셀 내의 오브젝트를 정적 객체 및 동적 객체로 분류하는 단계; 상기 가상공간 내의 3D 모델링 객체와 상기 객체 인식 및 분류부에서 분류된 정적 객체 및 동적 객체를 맵핑한 후, 상기 3D 모델링 객체의 조도 및 색상을 상기 영상 프레임의 정적 객체의 픽셀값 및동적 객체의 픽셀값 변화에 따라 보정하는 단계; 및 3D 가상현실 공간정보 내에 지리정보, 조도 및 색상이 보정 된 정적 객체 및 동적 객체가 융합된 3D 가상화 맵을 생성하는 단계를 포함한다. 일 실시예에서, 상기 보정하는 단계는 영상 프레임의 실측정보와 90% 이상 일치되도록 상기 3D 모델링 객체의 조도값 및 색상값을 기 설정된 주기로 보정하는 단계를 포함한다."}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템 및 방법을 이용하면, CCTV에서 실제 모니터링한 영상을 3D 가상화 세계에 투영시키고, 다른 지 리적 위치에 배치된 모니터링 영역을 정합하여 대규모 3D 파노라마 동적 영상 구현이 가능함으로써, 전국 각지 의 모니터링 영역의 전체 상황에 대한 실시간 전면 제어를 가능하게 할 수 있다는 이점이 있다."}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하"}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며, 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 이하, 첨부된 도면들에 기초하여 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반으로 가상현실 과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템 및 방법을 보다 상세하게 설명하도록 한다. 먼저, 본 발명을 설명하기에 앞서, 본 발명이 적용될 디지털 트윈 기술을 간략하게 언급한다. 도시 모델링을 위하여 최근 이슈화 되고 있는 디지털 트윈(Digital Twin) 은 시스템, 도시기반시설, 환경, 에너 지, 교통 등을 가상공간에 동적 소프트웨어 모델로 디지털화하고 디지털화된 트윈과 IoT 기반 실시간 수집 데이 터와의 동기화 및 실시간 예측, 최적 운영 지원을 위해 컴퓨터 속에서 가상 세계에 구현한 것을 말한다. 디지털 트윈 기술은 실제 제품을 만들기 전 모의시험을 통해 발생할 수 있는 문제점을 파악하고 이를 해결하기 위해 활 용되고 있다. 즉, 디지털 트윈은 가상 공간에 실물과 똑같은 물체(쌍둥이, Twin)를 만들어 다양한 모의시험(시뮬레이션)을 통 해 검증해 보는 기술을 의미하며, 미국 가전업체인 제너럴 일렉트릭(GE)이 최초 주창한 개념으로 2000년대 들어 제조업에 도입되기 시작하여 항공, 건설, 헬스케어, 에너지, 국방, 도시설계 등 다양한 분야에서도 활용되고 있다. 이러한 디지털 트윈 기술을 활용하면 가상 세계에서 장비, 시스템 등의 상태를 모니터링하고 유지 및 보수 시점 을 파악해 개선할 수 있다. 가동 중 발생할 수 있는 다양한 상황을 예측해 안전을 검증하거나 돌발 사고를 예방 해 사고 위험을 줄일 수도 있다. 또한 생산성 향상, 장비 최적화 등의 결과를 가져올 수 있고 시제품 제작에 들 어가는 비용과 시간을 대폭 절감할 수 있다. 이에 본 발명은 스마트 시티의 교통정보와 관련된 데이터 입력, 분석, 시각화 구현을 위해 현실의 물리적 세계 를 가상의 공간에 재현하고, 이를 위하여 3D 객체 생성 모델링 프로그램 및 영상 융합 기술이 적용된 3D 영상 융합 감시 서비스를 제공하는 그 목적이 있다. 도 1은 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반으로 가상현실과 통합한 3D 영상 융합 감 시 서비스를 지원하는 시스템의 네트워크 구성도이다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반으로 가상현실과 통합 한 3D 영상 융합 감시 서비스를 지원하는 시스템은 영상정보 수집부, 3D 가상화 모델링부, 오브 젝트 인식 및 분류부 및 오브젝트 효과 처리부 및 3D 가상화 맵 생성부를 포함한다. 또한, 상기 시스템은 3D 가상화 맵 생성부에서 생성된 적어도 하나 이상의 3D 가상화 맵을 정합한 3D 파노라마 가상화 맵을 생성하는 3D 가상화 맵 정합부를 더 포함할 수 있다. 먼저, 상기 영상정보 수집부는 적어도 하나 이상의 CCTV로부터 실시간 촬영된 영상 프레임을 수집한 후, 데이터 셋으로 그룹화하는 구성일 수 있다(도 3 참조). 상기 영상정보 수집부는 기 설정된 구역 내에 인접한 적어도 하나 이상의 CCTV를 그룹화한 후 그룹화된 CCTV에서 촬영한 영상 프레임들을 데이터 셋으로 그룹화한다. 또한, 영상정보 수집부는 영상 프레임 내의 모든 픽셀 단위의 값들을 GPU(graphic processing unit, 그래 픽 처리장치)를 기반으로 깊이 버퍼에 저장 및 관리할 수 있고, 이 때, 각 깊이 정보를 수치화한 데이터들이 저 장될 수 있다. 다음으로, 3D 가상화 모델링부는 상기 영상 프레임 내의 절대좌표 공간정보를 3D 가상현실 공간정보로 모 델링하는 구성일 수 있다. 여기서, 상기 3D 가상화 모델링부에서 생성된 3D 가상현실 공간은 현실세계의 방위와 가상세계의 방위를 맞추는 수단으로 지리적 포인트(마커)를 이용하여 현실세계의 방위각과 매칭된 가상세계의 방위각을 포함한다. 즉, 가상세계의 방위각은 현실세계의 절대좌표와 동일할 수 있다. 상기 3D 가상화 모델링부는 랜드마크 등과 같이 임의의 지리적 포인트를 지정한 후, 지정된 지리적 포인트 에 절대 좌표를 3D 가상현실 공간에 대응시킨다. 참고로, 절대 좌표는 지구 표면 상의 위치를 나타내는 2차원 지리 좌표와 해당 위치의 기준 해수면에서의 높이 를 나타내는 고도를 포함할 수 있다. 또한, 2차원 지리 좌표는 위도와 경도를 포함할 수 있다. 사용자 단말로 제공되는 3D 가상현실 서비스에서 절대 좌표가 균등하고 많은 포인트에 대응되어 있다면 안정적인 서비스를 제 공할 수 있다. 예컨대, 절대 좌표를 지원하는 측정 기법은 예를 들면 GPS(global positioning system), 글로나 스 (Glonass), 갈릴레오(Galileo) 또는 베이더우 위성 항법 시스템(Beidou navigation Satellite system)를 포 함 할 수 있다. 한 실시예에서, 절대 좌표는 하드웨어를 통해 측정하는 절대적 방법(예를 들면, 앞에서 설명한 측정 기법)을 통해 직접 측정될 수 있다. 다른 실시예에서, 절대 좌표는 기존에 미리 얻어진 3개 이상의 절대 좌표를 이용하여 상대 계측하여(예를 들면, 삼각 측량) 절대 좌표를 계산하는 상대적 방법으로 계산될 수 있다. 예를 들어, 삼성역 사거리 지역을 모델링한 3D 가상현실 공간 맵은 삼성역 및 삼성역 주변의 랜드마크(적어도 3 개 이상)를 지리적 포인트로 지정하고, 해당 지리적 포인트를 절대 좌표와 매칭한 후, 3개 이상의 절대 좌표를 상대 계측(예를 들면, 삼각 측량) 방법에 적용시켜 공간 내의 임의의 객체의 좌표를 산출한다. 또한, 상기 3D 가상화 모델링부는 영상 프레임 내의 2D 객체(사물, 배경 등)를 3D 객체로 모델링하는 구성 일 수 있다. 더 나아가, 3D 가상화 모델링부는 특정 공간에 대한 3차원적인 정보에 기초하여 해당 공간을 디지털 트윈 기법을 이용하여 가상 공간으로 모사하여 생성한다. 예컨대, 특정 공간에 대한 3차원적인 정보는 해당 공간에 대한 설계도, 3D 스캔한 자료, 평면도, 특정 공간을 실측하여 생성된 자료 중 어느 하나일 수 있다. 또한, 디지털 트윈 기법을 이용하여 CCTV 카메라가 위치한 지점에서 촬영한 화각(View angle)을 갖는 가상공간 을 생성할 수 있다. 또한, 초기 위치(Initial position)를 기반으로 디지털 트윈에 배치된 3D 모델(3D model Reconstruction)을 이 용하여 영상 데이터 내 객체와의 차이를 계산하며, 차이를 최소화하는 최적화(optimization)를 통해 객체의 위 치 및 각도를 포함하는 지리적 데이터를 추정하여 추정된 지리적 데이터를 디지털 트윈공간으로 구현할 수 있다. 또한, PSO(Particle Swarm Optimization) 알고리즘을 이용하여 초기 위치에 3D 모델의 3D 객체를 프로젝션 (projection)하여 생성된 추정 데이터의 객체 윤곽(outline)과 영상 데이터 내 객체 윤곽(outline) 간의 차이를 계산하며, 오차를 최소화하는 최적화를 수행할 수 있다. 또한, PSO 알고리즘을 이용하여 3D 객체의 위치(position) 및 회전(rotation)을 변화(Position/Rotation Refinement)하는 반복(Iteration)으로 최적화 과정을 수행하여 영상 데이터 내 객체의 위치 및 각도를 포함하는 6DoF 포즈(6DoF pose)를 추정(Final position/rotation)하여 디지털 트윈공간으로 구현할 수 있다 다음으로, 객체 인식 및 분류부는 상기 영상 프레임을 기 설정된 픽셀 단위로 분할 한 후, 분할된 픽셀 내 의 오브젝트를 정적 객체 및 동적 객체로 분류하는 구성일 수 있다. 상기 객체 인식 및 분류부는 전처리부를 포함할 수 있고, 상기 전처리부는 영상 프레임으로부터 객체를 검 출하기 전에 검출 결과의 정확도를 향상시키기 위하여 영상을 전처리하는 구성으로, 밤 시간이나 조명이 부족한 환경에서 촬영한 저조도의 영상 프레임의 조도를 개선하여 객체 검출을 비롯한 각종 영상 처리 결과의 정확도 및 신뢰성을 높이기 위한 구성일 수 있다. 한편, 객체 인식 및 분류부는 RPN(Region Proposal Network)를 이용하여 객체영역을 추출한다. 상기 추출 된 객체영역에 있는 물체를 하나의 객체로 인식하기 위하여 딥러닝 알고리즘인 R-CNN알고리즘을 이용하여 학습 하여 저장된 여러 객체들과 비교하여 이미지 속의 물체가 객체로 인식이 되면 인식된 객체의 명칭 결과를 업데 이트한다. 즉, 객체 인식 및 분류부는 객체영역을 특정하는 RPN과 특정된 객체를 인식하는 알고리즘인 Fast R-CNN을 하나의 네트워크로 컨볼루션 결합을 통해 보다 빠르게 객체인식을 객체인식을 위해 이미지내의 물체와 객체 데 이터베이스에 저장된 다양한 정보와 비교하는 구성일 수 있다. 다음으로, 3D 모델링 객체 효과 처리부는 상기 가상현실 공간정보 내의 3D 모델링 객체와 상기 객체 인식 및 분류부에서 분류된 정적 객체 및 동적 객체를 맵핑한 후, 상기 3D 모델링 객체의 조도 및 색상을 상기 영상 프레임의 정적 객체의 픽셀값 및 동적 객체의 픽셀값 변화에 따라 보정하는 구성일 수 있다. 여기서, 상기 3D 모델링 객체효과 처리부는 영상 프레임의 실측정보와 90% 이상 일치되도록 상기 3D 모델 링 객체의 조도값 및 색상값을 기 설정된 주기로 보정한다. 다음으로, 3D 가상화 맵 생성부는 3D 가상현실 공간정보 내에 지리정보, 조도 및 색상이 보정된 정적 객체 및 동적 객체가 융합된 3D 가상화 맵을 생성하는 구성일 수 있다. 상기 3D 가상화 맵 생성부는 모델링된 3D 가상공간과 맵핑되는 영상 프레임을 오버랩하여 상기 3D 가상화 맵을 생성한다. 한편, 상기 3D 가상화 맵은 3D 도로시설물 객체정보를 표시할 수 있고, 상기 3D 도로시설물 객체란 노면표시, 주의표시, 규제표시, 지시표시, 보조표시, 표시판, 신호등, 가로등, 지주, 맨홀, 연석, 중앙분리대, 소화전, 및 건물 중 적어도 하나를 포함한다. 이러한 도로시설물 객체는 도로 노면상에 고정되거나 표시될 수 있으며, 또한 신호등, 건물의 일부 특징점, 또는 간판처럼 공중에 떠있는 시설물이나 그 시설물에 표시될 수도 있다. 즉, 도로시설물 객체란 3D 가상화 맵에 표시되는 모든 종류의 시설물을 의미하며, 각종 노면표시, 주의표시, 규 제표시, 지시표시, 보조표시, 표시판, 신호등, 가로등, 지주, 맨홀, 연석, 중앙분리대, 소화전, 건물, 건물의간판 등을 포함하는 개념으로서, 본 발명에서는 이들 객체 중 적어도 하나 이상이 활용될 수 있다. 예를 들면, 도로 노면 상에 표기된 중앙선, 실선 차선, 점선 차선, 좌회전 화살표, 직진 화살표, 서행 표시 마 름모, 속도제한구역 등 도로 노면에 표시될 수 있는 모든 표시가 시설물 객체에 포함되고, 도로나 지상에 설치 된 가로등, 지주, 맨홀, 소화전, 연석, 중앙분리대, 표시판 등의 구조물과 그 구조물 상의 각종 표시, 그리고 신호등에 설치된 각종 표시판과 표시, 건물 등도 모두 포함된다. 도 2는 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 방법을 설명한 흐름도이고, 도 3은 실시간 CCTV 영상을 절대좌표 기반으로 가상현실과 통합 한 3D 영상 제작 과정을 도식화 한 예시도이다. 먼저, 도 2를 참조하면, 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 방법(S700)은 적어도 하나 이상의 CCTV로부터 실시간 촬영된 영상 프레임을 수집한 후, 데이터 셋으로 그룹화(S710)한다. 이후, 상기 영상 프레임 내의 실측정보를 3D 가상공간으로 모델링 (S720)한다. 상기 S720 과정은 영상 프레임 내의 2D 객체(사물, 배경 등)를 3D 객체로 모델링하는 과정을 포함하는 과정일 수 있고, 특정 공간에 대한 3차원적인 정보에 기초하여 해당 공간을 디지털 트윈 기법을 이용하여 가상 공간으 로 모사하여 생성하는 과정일 수 있다. 예컨대, 특정 공간에 대한 3차원적인 정보는 해당 공간에 대한 설계도, 3D 스캔한 자료, 평면도, 특정 공간을 실측하여 생성된 자료 중 어느 하나일 수 있다. 또한, 디지털 트윈 기법을 이용하여 CCTV 카메라가 위치한 지점에서 촬영한 화각(View angle)을 갖는 가상공간 을 생성하는 과정일 수 있다. 또한, 초기 위치(Initial position)를 기반으로 디지털 트윈에 배치된 3D 모델(3D model Reconstruction)을 이 용하여 영상 데이터 내 객체와의 차이를 계산하며, 차이를 최소화하는 최적화(optimization)를 통해 객체의 위 치 및 각도를 포함하는 지리적 데이터를 추정하여 추정된 지리적 데이터를 디지털 트윈공간으로 구현하는 과정 일 수 있다. 또한, PSO(Particle Swarm Optimization) 알고리즘을 이용하여 초기 위치에 3D 모델의 3D 객체를 프로젝션 (projection)하여 생성된 추정 데이터의 객체 윤곽(outline)과 영상 데이터 내 객체 윤곽(outline) 간의 차이를 계산하며, 오차를 최소화하는 최적화를 수행하는 과정을 포함한다. 또한, PSO 알고리즘을 이용하여 3D 객체의 위치(position) 및 회전(rotation)을 변화(Position/Rotation Refinement)하는 반복(Iteration)으로 최적화 과정을 수행하여 영상 데이터 내 객체의 위치 및 각도를 포함하는 6DoF 포즈(6DoF pose)를 추정(Final position/rotation)하여 디지털 트윈공간으로 구현하는 과정일 수 있다. 다음으로, 상기 S720 과정이 완료되면, 상기 영상 프레임을 기 설정된 픽셀 단위로 분할 한 후, 분할된 픽셀 내 의 오브젝트를 정적 객체 및 동적 객체로 분류(S730)한다. 여기서, S730 과정은 영상 프레임을 전처리하는 과정을 포함할 수 있고, RPN(Region Proposal Network)를 이용 하여 객체영역을 추출하고, 추출된 객체영역에 있는 물체를 하나의 객체로 인식하기 위하여 딥러닝 알고리즘인 R-CNN알고리즘을 이용하여 학습하여 저장된 여러 객체들과 비교하여 이미지 속의 물체가 객체로 인식이 되면 인 식된 객체의 명칭 결과를 업데이트하는 과정을 포함할 수 있다. 상기 가상공간 내의 3D 모델링 객체와 상기 객체 인식 및 분류부에서 분류된 정적 객체 및 동적 객체를 맵핑한 후, 상기 3D 모델링 객체의 조도 및 색상을 상기 영상 프레임의 정적 객체의 픽셀값 및 동적 객체의 픽셀값 변 화에 따라 보정(S740)한다. 이후, 3D 가상현실 공간정보 내에 지리정보, 조도 및 색상이 보정된 정적 객체 및 동적 객체가 융합된 3D 가상 화 맵을 생성(S750)하는 과정을 포함한다. 또한, 상기 S700 과정은 인접한 적어도 하나 이상의 3D 가상화 맵을 정합하여 3D 파노라마 가상화 맵을 생성하 는 과정을 더 포함할 수 있다.따라서, 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템 및 방법을 이용하면, CCTV에서 실제 모니터링한 영상을 3D 가상화 세계에 투영시키고, 다른 지리적 위치에 배치된 모니터링 영역을 정합하여 대규모 3D 파노라마 동적 영상 구현이 가능 함으로써, 전국 각지의 모니터링 영역의 전체 상황에 대한 실시간 전면 제어를 가능하게 할 수 있다는 이점이 있다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(programmable logic unit), 마이크로프로세서, 또 는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특 수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하 나 이상의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이 터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으"}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0164712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다."}
{"patent_id": "10-2022-0164712", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 시스템의 네트워크 구성도이다. 도 2는 본 발명의 일 실시예에 따른 실시간 CCTV 영상을 절대좌표 기반 가상현실과 통합한 3D 영상 융합 감시 서비스를 지원하는 방법을 설명한 흐름도이다. 도 3은 실시간 CCTV 영상을 절대좌표 기반으로 가상현실과 통합한 3D 영상 제작 과정을 도식화 한 예시도이다."}
