{"patent_id": "10-2020-7036850", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0022000", "출원번호": "10-2020-7036850", "발명의 명칭": "자연 언어 문장을 데이터베이스 쿼리로 번역하기 위한 시스템 및 방법", "출원인": "비트데펜더 아이피알 매니지먼트 엘티디", "발명자": "트라이안, 레베데아"}}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 언어(artificial language, AL) 인코더(encoder) 및 상기 AL 인코더에 연결된 디코더(decoder)를 실행하고(이 때, 상기 AL 인코더는 인공 언어로 만들어진 입력 AL 문장의 표현을 포함하는 제1 입력 배열을 수신하고,응답으로 제1 내부 배열을 생성하도록 구성되고, 상기 디코더는 상기 제1 내부 배열을 수신하고, 응답으로 상기인공 언어로 만들어진 제1 출력 AL 문장의 표현을 포함하는 제1 출력 배열을 생성하도록 구성됨);상기 AL 인코더에 상기 제1 입력 배열을 제공하는 것에 응답으로, 상기 입력 AL 문장과 상기 제1 출력 AL 문장사이의 유사 정도를 나타내는 제1 유사성 스코어를 결정하고;AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제1 유사성 스코어에 따라 상기 디코더의파라미터들의 제1 세트를 조정하고;제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하고;상기 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것에 응답으로, 상기 제1 단계 훈련 종료 조건이만족되는 경우, 자연 언어(natural language, NL)로 만들어진 입력 NL 문장의 표현을 포함하는 제2 입력 배열을수신하고, 응답으로 제2 내부 배열을 상기 디코더에 출력하도록 구성된 자연 언어(NL) 인코더를 실행하고;상기 제2 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열을 결정하고, 상기 제2출력 배열은 상기 인공 언어로 만들어진 제2 출력 AL 문장의 표현을 포함하고;상기 입력 NL 문장의 상기 인공 언어로의 변환(translation)을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장사이의 유사 정도를 나타내는 제2 유사성 스코어를 결정하고; 그리고상기 NL 인코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어에 따라 상기 NL 인코더의 파라미터들의 제2 세트를 조정하기 위하여; 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서를 채용하는 것을 포함하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공 언어는 데이터베이스 쿼리 언어, 프로그래밍 언어 및 마크업 언어(markup language)로 구성되는 그룹으로부터 선택되는 항목을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 인공 언어는 구조화된 쿼리 언어(structured query language, SQL)인 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 타겟 AL 문장의 표현을 포함하는 타겟 배열과 상기 제2 출력 배열 사이의 유사 정도에 따라 상기 제2 유사성 스코어를 결정하는 것을 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제2 유사성 스코어를 결정하는 것은,상기 AL 인코더에 상기 타겟 AL 문장의 표현을 입력하고;공개특허 10-2021-0022000-3-상기 타겟 AL 문장의 상기 표현을 입력으로서 수신하는 것에 응답으로 상기 AL 인코더의 출력을 포함하는 제3내부 배열을 결정하고; 그리고상기 제2 및 제3 내부 배열 사이의 유사 정도에 따라서 상기 제2 유사성 스코어를 결정하도록 하기 위하여, 상기 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서를 채용하는 것을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것에 응답으로, 상기 제1 단계 훈련 종료 조건이만족되지 않는 경우, 상기 AL 인코더에 제3 입력 배열을 제공하고, 상기 제3 입력 배열은 상기 인공 언어로 만들어진 제3 AL 문장의표현을 포함하고;상기 AL 인코더가 상기 제3 입력 배열을 수신하는 것에 응답으로 상기 디코더의 출력을 포함하는 제3 출력 배열을 결정하고, 상기 제3 출력 배열은 제3 출력 AL 문장의 표현을 포함하고;상기 제3 입력 AL 문장과 상기 제3 출력 AL 문장 사이의 유사 정도를 나타내는 제3 유사성 스코어를 결정하고;AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위하여, 상기 제3 유사성 스코어에 따라 상기 디코더의 파라미터들의 상기 제1 세트를 조정하기 위하여, 상기 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서를채용하는 것을 추가적으로 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 NL 인코더의 파라미터들의 상기 제2 세트를 조정하는 것에 응답으로, 또 다른 NL 문장의 표현을 포함하는 제3 입력 배열을 수신하고, 응답으로 상기 디코더에 제3 내부 배열을 출력하도록 구성된 또 다른 NL 인코더를 실행하고, 상기 또 다른 NL 문장은 상기 자연 언어와는 구별되는 또 다른자연 언어로 만들어지고;상기 제3 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제3 출력 배열을 결정하고, 상기 제3출력 배열은 제3 출력 AL 문장의 표현을 포함하고;상기 인공 언어로의 상기 또 다른 NL 문장의 변환을 포함하는 제3 타겟 AL 문장과 상기 제3 출력 AL 문장 사이의 유사 정도를 나타내는 제3 유사성 스코어를 결정하고; 그리고상기 또 다른 NL 디코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력의 또다른 세트와 디코더 출력 사이에 매치를 향상시키기 위해 상기 제3 유사성 스코어에 따라 상기 또 다른 NL 인코더의 파라미터들의 제3 세트를 조정하도록, 상기 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서를 채용하는것을 추가적으로 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 NL 인코더는 순환 신경망(recurrent neural network)을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 하드웨어 프로세서 및 메모리를 포함하는 컴퓨터 시스템으로서, 상기 적어도 하나의 하드웨어 프로세서는:인공 언어(artificial language, AL) 인코더(encoder) 및 상기 AL 인코더에 연결된 디코더(decoder)를 실행하고, 상기 AL 인코더는 인공 언어로 만들어진 입력 AL 문장의 표현을 포함하는 제1 입력 배열을 수신하고, 응답으로 제1 내부 배열을 생성하도록 구성되고, 상기 디코더는 상기 제1 내부 배열을 수신하고, 응답으로 상기 인공 언어로 만들어진 제1 출력 AL 문장의 표현을 포함하는 제1 출력 배열을 생성하도록 구성되고;공개특허 10-2021-0022000-4-상기 AL 인코더에 상기 제1 입력 배열을 제공하는 것에 응답으로, 상기 입력 AL 문장과 상기 제1 출력 AL 문장사이의 유사 정도를 나타내는 제1 유사성 스코어를 결정하고;AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제1 유사성 스코어에 따라 상기 디코더의파라미터들의 제1 세트를 조정하고;제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하고;상기 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것에 응답으로, 상기 제1 단계 훈련 종료 조건이만족되는 경우, 자연 언어(natural language, NL)로 만들어진 입력 NL 문장의 표현을 포함하는 제2 입력 배열을수신하고, 응답으로 제2 내부 배열을 상기 디코더에 출력하도록 구성된 자연 언어(NL) 인코더를 실행하고;상기 제2 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열을 결정하고, 상기 제2출력 배열은 상기 인공 언어로 만들어진 제2 출력 AL 문장의 표현을 포함하고;상기 입력 NL 문장의 상기 인공 언어로의 변환을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장 사이의 유사정도를 나타내는 제2 유사성 스코어를 결정하고; 그리고상기 NL 인코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어에 따라 상기 NL 인코더의 파라미터들의 제2 세트를 조정하도록; 구성된 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 인공 언어는 데이터베이스 쿼리 언어, 프로그래밍 언어 및 마크업 언어(markup language)로 구성되는 그룹으로부터 선택되는 항목을 포함하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 인공 언어는 구조화된 쿼리 언어(structured query language, SQL)인 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 적어도 하나의 하드웨어 프로세서는 상기 타겟 AL 문장의 표현을 포함하는 타겟 배열과 상기 제2 출력 배열 사이의 유사 정도에 따라 상기 제2 유사성 스코어를 결정하도록 추가적으로 구성되는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 제2 유사성 스코어를 결정하는 것은,상기 AL 인코더에 상기 타겟 AL 문장의 표현을 입력하고;상기 타겟 AL 문장의 상기 표현을 입력으로서 수신하는 것에 응답으로 상기 AL 인코더의 출력을 포함하는 제3내부 배열을 결정하고; 그리고상기 제2 및 제3 내부 배열 사이의 유사 정도에 따라서 상기 제2 유사성 스코어를 결정하기 위하여, 상기 컴퓨터 시스템의 상기 적어도 하나의 하드웨어 프로세서를 채용하는 것을 포함하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 적어도 하나의 하드웨어 프로세서는, 공개특허 10-2021-0022000-5-상기 제1 종료 조건이 만족되는지 여부를 결정하는 것에 응답으로, 상기 제1 종료 조건이 만족되지 않는 경우, 상기 AL 인코더에 제3 입력 배열을 제공하고, 상기 제3 입력 배열은 상기 인공 언어로 만들어진 제3 AL 문장의표현을 포함하고;상기 AL 인코더가 상기 제3 입력 배열을 수신하는 것에 응답하여 상기 디코더의 출력을 포함하는 제3 출력 배열을 결정하고, 상기 제3 출력 배열은 제3 출력 AL 문장의 표현을 포함하고;상기 제3 입력 AL 문장과 상기 제3 출력 AL 문장 사이의 유사 정도를 나타내는 제3 유사성 스코어를 결정하고;AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위하여, 상기 제3 유사성 스코어에 따라 상기 디코더의 파라미터들의 상기 제1 세트를 조정하도록, 추가적으로 구성되는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 적어도 하나의 하드웨어 프로세서는, 상기 NL 인코더의 파라미터들의 상기 제2 세트를 조정하는 것에 응답으로, 제3 입력 배열을 수신하고, 응답으로 상기 디코더에 제3 내부 배열을 출력하도록 구성된 또 다른 NL 인코더를실행하고, 상기 또 다른 NL 문장은 상기 자연 언어와는 구별되는 또 다른 자연 언어로 만들어지고;상기 제3 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제3 출력 배열을 결정하고, 상기 제3출력 배열은 제3 출력 AL 문장의 표현을 포함하고;상기 인공 언어로의 상기 또 다른 NL 문장의 변환을 포함하는 제3 타겟 AL 문장과 상기 제3 출력 AL 문장 사이의 유사 정도를 나타내는 제3 유사성 스코어를 결정하고; 그리고상기 또 다른 NL 디코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력의 또다른 세트와 디코더 출력 사이에 매치를 향상시키기 위해 상기 제3 유사성 스코어에 따라 상기 또 다른 NL 인코더의 파라미터들의 제3 세트를 조정하도록, 추가적으로 구성되는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 NL 인코더는 순환 신경망(recurrent neural network)을 포함하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1 컴퓨터 시스템의 제1 하드웨어 프로세서에 의하여 실행될 때, 상기 제1 컴퓨터 시스템으로 하여금 NL 인코더 및 상기 NL 인코더에 연결된 디코더를 포함하는 훈련된 변환기(translator) 모듈을 형성하도록 하는 명령들을 저장하는 비-일시적 컴퓨터 판독가능 매체(non-transitory computer-readable medium)로서, 상기 변환기 모듈을 훈련시키는 것은,인공 언어로 만들어진 입력 AL 문장의 표현을 포함하는 제1 입력 배열을 수신하고, 응답으로 제1 내부 배열을생성하도록 구성되는 AL 인코더에 상기 디코더를 연결하고, 상기 AL 인코더는 상기 디코더에 연결되어 상기 디코더가 상기 제1 내부 배열을 수신하고, 응답으로 상기 인공 언어로 만들어진 제1 출력 AL 문장의 표현을 포함하는 제1 출력 배열을 생성하고;상기 AL 인코더에 상기 제1 입력 배열을 제공하는 것에 응답으로, 상기 입력 AL 문장과 상기 제1 출력 AL 문장사이의 유사 정도를 나타내는 제1 유사성 스코어를 결정하고;AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제1 유사성 스코어에 따라 상기 디코더의파라미터들의 제1 세트를 조정하고;제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하고;상기 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것에 응답으로, 상기 제1 단계 훈련 종료 조건이만족되는 경우, 상기 NL 인코더를 상기 디코더에 연결하여 상기 NL 인코더가 자연 언어(natural language, NL)로 만들어진 입력 NL 문장의 표현을 포함하는 제2 입력 배열을 수신하고, 응답으로 제2 내부 배열을 상기 디코공개특허 10-2021-0022000-6-더에 출력하도록 하고;상기 제2 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열을 결정하고, 상기 제2출력 배열은 상기 인공 언어로 만들어진 제2 출력 AL 문장의 표현을 포함하고;상기 입력 NL 문장의 상기 인공 언어로의 변환을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장 사이의 유사정도를 나타내는 제2 유사성 스코어를 결정하고; 그리고상기 NL 인코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어에 따라 상기 NL 인코더의 파라미터들의 제2 세트를 조정하기 위하여; 제2 컴퓨터 시스템의 제2 하드웨어 프로세서를 채용하는 것을 포함하는 것을 특징으로 하는 비-일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2020-7036850", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "NL 인코더 및 상기 NL 인코더에 연결된 디코더를 포함하는 훈련된 변환기 모듈을 실행하도록 구성된 제1 하드웨어 프로세서를 포함하는 컴퓨터 시스템으로서, 상기 변환기 모듈을 훈련시키는 것은,인공 언어로 만들어진 입력 AL 문장의 표현을 포함하는 제1 입력 배열을 수신하고, 응답으로 제1 내부 배열을생성하도록 구성되는 AL 인코더에 상기 디코더를 연결하고, 상기 AL 인코더는 상기 디코더에 연결되어 상기 디코더가 상기 제1 내부 배열을 수신하고, 응답으로 상기 인공 언어로 만들어진 제1 출력 AL 문장의 표현을 포함하는 제1 출력 배열을 생성하고;상기 AL 인코더에 상기 제1 입력 배열을 제공하는 것에 응답으로, 상기 입력 AL 문장과 상기 제1 출력 AL 문장사이의 유사 정도를 나타내는 제1 유사성 스코어를 결정하고;AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제1 유사성 스코어에 따라 상기 디코더의파라미터들의 제1 세트를 조정하고;제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하고;상기 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것에 응답으로, 상기 제1 단계 훈련 종료 조건이만족되는 경우, 상기 NL 인코더를 상기 디코더에 연결하여 상기 NL 인코더가 자연 언어(natural language, NL)로 만들어진 입력 NL 문장의 표현을 포함하는 제2 입력 배열을 수신하고, 응답으로 제2 내부 배열을 상기 디코더에 출력하도록 하고;상기 제2 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열을 결정하고, 상기 제2출력 배열은 상기 인공 언어로 만들어진 제2 출력 AL 문장의 표현을 포함하고;상기 입력 NL 문장의 상기 인공 언어로의 변환을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장 사이의 유사정도를 나타내는 제2 유사성 스코어를 결정하고; 그리고상기 NL 인코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어에 따라 상기 NL 인코더의 파라미터들의 제2 세트를 조정하기 위하여, 제2 컴퓨터 시스템의 제2 하드웨어 프로세서를 채용하는 것을 포함하는 것을 특징으로 하는 컴퓨터 시스템."}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "설명된 시스템들과 방법들은 자연 언어(예를 들어서, 영어)로부터 구조화된 쿼리 언어(structured query language, SQL)와 같은 인공 언어로의 자동 변환을 가능하게 한다. 일부 실시예에서는, 변환기 모듈이 인코더 요 소와 디코더 요소를 포함하고, 이 둘 요소는 순환 신경망을 포함한다. 상기 변환기 모듈을 훈련하는 것은 2개의 국면을 포함한다. 제1 국면은 변환기 모듈이 인공 언어 입력이 제공될 때 인공 언어(AL) 출력을 생성하도록 훈련 한다. 예를 들어서, 변환기가 처음에는 인공 언어 입력을 재생성하도록 훈련된다. 제2 국면의 훈련은 변환기가 자연 언어 입력이 제공될 때 인공 언어 출력을 생성하도록 훈련하는 것을 포함한다."}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자연 언어로부터 인공적인 기계-판독가능 언어로의 자동 번역(변환, translation)을 위한 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에는, 점점 많은 수의 제품과 서비스들이 대용량의 데이터를 수집하고 분석하는데 의존하고 있다. 예시로는 생산(production)에서부터 상업, 과학적 연구, 헬쓰케어 및 방위에까지 사실상 모든 분야의 인간의 행위가 포함 된다. 이들은, 예를 들어서, 복수의 매장과 창고에 걸쳐서 재고, 고객 및 판매를 관리하는 소매 시스템, 대규모 의 다양한 군의 운송업체(carrier)를 관리하기 위한 물류 소프트웨어, 및 잠재 고객의 타겟 제안에 대한 사용자프로파일링에 의존하는 인터넷 광고 서비스를 포함한다. 대용량의 데이터를 관리하는 것은 개별 데이터와 상호 작용하는 시스템과 방법에서 뿐만 아니라 데이터베이스 구조에서 혁신과 발전을 가져온다. 데이터베이스의 크기 와 복잡도가 증가함에 따라서, 인간 운영자를 이용하여 데이터를 검색(search), 탐색(retrieve) 및 분석하는 것 은 빠르게 비현실적이 되어 간다. 동시에, 통상적으로 \"사물 인터넷\"으로 알려진 전자 기기의 폭발적 성장과 다양화를 우리는 목도하고 있다. 모 바일 전화기로부터 홈 어플라이언스, 웨어러블 기기, 엔터테인먼트 기기들, 및 자동차와 집 등에 설치되는 다양 한 센서와 가젯(gadget)과 같은 기기들은 대체적으로 이들의 기능을 수행하기 위하여 원격의 컴퓨터 및/또는 다 양한 데이터베이스에 연결된다. 그러한 기기 및 서비스들에 높이 요구되는 특징은 사용자 친화성이다. 그러한 제품들과 서비스들을 많은 사람들(broad audience)에게 접근가능하게 하려는 상업적 압력은 혁신적인 인간-기계 간 인터페이스의 연구와 발달을 가져오고 있다. 그러한 기술들의 일부 예들로서는, 그 중에서도 Apple의 Siri® 와 Amazon®의 Echo® 와 같은 개인 비서(personal assistant)를 포함한다."}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 특히 데이터베이스 접근 및/또는 관리를 포함하는 어플리케이션에 있어서, 인간과 컴퓨터 사이의 상호 작용을 촉진할 수 있는 시스템과 방법을 개발할 필요가 상당하다."}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 태양에 따르면, 본 발명에 따른 방법은, 인공 언어(artificial language, AL) 인코더(encoder) 및 상기 AL 인코더에 연결된 디코더(decoder)를 실행하기 위하여 상기 컴퓨터 시스템의 적어도 하나의 하드웨어 프로세서를 채용하는 것을 포함하고, 상기 AL 인코더는 인공 언어로 만들어진 입력 AL 문장의 표현을 포함하는 제1 입력 배열을 수신하고, 응답으로 제1 내부 배열을 생성하도록 구성된다. 상기 디코더는 상기 제1 내부 배열 을 수신하고, 응답으로 상기 인공 언어로 만들어진 제1 출력 AL 문장의 표현을 포함하는 제1 출력 배열을 생성 하도록 구성된다. 상기 방법은 또한, 상기 AL 인코더에 상기 제1 입력 배열을 제공하는 것에 응답으로, 상기 입 력 AL 문장과 상기 제1 출력 AL 문장 사이의 유사 정도를 나타내는 제1 유사성 스코어를 결정하는 것과, AL 인 코더 입력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제1 유사성 스코어에 따라 상기 디코더의 파라미 터들의 제1 세트를 조정하는 것을 포함한다. 상기 방법은 또한, 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것과, 응답으로, 상기 제1 단계 훈련 종료 조건이 만족되는 경우, 자연 언어(natural language, NL)로 만들어진 입력 NL 문장의 표현을 포함하는 제2 입력 배열을 수신하고, 응답으로 제2 내부 배열을 상기 디코더에 출력하도록 구성된 자연 언어(NL) 인코더를 실행하는 것을 포함한다. 상기 방법은 또한, 상기 제2 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열을 결정하는 것과(이 때, 상기 제2 출력 배열 은 상기 인공 언어로 만들어진 제2 출력 AL 문장의 표현을 포함), 상기 입력 NL 문장의 상기 인공 언어로의 변 환(translation)을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장 사이의 유사 정도를 나타내는 제2 유사성 스코어를 결정하는 것을 포함한다. 상기 방법은 또한, 상기 NL 인코더에 의해 수신된 입력의 상기 인공 언어로 의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어 에 따라 상기 NL 인코더의 파라미터들의 제2 세트를 조정하는 것을 포함한다. 본 발명의 다른 태양에 따르면, 컴퓨터 시스템은 적어도 하나의 하드웨어 프로세서 및 메모리를 포함하고, 상기 적어도 하나의 하드웨어 프로세서는 인공 언어(artificial language, AL) 인코더(encoder) 및 상기 AL 인코더 에 연결된 디코더(decoder)를 실행하도록 구성되고, 상기 AL 인코더는 인공 언어로 만들어진 입력 AL 문장의 표 현을 포함하는 제1 입력 배열을 수신하고, 응답으로 제1 내부 배열을 생성하도록 구성된다. 상기 디코더는 상기 제1 내부 배열을 수신하고, 응답으로 상기 인공 언어로 만들어진 제1 출력 AL 문장의 표현을 포함하는 제1 출력 배열을 생성하도록 구성된다. 상기 적어도 하나의 하드웨어 프로세서는 추가적으로, 상기 AL 인코더에 상기 제1 입력 배열을 제공하는 것에 응답으로, 상기 입력 AL 문장과 상기 제1 출력 AL 문장 사이의 유사 정도를 나타내 는 제1 유사성 스코어를 결정하고, AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제1 유 사성 스코어에 따라 상기 디코더의 파라미터들의 제1 세트를 조정하도록 구성된다. 상기 적어도 하나의 하드웨 어 프로세서는 추가적으로, 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하고, 응답으로, 상기 제1 단계 훈련 종료 조건이 만족되는 경우, 자연 언어(natural language, NL)로 만들어진 입력 NL 문장의 표현을 포함하 는 제2 입력 배열을 수신하고, 응답으로 제2 내부 배열을 상기 디코더에 출력하도록 구성된 자연 언어(NL) 인코 더를 실행하도록 구성된다. 상기 적어도 하나의 하드웨어 프로세서는 추가적으로, 상기 제2 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열을 결정하고, 상기 제2 출력 배열은 상기 인공 언어 로 만들어진 제2 출력 AL 문장의 표현을 포함하도록 구성된다. 상기 적어도 하나의 하드웨어 프로세서는 추가적 으로, 상기 입력 NL 문장의 상기 인공 언어로의 변환을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장 사이의 유사 정도를 나타내는 제2 유사성 스코어를 결정하고, 그리고 상기 NL 인코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어에 따라 상기 NL 인코더의 파라미터들의 제2 세트를 조정하도록 구성된다. 본 발명의 다른 태양에 따르면, 비-일시적 컴퓨터 판독가능 매체(non-transitory computer-readable medium)는 제1 컴퓨터 시스템의 제1 하드웨어 프로세서에 의하여 실행될 때, 상기 제1 컴퓨터 시스템으로 하여금 NL 인코 더 및 상기 NL 인코더에 연결된 디코더를 포함하는 훈련된 변환기(translator) 모듈을 형성하도록 하는 명령들 을 저장하고, 상기 변환기 모듈을 훈련시키는 것은, 인공 언어로 만들어진 입력 AL 문장의 표현을 포함하는 제1 입력 배열을 수신하고, 응답으로 제1 내부 배열을 생성하도록 구성되는 AL 인코더에 상기 디코더를 연결하기 위 하여, 제2 컴퓨터 시스템의 제2 하드웨어 프로세서를 채용하는 것을 포함한다. 상기 AL 인코더는 상기 디코더에 연결되어 상기 디코더가 상기 제1 내부 배열을 수신하고, 응답으로 상기 인공 언어로 만들어진 제1 출력 AL 문 장의 표현을 포함하는 제1 출력 배열을 생성한다. 상기 변환기 모듈을 훈련시키는 것은 추가적으로, 상기 AL 인 코더에 상기 제1 입력 배열을 제공하는 것에 응답으로, 상기 입력 AL 문장과 상기 제1 출력 AL 문장 사이의 유 사 정도를 나타내는 제1 유사성 스코어를 결정하는 것과, AL 인코더 입력과 디코더 출력 사이에 매치를 향상시 키기 위해 상기 제1 유사성 스코어에 따라 상기 디코더의 파라미터들의 제1 세트를 조정하는 것을 포함한다. 상 기 변환기 모듈을 훈련시키는 것은 추가적으로, 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것과, 응답으로, 상기 제1 단계 훈련 종료 조건이 만족되는 경우, 상기 NL 인코더를 상기 디코더에 연결하여 상기 NL 인코더가 자연 언어(natural language, NL)로 만들어진 입력 NL 문장의 표현을 포함하는 제2 입력 배열을 수신 하고, 응답으로 제2 내부 배열을 상기 디코더에 출력하도록 하는 것을 포함한다. 상기 변환기 모듈을 훈련시키 는 것은 추가적으로, 상기 제2 내부 배열을 수신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열 을 결정하는 것과(이 때, 상기 제2 출력 배열은 상기 인공 언어로 만들어진 제2 출력 AL 문장의 표현을 포함), 상기 입력 NL 문장의 상기 인공 언어로의 변환을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장 사이의 유사 정도를 나타내는 제2 유사성 스코어를 결정하는 것을 포함한다. 상기 변환기 모듈을 훈련시키는 것은 추가적으 로, 상기 NL 인코더에 의해 수신된 입력의 상기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어에 따라 상기 NL 인코더의 파라미터들의 제2 세트 를 조정하는 것을 포함한다. 본 발명의 다른 태양에 따르면, 컴퓨터 시스템은 NL 인코더 및 상기 NL 인코더에 연결된 디코더를 포함하는 훈 련된 변환기 모듈을 실행하도록 구성된 제1 하드웨어 프로세서를 포함하고, 상기 변환기 모듈을 훈련시키는 것 은, 인공 언어로 만들어진 입력 AL 문장의 표현을 포함하는 제1 입력 배열을 수신하고, 응답으로 제1 내부 배열 을 생성하도록 구성되는 AL 인코더에 상기 디코더를 연결하기 위하여 제2 컴퓨터 시스템의 제2 하드웨어 프로세 서를 채용하는 것을 포함한다. 상기 AL 인코더는 상기 디코더에 연결되어 상기 디코더가 상기 제1 내부 배열을 수신하고, 응답으로 상기 인공 언어로 만들어진 제1 출력 AL 문장의 표현을 포함하는 제1 출력 배열을 생성한다. 상기 변환기 모듈을 훈련하는 것은 추가적으로, 상기 AL 인코더에 상기 제1 입력 배열을 제공하는 것 에 응답으로, 상기 입력 AL 문장과 상기 제1 출력 AL 문장 사이의 유사 정도를 나타내는 제1 유사성 스코어를 결정하는 것과, AL 인코더 입력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제1 유사성 스코어에 따라 상기 디코더의 파라미터들의 제1 세트를 조정하는 것을 포함한다. 상기 변환기 모듈을 훈련하는 것은 추가적으 로, 제1 단계 훈련 종료 조건이 만족되는지 여부를 결정하는 것과, 응답으로, 상기 제1 단계 훈련 종료 조건이 만족되는 경우, 상기 NL 인코더를 상기 디코더에 연결하여 상기 NL 인코더가 자연 언어(natural language, NL) 로 만들어진 입력 NL 문장의 표현을 포함하는 제2 입력 배열을 수신하고, 응답으로 제2 내부 배열을 상기 디코 더에 출력하도록 하는 것을 포함한다. 상기 변환기 모듈을 훈련하는 것은 추가적으로, 상기 제2 내부 배열을 수 신하는 것에 응답으로 상기 디코더에 의해 생성된 제2 출력 배열을 결정하는 것을 포함하고, 상기 제2 출력 배 열은 상기 인공 언어로 만들어진 제2 출력 AL 문장의 표현을 포함한다. 상기 변환기 모듈을 훈련하는 것은 추가 적으로, 상기 입력 NL 문장의 상기 인공 언어로의 변환을 포함하는 타겟 AL 문장과 상기 제2 출력 AL 문장 사이 의 유사 정도를 나타내는 제2 유사성 스코어를 결정하는 것과, 그리고 상기 NL 인코더에 의해 수신된 입력의 상 기 인공 언어로의 개별적인 변환을 나타내는 타겟 출력과 디코더 출력 사이에 매치를 향상시키기 위해 상기 제2 유사성 스코어에 따라 상기 NL 인코더의 파라미터들의 제2 세트를 조정하는 것을 포함한다."}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 설명에서, 구조들 사이에서 언급된 모든 연결들은 직접적인 동작 연결들 (operative connections) 또는 매개 구조들을 통한 간접적인 동작 연결들일 수 있는 것으로 이해된다. 구성 요소들의 세트는 하나 이상의 구성 요소를 포함한다. 구성 요소의 임의의 열거는 적어도 하나의 구성 요소를 언급하는 것으로 이해된다. 복수의 구 성 요소는 적어도 2개의 구성 요소를 포함한다. 달리 요구되지 않는다면, 기술된 어떠한 방법 단계들도 설명된 특정 순서로 반드시 실행될 필요는 없다. 제2 구성 요소로부터 유도되는 제1 구성 요소(예컨대, 데이터)는 제2 구성 요소와 동일한 제1 구성 요소는 물론, 제2 구성 요소 그리고 선택적으로는 다른 데이터를 처리하는 것에 의해 생성된 제1 구성 요소를 포함한다. 파라미터에 따라 결정 또는 판정하는 것은 파라미터에 따라 그리고 선 택적으로는 다른 데이터에 따라 결정 또는 판정하는 것을 포함한다. 달리 구체화되지 않는다면, 일부 수량/데이 터의 표시자는 수량/데이터 그 자체, 또는 수량/데이터 그 자체와 상이한 표시자일 수 있다. 컴퓨터 프로그램은 과업을 수행하는 프로세서 명령들의 시퀀스이다. 본 발명의 일부 실시예들에서 설명되는 컴퓨터 프로그램들은 독립형 소프트웨어 개체들 또는 다른 컴퓨터 프로그램들의 서브-개체들(예를 들어, 서브루틴들, 라이브러리들) 일 수 있다. “데이터베이스”라는 용어는 본 명세서에서 데이터의 임의로 조직된 집합을 의미하기 위하여 사용 된다. 달리 특정되지 않는다면, 문장은 자연 또는 인공 언어로 만들어진 단어들 및/또는 토큰(token)들의 시퀀 스이다. 다른 언어들로 만들어진 2개의 문장들은 본 명세서에서는, 상기 2개의 문장들이 서로 의미상 균등물 (semantic equivalents)일 때, 즉 상기 2개의 문장들이 동일하거나 매우 비슷한 의미를 가질 때 서로의 변환(번 역, translation)인 것으로 생각된다. 컴퓨터 판독 가능 매체는 자성, 광, 및 반도체 저장 매체와 같은 비-일시 적 매체(non-transitory medium)(예컨대, 하드 드라이브, 광 디스크, 플래시 메모리, DRAM)는 물론, 전도성 케 이블 및 파이버 옵틱 링크와 같은 통신 링크들을 포함한다. 일부 실시예들에 따르면, 본 발명은, 그 중에서도, 본원에 설명된 방법들을 수행하기 위해 프로그래밍된 하드웨어(예컨대, 하나 이상의 프로세서들)는 물론, 본원 에서 설명된 방법들을 수행하기 위한 명령들을 인코딩하는 컴퓨터-판독 가능 매체를 포함하는 컴퓨터 시스템을제공한다. 후술하는 설명은 본 발명의 실시예들을 예시적으로 설명하는 것이며, 반드시 제한적인 것은 아니다. 도 1은 본 발명의 일부 실시예에 따른 예시적 데이터베이스 접근 및 관리 시스템을 보여준다. 복수의 클라이언 트 시스템들(12a-d)은, 예를 들어서 쿼리(query)를 실행함으로써 데이터베이스로 또는 이로부터 데이터의 세트의 접근/검색/쓰기를 하기 위하여 데이터베이스 서버와 상호 작동할 수 있다. 예시적 데이터베이스(2 0)는 특히 관계형 데이터베이스(relational database), 확장성 마크업 언어 (extensible markup language, XML) 데이터베이스, 스프레드시트, 및 키값 저장소(key-value store)를 포함한다. 예시적 클라이언트 시스템(12a-d)은 개인용 컴퓨터 시스템, 모바일 컴퓨팅 플랫폼(랩탑 컴퓨터, 태블릿, 모바일 전화기), 엔터테인먼트 장치(TV, 게임 컨솔), 웨어러블 장치(스마트워치, 피트니스 밴드), 가전 제품, 및 프로 세서, 메모리 및 통신 인터페이스를 포함하는 임의의 다른 전자 장치를 포함한다. 클라이언트 시스템(12a-d)은 통신 네트워크 상, 예를 들어서 인터넷 상에서 서버에 연결된다. 네트워크의 일부는, 가정 또는 기 업 네트워크와 같은 근거리 통신망(local area network, LAN)을 포함할 수 있다. 데이터베이스 서버는 일반 적으로 데이터베이스에 통신 가능하게 연결되고 데이터 삽입(data insertion), 데이터 검색(data retrieval), 및/또는 다른 데이터베이스 관리 작업을 수행하기 위하여 데이터베이스에 접근하도록 구성된 컴퓨팅 시스템들의 세트를 나타낸다. 상기 설명된 시스템의 하나의 예시적 적용에서, 클라이언트 시스템(12a-d)은 e-커머스 업체의 직원들에 의하여 사용되는 개인 컴퓨터를 나타내고, 데이터베이스는 각각의 업체가 판매하고 있는 제품의 레코드를 저장하는 관계형 데이터베이스(relational database)를 나타낸다. 직원들은 상기 설명된 시스템을, 예를 들어서, 특정 창 고에 특정 제품이 현재 얼마나 많이 재고로 있는지를 알기 위하여 사용할 수 있다. 일부 실시예에서, 데이터베이스로의 접근은 클라이언트 시스템(12a-d) 및/또는 데이터베이스 서버에서 실행되는 소프트웨어에 의하여 가능하게 되고, 각각의 소프트웨어는 자연 언어(예를 들어서, 영어, 중국어)로 만들어진 문장을 구조화된 쿼리 언어(structured query language, SQL), 프로그래밍 언어(예를 들어서, C++, Java®, bytecode), 및/또는 마크업 언어(markup language)(예를 들어서, XML, 하이퍼텍스트 마크업 언어 - HTML)와 같은 인공의 형식적 언어로 형성된 문장들의 세트로 자동 변환(translation, 번역)할 수 있도록 하는 변환기 요소(translator component)를 포함한다. 일부 실시예에서, 개별 변환기는 네트워크에 또한 연결된 변환기 훈련 시스템에 의해서 훈련된 신경망(neural network)의 세트와 같은 인공 지능 시스템(artificial intelligence system)을 포함한다. 상기 변환기 자체의 작동뿐만 아니라 변환기 훈련 시스템의 작동은 이하 에서 보다 상세히 설명될 것이다. 도 2a는 클라이언트 시스템의 예시적 하드웨어 구성을 보여준다. 클라이언트 시스템은 도 1의 클라이언 트 시스템들(12a-d) 중 임의의 것을 나타낼 수 있다. 일반성을 잃지 않고서, 도시된 클라이언트 시스템은 컴퓨 터 시스템이다. 다른 클라이언트 시스템(예를 들어서, 모바일 전화기, 스마트워치)의 하드웨어 구성은 도 2a에 서 도시된 것과는 다소 다를 수 있다. 클라이언트 시스템은 하드웨어 프로세서 및 메모리 유닛을 포함하는 물리적 장치들의 세트를 포함한다. 프로세서는 신호 및/또는 데이터의 세트로 산술 및/또는 논리 연산을 실행하도록 구성된 물리적 장치(예컨대, 반도체 기판에 형성된 멀티-코어 집적 회로, 마이크로프로세서 등)를 포함한다. 일부 실시예들에서, 이러한 연산들은 프로세서 명령들(예를 들어, 머신 코드 또는 다른 유형의 인코딩)의 시퀀스 형태로 프로세서에 전달된다. 메모리 유닛은 프로세서에 의해 액세스되거나 생성 되는 명령들 및/또는 데이터를 저장하는 휘발성 컴퓨터-판독 가능 매체(예컨대, DRAM, SRAM)를 포함할 수 있다. 입력 장치는 사용자가 클라이언트 시스템으로 데이터 및/또는 명령들을 도입할 수 있게 하는 개별 하드 웨어 인터페이스 및/또는 어댑터를 포함하는, 특히 컴퓨터 키보드, 마우스, 및 마이크를 포함할 수 있다. 출력 장치는 특히 모니터와 같은 디스플레이 장치 및 스피커는 물론, 클라이언트 시스템이 사용자에게 데이 터를 통신하게 할 수 있는 그래픽 카드와 같은 하드웨어 인터페이스/어댑터를 포함할 수 있다. 일부 실시예들에 서, 입력 장치와 출력 장치는 터치-스크린 장치의 경우에서와 같이 하드웨어의 공통적인 부품을 공유할 수 있다. 저장 장치는 소프트웨어 명령들 및/또는 데이터의 비휘발성 저장, 판독, 및 기록을 가능하게 하는 컴퓨터-판독 가능 매체를 포함한다. 예시적인 저장 장치는 자성 및 광 디스크들 및 플래시 메모리 장치들은 물론, CD 및/또는 DVD 디스크들 및 드라이브들과 같은 소거 가능 매체를 포함한다. 네트워크 어댑터들의 세 트는 클라이언트 시스템이 컴퓨터 네트워크 및/또는 다른 장치들/컴퓨터 시스템들에 연결될 수 있게 한다. 컨트롤러 허브는 프로세서와 장치들(24, 26, 28, 32 및 34) 사이의 통신을 가능하게 하는 복수의 시스 템, 주변, 및/또는 칩셋 버스들, 및/또는 다른 모든 회로망을 나타낸다. 예를 들어, 컨트롤러 허브는 특히메모리 컨트롤러, 입력/출력(I/O) 컨트롤러, 및 인터럽트 컨트롤러(interrupt controller)를 포함할 수 있다. 다른 예에서, 컨트롤러 허브는 프로세서를 메모리에 연결시키는 노스브리지(northbridge) 및/또는 프로세서를 장치들(26, 28, 32 및 34)에 연결시키는 사우스브리지(southbridge)를 포함할 수 있다. 도 2b는 본 발명의 일부 실시예들에 따른 변환기 훈련 시스템의 예시적 하드웨어 구성을 보여준다. 도시된 훈련 시스템은 적어도 훈련 프로세서(예를 들면, 마이크로프로세서, 멀티-코어 집적 회로), 물리적 메모리 , 훈련 저장 장치들의 세트, 및 훈련 네트워크 어댑터들의 세트를 포함하는 컴퓨터를 포함한다. 저장 장치들은 소프트웨어 명령들 및/또는 데이터의 비휘발성 저장, 판독, 및 기록을 가능하게 하는 컴퓨 터-판독 가능 매체를 포함한다. 어댑터들은 훈련 시스템이 통신 네트워크에 연결될 수 있게 하는 네트워크 카드 및 다른 통신 인터페이스를 포함할 수 있다. 일부 실시예들에서, 변환기 훈련 시스템은 클라 이언트 시스템의 입력 및 출력 장치(26 및 28)들 각각과 기능면에서 유사할 수 있는 입력 및 출력 장치들을 더 포함한다. 도 3은 본 발명의 일부 실시예들에 따른 클라이언트 시스템 상에서 실행되는 예시적인 컴퓨터 프로그램을 보여준다. 이러한 소프트웨어는 운영 시스템(operating system, OS)을 포함할 수 있고, 이에는 특히, Microsoft Windows®, MacOS®, Linux®, iOS®, 또는 Android™과 같은 임의의 널리 이용가능한 운영 시스템 이 포함될 수 있다. OS는 클라이언트 시스템의 하드웨어와, 예를 들어 변환 어플리케이션을 포함하 는 어플리케이션들의 세트 사이에 인터페이스를 제공한다. 일부 실시예들에서, 어플리케이션은 자연 언어 (natural language, NL) 문장들을 인공 언어(artificial language, AL) 문장들로, 예를 들어서, SQL 쿼리들의 세트로 그리고/또는 소프트웨어 명령들(코드)의 시퀀스로 자동으로 변환하도록 구성된다. 변환 어플리케이션 은 실제 변환(actual translation)을 수행하는 변환기 모듈(translator module, 번역기 모듈)을 포함 하고, 추가적으로, 특히 사용자로부터 (예를 들어서, 입력 장치를 통하여 텍스트나 말로서) 개별 자연 언어 문장들을 수신하는 요소들, 상기 개별 자연 언어 입력을 파스(parse)하고 분석하는 요소들(예를 들어서, 음성 파서(speech parser), 토케나이저(tokenizer), 여러 사전 등), 변환된 인공 언어 출력을 데이터베이스 서버(1 8)로 전송하는 요소들, 및 서버로부터 사용자로 응답의 콘텐트를 디스플레이하는 요소들을 포함할 수 있다. 변환기 모듈은 이하에서 상술되는 바와 같이 자연 언어-인공 언어 변환을 수행하기 위하여 변환기 훈련 시 스템에 의하여 훈련되는 인공 지능 시스템의 인스턴스(instance)를 포함한다(예를 들어서, 신경망 세트). 그러한 훈련은 변환기의 최적의 파라미터 값들, 훈련 시스템으로부터 클라이언트 및/또는 데이터베 이스 서버로 예를 들어서 주기적 또는 요청에 의한 소프트웨어 업데이트를 통하여 전송될 수 있는 값들의 세트로 귀결될 수 있다. 본 명세서에서 “훈련된 변환기(trained translator)”라는 용어는 변환기 훈련 시스템 으로부터 수신된 그러한 최적의 파라미터 값들로 인스턴스생성되는 변환기 모듈(translator module instantiated with such optimal parameter values)을 의미한다. 명료성을 위하여, 하기의 설명은 변환기 모듈이 데이터베이스 쿼리, 즉 SQL과 같은 쿼리 언어로 만들어진 문장들의 세트를 출력하는 예시적 적용에 초점을 맞출 것이다. 설명되는 시스템들과 방법들은 따라서 인간 작업 자가 데이터베이스 쿼리들을 수행할 수 있도록 하는 것에 대한 것이다. 그러나, 통상의 기술자라면 설명된 시스 템들과 방법이 변환기가 컴퓨터 코드(예를 들어서, Java®, bytecode 등), 데이터 마크업(예를 들어서, XML), 또는 임의의 다른 인공 언어로 만들어진 출력들을 생성하도록 구성되는 다른 적용예(application)로 수정되거나 적합해지게 될 수 있다는 것을 이해할 것이다. 도 4는 본 발명의 일부 실시예들에 따른 클라이언트 시스템과 데이터베이스 서버 사이의 예시적 데이터 교환을 보여준다. 클라이언트 시스템이 쿼리를 데이터베이스 서버에 전송하고, 응답으로 실행 쿼리 (executing query)의 결과를 포함하는 쿼리 결과를 수신한다. 쿼리는 서버에 의하여 실행될 때, 서버로 하여금 데이터베이스의 특정 조작(manipulation), 예를 들어서, 데이터베이스 내로/로 부터 선택적으로 삽입 또는 검색을 각각 하도록 하는, 명령들의 세트를 인코딩하는 것을 포함한다. 쿼리 결과 는, 예를 들어서, 쿼리에 따라서 데이터베이스로부터 선택적으로 검색된 데이터베이스 레코드들의 세트의 인코딩을 포함할 수 있다. 일부 실시예에서, 쿼리는 SQL과 같은 인공 언어로 형성된다. 선택적 실시예에서, 쿼리는 자연 언어 문 장들의 세트로서 형성될 수 있다. 그러한 실시예들에서, 본 명세서에서 설명되는 변환기 모듈은 데이터베이스 서버에서 실행될 수 있다. 도 5는 본 발명의 일부 실시예들에 따른 변환기 훈련 시스템의 예시적 구성요소를 설명한다. 훈련 시스템은 변환기 모듈과 변환기 모듈에 연결된 훈련 모듈의 인스턴스를 포함하는 변환기 훈련 엔진을 실행시킬 수 있다. 본 발명의 일부 실시예에서, 엔진은 변환기 모듈을 훈련시키기 위하여 훈련 모듈 에 의하여 채용되는 훈련 코퍼스(training corpora)의 세트에 통신 가능하게 연결된다. 코퍼스는 적어 도 하나의 인공 언어(AL) 훈련 코퍼스, 및/또는 자연 언어 대 인공 언어 (NL-AL, natural-language-to- artificial-language) 훈련 코퍼스(68a-b)의 세트를 포함할 수 있다. 일부 실시예에서, AL 훈련 코퍼스는 복수의 엔트리(entry)를 포함하는데, 이들은 모두 동일한 인공 언어로 형성된다. 일 예에서, 각 엔트리는, 자동으로 또는 인간 작업자에 의하여 생성된 적어도 하나의 AL(인공 언어) 문구(statement)로 구성된다. 일부 엔트리는 복수의 AL 문구 (statement)를 포함할 수 있는데, 이들의 일부는 서로의 동의어(synonym) 또는 의미상 균등물(semantic equivalents)로 생각된다. 각각의 AL이 데이터베이스 쿼 리 언어인 예에서, 2개의 AL 문구(statement)는 이들이 데이터베이스로부터 동일한 데이터의 검색을 유발할 때 동의어로 여겨질 수 있다. 유사하게, 프로그래밍 언어 예에서, 2개의 AL 문구(statement)(즉, 코드의 일부들)는 이들이 동일한 연상 결과를 생성한다면 동의어/의미상 균등물일 수 있다. 일부 실시예들에서, NL-AL 코퍼스(68a-b)는 복수의 엔트리를 포함하고, 각 엔트리는 문장들(sentence)의 투플 (예를 들어서, 쌍)로 구성되고, 적어도 하나의 문장은 인공 언어로 형성되고, 반면에 다른 문장은 자연 언어로 형성된다. 일부 실시예들에서, 상기 투플의 AL 부분은 개별 투플의 NL 부분을 인공 언어로 변환한 것을 포함한 다. 달리 설명되지 않는다면, 상기 투플의 개별 AL 부분은 상기 개별 투플의 NL 부분과 동일하거나 매우 유사한 의미를 가진다. 일부 NL-AL 투플들은 하나의 NL 문장과 복수의 동의의 AL 문장들(multiple synonymous AL sentences)로 구성될 수 있다. 다른 NL-AL 투플들은 하나의 AL 문장에 대응되는 복수의 NL 문장들을 가질 수 있 다. 특징적인(distinct) NL-AL 코퍼스(68a-b)는 특징적인 자연 언어(distinct natural languages)(예를 들어서, 영어 vs 중국어)에 대응될 수 있다. 다른 예에서, 특징적인 NL-AL 코퍼스(distinct NL-AL corpora)는 동일한 자연 언어(예를 들어서, 영어)로 만들어진 NL 문장들의 특징적 세트들을 포함할 수 있다. 하나의 그러한 예에서, 하나의 NL-AL 코퍼스는 영어를 구사하는 판매 대표에 의해서 사용되는 변환기를 훈련하는 데 사용되고, 반면에 다른 NL-AL 코퍼스는 영어를 구사하는 데이터베이스 관리자(administrator)에 의해서 사용되기 위한 변 환기를 훈련시키기 위하여 사용될 수 있다. 훈련 모듈은 원하는 출력을 생성하기 위하여, 예를 들어서, 이하에서 보다 상세히 설명되는 바와 같이, 자 연 언어 문장들을 인공 언어 문장들로 정확하게 번역하기 위하여, 변환기 모듈을 훈련하도록 구성된다. 본 명세서에서 훈련은 대체적으로 변환기 모듈의 파라미터들의 세트를 원하는 결과(예를 들어서 정확한 번역, 변환)를 달성하기 위한 노력으로 조정하는 과정을 나타낸다. 훈련을 설명하는 단계들의 예시적인 시퀀스는 도 6 에 도시되어 있다. 단계들(302 내지 304)의 시퀀스는 코퍼스 항목(corpus item)(예를 들어서, 자연 언어 문장) 을 선택하고 개별 코퍼스 항목을 변환기 모듈로 입력할 수 있다. 모듈은 그리고 나서 수신된 입력에 따 라서 출력을 생성할 수 있다. 단계는 개별 출력을 원하는 출력과 비교하고 성능 스코어(performance score), 예를 들어서, 모듈의 실제 출력과 원하는 출력 사이의 유사의 정도를 나타내는 변환(번역) 에러를 결정한다. 상기 성능 스코어를 결정하는 것에 응답으로, 단계에서 훈련 모듈은 모듈의 파라미터들 을, 변환기 모듈의 성능을 개선하는 방식으로, 예를 들어서, 변환 에러를 감소시킴으로써, 업데이트할 수"}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있다. 그러한 파라미터 조정은 본 기술분야에서 알려진 임의의 방법에 따라서 진행될 수 있다. 일부 예들은 경 사도 하강(gradient descent), 모의 어닐링(simulated annealing), 및 유전 알고리즘(genetic algorithms)을 이용하는 역전파(backpropagation)를 포함한다. 일부 실시예들은, 일부 종료 조건이 만족될 때(단계 312) 훈련 이 종료된다. 종료 조건에 대한 보다 상세한 것은 이하에서 설명된다. 일부 실시예에서는, 훈련이 종료되면, 단계에서 변환기 훈련 시스템이 변환기 파라미터 값들의 세 트를 출력한다. 모듈이 인공 신경망을 포함할 때, 변환기 파라미터 값들은, 예를 들어서, 시냅스 가중 치(synapse weight)들의 세트, 및/또는 네트워크 아키텍처 파라미터 값들(network architectural parameter values)(예를 들어서, 레이어들의 수, 레이어당 뉴런들(neurons)의 수, 연결 맵(connectivity map) 등)의 세트 를 포함할 수 있다. 파라미터 값들은 그리고 나서 클라이언트 시스템(12a-d) 및/또는 데이터베이스 서버 로 전송될 수 있고 자동화된 자연-인공 언어 변환을 수행하는 개별 로컬 변환기를 인스턴스생성 (instantiating, instantiation)을 하는데 사용될 수 있다. 도 7은 본 발명의 일부 실시예에 따른 변환기 모듈의 예시적 작동을 보여준다. 모듈은 예시적 문장(5 4)과 같은 자연 언어(NL) 문장을 예시적 문장과 같은 인공 언어(AL) 문장으로 자동으로 변환하도록 구성된 다. “문장(sentence)” 이라는 용어는 본 명세서에서 자연 또는 인공 언어로 형성된 단어들/토큰들(tokens)의 임의의 시퀀스를 나타내기 위하여 사용된다. 자연 언어의 예로는 특히 영어, 독일어, 및 중국어를 포함한다. 인 공 언어는 토큰들의 세트(예를 들어서, 키워드, 식별자(identifier), 연산자(operator))와 개별 토큰들을 결합하기 위한 규칙(rule)들의 세트를 함께 포함한다. 규칙들은 통상적으로 문법(grammar) 또는 구문(syntax)으로 알려져 있고, 대개 언어 특정적(language-specific)이다. 예시적 인공 언어는 쿼리 언어(query language) (예 를 들어서, SQL), 프로그래밍 언어(예를 들어서, C++, Perl, Java®, bytecode), 및 마크업 언어(예를 들어서, XML, HTML)과 같은 정규의 컴퓨터 언어를 포함한다. 예시적 NL 문장들은 특히 문구(statement), 질문 (question), 및 명령어(command)를 포함한다. 예시적 AL 문장은 예를 들어서 컴퓨터 코드 및 SQL 쿼리의 일부 (piece)를 포함한다. 일부 실시예에서는, 변환기 모듈은 NL 문장의 컴퓨터 판독가능한 표현을 포함하는 입력 배열(input array)을 수신하고, 상기 입력된 NL 문장을 변환한 결과의 상기 AL 문장(들)의 인코딩을 포함하는 출력 배 열(output array, 57)을 생성한다. 상기 입력 및/또는 출력 배열들은 본 기술 분야에서 알려진 임의의 방법, 예 를 들어서, 원-핫 인코딩(one-hot encoding)을 이용하여 계산된 수치 값들의 배열을 포함할 수 있다. 하나의 그 러한 예에서, NL 어휘(vocabulary)의 각 단어(word)는 특징적인 수치 라벨(distinct numerical label)이 할당 된다. 예를 들어서, 'how'라는 단어는 라벨 2를 가질 수 있고, “many”라는 단어는 라벨 37을 가질 수 있다. 그리고, 단어 'how'의 원-핫 표현(one-hot representation)은 2진수 N x 1 벡터(binary N x 1 vector)를 포함 할 수 있고, 여기서 N은 어휘의 크기이고, 모든 요소들은 값 1을 가지는 제2 요소를 제외하고는 0이다. 한편, 단어 'many'는 2진수 N x 1 벡터(binary N x 1 vector)로 표현될 수 있고, 모든 요소들은 제37번째를 제외하고 는 0이다. 일부 실시예에서, 입력 문장과 같은 단어들의 시퀀스를 인코딩하는 입력 배열은 N x M 이진 수 배열을 포함하고, 여기서 M은 입력 문장의 단어들의 수(count)를 나타내고, 입력 배열의 각 열(column) 은 입력 문장의 특징적 단어(distinct word)를 나타낸다. 입력 배열의 연속적 열들(consecutive columns) 은 입력 문장의 연속적 단어들(consecutive words)에 대응할 수 있다. 출력 배열은, 입력 및 출력을 인코딩 하기 위해 사용되는 어휘들이 서로 다를 수 있지만, 유사한 원-핫 인코딩 전략을 사용할 수 있다. 입력 배열 과 출력 배열이 입력 문장과 출력 문장을 각각 나타내기 때문에, 출력 배열은 본 명세서에 서 입력 배열의 변환으로 여겨질 것이다. NL 문장을 입력 배열로 변형하는 것은 물론, 출력 배열을 AL 문장(들)으로 변형 (transforming)하는 것은, 변환 모듈과 별개의 소프트웨어 요소들에 의하여 수행될 수 있는 파싱(parsing), 토큰화(tokenization) 등과 같은 작업(연산)을 포함할 수 있다. 일부 실시예에서는, 모듈은 설명된 변환을 수행하기 위하여 훈련된 인공 신경망과 같은 인공 지능 시스템을"}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "포함한다. 그러한 인공 지능 시스템들은 본 기술분야에서 알려진 임의의 방법을 사용하여 구성될 수 있다. 도 8 에 도시된 바람직한 실시예에서, 모듈은 인코더와 인코더에 연결된 디코더를 포함한다. 인코더 와 디코더 각각은 신경망, 예를 들어서, 순환 신경망(recurrent neural network, RNN)을 포함할 수 있 다. RNN들은 인공 신경망들의 특별 분류를 형성하는데, 망 노드들 사이의 연결이 방향 그래프(directed graph) 를 형성한다. 순환 신경망의 예들은 특히 장단기 메모리(LSTM: Long Short-Term Memory) 네트워크를 포함한다. 인코더는 입력 배열을 수신하고 입력 문장의 변환기 모듈의 고유한 내부 표현(internal representation)을 포함하는 내부 배열을 출력한다. 실제로, 내부 배열은 인코더에 특정적인 작업 들의 세트(예를 들어서, 행렬곱(matrix multiplication), 활성화 함수의 적용(application of activation functions) 등)를 통해서 입력 배열의 수학적 변형을 포함한다. 일부 실시예에서, 내부 배열의 크기는 고정되고 있고, 한편 입력 배열의 크기는 입력 문장에 따라서 변화될 수 있다. 예를 들어서, 긴 입력 문장 들은 짧은 입력 문장들과 비교하여 상대적으로 더 큰 입력 배열을 사용하여 표현될 수 있다. 이러한 관점에서 볼 때, 일부 실시예에서는 인코더가 변형 가능한 크기의 입력(variable-size input)을 개별 입력의 고정된 크기의 인코딩으로 변형한다고 말할 수 있다. 일부 실시예에서는, 디코더는 입력으로서 내부 배열을 취 하고, 수학적 연산들의 제2 세트에 의하여 출력 배열을 생성한다. 출력 배열의 크기는 내부 배열의 콘텐츠에 따라서 변화될 수 있고, 따라서 입력 문장에 따라서 변화될 수 있다. 도 9는 자동화된 NL에서 AL로의 변환을 수행하기 위하여 변환기 모듈을 훈련시키는 예시적 순서를 보여준다. 일부 실시예에서는, 훈련은 적어도 2개의 국면(stage)을 포함한다. 단계들(322-324)이 나타내는 제1 국면은 인공 언어 코퍼스(예를 들어서, 도 5의 AL 코퍼스)에서 변환기 모듈의 인스턴스를 훈련하는 것 을 포함한다. 일부 실시예에서는, 단계는 AL 입력이 주입(feeding)될 때 AL 출력을 생성하도록 변환기 모 듈을 훈련하는 것을 포함한다. 그러한 일 예에서, 변환기 모듈은 개별 인공 언어로 만들어진 입력을 재 생성(reproducing)하도록 훈련된다. 다른 예에서, 모듈은 AL 입력이 주입될 때, 개별 입력의 동의어/의미상 균등물을 생성하도록 훈련된다. 또 다른 예에서, 모듈은 그 출력이 적어도 문법적으로 옳도록, 즉 그 출력이 개별 인공 언어의 문법/구문 규칙을 준수하도록 훈련된다. 일부 실시예에서, 제1 국면의 훈련은 종료 조건(들)의 세트가 만족될 때까지(단계 324) 진행된다. 종료 조건들 은 성능 기준, 예를 들어서, 모듈의 예상되는 출력으로부터의 평균적 이탈(average departure)(즉, 변환 에 러)이 사전에 결정된 임계치(threshold)보다 작은지 여부를 포함할 수 있다. 또 다른 예시적 성능 기준은 변환 모듈의 출력이 대체적으로 문법적으로 옳은지 여부, 예를 들어서, 소정 기간의 적어도 90% (at least 90% of the time) 여부를 포함한다. 모듈의 출력이 프로그래밍 언어로 형성되는 실시예에서, 문법적 정확성을 테스트하는 것은 개별 출력을 컴파일링 시도하는 것, 개별 출력이 어떠한 컴파일 오류가 없을 때 정확하다고 결 정하는 것을 포함할 수 있다. 다른 예시적 종료 조건들은 컴퓨팅 비용 기준(computational cost criteria)을 포 함하는데, 예를 들어서 훈련이 소정의 시간 제한 또는 반복 횟수가 초과될 때까지 계속될 수 있는 것을 포함한 다. 일부 실시예들에서, 도 9에서 단계들(326-328)로 설명되는 훈련의 제2 국면은 자연 언어 대 인공 언어 코퍼스 상에서, 즉 NL-AL 투플들을 사용하여 변환기 모듈을 훈련시키는 것을 포함한다. 그러한 일 예에서, 모듈 은, 입력으로서 상기 투플의 NL 부분이 입력될 때, 상기 투플의 대응되는 AL 부분을 출력하도록 훈련된다. 선택적 실시예에서, 모듈은 개별 투플의 AL 부분의 동의어를 적어도 출력하도록 훈련될 수 있다. 상기 제2 국면의 훈련은 종료 기준이 만족될 때까지(예를 들어서, 희망하는 퍼센트의 정확한 NL에서 AL로의 변환이 달성 될 때까지) 계속될 수 있다. 다음으로, 단계에서, 변환기 훈련 시스템은 훈련으로부터 생성된 변환기 파라미터 값들을 출력할 수 있다. 변환기 모듈이 신경망을 사용하는 예시적 실시예에서, 파라미터 값들 은 훈련을 통하여 얻어진 시냅스 가중치(synapse weight)들의 값들을 포함할 수 있다. 도 10은 본 발명의 바람직한 실시예에서 제1 국면 훈련을 추가적으로 설명한다. 도시된 제1 국면 변환기 모듈 (62a)은 디코더에 연결된 인공 언어 인코더(70a)를 포함한다. AL 인코더(70a)는 입력 배열(55a)을 가져가고 내부 배열(59a)을 출력하고, 이것은 다시 디코더에 의하여 출력 배열(57a)로 변형된다. 일부 실시예에서, 제1 국면 훈련은 변환 모듈(62a)에게 복수의 AL 입력을 제공하는 것, 및 제공된 입력들 각각과 유사한 AL 출력 을 생성하도록 모듈(62a)의 파라미터를 튜닝(tuning)하는 것을 포함한다. 달리 설명되지 않는다면, 일부 실시예 에서는, 제1 국면 훈련의 목표는 출력을 보다 입력에 유사하게 만드는 것일 수 있다. 선택적 실시예에서, 훈련 의 목표는 출력이 개별 입력과 적어도 동의어인 것이거나, 또는 출력이 개별 인공 언어에서 문법적으로 옳은 것 일 수 있다. 제1 국면 훈련의 일예에서, 입력/출력 배열들의 각 쌍에 대해서, 훈련 모듈은 출력과 입력 배열들(도 10에 서 각각 57a 및 55a) 사이의 유사의 정도를 나타내는 유사성 지표(similarity measure)를 계산할 수 있다. 유사 성 지표는 본 기술 분야에서 알려진 임의의 방법을 사용하여, 예를 들어서, 입력 및 출력 배열들 사이의 맨하탄 또는 르벤슈타인 거리(Manhattan or Levenshtein distance)에 따라서 연산될 수 있다. 그리고 나서 훈련 모듈 은 AL 인코더(70a) 및/또는 디코더의 파라미터들을 조정하여 AL 인코더(70a)의 입력들과 디코더의 출력들 사이의 유사도를 증가시킬 수 있다. 예를 들어서 배열들(55a 및 57a) 사이의 평균 맨하탄 거리를 감소시 킬 수 있다. 제1 국면 훈련은 제1 국면 종료 조건(들)이 만족될 때까지(예를 들어서, 소정의 성능 레벨이 달성될 때까지, AL 코퍼스들의 모든 구성요소들이 훈련에서 사용될 때까지, 등) 계속될 수 있다. 도 11a는 제1 국면 훈련에서 사용되는 인공 언어와 자연 언어 사이를 변환하기 위한 훈련을 포함하는 예시적 제 2 국면 훈련 프로세스를 보여준다. 일부 실시예들에서, 제1 국면에서 제2 국면으로의 진행(progressing)은 AL 인코더(70a)를 자연 언어 인코더(70b)로 대체함으로써 얻어지는 제2 국면 변환기 모듈(62b)로 전환하고, 한편으 로는 이미 훈련된 디코더를 유지하는 것을 포함한다. 달리 설명되지 않는다면, 디코더는 제1 국면 훈련 으로부터 생성되는 파라미터 값들로 인스턴스생성되는 것(instantiating with the parameter values resulting from first-stage training)이 유지된다. NL 인코더(70b)의 아키텍처(architecture) 및/또는 파라미터 값들은 AL 인코더(70a)의 것과 실질적으로 상이할 수 있다. 그러한 차이의 한 이유는 인공 및 자연 언어들의 어휘가 통 상적으로 서로 달라서, NL 문장들을 나타내는 입력 배열들이 AL 문장들을 나타내는 입력 배열들과 적어도 크기 에서 상이할 수 있다. 인코더(70a-b)가 특징적인 아키텍처들을 가질 수 있는 다른 이유는 인공 언어의 문법/구 문이 통상적으로 자연 언어의 그것과 실질적으로 다르기 때문이다. NL 인코더(70b)는 NL 문장을 나타내는 입력 배열(55b)을 취하고(taking) 내부 배열(59b)을 출력한다. 일부 실시 예에서, 내부 배열(59b)은 변환 모듈(62a)의 AL 인코더(59a)에 의하여 출력된 내부 배열(59a)과 동일한 크기 및 /또는 구조를 가진다(도 10 참조). 내부 내열(59b)은 그리고 나서 입력으로서 디코더로 주입되고 이것이다시 AL 문장을 나타내는 출력 배열(57c)을 생성한다. 일부 실시예에서, 제2 국면 훈련은 NL-AL 투플들을 사용하고, 상기 투플의 AL 부분은 각 투플의 NL 부분의 타겟 AL로의 변환을 나타낸다. 제2 국면 훈련은 NL 인코더(70b)에 복수의 NL 입력들을 제공하는 것을 포함할 수 있고 (각 NL 입력은 NL-AL 투플의 NL 부분을 포함한다), 또한 변환기 모듈(62b)의 파라미터들을 튜닝(tuning)하는 것 을 포함해서 디코더의 출력이 NL-AL 투플의 개별 투플의 AL 부분과 유사하게 될 수 있다. 달리 설명되지 않 는다면, 제2 국면 훈련의 목표는 디코더의 출력들이 개별 NL 입력들의 타겟 AL로의 변환과 보다 유사하게 만드는 것이다. 하나의 예시적 실시예에서, (도 11a에서 배열(55b)로서 표현되는) 각 투플의 NL 부분을 NL 인코더(70b)로 주입 하는 것에 대한 응답으로, 모듈을 훈련하는 것은 디코더의 출력(배열 57c)과 개별 투플의 AL 부분(배열 57b)을 비교할 수 있다. 상기 비교는 배열들(57b과 57c) 사이의 유사도의 정도를 나타내는 유사도 지표를 계산 하는 것을 포함할 수 있다. 훈련 모듈은 그리고 나서 배열들(57b과 57c) 사이의 유사도를 증가시키는 방향 으로 NL 인코더(70b) 및/또는 디코더의 파라미터들을 조정할 수 있다. 제2 국면 훈련을 위한 선택적 시나리오는 도 11b에 도시되어 있다. 이러한 선택적 시나리오는, NL 인코더(70b) 와, 제1 국면 훈련에서 획득된 (훈련된) AL 인코더(예를 들어서, 제1 국면 훈련으로부터 생성된 파라미터 값들 로 인스턴스생성된 도 10의 AL 인코더(70a)) 모두를 채용한다. 일부 실시예들에서, NL 인코더(70b)는 NL-AL 투 플의 NL 부분을 나타내는 입력 배열(55b)이 주입되고, 한편 AL 인코더는 각 투플의 AL 부분을 나타내는 출력 배 열(57b)이 주입된다. 상기 방법은 디코더가 이후 개별 AL 입력으로 다시 변형할 수 있는 '적절한' 내부 배 열(59c)로 AL 입력을 변형하도록 AL 인코더(70a)가 이미 제1 국면 훈련 중에 구성되었다는 점에 의존한다. 달리 설명되지 않는다면, 디코더가 출력 배열(57a)을 생성하기 위하여, 그 입력은 (이미 훈련된) AL 인코더(70 a)의 출력과 가능한 근접해야만 한다. 따라서, 도 11b에 도시된 실시예에서, 훈련 모듈은 NL 인코더의 출력(즉, 내부 배열(59b))을 내부 배열(59c)과 비교할 수 있고, 유사도 지표로서 그 차이를 수량화(quantify)할 수 있다. 훈련 모듈은 그리고 나서 배열들(59b과 59c) 사이의 유사도를 증가시키는 방향으로 NL 인코더 (70b) 및/또는 디코더의 파라미터들을 조정할 수 있다. 도 12는 본 발명의 일부 실시예에 따른 복수의 훈련 코퍼스(corpora)에서 변환기 모듈을 훈련시키기 위한 단계들의 예시적 시퀀스를 보여준다. 설명된 방법은, 디코더가 각 타겟 인공 언어에 대하여 딱 한 번만 훈 련되고(상기의 제1 국면 훈련 참조), 그리고 나서 복수의 변환기 모듈들을, 예를 들어서 복수의 원시 자연 언어 들(source natural languages)(예를 들어서, 영어, 독일어 등)로부터 개별 타겟 인공 언어(예를 들어서, SQL) 로 변환할 수 있는 모듈들을 도출하기 위하여 이미 훈련된 형태로 재사용될 수 있는 점에 의지한다. 다른 예에서, 각각의 특징적인 변환기 모듈은 동일한 자연 언어(예를 들어서, 영어)로 만들어진 NL 문장들의 특 징적인 세트에서 훈련될 수 있다. 이러한 구체적인 실시예는, 언어가 통상적으로 특화되어 있고 작업에 특정 (task-specific)되어 있다는 점, 즉 인간 작업자들이 특정 문제를 풀기 위하여 사용하는 문장들/명령어들이 다 른 환경에서 사용되는 문장들/명령어들과 상이하다는 점에 의존한다. 따라서, 일부 실시예들은 판매원 (salesperson)에 의하여 사용되는 변환기를 훈련하기 위하여 하나의 코퍼스(즉, NL 문장들의 세트)를 채용하고, 기술자 스탭에 의하여 사용되는 변환기를 훈련하기 위하여 또 다른 코퍼스를 채용한다. 도 12의 단계들(342-344)은 AL 인코더(70a) 및/또는 디코더를 훈련시키는 것을 포함하는 제1 국면 훈련 프 로세스를 보여준다. 성공적인 제1 국면 훈련에 응답으로, 단계는 AL 인코더(70a)를 NL 인코더로 대체한다. 일부 실시예들에서, 상기 NL 인코더의 제2 국면 훈련은 그리고 나서 각각의 이용가능한 NL-AL 코퍼스에 대하여 수행된다. 하나의 NL-AL 코퍼스로부터 다른 것으로 전환될 때(예를 들어서, 영어에서 스페인어로 또는 \"판매 영 어\"에서 \"기술 영어\"로 전환될 때), 일부 실시예들은 기존의 NL 인코더를 현재 NL-AL 코퍼스에 적합한 새로운 NL 인코더로 교체하고(단계 358), 한편 이미 훈련된 디코더를 유지한다. 그러한 최적화는 자동 변환기들의 훈련을 실질적으로 촉진하고 가속화할 수 있다. 일부 실시예에서, 제2 국면 훈련은 단지 NL 인코더(70b)의 파라미터들을 조정하고(그림 11a 내지 11b 참조), 한 편 제1 국면 훈련을 통하여 얻어진 값(들)에 고정된 디코더의 파라미터들을 유지한다. 그러한 훈련 전략은 원시 자연 언어 또는 NL-AL 코퍼스의 선택에 관계없이 제1 국면 훈련을 통하여 달성된 레벨에서 디코더의 성능을 유지하려는 목적이다. 훈련이 NL 인코더(70b) 및 디코더 모두의 파라미터들을 조정하는 것을 포함하 는 다른 실시예에서, 단계는 제1 국면 훈련의 종료에서 얻어진 값들과 디코더의 파라미터들을 리셋하 는 것을 추가적으로 포함할 수 있다. 상술한 예시적인 시스템들과 방법들은 영어와 같은 원시 자연 언어로부터 타겟 인공 언어(예를 들어서, SQL, 프 로그래밍 언어, 마크업 언어 등)로 자동 변환이 가능하게 한다. 본 발명의 일부 실시예들의 하나의 예시적 적용 은 평범한 사람이 SQL과 같은 쿼리 언어의 지식의 필요 없이도 자연 언어로 만들어진 평이한 질문들을 이용하여 데이터베이스 쿼리를 수행할 수 있게 한다. 예를 들어서, 판매 작업자가 클라이언트 머신에 \"how many customers under 30 do we have in Colorado ? (우리가 콜로라도에 30세 이하의 고객을 얼마나 많이 가지고 있 나요?)\"라고 물을 수 있다. 응답으로, 상기 머신은 각각의 질문을 데이터베이스 쿼리로 변환하고 개별 쿼리를 실행하여 상기 작업자의 질문에 대한 답을 도출(retrieve)할 수 있다. 일부 실시예들은 변환기 모듈을 사용하여 단어들의 NL 시퀀스를 AL 문장으로, 예를 들어서 데이터베이스로부터 데이터를 선택적으로 검색하는데 사용할 수 있는 유효한 쿼리(valid query)로 변환한다. 변환기 모듈은 인코더 네트워크와 디코더 네트워크와 같은 인공 신경망의 세트를 포함할 수 있다. 인코더와 디코더는 순환 신경망 (RNN) 또는 임의의 다른 인공 지능 기술을 이용하여 구현될 수 있다. 일부 실시예에서, 변환기 모듈을 훈련하는 것은 적어도 2개의 국면을 포함한다. 제1 국면에서, 변환기 모듈은 AL 입력에 응답으로 AL 출력을 생성하도록 훈련된다. 예를 들어서, 제1 국면 훈련은 AL 입력을 재생성하기 (reproduce) 위하여 변환기 모듈을 훈련하는 것을 포함할 수 있다. 선택적 실시예에서, 변환기는 AL 입력에 응 답으로 문법적으로 정확한 AL 문장들을 생성하도록 훈련된다. 편리한 메타포어(metaphor)를 사용하여, 제1 국면 훈련은 변환기 모듈이 개별 인공 언어를 \"말하도록\" 교육한다고 애기할 수 있다. 실제로, 제1 국면 훈련은 변환 기에게 막대한 코퍼스의 AL 문장들(예를 들어서, SQL 쿼리들)을 제공하는 것을 포함한다. 각 입력 문장에 대하 여, 변환기 출력은 성능 스코어를 결정하기 위하여 평가되고, 변환기의 파라미터들은 훈련 시 변환기의 성능을 향상시키도록 조정된다. 그 다음의 제2 국면은 원시 언어로 만들어진 NL 입력에 응답으로 AL 출력을 생성하기 위하여 변환기 모듈을 훈 련하는 것을 포함한다. 제2 국면의 훈련은 복수의 문장 투플들(예를 들어서, 쌍(pairs))을 포함하는 NL-AL 코퍼 스를 채용할 수 있고, 각 투플은 적어도 NL 부분(NL side)과 AL 부분(AL side)을 가진다. 예시적 실시예에서, 투플의 각 AL 부분은 각각의 NL 부분의 변환, 즉 투플의 각각의 NL 부분이 주어졌을 때 변환기의 희망하는 출력 을 나타낼 수 있다. 예시적 제2 국면 훈련은 다음과 같이 진행된다. 각각의 NL-AL 투플에 대하여 변환기는 입력 으로서 NL 부분을 수신한다. 변환기의 출력은 변환 에러를 결정하기 위하여 투플의 AL 부분과 비교되고, 변환기 의 파라미터들은 변환 에러를 줄이기 위하여 조정된다. 종래의 자동 변환기들은 통상적으로 쌍을 이루는 항목들을 이용하여 훈련되고, 상기 쌍의 한 요소는 원시 언어 로 만들어지는 반면 상기 쌍의 다른 요소는 타겟 언어로 만들어진다. 그러한 종래의 훈련이 당면하는 하나의 기 술적 장애는 훈련 코퍼스의 크기이다. 코퍼스가 더 크고 더 다양할수록 보다 강력하고 성능이 좋은 변환기를 생"}
{"patent_id": "10-2020-7036850", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "성한다는 것은 본 기술분야에서 널리 인정되고 있다. 합리적인 변환 성능을 달성하는 것은 수만의 NL-AL 투플들 또는 그 이상이 필요 할 수 있다. 그러나 NL-AL 투플들이 일반적으로 자동으로 생성될 수 없기 때문에, 그러한 대형 코퍼스를 세팅하기 위하여 필요한 숙련된 인간 작업량은 비현실적이다. 반대로, AL 문장들은 많은 수가 자동으로 생성될 수 있다. 본 발명의 일부 실시예들은 이 점을 채용하여 성능을 향상시키고, 훈련을 촉진하고, 변환기 모듈의 출시 기간(time-to-market)을 단축한다. 제1 국면의 훈련은 상대 적으로 크고 자동적으로 생성된 AL 코퍼스에서 실행되고 타겟 인공 언어로 문법적으로 정확한 AL 문장들을 신뢰 할 수 있게 생성할 수 있는 부분적으로 훈련된 변환기를 가져온다. 제2 국면의 훈련은 그리고 나서 보다 중간 규모의 NL-AL 코퍼스에서 수행될 수 있다. 본 명세서에서 설명된 바와 같은 이러한 2 단계 훈련의 다른 장점은 복수의 NL-AL 변환기들이 서로에 대해서 독 립적으로 제1 국면 훈련을 반복할 필요 없이 개발될 수 있다는 것이다. 변환기 모듈의 디코더 부분은 따라서 복 수의 변환기들에서 그대로(즉, 재훈련 없이) 재사용될 수 있고, 이것은 이들의 개발 비용과 시장 출시 시간을 실질적으로 감소시킬 수 있다. 각각의 그러한 특징적인 변환기는 예를 들어서 영어, 독일어, 및 중국어와 같은 특징적인 원시 자연 언어에 대응될 수 있다. 다른 예에서, 각각의 특징적인 변환기는 동일한 자연 언어(예를 들 어서, 영어)의 문장들의 다른 세트에서 훈련될 수 있다. 그러한 상황은 각 변환기가 특징적인 과업/적용에 대해 서 채용될 때, 예를 들어서 하나의 변환기는 판매에서 사용되고 한편 다른 것은 데이터베이스 관리에서 사용될 때 발생할 수 있다. 본 발명의 설명의 많은 부분이 자연 언어로부터 SQL과 같은 쿼리 언어로 자동 변환을 하기 위한 훈련에 대해서 할애되었지만, 통상의 기술자라면 설명된 시스템과 방법들이 다른 적용예나 인공 언어들에 적용될 수 있다는 것 을 이해할 것이다. 선택적인 쿼리 언어는 SPARQL 및 다른 자원 기술 포맷(resource description format, RDF)쿼리 언어들을 포함한다. 그러한 변환들의 예시적인 적용예들은, 예를 들어서 월드 와이드 웨브(World Wide Web) 및/또는 Wikipedia®와 같은 이종 지식 베이스(heterogeneous knowledgebases)로부터 정보를 도출하기 위 하여 RDF로 표현된 데이터로의 접근을 용이하게 하는 것을 포함한다. 본 발명의 일부 실시예들의 또 다른 예시 적 적용예는 예를 들어서 이종 데이터를 자동으로 조직/구조화화기 위하여, 또는 프로그래밍이나 쿼리 언어에 대한 특별한 지식을 가지지 않고서도 지식 베이스로 데이터를 도입하기 위하여, RDF 코드를 자동으로 생성하는 것이다. 타겟 언어가 프로그래밍 언어인 일부 실시예들의 적용예는 특히 인간-기계 상호작용을 가능하게 하는 코드(예를 들어서, 쉘 스크립트)를 자동으로 생성하는 것을 포함할 수 있다. 예를 들어서, 사용자는 머신에 작업(예를 들 어서, 전화기 번호로 전화하는 것, 웹페이지에 접속하는 것, 객체를 인출하는 것(fetch an object) 등)을 수행 하라고 요청할 수 있다. 자동 변환기(자동 번역기, automatic translator)는 개별 NL 명령(command)을 사용자 의 명령을 수신하는 것에 응답으로 실행될 수 있는 컴퓨터 판독가능한 명령의 세트로 변환할 수 있다. 다른 예 시적 적용예들은 2개의 특징적인 프로그래밍 언어들(예를 들어서, python 부터 Java®까지) 사이의 코드를 자동 변환하는 것과, 리치 미디어(rich media)(예를 들어서, 이미지와 비디오에 주석 달기(annotating))를 자동으로 처리하는 것을 포함한다. 또 다른 예에서는, 악성 소프트웨어를 탐지하는 데 특화되어 있는 일부 컴퓨터 보안 제공자들은 멀웨어 탐지 루 틴(malware detection routine) 및/또는 멀웨어를 가리키는 시그너처(signature)들을 인코딩하기 위하여 특화 된 프로그래밍 언어(dedicated programming language)(bytecode의 버전)를 사용한다. 본 발명의 일부 실시예들 은 작업자들이 바이트코드에 대한 특수한 지식 없이도 바이트코드 루틴을 자동으로 생성할 수 있도록 함으로써 그러한 안티-멀웨어 연구와 개발을 용이하게 할 수 있게 한다. 상기의 실시예들이 본 발명의 범위를 벗어나지 않는다면 다양한 방법으로 변경될 수 있음은 통상의 기술자에게 당연한 것이다. 따라서 본 발명의 범위는 이하의 청구항과 그들의 법적 균등물에 의해서 결정되어야 한다.도면 도면1 도면2a 도면2b 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11a 도면11b 도면12"}
{"patent_id": "10-2020-7036850", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 전술한 태양들 및 장점은 후술하는 상세한 설명 및 도면을 참조로 이해하면 더욱 잘 이해될 것이다. 도 1은 예시적 자동화된 데이터베이스 접근 시스템을 보여주는 도면으로서, 본 발명의 일부 실시예에 따라서 클 라이언트의 세트는 변환기 훈련 시스템과 데이터베이스 서버와 협력한다. 도 2a는 본 발명의 일부 실시예에 따른 클라이언트 시스템의 예시적인 하드웨어 구성을 보여주는 도면이다. 도 2b는 본 발명의 일부 실시예에 따른 변환기 훈련 시스템의 예시적인 하드웨어 구성을 보여주는 도면이다. 도 3은 본 발명의 일부 실시예에 따른 클라이언트 시스템에서 실행되는 예시적 소프트웨어 요소들의 세트를 보 여주는 도면이다. 도 4는 본 발명의 일부 실시예에 따른 클라이언트 시스템과 상기 데이터베이스 서버 사이의 예시적 데이터 교환 을 보여주는 도면이다. 도 5는 본 발명의 일부 실시예에 따른 변환기 훈련 시스템의 예시적 요소를 보여주는 도면이다. 도 6은 본 발명의 일부 실시예에 따른 예시적 변환기 훈련 절차를 보여주는 도면이다. 도 7은 본 발명의 일부 실시예에 따른 변환기 모듈의 예시적 작동을 보여주는 도면이다. 도 8은 본 발명의 일부 실시예에 따른 상기 변환기 모듈의 예시적 요소와 작동을 보여주는 도면이다. 도 9는 본 발명의 일부 실시예에 따른 상기 변환기 훈련 시스템에 의하여 수행되는 단계들의 예시적 순서를 보 여주는 도면이다. 도 10은 본 발명의 일부 실시예에 따른 상기 변환기 모듈을 훈련시키는 예시적 제1 국면(stage)을 보여주는 도 면이다. 도 11a는 본 발명의 일부 실시예에 따른 상기 변환기 모듈을 훈련시키는 예시적 제2 국면(stage)을 보여주는 도 면이다. 도 11b는 본 발명의 일부 실시예에 따른 상기 변환기 모듈을 훈련시키는 다른 예시적 제2 국면(stage)을 보여주 는 도면이다. 도 12는 본 발명의 일부 실시예에 따른 복수의 훈련 코퍼스(corpora)에서 변환기 모듈을 훈련시키기 위한 단계 들의 예시적 시퀀스를 보여주는 도면이다."}
