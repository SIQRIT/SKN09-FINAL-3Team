{"patent_id": "10-2023-0073916", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0174545", "출원번호": "10-2023-0073916", "발명의 명칭": "대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법", "출원인": "주식회사 뉴엔에이아이", "발명자": "김광수"}}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 복수의 문서를 수집하는 단계;(b) 상기 복수의 문서를 클러스터링하는 단계;(c) 상기 클러스터링으로 생성된 복수의 클러스터 각각의 대표 문서를 결정하는 단계; 및(d) 상기 결정된 대표 문서를 기초로 상기 복수의 클러스터 각각의 토픽을 생성하는 단계;를 포함하는,대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법."}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 (b)는,(b-1) 상기 복수의 문서 각각에 대응되는 임베딩 벡터를 획득하는 단계; 및(b-2) 상기 임베딩 벡터를 이용해 상기 복수의 문서를 클러스터링하는 단계;를 포함하는, 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법."}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 (b-2)는, 상기 임베딩 벡터에 HDBSCAN(Hierarchical DBSCAN, Density based Spatial Clustering of Applications withNoise) 알고리즘을 적용해 상기 복수의 문서를 클러스터링하는 단계;를 포함하는, 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법."}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 (c)는, 상기 복수의 클러스터 각각에 포함된 문서들의 속성을 고려해 상기 복수의 클러스터 각각의 상기 대표 문서를결정하는 단계;를 포함하는, 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법."}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서, 상기 문서들의 속성은 상기 문서들의 중요도를 나타내는 영향력 지수 및 상기 문서들 각각에 대응되는 포인트가대응되는 클러스터에 포함될 확률을 나타낸 확률 지수 중 적어도 하나를 포함하는,공개특허 10-2024-0174545-3-대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법."}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서, 상기 (d)는,토픽생성모델을 이용해 상기 결정된 대표 문서로부터 상기 복수의 클러스터 각각의 토픽을 생성하는 단계;를 포함하고, 상기 토픽생성모델은 학습용 문서에 기초해 학습용 토픽을 분류하도록 전이 학습된 모델인,대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법."}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,(e) 상기 복수의 클러스터 각각에 포함된 문서들의 개수의 변화를 시계열적으로 나타낸 그래프를 출력하는단계;를 더 포함하는, 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법."}
{"patent_id": "10-2023-0073916", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제어부; 및상기 제어부에 의해 실행 가능한 명령어들을 저장하는 저장부;를 포함하고, 상기 제어부는, 상기 명령어들을 실행함으로써, 복수의 문서를 수집하고, 상기 복수의 문서를 클러스터링하며, 상기 클러스터링으로 생성된 복수의 클러스터 각각의 대표 문서를 결정하고, 상기 결정된 대표 문서를 기초로 상기 복수의 클러스터 각각의 토픽을 생성하는,대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 장치."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따라 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법은 (a) 복수의 문서를 수집하는 단계; (b) 상기 복수의 문서를 클러스터링하는 단계; (c) 상기 클러스터링으로 생성된 복수의 클러스터 각각의 대표 문서를 결정하는 단계; 및 (d) 상기 결정된 대표 문서를 기초로 상기 복수의 클러스터 각각의 토픽을 생성하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법 및 토 픽 결정 장치에 관한 것으로, 보다 구체적으로, 대용량 문서를 클러스터링하여 클러스터들을 생성하고, 생성한 클러스터들을 이용해 문서의 토픽을 결정하는 방법을 제공하기 위한, 대규모 언어 기반의 인공지능모델을 이용 한 대용량 문서의 클러스터링에 따른 토픽 결정 방법 및 토픽 결정 장치에 관한 것이다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "회사 및 브랜드의 운영 또는 신규 런칭에 있어 시대의 흐름과 대중의 선호도를 반영하기 위해서 소셜 빅데이터 를 분석하여 이슈나 토픽을 도출하고 트렌드를 분석하는 과정이 필요하다. 이 같은 과정은 종래에 데이터의 단 어의 빈도를 통계적으로 분석하여 토픽을 유추하는 과정으로 진행되어(예> LDA) 작업자의 직관이 필연적으로 개 입되어야 했으며 그로 인해 원하는 결과를 도출하기까지 많은 시간과 노력이 필요하며, 작업자의 능력과 성향에따라 결과의 일관성이 없고 객관성이 떨어지는 문제가 있다. 또한, 상기 방식의 경우, 다양한 토픽에 영향을 미치는 여러 요소들을 모두 반영할 수 없다는 문제가 있으며, 자연어의 관용적 표현, 반어적 표현, 중의적 표현 등의 뉘앙스와 문화를 반영한 결과를 도출하는 것은 불가능한 문제가 있다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 개선하기 위해 도출된 것으로, 컨텍스트 기반 대용량 언어 모델을 이용해 획득된 임 베딩 벡터를 기초로 대용량 문서를 클러스터링하고, 클러스터링한 결과를 이용해 토픽을 자동 생성하도록 함으 로써, 컨텍스트에 기반한 토픽 생성 결과를 획득할 수 있도록 하는 데에 그 목적이 있다. 본 발명에 따르면, 단어의 빈도를 이용한, 즉, 개별 단어를 통한 임베딩값을 통한 단어 사이의 단순 유사성 비 교가 아닌, 문서 기반의 토픽 생성이 가능하도록 함으로써, 즉, 문서 자체의 임베딩값을 통한 문서 사이의 유사 성 비교를 통해 문서 기반의 토픽 생성이 가능하도록 함으로써, 문서 사이의 전반적이고 통합적이며 직관적인 컨텍스트 기반 분석이 수행될 수 있고, 이로써 유사성 판단의 정확도가 높아질 수 있으며, 해당 유사성에 기초 한 토픽 생성이 가능해지도록 하는 데에 그 목적이 있다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따라 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 방법은 (a) 복수의 문서를 수집하는 단계; (b) 상기 복수의 문서를 클러스터링하는 단계; (c) 상기 클러스터링으로 생성된 복수의 클러스터 각각의 대표 문서를 결정하는 단계; 및 (d) 상기 결정된 대표 문서를 기초로 상기 복수의 클러스터 각각의 토픽을 생성하는 단계;를 포함할 수 있다. 상기 (b)는, (b-1) 상기 복수의 문서 각각에 대응되는 임베딩 벡터를 획득하는 단계; 및 (b-2) 상기 임베딩 벡터를 이용해 상기 복수의 문서를 클러스터링하는 단계;를 포함할 수 있다. 상기 (b-2)는, 상기 임베딩 벡터에 HDBSCAN(Hierarchical DBSCAN, Density based Spatial Clustering of Applications with Noise) 알고리즘을 적용해 상기 복수의 문서를 클러스터링하는 단계;를 포함할 수 있다. 상기 (c)는, 상기 복수의 클러스터 각각에 포함된 문서들의 속성을 고려해 상기 복수의 클러스터 각각의 상기 대표 문서를 결정하는 단계;를 포함할 수 있다. 상기 문서들의 속성은 상기 문서들의 중요도를 나타내는 영향력 지수 및 상기 문서들 각각에 대응되는 포인트가 대응되는 클러스터에 포함될 확률을 나타낸 확률 지수 중 적어도 하나를 포함할 수 있다. 상기 (d)는, 토픽생성모델을 이용해 상기 결정된 대표 문서로부터 상기 복수의 클러스터 각각의 토픽을 생성하는 단계;를 포 함하고, 상기 토픽생성모델은 학습용 문서에 기초해 학습용 토픽을 분류하도록 전이 학습된 모델일 수 있다. (e) 상기 복수의 클러스터 각각에 포함된 문서들의 개수의 변화를 시계열적으로 나타낸 그래프를 출력하는 단계;를 더 포함할 수 있다.실시예에 따른 대용량 문서의 클러스터링을 통한 토픽 결정 장치는 제어부; 및 상기 제어부에 의해 실행 가능한 명령어들을 저장하는 저장부;를 포함하고, 상기 제어부는, 상기 명령어들을 실행함으로써, 복수의 문서를 수집하고, 상기 복수의 문서를 클러스터링하며, 상기 클러스터링으로 생성된 복수의 클러스터 각 각의 대표 문서를 결정하고, 상기 결정된 대표 문서를 기초로 상기 복수의 클러스터 각각의 토픽을 생성할 수 있다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 컨텍스트 기반 대용량 언어 모델을 이용해 획득된 임베딩 벡터를 기초로 대용량 문서를 클러 스터링하고, 클러스터링한 결과를 이용해 토픽을 자동 생성하도록 함으로써, 컨텍스트에 기반한 토픽 생성 결과 를 자동 획득할 수 있게 되고, 이로서, 작업자의 개입과 비용이 상당히 감소될 수 있게 된다. 본 발명에 따르면, 문서 자체의 임베딩값을 통한 문서 사이의 유사성 비교를 통해 문서 기반의 토픽 생성이 가 능하도록 함으로써, 문서 사이의 전반적이고 통합적이며 직관적인 컨텍스트 기반 분석이 수행될 수 있고, 이로 써 유사성 판단의 정확도가 높아질 수 있으며, 해당 유사성과 클러스터링에 기초한 토픽 생성으로, 각 클러스터 를 대표하는 토픽의 정확도가 높아질 수 있게 된다. 본 발명에 따르면, 대용량 문서를 토픽별로 분류하여 사용자에게 모든 토픽을 한눈에 볼 수 있도록 표시할 수 있게 되고, 시간별 토픽 분류에 따라 토픽의 트렌드를 사용자에게 제공할 수 있게 된다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시 예로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미 로서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모 든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하 거나 유사한 기능을 지칭한다. 도 1은 실시예에 따른 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 장치의 블록도이다. 실시예에 따른 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 장치 는 제어부, 저장부, 및 사용자 인터페이스부를 포함할 수 있다. 제어부는 대규모 언어 기반의 인공지능모델을 이용한 대용량 문서의 클러스터링에 따른 토픽 결정 장치 의 전체 기능을 제어한다. 실시예에 따라, 제어부는 복수의 문서를 수집하고, 상기 복수의 문서를 클러스터링하며, 상기 클러스터링으 로 생성된 복수의 클러스터 각각의 대표 문서를 결정하고, 상기 결정된 대표 문서를 기초로 상기 복수의 클러스터 각각의 토픽을 결정할 수 있다. 저장부는 수집데이터DB, 임베딩모델, 및 토픽생성모델을 포함할 수 있다. 수집데이터DB는 대용량 문서의 클러스터링을 통한 토픽 결정 장치가 외부 장치(미도시)로부터 수집한 문 서를 저장할 수 있다. 임베딩모델은 버트(BERT), 지피티(GPT) 등 트랜스포머(Transformer)에 기반한 모델일 수 있다. 토픽생성모델은 학습용 문서에 기초해 학습용 토픽을 분류하도록 학습된 모델로, 제어부에 의해 학습 및 생성되어 저장부에 저장될 수 있다. 사용자 인터페이스부는 제어부의 처리 결과를 사용자에게 제공하는 것으로, 실시예에 따라, 제어부(1 0)에 의해 복수의 클러스터 각각에 포함된 문서들의 개수의 변화를 시계열적으로 나타낸 그래프를 출력할 수 있 다. 도 2 및 도 3은 실시예에 따른 대용량 문서의 클러스터링을 통한 토픽 결정 방법을 나타낸 순서도이다. 참고로, 본 발명의 각 순서도에 있어서, 각 단계는 일예이며, 각 순서를 다르게 변경 및/또는 조합한 경우에도 본 발명이 동일/유사하게 적용될 수 있다. 제어부는 복수의 문서를 수집할 수 있다(s1). 실시예에 따라 제어부는 SNS 데이터를 크롤링 방식으로 수집 및 저장한 외부 장치(예>빅데이터 DB서버)로부 터, 사용자의 키워드 기반 검색을 통해 검색된 문서들에 대해 공지된 토픽 모델링 알고리즘을 실행하여 복수의 문서를 수집할 수 있다. 실시예에 따라 제어부는 외부 장치(미도시)로부터 복수의 문서(대용량 빅데이터 문서)를 수집할 수 있다. 예를 들어, 제어부는 외부 장치가 제공하는 API(Application Programming Interface)를 이용하여 복수의 문서를 수집하거나, 크롤링(crawling) 방식으로 복수의 문서를 수집할 수 있다. 제어부는 복수의 문서를 주 기적으로/비주기적으로 자동 수집할 수 있다. 외부 장치(미도시)는 뉴스를 제공하는 언론사의 웹 서버, 인터넷 포털 서비스를 제공하는 웹 서버, SNS 데이터 서버 등을 포함할 수 있다. 실시예에 따라 복수의 문서 각각은 SNS 데이터, 논문, 뉴스 등 다양한 텍스트 기반의 자료를 포함할 수 있다. 실시예에 따라 복수의 문서 각각은 하나의 긴 문장으로 정의될 수 있다. 제어부는 수집된 복수의 문서를 저장부의 수집데이터DB에 저장할 수 있다. 제어부는 복수의 문서를 클러스터링할 수 있다(s2). 실시예에 따라 제어부는 상기 복수의 문서 각각에 대응되는 임베딩 벡터를 획득하고(s2-1), 상기 임베딩 벡 터를 이용해 상기 복수의 문서를 클러스터링할 수 있다(s2-2). s-1에서, 실시예에 따라 제어부는 대규모 언어 기반의 임베딩모델을 이용해 상기 복수의 문서 각각에 대응되는 임베딩 벡터를 획득할 수 있다. 실시예에 따라, 제어부는 복수의 문서 각각의 단어별 형태소 분석을 수행하여 각 단어와 대응하는 형태소 가 짝을 이루는 토큰을 생성할 수 있다. 그리고, 토큰화된 단어를 임베딩모델에 입력시켜 단어별 임베딩 벡 터를 생성하고, 생성된 단어별 임베딩 벡터를 모두 합산하여(또는 평균값을 계산해) 상기 복수의 문서 각각에 대응되는 임베딩 벡터를 획득할 수 있다. 실시예에 따라, 임베딩모델은, 버트(BERT), 지피티(GPT)등 트랜스포머(Transformer)에 기반한 모델일 수 있 다. 다른 실시예에 따라, 도 9를 참조하면, 제어부는 대규모 언어 기반의 인코더 모델(도 9의 STS모델)을 이용 하여 복수의 문서 각각에 대응되는 임베딩 벡터를 획득할 수 있다. 상기 인코더 모델은 오토 인코더 모델로, 입력된 문서를 주어진 문장의 길이만큼 소정 차원(일례로 768 차원)의 크기의 임베딩 값을 반환할 수 있다. 구체적으로 복수의 문서 각각에 대응하는 소정 차원의 임베딩 값을 출력한후, 각 출력 값을 벡터변환부(미도시)를 통해 전달하여 임베딩 벡터를 획득할 수 있다. 여기서, 임베딩 값은 특정 언어(일례로 한국어)의 말뭉치를 기반으로 학습하여 주어진 문장에 대한 구조적, 문 맥적 언어 정보를 표상한다. 인코더 모델은, 예를 들어, 버트(BERT), 지피티(GPT)등 트랜스포머(Transformer) 기반의 모델에 대해 SNS 데이터를 이용한 학습으로 획득된 사전학습모델에 기반해 구현되는 것도 가능하다. 실 시예에 따라서, 인코더 모델은 사전에 훈련된 것일 수 있으며, 예를 들어, 소정의 훈련 데이터(일례로 문장 텍 스트의 유사도(STS: sentence textual similarity)나 한국어 문장 텍스트의 유사도(KoSTS) 등)을 이용하여 사 전학습모델에 대한 전이 학습을 통해 사전에 훈련되어 획득된 것일 수도 있다. 벡터변환부(미도시)는, 각 문서를 구성하는 문장 길이 차이를 동일하게 처리하기 위해, 인코더 모델에서 전달된 각 임베딩 값을 동일한 차원의 벡터로 변환할 수 있다. 실시예에 따라, 제어부는 전술한 각 실시예에서, 차원 감소(Dimension Reduction)를 통해 상기 복수의 문서 각각에 대응되는 임베딩 벡터를 획득할 수 있다. 즉, 제어부는 클러스터링의 연산량을 감소시키기 위해, 차 원이 감소된 임베딩 벡터를 클러스터링 연산의 입력으로 이용할 수 있다. 예를 들어, 도 4의 경우, UMAP(Uniform Manifold Approximation and Projection, 균등 다양체 가정 근사 투영 법) 알고리즘을 통한 차원 축소를 이용할 경우 성능이 보다 우수한 것을 확인할 수 있으나, 본 발명은 이외에도 다양한 차원 축소 알고리즘을 이용할 수 있다. 이에 따라, 각 문서의 임베딩 벡터는 두 개의 값으로 표현(정의)될 수 있다. (X: 0.xxxx Y: 0.yyyy) 예를 들어, 각 문서가 아래 표1과 같은 768개의 토큰화된 단어의 벡터로 표현된다면, 차원 축소를 통해 각 문서의 임베딩 벡터는 최종적으로 두개의 값으로 표현될 수 있다. [표1]"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "s2-2에서, 제어부는 복수의 문서 각각의 임베딩 벡터에 HDBSCAN(Hierarchical DBSCAN, Density based Spatial Clustering of Applications with Noise, 계층적 밀도 기반 공간적 클러스터링) 알고리즘을 적용해 상 기 복수의 문서를 클러스터링할 수 있다. 구체적으로, 제어부는 상기 임베딩 벡터 각각을 2D 그래프 상에 매핑하고, 매핑한 결과를 이용해 HDBSCAN 알고리즘을 동작시킬 수 있다. 예를 들어, 도 5a를 참조하면, 각 하나의 점(포인트)은 각 문서의 임베딩 벡터를 표현한 것으로, 각 임베딩 벡 터는 두 개의 실수 데이터(X, Y: UMAP 알고리즘으로 구현된 정규화된 벡터거리)로 표현될 수 있다. HDBSCAN 알고리즘은 클러스터링 알고리즘의 하나로, 계층적 클러스터링을 DBSCAN 알고리즘에 적용하여 DBSCAN의 단점을 보완한 알고리즘이다. 도 5b 내지 도 5d를 참조하여 HDBSCAN 알고리즘의 적용을 설명하면, 군집 대상이 되는 데이터셋을 Density(밀집도)/Sparsity(희소성) 의미를 포함한 값으로 변환하고, 포인트간의 Mutual Reachability Distance(상호도달거리)값을 기반으로 MST(minimum spanning tree)를 만들고, connected component들의 클러스터 hierarchy를 구축하며, 설정된 MinPts(클러스터를 형성하기 위해 필요한 최소 이웃 수)값을 기반으로 클러스터 hierarchy를 축약하고, 축약된 클러스터 hierarchy에서 stable한 클러스터만 선택하 는 방식으로 클러스터링을 수행한다. (참고로, 그래프 순서대로 계층화 과정이 단계적으로 진행되며 도 5d에서 빨간원으로 표시된것이 최종 토픽에 대응되는 것일 수 있다.) 여기서, Mutual Reachability Distance(상호도달거리)는 아래 수식1과 같이 정의될 수 있다. [수식1]"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "즉, 두 개의 서로 이웃한 점(포인트) a,b에 대하여, 점 a를 기준으로 한 k개(k는 임의의 수로 미리 설정될 수 있음)의 이웃을 포함하는 클러스터의 최소의 반지름값, 점 b를 기준으로 한 k개(k는 임의의 수로 미리 설정될 수 있음)의 이웃을 포함하는 클러스터의 최소의 반지름값, 및 점 a와 점 b 사이의 거리 중 가장 큰 값이 상호도 달거리로 정의될 수 있다. 제어부는 상기 클러스터링으로 생성된 복수의 클러스터 각각의 대표 문서를 결정할 수 있다(s3). 실시예에 따라 제어부는 상기 복수의 클러스터 각각에 포함된 문서들의 속성을 고려해 상기 복수의 클러스 터 각각의 상기 대표 문서를 결정할 수 있다. 실시예에 따라, 상기 문서들의 속성은 각 클러스터 내에서의 상기 문서들의 중요도를 나타내는 영향력 지수 및 상기 문서들 각각에 대응되는 포인트가 대응되는 클러스터에 포함될 확률을 나타낸 확률 지수 중 적어도 하나를 포함할 수 있다. 실시예에 따라 영향력 지수는, 문서들의 방문자수(조회수), 댓글수, '좋아요'수, 팔로워수, 회원수 및 고객추천 지수(SNPS, Social Net Promoter Score) 중 적어도 하나의 요소를 참조해 결정될 수 있다. 실시예에 따라 상기 적어도 하나의 요소는 문서 내에 기재된 정보로 확인될 수 있다. 고객추천지수(SNPS, Social Net Promoter Score)는 사회적 고객 순 추천 지수를 의미하는 것으로, 특정 제품, 서비스, 기업, 브랜드 등에 대해 고객이 타인에게 추천하고자 하는 의지의 정도를 나타내는 지수일 수 있다. 실시예에 따라 고객추천지수(SNPS, Social Net Promoter Score)는 문서의 감성 정보와 문서량에 기초해 획득될 수 있다. 구체적으로, 문서에 각각 태깅된 감성 정보와 태깅된 감성 정보의 종류(예> 긍정, 부정, 중립)에 대응 되는 문서의 개수에 기초해 하기 수식1에 따라 고객추천지수가 산출될 수 있다. 수식2: 고객추천지수 = (감성 정보가 긍정으로 태깅된 문서의 갯수 - 감성 정보가 부정으로 태깅된 문서의 갯수) / (감성 정보가 긍정으로 태깅된 문서의 갯수 + 감성 정보가 중립으로 태깅된 문서의 갯수 + 감성 정보가 부정으로 태깅된 문서의 갯수) (이 때, 고객추천지수는 -100%로부터 +100%까지 산출될 수 있음.) 실시예에 따라, 각 클러스터에 포함된 n번째 문서의 영향력 지수( )는 상기 적어도 하나의 요소 및/또는 문 서의 수집 채널별 기 정의된 기준 수치를 참조해 아래 수식3 및 표 2와 같이 정의될 수 있다. 수식3: (x: 요소, : 문서의 수집 채널별 기 정의된 기준 수치) 표2:"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "실시예에 따라, 요소(x)의 종류는 문서가 수집된 채널별로 상이하도록 미리 설정될 수 있다. 실시예에 따라, 문서의 수집 채널별 기 정의된 기준 수치( )는 문서의 클러스터 내 중요도를 결정하기 위해 수 집 채널별로 기 설정된 것으로, 측정 요소의 최대값( )으로도 정의되며, 측정 요소(x)의 값이 측정 요소의 최대 값( )에 가까울 수록 영향력이 높은 문서임을 나타내도록 기 정의된 기준 수치일 수 있다. 실시예에 따라, 표2에 따르면, 제어부는 문서가 수집된 채널이 언론이나 커뮤니티 이외의 채널인 경우, 제 어부는 각 채널에 대응되는 요소(x)와 문서의 수집 채널별 기 정의된 기준 수치( )를 참조해 영향력 지수를 결정할 수 있다. 예를 들어, 페이스북 채널의 경우, 해당 문서에 기재된 좋아요수와 9,000,000을 참조해 영향력 지수를 결정할 수 있다. 실시예에 따라, 표3에 따르면, 제어부는 문서가 수집된 채널이 언론이나 커뮤니티 채널인 경우, 요소를 참 조해 영향력 지수를 결정할 수 있다. 즉, 요소에 미리 매핑된 영향력 지수를 참조하여 결정할 수 있다. 이 때, 요소별 미리 매핑된 영향력 지수는 등급별로 구분되어 결정될 수 있다. (참고로, 등급은 방문자수가 많을수록 높은 등급으로, 영향력 지수가 높은 값을 갖는 것을 의미할 수 있다.) 표3:"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "전술한 표2 및 표3에 따르면, 제어부는 문서가 수집된 채널의 종류를 구분하고, 채널의 종류에 대응되는 영 향력 지수 결정 방식을 이용할 수 있다. 실시예에 따라 영향력 지수는, 0 내지 90의 값으로 표현될 수 있다. 실시예에 따라 영향력 지수는, 문서들의 방문자수(조회수), 댓글수, 좋아요수, 팔로워수, 및/또는 고객추천지수 (SNPS, Social Net Promoter Score)에 매핑되어 미리 결정되거나, 문서들의 방문자수(조회수), 댓글수, 팔로워 수, 좋아요수, 및/또는 고객추천지수(SNPS, Social Net Promoter Score) 각각에 기 설정된 가중치를 고려해 최 종적으로 결정될 수 있다. 다만, 이는 일 실시예이며 다양한 방법으로 영향력 지수가 산출될 수 있다. 실시예에 따라, 확률 지수는, 상기 문서들 각각에 대응되는 포인트가 대응되는 클러스터에 포함될 확률을 나 타낸 지수( )로, 아래와 같은 수식4로 정의될 수 있다. 수식4:"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "즉, 수식1에서 전술한, 클러스터 내의 두 개의 서로 이웃한 포인트 a와 b 사이의 상호도달거리(Mutual Reachability Distance)의 역수를 확률 지수로 산출할 수 있다. 실시예에 따라, 확률 지수는, 0 내지 1의 값으로 표현될 수 있다. 참고로, 확률 지수는, 도 5c의 트리 구조에서, 클러스터로 분할된 시점에서 문서별로 획득되는 값으로, 해당 값 이 클수록 초기에 클러스터로 분할된 문서로, 해당 클러스터에 포함될 확률이 높은 것으로 판단(결정)될 수 있 다. 실시예에 따라, 제어부는 각 클러스터에 포함된 문서별 산출된 상기 영향력 지수 및/또는 확률 지수 각각에 가중치를 적용하고, 각 가중치 적용 결과를 합산하여 상기 복수의 클러스터 각각의 상기 대표 문서를 결정할 수 있다. 예를 들어, 아래 수식5와 같이 각 클러스터에서 아래와 같은 합산값이 최대인 것을 나타내는 문서를 대표 문서 로 결정할 수 있다. 수식5:"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": ", : 각 지수를 반영할 정도를 나타내는 가중치(0과 1사이의 값으로 나타나는 수치로 각각의 가중치는 서로 반비례 관계에 있음) 바람직하게는 각 클러스터의 대표 문서는 하나일 수 있으나, 다른 실시예에 따라 두 개 이상의 추출 문서를 대 표 문서로 결정할 수도 있다. 본 발명에 따르면, 위와 같은 기준에 따라 대표 문서를 결정하도록 함으로써, 클러스터를 대표하는 대표 문서의 정확도가 높아질 수 있게 된다. 제어부는 결정된 대표 문서를 기초로 상기 복수의 클러스터 각각의 토픽을 생성할 수 있다(s4). 제어부는 대규모 언어 기반의 토픽생성모델을 이용해 상기 결정된 대표 문서로부터 상기 복수의 클러스 터 각각의 토픽을 생성할 수 있다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "즉, 제어부는 토픽생성모델을 이용해 상기 결정된 대표 문서가 요약된, 상기 복수의 클러스터 각각의 토픽을 생성할 수 있다. 토픽생성모델은 제어부에 의해, 학습용 문서에 기초해 학습용 토픽을 분류하도록 학습된 모델일 수 있"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "다. 구체적으로, 토픽생성모델은 생성 요약(abstractive text summarization) 방식에 의해 학습된 모델일"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "수 있다. 생성 요약은 핵심 문맥을 반영하여 원문에 없는 새로운 문장을 생성하여 원문을 요약하는 방식이다. 실시예에 따라 학습용 문서는 SNS 데이터, 논문, 뉴스 등 다양한 텍스트 기반의 자료를 포함할 수 있다."}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "토픽생성모델은 트랜스포머 기반의 BERT를 생성 요약 태스크에 맞게 적응적으로 학습시키는 과정을 통해 획 득될 수 있다. 즉, 토픽생성모델은 BERT를 이용해 학습용 문서에 학습용 토픽을 레이블링하여 파인 튜닝(미 세 조정)을 통한 학습으로 획득될 수 있다. 참고로, 여기서, 학습용 문서는 문서의 본문, 즉, 내용(도 6의 B)에"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "대응되고, 학습용 토픽은 요약(도 6의 Y)에 대응될 수 있다. 참고로, 도 7은 클러스터링 결과인 복수의 클러스터 각각과 복수의 클러스터 각각에 대응되는 대표 문서로부터 생성된 토픽을 예시한다.본 발명에 따르면, 클러스터를 대표하는 대표 문서를 추출해 토픽을 생성함으로써, 클러스터의 대표적인 특징을"}
{"patent_id": "10-2023-0073916", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "한눈에 파악할 수 있게 되고, 이를 위해 모든 문서를 요약하는 것이 아닌 대표 문서만을 요약하도록 함으로써 연산 시간이 줄어들어 효율적으로 클러스터의 특징 파악을 할 수 있게 된다. 제어부는 상기 복수의 클러스터 각각에 포함된 문서들의 개수의 변화를 시계열적으로 나타낸 그래프를 사용 자 인터페이스부를 통해 출력할 수 있다(s5). 실시예에 따라, 제어부는 상기 문서들의 생성 시간 및/또는 수집 시간을 기준으로 한 상기 문서들의 개수의 변화로 상기 그래프를 구성할 수 있다. 구체적으로, 제어부는 복수의 클러스터 각각에 포함된 문서들에 포함된 생성 시간 및/또는 수집 시간을 참 조하여 생성 시간별 및/또는 수집 시간별 문서들의 개수를 산출함으로써 시계열적으로 표현하여 시각화할 수 있 다. 도 8의 경우, 생성 시간 및/또는 수집 시간의 단위로 날짜를 예시하였으나, 요일별, 분기별, 연도별로 생성 시 간 및/또는 수집 시간의 단위를 구성한 경우에도 본 발명이 동일/유사하게 적용될 수 있다. 실시예에 따라, 제어부는 상기 그래프와 s4 단계에서 생성한 상기 복수의 클러스터 각각에 대응되는 토픽을 함께 하나의 화면으로 구성하여 상기 사용자 인터페이스부를 통해 출력할 수 있다. 이에 따라, 본 발명의 경우, 클러스터별 시계열적인 특징과 토픽을 한눈에 파악할 수 있게 되고, 토픽의 활성화 정도와 트렌드를 예측하여 사용자가 다양한 측면에서 해당 정보를 참고하여 의사결정을 할 수 있게 된다. 이상 설명된 실시 형태는 다양한 컴퓨터 구성요소를 통하여 실행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터로 판독가능한 기록매체에 기록될 수 있다. 상기 컴퓨터로 판독가능한 기록매체는 프로그램 명령어, 데이 터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터로 판독가능한 기록매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터로 판독가능한 기록매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니 라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치 는 본 발명에 따른 처리를 실행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 본 명세서의 양상들은 전체적으로 하드웨어, 전체적으로 소프트웨어 (펌웨어, 상주 소프트웨어, 마이크로 코드 등을 포함 함) 또는 컴퓨터 판독 가능 프로그램 코드가 구현 된 하나 이상의 컴퓨터 판독 가능 매체에 구현 된 컴퓨터 프로그램 제품의 형태를 취할 수 있다. 이상에서 실시예들에 설명된 특징, 구조, 효과 등은 본 발명의 하나의 실시예에 포함되며, 반드시 하나의 실시 예에만 한정되는 것은 아니다. 나아가, 각 실시예에서 예시된 특징, 구조, 효과 등은 실시예들이 속하는 분야의 통상의 지식을 가지는 자에 의해 다른 실시예들에 대해서도 조합 또는 변형되어 실시 가능하다. 따라서 이러한 조합과 변형에 관계된 내용들은 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다. 또한, 이상에서 실시예를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니며, 본 발 명이 속하는 분야의 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성을 벗어나지 않는 범위에서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 예를 들어, 실시예에 구체적으로 나타 난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면5c 도면5d 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2023-0073916", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 대용량 문서의 클러스터링을 통한 토픽 결정 장치의 블록도이다. 도 2 및 도 3은 실시예에 따른 대용량 문서의 클러스터링을 통한 토픽 결정 방법을 나타낸 순서도이다. 도 4 내지 도 8은 도 2 및 도 3의 방법을 설명하기 위해 참조되는 도면이다."}
