{"patent_id": "10-2023-0119320", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0036617", "출원번호": "10-2023-0119320", "발명의 명칭": "이미지 분류 장치 및 방법", "출원인": "한양대학교 산학협력단", "발명자": "조인휘"}}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "임의의 쓰레기 이미지를 입력받는 입력부;다양한 쓰레기 이미지를 학습데이터로 사용하여 학습을 진행한 분류 모델을 이용하여 상기 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 분류부; 및상기 분류 모델이 오분류를 하지 않은 경우 분류 결과를 출력하며, 상기 분류 모델이 오분류를 한 경우 오분류결과를 시각화하고 시각화한 결과를 이용하여 상기 분류 모델을 업데이트하는 처리부;를 포함하는 쓰레기 이미지 분류 장치."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 분류 모델은 컨벌루션 뉴럴 네트워크를 이용하여 쓰레기의 종류를 분류하는 쓰레기 이미지 분류 장치."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 처리부는 상기 분류 모델을 통과함에 따라 획득된 제1 특징 맵으로부터 상기 오분류 결과를 시각화하는 쓰레기 이미지 분류 장치."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 처리부는 상기 제1 특징 맵으로부터 제2 특징 맵을 획득하여 상기 분류 모델을 업데이트하는 쓰레기 이미지 분류 장치."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 제2 특징 맵은 상기 제1 특징 맵의 각 채널에 대하여 각각 가중치를 부여한 특징 맵인 쓰레기 이미지 분류장치."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 가중치는 상기 제1 특징 맵을 압축한 뒤 상기 압축된 제1 특징 맵의 각 채널의 특징을 학습하여 결정되는쓰레기 이미지 분류 장치."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "임의의 쓰레기 이미지를 입력받는 입력 단계;다양한 쓰레기 이미지를 학습데이터로 사용하여 학습을 진행한 분류 모델을 이용하여 상기 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 분류 단계; 및상기 분류 모델이 오분류를 하지 않은 경우 분류 결과를 출력하며, 상기 분류 모델이 오분류를 한 경우 오분류결과를 시각화하고 시각화한 결과를 이용하여 상기 분류 모델을 업데이트하는 처리 단계를 포함하는 쓰레기 이미지 분류 방법. 공개특허 10-2025-0036617-3-청구항 8 제 7 항에 있어서,상기 분류 모델은 컨벌루션 뉴럴 네트워크를 이용하여 쓰레기의 종류를 분류하는 쓰레기 이미지 분류 방법."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 처리단계는 상기 분류 모델을 통과함에 따라 획득된 제1 특징 맵으로부터 상기 오분류 결과를 시각화하는쓰레기 이미지 분류 방법."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 처리부는 상기 제1 특징 맵으로부터 제2 특징 맵을 획득하여 상기 분류 모델을 업데이트하는 쓰레기 이미지 분류 방법."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제2 특징 맵은 상기 제1 특징 맵의 각 채널에 대하여 각각 가중치를 부여한 특징 맵인 쓰레기 이미지 분류방법."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 가중치는 상기 제1 특징 맵을 압축한 뒤 상기 압축된 제1 특징 맵의 각 채널의 특징을 학습하여 결정되는쓰레기 이미지 분류 방법."}
{"patent_id": "10-2023-0119320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "임의의 쓰레기 이미지, 분류 모델을 저장하는 메모리, 상기 분류 모델은 임의의 쓰레기 이미지로부터 쓰레기의종류를 분류하는 인공신경망 기반 학습을 진행한 분류 모델임; 및임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 작업이 요청되면, 상기 메모리에 저장된 인공신경망 기반 학습을 진행한 분류 모델을 실행하여 쓰레기의 종류를 분류하는 프로세서를 포함하는 컴퓨터 장치."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 실시예들에 의하면, 임의의 쓰레기 이미지를 입력받고, 다양한 쓰레기 이미지를 학습데이터로 사용하여 학습 을 진행한 분류 모델을 이용하여 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 분류하며, 분류 모델이 오분류를 하지 않은 경우 분류 결과를 출력하며, 분류 모델이 오분류를 한 경우 오분류 결과를 시각화하고 시각 화한 결과를 이용하여 분류 모델을 업데이트하는 쓰레기 이미지 분류 장치 및 방법을 제공한다."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지를 분류하는 장치 및 방법에 관한 기술이다."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술 발전에 따라 인공지능 기술은 이미지 분류, 물체 감지 등 다양한 분야에서 인간의 수준에 가까운 성능을 보여주고 있다. 특히 이미지 분류 분야에서 인공지능은 특정 이미지를 학습한 뒤 이미지를 보고 이미지에 해당 하는 물체를 정확히 식별해내는 작업을 수행하고 있다. 인공지능 기술을 이용한 이미지 분류가 사용될 수 있는 분야는 쓰레기 처리 분야, 의료 분야 등 다양하게 존재 한다. 그 중 쓰레기 처리 분야에서는 인공지능 모델이 다양한 종류의 쓰레기 이미지에 대하여 학습한 뒤 쓰레기 의 이미지를 보고 쓰레기의 종류를 분류해내는 작업을 수행하고 있고, 산업의 특성상 쓰레기의 종류를 정확히 분류하는 것이 중요하다. 그러나 인공지능 모델의 학습 과정에서 사용되는 학습데이터는 제한적이므로 제한된 학습 데이터를 사용하여 학 습된 인공지능 모델은 오분류를 일으킬 확률이 높다. 이 때 인공지능 모델의 특성상 인공지능 모델이 오분류를일으킨 경우 오분류의 원인을 정확히 알기 어렵다는 문제가 있다. 또한 오분류의 원인을 제대로 알 수 없기 때문에 모델의 성능을 개선하기 위해서는 새로운 학습데이터를 통해 모델을 다시 학습하여야 하는 번거로움이 있다. 따라서 인공지능 모델이 오분류를 일으킨 경우 오분류의 원인을 정확히 파악하는 것이 필요하며 이를 통해 모델 의 성능을 개선하는 것이 필요하다."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 실시예들은 모델이 오분류를 일으킨 경우 오분류의 원인을 찾아내고 그에 따라 모델의 성능을 개선할 수 있 는 이미지 분류 장치 및 그 방법을 제공한다."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 과제를 해결하기 위한 일 실시예는 임의의 쓰레기 이미지를 입력받는 입력부와 다양한 쓰레기 이미지를 학습데이터로 사용하여 학습을 진행한 분류 모델을 이용하여 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류 하는 분류부 및 분류 모델이 오분류를 하지 않은 경우 분류 결과를 출력하며, 분류 모델이 오분류를 한 경우 오 분류 결과를 시각화하고 시각화한 결과를 이용하여 분류 모델을 업데이트하는 처리부를 포함하는 쓰레기 이미지 분류 장치를 제공한다. 또한, 다른 실시예는 임의의 쓰레기 이미지를 입력받는 입력 단계와 다양한 쓰레기 이미지를 학습데이터로 사용 하여 학습을 진행한 분류 모델을 이용하여 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 분류 단계 및 분류 모델이 오분류를 하지 않은 경우 분류 결과를 출력하며, 분류 모델이 오분류를 한 경우 오분류 결과를 시 각화하고 시각화한 결과를 이용하여 분류 모델을 업데이트하는 처리 단계를 포함하는 쓰레기 이미지 분류 방법 을 제공한다."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 실시예들에 따른 이미지 분류 장치 및 그 방법은 모델이 오분류를 일으킨 경우 오분류의 원인을 찾아낼 수 있고 그에 따라 모델의 성능을 개선할 수 있다."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 참조하여 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가질 수 있다. 또한, 본 실시예들을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명 이 본 기술 사상의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략할 수 있다. 본 명세서 상 에서 언급된 \"포함한다\", \"갖는다\", \"이루어진다\" 등이 사용되는 경우 \"~만\"이 사용되지 않는 이상 다른 부분이추가될 수 있다. 구성 요소를 단수로 표현한 경우에 특별한 명시적인 기재 사항이 없는 한 복수를 포함하는 경 우를 포함할 수 있다. 또한, 본 개시의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질, 차례, 순서 또는 개수 등이 한정되지 않는다. 구성 요소들의 위치 관계에 대한 설명에 있어서, 둘 이상의 구성 요소가 \"연결\", \"결합\" 또는 \"접속\" 등이 된다 고 기재된 경우, 둘 이상의 구성 요소가 직접적으로 \"연결\", \"결합\" 또는 \"접속\" 될 수 있지만, 둘 이상의 구성 요소와 다른 구성 요소가 더 \"개재\"되어 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 여 기서, 다른 구성 요소는 서로 \"연결\", \"결합\" 또는 \"접속\" 되는 둘 이상의 구성 요소 중 하나 이상에 포함될 수 도 있다. 구성 요소들이나, 동작 방법이나 제작 방법 등과 관련한 시간적 흐름 관계에 대한 설명에 있어서, 예를 들어, \"~후에\", \"~에 이어서\", \"~다음에\", \"~전에\" 등으로 시간적 선후 관계 또는 흐름적 선후 관계가 설명되는 경우, \"바로\" 또는 \"직접\"이 사용되지 않는 이상 연속적이지 않은 경우도 포함할 수 있다. 한편, 구성 요소에 대한 수치 또는 그 대응 정보(예: 레벨 등)가 언급된 경우, 별도의 명시적 기재가 없더라도, 수치 또는 그 대응 정보는 각종 요인(예: 공정상의 요인, 내부 또는 외부 충격, 노이즈 등)에 의해 발생할 수 있는 오차 범위를 포함하는 것으로 해석될 수 있다. 본 발명의 상세한 설명 및 청구항들에 걸쳐 나타나는 '학습' 혹은 '러닝'은 절차에 따른 컴퓨팅(computing)을 통하여 기계 학습(machine learning)을 수행함을 일컫는 용어인 바, 인간의 교육 활동과 같은 정신적 작용을 지 칭하도록 의도된 것이 아님을 통상의 기술자는 이해할 수 있을 것이다. 이하 도면을 참조해서 실시예들을 상세히 설명한다. 도 1은 일 실시예에 따른 이미지 분류 장치의 블록도이다. 도 1을 참조하면, 일 실시예에 따른 이미지 분류 장치는 임의의 쓰레기 이미지를 입력받는 입력부와 다양한 쓰레기 이미지를 학습데이터로 사용하여 학습을 진행한 분류 모델을 이용하여 임의의 쓰레기 이미 지로부터 쓰레기의 종류를 분류하는 분류부 및 분류 모델이 오분류를 하지 않은 경우 분류 결과를 출 력하며, 분류 모델이 오분류를 한 경우 오분류 결과를 시각화하고 시각화한 결과를 이용하여 분류 모델 을 업데이트하는 처리부를 포함할 수 있다. 입력부는 임의의 쓰레기 이미지를 입력받는다. 임의의 쓰레기 이미지는 다양한 종류의 쓰레기에 대한 이미지를 포함할 수 있다. 쓰레기의 종류는 종이류, 고철류, 유리병류, 캔류, 플라스틱류, 스티로폼 완충 제, 필름류, 비닐류, 의류 등을 포함할 수 있으며 어느 하나에 제한되지 않는다. 또한 임의의 쓰레기 이미지 는 이미지넷(ImageNet)에 포함된 이미지일 수 있다. 분류부는 분류 모델을 포함할 수 있다. 분류 모델은 입력받은 임의의 쓰레기 이미지를 학습 데이터로 하여 쓰레기 이미지로부터 쓰레기의 종류를 분류하도록 학습된 모델일 수 있다. 분류 모델은 하기에서 설명할 것처럼 인공 신경망 기반의 인공지능 모델을 사용할 수 있다. 분류 모델 이 인공 신경망 기반의 인공지능 모델을 사용할 경우 분류 모델은 데이터를 입력 받는 입력 노드와 데이터를 출력하는 출력 노드 및 그 사이에 배치되는 히든 노드를 포함할 수 있다. 입력 노드 및 출력 노드는 하나 이상일 수 있으며 인공 신경망에 입력되는 데이터의 종류나 양에 따라 그 개수가 달라질 수 있다. 히든 노 드는 하나 이상일 수 있으며 여러 개의 히든 노드들로 히든 레이어를 구성할 수 있다. 히든 노드 및 히든 레이 어의 수는 하나 이상일 수 있으며 학습 데이터의 양에 따라 그 개수가 다양하게 변형될 수 있다. 예를 들어 학 습 데이터가 많은 경우 히든 노드 및 히든 레이어의 개수는 많을 수 있고, 학습 데이터가 적은 경우 히든 노드 및 히든 레이어의 개수는 적을 수 있다. 처리부는 분류부에 포함된 분류 모델이 입력된 이미지를 제대로 분류했는지 확인할 수 있다. 분 류 모델이 입력된 이미지를 이미지에 맞게 분류한 경우 처리부는 분류 모델의 분류 결과를 출력 한다. 그러나 분류 모델이 입력된 이미지를 다르게 분류한 경우 처리부는 입력된 이미지 중 어느 영역에 분 류 모델이 집중했는지에 대한 정보를 시각화하여 표현하고 시각화한 결과에 따라 분류 모델을 업데이트 한다. 예를 들면, 종이 쓰레기의 이미지에 대하여 분류 모델이 이를 종이류로 분류한 경우 처리부(14 0)는 그 결과를 바로 출력하지만, 플라스틱류로 분류한 경우 처리부는 종이 쓰레기의 이미지 중 분류 모델 이 어느 영역에 집중했는지를 시각화하여 표현한다. 분류 모델이 집중한 영역을 시각화하여 표현하면 종이류를 플라스틱류로 잘못 분류한 것이 이미지의 어느 영역에서 기인한 것인지를 확인할 수 있다. 이를 확인 한 후에 처리부는 모델이 종이 이미지에 좀 더 적합한 영역에 집중하도록 분류 모델을 업데이트할 수 있다. 이하에서는 전술한 이미지 분류 모델의 세부 구성을 도면을 참조하여 예시적으로 설명한다. 도 2는 도 1의 분류부에 포함된 분류 모델의 예시적 구성을 표현한 도면이다. 도 2를 참조하면, 분류 모델은 인공 신경망 기반의 인공지능 모델을 사용할 수 있으며 특히 컨벌루션 뉴럴 네트워크를 사용할 수 있으나 반드시 이에 제한되지는 않는다. 다만 설명의 편의를 위하여 이하에서는 분류 모 델이 컨벌루션 네트워크를 사용하는 경우를 예시로 하여 설명한다. 임의의 쓰레기 이미지가 분류 모델에 입력되는 경우 임의의 쓰레기 이미지는 컨벌루션 필터 (Convolution filter)를 통해 압축될 수 있다. 컨벌루션 필터는 하나 이상일 수 있으며 컨벌루션 필터에 포함되는 값은 초기에 임의로 설정될 수 있다. 분류 모델을 학습하는 과정은 컨벌루션 필터에 포함되는 값, 즉 가중치를 학습하는 과정이다. 컨벌루션 필터를 통과한 임의의 쓰레기 이미지는 C0×H0×W0의 픽셀 정보로 표현될 수 있다. 여기서 C0는 채널 수를 의미하며, H0, W0는 각각 H, W 방향으로 압축된 픽셀의 개수를 의미할 수 있다. 컨벌루션 필터를 통과한 픽셀 정보는 C0보다 작은 채널 수를 가질 수 있으며, H, W 방향으로 각각 H0, W0 보다 작은 픽셀 수를 가질 수 있다. 그러나 반드시 이에 제한되지는 않으며 C0, H0, W0과 같은 값들을 가질 수도 있 다. 컨벌루션 필터를 통과한 C0×H0×W0의 픽셀 정보는 풀링(Pooling) 레이어를 통해 더 작은 수의 채널 및 픽 셀 수를 가진 정보로 압축될 수 있다. 풀링에는 최대값 풀링(Max pooling), 평균값 풀링(Average pooling)등이 있으며 본 발명은 어느 하나에 제한되지 않는다. 풀링 레이어를 통과한 픽셀 정보는 이후 다시 컨벌루션 레이어를 거치면서 더 작은 채널 수 및 픽셀 수를 갖는 정보로 압축될 수 있고, 풀링 레이어를 통과한 픽셀 정보는 다시 컨벌루션 레이어를 거칠 수 있다. 즉 분류 모델은 전술한 것처럼 컨벌루션 레이어와 풀링 레이어가 반복되는 구조를 가짐에 따라 입력되는 임의의 쓰레기 이미지를 작은 크기로 압축할 수 있다. 컨벌루션 레이어와 풀링 레이어를 반복하여 최종적으로 압축된 픽셀 정보는 전체 연결 레이어를 만들기 위하여 1차원 벡터로 펴질(Flatten) 수 있다. 이하에서는 최종적으로 압축된 픽셀 정보를 특징 맵이라 명명하여 설명한다. 특징 맵에 포함된 픽셀 정보는 1차원 벡터로 펴질 수 있으며, 1차원 벡터는 클래스 분류 노드 와 전체 연결(Fully connect)될 수 있다. 클래스 분류 노드는 입력된 임의의 쓰레기 이미지가 종 이류 인지 또는 플라스틱류인지 등을 분류하는 노드이며, 도 2에서는 두 개의 노드 만을 포함하는 것으로 도시 하였으나 이에 제한되지는 않으며 분류하고자 하는 쓰레기 종류의 개수만큼의 노드 수를 가질 수 있다. 이하에서는 분류 모델이 오분류를 일으키는 경우 처리부의 세부 동작을 도면을 참조하여 예시적으로 설명한다. 도 3은 분류 모델이 집중한 영역을 시각화하여 표현한 도면이다. 도 3을 참조하면, 처리부는 분류 모델을 통과함에 따라 획득된 특징 맵으로부터 오분류 결과를 시각 화할 수 있다. 구체적으로, 건전지의 이미지가 분류 모델에 입력되는 경우 분류 모델은 이를 건전지류 또는 고철류 로 분류할 수 있으나 이와는 다른 종류로 분류할 수도 있다. 처리부는 분류 모델이 건전지 이미지를건전지류 또는 고철류로 분류하는 경우 이를 출력한다. 그러나 분류 모델이 건전지류 또는 고철류 외의 다른 종류로 분류하는 경우 처리부는 오분류에 대한 시각화 이미지를 생성한다. 오분류에 대한 시각화 이미지를 생성하는 과정을 자세히 설명하면 다음과 같다. 시각화 이미지는 다음과 같은 수식을 통해 얻을 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서 은 예측 범주 c의 히트맵(heatmap)이고, ReLU 함수는 활성화 함수이고, 는 특징 맵에 대한 범주 c의 스칼라 가중치이고, 는 특징 맵의 k번째 채널의 i행, j열의 활성화 값이다. 여기서 는 아래와 같이 수학식 2로 표현될 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서 Z는 표준화 인자이고, 는 범주 c에 대한 스코어 값이다. 는 특징 맵의 채널 중 k번째 채널에서 (i, j)좌표가 가지는 픽셀 값을 의미한다. 즉 수학식 2를 참 조하면, 는 범주 c에 대한 스코어 값인 에 특징 맵의 각 픽셀 정보가 주는 영향력의 평균을 의미할 수 있다. 수학식 1을 참조하면, 에 을 곱한 값은 특징 맵의 각 픽셀 정보가 주는 영향력에 특징 맵 의 k번째 채널의 i행, j열의 활성화 값을 곱한 값이므로, 이러한 과정을 모든 행과 열에 대하여 행해주면 채널 별로 모델이 집중하는 영역을 나타내는 히트맵 정보를 얻을 수 있다. 이후 각 채널 별 히트맵 정보를 모두 더한 뒤 활성화 함수(RELU)를 적용하게 되면 결과적으로 입력된 건전지 이 미지에 대하여 도 3에 도시된 것처럼 모델이 집중하는 영역이 표시된 이미지를 얻을 수 있다. 도 3을 참조하면, 모델이 강하게 집중한 영역, 즉 각 채널의 히트맵 정보가 높은 값을 갖는 영역은 빨간색으로 표현되며 모델이 약하게 집중한 영역, 즉 각 채널의 히트맵 정보가 낮은 값을 갖는 영역은 파란색으로 표현된다. 이 때 빨갛게 표시된 영역이 건전지 외부에 위치하고 있으므로 분류 모델은 건전지가 아닌 건전 지 외부의 영역에 더 집중하여 쓰레기 이미지의 종류를 분류하였다고 해석할 수 있다. 이상에서 설명한 바와 같이 분류 모델이 쓰레기 이미지를 분류하기 위하여 입력된 이미지에서 더 집중한 영역을 시각화하여 표현할 수 있으며 결과적으로 분류 모델이 오분류를 일으키는 원인을 찾아낼 수 있다. 이하에서는 분류 모델이 오분류를 일으키는 원인을 찾아낸 경우 분류 모델을 업데이트하는 내용을 도 면을 참조하여 설명한다. 도 4는 도 2의 분류 모델 중 일부 구성이 변경된 구조를 나타내는 도면이다. 도 5는 도 4의 변경된 구조를 자세 히 설명하는 도면이다. 도 4 및 도 5를 참조하면, 분류 모델의 특징 맵은 C×H×W의 픽셀 정보로 표현될 수 있다. 이 때 C는 C0보다 작을 수 있고, H는 H0보다 작을 수 있으며, W는 W0보다 작을 수 있다. 특징 맵은 C개의 채널을 가 진 픽셀 정보일 수 있다. 처리부는 분류 모델이 오분류를 일으킨 경우 특징 맵으로부터 새로운 특징 맵을 얻을 수 있다. 새로운 특징 맵은 특징 맵의 각 채널에 대하여 임의의 가중치가 곱해진 픽셀 정보일 수 있다. 또한 가중치는 특징 맵을 압축한 뒤 압축된 특징 맵의 각 채널의 특징을 학습하여 결정될 수 있다. 이하 새로운 특징 맵을 얻는 과정을 자세히 설명하면 다음과 같다. 분류 모델의 특징 맵은 C×1×1의 픽셀 정보로 압축될 수 있다. 여기서 C는 채널 수를 말한다. 즉 C×1×1의 픽셀 정보는 C개의 채널이 각각 1개의 픽셀 값만을 포함하는 픽셀 정보를 의미한다. 이 때 특징 맵을 C×1×1의 픽셀 정보로 압축하는 방법으로는 전역 평균 풀링(Global Average Pooling)이 사용될 수 있으나 반드시 이에 제한되지는 않는다. 전역 평균 풀링을 사용하는 경우 압축된 특징 맵 의 각 채널 별 1개의 픽셀 값은 특징 맵의 각 채널에서 i행, j열의 값들을 모두 더한 뒤 이를 평균낸 값이다. 전역 평균 풀링을 사용하여 특징 맵을 압축하는 경우 각 채널의 픽셀 분포에서 각 채널들을 대표하는 값들 로 이루어진 C×1×1의 픽셀 정보를 얻을 수 있다. C×1×1의 픽셀 정보를 얻은 뒤에는 이를 C/r×1×1의 픽셀 정보를 담고 있는 레이어와 전체 연결시 켜 준다. C×1×1의 픽셀 정보는 1차원 벡터 형태의 정보이므로 전체 연결(Fully Connected, FC)레이어로 표현될 수 있다. 즉 C×1×1의 픽셀 정보를 하나의 레이어로 만들고 C/r×1×1의 픽셀 정보를 담고 있는 레이어를 만든 후 두 레이어를 연결해준다. 이 때 두 레이어는 전체 연결될 수 있다. C/r×1×1의 픽셀 정보를 담고 있는 레이어는 채널의 수가 C에서 C/r로 압축된 레이어일 수 있다. 예를 들 어 C가 10이고 r이 2인 경우 C/r×1×1의 픽셀 정보를 담고 있는 레이어는 5개의 노드를 가진 레이어일 수 있다. 이후 C/r×1×1의 픽셀 정보를 담고 있는 레이어에 활성화 함수(ReLu)를 적용하는 과정을 거칠 수 있다. 활성화 함수를 적용한 뒤에는 다시 전체 연결 레이어로 연결될 수 있다. 즉 C/r×1×1의 픽셀 정보를 담고 있는 레이어는 C×1×1의 레이어로 전체 연결될 수 있다. C×1×1의 레이어는 C개의 채널을 가진 레 이어이다. C×1×1의 레이어의 각 노드 값에 시그모이드(Sigmoid) 함수를 적용하여 최종적으로 채널 특성이 반영된 레이어를 생성할 수 있다. 도 4 및 도 5를 참조하면, 채널 특성이 반영된 레이어는 C×1×1의 픽셀 정보를 가질 수 있다. 채널 특성 이 반영된 레이어의 각 채널의 값은 시그모이드 함수가 적용됨에 따라 0~1사이의 값을 가질 수 있다. C×1×1의 픽셀 정보가 압축되고 확장되는 과정을 거치면서 채널 특성이 반영된 레이어의 각 채널의 값들은 이전과 다른 값을 가지게 될 수 있다. 구체적으로, 채널C×1×1의 픽셀 정보가 C/r×1×1의 픽셀 정보를 담고 있는 레이어로 압축되고 활성 화 함수(ReLu)를 거치면서 비선형적인 값을 갖게 될 수 있다. 이후 다시 C×1×1의 레이어로 확장되면 기 존의 C×1×1의 픽셀 정보는 이전과 다른 채널 값을 가지게 될 수 있다. 달라진 채널 값은 이후 시그모이 드 함수가 적용됨에 따라 0~1사이의 값으로 정규화 될 수 있다. 채널의 값이 0과 1사이의 값을 가짐에 따라 채널 특성이 반영된 레이어는 각 채널의 중요도를 상대적으로 표현할 수 있다. 즉 C×1×1의 픽셀 정보와 C/r×1×1의 픽셀 정보를 담고 있는 레이어 및 C×1×1의 레이어와 순차적으로 전체 연결됨에 따라 분류 모델은 각 채널의 특징을 학습할 수 있고 채널의 특징 이 학습된 값을 정규화 시킴으로써 채널 특성이 반영된 레이어는 분류에 중요한 역할을 하는 채널의 값을 높게 표현하고 중요하지 않은 역할을 하는 채널의 값을 낮게 표현할 수 있다. 채널 특성이 반영된 레이어의 각 채널 값은 특징 맵에 곱해질 수 있다. 즉 채널 특성이 반영된 레이 어와 특징 맵은 동일한 채널 수를 가지고 있으므로 채널 특성이 반영된 레이어의 각 채널 값이 특징 맵의 각 채널에 곱해질 수 있다. 채널 특성이 반영된 레이어의 각 채널 값이 곱해진 특징 맵은 새로운 특징 맵으로 표현될 수 있다. 새로운 특징 맵은 기존의 특징 맵에 채널 특성이 반영된 레이어의 각 채널 값, 즉 각 채널의 중 요도를 상대적으로 표현한 값을 곱한 특징 맵이므로 분류에 중요한 역할을 하는 채널은 상대적으로 높은 픽셀 정보를 갖게 되고 분류에 중요하지 않은 역할을 하는 채널은 상대적으로 낮은 픽셀 정보를 갖게 될 수 있다. 이에 따라 분류 모델의 분류 성능은 개선될 수 있다. 도 6은 도 4의 변경된 구조를 갖는 분류 모델이 집중한 영역을 시각화하여 표현한 도면이다. 분류 모델이 오분류를 일으킨 경우 분류 모델의 특징 맵은 전술한 것처럼 분류에 중요한 역할을 하는 채널이 상대적으로 낮은 픽셀 값을 갖고, 분류에 중요하지 않은 역할을 하는 채널이 상대적으로 높은 픽셀 값을 갖도록 표현될 수 있다. 컨벌루션 신경망의 마지막 출력 층에 해당하는 특징 맵의 픽셀 정보를 모두 확인하여 어떤 채널이 상대적으로 낮은 픽셀 값을 갖고 어떤 채널이 상대적으로 높은 픽셀 값을 갖는지를 일일히 확인하는 것은 불가능하지만 도 6에 도시된 것처럼 특징 맵으로부터 오분류에 대한 시각화 이미지를 생성하게 되면 모델이 어떤 부분에 집중했 는지를 파악할 수 있다. 즉 오분류에 대한 시각화 이미지를 통해 모델이 오분류를 일으킨 원인을 파악할 수 있 다. 오분류의 원인이 된 부분을 파악한 뒤에는 도 4 및 도 5를 참조하여 설명한 것처럼 분류 모델의 성능을 개 선할 수 있고, 개선된 분류 모델은 채널 별로 중요도가 설정된 새로운 특징 맵을 가질 수 있다. 도 6을 참조하면, 새로운 특징 맵으로부터 다시 시각화 이미지를 생성할 수 있다. 다시 시각화 이미지를 생성하는 과정은 앞서 설명한 방법과 동일한 방법이 적용될 수 있다. 도 6에서 볼 수 있듯이, 각 채널의 중요도가 설정된 새로운 특징 맵으로부터 얻어진 시각화 이미지는 건전 지 부분을 빨갛게 표현하고, 건전지를 제외한 영역을 파랗게 표현한다. 즉 쓰레기 이미지를 분류하는 데에 중요 한 영역에 분류 모델이 좀 더 집중하고 있음을 확인할 수 있다. 즉 새로운 특징 맵에 대한 시각화 이 미지를 통해 분류 모델의 성능이 개선된 것을 확인할 수 있다. 처리부는 분류 모델이 쓰레기 이미지를 올바르게 분류한 경우 그 결과를 출력하고 잘못 분류한 경우 오분류 결과를 시각화하고 시각화한 결과를 이용하여 분류 모델을 업데이트할 수 있다. 그러나 반드시 이 에 제한되지는 않는다. 즉 분류 모델이 쓰레기 이미지를 올바르게 분류한 경우에도 그 결과를 시각화하고 시각화한 결과를 이용하 여 분류 모델을 업데이트할 수 있다. 분류 모델이 쓰레기 이미지를 올바르게 분류한 경우라도 새로운 종류의 쓰레기 이미지가 다시 입력되었을 때 분류 모델은 다시 오분류를 일으킬 가능성이 있다. 도 6을 참조하여 예를 들어 설명하면, 분류 모델 이 건전지 이미지를 건전지류, 고철류로 분류한 경우에도 두 개의 건전지 중 하나의 건전지에는 집중하지 못한 것을 확인할 수 있다. 이와 같이 모델이 집중하지 못한 영역의 이미지 또는 전혀 새로운 이미지가 입력될 경우 분류 모델이 다시 오분류를 일으킬 수 있다. 따라서 분류 모델이 입력된 쓰레기 이미지를 올바르게 분류한 경우라도 분류 결과를 시각화하여 분류 모델 이 개선될 여지가 있는지를 확인할 수 있고 오분류를 일으킬 잠재적 가능성을 차단할 수 있다. 이상에서 설명한 동작을 통해서 본 발명의 이미지 분류 장치는 모델이 오분류를 일으킨 경우 오분류 결과를 시 각화할 수 있고 이에 따라 모델을 업데이트할 수 있다. 이하에서는 위에서 설명한 본 발명이 모두 수행될 수 있는 쓰레기 이미지 분류 방법을 도 7을 참조하여 간략히 설명한다. 도 7은 다른 실시예에 따른 이미지 분류 방법의 흐름도이다. 도 7을 참조하면, 다른 실시예에 따른 이미지 분류 방법은 임의의 쓰레기 이미지를 입력받는 입력단계 (S300)와 다양한 쓰레기 이미지를 학습데이터로 사용하여 학습을 진행한 분류 모델을 이용하여 임의의 쓰 레기 이미지로부터 쓰레기의 종류를 분류하는 분류단계(S310) 및 분류 모델이 오분류를 하지 않은 경우 분 류 결과를 출력하며, 분류 모델이 오분류를 한 경우 오분류 결과를 시각화하고 시각화한 결과를 이용하여 분류 모델을 업데이트하는 처리단계(S320)를 포함할 수 있다. 도 2 내지 도 6을 참조하여 전술한 것처럼, 입력단계(S300)는 임의의 쓰레기 이미지를 입력받는다. 임의의 쓰레기 이미지는 다양한 종류의 쓰레기에 대한 이미지를 포함할 수 있다. 쓰레기의 종류는 종이류, 고철류, 유리병류, 캔류, 플라스틱류, 스티로폼 완충제, 필름류, 비닐류, 의류 등을 포함할 수 있으며 어느 하나에 제한 되지 않는다. 또한 임의의 쓰레기 이미지는 이미지넷(ImageNet)에 포함된 이미지일 수 있다. 분류 모델은 입력받은 임의의 쓰레기 이미지를 학습데이터로 하여 쓰레기 이미지로부터 쓰레기의 종류 를 분류하도록 학습된 모델일 수 있다. 처리단계(S320)는 분류 모델이 입력된 이미지를 제대로 분류했는지 확인할 수 있다. 분류 모델이 입 력된 이미지를 이미지에 맞게 분류한 경우 처리단계(S320)는 분류 모델의 분류 결과를 출력한다. 그러나 분류 모델이 입력된 이미지를 다르게 분류한 경우 처리단계(S320)는 입력된 이미지 중 어느 영역에 분류 모델이 집중했는지에 대한 정보를 시각화하여 표현하고 시각화한 결과에 따라 분류 모델을 업데 이트 한다. 예를 들면, 종이 쓰레기의 이미지에 대하여 분류 모델이 이를 종이류로 분류한 경우 처리단계 (S320)는 그 결과를 바로 출력하지만, 플라스틱류로 분류한 경우 처리단계(S320)는 종이 쓰레기의 이미지 중 분 류 모델이 어느 영역에 집중했는지를 시각화하여 표현한다. 분류 모델이 집중한 영역을 시각화하여 표현하면 종이류를 플라스틱류로 잘못 분류한 것이 이미지의 어느 영역에서 기인한 것인지를 확인할 수 있다. 이를 확인한 후에 처리단계(S320)는 모델이 종이 이미지에 좀 더 적합한 영역에 집중하도록 분류 모델을 업데이트할 수 있다. 도 2 내지 도 6을 참조하여 전술한 것처럼, 분류 모델은 인공 신경망 기반의 인공지능 모델일 수 있으며 특히 컨벌루션 뉴럴 네트워크를 이용한 모델일 수 있으나 반드시 이에 제한되지는 않는다. 처리단계(S320)는 분류 모델을 통과함에 따라 획득된 특징 맵으로부터 오분류 결과를 시각화할 수 있다. 오분류 결과를 시각화하는 과정, 즉 오분류에 대한 시각화 이미지를 생성하는 과정은 수학식 1 및 수학식 2를 참조하여 전술한 것과 동일하게 설명될 수 있다. 즉 수학식 1 및 수학식 2를 통해 도출한 이미지를 통해 분류 모델이 이미지를 분류하기 위하여 입력된 이미지에서 더 집중한 영역을 시각화하여 표현할 수 있으며 결과 적으로 분류 모델이 오분류를 일으키는 원인을 찾아낼 수 있다. 처리단계(S320)는 분류 모델이 오분류를 일으킨 경우 특징 맵으로부터 새로운 특징 맵을 얻을 수 있다. 새로운 특징 맵은 특징 맵의 각 채널에 대하여 임의의 가중치가 곱해진 픽셀 정보일 수 있다. 또한 가중치는 특징 맵을 압축한 뒤 압축된 특징 맵의 각 채널의 특징을 학습하여 결정될 수 있다. 새로운 특징 맵은 기존의 특징 맵에 채널 특성이 반영된 레이어의 각 채널 값, 즉 각 채널의 중 요도를 상대적으로 표현한 값을 곱한 특징 맵이므로 분류에 중요한 역할을 하는 채널은 상대적으로 높은 픽셀 정보를 갖게 되고 분류에 중요하지 않은 역할을 하는 채널은 상대적으로 낮은 픽셀 정보를 갖게 될 수 있다. 이 에 따라 분류 모델의 분류 성능은 개선될 수 있다. 도 7을 참조하여 설명한 다른 실시예에 따른 이미지 분류 방법은 도 1 내지 도 6을 참조하여 설명한 일 실 시예에 따른 이미지 분류 장치에서 설명한 내용들을 동일 또는 유사하게 적용할 수 있다. 본 실시예들에 따른 이미지 분류 장치 및 그 방법은 분류 모델이 오분류를 일으킨 경우 오분류의 원인을 파악할 수 있고 이에 따라 모델의 성능을 개선할 수 있다. 도 8은 본 발명의 실시예들에 따른 컴퓨팅 시스템의 구성도이다. 도 8을 참조하면, 컴퓨팅 시스템은 입력부, 메모리 및 프로세서를 포함할 수 있다. 메모리는 입력부로부터 입력받은 임의의 쓰레기 이미지를 저장할 수 있으나, 별도의 대용량 스토 리지 서버 등에 별도로 저장할 수도 있다. 메모리는 휘발성 메모리(e.g. SRAM, DRAM) 또는 비휘발성 메모 리(e.g. NAND Flash)일 수 있다. 프로세서는 다양한 쓰레기 이미지를 학습데이터로 하여 학습을 진행한 분류 모델에 임의의 쓰레기 이 미지를 입력하여 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류한다. 메모리는 인공신경망 기반 학습을 진행한 분류 모델을 저장한다. 임의의 쓰레기 이미지로부터 쓰 레기의 종류를 분류하는 작업이 요청되면, 프로세서는 메모리에 저장된 인공신경망 기반 학습을 진행 한 분류 모델을 실행하여 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 작업을 수행하고 그결과를 출력한다. 본 발명의 실시예들에 따른 컴퓨팅 시스템은 메모리 및 프로세서를 포함하는 컴퓨터 장치와 메 모리 및 프로세서를 포함하는 서버를 포함할 수 있다. 컴퓨터 장치와 서버는 네트워 크를 통해 유선 또는 무선으로 연결될 수 있다. 서버의 메모리는 전술한 인공신경망 기반 학습을 진행한 분류 모델을 저장할 수 있다. 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 작업이 요청(query)되면, 컴퓨터 장치의 프로 세서는 메모리에 저장된 임의의 쓰레기 이미지를 가져온다. 컴퓨터 장치의 메모리는 전술한 임의의 쓰레기 이미지를 저장할 수 있다. 컴퓨터 장치의 프로세서는 메모리에 저장된 임의의 쓰레기 이미지 및 이 요청(query)을 서 버에 전송할 수 있다. 서버의 프로세서는 전송받은 임의의 쓰레기 이미지에 대하여 메모리에 저장된 인공신경망 기반 학습을 진행한 분류 모델을 실행하여 임의의 쓰레기 이미지로부터 쓰레기의 종류를 분류하는 작업을 수행하여, 그 결과를 컴퓨터 장치에 전송할 수 있다. 도 8 및 도 9를 참조하여 설명한 컴퓨터 시스템에 대해서 아래에서 가능한 다양한 예들을 설명한다. 이미지 분류 장치는 도 9에 도시한 컴퓨팅 시스템으로 구성할 수도 있고, GPU 프로세서와 일반 메모 리가 장착된 GPU 서버로 구성할 수도 있으나, 본 발명은 이에 제한되지 않는다. 전술한 이미지 분류 장치는, 프로세서, 메모리, 사용자 입력장치, 프레젠테이션 장치 중 적어도 일부를 포 함하는 컴퓨팅 장치에 의해 구현될 수 있다. 메모리는, 프로세서에 의해 실행되면 특정 태스크를 수행할 있도록 코딩되어 있는 컴퓨터-판독가능 소프트웨어, 애플리케이션, 프로그램 모듈, 루틴, 인스트럭션(instructions), 및/또는 데이터 등을 저장하는 매체이다. 프로세서는 메모리에 저장되어 있는 컴퓨터-판독가능 소프트웨어, 애 플리케이션, 프로그램 모듈, 루틴, 인스트럭션, 및/또는 데이터 등을 판독하여 실행할 수 있다. 사용자 입력장 치는 사용자로 하여금 프로세서에게 특정 태스크를 실행하도록 하는 명령을 입력하거나 특정 태스크의 실행에 필요한 데이터를 입력하도록 하는 수단일 수 있다. 사용자 입력장치는 물리적인 또는 가상적인 키보드나 키패드, 키버튼, 마우스, 조이스틱, 트랙볼, 터치-민감형 입력수단, 또는 마이크로폰 등을 포함할 수 있다. 프 레젠테이션 장치는 디스플레이, 프린터, 스피커, 또는 진동장치 등을 포함할 수 있다. 컴퓨팅 장치는 스마트폰, 태블릿, 랩탑, 데스크탑, 서버, 클라이언트 등의 다양한 장치를 포함할 수 있다. 컴퓨 팅 장치는 하나의 단일한 스탠드-얼론 장치일 수도 있고, 통신망을 통해 서로 협력하는 다수의 컴퓨팅 장치들로 이루어진 분산형 환경에서 동작하는 다수의 컴퓨팅 장치를 포함할 수 있다. 한편, 컴퓨팅 장치는 고전(classic) 컴퓨팅 장치가 아니라 양자(quantum) 컴퓨팅 장치일 수 있다. 양자 컴퓨팅 장치는 비트가 아닌 큐비트(Qubit) 단위로 연산을 수행한다. 큐비트는 0과 1이 동시에 중첩(superposition)되는 상태를 가질 수 있으며, M개의 큐비트가 있으면 동시에 2^M개의 상태를 표현할 수 있다. 양자 컴퓨팅 장치는 양자 연산을 수행하기 위해 하나 이상의 큐비트를 입력받아 지정된 연산을 수행하는 다양한 종류의 양자 게이트들(e.g. Pauli / Rotation / Hadamard / CNOT / SWAP / Toffoli)를 사용할 수 있고, 양자 게이트들을 조합하여 특수한 기능을 하는 양자 회로를 구성할 수 있다. 양자 컴퓨팅 장치는 기존의 인공 신경망(e.g. CNN, RNN)이 수행하는 기능을 적은 파라미터를 사용하면서도 더 빠른 속도로 수행할 수 있는 양자 인공 신경망(e.g. QCNN, QGRNN)을 사용할 수 있다. 또한 전술한 이미지 분류 장치는, 프로세서를 구비하고, 또한 프로세서에 의해 실행되면 딥 러닝 모델을 활용한 이미지 분류 방법을 수행할 수 있도록 코딩된 컴퓨터 판독가능 소프트웨어, 애플리케이션, 프로그램 모 듈, 루틴, 인스트럭션, 및/또는 데이터 구조 등을 저장한 메모리를 구비하는 컴퓨팅 장치에 의해 실행될 수 있 다. 본 실시예들에서 설명하는 인공 지능 모델은 전술한 컴퓨팅 장치에서 동작하는 알고리즘 기반 기계 학습을 진행 한 모델 또는 인공 신경망 기반의 학습을 진행한 모델 등과 같은 현재 또는 미래의 기계 학습 모델일 수 있다. 알고리즘 기반 기계 학습을 진행한 모델은 예를 들어 트리 기반 모델(tree-based model), k-최근접 이웃(k- Nearest Neighbors), k-평균 균집화(k-Means Clustering), PCA(Principal Component Analysis), SVM(supportvector machine) 등과 같은 고전적인 기계 학습 모델일 수 있다. 트리 기반 모델은 예를 들어 결정 트리 모델(decision tree model)이거나 회귀 모델(regression model) 또는 랜덤 트리 모델(random tree model)일 수 있다. 한편, 인공 지능 모델은 하나의 학습된 모델만을 사용하지 않고 여러 모델들을 학습시켜 결합하는 방식으로 문 제를 해결하는 앙상블 모델(ensemble model)일 수 있다. 앙상블 모델은 개별적으로 학습된 여러 모델들을 조합함으로써, 과적합(overfitting)을 막고 일반화 성능을 향 상시킬 수 있다. 앙상블 모델은 개별 모델의 성능이 확보되지 않을 때 성능 향상에 도움이 될 수 있다. 앙상블 모델은 크게 투표 방식과 부스팅 방식으로 나눌 수 있다. 투표 방식은 여러 개의 모델들이 생성한 결과들에 대한 투표를 통해 최종 결과를 도출하는 방식이다. 예를 들어, 투표 방식은 동일 유형의 알고리즘들을 조합하되 각각 학습하는 데이터를 다르게 하는 배깅(bagging) 방 식과 서로 다른 종류의 알고리즘을 결합하는 보팅(voting) 방식이 있다. 부스팅 방식은 약한 기계 학습 모델들을 결합해서 보다 정확하고 강력한 기계 학습 모델을 만드는 방식이다. 부 스팅 방식은 약한 기계 학습 모델들 각각이 순서대로 일을 하면 뒤의 기계 학습 모델들이 앞의 기계 학습 모델 이 찾지 못한 부분을 추가적으로 탐색하는 방식이다. 예를 들어, 부스팅 방식은 랜덤 포레스트, 그래디언트 부 스팅, XGBoost(eXtra Gradient Boost) 등일 수 있다. 인공 신경망은 인간의 뇌의 동작 원리를 모방하여, 서로 연결된 다수의 인공 뉴런을 기초로 하여 복잡한 데이터 를 분석하고 학습하는 기계 학습 알고리즘이다. 인공 신경망은 입력층, 은닉층, 출력층으로 이루어져 있는 가장 기본적인 인공 신경망 구조인 다층 퍼셉트론(MLP, Multi-Layer Perceptron), 이미지의 특징을 추출하기 위해서 컨볼루션(convolution) 연산을 수행하고, 풀링(pooling) 연산으로 차원을 축소하는 합성곱 신경망(CNN, Convolutional Neural Network), 순서가 있는 데이터를 처리하는 데 사용되는 인공 신경망 구조인 순환 신경망 (RNN, Recurrent Neural Network) 등 어떤 인공 신경망일 수 있으며, 데이터의 복잡도와 다양성에 따라 다양하 게 변형될 수 있다. 인공 신경망 기반의 학습을 진행한 모델 역시 하나의 모델만을 학습시켜 사용하지 않고 여러 모델들을 학습시켜 결합하는 방식으로 문제를 해결하는 앙상블 모델일 수 있다. 한편, 알고리즘 기반 기계 학습 모델과 인공 신경망 기반의 학습을 진행한 모델은 서로 보완적으로 사용될 수 있다. 예를 들어, 알고리즘 기반 기계 학습 모델은 인공 신경망 기반의 학습을 진행한 모델의 결과를 사용할 수 있으며, 인공 신경망 기반의 학습을 진행한 모델이 알고리즘 기반 기계 학습 모델의 결과를 사용할 수도 있다. 알고리즘 기반 기계 학습 모델과 인공 신경망 기반의 학습을 진행한 모델 간의 앙상블 모델이 사용될 수도 있다. 상술한 본 실시예들은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 실시예들은 하드웨어, 펌웨어 (firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 실시예들에 따른 딥 러닝 모델을 활용한 이미지 분류 방법은 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서, 컨트롤러, 마이크로 컨트롤러 또는 마이크로 프로세서 등에 의해 구현될 수 있다. 예를 들어 실시예들에 따른 이미지 분류 방법은 심층 신경망의 뉴런(neuron)과 시냅스(synapse)가 반도체 소자들로 구현된 인공지능 반도체 장치를 이용하여 구현될 수 있다. 이때 반도체 소자는 현재 사용하는 반도체 소자들, 예를 들어 SRAM이나 DRAM, NAND 등일 수도 있고, 차세대 반도체 소자들, RRAM이나 STT MRAM, PRAM 등 일 수도 있고, 이들의 조합일 수도 있다. 실시예들에 따른 이미지 분류 방법을 인공지능 반도체 장치를 이용하여 구현할 때, 딥 러닝 모델을 소프트 웨어로 학습한 결과(가중치)를 어레이로 배치된 시냅스 모방소자에 전사하거나 인공지능 반도체 장치에서 학습 을 진행할 수도 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 실시예들에 따른 이미지 분류 방법은 이상에서 설명된 기능 또는 동작들을 수행하는 장치, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리 유닛에 저장되어 프로세서에 의해 구동될 수 있다. 메모리 유닛은 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 프로세서와 데이터를 주고 받을 수 있다. 또한, 위에서 설명한 \"시스템\", \"프로세서\", \"컨트롤러\", \"컴포넌트\", \"모듈\", \"인터페이스\", \"모델\", 또는 \"유 닛\" 등의 용어는 일반적으로 컴퓨터 관련 엔티티 하드웨어, 하드웨어와 소프트웨어의 조합, 소프트웨어 또는 실 행 중인 소프트웨어를 의미할 수 있다. 예를 들어, 전술한 구성요소는 프로세서에 의해서 구동되는 프로세스, 프로세서, 컨트롤러, 제어 프로세서, 개체, 실행 스레드, 프로그램 및/또는 컴퓨터일 수 있지만 이에 국한되지 않는다. 예를 들어, 컨트롤러 또는 프로세서에서 실행 중인 애플리케이션과 컨트롤러 또는 프로세서가 모두 구 성 요소가 될 수 있다. 하나 이상의 구성 요소가 프로세스 및/또는 실행 스레드 내에 있을 수 있으며, 구성 요 소들은 하나의 장치(예: 시스템, 컴퓨팅 디바이스 등)에 위치하거나 둘 이상의 장치에 분산되어 위치할 수 있다. 한편, 또 다른 실시예는 전술한 이미지 분류 방법을 수행하는, 컴퓨터 기록매체에 저장되는 컴퓨터 프로그 램을 제공한다. 또한 또 다른 실시예는 전술한 이미지 분류 방법을 실현시키기 위한 프로그램을 기록한 컴 퓨터로 읽을 수 있는 기록매체를 제공한다. 기록매체에 기록된 프로그램은 컴퓨터에서 읽히어 설치되고 실행됨으로써 전술한 단계들을 실행할 수 있다. 이와 같이, 컴퓨터가 기록매체에 기록된 프로그램을 읽어 들여 프로그램으로 구현된 기능들을 실행시키기 위하 여, 전술한 프로그램은 컴퓨터의 프로세서(CPU)가 컴퓨터의 장치 인터페이스(Interface)를 통해 읽힐 수 있는 C, C++, JAVA, 기계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 전술한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Function Code)를 포함할 수 있고, 전 술한 기능들을 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수도 있다. 또한, 이러한 코드는 전술한 기능들을 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 컴퓨터 의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조 되어야 하는지에 대한 메모리 참조 관련 코드를 더 포함할 수 있다. 또한, 컴퓨터의 프로세서가 전술한 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서 버 등과 통신이 필요한 경우, 코드는 컴퓨터의 프로세서가 컴퓨터의 통신 모듈을 이용하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야만 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는 지 등에 대한 통신 관련 코드를 더 포함할 수도 있다. 이상에서 전술한 바와 같은 프로그램을 기록한 컴퓨터로 읽힐 수 있는 기록매체는, 일 예로, ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 미디어 저장장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함할 수 있다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고, 본 발명을 구현하기 위한 기능적인(Functional) 프로그램과 이와 관련된 코드 및 코드 세그먼트 등은,"}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "기록매체를 읽어서 프로그램을 실행시키는 컴퓨터의 시스템 환경 등을 고려하여, 본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론되거나 변경될 수도 있다. 도 7을 통해 설명된 이미지 분류 방법은, 컴퓨터에 의해 실행되는 애플리케이션이나 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임 의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 전술한 이미지 분류 방법은, 단말기에 기본적으로 설치된 애플리케이션(이는 단말기에 기본적으로 탑재된 플랫폼이나 운영체제 등에 포함된 프로그램을 포함할 수 있다)에 의해 실행될 수 있고, 사용자가 애플리케이션 스토어 서버, 애플리케이션 또는 해당 서비스와 관련된 웹 서버 등의 애플리케이션 제공 서버를 통해 마스터 단 말기에 직접 설치한 애플리케이션(즉, 프로그램)에 의해 실행될 수도 있다. 이러한 의미에서, 전술한 이미지 분 류 방법은 단말기에 기본적으로 설치되거나 사용자에 의해 직접 설치된 애플리케이션(즉, 프로그램)으로구현되고 단말기에 등의 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다."}
{"patent_id": "10-2023-0119320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 기술 사상의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형 이 가능할 것이다. 또한, 본 실시예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 므로 이러한 실시예에 의하여 본 기술 사상의 범위가 한정되는 것은 아니다. 본 개시의 보호 범위는 아래의 청 구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개시의 권리 범위에 포함 되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0119320", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 이미지 분류 장치의 블록도이다. 도 2는 도 1의 분류부에 포함된 분류 모델의 예시적 구성을 표현한 도면이다. 도 3은 분류 모델이 집중한 영역을 시각화하여 표현한 도면이다. 도 4는 도 2의 분류 모델 중 일부 구성이 변경된 구조를 나타내는 도면이다. 도 5는 도 4의 변경된 구조를 자세히 설명하는 도면이다. 도 6은 도 4의 변경된 구조를 갖는 분류 모델이 집중한 영역을 시각화하여 표현한 도면이다. 도 7은 다른 실시예에 따른 이미지 분류 방법의 흐름도이다. 도 8은 또 다른 실시예에 따른 컴퓨팅 시스템의 구성도이다. 도 9는 또 다른 실시예에 따른 클라이언트-서버의 컴퓨터 시스템의 구성도이다."}
