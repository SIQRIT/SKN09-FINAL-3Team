{"patent_id": "10-2018-7014315", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0057734", "출원번호": "10-2018-7014315", "발명의 명칭": "신체 이미징", "출원인": "마이피지크 리미티드", "발명자": "이스코, 캐서린"}}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 신체를 이미징하는 장치로서, 상기 장치는, 제어기;상기 제어기를 제어하기 위한 전자 프로그램 명령을 저장하는 저장 장치;사용자 인터페이스를 디스플레이하기 위한 디스플레이; 및시각적 이미지들을 캡처하도록 구성된 이미지 캡처 장치를 포함하고;상기 제어기는, 상기 전자 프로그램 명령의 제어 하에,상기 신체의 제1 표현을 포함하는 입력을 적어도 부분적으로 상기 이미지 캡처 장치를 통해 수신하는 동작으로서, 상기 제1 표현은 상기 신체의 하나 이상의 시각적 표현을 포함하는, 상기 입력을 수신하는 동작;상기 제1 표현을 상기 디스플레이를 통해 디스플레이하는 동작;상기 입력이 수신되면, (i) 골격 관절 위치들의 모델 및 (ii) 상기 사용자의 적어도 체중을 사용하여, 상기 디스플레이 상에 나타나는 사용자별 골격을 생성하는 동작;적어도 부분적으로 (i) 상기 신체의 하나 이상의 실시간 캡처된 이미지와 함께 상기 사용자별 골격을 디스플레이하고, (ii) 상기 디스플레이된 신체가 상기 디스플레이된 사용자별 골격과 정렬되는 방식으로 상기 사용자에게 이동할 것을 지시하는 것에 의해, 상기 사용자가 상기 제1 표현에 있는 상기 신체를 상기 사용자별 골격과정렬하게 하는 동작;상기 디스플레이된 신체가 상기 디스플레이된 사용자별 골격과 정렬되었을 때 상기 신체의 상기 제1 표현을 분할하는 것에 의해 상기 제1 표현을 처리하여 상기 신체의 실질적으로 진정한 3차원 스캔의 투영된 음영들에 대응하는 복수의 실루엣을 획득하는 동작;상기 복수의 실루엣에 기초하여 상기 신체의 제2 표현을 생성하는 동작; 및상기 생성된 제2 표현을 상기 디스플레이를 통해 디스플레이하는 동작을 수행하도록 동작가능한 것을 특징으로하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에,지능형 기계 학습 기술을 사용하여 오프라인으로 학습된 수천 개의 알려진 인간 형상과 복수의 실루엣에 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작을 수행하도록 동작가능한 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제어기는 또한, 상기 전자 프로그램 명령의 제어 하에, 상기 디스플레이된 신체의 부분들을 상기 디스플레이된 사용자별 골격과 정렬시킬 것을 가청 음성, 단어, 또는발언을 통해 상기 사용자에게 지시하도록 동작가능하고, 상기 전자 프로그램 명령은, 상기 생성된 골격과 상기신체의 하나 이상의 실시간 캡처된 이미지로부터 추출된 형상 특징, 자세 특징, 및 시공간 특징을 포함하는 특성들 사이에 계산된 에러들에 의해 정렬 공정을 제어하도록 동작가능한 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제어기는 또한, 상기 전자 프로그램 명령의 제어 하에, 제시된 사용자 신장 정보 및 픽셀 단위의 이미지 높이와 폭에 기초하여, 및 이진 이미지, 투영 이론 및 카메라공개특허 10-2018-0057734-3-모델의 얼룩 분석을 사용하여 다음, 즉:자세(P)로 정의된, 각 이미지에서 카메라 위치와 배향을 포함하는 캡처 카메라의 내재적 파라미터와 외인성 파라미터의 초기 추정치; 및상기 골격 모델의 각 관절의 3D 위치와 3D 배향을 포함하는, JK로 정의된, 상기 신체의 골격을 나타내는 골격모델의 관절 운동학(joint kinematics)의 초기 추정치를 계산하도록 동작가능한 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 제어기는 또한, 상기 전자 프로그램 명령의 제어 하에,제시된 사용자 신장과 체중 정보에 기초하거나 또는 상기 사용자 신장 정보에만 기초하여, 상기 사용자가 입력한 신장, 체중, 또는 알려진 경우 다른 신체 측정값에 따라 변하는, Av로 정의된 초기 평균 아바타를 예측하는동작; 및,W로 정의된 골 중량/신장 행렬과, 기준 자세에서 알려진 골격 모델(JK)을 갖는 사이즈 N-관절의 기준 골격에 평균 아바타(Av)를 장착하는 동작을 수행하도록 동작가능한 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 행렬(W)은 예측 공정의 학습 공정 동안 단 한번만 오프라인으로 계산되고 나서, 다른 아바타를 예측 또는 생성하는데 사용되기 위해 기준 골격 모델(JK)과 함께 기억되고, W는 관절, 골, 및 정점(V),에지(E) 및 면(F)으로 표시되는 실제 3D 아바타 표면 간의 관계를 제한하고 제어하고 모델링하는데 사용되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 초기 평균 아바타(Av)를 예측하는 공정은 다변수-기반 기계 학습 접근법을 따르는 것을특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 입력은 상기 신체의 분류를 더 포함하고, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 분류에 기초하여, 상기 신체의 분류에 대응하는 데이터를 획득하는 동작;상기 제1 표현과 상기 획득된 데이터를 더 비교함으로써 상기 제1 표현을 처리하는 동작; 및상기 비교에 더 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작을 수행하도록 동작가능한 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 획득된 데이터는 템플릿; 상기 신체의 이전의 표현; (i) 상기 신체 및 (ii) 다른 신체의하나 또는 둘 모두의 하나 이상의 이전의 표현의 통합 또는 이와 연관된 데이터의 통합 중 적어도 하나를 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 입력은, 움직임 센서; 적외선 센서; 깊이 센서; 3차원 이미징 센서; 관성 센서;MEMS(Micro-Electromechanical) 센서; 가속도 센서; 배향 센서; 방향 센서; 및 위치 센서 중 하나 이상의 센서를 통해 부분적으로 수신되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 입력은 평면과의 정렬을 용이하게 하여 정확도를 증가시키기 위해 상기 신체의 상기 하공개특허 10-2018-0057734-4-나 이상의 시각적 표현을 캡처하는 동안 사용할 배향 데이터를 제공하도록 동작가능한 배향 센서를 통해 부분적으로 수신되는 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 신체의 상기 하나 이상의 시각적 표현은 상기 신체의 정면도의 적어도 하나의 사진 및상기 신체의 측면도의 적어도 하나의 사진을 포함하고,상기 사진은, 표준 2차원(2D) 이진(binary), 그레이(gray) 또는 컬러(color) 이미지; 컬러와 질감 중 하나 또는 둘 모두가 있거나 없는 깊이 이미지;컬러와 질감 중 하나 또는 둘 모두가 있거나 없는, 상기 신체의 완전한 3차원(3D) 포인트 클라우드(pointcloud) 또는 다수의 불완전한 포인트 클라우드; 또는 컬러와 질감 중 하나 또는 둘 모두가 있거나 없는, 상기 신체의 3차원(3D) 메쉬 중 적어도 하나를 포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에,상기 신체의 부분들을 상기 디스플레이된 사용자별 골격과 정렬시킬 것을 가청 음성, 단어, 또는 발언을 통해상기 사용자에게 지시하는 동작으로서, 상기 전자 프로그램 명령은, 상기 생성된 골격과 상기 신체의 하나 이상의 실시간 캡처된 이미지로부터 추출된 형상 특징, 자세 특징, 및 시공간 특징을 포함하는 여러 데이터와 특성들 사이에 계산된 에러에 의해 정렬 공정을 제어하도록 동작가능한, 상기 사용자에게 지시하는 동작;상기 신체의 하나 이상의 시각적 표현의 하나 이상의 전경(foreground) 구역 또는 특징부를, 명확하거나, 가능성이 매우 높거나, 또는 아마도/대개 가능성이 있는 신체 부분으로 분할하는 동작;상기 하나 이상의 시각적 표현의 상기 하나 이상의 분할된 전경 구역 또는 특징부를 상기 복수의 실루엣의 각각의 실루엣으로 변환하는 동작;상기 하나 이상의 분할된 전경 구역 또는 특징부 및 각각의 실루엣을 사용하여 (i) 상기 신체의 형상의 외피(hull)를 구성하는 동작, (ii) 특징을 추출하는 동작, 및/또는 (iii) 키 포인트의 측정값을 추출하는 동작 중하나 이상의 동작을 수행하는 동작; 및상기 외피, 특징, 또는 키 포인트 측정값 중 하나 이상을 사용하여, 선택된 템플릿의 평균 신체의 3D 모델을 수정, 장착 및 변형하는 것 중 하나 이상을 수행하여, 상기 제2 표현인 수정된 개체별 3D 모델 이미지를 생성하는동작을 수행하도록 더 동작가능한 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13에 있어서, 컬러와 질감 중 하나 또는 둘 모두가 있거나 없는, 깊이 이미지, 포인트 클라우드 및 메쉬의 경우, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 3차원 개체별 형상을 재구성하도록 동작가능한 것을 특징으로 하는 장치."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "사용자의 신체를 이미징하는 방법으로서, 상기 방법은, 제어기를 제어하기 위한 전자 프로그램 명령을 저장하는 단계; 및상기 전자 프로그램 명령을 통해 상기 제어기를 제어하여,시각적 이미지들을 캡처하도록 구성된 이미지 캡처 장치를 통해 상기 신체의 제1 표현을 포함하는 입력을 수신하는 동작으로서, 상기 제1 표현은 상기 신체의 하나 이상의 시각적 표현을 포함하는, 상기 입력을 수신하는 동작;공개특허 10-2018-0057734-5-상기 제1 표현을 사용자 디스플레이 상에 디스플레이하는 동작;상기 입력이 수신되면, (i) 골격 관절 위치의 모델 및 (ii) 상기 사용의 적어도 체중을 사용하여, 상기 디스플레이 상에 나타나는 사용자별 골격을 생성하는 동작;적어도 부분적으로 (i) 상기 신체의 하나 이상의 실시간 캡처된 이미지와 함께 상기 사용자별 골격을 디스플레이하고, (ii) 상기 디스플레이된 신체가 상기 디스플레이된 사용자별 골격과 정렬되는 방식으로 상기 사용자에게 이동할 것을 지시하는 것에 의해, 상기 사용자가 상기 제1 표현에 있는 상기 신체를 상기 사용자별 골격과정렬하게 하는 동작;상기 디스플레이된 신체가 상기 디스플레이된 사용자별 골격과 정렬되었을 때 상기 신체의 상기 제1 표현을 분할하는 것에 의해 상기 제1 표현을 처리하여, 상기 신체의 실질적으로 진정한 3차원 스캔의 투영된 음영들에 대응하는 복수의 실루엣을 획득하는 동작; 상기 복수의 실루엣에 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작; 및상기 생성된 제2 표현을 디스플레이하는 동작을 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 사용자가 상기 신체를 상기 사용자별 골격과 정렬하게 하는 동작은, 상기 신체의 부분들을 상기 디스플레이된 사용자별 골격과 정렬시킬 것을 가청 음성, 단어, 또는 발언을 통해 상기 사용자에게 지시하는 동작을 포함하고, 상기 전자 프로그램 명령은, 상기 생성된 골격과 상기 신체의 하나 이상의 실시간 캡처된 이미지로부터 추출된 형상 특징, 자세 특징, 및 시공간 특징을 포함하는 특성들 사이에 계산된 에러에 의해 정렬 공정을 제어하도록 동작가능한 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 전자 프로그램 명령을 통해 상기 제어기를 제어하여,제시된 사용자 신장 정보 및 픽셀 단위의 이미지 높이 및 폭에 기초하여, 및 이진 이미지, 투영 이론 및 카메라모델의 얼룩 분석을 사용하여 다음, 즉:자세(P)로 정의된, 각 이미지에서 카메라 위치와 배향을 포함하는 캡처 카메라의 내재적 파라미터와 외인성 파라미터의 초기 추정치; 및상기 골격 모델의 각 관절의 3D 위치와 3D 배향을 포함하는, JK로 정의된, 상기 신체의 골격을 나타내는 골격모델의 관절 운동학의 초기 추정치를 계산하는 동작을 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 전자 프로그램 명령을 통해 상기 제어기를 제어하여,제시된 사용자 신장과 체중 정보에 기초하여 또는 상기 사용자 신장 정보에만 기초하여, 상기 사용자가 입력한신장, 체중, 또는 알려진 경우 다른 신체 측정값에 따라 변하는, Av로 정의된, 초기 평균 아바타를 예측하는 동작; 및W로 정의된 골 중량/신장 행렬과, 기준 자세에서 알려진 골격 모델(JK)을 갖는 사이즈 N-관절의 기준 골격에 상기 평균 아바타(Av)를 장착하는 동작을 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 행렬(W)은 예측 공정의 학습 공정 동안 단 한번만 오프라인으로 계산되고 나서, 다른 아바타를 예측 또는 생성하는데 사용되기 위해 기준 골격 모델(JK)과 함께 기억되고, W는 관절, 골, 및 정점(V),에지(E) 및 면(F)으로 표시되는 실제 3D 아바타 표면 사이의 관계를 제한하고 제어하고 모델링하는데 사용되는공개특허 10-2018-0057734-6-것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 초기 평균 아바타(Av)를 예측하는 공정은 다변수-기반 기계 학습 접근법을 따르는 것을특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 다변수-기반 기계 학습 접근법은 상이한 연령과 자세의 실제 인간의 복수의 장착되고 렌더링된 3차원 스캔으로부터 추출된 3D 특징을 사용하여 인간 형상을 오프라인으로 기계 지능으로 학습하는 것을포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 다변수-기반 기계 학습 접근법은 L개의 상이한 측정값을 갖는 벡터 M = (m1, m2, ...,mL)로서 정의된 상이한 신체 측정값들 사이의 다양한 통계적 관계를 기계 지능으로 학습하는 것을 더 포함하고,사용시 하나 이상의 측정값은 하나 이상의 상이한 측정값이 주어진 경우 예측될 수 있고, 평균 아바타(Av)는 상기 측정값들 중 하나 이상이 주어진 경우 예측될 수 있는 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 아바타를, 새로운 제1 표현으로 표현된, 상기 신체의 Av1로 정의된 새로운 아바타로 변형시키거나 단순히 애니메이팅하기 위해, 상기 기준 또는 평균 아바타 데이터(V, E, F, JK, W)와, 상기 새로운 제1 표현의 JK1로 정의된 사용자 관절 운동학의 알려진 또는 추정치는 자연스러운 인간 동작으로부터 알려진 또는 학습된 다수의 물리적 제약 조건에 따라 Av를 Av1로 최적화하고 변형시키는 비용 함수에 공급되고, 사용시, 상기평균 아바타(Av)와 동일한 신체 측정값을 갖는 상기 새로운 애니메이팅된 아바타(Av1)는 Av1 = f(Av, W, JK,JK1)이도록 상기 기준 또는 평균 데이터의 함수인 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 2개의 가중된 에너지 최소화 함수, 즉V, F 및 E를 사용하는 라플라시안 코탄젠트 행렬을 사용하는 표면 평활 함수; 및V, F 및 W를 사용하여 아바타 정점들과 그 골격 구조 사이에 대응 관계가 제한되는 것을 보장하는 골 부착 함수를 결합시키는 함수가 유도되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제15항에 있어서, 상기 입력은 상기 신체의 분류를 더 포함하고, 상기 전자 프로그램 명령을 통해 상기 제어기를 제어하여,상기 신체의 분류에 기초하여, 상기 신체의 분류에 대응하는 데이터를 획득하는 동작;상기 제1 표현과 상기 획득된 데이터를 더 비교함으로써 상기 제1 표현을 처리하는 동작; 및상기 비교에 더 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작을 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2018-7014315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "비-일시적인 컴퓨터 판독가능한 저장 매체로서, 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서로 하여금, 신체의 제1 표현을 포함하는 입력을 시각적 이미지들을 캡처하도록 구성된 이미지 캡처 장치를 통해 수신하는동작으로서, 상기 제1 표현은 상기 신체의 하나 이상의 시각적 표현을 포함하는, 상기 입력을 수신하는 동작;상기 제1 표현을 사용자 디스플레이 상에 디스플레이하는 동작;상기 입력이 수신되면, (i) 골격 관절 위치들의 모델 및 (ii) 사용자의 적어도 체중을 사용하여, 상기 디스플레공개특허 10-2018-0057734-7-이 상에 나타나는 사용자별 골격을 생성하는 동작;적어도 부분적으로 (i) 상기 신체의 하나 이상의 실시간 캡처된 이미지와 함께 상기 사용자별 골격을 디스플레이하고, (ii) 상기 디스플레이된 신체가 상기 디스플레이된 사용자별 골격과 정렬되는 방식으로 상기 사용자에게 이동할 것을 지시하는 것에 의해, 상기 사용자가 상기 제1 표현에 있는 상기 신체를 상기 사용자별 골격과정렬하게 하는 동작;상기 디스플레이된 신체가 상기 디스플레이된 사용자별 골격과 정렬되었을 때 상기 신체의 상기 제1 표현을 분할하는 것에 의해 상기 제1 표현을 처리하여 상기 신체의 실질적으로 진정한 3차원 스캔의 투영된 음영들에 대응하는 복수의 실루엣을 획득하는 동작;상기 복수의 실루엣에 기초하여 상기 신체의 제2 표현을 생성하는 동작; 및상기 생성된 제2 표현을 디스플레이하는 동작을 수행하게 하는 명령을 저장하는 것을 특징으로 하는 비-일시적인 컴퓨터-판독가능한 저장 매체."}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 양태에서, 신체를 이미징하는 장치가 개시된다. 일 배열에서, 상기 장치는, 제어기; 상기 제어기를 제어하기 위한 전자 프로그램 명령을 저장하는 저장 장치; 사용자 인터페이스를 디스플레이하기 위한 디스플레이; 및 입력 수단을 포함한다. 일 형태에서, 상기 제어기는, 전자 프로그램 명령의 제어 하에, 상기 신체의 제1 표현을 포함 하는 입력을 상기 입력 수단을 통해 수신하는 동작; 상기 제1 표현을 처리하는 동작; 상기 제1 표현의 처리에 기 초하여 상기 신체의 제2 표현을 생성하는 동작; 및 상기 생성된 제2 표현을 상기 디스플레이를 통해 디스플레이 하는 동작을 수행하도록 동작할 수 있다."}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 일반적으로 신체를 이미징하는 것에 관한 것이다. 본 발명은 개인의 피트니스(personal fitness) 목표를 포함하는 목적을 달성하는 것을 용이하게 하기 위해 특히 인체를 이미징하는 것과 관련하여 설명될 것이지만, 추가적인 목적 및/또는 다른 목적을 위해 및 다른 것의 신 체에 사용될 수도 있는 것으로 이해된다."}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간 비만은 전세계적으로 유행하고 있는 것으로 확인되었다. 세계 보건 기구(World Health Organisation) 2008 의 간행물: 세계 질병 부담 연구 2013, The Lancet에 따르면 과체중으로 분류된 사람들의 추정 숫자는 1980년 8 억 5천 7백만 명에서 2013년 21억 명으로 증가했으며 2030년까지 40억 명이 과체중이 될 것으로 예측되었다. 이것은 경제적 비용이 든다. 예를 들어, 영국에서는 2007년에 남성의 42%와 여성의 32%가 과체중인 것으로 추정 되어 경제적 비용이 260억 US달러로 추정되었고, 미국에서는 2010년에 남성의 74%와 여성의 64%가 과체중으로 추정되어 경제적 비용이 1,470억 US달러로 추정되었으며, 호주에서는 2012년에 남성의 42%와 여성의 28%가 과체 중인 것으로 추정되어 경제적 비용이 530억 US달러로 추정되었다. [국립 건강 및 의학 연구 협의회(National Health and Medical Research Council: NHMRC), 호주 심장 재단(Australian Heart Foundation); 질병 통제 센 터(Centre for Disease Control: CDC); 국민 건강 및 영양 심사 서베이(National Health and Nutrition Examination Survey: NHANES); 보건 및 사회 복지 정보 센터(The Health and Social Care Information Centre: HSCIC).] 또한, 다음 사항이 보고되었다: 절반 이상의 호주인(55.7%)과 미국인(51%)이 체중 감량을 시도하고 있고; 건강 한 체중 범위에 있는 여성의 45%와 남성의 23%는 과체중이라고 생각한다; 약 91%의 여성이 자신의 신체에 만족 하지 않는다; 및 비만의 증가는 주로 20세 내지 40세에서 발생한다. [Jeffery RW, Sherwood NE, Brelje K, et al. 건강-관리 환경에서 체중 감량을 위한 메일 및 전화 중재(Mail and phone interventions for weight loss in a managed-care setting): 체중 감량 1년 결과(Weigh-To-Be one-year outcome). Int J Obes Related Metab Disord. 2003; 27:1584-1592; Linde JA, Jeffery RW, French SA, Pronk NP, Boyle RG. 체중 증가 예방 및 체중 감소 실험에서의 자기 측정(Selfweighing in weight gain prevention and weight loss trial). Ann Behav Med. 2005;30:210-216; Butryn ML, Phelan S, Hill JO, Wing RR. 지속적인 체중 자가 모니터링: 성공적인 체중 감량 관리의 핵심 요소. 비만(a key component of successful weight loss maintenance. Obesit). 2007;15:3091-3096; 기술 붐: 비만 관리의 새로운 시대(The Technology Boom: A New Era in Obesity Managemen). Gilmore, Duhe, Frost, Redman. J Diabetes Sci Technol. 2014 Feb 27;8: 596-608.] 이러한 통계에 비춰볼 때, 많은 사람들이 체중을 감량시키거나 증가시키거나 또는 유지하거나/모니터링하거나 및/또는 신체 사이즈 또는 형상(shape)을 향상시키려는 개인의 피트니스 목표를 가지고 있다는 것은 놀라운 일이 아니다. 연구에 따르면, 체중 측정 및/또는 둘레 측정과 같은 빈번한 자가 모니터링이 체중 감량 및/또는 체중 증가, 및 다른 피트니스 목표를 달성하는데 결정적이지는 않지만 중요한 역할을 하는 것을 반복적으로 보여주었다. 체중을 모니터링하는 현재의 방법은 다음을 포함한다: 저울(weighing scale)의 사용(즉, 물체의 무게 또는 질량을 측정하는 측정 기구). 이 기술은 저렴하고 빠르 다는 장점이 있지만 신체 형상의 변화를 나타낼 수는 없다. 측정 테이프의 사용. 저렴한 반면, 이 기술은 사용자 에러, 비실용적이며 시간 소모적인 경향이 있다. 이중 에너지 X선 흡수 측정법(DXA 또는 DEXA) 사용. 이 기술은 정확한 신체 조성 측정을 용이하게 하지만, 신체 허리/둘레 측정을 제공하지 않고, 비싸고 시간이 많이 걸린다는 단점이 있다. 또한 이것은 건강 문제와 관 련이 있을 수 있다. 이와 관련하여 이 기술에 사용된 방사선의 양은 임상적 및 상업적 용도로 표준 흉부 X-선 선량의 1/10 미만이며 자연 방사선에 대한 하루 노출량 미만으로 통상적으로 극히 작은 양이지만 건강에 영향을 미치기 때문에 개인은 연 2회만 스캔되어야 한다는 권고 사항이 있다. Image Twin™ 및 mPort™ 상표로 제공되는 것과 같은 3차원(3D) 바디 스캐너 및 매퍼(mapper)의 사용. Image Twin™ 시스템은 신체의 정확한 3D 아바타 표현(avatar representation)을 생성할 수 있지만, 이것은 비 용이 많이 들고 통상적으로 실험실에 위치된 특수 장비의 사용을 필요로 한다. mPort™ 시스템은 신체의 정확한 3D 아바타 표현을 생성할 수 있고 둘레 측정을 제공할 수 있다. 그러나, 이것도 또한 비싸고, 규정된 위치에서 특수 장비를 사용할 것을 요구하며 체중 변화에 대한 그래픽 데이터만 제공한다. Model My Diet™, Change in Seconds™ 및 Virtual Weight Loss Model Lite™ (소프트웨어 애플리케이션) 상표로 제공된 것과 같은 가상 체중 감량 시뮬레이터의 사용. 이러한 시스템은 통상적으로 신체의 \"이전\" 및 \" 이후\" 만화 아바타 표현을 생성할 수 있다. 이런 시스템은 컴퓨터, 예를 들어, 데스크탑에서 실행되는 실행가능 한(executable) 것으로만 이용가능하고, 기본 인체 측정 데이터를 사용하여 기본 추정치만을 제공한다. 상표 Optitex™로 제공되는 것과 같은 가상 제품 시뮬레이터의 사용. Optitex™ 시스템은 신체의 하나의 만 화 아바타 표현을 생성할 수 있다. 이 시스템은 컴퓨터에서 실행되는 실행가능한 것으로만 이용가능하고, 기본 인체 측정 데이터를 사용하여 기본 추정치만을 제공한다. Good Housekeeping™ 상표로 제공되는 것과 같은 사진의 사용. Good Housekeeping™ 시스템은 사진 기반이 지만 이미지 조작/처리 소프트웨어(예를 들어, 포토샵)에 사용되는 이미지 변형 접근 방식(image morphing approach)의 기본 유형인 2차원(2D) 공간에 업로드된 사진을 간단하게 축소 및 확장할 수 있다. 조사(J Diabetes Sci Technol. 2013년 7월 1일 발행; 7:1057-65. 아바타를 사용하여 체중 감량 행동 모델링: 참가자의 태도와 기술 개발)에 따르면, 유망도를 나타내는 조형적 작업이 있는 아바타 기반 프로그램에 높은 관심도를 보여주었다. 생체 내 노출 및 실행과 관련된 높은 비용을 감안할 때 이 조사는 아바타 기반 기술 을 체중 감량 행동을 모델링하는 도구로 사용할 가능성이 있음을 보여준다. 이러한 배경을 감안하여 본 발명이 개발되었다."}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 전술한 선행 기술의 결점 중 하나 이상을 극복하거나 적어도 개선하거나, 또는 소비자에게 유 용하거나 상업적인 선택권을 제공하는 것이다. 본 발명의 다른 목적 및 잇점은 설명과 예시를 위하여 본 발명의 바람직한 실시예가 개시된 첨부된 도면과 관련 하여 취해진 다음의 설명으로부터 명백히 드러날 것이다."}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 광의의 양태에 따르면, 신체를 이미징하는 장치가 제공되며, 상기 장치는, 제어기; *상기 제어기를 제어하기 위한 전자 프로그램 명령을 저장하는 저장 장치(storage); 사용자 인터페이스를 디스플레이하기 위한 디스플레이; 및 입력 수단을 포함하고; 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 분류 및 상기 신체의 제1 표현을 포함하는 입력을 상기 입력 수단을 통해 수신하는 동작; 상기 신체의 분류가 주어진 경우 상기 제1 표현을 처리하는 동작; 상기 제1 표현의 처리에 기초하여 상기 신체의 제2 표현을 생성하는 동작; 및 상기 생성된 제2 표현을 상기 디스플레이를 통해 디스플레이하는 동작을 수행하도록 동작가능하다. 본 발명의 제1 광의의 양태에 따르면, 신체를 이미징하는 장치가 제공되며, 상기 장치는, 제어기; 상기 제어기를 제어하기 위한 전자 프로그램 명령을 저장하는 저장 장치; 사용자 인터페이스를 디스플레이하기 위한 디스플레이; 및 입력 수단을 포함하고; 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 제1 표현을 포함하는 입력을 상기 입력 수단을 통해 수신하는 동작; 상기 제1 표현을 상기 디스플레이를 통해 디스플레이하는 동작; 상기 입력이 수신되면, 상기 디스플레이 상에 나타나는 사용자별 골격을 생성하는 동작; 상기 사용자로 하여금 상기 제1 표현에 있는 상기 신체를 상기 사용자별 골격과 정렬하게 하는 동작; 상기 신체의 상기 제1 표현을 분할(segmenting)하는 것에 의해 상기 신체가 상기 사용자별 골격과 정렬되었을 때 상기 제1 표현을 처리하는 동작; 상기 제1 표현의 처리에 기초하여 상기 신체의 제2 표현을 생성하는 동작; 및 상기 생성된 제2 표현을 상기 디스플레이를 통해 디스플레이하는 동작을 수행하도록 동작가능하다. 일 실시예에서, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 상기 제1 표현을 분할하는 것에 의해 상기 신체의 상기 제1 표현을 처리하여, 상기 신체의 실질적으로 진정한 3차원 스캔의 투영된 음영 (projected shadow)을 간단한 형태로 나타내는 복수의 실루엣(silhouette)을 획득하는 동작; 및 상기 실루엣에 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작을 수행하도록 동작가능하다. 일 실시예에서, 상기 실루엣은 예를 들어 투영 및 인체의 기본적인 움직임을 포함할 수 있다. 다른 실시예에서, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 상기 제1 표현을 분할하 는 것에 의해 상기 신체의 상기 제1 표현을 처리하여, 상기 신체의 실질적으로 진정한 3차원 스캔의 투영된 음 영(projected shadow)을 간단한 형태로 나타내는 복수의 실루엣(silhouette)을 획득하는 동작; 상기 실루엣에 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작; 및 지능형 기계 학습 기술을 사용하여 오프라인으로 학 습된 수천 개의 알려진 인간 형상과 실루엣에 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작을 수행하도 록 동작가능하다. 유리하게는, 상기 제어기는 또한, 상기 전자 프로그램 명령의 제어 하에, 상기 디스플레이된 사용자별 골격에 상기 신체의 부분들을 정렬시킬 것을 가청 음성, 단어 또는 발언을 통해 상 기 사용자에게 지시하는 동작을 수행하도록 동작가능하고, 상기 전자 프로그램 명령은 생성된 골격과 상기 신체 의 하나 이상의 실시간 캡처된 이미지들로부터 추출된 형상 특징, 자세 특징 및 시공간 특징을 포함하는 특성들사이에서 계산된 에러들에 의해 정렬 공정을 제어하도록 동작가능하다. 바람직하게는, 상기 제어기는 또한, 상기 전자 프로그램 명령의 제어 하에, 제시된 사용자 신장 정보, 이미지 사이즈(픽셀 단위의 이미지 높이와 폭)에 기초하여, 및 이진 이미지(binary image), 투영 이론 및 카메라 모델의 얼룩(blob) 분석을 사용하여, 다음, 즉: 자세(P)로 정의된, 각 이미지에서 카메라 위치와 방향을 포함하는 캡처 센서 또는 카메라의 내재적 파라미터와 외인성 파라미터의 초기 추정치; 및 골격 모델의 각 관절의 3D 위치와 3D 방향을 포함하는, JK로 정의된, 상기 신체의 골격을 나타내는 상기 골격 모델의 관절 운동학(joint kinematics)의 초기 추정치를 계산하도록 동작가능하다. 이 실시예에서, 상기 제어기는 또한, 상기 전자 프로그램 명령의 제어 하에, 제시된 사용자 신장과 체중 및 정보 또는 사용자 신장과 정보에만 기초하여, 일반적으로 사용자의 입력된 신장, 체중 또는 알려진 경우 다른 신체 측정값에 따라 변하는, Av로 정의된, 초기 평균 아바타(on-average avatar)를 예측하는 동작; 및 W로 정의된 골 중량(bone weight)/신장 행렬(height matrix)과 기준 자세에서 알려진 골격 모델(JK)을 갖는 사 이즈 N-관절의 기준 골격에 상기 평균 아바타(Av)를 장착(rig)하는 동작을 수행하도록 동작가능하다. 바람직하게는, 상기 행렬(W)은 인간 형상의 오프라인 기계 학습 공정 동안 단 한번만 오프라인으로 계산되고 나 서, 이전에 학습되지 않은 다른 아바타 또는 인간 형상을 예측하거나 또는 생성하는데 사용되기 위해 기준 골격 모델(JK)과 함께 기억(saved)되고, 여기서 W는 관절, 골, 및 인간의 피부에서 발생하는 자연스러운 변형 (deformation)을 포함하는 실제 3D 아바타 표면 또는 3D 토폴로지 사이의 관계를 제한하고 제어하고 모델링하는 데 사용된다. 이 표면 또는 3D 토폴로지는 정점(vertex)(V), 에지(edge)(E) 및 면(face)(F)으로 고유하게 모델 링되고 표현될 수 있다. 유리하게는, 초기 평균 아바타(Av)를 예측하는 공정은 다변수-기반 기계 학습 접근법을 따른다. 바람직하게는, 다변수-기반 기계 학습 접근법은 상이한 연령, 인종 및 상이한 신체 자세의 실제 인간(남성과 여성)의 복수의 장착되고 렌더링된 3차원 스캔으로부터 추출된 고유하고 현저한 3D 특징을 사용하여 인간 형상의 3D 기하학적 형상의 오프라인 학습을 포함한다. 통상적으로, 다변수-기반 기계 학습 접근법은 L개의 상이한 측정값을 갖는 벡터 M = (m1, m2, ..., mL)으로 정의된 상이한 신체 측정값들 사이의 다양한 통계적 관계를 더 포함하고, 사용 시 하나 이상의 측정값은 하나 이상의 상이한 측정값이 주어진 경우 예측될 수 있고, 평균 아바타(Av)는 이들 측정값들 중 하나 이상이 주어진 경우 예측될 수 있다. 바람직하게는, 아바타를, 새로운 제1 표현으로 표현된, 신체의 Av1로 정의된 새로운 아바타로 변형시키거나 간 단히 애니메이팅하기 위해, 상기 기준 또는 평균 아바타 데이터(V, E, F, JK, W)와, 상기 새로운 제1 표현의 JK1로 정의된 사용자 관절 운동학의 알려진 또는 추정치는 자연스러운 인간 동작으로부터 알려지거나 학습된 다 수의 물리적 제약 조건(constraint)에 따라 Av를 Av1로 최적화하고 변형시키는 ￡로 정의된 비용 함수에 공급되 고, 사용시, 상기 새로운 애니메이팅된 아바타(Av1)는 단순화를 위해 평균 아바타(Av)와 동일한 신체 측정값을 갖는다고 가정하면, 기준 또는 평균 아바타 데이터의 비선형 함수로 모델링될 수 있고, 즉 Av1 = f(Av, W, JK, JK1)로 모델링될 수 있다. 통상적으로 비용 함수(￡)의 구현은 다음 함수, 즉 V, F 및 E를 사용하는 예를 들어 라플라시안 코탄젠트 행렬(Laplacian cotangent matrix)을 사용하는 표면 평활 함수(surface smoothness function); 및 V, F 및 W를 사용하여 아바타 정점과 그 골격 구조 사이에 대응 관계가 제한되는 것을 보장하는 골 부착 함수 (bone attachment function) 를 포함하는 2개 이상의 가중된 에너지 최소화 함수를 결합하는 것에 의해 유도된다. 바람직하게는, 실제 신체의 3D 표현, 즉 3D 아바타를 생성하기 위해; 실루엣 또는 그 표현 중 하나 이상에 대한 적응적 비선형 최적화를 사용하여 Av1의 하나 이상의 표현이 매칭되고 비교된다. 이 공정은 매칭이 달성될 때까 지 M, JK를 포함하는 Av1 데이터와 측정값의 초기 추정치를 조정(tune up)한다. 추가적인 실시예에서, 상기 입력은 상기 신체의 분류를 포함하고, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 분류에 기초하여, 상기 신체 분류에 대응하는 데이터를 획득하는 동작; 상기 제1 표현과 상기 획득된 데이터를 비교함으로써 상기 제1 표현을 처리하는 동작; 및 상기 비교에 기초하여 상기 신체의 상기 제2 표현을 생성하는 동작을 수행하도록 동작가능하다. 일 실시예에서, 상기 입력은 상기 신체의 상세를 포함한다. 상기 상세는 상기 신체와 관련된 데이터 및/또는 정 보를 포함할 수 있다. 본 발명의 실시예에서, 상기 데이터는 하나 이상의 소스로부터 데이터를 검색, 수신, 추출 및 식별하는 것 중 하나 이상에 의해 획득될 수 있다. 일 실시예에서, 상기 획득된 데이터는 템플릿(template); 상기 신체의 이전 의 표현(이 경우 상기 신체 분류는 상기 신체의 식별을 포함할 수 있다); 및 상기 신체 및/또는 다른 신체의 하 나 이상의 이전의 표현의 통합 또는 이의 데이터의 통합 또는 이와 연관된 것 중 적어도 하나를 포함한다. 일 실시예에서, 상기 신체의 상기 제1 표현은 상기 신체의 분류를 포함한다. 일 실시예에서, 상기 신체는 인체 또는 그 하나 이상의 부분이다. 이 경우 상기 신체는 인체 측정법에 따라 분 류될 수 있다. 일 실시예에서, 상기 장치는 복수의 템플릿을 포함하고, 각 템플릿은 표준 평균 인체 측정 측정 값을 갖는 인체의 3차원 모델을 포함하는 템플릿 데이터와 관련된다. 이것은 평균 신체 모델이라고 지칭될 수 있다. 상기 표준 평균 인체 측정 측정값은 성별, 사이즈(예를 들어, 사람의 옷 사이즈), 체중, 신장, 연령 및 인종 그룹의 변동에 대한 측정값을 포함하는 하나 이상의 측정값에 대한 것일 수 있다. 일 실시예에서, 상기 신체는 살아 있는 것의 신체 또는 그 하나 이상의 부분이다. 일 실시예에서, 상기 신체는 살아 있지 않은 것의 신체 또는 그 하나 이상의 부분이다. 상기 입력 수단은 적어도 하나의 센서를 포함할 수 있으며, 상기 센서는 센서 시스템 또는 센서 세트의 일부일 수 있다. 일 실시예에서, 상기 제1 표현은 상기 신체의 시각적 표현을 포함한다. 이러한 구현예에서, 상기 적어도 하나의 센서는 상기 신체의 시각적 표현을 캡처하도록 동작가능한 이미징 수단을 포함할 수 있다. 상기 이미징 수단은 디지털 카메라일 수 있다. 상기 센서 세트 내의 개별 센서는 움직임 센서; 적외선 센서; 깊이 센서; 3차원 이미징 센서; 관성 센서; MEMS(Micro-Electromechanical) 센서; 이미징 수단; 가속도 센서; 방향 센서; 방위 센서; 및 위치 센서를 포함 할 수 있다. 일 실시예에서, 상기 제1 표현은 상기 신체의 하나 이상의 시각적 표현을 포함한다. 이러한 실시예에서, 제공되 는 경우, 상기 하나 이상의 센서는, 상기 신체의 하나 이상의 시각적 표현을 캡처하도록 동작가능한 이미징 수 단을 포함할 수 있다. 또한, 상기 하나 이상의 센서는 증가된 정확도를 위해 평면과의 정렬을 용이하게 하기 위 해 상기 신체의 상기 하나 이상의 시각적 표현을 캡처하는 동안 사용할 방향 데이터를 제공하도록 동작가능한 방향 센서를 포함할 수 있다. 일 실시예에서, 상기 신체의 상기 하나 이상의 시각적 표현은 상기 신체의 적어도 하나의 정면 사진과 적어도 하나의 측면 사진을 포함한다. 상기 사진은 본 발명의 실시예에서, 표준 2차원(2D) 이진, 그레이(gray) 또는 컬 러(color) 이미지; 컬러 및/또는 질감(texture)이 있거나 없는 깊이 이미지; 컬러 및/또는 질감이 있거나 없는 완전한 3차원(3D) 포인트 클라우드(point cloud) 또는 다수의 불완전한 포인트 클라우드; 및/또는 컬러 및/또는 질감이 있거나 없는 신체의 3차원(3D) 메쉬(mesh)를 포함할 수 있다. 일 실시예에서, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 제1 표현의 상기 신체의 하나 이상의 시각적 표현의 상기 신체를 포함하는 적어도 하나의 전경 (foreground)을 분할하는 동작; 상기 제1 표현의 상기 하나 이상의 시각적 표현의 상기 하나 이상의 분할된 전경을 각 실루엣으로 변환하는 동 작; 상기 하나 이상의 분할된 전경과 각 실루엣을 사용하여 (ⅰ) 상기 신체의 형상의 3D 시각적 외피(visual hull) 를 구성, (ⅱ) 특징을 추출 또는 (ⅲ) 키 포인트(key point)의 측정값을 추출 중 하나 이상을 수행하는 동작; 및 상기 외피, 특징 또는 키 포인트 측정값 중 하나 이상을 사용하여, 선택된 템플릿의 평균 신체의 3D 모델을 수 정(modify), 장착(rig) 및 변형(morph)하는 것 중 하나 이상을 수행하여, 상기 제2 표현인 수정된 개체별 3D 모델 이미지를 생성하는 동작을 수행하도록 더 동작가능하다. 일 실시예에서, 컬러 및/또는 질감이 있거나 없는, 깊이 이미지, 포인트 클라우드 및 메쉬의 경우, 상기 제어기 는, 상기 전자 프로그램 명령의 제어 하에, 상기 신체의 3차원 개체별 형상을 재구성하도록 동작할 수 있다. 일 실시예에서, 상기 제어기는, 상기 전자 프로그램 명령의 제어 하에, 상기 제1 표현의 상기 하나 이상의 시각적 표현을 삭제하도록 더 동작할 수 있다. 상기 디스플레이, 사용자 인터페이스 및 입력 수단은 예를 들어 터치스크린에 통합될 수 있다. 대안적으로 이들 은 별개의 것일 수도 있다. 일 실시예에서, 상기 입력은 상기 입력 수단을 통해 사용자에 의해 입력되는 사용자 명령을 포함한다. 상기 사 용자 명령은 동작을 수행하기 위한 명령을 포함할 수 있으며, 이 경우 상기 제어기는, 상기 전자 프로그램 명령 의 제어 하에, 상기 수신된 사용자 명령에 따라 상기 동작을 수행하도록 동작할 수 있다. 상기 동작은 상호 작용 동작을 포함할 수 있고, 다음 중 하나 이상의 동작, 즉 생성된 제2 표현의 영역 또는 부 분을 선택하여 그 측정 상세를 획득하는 동작을 포함할 수 있다. 상기 템플릿은 상기 장치의 저장 장치로부터 검색되거나 또는 상기 장치로부터 원격에 있는 저장 장치로부터 검 색될 수 있다. 실시예에서, 상기 제1 표현, 상기 템플릿 및 상기 제2 표현 중 하나 이상은 하나 이상의 데이터베이스 내에 또 는 상기 데이터베이스에 걸쳐 저장될 수 있다. 일 실시예에서, 상기 전자 프로그램 명령은 소프트웨어를 포함한다. 상기 장치는 이동 통신 장치일 수 있으며, 이 경우 상기 이동 통신 장치는 소프트웨어가 설치된, 스마트폰, 노트북/태블릿/데스크탑 컴퓨터, 카메라 또는 휴대용 미디어 장치를 포함할 수 있다. 상기 소프트웨어는 상기 장치에 다운로드될 수 있는 소프트웨어 애플리 케이션으로 제공될 수 있다. 바람직하게는, 상기 장치에 의해 수행되는 동작은 사람의 개입 없이 자동적으로 발생한다. 본 발명의 제2 광의의 양태에 따르면, 신체를 이미징하는 방법이 제공되고, 상기 방법은, 제어기를 제어하기 위한 전자 프로그램 명령을 저장하는 단계; 및 상기 전자 프로그램 명령을 통해 상기 제어기를 제어하여, 상기 신체의 제1 표현을 포함하는 입력을 입력 수단을 통해 수신하는 동작; 상기 제1 표현을 사용자 디스플레이에 디스플레이하는 동작; 상기 입력이 수신되면 상기 디스플레이 상에 나타나는 사용자별 골격을 생성하는 동작; 상기 사용자로 하여금 상기 제1 표현에 있는 상기 신체를 상기 사용자별 골격과 정렬하게 하는 동작; 상기 신체의 상기 제1 표현을 분할하는 것에 의해 상기 신체가 상기 사용자별 골격과 정렬되었을 때 상기 제1 표현을 처리하는 동작; 및 상기 제1 표현의 처리에 기초하여 상기 신체의 제2 표현을 생성하는 동작을 수행하는 단계를 포함한다. 일 실시예에서, 상기 방법은 상기 생성된 제2 표현을 통신하는 단계를 더 포함할 수 있다. 상기 통신하는 단계 는 상기 생성된 제2 표현을 디스플레이를 통해 디스플레이하는 단계를 포함할 수 있다. 일 실시예에서, 상기 방법은, 상기 전자 프로그램 명령을 통해 상기 제어기를 제어하여, 상기 신체의 상기 제1 표현을 분할하는 것에 의해 상기 신체의 상기 제1 표현을 처리하여, 상기 신체의 실질적으로 진정한 3차원 스캔 의 투영된 음영을 간단한 형태로 표현하는 복수의 실루엣을 획득하는 동작; 및 상기 실루엣에 기초하여 상기 신 체의 상기 제2 표현을 생성하는 동작을 수행하는 단계를 더 포함한다. 바람직하게는 상기 사용자로 하여금 하게 하는 단계는 디스플레이된 사용자별 골격에 상기 신체의 부분들을 정 렬시킬 것을 가청 음성, 단어 또는 발언을 통해 상기 사용자에게 지시하는 단계를 포함하고, 상기 전자 프로그 램 명령은 생성된 골격과 하나 이상의 신체의 실시간 캡처된 이미지들로부터 추출된 형상 특징, 자세 특징, 시 공간 특징 사이에서 계산된 에러에 의해 정렬 공정을 제어하도록 동작가능하다. 유리하게는, 상기 방법은, 상기 전자 프로그램 명령을 통해, 상기 제어기를 제어하여, 제시된 사용자 신장 정보, 이미지 사이즈(픽셀 단위의 이미지 높이와 폭)에 기초하여, 및 이진 이미지, 투영 이 론 및 카메라 모델의 얼룩 분석을 사용하여 다음, 즉: 자세(P)로 정의된, 각 이미지에서 카메라 위치와 방향을 포함하는 캡처 카메라의 내재적 파라미터와 외인성 파 라미터의 초기 추정치; 및 골격 모델의 각 관절의 3D 위치와 3D 방향을 포함하는, JK로 정의된, 신체의 골격을 나타내는 상기 골격 모델의 관절 운동학의 초기 추정치를 계산하는 동작을 수행하는 단계를 더 포함한다. 유리하게는, 상기 방법은, 상기 전자 프로그램 명령을 통해, 상기 제어기를 제어하여, 제시된 사용자 신장 정보, 이미지 사이즈(픽셀 단위의 이미지 높이와 폭)에 기초하여, 및 이진 이미지, 투영 이 론 및 카메라 모델의 얼룩 분석을 사용하여 다음, 즉: 자세(P)로 정의된, 각 이미지에서 카메라 위치와 방향을 포함하는 캡처 센서 또는 카메라의 내재성 파라미터와 외인성 파라미터의 초기 추정치; 및 골격 모델의 각 관절의 3D 위치와 3D 방향을 포함하는, JK로 정의된, 신체의 골격을 나타내는 상기 골격 모델의 관절 운동학의 초기 추정치를 계산하는 동작을 수행하는 단계를 더 포함한다. 통상적으로, 상기 방법은, 상기 전자 프로그램 명령을 통해, 상기 제어기를 제어하여, 제시된 사용자 신장과 체중 및 성별 정보 또는 사용자 신장 정보와 성별에만 기초하여, 사용자의 입력된 신장, 체중 또는 알려진 경우 다른 신체 측정값에 따라 변하는, Av로 정의된, 초기 평균 아바타를 예측하는 동작; 및 W로 정의된 골 중량/신장 행렬과 기준 자세에서 알려진 골격 모델(JK)을 갖는 사이즈 N-관절의 기준 골격에 평 균 아바타(Av)를 장착하는 동작을 수행하는 단계를 더 포함한다. 바람직하게는 행렬(W)은 예측 공정의 학습 공 정 동안 단 한번만 오프라인으로 계산되고 나서, 다른 아바타를 예측하거나 또는 생성하는데 사용되기 위해 기 준 골격 모델(JK)과 함께 기억되고, 여기서 W는 관절, 골, 및 그 정점(V), 에지(E) 및 면(F)으로 표현되는 실제 3D 아바타 표면 사이의 관계를 제한하고 제어하고 모델링하는데 사용된다. 통상적으로, 상기 방법은, 상기 전자 프로그램 명령을 통해, 상기 제어기를 제어하여, 제시된 사용자 신장과 체중 및 정보 또는 사용자 신장 정보에만 기초하여, 사용자의 입력된 신장, 체중 또는 알 려진 경우 다른 신체 측정값에 따라 변하는 Av로 정의된 초기 평균 아바타를 예측하는 동작; 및 W로 정의된 골 중량/신장 행렬과 기준 자세에서 알려진 골격 모델(JK)을 갖는 사이즈 N-관절의 기준 골격에 평 균 아바타(Av)를 장착하는 동작을 수행하는 단계를 더 포함한다. 바람직하게는, 행렬(W)은 인간 형상의 오프라 인 기계 학습 공정 동안 단 한번만 오프라인으로 계산되고 나서, 이전에 학습되지 않은 다른 아바타 또는 인간 의 형상을 예측 또는 생성하는 데 사용되기 위해 기준 골격 모델(JK)과 함께 기억되고, 여기서 W는 관절, 골, 및 인간의 피부에서 발생하는 자연스러운 변형을 포함하는 실제 3D 아바타 표면 또는 3D 토폴로지 사이의 관계 를 제한하고 제어하고 모델링하는데 사용된다. 표면 또는 3D 토폴로지는 정점(V), 에지(E) 및 면(F)으로 고유하 게 표현될 수 있다. 바람직하게는, 초기 평균 아바타(Av)를 예측하는 공정은 다변수-기반 기계 학습 접근법을 따른다. 통상적으로 다변수-기반 기계 학습 접근법은 상이한 연령과 자세의 실제 인간(남성과 여성)의 복수의 장착되고 렌더링된 3 차원 스캔으로부터 추출된 독특하고 현저한 3D 특징을 사용하여 인간 형상의 3D 기하학적 형상을 오프라인으로 학습하는 것을 포함한다. 유리하게는, 상기 다변수-기반 기계 학습 접근법은 L개의 상이한 측정값을 갖는 벡터 M = (m1, m2, ..., mL)으 로서 정의된 상이한 신체 측정값들 사이의 다양한 통계적 관계를 학습하는 기계 지능을 더 포함하고, 사용시 하 나 이상의 측정값은 하나 이상의 상이한 측정값이 주어진 경우 예측될 수 있고, 평균 아바타(Av)는 이들 측정값 들 중 하나 이상이 주어진 경우 예측될 수 있다. 이 실시예에서, 아바타를, 새로운 제1 표현으로 표현된, 신체의 Av1로 정의된 새로운 아바타로 변형시키거나 단 순히 애니메이팅하기 위해, 기준 또는 평균 아바타 데이터(V, E, F, JK, W)와, 새로운 제1 표현의 JK1로서 정의 된 사용자 관절 운동학의 알려진 또는 추정치는 자연스러운 인간 동작으로부터 알려지거나 학습된 다수의 물리 적 제약 조건에 따라 Av를 Av1로 최적화하고 변형시키는 비용 함수(￡)에 공급되고, 사용시 새로운 애니메이팅 된 아바타(Av1)는 단순화를 위해 평균 아바타(Av)와 동일한 신체 측정값을 갖는 것으로 가정하면, 기준 또는 평균 아바타 데이터의 비선형 함수로 모델링될 수 있는데, 즉 Av1 = f(Av, W, JK, JK1)으로 모델링될 수 있다. 통 상적으로 비용 함수(￡)의 구현은 다음 함수, 즉: V, F 및 E를 사용하는 예를 들어 라플라시안 코탄젠트 행렬을 사용하는 표면 평활 함수; 및, V, F 및 W를 사용하여 아바타 정점과 골 사이에 대응 관계가 제한되는 것을 보장하는 골 부착 함수 를 포함하는 2개 이상의 가중된 에너지 최소화 함수를 결합하는 것에 의해 유도된다. 추가적인 실시예에서, 실제 신체의 3D 표현, 즉 3D 아바타를 생성하기 위해; 실루엣 또는 그 표현 중 하나 이상 에 적응적 비선형 최적화를 사용하여 Av1의 하나 이상의 표현이 매칭되고 비교된다. 이 공정은 매칭이 달성될 때까지 M, JK를 포함한 Av1 데이터와 측정값의 초기 추정치를 조정할 수 있다. 추가적인 실시예에서, 상기 입력은 상기 신체의 분류를 포함하고, 상기 방법은, 상기 전자 프로그램 명령을 통 해, 상기 제어기를 제어하여, 상기 신체의 분류에 기초하여, 상기 신체 분류에 대응하는 데이터를 획득하는 동작; 상기 제1 표현과 상기 획득된 데이터를 비교함으로써 상기 제1 표현을 처리하는 동작; 및 상기 비교에 기초하여 상기 신체의 제2 표현을 생성하는 동작을 수행하는 단계를 더 포함한다. 본 발명의 제3 광의의 양태에 따르면, 컴퓨팅 수단에 의해 실행될 때, 상기 컴퓨팅 수단으로 하여금 전술된 본 발명의 제2 광의의 양태에 따른 방법을 수행하게 하는 명령을 저장하는 컴퓨터 판독가능한 저장 매체가 제공된 다. 본 발명의 제4 광의의 양태에 따르면, 전술된 본 발명의 제2 광의의 양태에 따른 방법을 수행하도록 프로그래밍 된 컴퓨팅 수단이 제공된다. 본 발명의 제5 광의의 양태에 따르면, 컴퓨팅 시스템에 의해 수신되고 해석될 수 있는 적어도 하나의 명령을 포 함하는 데이터 신호가 제공되며, 상기 명령은 전술된 본 발명의 제2 광의의 양태에 따른 방법을 구현한다. 본 발명의 제6 광의의 양태에 따르면, 전술된 본 발명의 제1 광의의 양태에 따른 장치를 포함하는 신체를 이미 징하는 시스템이 제공된다. 본 발명의 제7 광의의 양태에 따르면, 목적을 달성하기 위한 방법이 제공되며, 상기 방법은, 전술된 본 발명의 제1 광의의 양태에 따른 장치를 사용하여, 상기 목적을 달성하기 위한 동기 부여를 제공하기 위해 상기 디스플 레이를 통해 상기 신체의 하나 이상의 제2 표현을 생성하고 디스플레이하는 단계를 포함한다. 일 실시예에서, 상기 신체는 인체이고, 상기 목표는 상기 인체에 대한 개인의 피트니스 목표를 포함한다."}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 이하의 특정 실시예에 의해 그 범위가 제한되지 않는다. 본 상세한 설명은 단지 예시의 목적을 위한 것이다. 기능적으로 동등한 제품, 조성물 및 방법은 본 명세서에 설명된 본 발명의 범위 내에 있다. 이 위치에서, 이 기술 분야에 통상의 지식을 가진 자라면 본 명세서에 설명된 본 발명은 구체적으로 설명된 것과는 다르 게 변형 및 변경될 수 있음을 이해할 수 있을 것이다. 본 발명은 이러한 모든 변형 및 변경을 포함하는 것으로 이해되어야 한다. 본 발명은 또한 본 명세서에서 언급되거나 지시된 모든 단계, 특징, 조성물 및 화합물을 개별 적으로 또는 집합적으로 및 이들 단계 또는 특징 중 임의의 조합, 모든 조합 또는 임의의 둘 이상의 조합을 포 함한다. 본 발명의 추가적인 특징은 본 명세서의 예에서 보다 충분히 설명된다. 그러나, 이러한 상세한 설명은 본 발명 을 예시하기 위한 목적으로만 포함되고, 어쨌든 본 명세서에서 제시된 본 발명의 광범위한 설명에 제한을 두기 위한 것으로 이해되어서는 안된다. 본 명세서에 인용된 모든 간행물(특허 문헌, 특허 출원 문헌, 학술지 논문, 실험실 매뉴얼, 서적 또는 기타 문 서를 포함함)은 그 전체 내용이 본 명세서에 병합된다. 인용 문헌들 중 그 어느 것도 종래 기술을 구성한다거나 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 일반적으로 알려진 지식의 공지 기술임을 인정하는 것은 아니다. 본 명세서 전반에 걸쳐, 문맥상 달리 요구되지 않는 한, \"포함하는\"라는 용어 또는 \"구비하는\" 또는 \"갖는\"과 같은 변형어는 언급된 정수 또는 정수 그룹을 포함하지만 임의의 다른 정수 또는 정수 그룹을 배제하는 것은 아 닌 것을 의미하는 것으로 이해된다. 본 명세서에서 사용된 선택된 용어에 대한 다른 정의가 본 발명의 상세한 설명 내에서 찾아볼 수 있고, 전반에 걸쳐 적용될 수 있다. 달리 정의되지 않는 한, 본 명세서에서 사용된 모든 다른 과학적 및 기술적 용어는 본 발 명이 속하는 기술 분야에 통상의 지식을 가진 자에게 일반적으로 이해되는 것과 동일한 의미를 갖는다. 본 명세서에 설명된 본 발명은 하나 이상의 값 범위(예를 들어, 사이즈, 변위 및 전계 강도 등)를 포함할 수 있 다. 이 값 범위는, 이 범위를 한정하는 값들을 포함하여 이 범위 내의 모든 값, 및 이 범위에 경계를 한정하는, 이 값에 바로 인접한 값과 동일하거나 실질적으로 동일한 결과를 초래하는 범위에 인접한 값들을 포함하는 것으 로 이해된다. 예를 들어, 이 기술 분야에 통상의 지식을 가진 자라면 범위의 상한 또는 하한에서 10%의 변동은 완전히 적절한 것일 수 있고 본 발명에 포함된다는 것을 이해할 수 있을 것이다. 보다 구체적으로, 범위의 상한 또는 하한에서 변동은 5% 또는 이 기술 분야에서 일반적으로 인정되는 것 중 더 큰 것일 수 있다. 본 명세서 전반에 걸쳐 '약' 및 '대략'이라는 단어와 같은 상대적인 언어가 사용된다. 이 언어는 제시된 숫자 또는 범위에 적어도 10%의 변동을 포함하려는 것이다. 그 변동은 제시된 특정 숫자의 +10% 또는 -10%일 수 있다. 도면에서, 유사한 특징들은 동일한 참조 번호로 지정되었다. 도 1에는 본 발명의 양태에 따라 장치를 사용하여 신체를 이미징하기 위한 시스템의 제1 실시예의 사용 시 수행되는 동작이 도시되어 있다. 설명된 실시예에서, 신체는 체중을 감량하거나 증가시키거나 유지하거나/모니터링하거나 및/또는 신체 사이즈 또는 형상을 향상시키는 개인의 피트니스 목표를 포함하는 목적을 달성하기를 원하는 인간(시스템의 사 용자임)의 신체이다. 그리하여, 이 시스템은 특히 16세 내지 48세의 여성, 신부/신랑, 운동 선수, 및 보디 빌더; 임신 전/후에; 및 의료 모니터링에 사용하는데 적용될 수 있다. 보다 상세히 설명될 바와 같이, 시스템 은 신체를 효과적이고 정확히 모니터링하는 것을 통해 개인의 피트니스 목표를 달성하는 것을 촉진하고 보조하도록 인간의 정확한 개인화된 개체별 이미지를 제공하도록 동작가능하다. 제공된 이미지는 아바타라 고 언급될 수 있다. 본 발명은 개인의 피트니스 목표를 달성하기 위한 동기 부여를 촉진하고 제공하기 위해 인체를 이미징하는 것을 참조하여 특히 설명될 것이지만, 본 발명은 추가적인 및/또는 대안적인 목표 또는 목적을 위해 및 다른 것의 신 체에 대해 사용될 수 있는 것으로 이해된다. 본 발명은 이미징된 신체 또는 이미징되는 목적과 관련하여 제한되지 않으며, 대안적인 실시예에서, 본 발명은 설명된 목적에 추가적인 및/또는 대안적인 목적을 위해 추가적인 및/또는 대안적인 것의 신체를 이미징하는데 적용될 수 있다. 구현에 따라, 신체는 살아 있는 것의 신체 또는 그 하나 이상의 부분이거나, 또는 살아 있지 않은 것의 신체 또는 그 하나 이상의 부분일 수 있다. 본 발명의 실시예는 가축을 포함하는 동물 및 자연 상태 의 음식과 같이 하나의 신체와 다른 신체 사이에 변동이 있는 것의 신체를 이미징하는데에 특히 적용가능하다.장치는 사용자인 사람으로 운반된다. 장치는 적절한 회로 및 연결을 통해 동작가능하게 결합된 복수의 구성 요소, 서브시스템 및/또는 모듈을 포 함하여, 장치가 본 명세서에서 설명된 기능과 동작을 수행할 수 있게 한다. 장치는 신체를 이미징하는 방법 및 본 발명의 실시예에 따른 목적을 달성하기 위한 방법과 같은 적절한 컴퓨터 명령을 수신, 저장 및 실행 하는데 필요한 적절한 구성 요소를 포함한다. 특히, 도 2에 도시된 바와 같이, 장치는 이 실시예에서 제어기, 및 이 제어기를 제어하기 위한 전 자 프로그램 명령과 정보 및/또는 데이터를 저장하는 저장 장치, 사용자 인터페이스를 디스플레이하기 위한 디스플레이; 및 입력 수단을 포함하는 컴퓨팅 수단을 포함하고; 이들 구성 요소는 모두 컨테이너 또는 하우징 내에 수용된다. 보다 상세히 설명될 바와 같이, 제어기는, 전자 프로그램 명령의 제어 하에, 상기 신체의 제1 표현을 포함하는 입력을 상기 입력 수단을 통해 수신하는 동작; 상기 제1 표현을 처리하는 동작; 상기 처리에 기초하여 상기 신체의 제2 표현을 생성하는 동작; 및 상기 생성된 제2 표현을 상기 디스플레이를 통해 디스플레 이하는 동작을 수행하도록 동작가능하다. 또한, 제1 실시예에서, 상기 입력은 또한 상기 신체의 분류를 포함하고, 상기 제어기는, 상기 전자 프 로그램 명령의 제어 하에, 상기 신체의 분류에 기초하여, 상기 신체 분류에 대응하는 데이터를 획득하는 동 작; 상기 제1 표현과 상기 획득된 데이터를 비교함으로써 상기 제1 표현을 처리하는 동작; 및 상기 비교에 기초 하여 상기 신체의 제2 표현을 생성하는 동작을 수행하도록 동작가능하다. 본 발명의 실시예에서, 상기 데이터는 하나 이상의 소스로부터 데이터를 검색, 수신, 추출 및 식별하는 것 중 하나 이상에 의해 획득될 수 있다. 상기 하나 이상의 데이터 소스는 저장 장치 상에 상주하거나 및/또는 그 밖에 장치로부터 원격에 상주할 수 있다. 설명된 실시예에서, 상기 획득된 데이터는 상기 신체의 분류에 기초하여 검색된 템플릿의 형태로 제공되고, 인체 측정법은 신체를 분류하는데 사용된다. 복수의 템플릿이 제공되고, 각 템플릿은 성별과 인종 그룹의 변동을 포함하는 항목에 대한 표준 평균 인체 측정 측정값을 갖는 인체의 3차원(3D) 모델을 포함하는 템플릿 데이터와 관련된다. 템플릿은 모든 신체 요소의 높이 와 폭에 대한 전체 치수를 갖는 평균 3D 디지털 모델이다. 이 실시예에서, 장치는 디스플레이되거나 계산될 수 있는 수치 측정값으로서 이들의 서브 세트를 추출하도록 동작가능하다. 보다 상세히 설명될 바와 같이, 이들 특 정 데이터 포인트는 입력 이미지와 비교하고 템플릿이 이미지 사이즈 데이터와 관련되도록 수정될 수 있게 하는 데 사용된다. 본 발명의 실시예에서, 상기 획득된 데이터는 신체의 이전의 표현을 포함할 수 있으며, 이 경우 신체 분류는 신 체의 식별을 포함할 수 있다. 다른 실시예에서, 상기 획득된 데이터는 신체 및/또는 다른 신체의 하나 이상의 이전의 표현의 통합 또는 이의 데이터의 통합을 포함하거나 또는 이와 연관될 수 있다. 이러한 데이터는 장치의 동작을 통해 생성될 수 있 고 및/또는 예를 들어 하나 이상의 다른 장치 또는 DEXA 기술과 같은 하나 이상의 다른 소스(들)로부터 획 득될 수 있다. 제어기는 프로세서 형태의 처리 수단을 포함한다. 저장 장치는 판독 전용 메모리(ROM)와 랜덤 액세스 메모리(RAM)를 포함한다. 장치는 ROM 또는 RAM에 보유(held)될 수 있고 프로세서에 의해 실행될 수 있는 명령을 수신할 수 있다. 프 로세서는 아래에서 보다 상세히 설명될 바와 같이 명령을 처리/실행하고 장치를 통해 데이터와 정보의 흐름 을 관리하는 것을 포함하는 동작을 전자 프로그램 명령의 제어 하에 수행하도록 동작가능하다. 이 실시예에서, 장치에 대한 전자 프로그램 명령은 이미징 애플리케이션으로 지칭될 수 있는 단일 소프트웨 어 애플리케이션(앱) 또는 모듈을 통해 제공된다. 설명된 실시예에서, 앱은 상표 MYFIZIQ™ 하에 시판되고, 웹 사이트(또는 다른 적절한 전자 장치 플랫폼)로부터 다운로드되거나 또는 장치의 저장 장치에 기억되거 나 저장될 수 있다. 본 발명의 바람직한 실시예에서, 장치는 이동 통신 장치이고, 안드로이드, WEBOS, 윈도우즈(Windows) 또는 다른 전화 앱 플랫폼을 갖는, 애플사(Apple Inc.)에 의해 상표명 IPHONE으로 시판되는 것과 같은 스마트폰, 또는 다른 제공자, 예를 들어, 노키아 코포레이션(Nokia Corporation) 또는 삼성 그룹에 의해 시판되는 스마트 폰을 포함한다. 대안적으로, 장치는 예를 들어 애플사의 상표 IPAD 또는 IPOD TOUCH로 시판되는 것 또 는 휴렛-패커드사(Hewlett-Packard Company) 또는 델사(Dell, Inc)와 같은 다른 제공자에 의해 시판되는 것과 같은 개인용, 노트북 또는 태블릿 컴퓨터와 같은 다른 컴퓨팅 수단 또는 다른 적절한 장치를 포함할 수 있다. 장치는 또한 명령을 발행할 수 있는 운영 시스템을 포함하고, 앱과 상호 작용하여 장치로 하여금 본 명 세서에서 설명된 본 발명의 실시예에 따라 각각의 단계, 기능 및/또는 절차를 수행하게 하도록 배열된다. 운영 시스템은 장치에 적절한 것일 수 있다. 예를 들어, 장치가 IPHONE 스마트폰을 포함하는 경우, 운영 시스템은 iOS일 수 있다. 도 3에 도시된 바와 같이, 장치는 서버, 퍼스널 컴퓨터, 단말, 무선 또는 핸드헬드 컴퓨팅 장치, 유선 통신 장치, 또는 이동 (셀) 전화기와 같은 이동 통신 장치와 같은 하나 이상의 원격 장치에 다양하게 연결될 수 있는 하나 이상의 통신 링크(들)를 통해 통신하도록 동작가능하다. 복수의 통신 링크(들) 중 적어도 하 나는 통신 네트워크를 통해 외부 컴퓨팅 네트워크에 연결될 수 있다. 설명된 실시예에서, 원격 장치는 다른 사람에 의해 소유 및/또는 동작되는 다른 장치뿐만 아니라 관리 자에 의해 소유 및 동작되는 컴퓨팅 시스템을 포함한다. 관리자 컴퓨팅 시스템은 본 실시예에서 서버의 형태를 갖는다. 서버는 신체를 이미징하는 시스템 및 방법, 및 본 발명의 실시예에 따른 목적을 달성하기 위한 방법과 같은 애플리케이션 및/또는 시스템 서비스 를 실행하는데 사용될 수 있다. 이 실시예에서, 서버는 물리적으로 중앙에서 관리되는 관리 센터에 위치한다. 대안적인 실시예에서, 이 서 버는 클라우드 기반 플랫폼 상에 유지될 수 있다. 장치와 유사하게, 서버는 적절한 전자 프로그램 명령을 수신, 저장 및 실행하는데 필요한 적절한 구성 요소들을 포함한다. 이들 구성 요소는 서버 프로세서 형태의 처리 수단, 판독 전용 메모리(ROM) 및 랜덤 액세스 메모리(RAM)를 포함하는 서버 저장 장치, 디스크 드라이브와 같은 하나 이상의 서버 입력/출력 장치, 및 연관된 서버 사용자 인터페이스를 포함한다. 원격 통신 장치(장치를 포함함)는 하나 이상의 통신 링크를 통해 서버와 통신하도록 배열된다. 서버는 ROM, RAM 또는 디스크 드라이브에 보유될 수 있는 명령을 수신할 수 있고 서버 프로세서에 의해 실 행될 수 있다. 서버 프로세서는 아래에서 보다 상세히 설명될 바와 같이 명령을 처리/실행하고 컴퓨팅 시스템 을 통해 데이터와 정보의 흐름을 관리하는 것을 포함하는 동작을 전자 프로그램 명령의 제어 하에 수행하도 록 동작가능하다. 서버는 저장 장치 상에 상주하는 복수의 데이터베이스 또는 데이터 뱅크에 액세스하기 위한 명령을 발행할 수 있는 서버 운영 시스템을 포함한다. 이 실시예에서, 2개의 그러한 데이터베이스 또는 데이터 뱅크가 제공되 며, 이는 RU(registered user) 데이터베이스로 지칭될 수 있는 시스템의 등록된 사용자(RU)들 중 하나; 및 템플릿 데이터베이스로 지칭될 수 있는 템플릿 데이터를 포함하여 전술된 템플릿들 중 하나를 포함할 수 있다. 운영 시스템은 데이터베이스(38 및 40) 및 한 세트/벌의 서버 소프트웨어의 하나 이상의 컴퓨터 프로그램 과 상호 작용하여 서버로 하여금 본 명세서에 설명된 본 발명의 실시예에 따른 각각의 단계들, 기능들 및/ 또는 절차들을 수행하도록 한다. 장치와 서버의 컴퓨팅 구성 요소를 위한 앱, 서버 소프트웨어 세트의 컴퓨터 프로그램, 및 다른 전자 명령 또는 프로그램은 이 기술 분야에 통상의 지식을 가진 자에 잘 알려진 임의의 적절한 언어로 작성될 수 있 다. 예를 들어, IPHONE 스마트폰을 포함하는 장치에서 동작하기 위해, 이미징 앱은 객체(Objective)-C 언어로 작성될 수 있다. 본 발명의 실시예에서, 전자 프로그램 명령은 구현예 또는 실시예의 요구 사항에 따라 독립 실행형 애플리케이션(들)으로서 제공되거나, 세트의 또는 복수의 애플리케이션으로서 제공되거나, 네트워 크를 통해 제공되거나, 또는 미들웨어로서 추가될 수 있다. 본 발명의 대안적인 실시예에서, 소프트웨어는 하나 이상의 모듈을 포함할 수 있으며, 하드웨어로 구현될 수 있 다. 이러한 경우에, 예를 들어, 모듈들은 이 기술 분야에서 각각 잘 알려진 다음의 기술, 즉: 데이터 신호들에 논리 기능들을 구현하기 위한 논리 게이트들을 갖는 이산 논리 회로(들), 적절한 조합 논리 게이트를 갖는 응용특정 집적 회로(ASIC), 프로그래밍가능한 게이트 어레이(들)(PGA), 전계 프로그래밍가능한 게이트 어레이(FPGA) 등 중 임의의 하나 또는 조합으로 구현될 수 있다. 각각의 컴퓨팅 수단은, 프로그래밍가능한 논리 제어기(PLC); 디지털 신호 프로세서(DSP); 마이크로제어기; 퍼스 널 컴퓨터, 노트북 또는 태블릿 컴퓨터 또는 전용 서버 또는 네트워크 서버를 포함하는 임의의 적절한 유형의 시스템일 수 있다. 각각의 프로세서는 컴퓨팅 수단과 관련된 몇몇 프로세서들 중 임의의 맞춤형 또는 상용 프로세서, 중앙 처리 장 치(CPU), 데이터 신호 프로세서(DSP) 또는 보조 프로세서일 수 있다. 본 발명의 실시예에서, 처리 수단은 예를 들어 반도체 기반 마이크로프로세서(마이크로 칩의 형태로) 또는 마이크로프로세서일 수 있다. 본 발명의 실시예에서, 각각의 저장 장치는 휘발성 메모리 소자(예를 들어, 랜덤 액세스 메모리(RAM), 예를 들 어, DRAM(dynamic random access memory), SRAM(static random access memory) 및 비-휘발성 메모리 소자(예를 들어, 판독 전용 메모리(ROM), 소거가능한 프로그래밍가능한 판독 전용 메모리(EPROM), 전기적으로 소거가능한 프로그래밍가능한 판독 전용 메모리(EEPROM), 프로그래밍가능한 판독 전용 메모리(PROM), 테이프, 콤팩트 디스 크 판독 전용 메모리(CD-ROM), 등) 중 임의의 것 또는 이들의 조합을 포함할 수 있다. 각각의 저장 장치는 전자, 자기, 광학 및/또는 다른 유형의 저장 매체를 포함할 수 있다. 또한, 각각의 저장 장치는 분산 구조를 가 질 수 있으며, 여기서 다양한 구성 요소는 서로 멀리 떨어져 위치되지만 처리 수단에 의해 액세스될 수 있다. 예를 들어, ROM은 장치의 동작을 제어하기 위해 처리 수단에 의해 실행될 다양한 명령, 프로그램, 소프트웨 어 또는 애플리케이션을 저장할 수 있고, RAM은 동작의 변수 또는 결과를 일시적으로 저장할 수 있다. 소프트웨어 애플리케이션을 사용하여 컴퓨터를 사용하고 동작시키는 것은 이 기술 분야에 통상의 지식을 가진 자에게 잘 알려져 있으므로, 본 발명과 관련된 것을 제외하고는 본 명세서에서 더 자세히 설명될 필요는 없다. 또한, 임의의 적절한 통신 프로토콜은, 이 기술 분야에 통상의 지식을 가진 자에 잘 알려진 바와 같이, 장치 의 임의의 서브시스템 또는 구성 요소, 서버의 임의의 서브시스템 또는 구성 요소, 및 장치와 서버 및 유선과 무선을 포함하는 다른 장치 또는 시스템 사이에 연결 및 통신을 수행하는데 사용될 수 있고, 본 발명과 관련된 경우를 제외하고는 본 명세서에서 보다 상세히 설명될 필요는 없다. \"저장\", \"보유\" 및 \"기억\"이라는 단어 또는 이와 유사한 단어가 본 발명의 문맥에서 사용되는 경우, 이들 단어 는 차후 검색을 위해 및 예를 들어 수행되는 처리 동작의 일부로서 순간적으로 또는 순시적으로 저장 수단, 장 치 또는 매체에 영구적으로 및/또는 일시적으로 데이터 또는 정보의 유지 또는 보유를 언급하는 것을 포함하는 것으로 이해되어야 한다. 또한, \"시스템\", \"장치\" 및 \"기계\"라는 용어가 본 발명의 문맥에서 사용되는 경우, 이들 용어는, 서로 인접해 있거나, 서로 분리되거나, 서로 통합되거나, 또는 서로 이격되어 있을 수 있는, 기능적으로 관련되거나 상호 작 용하거나, 상호 관련되거나, 상호 의존적이거나 또는 연관된 구성 요소들 또는 요소들의 임의의 그룹을 언급하 는 것을 포함하는 것으로 이해되어야 한다. *또한, 본 발명의 실시예에서, \"결정하는\"이라는 단어는 관련 데이터 또는 정보를 수신 또는 액세스하는 것을 포함하는 것으로 이해된다. 본 발명의 실시예에서, 사용자 인터페이스와 사용자 입력 수단을 디스플레이하기 위한 디스플레이 는 터치스크린에 통합된다. 대안적인 실시예에서, 이들 구성 요소는 별개의 요소 또는 항목으로 제공될 수 있다. 터치스크린은 장치의 디스플레이 영역 내 터치의 존재와 위치를 감지 또는 검출하도록 동작가능하다. 터치스크린의 감지된 \"터치\"는 커맨드 또는 명령으로서 장치에 입력되고 제어기로 통신된다. 사용 자 입력 수단은 터치스크린을 포함하는 것으로 제한되지 않고, 본 발명의 대안적인 실시예에서 입력, 커맨 드 또는 명령을 수신하고 제어된 상호 작용을 제공하기 위해, 예를 들어, 키패드 또는 키보드, 포인팅 장치 또 는 복합 장치, 및 음성 활성화, 음성 및/또는 사고 제어, 및/또는 홀로그래픽/투영된 이미징을 포함하는 시스템 을 포함하는 임의의 적절한 장치, 시스템 또는 기계가 사용될 수 있는 것으로 이해되어야 한다. 입력은 또한 장치의 센서 시스템 또는 센서 세트의 일부인 적어도 하나의 센서를 통해 수신될 수 있다. 센서 세트 내의 개별 센서는 장치, 주변 환경, 또는 이들과 연관되거나 이에 결합된 구성 요소, 시스템 또는 장치의 하나 이상의 특성, 속성 및 파라미터와 연관되거나 관련되는 센서 데이터 및/또는 정보를모니터링, 감지 및 수집하거나 측정하도록 동작가능하다. 예를 들어, 센서 세트는 장치의 상태 및/또는 장치를 둘러싸는 환경의 상태에 관한 센서 데이터를 감지하고 수집하도록 동작할 수 있다. 일 실시예에서, 장치의 상태는 장치의 위치를 포함한다. 일 실시예에서, 장치의 상태는 장치의 속도 및/또는 속력을 더 포함한다. 센서 세트는 가속도 센서와 방향 센서를 포함하는 관성 센서 시스템, 방위 센서 및 위 치 센서를 포함한다. 본 발명의 대안적인 실시예는 움직임 센서, 적외선 센서, 깊이 센서, 3차원 이미징 센서, 관성 센서 및 MEMS(Micro-Electromechanical) 센서를 포함하는 추가적인 및/또는 대안적인 센서를 포함할 수 있 다. 가속도 센서는 장치의 가속도를 측정하고 가속도 데이터를 생성하도록 동작가능하다. 예를 들어, 가속도 센 서는 가속도계일 수 있다. 방향 센서는 장치의 방향(즉, 각속도)의 변화율을 측정하고 방향 데이터를 생성 하도록 동작가능하다. 예를 들어, 방향 센서는 자이로스코프일 수 있다. 방위 센서는 지구의 자극에 대한 방위 를 결정하고 방위 데이터를 생성하도록 동작가능하다. 예를 들어, 방위 센서는 전자 나침반일 수 있다. 위치 센 서는 장치의 위치를 결정하고 위치 데이터를 생성하도록 동작가능하다. 예를 들어, 위치 센서는 GPS(Global Positioning System)일 수 있다. 이러한 센서를 사용하고 동작시키는 것은 이 기술 분야에 통상의 지식을 가진 자에게 잘 알려져 있으므로, 본 발명과 관련된 것을 제외하고는 본 명세서에서 보다 상세히 설명될 필요는 없다. 제1 표현은 신체의 하나 이상의 시각적 표현을 포함할 수 있다. 설명된 실시예에서, 제1 표현은 신체의 시각적 표현의 세트를 포함한다. 따라서, 센서 세트는 시각적 표현을 포함하는 이미지를 캡처하도록 동작가 능한 디지털 카메라 형태의 이미징 수단을 포함한다. 카메라는 이 실시예에서 장치와 통합되어 있다. 상기 이미징 수단은 정지 영상 및/또는 동영상의 획득을 용이하게 하는 임의의 적절한 시스템 또는 장치를 포함할 수 있다. 예를 들어, 장치가 IPHONE 스마트폰을 포함하는 경우, 이미징 수단은 iSight™ 카메라일 수 있다. 카메라를 사용하고 동작시키는 것은 이 기술 분야에 통상의 지식을 가진 자에게 잘 알려져 있으므로, 본 발명과 관련된 것을 제외하고는 본 명세서에서 보다 상세히 설명될 필요는 없다. 장치는 적절한 컴퓨터 칩(집적 회로), 트랜시버/수신기 안테나, 및 사용되는 감지 기술(sensory technology)을 위한 소프트웨어를 포함하는, 설명된 수행을 용이하게 하는 동작가능하게 연결된/결합된 구성 요 소를 포함한다. IPHONE 스마트폰을 포함하는 경우일 수 있는 바와 같이, 센서 세트 중 하나 이상의 센서가 장치와 통합될 수 있다. 대안적으로, 장치는 전술된 센서 세트 중 하나 이상에 동작가능하게 결합될 수 있다. 템플릿 데이터베이스에 저장되는 것에 더하여, 이 실시예에서, 템플릿의 상세 중 적어도 일부는 저장 장치 에 상주하고 앱의 제어 하에 제어기에 의해 액세스가능한 데이터베이스 또는 데이터 뱅크에 저장되 거나 기억된다. 이들은 앱의 일부로 설치될 수 있다. 제어기는 데이터베이스와 상호 작용하여 장치(1 2)로 하여금 본 명세서에서 설명된 본 발명의 실시예에 따라 각각의 단계, 기능 및/또는 절차를 수행하도록 배 열된다. 템플릿의 다른 것의 상세는, 예를 들어 서버의 템플릿 데이터베이스와 같은 하나 이상의 원격 시스템 또는 장치의 각각의 저장 장치 상에 상주하고 하나 이상의 통신 링크(들)를 통해 장치에 의해 액세 스가능한 하나 이상의 원격 데이터베이스 모듈에 원격으로 저장되거나 기억된다. 제어기는 하나 이상의 원 격 데이터베이스와 사용자 상호 작용을 제공하여 원격으로 저장된 콘텐츠를 필요에 따라 사용할 수 있도록 배열 된다. 데이터베이스(들)는 솔리드 스테이트 드라이브, 하드 디스크 드라이브, 광학 드라이브 또는 자기 테이프 드라이 브를 포함할 수 있는 임의의 적절한 저장 장치 상에 상주할 수 있는 것으로 이해된다. 데이터베이스(들)는 단일 물리적 저장 장치에 상주하거나 다중 저장 장치 또는 모듈에 걸쳐 분산될 수 있다. 데이터베이스는 이 기술 분야에 통상의 지식을 가진 자에 잘 알려진 바와 같이 정보와 데이터가 데이터베이 스로 및 데이터베이스로부터 판독될 수 있게 하기 위해 제어기에 결합되고 이와 데이터 통신이 수 행된다. 임의의 적절한 데이터베이스 구조가 사용될 수 있으며 하나 이상의 데이터베이스가 있을 수 있다. 본 발명의 실시예에서, 데이터베이스는, 전자 프로그램 명령 및 수집되거나 및/또는 제공될 임의의 다른 데이 터 또는 정보와 같이, 장치의 구성 요소로서 (예를 들어, 저장 장치에서) 국부적으로 제공되거나 또는 원격으로 예를 들어 원격 서버 상에 제공될 수 있다.유사하게, RU 및 템플릿 데이터베이스(38 및 40)들 모두는 이 기술 분야에 통상의 지식을 가진 자에 잘 알려진 바와 같이 서버에 결합되고 이 서버와 데이터 통신을 하며 데이터가 RU 및 템플릿 데이터베이스(38 및 40) 들로 및 이들로부터 판독가능하게 한다. 임의의 적절한 데이터베이스 구조가 사용될 수 있다. RU 및 템플릿 데 이터베이스(38 및 40)들 중 임의의 하나 또는 둘 모두는 소프트웨어의 서버 세트와 같이 서버의 구성 요소 로서 (예를 들어, 메모리 장치에서) 국부적으로 제공되거나 또는 원격으로 예를 들어 원격 서버 상에 제공될 수 있다. 일 실시예에서, 일부 컴퓨터는 네트워크 클라이언트-서버 애플리케이션을 가지도록 이러한 방식으로 설정 될 수 있다. 설명된 실시예에서, RU 및 템플릿 데이터베이스(38 및 40)들 각각은 단일 데이터베이스 구조의 파 티션으로서 서버의 메모리 장치에 내부적으로 저장된다. 본 발명의 다른 실시예에서, 더 많거나 적은 데이 터베이스가 있을 수 있다. 일단 앱이 장치 상에 설치되면, 제어기는, 앱의 제어 하에, 터치스크린을 통해, 네비게이션가능한 전자 페이지, 스크린과 양식의 시퀀스를 장치의 사용자에 제시하여, 카메라를 통해 캡처된 이미지와 같 은 센서 세트의 센서를 통해 감지된 데이터 및/또는 정보를 포함하는 정보 및/또는 데이터, 장치와 시 스템의 동작에 관련된 명령과 커맨드를 입력하거나 또는 캡처하는 것을 가능하게 하도록 동작가능하다. 설명된 실시예에서, 서버의 서버 소프트웨어 세트는 웹 서버 애플리케이션, 등록 및 요청 애플리케이션, 이 미지 처리 애플리케이션, 통신 애플리케이션, 송장(invoicing) 작성/청구서 발행(billing) 애플리케이션 및 지 불 처리 애플리케이션을 포함한다. 보다 상세히 설명될 바와 같이, 서버 소프트웨어 세트의 각 애플리케이션을 통해, 서버는 사용자 데이터를 등록 및 공유하는 기능; 앱을 통해 수신된 데이터와 데이터를 추출, 변환 및 결합하는 기능; 앱 인터페이스를 통과하는 모든 실시간 데이터를 기록하는 기능을 포함하는 기능을 수행하도록 동작가능하다. 웹 서버 애플리케이션은 웹 페이지 또는 다른 전자 페이지 또는 스크린과 같은 전용 웹 사이트를 통해 시스템 의 현존하거나 잠재적인 사용자에게 시스템에 관련된 콘텐츠를 전달하도록 동작가능하다. 웹 사이트는 통신 네트워크를 통해 시스템과 데이터 통신하도록 동작가능하게 연결된 노트북 컴퓨터 또는 스마트폰(이 실시예에서의 장치를 포함함)과 같은 인터넷 가능 이동 통신 장치의 웹 브라우저를 통해 액세스가능하다. 설명된 실시예에서, 데이터 통신 수단은 인터넷을 통하지만, 직접 연결과 같은 다른 방법이 본 발명의 다른 실 시예에서 사용될 수 있다. 콘텐츠는, 예를 들어, YouTube™, Facebook™ 및/또는 Twitter™ 상표로 제공된 서비스를 포함하여 포럼 또는 매체의 적절한 하나 또는 조합을 통해 전달된 피트니스 목표, 광고 및 판촉 또는 공중 관련 정보와 관련된 일반 정보를 포함할 수 있다. 액세스될 수 있는 웹 페이지는 사용자에 의한 시스템의 최초 사용시 완료될 온라인 등록 페이지와 요 청 페이지를 포함한다. 웹 사이트 애플리케이션은 시스템의 잠재적인 사용자가 수동으로 등록하거나 자기 자신을 사용자로 기록하여 개인 계정을 만들고 아바타를 요청하도록 동작가능하다. 이것은 사용자가 사용자 등 록 및 요청 정보를 각각 포함하는 전자 등록 및 요청 양식의 형태의 통신을 완료하고 이를 등록 페이지와 요청 페이지(110 및 112)를 통해 서버에 제출하는 것에 의해 제공된다. 사용자 등록 정보는 다음 사항을 포함하는 사용자 및 그 신체에 관한 정보 및/또는 데이터를 포함하는 상세를 포함한다: 1) 사용자 식별 및 연락처 상세: 사용자의 식별 및 사용자와 통신을 용이하게 하는 상세. 이러한 상세는 사용자 의 전체 개인 이름, 시스템을 사용할 때의 사용자 이름, 개인 집 주소, 통신(correspondence)을 전달에 사 용되는 물리적 및/또는 전자 메일 주소, 연락 전화 번호, 인증 정보(예를 들어, 암호), 및 적용가능한 경우 임 의의 다른 고유한 및/또는 관련 식별 정보를 포함할 수 있다. 이 정보는 시스템을 사용하여, 생성된 아바타 에 관련된 통신 및 청구서 발행을 포함하여 사용자와 통신하기 위해 시스템에 의해 사용된다. 2) 사용자 신체 상세: 사용자의 신체와 관련된 정보 및/또는 데이터. 설명된 실시예에서, 이것은 성별, 신장, 체중, 옷 크기(예를 들어, 소형, 중형, 대형, X-대형 또는 XXL), 연령 및 인종 그룹을 포함하는 신체의 인체 측 정 데이터를 포함한다. 본 발명의 대안적인 실시예에서, 사용자의 신체에 관한 및/또는 연관된 추가적인 및/또 는 대안적인 상세들이 요청될 수 있다. 3) 청구서 발행 및 지불 상세: 사용자에 의해 시스템의 사용료를 지불할 책임이 있는 채무자(사람)에 청구 서를 발행하고 이 채무자로부터 지불을 수신하는 것을 용이하게 하는 상세. 청구서 발행 상세는 예를 들어 처리및 지불에 대한 청구서 발행 통지를 포함하여 통신 전달에 사용되는 물리적 및/또는 전자 메일 주소를 포함할 수 있다. 지불 상세는, 이 실시예에서 아바타를 생성하는 것과 같이, 시스템을 통해 수행되는 동작과 관련 된 항목을 구매하는데 사용되고 저장된 채무자의 신용 카드 계좌와 같은 금융 계좌의 상세를 포함할 수 있다. 본 발명의 실시예에서 PayPal 및 Bitcoin(BTC) 서비스를 포함하지만 이에 국한되지 않는 추가적인 및/또는 대안 적인 지불 처리 플랫폼이 사용될 수 있다. 요청 정보는 제1 표현을 포함한다. 전술된 바와 같이, 이 실시예에서, 제1 표현은 신체의 시각적 표현의 세 트를 포함한다. 바람직하게, 시각적 표현 세트 내의 시각적 표현은 신체의 상이한 장면(view)을 포함하고, 이들 장면은, 신체가 대조되는 실질적으로 클러터/잡음이 없는 (즉, 복잡하지 않은) 배경 앞에 위치된 상태 에서 캡처된다. 특히, 설명된 실시예에서, 시각적 표현 세트는, 비 제한적인 예로서, 신체의 2개의 사진, 즉 신체의 정면도의 제1 사진과 신체의 측면도의 제2 사진을 포함한다. 이 2개의 사진을 캡처하고 업로 드하는 것을 용이하게 하기 위해 요청 페이지를 통해 사용자는 이미지 캡처 스크린에 액세스할 수 있다. 이미지 캡처 스크린은 이들이 업로드되기 전에 사진을 캡처하고 리뷰할 수 있게 하며, 공정을 통해 사 용자를 안내하기 위한 하나 이상의 서브스크린을 포함할 수 있다. 설명된 실시예에서, 장치는, 이미징 앱의 제어 하에, 제어기를 통해, 그 정밀도를 높이기 위해 이미지가 수직 평면에서 촬영되는 것을 보장하기 위해 (장치의 방향을 계산하는 방향 센서의) 내부 자이로스코프를 통해 생성된 방향 데이터를 포함하는 데이터를 사용하도록 동작가능하다. 본 발명의 실시예에서, (사진과 같은) 시각적 표현의 세트는 컬러, 그레이 또는 이진(예를 들어, 실루엣) 이미 지들을 포함하는 표준 2차원(2D) 이미지; 컬러 및/또는 질감이 있거나 없는 깊이 이미지; 컬러 및/또는 질감이 있거나 없는 신체의 MRI, DEXA(DXA), X-선, CT-스캔, 완전한 3차원(3D) 포인트 클라우드 또는 복수의 불완전한 포인트 클라우드; 및 컬러 및/또는 질감이 있거나 없는 신체의 3차원(3D) 메쉬 중 하나 이상을 포함하는 이미지 세트를 포함할 수 있다. 시각적 표현의 세트는 개체의 형상(예를 들어, 설명된 실시예에서 인간의 형상)을 물리 적인 개체들, 3차원(3D) 표면 또는 외피를 재구성할 수 있게 하는 레벨로 나타내는 임의의 형태의 데이터 또는 특징을 감지 및 출력할 수 있는 이미징(감지) 장치를 사용하여 캡처된 임의의 이미지들 중 하나 또는 그 조합을 포함할 수 있다. 본 발명의 실시예에서, 강화된 프라이버시를 위해, 시각적 표현들의 세트에서 사용자의 얼굴 및/또는 다른 구별 특징들을 마스킹하도록 동작가능한 정규화/블러링(normalization/blurring) 기능이 제공될 수 있다. 시각적 표 현은 더 프라이버시 보호될 수 있다. 본 발명의 대안적인 실시예에서, 사용자 등록 및 요청 정보는 대안적인 또는 추가적인 상세, 정보 및/또는 데이 터를 포함할 수 있다. 웹 서버 애플리케이션과 등록 애플리케이션을 포함하는 서버 소프트웨어 세트의 애플리케이션을 통해 수집된 모 든 데이터와 정보는 본 명세서에 설명된 바와 같이 사용하기 위해 시스템 내에 분배된다. RU 데이터베이스는 복수의 RU 레코드를 갖는다. 각각의 RU 레코드는, 전술된 바와 같은 등록 및 요청 정보 를 포함하여 시스템의 RU의 계정에 관한 RU 정보 세트를, RU와 관련된 다른 정보, 예를 들어, 이를 위해 생 성된 아바타와 함께 포함한다. 서버는 사용자 등록 및 요청 정보(본 명세서에 설명된 전용 웹 사이트 또는 다른 수단을 통해 전송됨)를 포 함하는 통신의 수신을 감지 또는 검출하도록 동작가능한 감지 수단을 갖는다. 이러한 정보의 수신을 감지하면, 서버는, 데이터베이스 관리 모듈 또는 애플리케이션을 포함하는 서버 소프트웨어 세트의 관련 애플리케이션 의 제어 하에 자신의 프로세서를 통해, RU 데이터베이스에 레코드를 (그리고 템플릿 데이터베이스에 레 코드를) 생성, 식재, 관리하며, 수신된 데이터와 정보에 따라 본 명세서에 설명된 동작을 실행하도록 동작가능 하다. 잠재적인 사용자는 또한, 예를 들어, 서버 소프트웨어 세트 중 소프트웨어의 동작에 의해 또는 데이터 입력 운 영자 또는 관리자의 다른 직원에 의해 RU 데이터베이스로 자동 캡처 및 입력을 위해, 이메일, 팩시밀리, 또 는, 예를 들어, Facebook™ 또는 Twitter™와 같은 소셜 네트워킹 서비스를 통할 수 있는 다른 통신을 통해 사 용자 등록 정보를 제공함으로써 자기 자신을 사용자로서 등록 또는 레코드할 수도 있다. 성공적인 등록에 이어서, RU는 온라인 액세스 또는 \"로그인\" 페이지를 통해 시스템에 이후 액세스하여, 사용자가 자신의 사용자 이름 및 연관된 패스워드와 같은 적절한 식별 및 보안 권한을 입력하면, 시스템에 대한 액세스를 제공할 수 있다는 점에 유의해야 한다.이미지 처리 애플리케이션은 제시된 사용자 신체 상세와 신체의 제1 표현을 수신하고 처리하여, 제2 표현을 생성하도록 동작가능하다. 설명된 실시예에서, 이미지가 2D 깊이 이미지이든지 또는 3D 깊이 이미지 이든지 상관없이, 이미지가 제출될 때 (사용자 신체 상세의) 등록으로부터의 디폴트 설정이 사용되며, 사용자는 (예를 들어 그 목표를 향해 진행할 때 시간에 따라 신체의 상세가 변할 수 있으므로) 사진 스크린의 형태를 통해 필요에 따라 이 이미지를 업데 이트할 수 있다. 이것은 유리하게도 데이터 입력 시간을 감소시킨다. 특히, 사이즈가 있거나 없이, 제시된 인종 그룹 정보가 있거나 없이 성별, 신장, 체중에 기초하여, 이미지 처리 애플리케이션은 신체를 분류하고, 이 신체에 가장 가까운 3D 모델을 갖는 복수의 템플릿 중 하나의 템플릿 을 선택하도록 동작가능하다. 이 동작이 수행되면 이미지 처리 애플리케이션이 다음 동작, 즉: 2개의 사진으로부터 전경(인체)을 분할하고 제1 표현을 2개의 각각의 실루엣으로 변환하는 동작; 분할된 전경과 각 실루엣을 사용하여 주요 포인트 및/또는 디스크립터(descriptor) 및/또는 특징부의 특징 및 측정값을 추출하는 동작; 상기 추출된 특징과 키 포인트 측정값을 사용하여 선택된 템플릿의 3D 모델을 수정하여 수정된 개체별 3D 모델 이미지(이는 제2 표현임)를 생성하는 동작; 상기 수정된 3D 모델 이미지를 사용자 계정과 연관시키는 동작; 및 상기 제1 표현의 2개의 사진을 삭제/파괴하는 동작을 수행하도록 동작할 수 있다. 유리하게는, 이 실시예에서, 생성된 제2 이미지는 개체(즉, 이미징되는 신체)에 특유하고, 그 원하는 특징을 정 확히 표현한다. 본 발명의 실시예에서, 이미지 처리 애플리케이션은, 제1 표현의 신체의 하나 이상의 시각적 표현의 신체를 포 함하는 적어도 하나의 전경을 분할하는 동작; 상기 제1 표현의 하나 이상의 시각적 표현의 하나 이상의 분할된 전경을 각 실루엣으로 변환하는 동작; 하나 이상의 분할된 전경과 각 실루엣을 사용하여 상기 신체의 형상의 외 피를 구성하거나, 및/또는 특징을 추출하거나 및/또는 키 포인트의 측정값을 추출하는 동작; 및 상기 외피 및/ 또는 특징 및/또는 키 포인트 측정값을 중 하나 이상을 사용하여, 선택된 템플릿의 신체(평균 신체 모델)의 3D 모델을 수정, 장착 및 변형하는 것 중 하나 이상을 수행하여, 제2 표현인 수정된 개체별 3D 모델 이미지를 생성 하도록 동작가능하다. 일 실시예에서, 컬러 및/또는 질감이 있거나 없는 깊이 이미지, 포인트 클라우드 및 메쉬의 경우, 이미지 처리 애플리케이션은 신체의 3차원 개체별 형상을 재구성하도록 동작가능하다. 통신 애플리케이션은 서버와 이 서버와 통신하는 장치 사이의 통신을 가능하게 하도록 동작가능하다. 이러 한 통신은 본 명세서에 설명된 통신을 포함하고, 전자 메일, 팝업 통지 및 SMS 메시지를 포함하는 임의의 적절 한 유형일 수 있으며, 향상된 보안을 위해 암호화될 수 있다. 통신 애플리케이션을 통해 이루어진 통신은 업로드된 이미지가 삭제되었음을 확인하는 통지 및 사용자의 3D 아 바타를 생성하는데 실루엣이 사용되고 있음을 나타내는 통지와 같은 사용자에 대한 상태 통지를 포함할 수 있다. 통신 애플리케이션을 통해, 수정된 3D 모델 이미지는 (적절한 통지 메시지와 함께) 주 이미지 스크린 상에 디스플레이할 수 있는 장치로 통신된다. 이 실시예에서 생성된 수정된 3D 모델 이미지는 사용자의 신체(1 4)의 형상과 측정값을 정확히 반영하는 작업 모델이고, 이에 대해 사용자는 사용자 인터페이스를 통해 하나 이상의 상호 작용을 수행할 수 있다. 하나 이상의 상호 작용은 모델의 영역 또는 부분을 선택하여 정확한 원주 상세를 획득하는 것을 포함할 수 있다. 특히, 설명된 실시예에서, 사용자는 3D 모델의 일부를 \"클릭하거나\" 선 택할 수 있고, 선택된 부분과 관련된 수치 값을 (디스플레이를 통해) 볼 수 있다. 사용자가 사용자 인터페 이스를 통해 3D 모델을 회전시키고 줌(zoom) 기능을 수행할 수 있는 기능이 또한 제공된다. 본 발명의 실시예에서, 요청 정보를 제출하는 사용자와, 생성 후 장치로 통신된 수정된 3D 모델 이미지 사 이에 약 90 초가 경과할 수 있다. 이 실시예에서, 이 모델은 성별에 기초하여 착색된다: 여성은 분홍색, 남성은 청색이다. 사용자는, 전자 스크린과 페이지에 제공된 각 네비게이션 인터페이스 요소 버튼을 실행하는 것을 통해, 생성된 전자 스크린과 페이지로 진행하고 및 이로부터 리턴하는 것을 포함하여 네비게이션할 수 있다. 특히, 인터페이 스 요소 버튼을 갖는 네비게이션 바가 제공되어, 이를 통해 사용자는 시스템을 제어하여 그 특정 측정 값과 요구조건에 기초하여 개인의 피트니스 목표를 지원하는 것에 액세스하는 것을 포함하는 동작을 수행할 수 있다. 설명된 실시예에서, 이러한 지원은, 사용자가 개인의 피트니스 목표를 달성하는 것을 도와주는 소비량을 나타내는 식사에 대한 조리법에 액세스하는 단계; 측정하는 단계; 사용자에게 맞을 수 있는 영양 계획과 운동 프로그램을 포함하는 계획(들)을 수립하는 단계; 새로운 이미지를 가져오는 (새로운 수정된 3D 모델 이미지를 생성하는) 단계; 및 시스템을 사인 아웃(sign out)/퇴장하는 단계를 포함한다. 본 발명의 실시예에서, 장치는 생성된 수정된 3D 모델 이미지(이는 제2 표현임)를 저장하는 동작, 및 사용 자가 장치를 사용하여 신체의 새로운 이미지를 생성하는 그 다음 시간에 비교하기 위한 템플릿으로서 이것 을 사용하는 동작을 수행하도록 동작가능하다. 즉, 사용자가 장치의 초기 사용 이후 장치를 사용하여 신체의 새로운 이미지를 생성할 때마다, 장치의 이전의 사용 동안 생성된 수정된 3D 모델 이미지가 새 로운 이미지를 생성하는데 사용된다. 따라서, 이 실시예에서 신체의 제3 표현은 신체의 생성된 제2 표 현에 기초하여 생성되고, 신체의 제4 표현은 신체의 생성된 제3 표현에 기초하여 생성되고, 이와 같은 방식으로 계속된다. 실시예에서, 지원은 예를 들어 DEXA 스캔 통합과 같은 하나 이상의 다른 시스템과의 통합을 포함할 수 있다. 이 러한 경우에, 사용자 인터페이스를 통해 수행될 수 있는 하나 이상의 상호 작용은 3D 모델의 상부에 디스플 레이된 오버레이로서 DEXA 스캔으로부터 발생하는 데이터 및/또는 정보를 액세스하는 동작, 3D 모델의 일부를 선택하는 동작, 선택된 부분과 관련된 DEXA 스캔 데이터 및/또는 정보를 (디스플레이를 통해) 보는 동작을 포함할 수 있다. 송장 작성/청구서 발행 애플리케이션은 시스템의 사용에 따라 지불할 금액을 포함하는 각 등록된 사용자에 대한 송장을 생성하도록 동작가능하다. 지불 처리 애플리케이션은 각 송장에 대한 지불을 수신하도록 동작가능하다. 본 발명의 실시예에서, 시스템에 의해 수행되는 설명된, 추가적인 및/또는 대안적인 동작들 중 하나 이상은 인간의 개입을 요구하지 않고 자동적으로 발생한다. 본 발명의 실시예의 상기 및 다른 특징들 및 잇점들은 이제 도면의 도 1에 도시된 흐름도를 참조하여 사용시 시 스템에 대하여 더 설명될 것이다. 관심 있는 사람은 전술된 등록 공정을 통해 시스템의 사용자로서 등록하고, 그 결과 이들에 사용자 계정이 제공된다. 이후, (이제 등록된) 사용자는 전술된 시스템에 액세스하여 이 시스템을 사용하여, 신체의 하나 이상의 수 정된 3D 모델 이미지를 생성하고, 개인의 피트니스 목표를 달성하는 것을 도와주기 위해 다른 제공된 지원에 액 세스한다. 시간에 따라, 사용자는 이미지의 변화를 나타내는 신체의 수정된 3D 모델 이미지의 시퀀스를 생성할 수 있다. 이러한 빈번한 자가 모니터링을 통해 사용자는 개인의 피트니스 목표를 향한 진행 상황을 평가할 수 있어서, 이 목표를 달성할 가능성이 더 커진다. 도면의 도 4 및 도 5는 본 발명의 양태에 따른 장치를 사용하여 신체를 이미징하기 위한 시스템의 제 2 실시예의 사용 동안 수행되는 동작을 도시한다. 제2 실시예의 시스템과 유사하거나 동일한 특징은 제1 실시예와 동일한 참조 부호로 표시된다. 보다 상세히 설명될 바와 같이, 제2 실시예는 3차원 인간 모델(아바타)을 재구성하기 위해 생태학적으로 적절한 시스템 및 방법을 제공한다. 보다 상세히 설명될 바와 같이, 시스템 및 방법은 (일반성을 상실하지 않으면서, 예를 들어, 사람의 경우에) 그 신장 및/또는 체중이 주어지는 경우 개체의 하나 이상의 이미지를 사용한다. 제2 실시예에서, 장치의 제어기는, 전자 프로그램 명령의 제어 하에, 신체의 제1 표현을 분할하는 것 에 의해 신체의 제1 표현을 처리하여, 신체의 실질적으로 진정한 3차원 스캔의 투영된 음영을 간단한 형태로 나타내는 복수의 실루엣을 획득하는 동작; 및 이들 실루엣에 기초하여 신체의 제2 표현을 생성하는 동작을 수행하도록 동작할 수 있다.제어기는 또한, 전자 프로그램 명령의 제어 하에, 입력이 수신되면, 장치의 디스플레이 상에 나타나는 사 용자별 골격을 생성하는 동작; 및 제1 표현을 분할하는 공정 동안, 사용자로 하여금 제1 표현의 신체를 사 용자별 골격과 정렬하게 하는 동작을 수행하도록 동작가능하다. 특히, 제2 실시예에서, 시스템은, 앱의 전자 프로그램 명령의 제어 하에, 사용자의 3D 아바타를 생성하거 나 또는 구축하기 위해 다음의 순차적인 작업(task)(1-6)을 수행하도록 동작가능하다: 작업 1: 각 이미지에서 사용자를 자동으로 분류하여 사용자의 실제 3D 스캔의 투영된 음영을 간단한 형태로 나 타내는 이진 이미지(실루엣, S를 정의한다)를 취득한다. 제2 실시예에서, 분할하는 것은 다음 중 하나 또는 둘 모두가 수행될 때 달성된다: a. 장치가 신체의 정면도의 제1 사진을 캡처하기 시작하면 사용자는 장치의 디스플레이를 통해 생 성되고 디스플레이된 사용자별 골격과 신체를 정렬시킨다. 이 동작에는 최적의 이미지가 캡처되는 것을 보장하 기 위해 장치를 통해 전달되는 시각적 및/또는 청각적 피드백이 동반될 수 있다; 및 b. 사용자는 신체의 정면도의 제1 사진에서 얼굴, 손, 발이 보이고 덮히지 않는 것을 보장한다. 신체의 측면도 의 제2 사진에서, 제2 실시예에 따라, 단지 얼굴과 하나의 발 또는 두 발은 보여야 할 필요가 있다. 작업 2: 분할된 실루엣으로부터 다양한 유형의 특징을 추출하고 추출된 특징을 서로 융합시켜 표현(데이터 벡터)을 형성한다. 실루엣당 하나의 표현. 작업 3: 제시된 사용자 신장 정보, 이미지 사이즈(픽셀 단위의 이미지 높이 및 폭)에 기초하여, 및 이진 이미지, 투영 이론 및 카메라 모델의 얼룩 분석을 사용하여; 다음을 계산한다: a. 각 이미지에서 카메라 위치와 방향을 포함하는 캡처 카메라(이는 자세라고도 한다)의 내재적 파라미터와 외 인성 파라미터의 초기 추정치; P를 정의한다. b. 사용자 골격을 나타내는 골격 모델의 관절 운동학의 초기 추정치, JK를 정의한다. 이것은 골격 모델의 각 관 절의 3D 위치와 3D 방향을 포함한다. 작업 4: 제시된 사용자 신장 및 체중 정보 또는 사용자 신장 정보에만 기초하여, 사용자가 입력한 신장, 체중 또는 알려진 경우 더 많은 신체 측정값에 따라 변하는 평균 아바타(Av를 정의한다)를 예측한다. Av는 또한 사이 즈 N-관절의 기준 골격에 장착되고, 기준 자세에서 알려진 JK 및 골 중량/신장 행렬(W를 정의한다)을 가진다. 제2 실시예에서, 행렬(W)은 예측 모듈의 학습 공정 동안 단 한번만 오프라인으로 계산되고 나서, 다른 아바타를 예측하거나 또는 생성하는데 사용될 기준 골격(JK)과 함께 이미징 앱에 기억된다. W의 목적은 관절, 골, 및 정 점(V), 에지(E) 및 면(F)으로 표시된 실제 3D 아바타 표면 사이의 관계를 제한하고 제어하고 모델링하는 것이다. 즉, 아바타를 이미징 앱에 제시된 이미지에서 사용자의 새로운 이미지(Av1을 정의한다)로 변형하거나 단순히 애니메이팅한다. 제시된 이미지의 기준 또는 평균 아바타 데이터(V, E, F, JK, W)와, 사용자 관절 운동 학(JK1을 정의한다)의 알려진 또는 추정치는 자연스러운 인간 동작으로 알려진 또는 학습된 다수의 물리적 제약 조건에 따라 Av를 Av1로 최적화하고 변형시키는 비용 함수에 공급된다. 제약 조건은 예를 들어 골반 관절이 가 질 수 있는 최대 회전 또는 다른 것에 대한 관절의 3D 위치와 방향, 관절의 계층 구조, 및 다른 것의 움직임에 영향을 미치는 요소를 포함할 수 있다. 즉, 평균 아바타와 동일한 신체 측정값을 가진 새로운 애니메이션 아바 타(Av1)는 기준/평균 데이터의 함수이다; 즉 Av1 = f(Av, W, JK, JK1)이다. 제2 실시예의 기술에서, 다음 2개의 가중된 에너지 최소화 함수를 결합하는 함수가 유도된다: a. V, F 및 E를 사용하는 라플라시안 코탄젠트 행렬을 사용한 표면 평활 함수, 및 b. (V, F 및 W)를 사용하여 아바타 정점과 골 사이의 대응 관계가 제한되는 것을 보장하는 골 부착 함수. 초기 아바타(Av)의 예측(예를 들어, 베이지안 다변수(Bayesian multivariate) 사용)은 정교한 다변수-기반 기계 학습 접근법을 따른다. 제2 실시예에서, 이것은 상이한 연령과 자세(따라서 본 명세서에서 사용된 생태학적으로 적절한 용어)의 실제 인간(남성과 여성)의 20,000회 이상 장착되고 렌더링된 3차원 스캔으로부터 추출된 3D 특 징을 사용하여 인간 형상의 기계 지능 학습(오프라인으로 수행됨)을 포함한다. 이것은 또한 L개의 상이한 측정 값을 갖는 서로 다른 신체 측정값(벡터 M = (m1, m2, ..., mL을 정의한다)들 사이의 다양한 통계적 관계의 기계 지능 학습을 포함한다. 예를 들어, m1은 가슴 둘레일 수 있다. 개발된 기술은 하나 이상의 상이한 측정값이 주 어진 경우 하나 이상의 측정값을 예측할 수 있고, 이들 측정값들 중 하나 이상이 주어진 경우 아바타를 예측할 수 있다. 학습 공정은 각 실제 3D 스캔으로부터 추출된 다양한 3차원 형상 (표면) 특징을 사용하는 것을 수반한다. 인공 지능과 기계 학습은 이와 관련하여 제한되지 않으며, 본 발명의 대안적인 실시예에서, 추가적인 및/또는 대안적인 훈련, 테스트 및 검증이 이미징되도록 의도된 신체 또는 물건, 및 만들어지거나 분류될 결정에 따라 사용될 수 있다. 작업 5: 제공 사항 a. 사용자의 신장 또는 신장과 체중 및 성별, 나머지 측정값을 M으로 예측하고 나서, 사용자의 초기 평균 아바 타(Av)를 생성(예측)한다. 그리하여 Av 그 자체는 측정값 M의 함수이고, 즉 Av = fa(m1, m2, ..., mL) = fa (M)이다, b. 투영 행렬들(P)의 초기 추정치들, c. Av의 기준 자세 관절 운동학(JK)과 그 골 행렬(W), d. 분할된 실루엣은 제1 표현의 S를 정의한다. 문제: 위의 사항이 주어진 경우, 아바타(Av1)를 찾고 그 정확한 측정값은 사용자의 M1을 한정하는가? 해결책: a- M으로 M1을 초기화한다 b- 사용자가 기준 자세로부터 다른 신체 자세를 가질 때, 우리는 사용자의 관절 운동학이 JK1이라고 가정하고 이를 기준 오프라인 자세(JK)로 초기화한다 c- P로 P1을 초기화한다, 여기서 P1은 정확한 카메라 파라미터이다 d- 함수 Av1 = f(V, F, E, M1, JK1, W)를 형성한다. 적응적 및 반복적 제한적인 볼록한 최적화 기술은 사용자의 실루엣(S), 사용자의 실루엣으로부터 추출된 표현 또는 현저한 특징, 및 아바타(Av1)의 투영된 실루엣, 즉 Av1의 S개의 실루엣을 비교하거나 매칭하는 비용 함수 를 최소화하는데 사용된다. Av1의 실루엣은 Av1 = P1(Av1)을 투영한 후에 이미지 변형 공정(예를 들어, 평활화, 에지 검출, 침식, 팽창, 구 멍 매우기, 연결된 구성 요소 분석을 사용하여 고립된 픽셀과 작은 얼룩을 제거하는 것을 포함함)을 사용하여 평가된다. 이미징 기술의 개발된 최적화 공정은 (i) 새로운 신체 특정 값(M1)에 도달하기 위해 초기에 예측된 측정값(M), (ii) 새로운 실제 행렬(P1)에 도달하기 위해 초기 추정된 투영 행렬(P), 및 (iii) 실제 3D 세계에서 신체의 새로운 값과 실제 값(JK1)에 대해 처음 추정된 관절 운동학(JK)을 적응적이고 자동적으로 조정한다. 국 부적인 최소값에 도달하고 사용자의 실루엣(또는 특징 또는 표현)이 아바타의 Av1 투영된 실루엣과 매칭할 때까 지 하나의 반복적이고 제한적인 방식으로 모두 수행된다. 제약 조건은 예를 들어 사람의 엉덩이, 허리 등이 현 실적으로 가능할 수 있는 최대값과 최소값, JK 중 특정 관절의 위치 및 방향이 가질 수 있는 최대값과 최소값; 또는 카메라가 가질 수 있는 최대 회전 각도와 병진이동(오프셋)을 포함한다. 종래 기술의 시스템과 달리, 제2 실시예의 시스템 및 방법은 사용자 아바타 또는 실루엣과 매칭하는 가장 가까 운 실루엣 또는 아바타를 발견하기 위해 이산 주 성분 분석(principal component analysis: PCA) 기반의 룩업 테이블(LOOKUP table)을 요구하지 않는다. 개발된 모델 기반 다변수-기반 기계 학습 접근법은 학습된 3D 스캔 각각을 고차원 초공간(예를 들어, 리마이넨(Remainen), 그라스마니안(Grassmannian) 매니폴드 또는 라이(Lie) 그룹) 내의 한 점으로 나타낸다. 이것은 캡처된 이미지에서 수동 조정도 요구하지 않고 기준 객체도 요구하지 않는다. 또한, 전체 최적화 공정은 완전 자동이며, 정확한 사용자별 아바타 생성, 각 이미지에서 사용자 자세의 자동 추정, 및 카메라 내재적 파라미터와 외인성 파라미터의 자동 추정을 가능하게 한다. 작업 6: 작업 5에서 실루엣을 매칭시키기 위해 다양한 특징과 표현이 테스트되고 최적의 것들이 선택된다. 예를 들어 DCT(Direct Cosine Transform), 코너/에지, HOG(Histogram of Oriented Gradients), SURF(Speeded Up Robust Features), SIFT(Simultaneous Feature Transform) 및 커블릿 특징(Curvlet Features)에 기초한 특징. 제2 실시예의 시스템을 위한 전자 프로그램 명령은 등록 모듈(전방 앱), 이미지 캡처 모듈, 이미지 검사 및 전처리 모듈, 전경(사용자의 실루엣) 분할 모듈 및 아바타와 실루엣 매칭 모듈을 포함하는 복수의 소프트웨어 모듈을 포함한다. 등록 모듈(전방 앱) 제2 실시예의 등록 모듈(전방 앱)은 제1 실시예의 웹 사이트 애플리케이션과 유사하게 동작하며, 사용자가 자신 의 신체에 관한 정보 및/또는 데이터를 입력하는 것을 용이하게 한다. 제2 실시예에서, 이것은 사용자의 신장과 체중을 포함하거나, 또는 신장만을 포함할 수 있다. 또한, 이것은 예를 들어 수신된 이미지 등이 흐려지거나 암 호화되는 정도를 결정할 수 있는 시스템의 테스트 단계 또는 학습 단계에 자신의 데이터를 사용자가 제공하 기를 원하는지에 대한 표시를 사용자로부터 수신하도록 동작가능할 수 있다. 제2 실시예에서, 사용자 데이터는 SSL을 통해 클라우드에 저장되고 개인 데이터는 암호화된다. 이미지 캡처 모듈 이미지 캡처 모듈은, 전통적인 옵션과 스마트 옵션을 포함하는, 시스템에 이미지(들)를 입력하는 옵션을 사용자 에게 제공하도록 동작가능하다. 전통적인 옵션을 통해 사용자는 자신의 디지털 카메라 또는 (본 명세서에 설명된 것과 같은) 임의의 유형의 이 미지를 사용하여 하나 이상의 이미지를 캡처하고, 퍼스널 컴퓨터, 노트북, 아이패드(ipad), 태블릿 또는 유사한 장치를 사용하여 이미지를 업로드하도록 안내된다. 스마트 옵션(스마트폰, 퍼스널 컴퓨터, 랩탑, 태블릿 또는 유사한 장치를 사용할 때 적용가능)을 통해 사용자는 스마트 폰, 랩탑에 연결되거나 내장된 카메라, 퍼스널 컴퓨터, 또는 캡처 장치(예를 들어, 카메라)를 통합하고 프로그램, 스크립트, 앱 또는 유사 프로그램을 실행할 수 있는 임의의 장치를 사용하여 이미지를 캡처한다. 이미지 캡처 모듈은 사용자가 자기 자신이 이미지를 캡처하는지 또는 다른 사람이 이미지를 캡처하는지 여부에 따라 최적 이미지(들)를 캡처하도록 사용자를 안내하는 시각적 및 청각적 보조 기능을 제공하도록 동작할 수 있 다. 일반성을 잃지 않으면서 실시간 인간 추적기(들) 및/또는 사람의 얼굴 추적기(들)와 같은 시각적 보조 기능이 트리거되고 나서, 캡처 공정 동안 초기화되어 제3자가 최상의 최적 이미지를 캡처하는 것을 도와줄 수 있다. 이와 관련하여 이미지 캡처 모듈은 고유한 키포인트와 독특한 얼굴 특징 및 컬러 또는 그레이스케일 이미지에서 시공간 특징의 융합을 사용하여 인간의 얼굴을 검출하고 추적하는 방법을 학습하는 적응적 커널(kernel) 기반 추적기를 포함한다. 눈, 코, 귀 및 입 검출기와 추적기는 주 얼굴 추적기 내에서 커버되는 간접적인 서브 모드 (sub-modality)이다. 개발된 추적기는 결정론적인, 단일 및 다변수 확률 모델을 사용한다. 인간 추적기는 얼굴 추적기와 동일한 기술을 따르지만 본 명세서에 언급된 독특한 인간 형상과 움직임 특징을 갖는다. 전술된 바와 같이, 이미지 캡처 모듈은 사용자에게 최적의 이미지를 캡처하도록 안내하기 위해 고유한 개체(사 용자)별 인간 골격을 생성하도록 동작가능하다. 이를 위해 다변수 데이터 분석을 수반하는 고급 인공 지능과 기 계 학습 기술을 사용하여 개체 신장과 체중 또는 단지 중량만이 주어진 경우 골격 관절의 3차원 위치를 생성하 는 것을 담당하는 모델을 학습한다. 제2 실시예에서, 학습 공정은 진정한 (실제) 해부학적 데이터가 20,000명 이상의 실제 인간 개체의 3D 스캔에 속하는 것에 의해 제한되고 그리하여 생태학적으로 적절한 용어이다. 볼록 한 최적화 및 맞춤 공정, 기하학적 수축이 또한 3D 스캔에 피부를 생성하고 이 3D 스캔을 그 곡선 골격, 해부학 적 골격에 장착하여, 이들 중 각각 2개 사이의 대응 관계를 획득하도록 개발된다. 인공 지능과 기계 학습은 이와 관련하여 제한되지 않으며, 본 발명의 대안적인 실시예에서, 추가적인 모델 및/ 또는 대안적인 모델이 이미징되도록 의도된 신체 또는 물건에 따라 학습되고 골격이 생성될 수 있다는 것을 이 해해야 한다. 학습 공정의 제약 조건은 본 발명의 구현에 적절하게, 제2 실시예의 것보다 더 많거나 더 적은 데 이터 및 추가적인 및/또는 대안적인 유형(들)의 데이터를 포함할 수 있다. 캡처 공정 동안, 시스템에 의해 구현되는 상기 접근법은 다수의 골 및 관절을 포함하는 실시간 온-스크린 인간 골격을 생성하여 (장치의 터치스크린 상에) 제시한다. 그 후, 가슴, 팔, 다리 및 머리와 같은 신체 부위를 온스크린 인간 골격의 골에 정렬시킬 것을 가청 음성/단어/발언(시스템의 동작에 의해 생성되 고 장치를 통해 출력됨)을 통해 사용자에게 요구한다. 이미지 캡처 모듈은, 생성된 골격과 사용자의 실시 간 캡처된 이미지(들)로부터 추출된, 형상 외관과 변동 특징, 자세 특징, 시공간적(또는 예를 들어 광학 흐름특징 또는 다른 움직임 데이터 벡터)을 포함하는 다양한 데이터와 특성들 사이에서 계산된 에러에 의해 정렬 공 정을 제어하도록 동작가능하다. 자이로스코프에 의해 캡처된 3차원 방향 자이로스코프 각도와 같은, 장치 의 센서 세트의 센서로부터의 출력은 또한 최적의 직선 이미지 캡처를 더욱 보장하기 위해 이 모듈에서 사용된 다. 이미지에서 골격 자세와 사용자 자세 사이의 에러 범주와 유형은 사용자를 안내하여 최적의 이미지(화상)를 취 하도록 피드백 모듈에 공급되거나 입력된다. 정렬 공정과 시각적 및 청각적 피드백 모듈은 도면의 도 4에 도시된 바와 같이, 사용자 이미지와 골격 사이의 허용가능한 정렬이 달성될 때까지 동시에 동작한다. 이미지 검사 및 전처리 모듈 이미지 검사 및 전처리 모듈은 정확한 인간 아바타를 재구성하는데 영향을 미치는 하나 이상의 문제와 바람직하 게는 임의의 문제에 대해 캡처된 이미지를 철저히 검사하도록 동작할 수 있다. 이러한 문제는 사용자 에러, 이 미지 품질로 인한 에러, 내재적 잡음과 외인성 잡음으로 인한 에러, 외국인 개체, 다수의 개체의 존재, 및 카메 라 렌즈로 인한 왜곡을 포함할 수 있지만 이에 국한되지는 않는다. 이것은 제2 실시예에서 2개의 레벨로 수행된 다: a. 제1 레벨의 검사는 (i) 앱이 관심 개체(제2 실시예에서 개체의 일례로서 인간 사용자를 포함함)의 존재를 체 크하도록 동작할 수 있는 앱 레벨에 있다. 이 작업을 위해 간단하지만 효율적인 얼굴과 사람 검출기와 추적기가 개발되어 검사하고 검사에 기초하여 이미지를 수용하거나 또는 거부하도록 동작할 수 있다. (ii) 앱은 또한 장 치의 내장된 자이로스코프 데이터를 사용하여 사용자에게 최적의 이미지를 캡처하도록 안내하고 미리 한정 된 자세 임계값 세트에 따라 이미지를 수용하거나 거부하도록 동작할 수 있다. (iii) 앱은 또한 규정된 기준이 충족되고 수용가능한지 여부를 결정하기 위해, 예를 들어, 포맷, 사이즈(픽셀 단위의 치수와 필요한 저장 공간 을 포함함)를 포함하여 이미지의 상세를 체크하도록 동작할 수 있다. 수용되는 경우 앱은 원래 허용된 품질의 99% 이상으로 품질을 유지하면서 이미지의 사이즈를 줄이도록 동작가능하다. 이들 단계들 중 임의의 단계에서, 사용자를 안내하기 위해 (전술된 바와 같이) 청각적 및 시각적 피드백이 생성되고 제공될 수 있다. b. 제2 레벨의 검사는 클라우드에서 실행되고 다음과 같이 동작하는 고급 이미지 전처리(advanced image pre- processing: AIPP) 모듈에서 발생하는 심층 검사이다. i. AIPP는 가변 사이즈와 분산의 가우시안 커널을 사용하여 캡처된 이미지를 필터링하여 이미지에서 잡음을 최 소화하고 다가올 공정 분할을 위해 이미지를 준비한다. ii. AIPP는 또한 픽셀 컬러 값 또는 그 강도와 이미지 위치를 사용하여 추정된 확률과 공동 확률 함수에 기초하 여 통계적 테스트를 구축한다. 그런 다음 이 AIPP는 조명과 조명 관련 변동 또는 음영을 수정한다. 그런 다음 통계적 테스트는 큰 이미지 데이터베이스의 오프라인 테스트를 통해 식별된 미리 한정된 임계 값에 기초하여 이 미지를 허용할지 거부할지 여부를 결정한다. iii. AIPP는 이미지를 검사해서, 사용자가 수족 절단자임을 나타내고 추가적인 데이터를 제공하는 경우 또는 2 개 이상의 이미지가 사용된 경우(2개의 이미지의 경우 사용자의 정면을 보는 전체 캡처 사진이 제시되어야 한다)를 제외하고, 다수의 얼굴을 가지고 있는 이미지, 불규칙적으로 뒤집히거나 왜곡된 이미지, 다수의 사람/ 완전하거나 불완전한 사람이 있는 이미지, 주 개체(사용자)를 방해하는 특성을 가진 임의의 외국인 개체 또는 배경이 있는 이미지, 사용자 신체가 불완전하게 캡처된 이미지를 거부한다. 이 목적/작업을 위해 기계 학습 접 근법은 하나 이상의 사람을 포함하거나 사람을 전혀 포함하지 않는 비디오를 포함하는 이미지의 큰 데이터베이 스로부터 추출된 다양한 융합된, 다중 모드의 현저한 이미지 특징, 디스크립터 및 키포인트에 의해 사용되고 구 동된다. 특징, 디스크립터 및 키포인트는 (예를 들어) 인간의 피부, 얼굴, 코, 입, 귀, 팔, 상체, 하체, 다리, 발에 속하고, 또한 이 검사 모듈에서 상기 기계 학습을 훈련, 테스트 및 검증하는데 사용된다. 인공 지능과 기계 학습은 이와 관련하여 제한되지 않으며, 본 발명의 대안적인 실시예에서, 추가적인 및/또는 대안적인 훈련, 테스트 및 검증이 이미징되도록 의도된 신체 또는 물건 및 이루어질 결정에 따라 사용될 수 있 는 것으로 이해된다. 전경(사용자의 실루엣) 분할 모듈 단일 이미지로부터 전경-배경 분할에서 수행된 대부분의 종래 기술 작업은 TV 쇼에서 사용되는 크로마(chroma) 키 스크린과 같은 알려진 또는 반쯤 알려진 배경 특성(들)을 가정한다. 다른 사람들은 사용자가 이미지를 수동으로 디지털화하거나 이미지 또는 이미지들에서 자신의 신체를 식별하도록 요구한다. 그러나, 이미지에서 사용 자의 신체의 윤곽 또는 사용자 또는 배경에 속하는 독특한 특징(알려진 경우, 결정/입력되거나 추정될 수 있는 경우)은 신체 형상의 정확한 실루엣을 분할하는데 강한 제약을 제공한다. 본 발명자는, 완전 자동 방식으로 사용되는, \"그래프 컷(graph-cut)\"에 기초하여 이미지에서 사람의 실루엣을 분할하여 최적화하는 것에 기초한 반복적인 접근법을 개발했다. 본 발명의 접근법은 최대-흐름 최소-컷 원리, 베이즈의 매팅(Bayes Matting)(삼중 지도(tri-map)를 포함함) 및 확률적 컬러 모델과 같은 표준 그래프-컷에서 사용되는 원리를 다수의 측면으로 확장하며, 제2 실시예에서 가장 중요한 것은 발명자 확률 모델은 픽셀 강도를 포함할 뿐만 아니라 인간 형상(그래프)의 구조와의 위치와 관련성/연결성(준수)을 포함하므로, 전경 및 배경 컬 러 분배가 잘 분리되지 않은 경우 이것은 완전 자동이며 강력하다는 것이다. 제2 실시예의 시스템이 수행"}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하도록 동작할 수 있는 개발된 접근법의 단계는 다음과 같이 요약될 수 있다. 이 접근법은 이미지로부터 사용자 실루엣을 분할하기 위해 다음 입력들 중 일부 또는 전부를 필요로 한다. 본 발명은 이들을 자동으로 식별한다. i. 사용자의 신체를 포함하는 이미지에서 경계 상자 또는 구역 또는 얼룩. 이것은 \"하드(hard)\" 분할 그래프-컷 시나리오로 알려져 있는 것에 사용된다. ii. 이미지에서 명확히, 가능성이 매우 높거나, 아마도/대개 가능성이 있는 사용자의 신체인 전경 구역 또는 특 징부. iii. 이미지에서 명확히, 가능성이 매우 높거나, 아마도/대개 가능성이 있는 사용자의 신체가 아닌 배경 구역 또는 특징부. 즉, 이미지에서 각 픽셀에는 전경 또는 배경에 속할 가능성을 알려주는 확률 값이 주어진다. 앞서 언급한 온스크린 골격에 신체를 정렬할 것을 사용자에 요구하기 때문에, 이에 따라, iv. 골격을 포함하는 경계 상자(구역)는 상기 (i)에서 요구되는 경계 상자를 엄격히 한정한다. 그러나, 불확실 성 에러를 제공하기 위해, 제2 실시예에서 5%의 불확실성 계수가 구역 위치에 가산되고, 즉 5%만큼 증가된다. v. 골격의 골을 따라 (이와 중첩되거나 함께 등록된) 이미지 픽셀은 명확히 또는 가능성이 매우 높은 인체의 일 부분이고 이것은 상기 (ii)를 충족시킨다. 시스템은 가변 사이즈의 커널에 의해 이들 중첩된 이미지-골격 구역을 확장시킴으로써 이들 \"한정적인\" 신체 부위 이미지 구역을 더욱 개선하고 확장하도록 동작가능하다. 사 이즈는 신체 부위에 비례할 수 있다. 예를 들어, 도 2에 도시된 바와 같이, 골격의 골을 따른 영역은 팔의 영역 보다 더 큰 사이즈의 커널에 의해 확장된다. vi. 경계 상자 외부의 픽셀은 배경에 속할 가능성이 매우 높으므로 이것은 상기 (iii)를 충족한다. vii. 전경 또는 배경으로 표시되지 않은 경계 상자 내의 픽셀은 아래에 설명된 다른 접근 방법에 의해 체크될 때까지 동일한 확률로 주어진다. 이 서브-모듈(sub-module)은 실루엣을 정확히 분할하는 것을 더욱 강화하도록 동작할 수 있다. 베이지안 기반의 피부 컬러 검출기는 또한 학습되고 개발되어 피부 컬러를 가질 가능성이 있는 이미지의 픽셀을 식별한다. 이것 은 사용자의 얼굴, 손, 발(신체의 나머지 부분이 덮여 있는 최악의 시나리오) 및 기타 원하지 않는 피부와 같은 개체를 검출하고 (식별하는 것이 아닌) 분할하도록 동작할 수 있다. 시스템은 연결된 구성 요소 분석 및 맞춤, 곡률 분석을 사용하여 분할된 피부-얼룩을 분석하고 반(semi)-골격 링크를 생성하도록 동작가능하다. 이 후 인접성 데이터(행렬)가 재구성되고 분석되어 인간의 골격 링크(골과 같은)의 일부가 아닌 얼룩을 제거한다. 나머지 얼룩은 사용자 신체일 가능성이 높은 부분으로 분류된다. 그런 다음 학습된 얼굴 검출기를 사용하여 사용자 얼굴을 검출하여 전술된 접근법을 더욱 개선한다. 얼굴 또는 얼굴 윤곽이 검출되면 미리 한정된 마스크를 적용하여 사람의 피부 톤만 있는 얼굴 구역을 오려내고(crop), 즉 눈, 눈썹 및 입을 검출하고 제거하는 것을 의미한다. 오려낸 얼굴 마스크의 컬러 히스토그램에 기초한 역-투영 알고리즘은 얼굴 마스크의 것과 동일한 통계값을 갖는 이미지의 픽셀을 식별하는데 적용된다. 제2 실시예에서 이 서브-모듈의 출력은 설명된 반복적인 그래프-컷 접근법에 필요한 픽셀과 구역의 분류에 더 추가되고 이를 개 선할 사용자별 피부 톤(skin tone)을 갖는 얼룩을 포함한다. 마지막으로 픽셀의 컬러, 그 위치 및 그 분류가 제안된 반복적인 그래프 컷에 공급되어 사용자 실루엣을 분할한 다. 이후 이미지와 에지 평활화, 홀(hole)과 누락 데이터 채움, 및 작은 고립된 얼룩의 제거와 같은 시스템이 수행하도록 동작가능한 다수의 이미지 처리 및 변형 공정이 뒤 따른다. 아바타와 실루엣 매칭 모듈. 아바타와 실루엣 매칭 모듈은 본 명세서에 설명된 작업 4, 작업 5 및 작업 6에 따라 아바타와 실루엣 매칭 공정 을 수행하도록 동작가능하다."}
{"patent_id": "10-2018-7014315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "요약하면, 본 발명의 제2 실시예는 3D 관절 모델(골격에 장착된 인간 모델/아바타)을 사용한다. 그래프 매칭 유 형의 전경 분할(실루엣)이 사용되며, 화면의 골격과 겹치는 이미지 데이터로 제한된다. 피부, 얼굴, 코, 입, 귀 검출기 및 추적기가 이를 더 향상/제한하는 데 사용된다. 스마트 마스크는 사용자별 피부 톤을 얻는 데 사용된 다. 이후 역-투영(back projection) 기법을 사용하여 사용자 고유의 피부 얼룩을 분류하고, 사람 신체 부위가 서로 연결되고 관련되는 방법에 관해 결정된 연결 분석과 매칭하지 않거나 부합하지 않는 것을 거부한다. 또한 주요 측지 분석(principal geodesic analysis: PGA)과 일반 매니폴드가 사용된다. 기하학적 데이터 분석과 통계 적 형상 분석에서 주요 측지 분석은 형상 디스크립터 및 표현과 함께 사용하기에 적절한 매니폴드의 비-유클리 드 비선형 설정에 주요 성분 분석을 일반화한 것이다. 본 발명의 설명된 실시예는 몇 가지 잇점을 제공하는 것으로 이해된다. 본 발명의 일 실시예의 기본적인 잇점은, 체중 감량/체중 증가/체중 유지의 노력의 결과 나타나는 실제 데이터 를 사용자에 제공할 수 있도록 하는 것이며, 이런 관점에서 본 발명의 실시예는 교육적 도구로 기능하는 것으로 볼 수 있다. 사용자로부터의 데이터가 수집됨에 따라, 본 발명의 실시예는 사용자에 대한 잠재적 건강 잇점을 추정하도록 동작가능한 하나 이상의 예측 알고리즘을 포함할 수 있다. 이런 점에서, 본 명세서에 설명된 바와 같이, 본 발명의 실시예에서, 검색된 데이터는 신체 및/또는 다른 신체들의 하나 이상의 이전의 표현의 통합 또 는 이의 데이터의 통합을 포함하거나 이와 연관될 수 있고, 이 데이터는 장치의 동작을 통해 생성되고, 및/ 또는 예를 들어 하나 이상의 다른 장치와 같은 하나 이상의 다른 소스(들) 또는 DEXA 기술로부터 획득될 수 있다. 하나 이상의 예측 알고리즘을 통해 일정 기간 동안 칼로리 섭취 및 사용자의 움직임을 포함할 수 있는 데 이터에 기초하여, 장치는 예를 들어, 사용자의 신체가 그러한 조직(regime)이 유지되고 있는 것처럼 보 일 것 같은 것을 나타내는 하나 이상의 예측 아바타를 생성하고 디스플레이하도록 동작할 수 있다. 본 발명의 실시예의 장치는 이러한 다른 소스(들)를 탐색, 위치 결정 및 이와 통신을 수립하도록 동작할 수 있다. 본 발명의 실시예는 효과적이고 정확한 모니터링을 통해 체중 감량(및/또는 다른 개인 피트니스 목표(들))을 촉 진시키는 정확한 개인화된 아바타의 생성을 제공한다. 아바타는 비-침습적 절차를 통해 즉시 생성될 수 있다. 생성된 아바타 및 관련 데이터를 저장하면 시간 경과에 따라 이루어지는 비교를 할 수 있어서 신체의 변화를 정 확히 모니터링할 수 있다. 본 발명의 실시예는 추가적인 건강 변화를 촉진시키는 피드백을 제공하는데 사용될 수 있다. 시스템을 통해 시 간 경과에 따른 사용자의 신체 변화를 보여주는 아바타의 시퀀스가 생성될 수 있다. 아바타의 시퀀스는 사용자 노력에 대한 역사적인 사례 연구를 생성한다. 사용자는 (관찰자가 편견을 갖는 사진을 사용하는 것에 비해) 정 량적으로 결과를 볼 수 있다. 작은 범위의 표준 템플릿과 실루엣을 사용하는 것에 의해 처리 요구조건과 같이 불량한 이미지로 인해 발생하는 에러가 줄어든다. 이것으로 공정을 보다 빠르고 보다 저렴한 비용으로 수행하여 사용자 경험을 개선할 수 있다. 또한, 분할된 전경과 실루엣의 특징은 사용자의 제시된 이미지가 개인 사진 이미지 데이터 없이 저장되도록 한 다. 설명된 실시예에서, 사용자의 사진 이미지는 파괴되고, 이에 따라 사용자의 프라이버시에 대한 강화된 보호 를 제공한다. 이 기술 분야에 통상의 지식을 가진 자라면 본 명세서에 설명된 본 발명의 변형 및 수정이 본 발명의 사상과 범 위를 벗어나지 않고 이루어질 수 있다는 것을 이해할 수 있을 것이다. 이 기술 분야에 통상의 지식을 가진 자에 게 자명한 변형 및 수정은 본 명세서에 기재된 본 발명의 광의의 범위와 영역 내에 있는 것으로 간주된다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2018-7014315", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명을 보다 완전하게 이해하고 실시할 수 있도록 하기 위해, 본 발명의 바람직한 실시예가 이제 첨부 도면 을 참조하여 설명될 것이다. 도 1은 본 발명의 양태에 따른, 시스템의 제1 실시예를 사용하여, 방법의 제1 실시예의 사용자 완료된 동작의 흐름도를 도시한다; 도 2는 본 발명의 일 양태에 따른 장치의 실시예의 개략도를 도시한다; 도 3은 도 1의 시스템의 단순화된 시스템 다이어그램을 도시한다; 도 4는 본 발명의 양태에 따른, 시스템의 제2 실시예를 사용하여, 방법의 제2 실시예의 사용자 완료된 동작의 흐름도를 도시한다; 및 도 5는 방법 및 시스템의 제2 실시예를 사용하는 동안 이미지에서 가능성이 높은 사용자 신체를 라벨링하는 공 정을 도시한다."}
