{"patent_id": "10-2019-0177172", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0084154", "출원번호": "10-2019-0177172", "발명의 명칭": "휴먼 인터랙티브 AI를 사용한 반자동 작문 방법 및 장치", "출원인": "주식회사 투블럭에이아이", "발명자": "조영환"}}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법에 있어서,(a) 컴퓨팅 장치가, 적어도 하나의 주제 단위문을 포함하는 주제 텍스트가 획득되면, 제1 뉴럴 네트워크로 하여금, 각각의 상기 주제 단위문에 적어도 하나의 제1 뉴럴 네트워크 연산을 가하여, 상기 주제 텍스트에대응하는, 제1 인공 단위문을 포함하는 제1 인공 텍스트를 생성하도록 하는 단계;(b) 상기 컴퓨팅 장치가, 상기 제1 인공 텍스트를 참조로 하여 생성된, 적어도 하나의 구조 단위문을 포함하는구조 텍스트가 획득되면, 제2 뉴럴 네트워크로 하여금, 상기 구조 텍스트에 대응하는, 제2 인공 단위문을 포함하는 제2 인공 텍스트를 생성하도록 하는 단계; 및(c) 상기 컴퓨팅 장치가, 상기 구조 텍스트 및 상기 제2 인공 텍스트를 참조로 하여, 상기 주제 텍스트에 대응하는 완성 텍스트를 생성하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 (a) 단계는,상기 컴퓨팅 장치가, (i) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 인코딩 레이어로 하여금, 상기주제 단위문 각각에 적어도 하나의 제1 인코딩 연산을 가하여, 상기 주제 단위문 각각에 대응하는, 이들이 포함된 각각의 주제 단위문 집합의 각 성분별로 제1 어텐션 스코어를 계산함으로써, 제1 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 디코딩 레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 연산을 가하여, 각각의 상기 주제 단위문에 대응하는 각각의 상기 제1 인공 단위문을 생성하도록 하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 (a) 단계는,상기 컴퓨팅 장치가, 상기 제1 인코딩 레이어에 포함된 적어도 하나의 제1-1 인코딩 서브레이어 및 적어도 하나의 제1-2 인코딩 서브레이어로 하여금, 상기 주제 단위문 중 하나인 특정 주제 단위문에 적어도 하나의 제1 인코딩 멀티헤드 어텐션 연산 및 제1 인코딩 Feed-Forward(FF) 네트워크 연산을 가하여, 상기 특정 주제 단위문이포함된, 상기 주제 단위문 집합 중 하나인 특정 주제 단위문 집합의 각각의 성분과 상기 특정 주제 단위문 간의연관도를 나타내는, 상기 제1 어텐션 스코어들 중 적어도 일부인 제1 특정 어텐션 스코어를 생성함으로써 상기제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반 인코딩 벡터를 생성하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2항에 있어서,상기 (a) 단계는,상기 컴퓨팅 장치가, 상기 제1 디코딩 레이어에 포함된 적어도 하나의 제1-1 디코딩 서브레이어 및 적어도 하나의 제1-2 디코딩 서브레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 멀티헤드 어텐션 연산 및 적어도 하나의 제1 디코딩 FF 연산을 가하여, 특정 주제 단위문에 대응하는 제1 특정 인공 단위문을 생성하도록 하는 것을 특징으로 하는 방법.공개특허 10-2021-0084154-3-청구항 5 제 4항에 있어서,상기 컴퓨팅 장치가, 상기 제1-1 디코딩 서브레이어로 하여금, 상기 제1 디코딩 레이어에 포함된 제1 지원 서브레이어가 제1 마스크 멀티헤드 어텐션 연산을 수행함으로써 생성된 제1 지원 정보를 참조로 하여 상기 제1 디코딩 멀티헤드 어텐션 연산을 수행하도록 하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 (b) 단계는,상기 컴퓨팅 장치는, 상기 제2 뉴럴 네트워크로 하여금, 상기 구조 단위문에 포함된 제1 내지 제N 구조 단위문중 적어도 일부인 제K 구조 단위문 - K는 1 이상 N-1 이하의 정수임 - 들을 포함하는 제K 구조 단위문 집합 및제K+1 구조 단위문들을 포함하는 제K+1 구조 단위문 집합 사이에 삽입될 적어도 하나의 제2 특정 인공 단위문들을 포함하는 제2 특정 인공 단위문 집합을 생성함으로써 상기 제2 인공 텍스트 중 적어도 일부를 생성하도록 하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 (b) 단계는,상기 컴퓨팅 장치가, (i) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 인코딩 레이어로 하여금, 상기제K 및 제K+1 구조 단위문 각각에 적어도 하나의 제2 인코딩 연산을 가하여, 상기 제K 및 제K+1 구조 단위문 각각에 대응하는, 이들이 포함된 상기 제K 및 제K+1 구조 단위문 집합에 대한, 제2 어텐션 스코어 중 일부인 제2특정 어텐션 스코어를 계산함으로써, 제2 컨텍스트 기반 인코딩 벡터 중 하나인 제2 특정 컨텍스트 기반 인코딩벡터를 계산한 후, (ii) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 디코딩 레이어로 하여금, 상기 제2 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제2 디코딩 연산을 가하여, 각각의 상기 제K 및 제K+1 구조단위문에 대응하는, 상기 제2 인공 단위문 중 적어도 일부인 각각의 제2 특정 인공 단위문을 생성하도록 하는것을 특징으로 하는 방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6항에 있어서,상기 (b) 단계는,상기 컴퓨팅 장치가, 상기 제1 인공 텍스트를 소정 디스플레이 장치를 통해 관리자에게 제공하면, 상기 관리자가 상기 제1 인공 텍스트에 포함된 상기 제1 인공 단위문 중, 제1 내지 제N 구조 단위문 - N은 2 이상의 정수임- 을 포함하는 상기 구조 단위문을 순서대로 선택함으로써 상기 구조 텍스트를 상기 컴퓨팅 장치에 입력하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항에 있어서,상기 (a) 단계 이전에,(a1) 상기 컴퓨팅 장치가, (i) 순차적으로 배열된, 하나 이상의 제1 학습 단위문으로 이루어진 하나 이상의 제1학습 단위문 집합을 포함하는 제1 학습 텍스트를 사용하여 상기 제1 뉴럴 네트워크를 학습하는 프로세스 및(ii) 하나 이상의 제2 학습 단위문으로 이루어진 하나 이상의 제2 학습 단위문 집합을 사용하여 상기 제2 뉴럴네트워크를 학습하되, 상기 제2 학습 단위문 집합 간의 관계 정보를 함께 사용하여 상기 제2 뉴럴 네트워크를학습하는 프로세스를 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법.공개특허 10-2021-0084154-4-청구항 10 제 1항에 있어서,상기 제1 및 제2 뉴럴 네트워크는, Recurrent Neural Network(RNN)의 형태로 구현되는 것을 특징으로 하는방법."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "휴먼 인터랙티브 인공지능을 사용한 반자동 작문 장치에 있어서,인스트럭션들을 저장하는 하나 이상의 메모리; 및상기 인스트럭션들을 수행하도록 설정된 하나 이상의 프로세서를 포함하되, 상기 프로세서는, (I) 적어도 하나의 주제 단위문을 포함하는 주제 텍스트가 획득되면, 제1 뉴럴 네트워크로 하여금, 각각의 상기 주제 단위문에적어도 하나의 제1 뉴럴 네트워크 연산을 가하여, 상기 주제 텍스트에 대응하는, 제1 인공 단위문을 포함하는제1 인공 텍스트를 생성하도록 하는 프로세스; (II) 상기 제1 인공 텍스트를 참조로 하여 생성된, 적어도 하나의 구조 단위문을 포함하는 구조 텍스트가 획득되면, 제2 뉴럴 네트워크로 하여금, 상기 구조 텍스트에 대응하는, 제2 인공 단위문을 포함하는 제2 인공 텍스트를 생성하도록 하는 프로세스; 및 (III) 상기 구조 텍스트 및상기 제2 인공 텍스트를 참조로 하여, 상기 주제 텍스트에 대응하는 완성 텍스트를 생성하는 프로세스를 수행하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 (I) 프로세스는,상기 프로세서가, (i) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 인코딩 레이어로 하여금, 상기 주제단위문 각각에 적어도 하나의 제1 인코딩 연산을 가하여, 상기 주제 단위문 각각에 대응하는, 이들이 포함된 각각의 주제 단위문 집합의 각 성분별로 제1 어텐션 스코어를 계산함으로써, 제1 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 디코딩 레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 연산을 가하여, 각각의 상기 주제 단위문에 대응하는 각각의상기 제1 인공 단위문을 생성하도록 하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 (I) 프로세스는,상기 프로세서가, 상기 제1 인코딩 레이어에 포함된 적어도 하나의 제1-1 인코딩 서브레이어 및 적어도 하나의제1-2 인코딩 서브레이어로 하여금, 상기 주제 단위문 중 하나인 특정 주제 단위문에 적어도 하나의 제1 인코딩멀티헤드 어텐션 연산 및 제1 인코딩 Feed-Forward(FF) 네트워크 연산을 가하여, 상기 특정 주제 단위문이 포함된, 상기 주제 단위문 집합 중 하나인 특정 주제 단위문 집합의 각각의 성분과 상기 특정 주제 단위문 간의 연관도를 나타내는, 상기 제1 어텐션 스코어들 중 적어도 일부인 제1 특정 어텐션 스코어를 생성함으로써 상기 제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반 인코딩 벡터를 생성하는 것을 특징으로 하는장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12항에 있어서,상기 (I) 프로세스는,상기 프로세서가, 상기 제1 디코딩 레이어에 포함된 적어도 하나의 제1-1 디코딩 서브레이어 및 적어도 하나의제1-2 디코딩 서브레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반인코딩 벡터에 적어도 하나의 제1 디코딩 멀티헤드 어텐션 연산 및 적어도 하나의 제1 디코딩 FF 연산을가하여, 특정 주제 단위문에 대응하는 제1 특정 인공 단위문을 생성하도록 하는 것을 특징으로 하는 장치.공개특허 10-2021-0084154-5-청구항 15 제 14항에 있어서,상기 프로세서가, 상기 제1-1 디코딩 서브레이어로 하여금, 상기 제1 디코딩 레이어에 포함된 제1 지원 서브레이어가 제1 마스크 멀티헤드 어텐션 연산을 수행함으로써 생성된 제1 지원 정보를 참조로 하여 상기 제1 디코딩멀티헤드 어텐션 연산을 수행하도록 하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11항에 있어서,상기 (II) 프로세스는,상기 프로세서가, 상기 제2 뉴럴 네트워크로 하여금, 상기 구조 단위문에 포함된 제1 내지 제N 구조 단위문 중적어도 일부인 제K 구조 단위문 - K는 1 이상 N-1 이하의 정수임 - 들을 포함하는 제K 구조 단위문 집합 및 제K+1 구조 단위문들을 포함하는 제K+1 구조 단위문 집합 사이에 삽입될 적어도 하나의 제2 특정 인공 단위문들을포함하는 제2 특정 인공 단위문 집합을 생성함으로써 상기 제2 인공 텍스트 중 적어도 일부를 생성하도록 하는것을 특징으로 하는 장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서,상기 (II) 프로세스는,상기 프로세서가, (i) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 인코딩 레이어로 하여금, 상기 제K및 제K+1 구조 단위문 각각에 적어도 하나의 제2 인코딩 연산을 가하여, 상기 제K 및 제K+1 구조 단위문 각각에대응하는, 이들이 포함된 상기 제K 및 제K+1 구조 단위문 집합에 대한, 제2 어텐션 스코어 중 일부인 제2 특정어텐션 스코어를 계산함으로써, 제2 컨텍스트 기반 인코딩 벡터 중 하나인 제2 특정 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 디코딩 레이어로 하여금, 상기 제2 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제2 디코딩 연산을 가하여, 각각의 상기 제K 및 제K+1 구조 단위문에 대응하는, 상기 제2 인공 단위문 중 적어도 일부인 각각의 제2 특정 인공 단위문을 생성하도록 하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 16항에 있어서,상기 (II) 프로세스는,상기 프로세서가, 상기 제1 인공 텍스트를 소정 디스플레이 장치를 통해 관리자에게 제공하면, 상기 관리자가상기 제1 인공 텍스트에 포함된 상기 제1 인공 단위문 중, 제1 내지 제N 구조 단위문 - N은 2 이상의 정수임 -을 포함하는 상기 구조 단위문을 순서대로 선택함으로써 상기 구조 텍스트를 상기 컴퓨팅 장치에 입력하는 것을특징으로 하는 장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 11항에 있어서,상기 (I) 프로세스 이전에,상기 프로세서가, (I1) 상기 컴퓨팅 장치가, (i) 순차적으로 배열된, 하나 이상의 제1 학습 단위문으로 이루어진 하나 이상의 제1 학습 단위문 집합을 포함하는 제1 학습 텍스트를 사용하여 상기 제1 뉴럴 네트워크를 학습하는 프로세스 및 (ii) 하나 이상의 제2 학습 단위문으로 이루어진 하나 이상의 제2 학습 단위문 집합을 사용하여 상기 제2 뉴럴 네트워크를 학습하되, 상기 제2 학습 단위문 집합 간의 관계 정보를 함께 사용하여 상기 제2뉴럴 네트워크를 학습하는 프로세스를 수행하는 프로세스를 더 수행하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2019-0177172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2021-0084154-6-제 11항에 있어서,상기 제1 및 제2 뉴럴 네트워크는, Recurrent Neural Network(RNN)의 형태로 구현되는 것을 특징으로 하는장치."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법이 개시된다. 즉, (a) 컴퓨팅 장치가, 적어도 하나의 주제 단위문을 포함하는 주제 텍스트가 획득되면, 제1 뉴럴 네트워크로 하여금, 각각의 상기 주제 단위문에 적어도 하 나의 제1 뉴럴 네트워크 연산을 가하여, 상기 주제 텍스트에 대응하는, 제1 인공 단위문을 포함하는 제1 인공 텍 스트를 생성하도록 하는 단계; (b) 상기 컴퓨팅 장치가, 상기 제1 인공 텍스트를 참조로 하여 생성된, 적어도 하 나의 구조 단위문을 포함하는 구조 텍스트가 획득되면, 제2 뉴럴 네트워크로 하여금, 상기 구조 텍스트에 대응하 는, 제2 인공 단위문을 포함하는 제2 인공 텍스트를 생성하도록 하는 단계; 및 (c) 상기 컴퓨팅 장치가, 상기 구 조 텍스트 및 상기 제2 인공 텍스트를 참조로 하여, 상기 주제 텍스트에 대응하는 완성 텍스트를 생성하는 단계 를 포함하는 것을 특징으로 하는 방법이 개시된다."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 휴먼 인터랙티브 AI를 사용한 반자동 작문 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자연어를 처리함으로써 글을 써내는 알고리즘을 만드는 것은 최근 주목받고 있는 컴퓨터 프로그래밍의 많은 목 표들 중 하나이다. 자연어를 처리하기 위해, 프로그래머들은 먼저 통계적 언어 모델을 수립한 바 있다. 통계적 언어 모델이란, 조건부 확률의 개념을 도입하여, 각각의 단어가 존재할 때, 그 다음 단어로 어떤 단어가 나올 가능성이 높은지를 계산함으로써 글을 쓰는 모델이다. 하지만, 통계적 언어 모델의 경우, 방대한 양의 데이터를 학습하지 못하면, 희소 문제에 의해 적절한 글을 출력할 수 없는 단점이 있다. 예를 들어, \"나는 밥을\" 이라는 말 다음에 올 단어는 \"먹었다\"인 것이 자명하지만, 만일 학습 데이터에 이와 같은 문장이 포함되어 있지 않았다 면, \"나는 밥을\"이라는 말이 입력되더라도 적절한 결과가 출력될 수 없다는 것이다. 따라서 통계적 언어 모델을 사용할 경우, 학습 데이터가 이와 같은 모든 경우를 반영하여야 하므로, 그 구현이 매우 어렵다고 볼 수 있다. 이를 보완하기 위해 제시된 모델이 N-Gram 모델이다. N-Gram 모델은, 학습 데이터를 N개의 단어 집합으로 끊어 각각을 하나의 토큰으로 간주한 후, 각 단어 집합을 단위로 하여 그 다음에 올 단어를 예측하는 모델이다. 예를 들어, N-Gram 모델 중 2-Gram 모델의 경우,\"영희와 나는 밥을\"이라는 말이 입력되었을 때, 학습 데이터에 \"영희 와 나는 밥을 먹었다\"라는 문장이 존재하지 않더라도, \"나는 밥을 먹었다\"라는 문장만 존재한다면 2-Gram 모델 은 적절한 출력을 생성할 수 있다. 하지만, 이 역시 희소 문제가 여전히 존재하고, N의 증감에 따라 trade- off가 존재한다는 단점이 있다. 위와 같은 문제에 따라 자연어 처리를 이용한 글쓰기 AI의 개발은 지지부진했다. 하지만, 딥러닝이 널리 알려짐 에 따라 뉴럴 네트워크를 사용하여 글쓰기 AI를 개발하는 방식이 제시되었고, 이에 따라 많은 발전이 있었다. 먼저 입력 값들의 시계열적 관계를 잘 파악할 수 있는 뉴럴 네트워크 모델인 Recurrent Neural Network(RNN) 모 델이 연구된 바 있다. RNN 모델은, 자신에 포함된 스테이트 벡터를 이용하여 입력 값을 연산하여 출력 값을 계 산하면서, 스테이트 벡터를 업데이트한 후 다음 입력 값을 연산할 때 사용하는 모델이다. 이에 따라, RNN 모델 은 입력 값들의 시계열적 관계를 출력 값에 반영할 수 있는 장점이 있으나, 시계열적으로 연산을 수행해야 하는 특징 상, 그 프로세스의 병렬화가 어렵고, 이에 따라 시간적 오버헤드가 매우 큰 단점이 있다. 이를 개선하기 위해, 병렬적인 구성을 채택한 Transformer 네트워크 모델이 제시되었다. 이는 문장에 포함된 각 각의 단어 별로, 해당 단어와, 같은 문장에 포함된 타 단어들과의 관계를 나타내는 어텐션 스코어를 계산함으로 써 각 문장을 인코딩한 후, 어텐션 스코어를 이용하여 디코딩함으로써 글을 써내는 모델이다. 이는 프로세스의 병렬화가 가능하므로 RNN 모델에 비해 시간적 오버헤드가 작은 장점이 있다. 하지만, 여전히 앞뒤가 안 맞는 문 장이나, 흐름이 인간적이지 않은 단락들이 출력되는 단점이 있다. 이와 같은 다소간의 문제점은 사람과의 인터랙션을 약간 추가한 반자동 인공지능 모델을 도입함으로써 해결될 수 있으나, 이에 대한 연구는 많지 않은 실정이다."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하는 것을 목적으로 한다. 또한 본 발명은 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 제공하는 것을 목적으로 한다. 또한 본 발명은 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 제공함으로써 앞뒤가 안 맞는 문장 및 흐름이 인간적이지 않은 단락들이 출력되지 않도록 하는 것을 목적으로 한다. 또한 본 발명은 앞 문장 및 뒷 문장을 제공하면 이에 맞추어 가운데의 문장들을 생성하는 인공지능을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 본 발명의 목적을 달성하고, 후술하는 본 발명의 특징적인 효과를 실현하기 위한 본 발명의 특징적인 구성은 하기와 같다. 본 발명의 일 태양에 따르면, 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법에 있어서, (a) 컴퓨팅 장치 가, 적어도 하나의 주제 단위문을 포함하는 주제 텍스트가 획득되면, 제1 뉴럴 네트워크로 하여금, 각각의 상기 주제 단위문에 적어도 하나의 제1 뉴럴 네트워크 연산을 가하여, 상기 주제 텍스트에 대응하는, 제1 인공 단위 문을 포함하는 제1 인공 텍스트를 생성하도록 하는 단계; (b) 상기 컴퓨팅 장치가, 상기 제1 인공 텍스트를 참 조로 하여 생성된, 적어도 하나의 구조 단위문을 포함하는 구조 텍스트가 획득되면, 제2 뉴럴 네트워크로 하여 금, 상기 구조 텍스트에 대응하는, 제2 인공 단위문을 포함하는 제2 인공 텍스트를 생성하도록 하는 단계; 및 (c) 상기 컴퓨팅 장치가, 상기 구조 텍스트 및 상기 제2 인공 텍스트를 참조로 하여, 상기 주제 텍스트에 대응 하는 완성 텍스트를 생성하는 단계를 포함하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 (a) 단계는, 상기 컴퓨팅 장치가, (i) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 인 코딩 레이어로 하여금, 상기 주제 단위문 각각에 적어도 하나의 제1 인코딩 연산을 가하여, 상기 주제 단위문 각각에 대응하는, 이들이 포함된 각각의 주제 단위문 집합의 각 성분별로 제1 어텐션 스코어를 계산함으로써, 제1 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 디코딩 레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 연산을 가하여, 각각의 상 기 주제 단위문에 대응하는 각각의 상기 제1 인공 단위문을 생성하도록 하는 것을 특징으로 하는 방법이 개시된 다. 일례로서, 상기 (a) 단계는, 상기 컴퓨팅 장치가, 상기 제1 인코딩 레이어에 포함된 적어도 하나의 제1-1 인코 딩 서브레이어 및 적어도 하나의 제1-2 인코딩 서브레이어로 하여금, 상기 주제 단위문 중 하나인 특정 주제 단 위문에 적어도 하나의 제1 인코딩 멀티헤드 어텐션 연산 및 제1 인코딩 Feed-Forward(FF) 네트워크 연산을 가하 여, 상기 특정 주제 단위문이 포함된, 상기 주제 단위문 집합 중 하나인 특정 주제 단위문 집합의 각각의 성분 과 상기 특정 주제 단위문 간의 연관도를 나타내는, 상기 제1 어텐션 스코어들 중 적어도 일부인 제1 특정 어텐 션 스코어를 생성함으로써 상기 제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반 인코딩 벡 터를 생성하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 (a) 단계는, 상기 컴퓨팅 장치가, 상기 제1 디코딩 레이어에 포함된 적어도 하나의 제1-1 디코 딩 서브레이어 및 적어도 하나의 제1-2 디코딩 서브레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 멀티헤드 어텐션 연산 및 적어도 하나 의 제1 디코딩 FF 연산을 가하여, 특정 주제 단위문에 대응하는 제1 특정 인공 단위문을 생성하도록 하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 컴퓨팅 장치가, 상기 제1-1 디코딩 서브레이어로 하여금, 상기 제1 디코딩 레이어에 포함된 제1 지원 서브레이어가 제1 마스크 멀티헤드 어텐션 연산을 수행함으로써 생성된 제1 지원 정보를 참조로 하여 상기 제1 디코딩 멀티헤드 어텐션 연산을 수행하도록 하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 (b) 단계는, 상기 컴퓨팅 장치는, 상기 제2 뉴럴 네트워크로 하여금, 상기 구조 단위문에 포함 된 제1 내지 제N 구조 단위문 중 적어도 일부인 제K 구조 단위문 - K는 1 이상 N-1 이하의 정수임 - 들을 포함 하는 제K 구조 단위문 집합 및 제K+1 구조 단위문들을 포함하는 제K+1 구조 단위문 집합 사이에 삽입될 적어도 하나의 제2 특정 인공 단위문들을 포함하는 제2 특정 인공 단위문 집합을 생성함으로써 상기 제2 인공 텍스트 중 적어도 일부를 생성하도록 하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 (b) 단계는, 상기 컴퓨팅 장치가, (i) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 인 코딩 레이어로 하여금, 상기 제K 및 제K+1 구조 단위문 각각에 적어도 하나의 제2 인코딩 연산을 가하여, 상기 제K 및 제K+1 구조 단위문 각각에 대응하는, 이들이 포함된 상기 제K 및 제K+1 구조 단위문 집합에 대한, 제2 어텐션 스코어 중 일부인 제2 특정 어텐션 스코어를 계산함으로써, 제2 컨텍스트 기반 인코딩 벡터 중 하나인 제2 특정 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 디코딩 레이어로 하여금, 상기 제2 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제2 디코딩 연산을 가하여, 각각의 상기 제K 및 제K+1 구조 단위문에 대응하는, 상기 제2 인공 단위문 중 적어도 일부인 각각의 제2 특정 인공 단위문을 생성하도록 하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 (b) 단계는, 상기 컴퓨팅 장치가, 상기 제1 인공 텍스트를 소정 디스플레이 장치를 통해 관리자 에게 제공하면, 상기 관리자가 상기 제1 인공 텍스트에 포함된 상기 제1 인공 단위문 중, 제1 내지 제N 구조 단 위문 - N은 2 이상의 정수임 - 을 포함하는 상기 구조 단위문을 순서대로 선택함으로써 상기 구조 텍스트를 상 기 컴퓨팅 장치에 입력하는 것을 특징으로 하는 방법이 개시된다. 일례로서, 상기 (a) 단계 이전에, (a1) 상기 컴퓨팅 장치가, (i) 순차적으로 배열된, 하나 이상의 제1 학습 단 위문으로 이루어진 하나 이상의 제1 학습 단위문 집합을 포함하는 제1 학습 텍스트를 사용하여 상기 제1 뉴럴 네트워크를 학습하는 프로세스 및 (ii) 하나 이상의 제2 학습 단위문으로 이루어진 하나 이상의 제2 학습 단위 문 집합을 사용하여 상기 제2 뉴럴 네트워크를 학습하되, 상기 제2 학습 단위문 집합 간의 관계 정보를 함께 사 용하여 상기 제2 뉴럴 네트워크를 학습하는 프로세스를 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법 이 개시된다, 일례로서, 상기 제1 및 제2 뉴럴 네트워크는, Recurrent Neural Network(RNN)의 형태로 구현되는 것을 특징으로 하는 방법이 개시된다. 본 발명의 다른 태양에 따르면, 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 장치에 있어서, 인스트럭션들 을 저장하는 하나 이상의 메모리; 및 상기 인스트럭션들을 수행하도록 설정된 하나 이상의 프로세서를 포함하되, 상기 프로세서는, (I) 적어도 하나의 주제 단위문을 포함하는 주제 텍스트가 획득되면, 제1 뉴럴 네 트워크로 하여금, 각각의 상기 주제 단위문에 적어도 하나의 제1 뉴럴 네트워크 연산을 가하여, 상기 주제 텍스 트에 대응하는, 제1 인공 단위문을 포함하는 제1 인공 텍스트를 생성하도록 하는 프로세스; (II) 상기 제1 인공 텍스트를 참조로 하여 생성된, 적어도 하나의 구조 단위문을 포함하는 구조 텍스트가 획득되면, 제2 뉴럴 네트 워크로 하여금, 상기 구조 텍스트에 대응하는, 제2 인공 단위문을 포함하는 제2 인공 텍스트를 생성하도록 하는 프로세스; 및 (III) 상기 구조 텍스트 및 상기 제2 인공 텍스트를 참조로 하여, 상기 주제 텍스트에 대응하는 완성 텍스트를 생성하는 프로세스를 수행하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 (I) 프로세스는, 상기 프로세서가, (i) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 인 코딩 레이어로 하여금, 상기 주제 단위문 각각에 적어도 하나의 제1 인코딩 연산을 가하여, 상기 주제 단위문 각각에 대응하는, 이들이 포함된 각각의 주제 단위문 집합의 각 성분별로 제1 어텐션 스코어를 계산함으로써, 제1 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 상기 제1 뉴럴 네트워크에 포함된 적어도 하나의 제1 디코딩 레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 연산을 가하여, 각각의 상 기 주제 단위문에 대응하는 각각의 상기 제1 인공 단위문을 생성하도록 하는 것을 특징으로 하는 장치가 개시된 다. 일례로서, 상기 (I) 프로세스는, 상기 프로세서가, 상기 제1 인코딩 레이어에 포함된 적어도 하나의 제1-1 인코 딩 서브레이어 및 적어도 하나의 제1-2 인코딩 서브레이어로 하여금, 상기 주제 단위문 중 하나인 특정 주제 단 위문에 적어도 하나의 제1 인코딩 멀티헤드 어텐션 연산 및 제1 인코딩 Feed-Forward(FF) 네트워크 연산을 가하 여, 상기 특정 주제 단위문이 포함된, 상기 주제 단위문 집합 중 하나인 특정 주제 단위문 집합의 각각의 성분 과 상기 특정 주제 단위문 간의 연관도를 나타내는, 상기 제1 어텐션 스코어들 중 적어도 일부인 제1 특정 어텐 션 스코어를 생성함으로써 상기 제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반 인코딩 벡 터를 생성하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 (I) 프로세스는, 상기 프로세서가, 상기 제1 디코딩 레이어에 포함된 적어도 하나의 제1-1 디코 딩 서브레이어 및 적어도 하나의 제1-2 디코딩 서브레이어로 하여금, 상기 제1 컨텍스트 기반 인코딩 벡터들 중 하나인 제1 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 멀티헤드 어텐션 연산 및 적어도 하나 의 제1 디코딩 FF 연산을 가하여, 특정 주제 단위문에 대응하는 제1 특정 인공 단위문을 생성하도록 하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 프로세서가, 상기 제1-1 디코딩 서브레이어로 하여금, 상기 제1 디코딩 레이어에 포함된 제1 지 원 서브레이어가 제1 마스크 멀티헤드 어텐션 연산을 수행함으로써 생성된 제1 지원 정보를 참조로 하여 상기 제1 디코딩 멀티헤드 어텐션 연산을 수행하도록 하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 (II) 프로세스는, 상기 프로세서가, 상기 제2 뉴럴 네트워크로 하여금, 상기 구조 단위문에 포 함된 제1 내지 제N 구조 단위문 중 적어도 일부인 제K 구조 단위문 - K는 1 이상 N-1 이하의 정수임 - 들을 포 함하는 제K 구조 단위문 집합 및 제K+1 구조 단위문들을 포함하는 제K+1 구조 단위문 집합 사이에 삽입될 적어도 하나의 제2 특정 인공 단위문들을 포함하는 제2 특정 인공 단위문 집합을 생성함으로써 상기 제2 인공 텍스 트 중 적어도 일부를 생성하도록 하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 (II) 프로세스는, 상기 프로세서가, (i) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 인코딩 레이어로 하여금, 상기 제K 및 제K+1 구조 단위문 각각에 적어도 하나의 제2 인코딩 연산을 가하여, 상 기 제K 및 제K+1 구조 단위문 각각에 대응하는, 이들이 포함된 상기 제K 및 제K+1 구조 단위문 집합에 대한, 제 2 어텐션 스코어 중 일부인 제2 특정 어텐션 스코어를 계산함으로써, 제2 컨텍스트 기반 인코딩 벡터 중 하나인 제2 특정 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 상기 제2 뉴럴 네트워크에 포함된 적어도 하나의 제2 디코딩 레이어로 하여금, 상기 제2 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제2 디코딩 연산을 가하여, 각각의 상기 제K 및 제K+1 구조 단위문에 대응하는, 상기 제2 인공 단위문 중 적어도 일부인 각각의 제 2 특정 인공 단위문을 생성하도록 하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 (II) 프로세스는, 상기 프로세서가, 상기 제1 인공 텍스트를 소정 디스플레이 장치를 통해 관리 자에게 제공하면, 상기 관리자가 상기 제1 인공 텍스트에 포함된 상기 제1 인공 단위문 중, 제1 내지 제N 구조 단위문 - N은 2 이상의 정수임 - 을 포함하는 상기 구조 단위문을 순서대로 선택함으로써 상기 구조 텍스트를 상기 컴퓨팅 장치에 입력하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 (I) 프로세스 이전에, 상기 프로세서가, (I1) 상기 컴퓨팅 장치가, (i) 순차적으로 배열된, 하 나 이상의 제1 학습 단위문으로 이루어진 하나 이상의 제1 학습 단위문 집합을 포함하는 제1 학습 텍스트를 사 용하여 상기 제1 뉴럴 네트워크를 학습하는 프로세스 및 (ii) 하나 이상의 제2 학습 단위문으로 이루어진 하나 이상의 제2 학습 단위문 집합을 사용하여 상기 제2 뉴럴 네트워크를 학습하되, 상기 제2 학습 단위문 집합 간의 관계 정보를 함께 사용하여 상기 제2 뉴럴 네트워크를 학습하는 프로세스를 수행하는 프로세스를 더 수행하는 것을 특징으로 하는 장치가 개시된다. 일례로서, 상기 제1 및 제2 뉴럴 네트워크는, Recurrent Neural Network(RNN)의 형태로 구현되는 것을 특징으로 하는 장치가 개시된다."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 제공할 수 있는 효과가 있다. 또한 본 발명은 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 제공함으로써 앞뒤가 안 맞는 문장 및 흐름이 인간적이지 않은 단락들이 출력되지 않도록 할 수 있는 효과가 있다. 또한 본 발명은 앞 문장 및 뒷 문장을 제공하면 이에 맞추어 가운데의 문장들을 생성하는 인공지능을 제공할 수 있는 효과가 있다."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있 는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시예 로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범 위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로 서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거 나 유사한 기능을 지칭한다."}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이하, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실시할 수 있도록 하기 위 하여, 본 발명의 바람직한 실시예들에 관하여 첨부된 도면을 참조하여 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하는 컴퓨팅 장치의 구성을 나타낸 도면이다. 도 1을 참조하면, 컴퓨팅 장치는 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크을 포함할 수 있다. 이 때, 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크의 입출력 및 연산 과정은 각각 통신부 및 프로 세서에 의해 이루어질 수 있다. 다만 도 1에서는 통신부 및 프로세서의 구체적인 연결 관계를 생략하였다. 이 때, 메모리는 후술할 여러 가지 지시들을 저장한 상태일 수 있고, 프로세서는 메모리 에 저장된 지시들을 수행하도록 설정되되, 프로세서는 추후 설명할 프로세스들을 수행함으로써 본 발 명을 수행할 수 있다. 이와 같이 컴퓨팅 장치가 묘사되었다고 하여, 컴퓨팅 장치가 본 발명을 실시하 기 위한 미디엄, 프로세서 및 메모리가 통합된 형태인 integrated 프로세서를 포함하는 경우를 배제하는 것은 아니다. 이상 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하는 컴퓨팅 장 치의 구성에 대해 설명한 바, 반자동 작문 방법에 대해 설명하도록 한다. 먼저 전반적인 구성을 살피기 위해 도 2를 참조하도록 한다. 도 2는 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 나타낸 흐름도이다. 도 2를 참조로 하면, 컴퓨팅 장치는, 적어도 하나의 주제 단위문을 포함하는 주제 텍스트가 획득되면, 제1 뉴럴 네트워크로 하여금, 상기 주제 단위문에 적어도 하나의 제1 뉴럴 네트워크 연산을 가하여, 주제 텍스 트에 대응하는, 제1 인공 단위문을 포함하는 제1 인공 텍스트를 생성하도록 할 수 있다(S01). 이후, 컴퓨팅 장 치는, 제1 인공 텍스트를 참조로 하여 생성된, 적어도 하나의 구조 단위문을 포함하는 구조 텍스트가 획득 되면, 제2 뉴럴 네트워크로 하여금, 구조 텍스트에 대응하는, 제2 인공 단위문을 포함하는 제2 인공 텍스 트를 생성하도록 할 수 있다(S02). 그리고, 컴퓨팅 장치는, 구조 텍스트 및 제2 인공 텍스트를 참조로 하 여, 주제 텍스트에 대응하는 완성 텍스트를 생성할 수 있다(S03). 이하 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법에 대해 더욱 구체적으 로 설명하도록 한다. 먼저, 주제 텍스트는, 컴퓨팅 장치가 소정 주제에 따라 글을 쓰도록 관리자가 입력하는 텍스트일 수 있다. 여기서 주제 단위문은, 주제 텍스트에 포함된 각각의 단어들일 수 있고, 주제 단위문 집합은, 주제 단위문들로 이루어진 각각의 문장들일 수 있다. 이와 같은 표기는 다른 것들, 즉 인공 단위문/텍스트 및 구조 단위문/텍스 트에서도 동일한 것으로, 단위문은 각각의 단어를 의미할 수 있고, 단위문 집합은 각각의 문장을 의미할 수 있 다. 이와 같은 주제 텍스트는 제1 뉴럴 네트워크에 의해 연산될 수 있다. 여기서, 제1 뉴럴 네트워크 및 추후 자세히 설명할 제2 뉴럴 네트워크는, Recurrent Neural Network(RNN)의 형태 또는 Transformer 네트 워크의 형태로 구현될 수 있다. 각각의 뉴럴 네트워크들은 서로 다른 형태로 구현될 수도 있을 것이다. 예를 들 어, 제1 뉴럴 네트워크는 RNN의 형태로 구현되고, 제2 뉴럴 네트워크는 Transformer 네트워크의 형태 로 구현될 수 있으며, 그 반대로도 가능하다. 두 뉴럴 네트워크의 구현 형태가 같은 경우는 물론 가능하다. 제1 뉴럴 네트워크가 RNN의 형태로 구현된 경우, 제1 뉴럴 네트워크는 내부에 제1 스테이트 벡터를 포함한 상태로, 자신에게 입력된 값을, 자신의 제1 스테이트 벡터를 사용하여 연산한 후 결과 값을 출력하면서 자신의 제1 스테이트 벡터를 업데이트할 수 있다. 이후, 업데이트된 자신의 제1 스테이트 벡터를 사용하여 다음으로 입력된 값을 연산할 수 있을 것이다. 추후 설명할 제2 뉴럴 네트워크와 달리, 제1 뉴럴 네트워크 는 통상적으로 알려진 RNN 기술을 사용하여 구현할 수 있는 것이므로 이상의 설명은 생략하도록 한다. 제1 뉴럴 네트워크를 Transformer 네트워크의 형태로 구현하는 방법에 대해 설명하도록 한다. 이를 위해 도 3을 참조할 것이다. 도 3은 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 제1 뉴럴 네트워크의 구성의 일 예시를 나타낸 도면이다. 도 3을 참조로 하면, 제1 뉴럴 네트워크는 적어도 하나의 제1 인코딩 레이어 및 제1 디코딩 레이어 를 포함할 수 있다. 또한, 제1 인코딩 레이어는 제1-1 인코딩 서브레이어(131-1) 및 제1-2 인코딩 서 브레이어(131-2)를 포함할 수 있고, 제1 디코딩 레이어는 제1-1 디코딩 서브레이어(132-1), 제1-2 디코딩 서브레이어(132-2) 및 제1 지원 서브레이어(132-3)를 포함할 수 있다. 여기서, 제1-1 인코딩 서브레이어(131-1)는, 적어도 하나의 제1 인코딩 멀티헤드 어텐션 연산을 수행할 수 있고, 제1-2 인코딩 서브레이어(131-2)는 제1 인코딩 Feed-Forward(FF) 네트워크 연산을 수행할 수 있다. 제1 멀티헤드 어텐션 연산은, 각각의 주제 단위문별로, 해당 주제 단위문이 포함된 주제 단위문 집합의 타 성분들과 의 연관도를 나타내는 제1 어텐션 스코어를 생성하기 위해 수행되는 연산이다. 제1 인코딩 FF 연산은, Point- wise하게 값을 연산하기 위해 수행되는 연산이다. 여기서, 제1 인코딩 멀티헤드 어텐션 연산의 결과 값, 즉 제 1-1 인코딩 서브레이어(131-1)의 출력 값이 제1-2 인코딩 서브레이어(132-1-2)에 입력되어 제1 인코딩 FF 연산 될 수 있다. 또한, 제1 인코딩 멀티헤드 어텐션 연산 및 제1 인코딩 FF 연산은 레지듀얼 커넥션 형태로 설계된 것일 수 있다. 즉, 그 입력 값을 그대로 출력 값과 더한 것을 최종 결과 값으로 출력할 수 있다. 제1 어텐션 스 코어의 예시를 살피기 위해 도 4를 참조하도록 한다. 도 4는 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 제1 뉴럴 네트워크가 제1 어텐션 스코어를 생성하는 과정의 일 예시를 나타낸 도면이다. 도 4를 참조로 하면, 제1 뉴럴 네트워크가 \"어머니는 철수에게 시장에 가서 두부 한 모를 사오라고 시켰다.\"라는 특정 주제 단위문 집합을 연산함으로써 생성되는, 제1 어텐션 스코어 중 적어도 일부를 확인할 수 있다. 예를 들어, 주제 단위문들 중 특정 주제 단위문 \"가서\"는, 주제 단위문 \"시장에\"와 연관도가 높아 이에 대응하는 제1 특정 어텐션 스코어가 높고, \"두부\", \"한\" 및 \"모\" 등의 주제 단위문들과는 연관도가 낮아 이에 대응하는 제1 특정 어텐션 스코어가 낮은 것을 확인할 수 있다. 또한, 다른 특정 주제 단위문 \"사오라고\"는, 주 제 단위문 \"두부\", \"한\", \"모\" 및 \"시켰다\"와 연관도가 높아 제1 특정 어텐션 스코어가 높고, 주제 단위문 \"시 장에\" 및 \"가서\"와 연관도가 낮아 제1 특정 어텐션 스코어가 낮은 것을 확인할 수 있다. 이와 같은 예시와 같이, 제1-1 인코딩 서브레이어(131-1) 및 제1-2 인코딩 서브레이어(131-2)는 전술한 제1 인코딩 멀티헤드 어텐 션 연산 및 제1 인코딩 FF 연산을 수행함으로써, 각각의 주제 단위문별로 각각의 제1 어텐션 스코어를 생성할 수 있다. 특정 주제 단위문에 대한 제1 특정 어텐션 스코어들이 생성되면, 이를 그 성분으로 포함하는 제1 특정 컨텍스트 기반 인코딩 벡터가 생성될 수 있다. 다시 도 3을 참조로 하면, 컴퓨팅 장치는, 제1 디코딩 레이어로 하여금, 제1 특정 컨텍스트 기반 인 코딩 벡터에 적어도 하나의 제1 디코딩 연산을 가하여 특정 주제 단위문에 대응하는 제1 특정 인공 단위문을 생 성하도록 할 수 있다. 구체적으로는, 제1 디코딩 레이어에 포함된 적어도 하나의 제1-1 디코딩 서브레이어 (132-1) 및 적어도 하나의 제1-2 디코딩 서브레이어(132-2)로 하여금, 제1 특정 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제1 디코딩 멀티헤드 어텐션 연산 및 적어도 하나의 제1 디코딩 FF 연산을 가하도록 할 수 있다. 대부분의 과정은 인코딩 연산의 그것과 대동소이할 것인데, 제1 디코딩 멀티헤드 어텐션 연산을 수행할 때, 제1 디코딩 레이어에 포함된 적어도 하나의 제1 지원 서브레이어(132-3)로부터 생성된 정보를 사용한다는 점이 다르다. 즉, 제1 지원 서브레이어(132-3)는, 특정 주제 단위문이 포함된 특정 주제 단위문 집합에서 특정 주제 단위문보다 앞에 위치한 주제 단위문들에 대해 인코딩 레이어가 생성한 제1 컨텍스트 기반 인코딩 벡터들 에 제1 마스크 멀티헤드 어텐션 연산을 수행함으로써, 특정 주제 단위문 집합에 대한 추가적인 정보인 제1 지원 정보를 생성할 수 있다. 제1 디코딩 레이어는 제1 지원 정보를 추가로 사용함으로써 특정 주제 단위문에 대한 제1 특정 인공 단위문을 더욱 정확하게 생성할 수 있게 된다. 상기와 같은 과정을 통해 제1 특정 인공 단위문을 포함하는 제1 인공 텍스트가 생성되면, 컴퓨팅 장치는 제1 인공 텍스트를 소정 디스플레이 장치를 통해 관리자에게 제공할 수 있다. 이후, 관리자는 제1 인공 텍스트 에 포함된 제1 인공 단위문 중, 제1 내지 제N 구조 단위문을 순서대로 선택함으로써 구조 텍스트를 컴퓨팅 장치에 입력할 수 있다. 이에 대한 일 예시를 살피기 위해 도 5를 참조하도록 한다. 도 5는 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 구조 텍스트 선택 과정의 일 예시를 나타낸 도면이다. 도 5를 참조로 하면, 주제 텍스트가\"어머니는 철수에게 시장에 가서 두부 한 모를 사오라고 시켰다. 철수는 어 머니께 오천 원을 받았다.\"인 경우에 대해 생성된 제1 인공 단위문을 확인할 수 있다. 제1 인공 단위문은, 제1 뉴럴 네트워크의 학습 상황에 따라 다르지만, 다소 문맥에 맞지 않거나 자연스럽지 않은 문장을 포함할 수 있다. 이에 따라, 관리자는, 도 5와 같이, \"철수는 똥을 쌌다.\" 및 \"철수는 김치찌개가 먹고 싶었다.\" 등의 제1 인공 단위문 집합은 제외하고, 정상적인 제1 인공 단위문 집합인\"철수는 시장에 가서 두부를 샀다.\" \"두부를 사 서 돌아오는 길에 고양이 한 마리를 보았다.\" 및 \"고양이는 철수에게 꼬리를 흔들었다.\"를 구조 단위문 집합으 로 선택할 수 있다. 이와 같이 구조 단위문 집합이 선택되면, 컴퓨팅 장치는 이들을 순서대로 구조 텍스트 로서 획득할 수 있다. 이와 같이 구조 텍스트가 획득되면, 컴퓨팅 장치는, 제2 뉴럴 네트워크로 하여금, 구조 텍스트를 참 조로 하여, 이에 대응하는 제2 인공 텍스트를 생성하도록 할 수 있다. 여기서, 제2 뉴럴 네트워크는 제1 뉴럴 네트워크과 그 구조가 대동소이할 수 있다. 예를 들어, 제2 뉴럴 네트워크가 RNN 형태로 구현된 경우 이는 제2 스테이트 벡터를 포함할 수 있다. 또한, 제2 뉴럴 네트워크가 Transformer 네트워크 형태로 구현된 경우, 제1 뉴럴 네트워크와 유사하게 제2인코딩 레이어 및 제2 디코딩 레이어를 포함할 수 있고, 제2 인코딩 레이어는 제2-1 인코딩 서브레이어 및 제2-2 인코딩 서브레이어를 포함할 수 있으며, 제2 디코딩 레 이어는 제2-1 디코딩 서브레이어, 제2-2 디코딩 서브레이어 및 제2-3 디코딩 서브레이어를 포함할 수 있다. 제2 뉴럴 네트워크의 각각의 레이어들 및 서브레이어들이 수행하는 연산도 제1 뉴럴 네트워크의 그것과 유사하므로, 이하 양 뉴럴 네트워크의 차이점에 대해 중점적으로 설명하도록 한다. 제1 뉴럴 네트워크와 제2 뉴럴 네트워크가 기본적으로 다른 부분은 그 입력 값일 수 있다. 제1 뉴럴 네트워크는 전술한 바와 같이 주제 텍스트가 주어지면 그 뒤로 이어질 제1 인공 텍스트를 생성하도록 설계 되어 있다. 제2 뉴럴 네트워크는 이와 달리, 주어진 구조 텍스트에 포함된 각각의 문장, 즉 각각의 구조 단위문 집합들 사이사이에 들어갈 제2 인공 텍스트를 생성하도록 설계되어 있다. 구체적으로는, 컴퓨팅 장치 가, 제2 뉴럴 네트워크로 하여금, 구조 단위문에 포함된 제1 내지 제N 구조 단위문 중 적어도 일부인 제K 구조 단위문들을 포함하는 제K 구조 단위문 집합 및 제K+1 구조 단위문들을 포함하는 제K+1 구조 단위문 집 합 사이에 삽입될 적어도 하나의 제2 특정 인공 단위문들을 포함하는 제2 특정 인공 단위문 집합을 생성함으로 써 제2 인공 텍스트 중 적어도 일부를 생성하도록 할 수 있다. 여기서, N은 1 이상의 정수이고, K는 1 이상 N-1 이하의 정수이다. 이를 위해, 제1 인코딩 레이어가 제1 어텐션 스코어를 생성할 때, 특정 주제 단위문이 포함된 특정 주제 단위문 집합만을 고려한 것과 달리, 제2 인코딩 레이어는 제2 어텐션 스코어를 생성할 때, 해당 구조 단위문이 포함된 해당 구조 단위문 집합 외에 그 다음 구조 단위문 집합까지 고려하게 된다. 위 표기에 따르면, 제K 구조 단위문 집합 및 제K+1 구조 단위문 집합을 모두 고려하여 제K 구조 단위문들 및 제K+1 구조 단위문들의 제2 특 정 어텐션 스코어를 생성하게 된다. 구체적으로는, 컴퓨팅 장치가, (i) 제2 뉴럴 네트워크에 포함된 제2 인코딩 레이어로 하여금, 제K 및 제K+1 구조 단위문 각각에 적어도 하나의 제2 인코딩 연산을 가하여, 제K 및 제K+1 구조 단위문 각각에 대응하 는, 이들이 포함된 제K 및 제K+1 구조 단위문 집합에 대한, 제2 어텐션 스코어 중 일부인 제2 특정 어텐션 스코 어를 계산함으로써, 제2 컨텍스트 기반 인코딩 벡터 중 하나인 제2 특정 컨텍스트 기반 인코딩 벡터를 계산한 후, (ii) 제2 뉴럴 네트워크에 포함된 제2 디코딩 레이어로 하여금, 제2 특정 컨텍스트 기반 인코딩 벡터 에 적어도 하나의 제2 디코딩 연산을 가하여, 각각의 제K 및 제K+1 구조 단위문에 대응하는, 제2 인공 단위문 중 적어도 일부인 각각의 제2 특정 인공 단위문을 생성하도록 할 수 있다. 이에 대한 일 예시를 살피기 위해 도 6을 참조하도록 한다. 도 6은 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 제2 뉴럴 네트워크가 제2 어텐션 스코어를 생성하는 과정의 일 예시를 나타낸 도면이다. 도 6을 참조로 하면, 제1 구조 단위문 집합인 \"철수는 시장에 가서 두부를 샀다.\" 및 제2 구조 단위문 집합인\" 두부를 사서 돌아오는 길에 고양이 한 마리를 보았다.\"를 고려한, 특정 구조 단위문 \"시장에\"에 대한 제2 특정 어텐션 스코어가 생성된 것을 확인할 수 있다. 제1 뉴럴 네트워크과 달리, 제2 뉴럴 네트워크는 제1구조 단위문 집합에 포함된 특정 구조 단위문 \"시장에\"에 대한 제2 특정 어텐션 스코어를 생성하기 위해 제1 구 조 단위문 집합 및 제2 구조 단위문 집합 모두를 고려하였다. 위와 같이 제2 어텐션 스코어를 계산하는 부분 외에는 제1 뉴럴 네트워크와 제2 뉴럴 네트워크가 거 의 같으므로, 통상의 기술자는 이상의 설명으로도 제2 뉴럴 네트워크의 동작 과정에 대해 잘 이해할 수 있 을 것이다. 즉, 전술한 것과 같이, 컴퓨팅 장치는 제2 뉴럴 네트워크에 포함된 제2 디코딩 레이어로 하여금, 제2 어텐션 스코어를 포함하는 제2 컨텍스트 기반 인코딩 벡터에 적어도 하나의 제2 디코딩 연산을 가 하여, 각각의 구조 단위문 별로 제2 인공 단위문들을 생성함으로써 제2 인공 텍스트를 생성하도록 할 수 있다. 여기서, 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크가 Transformer 네트워크 형태로 구현된 경우에 대 한 더욱 깊은 이해가 필요할 경우, 통상의 기술자는 업계에 널리 알려진 논문인 Vaswani et al.의 Attention is all you need 논문 및 Radford et al.의 Improving Language Understanding by Generative Pre-Training 논문 을 참고할 수 있을 것이다. 상기와 같은 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크는 일반적인 작문 AI와 동일하게 학습 텍스트들 을 사용함으로써 위 기능들을 수행할 수 있도록 학습될 수 있다. 예를 들어, 컴퓨팅 장치는, (i) 순차적으 로 배열된, 하나 이상의 제1 학습 단위문으로 이루어진 하나 이상의 제1 학습 단위문 집합을 포함하는 제1 학습 텍스트를 사용하여 제1 뉴럴 네트워크를 학습하는 프로세스 및 (ii) 하나 이상의 제2 학습 단위문으로 이 루어진 하나 이상의 제2 학습 단위문 집합을 사용하여 제2 뉴럴 네트워크를 학습하되, 제2 학습 단위문 집 합 간의 관계 정보를 함께 사용하여 제2 뉴럴 네트워크를 학습하도록 할 수 있다. 여기서 관계 정보는, 제 2 학습 단위문들의 각각의 순서 정보에 대응할 수 있는데, 이를 참조로 하여 제2 학습 텍스트 중 적어도 일부를 뽑았을 때, 가장 앞의 제2 학습 단위문 집합과 가장 뒤의 제2 학습 단위문 집합이 입력되면 그 가운데에 위치한 제2 학습 단위문 집합들이 출력될 수 있도록 제2 뉴럴 네트워크가 학습되게 하기 위해 사용되는 것이다. 이상 설명된 본 발명에 따른 실시예들은 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로 그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능 한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프 트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하 드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM, DVD와 같은 광기록 매체, 플롭티컬 디스 크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프 로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에는, 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처리를 수행하기 위해 하나 이상 의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서 본 발명이 구체적인 구성요소 등과 같은 특정 사항들과 한정된 실시예 및 도면에 의해 설명되었으나, 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명이 상기 실시예들에 한정되는 것은"}
{"patent_id": "10-2019-0177172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "아니며, 본 발명이 속하는 기술분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형 을 꾀할 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등하게 또는 등가적으로 변형된 모든 것들은 본 발명의 사상의 범주에 속한다고 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2019-0177172", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하는 컴퓨팅 장치의 구성을 나타낸 도면이다. 도 2는 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 나타낸 흐름도이다. 도 3은 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 제1 뉴럴 네트워크의 구성의 일 예시를 나타낸 도면이다. 도 4는 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 제1 뉴럴 네트워크가 제1 어텐션 스코어를 생성하는 과정의 일 예시를 나타낸 도면이다. 도 5는 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 구조 텍스트 선택 과정의 일 예시를 나타낸 도면이다. 도 6은 본 발명의 일 실시예에 따른 휴먼 인터랙티브 인공지능을 사용한 반자동 작문 방법을 수행하기 위해 사 용되는 제2 뉴럴 네트워크가 제2 어텐션 스코어를 생성하는 과정의 일 예시를 나타낸 도면이다."}
