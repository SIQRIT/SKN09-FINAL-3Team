{"patent_id": "10-2022-0014969", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0121182", "출원번호": "10-2022-0014969", "발명의 명칭": "문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법 및 시스템", "출원인": "주식회사 바이칼에이아이", "발명자": "이헌복"}}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터에 의해 수행되는 방법에 있어서,평가 대상인 문서에 대한 피험자의 발화 데이터를 수신하는 단계;상기 피험자의 발화 데이터를 전사하는 단계;상기 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅을 수행하는 단계;상기 태깅된 비유창성 특징 및 각 단어에 대하여 토큰화하는 단계;상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행하는 단계; 및상기 임베딩된 발화 데이터를 미리 학습된 예측 모델에 입력하여 인지장애에 영향을 주는 파라미터에 상응하는예측 결과값을 출력하는 단계를 포함하는,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅을 수행하는 단계는,상기 전사된 발화 데이터 중 소정의 시간 동안 침묵하는 주저 행위 특징, 의미 전달과 관계없는 중모음, 낱말,구가 발화에 포함되는 삽입 행위 특징, 발화 시 전달 내용, 문법 형태나 낱말의 발음을 바꾸어 말하는 수정 행위 특징, 낱말이나 발화가 완성되지 않고 종료되는 미완성 행위 특징, 복수의 완성된 낱말이 반복되는 구반복특징, 낱말 전체가 반복되는 단어반복 특징, 음절이 반복되는 음절반복 특징, 한 음소나 이중 모음의 일부만이반복되는 소리반복 특징, 음운 또는 모음의 한 요소가 길게 지속되는 연장 행위 특징, 및 음운을 시작하거나 파열음 발화시 생기는 시간차로 인해 소리가 중단되는 막힘 행위 특징 중 적어도 하나를 포함하는 비유창성 특징에 대한 태깅을 수행하는 것인,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 태깅된 비유창성 특징 및 각 단어에 대하여 토큰화하는 단계는,상기 태깅된 비유창성 특징에 상응하는 태그 부분 및 내용 부분 중 내용 부분을 삭제시키는 단계; 및상기 내용 부분이 삭제된 비유창성 특징 및 각 단어에 대하여 토큰화를 수행하는 단계를 포함하는,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행하는 단계는,공개특허 10-2022-0121182-3-상기 토큰화된 발화 데이터를 구성하는 모든 단어를 벡터화하는 단어 임베딩을 수행하는 단계; 및상기 단어 임베딩 결과에 대하여 상기 문서의 특징 정보를 나타내는 벡터를 추가하는 문서 임베딩을 수행하는단계를 포함하는,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행하는 단계는,상기 토큰화된 발화 데이터를 구성하는 토큰 중 상기 미리 학습된 예측 모델에서 학습되지 않은 새로운 토큰이존재하는 경우 상기 임베딩을 수행하는 것인,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 새로운 토큰을 기반으로 수행한 임베딩 결과에 기초하여 상기 예측 모델을 업데이트하는 단계를 더 포함하는,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 예측 모델의 학습을 위한 학습 데이터를 예측 모델의 입력단에 입력되도록 설정하는 단계;상기 인지장애에 영향을 주는 파라미터에 상응하는 미리 설정된 예측 결과값을 상기 예측 모델의 출력단으로 출력되도록 설정하는 단계; 및 상기 입력단 및 출력단이 설정된 예측 모델을 학습시키는 단계를 더 포함하고,상기 학습 데이터는 소정의 발화 데이터를 대상으로 전사하고, 전사된 발화 데이터 중 소정의 비유창성 특징에대한 태깅이 수행된 후, 상기 태깅된 발화 데이터가 토큰화 및 임베딩화되어 구성되는 것인,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 학습 데이터는 상기 태깅된 비유창성 특징에 상응하는 태그 부분 및 내용 부분 중 내용 부분이 삭제된 후토큰화되는 것인,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 학습 데이터는 상기 토큰화된 학습 데이터를 구성하는 모든 단어를 벡터화하는 단어 임베딩 및 상기 단어공개특허 10-2022-0121182-4-임베딩이 수행된 결과에 대하여 상기 학습 데이터를 구성하는 문서의 특징 정보를 나타내는 벡터를 추가하는 문서 임베딩이 수행되어 벡터화되는 것인,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법."}
{"patent_id": "10-2022-0014969", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 시스템에 있어서,평가 대상 문서에 대한 피험자의 발화 데이터를 수신하는 통신모듈,상기 발화 데이터를 기반으로 미리 학습된 예측 모델을 통해 인지장애에 영향을 주는 파라미터에 상응하는 예측결과값을 출력하기 위한 프로그램이 저장된 메모리 및상기 메모리에 저장된 프로그램을 실행시키는 프로세서를 포함하되,상기 프로세서는 상기 메모리에 저장된 프로그램을 실행시킴에 따라, 상기 피험자의 발화 데이터를 전사하고,상기 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅을 수행하고, 상기 태깅된 비유창성 특징 및 각단어에 대한 토큰화를 수행하고, 상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행한후, 상기 임베딩된 발화 데이터를 상기 예측 모델에 입력하여 예측 결과값을 출력하는 것인,문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 시스템."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법이 제공된다. 상기 방법은 평가 대상인 문서에 대한 피험자의 발화 데이터를 수신하는 단계; 상기 피험자의 발화 데이터를 전사하는 단계; 상기 전사된 발화 데 이터 중 소정의 비유창성 특징에 대한 태깅을 수행하는 단계; 상기 태깅된 비유창성 특징 및 각 단어에 대하여 토큰화하는 단계; 상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행하는 단계; 및 상기 임베딩된 발화 데이터를 미리 학습된 예측 모델에 입력하여 인지장애에 영향을 주는 파라미터에 상응하는 예측 결과값을 출력하는 단계를 포함한다."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인지장애는 기억력, 언어능력, 시공간 분석 및 구성 능력, 주의 집중력, 판단력, 추리력 등 두뇌에서 이루어지 는 지적능력에 이상이 발생하는 것을 말한다. 인지장애의 원인으로는 뇌의 물리적 손상부터 노인성 치매질환, 감염성 질환, 뇌종양, 우울증 등 수십가지에 이르는 등 매우 다양한다. 이러한 인지장애는 일단 발생하게 되면 일상생활과 사회생활에 큰 부정적인 영향을 미치게 된다. 인지장애를 진단하기에 앞서 인지장애를 예측할 수 있는 간단한 수단으로는 MMSE(Mini-Mental State Examination), BNT(Boston Naming Test) 등이 있다. 이는 전문 의료기기나 시간, 비용을 들여 인지장애를 진단 하기 전에 간편한 방법을 통해 장애 여부를 예측할 수 있도록 하여 인지장애 진단의 문턱을 낮추도록 한다. 이러한 예측이 자주 쉽게 실시되어 조기 진단으로 이어지게 되면 치매와 같은 더 큰 후속 질병을 조기에 발견하 고, 치료 등 적절한 조치를 신속하 취할 수 있도록 하는 중요한 역할을 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2019-0021896호 (2019.03.06)"}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 자연 발화된 내용의 비유창성 특징들을 문서 분류 모델 기법으로 모델링하고, 이를 기반으로 발화 내용에 대한 인지장애에 영향을 줄 수 있는 파라미터에 대한 예측값을 도출할 수 있는, 문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법 및 시스템을 제공하는 것이다. 다만, 본 발명이 해결하고자 하는 과제는 상기된 바와 같은 과제로 한정되지 않으며, 또다른 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 제1 측면에 따른 문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장 애 예측 방법은 평가 대상인 문서에 대한 피험자의 발화 데이터를 수신하는 단계; 상기 피험자의 발화 데이터를 전사하는 단계; 상기 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅을 수행하는 단계; 상기 태깅된 비유창성 특징 및 각 단어에 대하여 토큰화하는 단계; 상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기 반의 임베딩을 수행하는 단계; 및 상기 임베딩된 발화 데이터를 미리 학습된 예측 모델에 입력하여 인지장애에 영향을 주는 파라미터에 상응하는 예측 결과값을 출력하는 단계를 포함한다. 본 발명의 일부 실시예에서, 상기 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅을 수행하는 단계는, 상기 전사된 발화 데이터 중 소정의 시간 동안 침묵하는 주저 행위 특징, 의미 전달과 관계없는 중모음, 낱말, 구가 발화에 포함되는 삽입 행위 특징, 발화 시 전달 내용, 문법 형태나 낱말의 발음을 바꾸어 말하는 수정 행위 특징, 낱말이나 발화가 완성되지 않고 종료되는 미완성 행위 특징, 복수의 완성된 낱말이 반 복되는 구반복 특징, 낱말 전체가 반복되는 단어반복 특징, 음절이 반복되는 음절반복 특징, 한 음소나 이중 모 음의 일부만이 반복되는 소리반복 특징, 음운 또는 모음의 한 요소가 길게 지속되는 연장 행위 특징, 및 음운을 시작하거나 파열음 발화시 생기는 시간차로 인해 소리가 중단되는 막힘 행위 특징 중 적어도 하나를 포함하는 비유창성 특징에 대한 태깅을 수행할 수 있다. 본 발명의 일부 실시예에서, 상기 태깅된 비유창성 특징 및 각 단어에 대하여 토큰화하는 단계는, 상기 태깅된 비유창성 특징에 상응하는 태그 부분 및 내용 부분 중 내용 부분을 삭제시키는 단계; 및 상기 내용 부분이 삭제 된 비유창성 특징 및 각 단어에 대하여 토큰화를 수행하는 단계를 포함할 수 있다. 본 발명의 일부 실시예에서, 상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행하는 단 계는, 상기 토큰화된 발화 데이터를 구성하는 모든 단어를 벡터화하는 단어 임베딩을 수행하는 단계; 및 상기 단어 임베딩 결과에 대하여 상기 문서의 특징 정보를 나타내는 벡터를 추가하는 문서 임베딩을 수행하는 단계를 포함할 수 있다. 본 발명의 일부 실시예에서, 상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행하는 단 계는, 상기 토큰화된 발화 데이터를 구성하는 토큰 중 상기 미리 학습된 예측 모델에서 학습되지 않은 새로운 토큰이 존재하는 경우 상기 임베딩을 수행할 수 있다. 본 발명의 일부 실시예는, 상기 새로운 토큰을 기반으로 수행한 임베딩 결과에 기초하여 상기 예측 모델을 업데 이트하는 단계를 더 포함할 수 있다. 본 발명의 일부 실시예는, 상기 예측 모델의 학습을 위한 학습 데이터를 예측 모델의 입력단에 입력되도록 설정 하는 단계; 상기 인지장애에 영향을 주는 파라미터에 상응하는 미리 설정된 예측 결과값을 상기 예측 모델의 출 력단으로 출력되도록 설정하는 단계; 및 상기 입력단 및 출력단이 설정된 예측 모델을 학습시키는 단계를 더 포 함하고, 상기 학습 데이터는 소정의 발화 데이터를 대상으로 전사하고, 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅이 수행된 후, 상기 태깅된 발화 데이터가 토큰화 및 임베딩화되어 구성될 수 있다. 본 발명의 일부 실시예에서, 상기 학습 데이터는 상기 태깅된 비유창성 특징에 상응하는 태그 부분 및 내용 부 분 중 내용 부분이 삭제된 후 토큰화될 수 있다. 본 발명의 일부 실시예에서, 상기 학습 데이터는 상기 토큰화된 학습 데이터를 구성하는 모든 단어를 벡터화하 는 단어 임베딩 및 상기 단어 임베딩이 수행된 결과에 대하여 상기 학습 데이터를 구성하는 문서의 특징 정보를 나타내는 벡터를 추가하는 문서 임베딩이 수행되어 벡터화될 수 있다. 또한, 본 발명의 제2 측면에 따른 문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 시스템은 평가 대상 문서에 대한 피험자의 발화 데이터를 수신하는 통신모듈, 상기 발화 데이터를 기반으로 미리 학습된 예측 모델을 통해 인지장애에 영향을 주는 파라미터에 상응하는 예측 결과값을 출력하기 위한 프로그램이 저장된 메 모리 및 상기 메모리에 저장된 프로그램을 실행시키는 프로세서를 포함한다. 이때, 상기 프로세서는 상기 메모 리에 저장된 프로그램을 실행시킴에 따라, 상기 피험자의 발화 데이터를 전사하고, 상기 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅을 수행하고, 상기 태깅된 비유창성 특징 및 각 단어에 대한 토큰화를 수행하 고, 상기 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행한 후, 상기 임베딩된 발화 데이 터를 상기 예측 모델에 입력하여 예측 결과값을 출력한다.상술한 과제를 해결하기 위한 본 발명의 다른 면에 따른 컴퓨터 프로그램은, 하드웨어인 컴퓨터와 결합되어 상 기 문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법을 위한 프로그램을 실행하며, 컴퓨터 판 독가능 기록매체에 저장된다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 본 발명에 의하면, 비유창성 특징들에 대한 태깅, 토큰화 및 임베딩 과정을 통해 예측 모델을 학습 및 적용함으로써, 인지장애에 영향을 줄 수 있는 파라미터에 대한 예측 결과값을 정확하게 도출할 수 있는 장점이 있다."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 발명은 문서 분류 모델 기법 및 유창성 태깅에 기반한 인지장애 예측 방법 및 시스템에 관한 것이다. 인지장애를 간편하고 조속히 예측할 수 있는 예측 수단을 더욱 단순화, 자동화하기 위해, 자연발화를 음성, 언 어 분석하여 실시간 또는 그에 가깝게 예측하는 모델들이 지속적으로 연구되어 오고 있다. 본 발명의 일 실시예는 이러한 예측 수단의 일환으로 자연발화를 전사한 내용과 그 내용의 비유창성 특징들을 NLP(Natural Language Processing)의 문서 분류 모델 기법으로 모델링하고, 이를 이용한 예측 모델을 제시한다. 이러한 본 발명은 인지장애를 진단하는 것이 아니고, 인지장애에 영향을 줄 수 있는 적어도 하나의 파라미터에 대한 예측값을 도출하는 것을 특징으로 한다. 이하에서는 도 1 내지 도 4를 참조하여 본 발명의 일 실시예에 따른 문서 분류 모델 기법 및 유창성 태깅에 기 반한 인지장애 예측 방법(이하, 인지장애 예측 방법)에 대하여 설명하도록 한다. 도 1은 본 발명의 일 실시예에 따른 예측 모델을 학습하는 과정을 설명하기 위한 순서도이다. 도 2는 학습 데이 터를 구성하는 내용을 설명하기 위한 순서도이다. 도 3은 비유창성 특징에 대하여 정의된 태그를 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 인지장애 예측 방법의 순서도이다. 한편, 도 1, 도 2 및 도 4에 도시된 각 단계들은 후술하는 도 5의 인지장애 예측 시스템에 의해 수행되는 것으로 이해될 수 있으나, 반드시 이에 한정되는 것은 아니다. 먼저, 도 1 내지 도 3을 참조하여 본 발명에 적용되는 예측 모델을 학습하는 과정을 설명한 후, 도 4를 참조하 여 학습이 완료된 예측 모델을 기반으로 인지장애를 예측하는 과정을 설명하도록 한다. 먼저, 예측 모델의 학습을 위해 준비된 학습 데이터를 예측 모델의 입력단에 입력되도록 설정한다(S110). 이를 위해 소정의 발화 데이터로 구성되는 학습 데이터를 준비한다(S210). 일 실시예로, 본 발명에서의 학습 데이터는 소정의 발화 데이터일 수 있다. 발화 데이터는 피험자와 대상자 간 의 1:1 대화를 통해 획득한 것으로, 피험자와 대상자 간의 대화 중 피험자에 상응하는 발화를 자동 또는 수동으 로 전사한 내용에, 비유창성 특징을 나타내는 태그를 자동 또는 수동으로 추가한 문서이다. 여기에서 대상자는 소정의 사람일 수 있으며, 인공지능 기반의 AI 챗봇일 수도 있다. 이때, 입력되는 학습 데이터는 하나의 문장으로 구성될 수 있으나 일반적으로 복수 개의 문장으로 이루어진 문 단으로 구성되며, 본 발명에서는 이러한 단위를 편의상 문서라 지칭하도록 한다. 또한, 피험자 1인당 1개의 문 서를 하나의 학습 데이터 단위로 하나, 경우에 따라 복수 개로 구분되어 제공될 수도 있다. 피험자와 대상자 간의 대화 내용은 기존 MMSE 과정이나 미리 준비한 일련의 질문에 대한 답변 등, 일관성있는 단어 사용 등을 예측할 수 있는 내용으로 제공되는 것이 바람직하나 반드시 이에 한정되는 것은 아니다. 또한, 언어의 의미적 분석이 가능하기 위해서 학습 데이터는 한 단어 문장이나 의미 없는 추임새는 제거하고 기 록하는 것이 좋을 수 있으나, 반드시 이에 한정되는 것은 아니며 인지장애 예측 목적에 따라 상이하게 구성될 수 있음은 물론이다. 또한, 본 발명의 일 실시예는 전사나 태깅의 방법에 있어 소정의 음성인식 기술을 적용한 자동 전사, 태깅 방법 을 적용할 수도 있고, 수동 전사, 태깅 방법을 적용할 수도 있으나, 효율성을 위해 자동으로 만든 데이터라도 수동으로 정제하여 정확성을 높이는 방법이 추천된다. 한편, 본 발명의 일 실시예는 학습 데이터를 구성하기 위해 발화 데이터가 전사되고 나면(S220), 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅이 수행된다(S230). 예를 들어, 비유창성(disfluency) 특징은 도 3과 같은 유형으로 구분될 수 있으며, 각각 소정의 태그로 구분된 다. 구체적으로, ①주저(Hesitation) 행위 특징은 발화 데이터 중 소정의 시간(예를 들어 1초 또는 그 이상의 시간) 동안 침묵하는 행위로 {H} 태그가 할당된다. ②삽입(Interjection) 행위 특징은 의미 전달과 관계없는 중 모음, 낱말, 구가 발화에 포함되는 행위로 {I} 태그가 할당된다. ③수정(Revision) 행위 특징은 발화 시 전달 내용, 문법 형태나 낱말의 발음을 바꾸어 말하는 행위로 {R} 태그가 할당된다. ④미완성(Unfinished) 행위 특징 은 낱말이나 발화가 완성되지 않고 종료되는 행위로, 보통 수정 행위 특징이 뒤따르며, {U} 태그가 할당된다. ⑤구반복(Phrase repetition) 특징은 복수의 완성된 낱말에서의 반복 행위로 {RP} 태그가 할당된다. ⑥단어반복 (Word repetition) 특징은 낱말 전체의 반복 행위로, 일음절 단어의 반복 행위도 이에 포함되며, {RW} 태그가 할당된다. ⑦음절반복(Syllable repetition) 특징은 소리반복과 낱말반복의 중간으로 음절만 반복하는 행위로 {RL} 태그가 할당된다. ⑧소리반복(Sound repetition) 특징은 한 음소나 이중모음의 일부만이 반복되는 행위로 {RS} 태그가 할당된다. ⑨연장(Prolongation) 행위 특징은 음운 또는 모음의 한 요소가 부적절하게 길게 지속되 는 행위로 {P} 태그가 할당된다. ⑩막힘(Block) 행위 특징은 음운을 시작하거나 파열음 발화시 생기는 부적절한 시간차로 인해 소리가 중단되는 막힘 행위로 {B} 태그가 할당된다. 이때, 막힘 행위 특징의 경우 막힘이 뚜렷이 구분되는 경우 사용되나, 그렇지 않은 경우에는 주저 행위 특징 태그가 사용된다. 전사된 발화 데이터에 대한 태깅이 수행되고 나면, 태깅된 비유창성 특징 및 각 단어에 대하여 토큰화 (Tokenizing)를 수행한다(S240). 앞서 문서는 문장들의 합으로 구성되고, 문장은 복수의 단어로 이루어져 있으므로, 결국 문서는 일정 단어들이 나열된 것이라 할 수 있다. 이때, 문서를 이루는 최소 단위인 단어를 토큰이라 지칭할 수 있다. 토큰이라고 별도로 칭하는 것은 이 단위가 언어에서 말하는 단어의 단위와 일치하지 않을 수도 있고 비언어적 표현이 포함될 수도 있기 때문이다. 일반적으로 하나의 단어는 하나의 토큰으로 볼 수 있으며, 본 발명에서는 비유창성 특징에 상응하는 하나의 태 그도 하나의 특정한 토큰으로 취급된다. 비유창성 특징에 대항 태깅화의 예시는 다음과 같다. - 입력: 나는 그러니깐 어어어제 학교에 갔… - 태깅: 나는 {그러니깐:I} {어어:RL} 어제 학교에 갔{U} - 토큰화: 나+는+{I}+{RL}+어제+학교+에+가+았+{U} 이때, 본 발명의 일 실시예는 태깅된 비유창성 특징에 상응하는 태그 부분 및 내용 부분 중 내용 부분이 삭제시 키고, 내용 부분이 삭제된 비유창성 특징 및 각 단어에 대하여 토큰화를 수행할 수 있다. 위 예시의 경우, 태깅에서 {I}, {RL} 부분은 문장의 의미와 관련이 없는 부분이므로, 내용 부분은 삭제된 후 태 그 부분만 토큰으로 변경된다. 또한, 마지막에 '갔'이 '가+았'이 되는 것은 토큰화에 형태소 분리를 적용한 것 이다. 한편, 본 발명의 일 실시예에서 토큰화를 위한 문장 분할 방법은 다양한 방법이 적용될 수 있으며, 입력의 종류, 크기, 모델의 목적 등에 따라 적절한 방법의 선택 적용이 가능하다. 학습 데이터를 대상으로 비유창성 특징 및 각 단어에 대한 토큰화가 완료되면, 토큰화된 발화 데이터를 대상으 로 단어 및 문서 기반의 임베딩을 수행한다(S250). 이때, 본 발명의 일 실시예는 토큰화된 발화 데이터를 구성하는 모든 단어를 벡터화하는 단어 임베딩과, 단어 임베딩 결과에 대하여 문서의 특징 정보를 나타내는 벡터를 추가하는 문서 임베딩을 수행할 수 있다. 자연어 처리에서 단어 임베딩이란 단어로 이루어진 문장 또는 문서나 그 단어를 컴퓨터가 이해할 수 있는 방법 으로 표현하는 모든 방법을 뜻한다. 가장 유용한 경우는 모든 문서를 구성하는 모든 단어(토큰)들을 적절한 값 을 갖는 벡터로 변환하는 것이다. 단어 임베딩에서의 단어란 문장을 구성하는 기본 단위를 말하는 것으로, 앞서 설명한 토큰과 그 개념이 같다고 볼 수 있다. 이하, 단어, 토큰이라 표현하는 것은 동일한 의미를 갖는 것으로 본다. 임베딩을 수행하기 위해, 기본적으로 각 문서를 구성하는 단어가 의미상의 서로의 위치 관계를 잘 나타내는 일 반적인 방법인 Word2Vec, Doc2Vec 등을 사용할 수 있다. 이때, 본 발명의 일 실시예는 Doc2Vec를 기본으로 적용 하여, Word2Vec에서 문장 및 문서를 구성하는 모든 단어를 벡터로 변환하는 것에 더하여, Doc2Vec를 통해 단어 에 문서를 나타내는 벡터를 추가한 방법을 적용하는 것을 특징으로 한다. 이는 Word2Vec와 같은 방법으로 각 토 큰의 벡터를 변환한 이후, 문서를 나타내는 벡터에 전체 문서에 대한 정보를 부여하는 것이다. Word2Vec의 일 예시는 다음과 같다. 문서: 저 하늘은 푸른 하늘 → 저(w1) + 하늘(w2) + 은(w3) + 푸른(w4) + 하늘(w2) 여기에서 단어(토큰)에 해당하는 w1, w2, w3, w4는 각각 임의의 벡터를 의미한다. 이때, Word2Vec는 입력이 w1, w2, w3, X, w2로 주어질 때, X가 w4가 되는 확률을 높이는 방향으로 각 단어의 값 (벡터)을 변경하면서 학습시키는 과정을 모든 문서의 모든 단어에 대해, 모든 단어가 적절한 벡터값을 가질 때 까지 반복하여 계산하는 과정이다. 이 과정을 거치면 각 단어는 단어들에 의해 형성된 벡터 공간에서 각 문서에 서의 상호 관계와 적합한 위치를 갖도록 되어 의미를 표현하게 된다. Doc2Vec의 일 예시는 다음과 같다. 문서: 저 하늘은 푸른 하늘 → D1 = 저(w1) + 하늘(w2) + 은(w3) + 푸른(w4) + 하늘(w2) + p1 여기에서 w1, w2, w3, w4, p1은 각각 임의의 벡터를 의미한다. Doc2Vec는 문서에 대한 벡터를 하나 추가하여 Word2Vec와 동일한 과정을 통해 모든 벡터를 계산하는 방법이다. 즉, 입력이 w1, w2, w3, X, w2, P1으로 주어질 때 X가 w4가 되는 확률을 높이는 방향으로 학습을 하는 것은 Word2Vec와 같으며, 이 과정에서 문서의 특성을 나타내는 p1이 추가로 정해지게 된다.다시 도 1을 참조하면, 이와 같이 준비된 학습 데이터를 예측 모델의 입력단으로 입력되도록 설정하고(S110), 인지장애에 영향을 주는 파라미터에 상응하는 미리 설정된 예측 결과값을 예측 모델의 출력단으로 출력되도록 설정한다(S120). 즉, 학습데이터의 모든 문서의 임베딩을 입력값 X로 하고, 인지장애 여부, 중증도, MMSE 점수 등과 같은 인지장 애에 영향을 주는 파라미터에 상응하는 미리 설정된 예측 결과값을 각각 Y로 설정하여 예측 모델을 학습한다. 예측 모델은 예측 결과값 설정에 따라 이진, 다항 분류 모델이 될 수도 있고 선형 회귀 모델이 될 수도 있다. 한편, 예측 모델을 생성하는 방법은 SVM이나 DNN 등 기존 머신러닝 방법을 적용할 수도 있으며, 입력 데이터의 규모 특성에 따라 적절히 선택 가능하다. 예측 모델의 예측 결과값은 입력 데이터와 동일한 형태를 가지며, 마찬가지로 전사, 태깅 과정을 거쳐 원본 데 이터로 제공될 수 있다. 이와 같이, 입력단 및 출력단이 설정되고 나면 예측 모델을 학습시킨다(S130). 만약, 기 형성된 모델의 크기가 충분히 클 경우, 예측 결과값의 토큰은 이미 임베딩 결과에 포함되어 있어 거의 그대로 높은 정확성을 갖는 예측 결과값이 될 수 있다. 하지만, 모델의 크기가 상당히 크더라도 새로운 토큰이 존재하는 경우에는 임베딩만 새로 하고 빠른 예측을 수행한 후, 변경된 임베딩 결과에 기초하여 예측 모델을 업 데이트하는 방법도 사용할 수 있다. 이하에서는 도 4를 참조하여 학습된 예측 모델을 기반으로 피험자의 발화 데이터에 대한 인지장애를 예측화는 과정을 설명하도록 한다. 이때, 도 1 내지 도 3에서의 예측 모델 학습 과정에서 설명한 내용과 중복되는 내용은 생략하도록 한다. 먼저, 평가 대상인 문서에 대한 피험자의 발화 데이터를 수신한다(S310). 다음으로, 피험자의 발화 데이터를 전사하고(S320), 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅 을 수행한다(S330). 이때, 본 발명의 일 실시예에 적용되는 태깅 중 비유창성 특징에 상응하는 태깅은 도 3에서 설명한 바와 같이 주저 행위 특징, 삽입 행위 특징, 수정 행위 특징, 미완성 행위 특징, 단어반복 특징, 음절반복 특징, 소리반복 특징, 연장 행위 특징, 막힘 행위 특징 중 적어도 하나의 비유창성 특징에 대하여 태깅을 수행할 수 있다. 다음으로, 태깅된 비유창성 특징 및 각 단어에 대하여 토큰화를 수행하고(S340), 토큰화된 발화 데이터를 대상 으로 단어 및 문서 기반의 임베딩을 수행한다(S350). 일 실시예로, 토큰화는 태깅된 비유창성 특징에 상응하는 태그 부분 및 내용 부분 중 내용 부분을 삭제시킨 후, 내용 부분이 삭제된 비유창성 특징 및 각 단어에 대한 토큰화를 수행하는 것일 수 있다. 이와 같이 토큰화된 발화 데이터를 구성하는 모든 단어를 벡터화하는 단어 임베딩을 수행하고, 단어 임베딩 결 과에 대하여 문서의 특징 정보를 나타내는 벡터를 추가하는 문서 임베딩을 수행하게 된다. 한편, 임베딩 과정의 경우 토큰화된 발화 데이터를 구성하는 토큰 중 미리 학습된 예측 모델에서 학습되지 않은 새로운 토큰이 존재하는 경우에 수행될 수 있다. 그리고 새로운 토큰을 기반으로 수행한 임베딩 결과에 기초하 여 예측 모델을 업데이트할 수 있다. 즉, 학습된 모델의 크기가 상당히 큰 경우에는 새로운 토큰이 있는 경우 임베딩만 새로 하고 빠른 예측을 수행 한 후, 변경된 임베딩으로 모델을 업데이트하는 방법도 사용할 수 있다. 다음으로, 임베딩된 발화 데이터를 미리 학습된 예측 모델에 입력하여 인지장애에 영향을 주는 파라미터에 상응 하는 예측 결과값을 출력한다(S360). 한편, 예측 모델이 충분히 많은 데이터로 학습되어 있거나 새로운 토큰이 적은 경우에는, 기존의 학습된 모델로 우선 예측 결과값을 제공할 수도 있으며, 차후 임베딩과 모델을 갱신하여 정확한 예측값을 도출하는 방법도 적 용할 수 있다. 한편, 상술한 설명에서, 단계 S110 내지 S360은 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 한편, 기타 생략된 내용이라 하더라도 도 1 내지 도 4의 내용은 도 5의 인지장애 예측 시스템 에도 적용된다.도 5는 본 발명의 일 실시예에 따른 인지장애 예측 시스템의 블록도이다. 본 발명의 일 실시예에 따른 인지장애 예측 방법은 통신모듈, 메모리 및 프로세서를 포함한다. 통신모듈은 평가 대상 문서에 대한 피험자의 발화 데이터를 수신한다. 이와 같은 통신 모듈은 유선 통신 모듈 및 무선 통신 모듈을 모두 포함할 수 있다. 유선 통신 모듈은 전력선 통신 장치, 전화선 통신 장치, 케이블 홈(MoCA), 이더넷(Ethernet), IEEE1294, 통합 유선 홈 네트워크 및 RS-485 제어 장치로 구현될 수 있다. 또한, 무선 통신 모듈은 WLAN(wireless LAN), Bluetooth, HDR WPAN, UWB, ZigBee, Impulse Radio, 60GHz WPAN, Binary-CDMA, 무선 USB 기술 및 무선 HDMI 기술 등으로 구현될 수 있다. 메모리에는 발화 데이터를 기반으로 미리 학습된 예측 모델을 통해 인지장애에 영향을 주는 파라미터에 상 응하는 예측 결과값을 출력하기 위한 프로그램이 저장된다. 여기에서, 메모리는 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 비휘발성 저장장치 및 휘발성 저장장치를 통칭하는 것이다. 예를 들어, 메모리는 콤팩트 플래시(compact flash; CF) 카드, SD(secure digital) 카드, 메모리 스틱 (memory stick), 솔리드 스테이트 드라이브(solid-state drive; SSD) 및 마이크로(micro) SD 카드 등과 같은 낸드 플래시 메모리(NAND flash memory), 하드 디스크 드라이브(hard disk drive; HDD) 등과 같은 마그네틱 컴 퓨터 기억 장치 및 CD-ROM, DVD-ROM 등과 같은 광학 디스크 드라이브(optical disc drive) 등을 포함할 수 있 다. 또한, 메모리에 저장된 프로그램은 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)와 같은 하드웨어 형태로 구현될 수 있으며, 소정의 역할들을 수행할 수 있다. 프로세서는 메모리에 저장된 프로그램을 실행시킨다. 구체적으로, 프로세서는 피험자의 발화 데 이터를 전사하고, 전사된 발화 데이터 중 소정의 비유창성 특징에 대한 태깅을 수행하고, 태깅된 비유창성 특징 및 각 단어에 대한 토큰화를 수행하고, 토큰화된 발화 데이터를 대상으로 단어 및 문서 기반의 임베딩을 수행한 후, 임베딩된 발화 데이터를 상기 예측 모델에 입력하여 예측 결과값을 출력한다. 이상에서 전술한 본 발명의 일 실시예는, 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 어플리케 이션)으로 구현되어 매체에 저장될 수 있다. 상기 전술한 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, Ruby, 기계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하 는 필요한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들 을 상기 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있 다. 또한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하 는지 등에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다."}
{"patent_id": "10-2022-0014969", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2022-0014969", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 예측 모델을 학습하는 과정을 설명하기 위한 순서도이다. 도 2는 학습 데이터를 구성하는 내용을 설명하기 위한 순서도이다. 도 3은 비유창성 특징에 대하여 정의된 태그를 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 인지장애 예측 방법의 순서도이다. 도 5는 본 발명의 일 실시예에 따른 인지장애 예측 시스템의 블록도이다."}
