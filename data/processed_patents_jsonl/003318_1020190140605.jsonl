{"patent_id": "10-2019-0140605", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0054678", "출원번호": "10-2019-0140605", "발명의 명칭": "전처리 모듈을 포함하는 머신 러닝 기반의 인공지능을 이용하는 영상 분석 장치", "출원인": "한국과학기술연구원", "발명자": "최기환"}}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "머신 러닝 기반의 인공지능을 이용하는 영상 전처리 장치로서, 상기 영상 전처리 장치는 컴퓨팅 시스템을 포함하며, 상기 컴퓨팅 시스템은프로세서;입력 영상을 수신하는 통신 모듈; 및상기 입력 영상에 대한 추론을 통하여 제1 전처리 조건 및 제2 전처리 조건을 생성하는 인공 신경망; 을 포함하고,상기 프로세서는상기 입력 영상에 대하여 상기 제1 전처리 조건을 적용하여 상기 제1 전처리 영상을 생성하는 제1 전처리 모듈;및상기 입력 영상에 대하여 상기 제2 전처리 조건을 적용하여 상기 제2 전처리 영상을 생성하는 제2 전처리 모듈;을 포함하고,상기 프로세서는 상기 제1 전처리 영상 및 상기 제2 전처리 영상에 기반하여 상기 입력 영상에 대한 영상 분석을 수행하는 영상 분석 모듈에 상기 제1 전처리 영상 및 상기 제2 전처리 영상이 전달되도록 상기 제1 전처리모듈, 상기 제2 전처리 모듈, 상기 인공 신경망, 및 상기 통신 모듈을 제어하는 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는 상기 인공 신경망 및 상기 영상 분석 모듈이 함께 훈련용 입력 영상 및 상기 훈련용 입력 영상에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 상기 영상 분석 모듈의 목적 함수 출력의 피드백 및 상기 훈련용 입력 영상을 상기 인공 신경망에 전달하고, 상기 인공 신경망이 상기 영상 분석 모듈과 함께 훈련하도록 상기 인공 신경망 및 상기 영상 분석 모듈을 제어하는 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 컴퓨팅 시스템은 상기 영상 분석 모듈;을 더 포함하는 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 통신 모듈은 상기 컴퓨팅 시스템 외부의 상기 영상 분석 모듈에 상기 제1 전처리 영상 및 상기 제2 전처리영상을 전송하고, 상기 통신 모듈은 상기 인공 신경망 및 상기 영상 분석 모듈이 함께 훈련용 입력 영상 및 상기 훈련용 입력 영상에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 상기 훈련용 입력 영상 및 상기 영상 분석 모듈의목적 함수 출력을 피드백받아 상기 인공 신경망에 전달하고, 공개특허 10-2021-0054678-3-상기 프로세서는 상기 인공 신경망이 상기 영상 분석 모듈과 함께 훈련하도록 상기 인공 신경망을 제어하고, 상기 통신 모듈을 경유하여 상기 영상 분석 모듈을 제어하는 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제1 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제1 윈도우 레벨이고,상기 제2 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제2 윈도우 레벨인 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 입력 영상은 X선 촬영 영상(X-ray), 컴퓨터 단층촬영 영상(CT), 자기 공명 영상(MRI), 초음파 영상, 양전자 방출 단층촬영영상(PET, Positron Emission Tomography), 및 단일 광자 방출 컴퓨터 단층촬영(SPECT, Single PhotonEmission CT) 중 적어도 하나 이상을 포함하는 모달리티에 의하여 획득되는 영상인 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 영상 분석 모듈은 상기 입력 영상에 대한 영상 분할(segmentation), 객체 검출(object detection), 진단(diagnosis), 정량화(quantification), 및 영상 분석(image analysis) 중 적어도 하나 이상을 포함하는 태스크(Task)를 수행하는모듈인 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 인공 신경망은 상기 입력 영상에 대한 추론을 통하여 제3 전처리 조건을 생성하고,상기 프로세서는 상기 입력 영상에 대하여 상기 제3 전처리 조건을 적용하여 제3 전처리 영상을 생성하는 제3 전처리 모듈;을 더 포함하고,상기 프로세서는 상기 영상 분석 모듈에 상기 제1 전처리 영상, 상기 제2 전처리 영상, 및 상기 제3 전처리 영상이 전달되도록상기 제1 전처리 모듈, 상기 제2 전처리 모듈, 상기 제3 전처리 모듈, 상기 인공 신경망, 및 상기 통신 모듈을제어하는 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제1 전처리 모듈과 상기 제2 전처리 모듈은 상호 독립적으로 동작하는, 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는 상기 제1 전처리 조건, 및 상기 제2 전처리 조건을 상기 입력 영상, 상기 제1 전처리 영상, 상기 제2 전처리 영상, 상기 영상 분석 모듈, 및 상기 입력 영상에 대한 상기 영상 분석 모듈의 분석 결과 중 적어도 하나 이상에공개특허 10-2021-0054678-4-대한 설명적 정보로서 사용자에게 제공하는 영상 전처리 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "머신 러닝 기반의 인공지능을 이용하는 영상 분석 지원 장치로서, 상기 영상 분석 지원 장치는 컴퓨팅 시스템을포함하며, 상기 컴퓨팅 시스템은프로세서;입력 영상을 수신하는 통신 모듈; 및상기 입력 영상에 대한 추론을 통하여 제1 전처리 조건 및 제2 전처리 조건을 생성하는 인공 신경망; 을 포함하고,상기 프로세서는 상기 입력 영상에 대하여 상기 제1 전처리 조건을 적용하여 상기 제1 전처리 영상을 생성하는제1 전처리 모듈에 상기 제1 전처리 조건이 전달되고, 상기 입력 영상에 대하여 상기 제2 전처리 조건을 적용하여 상기 제2 전처리 영상을 생성하는 제2 전처리 모듈에 상기 제2 전처리 조건이 전달되도록 상기 인공 신경망,및 상기 통신 모듈을 제어하고, 상기 프로세서는 상기 제1 전처리 영상 및 상기 제2 전처리 영상에 기반하여 상기 입력 영상에 대한 영상 분석을 수행하는 영상 분석 모듈에 상기 제1 전처리 영상 및 상기 제2 전처리 영상이 전달되도록 상기 통신 모듈을경유하여 상기 제1 전처리 모듈, 상기 제2 전처리 모듈, 및 상기 영상 분석 모듈을 제어하는 영상 분석 지원 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는 상기 인공 신경망 및 상기 영상 분석 모듈이 함께 훈련용 입력 영상 및 상기 훈련용 입력 영상에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 상기 영상 분석 모듈의 목적 함수 출력의 피드백 및 상기 훈련용 입력 영상을 상기 인공 신경망에 전달하고, 상기 인공 신경망이 상기 영상 분석 모듈과 함께 훈련하도록 상기 인공 신경망 및 상기 영상 분석 모듈을 제어하는 영상 분석 지원 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 제1 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제1 윈도우 레벨이고,상기 제2 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제2 윈도우 레벨인 영상 분석 지원 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 프로세서는 상기 제1 전처리 조건, 및 상기 제2 전처리 조건을 상기 입력 영상, 상기 제1 전처리 영상, 상기 제2 전처리 영상, 상기 영상 분석 모듈, 및 상기 입력 영상에 대한 상기 영상 분석 모듈의 분석 결과 중 적어도 하나 이상에대한 설명적 정보로서 사용자에게 제공하는 영상 분석 지원 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "머신 러닝 기반의 인공지능을 이용하는 영상 분석 장치로서, 상기 영상 분석 장치는 컴퓨팅 시스템을 포함하며,상기 컴퓨팅 시스템은프로세서;공개특허 10-2021-0054678-5-입력 영상을 수신하는 통신 모듈; 상기 입력 영상에 대한 추론을 통하여 제1 전처리 조건 및 제2 전처리 조건을 생성하는 제1 인공 신경망; 및상기 입력 영상에 대한 영상 분석을 수행하여 분석 결과를 생성하는 제2 인공 신경망;을 포함하고,상기 프로세서는상기 입력 영상에 대하여 상기 제1 전처리 조건을 적용하여 상기 제1 전처리 영상을 생성하는 제1 전처리 모듈;및상기 입력 영상에 대하여 상기 제2 전처리 조건을 적용하여 상기 제2 전처리 영상을 생성하는 제2 전처리 모듈;을 포함하고,상기 프로세서는 상기 제2 인공 신경망에 상기 제1 전처리 영상 및 상기 제2 전처리 영상이 전달되고 상기 제2인공 신경망이 상기 제1 전처리 영상 및 상기 제2 전처리 영상에 기반하여 상기 입력 영상에 대한 상기 분석 결과를 생성하도록 상기 제1 전처리 모듈, 상기 제2 전처리 모듈, 상기 제1 인공 신경망, 상기 제2 인공 신경망,및 상기 통신 모듈을 제어하는 영상 분석 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는 상기 제1 인공 신경망 및 상기 제2 인공 신경망이 함께 훈련용 입력 영상 및 상기 훈련용 입력 영상에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 상기 제2 인공 신경망의 목적 함수 출력의 피드백 및 상기 훈련용 입력 영상을 상기 제1 인공 신경망에 전달하고, 상기 제1 인공 신경망이 상기 제2 인공 신경망과 함께 훈련하도록 상기 제1 인공 신경망 및 상기 제2 인공 신경망을 제어하는 영상 분석 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 제1 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제1 윈도우 레벨이고,상기 제2 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제2 윈도우 레벨인 영상 분석 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,상기 제2 인공 신경망은 상기 입력 영상에 대한 영상 분할(segmentation), 객체 검출(object detection), 진단(diagnosis), 정량화(quantification), 및 영상 분석(image analysis) 중 적어도 하나 이상을 포함하는 태스크(Task)를 수행하는인공 신경망인 영상 분석 장치."}
{"patent_id": "10-2019-0140605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서,상기 프로세서는 상기 제1 전처리 조건, 및 상기 제2 전처리 조건을 상기 입력 영상, 상기 제1 전처리 영상, 상기 제2 전처리 영상, 상기 입력 영상에 대한 상기 제2 인공 신경망의 상기 분석 결과 중 적어도 하나 이상에 대한 설명적 정보로서 사용자에게 제공하는 영상 분석 장치.공개특허 10-2021-0054678-6-"}
{"patent_id": "10-2019-0140605", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "머신 러닝 기반의 인공지능을 이용하는 영상 분석 장치가 개시된다. 상기 영상 분석 장치는 컴퓨팅 시스템을 포 함하며 상기 컴퓨팅 시스템은 프로세서를 포함하고, 상기 컴퓨팅 시스템은 프로세서; 입력 영상을 수신하는 통신 모듈; 및 상기 입력 영상에 대한 추론을 통하여 제1 전처리 조건 및 제2 전처리 조건을 생성하는 인공 신경망을 (뒷면에 계속)"}
{"patent_id": "10-2019-0140605", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 머신 러닝 기반의 인공지능을 이용하는 영상 분석 기법에 관한 것이다. 구체적으로는 머신 러닝 기반 의 인공지능을 이용한 학습 과정에서 종래 기술보다 개선된 학습 기법 및 네트워크를 적용한 영상 분석 기법 및 그 방법이 적용되는 컴퓨팅 시스템을 포함하는 영상 분석 장치에 관한 것이다."}
{"patent_id": "10-2019-0140605", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상의 분할(segmentation)에 기반하여 관심 영역(ROI, Region of Interest)을 검출하는 기술은 영상 처리에서 다양한 용도로 활용된다. 의료 영상에서는 영상의 밝기 값 또는 강도 값(intensity)에 기반하여 영상을 분할하 며, 분할되는 대상은 인체의 장기(organ), 병변(lesion)일 수 있다. 최근 정밀한 의료 진단 목적으로 실행되는 컴퓨터 단층촬영(CT, Computed Tomography)의 결과로 얻어지는 CT 영 상에 대한 영상 분할을 최적화하려는 시도가 다수 존재한다. CT 영상은 CT 넘버로 표현될 수 있다. CT 넘버는 Hounsfield unit(HU)이라고도 부르며, 방사선 투과성을 나타내 는 수치이다. CT 넘버는 예를 들면 -1024~3071 범위의 정수로 나타낼 수 있으며, 12비트 영상 데이터로 표현될 수 있다. CT 영상은 CT 넘버를 이용하여 흑백 영상으로 표현되거나, 제한된 칼라 성분으로 표현되는 경우가 많 다. 따라서 정확한 진단을 위해서는, 영상을 넓은 계조 범위로 표현해야 하는데, 표시부에서 표현 가능한 계조 수가, CT 영상 데이터의 CT 넘버의 수보다 적은 경우가 있어, CT 영상 데이터의 표시에 어려움이 있다. 또한 의료 영상을 통하여 병변을 진단하고자 하는 경우에 CT 넘버의 전체 윈도우 영역이 모두 필요하지 않은 경 우가 일반적이다. 인체 부위(body part), 장기(organ), 및 병변(lesion)에 따라서 분할 및 진단하고자 하는 관 심 영역이 용이하게 구분되기 위한 CT 넘버의 윈도우 영역은 서로 다르게 설정될 수 있다. 의료 현장에서는 CT 영상을 획득하는 목적, 즉, 인체 부위, 장기, 및 병변을 고려하여 각 의료 기관에서 빈번하 게 사용하는 윈도우 레벨을 지정하고 그에 맞추어 CT 영상을 전처리한 후 전처리된 영상이 영상의학과 판독의 (radiologist) 또는 임상의(clinician)에게 전달된다. 이 과정에서 필요한 인력과 시간은 매우 큰 부담이 되고 있다. 이러한 과정을 일부나마 자동화하려는 시도가 한국등록특허 KR 10-1798083 \"단층 영상 처리 장치, 방법, 및 그 방법에 관련된 기록매체\" 및 한국등록특허 KR 10-1971625 \"CT 영상을 처리하는 장치 및 방법\" 등에 소개된다. KR 10-1798083에서는 CT 영상 데이터 내의 관심 지점에 대응하는 화소 영역에서 관심 CT 넘버를 결정하고, 히스 토그램 상에서 기준 값 이상의 빈도 수를 가지는 CT 넘버 범위를 CT 윈도우로서 설정하는데, 하나의 CT 영상에 서 둘 이상의 관심 영역이 존재하는 경우 각각의 관심 영역에 서로 다른 CT 윈도우가 설정될 수 있다. KR 10-1971625에서는 복수의 설정 영역 각각에 대응하는 복수의 CT 영상에서, 각 설정 영역, 영상의 표시 방법 에 기반하여 각각 CT 윈도우의 폭 및 윈도우의 레벨을 설정하고 설정된 폭 및 레벨에 따라 각각 복수의 CT 영상 을 변환하는 구성이 개시된다. 그러나 이러한 선행기술들에 의하더라도 얻어지는 CT 윈도우 레벨 및 그에 의한 전처리는 진단에 매우 불필요한 조직을 배제하는 용도로 이용되는 수준이며, 이러한 수준의 전처리가 최종적으로 임상 진단에 긍정적인 영향을 줄 정도로 최적화되어 있지 않아 부분적 자동화 과정 이후에도 전문가에 의한 수동 작업이 여전히 필요한 상황 이다. 또한 한국등록특허 KR 10-1938992 \"진단 이유 설명이 생성되는 CAD 시스템 및 그 방법\" 에서는 병변 진단에 대 한 근거 정보를 도출하기 위하여 DNN 기반으로 추출된 특징 정보를 연쇄적으로 융합하여 특징 벡터를 생성하는 기술이 소개되었다. 그러나 KR 10-1938992는 인공 신경망이 스스로 특징 정보를 도출할 뿐, 추출된 특징 정보가 임상적으로 유용한 정보인 지에 대한 검증이 전혀 이루어지지 않기 때문에, 인공 신경망의 진단 결과에 대한 설 명으로 인간이 인식할 수 있으리라는 근거가 희박하다. 선행기술문헌 특허문헌(특허문헌 0001) 한국등록특허 KR 10-1798083 \"단층 영상 처리 장치, 방법, 및 그 방법에 관련된 기록매체\" (2017년 11월 9일) (특허문헌 0002) 한국등록특허 KR 10-1971625 \"CT 영상을 처리하는 장치 및 방법\" (2019년 4월 17일) (특허문헌 0003) 한국등록특허 KR 10-1938992 \"진단 이유 설명이 생성되는 CAD 시스템 및 그 방법\" (2019년 1월 9일) 비특허문헌 (비특허문헌 0001) \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\", Mark Sandler, 외, (2019.03.21)"}
{"patent_id": "10-2019-0140605", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "최근 딥러닝 기반의 인공지능 기법을 적용하여 영상 분할에 기반한 영상 분석 기법의 성능을 향상하고자 하는 노력이 계속되고 있다. 그러나 딥러닝 기반 인공지능의 경우, 그 동작으로부터 제공되는 결과물이 우연히 높은 성능을 보이는 것인지, 그 임무(task)에 적절한 판단 과정을 거친 것인 지를 사용자가 알 수 없는 블랙박스 (black-box)라는 점이 활용 가능성을 제한하고 있다. 반면 설명이 용이한 룰-베이스드(rule-based) 방식의 훈련 또는 학습으로는 딥러닝 만큼의 성과가 얻어지지 못 하는 점에서 사용이 제한되고 있다. 따라서 향상된 성능을 가지면서도 설명적 정보(descriptive information, explanation)를 제공할 수 있는 딥러닝 기반 인공지능에 대한 연구가 활발하다. 본 발명의 목적은 자동화된 영상 분석 기법의 성능을 향상하여 인간의 육안으로 판독할 때 놓칠 수 있는 병변에 대한 분할, 검출 및 진단까지도 가능한 영상 분석 기법을 제공하는 것이다. 본 발명의 목적은 의료 전문가에게 영상 분석, 분할, 검출, 및 진단 결과물에 대한 설명적 정보(descriptive information, explanation)로서, 임상적으로 유의미한 정보를 제공할 수 있는 영상 분석 기법을 구현하는 것이다. 한편 영상의 밝기 값에 관한 윈도우 레벨 설정은, 영상의 분할 및 영상의 분석에 영향을 미칠 것으로 기대되나, 종래기술들은 윈도우 레벨 설정이 영상의 분할 및 분석 결과에 미치는 관련성이 파악되지 않는 문제점이 있다. 의료 영상에서, 예를 들어 CT 윈도우 레벨의 경우에는 임상적 진단의 효율성으로 연결되는 관련성에 대한 연구 가 더욱 필요한데, 종래 기술의 CT 윈도우 레벨은 관습적인 룰-베이스드 방식 또는 단순한 딥러닝을 변용하여 자동화 및 모듈화하는 데에만 치중하고 있어 임상적 진단과 연계될 때 효율적인 지 여부를 알 수단이 없는 문제 점이 있다. 본 발명의 목적은 영상의 윈도우 레벨을 전처리하는 과정을 최적화하여 자동화된 전처리 과정의 완성도를 높이 는 것이다. 본 발명의 목적은, 영상 분석 모듈 또는 영상 분석 인공 신경망의 성능을 향상시킬 수 있는 영상 전처리 조건을 제공하는 것이다. 본 발명의 목적은 의료 영상에 대한 자동화된 전처리 과정으로 얻어지는 윈도우 레벨이 임상적으로 진단에 긍정 적인 영향을 줄 정도로 최적화되는 전처리 과정을 제공하는 것이다. 본 발명의 목적은, 영상 분석 모듈 또는 영상 분석 인공 신경망의 성능을 향상시킬 수 있는 전처리된 영상 집합 을 제공하는 것이다. 본 발명의 목적은 학습 과정에서 영상 분석 인공 신경망과 윈도우 레벨 전처리 모듈을 함께 학습하여 인공 신경 망이 수행하는 임무(task)와 관련성이 높은 윈도우 레벨을 도출할 수 있도록 전처리 모듈과 인공 신경망 양쪽의 성능을 향상하는 것이다. 본 발명의 목적은 복수의 전처리 모듈을 상호 독립적으로, 병렬적으로 동작하도록 설계하여 초기값의 지정에 따 른 진단 정확도에 대한 영향, 및 local optimum에 의하여 global optimum을 찾지 못하는 문제점에 대한 robustness를 확보하는 것이다. 본 발명의 목적은 영상 분석 인공 신경망이 내부에서 문제를 해결하는 과정을 외부에서 이해할 수 있는 설명적 정보로서, 영상 분석 인공 신경망이 문제를 해결하기에 적합화된 전처리 조건을 도출하고, 전처리 조건에 기반 하여 영상 분석 인공 신경망이 문제를 해결하는 과정을 적어도 부분적으로 설명하는 것이다. 또한 종래 기술들과 달리 본 발명은 단순히 인공 신경망의 분석 과정에서 도출되는 히트맵 등을 분석하여 설명 적 정보로서 도출하는 데에 그치지 않고, 본 발명의 생성적 인공 신경망의 도출 결과가 인공 신경망의 분석 과 정에 미치는 영향을 관찰할 수 있으며, 이로 인하여 결과에 대한 검증을 거쳐 신뢰할 수 있는 설명적 정보를 생 성하는 것을 목적으로 한다."}
{"patent_id": "10-2019-0140605", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상기의 종래기술의 문제점을 해결하기 위한 수단으로 도출된 것으로서, 본 발명의 일 실시예에 따른 영상 전처리 장치는 머신 러닝 기반의 인공지능을 이용하는 영상 전처리 장치로서, 상기 영상 전처리 장치는 컴 퓨팅 시스템을 포함한다. 상기 컴퓨팅 시스템은 프로세서; 입력 영상을 수신하는 통신 모듈; 및 상기 입력 영상 에 대한 추론을 통하여 제1 전처리 조건 및 제2 전처리 조건을 생성하는 인공 신경망을 포함한다. 상기 프로세 서는 상기 입력 영상에 대하여 상기 제1 전처리 조건을 적용하여 상기 제1 전처리 영상을 생성하는 제1 전처리 모듈; 및 상기 입력 영상에 대하여 상기 제2 전처리 조건을 적용하여 상기 제2 전처리 영상을 생성하는 제2 전 처리 모듈을 포함한다. 상기 프로세서는 상기 제1 전처리 영상 및 상기 제2 전처리 영상에 기반하여 상기 입력 영상에 대한 영상 분석을 수행하는 영상 분석 모듈에 상기 제1 전처리 영상 및 상기 제2 전처리 영상이 전달되 도록 상기 제1 전처리 모듈, 상기 제2 전처리 모듈, 상기 인공 신경망, 및 상기 통신 모듈을 제어한다. 상기 프로세서는 상기 인공 신경망 및 상기 영상 분석 모듈이 함께 훈련용 입력 영상 및 상기 훈련용 입력 영상 에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 상기 영상 분석 모듈의 목적 함수 출력의 피드백 및 상기 훈련용 입력 영상을 상기 인공 신경망에 전달할 수 있고, 상기 인공 신경망이 상기 영상 분석 모듈과 함께 훈련하도록 상기 인공 신경망 및 상기 영상 분석 모듈을 제어할 수 있다. 상기 컴퓨팅 시스템은 상기 영상 분석 모듈을 상기 컴퓨팅 시스템의 내부에 더 포함할 수 있다. 상기 통신 모듈은 상기 컴퓨팅 시스템 외부의 상기 영상 분석 모듈에 상기 제1 전처리 영상 및 상기 제2 전처리 영상을 전송할 수 있다. 상기 통신 모듈은 상기 영상 분석 모듈이 훈련용 입력 영상 및 상기 훈련용 입력 영상 에 대한 분석 결과 간의 관련성에 대하여 훈련하는 동안 상기 훈련용 입력 영상 및 상기 영상 분석 모듈의 목적 함수 출력을 피드백받아 상기 인공 신경망에 전달할 수 있다. 상기 프로세서는 상기 인공 신경망이 상기 영상 분석 모듈이 훈련하는 동안 상기 영상 분석 모듈과 함께 훈련하 도록 상기 인공 신경망을 제어할 수 있다. 상기 제1 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제1 윈도우 레 벨일 수 있다. 상기 제2 전처리 조건은 상기 입력 영상에 대한 밝기 값의 상한과 하한에 대한 정보를 포함하는 제2 윈도우 레벨일 수 있다. 상기 입력 영상은 X선 촬영 영상(X-ray), 컴퓨터 단층촬영 영상(CT), 자기 공명 영상(MRI), 초음파 영상, 양전 자 방출 단층촬영 영상(PET, Positron Emission Tomography), 및 단일 광자 방출 컴퓨터 단층촬영(SPECT, Single Photon Emission CT) 중 적어도 하나 이상을 포함하는 모달리티에 의하여 획득되는 영상일 수 있다. 상기 영상 분석 모듈은 상기 입력 영상에 대한 영상 분할(segmentation), 객체 검출(object detection), 진단 (diagnosis), 정량화(quantification), 및 영상 분석(image analysis) 중 적어도 하나 이상을 포함하는 태스크 (Task)를 수행하는 모듈일 수 있다. 상기 인공 신경망은 상기 입력 영상에 대한 추론을 통하여 제3 전처리 조건을 생성할 수 있다. 이때 상기 프로 세서는 상기 입력 영상에 대하여 상기 제3 전처리 조건을 적용하여 제3 전처리 영상을 생성하는 제3 전처리 모 듈을 더 포함할 수 있다. 상기 프로세서는 상기 영상 분석 모듈에 상기 제1 전처리 영상, 상기 제2 전처리 영상, 및 상기 제3 전처리 영상이 전달되도록 상기 제1 전처리 모듈, 상기 제2 전처리 모듈, 상기 제3 전처리 모듈, 상기 인공 신경망, 및 상기 통신 모듈을 제어할 수 있다. 상기 제1 전처리 모듈과 상기 제2 전처리 모듈은 상호 독립적으로 동작할 수 있다. 상기 프로세서는 상기 제1 전처리 조건, 및 상기 제2 전처리 조건을 상기 입력 영상, 상기 제1 전처리 영상, 상 기 제2 전처리 영상, 상기 영상 분석 모듈, 및 상기 입력 영상에 대한 상기 영상 분석 모듈의 분석 결과 중 적 어도 하나 이상에 대한 설명적 정보로서 사용자에게 제공할 수 있다. 본 발명의 일 실시예에 따른 영상 분석 지원 장치는 머신 러닝 기반의 인공지능을 이용하는 영상 분석 지원 장 치로서, 상기 영상 분석 지원 장치는 컴퓨팅 시스템을 포함한다. 상기 컴퓨팅 시스템은 프로세서; 입력 영상을 수신하는 통신 모듈; 및 상기 입력 영상에 대한 추론을 통하여 제1 전처리 조건 및 제2 전처리 조건을 생성하는 인공 신경망을 포함한다. 상기 프로세서는 상기 입력 영상에 대하여 상기 제1 전처리 조건을 적용하여 상기 제1 전처리 영상을 생성하는 제1 전처리 모듈에 상기 제1 전처리 조건이 전달되고, 상기 입력 영상에 대하여 상기 제2 전처리 조건을 적용하여 상기 제2 전처리 영상을 생성하는 제2 전처리 모듈에 상기 제2 전처리 조건이 전달 되도록 상기 인공 신경망, 및 상기 통신 모듈을 제어한다. 상기 프로세서는 상기 제1 전처리 영상 및 상기 제2 전처리 영상에 기반하여 상기 입력 영상에 대한 영상 분석을 수행하는 영상 분석 모듈에 상기 제1 전처리 영상 및 상기 제2 전처리 영상이 전달되도록 상기 통신 모듈을 경유하여 상기 제1 전처리 모듈, 상기 제2 전처리 모 듈, 및 상기 영상 분석 모듈을 제어한다. 상기 프로세서는 상기 인공 신경망 및 상기 영상 분석 모듈이 함께 훈련용 입력 영상 및 상기 훈련용 입력 영상 에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 상기 영상 분석 모듈의 목적 함수 출력의 피드백 및 상기 훈련용 입력 영상을 상기 인공 신경망에 전달할 수 있고, 상기 인공 신경망이 상기 영상 분석 모듈과 함께 훈련하도록 상기 인공 신경망 및 상기 영상 분석 모듈을 제어할 수 있다. 상기 프로세서는 상기 제1 전처리 조건, 및 상기 제2 전처리 조건을 상기 입력 영상, 상기 제1 전처리 영상, 상 기 제2 전처리 영상, 상기 영상 분석 모듈, 및 상기 입력 영상에 대한 상기 영상 분석 모듈의 분석 결과 중 적 어도 하나 이상에 대한 설명적 정보로서 사용자에게 제공할 수 있다. 본 발명의 일 실시예에 따른 영상 분석 장치는 머신 러닝 기반의 인공지능을 이용하는 영상 분석 장치로서, 상 기 영상 분석 장치는 컴퓨팅 시스템을 포함한다. 상기 컴퓨팅 시스템은 프로세서; 입력 영상을 수신하는 통신 모듈; 상기 입력 영상에 대한 추론을 통하여 제1 전처리 조건 및 제2 전처리 조건을 생성하는 제1 인공 신경망; 및 상기 입력 영상에 대한 영상 분석을 수행하여 분석 결과를 생성하는 제2 인공 신경망을 포함한다. 상기 프로 세서는 상기 입력 영상에 대하여 상기 제1 전처리 조건을 적용하여 상기 제1 전처리 영상을 생성하는 제1 전처 리 모듈; 및 상기 입력 영상에 대하여 상기 제2 전처리 조건을 적용하여 상기 제2 전처리 영상을 생성하는 제2 전처리 모듈을 포함한다. 상기 프로세서는 상기 제2 인공 신경망에 상기 제1 전처리 영상 및 상기 제2 전처리 영상이 전달되고 상기 제2 인공 신경망이 상기 제1 전처리 영상 및 상기 제2 전처리 영상에 기반하여 상기 입력 영상에 대한 상기 분석 결과를 생성하도록 상기 제1 전처리 모듈, 상기 제2 전처리 모듈, 상기 제1 인공 신경망, 상기 제2 인공 신경망, 및 상기 통신 모듈을 제어한다. 상기 프로세서는 상기 제1 인공 신경망 및 상기 제2 인공 신경망이 함께 훈련용 입력 영상 및 상기 훈련용 입력 영상에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 상기 제2 인공 신경망의 목적 함수 출력의 피드 백 및 상기 훈련용 입력 영상을 상기 제1 인공 신경망에 전달하고, 상기 제1 인공 신경망이 상기 제2 인공 신경 망과 함께 훈련하도록 상기 제1 인공 신경망 및 상기 제2 인공 신경망을 제어할 수 있다. 상기 제2 인공 신경망은 상기 입력 영상에 대한 영상 분할(segmentation), 객체 검출(object detection), 진단 (diagnosis), 정량화(quantification), 및 영상 분석(image analysis) 중 적어도 하나 이상을 포함하는 태스크 (Task)를 수행하는 인공 신경망일 수 있다. 상기 프로세서는 상기 제1 전처리 조건, 및 상기 제2 전처리 조건을 상기 입력 영상, 상기 제1 전처리 영상, 상 기 제2 전처리 영상, 상기 입력 영상에 대한 상기 제2 인공 신경망의 상기 분석 결과 중 적어도 하나 이상에 대 한 설명적 정보로서 사용자에게 제공할 수 있다."}
{"patent_id": "10-2019-0140605", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 자동화된 영상 분석 기법의 성능을 향상하여 인간의 육안으로 판독할 때 놓칠 수 있는 병변에 대한 분할, 검출, 및 진단까지도 가능한 영상 분석 기법을 제공할 수 있다. 본 발명에 따르면 의료 전문가에게 영상 분석, 분할, 검출, 및 진단 결과물에 대한 설명적 정보(descriptive information, explanation)로서, 임상적으로 유의미한 정보를 제공할 수 있는 영상 분석 기법을 구현할 수 있다.본 발명에 따르면 영상의 윈도우 레벨을 전처리하는 과정을 최적화하여 자동화된 전처리 과정의 완성도를 높일 수 있다. 본 발명에 따르면 영상 분석 모듈 또는 영상 분석 인공 신경망의 성능을 향상시킬 수 있는 영상 전처리 조건을 제공할 수 있다. 본 발명에 따르면 의료 영상에 대한 자동화된 전처리 과정으로 얻어지는 윈도우 레벨이 임상적으로 진단에 긍정 적인 영향을 줄 정도로 최적화되는 전처리 과정을 제공할 수 있다. 본 발명에 따르면 영상 분석 모듈 또는 영상 분석 인공 신경망의 성능을 향상시킬 수 있는 전처리된 영상 집합 을 제공할 수 있다. 본 발명에 따르면 학습 과정에서 인공 신경망과 윈도우 레벨 전처리 모듈을 함께 학습하여 인공 신경망이 수행 하는 임무(task)와 관련성이 높은 윈도우 레벨을 도출할 수 있도록 전처리 모듈과 인공 신경망 양쪽의 성능을 향상할 수 있다. 본 발명에 따르면 복수의 전처리 모듈을 상호 독립적으로, 병렬적으로 동작하도록 설계함으로써 초기값의 지정 에 따른 진단 정확도에 대한 영향, 및 local optimum에 의하여 global optimum을 찾지 못하는 문제점에 대한 robustness를 확보할 수 있다. 본 발명에 따르면 영상 분석 인공 신경망이 내부에서 문제를 해결하는 과정을 외부에서 이해할 수 있는 설명적 정보로서, 영상 분석 인공 신경망이 문제를 해결하기에 적합화된 전처리 조건을 도출할 수 있다. 또한 본 발명 에 따르면 도출된 전처리 조건에 기반하여 영상 분석 인공 신경망이 문제를 해결하는 과정을 적어도 부분적으로 설명할 수 있다. 본 발명에 따르면 종래 기술들과 달리 단순히 인공 신경망의 분석 과정에서 도출되는 히트맵 등을 분석하여 설 명적 정보로서 도출하는 데에 그치지 않고, 본 발명의 생성적 인공 신경망의 도출 결과가 인공 신경망의 분석 과정에 미치는 영향을 관찰할 수 있으며, 이로 인하여 결과에 대한 검증을 거쳐 신뢰할 수 있는 설명적 정보를 생성할 수 있다."}
{"patent_id": "10-2019-0140605", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "상기 목적 외에 본 발명의 다른 목적 및 특징들은 첨부 도면을 참조한 실시예에 대한 설명을 통하여 명백히 드 러나게 될 것이다. 본 발명의 바람직한 실시예를 첨부된 도면들을 참조하여 상세히 설명한다. 본 발명을 설명함에 있어, 관련된 공 지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설 명은 생략한다. 인공 신경망이 주어지는 문제를 해결하는 내부 과정은 자세히 알려져 있지 않다. 최근 영상 분할, 영상 처리 등 에 있어서 획기적인 성능 향상을 가져온 딥러닝, 컨볼루션 신경망(CNN, Convolutional Neural Network) 등에 있어서는 특히 내부가 블랙박스에 가까워, 도출되는 결과가 우수하더라도 사용자가 이를 전적으로 수용하고 채 택하는 데에 거부감이 있다. 이러한 배경에서 설명 가능한 인공지능(explainable artificial intelligence, X-AI)에 대한 연구가 미국국방 고등연구기획국(DARPA) 등에서 시도되고 있다 (https://www.darpa.mil/program/explainable-artificial- intelligence). 다만 아직까지 가시적인 성과는 드러나지 않고 있는 상황이다. 최근의 딥러닝/CNN 기반 인공 신경망 및 그 이후에 연구된 V-NET, U-NET, RNN 등의 인공 신경망은 주어지는 문 제를 복수개의 task로 구분하여 접근할 것으로 예상되지만 어떤 파라미터가 각각의 task에 영향을 미치는 지에 대한 정보는 아직까지 충분히 연구되지 않았다. 본 발명은 인공 신경망과 전처리 모듈을 함께 훈련하여 인공 신경망과 전처리 모듈 양쪽의 성능을 향상시키는 성과로부터 도출되었다. 인공 신경망과 전처리 모듈을 함께 훈련함으로써 인공 신경망의 영상 처리(본 발명에서 는 주로 영상 분할 및 관심 영역 검출)의 성능을 향상시키는 결과가 확인되었다. 이 과정에서 인공 신경망의 성능을 향상시키기 위한 의도, 및 전처리 모듈의 초기값의 지정이 최적화된 범위를 벗어나 local optimum으로 제한되는 경우를 회피하기 위하여 복수의 전처리 모듈을 병렬적, 상호 독립적으로 구 현하는 과정에서 본 발명은 더욱 고도화된 결과를 도출하였다. 본 발명은 복수개의 전처리 모듈을 사용함으로써, 인공 신경망에게 주어지는 문제를 해결하기 위하여 인공 신경 망이 개별적인 task에 대하여 각각 복수개의 전처리 모듈을 서로 다른 양상으로 최적화하는 결과를 도출하였고, 이에 기반하여 복수개의 전처리 모듈이 학습에 의하여 도출한 파라미터가 인공 신경망의 내부 동작을 이해하는 열쇠로서 활용될 수 있음에 착안하였다. 사용자는 본 발명을 활용함으로써, 인공 신경망에게 주어지는 문제를 해결하기 위하여 인공 신경망이 주어지는 문제를 어떠한 개별적인 task로 구분하는지를 들여다 볼 수 있고, 각각의 task에 대하여 인공 신경망이 전처리 모듈을 최적화한 결과물을 관련 정보로서 함께 제공받음으로써 인공 신경망이 제시하는 영상 분할, 및 관심 영 역의 검출은 물론, 그로부터 기인하는 의료 진단 결과물이 임상적으로 유의미한 결과를 동반하는 지 여부를 확 인할 수 있다. 이하에서는, 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 분석 장치 및 방법을 도 1 내지 도 14를 참조하여 상세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 전처리 및 분석 장치의 훈련/ 학습 과정을 도시하는 도면이다. 도 1을 참조하면, 영상 전처리 및 분석 장치는 컴퓨팅 시스템을 포함한다. 컴퓨팅 시스템은 수신 모 듈, 제1 인공 신경망, 프로세서, 영상 분석 모듈, 및 목적 함수 로직을 포함한다. 프 로세서는 제1 전처리 모듈, 제2 전처리 모듈, 제3 전처리 모듈을 포함한다. 프로세서(12 0)는 제1 인공 신경망과 수신 모듈을 제어할 수 있다. 훈련용 입력 영상은 의료 영상이고, 설명의 편의를 위하여 컴퓨터 단층촬영(CT) 영상을 주로 언급하지만, 훈련용 입력 영상은 CT 영상에 국한되지 않고, X선 촬영 영상(X-ray), 컴퓨터 단층촬영 영상(CT), 자기 공 명 영상(MRI), 초음파 영상, 양전자 방출 단층촬영 영상(PET, Positron Emission Tomography), 및 단일 광자 방출 컴퓨터 단층촬영(SPECT, Single Photon Emission CT) 중 적어도 하나 이상을 포함하는 모달리티 (modality)에 의하여 획득되는 영상일 수 있다. 여기서 제시한 것은 예시일 뿐, 인체의 해부학적 정보를 포함하 는 의료 영상이면 어떠한 모달리티(modality)를 이용한 경우에도 대응할 수 있다. 훈련용 입력 영상은 수신 모듈을 경유하여 제1 인공 신경망에 전달될 수 있다. 이때, 발명의 실 시예에 따라서는 훈련용 입력 영상의 원본 영상이 영상 분석 모듈에도 전달될 수 있다. 또는 발명의 다른 실시예에 따라서는 훈련용 입력 영상이 복수의 전처리 모듈들(121, 122, 123)에 의하여 전처리된 영 상들이 영상 분석 모듈에 전달될 수 있다. 어느 쪽이든, 영상 분석 모듈은 훈련용 입력 영상에 기반한 영상 분석을 수행할 수 있다. 제1 인공 신경망은 훈련용 입력 영상에 대한 추론을 통하여 제1 전처리 조건, 제2 전처리 조건, 및 제3 전처리 조건을 생성할 수 있다. 제1 전처리 조건은 제1 전처리 모듈을 위한 것이고, 제2 전처리 조건 은 제2 전처리 모듈을 위한 것이며, 제3 전처리 조건은 제3 전처리 모듈을 위한 것이다. 전처리 조건 들은 훈련용 입력 영상의 밝기 값의 상한과 하한을 포함하는 윈도윙(Windowing) 정보일 수 있으며, 상한과 하한으로 표시되는 대신, 중심 레벨(Level)과 폭(Width)으로 표현될 수도 있다. 영상 분석 모듈은 훈련용 입력 영상에 대한 영상 분석을 수행하여 분석 결과를 도출하는 모듈이다. 영상 분석 모듈은 훈련용 입력 영상에 대한 영상 분할(segmentation), 객체 검출(object detection), 진단(diagnosis), 정량화(quantification), 및/또는 영상 분석(image analysis) 중 적어도 하나 이상을 포함하는 태스크(Task)를 수행하는 모듈일 수 있다. 영상 분석 모듈은 인공 신경망으로 구현될 수도 있고, rule-based 방식으로 구현될 수도 있다. 또한 영상 분석 모듈은 학습 또는 훈련에 의하여 형성된 모듈일 수도 있고 처음부터 고정된 파라미터를 가지는 모듈 일 수도 있다. 도 1에 도시된 본 발명의 일 실시예에서는 영상 분석 모듈이 인공 신경망으로 구현되었지만, 이미 훈련용 입력 영상에 대하여 학습이 완료되어 고정된 내부 파라미터를 가지는 경우를 가정한다. 이 때 도 1의 실시예의 훈련/학습 과정은 영상 분석 모듈을 훈련하기 위한 것이 아니고, 제1 인공 신경망을 훈련하기 위한 과정이다. 후술할 도 7과 도 8에서는 도 1과 도 2의 영상 분석 모듈이 제2 인공 신경망으로 대체되어, 도 7과 도 8의 제1 인공 신경망과 함께 훈련되는 실시예가 도시된다. 다시 도 1을 참조하면, 제1 인공 신경망은 복수의 전처리 모듈들(121, 122, 123)에서 수행하는 전처리 과 정에서 이용되는 전처리 조건들을 생성한다. 이때 제1 인공 신경망은 생성적 인공 신경망(Generative Artificial Neural Network)일 수 있다. 제1 인공 신경망은 훈련용 입력 영상에 기반하여 전처리 조 건들을 생성한다. 제1 인공 신경망에 의하여 생성된 전처리 조건들은 프로세서에 의하여 복수의 전처리 모듈들(121, 122, 123)에 전달된다. 제1 전처리 모듈은 제1 전처리 조건을 이용하여 훈련용 입력 영상을 전처리하 여 제1 전처리 영상을 생성하고, 제2 전처리 모듈은 제2 전처리 조건을 이용하여 훈련용 입력 영상을 전처리하여 제2 전처리 영상을 생성하고, 제3 전처리 모듈은 제3 전처리 조건을 이용하여 훈련용 입력 영 상을 전처리하여 제3 전처리 영상을 생성한다. 제1, 제2, 제3 전처리 영상들은 영상 분석 모듈로 입력되고, 영상 분석 모듈은 제1, 제2, 제3 전처리 영상들에 기반하여 훈련용 입력 영상에 대한 분석 결과를 도출한다. 프로세서는 제1, 제2, 제3 전처 리 영상들이 영상 분석 모듈에 전달되도록 전처리 모듈들(121, 122, 123) 및 영상 분석 모듈을 제어 할 수 있다. 이때 제1, 제2, 제3 전처리 영상들은 훈련용 입력 영상에 기반하여 형성된 것이고, 훈련용 입 력 영상이 관련되는 레이블(label) 정보는 제1, 제2, 제3 전처리 영상들도 관련된다. 목적 함수 로직(14 0)은 영상 분석 모듈의 분석 결과 및 훈련용 입력 영상이 관련되는 레이블 정보, 또는 제1, 제2, 제3 전처리 영상들과 그 레이블 정보(훈련용 입력 영상의 레이블 정보에 기반하여 획득)에 기반하여 분석 결과 에 대한 판정을 수행한다. 분석 결과에 대한 판정이 목적 함수 로직이 설정한 기준 조건을 충족하였는지 여부가 목적 함수 로직의 피드백 정보로서 제1 인공 신경망에 전달된다. 제1, 제2, 제3 전처리 영상들은 윈도윙 정보에 기반하여 전처리된 windowed images이다. 실시예에 따라서는 windowed images 는 영상 분석 모듈에 직접 전달될 수도 있고, 영상 분석 모듈이 처리하기 용이한 형태로 가공되어 영상 분석 모듈에 전달될 수도 있다. 이와 관련된 실시예는 후술할 도 11에 소개된다. 제1 인공 신경망은 전처리 모듈들(121, 122, 123)이 수행할 윈도윙 정보를 생성함으로써 영상 분석 모듈 이 훈련용 입력 영상에 대한 영상 분석 성능을 향상시킬 수 있도록 지원한다. 생성적 제1 인공 신경 망은 영상 분석 모듈이 훈련용 입력 영상에 대하여 수행하는 영상 분석 과정, 영상 분석 모듈 이 훈련용 입력 영상에 대하여 제공하는 분석 결과에 대한 설명적 정보로서 전처리 모듈들(121, 122, 123)이 수행할 윈도윙 정보를 제공할 수 있다. 실시예에 따라서는 영상 분석 모듈이 최초 훈련 과정에서 도달한 목표 성능보다 높은 목표 성능을 가지도 록 목적 함수 로직의 기준 조건이 설정될 수 있다. 이 때에는 제1 인공 신경망이 영상 분석 모듈 의 성능 향상에 기여한 요인에 대한 설명적 정보로서 윈도윙 정보가 이용될 수도 있다. 영상 분석 모듈이 영상 분할 Task를 수행하는 경우, 영상 분석 모듈의 분석 결과로 도출된 관심 영역 및 훈련용 입력 영상에 대한 레퍼런스 관심 영역 간의 유사도가 목적 함수 로직의 기준 조건이 될 수 도 있으며, 영상 분석 모듈이 객체 검출 Task를 수행하는 경우, 영상 분석 모듈의 분석 결과로 도출 된 관심 영역의 수 및 위치와 훈련용 입력 영상에 대한 레퍼런스 관심 영역의 수 및 위치 간의 유사도가 목적 함수 로직의 기준 조건이 될 수도 있다. 영상 분석 모듈이 병변의 진단 또는 정량화에 대한 Task를 수행하는 경우, 영상 분석 모듈의 진단 또는 정량화 결과와 레퍼런스 진단 결과 또는 정량화 결과 간의 정확도가 목적 함수 로직의 기준 조건이 될 수도 있다. 도 1의 영상 전처리 및 분석 장치의 컴퓨팅 시스템 내에서는 프로세서의 제어에 의하여 제1 인공 신 경망, 전처리 모듈들(121, 122, 123), 영상 분석 모듈, 및 목적 함수 로직이 함께 훈련용 입력 영상 및 훈련용 입력 영상에 대한 분석 결과 간의 관련성에 대하여 훈련/학습할 수 있도록 훈련/학습 과정의 피드백 루프를 형성한다. 훈련용 입력 영상은 제1 인공 신경망의 입력으로 전달되어 전처리 조건들을 생성하는 기반으로 적용된다. 피드백 루프 내에서는 목적 함수 로직의 출력의 피드백이 제1 인공 신경망에 전달된다. 프로세서는 제1 인공 신경망, 전처리 모듈들(121, 122, 123), 영상 분석 모 듈, 및 목적 함수 로직 간의 데이터 전달 경로 및 피드백 전달 경로를 제어할 수 있다. 제1 전처리 모듈, 제2 전처리 모듈, 및 제3 전처리 모듈은 상호 독립적으로 동작한다. 또한 제1 인공 신경망은 전처리 모듈들(121, 122, 123) 모두에 대하여 전처리 모듈들(121, 122, 123) 각각의 전처리 조건들을 동시에 생성하지만, 전처리 조건들은 생성된 이후에는 전처리 모듈들(121, 122, 123) 각각으로 전달되 고 전처리 모듈들(121, 122, 123) 각각의 동작은 상호 독립적이다. 도 2는 도 1의 영상 전처리 및 분석 장치를 이용한 추론 과정을 도시하는 도면이다. 도 2의 입력 영상는 새로운 분석 및 추론을 위한 새로운 입력이다. 수신 모듈은 입력 영상을 수신한다. 제1 인공 신경망은 입력 영상에 대한 추론을 통하여 제1 전처리 조건, 제2 전처리 조건, 및 제3 전처 리 조건을 생성한다. 프로세서 내부의 전처리 모듈들(121, 122, 123)은 각각에 할당되는 전처리 조건들을 입력 영상에 적 용하여 제1, 제2, 제3 전처리 영상들을 생성한다. 프로세서는 제1 전처리 모듈이 제1 전처리 조건을 입력 영상에 적용하여 생성한 제1 전처리 영 상, 제2 전처리 모듈이 제2 전처리 조건을 입력 영상에 적용하여 생성한 제2 전처리 영상, 및 제3 전 처리 모듈이 제3 전처리 조건을 입력 영상에 적용하여 생성한 제3 전처리 영상이 영상 분석 모듈 에 전달되도록 제1 인공 신경망, 전처리 모듈들(121, 122, 123), 및 영상 분석 모듈을 제어할 수 있다. 프로세서는 제1 전처리 조건, 제2 전처리 조건, 및 제3 전처리 조건을 입력 영상, 제1 전처리 영상, 제2 전처리 영상, 제3 전처리 영상, 영상 분석 모듈, 및 입력 영상에 대한 영상 분석 모듈의 분 석 결과 중 적어도 하나 이상에 대한 설명적 정보로서 사용자에게 제공할 수 있다. 제1 인공 신경망이 입력 영상에 대해서 도출한 전처리 조건들, 윈도윙 정보는 입력 영상을 영상 분석 모듈이 효과적으로 분석할 수 있도록 도출된 전처리 조건들일 수 있으므로, 입력 영상이 포함하 는 질환, 및 병변에 대한 설명적 정보로 해석될 수도 있고, 입력 영상을 영상 분석 모듈이 분석하는 과정 및 수단을 외부에서 들여다 볼 수 있는 설명적 정보로 해석될 수도 있다. 또한 영상 분석 모듈의 성능 향상을 위한 전처리 영상들이 도출되는 과정, 영상 분석 모듈의 성능 향상을 도모할 수 있는 수단에 대 한 설명적 정보로 해석될 수도 있다. 도 1과 도 2의 실시예에서는 영상 분석 모듈이 컴퓨팅 시스템 내에 포함된다. 또한 도시되지는 않았 으나, 컴퓨팅 시스템 외부로 데이터 및 정보를 전송할 수 있는 전송 모듈(도시되지 않음)이 컴퓨팅 시스템 내에 더 포함될 수 있다. 수신 모듈과 전송 모듈은 하나의 모듈로 통합되어 \"통신 모듈\"을 구성할 수도 있다. 도 3은 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 전처리 장치의 훈련/학습 과정 을 도시하는 도면이다. 도 3을 참조하면, 영상 전처리 및 분석 장치는 컴퓨팅 시스템을 포함한다. 컴퓨팅 시스템은 수신 모 듈, 제1 인공 신경망, 프로세서, 및 전송 모듈을 포함한다. 컴퓨팅 시스템 외부의 영 상 분석 모듈, 및 목적 함수 로직과 통신하거나, 영상 분석 모듈 및 목적 함수 로직을 제 어하기 위하여 프로세서는 수신 모듈과 전송 모듈을 포함한다. 실시예에 따라서는 수신 모듈 과 전송 모듈은 하나의 모듈로 통합되어 \"통신 모듈\"로서 기능할 수도 있다. 프로세서는 제1 전처리 모듈, 제2 전처리 모듈, 제3 전처리 모듈을 포함한다. 프로세서 는 제1 인공 신경망, 수신 모듈, 전송 모듈을 제어할 수 있다. 전송 모듈은 컴퓨팅 시스템 외부의 영상 분석 모듈에 제1 전처리 영상, 제2 전처리 영상, 및 제 3 전처리 영상을 전송한다. 수신 모듈은 제1 인공 신경망 및 영상 분석 모듈이 함께 훈련용 입력 영상 및 훈련용 입력 영상에 대한 분석 결과 간의 관련성에 대하여 훈련할 수 있도록 훈련용 입력 영상 및 영상 분석 모듈 의 분석 결과에 대한 목적 함수 로직의 출력을 피드백받아 제1 인공 신경망에 전달할 수 있다. 프로세서는 제1 인공 신경망이 영상 분석 모듈과 함께 훈련하도록 제1 인공 신경망을 제어 하고, 수신 모듈과 전송 모듈을 경유하여 영상 분석 모듈 및 목적 함수 로직을 제어할 수 있다. 도 3의 컴퓨팅 시스템은 제1 인공 신경망의 훈련에 의하여 영상 분석 모듈을 위한 제1, 제2, 제 3 전처리 영상들을 생성한다. 이때 제1, 제2, 제3 전처리 영상들은 훈련용 입력 영상 및 제1, 제2, 제3 전 처리 조건들에 기반하여 생성된다. 제1 인공 신경망이 영상 분석 모듈에 대한 전처리 조건들을 도출할 수 있도록 제1 인공 신경망 을 훈련/학습하는 과정은, 수신 모듈, 제1 인공 신경망, 프로세서, 제1 전처리 모듈, 제2 전처리 모듈, 제3 전처리 모듈, 전송 모듈, 영상 분석 모듈, 및 목적 함수 로직에 의 하여 형성되는 피드백 루프 내에서 실행된다. 도 4는 도 3의 영상 전처리 장치를 이용한 추론 과정을 도시하는 도면이다. 도 4에서 입력 영상을 수신 모듈이 수신하고, 제1 인공 신경망이 입력 영상에 기반하여 제 1, 제2, 제3 전처리 조건들을 생성하고, 프로세서 내부의 전처리 모듈들(221, 222, 223) 각각이 제1, 제2, 제3 전처리 조건들을 입력 영상에 적용하여 제1, 제2, 제3 전처리 영상들을 생성하고, 영상 분석 모듈 이 제1, 제2, 제3 전처리 영상들을 전달받아 추론에 의한 영상 분석 결과를 입력 영상에 대한 영상 분석 결과로서 도출하는 것은 도 2에서 설명된 과정과 유사하므로 중복되는 설명은 생략한다. 도 4에서는 전송 모듈이 제1, 제2, 제3 전처리 영상들을 컴퓨팅 시스템 외부의 영상 분석 모듈 에 전송하는 점이 도 2에서와 상이할 뿐, 다른 구성은 도 2와 매우 유사하다. 도 5는 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 분석 지원 장치의 훈련/학습 과정을 도시하는 도면이다. 훈련용 입력 영상에 기반하여 수신 모듈, 제1 인공 신경망, 제1 전처리 모듈, 제2 전처리 모듈, 제3 전처리 모듈, 영상 분석 모듈, 및 목적 함수 로직이 피드백 루프를 이루고, 제1 인공 신경망 및 영상 분석 모듈이 함께 훈련용 입력 영상 및 훈련용 입력 영상의 레퍼런스 분석 결과 간의 관련성을 훈련/학습하는 과정이 실행되는 것은 도 1 및 도 3의 실시예와 동일하므로 중복되는 설명은 생략한다.영상 분석 모듈은 제1 인공 신경망의 훈련/학습 과정에 함께 참여하지만, 영상 분석 모듈은 이 미 훈련/학습이 종료된 상태이고, 영상 분석 모듈 내부의 파라미터는 고정된 상태일 수도 있다. 이 경우 실질적으로 훈련/학습되는 대상은 제1 인공 신경망이다. 도 5의 실시예에서는 전송 모듈이 프로세서의 제어에 의하여 제1 전처리 조건을 컴퓨팅 시스템 외부의 제1 전처리 모듈에 전달하고, 제2 전처리 조건을 컴퓨팅 시스템 외부의 제2 전처리 모듈(32 2)에 전달하고, 제3 전처리 조건을 컴퓨팅 시스템 외부의 제3 전처리 모듈에 전달한다. 제1 인공 신경망의 훈련/학습을 위한 피드백 루프는 컴퓨팅 시스템 외부의 전처리 모듈들(321, 322, 323), 영상 분석 모듈, 목적 함수 로직을 포함하므로, 프로세서는 수신 모듈과 전송 모듈 을 경유하여 컴퓨팅 시스템 외부의 전처리 모듈들(321, 322, 323), 영상 분석 모듈, 목적 함수 로직을 제어할 수 있다. 제1 인공 신경망은 컴퓨팅 시스템 외부의 전처리 모듈들(321, 322, 323)의 개수를 사전에 인식하고 있는 것을 전제로 한다. 도 6은 도 5의 영상 분석 지원 장치를 이용한 추론 과정을 도시하는 도면이다. 도 6에서 입력 영상을 수신 모듈이 수신하고, 제1 인공 신경망이 입력 영상에 기반하여 제 1, 제2, 제3 전처리 조건들을 생성하고, 전처리 모듈들(321, 222, 223) 각각이 제1, 제2, 제3 전처리 조건들을 입력 영상에 적용하여 제1, 제2, 제3 전처리 영상들을 생성하고, 영상 분석 모듈이 제1, 제2, 제3 전 처리 영상들을 전달받아 추론에 의한 영상 분석 결과를 입력 영상에 대한 영상 분석 결과로서 도출하는 것 은 도 2, 및 도 4에서 설명된 과정과 유사하므로 중복되는 설명은 생략한다. 도 6에서는 전송 모듈이 제1 인공 신경망이 생성한 제1, 제2, 제3 전처리 조건들을 컴퓨팅 시스템 외부의 전처리 모듈들(321, 322, 323)에 전달하는 점이 도 2, 및 도 4에서와 상이할 뿐, 다른 구성은 도 2, 및 도 4와 매우 유사하다. 도 7은 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 분석 장치의 훈련/학습 과정을 도시하는 도면이다. 도 7에서는 도 1의 영상 분석 모듈이 제2 인공 신경망으로 대체된다. 도 7을 참조하면, 훈련용 입력 영상에 기반하여 수신 모듈, 제1 인공 신경망, 제1 전처리 모듈 , 제2 전처리 모듈, 제3 전처리 모듈, 제2 인공 신경망, 및 목적 함수 로직이 피드 백 루프를 이루고, 제1 인공 신경망 및 제2 인공 신경망이 함께 훈련용 입력 영상 및 훈련용 입 력 영상의 레퍼런스 분석 결과 간의 관련성을 훈련/학습하는 과정이 실행되는 것은 도 1의 실시예와 동일하므로 중복되는 설명은 생략한다. 제2 인공 신경망은 제1 인공 신경망의 훈련/학습 과정에 함께 참여하고, 제1 인공 신경망 및 제 2 인공 신경망이 함께 훈련/학습될 수 있다. 이때에는 제2 인공 신경망은 제1 인공 신경망에 의 하여 동작 원리에 대한 설명적 정보가 부분적이나마 생성될 수 있다. 제2 인공 신경망은 일반적으로 내부 가 블랙 박스에 가까워 내부의 동작을 외부에서 들여다볼 수 없지만, 제1 인공 신경망이 함께 훈련/학습하 여 전처리 조건들을 생성하고, 외부에서는 전처리 조건들을 제2 인공 신경망이 문제를 해결하는 과정을 부 분적으로나마 이해하는 수단으로 활용할 수 있다. 도 7은 도 8의 영상 분석 장치를 이용한 추론 과정을 도시하는 도면이다. 도 8에서 입력 영상을 수신 모듈이 수신하고, 제1 인공 신경망이 입력 영상에 기반하여 제 1, 제2, 제3 전처리 조건들을 생성하고, 프로세서 내부의 전처리 모듈들(421, 222, 223) 각각이 제1, 제2, 제3 전처리 조건들을 입력 영상에 적용하여 제1, 제2, 제3 전처리 영상들을 생성하고, 제2 인공 신경망 이 제1, 제2, 제3 전처리 영상들을 전달받아 추론에 의한 영상 분석 결과를 입력 영상에 대한 영상 분석 결과로서 도출하는 것은 도 2에서 설명된 과정과 유사하므로 중복되는 설명은 생략한다. 도 7과 도 8의 실시예에 따르면, 학습 과정에서 인공 신경망과 윈도우 레벨 전처리 모듈을 함께 학습하여 인공 신경망이 수행하는 임무(task)와 관련성이 높은 윈도우 레벨을 도출할 수 있도록 전처리 모듈과 인공 신경망 양 쪽의 성능을 향상할 수 있다. 도 1 내지 도 8의 실시예에 따르면, 영상 분석 모듈에 대한 입력 영상의 윈도우 레벨을 전처리하는 과정을 최적 화하여 자동화된 전처리 과정의 완성도를 높일 수 있다. 도 1 내지 도 8의 실시예에 따르면, 영상 분석 모듈 또는 영상 분석 인공 신경망의 성능을 향상시킬 수 있는 영 상 전처리 조건을 제공할 수 있다. 도 1 내지 도 8의 실시예에 따르면, 의료 영상에 대한 자동화된 전처리 과정으로 얻어지는 윈도우 레벨이 임상 적으로 진단에 긍정적인 영향을 줄 정도로 최적화되는 전처리 과정을 제공할 수 있다. 도 1 내지 도 8의 실시예에 따르면, 영상 분석 모듈 또는 영상 분석 인공 신경망의 성능을 향상시킬 수 있는 전 처리된 영상 집합을 제공할 수 있다. 도 1 내지 도 8의 실시예에 따르면, 영상 분석 인공 신경망이 내부에서 문제를 해결하는 과정을 외부에서 이해 할 수 있는 설명적 정보로서, 영상 분석 인공 신경망이 문제를 해결하기에 적합화된 전처리 조건을 도출할 수 있다. 또한 본 발명에 따르면 도출된 전처리 조건에 기반하여 영상 분석 인공 신경망이 문제를 해결하는 과정을 적어도 부분적으로 설명할 수 있다. 도 1 내지 도 8의 실시예에 따르면, 종래 기술들과 달리 단순히 영상 분석 인공 신경망의 분석 과정에서 도출되 는 히트맵 등을 분석하여 설명적 정보로서 도출하는 데에 그치지 않고, 본 발명의 생성적 인공 신경망의 도출 결과가 영상 분석 인공 신경망의 분석 과정에 미치는 영향을 관찰할 수 있으며, 이로 인하여 설명적 정보가 개 입한 결과에 대한 검증을 거쳐 신뢰할 수 있는 설명적 정보를 생성할 수 있다. 도 1 내지 도 6의 실시예에서처럼, 기존의 컴퓨터 보조 진단(CAD, Computer-aided Diagnosis) 인공 신경망(훈 련/학습이 종료된 상태)의 성능을 부스트하기 위한 용도로 본 발명의 제1 인공 신경망(110, 210, 310)을 애드- 온하는 방식으로 본 발명이 실행될 수도 있다. 이때 본 발명의 제1 인공 신경망(110, 210, 310)은 기존의 CAD 모델의 성능을 부스트하거나, 또는 기존의 CAD 모델이 의료 영상에 대한 분석을 수행할 때 실제로는 내부에서 복수의 Task로 구분하여 수행함을 설명적 정보로서 생성할 수도 있다. 도 7과 도 8의 실시예에서는 새로운 CAD 모델을 설계함에 있어서, 새로운 CAD 모델과 본 발명의 제1 인공 신경 망을 함께 훈련하여 성능이 향상된 CAD 모델을 개발하는 수단으로 본 발명을 활용할 수도 있다. 도 7 내지 도 8의 실시예에서 전처리 모듈들이 3개인 실시예가 도시되었으나, 본 발명의 사상은 실시예들에 국 한되지 않는다. 주어지는 Task의 특성에 따라서 다른 개수의 전처리 모듈들이 이용될 수 있음은 본 발명의 개시 에 기반하여 당업자가 자명하게 이해할 수 있을 것이다. 도 1 내지 도 8의 실시예에서, 생성적 제1 인공 신경망으로는 컨볼루션 신경망, 또는 Feature Extracter 와 Parameter Generator를 결합한 형태를 이용하여 구성할 수 있다. 다만 이러한 예시는 본 발명의 사상을 한정하 지 않으며, 훈련에 의하여 윈도윙 조건을 생성할 수 있는 생성적 인공 신경망은 모두 본 발명의 구성으로 적용 가능할 것이다. 도 9는 본 발명의 일부를 구성하는 CT 윈도우잉 과정을 설명하는 도면이다. 최근 의료 영상을 이용한 병변 판별의 자동화에 대한 관심이 높아진 상태에서, 의료 영상은 인체 내의 장기 (organ) 별로 CT 또는 MRI 등의 영상에서 나타나는 밝기 값에 차이가 있음이 알려져 있다. CT 영상의 경우에는 의료 영상 판별에 있어서 Hounsfield Unit의 정규화 과정이 매우 중요함이 잘 알려져 있다. 도 9를 참조하면, 뼈(bone), 혈액(Blood), 심장(Heart), 간(Liver), 종양(Tumor), 맘모(Mammo), 지방(Fat), 폐 (Lung) 장기와 일반적인 물(Water), 공기(Air)가 CT 영상 내에서 가지는 Hounsfield 값의 범위가 도시된다. 윈도윙 전의 CT 영상은 각 장기의 구별이 육안으로 쉽지 않도록 표시되지만, 윈도윙 후의 CT 영상은 육안으로 장기를 구별하기 쉽도록 표현될 수 있다. 이때 윈도윙 조건은 중심 레벨과 폭(Width), 또는 상한과 하한으로 표 현될 수 있다. 이러한 윈도윙 조건은 원하지 않는 정보는 제외하고 원하는 정보만 관찰하기 위한 것으로, 간 관 찰을 예로 들면, 뼈 부위 또는 지방 부위의 밝기 범위를 제외하고, 간 영역의 밝기 차이를 주로 분석하기 위하 여 windowing 조건을 설정하고, windowing을 수행할 수 있다. 한편 도 9에서 CT를 예시로 들었으나, MRI 또는 다른 모달리티에도 적용 가능하며, 발명이 적용되는 모달리티에 맞게 윈도윙 조건을 변형하여 적용할 수 있다. 도 10은 본 발명의 일 실시예에 따른 복수의 윈도우잉 전처리 모듈에서 생성되는 windowed images의 예시를 도 시하는 도면이다.제1 윈도우 영상들은 제1 전처리 조건에 의하여 생성되고, 제2 윈도우 영상들은 제2 전처리 조건에 의하여 생성되고, 제3 윈도우 영상들은 제3 전처리 조건에 의하여 생성된다. 이때 제1 전처리 조건, 제2 전처리 조건, 제3 전처리 조건은 서로 다르므로 동일한 입력 영상에 대해서 생성되는 제1 윈도우 영상들, 제2 윈도우 영상들, 제3 윈도우 영상들이 시각화되는 결과는 미묘하게 다르며, 이들 제1 윈도우 영 상들, 제2 윈도우 영상들, 제3 윈도우 영상들의 조합에 의하여 영상 분석 모듈 또는 영상 분 석 인공 신경망은 영상 분석의 성능을 향상시킬 수 있다. 도 11은 본 발명의 일 실시예에 따른 영상 전처리 및/또는 영상 분석 장치에서, 영상 분석을 효과적으로 지원하 기 위한 전처리 데이터 생성 과정을 도시하는 도면이다. 본 발명의 실시예들에서는 전처리 영상들이 영상 분석 모듈 또는 영상 분석 인공 신경망에 직접 입력될 수도 있 으나, 도 11에서와 같이 추가 전처리 과정을 거쳐 영상 분석 모듈 또는 영상 분석 인공 신경망에 입력될 수도 있다. 도 11을 참조하면, 1차 전처리된(windowed) 영상들을 컨벌루션하여 k개의 슬라이드에서 k개의 feature map을 생 성하는 2차 전처리 과정이 수행된다. 2차 전처리 과정에 의하여 생성되는 k개의 feature map 영상이 영상 분석 을 수행하는 Task module에 입력된다. 여기에서 도 11에서는 Task module의 일 예로 segmentation인 경우가 도 시되었으나, 본 발명의 다른 실시예에서는 Task module이 detection, diagnosis, quantification, analysis 일 수도 있고, 이들 중 둘 이상의 조합을 함께 수행하는 경우일 수도 있다. 도 12는 본 발명의 비교예로서, 1개의 전처리 조건을 이용하는 인공 신경망이 간과 간암 영역을 검출한 결과를 도시하는 도면이다. 도 12에서 initial 조건은 일반적으로 의료 기관에서 이용하는 간암 진단을 위한 전처리 윈도윙 기준일 수 있다. 1개의 전처리 모듈을 이용하여 훈련하는 경우 윈도윙 조건의 범위는 initial 조건보다 좁혀지는 경향이 있다. 다만 이 경우에 윈도윙 조건이 나타나는 현상의 원인을 정확히 진단하기는 어려울 수 있다. 도 13과 도 14는 본 발명의 실시예들로서, 복수의 전처리 모듈과 인공 신경망이 함께 훈련되는 네트워크 구조에 서 간과 간암 영역을 검출한 결과를 도시하는 도면이다. 도 13에서는 최초의 initial 조건에서 트레이닝을 시작하여, 본 발명의 개념을 적용하여 훈련한 결과, 간과 간 암을 구별하고자 하는 Task에서 제1 전처리 조건은 tumor의 윈도우 레벨에 유사하도록 훈련되고, 제2 전처리 조 건은 간과 간암을 포함하여 주변의 생체 조직을 나타내도록 훈련되고, 제3 전처리 조건은 건강한 liver의 윈도 우 레벨에 유사하도록 훈련되었음을 나타낸다. 이때, 본 발명의 생성적 인공 신경망은 분석용 인공 신경망이 해당 Task를 수행하기 위하여 건강한 간(liver)과 간암(tumor) 각각을 구별하는 적어도 두 개의 sub-task를 수행하고 있음을 간접적으로 파악할 수 있다. 제2 전 처리 조건은 건강한 간과 간암 양쪽 모두 외에도 주변 장기들을 파악하는 좀 더 넓은 범위로 수렴하는데, 이는 인간이 육안으로 주변 부위를 인식하기 위하여 설정하는 윈도윙 조건과 매우 유사하다. 마찬가지로, 영상 분석 인공 신경망이 주변의 정황 정보를 인식하기 위하여 인간이 육안으로 인식하는 윈도윙 조건과 유사한 윈도윙 조 건을 이용한다는 것 또한 간접적으로 파악할 수 있다. 종합적으로는 간과 간암을 구별하는 Task를 수행하기 위하여, 인공 신경망이 맥락(context)를 파악하기 위한 수 단으로 제2 전처리 조건과 같이 대상의 주변을 포함하는 윈도윙 조건을 필요로 하는 것으로 이해될 수도 있을 것이다. 도 14의 실시예에서는 윈도윙 조건들의 초기값을 도 13과 조금 달리 설정하였지만, 결과는 실질적으로 동일하거 나 유사하다. 도 14에서는 제1 전처리 조건이 건강한 간(liver)의 윈도윙 범위에 대응하고, 제3 전처리 조건이 간암(tumor)의 윈도윙 범위에 대응한다. 제2 전처리 조건은 간과 간암을 모두 포함하는 초기 윈도윙 조건과 유사하게 대응한다. 결국, 도 13과 도 14세어 초기값을 조금 달리 설정하더라도 결과는 매우 유사하면, 본 발명은 다양한 조건 하에서도 robust한 결과를 도출한다는 점을 시사한다. 도 15는 도 1의 실시예에서 훈련된 제1 인공 신경망이 도 2의 실시예에서 새로운 입력 영상을 수신하 여 전처리 영상들을 생성하는 과정의 일 예를 도시하는 도면이다. 입력 영상인 CT 영상에서 인간 전문가가 진단한 판독 결과인 Ground Truth, 영상 분석 모듈의 기존 판독 결과가 Existing으로 도 15에 표시된다. 영상 분석 모듈은 훈련이 종료되어 파라미터가 fixed되었다 고 가정한다. 본 발명의 제1 인공 신경망은 영상 분석 모듈과 함께 피드백 루프를 형성하고, 훈련하여 영상 분석 모듈의 성능을 향상시킬 수 있는 전처리 조건을 학습한다. 제1 인공 신경망이 생성한 전처리 조건들 을 이용하여 윈도윙 처리된 영상들이 도 15에 도시된다. 또한 윙도윙 처리된 전처리 영상들이 fixed 영상 분석 모듈에 입력되어 얻은 결과가 Proposal 로 표시된다. 영상 분석 모듈이 CT 영상을 [-230, 230] 윈도 윙 처리한 후 입력받아 단독으로 동작한 경우 검출하지 못했던 영역을 제1 인공 신경망의 전처리 조건에 기반한 전처리 영상들을 수신하여 동작한 경우에는 검출하는 데에 성공한 결과가 도시된다. 제1 인공 신경망이 CT 영상과 영상 분석 모듈을 위하여 도출한 윈도윙 조건은 [54, 69], [-19, -11], [-27, -17] 로 해당 CT 영상 내에서 특정한 장기들을 구분하고 검출하는 데에 최적화되는 조건들이다. 따 라서 이러한 윈도윙 조건들은 영상 분석 모듈이 CT 영상을 분석하는 과정을 제1 인공 신경망이 학습 한 결과이고, 영상 분석 모듈이 CT 영상을 분석하는 과정을 제1 인공 신경망을 통하여 외부에서 들여 다볼 수 있는 설명적 정보로서 이용될 수 있다. 또한 제1 인공 신경망이 이미 학습이 종료되어 파라미터가 fixed된 영상 분석 모듈의 성능을 더욱 향 상시킬 수 있는 윈도윙 이미지를 생성할 수 있음이 도 15에 의하여 도시된다. 도 16은 도 15에서 도출된 제1 인공 신경망에 의하여 생성된 Window Parameter를 입력 CT 영상의 Hounsfield Unit 값의 분포와 함께 도시한 도면이다. 도 16을 참조하면, 도 15에 나타난 예시에서 입력 CT 영상의 조영 값(Contrast Value)의 분포(Other, Tumor, Liver)와, CT 영상을 입력했을 때 제1 인공 신경망이 생성한 전처리 파라미터로부터 얻어진 Hounsfield Unit 범위들(Window 1, Window 2, Window 3)이 도시된다. 도 16을 참조하면, 기존의 영상 분석 모듈의 훈련에 사용한 CT 영상들의 Hounsfield Unit 범위는 [-230, 230]으로 간, 간암, 기타 조직의 Hounsfield Unit 범위를 폭 넓게 포함한다. 반면, 제1 인공 신경망이 생성한 전처리 파라미터로부터 얻어진 Hounsfield Unit 범위들(Window 1, Window 2, Window 3)은 간과 간암 조직 사이의 경계값에 민감하게 특화되어 있어, 간과 간암의 조영 값의 분포 를 구별하는데 특화되거나(Window 1), 간암 조직과 다른 조직간의 차이를 구별하는데 특화되는 모습이 도시된다 (Window 2, Window 3). 도 16을 통하여 제1 인공 신경망이 기존의 영상 분석 모듈이 영역을 분별하는데 최적화된 Hounsfield Unit 범위를 포커싱하여 제공하고, 불필요한 조영 범위를 제거함으로써 기존의 영상 분석 모듈의 성능을 향상시키는 것으로 이해할 수 있다.본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 전 처리, 분석 지원, 및/또는 분석 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구 현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있 다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체 (magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장 하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지 는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코 드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작 동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 그러나, 본 발명이 실시예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 본 발명의 실시예와 도면에 소개된 길이, 높이, 크기, 폭 등은 이해를 돕기 위해 과장 된 것일 수 있다. 이상과 같이 본 발명에서는 구체적인 구성 요소 등과 같은 특정 사항들과 한정된 실시예 및 도면에 의해 설명되 었으나 이는 본 발명의 보다 전반적인 이해를 돕기 위해서 제공된 것일 뿐, 본 발명은 상기의 실시예에 한정되 는 것은 아니며, 본 발명이 속하는 분야에서 통상적인 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및변형이 가능하다. 따라서, 본 발명의 사상은 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등하거나 등가적 변형이 있는 모든 것들은 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2019-0140605", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 전처리 및 분석 장치의 훈련/ 학습 과정을 도시하는 도면이다. 도 2는 도 1의 영상 전처리 및 분석 장치를 이용한 추론 과정을 도시하는 도면이다. 도 3은 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 전처리 장치의 훈련/학습 과정 을 도시하는 도면이다. 도 4는 도 3의 영상 전처리 장치를 이용한 추론 과정을 도시하는 도면이다. 도 5는 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 분석 지원 장치의 훈련/학습 과정을 도시하는 도면이다. 도 6은 도 5의 영상 분석 지원 장치를 이용한 추론 과정을 도시하는 도면이다. 도 7은 본 발명의 일 실시예에 따른 머신 러닝 기반의 인공지능을 이용하는 영상 분석 장치의 훈련/학습 과정을 도시하는 도면이다. 도 7은 도 8의 영상 분석 장치를 이용한 추론 과정을 도시하는 도면이다. 도 9는 본 발명의 일부를 구성하는 CT 윈도우잉 과정을 설명하는 도면이다. 도 10은 본 발명의 일 실시예에 따른 복수의 윈도우잉 전처리 모듈에서 생성되는 windowed images의 예시를 도 시하는 도면이다. 도 11은 본 발명의 일 실시예에 따른 영상 전처리 및/또는 영상 분석 장치에서, 영상 분석을 효과적으로 지원하 기 위한 전처리 데이터 생성 과정을 도시하는 도면이다. 도 12는 본 발명의 비교예로서, 1개의 전처리 조건을 이용하는 인공 신경망이 간과 간암 영역을 검출한 결과를 도시하는 도면이다.도 13과 도 14는 본 발명의 실시예들로서, 복수의 전처리 모듈과 인공 신경망이 함께 훈련되는 네트워크 구조에 서 간과 간암 영역을 검출한 결과를 도시하는 도면이다. 도 15와 도 16은 본 발명의 또 다른 일 실시예에서 복수의 전처리 모듈과 인공 신경망이 영상 분석 모듈과 함께 훈련되는 네트워크 구조에서 간과 간암 영역을 검출한 결과를 도시하는 도면이다."}
