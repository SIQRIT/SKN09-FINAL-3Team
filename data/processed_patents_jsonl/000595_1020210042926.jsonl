{"patent_id": "10-2021-0042926", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0137220", "출원번호": "10-2021-0042926", "발명의 명칭": "인공지능 기반의 의료 영상 3차원 변환 장치 및 방법", "출원인": "고려대학교 산학협력단", "발명자": "안경식"}}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 의료 영상 3차원 변환 방법에 있어서,대상자의 2차원 의료 영상인 제1학습 영상 및 상기 대상자의 3차원 의료 영상인 제2학습 영상을 포함하는 학습데이터를 수집하는 단계;상기 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영상이 입력되면 상기 대상 영상에 기초하여 상기 대상영상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생성하는 인공지능 모델을 학습시키는 단계;상기 대상 영상을 수신하는 단계; 및상기 인공지능 모델에 기초하여 상기 변환 영상을 생성하는 단계,를 포함하는, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 모델을 학습시키는 단계는,생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 상기 인공지능 모델을 학습시키는것인, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1학습 영상 및 상기 대상 영상은 엑스레이 영상이고,상기 제2학습 영상은 컴퓨터 단층촬영(Computed Tomography, CT) 영상인 것인, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 인공지능 모델을 학습시키는 단계는,상기 제1학습 영상에 기초하여 상기 변환 영상을 생성하고, 상기 변환 영상의 진위 여부를 상기 제2학습 영상에기초하여 판별하는 단계,를 포함하는 것인, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 인공지능 모델을 학습시키는 단계는,상기 제2학습 영상에 기초하여 가상의 2차원 변환 영상을 생성하고, 상기 2차원 변환 영상의 진위 여부를 상기제1학습 영상에 기초하여 판별하는 단계,를 더 포함하는 것인, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 변환 영상으로부터 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 도출하는공개특허 10-2022-0137220-3-단계;상기 투과 이미지 및 상기 대상 영상을 합성하는 단계; 및상기 합성 결과에 기초하여 상기 변환 영상을 보정하는 단계,를 더 포함하는 것인, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 학습 데이터를 수집하는 단계는,상기 제1학습 영상 및 상기 제2학습 영상 내의 골절 부위를 마킹하는 단계,를 포함하고,상기 학습시키는 단계는,상기 마킹된 학습 데이터에 기초하여 상기 대상 영상에 대한 골절 유무 정보 및 골절 영역의 위치 정보를 도출하는 상기 인공지능 모델을 학습시키는 것인, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 골절 영역이 시각적으로 식별되도록 상기 변환 영상을 표출하는 단계,를 더 포함하는 것인, 변환 방법."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능 기반의 의료 영상 3차원 변환 장치에 있어서,대상자의 2차원 의료 영상인 제1학습 영상 및 상기 대상자의 3차원 의료 영상인 제2학습 영상을 포함하는 학습데이터를 수집하는 수집부;상기 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영상이 입력되면 상기 대상 영상에 기초하여 상기 대상영상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생성하는 인공지능 모델을 학습시키는 학습부; 및상기 대상 영상을 수신하고, 상기 인공지능 모델에 기초하여 상기 변환 영상을 생성하는 변환부,를 포함하는, 변환 장치."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 학습부는,생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 상기 인공지능 모델을 학습시키는것인, 변환 장치."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제1학습 영상 및 상기 대상 영상은 엑스레이 영상이고,상기 제2학습 영상은 컴퓨터 단층촬영(Computed Tomography, CT) 영상인 것인, 변환 장치."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 학습부는,공개특허 10-2022-0137220-4-상기 제1학습 영상에 기초하여 상기 변환 영상을 생성하고, 상기 변환 영상의 진위 여부를 상기 제2학습 영상에기초하여 판별하는 순방향(Forward) 학습부; 및상기 제2학습 영상에 기초하여 가상의 2차원 변환 영상을 생성하고, 상기 2차원 변환 영상의 진위 여부를 상기제1학습 영상에 기초하여 판별하는 역방향(Backward) 학습부,를 포함하는 것인, 변환 장치."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 변환 영상으로부터 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 도출하고,상기 투과 이미지 및 상기 대상 영상을 합성하고, 상기 합성 결과에 기초하여 상기 변환 영상을 보정하는 보정부,를 더 포함하는 것인, 변환 장치."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 수집부는,영상 내의 골절 부위가 마킹된 상기 제1학습 영상 및 상기 제2학습 영상을 상기 학습 데이터로서 수집하고,상기 학습부는,상기 마킹된 학습 데이터에 기초하여 상기 대상 영상에 대한 골절 유무 정보 및 골절 영역의 위치 정보를 도출하는 상기 인공지능 모델을 학습시키는 것인, 변환 장치."}
{"patent_id": "10-2021-0042926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 골절 영역이 시각적으로 식별되도록 상기 변환 영상을 표출하는 표시부,를 더 포함하는 것인, 변환 장치."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 의료 영상 3차원 변환 장치 및 방법이 개시되며, 본원의 일 실시예에 따른 인공지능 기반의 의 료 영상 3차원 변환 방법은, 대상자의 2차원 의료 영상인 제1학습 영상 및 상기 대상자의 3차원 의료 영상인 제2 학습 영상을 포함하는 학습 데이터를 수집하는 단계, 상기 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영 상이 입력되면 상기 대상 영상에 기초하여 상기 대상 영상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생 성하는 인공지능 모델을 학습시키는 단계, 상기 대상 영상을 수신하는 단계 및 상기 인공지능 모델에 기초하여 상기 변환 영상을 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 인공지능 기반의 의료 영상 3차원 변환 장치 및 방법에 관한 것이다. 예를 들면, 본원은 인공지능에 기 반한 2차원 골격 엑스레이 영상의 3차원 자동 변환 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "골절 검사를 위한 가장 기본적인 검사는 엑스레이(X-Ray) 검사이며, 이러한 엑스레이 검사는 간편하게 촬영 가 능하다는 이점이 있으나, 이차원 의료 영상을 통해 골절을 진단하기 때문에 뼈가 중첩되는 부위나 해부학적인 복잡도가 높은 부위에 대한 골절 진단에 활용하기에는 제한점이 존재한다. 이러한 이차원 의료 영상의 한계를 극복하기 위해 컴퓨터 단층촬영(Computed Tomography, CT) 등 삼차원 의료 영상을 획득하기 위한 검사를 수행하게 되나 통상적으로 컴퓨터 단층촬영(Computed Tomography, CT) 등 삼차원 의료 영상을 획득하기 위한 계측 장비는 어느 정도 규모가 있는 의료 기관에만 구비되며, 대상자의 신체에 과도 한 방사선을 노출시키는 단점이 있다. 따라서, 엑스레이 영상 등 이차원 의료 영상을 활용하여 촬영된 대상자의 신체 부위에 대한 입체적인 정보를 제 공할 수 있는 삼차원 의료 영상을 구축하고, 삼차원 변환된 의료 데이터에 기초하여 골절의 정도, 골편의 방향 등을 정밀하게 확인하도록 하여 의료진의 의사 결정에 도움을 주고, 골절 진단에 대한 효율성과 정확성을 향상 시킬 수 있는 방안의 개발이 요구된다.본원의 배경이 되는 기술은 한국등록특허공보 제10-2197635호에 개시되어 있다."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 동일 대상자에 대하여 촬영된 2차원 의료 영상 및 3차원 의료 영상 세트를 학습 데이터로 활용하여 2차원의 대상 영상이 입력되면, 이에 대응하는 가상의 3차 원 변환 영상을 제공하는 인공지능 기반의 의료 영상 3차원 변환 장치 및 방법을 제공하려는 것을 목적으로 한 다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 방법은, 대상자의 2차원 의료 영상인 제1학습 영상 및 상기 대상자의 3차원 의료 영상인 제2학습 영 상을 포함하는 학습 데이터를 수집하는 단계, 상기 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영상이 입 력되면 상기 대상 영상에 기초하여 상기 대상 영상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생성하는 인공지능 모델을 학습시키는 단계, 상기 대상 영상을 수신하는 단계 및 상기 인공지능 모델에 기초하여 상기 변 환 영상을 생성하는 단계를 포함할 수 있다. 또한, 상기 인공지능 모델을 학습시키는 단계는, 생성적 대립 신경망(Generative Adversarial Network) 알고리 즘에 기초하여 상기 인공지능 모델을 학습시킬 수 있다. 또한, 상기 제1학습 영상 및 상기 대상 영상은 엑스레이 영상일 수 있다. 또한, 상기 제2학습 영상은 컴퓨터 단층촬영(Computed Tomography, CT) 영상일 수 있다. 또한, 상기 인공지능 모델을 학습시키는 단계는, 상기 제1학습 영상에 기초하여 상기 변환 영상을 생성하고, 상 기 변환 영상의 진위 여부를 상기 제2학습 영상에 기초하여 판별하는 단계를 포함할 수 있다. 또한, 상기 인공지능 모델을 학습시키는 단계는, 상기 제2학습 영상에 기초하여 가상의 2차원 변환 영상을 생성 하고, 상기 2차원 변환 영상의 진위 여부를 상기 제1학습 영상에 기초하여 판별하는 단계를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 방법은, 상기 변환 영상으로부터 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 도출하는 단계, 상기 투과 이미지 및 상기 대상 영상을 합성하는 단계 및 상기 합성 결과에 기초하여 상기 변환 영상을 보정하는 단계를 포함할 수 있다. 또한, 상기 학습 데이터를 수집하는 단계는, 상기 제1학습 영상 및 상기 제2학습 영상 내의 골절 부위를 마킹하 는 단계를 포함할 수 있다. 또한, 상기 학습시키는 단계는, 상기 마킹된 학습 데이터에 기초하여 상기 대상 영상에 대한 골절 유무 정보 및 골절 영역의 위치 정보를 도출하는 상기 인공지능 모델을 학습시킬 수 있다. 또한, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 방법은, 상기 골절 영역이 시각적으로 식별되도록 상기 변환 영상을 표출하는 단계를 포함할 수 있다. 한편, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치는, 대상자의 2차원 의료 영상인 제 1학습 영상 및 상기 대상자의 3차원 의료 영상인 제2학습 영상을 포함하는 학습 데이터를 수집하는 수집부, 상 기 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영상이 입력되면 상기 대상 영상에 기초하여 상기 대상 영 상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생성하는 인공지능 모델을 학습시키는 학습부 및 상기 대 상 영상을 수신하고, 상기 인공지능 모델에 기초하여 상기 변환 영상을 생성하는 변환부를 포함할 수 있다. 또한, 상기 학습부는, 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 상기 인공지 능 모델을 학습시킬 수 있다. 또한, 상기 학습부는, 상기 제1학습 영상에 기초하여 상기 변환 영상을 생성하고, 상기 변환 영상의 진위 여부 를 상기 제2학습 영상에 기초하여 판별하는 순방향(Forward) 학습부 및 상기 제2학습 영상에 기초하여 가상의 2차원 변환 영상을 생성하고, 상기 2차원 변환 영상의 진위 여부를 상기 제1학습 영상에 기초하여 판별하는 역방 향(Backward) 학습부를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치는, 상기 변환 영상으로부터 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 도출하고, 상기 투과 이미지 및 상기 대상 영상을 합성하고, 상기 합성 결과에 기초하여 상기 변환 영상을 보정하는 보정부를 포함할 수 있다. 또한, 상기 수집부는, 영상 내의 골절 부위가 마킹된 상기 제1학습 영상 및 상기 제2학습 영상을 상기 학습 데 이터로서 수집할 수 있다. 또한, 상기 학습부는, 상기 마킹된 학습 데이터에 기초하여 상기 대상 영상에 대한 골절 유무 정보 및 골절 영 역의 위치 정보를 도출하는 상기 인공지능 모델을 학습시킬 수 있다. 또한, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치는, 상기 골절 영역이 시각적으로 식별되도록 상기 변환 영상을 표출하는 표시부를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 동일 대상자에 대하여 촬영된 2차원 의료 영상 및 3차원 의료 영상 세 트를 학습 데이터로 활용하여 2차원의 대상 영상이 입력되면, 이에 대응하는 가상의 3차원 변환 영상을 제공하 는 인공지능 기반의 의료 영상 3차원 변환 장치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, CT 스캐너 등 3차원 의료 영상을 촬영하기 위한 고가의 장비를 구비하 지 않은 의료 기관에서도 2차원 의료 영상을 가상의 3차원 변환 영상으로 변환하여 의료진에게 제공함으로써, 의료진의 의사 결정을 보조할 뿐만 아니라, 대상자에 대한 방사선 노출을 줄일 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 동일 대상자에 대하여 촬영된 2차원 의료 영상 및 3차원 의료 영상 세 트를 활용하여 인공지능 모델을 학습시킴으로써 다양한 방향에서 촬영된 대상 영상이 확보되지 않더라도 대상자 의 신체 부위에 대한 입체적인 정보를 제공하는 가상의 3차원 의료 영상을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 간단한 엑스레이 검사만으로도 3차원 영상을 재구성하여 골절의 정도 및 골편의 방향 등의 골절 관련 정보를 의료진이 용이하게 확인할 수 있도록 보조하며, 골절 부위를 자동 표시 해줌으로써 의료진의 골절 진단에 대한 효율성 및 정확성을 향상시킬 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 인공지능 기반의 의료 영상 3차원 변환 장치 및 방법에 관한 것이다. 예를 들면, 본원은 인공지능에 기 반한 2차원 골격 엑스레이 영상의 3차원 자동 변환 장치 및 방법에 관한 것이다. 도 1은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치를 포함하는 의료 영상 제공 시스 템의 개략적인 구성도이다. 도 1을 참조하면, 본원의 일 실시예에 따른 의료 영상 제공 시스템은 본원의 일 실시예에 따른 인공지능 기 반의 의료 영상 3차원 변환 장치(이하, '변환 장치'라 한다.), 학습 DB, 의료 영상 촬영 장치 및 사용자 단말을 포함할 수 있다. 한편, 의료 영상 제공 시스템은 병원, 의료기관 등과 연계하여 구축되는 의료 영상 저장/전송 시스템 (Picture Archiving and Communication System, PACS)을 지칭하는 것일 수 있으며, 변환 장치는 의료 영 상 제공 시스템에 포함되는 의료 영상 촬영 장치에 의해 촬영된 의료 영상을 의료 영상 촬영 장치 로부터 대상 영상으로서 획득하여, 대상 영상에 대응하는 가상의 변환 영상을 출력하는 별도의 디바이스로 구현되거나 의료 영상 촬영 장치에 탑재되는 형태(예를 들면, 의료 영상 촬영 장치에 설치되는 소프 트웨어, 프로그램 형태 등)로 구현되는 것일 수 있다. 변환 장치, 학습 DB, 의료 영상 촬영 장치 및 사용자 단말 상호간은 네트워크를 통해 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조 를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 학습 DB는 이하에서 상세히 후술하는 변환 장치의 인공지능 모델을 생성하는 훈련(Training) 과정에 서 활용되는 학습 데이터를 저장하는 데이터베이스, 서버 등일 수 있다. 보다 구체적으로, 학습 DB는 대상 자의 2차원 의료 영상인 제1학습 영상 및 해당 대상자(동일 대상자)의 3차원 의료 영상인 제2학습 영상을 포함 하는 학습 데이터를 저장할 수 있다. 또한, 학습 DB는 복수의 대상자 각각에 대한 제1학습 영상 및 제2학 습 영상을 포함하는 학습 데이터 셋을 보유하는 것일 수 있다. 의료 영상 촬영 장치는 변환 장치에 의해 3차원 의료 영상으로 변환될 대상 영상을 촬영하는 디바이 스일 수 있다. 달리 말해, 의료 영상 촬영 장치에 의해 촬영된 대상 영상은 변환 장치로 전달되어 가 상의 3차원 의료 영상이 변환 영상으로 변환될 수 있다. 본원의 일 실시예에 따르면, 의료 영상 촬영 장치는 X-선 촬영 장치일 수 있으나, 이에만 한정되는 것은 아니다. 다른 예로, 의료 영상 촬영 장치는 자기공명영상(Magnetic Resonance Imaging, MRI) 스캐너, 초 음파 영상 촬영 장치, 컴퓨터 단층촬영(Computerized Tomography, CT) 스캐너 등일 수 있다. 또한, 의료 영상 촬영 장치의 유형에 따라 변환 장치로 제공되는 의료 영상(달리 말해, 후술하는 대상 영상 등)은 X- 선 영상, 자기공명영상(MRI) 영상, CT 이미지, 초음파 영상 등에 해당할 수 있다. 구체적으로, 본원의 일 실시예에 따르면, 의료 영상 촬영 장치에 의해 획득되는 대상 영상, 후술하는 인공 지능 모델의 구축을 위한 학습 데이터 셋으로 활용되는 제1학습 영상 및 제2학습 영상은 DICOM(Digital Imaging and Communications in Medicine) 이미지일 수 있다. 사용자 단말은 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 예를 들어, 사용자 단말은 대상 영상 및 대상 영상으로부터 변환된 가상의 3차원 의료 영상인 변환 영상 중 적 어도 하나를 출력하는 디바이스일 수 있다. 이하에서는, 도 2 및 도 3을 참조하여 변환 장치의 구체적인 기능 및 동작에 대해 상세히 설명하도록 한다. 도 2는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치에 의해 수행되는 의료 영상의 3차 원 변환 기법의 전체 프로세스를 개략적으로 나타낸 개념도이다. 도 2를 참조하면, 변환 장치는 대상자의 2차원 의료 영상인 제1학습 영상 및 해당 대상자의 3차원 의료 영 상인 제2학습 영상을 포함하는 학습 데이터를 수집할 수 있다. 구체적으로, 변환 장치는 동일 대상자에 대 한 한 쌍의(Paired) 제1학습 영상 및 제2학습 영상을 학습 데이터로서 수집할 수 있다. 또한, 변환 장치는 복수의 대상자 각각에 대하여 2차원 의료 영상인 제1학습 영상 및 3차원 의료 영상인 제2학습 영상을 함께 수집하여 후술하는 인공지능 모델의 학습을 위한 데이터 셋으로 활용할 수 있다. 또한, 변환 장치는 의료 영상 촬영 장치에 의해 촬영된 의료 영상을 학습 영상으로서 의료 영상 촬영 장치로부터 수집하는 것일 수 있으나, 이에만 한정되는 것은 아니며, 의료 영상 제공 시스템 내의 의 료 영상 촬영 장치 외의 별도의 경로(예를 들면, 외부 저장 장치, 외부 서버, 기 구축된 학습 DB 등)로 학습 영상을 수집하는 것일 수 있다. 보다 구체적으로, 본원의 일 실시예에 따르면, 제1학습 영상 및 대상 영상은 2차원의 엑스레이 영상이고, 제2학 습 영상은 컴퓨터 단층촬영(Computed Tomography, CT) 영상일 수 있다. 이와 관련하여, 2차원의 엑스레이 영상 인 대상 영상으로부터 도출되는 본원에서의 '변환 영상'은 가상의 3차원 컴퓨터 단층촬영(Computed Tomography, CT) 영상을 의미할 수 있다. 또한, 변환 장치는 수집된 학습 데이터(제1학습 영상 및 제2학습 영상)에 대한 전처리(Pre-processing)를 수행할 수 있다. 예를 들어, 변환 장치는 제1학습 영상 및 제2학습 영상 각각의 밝기 정보 범위(Range)가 표준화(정규화)되지 않을 수 있는 점을 고려하여 이를 통일적으로 처리하기 위하여, 수집된 학습 영상 각각의 DICOM 이미지 헤더 정보를 기초로, 최소 밝기 및 최대 밝기를 결정함으로써 학습 영상에 대한 밝기 정보 범위 (Range)를 표준화(정규화)하는 전처리를 수행할 수 있으나, 이에만 한정되는 것은 아니다. 또한, 변환 장치는 수집된 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영상이 입력되면, 입력된 대 상 영상에 기초하여 대상 영상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생성하는 인공지능 모델을 학 습시킬 수 있다. 구체적으로, 변환 장치는 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 변 환 영상 재구성을 위한 인공지능 모델을 학습시킬 수 있다. 여기서, 생성적 대립 신경망(Generative Adversarial Network) 알고리즘은, 생성기(Generator)와 판별기 (Discriminator)가 경쟁하면서 학습이 이루어져 실제와 흡사한 결과물(예를 들면, 이미지, 동영상, 음성 등)을 자동으로 만들어 내도록 하는 기계학습(Machine Learning) 방식의 하나로, 본원의 일 실시예에 따르면, 변환 장 치는 수집된 학습 영상을 기초로 가상의 모사 영상(이미지)을 만드는 생성기(Generator)와 생성된 모사 영 상(이미지)의 진위를 가리는 판별기(Discriminator)를 포함하고, 이러한 생성기(Generator)와 판별기 (Discriminator)가 반복적으로 경쟁하도록 하여 학습이 진행된 후의 생성기(Generator)가 판별기 (Discriminator)에 의해 진위를 가리기 힘든 수준까지 잘 모사된 영상을 생성하도록 학습되는 것일 수 있다. 즉, 본원의 일 실시예에 따르면, 변환 장치는 생성적 대립 신경망(Generative Adversarial Network) 알고 리즘에 기초하여, 생성기(Generator)가 2차원 의료 영상인 제1학습 영상에 기초하여 가상의 3차원 의료 영상인 변환 영상을 생성하고, 판별기(Discriminator)가 생성된 변환 영상의 진위 여부를 제2학습 영상에 기초하여 판별하는 과정을 반복 수행하는 것일 수 있다. 또한, 본원의 일 실시예에 따르면, 변환 장치는 순방향(Forward) 사이클 및 역방향(Backward) 사이클을 포 함하는 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 인공지능 모델을 학습시키는 것일 수 있다. 여기서, 순방향(Forward) 사이클 및 역방향(Backward) 사이클을 포함하는 생성적 대립 신경망 (Generative Adversarial Network) 알고리즘은 CycleGAN 등으로 달리 지칭될 수 있다. 이와 관련하여, 변환 장치는 2차원 의료 영상인 제1학습 영상에 기초하여 가상의 의료 영상(모사 영상)인 3차원 변환 영상을 생성하는 제1생성기(미도시) 및 생성된 3차원 변환 영상의 진위 여부를 판단하는 제1판별기 (미도시)를 통한 순방향(Forward) 학습을 수행할 수 있다. 또한, 이와 대응되게 변환 장치는 3차원 의료 영상인 제2학습 영상에 기초하여 가상의 2차원 의료 영상(모 사 영상)인 2차원 변환 영상을 생성하는 제2생성기(미도시) 및 2차원 변환 영상의 진위 여부를 판단하는 제2판 별기(미도시)를 통한 역방향(Backward) 학습을 수행할 수 있다. 구체적으로, 순방향 학습을 위한 제1판별기는 제1생성기에 의해 생성된 모사 영상인 3차원 변환 영상의 진위 여 부를 실제로 촬영된 3차원 의료 영상인 제2학습 영상 중 적어도 일부에 기초하여 판별하는 것일 수 있다. 마찬가지로, 역방향 학습을 위한 제2판별기는 제2생성기에 의해 생성된 모사 영상인 2차원 변환 영상의 진위 여 부를 실제로 촬영된 2차원 의료 영상인 제1학습 영상 중 적어도 일부에 기초하여 판별하는 것일 수 있다. 종합하면, 변환 장치는 입력된 2차원 의료 영상을 기초로 가상의 3차원 변환 영상을 반복하여 생성(재구성)하는 과정과, 생성된 3차원 변환 영상의 진위 여부를 반복하여 판별하는 과정의 경쟁적인 반복 수 행을 통해 대상 영상에 대한 3차원 재구성 프로세스를 보다 정밀하게 수행하도록 하는 순방향 학습(Forward Cycle) 및 입력된 3차원 의료 영상을 기초로 가상의 2차원 변환 영상을 반복하여 생성하는 과정과, 생성된 2차 원 변환 영상의 진위 여부를 반복하여 판별하는 과정의 경쟁적인 반복 수행을 통해 전술한 3차원 재구성 프로세 스의 정확도(정밀도)를 향상시키는 역방향 학습(Backward Cycle)을 순환하여 수행할 수 있다. 상술한 바와 같이 각기 반대되는 방향으로의 영상 재구성을 위한 두 가지의 구분되는 학습 사이클이 반복되는 생성적 대립 신경망(예를 들면, CycleGAN) 기반의 인공지능 모델의 학습을 통해 학습이 완료된 본원에서의 인공 지능 모델은 대상자의 2차원 의료 영상(예를 들면, 엑스레이 영상)을 해당 대상자의 촬영 부위에 대한 3차원 볼 륨(Volume) 데이터를 반영하도록 모사되는 이종 유형의 3차원 가상 변환 영상(예를 들면, 3차원 CT 영상)으로 변환하는 동작과 이와 반대되게 3차원 의료 영상(예를 들면, 3차원 CT 영상)을 이에 대응되는 이종 유형의 가상 의 2차원 변환 영상(예를 들면, 엑스레이 영상)으로 변환하는 동작을 모두 수행할 수 있다. 이렇듯, 변환 장치를 통해 구축(학습)되는 인공지능 모델은 대상자의 신체 중 대상 영상에 반영된 소정의 부위와 연계된 형태학적(morphological) 특징의 변화를 반영하여 3차원 볼륨(Volume) 데이터를 예측(추론)하고, 대상 영상에 대응하는 가상의 3차원 변환 영상(모사 영상)을 생성할 수 있게 된다. 이와 관련하여, 변환 장치가 제1학습 영상과 제2학습 영상을 모두 활용한 양방향 변환(예를 들면, 합성 및 복구)이 모두 가능한 인공지능 모델을 구축함으로써, 단방향(예를 들면, 2차원 의료 영상을 3차원 재구성하는 단일 방향)으로의 변환만을 수행하도록 하는 학습만을 진행하는 경우, 생성기(Generator)가 오직 판별기 (Discriminator)를 속이기 위하여 소정의 부위의 대상자의 자세에 따른 형태학적 특징 변화를 고려하지 못하는 낮은 수준의 모사 영상을 출력하게 되는 문제를 방지할 수 있다. 또한, 본원의 일 실시예에 따르면, 변환 장치는 수집된 학습 영상과 생성기(Generator)에 의해 생성되는 모사 영상 사이의 변화 정보 및 촬영 대상 영역인 소정의 부위의 기하학적(Geometric) 정보를 고려하여 전술한 인공지능 모델의 학습을 수행할 수 있다. 달리 말해, 변환 장치는 제1학습 영상과 3차원 변환 영상 사이의 변화 정보 및 소정의 부위의 기하학적 정 보를 고려하여 순방향 학습을 수행하고, 제2학습 영상과 2차원 변환 영상 사이의 변화 정보 및 소정의 부위의 기하학적 정보를 고려하여 역방향 학습을 수행하는 것일 수 있다. 도 3은 대상 영상을 가상의 3차원 의료 영상으로 변환하는 인공지능 모델을 학습시키는 과정을 설명하기 위한 개념도이다. 도 3을 참조하면, 변환 장치는 인코더(Encoder) 측의 다운 샘플링(Down Sampling) 결과에 기초하여 도출되 는 활성화맵(Activation map)을 활용하여 입력된 학습 영상(Source)으로부터 출력된 가상의 모사 영상(Destination) 사이의 변화량을 파악하고(Weighted Activation Map), 이를 인공지능 모델 학습에서의 손실 (Loss) 함수에 반영함으로써, 학습 영상과 모사 영상 사이의 변화 정보를 고려한 학습을 수행할 수 있다. 본원의 일 실시예에 따르면, 활성화맵(Activation map)은 Grad-CAM(gradient-class activation map) 및 Score- CAM을 포함하는 다중 클래스 활성화맵(Multi-Class Activation Map)일 수 있고, 이러한 다중 클래스 활성화맵 (Multi-Class Activation Map)과 연계된 다중 주의맵(M-attentionMap)은 하기 식 3을 통해 도출될 수 있다. 한 편, 다중 클래스 활성화맵은 혼합 맵(Mixed Map) 등으로 달리 지칭될 수 있다. [식 1]"}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 이러한 다중 클래스 활성화맵(Multi-Class Activation Map)은 입력된 의료 영상에 기초하여 가상의 3차원 변환 영상을 생성하는 과정에서 주요하게 변환된 영역인 근거 영역을 도출하도록 활용되는 것일 수 있다. 또한, 인공지능 모델을 구축하기 위한 학습 과정에서 소정의 부위(예를 들면, 척추 영역)의 기하학적 정보가 고 려된다는 것은, 구체적으로, 본원에서 인공지능 모델 학습에 적용되는 손실(Loss) 함수를 나타내는 하기 식 2에 서 확인할 수 있는 바와 같이 소정의 부위의 특정 지역의 기하학적 정보의 부분적인 변화에 대응하는 텀 (LGeometry)을 포함되는 것으로 이해될 수 있다. [식 2]"}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "구체적으로, 식 2를 참조하면, 본원에서의 인공지능 모델의 학습을 위한 손실 함수는 종래의 CycleGAN의 손실 텀(LGAN + Lcycle + Lidentity) 뿐만 아니라, 다중 클래스 활성화맵에 기초하여 파악되는 입력된 학습 영상(Source)으 로부터 출력된 가상의 모사 영상(Destination) 사이의 변화량을 반영하는 손실 텀(Lmcam) 및 촬영 대상인 소정의 부위의 국부적인 특이 변화량을 반영하는 손실텀(LGeometry)을 포함할 수 있다. 또한, 본원의 일 실시예에 따르면, 본원에서의 인공지능 모델의 학습을 위한 손실 함수는 정합 손실 (Registration loss, R-loss) 텀을 포함할 수 있다. 구체적으로, 정합 손실은 하기 식 3과 같이 연산될 수 있다. [식 3]"}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "구체적으로, 변환 장치는 중복 포인트 세트로 이루어진 그룹(D)을 포함하는 데이터 세트에 대한 정합 손실 을 최소화하도록 특성 추출기(Feature Extractor)의 매개 변수를 학습시킬 수 있다. 전술한 과정을 통해 인공지능 모델의 학습(훈련)이 완료되면, 변환 장치는 대상 영상을 수신할 수 있다. 예시적으로, 변환 장치는 의료 영상 촬영 장치로부터 3차원 재구성(변환)할 대상 영상을 수신할 수 있다. 또한, 변환 장치는 수신된 대상 영상을 앞서 학습(구축)된 인공지능 모델에 기초하여 3차원 재구성함으로 써 변환 영상을 생성할 수 있다. 보다 구체적으로, 변환 장치는 학습 데이터에 반영된 다수의 대상자에 대 한 2차원 의료 영상(예를 들면, 엑스레이 영상)과 동일한 대상자의 3차원 의료 영상(예를 들면, CT 영상)의 형 태학적 특징(morphological)을 학습함으로써, 새로이 2차원 의료 영상인 대상 영상이 인가되면, 2차원 의료 영 상과 3차원 의료 영상 간의 기하학적 변화(geometric change)를 고려하여 해당 대상자의 가상의 3차원 입체 볼 륨을 생성함으로써 변환 영상을 생성할 수 있다(Image To Image). 한편, 본원의 일 실시예에 따르면, 변환 장치는 대상 영상을 기초로 3차원 변환된 변환 영상으로부터 도출 되는 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 기초로 대상 영상을 재차 합 성함으로써 가상의 3차원 볼륨 데이터가 정확도 높게 생성되도록 하여 변환 영상을 보정할 수 있다.구체적으로, 변환 장치는 1차적으로 생성된 변환 영상으로부터 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 도출하고, 도출된 투과 이미지(도 3의 Simulated 2D image, DRR) 및 기 입 력된 대상 영상(도 3의 Acquired 2D image)을 합성하고, 합성 결과에 기초하여 변환 영상을 보정하는 동작(도 3 의 Registration → Optimized image)을 수행할 수 있다. 한편, 도 2를 참조하면, 변환 장치에 의해 생성되는 인공지능 모델은 입력된 대상 영상(2차원 엑스레이 영 상)을 가상의 3차원 변환 영상(모사된 3차원 CT 영상)으로 재구성하는 동작과 함께, 대상 영상으로부터 골절과 관련된 정보를 추출하는 동작을 수행하도록 구축될 수 있다. 이와 관련하여, 변환 장치는 학습 데이터를 수집하는 과정에서 제1학습 영상 및 제2학습 영상 내의 골절 부위를 마킹할 수 있다. 도 4는 학습 영상의 골절 부위를 포함하는 영역에 대한 마킹 결과를 예시적으로 나타낸 도면이다. 도 4를 참조하면, 변환 장치는 제1학습 영상 및 제2학습 영상에 포함된 적어도 하나 이상의 골절 부위를 포함하는 영역을 미리 설정된 도형 형상에 기초하여 마킹할 수 있다. 또한, 도 4를 참조하면, 골절 부위를 포함 하는 영역에 대한 마킹을 위한 도형 형상은 예시적으로 원형 또는 타원형일 수 있다. 이와 관련하여, 골절 영역에 대한 마킹 기법은 크게 두 종류로 구분될 수 있는데, 첫 번째는 골절 영역을 포위 하는 테두리 선으로 이루어진 사각형 등의 다각형 형상의 경계 박스(Bounding Box)를 표시하여 마킹하는 방식이 고, 두 번째는 골절이 발생한 영역의 색상을 구분되게 표시하는 방법이다. 먼저, 경계 박스 기반 방식에 의할 때, 표시되는 하나의 경계 박스가 하나의 골절 부위에 대응될 수 있으나, 뼈 의 골절이 발생하는 경우에 각각의 골절 영역은 주로 밀집되어 있으며, 골절의 수(상호 구분되는 골절 부위의 개수)를 특정하기 모호한 특성이 크기 때문에 적합하지 않을 수 있다. 한편, 골절이 발생한 영역을 구분되는 색상으로 표시(마킹)하는 방식의 경우에는, 다시 골절이 발생한 뼈를 표 시하는 방법과 단순히 골절영역을 표시하는 방법으로 구분될 수 있는데, 전자의 경우는 표시해야 하는 뼈의 시 작 부위와 끝 부위를 특정하기 어렵고, 골절이 발생한 것이 아닌데도 구분되어 표시된 두 뼈 사이에 단순히 공 간이 존재하는 경우에도 진단 모델이 이를 최종적으로 골절 부위로 오인할 수 있는 가능성이 크기 때문에 부적 합할 수 있다. 따라서, 본원에서 개시하는 변환 장치는 협소한 영역 내에서 발생하는 골절과 연계된 정보를 효과적으로 도출하는 인공지능 모델을 정밀하게 학습시키기 위하여 골절 부위를 원형 또는 타원형의 브러쉬를 이용하여 마 킹하는 방식으로 학습 데이터를 준비할 수 있다. 이에 따라, 변환 장치는 단순한 브러쉬 방식의 전처리를 통해 신속하게 학습 데이터를 준비할 수 있으며, 마킹된 골절 부위를 포함하는 영역이 원형 또는 타원으로 정형화된 형태를 가지기 때문에 인공지능 모델의 학습 이 용이하게 이루어질 수 있는 이점이 있다. 또한, 변환 장치는 준비된 학습 데이터에 기초하여, 대상 영상이 입력되면 입력된 대상 영상에 대한 골절 유무 정보 및 골절 영역의 위치 정보를 도출하도록 인공지능 모델을 학습시킬 수 있다. 예시적으로, 대상 영상 으로부터 골절과 연계된 정보를 도출하도록 학습되는 인공지능 모델은 앞서 설명한 대상 영상을 가상의 3차원 변환 영상으로 재구성하는 동작을 수행하는 인공지능 모델과 별개로 학습되는 것일 수 있으나, 이에만 한정되는 것은 아니다. 보다 구체적으로, 학습된 인공지능 모델의 출력인 골절 유무 정보 및 골절 영역의 위치 정보 중 골절 영역의 위 치 정보는 인공지능 모델에 기초하여 탐색된 골절 영역의 중심 좌표(예를 들면, (x, y) 형태 등)와 영역의 크기 (예를 들면, 너비 정보 및 높이 정보를 포함하는 (w, h) 형태 등)를 포함할 수 있다. 본원의 일 실시예에 따르면, 골절 관련 정보를 도출하도록 학습되는 인공지능 모델은 마킹된 학습 데이터인 골 절 데이터와 마킹이 미부여된 정상 데이터의 차이를 학습함으로써, 입력된 대상 영상으로부터 학습된 정상 데이 터의 특성에 부합하지 않는 소정의 특성이 도출되는 경우, 골절이 발생한 것으로 골절 유무 정보를 출력하도록 동작하고, 골절이 발생한 것으로 골절 유무 정보가 도출된 대상 영상에 대하여, 마킹이 부여된 골절 데이터의 마킹 영역의 특성과 대상 영상이 정상 데이터에 대응하지 않는 것으로 판단된 영역(비정상 영역)의 국부적인 특 성을 비교함으로써 골절 영역의 위치 정보를 도출하도록 동작하는 것일 수 있다. 또한, 변환 장치는 학습된 인공지능 모델에 기초하여 골절 영역의 위치 정보가 도출되면, 골절 영역이 시 각적으로 식별되도록 대상 영상 및 변환 영상 중 적어도 하나를 사용자 단말을 통해 표출할 수 있다. 달리 말해, 변환 장치는 골절 유무 정보 및 골절 위치 정보를 기초로 골절 진단을 위한 부분(영역)을 특정하고, 특정된 부분(영역)에 대한 국부적인 크롭(Crop) 영상과 대상 영상 및 변환 영상을 활용하여 골절 진단을 수행할 수 있으며, 나아가 골절 영역을 표시하는 동작 및 골절의 유형을 분류하는 동작 등 골절 진단과 연계된 다양한 기능을 수행할 수 있다. 도 5는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치의 개략적인 구성도이다. 도 5를 참조하면, 변환 장치는 수집부, 학습부, 변환부, 보정부 및 표시부를 포함할 수 있다. 또한, 도 5를 참조하면, 학습부는 순방향 학습부 및 역방향 학습부를 포함할 수 있다. 수집부는 대상자의 2차원 의료 영상인 제1학습 영상 및 대상자의 3차원 의료 영상인 제2학습 영상을 포함 하는 학습 데이터를 수집할 수 있다. 또한, 본원의 일 실시예에 따르면, 수집부는 영상 내의 골절 부위가 마킹된 제1학습 영상 및 제2학습 영상 을 학습 데이터로서 수집할 수 있다. 학습부는 수집된 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영상이 입력되면, 입력된 대상 영상에 기초하여 대상 영상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생성하는 인공지능 모델을 학습시킬 수 있다. 구체적으로, 순방향 학습부는 제1학습 영상에 기초하여 변환 영상을 생성하고, 생성된 변환 영상의 진위 여부를 제2학습 영상에 기초하여 판별할 수 있다. 또한, 역방향 학습부는 제2학습 영상에 기초하여 가상의 2차원 변환 영상을 생성하고, 생성된 2차원 변환 영상의 진위 여부를 제1학습 영상에 기초하여 판별할 수 있다. 또한, 본원의 일 실시예에 따르면, 학습부는 마킹된 학습 데이터에 기초하여 대상 영상에 대한 골절 유무 정보 및 골절 영역의 위치 정보를 도출하는 인공지능 모델을 학습시킬 수 있다. 변환부는 대상 영상을 수신하고, 인공지능 모델에 기초하여 수신된 대상 영상에 대응하는 가상의 3차원 의 료 영상인 변환 영상을 생성할 수 있다. 보정부는 생성된 변환 영상으로부터 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 도출하고, 도출된 투과 이미지 및 대상 영상을 합성한 결과에 기초하여 변환 영상을 보정할 수 있다. 표시부는 골절 영역이 시각적으로 식별되도록 변환 영상을 표출할 수 있다. 예를 들면, 표시부는 사 용자 단말을 통해 생성된 변환 영상을 표출(출력)할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 6은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 방법에 대한 동작 흐름도이다. 도 6에 도시된 인공지능 기반의 의료 영상 3차원 변환 방법은 앞서 설명된 변환 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 변환 장치에 대하여 설명된 내용은 인공지능 기반의 의료 영상 3차원 변환 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 6을 참조하면, 단계 S11에서 수집부는 대상자의 2차원 의료 영상인 제1학습 영상 및 대상자의 3차원 의 료 영상인 제2학습 영상을 포함하는 학습 데이터를 수집할 수 있다. 예를 들면, 단계 S11에서 수집부는 학 습 DB로부터 복수의 대상자 각각에 대한 학습 데이터를 수집하는 것일 수 있다. 또한, 본원의 일 실시예에 따르면, 단계 S11에서 수집부는 영상 내의 골절 부위가 마킹된 제1학습 영상 및 제2학습 영상을 학습 데이터로서 수집할 수 있다. 다음으로, 단계 S12에서 학습부는 단계 S11에서 수집된 학습 데이터에 기초하여, 2차원 의료 영상인 대상 영상이 입력되면, 입력된 대상 영상에 기초하여 대상 영상에 대응하는 가상의 3차원 의료 영상인 변환 영상을 생성하는 인공지능 모델을 학습시킬 수 있다. 또한, 본원의 일 실시예에 따르면, 단계 S12에서 학습부는 마킹된 학습 데이터에 기초하여 대상 영상에 대 한 골절 유무 정보 및 골절 영역의 위치 정보를 도출하는 인공지능 모델을 학습시킬 수 있다.이와 관련하여, 단계 S12에서 학습부는 생성적 대립 신경망(Generative Adversarial Network) 알고리즘에 기초하여 인공지능 모델을 학습시킬 수 있다. 구체적으로, 본원의 일 실시예에 따르면, 단계 S12에서 순방향 학습부는 수집된 제1학습 영상에 기초하여 변환 영상을 생성하고, 생성된 변환 영상의 진위 여부를 제2학습 영상에 기초하여 판별하는 순방향(Forward) 학 습을 수행할 수 있다. 또한, 단계 S12에서 역방향 학습부는 수집된 제2학습 영상에 기초하여 가상의 2차원 변환 영상을 생성하고, 상기 2차원 변환 영상의 진위 여부를 상기 제1학습 영상에 기초하여 판별하는 역방향(Backward) 학습 을 수행할 수 있다. 한편, 단계 S12에서 순방향(Forward) 학습 및 역방향(Backward) 학습은 미리 설정된 소정의 반복 횟수만큼 반복 수행되는 것이거나 학습 결과 생성된 인공지능 모델의 성능이 미리 설정된 소정의 수준에 도달하도록 반복 수행 되는 것일 수 있다. 다음으로, 단계 S13에서 변환부는 대상 영상을 수신할 수 있다. 예시적으로, 단계 S13에서 변환부는 의료 영상 촬영 장치로부터 가상의 3차원 변환 영상을 생성할 2차원의 대상 영상을 수신하는 것일 수 있다. 다음으로, 단계 S14에서 변환부는 단계 S12에서 학습된 인공지능 모델에 기초하여 수신된 대상 영상에 대 응하는 가상의 3차원 의료 영상인 변환 영상을 생성할 수 있다. 상술한 설명에서, 단계 S11 내지 S14는 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 도 7은 3차원 변환된 변환 영상을 보정하는 프로세스에 대한 동작 흐름도이다. 도 7에 도시된 3차원 변환된 변환 영상을 보정하는 프로세스는 앞서 설명된 변환 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 변환 장치에 대하여 설명된 내용은 도 7에 대한 설명에도 동일하게 적용될 수 있다. 도 7을 참조하면, 단계 S15에서 보정부는 생성된 가상의 3차원 변환 영상으로부터 디지털 재구성된 투과 이미지(Digitally Reconstructed Radiograph, DRR)를 도출할 수 있다. 다음으로, 단계 S16에서 보정부는 디지털 재구성된 투과 이미지 및 대상 영상을 합성할 수 있다. 다음으로, 단계 S17에서 보정부는 단계 S16의 합성 결과에 기초하여 변환 영상을 보정할 수 있다. 상술한 설명에서, 단계 S15 내지 S17은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체 는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록 되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공 지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자 기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디 스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등 과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에 는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이 상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 인공지능 기반의 의료 영상 3차원 변환 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴 퓨터 프로그램 또는 애플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2021-0042926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2021-0042926", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치를 포함하는 의료 영상 제공 시스 템의 개략적인 구성도이다. 도 2는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치에 의해 수행되는 의료 영상의 3차 원 변환 기법의 전체 프로세스를 개략적으로 나타낸 개념도이다. 도 3은 대상 영상을 가상의 3차원 의료 영상으로 변환하는 인공지능 모델을 학습시키는 과정을 설명하기 위한 개념도이다. 도 4는 학습 영상의 골절 부위를 포함하는 영역에 대한 마킹 결과를 예시적으로 나타낸 도면이다. 도 5는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 장치의 개략적인 구성도이다. 도 6은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 3차원 변환 방법에 대한 동작 흐름도이다. 도 7은 3차원 변환된 변환 영상을 보정하는 프로세스에 대한 동작 흐름도이다."}
