{"patent_id": "10-2023-0043193", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0147349", "출원번호": "10-2023-0043193", "발명의 명칭": "가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치 및 방법", "출원인": "주식회사 앙트러리얼리티", "발명자": "이동윤"}}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치로서,상기 가상공간 내의 오브젝트의 움직임을 감지하는 움직임 감지부;상기 감지된 오브젝트의 움직임에 연동하여 상기 가상공간 내의 시야를 결정하는 시야결정부;상기 결정된 가상공간 내 시야에 있는 콘텐츠를 식별하는 콘텐츠 식별부;상기 식별된 콘텐츠를 시계열 정보가 포함된 가상공간 데이터로 변환하는 데이터처리부;및상기 시계열 정보가 포함된 가상공간 데이터를 저장하는 데이터 저장부;를 포함하고,상기 가상공간 내의 시야의 정보는 상기 가상공간 내 아바타의 시선 벡터와 사용자의 시선 벡터를 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 움직임 감지부는 상기 오브젝트의 움직임을 감지하기 위해서, 모션 센서를 포함하는 가상공간 내 시선 센싱을 수행하는 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 가상공간 시야 내에 있는 콘텐츠는 2D이미지, 2D 애니메이션, 3D모델, 3D 애니메이션 또는 음성을 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 가상공간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별부의 식별방법은, 아이트래킹 방법, 인공지능 학습을 통한 식별방법 또는 객체에 부여된 코드를 통한 식별방법을 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 시계열 정보가 포함된 가상공간 데이터는, 상기 콘텐츠의 위치, 종류 또는 사용자 시청시간을 포함하는 것을 특징으로하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 데이터 저장부의 저장된 데이터를 서버로 전송시키는 데이터 전송부;를 더 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,공개특허 10-2024-0147349-3-상기 데이터 저장부는,상기 시계열 정보가 포함된 가상공간 데이터에 대한 사용자 정보에 기초하여 상기 사용자 정보와 연관된 상기시계열 정보가 포함된 가상공간 데이터의 분류를 진행하고, 저장하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 상기 데이터 전송부는,상기 서버에 적합한 파일의 형식으로 가공한 뒤 전송하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치는 스마트폰, 태블릿PC, 스마트 글래스(SmartGlass) 또는 HMD(Head Mounted Display)인 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법으로서,가상공간 시야 내 콘텐츠를 식별하는 콘텐츠 식별단계;상기 식별된 콘텐츠를 시계열 정보가 포함된 가상공간 데이터로 변환하는 데이터처리단계; 및상기 시계열 정보가 포함된 가상공간 데이터를 저장하는 저장단계;를 포함하고, 상기 가상공간 내의 시야의 정보는 상기 가상공간 내 아바타의 시선 벡터와 사용자의 시선 벡터를 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 시계열 정보가 포함된 가상공간 데이터를 서버로 전송하는 전송단계를 더 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 가상공간 시야 내 콘텐츠는 2D이미지, 2D 애니메이션, 3D모델, 3D 애니메이션 또는 음성을 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 가상공간 시야 내 콘텐츠를 식별하는 콘텐츠 식별단계의 식별방법은 아이트래킹 방법, 인공지능 학습을 통한 식별방법 또는 객체에 부여된 코드를 통한 식별방법을 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집,활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 시계열 정보가 포함된 가상공간 데이터는, 상기 콘텐츠의 위치, 종류 또는 사용자의 시청시간을 포함하는가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법.공개특허 10-2024-0147349-4-청구항 15 제10항에 있어서,상기 데이터 저장단계는,상기 시계열 정보가 포함된 가상공간 데이터에 대한 사용자 정보에 기초하여 상기 사용자 정보와 연관된 상기시계열 정보가 포함된 가상공간 데이터를 분류하고, 저장하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 데이터 전송단계는, 상기 서버에 적합한 파일의 형식으로 가공한 뒤 전송하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,저장된 데이터를 불러오는 로딩 단계;를 더 포함하고,상기 로딩 단계는 상기 불러온 데이터를 기반으로 가상공간에 객체를 배치하는 단계 또는 상기 사용자의 가상공간 내 시야에 배치하는 단계를 포함하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 가상공간에 객체를 배치하는 단계는,상기 사용자 정보를 인공지능 학습을 통해서 사용자에 맞는 객체를 자동으로 제시할 수 있는 것을 특징으로 하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "가상공간 내 시선센싱을 통한 데이터 활용 서비스 제공 방법으로서,가상공간 시야 정보를 습득하는 가상공간 시야 정보 습득단계;상기 가상공간 시야 정보 내의 콘텐츠를 식별하는 콘텐츠 식별단계;및상기 가상공간 시야 정보와 상기 식별된 콘텐츠 정보에 기반하여 사용자 적합 서비스를 제공하는 서비스 제공단계;를 포함하고,상기 가상공간 내의 시야 정보는 가상공간 내 아바타의 시선 벡터와 사용자의 시선 벡터를 포함하는 가상공간내 시선 센싱을 통한 데이터 수집, 활용 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 서비스 제공단계는,상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검출하는 시선 검출단계;상기 검출된 아바타 시선 방향 벡터와 사용자 시선 정보의 일치율을 판단하는 시선 일치 판단단계;및상기 일치율이 미리 설정된 일치율을 초과하는 시간이 기 설정된 시간을 초과하는 경우, 미리 설정된 가상공간내 이벤트를 발생시키는 인터렉션 단계; 를 포함하는 가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공방법.공개특허 10-2024-0147349-5-청구항 21 제19항에 있어서,상기 서비스 제공단계는,상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검출하는 시선 검출단계;상기 검출된 시선을 가상 공간 내 좌표로 변환하는 좌표 변환 단계;및상기 변환된 좌표로 아바타를 이동시키는 아바타 이동단계를 포함하고,상기 좌표 변환 단계는 검출된 시선이 기 설정된 시간을 초과하는 경우, 좌표 변환을 진행하는 것을 특징으로하는 가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제19항에 있어서,상기 서비스 제공단계는,상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검출하는 시선 검출단계;상기 검출된 시선이 상기 식별된 콘텐츠가 정보 수집 대상 콘텐츠에 해당하는지 여부를 판단하는 대상 콘텐츠여부 판단 단계; 및상기 식별된 콘텐츠가 상기 대상 콘텐츠에 해당하는 경우, 시간을 측정하는 시간 측정 시작 단계;를 포함하는가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공 방법."}
{"patent_id": "10-2023-0043193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 식별된 콘텐츠가 상기 대상 콘텐츠에 해당하지 않는 경우, 시간 측정을 종료하는 시간 측정 종료 단계;상기 시간 측정 종료가 확인되면, 상기 시간 측정 시작 단계 및 시간 측정 종료 단계의 시계열적 정보를 보고하는 시간 보고 단계;를 더 포함하는 것을 특징으로 하는 가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공 방법."}
{"patent_id": "10-2023-0043193", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법은 가상공간 시야 내 콘텐츠를 식별하는 콘텐츠 식별단계, 상기 식별된 콘텐츠를 시계열 정보가 포함된 가상공간 데이터로 변환하는 데이터처리단계 및 상기 시계열 정보가 포함된 가상공간 데이터를 저장하는 저장단계를 포함할 수 있다. 상기 가상공간 시야 내 콘텐츠를 식별하는 방법으로는 아이트래킹 방법, 인공지능 학습을 통한 객체 식별방법 또 는 객체에 부여된 코드를 통해 식별하는 방법을 포함할 수 있다. 상기 가상공간 시야 내 콘텐츠는 2D이미지, 2D 애니메이션, 3D모델, 3D 애니메이션 또는 음성을 포함하고, 상기 시계열 정보가 포함된 가상공간 데이터는 상기 콘텐츠의 위치, 종류 또는 사용자의 시청시간을 포함할 수 있다."}
{"patent_id": "10-2023-0043193", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상공간 내 사용자의 시선을 센싱하여 사용자의 가상공간 내 디스플레이 관찰 데이터를 수집하는 방 법에 관한 것으로, 더욱 상세하게는, 가상공간 공간 내 디스플레이 관람 등의 시선 정보(디스플레이 클릭여부, 시청 시간, 광고 시청 여부 등)을 수집하는 시선 센싱을 통한 데이터 수집, 활용 방법에 관한 것이다."}
{"patent_id": "10-2023-0043193", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "가상공간 중 하나인 메타버스는 '가상', '초월' 등을 뜻하는 영어단어 '메타(META)'와 '우주', '세계'를 뜻하는 '유니버스(Universe)'의 합성어로, 현실세계의 한계를 극복하여 사회적 활동이 이루어지는 3차원의 가상세계를 의미한다. 가상공간 중 하나인 메타버스는 가상현실(VR, Virtual Reality)보다 한 단계 더 진화한 개념으로 게임이나 가상 세계를 단순히 즐기는 것을 넘어서 사회적 작용이 가능하며, 실제 현실에서의 시간적 공간적 한계를 넘어선 활 동이 가능하다는 것에 그 의의가 있다. 메타버스라는 가상공간에서는 실제 현실과 유사한 사회적 작용이 발생하는데, 이 작용에서의 사용자 데이터는 현실세계와 다르게 실시간 데이터로서 활용할 수 있다. 사용자의 데이터를 활용한 사용자 친화적 서비스들의 발 달, AI기술을 활용한 사용자 최적화 서비스 제공 등에 있어서 사용자의 활동 데이터를 수집하는 것은 기술 발전 과 사용자 서비스 개발에 있어서 중요한 요소이다.한국 특허공보 제10-2343815호(발명의 명칭: 네트워크 데이터를 이용한 광고 효과 측정 방법, 광고 효과 측정 장치, 광고 효과 측정 시스템)는 광고 노출 데이터 네트워크를 활용한 광고 매체별 광고 노출수를 분석하고 관 리자 단말에 데이터를 전달하는 광고효과 측정에 관한 것이다. 다만, 네트워크 데이터를 활용하여 사용자의 데 이터를 수집하는 점에 있어서, 종래의 사용자의 네트워크에서의 활동을 평면적으로 수집한다는 점에서 충분한 시계열적인 데이터를 수집할 수 없다는 점에서 가상공간이라는 특별한 환경에서의 데이터수집, 활용 방법으로의 한계가 존재한다. 또한, 가상공간 내에서 사용자 데이터를 활용하여 맞춤형 서비스 및 광고 제공 서비스 등이 도입되는 등, 사용 자 맞춤형 서비스를 위한 시계열적인 데이터의 필요성이 증가하고 있다. 예를 들어, 한국 특허공보 제10- 2479479호(발명의 명칭: 가상공간 상에서 사용자 맞춤형 영상광고를 송출하는 서비스 제공 장치)는 사용자 정보 (사용자의 기본 정보, 위치 정보, 검색기록 정보)를 활용하여 사용자에게 맞춤형 광고를 제공하는 발명이다. 다 만, 가상공간 내에서의 활동기록에 관련한 데이터를 활용하지 않고, 사용자 단말로부터 얻은 정보를 기본정보로 사용한다. 다른 예로, 한국 특허공보 제10-2480218호(발명의 명칭: 사용자 경험을 기초로 가상공간 환경을 제공 하는 방법 및 장치)는 사용자 기기로부터 수집된 센싱 데이터를 분석하고, 이를 활용하여 사용자의 적응도를 결 정함으로써, 가상공간 환경을 제공하는 방법 및 장치에 관한 것이다. 사용자의 나이, 성별, 직업 등 개인 정보 를 이용하여 인지 능력 및 방문 이력 등을 사용자 정보로써 활용한다. 이러한 서비스에 있어서 가상공간이라는 특별한 환경의 데이터 수집의 방법으로는 실시간으로 얻어지는 시계열적 가상공간 내 사용자 데이터를 수집하는 방법이 필요하다. 사용자에게 최적화된 정보를 제공하는 서비스뿐만 아니라 가상공간에 접속하기 위한 장치 외에 별도의 생체정보 를 가상공간 내에 적용시켜서 활용하는 기술 또한 등장했다. 예를 들어, 한국 특허공보 제10-2441662호(발명의 명칭: 가상공간을 이용한 케어 플랫폼 서비스 시스템 및 그 제어방법)는 치료 전후의 생체정보를 활용하여 인공 지능학습을 통해서 케어 플랫폼 서비스를 제공하는 것으로, 사용자는 이와 같은 기술을 활용하여 케어 업무를 보조할 수 있다. 하지만, 종래의 가상공간 내에서 데이터를 활용한 기술은 대부분 가상공간 내에서 얻을 수 있는 정보를 활용하 지 않고, 가상공간 외적으로 얻어지는 정보에 기초해서만 서비스를 제공하고 있기에 가상공간 환경이라는 특수 성에서 기인한 시계열적인 정보를 손쉽게 데이터화하여 보관할 수 있다는 장점을 활용하지 못하고 있다는 한계 가 존재한다. 이를 보완하여, 생체 정보 등 별도의 사용자 데이터를 활용하여 최적의 서비스 제공을 위한 데이 터를 보완하지만, 가상공간 자체에서 얻어지는 데이터를 활용하지 않는다는 한계가 존재한다. 또한, 가상공간 내부의 사용자의 데이터를 활용하지 못하여, 직접적인 가상공간 플랫폼의 이용자들이 어떠한 정 보에 관심을 가지고 시간을 사용하는지에 대한 정량적인 데이터를 얻을 수 없다는 한계점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허공보 제10-2343815호 (2021.12.22. 등록) (특허문헌 0002) 한국 등록특허공보 제10-2479479호 (2022.12.15. 등록) (특허문헌 0003) 한국 등록특허공보 제10-2480218호 (2022.12.19. 등록) (특허문헌 0004) 한국 등록특허공보 제10-2441662호 (2022.09.05. 등록)"}
{"patent_id": "10-2023-0043193", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 종래 기술의 문제점을 감안하여 안출된 것으로, 본 발명의 목적은 가상공간 내에서 얻을 수 있는 사용자의 데이터를 사용자 시선 센싱을 통해서 얻는 방법이다. 또한, 본 발명의 목적은 가상공간 내에서 사용자의 정보를 활용한 서비스 제공 및 광고효과를 증대시키는데 활용하고, 광고의 효과를 데이터로 확인하는 것에 있어서 목적이 있다."}
{"patent_id": "10-2023-0043193", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명에 따른 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치 는, 가상공 간에서 사용자 최적화 서비스 제공 및 광고를 위한 데이터 수집을 진행하는 장치로, 상기 가상공간 내 시선 센 싱을 통한 데이터 수집, 활용 장치의 움직임을 감지하는 움직임 감지부; 상기 스마트 장치의 움직임을 가상공간 시야 전환동작으로 변환하는 시야결정부; 상기 가상공간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별부; 상 기 식별된 콘텐츠를 시계열 정보가 포함된 가상공간 데이터로 변환하는 데이터처리부; 상기 시계열 정보가 포함 된 가상공간 데이터를 저장하는 데이터 저장부;를 포함할 수 있다. 상기 가상공간 내의 시야는 가상공간 내 아바타의 시선 방향 벡터와 사용자의 시선 정보를 포함할 수 있다. 그리고, 상기 움직임 감지부는 상기 스마트 장치의 움직임을 감지하기 위해서, 모션 센서를 포함할 수 있다. 또한, 상기 가상공간 시야 내에 있는 콘텐츠는 2D이미지, 2D 애니메이션, 3D모델, 3D 애니메이션 또는 음성일 수 있다. 그리고, 상기 가상공간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별부의 식별방법은 아이트래킹 방법, 인공 지능 학습을 통한 식별방법 또는 객체에 부여된 코드를 통한 식별일 수 있다. 또한, 상기 시계열 정보가 포함된 가상공간 데이터는, 상기 콘텐츠의 위치, 종류, 사용자의 상기 콘텐츠의 시청 시간이 포함될 수 있다. 그리고, 상기 데이터 저장부의 저장된 데이터를 서버로 전송시키는 데이터 전송부;를 더 포함할 수 있다. 또한, 상기 데이터 저장부는, 상기 시계열 정보가 포함된 가상공간 데이터에 대한 사용자 정보에 기초하여 상기 사용자 정보와 연관된 상기 시계열 정보가 포함된 가상공간 데이터의 분류를 진행하고, 저장할 수 있다. 그리고, 상기 데이터 전송부는, 상기 서버에 적합한 파일의 형식으로 가공한 뒤 전송할 수 있다. 또한, 상기 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치는 스마트폰, 태블릿PC, 스마트 글래스(Smart Glass)또는 HMD(Head Mounted Display)일 수 있다. 한편, 상기 목적을 달성하기 위한 본 발명에 따른 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법은, 가 상공간에서 사용자 최적화 서비스를 제공 및 광고를 위한 데이터 수집을 진행하는 가상공간 내 시선 센싱을 통 한 데이터 수집, 활용 방법으로서, 가상공간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별단계; 상기 식별된 콘텐츠를 시계열 정보가 포함된 가상공간 데이터로 변환하는 데이터처리단계; 상기 시계열 정보가 포함된 가상 공간 데이터를 저장하는 저장단계;를 포함할 수 있다. 상기 가상공간 내의 시야는 가상공간 내 아바타의 시선 방향 벡터와 사용자의 시선 정보를 포함할 수 있다. 그리고, 상기 시계열 정보가 포함된 가상공간 데이터를 서버로 전송하는 전송단계;를 더 포함할 수 있다. 또한, 상기 가상공간 시야 내 콘텐츠는 2D이미지, 2D 애니메이션, 3D모델, 3D 애니메이션 또는 음성일 수 있다. 그리고, 상기 가상공간 시야 내 콘텐츠를 식별하는 콘텐츠 식별단계의 식별방법은 아이트래킹 방법, 인공지능 학습을 통한 식별방법 또는 객체에 부여된 코드를 통한 식별일 수 있다. 또한, 상기 시계열 정보가 포함된 가상공간 데이터는, 상기 콘텐츠의 위치, 종류, 사용자의 상기 콘텐츠의 시청 시간이 포함될 수 있다. 그리고, 상기 데이터 저장단계는, 상기 시계열 정보가 포함된 가상공간 데이터에 대한 사용자 정보에 기초하여 상기 사용자 정보와 연관된 상기 시계열 정보가 포함된 가상공간 데이터를 분류하고, 저장할 수 있다. 또한, 상기 데이터 전송단계는, 상기 서버에 적합한 파일의 형식으로 가공할 수 있다. 그리고, 저장된 데이터를 불러오는 로딩 단계;를 더 포함하고, 상기 로딩 단계는 상기 불러온 데이터를 기반으 로 가상공간에 객체를 배치하는 단계 또는 상기 사용자의 가상공간 내 시야에 배치하는 단계를 포함할 수 있다. 또한, 상기 가상공간에 객체를 배치하기 위해, 상기 사용자 정보를 인공지능 학습을 통해서 자동 제시할 수 있 다. 그리고, 상기 사용자의 가상공간 내 시야에 배치하기 위해, 상기 사용자 정보를 인공지능 학습을 통해서 자동 제시할 수 있다. 한편, 상기 목적을 달성하기 위한 본 발명에 따른 가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공 방법 은, 시선 센싱을 통해 얻어지는 데이터를 활용하여 서비스를 제공할 수 있는 방법으로서, 가상공간 시야 정보를 습득하는 가상공간 시야 정보 습득단계;상기 가상공간 시야 정보 내의 콘텐츠를 식별하는 콘텐츠 식별단계;및 상기 가상공간 시야 정보와 상기 식별된 콘텐츠 정보에 기반하여 사용자 적합 서비스를 제공하는 서비스 제공단 계;를 포함하고, 상기 가상공간 내의 시야 정보는 가상공간 내 아바타의 시선 방향 벡터와 사용자의 시선 벡터 정보를 포함할 수 있다. 그리고, 상기 서비스 제공단계는, 상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검출하는 시선 검출단 계; 상기 검출된 아바타 시선 방향 벡터와 사용자 시선 정보의 일치율을 판단하는 시선 일치 판단단계;및 상기 일치율이 미리 설정된 일치율을 초과하는 시간이 기 설정된 시간을 초과하는 경우, 미리 설정된 가상공간 내 이 벤트를 발생시키는 인터렉션 단계; 를 포함 할 수 있다. 또한, 상기 서비스 제공단계는, 상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검출하는 시선 검출단계; 상기 검출된 시선을 가상 공간 내 좌표로 변환하는 좌표 변환 단계;및 상기 변환된 좌표로 아바타를 이동시키는 아바타 이동단계를 포함할 수 있고, 상기 좌표 변환 단계는 검출된 시선이 기 설정된 시간을 초과하 는 경우, 좌표 변환을 진행하는 것을 특징으로 할 수 있다. 그리고, 상기 서비스 제공단계는, 상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검출하는 시선 검출단 계; 상기 검출된 시선이 상기 식별된 콘텐츠가 정보 수집 대상 콘텐츠에 해당하는지 여부를 판단하는 대상 콘텐 츠 여부 판단 단계;및 상기 식별된 콘텐츠가 상기 대상 콘텐츠에 해당하는 경우, 시간을 측정하는 시간 측정 시 작 단계; 를 포함할 수 있다. 또한, 상기 식별된 콘텐츠가 상기 대상 콘텐츠에 해당하지 않는 경우, 시간 측정을 종료하는 시간 측정 종료 단 계;및 상기 시간 측정 종료가 확인되면, 상기 시간 측정 시작 단계 및 시간 측정 종료 단계의 시계열적 정보를 보고하는 시간 보고 단계;를 더 포함할 수 있다."}
{"patent_id": "10-2023-0043193", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 가상공간 내 사용자의 시선센싱을 통한 데이터 수집, 활용 방법 및 장치에 의하면, 가상공간 내 에서 얻어지는 시계열적 정보가 포함된 데이터를 쉽게 수집할 수 있다. 또한, 본 발명에 따른 데이터 수집, 활 용 방법에 의하면, 본 발명의 의의는 가상공간 내부에서 얻어지는 시계열적 정보가 포함된 사용자 데이터를 수 집하고, 이를 가상공간을 활용한 사용자 친화적인 서비스 제공방법에 활용함과 가상공간 내 광고 홍보 효과 증 진에 데이터를 활용함에 있다."}
{"patent_id": "10-2023-0043193", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 명세서에 개시된 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개 시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세 서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기 술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함 하는 것으로 이해되어야 한다. 도 1은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 장치의 구성도이다. 본 발명에 따른 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치는, 움직임 감지부, 시야결정부, 콘 텐츠 식별부, 데이터 처리부, 데이터 저장부를 포함한다. 도 2는 가상공간 내의 시야 정보의 아바타의 시선 방향 벡터와 사용자의 시선 벡터 정보를 설명하기 위한 도면 이다. 도 2에 도시된 바와 같이, 상기 가상공간 내의 시야 정보는 가상공간 내 아바타의 시선 벡터 정보와 사용 자의 시선 벡터 정보를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 가상공간 내 시선 센싱을 통한 데이터 수집 디바이스는 데스크탑, 스마트폰, 태 블릿PC, 스마트 글래스(Smart Glass) 또는 HMD(Head Mounted Display)일 수 있지만 이에 한정되지 않는다. 움직임 감지부는, 상기 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 장치의 움직임을 감지할 수 있다. 상기 움직임 감지부는 상기 스마트장치의 움직임을 감지하기 위해서, 모션 센서를 포함할 수 있다. 모션 센서는 적외선감지 센서, 영상촬영 카메라, 자이로 센서, 중력 센서, 가속도 센서, 근접 센서 일 수 있지만 이에 한정 되지 않는다. 도 3은 본 발명에 따른 스마트 디바이스의 움직임을 감지하기 위한 자이로센서의 움직임 감지 실시예를 나 타내는 개략도이다. 도 3에 따른 본 발명의 일 실시예로, 자이로 센서는 스마트 장치의 회전각을 감지할 수 있다. 가속도 센서 는 스마트 장치의 기울어진 정도를 감지할 수 있다. 감지된 스마트 장치의 회전각과 기울어지는 정도를 감지하 여, 모션 센서는 움직임을 감지할 수 있다.시야결정부는, 상기 스마트 장치의 움직임을 대응되게 가상공간 시야 전환동작으로 변환할 수 있다. 본 발명의 실시예에 따르면, 상기 스마트 장치의 움직임이 좌측으로 이동되는 것을 감지하는 경우에 가상공간 내 시야가 스마트 장치의 좌측 방향으로의 움직임에 대응되게 전환할 수 있다. 본 발명의 실시예에 따르면, 상기 모션 센서에 의해 일정시간 이내에 일정 횟수 이상으로 전환되는 경우에 시야 결정부에서는 복원 움직임으로 판단하고 대응하는 동작을 수행하게 할 수 있다. 시야결정부는 일정 움직임속도 이상으로 움직였다고 판단되는 경우, 움직임이 시작되었다고 판단할 수 있다. 일정 움직임속도 미만으로 움직였 다고 판단되는 경우, 움직임이 시작되었다고 판단하지 않는다. 콘텐츠 식별부는 상기 가상공간 시야 내에 있는 콘텐츠를 식별할 수 있다. 상기 가상공간 시야 내에 있는 콘텐 츠는 2D이미지, 2D 애니메이션, 3D모델, 3D 애니메이션 또는 음성을 포함할 수 있다. 상기 가상공간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별부의 식별방법은 아이트래킹 방법, 인공지능 학습 을 통한 식별방법 또는 객체에 부여된 코드를 통한 식별방법을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 콘텐츠 식별방법은 인공지능 학습을 통한 식별방법일 수 있다. 인공지능 학습을 통한 식별방법은, 객체 분류부, 객체 추적부, 객체 판단부를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 인공지능 학습을 통한 식별방법의 객체 분류부는 가상공간 시야 영상으로부터 딥러닝 기반의 객체 인식작업을 통해 가상공간 환경과 객체를 분류할 수 있다. 인공지능 학습을 통한 객체 분류 부는, 수신된 영상 데이터에서 실시간으로 이미지 프레임 데이터를 추출할 수 있다. 이미지데이터는 가상공간 환경과 객체 감지를 위해서 딥러닝 모델의 입력으로 사용될 수 있다. 여기서, 딥 러닝 모델은 이미지 객체 감지 를 위해서 사용될 수 있고, CNN(Convolutional Neural Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer)일 수 있으나 여기에 한정되지 않는다. 본 발명의 일 실시예에 따르면, 인공지능 학습을 통한 식별방법의 객체 추적부는 객체 분류부에서 분류된 객체 중 타겟 객체를 추적할 수 있다. 객체 추적부는 분류된 객체를 각각에 ID를 부여하고, 현재 프레임과 과거 프레 임을 비교하여 객체를 추적할 수 있다. 객체 추적부는 객체 추적을 위하여 딥러닝 모델을 사용할 수 있다. 여기 서, 딥 러닝 모델은 CNN(Convolutional Neural Network), CAE(Convolutional Auto-Encoder), RPN(Region Proposal Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer)일 수 있으나 여기에 한 정되지 않는다. 본 발명의 일 실시예에 따르면, 인공지능 학습을 통한 식별방법의 객체 판단부는 객체 추적부에서 추적한 객체 에 대한 판단을 할 수 있다. 추적된 객체 내에 있는 텍스트와 이미지 정보를 추출하여 판단할 수 있다. 텍스트 와 이미지 정보를 추출하기 위해서, 딥러닝 모델을 사용할 수 있다. 여기서, 딥 러닝 모델은 CNN(Convolutional Neural Network), CAE(Convolutional Auto-Encoder), RPN(Region Proposal Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer), Transformer일 수 있으나 여기에 한정되지 않는다. 본 발명의 일 실시예에 따르면, 아이트래킹을 통한 식별방법은 아이트래킹 장치를 통해서 구현될 수 있다. 아이 트래킹 장치는 아이트래킹 장치 하우징, 영상 센서, 영상 수집부, 영상 학습부, 아이트래킹 기능 제어부를 포함 할 수 있다. 본 발명의 일 실시예에 따르면, 아이트래킹 방법의 영상센서는 사용자의 안면과 동공의 움직임을 인식할 수 있 다. 아이트래킹 방법의 영상 수집부는 영상센서가 인식한 안면과 동공의 움직임을 영상으로 하여 수집할 수 있 다. 아이트래킹 방법의 영상 수집부는 학습을 위한 영상을 수집하기 위해서, 음성 또는 텍스트 문구를 출력할 수 있다. 본 발명의 일 실시예에 따르면, 아이트래킹 방법의 영상 학습부는 수집된 사용자의 안면과 동공의 움직임 영상 을 딥러닝 모델의 입력으로하여 학습되도록 구성될 수 있다. 이에 따라, 사용자의 안구의 개폐, 사용자의 동공 의 움직임을 딥러닝 모델의 입력으로 하여 시선의 방향을 추론할 수 있다. 여기서, 딥 러닝 모델은 CNN(Convolutional Neural Network), CAE(Convolutional Auto-Encoder), RPN(Region Proposal Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer)일 수 있으나 여기에 한정되지 않는다. 본 발명의 일 실시예에 따르면, 아이트래킹 방법의 기능 제어부는 딥 러닝 모델에 의해 추론된 시선의 방향을 입력으로 하여, 아이트래킹 기능의 온-오프 및 홀드 동작을 제어할 수 있다. 데이터 처리부는 상기 식별된 콘텐츠를 시계열 정보가 포함된 가상공간 데이터로 변환할 수 있다. 가상공간 데 이터는 콘텐츠 식별부에서 식별한 가상공간 내 콘텐츠를 시계열 정보가 포함된 텍스트 또는 이미지일 수 있다. 시계열 정보가 포함된 가상공간 데이터는, 상기 콘텐츠의 위치, 종류 또는 사용자 시청시간을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 시계열 정보가 포함된 가상공간 데이터는 콘텐츠의 제목, 콘텐츠를 제공한 기업, 사용자의 콘텐츠 시청시간, 사용자의 콘텐츠 클릭여부 및 사용자의 콘텐츠 감지여부를 포함할 수 있다. 데이터 저장부는, 상기 시계열 정보가 포함된 가상공간 데이터에 대한 사용자 정보에 기초하여 상기 사용자 정 보와 연관된 상기 시계열 정보가 포함된 가상공간 데이터의 분류를 진행하고, 분류된 데이터를 저장할 수 있다 본 발명의 일 실시예에 따르면, 데이터 저장부는 데이터를 저장할 수 있는 모든 종류의 기록장치를 포함할 수 있다. 데이터 저장부는 HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 광데이터 저장장치 일 수 있으며, 이에 한정되지 않는다. 한편, 본 발명에 따른 데이터 수집 디바이스는 데이터 전송부를 포함할 수 있다. 데이터 전송부는 상기 데이터 저장부의 저장된 데이터를 서버로 전송할 수 있다. 데이터 전송부는, 상기 서버에 적합한 파일의 형식으로 가공한 뒤 전송할 수 있다. 또한, 데이터 전송부는 무선 인터넷에 접속할 수 있다. 무선 인터넷 기술로는, 예를 들어 WLAN(wireless LAN), Wi-Fi(Wireless_fidelity), DLNA(Digital Living Network Alliance), Wibro(Wireless Broadband), LTE(Long Term Evolution) 등이 있으며, 상기 데이터 전송부 는 무선 인터넷 기술을 활용하여 서버로 저장된 데이터를 전송할 수 있다. 도 4은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법을 설명하기 위한 흐름도이다. 한편, 본 발명의 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법은, 가상공간에서 사용자 최적화 서비스 를 제공 및 광고를 위한 데이터수집을 진행하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법으로서 가상공간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별단계(S100), 상기 식별된 콘텐츠를 시계열 정보가 포함 된 가상공간 데이터로 변환하는 데이터처리단계(S110), 상기 시계열 정보가 포함된 가상공간 데이터를 저장하는 저장단계(S120)를 포함할 수 있다. 도 2는 가상공간 내의 시야 정보의 아바타의 시선 방향 벡터와 사용자의 시선 벡터 정보를 설명하기 위한 도면 이다. 도 2에 도시된 바와 같이, 상기 가상공간 내의 시야 정보는 가상공간 내 아바타의 시선 벡터 정보와 사용 자의 시선 벡터 정보를 포함할 수 있다. 도 5는 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 저장된 데이터를 불 러와 로딩하는 것을 더 포함하는 데이터 수집, 활용 방법을 설명하기 위한 흐름도이다. 본 발명의 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법은, 가상공간에서 사용자 최적화 서비스를 제 공 및 광고를 위한 데이터수집을 진행하는 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법으로서 가상공 간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별단계(S200), 상기 식별된 콘텐츠를 시계열 정보가 포함된 가 상공간 데이터로 변환하는 데이터처리단계(S210), 상기 시계열 정보가 포함된 가상공간 데이터를 저장하는 저장 단계(S220)를 포함할 수 있다. 또한 본 발명의 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법은 시계열 정보가 포함된 가상공간 데이 터를 서버로 전송하는 전송단계를 포함할 수 있다. 본 발명의 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법은, 저장된 데이터를 불러오는 로딩 단계 (S240)를 더 포함할 수 있다. 콘텐츠 식별단계는 상기 가상공간 시야 내에 있는 콘텐츠를 식별할 수 있다. 상기 가상공간 시야 내에 있는 콘 텐츠는 2D이미지, 2D 애니메이션, 3D모델, 3D 애니메이션 또는 음성을 포함할 수 있다. 상기 가상공간 시야 내에 있는 콘텐츠를 식별하는 콘텐츠 식별단계에서의 식별방법은 아이트래킹 방법, 인공지 능 학습을 통한 식별방법 또는 객체에 부여된 코드를 통한 식별방법을 포함할 수 있다. 도 6은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 인공지능 학습을 통 해 콘텐츠를 식별하는 방법을 설명하기 위한 흐름도이다.본 발명의 일 실시예에 따르면, 콘텐츠 식별방법은 인공지능 학습을 통한 식별방법일 수 있다. 인공지능 학습을 통한 식별방법은, 객체 분류 단계(S300), 객체 추적 단계(S310) 및 객체 판단 단계(S320)를 포함할 수 있다. 도 7은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 콘텐츠를 식별하기 위해 인공지능 학습을 통해 객체를 분류하는 방법을 설명하기 위한 흐름도이다 본 발명의 일 실시예에 따르면, 인공지능 학습을 통한 식별방법의 객체 분류 단계(S300)는 가상공간 시야 영상 으로부터 딥러닝 기반의 객체 인식작업을 통해 가상공간 환경과 객체를 분류할 수 있다. 인공지능 학습을 통한 객체 분류 단계는, 수신된 영상 데이터에서 실시간으로 이미지 프레임 데이터를 추출 단계(S302)를 포함할 수 있다. 이미지데이터는 가상공간 환경과 객체 감지를 위해서 딥러닝 모델의 입력하는 단계(S304)을 포함할 수 있 다. 여기서, 딥 러닝 모델은 이미지 객체 감지를 위해서 사용될 수 있고, CNN(Convolutional Neural Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer)일 수 있으나 여기에 한정되지 않는다. 인공 지능 학습을 통한 객체 분류 단계는, 가상환경과 객체를 분류하는 단계(S306)을 포함할 수 있다. 도 8는 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 콘텐츠를 식별하기 위해 인공지능 학습을 통해 객체를 추적하는 방법을 설명하기 위한 흐름도이다. 본 발명의 일 실시예에 따르면, 인공지능 학습을 통한 식별방법의 객체 추적 단계(S310)는 객체 분류 단계에서 분류된 객체 중 타겟 객체를 추적할 수 있다. 객체 추적 단계는 분류된 객체를 각각에 ID를 부여하는 단계 (S312)를 포함할 수 있고, 현재 프레임과 과거 프레임을 비교하여 객체를 추적하는 단계(S314)를 포함할 수 있 다. 객체 추적 단계는 객체 추적을 위하여 딥러닝 모델을 사용할 수 있다. 여기서, 딥 러닝 모델은 CNN(Convolutional Neural Network), CAE(Convolutional Auto-Encoder), RPN(Region Proposal Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer)일 수 있으나 여기에 한정되지 않는다. 객체 추적 단계는 현재와 과거의 프레임을 비교하는 단계(S16)을 통해서 타겟 객체를 추적할 수 있다. 도 9은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 콘텐츠를 식별하기 위해 인공지능 학습을 통해 객체를 판단하는 방법을 설명하기 위한 흐름도이다. 본 발명의 일 실시예에 따르면, 인공지능 학습을 통한 식별방법의 객체 판단 단계는 객체 추적 단계에서 추적한 객체에 대한 판단을 할 수 있다. 추적된 객체 내에 있는 텍스트와 이미지 정보를 추출하여 판단할 수 있다. 객 체 판단단계는 추출된 정보를 활용하여 딥러닝 입력의 전처리를 하는 단계(S322)를 포함할 수 있다. 텍스트와 이미지 정보를 추출하기 위해서, 딥러닝 모델을 사용하는 단계(S324)를 포함할 수 있다. 여기서, 딥 러닝 모델 은 CNN(Convolutional Neural Network), CAE(Convolutional Auto-Encoder), RPN(Region Proposal Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer), Transformer일 수 있으나 여기에 한정되지 않는다. 객체 판단 단계는 객체 별 필요한 텍스트와 이미지를 추출하는 단계(S326)을 포함할 수 있다. 도 10은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 아이트래킹 장치를 통해 콘텐츠를 식별하는 방법을 설명하기 위한 흐름도이다. 본 발명의 일 실시예에 따르면, 아이트래킹을 통한 식별방법은 아이트래킹 추적 방법일 수 있다. 아이트래킹 추 적 방법은 영상 센싱 단계, 영상 수집 단계, 영상 학습 단계, 아이트래킹 기능 제어 단계를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 아이트래킹 방법의 영상 센싱 단계는 사용자의 안면과 동공의 움직임을 인식할 수 있다. 아이트래킹 방법의 영상 수집 단계는 영상센서가 인식한 안면과 동공의 움직임을 영상으로 하여 수집 하는 단계(S400)을 포함할 수 있다. 아이트래킹 방법의 영상 수집 단계는 학습을 위한 영상을 수집하기 위해서, 음성 또는 텍스트 문구를 출력할 수 있다. 본 발명의 일 실시예에 따르면, 아이트래킹 추적 방법의 영상 학습 단계는 수집된 사용자의 안면과 동공의 움직 임 영상을 딥러닝 모델의 입력으로하여 학습 단계(S410)를 포함할 수 있다. 이에 따라, 사용자의 안구의 개폐, 사용자의 동공의 움직임을 딥러닝 모델의 입력으로 하여 시선의 방향을 추론할 수 있다. 여기서, 딥 러닝 모델 은 CNN(Convolutional Neural Network), CAE(Convolutional Auto-Encoder), RPN(Region Proposal Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer)일 수 있으나 여기에 한정되지 않는다. 본 발명의 일 실시예에 따르면, 아이트래킹 추적 방법의 기능 제어 단계는 딥 러닝 모델에 의해 추론된 시선의 방향을 입력으로 하여, 아이트래킹 기능의 온-오프 및 홀드 동작을 제어할 수 있다. 데이터 처리 단계는 상기 식별된 콘텐츠를 시계열 정보가 포함된 가상공간 데이터로 변환할 수 있다. 가상공간 데이터는 콘텐츠 식별부에서 식별한 가상공간 내 콘텐츠를 시계열 정보가 포함된 텍스트 또는 이미지일 수있다. 시계열 정보가 포함된 가상공간 데이터는, 상기 콘텐츠의 위치, 종류 또는 사용자 시청시간을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 시계열 정보가 포함된 가상공간 데이터는 콘텐츠의 제목, 콘텐츠를 제공한 기업, 사용자의 콘텐츠 시청시간, 사용자의 콘텐츠 클릭여부 및 사용자의 콘텐츠 감지여부를 포함할 수 있다. 데이터 저장 단계는, 상기 시계열 정보가 포함된 가상공간 데이터에 대한 사용자 정보에 기초하여 상기 사용자 정보와 연관된 상기 시계열 정보가 포함된 가상공간 데이터의 분류를 진행하고, 분류된 데이터를 저장할 수 있 다. 본 발명의 일 실시예에 따르면, 데이터 저장부는 데이터를 저장할 수 있는 모든 종류의 기록장치를 포함할 수 있다. 데이터 저장부는 HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 광데이터 저장장치 일 수 있으며, 이에 한정되지 않는다. 한편, 본 발명에 따른 데이터 수집 디바이스는 데이터 전송 단계를 포함할 수 있다. 데이터 전송 단계는 상기 데이터 저장부의 저장된 데이터를 서버로 전송할 수 있다. 데이터 전송 단계는, 상기 서버에 적합한 파일의 형식으로 가공한 뒤 전송할 수 있다. 또한, 데이터 전송 단계 는 무선 인터넷에 접속할 수 있다. 무선 인터넷 기술로는, 예를 들어 WLAN(wireless LAN), Wi-Fi(Wireless_fidelity), DLNA(Digital Living Network Alliance), Wibro(Wireless Broadband), LTE(Long Term Evolution) 등이 있으며, 상기 데이터 전송 단 계는 무선 인터넷 기술을 활용하여 서버로 저장된 데이터를 전송할 수 있다. 도 11는 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 가상 공간에 객체 를 배치하는 방법을 설명하기 위한 흐름도이다. 본 발명의 가상공간 내 시선 센싱을 통한 데이터 수집, 활용 방법은, 저장된 데이터를 불러오는 로딩 단계를 더 포함할 수 있는데, 상기 로딩 단계는 불러온 데이터를 기반으로 가상공간에 객체를 배치하는 단계 또는 가상공 간 내 시야에 배치하는 단계를 포함할 수 있다. 가상공간에 객체를 배치하는 단계는 사용자가 어떤 콘텐츠를 선호하는지 판단할 수 있는 사용자 적합 콘텐츠 판 단 단계(S500), 콘텐츠 별 사용자의 선호도와 성과를 관리할 수 있는 콘텐츠 관리 단계(S510), 사용자의 선호 콘텐츠를 객체를 배치하는 것에 있어서 적합도를 추산하여 객체를 매칭하고 표출시점을 결정하는 사용자 콘텐츠 매칭 단계(S520)를 포함할 수 있다. 또한, 가상공간에 객체를 배치하는 단계는 가상공간에 콘텐츠의 표출시점을 결정하는 단계(S530)와 가상공간에 사용자에게 적합한 콘텐츠를 배치하는 단계(S540)를 포함할 수 있다. 가상공간에 객체를 배치하는 단계는 사용자 정보를 인공지능 학습을 통해서 사용자에 맞는 객체를 자동으로 제 시할 수 있다. 본 발명의 일 실시예에 따르면, 사용자 적합 콘텐츠 판단 단계는 사용자 데이터를 기반으로 딥러닝 모델 학습으 로 사용자에게 적합한 콘텐츠를 판단할 수 있다. 딥러닝 모델은 자연어 처리와 이미지 처리를 기반으로 한 CNN(Convolutional Neural Network), CAE(Convolutional Auto-Encoder), RPN(Region Proposal Network), ViT(Vision Transformer), MobileViT(Mobile Vision Transformer)일 수 있으나 여기에 한정되지 않는다. 본 발명의 일 실시예에 따르면, 콘텐츠 관리 단계는 콘텐츠 별로 노출 정도와 사용자의 데이터를 관리할 수있다. 어떤 콘텐츠가 가상공간 내에서 노출되었는지 로그(log)를 확인할 수 있으며, 콘텐츠에서 경향을 분석 하는 단계를 더 포함할 수 있다. 본 발명의 일 실시예에 따르면, 콘텐츠 매칭 단계는 사용자의 데이터, 가상공간 내 사용자의 위치, 접속 시간 등을 활용하여 적합도를 추산할 수 있다. 추산된 적합도에 기반하여, 콘텐츠가 표출되는 표출 시점 또는 사용자 에게 적합한 콘텐츠를 개별적으로 매칭할 수 있다. 도 12은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 가상공간 데이터를 활용하여 인공지능 학습을 통해 사용자에게 적합한 객체를 배치하는 방법을 설명하기 위한 흐름도이다 또한, 본 발명의 일 실시예에 따르면, 가상공간 데이터를 활용하여 인공지능 학습을 통해 사용자에게 적합한 객 체를 배치하는 방법은, 가상공간 시야 내 콘텐츠 식별 단계(S600), 가상 공간 내 식별된 콘텐츠를 시계열 정보 가 포함된 가상공간 데이터로 변환하는 단계(S610), 가상공간 데이터를 저장부에 저장하는 저장단계(S620), 가상공간 데이터를 서버로 전송하는 전송 단계(S630), 저장된 가상공간 데이터를 사용하기 위해서 로딩하는 단계 (S640), 가상 공간 데이터를 입력으로 하여 인공지능 학습을 진행하는 인공지능 학습 단계(S650)를 포함할 수 있다. 가상공간 데이터를 활용하여 인공지능 학습을 통해 사용자에게 적합한 객체를 배치하는 방법은, 가상공간 에 객체를 배치하는 단계(S612) 또는 가상공간 내 사용자 시야에 배치하는 단계(S614)를 포함할 수 있다. 본 발명에 따른 가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공 방법은, 시선 센싱을 통해 얻어지는 데 이터를 활용하여 서비스를 제공할 수 있는 방법으로서, 가상공간 시야 정보를 습득하는 가상공간 시야 정보 습 득단계, 상기 가상공간 시야 정보 내의 콘텐츠를 식별하는 콘텐츠 식별단계 및 상기 가상공간 시야 정보와 상기 식별된 콘텐츠 정보에 기반하여 사용자 적합 서비스를 제공하는 서비스 제공단계를 포함할 수 있다. 도 2는 가상공간 내의 시야 정보의 아바타의 시선 방향 벡터와 사용자의 시선 벡터 정보를 설명하기 위한 도면 이다. 도 2에 도시된 바와 같이, 상기 가상공간 내의 시야 정보는 가상공간 내 아바타의 시선 벡터 정보와 사용 자의 시선 벡터 정보를 포함할 수 있다. 도 13은 본 발명의 인터렉션을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공방법의 흐름도 이다. 도 13에 도시된 바와 같이, 상기 서비스 제공단계는, 상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검 출하는 시선 검출단계(S700), 상기 검출된 아바타 시선 방향 벡터와 사용자 시선 정보의 일치율을 판단하는 시 선 일치 판단단계(S710) 및 상기 일치율이 미리 설정된 일치율을 초과하는 시간이 기 설정된 시간을 초과하는 경우, 미리 설정된 가상공간 내 이벤트를 발생시키는 인터렉션 단계(S720)를 포함 할 수 있다. 도 14는 인터렉션을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 서비스의 본 발명에 따른 실시예를 설 명하기 위한 도면이다. 도 14에 도시된 바와 같이, 본 발명의 일 실시예에 따르면, 사용자의 시선을 감지하고 필요한 동작을 파악(30 0)하고, 이후 정의된 UI 상호작용을 수행하는 인터렉션을 제공할 수 있다. 본 발명의 일 실시예에 따르면, 시선 검출단계의 사용자 시선 벡터 검출 방법은 아이트래킹 방법을 포함할 수 있으나, 여기에 한정되지 않는다. 본 발명의 일 실시예에 따르면, 시선 검출단계의 아바타 시선 벡터 검출 방법은 인공지능 학습 방법, 가상공간 데이터 활용 방법을 포함할 수 있으나, 여기에 한정되지 않는다. 본 발명의 일 실시예에 따르면, 미리 설정된 가상공간 내 이벤트를 발생시키는 인터렉션은 가상공간 내에서 UI 상호작용을 제어(예컨대, 오브젝트 클릭 등) 하는 것을 포함할 수 있다. 도 15은 아바타 자동 이동기능을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 방법의 흐름도이다. 도 15에 도시된 바와 같이, 상기 서비스 제공단계는, 상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검 출하는 시선 검출단계(S800), 상기 검출된 시선을 가상 공간 내 좌표로 변환하는 좌표 변환 단계(S810) 및 상기 변환된 좌표로 아바타를 이동시키는 아바타 이동단계(S820)를 포함할 수 있고, 상기 좌표 변환 단계는 검출된 시선이 기 설정된 시간을 초과하는 경우, 좌표 변환을 진행하는 것을 특징으로 할 수 있다. 도 16은 아바타 자동 이동기능을 제공 가상공간 내 시선 센싱을 통한 데이터 활용 서비스의 실시예를 설명하기 위한 도면이다. 도 16에 따른 본 발명의 일 실시예에 따르면, 아바타의 자동 이동 기능을 제공하기 위해서, 아바타 이동 단계는 아바타 제어 의도 파악단계, 아바타 제어단계 및 아바타 위치 이동 완료단계를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 아바타 제어 의도 파악단계의 아바타 제어 의도는, 미리 분류 된 제어 의도와 인공지능 학습된 제어의도를 포함할 수 있고 이에 한정되지 않는다. 도 17은 시간 측정을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 방법의 흐름도이다. 도 17에 도시된 바와 같이, 상기 서비스 제공단계는, 상기 아바타의 시선 방향 벡터와 사용자의 시선 정보를 검 출하는 시선 검출단계(S900), 상기 검출된 시선이 상기 식별된 콘텐츠가 정보 수집 대상 콘텐츠에 해당하는지 여부를 판단하는 대상 콘텐츠 여부 판단 단계(S910) 및 상기 식별된 콘텐츠가 상기 대상 콘텐츠에 해당하는 지 판단하는 단계(S920), 상기 대상 콘텐츠에 해당하는 경우, 시간을 측정하는 시간 측정 시작 단계(S930)를 더 포함할 수 있다. 또한, 상기 식별된 콘텐츠가 상기 대상 콘텐츠에 해당하지 않는 경우, 시간 측정을 종료하는 시간 측정 종료 단 계(S940) 및 상기 시간 측정 종료가 확인되면, 상기 시간 측정 시작 단계 및 시간 측정 종료 단계의 시계열적 정보를 보고하는 시간 보고 단계(S950)를 더 포함할 수 있다. 본 발명의 일 실시예에 따르면, 시간 보고 단계(S950)은 측정된 시간을 활용하여 가공되어 정리 된 정보(예컨데, 관리자 인터페이스, 광고 효과 측정 서비스 정보 등)가 포함된 보고를 포함할 수 있다. 본 발명의 실시예에 따르면, 시간 측정 방법은 서버 또는 사용자 단말에서 진행될 수 있으며 이에 한정되지 않 는다. 또한, 이상에서 실시예를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니며, 본 발 명이 속하는 분야의 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성을 벗어나지 않는 범위에서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 예를 들어, 실시예에 구체적으로 나타 난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함 되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0043193", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 장치의 구성도이다. 도 2는 가상공간 내의 시야 정보의 아바타의 시선 방향 벡터와 사용자의 시선 벡터 정보를 설명하기 위한 도면 이다. 도 3은 본 발명에 따른 스마트 디바이스의 움직임을 감지하기 위한 자이로센서의 움직임 감지 실시예를 나타내 는 개략도이다. 도 4은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법을 설명하기 위한 흐름도이다. 도 5는 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 저장된 데이터를 불 러와 로딩하는 것을 더 포함하는 데이터 수집, 활용 방법을 설명하기 위한 흐름도이다. 도 6은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 인공지능 학습을 통 해 콘텐츠를 식별하는 방법을 설명하기 위한 흐름도이다. 도 7은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 콘텐츠를 식별하기 위해 인공지능 학습을 통해 객체를 분류하는 방법을 설명하기 위한 흐름도이다 도 8는 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 콘텐츠를 식별하기 위해 인공지능 학습을 통해 객체를 추적하는 방법을 설명하기 위한 흐름도이다.도 9은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 콘텐츠를 식별하기 위해 인공지능 학습을 통해 객체를 판단하는 방법을 설명하기 위한 흐름도이다. 도 10은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 아이트래킹 장치를 통해 콘텐츠를 식별하는 방법을 설명하기 위한 흐름도이다. 도 11는 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 가상 공간에 객체 를 배치하는 방법을 설명하기 위한 흐름도이다. 도 12은 본 발명에 따른 가상공간 내 시선 센싱을 활용한 데이터 수집, 활용 방법에 있어서, 가상공간 데이터를 활용하여 인공지능 학습을 통해 사용자에게 적합한 객체를 배치하는 방법을 설명하기 위한 흐름도이다. 도 13은 본 발명의 인터렉션을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 서비스 제공방법의 흐름도 이다. 도 14는 인터렉션을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 서비스의 본 발명에 따른 실시예를 설 명하기 위한 도면이다. 도 15은 아바타 자동 이동기능을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 방법의 흐름도이다. 도 16은 아바타 자동 이동기능을 제공 가상공간 내 시선 센싱을 통한 데이터 활용 서비스의 실시예를 설명하기 위한 도면이다. 도 17은 시간 측정을 제공하는 가상공간 내 시선 센싱을 통한 데이터 활용 방법의 흐름도이다."}
