{"patent_id": "10-2025-0010867", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055445", "출원번호": "10-2025-0010867", "발명의 명칭": "인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치, 방법 및 프로그램", "출원인": "주식회사 센티넬딥액티브", "발명자": "이준"}}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 객체를 포함하는 이미지 정보를 입력 데이터로 하고 상기 이미지 정보에 포함된 복수의 상기 객체를 추출하여 각각의 상기 객체에 대한 객체 class 정보 및 객체 좌표 정보를 포함하는 객체 박스 정보를 출력 데이터로 출력하는 인공신경망 모듈을 포함하는 객체 인식 모듈; 및상기 객체 박스 정보를 기초로 생성된 객체 이미지 정보를 입력 받고, 상기 객체 이미지 정보에 대한 객체 특징벡터를 출력하는 객체 특징 벡터 생성 모듈;을 포함하고, 상기 객체 특징 벡터 생성 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하여 Quick Draw Dataset으로 Pre-trained 되고 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 제1 Quick Draw Dataset 인공신경망 모듈;을 포함하고, 상기 제1 Quick Draw Dataset 인공신경망 모듈의 복수의 상기 BottleNeck에서 각각의 상기 객체에 대한 Feature map인 객체 특징 벡터를 추출하는 특징 추출 모듈;을 포함하도록 구성되고,상기 객체 특징 벡터 생성 모듈은 객체 분절 모듈;을 더 포함하고, 상기 객체 분절 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하고 상기 객체 이미지 정보에 대한 액티베이션 정보를 출력 데이터로 하며 FCN layer가 포함된 CNN 기반의 인공신경망 모듈인 FCN 인공신경망 모듈 및 상기액티베이션 정보를 기반으로 상기 객체 이미지 정보의 길이방향으로 상기 객체 이미지 정보를 복수의 이미지로분절하여 복수의 객체 분절 이미지 정보를 생성하고, 상기 복수의 객체 분절 이미지를 상기 제1 Quick Draw Dataset 인공신경망 모듈의 입력 데이터로 입력하고, 상기 특징 추출 모듈은 상기 복수의 객체 분절 이미지에 대한 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를생성하도록 구성되는 것을 특징으로 하는, 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 객체 분절 모듈은, 상기 FCN 인공신경망 모듈에서 출력되는 객체 클래스 확률에 따라 상기 객체 이미지 정보의 크기를 특정 가중치만큼 조정하여 상기 FCN 인공신경망 모듈의 입력 데이터로 재입력하고,상기 특정 가중치는 1/[객체 클래스 확률] 또는 1＋(1－[객체 클래스 확률])인 것을 특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 객체 분절 모듈은,상기 FCN 인공신경망 모듈로부터 출력된 액티베이션 정보를 기반으로, 상기 객체 이미지 정보의 길이 방향으로액티베이션 값의 피크와 피크 사이를 분절하여 복수의 분절 좌표 정보를 생성하고,상기 분절 좌표 정보에 따라 상기 객체 이미지 정보를 분절하여 복수의 객체 분절 이미지 정보를 생성하는 것을특징으로 하는,공개특허 10-2025-0055445-3-인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 FCN 인공신경망 모듈은,전결합층(Fully Connected Layer) 대신 전합성곱층(Fully Convolutional Layer)을 포함하고,Global Average Pooling(GAP)이 적용된 출력층을 통해 상기 객체 이미지 정보에 대한 객체 클래스 확률을 출력하도록 구성된 것을 특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 특징 추출 모듈은,상기 복수의 객체 분절 이미지 정보 각각에 대해 출력되는 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를생성하고,상기 객체 특징 벡터들을 조합하여 특징 벡터를 생성하도록 구성된 것을 특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "객체 인식 모듈이, 복수의 객체를 포함하는 이미지 정보를 입력받고 상기 이미지 정보에 포함된 복수의 상기 객체를 추출하여 각각의 상기 객체에 대한 객체 class 정보 및 객체 좌표 정보를 포함하는 객체 박스 정보를 출력하는 객체 인식 단계; 및객체 특징 벡터 생성 모듈이, 상기 객체 박스 정보를 기초로 생성된 객체 이미지 정보를 입력 받고, 상기 객체이미지 정보에 대한 객체 특징 벡터를 출력하는 객체 특징 벡터 생성 단계;를 포함하고, 상기 객체 특징 벡터 생성 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하여 Quick Draw Dataset으로 Pre-trained 되고 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 제1 Quick Draw Dataset 인공신경망 모듈;을 포함하고, 상기 제1 Quick Draw Dataset 인공신경망 모듈의 복수의 상기 BottleNeck에서 각각의 상기 객체에 대한 Feature map인 객체 특징 벡터를 추출하는 특징 추출 모듈;을 포함하도록 구성되고,상기 객체 특징 벡터 생성 모듈은 객체 분절 모듈;을 더 포함하고, 상기 객체 분절 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하고 상기 객체 이미지 정보에 대한 액티베이션 정보를 출력 데이터로 하며 FCN layer가 포함된 CNN 기반의 인공신경망 모듈인 FCN 인공신경망 모듈 및 상기액티베이션 정보를 기반으로 상기 객체 이미지 정보의 길이방향으로 상기 객체 이미지 정보를 복수의 이미지로분절하여 복수의 객체 분절 이미지 정보를 생성하고, 상기 복수의 객체 분절 이미지를 상기 제1 Quick Draw Dataset 인공신경망 모듈의 입력 데이터로 입력하고, 상기 특징 추출 모듈은 상기 복수의 객체 분절 이미지에 대한 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를생성하도록 구성되는 것을 특징으로 하는, 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 방법.공개특허 10-2025-0055445-4-청구항 7 제6항에 있어서, 상기 객체 분절 모듈은, 상기 FCN 인공신경망 모듈에서 출력되는 객체 클래스 확률에 따라 상기 객체 이미지 정보의 크기를 특정 가중치만큼 조정하여 상기 FCN 인공신경망 모듈의 입력 데이터로 재입력하고,상기 특정 가중치는 1/[객체 클래스 확률] 또는 1＋(1－[객체 클래스 확률])인 것을 특징으로 하는, 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 방법."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 객체 분절 모듈은,상기 FCN 인공신경망 모듈로부터 출력된 액티베이션 정보를 기반으로, 상기 객체 이미지 정보의 길이 방향으로액티베이션 값의 피크와 피크 사이를 분절하여 복수의 분절 좌표 정보를 생성하고,상기 분절 좌표 정보에 따라 상기 객체 이미지 정보를 분절하여 복수의 객체 분절 이미지 정보를 생성하는 것을특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 방법."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 FCN 인공신경망 모듈은,전결합층(Fully Connected Layer) 대신 전합성곱층(Fully Convolutional Layer)을 포함하고,Global Average Pooling(GAP)이 적용된 출력층을 통해 상기 객체 이미지 정보에 대한 객체 클래스 확률을 출력하도록 구성된 것을 특징으로 하는, 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 방법."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 특징 추출 모듈은,상기 복수의 객체 분절 이미지 정보 각각에 대해 출력되는 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를생성하고,상기 객체 특징 벡터들을 조합하여 특징 벡터를 생성하도록 구성된 것을 특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 방법."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공지능 기반의 객체 분절을 활용한 객체 특징 추출 프로그램을 포함하는 메모리; 및상기 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 프로그램을 처리하는 프로세서;공개특허 10-2025-0055445-5-를 포함하고,상기 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 프로그램은,객체 인식 모듈이, 복수의 객체를 포함하는 이미지 정보를 입력받고 상기 이미지 정보에 포함된 복수의 상기 객체를 추출하여 각각의 상기 객체에 대한 객체 class 정보 및 객체 좌표 정보를 포함하는 객체 박스 정보를 출력하는 객체 인식 단계; 및객체 특징 벡터 생성 모듈이, 상기 객체 박스 정보를 기초로 생성된 객체 이미지 정보를 입력 받고, 상기 객체이미지 정보에 대한 객체 특징 벡터를 출력하는 객체 특징 벡터 생성 단계;를 포함하는 단계를 컴퓨터 상에서 수행하도록 구성되고,상기 객체 특징 벡터 생성 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하여 Quick Draw Dataset으로 Pre-trained 되고 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 제1 Quick Draw Dataset 인공신경망 모듈;을 포함하고, 상기 제1 Quick Draw Dataset 인공신경망 모듈의 복수의 상기 BottleNeck에서 각각의 상기 객체에 대한 Feature map인 객체 특징 벡터를 추출하는 특징 추출 모듈;을 포함하도록 구성되고,상기 객체 특징 벡터 생성 모듈은 객체 분절 모듈;을 더 포함하고, 상기 객체 분절 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하고 상기 객체 이미지 정보에 대한 액티베이션 정보를 출력 데이터로 하며 FCN layer가 포함된 CNN 기반의 인공신경망 모듈인 FCN 인공신경망 모듈 및 상기액티베이션 정보를 기반으로 상기 객체 이미지 정보의 길이방향으로 상기 객체 이미지 정보를 복수의 이미지로분절하여 복수의 객체 분절 이미지 정보를 생성하고, 상기 복수의 객체 분절 이미지를 상기 제1 Quick Draw Dataset 인공신경망 모듈의 입력 데이터로 입력하고, 상기 특징 추출 모듈은 상기 복수의 객체 분절 이미지에 대한 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를생성하도록 구성되는 것을 특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 객체 분절 모듈은, 상기 FCN 인공신경망 모듈에서 출력되는 객체 클래스 확률에 따라 상기 객체 이미지 정보의 크기를 특정 가중치만큼 조정하여 상기 FCN 인공신경망 모듈의 입력 데이터로 재입력하고,상기 특정 가중치는 1/[객체 클래스 확률] 또는 1＋(1－[객체 클래스 확률])인 것을 특징으로 하는, 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 객체 분절 모듈은,상기 FCN 인공신경망 모듈로부터 출력된 액티베이션 정보를 기반으로, 상기 객체 이미지 정보의 길이 방향으로액티베이션 값의 피크와 피크 사이를 분절하여 복수의 분절 좌표 정보를 생성하고,상기 분절 좌표 정보에 따라 상기 객체 이미지 정보를 분절하여 복수의 객체 분절 이미지 정보를 생성하는 것을특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치.공개특허 10-2025-0055445-6-청구항 14 제11항에 있어서,상기 FCN 인공신경망 모듈은,전결합층(Fully Connected Layer) 대신 전합성곱층(Fully Convolutional Layer)을 포함하고,Global Average Pooling(GAP)이 적용된 출력층을 통해 상기 객체 이미지 정보에 대한 객체 클래스 확률을 출력하도록 구성된 것을 특징으로 하는,인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 특징 추출 모듈은,상기 복수의 객체 분절 이미지 정보 각각에 대해 출력되는 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를생성하고,상기 객체 특징 벡터들을 조합하여 특징 벡터를 생성하도록 구성된 것을 특징으로 하는, 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치."}
{"patent_id": "10-2025-0010867", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "인공지능 기반의 객체 분절을 활용한 객체 특징 추출를 수행하는 명령어들의 시퀀스를 포함하는 컴퓨터 판독 가능 기록매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우, 객체 인식 모듈이, 복수의 객체를 포함하는 이미지 정보를 입력받고 상기 이미지 정보에 포함된 복수의 상기 객체를 추출하여 각각의 상기 객체에 대한 객체 class 정보 및 객체 좌표 정보를 포함하는 객체 박스 정보를 출력하는 객체 인식 단계; 및객체 특징 벡터 생성 모듈이, 상기 객체 박스 정보를 기초로 생성된 객체 이미지 정보를 입력 받고, 상기 객체이미지 정보에 대한 객체 특징 벡터를 출력하는 객체 특징 벡터 생성 단계;를 포함하는 명령어들의 시퀀스를 포함하고, 상기 객체 특징 벡터 생성 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하여 Quick Draw Dataset으로 Pre-trained 되고 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 제1 Quick Draw Dataset 인공신경망 모듈;을 포함하고, 상기 제1 Quick Draw Dataset 인공신경망 모듈의 복수의 상기 BottleNeck에서 각각의 상기 객체에 대한 Feature map인 객체 특징 벡터를 추출하는 특징 추출 모듈;을 포함하도록 구성되고,상기 객체 특징 벡터 생성 모듈은 객체 분절 모듈;을 더 포함하고, 상기 객체 분절 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하고 상기 객체 이미지 정보에 대한 액티베이션 정보를 출력 데이터로 하며 FCN layer가 포함된 CNN 기반의 인공신경망 모듈인 FCN 인공신경망 모듈 및 상기액티베이션 정보를 기반으로 상기 객체 이미지 정보의 길이방향으로 상기 객체 이미지 정보를 복수의 이미지로분절하여 복수의 객체 분절 이미지 정보를 생성하고, 상기 복수의 객체 분절 이미지를 상기 제1 Quick Draw Dataset 인공신경망 모듈의 입력 데이터로 입력하고, 상기 특징 추출 모듈은 상기 복수의 객체 분절 이미지에 대한 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를생성하도록 구성되는 것을 특징으로 하는, 공개특허 10-2025-0055445-7-컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치 및 방법에 관한 것이다. 이를 위하여, 복수 의 객체를 포함하는 이미지 정보를 입력 데이터로 하고 이미지 정보에 포함된 복수의 객체를 추출하여 각각의 객 체에 대한 객체 class 정보 및 객체 좌표 정보를 포함하는 객체 박스 정보를 출력 데이터로 출력하는 인공신경망 모듈을 포함하는 객체 인식 모듈; 객체 박스 정보를 기초로 생성된 객체 이미지 정보를 입력 받고, 객체 이미지 정보에 대한 객체 특징 벡터를 출력하는 객체 특징 벡터 생성 모듈; 이미지 정보를 입력 받고, 이미지 정보에 대 한 스타일 벡터를 출력하는 스타일 벡터 생성 모듈; 각각의 객체에 대한 객체 특징 벡터를 조합(concatenate)한 벡터인 특징 벡터와 스타일 벡터와의 조합 벡터를 입력 데이터로 하고, 이미지 정보에 대한 분류 정보를 출력 데 이터로 출력하는 인공신경망 모듈을 포함하는 분류 모듈이 제안될 수 있다."}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치, 방법 및 프로그램에 관한 것이다."}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "그림을 이용한 심리 분석은 20세기를 전후로 발달되기 시작하였다. 19세기 말 유럽에서는 정신장애 환자들의 그 림에 대한 관심이 증가하면서 그림이 심리의 진단에 도움을 주는 도구로 사용될 수 있다는 인식이 싹트기 시작 하였으며, 20세기 초에는 정신장애 환자들의 그림이 정신분열증과 같은 정신장애 진단을 확증해줄 수 있을만큼 타당성을 지닌다는 견해가 당대 학자들 사이에서 광범위하게 확산되면서 지능 및 성격 평가도구로서 그림 심리 분석이 출현하였다. 즉, 그림에 대한 공식적인 연구는 20세기를 전후로 정신장애 환자들의 그림에 대한 관심이 증대되고 프로이트와 융의 창조적인 연구들이 축적되어 가는 가운데 아동심리발달에 관한 이론적, 경험적 연구 들이 맞물리면서부터 시작되었다고 할 수 있다. 1940년을 전후로 하여 그림이 개인의 정서적 측면과 성격을 평가하는 도구로 사용할 수 있다는 주장이 대두되면 서, '그림은 개인의 심리적 현실 및 주관적 경험을 드러내준다'는 인식(그림을 내적 심리 상태에 대한 시각적 표상이라는 인식)에 바탕을 두고 '투사적 그림'이라는 용어가 등장하였고 투사적 그림 심리 분석이 발전하게 되 었다. 이러한 투사적 그림 심리 분석은 '사람이나 집, 나무와 같은 특정한 형상에 대한 그림은 개인의 성격, 지 각, 태도를 반영해준다'라는 가정에 기반하고 있다. 그림을 이용한 심리 분석에는 여러가지 종류가 있는데, 가장 널리 알려진 투사적 그림 심리 분석 중 하나가 벅 (1948, 1966)의 'House-Tree-Person Test(HTP)'이다. 집-나무-사람 검사(House-Tree-Person test), 간단히 HTP 검사(HTP test)는 인격의 양상을 측정하기 위해 설계된 투영 검사법이다. 이 검사는 뇌 손상과 일반적인 정신 기능을 분석하기 위해 사용될 수도 있다. 이 검사는 임상심리학자, 교육자, 고용주들을 위한 진단 도구이다. 검 사를 받는 사람은 집, 나무, 사람 그림을 그려보라는 분명하지 않은 짧은 지시를 받는다. 그림을 완성하면 자신 이 그린 그림에 대해 설명하라고 요청을 받는다. 피실험자가 그림을 그릴 때 자신의 내면 세계를 종이 위로 투 영하고 있다고 가정한다. 이 시험의 관리자는 드로잉을 통한 피실험자의 내면 세계를 파악하는 목적을 위해 구 축해놓은 도구들과 스킬들을 사용한다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 10-2294741, 딥러닝을 통한 그림기반 심리검사 방법 및 서버, (주)제이앤리 (특허문헌 0002) 대한민국 등록특허 10-1772987, 스캔 이미지를 이용한 심리검사결과 제공 방법, (주)코뮤즈"}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "최근 비대면 심리 상담의 요구가 증대되고 있어, 온라인으로 그림 심리 분석을 수행하는 인공신경망의 개발이 필요한 실정이다. 하지만, 이러한 그림 심리 분석을 수행하는 인공신경망의 개발에는 단순히 기존에 개발된 인공신경망 구조를 그 대로 이용하는 것에 어려움이 있었다. 심리학에서는 어떠한 행동의 인과관계를 이해하는 것에 관심을 두지만, 딥러닝은 결과를 도출하는 것에 집중하기 때문이다. 사람의 행동을 예시로 설명하자면, 딥러닝은 사람의 행동을 예측하는 데 매우 유용하지만, 왜 그 행동을 하게 되었는지를 설명하는 데에는 큰 도움을 주지 못하기 때문에심리학에 딥러닝을 적용하기는 어려움이 있었다. 따라서, 본 발명의 목적은, 그림 심리의 인과관계를 이해하는데 도움을 줄 수 있는 인공지능 기반의 객체 분절 을 활용한 객체 특징 추출 장치 및 방법을 제공하는데에 있다."}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 목적은, 복수의 객체를 포함하는 피검사자 그림 이미지 정보를 입력 데이터로 하고 상기 피검사자 그 림 이미지 정보에 포함된 복수의 상기 객체를 추출하여 각각의 상기 객체에 대한 객체 class 정보 및 객체 좌표 정보를 포함하는 객체 박스 정보를 출력 데이터로 출력하는 인공신경망 모듈을 포함하는 객체 인식 모듈; 상기 객체 박스 정보를 기초로 생성된 객체 이미지 정보를 입력 받고, 상기 객체 이미지 정보에 대한 객체 특징 벡터 를 출력하는 객체 특징 벡터 생성 모듈; 상기 피검사자 그림 이미지 정보를 입력 받고, 상기 피검사자 그림 이 미지 정보에 대한 그림 스타일 벡터를 출력하는 그림 스타일 벡터 생성 모듈; 각각의 상기 객체에 대한 상기 객 체 특징 벡터를 조합(concatenate)한 벡터인 피검사자 그림 특징 벡터와 상기 그림 스타일 벡터와의 조합 벡터 를 입력 데이터로 하고, 상기 피검사자 그림 이미지 정보에 대한 감정 분류 정보를 출력 데이터로 출력하는 인 공신경망 모듈을 포함하는 감정 분류 모듈; 및 상기 객체 인식 모듈 및 상기 감정 분류 모듈에 포함된 인공신경 망 모듈의 학습 세션을 처리하여 파라미터를 업데이트 하고, 업데이트 된 파라미터를 메인 신경망 서버의 일구 성인 연합 학습 모듈에 업로드 하며, 상기 메인 신경망 서버의 일구성인 메인 신경망 모듈에서 복수의 피검사자 클라이언트에 의해 연합 학습된 메인 신경망을 다운로드 받아 상기 객체 인식 모듈 및 상기 감정 분류 모듈에 포함된 인공신경망 모듈의 적어도 일부를 대체하는 신경망 처리 모듈; 을 포함하고, 상기 메인 신경망 서버는, 상기 파라미터와 다른 피검사자 클라이언트에서 업로드 된 다른 파라미터를 통합하여 상기 객체 인식 모듈 및 상기 감정 분류 모듈에 포함된 인공신경망을 업데이트 하도록 구성되는, 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치를 제공하여 달성될 수 있다. 또한, 상기 객체 특징 벡터 생성 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하여 Quick Draw Dataset으로 Pre-trained 되고 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 제1 Quick Draw Dataset 인공 신경망 모듈;을 포함하고, 상기 제1 Quick Draw Dataset 인공신경망 모듈의 복수의 상기 BottleNeck에서 각각의 상기 객체에 대한 Feature map인 객체 특징 벡터를 추출하는 특징 추출 모듈;을 포함하도록 구성될 수 있다. 또한, 상기 그림 스타일 벡터 생성 모듈은, 상기 피검사자 이미지 정보를 입력 데이터로 하여 상기 피검사자 그 림 이미지 정보의 Style Feature를 추출하기 위해 Quick Draw Dataset으로 Pre-trained 되고 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 제2 Quick Draw Dataset 인공신경망 모듈;을 포함하고, 상기 제2 Quick Draw Dataset 인공신경망 모듈의 복수의 상기 BottleNeck에서 상기 피검사자 그림 이미지 정보 에 대한 Style Feature Map인 그림 스타일 벡터를 추출하는 스타일 특징 추출 모듈;을 포함하도록 구성될 수 있 다. 또한, 상기 감정 분류 모듈은, Multi-head Self Attention Layer, FFNN 및 softmax를 포함하도록 구성될 수 있 다. 또한, 상기 객체 특징 벡터 생성 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하여 Quick Draw Dataset으로 Pre-trained 되고 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 제1 Quick Draw Dataset 인공 신경망 모듈;을 포함하고, 상기 제1 Quick Draw Dataset 인공신경망 모듈의 복수의 상기 BottleNeck에서 각각의 상기 객체에 대한 Feature map인 객체 특징 벡터를 추출하는 특징 추출 모듈;을 포함하도록 구성되고, 상기 객 체 분절 모듈은, 상기 객체 이미지 정보를 입력 데이터로 하고 상기 객체 이미지 정보에 대한 액티베이션 정보 를 출력 데이터로 하며 FCN layer가 포함된 CNN 기반의 인공신경망 모듈인 FCN 인공신경망 모듈 및 상기 액티베 이션 정보를 기반으로 상기 객체 이미지 정보의 길이방향으로 상기 객체 이미지 정보를 복수의 이미지로 분절하 여 복수의 객체 분절 이미지 정보를 생성하고, 상기 복수의 객체 분절 이미지를 상기 제1 Quick Draw Dataset 인공신경망 모듈의 입력 데이터로 입력하고, 상기 특징 추출 모듈은 상기 복수의 객체 분절 이미지에 대한 객체 분절 벡터를 조합하여 상기 객체 특징 벡터를 생성하도록 구성될 수 있다. 본 발명의 다른 목적은, 객체 인식 모듈이, 복수의 객체를 포함하는 피검사자 그림 이미지 정보를 입력받고 상 기 피검사자 그림 이미지 정보에 포함된 복수의 상기 객체를 추출하여 각각의 상기 객체에 대한 객체 class 정 보 및 객체 좌표 정보를 포함하는 객체 박스 정보를 출력하는 객체 인식 단계; 객체 특징 벡터 생성 모듈이, 상 기 객체 박스 정보를 기초로 생성된 객체 이미지 정보를 입력 받고, 상기 객체 이미지 정보에 대한 객체 특징 벡터를 출력하는 객체 특징 벡터 생성 단계; 그림 스타일 벡터 생성 모듈이, 상기 피검사자 그림 이미지 정보를 입력 받고, 상기 피검사자 그림 이미지 정보에 대한 그림 스타일 벡터를 출력하는 그림 스타일 벡터 생성 단계; 감정 분류 모듈이, 각각의 상기 객체에 대한 상기 객체 특징 벡터를 조합(concatenate)한 벡터인 피검사자 그림 특징 벡터와 상기 그림 스타일 벡터와의 조합 벡터를 입력받고, 상기 피검사자 그림 이미지 정보에 대한 감정 분류 정보를 출력하는 감정 분류 단계; 및 신경망 처리 모듈이, 상기 객체 인식 모듈 및 상기 감정 분류 모듈에 포함된 인공신경망 모듈의 학습 세션을 처리하여 파라미터를 업데이트 하고, 업데이트 된 파라미터를 메인 신경 망 서버의 일구성인 연합 학습 모듈에 업로드 하며, 상기 메인 신경망 서버의 일구성인 메인 신경망 모듈에서 복수의 피검사자 클라이언트에 의해 연합 학습된 메인 신경망을 다운로드 받아 상기 객체 인식 모듈 및 상기 감 정 분류 모듈에 포함된 인공신경망 모듈의 적어도 일부를 대체하는 신경망 처리 단계;를 포함하고, 상기 메인 신경망 서버는, 상기 파라미터와 다른 피검사자 클라이언트에서 업로드 된 다른 파라미터를 통합하여 상기 객체 인식 모듈 및 상기 감정 분류 모듈에 포함된 인공신경망을 업데이트 하도록 구성되는, 인공지능 기반의 객체 분 절을 활용한 객체 특징 추출 장치 방법을 제공하여 달성될 수 있다."}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 첫째, 본 발명의 일실시예에 따르면, 피검사자 그림 이미지에 포함된 개인정보가 다른 피검사자 클라이언트에 공유되지 않으면서도 그림 심리 분석을 수행하기 위한 객체 인식 모듈 및 감정 분류 모듈의 인공신경망을 학습 시킬 수 있게 되는 효과가 발생된다. 둘째, 본 발명의 일실시예에 따르면, 객체 좌표 정보에 '각도' 정보가 더 포함되게 되므로, 객체 박스 이미지의 객체 각도가 표준화되고, 객체 특징 벡터에 피검사자가 객체를 그린 각도에 대한 특징이 포함되는 효과가 발생 된다. 셋째, 본 발명의 일실시예에 따른 객체 특징 벡터 생성 모듈의 Quick Draw Dataset 인공신경망 모듈 및 특징 추 출 모듈에 따르면, 연산 효율이 증대되고 파라미터가 감소되는 동시에 피검사자 그림 이미지 정보와 같은 Quick Draw Dataset에 존재하는 노이즈 성분의 학습 세션에서의 영향을 최소화하는 효과가 발생된다. 또한, 특징 추출 모듈에 의해 추상화 레벨의 특징 정보와 디테일 레벨의 특징 정보를 모두 포함할 수 있게 되는 효과가 발생된다."}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하에서는, 설명의 편의를 위해 HTP test를 기초로 설명하였으나, 본 발명의 범위는 HTP test에 한정되지 않고, Draw-a-Person test(DAP), Kinetic House-Tree-Person test(KHTP), Chromatic or Color Drawing test, Draw-a-Person-in-the-Rain test, Drawing of Animals test, Self-Portrait test, Draw-a-Family(DAF), Kinetic Family Drawing(KFD), Family-Centerd-Circle Drawing(Fccd), Draw-a-Group(DAG), Akinetic School Drawing(ASD), Kinetic School Drawing(KSD), Landscape Montage Technique(LMT), 나무그림검사 등의 그림 심 리 분석 기법을 포함할 수 있다. 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치의 작동관계와 관련하여, 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치의 작동관계를 도 시한 모식도, 도 2는 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치와 메인 신경망 서버의 각 단계에 따른 작동관계를 도시한 모식도, 도 3은 본 발명의 일실시예에 따른 인공지능 기 반의 객체 분절을 활용한 객체 특징 추출 장치의 구성관계를 도시한 모식도, 도 4는 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치의 구체적인 작동관계를 도시한 모식도이다. 도 1에 도시된 바와 같이, 피검사자가 검사자의 지시에 따라 그린 특정 검사 그림을 피검사자 클라이언트의 drawing application을 통해 생성, 피검사자 클라이언트의 촬영 또는 별도의 스캔 장비의 스캔을 통해 생 성한 피검사자 그림 이미지 정보를 피검사자 클라이언트에 포함된 본 발명의 일실시예에 따른 인공지능 기 반의 객체 분절을 활용한 객체 특징 추출 장치에 입력하고, 인공지능 기반의 객체 분절을 활용한 객체 특징 추 출 장치에서 메인 신경망 서버에 인공지능 기반 그림 심리 분석 장치에 포함된 인공신경망의 파라미터를 송신하 도록 구성되며, 피검사자 클라이언트에서 검사자 클라이언트에 객체 박스 정보 및 감정 분류 정보를 송신하고 검사자 클라이언트에서는 수정 정보를 수신하도록 구성된다. 또한, 도 2에 도시된 바와 같이 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치는 복수개의 피검사자 클라이 언트에 각각 구성되며, 메인 신경망 서버와 유무선 네트워크로 연결되어 클라이언트 학습 단계, 파라 미터 업데이트 단계 및 메인 신경망 다운로드 단계를 수행하도록 구성될 수 있다. 또한, 도 3, 4에 도시된 바와 같이 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치는, 피검사자가그린 그림의 이미지 정보인 피검사자 그림 이미지 정보를 입력 데이터로 하고 상기 피검사자 그림 이미지 정보 에 대응되는 피검사자의 감정 분류 정보를 출력 데이터로 하며, 객체 인식 모듈, 객체 특징 벡터 생성 모듈, 그 림 스타일 벡터 생성 모듈, 감정 분류 모듈, 클라이언트 학습 모듈, 파라미터 업로드 모듈, 메인 신경망 다운로 드 모듈을 포함할 수 있다. 파라미터 업로드 모듈에서는 변경된 파라미터와 수정 변화 정보를 메인 신경망 서버 의 연합 학습 모듈에 송신하고, 연합 학습 모듈에서는 복수의 피검사자 클라이언트에서 수 신된 파라미터와 수정 변화 정보를 기초로 연합 학습을 수행하여 기학습된 메인 신경망을 생성하도록 구성될 수 있다. 기학습된 메인 신경망은 메인 신경망 모듈을 통해 객체 인식 모듈 및 감정 분류 모듈의 인공신경망 모듈을 업데이트하도록 구성될 수 있다. 이에 따르면, 피검사자 그림 이미지에 포함된 개인정보가 다른 피검사 자 클라이언트에 공유되지 않으면서도 그림 심리 분석을 수행하기 위한 객체 인식 모듈 및 감정 분류 모듈 의 인공신경망을 학습시킬 수 있게 되는 효과가 발생된다. 객체 인식 모듈과 관련하여, 도 5는 본 발명의 일실시예에 따른 객체 인식 모듈을 도시한 모식도이다. 도 5에 도시된 바와 같이, 객체 인식 모듈은, 피검사자 그림 이미지 정보를 입력 데이터로 하고 피검사자 그림 이미지 정보에 포함된 객체를 둘러싸는 bounding box인 객체 박스에 어떤 class의 객체가 포함되어있는지 여부인 객체 class 정보, 객체 class 신뢰도(confidence score 또는 class probability), 상기 객체 박스의 좌표, 높이, 너 비, 각도를 포함하는 객체 좌표 정보 및 해당 객체가 얼마나 상세히 그려졌는지에 대한 Score를 의미하는 객체 디테일 정보를 포함하는 객체 박스 정보를 출력 데이터로 하는 인공신경망 모듈을 의미할 수 있다. 본 발명의 일실시예에 따른 객체 인식 모듈은 classification과 localization을 수행하는 multi-object detection 인공신경망 모듈을 포함할 수 있고, 이러한 multi-object detection 인공신경망 모듈로는 2-stage detector로서 RCNN, OverFeat(ICLR 2014), Fast RCNN(ICCV 2015), Faster RCNN(NIPS 2015), Mask RCNN(ICCV 2017) 등이 활용될 수 있고, 1-stage detector로서 anchor based의 YOLO v1(CVPR 2016), YOLO v2(CVPR 2017), YOLO v3(arXiv 2018), SSD(ECCV 2016), RetinaNet(ICCV 2017) 등이 활용될 수 있으며, 1- stage detector로서 non-anchor based의 CornerNet(ECCV 2018), ExtreamNet, CenterNet 등이 활 용될 수 있고, CRAFT(down sampling/up sampling) 등이 활용될 수 있다. 본 발명의 일실시예에 따른 객체 인식 모듈의 출력 데이터는, 피검사자 그림 이미지 정보 내에 포함되는 적어도 하나 이상의 object에 대한 객체 class의 신뢰도를 의미하는 객체 class 정보(confidence score 또는 class probability), 해당 객체 object(객체 class로 추론되는 object)의 좌표 정보인 객체 좌표 정보(coordinate data)를 포함할 수 있고, object의 객체 좌표 정보는 인공신경망의 구성에 따라 bounding box의 top-left coner와 bottom-right coner의 좌표, bounding box의 centeral region 좌표, bounding box의 width 및 hight, bounding box의 각도(angle)를 포함하도록 구성될 수 있으며, bounding box 내의 해당 객체가 얼마나 상세히 그 려졌는지를 의미하는 객체 디테일 정보를 포함하도록 구성될 수 있다. 예를 들어, 피검사자 그림 이미지 정보 내에 포함되는 특정 object에 대한 객체 class 정보는 [0.8], 객체 좌표 정보는 [x,y,w,h,θ], 객체 디테일 정 보는 [0.4] 등의 형태로 구성될 수 있다. 본 발명의 일실시예에 따르면, 객체 좌표 정보에 '각도' 정보가 더 포 함되게 되므로, 객체 박스 이미지의 객체 각도가 표준화되고, 객체 특징 벡터에 피검사자가 객체를 그린 각도에 대한 특징이 포함되는 효과가 발생된다. 도 6은 본 발명의 일실시예에 따른 객체 인식 모듈이 YOLO v5으로 구성되는 경우의 구조를 도시한 모식도이다. 예를 들어, 도 6에 도시된 바와 같이 본 발명의 일실시예에 따른 객체 인식 모듈을 YOLO v5으로 구성하는 경우, ImageNet Pre-trained Model을 사용할 수 있으며, convolution layer들을 통해 feature map을 추출하고, fully connected layer를 거쳐 바로 bounding box의 객체 class probability(class confidence, 객체 클래스 정보), coordinate data(객체 좌표 정보)와 객체 디테일 정보를 추론(inference)하여 출력 데이터로서 출력하도록 구성 된다. YOLO에서는 input 이미지인 피검사자 그림 이미지 정보를 SxS grid로 나누고 각 grid 영역에 해당하는 bounding box(SxSxB개)와 Class confidence(Probability(object)×IoU(prediction, ground truth)), Class probability map(Probability(Class_i|object))을 구하도록 구성된다. 구체적인 네트워크 구조를 예를 들면, 한 grid 영역당 n개의 bounding box coordinate(객체 좌표 정보)와 confidence score(객체 클래스 정보)를 출 력하도록 구성될 수 있고, 예를 들어, 피검사자 그림 이미지 정보는 448x448x3의 크기로 입력되도록 구성될 수 있으며, ImageNet Pre-trained Model의 Activation map은 7x7x1024의 크기로 구성될 수 있고, ImageNet Pre- trained Model 이후 4096 및 7x7x30의 Fully Connected Layer가 구성될 수 있다. 본 발명의 일실시예에 따른 객체 인식 모듈의 학습 세션에서는 피검사자 그림 이미지 정보의 원본 이미지에서 House, Tree, Person 객체를 이용하여 정답 데이터(Ground Truth) 생성 후 ImageNet Pre-trained Model의 파라미터를 fine-tuning 하도록구성될 수 있다. 객체 특징 벡터 생성 모듈과 관련하여, 도 7은 본 발명의 일실시예에 따른 객체 특징 벡터 생성 모듈을 도시한 모식도이다. 도 7에 도시된 바와 같이, 본 발명의 일실시예에 따른 객체 특징 벡터 생성 모듈은, 객체 클래스 정보의 각 객체 class에 따른 상기 객체 좌표 정보를 기반으로 상기 피검사자 그림 이미지 정보에서 각 객체 class에 대한 객체 이미지 정보를 생성하여 상기 객체 이미지 정보를 입력 데이터로 하고 각 객체 class에 대한 객체 특징 벡터를 출력 데이터로 하는 인공신경망 모듈을 의미할 수 있다. 또한, 각 객체 class에 대한 객체 특 징 벡터를 조합(concatenate)하여 피검사자 그림 이미지 정보에 대한 특징 벡터인 피검사자 특징 벡터를 출력하 도록 구성될 수 있다. 객체 특징 벡터 생성 모듈의 구체적인 구성과 관련하여, 본 발명의 일실시예에 따른 객체 특징 벡터 생성 모듈 은 상기 객체 이미지 정보를 입력 데이터로 하여 피검사자 그림 이미지 정보의 각 객체에 관한 그림 데이터에 최적화된 Feature를 추출하기 위해 Quick Draw Dataset으로 Pre-trained 되고, 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경망 모듈인 Quick Draw Dataset 인공신경망 모듈(예를 들어, ResNet을 backbone network로 할 수 있음)을 포함할 수 있고, 상기 Quick Draw Dataset 인공신경망 모듈의 복수의 BottleNeck에서 각 객체 class(예를 들어, House, Tree, Person 객체)의 Feature map를 추출하는 특징 추출 모듈(Feature Extraction Module)을 더 포함할 수 있다. 이때, Quick Draw Dataset 인공신경망 모듈의 BottleNeck은, CNN에서 차원이 축 소되기 전의 Layer를 의미할 수 있으며, BottleNeck Feature map은 CNN에서 차원이 축소되기 전의 Convolution Layer의 출력 feature map을 의미할 수 있다. 객체 특징 벡터 생성 모듈과 특징 추출 모듈은 아래의 단계로 각 객체 class에 대한 객체 특징 벡터 및 피검사 자 그림 특징 벡터를 출력하도록 구성될 수 있다. ① 객체 인식 모듈에서 추출한 각 객체 class(House, Tree, Person)의 객체 이미지 정보가 객체 특징 벡터 생성 모듈의 Quick Draw Dataset 인공신경망 모듈의 입력 데이터로 입력 ② 특징 추출 모듈이, Quick Draw Dataset 인공신경망 모듈에 구성된 복수의 BottleNeck에서 서로 다른 scale 을 가진 Feature map(BottleNeck Feature map)을 추출(a1, a2, a3 vector, Bottom-up pathway) ③ 특징 추출 모듈이, 추출된 복수의 BottleNeck Feature map 각각에 1x1 conv. 연산을 적용하여 모든 BottleNeck Feature map의 channel 수를 n(예를 들어, 256)으로 맞추고 크기를 m배(예를 들어, 2배)로 Upsampling ④ 특징 추출 모듈이, Upsampling된 복수의 BottleNeck Feature map에 Lateral connections을 적용하여 각 feature map을 바로 아래 pyramid level에 존재하는 feature map과 element-wise addition 연산하여 Top-down pathway로 통합하고 3x3 conv. 연산을 적용(b1, b2, b3 vector) ⑤ 특징 추출 모듈이, 통합 된 feature map 중 최상단 level의 BottleNeck Feature map을 추출 ⑥ 특징 추출 모듈이, 추출 된 최상단 level의 BottleNeck Feature map에 SVD(Singular value decomposition) 적용하여 해상도 축소하여 각 객체 class에 대한 객체 특징 벡터 생성 ⑦ 특징 추출 모듈이, 각 객체 class(예를 들어, House, Tree, Person)에 대응되는 객체 특징 벡터를 Concatenate하여 피검사자 그림 특징 벡터를 출력 본 발명의 일실시예에 따른 객체 특징 벡터 생성 모듈의 Quick Draw Dataset 인공신경망 모듈 및 특징 추출 모 듈에 따르면, 연산 효율이 증대되고 파라미터가 감소되는 동시에 피검사자 그림 이미지 정보와 같은 Quick Draw Dataset에 존재하는 노이즈 성분의 학습 세션에서의 영향을 최소화하는 효과가 발생된다. 또한, 특징 추출 모듈 에 의해 추상화 레벨의 특징 정보와 디테일 레벨의 특징 정보를 모두 포함할 수 있게 되는 효과가 발생된다. 본 발명의 변형예에 따르면, 객체 특징 벡터 생성 모듈은 Quick Draw Dataset 인공신경망 모듈의 입력층에 연결 된 객체 분절 모듈을 더 포함할 수 있고, 객체 인식 모듈에서 추출한 각 객체 class(House, Tree, Person)의 객 체 이미지 정보가 객체 분절 모듈에 의해 생성된 분절 좌표 정보로 분절되어 생성된 객체 분절 이미지 정보가 Quick Draw Dataset 인공신경망 모듈에 입력 데이터로 입력되고, 특징 추출 모듈에 의해 각 객체 분절 이미지 정보에 대하여 출력되는 객체 분절 벡터를 조합(concatenate)하여 각 객체 class(예를 들어, House, Tree,Person)에 대응되는 객체 특징 벡터를 생성하고, 각 객체 특징 벡터를 조합(concatenate)하여 피검사자 그림 특 징 벡터를 생성하도록 구성될 수 있다. 객체 분절 모듈과 관련하여, 도 8은 반 발명의 일실시예에 따른 객체 분절 모듈을 도시한 모식도이다. 도 8에 도시된 바와 같이, 객체 분절 모듈은, 상기 객체 박스 정보에 대응되는 피검사자 그림 이미지의 일부분인 객체 이미지 정보를 입력 데이터로 하고 상기 객체 이미지 정보에 대한 Feature map(activation map, 액티베이션 정 보)을 출력 데이터로 하는 피검사자 그림 이미지 정보의 각 객체에 관한 그림 데이터에 최적화된 Feature를 추 출하기 위해 Quick Draw Dataset으로 Pre-trained 되고, 복수의 BottleNeck을 포함하며 Fully connected layer(FC layer) 대신 Fully convolutional layer(FCN layer)가 포함된 CNN 기반의 인공신경망 모듈인 FCN 인 공신경망 모듈 및 상기 액티베이션 정보를 기반으로 객체 이미지 정보의 길이 방향으로 객체 이미지 정보를 n개 (특정 분절 개수)의 이미지로 분절(분절 좌표 정보)하여 구성된 n개의 객체 분절 이미지 정보를 생성하는 분절 이미지 생성 모듈을 포함하는 모듈이다. 분절 이미지 생성 모듈에 의해 생성된 각 객체 class(House, Tree, Person)에 대한 복수의 객체 분절 이미지 정보가 Quick Draw Dataset 인공신경망 모듈에 입력 데이터로 입력되 고, 특징 추출 모듈에 의해 각 객체 분절 이미지 정보에 대하여 출력되는 객체 분절 벡터를 조합(concatenate) 하여 각 객체 class(예를 들어, House, Tree, Person)에 대응되는 객체 특징 벡터를 생성하고, 각 객체 특징 벡 터를 조합(concatenate)하여 피검사자 그림 특징 벡터를 생성하도록 구성될 수 있다. 분절 이미지 생성 모듈과 관련하여, 도 9는 본 발명의 일실시예에 따른 분절 이미지 생성 모듈의 작동관계를 도 시한 모식도이다. 도 9에 도시된 바와 같이, 분절 이미지 생성 모듈은 FCN 인공신경망 모듈에 구성된 복수의 Conv. Layer의 BottleNeck과 연결되고, FCN 인공신경망 모듈의 입력 데이터가 특정 크기의 객체 이미지 정보일 때 Conv. Layer의 BottleNeck에서 출력되는 적어도 한 차원 이상의 Activation map을 포함하는 복수개의 액티 베이션 정보(좌표 별 액티베이션 값을 포함)를 입력받고, 객체 이미지 정보에 대한 객체 class의 coordinate data(객체 좌표 정보)를 입력받으며, 복수개의 액티베이션 정보의 크기를 객체 좌표 정보에 대응되게 조정하고 통합하여 통합 액티베이션 정보를 생성하며, 객체 박스의 길이방향으로 액티베이션 값의 peak와 peak 사이를 분 절하여 n개의 분절 좌표 정보를 생성하고, 분절 좌표 정보 기반으로 객체 이미지 정보를 분절하여 객체 분절 이 미지 정보를 생성하는 모듈이다. 이때, FCN Layer가 포함된 CNN 모듈인 FCN 인공신경망 모듈은, FCN layer에 Global Average Pooling(GAP)이 적용되어 해당 객체 이미지 정보의 객체 class probability를 출력하는 output layer가 구성된 상태에서 기학습되도록 구성된다. 또한, 본 발명의 일실시예에 따른 분절 이미지 생성 모듈은, FCN Layer가 포함된 CNN 모듈인 FCN 인공신경망 모듈에서 출력되는 객체 class probability에 따라 입력 데이터 인 객체 이미지 정보의 크기(w,h)를 특정 가중치만큼 확장하여 입력 데이터로 다시 feed 하도록 구성될 수 있다. 이때, 예를 들어 특정 가중치는 1/[객체 class probabilty] 또는 1+(1-[객체 class probabilty])의 형태 로 구성될 수 있다. 예를 들어, FCN Layer가 포함된 CNN 모듈인 FCN 인공신경망 모듈에 입력된 객체 이미지 정 보에 의해 출력된 객체 class probability가 0.7인 경우, 1.3의 가중치만큼 객체 이미지 정보를 확장하여 입력 데이터로 입력하도록 구성될 수 있다. 본 발명의 일실시예에 따른 객체 분절 모듈에 따르면, 객체 이미지 정보 내에 포함된 객체의 구성요소(Tree의 경우, 나뭇잎 부분, 나무 줄기 부분, 나무 뿌리 부분 등) 하나 하나를 별도의 분절 좌표 정보 및 객체 분절 이 미지 정보로 분절하여 객체 특징 벡터를 정밀하게 추론(inference)할 수 있게 되는 효과가 발생된다. 또한, 객 체 특징 벡터 생성 모듈을 단일 인공신경망 모듈로 구성할 수 있게 됨으로써 인공신경망 학습 및 추론의 효율이 향상되는 효과가 발생된다. 또한, FCN layer 및 GAP이 구성됨으로써, 입력 데이터인 객체 이미지 정보의 크기가 다양하게 구성되어도 객체 특징 벡터의 생성이 가능한 효과가 발생된다. 또한, 객체 인식 모듈과 객체 분절 모 듈에서 각각 객체 class probability를 추론하게 되므로, 객체 인식 모듈에서 기추론된 객체 class probability를 기초로 객체 분절 모듈의 FCN Layer가 포함된 CNN 모듈인 FCN 인공신경망 모듈을 기학습시킬 수 있는 효과가 발생된다. 분절 이미지 생성 모듈의 제2변형예와 관련하여, 도 10은 본 발명의 제2변형예에 따른 분절 이미지 생성 모듈의 작동관계를 도시한 모식도이다. 도 10에 도시된 바와 같이, 본 발명의 제2변형예에 따르면, 객체 분절 모듈의 FCN 인공신경망 모듈이 Global average pooling을 통해 객체 class probability를 출력 데이터로 출력하는 단 일 컨볼루젼 네트워크로 구성된 인공신경망으로 구성되고, 분절 이미지 생성 모듈과 FCN 인공신경망 모듈의 사 이에 차원을 축소하는 클래스 액티베이션 생성 모듈을 더 포함하며, 클래스 액티베이션 생성 모듈은 FCN 인공신 경망 모듈의 복수의 Conv. Layer와 연결되어 FCN Layer가 포함된 CNN 모듈인 FCN 인공신경망 모듈의 입력 데이 터가 객체 이미지 정보일 때 Conv. Layer의 BottleNeck에서 출력되는 적어도 한 차원 이상의 Activation map을포함하는 액티베이션 정보(좌표 별 액티베이션 값을 포함)를 입력받고 객체 class에 대응되는 Activation map을 포함하는 클래스 액티베이션 정보(객체 class에 따른 좌표 별 액티베이션 값을 포함)를 출력하며, Global average pooling 함수를 통해 객체 class probability를 출력하도록 구성된 FCN 인공신경망 모듈과 함께 학습 될 수 있다. 또한, 분절 이미지 생성 모듈에는 상기 클래스 액티베이션 정보와 객체 좌표 정보가 입력되며, 분 절 이미지 생성 모듈은 입력되는 클래스 액티베이션 정보의 크기를 객체 좌표 정보의 크기에 대응되게 조정하고 통합하여 통합 액티베이션 정보를 생성하며, 객체 박스의 길이방향으로 액티베이션 값의 peak와 peak 사이를 분 절하여 n개의 분절 좌표 정보를 생성하고, 분절 좌표 정보 기반으로 객체 이미지 정보를 분절하여 객체 분절 이 미지 정보를 생성하도록 구성될 수 있다. 이때, 클래스 액티베이션 생성 모듈에 의한 클래스 액티베이션 정보의 생성은 아래와 같이 수행될 수 있다. 수학식 1"}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 수학식 1에서, Mc(x,y)는 class c로의 분류에 영향을 주는 (x,y)에 위치한 액티베이션 값, wkc는 activation map에서 class c에 대한 k번째 채널의 가중치, fk(x,y)는 Activation map의 k번째 채널의 (x,y)에 위치한 액티 베이션 값을 의미한다. 본 발명의 변형예에 따르면, 전체 클래스에 대한 Activation map이 아닌, 객체 class에 한정되어 생성되는 Class activaiton map을 이용하여 객체 class에 한정된 통합 액티베이션 정보를 분절 좌표 생성에 이용할 수 있 게 되므로, 객체 이미지 정보 내에 포함된 객체의 구성요소 하나 하나를 별도의 분절 좌표 정보로 보다 정밀하 게 추론(inference)할 수 있게 되는 효과가 발생된다. 또한, FCN 인공신경망 모듈부터 클래스 액티베이션 생성 모듈까지 단일 인공신경망 모듈로 구성할 수 있게 됨으로써 인공신경망 학습 및 추론의 효율이 향상되는 효과가 발생된다. 또한, FCN layer 및 GAP이 구성됨으로써, 입력 데이터인 객체 이미지 정보의 크기가 다양하게 구성되 어도 객체 특징 벡터의 생성이 가능한 효과가 발생된다. 또한, 객체 인식 모듈과 객체 분절 모듈에서 각각 객체 class probability를 추론하게 되므로, 객체 인식 모듈에서 기추론된 객체 class probability를 기초로 객체 분절 모듈의 FCN 인공신경망 모듈을 기학습시킬 수 있는 효과가 발생된다. 그림 스타일 벡터 생성 모듈과 관련하여, 도 11은 본 발명의 일실시예에 따른 그림 스타일 벡터 생성 모듈을 도 시한 모식도이다. 도 11에 도시된 바와 같이, 본 발명의 일실시예에 따른 그림 스타일 벡터 생성 모듈은, 피검 사자 그림 이미지 정보를 입력 데이터로 하고 그림 스타일 벡터를 출력 데이터로 하는 인공신경망 모듈을 의미 할 수 있다. 그림 스타일 벡터 생성 모듈에서 생성된 그림 스타일 벡터는, 상기 피검사자 그림 특징 벡터와 조 합(concatenate)되어 감정 분류 모듈의 입력 데이터로 입력되도록 구성될 수 있다. 그림 스타일 벡터 생성 모듈의 구체적인 구성과 관련하여, 본 발명의 일실시예에 따른 그림 스타일 벡터 생성 모듈은 상기 피검사자 그림 이미지 정보를 입력 데이터로 하여 피검사자 그림 이미지 정보의 Style Feature를 추출하기 위해 Quick Draw Dataset으로 Pre-trained 되고, 복수의 BottleNeck을 포함하는 CNN 기반의 인공신경 망 모듈인 Quick Draw Dataset 인공신경망 모듈(예를 들어, ResNet을 backbone network로 할 수 있음)을 포함 할 수 있고, 상기 Quick Draw Dataset 인공신경망 모듈의 복수의 BottleNeck에서 Style Feature Map를 추출하 는 스타일 특징 추출 모듈(Style Feature Extraction Module)을 더 포함할 수 있다. 이때, Quick Draw Dataset 인공신경망 모듈의 BottleNeck은, CNN에서 차원이 축소되기 전의 Layer를 의미할 수 있으며, BottleNeck Feature map은 CNN에서 차원이 축소되기 전의 Convolution Layer의 출력 feature map을 의미할 수 있다. 그림 스타일 벡터 생성 모듈과 스타일 특징 추출 모듈은 아래의 단계로 그림 스타일 벡터 및 그림 스타일 벡터 와 피검사자 그림 특징 벡터의 조합 벡터를 출력하도록 구성될 수 있다. ① 피검사자 그림 이미지 정보가 그림 스타일 벡터 생성 모듈의 Quick Draw Dataset 인공신경망 모듈의 입력 데 이터로 입력 *② 스타일 특징 추출 모듈이, 그림 스타일 벡터 생성 모듈의 Quick Draw Dataset 인공신경망 모듈에 구성된 복 수의 BottleNeck에서 서로 다른 scale을 가진 Feature map(BottleNeck Feature map)을 추출(a1, a2, a3 vector, Bottom-up pathway) ③ 스타일 특징 추출 모듈이, 추출된 복수의 BottleNeck Feature map 각각에 gram matrix 연산을 적용하여 모 든 BottleNeck Feature map를 내적하여 각 layer에 대한 Style representation을 생성 ④ 스타일 특징 추출 모듈이, gram matrix 연산된 복수의 BottleNeck Feature map에 Lateral connections을 적 용하여 각 layer의 Style representation을 바로 아래 pyramid level에 존재하는 Style representation과 element-wise addition 연산하여 Top-down pathway로 통합(c1, c2, c3 vector) ⑤ 스타일 특징 추출 모듈이, 통합 된 Style representation 중 최상단 level의 벡터인 그림 스타일 벡터를 추 출 ⑥ 스타일 특징 추출 모듈이, 추출 된 그림 스타일 벡터와 피검사자 그림 특징 벡터를 조합(Concatenate)하여 조합 벡터를 출력 본 발명의 일실시예에 따른 그림 스타일 벡터 생성 모듈의 Quick Draw Dataset 인공신경망 모듈 및 스타일 특징 추출 모듈에 따르면, high resolution style feature가 low resolution style feature의 특징을 포함할 수 있 게 되고, 피검사자 그림 이미지의 스타일을 추출하고 Self-Attention Layer를 통과시켜 객체(예를 들어, 집, 나 무, 사람) 그림의 style 사이의 관계를 파악하여 감정 분류 모듈에서 감정 분류를 수행할 수 있게 되는 효과가 발생된다. 감정 분류 모듈과 관련하여, 도 12는 본 발명의 일실시예에 따른 감정 분류 모듈을 도시한 모식도이다. 도 12에 도시된 바와 같이, 본 발명의 일실시예에 따른 감정 분류 모듈은, 그림 스타일 벡터와 피검사자 그림 특징 벡터 를 조합(Concatenate)한 조합 벡터를 입력 데이터로 하고 피검사자의 감정 분류 class(예를 들어, Angry, Nervous, Annoying, Excited, Happy 등) 및 confidence를 포함하는 감정 분류 정보를 출력 데이터로 하는 인 공신경망 모듈로 구성될 수 있다. 감정 분류 모듈의 구체적인 구성과 관련하여, 본 발명의 일실시예에 따른 감정 분류 모듈은 Multi-head Self Attention Layer - FFNN - softmax를 포함하도록 구성될 수 있다. 감정 분류 모듈의 Multi-head Self Attention Layer는 그림 스타일 벡터와 피검사자 그림 특징 벡터를 조합(Concatenate)한 조합 벡터를 입력 데이 터로 입력받고 위치 정보를 조합하는 Positional encoding을 수행하며, Positional encoding된 matrix에 병렬 적으로 복수개의 Self Attention 연산(예를 들어, scaled dot product attention)을 수행하여 생성된 attention value matrix를 concatenate 하여 어텐션 정보를 생성하는 layer를 의미한다. 감정 분류 모듈의 FFNN(Feed Forward Neural Network)은 Position-wise FFNN을 의미할 수 있으며, Fully-connected FFNN을 의미 할 수 있다. 감정 분류 모듈의 FFNN의 입력 데이터는 그림 스타일 벡터와 피검사자 그림 특징 벡터를 조합 (Concatenate)한 조합 벡터와 상기 어텐션 정보가 잔차연결(Residual Connection)된 matrix를 층 정규화(layer normalization) 한 값으로 구성될 수 있다. 감정 분류 모듈의 softmax는 FFNN의 출력 matrix가 잔차연결 (Residual Connection)된 matrix를 층 정규화(layer normalization) 한 값을 입력 데이터로 하고 감정 분류 정 보를 출력 데이터로 하는 활성화 layer를 의미할 수 있다. 이에 따르면, positional encoding에 의해 피검사자 그림 이미지 정보의 각 객체 위치에 대한 특징도 감정 분류에 영향을 주게 되고, Multi-head self attention layer에 의해 병렬로 복수의 어텐션 연산이 수행되게 되므로 다양한 값의 어텐션이 활용되어 보다 정교한 감정 분류가 가능해지는 효과가 발생된다. 이때, 피검사자 클라이언트의 객체 인식 모듈에 의해 생성된 객체 박스 정보(객체 class 정보, 객체 class 신뢰도, 객체 좌표 정보 및 객체 디테일 정보 포함) 및 감정 분류 모듈에 의해 생성된 감정 분류 정보는 피검사 자 클라이언트의 통신모듈을 통해 검사자 클라이언트로 송신될 수 있고, 검사자 클라이언트의 일구성인 수정 정보 생성 모듈에서는 수신된 객체 박스 정보와 감정 분류 정보에 수정 사항이 있는 경우 검사자 의 수정이 반영된 수정 정보를 생성할 수 있다.클라이언트 학습 모듈은, 피검사자 클라이언트가 출력된 피검사자의 감정 분류 정보에 대한 검사자의 수정 이 반영된 수정 정보를 검사자 클라이언트를 통해 수신하는 경우, 수정 정보를 ground truth로 하여 피검 사자 클라이언트의 객체 인식 모듈과 감정 분류 모듈에 포함된 인공신경망의 파라미터를 업데이트 하도록 객체 인식 모듈과 감정 분류 모듈의 학습 세션을 수행할 수 있다. 클라이언트 학습 모듈의 객체 인식 모듈의 일구성인 객체 박스 생성 인공신경망 모듈의 학습 세션과 관련하여, 도 13은 본 발명의 일실시예에 따른 객체 박스 생성 인공신경망 모듈의 학습 세션을 도시한 모식도이다. 도 13 에 도시된 바와 같이, 클라이언트 학습 모듈의 객체 박스 생성 인공신경망 모듈의 학습 세션은 상기 수정 정보 생성 모듈에서 수신된 수정 정보에 객체 박스 정보에 대한 수정이 포함된 경우 수행되도록 구성될 수 있고, 객 체 박스 생성 인공신경망 모듈에 피검사자 그림 이미지 정보를 입력 데이터로 입력하고 피검사자 그림 이미지 정보에 포함된 객체를 둘러싸는 bounding box인 객체 박스의 좌표, 높이, 너비, 각도를 포함하는 객체 박스 정 보를 출력 데이터로 하며, 출력된 객체 박스 정보와 수정 정보의 수정된 객체 박스 정보(ground truth)의 손실 (loss)이 작아지는 방향으로(또는, 유사도가 높아지는 방향으로) 객체 박스 생성 인공신경망 모듈의 파라미터가 업데이트 되도록 구성될 수 있다. 클라이언트 학습 모듈의 감정 분류 모듈의 학습 세션과 관련하여, 도 14는 본 발명의 일실시예에 따른 감정 분 류 모듈의 학습 세션을 도시한 모식도이다. 도 14에 도시된 바와 같이, 클라이언트 학습 모듈의 감정 분류 모듈 의 학습 세션은 상기 수정 정보 생성 모듈에서 수신된 수정 정보에 감정 분류 class에 대한 수정이 포함된 경우 수행되도록 구성될 수 있고, 감정 분류 모듈에 그림 스타일 벡터와 피검사자 그림 특징 벡터를 조합 (Concatenate)한 조합 벡터를 입력 데이터로 하고, 감정 분류 class 및 confidence를 출력 데이터로 하며, 출력 된 감정 분류 class와 수정 정보의 수정된 감정 분류 class(ground truth)의 손실(loss)이 작아지는 방향으로 ((또는, 유사도가 높아지는 방향으로) 감정 분류 모듈의 파라미터가 업데이트 되도록 구성될 수 있다. 파라미터 업로드 모듈은, 클라이언트 학습 모듈에 의한 객체 인식 모듈 및 감정 분류 모듈의 학습 세션 이후, 객체 인식 모듈 및 감정 분류 모듈의 변경된 파라미터를 메인 신경망 서버의 연합 학습 모듈에 업로 드하는 모듈이다. 파라미터는, 객체 인식 모듈 및 감정 분류 모듈의 학습 세션 이후 그래디언트(g) 또는 인공신 경망의 웨이트(w)를 포함할 수 있다. 파라미터 업로드 모듈의 객체 박스 생성 인공신경망 모듈에 대한 파라미터 업로드는 상기 수정 정보 생성 모듈에서 수신된 수정 정보에 객체 박스 정보에 대한 수정이 포함된 경우에 수행 되도록 구성되고, 파라미터 업로드 모듈의 감정 분류 모듈에 대한 파라미터 업로드는 상기 수정 정보 생성 모듈 에서 수신된 수정 정보에 감정 분류 class에 대한 수정이 포함된 경우에 수행되도록 구성된다. 또한, 파라미터 업로드 모듈은, 객체 인식 모듈 및 감정 분류 모듈의 변경된 파라미터에 노이즈(ε)를 적용하여 메인 신경망 서버에 업로드하도록 구성될 수 있다. 예를 들어, 파라미터가 그래디언트(g)인 경우, g+ε로 업로드 되도록 구성될 수 있고, 파라미터가 웨이트(w)인 경우 w+ε로 업로드 되도록 구성될 수 있다. 이때, 노 이즈(ε)는 양의 값과 음의 값이 랜덤하게 부여되어 연합 학습 모듈에서의 연합 학습 시 노이즈의 영향이 최소한으로 적용되도록 구성될 수 있다. 이에 따르면, 피검사자 클라이언트에서 파라미터에 노이즈가 적용 되어 메인 신경망 서버에 업로드 되므로, 제3자가 파라미터를 취득하더라도 피검사자 그림 이미지 정보의 취득 이 불가능한 효과가 발생된다. 메인 신경망 다운로드 모듈은, 메인 신경망 서버의 연합 학습 모듈에 의해 기학습된 객체 인식 메인 신경망, 감정 분류 메인 신경망을 다운로드하여 객체 인식 모듈, 감정 분류 모듈의 적어도 일부 네트워크를 치 환(교체, 전이)하는 모듈이다. 객체 인식 모듈의 네트워크 다운로드는, 메인 신경망 서버의 메인 신경망 모듈에서 기학습된 객체 인 식 메인 신경망을 다운로드 받고, 객체 인식 모듈의 후방 레이어(최후 n개의 layer)를 제외한 나머지를 다운로 드 받은 객체 인식 메인 신경망으로 치환(교체, 전이)하도록 구성된다. 이에 따르면, 각 피검사자 클라이언트 의 객체 인식 모듈의 신경망을 메인 신경망으로 완전히 교체하지 않으므로, 객체 인식 모듈을 계속적으로 업데이트 하면서도 피검사자의 그림 스타일에 따른 객체 박스의 개인화가 가능해지는 효과가 발생된다. 감정 분류 메인 신경망의 네트워크 다운로드는, 메인 신경망 서버의 메인 신경망 모듈에서 기학습된 감정 분류 메인 신경망을 다운로드 받고, 감정 분류 모듈을 다운로드 받은 감정 분류 메인 신경망으로 치환(교 체, 전이)하도록 구성된다. 메인 신경망 서버는, 메인 신경망 모듈과 연합 학습 모듈을 포함할 수 있고, 복수의 피검사자 클라이언트에서 업로드되는 객체 인식 모듈, 감정 분류 모듈의 파라미터를 취합하여 메인 신경망 모듈 을 업데이트한 뒤, 기학습된 메인 신경망을 피검사자 클라이언트에 다시 배포하도록 구성되는 서버이 다. 메인 신경망 모듈은, 객체 인식 메인 신경망, 감정 분류 메인 신경망을 포함할 수 있으며, 연합 학습 모듈 에 의해 특정 그래디언트(g) 또는 특정 웨이트(w)로 파라미터가 업데이트되도록 구성될 수 있다. 객체 인 식 메인 신경망은, 객체 인식 모듈에 대응되는 메인 신경망을 의미하고, 감정 분류 메인 신경망은 감정 분류 모 듈에 대응되는 메인 신경망을 의미한다. 연합 학습 모듈은, 복수의 피검사자 클라이언트에서 업로드되는 객체 인식 메인 신경망, 감정 분류 메인 신경망의 파라미터를 취합한 뒤, 취합 된 파라미터를 이용하여 메인 신경망 모듈을 업데이트 하도록 구성되는 모듈이다. 이때, 취합된 파라미터를 이용하여 메인 신경망 모듈을 업데이트하는 방법은 아래와 같이 수정 정보 생성 모듈에서 수신된 수정 정보와 수정 전 정보(객체 박스 정보, 감정 분류 class)의 차이인 수정 변화 정보가 파라미터의 가중치로 사용되고, 파라미터와 수정 변화 정보의 곱의 합산을 상기 수정 변화 정 보의 합으로 나눔으로써 파라미터가 수정 변화 정보를 기준으로 평균되도록 구성될 수 있다. 파라미터가 그래디언트(g)인 경우, 연합 학습 모듈에서는 아래의 수학식과 같이 메인 신경망 모듈의 파라미터를 업데이트 하도록 구성될 수 있다. 수학식 2"}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위 수학식 2에서, wnew는 메인 신경망 모듈의 업데이트 후 웨이트, wold는 메인 신경망 모듈의 업데이 트 이전 웨이트, α는 learning rate, sn은 피검사자 클라이언트 n에서 업로드 된 수정 변화 정보, gn은 피검사자 클라이언트 n에서 업로드 된 그래디언트를 의미하도록 구성될 수 있다. 파라미터가 웨이트(w)인 경우, 연합 학습 모듈에서는 아래의 수학식과 같이 메인 신경망 모듈의 파라 미터를 업데이트 하도록 구성될 수 있다. 수학식 3"}
{"patent_id": "10-2025-0010867", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "위 수학식 3에서, wnew는 메인 신경망 모듈의 업데이트 후 웨이트, sn은 피검사자 클라이언트 n에서 업로드 된 수정 변화 정보, wn은 피검사자 클라이언트 n에서 업로드 된 웨이트를 의미하도록 구성될 수 있 다. 이에 따르면, 메인 신경망 모듈에서의 연합 학습 시 수정 변화 정보가 파라미터의 가중치로 사용됨으로써 미니 배치(mini batch)의 효과가 발생된다. 또한, 메인 신경망 모듈에서의 연합 학습 시 수정 변화 정보가 파라미터의 가중치로 사용됨으로써 네트워크 토폴로지 및 비동기 통신 문제가 저감되는 효과가 발생된다. 또한,수정 정보와 수정 전 정보의 차이가 큰 경우가 메인 신경망 모듈의 업데이트에 보다 큰 영향력을 갖게 되는 효 과가 발생된다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2025-0010867", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치의 작동관계를 도 시한 모식도, 도 2는 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치와 메인 신경망 서 버의 각 단계에 따른 작동관계를 도시한 모식도, 도 3은 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치의 구성관계를 도 시한 모식도, 도 4는 본 발명의 일실시예에 따른 인공지능 기반의 객체 분절을 활용한 객체 특징 추출 장치의 구체적인 작동 관계를 도시한 모식도, 도 5는 본 발명의 일실시예에 따른 객체 인식 모듈을 도시한 모식도,도 6은 본 발명의 일실시예에 따른 객체 인식 모듈이 YOLO v5으로 구성되는 경우의 구조를 도시한 모식도, 도 7은 본 발명의 일실시예에 따른 객체 특징 벡터 생성 모듈을 도시한 모식도, 도 8은 반 발명의 일실시예에 따른 객체 분절 모듈을 도시한 모식도, 도 9는 본 발명의 일실시예에 따른 분절 이미지 생성 모듈의 작동관계를 도시한 모식도, 도 10은 본 발명의 제2변형예에 따른 분절 이미지 생성 모듈의 작동관계를 도시한 모식도, 도 11은 본 발명의 일실시예에 따른 그림 스타일 벡터 생성 모듈을 도시한 모식도, 도 12는 본 발명의 일실시예에 따른 감정 분류 모듈을 도시한 모식도, 도 13은 본 발명의 일실시예에 따른 객체 박스 생성 인공신경망 모듈의 학습 세션을 도시한 모식도, 도 14는 본 발명의 일실시예에 따른 감정 분류 모듈의 학습 세션을 도시한 모식도이다."}
