{"patent_id": "10-2022-0178220", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0111318", "출원번호": "10-2022-0178220", "발명의 명칭": "인공지능 에이전트의 장면 이해 구성 및 병합 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "이용주"}}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 에이전트의 장면 구성 및 병합 방법에 있어서,제1 공간의 이미지를 획득하는 단계;상기 이미지 내 객체들을 인식하는 단계;상기 객체들 간의 관계 정보 및 상기 객체들 각각의 상태 정보를 그래프 형태로 구조화하는 단계; 및상기 구조화된 정보를 주변 인공지능 에이전트로부터 수신한 정보와 병합하는 단계를 포함하는 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 객체들은 특정 공간의 이미지를 입력으로 기학습된 제1 인공지능 신경망에 기반하여 인식되고,상기 객체들 각각의 상태 정보는객체들을 상태별로 레이블링한 학습데이터에 기반하여 학습된 제2 인공지능 신경망에 상기 객체들을 입력하여획득되는 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 병합하는 단계는상기 제1 공간에 상응하는 정보를 상기 주변 인공지능 에이전트의 제2 공간에 상응하는 정보와 병합하는 것을특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 병합된 정보는상기 제1 공간과 상기 제2 공간의 위치 관계가 링크 형태로 연결된 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 병합하는 단계는상기 주변 인공지능 에이전트의 메타데이터에 기반하여 병합 여부를 결정하고, 상기 메타데이터는 상기 객체들각각의 상태 정보에 상응하는 타임스탬프 정보를 포함하는 것을 특징으로 하는 인공지능 에이전트의 장면 구성및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,공개특허 10-2024-0111318-3-상기 병합하는 단계는상기 타임스탬프 정보를 이용하여, 상기 객체들 각각의 상태 정보가 현재 시간으로부터 기설정된 시간 이내에업데이트된 정보를 병합하는 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 병합하는 단계는시간 변화에 따라 상태가 변화한 객체에 관한 정보를 상기 주변 인공지능 에이전트와 교환하는 것을 특징으로하는 인공지능 에이전트의 장면 구성 및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 병합하는 단계는상기 객체들 각각의 상태 정보에 기반하여 생성된 문장 단위의 정보를 상기 주변 인공지능 에이전트와 교환하는것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 방법."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 프로그램이 기록된 메모리; 및상기 프로그램을 실행하는 프로세서를 포함하며,상기 프로그램은 제1 공간의 이미지를 획득하는 단계;상기 이미지 내 객체들을 인식하는 단계;상기 객체들 간의 관계 정보 및 상기 객체들 각각의 상태 정보를 그래프 형태로 구조화하는 단계; 및상기 구조화된 정보를 주변 인공지능 에이전트로부터 수신한 정보와 병합하는 단계의 수행을 위한 명령어들을 포함하는 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 객체들은 특정 공간의 이미지를 입력으로 기학습된 제1 인공지능 신경망에 기반하여 인식되고,상기 객체들 각각의 상태 정보는객체들을 상태별로 레이블링한 학습데이터에 기반하여 학습된 제2 인공지능 신경망에 상기 객체들을 입력하여획득되는 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 9에 있어서,상기 병합하는 단계는상기 제1 공간에 상응하는 정보를 상기 주변 인공지능 에이전트의 제2 공간에 상응하는 정보와 병합하는 것을특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2024-0111318-4-청구항 11에 있어서,상기 병합된 정보는상기 제1 공간과 상기 제2 공간의 위치 관계가 링크 형태로 연결된 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서,상기 병합하는 단계는상기 주변 인공지능 에이전트의 메타데이터에 기반하여 병합 여부를 결정하고, 상기 메타데이터는 상기 객체들각각의 상태 정보에 상응하는 타임스탬프 정보를 포함하는 것을 특징으로 하는 인공지능 에이전트의 장면 구성및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서,상기 병합하는 단계는상기 타임스탬프 정보를 이용하여, 상기 객체들 각각의 상태 정보가 현재 시간으로부터 기설정된 시간 이내에업데이트된 정보를 병합하는 것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 9에 있어서,상기 병합하는 단계는시간 변화에 따라 상태가 변화한 객체에 관한 정보를 상기 주변 인공지능 에이전트와 교환하는 것을 특징으로하는 인공지능 에이전트의 장면 구성 및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 9에 있어서,상기 병합하는 단계는상기 객체들 각각의 상태 정보에 기반하여 생성된 문장 단위의 정보를 상기 주변 인공지능 에이전트와 교환하는것을 특징으로 하는 인공지능 에이전트의 장면 구성 및 병합 장치."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 방법은 제1 공간의 이미지를 획득하는 단계, 상기 이미지 내 객체들을 인식하는 단계, 상기 객체들 간의 관계 정보 및 상기 객체들 각각의 상태 정보를 그래프 형태로 구조화하는 단계 및 상기 구조화된 정보를 주변 인공지능 에이전트로부터 수신한 정보와 병합하는 단계를 포함한다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기술이 적용된 다양한 에이전트들의 장면 이해 기술에 관한 것이다. 구체적으로, 본 발명은 인공지능 에이전트가 획득한 시각 정보를 이용하여 장면 이해를 구성하고 이를 주변 에 이전트와 교환 및 병합하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 발명은 인공지능이 탑재된 다양한 로봇 등에서 시각적 정보를 이해하고 표현(구성)하는 문제점을 개선하고자 한다. 종래 기술은 어떠한 장면에서 사물의 탐지하고 사물의 관계에 따라 장면 그래프를 구성하는데 국한된 방 식이다. 한 예로 방(room)안에 테이블(table)이 있고 그 위에 컵(cup)이 있으면 방(room)-테이블(table)-컵 (cup)을 연결하고 방(room)과 테이블(table)과 컵(cup)은 방에 속해(in)있고, 테이블에 컵은 올려져(on) 있다는 표현 방식을 사용한다. 하지만 종래 기술은 복수의 에이전트 간 생성한 장면 이해 정보를 효율적으로 교환 및 병합하지 못하는 단점이 존재하며, 이를 해결할 수 있는 기술에 대한 필요성이 절실히 대두된다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허공보 제10-2022-014672호(발명의 명칭: 주행 계획 장치 및 방법, 이를 적용한 이 동 로봇)"}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 인공지능 에이전트가 획득한 장면 정보에 기반하여 객체 간의 관계를 포함하는 장면 이해 정 보를 생성하는 것이다. 또한, 본 발명의 목적은 복수의 인공지능 에이전트가 각각 생성한 장면 이해 정보를 효율적으로 교환 및 병합하 는 것이다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 방법은 제1 공간의 이미지를 획득하는 단계, 상기 이미지 내 객체들을 인식하는 단계, 상기 객체들 간의 관계 정보 및 상기 객체들 각각의 상태 정보를 그래프 형태로 구조화하는 단계 및 상기 구조화된 정보를 주변 인공지능 에이 전트로부터 수신한 정보와 병합하는 단계를 포함한다. 이때, 상기 객체들은 상기 특정 공간의 이미지를 입력으로 기학습된 제1 인공지능 신경망에 기반하여 인식되고, 상기 객체들 각각의 상태 정보는 객체들을 상태별로 레이블링한 학습데이터에 기반하여 학습된 제2 인공지능 신 경망에 상기 객체들을 입력하여 획득될 수 있다. 이때, 상기 병합하는 단계는 상기 제1 공간에 상응하는 정보를 상기 주변 인공지능 에이전트의 제2 공간에 상응 하는 정보와 병합할 수 있다. 이때, 상기 병합된 정보는 상기 제1 공간과 상기 제2 공간의 위치 관계가 링크 형태로 연결될 수 있다. 이때, 상기 병합하는 단계는 상기 주변 인공지능 에이전트의 메타데이터에 기반하여 병합 여부를 결정하고, 상 기 메타데이터는 상기 객체들 각각의 상태 정보에 상응하는 타임스탬프 정보를 포함할 수 있다. 이때, 상기 병합하는 단계는 상기 타임스탬프 정보를 이용하여, 상기 객체들 각각의 상태 정보가 현재 시간으로 부터 기설정된 시간 이내에 업데이트된 정보를 병합할 수 있다. 이때, 상기 병합하는 단계는 시간 변화에 따라 상태가 변화한 객체에 관한 정보를 상기 주변 인공지능 에이전트 와 교환할 수 있다. 이때, 상기 병합하는 단계는 상기 객체들 각각의 상태 정보에 기반하여 생성된 문장 단위의 정보를 상기 주변 인공지능 에이전트와 교환할 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 장치는 적어도 하나의 프로그램이 기록된 메모리 및 상기 프로그램을 실행하는 프로세서를 포함하며, 상기 프로 그램은 제1 공간의 이미지를 획득하는 단계, 상기 이미지 내 객체들을 인식하는 단계, 상기 객체들 간의 관계 정보 및 상기 객체들 각각의 상태 정보를 그래프 형태로 구조화하는 단계 및 상기 구조화된 정보를 주변 인공지 능 에이전트로부터 수신한 정보와 병합하는 단계의 수행을 위한 명령어들을 포함한다. 이때, 상기 객체들은 상기 특정 공간의 이미지를 입력으로 기학습된 제1 인공지능 신경망에 기반하여 인식되고, 상기 객체들 각각의 상태 정보는 객체들을 상태별로 레이블링한 학습데이터에 기반하여 학습된 제2 인공지능 신경망에 상기 객체들을 입력하여 획득될 수 있다. 이때, 상기 병합하는 단계는 상기 제1 공간에 상응하는 정보를 상기 주변 인공지능 에이전트의 제2 공간에 상응 하는 정보와 병합할 수 있다. 이때, 상기 병합된 정보는 상기 제1 공간과 상기 제2 공간의 위치 관계가 링크 형태로 연결될 수 있다. 이때, 상기 병합하는 단계는 상기 주변 인공지능 에이전트의 메타데이터에 기반하여 병합 여부를 결정하고, 상 기 메타데이터는 상기 객체들 각각의 상태 정보에 상응하는 타임스탬프 정보를 포함할 수 있다. 이때, 상기 병합하는 단계는 상기 타임스탬프 정보를 이용하여, 상기 객체들 각각의 상태 정보가 현재 시간으로 부터 기설정된 시간 이내에 업데이트된 정보를 병합할 수 있다. 이때, 상기 병합하는 단계는 시간 변화에 따라 상태가 변화한 객체에 관한 정보를 상기 주변 인공지능 에이전트 와 교환할 수 있다. 이때, 상기 병합하는 단계는 상기 객체들 각각의 상태 정보에 기반하여 생성된 문장 단위의 정보를 상기 주변 인공지능 에이전트와 교환할 수 있다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능 에이전트가 획득한 장면 정보에 기반하여 객체 간의 관계를 포함하는 장면 이해 정 보를 생성할 수 있다. 또한, 본 발명은 복수의 인공지능 에이전트가 각각 생성한 장면 이해 정보를 효율적으로 교환 및 병합할 수 있 다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다(comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다. 본 명세서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함 께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 종래 단일 에이전트의 장면 이해 기술의 문제점을 개념적으로 나타낸다. 도 1을 참조하면, 시각적 정보를 인식하고 이해하는데 각각의 사물을 인식하고 이를 그래프 형태로 구성하여, 사물의 상관관계를 이해하는데 활용되는 장면 그래프(Scene Graph)를 활용한다. 이때, 사물의 구체적인 상태 변 화(Scene Change)에 대한 구체적인 방법이 존재하지 않으므로, 가령 “문이 열려 있다”, “테이블 위의 컵의 물이 쏟아져 있다”와 같은 상황 변화를 표현할 수 없으며, 기존 장면에서 시간의 흐름에 따라 장면의 변화를 구체적으로 묘사하기가 어렵다. 하나의 에이전트 A이 특정 공간을 보고 있다고 가정하면, 특정 공간 은 계속된 시간의 흐름상에서 사물의 위치와 그 속성이 변화하게 된다. 한 예로 문이 열리거나(311, 321) 또는 테이블 위의 컵에 물이 쏟아진 경우(312, 322)와 같이 기존의 장면 그래프로는 표현하지 못하는 경우 가 발생하게 된다. 도 2는 종래 다중 에이전트의 장면 이해 기술의 문제점을 개념적으로 나타낸다. 도 2를 참조하면, 인공지능 에이전트 A와 인공지능 에이전트 B가 각각 획득한 서로 다른 공간(330, 340)의 장면 이해 정보(210,220)를 병합하기 어려운 구조를 가지고 있다. 결국, 하나의 로봇이 특정 공간의 사물을 인식하고, 또 다른 로봇이 다른 공간의 사물을 인식하여 사물 간의 관 계를 장면 그래프 형태로 묘사할 경우, 로봇들 간의 장면 그래프의 병합(Scene Integration)을 통해 반복적인 인식과 이해의 단계를 공유하는 것이 불가능하다. 이러한 종래 기술의 문제점을 해결하고자 본 발명에서는 사물의 변화와 병합을 원활하게 하기 위해 다중 에이전 트 관점에서의 장면 구성 및 이해를 위한 방법 및 시스템을 제시한다. 도 3은 본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 방법을 나타낸 흐름도이다. 본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 방법은 인공지능 에이전트에서 수행 될 수 있으며, 서버와 같은 별도의 장치에서 인공지능 에이전트에 명령을 전송하는 방식으로 수행될 수도 있다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 방법은 제1 공간의 이미지를 획득하는 단계(S110), 상기 이미지 내 객체들을 인식하는 단계(S120), 상기 객체들 간의 관계 정보 및 상기 객체들 각각의 상태 정보를 그래프 형태로 구조화하는 단계(S130) 및 상기 구조화된 정보를 주변 인공지능 에이전트로부터 수신한 정보와 병합하는 단계(S140)를 포함한다. 이때, 상기 객체들은 상기 특정 공간의 이미지를 입력으로 기학습된 제1 인공지능 신경망에 기반하여 인식되고, 상기 객체들 각각의 상태 정보는 객체들을 상태별로 레이블링한 학습데이터에 기반하여 학습된 제2 인공지능 신 경망에 상기 객체들을 입력하여 획득될 수 있다. 이때, 상기 병합하는 단계(S140)는 상기 제1 공간에 상응하는 정보를 상기 주변 인공지능 에이전트의 제2 공간 에 상응하는 정보와 병합할 수 있다. 이때, 상기 병합된 정보는 상기 제1 공간과 상기 제2 공간의 위치 관계가 링크 형태로 연결될 수 있다. 이때, 상기 병합하는 단계(S140)는 상기 주변 인공지능 에이전트의 메타데이터에 기반하여 병합 여부를 결정하 고, 상기 메타데이터는 상기 객체들 각각의 상태 정보에 상응하는 타임스탬프 정보를 포함할 수 있다. 이때, 상기 병합하는 단계(S140)는 상기 타임스탬프 정보를 이용하여, 상기 객체들 각각의 상태 정보가 현재 시 간으로부터 기설정된 시간 이내에 업데이트된 정보를 병합할 수 있다. 이때, 상기 병합하는 단계(S140)는 시간 변화에 따라 상태가 변화한 객체에 관한 정보를 상기 주변 인공지능 에 이전트와 교환할 수 있다. 이때, 상기 병합하는 단계(S140)는 상기 객체들 각각의 상태 정보에 기반하여 생성된 문장 단위의 정보를 상기 주변 인공지능 에이전트와 교환할 수 있다. 이하, 도 4 내지 도 7을 참조하여 본 발명의 일 실시예에 따른 장면 이해 구성 및 병합 방법을 보다 상세히 설 명한다. 도 4는 단일 에이전트의 시간 흐름에 따른 장면 이해 구성 예시이다. 도 4를 참조하면, 본 발명은 에이전트가 바라보는 시점에서 특정 공간을 구조화하는 방법에 대한 것으로, 특정 시점의 장면이 주어졌을 때, 각각의 사물에 대한 인식을 먼저 수행한다. 사물들의 관계를 그래프 형태로 구조화하는데, 가령 한 공간 내에 존재하는 사물들의 관계는 기존의 기술을 활용하여 구조화할 수 있다. 이때, 본 발명의 실시예에 따른 방법은 각 사물이 가지는 세부 의미를 새롭게 정의하고, 이를 각 사물의 구조 정보에 더하는 방식을 활용한다. 가령 도어(311, 321)의 경우 열렸다(Open), 닫혔다(Closed), 잠겼다(Locked), 부서졌 다(Broken)와 같은 의미 부여가 가능하다. 이런 의미 부여를 통해 이후 시점에서의 사물의 변화를 계속해 서 인식할 수 있다. 특정 시점 이후의 시점에서는 기존 시점에서의 도어는 닫혀 있는 상태(Closed)에서 열 려 있는 상태(Open)로 바뀐 것을 확인할 수 있다. 또한 테이블 위의 컵(312, 312)의 경우에도 기존의 컵에 물이 차 있는 상태(Full)에서 물이 쏟아진 상태(Spill)의 상태 변화도 가능하다. 이때, 전술한 바와 같이 각 사물에 상태 정보를 정의하는 과정은 별도의 인공지능 신경망을 통해 수행될 수 있 다. 즉, 장면 그래프 내 객체들을 분리한 서브 이미지를 입력으로 상기 서브 이미지에 상응하는 객체 상태 정보 를 출력하는 인공지능 신경망을 이용할 수 있다. 이때, 상기 상태 정보를 출력하는 인공지능 신경망은 상기 객체 및 상태 정보 별로 레이블링된 학습데이터를 이 용하여 학습된 인공지능 신경망에 상응할 수 있다. 즉, 전수한 바와 같이 닫힌 문, 열린 문, 잠긴 문, 부서진 문 등으로 라벨링된 이미지를 학습데이터로 이용한 인공지능 신경망을 이용할 수 있다. 정리하면, 본 발명의 일 실시예에 따른 방법은 에이전트의 카메라를 통해 수집된 이미지를 입력으로 장면 그래 프를 생성하고(객체 인식, 객체들 간의 관계), 인식된 객체들 각각의 상태 정보를 정의할 수 있다. 도 5는 단일 에이전트의 이동 또는 다중 에이전트 간 정보 교환에 따른 복합 장면의 결합 예시이다. 도 5를 참조하면, 하나의 에이전트 A는 상기 도 4와 같은 시간의 흐름에 따라 계속하여 장면 이해가 진행 되고 있다고 가정하면, 에이전트 A가 계속하여 공간을 이동하면서 보는 또 다른 장면(Scene)에 대한 이해 도 필요하게 된다. 이때 하나의 에이전트는 점진적으로 이동하면서 자신이 이미 이해한 장면에 새롭게 얻 은 장면을 결합하여 새로운 장면 이해를 구성하게 된다. 또한, 새로운 인공지능 에이전트 B가 특정 시점에 기존 인공지능 에이전트 A와 에이전트 간 교류를 통해 장면 이해(230, 240)와 또 다른 장면 이해를 서로 결합되게 된다. 이러한 방식으로 다중 에이전트 관점에서의 장면 구성 및 이해를 본 발명에서 제시하고자 한다. 이때, 상기 결합을 나타내기 위해 링크 형태로 공간 간의 위치 관계를 나타낼 수 있다. 이때, 에이전트 A와 에이전트 B가 장면 이해를 결합하는 과정은 모든 장면 이해 정보를 결합하는 것이 아니라, 기설정된 조건의 장면 이해를 결합할 수 있다. 예를 들어, 각각의 에이전트들은 장면 이해를 생성할 때, 장면 이해의 메타데이터로 타임스탬프 데이터를 포함 할 수 있다. 또한, 장면 이해 내 객체들 또는 객체 속성들을 업데이트하는 경우에 상기 타임스탬프 데이터를 업 데이트할 수 있다. 에이전트 들은 서로 장면 이해를 결합(데이터 교환)할 때, 상기 타임스탬프 정보를 활용할 수 있다. 예를 들어 에이전트 A의 ROOM 1에 관한 장면 이해 정보가 1시간 전에 생성되었고, ROOM 2에 관한 장면 이해 정보가 15분 전에 생성되었다면, 에이전트 B는 ROOM 2에 관한 장면 이해 정보만을 결합 또는 업데이트할 수 있다. 이와 같이 특정 조건을 만족하는 장면 이해 정보만을 결합 또는 업데이트 함으로써, 불필요한 데이터 교환을 줄 일 수 있고 결합 데이터가 비대해지는 것을 방지할 수 있다.도 6은 본 발명의 일 실시예에 따른 장면 이해 정보에 기반한 문장 정보 생성 방법을 개념적으로 나타낸 도면이 다. 도 6을 참조하면, 하나의 장면이 주어지고, 이 장면에 대한 특정 시점의 변화가 있을 때, 장면 검출부를 통해 장면을 검출하게 된다. 검출된 장면은 각각의 사물에 대한 레이블(예: door, cup)이며, 이러한 레이블을 통해 언어 사전학습모델에 입력으로 들어가게 된다. 언어 사전학습 모델에서는 입력된 레이블을 통해 레이 블에 붙을 수 있는 단어들을 선별하게 된다. 가령, 문(door)이 주어지면 문(door)이 열렸거나, 닫혔거나, 잠겼 거나, 부서진 경우들이 있으면 이를 활용하게 된다. 이러한 정보는 사전에 정의된 언어 지식 그래프을 사 용한다. 이후 언어사전학습 모델은 가능한 문장들을 선별하게 된다. 또한 장면 비교부에서는 이 결과를 통해 장 면 인코더를 통해 변화된 장면을 찾아내게 된다. 장면 인코더의 변화된 장면들과 이전에 찾은 언어사"}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전학습 모델의 잠재적인 단어 후보들을 통해 언어시각모델은 결과적으로 장면의 변화에 따른 적절한 요약 문장을 생성하게 된다. 이렇게 생성된 문장을 통해, 다중 에이전트들의 서로 교류 및 협력하여 문장을"}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "결합하여, 전체적인 요약 정보를 생성하게 된다. 도 7 내지 9는 본 발명의 일 실시예에 따른 장면 이해 정보의 교환 및 결합 방법을 개념적으로 나타낸 도면이다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 6, "content": "도 7은 인공지능 에이전트 A가 생성한 언어적 요약문을 나타내고, 도 8은 인공지능 에이전트 B가 생성한 언어적"}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "요약문을 나타낸다. 도 9는 인공지능 에이전트 A와 인공지능 에이전트 B가 각각 생성한 언어적 요약문을 교환하 는 과정을 나타낸다."}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 8, "content": "도 6에서 하나의 에이전트가 언어적 요약문을 생성하는 방식에 대한 것을 다중 에이전트 관점에서 살펴보면, 두"}
{"patent_id": "10-2022-0178220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "개의 에이전트가 있다고 가정하고, 각각의 상황 변화가 있을 때 이를 언어적 요약으로 표현할 수 있다. 이를 통 해 다수의 에이전트가 있다고 가정해도, 언어적 결합으로 다양한 환경 변화에도 구성 및 이해가 가능하다. 도 10은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다. 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 장치는 컴퓨터로 읽을 수 있는 기록매체와 같은 컴 퓨터 시스템에서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들 을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 장치는 적어도 하나의 프로그램이 기 록된 메모리 및 상기 프로그램을 실행하는 프로세서를 포함하며, 상기 프로그램은 제1 공간의 이미 지를 획득하는 단계, 상기 이미지 내 객체들을 인식하는 단계, 상기 객체들 간의 관계 정보 및 상기 객체들 각 각의 상태 정보를 그래프 형태로 구조화하는 단계 및 상기 구조화된 정보를 주변 인공지능 에이전트로부터 수신 한 정보와 병합하는 단계의 수행을 위한 명령어들을 포함한다. 이때, 상기 객체들은 상기 특정 공간의 이미지를 입력으로 기학습된 제1 인공지능 신경망에 기반하여 인식되고, 상기 객체들 각각의 상태 정보는 객체들을 상태별로 레이블링한 학습데이터에 기반하여 학습된 제2 인공지능 신 경망에 상기 객체들을 입력하여 획득될 수 있다. 이때, 상기 병합하는 단계는 상기 제1 공간에 상응하는 정보를 상기 주변 인공지능 에이전트의 제2 공간에 상응 하는 정보와 병합할 수 있다. 이때, 상기 병합된 정보는 상기 제1 공간과 상기 제2 공간의 위치 관계가 링크 형태로 연결될 수 있다. 이때, 상기 병합하는 단계는 상기 주변 인공지능 에이전트의 메타데이터에 기반하여 병합 여부를 결정하고, 상 기 메타데이터는 상기 객체들 각각의 상태 정보에 상응하는 타임스탬프 정보를 포함할 수 있다. 이때, 상기 병합하는 단계는 상기 타임스탬프 정보를 이용하여, 상기 객체들 각각의 상태 정보가 현재 시간으로 부터 기설정된 시간 이내에 업데이트된 정보를 병합할 수 있다. 이때, 상기 병합하는 단계는 시간 변화에 따라 상태가 변화한 객체에 관한 정보를 상기 주변 인공지능 에이전트 와 교환할 수 있다. 이때, 상기 병합하는 단계는 상기 객체들 각각의 상태 정보에 기반하여 생성된 문장 단위의 정보를 상기 주변 인공지능 에이전트와 교환할 수 있다. 본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “ 필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요 소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다 고 할 것이다."}
{"patent_id": "10-2022-0178220", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래 단일 에이전트의 장면 이해 기술의 문제점을 개념적으로 나타낸다. 도 2는 종래 다중 에이전트의 장면 이해 기술의 문제점을 개념적으로 나타낸다. 도 3은 본 발명의 일 실시예에 따른 인공지능 에이전트의 장면 이해 구성 및 병합 방법을 나타낸 흐름도이다. 도 4는 단일 에이전트의 시간 흐름에 따른 장면 이해 구성 예시이다. 도 5는 단일 에이전트의 이동 또는 다중 에이전트 간 정보 교환에 따른 복합 장면의 결합 예시이다. 도 6은 본 발명의 일 실시예에 따른 장면 이해 정보에 기반한 문장 정보 생성 방법을 개념적으로 나타낸 도면이 다. 도 7 내지 9는 본 발명의 일 실시예에 따른 장면 이해 정보의 교환 및 결합 방법을 개념적으로 나타낸 도면이다. 도 10은 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다."}
