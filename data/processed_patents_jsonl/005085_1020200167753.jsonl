{"patent_id": "10-2020-0167753", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0078327", "출원번호": "10-2020-0167753", "발명의 명칭": "실시간 분석 및 예측을 위한 학습 모델 관리 방법 및 장치", "출원인": "주식회사 이노커스", "발명자": "김재헌"}}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "운영체제 레벨 가상화(virtualization) 환경에서 개별 태스크(task)를 위한 가상 공간을 할당하는 컨테이너를기반으로, 인공지능 서비스 구축을 위한 사용자 인터페이스를 제공하는 학습 모델 관리 장치를 통하여, 실시간분석 및 예측을 위한 학습 모델 관리 방법에 있어서,사용자 단말이 상기 학습 모델 관리 장치에 접속하여 상기 사용자 단말의 사용자 식별 정보가 획득되면 상기 사용자 단말에 대한 개별 컨테이너를 할당하는 단계;상기 생성된 컨테이너 내에서, 상기 사용자 단말로부터 업로드 된 학습 모델 및 기 저장된 학습 모델 중 상기사용자 단말로부터 요청된 학습 모델 기반 학습 모델 목록을 생성하는 단계;상기 생성된 학습 모델 목록의 각각의 학습 모델에 대해 서빙(serving) 실행 또는 중지 여부를 설정하는 단계;및상기 학습 모델 목록 내 서빙 실행 학습 모델에, 기 수집되어 저장되거나 수집되는 데이터를 적용하여 상기 서빙 실행 학습 모델 각각에 대한 예측 및 분석 결과 값을 출력하는 단계를 포함하는,학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 개별 컨테이너를 할당하는 단계는,상기 사용자 단말로부터 액세스 요청을 수신하는 단계;상기 액세스 요청한 사용자 단말에 대한 컨테이너를 매칭하여 상기 사용자 단말의 사용자 식별 정보를 기반으로하는 컨테이너 접속 정보를 생성하는 단계; 및상기 사용자 단말에 상기 컨테이너 접속 정보를 제공하는 단계를 포함하는,학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 사용자 단말에 할당된 컨테이너 내의 프로세스가 종료되면 상기 사용자 단말에 할당된 컨테이너를 삭제하는 단계를 더 포함하는,학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 사용자 단말로부터 학습 모델이 업로드 되는 경우, 상기 업로드 된 학습 모델의 포맷이 기 설정된 형식과다르면 상기 업로드 된 학습 모델의 포맷을 기 설정된 형식으로 변경하는 단계를 더 포함하는,공개특허 10-2022-0078327-3-학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 학습 모델 목록을 생성하는 단계는,상기 학습 모델의 모델명, 상기 학습 모델의 업로드 날짜 및 상기 학습 모델의 현재 서빙 상태를 포함하여 상기학습 모델 목록을 생성하는 단계를 포함하는,학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 사용자 단말로부터 상기 학습 모델 목록의 학습 모델 삭제가 요청되면, 상기 학습 모델의 서빙 중지 여부를 확인하는 단계; 및상기 학습 모델이 서빙 중지 상태인 경우, 상기 사용자 단말로부터의 삭제 요청에 따른 학습 모델 삭제를 수행하는 단계를 더 포함하는,학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 예측 및 분석 결과 값을 출력하는 단계는,상기 사용자 단말로부터 상기 서빙 실행 학습 모델 중 적어도 하나 이상의 예측 및 분석을 위한 데이터,모델명, 그래프 대분류 및 그래프 중분류 항목에 대한 선택 정보를 획득하는 단계; 및상기 획득한 선택 정보를 기반으로 하여 상기 서빙 실행 학습 모델 중 적어도 하나 이상의 예측 및 분석을 수행하는 단계를 포함하는,학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 사용자 단말로부터 로그인 정보를 포함하는 로그인 요청을 수신하는 단계; 및상기 로그인 요청에 응답하여 상기 사용자 단말의 인증을 수행해 관리자 단말로 판별되는 경우 컨테이너가 할당된 모든 사용자 단말들의 학습 모델 목록을 제공하는 단계를 더 포함하는,학습 모델 관리 방법."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "운영체제 레벨 가상화(virtualization) 환경에서 개별 태스크(task)를 위한 가상 공간을 할당하는 컨테이너를기반으로, 인공지능 서비스 구축을 위한 사용자 인터페이스를 제공하는 실시간 분석 및 예측을 위한 학습 모델관리 장치에 있어서,공개특허 10-2022-0078327-4-사용자 단말과 통신할 수 있도록 하는 통신부;메모리; 및상기 메모리와 연결되고, 상기 메모리에 포함된 컴퓨터 판독 가능한 명령들을 실행하도록 구성된 적어도 하나의프로세서를 포함하고,상기 적어도 하나의 프로세서는,상기 사용자 단말이 상기 학습 모델 관리 장치에 접속하여 상기 사용자 단말의 사용자 식별 정보가 획득되면 상기 사용자 단말에 대한 개별 컨테이너를 할당하는 동작,상기 생성된 컨테이너 내에서, 상기 사용자 단말로부터 업로드 된 학습 모델 및 기 저장된 학습 모델 중 상기사용자 단말로부터 요청된 학습 모델 기반 학습 모델 목록을 생성하는 동작,상기 생성된 학습 모델 목록의 각각의 학습 모델에 대해 서빙(serving) 실행 또는 중지 여부를 설정하는 동작,및상기 학습 모델 목록 내 서빙 실행 학습 모델에, 기 수집되어 저장되거나 수집되는 데이터를 적용하여 상기 서빙 실행 학습 모델 각각에 대한 예측 및 분석 결과 값을 출력하는 동작을 수행하도록 구성된,학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 개별 컨테이너를 할당하는 동작은,상기 사용자 단말로부터 액세스 요청을 수신하는 동작,상기 액세스 요청한 사용자 단말에 대한 컨테이너를 매칭하여 상기 사용자 단말의 사용자 식별 정보를 기반으로하는 컨테이너 접속 정보를 생성하는 동작, 및상기 사용자 단말에 상기 컨테이너 접속 정보를 제공하는 동작을 포함하는,학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9 항에 있어서,상기 적어도 하나의 프로세서는,상기 사용자 단말에 할당된 컨테이너 내의 프로세스가 종료되면 상기 사용자 단말에 할당된 컨테이너를 삭제하는 동작을 더 수행하도록 구성된,학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9 항에 있어서,상기 적어도 하나의 프로세서는,상기 사용자 단말로부터 학습 모델이 업로드 되는 경우, 상기 업로드 된 학습 모델의 포맷이 기 설정된 형식과다르면 상기 업로드 된 학습 모델의 포맷을 기 설정된 형식으로 변경하는 동작을 더 수행하도록 구성된,공개특허 10-2022-0078327-5-학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9 항에 있어서,상기 학습 모델 목록을 생성하는 동작은,상기 학습 모델의 모델명, 상기 학습 모델의 업로드 날짜 및 상기 학습 모델의 현재 서빙 상태를 포함하여 상기학습 모델 목록을 생성하는 동작을 포함하는,학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서,상기 적어도 하나의 프로세서는,상기 사용자 단말로부터 상기 학습 모델 목록의 학습 모델 삭제가 요청되면, 상기 학습 모델의 서빙 중지 여부를 확인하는 동작, 및상기 학습 모델이 서빙 중지 상태인 경우, 상기 사용자 단말로부터의 삭제 요청에 따른 학습 모델 삭제를 수행하는 동작을 더 수행하도록 구성된,학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9 항에 있어서,상기 예측 및 분석 결과 값을 출력하는 동작은,상기 사용자 단말로부터 상기 서빙 실행 학습 모델 중 적어도 하나 이상의 예측 및 분석을 위한 데이터,모델명, 그래프 대분류 및 그래프 중분류 항목에 대한 선택 정보를 획득하는 동작, 및상기 획득한 선택 정보를 기반으로 하여 상기 서빙 실행 학습 모델 중 적어도 하나 이상의 예측 및 분석을 수행하는 동작을 더 수행하도록 구성된,학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 9 항에 있어서,상기 적어도 하나의 프로세서는,상기 사용자 단말로부터 로그인 정보를 포함하는 로그인 요청을 수신하는 동작, 및상기 로그인 요청에 응답하여 상기 사용자 단말의 인증을 수행해 관리자 단말로 판별되는 경우 컨테이너가 할당된 모든 사용자 단말들의 학습 모델 목록을 제공하는 동작을 더 수행하도록 구성된,학습 모델 관리 장치."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시간 분석 및 예측을 위한 학습 모델 관리 방법 및 장치가 개시된다. 본 개시의 일 실시 예에 따른 실시간 분 석 및 예측을 위한 학습 모델 관리 방법은, 사용자 단말이 학습 모델 관리 장치에 접속하여 사용자 단말의 사용 자 식별 정보가 획득되면 사용자 단말에 대한 개별 컨테이너를 할당하는 단계와, 생성된 컨테이너 내에서, 사용 자 단말로부터 업로드 된 학습 모델 및 기 저장된 학습 모델 중 사용자 단말로부터 요청된 학습 모델 기반 학습 모델 목록을 생성하는 단계와, 생성된 학습 모델 목록의 각각의 학습 모델에 대해 서빙(serving) 실행 또는 중지 여부를 설정하는 단계와, 학습 모델 목록 내 서빙 실행 학습 모델에, 기 수집되어 저장되거나 수집되는 데이터를 적용하여 서빙 실행 학습 모델 각각에 대한 예측 및 분석 결과 값을 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 실시간 데이터 분석을 통한 인공지능 서비스 구축을 용이하게 수행하고 학습 모델의 예측 결과를 다 양한 방법으로 시각화 가능한 사용자별 대시보드(dashboard)를 제공하는 실시간 분석 및 예측을 위한 학습 모델 관리 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 기계학습(Machine Learning)은 인공지능의 한 분야로, 사람이 학습하듯이 컴퓨터에도 데이터들을 줘 서 학습하게 함으로써 새로운 지식을 얻어내게 하는 분야이다. 특히 딥러닝은 인공신경망에 기반을 둔 기계학습 기술의 한 종류로, 사물이나 데이터를 군집화하거나 분류하는데 사용하는 기술이다. 딥러닝의 핵심은 분류를 통 한 예측이다. 수많은 데이터 속에서 패턴을 발견해 인간이 사물을 구분하듯 컴퓨터가 데이터를 나눈다. 이 같은 분별 방식은 두 가지로 나뉜다. '지도 학습(supervised learning)'과 '비지도 학습(unsupervised learning)'이 다. 한편, 이러한 딥러닝 등의 기계학습을 개발하고 이용하기 위해서, 딥러닝 등의 기계학습에 활용하기 위한 다양 한 오픈 소스 플랫폼들이 개발되고 있다. 또한 개발된 기계학습 모델을 실제로 적용하고 활용하기 위해서는, 기 계학습 모델을 학습하고 평가하는 일련의 과정, 기계학습 모델을 추론(inference)하는 과정이 필요하다. 그리고 기계학습 모델을 실제로 적용하고 활용하는 환경에서 사용할 수 있도록 배포할 수 있어야 한다. 이와 같이, 선행기술 1에 개시된 봐와 같은, 기계학습에 대해 개발, 최적화, 배포하는 인공지능 서비스들이 개 발되고 있다. 그러나 인공지능을 기반으로 한 서비스를 실현하기 위해 대규모 인프라 기술이 요구되어 인공지능 개발자와 인프라 엔지니어 간의 격차가 벌어지고 인공지능 서비스 개발에 어려움이 생기고 있다. 또한 인공지능 서비스들은 대부분 기계학습(예를 들어, 딥러닝) 기술을 이용한 모델의 추론 정확도를 만족시킬 뿐 리소스를 효율적으로 사용하는데 한계점이 있다. 또한 실제 서비스 적용에 대한 웹 또는 플랫폼 아키텍처를 구성하는 부분에 있어서, 데이터에 대한 유입부터 전 처리, 모델 학습, 서빙(serving)에 대한 요구를 처리하는 다양한 이종의 인프라 기술을 운영하고 관리하기 위해 비용이 소요된다."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 선행기술 1: 한국공개특허 제10-2019-0043446호(2019.04.26공개)"}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시 예의 일 과제는, 다양한 종류의 학습 모델을 기반으로 실시간 데이터 분석 결과의 시각화를 통 한 인공지능 서비스 구축을 용이하게 수행할 수 있도록 사용자 개인별 대시보드(dashboard)를 제공하고자 하는 데 있다. 본 개시의 실시 예의 일 과제는, 운영체제 레벨 가상화(virtualization) 환경에서 개별 태스크(task)를 위한 가 상 공간을 할당하는 컨테이너를 기반으로, 인공지능 서비스 구축을 위한 사용자 인터페이스를 제공하고자 하는 데 있다. 본 개시의 실시 예의 일 과제는, 인터넷 상에서 대시보드를 이용하는 사용자에게 개인별 맞춤 딥러닝 모델을 적 용하여, 데이터 분석 및 시각화 결과를 제공하고 리소스를 효율적으로 사용할 수 있도록 하는데 있다. 본 개시의 실시 예의 일 과제는, 인공지능 서비스를 웹(WEB)을 통해 제공하는 것에 대한 문제를 해결하기 위해 가상화 기술을 기반으로 하여 딥러닝 모델을 적용하는 안정적인 아키텍처를 구현하고자 하는데 있다.본 개시의 실시 예의 일 과제는, 가상화 기술을 기반으로 하여 딥러닝 모델을 적용하는 안정적인 웹 서비스 개 발과 배포 및 관리를 용이하게 하기 위해 운영체제 레벨 가상화 기술을 제공하는 컨테이너를 사용하고자 하는데 있다. 본 개시의 실시 예의 일 과제는, 컨테이너 기반의 딥러닝 모델 관리 시스템을 제공할 수 있는 다양한 아키텍처 를 설계하고 아키텍처들간의 성능을 비교하여 가장 좋은 성능의 것으로 시스템을 구축할 수 있도록 하는데 있다. 본 개시의 실시 예의 일 과제는, 오픈 paas(platform as a service) 에서 제공되는 데이터의 연동을 위해서 도 커 엔진을 사용하여 컨테이너 단위의 카프카 컨슈머(데이터를 받아 저장하고 있는 상태)를 구동하고, 사용자가 해당 데이터와 데이터에 맞는 학습모델을 선택하여 위젯을 구성하게 될 경우, 사용자 별로 부여되어있는 실시간 데이터 분석 모듈에 입력 값으로 전송되어 사용자가 자신이 선택한 데이터에 따른 실시간 분석 및 예측 결과를 대시보드 위젯에서 확인할 수 있도록 하는데 있다. 본 개시의 실시 예의 일 과제는, 컨슈머를 오픈 paas 연동 기술로써 정의하며 개발된 연동 모듈을 도커 이미지 로 패키징하여 배포가 용이하도록 하고, 외부 환경에서 실행시키고자 할 때 프로세스의 독립성을 높여서 리소스 분할을 통해 서비스가 안정적으로 구동될 수 있도록 설계하고자 하는데 있다. 본 개시의 실시 예의 목적은 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 실시간 분석 및 예측을 위한 학습 모델 관리 방법은, 운영체제 레벨 가상화 (virtualization) 환경에서 개별 태스크(task)를 위한 가상 공간을 할당하는 컨테이너를 기반으로, 인공지능 서 비스 구축을 위한 사용자 인터페이스를 제공하는 단계를 포함할 수 있다. 구체적으로 본 개시의 일 실시 예에 따른 실시간 분석 및 예측을 위한 학습 모델 관리 방법은, 사용자 단말이 학습 모델 관리 장치에 접속하여 사용자 단말의 사용자 식별 정보가 획득되면 사용자 단말에 대한 개별 컨테이 너를 할당하는 단계와, 생성된 컨테이너 내에서, 사용자 단말로부터 업로드 된 학습 모델 및 기 저장된 학습 모 델 중 사용자 단말로부터 요청된 학습 모델 기반 학습 모델 목록을 생성하는 단계와, 생성된 학습 모델 목록의 각각의 학습 모델에 대해 서빙(serving) 실행 또는 중지 여부를 설정하는 단계와, 학습 모델 목록 내 서빙 실행 학습 모델에, 기 수집되어 저장되거나 수집되는 데이터를 적용하여 서빙 실행 학습 모델 각각에 대한 예측 및 분석 결과 값을 출력하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 실시간 분석 및 예측을 위한 학습 모델 관리 방법을 통하여, 인터넷 상에서 대시 보드를 이용하는 사용자에게 개인별 맞춤 딥러닝 모델을 적용하여, 데이터 분석 및 시각화 결과를 제공함으로써, 인공지능 서비스 구축하는데 있어 리소스가 효율적으로 사용되도록 할 수 있다. 이 외에도, 본 발명의 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예에 의하면, 인터넷 상에서 대시보드를 이용하는 사용자에게 개인별 맞춤 딥러닝 모델을 적용 하여, 실시간으로 데이터 분석 및 시각화 결과를 제공함으로써, 인공지능 서비스 구축하는데 있어 리소스가 효 율적으로 사용되도록 할 수 있다. 또한, 운영체제 레벨 가상화 환경에서 개별 태스크를 위한 가상 공간을 할당하는 컨테이너를 기반으로, 다양한 종류의 학습 모델에 대한 실시간 데이터 분석을 수행하여 인공지능 서비스 구축을 용이하게 수행할 수 있도록 하는 사용자 인터페이스를 제공하고, 데이터에 대한 유입부터 전처리, 모델 학습, 서빙에 대한 요구를 수행할 수 있는 웹 또는 플랫폼 아키텍처를 제공함으로써, 비용을 감소시킬 수 있으며, 사용자 만족도를 향상시킬 수있다. 또한, 인공지능 서비스를 웹(WEB)을 통해 제공하는 것에 대한 문제를 해결하기 위해 가상화 기술을 기반으로 하 여 딥러닝 모델을 적용하는 안정적인 아키텍처를 구현함으로써, 안정적인 웹 서비스 개발과 배포 및 관리를 용 이하게 할 수 있도록 한다. 또한, 운영체제 레벨 가상화 기술을 제공하는 컨테이너를 사용하여, 컨테이너 기반의 딥러닝 모델 관리 시스템 을 제공할 수 있는 다양한 아키텍처를 설계하고 아키텍처들간의 성능을 비교하여 가장 좋은 성능의 것으로 시스 템을 구축할 수 있도록 할 수 있다. 또한, 데이터 허브의 모델 또는 사용자가 등록한 학습 모델을 토대로 데이터 허브의 데이터들을 위젯(widget) 기능을 통해 실시간으로 분석할 수 있는 기능을 제공함으로써, 사용자가 분석 결과를 직관적으로 확인할 수 있 도록 할 수 있다. 또한, 기 설정된 포맷의 모델뿐만 아니라 다른 포맷의 모델에 서비스를 제공할 수 있도록 확장이 용이하며, 데 이터 학습에서 학습된 모델을 서빙하는 과정까지 새로운 모델과 업데이트된 버전을 전달하는 시스템, 즉 머신러 닝 파이프라인 시스템과의 통합을 지원하는 방식이 매우 유연하고, 모델 조회 및 추론기능을 수행하는 시스템 내 위치한 핵심 코드를 단순히 이식된 모델에서 발견될 수 있는 성능 급 저하를 피하기 위해 세심하게 최적화 시킴으로써, 학습 모델 관리 장치의 만족도 및 성능을 향상시킬 수 있다."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야"}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련 된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략 한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 상기 용어들에 의해 한정되어서 는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 이하, 본 발명에 따른 실시 예들을 첨부된 도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설 명함에 있어, 동일하거나 대응하는 구성요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하 기로 한다. 본 실시 예는 데이터 허브의 실시간 분석 및 예측을 수행하는 것이다. 데이터 허브는 IoT 필드 디바이스/게이트 웨이 및 IoT 인프라로부터 실시간 대용량 정형/비정형 데이터를 수집하여 분석, 학습, 시각화 제공 가능한 데이 터 중심의 플랫폼을 말하며, 예를 들어 스마트시티에 대한 데이터 허브일 수 있다. 본 실시 예는 Classification Model, Regression Model, Cluster Model 등 다양한 종류의 학습 모델을 저장하 고, 저장한 학습 모델을 기반으로 데이터 허브의 데이터들을 실시간으로 분석할 수 있는 기능을 제공할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 실시간 분석 및 예측을 위한 학습 모델 관리 시스템 환경을 설명하기 위한 예시도이다. 도 1에 도시된 바와 같이, 학습 모델 관리 시스템은 학습 모델 관리 장치, 사용자 단말, 서버 및 네트워크를 포함할 수 있으며, 특히 네트워크를 통해 사용자 단말과 통신하여 상기 사 용자 단말에 실시간 분석 및 예측을 위한 사용자 인터페이스를 제공할 수 있다. 이때 본 실시 예에서는, 사용자들이 사용자 단말에서 구현되는 어플리케이션 또는 웹사이트에 접속하여, 인공지능 서비스 구축을 위하여 실시간 데이터 분석 및 예측을 수행하는 과정 등을 수행할 수 있다. 이러한 사 용자 단말은 학습 모델 관리 평가 어플리케이션 또는 학습 모델 관리 웹사이트에 접속한 후 인증 과정을 통하여 학습 모델 관리를 위한 서비스를 제공받을 수 있다. 인증 과정은 회원가입 등 사용자 정보를 입력하는 인증, 사용자 단말에 대한 인증 등을 포함할 수 있으나, 이에 한정되지 않고 학습 모델 관리 장치 및/또는 서버에서 전송되는 링크에 접속하는 것만으로 인증 과정이 수행될 수도 있다. 즉 본 실시 예에서는 사용자 단말에서 인증 과정이 수행된 경우, 사용자 식별 정보가 획득될 수 있으며, 실시 예에 따라서 사용자 식별 정보 및 사용자 단말 식별 정보가 획득될 수 있다. 한편 본 실시 예에서는, 학습 모델 관리 시스템을 이용하는데 있어, 학습 모델을 등록하고 실행 및 중지 기 능 등을 수행하는 사용자와 모든 사용자에 대해 관리하는 관리자로 구분할 수 있다. 사용자 단말에서 인증 과정을 수행하는 경우, 본 실시 예에서는 사용자 식별 정보에 기반하여 사용자인지 관리자인지 구분하여 학습 모델 관리 시스템의 사용자 인터페이스를 달리하여 제공할 수 있다. 즉 사용자 단말은 사용자가 소지하 는 제 1 사용자 단말 및 관리자가 소지하는 제 2 사용자 단말로 구분될 수 있다. 다시 말해, 제 1 사 용자 단말은 학습 모델을 등록하고, 학습 모델의 서빙 실행 및 중지 기능 등이 수행될 수 있도록 설정할 수 있으며, 제 2 사용자 단말은 데이터 허브의 학습 모델 또는 사용자가 등록한 학습 모델의 상태(실행, 중지) 및 목록을 관리할 수 있도록 설정할 수 있다. 본 실시 예에서, 사용자 단말은 사용자가 조작하는 데스크 탑 컴퓨터, 스마트폰, 노트북, 태블릿 PC, 스마 트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 사용 자 단말은 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 단 말기 일 수 있다. 사용자 단말은 상술한 내용에 제한되지 아니하며, 웹 브라우징이 가능한 단말기는 제한 없이 차용될 수 있다. 한편, 본 실시 예에서 학습 모델 관리 시스템은 학습 모델 관리 장치 및/또는 서버에 의해 구현될 수 있다. 이때 서버는 학습 모델 관리 장치가 포함되는 학습 모델 관리 시스템을 운용하기 위한 서버일 수 있다. 또한 서버는 각종 인공 지능 알고리즘을 적용하는데 필요한 빅데이터와, 학습 모델 관리 장치를 동작시키는 데이터를 제공하는 데이터베이스 서버일 수 있다. 그 밖에 서버는 학습 모델 관리 시스템 이 구현될 수 있도록 하는 웹 서버 또는 어플리케이션 서버, 학습 모델 서빙을 위한 서빙 서버 등을 포함할 수 있다. 네트워크는 학습 모델 관리 시스템에서 학습 모델 관리 장치, 서버 및 사용자 단말을 연결하는 역할을 수행할 수 있다. 이러한 네트워크는 예컨대 LANs(local area networks), WANs(Wide area networks), MANs(metropolitan area networks), ISDNs(integrated service digital networks) 등의 유선 네트 워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 발명의 범위가 이 에 한정되는 것은 아니다. 또한 네트워크는 근거리 통신 및/또는 원거리 통신을 이용하여 정보를 송수신할 수 있다. 여기서 근거리 통신은 블루투스(bluetooth), RFID(radio frequency identification), 적외선 통신 (IrDA, infrared data association), UWB(ultra-wideband), ZigBee, Wi-Fi(Wireless fidelity) 기술을 포함할 수 있고, 원거리 통신은 CDMA(code division multiple access), FDMA(frequency division multiple access), TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access), SC- FDMA(single carrier frequency division multiple access) 기술을 포함할 수 있다. 네트워크는 허브, 브리지, 라우터, 스위치 및 게이트웨이와 같은 네트워크 요소들의 연결을 포함할 수 있 다. 네트워크는 인터넷과 같은 공용 네트워크 및 안전한 기업 사설 네트워크와 같은 사설 네트워크를 비롯 한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 네트워크에의 액세스는 하나 이상의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다. 더 나아가 네트워크는 사물 등 분 산된 구성 요소들 간에 정보를 주고받아 처리하는 IoT(Internet of Things, 사물인터넷) 망 및/또는 5G 통신을 지원할 수 있다. 도 2는 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 컨테이너 시스템에 대해 설명하기 위한 도면이다. 본 실시 예는, 딥러닝 모델을 적용하는 안정적인 웹 서비스 개발과 배포 및 관리를 용이하게 하기 위해 운영체 제 레벨 가상화 기술인 컨테이너 기술을 사용할 수 있다. 즉 본 실시 예는 인공지능 서비스를 웹을 통해 제공하는 것에 대한 문제를 해결하기 위해, 딥러닝 모델을 적용 하는 안정적인 아키텍처에 관한 것으로, 안정적인 아키텍처를 구성하기 위해 가상화 기술을 적용하고, 컨테이너 기반의 딥러닝 모델 관리 시스템을 제공할 수 있는 다양한 아키텍처를 설계하고 아키텍처들 간의 성능을 비교를 하여 가장 좋은 성능의 것으로 시스템을 구축하고자 하는 것을 특징으로 한다. 본 실시 예는, 컨테이너 기술로 예를 들어, 도커 컨테이너를 사용할 수 있으나 이에 한정되지는 않는다. 도 2를 참조하면, 본 실시 예의 학습 모델 관리 장치의 아키텍처는 컨테이너 기반의 서빙 기술을 이용해서 처리하는 방식의 아키텍처로, 딥러닝 기반 플랫폼 또는 웹서비스를 구축하기 위한 구성요소를 갖추고 있다. 본 실시 예에서는, 서빙 기술로, 예를 들어 텐서플로우 서빙이 이용될 수 있으나 이에 한정되지는 않는다. 텐서플 로우 서빙은 내부적으로 실시간에 최적화 되어있는 통신 방법을 사용함으로써 연산속도를 최소화하였기 때문에, 다수의 다른 오픈소스 상용 소프트웨어 시스템 중에서 가장 낮은 지연율을 제공하며, 텐서플로우에서 제공하는 프로덕션 환경을 위해 설계된 머신러닝 모델을 위한 확장성을 갖고 있는 고성능 모델 서빙 기술로써 사전 학습 된 모델을 쉽게 배포하고 활용할 수 있다. 또한 본 실시 예에서는, 실시간 딥러닝 분석 결과를 출력하기 위해 사전에 학습된 모델을 포함하는 서빙 기술을 이용할 수 있으며, 서빙 기술은 모델의 저장과 추론을 수행하기 위해 사용자가 로컬 또는 클라우드 서버 위에서 서빙을 배포 하는 것이 요구되는 자동화 서비스를 말한다. 도 2에 도시된 바와 같이, 본 실시 예의 아키텍처의 컨테이너 간 데이터 전송은 컨테이너 네트워크 브릿지 (network bridge)를 통하여 포워딩 된 포트를 통해서 이루어지며, 웹(WEB) 컨테이너(예를 들어, Nginx)를 통해 서 접근하는 요청은 프레임워크 컨테이너(예를 들어, Django 및 Gunicorn이 실행되고 있는 컨테이너)로 연결되 어 미들웨어를 거쳐 웹 어플리케이션 서버(Web Application Server, WAS)(예를 들어, Django)로 전달될 수 있 다. 이때 본 실시 예에서는 서빙 컨테이너(예를 들어, 텐서플로우 서빙 컨테이너, TFserving container)를 통해, 데이터 컨테이너(예를 들어, MariaDB container)로부터의 데이터를 JSON 형식으로 모델 서빙 서버에 전달 하여 POST 방식의 통신을 통해 추론된 결과를 반환 받을 수 있다. JSON(JavaScript Object Notation)은 웹과 컴퓨터 프로그램에서 용량이 적은 데이터를 교환하기 위해 데이터 객체를 속성 및 값의 쌍 형태로 표현하는 형 식을 의미할 수 있으며, 웹 브라우저와 웹 서버 간 비동기 통신, 웹 서버 간의 데이터 교환 등에 주로 사용될 수 있다. JSON은 자바스크립트(JavScript)의 구문 형식을 따르지만, C, C++, C#, 자바(Java), 파이선(Python)등의 프로그램 언어와도 함께 사용되는 플랫폼과 프로그래밍 언어 면에서 독립적인 언어이다. 한편, 컨테이너란 호스트 OS(HostOS)상에 논리적인 구획(컨테이너)을 만들고, 어플리케이션을 작동시키기 위해 필요한 라이브러리나 어플리케이션 등을 하나로 모아, 마치 별도의 서버인 것처럼 사용할 수 있게 만든 가상화 기술을 의미할 수 있다. 또한 컨테이너는 호스트 OS의 리소스를 논리적으로 분리시키고, 여러 개의 컨테이너가 호스트 OS의 커널(Kernel)을 공유하여 사용할 수 있다. 본 실시 예에서는, 예를 들어 도커 시스템이 적용되어, 어플리케이션뿐만 아니라 실행에 필요한 시스템 환경을 모아서 컨테이너로 관리할 수 있다. 이러한 관리를 위해 만든 것을 이미지라고 하며, 이 이미지로 만든 컨테이 너는 도커 시스템(예를 들어, Docker Engine)이 설치된 곳이라면 어디든 똑같이 동작할 수 있다. 다만 도커 시 스템은 일 실시 예로, 컨테이너 기술이 구현되는 다양한 시스템이 적용될 수 있다. 도커는 컨테이너 기반의 오픈 소스 가상화 플랫폼이다. 다양한 프로그램, 실행환경을 컨테이너로 추상화하고 동 일한 인터페이스를 제공하여 프로그램의 배포 및 관리를 단순하게 해준다. 백엔드 프로그램, 데이터베이스 서버, 메시지 큐 등 어떤 프로그램도 컨테이너로 추상화할 수 있고 조립PC, AWS, Azure, Google Cloud Platform등 어디에서든 실행할 수 있다. 즉 도커는 컨테이너의 리소스, 파일 시스템, 네트워크를 기존 시스템과 격리시키고 이미지를 관리하고 공유하는 기능을 제공할 수 있다. 도커의 기능은 크게 이미지 만들기(Build), 이미지 공유(Ship), 컨테이너 동작(Run)로 구분할 수 있다. 이미지 만들기 기능에 대해 살펴보면, 도커는 어플리케이션과 실행에 필요한 라이브러리, 미들웨어, OS, 네트워 크 설정 등 필요한 모든 파일을 모아서 이미지로 만들 수 있다. 이미지는 명령어를 이용해 수동으로 만들 수도 있지만 자동으로 빌드와 배포를 하는 CI/CD(Continuous Integration/Continuous Delivery) 환경에서는 도커 설 정 파일(Dockerfile)을 이용해 자동으로 만들 수도 있다. 보통 이미지에는 하나의 어플리케이션만 넣고 여러 컨 테이너를 조합해서 서비스를 구축하는 방법을 사용할 수 있다. 또한 이미지를 여러 개 같이 사용할 수 있다. 예 를 들면 CentOS 리눅스 이미지와 Nginx 웹 서버 이미지를 겹쳐서 새로운 이미지를 만들 수 있다. 이미지 공유 기능에 대해 살펴보면, 도커는 이미지를 업로드해서 공유하는 저장소를 구현할 수 있으며, 상기 저 장소에 기본 제공되는 베이스 이미지를 활용하여 환경을 빠르고 안전하게, 그리고 자동으로 구축할 수 있다. 또 한 사용자가 만든 어플리케이션 또한 이미지로 만들어서 업로드하고 공유할 수 있고, 형상 관리 툴과 연동해서 Dockerfile을 관리하고 이미지를 자동으로 빌드해서 저장소에 배포도 가능할 수 있다. 한편, 이미지는 컨테이너 실행에 필요한 파일과 설정 값 등을 포함하고 있는 것으로 상태 값을 가지지 않고 변 하지 않는다(Immutable). 같은 이미지에서 여러 개의 컨테이너를 생성할 수 있고 컨테이너의 상태가 바뀌거나 삭제되더라도 이미지는 변하지 않고 그대로 남아있다. 컨테이너 동작 기능에 대해 살펴보면, 도커는 이미지를 가지고 컨테이너를 생성해서 동작시킨다. 하나의 이미지 를 가지고 여러 개의 컨테이너를 만들어낼 수도 있다. 도커는 컨테이너를 생성하고 관리하기 위한 여러 명령을 제공할 수 있다. 실제 업무에서는 보통 한 대의 호스트에 모든 컨테이너를 동작시키는 것이 아니라 여러 호스트 로 된 분산 환경인 경우가 많으며, 이런 분산 환경에서 여러 노드의 컨테이너를 관리하기 위해 컨테이너 오케스 트레이션 툴(Container Orchestration Tool)이 사용될 수 있다. 오케스트레이션이란 컨테이너 배포, 장애 복구, 로드 밸런싱 등 여러 기능을 자동으로 처리해주는 것을 말한다. 한편, 본 실시 예에서는, 실시간 분석 및 예측을 위한 학습 모델 관리 장치에 서빙 시스템이 적용될 수 있 다. 서빙 시스템은 다양한 서빙 시스템이 적용될 수 있으나 본 실시 예에서는 상술한 바와 같이, TensorFlow Serving이 적용될 수 있으며, 이러한 텐서플로우 서빙은 딥러닝 모델 배포를 위한 고성능 서빙 시스템이다. 텐 서플로우 서빙은 텐서플로우 모델과는 즉시 통합할 수 있으며 다른 유형의 모델에도 서비스를 제공하도록 쉽게 확장될 수 있다. 즉 텐서플로우 서빙은 지원하는 딥러닝 프레임워크의 종류가 TensorFlow로 학습된 모델에 국한 되어있지만, 데이터 학습에서부터 학습된 모델을 서빙하는 과정까지 새로운 모델과 업데이트된 버전을 전달하는 시스템, 즉 머신러닝 파이프라인 시스템과의 통합을 지원하는 방식이 매우 유연하게 구현될 수 있다. 또한 이와 동시에 학습 모델 조회 및 추론기능을 수행하는 시스템 내 위치한 핵심 코드는 단순히 이식된 모델에서 발견될 수 있는 성능 급 저하를 피하기 위해 세심하게 최적화 될 수 있다. 텐서플로우(TensorFlow, TF)는 다양한 작업에 대해 데이터 흐름 프로그래밍을 위한 오픈소스 소프트웨어 라이브 러리이고, 텐서플로우 서빙(TensorFlow Serving, TFserving)은 프로덕션(production) 환경을 위한 유연하고(flexible), 고성능(high-performance)의 serving 시스템이다. 도 3은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 서빙 시스템의 구성 요소를 설명하기 위한 도면이 다. 상기 서빙 시스템은 도 3에 도시된 바와 같이 구성요소들이 포함될 수 있다. 여기서, 서버블(Servable)은 클라 이언트(CLIENT)가 계산을 수행하는데 사용하는 기본 object(perform computation)로, 학습 모델을 저장할 수 있으며, 4 개의 구성요소(component)의 중심을 의미할 수 있다. 그리고 로더(Loader)는 서버블(서버블 내 학습 모델)의 주기(life cycle)를 관리할 수 있으며, 매니저(manager)를 위한 임시 저장소(temporary storage for the manager)를 의미할 수 있다. 또한 소스(Source)는 서버블을 포함할 수 있으며, 게이트웨이 기능을 수행하여 로더로 올려주는 역할을 수행할 수 있고, 학습 모델의 다른 버전을 track 할 수 있다. 그리고 매니저(Manager) 는 전체 주기(full lifecycle)를 관리할 수 있다. 도 4는 본 개시의 일 실시 예에 따른 학습 모델 관리 장치를 개략적으로 나타낸 블록도이다. 도 4에 도시된 바와 같이, 학습 모델 관리 장치는 메모리, 통신부, 프로세서 및 사용자 인 터페이스를 포함할 수 있다. 메모리는 학습 모델 관리 장치의 동작에 필요한 각종 정보들을 저장하고, 학습 모델 관리 장치 를 동작시킬 수 있는 제어 소프트웨어를 저장할 수 있는 것으로, 휘발성 또는 비휘발성 기록 매체를 포함할 수 있다. 메모리는 하나 이상의 프로세서와 연결되는 것으로, 프로세서에 의해 실행될 때, 프로세서(13 0)로 하여금 학습 모델 관리 장치를 제어하도록 야기하는(cause) 코드들을 저장할 수 있다. 여기서, 메모리는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage medi a)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 이러한 메모리는 내장 메모리 및/ 또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD. CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 특히, 본 실시 예에서, 메모리에는 본 개시에 따른 신경망 모델, 예를 들어 딥러닝 모델을 이용하여 본 개 시의 다양할 실시 예를 구현할 수 있도록 구현된 모듈이 저장될 수 있다. 그리고, 메모리에는 본 개시에 따른 학습을 수행하기 위한 알고리즘에 관련된 정보가 저장될 수 있다. 그 밖에도 본 개시의 목적을 달성하기 위한 범위 내에서 필요한 다양한 정보가 메모리에 저장될 수 있으며, 메모리에 저장된 정보는 서버 또는 외부 장치로부터 수신되거나 사용자에 의해 입력됨에 따라 갱신될 수도 있다. 통신부는 네트워크와 연동하여 외부 장치(서버를 포함) 간의 송수신 신호를 패킷 데이터 형태로 제공 하는 데 필요한 통신 인터페이스를 제공할 수 있다. 특히 본 실시 예에서 통신부는 사용자 단말과의 통신이 가능하도록 할 수 있다. 또한 통신부는 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수 신하기 위해 필요한 하드웨어 및 소프트웨어를 포함하는 장치일 수 있다. 이러한 통신부는 각종 사물 지능 통신(IoT(internet of things), IoE(internet of everything), IoST(internet of small things) 등)을 지원할 수 있으며, M2M(machine to machine) 통신, V2X(vehicle to everything communication) 통신, D2D(device to device) 통신 등을 지원할 수 있다. 즉, 프로세서는 통신부를 통해 연결된 외부 장치로부터 각종 데이터 또는 정보를 수신할 수 있으며, 외부 장치로 각종 데이터 또는 정보를 전송할 수도 있다. 그리고, 통신부는 WiFi 모듈, Bluetooth 모듈, 무선 통신 모듈, 및 NFC 모듈 중 적어도 하나를 포함할 수도 있다. 한편, 프로세서는 학습 모델 관리 장치의 전반적인 동작을 제어할 수 있다. 구체적으로, 프로세서 는 상술한 바와 같은 메모리를 포함하는 학습 모델 관리 장치의 구성과 연결되며, 상술한 바와 같은 메모리에 저장된 적어도 하나의 명령을 실행하여 학습 모델 관리 장치의 동작을 전반적으로 제 어할 수 있다. 즉 프로세서는 운영체제 레벨 가상화(virtualization) 환경에서 개별 태스크(task)를 위한 가상 공간을 할 당하는 컨테이너를 기반으로, 인공지능 서비스 구축을 위한 사용자 인터페이스를 제공하는 실시간 분석 및 예측 을 위한 학습 모델 관리 장치에 있어서, 사용자 단말이 학습 모델 관리 장치에 접속하여 사용자 단말의 사용자 식별 정보가 획득되면 사용자 단말에 대한 개별 컨테이너를 할당할 수 있다. 이때 프 로세서는 사용자 단말로부터 액세스 요청을 수신하고, 액세스 요청한 사용자 단말에 대한 컨테 이너를 매칭하여 사용자 단말의 사용자 식별 정보를 기반으로 하는 컨테이너 접속 정보를 생성할 수 있다. 그리고 프로세서는 사용자 단말에 컨테이너 접속 정보를 제공하여, 사용자 단말이 할당된 컨테 이너에 접속할 수 있도록 할 수 있다. 또한 프로세서는 상기 생성된 컨테이너 내에서, 사용자 단말로부터 업로드 된 학습 모델 및 기 저장 된 학습 모델 중에서 사용자 단말로부터 요청된 학습 모델들을 기반으로 하는 학습 모델 목록을 생성할 수 있다. 이때, 프로세서는 학습 모델의 모델명, 학습 모델의 업로드 날짜 및 학습 모델의 현재 서빙 상태를 포함하여 학습 모델 목록을 생성할 수 있다. 한편 프로세서는 사용자 단말로부터 학습 모델이 업로드 되는 경우, 업로드 된 학습 모델의 포맷이 기 설정된 형식과 다르면 업로드 된 학습 모델의 포맷을 기 설정된 형식으로 변경할 수 있다. 프로세서는 생성된 학습 모델 목록의 각각의 학습 모델에 대해 서빙(serving) 실행 또는 중지 여부를 설 정할 수 있으며, 서빙 실행 학습 모델에, 기 수집되어 저장되었거나 수집되는 데이터를 적용하여 서빙 실행 학 습 모델 각각에 대한 예측 및 분석 결과 값을 출력할 수 있다. 이때 프로세서는 사용자 단말로부터 서빙 실행 학습 모델 중 적어도 하나 이상의 예측 및 분석을 위한 데이터, 모델명, 그래프 대분류 및 그래프 중 분류 항목에 대한 선택 정보를 획득하고, 획득한 선택 정보를 기반으로 하여 서빙 실행 학습 모델 중 적어도 하 나 이상의 예측 및 분석을 수행하여, 시각화된 결과를 출력할 수 있다. 또한 본 실시 예에서, 프로세서는 예를 들어, POST Request를 통하여 데이터 전송 및 예측 결과 확인이 가 능할 수 있다. 예를 들어, 서빙 컨테이너를 통한 서빙 실행 시 지정한 서버로 인풋 데이터를 전송한 후, 해당 인풋 데이터에 대한 예측 및 분석 결과 값을 반환 받을 수 있다. 그리고 프로세서는 사용자 단말에 할당된 컨테이너 내의 프로세스가 종료되면 사용자 단말에 할 당된 컨테이너를 삭제할 수 있다. 예를 들어, 사용자 단말에서 회원 탈퇴를 요청하는 경우, 컨테이너를 삭 제할 수 있다. 본 실시 예에서, 이미지는 예를 들어, Dockerfile로 만들어진 여러 레이어로 이루어져 있고 각 레이어는 읽기만 가능(Read-only)할 수 있다. 이미지를 가지고 새로운 컨테이너를 생성하면 읽고 쓸 수 있는 (Readable and Writable) 레이어가 추가되는데 이를 컨테이너 레이어(Container Layer)라고 할 수 있다. 컨테 이너를 가지고 작업을 수행할 때 생기는 변경 사항을 모두 컨테이너 레이어에 저장하고 읽을 때는 이미지에 변 경된 사항을 조합해서 데이터를 읽을 수 있다. 이때 컨테이너가 삭제되면 컨테이너 레이어도 사라지고 기존 이 미지는 변경되지 않고 유지될 수 있다. 또한 프로세서는 사용자 단말로부터 학습 모델 목록의 학습 모델 삭제가 요청되면, 학습 모델의 서빙 중지 여부를 확인하고, 학습 모델이 서빙 중지 상태인 경우, 사용자 단말로부터의 삭제 요청에 따른 학습 모델 삭제를 수행할 수 있다. 한편, 프로세서는 사용자 단말로부터 로그인 정보를 포함하는 로그인 요청을 수신할 수 있다. 이때 로그인 요청에 응답하여 사용자 단말의 인증을 수행해 관리자 단말(제 2 사용자 단말)로 판별되는 경우 컨 테이너가 할당된 모든 사용자 단말들의 학습 모델 목록을 제공하여 제 2 사용자 단말에서 전체적인 관리가 가능하도록 할 수 있다. 이러한 프로세서는 다양한 방식으로 구현될 수 있다. 예를 들어, 프로세서는 주문형 집적 회로 (Application Specific Integrated Circuit, ASIC), 임베디드 프로세서, 마이크로 프로세서, 하드웨어 컨트롤 로직, 하드웨어 유한 상태 기계(Hardware Finite State Machine, FSM), 디지털 신호 프로세서(Digital Signal Processor, DSP) 중 적어도 하나로 구현될 수 있다. 프로세서는 일종의 중앙처리장치로서 메모리에 탑재된 제어 소프트웨어를 구동하여 학습 모델 관리 장치 전체의 동작을 제어할 수 있다. 프로세서는 데이터를 처리할 수 있는 모든 종류의 장치를 포함 할 수 있다. 여기서, '프로세서(processor)'는, 예를 들어 프로그램 내에 포함된 코드 또는 명령어로 표현된 기 능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로세서(microprocessor), 중앙처리장치 (central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor),ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망 라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 본 실시 예에서 프로세서는 학습 모델 관리 장치가 최적의 분석 및 예측 결과를 출력하도록, 딥러닝 (Deep Learning) 등 머신 러닝(machine learning)을 수행할 수 있고, 메모리는, 머신 러닝에 사용되는 데 이터, 결과 데이터 등을 저장할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 구조를 설명하기 위해 개략적으로 나타낸 도면이며, 상술한 내용을 정리하면, 프로세서는 도 5에 도시된 바와 같이, 예측 지원 분석 플랫폼에서의 분석 프로파일 관리 모듈을 의미할 수 있으며, 분석 엔진을 통한 각각의 예측 모델에 대한 예측 및 분석 결과를 사용자 단말에 사용자 인터페이스(예를 들어, 대시보드)를 통해 제공할 수 있다. 사용자 인터페이스는 학습 모델 관리를 위해, 학습 모델 관리 장치에 적용되는 다양한 학습 모델들이 등록되고, 학습 모델 관리를 위한 사용자 요청 및 명령들이 입력되는 입력 인터페이스를 포함할 수 있다. 학습 모델은 사용자에 의해 등록되거나 기 저장되어 서버로부터 수신될 수 있다. 그리고 사용자 인터페이스는 학습 모델 관리 장치에서 수행된 결과(예를 들어, 시각화 데이터들)가 출력되는 출력 인터페이스를 포함할 수 있다. 예를 들어, 사용자가 위젯을 등록하는 경우, 분석 및 예측 결과가 등록된 설정에 따른 그래프 형태로 출력될 수 있다. 즉 사용자 인터페이스는 실시간 데이터 분석 및 예측 을 위한 사용자 요청 및 명령에 따른 결과를 출력할 수 있다. 이러한 사용자 인터페이스의 입력 인터페이스와 출력 인터페이스는 동일한 인터페이스에서 구현될 수 있으 며, 본 실시 예에서 약물 평가를 위해 제공되는 사용자 인터페이스의 구체적인 설명은 도 8 내지 도 16을 통해 후술하도록 한다. 한편, 도 6은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 전체적인 학습 모델 관리 과정을 개략적으로 나타낸 도면이며, 도 6을 참조하여 학습 모델 관리 장치의 실시간 데이터 분석 및 예측 과정에 대해 간략 히 설명하도록 한다. 도 6에 도시된 바와 같이, 학습 모델 관리 장치를 이용하는 사용자는 사용자와 관리자로 구분할 수 있으며, 사용자는 먼저 학습 모델 관리 장치에 접속하여 회원가입을 수행할 수 있다. 이때 본 실시 예에서 는, 사용자의 사용자 단말이 접속하여 회원가입을 요청하면 회원가입 프로세스를 수행할 수 있고, 해당 사 용자 단말에 할당된 컨테이너(독립 컨테이너)를 자동 생성 및 실행할 수 있다. 이때 생성되는 컨테이너의 이름은 회원가입을 수행한 사용자 단말의 사용자 식별 정보(예를 들어, 사용자 ID)에 기반하여 설정할 수 있다. 그리고 이러한 컨테이너는 컨테이너 안의 프로세스가 종료되면 자동으로 삭제될 수 있다. 또한 본 실시 예에서는, 서빙 컨테이너를 이용해서 저장된 학습 모델에 대한 REST API 추론 서버가 실행되도록 할 수 이다. 여기서, REST API 추론 서버는 일 실시 예이며, REST(Representational State Transfer)란 정보들 이 주고받아지는 데 있어서 개발자들 사이에 널리 쓰이는 일종의 형식으로, 자원을 URI(Uniform Resource Identifier)로 표시하고 해당 자원의 상태를 주고 받는 것을 의미할 수 있다. API(Application Programming Interface)란 소프트웨어가 다른 소프트웨어로부터 지정된 형식으로 요청, 명령을 받을 수 있는 수단을 의미할 수 있다. 즉 REST API는 REST 기반의 규칙들을 지켜서 설계된 API를 의미할 수 있다. 그리고 사전에 회원가입 된 사용자의 사용자 단말이 학습 모델 관리 장치에 접속하여 로그인 요청하 면, 본 실시 예에서는 분석 모델 등록, 분석 모델 조회 및 분석 모델 조회가 가능한 사용자 인터페이스를 제공할 수 있다. 또한 사용자 단말이 학습 모델 관리 장치에 접속하면, 본 실시 예에서는 위젯 조회 및 위젯 추가가 가능한 사용자 인터페이스가 제공되도록 할 수 있으며, 이는 설정에 따라 변경될 수 있다. 한편, 학습 모델 관리 장치에 접속한 사용자 단말의 사용자가 관리자인 경우, 본 실시 예에서는, 모 든 사용자에 대한 분석 모델 조회 및 분석 모델 관리가 가능하도록 사용자 인터페이스를 제공할 수 있다. 한편, 위젯(widget)은 이용자와 응용프로그램 및 운영체계와의 상호작용을 보다 원활하게 지원해주는 그래픽 유 저 인터페이스(GUI; 그래픽을 통해 작업할 수 있는 환경을 뜻하는 말로, 마우스를 이용하여 화면의 메뉴 중 하 나를 선택하여 작업하는 형태)를 의미하는 것으로, 특히 본 실시 예에서는, 실시간 데이터 분석 및 예측 결과를 사용자가 선택한 설정에 기반하여 시각화 출력하는 것을 의미할 수 있다. 본 실시 예에서는, 서빙 컨테이너에 학습 모델을 등록하기 위해, 학습 모델 관리 장치의 \"분석 모델 등록\" 기능을 통해 학습 모델을 등록할 수 있다. 예를 들어, Keras 기반 학습 모델을 업로드 하게 되면 TensorFlow 형식으로 포맷이 변경되어 서빙이 되도록 할 수 있다. 또한, 학습 모델에 대해, 업로드 하는 파일 형태는 압축파 일(.zip)이 가능할 수 있다. 그리고 학습 모델을 등록하면서, 등록하려는 학습 모델에 간단한 설명도 함께 등록 할 수 있다. 예를 들어, 사용자는 학습 모델을 다음 표 1과 같은 포맷을 이용하여 Zip파일로 압축하여 업로드를 진행할 수 있다. 표 1"}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "사용자 단말로부터의 압축파일(.zip) 업로드 시 압축된 파일은 사용자별 독립 컨테이너에 압축 해제될 수 있다. 압축 해제된 학습 모델이 예를 들어, 텐서플로우 모델 포맷(.pb)이 아닌 Keras의 모델 포맷(.h5)이면 텐 서플로우 모델 포맷으로 자동 변환될 수 있다. 또한, 본 실시 예에서는, 사용자 단말로부터 여러 개의 모델이 업로드 된 경우, 아래 표 2와 같이 .config 파일이 자동으로 수정되어 여러 개의 모델을 서빙할 수 있도록 할 수 있다. 이때 본 실시 예에서는, 서빙 컨테 이너에서 모델을 실행시키기 위해서는 .config파일이 학습 모델 변경 시마다 업데이트 되도록 해야 한다. 표 2"}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 7은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 아키텍처를 나타낸 예시도이다. 도 7을 참조하여 컨테이너 생성 및 분석 결과 출력 과정에 대해 보다 구체적으로 설명하면, 본 실시 예에서는, 오픈 paas(Platform as a Service)에서 제공되는 데이터의 연동을 위해서, 예를 들어, 도커 엔진을 사용하여 컨테이 너 단위의 카프카(kafka) 컨슈머(consumer)를 구동할 수 있다. 여기서 paas는 인터넷으로 컴퓨터 응용 프로그램 (어플리케이션) 설계, 개발 및 배포 등에 필요한 하드웨어(HW)와 소프트웨어(SW)를 제공하는 체계를 일컫는다. 그리고 paas는 '클라우드웨어(Cloudware)'로 부르기도 하며, 여럿이 한곳에 머무르지 않더라도 인터넷을 매개로 삼아 어플리케이션을 함께 개발할 수 있는 게 특징이다. 그리고 본 실시 예에서, 컨슈머는 오픈 paas에서 작동되는 카프카의 토픽 개수만큼 구동시키게 되며, 각 컨슈머 는 데이터를 받아 저장하고 있는 상태일 수 있다. 또한 본 실시 예에서는, 사용자가 해당 데이터와 데이터에 맞 는 학습 모델을 선택하여 위젯을 구성하게 될 경우, 상기 구성한 위젯 기반 데이터와 학습 모델에 대해, 사용자 별로 부여되어있는 실시간 데이터 분석 모듈(Analysis module)에 입력 값으로 전송할 수 있다. 이때 사용자는 자신이 선택한 데이터에 따른 실시간 분석 및 예측 결과를 대시보드 위젯에서 확인할 수 있다. 본 실시 예에서 는, 컨슈머를 오픈 paas 연동 기술로 정의할 수 있으며 개발된 연동 모듈은 이미지로 패키징하여 배포가 용이하 도록 할 수 있고, 외부 환경에서 실행시키고자 할 때 프로세스의 독립성을 높여서 리소스 분할을 통해 서비스가안정적으로 구동될 수 있도록 구현될 수 있다. 여기서, 카프카(아파치 카프카)는 일 실시 예로, 분산 스트리밍 플랫폼이며 데이터 파이프라인을 만들 때 주로 사용되는 오픈 소스 솔루션이다. 카프카는 대용량의 실시간 로그처리에 특화되어 있는 솔루션이며 데이터를 유 실 없이 안전하게 전달하는 것이 주 목적이다. 또한, 컨슈머는 메시지를 소비하는 주체이다. 해당 메시지의 topic을 구독함으로써, 스스로 데이터의 수신을 제 어 할 수 있다. 컨슈머는 해당 topic내의 각 파티션에 존재하는 offset의 위치를 통해서 이전에 가져왔던 offset 위치를 기억하고 관리해서, 컨슈머가 죽었다가 다시 살아나도, 전에 마지막으로 읽었던 위치에서부터 다 시 읽어 들일 수 있다. 한편, 예를 들어, 도커(Docker)를 이용한 패키징 및 배포에 대한 일련의 과정을 명령어 기반으로 보다 구체적으 로 살펴보면, 먼저 호스트OS 상에 도커를 설치하고, 컨테이너를 생성한다. 이때 컨테이너 생성을 위한 명령 어는 예를 들어, \"docker run t --rm name {토픽이름_consumer} -p {HOST PORT}:{CONTAINER PORT}\"와 같이 나 타낼 수 있다. 여기서 'rm' 옵션을 통해 컨테이너를 구동시킴으로써 컨테이너 안의 프로세스가 종료되면 컨테이 너를 자동으로 삭제하게 하여 사용자에게 이상이 있음을 알리고 새로운 컨테이너를 실행 할 수 있도록 할 수 있 다. 그리고 'name'을 통해 카프카 컨슈머가 구독할 토픽의 이름으로 컨테이너 이름을 설정할 수 있다. 그리고 '-p' 옵션을 사용하여 컨슈머로 데이터를 받아 WAS가 존재하는 호스트 OS로 데이터를 전송할 포트(예를 들어, -p 8081:3000)를 설정할 수 있다. 그리고 본 실시 예에서는, 컨테이너 생성 여부를 확인할 수 이으며 이때의 명령어는 예를 들어, 표 3과 같이 나타낼 수 있다. 표 3"}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "또한 본 실시 예에서는, 생성한 컨테이너에서 작업을 진행할 수 있다. 이때 개발한 컨슈머 모듈이 컨테이너 로 구동되었을 때 자동으로 실행 될 수 있도록 진입점(ENTRYPOINT)로 설정할 수 있다. 또한 본 실시 예에서는, 각기 다른 토픽을 구독하기 위해 argument로 옵션을 강제하여 사용자가 데이터를 선택했을 때 해당 데이터셋의 ID를 토픽으로 설정하여 구동될 수 있도록 설정할 수 있다. 다음으로, 본 실시 예에서는, 컨테이너의 현재 상태 이미지 파일을 생성하기 위해 docker commit을 사용할 수 있다. Docker commit은 간단히 설명하면 컨테이너의 변경 사항을 이미지 파일로 생성하는 명령어(예를 들어, \"$ docker commit <옵션> <컨테이너 이름> <이미지 이름\")를 의미할 수 있으며, 예를 들어 표 4와 같이 나타낼 수 있다. 표 4"}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "또한 본 실시 예에서는, 예를 들어, \"$ docker images\"와 같은 명령어를 통해 이미지 생성 여부를 확인할 수 있으며, 예를 들어, 표 5와 같이 나타낼 수 있다. 표 5 그리고 본 실시 예에서는, 이미지 빌드를 하기 위하여 도커 로그인을 진행할 수 있으며, 이때 예를 들어, GitHub와 동일하게 DockerHub에 회원가입 후 로그인을 진행할 수 있고, 명령어는 예를 들어 \" $ docker logi n\"와 같이 나타낼 수 있다. 다음으로 본 실시 예에서는, 이미지를 푸시(Push)할 수 있으며, 예를 들어, \"$ docker push <Docker 레지스 트리URL>/<이미지 이름>:<태그>\"와 같은 명령어를 사용할 수 있다. 즉 본 실시 예에서는, 이미지를 생성을 통해 다른 외부 환경에 배포 시 용이하도록 컨테이너를 패키징 할 수 있다. 이는 예를 들어 표 6과 같이 나타낼 수 있다. 표 6"}
{"patent_id": "10-2020-0167753", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 7, "content": "도 8 내지 도 16은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 사용자 인터페이스를 나타낸 예시도이 다. 도 8은 사용자 인터페이스 중 로그인 화면을 나타내는 것으로, 학습 모델 관리 어플리케이션 및/또는 학습 모델 관리 사이트 접속 시 초기 화면(①)을 도시한 것이다. 이때 사용자는 회원가입 기능(②)을 선택 요청하여 회원가입을 수행할 수 있고, 프로세서는 사용자 단말로부터 회원가입이 요청되면 회원가입 페이지로 이동할 수 있도록 화면을 전환시킬 수 있다. 사전에 회원가입을 수행한 사용자인 경우에는, 회원가입 시 입력한 아이디와 비밀번호를 입력하고(③), 로그인을 요청할 수 있다(④). 이때 프로세서는 사용자 단말로부 터의 로그인 요청 시 등록된 회원가입 정보(또는 사용자 식별 정보)와 비교하여, 일치하지 않거나 등록되지 않 은 회원이라고 판단되면 회원가입을 요청하고 회원가입 화면으로 전환되도록 할 수 있다. 한편, 프로세서 는 사용자로 등록된 제 1 사용자 단말로부터 로그인이 요청되면 '메인 대시보드 화면'으로 전환할 수 있고, 관리자로 등록된 제 2 사용자 단말로부터 로그인이 요청되면 '전체 사용자 모델 관리 화면'으로 이 동하도록 화면을 전환할 수 있다. 이때 관리자 확인 여부는 사용자 식별 정보에 기반하여 확인 가능하거나 /admin으로 접속하는지 여부에 따라 확인 가능할 수 있다. 도 9는 사용자 인터페이스 중 회원가입을 할 수 있는 사용자 회원가입 화면(①)을 도시한 것이다. 이때 사 용자는 사용자 단말을 통해 아이디, 비밀번호 등 회원가입에 필요한 정보를 입력하고(②), 로그인을 요청 할 수 있다(③). 프로세서는 사용자 단말로부터 회원가입 정보가 입력되면 사용자별로 저장하고 관리 할 수 있으며, 회원가입 정보 입력 후 사용자가 로그인을 요청하면 회원가입 수행 후 로그인이 바로 수행될 수 있도록 로그인 화면(도 8 참조)으로 전환할 수 있다. 한편, 본 실시 예에서는, 사용자 단말로부터 업로드 되는 학습 모델을 등록할 수 있다. 도 10은 사용자 인 터페이스 중 학습 모델을 등록할 수 있는 모델 등록 화면(①)을 도시한 것이다. 이때 사용자는 사용자 단 말을 통해 모델을 선택하여 사용자 학습 모델을 업로드 할 수 있으며(②), 학습 모델 업로드와 함께 학습 모델에 대한 설명을 기입하여 등록할 수 있다(③). 프로세서는 사용자 단말로부터의 학습 모델 업로 드와 학습 모델 설명 기입이 완료되면, 모델 파일, 모델 이름 및 모델 설명 등을 등록할 수 있다(④). 이때 백 엔드(backend)에는 .config 파일이 생성 및 수정될 수 있다. 그리고 본 실시 예에서는, 사용자 단말로부터 업로드 된 학습 모델뿐만 아니라 기 저장된 학습 모델 중에 서, 사용자 단말로부터 데이터 분석을 위해 선택 요청된 학습 모델들을 기반으로 하여 학습 모델 목록을 생성할 수 있다. 도 11은 사용자 인터페이스 중 학습 모델 목록을 제공하는 사용자 본인의 모델을 관리하 는 모델 목록 화면(①)을 도시한 것이다. 프로세서는 모델 목록 화면에서 사용자 단말로부터 모델 등 록 기능이 선택 요청되면 학습 모델 등록을 위해 모델 등록 화면(도 10 참조)으로 전환할 수 있다. 또한, 프로세서는 모델 목록 화면에서 사용자 단말로부터 특정 학습 모델이 선택되어 삭제 요청(③) 되면, 선택된 학습 모델의 삭제를 수행할 수 있다. 예를 들어, 좌측 체크박스를 체크한 뒤 '삭제' 버튼을 누르게 되면 모델을 삭제할 수 있다. 이때 본 실시 예에서는, 현재 상태가 중지 상태인 학습 모델만 삭제를 수행할 수 있으며, 사용자 단말로부터 실행 중인 학습 모델에 대해 삭제가 요청된 경우, 팝업창(예를 들어, \"모델 중지 후 삭제할 수 있습니다\")을 출력할 수 있다. 그리고 모델 목록 화면에는 로그인한 사용자가 등록한 모델들이 모두 표시될 수 있으며(④), 사용자 ID, 모델 이름, 신청일, 현재 상태 등이 함께 표시될 수 있다. 또한 본 실시 예에서는, 사용자가 모델 목록 화면에서 모 델 상태를 관리할 수 있는데(⑤), 학습 모델의 서빙 실행 및 중지를 설정 및 변경할 수 있다. 즉 현재 학습 모 델의 서빙 상태가 실행 중인 경우, 중지 상태로의 변경 요청이 가능하고, 현재 학습 모델의 서빙 상태가 중지인 경우, 실행 상태로의 변경 요청이 가능할 수 있다. 또한, 본 실시 예의 모델 목록 화면에서, 사용자가 모델명을 선택하면(⑥), 프로세서는 선택된 학습 모델 에 대한 상세보기 화면(도 12 참조)으로 전환하여, 해당 학습 모델에 대한 상세정보를 조회 가능하도록 할 수 있다. 상세정보는 예를 들어, 해당 모델의 모델명, 파일명, 모델 설명 등을 포함할 수 있다. 즉 도 12는 사용자 인터페이스 중 각각의 학습 모델에 대한 상세정보를 조회할 수 있는 모델 관리 화면(①)을 도시한 것이다. 사용자가 사용자 단말을 통해 자신의 등록 학습 모델들의 관리 및 상세정보 확 인을 수행할 수 있다. 그리고 사용자가 '목록'을 선택 요청하면(②), 프로세서는 모델 목록 화면(도 11 참 조)으로 전환할 수 있다. 도 13은 사용자 인터페이스 중 위젯 등록을 위한 설정을 할 수 있는 위젯 등록 화면(①)을 도시한 것이다. 본 실시 예에서, 사용자는 사용자 단말을 통해 실시간 분석하고자 하는 데이터를 선택하고(②), 학습 모델 을 선택한 후(③), 그래프의 대분류 종류(④) 및 중분류 종류(⑤)를 선택하고, '등록' 버튼을 눌러 위젯을 등록 할 수 있다(⑥). 프로세서는 사용자 단말로부터 설정된 값을 토대로 위젯을 등록할 수 있다. 도 14는 데이터 실시간 분석 대시보드를 출력하는 메인 대시보드 화면(①)을 도시한 것이다. 즉 본 실시 예에서 는 예측 및 분석 결과 값을 대시보드 위젯을 통해 확인할 수 있다. 사용자가 '대시보드' 버튼을 선택하면(②), 프로세서는 메인 대시보드 화면이 출력되도록 할 수 있다. 그리고 사용자가 '나의 모델 관리' 버튼을 선택 하면(③), 프로세서는 모델 목록 화면(도 11 참조)으로 전환할 수 있다. 또한 사용자가 '로그아웃' 버튼을 선택하면(④), 프로세서는 로그인 화면(도 8 참조)으로 전환할 수 있고, 사용자가 '위젯등록' 버튼을 선택 하면(⑤), 프로세서는 위젯 등록 화면(도 13 참조)으로 전환할 수 있다. 이때 위젯 등록 화면은 팝업 형태 로 출력될 수 있다. 즉 본 실시 예에서는, 위젯 등록 화면에서 등록된 위젯 설정에 따라 데이터에 대한 실시간 분석 및 예측 결과가 시각화되어 위젯으로 출력될 수 있다(⑥). 한편, 도 15 및 도 16은 관리자에 대해 제공하는 사용자 인터페이스를 나타내는 것으로, 도 15는 전체 사 용자 모델 관리 화면(①)을 도시한 것이다. 본 실시 예에서는, 관리자가 '로그아웃' 버튼을 선택하면(②), 프로 세서는 로그아웃을 수행하여 로그인 화면(도 8 참조)으로 전환할 수 있다. 그리고 관리자가 특정 학습 모 델의 상세 조회를 위해 모델명을 선택하면, 프로세서는 학습 모델 상세 조회를 위한 전체 사용자 모델 상 세관리 화면(도 16 참조)으로 전환할 수 있다. 또한 관리자가 '관리' 버튼을 선택하면(④), 프로세서는 해 당 모델에 대한 중지 및 실행 여부 선택이 가능한 팝업창을 출력할 수 있다. 도 16은 전체 사용자 모델 상세관리 화면(①)을 도시한 것이다. 본 실시 예에서는, 전체 사용자 모델 상세관리 화면에서 관리자가 상세 조회를 위해 선택 요청한 모델에 대한 모델명, 모델 설명 등을 출력할 수 있다. 그리고 전체 사용자 모델 상세관리 화면에서, 관리자가 '목록' 버튼을 선택하면, 프로세서는 전체 사용자 모델 관 리 화면(도 15 참조)으로 전환할 수 있다. 도 17은 본 개시의 일 실시 예에 따른 학습 모델 관리 방법을 설명하기 위한 흐름도이다. 도 17에 도시된 바와 같이, S100단계에서, 학습 모델 관리 장치는 사용자 단말이 학습 모델 관리 장 치에 접속하여 사용자 단말의 사용자 식별 정보가 획득되면 사용자 단말에 대한 개별 컨테이너 를 할당한다. 이때 학습 모델 관리 장치는 사용자 단말로부터 액세스 요청을 수신하고, 액세스 요청한 사용자 단말 에 대한 컨테이너를 매칭하여 사용자 단말의 사용자 식별 정보를 기반으로 하는 컨테이너 접속 정보 를 생성할 수 있다. 그리고 학습 모델 관리 장치는 사용자 단말에 컨테이너 접속 정보를 제공하여, 사용자 단말이 할당된 컨테이너에 접속할 수 있도록 할 수 있다. 또한, 본 실시 예에서는, 학습 모델 관리 장치를 이용하는 사용자는 사용자와 관리자로 구분할 수 있으며, 사용자는 먼저 학습 모델 관리 장치에 접속하여 회원가입을 수행할 수 있다. 이때 본 실시 예에서는, 사용 자의 사용자 단말이 접속하여 회원가입을 요청하면 회원가입 프로세스를 수행할 수 있고, 해당 사용자 단 말에 할당된 컨테이너(독립 컨테이너)를 자동 생성 및 실행할 수 있다. 이때 생성되는 컨테이너의 이름은 회원가입을 수행한 사용자 단말의 사용자 식별 정보(예를 들어, 사용자 ID)에 기반하여 설정할 수 있다. 그리고 이러한 컨테이너는 컨테이너 안의 프로세스가 종료되면 자동으로 삭제될 수 있다. S200단계에서, 학습 모델 관리 장치는 생성된 컨테이너 내에서, 사용자 단말로부터 업로드 된 학습 모델 및 기 저장된 학습 모델 중 사용자 단말로부터 요청된 학습 모델 기반 학습 모델 목록을 생성한다. 본 실시 예에서는, 생성된 학습 모델 목록을 사용자 인터페이스를 통해 제공하여, 사용자가 학습 모델에 대해 서빙 실행 또는 중지 여부를 설정하고, 학습 모델들의 관리 및 상세 정보 확인이 가능하도록 할 수 있으며, 또한 학습 모델의 삭제가 가능하도록 할 수 있다. S300단계에서, 학습 모델 관리 장치는 생성된 학습 모델 목록의 각각의 학습 모델에 대해 서빙(serving) 실행 또는 중지 여부를 설정한다. 즉 본 실시 예에서는, 서빙 실행 또는 중지 여부 설정을 통해, 딥러닝 모델에 대한 서비스가 수행되거나 중지되 도록 할 수 있다. 서빙은 딥러닝 모델 추론(inference) 서비스 구현을 위한 것으로, 학습 모델의 버전 관리, 가 지치기(Pruning)와 양자화(Quantization) 등의 모델 경량화 및 최적화, 및 Request 처리를 위한 세션과 스레드 (thread) 관리 등이 가능하도록 할 수 있다. 예를 들어, 서빙 실행을 위해서는 Dockerfile을 작성하고 선택된 모델에 대해 이미지를 생성 및 실행한 후 추론 테스트를 수행할 수 있다. S400단계에서, 학습 모델 관리 장치는 학습 모델 목록 내 서빙 실행 학습 모델에, 기 수집되어 저장되거나 수집되는 데이터를 적용하여 서빙 실행 학습 모델 각각에 대한 예측 및 분석 결과 값을 출력한다. 이때 학습 모델 관리 장치는 사용자 단말로부터 서빙 실행 학습 모델 중 적어도 하나 이상의 예측 및 분석을 위한 데이터, 모델명, 그래프 대분류 및 그래프 중분류 항목에 대한 선택 정보를 획득하고, 획득한 선택 정보를 기반으로 하여 서빙 실행 학습 모델 중 적어도 하나 이상의 예측 및 분석을 수행할 수 있다. 그리고 본 실시 예에서는, 예를 들어, 사용자 인터페이스를 통해 사용자로부터 위젯 등록에 대한 설정을 입력받아, 설정된 값을 토대로 위젯을 생성 및 출력할 수 있다. 즉 실시간 데이터 분석 및 예측 결과에 대해 시각화하여 제공할 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값 을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2020-0167753", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 실시간 분석 및 예측을 위한 학습 모델 관리 시스템 환경을 설명하기 위한 예시도이다. 도 2는 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 컨테이너 시스템에 대해 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 서빙 시스템의 구성 요소를 설명하기 위한 도면이 다. 도 4는 본 개시의 일 실시 예에 따른 학습 모델 관리 장치를 개략적으로 나타낸 블록도이다. 도 5는 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 구조를 설명하기 위해 개략적으로 나타낸 도면이다. 도 6은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 전체적인 학습 모델 관리 과정을 개략적으로 나타 낸 도면이다. 도 7은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 아키텍처를 나타낸 예시도이다. 도 8 내지 도 16은 본 개시의 일 실시 예에 따른 학습 모델 관리 장치의 사용자 인터페이스를 나타낸 예시도이 다. 도 17은 본 개시의 일 실시 예에 따른 학습 모델 관리 방법을 설명하기 위한 흐름도이다."}
