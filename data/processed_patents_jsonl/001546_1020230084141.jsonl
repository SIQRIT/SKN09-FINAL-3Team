{"patent_id": "10-2023-0084141", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0001657", "출원번호": "10-2023-0084141", "발명의 명칭": "딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템", "출원인": "주식회사 디디에스", "발명자": "이중수"}}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "콘솔 디바이스의 적어도 하나의 프로세서가 실행하는 구강스캔 애플리케이션이 딥러닝을 기초로 라벨링된 3차원구강모델을 제공하는 방법으로서, 스캔 대상객체 및 스캔 제외객체 중 적어도 하나를 설정하는 단계; 구강 스캐너와 연동하여 소정의 구강 이미지를 획득하는 단계; 상기 구강 이미지를 기초로 시멘틱 세그멘테이션(Semantic segmentation)을 수행한 이미지인 라벨링 이미지를획득하는 단계; 상기 라벨링 이미지 내 상기 스캔 대상객체를 포함하고 상기 스캔 제외객체를 제거한 이미지인 모델링 이미지를획득하는 단계; 및 상기 모델링 이미지를 기초로 소정의 구강정보를 포함하는 3차원 구강모델인 3차원 라벨링 구강모델을 제공하는단계를 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 구강정보는, 소정의 구강 내 피사체가 포함하는 각각의 객체에 대한 경계선을 특정하는 엣지 정보와, 상기 각각의 객체에 대한 속성을 특정하는 라벨링 정보를 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 라벨링 이미지는, 상기 구강 이미지 내 각각의 객체를 물리적 의미 단위로 구분하고 라벨링한 정보를 포함하는 이미지인 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 라벨링 이미지를 획득하는 단계는, 기 학습된 시멘틱 세그멘테이션 딥러닝 모델에 상기 구강 이미지를 입력하는 단계와, 상기 구강 이미지를 입력한 딥러닝 모델로부터 상기 라벨링 이미지를 획득하는 단계를 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 상기 모델링 이미지를 획득하는 단계는, 상기 라벨링 이미지 내 각각의 객체별 라벨링 정보와 상기 스캔 대상객체를 비교하는 단계와, 상기 라벨링 이미공개특허 10-2025-0001657-3-지 내 각각의 객체별 라벨링 정보와 상기 스캔 제외객체를 비교하는 단계 중 적어도 하나의 단계를 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 모델링 이미지를 획득하는 단계는, 상기 라벨링 이미지 상에서 상기 스캔 제외객체와 대응되는 라벨링 정보를 가지는 객체를 제거하는 단계를 더포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서, 상기 3차원 라벨링 구강모델을 제공하는 단계는, 상기 모델링 이미지에 기초한 구강정보를 포함하는 상기 3차원 라벨링 구강모델을 생성하는 단계와, 상기 생성된 3차원 라벨링 구강모델 내 각각의 객체별 구강정보를 제공하는 단계를 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서, 소정의 관심영역은 상대적 고해상도로 표시하고 상기 관심영역 이외의 나머지 영역은 상대적 저해상도로 표시하는 상기 3차원 라벨링 구강모델인 3차원 라벨링 복합해상도 구강모델을 제공하는 단계를 더 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서, 상기 3차원 라벨링 복합해상도 구강모델을 제공하는 단계는, 상기 관심영역에 대응되는 라벨링 정보인 관심 라벨정보를 획득하는 단계와, 상기 구강 스캐너와 연동하여 소정의 구강 이미지를 획득하는 단계와, 상기 구강 이미지를 기초로 시멘틱 세그멘테이션(Semantic segmentation)을 수행한 이미지인 라벨링 이미지를획득하는 단계와, 상기 라벨링 이미지에 기초한 구강정보를 포함하는 상기 3차원 라벨링 구강모델을 획득하는 단계와, 상기 3차원 라벨링 구강모델 내 각각의 객체별 라벨링 정보와 상기 관심 라벨정보를 비교하는 단계와, 상기 3차원 라벨링 구강모델 상에서 상기 관심 라벨정보와 대응되는 라벨링 정보를 가지는 객체를 검출하는 단계와, 상기 검출된 객체가 포함하는 영역을 상기 관심영역으로 설정하는 단계를 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법."}
{"patent_id": "10-2023-0084141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "구강스캔 애플리케이션이 저장된 적어도 하나의 메모리; 및 상기 메모리에 저장된 구강스캔 애플리케이션을 독출하여 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는적어도 하나의 프로세서;를 포함하고, 공개특허 10-2025-0001657-4-상기 구강스캔 애플리케이션의 명령어는, 스캔 대상객체 및 스캔 제외객체 중 적어도 하나를 설정하는 단계와, 구강 스캐너와 연동하여 소정의 구강 이미지를 획득하는 단계와, 상기 구강 이미지를 기초로 시멘틱 세그멘테이션(Semantic segmentation)을 수행한 이미지인 라벨링 이미지를획득하는 단계와, 상기 라벨링 이미지 내 상기 스캔 대상객체를 포함하고 상기 스캔 제외객체를 제거한 이미지인 모델링 이미지를획득하는 단계와, 상기 모델링 이미지를 기초로 소정의 구강정보를 포함하는 3차원 구강모델인 3차원 라벨링 구강모델을 제공하는단계를 수행하는 명령어를 포함하는 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 시스템."}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법은, 콘솔 디바이스의 적어도 하나 의 프로세서가 실행하는 구강스캔 애플리케이션이 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는 방법으 로서, 스캔 대상객체 및 스캔 제외객체 중 적어도 하나를 설정하는 단계; 구강 스캐너와 연동하여 소정의 구강 이미지를 획득하는 단계; 상기 구강 이미지를 기초로 시멘틱 세그멘테이션(Semantic segmentation)을 수행한 이 미지인 라벨링 이미지를 획득하는 단계; 상기 라벨링 이미지 내 상기 스캔 대상객체를 포함하고 상기 스캔 제외 객체를 제거한 이미지인 모델링 이미지를 획득하는 단계; 및 상기 모델링 이미지를 기초로 소정의 구강정보를 포 함하는 3차원 구강모델인 3차원 라벨링 구강모델을 제공하는 단계를 포함한다."}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템에 관한 것이다. 보다 상세하게는, 학 습된 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하여 2차원 구강 이미지 내 객체를 라벨링하 고, 라벨링된 객체 중 적어도 일부를 기초로 3차원 구강모델을 제공하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 환자의 구강 정보를 획득하기 위한 방법으로, 환자의 구강에 삽입하여 구강 내의 이미지를 획득하는 구강 스캐너가 이용되고 있다. 구강 스캐너는 일련의 스캐닝 시퀀스(Scanning Sequence)를 통해 대상 물체(구강내부, 치아, 치열)에 대한 다수 의 광학 이미지를 획득하고, 획득된 이미지를 이용하여 3차원 모델 데이터를 생성하는 3차원 스캐너의 일종이다. 구강 스캐너는 이러한 3차원 스캐너 중에서 신체 일부, 특히 치아와 잇몸 등 구강 내부의 구조물에 대한 일련의 광학 이미지를 획득하기에 적합하도록 구성된 장치를 말한다. 3차원 모델 데이터를 제공하기 위해 구강 스캐너를 통해 광학 이미지를 획득하는 방식의 일 예로 액티브 스테레 오 비전(active stereo vision) 방식이 있는데, 미리 알려진 패턴광(patterned light)을 치아 표면에 조사하고, 조사된 패턴을 두 개 또는 그 이상의 광학 카메라로 촬영하여 다수의 광학 이미지를 획득하는 방식이 다. 다른 예로 삼각측량(triangulation) 방식이 있는데, 구조광(structural light)을 치아 표면에 조사하고, 그 이 미지를 하나 또는 그 이상의 광학 카메라로 촬영하여 다수의 광학 이미지를 획득하는 방식이다. 이러한 두 방식은 모두 광의 패턴이 치아 등의 구강 내부 표면에 선명하게 도달되어야 헤이즈(haze) 현상 없이 선명한 광학 이미지와 3차원 모델 데이터를 획득할 수 있다. 유저들은 위와 같은 구강 스캐너를 이용하여 환자의 구강을 스캔함으로써 상악 스캔 데이터, 하악 스캔 데이터 및 상악과 하악의 교합 스캔 데이터 등을 획득할 수 있다. 그리고 획득된 스캔 데이터를 이용하여 3차원 가상 모델을 생성하고, 생성된 3차원 가상 모델을 이용하여 치아 의 치료나 교정 등을 진행할 수 있다. 이때, 3차원 가상 모델은 구강 내 특정한 치아 등과 같이 유저가 원하는 구강 내 오브젝트를 삼차원적으로 구현 하는 것이므로, 3차원 가상 모델에는 유저가 원하는 오브젝트 이외의 외부 물질(foreign object)이 포함되지 않 도록 처리하는 것이 중요하다. 또한 구강 내에서 치아 이외에 특정한 재질로 된 치료 보조 장치 등은 구강 스캐너에 의해 스캔 시 치아만큼 정 확한 데이터를 획득하기 어려울 수 있는데, 이와 같이 특정한 재질로 된 치료 보조 장치를 포함하거나, 또는 유 저가 특히 소상한 스캔 데이터를 원하는 오브젝트에 대해서는 보다 정확한 스캔 데이터를 획득하는 것이 요구될수 있다. 이를 위해 3차원 가상 모델 처리 시 유저가 원하는 오브젝트 이외의 외부 물질(foreign object)을 포함하지 않 도록 또는 특정한 오브젝트에 대해서는 좀더 정확한 이미지 처리가 될 수 있도록 3차원 가상 모델을 구현하기 위한 방안이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2269897 B1"}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 학습된 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하여 2차원 구강 이미지 내 객 체를 라벨링하고, 라벨링된 객체 중 적어도 일부를 기초로 3차원 구강모델을 제공하는 방법 및 시스템을 구현하 고자 한다. 또한 본 발명은, 딥러닝을 기초로 3차원 구강모델 내 각각의 객체 영역을 의미 있는 단위로 자동 구분하고, 구 분된 객체 영역별로 대응되는 구강정보를 제공하는 3차원 구강모델 제공 방법 및 시스템을 구현하고자 한다. 다만, 본 발명 및 본 발명의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되 지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법은, 콘솔 디바이스의 적어도 하나 의 프로세서가 실행하는 구강스캔 애플리케이션이 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는 방법으 로서, 스캔 대상객체 및 스캔 제외객체 중 적어도 하나를 설정하는 단계; 구강 스캐너와 연동하여 소정의 구강 이미지를 획득하는 단계; 상기 구강 이미지를 기초로 시멘틱 세그멘테이션(Semantic segmentation)을 수행한 이미지인 라벨링 이미지를 획득하는 단계; 상기 라벨링 이미지 내 상기 스캔 대상객체를 포함하고 상기 스캔 제 외객체를 제거한 이미지인 모델링 이미지를 획득하는 단계; 및 상기 모델링 이미지를 기초로 소정의 구강정보를 포함하는 3차원 구강모델인 3차원 라벨링 구강모델을 제공하는 단계를 포함한다. 다른 측면에서, 상기 구강정보는, 소정의 구강 내 피사체가 포함하는 각각의 객체에 대한 경계선을 특정하는 엣 지 정보와, 상기 각각의 객체에 대한 속성을 특정하는 라벨링 정보를 포함한다. 다른 측면에서, 상기 라벨링 이미지는, 상기 구강 이미지 내 각각의 객체를 물리적 의미 단위로 구분하고 라벨 링한 정보를 포함하는 이미지이다. 다른 측면에서, 상기 라벨링 이미지를 획득하는 단계는, 기 학습된 시멘틱 세그멘테이션 딥러닝 모델에 상기 구 강 이미지를 입력하는 단계와, 상기 구강 이미지를 입력한 딥러닝 모델로부터 상기 라벨링 이미지를 획득하는 단계를 포함한다. 다른 측면에서, 상기 모델링 이미지를 획득하는 단계는, 상기 라벨링 이미지 내 각각의 객체별 라벨링 정보와 상기 스캔 대상객체를 비교하는 단계와, 상기 라벨링 이미지 내 각각의 객체별 라벨링 정보와 상기 스캔 제외객 체를 비교하는 단계 중 적어도 하나의 단계를 포함한다. 다른 측면에서, 상기 모델링 이미지를 획득하는 단계는, 상기 라벨링 이미지 상에서 상기 스캔 제외객체와 대응 되는 라벨링 정보를 가지는 객체를 제거하는 단계를 더 포함한다. 다른 측면에서, 상기 3차원 라벨링 구강모델을 제공하는 단계는, 상기 모델링 이미지에 기초한 구강정보를 포함 하는 상기 3차원 라벨링 구강모델을 생성하는 단계와, 상기 생성된 3차원 라벨링 구강모델 내 각각의 객체별 구 강정보를 제공하는 단계를 포함한다. 다른 측면에서, 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법은, 소정의 관심 영역은 상대적 고해상도로 표시하고 상기 관심영역 이외의 나머지 영역은 상대적 저해상도로 표시하는 상기 3차 원 라벨링 구강모델인 3차원 라벨링 복합해상도 구강모델을 제공하는 단계를 더 포함한다. 다른 측면에서, 상기 3차원 라벨링 복합해상도 구강모델을 제공하는 단계는, 상기 관심영역에 대응되는 라벨링 정보인 관심 라벨정보를 획득하는 단계와, 상기 구강 스캐너와 연동하여 소정의 구강 이미지를 획득하는 단계와, 상기 구강 이미지를 기초로 시멘틱 세그멘테이션(Semantic segmentation)을 수행한 이미지인 라벨링 이미지를 획득하는 단계와, 상기 라벨링 이미지에 기초한 구강정보를 포함하는 상기 3차원 라벨링 구강모델을 획득하는 단계와, 상기 3차원 라벨링 구강모델 내 각각의 객체별 라벨링 정보와 상기 관심 라벨정보를 비교하는 단계와, 상기 3차원 라벨링 구강모델 상에서 상기 관심 라벨정보와 대응되는 라벨링 정보를 가지는 객체를 검출 하는 단계와, 상기 검출된 객체가 포함하는 영역을 상기 관심영역으로 설정하는 단계를 포함한다. 한편, 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 시스템은, 구강스캔 애플리케이 션이 저장된 적어도 하나의 메모리; 및 상기 메모리에 저장된 구강스캔 애플리케이션을 독출하여 딥러닝을 기초 로 라벨링된 3차원 구강모델을 제공하는 적어도 하나의 프로세서;를 포함하고, 상기 구강스캔 애플리케이션의 명령어는, 스캔 대상객체 및 스캔 제외객체 중 적어도 하나를 설정하는 단계와, 구강 스캐너와 연동하여 소정의 구강 이미지를 획득하는 단계와, 상기 구강 이미지를 기초로 시멘틱 세그멘테이션(Semantic segmentation)을 수행한 이미지인 라벨링 이미지를 획득하는 단계와, 상기 라벨링 이미지 내 상기 스캔 대상객체를 포함하고 상 기 스캔 제외객체를 제거한 이미지인 모델링 이미지를 획득하는 단계와, 상기 모델링 이미지를 기초로 소정의 구강정보를 포함하는 3차원 구강모델인 3차원 라벨링 구강모델을 제공하는 단계를 수행하는 명령어를 포함한다."}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템은, 학습된 딥러닝 뉴 럴 네트워크(Deep-learning Neural Network)를 이용하여 2차원 구강 이미지 내 객체를 라벨링하고, 라벨링된 객 체 중 적어도 일부를 기초로 3차원 구강모델을 제공함으로써, 2차원 구강 이미지 내 유저가 스캔하고자 하는 대 상을 기계적 알고리즘을 이용해 자동 선별할 수 있고, 선별된 스캔 대상에 특화된 3차원 구강모델을 생성해 제 공할 수 있다. 따라서 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템은, 유저 니즈 (needs) 맞춤형의 3차원 구강모델을 자동화된 방식으로 빠르고 간편하게 높은 정확도로 구축하여 제공할 수 있 는 효과가 있다. 또한, 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템은, 딥러닝을 기 초로 3차원 구강모델 내 각각의 객체 영역을 의미 있는 단위로 자동 구분하고, 구분된 객체 영역별로 대응되는 구강정보를 제공함으로써, 제공되는 3차원 구강모델 내 각각의 객체를 보다 직관적으로 용이하게 파악할 수 있 는 유저 인터페이스를 구현할 수 있는 효과가 있다. 다만, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효 과들은 아래의 기재로부터 명확하게 이해될 수 있다."}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적 인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별하는 목적으로 사용되었다. 또한, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 포함하다 또는 가지다 등의 용어는 명 세서상에 기재된 특징, 또는 구성요소가 존재함을 의미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 또한, 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나 타내었으므로, 본 발명이 반드시 도시된 바에 한정되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는 시스템의 개념도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는 시스템(1000: 이하, 3차원 구강모델 제공 시스템)은, 학습된 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하 여 2차원 구강 이미지 내 객체를 라벨링하고, 라벨링된 객체 중 적어도 일부를 기초로 3차원 구강모델을 제공하 는 3차원 구강모델 제공 서비스를 구현할 수 있다. 실시예에서, 3차원 구강모델 제공 서비스를 구현하는 3차원 구강모델 제공 시스템은, 콘솔 디바이스 , 구강 스캐너 및 네트워크(300: Network)를 포함할 수 있다. 이때, 콘솔 디바이스 및 구강 스캐너는, 네트워크를 통하여 연결될 수 있다. 여기서, 실시예에 따른 네트워크는, 콘솔 디바이스 및/또는 구강 스캐너 등과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것이다. 네트워크의 일례로는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크 및/또는 DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 이하, 첨부된 도면을 참조하여 3차원 구강모델 제공 시스템을 구현하는 콘솔 디바이스 및 구강 스캐 너에 대해 상세히 설명한다. - 콘솔 디바이스(100: Console Device) 본 발명의 실시예에 따른 콘솔 디바이스는, 3차원 구강모델 제공 서비스를 제공하는 구강스캔 애플리케이 션(이하, 애플리케이션)이 설치된 소정의 컴퓨팅 디바이스일 수 있다. 이때, 실시예에 따른 3차원 구강모델 제공 서비스는, 3차원 구강모델 생성을 위하여 구강을 스캔할 시 구강 내 제1 영역을 고해상도로 스캔하고 나머지 제2 영역을 상대적 저해상도로 스캔하여 생성한 3차원 구강모델을 제공 하는 서비스를 더 포함할 수 있다. 자세히, 하드웨어적 관점에서 콘솔 디바이스는, 애플리케이션이 설치된 모바일 타입 컴퓨팅 장치(100-1) 및/또는 데스크탑 타입 컴퓨팅 장치(100-2) 등을 포함할 수 있다. 여기서, 모바일 타입 컴퓨팅 장치(100-1)는, 애플리케이션이 설치된 모바일 장치일 수 있다. 예를 들어, 모바일 타입 컴퓨팅 장치(100-1)는, 스마트 폰(smart phone), 휴대폰, 디지털방송용 디바이스, PDA(personal digital assistants), PMP(portable multimedia player) 및/또는 태블릿 PC(tablet PC) 등을 포 함할 수 있다. 또한, 데스크탑 타입 컴퓨팅 장치(100-2)는, 애플리케이션이 설치된 유/무선 통신 기반 장치일 수 있다. 예를 들면, 데스크탑 타입 컴퓨팅 장치(100-2)는, 고정형 데스크탑 PC, 노트북 컴퓨터(laptop computer) 및/또 는 울트라북(ultrabook)과 같은 퍼스널 컴퓨터 등을 포함할 수 있다. 실시예에 따라서 콘솔 디바이스는, 3차원 구강모델 제공 서비스 환경을 제공하는 소정의 서버(Server) 컴 퓨팅 디바이스를 더 포함할 수도 있다. 도 2는 본 발명의 실시예에 따른 콘솔 디바이스의 내부 블록도이다. 한편, 도 2를 참조하면, 기능적 관점에서 콘솔 디바이스는, 메모리, 프로세서 어셈블리, 통신 프로세서, 인터페이스부, 입력 시스템, 센서 시스템 및 디스플레이 시스템을 포함할 수 있다. 실시예에서 콘솔 디바이스는, 상기 구성요소들을 하우징 내에 포함할 수 있다. 자세히, 메모리는, 애플리케이션을 저장할 수 있다. 이때, 애플리케이션은, 3차원 구강모델 제공 서비스 환경을 제공하기 위한 각종 응용 프로그램, 데이터 및 명령어 중 어느 하나 이상을 저장할 수 있다. 즉, 메모리는, 3차원 구강모델 제공 서비스 환경을 생성하기 위하여 사용될 수 있는 명령 및 데이터 등을 저장할 수 있다. 또한, 메모리는, 프로그램 영역과 데이터 영역을 포함할 수 있다. 여기서, 실시예에 따른 프로그램 영역은, 콘솔 디바이스를 부팅하는 운영체제(OS: Operating System) 및 기능요소들 사이에 연계될 수 있다. 또한, 실시예에 따른 데이터 영역은, 콘솔 디바이스의 사용에 따라 발생하는 데이터가 저장될 수 있다. 또한, 메모리는, 적어도 하나 이상의 비일시적 컴퓨터 판독 가능 저장매체와, 일시적 컴퓨터 판독 가능 저 장매체를 포함할 수 있다. 예를 들어, 메모리는, ROM, EPROM, 플래시 드라이브, 하드 드라이브 등과 같은 다양한 저장기기일 수 있고, 인터넷(internet) 상에서 메모리의 저장 기능을 수행하는 웹 스토리지(web storage)를 포함할 수 있 다. 프로세서 어셈블리는, 3차원 구강모델 제공 서비스 환경을 생성하기 위한 다양한 작업을 수행하기 위하여, 메모리에 저장된 애플리케이션의 명령들을 실행할 수 있는 적어도 하나 이상의 프로세서를 포함할 수 있다. 실시예에서 프로세서 어셈블리는, 3차원 구강모델 제공 서비스를 제공하기 위하여 메모리의 애플리케 이션을 통해 구성요소의 전반적인 동작을 컨트롤할 수 있다. 자세히, 프로세서 어셈블리는, 중앙처리장치(CPU) 및/또는 그래픽처리장치(GPU) 등이 포함된 콘솔 디바이 스에 적합한 시스템 온 칩(SOC)일 수 있다. 또한, 프로세서 어셈블리는, 메모리에 저장된 운영체제(OS) 및/또는 응용 프로그램 등을 실행할 수 있다. 또한, 프로세서 어셈블리는, 콘솔 디바이스에 탑재된 각 구성요소들을 제어할 수 있다. 또한, 프로세서 어셈블리는, 각 구성요소와 내부적으로 시스템 버스(System Bus)에 의해 통신을 수행할 수 있고, 로컬 버스(Local Bus)를 비롯한 소정의 버스 구조들을 하나 이상 포함할 수 있다. 또한, 프로세서 어셈블리는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스 (microprocessors) 및/또는 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 포함하여 구현될 수 있다. 통신 프로세서은, 외부의 장치와 통신하기 위한 하나 이상의 장치를 포함할 수 있다. 이러한 통신 프로세 서은, 무선 네트워크를 통해 통신할 수 있다. 자세히, 통신 프로세서은, 3차원 구강모델 제공 서비스 환경을 구현하기 위한 콘텐츠 소스를 저장한 콘솔 디바이스와 통신할 수 있다. 또한, 통신 프로세서는, 유저 입력을 받는 컨트롤러와 같은 다양한 유저 입력 컴포넌트와 통신할 수 있다. 실시예에서, 통신 프로세서은, 3차원 구강모델 제공 서비스와 관련된 각종 데이터를 타 콘솔 디바이스 및/또는 외부의 서버 등과 송수신할 수 있다. 이러한 통신 프로세서은, 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced),5G NR(New Radio), WIFI) 또는 근거리 통신방식 등을 수행 할 수 있는 통신장치를 통해 구축된 이동 통신망 상에서 기지국, 외부의 콘솔 디바이스, 임의의 서버 중 적어도 하나와 무선으로 데이터를 송수신할 수 있다. 센서 시스템은, 이미지 센서, 위치 센서(IMU, 163), 오디오 센서, 거리 센서, 근접 센서, 접촉 센서 등 다양한 센서를 포함할 수 있다. 여기서, 이미지 센서는, 콘솔 디바이스 주위의 물리적 공간에 대한 영상(이미지 및/또는 동영상 등) 을 촬영할 수 있다. 자세히, 이미지 센서는, 콘솔 디바이스의 외부를 향해 배치된 카메라를 통하여 소정의 물리적 공간을 촬영할 수 있다. 실시예로, 이미지 센서는, 콘솔 디바이스의 전면 또는/및 후면에 배치되어 배치된 방향 측의 물리적 공간을 촬영할 수 있다. 실시예에서, 이미지 센서는, 3차원 구강모델 제공 서비스와 관련된 각종 영상(예컨대, 구강 이미지 등) 등 을 촬영하여 획득할 수 있다. 이러한 이미지 센서는, 이미지 센서장치와 영상 처리 모듈을 포함할 수 있다. 자세히, 이미지 센서는, 이미지 센서장치(예를 들면, CMOS 또는 CCD)에 의해 얻어지는 정지영상 또는 동영 상을 처리할 수 있다. 또한, 이미지 센서는, 영상 처리 모듈을 이용하여 이미지 센서장치를 통해 획득된 정지영상 또는 동영상을 가공해 필요한 정보를 추출하고, 추출된 정보를 프로세서에 전달할 수 있다. 이러한 이미지 센서는, 적어도 하나 이상의 카메라를 포함하는 카메라 어셈블리일 수 있다. 여기서, 카메라 어셈블리는, 가시광선 대역을 촬영하는 일반 카메라를 포함할 수 있으며, 적외선 카메라, 스테 레오 카메라 등의 특수 카메라를 더 포함할 수 있다. 또한, 위와 같은 이미지 센서는, 실시예에 따라서 콘솔 디바이스에 포함되어 동작할 수도 있고, 외부 의 장치(예컨대, 구강 스캐너 및/또는 외부의 서버 등)에 포함되어 상술된 통신 프로세서 및/또는 인 터페이스부에 기초한 연동을 통해 동작할 수도 있다. 위치 센서(IMU, 163)는, 콘솔 디바이스의 움직임 및 가속도 중 적어도 하나 이상을 감지할 수 있다. 예를 들어, 가속도계, 자이로스코 및/또는 자력계와 같은 다양한 위치 센서의 조합으로 이루어질 수 있다. 또한, 위치 센서(IMU, 163)는, 통신 프로세서의 GPS와 같은 위치 통신 프로세서과 연동하여, 콘솔 디 바이스 주변의 물리적 공간에 대한 공간 정보를 인식할 수 있다. 오디오 센서는, 콘솔 디바이스 주변의 소리를 인식할 수 있다. 자세히, 오디오 센서는, 콘솔 디바이스를 사용하는 유저의 음성 입력을 감지할 수 있는 마이크로폰을 포함할 수 있다. 실시예에서 오디오 센서는 3차원 구강모델 제공 서비스를 위해 필요한 음성 데이터를 유저로부터 입력 받 을 수 있다. 인터페이스부은, 콘솔 디바이스를 하나 이상의 다른 장치와 통신 가능하게 연결할 수 있다. 자세히, 인터페이스부은, 하나 이상의 상이한 통신 프로토콜과 호환되는 유선 및/또는 무선 통신 장치를 포함할 수 있다. 이러한 인터페이스부을 통해 콘솔 디바이스는, 여러 입출력 장치들과 연결될 수 있다. 예를 들어, 인터페이스부은, 헤드셋 포트나 스피커와 같은 오디오 출력장치와 연결되어, 오디오를 출력할 수 있다. 예시적으로 오디오 출력장치가 인터페이스부을 통해 연결되는 것으로 설명하였으나, 콘솔 디바이스 내부에 설치되는 실시예도 포함될 수 있다. 또한, 예를 들면 인터페이스부은, 키보드 및/또는 마우스와 같은 입력장치와 연결되어, 유저 입력을 획득 할 수도 있다. 이러한 인터페이스부은, 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트 (port), 메모리 카드(memory card) 포트, 식별 모듈이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트(port), 전력 증폭기, RF 회로, 송수신기 및 기타 통신 회로 중 적어도 하나를 포함하여 구성될 수 있다. 입력 시스템은 3차원 구강모델 제공 서비스와 관련된 유저의 입력(예를 들어, 제스처, 음성 명령, 버튼의 작동 또는 다른 유형의 입력)을 감지할 수 있다. 자세히, 입력 시스템은 소정의 버튼, 터치 센서, 유저 모션 입력을 감지하는 이미지 센서 및/또는 유 저 음성 입력을 감지하는 오디오 센서 등을 포함할 수 있다. 또한, 입력 시스템은, 인터페이스부을 통해 외부 컨트롤러와 연결되어 유저의 입력을 수신할 수 있다. 디스플레이 시스템은, 3차원 구강모델 제공 서비스와 관련된 다양한 정보를 그래픽 이미지로 출력할 수 있 다. 실시예로, 디스플레이 시스템은, 3차원 구강모델 제공 서비스를 위한 각종 유저 인터페이스, 구강 이미지, 라벨링 이미지, 모델링 이미지 및/또는 3차원 구강모델 등을 표시할 수 있다. 이러한 디스플레이는, 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display) 및/또는 전자잉크 디스플레이 (e-ink display) 중에서 적어도 하나를 포함할 수 있으며, 이에 한정되지 않는다. 또한, 실시예에 따라서 디스플레이 시스템은, 이미지를 출력하는 디스플레이와, 유저의 터치 입력을 감지하는 터치 센서를 포함할 수 있다. 예시적으로 디스플레이는, 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써 터치 스크린으로 구현될 수 있다. 이러한 터치 스크린은, 콘솔 디바이스와 유저 사이의 입력 인터페이스를 제공하는 유저 입력부로써 기능함 과 동시에, 콘솔 디바이스와 유저 사이의 출력 인터페이스를 제공할 수 있다. 한편, 본 발명의 실시예에 따른 콘솔 디바이스는, 소정의 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)에 기초하여 3차원 구강모델 제공 서비스와 관련된 딥러닝을 수행할 수 있다. 여기서, 실시예에 따른 상기 딥러닝 뉴럴 네트워크는, EfficientNet, ResNet, ARIMA(Autoregressive Integrated Moving Average), VAR(Vector Auto Regression), RNN(Recurrent Neural Networks), LSTM(Long Short-Term Memory models), GRU(Gated Recurrent Unit), GAN(Generative Adversarial Networks), DualStyleGAN, StyleGAN, Graph Convolution Network(GCN), CNN(Convolution Neural Network, CNN), DPSNet(Deep Plane Sweep Network, DPSNet), AGN(Attention Guided Network, AGN), R-CNN(Regions with CNN features), Fast R-CNN, Faster R-CNN, Mask R-CNN 및/또는 U-Net network 등을 포함할 수 있으며, 이에 한정 되지 않는다. 자세히, 실시예에서 콘솔 디바이스는, 본 발명의 실시예에 따른 세그멘테이션 딥러닝 모델(Segmentation Deep-learning Model)을 구현 가능한 적어도 하나 이상의 딥러닝 뉴럴 네트워크와 연동하여, 3차원 구강모델 제 공 서비스에 필요한 딥러닝을 수행할 수 있다. 이때, 실시예에서 세그멘테이션 딥러닝 모델은, 소정의 구강 이미지를 입력 데이터로 하고, 입력된 구강 이미지 내 각각의 객체(예컨대, 마진라인, 각 치아, 치은(잇몸), 입천장, 입바닥, 혀, 볼, 입술 또는 기타 등)를 물리 적 의미 단위로 구분하여 속성(종류)에 따라 라벨링한 이미지를 출력 데이터로 하는 딥러닝(즉, 시멘틱 세그멘 테이션 딥러닝)을 수행할 수 있다. 다만, 본 발명의 실시예에서는 세그멘테이션 딥러닝 모델을 구현하는 딥러닝 알고리즘 자체를 한정하거나 제한 하지 않으며, 본 발명의 실시예에 따른 세그멘테이션 딥러닝 모델은 공지된 적어도 하나의 딥러닝 알고리즘에 기초하여 구현될 수 있다. 다른 한편, 실시예에 따라서 콘솔 디바이스에서 수행하는 기능 동작의 적어도 일부를 외부의 장치(예컨대, 구강 스캐너 등)에서 수행할 수도 있고, 상기 외부의 장치에서 수행하는 기능 동작의 적어도 일부를 콘솔 디바이스에서 더 수행할 수도 있는 등 다양한 실시예가 가능할 수 있다. - 구강 스캐너(200: Intra-oral Scanner) 도 3은 본 발명의 실시예에 따른 구강 스캐너의 개략적인 구조를 도시한 도면이고, 도 4는 본 발명의 실시 예에 따른 구강 스캐너의 구성요소를 도시한 도면이다. 도 3 및 도 4를 참조하면, 본 발명의 일 실시예에 따른 구강 스캐너는 크게 구강 스캐너 몸체, 가속도센서, 스캔모드 결정부 및 품질정보 자동 보정부를 포함할 수 있다. 또한, 추가적인 일 실시예에서 구강 스캐너는, 2차원 영상 데이터를 3차원 영상 데이터로 변환하는 컴퓨팅 장치(실시예로, 콘솔 디바이스) 및 컴퓨팅 장치와의 무선 데이터 통신이 가능한 무선 전송장치를 더 포함할 수도 있다. 자세히, 실시예에 따른 구강 스캐너 몸체는, 구강 내 피사체(S: 예컨대, 구강구조)에 패턴광을 조사 하고, 구강 내 피사체(S)로부터 반사되는 반사광에 의해 형성되는 영상 데이터를 획득하는 역할을 할 수 있다. 보다 구체적으로, 구강 스캐너 몸체는, 광원으로부터 출사되는 광에 소정의 패턴을 형성하여 패턴광 을 구강 내 피사체(S)에 조사하는 디지털 프로젝터, 패턴광에 의해 구강 내 피사체(S)에 반사되는 반사광 에 의해 형성되는 2차원 영상 데이터를 센싱하는 이미지 센싱부, 디지털 프로젝터로부터 구강 내 피 사체(S)에 출사되는 패턴광 및 패턴광에 의해 반사되는 반사광을 제어하는 초점렌즈 및/또는 광학 부품 등을 포함할 수 있다. 이때, 실시예에 따른 디지털 프로젝터는 광원을 포함하고, 광원으로부터 출사되는 소정의 패턴을 형성하여 패턴광을 피사체(S)에 조사하는 장치일 수 있다. 그리하여 디지털 프로젝터는, 유리판의 일면에 원하는 패턴을 가공하여 패턴 마스크를 별도로 제작할 필요 없이 프로그래밍에 의해 원하는 패턴을 자유롭게 제작 및 교체할 수 있고, 미세한 패턴 형성이 가능하다는 이점 을 가질 수 있다. 이러한 디지털 프로젝터는 LCD(Liquid Crystal Display) 프로젝터, LCOS(Liquid Crystal On Silicon) 프 로젝터 또는 DLP(Digital Light Processing) 프로젝터를 이용할 수 있다.예를 들어, DLP 프로젝터는 DMD(Digital Micromirror Device) 칩을 이용하여 하나의 픽셀(Pixel)에 하나의 마 이크로미러(Micromirror)가 대응되도록 하여 상기 마이크로미러가 신호에 따라 반사 각도를 조절하여 이미지를 구현하는 방식으로 작동되는 것으로, 디지털 프로젝터를 사용하는 경우 고화질 및 고휘도의 영상을 제공할 수 있다는 이점이 있을 수 있다. 또한, 실시예에 따라서 디지털 프로젝터는, 소정의 패턴 정보를 저장할 수 있는 저장부를 더 포함할 수 있 다. 이때 상기 저장부는, 디지털 프로젝터에 장착되도록 구성할 수도 있으나 상기 디지털 프로젝터에 착 탈 가능한 USB(Universal Serial Bus)와 같은 이동식 저장장치로 구성할 수도 있다. 디지털 프로젝터가 저장부를 더 포함하도록 구성하는 경우, 패턴 정보를 외부 장치로부터 별도로 받을 필 요가 없어지므로 데이터 처리 속도가 향상된다는 이점을 가질 수 있다. 또한, 실시예에 따른 이미지 센싱부는, 상기 디지털 프로젝터에 의해 형성되는 패턴광에 의해 피사체 (S)에 반사되는 반사광에 의해 형성되는 2차원 영상 데이터를 센싱하는 장치로, 디지털 카메라를 이용하는 것이 바람직할 수 있다. 예를 들어, 디지털 카메라를 이용하는 경우 디지털 프로젝터에 의해 패턴광이 형성되고, 상기 패턴광은 초 점렌즈 및 광학부품을 통과하여 피사체(S)에 조사될 수 있다. 패턴광이 조사되면 피사체(S)의 표면에는 피사체(S)의 입체적 형상에 따라 특정한 패턴의 무늬가 나타나게 되는 데, 이러한 특정한 패턴 무늬는 피사체(S)의 입체적 형상에 대한 정보를 포함할 수 있다. 또한, 위와 같이 피사체(S) 표면에 형성된 무늬는, 광학 부품 및 초점렌즈를 통과하여 카메라에 도달할 수 있다. 이미지 센싱부에 도달된 특정 패턴의 무늬는, 예를 들어, CCD(Charge Coupled Device) 또는 CMOS(Complementary Metal-Oxide Semiconductor)와 같은 메모리 소자에 의해 상기 2차원의 영상 데이터로 센싱 및 저장될 수 있다. 또한, 실시예에 따른 초점렌즈는, 상기 디지털 프로젝터로부터 피사체(S)에 출사되는 패턴광 및 상기 패턴광에 의해 피사체(S)에 반사되는 반사광을 제어하는 렌즈 등의 집합체로, 상기 패턴광 및 반사광이 평행광 을 유지하도록 하거나 광로를 조정하는 등의 역할을 할 수 있다. 또한, 초점렌즈는, 회절에 의한 상붕괴를 방지하여 반사광에 의해 형성된 2차원의 영상 데이터의 해상도를 향상시킬 수 있는 콜리메이팅 렌즈를 포함할 수 있으나, 이에 한정하지는 않는다. 또한, 초점렌즈는, 패턴광 및 반사광의 경로를 조정할 수 있는 광학 부품과 연결될 수 있다. 이처럼 초점렌즈는 말단부에 광학 부품을 구성함으로써, 좁은 구강 내 공간에서 치아를 촬영해야 하는 공 간상 제약에 따른 문제점을 해결할 수 있다. 이때, 실시예에 따른 광학 부품은, 프리즘이나 거울로 구성될 수 있으나 이에 한정되지는 않는다. 또한, 상기 초점렌즈는 고정된 형태로 구성될 수도 있지만, 보다 정밀한 평행광을 얻거나 광로를 조정하기 위하여 초점 거리 등을 기계적으로 제어할 수 있도록 구성될 수 있다. 보다 구체적으로, 초점렌즈는, 구강 스캐너 몸체 내에서 전후 방향으로 위치 이동되어 초점을 조절하는 형태를 가질 수도 있고, 또는 액체렌즈 기술 및/또는 초고속 가변초점렌즈시스템(MALS) 기술 등이 적 용될 수도 있다. 한편, 실시예에 따른 가속도 센싱부는, 구강 스캐너 몸체의 운동상태를 감지하여 가속도 정보를 산출하는 역할을 할 수 있다. 그리하여 후술되는 스캔모드 결정부에서는, 실시예에 따라서 가속도 센싱부를 통해 산출된 가속도 정 보를 이용하여 구강 스캐너 몸체를 통한 스캔모드를 자동으로 결정할 수 있다. 또한, 실시예에 따른 스캔모드 결정부는, 가속도 센싱부를 통해 산출된 가속도 정보가 임계값을 초과 하는 경우, 구강 스캐너 몸체의 운동상태가 제1 상태(예컨대, 고속으로 움직이는 일반적인 상태)인 것으로 판단하여 해당 스캔모드를 제1 스캔모드(일반 스캔모드)로 전환할 수 있다. 여기서, 실시예에 따른 제1 스캔모드는, 구강 내 피사체(S)의 일반적인 디지털 인상채득 정보를 획득하기 위한 스캔모드(실시예로, 저해상도 스캔모드)를 의미할 수 있다. 반대로, 스캔모드 결정부는, 가속도 센싱부를 통해 산출된 가속도 정보가 임계값 미만인 경우, 구강 스캐너 몸체의 운동상태가 제2 상태(예컨대, 저속으로 움직이는 정밀측정을 위한 상태)인 것으로 판 단하여 해당 스캔모드를 제2 스캔모드(정밀 스캔모드)로 전환할 수 있다. 여기서, 실시예에 따른 제2 스캔모드는, 구강 내 피사체(S)의 정밀한 디지털 인상채득 정보를 획득하기 위한 스 캔모드(실시예로, 고해상도 스캔모드)를 의미할 수 있다. 따라서, 구강 스캐너 몸체를 사용하는 유저의 움직임은 가속도 센싱부를 통해 그 운동상태가 판 단될 수 있고, 이러한 유저의 움직임을 토대로 구강 스캐너의 스캔모드를 일반 스캔모드 혹은 정밀 스캔모 드로 자동 결정하여 변경할 수 있다. 다른 한편, 실시예에 따른 품질정보 자동 보정부는, 구강 스캐너 몸체를 통해 획득된 영상 데이 터(디지털 인상채득 정보)의 품질정보가 기준 품질정보에 상응해지도록 자동으로 보정하는 역할을 할 수 있다. 보다 구체적으로, 품질정보 자동 보정부는, 2차원의 영상 데이터에 대한 밝기정보, 초점정보, 흔들림정보 및/또는 선명도정보를 자동으로 보정함으로써, 영상 데이터의 식별력을 높여 정확한 디지털 인상채득이 가능하 게 할 수 있다. 이러한 품질정보 자동 보정부는, 이미지 센싱부에 입력되는 영상 데이터의 현 노출정도를 연산한 후, 이를 토대로 이미지 센서에 대한 게인(GAIN)값 및 노출시간(EXPOSURE TIME)값, 디지털 프로젝터의 LED밝기 및/또는 LED동작시간 등을 조절함으로써, 영상 데이터에 대한 밝기정보를 보정할 수 있다. 한편, 실시예에 따라서 상술한 바와 같은 구성들을 포함하는 구강 스캐너에서 수행하는 기능 동작의 적어 도 일부를 외부의 장치(예컨대, 콘솔 디바이스 등)에서 수행할 수도 있고, 상기 외부의 장치에서 수행하는 기능 동작의 적어도 일부를 구강 스캐너에서 더 수행할 수도 있는 등 다양한 실시예가 가능할 수 있다. - 저해상도 영역과 고해상도 영역을 포함하는 3차원 구강모델 제공 방법 이하, 본 발명의 실시예에 따른 콘솔 디바이스의 적어도 하나 이상의 프로세서에 의하여 실행되는 애플리 케이션이, 저해상도 영역과 고해상도 영역을 포함하는 3차원 구강모델을 제공하는 방법을 첨부된 도면들을 참조하여 상세히 설명한다. 본 발명의 실시예에서 콘솔 디바이스의 적어도 하나 이상의 프로세서는, 적어도 하나 이상의 메모리 에 저장된 적어도 하나 이상의 애플리케이션을 실행하거나 백그라운드 상태로 동작하게 할 수 있다. 이하, 콘솔 디바이스의 적어도 하나 이상의 프로세서가, 애플리케이션의 명령어를 실행하기 위해 동 작하여 저해상도 영역과 고해상도 영역을 포함하는 3차원 구강모델 제공 방법을 수행하는 것을, 애플리케이션 이 수행하는 것으로 단축하여 설명한다. 도 5는 본 발명의 실시예에 따른 저해상도 영역과 고해상도 영역을 포함하는 3차원 구강모델 제공 방법을 설명 하기 위한 흐름도이다. 도 5를 참조하면, 실시예에서 콘솔 디바이스의 적어도 하나 이상의 프로세서에 의하여 실행되거나 백그라 운드 상태로 동작하는 애플리케이션은, 저해상도 스캔모드 기반 제1 구강 이미지를 획득할 수 있다. (S101) 자세히 실시예에서 애플리케이션은, 구강 스캐너와 연동하여, 구강 내 피사체(S)의 디지털 인상채득 정보를 소정의 저해상도로 획득하는 저해상도 스캔모드를 실행할 수 있다. 여기서, 저해상도는 고해상도 스캔모드 대비 상대적으로 해상도가 낮다는 의미로, 기본 스캔모드를 저해상도 스 캔모드라고 표현한 것으로 볼 수 있다. 이때, 구강 스캔을 수행하는 구강 스캐너는, 구강 내 피사체(S)에 소정의 패턴광을 조사하고, 구강 내 피 사체(S)로부터 반사되는 반사광에 의해 형성되는 영상 데이터를 획득할 수 있다. 구체적으로 구강 스캐너는, 광원으로부터 출사되는 광에 소정의 패턴을 형성(즉, 패턴광을 형성)하여 구강 내 피사체(S)에 조사하는 디지털 프로젝터와, 조사된 패턴광에 의해 구강 내 피사체(S)로부터 반사되는 반 사광을 기초로 형성되는 2차원 영상 데이터를 센싱하는 이미지 센싱부 등을 이용하여, 구강 스캔을 수행할 수 있다. 즉, 실시예에서 구강 스캐너는, 단안 카메라와 패턴광을 활용하는 스캔 방식을 이용하여 구강 내 피사체 (S)에 대한 스캔을 수행할 수 있다. 예시적으로 구강 스캐너는, 다이렉트 코딩(Direct coding) 및/또는 타임 멀티플렉서(Time MUX) 방식 등의 패턴광 출력 방식을 이용하여 구강 스캔을 수행할 수 있다. 그리하여 실시예에서 애플리케이션은, 구강 스캐너와의 연동을 통하여 소정의 저해상도 스캔모드를 실행할 수 있다. 또한 애플리케이션은, 실행된 저해상도 스캔모드에 따라서 획득된 영상 데이터를 토대로 제1 구강 이미지 를 획득할 수 있다. 즉 실시예에서 제1 구강 이미지는, 구강 내 피사체(S)에 대한 디지털 인상채득 정보를 소정의 저해상도로 획득 한 2차원 영상 데이터일 수 있다. 이때, 실시예에 따라서 애플리케이션은, 유저 설정에 따라 소정의 고해상도로 구강 내 피사체(S)의 디지털 인상채득 정보를 획득하는 고해상도 스캔모드를 실행할 수도 있고, 실행된 고해상도 스캔모드를 통해 획득된 영 상 데이터를 토대로 제1 구강 이미지를 획득할 수도 있다. 또한, 실시예에서 애플리케이션은, 획득된 제1 구강 이미지를 기초로 3차원 저해상도 구강모델을 제공할 수 있다. (S103) 도 6은 본 발명의 실시예에 따른 3차원 저해상도 구강모델을 설명하기 위한 도면의 일례이다. 여기서, 도 6을 참조하면, 실시예에 따른 3차원 저해상도 구강모델이란, 제1 구강 이미지를 기초로 생성된 3차 원 구강모델을 의미할 수 있다. 자세히, 실시예에서 애플리케이션은, 소정의 알고리즘을 이용하여 제1 구강 이미지에 기초한 3차원 저해상 도 구강모델을 생성할 수 있다. 이때 애플리케이션은, 개시된 다양한 알고리즘을 이용하여 소정의 구강 이미지에 기초한 3차원 구강모델을 생성할 수 있으며, 본 발명의 실시예에서는 상기 알고리즘 자체를 한정하거나 제한하지 않는다. 또한, 실시예에서 애플리케이션은, 생성된 3차원 저해상도 구강모델을 표시하여 제공할 수 있다. 자세히, 실시예에서 애플리케이션은, 구강 스캔 인터페이스에 기초하여 3차원 저해상도 구강모델을 표시할 수 있다. 여기서, 실시예에 따른 구강 스캔 인터페이스는, 실시간 촬영되는 구강 이미지, 상기 구강 이미지를 기초로 실 시간 생성되는 3차원 구강모델 및/또는 실시간 스캔 가이드 이미지를 표시할 수 있다. 이때, 실시예에서 구강 스캔 인터페이스를 통해 표시되는 3차원 구강모델은, 스캔 신뢰도가 높은 고신뢰 영역, 스캔 신뢰도가 낮은 저신뢰 영역 및/또는 스캔이 수행되지 않은 미생성 영역을 구분하여 표시할 수 있다. 또한, 실시예에서 실시간 스캔 가이드 이미지는, 구강 스캐너의 현재 스캔 지점을 기준으로 하는 실시간 이동방향 및/또는 이동속도 등을 안내하는 소정의 그래픽 이미지일 수 있다. 이처럼 애플리케이션은, 구강 내 피사체(S)에 대하여 획득되는 구강 이미지, 3차원 구강모델 및/또는 스캔 가이드 이미지를 실시간으로 표시하여 제공할 수 있다. 따라서 애플리케이션은, 유저가 실시간 구강 스캔 데이터들을 다각적 방식으로 용이하게 확인하도록 지원 할 수 있다. 또한, 실시예에서 애플리케이션은, 제공된 3차원 저해상도 구강모델을 기초로 관심영역을 설정할 수 있다. (S105) 여기서, 실시예에 따른 관심영역이란, 3차원 저해상도 구강모델 상에서 보다 정밀한 디지털 인상채득 정보를 획 득하고자 하는 영역을 의미할 수 있다. 즉, 실시예에서 관심영역은, 3차원 저해상도 구강모델 상에서 보다 높은 해상도(고해상도)로 디지털 인상채득 정보를 획득하기 위해 추가 스캔을 수행하고자 하는 영역일 수 있다. 도 7은 본 발명의 실시예에 따른 관심영역을 설정하는 방법을 설명하기 위한 도면의 일례이다. 자세히, 도 7을 참조하면, 실시예에서 애플리케이션은, 3차원 저해상도 구강모델을 기초로 관심영역(AOI) 을 설정할 수 있는 유저 인터페이스인 관심영역 설정 인터페이스를 제공할 수 있다. 또한, 실시예에서 애플리케이션은, 관심영역 설정 인터페이스에 기초한 유저 입력에 따라서 관심영역(AO I)을 설정할 수 있다. 보다 상세히, 실시예에서 애플리케이션은, 관심영역 설정 인터페이스에 기초한 유저 입력을 토대로 3차원 저해상도 구강모델 내 관심영역(AOI)을 결정할 수 있다. 예를 들어, 애플리케이션은 관심영역 설정 인터페이스를 통해 소정의 영역을 선택할 수 있는 브러쉬 툴 (Brush tool)을 제공하고, 유저가 소정의 입력을 통해 브러쉬를 드래그하면 브러쉬가 드래그된 영역을 관심영역 (AOI)으로 설정하도록 제공할 수 있다. 추가적으로, 유저가 관심영역(AOI)을 좀더 쉽고 정확하게 설정하도록 하기 위하여 하기와 같은 프로세스를 더 제공할 수 있다. 먼저, 애플리케이션은 관심영역 설정 인터페이스를 기초로 3차원 저해상도 구강모델에서 관심영역(AOI)을 지정할 영역 내의 일 위치를 선택하도록 하고, 선택된 일 위치를 관심 포인트로 결정할 수 있다. 여기서, 실시예에 따른 관심 포인트란, 3차원 저해상도 구강모델 상에서 보다 정밀한 디지털 인상채득 정보를 획득하고자 하는 피사체(S)의 적어도 일 지점일 수 있다. 또한, 실시예에서 애플리케이션은, 관심 포인트를 기초로 적어도 하나 이상의 타겟 치아를 결정할 수 있다. 여기서, 실시예에 따른 타겟 치아란, 구강 내 복수의 치아객체 중에서 관심 포인트에 매칭되는 치아객체를 의미 할 수 있다. 실시예로 애플리케이션은, 구강 내 복수의 치아객체 각각이 형성하는 영역 중에서 유저 입력에 따라 결정 된 관심 포인트를 포함하는 영역을 검출할 수 있다. 또한 애플리케이션은, 검출된 영역에 대응되는 치아객체를 검출할 수 있다. 그리고 애플리케이션은, 검출된 치아객체를 타겟 치아로 결정할 수 있다. 또한, 실시예에서 애플리케이션은, 타겟 치아에 기초한 3차원 탑뷰 콘텐츠를 제공할 수 있다. 여기서, 실시예에 따른 3차원 탑뷰 콘텐츠(TTV)란, 타겟 치아를 기준으로 3차원 저해상도 구강모델을 표시하는 그래픽 이미지를 의미할 수 있다. 구체적으로, 실시예에서 3차원 탑뷰 콘텐츠(TTV)는, 1) 타겟 치아를 디스플레이 화면 내 중심영역에 표시하는 그래픽 이미지일 수 있다. 또한 3차원 탑뷰 콘텐츠(TTV)는, 2) 기 설정된 크기 이상을 충족하도록 타겟 치아를 확대 표시하는 그래픽 이미 지일 수 있다. 또한 3차원 탑뷰 콘텐츠(TTV)는, 3) 타겟 치아를 수직방향으로 바라보는 뷰 포인트(즉, 탑뷰)로 표시하는 그래 픽 이미지일 수 있다. 이와 같이 애플리케이션은, 유저가 보다 정밀한 스캔 정보를 획득하고자 하는 치아를 선택하면 해당 치아 를 확대하여 화면 중앙에 탑 뷰포인트로 표시하는 3차원 탑뷰 콘텐츠(TTV)를 제공할 수 있다. 따라서 애플리케이션은, 관심영역(AOI)을 보다 편리하게 지정할 수 있도록 특화된 인터페이스 화면을 통하 여 유저가 관심영역(AOI)을 설정하기 위한 입력을 수행할 시 더욱 손 쉽게 관심영역(AOI) 입력을 수행하도록 할 수 있다. 계속해서, 실시예에서 3차원 탑뷰 콘텐츠(TTV)를 제공한 애플리케이션은, 3차원 탑뷰 콘텐츠(TTV)에 기초 한 유저 입력을 토대로 관심영역(AOI)을 설정할 수 있다. 실시예로 애플리케이션은, 3차원 탑뷰 콘텐츠(TTV) 내 적어도 일부영역을 드래그하는 유저 입력을 획득할 수 있다. 그리고 애플리케이션은, 획득된 유저 입력에 대응되는 영역을 관심영역(AOI)으로 설정할 수 있다. 다른 실시예로 애플리케이션은, 타겟 치아의 질환상태 정보를 획득할 수 있다. 여기서, 실시예에 따른 질환상태 정보란, 치아에 발병된 치과질환 여부 및 발병영역을 나타내는 정보일 수 있다. 예를 들어 질환상태 정보는, 충치(치아우식증: Dental Caries), 풍치(잇몸병: Periodontal Disease), 삐뚠이 (부정교합: Malocclusion) 및/또는 교모증/마모증(Attrision, Abrasion) 등에 대한 발병 여부 및 발병영역을 나타내는 정보일 수 있다. 자세히, 실시예에서 애플리케이션은, 타겟 치아를 포함하는 구강 이미지 및/또는 3차원 구강모델을 이용하 여 타겟 치아에 대한 질환상태 정보를 획득할 수 있다. 이때 애플리케이션은, 자체 메모리 및/또는 외부 서버와의 연동을 통하여, 타겟 치아의 구강 이미지 및/또는 3차원 구강 모델에 기반한 질환상태 정보를 획득할 수 있다. 실시예로 애플리케이션은, 소정의 딥러닝 알고리즘을 이용하여 타겟 치아에 대한 질환상태 정보를 획득할 수도 있다. 또한 실시예에서 애플리케이션은, 자체 메모리 및/또는 외부 서버와의 연동을 통하여, 질환상태 정보 에 대응되는 치료방식을 결정할 수 있다. 예시적으로 애플리케이션은, 아말감 치료, 글라스아이오노머 치료, 레진 치료, 인레이 치료, 크라운 치료, 브릿지 치료, 근관치료(신경치료), 발치 치료 및/또는 임플란트 치료 중 적어도 하나의 치료를 치료방식으로 결 정할 수 있다. 또한, 실시예에서 애플리케이션은, 자체 메모리 및/또는 외부 서버와의 연동을 통하여, 치료방식, 타 겟 치아 및/또는 발병영역에 대응되는 치료영역을 결정할 수 있다. 실시예로 애플리케이션은, 기 지정된 각각의 치료방식에 대응되는 치료영역 결정 알고리즘을 메모리 에 기 저장할 수 있다. 또한 애플리케이션은, 상술된 바와 같이 결정된 치료방식에 대응되는 치료영역 결정 알고리즘에 따라서 타 겟 치아 및/또는 발병영역에 기초한 치료영역을 결정할 수 있다. 실시예로 애플리케이션은, 제1 치료방식에 대응되는 치료영역 결정 알고리즘을 기초로 발병영역, 타겟 치 아 영역, 타겟 치아의 마진라인 영역, 타겟 치아로부터 기 설정된 범위 이내의 외곽 영역 및/또는 인접 치아 영 역 중 적어도 하나의 영역을 포함하는 치료영역을 결정할 수 있다. 구체적으로 애플리케이션은, 치료방식이 제1 치료방식으로 결정되면, 발병영역에 대응하는 치아영역 및 상 기 치아영역에 기준한 소정의 마진영역을 포함하는 영역을 치료영역으로 결정할 수 있다. 한편 애플리케이션은, 치료방식이 제2 치료방식으로 결정되면, 타겟 치아 영역, 상기 타겟 치아의 마진라 인 영역 및 상기 타겟 치아의 마진라인 영역에 기준한 소정의 마진영역을 포함하는 영역을 치료영역으로 결정할 수 있다. 다른 한편 애플리케이션은, 치료방식이 제3 치료방식으로 결정되면, 타겟 치아 영역, 상기 타겟 치아로부 터 기 설정된 범위 이내에 존재하는 적어도 하나의 인접 치아 영역, 상기 인접 치아의 마진라인 영역 및 상기 인접 치아의 마진라인 영역에 기준한 소정의 마진영역을 포함하는 영역을 치료영역으로 결정할 수 있다. 또한 실시예에서 애플리케이션은, 타겟 치아에 대하여 결정된 치료영역을 관심영역(AOI)으로 자동 설정할 수 있다. 즉 실시예에서 애플리케이션은, 타겟 치아를 선택하기만 하면 해당 타겟 치아의 질환상태를 자동으로 판단 하고, 판단된 질환상태에 대응되는 치료방식에 따라서 치료영역을 자동으로 검출해 이를 관심영역(AOI)으로 설 정할 수 있다. 이처럼 애플리케이션은, 관심영역(AOI)을 지정하는 별도의 유저 입력 없이도 자동화된 기계적 프로세스를 통해 관심영역(AOI)을 자동 설정함으로써, 관심영역(AOI) 설정의 편의성 및 효율성을 더욱 향상시킬 수 있다. 추가적으로 애플리케이션은, 자동 설정된 관심영역(AOI)을 수정할 수 있는 관심영역 설정 인터페이스를 더 제공할 수 있다. 자세히, 실시예로 애플리케이션은, 각각의 치료영역에 따른 관심영역(AOI)을 기준으로 3차원 저해상도 구 강모델을 표시하는 그래픽 이미지인 3차원 관심영역 탑뷰 콘텐츠를 제공할 수 있다. 구체적으로, 실시예에서 3차원 관심영역 탑뷰 콘텐츠는, 1) 관심영역(AOI)을 디스플레이 화면 내 중심영역에 표 시하는 그래픽 이미지일 수 있다. 또한 3차원 관심영역 탑뷰 콘텐츠는, 2) 기 설정된 크기 이상을 충족하도록 관심영역(AOI)을 확대 표시하는 그 래픽 이미지일 수 있다. 또한 3차원 관심영역 탑뷰 콘텐츠는, 3) 관심영역(AOI)을 수직방향으로 바라보는 뷰 포인트(즉, 탑뷰)로 표시하 는 그래픽 이미지일 수 있다. 계속해서, 실시예에서 애플리케이션은, 3차원 관심영역 탑뷰 콘텐츠에 기초한 유저 입력을 토대로 관심영 역(AOI)을 수정할 수 있다. 실시예로 애플리케이션은, 3차원 관심영역 탑뷰 콘텐츠 내 관심영역(AOI)의 적어도 일부영역을 브러쉬를 통해 드래그하는 유저 입력을 획득할 수 있다. 그리고 애플리케이션은, 획득된 유저 입력에 대응되는 영역을 유저 선택에 따라서 관심영역(AOI)에 추가 또는 관심영역(AOI)에서 삭제할 수 있다. 즉 애플리케이션은, 치료영역을 기초로 자동 결정된 관심영역(AOI)을 유저 입력에 따라서 확장 또는 축소 시키며 변형할 수 있다. 다른 실시예로 애플리케이션은, 상술된 바와 같이 결정된 치료방식을 변경하는 유저 입력을 관심영역 설정 인터페이스를 통해 획득할 수 있다. 그리고 애플리케이션은, 유저 입력에 따라서 변경된 치료방식과 기 결정되어 있는 타겟 치아 및/또는 발병 영역에 기초하여 치료영역을 자동으로 재결정할 수 있다. 또한 애플리케이션은, 재결정된 치료영역을 관심영역(AOI)으로 재설정함으로써 관심영역(AOI)을 수정할 수 있다. 이처럼 애플리케이션은, 자동 결정된 관심영역(AOI)을 유저 니즈(needs)에 따라서 유연하게 변경할 수 있 는 인터페이스를 제공할 수 있다. 즉 애플리케이션은, 자동 및 수동 방식을 적절하게 혼합하여 관심영역(AOI)을 설정할 수 있도록 지원함으 로써, 3차원 구강모델 제공 서비스에 대한 유저 만족도를 제고할 수 있다. 한편, 실시예에 따라서 애플리케이션은, 3차원 저해상도 구강모델을 복수의 시점으로 분할하여 표시해 제 공할 수 있다. 실시예로 애플리케이션은, 3차원 저해상도 구강모델을 탑뷰, 외측 정면뷰 및 내측 후면뷰를 포함하는 복수 의 시점뷰로 분할하여 표시할 수 있다. 이때, 실시예에서 애플리케이션은, 3차원 저해상도 구강모델의 탑뷰 상에서 관심영역(AOI)을 설정하는 유 저 입력을 획득하면, 획득된 유저 입력에 대응되는 영역 및 상기 유저 입력에 대응되는 영역에 대한 수직방향의 영역을 관심영역(AOI)으로 설정할 수 있다. 그리고 애플리케이션은, 설정된 관심영역(AOI)을 탑뷰뿐만 아니라 병렬적으로 분할 표시되고 있는 외측 정 면뷰 및 내측 후면뷰 상에 실시간으로 연동하여 표시할 수 있다. 이때, 실시예에서 애플리케이션은, 외측 정면뷰 및 내측 후면뷰 상에 표시되는 관심영역(AOI) 즉, 수직방 향으로 바라보는 관심영역(AOI)(이하, 관심 수직영역)을 수정할 수 있는 관심영역 설정 인터페이스를 더 제공할 수 있다. 자세히, 실시예에서 애플리케이션은, 외측 정면뷰 및/또는 내측 후면뷰 상에서 외측 정면뷰 및/또는 내측 후면뷰 내 관심 수직영역의 적어도 일부영역을 선택하는 유저 입력을 획득할 수 있다. 실시예로 애플리케이션은, 관심 수직영역의 적어도 일부영역을 브러쉬를 통해 드래그하는 유저 입력을 획 득할 수 있다. 또한 실시예에서 애플리케이션은, 획득된 유저 입력에 대응되는 영역을 유저 선택에 따라서 관심 수직영역 에 추가 또는 관심 수직영역에서 삭제할 수 있다. 즉 애플리케이션은, 관심 수직영역을 유저 입력에 따라서 확장 또는 축소시키며 변형할 수 있다. 이때, 실시예에서 애플리케이션은, 외측 정면뷰 및/또는 내측 후면뷰 상에서의 유저 입력에 따라서 수정된 관심 수직영역과 탑뷰 상에서의 유저 입력에 따라서 설정된 관심영역(AOI)을 상호 비연동할 수 있다. 즉 애플리케이션은, 수직방향 시점에서 관심영역(AOI)이 수정됨으로 인해 수평방향 시점에서 설정된 관심 영역(AOI)이 변형되는 것을 방지할 수 있다. 따라서 애플리케이션은, 다 시점 상에서 관심영역(AOI)을 보다 안정적으로 정밀하게 설정하도록 지원할 수 있다. 또한, 실시예에서 애플리케이션은, 설정된 관심영역(AOI)을 기초로 고해상도 스캔모드 기반 제2 구강 이미 지를 획득할 수 있다. (S107) 자세히 실시예에서 애플리케이션은, 구강 스캐너와 연동하여, 관심영역(AOI)을 포함하는 구강 내 피 사체(S)에 대한 디지털 인상채득 정보를 소정의 고해상도로 획득하는 고해상도 스캔모드를 실행할 수 있다. 즉 애플리케이션은, 3차원 저해상도 구강모델로부터 선출된 관심영역(AOI)을 포함하는 구강 내 피사체(S) 를 소정의 고해상도로 추가 스캔할 수 있다. 이때 애플리케이션은, 기 설정된 횟수(예컨대, 1회, 2회, …, 또는 N회 등)만큼 관심영역(AOI)에 대한 고 해상도 스캔 기능동작을 실행할 수 있다. 또한, 실시예에서 애플리케이션은, 실행된 고행상도 스캔모드에 따라서 획득된 영상 데이터를 토대로 제2 구강 이미지를 획득할 수 있다. 즉 실시예에서 제2 구강 이미지는, 관심영역(AOI)을 포함하는 구강 내 피사체(S)에 대한 디지털 인상채득 정보 를 소정의 고해상도로 획득한 2차원 영상 데이터일 수 있다. 이때, 구강 스캐너와 연동하여 고해상도 스캔모드를 실행할 시 애플리케이션은, 유저 입력을 기초로 구강 스캐너의 스캔모드 세팅값을 변경할 수 있다. 여기서, 실시예에 따른 스캔모드 세팅값은, 패턴광, 프레임 레이트(Frame rate) 및/또는 해상도 등의 데이터 세 팅값을 포함할 수 있다. 실시예로 애플리케이션은, 고해상도 스캔모드를 실행할 시의 스캔모드 세팅값을 저해상도 스캔모드를 실행 할 시의 스캔모드 세팅값과 상이하도록 변경할 수 있다. 예시적으로 애플리케이션은, 패턴광의 형태를 변경하고 프레임 레이트 및 해상도를 증가시키는 스캔모드 세팅값 변경을 수행할 수 있다. 이처럼 애플리케이션은, 고해상도 스캔에 관여되는 각종 파라미터 값을 유저의 니즈(needs)에 따라서 세밀 히 조정할 수 있도록 하여 유저 맞춤형의 고해상도 스캔모드를 실행할 수 있다. 이를 통해 애플리케이션은, 고해상도 스캔을 위한 데이터 처리 효율을 유저가 원하는 정도로 조정하여 제 고시킬 수 있다. 다른 실시예로 애플리케이션은, 구강 스캐너와 연동하여 고해상도 스캔모드를 실행할 시 구강 스캐너 의 스캔모드 세팅값을 유지할 수 있다. 즉 애플리케이션은, 저해상도 스캔모드를 실행할 시의 스캔모드 세팅값을 그대로 유지하면서 고해상도 스 캔모드를 실행할 수 있다. 따라서 애플리케이션은, 고해상도 스캔을 위한 별도의 세팅 변경을 수행하지 않고도, 추가적으로 스캔이 실행됨에 따라 획득되는 디지털 인상채득 정보의 축척 및 중첩을 통해 고해상도 스캔을 구현할 수 있다. 그리하여 애플리케이션은, 고해상도 스캔을 위한 데이터 처리의 효율을 간편 용이하게 향상시킬 수 있다. 또한, 실시예에서 애플리케이션은, 획득된 제2 구강 이미지를 기초로 3차원 복합해상도 구강모델을 제공할 수 있다. (S109) 여기서, 실시예에 따른 3차원 복합해상도 구강모델이란, 3차원 저해상도 구강모델 및 제2 구강 이미지를 기초로 생성된 3차원 구강모델을 의미할 수 있다. 자세히, 실시예에서 애플리케이션은, 3차원 저해상도 구강모델 및 제2 구강 이미지를 기초로 3차원 복합해 상도 구강모델을 생성할 수 있다. 보다 상세히, 실시예에서 애플리케이션은, 3차원 저해상도 구강모델 상에 고해상도 스캔에 따라서 획득된 제2 구강 이미지의 고해상도 픽셀을 오버랩(overlap)함으로써 3차원 복합해상도 구강모델을 생성할 수 있다. 즉 실시예에서 3차원 복합해상도 구강모델은, 3차원 저해상도 구강모델 상에서 관심영역(AOI)(즉, 추가 스캔을 통해 획득된 고해상도 픽셀이 채워진 영역)은 고해상도로 표시되고, 나머지 영역은 기존의 저해상도로 표시되는 3차원 구강모델일 수 있다. 이때 실시예에서 애플리케이션은, 기 설정된 복수의 횟수(예컨대, 2회, …, 또는 N회 등)만큼 관심영역 (AOI)에 대한 고해상도 스캔이 실행된 경우, 실행된 고해상도 스캔 시마다 획득된 복수의 제2 구강 이미지에 기 초하여 복수 회에 걸친 상기 오버랩 기능동작을 수행해 3차원 복합해상도 구강모델을 생성할 수 있다. 더욱 구체적으로, 실시예에서 애플리케이션은, 1) 제2 구강 이미지 내 비관심 영역을 제거할 수 있다. 여기서, 실시예에 따른 비관심 영역이란, 관심영역(AOI)을 제외한 나머지 영역을 의미할 수 있다. 실시예로 애플리케이션은, 제2 구강 이미지 내 비관심 영역이 존재하면 해당 비관심 영역의 픽셀값을 제거 할 수 있다. 이를 통해 애플리케이션은, 추후 3차원 복합해상도 구강모델을 생성할 시 제2 구강 이미지 내 비관심 영역 이 존재함에 따른 불필요한 데이터 처리를 방지하여 데이터 처리량을 절감하고 그 효율을 증진시킬 수 있다. 또한, 실시예에서 애플리케이션은, 2) 3차원 저해상도 구강모델 상에 제2 구강 이미지에 따른관심영역 (AOI)을 매칭할 수 있다. 자세히 애플리케이션은, 3차원 저해상도 구강모델 상에 비관심 영역이 제거된 제2 구강 이미지를 매칭함으 로써, 3차원 저해상도 구강모델과 제2 구강 이미지 내 관심영역(AOI)을 매칭할 수 있다. 도 8 및 도 9는 본 발명의 실시예에 따른 3차원 복합해상도 구강모델을 생성하는 방법을 설명하기 위한 도면의 일례들이다. 또한, 도 8 및 도 9를 참조하면, 실시예에서 애플리케이션은, 3) 3차원 저해상도 구강모델 상에 매칭된 관 심영역(AOI)에 기초한 고해상도 픽셀 오버랩을 수행할 수 있다. 즉 애플리케이션은, 3차원 저해상도 구강모델 내 관심영역(AOI)(이하, 대상 관심영역)의 저해상도 복셀값 을 제2 구강 이미지 내 관심영역(AOI)(이하, 기준 관심영역)의 고해상도 픽셀값에 기초한 데이터 오버랩을 통하 여 조밀화할 수 있다. 실시예로 애플리케이션은, 리메쉬 알고리즘(Remesh Algorithm) 및/또는 데서메이트 알고리즘(Decimate Algorithm) 등을 이용하여 대상 관심영역에 대한 기준 관심영역 기반의 데이터 오버랩을 수행할 수 있다. 예시적으로 애플리케이션은, 이방성(비등방성) 리메슁 알고리즘(Anisotropic Remeshing Algorithm)을 이 용하여 고해상도 픽셀 오버랩을 수행할 수 있다. 다만 이는 일례일 뿐 본 발명의 실시예에 따른 애플리케이션은, 고해상도 픽셀 오버랩을 수행할 수 있는 기술이라면 개시된 어떠한 알고리즘을 이용해서도 상술된 기능동작을 수행할 수 있으며, 이에 대한 별도의 한정 이나 제한은 하지 않는다. 그리하여 애플리케이션은, 3차원 저해상도 구강모델 내 관심영역(AOI)(대상 관심영역)을 고해상도로 표시 하고, 나머지 영역을 기존의 저해상도로 표시할 수 있다. 또한, 실시예에서 애플리케이션은, 4) 고해상도 픽셀 오버랩이 수행된 3차원 저해상도 구강모델 내 관심영 역(AOI)에 대한 스무딩(Smoothing) 데이터 처리를 수행할 수 있다. 즉 애플리케이션은, 고해상도 픽셀 오버랩이 수행된 대상 관심영역(이하, 변환 관심영역)에 대한 노이즈를 제거하거나 최소화하여, 변환 관심영역을 보다 매끄럽게 표시하는 스무딩 데이터 처리를 수행할 수 있다. 실시예로 애플리케이션은, 이동평균 스무딩(Moving average smoothing), 지수 스무딩(Exponential smoothing), 이중지수 스무딩(Double exponential smoothing) 및/또는 삼중지수 스무딩(Triple Exponential smoothing) 알고리즘 등을 이용하여 변환 관심영역에 대한 스무딩 데이터 처리를 수행할 수 있다. 이와 같이 애플리케이션은, 개시된 다양한 알고리즘(실시예에서, 리메쉬(Remesh), 데서메이트(Decimate) 및/또는 스무딩(Smoothing) 알고리즘)을 활용하여 3차원 저해상도 구강모델 상의 관심영역(AOI)을 높은 품질의 고해상도로 표시하고, 나머지 영역을 기존의 저해상도로 표시할 수 있다. 그리하여 애플리케이션은, 일반적으로 여러 방향의 데이터들을 누적하여 생성되는 3차원 구강모델의 특성 상 유발되는 문제점들(예컨대, 매끄럽지 못한 표면 등)을 해소하면서도, 3차원 구강모델 내 관심영역(AOI)이 포 함하는 피사체(S)가 마진이나 그루브 데이터 등을 고해상도로 선명하게 표시하도록 할 수 있다. 다시 말하면 애플리케이션은, 일반적인 해상도로 3차원 구강모델을 생성한 후 유저가 원하는 영역을 부분 적으로 재스캔하여 상대적 고해상도로 구현함으로써, 유저가 원하는 영역은 고해상도로 표시하고 나머지 영역은 일반적인 해상도로 표시하는 3차원 구강모델을 제공할 수 있다. 즉 애플리케이션은, 유저가 원하는 영역을 고품질의 해상도로 처리하고 유저가 원하는 영역 이외의 나머지 영역을 상대적으로 데이터 처리량이 적고 그 처리속도가 빠른 일반적인 해상도로 처리할 수 있다. 따라서 애플리케이션은, 유저 니즈(needs)에 특화된 즉, 3차원 구강모델의 전반적인 형상을 제공하면서도 동시에 유저가 원하는 특정 영역에 대해서는 보다 소상한 스캔 데이터를 제공하는 3차원 구강모델을 빠르고 효 율적인 데이터 처리를 통해 생성하여 제공할 수 있다. 또한, 실시예에서 애플리케이션은, 5) 최종적으로 3차원 복합해상도 구강모델을 생성할 수 있다. 즉 애플리케이션은, 3차원 저해상도 구강모델과 제2 구강 이미지에 기초한 고해상도 픽셀 오버랩 및 스무 딩 데이터 처리를 거쳐 최종적으로 3차원 복합해상도 구강모델을 생성할 수 있다. 이때, 실시예로 애플리케이션은, 포아송 리컨스트럭션 매서드(Poisson reconstruction method) 및/또는 컨커런트 코-코운즈 매서드(Concurrent Co-Cones) 등을 이용하여 최종적으로 저해상도 및 고해상도 데이터를 결 합한 3차원 복합해상도 구강모델을 생성할 수 있다. 다만 이는 일례일 뿐 본 발명의 실시예에 따른 애플리케이션은, 저해상도 및 고해상도 데이터를 결합할 수 있는 기술이라면 개시된 어떠한 알고리즘을 이용해서도 상술된 기능동작을 수행할 수 있으며, 이에 대한 별도의 한정이나 제한은 하지 않는다. 실시예에 따라서 애플리케이션은, 유저 입력에 따라 전술된 기능동작들의 반복 횟수, 파라미터 값 및/또는 실행 순서를 변경할 수 있다. 또한 애플리케이션은, 변경된 반복 횟수, 파라미터 값 및/또는 실행 순서에 따라서 전술된 프로세스를 수 행할 수 있다. 그리하여 애플리케이션은, 최종 결과물인 3차원 복합해상도 구강모델의 품질을 유저 설정에 따라서 용이하 게 조정할 수 있다. 또한, 실시예에서 애플리케이션은, 6) 생성된 3차원 복합해상도 구강모델을 제공할 수 있다. 도 10 및 도 11은 본 발명의 실시예에 따른 3차원 복합해상도 구강모델을 제공하는 방법을 설명하기 위한 도면 의 일례들이다. 자세히, 도 10을 참조하면, 애플리케이션은, 상술된 방식에 따라서 생성되는 3차원 복합해상도 구강모델을 실시간으로 표시하여 제공할 수 있다. 보다 상세히 애플리케이션은, 구강 스캔 인터페이스에 기초하여 3차원 복합해상도 구강모델을 실시간 표시 할 수 있다. 여기서, 다시 말하자면, 실시예에 따른 구강 스캔 인터페이스는, 실시간 촬영되는 구강 이미지, 상기 구강 이미 지를 기초로 실시간 생성되는 3차원 구강모델 및/또는 실시간 스캔 가이드 이미지를 표시할 수 있다. 이때, 실시예에서 구강 스캔 인터페이스를 통해 표시되는 3차원 구강모델은, 스캔 신뢰도가 높은 고신뢰 영역, 스캔 신뢰도가 낮은 저신뢰 영역 및/또는 스캔이 수행되지 않은 미생성 영역을 구분 표시할 수 있다. 또한, 실시예에서 실시간 스캔 가이드 이미지는, 구강 스캐너의 현재 스캔 지점을 기준으로 하는 실시간 이동방향 및/또는 이동속도 등을 안내하는 소정의 그래픽 이미지일 수 있다. 다시 돌아와서, 이때 애플리케이션은, 고해상도 픽셀 오버랩(및/또는 스무딩 데이터 처리)이 수행될 때마 다 단계적으로 조밀화가 구현되는 3차원 복합해상도 구강모델을 실시간으로 표시할 수 있다. 즉 애플리케이션은, 3차원 저해상도 구강모델 내 관심영역(AOI)이 고해상도 스캔모드를 통해 점차 고해상 도로 변해가는 과정을 실시간으로 표시하여 제공할 수 있다. 이처럼 애플리케이션은, 관심영역(AOI)에 대한 디지털 인상채득 정보가 점차 소상해지는 변화 과정을 제공 하여 보다 직관적인 정보 인식을 지원할 수 있다. 이때, 실시예에 따라서 애플리케이션은, 실시간 표시되는 3차원 복합해상도 구강모델 내 관심영역(AOI) 전 체가 기 설정된 해상도(예컨대, 소정의 수치 등) 이상을 충족하면, 상술된 복합해상도 구강모델 생성 프로세스 를 종료할 수 있다. 자세히, 실시예로 애플리케이션은, 유저 입력을 통하여 3차원 복합해상도 구강모델 내 관심영역(AOI)에 대 하여 요구되는 목표 해상도를 획득할 수 있다. 또한 애플리케이션은, 목표 해상도를 충족할 때까지 상술된 복합해상도 구강모델 생성 프로세스를 반복 수 행할 수 있다. 이때 애플리케이션은, 반복 수행 시마다 생성되는 3차원 복합해상도 구강모델 내 관심영역(AOI)의 해상도 (이하, 진행 해상도)를 목표 해상도와 비교할 수 있다. 또한 애플리케이션은, 비교의 결과 진행 해상도가 목표 해상도 이상을 불충하면, 상술된 복합해상도 생성 프로세스를 계속해서 반복 수행할 수 있다. 또한, 도 11을 참조하면, 애플리케이션은, 비교의 결과 진행 해상도가 목표 해상도 이상을 충족하면, 상술 된 복합해상도 생성 프로세스를 종료하고 최종적인 3차원 복합해상도 구강모델을 표시해 제공할 수 있다. 그리하여 애플리케이션은, 3차원 복합해상도 구강모델 내 관심영역(AOI)의 해상도를 유저가 원하는 수준까 지 자동으로 맞추어 제공할 수 있다. 이상, 본 발명의 실시예에 따른 저해상도 영역과 고해상도 영역을 포함하는 3차원 구강모델 제공 방법 및 시스 템은, 3차원 구강모델 생성을 위하여 구강을 스캔할 시 구강 내 제1 영역을 고해상도로 스캔하고 나머지 제2 영 역을 상대적 저해상도로 스캔하여 생성한 3차원 구강모델을 제공함으로써, 유저가 원하는 특정 영역은 고품질의 해상도로 구현하고 나머지 영역은 상대적으로 데이터 처리량이 적고 그 처리속도가 빠른 일반적인 해상도로 구 현한 3차원 구강모델을 제공할 수 있다. 따라서 본 발명의 실시예에 따른 저해상도 영역과 고해상도 영역을 포함하는 3차원 구강모델 제공 방법 및 시스 템은, 유저 니즈(needs)에 특화된 즉, 3차원 구강모델의 전반적인 형상을 제공하면서도 동시에 유저가 원하는 특정 영역에 대해서는 보다 소상한 스캔 데이터를 제공하는 3차원 구강모델을 빠르고 효율적인 데이터 처리를 통해 생성하여 제공할 수 있는 효과가 있다. - 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 이하, 본 발명의 실시예에 따른 애플리케이션이, 학습된 딥러닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하여 2차원 구강 이미지 내 객체를 라벨링하고, 라벨링된 객체 중 적어도 일부를 기초로 3차원 구강모델을 제공하는 방법을 첨부된 도면들을 참조하여 상세히 설명한다. 도 12는 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는 방법을 설명하기 위한 흐름도이다. 도 12를 참조하면, 실시예에서 애플리케이션은, 인공지능 스캔모드를 실행 및 환경설정 할 수 있다. (S201) 여기서, 실시예에 따른 인공지능 스캔모드란, 딥러닝을 이용하여 구강 내 특정 피사체(S)에 대한 구강정보를 포 함하는 3차원 구강모델을 제공하는 스캔모드를 의미할 수 있다. 이때, 실시예에 따른 구강정보는, 구강 내 스캔된 피사체(S)가 포함하는 각각의 객체(이하, 스캔객체)별 엣지 (Edge) 정보 및 라벨링(Labeling) 정보를 포함할 수 있다. 구체적으로 실시예에 따른 엣지 정보란, 스캔객체 각각의 외곽을 형성하는 경계선을 특정하는 정보일 수 있다. 또한, 실시예에 따른 라벨링 정보란, 스캔객체 각각의 속성(종류)를 특정하는 정보일 수 있다. 실시예로 라벨링 정보는, 마진라인(Margin line), 치아번호(제11 내지 제18 치아, 제21 내지 제28 치아, 제31 내지 제38 치아, 제41 내지 제48 치아), 치은(잇몸), 입천장, 입바닥, 혀, 볼, 입술 또는 기타 등의 라벨 카테 고리 중 어느 하나의 카테고리를 포함할 수 있다. 또한, 실시예로 라벨링 정보는, 스캔객체 각각의 보철타입을 특정하는 카테고리를 더 포함할 수 있다. 예를 들어 라벨링 정보는, '임플란트(Implant), 브릿지(Bridge), 크라운(Crown), 인레이(Inlay) 또는 온레이 (Onlay) 등의 보철타입 카테고리 중 어느 하나의 카테고리를 더 포함할 수 있다. 자세히, 실시예에서 애플리케이션은, 구강 스캐너와 연동하여 인공지능 스캔모드를 실행할 수 있다. 또한, 인공지능 스캔모드를 실행하면 애플리케이션은, 인공지능 스캔모드의 세팅값을 설정(즉, 인공지능 스캔모드 환경설정)할 수 있다. 자세히, 실시예에서 애플리케이션은, 스캔 대상객체 및/또는 스캔 제외객체를 설정할 수 있는 유저 인터페 이스(이하, 스캔객체 설정 인터페이스)를 제공할 수 있다. 여기서, 실시예에 따른 스캔 대상객체는 스캔을 수행하고자 하는 객체를 의미할 수 있고, 스캔 제외객체는 스캔 에서 제외하고자 하는 객체를 의미할 수 있다. 또한 실시예에서 애플리케이션은, 스캔객체 설정 인터페이스에 대한 유저 입력을 토대로 스캔 대상객체 및 /또는 스캔 제외객체의 속성값을 획득할 수 있다. 예를 들면 애플리케이션은, 스캔 대상객체의 속성값으로 '제11 내지 제18 치아'를 획득하고 스캔 제외객체 의 속성값으로 '입천장, 입바닥, 혀, 볼, 입술 및 기타'를 획득할 수 있다. 그리하면 애플리케이션은, 획득된 스캔 대상객체 및/또는 스캔 제외객체의 속성값에 따라서 스캔 대상객체 및/또는 스캔 제외객체를 결정할 수 있다. 그리하여 애플리케이션은, 인공지능 스캔모드의 동작을 위한 기본 세팅값을 설정할 수 있다. 이때, 실시예에 따라서 애플리케이션은, 스캔 대상객체 및/또는 스캔 제외객체의 디폴트 값을 기 설정하여 제공할 수 있다. 예를 들어 애플리케이션은, 스캔 대상객체의 디폴트 값으로 '마진라인, 제11 내지 제18 치아, 제21 내지 제28 치아, 제31 내지 제38 치아, 제41 내지 제48 치아 및 치은(잇몸)'을 기 설정하고, 스캔 제외객체의 디폴트 값으로 '입천장, 입바닥, 혀, 볼, 입술 및 기타'를 기 설정하여 제공할 수 있다. 따라서 애플리케이션은, 별도의 유저 설정이 부재할 시 일반적으로 사용되는 스캔 대상객체 및/또는 스캔 제외객체를 제공하여 인공지능 스캔 수행 시의 편리함을 증진할 수 있다. 또한, 실시예에서 애플리케이션은, 인공지능 스캔모드 기반 제3 구강 이미지를 획득할 수 있다. (S203) 자세히 실시예에서 애플리케이션은, 구강 스캐너와 연동하여 인공지능 스캔모드에 따른 구강 스캔을 실행할 수 있다. 이때 애플리케이션은, 유저 설정에 따라서 저해상도 스캔모드 또는 고해상도 스캔모드 중 어느 하나의 스 캔모드로 인공지능 스캔모드를 실행할 수 있다. 여기서, 다시 말하자면 실시예에 따른 구강 스캐너는, 구강 내 피사체(S)에 소정의 패턴광을 조사하고, 구 강 내 피사체(S)로부터 반사되는 반사광에 의해 형성되는 영상 데이터를 획득할 수 있다. 자세히 구강 스캐너는, 광원으로부터 출사되는 광에 소정의 패턴을 형성(즉, 패턴광을 형성)하여 구강 내 피사체(S)에 조사하는 디지털 프로젝터와, 조사된 패턴광에 의해 구강 내 피사체(S)로부터 반사되는 반사 광을 기초로 형성되는 2차원 영상 데이터를 센싱하는 이미지 센서 등을 이용하여, 구강 스캔을 수행할 수 있다. 즉, 실시예에서 구강 스캐너는, 단안 카메라와 패턴광을 활용하는 스캔 방식을 이용하여 구강 내 피사체 (S)에 대한 스캔을 수행할 수 있다. 예시적으로 구강 스캐너는, 다이렉트 코딩(Direct coding) 및/또는 타임 멀티플렉서(Time MUX) 방식 등의 패턴광 출력 방식을 이용하여 구강 스캔을 수행할 수 있다. 또한, 실시예에서 애플리케이션은, 구강 스캐너와의 연동을 통하여 실행된 인공지능 스캔모드에 따라 서 획득된 영상 데이터를 토대로 제3 구강 이미지를 획득할 수 있다. 즉 실시예에서 제3 구강 이미지는, 인공지능 스캔 과정에서 구강 내 피사체(S)에 대한 디지털 인상채득 정보를 소정의 해상도로 획득한 2차원 영상 데이터일 수 있다. 또한, 실시예에서 애플리케이션은, 획득된 제3 구강 이미지를 기초로 라벨링 이미지를 획득할 수 있다. (S205) 도 13은 본 발명의 실시예에 따른 라벨링 이미지를 설명하기 위한 도면의 일례이다. 여기서, 도 13을 참조하면, 실시예에 따른 라벨링 이미지란, 시멘틱 세그멘테이션(Semantic segmentation)이 수행된 소정의 구강 이미지를 의미할 수 있다. 도 14는 본 발명의 실시예에 따른 구강 이미지를 기초로 시멘틱 세그멘테이션을 수행한 모습의 일례들이다. 참고적으로, 도 14를 참조하면, 시멘틱 세그멘테이션이란, 이미지 내 객체를 실제로 인식할 수 있는 물리적 의 미 단위로 구분하여 라벨링하는 딥러닝 기반의 이미지 인식 방법일 수 있다. 즉, 실시예에서 라벨링 이미지는, 시멘틱 세그멘테이션을 통하여 구강 이미지 내 각각의 객체를 물리적 의미 단 위로 구분한 정보(엣지 정보)와, 각 객체의 속성을 특정한 정보(라벨링 정보)를 포함하는 구강 이미지일 수 있 다. 자세히 실시예에서 애플리케이션은, 시멘틱 세그멘테이션을 수행하도록 기 학습된 딥러닝 모델(이하, 세그 멘테이션 딥러닝 모델)과 연동하여 제3 구강 이미지에 기초한 라벨링 이미지를 획득할 수 있다. 보다 상세히, 실시예에서 애플리케이션은, 제3 구강 이미지를 세그멘테이션 딥러닝 모델에 입력할 수 있다. 이때, 실시예에 따른 세그멘테이션 딥러닝 모델은, 복수의 구강 이미지 및 각 구강 이미지별 구강정보를 포함하 는 트레이닝 데이터 셋(Training data set)을 기초로 기 학습될 수 있다. 그리하여 세그멘테이션 딥러닝 모델은, 소정의 구강 이미지를 입력 데이터로 하고, 입력된 구강 이미지 내 각각 의 객체(예컨대, 마진라인, 각 치아, 치은(잇몸), 입천장, 입바닥, 혀, 볼, 입술 또는 기타 등)를 물리적 의미 단위로 구분하여 속성(실시예에서, 라벨 및/또는 보철타입)에 따라 라벨링한 이미지(라벨링 이미지)를 출력 데 이터로 할 수 있다. 따라서 세그멘테이션 딥러닝 모델에 제3 구강 이미지를 입력한 애플리케이션은, 제3 구강 이미지를 입력받 은 세그멘테이션 딥러닝 모델로부터 제3 구강 이미지에 기초한 라벨링 이미지를 획득할 수 있다. 또한, 실시예에서 애플리케이션은, 획득된 라벨링 이미지를 기초로 모델링 이미지를 획득할 수 있다. (S207) 여기서, 실시예에 따른 모델링 이미지란, 3차원 구강모델을 생성할 시 사용되는 소정의 구강 이미지를 의미할 수 있다. 도 15는 본 발명의 실시예에 따른 라벨링 이미지를 기초로 모델링 이미지를 획득하는 방법을 설명하기 위한 도 면의 일례이다. 자세히, 도 15를 참조하면, 실시예에서 애플리케이션은, 라벨링 이미지(LI)가 포함하는 객체별 라벨링 정 보와 상술된 S201 단계에서 기 설정된 스캔 대상객체(STO) 및/또는 스캔 제외객체(SEO)를 상호 비교할 수 있다. 또한, 실시예에서 애플리케이션은, 비교의 결과로 스캔 대상객체(STO)와 대응되는 라벨링 정보를 가지는 객체(이하, 타겟객체)를 검출할 수 있다. 이때 애플리케이션은, 검출된 타겟객체의 라벨링 정보를 라벨링 이미지(LI) 내 해당 타겟객체가 포함하는 픽셀에 매칭하여 저장 및 관리할 수 있다. 또한, 실시예에서 애플리케이션은, 비교의 결과로 스캔 제외객체(SEO)와 대응되는 라벨링 정보를 가지는 객체(이하, 배제객체)를 검출할 수 있다. 그리고 애플리케이션은, 검출된 배제객체가 포함하는 픽셀값을 라벨링 이미지(LI)로부터 제거할 수 있다. 즉 애플리케이션은, 유저 설정에 의해 스캔 대상에서 제외되는 객체를 라벨링 이미지(LI) 상에서 제거할 수 있다. 또한, 실시예에서 애플리케이션은, 비교의 결과로 스캔 대상객체(STO) 및 스캔 제외객체(SEO) 중 어느 객 체의 라벨링 정보와도 미대응하는 객체(이하, 열외객체)를 검출할 수 있다. 그리고 애플리케이션은, 검출된 열외객체가 포함하는 픽셀값을 라벨링 이미지(LI)로부터 제거할 수 있다. 즉 애플리케이션은, 스캔 시 고려 대상에서 제외되는 객체를 라벨링 이미지(LI) 상에서 제거할 수 있다. 그리하여 실시예에서 애플리케이션은, 라벨링 이미지(LI) 내에서 스캔 대상객체(STO)는 보존하고 스캔 제 외객체(SEO) 및 그 외 객체는 제거한 상태의 이미지인 모델링 이미지(MI)를 획득할 수 있다. 또한, 실시예에서 애플리케이션은, 획득된 모델링 이미지(MI)를 기초로 3차원 라벨링 구강모델을 생성 및 제공할 수 있다. (S209) 여기서, 실시예에 따른 3차원 라벨링 구강모델이란, 구강정보를 포함하는 3차원 구강모델을 의미할 수 있다. 즉 실시예에서 3차원 라벨링 구강모델은, 해당하는 3차원 구강모델 내 객체별 엣지 정보 및 라벨링 정보를 포함 할 수 있다. 도 16은 본 발명의 실시예에 따른 3차원 라벨링 구강모델을 설명하기 위한 도면의 일례이다. 자세히, 도 16을 참조하면, 실시예에서 애플리케이션은, 소정의 알고리즘을 이용하여 모델링 이미지(MI)에 기초한 3차원 구강모델을 생성할 수 있다. 즉 애플리케이션은, 유저가 스캔하고자 하는 대상(즉, 타겟객체)을 포함하고 나머지 객체(즉, 배제객체 및 /또는 열외객체)를 불포함하는 3차원 구강모델을 생성할 수 있다. 이때, 다시 말하자면 애플리케이션은, 개시된 다양한 알고리즘을 이용하여 소정의 구강 이미지에 기초한 3 차원 구강모델을 생성할 수 있으며, 본 발명의 실시예에서는 상기 알고리즘 자체를 한정하거나 제한하지 않는다. 이와 같이 애플리케이션은, 학습된 딥러닝 모델을 통해 구강 이미지 내 객체를 구분 및 라벨링하고, 라벨 링된 객체 중 유저가 스캔하고자 하는 대상을 선별적으로 추출하고, 추출된 스캔 대상에 대한 3차원 구강모델을 생성해 제공할 수 있다. 그리하여 애플리케이션은, 유저 니즈(needs)에 따른 맞춤형 3차원 구강모델을 빠르고 간편하게 높은 정확 도로 자동 구축하여 제공할 수 있다. 또한, 실시예에서 애플리케이션은, 생성된 3차원 구강모델 내 복셀에 대하여 상기 복셀에 대응되는 모델링 이미지(MI) 내 픽셀에 매칭된 라벨링 정보(실시예에서, 라벨 카테고리 및/또는 보철타입 카테고리)를 매칭할 수 있다. 즉 애플리케이션은, 생성된 3차원 구강모델 상에 모델링 이미지(MI)가 포함하는 객체(즉, 타겟객체)에 대 한 구강정보를 매칭할 수 있다. 그리하여 실시예에서 애플리케이션은, 모델링 이미지(MI) 내 타겟객체별 구강정보(즉, 엣지 정보 및 라벨 링 정보)를 포함하는 3차원 라벨링 구강모델을 생성할 수 있다. 도 17은 본 발명의 실시예에 따른 3차원 라벨링 구강모델을 제공하는 방법을 설명하기 위한 도면의 일례이다. 또한 실시예에서 애플리케이션은, 생성된 3차원 라벨링 구강모델을 제공할 수 있다. 이때, 실시예에서 애플리케이션은, 시멘틱 세그멘테이션을 통하여 구분된 각 객체별로 구강정보(즉, 엣지 정보 및 라벨링 정보)를 제공할 수 있다. 예를 들면 애플리케이션은, 3차원 라벨링 구강모델 내 마진라인, 각 치아 및 치은(잇몸)별로 구분하여 구 강정보를 제공할 수 있다. 즉 애플리케이션은, 3차원 라벨링 구강모델 내 각각의 객체 영역을 의미 있는 단위로 자동 구분하고, 구분 된 객체 영역별 대응되는 구강정보를 제공할 수 있다. 따라서 애플리케이션은, 3차원 구강모델 내 각각의 객체를 보다 직관적으로 용이하게 파악할 수 있는 유저 인터페이스를 구현할 수 있다. 또한, 실시예에서 애플리케이션은, 라벨기반 복합해상도 스캔모드를 제공할 수 있다. (S211) 도 18은 본 발명의 실시예에 따른 라벨기반 복합해상도 스캔모드를 기초로 생성된 3차원 복합해상도 구강모델을 제공하는 방법을 설명하기 위한 도면의 일례이다. 여기서, 도 18을 참조하면, 실시예에 따른 라벨기반 복합해상도 스캔모드란, 라벨링 정보를 기초로 관심영역 (AOI)을 설정하고, 설정된 관심영역(AOI)을 기초로 3차원 복합해상도 구강모델을 제공하는 스캔모드를 의미할 수 있다. 이때, 실시예에서 라벨기반 복합해상도 스캔모드를 기초로 제공되는 3차원 복합해상도 구강모델(이하, 3차원 라 벨링 복합해상도 구강모델)은, 3차원 라벨링 구강모델의 특성을 더 포함할 수 있다. 즉, 실시에에서 3차원 라벨링 복합해상도 구강모델은, 라벨링 정보를 기초로 설정된 관심영역(AOI)은 상대적 고 해상도로 표시하고 나머지 영역은 상대적 저해상도로 표시하는 3차원 라벨링 구강모델을 의미할 수 있다. 자세히, 실시예에서 애플리케이션은, 관심영역(AOI) 설정 인터페이스에 기초한 유저 입력을 토대로 관심 라벨정보를 획득할 수 있다. 여기서, 실시예에 따른 관심 라벨정보란, 3차원 저해상도 구강모델 상에서 보다 정밀한 디지털 인상채득 정보를 획득하고자 하는 영역(즉, 관심영역(AOI))에 대응되는 라벨링 정보를 의미할 수 있다. 예시적으로 애플리케이션은, '마진라인, 각 치아, 치은(잇몸), 입천장, 입바닥, 혀, 볼 또는 입술' 중 어 느 하나의 라벨 카테고리를 관심 라벨정보로 획득할 수 있다. 또한, 실시예에서 애플리케이션은, 전술된 S203 및 S205 단계를 수행할 수 있다. 이에 대한 자세한 설명은 각 단계에서 기술된 설명을 준용한다. 그리하여 애플리케이션은, 소정의 라벨링 이미지(LI)를 획득할 수 있다. 또한, 실시예에서 애플리케이션은, 획득된 라벨링 이미지(LI)를 기초로 S209 단계를 수행할 수 있다. 이에 대한 자세한 설명은 각 단계에서 기술된 설명을 준용한다. 그리하여 애플리케이션은, 라벨링 이미지(LI)에 기초한 3차원 라벨링 구강모델(여기서, 3차원 저해상도 구 강모델에 대응)을 생성할 수 있다. 또한, 실시예에서 애플리케이션은, 생성된 3차원 라벨링 구강모델이 포함하는 객체별 라벨링 정보 중 관심 라벨정보에 대응되는 라벨링 정보를 가지는 객체(이하, 라벨객체)를 검출할 수 있다. 또한, 실시예에서 애플리케이션은, 검출된 라벨객체가 포함하는 복셀영역을 관심영역(AOI)으로 설정할 수 있다. 또한, 실시예에서 애플리케이션은, 설정된 관심영역(AOI)을 기초로 전술된 S107 및 S109 단계를 수행할 수 있다. 이에 대한 자세한 설명은 각 단계에서 기술된 설명을 준용한다. 그리하여 실시예에서 애플리케이션은, 라벨링 정보를 기초로 설정된 관심영역(AOI)을 고해상도로 표시하고, 나머지 영역을 기존의 저해상도로 표시하는 3차원 라벨링 복합해상도 구강모델을 제공할 수 있다. 이때 상기 제공되는 3차원 라벨링 복합해상도 구강모델은, 3차원 라벨링 구강모델을 기반으로 구현되었으므로, 상기 3차원 복합해상도 구강모델 내 각각의 객체 영역을 의미 있는 단위로 자동 구분하고, 구분된 객체 영역별 대응되는 구강정보(즉, 엣지 정보 및 라벨링 정보)를 제공할 수 있다. 이처럼 애플리케이션은, 3차원 저해상도 구강모델에 대한 유저 입력에 따라서 관심영역(AOI)을 설정할 수 있을 뿐만 아니라, 특정 라벨(예컨대, 마진라인, 각 치아, 치은(잇몸), 입천장, 입바닥, 혀, 볼 또는 입술 등) 을 이용한 유저 입력을 통해서도 관심영역(AOI)을 설정할 수 있고, 설정된 관심영역(AOI)에 따른 3차원 복합해 상도 구강모델 및/또는 3차원 라벨링 복합해상도 구강모델을 제공할 수 있다. 다시 말해서 애플리케이션은, 유저가 세밀한 영역지정 입력을 통하여 관심영역(AOI)을 설정하게 할 수도 있고 간편한 라벨 입력을 통하여 관심영역(AOI)을 설정하게 할 수도 있으며, 이들 중 어떠한 방식에 따라서 설 정된 관심영역(AOI)에 따른 3차원 복합해상도 구강모델(3차원 라벨링 구강모델의 특성 포함 가능)을 제공할 수 있다. 이와 같이 애플리케이션은, 다각적 방법으로 타 영역 대비 고해상도로 스캔하고자 하는 관심영역(AOI)을 설정 가능하게 하여, 유저가 다양한 방식들 중 자신이 원하는 방식을 선택적으로 사용해 보다 편리하게 관심영 역(AOI)을 각기 지정하게 할 수 있고, 이에 따라 3차원 구강모델 제공 서비스에 대한 유저 편의성 및 만족도를 더욱 향상시킬 수 있다. 이상, 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템은, 학습된 딥러 닝 뉴럴 네트워크(Deep-learning Neural Network)를 이용하여 2차원 구강 이미지 내 객체를 라벨링하고, 라벨링 된 객체 중 적어도 일부를 기초로 3차원 구강모델을 제공함으로써, 2차원 구강 이미지 내 유저가 스캔하고자 하 는 대상을 기계적 알고리즘을 이용해 자동 선별할 수 있고, 선별된 스캔 대상에 특화된 3차원 구강모델을 생성 해 제공할 수 있다. 따라서 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템은, 유저 니즈 (needs) 맞춤형의 3차원 구강모델을 자동화된 방식으로 빠르고 간편하게 높은 정확도로 구축하여 제공할 수 있 는 효과가 있다. 또한, 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델 제공 방법 및 시스템은, 딥러닝을 기 초로 3차원 구강모델 내 각각의 객체 영역을 의미 있는 단위로 자동 구분하고, 구분된 객체 영역별로 대응되는 구강정보를 제공함으로써, 제공되는 3차원 구강모델 내 각각의 객체를 보다 직관적으로 용이하게 파악할 수 있 는 유저 인터페이스를 구현할 수 있는 효과가 있다. 한편, 이상에서 설명된 본 발명에 따른 실시예는 다양한 컴퓨터 구성요소를 통하여 실행될 수 있는 프로그램 명 령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체 는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판 독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에 는, 컴파일러에 의하여 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해 서 실행될 수 있는 고급 언어 코드도 포함된다. 하드웨어 장치는 본 발명에 따른 처리를 수행하기 위하여 하나 이상의 소프트웨어 모듈로 변경될 수 있으며, 그 역도 마찬가지이다. 본 발명에서 설명하는 특정 실행들은 일 실시 예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “필 수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소 가 아닐 수 있다.또한 설명한 본 발명의 상세한 설명에서는 본 발명의 바람직한 실시 예를 참조하여 설명하였지만, 해당 기술 분"}
{"patent_id": "10-2023-0084141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "야의 숙련된 당업자 또는 해당 기술분야에 통상의 지식을 갖는 자라면 후술할 특허청구범위에 기재된 본 발명의 사상 및 기술 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 기술적 범위는 명세서의 상세한 설명에 기재된 내용으로 한정되는 것이 아 니라 특허청구범위에 의해 정하여져야만 할 것이다."}
{"patent_id": "10-2023-0084141", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는 시스템의 개념도이다. 도 2는 본 발명의 실시예에 따른 콘솔 디바이스의 내부 블록도이다. 도 3은 본 발명의 실시예에 따른 구강 스캐너의 개략적인 구조를 도시한 도면이다. 도 4는 본 발명의 실시예에 따른 구강 스캐너의 구성요소를 도시한 도면이다. 도 5는 본 발명의 실시예에 따른 저해상도 영역과 고해상도 영역을 포함하는 3차원 구강모델 제공 방법을 설명 하기 위한 흐름도이다. 도 6은 본 발명의 실시예에 따른 3차원 저해상도 구강모델을 설명하기 위한 도면의 일례이다. 도 7은 본 발명의 실시예에 따른 관심영역을 설정하는 방법을 설명하기 위한 도면의 일례이다. 도 8 및 도 9는 본 발명의 실시예에 따른 3차원 복합해상도 구강모델을 생성하는 방법을 설명하기 위한 도면의 일례들이다. 도 10 및 도 11은 본 발명의 실시예에 따른 3차원 복합해상도 구강모델을 제공하는 방법을 설명하기 위한 도면 의 일례들이다. 도 12는 본 발명의 실시예에 따른 딥러닝을 기초로 라벨링된 3차원 구강모델을 제공하는 방법을 설명하기 위한 흐름도이다. 도 13은 본 발명의 실시예에 따른 라벨링 이미지를 설명하기 위한 도면의 일례이다. 도 14는 본 발명의 실시예에 따른 구강 이미지를 기초로 시멘틱 세그멘테이션을 수행한 모습의 일례들이다. 도 15는 본 발명의 실시예에 따른 라벨링 이미지를 기초로 모델링 이미지를 획득하는 방법을 설명하기 위한 도 면의 일례이다. 도 16은 본 발명의 실시예에 따른 3차원 라벨링 구강모델을 설명하기 위한 도면의 일례이다. 도 17은 본 발명의 실시예에 따른 3차원 라벨링 구강모델을 제공하는 방법을 설명하기 위한 도면의 일례이다. 도 18은 본 발명의 실시예에 따른 라벨기반 복합해상도 스캔모드를 기초로 생성된 3차원 복합해상도 구강모델을 제공하는 방법을 설명하기 위한 도면의 일례이다."}
