{"patent_id": "10-2024-7028676", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0141808", "출원번호": "10-2024-7028676", "발명의 명칭": "기계 학습 작업을 수행하기 위한 신경 네트워크 훈련", "출원인": "피터센 리서치, 엘엘씨", "발명자": "피터센 펠릭스"}}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 분류와 같은 기계 학습 작업을 수행하기 위해 신경 네트워크를 훈련하기 위한 컴퓨터 구현 방법으로, 상기 방법은:상기 신경 네트워크에 대한 입력 데이터를 수신하는 단계 (S201);상기 신경 네트워크의 복수의 하이퍼파라미터들에 대한 값들을 결정하는 단계 (S203);상기 하이퍼파라미터 값들에 따라 상기 신경 네트워크를 구축하는 단계 (S205) - 여기에서 상기 신경 네트워크는 복수의 뉴런들(1.1 내지 3.4)을 포함함, 여기에서, 각 뉴런(1.1 내지 3.4)은 복수의 논리 연산자들에 대한 확률 분포를 포함하며, 그래서 상기 뉴런(1.3내지 3.4)이 상기 논리 연산자들 각각에 대한 대응 확률을 포함함 -,각 뉴런(1.3 내지 3.4)의 확률 분포를 학습하여 상기 하이퍼파라미터 값들 및 상기 입력 데이터에 따라 상기 신경 네트워크를 학습시키는 단계 (S207); 그리고상기 확률 분포에서 값을 선택하여 각 뉴런(1.3 내지 3.4)에 대한 복수의 논리 연산자들 중의 논리 연산자를 결정하는 단계 (S209)를 포함하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 입력 데이터는 입력들 및 대응하는 원하는 출력들을 포함하며, 상기 입력 데이터는: 훈련 데이터, 검증 데이터 및 테스트 데이터 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 하이퍼파라미터 값들은 하나 이상의 지정된 계산 리소스 제약들 하에 상기 신경 네트워크의 검증 오류를최소화하도록 결정되며, 상기 지정된 계산 리소스 제약들에는 프로세서 및/또는 메모리 제약들이 포함될 수 있는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "이전 항들 중 어느 한 항에 있어서, 상기 하이퍼파라미터들은: 계층당 뉴런들, 계층들의 수, 에포크(epoch)들의 수, 배치(batch) 크기 및 학습 레이트 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "이전 항들 중 어느 한 항에 있어서, 상기 신경 네트워크는 출력 계층(107)을 포함하는 다수의 계층들을 포함하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 출력 계층(107)은 n개의 뉴런들을 포함하고, 상기 기계 학습 작업은 k개의 클래스들을 구비한 분류 작업이며, 상기 방법은 훈련된 신경 네트워크를 사용하여 상기 분류 작업을 수행하는 단계를 더 포함하며, 상기 수행 단계공개특허 10-2024-0141808-3-는:상기 훈련된 신경 네트워크에 의해 상기 클래스들 각각에 대한 분류 점수를 출력하는 단계;상기 출력을 크기 인 k개 그룹들로 그룹화하는 단계 - 여기에서 각 그룹 내 1의 개수는 그 그룹에 대응하는클래스에 대한 분류 점수에 대응함 -; 분류를 결정하는 단계를 포함하며, 여기에서 상기 분류를 결정하는 단계는 상기 분류 점수들의 최대를 결정하는단계를 포함하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "이전 항들 중 어느 한 항에 있어서, 상기 신경 네트워크를 훈련시킨 후 기계 학습 작업을 수행하기 전에 상기방법은:상기 훈련된 신경 네트워크를 중앙 처리 유닛 또는 그래픽 처리 유닛에서 실행 가능한 바이너리(binary)로 변환하는 단계를 더 포함하며,여기에서 상기 실행 가능한 바이너리는 공유 객체 바이너리들을 처리할 수 있는 프로그램을 통해 호출가능하며, 상기 프로그램은 Python으로 작성될 수 있는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "이전 항들 중 어느 한 항에 있어서, 각 뉴런의 출력들은 0 내지 1 범위의 값들이며, 그리고/또는각 뉴런은 0 내지 3개의 입력을 수신하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "이전 항들 중 어느 한 항에 있어서, 상기 신경 네트워크를 구축하는 단계는 상기 뉴런들 간의 연결을 의사-랜덤으로 초기화하는 단계를 추가로 포함하며;훈련하는 동안, 뉴런들 간의 연결들은 고정되어 유지될 수 있는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "이전 항들 중 어느 한 항에 있어서, 상기 기계 학습 작업은 분류 작업이며, 이 분류 작업은: 이진 분류, 패턴 인식, 이미지 분류, 객체 식별 또는 인식, 문자 인식, 제스처 또는 얼굴 인식, 음성 검출 또는음성 인식, 텍스트 분류 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "이전 항들 중 어느 한 항에 있어서, 상기 기계 학습 작업은 회귀 작업이며, 여기에서 상기 회귀 작업은:이미지 생성, 텍스트 생성, 비디오 생성, 음성 생성, 3D 재구성, 압축, 인코딩 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "이전 항들 중 어느 한 항에 있어서, 상기 복수의 논리 연산자들은 최소한 2개의 연산자들 또는 정확하게 16개의 연산자들을 포함하며; 상기 복수의 논리 연산자들은 실수 값 연산자들일 수 있으며; 상기 실수 값 연산자들은: 확률적 해석, 하마허 t-노름(norm) 해석, 상대론적 아인슈타인 합 t-코노름(conorm)해석, 루카시에비츠 t-코노름 해석 및 t-코노름 해석 중 하나를 따를 수 있는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "이전 항들 중 어느 한 항에 있어서, 공개특허 10-2024-0141808-4-상기 입력 데이터는 복수의 샘플들을 갖는 테스트 데이터를 포함하며;추론 동안에, 상기 신경 네트워크의 제1 계층(103)에 의해 상기 테스트 데이터의 집계에 액세스함으로써 상기기계 학습 작업을 수행하며, 상기 액세스하는 것은 상기 테스트 데이터의 각 샘플의 요소들을 상기 정수들의 연속 비트들에 할당하는 것을 포함하며, 추론 동안에, 각 뉴런의 두 입력들은 기계 학습 작업이 수행될 컴퓨터의 프로세서의 하드웨어로 구현된 데이터유형에 대응하는 숫자형 데이터 유형을 갖는, 방법."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "명령어들을 포함하는 컴퓨터 프로그램으로, 상기 명령어들은 컴퓨터에 의해 실행될 때 상기 컴퓨터로 하여금 이전 항들 중 어느 한 항의 방법을 수행하도록 하는, 컴퓨터 프로그램."}
{"patent_id": "10-2024-7028676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "이미지 분류와 같은 기계 학습 작업을 수행하기 위해 신경 네트워크를 훈련하기 위한 컴퓨터 시스템으로, 상기시스템은:적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는:상기 신경 네트워크에 대한 입력 데이터를 수신하며;상기 신경 네트워크의 복수의 하이퍼파라미터들에 대한 값들을 결정하며;상기 하이퍼파라미터 값들에 따라 상기 신경 네트워크를 구축하며 - 여기에서 상기 신경 네트워크는 복수의 뉴런들(1.3 내지 3.4)을 포함함, 여기에서, 각 뉴런(1.3 내지 3.4)은 복수의 논리 연산자들에 대한 확률 분포를 포함하며, 그래서 상기 뉴런(1.3 내지 3.4)이 상기 논리 연산자들 각각에 대한 대응 확률을 포함함 -,각 뉴런(1.3 내지 3.4)의 확률 분포를 학습하여 상기 하이퍼파라미터 값들 및 상기 입력 데이터에 따라 상기 신경 네트워크를 학습시키며; 그리고상기 확률 분포에서 값을 선택하여 각 뉴런(1.3 내지 3.4)에 대한 복수의 논리 연산자들 중의 논리 연산자를 결정하도록 구성된, 컴퓨터 시스템."}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "기계 학습 작업을 수행하기 위해 신경 네트워크를 훈련하는 방법, 프로그램 및 시스템이 제공된다. 상기 방법은 신경 네트워크에 대한 입력 데이터를 수신하는 단계를 포함한다. 이 방법은 신경 네트워크의 복수의 하이퍼파라 미터에 대한 값을 결정하는 단계를 또한 포함한다. 이 방법은 하이퍼 파라미터 값에 따라 신경 네트워크를 구축 하는 단계를 또한 포함하며, 여기에서 신경 네트워크는 복수의 뉴런을 포함한다. 각 뉴런은 복수의 논리 연산자 에 대한 확률 분포를 포함하며, 그래서 뉴런이 각 논리 연산자에 대한 대응 확률을 포함하도록 한다. 이 방법은 각 뉴런의 확률 분포를 학습하여 하이퍼 파라미터 값과 입력 데이터에 따라 신경 네트워크를 훈련하는 단계를 또 한 포함한다. 이 방법은 확률 분포에서 값을 선택하여 각 뉴런의 복수의 논리 연산자 중 하나의 논리 연산자를 결정하는 단계를 또한 포함한다."}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 기술 분야는 인공지능, 특히 신경 네트워크이다. 본 발명 측면들은 기계 학습 작업을 수행하기 위해 신경 네 트워크를 훈련하는 것과 관련이 있다. 상기 기계 학습 작업은 분류 작업일 수도 있고 회귀 작업일 수도 있다. 분류 작업에는 다음 중 하나 이상이 포함될 수 있다: 패턴 및/또는 시퀀스 인식, 신규성 검출(예: 이상치 또는 이상 감지), 순차적 의사 결정. 회귀 작업에는 압축이나 압축 해제가 포함될 수 있다. 또한, 이러한 측면은 훈 련된 신경 네트워크를 사용하여 기계 학습 작업을 수행하는 것과 관련될 수 있다."}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "신경 네트워크는 인공 뉴런(즉, 뉴런, 노드, 계산 유닛, 또는 유닛들)을 포함할 수 있으며 인공 지능 문제를 해 결하는 데 사용될 수 있다. 뉴런들 간의 연결은 신경 네트워크에서 가중치들로서 모델화될 수 있다. 신경 네트 워크에는 파라미터가 포함될 수 있는데, 이 파라미터는 훈련이 가능한 신경 네트워크의 컴포넌트 또는 요소이다. 예를 들어, 가중치는 일부 신경 네트워크의 파라미터가 될 수 있다. 하지만 다른 파라미터도 가능하 다. 활성화 함수를 사용하면 신경 네트워크 출력의 진폭을 제어할 수 있다. 따라서 활성화 함수는 신경 네트워크의 출력 값을 제한하고 신경 네트워크에 비선형성을 추가하기 위해 사용될 수 있다. 신경 네트워크는 최적화 알고리즘을 사용하여 훈련될 수 있다. 훈련에는 신경 네트워크가 충분히 정확해질 때까 지 신경 네트워크의 파라미터들을 조정하는 작업이 포함될 수 있다. 최적화 알고리즘은 경사 하강법을 기반으로 할 수 (또는 이에 의존할 수도) 있다. 경사 하강법을 기반으로 하는 최적화 알고리즘의 예로는 확률적 경사 하강법(Stochastic Gradient Descent, SGD)과 Adam (adaptive learning rate optimization algorithm) (적응 학 습률 최적화 알고리즘 - 평균 제곱근 전파와 모멘텀을 갖춘 SGD를 조합하여 구현됨)이 있다. Adam에 대한 자세 한 내용은 \"Adam : A method for stochastic optimization\", Kingma et. al., 2014에서 확인할 수 있다. 경사 하강법은 역전파(backpropagation, 즉, 백드롭 또는 후방 전파)를 기반으로 할 수 있다. 경사 하강법에는, 파라미터의 정확도를 측정하고 파라미터 변경이 네트워크를 개선하는 방향, 즉, 그래서 파라미터를 개선될 수 있도록 하는 방향을 판단하는 비용 함수가 포함될 수 있다. 비용 함수의 출력이 0이거나, 최소값이거나, 또는 0 의 지정된 범위 내에 있을 때 충분한 정확도가 획득될 수 있다. 상기 지정된 범위는 기계 학습 작업에 따라 달 라질 수 있다. 어떤 경우에는, 경사 하강법 (또는 경사 하강법을 기반으로 하는 알고리즘)은 미분 가능한 파라 미터를 갖는 신경 네트워크를 훈련하는 데만 사용할 수 있으며, 그래서 이진 또는 부울(Boolean) 파라미터들은 경사 하강법을 통해 훈련될 수 없다. 부울 파라미터(신경 네트워크에서 0 또는 1로 표현)는 불연속성(예: 0에서 1로 점프)으로 이어질 수 있으며, 이 경우 기울기가 정의되지 않으며 경사 하강법이 불가능하다. 신경 네트워크의 정확도는 다양한 방법으로 계산될 수 있다. 예를 들어, 분류 작업의 맥락에서, 훈련 오류 (또 는 손실)는 신경 네트워크를 훈련하기 위해 사용된 데이터를 신경 네트워크가 얼마나 정확하게 분류할 수 있는 지 측정하여 얻을 수 있다. 분류 손실 (일반화 오류 또는 예상 손실이라고도 함)은 신경 네트워크가 이전에 보 지 못한 데이터에 대해 분류 작업을 얼마나 정확하게 수행할 수 있는지 측정하여 얻을 수 있다. 어떤 경우, 신경 네트워크는 여러 개의 계층, 즉 최소한 하나의 은닉 계층과 출력 계층을 포함할 수 있다. 이런 경우, 신경 네트워크는 심층 학습 (deep learning) 신경 네트워크라고 언급될 수 있으며, 은닉 계층들의 개수는 무제한일 수 있다. 따라서 여러 계층을 사용하여 입력으로부터 점진적으로 상위 수준의 기능들이 추출될 수 있 다. 신경 네트워크는 데이터가 루프백 없이 이전 은닉 계층에서 출력 계층으로 흐르는 피드포워드 네트워크로서 구현될 수 있다. 신경 네트워크 초기화에는 뉴런들 간 연결에 임의의 가중치를 할당하는 것이 포함될 수 있다. 기존에는 신경 네트워크가 기계 학습 작업을 정확하게 수행하지 못할 경우 가중치들이 조정되었다. 이런 식으로, 기계 학습 작업을 수행하기 위한 입력에 대한 적절한 수학적 조작이 결정될 때까지 네트워크 내 다양한 뉴런들의 영향이 보정될 수 있다. 일단 기계 학습 작업을 수행하도록 훈련이 완료되면, 신경 네트워크를 사용하여 기계 학습 작업이 수행될 수 있 다. 기계 학습 작업을 수행하는 것을 추론 또는 추론 수행이라고도 언급될 수 있다. 신경 네트워크는 다양한 문제에 직면한다. 예를 들어, 훈련 오차가 낮지만 분류 손실이 상대적으로 높은 경우 과도적합(overfitting)이 발생할 수 있다. 즉, 신경 네트워크는 그 신경 네트워크를 훈련하는 데 사용된 훈련 데이터에 특화된 접근법을 학습하는데, 이는 상기 훈련 데이터와 다른 데이터에는 잘 일반화되지 않는다. 신경 네트워크가 자신의 입력과 자신의 출력 간의 관계를 정확하게 포착할 수 없으면 과소적합(underfitting)이 발생 할 수 있으며, 이로 인해 훈련 데이터와 기타 데이터 모두에서 높은 오류 비율이 발생한다. 신경 네트워크는 분류 작업을 수행하는 데 효과적일 수 있지만, 비효율적일 수도 있다. 따라서 신경 네트워크의 효율성을 높이기 위한 다양한 접근 방식이 개발되었다. 예를 들어, 기존의 신경 네트워크는 적어도 하나의 밀집 (dense) 계층을 포함하는 심층 학습 신경 네트워크일 수 있으며, 그래서 신경 네트워크의 일부 또는 전체가 완전히 연결되도록 하며; 즉, 밀집 계층 내 각 뉴런은 이 전 계층의 모든 뉴런들에 대한 입력을 수신한다. 이 예에서, 상기 신경 네트워크는 밀집 연결 (densely connected) 신경 네트워크 또는 완전 연결 (fully connected) 신경 네트워크로도 언급될 수 있다. 또한, 기존의 신경 네트워크는 전체 정밀도 가중치와 활성화(예: 배정밀도, 즉 64비트)를 갖춘 부동 소수점 계 산을 사용할 수 있으며, 일반적으로 비용이 많이 드는 행렬 곱셈을 필요로 한다. 낮은 정밀도의 부동 소수점 가 중치와 활성화(예: 단정밀도 또는 반정밀도)를 사용하더라도 계산에는 여전히 비용이 많이 들 수 있다. 이진 신경 네트워크는, 1비트 활성화 (및/또는 가중치)가 기존 신경 네트워크의 부동 소수점 활성화 (및/또는 가중치)를 대체한다는 점에서 기존 신경 네트워크와 다를 수 있다. 따라서, 예를 들면 0이나 1과 같이 두 가지 값 중 하나만 가질 수 있다는 점에서, 네트워크를 통해 전파되는 요소들은 이진수이다. 따라서 기존 신경 네트 워크와 비교했을 때, 비용이 많이 드는 행렬 곱셈이 더 빠른 XNOR 및 비트 카운트 연산으로 단순화될 수 있으며, 이는 이진 신경 네트워크의 추론 성능을 기존 신경 네트워크에 비해 크게 향상시킨다. 어떤 경우에는, XNOR가 비트 카운트 연산보다 빠를 수 있으며, 둘 다 부동 소수점 연산보다 빠를 수 있다. 신경 네트워크를 훈련하는 데 필요한 부동 소수점 연산은 컴퓨터 하드웨어에서 지원될 수 있다. 구체적으로, float32 덧셈기 및/또는 float32 곱셈기는 최소 1,000개의 논리 게이트 (또는 룩업 테이블)를 필요로 할 수 있 으며 수십 개의 논리 레벨에 대한 지연이 있을 수 있다. float32 덧셈기 및/또는 float32 곱셈기는 중앙 처리 유닛 (CPU) 또는 그래픽 처리 유닛치(GPU)에서 직접 구현될 수 있다. 그럼에도 불구하고 float32 덧셈기와 float32 곱셈기는, 심지어는 float32 및 int32 데이터 유형에 최적화된 GPU에서도 int64 데이터 유형에 대한 비 트 논리 연산보다 훨씬 더 많은 계산 리소스(예: 처리 주기)를 필요로 할 수 있다. GPU가 int32에 최적화된 경 우 int64는 효율적으로 지원되지 않을 수도 있을 것이다. 따라서 이러한 GPU에서는 int32 데이터 유형을 사용하 는 것이 더 효율적일 수 있다. 일부 하드웨어 구현에서는, 논리 연산이 덧셈 및/또는 곱셈 연산보다 더 빠를 수 있다. CPU에서, 클록 사이클당 약 3~10개의 int64 비트 연산이 수행될 수 있는 반면, 부동 소수점 연산에는 일반적으 로 전체 클록 사이클을 필요로 한다 (즉, 클록 사이클당 부동 소수점 연산 하나만이 수행될 수 있음). 따라서 이진 신경 네트워크를 훈련할 때 수행되는 XNOR 및 비트 카운트 연산은, 부동 소수점 연산 (예: float32 덧셈기 나 float32 곱셈기)이 GPU나 CPU에서 특수한 하드웨어 지원을 받는 경우에도 기존 신경 네트워크를 위해 수행되 는 부동 소수점 연산과 비교해 상당한 성능상의 이점을 가질 수 있다. 부동 소수점 및 정수 연산에 대한 고려 사항은 기계 학습 작업을 위해 신경 네트워크를 훈련하는 데에도 적용될 수 있다. 컨벌루션 신경 네트워크(convolutional neural network, CNN)는 적어도 하나의 은닉 계층이 구조화된 연결을 가 지고 있는, 즉 완전히 연결되지 않은 심층 학습 신경 네트워크일 수 있다. 따라서 CNN은 컨벌루션(convolutio n)을 수행할 수 있으며, 예를 들어, 은닉 계층은 컨벌루션 커널과 은닉 계층의 입력 행렬의 내적을 수행한다. 따라서 CNN에서 컨벌루션 커널로 덮인 은닉 계층의 뉴런들만이 CNN 내 다른 계층의 해당 뉴런에 연결될 수 있다. 기존의 예에서 이진 신경 네트워크는 매우 깊은 컨벌루션 신경 네트워크(예: VGG) 아키텍처를 기반으로 할 수 있으며, 이는 매우 작은(3x3) 컨벌루션 필터를 통해 깊이를 늘리고, 3개의 완전히 연결된 계층들을 포함하고, ReLU (rectification nonlinearity) (정류 비선형성)를 사용하여 학습 시간을 단축한다. 또는 이진 신경 네트 워크는, 일부 계층을 건너뛰기 위해 스킵 연결을 사용하는 잔여 신경 네트워크(residual neural network, ResNet) 아키텍처를 기반으로 할 수 있다. VGG와 ResNet 아키텍처는 모두 매우 큰 신경 네트워크의 결과를 가져 올 수 있으며, 이는 비효율성을 초래할 수 있다. 신경 네트워크는 희소(sparse)할 수 있다(이 예에서는 희소 신경 네트워크). 따라서, 희소 신경 네트워크는 완 전 연결 신경 네트워크 연결의 적절한 서브세트를 갖는다. 즉, 완전히 연결된 계층 대신, 희소 신경 네트워크의 계층 내 모든 뉴런이 서로 연결되어 있지 않다. 희소성은 신경 네트워크의 연결성을 나타내며, 그래서 각 뉴런 이 제한된 수의 다른 뉴런으로부터만 입력을 받을 수 있으며, 그리고/또는 신경 네트워크의 상태를 나타낼 수 있으며, 이는 그 신경 네트워크에 있는 모든 뉴런의 활동 수준을 기술하여, 희소 신경 네트워크에 있는 모든 뉴 런이 주어진 시간에 활성화되지 않도록 한다. 희소 신경 네트워크는 완전 연결 신경 네트워크의 연결 수의 90% 미만을 가질 수 있으며, 즉, 희소 신경 네트워 크는 최소 10%의 희소성을 가질 수 있다 (10%~70% 사이의 희소성은 낮은 희소성, 70%~90% 사이의 희소성은 중간 희소성, 90%~99.9% 사이의 희소성은 중간 희소성, 99.9% 이상의 희소성은 높은 희소성이라고 할 수 있다). 10% 미만의 희소성을 갖는 신경 네트워크는 밀집된 신경 네트워크라고 할 수 있다. 희소 신경 네트워크는 가지치기(pruning)나 압축 기술, 예를 들면, 정규화 기술을 사용하여 밀집 연결 신경 네 트워크나 완전 연결 신경 네트워크에서 파생될 수 있다. 예를 들어, 하나 이상의 분석 방법이나 휴리스틱을 사 용하여 신경 네트워크에서 유지해야 할 가중치와 제거해야 할 가중치를 결정할 수 있다 (가중치를 제거하려면 가중치를 0으로 설정해야 할 수 있음). 보다 구체적으로, L1 또는 L2 정규화는 정규화 항을 추가하여 일반적인 비용 함수를 업데이트하는 데 사용될 수 있다. 또 다른 예로, 드롭아웃은 신경 네트워크 내의 랜덤 뉴런이 취소 되거나 제거되는 정규화 기술이다. 드롭아웃은 변형될 수 있으며 경계(예: 취소되는 뉴런의 수에 대한 제한)에 의해 제한될 수 있다. 어떤 경우에는, 가중치를 제거하는 대신 뉴런 자체를 신경 네트워크에서 제거할 수도 있 다. 위에 설명된 가지치기 기술은 과도적합을 방지하는 데 도움이 되어 일반화 오류를 줄일 수 있다. 다른 기술 로는 신경 네트워크의 전체 계층을 제거하거나 신경 네트워크의 상대적으로 큰 가중치에 대한 추가 비용을 추가 하는 것이 있다. 따라서, 희소 신경 네트워크는 밀집 신경 네트워크에 비해 더 나은 정확도(예: 과도적합 감 소)를 제공할 수 있다. 희소 신경 네트워크는 밀집 신경 네트워크에 비해 더 적은 저장 공간을 필요로 할 수도 있다. 그러나 밀집 신경 네트워크에서 가중치를 제거하여 희소 신경 네트워크가 유도된 경우, 희소 신경 네트워 크는 실제 가중치에 추가로 가중치 위치를 저장하기 위해 더 많은 저장 공간을 필요로 할 수 있다. 다음 두 가지 기존 구현 예에서, 신경 네트워크의 연결성이 완화될 수 있다. 첫 번째 예에서, 신경 네트워크의 뉴런은 논리 모듈로 구현될 수 있는데, 이 경우 논리 모듈의 절반은 퍼지(즉, 완화된) 결합(conjunction)으로 정의되고 나머지 절반은 퍼지(즉, 완화된) 분리(disjunction)로 정의된다. 이 예에서, 신경 네트워크의 파라미터에는 가중치가 포함되는 반면 연산자(즉, 퍼지 결합 및 퍼지 분리)는 고정되 어 있다. 따라서 퍼지 결합과 분리에 포함되는 뉴런의 가중치는 0 또는 1부터 0 내지 1 범위 내 값들로 완화될 수 있다. 이런 방식으로 논리 모듈의 파라미터는 부울 파라미터와 달리 경사 하강법을 통해 학습될 수 있다. 두 번째 예에서, 각 계층에 대해 산술 연산들의 세트가 미리 정의되어 그 계층의 뉴런에 대해 구현된다. 소프트 맥스 형태는 학습에 사용되고, 이전 계층의 출력은 현재 계층에 대응하는 산술 연산의 입력으로 사용된다. 이런 방식으로 데이터로부터 상징적 표현이 학습될 수 있다. 또 다른 기존의 예에서, 인공 신경 네트워크의 완전 연결 계층은 훈련 전에 희소 계층으로 대체되어 정확도가 크게 떨어지지 않으면서도 (예: 정확도가 5% 이상 떨어지거나 10% 이상 떨어지지 않으면서) 파라미터의 개수를 이차식으로 (quadratically) 줄인다. 희소 토폴로지는 두 개의 연속된 계층을 가지고 있으며, 학습하는 동안 스 케일 없는 토폴로지로 진화된다. 스케일 없는 토폴로지는 거듭제곱 법칙 차수 분포 (power-law degree distribution) P(d) ~ d-y를 근사하는 희소 그래프이며, 여기에서 네트워크의 전체 뉴런 중 일부 P(d)는 다른 뉴런과 d개의 연결을 갖고 있으며 파라미터 γ는 일반적으로 γ ∈ (2, 3) 범위에 있다. 또 다른 기존 예에서는 단일 공유 가중치 파라미터가 신경 네트워크의 모든 연결에 할당된다. 가중치를 최적화 하는 대신, 신경 네트워크는 광범위한 가중치에 걸쳐서 좋은 성능을 보이는 네트워크 토폴로지에 맞춰 최적화된 다. 뉴런과 연결은 점진적으로 추가되고, 활성화 함수(예: sin, cosine, Gaussian, tanh, sigmoid, inverse, absolute value, ReLU)가 새로운 뉴런에 랜덤으로 할당된다. 활성화 함수는 신경 네트워크가 성장함에 따라 진 화한다. 신경 네트워크는 부동 소수점 연산자를 사용한다. 또 다른 기존 예에 따르면, 이진(2개 입력) 룩업 테이블들의 네트워크를 사용하여 이진 분류 데이터 세트를 기 억하는 방법이 제공된다. 룩업 테이블들의 네트워크는 훈련 데이터에서 조건부 빈도를 카운트함으로써 구축된다 (예: 훈련 데이터에서 패턴 p가 특정 출력 0과 연관된 횟수). 신경 네트워크처럼, 룩업 테이블은 연속적인 계층 들에 배열된다. 신경 네트워크와 달리 학습은 기억을 통해 이루어지며 역전파나 경사 하강을 수반하지 않는다. 기억은 훈련 데이터에서 입력과 가장 일반적으로 연관된 출력을 기억하는 것을 수반한다. 또 다른 전통적인 예로, 신경 네트워크는 먼저 기계 학습 작업에 관해 훈련을 받은 다음, 신경 네트워크는 랜덤 포레스트로 변환되고, 랜덤 포레스트는 다시 AND-인버터 논리 게이트의 네트워크로 변환되며, 즉, 네트워크는 \"AND\"와 \"NOT\" 논리 게이트를 기반으로 한다. 비슷한 정확도를 유지하면서도 위에서 설명한 기존의 예보다 더 효율적인 기계 학습 작업을 수행하기 위해 신경 네트워크를 제공하는 것이 바람직할 수 있다. 예를 들어, 논리 게이트 네트워크가 사용될 수 있다. 논리 게이트 네트워크는 각 뉴런이 논리 연산자 (즉, \"AND\"나 \"NAND\"와 같은 논리 게이트)를 포함하는 신경 네트워크일 수 있다. 각 논리 연산자는 0 내지 2개의 입 력을 가질 수 있다. 논리 게이트 네트워크는 완전 연결 신경 네트워크에 비해 희소하며, 완전 연결 신경 네트워 크에서 이전 계층의 모든 뉴런은 현재 계층의 각 뉴런에 입력으로 제공된다. 다시 말해서, 논리 게이트 네트워 크는 n개의 입력을 받지 않고(n은 계층당 뉴런 수), 논리 게이트 네트워크의 각 뉴런은 2개의 입력만 받기 때문 에 희소하다. 따라서, (예: 논리 연산이 종종 프로세서 아키텍처에 내장되어 있기 때문에) 논리 연산을 매우 빠 르게 계산할 수 있으므로, 기계 학습 작업을 효율적으로 수행할 수 있다. 또한 각 뉴런은 최대 2개의 입력을 가 지므로 논리 게이트 네트워크는 매우 희소하며, 예를 들어, 적어도 중간 정도의 희소성을 가지며, 이는 밀도가 높은 네트워크에 비해 향상된 정확도로 이끌 수 있다. 선택적으로, 논리 게이트 네트워크는 3개 이상의 입력을 갖는 최소한 하나의 연산자를 포함할 수 있다. 유리하게도, 논리 게이트 네트워크는 (예를 들어 훈련 후) 이진값에서 작동할 수 있고 비선형이기 때문에 활성 화 함수가 필요하지 않을 수 있다. 그러나 기존 논리 게이트 네트워크는 (위에서 설명된) SGD나 Adam과 같은 경사 하강법을 기반으로 한 최적화 알 고리즘을 사용하여 훈련될 수 없기 때문에 신경 네트워크를 논리 게이트 네트워크로 구현하는 데 문제가 있을 수 있다. 이는 기존 논리 게이트 네트워크에서의 값이 항상 0 또는 1이기 때문이다. 그래서, 네트워크의 계층의 파라미터에 대한 손실 함수에 미분이 없기 때문에 기존 논리 게이트 네트워크에서 기울기를 계산하는 것은 불가능하다. 따라서, 경사 하강법을 기반으로 최적화 알고리즘을 사용하여 훈련될 수 있는 논리 게이트 네트워크를 제공하는 것이 바람직할 수 있다. 더욱이, 기존의 논리 게이트 네트워크는 단일 이진 출력(예: 회귀 작업의 경우)이나 k개 클래스에 대한 k개 이 진 출력(예: 분류 작업의 경우)을 제공할 수 있다. 이는 등급별 예측, 즉 분류들을 서로에 대해 평가하는 것을 허용하지 않는다. 다시 말해, 이는 \"최대 활성화\" 분류 체계에 따른 분류를 허용하지 않는다 (\"How a Neural Network Works\", Arkin Gupta, 2018년 5월 27일)."}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "한 측면에 따르면, 기계 학습 작업을 수행하기 위해 신경 네트워크를 훈련하는 컴퓨터 구현 방법이 제공된다. 상기 방법은 신경 네트워크에 대한 입력 데이터를 수신하는 단계를 포함한다. 이 방법은 신경 네트워크의 복수 의 하이퍼파라미터에 대한 값을 결정하는 단계를 또한 포함한다. 이 방법은 하이퍼파라미터 값에 따라 신경 네 트워크를 구축하는 단계를 또한 포함하며, 여기에서 신경 네트워크는 복수의 뉴런을 포함한다. 각 뉴런은 복수 의 논리 연산자에 대한 확률 분포를 포함하며, 그래서 뉴런이 각 논리 연산자에 대한 대응 확률을 포함하도록 한다. 이 방법은 각 뉴런의 확률 분포를 학습하여 하이퍼파라미터 값과 입력 데이터에 따라 신경 네트워크를 훈 련하는 단계를 또한 포함한다. 이 방법은 확률 분포에서 값을 선택하여 각 뉴런의 복수의 논리 연산자 중 하나 의 논리 연산자를 결정하는 단계를 또한 포함한다. 신경 네트워크는 이진 신경 네트워크 (신경 네트워크가 훈련된 후에는 네트워크에서 전파되는 요소가 두 가지 값 중 하나만 가질 수 있기 때문임), 논리 게이트 네트워크 (뉴런이 논리 연산자를 구현하기 때문임) 또는 이진 논리 게이트 네트워크라고도 언급될 수 있다. 논리 연산자는 논리 게이트라고도 언급될 수 있다. 어떤 경우에는, 뉴런당 입력이 최대 두 개뿐이다. 뉴런당 정확히 2개의 입력이 있고 계층당 n개의 뉴런이 있는 경우에, 신경 네트워크는 최대 1 - (2/n)의 희소성을 가질 수 있다. 복수의 하이퍼파라미터의 값은 수신된 하이퍼파라미터(예: 유사한 기계 학습 작업을 수행하는 데 사용되거나 유 사한 신경 네트워크가 동일한 기계 학습 작업을 수행하는 데 사용됨)로부터 결정되거나 또는 초기 값을 수신하 지 않고 정의될 수 있다. 어떤 경우에는, 각 뉴런의 확률 분포가 여러 부동 소수점 값에서 파생된 범주형 확률 분포일 수 있으며, 그래서 상기 확률 분포에서의 모든 항목은 합이 1이고 음수가 아니도록 한다. 상기 확률 분포는 소프트맥스를 통해 부 동 소수점 값들로부터 유도될 수 있으며, 부동 소수점 값이 확률 심플렉스에 매핑되어 범주형 확률 분포의 결과 를 가져온다. 확률 분포가 훈련되므로, 신경 네트워크의 확률 분포는 신경 네트워크의 파라미터로 언급될 수도 있다. 확률 분포의 확률들은 ≥ 0과 ≤ 1이 될 수 있다. 소프트맥스는 값을 확률로 변환하는 데 사용되는 기존 함수일 수 있다. 소프트맥스에는 온도(즉, 온도 파라미터)가 포함될 수 있는데, 여기에서 온도는 낮은 확률에 대한 민감도를 높일 수 있다. 다시 말해, 온도는 확률 분포의 엔트로피를 제어하는 방법이 될 수 있다 (높은 온도는 엔트로피를 증가시켜 확률 분포를 더욱 균일 하게 만들고, 낮은 온도는 엔트로피를 감소시켜고 더 높은 확률을 두드러지게 한다). 확률 분포에서 값을 선택하는 것은 가장 가능성이 높은 값을 선택하거나 랜덤 값을 선택하는 방식으로 구현될 수 있다. 보다 구체적으로, 값을 선택하는 것은 적절한 값을 찾을 때까지 무작위 값을 반복적으로 선택하는 것 을 포함할 수 있다. 어떤 경우, 상기 선택하는 것은 확률 분포를 그 확률 분포의 모드로 대체하는 것을 포함할 수 있다. 따라서, 훈련된 신경 네트워크에서, 각 뉴런의 입력과 출력은 부울(0 또는 1)이 될 수 있으며 그리고/ 또는 각 뉴런의 연산자는 고정될 수 있다 (즉, 확률 분포가 아닌 단일 연산자). 따라서 논리 게이트 네트워크는 각 뉴런의 확률 분포를 학습시킴으로써 훈련될 수 있는데, 이는 확률 분포를 사 용하면 손실 함수를 최소화하는 데 사용할 수 있는 경사를 계산할 수 있기 때문이다. 따라서, 위에 설명된 기존 논리 게이트 네트워크와 비교하여, 손실 함수의 미분이 계산될 수 있고 기울기 벡터가 획득될 수 있다. 손실 함 수의 미분은 신경 네트워크가 개선되는 방향이다. 따라서 손실 함수의 미분을 계산할 수 있게 되면 훈련 동안에 신경 네트워크를 개선하는 것이 가능하다. 입력 데이터에는 입력과 이에 대응하는 원하는 출력이 포함될 수 있다. 입력 데이터에는 훈련 데이터, 검증 데 이터, 테스트 데이터가 포함될 수 있다. 훈련 데이터, 검증 데이터 및 테스트 데이터는 상호 배타적이거나 분리 될 수 있다. 즉, 훈련 데이터 내 샘플은 검증 데이터나 테스트 데이터에 전혀 나타나지 않고, 테스트 데이터 내 샘플은 검증 데이터나 훈련 데이터에 전혀 나타나지 않는다. 이런 방식으로, 검증 데이터를 사용하여 하이퍼파 라미터를 평가할 때 그리고 테스트 데이터를 사용하여 신경 네트워크의 정확도를 테스트할 때 과도적합이 판단 될 수 있다. 어떤 경우에는, 과도적합을 피하는 것이 바람직할 수 있다. (때로는 양성 과도적합이라고 언급되는) 다른 경우에, 훈련 데이터에서 약 100%의 정확도를 달성하더라도, 신경 네트워크는 검증 및 테스트 데이터와 관련하여 여전히 비교적 정확할 수 있다. 샘플은 데이터 포인트라고도 언급될 수 있다. 어떤 경우에는, 결정된 하이퍼파라미터 값에 따라 신경 네트워크를 훈련시키기 위해 훈련 데이터가 사용될 수 있다. 검증 데이터는 결정된 하이퍼파라미터 값의 한 세트와 결정된 하이퍼파라미터 값의 다른 세트와 비교하는 데 사용될 수 있다. 하이퍼파라미터에 대한 최종 값(가장 정확한 값)이 일단 결정되면 기계 학습 작업을 수행할 때 신경 네트워크의 정확도를 판단하기 위해 테스트 데이터가 사용될 수 있다. 원하는 출력들은 라벨들로 언급될 수 있다. 입력 데이터는 튜플(tuple)들의 세트로 제공될 수 있으며, 각 튜플 은 다음과 같은 형식을 갖는다: (입력 또는 샘플, 대응 출력). 샘플은 고정된 크기 벡터(예: 이진 벡터)로 제공 될 수도 있고 알려진 위상 구조(예: 이미지)를 가질 수도 있다. 몇몇 경우에, 하이퍼파라미터 값은 하나 이상의 지정된 계산 리소스 제약 하에서 신경 네트워크의 검증 오류를 최소화하도록 결정될 수 있으며, 여기에서 지정된 계산 리소스 제약에는 프로세서 및/또는 메모리 제약이 포함 될 수 있다. 최소 5개의 하이퍼파라미터 또는 최소 10개의 하이퍼파라미터가 있을 수 있다. 하이퍼파라미터 값은 신경 네트 워크의 구조와 신경 네트워크의 훈련 방법을 결정할 수 있다. 하이퍼파라미터는 신경 네트워크를 통해 수행되는 추론의 컴퓨팅 시간과 메모리 비용에 영향을 미칠 수 있다. 또한, 하이퍼파라미터는 신경 네트워크의 정확도에 영향을 미칠 수 있다. 예를 들어, 계층당 뉴런이 너무 많으면 과대적합이 발생할 수 있고, 계층이나 계층당 뉴 런이 너무 적으면 과소적합이 발생할 수 있다. 어떤 경우에는 하이퍼파라미터 값들의 여러 세트들이 결정될 수 있으며, 신경 네트워크는 각 하이퍼파라미터 값 들의 각 세트에 따라 훈련될 수 있다. 충분히 정확하다면, 훈련된 신경 네트워크들 중 가장 정확한 신경 네트워 크가 추론을 위해 사용될 수 있다. 하이퍼파라미터 값(복수의 하이퍼파라미터에 대한 값)은 최적화 알고리즘(예: 그리드 탐색이나 자동화된 기계 학습 - AutoML)이나 랜덤 탐색을 통해 무작위로 선택될 수 있다. 최적화 알고리즘은 사용자가 제공한 제약들을 사용하여 구현될 수 있다. 상기 제약들은 기계 학습 작업에 따라 달라질 수 있다. 그리드 검색의 맥락에서, 상 기 제약들은 그리드로 지칭될 수 있다. 그리드 탐색은 기존의 그리드 탐색 알고리즘을 통해 수행될 수 있다. 어떤 경우에는 입력 데이터에는 훈련 데이터와 검증 데이터가 포함될 수 있다. 따라서, 하이퍼파라미터 값들의 여러 세트들 내 각 세트에 대해, 신경 네트워크는 훈련 데이터와 하이퍼파라미터 값들의 세트를 사용하여 훈련 될 수 있으며, 그런 다음 하이퍼파라미터 값 세트와 검증 데이터를 사용하여 신경 네트워크의 정확도가 검증될 수 있다. 검증 데이터와의 오류가 가장 낮은 하이퍼파라미터 값들의 세트 (즉, 검증 오류가 가장 낮고 가장 정 확한 하이퍼파라미터 값들)이 결정된 하이퍼파라미터 값들일 수 있다. 하이퍼파라미터에는 다음 중 하나 이상이 포함될 수 있다: 계층당 뉴런 수, 계층들의 수, 에포크(epoch)들의 수, 배치 (batch) 크기, 학습 레이트(learning rate). 분류 작업의 맥락에서, 하이퍼파라미터에는 확률 분포를 훈련하기 위한 소프트맥스 온도가 추가로 포함될 수 있다. 소프트맥스 온도는 계층당 뉴런 수가 늘어날수록 증 가할 수 있다. 따라서 소프트맥스 온도는 클래스당 출력 수에 따라 달라질 수 있다(예: 클래스당 출력 수가 증 가함에 따라 소프트맥스 온도도 높아질 수 있음). 신경 네트워크 내 계층당 뉴런들의 수는 다음 제약 조건에 따라 결정될 수 있다(예: 다음 그리드에서 선택): {100, 1000, 10,000, 100,000, 1,000,000, 10,000,000}. 신경 네트워크 내 계층들의 수는 다음 제약 조건에 따 라 결정될 수 있다 (예: 다음 그리드에서 선택): {4, 5, 6, 7, 8}. 대안으로, {2,3,4,5,6,7,8,9}의 그리드가 사용될 수 있다. 뉴런 수가 적은 신경 네트워크는 특정 기계 학습 작업(예: 표 형식 데이터를 포함하는 분류 작 업)에서 더 나은 성능을 보일 수 있다. 이런 경우에는 뉴런 수가 적으면 과도적합을 피하는 데 도움이 될 수 있 다. 반면에, 더 많은 뉴런(예: 64,000개)이 이미지 분류에 더 적합할 수 있다. 소프트맥스 온도는 다음 제약 조건에 따라 결정될 수 있다(예: 다음 그리드에서 선택): {1, 3, 10, 30, 100}. 대안으로, {1, 1/0.3, 1/0.1, 1/0.03, 1/0.01}의 그리드가 사용될 수 있다. 계층당 뉴런 수가 늘어날수록 소프트맥스 온도를 높이면 성능이 향상될 수 있다. 예를 들어, 계층당 뉴런들 수가 2,000 내지 10,000개라면, 소프 트맥스 온도가 약 10이면 다른 소프트맥스 온도 값에 비해 정확한 신경 네트워크(검증 오류가 낮음)로 이끌 수 있다. 계층당 뉴런들의 수가 12,000 내지 100,000개일 경우, 약 30인 소프트맥스 온도는 정확한 신경 네트워크 로 그끌 수 있다. 계층당 뉴런의 수가 100,000를 넘으면, 약 100의 소프트맥스 온도는 정확한 신경 네트워크로 이끌 수 있다. 계층당 뉴런의 수가 100개일 경우, 소프트맥스 온도가 3 미만 (예: 1 또는 3)이면 정확한 신경 네트워크로 이끌 수 있다. 하이퍼파라미터 값에 따라 신경 네트워크를 훈련하는 것은 상기 학습 레이트를 사용하여 배치 크기에서 에포크 들의 수에 대해 훈련하는 것을 포함할 수 있다. 에포크들의 수는 학습하는 동안 모든 학습 데이터가 신경 네트워크에 표시되는 (예: 신경 네트워크에 입력으로 제공되는) 횟수일 수 있다. 예를 들어, 하이퍼파라미터를 결정할 때, 훈련 오류가 감소하더라도(과도적합) 검증 오류가 증가할 때까지 에포크 수를 늘릴 수 있다. 에포크 수에 적합한 값은 약 200이 될 수 있다. 배치 크기는 학습 반복 당 신경 네트워크를 통해 전파되는 입력 데이터로부터의 샘플들(예: 인스턴스, 관찰, 입 력 벡터 또는 특징 벡터)의 수를 나타낼 수 있다. 예를 들어, 이미지 분류의 분류 작업 맥락에서 입력 데이터의 각 샘플에는 이미지와 그 이미지에 대한 레이블이 포함될 수 있다. 배치 크기에 가능한 값은 32, 64, 128, 256 및 기타 2의 거듭제곱이 될 수 있다. 어떤 경우에는 약 100개의 배치 크기를 사용할 수 있다. 학습 레이트는 각 에포크의 검증 오류에 대한 응답에서 신경 네트워크를 얼마나 변경해야 하는지 지정할 수 있 다. 학습 레이트를 설정할 때, 검증 오류를 낮추기 위한 수렴 속도 그리고 훈련 동안에 학습 오류를 높이는 것 사이에 트레이드 오프가 있을 수 있다. 학습 레이트는 다음 제약 조건에 따라 결정될 수 있다(예: 다음 그리드 에서 선택): {0.1, 0.01, 10-3, 10-4, 10-5}. 예를 들어, 약 0.01의 학습 레이트가 사용될 수 있다. 신경 네트워크를 훈련하는 것은 확률 분포를 지속적으로 파라미터화하는 것을 포함할 수 있다. 따라서 각 뉴런 의 확률 분포는 훈련 동안에 파라미터화될 수 있다 (예: 소프트맥스를 사용하여 표준 정규 분포에서 요소들을 독립적으로 선택). 예를 들어, 결과는 신경 네트워크의 각 확률 분포로부터 계산될 수 있으며, 예를 들어, 결과 는 각 에포크(즉, 학습의 각 단계) 동안 계산될 수 있다. 상기 결과는 평균, 가중 평균 또는 확률 분포의 다른 통계적 함수일 수 있다. 신경 네트워크는 여러 개의 계층을 포함할 수 있으며, 여러 개의 층에는 출력 층이 포함된다. 신경 네트워크는 적어도 하나의 은닉 계층을 포함할 수 있다. 최소한 하나의 계층(예: 숨겨진 계층)이 출력 계층보다 앞에 올 수 있다. 신경 네트워크로의 입력은 제1 계층, 예를 들면, 여러 개의 은닉 계층들 중 첫 번째 계층에 의해 액세스 될 수 있다. 여러 개의 은닉 계층이 있는 경우, 각 은닉 계층은 동일한 수의 뉴런을 가질 수 있다. 신경 네트워크는 은닉 계층과 출력 계층에 같은 수의 뉴런을 가질 수 있다. 추가로 또는 대안으로, 신경 네트워 크는 4개에서 8개 사이의 계층을 가질 수 있다. 기계 학습 작업이 분류 작업인 경우, 분류 작업은 최소한 두 개의 클래스를 가질 수 있다. 어떤 경우에는 분류 작업의 각 클래스가 출력 계층의 여러 뉴런과 연관되도록 계층당 뉴런의 수가 선택될 수 있다. 따라서 클래스당 여러 개의 뉴런을 사용하고 이를 합산하여 집계하면 클래스당 뉴런의 수만큼의 등급(레벨)을 갖는 등급 분류가 수행될 수 있다. 클래스 내의 각 뉴런은 클래스의 다른 증거(또는 측면)를 포착할 수 있으므로, 기존 논리 게이 트 네트워크에 비해 더욱 세밀한 등급 분류를 가능하게 한다. 이 방법은 각 뉴런에 대한 논리 연산자를 결정한 후, 훈련된 신경 네트워크를 사용하여 기계 학습 작업을 수행 하는 단계를 또한 포함할 수 있다. 분류 작업의 경우, 출력 계층은 n개의 뉴런을 포함할 수 있고 분류 작업은 k 개의 클래스를 가질 수 있다. 따라서 훈련된 신경 네트워크를 사용하여 분류 작업을 수행하는 것은 다음을 포함 할 수 있다. 상기 훈련된 신경 네트워크에 의해 상기 클래스들 각각에 대한 분류 점수를 출력하는 단계, 상기 출력을 크기 인 k개 그룹들로 그룹화하는 단계 - 여기에서 각 그룹 내 1의 개수는 그 그룹에 대응하는 클래스에 대한 분류 점수에 대응함 -, 분류를 결정하는 단계 - 분류 점수들의 최대값을 결정하는 것을 포함함-. 분류 점수의 최대값을 결정하는 단계는 가장 큰 확률(즉, 가장 큰 예측 확률)을 갖는 클래스를 결정하는 연산을 사용하는 단계를 포함할 수 있다. 따라서, 분류 점수의 최대값은 argmax 연산을 사용하여 결정될 수 있다. 어떤 경우에는, 예측(즉, 분류 점수)을 반환하는 데 필요한 메모리 대역폭을 줄이기 위해 각 클래스(즉, 각 분 류 점수에 대한)를 위한 출력 비트를 이진수로 집계할 수 있다. 이는 고정 논리 게이트 네트워크를 통해 표현될 수 있다. 구체적으로, 논리 게이트를 사용하여 이진수에 하나의 비트를 더할 수 있는 덧셈기들이 구현될 수 있 다. 따라서, 각 분류 점수에 대해 덧셈기가 구현될 수 있으며, 덧셈기들의 개수는 분류 점수들의 개수와 일치하 도록 할 수 있다. 이러한 덧셈기는 대응 클래스의 출력 비트를 정수로 더하는 데 적합하도록 수정될 수 있다. 이런 방식으로 집계는 매우 효율적이며, 특히 집계는 집계되지 않은 결과를 VRAM에 저장하는 것보다 더 빠르다. 각 뉴런에 대한 논리 연산자를 결정하고 분류 점수를 출력하기 전에, 본 방법은 훈련된 신경 네트워크를 중앙 처리 유닛(CPU) 또는 그래픽 처리 유닛(GPU)에서 실행 가능한 바이너리로 변환하는 단계를 더 포함할 수 있다. 어떤 경우에는, 상기 실행 가능한 바이너리는 공유 객체 바이너리를 처리할 수 있는 프로그램, 예를 들어, Python을 통해 호출 가능하다. CPU에서 실행 가능한 바이너리는 C 코드에서 컴파일될 수 있다. GPU에서 실행할 수 있는 바이너리는 CUDA(이전의 Compute Unified Device Architecture)에서 컴파일될 수 있다. 뉴런의 입력과 출력은 실수 값일 수 있다. 어떤 경우에는, 훈련 동안에, 모든 뉴런의 출력이 0 내지 1 사이의 범위 내의 값(즉, 0보다 크거나 같고 1보다 작거나 같음)일 수 있다. 마찬가지로, 뉴런에 대한 입력은 0보다 크거나 같고 1보다 작거나 같을 수 있다. 추가 로 또는 대안으로, 각 뉴런은 0 및 3개 사이의 입력을 받을 수 있다. 더 구체적으로 말하면, 각 뉴런은 0 및 2 개 사이의 입력을 받을 수 있다. 예를 들어, \"0\" 연산자는 0개의 입력을 받을 수 있고, \"A\" 연산자는 1개의 입 력만 받을 수 있으며, \"A-AB\" 연산자는 2개의 입력을 받을 수 있다. 신경 네트워크를 구축하는 것은 뉴런들 간 연결(즉, 신경 네트워크의 가중치)을 의사 난수로 초기화하는 것을 추가로 포함할 수 있다. 의사 난수 초기화는 연결들이 저장될 필요가 없고 필요에 따라 생성될 수 있다는 이점 을 가진다. 특히, 연결은 시드 (즉, 의사난수 생성기를 초기화하는 데 사용되는 랜덤 시드)에서 생성될 수 있으 며 동일한 시드에서 재생성될 수 있다. 상기 시드는 컴퓨터 상태(예: 시간)로부터 생성될 수도 있고 하드웨어 기반 특수 목적 난수 생성기로부터 생성될 수도 있다. 신경 네트워크를 구축하는 것은 다른 휴리스틱을 사용하 여, 예를 들어 그룹들 내에서 의사 난수나 특정 하드웨어에서 더 빠른 계산을 허용하는 구조를 사용하여 연결을 초기화하는 것을 포함할 수도 있다. 따라서, 일단 신경 네트워크가 훈련되면 그 신경 네트워크를 저장하는 것은 각 뉴런을 위해 사용된 논리 연산자 를 지정하는 4비트 정보를 저장하는 것을 필요로 할 뿐이다. 즉, 신경 네트워크를 저장하는 것은 n x 4비트(여 기에서 n은 신경 네트워크 내의 뉴런들 수)에 상대적으로 낮은 상수 값들을 더한 것을 필요로 할 수 있다. 상기 상수 값들은 상기 시드와 계층들의 크기(입력들의 개수와 출력들의 개수)를 포함할 수 있다(예: 이에 국한될 수 있음). 계층들의 크기가 같은 경우 (즉, 모든 계층들의 크기가 같은 경우), 단 한의 크기 값만이 필요하다. 이 런 방식에서, 신경 네트워크에 대한 저장 요구 사항은 기존 신경 네트워크 (예: 밀집 신경 네트워크, 컨벌루션 신경 네트워크, 희소 신경 네트워크 또는 이진 신경 네트워크)보다 상당히 낮을 수 있다. 훈련하는 동안, 뉴런들 간의 연결은 고정된 상태로 유지될 수 있다. 즉, 그것은 신경 네트워크가 뉴런들의 가중 치를 조정하여 훈련되지 않을 수도 있다는 것이다. 분류 작업은 다음 중 하나 이상을 포함될 수 있다: 이진 분류, 패턴 인식(예: 특징 분류), 이미지 분류, 객체 식별 또는 인식, 문자 인식, 제스처 또는 얼굴 인식, 음성 검출 또는 음성 인식, 텍스트 분류. 예를 들어, 이진 분류 작업의 입력 데이터에는 크기가 17인 이진 벡터들이 포함될 수 있다. 각 이진 벡터는 클 래스 0 또는 클래스 1로 분류될 수 있다. 또 다른 예로, 패턴 인식(특히, 이미지 분류) 작업을 위한 입력 데이 터에는 0에서 9까지의 숫자 이미지와 각 이미지에 대한 대응 레이블이 포함될 수 있다. 각 이미지는 상기 이미 지가 어느 숫자에 대응하는지를 식별함으로써 분류될 수 있다. 이진 분류는 다음 중 하나를 포함할 수 있다: (환자가 질병을 앓고 있는지 여부를 판단하기 위한) 의료 테스트, 품질 관리(기술 사양을 충족했는지 여부를 확인) 및 정보 검색 (페이지가 검색 결과 세트에 포함되어야 하는지 여부를 판단). 패턴 인식은 이미지 처리(예: 이미지 분류)를 포함할 수 있다. 패턴 인식은 다음 중 하나에 사용될 수 있다: 식 별 및/또는 인증, 의료 진단, 방어 및 이동성. 식별 및/또는 인증에는 차량 번호판 인식, 지문 분석, 얼굴인식, 음성 기반 인증이 포함될 수 있다. 의료 진단에는 자궁 경부암, 유방 종양 또는 심장음에 대한 검진이 포 함될 수 있다. 방어에는 항법 및 유도 시스템, 표적 인식 시스템, 형상 인식 기술이 포함될 수 있다. 이동성에 는 (운전 및 주차를 지원하기 위한) 운전자 지원 시스템 및/또는 자율 주행차 기술(인간의 개입이 거의 또는 전 혀 없이 안전하게 이동할 수 있는 지상 차량용)이 포함될 수 있다. 기계 학습 작업은 회귀 작업일 수 있으며, 여기에서 상기 회귀 작업은 다음 중 하나 이상을 포함할 수 있다: 이 미지 생성, 텍스트 생성, 비디오 생성, 음성 생성, 3D 재구성, 압축, 인코딩. 특히 회귀 작업에는 비디오, 오디 오 또는 이미지 압축이 포함될 수 있다. 인코딩에는 음성 인코딩이 포함될 수 있다. 신경 네트워크를 훈련시키는 것은 신경 네트워크의 정확도를 지정된 정확도와 비교하여 신경 네트워크가 충분히 정확한지 여부를 판단하는 단계를 또한 포함할 수 있다. 훈련시키는 것은 미분 가능한 방식으로 수행되며, 즉, 신경 네트워크에서의 뉴런들에 대한 논리 연산자들의 확률 분포는 훈련 동안에 학습된다. 따라서 훈련에는 뉴런 확률 분포의 손실이나 오류를 판별하는 것이 포함된다. 훈련과 달리 추론(즉, 훈련된 신경 네트워크 사용)은 미 분 가능할 필요가 없으며 (0에서 1까지의 확률인) 완화된 값이 아닌 고정된 논리 연산자와 하드 값(0 또는 1)을 사용하여 수행할 수 있다. 신경 네트워크의 정확도는 기존의 손실 함수를 사용하여 통상적으로 결정될 수 있다. 예를 들어, 소프트맥스 교 차 엔트로피 분류 손실 함수가 사용될 수 있다. 이 맥락에서, 교차 엔트로피는 두 확률 분포들 간 차이의 발산 측정이다. 대안으로, 회귀를 위해 평균 제곱 오차 손실이 사용될 수 있다. 지정된 정확도는 기계 학습 작업에 따라 결정될 수 있다. 예를 들어, 이진 분류에 대한 지정된 정확도는 약 100%일 수 있는 반면, 이미지 분류에 대한 지정된 정확도는 최소 95% 또는 최소 97%일 수 있다. 신경 네트워크를 훈련하는 것은, 신경 네트워크의 정확도가 충분하지 않은 때에, 하이퍼파라미터에 대한 새로운 값을 결정하는 것을 더 포함할 수 있다. 하이퍼파라미터의 새로운 값은, 예를 들어, 베이지안 최적화를 사용하 여 반복적으로 결정될 수 있다. 따라서, 신경 네트워크는 새로운 값에 따라 재구축될 수 있으며, 재구측된 신경 네트워크는 새로운 값에 따라 훈련될 수 있다. 지정된 횟수의 반복을 수행한 후 (또는 지정된 정확도에 도달한 때에), 신경 네트워크 및 재구축된 신경 네트워크 중에서 가장 정확한 신경 네트워크가 결정될 수 있다. 가장 정확한 신경 네트워크는 훈련된 신경 네트워크로서 제공될 수 있다. 정확도와 효율성 간에는 트레이드-오프가 있을 수 있다. 특히, 더 많은 뉴런을 포함하는 신경 네트워크는 추론 에 있어서 효율적이지 않을 수 있다. 따라서 효율성을 위해, 상기 지정된 정확도를 낮추는 것이 바람직할 수 있 다. 또한, 이전 반복들로부터의 지식이 후속 반복들에 대한 새로운 하이퍼파라미터 값을 결정하기 위해 사용될 수 있다. 예를 들어, 하이퍼파라미터 값을 결정하기 위한 제약 조건이 수정될 수 있다. 일부 예에서, 복수의 논리 연산자는 적어도 2개의 연산자, 적어도 8개의 연산자 또는 정확히 16개의 연산자를 포함할 수 있다. 일부 예에서, 복수의 논리 연산자는 실수 값(즉, 논리 게이트의 완화된 대응물)을 가질 수 있다. 논리 연산자는 다음 해석들 중 하나를 따를 수 있다: 확률적, 하마허 t-노름(norm), 상대론적 아인슈타인 합 t- 코노름(conorm), 루카시에비츠 t-노름 및 t-코노름. 실수 값을 갖는 논리 연산자는 퍼지 논리에서 파생될 수 있다. t-노름은 퍼지 논리에서 결합을 나타내는 데 사용되는 이진 연산일 수 있다. 마찬가지로, t-코노름은 퍼지 논리 에서 분리를 표현하는 데 사용될 수 있다. 실수 값을 갖는 논리 연산자 및/또는 실수 값을 갖는 입력을 사용하면 신경 네트워크를 미분가능하게 만드는 데 기여할 수 있다. 기존 논리 게이트 네트워크는 그 네트워크의 파라미터가 0과 1로 제한되어 있기 때문에 미분 불가능하다. 실수 값을 사용하면 네트워크 파라미터에 대한 손실 함수의 미분(예: 다차원 미분)으로 경사를 계 산하는 것을 가능하게 할 수 있으며, 이는 실수 값을 사용하면 불연속, 예를 들면, 0에서 1로 점프하는 불연속 을 제거하기 때문이다. 따라서, 신경 네트워크는 미분가능 논리 게이트 네트워크로 언급될 수 있다. 신경 네트 워크를 미분 가능하게 만들면 경사 하강법에 기반한 알고리즘을 사용하여 훈련하는 것을 용이하게 할 수 있다. 게다가, 뉴런의 입력과 출력은 훈련 중에는 실수 값이 될 수 있지만, 훈련된 신경 네트워크에서는 부울(고정) 값이 될 수 있다. 마찬가지로, 훈련된 신경 네트워크의 논리 연산자는 자신의 모드를 취하여 이산화될 수 있으 며, 그래서 각 확률 분포가 확률 분포에서 가장 높은 값을 갖는 논리 연산자로 대체될 수 있도록 한다. 실수 값 논리 연산자에는 다음이 포함될 수 있다: 0, , , , , , , , , , , ,"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": ", , , 1. 실수 값 논리 연산자에서 상기 A와 B는 대응 뉴런들로부터의 입력일 수 있다. 다시 말해, 주어진 뉴런의 실수 값 논리 연산자는 첫 번째 뉴런으로부터의 입력 A와 두 번째 뉴런으로부터의 입력 B에 대한 연산을 수행할 수 있다. 0과 1의 경우, 입력에 관계없이 이러한 값들이 출력될 수 있다. 위의 실수 값 논리 연산자들은 확률적 해 석(즉, 확률적 곱 T-노름(T-norm) 및 확률적 합 T-코노름(T-conorm)에 대응할 수 있다. 하지만, (위에 나열된 것과 같은) 다른 해석들도 사용될 수 있다. 어떤 경우, 상기 입력 데이터는 복수의 샘플들을 갖는 테스트 데이터를 포함할 수 있다. 이 방법은 추론 동안에 (즉, 훈련 후에) 신경 네트워크의 제1 계층에 의해 테스트 데이터의 집계에 액세스하여 기계 학습 작업을 수행 하는 단계를 더 포함할 수 있으며, 상기 액세스하는 것은 상기 테스트 데이터의 각 샘플의 요소들을 정수들의 연속된 비트들에 할당하는 것을 포함한다. 따라서, 추론 동안에 (즉, 훈련 후에), 각 뉴런의 두 입력은 기계 학 습 작업이 수행될 컴퓨터의 프로세서의 하드웨어로 구현된 데이터 유형에 대응하는 숫자형 데이터 유형을 갖는 다. 따라서, 테스트 데이터의 집계는 집계 크기, 즉 추론 동안의 배치(batch)의 집계 크기를 가질 수 있다. 상기 집 계 크기는 프로세서의 하드웨어 구현된 데이터 유형(즉, 어셈블리 언어 데이터 유형)에 대응하며, 그러므로 효 율적이다. 예를 들어, int64 하드웨어 구현 데이터 유형에는 집계 크기 64가 사용할 수 있을 것이며, int32 하 드웨어 구현 데이터 유형에는 집계 크기 32가 사용될 수 있을 것이다. 구체적으로, 테스트 데이터의 샘플은 이미지일 수 있고, 샘플의 요소는 이미지의 픽셀일 수 있다. 숫자형 데이 터 유형은 이진 신경 네트워크에서 일반적으로 사용되는 부울 데이터 유형이 아닌 정수형 데이터 유형(예: int64)일 수 있다. 따라서 각 뉴런 입력은 int64 정수의 일부일 수 있고, 그래서 전체 정수는 64개의 상이한 뉴 런 입력들로 구성될 수 있다. 상기 집계 크기는 64일 수 있다. 따라서, 기계 학습 작업에 제공된 이미지들의 각 배치에는 64개의 이미지들이 포함될 수 있으며, 각 이미지는 784개의 바이너리 픽셀(즉, 28x28 비트맵 이미지) 을 가지며, 그래서 상기 이미지들이 784개의 정수 변수들의 어레이로 배치(batch)(즉, 확산)될 수 있으며, 각 변수는 int64의 하드웨어 구현 데이터 유형을 가진다. 기계 학습 작업을 수행하는 컴퓨터의 프로세서는 CPU일 수도 있고 GPU일 수도 있다. 제1 계층 내 뉴런들에 의해 테스트 데이터에 액세스하는 것은 그 테스트 데이터를 상기 제1 계층의 뉴런들에 걸 쳐 확산하는 것에 대응할 수 있다. 상기 액세스하는 것은 이미지 1의 (모든) 값들을 정수들의 비트 1에 할당하 고 이미지 2의 (모든) 값들을 정수들의 비트 2에 할당하는 것을 포함할 수 있으며, 그래서 각각의 연속적인 이 미지가 상기 제1 계층의 모든 정수들에 걸쳐 분산되도록 한다. 다른 말로 하면, 이미지 k의 부울 값 i는 int64 값 i의 비트 k에 할당될 수 있다. 따라서, 각 이미지에 대해 동일한 연산이 적용되므로 모든 논리 연산은 정수에 대해 실행된다. 그래서, 비트 연 산자는, 일반적으로 부울 데이터 유형을 가지는 단일 값에 비트 연산자를 적용하는 것과 동일한 (또는 비슷한) 처리 비용으로 int64의 64비트에 동시에 적용될 수 있다. 이런 방식으로, 부울 데이터 유형을 가지는 값들에 대한 연산 성능과 비교했을 때 성능이 크게 향상될 수 있다. 특히, 이러한 성능 향상은 많은 프로세서(예: 대부분의 CPU)에서 부울 데이터 유형의 값과 프로세서의 하드웨어 구현 데이터 유형(예: int64 데이터 유형)에 대응하는 정수 데이터 유형의 값에 대한 비트 연산을 수행하는 것 은 실제로는 동일한 시간이 걸린다는 사실, 즉 하나의 명령어만 필요하다는 사실에 의존한다. 예를 들어, int64 보다 큰 데이터 유형을 사용하여, 예를 들면, 고급 벡터 확장 (예를 들면, AVX, AVX2, AVX-512) 명령어 세트를 사용하여 더 많은 효율성이 실현될 수 있다. CPU나 GPU에 대한 대안으로, 특수 하드웨어가, 예를 들어, ASIC이나 FPGA가 사용될 수 있다. 이 경우, 부울 데 이터 유형을 효율적으로 사용될 수 있다. 또 다른 측면에 따르면, 컴퓨터 프로그램이 제공된다. 상기 컴퓨터 프로그램은, 컴퓨터에 의해 실행될 때 그 컴 퓨터로 하여금 위에 설명된 방법을 수행하게 하는 명령어들을 포함한다. 상기 컴퓨터 프로그램은 컴퓨터 프로그 램 제품의 일부일 수도 있다 (또는 그 내부에 포함될 수 있다). 상기 컴퓨터 프로그램은 컴퓨터가 읽을 수 있는 매체에 (유형적으로) 구현될 수 있다. 상기 컴퓨터 프로그램은 하드웨어나 소프트웨어로 구현될 수 있다. 특히, 상기 컴퓨터 프로그램은 FPGA나 ASIC을 사용하여 구현될 수 있다. 추가로 또는 대안으로, 상기 컴퓨터 프로그램 은 특정 작업을 수행하기 위해 신경 네트워크를 구현하는 하드웨어 인코딩(예: FPGA 또는 ASIC)을 포함하는 프 로세서(CPU 또는 GPU) 컴포넌트에서 구현될 수 있다. 또 다른 측면에 따르면, 기계 학습 작업을 수행하기 위해 신경 네트워크를 훈련하기 위한 컴퓨터 시스템이 제공 된다. 상기 컴퓨터 시스템은 최소한 하나의 프로세서를 포함한다. 상기 프로세서는 신경 네트워크에 대한 입력 데이터를 수신하고, 상기 신경 네트워크의 복수의 하이퍼파라미터에 대한 값을 결정하며 그리고 상기 하이퍼파 라미터 값에 따라 신경 네트워크를 구축하도록 구성된다. 상기 신경 네트워크는 다수의 뉴런들을 포함한다. 각 뉴런은 복수의 논리 연산자에 대한 확률 분포를 포함하며, 그래서 뉴런이 각 논리 연산자에 대한 대응 확률을 포함하도록 한다. 상기 프로세서는 각 뉴런의 확률 분포를 학습하여 하이퍼파라미터 값과 입력 데이터에 따라 신경 네트워크를 훈련하도록 추가로 구성된다. 상기 프로세서는 확률 분포에서 값을 선택함으로써 각 뉴런에 대 한 복수의 논리 연산자들 중 하나의 논리 연산자를 결정하도록 추가로 구성된다. 상기 프로세서는, (본 개시의 기술들을 사용하여) 기계 학습 과제를 수행하기 위해 신경 네트워크의 훈련을 가 속화하거나 기계 학습 작업의 성능을 가속화하기 위해 활용될 수 있는 기능들을 포함하는 GPU일 수 있다. 추가로 또는 대안으로, 상기 컴퓨터 시스템은 적어도 하나의 FPGA 및/또는 ASIC를 사용하여 구현될 수 있다. 추가로 또는 대안으로, 상기 컴퓨터 시스템은 논리 게이트 네트워크를 위한 하드웨어 가속(예: ASIC)을 포함할 수 있다. 본 개시에서 설명된 주제는 방법으로서 또는 디바이스에서, 아마도 하나 이상의 컴퓨터 프로그램(예: 컴퓨터 프 로그램 제품)의 형태로 구현될 수 있다. 이러한 컴퓨터 프로그램은 데이터 처리 장치가 본 개시에서 설명된 하 나 이상의 작업들을 수행하도록 할 수 있다. 본 개시에 기술된 주제는 데이터 신호 또는 기계 판독 가능 매체에 구현될 수 있으며, 여기에서 상기 매체는 테 이프, CD-ROM, DVD-ROM, 반도체 메모리 또는 하드 디스크와 같은 하나 이상의 정보 캐리어에서 구현된다. 특히, 개시된 주제는 기계(컴퓨터)에서 읽을 수 있는 매체에 실체적으로 구현될 수 있다. 또한, 본 개시에서 설명된 주제는 적어도 하나의 프로세서와 그 프로세서에 결합된 메모리를 포함하는 시스템으 로 구현될 수 있다. 상기 프로세서는 중앙 처리 유닛(CPU)이거나 그래픽 처리 유닛(GPU)일 수 있다. 상기 메모 리는 프로세서가 응용프로그램에 설명된 하나 이상의 방법을 수행하도록 하기 위해 하나 이상의 프로그램을 인 코딩할 수 있다. 본 개시에서 기술된 추가적인 주제는 다양한 기계를 사용하여 구현될 수 있다. CPU 및/또는 GPU에는 하드웨어 가속(예: 부동 소수점 산술을 위한 하드웨어 가속)을 구비한 집적 회로가 포함될 수 있다. 대 안으로, 상기 프로세서는 하드웨어 가속(예: 부동 소수점 가속) 기능이 없는 범용 하드웨어일 수도 있다. 게다가, 본 개시의 주제는 적어도 하나의 현장 프로그래밍 가능 게이트 어레이(FPGA)에 구현될 수 있다. 상기 FPGA는 인공지능을 위해 특별히 설계될 수도 있고, 특히 신경 네트워크를 구현하기 위해 설계될 수도 있다. 상 기 FPGA는 사전 정의된 작업이 (또는 작업들의 세트가) 논리 게이트를 통해 표현될 때 그 사전 정의된 작업을 효율적으로 수행할 수 있는 설정 가능한 하드웨어 가속 프로세서일 수 있다. 상기 FPGA는, 암호화폐 (예: 비트 코인) 채굴이나 오실로스코프 구현과 같이 복잡성은 제한적이지만 높은 속도가 필요한 작업에 특히 적합할 수 있다. 따라서, 신경 네트워크에서의 연산에 대해, 신경 네트워크 처리를 위해 특별히 설계된 FPGA는 기존 CPU보 다 10~100배 더 빠를 수 있다. 추가로 또는 대안으로, 본 개시의 주제 사항은 특정 용도를 위해 맞춤화된 ASIC(application specific integrated circuit, 주문형 집적 회로)을 사용하여 구현될 수 있다. 예를 들어, 상기 ASIC은 인공지능을 지원 하도록 개발될 수 있다. 구체적으로는, 구글의 텐서 처리 유닛 (Tensor Processing Unit)이나 후지쯔의 입 러닝 유닛 (Deep Learning Unit)이 사용될 수 있다. 추가로 또는 대안으로, 논리 게이트 네트워크의 하드웨어 구현이 사용될 수 있다. 구체적으로, 논리 게이트 네 트워크를 구현하기 위해 FPGA 또는 ASIC이 사용될 수 있으며, GPU는 (본 개시의 기술을 사용하여) 기계 학습 작 업을 수행하기 위해 신경 네트워크의 훈련을 가속화하거나 기계 학습 작업의 성능을 가속화하기 위해 활용될 수있는 기능들을 포함할 수 있다. 하나 이상의 구현예에 대한 세부 사항은 다음의 예시적 도면과 설명에서 제시된다. 기타 특징은 설명, 도면 및 청구항에서 분명해질 것이다."}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음 텍스트에서는 도면들을 참조하여 예시에 대한 자세한 설명이 제공된다. 예시에 다양한 수정들이 가해질 수 있다. 특히, 일 예의 하나 이상의 요소들이 결합되어 다른 예에서 사용될 수 있어서 새로운 예를 형성한다. 도 1은 기계 학습 작업을 수행하기 위한 예시적인 신경 네트워크를 보여준다. 더 구체적으로는, 상기 신경 네트 워크는 분류 작업을 수행하기 위한 것이다. 신경 네트워크는 결정된 하이퍼파라미터 값에 따라 구축될 수 있다. 그래서, 하이퍼파라미터 값들은 신경 네트워크의 구조를 정의할 수 있다. 하이퍼파라미터 값들은 여러 계층과 계층당 여러 뉴런을 포함할 수 있다. 따라서, 신경 네트워크는 하이퍼파라미터에 따라 구축될 수 있으며, 상기 신경 네트워크는 입력들 , 제1 계층 , 제2 계층 및 출력 계층 을 포함한다. 또한, 상기 출력 계층 은 4개의 뉴런들을 포함한다. 추가로, 계층들 및 105) 각각은 4개의 뉴런을 포함한다. 그래서, 상기 신경 네트워크의 계층들 , 105) 및 출력 계층 은 각각 동일한 수의 뉴런들을 포함할 수 있다. 다시 말해, 신경 네트워크의 각 계층은 동일한 개수의 뉴런들을 포함할 수 있다. 단순화된 신경 네트워크의 분류 작업에는 클래스 0과 클래스 1의 두 가지 클래스가 있다. 따라서 분류 작업은 이진 분류를 포함한다. 예를 들어, 뉴런 3.1과 3.2는 각각 \"1\"을 출력하고 뉴런 3.3과 3.4는 각각 \"0\"을 출력할 수 있다. 이 경우, 클래스의 개수 k는 2이고, 외측 계층 의 뉴런의 개수 n은 4이므로, 출력은 크기가 2인 2개의 그룹으로 그룹화될 수 있다. 따라서, 클래스 0의 분류 점수는 2일 것이며, 클래스 1의 분류 점수는 0일 것이다. 그래서, 분류 점수의 최대값에 따라 분류를 결정하면 클래스 0을 분류로서 결정하는 결과를 가져올 수 있을 것이다. 다른 예에서는 더 많은 클래스가 사용될 수도 있다. 신경 네트워크 내의 각 뉴런 1.1 내지 3.4는 두 개의 서로 다른 뉴런으로부터 두 개의 입력을 받는다. 예를 들 어, 제1 계층 의 뉴런 1.4는 입력 의 입력 0.5와 0.6을 수신한다. 각 뉴런은 복수의 논리 연산자들 각각에 대해 대응 확률을 포함할 수 있다. 뉴런의 확률은 그 뉴런의 확률 분포 의 일부일 수 있으며, 이는 신경 네트워크가 훈련됨에 따라 학습될 수 있다. 논리 연산자는 실수 값을 가질 수 있다(즉, 완화됨). 실수 값 논리 연산자는 T-노름 (\"and\"의 완화) 및 T-코노름 (\"or\"의 완화)을 기반으로 할 수 있다. 실수 값 논리 연산자는 미분가능하며 그리고/또는 연속적일 수 있다. 따라서 극단적인 T-Norm이나 최소 T-Norm 모두 실수 값 논리 연산자에 대한 적절한 기반을 제공하지 못할 수도 있다. 실수 값 논리 연산자는 0과 1의 입력뿐만 아니라 0과 1 사이의 입력에 대해서도 정의된다는 점에서 기존 부울 논리 연산자의 확장으로 볼 수 있다. 계층 의 뉴런 1.1에 대한 예시적인 확률 분포는 표 1에 표시된 바와 같이 다음과 같은 확률들을 포함할 수 있다: 표 1 AND OR NAND NOR XOR … TRUE FALSE 3% 1% 7% 2% 72% 9% 1% 표 2는 실수 값 논리 연산자들(확률적 논리 연산자)의 확률적 해석과 그것들의 대응 부울 해석을 보여준다. 표 2"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 2에서 ID 열은 각 행을 식별한다. 연산자 (Operator) 열은 부울 연산자를 보여준다. 실수 값 (rea-valued) 열의 행은 그 행 내 부울 연산자에 대응하는 실수 값 연산자를 보여준다. \"00\", \"01\", \"10\", \"11\" 열의 행은 그 열의 헤더 값(예: \"00\")이 입력으로 주어지면, 그 행에 대응하는 연산자 (부울 또는 실수 값)의 출력을 보여준 다. 테스트 결과, 표 2의 연산자 수를 줄이면 저하된 성능으로 이끌 수 있다. 다시 말해, 16개 미만의 논리 연 산자를 사용하는 것과는 반대로 16개의 논리 연산자를 사용하면 기계 학습 작업을 수행하기 위해 신경 네트워크 를 훈련하는 방법의 효율성을 향상시킬 수 있다. 표 2의 값들은 확률적 논리 연산자를 보여준다. 실수 값을 갖는 논리 연산자에 대해서도 다른 해석이 사용될 수 있다. 예를 들어, 하마허 곱 (Hamacher product) T-노름과 그것의 쌍대, 아인슈타인 합 T-코노름은 미분 가능할 수 있으며 실수 값 논리 연산자에 적합한 기반을 제공할 수 있다. Hamacher 곱 T-노름과 Einstein 합 T-코노름 을 기반으로 하는 실수 값 논리 연산자는 아래 표 3에 나와 있다. 표 3 ID 부울 연산자 Hamacher/Einstein 연산자 0False 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15True 1 표 3의 일부 연산자는 표 3의 다른 연산자에서 파생될 수 있다. 표 3의 2, 4, 9행에서 각 부울 연산자는 대응하 는 실수 값 연산자를 가지지 않는다. 암시(implication)(표 3의 행 2 및 행 4)에 대해서는 T-노름에 대응하는 R-암시(또는 잔류)가 사용될 수 있다 (\"Continuous R-implications\", B. Jayaram et al., July 20-24, 2009 참조). 표 2의 확률 연산자는 테스트에서 표 3의 Hamacher T-노름과 Einstein 합산 T-코노름보다 더 나은 성능을 보이는 것으로 나타났다. 실수 값 연산자의 다른 구현은 대응 T-코노름에 추가로, Frank T-노름, Yager T-노름, Acz l-Alsina T-노름, Dombi T-노름, 및 Sugeno-Weber T-노름을 기반으로 할 수 있다. 논리 연산자에 대한 더 많은 정보는 \"Analyzing Differentiable Fuzzy Logic Operators\", van Krieken et al., Aug. 24, 2021 에서 찾아볼 수 있 다. 실수 값 연산자를 구현하는 데 사용할 수 있는 추가 T-노름 및 T-코노름은 아래 표 4 및 5에 나와 있다: 표 4"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 5"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "아래 표에는 훈련 동안에 도 1의 뉴런에 대한 예시 값들이 제공된다. 신경 네트워크를 훈련하는 중간에서의 논리 연산자 확률:"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "신경 네트워크를 훈련하는 후반부, 즉 수렴 후의 논리 연산자 확률들"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "위에 표시된 논리 연산자 확률의 각 행에 대응하는 도 1의 뉴런은 행의 시작 부분에 제공된다. 예를 들어, \"1.1\"로 시작하는 행은 계층 의 뉴런 1.1에 대한 값을 보여준다. 논리 연산자 확률의 행에 있는 각 열은 표 2의 연속된 ID에 대응한다. 예를 들어, 논리 연산자 확률의 열 1은 표 2의 ID 0에 대응하며, 논리 연산자 확 률의 열 2는 ID 1에 대응한다. 따라서, 훈련 중간에서, 뉴런 3.2에 대한 가장 높은 확률은 0.678이며, 이는 표 2의 ID 10, 즉 실수 값 연산자 에 대응한다. 훈련의 중간은 네트워크가 학습되는 에포크들 수를 나타낼 수 있다. 따라서, 훈련의 중간은 에포크들 수의 약 절반을 의미할 수 있다. 마찬가지로, 훈련 후반부는 최종 에포크의 10% 이내의 에포크를 의미할 수 있다. 예를 들어, 신경 네트워크가 200 에포크 동안 훈련되었다면 훈련의 중간은 에포크 90과 110 사이에 있을 수 있다. 마 찬가지로, 훈련 후반부는 에포크 190과 에포크 200 사이일 수 있다. 수렴은 추가적인 훈련으로 신경 네트워크이 개선되지 않는 훈련 단계를 의미할 수 있다. 위의 예시적 값에서 볼 수 있듯이, 학습의 중간에 각 뉴런에 대해 0과 1 사이의 논리 연산자들에 대한 확률이 존재한다. 그러나, 수렴 후에는 일반적으로 확률들 중 하나나 두 개만이 0이 아닌 값을 가지며, 적어도 하나의 값은 1에 가깝다. 도 2는 회귀 작업을 수행하기 위한 신경 네트워크를 보여준다. 이 경우, \"클래스 0\"이나 \"클래스 1\" 대신, 신경 네트워크의 출력은 출력 계층 의 값이다. 보다 구체적으로, 상기 출력들은 부울 값의 어레이 (즉, 각 값이 0 또는 1인 값들의 벡터)일 수 있다. 대안으로, 스칼라 출력이 있을 수 있다. 보다 구체적으로, k차원 출력을 생성(예측)하기 위해 출력 계층 에 n개의 뉴런이 있을 수 있다. 상기 출력 은 k개의 그룹들로 그룹화될 수 있다(예: 의 크기). 출력(예측)의 각 차원 i에 대해, 다음과 같은 스칼라 파라미터 가 있을 수 있으며, 그래서 는 유효하며 출력(예측)에 대해 결정된(바람직한) 범위를 제공 한다. 예를 들어, 회귀 작업의 목적이 강수량을 예측하는 것이라면 차원이 1개일 수 있지만, 회귀 작업의 목적이 강수 량과 풍속을 예측하는 것이라면 차원이 2개일 수 있다. 강수량의 범위는 0~200mm로 결정된다. 또 다른 예로, 회 귀 작업이 이미지 생성인 경우 k는 픽셀 개수일 수 있으며, 따라서 784픽셀 이미지를 생성하려면 k는 784일 수 있다. 최종 출력은 출력 계층 에서의 출력 뉴런들의 1 값을 카운트함으로써 결정될 수 있다. 양수 값과 음수 값을 모두 포함하는 출력을 생성하려면 바이어스 는 결정된 범위(즉, 출력 공간)를 시프트시 키기 위해 사용될 수 있다. 따라서 최종 출력은 다음에 표시된 것처럼 출력 뉴런들을 카운트하고 아핀(affine) 변환을 적용하여 결정될 수 있다: (수학식 1) 아핀 변환은 0 내지 n/k의 결정된 범위를 더욱 적합한 응용 프로그램 특정 범위로 변환(또는 시프트)하는 데 사 용될 수 있다. 몇몇 경우, 출력의 모든 차원이 동일한 범위를 갖기 때문에 모든 i에 대해 그리고 이다. 어떤 경우, 결정된 범위가 모든 실수를 포함하는 것이 바람직할 수 있으며, 이는 다음과 같이 로짓(logit) 변환 을 사용하여 달성할 수 있다: (수학식 2) 여기에서"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "출력을 사용하면, 평균 제곱 오차(mean squared error, MSE) 손실은 다음과 같이 공식화될 수 있다. (수학식 3) 다른 측면에서, 도 2의 신경 네트워크는 도 1의 신경 네트워크에 대응한다. 도 3은 기계 학습 작업을 수행하기 위해 신경 네트워크를 훈련하는 방법을 보여준다. 상기 신경 네트워크는 위 에서 설명한 도 1과 2의 신경 네트워크에 대응할 수 있다. 신경 네트워크는 심층 미분가능 논리 게이트 네트워크라고 할 수 있는데, 훈련 후 모든 계산을 기존 신경 네트 워크에서 일반적으로 수행되는 부동 소수점 계산이 아닌 부울 값에 대한 이진 연산으로 수행한다. 신경 네트워 크의 각 뉴런에 대한 연산자는 논리 게이트를 사용하여 독점적으로 구현될 수 있다. 이는 훈련된 신경 네트워크 를 이용하여 기계 학습 작업을 수행할 때 매우 희소한 네트워크 및 증가된 효율성으로 이끌 수 있다. 기계 학습 작업을 위한 데이터(예: 테스트 데이터)를 제1 계층 의 뉴런들에 걸쳐 확산함으로써 효율성이 더욱 증가될 수 있다. S201 단계에서, 신경 네트워크에 대한 입력 데이터가 수신된다. 입력 데이터는 이진값 입력들 로서 수신될 수 있으며, 그래서 계층들 (103 내지 105) 내 각 뉴런이 두 개의 입력을 수신하도록 한다. 입력 데이터에는 훈 련 데이터, 검증 데이터, 및 테스트 데이터가 포함될 수 있다. 훈련 데이터는 각 뉴런의 확률 분포를 학습하는 데 사용될 수 있다. 검증 데이터는 신경 네트워크가 충분히 정확한지 여부를 판단하는 데 사용될 수 있으며, 즉, 학습이 완료되었는지 여부를 판단하는 데 사용될 수 있다. 테스트 데이터는 추론 동안에 (학습이 완료된 후) 사용될 수 있으며, 예를 들어, 다른 신경 네트워크나 기존 신경 네트워크에 대해 신경 네트워크를 평가하는 데 사용될 수 있다. 단계 S203에서, 신경 네트워크의 복수의 하이퍼파라미터에 대한 값들이 결정된다. 하이퍼파라미터에는 여러 계 층들 (예: 약 2개에서 약 32개), 각 계층의 뉴런들의 수 (예: 약 12개에서 약 1,024,000개) 및 학습 레이트가 포함될 수 있다. 예를 들어, 각 계층은 같은 수의 뉴런을 가질 수 있다. 추가로 또는 대안으로, 약 4개에서 약 8개의 계층이 있 을 수 있다. 이는 신경 네트워크의 아키텍처/구조를 미세하게 조정할 필요가 없다는 이점으로 이끌 수 있다. 따 라서, 이는 하이퍼파라미터들을 결정하는 것을 간소화하고 빠르게 할 수 있다. 학습 레이트는 약 0.01의 상수 값을 가질 수 있다. 단계 S205에서, 신경 네트워크는 하이퍼파라미터 값들에 따라 구축될 수 있다. 이는 하이퍼파라미터 값들에 따 라 여러 개의 계층(예: 4개) 및 계층당 여러 개의 뉴런(예: 8000개)을 생성하는 것을 포함할 수 있다. 구축하는 것은 뉴런들 간 연결(즉, 네트워크의 가중치)을 의사 난수로 초기화하는 것을 포함할 수 있다. 연결(가중치)을 초기화하는 다른 방법도 가능하다. 예를 들어, 기존 방식에 따라 결정된 가중치들을 가진 훈련된 신경 네트워크 가 기반으로서 사용될 수 있다. 각 뉴런은 복수의 논리 연산자들에 대한 확률 분포를 포함할 수 있다. 논리 연산자들 각각은 다음과 같은 서명 을 가질 수 있다."}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "하드 바이너리 값들 대신에, 확률 분포의 확률들은 로 완화될 수 있다. 이는 신경 네트워 크를 미분가능하게 만드는 단계일 수 있다. 신경 네트워크에서, 단일 뉴런은 다음과 같이 정의될 수 있다. 뉴런에 대한 두 개의 입력은 로 정의 될 수 있다. 따라서, 는 확률 심플렉스 에 있으며, 그리고 논리 연산자들에 걸친 확률 분포이다. 는 를 통해 파라미터화될 수 있으며, 여기에서 이다. 또한, 는 위의 표 2에 따르면 ID i를 갖는 실수 값 논리 연산자일 수 있다. 그러면 뉴런의 출력 o는 다음과 같이 정의될 수 있다. (수학식 4)"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "출력 는 일 수 있다. 각 뉴런에 존재하는 논리 연산자(즉, 논리 게이트)에 대한 선택을 확률 분포(예: 범주형 확률 분포)에 의해 표 현함으로써(예: 경사 하강 기반 알고리즘 사용), 이진 입력들을 사용하더라도 신경 네트워크 내 뉴런들이 서로 구별될 수 있으므로, 즉, 네트워크 내 값들이 더 이상 로 제한되지 않으므로, 훈련이 수행될 수 있다. 유리하게는, 신경 네트워크를 저장하는 데 필요한 저장 공간 요구 사항은 논리 연산자를 사용하는 대신 부동 소 수점 연산을 수행하는 신경 네트워크를 위한 공간 요구 사항에 비해 상당히 적을 수 있다. 예를 들어, 복수의 논리 연산자는 16개의 논리 연산자로 구성될 수 있다. 따라서, 신경 네트워크가 훈련된 후에는 주어진 뉴런에 대한 논리 연산자를 표현하는 데 4비트만이 필요하다. 즉, 주어진 뉴런이 실행하는 연산을 지정하는 정보를 저 장하기 위해 4비트만이 필요하다. 이는 뉴런들이 더 복잡한 연산을 수행하는 신경 네트워크에 필요한 메모리보 다 훨씬 더 적을 수 있다. 기존의 희소 신경 네트워크에서, 희소 신경 네트워크의 뉴런들 (가중치들) 간의 연결들이 훈련될 수 있다. 단계 S207에서, 신경 네트워크는 하이퍼파라미터 값들에 따라 훈련될 수 있다. 기존의 희소 신경 네트워크와 달 리, 신경 네트워크를 훈련하는 것은 각 뉴런에서 어떤 논리 연산자(즉, 이진 함수)를 구현할 것인지 학습하는 것을 포함할 수 있지만, 뉴런들 간의 연결들은 초기화 후 고정된 상태로 유지된다. 그래서, 학습 목표는 각 뉴 런에 어떤 논리 연산자가 있어야 하는지 결정하는 것일 수 있다. 따라서, 네트워크는 각 뉴런에서 논리 연산자 에 대한 확률 분포를 학습함으로써 (연속적으로) 파라미터화될 수 있다. 상기 신경 네트워크는 완화될 수 있다. 즉, 고정된 논리 연산자 대신 논리 연산자의 확률 분포가 사용될 수 있 으며, 신경 네트워크는 훈련 동안에 확률들에 따라 작동할 수 있다. 논리 연산자를 완화하는 것은 신경 네트워 크를 미분가능하게 만드는 다른 단계일 수 있다. 각 뉴런의 확률 분포를 학습하는 것은 (완화된) 소프트맥스 파 라미터화를 통해 수행될 수 있다. 확률 분포를 학습하는 것은 16개의 논리 연산자에 대응하는 16개의 부동 소수점 값으로 각 뉴런을 파라미터화하 여 구현될 수 있다. 소프트맥스를 사용하면 16개의 부동 소수점 값을 확률 심플렉스(즉, 모든 항목들을 합하면 1이 되고 음수가 아닌 값들만 존재하는 범주형 확률 분포)로 매핑할 수 있다. 위의 수학식 4에 대한 논의를 참 조하면, 신경 네트워크를 초기화하는 동안 뉴런을 파라미터화하는 것은 표준 정규 분포와 독립적으로 q의 요소 를 선택(그리기(drawing)하는 것을 포함할 수 있다. 훈련은 각 뉴런에 대한 16개의 논리 연산자를 모두 평가하고 범주형 확률 분포를 사용하여 가중 평균을 계산하 는 것을 포함할 수 있다. 따라서 훈련 동안에 모든 뉴런의 출력은 일 수 있다. 보다 구체적으로, 출력 계층에 k개의 클래스와 n개의 뉴런이 있는 분류 작업의 경우, 출력은 n/k 크기의 k개 그 룹으로 그룹화될 수 있다. 이런 방식에서, 각 그룹에서 1의 개수를 카운트함으로써 클래스들 각각에 대한 분류 점수가 결정될 수 있다. 따라서, 분류 작업의 맥락에서, 신경 네트워크의 출력은 분류 점수들의 argmax를 취함 으로써 결정될 수 있다. 신경 네트워크의 정확도가 충분한지 판단하기 위해 1의 개수를 카운트하는 대신 그룹들 각각에서의 출력들의 확 률들이 합산될 수도 있다. 따라서, 분류 손실을 계산하여 정확도 측정이 결정될 수 있다. 예를 들어, 소프트맥 스 교차 엔트로피 분류 손실은 다음과 같이 계산될 수 있다: (수학식 5) 출력 뉴런들 에 대해, 결과(참) 클래스 에 대한 원-핫 (one-hot) 인코딩, 그리고 소프트맥 스 온도 . 훈련을 위해 Adam 최적화 알고리즘이 사용될 수 있다. 훈련이 완료된 후, 뉴런에 대한 두 개의 입력은 로 정의될 수 있다. 그래서, 학습 동안의 뉴런(방정 식 4 참조)과는 달리, 뉴런에 대한 입력은 부동 소수점 값 ≥ 0 및 ≤ 1이 될 수 있지만, 훈련 후에는 뉴런에 대한 입력은 부울 값, 즉 0 또는 1이 될 수 있다. 마찬가지로 뉴런의 출력 o는 일 수 있다. 따라서, 훈 련 후 뉴런의 출력 o는 다음과 같이 정의될 수 있다. (수학식 6) 여기에서, 수학식 6에서 . i는 표 2에서의 ID를 지칭한다. 단계 S209에서, 각 뉴런에 대한 논리 연산자가 결정될 수 있다. 논리 연산자는 훈련이 완료된 후, 즉 추론 동안 에 결정될 수 있다. 결정된 논리 연산자는 가장 가능성이 높은 논리 연산자,예를 들어, 가장 높은 확률을 갖는 확률 분포의 논리 연산자일 수 있다. 즉, 확률 분포는 최빈값을 취함으로써 이산화될 수 있다. 따라서, 기계 학 습 작업은 부동 소수점 값이 아닌 부울 값을 계산함으로써 수행될 수 있으며, 이를 통해 부동 소수점 연산에 의 존하는 신경 네트워크에 비해 분류를 효율적으로 만든다. 훈련된 신경 네트워크를 사용하여 기계 학습 작업을 수행하기 전에, 신경 네트워크는 실행 가능한 적어도 하나 의 바이너리로 컴파일될 수 있다. 상기 실행 가능한 바이너리는 프로세서에 따라 달라질 수 있다. 예를 들어, 두 개의 바이너리 실행 파일이 컴파일될 수 있는데, 하나는 CPU용(예: C 코드에서)이고 다른 하나는 GPU용(예: CUDA에서)이다. 또한, 논리적 표현식 및/또는 하위 표현식이 단순화될 수 있다. 예를 들어, 부울 데이터 유형 대신, 기계 학습 작업이 수행될 프로세서에 대응하는 하드웨어-구현 데이터 유형을 사용할 수 있다. 예를 들어, 64비트 CPU의 경우 하드웨어-구현 데이터 유형은 int64가 될 수 있다. 또한 64의 집계 크기를 사용 할 수 있는데, 이는 주어진 반복(즉, 에포크)에서 64개의 샘플(예: 이미지)이 신경 네트워크를 통해 처리된다는 것을 의미한다. GPU에서, 출력 뉴런들은 각자의 덧셈기를 구성하는 논리 게이트를 사용하여 직접 집계될 수 있 으며, 이는 GPU 메모리에 대한 어떤 쓰기들도 병목(즉, 성능 저하)을 초래하는 결과를 가져올 수 있기 때문이다. 일반적으로 병목(속도를 저하시킬 수 있는 시스템에서의 포인트)은 데이터 로더 및/또는 전송 속도일 수 있다. 따라서, 더 큰 배치들에서 비트 연산이 수행될 수 있으며, 이는 기계 학습 작업을 수행하는 속도에 상당한 영향 을 미칠 수 있다. 출력 계층 은 클래스당 여러 개의 출력을 생성할 수 있다. 출력은 비트 카운팅을 통해, 예를 들어, 1을 카 운트함으로써 집계될 수 있으며, 각 클래스에 대한 점수를 산출한다. 따라서, 기계 학습 작업이 분류 작업일 때 에, 신경 네트워크의 출력으로 가장 높은 점수를 받은 클래스를 제공함으로써 분류 작업이 완료될 수 있다. 이진 벡터를 입력으로 주어 기계 학습 작업을 수행할 때, 이진 벡터에서 부울 값의 쌍이 선택될 수 있으며, 계 층 중 하나(예: 계층 의 논리 연산자(즉, 이진 논리 게이트)는 부울 값에 적용될 수 있으며, 그것의 출력은 신경 네트워크 내 후속 계층(예: 계층 (105 또는 107)을 위해 그 후에 사용될 수 있다. 훈련 후, 기계 학습 작업을 수행하는 계산 비용은 기존의 이진 및 희소 신경 네트워크와 비교했을 때 최소한 한 자릿수까지 줄어들 수 있으며, 다른 유형의 기존 신경 네트워크와 비교했을 때 훨씬 더 줄어들 가능성이 있다. 예시적인 기계 학습 작업은, \"The monk's problems: A performance comparison of different learning algorithms\", Thrun et al., 1991.에서 설명된 바와 같은 MONK의 문제가 있다. MONK 문제인 MONK-1, MONK-2, MONK-3은 기계 학습 알고리즘을 벤치마킹하는 데 사용된 3가지 기계 학습 작업들이다. 이는 각각 2 내지 4개의 가능한 값을 갖는 6개 속성을 구비한 데이터 세트에 대한 3개의 이진 분류 작업으로 구성된다. 따라서, 데이터 포인트(샘플)는 크기 17의 이진 벡터로서 인코딩될 수 있다. 테스트 결과, 위에서 논의된 신경 네트워크는 세 가지 MONK 데이터 세트 모두에서 로지스틱 회귀보다 더 정확한 분류를 수행하는 것을 보여준다. 또한, MONK-3의 경우, 위에서 논의된 신경 네트워크(즉, 도 1 및 2)는 훨씬 더 큰 컨벌루션 신경 네트워크보다 더 정확하다. 게다가, 위에서 논의된 신경 네트워크는 로지스틱 회귀보다 3배 이상 빠르고, 더 큰 컨벌루션 신경 네트워크보다 7배 이상 빠르다. 게다가, 위에서 논의된 신경 네트워크는 로 지스틱 회귀나 컨벌루션 신경 네트워크보다 훨씬 적은 저장 공간을 필요로 한다. 또 다른 예시적인 기계 학습 작업으로 성인 인구 조사(\"Uci machine learning repository: Adult data set\", Kohavi et al., 1996) 및 유방암(\"Uci machine learning repository breast cancer dataset\", Zwitter et al., 1988) 데이터 세트가 고려될 수 있다. 성인 데이터 세트에 관련하여, 상기 기계 학습 작업은 주당 근무 시 간 및 교육과 같은 속성들을 기반으로 주어진 성인이 연봉 5만 달러를 넘는지 예측하는 것이다. 유방암과 관련 하여, 상기 기계 학습 작업은 이진 분류가 포함하며 그리고 둘레, 면적, 매끄러움을 포함하는 세포 핵의 특성들 을 기반으로 암 진단이 양성인지 악성인지를 판별하는 것을 수반한다. 이러한 작업들에 대해, 위에서 설명된 신 경 네트워크에 의해 달성된 (분류) 정확도는 기존의 (컨벌루션) 신경 네트워크와 로지스틱 회귀와 비슷하다. 추 가로, 분류 속도는 로지스틱 회귀보다 10배 이상 빠르고 기존 신경 네트워크보다 40배 이상 빠르다. 또한, 앞서 설명된 신경 네트워크는 로지스틱 회귀보다 약 20% 적은 저장 공간을 필요로 하고, 기존 신경 네트워크보다 약 75% 적은 저장 공간을 필요로 한다. 더욱이, 이미지 분류에서 매우 높은 프레임 속도가 달성될 수 있다. 예를 들어, 위에서 논의된 신경 네트워크의 경우, 초당 100만 개 이미지들을 초과하는 프레임 속도는 MNIST (Modified National Institute of Standards and Technology) 데이터세트 (http://yann.lecun.com/exdb/mnist/) 및 CIFAR-10 (Canadian Institute For Advanced Research) 데이터세트의 이미지들에서 달성될 수 있다 (\"Learning Multiple Layers of Features from Tiny Images\", Alex Krizhevsky, April 8, 2009). 즉, 초당 100만 개 이상의 이미지들을 분류하는 속도가 단일 CPU 코어를 사용하여 달성될 수 있다. 이는 기존의 접근 방식의 효율을 능가할 수 있다. 더 구체적으로, 위에서 논의된 신경 네트워크는, 이진 연산의 10% 미만의 개수만을 필요로 하면서도, 가장 빠른 기존 이진 신경 네트워크와 비슷한 MNIST 데이터 세트에 대한 이미지 분류 정확도를 가질 수 있다. 표준 GPU(예: NVIDIA A6000)에서, 위에서 설명된 신경 네트워크는 7% GPU 활용만을 필요로 하면서도, 특화된 FPGA 상 에서의 기존 이진 신경 네트워크보다 12배 더 빠르게 수행할 수 있다. 다른 기존의 이진 신경 네트워크와 비교 했을 때, 위에서 논의된 신경 네트워크는 약 3배 정도 더 빠를 수 있다. 진화적으로 학습된 희소 함수 네트워크 와 비교해 볼 때, 위에서 논의된 신경 네트워크가 더 정확하다. CIFAR-10 데이터 세트를 사용한 이미지 분류의 경우, 위에서 설명된 신경 네트워크의 정확도는 기존의 컨벌루션 신경 네트워크와 비슷할 수 있으나, 어떤 경우에는 0.1% 미만의 메모리만을 필요로 하며 다른 경우에는 1% 미만 의 메모리만을 필요로 한다. 특화된 완전 연결 네트워크는 정확도가 약간 더 높을 수 있지만(4% 미만), 64% 더 많은 메모리의 비용을 필요로 한다. CIFAR-10 데이터 세트를 사용하여 이미지 분류를 수행할 때, 부동 소수점 연산에 의존하는 기존의 완전 연결 신 경 네트워크는 기계 학습 작업을 수행하기 위해 2,000,000개의 부동 소수점 연산을 필요로 할 수 있는 반면, 위 에서 설명된 신경 네트워크는 가지치기나 최적화 전에 5,000,000개의 비트 논리 연산을 필요로 한다. 부동 소수 점 산술 하드웨어 가속 집적 회로(예: 최신 GPU 및 많은 CPU)에서는 2,000,000개의 부동 소수점 연산은 5,000,000개의 비트 논리 연산보다 약 100배 더 느리다. 부동 소수점 산술 가속이 없다면, 속도에서의 차이는 한 자릿수 더 클 것이며, 즉, 상기 차이는 세 자릿수가 될 것이다. 기존의 희소 신경 네트워크조차도 기존의 완전 연결 신경 네트워크보다 빠르지만, 여전히 위에서 설명된 신경 네트워크보다 최소한 한 자릿수 이상 느리다. 하나의 희소 신경 네트워크는 위에서 설명된 신경 네트워크보다최소한 두 배나 많은 저장 공간을 필요로 한다. (도 1 및 2와 관련하여) 위에서 논의된 신경 네트워크의 가능한 예시적인 아키텍처는 아래 표 6에 나와 있다: 표 6"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "표 7은 표 6의 신경 네트워크 구성과 비교하기 위한 기준으로 사용되었던 완전 연결된 ReLU 네트워크의 구성을 보여준다. 표 7"}
{"patent_id": "10-2024-7028676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "추가로, 일반적인 범용 데스크톱이나 노트북 컴퓨터에서 CPU의 각 클록 사이클에서 (즉, 헤르츠당) 그 CPU의 각 코어에서 평균 약 250개의 이진 논리 게이트를 계산하는 것이 가능할 수 있다. 이는 일반적인 CPU가 단일 코어 에서도 클록 사이클 당 많은 명령어들을 실행하기 때문에 가능하다. 이는 부동 소수점 연산에 의존하는 신경 네 트워크를 실행할 때에 가능한 것보다 훨씬 빠를 수 있다. 또한, CPU는 데이터의 여러 샘플들(예: 이미지들)로부 터의 비트들을 단일 정수(예: int64 데이터 유형을 갖는 정수)로 그룹화함으로써 기계 학습 작업의 데이터가 제 1 계층 의 뉴런들에 걸쳐 확산되는 것을 가능하게 할 수 있다. 여러 샘플들로부터의 비트들을 단일 정수로 그룹화하는 것은 단일 명령 다중 데이터(single-instruction multiple-data, SIMD)로 지칭될 수 있다. 고급 벡 터 확장(advanced vector extensions, AVX)을 사용하면 추가의 효율성이 가능할 수도 있을 것이다. n개의 뉴런들이 있는 계층(예: 계층들 (103, 105 또는 107)에 의해 수행되는 기계 학습 작업의 일부에 대한 계 산 비용은 작은 상수 비용을 포함하여 O(n)일 수 있으며, 이는 부울의 논리 게이트만 필요하기 때문이다(즉, 연 산은 논리 연산자를 통해서만 수행되므로 매우 효율적으로 수행할 수 있음). 비교해 보면, m개의 입력 뉴런을 갖는 완전 연결 계층은 상당히 높은 상수 비용을 구비한 O( )의 계산 비용을 가지며, 그 이유는 특히 완전 히 연결된 계층은 일반적으로 부동 소수점 연산을 필요로 하기 때문이다. 전반적으로, 도 1과 도 2를 참조하여 설명된 상기 방법에 따라 훈련된 신경 네트워크를 사용하여 기계 학습 작업을 수행하는 것은 완전히 연결된 ReLU 신경 네트워크(ReLU 활성화 함수를 사용하는 신경 네트워크)보다 두 배나 더 빠른 추론 속도로 이끌 수 있 다. 또한, 도 1과 도 2의 방법에 따라 학습된 신경 네트워크는 기존의 이진 신경 네트워크보다 13배 이상 빠르 고, 기존의 희소 신경 네트워크의 이론적인 속도보다 2~3배 더 빠를 수 있다.도 4는 기계 학습 작업을 수행하도록 훈련된 후 신경 네트워크 상의 논리 게이트의 분포를 보여준다. 이 경우, 기계 학습 작업은 이미지 분류를 포함한다. 상기 신경 네트워크는 계층마다 12,000개의 뉴런이 있는 4개의 계층 을 가진다. 계층 1과 계층 2의 경우, X축의 값은 표 2에서의 ID에 대응하며, 계층 3과 계층 4에 대한 X축의 값 에도 대응한다. Y축의 값은 X축의 논리 연산자가 있는 뉴런들의 수에 대한 카운트를 제공한다. 도 4에서, (표 2에서의 ID 0과 15에 대응하는) 상수 \"0\"과 \"1\"에 대한 논리 연산자들이 매우 드물게 사용되며 계층 4에서는 전혀 나타나지 않는다는 것을 알 수 있다. 제1 계층에서, \"and\", \"nand\", \"or\", 및 \"nor\"가 상대 적으로 강한 확률을 갖는다. 제2 계층 및 제3 계층에서, \"A\", \"B\", \" A\", 및 \" B\"가 더 많이 나오며, 이는 잔여 직접 연결로 볼 수 있으며, 그 이유는 두 입력들 중 하나가 무시되고 다른 입력이 (아마도 수정된 형태로) 다음 계층으로 전달되기 때문이 다. 이는 상기 신경 네트워크가 미리 정의된 계층들 수보다 더 적은 계층을 사용하여 하위 순위 종속성을 표현 함으로써 더욱 효율적으로 하위 순위 종속성을 모델링하는 것을 가능하게 할 수 있다. 계층 4에서, 가장 빈번한 연산은 \"xor\" 및 \"xnor\"인데, 이는 이전 계층들의 활성화에 대한 조건부 종속성을 생 성할 수 있다. 보여진 바와 같이, 암시는 자주 사용되지 않는다. 그러나, 테스트 결과, (표 2의 확률적 해석의 16개 연산자 대신) 논리 연산자의 적절한 서브세트만을 사용하는 것이 감소된 정확도로 이끌 수 있다는 것을 보 여준다."}
{"patent_id": "10-2024-7028676", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 입력들, 두 개의 은닉 계층들 및 출력 계층을 포함하는 단순화된 신경 네트워크를 보여준다. 도 2는 또 다른 단순화된 신경 네트워크를 보여준다. 도 3은 기계 학습 작업을 수행하기 위해 신경 네트워크를 훈련하는 방법의 단계들을 보여준다. 도 4는 훈련 후 4개 계층 신경 네트워크의 논리 연산자들 분포를 보여준다."}
