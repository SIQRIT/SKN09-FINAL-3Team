{"patent_id": "10-2022-0023210", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0126110", "출원번호": "10-2022-0023210", "발명의 명칭": "보완된 신경망 양자화 연산을 이용한 데이터 처리 방법 및 데이터 처리 장치", "출원인": "삼성전자주식회사", "발명자": "박미정"}}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "보완된 신경망 양자화 연산을 이용한 데이터 처리 방법에 있어서,신경망의 가중치를 양자화하여 양자화된 가중치를 획득하는 단계;상기 가중치와 상기 양자화된 가중치의 차이인 양자화 에러를 획득하는 단계;상기 신경망에 대한 입력 데이터를 획득하는 단계;상기 양자화된 가중치와 상기 입력 데이터의 콘볼루션 연산을 수행하여 제1 콘볼루션 연산 결과를 획득하는 단계;상기 양자화 에러와 상기 입력 데이터의 콘볼루션 연산을 수행하여 제2 콘볼루션 연산 결과를 획득하고, 비트시프트 연산을 이용하여 상기 제2 콘볼루션 연산 결과를 스케일링함으로써 스케일링된 제2 콘볼루션 연산 결과를 획득하는 단계;상기 제1 콘볼루션 연산 결과 및 상기 스케일링된 제2 콘볼루션 연산 결과를 이용하여 출력 데이터를 획득하는단계;를 포함하는, 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 양자화는 부동소수점 데이터를 n 비트의 양자화된 고정소수점 데이터로 변환하는 연산인, 보완된 신경망양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 양자화 에러는 상기 차이에 양자화가 수행된 것인, 보완된 신경망 양자화 연산을 이용한 데이터 처리방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 비트 시프트 연산에서 비트 시프트 값은 상기 가중치에 대한 제1 스케일 인자와 상기 양자화 에러에 대한제2 스케일 인자에 기초하여 결정되는, 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 양자화 에러의 크기가 상기 제1 스케일 인자와 동일한 경우, 상기 비트 시프트 값은 n 비트로 결정되고,상기 n은 양자화 비트 값인, 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 제1 스케일 인자와 상기 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되는 경우, 상기 비트 시프트값은 n + k 비트로 결정되고, 상기 n은 양자화 비트 값이고, k는 2의 제곱수에서 제곱수의 값인, 보완된 신경망양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2023-0126110-3-제4항에 있어서,상기 제1 스케일 인자와 상기 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되지 않는 경우, 상기 비트 시프트 값은 로그 연산과 라운딩 연산을 통해 결정된 k에 기초하여 결정되는, 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제4항에 있어서,상기 제1 스케일 인자의 범위는 상기 가중치의 최대값과 최소값에 기초하여 결정되는, 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서,상기 제2 스케일 인자의 범위는 상기 양자화 에러의 최대값과 최소값에 기초하여 결정되는, 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제4항에 있어서,상기 제1 스케일 인자는 상기 제2 스케일 인자보다 큰, 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "보완된 신경망 양자화 연산을 이용한 데이터 처리 장치에 있어서,메모리; 및뉴럴 프로세서를 포함하고,상기 뉴럴 프로세서는:신경망의 가중치를 양자화하여 양자화된 가중치를 획득하고, 상기 가중치와 상기 양자화된 가중치의 차이인 양자화 에러를 획득하고, 상기 신경망에 대한 입력 데이터를 획득하고, 상기 양자화된 가중치와 상기 입력 데이터의 콘볼루션 연산을 수행하여 제1 콘볼루션 연산 결과를 획득하고,상기 양자화 에러와 상기 입력 데이터의 콘볼루션 연산을 수행하여 제2 콘볼루션 연산 결과를 획득하고, 비트시프트 연산을 이용하여 상기 제2 콘볼루션 연산 결과를 스케일링함으로써 스케일링된 제2 콘볼루션 연산 결과를 획득하고,상기 제1 콘볼루션 연산 결과 및 상기 스케일링된 제2 콘볼루션 연산 결과를 이용하여 출력 데이터를 획득하도록 구성된, 보완된 신경망 양자화 연산을 이용한 데이터 처리 장치."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 비트 시프트 연산에서 비트 시프트 값은 상기 가중치에 대한 제1 스케일 인자와 상기 양자화 에러에 대한제2 스케일 인자에 기초하여 결정되는, 보완된 신경망 양자화 연산을 이용한 데이터 처리 장치."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 양자화 에러의 크기가 상기 제1 스케일 인자와 동일한 경우, 상기 비트 시프트 값은 n 비트로 결정되고,상기 n은 양자화 비트 값인, 보완된 신경망 양자화 연산을 이용한 데이터 처리 장치.공개특허 10-2023-0126110-4-청구항 14 제12항에 있어서,상기 제1 스케일 인자와 상기 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되는 경우, 상기 비트 시프트값은 n + k 비트로 결정되고, 상기 n은 양자화 비트 값이고, k는 2의 제곱수에서 제곱수의 값인, 보완된 신경망양자화 연산을 이용한 데이터 처리 장치."}
{"patent_id": "10-2022-0023210", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 제1 스케일 인자와 상기 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되지 않는 경우, 상기 비트 시프트 값은 로그 연산과 라운딩 연산을 통해 결정된 k에 기초하여 결정되는, 보완된 신경망 양자화 연산을 이용한 데이터 처리 장치."}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "신경망의 가중치를 양자화하여 양자화된 가중치를 획득하는 단계; 가중치와 양자화된 가중치의 차이인 양자화 에 러를 획득하는 단계; 신경망에 대한 입력 데이터를 획득하는 단계; 양자화된 가중치와 입력 데이터의 콘볼루션 연산을 수행하여 제1 콘볼루션 연산 결과를 획득하는 단계; 양자화 에러와 입력 데이터의 콘볼루션 연산을 수행 하여 제2 콘볼루션 연산 결과를 획득하고, 비트 시프트 연산을 이용하여 제2 콘볼루션 연산 결과를 스케일링함으 로써 스케일링된 제2 콘볼루션 연산 결과를 획득하는 단계; 제1 콘볼루션 연산 결과 및 스케일링된 제2 콘볼루션 연산 결과를 이용하여 출력 데이터를 획득하는 단계를 포함하는 보완된 신경망 양자화 연산을 이용한 데이터 처 리 방법 및 데이터 처리 장치가 제공된다."}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 보완된 신경망 양자화 연산을 이용하는 데이터 처리 방법 및 장치에 관한 것이다. 구체적으로, 본 개 시는 AI(Artificial Intelligence), 예를 들어, 신경망의 양자화 연산에 있어서, 양자화 에러를 고려하여 보완 함으로써 데이터를 처리하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(artificial intelligence) 관련 기술의 발달과 인공지능을 이용한 데이터를 처리하는 하드웨어의 개발 및 보급에 따라, 신경망을 이용하여 데이터를 효과적으로 처리하는 방법 및 장치에 대한 필요성이 증대하고 있 다."}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예에 따른 보완된 신경망 양자화 연산을 이용하는 데이터 처리 방법 및 장치는 신경망의 가중치를 양자 화하여 양자화된 가중치를 획득하고, 가중치와 양자화된 가중치의 양자화 에러를 획득하고, 신경망의 입력 데이 터와 양자화된 가중치 사이의 제1 콘볼루션 연산 결과를 획득하고, 양자화 에러와 입력 데이터 사이의 제2 콘볼 루션 연산 결과를 획득하고, 제2 콘볼루션 연산 결과에 대하여 가중치에 대한 스케일링 인자와 양자화 에러에 대한 스케일링 인자에 기초하여 계산된 하드웨어 연산에 효율적인 비트 연산자 스케일을 이용한 비트 시프트 연 산을 수행하여 스케일링된 제2 콘볼루션 연산 결과를 획득하고, 제1 콘볼루션 연산 결과 및 스케일링된 제2 콘 볼루션 연산 결과를 이용하여 출력 데이터를 획득함으로써, 양자화 에러를 이용하여 저 정밀도(Low precision) 를 지원하는 뉴럴 프로세싱 유닛(Neural Processing Unit, NPU)의 콘볼루션 연산에서 고 정밀도(High precision)의 효과를 낼 수 있도록 하는 것을 과제로 한다."}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 보완된 신경망 양자화 연산을 이용한 데이터 처리 방법은 신경망의 가중치를 양자화하여 양자 화된 가중치를 획득하는 단계; 가중치와 양자화된 가중치의 차이인 양자화 에러를 획득하는 단계; 신경망에 대 한 입력 데이터를 획득하는 단계; 양자화된 가중치와 입력 데이터의 콘볼루션 연산을 수행하여 제1 콘볼루션 연 산 결과를 획득하는 단계; 양자화 에러와 입력 데이터의 콘볼루션 연산을 수행하여 제2 콘볼루션 연산 결과를 획득하고, 비트 시프트 연산을 이용하여 제2 콘볼루션 연산 결과를 스케일링함으로써 스케일링된 제2 콘볼루션 연산 결과를 획득하는 단계; 제1 콘볼루션 연산 결과 및 스케일링된 제2 콘볼루션 연산 결과를 이용하여 출력 데이터를 획득하는 단계를 포함할 수 있다. 일 실시예에 따라, 양자화는 부동소수점 데이터를 n 비트의 양자화된 고정소수점 데이터로 변환하는 연산일 수 있다.일 실시예에 따라, 양자화 에러는 가중치와 양자화된 가중치의 차이에 양자화가 수행된 것일 수 있다. 일 실시예에 따라, 비트 시프트 연산에서 비트 시프트 값은 가중치에 대한 제1 스케일 인자와 양자화 에러에 대 한 제2 스케일 인자에 기초하여 결정될 수 있다. 일 실시예에 따라, 양자화 에러의 크기가 제1 스케일 인자와 동일한 경우, 상기 비트 시프트 값은 n 비트로 결 정되고, n은 양자화 비트 값일 수 있다. 일 실시예에 따라, 제1 스케일 인자와 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되는 경우, 비트 시프 트 값은 n + k 비트로 결정되고, n은 양자화 비트 값이고, k는 2의 제곱수에서 제곱수의 값일 수 있다. 일 실시예에 따라, 제1 스케일 인자와 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되지 않는 경우, 비트 시프트 값은 로그 연산과 라운딩 연산을 통해 결정된 k에 기초하여 결정될 수 있다. 일 실시예에 따라, 제1 스케일 인자의 범위는 가중치의 최대값과 최소값에 기초하여 결정될 수 있다. 일 실시예에 따라, 제2 스케일 인자의 범위는 양자화 에러의 최대값과 최소값에 기초하여 결정될 수 있다. 일 실시예에 따라, 제1 스케일 인자는 제2 스케일 인자보다 클 수 있다. 일 실시예에 따른 보완된 신경망 양자화 연산을 이용한 데이터 처리 장치는 메모리; 및 뉴럴 프로세서를 포함하 고, 뉴럴 프로세서는: 신경망의 가중치를 양자화하여 양자화된 가중치를 획득하고, 가중치와 양자화된 가중치의 차이인 양자화 에러를 획득하고, 신경망에 대한 입력 데이터를 획득하고, 양자화된 가중치와 입력 데이터의 콘 볼루션 연산을 수행하여 제1 콘볼루션 연산 결과를 획득하고, 양자화 에러와 입력 데이터의 콘볼루션 연산을 수 행하여 제2 콘볼루션 연산 결과를 획득하고, 비트 시프트 연산을 이용하여 제2 콘볼루션 연산 결과를 스케일링 함으로써 스케일링된 제2 콘볼루션 연산 결과를 획득하고, 제1 콘볼루션 연산 결과 및 스케일링된 제2 콘볼루션 연산 결과를 이용하여 출력 데이터를 획득하도록 구성될 수 있다. 일 실시예에 따라, 비트 시프트 연산에서 비트 시프트 값은 가중치에 대한 제1 스케일 인자와 양자화 에러에 대 한 제2 스케일 인자에 기초하여 결정될 수 있다. 일 실시예에 따라, 양자화 에러의 크기가 제1 스케일 인자와 동일한 경우, 상기 비트 시프트 값은 n 비트로 결 정되고, n은 양자화 비트 값일 수 있다. 일 실시예에 따라, 제1 스케일 인자와 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되는 경우, 비트 시프 트 값은 n + k 비트로 결정되고, n은 양자화 비트 값이고, k는 2의 제곱수에서 제곱수의 값일 수 있다. 일 실시예에 따라, 제1 스케일 인자와 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되지 않는 경우, 비트 시프트 값은 로그 연산과 라운딩 연산을 통해 결정된 k에 기초하여 결정될 수 있다."}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 보완된 신경망 양자화 연산을 이용하는 데이터 처리 방법 및 장치는 신경망의 가중치를 양자 화하여 양자화된 가중치를 획득하고, 가중치와 양자화된 가중치의 양자화 에러를 획득하고, 신경망의 입력 데이 터와 양자화된 가중치 사이의 제1 콘볼루션 연산 결과를 획득하고, 양자화 에러와 입력 데이터 사이의 제2 콘볼 루션 연산 결과에 대하여 가중치에 대한 스케일링 인자와 양자화 에러에 대한 스케일링 인자에 기초하여 계산된 하드웨어 연산에 효율적인 비트 연산자 스케일을 이용하여 비트 시프트 연산을 수행하여 스케일링된 제2 콘볼루 션 연산 결과를 획득하고, 제1 콘볼루션 연산 결과 및 스케일링된 제2 콘볼루션 연산 결과를 이용하여 출력 데 이터를 획득함으로써, 실제 NPU에서 신경망 가중치의 양자화로 발생한 에러를 보완하여 고 정밀도(High precision)의 비트만큼 정확도를 유지하고, 저 정밀도(Low precision)의 NPU의 콘볼루션 연산에서 고 정밀도에 서 가질 수 있는 정확도를 보존하면서 연산량 및 메모리의 최적화 효과를 동시에 얻을 수 있다."}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고, 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 개시의 실시 형태에 대해 한정 하려는 것이 아니며, 본 개시는 여러 실시예들의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 실시예를 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제 1, 제 2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에서 '~부(유닛)', '모듈' 등으로 표현되는 구성요소는 2개 이상의 구성요소가 하나의 구성요소 로 합쳐지거나 또는 하나의 구성요소가 보다 세분화된 기능별로 2개 이상으로 분화될 수도 있다. 또한, 이하에 서 설명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다른 구성요소 에 의해 전담되어 수행될 수도 있음은 물론이다. 또한, 본 명세서에서 '신경망(neural network)'은 뇌 신경을 모사한 인공신경망 모델의 대표적인 예시로서, 특 정 알고리즘을 사용한 인공신경망 모델로 한정되지 않는다. 신경망은 심층 신경망(deep neural network)으로 참 조될 수도 있다. 또한, 본 명세서에서 '파라미터(parameter)'는 신경망을 이루는 각 레이어의 연산 과정에서 이용되는 값으로서 예를 들어, 입력 값을 소정 연산식에 적용할 때 이용될 수 있다. 파라미터는 훈련의 결과로 설정되는 값으로서, 필요에 따라 별도의 훈련 데이터(training data)를 통해 갱신될 수 있다. 또한, 본 명세서에서 '가중치(weight)'는 파라미터 중 하나로, 신경망에 대한 출력 데이터를 획득하기 위해, 입 력 데이터의 콘볼루션 계산에 이용되는 값이다. 도 1은 신경망의 가중치를 양자화하여 데이터를 출력하는 과정을 설명하기 위한 도면이다. 도 1을 참고하면, 훈련된 신경망을 이용하여 데이터를 처리하는 과정은 신경망의 부동 소수점 모델을 양자 화하여 싱글 정밀도(single precision) 모델 데이터, 즉 32 비트로 표현된 신경망의 양자화된 가중치 를 획득하고, 신경망에 대한 입력 데이터와 콘볼루션함으로써 출력 데이터를 획득하는 과정이다. '부동 소수점'은 컴퓨터에서 소수점의 위치를 고정시키지 않으며 가수와 지수를 이용하여 수를 표현하는 방식이 고, '고정 소수점'은 컴퓨터에서 고정된 위치의 소수점을 이용하여 수를 표현하는 방식이다. 고정 소수점 방식 은 한정된 메모리에서 부동 소수점 방식보다 좁은 범위의 수만 나타낼 수 있다.즉, 부동 소수점 방식으로 수, 데이터를 나타내는 것은 고정 소수점 방식보다 많은 비용이 요구될 수 있으므로, 저 정밀도의 NPU에서 부동 소수점 방식으로 표현된 데이터를 고정 소수점 방식으로 양자화할 필요가 있다. 후술 되는 도 2에서 부동 소수점 방식에서 고정 소수점 방식으로 양자화하는 과정이 상술된다. 도 2는 부동 소수점 데이터를 고정 소수점 데이터로 양자화하는 과정을 설명하기 위한 도면이다. 도 2를 참고하면, 부동 소수점으로 표현된 가중치 w을 고정 소수점으로 표현된 가중치 (25 0)으로 양자화하기 위해, 부동 소수점에서 가중치 에 대응하는 가중치 으로 매핑된다. 이에 따 라 부동 소수점 방식의 가중치 w와 양자화된 가중치 에 대응하는 가중치 사이의 양자화 에러 Δ가 발생된다. 여기서, 연속적인 부동 소수점의 가중치들을 n비트의 값으로 표현하기 위해서, 가중치의 최소값 및 최대값의 범 위를 기준으로 스케일 인자(scale factor) s가 한 개의 값으로 수학식 1과 같이 표현된다. [수학식 1]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이에 따라, 고정 소수점의 양자화 가중치 는 아래와 같이 2n 값 중 하나로 수학식 2와 같이 표현된다. [수학식 2]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "그리고, 양자화 가중치에 대응하는 부동 소수점의 가중치 는 수학식 3과 같이 표현된다. [수학식 3]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "또한, 양자화로 인해 발생하는 양자화 에러 Δ는 수학식 4와 같이 표현된다. [수학식 4]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "또한, 양자화 에러 에러 Δ의 스케일()은 양자화 에러들의 최대값 및 최소값을 기준으로 결정되기 때문 에 [0, ] 사이의 값으로 결정된다. 도 3은 종래의 양자화된 가중치를 이용하여 데이터를 출력하는 과정을 설명하기 위한 도면이다. 신경망의 가중치(w)와 입력 데이터(x)를 이용한 콘볼루션 계산을 통한 출력 데이터(y)는 일반적으로 수학식 5와 같이 표현된다 [수학식 5]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 6, "content": "도 3을 참고하면, 위의 콘볼루션 연산식은 양자화된 입력 데이터의 x 입력 스케일 인자 sin과 양자화된 출 력 데이터의 y 출력 스케일 인자 sout을 이용하여 수학식 6과 같은 양자화 콘볼루션 연산식으로 표현된다.[수학식 6]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 6은 일반적인 콘볼루션 연산과 동일한 형태이나, 양자화 가중치 와 입력 를 이용하여 연산 후, 전 체 스케일( )이 반영된 것이다. 구체적으로, 양자화 콘볼루션에서는 싱글 정밀도(single precision)으로 양자화된 입력 데이터와 가중치의 누적(accumulate) 연산이 수행된 후, 양자화된 입력, 가중치, 출력의 스케일을 반영한 전체 스케일( )값으 로 리스케일(rescale)하는 것이다. 그러나, 이러한 양자화 콘볼루션 연산으로 인해, 부동 소수점으로 표현된 가중치 w와 양자화 가중치 에 대응 하는 부동 소수점의 사이에는 양자화 에러 Δ가 발생되고, 양자화 에러 Δ만큼의 에러가 보정되지 않 아, 기존 콘볼루션의 결과와 차이가 발생하게 된다. 이러한 양자화 에러를 보완하기 위한 변형된 부분합 양자화 콘볼루션 연산이 도 4에서 상술된다. 도 4는 일 실시예에 따른 양자화된 가중치, 양자화 에러, 비트 시프트 연산을 이용하여 데이터를 출력하는 과정 을 설명하기 위한 도면이다. 도 4를 참고하면, 양자화 콘볼루션 연산 외에 양자화 에러에 대한 추가적인 연산을 이용하여 부분합 연산을 수행하고, 양자화된 입력 데이터의 x 입력 스케일 인자 sin과 양자화된 출력 데이터의 y 출력 스케 일 인자 sout을 이용하여 수학식 7과 같은 보완된 콘볼루션 연산이 수행된다. [수학식 7]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 7과 같이, 기존의 수학식 6의 양자화 콘볼루션에서 부분을 추가되어 양자화 콘볼루션 연산 이 보완된다. 양자화 에러 Δ를 양자화한 값 과 양자화 에러의 스케일 인자 를 반영하면서 양자화 콘볼루션의 전체 스 케일을 반영하기 위해, 양자화 에러 Δ에 대한 스케일이 기존의 가중치 스케일 인자 로 표현된다. 수학식 7에서 추가된 양자화 에러에 대한 부분을 기존의 부분합 콘볼루션을 변형하여 보정하기 위해, 부분합 콘 볼루션의 스케일 을 하드웨어 연산에 효율적인 비트 연산자 형태인 shift scale로 표현한다. 즉, 양자화 에 러와 신경망의 입력 데이터의 콘볼루션 연산 결과에 스케일 에 기초한 비트 시프트 연산이 수행된다. 이에 따라, 수학식 7의 추가된 양자화 에러에 대한 연산을 3가지 경우에 따라 표현된다. 먼저, 을 최대값으로 가정하면, 양자화 에러 Δ의 스케일이 가장 큰 경우는 w와 차이가 기존 가중치의 스케일과 동일한 범위를 가지는 경우, 즉 양자화 에러의 크기(Δ)가 기존 가중치 스케일()과 동일한 경우이 므로, 는 아래 수학식 8과 같이 표현된다.[수학식 8]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이에 따라, 비트 스케일 값은 아래 수학식 9에 따라 n 비트 시프트 스케일 값으로 결정된다. [수학식 9]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "2번째로, 과 의 관계가 2의 제곱수로 표현 가능하면, 수학식 10에 따라 비트 스케일 값은 n+k 비트 시프 트 스케일 값으로 결정된다. [수학식 10]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "마지막으로, 과 의 관계가 2의 제곱수로 표현 불가능하면, 과 에 로그 연산 및 라운딩 연산을 적 용하여 수학식 11과 같이, k를 구한다. [수학식 11]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "수학식 11을 통해 구한 k를 이용하여 를 시프트 스케일에 맞게 로 재정의하고, 새로 정의된 양자 화 에러 Δ의 범위의 넛지(nudge)된 최소값 및 최대값을 정의함으로써, 수학식 12에 따라 비트 스케일 값은 n+k 비트 시프트 스케일 값으로 결정된다. [수학식 12]"}
{"patent_id": "10-2022-0023210", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 13, "content": "도 5a 및 도 5b에서는 비트시프트 연산이 수행되지 않는 다른 실시예에서의 문제점이 후술되고, 도 5c는 일 실 시예에 따른 장점이 후술된다. 도 5a는 다른 실시예에 따른 양자화된 가중치와 양자화 에러를 이용하여 데이터를 출력하는 과정을 설명하기 위 한 도면이다. 도 5b는 다른 실시예에 따른 양자화된 가중치와 양자화 에러를 이용하여 데이터를 출력하는 과정 을 설명하기 위한 도면이다. 도 5c는 일 실시에에 따른 따른 양자화된 가중치, 양자화 에러, 및 비트 시프트 연 산을 이용하여 데이터를 출력하는 과정을 설명하기 위한 도면이다. 도 5a를 참고하면, 입력 데이터를 양자화 가중치와 누적 연산한 후, 리스케일링 값 으로 리스케 일링한 출력 값과, 입력 데이터를 양자화 에러와 누적 연산한 후 리스케일링 값 으로 리 스케일링한 출력 값을 더하여 출력 데이터가 획득된다. 도 5a의 구조는 부분합 콘볼루션이 아니라 기존의 콘볼루션을 2번 이용하는 것과 동일하고, 누적(accumulate) 연산 과정에서 합이 아니라 양자화된 값을 더함으로써 양자화 에러 Δ의 값의 소실이 커서 양자화 에러를 보완 할 수 없다. 도 5b를 참고하면, 입력 데이터를 양자화 가중치와 누적 연산하고, 입력 데이터를 양자화 에러 와 누적 연산 후, 리스케일링 값 으로 리스케일링한 출력 데이터가 획득된다. 도 5b의 구조는 양자화 에러 Δ의 스케일이 반영되지 않아 잘못된 누적 계산 값이 도출된다. 도 5c를 참고하면 입력 데이터를 양자화 가중치와 누적 연산하고, 입력 데이터와 양자화 에러의 누적 연산 및 비트 시프트 연산을 수행한 후, 리스케일링 값 으로 리스케일링한 출력 데이터가 획득된다. 도 5c의 구조는 양자화 에러 Δ의 스케일이 반영되어 기존 뉴럴 프로세싱 유닛(NPU)의 정밀도의 양자화 에러가 적절히 보완된 값이 도출된다. 도 6a는 다른 실시예에 따른 비트 시프트 연산을 수행하지 않는 하드웨어 구조를 설명하기 위한 도면이다. 도 6b는 일 실시예에 따른 비트 시프트 연산을 수행하는 하드웨어 구조를 설명하기 위한 도면이다. 도 6a를 참고하면, 하드웨어 구조 내에서 부분합(Partial Sum)을 수행하는 PSUM RF가 부분합을 연속 적으로 수행하여 더하고, 더한 값을 다시 누적(accumulation) 연산을 수행하는 ACC SRAM에서 더하여 처리한다. 모든 하드웨어 연산자는 한번에 모든 누적(accumulation) 결과 값을 처리하지 못하기 때문에 부분합 콘볼루션을 사용하여 중간 결과를 ACC SRAM에 저장하고, 이전에 누적된 값과 현재 계산 값을 누적하여 결과를 도출한다. 여기서, PSUM RF 및 ACC SRAM는 각각 부분합과 누적 연산을 수행하는 하드웨어(예 를 들어, 메모리)로서, 각자의 역할에 따라 명칭이 명명된 것일 뿐, 이에 한정되지 않는다. 도 6b를 참고하면, 중간 결과를 누적하는데 이용하는 부분합 콘볼루션을 약간의 변형, 즉, 아주 작은 하드웨어 로직 변경을 통해 양자화 에러를 반영하여 보정한다. 곱하기(multiply) 또는 나누기(divider) 연산자를 이용한 리스케일링의 경우에는 비용 또는 면적이 크기 때문에 하드웨어의 이득이 없는 반면에 비트 시프트 연산의 경우 비용 또는 면적이 적게 든다. 도 7은 일 실시예에 따른 양자화된 가중치, 양자화 에러, 비트 시프트 연산을 이용하는 데이터 처리 방법의 순 서도이다. S710 단계에서, 데이터 처리 장치는, 신경망의 가중치를 양자화하여 양자화된 가중치를 획득한다. 일 실시예에 따라, 양자화는 부동소수점 데이터를 n 비트의 양자화된 고정소수점 데이터로 변환하는 연산일 수 있다. S720 단계에서, 데이터 처리 장치는, 가중치와 양자화된 가중치의 차이인 양자화 에러를 획득한다. 일 실시예에 따라, 양자화 에러는 가중치와 양자화된 가중치의 차이에 양자화가 수행된 것일 수 있다. S730 단계에서, 데이터 처리 장치는, 신경망에 대한 입력 데이터를 획득한다. S740 단계에서, 데이터 처리 장치는, 양자화된 가중치와 입력 데이터의 콘볼루션 연산을 수행하여 제1 콘 볼루션 연산 결과를 획득한다. S750 단계에서, 데이터 처리 장치는, 양자화 에러와 입력 데이터의 콘볼루션 연산을 수행하여 제2 콘볼루 션 연산 결과를 획득하고, 비트 시프트 연산을 이용하여 제2 콘볼루션 연산 결과를 스케일링함으로써 스케일링 된 제2 콘볼루션 연산 결과를 획득한다. 일 실시예에 따라, 비트 시프트 연산에서 비트 시프트 값은 상기 가중치에 대한 제1 스케일 인자와 상기 양자화 에러에 대한 제2 스케일 인자에 기초하여 결정될 수 있다. 일 실시예에 따라, 양자화 에러의 크기가 제1 스케일 인자와 동일한 경우, 비트 시프트 값은 n 비트로 결정되고, n은 양자화 비트 값일 수 있다. 일 실시예에 따라, 제1 스케일 인자와 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되는 경우, 비트 시프 트 값은 n + k 비트로 결정되고, n은 양자화 비트 값이고, k는 2의 제곱수에서 제곱수의 값일 수 있다. 일 실시예에 따라, 제1 스케일 인자와 제2 스케일 인자 사이의 관계가 2의 제곱수로 표현되지 않는 경우, 비트 시프트 값은 로그 연산과 라운딩 연산을 통해 결정된 k에 기초하여 결정될 수 있다. 일 실시예에 따라, 제1 스케일 인자의 범위는 가중치의 최대값과 최소값에 기초하여 결정될 수 있다. 일 실시예에 따라, 제2 스케일 인자의 범위는 양자화 에러의 최대값과 최소값에 기초하여 결정될 수 있다. 일 실시예에 따라, 제1 스케일 인자는 제2 스케일 인자보다 클 수 있다. S760 단계에서, 데이터 처리 장치는, 제1 콘볼루션 연산 결과 및 스케일링된 제2 콘볼루션 연산 결과를 이 용하여 출력 데이터를 획득한다. 도 8은 일 실시예에 따른 양자화된 가중치, 양자화 에러, 비트 시프트 연산을 이용하는 데이터 처리 장치의 구 성을 도시하는 도면이다. 도 8을 참조하면, 데이터 처리 장치는 양자화 가중치 획득부, 양자화 에러 획득부, 입력 데이터 획득부, 제1 콘볼루션 연산 결과 획득부, 스케일링된 제2 콘볼루션 연산 결과 획득부, 및 출력 데이터 획득부를 포함한다. 양자화 가중치 획득부, 양자화 에러 획득부, 입력 데이터 획득부, 제1 콘볼루션 연산 결과 획득 부, 스케일링된 제2 콘볼루션 연산 결과 획득부, 및 출력 데이터 획득부는 뉴럴 프로세서로 구 현될 수 있고, 양자화 가중치 획득부, 양자화 에러 획득부, 입력 데이터 획득부, 제1 콘볼루션 연산 결과 획득부, 스케일링된 제2 콘볼루션 연산 결과 획득부, 및 출력 데이터 획득부는 메모 리(미도시)에 저장된 인스트럭션에 따라 동작할 수 있다. 도 8은 양자화 가중치 획득부, 양자화 에러 획득부, 입력 데이터 획득부, 제1 콘볼루션 연산 결 과 획득부, 스케일링된 제2 콘볼루션 연산 결과 획득부, 및 출력 데이터 획득부를 개별적으로 도시하고 있으나, 양자화 가중치 획득부, 양자화 에러 획득부, 입력 데이터 획득부, 제1 콘볼루 션 연산 결과 획득부, 스케일링된 제2 콘볼루션 연산 결과 획득부, 및 출력 데이터 획득부는 하 나의 프로세서를 통해 구현될 수 있다. 이 경우, 양자화 가중치 획득부, 양자화 에러 획득부, 입력 데이터 획득부, 제1 콘볼루션 연산 결과 획득부, 스케일링된 제2 콘볼루션 연산 결과 획득부, 및 출력 데이터 획득부는 전용 프로세서로 구현되거나, AP(application processor), CPU(central processing unit), GPU(graphic processing unit), 또는 NPU(neural processing unit)와 같은 범용 프로세서와 소프트웨어의 조합을 통해 구현될 수도 있다. 또한, 전용 프로세서의 경우, 본 개시의 실시예를 구현하기 위한 메모리를 포함하거나, 외부 메모리를 이용하기 위한 메모리 처리부를 포함할 수 있다. 양자화 가중치 획득부, 양자화 에러 획득부, 입력 데이터 획득부, 제1 콘볼루션 연산 결과 획득 부, 스케일링된 제2 콘볼루션 연산 결과 획득부, 및 출력 데이터 획득부는 복수의 프로세서로 구성될 수도 있다. 이 경우, 전용 프로세서들의 조합으로 구현되거나, AP, CPU, GPU, 또는 NPU와 같은 다수의 범용 프로세서들과 소프트웨어의 조합을 통해 구현될 수도 있다. 양자화 가중치 획득부는 신경망의 가중치를 양자화하여 양자화된 가중치를 획득한다. 양자화 에러 획득부는 가중치와 양자화된 가중치의 차이인 양자화 에러를 획득한다. 입력 데이터 획득부는 신경망에 대한 입력 데이터를 획득한다. 제1 콘볼루션 연산 결과 획득부는 양자화된 가중치와 입력 데이터의 콘볼루션 연산을 수행하여 제1 콘볼루 션 연산 결과를 획득한다. 스케일링된 제2 콘볼루션 연산 결과 획득부는 양자화 에러와 입력 데이터의 콘볼루션 연산을 수행하여 제2 콘볼루션 연산 결과를 획득하고, 비트 시프트 연산을 이용하여 제2 콘볼루션 연산 결과를 스케일링함으로써 스 케일링된 제2 콘볼루션 연산 결과를 획득한다. 출력 데이터 획득부는 제1 콘볼루션 연산 결과 및 스케일링된 제2 콘볼루션 연산 결과를 이용하여 출력 데 이터를 획득한다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2022-0023210", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 신경망의 가중치를 양자화하여 데이터를 출력하는 과정을 설명하기 위한 도면이다. 도 2는 부동 소수점 데이터를 고정 소수점 데이터로 양자화하는 과정을 설명하기 위한 도면이다. 도 3은 종래의 양자화된 가중치를 이용하여 데이터를 출력하는 과정을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 양자화된 가중치, 양자화 에러, 비트 시프트 연산을 이용하여 데이터를 출력하는 과정을 설명하기 위한 도면이다. 도 5a는 다른 실시예에 따른 양자화된 가중치와 양자화 에러를 이용하여 데이터를 출력하는 과정을 설명하기 위 한 도면이다. 도 5b는 다른 실시예에 따른 양자화된 가중치와 양자화 에러를 이용하여 데이터를 출력하는 과정 을 설명하기 위한 도면이다. 도 5c는 일 실시에에 따른 따른 양자화된 가중치, 양자화 에러, 및 비트 시프트 연 산을 이용하여 데이터를 출력하는 과정을 설명하기 위한 도면이다. 도 6a는 다른 실시예에 따른 비트 시프트 연산을 수행하지 않는 하드웨어 구조를 설명하기 위한 도면이다. 도 6b는 일 실시예에 따른 비트 시프트 연산을 수행하는 하드웨어 구조를 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 양자화된 가중치, 양자화 에러, 비트 시프트 연산을 이용하는 데이터 처리 방법의 순 서도이다. 도 8은 일 실시예에 따른 양자화된 가중치, 양자화 에러, 비트 시프트 연산을 이용하는 데이터 처리 장치의 구 성을 도시하는 도면이다."}
