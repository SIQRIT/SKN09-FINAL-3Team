{"patent_id": "10-2022-0020109", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0123226", "출원번호": "10-2022-0020109", "발명의 명칭": "AI 기반 객체인식을 통한 감시 카메라 영상의 노이즈 제거", "출원인": "한화비전 주식회사", "발명자": "정영제"}}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서로 다른 조사각을 가지도록 배치된 복수의 IR LED를 구비하는 카메라부; 및상기 카메라부를 통해 획득된 영상을 복수의 블록으로 분할하고, 상기 복수의 블록 중 객체가 포함된 적어도 하나의 블록으로 구성되는 객체블록의 밝기를 산출하고, 상기 객체블록의 밝기에 기초하여 상기 복수의 IR LED 중상기 객체블록을 조사영역으로 포함하는 적어도 하나의 IR LED의 밝기를 제어하는 프로세서;를 포함하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 복수의 IR LED는,상기 감기 카메라에 의한 촬영 영역이 상기 복수의 IR LED 각각의 조사영역에 따라 복수의 구역으로 구분되도록배치되는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 프로세서는, 상기 영상을 M x N 개의 블록으로 분할하고, 분할된 각 블록은 m x n 개의 픽셀수로 구성되는것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 프로세서는,상기 분할된 블록에 대하여 픽셀밝기에 기초하여 블록별 평균밝기를 산출하고, 상기 블록별 평균밝기에 기초하여 상기 객체블록의 평균밝기를 산출하고, 상기 객체블록의 평균밝기가 미리 정해진 기준 밝기에 도달되도록 상기 타겟 IR LED의 밝기를 제어하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 프로세서는,상기 타겟 IR LED의 한계 밝기가 상기 기준 밝기 미만인 경우, 상기 카메라부에 포함된 이미지 센서의 이득(Gain)을 증폭하여 상기 객체블록의 밝기를 보완하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 프로세서는,상기 객체블록의 밝기에 따라 상기 이미지 센서의 이득 증폭량을 결정하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 프로세서는,공개특허 10-2023-0123226-3-상기 영상에서 상기 객체블록의 위치를 인식한 경우, 상기 객체블록의 위치에 대응되는 상기 타겟 IR LED를 결정하고, 상기 타겟 IR LED의 밝기를 자동으로 제어하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 프로세서는,상기 복수의 IR LED 중 상기 타겟 IR LED를 제외한 IR LED를 오프시키는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 프로세서는,상기 영상에서 상기 객체블록의 위치에 따라 상기 복수의 IR LED 중 밝기 제어 대상 IR LED를 동적으로 가변하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 프로세서는,딥러닝 기반의 객체인식 알고리즘을 이용하여 상기 객체를 인식하고, 상기 인식된 객체별로 ID를 부여하고, 상기 ID가 부여된 객체의 좌표를 추출하여 상기 객체의 좌표를 상기 객체가 포함된 블록의 좌표와 매칭하는 것을특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "복수의 IR LED를 구비하는 카메라부; 및상기 카메라부를 통해 획득된 영상에서 딥러닝 객체인식 알고리즘을 통해 객체를 인식하고, 상기 복수의 IR LED중 상기 객체의 좌표정보에 대응하는 적어도 하나의 타겟 IR LED를 선택하고, 상기 객체의 밝기정보에 기초하여상기 선택된 타겟 IR LED의 밝기를 제어하는 프로세서;를 포함하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 복수의 IR LED는 상기 카메라부의 렌즈 주위를 따라 배치되며,상기 감시 카메라의 감시 영역은, 상기 복수의 IR LED의 조사각에 따라 상기 영상에서 복수의 구역으로 구획되며.상기 프로세서는, 상기 복수의 구역에 각각 매칭되도록 상기 복수의 IR LED를 적어도 하나의 IR LED을 포함하는 그룹화하여 관리하고, 상기 객체의 위치에 대응되는 그룹을 선택하여 선택된 그룹에 포함된 IR LED의 밝기를 제어하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 복수의 구역은,상기 영상의 모서리에 대응되는 제1 내지 제4 영역과 상기 영상의 중앙부에 대응되는 제5 영역으로 구분되는 것을 특징으로 하는 감시 카메라.공개특허 10-2023-0123226-4-청구항 14 제 11 항에 있어서,상기 프로세서는 상기 영상을 복수의 블록으로 분할하고, 상기 복수의 블록 중 상기 객체가 포함된 적어도 하나의 블록으로 구성되는 객체블록의 밝기를 산출하고, 상기 객체블록의 밝기에 기초하여 상기 타겟 IR LED의 밝기를 제어하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 프로세서는,상기 분할된 블록에 대하여 픽셀밝기에 기초하여 블록별 평균밝기를 산출하고, 상기 블록별 평균밝기에 기초하여 상기 객체블록의 평균밝기를 산출하고, 상기 객체블록의 평균밝기가 미리 정해진 기준 밝기에 도달되도록 상기 타겟 IR LED의 밝기를 제어하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 프로세서는,상기 타겟 IR LED의 한계 밝기가 상기 기준 밝기 미만인 경우, 상기 카메라부에 포함된 이미지 센서의 이득(Gain)을 증폭하여 상기 객체블록의 밝기를 보완하는 것을 특징으로 하는 감시 카메라."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "서로 다른 조사각을 가지도록 배치된 복수의 IR LED를 구비하는 카메라부를 통해 획득된 영상을 복수의 블록으로 분할하는 단계;딥러닝 객체인식 알고리즘을 통해 객체를 인식하는 단계;상기 복수의 블록 중 상기 객체가 포함된 적어도 하나의 블록으로 구성되는 객체블록의 밝기를 산출하는 단계;및상기 객체블록의 밝기에 기초하여 상기 복수의 LED 중 상기 객체블록을 조사영역으로 포함하는 적어도 하나의IR LED의 밝기를 제어하는 단계;를 포함하는 감시 카메라의 제어 방법."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 복수의 IR LED는, 상기 감기 카메라에 의한 촬영 영역이 상기 복수의 IR LED 각각의 조사영역에 따라 복수의 구역으로 구분되도록 배치되고,상기 객체의 위치 및 상기 객체블록의 위치를 확인하는 단계;상기 복수의 IR LED 중 상기 객체블록의 위치에 대응되는 적어도 하나의 타겟 IR LED를 결정하는 단계; 및상기 타겟 IR LED의 밝기를 미리 정해진 기준 밝기에 도달하도록 제어하는 단계;를 더 포함하는 것을 특징으로 하는 감시 카메라의 제어 방법."}
{"patent_id": "10-2022-0020109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 타겟 IR LED의 한계 밝기가 상기 기준 밝기 미만인 경우, 상기 카메라부에 포함된 이미지 센서의 이득(Gain)을 증폭하여 상기 객체블록의 밝기를 보완하는 단계;공개특허 10-2023-0123226-5-를 더 포함하는 것을 특징으로 하는 감시 카메라의 제어 방법."}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "감시 카메라 및 감시 카메라 제어 방법이 개시된다. 본 명세서는 영상에서 객체의 위치를 비추는 IR LED 에 대해 서 선택적으로 IR LED의 밝기를 제어한다. 본 명세서는 IR LED의 한계 밝기를 보완하기 위해 객체가 검출된 영역 의 AE를 반영하여 IR LED 밝기의 제어범위를 이미지 센서의 이득 증폭으로 보완한다. 이에 따라, 소비전력 효율 을 높이고 발열 현상을 최소화할 수 있다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계될 수 있다."}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 감시 카메라 영상 처리 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "저조도 환경 외부 광원이 거의 없는 극저조도 환경의 감시 카메라 시스템은 어두운 환경에서 피사체를 인식하고 촬영할 수 있도록 감시 카메라의 외부 또는 내부에 적외선 투광기를 구비할 수 있다. 그러나, 감시 거리가 길어질수록 많은 양의 적외선 LED를 사용해야 하며, 적외선 LED의 경우 연속적으로 점등시 키는 경우 LED의 특성상 열이 매우 많이 발생되고, 파열로 인해 수명이 단축되는 문제가 있다. 감시 카메라가 감시하는 사이트의 경우 항상 주 감시대상인 사람과 객체가 존재하지 않지만 상시적으로 필요한 밝기를 유지해야 한다. 하지만 높은 출력의 적외선 LED 광의 사용은 필연적으로 높은 소비 전력이 필요하게 된 다. 이는 카메라 내부의 발명문제, 화면상의 발열 노이즈 발생 등의 문제가 발생한다. 한편, 적외선 LED 광을 오프시키거나, 밝기를 줄이면 감시 대상의 식별이 불가능하며, 화면 밝기가 어두워진 만 큼 자동 노출(Auto Exposure) 증폭양이 많아져 화면상의 센서 증폭 노이즈를 야기시키는 문제가 있다. 따라서, 극 저조도 환경에서 카메라의 소비전력도 줄이고 객체 인식을 위한 밝기도 유지하기 위한 방안이 필요 하다."}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "최근, 인공지능 객체인식 기술로 인해 객체의 모션 데이터의 인식에 대한 오알람(False Alarm) 문제가 상당히 개선되었다. 이에 따라, 본 명세서는, 전술한 문제를 해결하기 위해 AI 객체인식 결과에 기초하여 객체의 유무에 따라 적외 선 LED 및/또는 자동노출(AE)을 가변적으로 제어함으로써, 저전력의 소비전력을 유지하면서 효율적으로 AE 증폭 이득값을 줄일 수 있는 감시 카메라 및 감시 카메라의 제어 방법을 제공하는 것을 목적으로 한다. 또한, 본 명세서는 객체의 위치에 따라 감시 카메라에 구비된 적외선 LED(이하, IR LED라 함)의 적어도 일부에 대한 밝기를 제어함으로써, 객체 인식률을 높이고 소비전력을 낮출 수 있는 감시 카메라 및 감시 카메라의 제어 방법을 제공하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은"}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 이하의 발명의 상세한 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 감시 카메라는 서로 다른 조사각을 가지도록 배치된 복수의 IR LED를 구비하는 카메라부; 및 상기 카메라부를 통해 획득된 영상을 복수의 블록으로 분할하고, 상기 복수의 블록 중 객체가 포 함된 적어도 하나의 블록으로 구성되는 객체블록의 밝기를 산출하고, 상기 객체블록의 밝기에 기초하여 상기 복 수의 IR LED 중 상기 객체블록을 조사영역으로 포함하는 적어도 하나의 IR LED의 밝기를 제어하는 프로세서;를 포함한다. 상기 복수의 IR LED는, 상기 감기 카메라에 의한 촬영 영역이 상기 복수의 IR LED 각각의 조사영역에 따라 복수 의 구역으로 구분되도록 배치될 수 있다. 상기 프로세서는, 상기 영상을 M x N 개의 블록으로 분할하고, 분할된 각 블록은 m x n 개의 픽셀수로 구성될 수 있다. 상기 프로세서는, 상기 분할된 블록에 대하여 픽셀밝기에 기초하여 블록별 평균밝기를 산출하고, 상기 블록별 평균밝기에 기초하여 상기 객체블록의 평균밝기를 산출하고, 상기 객체블록의 평균밝기가 미리 정해진 기준 밝 기에 도달되도록 상기 타겟 IR LED의 밝기를 제어할 수 있다. 상기 프로세서는, 상기 타겟 IR LED의 한계 밝기가 상기 기준 밝기 미만인 경우, 상기 카메라부에 포함된 이미 지 센서의 이득(Gain)을 증폭하여 상기 객체블록의 밝기를 보완할 수 있다. 상기 프로세서는, 상기 객체블록의 밝기에 따라 상기 이미지 센서의 이득 증폭양을 결정할 수 있다. 상기 프로세서는, 상기 영상에서 상기 객체블록의 위치를 인식한 경우, 상기 객체블록의 위치에 대응되는 상기 타겟 IR LED를 결정하고, 상기 타겟 IR LED의 밝기를 자동으로 제어할 수 있다. 상기 프로세서는, 상기 복수의 IR LED 중 상기 타겟 IR LED를 제외한 IR LED를 오프시킬 수 있다. 상기 프로세서는, 상기 영상에서 상기 객체블록의 위치에 따라 상기 복수의 IR LED 중 상기 타겟 IR LED의 대상 을 동적으로 가변할 수 있다. 상기 프로세서는, 딥러닝 기반의 객체인식 알고리즘을 이용하여 상기 객체를 인식하고, 상기 인식된 객체별로 ID를 부여하고, 상기 ID가 부여된 객체의 좌표를 추출하여 상기 객체의 좌표를 상기 객체가 포함된 블록의 좌표 와 매칭할 수 있다. 본 명세서의 다른 실시예에 다른 감시 카메라는, 복수의 IR LED를 구비하는 카메라부; 및 상기 카메라부를 통해 획득된 영상에서 딥러닝 객체인식 알고리즘을 통해 객체를 인식하고, 상기 복수의 IR LED 중 상기 객체의 좌표 정보에 대응하는 적어도 하나의 타겟 IR LED를 선택하고, 상기 객체의 밝기정보에 기초하여 상기 선택된 타겟 IR LED의 밝기를 제어하는 프로세서;를 포함한다. 상기 복수의 IR LED는 상기 카메라부의 렌즈 주위를 따라 배치되며, 상기 감시 카메라의 감시 영역은, 상기 복 수의 IR LED의 조사각에 따라 상기 영상에서 복수의 구역으로 구획되며, 상기 프로세서는, 상기 복수의 구역에 각각 매칭되도록 상기 복수의 IR LED를 적어도 하나의 IR LED을 포함하는 그룹화하여 관리하고, 상기 객체의 위 치에 대응되는 그룹을 선택하여 선택된 그룹에 포함된 IR LED의 밝기를 제어할 수 있다. 상기 복수의 구역은, 상기 영상의 모서리에 대응되는 제1 내지 제4 영역과 상기 영상의 중앙부에 대응되는 제5 영역으로 구분될 수 있다. 상기 프로세서는 상기 영상을 복수의 블록으로 분할하고, 상기 복수의 블록 중 상기 객체가 포함된 적어도 하나 의 블록으로 구성되는 객체블록의 밝기를 산출하고, 상기 객체블록의 밝기에 기초하여 상기 타겟 IR LED의 밝기 를 제어할 수 있다. 상기 프로세서는, 상기 분할된 블록에 대하여 픽셀밝기에 기초하여 블록별 평균밝기를 산출하고, 상기 블록별 평균밝기에 기초하여 상기 객체블록의 평균밝기를 산출하고, 상기 객체블록의 평균밝기가 미리 정해진 기준 밝 기에 도달되도록 상기 타겟 IR LED의 밝기를 제어할 수 있다. 상기 프로세서는, 상기 타겟 IR LED의 한계 밝기가 상기 기준 밝기 미만인 경우, 상기 카메라부에 포함된 이미 지 센서의 이득(Gain)을 증폭하여 상기 객체블록의 밝기를 보완할 수 있다. 본 명세서의 또 다른 실시예에 따른 감시 카메라의 제어 방법은, 서로 다른 조사각을 가지도록 배치된 복수의 IR LED를 구비하는 카메라부를 통해 획득된 영상을 복수의 블록으로 분할하는 단계; 딥러닝 객체인식 알고리즘 을 통해 객체를 인식하는 단계; 상기 복수의 블록 중 상기 객체가 포함된 적어도 하나의 블록으로 구성되는 객 체블록의 밝기를 산출하는 단계; 및 상기 객체블록의 밝기에 기초하여 상기 복수의 LED 중 상기 객체블록을 조 사영역으로 포함하는 적어도 하나의 IR LED의 밝기를 제어하는 단계;를 포함한다. 상기 복수의 IR LED는, 상기 감기 카메라에 의한 촬영 영역이 상기 복수의 IR LED 각각의 조사영역에 따라 복수 의 구역으로 구분되도록 배치되고, 상기 객체의 위치 및 상기 객체블록의 위치를 확인하는 단계; 상기 복수의 IR LED 중 상기 객체블록의 위치에 대응되는 적어도 하나의 타겟 IR LED를 결정하는 단계; 및 상기 타겟 IR LED 의 밝기를 미리 정해진 기준 밝기에 도달하도록 제어하는 단계;를 더 포함할 수 있다. 상기 감시 카메라의 제어 방법은, 상기 타겟 IR LED의 한계 밝기가 상기 기준 밝기 미만인 경우, 상기 카메라부 에 포함된 이미지 센서의 이득(Gain)을 증폭하여 상기 객체블록의 밝기를 보완하는 단계;를 더 포함할 수 있다."}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 실시예에 따르면, AI 객체인식 결과에 기초하여 객체의 유무에 따라 적외선 LED 및/또는 자동노 출(AE)을 가변적으로 제어함으로써, 저전력의 소비전력을 유지하면서 효율적으로 AE 증폭 이득값을 줄일 수 있 다. 또한, 본 명세서의 일 실시예에 따르면, 객체의 위치에 따라 감시 카메라에 구비된 적외선 LED(이하, IR LED라 함)의 적어도 일부에 대한 밝기를 제어함으로써, 객체 인식률을 높이고 소비전력을 낮출 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다.어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 본 명세서의 일 실시예에 따른 감시 카메라 시스템은 촬영 장치 및 영상 관리 서버 을 포함할 수 있다. 촬영 장치는 특정 장소의 고정된 위치에 배치되는 촬영용 전자 장치일 수도 있고, 일정한 경로를 따라 자동 또는 수동으로 움직일 수 있는 촬영용 전자 장치일 수도 있고, 사람 또는 로봇 등에 의하여 이동될 수 있는 촬영용 전자 장치일 수도 있다. 촬영 장치는 유무선 인터넷에 연결하여 사용 하는 IP 카메라일 수 있다. 촬영 장치는 팬(pan), 틸트(tilt), 및 줌(zoom) 기능을 갖는 PTZ 카메라일 수 있다. 촬영 장치는 감시 하는 영역을 녹화하거나 사진을 촬영하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 발생하는 소리를 녹음하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 움직 임 또는 소리 등 변화가 발생 할 경우, 이에 대한 알림을 발생시키거나 녹화 또는 사진 촬영을 수행하는 기능을 가질 수 있다. 영상 관리 서버는 촬영 장치를 통하여 촬영된 영상 자체 및/또는 해당 영상을 편집하여 얻어지는 영 상을 수신하여 저장하는 장치일 수 있다. 영상 관리 서버는 수신한 용도에 대응되도록 분석할 수 있다. 예 를 들어, 영상 관리 서버는 영상에서 객체를 검출하기 위해 객체 검출 알고리즘을 이용하여 객체를 검출할 수 있다. 상기 객체 검출 알고리즘은 AI 기반 알고리즘이 적용될 수 있으며, 미리 학습된 인공신경망 모델을 적 용하여 객체를 검출할 수 있다. 상기 객체 검출 알고리즘을 통해 객체를 검출하는 동작은 전술한 영상 촬영 장 치를 통해서도 구현이 가능함은 물론이다. 한편, 영상 관리 서버는 영상 분석 목적에 맞는 다양한 학습 모델을 저장하고 있을 수 있다. 전술한 객체 검출을 위한 학습 모델 외에, 검출된 객체의 이동 속도를 획득할 수 있는 모델을 저장하고 있을 수도 있다. 여 기서 상기 학습된 모델들은 감시 카메라릍 통해 획득된 영상의 크기, 미리 정의된 크기로 분할된 블록 크기를 입력데이터로 하고, 상기 영상 내에서 검출된 객체의 좌표, 상기 객체를 포함하는 블록의 좌표 정보가 출력되도 록 학습된 모델일 수 있다. 또한, 영상 관리 서버는 수신한 영상을 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 서버는 수신한 영상에 포함된 영상 정보 및 /또는 음향 정보를 함께 또는 별도 로 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 시스템은 촬영 장치 및/또는 영상 관리 서버와 유무선 통신을 수행할 수 있는 외부 장 치를 더 포함할 수 있다. 외부 장치는 영상 관리 서버로 영상 전체 또는 일부의 제공을 요청하는 정보 제공 요청 신호를 송신 할 수 있다. 외부 장치는 영상 관리 서버로 영상 분석 결과 객체의 존재 여부, 객체의 이동 속도, 객 체의 이동 속도에 따른 셔터 속도 조절값, 객체의 이동 속도에 따른 노이즈 제거값 등을 요청하는 정보 제공 요 청 신호를 송신할 수 있다. 또한 외부 장치는 영상 관리 서버로 영상을 분석하여 얻어진 메타 데이터 및/또는 메타 데이터에 대한 인덱스 정보를 요청하는 정보 제공 요청 신호를 송신할 수 있다. 영상 관리 시스템은 촬영 장치, 영상 관리 서버, 및/또는 외부 장치 간의 유무선 통신 경로 인 통신망을 더 포함할 수 있다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트 워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 명세서의 범위가 이 에 한정되는 것은 아니다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 2는 도 1에 도시된 영상 촬영 장치(100, 이하, 카메라)의 구성을 나타내는 블록도이다. 도 2를 참조하면, 카메라는 지능형 영상분석 기능을 수행하여 상기 영상분석 신호를 생성하는 네트워크 카메라임을 그 예로 설명하나, 본 발명의 실시예에 의한 네트워크 감시 카메라 시스템의 동작이 반드시 이에 한정되는 것은 아니 다. 카메라는 이미지 센서, 인코더, 메모리, 통신부, AI 프로세서, 프로세서 를 포함할 수 있다. 이미지 센서는 감시 영역을 촬영하여 영상을 획득하는 기능을 수행하는 것으로서, 예컨대, CCD(Charge- Coupled Device) 센서, CMOS(Complementary Metal-Oxide-Semiconductor) 센서 등으로 구현될 수 있다. 인코더는 이미지 센서를 통해 획득한 영상을 디지털 신호로 부호화하는 동작을 수행하며, 이는 예컨 대, H.264, H.265, MPEG(Moving Picture Experts Group), M-JPEG(Motion Joint Photographic Experts Group) 표준 등을 따를 수 있다. 메모리는 영상 데이터, 음성 데이터, 스틸 이미지, 메타데이터 등을 저장할 수 있다. 앞서 언급한 바와 같 이, 상기 메타데이터는 상기 감시영역에 촬영된 객체 검출 정보(움직임, 소리, 지정지역 침입 등), 객체 식별 정보(사람, 차, 얼굴, 모자, 의상 등), 및 검출된 위치 정보(좌표, 크기 등)을 포함하는 데이터일 수 있다. 또한, 상기 스틸 이미지는 상기 메타데이터와 함께 생성되어 메모리에 저장되는 것으로서, 상기 영상분석 정보들 중 특정 분석 영역에 대한 이미지 정보를 캡쳐하여 생성될 수 있다. 일 예로, 상기 스틸 이미지는 JPEG 이미지 파일로 구현될 수 있다. 일 예로, 상기 스틸 이미지는 특정 영역 및 특정 기간 동안 검출된 상기 감시영역의 영상 데이터들 중 식별 가 능한 객체로 판단된 영상 데이터의 특정영역을 크롭핑(cropping)하여 생성될 수 있으며, 이는 상기 메타데이터 와 함께 실시간으로 전송될 수 있다. 통신부는 상기 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 외부 장치에 전송한다. 일 실시예에 따른 통신부는 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 외 부 장치에 실시간으로 전송할 수 있다. 통신 인터페이스(미도시)는 유무선 LAN(Local Area Network), 와이 파이(Wi-Fi), 지그비(ZigBee), 블루투스(Bluetooth), 근거리 통신(Near Field Communication) 중 적어도 하나 의 통신 기능을 수행할 수 있다. AI 프로세서는 인공지능 영상 처리를 위한 것으로서, 본 명세서의 일 실시예에 따라 감시 카메라 시스템을 통해 획득된 영상에서 관심객체로 학습된 딥러닝 기반의 객체 탐지(Objection Detection) 알고리즘을 적용한다. 상기 AI 프로세서는 시스템 전반에 걸쳐 제어하는 프로세서와 하나의 모듈로 구현되거나 독립된 모듈 로 구현될 수 있다. 본 명세서의 일 실시예들은 객체 탐지에 있어서 YOLO(You Only Lock Once) 알고리즘을 적용 할 수 있다. YOLO은 객체 검출 속도가 빠르기 때문에 실시간 동영상을 처리하는 감시 카메라에 적당한 AI 알고 리즘이다. YOLO 알고리즘은 다른 객체 기반 알고리즘들(Faster R-CNN, R_FCN, FPN-FRCN 등)과 달리 한 장의 입 력 영상을 리사이즈(Resize)후 단일 신경망을 단 한 번 통과킨 결과로 각 객체의 위치를 인디케이팅하는 바운딩 박스(Bounding Box)와 객체가 무엇인지 분류 확률을 출력한다. 최종적으로 Non-max suppression을 통해 하나의 객체를 한번 인식(detection)한다. 한편, 본 명세서에 개시되는 객체 인식 알고리즘은 전술한 YOLO에 한정되지 않고 다양한 딥러닝 알고리즘으로 구현될 수 있음을 밝혀둔다. 한편, 본 명세서에 적용되는 객체 인식을 위한 학습 모델은 영상에서 객체의 좌표정보 등을 학습데이터로 정의 하여 훈련된 모델일 수 있다. 이에 따라 학습된 모델은 입력 데이터가 영상 데이터이며, 출력 데이터가 영상 데 이터 내에 포함된 객체의 좌표 정보 및/또는 상기 영상이 소정의 블록 크기로 분할된 상태에서 객체가 포함된 블록의 위치정보를 출력데이터로 할 수 있다. 본 명세서는 영상 내에서 상기 객체의 위치가 감지되면, 상기 객체의 위치에 대응되는 IR LED만을 선택하여 선 별적으로 IR LED의 밝기를 제어함으로써, 소비전력 및 객체인식율을 높일 수 있다. 도 3은 본 명세서의 일 실시예에 따른 감시 카메라 영상의 분석에 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 3을 살펴보면, AI 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 AI 모듈을 포함하는 서버 등을 포함할 수 있다. 또한, AI 장치는 감시 카메라 또는 영상 관리 서버의 적어도 일부의 구성으로 포함되어 AI 프로세싱 중 적어도 일부를 함께 수행하도록 구비될 수도 있다. AI 프로세싱은 감시카메라 또는 영상 관리 서버의 제어부와 관련된 모든 동작들을 포함할 수 있다. 예를 들어, 감시 카메라 또는 영상 관리 서버는 획득된 영상 신호를 AI 프로세싱 하여 처리/판단, 제어 신호 생성 동작을 수행할 수 있다. AI 장치는 AI 프로세싱 결과를 직접 이용하는 클라이언트 디바이스이거나, AI 프로세싱 결과를 다른 기기에 제공하는 클라우드 환경의 디바이스일 수도 있다. AI 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서 버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함할 수 있다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, AI 프로세서(2 1)는 감시 카메라의 관련 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여기서, 감시 카메라의 관련 데이 터를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데 이터를 주고 받을 수 있다. 여기서 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥러닝 모 델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데 이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신 (RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함하며, 컴퓨터비젼, 음성인식, 자연어처리, 음성/신호처리 등의 분야에 적용될 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지능 학 습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발 성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드 라이브(SDD) 등으로 구현할 수 있다. 메모리는 AI 프로세서에 의해 액세스되며, AI 프로세서에 의 한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 본 발명의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예를 들어, 딥 러닝 모델)을 저장할 수 있다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 데 이터 학습부는 데이터 분류/인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하여 데이터를 어떻게 분류하고 인식할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습데이터를 딥러닝 모델에 적용함으로써, 딥러닝 모델을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부는 인공지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 범용 프로세서(CPU) 또 는 그래픽 전용 프로세서(GPU)의 일부로 제작되어 AI 장치에 탑재될 수도 있다. 또한, 데이터 학습부 는 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(또는 인스트럭션(instruction)을 포함하는 프로그램 모 듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록 매체 (non-transitory computer readable media)에 저장될 수 있다. 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 애플리케이션에 의해 제공될 수 있다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있다. 학습 데이터 획득부는 데이터를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있 다. 모델 학습부는 획득된 학습 데이터를 이용하여, 신경망 모델이 소정의 데이터를 어떻게 분류할지에 관한 판 단 기준을 가지도록 학습할 수 있다. 이 때 모델 학습부는 학습 데이터 중 적어도 일부를 판단 기준으로 이 용하는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또는 모델 학습부는지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 학습에 따른 상황 판단의 결과가 올바른지에 대한 피드백을 이용하여 강화 학습(reinforcement learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient decent)을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 학습부는 학습된 신경망 모델을 메모리에 저장할 수 있다. 모델 학습부 는 학습된 신경망 모델을 AI 장치와 유선 또는 무선 네트워크로 연결된 서버의 메모리에 저장할 수도 있다. 데이터 학습부는 인식 모델의 분석 결과를 향상시키거나, 인식 모델의 생성에 필요한 리소스 또는 시간을 절약하기 위해 학습 데이터 전처리부(미도시) 및 학습 데이터 선택부(미도시)를 더 포함할 수도 있다. 학습 데이터 전처리부는 획득된 데이터가 상황 판단을 위한 학습에 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 예를 들어, 학습 데이터 전처리부는, 모델 학습부가 이미지 인식을 위한 학습을 위하여 획득된 학습 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 또한, 학습 데이터 선택부는, 학습 데이터 획득부에서 획득된 학습 데이터 또는 전처리부에서 전처리된 학 습 데이터 중 학습에 필요한 데이터를 선택할 수 있다.선택된 학습 데이터는 모델 학습부에 제공될 수 있다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여 모델 평가부(미도시)를 더 포함할 수 도 있다. 모델 평가부는, 신경망 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 인식 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 일 예로, 모델 평가부는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중, 분석 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정되 임계치를 초과 하는 경우, 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 통신부는 AI 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 예를 들어, 외부 전자 기기는 감시카메라, 블루투스 장치, 자율주행 차량, 로봇, 드론, AR 기기, 모바일 기기, 가전 기기 등을 포함할 수 있다. 한편, 도 3에 도시된 AI 장치는 AI 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설 명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈로 호칭될 수도 있음을 밝혀둔다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G 서비스와 관련된 장치 등과 연계될 수 있다. 도 4는 본 명세서의 일 실시예에 따른 감시 카메라의 제어 방법의 흐름도이다. 도 4에 도시된 감시 카메라 제어 방법은 도 1 내지 도 3을 통해 설명한 감시 카메라 시스템, 감시 카메라 장치, 감시 카메라 장치에 포함된 프로 세서 또는 제어부를 통해 구현될 수 있다. 설명의 편의를 위해 상기 감시 카메라 제어방법은 도 2에 도시된 감 시 카메라의 프로세서를 통해 다양한 기능들이 제어될 수 있음을 전제로 설명하나, 본 명세서는 이에 한정되는 것이 아님을 밝혀둔다. 도 4를 참조하면, 프로세서는 영상을 복수의 블록으로 분할한다. 상기 영상은 감시 카메라 영상일 수 있다 (S400). 프로세서는 소정 크기로 제공되는 상기 영상에 대하여 영상 내에서 객체의 위치를 검출하기 위하 여 영상을 복수의 블록으로 분할할 수 있다. 프로세서는 딥러닝 알고리즘을 통해 영상에서 객체를 인식한다(S410). 일 실시예에 따라 상기 딥러닝 알고 리즘은 YOLO(You Only Lock Once) 알고리즘을 적용될 수 있다. 본 명세서의 실시예는 극저조도 환경 예를들어, 외부 광원이 존재하지 않거나 외부 광원이 존재하더라도 미미하여 객체 인식율이 매우 낮은 환경에서 적용되는 감시 카메라의 제어 방법으로서, 인공신경망을 학습하는 과정에서 저조도 환경에서 촬영된 영상 데이터가 입력 데이터로 활용될 수 있다. 프로세서는 객체가 포함된 객체블록의 밝기를 산출한다(S420). 프로세서는 복수의 블록으로 분할된 영상에서 인식된 객체가 포함된 블록(이하, 객체블록이라 함)을 확인할 수 있다. 상기 객체블록은 복수의 단위블록으로 구성될 수 있다. 상기 단위 블록은 영상이 단위 크기로 분할되는 과정에서 생성되는 것으로서, 상기 단위 블록은 복수의 픽셀로 구성될 수 있다. 여기서 객체블록의 밝기는 상기 객체가 포함된 모든 단위블록의 평 균 밝기를 의미할 수 있다. 프로세서는 블록별 평균밝기를 산출한 후 블록별 평균밝기에 기초하여 객체블 록의 평균밝기를 산출할 수 있다. 객체블록의 밝기에 대해서는 도 7 및 도 8을 통해 보다 구체적으로 설명한다. 프로세서는 객체블록의 밝기(이하, 블록의 밝기는 블록의 평균밝기를 의미함)가 미리 정해진 기준 밝기에 도달되도록 IR LED의 밝기를 제어할 수 있나(S430). 여기서 미리 정해진 기준 밝기라 함은 극저조도 환경에서 객체인식을 위해 필요한 최소한의 조도의 세기를 의미할 수 있다. 상기 기준 밝기는 감시 사이트의 넓이, 감시 사이트에 등작하는 객체수, 감시 사이트에서 복수의 객체간의 이격 거리 등에 따라 달라질 수 있다. 상기 기준 밝기는 감시 카메라 제조과정에서 초기 출시 시점에서 고정된 값으로 설정될 수도 있지만, 감시 카메라의 조도 환경에 따라 가변될 수 있도록 설정될 수도 있다. 상기 기준 밝기는 전술한 인공지능 학습 모델을 통해 기준밝 기 산출을 위해 모델 훈련을 통해 획득될 수도 있다. 예를 들어, 프로세서는 감시 사이트의 조도를 디텍트 하고, 특정 조도 환경에서 외부 광원의 세기를 조절하면서 촬영된 복수의 영상에서 객체 인식률 정보를 획득할 수 있다. 이에 따라 조도 정보 및 영상 데이터를 입력 데이터로 정의하고, 특정 객체 인식율에 따라 지도 학습 을 수행하여 목표 객체 인식률을 얻기 위한 최적의 IR LED 밝기 정보를 출력 데이터가 되도록 인공신경망 학습 을 진행할 수 있다. 이상, 도 4에서는 본 명세서의 일 실시예에 따라 객체의 위치에 따라 특정 IR LED 에 대해서만 선택적으로 밝기 제어하는 전체적은 흐름을 설명하였다. 이하, 도 5를 통해 객체블록 정보를 활용하여 IR LED의 밝기를 제어하는 과정을 보다 구체적으로 설명한다. 도 5는 본 명세서의 일 실시예에 따라 객체가 위치하는 영역의 IR LED 만을 선택적으로 밝기 제어하기 위한 흐 름도이다. 도 6은 본 명세서의 일 실시예에 따라 IR LED의 위치에 따른 밝기 제어 영역을 구분한 예시이다. 도 5를 참조하면, 프로세서는 카메라로부터 획득된 영상을 M X N 개의 블록으로 분할할 수 있다(S500). 도 6을 참조하면, 감시 카메라는 (b)에 도시된 바와 같이 렌즈 주변을 따라 복수의 IR LED가 배치될 수 있다. 도 6의 (b)에 개시된 배치는 예시적인 배치이며 본 명세서는 이에 한정되는 것은 아니다. 프로세서는 IR LED의 조사각을 고려하여 IR LED의 위치를 조절하는 경우 IR LED가 비추는 영역을 분할할 수 있다. 예를 들어, 프로세서는 카메라부의 렌즈 주위를 따라 배치된 복수의 IR LED를 그룹화하여 관리할 수 있다. 그룹화 하 여 관리하는 것은, 밝기제어를 그룹별로 수행하는 것을 의미할 수 있다. 상기 그룹화의 기준은 복수의 IR LED 각각이 감시 사이트를 조사하는 위치일 수 있다. 즉, 도 6의 (b)에서 그룹 A(GA)에 포함된 두 개의 IR LED의 광 원은 감시 사이트(또는 감시 영상) 중 A 구역을 비추는 그룹을 의미할 수 있다. 그룹 B(GB), 그룹 C(GC), 그룹 D(GD)에 포함되는 IR LED는 각각 B구역, C구역, D구역을 비추는 그룹들이다. 한편, A~D구역은 영상의 모서리 영 역에 해당되며, 모서리가 아닌 중앙영역(E 구역)을 비추는 IR LED는 렌즈 상단부와 하단부로 각각 물리적으로 180도 이격되어 있지만, 조사영역이 E 구역으로 중첩되어 하나의 그룹(GE)으로 분류될 수 있다. 렌즈 주변에 배치되는 IR LED의 개수는 도 6의 예시보다 많거나 적을 수 있으며, IR LED의 개수 및 배치 형태에 따라 도 6의 (a)에 예시한 밝기 제어 영역의 구분 형태는 다양하게 변형될 수 있음은 물론이다. 본 명세서의 일 실시예는 도 6의 (a)에 예시된 밝기 제어 영역에서 객체의 위치를 확인하고, 객체가 위치한 영 역을 비추는 IR LED의 밝기만을 제어할 수 있다. 다만, 객체의 위치 산출 결과로 현재의 객체의 유무와 위치를 확인할 수는 있지만, 객체가 위치한 구역을 선택하여 대응되는 IR LED의 밝기를 최대 밝기로 제어하게 되면 선 택된 구역을 밝아지겠지만, 최대 밝기에 따른 소비전력이 많이 늘어날 수 있고, 발열문제도 발생할 수 있다. 따 라서, 이를 최대한 효율적으로 제어하기 위해 객체가 발생된 영역의 AE(자동노출) 밝기를 판단하여 적당한 밝기 만큼 IR LED 밝기를 재조정하면 효율적으로 밝기를 제어할 수 있다. IR LED 밝기 제어를 위해서는 영상의 블록별 밝기의 통계 데이터를 활용할 수 있다. 도 7을 참조하여, 영상의 블록별 통계데이터 산출과정을 설명한다. 프로세서는 입력된 영상은 M X N 개의 블록으로 분할하되, 각각 의 블록은 m X n 개의 픽셀로 구성되어 있다. 다시 도 5를 참조하면, 프로세서는 분할된 블록의 픽셀밝기에 기초하여 블록별 평균밝기를 산출할 수 있다 (S540). 이를 위해, 프로세서는 객체가 포함된 객체블록의 위치를 확인하고(S520), 객체블록의 위치에 기 초하여 밝기 제어 대상인 타겟 IR LED를 셜정할 수 있다(S530). 프로세서는 아래 수식 1에서와 같이 분할된 블록 내에서 모든 픽셀의 밝기를 합산함으로써, 블록별 평균 밝기를 산출할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "프로세서는 감시 카메라의 영상에서 도 6의 (a)이 같이 영역을 구획하였지만, 실제로 객체는 영상 전체에 걸쳐서 랜덤하게 특정 영역에서 검출될 수 있다. 이에 따라 수학식 1을 통해 모든 블록의 블록별 평균 밝기를 산출하고, 객체가 발생된 위치의 부분의 블록들만 선택하고, 상기 선택된 블록의 평균 밝기 정보를 활용할 수 있다. 예를 들어, 도 8에 도시된 바와 같이, 객체의 적어도 일부를 포함하는 블록은 총 8개의 블록이며 프로세서(26 0)는 상기 8개 블록 각각의 평균 밝기를 합산한 후 객체블록에 포함된 단위블록 수로 나누어 객체 밝기를 산출 할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0020109", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "프로세서는 이와 같이 산출된 객체 밝기가 미리 정해진 기준 밝기보다 낮은 경우(S550:Y), 객체 블록 밝기 가 상기 기준 밝기에 도달하도록 타겟 IR LED의 밝기를 제어할 수 있다(S560). 여기서, 상기 타겟 IR LED 밝기제어 값은 전술한 바와 같이 객체 밝기 값에 의존하는 항목이다. 이에 따라 과도 하게 IR LED 밝기 제어에 따른 높은 소비전력 사용으로 인한 카메라 발열문제를 줄일 수 있다. 또한, 영상에서 객체가 발행된 영역만을 디텍트하여 자동으로 IR LED 밝기를 높일 수 있으므로 효율적으로 소비전력을 줄이면서 밝기를 제어할 수 있다. 도 9를 참조하면, 프로세서는 영상에서 객체를 인식하고, 객체를 포함하는 객체블록의 위치를 확인한다. 프로세서는 상기 객체블록의 위치(A 구역)을 담당하는 IR LED (GA)의 밝기를 제어하기 위해, 객체블록의 밝기를 산출한 후, 타겟 IR LED (GA)의 밝기를 기준 밝기 까지 도달되도록 제어할 수 있다. 도 10은 본 명세서의 일 실시예에 따라 객체의 위치에 따른 AE 제어 방법의 흐름도이다. 다만, 본 명세서의 일 실시예에 따르면 타겟 IR LED의 밝기를 높이도록 제어할 수 있지만, 제어 범위가 타겟 IR LED의 성능 등을 고려할 때 각 IR LED의 한계 밝기 이상으로 밝기를 높일 수는 없다. 이에 따라, 프로세서(26 0)는 영상에서 객체의 위치에 대한 자동노출(AE) 밝기를 기준으로 일정양의 자동노출 증폭량을 추가적으로 제어 할 수 있다. 프로세서는 타겟 IR LED의 한계 밝기가 상기 기준밝기 미만인 경우(S1000:Y), 객체블록 밝기 에 따라 이미지 센서의 이득(Gain) 증폭량을 결정할 수 있다(S1010) 도 11은 본 명세서의 일 실시예에 따라 AI 알고리즘 기반 객체 인식을 통해 IR LED 밝기를 제어하는 다른 예를 설명하기 위한 도면이다. 도 12는 본 명세서의 일 실시예에 따라 AI 기반 객체 인식 결과를 예시한다. 감시 카메라의 프로세서는 영상 프레임을 인공 신경망(Artificial Neural Network, 이하 신경망이라 함) 모델에 입력한다. 상기 신경망 모델은 카메라 영상을 입력 데이터로 하고 상기 입력된 영상 데이터에 포함된 객 체(사람, 자동차 등)를 인식하도록 훈련된 모델일 수 있다. 전술한 바와 같이 본 명세서의 일 실시예에 따라 상 기 신경망 모델은 YOLO 알고리즘이 적용될 수 있다. 프로세서는 신경망 모델의 출력 데이터를 통해 객체의 종류 및 객체의 위치를 인식할 수 있다. 도 12를 참조하면 신경망 모델의 출력 결과 객체인식 결과, 인식된 객 체에 대하여 ID (ID:1, ID:2)를 부여하고, 바운딩 박스(B1,B2)로 표시하고, 각 바운딩 박스의 모서리(C11,C12/ C21, C22)의 좌표값을 포함할 수 있다. 프로세서는 상기 바운딩 박스의 모서리 정보를 통해 각 바운딩 박스의 중심 좌표를 산출할 수 있다. 한편, 감시 카메라에서 AI 프로세싱 결과를 통해 객체를 인식하는 과정을 설명하였으나, 도 11은 상기 AI 프로 세싱 동작을 네트워크 즉 외부 서버를 통해 수행하는 경우를 예시한다. 도 11을 참조하면, 감시 카메라는 영상을 획득한 경우, 획득한 영상 데이터를 네트워크(외부 서버 등)로 전송한 다(S1100). 여기서 감시 카메라는 영상 데이터 전송과 함께 영상에 포함된 객체의 존재 유무, 객체가 존재하는 경우, 영상 내에서 객체의 좌표정보를 함께 요청할 수도 있다. 외부 서버는 AI 프로세서를 통해 감시 카메라로부터 수신된 영상 데이터로부터 신경망 모델에 입력할 영상 프레 임을 확인하고, AI 프로세서는 상기 영상 프레임을 신경망 모델에 적용하도록 제어할 수 있다(S1110). 또한 외 부 서버에 포함된 AI 프로세서는 신경망 모델의 출력 데이터를 통해 객체의 종류 및 객체의 위치를 인식할 수 있다(S1120). 외부 서버는 영상 내에서의 객체 위치정보에 기초하여 객체블록의 위치를 검출할 수 있다(S1130). 감시 카메라는 외부 서버로부터 객체 인식 결과 및/또는 객체블록의 위치정보를 수신할 수 있다(S1140). 감시 카메라는 객체블록 위치에 대응되는 타겟 IR LED를 결정하고(S1150), 객체블록 밝기를 산출한 후, 객체블 록 밝기에 기초하여 타겟 IR LED 밝기를 제어할 수 있다(S1160). 도 13은 본 명세서의 일 실시예에 따라 감시 사이트 내에서 객체가 이동할 경우, 감시 카메라의 제어 방법을 설 명하기 위한 도면이다. 도 13을 참조하면, 본 명세서의 일 실시예에 따라 영상에는 복수의 객체가 포함될 수 있으며, 경우에 따라 객체 가 특정 구역에서 다른 구역으로 이동하는 경우가 발생할 수 있다. 프로세서는 영상에서 객체블록의 위치에 따 라 복수의 IR LED 중 타겟 IR LED를 동적으로 가변할 수 있다. 예를 들어, 프로세서는 제1 객체(ID:1)의 객체블록이 A 구역에서 E 구역으로 이동하고, 제2 객체(ID:2)의 객체블록이 B구역에서 D 구역으로 이동된 것을 감지할 수 있다. 프로세서는 그룹 E의 IR LED와 그룹 D의 IR LED를 밝기제어 대상인 타겟 IR LED로 결정하 고, 각 그룹의 IR LED의 밝기를 제어할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항 의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함 된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2022-0020109", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 명세서에 대한 실시예를 제공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을도 설명한다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라 시스템을 설명하기 위한 도면이다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 3은 본 명세서의 일 실시예에 따른 감시 카메라 영상의 분석에 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 4는 본 명세서의 일 실시예에 따른 감시 카메라의 제어 방법의 흐름도이다. 도 5는 본 명세서의 일 실시예에 따라 객체가 위치하는 영역의 IR LED 만을 선택적으로 밝기 제어하기 위한 흐 름도이다. 도 6은 본 명세서의 일 실시예에 따라 IR LED의 위치에 따른 밝기 제어 영역을 구분한 예시이다. 도 7 내지 도 9은 본 명세서의 일 실시예에 따라 영상 분할을 통해 객체가 위치하는 영역의 IR LED 만을 선택적 으로 밝기 제어하는 방법을 설명하기 위한 도면들이다. 도 10은 본 명세서의 일 실시예에 따라 객체의 위치에 따른 AE 제어 방법의 흐름도이다. 도 11은 본 명세서의 일 실시예에 따라 AI 알고리즘 기반 객체 인식을 통해 IR LED 밝기를 제어하는 다른 예를 설명하기 위한 도면이다. 도 12는 본 명세서의 일 실시예에 따라 AI 기반 객체 인식 결과를 예시한다. 도 13은 본 명세서의 일 실시예에 따라 감시 사이트 내에서 객체가 이동할 경우, 감시 카메라의 제어 방법을 설 명하기 위한 도면이다. 본 발명에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 발명에 대한 실시예를 제공 하고, 상세한 설명과 함께 본 발명의 기술적 특징을 설명한다."}
