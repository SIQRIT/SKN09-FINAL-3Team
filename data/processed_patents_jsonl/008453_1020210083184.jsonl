{"patent_id": "10-2021-0083184", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0001056", "출원번호": "10-2021-0083184", "발명의 명칭": "차량에 탑재된 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "정민수"}}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량에 탑재되는 전자 장치에 있어서, 디스플레이부; 하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 메모리; 및상기 메모리에 저장된 프로그램의 하나 이상의 명령어들을 실행하는 프로세서; 를 포함하고, 상기 프로세서는, 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나를 획득하고, 획득된 상기 적어도 하나의 정보에 기초하여 상기 차량 또는 상기 전자 장치가 제공하는 기능을 실행하기 위한 음성 명령어를 간소화한 적어도 하나의 단축 명령어를 생성하고, 상기 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나의 음성 명령어 가이드 UI(UserInterface)를 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 프로세서는, 탑승자의 사용자 식별 정보(user identification information) 및 사용 이력 정보를 획득하고, 상기 사용자 식별 정보 및 사용 이력 정보로부터 상기 탑승자가 자주 사용하는 애플리케이션 정보를 획득하고, 상기 획득된 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어를 간소화함으로써 상기 적어도 하나의단축 명령어를 생성하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 프로세서는, 상기 디스플레이 출력 정보로부터 상기 디스플레이부 상에 출력되는 적어도 하나의 그래픽 UI(GUI)가 나타내는기능을 인식하고, 상기 인식된 기능을 자연어로 변환함으로써, 상기 적어도 하나의 GUI 각각에 대응되는 상기 적어도 하나의 단축명령어를 생성하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 프로세서는,상기 적어도 하나의 음성 명령어 가이드 UI를 상기 적어도 하나의 음성 명령어 가이드 UI 각각에 대응되는 기능을 나타내는 적어도 하나의 그래픽 UI의 인접한 위치에 디스플레이하도록 상기 디스플레이부를 제어하는, 전자공개특허 10-2023-0001056-3-장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서, 상기 디스플레이부는 상기 차량에 포함되는 탑승석들에 대응하는 복수의 디스플레이들을 포함하고,상기 프로세서는, 상기 차량에 탑승한 탑승자로부터 음성 인식 기능을 활성화하는 사용자 입력을 수신하고,상기 사용자 입력에 응답하여 상기 복수의 디스플레이들 중 상기 탑승자가 탑승한 탑승석에 대응하는 디스플레이의 음성 인식 기능을 활성화하고, 상기 디스플레이 상에 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 상기 프로세서는, 상기 차량 주행 정보에 포함되는 상기 차량의 현재 위치, 주행 도로, 및 주행 속도에 관한 정보에 기초하여 안전 속도를 결정하고, 상기 차량 주행 정보, 상기 탑승자 정보, 상기 디스플레이 출력 정보, 및 결정된 상기 안전 속도 중 적어도 하나에 기초하여 상기 음성 명령어 가이드 UI의 가중치를 결정하고, 상기 결정된 가중치에 기초하여 상기 음성 명령어 가이드 UI의 표시 여부, 표시 위치, 및 표시 크기를결정하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 프로세서는, 상기 차량의 주행 정보로부터 차량의 주행 속도가 상기 안전 속도 이상인지 여부를 인식하고,상기 차량의 주행 속도의 인식 결과에 기초하여, 상기 차량의 주행과 관련되는 기능을 실행하기 위한 적어도 하나의 제1 음성 명령어 가이드 UI의 가중치 및 상기 차량의 주행과 관련되지 않는 편의 기능을 실행하기 위한 적어도 하나의 제2 음성 명령어 가이드 UI의 가중치를 조절하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,상기 프로세서는, 상기 디스플레이부 상에 디스플레이되는 그래픽 UI를 오버레이하는 팝 업 메시지(pop-up message)가 출력되는경우, 상기 팝 업 메시지를 상기 디스플레이부 상에서 제거하기 위한 기능을 실행하는 음성 명령어 가이드 UI의가중치를 조절하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2023-0001056-4-제1 항에 있어서,상기 프로세서는, 탑승자의 위치와 상기 디스플레이부 사이의 거리에 기초하여, 상기 디스플레이부 상에서 상기 적어도 하나의 음성 명령어 가이드 UI가 디스플레이되는 영역을 결정하고,상기 결정된 영역에 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하도록 상기 디스플레이부를 제어하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,탑승자에 의해 발화된 음성 입력을 수신하는 마이크로폰;을 더 포함하고, 상기 프로세서는, 상기 마이크로폰을 통해 수신된 음성 입력과 상기 적어도 하나의 음성 명령어 가이드 UI가 나타내는 상기 적어도 하나의 단축 명령어를 비교함으로써, 상기 음성 입력과 대응되는 단축 명령어를 식별하고,상기 식별된 단축 명령어에 대응되는 기능을 실행하는, 전자 장치."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "차량에 탑재되는 전자 장치의 동작 방법에 있어서, 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나를 획득하는 단계; 상기 획득된 적어도 하나의 정보에 기초하여, 탑승자로부터 수신되는 음성 입력에 의해 상기 차량 또는 상기 전자 장치가 제공하는 기능을 실행하기 위한 음성 명령어를 간소화한 적어도 하나의 단축 명령어를 생성하는단계; 및생성된 상기 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나의 음성 명령어 가이드UI(User Interface)를 디스플레이하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 적어도 하나의 정보를 획득하는 단계는, 탑승자의 사용자 식별 정보(user identification information) 및 사용 이력 정보를 획득하는 단계; 및 상기 사용자 식별 정보 및 사용 이력 정보로부터 상기 탑승자가 자주 사용하는 애플리케이션 정보를 획득하는단계; 를 포함하고, 상기 적어도 하나의 단축 명령어를 생성하는 단계는, 상기 획득된 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어를 간소화함으로써 상기 적어도 하나의단축 명령어를 생성하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2023-0001056-5-제11 항에 있어서,상기 적어도 하나의 정보를 획득하는 단계는, 디스플레이부 상에 출력되는 적어도 하나의 그래픽 UI(GUI)가 나타내는 기능을 인식하는 단계를 포함하고, 상기 적어도 하나의 단축 명령어를 생성하는 단계는, 상기 인식된 기능을 자연어로 변환함으로써, 상기 적어도 하나의 GUI 각각에 대응되는 상기 적어도 하나의 단축명령어를 생성하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항에 있어서,상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계는,상기 적어도 하나의 음성 명령어 가이드 UI를 상기 적어도 하나의 음성 명령어 가이드 UI 각각에 대응되는 기능을 나타내는 적어도 하나의 그래픽 UI의 인접한 위치에 각각 디스플레이하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서, 상기 전자 장치는 상기 차량에 포함되는 운전석, 조수석, 및 뒷좌석 각각에 대응되는 복수의 디스플레이들을 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계는, 상기 운전석, 조수석, 및 뒷좌석 중 적어도 하나에 탑승한 탑승자로부터 음성 인식 기능을 활성화하는 사용자입력을 수신하는 단계;상기 사용자 입력에 응답하여, 상기 복수의 디스플레이들 중 상기 운전석, 조수석, 및 뒷좌석 중 상기 탑승자가탑승한 탑승석에 대응되는 디스플레이의 음성 인식 기능을 활성화하는 단계; 및상기 디스플레이 상에 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11 항에 있어서, 상기 차량 주행 정보에 포함되는 상기 차량의 현재 위치, 주행 도로, 및 주행 속도에 관한 정보에 기초하여 안전 속도를 결정하는 단계; 를 더 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계는, 상기 차량 주행 정보, 상기 탑승자 정보, 상기 디스플레이 출력 정보, 및 결정된 상기 안전 속도 중 적어도 하나에 기초하여 상기 적어도 하나의 음성 명령어 가이드 UI 각각의 가중치를 결정하는 단계; 상기 결정된 가중치에 기초하여 상기 적어도 하나의 음성 명령어 가이드 UI의 표시 여부, 표시 위치, 및 표시크기를 결정하는 단계; 및 결정된 개수, 위치, 및 크기에 따라 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계; 를 포함하는, 방법. 공개특허 10-2023-0001056-6-청구항 17 제16 항에 있어서,상기 적어도 하나의 정보를 획득하는 단계는, 상기 차량의 주행 정보로부터 차량의 주행 속도가 상기 안전 속도 이상인지 여부를 인식하는 단계를 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI의 가중치를 결정하는 단계는, 상기 차량의 주행 속도의 인식 결과에 기초하여, 상기 차량의 주행과 관련되는 기능을 실행하기 위한 적어도 하나의 제1 음성 명령어 가이드 UI의 가중치 및 상기 차량의 주행과 관련되지 않는 편의 기능을 실행하기 위한 적어도 하나의 제2 음성 명령어 가이드 UI의 가중치를 조절하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16 항에 있어서,상기 적어도 하나의 음성 명령어 가이드 UI의 가중치를 결정하는 단계는, 상기 디스플레이부 상에 디스플레이되는 그래픽 UI를 오버레이하는 팝 업 메시지(pop-up message)가 출력되는경우, 상기 팝 업 메시지를 상기 디스플레이부 상에서 제거하기 위한 기능을 실행하는 음성 명령어 가이드 UI의가중치를 조절하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11 항에 있어서,상기 적어도 하나의 정보를 획득하는 단계는, 탑승자의 탑승 위치에 관한 정보를 획득하는 단계를 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계는, 상기 탑승자의 탑승 위치 정보에 따른 상기 탑승자와 상기 디스플레이부 사이의 거리에 기초하여, 상기 디스플레이부 상에서 상기 적어도 하나의 음성 명령어 가이드 UI가 디스플레이되는 영역을 결정하는 단계; 및 상기 결정된 영역에 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2021-0083184", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11 항 내지 제19 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0083184", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 음성 명령을 통해 차량 또는 전자 장치의 기능을 실행하기 위한 시각적인 가이드 UI(User Interface) 를 제공하는 방법 및 전자 장치를 제공한다. 본 개시의 일 실시예는 차량의 주행 정보, 탑승자 정보, 및 디스플 레이 출력 정보 중 적어도 하나에 관한 정보를 획득하고, 획득된 적어도 하나의 정보에 기초하여 탑승자로부터 수신되는 음성 입력에 의해 상기 차량 또는 상기 전자 장치가 제공하는 적어도 하나의 기능을 실행하기 위한 음 성 명령어들을 간소화한 적어도 하나의 단축 명령어를 생성하며, 생성된 적어도 하나의 단축 명령어 각각을 문자, 숫자, 또는 기호를 이용하여 시각적으로 나타내는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 전자 장치를 제공한다."}
{"patent_id": "10-2021-0083184", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 차량에 탑재된 전자 장치 및 그 동작 방법에 관한 것이다. 구체적으로, 본 개시는 음성 명령을 통해 차량 또는 전자 장치의 기능을 실행하기 위한 시각적인 가이드 UI(User Interface)를 제공하는 방법 및 전자 장 치를 제공한다."}
{"patent_id": "10-2021-0083184", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 인식 기술의 발전으로 인하여, 차량 내에서도 운전자의 음성 입력을 통해 기능을 실행할 수 있는 음성 인 식 기술이 보급되고 있다. 종래의 차량에서 제공되는 음성 인식 기능은, 운전자로부터 음성 입력을 수신하여 차 량 또는 차량 내 전자 장치에 의해 제공되는 기능을 실행하는 일반적인 음성 인식 에이전트(voice agent)와 차 량 내 디스플레이 화면 및 상황을 인식하여 음성 인식 기능 리스트를 제공하는 voice access 로 구분될 수 있다. 일반적인 음성 인식 에이전트의 경우, 차량 내에서 제공되는 기능에 관한 음성 명령어 리스트에 관한 안내가 존 재하지 않으며, 이로 인하여 사용자는 어떠한 음성 명령을 발화해야 어떤 기능이 실행되는지를 정확하게 알 수 없다. 따라서, 사용자가 특정 음성 명령어를 발화하면, 차량에서는 대응되는 기능을 실행하기 위하여 필요한 파 라미터(parameter)를 문의하고, 사용자는 문의에 따라 특정 파라미터를 다시 발화하여 차량에 기능에 관한 정보 를 제공해야 하는 번거로움이 있다. 예를 들어, 운전자가 음악 애플리케이션을 통해 현재 듣고 있는 곡에서 다 음 곡을 플레이하고 싶은 경우, 운전자는 \"다음 곡 틀어줘~\"라는 음성 명령을 발화할 수 있다. 이 경우, 차량 내 전자 장치는 운전자의 음성 명령과 관련하여, 음악 애플리케이션과 관련된 발화인지, 현재 플레이되고 있는 곡의 다음 곡을 의미하는지, 아니면 곡의 이름이 '다음곡'인지 여부를 정확하게 알 수 없다. 따라서, 차량 내 전자 장치는 \"음악 애플리케이션에서 다음 곡을 플레이하라는 말씀이신가요?\" 와 같은 운전자의 음성 명령에 관 한 파라미터 정보를 획득 또는 확인하기 위한 문의 메시지를 출력할 수 있다. 운전자는 문의 메시지에 관하여 \"응. 음악 애플리케이션에서 다음 곡 플레이\"와 같은 추가 음성 명령을 발화해야만 한다. 전술한 예시에서, 운 전자는 음성 인식 기능을 이용함에 있어서 차량의 전자 장치와의 인터랙션(interaction)이 증가하고, 이로 인하 여 운전자의 피로도가 감소되며, 주의력이 분산되어 사고 위험성이 증가되는 문제점이 있다. 또한, 추가적인 파 라미터 정보를 입력해야 하는 번거로움 때문에, 운전자가 음성 인식 기능을 활용하는 빈도수가 떨어질 수 있다. 음성 인식을 통해 기능을 수행하기 위한 음성 명령어 리스트를 제공하는 voice access의 경우, 디스플레이 화면 에 많은 정보를 표시하여 주행 중 운전자의 주의력 분산을 유발하는 문제점이 있다. 또한, 종래의 voice access 는 차량의 주행 환경이나 탑승자 정보와는 관계없이 동일한 음성 명령어 리스트만을 제공하는 바, 사용자에 특 화된 음성 인식 서비스를 제공하지 않는다."}
{"patent_id": "10-2021-0083184", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 음성 인식 기능 사용 시 운전자와 차량 내 전자 장치 간의 인터랙션을 감소시키고, 음성 인식의 정확 성을 향상시키기 위하여, 차량 또는 전자 장치의 기능을 실행하기 위한 음성 명령어를 시각적으로 표시하는 가 이드 UI(User Interface)를 출력하는 전자 장치 및 그 동작 방법을 제공한다."}
{"patent_id": "10-2021-0083184", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위하여 본 개시의 일 실시예는 차량에 탑재되는 전자 장치를 제공한다. 본 개시 의 전자 장치는 디스플레이부, 하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 메모리, 및 상기 메모리에 저장된 프로그램의 하나 이상의 명령어들을 실행하는 프로세서를 포함하고, 상기 프로세서는 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나를 획득하고, 획득된 상기 적어도 하 나의 정보에 기초하여 상기 차량 또는 상기 전자 장치가 제공하는 기능을 실행하기 위한 음성 명령어를 간소화 한 적어도 하나의 단축 명령어를 생성하고, 상기 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어 도 하나의 음성 명령어 가이드 UI(User Interface)를 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 일 실시 예에서, 상기 프로세서는 탑승자의 사용자 식별 정보(user identification information) 및 사용 이력 정보를 획득하고, 상기 사용자 식별 정보 및 사용 이력 정보로부터 상기 탑승자가 자주 사용하는 애플리케이션 정보를 획득하고, 상기 획득된 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어를 간소화함으로써 상기 적어도 하나의 단축 명령어를 생성할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 디스플레이 출력 정보로부터 상기 디스플레이부 상에 출력되는 적어도 하나의 그래픽 UI(GUI)가 나타내는 기능을 인식하고, 상기 인식된 기능을 자연어로 변환함으로써, 상기 적어도 하나의 GUI 각각에 대응되는 상기 적어도 하나의 단축 명령어를 생성할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 적어도 하나의 음성 명령어 가이드 UI를 상기 적어도 하나의 음성 명령 어 가이드 UI 각각에 대응되는 기능을 나타내는 적어도 하나의 그래픽 UI의 인접한 위치에 디스플레이하도록 상 기 디스플레이부를 제어할 수 있다. 일 실시 예에서, 상기 디스플레이부는 상기 차량에 포함되는 탑승석들에 대응하는 복수의 디스플레이들을 포함 하고, 상기 프로세서는 상기 차량에 탑승한 탑승자로부터 음성 인식 기능을 활성화하는 사용자 입력을 수신하고, 사용자 입력에 응답하여 상기 복수의 디스플레이들 중 상기 탑승자가 탑승한 탑승석에 대응하는 디스 플레이의 음성 인식 기능을 활성화하고, 상기 디스플레이 상에 상기 적어도 하나의 음성 명령어 가이드 UI를 디 스플레이하도록 상기 디스플레이부를 제어할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 차량 주행 정보에 포함되는 상기 차량의 현재 위치, 주행 도로, 및 주행 속도에 관한 정보에 기초하여 안전 속도를 결정하고, 상기 차량 주행 정보, 상기 탑승자 정보, 상기 디스플레이 출력 정보, 및 결정된 상기 안전 속도 중 적어도 하나에 기초하여 상기 음성 명령어 가이드 UI의 가중치를 결정 하고, 상기 결정된 가중치에 기초하여 상기 음성 명령어 가이드 UI의 표시 여부, 표시 위치, 및 표시 크기를 결 정할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 차량의 주행 정보로부터 차량의 주행 속도가 상기 안전 속도 이상인지 여부를 인식하고, 상기 차량의 주행 속도의 인식 결과에 기초하여, 상기 차량의 주행과 관련되는 기능을 실행하 기 위한 적어도 하나의 제1 음성 명령어 가이드 UI의 가중치 및 상기 차량의 주행과 관련되지 않는 편의 기능을 실행하기 위한 적어도 하나의 제2 음성 명령어 가이드 UI의 가중치를 조절할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 디스플레이부 상에 디스플레이되는 그래픽 UI를 오버레이하는 팝 업 메 시지(pop-up message)가 출력되는 경우, 상기 팝 업 메시지를 상기 디스플레이부 상에서 제거하기 위한 기능을 실행하는 음성 명령어 가이드 UI의 가중치를 조절할 수 있다. 일 실시 예에서, 상기 프로세서는 탑승자의 위치와 상기 디스플레이부 사이의 거리에 기초하여 상기 디스플레이 부 상에서 상기 적어도 하나의 음성 명령어 가이드 UI가 디스플레이되는 영역을 결정하고, 상기 결정된 영역에 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하도록 상기 디스플레이부를 제어할 수 있다. 일 실시 예에서, 상기 전자 장치는 탑승자에 의해 발화된 음성 입력을 수신하는 마이크로폰을 더 포함하고, 상 기 프로세서는 상기 마이크로폰을 통해 수신된 음성 입력과 상기 적어도 하나의 음성 명령어 가이드 UI가 나타 내는 상기 적어도 하나의 단축 명령어를 비교함으로써, 상기 음성 입력과 대응되는 단축 명령어를 식별하고, 상 기 식별된 단축 명령어에 대응되는 기능을 실행할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 본 개시의 일 실시예는 차량에 탑재된 전자 장치의 동작 방법을 제공한 다. 상기 방법은, 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나를 획득하는 단계, 상기 획득된 적어도 하나의 정보에 기초하여, 탑승자로부터 수신되는 음성 입력에 의해 상기 차량 또는 상기 전 자 장치가 제공하는 기능을 실행하기 위한 음성 명령어를 간소화한 적어도 하나의 단축 명령어를 생성하는 단계, 및 생성된 상기 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나의 음성 명령어 가이 드 UI(User Interface)를 디스플레이하는 단계를 포함할 수 있다. 일 실시 예에서, 상기 적어도 하나의 정보를 획득하는 단계는 탑승자의 사용자 식별 정보(user identification information) 및 사용 이력 정보를 획득하는 단계, 및 상기 사용자 식별 정보 및 사용 이력 정보로부터 상기 탑 승자가 자주 사용하는 애플리케이션 정보를 획득하는 단계를 포함하고, 상기 적어도 하나의 단축 명령어를 생성 하는 단계에서 상기 전자 장치는 상기 획득된 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어를 간 소화함으로써 상기 적어도 하나의 단축 명령어를 생성할 수 있다. 일 실시 예에서, 상기 적어도 하나의 정보를 획득하는 단계에서 상기 전자 장치는 디스플레이부 상에 출력되는 적어도 하나의 그래픽 UI(GUI)가 나타내는 기능을 인식하는 단계를 포함하고, 상기 적어도 하나의 단축 명령어 를 생성하는 단계는 상기 인식된 기능을 자연어로 변환함으로써, 상기 적어도 하나의 GUI 각각에 대응되는 상기 적어도 하나의 단축 명령어를 생성할 수 있다. 일 실시 예에서, 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계에서 상기 전자 장치는 상기 적어도 하나의 음성 명령어 가이드 UI를 상기 적어도 하나의 음성 명령어 가이드 UI 각각에 대응되는 기능을 나 타내는 적어도 하나의 그래픽 UI의 인접한 위치에 각각 디스플레이할 수 있다. 일 실시 예에서, 상기 전자 장치는 상기 차량에 포함되는 운전석, 조수석, 및 뒷좌석 각각에 대응되는 복수의 디스플레이들을 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계는 상기 운전석,조수석, 및 뒷좌석 중 적어도 하나에 탑승한 탑승자로부터 음성 인식 기능을 활성화하는 사용자 입력을 수신하 는 단계, 상기 사용자 입력에 응답하여 상기 복수의 디스플레이들 중 상기 운전석, 조수석, 및 뒷좌석 중 상기 탑승자가 탑승한 탑승석에 대응되는 디스플레이의 음성 인식 기능을 활성화하는 단계, 및 상기 디스플레이 상에 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계를 포함할 수 있다. 일 실시 예에서, 상기 방법은 상기 차량 주행 정보에 포함되는 상기 차량의 현재 위치, 주행 도로, 및 주행 속 도에 관한 정보에 기초하여 안전 속도를 결정하는 단계를 더 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계는 상기 차량 주행 정보, 상기 탑승자 정보, 상기 디스플레이 출력 정보, 및 결정된 상기 안전 속도 중 적어도 하나에 기초하여 상기 적어도 하나의 음성 명령어 가이드 UI 각각의 가중치를 결정하 는 단계, 상기 결정된 가중치에 기초하여 상기 적어도 하나의 음성 명령어 가이드 UI의 표시 여부, 표시 위치, 및 표시 크기를 결정하는 단계, 및 결정된 개수, 위치, 및 크기에 따라 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계를 포함할 수 있다. 일 실시 예에서, 상기 적어도 하나의 정보를 획득하는 단계는 상기 차량의 주행 정보로부터 차량의 주행 속도가 상기 안전 속도 이상인지 여부를 인식하는 단계를 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI의 가중 치를 결정하는 단계에서 상기 전자 장치는 상기 차량의 주행 속도의 인식 결과에 기초하여, 상기 차량의 주행과 관련되는 기능을 실행하기 위한 적어도 하나의 제1 음성 명령어 가이드 UI의 가중치 및 상기 차량의 주행과 관 련되지 않는 편의 기능을 실행하기 위한 적어도 하나의 제2 음성 명령어 가이드 UI의 가중치를 조절할 수 있다. 일 실시 예에서, 상기 적어도 하나의 음성 명령어 가이드 UI의 가중치를 결정하는 단계에서 상기 디스플레이부 상에 디스플레이되는 그래픽 UI를 오버레이하는 팝 업 메시지(pop-up message)가 출력되는 경우, 상기 전자 장 치는 상기 팝 업 메시지를 상기 디스플레이부 상에서 제거하기 위한 기능을 실행하는 음성 명령어 가이드 UI의 가중치를 조절할 수 있다. 일 실시 예에서, 상기 적어도 하나의 정보를 획득하는 단계는 탑승자의 탑승 위치에 관한 정보를 획득하는 단계 를 포함하고, 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 단계는 상기 탑승자의 탑승 위치 정 보에 따른 상기 탑승자와 상기 디스플레이부 사이의 거리에 기초하여, 상기 디스플레이부 상에서 상기 적어도 하나의 음성 명령어 가이드 UI가 디스플레이되는 영역을 결정하는 단계, 및 상기 결정된 영역에 상기 적어도 하 나의 음성 명령어 가이드 UI를 디스플레이하는 단계를 포함할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 본 개시의 다른 실시예는 컴퓨터에서 실행시키기 위한 프로그램을 기록 한 컴퓨터로 읽을 수 있는 기록매체를 제공한다."}
{"patent_id": "10-2021-0083184", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라 질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 개시에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일 반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 “포함”한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 개시에 기재 된 “...부”, “...모듈” 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드 웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 사용된 표현 “~하도록 구성된(또는 설정된)(configured to)”은 상황에 따라, 예를 들면, “~에 적합한(suitable for)”, “~하는 능력을 가지는(having the capacity to)”, “~하도록 설계된(designed to) ”, “~하도록 변경된(adapted to)”, “~하도록 만들어진(made to)”, 또는 “~를 할 수 있는(capable of)” 과 바꾸어 사용될 수 있다. 용어 “~하도록 구성된(또는 설정된)”은 하드웨어적으로 “특별히 설계된 (specifically designed to)” 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, “~하도록 구성 된 시스템”이라는 표현은, 그 시스템이 다른 장치 또는 부품들과 함께 “~할 수 있는” 것을 의미할 수 있다. 예를 들면, 문구 “A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서”는 해당 동작을 수행하기 위한 전 용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로 써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시에서 '차량'은 도로 위를 주행하는 모든 종류의 차를 의미하고, 특히 전자 장치가 탑재된 차를 의미한다. 본 개시에서 '음성 입력'은 차량 내에 탑승한 운전자, 조수석 탑승자, 또는 뒷좌석 탑승자 중 적어도 하나의 탑 승자에 의해 발화되고, 전자 장치의 음성 입력부(예를 들어, 마이크로폰)를 통해 수신되는 입력을 의미한다. 본 개시에서 '음성 명령어'는 탑승자에 의해 발화되는 음성 입력으로서, 차량 또는 전자 장치의 기능 및/또는 동작을 실행하기 위한 명령어를 의미한다. 음성 명령어는 예를 들어, \"~~(목적지)까지 이동 경로 알려줘\" 또는 \"다음 노래 틀어줘\"일 수 있다. 본 개시에서 '단축 명령어'는 차량 또는 전자 장치의 기능 및/또는 동작을 실행하기 위한 명령어의 키워드만을 추출함으로써 생성된 단축된 명령어를 의미한다. 예를 들어, 네비게이션 애플리케이션에서 목적지까지 이동 경로를 알고 싶은 경우 단축 명령어는 '목적지'이고, 음악 애플리케이션에서 다음 곡을 듣고 싶은 경우 단축 명령 어는 '다음곡'일 수 있다. 본 개시에서 '단축 명령어 리스트'는 적어도 하나의 단축 명령어를 포함하는 리스트이다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1은 본 개시의 전자 장치가 음성 명령어 가이드 UI(101, 102, 103, 104)를 디스플레이하는 실시예를 도시한 개념도이다. 도 1을 참조하면, 전자 장치는 차량 내에 배치되고, 디스플레이부를 포함할 수 있다. 일 실시예에 서, 디스플레이부는 CID(Center Information Display)일 수 있으나, 이에 한정되는 것은 아니다. 디스플 레이부는 예를 들어, 네비게이션 장치, 계기판 디스플레이, HUD(Head Up Display), 또는 조수석 디스플레 이 중 적어도 하나로 구성될 수 있다. 전자 장치는 디스플레이부 상에 애플리케이션의 기능을 실행하기 위한 음성 명령어의 발화를 유도 하는 음성 명령어 가이드 UI(101, 102, 103, 104)를 디스플레이할 수 있다. '음성 명령어 가이드 UI(101, 102, 103, 104)'는 애플리케이션을 통해 제공되는 차량 또는 전자 장치의 기능을 실행하기 위하여 탑승자의 발 화를 유도하는 음성 명령어를 문자, 숫자, 또는 기호로 표시하는 UI이다. 일 실시예에서, 음성 명령어 가이드 UI(101, 102, 103, 104)는 그래픽 UI(Graphic User Interface)일 수 있다. 음성 명령어 가이드 UI(101, 102, 103, 104)는 하나 또는 그 이상의 복수 개로 구성될 수 있다. 전자 장치는 애플리케이션의 기능을 실행하기 위한 사용자 입력을 수신하는 기능 UI(111, 112, 113, 11 4)를 디스플레이할 수 있다. 일 실시예에서, 기능 UI(111, 112, 113, 114)는 애플리케이션의 실행 화면을 표시 하는 위젯, 애플리케이션의 기능을 나타내는 아이콘, 또는 버튼 UI 중 적어도 하나를 포함할 수 있다. 음성 명령어 가이드 UI(101, 102, 103, 104)는 대응되는 기능 UI(111, 112, 113, 114)와 인접한 위치에 배치되 고, 디스플레이될 수 있다. 도 1에 도시된 실시예에서, 음악 애플리케이션의 실행을 위한 제1 UI와 인접한 위치에는 '음악'이라는 음성 명령어를 수신하기 위한 문자로 구성되는 제1 음성 명령어 가이드 UI가 디스 플레이될 수 있다. 또한, 이전 곡을 플레이하기 위한 버튼형 그래픽 UI인 제2 UI와 인접한 위치에는 '이전 곡'이라는 문자로 구성되는 제2 음성 명령어 가이드 UI가, 플레이(또는 정지(pause))를 위한 버튼형 그래 픽 UI인 제3 UI와 인접한 위치에는 '플레이'라는 문자로 구성되는 제3 음성 명령어 가이드 UI가, 다 음 곡을 플레이하기 위한 버튼형 그래픽 UI인 제4 UI와 인접한 위치에는 '다음곡'이라는 문자로 구성되는 제4 음성 명령어 가이드 UI가 각각 디스플레이될 수 있다. 도 1에 도시된 실시예에서, 음성 명령어 가이드 UI(101, 102, 103, 104)는 상술한 '음악', '이전곡', '플레이', '다음곡' 외에 '네비', '줌 인', '줌 아웃', '날씨', '에어컨', '온도 업', 또는 '온도 다운'을 더 포함할 수 있다. 전자 장치는 운전자로부터 음성 인식 기능을 활성화하는 사용자 입력을 수신하고, 수신된 사용자 입력에 따라 대기 모드에서 음성 명령어를 수신하는 음성 인식 모드로 전환될 수 있다. 전자 장치는 예를 들어, 음성 인식 기능을 실행하기 위한 버튼 입력 또는 디스플레이부 상에 디스플레이되는 GUI를 통한 터치 입 력을 수신할 수 있다. 전자 장치는 사용자 입력을 수신함에 따라, 음성 입력을 수신하기 위한 음성 인식 UI를 디스플레이할 수 있다. 전자 장치는 음성 인식 UI를 통해 운전자에 의해 발화된 음성 입 력을 수신할 수 있다. 도 1에 도시된 실시예에서, 전자 장치는 운전자에 의해 발화된 '다음 곡'이라는 음 성 입력을 수신할 수 있다. 전자 장치는 수신된 음성 입력을 디스플레이부 상에 디스플레이된 음성 명령어 가이드 UI(101, 102, 103, 104)와 각각 비교함으로써, 대응되는 음성 명령어 가이드 UI(101, 102, 103, 104)를 식별할 수 있다. 도 1에 도시된 실시예에서, 전자 장치는 '다음 곡'이라는 음성 입력을 수신하고, 복수의 음성 명령 어 가이드 UI(101, 102, 103, 104) 중 수신된 음성 입력과 대응되는 제4 음성 명령어 가이드 UI를 식별할 수 있다. 전자 장치는 제4 음성 명령어 가이드 UI가 나타내는 기능인 '다음 곡 플레이 기능'을 실행 할 수 있다. 종래 기술에서, 차량의 전자 장치에 의해 제공되는 일반적인 음성 인식 에이전트의 경우, 실행 가능한 기능에 관한 음성 명령어 리스트에 관한 안내가 존재하지 않으며, 이로 인하여 운전자 또는 탑승자는 어떠한 음성 명령 을 발화해야 어떤 기능이 실행되는지를 정확하게 알 수 없다. 따라서, 운전자가 특정 음성 명령어를 발화하면, 차량의 전자 장치는 발화에 대응되는 기능을 실행하기 위하여 필요한 파라미터(parameter)를 문의하고, 운전자 는 문의에 따라 특정 파라미터를 다시 발화하여 차량에 기능에 관한 정보를 제공해야 하는 번거로움이 있다. 예 를 들어, 운전자가 음악 애플리케이션을 통해 현재 듣고 있는 곡에서 다음 곡을 플레이하고 싶은 경우, 운전자 는 \"다음 곡 틀어줘~\"라는 음성 명령을 발화할 수 있다. 이 경우, 차량 내 전자 장치는 운전자의 음성 명령과 관련하여, 음악 애플리케이션과 관련된 발화인지, 현재 플레이되고 있는 곡의 다음 곡을 의미하는지, 아니면 곡 의 이름이 '다음곡'인지 여부를 정확하게 알 수 없다. 따라서, 차량 내 전자 장치는 \"음악 애플리케이션에서 현 재 플레이되고 있는 곡의 다음 곡을 플레이하라는 말씀이신가요?\" 와 같은 운전자의 음성 명령에 관한 파라미터 정보를 획득 또는 확인하기 위한 문의 메시지를 출력할 수 있다. 운전자는 문의 메시지에 관하여 \"응. 음악 애 플리케이션에서 다음 곡 플레이\"와 같은 추가 음성 명령을 발화해야만 한다. 전술한 예시에서, 운전자는 음성 인식 기능을 이용함에 있어서 차량의 전자 장치와의 인터랙션(interaction)이 증가하고, 이로 인하여 운전자의 피로도가 감소되며, 주의력이 분산되어 사고 위험성이 증가되는 문제점이 있다. 또한, 추가적인 파라미터 정보 를 입력해야 하는 번거로움 때문에, 운전자가 음성 인식 기능을 활용하는 빈도수가 떨어질 수 있다. 도 1에 도시된 실시예에 따른 전자 장치는 애플리케이션에 의해 제공되는 기능 각각에 대하여 음성 명령 을 발화하도록 유도하는 음성 명령어 가이드 UI(101, 102, 103, 104)를 디스플레이할 수 있다. 이에 따라, 운전 자 또는 탑승자가 실행하고자 하는 기능을 직관적으로 이해할 수 있도록 하고, 기능 인식도 및 사용자 편의성을 향상시키는 효과가 있다. 또한, 본 개시의 전자 장치는 기능을 실행하기 위하여 추가적인 파라미터 정보 를 요구하지 않고, 음성 명령어 가이드 UI(101, 102, 103, 104)를 통해 제공되는 음성 명령어에 매칭되는 발화 를 수신함에 따라 기능을 실행하므로, 전자 장치와의 인터랙션을 감소시킬 수 있고, 운전자의 집중력 분 산을 최소화할 수 있다. 또한, 본 개시의 일 실시예에 따른 전자 장치는, 디스플레이부가 대화면 디스플레이인 경우, 또는 복수의 디스플레이부를 포함하는 멀티 디스플레이인 경우, 또는, 운전자 또는 탑승자가 직접 기능 UI(111, 112, 113, 114)를 터치하기 어려운 경우, 음성 명령어 가이드 UI(101, 102, 103, 104)에 표시되는 음성 명령어를 발 화함으로써 관련 기능을 실행시킬 수 있다. 이에 따라, 보이스 터치(voice touch)와 같은 사용자 경험(User eXperience; UX)을 제공할 수 있다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 도 2를 참조하면, 전자 장치는 통신 인터페이스, 프로세서, 메모리, 단축 명령어 데이 터베이스, 입력부, 및 출력부를 포함할 수 있다. 통신 인터페이스, 프로세서, 메모리, 단축 명령어 데이터베이스, 입력부, 및 출력부는 각각 전기적 및/또는 물리적 으로 서로 연결될 수 있다. 도 2에 도시된 구성 요소는 본 개시의 일 실시예에 따른 것일 뿐, 전자 장치가 포함하고 있는 구성 요소 가 도 2에 도시된 것으로 한정되는 것은 아니다. 전자 장치는 도 2에 도시된 구성 요소 중 일부를 포함하 지 않을 수 있고, 도 2에 도시되지 않은 구성 요소를 더 포함할 수도 있다. 예를 들어, 전자 장치는 차량 의 현재 위치에 관한 정보를 획득하기 위한 GPS 센서 또는 탑승자의 위치를 인식하기 위한 적외선 센서를 더 포 함할 수 있다. 통신 인터페이스는 차량 센서 모듈(200, 도 3 참조), 서버 또는 외부 디바이스와 데이터 통신을 수행하도 록 구성된다. 통신 인터페이스는 CAN 통신 모듈 및 데이터 통신 모듈을 포함할 수 있다. CAN(Controller Area Network) 통신 모듈은 차량에 탑재된 차량 센서 모듈과 CAN 통신을 수행할 수 있다. CAN 통신 모듈은 CAN 통신을 통해 차량 센서 모듈로부터 차량의 현재 위치, 주행 중인 도로, 또는 주행 속도 중 적어도 하나를 포함하는 주행 관련 정보를 수신할 수 있다. 일 실시예에서, CAN 통신 모듈 은 차량의 시트 센서(230, 도 3 참조)로부터 차량 내 운전석, 조수석, 및 뒷좌석 각각에 탑승한 탑승자 정보를 수신할 수도 있다. 일 실시예에서, CAN 통신 모듈은 차량의 적외선 센서(240, 도 3 참조)로부터 탑승자의 탑승 위치에 따른 탑승자와 디스플레이부 사이의 거리에 관한 정보를 수신할 수도 있다. CAN 통 신 모듈은 수신된 주행 정보, 탑승자 정보, 탑승자와 디스플레이부 간의 거리 정보를 프로세서에 제공할 수 있다. 차량 센서 모듈에 관해서는 도 3에서 상세하게 설명하기로 한다. 데이터 통신 모듈은 차량 외부의 서버 또는 외부 디바이스와 데이터 통신을 수행하도록 구성된다. 데이터 통신 모듈은 예를 들어, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), 또는 블루투스와 같은 근거리 무선 데이터 통신 뿐만 아니라, CDMA, WCDMA, 3G, 4G, 및/또는 5G, 밀리미터파(mmWAVE)와 같은 이동 통신 네트워크를 이용하여 데이터 송수신을 수행 할 수 있다. 일 실시예에서, 데이터 통신 모듈은 서버로부터 교통 정보, 도로 정보(예를 들어, 어린이 보 호 구역, 고속 도로, 일반 도로, 지방 국도 등), 또는 안전 속도 정보를 수신할 수 있다. 다른 실시예에서, 데 이터 통신 모듈은 서버로부터 애플리케이션의 실행을 위하여 필요한 데이터 또는 애플리케이션을 업데이 트하기 위한 데이터 등을 수신할 수도 있다. 프로세서는 메모리에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), 애플리케이션 프로세서(Application Processor), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에서, 프로세서는 인공 지능(Artificial Intelligence; AI) 학습을 수행하는 전용 하드웨어 칩으로 구성될 수도 있다. 프로세서는 하나 또는 그 이상의 복수 개의 하드웨어로 구성될 수 있다. 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 롬(ROM, Read-Only Memory), 및 EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory) 중 적어도 하나를 포함하는 비휘발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모리를 포함할 수 있다. 메모리에는 프로세서가 판독할 수 있는 명령어들(instructions), 데이터 구조, 및 프로그램 코드 (program code)가 저장될 수 있다. 이하의 실시예에서, 프로세서는 메모리에 저장된 프로그램의 명 령어들 또는 프로그램 코드들을 실행함으로써 구현될 수 있다. 프로세서는 CAN 통신 모듈을 통해 차량의 주행 정보 및 탑승자 정보 중 적어도 하나를 획득할 수 있다. 일 실시예에서, 프로세서는 차량의 현재 위치, 주행 중인 도로, 또는 주행 속도 중 적어도 하나를 포함하는 주행 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 CAN 통신 모듈로부터 차량 내 운전석, 조수석, 및 뒷좌석 각각에 탑승한 탑승자 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 탑 승자가 전자 장치에 로그인하는 과정에서 입력한 사용자 식별 정보(user id)에 기초하여 탑승자 정보를 획득할 수도 있다. 프로세서는 디스플레이부 상에 디스플레이되고 있는 기능 UI(111, 112, 113, 114, 도 1 참조)에 관한 정보를 포함하는 디스플레이 출력 정보를 획득할 수 있다. 프로세서는 획득된 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나에 기초하여, 차량 또는 전자 장치가 제공하는 적어도 하나의 기능을 실행하기 위한 음성 명령어들을 간소화 한 적어도 하나의 단축 명령어를 생성할 수 있다. 여기서, '단축 명령어'는 차량 또는 전자 장치의 기능 및/또는 동작을 실행하기 위하여 탑승자로부터 수신되는 음성 명령어 중 키워드만을 추출하여 생성되는 간소화 된 명령어를 의미한다. 단축 명령어는 차량 또는 전자 장치의 애플리케이션에 의해 제공되는 하나 또는 그 이상의 기능에 각각 대응되는 하나 또는 그 이상의 복수 개일 수 있다. 일 실시예에서, 프로세서는 음 성 명령어 중 기능을 실행하기 위하여 필수적인 핵심 명령어들만을 포함하도록 간소화함으로써, 단축 명령어를 생성할 수 있다. 예를 들어, 네비게이션 애플리케이션에서 목적지까지 이동 경로를 결정하기 위한 음성 명령어 가 \"목적지까지 이동 경로 알려줘~\" 인 경우, 프로세서는 음성 명령어 중 기능을 실행하기 위한 핵심 명 령어인 '목적지'를 단축 명령어로 생성할 수 있다. 다른 예를 들어, 음악 애플리케이션에서 다음 곡을 플레이하 기 위한 음성 명령어가 \"다음 곡 틀어줘~\"인 경우, 프로세서는 음성 명령어 중 기능을 실행하기 위한 핵심 명령어인 '다음곡'을 단축 명령어로 생성할 수 있다. 프로세서는 디스플레이 출력 정보로부터 기능 UI가 나타내는 기능을 인식하고, 인식된 기능을 자연어로 변환함으로써 기능 UI에 각각 대응되는 적어도 하나의 단축 명령어를 생성할 수 있다. 일 실시예에서, 프로세서 는 디스플레이부 상에서 디스플레이되고 있는 적어도 하나의 기능과 관련된 그래픽 UI 각각의 기능 을 식별할 수 있다. 예를 들어, 프로세서는 애플리케이션을 구성하는 소프트웨어의 플랫폼 레이어 (platform layer)에서 UI Framework의 resource name을 검색함으로써, 그래픽 UI 각각에 관한 기능 정보를 획 득하고, 획득된 기능 정보를 자연어로 변환하여 적어도 하나의 단축 명령어를 생성할 수 있다. 다른 예를 들어, 프로세서는 애플리케이션의 API(Application Programmable Interface)를 분석함으로써, 그래픽 UI 각각 에 대응되는 기능에 관한 정보를 획득하고, 기능 정보를 자연어로 변환하여 적어도 하나의 단축 명령어를 생성 할 수 있다. 일 실시예에서, 프로세서는 애플리케이션의 실행 화면에 포함되는 위젯 또는 아이콘을 인식 하고, 인식된 위젯 또는 아이콘에 관한 적어도 하나의 단축 명령어를 생성할 수도 있다. 그러나, 이에 한정되는 것은 아니고, 프로세서는 이미지 프로세싱(image processing)을 통해, 디스플레이 부 상에 디스플레이되는 아이콘 또는 위젯을 포함하는 그래픽 UI가 나타내는 기능 정보를 식별하고, 식별 된 기능 정보를 자연어로 변환하여 적어도 하나의 단축 명령어를 생성할 수도 있다. 프로세서는 탑승자가 자주 사용하는 애플리케이션 또는 애플리케이션의 기능을 실행하기 위한 명령어들을 간소화함으로써, 단축 명령어를 생성할 수 있다. 일 실시예에서, 프로세서는 로그인 과정을 통해 획득한 탑승자의 식별 정보(user id)로부터 탑승자의 사용 이력 정보를 획득하고, 탑승자의 사용자 식별 정보 및 사용 이력 정보에 기초하여 탑승자가 자주 사용하는 애플리케이션 정보를 획득할 수 있다. 프로세서는 탑승자 가 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어들로부터 핵심 키워드들만을 추출하여, 적어도 하나의 단축 명령어를 생성할 수 있다. 프로세서가 탑승자의 사용 이력 정보에 기초하여 자주 사용하는 애플리케이션과 관련된 적어도 하나의 단축 명령어를 생성하는 실시예에 대해서는 도 6에서 상세하게 설명하기 로 한다. 그러나, 이에 한정되는 것은 아니고, 단축 명령어는 애플리케이션의 기능에 대하여 미리 설정되어 있거나, 또는 사용자로부터 수신된 입력에 의해 결정될 수 있다. 적어도 하나의 단축 명령어는 단축 명령어 데이터베이스에 저장될 수 있다. 일 실시예에서, 프로세서 는 적어도 하나의 단축 명령어를 관련되는 적어도 하나의 기능 또는 적어도 하나의 애플리케이션 정보와 함께 리스트 형태로 단축 명령어 데이터베이스에 저장할 수 있다. 프로세서는 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이부 상에 디스플레이할 수 있다. '음성 명령어 가이드 UI'는 차량 또는 전자 장치의 애플리케이션을 통해 제공되는 기능을 실행하기 위하여 탑승자의 발화를 유도하는 음성 명령어를 문자, 숫자, 또는 기호로 표시하는 UI이다. 일 실시예에서, 음성 명령어 가이드 UI는 그래픽 UI(Graphic User Interface)일 수 있다. 음성 명령어 가이드 UI는 하나 또는 그 이상의 복수로 구성될 수 있다. 프로세서는 적어도 하나의 음성 명령어 가이드 UI 각각을 대응되는 적어도 하나의 기능 UI의 위치에 인접 한 영역에 디스플레이할 수 있다. 일 실시예에서, 프로세서는 적어도 하나의 기능 UI가 디스플레이되는 위치로부터 기 설정된 거리만큼 이격된 위치에 관련되는 적어도 하나의 음성 명령어 가이드 UI를 배치하여 디스 플레이할 수 있다. 예를 들어, 음악 애플리케이션의 실행을 위한 제1 UI가 디스플레이되는 위치로부터 기 설정 된 거리만큼 이격된 위치에 '음악'이라는 문자로 구성되는 제1 음성 명령어 가이드 UI가 디스플레이될 수 있다. 또한, 이전 곡을 플레이하기 위한 버튼형 그래픽 UI인 제2 UI와 기 설정된 거리만큼 이격된 위치에는 '이전곡' 이라는 문자로 구성되는 제2 음성 명령어 가이드 UI가 디스플레이될 수 있다. 프로세서가 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 구체적인 실시예에 대해서는 도 5에서 상세하게 설명하기로 한다. 프로세서는 적어도 하나의 음성 명령어 가이드 UI 각각에 가중치를 부여하고, 가중치에 기초하여 디스플 레이되는 음성 명령어 가이드 UI의 개수, 위치, 및 크기 중 적어도 하나를 결정할 수 있다. 일 실시예에서, 프 로세서는 차량의 주행 정보, 탑승자 정보, 디스플레이 출력 정보, 및 안전 속도 중 적어도 하나에 기초하 여 적어도 하나의 음성 명령어 가이드 UI에 관한 가중치를 결정할 수 있다. 여기서, '안전 속도'는 차량의 주행 정보에 기초하여 결정될 있다. 일 실시예에서, 프로세서는 차량의 주 행 정보로부터 차량의 현재 위치, 주행 중인 도로 정보, 또는 주행 속도 중 적어도 하나의 정보를 획득하고, 획 득된 정보에 기초하여 안전 속도를 결정할 수 있다. 일 실시예에서, 안전 속도는 주행 중인 도로의 특성 정보,예를 들어 어린이 보호 구역, 고속 도로, 또는 지방 도로에 따라 정해진 제한 속도에 의해 결정될 수 있다. 안 전 속도는 제한 속도 보다 기 설정된 값 만큼 느린 속도일 수 있다. 예를 들어, 어린이 보호 구역 내의 제한 속 도가 30km/h인 경우, 안전 속도는 25km/h이고, 고속 도로의 제한 속도가 110km/h인 경우 안전 속도는 100km/h로 결정될 수 있다. 그러나, 이에 한정되는 것은 아니고, 안전 속도는 도로에 따라 기 설정된 제한 속도와 동일한 속도일 수 있다. 프로세서는 차량의 주행 속도와 안전 속도를 비교하고, 비교 결과에 따라 적어도 하나의 음성 명령어 가 이드 UI의 가중치를 다르게 결정할 수 있다. 일 실시예에서, 주행 속도가 안전 속도를 초과하는 경우, 프로세서 는 운전자가 안전을 위하여 운전에 집중해야 하는 상황으로 판단하고, 주행과 관련된 기능을 실행하기 위 한 적어도 하나의 음성 명령어 가이드 UI의 가중치를 높게 조절하고, 주행이 아닌 편의 기능, 예를 들어, 음악 재생과 관련된 기능을 실행하기 위한 적어도 하나의 음성 명령어 가이드 UI의 가중치는 낮게 조절할 수 있다. 일 실시예에서, 프로세서는 탑승자의 사용 이력 정보에 기초하여, 자주 사용하는 애플리케이션의 기능과 관련된 음성 명령어 가이드 UI의 가중치를 다른 음성 명령어 가이드 UI 보다 높게 설정할 수 있다. 일 실시예에서, 프로세서는 디스플레이부 상에 디스플레이되고 있는 아이콘 또는 위젯을 통해 실행 되는 애플리케이션과 관련된 음성 명령어 가이드 UI의 가중치를 디스플레이되지 않은 다른 애플리케이션과 관련 된 음성 명령어 가이드 UI의 가중치 보다 높게 설정할 수 있다. 일 실시예에서, 프로세서는 가중치가 기 설정된 임계치 보다 높은 적어도 하나의 음성 명령어 가이드 UI 만을 디스플레이할 수 있다. 다른 실시예에서, 프로세서는 가중치가 높은 적어도 하나의 음성 명령어 가 이드 UI를 가중치가 상대적으로 낮은 적어도 하나의 음성 명령어 가이드 UI 보다 큰 크기로 디스플레이할 수 있 다. 프로세서가 차량의 주행 속도와 안전 속도를 비교하여 적어도 하나의 음성 명령어 가이드 UI의 가중 치를 조절하고, 조절된 가중치에 기초하여 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 구체적인 실 시예에 대해서는 도 8 내지 도 10에서 상세하게 설명하기로 한다. 프로세서는 차량이 주행 중에만 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하고, 차량이 정차 또 는 주차되어 있는 경우에는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하지 않을 수 있다. 일 실시예에 서, 프로세서는 차량 센서 모듈(200, 도 3 참조)의 속도 센서(220, 도 3 참조)로부터 차량의 속도 정보를 획득하고, 차량의 속도가 0km/h이거나 기 설정된 임계 속도(예를 들어, 5km/h) 미만인 경우 차량이 주정차 중이 라고 판단하고, 판단 결과에 따라 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하지 않을 수 있다. 그러 나, 이에 한정되는 것은 아니고, 프로세서는 차량의 속도와 관계없이 적어도 하나의 음성 명령어 가이드 UI를 디스플레이할 수도 있다. 애플리케이션에서 오류가 발생되거나, 업데이트를 요하는 상황이거나, 또는 인근 도로에서 사고가 발생하는 등 의 이벤트 발생 시 디스플레이부 상에 경고 메시지가 표시될 수 있다. 경고 메시지는 팝 업 메시지(pop- up message) 형태로 기능 UI 또는 적어도 하나의 음성 명령어 가이드 UI를 오버레이하여 디스플레이될 수 있다. 이 경우, 탑승자는 디스플레이부 상에 표시되는 기능 UI 및 적어도 하나의 음성 명령어 가이드 UI를 볼 수 없게 되는 문제점이 발생된다. 프로세서는 팝 업 메시지를 디스플레이부 상에서 보이지 않도록 제거하는 기능과 관련된 음성 명령어 가이드 UI의 가중치를 높일 수 있다. 일 실시예에서, 프로세서는 팝 업 메시지를 제거하는 기능을 실행하기 위한 음성 명령어 가이드 UI의 가중치를 나머지 적어도 하나의 음성 명 령어 가이드 UI의 가중치 보다 높도록 최대값으로 설정할 수 있다. 프로세서가 팝 업 메시지를 제거하는 음성 명령어 가이드 UI의 가중치를 설정하는 구체적인 실시예는 도 11에서 상세하게 설명하기로 한다. 프로세서는 탑승자의 위치와 디스플레이부 사이의 거리에 기초하여, 디스플레이부 상에서 적 어도 하나의 음성 명령어 가이드 UI가 디스플레이되는 영역을 결정할 수 있다. 일 실시예에서, 프로세서 는 CAN 통신 모듈로부터 탑승자의 위치 정보를 획득하거나, 또는 전자 장치에 포함되는 적외선 센 서를 통해 탑승자의 위치 정보를 획득할 수 있다. 프로세서는 탑승자의 위치 정보를 이용하여, 탑승자와 디스플레이부 사이의 거리를 측정할 수 있다. 일 실시예에서, 디스플레이부는 복수의 영역으로 구 분되고, 프로세서는 복수의 영역 중 탑승자와의 거리가 상대적으로 먼 영역에만 적어도 하나의 음성 명령 어 가이드 UI를 디스플레이할 수 있다. 프로세서가 탑승자와 디스플레이부 사이의 거리에 기초하여 디스플레이부의 일부 영역에만 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 구체적인 실시예 에 대해서는 도 12에서 상세하게 설명하기로 한다. 프로세서는 마이크로폰을 통해 탑승자에 의해 발화된 음성 입력을 수신하고, 수신된 음성 입력을 디스플레이되는 적어도 하나의 음성 명령어 가이드 UI와 비교함으로써, 음성 입력과 매칭되는 음성 명령어 가이 드 UI를 식별할 수 있다. 프로세서는 식별된 음성 명령어 가이드 UI에 대응되는 단축 명령어를 식별하고, 단축 명령어에 해당되는 기능을 실행하도록 관련 장치들을 제어할 수 있다. 일 실시예에서, 프로세서는 음성 입력과 매칭되는 음성 명령어 가이드 UI를 식별하지 못한 경우, 서버에 음성 입력에 관한 데이터를 전송할 수 있다. 프로세서가 음성 인식 기능을 수행하는 구체적인 실시예에 대해서는 도 14에서 상세하게 설명하 기로 한다. 단축 명령어 데이터베이스는 적어도 하나의 단축 명령어들을 저장하는 저장소이다. 단축 명령어 데이터베 이스는 비휘발성 메모리로 구성될 수 있다. 비휘발성 메모리(Non-volatile memory)는 전원이 공급되지 않 은 상태에서도 정보를 저장 및 유지하고, 전원이 공급되면 다시 저장된 정보를 사용할 수 있는 기억 매체를 의 미한다. 비휘발성 메모리는 예를 들어, 플래시 메모리(flash memory), 하드디스크(hard disk), SSD(Solid State Drive), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 자기 메모리, 자기 디스크, 또는 광디스크 중 적어도 하나를 포함할 수 있다. 도 2에서 단축 명령어 데이터베이스는 전자 장치 내에 포함되는 구성 요소로 도시되었지만, 이에 한정되는 것은 아니다. 일 실시예에서, 단축 명령어 데이터베이스는 전자 장치에 포함되지 않은 외 장 메모리 형태(예를 들어, SD 또는 XD 메모리 등)로 구현되거나 또는 데이터 통신 모듈을 통해 유무선 네트워크로 연결되는 웹 기반 저장 매체로 구현될 수도 있다. 입력부는 차량 내 탑승자(운전자, 조수석 탑승자, 및 뒷좌석 탑승자 중 적어도 1명의 탑승자)로부터 입력 을 수신하도록 구성된다. 입력부는 음성 인식 기능 입력부 및 마이크로폰을 포함할 수 있다. 음성 인식 기능 입력부는 음성 인식 기능을 실행하는 사용자 입력을 수신하도록 구성된다. 일 실시예에서, 음성 인식 기능 입력부는 하드웨어 버튼으로써, 차량의 스티어링 휠에 배치되거나 또는 대시 보드(dashboard) 상에 배치될 수 있다. 그러나, 이에 한정되는 것은 아니고, 음성 인식 기능 입력부는 디 스플레이부 상에 디스플레이되는 그래픽 UI일 수도 있다. 또한, 실시예에 따라, 음성 인식 기능 입력부는 전자 장치에 포함되지 않을 수 있다. 이 경우, 마 이크로폰을 통해 수신된 웨이크 업 음성에 기초하여 음성 인식 기능이 실행될 수 있다. 웨이크 업 음성은 전자 장치가 음성 인식 기능을 수행하도록 웨이크 업하는 음성 명령어로서, 예를 들어, '하이 빅스비' 또 는 '오케이 구글' 등을 포함할 수 있다. 마이크로폰은 탑승자에 의해 발화된 음성 입력을 수신할 수 있다. 일 실시예에서, 마이크로폰은 수 신된 음성 입력을 음향 신호로 변환하고, 음향 신호로부터 노이즈(예를 들어, 비음성 성분)를 제거하여 음성 신 호를 획득할 수 있다. 마이크로폰은 음성 신호를 프로세서에 제공할 수 있다. 출력부는 디스플레이부 및 스피커를 포함할 수 있다. 디스플레이부는 애플리케이션의 실행 화면, 기능 UI, 및 음성 명령어 가이드 UI를 디스플레이할 수 있다. 디스플레이부는 CID(Center Information Display)일 수 있으나, 이에 한정되는 것은 아니다. 디스플레이 부는 예를 들어, 네비게이션 장치, 계기판 디스플레이, HUD(Head Up Display), 또는 조수석 디스플레이 중 어느 하나로 구성될 수 있다. 디스플레이부는 예를 들어, 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이 (thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode display), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 또는 전기영동 디스플레이 (electrophoretic display) 중 적어도 하나로 구성되는 스크린을 포함할 수 있다. 일 실시예에서, 디스플레이부는 복수의 디스플레이들을 포함할 수 있다. 이때, 복수의 디스플레이들은 차 량에 포함되는 복수의 탑승석들에 대응되도록 위치할 수 있다. 일 실시예에서, 프로세서는 복수의 디스플 레이들 중 탑승자에 의해 음성 인식 기능이 활성화된 디스플레이 상에만 적어도 하나의 음성 명령어 가이드 UI 를 디스플레이할 수 있다. 프로세서가 복수 개의 디스플레이부 중 특정 디스플레이부에만 음성 명 령어 가이드 UI를 디스플레이하는 실시예에 대해서는 도 7에서 상세하게 설명하기로 한다. 스피커는 오디오 신호를 출력할 수 있다. 스피커는 프로세서의 제어에 의해 기능의 수행과 관련된 알림 메시지를 출력할 수 있다. 그러나, 이에 한정되는 것은 아니고, 스피커는 효과음, 벨소리, 멜로디, 음악, 또는 노래 중 적어도 하나를 포함하는 오디오 신호를 출력할 수도 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치 및 차량 센서 모듈을 도시한 블록도이다. 차량 센서 모듈은 차량에 탑재되고, 차량의 위치, 속도, 및 탑승자를 모니터링하고, 차량의 주행 정보 및 탑승자 정보를 전자 장치에 제공할 수 있다. 차량 센서 모듈은 차량의 주행 정보 및 탑승자 정보를 CAN 통신 모듈을 통해 전자 장치에 전송할 수 있다. 차량 센서 모듈은 전자 장치와 CAN(Controller Area Network) 통신을 수행할 수 있다. 도 3을 참조하면, 차량 센서 모듈은 GPS 모듈, 속도 센서, 시트 센서, 및 적외선 센서 를 포함할 수 있다. 차량 센서 모듈은 전자 장치와는 별개의 구성 요소이다. 그러나, 이에 한 정되는 것은 아니고, 차량 센서 모듈에 포함되는 적어도 하나의 구성 요소는 전자 장치 내에 포함될 수 있다. 예를 들어, 차량 센서 모듈에 포함되는 GPS 모듈 또는 적외선 센서는 전자 장치(100 0)에 포함될 수도 있다. GPS 모듈은 GPS 신호를 수신하고, 획득된 GPS 신호에 기초하여 차량의 현재 위치에 관한 정보를 획득하도 록 구성된다. 일 실시예에서, GPS 모듈은 지구 상공에 위치한 적어도 하나의 GPS 위성으로부터 항법 메시 지를 수신하여 차량의 위치 정보를 획득할 수 있다. 구체적으로, GPS 모듈은 GPS 위성에서 발사되는 전파 의 지연시간을 계측하는 방법으로 차량의 현재 위치 좌표를 획득할 수 있다. 일 실시예에서, GPS 모듈은 차량이 현재 주행 중인 도로 정보를 획득할 수도 있다. 프로세서는 CAN 통신 모듈을 통해 GPS 모듈로부터 차량의 현재 위치 정보를 획득할 수 있다. 속도 센서는 차량의 주행 속도를 감지하고, 주행 속도 정보를 전자 장치에 전송할 수 있다. 시트 센서는 차량의 시트 쿠션 내에 배치되고, 시트 쿠션으로부터 가해지는 압력값을 측정함으로써, 탑승 자의 착좌 여부를 인식할 수 있다. 시트 센서는 예를 들어, 압력 센서로 구성될 수 있다. 일 실시예에서, 시트 센서는 시트 쿠션에 가해지는 압력값이 기 설정된 임계 압력을 초과하는 경우, 탑승자가 착좌한 것으 로 인식할 수 있다. 또한, 시트 센서는 시트 쿠션에 가해지는 압력값이 기 설정된 임계 압력 이하인 경우, 탑승자가 탑승하지 않은 상태로 인식할 수 있다. 시트 센서는 탑승자의 탑승 여부 인식 결과에 관한 정보 를 프로세서에 제공할 수 있다. 프로세서는 시트 센서로부터 수신된 탑승자 정보에 기초하여, 운전석, 조수석, 및 뒷좌석 중 어느 하나에 관한 탑승 여부에 관한 정보를 획득할 수 있다. 적외선 센서는 탑승자로부터 반사되는 적외선을 수신함으로써 탑승자의 위치를 인식할 수 있다. 적외선 센 서는 적외선 신호의 강도, 송출 각도, 및 송출 위치에 관한 정보를 프로세서에 제공할 수 있다. 프 로세서는 적외선 센서로부터 획득한 정보에 기초하여 탑승자의 위치 정보를 획득할 수 있다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 단계 S410에서, 전자 장치는 차량 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나를 획득한다. 일 실시예에서, 전자 장치는 차량 센서 모듈(200, 도 3 참조)로부터 차량의 현재 위치, 주행 중인 도로 정보, 속도 정보, 및 탑승자의 탑승 여부에 관한 정보를 획득할 수 있다. 일 실시예에서, 전자 장치 는 서버로부터 교통 정보, 도로 정보(예를 들어, 어린이 보호 구역, 고속 도로, 일반 도로, 지방 국도 등), 또는 안전 속도에 관한 정보를 수신할 수 있다. 전자 장치는 디스플레이부(1610, 도 2 참조) 상에 디스플레이되고 있는 애플리케이션의 실행 화면 및 기 능 UI에 관한 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 디스플레이부 상에서 디스플레 이되고 있는 적어도 하나의 기능과 관련된 그래픽 UI 각각의 기능을 식별할 수 있다. 예를 들어, 전자 장치 는 애플리케이션을 구성하는 소프트웨어의 플랫폼 레이어(platform layer)에서 UI Framework의 resource name을 검색함으로써, 그래픽 UI 각각에 관한 기능 정보를 획득할 수 있다. 다른 실시예에서, 전자 장치 는 애플리케이션의 API(Application Programmable Interface)를 분석함으로써, 그래픽 UI 각각에 대응되는 기 능에 관한 정보를 획득할 수 있다. 단계 S420에서, 전자 장치는 적어도 하나의 정보에 기초하여, 차량 또는 전자 장치가 제공하는 적어도 하 나의 기능을 실행하기 위한 음성 명령어들을 간소화한 적어도 하나의 단축 명령어를 생성한다. 일 실시예에서, 전자 장치는 음성 명령어 중 기능을 실행하기 위하여 필수적인 핵심 명령어들만을 포함하도록 간소화하여단축 명령어를 생성할 수 있다. 일 실시예에서, 전자 장치는 디스플레이 출력 정보로부터 기능 UI가 나타내는 기능을 인식하고, 기능을 자연어로 변환함으로써 기능 UI 각각에 대응되는 적어도 하나의 단축 명령어를 생성할 수 있다. 일 실시예에서, 전자 장치는 탑승자가 자주 사용하는 애플리케이션 또는 애플리케이션의 기능을 실행하기 위한 명령어들을 간소화함으로써, 단축 명령어를 생성할 수 있다. 일 실시예에서, 전자 장치는 로그인 과 정을 통해 획득한 탑승자의 식별 정보(user id)로부터 탑승자의 사용 이력 정보를 획득하고, 탑승자의 사용자 식별 정보 및 사용 이력 정보에 기초하여 탑승자가 자주 사용하는 애플리케이션 정보를 획득할 수 있다. 전자 장치는 탑승자가 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어들로부터 핵심 키워드들만을 추출하여, 적어도 하나의 단축 명령어를 생성할 수 있다. 일 실시예에서, 전자 장치는 생성된 적어도 하나의 단축 명령어들을 리스트 형태로 단축 명령어 데이터베 이스에 저장할 수 있다. 단계 S430에서, 전자 장치는 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이한다. '음성 명령어 가이드 UI'는 차량 또는 전자 장치의 애플리케이션을 통해 제공되는 기능을 실행하기 위하여 탑승자의 발화를 유도하는 음성 명령어를 문자, 숫자, 또는 기호로 표시 하는 UI이다. 일 실시예에서, 음성 명령어 가이드 UI는 그래픽 UI(Graphic User Interface)일 수 있다. 전자 장치는 적어도 하나의 음성 명령어 가이드 UI 각각을 대응되는 적어도 하나의 기능 UI의 위치에 인 접한 영역에 디스플레이할 수 있다. 전자 장치는 적어도 하나의 음성 명령어 가이드 UI 각각에 가중치를 부여하고, 가중치에 기초하여 디스플 레이되는 음성 명령어 가이드 UI의 표시 여부, 표시 위치, 및 표시 크기 중 적어도 하나를 결정할 수 있다. 일 실시예에서, 전자 장치는 차량의 주행 정보, 탑승자 정보, 디스플레이 출력 정보, 및 안전 속도 중 적어 도 하나에 기초하여 적어도 하나의 음성 명령어 가이드 UI에 관한 가중치를 결정할 수 있다. 전자 장치는 차량의 주행 속도와 안전 속도를 비교하고, 비교 결과에 따라 적어도 하나의 음성 명령어 가 이드 UI의 가중치를 다르게 결정할 수 있다. 일 실시예에서, 주행 속도가 안전 속도를 초과하는 경우, 전자 장 치는 운전자가 안전을 위하여 운전에 집중해야 하는 상황으로 판단하고, 주행과 관련된 기능을 실행하기 위한 적어도 하나의 음성 명령어 가이드 UI의 가중치를 높게 조절하고, 주행이 아닌 편의 기능, 예를 들어, 음 악 재생과 관련된 기능을 실행하기 위한 적어도 하나의 음성 명령어 가이드 UI의 가중치는 낮게 조절할 수 있다. 일 실시예에서, 전자 장치는 가중치가 기 설정된 임계치 보다 높은 적어도 하나의 음성 명령어 가이드 UI 만을 디스플레이할 수 있다. 다른 실시예에서, 전자 장치는 가중치가 높은 적어도 하나의 음성 명령어 가 이드 UI의 크기를 가중치가 상대적으로 낮은 적어도 하나의 음성 명령어 가이드 UI 크기 보다 크게 디스플레이 할 수 있다. 도 5는 본 개시의 전자 장치가 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 도면이다. 도 5를 참조하면, 전자 장치는 디스플레이부 상에 애플리케이션의 기능을 실행하기 위한 음성 명령 어의 발화를 유도하는 음성 명령어 가이드 UI(501, 502, 503, 504, 505) 및 애플리케이션의 실행 화면과 기능을 나타내는 기능 UI(511, 512, 513, 514, 515)를 디스플레이할 수 있다. 도 5에 도시된 실시예에서, 음성 명령어 가이드 UI(501, 502, 503, 504, 505) 및 기능 UI(511, 512, 513, 514, 515)는 복수로 도시되었으나, 이에 한정 되는 것은 아니다. 디스플레이부 상에 디스플레이되는 음성 명령어 가이드 UI(501, 502, 503, 504, 505) 및 기능 UI(511, 512, 513, 514, 515)는 각각 1개일 수도 있다. 전자 장치는 디스플레이부의 출력 정보에 기초하여 단축 명령어를 생성할 수 있다. 일 실시예에서, 전자 장치는 디스플레이되는 복수의 기능 UI(511, 512, 513, 514, 515) 각각이 나타내는 기능을 인식하고, 인식된 기능을 자연어로 변환함으로써 복수의 기능 UI(511, 512, 513, 514, 515)에 각각 대응되는 복 수의 단축 명령어를 생성할 수 있다. 일 실시예에서, 전자 장치의 프로세서(1200, 도 2 참조)는 애플리케 이션을 구성하는 소프트웨어의 플랫폼 레이어(platform layer)에서 UI Framework의 resource name을 검색함으 로써, 복수의 기능 UI(511, 512, 513, 514, 515) 각각에 관한 기능 정보를 획득하고, 획득된 기능 정보를 자연 어로 변환하여 복수의 단축 명령어를 생성할 수 있다. 다른 실시예에서, 프로세서는 애플리케이션의API(Application Programmable Interface)를 분석함으로써, 복수의 기능 UI(511, 512, 513, 514, 515) 각각에 대응되는 기능에 관한 정보를 획득하고, 기능 정보를 자연어로 변환하여 복수의 단축 명령어를 생성할 수 있다. 그러나, 이에 한정되는 것은 아니고, 프로세서는 이미지 프로세싱(image processing)을 통해, 디스플레이 부 상에 디스플레이되는 아이콘 또는 위젯을 포함하는 복수의 기능 UI(511, 512, 513, 514, 515)가 나타 내는 기능 정보를 식별하고, 식별된 기능 정보를 자연어로 변환하여 복수의 단축 명령어를 생성할 수도 있다. 도 5에 도시된 실시예에서, 프로세서는 제1 기능 UI에 관한 기능 정보가 '이전 곡 플레이'임을 인식 하고, 기능 정보를 자연어로 변환함으로써 '이전 곡'이라는 단축 명령어를 생성할 수 있다. 다른 예를 들어, 프 로세서는 '+'라는 기호로 표시된 제4 UI에 관한 기능 정보가 '에어컨의 설정 온도 올림'임을 인식하 고, 기능 정보를 자연어로 변환하고 기능을 나타내는 핵심 단어만을 추출하여 '온도 업'이라는 단축 명령어를 생성할 수 있다. 그러나, 이에 한정되는 것은 아니고, 단축 명령어는 복수의 기능 UI(511, 512, 513, 514, 515) 각각에 대하여 미리 설정되어 있거나, 또는 사용자로부터 수신된 입력에 의해 결정될 수 있다. 전자 장치는 생성된 복수의 단축 명령어를 문자, 숫자, 또는 기호를 이용하여 시각적으로 표시하는 복수 의 음성 명령어 가이드 UI(501, 502, 503, 504, 505)를 디스플레이할 수 있다. 일 실시예에서, 전자 장치 는 복수의 음성 명령어 가이드 UI(501, 502, 503, 504, 505)를 각각 대응되는 복수의 기능 UI(511, 512, 513, 514, 515)가 디스플레이되는 위치와 인접한 영역에 디스플레이할 수 있다. 예를 들어, 음악 애플리케이션 에서 이전 곡 플레이 기능의 실행을 위한 제1 기능 UI가 디스플레이되는 위치와 인접한 위치에는 '이전 곡'이라는 단축 명령어를 나타내는 문자로 구성되는 제1 음성 명령어 가이드 UI가 디스플레이될 수 있다. 마찬가지로, 음악 애플리케이션에서 플레이(또는 pause) 기능을 실행하기 위한 제2 기능 UI가 디스플레이 되는 위치와 인접한 위치에는 '플레이'라는 제2 음성 명령어 가이드 UI가, 현재 플레이되는 곡의 다음 곡 을 플레이하는 기능을 실행하기 위한 제3 기능 UI가 디스플레이되는 위치와 인접한 위치에는 '다음 곡'이 라는 제3 음성 명령어 가이드 UI가 디스플레이될 수 있다. 에어컨 애플리케이션에서도 마찬가지로, 에어컨 의 설정 온도를 올리는 기능을 실행하기 위한 제4 기능 UI가 디스플레이되는 위치와 인접한 위치에는 '온 도 업'이라는 문자로 구성된 제4 음성 명령어 가이드 UI가, 에어컨의 설정 온도를 낮추는 기능을 실행하기 위한 제5 기능 UI가 디스플레이되는 위치와 인접한 위치에는 '온도 다운'이라는 문자로 구성된 제5 음성 명령어 가이드 UI가 디스플레이될 수 있다. 도 5에 도시된 실시예에서, 전자 장치는 애플리케이션을 통해 제공되는 기능을 실행하기 위한 복수의 기 능 UI(511, 512, 513, 514, 515)를 디스플레이하고, 복수의 기능 UI(511, 512, 513, 514, 515)가 디스플레이되 는 위치와 인접한 위치에 대응되는 복수의 음성 명령어 가이드 UI(501, 502, 503, 504, 505)를 디스플레이함으 로써, 탑승자가 실행하고 싶은 기능에 관한 음성 명령어를 직관적으로 알 수 있게 하여 사용자 편의성을 향상시 킬 수 있다. 또한, 본 개시의 일 실시예에 따른 전자 장치는 음성 명령을 통해 기능을 실행하는 경우, 추 가적인 파라미터 정보를 필요로 하지 않고, 음성 명령어 가이드 UI(501, 502, 503, 504, 505)에 표시된 문자에 해당되는 발화를 수신하기만 하면 기능을 실행하므로, 음성 인식의 정확도를 향상시키고, 운전자의 집중력 분산 을 최소화할 수 있다. 도 6은 본 개시의 전자 장치가 사용자의 식별 정보에 따라 자주 사용하는 애플리케이션의 기능과 관련된 단축 명령어들을 생성하는 실시예를 도시한 도면이다. 도 6을 참조하면, 전자 장치는 로그인 과정을 통해 탑승자의 사용자 식별 정보를 획득할 수 있다. 일 실시예에서, 사용자 식별 정보는 탑승자의 user id 정보를 포함할 수 있다. 전자 장치는 사용자 식별 정보로부터 애플리케이션의 사용 이력 정보를 획득할 수 있다. 애플 리케이션 사용 이력 정보는 탑승자가 사용자 id로 로그인하여 과거 시점에 사용하였던 애플리케이션의 사 용 횟수에 관한 누적 정보일 수 있다. 전자 장치의 프로세서(1200, 도 2 참조)는 애플리케이션 사용 이력 정보로부터 탑승자가 자주 사용하는 애플리케이션의 정보를 획득할 수 있다. 도 6에 도시된 실시예의 애플 리케이션 사용 이력 정보를 참조하면, 'XXX'라는 user id로 로그인한 탑승자는 과거 시점으로부터 현재까 지 음악 애플리케이션을 50회 사용하였고, 네비게이션 애플리케이션을 40회 사용하였으며, 날씨 애플리케이션은 10회, 전화 애플리케이션은 2회, 문자 애플리케이션은 1회 사용하였음을 알 수 있다. 도 6에는 도시되지 않았지 만, 일 실시예에서 프로세서는 애플리케이션 사용 이력 정보로부터 복수의 애플리케이션 각각에 의해 제공되는 복수의 기능의 사용 빈도에 관한 정보를 획득할 수도 있다. 프로세서는 탑승자가 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어들로부터 핵심 키워드들 만을 추출하여, 단축 명령어들(620, 622)을 생성할 수 있다. 일 실시예에서, 프로세서는 복수의 애플리케 이션 중 사용 횟수가 기 설정된 임계 횟수를 초과하는 적어도 하나의 애플리케이션만을 식별할 수 있다. 예를 들어, 기 설정된 임계 횟수가 30회인 경우, 프로세서는 애플리케이션 사용 이력 정보에 포함되는 복 수의 애플리케이션 중 50회 사용된 음악 애플리케이션과 40회 사용된 네비게이션 애플리케이션을 식별할 수 있 다. 프로세서는 식별된 적어도 하나의 애플리케이션에 의해 실행되는 기능에 관한 단축 명령어들(620, 622)를 생성할 수 있다. 도 6에 도시된 실시예에서, 프로세서는 음악 애플리케이션과 관련된 단축 명령어 로서 '이전 곡', '플레이', '다음 곡', '볼륨 업', 및 '볼륨 다운'을 생성하고, 네비게이션 애플리케이션 과 관련되 단축 명령어로서 '검색', '목적지', '경유지', '줌 인', 및 '줌 아웃'을 생성할 수 있다. 프로세서는 생성된 단축 명령어를 시각적으로 표시할 수 있도록 문자, 숫자, 또는 기호로 구성된 음성 명 령어 가이드 UI를 생성할 수 있다. 프로세서는 음성 명령어 가이드 UI를 디스플레이할 수 있다. 디스플레이 화면에 현재 실행 가능한 모든 기능과 관련된 음성 명령어 가이드 UI를 디스플레이하는 경우 화면이 복잡해지고, 복수의 음성 명령어 가이드 UI로 인하여 운전자의 집중력이 분산되는 문제점이 발생될 수 있다. 도 6에 도시된 실시예에서, 전자 장치는 사용 이력 정보에 기초하여 탑승자(또는 운전자)가 자주 사용하는 애플리케이션의 기능들을 실행하기 위한 발화를 수신하는 음성 명령어 가이드 UI를 디스플레이하므로, 탑 승자(또는 운전자)에 특화되어 개인화된 UI를 제공하고, 집중력 분산을 최소화할 수 있는 효과가 있다. 도 7은 본 개시의 전자 장치가 복수의 디스플레이부(1610-1, 1610-2, 1610-3) 중 사용자에 의해 음성 인식 기능 이 활성화된 디스플레이부에 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 도면이다. 도 7을 참조하면, 전자 장치는 복수의 디스플레이부(1610-1, 1610-2, 1610-3)를 포함할 수 있다. 복수의 디스플레이들은 차량에 포함된 복수의 탑승석들에 대응하도록 위치될 수 있다. 도 7에 도시된 실시예에서, 제1 디스플레이부(1610-1)는 CID(Center Information Display)이고, 제2 디스플레 이부(1610-2)는 운전석의 등받이에 부착된 디스플레이이고, 제3 디스플레이부(1610-3)는 조수석 등받이에 부착 된 디스플레이일 수 있다. 제2 디스플레이부(1610-2)는 뒷좌석 탑승자 중 왼쪽 좌석에 탑승한 탑승자가 이용하 도록 할당되고, 제3 디스플레이부(1610-3)는 뒷좌석 탑승자 중 오른쪽 좌석에 탑승한 탑승자가 이용하도록 할당 될 수 있다. 전자 장치는 복수의 디스플레이부(1610-1, 1610-2, 1610-3) 중 음성 인식 기능을 활성화하는 사용자 입력 이 수신된 디스플레이부에만 음성 명령어 가이드 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치 는 운전자, 조수석 탑승자, 또는 뒷좌석 탑승자 중 적어도 하나의 탑승자로부터 음성 인식 기능을 활성화하기 위한 버튼 입력 또는 그래픽 UI를 터치하는 터치 입력을 수신할 수 있다. 전자 장치는 버튼 입력 또는 터 치 입력을 수신함에 따라 음성 인식 기능을 활성화하고, 음성 명령어 가이드 UI를 디스플레이할 수 있다. 그러 나, 이에 한정되는 것은 아니다. 다른 실시예에서, 전자 장치는 운전자, 조수석 탑승자, 또는 뒷좌석 탑 승자 중 적어도 하나의 탑승자로부터 음성 인식 기능을 활성화하기 위한 웨이크 업 음성을 수신하고, 웨이크 업 음성을 수신함에 따라 음성 명령어 가이드 UI를 디스플레이할 수 있다. 웨이크 업 음성은 예를 들어, '하이 빅 스비' 또는 '오케이 구글' 등을 포함할 수 있다. 도 7에 도시된 실시예에서, 전자 장치는 운전자와 2명의 뒷좌석 탑승자 중 왼쪽 뒷좌석 탑승자로부터 음 성 인식 기능을 활성화하는 사용자 입력을 수신하고, 제2 디스플레이부(1610-2)에 음성 명령어 가이드 UI 를 디스플레이할 수 있다. 음성 명령어 가이드 UI는 제2 디스플레이부(1610-2) 상에 디스플레이되는 애플 리케이션의 기능을 나타내는 기능 UI를 실행하기 위한 단축 명령어를 시각적으로 표시한 UI로서, 대응되는 기능 UI의 인접한 위치에 디스플레이될 수 있다. 상기에서, 전자 장치가 탑승자로부터 음성 인식 기능을 활성화하는 버튼 입력, 터치 입력 또는 웨이크 업 음성 입력을 수신하는 경우에만 디스플레이부 상에 음성 명령어 가이드 UI를 디스플레이하는 실시예를 설명하였 지만, 본 개시의 실시예가 전술한 바와 같이 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 운전석, 조수석, 및 뒷좌석 탑승석의 탑승 여부를 인식하고, 복수의 디스플레이부(1610-1, 1610-2, 1610-3) 중 탑승이 인식된 좌석에 할당되는 디스플레이부 상에 음성 명령어 가이드 UI를 디스플레이할 수 있다. 전자 장치는차량 센서 모듈(200, 도 3 참조)의 시트 센서(230, 도 3 참조)로부터 획득된 압력 측정값에 기초하여, 운전석, 조수석, 및 뒷좌석 중 적어도 하나의 좌석의 탑승 여부를 인식하고, 탑승이 인식된 좌석에 할당된 디스플레이부 상에 음성 명령어 가이드 UI를 디스플레이할 수 있다. 예를 들어, 운전석, 조수석, 및 뒷좌석 중 시트 센서 로부터 획득한 압력 측정값이 기 설정된 임계값을 초과하는 탑승석이 오른쪽 뒷좌석인 경우, 전자 장치 는 복수의 디스플레이부(1610-1, 1610-2, 1610-3) 중 오른쪽 뒷좌석에 할당되는 제3 디스플레이부(1610- 3) 상에 음성 명령어 가이드 UI를 디스플레이할 수 있다. 도 8은 본 개시의 전자 장치가 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 흐름도이다. 도 8을 참조하면, 전자 장치가 음성 명령어 가이드 UI에 가중치를 부여하고, 가중치에 따라 음성 명령어 가이드 UI의 개수, 위치, 및 크기를 조절하여 디스플레이하는 실시예가 도시된다. 도 8에 도시된 단계들 S820 내지 S840은 도 4에 도시된 단계 S430을 구체화한 단계들이다. 단계 S810에서, 전자 장치는 차량의 주행 정보에 기초하여 안전 속도를 결정한다. 일 실시예에서, 전자 장치는 차량 센서 모듈(200, 도 3 참조)의 GPS 모듈(210, 도 3 참조) 차량의 현재 위치 및 주행 도로에 관한 정보를 획득할 수 있다. 전자 장치는 차량이 현재 주행하고 있는 도로의 특성 정보, 예를 들어, 어 린이 보호 구역, 고속 도로, 또는 지방 도로에 관한 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 속도 센서(220, 도 3 참조)로부터 차량의 주행 속도에 관한 정보를 획득할 수 있다. 전자 장치는 획득된 차량의 현재 위치, 주행 도로 특성, 및 주행 속도에 관한 정보에 기초하여 안전 속도 를 결정할 수 있다. 일 실시예에서, 전자 장치는 주행 도로 특성에 따른 제한 속도 보다 기 설정된 속도 만큼 느린 속도를 안전 속도로 결정할 수 있다. 예를 들어, 어린이 보호 구역 내의 제한 속도가 30km/h인 경우, 안전 속도는 25km/h이고, 고속 도로의 제한 속도가 110km/h인 경우 안전 속도는 100km/h로 결정될 수 있다. 그 러나, 이에 한정되는 것은 아니고, 전자 장치는 주행 중인 도로의 특성에 따라 기 설정된 제한 속도와 동 일한 속도를 안전 속도로 결정할 수도 있다. 단계 S820에서, 전자 장치는 차량의 주행 정보, 탑승자 정보, 디스플레이 출력 정보, 및 안전 속도 중 적 어도 하나에 기초하여, 적어도 하나의 음성 명령어 가이드 UI 각각의 가중치를 결정한다. 일 실시예에서, 전자 장치의 프로세서(1200, 도 2 참조)는 차량의 주행 속도와 안전 속도를 비교하고, 비 교 결과에 따라 적어도 하나의 음성 명령어 가이드 UI의 가중치를 다르게 결정할 수 있다. 일 실시예에서, 주행 속도가 안전 속도를 초과하는 경우, 프로세서는 운전자가 안전을 위하여 운전에 집중해야 하는 상황으로 판단하고, 주행과 관련된 기능을 실행하기 위한 적어도 하나의 음성 명령어 가이드 UI의 가중치를 높게 조절하 고, 주행이 아닌 편의 기능, 예를 들어, 음악 재생과 관련된 기능을 실행하기 위한 적어도 하나의 음성 명령어 가이드 UI의 가중치는 낮게 조절할 수 있다. 반대의 실시예에서, 주행 속도가 안전 속도 미만인 경우, 프로세서 는 상대적으로 운전에 집중을 덜 해도 되는 안전한 상황이라고 판단하고, 편의 기능을 실행하기 위한 적 어도 하나의 음성 명령어 가이드 UI의 가중치를 높게 조절할 수 있다. 일 실시예에서, 프로세서는 탑승자의 사용 이력 정보에 기초하여, 자주 사용하는 애플리케이션의 기능과 관련된 음성 명령어 가이드 UI의 가중치를 다른 음성 명령어 가이드 UI 보다 높게 설정할 수 있다. 일 실시예에서, 프로세서는 디스플레이부 상에 디스플레이되고 있는 아이콘 또는 위젯을 통해 실행 되는 애플리케이션과 관련된 음성 명령어 가이드 UI의 가중치를 디스플레이되지 않은 다른 애플리케이션과 관련 된 음성 명령어 가이드 UI 보다 높게 설정할 수 있다. 단계 S830에서, 전자 장치는 가중치에 기초하여 적어도 하나의 음성 명령어 가이드 UI가 표시되는 개수, 위치, 및 크기 중 적어도 하나를 결정한다. 일 실시예에서, 전자 장치는 가중치에 따라 적어도 하나의 음 성 명령어 가이드 UI의 표시 여부, 표시 위치, 및 표시 크기를 결정할 수 있다. 예를 들어, 전자 장치는 가중치가 기 설정된 임계치 보다 높은 적어도 하나의 음성 명령어 가이드 UI만을 디스플레이하고, 가중치가 임 계치 미만인 적어도 하나의 음성 명령어 가이드 UI는 디스플레이하지 않도록 결정할 수 있다. 예를 들어, 전자 장치는 가중치가 높은 적어도 하나의 음성 명령어 가이드 UI의 크기를 가중치가 상대적으로 낮은 적어도 하나의 음성 명령어 가이드 UI의 크기 보다 큰 크기로 결정할 수 있다. 단계 S840에서, 전자 장치는 전자 장치는 결정된 개수, 위치, 및 크기에 따라 적어도 하나의 음성 명령어 가이드 UI를 디스플레이할 수 있다. 일 실시예에서, 전자 장치는 가중치가 기 설정된 임계치 보다높은 적어도 하나의 음성 명령어 가이드 UI만을 디스플레이할 수 있다. 다른 실시예에서, 전자 장치는 가 중치가 높은 적어도 하나의 음성 명령어 가이드 UI의 크기를 가중치가 상대적으로 낮은 적어도 하나의 음성 명 령어 가이드 UI의 크기보다 크게 디스플레이할 수 있다. 도 9a는 본 개시의 전자 장치가 주행 속도에 따라 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도 시한 도면이다. 도 9a에 도시된 실시예는 차량의 주행 속도가 안전 속도 이하인 경우 전자 장치가 디스플 레이부 상에 복수의 음성 명령어 가이드 UI(901 내지 909)를 디스플레이하는 실시예이다. 도 9a를 참조하면, 전자 장치의 프로세서(1200, 도 2 참조)는 차량의 속도 센서(220, 도 3 참조)로부터 차량의 주행 속도에 관한 정보를 획득하고, 주행 속도를 안전 속도와 비교할 수 있다. 차량의 주행 속도가 안전 속도 이하인 것으로 판단된 경우, 프로세서는 디스플레이부 상에 출력되고 있는 모든 애플리케이션 에 제공되는 기능을 실행하기 위한 복수의 기능 UI 각각에 관한 복수의 음성 명령어 가이드 UI(910 내지 909)를 디스플레이할 수 있다. 차량의 주행 속도가 안전 속도 이하인 것으로 판단되는 경우, 프로세서는 복수의 음성 명령어 가이드 UI(901 내지 909)에 가중치를 부여하지 않거나, 또는 동일한 가중치를 부여하여 디스플레이할 수 있다. 그러나, 이에 한정되는 것은 아니고, 프로세서는 복수의 애플리케이션 중 차량의 주행과 관련이 없거나 상대적으 로 관련도가 낮은 편의 기능 애플리케이션, 예를 들어 음악 애플리케이션 또는 날씨 애플리케이션의 기능을 실 행하기 위한 음성 명령어 가이드 UI의 가중치를 높게 조절할 수 있다. 도 9a에 도시된 실시예에서, 프로세서 는 음악 애플리케이션의 실행과 관련되는 제4 음성 명령어 가이드 UI, 음악 애플리케이션에서 이전 곡을 플레이하는 기능의 실행과 관련되는 제5 음성 명령어 가이드 UI, 플레이 및 정지(pause) 기능의 실행 과 관련되는 제6 음성 명령어 가이드 UI, 및 다음 곡을 플레이하는 기능의 실행과 관련되는 제7 음성 명령 어 가이드 UI에 부여되는 가중치를 다른 음성 명령어 가이드 UI(901, 902, 903, 908, 909)의 가중치 보다 높은 값으로 조절할 수 있다. 도면에서는 동일한 크기로 도시되었지만, 일 실시에서 프로세서는 제4 음성 명령어 가이드 UI 내지 제7 음성 명령어 가이드 UI의 크기를 다른 음성 명령어 가이드 UI(901, 902, 903, 908, 909)의 크기 보다 크게 디스플레이할 수 있다. 도 9b는 본 개시의 전자 장치가 주행 속도에 따라 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도 시한 도면이다. 도 9b에 도시된 실시예는 차량의 주행 속도가 안전 속도를 초과하는 경우 전자 장치가 디 스플레이부 상에 복수의 음성 명령어 가이드 UI(901, 902, 903, 908, 909)를 디스플레이하는 실시예이다. 도 9b를 참조하면, 전자 장치의 프로세서(1200, 도 2 참조)는 차량의 주행 속도가 안전 속도를 초과하는 것으로 판단된 경우 디스플레이부 상에 출력되고 있는 모든 애플리케이션에 제공되는 기능을 실행하기 위 한 복수의 기능 UI 중 가중치가 높게 설정된 음성 명령어 가이드 UI(901, 902, 903, 908, 909)만을 디스플레이 할 수 있다. 일 실시예에서, 프로세서는 주행 속도가 안전 속도를 초과하는 것으로 판단되는 경우 차량의 주행 관련 기능을 실행하기 위한 음성 명령어 가이드 UI에 높은 가중치를 설정할 수 있다. 차량의 주행 관련 기 능을 실행하는 애플리케이션은 미리 정해져 있을 수 있다. 차량의 주행과 관련되는 기능을 실행하는 애플리케이 션은 예를 들어, 네비게이션 애플리케이션, 및 냉난방을 조절하는 HVAC(heating, ventilation, and air conditioning) 애플리케이션 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 프로세서는 차량의 주행 과 직접적인 관련이 없더라도 운전 중에 사용할 수 있는 애플리케이션, 예를 들어 전화 애플리케이션에도 높은 가중치를 설정할 수 있다. 도 9b에 도시된 실시예에서, 프로세서는 네비게이션 애플리케이션의 기능을 실 행하기 위한 제1 음성 명령어 가이드 UI 내지 제3 음성 명령어 가이드 UI 및 에어컨 애플리케이션의 기능을 실행하기 위한 제8 음성 명령어 가이드 UI, 제9 음성 명령어 가이드 UI를 디스플레이할 수 있 다. 프로세서는 가중치가 기 설정된 임계치 보다 낮은 제4 음성 명령어 가이드 UI 내지 제7 음성 명 령어 가이드 UI는 디스플레이하지 않을 수 있다. 도 10은 본 개시의 전자 장치가 차량의 주행 속도 및 안전 속도에 기초하여 음성 명령어 가이드 UI를 디 스플레이하는 실시예를 도시한 흐름도이다. 도 10을 참조하면, 전자 장치가 차량의 주행 속도 및 안전 속도에 기초하여 음성 명령어 가이드 UI에 가 중치를 부여하고, 가중치에 따라 음성 명령어 가이드 UI의 개수, 위치, 및 크기를 조절하여 디스플레이하는 실시예가 도시된다. 도 10에 도시된 단계들 S1030 내지 S1080은 도 4에 도시된 단계 S430을 구체화한 단계들이다. 단계 S1010에서, 전자 장치는 안전 속도를 결정한다. 일 실시예에서, 전자 장치는 차량의 현재 위 치, 주행 도로 특성, 및 주행 속도에 관한 정보에 기초하여 안전 속도를 결정할 수 있다. 단계 S1010은 도 8에 도시된 단계 S810과 동일하므로, 중복되는 설명은 생략한다. 단계 S1020에서, 전자 장치는 차량의 주행 속도와 안전 속도를 비교함으로써, 주행 속도가 안전 속도를 초과하는지 여부를 판단한다. 차량의 주행 속도가 안전 속도를 초과하는 것으로 판단되는 경우(단계 S1030), 전자 장치는 차량 주행과 관련되는 기능을 실행하기 위한 적어도 하나의 제1 단축 명령어의 가중치를 조절한다. 적어도 하나의 제1 단축 명령어는 차량의 주행과 관련되는 적어도 하나의 애플리케이션의 기능을 실행하기 위한 명령어이고, 적어도 하 나의 애플리케이션은 미리 정해져 있을 수 있다. 차량의 주행과 관련되는 기능을 실행하는 애플리케이션은 예를 들어, 네비게이션 애플리케이션, 및 냉난방을 조절하는 HVAC(heating, ventilation, and air conditioning) 애 플리케이션 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 전자 장치는 네비게이션 애플리케이션 및 HVAC 애플리케이션 각각에 의해 제공되는 기능을 실행하기 위한 적어도 하나의 제1 단축 명령어의 가중치를 높 게 조절할 수 있다. 일 실시예에서, 전자 장치는 차량의 주행과 직접적인 관련이 없더라도 운전 중에 사용할 수 있는 애플리 케이션, 예를 들어 전화 애플리케이션의 기능을 실행하기 위한 단축 명령어의 가중치를 높게 조절할 수 있다. 단계 S1040에서, 전자 장치는 조절된 가중치에 따라 적어도 하나의 제1 단축 명령어에 대응되는 적어도 하나의 제1 음성 명령어 가이드 UI의 개수, 크기, 및 위치를 결정한다. 일 실시예에서, 전자 장치는 적어 도 하나의 제1 단축 명령어를 문자, 숫자, 또는 기호를 이용하여 시각적으로 표시하는 적어도 하나의 제1 음성 명령어 가이드 UI를 디스플레이하거나, 적어도 하나의 제1 음성 명령어 가이드 UI 중에서도 가중치가 임계치를 초과하는 UI만을 디스플레이하도록 개수를 결정할 수 있다. 일 실시예에서, 전자 장치는 적어도 하나의 제1 음성 명령어 가이드 UI의 크기를 다른 음성 명령어 가이드 UI의 크기 보다 크게 디스플레이하도록 결정할 수 있다. 단계 S1050에서, 전자 장치는 결정된 개수, 크기, 및 위치에 따라 적어도 하나의 제1 음성 명령어 가이드 UI를 디스플레이한다. 차량의 주행 속도가 안전 속도 이하인 것으로 판단되는 경우(단계 S1060), 전자 장치는 편의 기능을 실행 하기 위한 적어도 하나의 제2 단축 명령어의 가중치를 조절한다. 적어도 하나의 제2 단축 명령어는 차량의 주행 과는 관련이 적고, 편의 기능을 실행하기 위한 명령어이다. 편의 기능 관련 애플리케이션은 미리 정해져 있을 수 있다. 차량의 편의 기능을 실행하는 애플리케이션은 예를 들어, 음악 애플리케이션 또는 날씨 애플리케이션 일 수 있다. 일 실시예에서, 전자 장치는 음악 애플리케이션 및 날씨 애플리케이션 각각에 의해 제공되는 기능을 실행하기 위한 적어도 하나의 제2 단축 명령어의 가중치를 높게 조절할 수 있다. 단계 S1070에서, 전자 장치는 조절된 가중치에 따라 적어도 하나의 제2 단축 명령어에 대응되는 적어도 하나의 제2 음성 명령어 가이드 UI의 개수, 크기, 및 위치를 결정한다. 일 실시예에서, 전자 장치는 적어 도 하나의 제2 단축 명령어를 문자, 숫자, 또는 기호를 이용하여 시각적으로 표시하는 적어도 하나의 제2 음성 명령어 가이드 UI를 디스플레이하거나, 적어도 하나의 제2 음성 명령어 가이드 UI 중에서도 가중치가 임계치를 초과하는 UI만을 디스플레이하도록 개수를 결정할 수 있다. 일 실시예에서, 전자 장치는 적어도 하나의 제2 음성 명령어 가이드 UI의 크기를 다른 음성 명령어 가이드 UI의 크기 보다 크게 디스플레이하도록 결정할 수 있다. 단계 S1080에서, 전자 장치는 결정된 개수, 크기, 및 위치에 따라 적어도 하나의 제2 음성 명령어 가이드 UI를 디스플레이한다. 도 11은 본 개시의 전자 장치가 팝 업 메시지와 관련된 음성 명령어 가이드 UI(1124, 1126)를 디스 플레이하는 실시예를 도시한 도면이다. 도 11을 참조하면, 전자 장치는 디스플레이부 상에 팝 업 메시지를 디스플레이할 수 있다. 일 실시예에서, 전자 장치의 프로세서(1200, 도 2 참조)는 실행 중인 애플리케이션에서 오류가 발생되거 나, 애플리케이션의 업데이트를 요하는 상황이거나, 또는 인근 도로에서 사고가 발생하는 등의 이벤트 발생을인식하고, 경고 메시지로서 팝 업 메시지를 디스플레이할 수 있다. 일 실시예에서, 팝 업 메시지는 디스플레이부 상에 출력되고 있는 애플리케이션의 실행 화면 및 UI들을 오버레이하여 디스플레이될 수 있 다. 도 11에 도시된 실시예에서, 팝 업 메시지는 전방 100m 지점의 사고 발생을 알리는 경고 메시지로서, 우회로 검색을 위한 제1 UI 및 팝 업 메시지를 닫기 위한 제2 UI를 포함할 수 있다. 프로세서는 팝 업 메시지를 디스플레이부 상에서 제거하는 기능과 관련된 기능 UI(1114, 1116)을 실행하기 위한 음성 명령어 가이드 UI(1124, 1126)를 디스플레이할 수 있다. 일 실시예에서, 프로세서 는 팝 업 메시지를 제거하기 위한 음성 명령어 가이드 UI(1124, 1126)의 가중치를 다른 음성 명령 어 가이드 UI에 부여된 가중치 보다 높게 설정할 수 있다. 예를 들어, 프로세서는 팝 업 메시지의 제거와 관련된 기능을 실행하기 위한 음성 명령어 가이드 UI(1124, 1126)의 가중치를 최대값으로 설정할 수 있 다. 예상하지 못한 상황에서 갑자기 팝 업 메시지가 디스플레이되는 경우, 네비게이션 화면을 가리기 때문에 운전자의 집중력을 분산시키고, 길을 잘못 갈 수 있는 등의 문제점이 발생된다. 또한, 팝 업 메시지가 디 스플레이부 상에 디스플레이되는 다른 기능을 사용하기 위한 UI를 가리기 때문에 사용자 편의성이 떨어질 수 있다. 도 11에 도시된 실시예에서, 전자 장치는 팝 업 메시지를 디스플레이부 상에서 제 거하기 위한 음성 명령어 가이드 UI(1124, 1126)에 부여되는 가중치를 높게 설정함으로써, 운전자가 쉽게 팝 업 메시지를 제거할 수 있도록 하는 효과를 제공한다. 도 12는 본 개시의 전자 장치가 디스플레이부 상의 일부 영역에 음성 명령어 가이드 UI(121 내지 127)를 디스플레이하는 실시예를 도시한 도면이다. 도 12를 참조하면, 전자 장치의 프로세서(1200, 도 2 참조)는 디스플레이부를 복수의 영역(1611, 1612, 1613)으로 구분하고, 탑승자의 위치와 디스플레이부의 복수의 영역(1611, 1612, 1613) 사이의 거리 에 기초하여 음성 명령어 가이드 UI(121 내지 127)를 디스플레이할 수 있다. 프로세서는 디스플레이부의 복수의 영역(1611, 1612, 1613)과 탑승자의 위치 사이의 거리를 측정할 수 있다. 일 실시예에서, 프로세서는 차량 센서 모듈(200, 도 3 참조)의 적외선 센서(2240, 도 3 참조)로 부터 탑승자의 위치 정보를 획득할 수 있다. 도 12에 도시된 실시예에서, 디스플레이부의 제1 영역(161 1)과 탑승자 사이의 거리는 제1 거리(d1)이고, 제2 영역과 탑승자 사이의 거리는 제2 거리(d2)이며, 제3 영역과 탑승자 사이의 거리는 제3 거리(d3)로 측정될 수 있다. 프로세서는 디스플레이부의 복수의 영역(1611, 1612, 1613) 중 측정된 탑승자 위치와의 거리가 기 설정된 기준값 이상인 영역에만 음성 명령어 가이드 UI(121 내지 127)을 디스플레이할 수 있다. 도 12에 도시된 실시예에서, 제2 거리(d2) 및 제3 거리(d3)는 기준값 이상으로 측정되고, 프로세서는 제2 영역 및 제3 영역에만 음성 명령어 가이드 UI(121 내지 127)을 디스플레이할 수 있다. 이 경우, 프로세서는 디스플레이부의 제1 영역에는 음성 명령어 가이드 UI를 디스플레이하지 않을 수 있다. 상기에서, 탑승자의 위치와 디스플레이부의 각 영역 간의 거리에 기초하여 음성 명령어 가이드 UI(121 내 지 127)를 디스플레이하는 실시예를 설명하였는데, 본 개시의 실시예가 전술한 바와 같이 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 차량 내의 공간을 운전석, 조수석, 및 뒷좌석 좌우 공간으로 각각 분할하고, 디스플레이부를 분할된 공간에 대응되도록 복수의 영역으로 구분할 수 있다. 전자 장치 는 분할된 디스플레이부의 복수의 영역에 대하여 탑승자의 터치 입력이 닿기 어려운 영역에만 음성 명령 어 가이드 UI(121 내지 127)를 디스플레이할 수 있다. 예를 들어, 디스플레이부는 운전석에 할당된 영역 과 조수석에 할당된 영역으로 구분되고, 전자 장치는 복수의 영역 중 운전자가 아이콘 또는 위젯을 터치 하기에는 먼 거리인 조수석에 할당된 영역에만 음성 명령어 가이드 UI(121 내지 127)를 디스플레이할 수 있다. 최근에는 차량 내부에 배치되는 디스플레이부가 대화면으로 구성되어 운전 중에 터치하기에는 허리를 숙 여야 되는 등 부가 동작이 필요하여 운전에 방해가 되는 경우가 있다. 도 12에 도시된 실시예에서, 전자 장치 는 디스플레이부의 복수의 영역(1611, 1612, 1613) 중 운전자(또는 탑승자)가 터치하기 어려운 먼 거리에 위치하는 영역(도 12의 실시예에서는 제2 영역, 제3 영역)에만 음성 명령어 가이드 UI(121 내지 127)을 디스플레이하므로, 운전자(또는 탑승자)가 직접 아이콘 또는 위젯 등 UI를 터치하지 않고 발화를 통해 기능을 수행할 수 있는 보이스 터치(voice touch)와 같은 사용자 경험을 제공할 수 있다. 도 13은 본 개시의 전자 장치가 HUD를 통해 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 도면이다. 도 13을 참조하면, 전자 장치는 HUD(Head Up Display)를 통해 애플리케이션 UI 및 음성 명령 어 가이드 UI를 디스플레이할 수 있다. 전자 장치는 프로젝터를 포함할 수 있다. 프로젝터 는 차량의 전면 유리창인 윈드 쉴드(wind shield) 상에 이미지를 투사하도록 구성되는 광학 엔진이다. 프 로젝터는 이미지의 광을 생성하도록 구성되고, 화상 패널, 조명 광학계, 투사 광학계 등을 포함하는 광학 엔진일 수 있다. 일 실시예에서, 프로젝터는 프로세서(1200, 도 2 참조)로부터 애플리케이션의 실행 화면 에 포함되는 애플리케이션 UI와 음성 명령어 가이드 UI를 구성하는 이미지를 포함하는 데이터를 획득 하고, 획득된 이미지 데이터에 기초하여 가상의 이미지를 생성하고, 광원으로부터 출력된 가상 이미지를 구성하 는 광을 출사면을 통해 윈드 쉴드 상에 투사할 수 있다. 프로젝터에 의해 투사된 이미지는 윈드 쉴드 상 의 HUD를 통해 디스플레이될 수 있다. 도 13에는 HUD를 통해 애플리케이션 UI와 음성 명령어 가이드 UI가 디스플레이되는 것으로 도시 되었지만, 이에 한정되는 것은 아니다. 일 실시예에서, HUD에는 음성 명령어 가이드 UI만 디스플레이 될 수 있다. 도 13에 도시된 실시예에서, 전자 장치는 HUD를 통해 음성 명령어 가이드 UI를 디스플레이하는 바, 운전자가 CID 또는 네비게이션 화면을 보려고 머리를 숙이지 않고도 기능 실행을 위한 단축 명령어를 직관 적으로 파악할 수 있도록 하여 사용자 편의성을 향상시킴은 물론, 운전자의 집중력 분산을 완화할 수도 있다. 도 14는 본 개시의 전자 장치가 음성 인식 기능을 수행하는 실시예를 도시한 흐름도이다. 단계 S1410에서, 전자 장치는 음성 인식 기능을 활성화하는 사용자 입력을 수신한다. 일 실시예에서, 전 자 장치의 프로세서(1200, 도 2 참조)는 음성 인식 기능 입력부(1510, 도 2 참조)를 통해 음성 인식 기능 을 활성화하는 사용자 입력을 수신할 수 있다. 음성 인식 기능 입력부는 하드웨어 버튼으로써, 차량의 스 티어링 휠에 배치되거나 또는 대시보드(dashboard) 상에 배치될 수 있다. 그러나, 이에 한정되는 것은 아니고, 음성 인식 기능 입력부는 디스플레이부 상에 디스플레이되는 그래픽 UI일 수도 있다. 일 실시예에서, 프로세서는 마이크로폰(1520, 도 2 참조)를 통해 음성 인식 기능을 활성화하기 위한 웨이 크 업 음성을 수신할 수 있다. 웨이크 업 음성은 예를 들어, '하이 빅스비' 또는 '오케이 구글' 등을 포함할 수 있다. 단계 S1420에서, 전자 장치는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이한다. 전자 장치 는 단계 S1410에서 사용자 입력을 수신함에 따라 음성 인식 기능을 활성화하고, 디스플레이부 상에 적어 도 하나의 음성 명령어 가이드 UI를 디스플레이할 수 있다. 단계 S1430에서, 전자 장치는 탑승자로부터 음성 입력을 수신한다. 일 실시예에서, 전자 장치의 프 로세서는 마이크로폰을 통해 운전석, 조수석, 또는 뒷좌석 중 적어도 하나에 탑승한 탑승자에 의해 발화된 음성 입력을 수신할 수 있다. 단계 S1440에서, 전자 장치는 수신된 음성 입력과 적어도 하나의 음성 명령어 가이드 UI에 대응되는 적어 도 하나의 단축 명령어를 비교한다. 일 실시예에서, 전자 장치의 프로세서는 ASR(Automatic Speech Recognition)을 수행하여 수신된 음성 입력을 컴퓨터로 판독 가능한 텍스트로 변환할 수 있다. 프로세서 는 변환된 텍스트를 적어도 하나의 음성 명령어 가이드 UI에 대응되는 적어도 하나의 단축 명령어와 비교할 수 있다. 비교 결과, 텍스트와 대응되는 단축 명령어가 식별된 경우(단계 S1450), 전자 장치는 식별된 단축 명령어 에 대응되는 기능을 실행한다. 예를 들어, 탑승자로부터 수신된 음성 입력이 \"볼륨 업\"인 경우, 전자 장치 는 디스플레이된 적어도 하나의 음성 명령어 가이드 UI에 대응되는 적어도 하나의 단축 명령어 중 '볼륨 업'과 매칭되는 단축 명령어를 식별하고, 식별된 단축 명령어에 대응되는 기능인 미디어 볼륨 올림 기능을 실행 할 수 있다. 비교 결과, 텍스트와 대응되는 단축 명령어가 식별되지 않은 경우(단계 S1470), 전자 장치는 음성 입력 데이터를 서버로 전송한다. 일 실시예에서, 전자 장치는 데이터 통신 모듈(1120, 도 2 참조)를 이용하여 음성 입력 데이터를 서버로 전송할 수 있다. 전자 장치는 예를 들어, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), 또는 블루투스를 포함하는 근거리 무선 통신 또는 CDMA, WCDMA, 3G, 4G, 및/또는 5G, 밀리미터파(mmWAVE)와 같은 이동 통신 네트워크를 이 용하여 음성 입력 데이터를 서버에 전송할 수 있다. 수 있다. 전자 장치는 단계 S1430에서 수신된 음성 입력 데이터를 그대로 서버에 전송할 수 있지만, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 음성 입력을 텍스트로 변환하고, 변환된 텍스트를 서버로 전송 할 수도 있다. 단계 S1480에서, 전자 장치는 서버로부터 음성 입력에 대응되는 기능 정보를 수신한다. 서버는 전자 장치 로부터 음성 입력 데이터를 수신하고, 자연어 이해 모델(Natural Language Understanding)을 이용하여 음성 입력 데이터를 해석함으로써 탑승자의 발화 의도(intent)를 인식할 수 있다. 서버는 인식된 발화 의도에 따른 기능을 식별하고, 식별된 기능에 관한 정보를 전자 장치에 전송할 수 있다. 단계 S1490에서, 전자 장치는 수신된 기능 정보를 이용하여 관련 기능을 식별하고, 식별된 기능을 실행한 다. 도 14에 도시된 실시예에서, 전자 장치는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하고, 탑승 자로부터 수신된 음성 입력을 서버에 전송하여 해석하기 전에 적어도 하나의 음성 명령어 가이드 UI 각각에 대 응되는 적어도 하나의 단축 명령어와 비교함으로써 매칭되는 단축 명령어를 미리 식별할 수 있다. 전자 장치 는 매칭되는 단축 명령어가 식별되는 경우, 식별된 단축 명령어와 관련된 기능을 실행하므로, 서버에 접 속할 필요가 없이 온 디바이스(on-device)로 기능을 실행할 수 있다. 따라서, 본 개시의 일 실시예에 따른 전자 장치는 서버와의 통신에 의해 소모되는 시간 및 통신 비용을 절감할 수 있고, 음성 인식의 정확도를 향상 시킬 수 있는 기술적 효과를 제공한다. 도 15는 본 개시의 일 실시예에 따른 전자 장치가 인공 지능 기술을 이용하여 수행되는 동작을 설명하기 위한 도면이다. 구체적으로, 전자 장치에 의해 수행되는 i) 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나에 관한 정보를 획득하는 동작, ii) 획득된 적어도 하나의 정보에 기초하여, 탑승자로부터 수신되는 음성 입력에 의해 상기 차량 또는 상기 전자 장치가 제공하는 적어도 하나의 기능을 실행하기 위한 음성 명령어 들을 간소화한 적어도 하나의 단축 명령어를 생성하는 동작, 및 iii) 생성된 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 동작 중 적어도 하나는, 신경망 (neural network)을 통한 연산을 수행하는 인공지능(AI: Artificial Intelligence) 기술을 이용하여 수행될 수 있다. 인공 지능 기술(이하, 'AI 기술')은 신경망(Neural Network)을 통한 연산을 기반으로 입력 데이터를 분석 및/또 는 분류 등과 같은 처리를 하여 목적하는 결과를 획득하는 기술이다. 이러한 AI 기술은 알고리즘을 활용하여 구현될 수 있다. 여기서, AI 기술을 구현하기 위한 알고리즘 또는 알고 리즘의 집합을 신경망(Neural Network)이라 한다. 여기서, 신경망은 입력 데이터를 입력받고, 전술한 분석 및/ 또는 분류를 위한 연산을 수행하여, 결과 데이터를 출력할 수 있다. 신경망이 입력 데이터에 대응되는 결과 데 이터를 정확하게 출력하기 위해서는, 신경망을 학습(training)시킬 필요가 있다. 여기서, '학습(training)'은 신경망에 대한 입력 데이터들을 분석하는 방법, 입력 데이터들을 분류하는 방법, 및/또는 입력 데이터들에서 결 과 데이터 생성에 필요한 특징을 추출하는 방법 등을 신경망이 스스로 발견 또는 터득할 수 있도록 훈련시키는 것을 의미할 수 있다. 구체적으로, 학습 과정을 통하여, 신경망은 학습 데이터(예를 들어, 서로 다른 복수의 이 미지들)를 학습(training)하여 신경망 내부의 가중치(weight) 값들을 최적화할 수 있다. 그리고, 최적화된 가중 치 값을 가지는 신경망을 통하여, 입력 데이터를 처리함으로써, 목적하는 결과를 출력한다. 신경망은 연산을 수행하는 내부의 레이어(layer)인 은닉 레이어(hidden layer)의 개수가 복수일 경우, 즉 연산 을 수행하는 신경망의 심도(depth)가 증가하는 경우, 심층 신경망으로 분류될 수 있다. 신경망은 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks) 등을 포함하고, 전술한 예시에 한정되지 않는다. 또한, 신경망은 세분화될 수 있다. 예를 들어, CNN 신경망은 DCNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 신경망(미도시) 등으로 세분화 될 수 있다. 'AI 모델'은 입력 데이터를 수신하고 목적하는 결과를 출력하도록 동작하는 적어도 하나의 레이어를 포함하는 신경망을 의미할 수 있다. 또한, 'AI 모델'은 신경망을 통한 연산을 수행하여 목적하는 결과를 출력하는 알고리 즘, 복수의 알고리즘의 집합, 알고리즘(또는 알고리즘의 집합)을 실행하기 위한 프로세서(processor), 알고리즘 (또는 알고리즘의 집합)을 실행하기 위한 소프트웨어, 또는 알고리즘(또는 알고리즘의 집합)을 실행하기 위한 하드웨어를 의미할 수 있다. 전술한 i) 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나에 관한 정보를 획득하는 동작, ii) 획득된 적어도 하나의 정보에 기초하여, 탑승자로부터 수신되는 음성 입력에 의해 상기 차량 또는 상 기 전자 장치가 제공하는 적어도 하나의 기능을 실행하기 위한 음성 명령어들을 간소화한 적어도 하나의 단축 명령어를 생성하는 동작, 및 iii) 생성된 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나 의 음성 명령어 가이드 UI를 디스플레이하는 동작 중 적어도 하나는 AI 모델 기반으로 수행될 수 있다. 도 15를 참조하면, 신경망은 학습 데이터(training data)를 입력받아 트레이닝(training)될 수 있다. 그리 고, 학습된 신경망은 입력단으로 입력 데이터를 입력받고, 입력단, 은닉 레이어(hidden layer) 및 출력단은 입력 데이터 및 이전 레이어로부터 전달된 데이터를 분석하여 출력 데이터 를 출력하기 위한 연산을 수행할 수 있다. 도 15에서는 은닉 레이어가 1개의 계층인 것으로 도시되어 있으나, 이는 예시일 뿐이고, 은닉 레이어는 복수의 계층으로 이루어질 수도 있다. 개시된 실시예에서 신경망은, 로그인 정보로부터 탑승자의 사용자 식별 정보 및 사용 이력 정보를 획득하 고, 사용자 식별 정보 및 사용 이력 정보로부터 탑승자가 자주 사용하는 애플리케이션 정보를 획득하며, 자주 사용하는 애플리케이션의 기능을 실행하기 위한 명령어를 간소화함으로써 적어도 하나의 단축 명령어를 생성하 도록 학습될 수 있다. 개시된 실시예에서 신경망은, 디스플레이부(1610, 도 2 참조) 상에 출력되는 적어도 하나의 그래픽 UI가 나타내는 기능을 인식하고, 인식된 기능을 자연어로 변환함으로써 적어도 하나의 GUI 각각에 대응되는 적어도 하나의 단축 명령어를 생성하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 적어도 하나의 음성 명령어 가이드 UI를 대응되는 기능을 실행하기 위한 적 어도 하나의 그래픽 UI의 인접한 위치에 각각 디스플레이하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 차량의 현재 위치, 주행 도로, 및 주행 속도에 관한 정보에 기초하여 안전 속도를 결정하고, 차량 주행 정보, 탑승자 정보, 디스플레이 출력 정보, 및 결정된 안전 속도 정보 중 적어도 하나에 기초하여 적어도 하나의 음성 명령어 가이드 UI 각각의 가중치를 결정하고, 결정된 가중치에 기초하여 적어도 하나의 음성 명령어 가이드 UI가 표시되는 개수, 위치, 및 크기를 결정하며, 결정된 개수, 위치, 및 크 기에 따라 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 차량의 주행 정보로부터 차량의 주행 속도가 상기 안전 속도 이상인지 여부 를 인식하고, 인식 결과에 기초하여 차량의 주행과 관련되는 기능을 실행하기 위한 적어도 하나의 제1 음성 명 령어 가이드 UI의 가중치 및 편의 기능을 실행하기 위한 적어도 하나의 제2 음성 명령어 가이드 UI의 가중치를 변경하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 디스플레이되는 팝 업 메시지를 제거하기 위한 기능을 실행하는 음성 명령어 가이드 UI의 가중치를 조절하도록 학습될 수 있다. 개시된 실시예에서 신경망은, 탑승자의 탑승 위치 정보에 따른 탑승자와 디스플레이부 사이의 거리를 측정 하고, 측정된 거리에 기초하여 디스플레이부 상에서 적어도 하나의 음성 명령어 가이드 UI가 디스플레이되는 영 역을 결정하며, 결정된 영역에 상기 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하도록 학습될 수 있다. 개시된 실시예에서, 전술한 i) 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나에 관 한 정보를 획득하는 동작, ii) 획득된 적어도 하나의 정보에 기초하여, 탑승자로부터 수신되는 음성 입력에 의 해 상기 차량 또는 상기 전자 장치가 제공하는 적어도 하나의 기능을 실행하기 위한 음성 명령어들을 간소화한 적어도 하나의 단축 명령어를 생성하는 동작, 및 iii) 생성된 적어도 하나의 단축 명령어 각각을 시각적으로 나 타내는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 동작 중 적어도 하나를 수행하는 신경망과 관련된 데이터 또는 프로그램 코드는 메모리(1300, 도 2 참조)에 저장되고, 신경망을 이용하는 학습은 프로세서(1200, 도 2 참조)에 의해 수행될 수 있다. 또는, 전술한 i) 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나에 관한 정보를 획득 하는 동작, ii) 획득된 적어도 하나의 정보에 기초하여, 탑승자로부터 수신되는 음성 입력에 의해 상기 차량 또 는 상기 전자 장치가 제공하는 적어도 하나의 기능을 실행하기 위한 음성 명령어들을 간소화한 적어도 하나의 단축 명령어를 생성하는 동작, 및 iii) 생성된 적어도 하나의 단축 명령어 각각을 시각적으로 나타내는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 동작 중 적어도 하나를 수행하는 신경망은 전자 장치 와 구별된 별도의 디바이스(미도시) 또는 프로세서(미도시) 내에 구현될 수 있다. 전술한 신경망을 통한 연산은 일 실시예에 따른 전자 장치와 무선 통신 네트워크를 통해 통신할 수 있는 서버(2000, 도 16 및 도 17 참조)에 의해 수행될 수도 있다. 전자 장치와 서버 간의 통신은 도 16 및 도 17을 참조하여 설명한다. 도 16은 서버와 연동하여 동작하는 개시된 실시예에 따른 전자 장치를 나타내는 도면이다. 서버는 통신 네트워크를 통하여 전자 장치와 데이터를 송수신하며 데이터를 처리할 수 있다. 도 17을 함께 참조하면, 서버는 전자 장치와 통신하는 통신부, 적어도 하나의 인스트럭션을 수행하는 프로세서, 및 데이터베이스를 포함할 수 있다. 서버는 AI 모델을 훈련시키고, 훈련된 AI 모델을 저장하고 있을 수 있다. 그리고, 서버는 훈련된 AI 모델을 이용하여 전술한 i) 차량의 주행 정보, 탑승자 정보, 및 디스플레이 출력 정보 중 적어도 하나에 관 한 정보를 획득하는 동작, ii) 획득된 적어도 하나의 정보에 기초하여, 탑승자로부터 수신되는 음성 입력에 의 해 상기 차량 또는 상기 전자 장치가 제공하는 적어도 하나의 기능을 실행하기 위한 음성 명령어들을 간소화한 적어도 하나의 단축 명령어를 생성하는 동작, 및 iii) 생성된 적어도 하나의 단축 명령어 각각을 시각적으로 나 타내는 적어도 하나의 음성 명령어 가이드 UI를 디스플레이하는 동작 중 적어도 하나를 수행할 수 있다. 일반적으로, 전자 장치는 메모리 저장 용량, 연산의 처리 속도, 학습 데이터 셋의 수집 능력 등이 서버 에 비하여 제한적일 수 있다. 따라서, 대용량 데이터의 저장 및 대용량의 연산량이 필요한 동작은 서버 에서 수행한 후, 통신 네트워크를 통하여 필요한 데이터 및/또는 AI 모델을 전자 장치에 전송할 수 있다. 그러면, 전자 장치는 대용량의 메모리 및 빠른 연산 능력을 갖는 프로세서 없이도, 서버를 통하여 필요한 데이터 및/또는 AI 모델을 수신하여 이용함으로써, 빠르고 용이하게 필요한 동작을 수행할 수 있 다. 개시된 실시예에서, 서버는 도 15에서 설명한 신경망을 포함할 수 있다. 도 17은 도 16을 상세하게 설명하기 위한 도면이다. 도 17을 참조하면, 서버는 통신부, 프로세서, 및 데이터베이스를 포함할 수 있다. 통신부는 무선 통신 네트워크를 통해서 외부 장치와 통신을 수행한다. 여기서, 외부 장치(미도시)는 전자 장치가 필요로 하는 연산 중 적어도 하나를 수행하거나, 전자 장치가 필요로 하는 데이터 등을 송 신할 수 있는 서버를 포함할 수 있다. 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등과 같은 적어도 하나의 통신 모듈을 포함한다. 여기서, 적어도 하나의 통신 모듈은 방송 수신을 수행하는 튜너, 블루투스, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), CDMA, WCDMA, 인터넷, 3G, 4G, 5G 및/또는 밀리미터 파(mmwave)를 이용한 통신 방식과 같은 통신 규 격을 따르는 네트워크를 통하여 데이터 송수신을 수행할 수 있는 통신 모듈을 의미한다. 예를 들어, 통신부가 밀리미터 파(mmWAVE)를 이용하여 통신을 수행하면, 대용량의 데이터를 빠르게 송수 신할 수 있다. 구체적으로, 차량은 밀리미터파를 이용하여 대용량의 데이터를 빠르게 수신하고, 차량의 안전에 필요한 데이터(예를 들어, 자율 주행에 필요한 데이터, 네비게이션 서비스를 위해 필요한 데이터 등), 사용자 이용 컨텐츠(예를 들어, 영화, 음악 등) 등을 빠르게 제공함으로써, 차량의 안전성 및/또는 사용자의 편리성을 증가시킬 수 있다. 통신부에 포함되는 이동 통신 모듈은 3G, 4G, 및/또는 5G 등의 통신 규격에 따르는 통신 네트워크를 통하 여 원거리에 위치하는 다른 장치(예를 들어, 전자 장치)와 통신을 수행할 수 있다. 여기서, 원거리에 위 치하는 다른 장치와 통신을 수행하는 통신 모듈을 '원거리 통신 모듈'이라 칭할 수 있다. 일 실시예에서, 통신 부는 전자 장치의 데이터 통신 모듈와 유선 또는 무선으로 데이터를 송수신할 수 있다. 프로세서는 서버의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 서버의 적어도 하나의 인스트럭션(instructions), 및 프로그램들 중 적어도 하나를 실행함으로써, 요구되는 동작들을 수행할 수 있다. 데이터베이스는 메모리(미도시)를 포함할 수 있으며, 메모리(미도시) 내에 서버가 소정 동작을 수 행하기 위해서 필요한 적어도 하나의 인스트럭션, 프로그램, 데이터 중 적어도 하나를 저장할 수 있다. 또한, 데이터베이스는 서버가 신경망에 따른 연산을 수행하기 위해서 필요한 데이터들을 저장할 수 있다. 개시된 실시예에서, 서버는 도 15에서 설명한 신경망을 저장하고 있을 수 있다. 신경망은 프로 세서 및 데이터베이스 중 적어도 하나에 저장될 수 있다. 서버가 포함하는 신경망은 학 습이 완료된 신경망이 될 수 있다. 또한, 서버는 학습이 완료된 신경망을 통신부를 통하여 전자 장치의 데이터 통신 모듈(112 0)로 전송할 수 있다. 그러면, 전자 장치는 학습이 완료된 신경망을 획득 및 저장하고, 신경망을 통하여 목적하는 출력 데이터를 획득할 수 있다. 본 명세서에서 설명된 전자 장치에 의해 실행되는 프로그램은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 프로그램은 컴퓨터로 읽을 수 있는 명령어들을 수행할 수 있는 모든 시스템에 의해 수행될 수 있다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령어(instruction), 또는 이들 중 하나 이상 의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어는, 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포함하 는 컴퓨터 프로그램으로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체로는, 예를 들어 마그네틱 저장 매체 (예컨대, ROM(read-only memory), RAM(random-access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판 독 매체(예컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있 는 기록 매체는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비 일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매 체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 예를 들어, '비일시적 저장매체'는 데이터가 임시적 으로 저장되는 버퍼를 포함할 수 있다. 또한, 본 명세서에 개시된 실시예들에 따른 프로그램은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 소프트웨어 프로그램, 소프트웨어 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체 를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예를 들어, 구글 플레이 스토어, 앱 스토어)을 통해 전자적으로 배포되는 소프트웨어 프로그램 형태의 상품(예를 들어, 다운로드 가능한 애플리케이션(downloadable application))을 포함할 수 있다. 전자적 배포를 위하여, 소프트웨어 프로그 램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체는 차량 또는 전 자 장치의 제조사의 서버, 전자 마켓의 서버, 또는 소프트웨어 프로그램을 임시적으로 저장하는 중계 서 버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 전자 장치, 서버(2000, 도 16 및 도 17 참조), 및 타 전자 장치로 구성되는 시 스템에서, 서버의 저장매체 또는 전자 장치의 저장매체를 포함할 수 있다. 또는, 전자 장치와 통 신 연결되는 제3 장치(예를 들어, 스마트 폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 전자 장치로부터 전자 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 전자 장치로 전송되는 소프트웨어 프로그램 자체를 포함할 수 있다. 이 경우, 전자 장치, 전자 장치, 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예 들에 따른 방법을 수행할 수 있다. 또는, 전자 장치, 전자 장치, 및 제3 장치 중 둘 이상이 컴퓨터 프로 그램 제품을 실행하여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 전자 장치가 메모리(1300, 도 2 참조)에 저장된 컴퓨터 프로그램 제품을 실행하여, 전자 장치 와 통신 연결된 타 전자 장치가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 장치가 컴퓨터 프로그램 제품을 실행하여, 제3 장치와 통신 연결된 전자 장치가 개시된 실시 예에 따른 방법을 수행하도록 제어할 수 있다. 제3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 장치는 전자 장치로부터 컴퓨터 프로그램 제품을 다운로드하고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 장치는 프리로드(pre-load)된 상 태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수도 있다."}
{"patent_id": "10-2021-0083184", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 컴퓨터 시스템 또는 모듈 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9a 도면9b 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17"}
{"patent_id": "10-2021-0083184", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 전자 장치가 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 개념도이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치 및 차량 센서 모듈을 도시한 블록도이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 도 5는 본 개시의 전자 장치가 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 도면이다. 도 6은 본 개시의 전자 장치가 사용자의 식별 정보에 따라 자주 사용하는 애플리케이션의 기능과 관련된 단축 명령어들을 생성하는 실시예를 도시한 도면이다. 도 7은 본 개시의 전자 장치가 복수의 디스플레이부 중 사용자에 의해 음성 인식 기능이 활성화된 디스플레이부 에 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 도면이다. 도 8은 본 개시의 전자 장치가 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 흐름도이다. 도 9a는 본 개시의 전자 장치가 주행 속도에 따라 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 도 면이다. 도 9b는 본 개시의 전자 장치가 주행 속도에 따라 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 도 면이다. 도 10은 본 개시의 전자 장치가 주행 속도 및 안전 속도에 기초하여 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시한 흐름도이다. 도 11은 본 개시의 전자 장치가 팝 업 메시지와 관련된 음성 명령어 가이드 UI를 디스플레이하는 실시예를 도시 한 도면이다. 도 12는 본 개시의 전자 장치가 디스플레이부 상의 일부 영역에 음성 명령어 가이드 UI를 디스플레이하는 실시 예를 도시한 도면이다. 도 13은 본 개시의 전자 장치가 HUD(Head Up Display)를 통해 음성 명령어 가이드 UI를 디스플레이하는 실시예 를 도시한 도면이다. 도 14는 본 개시의 전자 장치가 음성 인식 기능을 수행하는 실시예를 도시한 흐름도이다. 도 15는 본 개시의 전자 장치가 인공 지능 기술을 이용하여 수행하는 동작을 설명하기 위한 도면이다. 도 16은 본 개시의 전자 장치가 서버와 연동하여 동작하는 개시된 실시예를 도시한 도면이다. 도 17은 도 16을 상세하게 설명하기 위한 도면이다."}
