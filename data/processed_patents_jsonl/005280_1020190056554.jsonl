{"patent_id": "10-2019-0056554", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0131664", "출원번호": "10-2019-0056554", "발명의 명칭": "차량의 주행을 보조하는 전자 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "박요섭"}}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 차량의 주행을 보조하는 전자 장치에 있어서,통신부;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 통신부를 통해, 상기 복수의 차량으로부터, 상기 복수의 차량이 촬영한 복수의 영상과 상기 복수의 영상에대응하는 복수의 촬영 정보를 수신하고,상기 복수의 영상 중 제1 및 2 영상에 각각 대응하는 제1 및 2 촬영 정보에 기초하여 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 상기 제1 및 2 영상 내에 각각 포함된 제1 및 2 객체가 동일한 객체인지 여부를판단하고,상기 동일한 객체로 판단됨에 따라, 상기 제1 및 2 영상을, 영상으로부터 객체를 인식하도록 학습된 데이터 인식 모델의 학습 데이터로 이용하여 상기 데이터 인식 모델을 갱신하는, 전자 장치."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 객체와 상기 제2 객체의 매칭에 기초하여 유사도를 산출하고, 상기 유사도가 미리 설정된 임계치 이상으로 판단됨에 따라 상기 제1 객체와 상기 제2 객체를 동일한 객체로 판단하는, 전자 장치."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 촬영 정보는, 영상이 촬영된 시점 정보와 위치 정보를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 데이터 인식 모델을 이용하여 상기 복수의 영상으로부터 객체를 인식하고,상기 복수의 영상 중 상기 객체의 인식률이 미리 설정된 임계치 이하로 산출된 영상을 선택하고, 상기 선택된 영상을 상기 데이터 인식 모델의 학습 데이터로 이용할지 여부를 판단하는, 전자 장치."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2020-0131664-3-제1 항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 통신부를 통해, 상기 복수의 차량으로부터, 상기 복수의 영상 각각으로부터 객체를 인식한 인식률에 관한정보를 수신하고,상기 복수의 영상 중 상기 인식률이 미리 설정된 임계치 이하로 산출된 영상을 선택하고, 상기 선택된 영상을 상기 데이터 인식 모델의 학습 데이터로 이용할지 여부를 판단하는, 전자 장치."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 통신부를 통해, 상기 갱신된 데이터 인식 모델을 상기 복수의 차량에게 전송하는, 전자 장치."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "차량의 주행을 보조하는 방법에 있어서,통신부를 통해, 복수의 차량으로부터, 상기 복수의 차량이 촬영한 복수의 영상과 상기 복수의 영상에 대응하는복수의 촬영 정보를 수신하는 단계;상기 복수의 영상 중 제1 및 2 영상에 각각 대응하는 제1 및 2 촬영 정보에 기초하여 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 상기 제1 및 2 영상 내에 각각 포함된 제1 및 2 객체가 동일한 객체인지 여부를판단하는 단계; 및상기 동일한 객체로 판단됨에 따라, 상기 제1 및 2 영상을, 영상으로부터 객체를 인식하도록 학습된 데이터 인식 모델의 학습 데이터로 이용하여 상기 데이터 인식 모델을 갱신하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서, 상기 제1 및 2 객체가 동일한 객체인지 여부를 판단하는 단계는,상기 제1 객체와 상기 제2 객체의 매칭에 기초하여 유사도를 산출하는 단계; 및 상기 유사도가 미리 설정된 임계치 이상으로 판단됨에 따라 상기 제1 객체와 상기 제2 객체를 동일한 객체로 판단하는 단계를 포함하는, 방법."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7 항에 있어서, 상기 촬영 정보는, 영상이 촬영된 시점 정보와 위치 정보를 포함하는, 방법."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7 항에 있어서, 상기 데이터 인식 모델을 이용하여 상기 복수의 영상으로부터 객체를 인식하는 단계; 공개특허 10-2020-0131664-4-상기 복수의 영상 중 상기 객체의 인식률이 미리 설정된 임계치 이하로 산출된 영상을 선택하는 단계; 및상기 선택된 영상을 상기 데이터 인식 모델의 학습 데이터로 이용할지 여부를 판단하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7 항에 있어서, 상기 통신부를 통해, 상기 복수의 차량으로부터, 상기 복수의 영상 각각으로부터 객체를 인식한 인식률에 관한정보를 수신하는 단계;상기 복수의 영상 중 상기 인식률이 미리 설정된 임계치 이하로 산출된 영상을 선택하는 단계; 및상기 선택된 영상을 상기 데이터 인식 모델의 학습 데이터로 이용할지 여부를 판단하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7 항에 있어서,상기 통신부를 통해, 상기 갱신된 데이터 인식 모델을 상기 복수의 차량에게 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2019-0056554", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제7 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "복수의 차량의 주행을 보조하는 전자 장치 및 방법이 제공된다. 전자 장치 는, 통신부, 하나 이상의 인스트럭션 을 저장하는 메모리, 및 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 통신부를 통해, 복수의 차량으로부터, 복수의 차량이 촬영한 복수의 영 상과 복수의 영상에 대응하는 복수의 촬영 정보를 수신하고, 복수의 영상 중 제1 및 2 영상에 각각 대응하는 제1 및 2 촬영 정보에 기초하여 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 제1 및 2 영상 내에 각각 포함 된 제1 및 2 객체가 동일한 객체인지 여부를 판단하고, 동일한 객체로 판단됨에 따라, 제1 및 2 영상을, 영상으 로부터 객체를 인식하도록 학습된 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신할 수 있 다."}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 동작 방법에 관한 것으로서, 더욱 상세하게는, 차량의 주행을 보조하는 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술과 자동차 산업의 융합으로 인해 빠르게 자동차의 스마트화가 진행되고 있다. 스마트화로 인해, 자동차는 단순한 기계적 장치에서 스마트카로 진화하고 있으며, 특히 스마트카의 핵심기술로 자율 주행이 주목 받고 있다. 자율 주행이란 운전자가 핸들과 가속페달, 브레이크 등을 조작하지 않아도 차량 스스로 목적지까지 찾아가는 기 술이다. 최근 자율 주행과 관련된 다양한 부가 기능들이 지속적으로 개발되고 있으며, 각종 데이터를 이용하여 주행 환 경을 인지하고 판단하여 자동차를 제어함으로써 탑승자에게 안전한 자율 주행 경험을 제공할 수 있는 방법에 대 한 연구가 요구되고 있다. 또한, 인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스 템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해,추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다."}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "차량의 주행을 보조하는 전자 장치 및 방법을 제공하는 데 있다. 또한, 상기 방법을 컴퓨터에서 실행시키기 위 한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공하는 데 있다. 해결하려는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 따른 차량의 주행을 보조하는 전자 장치는, 통신부, 하나 이상의 인스트럭션을 저장하는 메모리, 및 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세서는, 하나 이상의 인스트럭 션을 실행함으로써, 통신부를 통해, 복수의 차량으로부터, 복수의 차량이 촬영한 복수의 영상과 복수의 영상에 대응하는 복수의 촬영 정보를 수신하고, 복수의 영상 중 제1 및 2 영상에 각각 대응하는 제1 및 2 촬영 정보에 기초하여 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 제1 및 2 영상 내에 각각 포함된 제1 및 2 객체 가 동일한 객체인지 여부를 판단하고, 동일한 객체로 판단됨에 따라, 제1 및 2 영상을, 영상으로부터 객체를 인 식하도록 학습된 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신할 수 있다. 다른 측면에 따른 차량의 주행을 보조하는 방법은, 통신부를 통해, 복수의 차량으로부터, 복수의 차량이 촬영한 복수의 영상과 복수의 영상에 대응하는 복수의 촬영 정보를 수신하는 단계, 복수의 영상 중 제1 및 2 영상에 각 각 대응하는 제1 및 2 촬영 정보에 기초하여 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 제1 및 2 영 상 내에 각각 포함된 제1 및 2 객체가 동일한 객체인지 여부를 판단하는 단계, 동일한 객체로 판단됨에 따라, 제1 및 2 영상을, 영상으로부터 객체를 인식하도록 학습된 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신하는 단계를 포함할 수 있다. 또 다른 측면에 따른 컴퓨터로 읽을 수 있는 기록매체는 상술한 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 기록매체를 포함한다."}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시 예들에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가 지는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 “포함”한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 “…부”, “…모듈” 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시 예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 발명의 실시 예들을 상세히 설명한다. 도 1은 일 실시 예에 따른 차량의 주행을 보조하는 전자 장치가 동작하는 일 예를 개략적으로 설명하기 위한 도 면이다. 일 실시 예에 따라, 전자 장치는 차량의 주행을 보조 또는 제어하는 서버로 동작할 수 있다. 일 실시 예에 따라, 차량(200a, 200b, 200c)은 자율 주행하거나, 주행 동작의 일부를 자율 제어할 수 있다. 예 를 들어, 차량(200a, 200b, 200c)은 자율 주행 시스템 또는 첨단 운전자 지원 시스템(ADAS: Advanced Driver Assistance Systems) 기능을 수행하도록 구현될 수 있다. 자율 주행하거나 적어도 일부 기능에 대해 자율 제어 할 수 있는 차량은, 차량이 주행하는 동안 다양한 센서를 이용하여 차량 주변의 객체를 인식함으로써 안정적인 운행 환경을 제공할 수 있다. 일 실시 예에 따른 객체는, 차량의 주변(전, 후방, 측방 등)을 촬영한 영상 내에 포함된 객체를 의미할 수 있다. 또한, 객체는, 차량이 주행하는 중에 차량의 주변(전, 후방, 측방 등)으로부터 센싱되는 객체를 의 미할 수도 있다. 예컨대, 객체는, 다른 차량, 보행자, 주행 경로 상의 장애물 등을 포함하며, 이에 제한되지 않 는다. 도 1을 참조하면, 차량(200a, 200b, 200c)은 전자 장치와의 데이터 송수신을 통해 보다 정확하고 안정적인 자율 주행 동작을 수행 할 수 있다. 일 실시 예에 따른 차량은, 이미지 센서(228, 도 17)를 이용하여 차량의 주변을 촬영하고, 촬영된 주 변 영상으로부터 객체(예컨대, 도로 상의 보행자, 차량, 도로 표지판 등)를 인식할 수 있다. 이미지 센서(228, 도 17)는 차량 외부의 환경을 기록하도록 구성되는 스틸 카메라 또는 비디오 카메라가 될 수 있다. 예를 들어, 이미지 센서는 다수의 카메라들을 포함할 수 있고, 다수의 카메라들은 차량의 내부 및 외부 상의 다수의 위치들에 배치될 수 있다.일 실시 예에 따라, 차량은, 이미지 센서(228, 도 17)를 이용하여 주변을 촬영하고, 차량의 주변이 촬영된 복수의 영상 프레임으로부터 객체를 인식하기 위해, 딥 러닝(deep learning) 기반의 학습된 데이터 인식 모델을 이용할 수 있다. 일 실시 예에 따라, 차량은, 영상 프레임 내의 객체를 인식하기 위해 영상 프레임 내의 후보 영역을 추출 하고 후보 영역에서의 객체의 종류와 위치를, 학습된 데이터 인식 모델을 이용하여 추정할 수 있다. 데이터 인식 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예컨대, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 데이터 인식 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 예를 들어, 차량은, 복수의 레이어(layers)를 보유한 컨볼루션 뉴럴 네트워크(Convolutional Neural Network; CNN) 등을 기반으로 하는 데이터 인식 모델을 이용하여, 영상 프레임에 포함된 객체(예컨대, 도로 상 의 보행자, 차량, 도로 표지판 등)를 인식할 수 있다. 각각의 레이어는 데이터를 수신할 수 있고, 입력되는 데 이터를 처리하여 각 레이어에서 출력되는 데이터를 생성할 수 있다. 일 실시 예에 따라, 차량는, 그래픽 전용 프로세서(GPU)에 의해 객체 인식을 수행할 수 있다. 또한, 차량 은, 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩에 의해 객체 인식을 수행할 수 있 으며, 이에 제한되지 않는다. 한편, 후술할 도 13 내지 도 16에서 설명하는 데이터 학습부, 데이터 인식부를 포함하는 프로세서 에 관한 설명은 전자 장치의 프로세서로 설명하였으나, 일 실시 예에 따라, 차량의 프로 세서(120, 도 17)가 도 13의 프로세서의 동작을 수행할 수도 있다. 또한, 일 실시 예에 따라, 전자 장치는, 딥 러닝(deep learning) 기반의 학습된 데이터 인식 모델을 이용 하여, 차량(200a, 200b, 200c)으로부터 수신한 차량의 주변이 촬영된 복수의 영상 프레임으로부터 객체를 인식 할 수 있다. 일 실시 예에 따라, 데이터 인식 모델은 미리 구축된 모델일 수 있다. 예를 들어, 데이터 인식 모델은, 기본 학 습 데이터(예를 들어, 샘플 이미지 등)을 입력 받아 미리 구축된 모델일 수 있다. 또한, 일 실시 예에 따라, 데이터 인식 모델은 학습 데이터를 이용하여 재 학습될 수 있다. 예를 들어, 데이터 인식 모델은, 별다른 지도 없이, 상황 판단을 위해 필요한 데이터를 스스로 학습함으로써, 상황 판단을 위한 기 준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 학습될 수 있다. 일 실시 예에 따라, 전자 장치는, 차량으로부터 수신한 복수의 영상 프레임과 객체 인식 결과를 학습 데이터로 이용하여 데이터 인식 모델을 학습시킬 수 있다. 일 실시 예에 따르면, 전자 장치는, 영상으로부터 객체를 인식한 인식률이 낮더라도, 동일한 시점에 촬영 된 다른 영상 내의 객체와 동일한 객체로 판단되면, 객체 인식률이 낮은 영상 및 데이터 인식 결과를 데이터 인 식 모델의 학습 데이터로 이용할 수 있다. 예를 들어, 전자 장치는, 다른 객체의 형상에 의해 상당 부분 가려져 있는 객체의 일부 형상 및 객체 인식 결과를 학습 데이터로 이용하여 데이터 인식 모델을 학습시킴으로써, 데이터 인식 모델의 객체 인식률을 향상시 킬 수 있다. 일 실시 예에 따라, 전자 장치는, 갱신된 데이터 인식 모델을 차량(200a, 200b, 200c)으로 전송할 수 있다. 일 실시 예에 따라, 차량은 갱신된 데이터 인식 모델을 이용하여 객체 인식을 수행함으로써, 영상으로부터 의 객체 인식을 보다 정확하게 수행할 수 있다. 이에 따라, 차량은 보다 안전하고 정확한 자율 주행을 수 행할 수 있다. 일 실시 예에 따른 전자 장치의 보다 구체적인 동작들에 대해서는 후술할 도면들을 참조하여 보다 상세히 설명하기로 한다. 도 1은 일 실시 예를 도시한 것으로서, 이에 한정되지 않는다. 도 2는 일 실시 예에 따라 전자 장치의 동작 방법의 흐름도이다. 도 3은 일 실시 예에 따라 전자 장치와 복수의 차량의 동작 방법의 흐름도이다. 도 4는 일 실시 예에 따라 복수의 차량이 촬영한 복수의 영상의 예를 설명하기 위한 도면이다. 도 5는 일 실시 예에 따라 영상을 학습 모델을 학습시키기 위한 입력 데이터로 이용하는 예를 설명하기 위한 도면이다. 도 2, 3의 흐름도를 설명하면서 도 4, 5, 6을 참조하여 설명하기로 한다. 도 2의 단계 S201에서, 전자 장치는, 복수의 차량으로부터, 복수의 차량이 촬영한 복수의 영상과 복수의 영상에 대응하는 복수의 촬영 정보를 수신할 수 있다. 일 실시 예에 따라, 차량은 이미지 센서(228, 도 17)를 이용하여 주변을 촬영하고, 촬영된 복수의 영상을 통신부(160, 도 17)를 통해 전자 장치로 전송할 수 있다. 일 실시 예에 따라, 차량은 촬영한 영상에 대응하는 촬영 정보를 획득할 수 있다. 차량은 촬영한 영 상에 대응하는 촬영 정보를 통신부(160, 도 17)를 통해 전자 장치로 전송할 수 있다. 일 실시 예에 따라, 촬영 정보는, 영상이 촬영된 시점 정보와 위치 정보를 포함할 수 있다. 예를 들어, 시점 정 보는, 차량이 영상을 촬영한 시, 분, 초 정보를 포함할 수 있다. 또한, 예를 들어, 위치 정보는, 차량 이 영상을 촬영한 시점의 영상 내의 객체의 지리적 위치(예컨대, GPS 정보)를 포함할 수 있다. 또한, 위치 정보는, 차량의 위치와 영상 내의 객체의 위치와의 상대적 거리 정보, 상대적 방향 정보 등을 포함할 수 있다. 또한, 위치 정보는 영상 내의 객체와 다른 객체간의 상대적 거리 정보, 상대적 방향 정보 등을 포함할 수 있으며, 이에 제한되지 않는다. 도 4는 주행 환경의 일 예를 도시한다. 도 4를 참조하면, 제1 차량(200a), 제2 차량(200b), 제3 차량(200c)은 주행 중 이미지 센서(228, 도 17)를 이용하여 전방을 촬영할 수 있다. 예를 들어, 제1 차량(200a), 제2 차량 (200b), 제3 차량(200c)의 전방에는 횡단 보도를 건너는 보행자가 있을 수 있다. 도 5는, 도 4에 도시한 주행 환경에서 제1 차량(200a), 제2 차량(200b), 제3 차량(200c)이 각각 촬영한 영상의 예를 도시한다. 도 5를 참조하면, 제1 차량(200a)이 촬영한 제1 영상(400a)에는 제1 객체(500a)가 포함될 수 있다. 또한, 제2 차량(200b)이 촬영한 제2 영상(400b)에는 제2 객체(500b)가 포함될 수 있다. 또한, 제3 차량(200c)이 촬영한 제 3 영상(400c)에는 제3 객체(500c)와 제4 객체(500d)가 포함될 수 있다. 일 실시 예에 따라, 제1 차량(200a)은 제1 영상(400a)과 제1 영상(400a)에 대응하는 제1 촬영 정보를 전자 장치 로 전송할 수 있다. 또한, 제2 차량(200b)은 제2 영상(400b)과 제2 영상(400b)에 대응하는 제2 촬영 정보 를 전자 장치로 전송할 수 있다. 또한, 제3 차량(200c)은 제3 영상(400c)과 제3 영상(400c)에 대응하는 제 3 촬영 정보를 전자 장치로 전송할 수 있다. 도 2의 단계 S202에서, 전자 장치는, 복수의 영상 중 제1 및 2 영상에 각각 대응하는 제1 및 2 촬영 정보 에 기초하여 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 제1 및 2 영상 내에 각각 포함된 제1 및 2 객체가 동일한 객체인지 여부를 판단할 수 있다. 일 실시 예에 따라, 전자 장치는 제1 영상에 대응하는 제1 촬영 정보에 기초하여, 제1 영상이 촬영된 시점 과 위치를 확인할 수 있다. 또한, 전자 장치는 제2 영상에 대응하는 제2 촬영 정보에 기초하여, 제2 영상 이 촬영된 시점과 위치를 확인할 수 있다. 일 실시 예에 따라, 전자 장치는 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 제1 및 2 영상 내 에 각각 포함된 제1 및 2 객체를 검출할 수 있다. 도 4, 도 5를 참조하면, 제1 영상(400a) 내에 포함된 제1 객체(500a)와 제2 영상(400b) 내에 포함된 제2 객체 (500b)는 보행자(300, 도 4)일 수 있다. 일 실시 예에 따라, 전자 장치는 제1 영상(400a)내에 포함된 제1 객체(500a)와 제2 영상(400b) 내에 포함 된 제2 객체(500b)가 동일한 객체인지 여부를 판단할 수 있다. 또한, 일 실시 예에 따라, 전자 장치는 제2 영상(400b)내에 포함된 제2 객체(500b)와 제3 영상(400c) 내에 포함된 제3 객체(500c)가 동일한 객체인지 여부 를 판단할 수 있다. 또한, 일 실시 예에 따라, 전자 장치는 제1 영상(400a)내에 포함된 제1 객체(500a)와 제3 영상(400c) 내에 포함된 제3 객체(500c)가 동일한 객체인지 여부를 판단할 수 있다. 일 실시 예에 따라, 복수의 객체가 동일한 객체인지 판단하는 방법의 구체적인 예에 관해서는 도 7, 도 8을 참 조하여 후술하기로 한다. 도 2의 단계 S203에서, 전자 장치는, 제1 및 제2 객체가 동일한 객체로 판단됨에 따라, 제1 및 2 영상을, 영상으로부터 객체를 인식하도록 학습된 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신 할 수 있다. 도 5를 참조하면, 일 실시 예에 따라, 전자 장치는 제1 객체(500a)와 제2 객체(500b)가 동일한 객체로 판 단됨에 따라, 제1 영상(400a) 및 제2 영상(400b)을, 영상으로부터 객체를 인식하도록 학습된 데이터 인식 모델 의 학습 데이터로 이용할 수 있다. 또한, 전자 장치는 제2 객체(500b)와 제3 객체(500c)가 동일한 객체로 판단됨에 따라, 제2 영상(400b) 및 제3 영상(400c)을 데이터 인식 모델의 학습 데이터로 이용할 수 있다. 도 6에 도시한 바와 같이, 일 실시 예에 따라, 전자 장치는 제1 영상(400a), 제2 영상(400b) 및 제3 영상 (400c)을 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신할 수 있다. 도 3은 일 실시 예에 따라 전자 장치와 복수의 차량의 동작을 설명하기 위한 흐름도이다. 도 3의 단계 S301에서, 전자 장치는, 제1, 2 영상과 제1, 2영상에 대응하는 제1, 2 촬영 정보를 수신할 수 있다. 일 실시 예에 따라, 전자 장치는 제1 차량(200a)으로부터 제1 영상과 제1 영상에 대응하는 제1 촬영 정보 를 수신할 수 있다. 또한, 일 실시 예에 따라, 전자 장치는 제2 차량(200b)으로부터 제2 영상과 제2 영상 에 대응하는 제2 촬영 정보를 수신할 수 있다. 도 3의 단계 S302에서, 전자 장치는, 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 제1 및 2 영상 내에 각각 포함된 제1 및 2 객체가 동일한 객체인지 여부를 판단할 수 있다. 도 4, 5를 참조하면, 예를 들어, 제1 차량(200a)과 제2 차량(200b)은 각각 전방의 보행자를 촬영할 수 있 다. 전자 장치는 제1 차량(200a)이 촬영한 제1 영상(400a)내에 포함된 제1 객체(500a)와 제2 차량(200b) 이 촬영한 제2 영상(400b) 내에 포함된 제2 객체(500b)가 동일한 객체인지 여부를 판단할 수 있다. 또한, 도 4, 5를 참조하면, 예를 들어, 제1 차량(200a)과 제3 차량(200c)은 각각 전방의 보행자를 촬영할 수 있다. 전자 장치는 제1 차량(200a)이 촬영한 제1 영상(400a)내에 포함된 제1 객체(500a)와 제3 차량 (200c)이 촬영한 제3 영상(400c) 내에 포함된 제3 객체(500c)가 동일한 객체인지 여부를 판단할 수 있다. 도 3의 단계 S303에서, 전자 장치는, 제1 및 2 영상을 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신할 수 있다. 도 4, 5를 참조하면, 예를 들어, 제1 영상(400a)내에 포함된 제1 객체(500a)와 제2 영상(400b) 내에 포함된 제2 객체(500b)가 동일한 객체(예컨대, 보행자, 도 4)로 판단됨에 따라, 제1 영상(400a)과 제2 영상(400b)을 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신할 수 있다. 또한, 도 4, 5를 참조하면, 예를 들어, 제1 영상(400a)내에 포함된 제1 객체(500a)와 제3 영상(400c) 내에 포함 된 제3 객체(500c)가 동일한 객체(예컨대, 보행자, 도 4)로 판단됨에 따라, 제1 영상(400a)과 제3 영상 (400c)을 데이터 인식 모델의 학습 데이터로 이용하여 데이터 인식 모델을 갱신할 수 있다. 도 3의 단계 S304에서, 전자 장치는, 갱신된 데이터 인식 모델을 제1 차량(200a), 제2 차량(200b)으로 전 송할 수 있다. 일 실시 예에 따라, 제1 차량(200a)과 제2 차량(200b)은, 촬영된 영상으로부터 객체를 인식하기 위해, 전자 장 치로부터 수신한 데이터 인식 모델을 이용할 수 있다. 제1 차량(200a)과 제2 차량(200b)은, 갱신된 데이터 인식 모델을 이용함으로써, 보다 정확도 높은 객체 인식을 수행할 수 있다. 이에 따라, 제1 차량(200a)과 제2 차량(200b)은 보다 안전하고 정확도 높은 자율 주행을 수행할 수 있다. 도 2 내지 도 6은 일 실시 예를 도시한 것으로서, 이에 한정되지 않는다. 도 7은 일 실시 예에 따라 제1 객체와 제2 객체가 동일한 객체인지 판단하는 예를 설명하기 위한 흐름도이다. 도 8은 일 실시 예에 따라 제1 객체와 제2 객체가 동일한 객체인지 판단하는 예를 설명하기 위한 도면이다. 일 실시 예에 따라, 전자 장치는 차량이 촬영한 영상을 데이터 인식 모델의 학습 데이터로 이용할지 여부를 판단하기 위해, 영상 내의 객체가 동일한 시점에 촬영된 다른 영상 내의 객체와 동일한 객체인지 여부를판단할 수 있다. 도 8을 참조하면, 예를 들어, 제3 영상(400c) 내에서 제3 객체(500c)는 제4 객체(500d)의 형상에 의해 가려져 일부만 나타날 수 있다. 이에 따라, 전자 장치가 제3 영상(400c)으로부터 제3 객체(500c)를 인식하는 인식 률은 낮을 수 있다. 일 실시 예에 따라, 전자 장치는 영상으로부터 객체를 인식한 결과를 데이터 인식 모델의 학습 데이터로 이용할 수 있다. 전자 장치는, 제3 객체(500c)를 인식한 결과 인식률이 낮더라도, 제3 객체(500c)가 동일 한 시점에 동일한 지점에 위치한 제1 객체(500a), 제2 객체(500b)와 동일한 객체로 판단되면, 제3 영상(400c)을 데이터 인식 모델의 학습 데이터로 이용할 수 있다. 이에 따라, 데이터 인식 모델이 제4 객체(500d)의 형상에 의해 상당 부분 가려져 있는 제3 객체(500c)의 일부 형상 및 객체 인식 결과를 학습함으로써, 데이터 인식 모델의 객체 인식률은 향상될 수 있다. 도 7의 단계 S701에서, 전자 장치는, 제1 객체와 제2 객체의 매칭에 기초하여 유사도를 산출할 수 있다. 일 실시 예에 따라, 전자 장치는, 동일한 시점에 동일한 지점에 위치한 것으로 판단되는, 제1 및 2 영상 내에 각각 포함된 제1 및 2 객체가 동일한 객체인지 여부를 판단할 수 있다. 도 8을 참조하면, 예를 들어, 전자 장치는, 제1 영상(400a)에 포함된 제1 객체(500a), 제2 영상(400b)에 포함된 제2 객체(500b)와, 제3 영상(400c)에 포함된 제3 객체(500c)가 동일한 객체인지 여부를 판단할 수 있다. 전자 장치는 둘 이상의 객체들의 매칭에 기초하여 유사도를 산출할 수 있다. 일 실시 예에 따라, 전자 장 치는 영상에 포함된 객체의 색상(hue), 채도(saturation), 명도(value), 컬러 히스토그램(color histogram)등을 이용하여 둘 이상의 객체들을 비교할 수 있으며, 이에 제한되지 않는다. 예를 들어, 전자 장치는 제1 객체(500a)와 제3 객체(500c)의 색상(hue), 채도(saturation), 명도(value) 를 이용하여 제1 객체(500a)와 제3 객체(500c)를 매칭시킬 수 있다. 전자 장치는 제1 객체(500a)와 제3 객 체(500c)의 매칭에 기초하여 유사도를 산출할 수 있다. 도 8을 참조하면, 예를 들어, 제1 객체(object 1)와 제3 객체(object 3)의 유사도가 0.9로 산출될 수 있다. 또 한, 예를 들어, 제1 객체(object 1)와 제2 객체(object 2)의 유사도가 0.8로 산출될 수 있다. 또한, 예를 들어, 제2 객체(object 2)와 제3 객체(object 3)의 유사도가 0.8로 산출될 수 있다. 도 7의 단계 S702에서, 전자 장치는, 유사도가 미리 설정된 임계치 이상으로 판단됨에 따라 제1 객체와 제 2 객체를 동일한 객체로 판단할 수 있다. 도 8을 참조하면, 예를 들어, 전자 장치는, 객체 간의 유사도가 미리 설정된 임계치(예컨대, 유사도 0.8) 이상으로 판단됨에 따라, 제1 객체, 제2 객체와 제3 객체를 동일한 객체로 판단할 수 있으며, 이에 제한되지 않 는다. 일 실시 예에 따르면, 서로 다른 영상 내에 포함된 객체가 동일한 객체 인지 판단하기 위해 객체의 동일 또는 유사를 판단하는 다른 영상 처리 기술이 적용될 수 있음은 물론이다. 도 7 내지 도 8은 일 실시 예를 도시한 것으로서, 이에 한정되지 않는다. 도 9는 일 실시 예에 따라 객체의 인식률에 따라 영상을 선택하는 일 예를 설명하기 위한 흐름도이다. 도 10은 일 실시 예에 따라 객체의 인식률에 따라 영상을 선택하는 다른 일 예를 설명하기 위한 흐름도이다. 도 11은 일 실시 예에 따라 객체의 인식률에 따라 영상을 선택하는 일 예를 설명하기 위한 도면이다. 도 9의 단계 S901에서, 전자 장치는, 데이터 인식 모델을 이용하여 복수의 영상으로부터 객체를 인식할 수 있다. 일 실시 예에 따라 전자 장치는, 영상으로부터 객체를 인식하도록 학습된 데이터 인식 모델을 이용하여, 차량(200, 도 1)으로부터 수신한 영상으로부터 객체를 인식할 수 있다. 도 9의 단계 S902에서, 전자 장치는, 복수의 영상 중 객체의 인식률이 미리 설정된 임계치 이하로 산출된 영상을 선택할 수 있다. 도 11을 참조하면, 예를 들어, 제1 영상(400a)을 데이터 인식 모델에 입력함으로써 제1 객체(500a)를 '사람'으 로 인식한 인식률은 95%, 제2 영상(400b) 내의 제2 객체(500b)를 '사람'으로 인식한 인식률은 97%, 제3 영상(400c) 내의 제3 객체(500c)를 '사람'으로 인식한 인식률은 48%일 수 있다. 예를 들어, 도 11을 참조하면, 전자 장치는, 복수의 영상 중 객체의 인식률이 미리 설정된 임계치(예컨대, 50%) 이하로 산출된 제3 영상(400c)을 선택할 수 있다. 도 9의 단계 S903에서, 전자 장치는, 선택된 영상을 데이터 인식 모델의 학습 데이터로 이용할지 여부를 판단할 수 있다. 예를 들어, 도 11을 참조하면, 전자 장치는, 선택된 제3 영상(400c)을, 동일한 시점에 촬영된 다른 영상 (예컨대, 제1 영상(400a) 또는 제2 영상(400c))과 매칭시킴으로써, 제3 영상(400c)을 데이터 인식 모델의 학습 데이터로 이용하기로 결정할 수 있다. 전자 장치는, 객체 인식률이 낮은 제3 영상(400c) 내에 포함된 제3 객체(500c)를, 동일한 시점에 촬영된 제1 영상(400a) 내에 포함된 제1 객체(400a)와 동일한 객체로 판단함에 따 라, 객체 인식률이 낮은 제3 영상(400c) 및 제3 객체(500c)의 인식 결과를 데이터 인식 모델의 학습 데이터로 이용할 수 있다. 이에 따라, 데이터 인식 모델을 보다 향상된 성능의 데이터 인식 모델로 갱신시킬 수 있다. 도 10은 전자 장치가 영상의 객체 인식률에 관한 정보를 차량으로부터 수신함으로써, 복수의 영상의 객체 인식률을 확인하는 예를 설명하기 위한 흐름도이다. 도 10의 단계 S1001에서, 전자 장치는, 복수의 차량으로부터, 복수의 영상 각각으로부터 객체를 인식한 인 식률에 관한 정보를 수신할 수 있다. 일 실시 예에 따라, 차량은 데이터 인식 모델을 이용하여 영상으로부터 객체를 인식할 수 있고, 영상의 객 체 인식률에 관한 정보를 전자 장치에게 제공할 수 있다. 도 10의 단계 S1002에서, 전자 장치는, 복수의 영상 중 객체의 인식률이 미리 설정된 임계치 이하로 산출 된 영상을 선택할 수 있다. 도 10의 단계 S1003에서, 전자 장치는, 선택된 영상을 데이터 인식 모델의 학 습 데이터로 이용할지 여부를 판단할 수 있다. 단계 S1002, S1003의 동작에 관해서는 도 9의 단계 S902, S903에 관한 설명을 참조할 수 있다. 도 9 내지 도 11은 일 실시 예를 도시한 것으로서 이에 한정되지 않는다. 도 12는 일 실시 예에 따른 전자 장치의 블록 구성도(block diagram)이다. 전자 장치는 일 실시 예에 따라, 통신부, 메모리 및 프로세서를 포함할 수 있다. 도 12 에 도시된 전자 장치는 본 실시 예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 12에 도시된 구성"}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 본 실시 예와 관련된 기술분야에서 통상의 지식 을 가진 자라면 이해할 수 있다. 일 실시 예에 따라, 프로세서는 적어도 하나의 프로세서로 구성될 수 있다. 일 실시 예에 따라, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 통신부를 통해, 복수의 차량으로부터, 복수의 차량이 촬영한 복수의 영상과 복수의 영상에 대응하는 복수의 촬영 정보를 수 신할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 복수의 영상 중 제1 및 2 영상에 각각 대응 하는 제1 및 2 촬영 정보에 기초하여 동일한 시점에 동일한 지점에 위치한 것으로 판단되는 제1 및 2 영상 내에 각각 포함된 제1 및 2 객체가 동일한 객체인지 여부를 판단할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 제1 객체와 제2 객체의 매칭에 기초하여 유 사도를 산출하고, 유사도가 미리 설정된 임계치 이상으로 판단됨에 따라 제1 객체와 제2 객체를 동일한 오브젝 트로 판단할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 제1 및 2 객체가 동일한 객체로 판단됨에 따 라, 제1 및 2 영상을, 영상으로부터 객체를 인식하도록 학습된 데이터 인식 모델의 학습 데이터로 이용하여 상 기 데이터 인식 모델을 갱신할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 데이터 인식 모델을 이용하여 복수의 영상으 로부터 오브젝트를 인식할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 통신부를 통해, 복수의 차량으로 부터, 복수의 영상 각각으로부터 오브젝트를 인식한 인식률에 관한 정보를 수신할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 복수의 영상 중 오브젝트의 인식률이 미리 설정된 임계치 이하로 산출된 영상을 선택할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 선택된 영상을 데이터 인식 모델의 학습 데 이터로 이용할지 여부를 판단할 수 있다. 또한, 프로세서는, 하나 이상의 인스트럭션을 실행함으로써, 통신부를 통해, 갱신된 데이터 인식 모델을 복수의 차량에게 전송할 수 있다. 통신부는 다른 디바이스와 무선으로 통신하기 위한 적어도 하나의 안테나를 포함할 수 있다. 프로세서에 의해 제어되는 통신부는 무선 신호를 송수신할 수 있다. 예를 들어, 프로세서는, 통신부가 셀룰러 네트워크와 무선 신호를 송수신하기 위해, 메모리에 포함된 프로그램을 실행시킬 수 있다. 통신부는, 전자 장치가 외부와 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있다. 예를 들 어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시)를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통 신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비(Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여 기에서, 무선 신호는, 다양한 형태의 데이터를 포함할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 도 13은 일 실시 예에 따른 프로세서의 블록도이다. 도 13을 참조하면, 일부 실시 예에 따른 프로세서는 데이터 학습부 및 데이터 인식부를 포함 할 수 있다. 데이터 학습부는 상황 판단을 위한 기준을 학습할 수 있다. 데이터 학습부는 소정의 상황을 판단하 기 위하여 어떤 데이터를 이용할 지, 데이터를 이용하여 상황을 어떻게 판단할 지에 관한 기준을 학습할 수 있 다. 데이터 학습부는 학습에 이용될 데이터를 획득하고, 획득된 데이터를 후술할 데이터 인식 모델에 적 용함으로써, 상황 판단을 위한 기준을 학습할 수 있다. 데이터 인식부는 데이터에 기초한 상황을 판단할 수 있다. 데이터 인식부는 학습된 데이터 인식 모 델을 이용하여, 소정의 데이터로부터 상황을 인식할 수 있다. 데이터 인식부는 학습에 의한 기 설정된 기 준에 따라 소정의 데이터를 획득하고, 획득된 데이터를 입력 값으로 하여 데이터 인식 모델을 이용함으로써, 소 정의 데이터에 기초한 소정의 상황을 판단할 수 있다. 또한, 획득된 데이터를 입력 값으로 하여 데이터 인식 모 델에 의해 출력된 결과 값은, 데이터 인식 모델을 갱신하는데 이용될 수 있다. 예를 들어, 차량이 촬영한 영상과 영상 내에 포함된 객체의 객체 인식 결과는, 영상으로부터 객체를 인식 하도록 학습된 데이터 인식 모델을 갱신하는데 이용될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로 세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 이 경우, 데이터 학습부 및 데이터 인식부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 하나는 전 자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부 는 유선 또는 무선으로 통하여, 데이터 학습부가 구축한 모델 정보를 데이터 인식부로 제공 할 수도 있고, 데이터 인식부로 입력된 데이터가 추가 학습 데이터로서 데이터 학습부로 제공될 수 도 있다. 한편, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이 터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포 함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소 프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플 리케이션에 의해 제공될 수 있다. 도 14는 일 실시 예에 따른 데이터 학습부의 블록도이다. 도 14를 참조하면, 일부 실시 예에 따른 데이터 학습부는 데이터 획득부(1310-1), 전처리부(1310-2), 학 습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5)를 포함할 수 있다. 데이터 획득부(1310-1)는 상황 판단에 필요한 데이터를 획득할 수 있다. 데이터 획득부(1310-1)는 상황 판단을 위한 학습을 위하여 필요한 데이터를 획득할 수 있다. 또한, 데이터 획득부(1310-1)는 서버로부터 데이터를 수 신할 수도 있다. 예를 들어, 데이터 획득부(1310-1)는 차량의 주변 영상을 입력 받을 수 있다. 주변 영상은 복수의 이미지 (또는, 프레임(frame))들로 구성될 수 있다. 일 예로, 데이터 획득부(1310-1)는 데이터 학습부를 포함하 는 전자 장치의 카메라, 또는 데이터 학습부를 포함하는 전자 장치와 통신 가능한 외부의 카메라(예로, CCTV 또는 블랙박스 등)를 통하여 동영상을 입력 받을 수 있다. 여기서, 카메라는 하나 이상의 이미지 센서(예: 전면 센서 또는 후면 센서), 렌즈, 이미지 시그널 프로세서(ISP), 또는 플래시(예: LED 또는 xenon lamp 등)를 포함할 수 있다. 또한, 일 예로, 데이터 획득부(1310-1)는 전자 장치의 입력 기기(예: 마이크로폰, 카메라 또는 센서 등)를 통해 데이터를 입력 받을 수 있다. 또는, 데이터 획득부(1310-1)는 전자 장치와 통신하는 외부 장치를 통해 데이터를 획득할 수 있다. 전처리부(1310-2)는 상황 판단을 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리부(1310-2)는 후술할 모델 학습부(1310-4)가 상황 판단을 위한 학습을 위하여 획득된 데이터를 이 용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부(1310-3)는 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 데이터 는 모델 학습부(1310-4)에 제공될 수 있다. 학습 데이터 선택부(1310-3)는 상황 판단을 위한 기 설정된 기준에 따라, 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부(1310-3)는 후술할 모델 학습부(1310-4)에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 예를 들어, 차량이 촬영한 영상과 영상 내에 포함된 객체의 객체 인식 결과에 관한 데이터가 선택될 수 있 다. 모델 학습부(1310-4)는 학습 데이터에 기초하여 상황을 어떻게 판단할 지에 관한 기준을 학습할 수 있다. 또한, 모델 학습부(1310-4)는 상황 판단을 위하여 어떤 학습 데이터를 이용해야 하는 지에 대한 기준을 학습할 수도 있다. 또한, 모델 학습부(1310-4)는 상황 판단에 이용되는 데이터 인식 모델을 학습 데이터를 이용하여 학습시킬 수 있다. 이 경우, 데이터 인식 모델은 미리 구축된 모델일 수 있다. 예를 들어, 데이터 인식 모델은 기본 학습 데 이터(예를 들어, 샘플 이미지 등)을 입력 받아 미리 구축된 모델일 수 있다. 데이터 인식 모델은, 인식 모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 데이터 인식 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예컨대, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 데이터 인식 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 다양한 실시예에 따르면, 모델 학습부(1310-4)는 미리 구축된 데이터 인식 모델이 복수 개가 존재하는 경우, 입 력된 학습 데이터와 기본 학습 데이터의 관련성이 큰 데이터 인식 모델을 학습할 데이터 인식 모델로 결정할 수 있다. 이 경우, 기본 학습 데이터는 데이터의 타입 별로 기 분류되어 있을 수 있으며, 데이터 인식 모델은 데이 터의 타입 별로 미리 구축되어 있을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이터 내의 객 체의 종류 등과 같은 다양한 기준으로 기 분류되어 있을 수 있다. 또한, 모델 학습부(1310-4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부(1310-4)는, 예를 들어, 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning)을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부(1310-4)는, 예를 들어, 별다른 지도 없이 상 황 판단을 위해 필요한 데이터의 종류를 스스로 학습함으로써, 상황 판단을 위한 기준을 발견하는 비지도 학습 (unsupervised learning)을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부(1310-4)는, 예 를 들어, 학습에 따른 상황 판단의 결과가 올바른 지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 데이터 인식 모델이 학습되면, 모델 학습부(1310-4)는 학습된 데이터 인식 모델을 저장할 수 있다. 이 경 우, 모델 학습부(1310-4)는 학습된 데이터 인식 모델을 데이터 인식부를 포함하는 전자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부(1310-4)는 학습된 데이터 인식 모델을 후술할 데이터 인식부를 포함 하는 전자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부(1310-4)는 학습된 데이터 인식 모델을 전자 장 치와 유선 또는 무선 네트워크로 연결되는 서버의 메모리에 저장할 수도 있다. 이 경우, 학습된 데이터 인식 모델이 저장되는 메모리는, 예를 들면, 전자 장치의 적어도 하나의 다른 구성요소 에 관계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수도 있다. 프로그램은, 예를 들면, 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플리 케이션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 모델 평가부(1310-5)는 데이터 인식 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 인식 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부(1310-4)로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 데이터 인식 모델을 평가하기 위한 기 설정된 데이터일 수 있다. 예를 들어, 모델 평가부(1310-5)는 평가 데이터에 대한 학습된 데이터 인식 모델의 인식 결과 중에서, 인식 결 과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하 지 못한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 데이터 인식 모델이 총 1000개의 평가 데이터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 인식 결과를 출력하는 경우, 모델 평 가부(1310-5)는 학습된 데이터 인식 모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 데이터 인식 모델이 복수 개가 존재하는 경우, 모델 평가부(1310-5)는 각각의 학습된 데이터 인식 모델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 데이터 인식 모델로서 결정할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부(1310-5)는 평가 점수가 높은 순으로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 데이터 인식 모델로서 결정할 수 있다. 한편, 데이터 학습부 내의 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위 한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부(1310-1), 전처리부(1310-2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(1310-1), 전처리부(1310- 2), 학습 데이터 선택부(1310-3), 모델 학습부(1310-4) 및 모델 평가부(1310-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 15는 일 실시 예에 따른 데이터 인식부의 블록도이다. 도 15를 참조하면, 일부 실시 예에 따른 데이터 인식부는 데이터 획득부(1320-1), 전처리부(1320-2), 인 식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5)를 포함할 수 있다. 데이터 획득부(1320-1)는 상황 판단에 필요한 데이터를 획득할 수 있으며, 전처리부(1320-2)는 상황 판단을 위 해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리부(1320-2)는 후술할 인식 결 과 제공부(1320-4)가 상황 판단을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷 으로 가공할 수 있다. 인식 데이터 선택부(1320-3)는 전처리된 데이터 중에서 상황 판단에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 인식 결과 제공부(1320-4)에게 제공될 수 있다. 인식 데이터 선택부(1320-3)는 상황 판단을 위한 기 설정된 기준에 따라, 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 인식 데이터 선택부 (1320-3)는 후술할 모델 학습부(1310-4)에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 인식 결과 제공부(1320-4)는 선택된 데이터를 데이터 인식 모델에 적용하여 상황을 판단할 수 있다. 인식 결과 제공부(1320-4)는 데이터의 인식 목적에 따른 인식 결과를 제공할 수 있다. 인식 결과 제공부(1320-4)는 인식 데이터 선택부(1320-3)에 의해 선택된 데이터를 입력 값으로 이용함으로써, 선택된 데이터를 데이터 인식 모델 에 적용할 수 있다. 또한, 인식 결과는 데이터 인식 모델에 의해 결정될 수 있다. 일 실시 예에 따라, 인식 결과는, 텍스트, 음성, 동영상, 이미지 또는 명령어(예로, 어플리케이션 실행 명령어, 모듈 기능 실행 명령어 등) 등으로 제공될 수 있다. 모델 갱신부(1320-5)는 인식 결과 제공부(1320-4)에 의해 제공되는 인식 결과에 대한 평가에 기초하여, 데이터 인식 모델이 갱신되도록 할 수 있다. 예를 들어, 모델 갱신부(1320-5)는 인식 결과 제공부(1320-4)에 의해 제공 되는 인식 결과를 모델 학습부(1310-4)에게 제공함으로써, 모델 학습부(1310-4)가 데이터 인식 모델을 갱신하도 록 할 수 있다. 한편, 데이터 인식부 내의 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320- 3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재 될 수도 있다. 또한, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부 (1320-4) 및 모델 갱신부(1320-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(1320-1), 전처리부(1320-2), 인식 데이터 선택부(1320-3), 인식 결과 제공부(1320-4) 및 모델 갱신부(1320-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 16은 일 실시 예에 따른 전자 장치가 외부 서버와 서로 연동함으로써 데이터를 학습하고 인식하는 예시를 나 타내는 도면이다. 도 16은 일부 실시 예에 따른 전자 장치 및 외부 서버가 서로 연동함으로써 데이터를 학습하고 인식 하는 예시를 나타내는 도면이다. 도 16을 참조하면, 서버는 상황 판단을 위한 기준을 학습할 수 있으며, 전자 장치 는 외부 서버 에 의한 학습 결과에 기초하여 상황을 판단할 수 있다. 이 경우, 외부 서버의 모델 학습부는 도 14에 도시된 데이터 학습부의 기능을 수행할 수 있 다. 외부 서버의 모델 학습부는 소정의 상황을 판단하기 위하여 어떤 데이터를 이용할 지, 데이터 를 이용하여 상황을 어떻게 판단할 지에 관한 기준을 학습할 수 있다. 모델 학습부는 학습에 이용될 데이 터를 획득하고, 획득된 데이터를 후술할 데이터 인식 모델에 적용함으로써, 상황 판단을 위한 기준을 학습할 수 있다. 또한, 전자 장치의 인식 결과 제공부(1320-4)는 인식 데이터 선택부(1320-3)에 의해 선택된 데이터를 외부 서버에 의해 생성된 데이터 인식 모델에 적용하여 상황을 판단할 수 있다. 예를 들어, 인식 결과 제공부 (1320-4)는 인식 데이터 선택부(1320-3)에 의해 선택된 데이터를 외부 서버에게 전송하고, 외부 서버 가 인식 데이터 선택부(1320-3)에 의해 선택된 데이터를 인식 모델에 적용하여 상황을 판단할 것을 요청 할 수 있다. 또한, 인식 결과 제공부(1320-4)는 외부 서버에 의해 판단된 상황에 관한 정보를 외부 서버 로부터 수신할 수 있다. 예를 들어, 전자 장치는 영상 프레임을 외부 서버에게 전송하고, 서버가 영상 프레임에 데이 터 인식 모델에 적용하여 객체를 인식할 것을 요청할 수 있다. 또한, 전자 장치는 외부 서버에 의해 판단된 객체 인식에 관한 정보를 서버로부터 수신할 수 있다. 또는, 전자 장치의 인식 결과 제공부(1320-4)는 외부 서버에 의해 생성된 인식 모델을 외부 서버 로부터 수신하고, 수신된 인식 모델을 이용하여 상황을 판단할 수 있다. 이 경우, 전자 장치의 인식 결과 제공부(1320-4)는 인식 데이터 선택부(1320-3)에 의해 선택된 데이터를 외부 서버로부터 수신된 데 이터 인식 모델에 적용하여 상황을 판단할 수 있다. 예를 들어, 전자 장치는 영상 프레임을 외부 서버로부터 수신된 데이터 인식 모델에 적용하여, 객체 를 인식 할 수 있다. 도 17은 일 실시 예에 따른 차량의 블록 구성도(block diagram)이다. 차량은 센싱부, 프로세서, 출력부, 저장부(140, 또는 메모리), 입력부, 및 통신부 를 포함할 수 있다. 센싱부는 차량이 위치해 있는 주변 환경에 관한 정보를 감지하도록 구성되는 다수의 센서들을 포함할 수 있고, 센서들의 위치 및/또는 배향을 수정하도록 구성되는 하나 이상의 액추에이터들을 포함할 수 있다. 예 를 들어, 센싱부는 GPS(Global Positioning System), IMU(Inertial Measurement Unit), RADAR 센서, LIDAR 센서, 이미지 센서 및 Odometery 센서를 포함할 수 있다. 또한, 센싱부(11 0)는 온/습도 센서, 적외선 센서, 기압 센서, 근접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으 로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략하기로 한다. 또한, 센싱부는 차량의 움직임을 센싱할 수 있는 움직임 센싱부를 포함할 수 있다. 움직임 센싱 부는 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 및 자이로스코프 센 서를 포함할 수 있다. GPS는 차량의 지리적 위치를 추정하도록 구성되는 센서일 수 있다. 즉, GPS는 지구에 대한 차량 의 위치를 추정하도록 구성되는 송수신기를 포함할 수 있다. IMU는 관성 가속도에 기초하여 차량의 위치 및 배향 변화들을 감지하도록 구성되는 센서들의 조합이 될 수 있다. 예를 들어, 센서들의 조합은, 가속도계들 및 자이로스코프들을 포함할 수 있다. RADAR 센서는 무선 신호를 사용하여 차량이 위치해 있는 환경 내의 물체들을 감지하도록 구성되는 센 서일 수 있다. 또한, RADAR 센서는, 물체들의 속도 및/또는 방향을 감지하도록 구성될 수 있다. LIDAR 센서는 레이저를 사용하여 차량이 위치해 있는 환경 내의 물체들을 감지하도록 구성되는 센서 일 수 잇다. 보다 구체적으로, LIDAR 센서는 레이저를 방출하도록 구성되는 레이저 광원 및/또는 레이저 스캐너와, 레이저의 반사를 검출하도록 구성되는 검출기를 포함할 수 잇다. LIDAR 센서는 코히런트 (coherent)(예컨대, 헤티로다인 검출을 사용함) 또는 비코히런트(incoherent) 검출 모드에서 동작하도록 구성될 수 있다. 이미지 센서는 차량 외부의 환경을 기록하도록 구성되는 스틸 카메라 또는 비디오 카메라가 될 수 있 다. 예를 들어, 이미지 센서는 다수의 카메라들을 포함할 수 있고, 다수의 카메라들은 차량의 내부 및 외부 상의 다수의 위치들에 배치될 수 있다. Odometery 센서는 차량의 위치를 추정하고, 이동 거리를 측정할 수 있다. 예를 들어, Odometery 센서 는 차량의 바퀴의 회전 수를 이용하여 차량의 위치 변화 값을 측정할 수 있다. 저장부는 마그네틱 디스크 드라이브, 광학 디스크 드라이브, 플래쉬 메모리를 포함할 수 있다. 또는 저장 부는 휴대 가능한 USB 데이터 저장 장치가 될 수 있다. 저장부는 본원과 관련되는 예들을 실행하기 위한 시스템 소프트웨어를 저장할 수 있다. 본원과 관련되는 예들을 실행하기 위한 시스템 소프트웨어는 휴대 가능한 저장 매체에 저장될 수 있다. 통신부는 다른 디바이스와 무선으로 통신하기 위한 적어도 하나의 안테나를 포함할 수 있다. 예를 들어, 통신부는 와이파이 또는 블루투스를 통해 무선으로 셀룰러 네트워크 또는 다른 무선 프로토콜 및 시스템과 통신하기 위해 이용될 수 있다. 프로세서에 의해 제어되는 통신부는 무선 신호를 송수신할 수 있다. 예를 들어, 프로세서는, 통신부가 셀룰러 네트워크와 무선 신호를 송수신하기 위해, 저장부에 포함된 프로그램을 실행시킬 수 있다. 입력부는 차량을 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 또한, 입력부는 마이크를 포함할 수 있는 바, 마이크는 차량 의 탑승자로부터 오디오(예를 들어, 음성 명령)를 수신하도록 구성될 수 있다. 출력부는 오디오 신호 또는 비디오 신호를 출력할 수 있으며, 출력 장치는 디스플레이, 및 음향 출력부를 포함할 수 있다. 디스플레이는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레 이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 출력부의 구현 형태에 따라, 출력부는 디스플레이를 2개 이상 포함할 수도 있다. 음향 출력부는 통신부로부터 수신되거나 저장부에 저장된 오디오 데이터를 출력한다. 또한, 음 향 출력부에는 스피커(speaker), 버저(Buzzer) 등이 포함될 수 있다. 입력부 및 출력부는 네트워크 인터페이스를 포함할 수 있고, 터치 스크린으로 구현될 수 있다. 프로세서는, 저장부에 저장된 프로그램들을 실행함으로써, 센싱부, 통신부, 입력부, 저장부, 및 출력부를 전반적으로 제어할 수 있다. 상기 살펴 본 실시 예들에 따른 장치는 프로세서, 프로그램 데이터를 저장하고 실행하는 메모리, 디스크 드라이 브와 같은 영구 저장부(permanent storage), 외부 장치와 통신하는 통신 포트, 터치 패널, 키(key), 버튼 등과 같은 사용자 인터페이스 장치 등을 포함할 수 있다. 소프트웨어 모듈 또는 알고리즘으로 구현되는 방법들은 상기 프로세서상에서 실행 가능한 컴퓨터가 읽을 수 있는 코드들 또는 프로그램 명령들로서 컴퓨터가 읽을 수 있 는 기록 매체 상에 저장될 수 있다. 여기서 컴퓨터가 읽을 수 있는 기록 매체로 마그네틱 저장 매체(예컨대, ROM(read-only memory), RAM(random-access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판독 매체(예 컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있는 기록 매체 는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행 될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 본 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들은 특정 기능들을 실행하는 다양한 개수의 하드웨어 또는/및 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 실시 예 는 하나 이상의 마이크로프로세서들의 제어 또는 다른 제어 장치들에 의해서 다양한 기능들을 실행할 수 있는, 메모리, 프로세싱, 로직(logic), 룩 업 테이블(look-up table) 등과 같은 직접 회로 구성들을 채용할 수 있다. 구성 요소들이 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행될 수 있는 것과 유사하게, 본 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조합으로 구현되는 다양한 알고리즘을 포함하 여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기 능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 실시 예는 전자 적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. “매커니즘”, “ 요소”, “수단”, “구성”과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 상기 용어는 프로세서 등과 연계하여 소프트웨어의 일련의 처리들(routines)의 의미를 포함할 수 있다. 본 개시에서 설명된 특정 실행들은 일 실시예 일 뿐이며, 어떠한 방법으로도 본 개시의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 및 상기 시스템들의 다 른 기능적인 측면들의 기재는 생략될 수 있다."}
{"patent_id": "10-2019-0056554", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시에서 모든 예들 또는 예시적인 용어의 사용은 단순히 본 개시를 상세히 설명하기 위한 것으로서 특허청 구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 개시의 범위가 한정되는 것은 아니 다. 또한, “필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 개시에 기재된 구성 요소들은 본 개시 의 실행을 위하여 반드시 필요한 구성 요소가 아닐 수 있다. 본 개시의 실시 예들과 관련된 기술 분야에서 통상의 지식을 가진 자는 상기 기재의 본질적인 특성에서 벗어나 지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 본 개시는 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 본 개시는 명세서에 기재된 특정 한 실시 형태에 의해 한정되는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물이 본 개시에 포함되는 것으로 이해되어야 한다. 그러므로, 개시된 실시예들은 한정적인 관점이 아닌 설 명적 관점에서 이해되어야 한다. 본 개시의 범위는 발명의 상세한 설명보다는 특허 청구 범위에 의하여 나타나며, 특허 청구 범위의 의미 및 범 위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으로 해 석되어야 한다. 본 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. \"부\", \"모듈\"은 어드레싱될 수 있는 저장 매체에 저장되며 프로세서에 의해 실행될 수 있는 프로그램에 의해 구 현될 수도 있다. 예를 들어, “부”, \"모듈\" 은 소프트웨어 구성 요소들, 객체 지향 소프트웨어 구성 요소들, 클래스 구성 요소 들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테 이블들, 어레이들 및 변수들에 의해 구현될 수 있다. 본 명세서에서, \"A는 a1, a2 및 a3 중 하나를 포함할 수 있다\"는 기재은, A라는 엘리먼트(element)에 포함될 수 있는 예시적인 엘리먼트가 a1, a2 또는 a3라는 넓은 의미이다. 상기 기재로 인해 엘리먼트 A를 구성할 수 있는 엘리먼트가 반드시 a1, a2 또는 a3로 국한된다는 것은 아니다. 따라서 A를 구성할 수 있는 엘리먼트가, a1, a2 및 a3 이외에 예시되지 않은 다른 엘리먼트들을 배제한다는 의 미로, 배타적으로 해석되지 않음에 유의하여야 한다. 또한, 상기 기재는, A는 a1를 포함하거나, a2를 포함하거나, 또는 a3를 포함할 수 있다는 의미이다. 상기 기재 가 A를 구성하는 엘리먼트들이 반드시 소정 집합 내에서 선택적으로 결정된다는 것을 의미하지는 않는다. 예를 들어 상기 기재가, 반드시 a1, a2 및 a3를 포함하는 집합으로부터 선택된 a1, a2, 또는 a3가 컴포넌트 A를 구성 한다는 것으로, 제한적으로 해석되지 않음에 유의하여야 한다. 또한 본 명세서에서, \"a1, a2 및 a3 중 적어도 하나\"라는 기재는, \"a1\", \"a2\", \"a3\", \"a1 및 a2\", \"a1 및 a3\", \"a2 및 a3\", 및 \"a1, a2 및 a3\" 중에서 한 가지를 나타낸다. 따라서, \"a1 중 적어도 하나, a2 중 적어도 하나 및 a3 중 적어도 하나\"라고 명시적으로 기재되지 않는 이상, \"a1, a2 및 a3 중 적어도 하나\"라는 기재는 \"a1 중 적어도 하나\", \"a2 중 적어도 하나\" 및 \"a3 중 적어도 하나\"라고 해석되지 않음에 유의하여야 한다."}
{"patent_id": "10-2019-0056554", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른 차량의 주행을 보조하는 전자 장치가 동작하는 일 예를 개략적으로 설명하기 위한 도 면이다. 도 2는 일 실시 예에 따라 전자 장치의 동작 방법의 흐름도이다. 도 3은 일 실시 예에 따라 전자 장치와 복수의 차량의 동작 방법의 흐름도이다. 도 4는 일 실시 예에 따라 복수의 차량이 주행 중 영상을 촬영하는 예를 설명하기 위한 도면이다. 도 5는 일 실시 예에 따라 복수의 차량이 촬영한 복수의 영상의 예를 설명하기 위한 도면이다. 도 6은 일 실시 예에 따라 영상을 데이터 인식 모델의 학습 데이터로 이용하는 예를 설명하기 위한 도면이다. 도 7은 일 실시 예에 따라 제1 객체와 제2 객체가 동일한 객체인지 판단하는 예를 설명하기 위한 흐름도이다. 도 8은 일 실시 예에 따라 제1 객체와 제2 객체가 동일한 객체인지 판단하는 예를 설명하기 위한 도면이다. 도 9는 일 실시 예에 따라 객체의 인식률에 따라 영상을 선택하는 일 예를 설명하기 위한 흐름도이다.도 10은 일 실시 예에 따라 객체의 인식률에 따라 영상을 선택하는 다른 일 예를 설명하기 위한 흐름도이다. 도 11은 일 실시 예에 따라 객체의 인식률에 따라 영상을 선택하는 일 예를 설명하기 위한 도면이다. 도 12는 일 실시 예에 따른 전자 장치의 블록 구성도(block diagram)이다. 도 13은 일 실시 예에 따른 전자 장치의 프로세서의 블록도이다. 도 14는 일 실시 예에 따른 데이터 학습부의 블록도이다. 도 15는 일 실시 예에 따른 데이터 인식부의 블록도이다. 도 16은 일 실시 예에 따른 전자 장치가 외부 서버와 서로 연동함으로써 데이터를 학습하고 인식하는 예시를 나 타내는 도면이다. 도 17은 일 실시 예에 따른 차량의 블록 구성도(block diagram)이다."}
