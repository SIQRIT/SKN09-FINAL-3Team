{"patent_id": "10-2021-0094528", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0059396", "출원번호": "10-2021-0094528", "발명의 명칭": "뉴럴 네트워크 가속기 및 그의 동작 방법", "출원인": "한국전자통신연구원", "발명자": "양정민"}}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "외부 장치로부터 뉴럴 네트워크 알고리즘의 제 1 층위에 대한 연산을 지시하는 제 1 명령어를 분석하는 명령어분석기;상기 명령어 분석기의 제어 하에, 상기 제 1 층위에 대한 연산을 수행하는 다수의 연산기들을 포함하는 다형연산기 어레이;상기 명령어 분석기의 제어 하에, 상기 외부 장치 및 외부 메모리와 통신하는 인터페이스;내부 메모리;상기 명령어 분석기의 제어 하에, 상기 인터페이스를 통해 상기 외부 메모리로부터 수신된 데이터를 상기 내부메모리에 저장하는 형변환 데이터 이동기; 및상기 명령어 분석기의 제어 하에, 상기 내부 메모리에 저장된 데이터 또는 상기 다형연산기 어레이에 의해 생성된 데이터의 변환을 수행하는 내부 형변환기를 포함하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 다형연산기 어레이의 상기 다수의 연산기들 중 제 1 연산기는 10-비트 덧셈기, 5-비트 덧셈기, 10-비트 곱셈기, 및 4-비트 곱셈기를 포함하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 제 1 층위보다 한 층위만큼 선행하여 연산이 수행된 제 2 층위의 결과 데이터가 상기 외부 메모리에 저장된 것에 응답하여, 상기 인터페이스는 상기 외부 메모리로부터 상기 제 2 층위의 결과 데이터를 읽고 그리고 상기 형변환 데이터 이동기로 전달하되,상기 제 2 층위의 결과 데이터는 상기 제 2 층위에 대한 상기 연산의 결과를 포함하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 제 1 층위에서 요구하는 데이터 타입의 총 비트수가 상기 제 2 층위에서 요구하는 데이터 타입의 총 비트수보다 큰 것에 응답하여, 상기 형변환 데이터 이동기는:상기 제 2 층위의 결과 데이터의 형변환을 수행하고, 그리고상기 형변환된 제 2 층위의 결과 데이터를 상기 내부 메모리에 저장하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 제 1 층위에서 요구하는 데이터 타입의 총 비트수가 상기 제 2 층위에서 요구하는 데이터 타입의 총 비트수보다 큰 것에 응답하여, 상기 형변환 데이터 이동기는 상기 제 2 층위의 결과 데이터를 상기 내부 메모리에저장하고, 그리고상기 내부 형변환기는 상기 내부 메모리에 저장된 상기 제 2 층위의 결과 데이터의 형변환을 수행하고, 그리고상기 형변환된 제 2 층위의 결과 데이터를 상기 다형연산기 어레이로 전달하는 뉴럴 네트워크 가속기.공개특허 10-2022-0059396-3-청구항 6 제 1 항에 있어서,상기 제 1 층위보다 한 층위만큼 선행하여 연산이 수행된 제 2 층위의 결과 데이터가 상기 내부 메모리에 저장된 것에 응답하여, 상기 내부 형변환기는:상기 내부 메모리에 저장된 상기 제 2 층위의 결과 데이터에 대해 형변환을 수행하고, 그리고 상기 형변환된 제 2 층위의 결과 데이터를 상기 다형연산기 어레이로 전달하되,상기 제 2 층위의 결과 데이터는 상기 제 2 층위에 대한 상기 연산의 결과를 포함하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 제 1 층위보다 한 층위만큼 후행하여 연산이 수행될 제 3 층위에서 요구하는 데이터 타입의 총 비트 수가상기 제 1 층위에서 요구하는 데이터 타입의 총 비트 수보다 큰 것에 응답하여, 상기 제 1 층위의 결과 데이터는 상기 내부 메모리 또는 상기 외부 메모리에 저장되되,상기 제 1 층위의 결과 데이터는 상기 다형연산기 어레이에 의해 수행된 상기 제 1 층위에 대한 상기 연산의 결과를 포함하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 제 1 층위보다 한 층위만큼 후행하여 연산이 수행될 제 3 층위에서 요구하는 데이터 타입의 총 비트 수가상기 제 1 층위에서 요구하는 데이터 타입의 총 비트 수보다 작은 것에 응답하여,상기 내부 형변환기는:상기 제 1 층위의 결과 데이터의 형변환을 수행하고, 그리고상기 형변환된 제 1 층위의 결과 데이터를 상기 내부 메모리에 저장하되,상기 제 1 층위의 결과 데이터는 상기 다형연산기 어레이에 의해 수행된 상기 제 1 층위에 대한 상기 연산의 결과를 포함하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 제 1 층위보다 한 층위만큼 후행하여 연산이 수행될 제 3 층위에서 요구하는 데이터 타입의 총 비트 수가상기 제 1 층위에서 요구하는 데이터 타입의 총 비트 수보다 작은 것에 응답하여,상기 형변환 데이터 이동기는:상기 제 1 층위의 결과 데이터의 형변환을 수행하고, 그리고상기 형변환된 제 1 층위의 결과 데이터를 상기 인터페이스로 전달하고, 그리고상기 인터페이스는 상기 형변환된 제 1 층위의 결과 데이터를 상기 외부 메모리에 저장하되,상기 제 1 층위의 결과 데이터는 상기 다형연산기 어레이에 의해 수행된 상기 제 1 층위에 대한 상기 연산의 결과를 포함하는 뉴럴 네트워크 가속기."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "뉴럴 네트워크 알고리즘을 처리하기 위한 연산들을 수행하는 다형연산기 어레이, 내부 메모리, 외부 메모리에저장된 데이터를 상기 내부 메모리로 전달하는 형변환 데이터 이동기, 및 상기 내부 메모리에 저장된 데이터 또는 상기 다형연산기 어레이에 의해 생성된 데이터의 형변환을 수행하는 내부 형변환기를 포함하는 뉴럴 네트워크 가속기의 동작 방법에 있어서:공개특허 10-2022-0059396-4-외부 장치로부터 뉴럴 네트워크 알고리즘의 제 1 층위에 대한 연산을 지시하는 제 1 명령어를 분석하는 단계;상기 제 1 층위보다 한 층위만큼 선행하여 연산이 수행된 제 2 층위의 결과 데이터의 형변환을 상기 형변환 데이터 이동기 또는 상기 내부 형변환기 중 어느 하나에 의해 수행하는 단계;상기 제 2 층위의 결과 데이터에 기반하여, 상기 제 1 층위에 대한 상기 연산을 수행하는 단계; 및상기 제 1 층위에 대한 상기 연산의 결과를 포함하는 상기 제 1 층위의 결과 데이터를 출력하는 단계를 포함하는 뉴럴 네트워크 가속기의 동작 방법."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제 2 층위의 결과 데이터가 상기 외부 메모리에 저장되고, 그리고 상기 제 1 층위에서 요구하는 데이터 타입의 총 비트수가 상기 제 2 층위에서 요구하는 데이터 타입의 총 비트 수보다 큰 것에 응답하여, 상기 제 2 층위의 결과 데이터의 상기 형변환은 상기 형변환 데이터 이동기에 의해 수행되는 뉴럴 네트워크 가속기의 동작방법."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 제 2 층위의 결과 데이터가 상기 외부 메모리에 저장되고, 그리고 상기 제 1 층위에서 요구하는 데이터 타입의 총 비트수가 상기 제 2 층위에서 요구하는 데이터 타입의 총 비트 수보다 작은 것에 응답하여, 상기 제 2층위의 결과 데이터의 상기 형변환은 상기 내부 형변환기에 의해 수행되는 뉴럴 네트워크 가속기의 동작 방법."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 제 2 층위의 결과 데이터가 상기 내부 메모리에 저장된 것에 응답하여, 상기 제 2 층위의 결과 데이터의상기 형변환은 상기 내부 형변환기에 의해 수행되는 뉴럴 네트워크 가속기의 동작 방법."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 제 1 층위의 결과 데이터를 출력하는 단계는:상기 제 1 층위보다 한 층위만큼 후행하여 연산이 수행될 제 3 층위에서 요구하는 데이터 타입의 총 비트 수가상기 제 1 층위에서 요구하는 데이터 타입의 총 비트 수보다 큰 것에 응답하여, 상기 제 1 층위의 결과 데이터를 상기 내부 메모리 또는 상기 외부 메모리에 저장하는 단계를 포함하되,상기 제 1 층위의 결과 데이터는 상기 다형연산기 어레이에 의해 수행된 상기 제 1 층위에 대한 상기 연산의 결과를 포함하는 뉴럴 네트워크 가속기의 동작 방법."}
{"patent_id": "10-2021-0094528", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 10 항에 있어서,상기 제 1 층위의 결과 데이터를 출력하는 단계는:상기 제 1 층위보다 한 층위만큼 후행하여 연산이 수행될 제 3 층위에서 요구하는 데이터 타입의 총 비트 수가상기 제 1 층위에서 요구하는 데이터 타입의 총 비트 수보다 작은 것에 응답하여, 상기 제 1 층위의 결과 데이터의 형변환을 수행하는 단계; 및상기 형변환된 제 1 층위의 결과 데이터를 상기 내부 메모리 또는 상기 외부 메모리에 저장하는 단계를 포함하되,상기 제 1 층위의 결과 데이터는 상기 다형연산기 어레이에 의해 수행된 상기 제 1 층위에 대한 상기 연산의 결과를 포함하는 뉴럴 네트워크 가속기의 동작 방법.공개특허 10-2022-0059396-5-"}
{"patent_id": "10-2021-0094528", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "뉴럴 네트워크 가속기 및 그의 동작 방법이 개시된다. 뉴럴 네트워크 가속기는: 외부 장치로부터 뉴럴 네트워크 알고리즘의 제 1 층위에 대한 연산을 지시하는 제 1 명령어를 분석하는 명령어 분석기; 상기 명령어 분석기의 제 어 하에, 상기 제 1 층위에 대한 연산을 수행하는 다수의 연산기들을 포함하는 다형연산기 어레이; 상기 명령어 분석기의 제어 하에, 상기 외부 장치 및 외부 메모리와 통신하는 인터페이스; 내부 메모리; 형변환기를 포함하고, 그리고 상기 명령어 분석기의 제어 하에, 상기 인터페이스를 통해 상기 외부 메모리로부터 수신된 데 이터를 상기 내부 메모리에 저장하는 형변환 데이터 이동기; 및 상기 명령어 분석기의 제어 하에, 상기 내부 메 모리에 저장된 데이터 또는 상기 다형연산기 어레이에 의해 생성된 데이터의 변환을 수행하는 내부 형변환기를 포함할 수 있다."}
{"patent_id": "10-2021-0094528", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 복합 정밀도 뉴럴 네트워크 가속기 및 그의 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0094528", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간의 뇌를 모방한 인공지능(Artificial Intelligence, AI) 반도체 설계 기술은 수십 년의 역사를 가지고 있지 만, 기존 실리콘 기반 반도체의 연산량 한계로 인해 정체된 상태였다. 입력 값에 대한 가중치(Weight)를 학습하 는 과정을 통해 뉴런(Neuron)의 신경 전달을 모델링한 신경망(Neural Network)는 오래 전에 제안되었지만, 반도 체 기술의 한계로 인하여 각광받지 못하였다. 하지만, 최근에 지속적인 반도체 공정 미세화 및 고도화에 따라, 인공 지능 반도체 설계 기술 및 신경망 모델이 다시 각광받고 있다. 인공지능 반도체는 대량의 입력 정보를 이용하여 특정 서비스에 최적화된 사고 및 추론, 행동 및 동작을 구현한 다. 이러한 인공지능 반도체 기술은 다층신경회로망(MLP; multi-layer perceptron)과 신경망(Neural Network) 회로의 개념이 도입되면서 인공지능 기술의 응용 분야가 다양화 및 다변화되고 있다. 지능형 개인서비스를 위한 디바이스(모바일 기기, 지능형 스마트폰 등), 자율이동체(자율주행 자동차, 자율이동형 드론, 물품 수송), 서버 형 딥러닝 가속기, 지능형 헬스케어(인공지능 의사, 원격 진료, 웨어러블 헬스케어 기기), 군용장비(무인비행체, 탐지형 로봇), 사회 서비스(금융-예측서비스, 범죄 감시) 등, 인공지능에 의한 기술 혁신 은 ICT소재부품 분야의 거의 모든 곳에 적용될 것으로 예상된다. 인공 지능 컴퓨터는 성능 향상을 위하여, 대량의 CPU 및 GPU 기반의 분산 컴퓨팅 기법을 활용한다. 하지만, 인 공 지능 컴퓨팅에 요구되는 연산량의 증가는 CPU 및 GPU 기반의 아키텍처가 처리 가능한 연산량의 범위를 벗어 나고 있다. 딥러닝(Deep learning)이 적용된 인공 지능은 현재의 모바일 프로세서의 1000배 이상의 성능을 요구 한다. 이러한 성능을 구현하기 위해 제조된 제품은 수 킬로와트(KW) 이상의 전력을 소모하고 있어, 상용화에 어 려움을 겪고 있다. 나아가, 반도체 장치는 현재 공정 스케일링에 대한 물리적 한계에 직면하고 있다. 증가된 연산량에 대응하여, GPU(Graphics Processing Unit)을 고도화한 초병렬 GPU 구조 및 뉴럴 네트워크 연산 전용의 가속기 구조가 제안되고 있다. 이러한 구조들은 뉴럴 네트워크 연산에서 높은 비중을 차지하는 다차원 행렬곱 연산 및 합성곱 연산을 가속하기 위한 구조일 수 있다."}
{"patent_id": "10-2021-0094528", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 효율적인 행렬 합성곱 연산을 제공하는, 복합 정밀도를 지원하는 뉴럴 네트워크 가속기 및 그 의 동작 방법을 제공하는 데 있다."}
{"patent_id": "10-2021-0094528", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 뉴럴 네트워크 가속기는: 외부 장치로부터 뉴럴 네트워크 알고리즘의 제 1 층위에 대한 연산을 지시하는 제 1 명령어를 분석하는 명령어 분석기; 상기 명령어 분석기의 제어 하에, 상기 제 1 층 위에 대한 연산을 수행하는 다수의 연산기들을 포함하는 다형연산기 어레이; 상기 명령어 분석기의 제어 하에, 상기 외부 장치 및 외부 메모리와 통신하는 인터페이스; 내부 메모리; 상기 명령어 분석기의 제어 하에, 상기 인터페이스를 통해 상기 외부 메모리로부터 수신된 데이터를 상기 내부 메모리에 저장하는 형변환 데이터 이동 기; 및 상기 명령어 분석기의 제어 하에, 상기 내부 메모리에 저장된 데이터 또는 상기 다형연산기 어레이에 의 해 생성된 데이터의 변환을 수행하는 내부 형변환기를 포함할 수 있다. 본 개시의 일 실시 예에 따른 뉴럴 네트워크 알고리즘을 처리하기 위한 연산들을 수행하는 다형연산기 어레이, 내부 메모리, 외부 메모리에 저장된 데이터를 상기 내부 메모리로 전달하는 형변환 데이터 이동기, 및 상기 내 부 메모리에 저장된 데이터 또는 상기 다형연산기 어레이에 의해 생성된 데이터의 형변환을 수행하는 내부 형변 환기를 포함하는 뉴럴 네트워크 가속기의 동작 방법은: 외부 장치로부터 뉴럴 네트워크 알고리즘의 제 1 층위에 대한 연산을 지시하는 제 1 명령어를 분석하는 단계; 상기 제 2 층위의 결과 데이터의 형변환을 상기 형변환 데 이터 이동기 또는 상기 내부 형변환기 중 어느 하나에 의해 수행하는 단계; 상기 제 2 층위의 결과 데이터에 기반하여, 상기 제 1 층위에 대한 상기 연산을 수행하는 단계; 및 상기 제 1 층위에 대한 상기 연산의 결과를 포 함하는 상기 제 1 층위의 결과 데이터를 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0094528", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 뉴럴 네트워크 가속기는 뉴럴 네트워크 각 층위에 대해 서로 다른 정밀도를 지원 할 수 있다. 이에 따라, 뉴럴 네트워크 가속기의 연산 효율 및 전력 효율이 개선될 수 있다. 나아가, 본 개시의 일 실시 예에 따른 뉴럴 네트워크 가속기는 각 층위 별로 데이터의 형변환을 수행할 수 있고, 이때 형변환이 수 행되는 시점은 유동적으로 조절될 수 있다. 이에 따라, 뉴럴 네트워크 가속기 내부 메모리의 용량이 절약되고, 뉴럴 네트워크 가속기의 외부 장치와 통신하는 인터페이스의 대역폭이 절약될 수 있다."}
{"patent_id": "10-2021-0094528", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 본 개시의 기술 분야에서 통상의 지식을 가진 자가 본 개시를 용이하게 실시할 수 있을 정도로, 본 개시의 실시 예들이 명확하고 상세하게 기재될 것이다. 이하에서, 첨부한 도면들을 참조하여, 본 개시의 몇몇 실시 예들을 보다 상세하게 설명하고자 한다. 본 개시를 설명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 유사한 구성요소에 대해서는 유사한 참조부호가 사용되고, 그리고 유사한 구성요소에 대해서 중복된 설명은 생략된다. 도 1은 본 개시의 일 실시 예에 따라, 컴퓨팅 장치의 블록도를 도시한다. 도 1을 참조하면, 컴퓨팅 장치 는 컨트롤러, 외부 메모리, 및 뉴럴 네트워크 가속기를 포함할 수 있다. 몇몇 실시 예들에 있 어서, 컴퓨팅 장치는 과학 기술 연산 등과 같은 다양한 분야에서 사용되는 슈퍼 컴퓨팅 장치일 수 있다. 그 러나 본 개시의 범위가 이에 한정되는 것은 아니며, 컴퓨팅 장치는 다양한 연산 기능을 지원하도록 구성된 다양한 종류의 컴퓨팅 장치들을 포함할 수 있다. 예를 들어, 컴퓨팅 장치는 개인용 컴퓨터, 노트북, 태블릿, 스마트폰, 서버, 워크스테이션, 블랙박스, 자동차 전장 시스템 등과 같은 다양한 컴퓨팅 장치 또는 정 보 처리 장치를 포함할 수 있다. 컨트롤러는 컴퓨팅 장치 내에서 수행되는 다양한 동작들을 제어할 수 있다. 예를 들어, 컨트롤러는 뉴럴 네트워크 가속기에서 사용되기 위한 연산 데이터, 또는 뉴럴 네트워크 알고리즘 등을 결정할 수 있다. 다른 예를 들어, 컨트롤러는 외부 메모리에 데이터를 저장하거나, 또는 외부 메모리에 저장 된 데이터를 읽을 수 있다. 외부 메모리는 컨트롤러 또는 뉴럴 네트워크 가속기에 의해, 데이터를 저장할 수 있다. 예를 들어, 외부 메모리는 뉴럴 네트워크 가속기로 입력되기 위한 데이터 또는 뉴럴 네트워크 가속기 의 학습 과정에서 생성 또는 갱신되는 다양한 파라미터들의 데이터를 저장할 수 있다. 몇몇 실시 예들에 있어서, 외부 메모리는 DRAM(Dynamic Random Access Memory)을 포함할 수 있다. 뉴럴 네트워크 가속기는 컨트롤러의 제어에 따라, 뉴럴 네트워크 모델 또는 알고리즘을 학습하거나, 또는 학습된 뉴럴 네트워크 모델에 기반하여 추론을 수행할 수 있다. 뉴럴 네트워크 가속기는 뉴럴 네트워 크 모델 또는 알고리즘을 학습하기 위한 다양한 연산들을 수행하거나, 또는 학습된 뉴럴 네트워크 모델에 기반 하여 추론을 수행하기 위한 다양한 연산들을 수행할 수 있다. 몇몇 실시 예들에 있어서, 뉴럴 네트워크 가속기 는 연산 데이터에 기반하여 합성곱(convolution) 연산을 수행하고, 그리고 연산의 결과를 결과 데이터로서뉴럴 네트워크 가속기의 내부 메모리 또는 외부 메모리에 저장할 수 있다. 뉴럴 네트워크 가속기는 명령어 분석기, 인터페이스, 형변환 데이터 이동기, 내부 메모리 , 내부 형변환기, 및 다형연산기 어레이를 포함할 수 있다. 명령어 분석기는 뉴럴 네트워크 가속기의 동작을 관리할 수 있다. 예를 들어, 명령어 분석기는 외부 장치(예를 들어, 컨트롤러 또는 외부 메모리)로부터 인터페이스를 통해 뉴럴 네트워크 가속 기의 동작을 지시하는 명령어를 수신할 수 있다. 명령어 분석기는 수신된 명령어를 분석하고, 그리고 분석된 명령어에 따라 뉴럴 네트워크 가속기의 인터페이스, 형변환 데이터 이동기, 내부 메모리 , 내부 형변환기, 또는 다형연산기 어레이 등의 동작들을 제어할 수 있다. 몇몇 실시 예들에 있 어서, 명령어 분석기는 뉴럴 네트워크 가속기의 컨트롤러 또는 프로세서로서 지칭될 수 있다. 예를 들어, 명령어 분석기는 행렬 연산의 수행, 데이터의 정밀도 조정, 또는 결과 데이터의 출력 등과 같 이, 뉴럴 네트워크의 어떤 층위(layer)의 연산 방식에 대해 정의된(또는 그러한 연산 방식을 지시하는) 명령어 를 수신할 수 있다. 명령어 분석기는 수신된 명령어를 분석하고, 그리고 분석된 명령어에 응답하여, 뉴럴 네트워크 가속기의 다른 구성 요소들을 제어할 수 있다. 인터페이스는 뉴럴 네트워크 가속기의 외부 장치와 통신할 수 있다. 예를 들어, 인터페이스는 명령어 또는 뉴럴 네트워크 가속기에 의해 처리되기 위한 연산 데이터를 외부 장치로부터 수신할 수 있다. 인터페이스는 뉴럴 네트워크 가속기에 의해 생성된 결과 데이터를 외부 장치로 출력할 수 있다. 예를 들어, 인터페이스는 결과 데이터를 외부 메모리에 저장할 수 있다. 몇몇 실시 예들에 있어서, 인터페 이스는 AXI(Advanced eXtensible Interface) 또는 PCIe(Peripheral Component Interconnect Express) 등 으로 구현될 수 있다. 형변환 데이터 이동기는 인터페이스를 통해 연산(예를 들어, 행렬 연산)을 위한 연산 데이터를 수신 할 수 있다. 형변환 데이터 이동기는 인터페이스를 통해 수신된 외부 장치의 데이터를 내부 메모리 에 저장할 수 있다. 예를 들어, 형변환 데이터 이동기는 데이터의 형변환(또는 정밀도 변환)을 수행 하고, 그리고 형변환된 데이터를 내부 메모리에 저장할 수 있다. 몇몇 실시 예들에 있어서, 형변환 데이터 이동기는 형변환기를 포함하는 DMA(Direct Memory Access)를 포함할 수 있다. 형변환 데이터 이동기(13 0)는 구체적으로 후술될 것이다. 내부 메모리는 인터페이스를 통해 외부 장치로부터 입력된 데이터, 명령어 분석기에 의해 처리 되고자 하는 명령어들, 또는 다형연산기 어레이에 의해 생성된 결과 데이터 등을 저장할 수 있다. 몇몇 실 시 예들에 있어서, 내부 메모리는 DRAM 또는 SRAM(Static Random Access Memory) 등으로서 구현될 수 있 다. 내부 형변환기는 다형연산기 어레이로 입력되기 위한 데이터의 형변환을 수행할 수 있다. 예를 들어, 내부 형변환기는 내부 메모리에 저장된 연산 데이터 또는 내부 메모리에 저장된 이전 층위의 결 과 데이터의 정밀도를 변환할 수 있다. 내부 형변환기는 형변환된 데이터를 다형연산기 어레이로 전 달할 수 있다. 다형연산기 어레이는 연산 데이터에 대해 다양한 연산들을 수행할 수 있다. 예를 들어, 다형연산기 어레이 는 다수의 연산 데이터에 대해 병렬 연산 또는 행렬 연산을 수행할 수 있다. 다형연산기 어레이는 행 렬 연산의 가속을 위한 다수의 다형연산기들로 구성된 어레이(들)를 포함할 수 있다. 다형연산기 어레이는 연산들의 수행으로 생성되는 결과 데이터를 내부 메모리에 저장하거나, 또는 외부 메모리에 저장하기 위해 인터페이스로 전달할 수 있다. 다형연산기 어레이의 동작은 구체적으로 후술될 것이다. 다형연산기 어레이에 의해 처리되고자 하는 연산 데이터는 입력 데이터 및 커널(kernel) 데이터를 포함할 수 있다. 입력 데이터는 프레임별 단위 이미지 또는 프레임별 단위 음성 행렬 데이터를 포함할 수 있다. 커널 데이터는 학습이 종료된 신경망의 경우 정해진 값을 가진 특수한 행렬 데이터일 수 있다. 다형연산기 어레이 는 다수의 입력 데이터에 대한 실시간 신경망 연산을 통해 실시간 영상, 음성 등의 데이터를 처리할 수 있 다. 이하에서, 뉴럴 네트워크 가속기에 의해 가속되는(또는 처리되는) 뉴럴 네트워크 알고리즘에 대하여, 다음 과 같은 전제들이 가정될 것이다: 1) 뉴럴 네트워크 알고리즘은 다수의 층위들로 구성될 수 있고 그리고 각 층 위에 대하여, 연산의 대상이 되는 행렬의 크기는 미리 결정될 수 있다; 2) 뉴럴 네트워크 알고리즘의 각 층위에 대하여, 커널 데이터는 뉴럴 네트워크 알고리즘의 학습을 통해 미리 그 값이 결정될 수 있다; 그리고, 3) 뉴럴네트워크 알고리즘의 각 층위에 대하여, 입력 데이터는 응용 프로그램에 따라 이미지, 음성 등과 같이 정해진 형태 그리고, 미리 결정된 값의 범위를 가질 수 있다. 뉴럴 네트워크 가속기에 의해 가속되는 뉴럴 네트워크 알고리즘은 다수의 층위들을 포함할 수 있다. 하나 의 층위에 대하여, 뉴럴 네트워크 가속기는 뉴럴 네트워크 가속기의 동작을 지시하는 명령어를 외부 장치(예를 들어, 컨트롤러)로부터 수신하고, 그리고 수신된 명령어를 분석하여, 연산 데이터에 대한 행렬 연산(예를 들어, 합성곱 연산)을 수행할 수 있다. 뉴럴 네트워크 가속기는 연산 결과를 내부 메모리 에 저장할 수 있다. 뉴럴 네트워크 가속기는 내부 메모리에 저장된 연산 결과를 외부 장치(예를 들어, 외부 메모리 또는 컨트롤러)로 출력하거나, 또는 다음 층위의 연산에 다시 사용할 수 있다. 이후, 다음 층위에 대하여, 뉴럴 네트워크 가속기는 다시 명령어를 수신하고, 수신된 명령어를 분석하여 연산을 수행하고, 그리고 수행된 연산의 결과를 저장 또는 출력할 수 있다. 몇몇 실시 예들에 있어서, 어떤 한 층위에서 사용되는(또는 요구되는) 데이터의 정밀도는 후속 층위에서 사용되 는(또는 요구되는) 데이터의 정밀도와 상이할 수 있다. 뉴럴 네트워크 가속기는 각 층위에 대하여 서로 다 른 정밀도를 지원할 수 있다. 예를 들어, 뉴럴 네트워크 가속기는 어떤 한 층위에 대하여, 이전 층위의 결 과 데이터에 대해 데이터 형변환을 독립적으로 수행하고, 그리고 형변환된 데이터에 대하여 연산을 수행할 수 있다. 이러한 실시 예들에서, 뉴럴 네트워크 가속기는 다양한 데이터 타입에 대한 연산을 지원할 수 있다. 뉴럴 네트워크 가속기는 복합 정밀도(Multi-Precision)를 지원하는 뉴럴 네트워크 가속기로서 이해될 수 있다. 뉴럴 네트워크 가속기에 의해 처리되는 뉴럴 네트워크 알고리즘의 각 층위는 동일한 정밀도를 사용할 필요 가 없을 수 있다. 이로 인해, 모든 층위에서 단일한 정밀도를 사용함에 따라 가장 높은 정밀도로 연산을 수행할 필요 또한 없을 수 있다. 이에 따라, 뉴럴 네트워크 가속기의 연산 효율 및 전력 효율이 개선될 수 있다. 이로 인해, 다형연산기 어레이에 대하여 블랙 실리콘 현상 또는 온도 제어 불가능 현상의 발생이 방지될 수 있다. 몇몇 실시 예들에 있어서, 뉴럴 네트워크 가속기가 형변환을 수행하는 시점은 유동적으로 가변될 수 있다. 예를 들어, 뉴럴 네트워크 가속기는 인터페이스 및 내부 메모리 사이의 형변환 데이터 이동기 에서, 또는 내부 메모리 및 다형연산기 어레이 사이의 형변환기에서 데이터의 형변환을 수 행할 수 있다. 형변환을 적절하게 수행함으로써, 뉴럴 네트워크 가속기는 상대적으로 적은 용량의 데이터 를 내부 메모리에 저장할 수 있다. 이에 따라, 내부 메모리의 용량이 절약될 수 있다. 몇몇 실시 예들에 있어서, 뉴럴 네트워크 가속기는 다형연산기 어레이에 의해 생성된 결과 데이터에 대해 추가적으로 형변환을 수행할 수 있다. 형변환된 데이터는 내부 메모리 또는 외부 메모리에 저장 될 수 있다. 이에 따라, 내부 메모리의 용량이 절약되거나, 또는 인터페이스의 대역폭이 절약될 수 있다. 도 2는 본 개시의 일 실시 예에 따라, 도 1의 다형연산기 어레이를 좀 더 구체적으로 도시한다. 도 3은 본 개시의 일 실시 예에 따라, 도 1의 다형연산기 어레이의 동작을 설명하기 위한 모식도이다. 도 1 내지 도 3을 참조하여, 다형연산기 어레이의 동작이 구체적으로 설명될 것이다. 다형연산기 어레이는 다수의 연산기들을 포함할 수 있다. 예를 들어, 다형연산기 어레이는 N개 의 행 및 N개의 열을 포함하는 N*N 다형연산기 어레이를 포함할 수 있다(N은 자연수). 연산기는 하나 이상 의 하위 연산기들을 포함할 수 있다. 예를 들어, 연산기는 10-비트 덧셈기(161a), 5-비트 덧셈기(161b), 10-비트 곱셈기(161c), 및 4-비트 곱셈기(161d)를 포함할 수 있다. 도 2 및 도 3에 도시된 실시 예에 있어서, 연산기를 포함하는 다형연산기 어레이는 다섯 가지 종류의 연산들 또는 다섯 가지 종류의 데이터 타 입을 지원할 수 있다. 그러나 본 개시의 다형연산기 어레이가 지원하는 데이터 타입의 가지 수는 도시된 실시 예에 한정되지 아니한다. 도 3을 참조하여, 연산기의 하위 연산기들의 동작이 결정될 수 있다. 도 3의 실시 예에서, 뉴럴 네트워크 가속기의 다형연산기 어레이는 16비트 부동소수점(FP16), 8비트 부동 소수점(HFP8), 2비트 고정소수 점(INT2), 4비트 고정소수점(IN4), 및 8비트 고정소수점(INT8)의 데이터 타입들(형들)을 지원할 수 있다. 예를 들어, 뉴럴 네트워크 가속기를 포함하는 컴퓨팅 장치 상에서, 뉴럴 네트워크 가속기에 의해 처리 되는 뉴럴 네트워크 알고리즘의 층위들에 따라 상술된 다섯 가지 유형의 데이터를 처리하는 응용 프로그램들이 구동될 수 있다.각 데이터 타입은 부호, 지수, 및 가수 부분으로 나눠질 수 있다. 이때, 세 부분들의 비트 수의 합이 데이터의 총 비트 수일 수 있다. 몇몇 실시 예에서, 고정소수점의 데이터는 부호 부분은 포함할 수 있으나, 지수 부분은 포함하지 않을 수 있다. 8비트 부동소수점은 IEEE 754(Institute of Electrical and Electronics Engineers Standard for Floating-Point Arithmetic)를 따르지 않는 새롭게 정의된 데이터 타입일 수 있다. 뉴럴 네트워 크 연산이 가수 부분의 높은 정밀도를 요구하지 않음을 고려하여, 8비트 부동소수점은 16비트 부동소수점 데이 터의 가수 부분을 부분적으로 또는 전부 제거한 데이터일 수 있다. 8비트 부동소수점과 같이 새롭게 고안된 데 이터 타입은 대부분 기존 표준인 IEEE 754에 따른 데이터 타입에서 가수 부분이 차지하는 부분을 줄이고 지수 부분을 늘림으로써, 데이터의 표현 범위는 늘리되 데이터의 유효 숫자는 줄이는 방식으로 생성될 수 있다. 도 3의 '덧셈' 열 및 '곱셈' 열은 다형연산기 어레이 내 각 연산기에서 데이터 타입들 각각에 대해 덧셈 연산 및 곱셈 연산이 각각 수행될 때 실제로 연산되는 비트 수를 나타낼 수 있다. 몇몇 실시 예들에 있어 서, 고정소수점 데이터 타입의 경우, 덧셈 연산 및 곱셈 연산이 수행될 때 실제로 연산되는 비트 수는 데이터의 총 비트 수와 동일할 수 있다. 반면에, 부동소수점 데이터 타입의 경우, 덧셈 연산이 수행될 때는 가수 부분의 덧셈 연산만이 수행되고, 그리고 곱셈 연산이 수행될 때는 지수 부분의 덧셈 연산 및 가수 부분의 곱셈 연산이 수행될 수 있으므로, 데이터 타입의 총 비트 수는 실제로 연산되는 비트 수와 상이할 수 있다. 실제 연산이 수행되는 비트 수에 따르면, 덧셈 연산의 경우, 10-비트 덧셈기(161a) 및 5-비트 덧셈기(161b)를 이용하면 5개의 데이터 타입간 덧셈 연산이 모두 수행될 수 있다. 5-비트 덧셈기(161b)는 곱셈 연산이 수행될 때 수행되는 지수 부분 사이의 덧셈 연산에도 사용될 수 있다. 곱셈 연산의 경우, 10-비트 곱셈기(161c) 및 4- 비트 곱셈기(161d)를 이용하면 5개의 데이터 타입의 가수 부분 사이의 곱셈 연산이 모두 수행될 수 있다. 결과 적으로, 도 3의 다섯 가지 데이터 타입들을 지원하기 위해 연산기가 10-비트 덧셈기(161a), 5-비트 덧셈기 (161b), 10-비트 곱셈기(161c), 및 4-비트 곱셈기(161d)를 포함하면, 다형연산기 어레이의 면적 및 전력 효율이 최적화될 수 있다. 각 층위에 대해 서로 다른 정밀도를 지원하기 위해, 뉴럴 네트워크 가속기는 연산 데이터 또는 결과 데이 터의 타입을 변환할 수 있다. 예를 들어, 데이터 형변환은 형변환 데이터 이동기 또는 내부 형변환기(15 0)에 의해 수행될 수 있다. 데이터 형변환의 수행 시점 및 그 수행 주체는 구체적으로 후술될 것이다. 데이터 형변환은 뉴럴 네트워크 가속기에 의해 지원되는 모든 데이터 타입들 사이에서 가능할 수 있다. 예 를 들어, 도 2 및 도 3에 도시된 실시 예에서, 총 20 가지 경우의 데이터 형변환이 발생할 수 있다(5P2). 몇몇 실시 예들에 있어서, 뉴럴 네트워크 가속기에 의해 수행되는 데이터 형변환은 일반적인 데이터 타입의 형 변환과 상이할 수 있다. 예를 들어, 뉴럴 네트워크 알고리즘은 정확한 결과값을 도출하는 것이 아니라, 가장 확 률이 높은 후보를 가려내기 위한 알고리즘이므로, 뉴럴 네트워크 가속기에 의해 수행되는 데이터 형변환은 대수적 의미의 유효 숫자 자체의 유지를 목표로 하지 않을 수 있다. 고정소수점 데이터 타입 사이에서 데이터의 총 비트수가 커지는 형변환의 경우, 상위 비트(Most Significant Bit; MSB)가 확장될 수 있다. 예를 들어, INT2 타입에서 INT4 타입으로의 변환, INT2 타입에서 INT8 타입으로의 변환, 또는 INT4 타입에서 INT8 타입으로의 변환이 수행될 때, 데이터의 상위 비트(들)가 확장될 수 있다. 이에 따라, 기존 데이터 값의 변동이 없을 수 있다. 고정소수점 데이터 타입 사이에서 데이터의 총 비트수가 감소하는 형변환의 경우, 기준점이 이동되는 형변환이 수행될 수 있다. 예를 들어, INT8 타입에서 INT4 타입으로의 변환, INT4 타입에서 INT2 타입으로의 변환, 또는 INT8 타입에서 INT2 타입으로의 변환이 수행될 때, 일반적인 데이터 타입의 형변환이 수행되면 데이터 사이의 상대적 차이가 존재하지 않을 수 있다(예를 들어, 데이터들이 모두 무한대로 변환되거나, 또는 모두 0으로 변환 될 수 있다). 따라서, 형변환이 수행될 때, 데이터의 기준점이 이동될 수 있다. 부동소수점 데이터 타입 사이에서 데이터의 총 비트수가 커지는 형변환의 경우, 데이터의 가수 부분의 상위 비 트가 확장될 수 있다. 예를 들어, HFP8 타입에서 FP16 타입으로의 변환이 수행될 때, 데이터의 가수 부분의 상 위 비트가 확장될 수 있다. 부동소수점 데이터 타입 사이에서 데이터의 총 비트수가 작아지는 형변환의 경우, 데이터의 가수 부분의 하위 비트가 절단될 수 있다. 예를 들어, FP16 타입에서 HFP8 타입으로의 변환이 수행될 때, 데이터의 가수 부분의 하위 비트가 버려질 수 있다. 고정소수점 데이터 타입 및 부동소수점 데이터 타입 사이의 형변환이 수행될 때, 데이터의 표현 범위에 따라 그 형변환의 방식이 결정될 수 있다. 예를 들어, 데이터의 표현 범위가 넓어지는 형변환의 경우(예를 들어, INT 타입에서 HFP으로 또는 INT 타입에서 FP로의 변환), 기존 데이터가 유지될 수 있다. 다른 예를 들어, 데이터의 표 현 범위가 작아지는 형변환의 경우(예를 들어, FP 타입에서 INT 타입으로의 변환, 또는 HFP 타입에서 INT 타입 으로의 변환), 데이터 사이의 상대적 차이의 유지를 목표로, 형변환이 수행될 수 있다. 도 4는 본 개시의 일 실시 예에 따라, 도 1의 형변환 데이터 이동기를 좀 더 구체적으로 도시한다. 도 1 내지 도 4를 참조하면, 형변환 데이터 이동기는 형변환기를 포함할 수 있다. 형변환 데이터 이동기 는 외부 메모리에 저장된 데이터를 인터페이스를 통해 수신하고, 수신된 데이터에 대해 선택적으 로 형변환을 수행하고, 그리고 수신된 데이터 또는 형변환된 데이터를 내부 메모리로 전달할 수 있다. 도 시의 편의를 위해, 인터페이스의 도시가 생략되었다. 형변환기는 데이터 타입 간 형변환을 수행하기 위한 하위 연산기들을 포함할 수 있다. 예를 들어, 형변환 기는 올림기(131a) 및 반올림기(131b)를 포함할 수 있다. 도시된 바와 달리, 형변환기는 도 2 및 도 3을 참조하여 설명된 데이터 타입 간 변환을 수행하기 위한 다른 하위 연산기들(예를 들어, 버림기 등)을 더 포 함할 수 있다. 형변환기는 하위 연산기들을 통해, 명령어 분석기의 제어 하에, 외부 메모리로부 터 수신된 데이터에 대해 형변환을 수행할 수 있다. 몇몇 실시 예들에 있어서, 내부 형변환기는 형변환 데 이터 이동기의 형변환기와 유사하게 구현될 수 있고, 그리고 그와 유사하게 동작할 수 있다. 형변환 데이터 이동기는 형변환기에 의해 형변환된 데이터를 내부 메모리에 저장할 수 있다. 이 후, 내부 메모리에 저장된 형변환된 데이터는 다형연산기 어레이로 제공될 수 있다. 도 5는 본 개시의 일 실시 예에 따라, 도 1의 뉴럴 네트워크 가속기의 동작 방법을 나타내는 흐름도를 도 시한다. 도 1 및 도 5를 참조하면, 뉴럴 네트워크 가속기는 S101 내지 S105 단계들을 수행할 수 있다. 이 하에서, 뉴럴 네트워크 가속기에 의해 연산되는 뉴럴 네트워크 알고리즘의 각 층위의 데이터 타입은 컨트 롤러 또는 명령어 분석기 등에 의해 미리 결정된 것으로 가정될 것이다. S101 단계에서, 뉴럴 네트워크 가속기는 연산을 수행하기 위한 명령어를 분석할 수 있다. 예를 들어, 뉴럴 네트워크 가속기의 인터페이스는 외부 장치(예를 들어, 컨트롤러)로부터 제 1 층위에 대해 다형 연산기 어레이에 의해 수행되고자 하는 연산을 지시하는 동작 명령어를 수신할 수 있다. 명령어 분석기 는 수신된 동작 명령어를 분석할 수 있다. S102 단계에서, 뉴럴 네트워크 가속기는 이전 층위의 결과 데이터의 위치를 판단할 수 있다. 예를 들어, 뉴럴 네트워크 가속기는 제 2 층위의 결과 데이터의 입력을 지시하는 입력 명령어를 더 수신할 수 있다. 뉴럴 네트워크 가속기는 입력 명령어를 분석하고, 그리고 분석된 입력 명령어에 응답하여, 외부 메모리 로부터 제 1 층위보다 한 층위만큼 선행하여 연산이 수행된 제 2 층위의 결과 데이터를 수신하거나 또는 내 부 메모리로부터 제 2 층위의 결과 데이터를 로드할 수 있다. S103 단계에서, 뉴럴 네트워크 가속기는 S102 단계에서 판단된 위치에 기반하여, 이전 층위의 결과 데이터 에 대해 형변환을 수행할 수 있다. 예를 들어, 제 1 층위의 데이터 타입 및 제 2 층위의 데이터 타입이 상이한 것에 응답하여, 제 2 층위의 결과 데이터에 대해 형변환이 수행될 수 있다. 제 2 층위의 결과 데이터의 형변환 은 형변환 데이터 이동기 또는 내부 형변환기 중 어느 하나에 의해 수행될 수 있다. 제 2 층위의 결 과 데이터의 형변환을 수행하는 주체는 S102 단계의 판단 결과에 따라 결정될 수 있다. 제 2 층위의 결과 데이 터의 형변환은 도 6을 참조하여 구체적으로 후술될 것이다. S104 단계에서, 뉴럴 네트워크 가속기는 이전 층위의 결과 데이터에 기반하여, 연산을 수행할 수 있다. 예 를 들어, 뉴럴 네트워크 가속기의 다형연산기 어레이는 S102 단계에서 검색된 제 2 층위의 결과 데이 터 또는 S103 단계에서 형변환된 제 2 층위의 결과 데이터에 대해, S101 단계에서 분석된 동작 명령어에 대응하 는 연산을 수행할 수 있다. S105 단계에서, 뉴럴 네트워크 가속기는 결과 데이터를 출력할 수 있다. 예를 들어, S101 단계에서 분석된 명령어에 응답하여, 뉴럴 네트워크 가속기는 S104 단계에서 수행된 연산의 결과를 제 1 층위의 결과 데이 터로서 내부 메모리 또는 외부 메모리에 저장할 수 있다. 다른 예를 들어, 뉴럴 네트워크 가속기(10 0)는 데이터의 출력을 명령하는 출력 명령어를 수신하고, 출력 명령어를 명령어 분석기를 통해 분석하고, 그리고 분석된 출력 명령어에 응답하여, S104 단계에서 수행된 연산의 결과를 제 1 층위의 결과 데이터로서 내 부 메모리 또는 외부 메모리에 저장할 수 있다. 몇몇 실시 예들에 있어서, 뉴럴 네트워크 가속기는 제 1 층위보다 한 층위만큼 후행하여 연산이 수행될 제 3 층위의 데이터 타입에 응답하여, 결과 데이터에 대해 형변환을 수행하고, 그리고 형변환된 결과 데이터를 내부 메모리 도는 외부 메모리에 저장할 수 있다. 제 1 층위의 결과 데이터의 형변환은 도 7을 참조하여 구체적으로 후술될 것이다. 도 6은 본 개시의 일 실시 예에 따라, 도 1의 뉴럴 네트워크 가속기의 동작 방법을 좀 더 구체적으로 도시 한다. 도 1, 도 5, 및 도 6을 참조하면, 제 1 층위의 데이터 타입 및 제 2 층위의 데이터 타입이 상이한 것에 응답하여, 뉴럴 네트워크 가속기는 S201 내지 S205 단계들을 더 수행할 수 있다. S201 단계에서, 뉴럴 네트워크 가속기는 이전 층위의 결과 데이터의 위치를 판단할 수 있다. 예를 들어, 뉴럴 네트워크 가속기는 S102 단계와 유사한 방식으로 S201 단계를 수행할 수 있다. 제 2 층위의 결과 데 이터가 외부 메모리에 위치할 때, 뉴럴 네트워크 가속기는 S202 내지 S204 단계들을 수행할 수 있다. 제 2 층위의 결과 데이터가 내부 메모리에 위치할 때, 뉴럴 네트워크 가속기는 S205 단계를 수행할 수 있다. S202 단계에서, 뉴럴 네트워크 가속기는 수행할 형변환의 종류를 판단할 수 있다. 예를 들어, 뉴럴 네트워 크 가속기의 명령어 분석기는 제 1 층위의 데이터 타입 및 제 2 층위의 데이터 타입을 비교함으로써, 제 2 층위의 결과 데이터에 대해 수행되어야 할 형변환의 종류를 판단할 수 있다. 다른 예를 들어, 뉴럴 네트워크 가속기는 외부 장치로부터 뉴럴 네트워크 가속기에 의해 제 2 층위의 결과 데이터에 대해 수행되어야 할 형변환의 종류를 지시하는 명령어를 수신할 수 있다. 몇몇 실시 예들에 있어 서, 상기 형변환을 지시하는 명령어는 S101 단계에서 수신된 명령어에 포함될 수도 있다. 상기 형변환을 지시하 는 명령어에 기반하여, 뉴럴 네트워크 가속기는 형변환의 종류를 판단할 수 있다. 제 2 층위의 결과 데이터의 비트 수를 증가시키는 형변환이 수행되어야 한다고 판단되는 것에 응답하여, 뉴럴 네트워크 가속기는 S203 단계를 수행할 수 있다. 예를 들어, 제 1 층위의 데이터 타입의 총 비트 수가 제 2 층위의 데이터 타입의 총 비트 수보다 큰 것 또는 제 1 층위의 데이터 타입의 표현 범위가 제 2 층위의 데이 터 타입의 표현 범위보다 큰 것에 응답하여, 뉴럴 네트워크 가속기는 S203 단계를 수행할 수 있다. 다른 예를 들어, 제 2 층위의 결과 데이터의 총 비트 수를 증가시키는 형변환 또는 제 2 층위의 결과 데이터의 표현 범위를 증가시키는 형변환이 수행되어야 한다고 판단되는 것에 응답하여, 뉴럴 네트워크 가속기는 S203 단 계를 수행할 수 있다. S203 단계에서, 뉴럴 네트워크 가속기의 내부 형변환기에 의해 제 2 층위의 결과 데이터의 형변환이 수행될 수 있다. 예를 들어, 형변환 데이터 이동기는 외부 메모리에 저장된 제 2 층위의 결과 데이터 를 그대로 내부 메모리에 저장할 수 있다. 즉, 형변환 데이터 이동기는 제 2 층위의 결과 데이터의 형변환을 수행하지 않을 수 있다. 이후, 내부 메모리에 저장된 제 2 층위의 결과 데이터에 대해 내부 형변 환기에 의해 형변환이 수행될 수 있다. 내부 형변환기에 의해 형변환된 제 2 층위의 결과 데이터는 다형연산기 어레이로 전달될 수 있다. S203 단계가 수행됨에 따라, 내부 메모리에 저장되는 제 2 층위의 결과 데이터의 크기는 내부 형변환기 에 의해 형변환된 데이터의 크기보다 작을 수 있다. 이에 따라, 상대적으로 작은 크기의 데이터가 내부 메 모리에 저장될 수 있고, 결과적으로 내부 메모리의 저장 용량이 절약될 수 있다. 제 2 층위의 결과 데이터의 비트 수를 감소시키는 형변환이 수행되어야 한다고 판단되는 것에 응답하여, 뉴럴 네트워크 가속기는 S204 단계를 수행할 수 있다. 예를 들어, 제 1 층위의 데이터 타입의 총 비트 수가 제 2 층위의 데이터 타입의 총 비트 수보다 작은 것 또는 제 1 층위의 데이터 타입의 표현 범위가 제 2 층위의 데 이터 타입의 표현 범위보다 작은 것에 응답하여, 뉴럴 네트워크 가속기는 S204 단계를 수행할 수 있다. 다 른 예를 들어, 제 2 층위의 결과 데이터의 총 비트 수를 감소시키는 형변환 또는 제 2 층위의 결과 데이터의 표 현 범위를 감소시키는 형변환이 수행되어야 한다고 판단되는 것에 응답하여, 뉴럴 네트워크 가속기는 S204 단계를 수행할 수 있다. S204 단계에서, 뉴럴 네트워크 가속기의 형변환 데이터 이동기에 의해 제 2 층위의 결과 데이터의 형 변환이 수행될 수 있다. 예를 들어, 형변환 데이터 이동기는 외부 메모리에 저장된 제 2 층위의 결과 데이터에 대해 형변환을 수행할 수 있다. 형변환 데이터 이동기는 형변환된 제 2 층위의 결과 데이터를 내 부 메모리에 저장할 수 있다. 내부 메모리에 저장된 형변환된 제 2 층위의 결과 데이터는 다형연산기 어레이로 전달될 수 있다. S204 단계가 수행됨에 따라, 내부 메모리에 저장되는 형변환된 제 2 층위의 결과 데이터의 크기는 외부 메 모리에 저장된 제 2 층위의 결과 데이터의 크기보다 작을 수 있다. 이에 따라, 상대적으로 작은 크기의 데이터가 내부 메모리에 저장될 수 있고, 결과적으로 내부 메모리의 저장 용량이 절약될 수 있다. S205 단계에서, 뉴럴 네트워크 가속기의 내부 형변환기는 제 2 층위의 결과 데이터에 대해 형변환을 수행할 수 있다. 예를 들어, 내부 형변환기는 내부 메모리에 저장된 제 2 층위의 결과 데이터에 대해, 형변환의 종류에 무관하게, 형변환을 수행할 수 있다. 이후, 내부 형변환기는 형변환된 데이터를 다 형연산기 어레이로 전달할 수 있다. 상술된 방식으로, 뉴럴 네트워크 가속기는 데이터의 형변환을 유동적으로 수행할 수 있다. 예를 들어, 뉴 럴 네트워크 가속기에 의해 데이터의 형변환이 수행되는 시점은, 이전 층위의 결과 데이터의 저장 위치 및 수행할 형변환의 종류에 기반하여 유동적으로 조절될 수 있다. 이에 따라, 뉴럴 네트워크 가속기는 각 층 위 별로 자유롭게 운용될 수 있고, 그리고 내부 메모리의 용량이 절약될 수 있다. 도 7은 본 개시의 다른 실시 예에 따라, 도 1의 뉴럴 네트워크 가속기의 동작 방법을 좀 더 구체적으로 도 시한다. 도 1, 도 5, 및 도 7을 참조하면, 뉴럴 네트워크 가속기는 S301 내지 S303 단계들을 수행할 수 있 다. 뉴럴 네트워크 가속기는 현재 층위의 결과 데이터에 대해 선택적으로 형변환을 수행한 후 내부 메모리 또는 외부 메모리로 저장할 수 있다. S301 단계에서, 다음 층위의 데이터 타입의 비트 수 및 현재 층위의 데이터 타입의 비트 수가 비교될 수 있다. 예를 들어, 뉴럴 네트워크 가속기의 명령어 분석기는 제 3 층위의 데이터 타입의 비트 수를 판단하고, 그리고 제 1 층위의 데이터 타입의 총 비트 수 및 제 3 층위의 데이터 타입의 총 비트 수를 비교할 수 있다. 몇몇 실시 예들에 있어서, 뉴럴 네트워크 가속기의 명령어 분석기는 컨트롤러로부터 미리 제공된 정보에 기반하여, 제 3 층위의 데이터 타입의 비트 수를 판단할 수 있다. 또는, 뉴럴 네트워크 가속기는 외부 장치로부터 뉴럴 네트워크 가속기에 의해 제 3 층위의 데이터 타입의 비트 수에 대한 정보를 포함하 는 명령어를 더 수신할 수 있다. 몇몇 실시 예들에 있어서, 이러한 명령어는 S101 단계에서 수신된 명령어에 포 함될 수도 있다. 이러한 명령어에 기반하여, 뉴럴 네트워크 가속기는 제 3 층위의 데이터 타입의 비트 수 를 판단할 수 있다. 다음 층위의 데이터 타입의 비트 수가 현재 층위의 데이터 타입의 비트 수보다 작은 것에 응답하여, S302 단계 에서, 뉴럴 네트워크 가속기에 의해 현재 층위의 결과 데이터에 대해 형변환이 수행될 수 있다. 예를 들어, 제 3 층위의 데이터 타입의 비트 수가 제 1 층위의 데이터 타입의 비트 수보다 작은 것에 응답하여, 뉴럴 네트워크 가속기의 내부 형변환기 또는 형변환 데이터 이동기에 의해 제 1 층위의 결과 데이터 에 대해 형변환이 수행될 수 있다. 이후, S303 단계에서, 형변환된 제 1 층위의 결과 데이터가 내부 메모리 또는 외부 메모리에 각각 저장될 수 있다. 형변환된 제 1 층위의 결과 데이터는 제 1 층위의 결과 데 이터보다 용량이 작을 수 있다. 따라서, 형변환된 제 1 층위의 결과 데이터가 데이터는 제 1 층위의 결과 데이 터 대신에 내부 메모리에 저장되거나 또는 외부 메모리에 인터페이스를 통해 저장될 수 있다. 결 과적으로 내부 메모리의 용량이 절약되거나 또는 인터페이스의 데이터 대역폭이 절약될 수 있다. 다음 층위의 데이터 타입의 비트 수가 현재 층위의 데이터 타입의 비트 수보다 작은 것에 응답하여, 뉴럴 네트 워크 가속기에 의해 현재 층위의 결과 데이터에 대해 형변환이 수행됨이 없이, S303 단계에서 현재 층위의 결과 데이터가 저장될 수 있다. 예를 들어, 제 3 층위의 데이터 타입의 비트 수가 제 1 층위의 데이터 타입의 비트 수보다 크거나 같은 것에 응답하여, 뉴럴 네트워크 가속기는 제 1 층위의 결과 데이터에 대한 형변환 을 수행하지 않고, 제 1 층위의 결과 데이터를 그대로 내부 메모리 또는 외부 메모리에 저장할 수 있 다. 몇몇 실시 예들에 있어서, S301 단계는 컴퓨팅 장치의 다른 구성 요소(예를 들어, 컨트롤러)에 의해 수 행될 수도 있다. 이러한 실시 예들에서, 뉴럴 네트워크 가속기는 다음 층위의 데이터 타입의 비트 수가 현 재 층위의 데이터 타입의 비트 수보다 작은 것에 응답하여 S302 단계의 수행을 지시하는 출력 명령어 또는 다음 층위의 데이터 타입의 비트 수가 현재 층위의 데이터 타입의 비트 수보다 크거나 같은 것에 응답하여 S303 단계 의 수행을 지시하는 출력 명령어를 수신할 수 있다. 수신되는 출력 명령어에 응답하여, 뉴럴 네트워크 가속기 는 S302 단계 또는 S303 단계를 수행할 수 있다. 상술된 내용은 본 개시를 실시하기 위한 구체적인 실시 예들이다. 본 개시는 상술된 실시 예들뿐만 아니라, 단 순하게 설계 변경되거나 용이하게 변경할 수 있는 실시 예들 또한 포함할 것이다. 또한, 본 개시는 실시 예들을 이용하여 용이하게 변형하여 실시할 수 있는 기술들도 포함될 것이다. 따라서, 본 개시의 범위는 상술된 실시예들에 국한되어 정해져서는 안 되며 후술하는 특허청구범위뿐만 아니라 이 발명의 특허청구범위와 균등한 것들 에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0094528", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따라, 컴퓨팅 장치의 블록도를 도시한다. 도 2는 본 개시의 일 실시 예에 따라, 도 1의 다형연산기 어레이를 좀 더 구체적으로 도시한다. 도 3은 본 개시의 일 실시 예에 따라, 도 1의 다형연산기의 어레이의 동작을 설명하기 위한 모식도이다. 도 4는 본 개시의 일 실시 예에 따라, 도 1의 형변환 데이터 이동기를 좀 더 구체적으로 도시한다. 도 5는 본 개시의 일 실시 예에 따라, 도 1의 뉴럴 네트워크 장치의 동작 방법을 나타내는 흐름도를 도시한다. 도 6은 본 개시의 일 실시 예에 따라, 도 1의 뉴럴 네트워크 가속기의 동작 방법을 좀 더 구체적으로 도시한다. 도 7은 본 개시의 다른 실시 예에 따라, 도 1의 뉴럴 네트워크 가속기의 동작 방법을 좀 더 구체적으로 도시한 다."}
