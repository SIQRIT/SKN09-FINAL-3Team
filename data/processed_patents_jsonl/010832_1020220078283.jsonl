{"patent_id": "10-2022-0078283", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0038083", "출원번호": "10-2022-0078283", "발명의 명칭": "메모리 내 컴퓨팅 가속기 및 비트 단위 활성화 함수를 사용한 인공 신경망 운영 방법", "출원인": "삼성전자주식회사", "발명자": "왕 징"}}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 신경망 운영 방법으로서,메모리 내 컴퓨팅 가속기를 포함하는 인공 신경망을 제공하는 단계로, 상기 인공 신경망은 제 1 복수의 인공 뉴런을 포함하는 은닉 계층을 더 포함하는 단계; 및상기 제 1 복수의 인공 뉴런의 각각에 대해 비트 단위 수정된 정류 선형 유닛 활성화 함수를 사용하여 상기 인공 신경망을 훈련하는 단계로, 상기 비트 단위 수정된 정류 선형 유닛 활성화 함수는, 입력이 임계값보다 작을때 상기 입력에 비례하는 출력을 생성하도록 구성되고, 상기 입력이 상기 임계값보다 클 때 상기 입력과 독립적인 출력을 생성하도록 구성되는 비트 활성화 함수를 포함하는 단계를 포함하고,상기 입력은 연관된 복수의 가중치를 가지는 상기 인공 신경망의 이전 계층의 제 2 복수의 인공 뉴런에 걸쳐,상기 제 2 복수의 인공 뉴런의 각각의 출력과 상기 복수의 가중치의 각각의 1비트의 곱의 합산을 포함하는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 복수의 가중치의 각각은 복수의 비트를 포함하고,상기 비트 단위 수정된 정류 선형 유닛 활성화 함수는 상기 복수의 비트에 걸친 상기 복수의 비트의 각각의 값과 상기 비트 활성화 함수의 상기 출력의 곱의 합산을 포함하는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 비트 활성화 함수는 상기 임계값보다 큰 입력 값에 대해 상기 입력과 독립적인 일정한 출력을 생성하도록구성되는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 일정한 출력은 상기 복수의 가중치에 대한 스케일링 인자의 역수인, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 인공 신경망을 훈련하는 단계는,훈련 데이터 세트에 응답하여 생성된 상기 인공 신경망의 출력에 기반하여 상기 임계값, 상기 스케일링 인자,및 상기 복수의 가중치 중 하나 이상의 값을 조정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 임계값에 기초하여 상기 메모리 내 컴퓨팅 가속기의 하나 이상의 매개변수를 조정하는 단계를 더포함하는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 공개특허 10-2023-0038083-3-상기 하나 이상의 매개변수는 상기 제 2 복수의 인공 뉴런 각각의 출력과 연관된 전압 펄스 폭, 및 상기 복수의가중치 각각의 상기 비트 위치에 각각 대응하는 복수의 출력 라인과 각각 연관된 복수의 로딩 커패시턴스를 포함하는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 메모리 내 컴퓨팅 가속기는 상기 복수의 출력 라인에 연결된 아날로그-디지털 변환기를 포함하고, 상기 방법은,상기 제 2 복수의 인공 뉴런의 상기 각각의 상기 출력에 기반하고 상기 출력 라인의 상기 각각에 인가된 펄스의총 수가 상기 임계값과 같을 때 상기 복수의 출력 라인 각각에 대한 출력 전압(Vout_low)을 결정하는 단계; 및상기 아날로그-디지털 변환기의 최소 기준 전압을 Vout_low와 동일하게 설정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 상기 아날로그-디지털 변환기는 Vout_low보다 작은 전압 값을 최대 출력으로 변환하도록 구성되는, 방법."}
{"patent_id": "10-2022-0078283", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 상기 제 2 복수의 인공 뉴런으로부터의 상기 복수의 출력 및 상기 복수의 가중치는 비 음수(non-negative)인,방법."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "방법은 메모리 내 컴퓨팅 가속기를 포함하는 인공 신경망을 제공하는 단계로, 인공 신경망은 제 1 복수의 인공 뉴런을 포함하는 은닉 계층을 더 포함하는 단계, 및 제 1 복수의 인공 뉴런의 각각에 대해 비트 단위 수정된 정 류 선형 유닛 활성화 함수를 사용하여 인공 신경망을 훈련하는 단계로, 비트 단위 수정된 정류 선형 유닛 활성화 함수는 입력이 임계값보다 작을 때 입력에 비례하는 출력을 생성하도록 구성되고, 입력이 임계값보다 클 때 입력 과 독립적인 출력을 생성하도록 구성되는, 비트 활성화 함수를 포함하는 단계를 포함하고, 입력은 연관된 복수의 가중치를 가지는 인공 신경망의 이전 계층의 제 2 복수의 인공 뉴런에 걸쳐, 제 2 복수의 인공 뉴런의 각각의 출 력과 복수의 가중치의 각각의 1비트의 곱의 합산을 포함한다."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 일반적으로 인공 지능에 관한 것으로, 특히 메모리 내 컴퓨팅 가속기를 포함하는 인공 신경망에 관한 것이다."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망은 일반적으로 동일한 기본적 개념을 기반으로 한다. 분석할 데이터는 이미지 인식 작업을 위한 픽 셀이나 예측 문제를 위한 매개변수와 같이, 노드 배열에 걸쳐 분산될 수 있는 요소로 나뉜다. 인공 신경망은 다 양한 방식으로 서로 연결될 수 있는 두 개 이상의 노드 계층으로 구성될 수 있다. 완전 연결 계층에서, 계층 A의 모든 노드는 계층 B의 모든 노드에 연결된다. 이에 비해 컨볼루션 계층에서는, 계층 A의 작은 부분을 계층 B의 각 노드에 할당하는 필터가 정의된다. 계층 A와 B가 완전히 연결된 예에서, 계 층 A의 각 노드는 데이터 요소를 계층 B의 각 노드로 보낸다. 계층 B의 각 노드는 계층 A 노드로부터 수신된 각 데이터 요소에 데이터 요소가 수신되는 계층 A 노드에 해당하는 각 가중치를 곱한 다음에 계층 A의 모든 노드에 대해서 이들 곱을 합산한다. 다음에 계층 B의 각 노드는 합산에 활성화 함수를 적용하고 출력을 다음 계층의 노 드상에서 전달할 수 있다. 이 과정은 신경망에 있는 계층 수만큼 반복된다. 인공 신경망의 출력은 예를 들어 인공 신경망에 입력 데이터를 여러 범주 중 하나에 할당하는 방법, 질문에 대 한 답변 또는 시스템이 주어진 입력 매개변수 집합에 응답하는 방법에 대한 설명과 같은, 추론을 나타낼 수 있 다. 지도 학습에서, 올바른 최종 결과가 알려지고, 오류는 개별 가중치에 대한 조정을 역전파하도록 사용된다. 대규모 인공 신경망은 각각 잠재적으로 수백 또는 수천 개의 노드를 갖는 5개 이상의 계층을 가질 수 있다. 따 라서 단일 곱셉-누산(MAC) 연산은 비교적 간단할 수 있지만, 여러 번 반복된다. 기존 아키텍처에서, 각 MAC 연 산은 관련 데이터와 가중치를 메모리에서 프로세서로 읽고, 계산을 수행하고, 그 결과를 메모리에 다시 쓰는 것 을 포함하며, 이는 처리 및 에너지 집약적일 수 있다. 메모리 내 컴퓨팅(CIM) 가속기는 MAC 연산 성능 병목 현상을 해결하려고 한다. CIM 가속기에서 전체 계층에 대 한 가중치는 CIM 메모리 어레이에 저장될 수 있다. 입력 데이터 벡터는 모든 노드에 한 번에 적용될 수 있으며,결과는 CIM 어레이의 출력 라인으로부터 읽힌다. 그러나 일부 CIM 가속기에서는, 각 뉴런에 대한 가중치 합을 계산한 후, 신경망 시스템에서 사용되는 활성화 함수는 산술 논리 장치(ALU) 또는 활성화 함수를 구현하기 위한 전용 추가 회로를 사용하여 처리될 수 있다. 이것은 CIM 가속기의 전체 회로 면적을 증가시키고, 전력 소비를 증가시키고고/거나, 신경망 시스템을 사용하여 추론을 생성할 때 지연을 증가시킬 수 있다."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시를 통해 해결하고자 하는 과제는 성능이 향상된 인공 신경망 운영 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일부 실시 예에 따르면, 방법은 메모리 내 컴퓨팅 가속기를 포함하는 인공 신경망을 제공하는 단계 - 상기 인공 신경망은 제 1 복수의 인공 뉴런을 포함하는 은닉 계층을 더 포함함 -; 및 상기 제 1 복수의 인공 뉴 런의 각각에 대해 비트 단위 수정된 정류 선형 유닛 활성화 함수를 사용하여 상기 인공 신경망을 훈련하는 단계 - 상기 비트 단위 수정된 정류 선형 유닛 활성화 함수는 입력이 임계값보다 작을 때 상기 입력에 비례하는 출력 을 생성하도록 구성되고, 상기 입력이 상기 임계값보다 클 때 상기 입력과 독립적인 출력을 생성하도록 구성되 는, 비트 활성화 함수를 포함함 - 를 포함하고, 상기 입력은 연관된 복수의 가중치를 가지는 상기 인공 신경망 의 이전 계층의 제 2 복수의 인공 뉴런에 걸쳐, 상기 제 2 복수의 인공 뉴런의 각각의 출력과 상기 복수의 가중 치의 각각의 1비트의 곱의 합산을 포함한다. 다른 실시 예에서, 상기 복수의 가중치의 각각은 복수의 비트를 포함하고, 상기 비트 단위 수정된 정류 선형 유 닛 활성화 함수는 상기 복수의 비트에 걸친 상기 복수의 비트의 각각의 값과 상기 비트 활성화 함수의 상기 출 력의 곱의 합산을 포함한다. 또 다른 실시 예에서, 상기 비트 활성화 함수는 상기 임계값보다 큰 입력 값에 대해 상기 입력과 독립적인 일정 한 출력을 생성하도록 구성된다. 또 다른 실시 예에서, 상기 일정한 출력은 상기 복수의 가중치에 대한 스케일링 인자의 역수이다. 또 다른 실시 예에서, 상기 인공 신경망을 훈련하는 단계는: 훈련 데이터 세트에 응답하여 생성된 상기 인공 신 경망의 출력에 기반하여 상기 임계값, 상기 스케일링 인자, 및 상기 복수의 가중치 중 하나 이상의 값을 조정하 는 단계를 포함한다. 또 다른 실시 예에서, 상기 방법은 상기 임계값에 기초하여 상기 메모리 내 컴퓨팅 가속기의 하나 이상의 매개 변수를 조정하는 단계를 더 포함한다. 또 다른 실시 예에서, 상기 하나 이상의 매개변수는 상기 제 2 복수의 인공 뉴런의 상기 각각으로부터의 상기 출력과 연관된 전압 펄스 폭, 및 상기 복수의 가중치 각각의 상기 비트 위치에 각각 대응하는 복수의 출력 라인 과 각각 연관된 복수의 로딩 커패시턴스를 포함한다. 또 다른 실시 예에서, 상기 메모리 내 컴퓨팅 가속기는 상기 복수의 출력 라인에 연결된 아날로그-디지털 변환 기를 포함하고, 상기 방법은: 상기 제 2 복수의 인공 뉴런의 상기 각각의 상기 출력에 기반하고 상기 출력 라인 의 상기 각각에 인가된 펄스의 총 수가 상기 임계값과 같을 때 상기 복수의 출력 라인 각각에 대한 출력 전압 (Vout_low)을 결정하는 단계; 및 상기 아날로그-디지털 변환기의 최소 기준 전압을 Vout_low와 거의 동일하게 설정하는 단계를 더 포함한다. 또 다른 실시 예에서, 상기 아날로그-디지털 변환기는 Vout_low보다 작은 전압 값을 최대 출력으로 변환하도록 구성된다. 또 다른 실시 예에서, 상기 제 2 복수의 인공 뉴런으로부터의 상기 복수의 출력 및 상기 복수의 가중치는 비 음 수이다. 또 다른 실시 예에서, 상기 방법은 상기 인공 신경망의 훈련에 응답하여 상기 인공 신경망을 추론 모드에서 운 영하는 단계를 더 포함하고, 상기 인공 신경망은 상기 추론 모드에 있을 때 현재 데이터 세트에 응답하여 출력추론을 생성하도록 구성된다. 본 발명의 일부 실시 예에서, 방법은 메모리 인 컴퓨팅 가속기를 포함하는 인공 신경망을 제공하는 단계 - 상기 인공 신경망은 제 1 복수의 인공 뉴런을 포함하는 은닉 계층을 더 포함함 - ; 및 상기 제 1 복수의 인공 뉴런의 각각에 대해 비트 단위 수정된 정류 선형 유닛 활성화 함수를 사용하여 상기 인공 신경망을 훈련하는 단계 - 상 기 비트 단위 수정된 정류 선형 유닛 활성화 함수는 입력이 임계값보다 작을 때 상기 입력에 비례하는 출력을 생성하도록 구성되고 상기 입력이 임계값보다 클 때 상기 입력과 독립적인 출력을 생성하도록 구성되는 비트 활 성화 함수를 포함함 - 를 포함하고, 상기 인공 신경망을 훈련하는 단계는 훈련 데이터 세트에 응답하여 생성된 상기 인공 신경망의 출력에 기반하여 상기 임계의 값을 조정하는 단계를 포함한다. 또 다른 실시 예에서, 상기 방법은 상기 임계값에 기반하여 상기 메모리 내 컴퓨팅 가속기의 하나 이상의 매개 변수를 조정하는 단계를 더 포함한다. 또 다른 실시 예에서, 상기 하나 이상의 매개변수는 상기 인공 신경망의 이전 계층의 제 2 복수의 인공 뉴런의 각각의 출력과 연관된 전압 펄스 폭, 및 상기 제 2 복수의 인공 뉴런과 연관된 복수의 가중치의 각각의 비트 위 치에 각각 대응하는 복수의 출력 라인과 연관된 복수의 로딩 커패시턴스를 포함한다. 또 다른 실시 예에서, 상기 메모리 내 컴퓨팅 가속기는 상기 출력 라인에 결합된 아날로그-디지털 변환기를 포 함하고, 상기 방법은: 제 2 복수의 인공 뉴런의 상기 각각의 상기 출력에 기반하고 상기 출력 라인의 각각에 인 가된 펄스의 총 수가 상기 임계값과 같을 때 상기 복수의 출력 라인의 각각에 대한 출력 전압(Vout_low)을 결정 하는 단계 ; 및 상기 아날로그-디지털 변환기의 최소 기준 전압을 Vout_low와 거의 동일하게 설정하는 단계를 포함한다. 또 다른 실시 예에서, 상기 입력은 연관되는 복수의 가중치를 각각 가지는 상기 인공 신경망의 이전 계층의 제 2 복수의 인공 뉴런에 걸쳐, 상기 제 2 복수의 인공 뉴런의 각각의 출력과 상기 복수의 가중치의 각각의 1비트 의 곱의 합산을 포함한다. 본 발명의 일부 실시 예에서, 방법은 메모리 내 컴퓨팅 가속기를 포함하는 인공 신경망을 제공하는 단계 - 상기 인공 신경망은 제 1 복수의 인공 뉴런을 포함하는 은닉 계층을 더 포함하고, 상기 메모리 내 컴퓨팅 가속기는 상기 인공 신경망의 이전 계층의 복수의 제 2 인공 뉴런과 연관된 복수의 가중치의 각각의 비트 위치에 각각 대 응하는 복수의 출력 라인에 연결된 아날로그-디지털 변환기를 포함함 - ; 상기 제 1 복수의 인공 뉴런의 각각에 대해 비트 단위 수정된 정류 선형 유닛 활성화 함수를 사용하여 인공 신경망을 훈련하는 단계 - 상기 비트 단위 수정된 정류 선형 유닛 활성화 함수는 입력이 임계값보다 작을 때 상기 입력에 비례하는 출력을 생성하도록 구 성되고 상기 입력이 상기 임계값보다 클 때 상기 입력과 독립적인 출력을 생성하도록 구성되는 비트 활성화 함 수를 포함함 - ; 상기 출력 라인의 각각에 인가된 펄스의 총 수가 상기 임계값과 동일한 경우, 상기 복수의 출 력 라인의 각각에 대해 출력 전압(Vout_low)을 결정하는 단계; 및 상기 아날로그-디지털 변환기의 최소 기준 전 압을 Vout_low와 거의 동일하게 설정하는 단계를 포함한다. 또 다른 실시 예에서, 상기 방법은 상기 임계값에 기초하여 상기 메모리 내 컴퓨팅 가속기의 하나 이상의 매개 변수를 조정하는 단계를 더 포함하고, 상기 하나 이상의 매개변수는 상기 인공 신경망의 이전 계층의 제 2 복수 의 인공 뉴런의 각각으로부터의 상기 출력과 연관된 전압 펄스 폭 및 상기 제 2 복수의 인공 뉴런과 연관된 복 수의 가중치의 각각의 비트 위치에 각각 대응하는 복수의 출력 라인과 연관된 복수의 로딩 커패시턴스를 포함한 다. 또 다른 실시 예에서, 상기 아날로그-디지털 변환기는 Vout_low보다 작은 전압 값을 최대 출력으로 변환하도록 구성된다. 또 다른 실시 예에서, 상기 입력은 상기 제 2 복수의 인공 뉴런에 걸쳐, 상기 제 2 복수의 인공 뉴런의 각각의 출력과 상기 복수의 가중치의 각각의 1비트의 곱의 합산을 포함한다. 본 발명의 개념의 실시예에 따른 다른 방법, 시스템, 제조 물품, 및/또는 컴퓨터 프로그램 제품은 다음 도면 및 상세한 설명을 검토할 때 당업자에게 명백하게 될 것이다. 이러한 모든 추가 시스템, 방법, 제조 물품, 및/또는 컴퓨터 프로그램 제품은 본 설명에 포함되고, 본 발명의 주제 범위 내에 있으며, 첨부된 청구범위에 의해 보호 되는 것이다."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음의 상세한 설명에서, 본 발명의 개념의 실시예의 완전한 이해를 제공하기 위해 다수의 특정 세부사항이 설 명된다. 그러나, 당업자라면 본 발명의 실시 예들이 이러한 특정한 세부 사항 없이도 실시될 수 있다는 것이 이 해될 것이다. 일부 경우에, 잘 알려진 방법, 절차, 구성요소 및 회로는 본 발명의 개념을 모호하게 하지 않기 위해 상세하게 설명되지 않았다. 본 명세서에 개시된 모든 실시예는 개별적으로 구현되거나 임의의 방식 및/또 는 조합으로 결합될 수 있음을 의도한다. 일 실시예와 관련하여 설명된 양태는 이에 대해 구체적으로 설명되지 는 않았지만 상이한 실시예에 통합될 수 있다. 즉, 모든 실시예 및/또는 임의의 실시예의 특징은 임의의 방식 및/또는 조합으로 조합될 수 있다. 본 발명의 개념의 실시예는 다층 신경망 및 메모리 내 컴퓨팅(CIM) 가속기를 포함하는 인공 지능(AI) 시스템과 관련하여 여기에서 설명된다. 다층 신경망은 인공 뉴런 또는 노드를 포함하는 다층 인공 신경망이며 실제 생물 학적 뉴런을 포함하는 생물학적 신경망은 포함하지 않는다는 것이 이해될 것이다. 본 발명의 개념의 일부 실시예는 기존의 CIM 가속기는 입력으로 곱셈-누산(MAC) 결과를 사용하는, 각 노드에서 활성화 함수을 구현하기 위해 산술 논리 장치 또는 추가 회로와 함께 사용될 수 있다는 실현에서 비롯된다. 이 러한 CIM 가속기는 산술 로직 장치(ALU) 또는 활성화 함수을 구현하기 위한 전용 추가 회로와 함께 사용될 수 있다. 이는 CIM 가속기의 전체 회로 면적을 증가시키고, 전력 소모를 증가시키거고/시키거나, 인공 신경망 시스 템을 사용하여 추론을 생성하는데 지연을 증가시킬 수 있다. 본 발명의 일부 실시예는 MAC 연산에 사용된 가중치의 각 비트 위치에 대응하는 비트 단위 방식으로 신경망 은 닉 계층의 각 뉴런에 활성화 함수가 적용되는, 정류 선형 유닛(ReLU) 활성화 함수의 수정된 버전을 제공할 수 있다. 활성화 함수는 비트 단위 수정된 ReLU(bm-ReLU) 활성화 함수로 지칭될 수 있다. 일부 실시 예에서, bm- ReLU 활성화 함수는 입력이 임계값보다 작을 때 입력에 비례하는 출력을 생성하고 입력이 임계값보다 클 때 입 력과 독립적인 출력(예를 들어, 일정한 출력)을 생성하도록 구성된다. 인공 신경망은 예를 들어 임계값, MAC 가중치 값에 대해 사용되는 스케일링 인자, 및/또는 MAC 가중치 값을 조 정하기 위해 이용 가능한 신경망 소프트웨어 훈련 플랫폼을 사용하여 훈련될 수 있다. CIM 가속기의 하나 이상 의 매개변수는 임계값에 따라 조정될 수 있다. 예를 들어, 하나 이상의 매개변수는 제하하는 것은 아니지만, 이 전 계층 뉴런의 출력과 관련된 전압 펄스 폭 및 MAC 가중치의 비트 위치 각각에 대응하는 복수의 출력 라인과 관련된 로딩 커패시턴스를 포함한다. 일부 실시예에서, CIM 가속기는 CIM 가속기 어레이의 출력 라인에 연결된 아날로그-디지털 변환기(ADC)를 포함 한다. 출력 라인과 관련된 가중치 비트 위치에 대한 MAC 합의 값이 증가함에 따라 출력 라인의 전압 레벨이 풀 다운되면서, 출력 전압(Vout_low)은 이전 계층 뉴런으로터의 출력에 기초한 총 펄스 수가 출력 라인에 인가되는 임계값과 동일한 경우에 결정될 수 있다. ADC의 최소 기준 전압은 Vout_low와 거의 같도록 설정될 수 있고, ADC는 Vout_low보다 작은 전압 값을 최대 출력으로 변환하도록 구성될 수 있다. 임계값, MAC 가중치 스케일링 인자 및 MAC 가중치 값과 같은 활성화 함수 매개변수와 함께, 이전 계층 뉴런의 출력(현재 계층 뉴런에 대한 입력) 및 출력 라인 로딩 커패시턴스를 기반으로 하는 펄스 폭과 같은, CIM 가속기 의 매개변수를 조정함으로써, bm-ReLU 활성화 함수는 추가 회로나 추가 ALU가 필요 없이 구현될 수 있다. 결과 적으로, 전체 CIM 가속기 회로 면적 및 CIM 가속기 전력 소모를 줄일 수 있고, 인공 신경망을 이용하여 추론을 생성하기 위한 처리 시간도 줄일 수 있다. 도 1은 본 발명의 일 실시예에 따른 CIM 가속기를 포함하는 인공 신경망 시스템을 포함하는 AI 시스템을 나타내는 블록도이다. 도 1에 도시된 바와 같이, AI 시스템은 예를 들어 추론 또는 분류를 만들기 위해 새로운 데이터를 처리하 는 데 사용되는 구성요소 및 훈련 구성요소 모두를 포함할 수 있다. AI 시스템의 훈련 부분에 사용되는 구 성요소는 훈련 데이터, 피처링(featuring) 구성요소, 라벨링(labeling) 구성요소, 및 CIM 가속 기 및 신경망 모델을 포함하는 신경망 시스템을 포함한다. 훈련 데이터는 추론 또는 분류가 이루어질 정보, 예를 들어 이미지와 연관된 픽셀 데이터, 이벤트, 사람 또는 사물과 연관된 매개변수 데이터 등을 포함할 수 있다. 피처링 구성요소는 종속 변수로 간주될 수 있는 추론 또는 분류를 수행하기 위해 AI 시스템에 의해 사용되는 개별 독립 변수를 식별하도록 구성된다. 예를 들어, 훈련 데이터는 일반적으로 처리되지 않거나 포맷될 수 있고 추론 또는 분류를 만들기 위한 관련 정보에 추가하여 추가 정보를 포함할 수 있다. 이 추가 정 보는 피처링 구성요소에 의해 필터링될 수 있다. 훈련 데이터에서 추출된 특징을 속성이라 하고 특징 의 개수를 차원이라고 부를 수 있다. 라벨링 구성요소는 입력 특징 및 출력 추론 또는 분류 모두에 대한 일관된 명명 규칙을 보장하기 위해 특 징화된 훈련 데이터 및 생성된 추론 또는 분류에 정의된 라벨을 할당하도록 구성될 수 있다. CIM 가속기와 함께 신경망 모델은 라벨링 구성요소에 의해 제공되는 라벨을 포함하는 특징화된 훈련 데이터를 처리할 수 있고, 특징 및 라벨링된 입력 데이터와 추론 또는 분류 출력 사이의 정량적 관계 를 설정하기 위해 수많은 기능을 테스트하도록 구성될 수 있다. 신경망 모델은 추론 또는 분류 출력이 성공 또는 정확도 메트릭을 개선하거나 최대화하도록 설계된 추론 또는 분류 출력에 대한 다양한 입력 데이터 특징의 효과를 평가하기 위해 회귀 기술을 사용할 수 있다. 그런 다 음 이러한 효과를 사용하여 특징 및 레이블 지정된 입력 데이터와 추론 또는 분류 출력 간의 양적 관계를 조정 하고 개선할 수 있다. 신경망 모델에 의해 생성된 특징 및 레이블 지정된 입력 데이터 사이의 조정 및 개 선된 양적 관계는 신경망 추론 엔진에서 사용하기 위해 출력된다. 신경망 모델은 신경망 알고리즘으 로 지칭될 수 있다. 추론 또는 분류를 만들기 위해 새로운 또는 현재 데이터를 처리하는 데 사용되는 구성 요소는 새로운 데이터 , 피처링 구성요소, 신경망 추론 엔진 및 추론 구성 요소를 포함한다. 새로운 데이터는 새로운 또는 현재 데이터가 실제 추론 또는 분류에 사용될 것이라는 점을 제외하고는 내 용 및 형태에서 훈련 데이터와 동일한 데이터/정보일 수 있다. 유사하게, 피처링 구성요소는 피처링 구성요소가 훈련 데이터에 대해 수행하는 것과 동일한 기능을 새로운 데이터에 대해 수행한다. 신경망 추론 엔진은 사실상 특징 및 레이블 지정된 입력 데이터와 추론 출력 사이에서 결정된 양적 관계의 형태로 신경망 모델에 의해 생성될 수 있다. 신경망 추론 엔진은 일부 실시예에서 AI 모델 또는 추론 모델로 지칭될 수 있다. 신경망 추론 엔진은 추론 구성요소를 통해 추론 또는 분류를 출력하도록 구 성될 수 있다. 추론 구성요소는 다양한 디스플레이 포맷으로 추론 또는 분류 출력을 전달하도록 구성될 수 있다. 도 2는 본 발명의 일부 실시예에 따른 도 1의 인공 신경망 시스템을 나타내는 도면이다. 도 2에 도시된 바와 같이, 인공 신경망은 입력 계층, 하나 이상의 은닉 계층, 및 출력 계층을 포함하는 복 수의 노드 계층을 포함한다. 도 2에 도시된 예에서, 입력 계층은 5개의 노드 또는 뉴런(202a, 202b, 202c, 202d, 202e)을 포함하고 출력 계층은 3개의 노드 또는 뉴런(210a, 210b, 210c)을 포함한다. 도시된 예에서, 3개 의 은닉 계층은 입력 계층을 5개의 노드 또는 뉴런(204a, 204b, 204c, 204d, 204e)을 포함하는 제 1 은닉계층, 5개의 노드 또는 뉴런(206a, 206b, 206c, 206d, 206e)을 포함하는 제 2 은닉 계층, 및 5개의 노드 및 뉴 런(208a, 208b, 208c, 208d, 208e)을 포함하는 제 3 은닉 계층을 포함하는 출력 계층에 연결한다. 다른 실시예 는 더 많거나 더 적은 은닉 계층을 사용할 수 있다. 각 노드 또는 뉴런은 다른 노드 또는 뉴런에 연결되며 연관 된 가중치 및 임계값을 갖는다. 개별 노드 또는 뉴런의 출력이 지정된 임계값보다 높으면 해당 노드가 활성화되 어 네트워크의 다음 계층로 데이터를 보낸다. 그렇지 않으면, 네트워크의 다음 계층으로 데이터가 전달되지 않 는다. 상술된 바와 같이, 신경망 시스템은 학습 데이터에 의존하여 시간이 지남에 따라 정확도를 개선하고 학습 한다. 신경망 시스템의 다양한 매개변수가 정확도를 위해 조정되고 정제되면, 다른 응용 프로그램 중에서 질문에 대한 응답으로 추론 또는 답변을 생성하고, 이미지를 분류하고, 음성을 인식 및 해석하고, 데이터를 클 러스터링하는 데에 사용할 수 있다. 각각의 개별 노드 또는 뉴런은 입력 데이터, 가중치, 편향(또는 임계값) 및 출력으로 구성된 선형 회귀 모델을 구현하는 것으로 볼 수 있다. 입력 계층이 결정되면, 가중치가 할당된다. 이러한 가중치는 주어진 변수의 중요 도를 결정하는 데 도움이 되며, 더 큰 변수는 다른 입력에 비해 출력에 더 크게 기여한다. 그런 다음 모든 입력 에 각각의 가중치를 곱한 다음 합산, 즉, MAC 연산한다. 도 2에 도시된 바와 같이, 노드 또는 뉴런(206a)은 예를 들어 노드 또는 뉴런(204a, 204b, 204c, 204d, 204e) 의 출력에 대응하는 입력을 수신한다. 이러한 입력은 노드 또는 뉴런(206a)에서 해당 가중치 곱해지고 합산된다. 그 후, 출력은 출력을 결정하는 활성화 함수를 통해 전달된다. 해당 출력이 주어진 임계값을 초과하 면, 네트워크의 다음 계층으로 데이터를 전달하여 노드를 활성화한다. 결과적으로 한 노드의 출력이 다음 노드 의 입력이 된다. 한 계층에서 다음 계층으로 데이터를 전달하는 이 과정은 피드포워드 인공 신경망의 한 예이다. 본 발명의 일부 실시예는 인공 신경망의 각 노드 또는 뉴런에 대해 도 1의 CIM 가속기, 신경망 모델, 및 신경망 추론 엔진을 사용하여 구현될 수 있는 비트 단위 수정된 정류 선형 유닛(bm-ReLU) 활성화 함수 를 제공할 수 있다. 신경망 모델에서 은닉 계층의 주어진 노드 또는 뉴런에 대해, MAC 연산의 가중 합 z는 다음 과 같이 계산될 수 있으며 여기서 이전 계층에서 수신된 가중치와 입력은 비음수(non-negative)이다."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "각각의 가중치는 CIM 가속기의 Nbl 비트셀에 의해 저장될 수 있고 각 비트셀은 Nbpc 비트를 저장할 수 있다. 따라서 가중치 wi는 다음과 같이 표현될 수 있다."}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "가중 합 z는 다음과 같이 표현될 수 있다:"}
{"patent_id": "10-2022-0078283", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "비트 단위 가중 합은 이전 계층 노드 또는 인공 뉴런 중 각각의 하나로부터의 출력과 그 이전 계층 노드 또는 인공 뉴런과 연관된 가중치의 1비트의 곱의 연관된 개별 가중치를 갖는 인공 신경망의 이전 계층에 있는 다수의 노드 또는 인공 뉴런에 걸친 합으로 볼 수 있다. 본 발명의 일부 실시예에 따른 노드 또는 인공 뉴런에 대한 활성화 함수는, activ가 현재 노드 또는 인공 뉴런 의 출력과 다음 계층의 노드 또는 인공 뉴런에 대한 입력에 해당하는 경우 다음과 같이 표현될 수 있다: 본 발명의 일부 실시예에 따른 비트 활성화 함수(Abit)는 도 3에 도시되며 전술한 가중치 비트에 대한 비트 단 위 가중치 합을 기반으로 한다. 비트 활성화 함수는 입력이 임계값 Np_crit보다 작을 때 입력에 비례하고 입력이 임계값 Np_crit보다 클 때 입 력과 독립적인 출력을 생성하도록 구성된다. 도 3에 도시된 바와 같이, 입력이 임계값 Np_crit보다 크거나 같을 때, 비트 활성화 함수는 가중치 스케일링 인자 α의 역의 일정한 출력을 생성한다. 본 발명의 일부 실시예에 따 른 bm-ReLU 활성화 함수는, 가중치를 구성하는 비트 수에 걸쳐, 비트 활성화 함수의 출력과 각 가중치 비트 위 치에서의 가중치 비트 값의 곱의 합산에 기반하여 활성인 출력을 생성한다. 도 4 및 도 5는 본 발명의 일부 실시예에 따른 도 1의 CIM 가속기의 블록도이다. 상술된 바와 같이, 대규모 인공 신경망에는 잠재적으로 수천 개의 노드를 갖는 다중 계층이 있을 수 있다. 각 노드 또는 뉴런에서 수행되는 MAC 연산은 처리 및 에너지 집약적일 수 있다. CIM 가속기는 추가적인 산술 유닛 또는 회로에 대한 필요 없이 bm-ReLU 활성화 함수을 구현하는 동안 신경망 시스템에서 MAC 연산의 성 능을 개선하는 데 사용될 수 있다. 도 4에 도시된 바와 같이, CIM 가속기는 이전 계층의 노드 또는 뉴런으 로부터 출력되는 입력 값을 수신하도록 구성된다. CIM 가속기는 CIM 가속기 드라이버 및 신경망 가중 치를 포함한다. CIM 가속기 드라이버의 사용을 통해, 입력 값은 워드 라인을 구동하는 데 사용될 수 있으며, 예를 들어, 가중치 비트가 높고 입력 값 비트가 높을 때 입력 값과 연관된 가중치와 결합된 출력 라인 의 전압을 더 낮게 구동할 수 있다. 전하 공유 구성요소는 예를 들어 시프트-앤-더하기 프로세스를 통해 각 가중치 비트 위치에 대한 MAC 결과를 결합하고 ADC에 출력을 제공하도록 구성된다. 다른 실시예에서, 시프트-앤드-더하기 프로세서는 ADC에 의한 변환 후에 수행될 수 있다. 도 5는 CIM 가속기 드라이버, 신경망 가중치, 및 전하 공유 구성요소의 동작을 보다 상세하게 예시한다. 도 5에 도시된 바와 같이, 가중치 값을 보유하는 각 비트 셀이 이진수라고 가정하면, 각 가중치는 출력 라인 OL[0]...OL[3]에 해당하는 4비트이다. 신경망 시스템의 이전 계층에서 생성된 N개의 출력에 해당하는, 노 드 또는 뉴런에 대한 CIM 가속기에 대한 N개의 입력은 워드 라인 WL[0]…WL[N-1]에 제공된다. 각 입력 값 은 펄스 값과 각 비트 위치의 가중치 값을 기반으로 그 관련 워드 라인 WL[0]…WL[N-1]에서 펄스되고 해당 출력 라인 OL[0]...OL[3]에서 전압을 풀다운한다. 전하 공유 구성요소는 각 비트 위치에 대응하는 출력 라인들 (OL[0]...OL[3]) 각각에 대한 결과를 결합하도록 구성될 수 있으며, 이는 변환을 위해 ADC에 제공된다. 이 러한 방식으로, 각각의 입력 값은 연관된 가중치로 곱해지고 이러한 곱은 예를 들어 전하 공유 구성요소를 사용하여 가중치 비트 위치에 의해 합산된다. 도 6 내지 도 9는 본 발명의 개념의 일부 실시 예에 따른 인공 신경망 시스템 및 CIM 가속기를 포함 하는 도 1의 인공지능 시스템의 동작을 설명하기 위한 순서도이다. 이하 도 6을 참조하면, CIM 가속기를 포함하는 인공 신경망 시스템이 제공되는 블록에서 동작이 시작된다. 인공 신경망 시스템은 블록에서 전술한 bm-ReLU 활성화 함수를 사용하여 훈련된다. 일부 실시 예에서, bm-ReLU 활성화 함수는 도 3과 관련하여 전술한 바와 같은 비트 활성화 함수를 포함하며, 이 것은 입력이 임계값(Np_crit)보다 작을 때 입력에 비례하는 출력을 생성하도록 구성되고 입력이 임계값보다 클 때 입력과 독립적인 출력을 생성하도록 구성된다. 입력은 각각 연관된 복수의 가중치를 갖고 인공 신경망 의 이전 계층의 복수의 노드 또는 인공 뉴런에 걸쳐, 이전 계층의 복수의 노드 또는 인공 뉴런 각각의 출력과 복수의 가중치 중 각각의 일 비트의 곱의 합을 포함할 수 있다. 도 7을 참조하면, 신경망 시스템은 블록에서 예를 들어 임계값, MAC 가중치에 사용되는 스케일링 인 자 α, 및/또는 MAC 가중치 값을 조정하도록 반복 프로세스를 통해 훈련될 수 있다. 도 8을 참조하면, CIM 가속기의 하나 이상의 매개변수는 임계값 Np_crit에 기초하여 조정될 수 있다. 예를 들어, 하나 이상의 매개변수는 제한하는 것은 아니지만, 도 5의 관련 워드 라인 WL[0]…WL[N-1]상에 펄스되는 이전 계층 뉴런의 출력과 관련된 전압 펄스 폭 및 MAC 가중치의 각 비트 위치에 각각 대응하는 도 5의 복수의출력 라인들(OL[0]…OL[3])과 관련된 로딩 커패시턴스를 포함한다. 도 9를 참조하면, 신경망 및 CIM 가속기는 ADC와 관련된 매개변수를 조정함으로써 추가로 조정 될 수 있다. 예를 들어, 도 5의 출력 라인(OL[0]…OL[3])의 전압 레벨은 출력 라인 OL[0]…OL[3]과 관련된 가중 치 비트 위치에 대한 MAC 합의 증가 값으로 풀 다운되기 때문에, 이전 계층 뉴런의 출력을 기반으로 한 총 펄스 수가 해당 WL[0]…WL[N-1]을 통해 출력 라인에 적용되고 가중치 비트가 임계값 Np_crit와 같을 때 블록에 서 출력 전압(Vout_low)이 결정될 수 있다. ADC의 최소 기준 전압은 블록에서 Vout_low와 대략 동일 하게 설정될 수 있고 ADC는 Vout_low보다 작은 전압 값을 최대 출력으로 변환하도록 구성될 수 있다. 도 10은 본 발명의 일부 실시 예에 따른 도 1의 AI 시스템을 구현하는데 사용될 수 있는 데이터 처리 시스 템의 블록도이다. 도 10에 도시된 바와 같이, 데이터 처리 시스템은 적어도 하나의 코어, 메모리, 인공 지능 (AI) 가속기, 및 하드웨어(HW) 가속기를 포함할 수 있다. 적어도 하나의 코어, 메모리 , AI 가속기, 및 HW 가속기는 버스를 통해 서로 통신할 수 있다. 적어도 하나의 코어는 컴퓨터 프로그램 명령을 실행하도록 구성될 수 있다. 예를 들어, 적어도 하나의 코 어는 메모리에 저장된 컴퓨터 판독 가능 프로그램 코드로 표현되는 운영 체제 및/또는 애플 리케이션을 실행할 수 있다. 일부 실시예에서, 적어도 하나의 코어는 AI 가속기 및/또는 HW 가속기 에게 명령을 실행함으로써 연산을 수행하고 AI 가속기 및/또는 HW 가속기로부터 연산 결과를 획득하게 지시하도록 구성될 수 있다. 일부 실시예에서, 적어도 하나의 코어는 특정 목적을 위해 맞춤화 된 ASIP일 수 있고 전용 명령어 세트를 지원할 수 있다. 메모리는 데이터를 저장하도록 구성된 임의의 구조를 가질 수 있다. 예를 들어, 메모리는 동적 랜 덤 액세스 메모리(DRAM) 및 정적 RAM(SRAM)과 같은 휘발성 메모리 장치를 포함할 수 있거나, 플래시 메모리 및 저항성 RAM(RRAM)과 같은 비휘발성 메모리 장치를 포함한다. 적어도 하나의 코어, AI 가속기 및 HW 가속기는 메모리에 데이터를 저장하거나 버스를 통해 메모리로부터 데이터를 독출할 수 있다. AI 가속기는 CIM 가속기와 같은 AI 애플리케이션을 위해 설계된 하드웨어를 지칭할 수 있다. AI 가 속기는 적어도 하나의 코어 및/또는 HW 가속기로부터 제공되는 입력 데이터를 처리하여 출력 데이터를 생성하고, 출력 데이터를 적어도 하나의 코어 및/또는 HW 가속기에 제공할 수 있다. 일부 실시 예에서, AI 가속기는 프로그래밍 가능하고 적어도 하나의 코어 및/또는 HW 가속기에 의 해 프로그래밍될 수 있다. HW 가속기는 특정 연산을 고속으로 수행하도록 설계된 하드웨어를 포함할 수 있다. HW 가속기는 프로그래밍 가능하고 적어도 하나의 코어에 의해 프로그래밍될 수 있다. 도 11은 본 발명의 일부 실시 예에 따른 bn-ReLU 활성화 함수를 사용하도록 구성된 신경망 시스템 및 CIM 가속기를 포함하는 AI 시스템의 동작을 용이하게 하기 위해서, 각각 도 1의 AI 시스템 및 도 10의 데 이터 처리 시스템과 같은 데이터 처리 시스템의 실시예에서 사용될 수 있는 메모리를 예시한다. 메모리는 본 명세서에 기술된 바와 같이 AI 시스템의 동작을 용이하게 하기 위해 사용되는 소프트웨 어 및 데이터를 포함하는 하나 이상의 메모리 장치를 나타낸다. 메모리는 캐시, ROM, PROM, EPROM, EEPROM, 플래시, SRAM 및 DRAM과 같은 유형의 장치를 포함할 수 있지만 이에 제한되지 않는다. 도 11에 도시된 바와 같이, 메모리는 소프트웨어 및/또는 데이터의 4개 이상의 카테고리: 운영 체제, AI 훈련 구성 요소, AI 추론 구성요소, 및 통신 구성요소를 포함할 수 있다. 특히, 운영 체제는 데 이터 처리 시스템의 소프트웨어 및/또는 하드웨어 리소스를 관리하고 프로세서에 의한 프로그램의 실행을 조정 할 수 있다. AI 훈련 구성요소는 AI 시스템 및 훈련 데이터, 피처링 구성요소, 라벨링 구성요소, 및 신경망 모델에 대해 위에서 설명된 바와 같이 하나 이상의 동작을 수행하도록 구성될 수 있다. AI 추론 구성요소는 새로운 데이터 구성요소, 피처링 구성요소, 신경망 추론 엔진, 및 추론 구성 요소에 대해 상술된 바와 같이 하나 이상의 동작을 수행하도록 구성될 수 있다. 통신 구성요소는 신 경망 시스템으로의 훈련 데이터, 새로운 데이터, 및 라벨링 데이터의 수신을 용이하게 하 고 추론 및/또는 분류를 예를 들어 추론 구성요소를 통해 사용자에게 전달하도록 구성될 수 있다. 도 10 및 11은 본 발명의 일부 실시 예에 따른, 도 1의 AI 시스템 및 도 10의 데이터 처리 시스템과 같은, 데이터 처리 시스템에서 사용될 수 있는 하드웨어/소프트웨어 아키텍처를 예시하고 있지만, 본 발명의 실시예들은 이러한 구성에 한정되지 않고, 본 명세서에서 설명하는 동작을 수행할 수 있는 모든 구성을 포함하는 것으로 이해될 것이다. 도 1 내지 도 9과 관련하여 상술된 데이터 처리 시스템의 동작을 수행하기 위한 컴퓨터 프로그램 코드는 개발 편의를 위해 Python, Java, C 및/또는 C++와 같은 고급 프로그래밍 언어로 작성할 수 있다. 또한, 본 발명의 동 작을 수행하기 위한 컴퓨터 프로그램 코드는 한정하는 것은 아니지만, 해석된 언어와 같은 다른 프로그래밍 언 어로도 작성될 수 있다. 일부 구성 요소 또는 루틴은 어셈블리 언어 또는 마이크로 코드로 작성되어 성능 및/또 는 메모리 사용을 향상시킬 수 있다. 프로그램 구성요소 중 임의의 것 또는 전부의 기능은 또한 개별 하드웨어 구성요소, 하나 이상의 응용 주문형 집적 회로(ASIC), 또는 프로그래밍된 디지털 신호 프로세서 또는 마이크로 컨트롤러를 사용하여 구현될 수 있다는 것이 더욱 이해될 것이다. 또한, 도 1의 AI 시스템 및 도 10의 데이터 처리 시스템의 기능은 각각 본 발명의 다양한 실시예에 따라, 단일 프로세서 시스템, 다중 프로세서 시스템, 다중 코어 프로세서 시스템, 또는 독립 실행형 컴퓨터 시 스템의 네트워크로 구현될 수 있다. 이러한 프로세서/컴퓨터 시스템 각각은 \"프로세서\" 또는 \"데이터 처리 시스 템\"으로 지칭될 수 있다. 도 1 내지 도 11과 관련하여 본 명세서에 설명된 데이터 처리 장치는 본 발명의 일부 실시 예에 따른 bn-ReLU 활성화 함수를 사용하도록 구성된 신경망 시스템 및 CIM 가속기를 포함하는 AI 시스템의 동작을 용이하게 하기 위해 사용될 수 있다. 이러한 장치는 소프트웨어, 펌웨어 및/또는 하드웨어의 적절한 조합을 사 용하여 데이터를 수신, 전송, 처리 및 저장하도록 작동할 수 있으며 독립형이거나 인터넷으로 알려진 글로벌 통 신 네트워크의 전체 또는 일부를 포함하는 공공 및/또는 개인, 실제 및/또는 가상, 유선 및/또는 무선 네트워크 에 의해 상호 연결될 수 있는 하나 이상의 엔터프라이즈, 애플리케이션, 개인, 퍼베이시브 및/또는 임베디드 컴 퓨터 시스템으로 구현될 수 있으며, 다양한 유형의 유형의 비일시적 컴퓨터 판독 가능 매체를 포함할 수 있다. 특히, 프로세서에 연결될 때 메모리는 프로세서에 의해 실행될 때, 프로세서로 하여금 도 1 내지 도 9과 관련하여 본 명세서에 설명된 동작들 중 하나 이상을 포함하는 동작을 수행하게 하는 컴퓨터 판독 가능 프로그 램 코드를 포함한다. 본 발명의 일부 실시 예는 MAC 연산의 성능을 향상시키기 위해 CIM 가속기를 사용하는 인공 신경망을 포함하는 AI 시스템을 제공할 수 있다. 또한 임계값 Np_crit, MAC 가중치 스케일링 인자 α, 및 MAC 가중치 값과 같은 활 성화 함수 매개변수와 함께, 이전 계층 뉴런의 출력(현재 계층 뉴런에 대한 입력) 및 출력 라인 로딩 커패시턴 스에 기반하는 펄스 폭과 같은, CIM 가속기의 매개변수의 조정 및 튜닝은, 추가 회로 또는 추가 ALU가 필요 없 이 bm-ReLU 활성화 함수을 구현하기 위해 수행될 수 있다. 16개의 뉴런을 갖는 하나의 은닉 계층과 28개의 뉴런 을 갖는 하나의 은닉 계층을 갖는 신경망 기반 분류 실험에 의하면 시그모이드(sigmoid) 및 tanh와 같은 비-비 트 단위 활성화 함수에 비해, 본 명세서에서 설명된 본 발명의 개념의 일부 실시예에 따른, bm-ReLU 활성화 함 수를 사용할 때, 10% 미만의 정확도 패널티가 결과된다. 따라서, 본 발명의 일부 실시 예는, CIM 가속기가 인공 신경망과 결합하여 CIM 가속기 회로 면적을 늘리지 않고 bm-ReLU 활성화 함수를 구현하는 동시에 CIM 가속기 전 력 소비를 줄이는 방식인, 인공 신경망을 포함하는 AI 시스템을 제공할 수 있다. 또한, 인공 신경망을 이용하여 추론 또는 분류를 생성하기 위한 처리 시간을 줄일 수 있다. 추가 정의 및 구현예: 본 발명의 다양한 실시예에 대한 상술한 설명에서, 본 명세서에 사용된 용어는 단지 특정 실시예를 설명하기 위 한 것이며 본 발명을 제한하려는 것이 아니라는 것을 이해해야 한다. 달리 정의되지 않는 한, 본 명세서에서 사 용되는 모든 용어(기술적, 과학적 용어 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 일반 적으로 이해하는 것과 동일한 의미를 갖는다. 일반적으로 사용되는 사전에 정의된 것과 같은 용어는 본 명세서 및 관련 기술의 맥락에서 그 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며 본 명세서에서 명시적으로 정의된 이상화되거나 지나치게 형식적인 의미로 해석되지 않는다는 것이 이해될 것이다. 도면의 흐름도 및 블록도는 본 발명의 개념의 다양한 양태에 따른 시스템, 방법, 및 컴퓨터 프로그램 제품의 가 능한 구현의 아키텍처, 기능 및 동작을 예시한다. 이와 관련하여, 흐름도 또는 블록도의 각 블록은 특정 논리 기능(들)을 구현하기 위한 하나 이상의 실행 가능한 명령을 포함하는 구성 요소, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또한, 일부 대안적인 구현에서, 블록에 언급된 기능은 도면에 언급된 순서와 다르게 발생할 수 있다는 점에 유의해야 한다. 예를 들어, 연속적으로 도시된 2개의 블록은 실제로 실질적으로 동시에 실행될 수 있거나 관련된 기능에 따라 블록이 때때로 역순으로 실행될 수 있다. 또한 블록 다이어그램 및/또는 순서도 그 림의 각 블록, 블록 다이어그램 및/또는 순서도 그림의 블록 조합은 특정 기능이나 동작을 수행하는 특수 목적하드웨어 기반 시스템, 또는 특수 목적 하드웨어와 컴퓨터 명령의 조합으로 구현될 수 있다는 것에 유의한다. 본 명세서에서 사용된 용어는 단지 특정한 양상을 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 본 명세서에 사용된 바와 같이, 단수 형은 문맥이 명백하게 달리 나타내지 않는 한 복수 형태도 포함하 는 것으로 의도된다. 본 명세서에서 사용될 때 \"포함하는\" 및/또는 \"포함하는\"이라는 용어는, 명시된 기능, 정 수, 단계, 작업, 요소 및/또는 구성 요소의 존재를 지정하지만 하나 이상의 다른 기능, 정수, 단계, 작업, 요소, 구성 요소 및/또는 이들의 그룹의 존재 또는 추가를 배제하지 않는다. 본 명세서에 사용된 바와 같이, \" 및/또는\"이라는 용어는 관련된 나열된 항목 중 하나 이상의 임의의 모든 조합을 포함한다. 유사한 참조 번호는 도면의 설명 전반에 걸쳐 유사한 요소를 나타낸다. 본 발명의 다양한 실시예에 대한 상술한 설명에서, 본 발명의 개념의 측면은 임의의 새롭고 유용한 프로세스, 기계, 제조, 또는 물질의 조성, 또는 이들의 임의의 새롭고 유용한 개선을 포함하는 다수의 특허 가능한 클래스 또는 컨텍스트 중 임의의 것으로 여기에서 예시 및 설명될 수 있다. 따라서, 본 발명의 개념의 양태는 여기에서 모두 일반적으로 \"회로\", \"모듈\", \"구성 요소\" 또는 \"시스템\"으로 지칭될 수 있는 전체 하드웨어, 전체 소프트 웨어(펌웨어, 상주 소프트웨어, 마이크로 코드 등 포함) 또는 소프트웨어와 하드웨어 구현을 결합하여 구현될 수 있다. 또한, 본 발명의 개념의 양태는 컴퓨터 판독가능 프로그램 코드가 구현된 하나 이상의 컴퓨터 판독가 능 매체를 포함하는 컴퓨터 프로그램 제품의 형태를 취할 수 있다. 하나 이상의 컴퓨터 판독가능 매체의 임의의 조합이 사용될 수 있다. 컴퓨터가 읽을 수 있는 매체는 컴퓨터가 읽을 수 있는 신호매체 또는 컴퓨터가 읽을 수 있는 저장매체일 수 있다. 컴퓨터 판독 가능 저장 매체는 제한하 는 것은 아니지만, 예를 들어 전자, 자기, 광학, 전자기, 또는 반도체 시스템, 장치 또는 장치, 또는 전술한 것 의 임의의 적절한 조합일 수 있다. 컴퓨터 판독 가능 저장 매체의 보다 구체적인 예(비제한적 목록)는: 휴대용 컴퓨터 디스켓, 하드 디스크, 랜덤 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 지울 수 있는 프로그램 가능한 읽기 전용 메모리(EPROM 또는 플래시 메모리), 리피터가 있는 적절한 광섬유, 휴대용 컴팩트 디스크 읽기 전용 메모리(CD-ROM), 광 저장 장치, 자기 저장 장치 또는 전술한 것의 적절한 조합을 포함할 수 있다. 이 문서의 맥 락에서, 컴퓨터 판독 가능 저장 매체는 명령 실행 시스템, 장치 또는 장치에 의해 또는 이와 관련하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있는 임의의 유형의 매체일 수 있다. 본 발명의 개념의 설명은 예시 및 설명의 목적으로 제시되었지만, 개시된 형태의 발명 개념을 완전하게 하거나 제한하도록 의도되지 않는다. 본 발명의 개념의 범위 및 정신을 벗어나지 않으면서 많은 수정 및 변형이 당업자 에게 명백할 것이다. 본 명세서에서 본 발명의 개념의 측면은 본 발명의 개념 및 실제 적용의 원리를 가장 잘 설명하고 당업자가 고려되는 특정 용도에 적합한 다양한 수정으로 본 발명의 개념을 이해할 수 있도록 선택되고 설명되었다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2022-0078283", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예의 다른 특징은 첨부 도면과 함께 읽을 때 특정 실시예에 대한 다음 상세한 설명으로부터 더 쉽게 이해될 것이다: 도 1은 본 발명의 일부 실시예에 따른 메모리 내 컴퓨팅 가속기를 포함하는 인공 신경망 시스템을 포함하는 인 공 지능 시스템을 도시하는 블록도이다; 도 2는 본 발명의 일부 실시예에 따른 도 1의 인공 신경망 시스템을 도시하는 도면이다; 도 3은 본 발명의 일부 실시예에 따른 비트 단위 수정된 정류 선형 유닛(bm-ReLU) 활성화 함수를 도시하는 그래 프이다; 도 4 및 도 5는 본 발명의 일부 실시예에 따른 도 1의 메모리 내 컴퓨팅 가속기의 블록도이다; 도 6 내지 도 9는 본 발명의 일부 실시예에 따른 인공 신경망 시스템 및 메모리 내 컴퓨팅 가속기를 포함하는 도 1의 인공지능 시스템의 동작을 설명하기 위한 순서도이다; 도 10은 본 발명의 실시 예에 따른 인공 신경망 시스템 및 메모리 내 컴퓨팅 가속기를 포함하는 인공 지능 시스 템을 구현하는 데 사용될 수 있는 데이터 처리 시스템이다; 및 도 11은 본 발명의 일부 실시예에 따른 인공 신경망 시스템 및 메모리 내 컴퓨팅 가속기를 포함하는 인공 지능 시스템에서 사용하기 위한 소프트웨어/하드웨어 아키텍처를 도시하는 블록도이다."}
