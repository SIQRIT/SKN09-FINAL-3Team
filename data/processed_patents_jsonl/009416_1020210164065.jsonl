{"patent_id": "10-2021-0164065", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0077130", "출원번호": "10-2021-0164065", "발명의 명칭": "그래디언트를 이용한 원본 데이터 재복원 방법 및 서버", "출원인": "숭실대학교산학협력단", "발명자": "최대선"}}
{"patent_id": "10-2021-0164065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기본 그래디언트- 상기 기본 그래디언트는 대상 데이터 및 대상 데이터에 대응되는 대상 라벨을 인공지능 모델에 입력하여 산출된 값임 -를 획득하는 단계;상기 인공지능 모델에 제1 라벨 및 랜덤 함수를 이용해 추출된 제1 데이터를 입력하여 제1 그래디언트를 획득하는 단계;상기 기본 그래디언트와 상기 제1 그래디언트의 차이인 제1 디스턴스를 산출하는 단계;상기 인공지능 모델에 상기 랜덤 함수를 이용해 추출된 제2 데이터 및 상기 제1 라벨을 입력하여 제2 그래디언트를 획득하는 단계; 및상기 기본 그래디언트와 상기 제2 그래디언트의 차이인 제2 디스턴스를 산출하는 단계를 포함하고,상기 제2 디스턴스는 상기 제1 디스턴스보다 작은그래디언트를 이용한 원본 데이터 재복원 방법."}
{"patent_id": "10-2021-0164065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 라벨은 상기 대상 라벨과 동일한그래디언트를 이용한 원본 데이터 재복원 방법."}
{"patent_id": "10-2021-0164065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 인공지능 모델에 상기 랜덤 함수를 이용해 추출된 제3 데이터 및 상기 제1 라벨을 입력하여 제3 그래디언트를 획득하는 단계; 및상기 기본 그래디언트와 상기 제3 그래디언트의 차이인 제3 디스턴스를 산출하는 단계를 더 포함하고,상기 제3 디스턴스는 상기 제2 디스턴스보다 작은그래디언트를 이용한 원본 데이터 재복원 방법."}
{"patent_id": "10-2021-0164065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인공지능 모델은,하나 이상의 컨볼루션 층(convolution layer), 하나 이상의 완전 연결 층(fully connected layer) 및 다중 분류 층(multi classification layer)를 포함하고,상기 컨볼루션 층, 상기 완전 연결 층 및 상기 다중 분류 층의 순서대로 구성된그래디언트를 이용한 원본 데이터 재복원 방법.공개특허 10-2023-0077130-3-청구항 5 제1항에 있어서,상기 제1 데이터와 상이한 상기 제2 데이터를 출력하기 위해, 상기 랜덤 함수는 시간 기반의 함수인그래디언트를 이용한 원본 데이터 재복원 방법."}
{"patent_id": "10-2021-0164065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중의 어느 한 항에 기재된 그래디언트를 이용한 원본 데이터 재복원 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0164065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "그래디언트를 이용하여 원본 데이터를 재복원하는 프로세서를 포함하고,상기 프로세서는,인공지능 모델에 대상 데이터 및 상기 대상 데이터를 나타내는 대상 라벨을 입력하여 기본 그래디언트를 획득하고,상기 인공지능 모델에 랜덤 함수를 이용해 추출된 제1 데이터 및 고정된 수치를 갖는 제1 라벨을 입력하여 제1그래디언트를 산출하고,상기 기본 그래디언트와 상기 제1 그래디언트의 차이인 제1 디스턴스를 획득하고,상기 인공지능 모델에 상기 랜덤 함수를 이용해 추출된 제2 데이터 및 상기 제1 라벨을 입력하여 제2 그래디언트를 산출하고,상기 기본 그래디언트와 상기 제2 그래디언트의 차이인 제2 디스턴스- 상기 제2 디스턴스는 상기 제1 디스턴스보다 작음 -를 산출하는 단계를 포함하는그래디언트를 이용한 원본 데이터 재복원 서버."}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 그래디언트를 이용한 원본 데이터 재복원 방법은 기본 그래디언트- 상기 기본 그래디언트는 대상 데이 터 및 대상 데이터에 대응되는 대상 라벨을 인공지능 모델에 입력하여 산출된 값임 -를 획득하는 단계; 상기 인 공지능 모델에 제1 라벨 및 랜덤 함수를 이용해 추출된 제1 데이터를 입력하여 제1 그래디언트를 획득하는 단계; 상기 기본 그래디언트와 상기 제1 그래디언트의 차이인 제1 디스턴스를 산출하는 단계; 상기 인공지능 모델에 상 기 랜덤 함수를 이용해 추출된 제2 데이터 및 상기 제1 라벨을 입력하여 제2 그래디언트를 획득하는 단계; 및 상 기 기본 그래디언트와 상기 제2 그래디언트의 차이인 제2 디스턴스를 산출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 그래디언트를 이용한 원본 데이터 재복원 방법 및 서버에 관한 것으로, 보다 상세하게는, 특정 라벨 을 이용하여 그래디언트의 차이를 감소시키는 그래디언트를 이용한 원본 데이터 재복원 방법 및 서버에 관한 것 이다."}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "AI의 발전은 사람들에게 일상생활의 편의성과 이로움을 제공해주고 있다. 하지만 AI가 주는 이로움에 반해, 개 인 정보와 프라이버시 노출 가능성의 증가로 인한 피싱과 해킹 사고가 증가하고 있다. 이에 데이터를 보호할 수 있는 방법에 대한 연구가 증가하고 있으며, 익명화와 식별방지를 위해 데이터를 서버로 모으지 않고 학습하는 방법으로 연합학습이 대두되고 있다."}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는 특정 라벨을 이용하여 그래디언트를 획득하고, 그래디언트의 차이를 계산하여 원본 데이터 를 복원하는 방법에 관한 것이다."}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 그래디언트를 이용한 원본 데이터 재복원 방법은 기본 그래디언트- 상기 기본 그래디언트는 대상 데이터 및 대상 데이터에 대응되는 대상 라벨을 인공지능 모델에 입력하여 산출된 값임 -를 획득하는 단계; 상기 인공지능 모델에 제1 라벨 및 랜덤 함수를 이용해 추출된 제1 데이터를 입력하여 제1 그래디언트를 획득하는 단계; 상기 기본 그래디언트와 상기 제1 그래디언트의 차이인 제1 디스턴스를 산출하는 단계; 상기 인 공지능 모델에 상기 랜덤 함수를 이용해 추출된 제2 데이터 및 상기 제1 라벨을 입력하여 제2 그래디언트를 획 득하는 단계; 및 상기 기본 그래디언트와 상기 제2 그래디언트의 차이인 제2 디스턴스를 산출하는 단계를 포함 하고, 상기 제2 디스턴스는 상기 제1 디스턴스보다 작을 수 있다. 여기서, 상기 제1 라벨은 상기 대상 라벨과 동일할 수 있다. 여기서, 상기 인공지능 모델에 상기 랜덤 함수를 이용해 추출된 제3 데이터 및 상기 제1 라벨을 입력하여 제3 그래디언트를 획득하는 단계; 및 상기 기본 그래디언트와 상기 제3 그래디언트의 차이인 제3 디스턴스를 산출하 는 단계를 더 포함하고, 상기 제3 디스턴스는 상기 제2 디스턴스보다 작을 수 있다. 여기서, 상기 인공지능 모델은, 하나 이상의 컨볼루션 층(convolution layer), 하나 이상의 완전 연결 층(fully connected layer) 및 다중 분류 층(multi classification layer)를 포함하고, 상기 컨볼루션 층, 상기 완전 연 결 층 및 상기 다중 분류 층의 순서대로 구성될 수 있다. 여기서, 상기 제1 데이터와 상이한 상기 제2 데이터를 출력하기 위해, 상기 랜덤 함수는 시간 기반의 함수일 수 있다. 여기서, 상기 그래디언트를 이용한 원본 데이터 재복원 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 제공될 수 있다. 일 실시예에 따른 그래디언트를 이용한 원본 데이터 재복원 서버는 그래디언트를 이용하여 원본 데이터를 재복 원하는 프로세서를 포함하고, 상기 프로세서는, 인공지능 모델에 대상 데이터 및 상기 대상 데이터를 나타내는 대상 라벨을 입력하여 기본 그래디언트를 획득하고, 상기 인공지능 모델에 랜덤 함수를 이용해 추출된 제1 데이 터 및 고정된 수치를 갖는 제1 라벨을 입력하여 제1 그래디언트를 산출하고, 상기 기본 그래디언트와 상기 제1 그래디언트의 차이인 제1 디스턴스를 획득하고, 상기 인공지능 모델에 상기 랜덤 함수를 이용해 추출된 제2 데 이터 및 상기 제1 라벨을 입력하여 제2 그래디언트를 산출하고, 상기 기본 그래디언트와 상기 제2 그래디언트의 차이인 제2 디스턴스- 상기 제2 디스턴스는 상기 제1 디스턴스보다 작음 -를 산출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 특정 라벨을 이용하여 그래디언트를 획득하고, 그래디언트의 차이를 계산하여 원 본 데이터를 복원하는 방법이 제공될 수 있다."}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기재된 실시예는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 사상을 명 확히 설명하기 위한 것이므로, 본 발명이 본 명세서에 기재된 실시예에 한정되는 것은 아니며, 본 발명의 범위 는 본 발명의 사상을 벗어나지 아니하는 수정예 또는 변형예를 포함하는 것으로 해석되어야 한다. 본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하여 가능한 현재 널리 사용되고 있는 일반적인 용어 를 선택하였으나 이는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자의 의도, 판례 또는 새로운 기술 의 출현 등에 따라 달라질 수 있다. 다만, 이와 달리 특정한 용어를 임의의 의미로 정의하여 사용하는 경우에는 그 용어의 의미에 관하여 별도로 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가진 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 한다. 본 명세서에 첨부된 도면은 본 발명을 용이하게 설명하기 위한 것으로 도면에 도시된 형상은 본 발명의 이해를 돕기 위하여 필요에 따라 과장되어 표시된 것일 수 있으므로 본 발명이 도면에 의해 한정되는 것은 아니다. 본 명세서에서 본 발명에 관련된 공지의 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있 다고 판단되는 경우에 이에 관한 자세한 설명은 필요에 따라 생략하기로 한다. 도 1은 연합학습을 설명하기 위한 도면이다. 도 1을 참조하면, 연합학습은 서버 및 제1 디바이스를 통해 이루어질 수 있다. 연합학습은 익명화 와 식별방지를 위해 데이터를 서버로 모으지 않고 학습하는 방법이다. 서버에 저장된 인공지능 모델을 각 디바이스(2000, 3000)에 전송하고, 각 디바이스(2000, 3000)들은 수신 한 인공지능 모델을 통해 학습(로컬 트레이닝)할 수 있다. 서버는 각 디바이스(2000, 3000)로부터 데이터 를 수신하는 것이 아닌, 인공지능 모델을 통해 추출된 결과값을 수신하기 때문에, 데이터의 집적으로 발생되는 프라이버시 침해를 예방할 수 있다. 연합학습을 하기 위해, 서버는 인공지능 모델을 제1 디바이스로 전송할 수 있다. 제1 디바이스 는 서버와 통신할 수 있는 전자 장치로서, 일반적인 무선 통신 또는 유선 통신의 방식으로 서버 와 통신할 수 있다. 예를 들어, 제1 디바이스는 사용자 단말기일 수 있다. 제1 디바이스는 수신한 인공지능 모델을 학습시킬 수 있다. 구체적으로, 제1 디바이스는 데이터와 데이터에 대응되는 라벨을 인공지능 모델에 입력시켜, 인공지능 모델을 학습시킬 수 있다. 제1 디바이스 를 통해 수행되는 인공지능 모델의 학습은 로컬 트레이닝일 수 있다. 인공지능 모델은 학습된 이후, 가중치(weight), 바이어스(bias), 그래디언트(gradient) 및 파라미터 (parameter)를 업데이트할 수 있다. 제1 디바이스는 인공지능 모델로부터 업데이트된 가중치(weight), 바 이어스(bias), 그래디언트(gradient) 및 파라미터(parameter)를 획득할 수 있다. 제1 디바이스는 가중치(weight), 바이어스(bias), 그래디언트(gradient) 및 파라미터(parameter) 중 적 어도 하나와 관련된 데이터를 서버로 전송할 수 있다. 서버는 제1 디바이스로부터 획득한 가 중치(weight), 바이어스(bias), 그래디언트(gradient) 및 파라미터(parameter)를 통해 인공지능 모델을 학습시 킬 수 있다. 즉, 서버는 제1 디바이스로부터 수신한 값들을 통해 글로벌 모델을 학습시키는 글로벌 트레이닝을 수행할 수 있다. 서버는 제1 디바이스와 수행했던 위 과정을 제1 디바이스와 다른 디바이스인 제2 디바이스 를 통해서도 수행할 수 있다. 제2 디바이스는 제1 디바이스와 유사하게, 서버와 통신 할 수 있는 전자 장치일 수 있다. 예를 들어, 제2 디바이스는 사용자 단말기일 수 있다. 서버가 디바이스에 모델에 대한 데이터를 전송하고, 디바이스로부터 업데이트된 값을 수신하는 과정을 1 라운드로 정의할 수 있다. 서버는 제1 디바이스와 N 라운드를 통해 연합학습을 수행할 수 있다. 또 한, 서버는 제1 디바이스와 다른 디바이스인 제2 디바이스와 M 라운드를 통해 연합학습을 수 행할 수 있다. 도 2는 일반적인 그래디언트를 이용한 원본 데이터 재복원 방법을 설명하기 위한 도면이다. 도 2(a)는 디바이스가 인공지능 모델을 통해 로컬 트레이닝하여 값을 서버로 전송하는 과정을 도시한 것 이고, 도 2(b)는 서버가 인공지능 모델을 글로벌 트레이닝하는 과정을 도시한 것이다.도 2(a)를 참조하면, 디바이스는 수신한 인공지능 모델에 대상 데이터 및 상기 대상 데이터(110, 원본 데 이터)에 대응되는 대상 라벨을 입력시킬 수 있다. 대상 데이터는 특정 이미지를 표현하는 데이터일 수 있다. 또한, 대상 라벨은 상기 특정 이미지를 표시하기 위한 라벨일 수 있다. 예를 들어, 디바이스가 0 내지 9를 표현하는 손글씨 데이터 셋인 MNIST 데이터 셋을 사용할 경우, 대상 데이터 는 0 내지 9 중 하나의 숫자를 표현하는 데이터 셋일 수 있다. 구체적으로, 도 2의 예시와 같이, 대상 데 이터는 숫자 0을 표현하는 행렬일 수 있다. 또한 예를 들어, 디바이스가 MNIST 데이터 셋을 사용할 경우, 대상 라벨은 대상 데이터를 표시하기 위한 값일 수 있다. 구체적으로, 도 2의 예시와 같이, 대상 라벨은 숫자 0을 표시하기 위해 (1,0,0,0,0,0,0,0,0,0)의 값을 가질 수 있다. 위 예시는 MNIST 데이터 셋을 사용할 경우이나, 이에 한정되지 않고, 대상 데이터 및 대상 라벨은 다 른 데이터 셋을 기반으로 다양한 값을 가질 수 있다. 예를 들어, 디바이스는 MNIST, CIFAR-10, COCO, VOC 등의 데이터 셋을 사용할 수 있으나, 이에 한정되지 않는다. 디바이스는 대상 데이터 및 대상 라벨을 인공지능 모델에 입력시킬 수 있다. 인공지능 모델 은 서버로부터 획득한 것일 수 있다. 인공지능 모델은 하나 이상의 컨볼루션 층(convolution layer), 하나 이상의 완전 연결 층(fully connected layer) 및 다중 분류 층(multi classification layer)을 포함하는 컨볼루션 신경망(CNN: Convolutional Neural Network) 모델일 수 있다. 예를 들어, 디바이스가 MNIST 데이터 셋을 사용할 경우, 인공지능 모델에 포함된 다중 분류 층은 마지막 층으로서 데이터를 0부터 9까지 10개로 분류할 수 있다. 인공지능 모델은 입력값에 기초하여 가중치(weight), 바이어스(bias), 그래디언트(gradient) 및 파라미터 (parameter)의 값을 업데이트할 수 있다. 특히, 본원 발명은 서버를 통해 인공지능 모델에 의해 업 데이트 또는 산출된 그래디언트를 이용하여 데이터를 재복원시킬 수 있다. 인공지능 모델은 대상 데 이터 및 대상 라벨에 기초하여 기본 그래디언트를 산출할 수 있다. 디바이스는 인공지능 모델에 의해 산출된 결과값들을 서버로 전송할 수 있다. 특히, 디바이스는 기 본 그래디언트를 서버로 전송할 수 있다. 디바이스는 데이터가 아닌 인공지능 모델에 의해 산 출된 결과값들을 서버로 전송하기 때문에, 프라이버시 침해를 예방할 수 있다. 도 2(b)를 참조하면, 서버도 인공지능 모델을 학습시켜, 결과값들을 산출할 수 있다. 구체적으로, 서버는 인공지능 모델에 랜덤 데이터 중 하나인 제1 데이터 및 랜덤 데이터 중 하나인 제1 라 벨를 입력시킬 수 있다. 제1 데이터 및 제1 라벨은 랜덤 함수에 의해 생성된 값일 수 있다. 이때, 랜덤 함수는 시간 기반의 함수일 수 있다. 랜덤 함수가 시간 기반이기 때문에, 랜덤 함수는 항상 이전과 상이한 값을 출력할 수 있다. 예 를 들어, 상기 랜덤 함수는 시간 정보를 이용하는 srand 함수, 랜덤을 적용하는 manual.seed 함수, 시간 정보를 이용하는 time.time 함수 또는 이들의 결합을 통해 구현될 수 있다. 서버는 제1 데이터 및 제1 라벨에 기초하여 인공지능 모델에 의해 산출된 결과값을 획득 할 수 있다. 구체적으로, 인공지능 모델에 의해 업데이트된 가중치(weight), 바이어스(bias), 그래디언트 (gradient) 및 파라미터(parameter) 값을 획득할 수 있다. 특히, 서버는 제1 데이터 및 제1 라벨 에 의해 산출된 제1 그래디언트를 획득할 수 있다. 도 3은 종래의 그래디언트를 이용한 원본 데이터 재복원 방법을 설명하기 위한 도면이다. 도 3을 참조하면, 도 2의 과정에서 획득한 기본 그래디언트 및 제1 그래디언트를 활용하여 서버 가 데이터를 복원하는 과정을 알 수 있다. 위 도 2를 참조하여 설명한 내용과 같이, 디바이스는 인공지능 모델을 통해 대상 데이터 및 대상 라 벨에 기초하여 기본 그래디언트를 획득할 수 있다. 디바이스는 기본 그래디언트를 서버로 전송할 수 있다.또한, 서버도 인공지능 모델을 통해 제1 데이터 및 제1 라벨에 기초하여 제1 그래디언트 를 획득할 수 있다. 이때, 서버는 제1 그래디언트와 디바이스로부터 획득한 기본 그래디언트 를 비교할 수 있다. 구체적으로, 서버는 기본 그래디언트와 제1 그래디언트의 차이인 제1 디스턴스(distance)를 산출할 수 있다. 서버가 제1 디스턴스를 산출하는 과정을 1번째 이터레이션 (iteration)으로 정의할 수 있다. 제1 디스턴스를 산출한 이후, 서버는 다시 인공지능 모델에 제2 데이터 및 제2 라벨을 입력시킬 수 있다. 이때, 제2 데이터 및 제2 라벨도 랜덤 함수에 의해 생성된 데이터일 수 있다. 따라서, 제2 데이터는 제1 데이터와 상이하고, 제2 라벨은 제1 라벨와 상이할 수 있다. 서버는 인공지능 모델을 통해 제2 데이터 및 제2 라벨에 기초하여 제2 그래디언트를 획득할 수 있다. 이때, 서버는 기본 그래디언트와 제2 그래디언트를 비교할 수 있다. 구체적으로, 서버 는 기본 그래디언트와 제2 그래디언트의 차이인 제2 디스턴스를 산출할 수 있다. 서버가 제2 디스턴 스를 산출하는 과정을 2번째 이터레이션으로 정의할 수 있다. 이때, 제2 디스턴스는 제1 디스턴스보다 작은 값일 수 있다. 즉, 서버는 이터레이션을 거듭하여, 기본 그 래디언트와 서버가 산출하는 그래디언트의 차이를 줄일 수 있다. 이는 서버가 디바이스가 사용한 대상 데이터 및 대상 라벨을 랜덤 함수에 의해 생성된 데이터 및 라벨을 통해 복원하는 과정일 수 있다. 서버는 이터레이션을 거듭하여, 인공지능 모델을 학습시키고, 학습된 인공지능 모델을 통해, 디바이스가 사용한 대상 데이터 및 라벨을 추출, 예측, 복원 또는 재생성할 수 있다. 즉, 그래디언트를 통해 데이터를 복원하는 기술을 통해, 연합학습의 프라이버시가 침해될 수 있다. 본원 발명은 그래디언트를 통한 데이터 복원 기술에서, 특히 복원할 데이터의 라벨을 알고 있는 경우에 대한 것이다. 즉, 본 원 발명은 복원할 데이터의 라벨을 이용하여 그래디언트를 통한 데이터를 복원하는 방법에 관한 것이다. 이에 대해서 이하에서 도 4 및 도 5를 참조하여 설명한다. 도 4는 본원 발명의 일 실시예에 따른 그래디언트를 이용한 원본 데이터 재복원 방법을 설명하기 위한 도면이다. 본원 발명의 데이터 재복원 방법의 주체는 서버의 프로세서일 수 있다. 이하에서 특별한 언급 이 없는 경우에는, 서버의 동작은 프로세서에 의해 수행되는 것으로 해석될 수 있다. 도 4를 참조하면, 디바이스로부터 획득한 기본 그래디언트 및 서버가 산출한 제1 그래디언트를 활용하여 서버가 데이터를 복원하는 과정을 알 수 있다. 위 도 2를 참조하여 설명한 내용과 같이, 디바이스는 인공지능 모델을 통해 대상 데이터 및 대상 라 벨에 기초하여 기본 그래디언트를 획득할 수 있다. 디바이스는 기본 그래디언트를 서버로 전송할 수 있다. 서버도 인공지능 모델을 통해 제1 데이터 및 제1 라벨에 기초하여 제1 그래디언트를 획득할 수 있다. 구체적으로, 서버는 인공지능 모델에 랜덤 데이터 중 하나인 제1 데이터 및 고정된 수치를 가지는 제1 라벨을 입력시킬 수 있다. 이때, 제1 라벨은 랜덤 함수에 의해 생성된 값 이 아닌, 특정 값일 수 있다. 구체적으로, 제1 라벨은 디바이스에서 이용된 대상 라벨과 동일한 값일 수 있다. 서버는 디바 이스로부터 대상 라벨의 값을 수신하거나 다른 방법을 통해 디바이스에서 이용된 대상 라벨의 값을 획득할 수 있다. 이때, 상기 다른 방법이란 상기 디바이스가 아닌 다른 외부 장치로부터 값을 수신하는 방법 또는 디바이스를 해 킹하는 방법일 수도 있다. 또는, 서버는 데이터 셋의 라벨 중 특정 하나의 값을 지정하여 사용할 수도 있 다. 예를 들어, 서버는 MNIST의 데이터 셋 중 0 내지 9를 표시하는 라벨을 지정하여 사용할 수 있다. 이 때, 서버는 그래디언트의 차이를 확인하면서 지정된 라벨을 수정할 수 있다. 구체적인 예를 들어, 대상 라벨이 0에 대한 라벨인 경우, 서버는 0 내지 9를 표시하는 10개의 라벨 각각을 사용하여 10개의 그래디언트를 산출하고, 각 그래디언트와 기본 그래디언트의 차이를 산출하여, 차 이가 가장 적은 그래디언트를 출력하는 라벨을 사용할 수도 있다.서버는 기본 그래디언트와 제1 그래디언트의 차이인 제1 디스턴스를 산출할 수 있다. 또한, 서버는 인공지능 모델을 통해 제2 데이터 및 제1 라벨에 기초하여 제2 그래디언트를 획 득할 수 있다. 구체적으로, 서버는 인공지능 모델에 랜덤 데이터 중 하나인 제2 데이터 및 고정된 수치를 가지는 제1 라벨을 입력시킬 수 있다. 이때, 제2 데이터는 제1 데이터와 상이한 값을 가질 수 있다. 서버는 기본 그래디언트와 제2 그래디언트의 차이인 제2 디스턴스를 산출할 수 있다. 이때, 제2 디 스턴스는 제1 디스턴스보다 작은 값일 수 있다. 따라서, 서버는 이터레이션을 거듭하여 0에 수렴하는 디 스턴스를 획득할 수 있다. 디스턴스가 0에 수렴할수록, 복원하는 데이터는 대상 데이터와 유사해질 수 있 다. 특히, 본원 발명은 랜덤 함수에 기초한 라벨이 아닌 특정 라벨을 이용함으로써, 이터레이션의 수를 줄일 수 있 다. 즉, 랜덤 라벨이 아닌 특정 라벨을 사용하면, 적은 이터레이션을 통해서도 원본 데이터와 유사한 데이터를 획득할 수 있다. 이때, 특정 라벨은 대상 데이터에 대응되는 라벨인 대상 라벨일 수 있다. 도 5는 본원 발명의 일 실시예에 따른 그래디언트를 이용한 원본 데이터 재복원 방법의 순서도이다. 도 5를 참조하면, 본원 발명의 일 실시예에 따른 그래디언트를 이용한 원본 데이터 재복원 방법은 기본 그래디 언트를 획득하는 단계(S110), 제1 그래디언트를 획득하는 단계(S120), 기본 그래디언트와 제1 그래디언트의 차 이인 제1 디스턴스를 산출하는 단계(S130), 제2 그래디언트를 획득하는 단계(S140) 및 기본 그래디언트와 제2 그래디언트의 차이인 제2 디스턴스를 산출하는 단계(S150)를 포함할 수 있다. 기본 그래디언트를 획득하는 단계(S110)는 도 4에서 서버가 디바이스로부터 대상 데이터 및 대상 라 벨에 기초하여 인공지능 모델을 통해 산출된 기본 그래디언트를 획득하는 단계일 수 있다. 제1 그래디언트를 획득하는 단계(S120)는 도 4에서 서버가 랜덤 데이터인 제1 데이터 및 특정 값을 가지는 제1 라벨에 기초하여 인공지능 모델을 통해 산출된 제1 그래디언트를 획득하는 단계일 수 있다. 기본 그래디언트와 제1 그래디언트의 차이인 제1 디스턴스를 산출하는 단계(S130)는 서버가 단계 S110에 서 수신한 기본 그래디언트와 단계 S120에서 획득한 제1 그래디언트의 차이를 계산하는 단계일 수 있 다. 제2 그래디언트를 획득하는 단계(S140)는 서버가 랜덤 데이터인 제2 데이터 및 특정 값을 가지는 제1 라 벨에 기초하여 인공지능 모델을 통해 산출된 제2 그래디언트를 획득하는 단계일 수 있다. 기본 그래디언트와 제2 그래디언트의 차이인 제2 디스턴스를 산출하는 단계(S150) 서버가 단계 S110에서 수신한 기본 그래디언트와 단계 S140에서 획득한 제2 그래디언트의 차이를 계산하는 단계일 수 있다. 단계 S150 이후, 서버는 단계 S120 내지 S140과 같이, 제3 그래디언트를 획득하는 단계를 수행할 수 있다. 또한, 서버는 기본 그래디언트와 제3 그래디언트의 차이인 제3 디스턴스를 산출하는 단계를 수행할 수 있다. 또한, 서버는 제N 그래디언트를 획득하는 단계 및 제N 디스턴스를 산출하는 단계를 수행 할 수 있다. 이때, N은 이터레이션의 횟수일 수 있다. 도 6은 종래의 방법과 본원 발명의 방법에 따른 데이터 재복원 결과를 비교하기 위한 도면이다. 도 6(a)는 종래 의 데이터 재복원 방법에 따른 결과를 나타낸 도면이고, 도 6(b)는 본원 발명의 데이터 재복원 방법에 따른 결 과를 나타낸 도면이다. 도 6(a)를 참조하면, 종래의 데이터 재복원 방법은 랜덤 데이터 및 랜덤 라벨을 이용한 방법으로, 이터레이션의 횟수가 70 내지 80이 되어야 원본 데이터의 형상이 나타난다. 도 6(b)를 참조하면, 본원 발명의 데이터 재복원 방법은 랜덤 데이터 및 특정 라벨을 이용한 방법으로, 이터레 이션의 횟수가 20 내지 30이 되면 원본 데이터의 형상이 나타난다. 즉, 본원 발명의 데이터 재복원 방법은 종래보다 이터레이션의 횟수를 줄일 수 있고, 이에 따른 재복원 시간 및 비용을 감축할 수 있다. 도 7은 MNIST 데이터 셋을 이용했을 경우, 종래의 방법과 본원 발명의 방법을 비교 평가한 결과이다. 도 7(a)는 이터레이션 횟수에 따른 평균 제곱 오차(MSE: Mean Squared Errer)를 나타낸 그래프이고, 도 7(b)는 이터레이션 횟수에 따른 로스(Loss)를 나타낸 그래프이고, 도 7(c)는 이터레이션 횟수에 따른 최대신호 대 잡음 비(PSNR: Peak Signal-to-Noise Ratio)를 나타낸 그래프이고, 도 7(d)는 이터레이션 횟수에 따른 이미지 품질 평가(SSIM: Structural Similarity)를 나타낸 그래프이다. 도 7(a)를 참조하면, 평균 제곱 오차는 각 값들이 얼마나 멀리 떨어져 있는지를 나타내는 지표로, 작을수록 좋 은 성능을 나타낼 수 있다. 종래의 방법과 비교했을 때, 본원 발명의 평균 제곱 오차가 종래보다 낮은 수치를 보여주는 것을 알 수 있다. 도 7(b)를 참조하면, 로스는 원본 데이터의 그래디언트와 랜덤 데이터의 그래디언트의 차이를 나타내는 지표로, 값이 적을수록 데이터가 이미지에 가까워짐을 알 수 있다. 종래의 방법과 비교했을 때, 본원 발명의 로스가 종 래보다 낮은 수치를 보여주는 것을 알 수 있다. 도 7(c)를 참조하면, 최대신호 대 잡음비는 영상, 동영상 등의 화질 손실 정보를 평가하는 지표로, 값이 클수록 이미지의 차이가 작은 것을 알 수 있다. 종래의 방법과 비교했을 때, 본원 발명의 최대신호 대 잡음비가 종래보 다 높은 수치를 보여주는 것을 알 수 있다. 도 7(d)를 참조하면, 이미지 품질 평가는 수치적인 차이가 아닌 인간의 시각적 화질 차이 및 유사도를 평가하기 위한 지표로, 값이 클수록 품질이 좋은 것을 알 수 있다. 종래의 방법과 비교했을 때, 본원 발명의 이미지 품질 평가 종래보다 높은 수치를 보여주는 것을 알 수 있다. 도 8은 CIFAR-10 데이터 셋을 이용했을 경우, 종래의 방법과 본원 발명의 방법을 비교 평가한 결과이다. 도 8(a)는 이터레이션 횟수에 따른 평균 제곱 오차(MSE: Mean Squared Errer)를 나타낸 그래프이고, 도 8(b)는 이터레이션 횟수에 따른 로스(Loss)를 나타낸 그래프이고, 도 8(c)는 이터레이션 횟수에 따른 최대신호 대 잡음 비(PSNR: Peak Signal-to-Noise Ratio)를 나타낸 그래프이고, 도 8(d)는 이터레이션 횟수에 따른 이미지 품질 평가(SSIM: Structural Similarity)를 나타낸 그래프이다. 도 8(a)를 참조하면, 종래의 방법과 비교했을 때, 본원 발명의 평균 제곱 오차가 종래보다 낮은 수치를 보여주 는 것을 알 수 있다. 도 8(b)를 참조하면 종래의 방법과 비교했을 때, 본원 발명의 로스가 종래보다 낮은 수치를 보여주는 것을 알 수 있다. 도 8(c)를 참조하면, 종래의 방법과 비교했을 때, 본원 발명의 최대신호 대 잡음비가 종래보다 높은 수치를 보 여주는 것을 알 수 있다. 도 8(d)를 참조하면, 종래의 방법과 비교했을 때, 본원 발명의 이미지 품질 평가 종래보다 높은 수치를 보여주 는 것을 알 수 있다. 따라서, 도 7 및 도 8에서도 알 수 있듯이, 본원 발명은 특정 데이터 셋에 한정하여 효과를 보이는 것이 아니라, 다양한 데이터 셋에서도 종래보다 나은 효과가 도출됨을 알 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다"}
{"patent_id": "10-2021-0164065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2021-0164065", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 연합학습을 설명하기 위한 도면이다. 도 2는 일반적인 그래디언트를 이용한 원본 데이터 재복원 방법을 설명하기 위한 도면이다. 도 3은 종래의 그래디언트를 이용한 원본 데이터 재복원 방법을 설명하기 위한 도면이다. 도 4는 본원 발명의 일 실시예에 따른 그래디언트를 이용한 원본 데이터 재복원 방법을 설명하기 위한 도면이다. 도 5는 본원 발명의 일 실시예에 따른 그래디언트를 이용한 원본 데이터 재복원 방법의 순서도이다. 도 6은 종래의 방법과 본원 발명의 방법에 따른 데이터 재복원 결과를 비교하기 위한 도면이다. 도 7은 MNIST 데이터 셋을 이용했을 경우, 종래의 방법과 본원 발명의 방법을 비교 평가한 결과이다. 도 8은 CIFAR-10 데이터 셋을 이용했을 경우, 종래의 방법과 본원 발명의 방법을 비교 평가한 결과이다."}
