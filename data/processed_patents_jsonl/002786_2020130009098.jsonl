{"patent_id": "20-2013-0009098", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "20-2014-0003899", "출원번호": "20-2013-0009098", "출원인": "주식회사 크라스아이디"}}
{"patent_id": "20-2013-0009098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 영상을 촬영하여 입력하는 영상 촬영부;상기 영상 촬영부에서 입력되는 영상에서 얼굴과 눈을 검출하여 얼굴을 인증하는 얼굴 인식부; 및상기 영상 촬영부에서 입력되는 영상에서 상기 얼굴과 상기 눈을 검출하고, 검출된 상기 눈을 기준으로 상기 얼굴의 크기와 회전에 대한 정규화 과정을 수행하여 얼굴 영상을 정규화하며, 정규화된 상기 얼굴 영상에 대해 히스토그램 평활화 과정을 통해 조명 분포를 고르게 하는 조명 정규화 과정을 거치고, 상기 조명 정규화 과정이완료된 상기 얼굴 영상에 대해 M×N의 영역으로 세부 분할 후 각 영역에 대해 균일국부이진패턴 형식에 대한 히스토그램 특징으로 히스토그램 특징값을 추출하며, 상기 히스토그램 특징값에 대하여 인공 신경망 분석 과정을통해 상기 얼굴에 대한 표정을 인식하는 표정 인식부;를 포함하는 표정 인식 기술이 적용된 인텔리전트 완구 시스템."}
{"patent_id": "20-2013-0009098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 표정 인식 기술이 적용된 인텔리전트 완구 시스템은 상기 표정 인식부에서 인식된 사용자의 표정에 따라미리 설정된 음향을 출력하는 출력부;를 포함하는 것을 특징으로 하는 표정 인식 기술이 적용된 인텔리전트 완구 시스템."}
{"patent_id": "20-2013-0009098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 표정 인식 기술이 적용된 인텔리전트 완구 시스템은 상기 표정 인식부에서 인식된 사용자의 표정에 따라상기 인텔리전트 완구 시스템이 미리 설정된 특정 반응을 수행하도록 하는 출력부;를 포함하는 것을 특징으로하는 표정 인식 기술이 적용된 인텔리전트 완구 시스템.명 세 서기 술 분 야본 고안은 표정 인식 기술이 적용된 인텔리전트 완구 시스템에 관한 것이다. [0001]배 경 기 술완구는 아이들이 가지고 노는 장난감으로, 종래의 완구는 만화 캐릭터 등 특정 캐릭터를 흉내내는 수준으로, 단 [0002]지 소유를 하거나 단순히 가지고 노는 놀이 수준에 한정되고, 완구가 사용자에 대하여 스스로 반응하는 지능을갖추지 못하여 쉽게 실증이 나는 단점이 있다.이러한 단점을 개선하기 위하여, 완구에 사용자의 얼굴 또는 음성을 인식하여 그에 반응하도록 하는 기술이 개 [0003]발되고 있으나, 그러한 반응을 위한 데이터 처리 속도 향상에 한계가 있어서, 완구가 제대로 사용자에게 반응하지 못하는 문제가 있었다. 이러한 문제를 해결하기 위한 노력의 일환으로, Yubo WANG, Haizhou AI, Bo WU,Chang HUANG가 공동 기술한 \"Real Time Facial Expression Recognition with Adaboost\" 등의 논고에서와 같은방법이 제시되고 있으나, 여전히 데이터 처리 속도 향상에 한계가 있다.선행기술문헌비특허문헌(비특허문헌 0001) 1. Yubo WANG, Haizhou AI, Bo WU, Chang HUANG가 공동 기술한 \"Real Time Facial [0004]Expression Recognition with Adaboost\" 공개실용신안 20-2014-0003899-3-고안의 내용해결하려는 과제본 고안은 사용자에 대하여 능동적이면서도 신속하게 반응할 수 있는 지능을 갖춘 표정 인식 기술이 적용된 인 [0005]텔리전트 완구 시스템을 제공하는 것을 일 목적으로 한다.과제의 해결 수단본 고안의 일 측면에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템은 사용자의 영상을 촬영하여 입력 [0006]하는 영상 촬영부; 상기 영상 촬영부에서 입력되는 영상에서 얼굴과 눈을 검출하여 얼굴을 인증하는 얼굴 인식부; 및 상기 영상 촬영부에서 입력되는 영상에서 상기 얼굴과 상기 눈을 검출하고, 검출된 상기 눈을 기준으로상기 얼굴의 크기와 회전에 대한 정규화 과정을 수행하여 얼굴 영상을 정규화하며, 정규화된 상기 얼굴 영상에대해 히스토그램 평활화 과정을 통해 조명 분포를 고르게 하는 조명 정규화 과정을 거치고, 상기 조명 정규화과정이 완료된 상기 얼굴 영상에 대해 M×N의 영역으로 세부 분할 후 각 영역에 대해 균일국부이진패턴 형식에대한 히스토그램 특징으로 히스토그램 특징값을 추출하며, 상기 히스토그램 특징값에 대하여 인공 신경망 분석과정을 통해 상기 얼굴에 대한 표정을 인식하는 표정 인식부;를 포함한다.고안의 효과본 고안의 일 측면에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에 의하면, 얼굴 영상 전체 영역에 [0007]대해 특징을 추출하고 표정 인식을 하는 것이 아니라, 표정 변화에 민감한 특정 영역들에 대해서만 인식 처리를수행함으로써, 표정 인식을 위하여 처리되어야 하는 데이터량이 현저하게 감소될 수 있고, 그에 따라 보다 신속한 표정 인식이 가능해질 수 있고, 나아가 실시간의 표정 인식이 가능해질 수 있으며, 사용자에 대하여 스스로반응하는 지능을 갖추어 사용자의 흥미를 지속적이고 능동적으로 유발할 수 있는 효과가 있다.도면의 간단한 설명도 1은 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템의 구성을 보이는 블럭도. [0008]도 2는 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 얼굴 인증이 수행되는 과정을 보이는 순서도.도 3은 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 표정 인식이 수행되는 과정을 보이는 순서도.도 4는 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 음성 인식이 수행되는 과정을 보이는 순서도.도 5는 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 특정 화소를 중심으로 국부이진패턴값을 계산하는 방법을 나타내는 도면.도 6은 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 국부이진패턴 기법이적용되는 특정 예시도로 얼굴 영상에서의 소정의 중심 화소를 중심으로 인접 화소들의 화소값을 기준으로 국부이진패턴 패턴을 획득하는 과정을 보여주는 도면.도 7은 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 학습단계에서 사용된인공 신경망의 구조를 보이는 도면.고안을 실시하기 위한 구체적인 내용이하에서는 도면을 참조하여 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에 [0009]대하여 설명한다.도 1은 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템의 구성을 보이는 블럭도 [0010]이고, 도 2는 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 얼굴 인증이수행되는 과정을 보이는 순서도이고, 도 3은 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트공개실용신안 20-2014-0003899-4-완구 시스템에서 표정 인식이 수행되는 과정을 보이는 순서도이고, 도 4는 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 음성 인식이 수행되는 과정을 보이는 순서도이고, 도 5는 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 특정 화소를 중심으로 국부이진패턴값을 계산하는 방법을 나타내는 도면이고, 도 6은 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 국부이진패턴 기법이 적용되는 특정 예시도로 얼굴 영상에서의 소정의 중심 화소를 중심으로 인접 화소들의 화소값을 기준으로 국부이진패턴 패턴을 획득하는 과정을 보여주는 도면이고, 도 7은 본고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에서 학습단계에서 사용된 인공 신경망의 구조를 보이는 도면이다.도 1 내지 도 7을 함께 참조하면, 본 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템(100)은 [0011]동작 센서부(115)와, 영상 촬영부(110)와, 얼굴 인식부(120)와, 표정 인식부(130)와, 음성 인식부(140)와, 출력부(150)를 포함한다.상기 영상 촬영부(110)는 카메라 등으로서, 사용자의 영상을 촬영하여 입력하는 것이다. [0012]상기 영상 촬영부(110)에서 입력되는 영상에 대해 히스토그램 평활화 과정을 통해 조명 분포를 고르게 하는 조 [0013]명 정규화 과정을 거치게 된다.상기 동작 센서부(115)는 사용자의 동작을 감지하여 상기 인텔리전트 완구 시스템(100)을 슬립 모드(sleep [0014]mode)에서 깨우는 기능을 수행할 수 있는 것이다.상기 얼굴 인식부(120)는 상기 영상 촬영부(110)에서 입력되는 영상에서 얼굴과 눈을 검출하여 얼굴을 인증하는 [0015]것이다. 상기 얼굴 인식부(120)는 상기 영상 촬영부(110)에서 촬영되어 입력되는 영상에서 얼굴과 눈을 검출한다음, 미리 등록되어 있는 얼굴 데이터와 비교하여, 사용자의 얼굴을 인증한다.상기 표정 인식부(130)는 상기 얼굴 인식부(120)에서 인식된 얼굴 영상을 세부 분할 후 각 영역에 대해 균일국 [0016]부이진패턴(uniform local binary pattern, ULBP) 형식에 대한 히스토그램 특징값을 추출하고, 상기 추출된 히스토그램 특징값을 인공 신경망(artificial neural network) 분석 과정을 통해 표정을 인식하는 것이다.상기 표정 인식부(130)는 상기 영상 촬영부(110)에서 입력되어 상기 얼굴 인식부(120)에서 인증된 사용자의 얼 [0017]굴 영상에서 얼굴의 표정 변화를 인식하여, 상기 출력부(150)가 미리 설정된 특정한 곡, 멘트 등을 재생하거나,상기 인텔리전트 완구 시스템(100)이 손을 흔드는 동작 등의 특정 반응이 출력되도록 한다.상기 음성 인식부(140)는 입력되는 사용자의 음성을 미리 설정된 음성과 비교하여, 사용자의 입력 음성이 미리 [0018]입력된 명령들 중 부합되는 특정 명령, 예를 들어 특정한 곡 재생 등의 명령을 검출하여, 그 검출된 특정 명령을 수행하도록 하는 것이다.상기 출력부(150)는 상기 표정 인식부(130)에서 인식된 사용자의 표정에 따라, 미리 설정된 음악, 멘트 등의 음 [0019]향을 출력하거나, 상기 인텔리전트 완구 시스템(100)이 미리 설정된 특정 반응을 수행하도록 한다.본 실시예에 따른 인텔리전트 완구 시스템(100)의 제어 방법은 영상 촬영부(110)에서 사용자의 영상을 촬영하여 [0020]입력하는 단계; 상기 영상 촬영부(110)에서 입력되는 영상에서 얼굴 인식부(120)가 얼굴과 눈을 검출하여 얼굴을 인증하는 단계; 및 표정 인식부(130)가 상기 얼굴 인식부(120)에서 인식된 얼굴 영상을 세부 분할 후 각 영역에 대해 균일국부이진패턴(uniform local binary pattern, ULBP) 형식에 대한 히스토그램 특징값을 추출하고,상기 추출된 히스토그램 특징값을 인공 신경망(artificial neural network) 분석 과정을 통해 표정을 인식하는단계;를 포함한다.상기 인텔리전트 완구 시스템(100)의 제어 방법은 상기 영상 촬영부(110)에서 입력되는 영상에 대해 히스토그램 [0021]평활화 과정을 통해 조명 분포를 고르게 하는 조명 정규화 과정을 거치는 단계;를 더 포함할 수 있다.또한, 상기 인텔리전트 완구 시스템(100)의 제어 방법은 상기 출력부(150)가 상기 표정 인식부(130)에서 인식된 [0022]사용자의 표정에 따라 미리 설정된 음악을 출력하는 단계를 포함하거나, 상기 출력부(150)가 상기 표정 인식부(130)에서 인식된 사용자의 표정에 따라 상기 인텔리전트 완구 시스템이 미리 설정된 특정 반응을 수행하도록하는 단계를 포함한다.이하에서는 도 2를 참조하여 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템 [0023](100)에서 얼굴 인증이 수행되는 과정을 설명한다.먼저, 상기 영상 촬영부(110)에서 사용자의 영상을 촬영하여 입력되면(S110), 상기 얼굴 인식부(120)에서 상기 [0024]공개실용신안 20-2014-0003899-5-입력된 영상에서 사용자의 얼굴 영상을 검출한다(S111).그런 다음, 상기 단계(S111)에서 검출된 사용자의 얼굴 영상에 얼굴 좌표를 맵핑하고, 눈 영역 및 동공의 중심 [0025]을 검출하는 방식으로 사용자의 눈을 검출한다(S112).그 후, 검출된 얼굴 및 눈 영상에서 특징을 분석하여(S113), 데이터베이스에 입력된 얼굴 데이터들과 상기 분석 [0026]된 특징을 비교하여 사용자의 얼굴을 인식 및 인증한다(S114).이하에서는 도 3을 참조하여 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템 [0027](100)에서 표정 인식이 수행되는 과정을 설명한다.먼저, 상기된 얼굴 인증 단계에서와 같이, 상기 영상 입력부에서 얼굴 영상을 입력받아(S120), 상기 입력되는 [0028]영상에서 얼굴과 눈을 검출한다(S121).상기와 같이 검출된 눈을 기준으로 얼굴의 크기와 회전에 대한 정규화 과정을 수행하여 얼굴 영상을 정규화한다 [0029](S122).그런 다음, 상기와 같이 정규화된 얼굴 영상에 대해 히스토그램 평활화 과정을 통해 조명 분포를 고르게 하는 [0030]조명 정규화 과정을 거치고, 상기 조명 정규화 과정이 완료된 얼굴 영상에 대해 M×N의 영역으로 세부 분할 후,각 영역에 대해 균일국부이진패턴 형식에 대한 히스토그램 특징으로 특징값 추출을 수행한다(S123).그 후, 상기와 같이 추출된 특징값을 인공 신경망 분석 과정을 통해 최종적으로 얼굴에 대한 표정을 판단하게 [0031]된다(S124).상기와 같이, 본 실시예에서는 얼굴 영상 전체 영역에 대해 특징을 추출하고 표정 인식을 하는 것이 아니라, 표 [0032]정 변화에 민감한 특정 영역들에 대해서만 인식 처리를 수행함으로써, 표정 인식을 위하여 처리되어야 하는 데이터량이 현저하게 감소될 수 있고, 그에 따라 보다 신속한 표정 인식이 가능해질 수 있고, 나아가 실시간의 표정 인식이 가능해질 수 있으며, 사용자에 대하여 스스로 반응하는 지능을 갖추어 사용자의 흥미를 지속적이고능동적으로 유발할 수 있다.본 실시예에서는 예시적으로, 10×10 화소의 크기로 얼굴 영상 영역을 분할 후, 표정의 변화에 민감한 영역에 [0033]대해 특징 추출 과정을 적용하고, 표정 변화에 영향이 적은 일부 영역에 대한 분석은 배제되었다.상세히, 정규화된 얼굴로부터 특징을 추출하는 과정에서는 먼저 국부이진패턴(LBP) 특징을 추출하고, 상기와 같 [0034]이 추출된 국부이진패턴으로부터 균일국부이진패턴 특징을 추출한다.국부이진패턴 기법을 위한 수학식은 다음과 같다. [0035]수학식 1[0036]여기서, 국부이진패턴(xc,yc)는 (xc,yc)중심 화소(210)에서의 국부이진패턴 변환된 값을 나타내며, gc는 (xc,yc) [0037]중심 화소(210)에서의 얼굴 영상의 화소값이며, gp는 (xc,yc)의 주변 화소(220)에서의 화소값을 나타낸다. 여기서, 화소값은 그레이 스케일 영상 또는 단일 채널 영상으로 변환될 때의 인텐서티(intensity) 값을 나타낼 수있다. 이와 함께, p는 (xc,yc)화소에서의 한 지점을 기준으로 시계방향 또는 반시계방향으로 돌아가며 1씩 증가한다.예를 들어, 국부이진패턴 기법이 3×3 크기의 픽셀 영역에 대하여 적용된다면, 얼굴 영상의 해당 화소값을 기준 [0038]으로 8개의 주변 화소값을 비교하여 1 또는 0의 이진값을 가지는 이진패턴(200)을 얻을 수 있다. 따라서, 3×3크기의 화소 영역에 국부이진패턴 기법이 적용되는 경우에는 8개의 이진수로 구성되는 이진패턴(200)이 구해질수 있고, 이러한 이진패턴(200)은 해당 화소의 국부이진패턴 패턴값(230)이 될 수 있다. 따라서, 얼굴 영상의각 화소마다 이러한 이진패턴(200)을 구하여, 각 화소마다의 국부이진패턴 패턴값(230)을 대입함으로써 변환 영상을 산출할 수 있다.공개실용신안 20-2014-0003899-6-3×3 크기의 화소 영역에서 중심 화소(210)의 화소값은 28이며, 주변 화소(220)들이 28보다 크면 1 값을 [0039]가지며, 28보다 같거나 작으면 0 값을 가진다. 따라서, 250의 화소값을 가지는 제 1 주변 화소(221)를 중심으로시계 방향으로 회전하면서 제8 주변 화소에까지 화소값의 비교를 통하여 8비트의 이진패턴인 (1, 1, 0, 1, 0,0, 0, 1)을 얻을 수 있다. 상기 이진패턴 (1, 1, 0, 1, 0, 0, 0, 1)을 하나의 이진수로 파악하여 십진수로 변환하면 209의 패턴값(230)을 중심 화소(210)에 대하여 얻을 수 있다.상기와 같이, 얼굴 영상의 각 화소에 대하여 국부이진패턴 기법을 적용함으로써 각 화소마다 소정의 패턴값이 [0040]도출되어, 상기 패턴값으로 구성되는 변환영상을 획득할 수 있다. 변환 영상은 해당 화소와 주변 화소들간의 화소값 또는 밝기의 관계에 의하여 결정되기 때문에, 전체적인 조명이나 간섭에 의한 영향이 감소될 수 있고, 따라서 전체적으로 밝은 영상 또는 어두운 영상에 대하여도 비교적 균일한 영상을 얻을 수 있다.한 점을 기준으로 1화소와 인접한 화소들의 국부이진패턴 패턴들 중, 비트 패턴을 원형으로 가정했을 때 인접 [0041]비트 사이에 0에서 1로 또는 1에서 0으로의 비트 변환이 2번 이하로 발생하는 패턴들만을 균일국부이진패턴(ULBP)으로 한다. 8비트의 원형 비트패턴으로 생성 가능한 균일국부이진패턴은 00000000, 11111111을 포함하여00011100, 11100001 등의 형식으로 나타나는 이진패턴들로 58가지의 형태로 나타난다.얼굴 영역에 대해 국부이진패턴을 추출하고, 이 패턴들 중 국부이진패턴에 대해서 영역별로 히스토그램을 계산 [0042]한다. 계산된 히스토그램 특징값들은 인공신경망 방법을 통해 표정 학습 또는 표정 인식을 위한 입력 값으로 사용된다.도 7은 본 실시예의 학습 단계에서 사용된 인공 신경망의 구조를 나타낸다. [0043]x는 블록별 균일국부이진패턴의 히스토그램 특징을 나타내며, 입력노드의 입력 벡터들을 나타낸다. 하나의 은닉 [0044]층과 각 표정에 해당하는 5개의 출력노드로 구성되었다. w는 각 노드 사이의 연결강도를 의미하는 가중치를 나타낸다. 최종 출력은 가중치 w와 입력값 x, 그리고 수학식 3과 같은 활성함수에 의해서 결정하였다. m은 입력층에서의 노드의 수를, n은 은닉층에서의 노드의 수를 각각 나타낸다.수학식 2[0045]수학식 3[0046]xi는 i번째 입력 벡터값을, wij는 i번째 입력노드와 j번째 은닉노드 사이의 가중치를, 그리고 wjk는 j번째 은닉노 [0047]드와 k번째 출력노드 사이의 가중치를 나타낸다.상기 수학식 3의 f(N)는 0과 1사이의 출력을 갖는 단극성 단조증가의 특성을 가지는 시그모이드(sigmoid) 함수 [0048]를 사용하였다. 가중치 w는 역전파(back propagation) 알고리즘을 이용하여 계산할 수 있다. 입력된 영상으로부터 검출된 얼굴 영상은 상기한 일련의 과정을 거쳐 무표정한 얼굴, 웃는 얼굴, 화난 얼굴, [0049]놀란 얼굴, 슬픈 얼굴 등의 표정을 인식하게 된다.이하에서는 도 4를 참조하여, 본 고안의 일 실시예에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템 [0050](100)에서 음성 인식이 수행되는 과정을 설명한다.먼저, 상기 음성 인식부(140)에서 사용자의 음성이 입력되면(S130), 상기 입력된 음성의 특징을 분석(S131), 퓨 [0051]리에 변환하여 기준 패턴값을 생성한다(S132).상기와 같이 생성된 기준 패턴값을 패턴 학습값과 매칭하여 유사도를 분석하고, 분석된 값을 어절, 어간 분석 [0052]및 단어 매칭 작업, 즉 언어 처리를 하여(S133), 단어 및 문장 처리하여 출력한다(S134).공개실용신안 20-2014-0003899-7-상기에서 본 고안은 특정한 실시예에 관하여 도시되고 설명되었지만, 당업계에서 통상의 지식을 가진 자라면 이 [0053]하의 특허청구범위에 기재된 본 고안의 사상 및 영역을 벗어나지 않는 범위 내에서 본 고안을 다양하게 수정 및변경시킬 수 있음을 알 수 있을 것이다. 그렇지만 이러한 수정 및 변형 구조들은 모두 본 고안의 권리범위 내에포함되는 것임을 분명하게 밝혀두고자 한다.산업상 이용가능성본 고안의 일 측면에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에 의하면, 사용자에 대하여 능동적 [0054]이면서도 신속하게 반응할 수 있는 지능을 갖추어 사용자의 흥미를 지속적이고 능동적으로 유발할 수 있으므로,그 산업상 이용가능성이 높다고 하겠다.부호의 설명110 : 영상 촬영부 115 : 동작 센서부 [0055]120 : 얼굴 인식부 130 : 표정 인식부140 : 음성 인식부 150 : 출력부도면도면1공개실용신안 20-2014-0003899-8-도면2도면3공개실용신안 20-2014-0003899-9-도면4도면5공개실용신안 20-2014-0003899-10-도면6도면7공개실용신안 20-2014-0003899-11-"}
{"patent_id": "20-2013-0009098", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "표정 인식 기술이 적용된 인텔리전트 완구 시스템이 개시된다. 개시되는 표정 인식 기술이 적용된 인텔리전트 완구 시스템은 사용자의 영상을 촬영하여 입력하는 영상 촬영부; 상기 영상 촬영부에서 입력되는 영상에서 얼굴과 눈을 검출하여 얼굴을 인증하는 얼굴 인식부; 및 상기 영상 촬 영부에서 입력되는 영상에서 상기 얼굴과 상기 눈을 검출하고, 검출된 상기 눈을 기준으로 상기 얼굴의 크기와 회전에 대한 정규화 과정을 수행하여 얼굴 영상을 정규화하며, 정규화된 상기 얼굴 영상에 대해 히스토그램 평활 화 과정을 통해 조명 분포를 고르게 하는 조명 정규화 과정을 거치고, 상기 조명 정규화 과정이 완료된 상기 얼 굴 영상에 대해 M×N의 영역으로 세부 분할 후 각 영역에 대해 균일국부이진패턴 형식에 대한 히스토그램 특징으 로 히스토그램 특징값을 추출하며, 상기 히스토그램 특징값에 대하여 인공 신경망 분석 과정을 통해 상기 얼굴에 대한 표정을 인식하는 표정 인식부;를 포함한다. 개시되는 표정 인식 기술이 적용된 인텔리전트 완구 시스템에 의하면, 얼굴 영상 전체 영역에 대해 특징을 추출 하고 표정 인식을 하는 것이 아니라, 표정 변화에 민감한 특정 영역들에 대해서만 인식 처리를 수행함으로써, 표 정 인식을 위하여 처리되어야 하는 데이터량이 현저하게 감소될 수 있고, 그에 따라 보다 신속한 표정 인식이 가 능해질 수 있고, 나아가 실시간의 표정 인식이 가능해질 수 있으며, 사용자에 대하여 스스로 반응하는 지능을 갖 추어 사용자의 흥미를 지속적이고 능동적으로 유발할 수 있는 장점이 있다."}
{"patent_id": "20-2013-0009098", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 고안은 표정 인식 기술이 적용된 인텔리전트 완구 시스템에 관한 것이다."}
{"patent_id": "20-2013-0009098", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "완구는 아이들이 가지고 노는 장난감으로, 종래의 완구는 만화 캐릭터 등 특정 캐릭터를 흉내내는 수준으로, 단 지 소유를 하거나 단순히 가지고 노는 놀이 수준에 한정되고, 완구가 사용자에 대하여 스스로 반응하는 지능을 갖추지 못하여 쉽게 실증이 나는 단점이 있다. 이러한 단점을 개선하기 위하여, 완구에 사용자의 얼굴 또는 음성을 인식하여 그에 반응하도록 하는 기술이 개 발되고 있으나, 그러한 반응을 위한 데이터 처리 속도 향상에 한계가 있어서, 완구가 제대로 사용자에게 반응하 지 못하는 문제가 있었다. 이러한 문제를 해결하기 위한 노력의 일환으로, Yubo WANG, Haizhou AI, Bo WU, Chang HUANG가 공동 기술한 \"Real Time Facial Expression Recognition with Adaboost\" 등의 논고에서와 같은 방법이 제시되고 있으나, 여전히 데이터 처리 속도 향상에 한계가 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) 1. Yubo WANG, Haizhou AI, Bo WU, Chang HUANG가 공동 기술한 \"Real Time Facial Expression Recognition with Adaboost\" 공개실용신안 20-2014-0003899 -3-고안의 내용"}
{"patent_id": "20-2013-0009098", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 고안은 사용자에 대하여 능동적이면서도 신속하게 반응할 수 있는 지능을 갖춘 표정 인식 기술이 적용된 인 텔리전트 완구 시스템을 제공하는 것을 일 목적으로 한다."}
{"patent_id": "20-2013-0009098", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 고안의 일 측면에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템은 사용자의 영상을 촬영하여 입력 하는 영상 촬영부; 상기 영상 촬영부에서 입력되는 영상에서 얼굴과 눈을 검출하여 얼굴을 인증하는 얼굴 인식 부; 및 상기 영상 촬영부에서 입력되는 영상에서 상기 얼굴과 상기 눈을 검출하고, 검출된 상기 눈을 기준으로 상기 얼굴의 크기와 회전에 대한 정규화 과정을 수행하여 얼굴 영상을 정규화하며, 정규화된 상기 얼굴 영상에 대해 히스토그램 평활화 과정을 통해 조명 분포를 고르게 하는 조명 정규화 과정을 거치고, 상기 조명 정규화 과정이 완료된 상기 얼굴 영상에 대해 M×N의 영역으로 세부 분할 후 각 영역에 대해 균일국부이진패턴 형식에 대한 히스토그램 특징으로 히스토그램 특징값을 추출하며, 상기 히스토그램 특징값에 대하여 인공 신경망 분석 과정을 통해 상기 얼굴에 대한 표정을 인식하는 표정 인식부;를 포함한다. 고안의 효과 본 고안의 일 측면에 따른 표정 인식 기술이 적용된 인텔리전트 완구 시스템에 의하면, 얼굴 영상 전체 영역에 대해 특징을 추출하고 표정 인식을 하는 것이 아니라, 표정 변화에 민감한 특정 영역들에 대해서만 인식 처리를 수행함으로써, 표정 인식을 위하여 처리되어야 하는 데이터량이 현저하게 감소될 수 있고, 그에 따라 보다 신속 한 표정 인식이 가능해질 수 있고, 나아가 실시간의 표정 인식이 가능해질 수 있으며, 사용자에 대하여 스스로 반응하는 지능을 갖추어 사용자의 흥미를 지속적이고 능동적으로 유발할 수 있는 효과가 있다."}
