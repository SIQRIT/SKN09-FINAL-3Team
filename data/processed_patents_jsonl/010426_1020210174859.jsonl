{"patent_id": "10-2021-0174859", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0086334", "출원번호": "10-2021-0174859", "발명의 명칭": "하이브리드 객체탐지 및 객체트랙킹 방법, 및 시스템", "출원인": "(주)넥스리얼", "발명자": "박준석"}}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "GPU 및 NPU 중 1 이상을 포함하는 제1프로세서모듈; 및 CPU를 포함하는 제2프로세서모듈;을 포함하는 컴퓨팅시스템에서 수행되는 하이브리드 객체탐지 및 객체트랙킹 방법으로서, 분석대상영상을 키프레임 및 두 키프레임 사이에서 연속되는 복수의 일반프레임으로 구분하는키프레임추출단계;상기 제1프로세서모듈에 의하여, 상기 키프레임에 대해 딥러닝 기반의 제1검출모델을 이용하여, 객체에 대한 제1바운딩박스정보 및 객체에 대한 특징정보를 포함하는 제1메타정보를 도출하는 제1메타정보도출단계;상기 제2프로세서모듈에 의하여, 상기 일반프레임에 대해 전경추출 및 배경학습 기반의 제2검출모델을이용하여, 객체에 대한 제2바운딩박스정보를 포함하는 제2메타정보를 도출하는 제2메타정보도출단계;상기 연속되는 복수의 프레임 각각의 제1메타정보, 혹은 제2메타정보에 기초하여 개별 객체 각각에 대하여 시간에 따른 객체정보 트랙킹정보를 도출하는 트랙킹정보도출단계;및상기 트랙킹정보에서, 인접한 두 키프레임에서의 해당 객체의 바운딩박스와 상기 인접한 두 키프레임 사이의 일반프레임에서의 해당 객체의 바운딩박스의 차이를 고려하여, 일반프레임에서의 바운딩박스를 보정하는 트래킹정보보정단계;를 포함하는, 하이브리드 객체탐지 및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 트래킹정보도출단계는 이전의 1 이상의 프레임의 제1바운딩박스정보 혹은 제2바운딩박스정보에 기초하여 예측되는 현재 프레임의 객체의 바운딩박스에 대한 정보와 현재 프레임의 제1바운딩박스정보 혹은 제2바운딩박스정보에 의하여 검출된 현재프레임의 객체의 바운딩박스에 대한 정보를 고려하여, 현재 프레임의 객체의 바운딩박스정보를 포함하는 트랙킹정보를 갱신하는, 하이브리드 객체탐지 및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 트래킹정보도출단계는,각각의 일반프레임에 존재하는 객체의 특징정보는 해당 일반프레임의 이전의 키프레임에서의 동일한 객체의 제1메타정보에 포함된 특징정보를 부여하여 트랙킹정보를 갱신하는, 하이브리드 객체탐지 및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 트래킹정보보정단계는, 인접한 2개의 키프레임에서의 바운딩박스정보로부터 도출될 수 있는 해당 객체의 괘적정보와 상기 인접한 2개의키프레임 사이의 일반프레임에서 검출된 해당 객체의 바운딩박스의 위치정보를 비교하여, 기설정된 기준 이상의차이가 있다고 판단하는 경우에는 상기 인접한 두 키프레임에서의 해당객체의 바운딩박스을 보간하여 상기 인접한 2개의 키프레임 사이의 일반프레임의 해당 객체의 바운딩박스의 위치정보를 보정하는, 하이브리드 객체탐지공개특허 10-2023-0086334-3-및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 트래킹정보보정단계는, 인접한 2개의 키프레임에서의 해당 객체의 바운딩박스의 크기정보와 상기 인접한 2개의 키프레임 사이의 일반프레임에서 검출된 해당 객체의 바운딩박스의 크기정보를 비교하여, 기설정된 기준 이상의 차이가 있다고 판단하는 경우에는 상기 인접한 두 키프레임에서의 해당객체의 바운딩박스의 크기정보에 기초하여 상기 인접한 2개의키프레임 사이의 일반프레임의 해당 객체의 바운딩박스의 크기정보를 보정하는, 하이브리드 객체탐지 및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 제1메타정보도출단계는,키프레임에 해당하는 N번째 프레임에서의 객체의 제1바운딩박스의 위치를 상기 제2메타정보도출단계에서 이용할수 있도록 제공하고, 상기 제2메타정보도출단계는,일반프레임에 해당하는 N번째 프레임의 다음 프레임에서의 상기 제1바운딩박스의 위치를 중심으로 하는 분석영역을 도출한 후에, 상기 분석영역에 대해서만 상기 제2검출모델을 이용하여 제2메타정보를 도출하는, 하이브리드 객체탐지 및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 상기 분석영역의 크기는,N번째 키프레임에서의 해당 객체의 바운딩박스의 위치와 N+1번째 키프레임에서의 해당 객체의 제1바운딩박스의위치의 차이가 클수록 상기 분석영역의 크기를 증가시키는 형태로 결정되는, 하이브리드 객체탐지 및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "GPU 및 NPU 중 1 이상을 포함하는 제1프로세서모듈; 및 CPU를 포함하는 제2프로세서모듈;을 포함하는 컴퓨팅시스템으로 구현되는 수행되는 하이브리드 객체탐지 및 객체트랙킹 장치로서,상기 장치는, 분석대상영상을 키프레임 및 두 키프레임 사이에서 연속되는 복수의 일반프레임으로 구분하는키프레임추출단계;상기 제1프로세서모듈에 의하여, 상기 키프레임에 대해 딥러닝 기반의 제1검출모델을 이용하여, 객체에 대한 제1바운딩박스정보 및 객체에 대한 특징정보를 포함하는 제1메타정보를 도출하는 제1메타정보도출단계;상기 제2프로세서모듈에 의하여, 상기 일반프레임에 대해 전경추출 및 배경학습 기반의 제2검출모델을이용하여, 객체에 대한 제2바운딩박스정보를 포함하는 제2메타정보를 도출하는 제2메타정보도출단계;상기 연속되는 복수의 프레임 각각의 제1메타정보, 혹은 제2메타정보에 기초하여 개별 객체 각각에 대하여 시간공개특허 10-2023-0086334-4-에 따른 객체정보 트랙킹정보를 도출하는 트랙킹정보도출단계;및상기 트랙킹정보에서, 인접한 두 키프레임에서의 해당 객체의 바운딩박스와 상기 인접한 두 키프레임 사이의 일반프레임에서의 해당 객체의 바운딩박스의 차이를 고려하여, 일반프레임에서의 바운딩박스를 보정하는 트래킹정보보정단계;를 수행하는, 하이브리드 객체탐지 및 객체트랙킹 방법."}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 하이브리드 객체탐지 및 객체트랙킹 방법, 및 시스템에 관한 것으로서, 더욱 상세하게는 딥러닝 기 반의 시각인공지능 (Vision AI)과 배경학습 및 전경추출에 기반한 영상분석 기법을 병용하여 영상으로부터 실 시간으로 영상객체를 탐지하고 트랙킹함으로써, GPU 및 NPU 중 1 이상과 CPU를 포함하는 컴퓨팅 시스템에서 (뒷면에 계속)"}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 하이브리드 객체탐지 및 객체트랙킹 방법, 및 시스템에 관한 것으로서, 더욱 상세하게는 딥러닝 기 반의 시각인공지능 (Vision AI)과 배경학습 및 전경추출에 기반한 영상분석 기법을 병용하여 영상으로부터 실 시간으로 영상객체를 탐지하고 트랙킹함으로써, GPU 및 NPU 중 1 이상과 CPU를 포함하는 컴퓨팅 시스템에서 NPU 혹은 GPU의 연산부하를 효율적으로 저감시켜 보다 높은 연산량을 요구하는 딥러닝모델을 사용하면서 전체 영상구간에 대하여 객체탐지 및 추적의 정확도를 높일 수 있는, 하이브리드 객체탐지 및 객체트랙킹 방법, 및 시스템에 관한 것이다."}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 또는 지능형 영상분석 기반의 실시간 영상객체 탐지추적 기술은 탐지관점에서 1) 배경학습/전경추출 방 식(전통적 방식), 2) 객체특징 탐색 방식(전통적 방식)과 3) 객체특징 학습 방식(딥러닝 방식)으로 구분하며, 추적관점에서 1) Tracking By Segmentation(이하 TBS 방식)과 2) Tracking By Detection(이하 TBD 방식)으로 구분할 수 있다. 영상객체 탐지방식에 있어 전통적인 배경학습은 동적인 객체(전경)의 영역을 추출하는 방식으로 객체의 위치만 추정할 수 있는 반면에, 딥러닝 기반 객체학습은 다수의 학습 영상으로부터 정적 또는 동적인 객체의 특징을 추 출해 학습한 후 추론단계에서 객체의 위치와 종류를 추정할 수 있다. 최근 컴퓨터 비전 분야에서 CNN 기반 딥러 닝 기술이 영상인식 분야에서 다양한 성과를 만들고 있으며, 영상객체 탐지에 있어서도 동적인 배경요소, 조도 변화 및 날씨 환경에 강건한 딥러닝 기반 객체학습이 GPU 또는 NPU와 같은 매트릭스 연산과 병렬처리에 최적화 된 프로세서의 도입확산과 더불어 대세를 이루고 있다. 영상객체 추적방식에 있어 1) TBS 방식의 경우는 전통적 방식과 딥러닝 방식으로 세분화할 수 있으며, 2) TBD 방식의 경우도 전통적 방식과 딥러닝 방식으로 세분화할 수 있다. TBS 방식은 TBD 방식에 비해 영상객체 특징벡 터 추출에 있어 전경객체가 아닌 배경영역의 픽셀정보가 노이즈로 작용할 가능성이 줄어들기 때문에 추적성능 개선에 도움이 되지만 TBD 방식에 비해 상대적으로 처리속도에 떨어지기 때문에 상충관계(Trade-Off)가 존재한 다. 한편, NPU/CPU 기반 엣지 디바이스 방식의 경우, 현장에서 1채널 비디오 스트림(또는 시그널) 실시간 처리에는 적합하지만, 정확도보다는 처리속도를 염두에 둔 경량 네트워크 모델의 사용으로 정확도가 다소 감소하는 단점 이 있다. 하지만, 무거운(네트워크 대역폭 점유가 큰) 비디오 스트림을 가벼운(네트워크 대역폭 점유가 작은) 메타 스트림으로 변환할 수 있기 때문에 후단에 위치한 전송 네트워크, 영상서버(수집/분배/저장) 및 스토리지 와 같은 백엔드 인프라를 경량화할 수 있는 장점을 제공한다. [선행기술문헌] (특허문헌 001) 한국등록특허 제10-1137110호, 영상 내 물체 감시 방법 및 장치"}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 딥러닝 기반의 시각인공지능 (Vision AI)과 배경학습 및 전경추출에 기반한 영상분석 기법을 병용 하여 영상으로부터 실시간으로 영상객체를 탐지하고 트랙킹함으로써, GPU 및 NPU 중 1 이상과 CPU를 포함하는컴퓨팅 시스템에서 NPU 혹은 GPU의 연산부하를 효율적으로 저감시켜 보다 높은 연산량을 요구하는 딥러닝모델을 사용하면서 전체 영상구간에 대하여 객체탐지 및 추적의 정확도를 높일 수 있는, 하이브리드 객체탐지 및 객체 트랙킹 방법, 및 시스템을 제공하는 것을 그 목적으로 한다."}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 과제를 해결하기 위하여, 본 발명의 일 실시예에서는, GPU 및 NPU 중 1 이상을 포함하는 제1프로세 서모듈; 및 CPU를 포함하는 제2프로세서모듈;을 포함하는 컴퓨팅시스템에서 수행되는 하이브리드 객체탐지 및 객체트랙킹 방법으로서, 분석대상영상을 키프레임 및 두 키프레임 사이에서 연속되는 복수의 일반프레임으로 구 분하는 키프레임추출단계; 상기 제1프로세서모듈에 의하여, 상기 키프레임에 대해 딥러닝 기반의 제1검출모델을 이용하여, 객체에 대한 제1바운딩박스정보 및 객체에 대한 특징정보를 포함하는 제1메타정보를 도출하는 제1메 타정보도출단계; 상기 제2프로세서모듈에 의하여, 상기 일반프레임에 대해 전경추출 및 배경학습 기반의 제2검 출모델을 이용하여, 객체에 대한 제2바운딩박스정보를 포함하는 제2메타정보를 도출하는 제2메타정보도출단계; 상기 연속되는 복수의 프레임 각각의 제1메타정보, 혹은 제2메타정보에 기초하여 개별 객체 각각에 대하여 시간 에 따른 객체정보 트랙킹정보를 도출하는 트랙킹정보도출단계; 및 상기 트랙킹정보에서, 인접한 두 키프레임에 서의 해당 객체의 바운딩박스와 상기 인접한 두 키프레임 사이의 일반프레임에서의 해당 객체의 바운딩박스의 차이를 고려하여, 일반프레임에서의 바운딩박스를 보정하는 트래킹정보보정단계;를 포함하는, 하이브리드 객체 탐지 및 객체트랙킹 방법을 제공한다. 본 발명의 몇 실시예에서는, 상기 트래킹정보도출단계는 이전의 1 이상의 프레임의 제1바운딩박스정보 혹은 제2 바운딩박스정보에 기초하여 예측되는 현재 프레임의 객체의 바운딩박스에 대한 정보와 현재 프레임의 제1바운딩 박스정보 혹은 제2바운딩박스정보에 의하여 검출된 현재 프레임의 객체의 바운딩박스에 대한 정보를 고려하여, 현재 프레임의 객체의 바운딩박스정보를 포함하는 트랙킹정보를 갱신할 수 있다. 본 발명의 몇 실시예에서는, 상기 트래킹정보도출단계는, 각각의 일반프레임에 존재하는 객체의 특징정보는 해 당 일반프레임의 이전의 키프레임에서의 동일한 객체의 제1메타정보에 포함된 특징정보를 부여하여 트랙킹정보 를 갱신할 수 있다. 본 발명의 몇 실시예에서는, 상기 트래킹정보보정단계는, 인접한 2개의 키프레임에서의 바운딩박스정보로부터 도출될 수 있는 해당 객체의 괘적정보와 상기 인접한 2개의 키프레임 사이의 일반프레임에서 검출된 해당 객체 의 바운딩박스의 위치정보를 비교하여, 기설정된 기준 이상의 차이가 있다고 판단하는 경우에는 상기 인접한 두 키프레임에서의 해당객체의 바운딩박스을 보간하여 상기 인접한 2개의 키프레임 사이의 일반프레임의 해당 객체 의 바운딩박스의 위치정보를 보정할 수 있다. 본 발명의 몇 실시예에서는, 상기 트래킹정보보정단계는, 인접한 2개의 키프레임에서의 해당 객체의 바운딩박스 의 크기정보와 상기 인접한 2개의 키프레임 사이의 일반프레임에서 검출된 해당 객체의 바운딩박스의 크기정보 를 비교하여, 기설정된 기준 이상의 차이가 있다고 판단하는 경우에는 상기 인접한 두 키프레임에서의 해당객체 의 바운딩박스의 크기정보에 기초하여 상기 인접한 2개의 키프레임 사이의 일반프레임의 해당 객체의 바운딩박 스의 크기정보를 보정할 수 있다. 본 발명의 몇 실시예에서는, 상기 제1메타정보도출단계는, 키프레임에 해당하는 N번째 프레임에서의 객체의 제1 바운딩박스의 위치를 상기 제2메타정보도출단계에서 이용할 수 있도록 제공하고, 상기 제2메타정보도출단계는, 일반프레임에 해당하는 N번째 프레임의 다음 프레임에서의 상기 제1바운딩박스의 위치를 중심으로 하는 분석영 역을 도출한 후에, 상기 분석영역에 대해서만 상기 제2검출모델을 이용하여 제2메타정보를 도출할 수 있다. 본 발명의 몇 실시예에서는, 상기 분석영역의 크기는, N번째 키프레임에서의 해당 객체의 바운딩박스의 위치와 N+1번째 키프레임에서의 해당 객체의 제1바운딩박스의 위치의 차이가 클수록 상기 분석영역의 크기를 증가시키 는 형태로 결정될 수 있다. 상기와 같은 과제를 해결하기 위하여, 본 발명의 일 실시예에서는, GPU 및 NPU 중 1 이상을 포함하는 제1프로세 서모듈; 및 CPU를 포함하는 제2프로세서모듈;을 포함하는 컴퓨팅시스템으로 구현되는 수행되는 하이브리드 객체탐지 및 객체트랙킹 장치로서, 상기 장치는, 분석대상영상을 키프레임 및 두 키프레임 사이에서 연속되는 복수 의 일반프레임으로 구분하는 키프레임추출단계; 상기 제1프로세서모듈에 의하여, 상기 키프레임에 대해 딥러닝 기반의 제1검출모델을 이용하여, 객체에 대한 제1바운딩박스정보 및 객체에 대한 특징정보를 포함하는 제1메타 정보를 도출하는 제1메타정보도출단계; 상기 제2프로세서모듈에 의하여, 상기 일반프레임에 대해 전경추출 및 배경학습 기반의 제2검출모델을 이용하여, 객체에 대한 제2바운딩박스정보를 포함하는 제2메타정보를 도출하는 제2메타정보도출단계; 상기 연속되는 복수의 프레임 각각의 제1메타정보, 혹은 제2메타정보에 기초하여 개별 객 체 각각에 대하여 시간에 따른 객체정보 트랙킹정보를 도출하는 트랙킹정보도출단계; 및 상기 트랙킹정보에서, 인접한 두 키프레임에서의 해당 객체의 바운딩박스와 상기 인접한 두 키프레임 사이의 일반프레임에서의 해당 객체의 바운딩박스의 차이를 고려하여, 일반프레임에서의 바운딩박스를 보정하는 트래킹정보보정단계;를 수행하 는, 하이브리드 객체탐지 및 객체트랙킹 방법을 제공한다."}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에서는, 딥러닝 기반의 시각인공지능 (Vision AI)과 배경학습 및 전경추출에 기반한 영 상분석 기법을 병용하여 영상으로부터 실시간으로 영상객체를 탐지하고 트랙킹하는 효과를 발휘할 수 있다. 본 발명의 일 실시예에서는, GPU 및 NPU 중 1 이상과 CPU를 포함하는 컴퓨팅 시스템에서 NPU 혹은 GPU의 연산부 하를 효율적으로 저감시켜 보다 높은 연산량을 요구하는 딥러닝모델을 사용하는 효과를 발휘할 수 있다. 본 발명의 일 실시예에서는, 효율적인 연산부하로 전체 영상구간에 대하여 객체탐지 및 추적의 정확도를 높일 수 있는 효과를 발휘할 수 있다. 본 발명의 일 실시예에서는, CPU 자원을 활용한 배경학습 기반 동적객체탐지로 NPU 또는 GPU 자원에 집중된 딥 러닝 기반 학습객체탐지의 부하를 감소시킬 수 있고, 부하 감소에 따른 NPU 또는 GPU의 여유 리소스는 학습객체 탐지 정확도를 좀 더 높이기 위해서 고성능의 CNN 기반 객체탐지 추론엔진을 사용하는 데 사용되거나, 키 프레 임만을 대상으로 학습객체탐지를 수행하므로 더 많은 비디오 스트림 채널을 대상으로 객체탐지를 수행하는 데 사용될 수 있다. 본 발명의 일 실시예에서는, 프레임간 관심객체(들)의 매핑을 통한 트랙 정보의 생성, 수정, 소멸 관리에 있어 칼만필터를 기본으로 가중 매칭, 템플릿 매칭 및 재식별(Re-ID)필터 중의 어느 하나와 결합해 사용하는 경우가 그렇지 않은 경우에 비해 이전 프레임 기준으로 현재 프레임에서 동일한 관심객체(들)을 탐색하기 위한 검색영 역을 줄일 수 있기 때문에 프레임간 객체추적 속도를 높일 수 있는 효과를 발휘할 수 있다."}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 다양한 실시예들 및/또는 양상들이 이제 도면들을 참조하여 개시된다. 하기 설명에서는 설명을 목 적으로, 하나이상의 양상들의 전반적 이해를 돕기 위해 다수의 구체적인 세부사항들이 개시된다. 그러나, 이러 한 양상(들)은 이러한 구체적인 세부사항들 없이도 실행될 수 있다는 점 또한 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 인식될 수 있을 것이다. 이후의 기재 및 첨부된 도면들은 하나 이상의 양상들의 특정한 예 시적인 양상들을 상세하게 기술한다. 하지만, 이러한 양상들은 예시적인 것이고 다양한 양상들의 원리들에서의 다양한 방법들 중 일부가 이용될 수 있으며, 기술되는 설명들은 그러한 양상들 및 그들의 균등물들을 모두 포함 하고자 하는 의도이다. 또한, 다양한 양상들 및 특징들이 다수의 디바이스들, 컴포넌트들 및/또는 모듈들 등을 포함할 수 있는 시스템 에 의하여 제시될 것이다. 다양한 시스템들이, 추가적인 장치들, 컴포넌트들 및/또는 모듈들 등을 포함할 수 있 다는 점 그리고/또는 도면들과 관련하여 논의된 장치들, 컴포넌트들, 모듈들 등 전부를 포함하지 않을 수도 있 다는 점 또한 이해되고 인식되어야 한다. 본 명세서에서 사용되는 \"실시예\", \"예\", \"양상\", \"예시\" 등은 기술되는 임의의 양상 또는 설계가 다른 양상 또 는 설계들보다 양호하다거나, 이점이 있는 것으로 해석되지 않을 수도 있다. 아래에서 사용되는 용어들 '~부', '컴포넌트', '모듈', '시스템', '인터페이스' 등은 일반적으로 컴퓨터 관련 엔티티(computer-related entity)를 의미하며, 예를 들어, 하드웨어, 하드웨어와 소프트웨어의 조합, 소프트웨어를 의미할 수 있다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하지만, 하나 이상의 다른 특징, 구성요소 및/또는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구 성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구 별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요 소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 또한, 본 발명의 실시예들에서, 별도로 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기 서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되 는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술 의 문맥 상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 발명의 실시예에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 도 1은 본 발명의 일 실시예에 따른 객체탐지 및 객체트랙킹 방법의 세부 단계들을 개략적으로 도시한다. 본 발명의 객체탐지 및 객체트랙킹 방법은 2 이상의 종류의 프로세서모듈을 갖는 컴퓨팅 시스템에 의하여 수행된다. 구체적으로 본 발명의 실시예들에 따른 하이브리드 객체탐지 및 객체트랙킹 방법은 GPU 및 NPU 중 1 이상을 포 함하는 제1프로세서모듈; 및 CPU를 포함하는 제2프로세서모듈;을 포함한다. 본 발명의 일 실시예에서는 상기 제1프로세서모듈은 복수의 GPU 혹은 복수의 NPU를 포함할 수 있고, 제2 프로세서모듈도 복수의 CPU를 포함할 수 있다. 상기 컴퓨팅시스템은 물리적으로 분리되는 복수의 컴퓨팅 장치들로 구성될 수도 있고, 이 경우 연산과정이 분산되어 수행될 수도 있다. 본 발명에서의 CPU는 DSP 등을 포 함하는 GPU 혹은 NPU를 제외하는 일반적인 프로세서를 포함하는 최광의로 해석되어야 할 것이다. 단계 S100에서는 분석대상영상을 키프레임 및 두 키프레임 사이에서 연속되는 복수의 일반프레임으로 구분하는 키프레임추출단계;가 수행된다. 분석대상영상의 비트스트림은 디코딩이 되고, 각각의 프레임정보를 도출할 수 있다. 상기 키프레임은 I프레임과 같이 프레임의 특성에 따라서 결정될 수도 있지만, 사용자가 임의의 규칙으로 설정할 수도 있다. 예를들어,10N+1 번째 프레임(N은 0 및 자연수)을 키프레임으로 지정하고, 나머지 프레임들을 일반프레임으로 지정될 수 있다. 단계 S200에서는, 상기 제1프로세서모듈에 의하여, 상기 키프레임에 대해 딥러닝 기반의 제1검출모델을 이용하여, 객체에 대한 제1바운딩박스정보 및 객체에 대한 특징정보를 포함하는 제1메타정보를 도출하는 제1메 타정보도출단계;가 수행된다. 상기 제1검출모델은 CNN 기반의 One-Stage(Region Proposal과 Classification이 동시적으로 진행되는) 객체탐 지 네트워크모델 또는 Two-Stage(Region Proposal과 Classification이 순차적으로 진행되는) 객체탐지 네트워 크 모델을 포함할 수 있다. 혹은, 본 발명의 다른 실시예에서는, Transformer 기반의 객체탐지 네트워크 모델을 포함할 수 있다. CNN 기반의 One-Stage 객체탐지 네트워크 모델은 YOLO 계열 네트워크를 예로 들 수 있으며, Two-Stage 객체탐지 네트워크 모델은 RCNN 계열 네트워크를 예로 들 수 있으며, Transformer 기반 객체탐재 네트워크 모델은 페이스 북(Facebook)이 제시한 DETR 네트워크를 예로 들 수 있다. 이와 같은 제1메타정보도출단계는 후술하는 제2메타정보도출단계와 달리 딥러닝 기반의 객체탐지를 수행하기 때 문에, 보다 정확한 객체탐지를 수행할 수 있다. 또한, 제1메타정보도출단계에서는 객체의 바운딩박스정보 뿐만 아니라 객체의 종류에 분류(CLASSIFICATION) 정보 등에 해당할 수 있는 특징정보까지 도출할 수 있다. 본 명세서에서, 바운딩박스정보는 바운딩박스의 위치 및 바운딩박스의 크기에 대한 정보를 포함한다. 본 발명의 일 실시예에서는, 바운딩박스는 4각형으로 구성되고, 바운딩박스정보는 4각형의 꼭지점 중 좌측상단 꼭지점의 픽셀좌표 및 바운딩박스의 너비 및 높이를 포함하는 크기정보를 포함할 수 있다. 단계 S300에서는, 상기 제2프로세서모듈에 의하여, 상기 일반프레임에 대해 전경추출 및 배경학습 기반의 제2검출모델을 이용하여, 객체에 대한 제2바운딩박스정보를 포함하는 제2메타정보를 도출하는 제2메타정보도출 단계;가 수행되다. 제2검출모델은 배경학습 기반의 동적객체탐지 기술을 구현하기 위한 모델로서, 일 예로, 픽셀 단위, 블록(픽셀 의 집합) 단위 또는 객체 단위의 배경모델 학습 및 전경객체 검출 기법을 이용한 전통적인 영상분석 기법을 구 현하여 객체영역을 검출하는 모델에 해당한다. 이와 같은 배경학습 및 전경추출 기반의 모델 알고리즘의 예로서, 픽셀단위의 배경모델 학습 알고리즘을 이용한 공지된 SuBSENSE 알고리즘에 기반한 모델이 이에 해당할 수 있고, 블록단위의 배경모델 학습 알고리즘으로서, 한국등록특허 제10-1137110호 혹은 제10-1192163호에 제시된 모델이 사용될 수 있다. 이와 같은 제2메타정보도출단계에서는 전통적인 객체검출을 수행하기 때문에, 객체에 대한 분류정보 등에 해당 하는 특징정보는 도출하지 않고, 객체에 대한 바운딩박스정보만을 도출한다. 이와 같이 본 발명에서는 일반프레 임에 대해서는 CPU에서 제2메타정보도출단계에 의한 객체검출을 수행하기 때문에, GPU의 연산부하를 줄일 수 있 고, 이에 따라 보다 제1메타정보도출단계에서는 보다 연산량은 많지만 정확하게 객체를 검출할 수 있는 제1검출 모델을 사용할 수 있는 이점이 있다. 단계 S400에서는, 상기 연속되는 복수의 프레임 각각의 제1메타정보, 혹은 제2메타정보에 기초하여 개별 객체 각각에 대한 트랙킹정보를 도출하는 트랙킹정보도출단계;가 수행된다. 단계 S200 및 단계 S300의 수행에 따라 제1메타정보 및 제2메타정보가 상기 트래킹정보도출단계를 수행하는 스 레드로 전달된다. 상기 트래킹정보도출단계에서는 딥러닝 기반의 검출결과 및 비딥러닝 기반의 검출결과에 대하 여 동일한 알고리즘에 의하여 객체트래킹을 수행하고, 객체별 트랙킹정보(객체식별ID, 시간에 따른 객체의 바운 딩박스정보, 및 선택적으로 객체에 대한 특징정보)를 생성한다. 단계 S500에서는, 상기 트랙킹정보에서 연속된 두 키프레임에 대한 제1바운딩박스정보와 상기 연속된 두 키프레 임 사이의 일반프레임의 제2바운딩박스정보의 위치 및 크기의 차이를 고려하여, 일반프레임에 대한 트래킹정보 를 보정하는 트래킹정보보정단계;가 수행된다. 키프레임에 대한 제1메타정보도출단계는 일반프레임에 대한 제2메타정보도출단계와 비교시 보다 높은 정확도로 객체를 검출할 수 있다. 따라서, 제2메타정보도출단계에서의 객체검출결과에 오류가 있는 경우에는, 제1메타정 보도출단계에 의한 결과에 기초하여 객체검출결과를 수정한다. 이에 대한 자세한 설명은 후술하도록 한다. 단계 S600에서는 트래킹정보에 기초하여 이벤트발생여부를 판단하는 이벤트판단단계가 수행된다. 출입인원의 계 수, 특정 객체의 가상라인의 침범, 교통량 분석, 대기행렬분석 등의 과정이 이벤트판단단계에 의해서 수행될 수 있고, 이는 영상분석의 목적에 따라서 다양하게 설정될 수 있고, 이에 따라 트랙킹정보의 형태도 가변할 수 있 다. 도 1에는 단계 S100, S400, S500가 제2프로세서모듈에서 수행되는 것으로 도시되어 있지만, 본 발명의 다 른 실시예에서는 단계 S100, S400, S500 중 1 이상은 제1프로세서모듈에서 수행될 수도 있다. 본 발명에 서 중요한 사항은 단계 S200은 제1프로세서모듈에서 수행되고, S300은 제2프로세서모듈에서 수행된 다는 점이다. 이와 같은 방식으로 제1프로세서모듈의 정확도를 높일 수 있고, 단계 S300에서 발생할 수 있는 사항은 S500에 의하여 보정을 하여 결과적으로 동일한 연산리소스로 정확한 객체탐지 및 트랙킹을 수행할 수 있는 이점이 있다. 도 2는 본 발명의 일 실시예에 따른 키프레임 및 일반프레임에 대하여 이종의 프로세서모듈의 연산배분에 대하 여 개략적으로 도시한다. 도 2에 도시된 실시예는 5N+1 번째 프레임의 경우 키프레임으로 결정하는 경우에 해당한다. 도 2에서 도시된 바와 같이, 키프레임에 대해서는 GPU를 포함하는 제1프로세서모듈을 이용하여 딥러닝 기 반의 제1검출모델이 동작하여 객체를 검출한다. 이 경우, 객체의 바운딩박스정보 뿐만 아니라, 객체의 종류 등 에 대한 특징정보도 도출할 수 있다. 한편, 일반프레임에 대해서는 CPU를 포함하는 제2프로세서모듈을 이용하여 비딥러닝 기반의 제2검출모델 이 동작하여 객체를 검출한다. 한편, 각각의 프레임에 대하여 S200 혹은 S300에 의하여 객체검출결과가 도출되고, 도출된 객체검출결과는 단계 S400에 의하여 트랙킹정보로 생성된다. 이 경우, 본 발명의 바람직한 실시예에서는 객체의 바운딩박스의 위치 및 속도(방향성)을 고려하여 보정을 수행하는 칼만필터 및 탐지된 객체들간의 이미지적 유사성을 고려하여 객체 를 트랙킹하는 재식별(Re-ID)의 과정이 수행된다. 이미지트랙킹에서의 칼만필터 및 재식별(Re-ID)의 경우 공지 된 알고리즘을 사용할 수 있다. 도 3은 본 발명의 일 실시예에 따른 트랙킹정보도출단계의 과정을 개략적으로 도시한다. 본 발명의 일 실시예에서는 제1메타정보 및 제2메타정보에 대하여 동일하게 칼만필터 및 재식별(Re-ID) 기반의 객체추적을 하여 트랙킹정보를 생성할 수 있다. 본 발명의 일 실시예에서는, 프레임간 탐지 또는 검출된 객체들 사이의 매핑을 통한 실시간 추적을 위해 칼만필 터 기반의 객체 위치추정이 수행되면서 동시에 재식별(Re-ID) 기술 기반의 객체의 이미지적 특징벡터 매칭을 수 행될 수 있다. 칼만필터에 의한 트랙킹은 이전 프레임에서 탐지된 관심객체(들)과 현재 프레임에서 탐지된 관심객체(들)간의 매핑은 칼만필터(선형/비선형)를 이용한 이동궤적 예측과 재식별(Re-ID)필터를 이용한 유사도 판단을 통해서 수 행함으로써 관심객체(들)의 트랙킹정보를 생성할 수 있다. 본 발명의 일 실시예에서는, 프레임간 관심객체(들)간의 매핑은 칼만필터 방식을 기본으로 하되, 가중 매칭, 템 플릿 매칭 및 재식별(Re-ID)필터 중 어느 하나를 적용해 객체의 이미지적 유사도를 판단하는 방식이 적용될 수있다. 상기 칼만필터를 이용한 포인트 추적방식은 관심객체(들)의 운동(위치와 속도, Motion)를 예측하는 모델이며, 재식별(Re-ID) 필터 또는 템플릿 매칭을 이용한 커널 추적 방식은 관심객체(들)의 외형특징(Appearance Representation)의 유사도를 판단하는 모델이다. 본 발명에서는, 키프레임 및 일반프레임에서의 객체검출결과에 대하여 구분없이 칼만필터 및 재식별필터(혹은 템플릿매칭)을 적용하여 객체에 대한 트랙킹정보를 생성한다. 특히, 칼만필터를 이용하여 객체 중심점과 객체 바운딩 박스의 네 꼭지점의 위치를 추적할 경우 일반 프레임들 (키 프레임 사이에 위치한 프레임)에서 배경학습 기반의 동적객체탐지 방식을 이용하지 않고 커널 추적 방식만 을 이용하여 관심객체(들)을 추적할 때 반드시 요구되는 현재 프레임에서의 검색영역 설정범위를 최소화할 수 있는 장점을 제공한다. 커널 추적 방식에 있어서 각 프레임간의 관심객체(들)간의 유사도 판단 알고리즘은 다수가 사용되고 있는데, 오 차절대값합산(SAD), 오차제곱값합산(SSD), 바타차라야(Battacharraya) 함수, 교차상관(Cross-Correlation) 함 수 등을 예로 들 수 있다. 도 3의 (A), (B), 및 (C)는 본 발명의 일 실시예에 따른 트랙킹정보의 생성과정을 도시한다. 도 3의 특징정보는 이미지적 특징정보에 해당할 수 있다. 본 발명의 다른 실시예에서는 도 3의 (A), (B), 및 (C)의 과정의 일부를 생략할 수도 있다. 본 발명의 바람직한 실시예에서는 상기 트래킹정보도출단계(S400)는, 이전의 1 이상의 프레임의 제1바운딩박스 정보 혹은 제2바운딩박스정보에 기초하여 예측되는 현재 프레임의 객체의 바운딩박스에 대한 정보와 현재 프레 임의 제1바운딩박스정보 혹은 제2바운딩박스정보에 의하여 검출된 현재 프레임의 객체의 바운딩박스에 대한 정 보를 고려하여, 현재 프레임의 객체의 식별정보, 바운딩박스의 크기 및 위치를 포함하는 트랙킹정보를 갱신한 다. 인접프레임 사이의 객체의 위치 및 속도를 고려하여 칼만필터를 이용하여 예측을 하고, 예측된 영역에 대하여 이미지적 유사도(Re-ID 필터 혹은 템플릿매칭 이용)을 고려하여, 객체의 트랙킹을 수행한다. 상기 이전의 1 이상의 프레임의 제1바운딩박스정보 혹은 제2바운딩박스정보에 기초하여 예측되는 현재 프레임의 객체의 바운딩박스에 대한 정보는 도 3의 (A)에서와 같이 직전 혹은 이전의 1 이상의 프레임에서의 최종적으로 트랙킹된 객체의 바운딩박스에 대한 정보에 해당할 수도 있다. 도 4는 본 발명의 일 실시예에 따른 키프레임에서 도출된 특징정보의 일반프레임의 탐지결과로의 부여 과정을 개략적으로 도시한다. 도 4에 도시된 바와 같이, 상기 트래킹정보도출단계는, 각각의 일반프레임에 존재하는 객체의 특징정보는 해당 일반프레임의 이전의 키프레임에서의 동일한 객체의 제1메타정보에 포함된 특징정보를 부여하여 트랙킹정보를 갱신한다. 본 발명의 일부 실시예들에서는 객체별 트랙킹정보는 시간에 따른 객체의 위치 및 크기(이는 바운딩박스정보로 구현될 수 있음)에 추가적으로 해당 객체에 대한 분류정보 등의 특징정보를 포함할 수 있다. 도 4에 도시된 바와 같이, #N+1 및 #N+2번째 프레임에서의 객체A에 대한 특징정보는 이전의 키프레임에 해당하 는 #N번째 프레임에서의 객체A에 대하여 제1검출모델이 도출한 특징정보#1이 그대로 부여되어 사용된다. 본 발명에서는 이와 같은 방식으로, 트랙킹정보에서 객체의 특징정보를 포함하면서도 동시에 GPU의 중복된 연산 을 저감할 수 있다. 도 5는 본 발명의 일 실시예에 따른 트래킹정보보정단계의 세부과정을 개략적으로 도시한다. 본 발명의 일 실시예에서는, 상기 트래킹정보보정단계(S500)는, 인접한 2개의 키프레임에서의 바운딩박스정보 로부터 도출될 수 있는 해당 객체의 괘적정보와 상기 인접한 2개의 키프레임 사이의 일반프레임에서 검출된 해 당 객체의 바운딩박스의 위치정보를 비교하여, 기설정된 기준 이상의 차이가 있다고 판단하는 경우에는 상기 인 접한 두 키프레임에서의 해당객체의 제1바운딩박스정보을 보간하여 상기 인접한 2개의 키프레임 사이의 일반프 레임의 해당 객체의 바운딩박스의 위치정보를 생성한다. 도 5의 (A)에서는 키프레임에서 제1추론모델에 의하여 검출한 객체의 위치(#N, #N+3번째 프레임)과 제2추론모델 에 의하여 검출한 객체의 위치(#N+1, #N+2번째 프레임)를 도시한다. 혹은, 도 5의 (A)는 상기 제1메타정보 및 상기 제2메타정보에 기초하여 최종적으로 생성된 트랙킹정보에 해당할 수 있다. 이 경우, 제1추론모델의 결과와 제2추론모델의 결과가 상이하다. 이 경우에는 본 발명의 바람직한 실시예에서는 딥러닝 기반의 제1추론모델의 결과가 보다 정확하다고 가정하여, #N 및 #N+3 프레임에서의 객체바운딩박스의 위 치정보에 기초하여 #N+1 및 #N+2 프레임의 객체바운딩박스의 정보를 수정한다. 도 5의 (B)은 인접한 키프레임에서 동일한 객체의 이동괘적라인을 도시한다. 트랙킹정보에서의 일반프레임의 객체바운딩정보의 오류여부는 상기 이동괘적라인과 상기 일반프레임의 객체바운딩정보 사이의 거리 (#2거리, #3 거리)가 기설정된 기준을 초과하는 지에 따라 결정될 수 있다. 상기 기설정된 기준은 객체의 크기(바운딩박스의 크기)가 클수록 커지는 형태로 가변될 수도 있다. 도 5의 (C)는 도 5의 (B)의 단계에서 괘적과 거리가 기설정된 기준을 초과한 경우에, #N+1 및 #N+2 번째 프레임 에서의 해당 객체의 바운딩박스를 #N 및 #N+3번째 프레임에서의 바운딩박스에 기초하여 생성한 상태를 도시한다. 본 발명의 일 실시예에서는, 도 5의 (C)에 도시된 바와 같이 인접한 키프레임 사이에서의 해당 객체의 이동괘적 라인(예를들어 선형라인)을 생성하고, 이동괘적라인을 보간한 지점을 상기 인접한 키프레임 사이의 일반프레임 의 해당객체의 바운딩박스의 위치로 할 수 있다. 이 경우, 위치는 바운딩박스의 중심점으로 할 수 있다. 도 5의 (C)에서는 선형의 괘적라인에서 1/3지점 및 2/3지점이 각각 #N+1번째 및 #N+2번째 프레임의 해당객체의 바운딩박스의 위치로 지정될 수 있다. 또한, #N+1번째 프레임의 바운딩박스의 크기는 #N번째 프레임의 바운딩박스의 크기와 #N+3번째 바운딩박스의 크 기를 보간 혹은 평균값으로 결정하고, #N+2번째 프레임의 바운딩박스의 크기는 #N번째 프레임의 바운딩박스의 크기와 #N+3번째 바운딩박스의 크기를 보간 혹은 평균값으로 결정할 수 있다. 도 6은 본 발명의 일 실시예에 따른 트래킹정보보정단계의 세부과정을 개략적으로 도시한다. 본 발명의 일 실시예에서는, 트랙킹정보보정단계는, 인접한 2개의 키프레임에서의 바운딩박스정보로부터 도출될 수 있는 해당 객체의 크기정보와 상기 인접한 2개의 키프레임 사이의 일반프레임에서 검출된 해당 객체의 바운 딩박스의 크기정보를 비교하여, 기설정된 기준 이상의 차이가 있다고 판단하는 경우에는 상기 인접한 두 키프레 임에서의 해당객체의 바운딩박스의 크기정보에 기초하여 상기 인접한 2개의 키프레임 사이의 일반프레임의 해당 객체의 바운딩박스의 크기정보를 생성할 수 있다. 도 6의 (A)에서, #1 내지 #4 객체는 동일한 객체에 해당한다. 우선 트랙킹정보보정단계는 키프레임에 해당하는 #1객체 및 #4객체의 크기(바운딩박스의 크기)의 평균값을 도출한다. 이후, 도출된 평균값과 #2객체 및 #3객체의 크기(바운딩박스의 크기)의 차이를 도출하고, 도출된 차이가 기설정 된 기준 이상인지 여부를 판단한다. 도 6의 (A)에서는 동일한 객체로 트랙킹이 되었음에도 불구하고, #1 및 #4의 객체의 크기보다 #2객체 및 #3객체 의 크기보다 훨씬 작다. 이 경우, 트랙킹정보에서의 #2객체 및 #3객체의 경우 바운딩박스의 중심은 그대로 유지 하면서, 크기를 상기 #1객체의 크기와 #4객체의 크기의 평균값으로 결정한다.혹은 본 발명의 다른 실시예에서는 #1객체의 크기(바운딩박스의 크기)와 #4객체의 크기(바운딩박스의 크기)를 선형보간하여 #2 및 #3객체의 크기를 결정할 수 있다. 예를들어, #1객체의 크기가 30이고, #4객체의 크기가 60인 경우에, #2객체의 크기는 40 (30 + (60-30) * (1/3))이 될 수 있고, #3객체의 크기는 50 (30 + (60-30) * (2/3))가 될 수 있다. 즉, N번째 프레임과 N+P 번째 프레임이 키프레임이 되는 경우에, 보정되는 N+Q번째 프레임의 해당개체의 크기 (바운딩박스 크기)는 하기와 같은 식으로 결정될 수 있다. 크기N+Q = 크기N + (크기N+P - 크기N) * (Q/P) (크기X는 X번째 프레임의 해당 객체의 바운딩박스의 크기) 도 7은 본 발명의 일 실시예에 따른 제2메타정보도출단계에서의 분석영역을 도출하는 과정에 대하여 개략적으로 도시한다. 본 발명의 일 실시예에서는, 상기 제1메타정보도출단계는, N번째 키프레임에서의 객체의 제1바운딩박스의 위치 를 상기 제2메타정보도출단계에서 이용할 수 있도록 제공하고, 상기 제2메타정보도출단계는, 상기 제1바운딩박 스의 위치를 중심으로 하는 분석영역을 도출한 후에, 상기 분석영역에 대해서만 상기 제2검출모델을 이용하여 제2메타정보를 도출한다. 도 7에 도시된 바와 같이 #1프레임에 해당하는 키프레임에서 객체(혹은 객체의 바운딩박스 정보)가 검출되는 경 우에는, 해당 객체의 위치를 중심으로 하고 특정한 크기를 갖는 분석영역을 도출한다. 이와 같이 도출된 분석영역에 대해서만 상기 제2메타정보도출단계에서 제2추론모델에 의한 객체검출이 수행됨으 로써, 제2프로세서모듈(CPU)의 연산량을 감소시키면서, 결과적으로 제1추론모델의 정확성을 이용하여 제2 추론모델의 정확성을 간접적으로 개선시킬 수 있다. 이후 #3프레임의 경우에는, 일반프레임인 #2프레임에서 검출된 객체의 객체바운딩박스의 위치정보를 중심으로 하고, 특정한 크기를 갖는 분석영역에 대해서 제2추론모델이 동작할 수 있다. 즉, 이전의 프레임이 일반프레임 인 경우에는 이전의 일반프레임에서의 객체의 위치가 분석영역을 결정하는 데 사용될 수도 있다. 도 8은 본 발명의 일 실시예에 따른 제2메타정보도출단계에서의 분석영역의 크기를 도출하는 과정에 대하여 개 략적으로 도시한다. 상기 도 7에서의 분석영역의 위치는 상수로서 고정될 수 있으나, 도 8의 실시예에서는 CPU의 연상량을 더욱 효 율적으로 감소시키기 위하여, 분석영역의 위치를 키프레임의 검출결과에 따라 가변한다. 본 발명의 바람직한 실시예에서는, 상기 분석영역의 크기는, N번째 키프레임에서의 해당 객체의 제1바운딩박스 의 위치와 N+1번째 키프레임에서의 해당 객체의 제1바운딩박스의 위치의 차이가 클수록 상기 분석영역의 크기를 증가시키는 형태로 결정된다. 키프레임 사이에서 객체의 이동이 많이 일어났다고 판단되면 객체의 속도가 빠른 것으로 판단하여, 객체의 분석 영역을 크게 하는 것이다. 예를들어 도 8에서는 #1번째 프레임과 #11번째 프레임이 키프레임에 해당한다. 이 경우, 분석영역의 크기는 #1 번째 프레임과 #11번째 프레임에서의 해당객체(객체1)의 이동거리가 클수록 크게 설정한다. 이와 같은 방식으로 가변크기의 분석영역을 도입하여 정확도를 그대로 유지하면서 CPU의 불필요한 연산을 감소시킬 수 있다. 도 9은 본 발명의 일 실시예에 따른 컴퓨팅장치의 내부 구성을 예시적으로 도시한다. 도 9에 도시된 바와 같이, 컴퓨팅장치는 적어도 하나의 프로세서(processor), 메모리 (memory), 주변장치 인터페이스(peripheral interface), 입/출력 서브시스템(I/O subsystem), 전력 회로 및 통신 회로를 적어도 포함할 수 있다. 이때, 컴퓨팅장치의 내부 구성은 도 1에 도시된 컴퓨팅시스템이 포함할 수 있고, 혹은 컴퓨팅장치은 도 1에 도시 된 컴퓨팅 시스템의 일 실시예에 해당할 수 있다. 상기 프로세서은 복수로 구성될 수 있고, 전술한 제1 프로세서모듈 및 제2프로세서모듈을 포함할 수 있다. 메모리는 일례로 고속 랜덤 액세스 메모리(high-speed random access memory), 자기 디스크, 에스램 (SRAM), 디램(DRAM), 롬(ROM), 플래시 메모리 또는 비휘발성 메모리를 포함할 수 있다. 메모리는 컴퓨팅 장치의 동작에 필요한 소프트웨어 모듈, 명령어 집합 또는 그 밖에 다양한 데이터를 포함할 수 있다. 이때, 프로세서나 주변장치 인터페이스 등의 다른 컴포넌트에서 메모리에 액세스하는 것 은 프로세서에 의해 제어될 수 있다. 주변장치 인터페이스는 컴퓨팅장치의 입력 및/또는 출력 주변장치를 프로세서 및 메모리 에 결합시킬 수 있다. 프로세서는 메모리에 저장된 소프트웨어 모듈 또는 명령어 집합을 실행하여 컴퓨팅장치을 위한 다양한 기능을 수행하고 데이터를 처리할 수 있다. 입/출력 서브시스템은 다양한 입/출력 주변장치들을 주변장치 인터페이스에 결합시킬 수 있다. 예를 들 어, 입/출력 서브시스템은 모니터나 키보드, 마우스, 프린터 또는 필요에 따라 터치스크린이나 센서 등의 주변 장치를 주변장치 인터페이스에 결합시키기 위한 컨트롤러를 포함할 수 있다. 다른 측면에 따르면, 입/출 력 주변장치들은 입/출력 서브시스템을 거치지 않고 주변장치 인터페이스에 결합될 수도 있다. 전력 회로는 단말기의 컴포넌트의 전부 또는 일부로 전력을 공급할 수 있다. 예를 들어 전력 회로 는 전력 관리 시스템, 배터리나 교류(AC) 등과 같은 하나 이상의 전원, 충전 시스템, 전력 실패 감지 회 로(power failure detection circuit), 전력 변환기나 인버터, 전력 상태 표시자 또는 전력 생성, 관리, 분배 를 위한 임의의 다른 컴포넌트들을 포함할 수 있다. 통신 회로는 적어도 하나의 외부 포트를 이용하여 다른 컴퓨팅장치와 통신을 가능하게 할 수 있다. 또는 상술한 바와 같이 필요에 따라 통신 회로는 RF 회로를 포함하여 전자기 신호(electromagnetic signal)라고도 알려진 RF 신호를 송수신함으로써, 다른 컴퓨팅장치와 통신을 가능하게 할 수도 있다. 이러한 도 9의 실시예는, 컴퓨팅장치의 일례일 뿐이고, 컴퓨팅장치는 도 9에 도시된 일부 컴포넌 트가 생략되거나, 도 9에 도시되지 않은 추가의 컴포넌트를 더 구비하거나, 2개 이상의 컴포넌트를 결합시키는 구성 또는 배치를 가질 수 있다. 예를 들어, 모바일 환경의 통신 단말을 위한 컴퓨팅장치는 도 9에 도시된 컴포 넌트들 외에도, 터치스크린이나 센서 등을 더 포함할 수도 있으며, 통신 회로에 다양한 통신방식(WiFi, 3G, LTE, Bluetooth, NFC, Zigbee 등)의 RF 통신을 위한 회로가 포함될 수도 있다. 컴퓨팅장치에 포함 가능한 컴포넌트들은 하나 이상의 신호 처리 또는 어플리케이션에 특화된 집적 회로를 포함하는 하드웨어, 소프 트웨어, 또는 하드웨어 및 소프트웨어 양자의 조합으로 구현될 수 있다. 본 발명의 실시예에 따른 방법들은 다양한 컴퓨팅장치를 통하여 수행될 수 있는 프로그램 명령(instruction) 형 태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 특히, 본 실시예에 따른 프로그램은 PC 기반의 프로그 램 또는 모바일 단말 전용의 어플리케이션으로 구성될 수 있다. 본 발명이 적용되는 어플리케이션은 파일 배포 시스템이 제공하는 파일을 통해 컴퓨팅장치에 설치될 수 있다. 일 예로, 파일 배포 시스템은 컴퓨팅장치 의 요청에 따라 상기 파일을 전송하는 파일 전송부(미도시)를 포함할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어구 성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크 로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명 령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목 적컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이 상의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장 치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또 는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨팅장치 상에 분산되어서, 분산 된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2021-0174859", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범 위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2021-0174859", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 객체탐지 및 객체트랙킹 방법의 세부 단계들을 개략적으로 도시한다. 도 2는 본 발명의 일 실시예에 따른 키프레임 및 일반프레임에 대하여 이종의 프로세서모듈의 연산배분에 대하 여 개략적으로 도시한다. 도 3은 본 발명의 일 실시예에 따른 트랙킹정보도출단계의 과정을 개략적으로 도시한다. 도 4는 본 발명의 일 실시예에 따른 키프레임에서 도출된 특징정보의 일반프레임의 탐지결과로의 부여 과정을 개략적으로 도시한다. 도 5는 본 발명의 일 실시예에 따른 트래킹정보보정단계의 세부과정을 개략적으로 도시한다. 도 6은 본 발명의 일 실시예에 따른 트래킹정보보정단계의 세부과정을 개략적으로 도시한다. 도 7은 본 발명의 일 실시예에 따른 제2메타정보도출단계에서의 분석영역을 도출하는 과정에 대하여 개략적으로 도시한다. 도 8은 본 발명의 일 실시예에 따른 제2메타정보도출단계에서의 분석영역의 크기를 도출하는 과정에 대하여 개 략적으로 도시한다. 도 9는 본 발명의 일 실시예에 따른 컴퓨팅장치의 내부 구성을 예시적으로 도시한다."}
