{"patent_id": "10-2019-0095643", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0099166", "출원번호": "10-2019-0095643", "발명의 명칭": "오브젝트 인식 기반의 정보 제공 방법 및 장치와 이를 위한 매핑 장치", "출원인": "엘지전자 주식회사", "발명자": "이은상"}}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "오브젝트 인식 기반의 정보 제공 장치로서,카메라를 포함하는 입력부;디스플레이를 포함하는 출력부; 및 상기 카메라의 촬영 범위 내에 배치된 오브젝트를 인식하는 프로세서를 포함하며,상기 프로세서는,인식된 오브젝트에 대응되는 하나 이상의 AR(Augmented Reality) 아이템을 출력하기 위한 소정의 이벤트가 발생되면, 상기 촬영 범위에 노출된 상기 오브젝트의 노출 영역 및 상기 촬영 범위에 비노출된 상기 오브젝트의 비노출 영역에 기초하여, 상기 AR 아이템을 상기 디스플레이 상에 출력하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 소정의 이벤트가 발생되면, 상기 오브젝트의 노출 영역에 제1 AR 아이템을 디스플레이하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 AR 아이템은,상기 오브젝트의 비노출 영역을 노출하기 위한 사용자의 동작을 유도하는 문구 또는 이미지를 포함하는, 정보제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 프로세서는,상기 제1 AR 아이템에 관한 정보, 상기 비노출 영역에 배치된 물품 정보, 상기 비노출 영역에 배치된 AR 아이템에 관한 정보 및 상기 오브젝트에 관한 정보 중 적어도 하나를 포함하는 제2 AR 아이템을 소정 영역에 디스플레이하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 오브젝트는, 수용 공간을 포함하며 상기 수용 공간을 개폐시키는 개폐부를 포함하며,상기 프로세서는,상기 소정의 이벤트가 발생되면, 상기 수용 공간의 오픈을 유도하는 제1 AR 아이템을 디스플레이하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2019-0099166-3-상기 프로세서는,상기 수용 공간이 오픈되면, 상기 카메라의 촬영 범위 내에 제3 AR 아이템을 디스플레이하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 오브젝트는 수용 공간을 포함하며, 상기 프로세서는,상기 소정의 이벤트가 발생되면, 상기 수용 공간의 내부를 소정만큼 채우는 물을 표시하는 제1 AR 아이템을 디스플레이하고, 상기 제1 AR 아이템 속에 유영체를 표시하는 제2 AR 아이템을 디스플레이하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는,사용자의 생활 패턴에 기초하여, 사용자의 메모 정보를 포함하는 상기 AR 아이템을 시간 정보, 이동 경로 정보,장소 정보 및 사용 빈도수 정보 중 적어도 하나에 기초하여 상기 디스플레이 상에 출력하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,근거리 통신 모듈 및 이동 통신 모듈을 구비한 통신부를 더 포함하며,상기 프로세서는,상기 근거리 통신 모듈을 통해 상기 오브젝트의 근거리 통신 커버리지에 진입한 경우, 또는 상기 이동 통신 모듈을 통해 상기 오브젝트가 속한 이동 통신 커버리지의 소정 범위 내 진입한 경우, 상기 소정의 이벤트가 발생된 것으로 결정하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 입력부는 마이크를 더 포함하며, 상기 프로세서는,기 설정된 사운드 시퀀스가 상기 마이크를 통해 입력되면, 상기 소정의 이벤트가 발생된 것으로 결정하는, 정보제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 입력부는 마커 인식부를 더 포함하며,상기 프로세서는,상기 오브젝트로부터 소정 거리 내에 위치한 마커가 상기 마커 인식부를 통해 인식되는 경우, 상기 소정의 이벤트가 발생된 것으로 결정하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 출력부는 스피커 또는 바이브레이터를 포함하며,상기 프로세서는,공개특허 10-2019-0099166-4-상기 소정의 이벤트가 발생되거나 상기 디스플레이 상에 상기 AR 아이템이 디스플레이된 경우, 상기 스피커를통해 소정의 사운드를 출력하거나 상기 바이브레이터를 통해 소정 패턴의 진동을 출력하는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 출력부는 스피커를 더 포함하며,프로세서는,상기 정보 제공 장치가 상기 오브젝트에 소정 거리 내로 근접한 경우, 상기 스피커를 통해 기 설정된 사운드를출력하고, 상기 오브젝트와의 거리가 가까워질수록 상기 사운드의 출력 세기를 상승시키는, 정보 제공 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "오브젝트 인식 기반의 정보 제공 방법으로서,카메라의 촬영 범위 내에 배치된 오브젝트를 인식하는 단계;인식된 오브젝트에 대응되는 하나 이상의 AR(Augmented Reality) 아이템을 출력하기 위한 소정의 이벤트 발생을감지하는 단계; 및 상기 소정의 이벤트가 발생되면, 상기 촬영 범위에 노출된 상기 오브젝트의 노출 영역 및 상기 촬영 범위에 비노출된 상기 오브젝트의 비노출 영역에 기초하여, 상기 AR 아이템을 디스플레이하는 단계를 포함하는, 정보 제공 방법."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 소정의 이벤트 발생을 감지하는 단계는,상기 오브젝트의 근거리 통신 커버리지에의 진입을 감지하는 단계;상기 오브젝트가 속한 소정 범위의 이동 통신 커버리지에의 진입을 감지하는 단계;기 설정된 사운드 시퀀스의 입력을 감지하는 단계; 및상기 오브젝트와 소정 거리 인접한 마커를 감지하는 단계 중 하나를 포함하는, 정보 제공 방법."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 AR 아이템을 디스플레이하는 단계는,상기 소정의 이벤트가 발생되면, 상기 오브젝트의 노출 영역에 제1 AR 아이템을 디스플레이하는 단계를 포함하는, 정보 제공 방법."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 제1 AR 아이템을 디스플레이하는 단계는,상기 오브젝트의 비노출 영역을 노출하기 위한 사용자의 동작을 유도하는 문구 또는 이미지를 디스플레이하는단계를 포함하는, 정보 제공 방법."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 제1 AR 아이템을 디스플레이하는 단계는,상기 제1 AR 아이템에 관한 정보, 상기 비노출 영역에 배치된 물품 정보, 상기 비노출 영역에 배치된 AR 아이템공개특허 10-2019-0099166-5-에 관한 정보 및 상기 오브젝트에 관한 정보 중 적어도 하나를 포함하는 제2 AR 아이템을 소정 영역에 디스플레이하는 단계를 포함하는, 정보 제공 방법."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "소정의 조건에서 활성화되는 하나 이상의 AR 아이템을 오브젝트에 매핑(Mapping)하는 장치로서,카메라를 포함하는 입력부;저장부; 및 프로세서를 포함하며,상기 프로세서는,상기 카메라의 촬영 범위 내에 배치된 오브젝트를 인식하고, 인식된 오브젝트에 관한 정보, AR 아이템의 배치정보 및 AR 아이템에 관한 정보 중 적어도 하나를 상기 저장부에 저장하며, 상기 촬영 범위 내에 노출된 상기 오브젝트의 노출 영역 및 상기 촬영 범위에 비노출된 상기 오브젝트의 비노출영역에 기초하여 상기 AR 아이템을 활성화시키는 이벤트 정보를 설정하는, 매핑 장치."}
{"patent_id": "10-2019-0095643", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 프로세서는,상기 인식된 오브젝트의 형상 정보, 모양 정보, 수용 공간의 유무 정보 및 배치 정보 중 적어도 하나를 포함하는 구성 정보에 기초하여, 상기 AR 아이템을 상기 오브젝트의 소정 영역에 배치하는, 매핑 장치."}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "탑재된 인공지능(artificial intelligence, AI) 알고리즘 및/또는 기계학습(machine learning) 알고리즘을 실행 하며, 5G 통신 환경에서 다른 전자 기기들 및 외부 서버와 통신할 수 있는 정보 제공 장치가 개시된다. 상기 장 치는 카메라, 디스플레이 및 프로세스 등을 포함한다. 상기 정보 제공 장치가 제공됨으로써, 인식된 오브젝트에 기반한 사용자 친화적인 AR 아이템이 제공될 수 있다."}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 오브젝트 인식 기반의 정보 제공 방법 및 장치와 이를 위한 매핑 장치에 관한 것으로, 더 상세하게는 오브젝트를 인식하고 인식된 오브젝트와 관련된 증강 현실 아이템을 제공하는 방법 및 장치, 그리고 오브젝트와 증강 현실 아이템을 매핑하는 장치에 관한 것이다."}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "단말기는 이동 가능 여부에 따라 이동 단말기 및 고정 단말기로 나뉠 수 있다. 다시 이동 단말기는 사용자의 직 접 휴대 가능 여부에 따라 휴대형 단말기 및 거치형 단말기로 나뉠 수 있다. 이동 단말기의 기능은 다양화되고 있으며, 카메라의 성능이 발달됨에 따라, 카메라를 이용한 다양한 기능들이 개발되고 있다. 예를 들어, 고화질의 정지영상 또는 동영상 등을 촬영하거나, 카메라를 통해 수신되는 영상의 깊이 정보를 이용하여 3D 이미지를 생성하는 기능들에 대한 개발이 활발히 이루어지고 있다. 선행 기술 1은 촬영 영상에서 사용자가 선택한 오브젝트와 관련된 정보를 디스플레이에 표시하는 글래스 타입의 이동 단말을 개시한다. 다만, 선행 기술 1에 개시된 이동 단말의 경우, 사용자가 명시적으로 오브젝트를 선택해야 하는 별도의 프로세 스가 필요하므로, 이동 단말이 이동할 때, 자동으로 오브젝트와 관련된 정보를 표시하지 못하는 한계가 있다. 선행 기술 2는 이미지를 복수의 분할 영역으로 나누고 분할 영역 각각에 포함된 텍스트를 추출하는 이동 단말을 개시한다. 다만, 선행 기술 2에 개시된 이동 단말의 경우, 이미지에 표현된 텍스트를 추출할 뿐이므로, 이미지에 표현되지 않았으나 오브젝트와 관련된 정보를 적절하게 표시하지 못하는 한계가 있다. 선행기술문헌 특허문헌(특허문헌 0001) 선행 기술 1: 등록특허공보 제10-1881529호(등록일: 2018.7.18) (특허문헌 0002) 선행 기술 2: 등록특허공보 제10-1421704호(등록일: 2014.7.15)"}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 촬영 범위 내의 오브젝트를 인식하고, 인식된 오브젝트에 대응되는 증강 현 실 기반의 아이템을 출력하는 정보 제공 방법 및 장치를 제공하는 데에 있다. 본 발명의 또 다른 과제는, 인식된 오브젝트의 특성에 맞도록 증강 현실 기반의 아이템 및 유저 인터페이스를 출력하는 정보 제공 방법 및 장치를 제공하는 데에 있다. 본 발명의 또 다른 과제는, 자동 및 실시간으로 주변 오브젝트에 관련된 정보를 적시에 제공하는 오브젝트 기반 의 정보 제공 방법 및 장치를 제공하는데 있다. 본 발명의 또 다른 과제는, 사용자가 누락하기 쉬운 정보를 메모 형태로 적절하게 출력하는 정보 제공 방법 및 장치를 제공하는데 있다. 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 일 실시 예에 따른 오브젝트 인식 기반의 정보 제공 장치는 카메라를 포함하는 입력부, 디스플레이를 포함하는 출력부 및 카메라의 촬영 범위 내에 배치된 오브젝트를 인식하는 프로 세서를 포함할 수 있다. 상기 프로세서는, 인식된 오브젝트에 대응되는 하나 이상의 AR(Augmented Reality) 아이템을 출력하기 위한 소 정의 이벤트가 발생되면, 촬영 범위에 노출된 상기 오브젝트의 노출 영역 및 촬영 범위에 비노출된 오브젝트의 비노출 영역에 기초하여, AR 아이템을 상기 디스플레이 상에 출력할 수 있다. 또한, 상기 프로세서는 소정의 이벤트가 발생되면, 오브젝트의 노출 영역에 제1 AR 아이템을 디스플레이할 수 있다. 또한, 상기 제1 AR 아이템은 오브젝트의 비노출 영역을 노출하기 위한 사용자의 동작을 유도하는 문구 또는 이 미지를 포함할 수 있다. 상기 프로세서는 제1 AR 아이템에 관한 정보, 비노출 영역에 배치된 물품 정보, 비노출 영역에 배치된 AR 아이 템에 관한 정보 및 오브젝트에 관한 정보 중 적어도 하나를 포함하는 제2 AR 아이템을 소정 영역에 디스플레이 할 수 있다. 또한, 상기 오브젝트는 수용 공간을 포함하며 상기 수용 공간을 개폐시키는 개폐부를 포함하며, 상기 프로세서 는 소정의 이벤트가 발생되면, 수용 공간의 오픈을 유도하는 제1 AR 아이템을 디스플레이할 수 있다. 상기 프로세서는 수용 공간이 오픈되면, 카메라의 촬영 범위 내에 제3 AR 아이템을 디스플레이할 수 있다. 또한, 상기 오브젝트는 수용 공간을 포함하며, 상기 프로세서는 소정의 이벤트가 발생되면, 수용 공간의 내부를 소정만큼 채우는 물을 표시하는 제1 AR 아이템을 디스플레이하고, 제1 AR 아이템 속에 유영체를 표시하는 제2 AR 아이템을 디스플레이할 수 있다. 상기 프로세서는 사용자의 생활 패턴에 기초하여, 사용자의 메모 정보를 포함하는 AR 아이템을 시간 정보, 이동 경로 정보, 장소 정보 및 사용 빈도수 정보 중 적어도 하나에 기초하여 상기 디스플레이 상에 출력할 수 있다. 몇몇 실시 예에서, 상기 정보 제공 장치는 근거리 통신 모듈 및 이동 통신 모듈을 구비한 통신부를 더 포함하며, 프로세서는 근거리 통신 모듈을 통해 오브젝트의 근거리 통신 커버리지에 진입한 경우, 또는 이동 통 신 모듈을 통해 오브젝트가 속한 이동 통신 커버리지의 소정 범위 내 진입한 경우, 소정의 이벤트가 발생된 것으로 결정할 수 있다. 또한, 상기 정보 제공 장치의 입력부는 마이크를 더 포함하며, 프로세서는 기 설정된 사운드 시퀀스가 마이크를 통해 입력되면, 소정의 이벤트가 발생된 것으로 결정할 수 있다. 또한, 상기 입력부는 마커 인식부를 더 포함하며, 프로세서는 오브젝트와 소정 거리 인접한 마커가 마커 인식부 를 통해 인식되는 경우, 소정의 이벤트가 발생된 것으로 결정할 수 있다. 또한, 상기 출력부는 스피커 또는 바이브레이터를 포함하며, 프로세서는 소정의 이벤트가 발생되거나 디스플레 이 상에 AR 아이템이 디스플레이된 경우, 스피커를 통해 소정의 사운드를 출력하거나 바이브레이터를 통해 소정 패턴의 진동을 출력할 수 있다. 또한, 상기 출력부는 스피커를 더 포함하며, 프로세서는 정보 제공 장치가 오브젝트에 소정 거리 내로 근접한 경우, 스피커를 통해 기 설정된 사운드를 출력하고, 오브젝트와의 거리가 가까워질수록 사운드의 출력 세기를 상승시킬 수 있다. 본 발명의 일 실시 예에 따른 오브젝트 인식 기반의 정보 제공 방법은 카메라의 촬영 범위 내에 배치된 오브젝 트를 인식하는 단계, 인식된 오브젝트에 대응되는 하나 이상의 AR(Augmented Reality) 아이템을 출력하기 위한 소정의 이벤트 발생을 감지하는 단계 및 소정의 이벤트가 발생되면, 촬영 범위에 노출된 오브젝트의 노출 영역 및 촬영 범위에 비노출된 오브젝트의 비노출 영역에 기초하여, AR 아이템을 디스플레이하는 단계를 포함할 수 있다. 상기 소정의 이벤트 발생을 감지하는 단계는, 오브젝트의 근거리 통신 커버리지에의 진입을 감지하는 단계, 오 브젝트가 속한 소정 범위의 이동 통신 커버리지에의 진입을 감지하는 단계, 기 설정된 사운드 시퀀스의 입력을 감지하는 단계, 및 오브젝트와 소정 거리 인접한 마커를 감지하는 단계 중 하나를 선택적으로 포함할 수 있다. 상기 AR 아이템을 디스플레이하는 단계는 소정의 이벤트가 발생되면, 오브젝트의 노출 영역에 제1 AR 아이템을 디스플레이하는 단계를 포함할 수 있다. 상기 제1 AR 아이템을 디스플레이하는 단계는, 오브젝트의 비노출 영역을 노출하기 위한 사용자의 동작을 유도 하는 문구 또는 이미지를 디스플레이하는 단계를 포함할 수 있다. 상기 제1 AR 아이템을 디스플레이하는 단계는 제1 AR 아이템에 관한 정보, 비노출 영역에 배치된 물품 정보, 비 노출 영역에 배치된 AR 아이템에 관한 정보 및 오브젝트에 관한 정보 중 적어도 하나를 포함하는 제2 AR 아이템 을 소정 영역에 디스플레이하는 단계를 포함할 수 있다. 본 발명의 일 실시 예에 따른 소정의 조건에서 활성화되는 하나 이상의 AR 아이템을 오브젝트에 매핑(Mapping) 하는 장치는 카메라를 포함하는 입력부, 저장부 및 프로세서를 포함하며, 프로세서는, 카메라의 촬영 범위 내에 배치된 오브젝트를 인식하고, 인식된 오브젝트에 관한 정보, AR 아이템의 배치 정보 및 AR 아이템에 관한 정보 중 적어도 하나를 저장부에 저장하며, 촬영 범위 내에 노출된 오브젝트의 노출 영역 및 촬영 범위에 비노출된 오브젝트의 비노출 영역에 기초하여 AR 아이템을 활성화시키는 이벤트 정보를 설정할 수 있다. 상기 프로세서는 인식된 오브젝트의 평면적 또는 입체적 형상 정보, 모양 정보, 수용 공간의 유무 정보 및 배치 정보 중 적어도 하나를 포함하는 구성 정보에 기초하여, AR 아이템을 상기 오브젝트의 소정 영역에 배치할 수 있다. 본 발명에서 이루고자 하는 기술적 과제들의 해결 수단은 이상에서 언급한 해결 수단들로 제한되지 않으며, 언"}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "급하지 않은 또 다른 해결 수단들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자 에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시 예에 따르면 아래와 같은 효과가 도출될 수 있다. 첫째로, 인식된 오브젝트에 대응되는 증강 현실 기반의 아이템이 출력됨으로써, 사용자 편의가 제고될 수 있으 며, 사용자 친화성이 향상될 수 있다. 둘째로, 인식된 오브젝트의 특성에 맞게 증강 현실 기반의 아이템이 출력되고, 유저 인터페이스의 사용 및 조작 방법이 제공됨으로써, 사용자 편의가 제고될 수 있다.셋째로, 자동 및 실시간으로 주변 오브젝트에 관련된 정보를 적시에 제공할 수 있으므로, 종래의 고정 공간에 메모 또는 메시지 등을 게시하는 것보다 사용자의 정보 접근이 용이하며, 사용자 편의가 제고될 수 있다. 넷째로, 사용자가 누락하기 쉬운 정보를 메모 형태로 적절하게 출력될 수 있으며, 해당 아이템을 찾아가는 접근 과정이 여러 가지 제공될 수 있으므로, 장치 효율성이 향상될 수 있으며, 사용자 편의가 제고될 수 있다."}
{"patent_id": "10-2019-0095643", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 다양한 실시 예에 인공 지능 및 확장 현실의 기술이 적용될 수 있으므로, 인공 지능 및 확장 현실에 대해 개략적으로 설명한다. 인공 지능(AI: Artificial Intelligence)은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미하며, 머신 러닝(기계 학습, Machine Learning)은 인공 지능 분야에서 다루는 다양한 문제를 정의하고 그것 을 해결하는 방법론을 연구하는 분야를 의미한다. 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작 업에 대한 성능을 높이는 알고리즘으로 정의하기도 한다. 인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로서, 시냅스의 결합으로 네트워 크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층 (Hidden Layer)을 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하 는 시냅스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함숫값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망에서 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함 수는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키 는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화 하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 인공 신경망 중에서 복수의 은닉층을 포함하는 심층 신경망(DNN: Deep Neural Network)으로 구현되는 머신 러닝 을 딥 러닝(심층 학습, Deep Learning)이라 부르기도 하며, 딥 러닝은 머신 러닝의 일부이다. 이하에서, 머신 러닝은 딥 러닝을 포함하는 의미로 사용된다. 다음으로, 확장 현실(XR: eXtended Reality)은 가상 현실(VR: Virtual Reality), 증강 현실(AR: Augmented Reality), 혼합 현실(MR: Mixed Reality)을 총칭한다. VR 기술은 현실 세계의 객체나 배경 등을 CG 영상으로만 제공하고, AR 기술은 실제 사물 영상 위에 가상으로 만들어진 CG 영상을 함께 제공하며, MR 기술 은 현실 세계에 가상 객체들을 섞고 결합시켜서 제공하는 컴퓨터 그래픽 기술이다. MR 기술은 현실 객체와 가상 객체를 함께 보여준다는 점에서 AR 기술과 유사하다. 그러나, AR 기술에서는 가상 객체가 현실 객체를 보완하는 형태로 사용되는 반면, MR 기술에서는 가상 객체와 현실 객체가 동등한 성격으로 사용된다는 점에서 차이점이 있다. XR 기술은 HMD(Head-Mount Display), HUD(Head-Up Display), 휴대폰, 태블릿 PC, 랩탑, 데스크탑, TV, 디지털 사이니지 등에 적용될 수 있고, XR 기술이 적용된 장치를 XR 장치(XR Device)라 칭할 수 있다. 본 명세서 상에 개시된 AR(Augmented Reality) 아이템은 증강 현실 기반의 아이템으로, 실제 사물 영상 위에 가 상으로 만들어진 CG 영상을 함께 제공되는 아이템을 포함하며, 영상 편집을 수행한 것처럼 실제 사물 영상과 CG 영상의 구분이 어려울 정도, 더 나아가 구분이 안되는 정도의 아이템을 포함할 수 있다. 이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 동일하거나 유사한 구성요소에 는 동일 유사한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐 릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 도 1은 본 발명의 일 실시 예에 따른 5G 네트워크 기반의 정보 제공 클라우드 시스템을 개략적으로 나타 낸다. 5G 네트워크 기반 정보 제공 클라우드 시스템은 5G 기반에서 제공될 수 있는 다양한 서비스를 정의할 수 있으며, 오브젝트 인식 기반의 정보 제공 장치, 소정의 조건에서 활성화되는 AR 아이템을 오브젝트에 매핑 하는 장치, 정보 제공 시스템, 각종 기기 및 5G 네트워크를 포함할 수 있다. 우선, 오브젝트 인식 기반의 정보 제공 장치(100, 이하 \"정보 제공 장치\"로 칭함)는 카메라(도 3의 121)를 이용 하여 다양한 오브젝트를 인식하고, 인식된 오브젝트에 관련된 정보를 사용자, 정보 제공 시스템 및 각종 기기 등에 제공할 수 있다. 정보 제공 장치는 휴대폰, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 디지털방송용 단말 기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 슬레이트 PC(slate PC), 태블릿 PC(tablet PC), 울트라북(ultrabook), 웨어러블 디바이스(wearable device, 예를 들어, 워치형 단 말기 (smartwatch), 글래스형 단말기 (smart glass), HMD(head mounted display)) 등의 이동 기기들을 포함할 수 있으며, 구현 예에 따라서는, 고정형으로 구현된 디지털 TV, 데스크탑 컴퓨터, 디지털 사이니지 등의 고정 기기 등도 포함할 수 있다. 본 명세서 상에서의 정보 제공 장치는 사용자의 몸에 부착되는 글래스형 단말 기, HMD, 워치형 단말기로 구현될 때, 가장 효율이 우수할 수 있다. 다음으로, 소정의 조건에서 활성화되는 AR 기반의 아이템(이하, \"AR 아이템\")을 오브젝트에 매핑하는 장치(200, 이하 \"매핑 장치\")는 촬영된 오브젝트 및 AR 아이템을 서로 매핑하고, AR 아이템을 적절하게 배치할 수 있다. 구체적으로, 매핑 장치는 AR 아이템을 오브젝트의 구성 정보(가령, 형상 정보, 모양 정보, 수용 공간의 포 함유무에 대한 정보, 배치 정보 등)에 기초하여, AR 아이템을 오브젝트의 소정 영역 또는 인접 영역에 배치할 수 있다. 배치되는 지점은 촬영된 오브젝트의 노출 영역 또는 비노출 영역일 수 있으며, 상기 AR 아이템은 촬영 구도에 따라 노출될 수도 아닐 수도 있다. 매핑된 AR 아이템은 정보 제공 장치가 오브젝트를 인식하는 경 우 소정의 조건하에서 정보 제공 장치에서 활성화될 수 있다. 매핑 장치는 오브젝트의 표면뿐만 아니 라 깊이 있는 공간에 AR 아이템을 배치할 수 있다. 매핑 장치는 GPS 기반의 마커를 남길 때는 영상을 세그먼테이션하여 레이어로 구분할 수 있다. 정보 제공 장치는 매핑 장치가 매핑한 AR 아이템 및 오브젝트에 관한 정보를 공유하는 어플리케이션 (앱)을 통해 정보 제공 시스템으로부터 수집할 수 있다. 선택적 또는 부가적 실시 예로, 상기 매핑 장치는 영상 정보만 제공하고 정보 제공 시스템이 오브젝 트와 AR 아이템을 서로 매핑시킬 수도 있다. 정보 제공 시스템는 정보 제공 장치 또는 매핑 장치의 요청에 따라 다양한 정보를 해당 장치로 전송할 수 있다. 정보 제공 시스템은 복수 개의 서버를 포함할 수 있으며, 클라우드 타입의 시스템으로 구 현될 수 있다. 각종 기기는 컴퓨터(400a), 냉장고, 세탁기, 에어컨, AI 스피커 등을 포함하는 홈 어플라이언스(Home Appliance), 자율 주행차(400b), 로봇(400c) 등을 포함할 수 있으며, 5G 네트워크를 통해 각종 정보를 송 수신할 수 있다. 각종 기기는 정보 제공 장치 및 매핑 장치 등과 5G 네트워크(500, 예를 들면, 인터넷)를 통해 무선으로 연결될 수 있다. 실시 예에 따르면, 상기 각종 기기는 상술한 휴대폰, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer) 등을 포함할 수 있다. 정보 제공 장치는 통신 모듈을 이용하여 네트워크를 통해 정보 제공 시스템, 각종 기기 등 과 통신할 수 있다. 정보 제공 장치는 정보 제공 시스템에 다양한 정보를 요청할 수 있으며, 정보 제 공 시스템으로부터 연산/검색된 다양한 정보를 수신할 수 있다. 상기 연산/검색은 인공 지능에 관련된 연 산 또는 검색을 포함할 수 있다. 상기 정보 제공 장치, 매핑 장치, 정보 제공 시스템 및 각종 기기는 모두 5G 모듈을 탑재 하여 100Mbps 내지 20Gbps(또는, 그 이상) 속도로 데이터를 송수신할 수 있어서 대용량의 동영상 파일을 다양한 기기로 전송할 수 있으며, 저전력으로 구동되어 전력 소비를 최소화할 수 있다. 다만, 상기 전송 속도는 실시 예에 따라 달리 구현될 수 있다. 5G 네트워크는 5G 이동 통신 네트워크, 근거리 네트워크, 인터넷 등을 포함하여 유무선으로 기기들의 통신 환경을 제공할 수 있다. 이하에서는 도 2를 참고하여, 본 발명의 일 실시 예에 따른 정보 제공 장치의 구동을 개략적으로 설명하기 로 한다. 사용자(USER)는 정보 제공 장치를 소지할 수 있으며, 정보 제공 장치는 AR 아이템 트리거 공간(TAR, 이하 \"트리거 공간\"로 칭함)으로 진입할 수 있다. 정보 제공 장치는 카메라(도 3의 121)를 통해 트리거 공간(TAR)에 실제로 배치된 제1 내지 제3 오브젝트들 (OB1a~Ob3a)을 비전 인식(Vision Recognition) 기반으로 인식할 수 있으며, 정보 제공 장치는 제1 내지 제3 오브젝트들(OB1a~Ob3a)에 대응되는 촬영된 제1 내지 제3 오브젝트들(OB1b~OB3b)을 디스플레이에 디스 플레이할 수 있다. 정보 제공 장치는 촬영 범위 내의 영상에서 시각적인 오브젝트들을 인식할 수 있으며, 필요한 경우 카메 라는 깊이 인식 기능을 구비할 수 있다. 선택적 실시 예로, 오브젝트들이 3차원 영상으로 구현된 경우, 복 수의 깊이 인식 기능을 구비한 센서 및 카메라가 탑재될 수 있다. 트리거 공간(TAR)에 진입한 정보 제공 장치는 제1 오브젝트(OB1a)의 특정 영역(AA)에 매핑된 AR 아이템 (ARI1)을 디스플레이에 표시할 수 있다. 상기 AR 아이템(ARI1)에 다양한 시각적 효과가 부여될 수 있으며, 선택적 또는 부가적 실시 예로 상기 AR 아이템 (ARI1)은 정지 영상뿐만 아니라 동영상으로 구현될 수 있다. 정보 제공 장치는 카메라 기반의 어플리케이션을 구동할 수 있으며, 상기 어플리케이션은 정보 제공 시스템로부터 실시간으로 AR 아이템의 존재 정보를 수신하여 디스플레이에 표시할 수 있다. 선택적 실시 예로, 정보 제공 장치는 저장부(도 3의 150)에 저장된 AI 관련 학습 모델을 통해서도 오브젝트 에 대응되는 AR 아이템 정보를 디스플레이할 수 있다. 이 경우, 정보 제공 장치는 촬영 범위에 노출된 오 브젝트의 노출 영역 및 촬영 범위에 비노출된 상기 오브젝트의 비노출 영역에 대응되는 AR 아이템을 상기 학습 모델에 기초하여 디스플레이할지 말지를 결정할 수 있다. 이하에서는, 정보 제공 장치의 구성을 도 3을 참고하여 설명하기로 한다. 도 3을 참고하면, 정보 제공 장치은 통신부, 입력부, 센싱부, 출력부, 저장부, 전원공급부 및 프로세서를 포함할 수 있다. 도 3에 도시된 구성요소들은 정보 제공 장치를 구현 하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 정보 제공 장치는 위에서 열거된 구성 요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 먼저, 통신부는 유무선 통신 기술을 이용하여 도 1에 도시된 각종 통신 엔티티(Entity)와 데이터를 송수신 할 수 있다. 예컨대, 통신부는 정보 제공 시스템, 각종 기기 등과 센서 정보, 사용자 입력 정보, 학습 모델에 관한 정보, 제어 신호 정보 등을 송수신할 수 있으나, 전송 정보가 이에 국한되는 것은 아니 다. 이때, 통신부는 이동 통신 모듈 및 근거리 통신 모듈을 포함할 수 있다. 이동 통신 모듈은 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G 등의 기술을 통해 통신하며, 근거리 통신 모듈은 WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블루투스 (Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association;IrDA), ZigBee, NFC(Near Field Communication) 등의 기술을 통해 통신할 수 있다. 입력부는 영상 신호 입력을 위한 카메라, 오디오 신호를 수신하기 위한 마이크로폰(123, 이하, \"마이 크\"로 칭함), 다양한 마커(Marker)를 인식하는 마커 인식부, 사용자로부터 정보를 입력 받기 위한 사용자 입력부 등을 포함할 수 있다. 여기서, 카메라나 마이크를 센서로 취급하여, 카메라나 마이크 로부터 획득한 신호를 센싱 데이터 또는 센서 정보라고 할 수도 있다. 입력부는 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때, 사용될 입력 데이터 등을 획득할 수 있다. 입력부는 가공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 프로세서(19 0)는 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 센싱부는 다양한 센서들을 이용하여 정보 제공 장치의 내부 정보, 정보 제공 장치의 주변 환경 정보 및 사용자 정보 중 적어도 하나를 획득할 수 있다. 이때, 센싱부에 포함되는 센서에는 거리 감지 센서, 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다, 레 이더 등이 있다. 여기서, 거리 감지 센서는 오브젝트 및 정보 제공 장치 간의 거리를 측정할 수 있다. 이에 따라, 정보 제공 장치는 오브젝트로 접근하는 동안 오브젝트와의 접근 거리를 인식할 수 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시킬 수 있는데, 출력부에는 시각 정보를 출 력하는 디스플레이, 청각 정보를 출력하는 스피커, 촉각 정보를 출력하는 햅틱 모듈(가령, 바이브레 이터) 등이 포함될 수 있다. 저장부는 정보 제공 장치의 다양한 기능을 지원하는 데이터를 저장한다. 저장부는 정보 제공 장 치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 정보 제 공 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 저장부는 인공 지능, 머신 러닝, 인공 신경망을 이용하여 연산을 수행하는데 필요한 정보를 저장할 수 있 다. 저장부는 상술한 학습 모델을 저장할 수 있다. 상기 학습 모델은 학습 데이터가 아닌 새로 운 입력 데이터에 대하여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기초로 이용될 수 있다. 여기서, 학습 모델은 오브젝트를 정확하게 인식하기 오브젝트 인식 모델, 인식된 오브젝트에 대응되는 AR 아이템을 추출하는 아이템 추출 모델, 추출된 AR 아이템을 오브젝트와의 관계에서 어디에 배치할지 AR 아이템 배치 모델 등을 포함할 수 있다. 학습 모델은 프로세서의 제어에 따라 촬영된 오브젝트의 노출 영역 및 비노출 영역에 대응되는 AR 아 이템을 표시여부를 결정할 수 있다. 전원공급부는 프로세서의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 정보 제공 장치 의 각 구성요소들에 전원을 공급한다. 이러한 전원공급부는 배터리를 포함하며, 상기 배터리는 내장형 배 터리 또는 교체가능한 형태의 배터리가 될 수 있다. 상기 배터리는 유선 또는 무선 충전 방식으로 충전될 수 있는데, 무선 충전 방식은 자기 유도 방식 또는 자기 공진 방식을 포함할 수 있다. 프로세서는 정보 제공 장치의 구성들을 컨트롤하는 모듈이다. 상기 프로세서는 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프 로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티 프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 프로세서는 인공 지능 연산을 수행하기 위한 러닝 프로세서를 별도로 구비하거나, 자체적으로 러닝 프로세 서를 포함할 수 있다. 프로세서는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있 다. 여기서, 학습된 또는 학습 중인 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아 닌 새로운 입력 데이터에 대하여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하 기 위한 판단의 기초로 이용될 수 있다. 이때, 프로세서는 인공 지능 시스템(가령, 정보 제공 시스템)의 러닝 프로세서와 함께 인공 지능 프 로세싱을 수행하도록 구현될 수도 있다. 프로세서는 비전 인식 기반으로 카메라의 촬영 범위 내에 배치된 오브젝트를 인식할 수 있다. 오브젝 트는 상술한 바와 같이, 수용 공간을 구비할 수 있으며, 수용 공간을 노출시키는 개폐부를 포함할 수 있고, 물 품뿐만 아니라 생물을 포함할 수 있다. 프로세서는 인식된 오브젝트에 대응되는 AR 아이템을 출력하기 위한 소정의 이벤트를 대기할 수 있다. 소 정의 이벤트는 정보 제공 장치에 의해 발생된 이벤트일 수 있으며, 특정 상황에 대응될 수 있다. 이하에서 는 소정의 이벤트 발생에 관한 설명하기로 한다. 프로세서는 정보 제공 장치가 오브젝트의 근거리 통신 커버리지에 진입한 경우 이를 소정의 이벤트가 발생된 것으로 결정할 수 있다. 예를 들면, 프로세서는 정보 제공 장치가 이벤트 발생 구역을 커버리 지로 하는 와이파이 통신, 블루투스 통신, NFC, UWB 통신 등의 커버리지로 진입한 경우, 이를 소정의 이벤트가 발생된 것으로 결정할 수 있다. 이 때, 오브젝트 자체가 통신모듈, 프로세서 등을 포함하는 전자 장치(스마트 기기)인 경우, 오브젝트가 정보 제공 장치로 다이렉트로 또는 정보 제공 시스템를 통해 인다이렉트로 근거리 통신 커버리지에 정보 제공 장치의 진입을 알릴 수 있다. 또한, 프로세서는 카메라 기반의 앱을 구동하고, 해당 앱에서 다양한 오브젝트의 거리 정보에 기반하 여 자동으로 오브젝트에 매핑된 AR 아이템 및 사용자에게 정보를 제공하는 AR 문구를 디스플레이 상에 디 스플레이할 수 있다. 선택적 또는 부가적 실시 예로, 프로세서는 다양한 방식으로 오브젝트에 매핑된 AR 아이템에 관한 정보를 자체적으로 표시하거나 외부에서 수신하여 표시할 수 있다. 또한, 프로세서는 정보 제공 장치가 오브젝트가 속한 이동 통신 커버리지의 소정 범위에 진입한 경우, 소정의 이벤트가 발생된 것으로 결정할 수 있다. 예를 들면, 프로세서는 정보 제공 장치가 이벤트 발생 구역을 커버리지로 하는 5G 밀리미터파 기반의 특정 셀의 통신 커버리지에 진입한 경우, 소정의 이벤트가 발생된 것으로 결정할 수 있다. 또한, 프로세서는 마이크를 통해 기 설정된 사운드 시퀀스가 마이크를 통해 입력되면, 소정의 이벤트가 발생된 것으로 결정할 수 있다. 여기서, 기 설정된 사운드 시퀀스는 해당 오브젝트를 노크하는 사운드, 사용자의 발화 사운드 등을 포함할 수 있으며, 배경 소음, 비가청 주파수의 사운드를 포함할 수 있고, 미리 저장된 경우라면 다양한 사운드가 소정의 이벤트 발생을 결정하는 사운드로 설정될 수 있다. 프로세서는 학습 모델을 통해 상기 사운드 시퀀스 의 입력을 분석 및 결정할 수 있다. 또한, 상기 기 설정된 사운드 시퀀스는 다른 상황과 복합적으로 이용되어 소정의 이벤트가 발생된 것으로 결정 될 수 있다. 가령, 프로세서는 오브젝트와 소정 거리로 근접한 상태에서 상기 사운드 시퀀스가 마이크 를 통해 입력되는 경우, 소정의 이벤트가 발생된 것으로 결정할 수 있다.또한, 프로세서는 마커 인식부를 통해 오브젝트와 소정 거리 인접한 마커가 마커 인식부를 통해 인식되는 경우, 소정의 이벤트가 발생된 것으로 결정할 수 있다. 상기 마커는 OID(Optical IDentification) 마 커, QR 마커 등을 포함할 수 있으며, 특정 패턴을 마커로 설정할 수 있다. 가령, 인식된 책의 책제목, 겉표지 이미지 등을 마커로 설정할 수 있으며, 다양한 마커가 정의될 수 있다. 프로세서는 소정의 이벤트가 발생되면, 촬영 범위에 노출된 오브젝트의 노출 영역 및 촬영 범위에 비노출 된 오브젝트의 비노출 영역에 기초하여 AR 아이템을 디스플레이에 디스플레이할 수 있다. 즉, 프로세서는 오브젝트에 AR 아이템이 매핑되더라도 촬영 범위에 표시되는 노출 영역에 매핑된 AR 아이 템만 디스플레이하고, 촬영 범위에 표시되지 않는 비노출 영역에 매핑된 AR 아이템을 디스플레이하지 않을 수 있다. 프로세서는 촬영 구도 정보, 오브젝트에 관한 정보, 오브젝트에 매핑된 하나 이상의 AR 정보를 학습 모델 에 입력 데이터로 제공하고, 촬영 각도에 따라 오브젝트가 어느 정도 노출되고, 노출되는 영역에 따라 AR 아이템의 표시 유무 정보, AR 아이템이 표시된다면 어느 정도 표시할지 여부에 대한 정보 등을 출력 데이터로 출력할 수 있다. 아울러, 상기 오브젝트와 이에 매핑되는 AR 아이템은 매핑 장치에 의해 매핑되며, 매핑 장치는 카메 라의 촬영 범위 내에 배치된 오브젝트를 인식하고, 인식된 오브젝트에 관한 정보, AR 아이템의 배치 정보 및 AR 아이템에 관한 정보 중 적어도 하나를 매핑 장치의 저장부에 저장할 수 있다. 또한, 매핑 장치는 AR 아이템을 활성화시키는 이벤트 정보를 설정할 수 있다. 구체적으로, 매핑 장치의 프로세서는 촬영 범위 내 에 노출된 오브젝트의 노출 영역 및 촬영 범위에 비노출된 오브젝트의 비노출 영역에 기초하여 AR 아이템을 활 성화시키는 이벤트 정보를 설정할 수 있다. 매핑 장치는 인식된 오브젝트의 형상 정보, 모양 정보, 수용 공간의 포함 유무 정보, 배치 정보 중 적어도 하나를 포함하는 구성 정보에 기초하여, AR 아이템을 상기 오브젝트의 소정 영역에 배치할 수 있다. 상기 매핑 장치의 구성 중에 대부분은 정보 제공 장치와 동일하므로 자세한 설명은 생략하기로 한다. 여기서, 형상 정보는 2차원 및 3차원의 형상을 나타내는 정보를 포함하며, 모양 정보는 소정의 면, 곡면 등에 배치된 모 양을 나타내는 정보를 포함할 수 있다. 상기 정보 제공 장치와 매핑 장치는 공유 프로그램(가령, 앱)을 통해 오브젝트에 관한 정보, AR 아이 템에 관한 정보, 배치에 관한 정보를 공유할 수 있다. 정보 제공 장치의 프로세서는 상술한 소정의 이벤트가 발생되면, 오브젝트의 노출 영역에 제1 AR 아 이템을 디스플레이할 수 있다. 상기 제1 AR 아이템은 오브젝트의 비노출 영역을 노출하기 위한 사용자의 동작을 유도하는 문구 또는 이미지를 포함할 수 있다. 가령, 프로세서는 오브젝트가 돌이고, 돌 아래에 AR 아이템 이 배치된 경우, 돌을 옮기라는 문구 또는 이미지를 상기 제1 AR 아이템에 포함시킬 수 있다. 프로세서는 상기 제1 AR 아이템에 관한 정보, 오브젝트의 비노출 영역에 배치된 물품 정보, 오브젝트의 비 노출 영역에 배치된 AR 아이템에 관한 정보 또는 오브젝트에 관한 정보 중 적어도 하나를 포함하는 제2 AR 아이 템을 소정 영역에 디스플레이할 수 있다. 상기 제2 AR 아이템은 제1 AR 아이템의 주변 영역에 배치될 수 있으나, 실시 예가 이에 국한되는 것은 아니다. 또한, 프로세서는 오브젝트의 구성 정보에 기초하여 AR 아이템을 디스플레이에 표시할 수 있다. 오브 젝트의 구성 정보는 오브젝트의 외관(형상, 모양)에 대한 정보, 오브젝트의 배치, 위치 정보, 및 오브젝트의 수 용 공간 유무에 대한 정보 등을 포함할 수 있다. 또한, 프로세서는 덮개가 덮인 수용 공간에 AR 아이템을 배치할 수 있으며, 덮인 책이 펼쳐진 경우에 책장 사이의 영역에 AR 아이템을 배치할 수 있고, 서랍 칸 속에 AR 배치할 수 있으며, 바닥과 돌 사이의 간격 사이에 AR 아이템을 배치할 수 있으나, 실시 예가 이에 국한되는 것은 아니다. 프로세서는 소정의 이벤트가 발생되면, 오브젝트의 구성 정보에 기초하여 AR 아이템을 표시하며, 소정의 이벤트가 발생되거나 상기 디스플레이 상에 AR 기반 아이템이 디스플레이된 경우, 스피커를 통해 소 정의 사운드를 출력하거나 상기 바이브레이터를 통해 특정 패턴의 진동을 출력할 수 있다. 이하에서는 도 4 내지 도 11을 참고하여 본 발명의 다양한 실시 예에 따른 정보 제공 장치의 구동을 설명 하기로 한다.도 4는 본 발명의 일 실시 예에 따른 AR 아이템이 매핑된 오브젝트의 위치를 지오 펜스 기반으로 표시하는 정보 제공 장치의 구동을 설명하기 위한 도면이다. 여기서, 지오펜스(IGFC, Indoor GeoFenCe)는 실내와 실외를 구분하는 영역으로 지오펜스(IGFC)의 밖 영역은 GPS 정보를 수신할 수 있는 구간이며, 지오펜스(IGFC)의 안 영역은 GPS 정보를 수신할 수 없는 구간이다. 이에, 정 보 제공 장치는 다양한 계측 기술(카메라에 의한 촬영, 근거리 통신 범위 감지, 사운드 인식, 정보 제공 장치의 각종 센싱부를 통한 이동 변위 계산 등)을 이용하여 실내의 AR 아이템에 매핑된 오브젝 트를 인식할 수 있다. 도 4를 참고하면, 정보 제공 장치를 중심(\"A\", 100A)에 두고 거리 순으로 오브젝트(OB4a~OB4c, OB5a~OB5c)를 표시할 수 있다. 정보 제공 장치는 디스플레이된 AR 아이템이 매핑된 오브젝트들(OB4a~OB4c, Ob5a~OB5c)을 검색한 후, 동서남북 방향 정보에 기초하여 사용자(USER)가 상기 오브젝트들(OB4a~OB4c, Ob5a~OB5c)로 이동하도록 가이드할 수 있다. 도 5는 본 발명의 일 실시 예에 따른 수용 공간을 구비하고 AR 아이템에 매핑된 오브젝트를 인식하는 정보 제공 장치의 구동을 설명하기 위한 도면이다. 도 5를 참고하면, 사용자(USER)는 트리거 공간(TAR)의 외부에서 트리거 공간(TAR) 내부로 진입(USER)할 수 있다. 정보 제공 장치는 진입한 트리거 공간(TAR)에 AR 아이템에 매핑되는 오브젝트(OB6a)가 있는 경우, 이를 촬영 오브젝트(OB6b)로 디스플레이에 표시할 수 있다. 선택적 실시 예로 상기 정보 제공 장치는 HMD 로 구현되어 사용자(USER)가 착용하도록 구현될 수 있다. 상기 오브젝트(OB6a)는 내부에 수용 공간을 포함 하는 박스이며, 수용 공간을 개폐하는 개폐부(가령, 덮개)를 포함할 수 있다. 이때, 프로세서는 소정의 상황에 따라 AR 아이템(ARI2~ARI4)을 표시하기 위한 이벤트가 발생된 것으로 결 정할 수 있다. 먼저, 프로세서는 촬영 영상에서 오브젝트의 노출 영역에 대응되는 제1 AR 아이템들(ARI2, ARI3)를 표시할 수 있다. 제1 AR 아이템들(ARI2, ARI3)은 사용자가 직접 오브젝트(OB6a)을 열도록 가이드하는 문구(\"박스를 열면 좋은 일이 있을 거에요\") 및 이미지를 포함할 수 있으며, 디스플레이에서만 촬영 오브 젝트(OB6b)의 개폐부(덮개)를 열도록 가이드(터치 입력 등을 통해)하는 아이템일 수 있다. 여기서, 프로세서는 특정 AR 아이템(ARI2)에 다양한 영상 효과(가령, 진동하는 효과)를 디스플레이에 표시할 수 있다. 실시 예에 따르면, 프로세서는 오브젝트(OB6a)에 포함된 수용 공간의 오픈을 유도하는 AR 아이템들(ARI2, ARI3)에 관한 알림 정보, 수용 공간에 배치된 물품 정보, 수용 공간에 배치된 AR 아이템(ARI4)에 관한 정보 또 는 상기 오브젝트(OB6a)에 관한 정보 중 적어도 하나를 촬영 오브젝트(OB6b)의 인접 영역에 표시할 수 있다. 프로세서는 사용자(USER)가 제2 지점(USER)으로 이동하여 개폐부를 오픈시키고, 카메라를 통해 오 브젝트(OB6a)를 포커싱하면 수용 공간에 배치된 AR 아이템(ARI4)을 표시할 수 있다. 이때, AR 아이템(ARI4)는 붕 떠오르는 것과 같은 효과를 내면서 디스플레이될 수 있다. 도 6 내지 도 8은 본 발명의 다양한 실시 예에 따른 정보 제공 장치의 구동을 나타낸다. 도 6 내지 도 8은 정보 제공 장치가 먼저 트리거 공간(TAR)에 진입한 경우에 노출되는 제1 AR 아이템 및 소정의 조건이 달성 되면 노출되는 제2 AR 아이템을 공통적으로 디스플레이한다. 도 6을 참고하면, 프로세서는 트리거 공간(TAR)에서 수용 공간을 구비한 오브젝트(OB7)를 촬영하면, \"물고 기야 나와라\"라는 사용자 음성 명령을 발하도록 가이드하는 제1 AR 아이템(ARI5)을 디스플레이할 수 있다. 정보 제공 장치는 사용자 음성을 수신하여 기 저장된 사운드와 비교하여 해당 사운드가 입력된 것으로 판 단되면, 그 다음에는 오브젝트의 수용 공간의 내부를 소정만큼 채우는 물을 표시하는 제2 AR 아이템(ARI6a)를 표시하고, 물 속을 유영하는 유영체를 제3 AR 아이템(ARI6b)로 디스플레이할 수 있다. 도 7을 참고하면, 프로세서는 트리거 공간(TAR)에서 비노출 영역(바닥면과 오브젝트 사이의 영역)을 포함 하는 오브젝트(OB8)를 촬영하면, \"이 돌을 들어보세요\"라는 AR 아이템(ARI7)을 디스플레이할 수 있다. 상기 AR 아이템(ARI7)은 상기 오브젝트(OB8)의 비노출 영역을 노출시키기 위한 문구이며, 이미지를 포함할 수 있다. 프로세서는 오브젝트(OB8)와 소정 거리 근접한 사용자의 손(USER(H))이 상기 오브젝트(OB8)를 들어 올리면, 오브젝트(OB8)의 비노출 영역에 AR 아이템(ARI8)을 디스플레이할 수 있다. 도 8을 참고하면, 프로세서는 트리거 공간(TAR)에서 소정의 오브젝트(OB9, 책)를 촬영하는 경우, 오브젝트 (OB9) 테두리에 하이라이트되어 AR 아이템(ARI9a)을 디스플레이될 수 있다. 프로세서는 상기 오브젝트 (OB9)가 펴지면, 오브젝트(OB9)의 비노출 영역에 배치된 AR 아이템(ARI9b)을 디스플레이할 수 있다. 이에 따라, 사용자 친화적인 유저 인터페이스가 제공될 수 있다. 도 9는 본 발명의 일 실시 예에 따른 오브젝트에 소정 거리 근접한 경우, 자동으로 AR 아이템을 디스플레이하는 정보 제공 장치의 구동을 설명하기 위한 도면이며, 사용자의 생활 패턴을 고려해서 사용자의 메모 정보를 포함 하는 AR 아이템을 디스플레이할 수 있다. 여기서, 오브젝트(OB10)는 빨래줄과 같은 줄로 구현될 수 있으나, 실 시 예가 이에 국한되는 것은 아니다. 도 9를 참고하면, 정보 제공 장치는 오브젝트(OB10)를 소정 거리에서 촬영하면 시간 순서 대로 사용자의 메모 정보(시간 정보, 사진 정보 등)를 순차적(좌->우)으로 디스플레이할 수 있다. 정보 제공 장치는 가장 오래된 제1 시점의 사진과 사진을 고정하는 집게를 나타내는 AR 아이템(ARI10)을 디스플레이하고, 제2 시점의 사진과 사진을 고정하는 집게를 나타내는 AR 아이템(ARI11)을 디스플레이하고, 마 지막으로 제3 시점의 사진과 사진을 고정하는 집게를 나타내는 AR 아이템(ARI12)를 순차적으로 나타낼 수 있다. 특히, 정보 제공 장치는 사용자의 이동 순서에 따라 이미 있는 오브젝트에 해당 AR 아이템들(ARI10~12)을 표시할 수 있다. 정보 제공 장치는 사용자의 생활 패턴에 기초하여 사용자의 메모 정보를 포함하는 AR 아이템을 시간 정보, 이동 경로 정보, 장소 정보, 및 사용 빈도수 정보 등을 고려하여 다양하게 디스플레이할 수 있다. 도 10 및 도 11은 본 발명의 다양한 실시 예에 따른 정보 제공 장치의 구동을 나타낸다. 도 10 및 도 11은 정보 제공 장치가 먼저 트리거 공간(TAR)에 진입한 경우에 노출되는 제1 AR 아이템 및 소정의 조건이 달성 되면 노출되는 제2 AR 아이템을 공통적으로 디스플레이한다. 도 10을 참고하면, 프로세서는 트리거 공간(TAR)에서 수용 공간(BB)을 구비한 오브젝트(OB11)를 촬영하면, 제1 AR 아이템(ARI13)을 디스플레이할 수 있다. 상기 제1 AR 아이템(ARI13)은 사용자(USER)로 하여금 서랍을 열 도록 유도하는 AR 아이템에 해당된다. 프로세서는 사용자(USER)가 해당 서랍을 오픈시킨 경우, 내부에 배치된 오브젝트들(OB12)에 대한 정보에 기초하여 채워져야할 오브젝트에 대한 정보를 제2 AR 아이템(ARI14)을 통해 표시할 수 있다. 즉, 프로세서(19 0)는 사용자(USER)가 채워야할 오브젝트들의 개수를 파악하여 사용자(USER)에게 알릴 수 있다. 예를 들면, 프로 세서는 서랍 안에 양말이 12켤레였는데, 6켤레가 사용된 경우, 이를 카운팅할 수 있으며, 필요 사항에 대 해 \"양말 6켤레가 채워져야 합니다\"와 같은 제안 문구를 사용자에게 제공할 수 있다. 이는, 미리 공간 상의 오브젝트들을 모두 파악한 후, 수량의 증감에 따른 관리가 중요한 분야(재고 관리, 물류 관리 등)에 유용하게 적용될 수 있다. 도 11을 참고하면, 프로세서는 트리거 공간(TAR)에서 오브젝트(OB13)를 촬영하면, AR 아이템(ARI15a, ARI16a)을 디스플레이할 수 있다. 상기 AR 아이템(ARI15a, ARI16a)은 사용자(USER)가 오브젝트(OB13)와 먼 거 리에 배치되었을 때, 기 설정된 사운드를 설정된 출력으로 제공하다가, 오브젝트(OB13)에 가까워질수록 상기 사 운드의 출력 세기를 높일 수 있다. 이에, 프로세서는 출력 및 사이즈를 높여서 AR 아이템(ARI15b, ARI16 b)을 제공할 수 있다. 도 12는 본 발명의 일 실시 예에 따른 오브젝트 인식 기반의 정보 제공 방법을 나타내는 시퀀스도이다. 정보 제공 장치는 카메라의 촬영 범위 내에 배치된 오브젝트를 인식한다(S710, \"오브젝트 인식 단 계\"). 그 다음, 정보 제공 장치는 인식된 오브젝트에 대응되는 하나 이상의 AR 아이템을 출력하기 위한 소정의 이벤트 발생을 대기한다(S720, \"이벤트 발생 감지 단계\"). 마지막으로, 정보 제공 장치는 소정의 이벤트가 발생되면, 상기 촬영 범위에 노출된 오브젝트의 노출 영역 및 촬영 범위에 비노출된 오브젝트의 비노출 영역에 기초하여, AR 아이템을 디스플레이한다(S730, \"AR 아이템 디스플레이 단계\"). 여기서, 이벤트 발생 감지 단계(S720)는 AR 아이템을 출력하기 위한 다양한 감지 단계를 포함할 수 있는데, 가 령, 오브젝트의 근거리 통신 커버리지에 정보 제공 장치의 진입 감지 단계, 오브젝트가 속한 소정 범위의 이동 통신 커버리지에 정보 제공 장치의 진입 감지 단계, 기 설정된 사운드 시퀀스의 입력 감지 단계 및오브젝트와 소정 거리 인접한 마커의 감지 단계 중 하나를 포함할 수 있다. 다만, 상기 감지 단계는 상술한 실 시 예에 국한되는 것은 아니다. 상기 AR 아이템 디스플레이 단계(S730)는 소정의 이벤트가 발생되면, 오브젝트의 노출 영역에 제1 AR 아이템을 디스플레이하는 단계를 포함할 수 있다. 상기 제1 AR 아이템을 디스플레이하는 단계는, 오브젝트의 비노출 영역을 노출하기 위한 사용자의 동작을 유도 하는 문구 또는 이미지를 디스플레이하는 단계를 포함할 수 있다. 상기 단계는 제1 AR 아이템에 관한 정보, 비 노출 영역에 배치된 물품 정보, 비노출 영역에 배치된 AR 아이템에 관한 정보 또는 오브젝트에 관한 정보 중 적 어도 하나를 포함하는 제2 AR 아이템을 소정 영역에 디스플레이하는 단계를 포함할 수 있다. 또한, 상기 정보 제공 방법은 소정의 이벤트가 발생되거나 상기 AR 아이템을 디스플레이하는 경우, 소정의 사운 드를 출력하거나 소정 패턴의 진동을 출력할 수 있다. 또한, 상기 정보 제공 방법은 오브젝트에 수용 공간이 배치된 경우, 소정의 이벤트가 발생되면, 오브젝트의 수 용 공간을 오픈하기 위한 제1 AR 아이템을 디스플레이할 수 있다. 여기서, 정보 제공 장치는 제1 AR 아이템을 디스플레이할 때, 제1 AR 아이템에 관한 정보, 상기 수용 공간 에 배치된 물품 정보, 상기 수용 공간에 배치된 AR 아이템에 관한 정보 및 오브젝트에 관한 정보 중 적어도 하 나를 포함하는 제2 AR 아이템을 상기 제1 AR 아이템의 인접 영역에 디스플레이할 수 있다. 또한, 상기 정보 제공 방법은 S730 단계 이전에, 상기 AR 아이템에 포함된 AR 아이템을 상기 오브젝트의 비노출 영역에 배치하는 단계 및 정보 제공 장치가 오브젝트에 소정 거리를 두고 접근하는 경우, 상기 비노출 영역에 배치된 AR 아이템을 노출시키기 위한 문구 또는 이미지를 포함하는 AR 아이템을 디스플레이하는 단계를 더 포함 할 수 있다. 또한, 상기 정보 제공 방법은 오브젝트에 소정 거리로 접근한 경우, 기 설정된 사운드를 출력하고, 오브젝트와 의 거리가 가까워질수록 사운드의 출력 세기를 상승시키는 단계를 더 포함할 수 있다. 한편, 본 발명의 일 실시 예에 따른 소정의 조건에서 활성화되는 하나 이상의 AR 아이템을 오브젝트에 매핑하는 매핑 장치는 카메라를 포함하는 입력부, 저장부 및 프로세서를 포함할 수 있다. 상기 프로세서는, 카메라 의 촬영 범위 내에 배치된 오브젝트를 인식하고, 오브젝트에 관한 정보, AR 아이템의 배치 정보 및 AR 아이템에 관한 정보 중 적어도 하나를 저장부에 저장하며, AR 아이템을 활성화시키는 이벤트 정보를 설정할 수 있다. 상기 매핑 장치는 상기 정보 제공 장치와 동일한 디바이스로 구현될 수 있다. 상기 매핑 장치의 프로세서는 인식된 오브젝트의 형상 정보, 모양 정보, 배치 정보 중 적어도 하나를 포함하는 구성 정보에 기초하여, AR 아이템을 상기 오브젝트의 비노출 영역 또는 노출 영역에 배치할 수 있다. 매핑 장치가 배치한 AR 아이템은 추후에 정보 제공 장치가 오브젝트를 인식하여 AR 아이템을 디스플레이할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한, 상기 컴퓨터는 정보 제공 장치의 프로세서를 포함할 수도 있다. 앞에서, 본 발명의 특정한 실시예가 설명되고 도시되었지만 본 발명은 기재된 실시예에 한정되는 것이 아니고, 이 기술 분야에서 통상의 지식을 가진 자는 본 발명의 사상 및 범위를 벗어나지 않고서 다른 구체적인 실시예로 다양하게 수정 및 변형할 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 범위는 설명된 실시예에 의하여 정하여 질 것이 아니고 청구범위에 기재된 기술적 사상에 의해 정하여져야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2019-0095643", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 5G 네트워크 기반의 정보 제공 클라우드 시스템을 나타낸 개략도, 도 2는 본 발명의 일 실시 예에 따른 증강 현실 아이템을 출력하는 정보 제공 장치의 구동을 설명하기 위한 도 면, 도 3은 본 발명의 일 실시 예에 따른 정보 제공 장치의 구성을 나타내는 블록도, 도 4는 본 발명의 일 실시 예에 따른 AR 아이템이 매핑된 오브젝트의 위치를 지오 펜스 기반으로 표시하는 정보 제공 장치의 구동을 설명하기 위한 도면, 도 5는 본 발명의 일 실시 예에 따른 수용 공간을 구비하고 AR 아이템에 매핑된 오브젝트를 인식하는 정보 제공 장치의 구동을 설명하기 위한 도면, 도 6 내지 도 8은 본 발명의 다양한 실시 예에 따른 정보 제공 장치의 구동을 나타내는 도면들, 도 9는 본 발명의 일 실시 예에 따른 오브젝트에 소정 거리 근접한 경우, 자동으로 AR 아이템을 디스플레이하는 정보 제공 장치의 구동을 설명하기 위한 도면, 도 10 및 도 11은 본 발명의 다양한 실시 예에 따른 정보 제공 장치의 구동을 나타내는 도면들, 그리고, 도 12는 본 발명의 일 실시 예에 따른 정보 제공 장치의 구동 방법을 나타내는 시퀀스도이다."}
