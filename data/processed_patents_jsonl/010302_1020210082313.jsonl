{"patent_id": "10-2021-0082313", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0088461", "출원번호": "10-2021-0082313", "발명의 명칭": "네트워크를 훈련하는 방법, 장치, 기기, 저장매체 및 프로그램", "출원인": "베이징 바이두 넷컴 사이언스 앤 테크놀로지 코.,", "발명자": "첸 리"}}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "네트워크를 훈련하는 방법으로서, 초기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 상기 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 상기 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 상기 도메인은 시나리오 명령 중의 슬롯에 대응되고; 상기 방법은, 목표 음성 샘플의 제1 음성 특징을 획득하는 단계 - 상기 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 상기 합성 음성 샘플에는 샘플 음절 태그 및 상기 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 상기 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부됨 - ; 및 상기 제1 음성 특징을 상기 합성곱층에 입력하고, 상기 합성곱층의 출력 특징을 상기 장단기 기억 네트워크층에입력하고, 상기 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 상기 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크에 입력하고, 상기 제1 음성 특징에 대응되는 시맨틱 태그를 상기 적어도 하나의 디코더네트워크의 출력으로 하고, 상기 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고, 상기 제1 음성 특징에대응되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 하고, 상기 초기의 시맨틱 예측 네트워크와 상기 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻는 단계를 포함하는, 네트워크를 훈련하는 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 초기의 시맨틱 예측 네트워크는 하기 단계인,상기 합성 음성 샘플을 오리지널의 시맨틱 예측 네트워크의 입력으로 하고 상기 합성 음성 샘플에 대응되는 시맨틱 태그를 상기 오리지널의 시맨틱 예측 네트워크의 출력으로 하여 상기 오리지널의 시맨틱 예측 네트워크를훈련시켜 상기 초기의 시맨틱 예측 네트워크를 획득하는 단계에 기반하여 결정되는, 네트워크를 훈련하는 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 초기의 시맨틱 예측 네트워크는 멀티채널 음성강화 네트워크를 더 포함하고; 상기 목표 음성 샘플의 제1 음성 특징을 획득하는 단계는 상기 목표 음성 샘플을 멀티채널 음성강화 네트워크에 입력하여 상기 멀티채널 음성강화 네트워크에서 출력되는목표 음성 샘플의 제1 음성 특징을 획득하는 단계를 포함하는, 네트워크를 훈련하는 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 또는 제2항에 있어서, 상기 인코더 네트워크는 사전훈련된 인코더 네트워크이고; 상기 사전훈련된 인코더 네트워크는 공개특허 10-2021-0088461-3-실제 음성 샘플의 제2 음성 특징을 획득하는 단계; 및 상기 제2 음성 특징에 대한 훈련 단계 - 상기 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 상기 초기의인코더 네트워크에서 출력되는 제2 중간 특징을 획득하는 단계; 상기 제2 중간 특징을 음절 분류 네트워크에 입력하여 상기 음절 분류 네트워크에서 출력되는 예측 음절 태그를 획득하는 단계; 상기 예측 음절 태그와 상기샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되지 않는 것에 응답하여, 상기 초기의 인코더 네트워크의 파라미터를 조정하고 상기 훈련 단계로 점프하여 상기 차이값이 상기 사전설정된 중단조건을 충족시킬때까지 상기 훈련 단계를 수행하여 상기 사전훈련된 인코더 네트워크를 획득하는 단계 - 에 기반하여 사전훈련하여 획득되는, 네트워크를 훈련하는 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 각 디코더 네트워크는 차례로 직렬된 어텐션 메커니즘층, 완전연결층 및 softmax층을 포함하는, 네트워크를 훈련하는 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 음절 분류 네트워크는 완전연결층과 softmax층을 포함하는, 네트워크를 훈련하는 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 합성 음성 샘플은 하기 단계인, 목표 시나리오에 대한 텍스트 표현 및 문장패턴을 획득하는 단계; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴에 대해 음성 합성을 수행하여 목표 시나리오에 대한 음성신호를 획득하는 단계; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키워드에 기반하여 상기 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하는 단계; 상기 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그가 첨부된 상기 목표 시나리오에 대한 음성 신호를 상기 합성 음성 샘플로 적용하는 단계에 기반하여 결정되는, 네트워크를 훈련하는 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "시맨틱 인식 방법으로서, 인식할 음성 신호를 획득하는 단계; 및 상기 인식할 음성 신호를 제1항 내지 제7항 중의 어느 한 항의 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네트워크에 입력하여 상기 인식할 음성 신호의 시맨틱 태그를 획득하는 단계를 포함하는 시맨틱 인식 방법."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "네트워크를 훈련하는 장치로서, 초기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 상기 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 공개특허 10-2021-0088461-4-상기 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 상기 도메인은 시나리오 명령 중의 슬롯에 대응되고; 상기 장치는, 목표 음성 샘플의 제1 음성 특징을 획득하도록 구성되는 샘플 획득 모듈 - 상기 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 상기 합성 음성 샘플에는 샘플 음절 태그 및 상기 도메인의 값이 포함되는 시맨틱태그가 첨부되고, 상기 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부됨 - ; 및 상기 제1 음성 특징을 상기 합성곱층에 입력하고, 상기 합성곱층의 출력 특징을 상기 장단기 기억 네트워크층에입력하고, 상기 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 상기 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크에 입력하고, 상기 제1 음성 특징에 대응되는 시맨틱 태그를 상기 적어도 하나의 디코더네트워크의 출력으로 하고, 상기 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고, 상기 제1 음성 특징에대응되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 하고, 상기 초기의 시맨틱 예측 네트워크와 상기 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻도록 구성되는 공동 훈련 모듈을포함하는, 네트워크를 훈련하는 장치."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 합성 음성 샘플을 오리지널의 시맨틱 예측 네트워크의 입력으로 하고 상기 합성 음성 샘플에 대응되는 시맨틱 태그를 상기 오리지널의 시맨틱 예측 네트워크의 출력으로 하여 상기 오리지널의 시맨틱 예측 네트워크를훈련시켜 상기 초기의 시맨틱 예측 네트워크를 획득하도록 구성되는 시맨틱 훈련 모듈을 더 포함하는, 네트워크를 훈련하는 장치."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항 또는 제10항에 있어서, 상기 초기의 시맨틱 예측 네트워크는 멀티채널 음성강화 네트워크를 더 포함하고; 상기 샘플 획득 모듈은 나아가,상기 목표 음성 샘플을 멀티채널 음성강화 네트워크에 입력하여 멀티채널 음성강화 네트워크에서 출력되는 목표음성 샘플의 제1 음성 특징을 획득하도록 구성되는, 네트워크를 훈련하는 장치."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항 또는 제10항에 있어서,상기 인코더 네트워크는 사전훈련된 인코더 네트워크이고; 상기 장치는, 실제 음성 샘플의 제2 음성 특징을 획득하도록 구성되는 특징 획득 모듈; 및상기 제2 음성 특징에 대한 훈련 단계 - 상기 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 상기 초기의인코더 네트워크에서 출력되는 제2 중간 특징을 획득하는 단계; 상기 제2 중간 특징을 음절 분류 네트워크에 입력하여 상기 음절 분류 네트워크에서 출력되는 예측 음절 태그를 획득하는 단계; 상기 예측 음절 태그와 상기샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되지 않는 것에 응답하여, 상기 초기의 인코더 네트워크의 파라미터를 조정하고 상기 훈련 단계로 점프하여 상기 차이값이 상기 사전설정된 중단조건을 충족시킬때까지 상기 훈련 단계를 수행하여 상기 사전훈련된 인코더 네트워크를 획득하는 단계 - 를 수행하도록 구성되는 사전훈련 모듈을 더 포함하는, 네트워크를 훈련하는 장치. 공개특허 10-2021-0088461-5-청구항 13 제9항에 있어서, 상기 각 디코더 네트워크는 차례로 직렬된 어텐션 메커니즘층, 완전연결층 및 softmax층을 포함하는, 네트워크를 훈련하는 장치."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 음절 분류 네트워크는 완전연결층과 softmax층을 포함하는, 네트워크를 훈련하는 장치."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 상기 장치는, 목표 시나리오에 대한 텍스트 표현 및 문장패턴을 획득하도록 구성되는 텍스트 획득 모듈; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴에 대해 음성 합성을 수행하여 목표 시나리오에 대한 음성신호를 획득하도록 구성되는 합성 음성 모듈; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키워드에 기반하여 상기 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하도록 구성되는 태그 결정 모듈; 및 상기 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그가 첨부된 상기 목표 시나리오에 대한 음성 신호를 상기 합성 음성 샘플로 적용하도록 구성되는 음성 적용 모듈을 더 포함하는, 네트워크를 훈련하는 장치."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "시맨틱 인식 장치로서, 인식할 음성 신호를 획득하도록 구성되는 음성 획득 모듈; 및 상기 인식할 음성 신호를 제1항 내지 제7항 중의 어느 한 항의 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네트워크에 입력하여 상기 인식할 음성 신호의 시맨틱 태그를 획득하도록 구성되는 태그 예측 모듈을 포함하는, 시맨틱 인식 장치."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "칩으로서, 제1항 내지 제7항 중의 어느 한 항의 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네트워크가 구성되어 있는, 칩."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "전자기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신적으로 연결되는 메모리를 포함하고; 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행될 수 있는 명령이 저장되어 있고, 상기 명령은 상기적어도 하나의 프로세서에 의해 실행됨으로써 상기 적어도 하나의 프로세서가 제1항 내지 제7항 중의 어느 한공개특허 10-2021-0088461-6-항의 방법 또는 제8항의 방법을 실행하도록 하는, 전자기기."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제7항 중의 어느 한 항의 방법 또는 제8항의 방법을 수행하도록하는, 비일시적 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2021-0082313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "매체에 저장된 컴퓨터 프로그램으로서, 상기 프로그램이 프로세서에 의해 실행되는 경우, 제1항 내지 제7항 중의 어느 한 항의 방법 또는 제8항의 방법이 수행되는, 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0082313", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시예는 네트워크를 훈련하는 방법, 장치, 기기, 저장매체 및 프로그램을 개시하는바, 딥러닝 및 음 성 분석 등의 인공지능"}
{"patent_id": "10-2021-0082313", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 여기서, 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하 나의 디코더 네트워크를 포함하고, 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 도메인은 시나리오 명령 중의 슬 롯에 대응되며; 구체적인 방안으로는, 목표 음성 샘플의 제1 음성 특징을 획득하되, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 합성 음성 샘플에는 샘플 음절 태그 및 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부되고, 목표 음성 샘플의 제1 음성 특징을 사용하여 초기 의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻는 것이다. 대 표 도 - 도2"}
{"patent_id": "10-2021-0082313", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2021-0088461 CPC특허분류 G06N 3/08 (2013.01) G10L 15/02 (2013.01) G10L 15/063 (2013.01) G10L 15/22 (2013.01) G10L 15/26 (2013.01)명 세 서 청구범위 청구항 1 네트워크를 훈련하는 방법으로서, 초기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 상기 인코더 네 트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 상기 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 상기 도메인은 시 나리오 명령 중의 슬롯에 대응되고; 상기 방법은, 목표 음성 샘플의 제1 음성 특징을 획득하는 단계 - 상기 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘 플이고, 상기 합성 음성 샘플에는 샘플 음절 태그 및 상기 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 상 기 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부됨 - ; 및 상기 제1 음성 특징을 상기 합성곱층에 입력하고, 상기 합성곱층의 출력 특징을 상기 장단기 기억 네트워크층에 입력하고, 상기 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 상기 적어도 하나의 디코더 네트워크 중 의 각 디코더 네트워크에 입력하고, 상기 제1 음성 특징에 대응되는 시맨틱 태그를 상기 적어도 하나의 디코더 네트워크의 출력으로 하고, 상기 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고, 상기 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 하고, 상기 초기의 시맨틱 예측 네트워크와 상기 음 절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻는 단계를 포함하는, 네트워크를 훈련하는 방법. 청구항 2 제1항에 있어서, 상기 초기의 시맨틱 예측 네트워크는 하기 단계인, 상기 합성 음성 샘플을 오리지널의 시맨틱 예측 네트워크의 입력으로 하고 상기 합성 음성 샘플에 대응되는 시 맨틱 태그를 상기 오리지널의 시맨틱 예측 네트워크의 출력으로 하여 상기 오리지널의 시맨틱 예측 네트워크를 훈련시켜 상기 초기의 시맨틱 예측 네트워크를 획득하는 단계에 기반하여 결정되는, 네트워크를 훈련하는 방법. 청구항 3 제1항 또는 제2항에 있어서, 상기 초기의 시맨틱 예측 네트워크는 멀티채널 음성강화 네트워크를 더 포함하고; 상기 목표 음성 샘플의 제1 음성 특징을 획득하는 단계는 상기 목표 음성 샘플을 멀티채널 음성강화 네트워크에 입력하여 상기 멀티채널 음성강화 네트워크에서 출력되는 목표 음성 샘플의 제1 음성 특징을 획득하는 단계를 포함하는, 네트워크를 훈련하는 방법. 청구항 4 제1항 또는 제2항에 있어서, 상기 인코더 네트워크는 사전훈련된 인코더 네트워크이고; 상기 사전훈련된 인코더 네트워크는 실제 음성 샘플의 제2 음성 특징을 획득하는 단계; 및 상기 제2 음성 특징에 대한 훈련 단계 - 상기 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 상기 초기의 인코더 네트워크에서 출력되는 제2 중간 특징을 획득하는 단계; 상기 제2 중간 특징을 음절 분류 네트워크에 입 력하여 상기 음절 분류 네트워크에서 출력되는 예측 음절 태그를 획득하는 단계; 상기 예측 음절 태그와 상기 샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되지 않는 것에 응답하여, 상기 초기의 인코더 네트 워크의 파라미터를 조정하고 상기 훈련 단계로 점프하여 상기 차이값이 상기 사전설정된 중단조건을 충족시킬 때까지 상기 훈련 단계를 수행하여 상기 사전훈련된 인코더 네트워크를 획득하는 단계 - 에 기반하여 사전훈련 하여 획득되는, 네트워크를 훈련하는 방법. 청구항 5 제1항에 있어서, 상기 각 디코더 네트워크는 차례로 직렬된 어텐션 메커니즘층, 완전연결층 및 softmax층을 포함하는, 네트워크를 훈련하는 방법. 청구항 6 제1항에 있어서, 상기 음절 분류 네트워크는 완전연결층과 softmax층을 포함하는, 네트워크를 훈련하는 방법. 청구항 7 제1항에 있어서, 상기 합성 음성 샘플은 하기 단계인, 목표 시나리오에 대한 텍스트 표현 및 문장패턴을 획득하는 단계; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴에 대해 음성 합성을 수행하여 목표 시나리오에 대한 음성 신호를 획득하는 단계; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키워드에 기반하여 상기 목표 시나리오에 대한 음성 신 호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하는 단계; 상기 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그가 첨부된 상 기 목표 시나리오에 대한 음성 신호를 상기 합성 음성 샘플로 적용하는 단계에 기반하여 결정되는, 네트워크를 훈련하는 방법. 청구항 8 시맨틱 인식 방법으로서, 인식할 음성 신호를 획득하는 단계; 및 상기 인식할 음성 신호를 제1항 내지 제7항 중의 어느 한 항의 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네 트워크에 입력하여 상기 인식할 음성 신호의 시맨틱 태그를 획득하는 단계를 포함하는 시맨틱 인식 방법. 청구항 9 네트워크를 훈련하는 장치로서, 초기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 상기 인코더 네 트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 상기 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 상기 도메인은 시 나리오 명령 중의 슬롯에 대응되고; 상기 장치는, 목표 음성 샘플의 제1 음성 특징을 획득하도록 구성되는 샘플 획득 모듈 - 상기 목표 음성 샘플은 합성 음성 샘 플 또는 실제 음성 샘플이고, 상기 합성 음성 샘플에는 샘플 음절 태그 및 상기 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 상기 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부됨 - ; 및 상기 제1 음성 특징을 상기 합성곱층에 입력하고, 상기 합성곱층의 출력 특징을 상기 장단기 기억 네트워크층에 입력하고, 상기 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 상기 적어도 하나의 디코더 네트워크 중 의 각 디코더 네트워크에 입력하고, 상기 제1 음성 특징에 대응되는 시맨틱 태그를 상기 적어도 하나의 디코더 네트워크의 출력으로 하고, 상기 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고, 상기 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 하고, 상기 초기의 시맨틱 예측 네트워크와 상기 음 절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻도록 구성되는 공동 훈련 모듈을 포함하는, 네트워크를 훈련하는 장치. 청구항 10 제9항에 있어서, 상기 합성 음성 샘플을 오리지널의 시맨틱 예측 네트워크의 입력으로 하고 상기 합성 음성 샘플에 대응되는 시 맨틱 태그를 상기 오리지널의 시맨틱 예측 네트워크의 출력으로 하여 상기 오리지널의 시맨틱 예측 네트워크를 훈련시켜 상기 초기의 시맨틱 예측 네트워크를 획득하도록 구성되는 시맨틱 훈련 모듈을 더 포함하는, 네트워크를 훈련하는 장치. 청구항 11 제9항 또는 제10항에 있어서, 상기 초기의 시맨틱 예측 네트워크는 멀티채널 음성강화 네트워크를 더 포함하고; 상기 샘플 획득 모듈은 나아가, 상기 목표 음성 샘플을 멀티채널 음성강화 네트워크에 입력하여 멀티채널 음성강화 네트워크에서 출력되는 목표 음성 샘플의 제1 음성 특징을 획득하도록 구성되는, 네트워크를 훈련하는 장치. 청구항 12 제9항 또는 제10항에 있어서, 상기 인코더 네트워크는 사전훈련된 인코더 네트워크이고; 상기 장치는, 실제 음성 샘플의 제2 음성 특징을 획득하도록 구성되는 특징 획득 모듈; 및 상기 제2 음성 특징에 대한 훈련 단계 - 상기 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 상기 초기의 인코더 네트워크에서 출력되는 제2 중간 특징을 획득하는 단계; 상기 제2 중간 특징을 음절 분류 네트워크에 입 력하여 상기 음절 분류 네트워크에서 출력되는 예측 음절 태그를 획득하는 단계; 상기 예측 음절 태그와 상기 샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되지 않는 것에 응답하여, 상기 초기의 인코더 네트 워크의 파라미터를 조정하고 상기 훈련 단계로 점프하여 상기 차이값이 상기 사전설정된 중단조건을 충족시킬 때까지 상기 훈련 단계를 수행하여 상기 사전훈련된 인코더 네트워크를 획득하는 단계 - 를 수행하도록 구성되 는 사전훈련 모듈을 더 포함하는, 네트워크를 훈련하는 장치. 청구항 13 제9항에 있어서, 상기 각 디코더 네트워크는 차례로 직렬된 어텐션 메커니즘층, 완전연결층 및 softmax층을 포함하는, 네트워크를 훈련하는 장치. 청구항 14 제9항에 있어서, 상기 음절 분류 네트워크는 완전연결층과 softmax층을 포함하는, 네트워크를 훈련하는 장치. 청구항 15 제9항에 있어서, 상기 장치는, 목표 시나리오에 대한 텍스트 표현 및 문장패턴을 획득하도록 구성되는 텍스트 획득 모듈; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴에 대해 음성 합성을 수행하여 목표 시나리오에 대한 음성 신호를 획득하도록 구성되는 합성 음성 모듈; 상기 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키워드에 기반하여 상기 목표 시나리오에 대한 음성 신 호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하도록 구성되는 태그 결정 모듈; 및 상기 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그가 첨부된 상 기 목표 시나리오에 대한 음성 신호를 상기 합성 음성 샘플로 적용하도록 구성되는 음성 적용 모듈을 더 포함하 는, 네트워크를 훈련하는 장치. 청구항 16 시맨틱 인식 장치로서, 인식할 음성 신호를 획득하도록 구성되는 음성 획득 모듈; 및 상기 인식할 음성 신호를 제1항 내지 제7항 중의 어느 한 항의 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네 트워크에 입력하여 상기 인식할 음성 신호의 시맨틱 태그를 획득하도록 구성되는 태그 예측 모듈을 포함하는, 시맨틱 인식 장치. 청구항 17 칩으로서, 제1항 내지 제7항 중의 어느 한 항의 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네트워크가 구성되어 있는, 칩. 청구항 18 전자기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신적으로 연결되는 메모리를 포함하고; 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행될 수 있는 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행됨으로써 상기 적어도 하나의 프로세서가 제1항 내지 제7항 중의 어느 한항의 방법 또는 제8항의 방법을 실행하도록 하는, 전자기기. 청구항 19 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제7항 중의 어느 한 항의 방법 또는 제8항의 방법을 수행하도록 하는, 비일시적 컴퓨터 판독가능 저장매체. 청구항 20 매체에 저장된 컴퓨터 프로그램으로서, 상기 프로그램이 프로세서에 의해 실행되는 경우, 제1항 내지 제7항 중의 어느 한 항의 방법 또는 제8항의 방법 이 수행되는, 매체에 저장된 컴퓨터 프로그램. 발명의 설명 기 술 분 야"}
{"patent_id": "10-2021-0082313", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 3, "content": "본 개시의 실시예는 컴퓨터 기술분야에 관한 것으로, 구체적으로 딥러닝 및 음성 분석 등의 인공지능 기술분야 에 관한 것이고, 특히 네트워크를 훈련하는 방법, 장치, 기기, 저장매체 및 프로그램에 관한 것이다."}
{"patent_id": "10-2021-0082313", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 기술이 성숙함에 따라, 점점 더 많은 가전 기기가 음성 제어를 지원하기 시작하였고, 스마트 홈이 실제로 가정에서 사용되기 시작하였다. 그리고 칩에서의 음성인식 방안은 우리가 직면한 새로운 도전이 되었다. 현재 음성 인식 기술은 기본적으로 전통적인 3단계 캐스케이딩 방안을 기반으로 한다. 즉, 음향 모델, 언어 모 델 및 시맨틱 모델을 다단계로 직렬하여 음성에서 텍스트로, 다시 시맨틱으로의 변환을 구현한다. 그리고 음향 을 텍스트로 변환하는 과정에서 빔 서치(beam search) 또는 가중 유한 상태 변환기(weighted finite-state transducer, WFST) 등의 방식으로 디코딩함으로써 음성 및 언어 정보를 융합하여 음성인식을 구현한다. 본 개시의 실시예는 네트워크를 훈련하는 방법, 장치, 기기, 저장매체 및 프로그램을 제공한다. 제1 측면으로, 본 개시의 실시예는 네트워크를 훈련하는 방법을 제시하는바, 여기서, 초기의 시맨틱 예측 네트 워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응 되고, 도메인은 시나리오 명령 중의 슬롯에 대응되고; 당해 네트워크를 훈련하는 방법은, 목표 음성 샘플의 제1 음성 특징을 획득하는 단계 - 여기서, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 합성 음성 샘플에는 샘플 음절 태그 및 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부됨 - ; 및 제1 음성 특징을 합성곱층에 입력하고, 합성곱층의 출력 특징을 장단기 기억 네트워크층 에 입력하고, 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크에 입력하고, 제1 음성 특징에 대응되는 시맨틱 태그를 적어도 하나의 디코더 네트워크의 출력 으로 하고 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련(joint training)시켜 훈련된 시맨틱 예측 네트워크를 획득하는 단계를 포함한다. 제2 측면으로, 본 개시의 실시예는 시맨틱 인식 방법을 제시하는바, 인식할 음성 신호를 획득하는 단계; 인식할 음성 신호를 제1 측면에 따른 방법으로 훈련한, 훈련된 시맨틱 예측 네트워크에 입력하여 인식할 음성 신호의 시맨틱 태그를 획득하는 단계를 포함한다. 제3 측면으로, 본 개시의 실시예는 네트워크를 훈련하는 장치를 제시하는바, 여기서, 초기의 시맨틱 예측 네트 워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응 되고, 도메인은 시나리오 명령 중의 슬롯에 대응되고; 당해 네트워크를 훈련하는 장치는, 목표 음성 샘플의 제1 음성 특징을 획득하도록 구성되는 샘플 획득 모듈 - 여기서, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 합성 음성 샘플에는 샘플 음절 태그 및 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 실제 시맨 틱 샘플에는 샘플 음절 태그가 첨부됨 - ; 및 제1 음성 특징을 합성곱층에 입력하고, 합성곱층의 출력 특징을 장단기 기억 네트워크층에 입력하고, 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 적어도 하나의 디 코더 네트워크 중의 각 디코더 네트워크에 입력하고, 제1 음성 특징에 대응되는 시맨틱 태그를 적어도 하나의 디코더 네트워크의 출력으로 하고 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고 제1 음성 특징에 대응 되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워 크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻도록 구성되는 공동 훈련 모듈을 포함한다. 제4 측면으로, 본 개시의 실시예는 시맨틱 인식 장치를 제시하는바, 당해 시맨틱 인식 장치는, 인식할 음성 신 호를 획득하도록 구성되는 음성 획득 모듈; 인식할 음성 신호를 제1 측면에 따른 방법으로 훈련한, 훈련된 시맨 틱 예측 네트워크에 입력하여 인식할 음성 신호의 시맨틱 태그를 획득하도록 구성되는 태그 예측 모듈을 포함한 다. 제5 측면으로, 본 개시의 실시예는 칩을 제시하는바, 칩에는 제1 측면에 따른 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네트워크가 구성된다. 제6 측면으로, 본 개시의 실시예는 전자기기를 제시하는바, 적어도 하나의 프로세서; 및 적어도 하나의 프로세 서에 통신적으로 연결되는 메모리를 포함하며, 여기서, 메모리에는 적어도 하나의 프로세서에 의해 실행될 수 있는 명령이 저장되어 있고, 명령은 적어도 하나의 프로세서에 의해 실행됨으로써 적어도 하나의 프로세서가 제 1 측면 또는 제2 측면 중의 어느 한 구현방식에 따른 방법을 수행하도록 한다. 제7 측면으로, 본 개시의 실시예는 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체를 제시하 는바, 컴퓨터 명령은 컴퓨터가 제1 측면 또는 제2 측면 중의 어느 한 구현방식에 따른 방법을 수행하도록 한다. 제8 측면으로, 본 개시의 실시예는 매체에 저장된 컴퓨터 프로그램을 제시하는바, 프로그램이 프로세서에 의해 실행되는 경우, 제1 측면 또는 제2 측면 중의 어느 한 구현방식에 따른 방법이 수행된다. 본 개시의 실시예에 의해 제공되는 네트워크를 훈련하는 방법, 장치, 기기, 저장매체 및 프로그램에 있어서, 초 기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 인코더 네트워크 는 합성곱층과 장단기 기억 네트워크층을 포함하고; 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 도메인은 시나리오 명령 중의 슬롯에 대응되고; 우선, 목표 음성 샘플의 제1 음성 특징을 획득하되, 여기서, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 합성 음성 샘플에는 샘 플 음절 태그 및 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 실제 시맨틱 샘플에는 샘플 음절 태그가 첨 부되고; 그 다음, 제1 음성 특징을 합성곱층에 입력하고, 합성곱층의 출력 특징을 장단기 기억 네트워크층에 입 력하고, 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크에 입력하고, 제1 음성 특징에 대응되는 시맨틱 태그를 적어도 하나의 디코더 네트워크의 출력으로 하 고 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분 류 네트워크의 출력으로 하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨 틱 예측 네트워크를 획득한다. 이러한 과정에서, 배경 기술에서 3단계 캐스케이딩 음성인식 기술을 사용하는 것 과 비하면; 본 출원에서는, 초기의 시맨틱 예측 네트워크의 훈련 과정에서, 인코더 네트워크의 출력 측에 음절 분류 네트워크의 훈련을 추가함으로써 공동 훈련 과정에서, 시맨틱 태그 및 샘플 음절 태그를 각각 초기의 시맨 틱 예측 네트워크의 출력, 음절 분류 네트워크의 출력에 대한 제약으로 사용할 수 있고, 초기의 시맨틱 예측 네 트워크 중의 파라미터를 조정함으로써 인코더에 의해 출력된 중간 특징이 시맨틱 예측 네트워크 및 음절 분류 네트워크의 훈련 정밀도를 충족시킬 수 있는바, 혼합 훈련 샘플을 사용하여 인코더에 의해 출력된 중간 특징의 정확도를 향상시키고, 나아가 최종적으로 획득하는 훈련된 시맨틱 예측 네트워크의 예측 정밀도를 향상시킬 수 있고; 본 출원에서는 음성에 기반하여 음성의 시맨틱 분석이 가능하므로, 배경 기술에서의 음성을 텍스트로 변 환하고 다시 텍스트를 시맨틱 인식하는 경우의 리소스 오버헤드를 감소시킬 수 있으며, 또한 본 출원은 3단계 캐스케이딩 방안 중의 전통적인 음향 디코딩을 배제하였으므로 계산량이 감소된다. 여기서 서술하는 내용은 본 개시의 실시예의 핵심적인 또는 중요한 특징을 짚어내고자 하는 것이 아니며, 본 개 시의 범위를 한정짓고자 하는 것도 아님을 이해하여야 한다. 본 개시의 다른 특징은 아래 발명의 설명으로 이해 하기 수월해질 것이다."}
{"patent_id": "10-2021-0082313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래, 첨부도면을 결부하여 본 개시의 시범적인 실시예를 설명하고자 한다. 여기에는 이해를 돕고자 본 개시의 실시예의 여러 가지 세부사항이 포함되는데, 이러한 것들은 단지 시범적인 것으로 간주되어야 한다. 따라서, 당 업자라면, 여기서 서술하는 실시예는 본 개시의 범위와 사상에 위배되지 않으면서 여러 가지 변경 및 수정이 가 능하다는 점을 인지하여야 한다. 마찬가지로, 명확함과 간결함을 위해, 아래 서술에서는 공지된 기능과 구조에 대한 서술이 생략된다. 부연하면, 상충되지 않는 한, 본 개시의 실시예 및 실시예 중의 특징들은 상호 조합될 수 있다. 아래, 첨부도면 을 참조하고 실시예를 결부하여 본 개시에 대해 상세히 설명하고자 한다. 도 1은 본 개시의 네트워크를 훈련하는 방법 또는 네트워크를 훈련하는 장치 또는 시맨틱 인식 방법 또는 시맨 틱 인식 장치의 실시예가 응용될 수 있는 예시적인 시스템 아키텍처를 도시한다. 도 1에 도시한 바와 같이, 시스템 아키텍처는 클라이언트, 네트워크 및 서버를 포함할 수 있다. 네트워크는 클라이언트와 서버 사이에서 통신 링크를 제공하는 매체로 사용된다. 네트워 크는 여러 가지 연결유형, 예컨대 유선, 무선 통신 링크 또는 광섬유 케이블 등을 포함할 수 있다. 시맨틱 예측 네트워크를 훈련하는 단계에서, 서버는 다양한 서비스를 제공할 수 있는바, 예를 들어 서버 는 클라이언트로부터 목표 음성 샘플을 획득할 수 있고; 목표 음성 샘플을 사용하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻을 수 있다. 훈련된 시맨틱 예측 네트워크를 통해 시맨틱 태그를 예측하는 단계에서, 클라이언트는 인식할 음성 신호를 획득할 수 있고, 클라이언트에 배치된 칩에 의해 훈련된 시맨틱 예측 네트워크를 통해 획득된 인식할 음성 신호에 대해 예측을 수행하여 인식할 음성 신호의 시맨틱 태그를 획득할 수 있고; 또는, 클라이언트는 인식할 음성 신호를 획득할 수 있고, 클라이언트에 배치된 칩에 의해 훈련된 시맨틱 예 측 네트워크를 통해 클라이언트에 의해 획득된 인식할 음성 신호에 대해 예측을 수행하여 인식할 음성 신 호의 시맨틱 태그를 획득할 수 있다. 부연하면, 시맨틱 예측 네트워크를 통해 인식할 음성 신호의 시맨틱 태그를 예측하기 전에, 서버에 의해 훈련된 시맨틱 예측 네트워크를 클라이언트 내의 칩 또는 서버 내의 칩에 배치할 수 있다. 여기서, 당해 칩은 마이크로회로(microcircuit), 마이크로칩(microchip), 집적회로(integrated circuit, IC) 또는 디지 털 신호 처리(digital signal processing, DSP) 칩일 수 있다. 당해 칩은 집적회로가 내장된 웨이퍼를 가리킬 수도 있고, 컴퓨터 또는 다른 전자기기의 일부분일 수 있다. 부연하면, 서버는 하드웨어일 수도 있고 소프트웨어일 수도 있다. 서버가 하드웨어인 경우, 복수의 서버로 구성되는 분산 서버 클러스터로 구현될 수도 있고 하나의 서버로 구현될 수도 있다. 서버가 소프트 웨어인 경우, 복수의 소프트웨어 또는 소프트웨어 모듈(예를 들어 분산 서비스를 제공하는)로 구현될 수도 있고 하나의 소프트웨어 또는 소프트웨어 모듈로 구현될 수도 있다. 이에 대해 구체적으로 한정하지 않는다. 도 1의 클라이언트, 네트워크 및 서버의 수량은 단지 예시적일 뿐임을 이해하여야 한다. 구현의 필요에 따라, 임의 수량의 클라이언트, 네트워크 및 서버가 구비될 수 있다. 계속하여 도 2를 참조하면, 이는 본 개시에 따른 네트워크를 훈련하는 방법의 일 실시예의 흐름을 도시한 다. 여기서, 초기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함할 수 있고, 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함할 수 있고; 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고 도메인은 시나리오 명령 중의 슬롯에 대응된다. 초기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함할 수 있다. 여기서, 당해 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함할 수 있고, 인코더 네트워크의 입력 특징은 인코더 네트워크의 합성곱층의 입력이고, 인코더 네트워크의 합성곱층의 출력 특징은 인코더 네트워크의 장단기 기억 네트워크층의 입력이고, 인코더 네트워크의 장단기 기억 네트워크층의 출력 특징은 적어도 하나의 인코더 네트워크의 입력이다. 목표 음성 샘플의 제1 음성 특징을 합성곱층에 입력하면, 합성곱층에 의해 출력된 음성 특징을 획득할 수 있고; 합성곱층에 의해 출력된 음성 특징을 장단기 기억 네트워크층에 의해 특징 추출하고, 장단기 기억 네트워크층은 과거 추출된 특징을 사용하여 금번에 추출되는 특징을 결정하는 것을 도움으로써, 장단기 기억 네트워크층에 의 해 출력된 중간 특징을 획득하는바, 즉, 사전훈련된 인코더 네트워크에서 출력되는 중간 특징을 획득할 수 있다. 장단기 기억 네트워크층의 수량은 시맨틱 예측 네트워크의 예측 정밀도, 응용 시나리오 및 당업자의 경험 에 의해 결정할 수 있다. 초기의 시맨틱 예측 네트워크의 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는, 종래 기술이나 또 는 미래에 발전될 기술 중의 디코더 네트워크 구조일 수 있다. 각 디코더는 어느 한 특정 시나리오에 관련되는 명령에 대응되는 전체 슬롯 중의 하나의 슬롯을 디코딩한다. 각 디코더 네트워크에 대응되는 도메인은 당해 특 정 시나리오에 관련되는 명령 중의 슬롯에 대응될 수 있다. 적어도 하나의 디코더 네트워크 중의 각 디코더 네 트워크에 의하여 각각 하나의 슬롯을 디코딩하면, 입력 음성에 의해 적중되는 전체 슬롯의 내용을 획득할 수 있 고, 나아가 입력 음성의 시맨틱 태그를 획득할 수 있다. 구체적인 예시에서, 시맨틱 예측 네트워크는 에어컨 제어 시나리오의 시맨틱 인식을 수행한다. 당해 시맨틱 예 측 네트워크는 N개(N의 값은 에어컨 제어 시나리오에 관련되는 제어 명령에 의해 적중되는 시맨틱 슬롯의 수량 값임)의 디코더 네트워크를 포함한다. 에어컨 제어에 대한 시나리오에서, 사용자가 사용하게 될 음성 명령이 \"9 시에 안방의 에어컨을 켜주세요\"인 경우, 당해 음성 명령에 관련되는 모든 슬롯은 \"시간 슬롯\", \"의도 슬롯\", \"위치 슬롯\"이다. N개의 디코더 네트워크 중의 디코더 네트워크A의 도메인은 \"시간 슬롯\"에 대응되고, 당해 디 코더 네트워크A는 \"시간 슬롯\"을 디코딩하여 \"9시에 안방의 에어컨을 켜주세요\"에 의해 적중되는 \"시간 슬롯\"의 내용, 즉 \"9시\"를 적중하고; 적어도 하나의 디코더 네트워크 중의 디코더 네트워크D의 도메인은 \"의도 슬롯\"에 대응되고, 당해 디코더 네트워크D는 \"의도 슬롯\"을 디코딩하여 \"9시에 안방의 에어컨을 켜주세요\"에 의해 적중 되는 \"의도 슬롯\"의 내용, 즉 \"에어컨을 켜\"를 획득하고; 적어도 하나의 디코더 네트워크 중의 디코더 네트워크 H의 도메인은 \"위치 슬롯\"에 대응되고, 당해 디코더 네트워크H는 \"위치 슬롯\"을 디코딩하여 \"9시에 안방의 에어 컨을 켜주세요\"에 의해 적중되는 \"위치 슬롯\"의 내용, 즉 \"안방\"을 적중하고; 디코더 네트워크A의 디코딩 출력, 디코더 네트워크D 및 디코더 네트워크H의 디코딩 출력에 의해, 입력 음성의 시맨틱 태그 \"9시에 안방의 에어컨 을 켜주세요\"를 획득한다. 여기서, 당해 네트워크를 훈련하는 방법은 하기 단계를 포함한다. 단계에서, 목표 음성 샘플의 제1 음성 특징을 획득한다. 본 실시예에서, 네트워크를 훈련하는 방법의 수행 주체(예컨대 도 1에 도시한 바와 같은 서버)는 목표 음 성 샘플의 제1 음성 특징을 획득할 수 있다. 여기서, 목표 음성 샘플은 합성 음성 샘플과 실제 음성 샘플이 포 함되는 목표 음성 샘플 집합 중의 음성 샘플일 수 있는바, 즉, 당해 목표 음성 샘플은 합성 음성 샘플 또는 실 제 음성 샘플일 수 있다. 목표 음성 샘플 집합 중의 목표 음성 샘플에 대하여, 상술한 수행 주체는 목표 음성 샘플을 초기의 시맨틱 예측 네트워크의 음성 샘플에 입력함으로써 합성 음성 샘플 또는 실제 음성 샘플을 초기 의 시맨틱 예측 네트워크에 입력할 수 있다. 대안으로, 목표 음성 샘플의 제1 음성 특징을 획득하는 방법은, 종 래 기술 또는 미래에 발전될 기술 중의 목표 음성 샘플의 제1 음성 특징을 획득하는 방법일 수 있는바, 본 개시 는 이에 대해 한정하지 않는다. 예를 들어, 목표 음성 샘플의 제1 음성 특징을 획득하는 방법은 특징 추출 모듈 또는 네트워크를 가지는 방법에 의해 구현될 수 있다. 당해 제1 음성 특징은 목표 음성 샘플의 음성 특성을 특 성화할 수 있다. 여기서, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 합성 음성 샘플에는 샘플 음절 태그 및 도 메인의 값이 포함되는 시맨틱 태그가 첨부되고, 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부된다. 여기서, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플일 수 있다. 당해 합성 음성 샘플은 종래 기술 또는 미래에 발전될 기술 중의 음성 합성 기술에 기반하여 합성함으로써 결정할 수 있는바, 본 개시는 이에 대 해 한정하지 않는다. 예를 들어, 당해 음성 합성 기술은 엔드 투 엔드 음성 합성 기술(TTS) 또는 전통적인 TTS 일 수 있다. 여기서, 도메인의 값이 포함되는 시맨틱 태그는 합성 음성 샘플의 시맨틱을 레이블링할 수 있다. 당해 시맨틱 태그는 종래 기술 또는 미래에 발전될 기술 중의 시맨틱 태그를 결정하는 방법에 기반하여 결정할 수 있는데, 본 개시는 이에 대해 한정하지 않으며; 예를 들어, 시맨틱 태그를 결정하는 방법은 합성 음성 샘플의 텍스트 표 현 및 문장패턴의 키워드에 의한 방법 또는 수동 레이블링 방법으로 구현할 수 있다. 여기서, 도메인의 값은 슬 롯에 대응되는 내용을 특성화할 수 있다. 예를 들어, \"의도 슬롯\"에 대응되는 내용이 \"에어컨을 켜\"인 경우, 당 해 도메인의 값은 \"에어컨을 켜\"이다. 여기서, 당해 샘플 음절 태그는 합성 음성 샘플의 텍스트 표현 및 문장패턴의 키워드 중의 각 음절을 레이블링 할 수 있고; 합성 음성 샘플에 첨부된 샘플 음절 태그는 종래 기술 또는 발전 기술에서의 합성 음성 샘플에 첨 부된 샘플 음절 태그를 결정하는 방법에 의해 결정될 수 있는바, 예를 들어, 합성 음성 샘플에 첨부된 샘플 음 절 태그를 결정하는 방법은 합성 음성 샘플의 텍스트 표현 및 문장패턴의 키워드에 의한 방법 또는 수동 레이블 링 방법으로 구현할 수 있다. 여기서, 실제 음성 샘플은 처리되지 않은 음성 샘플 및 처리되지 않은 음성 샘플을 인식하여 획득하는 샘플 음 절 태그를 포함할 수 있다. 여기서, 당해 처리되지 않은 음성 샘플은 실제 수집한 음성 샘플일 수 있다. 실제 음성 샘플에 첨부된 샘플 음절 태그는 실제 음성 샘플의 각 음절을 레이블링할 수 있고; 실제 음성 샘플의 샘플 음절 태그는 종래 기술 또는 미래에 발전될 기술에서의 실제 음성 샘플의 샘플 음절 태그를 결정하는 방법으로 결정할 수 있는바, 예를 들어, 음절 태그를 인식하는 음향 모델을 사용하여 실제 음성 샘플을 인식하여 실제 음 성 샘플의 샘플 음절 태그를 획득할 수 있다. 단계에서, 제1 음성 특징을 합성곱층에 입력하고, 합성곱층의 출력 특징을 장단기 기억 네트워크층에 입력 하고, 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크에 입력하고, 제1 음성 특징에 대응되는 시맨틱 태그를 적어도 하나의 디코더 네트워크의 출력으로 하 고 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분 류 네트워크의 출력으로 하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨 틱 예측 네트워크를 획득한다. 본 실시예에서, 상술한 수행 주체는 우선, 제1 음성 특징을 합성곱층에 입력하고 합성곱층의 출력 특징을 장단 기 기억 네트워크층에 입력하여 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 획득할 수 있고, 다음, 상술한 수행 주체는 제1 중간 특징을 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크 및 음절 분류 네 트워크에 각각 입력하고, 제1 음성 특징에 대응되는 시맨틱 태그를 적어도 하나의 디코더 네트워크의 출력으로 하고 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 함으로써, 제1 음성 특징을 사용하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻을 수 있다. 본 개시의 실시예에 의해 제공되는 네트워크를 훈련하는 방법은, 인코더 네트워크의 출력 측에 음절 분류 네트 워크의 훈련을 추가함으로써 공동 훈련 과정에서, 시맨틱 태그 및 샘플 음절 태그를 각각 초기의 시맨틱 예측 네트워크의 출력, 음절 분류 네트워크의 출력에 대한 제약으로 사용할 수 있고, 초기의 시맨틱 예측 네트워크 중의 파라미터를 조정함으로써 인코더에 의해 출력된 중간 특징이 시맨틱 예측 네트워크 및 음절 분류 네트워크 의 훈련 정밀도를 충족시킬 수 있도록 하는바, 혼합 훈련 샘플을 사용하여 인코더에 의해 출력된 중간 특징의 정확도를 향상시키고, 나아가 최종적으로 획득하는 훈련된 시맨틱 예측 네트워크의 예측 정밀도를 향상시킬 수 있고; 본 출원에서는 음성에 기반하여 음성의 시맨틱 분석이 가능하므로, 배경 기술에서의 음성을 텍스트로 변 환하고 다시 텍스트를 시맨틱 인식하는 경우의 리소스 오버헤드를 감소시킬 수 있으며, 또한 본 출원은 3단계 캐스케이딩 방안 중의 전통적인 음향 디코딩을 배제하였으므로 계산량이 감소된다. 여기서, 공동 훈련은 시맨틱 예측 네트워크 훈련 과정에서 음절 분류 네트워크를 훈련시키는 것일 수 있는바, 초기의 시맨틱 예측 네트워크 중의 파라미터 조정을 구현할 수 있다. 구체적인 예시에서, 공동 훈련은 초기의 시맨틱 예측 네트워크의 훈련 과정과 음절 분류 네트워크의 훈련 과정 을 포함할 수 있다. 즉, 초기의 시맨틱 예측 네트워크의 훈련 과정에서, 인코더 네트워크의 출력 측에 음절 분 류 네트워크의 훈련을 추가함으로써 공동 훈련 과정에서, 시맨틱 태그 및 샘플 음절 태그를 각각 초기의 시맨틱 예측 네트워크의 출력, 음절 분류 네트워크의 출력에 대한 제약으로 사용할 수 있고, 초기의 시맨틱 예측 네트 워크 중의 파라미터를 조정함으로써 인코더에 의해 출력된 중간 특징이 시맨틱 예측 네트워크 및 음절 분류 네 트워크의 훈련 정밀도를 충족시킬 수 있도록 하는바, 혼합 훈련 샘플을 사용하여 인코더에 의해 출력된 중간 특 징의 정확도를 향상시키고, 나아가 최종적으로 획득하는 훈련된 시맨틱 예측 네트워크의 예측 정밀도를 향상시 킬 수 있다. 이해의 편의를 위해, 도 3은 공동 훈련의 개략도를 도시한다. 도 3을 참조하면, 당해 공동 훈련의 단계는 하기 단계를 포함할 수 있다. 단계에서, 목표 음성 샘플의 제1 음성 특징을 획득한다. 단계에서, 제1 음성 특징을 초기의 인코더 네트워크에 입력하여 초기의 인코더 네트워크에서 출력되는 제1 중간 특징을 획득하고 제1 중간 특징을 음절 분류 네트워크에 입력하여 음절 분류 네트워크에서 출력되는 예측 음절 태그를 획득한다. 단계에서, 예측 음절 태그와 샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되는지 여부를 판 단한다. 단계에서, 차이값이 사전설정된 중단조건에 부합되지 않는 경우, 초기의 시맨틱 예측 네트워크의 파라미터 를 조정하고 단계 내지 단계를 수행한다. 단계에서, 차이값이 사전설정된 중단조건에 부합되는 경우, 훈련된 시맨틱 예측 네트워크를 획득한다. 부연하면, 초기의 시맨틱 예측 네트워크 훈련 과정의 임의 훈련 단계에서, 인코더 네트워크의 출력 측에 음절 분류 네트워크의 훈련을 추가할 수 있다. 초기의 시맨틱 예측 네트워크 훈련 과정에서, 일반적으로 복수의 목표 음성 샘플을 입력하고, 각 목표 음성 샘플에 대해 단계 내지 단계를 수행하며; 복수의 목표 음성 샘 플에 대응되는 차이값이 사전설정된 중단조건에 부합될 때에만 단계를 수행하여 훈련된 시맨틱 예측 네트 워크를 획득한다. 여기서, 사전설정된 중단조건은 사용자가 시맨틱 예측 네트워크의 예측 정밀도에 대한 요구에 따라 설정할 수 있다. 본 개시의 상술한 실시예에 의해 제공되는 네트워크를 훈련하는 방법은, 초기의 시맨틱 예측 네트워크의 훈련 과정에서, 인코더 네트워크의 출력 측에 음절 분류 네트워크의 훈련을 추가할 수 있는데, 공동 훈련 과정에서, 예측 음절 태그와 샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되는 경우에 초기의 시맨틱 예측 네트워크의 파라미터에 대한 조정을 중지함으로써 인코더에 의해 출력된 중간 특징이 시맨틱 예측 네트워크 및 음절 분류 네트워크의 훈련 정밀도를 충족시킬 수 있게 하는바, 혼합 훈련 샘플을 사용하여 인코더에 의해 출력 된 중간 특징의 정확도를 향상시키고, 나아가 최종적으로 획득되는 훈련된 시맨틱 예측 네트워크의 예측 정밀도 를 향상시킬 수 있다. 본 개시의 일부 대안적인 구현방식에서, 당해 초기의 시맨틱 예측 네트워크는 하기의, 합성 음성 샘플을 오리지 널의 시맨틱 예측 네트워크의 입력으로 하고 합성 음성 샘플에 대응되는 시맨틱 태그를 오리지널의 시맨틱 예측 네트워크의 출력으로 하여 오리지널의 시맨틱 예측 네트워크를 훈련시켜 초기의 시맨틱 예측 네트워크를 획득하는 단계에 기반하여 결정할 수 있다. 본 구현방식에서, 상술한 수행 주체는 우선, 오리지널의 시맨틱 예측 네트워크를 구축하고; 다음, 합성 음성 샘 플을 당해 오리지널의 시맨틱 예측 네트워크에 입력하여 당해 오리지널의 시맨틱 예측 네트워크의 예측 출력을 획득하고; 다음, 당해 오리지널의 시맨틱 예측 네트워크의 예측 출력과 합성 음성 샘플에 대응되는 시맨틱 태그 간의 차이값이 사전설정된 중단조건을 충족시키지 못하는 경우, 당해 오리지널의 시맨틱 예측 네트워크 중의 파 라미터를 조정하고; 이러한 조정을, 합성 음성 샘플을 파라미터가 조정된 시맨틱 예측 네트워크에 입력하여 획 득되는 예측 출력과 합성 음성 샘플에 대응되는 시맨틱 태그 간의 차이값이 사전설정된 중단조건을 충족시킬 때 까지 진행하여 초기의 시맨틱 예측 네트워크를 획득한다. 구체적인 예시에서, 가령 합성 음성 샘플이 i번째 합성 음성 샘플(i는 양의 정수임)인 경우, i번째 합성 음성 샘플을 오리지널의 시맨틱 예측 네트워크에 입력하여 i번째 합성 음성 샘플에 대응되는 예측 출력을 획득하고, i번째 합성 음성 샘플에 대응되는 예측 출력과 i번째 합성 음성 샘플에 대응되는 샘플 음절 태그의 차이값이 사 전설정된 중단조건을 충족시키지 않는 경우, 오리지널의 시맨틱 예측 네트워크 중의 파라미터를 조정하고, 오리 지널의 시맨틱 예측 네트워크 중의 파라미터를 조정한 후마다, 다시 당해 i번째 합성 음성 샘플을 파라미터가 조정된 오리지널 시맨틱 예측 네트워크에 입력하여 예측 출력을 획득하고; 다시 당해 예측 출력과 i번째 합성 음성 샘플에 대응되는 샘플 음절 태그의 차이값을 사전설정된 중단조건과 비교하고; 차이값이 사전설정된 중단 조건을 충족시키는 경우, 오리지널의 시맨틱 예측 네트워크의 파라미터에 대한 조정을 중단하여 파라미터가 조 정된 시맨틱 예측 네트워크i를 획득하고; 이어서, (i+1)번째 합성 음성 샘플을 파라미터가 조정된 시맨틱 예측 네트워크i에 입력하고, (i+1)번째 합성 음성 샘플에 대응되는 예측 출력과 (i+1)번째 합성 음성 샘플에 대응되 는 시맨틱 태그의 차이값이 사전설정된 중단조건을 충족시키는지 여부를 판단다고; 차이값이 사전설정된 중단조 건을 충족시키지 않는 경우, 당해 차이값이 사전설정된 중단조건을 충족시킬 때까지 파라미터가 조정된 시맨틱 예측 네트워크i를 조정하고; …, N번째(N은 1보다 큰 양의 정수임) 합성 음성 샘플을 파라미터가 조정된 시맨틱 예측 네트워크(N-1)에 입력하고, N번째 합성 음성 샘플에 대응되는 예측 출력과 N번째 합성 음성 샘플에 대응되 는 시맨틱 태그의 차이값이 사전설정된 중단조건을 충족시키는지 여부를 판단하고, 차이값이 사전설정된 중단조 건을 충족시키지 않는 경우, 당해 차이값이 사전설정된 중단조건을 충족시킬 때까지 파라미터가 조정된 시맨틱 예측 네트워크(N-1)를 조정하여 초기의 시맨틱 예측 네트워크를 획득한다. 여기서, 오리지널의 시맨틱 예측 네 트워크는 파라미터를 조정하지 않은 시맨틱 예측 네트워크일 수 있다. 본 구현방식에서, 공동 훈련 전에, 합성 음성 샘플과 합성 음성 샘플에 첨부된 시맨틱 태그를 사용하여 오리지 널의 시맨틱 예측 네트워크를 훈련시켜 초기의 시맨틱 예측 네트워크를 결정할 수 있고; 공동 훈련 과정에서, 음절 분류 네트워크를 사용하여 오리지널의 시맨틱 예측 네트워크를 훈련시켜 획득한 초기의 시맨틱 예측 네트 워크에 대해 보조 훈련을 수행할 수 있는바, 따라서 훈련된 시맨틱 예측 네트워크의 예측 정밀도를 향상시킬 수 있다. 본 개시의 일부 대안적인 구현방식에서, 초기의 시맨틱 예측 네트워크는 멀티채널 음성강화 네트워크를 더 포함 할 수 있고; 단계에서의 목표 음성 샘플의 제1 음성 특징을 획득하는 것은, 목표 음성 샘플을 멀티채널 음 성강화 네트워크에 입력하여 멀티채널 음성강화 네트워크에서 출력되는 목표 음성 샘플의 제1 음성 특징을 획득 하는 것을 포함할 수 있다. 본 구현방식에서, 시맨틱 예측 네트워크가 멀티채널 음성강화 네트워크를 더 포함하는 경우, 목표 음성 샘플을 멀티채널 음성강화 네트워크에 입력하여 목표 음성 샘플의 제1 음성 특징을 획득할 수 있다. 상술한 멀티채널 음성강화 네트워크는 목표 음성 샘플의 음성 특징을 수출할 수 있다. 본 구현방식에서의 시맨틱 예측 네트워크는, 멀티채널 음성강화 네트워크 중의 복합 합성곱층을 통해 특징의 추 출을 구현할 수 있고, 복합 완전연결층을 통해 복합 합성곱층에 의해 추출된 특징을 취합하여 목표 음성 샘플 중에서 더더욱 차별성을 가지는 음성 특징을 획득할 수 있고, 나아가 목표 음성 샘플 중의 제1 음성 특징에 대 한 정확한 획득을 구현할 수 있다. 본 개시의 일부 대안적인 구현방식에서, 인코더 네트워크는 사전훈련된 인코더 네트워크이다. 사전훈련된 인코 더 네트워크는, 실제 음성 샘플의 제2 음성 특징을 획득하는 단계; 및 제2 음성 특징에 대한 훈련 단계 - 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 초기의 인코더 네트워크에서 출력되는 제2 중간 특징을 획득하 는 단계; 제2 중간 특징을 음절 분류 네트워크에 입력하여 음절 분류 네트워크에서 출력되는 예측 음절 태그를 획득하는 단계; 예측 음절 태그와 샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되지 않는 것에 응 답하여, 초기의 인코더 네트워크의 파라미터를 조정하고 훈련 단계로 점프하여 차이값이 사전설정된 중단조건을충족시킬 때까지 훈련 단계를 수행하여 사전훈련된 인코더 네트워크를 획득하는 단계 - 에 기반하여 사전훈련하 여 획득된다. 본 구현방식에서, 실제 음성 샘플의 제2 음성 특징을 획득하는 단계는 종래 기술 또는 미래에 발전될 기술 중의 실제 음성 샘플의 제2 음성 특징을 획득하는 단계일 수 있는바, 예를 들어, 특징 추출을 가지는 모듈 또는 네트 워크를 통해 실제 음성 샘플의 제2 음성 특징을 획득한다. 당해 제2 음성 특징은 실제 음성 샘플의 음성 특성을 특성화할 수 있다. 구체적인 예시에서, 가령 실제 음성 샘플의 제2 음성 특징이 j번째 제2 음성 특징(j는 양의 정수임)인 경우, j 번째 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 j번째 제2 음성 특징에 대응되는 예측 출력을 획득하 고, j번째 제2 음성 특징에 대응되는 예측 출력과 j번째 제2 음성 특징에 대응되는 샘플 음절 태그의 차이값이 사전설정된 중단조건을 충족시키지 않는 경우, 초기의 인코더 네트워크 중의 파라미터를 조정하고, 초기의 인코 더 네트워크 중의 파라미터를 조정한 후마다, 다시 당해 j번째 제2 음성 특징을 파라미터가 조정된 인코더 네트 워크에 입력하여 예측 출력을 획득하고; 다시 당해 예측 출력과 j번째 제2 음성 특징에 대응되는 샘플 음절 태 그의 차이값을 j번째 제2 음성 특징에 대응되는 샘플 음절 태그와 비교하고; 차이값이 사전설정된 중단조건을 충족시키는 경우, 초기의 인코더 네트워크 중의 파라미터에 대한 조정을 중단하여 파라미터가 조정된 인코더 네 트워크j를 획득하고; 이어서, (j+1)번째 제2 음성 특징을 파라미터가 조정된 인코더 네트워크j에 입력하고, (j+1)번째 제2 음성 특징에 대응되는 예측 출력과 (j+1)번째 제2 음성 특징에 대응되는 샘플 음절 태그의 차이 값이 사전설정된 중단조건을 충족시키는지 여부를 판단하고, 차이값이 사전설정된 중단조건을 충족시키지 않는 경우, 파라미터가 조정된 인코더 네트워크j 중의 파라미터를 조정하고, 당해 차이값이 사전설정된 중단조건을 충족시키는 경우, 파라미터가 조정된 인코더 네트워크(j+1)를 획득하고; …, M번째(M은 1보다 큰 양의 정수) 제 2 음성 특징을 파라미터가 조정된 인코더 네트워크(M-1)에 입력하고, M번째 제2 음성 특징에 대응되는 예측 출 력과 M번째 제2 음성 특징에 대응되는 샘플 음절 태그의 차이값이 사전설정된 중단조건을 충족시키는지 여부를 판단하고, 차이값이 사전설정된 중단조건을 충족시키지 않는 경우, 당해 차이값이 사전설정된 중단조건을 충족 시킬 때까지 파라미터가 조정된 인코더 네트워크(M-1) 중의 파라미터를 조정하여 사전훈련된 인코더 네트워크를 획득한다. 이해의 편의를 위해, 도 4는 사전훈련된 인코더 네트워크를 훈련하는 흐름도를 도시한다. 도 4에 도시한 바와 같이, 당해 사전훈련된 인코더 네트워크를 훈련하는 단계는 하기 단계를 포함할 수 있다. 단계에서, 실제 음성 샘플의 제2 음성 특징을 획득한다. 단계에서, 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 초기의 인코더 네트워크에서 출력되는 제2 중간 특징을 획득하고; 제2 중간 특징을 음절 분류 네트워크에 입력하여 음절 분류 네트워크에서 출력되는 예측 음절 태그를 획득한다. 단계에서, 예측 음절 태그와 샘플 음절 태그 간의 차이값이 사전설정된 중단조건에 부합되는지 여부를 판 단한다. 단계에서, 차이값이 사전설정된 중단조건에 부합되지 않는 경우, 초기의 인코더 네트워크의 파라미터를 조 정하고, 단계 내지 단계를 수행한다. 단계에서, 차이값이 사전설정된 중단조건에 부합되는 경우, 사전훈련된 인코더 네트워크를 획득한다. 부연하면, 사전훈련 과정에서, 일반적으로 복수의 실제 음성 샘플의 제2 음성 특징을 입력하고, 각 실제 음성 샘플의 제2 음성 특징에 대해 단계 내지 단계를 수행하고, 복수의 실제 음성 샘플의 제2 음성 특징에 대응되는 차이값이 모두 사전설정된 중단조건에 부합될 때에만 단계를 수행하여 사전훈련된 인코더 네트워 크를 획득한다. 본 구현방식에서, 공동 훈련 전에, 인코더 네트워크를 사전훈련하여 인코더 네트워크가 특징을 추출하는 정확률 을 향상시킬 수 있다. 본 개시의 일부 대안적인 구현방식에서, 단계 중의 각 디코더 네트워크는 차례로 직렬된 어텐션 메커니즘 층, 완전연결층 및 softmax층을 포함한다. 본 구현방식에서, 어텐션 메커니즘층은 인코더 네트워크에서 출력되는 중간 특징을 가중하고 차수 감소 처리를 수행하여 어텐션 메커니즘층에 의해 출력된 서로 다른 가중을 가지는 복수의 특징을 획득하고; 서로 다른 가중 의 가지는 복수의 특징은 각각 완전연결층을 거쳐 softmax층에 입력되고, 당해 완전연결층 중의 각 뉴런은 어텐션 메커니즘층의 모든 뉴런에 완전연결되고, 당해 완전연결층은 서로 다른 가중을 가지는 특징을 연결하여 출력 특징을 얻을 수 있고; 다음, softmax층은 당해 출력 특징이 속하는 분류 결과를 출력할 수 있다. 부연하면, 디코더 네트워크 중의 어텐션 메커니즘층 및 디코더 네트워크 중의 어텐션 메커니즘층에 대응되는 가 중은 서로 다를 수 있다. 본 구현방식에서의 적어도 하나의 디코더 네트워크는, 목표 음성 샘플의 제1 음성 특징을 각각 적어도 하나의 디코더 네트워크 중에서 각 디코더 네트워크에 포함되는 어텐션 메커니즘층, 완전연결층을 거쳐 당해 디코더 네 트워크의 softmax층에 입력하여 제1 음성 특징에 대한 정확한 출력(즉 예측 시맨틱 태그)을 구현하고, 예측 시 맨틱 태그와 시맨틱 태그의 차이값을 더 정확하게 할 수 있고, 초기의 시맨틱 예측 네트워크를 훈련하는 과정에 서 당해 차이값에 따라 초기의 시맨틱 예측 네트워크의 파라미터를 정확하게 조정할 수 있는바, 따라서 시맨틱 예측 네트워크의 예측 정밀도를 향상시킨다. 본 개시의 일부 대안적인 구현방식에서, 단계 중의 음절 분류 네트워크는 완전연결층과 softmax층을 포함 할 수 있다. 본 구현방식에서, 당해 음절 분류 네트워크에 포함되는 완전연결층은, 인코더 네트워크에서 출력되는 중간 특징 에서 카테고리 차별성을 가지는 국소 정보를 취합하여, 차별성을 가지는 차별 음성 특징을 획득하고, 나아가 실 제 음성 샘플에 대한 정확한 학습을 구현할 수 있는바, 공동 훈련 과정에서, 당해 음절 분류 네트워크를 통해 초기의 시맨틱 예측 네트워크에 대한 보조 훈련을 수행하여 시맨틱 예측 네트워크의 예측 정밀도를 향상시킬 수 있다. 본 개시의 일부 대안적인 구현방식에서, 단계 중의 합성 음성 샘플은 하기의, 목표 시나리오에 대한 텍스 트 표현 및 문장패턴을 획득하는 단계; 목표 시나리오에 대한 텍스트 표현 및 문장패턴에 대해 음성 합성을 수 행하여 목표 시나리오에 대한 음성 신호를 획득하는 단계; 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키 워드에 기반하여 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하는 단계; 및 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그 가 첨부된 목표 시나리오에 대한 음성 신호를 합성 음성 샘플로 적용하는 단계에 기반하여 획득된다. 본 구현방식에서, 우선, 목표 시나리오에 대한 텍스트 표현 및 문장패턴을 획득하고; 다음, 목표 시나리오에 대 한 텍스트 표현 및 문장패턴에 대해 음성 합성을 수행하여 목표 시나리오에 대한 음성 신호를 획득하고; 그 다 음, 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키워드에 기반하여 목표 시나리오에 대한 음성 신호의 샘 플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하고; 그 다음, 목표 시나리오에 대한 음성 신호 의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그가 첨부된 목표 시나리오에 대한 음성 신호를 합성 음성 샘플로 적용할 수 있다. 여기서, 목표 시나리오에 대한 텍스트 표현 및 문장패턴을 획득하는 과정에서의 목표 시나리오는 예측해야 할 음성의 사용 시나리오일 수 있다. 대안으로, 목표 시나리오에 대한 텍스트 표현 및 문장패턴을 획득하는 단계는 상술한 수행 주체 로컬 또는 원격으로부터 획득하는 것일 수 있다. 목표 시나리오에 대한 텍스트 표현 및 문장 패턴을 음성 합성하면, 목표 시나리오에 대한 음성 신호를 획득할 수 있다. 음성 합성하는 방법은 종래 기술이 나 또는 미래에 발전될 기술을 사용할 수 있는바, 예를 들어 엔드 투 엔드 음성 합성 기술 또는 전통적인 음성 합성 기술을 사용할 수 있다. 본 구현방식에서, 목표 시나리오에 대한 표현과 문장패턴을 합성함으로써 목표 시나리오에 대한 음성 신호를 획 득하고; 다음, 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키워드에 기반하여 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하고; 그 다음, 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그가 첨부된 목표 시나리오에 대한 음성 신 호를 합성 음성 샘플로 적용하는바, 나아가 합성 음성 샘플의 정밀도를 향상시킬 수 있고; 공동 훈련 과정에서, 당해 합성 음성 샘플을 훈련샘플로 하여, 나아가 시맨틱 예측 네트워크의 예측 정밀도를 향상시킬 수 있다. 도 5를 참조하면, 도 5는 본 개시의 실시예에 따른 공동 훈련되는 시맨틱 예측 네트워크와 음절 분류 네트워크 의 예시적인 구조도를 도시한다. 도 5에 도시한 바와 같이, 도 5에는 멀티채널 음성강화 네트워크, 사전훈련된 인코더 네트워크, 디코 더 네트워크 내지 디코더 네트워크(503N), 및 음절 분류 네트워크가 포함된다. 멀티채널 음성강화 네트워크는 복합 합성곱층과 복합 완전연결층을 포함할 수 있다. 복수의 채널의 실제 음성 샘플을 복합 합성곱층이 입력하여 실제 음성 샘플의 음성 특징을 획득하고; 실제 음성 샘플의 음성 특징을 복합 완전연결층에 입력하여 당해 복합 완전연결층 중의 각 뉴런과 복합 합성 곱층의 모든 뉴런을 완전연결하는바, 당해 복합 완전연결층은 복합 합성곱층 중의 카테고리 차별성을 가지는 국소 정보를 취합하여 실제 음성 샘플의 특징을 더 잘 특성화하는 음성 특징을 획득할 수 있다. 인코더 네트워크는 합성곱층, 장단기 기억 네트워크층 및 장단기 기억 네트워크층을 포 함할 수 있다. 목표 음성 샘플의 제1 음성 특징을 합성곱층에 입력하여 합성곱층에 의해 출력된 음 성 특징을 획득할 수 있고; 합성곱층에 의해 출력된 음성 특징을 각각 장단기 기억 네트워크층 및 장단기 기억 네트워크층에 의해 특징할 수 있는바, 여기서, 장단기 기억 네트워크층 및 장단기 기 억 네트워크층은 각각 과거 추출된 특징을 사용하여 금번에 추출되는 특징을 결정하는 것을 도움으로써, 장단기 기억 네트워크층에 의해 출력된 중간 특징을 획득하는바, 즉, 사전훈련된 인코더 네트워크에서 출 력되는 중간 특징을 획득할 수 있다. 부연하면, 장단기 기억 네트워크층의 수량은 시맨틱 예측 네트워크의 예측 정밀도, 응용 시나리오 및 당업자의 경험에 의해 결정할 수 있다. 디코더 네트워크 내지 디코더 네트워크(503N)(N은 양의 정수임) 중의 각 디코더 네트워크에 있어서, 디코 더 네트워크는 어텐션 메커니즘층, 완전연결층 및 softmax층을 포함할 수 있다. 여기서, 어텐션 메커니즘층은 풀링(pooling) 기능을 더 가질 수 있다. 디코더 네트워크(503N)는 어텐션 메커니즘층(503N1), 완전연결층(503N2) 및 softmax층(503N3)을 포함한다. 아래, 디코더 네트워크를 예시한다. 어텐션 메커니즘층은 인코더 네트워크에 의해 출력된 중 간 특징을 가중하고, 차수 감소 처리를 수행하여 어텐션 메커니즘층에 의해 출력된 서로 다른 가중을 가 지는 복수의 특징을 획득하고; 서로 다른 가중을 가지는 복수의 특징은 각각 완전연결층을 거쳐 softmax 층에 입력되고, 당해 완전연결층 중의 각 뉴런은 어텐션 메커니즘층의 모든 뉴런에 완전 연결되고, 당해 완전연결층은 서로 다른 가중을 가지는 복수의 특징을 연결하여 출력 특징을 얻을 수 있 고; 그 다음, softmax층은 당해 출력 특징이 속하는 분류 결과를 출력한다. 부연하면, 디코더 네트워크 중의 어텐션 메커니즘층 및 디코더 네트워크(503N) 중의 어텐션 메커니즘층(503N1)에 대응되는 가중은 다를 수 있다. 음절 분류 네트워크는 완전연결층과 softmax층을 포함할 수 있다. 인코더 네트워크의 출 력 특징을 각각 완전연결층 및 softmax층을 거치도록 하고, 당해 완전연결층 중의 각 뉴런은 인코더 네트워크 중의 장단기 기억 네트워크층의 모든 뉴런에 완전연결되고, 당해 완전연결층(504 1)은 장단기 기억 네트워크층에 의해 출력된 중간 특징 중의 카테고리 차별성을 가지는 국소 정보를 취합 하여 실제 음성 샘플의 특징을 더 잘 특성화할 수 있는 음성 특징을 획득하고; 다음, 당해 softmax층은 실제 음성 샘플의 특징을 더 잘 특성화할 수 있는 소속된 분류 결과를 출력한다. 사전훈련된 인코더 네트워크가 완성된 후, 음절 분류 네트워크 중의 완전연결층 및 softmax층을 제거하고 인코 더 네트워크에 적어도 하나의 디코더 네트워크를 연접하여 초기의 시맨틱 예측 네트워크를 획득한다. 상술한 도 5에 도시한 예시적인 구조도에 따르면, 상술한 실시예 중의 시맨틱 예측 네트워크에 의한 방법을 사 용하여, 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워크를 얻는바, 이러한 정에서, 배경 기술에서 3단계 캐스케이딩 음성인식 기술을 사용하는 것과 비하면; 본 출원에서 는, 초기의 시맨틱 예측 네트워크의 훈련 과정에서, 인코더 네트워크의 출력 측에 음절 분류 네트워크의 훈련을 추가함으로써 공동 훈련 과정에서, 시맨틱 태그 및 샘플 음절 태그를 각각 초기의 시맨틱 예측 네트워크의 출력, 음절 분류 네트워크의 출력에 대한 제약으로 사용할 수 있고, 초기의 시맨틱 예측 네트워크 중의 파라미 터를 조정함으로써 인코더에 의해 출력된 중간 특징이 시맨틱 예측 네트워크 및 음절 분류 네트워크의 훈련 정 밀도를 충족시킬 수 있도록 하는바, 혼합 훈련 샘플을 사용하여 인코더에 의해 출력된 중간 특징의 정확도를 향 상시키고, 나아가 최종적으로 획득하는 훈련된 시맨틱 예측 네트워크의 예측 정밀도를 향상시킬 수 있고; 본 출 원에서는 음성에 기반하여 음성의 시맨틱 분석이 가능하므로, 배경 기술에서의 음성을 텍스트로 변환하고 다시 텍스트를 시맨틱 인식하는 경우의 리소스 오버헤드를 감소시킬 수 있으며, 또한 본 출원은 3단계 캐스케이딩 방 안 중의 전통적인 음향 디코딩을 배제하였으므로 계산량이 감소된다. 나아가 도 6을 참조하면, 이는 시맨틱 인식 방법의 일 실시예의 흐름을 도시한다. 당해 시맨틱 인식 방법 은 하기 단계를 포함한다. 단계에서, 인식할 음성 신호를 획득한다. 본 구현방식에서, 시맨틱 인식 방법의 수행 주체(예를 들어 도 1의 클라이언트 또는 서버) 단계에서, 인식할 음성 신호를 훈련된 시맨틱 예측 네트워크에 입력하여 인식할 음성 신호의 시맨틱 태그 를 획득한다. 본 개시의 상술한 실시예에 의해 제공되는 시맨틱 인식 방법은, 시맨틱 예측 네트워크를 통해 인식할 음성 신호 의 시맨틱 태그에 대한 정확한 결정을 구현할 수 있다. 나아가 도 7을 참조하면, 상술한 각 도면에 도시한 방법에 대한 구현으로, 본 개시는 네트워크를 훈련하는 장치 의 일 실시예를 제공하는바, 당해 장치 실시예는 도 2에 도시한 방법 실시예에 대응되고, 당해 장치는 다양한 전자기기에 구체적으로 적용가능하다. 도 7에 도시한 바와 같이, 초기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 인코더 네트워크는 합성곱층과 장단기 기억 네트워크층을 포함하고; 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 도메인은 시나리오 명령 중의 슬롯에 대응되고; 본 실시 예의 네트워크를 훈련하는 장치는, 목표 음성 샘플의 제1 음성 특징을 획득하도록 구성되는 샘플 획득 모 듈 - 여기서, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 합성 음성 샘플에는 샘플 음절 태그 및 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 실제 시맨틱 샘플에는 샘플 음절 태그가 첨부됨 - ; 및 제1 음성 특징을 합성곱층에 입력하고, 합성곱층의 출력 특징을 장단기 기억 네트워크층에 입력하고, 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크에 입 력하고, 제1 음성 특징에 대응되는 시맨틱 태그를 적어도 하나의 디코더 네트워크의 출력으로 하고 제1 중간 특 징을 음절 분류 네트워크의 입력으로 하고 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분류 네트워크의 출력으로 하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨틱 예측 네트워 크를 얻도록 구성되는 공동 훈련 모듈을 포함할 수 있다. 본 실시예에서, 네트워크를 훈련하는 장치에서 샘플 획득 모듈 및 공동 훈련 모듈의 구체적인 처리 및 이에 따른 기술 효과는 각각 도 2의 대응되는 실시예의 단계 내지 단계에 대한 관련 설명을 참조할 수 있는바, 상세한 설명은 생략하기로 한다. 본 실시예의 일부 대안적인 구현방식에서, 네트워크를 훈련하는 장치는, 합성 음성 샘플을 오리지널의 시 맨틱 예측 네트워크의 입력으로 하고 합성 음성 샘플에 대응되는 시맨틱 태그를 오리지널의 시맨틱 예측 네트워 크의 출력으로 하여 오리지널의 시맨틱 예측 네트워크를 훈련시켜 초기의 시맨틱 예측 네트워크를 획득하도록 구성되는 시맨틱 훈련 모듈(미도시)을 더 포함한다. 본 실시예의 일부 대안적인 구현방식에서, 초기의 시맨틱 예측 네트워크는 멀티채널 음성강화 네트워크를 더 포 함하고; 샘플 획득 모듈은 나아가, 목표 음성 샘플을 멀티채널 음성강화 네트워크에 입력하여 멀티채널 음 성강화 네트워크에서 출력되는 목표 음성 샘플의 제1 음성 특징을 획득하도록 구성된다. 본 실시예의 일부 대안적인 구현방식에서, 인코더 네트워크는 사전훈련된 인코더 네트워크이고, 네트워크를 훈 련하는 장치는, 실제 음성 샘플의 제2 음성 특징을 획득하도록 구성되는 특징 획득 모듈(미도시); 및 제2 음성 특징에 대한 훈련 단계 - 제2 음성 특징을 초기의 인코더 네트워크에 입력하여 초기의 인코더 네트워크에 서 출력되는 제2 중간 특징을 획득하는 단계; 제2 중간 특징을 음절 분류 네트워크에 입력하여 음절 분류 네트 워크에서 출력되는 예측 음절 태그를 획득하는 단계; 예측 음절 태그와 샘플 음절 태그 간의 차이값이 사전설정 된 중단조건에 부합되지 않는 것에 응답하여, 초기의 인코더 네트워크의 파라미터를 조정하고 훈련 단계로 점프 하여 차이값이 사전설정된 중단조건을 충족시킬 때까지 훈련 단계를 수행하여 사전훈련된 인코더 네트워크를 획 득하는 단계 - 를 수행하도록 구성되는 사전훈련 모듈(미도시)을 더 포함한다. 본 실시예의 일부 대안적인 구현방식에서, 각 디코더 네트워크는 차례로 직렬된 어텐션 메커니즘층, 완전연결층 및 softmax층을 포함한다. 본 실시예의 일부 대안적인 구현방식에서, 음절 분류 네트워크는 완전연결층과 softmax층을 포함한다. 본 실시예의 일부 대안적인 구현방식에서, 네트워크를 훈련하는 장치는, 목표 시나리오에 대한 텍스트 표 현 및 문장패턴을 획득하도록 구성되는 텍스트 획득 모듈(미도시); 목표 시나리오에 대한 텍스트 표현 및 문장 패턴에 대해 음성 합성을 수행하여 목표 시나리오에 대한 음성 신호를 획득하도록 구성되는 합성 음성 모듈(미 도시); 목표 시나리오에 대한 텍스트 표현 및 문장패턴의 키워드에 기반하여 목표 시나리오에 대한 음성 신호의샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그를 결정하도록 구성되는 태그 결정 모듈(미도시); 목표 시나리오에 대한 음성 신호의 샘플 음절 태그, 및 도메인의 값이 포함되는 시맨틱 태그가 첨부된 목표 시나리오 에 대한 음성 신호를 합성 음성 샘플로 적용하도록 구성되는 음성 적용 모듈(미도시)을 더 포함한다. 나아가 도 8을 참조하면, 상술한 각 도면에 도시한 방법에 대한 구현으로, 본 개시는 시맨틱 인식 장치의 일 실 시예를 제공하는바, 당해 장치 실시예는 도 6에 도시한 방법 실시예에 대응되고, 당해 장치는 다양한 전자기기 에 구체적으로 적용가능하다. 도 8에 도시한 바와 같이, 본 실시예의 시맨틱 인식 장치는, 인식할 음성 신호를 획득하도록 구성되는 음 성 획득 모듈; 및 인식할 음성 신호를 도 2와 같은 방법을 사용하여 훈련한, 훈련된 시맨틱 예측 네트워크 에 입력하여 인식할 음성 신호의 시맨틱 태그를 획득하도록 구성되는 태그 예측 모듈을 포함할 수 있다. 본 실시예에서, 시맨틱 인식 장치에서, 음성 획득 모듈 및 태그 예측 모듈의 구체적인 처리 및 이에 따른 기술 효과는 각각 도 6에 대응되는 실시예의 단계 내지 단계의 관련 설명을 참조할 수 있 는바, 상세한 설명은 생략하기로 한다. 나아가 도 9를 참조하면, 본 개시는 칩이 설치되는 응용 시나리오의 일 실시예를 제공한다. 도 9에 도시한 바와 같이, 당해 칩이 설치되는 응용 시나리오는 클라이언트 및 클라이언트에 설치되는 칩을 포함할 수 있다. 훈련된 시맨틱 예측 네트워크를 통해 시맨틱 태그를 예측하는 단계에서, 클라이언트는 인식할 음성 신호를 획득할 수 있고, 칩은 훈련된 시맨틱 예측 네트워크를 통해 클라이언트에 의해 획득된 인식할 음성 신호에 대해 예측을 수행하여 인식할 음성 신호의 시맨틱 태그를 획득할 수 있다. 부연하면, 시맨틱 예측 네트워크를 통해 인식할 음성 신호의 시맨틱 태그를 예측하기 전에, 훈련된 시맨틱 예측 네트워크를 칩에 배치할 수도 있다. 대안으로, 서버가 훈련된 시맨틱 예측 네트워크를 칩에 배치하는 방법은 종래 기술이나 또는 미래에 발전될 기술 중의 배치 방법일 수 있다. 본 구현방식에서, 클라이언트에 설치된 칩에 있어서, 칩의 훈련된 시맨틱 예측 네트워크의 예측 정밀도가 보다 높으므로, 오프라인 상태에서 인식할 음성 신호를 인식하는 시맨틱 태그가 인식되는 정확도를 향상시킬 수 있다. 이 외에도, 칩에 배치된 훈련된 시맨틱 예측 네트워크의 용량이 보다 작으므로, 시맨틱 예측의 하드웨어 소모를 감소시킬 수 있고 예측 과정의 리소스 오버헤드를 감소시킬 수 있다. 본 개시의 실시예에 따르면, 본 개시는 전자기기 및 판독가능 저장매체를 더 제공한다. 도 10에 도시한 바로는, 본 개시의 실시예의 방법에 따른 전자기기의 블록도이다. 전자기기는 다양한 형식의 디 지털 컴퓨터, 예컨대, 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크벤치, 개인용 디지털 보조기, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적합한 컴퓨터를 가리킨다. 전자기기는 또한 다양한 형식의 이동 장치, 예컨대, 개인용 디지털 보조기, 셀룰러 폰, 스마트폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치를 가리킬 수 있다. 본 명세서 에서 제시하는 부품, 이들의 연결과 관계 및 이들의 기능은 단지 예시일 뿐, 본 명세서에서 서술한 및/또는 요 구하는 본 개시의 구현을 한정하고자 하는 하는 것이 아니다. 도 10에 도시한 바와 같이, 당해 전자기기는 하나 또는 복수의 프로세서, 메모리 및 각 부품을 연 결하는 인터페이스를 포함하는바, 고속 인터페이스와 저속 인터페이스가 포함된다. 각 부품은 부동한 버스를 이 용하여 서로 연결되고 공용 메인기판에 장착되거나 또는 필요에 따라 다른 방식으로 장착될 수 있다. 프로세서 는 전자 기기 내에서 실행되는 명령을 처리할 수 있는바, 메모리 내에 또는 메모리 위에 저장되어 외부 입력/출 력 장치(예를 들어 인터페이스에 커플링되는 디스플레이 기기)에 그래픽 유저 인터페이스(Graphical User Interface, GUI)의 그래픽 정보를 표시하는 명령이 포함된다. 다른 실시 방식에서, 필요하다면 복수의 프로세서 및/또는 복수의 버스를 복수의 메모리와 함께 사용할 수 있다. 마찬가지로, 복수의 전자 기기를 연결할 수 있는 바, 각 기기는 일부 필요한 동작을 제공한다 - 예를 들어 서버 어레이, 한 그룹의 블레이드 서버 또는 멀티프로 세서 시스템으로서 - . 도 10는 하나의 프로세서를 예시한다. 메모리가 바로 본 개시에 의해 제공되는 비일시적 컴퓨터 판독가능 저장매체이다. 상기 메모리에는 적어 도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있는바, 이는 상기 적어도 하나의 프로세서에 의해 본 개시에 의해 제공되는 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법이 수행되도록 한다. 본 개시의 비일시 적 컴퓨터 판독가능 저장매체는 컴퓨터 명령을 저장하고, 당해 컴퓨터 명령은 컴퓨터에 의해 본 개시에 의해 제 공되는 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법이 수행되도록 한다. 메모리 는 비일시적 컴퓨터 판독 가능 저장 매체로서, 비일시적 소프트웨어 프로그램, 비일시적 컴퓨터 실행 가능 프로그램 및 모듈, 예를 들면 본 개시의 실시예의 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법 에 대응되는 프로그램 명령/모듈을 저장할 수 있는바, 예를 들면, 도 7에 도시한 샘플 획득 모듈 및 공동 훈련 모듈, 또는 첨부도면 8에 도시한 음성 획득 모듈 및 태그 예측 모듈이 있다. 프로세서 는 메모리에 저장되는 비일시적 소프트웨어 프로그램, 명령 및 모듈을 실행함으로써 서버의 다양한 기능 응용 및 데이터 처리를 실행하는바, 즉 상술한 방법 실시예의 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법을 구현한다. 메모리는 프로그램 저장 영역과 데이터 저장 영역을 포함할 수 있는바, 여기서, 프로그램 저장 영역은 운 영 체제, 적어도 하나의 기능에 있어서 필요한 응용 프로그램을 저장할 수 있고, 데이터 저장 영역은 네트워크 를 훈련하는 방법 또는 시맨틱 인식 방법을 구현하는 전자 기기의 사용에 따라 구축되는 데이터 등을 저장할 수 있다. 이 외에도 메모리는 고속 랜덤 액세스 메모리를 포함할 수도 있고, 비일시적 메모리, 예를 들어 적 어도 하나의 자기 디스크 저장 장치, 플래시 메모리 장치 또는 다른 비일시적 고체 상태 저장 장치를 더 포함할 수도 있다. 일부 실시예에서, 메모리는 선택적으로 프로세서 대비 원격 설치되는 메모리를 포함할 수 있고, 이러한 원격 메모리는 네트워크를 통해 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법을 구현하는 전 자 기기에 연결될 수 있다. 상술한 네트워크의 실시예는 인터넷, 기업 내부 네트워크, 근거리 통신망, 이동 통 신 네트워크 및 이들의 조합을 포함하나 이에 한정되지 않는다. 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법을 구현하는 전자기기는 입력 장치와 출력 장치를 더 포함할 수 있다. 프로세서, 메모리, 입력 장치 및 출력 장치는 버스 또는 다른 방 식으로 연결될 수 있는바, 도 10에서는 버스에 의한 연결을 예시한다. 입력 장치는 입력되는 숫자 또는 캐릭터 정보를 수신하고, 본 실시예의 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법을 구현하는 전자 기기의 사용자 설정 및 기능 제어에 관련되는 키 신호 입력을 발생시킬 수 있는바, 예를 들면 터치 스크린, 숫자 키패드, 마우스, 트랙패드, 터치패드, 포인팅 스틱, 하나 또는 복수의 마 우스 버튼, 트랙볼, 조종 스틱 등 입력 장치가 있다. 출력 장치는 디스플레이 기기, 보조 조명장치, 예를 들어 발광 다이오드(Light Emitting Diode, LED; 및 촉각 피드백 장치, 예를 들어 진동 모터; 등을 포함할 수 있다. 당해 디스플레이 기기는 액정 디스플레이(Liquid Crystal Display, LCD), LED 디스플레이 및 플라즈마 디 스플레이를 포함할 수 있으나, 이에 한정되지 않는다. 일부 실시 방식에서 디스플레이 기기는 터치 스크린일 수 있다. 여기서 설명하는 시스템과 기술의 다양한 실시 방식은 디지털 전자 회로 시스템, 집적 회로 시스템, 주문형 집 적회로(Application Specific Integrated Circuit, ASIC), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들 의 조합에서 구현될 수 있다. 이러한 다양한 실시 방식은 하나 또는 복수의 컴퓨터 프로그램에서 실시되는 것을 포함할 수 있고, 당해 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행되거나 및/또는 해석될 수 있고, 당해 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터와 명령을 수신하고, 데이터와 명령을 당해 저장 시스템, 당해 적어도 하나의 입력 장치 및 당해 적어도 하나의 출력 장치로 전송할 수 있다. 이러한 컴퓨팅 프로그램 - 프로그램, 소프트웨어, 소프트웨어 애플리케이션 또는 코드로 지칭되기도 함 - 은 프 로그램 가능 프로세서의 기계 명령을 포함하며, 고급 절차 및/또는 객체지향 프로그래밍 언어, 및/또는 어셈블 리어/기계어를 이용하여, 이러한 컴퓨팅 프로그램을 실시할 수 있다. 본 명세서에서 사용한 바와 같이, 용어 ' 기계 판독 가능 매체'와 '컴퓨터 판독 가능 매체'는 기계 명령 및/또는 데이터를 프로그램 가능 프로세서에 제 공하기 위한 임의의 컴퓨터 프로그램 제품, 기기, 및/또는 장치 - 예를 들어, 자기 디스크, 광 디스크, 메모리, 프로그램 가능 논리 장치(Programmable Logic Device, PLD) - 를 가리키는바, 이는 기계 판독 가능 신호로서의 기계 명령을 수신하는 기계 판독 가능 매체를 포함한다. 용어 '기계 판독 가능 신호'는 기계 명령 및/또는 데이 터를 프로그램 가능 프로세서에 제공하기 위한 임의의 신호를 가리킨다. 사용자와의 인터랙션을 제공하기 위해, 여기서 설명하는 시스템과 기술을 컴퓨터에서 실시할 수 있는바, 당해 컴퓨터는 사용자한테 정보를 표시하기 위한 표시 장치, 예를 들어, 음극선관(Cathode Ray Tube, CRT) 또는 LCD 모니터; 및 키보드와 포인팅 장치, 예를 들어, 마우스 또는 트랙볼;을 포함하고, 사용자는 당해 키보드와 당해 포인팅 장치를 통해 입력을 컴퓨터에 제공할 수 있다. 기타 종류의 장치도 사용자와의 인터랙션을 제공하는 데 사용될 수 있는바, 예를 들어, 사용자한테 제공되는 피드백은 임의 형식의 감각 피드백 - 예를 들어 시각 피드백, 청각 피드백 또는 촉각 피드백 - 일 수 있고, 임의 형식 - 소리 입력, 음성 입력 또는 촉각 입력을 포함함 - 으로 사용자로부터의 입력이 수신될 수 있다. 여기서 설명하는 시스템과 기술을 백그라운드 부품을 포함하는 컴퓨팅 시스템 - 예를 들면 데이터 서버로서 - , 미들웨어를 포함하는 컴퓨팅 시스템 - 예를 들면 애플리케이션 서버 - , 프런트 엔드 부품을 포함하는 컴퓨팅 시스템 - 예를 들면 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터일 수 있는바, 사용자는 당해 그래픽 사용자 인터페이스 또는 당해 네트워크 브라우저를 통하여, 여기서 설명하는 시스템 및 기술의 실시 방식과 인터랙션할 수 있음 - 또는 이러한 백그라운드 부품, 미들웨어 또는 프런트 엔드 부품의 임 의 조합을 포함하는 컴퓨팅 시스템에서 구현할 수 있다. 임의 형식 또는 매체의 디지털 데이터 통신 - 예를 들 면 통신 네트워크 - 으로 시스템의 부품을 서로 연결시킬 수 있다. 통신 네트워크의 예시는 근거리 통신망 (Local Area Network, LAN), 광대역 통신망(Wide Area Network, WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로는 서로 멀리 떨어져 있 고, 통상적으로 통신 네트워크를 통해 인터랙션한다. 상응한 컴퓨터에서 실행되고 서로 클라이언트 - 서버 관계 를 이루는 컴퓨터 프로그램을 통해 클라이언트와 서버의 관계가 발생된다. 본 개시의 실시예에 의해 제공되는 네트워크를 훈련하는 방법, 장치, 기기, 저장매체 및 프로그램에 있어서, 초 기의 시맨틱 예측 네트워크는 인코더 네트워크와 적어도 하나의 디코더 네트워크를 포함하고, 인코더 네트워크 는 합성곱층과 장단기 기억 네트워크층을 포함하고; 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크는 하나의 도메인에 대응되고, 도메인은 시나리오 명령 중의 슬롯에 대응되고; 우선, 목표 음성 샘플의 제1 음성 특징을 획득하되, 여기서, 목표 음성 샘플은 합성 음성 샘플 또는 실제 음성 샘플이고, 합성 음성 샘플에는 샘 플 음절 태그 및 도메인의 값이 포함되는 시맨틱 태그가 첨부되고, 실제 시맨틱 샘플에는 샘플 음절 태그가 첨 부되고; 그 다음, 제1 음성 특징을 합성곱층에 입력하고, 합성곱층의 출력 특징을 장단기 기억 네트워크층에 입 력하고, 장단기 기억 네트워크층에서 출력되는 제1 중간 특징을 적어도 하나의 디코더 네트워크 중의 각 디코더 네트워크에 입력하고, 제1 음성 특징에 대응되는 시맨틱 태그를 적어도 하나의 디코더 네트워크의 출력으로 하 고 제1 중간 특징을 음절 분류 네트워크의 입력으로 하고 제1 음성 특징에 대응되는 샘플 음절 태그를 음절 분 류 네트워크의 출력으로 하여 초기의 시맨틱 예측 네트워크와 음절 분류 네트워크를 공동 훈련시켜 훈련된 시맨 틱 예측 네트워크를 획득한다. 이러한 과정에서, 배경 기술에서 3단계 캐스케이딩 음성인식 기술을 사용하는 것 과 비하면; 본 출원에서는, 초기의 시맨틱 예측 네트워크의 훈련 과정에서, 인코더 네트워크의 출력 측에 음절 분류 네트워크의 훈련을 추가함으로써 공동 훈련 과정에서, 시맨틱 태그 및 샘플 음절 태그를 각각 초기의 시맨 틱 예측 네트워크의 출력, 음절 분류 네트워크의 출력에 대한 제약으로 사용할 수 있고, 초기의 시맨틱 예측 네 트워크 중의 파라미터를 조정함으로써 인코더에 의해 출력된 중간 특징이 시맨틱 예측 네트워크 및 음절 분류 네트워크의 훈련 정밀도를 충족시킬 수 있도록 하는바, 혼합 훈련 샘플을 사용하여 인코더에 의해 출력된 중간 특징의 정확도를 향상시키고, 나아가 최종적으로 획득하는 훈련된 시맨틱 예측 네트워크의 예측 정밀도를 향상 시킬 수 있고; 본 출원에서는 음성에 기반하여 음성의 시맨틱 분석이 가능하므로, 배경 기술에서의 음성을 텍스 트로 변환하고 다시 텍스트를 시맨틱 인식하는 경우의 리소스 오버헤드를 감소시킬 수 있으며, 또한 본 출원은 3단계 캐스케이딩 방안 중의 전통적인 음향 디코딩을 배제하였으므로 계산량이 감소된다. 인공지능은 컴퓨터를 연구하여 인간의 사유 과정 및 지능 행위(예컨대 학습, 추론, 사고, 계획 등)를 시뮬레이 션하는 학과로서, 하드웨어 차원의 기술도 있고 소프트웨어 차원의 기술도 있다. 인공지능 하드웨어 기술은 일 반적으로 센서, 주문형 인공지능 칩, 클라우드 컴퓨팅, 분산 저장, 빅데이터 처리 등의 기술을 포함하고; 인공 지능 소프트웨어 기술은 주로 컴퓨터 비전 기술, 음성인식 기술, 자연 음성 처리 기술 및 머신러닝/딥러닝, 빅 데이터 처리 기술, 지식 그래프 기술 등의 큰 방향을 포함한다. 상술한 다양한 형식의 흐름을 이용하여 단계들을 재배열, 증가 또는 삭제할 수 있음을 이해하여야 한다. 예를 들어, 본 출원에 기재된 각 단계는 병렬도 수행될 수도 있고 순차로 수행될 수도 있고 다른 순서로 수행될 수도 있고, 본 개시에 개시한 기술 방안의 기대 효과를 구현가능할 수만 있다면 되는 것으로, 본 명세서에서는 이에 대하여 한정하지 않는다. 상술한 구체적인 실시방식은, 본 개시의 보호범위를 한정하지 않는다. 설계 요구와 기타 요소에 따른 다양한 수 정, 조합, 서브 조합 및 치환이 가능하다는 점은 당업자에 있어서 자명할 것이다. 본 개시의 사상과 원칙 이내 에 있는 임의의 수정, 등가적 치환 및 개량 등은 모두 본 개시의 보호 범위에 포함되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2021-0082313", "section": "도면", "subsection": "도면설명", "item": 1, "content": "하기 첨부도면을 참조한 비한정적 실시예에 대한 상세한 서술을 읽어보면, 본 개시의 다른 특징, 목적 및 이점 이 더욱 분명해질 것이다. 첨부도면은 본 방안을 더 잘 이해시키기 위한 것으로, 본 개시를 한정하지 않는다. 여기서, 도 1은 본 개시가 응용될 수 있는 예시적인 시스템 아키텍처이고; 도 2는 본 개시에 따른 네트워크를 훈련하는 방법의 일 실시예의 흐름도이고; 도 3은 본 개시에 따른 공동 훈련의 흐름도이고; 도 4는 본 개시에 따른 인코더 네트워크를 사전훈련하는 흐름도이고; 도 5는 본 개시의 실시예에 따른 공동 훈련되는 시맨틱 예측 네트워크와 음절 분류 네트워크의 예시적인 구조도 이고; 도 6은 본 개시에 따른 시맨틱 인식 방법의 일 실시예의 흐름도이고; 도 7은 본 개시에 따른 네트워크를 훈련하는 장치의 일 실시예의 구조 개략도이고; 도 8은 본 개시에 따른 시맨틱 인식 장치의 일 실시예의 구조 개략도이고; 도 9는 칩이 설치되는 응용 시나리오이고; 도 10은 본 개시의 실시예의 네트워크를 훈련하는 방법 또는 시맨틱 인식 방법을 구현하는 전자기기의 블록도이 다."}
