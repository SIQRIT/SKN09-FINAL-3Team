{"patent_id": "10-2024-7000620", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0014575", "출원번호": "10-2024-7000620", "발명의 명칭": "안과용 렌즈들의 이미지들의 획득 및 검사", "출원인": "쿠퍼비젼 인터내셔널 리미티드", "발명자": "요시다 알렉산드라-플로렌티나"}}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "안과용 렌즈들을 검사하고 상기 안과용 렌즈들의 이미지들에 분류를 할당하기 위한 방법으로서,a) 컴퓨터 시스템으로 제1 이미지에 액세스하는 단계 - 상기 제1 이미지는 제1 안과용 렌즈의 렌즈 에지 이미지또는 렌즈 표면 이미지를 포함함 -;b) 상기 컴퓨터 시스템의 하드웨어 프로세서 및 메모리로 구현된 인공 지능(AI) 네트워크로 상기 제1 이미지를처리함으로써 상기 제1 이미지 상의 영역을 식별하여 렌즈 결함을 분석하는 단계;c) 상기 제1 이미지에 기초하여 클래스 활성화 맵(CAM)을 생성하고 결함 영역을 갖는 상기 CAM을 출력하는단계;d) 히트맵 및 경계 상자 중 적어도 하나로 상기 CAM 상의 상기 결함 영역을 라벨링하여 라벨링된 CAM을 정의하는 단계; 및e) 상기 AI 네트워크로 상기 제1 이미지에 대한 분류를 생성하고 출력하여 제1 분류된 이미지를 생성하는 단계를 포함하고, 상기 분류는 상기 결함 영역에 적어도 부분적으로 기초하고, 상기 분류는 복수의 렌즈 표면 결함클래스 중 하나 또는 복수의 렌즈 에지 결함 클래스 중 하나인, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 안과용 렌즈의 제1 이미지는 상기 안과용 렌즈가 건조한 상태로 지지대 상에 위치할 때또는 상기 안과용 렌즈가 젖은 상태로 액체 수조 안에 있을 때 획득되는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 복수의 렌즈 표면 결함 클래스는 적어도 2개의 클래스를 포함하는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 복수의 렌즈 표면 결함 클래스는 적어도 3개의 클래스를 포함하고, 상기 적어도 3개의 클래스는 양호한 렌즈 클래스, 버블 클래스 및 스크래치 클래스를 포함하는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서, 상기 제1 이미지는 제1 카메라에 의해 획득되고, 상기 제1 이미지는높이 픽셀 값 및 폭 픽셀 값을 갖고, 상기 높이 및 폭 픽셀 값들은 상기 제1 카메라에 의해 획득된 템플릿 이미지에 기초하여 크기가 조정되는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제1 이미지에 표현되는 상기 제1 안과용 렌즈는 극좌표계로 표현되는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 극좌표계는 직교 좌표계로부터 변환된, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 제1 이미지는 픽셀 강도들의 제1 세트로부터 반전된 픽셀 강도들의 제2 세트를 갖는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 상기 라벨링된 CAM에 의해 제공된 정보에 기초하여 상기 AI 네트워공개특허 10-2024-0014575-3-크를 재훈련 또는 미세 조정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, (1) 실제 클래스 라벨 예측들이 이루어지는 상기 AI 네트워크의 끝에서 완전 연결된 노드들을제거하는 단계; (2) 완전 연결된 노드들을 새로 초기화된 노드들로 교체하는 단계; (3) 상기 AI 모델에 의해 학습된 임의의 이전의 강건한 특징들이 덮어쓰기 또는 폐기되지 않는 것을 보장하기 위해 상기 AI 네트워크 내의더 이른 또는 최상위 컨볼루션 계층들을 프리징(freezing)하는 단계; (4) 특정 학습률로 완전 연결된 계층들만을 훈련하는 단계; 및 (5) 상기 AI 네트워크 내의 일부 또는 모든 컨볼루션 계층들을 언프리징하고, 상대적으로더 낮은 학습률로 동일하거나 새로운 데이터 세트들로 추가적인 훈련을 수행하는 단계 중 적어도 하나를 수행함으로써 상기 AI 네트워크를 재훈련 또는 미세 조정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서, 상기 제1 이미지는 렌즈 에지 이미지이고, 상기 방법은 상기 컴퓨터 시스템으로 제2 이미지에 액세스하는 단계를 더 포함하고, 상기 제2 이미지는 상기 제1 안과용 렌즈의 렌즈표면 이미지인, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제2 이미지는 제2 카메라에 의해 획득되고, 상기 제2 이미지는 높이 픽셀 값 및 폭 픽셀값을 가지며, 상기 제2 이미지의 높이 및 폭 픽셀 값들은 상기 제2 카메라에 의해 획득된 템플릿 이미지에 기초하여 크기가 조정되는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제12항 중 어느 한 항에 있어서, 렌즈 표면 결함들, 렌즈 에지 결함들, 또는 상기 렌즈 표면 결함들및 렌즈 에지 결함들 모두를 분류하여 상기 렌즈 표면 결함 클래스들, 상기 렌즈 에지 결함 클래스들 또는 이들모두를 생성하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 렌즈를 분류하는 단계는 상기 액세스 단계 전에 수행되는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항 내지 제14항 중 어느 한 항에 있어서, 상기 CAM은 마지막 컨볼루션 계층의 출력에 기초하여 계산되는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 이미지는 전처리된 이미지이고, 상기 CAM은 상기 전처리된 제1 이미지 위에 외삽 및중첩되는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "안과용 렌즈들의 렌즈 이미지들을 분류하기 위한 시스템으로서,적어도 하나의 하드웨어 프로세서;상기 적어도 하나의 하드웨어 프로세서에 의해 실행될 때 상기 적어도 하나의 하드웨어 프로세서로 하여금 단계들을 수행하게 하는 명령어들을 저장한 메모리를 포함하고, 상기 단계들은:a) 상기 메모리로부터 제1 이미지에 액세스하는 단계 - 상기 제1 이미지는 제1 안과용 렌즈의 렌즈 에지 이미지또는 렌즈 표면 이미지를 포함함 -;b) 상기 메모리로부터 훈련된 컨볼루션 신경망(CNN)에 액세스하는 단계 - 상기 훈련된 CNN은 안과용 렌즈들의렌즈 이미지들에 대해 훈련되었고, 상기 안과용 렌즈들 각각은 양호한 렌즈이거나 적어도 하나의 렌즈 결함을공개특허 10-2024-0014575-4-가짐 -;c) 상기 제1 이미지에 기초하여 클래스 활성화 맵(CAM)을 생성하고 결함 영역을 갖는 상기 CAM을 출력하는단계;d) 히트맵 및 경계 상자 중 적어도 하나로 상기 CAM 상의 상기 결함 영역을 라벨링하여 라벨링된 CAM을 정의하는 단계; 및e) 상기 제1 이미지에 대한 분류를 생성하고 출력하는 단계를 포함하고, 상기 분류는 상기 결함 영역에 적어도 부분적으로 기초하고, 상기 분류는 복수의 렌즈 표면 결함클래스 중 하나 또는 복수의 렌즈 에지 결함 클래스 중 하나인, 시스템."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 제1 이미지는 관심 영역 주위의 경계 상자로 라벨링되고, 상기 제1 이미지의 관심 영역주위의 상기 경계 상자는 상기 라벨링된 CAM에 기초하는, 시스템."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "안과용 렌즈들을 검사하고 상기 안과용 렌즈들의 이미지들에 분류를 할당하기 위한 방법으로서,a) 하드웨어 프로세서로 구현된 인공 지능(AI) 네트워크로 제1 이미지를 처리함으로써 상기 제1 이미지 상의 영역을 식별하여 렌즈 결함을 분석하는 단계;b) 상기 제1 이미지에 기초하여 CAM을 생성하고 결함 영역을 갖는 상기 CAM을 출력하는 단계;c) 히트맵 및 경계 상자 중 적어도 하나로 상기 CAM 상의 상기 결함 영역을 라벨링하여 라벨링된 CAM을 정의하는 단계;d) 상기 AI 네트워크로 상기 제1 이미지에 대한 분류를 생성하고 출력하는 단계 - 상기 분류는 상기 결함 영역에 적어도 부분적으로 기초하고, 상기 분류는 복수의 렌즈 표면 결함 클래스 중 하나 또는 복수의 렌즈 에지 결함 클래스 중 하나임 -;e) 상기 하드웨어 프로세서로 구현된 상기 인공 지능(AI) 네트워크로 제2 이미지를 처리함으로써 렌즈 결함을위해 분석할 상기 제2 이미지 상의 영역을 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7000620", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 AI 네트워크는 클라우드에, 상기 제1 이미지와 상기 제2 이미지가 저장된 저장 메모리를갖는 컴퓨터 시스템에, 또는 상기 제1 이미지와 상기 제2 이미지가 저장되지 않은 저장 메모리를 갖는 컴퓨터시스템에 상주하는, 방법."}
{"patent_id": "10-2024-7000620", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "하나 이상의 카메라를 사용하여 안과용 렌즈들의 렌즈 이미지들을 획득하고 검사하여 건조한 상태 또는 젖은 상 태에서 렌즈들의 이미지들을 획득하기 위한 시스템들 및 방법들. 이미지들은 전처리된 후 컨볼루션 신경망(CN N)과 같은 인공 지능 네트워크에 입력되어 렌즈 결함들의 유형에 대해 분석 및 특성화된다. 인공 지능 네트워크 는 이미지들에서 결함 영역들을 식별하고, 결함 영역들에 부분적으로 기초하여 이미지들 각각에 대한 결함 카테 고리들 또는 분류들을 출력한다."}
{"patent_id": "10-2024-7000620", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 렌즈 검사 시스템들에 관한 것으로서, 더 구체적으로는 인공 지능을 사용하여 안과용 렌 즈들의 이미지들을 평가하고 상이한 렌즈 결함 카테고리들 또는 클래스들에 따라 이미지들을 분류하는 렌즈 검 사 시스템들에 관한 것이다."}
{"patent_id": "10-2024-7000620", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기계 학습(ML)과 같은 인공 지능(AI)은 다양한 작업들 및 응용들에 대한 검사 정확도, 이미지 특성화 또는 분류 속도, 및 이미지 해석의 개선에서 상당한 성공을 보였다. 기계 학습은 거의 모든 유형의 산업에서 사용되고 있 다. 기계들이 사람의 작업들의 대부분을 고성능으로 실행할 수 있으므로 사람들이 그들의 업무량을 최소화하는 데 도움이 되고 있다. 기계들은 분류 및 회귀(숫자 값들의 예측)와 같은 예측 분석과, 지능 및 동적 해석을 필 요로 하는 자동차 운전과 같은 작업들을 수행할 수 있다. 기계 학습은 기계에 데이터를 제공하여 기계가 데이터로부터 패턴들을 학습한 후에 유사한 장래의 문제들에 대 한 해결책들을 예측할 수 있게 하는 것을 포함한다. 컴퓨터 비전은 이미지들과 관련된 작업들에 중점을 두는 인공 지능의 분야이다. 컴퓨터 비전과 결합된 심층 학습은 이미지들의 분류로부터 천문학의 과학적 문제들의 해결 및 자율 주행 자동차 제작에 이르는 복잡한 동작들을 수행할 수 있다. 그러나 많은 심층 학습 네트워크는 충분한 정확도로 이미지들을 처리하지 못하거나 고속 대규모 설정에서 신뢰 가 보장되도록 적절한 파라미터들로 훈련되지 못한다. 또 다른 설정들에서, 심층 학습 루틴들은 이미지 내의 영역들을 구분할 만큼 충분히 민감하지 않거나 특정 대규모 제조 동작에서 구현할 적절한 파라미터들로 조정되 지 못할 수 있다. 본 발명의 양태들은 인공 지능(AI) 모델들을 사용하여 하나 이상의 이미지에서 발견된 상이한 결함들을 나타내 는 결함 클래스들을 출력하는 렌즈 검사를 위한 시스템들 및 방법들을 포함한다. 예시적인 실시예들에서, 본 발명의 렌즈 검사 시스템에 의해 검사될 각각의 렌즈 또는 복수의 안과용 또는 콘택트 렌즈에 대한 렌즈 에지 이미지 및 렌즈 표면 이미지가 에지 이미지 데이터 세트들 및 표면 이미지 데이터 세트들로 분리되는 시스템들 및 방법들이 제공된다. 2개의 상이한 데이터 세트는 이미지들 상에서, 존재할 경우, 캡처되는 결함들을 예측한 후에 각각의 결함의 클래스 또는 유형에 기초하여 결함들을 출력하기 위해 2개의 상이한 AI 모델에 의해 처리된 다. 예시적인 실시예들은 콘택트 렌즈 이미지들을 분석하고 분류하기 위해 AI 모델들로서 컨볼루션 신경망(CNN)들을 사용하는 것을 포함한다. 바람직한 CNN 모델들은 렌즈들의 이미지들에 기초하여 렌즈 결함 클래스들을 분석하 고 분류하도록 재훈련될 수 있는 VGG16 Net 및 VGG19 Net 모델들을 포함한다. 렌즈 에지 이미지들을 분석 및 분류하기 위해 \"에지\" AI 모델을 사용하고 렌즈 표면 이미지들을 분석 및 분류하기 위해 \"표면\" AI 모델을 사용 하는 것이 바람직하지만, 본 발명의 양태들은 동일한 이미지 상에서 렌즈 에지와 렌즈 표면 모두에 대한 결함들 을 분석하고 예측하도록 동일한 AI 모델을 훈련하는 것을 고려한다. 예를 들어, 이미징 시스템은 큰 피사계 심 도 및 큰 조리개 또는 큰 f 수를 가질 수 있고, 렌즈 에지와 렌즈 표면 모두에 초점이 맞춰진 이미지를 캡처할 수 있으므로, 단일 AI 모델이 동일한 이미지 내에서 렌즈 에지 결함들, 렌즈 표면 결함들 또는 이 두 가지 결함 유형 모두를 분석하고 예측할 수 있게 한다. 본 발명의 추가 양태는 이미지 템플릿들에 기초하는 입력 준비 이미지들의 준비를 포함한다. 데이터 세트가 일 례로 8개의 카메라에서 촬영한 이미지들을 포함하는 경우, 카메라의 거리와 각각의 카메라의 초점 거리의 변화 들을 고려하기 위해 8개의 이미지 템플릿이 생성될 수 있다. 훈련 이미지들 및 생성 이미지들은 원시 이미지 내에서 렌즈 영역을 찾는 데 사용된 템플릿들에 기초하여 정규화될 수 있는데, 예를 들어 크기가 조정될 수 있 다. 일부 예들에서, 훈련 이미지들 및 생성 이미지들은 템플릿들의 사용 없이 크기가 조정될 수 있다. 본 발명의 또 다른 양태들에서, 상이한 컨볼루션 계층들의 중간 활성화들이 시각화되는데, 예를 들어 클래스 활 성화 맵(CAM)들로 알려진 이미지들로서 출력된다. CAM 이미지는 모델이 모델의 최종 출력에 영향을 미치거나 기여하기 위해 사용한 이미지의 상이한 영역들을 보여준다. 훈련 동안, 트레이너는 CAM들을 사용하여 모델의 성능을 평가하고, 필요한 경우 추가 계층들을 로킹하고 언로킹하며, 추가 훈련 이미지들을 사용하는 것 등과 같 이 모델에 대한 교정들을 행할 수 있다. 생성된 이미지들은 히트맵들로서 제공될 수 있으며, 관심 영역들을 보 다 쉽게 전달하기 위해 경계 상자들로 주석이 첨부될 수 있다. 본 발명의 다른 양태들은 안과용 렌즈들을 검사하고 안과용 렌즈들의 이미지들에 분류를 할당하기 위한 방법을 포함한다. 방법은 a) 컴퓨터 시스템으로 제1 이미지에 액세스하는 단계 - 제1 이미지는 제1 안과용 렌즈의 렌 즈 에지 이미지 또는 렌즈 표면 이미지를 포함함 -; b) 컴퓨터 시스템의 하드웨어 프로세서 및 메모리로 구현된 인공 지능(AI) 네트워크로 제1 이미지를 처리함으로써 적어도 하나의 렌즈 결함을 위해 분석할 제1 이미지 상의 영역을 식별하는 단계; c) 제1 이미지에 기초하여 제1 중간 활성화 이미지를 생성하고 결함 영역을 갖는 제1 중 간 활성화 이미지를 출력하는 단계; d) 히트맵 및 경계 상자 중 적어도 하나로 제1 중간 활성화 이미지 상의 결 함 영역을 라벨링하여 라벨링된 중간 활성화 이미지를 정의하는 단계; 및 e) AI 네트워크로 제1 이미지에 대한 분류를 생성하고 출력하여 제1 분류된 이미지를 생성하는 단계를 포함할 수 있으며, 분류는 결함 영역에 적어도 부분적으로 기초하고, 분류는 복수의 렌즈 표면 결함 클래스 중 하나 또는 복수의 렌즈 에지 결함 클래스 중 하 나이다. 렌즈의 이미지의 결함 영역은 이미지의 나머지 영역들과 별개의 픽셀 강도들을 갖는 이미지 상의 영역에 의해 표현될 수 있다. 결함 영역은 히트 맵 및/또는 경계 상자로 라벨링될 수 있다.AI 네트워크 또는 모델은 이미지 분류를 위한 컨볼루션 신경망(CNN)일 수 있으며, 특히 고려되는 이미지 처리를 위한 다른 심층 신경망들을 갖는 VGG Net, 예를 들어 LeNet, AlexNet, GoogLeNet/Inception, ResNet, ZFNet일 수 있다. 안과용 렌즈의 제1 이미지는 안과용 렌즈가 건조한 상태로 지지대 상에 위치할 때 획득될 수 있다. 일례로, 지 지대는 사파이어 재료로 만들어질 수 있다. 안과용 렌즈의 제1 이미지는 대안적으로 안과용 렌즈가 이송 트레이 또는 블리스터 팩(blister pack)과 같은 액 체 수조에서 젖은 상태로 있을 때 획득될 수 있다. 액체 수조는 식염수일 수 있다. 복수의 렌즈 표면 결함 클래스는 적어도 2개의 클래스, 적어도 3개의 클래스 또는 4개 이상의 클래스를 포함할 수 있다. 다른 예들에서, 클래스들은 양호한 렌즈에 대한 클래스를 포함할 수 있는 적어도 8개의 클래스를 포 함할 수 있다. 표면 모델에 대한 적어도 2개의 클래스는 양호한 렌즈 클래스 및 불량 렌즈를 포함할 수 있다. 적어도 3개의 클래스는 양호한 렌즈 클래스, 버블 클래스, 및 스크래치 클래스를 포함할 수 있다. 렌즈 결함들을 분류하기 위해 8개의 클래스가 이용되는 경우, 이들은 \"브레인들\", \"버블\", \"파편\", \"더티 사파이어\", \"더블 렌즈\", \"양 호한 렌즈\", \"스크래치\", 및 \"보이드\"를 포함할 수 있다. 그러나 표면 모델들은 8개보다 많거나 적은 표면 결 함 유형에 대해 훈련될 수 있다. 예를 들어, 표면 모델들은 렌즈를 갖지 않는 이미지, 핀치드 렌즈(pinched lens)를 갖는 이미지, 너무 작은 렌즈를 갖는 이미지, 너무 큰 렌즈를 갖는 이미지 및/또는 너무 편심인 렌즈를 갖는 이미지로 훈련될 수 있다. 클래스들의 수는 위에 나열한 클래스들의 조합들의 임의의 수를 포함할 수 있 다. AI 네트워크가 출력하는 분류는 텍스트, 숫자 또는 영숫자 식별자일 수 있다. 제1 이미지는 제1 카메라에 의해 획득될 수 있고, 제1 이미지는 높이 픽셀 값 및 폭 픽셀 값을 가지며, 높이 및 폭 픽셀 값들은 제1 카메라에 의해 획득된 템플릿 이미지에 기초하여 크기가 조정된다. 제1 이미지는 픽셀 강도들의 제1 세트로부터 반전된 픽셀 강도들의 제2 세트를 가질 수 있다. 제1 이미지는 2개의 추가적인 동일한 이미지를 가질 수 있으며, 제1 이미지와 2개의 추가적인 동일한 이미지는 3채널 이미지를 정의한다. 제1 이미지는 렌즈 중심을 가질 수 있으며, 렌즈 중심은 제1 이미지의 좌상 코너에 대해 정의될 수 있다. 제1 이미지에 표현되는 제1 안과용 렌즈는 극좌표계 또는 직교 좌표계로 표현될 수 있다. 극좌표계는 직교 좌표계로부터 변환될 수 있다. 제1 이미지는 원본 이미지를 회전시켜 생성될 수 있다. 제1 이미지는 원본 이미지를 뒤집는 것, 원본 이미지를 작은 값만큼 확대 또는 축소하는 것, 원본 이미지의 광 강도를 조정하는 것, 또는 이들의 조합들에 의해 생성될 수 있다. 뒤집기(flipping)는 90도 증분으로 또는 상 이한 각도 회전에 의해 수행될 수 있다. 방법은 라벨링된 중간 활성화 이미지에서 제공하는 정보에 기초하여 AI 네트워크를 재훈련 또는 미세 조정하는 단계를 더 포함할 수 있다. 제1 이미지는 렌즈 에지 이미지일 수 있고, 방법은 컴퓨터 시스템으로 제2 이미지에 액세스하는 단계를 더 포함 할 수 있으며, 제2 이미지는 제1 안과용 렌즈의 렌즈 표면 이미지일 수 있다. 제2 이미지는 제2 카메라에 의해 획득될 수 있고, 제2 이미지는 높이 픽셀 값 및 폭 픽셀 값을 가질 수 있으며, 제2 이미지의 높이 및 폭 픽셀 값들은 제2 카메라에 의해 획득된 템플릿 이미지에 기초하여 크기가 조정될 수 있다. 제2 이미지는 2개의 추가적인 동일한 이미지를 가질 수 있으며, 제2 이미지와 2개의 추가적인 동일한 이미지는 3채널 이미지를 정의한다. 제2 이미지는 픽셀 강도들의 제1 세트로부터 반전된 픽셀 강도들의 제2 세트를 가질 수 있다. 방법은 제2 이미지에 기초하여 제2 중간 활성화 이미지를 생성하고, 결함 영역을 갖는 제2 중간 활성화 이미지 를 출력하는 단계를 더 포함할 수 있다. 방법은 히트맵 및 경계 상자 중 적어도 하나로 제2 중간 활성화 이미지 상의 결함 영역을 라벨링하여 제2 라벨 링된 중간 활성화 이미지를 정의하는 단계를 더 포함할 수 있다. 일부 예들에서, 분석 또는 훈련될 복수의 이 미지 각각에 대해, 원본 이미지 상의 결함 영역은 예를 들어 경계 상자로 또는 결함 영역의 윤곽을 강조함으로 써 라벨링된다. 라벨링된 원본 이미지는 훈련, 디스플레이, 마케팅 등을 위해 사용될 수 있다. 제2 라벨링된 중간 활성화 이미지는 AI 네트워크를 재훈련 또는 미세 조정하는 데 사용될 수 있다. 방법은 AI 네트워크로 제2 이미지에 대한 분류를 생성하고 출력하는 단계를 더 포함할 수 있으며, 분류는 결함 영역에 적어도 부분적으로 기초하고, 분류는 복수의 렌즈 표면 결함 클래스 중 하나이다. 일부 실시예들에서, 복수의 렌즈 에지 결함 클래스는 적어도 2개의 클래스, 적어도 3개의 클래스, 또는 4개 이 상의 클래스를 포함할 수 있다. 다른 예들에서, 클래스들은 양호한 렌즈에 대한 클래스를 포함할 수 있는 적어 도 8개의 클래스를 포함할 수 있다. 방법은 제1 분류된 이미지에 대한 분류를, 수동으로 검사되고 실측 자료(ground truth)로서 식별되었고 제1 분 류된 이미지가 생성된 제1 이미지의 전처리된 이미지 또는 원본 이미지와 비교하는 단계를 더 포함할 수 있다. 제1 이미지의 전처리된 이미지 또는 원본 이미지의 수동 검사는 복수의 렌즈 표면 결함 클래스 중 하나, 복수의 렌즈 에지 결함 클래스 중 하나, 또는 렌즈 표면 결함 및 렌즈 에지 결함 클래스들 모두로 분류된다. 에지 모델에 대한 적어도 2개의 클래스는 양호한 렌즈 클래스 및 불량 렌즈를 포함할 수 있다. 에지 모델에 대 한 적어도 3개의 클래스는 양호한 렌즈 클래스, 버블 클래스, 및 스크래치 클래스를 포함할 수 있다. 추가 클 래스들 또는 4개 이상의 에지 클래스가 실시되는 경우, 에지 모델들은 렌즈를 갖지 않는 이미지, 분할된 에지를 갖는 이미지, 핀치드 렌즈를 갖는 이미지, 에지 칩을 갖는 이미지, 너무 작은 렌즈를 갖는 이미지, 너무 큰 렌 즈를 갖는 이미지 및/또는 너무 편심인 렌즈를 갖는 이미지로 훈련될 수 있다. 클래스들의 수는 위에 나열한 클래스들의 조합들의 임의의 수를 포함할 수 있다. 본 발명의 더 추가적인 양태는 안과용 렌즈들의 렌즈 이미지들을 분류하기 위한 시스템을 포함한다. 안과용 렌 즈들의 렌즈 이미지들을 분류하기 위한 시스템은 적어도 하나의 하드웨어 프로세서; 적어도 하나의 하드웨어 프 로세서에 의해 실행될 때 적어도 하나의 하드웨어 프로세서로 하여금 단계들을 수행하게 하는 명령어들을 저장 한 메모리를 포함할 수 있으며, 단계들은 a) 메모리로부터 제1 이미지에 액세스하는 단계 - 제1 이미지는 제1 안과용 렌즈의 렌즈 에지 이미지 또는 렌즈 표면 이미지를 포함함 -; b) 메모리로부터 훈련된 컨볼루션 신경망 (CNN)에 액세스하는 단계 - 훈련된 CNN은 안과용 렌즈들의 렌즈 이미지들에 대해 훈련되었고, 안과용 렌즈들 각 각은 양호한 렌즈이거나 적어도 하나의 렌즈 결함을 가짐 -; c) 제1 이미지에 기초하여 중간 활성화 이미지를 생성하고 결함 영역을 갖는 중간 활성화 이미지를 출력하는 단계; d) 히트맵 및 경계 상자 중 적어도 하나로 중 간 활성화 이미지 상의 결함 영역을 라벨링하여 라벨링된 중간 활성화 이미지를 정의하는 단계; 및 e) 제1 이미 지에 대한 분류를 생성하고 출력하는 단계를 포함하고, 분류는 결함 영역에 적어도 부분적으로 기초하고, 분류 는 복수의 렌즈 표면 결함 클래스 중 하나 또는 복수의 렌즈 에지 결함 클래스 중 하나이다. 중간 활성화 이미지 또는 CAM은 CNN 모델의 마지막 컨볼루션 계층의 출력으로부터 취해질 수 있다. 중간 활성 화 이미지는 중간 활성화 이미지의 결함 영역을 라벨링하기 전에 제1 이미지 상에 중첩될 수 있다. 일례로, 중 간 활성화 이미지는 클래스 활성화 맵 또는 CAM으로 지칭될 수 있는 마지막 컨볼루션 계층의 출력으로서 생성된 마지막 중간 이미지이다. 본 발명의 추가 양태는 안과용 렌즈들을 검사하고 안과용 렌즈들의 이미지들에 분류를 할당하기 위한 방법을 포 함하며, 방법은 a) 컴퓨터 시스템으로 제1 이미지에 액세스하는 단계 - 제1 이미지는 제1 안과용 렌즈의 렌즈 에지 이미지 또는 렌즈 표면 이미지를 포함함 -; b) 컴퓨터 시스템의 하드웨어 프로세서 및 메모리로 구현된 인 공 지능(AI) 네트워크로 제1 이미지를 처리함으로써 렌즈 결함을 위해 분석할 제1 이미지 상의 영역을 식별하는 단계; c) 제1 이미지에 기초하여 클래스 활성화 맵(CAM)을 생성하고 결함 영역을 갖는 CAM을 출력하는 단계; d) 히트맵 및 경계 상자 중 적어도 하나로 CAM 상의 결함 영역을 라벨링하여 라벨링된 CAM을 정의하는 단계; 및 e) AI 네트워크로 제1 이미지에 대한 분류를 생성하고 출력하여 제1 분류된 이미지를 생성하는 단계를 포함하고, 분류는 결함 영역에 적어도 부분적으로 기초하고, 분류는 복수의 렌즈 표면 결함 클래스 중 하나 또는 복수의 렌즈 에지 결함 클래스 중 하나이다. 안과용 렌즈의 제1 이미지는 안과용 렌즈가 건조한 상태로 지지대 상에 위치할 때 획득될 수 있다. 안과용 렌즈의 제1 이미지는 안과용 렌즈가 젖은 상태로 액체 수조 안에 있을 때 획득될 수 있다. 복수의 렌즈 표면 결함 클래스는 적어도 2개의 클래스를 포함할 수 있다. 복수의 렌즈 표면 결함 클래스는 적어도 3개의 클래스를 포함할 수 있고, 적어도 3개의 클래스는 양호한 렌즈 클래스, 버블 클래스 및 스크래치 클래스를 포함할 수 있다. AI 네트워크가 출력하는 분류는 텍스트, 숫자 또는 영숫자 식별자를 포함할 수 있다. 제1 이미지는 제1 카메라에 의해 획득될 수 있고, 제1 이미지는 높이 픽셀 값 및 폭 픽셀 값을 가질 수 있으며, 높이 및 폭 픽셀 값들은 제1 카메라에 의해 획득된 템플릿 이미지에 기초하여 크기가 조정될 수 있다. 제1 이미지는 픽셀 강도들의 제1 세트로부터 반전될 수 있는 픽셀 강도들의 제2 세트를 가질 수 있다. 제1 이미지는 2개의 추가적인 동일한 이미지를 가질 수 있으며, 제1 이미지와 2개의 추가적인 동일한 이미지가 3채널 이미지를 정의할 수 있다. 제1 이미지는 렌즈 중심을 가질 수 있으며, 렌즈 중심은 제1 이미지의 좌상 코너에 대해 정의될 수 있다. 제1 이미지에 표현되는 제1 안과용 렌즈는 극좌표계로 표현될 수 있다. 극좌표계는 직교 좌표계로부터 변환될 수 있다. 제1 이미지는 픽셀 강도들의 제1 세트로부터 반전된 픽셀 강도들의 제2 세트를 가질 수 있다. 제1 이미지는 원본 이미지로부터 회전될 수 있다. 제1 이미지는 원본 이미지로부터 뒤집힐 수 있다. 방법은 라벨링된 CAM에 의해 제공된 정보에 기초하여 AI 네트워크를 재훈련 또는 미세 조정하는 단계를 더 포함 할 수 있다. 방법은 실제 클래스 라벨 예측들이 이루어지는 AI 네트워크의 끝에서 완전 연결된 노드들을 제거하는 단계; 완전 연결된 노드들을 새로 초기화된 노드들로 교체하는 단계; AI 모델에 의해 학습된 임의의 이전의 강건한 특징들이 덮어쓰기 또는 폐기되지 않는 것을 보장하기 위해 AI 네트워크 내의 더 이른 또는 최상위 컨볼 루션 계층들을 프리징(freezing)하는 단계; 특정 학습률로 완전 연결된 계층들만을 훈련하는 단계; 및 AI 네트워크 내의 일부 또는 모든 컨볼루션 계층들을 언프리징하고 상대적으로 더 낮은 학습률로 동일하거나 새 로운 데이터 세트들로 추가적인 훈련을 수행하는 단계 중 적어도 하나를 수행함으로써 AI 네트워크를 재훈련 또 는 미세 조정하는 단계를 더 포함할 수 있다. 제1 이미지는 제1 안과용 렌즈의 렌즈 에지 이미지일 수 있고, 컴퓨터 시스템에 의해 액세스되는 제2 이미지는 제1 안과용 렌즈의 렌즈 표면 이미지일 수 있다. 제2 이미지는 제2 카메라에 의해 획득될 수 있고, 제2 이미지는 높이 픽셀 값 및 폭 픽셀 값을 가지며, 제2 이 미지의 높이 및 폭 픽셀 값들은 제2 카메라에 의해 획득된 템플릿 이미지에 기초하여 크기가 조정된다. 제2 이미지는 2개의 추가적인 동일한 이미지를 가질 수 있으며, 제2 이미지와 2개의 추가적인 동일한 이미지는 3채널 이미지를 정의할 수 있다. 제2 이미지는 픽셀 강도들의 제1 세트로부터 반전된 픽셀 강도들의 제2 세트를 가질 수 있다. CAM은 제1 CAM일 수 있으며, 방법은 제2 이미지에 기초하여 제2 CAM을 생성하고 결함 영역을 갖는 제2 CAM을 출 력하는 단계를 더 포함할 수 있다. 방법은 히트맵 및 경계 상자 중 적어도 하나 이상으로 제2 CAM 상의 결함 영역을 라벨링하여 제2 라벨링된 CAM 을 정의하는 단계를 더 포함할 수 있다. 제2 라벨링된 CAM은 AI 네트워크를 재훈련 또는 미세 조정하는 데 사용될 수 있다. 방법은 AI 네트워크로 제2 이미지에 대한 분류를 생성하고 출력하는 단계를 더 포함할 수 있으며, 분류는 결함 영역에 적어도 부분적으로 기초하고, 분류는 복수의 렌즈 표면 결함 클래스 중 하나이다. 복수의 렌즈 표면 결함 클래스는 적어도 3개의 클래스를 포함할 수 있다. 적어도 3개의 클래스는 양호한 렌즈 클래스, 버블 클래스, 및 스크래치 클래스를 포함할 수 있다. 방법은 렌즈 표면 결함들, 렌즈 에지 결함들, 또는 렌즈 표면 결함들 및 렌즈 에지 결함들 모두를 분류하여 렌 즈 표면 결함 클래스들, 렌즈 에지 결함 클래스들 또는 이들 모두를 생성하는 단계를 더 포함할 수 있다. 렌즈를 분류하는 단계는 액세스 단계 전에 수행될 수 있다. 렌즈를 분류하는 단계는 수동으로 수행될 수 있다. 제1 이미지는 관심 영역 주변에서 경계 상자로 라벨링될 수 있으며, 제1 이미지 상의 관심 영역 주변의 경계 상 자는 라벨링된 중간 활성화 이미지에 기초할 수 있다. CAM은 마지막 컨볼루션 계층의 출력에 기초하여 계산될 수 있다. 제1 이미지는 전처리된 이미지일 수 있으며, CAM은 전처리된 제1 이미지 위에 외삽 및 중첩된다. 본 발명의 추가 양태는 안과용 렌즈들의 렌즈 이미지들을 분류하기 위한 시스템이며, 시스템은 적어도 하나의 하드웨어 프로세서; 적어도 하나의 하드웨어 프로세서에 의해 실행될 때 적어도 하나의 하드웨어 프로세서로 하 여금 단계들을 수행하게 하는 명령어들을 저장한 메모리를 포함하고, 단계들은 a) 메모리로부터 제1 이미지에 액세스하는 단계 - 제1 이미지는 제1 안과용 렌즈의 렌즈 에지 이미지 또는 렌즈 표면 이미지를 포함함 -; b) 메모리로부터 훈련된 컨볼루션 신경망(CNN)에 액세스하는 단계 - 훈련된 CNN은 안과용 렌즈들의 렌즈 이미지들 에 대해 훈련되었고, 안과용 렌즈들 각각은 양호한 렌즈이거나 적어도 하나의 렌즈 결함을 가짐 -; c) 제1 이미 지에 기초하여 클래스 활성화 맵(CAM)을 생성하고 결함 영역을 갖는 CAM을 출력하는 단계; d) 히트맵 및 경계 상자 중 적어도 하나로 CAM 상의 결함 영역을 라벨링하여 라벨링된 CAM을 정의하는 단계; 및 e) 제1 이미지에 대한 분류를 생성하고 출력하는 단계를 포함하고, 분류는 결함 영역에 적어도 부분적으로 기초하고, 분류는 복 수의 렌즈 표면 결함 클래스 중 하나 또는 복수의 렌즈 에지 결함 클래스 중 하나이다. 본 발명의 또 다른 양태는 안과용 렌즈들을 검사하고 안과용 렌즈들의 이미지들에 분류를 할당하기 위한 방법이 며, 방법은 a) 하드웨어 프로세서로 구현된 인공 지능(AI) 네트워크로 제1 이미지를 처리함으로써 렌즈 결함을 위해 분석할 제1 이미지 상의 영역을 식별하는 단계; b) 제1 이미지에 기초하여 CAM을 생성하고 결함 영역을 갖 는 CAM을 출력하는 단계; c) 히트맵 및 경계 상자 중 적어도 하나로 CAM 상의 결함 영역을 라벨링하여 라벨링된 CAM을 정의하는 단계; d) AI 네트워크로 제1 이미지에 대한 분류를 생성하고 출력하는 단계 - 분류는 결함 영역 에 적어도 부분적으로 기초하고, 분류는 복수의 렌즈 표면 결함 클래스 중 하나 또는 복수의 렌즈 에지 결함 클 래스 중 하나임 -; e) 하드웨어 프로세서로 구현된 인공 지능(AI) 네트워크로 제2 이미지를 처리함으로써 렌즈 결함을 위해 분석할 제2 이미지 상의 영역을 식별하는 단계를 포함한다. AI 네트워크는 클라우드에, 제1 이미지와 제2 이미지가 저장된 저장 메모리를 갖는 컴퓨터 시스템에, 또는 제1 이미지와 제2 이미지가 저장되지 않은 저장 메모리를 갖는 컴퓨터 시스템에 상주할 수 있다."}
{"patent_id": "10-2024-7000620", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부 도면들과 관련하여 아래에 제시된 상세한 설명은 본 디바이스들, 시스템들 및 방법들의 양태들에 따라 제 공되는 렌즈 검사 시스템들의 현재 바람직한 실시예들에 대한 설명으로서 의도된 것이며, 본 디바이스들, 시스 템들 및 방법들이 구성되거나 이용될 수 있는 유일한 형태들을 나타내도록 의도된 것이 아니다. 본 설명은 예 시된 실시예들과 관련하여 본 디바이스들, 시스템들 및 방법들의 실시예들을 구성 및 사용하기 위한 특징들 및 단계들을 제시한다. 그러나, 동일하거나 동등한 기능들 및 구조들은 본 개시의 사상 및 범위 내에 포함되도록 또한 의도된 상이한 실시예들에 의해 달성될 수 있다는 것이 이해되어야 한다. 본 명세서의 다른 곳에서 표시 된 바와 같이, 동일한 요소 번호들은 동일하거나 유사한 요소들 또는 특징들을 나타내도록 의도된다. 이제 도 1을 참조하면, 콘택트 렌즈들 또는 다른 안과용 렌즈들과 같은 렌즈들의 이미지들을 검사하고, 컨볼루 션 신경망(CNN)들과 같은 인공 지능(AI) 및 기계 학습을 사용하여 결함들의 클래스들 또는 카테고리들을 출력함 으로써 렌즈들을 자동으로 검사하는 데 사용될 수 있는 렌즈 검사 시스템을 예시하는 개략도가 도시되어 있다. 렌즈 검사 시스템은 안과용 렌즈들의 렌즈 이미지들을 분류하기 위한 시스템으로 지칭될 수 있다. 렌즈 검사 시스템은 렌즈들을 건조 또는 비수화 상태에서 검사하고, 건조 상태의 렌즈들에서 획득한 이미지들로 부터 결함들의 클래스들 또는 카테고리들을 출력하기 위한 하드웨어 및 소프트웨어를 구비하여 구성된다. 예를 들어, 수 몰드 부분(male mold part)과 암 몰드 부분(female mold part)을 갖는 몰드로부터 렌즈를 분리한 다 음에 렌즈를 세척 및/또는 수화하기 전에 건조 상태에서 검사할 수 있다. 다른 예들에서, 아래에서 더 설명되 는 바와 같이, 렌즈는 용액 내의 블리스터 패키지에 배치된 동안에, 예컨대 렌즈가 젖은 상태에 있을 때 검사될 수 있다. 본 발명의 예시된 실시예에서, 렌즈 검사 시스템은 각각의 렌즈가 렌즈 몰드에서 제거되어 사파이어 크리 스탈 지지 구조와 같은 지지대 상에 배치된 후에 렌즈를 검사한다. 렌즈 검사 시스템을 통과한 렌즈들은, 예를 들어 각각의 렌즈의 렌즈 에지와 렌즈 표면을 모두 이미징하여 렌즈의 이미지들을 촬영하고, 렌즈 검사 시 스템의 컴퓨터들에 로딩된 CNN들을 사용하여 이미지들을 처리함으로써 각각 검사된다. 렌즈 검사 시스템은 CNN 들을 사용하여, 존재할 경우, 렌즈의 결함 특성들을 특성화하여 제조자들이 단지 합격/불합격이 아니라 버블들, 스크래치들, 파편 등의 존재로 인한 결함과 같은 렌즈의 실패 모드들을 이해하는 것을 도우며, 이는 제조자가 제조 프로세스들을 개선하여 더 높은 수율을 얻을 수 있게 한다. 본 발명의 렌즈 검사 시스템을 사용하여 이미 징 및 분석할 수 있는 콘택트 렌즈는 소프트 실리콘 하이드로겔 콘택트 렌즈들 및 전통적인 하이드로겔 콘택트 렌즈를 모두 포함한다. 렌즈 검사 시스템은 일반적으로 이미지 획득 서브시스템 및 아래에서 더 설명되는 바와 같이 CNN 소 프트웨어를 동작시키는 이미지 분석 서브시스템을 포함한다. 이미지 획득 서브시스템은 하나 이상의 검사 헤드를 포함하며, 각각의 검사 헤드는 복수의 이미지 획득 디바이스를 갖고, 이들은 Basler Scout GigE scA1390-17gm 디지털 카메라와 같은 임의 수의 고해상도 디지털 흑백 카메라일 수 있으며, 충분한 해상도 및 처리 속도를 갖는 다른 상용 디지털 카메라들도 사용가능하다. 각각의 카메라는 고정 초점 거 리 카메라 렌즈와 함께 사용되어 초점면을 기준으로 장착된 또는 고정된 작동 거리에서 원하는 시야를 획득할 수 있다. 예시적인 카메라 렌즈는 Linos 35mm/1.6 또는 35mm/1.8 렌즈를 포함할 수 있으며, 충분한 초점 거리 들 및 f-스톱들을 갖는 다른 상용 고정 또는 가변 렌즈들도 사용 가능하다. 일부 예들에서, 렌즈는 전압이 인 가될 때 형상이 변하는 광선 액체를 포함하는 작은 셀들을 포함하는 액체 렌즈일 수 있으며, 따라서 렌즈의 초 점 거리들, 따라서 렌즈의 피사계 심도 및 초점을 변경할 수 있는 빠른 전자식 포커싱을 가능하게 하여 동일한 카메라가 렌즈 에지 이미지와 렌즈 표면 이미지를 캡처할 수 있게 한다. 일반적으로, 렌즈 에지, 렌즈 표면, 또는 렌즈 에지와 렌즈 표면 모두의 고품질 이미지를 생성하는 임의의 렌즈와 카메라 조합이 본 발명의 시스템 과 함께 채택될 수 있다. 본 발명의 예시된 렌즈 검사 시스템에서, 이미지 획득 서브시스템은 검사 어셈블리들 또는 검사 헤드 들의 4개의 그룹을 포함한다. 각각의 검사 헤드는 하나 이상의 조명 디바이스 또는 광원, 하나이상의 이미지 획득 디바이스 또는 카메라, 검사될 각각의 콘택트 렌즈에 대해 하나씩인 하나 이상의 지지대, 및 적어도 하나의 운영 컴퓨터 시스템을 가질 수 있다. 일 실시예에서, 렌즈 검사 시스템의 각각의 검사 헤드는 조명 디바이스, 및 카메라일 수 있는 4개의 이미지 획득 디바이스를 포함한 다. 조명 디바이스는 하나 이상의 카메라와 함께 작동 광을 방출하도록 크기가 조정되고 구조화된 복수의 LED를 갖는 단일 하우징을 포함할 수 있다. 대안적으로, 조명 디바이스는 분리된 하우징들을 구현 할 수 있으며, 각각의 분리된 하우징은 분리된 하우징과 페어링된 카메라에 대한 충분한 광을 제공하기에 충분한 수의 LED를 갖는다. 조명 디바이스와 이미지 획득 디바이스의 각각의 조합은 카메라가 페어 링된 광원과 광학적으로 정렬되도록 배열된다. 즉, 특정 광원에서 방출된 광은 페어링된 카메라의 렌즈로 투사 된다. 조명 디바이스의 LED들은 광 컨트롤러에 동작 가능하게 연결되어, LED들은 렌즈가 이미징될 때 활성 화하기 위해 광 컨트롤러로부터 전류 펄스와 같은 신호를 수신한다. 일례로, LED들은 약 880nm의 피크 파장에 서 NIR 광을 방출할 수 있으며, 다른 주파수들도 고려된다. 도시된 예에서, 하나의 광 컨트롤러는 2개의 검사 헤드의 조명 디바이스들을 동작가능하게 제어하도록 프로그래밍될 수 있다. 옵션으로서, 각각의 조 명 디바이스는 조명 디바이스의 기능들을 제어하기 위해 자체 컨트롤러와 페어링될 수 있다. 콘택트 렌즈 지지대는 렌즈 검사 시스템에 의해 검사될 하나 이상의 렌즈를 유지하도록 구조화 된다. 일례로, 디몰딩 테이블(demolding table)(도시되지 않음)은 축을 중심으로 회전하는 표면을 구비하고, 지지대들은 테이블 상에 위치하며, 지지대들은 렌즈 검사 시스템을 통해 렌즈들을 이미징하고 순환시키기 위해 테이블에 의해 회전 가능하다. 디몰딩 테이블이 회전함에 따라, 지지대들에 의해 지지되고 검사될 렌즈들 각각은 카메라와 광원 사이를 통과하여 카메라가 검사될 렌즈의 이미지를 획득할 수 있 도록 한다. 대안 실시예들에서, 렌즈들은 디렌징(delensing) 전에 각각의 렌즈가 수 몰드 부분 또는 암 몰드 부분에 여전히 부착되어 있는 동안 검사된다. 따라서, 디몰딩 테이블이 회전하여 렌즈가 카메라 아래를 통과할 때, 카메라는 렌즈가 수 몰드 부분 또는 암 몰드 부분에 여전히 부착되어 있는 동안 렌즈의 이미지를 캡처하도 록 구성될 수 있다. 일례로, 4개의 검사 헤드 각각은 4개의 카메라를 가지며, 다른 수의 카메라 및 대응하는 광원도 고려 된다. 4개의 검사 헤드는 카메라 유닛 1(CU1), 카메라 유닛 2(CU2), 카메라 유닛 3(CU3) 및 카메라 유닛 4(CU4)로 지정될 수 있다. 각각의 카메라 유닛의 4개의 카메라는 카메라 1(C1), 카메라 2(C2), 카메라 3(C3) 및 카메라 4(C4)로 지정될 수 있다. 카메라들은 상이한 시야들에 포커싱하도록 엇갈리게 배치될 수 있으 므로, 검사 헤드 내의 카메라, 예를 들어 CU1의 C1은 렌즈의 렌즈 에지에 포커싱할 수 있는 반면, 다른 카메라, 예를 들어 CU1의 C2는 제2 렌즈의 렌즈 표면에 포커싱할 수 있다. 일례로, 카메라 유닛 CU1 및 CU2는 렌즈 프로파일의 유사한 시퀀스를 이미징하기 위한 카메라들로 배열될 수 있 고, 카메라 유닛 CU3 및 CU4는 렌즈 프로파일의 유사한 시퀀스를 이미징하기 위한 카메라들로 배열될 수 있어서, 렌즈 검사 시스템은 이미징 사이클당 8개의 이미지의 2개의 세트를 캡처할 수 있다(즉, CU1 및 CU2는 8개의 이미지의 제1 세트를 나타내고, CU3 및 CU4는 8개의 이미지의 제2 세트를 나타낸다). 도시된 바와 같이, 카메라 유닛 CU1 및 CU2 각각은 4개의 상이한 렌즈에 대해 카메라 C1로 렌즈 에지 이미지를, 카메라 C2로 렌즈 표면 이미지를, 카메라 C3으로 렌즈 에지 이미지를, 카메라 C4로 렌즈 표면 이미지를 캡처하 도록 배열된다. 이어서, 카메라 유닛 CU1 및 CU2에 의해 8개의 렌즈가 이미징된 후, 지지대들 상에 위치하는 렌즈들은 카메라 유닛 CU1 및 CU2에 의해 캡처되는 동일한 8개의 렌즈의 렌즈 에지 이미지 또는 렌즈 표면 이미 지 중 다른 하나를 촬영하도록 엇갈리게 배치되는 카메라들을 갖는 카메라 유닛 CU3 및 CU4에 인덱싱된다. 따라서, 카메라 유닛 CU3 및 CU4 각각은 카메라 유닛 CU1 및 CU2에 의해 이미징된 동일한 대응하는 4개의 렌즈 에 대해 카메라 C1로 렌즈 표면 이미지를, 카메라 C2로 렌즈 에지 이미지를, 카메라 C3으로 렌즈 표면 이미지를, 카메라 C4로 렌즈 에지 이미지를 캡처하도록 배열된다. 이와 함께, 두 세트의 검사 헤드 CU1/CU2 및 CU3/CU4는 렌즈 검사 시스템에 의해 검사될 각각의 콘택트 렌즈의 렌즈 에지 이미지 및 렌즈 표면 이미지 를 캡처하도록 구성된다. 구체적인 예로, CU1의 C1은 렌즈-A의 렌즈 에지 이미지를 촬영하도록 구성되고, CU1의 C2는 렌즈-B의 렌즈 표면 이미지를 촬영하도록 구성된다. 디몰딩 테이블이 회전하고 CU1이 캡처한 렌즈들이 CU3에 인덱싱되면, CU3의 C1 은 렌즈-A의 렌즈 표면 이미지를 촬영하도록 구성되고, CU3의 C2는 렌즈-B의 렌즈 에지 이미지를 촬영하도록 구 성된다. 따라서, 카메라 유닛들은 엇갈리게 배치되어, 시스템에 의해 검사될 각각의 렌즈는 시스템에 의해 획 득된 2개의 이미지, 즉 렌즈의 렌즈 에지 이미지와 렌즈 표면 이미지를 갖게 될 것이다. 따라서, 렌즈-A는 CU1의 C1에 의해 캡처된 렌즈 에지 이미지와 CU3의 C1에 의해 캡처된 표면 에지 이미지를 갖는 반면, 렌즈-B는 CU1 의 C2에 의해 캡처된 렌즈 표면 이미지와 CU3의 C2에 의해 캡처된 렌즈 에지 이미지를 가질 것이다. 캡처된 이 미지들은 각각의 개개의 카메라의 메모리 칩에 국지적으로 저장된다. 이어서, 캡처된 이미지들은 하나 이상의 컴퓨터 시스템으로, 예컨대 컴퓨터의 하드 드라이브로 전송되며, 하나 이상의 컴퓨터 시스템은 캡처 된 이미지들의 렌즈 에지 이미지들 및 렌즈 표면 이미지들을 분석 및 분류하기 위해 상이한 CNN 모델들과 같은 상이한 AI 모델들을 동작시킬 수 있다. 일부 예들에서, 캡처된 이미지들은 컴퓨터 시스템 외부의 플래시 드라 이브들, 휴대용 하드 드라이브들, 데이터 디스크들 등과 같은 하나 이상의 외부 메모리 디바이스로 전송될 수 있다. 이어서, 컴퓨터에서 실행되는 AI 모델은 하나 이상의 외부 메모리 디바이스에서 데이터를 가져온 다음, 저장된 렌즈 이미지들을 검사하고 하나 이상의 렌즈 결함 카테고리에 따라 분류하는 것과 같이 데이터를 처리할 수 있다. 본 발명의 예시된 렌즈 검사 시스템에서, 검사 헤드들은 디몰더(demolder)를 통과하는 렌즈들의 전자 또는 디지털 이미지들의 획득을 담당한다. 각각의 검사 헤드는 하나의 기계 인덱스 기간 내에 그의 스테 이션에서 4개의 렌즈를 모두 검사할 수 있다. 4개의 검사 헤드는 렌즈 검사 시스템을 통과하는 모든 렌즈 의 2개의 이미지를 획득할 수 있는 용량을 제공한다. 4개의 검사 헤드는 각각의 렌즈의 상이한 부분들의 2개의 별개의 뷰, 예를 들어 에지 뷰 및 표면 뷰를 생 성하도록 구조화된다. 2개의 뷰는 단일 렌즈의 이미지에 대응할 것이다. 에지 뷰에서, 초점면은 렌즈의 에지 와 일치하거나 거의 일치하므로, 에지에서의 또는 그 근처에서의 에지 결함들 또는 이상들이 검출 가능하게 된 다. 렌즈 에지에 대해 획득된 이미지는 전체 렌즈 에지의 이미지이다. 즉, 이미지는 렌즈 에지의 단일의 완전 한 이미지이다. 예시된 실시예에서, 렌즈는 그의 에지가 사파이어 윈도우와 같은 윈도우 상에서 아래로 향한 상태에서 검사된다. 표면 뷰에서 또는 렌즈 표면들의 이미지들에 대해, 카메라의 초점면은 렌즈의 에지 위에서 렌즈와 교차하도록 상승되어, 표면 결함들이 검출 가능하게 된다. 렌즈의 표면 뷰는 렌즈 표면의 단일의 완전한 뷰를 제공한다. 일 실시예에서, 카메라의 렌즈와 안과용 렌즈 사이의 거리는 렌즈의 전체 표면(예를 들어, 렌즈 에지로부터 이 격된 렌즈 부분)이 단일 이미지를 형성하도록 설정된다. 초점 심도는 또한 검사 윈도우 상에 모이는 임의의 파 편이 표면 뷰에 선명한 초점으로 나타나지 않도록 제한될 수 있다. 렌즈의 표면 및 에지 뷰를 획득하는 이러한 접근법은 이미지에서 파편을 우연히 캡처할 수 있는, 렌즈 이미지들을 획득하는 데 단일의 높은 피사계 심도 뷰 를 이용하는 검사 시스템들에서 나타나는 높은 거짓 거부율을 극복할 수 있다. 본 명세서에 설명된 검사 시스 템의 더몰더는 과도한 파편이 축적되는 경우에 세척 스테이션을 포함할 수도 있다. 또한, 검사 시스템은 렌즈 들 상의 오염 물질들의 가능성을 줄이는 것을 돕기 위해 렌즈에 이온화된 공기를 전달하는 디바이스를 포함할 수 있다. 이미지 분석 서브시스템 또는 검사 플랫폼은 이미지 획득 서브시스템과 통신하는 하나 이상의 운영 컴퓨터 또는 컴퓨터 시스템을 포함하여, 컴퓨터들이 이미지 획득 서브시스템의 카메라들에 의해 획득된 이미지들을 수신한 다음에 AI를 사용하여 결과들을 분석 및 출력할 수 있도록 한다. 데이터 입력, 예컨 대 키보드 또는 마우스, 데이터 디스플레이, 예컨대 모니터, 네트워크 스위치들, 모뎀들 및 전원들을 허용하기 위해 추가적인 컴퓨터 컴포넌트들이 제공될 수 있다. 각각의 컴퓨터 시스템은 프로세서와 같은 하드웨어, 및 AI 소프트웨어 및 분석될 이미지들을 저장하기 위한 메모리를 가질 수 있다. 검사 플랫폼의 요소들은 하나 이상의 캐비닛에 제공될 수 있다. 검사 플랫폼의 요소들은 전기 통신을 허용하기 위해 함께 배선될 수 있다. 예시적인 이미지 분석 서브시스템은 윈도우 10 엔터프라이즈 운영 체제 또는 등가물 상에서 동작하는 윈도 우 기반 컴퓨터를 포함할 수 있다. 각각의 컴퓨터 시스템은 큰 이미지 데이터를 처리하기에 충분한 동작 속도, 전력 및 메모리를 가져야 하고, 배치 사용(batch use)도 고려되는 연속 사용을 핸들링하기에 충분히 강건해야 한다. 각각의 검사 헤드에 의해 캡처된 이미지들은 컴퓨터에 상주하는 CNN들을 사용하여 분석될 수 있다. 일례로, 각각의 컴퓨터는 적어도 2개의 상이한 CNN 모델, 예를 들어 렌즈 에지 이미지들을 분 석하기 위한 것과 렌즈 표면 이미지들을 분석하기 위한 것을 동작시킬 수 있다. 이어서, CNN들을 동작시키는 컴퓨터 시스템은 렌즈 이미지들의 결함 특성들을 프로그래머블 로직 컨트롤러에 보고하거나 출력할 수 있 고, 이어서 프로그래머블 로직 컨트롤러는 아래에서 더 설명하는 바와 같이 프로세스 감독을 위한 컴퓨터 를 포함하는 네트워크화된 감독 제어 및 데이터 애플리케이션(SCADA) 시스템과 통신할 수 있다. 각각의 컴퓨터 시스템은 이미지 데이터, 이미지들에 관한 데이터 결과들을 저장하고, 데이터를 대조하고, SCADA 시스템과 통신하고, 이미지 데이터를 분석하여 각각의 이미지에 대한 여러 클래스 중 결함 클래스를 결정하고, 하나 이상의 원격 컴퓨터와 통신하도록 구성된다. 운영 컴퓨터들은 SCADA와 카메라 유닛들 사이의 인터페이스를 제공한다. 예를 들어, SCADA에서 발행된 커맨드들은 실행을 위해 카메라 유닛들 로 전달될 수 있고, 카메라 유닛들에 의해 생성된 보고들은 SCADA로 전달될 수 있다. 예시적인 실시예들 에서, 하나 이상의 원격 서버는 운영 컴퓨터들 상의 이미지 데이터에 액세스할 수 있고, 원격 서버들 의 자체 컴퓨팅 플랫폼 상에서 이미지 데이터를 분석할 수 있다. 또 다른 예들에서, 이미지 데이터는 클라우드 에 저장되고, 운영 컴퓨터들 및/또는 하나 이상의 원격 서버는 이미지 데이터를 국지적으로 분석할 수 있다. 이미지 획득 시스템의 추가적인 양태들은 Leppard 등의 미국 특허 제7,256,881호에 설명되어 있으며, 그 내용은 전체가 제시된 것처럼 본 명세서에 참고로 명시적으로 통합된다. 렌즈 검사 시스템에 의해 획득된 이미 지 데이터를 분석하고 특성화하는 데 사용되는 기계 학습 및 AI의 특정 양태들은 아래에서 추가로 설명된다. 이제 도 2를 참조하면, 본 발명의 양태들에 따른 이미지 데이터 및 기계 학습을 사용하여 콘택트 렌즈 결함 분 류들을 자동으로 검출하기 위한 렌즈 검사 시스템을 묘사하는 개략도가 도시되어 있다. 컴퓨팅 디바이스 또는 컴퓨터 시스템은 이미지 획득 시스템으로부터 검사될 각각의 렌즈의 렌즈 에지 이미지 및 렌즈 표면 이미지 데이터를 수신할 수 있다. 일부 구성들에서, 이미지 획득 시스템은 검사될 각각의 안과용 렌 즈에 대한 렌즈 에지 이미지 및 렌즈 표면 이미지를 획득하기 위한 복수의 카메라를 각각 포함하는 복수의 검사 헤드를 포함할 수 있다. 일부 실시예들에서, 컴퓨팅 디바이스는 렌즈 결함들을 자동으로 분류하기 위해 자동 식별 시스템(AIS)의 적어도 일부를 실행할 수 있다. 일례로, 컴퓨팅 디바이스는 2개의 컨볼루 션 신경망(CNN)과 같은 적어도 2개의 상이한 AI 모델을 실행하여, 2개의 AI 모델 중 제1 AI 모델을 이용하여 렌 즈 에지 이미지가 양호한 렌즈를 나타내는지 또는 여러 렌즈 에지 결함 카테고리 중 하나를 포함하는지를 결정 하고, 2개의 AI 모델 중 제2 AI 모델을 이용하여 표면 에지 이미지가 양호한 렌즈를 나타내는지 또는 여러 렌즈 표면 결함 카테고리 중 하나를 포함하는지를 결정할 수 있다. 즉, 컴퓨팅 디바이스 상의 메모리는 적어도 하나 의 하드웨어 프로세서에 의해 실행될 때 적어도 하나의 하드웨어 프로세서가 데이터 파일들에 액세스하고, 데이 터 파일들을 분석하고, 데이터 파일들의 분석을 수행하고, 데이터 파일들에 의해 표현된 안과용 렌즈들의 결함 들 또는 상태를 나타내는 출력들을 제공하는 것을 포함하는 여러 작업을 수행하도록 CNN들을 동작시키게 하는 명령어들을 저장하거나 또는 그 내부에 갖는다. 일례로, 자동 식별 시스템은 이미지 데이터를 분석하기 위한 소프트웨어 드라이버들 및 라이브러리들을 포 함한다. 예시적인 소프트웨어 드라이버는 전사 학습이라고 하는 프로세스에서 수정된 여러 라이브러리 중 하나 를 컴파일하는 NVIDIA Cuda 컴파일러 드라이버와 함께 동작하는 Python 해석 고레벨 프로그래밍 언어일 수 있다. 라이브러리들은 cuDNN SDK 심층 학습 GPU 가속 라이브러리, 심층 학습 모델들을 개발 및 평가하기 위한 TensorFlow 오픈 소스 소프트웨어 라이브러리, Keras 오픈 소스 소프트웨어 라이브러리, 어레이 및 행렬 데이터 구조들과 함께 작업하기 위한 NumPy 오픈 소스 소프트웨어 라이브러리, 이미지 디스플레이 및 주석첨부, 또는 그래프 디스플레이를 위한 matplotlib 오픈 소스 소프트웨어 라이브러리, 및 객체들 및 특성들을 식별하기 위해 이미지들을 처리하기 위한 OpenCV 오픈 소스 라이브러리를 포함할 수 있다. 예시적인 실시예들에서, 컨볼루션 신경망(CNN)들은 복수의 렌즈 에지 및 렌즈 표면 결함 클래스를 분류하기 위한 비전 애플리케이션들을 위한 심 층학습 모델들로서 사용된다. CNN 모델을 사용하고 훈련할 때, 일례로, 이미지의 특정 위치에서의 학습된 패턴 은 이미지 내의 임의의 다른 곳에서 인식될 수 있다. 초기 컨볼루션 계층들은 렌즈 이미지의 에지들 또는 텍스 처들과 같은 작은 국지적 패턴들을 학습할 수 있는 반면, 후속 계층들은 초기 계층들에 의해 학습된 특징들로 구성된 더 큰 패턴들을 학습할 수 있다. 일부 실시예들에서, 컴퓨팅 시스템은 이미지 획득 시스템으로부터 수신된 이미지 데이터에 대한 정보 를 통신 네트워크를 통해 서버에 통신할 수 있고, 서버는 자동 식별 시스템의 적어도 일부 를 실행할 수 있다. 이러한 실시예들에서, 서버는 정보를 컴퓨터 시스템에 반환할 수 있으며, 이 정 보는 결함들의 여러 카테고리 또는 클래스 중 하나일 수 있는 자동 식별 시스템의 출력을 나타낸다. 일부 실시예들에서, 컴퓨팅 디바이스 및/또는 서버는 데스크톱 컴퓨터, 랩톱 컴퓨터, 스마트폰, 태블 릿 컴퓨터, 웨어러블 컴퓨터, 서버 컴퓨터, 물리적 컴퓨팅 디바이스에 의해 실행되는 가상 기계 등과 같은 임의 의 적합한 컴퓨팅 디바이스 또는 디바이스들의 조합일 수 있다. 일부 실시예들에서, 자동 식별 시스템(132, 133)은 이전에 일반 이미지 분류기로서 훈련된 컨볼루션 신경망(CNN)들을 사용하여 렌즈 표면 이미지 상의 결함 을 8개의 가능한 결함 중 하나로 분류할 수 있고, 렌즈 에지 이미지 상의 결함을 3개의 가능한 결함 중 하나로 분류할 수 있다.일부 실시예들에서, 도 1의 이미지 획득 시스템은 컴퓨팅 디바이스 및/또는 서버 컴퓨터에 이미 지 데이터를 공급하기 위한 이미지 소스이다. 일부 실시예들에서, 이미지 획득 시스템은 컴퓨팅 디바이스 와 함께 국지적으로 하우징될 수 있다. 예를 들어, 이미지 획득 시스템은 컴퓨팅 디바이스와 통합될 수 있다. 즉, 컴퓨팅 디바이스는 이미지 획득 시스템으로부터 이미지들을 캡처 및/또는 저장 하기 위한 디바이스의 일부로서 구성될 수 있다. 다른 예에서, 이미지 획득 시스템은 케이블, 직접 무선 링크 등에 의해 컴퓨팅 디바이스에 연결될 수 있다. 추가적으로 또는 대안적으로, 일부 실시예들에서, 이 미지 획득 시스템은 컴퓨팅 디바이스로부터 국지적으로 그리고/또는 원격적으로 위치할 수 있고, 통 신 네트워크를 통해 컴퓨팅 디바이스 및/또는 서버에 이미지 데이터를 통신할 수 있다. 일부 실시예들에서, 통신 네트워크는 임의의 적절한 통신 네트워크 또는 통신 네트워크들의 조합일 수 있 다. 예를 들어, 통신 네트워크는 와이파이 네트워크(하나 이상의 무선 라우터, 하나 이상의 스위치 등을 포함할 수 있음), 피어 대 피어 네트워크(예컨대, 블루투스 네트워크), 셀룰러 네트워크(예컨대, 4G 네트워크, CDMA, GSM, LTE, LTE Advanced, WiMAX 등과 같은 임의의 적합한 표준을 따르는 4G 네트워크 등), 유선 네트워 크 등을 포함할 수 있다. 일부 실시예들에서, 통신 네트워크는 근거리 네트워크, 광역 네트워크, 공개 네 트워크(예컨대, 인터넷), 비공개 또는 반-비공개 네트워크(예컨대, 기업 인트라넷), 임의의 다른 적절한 유형의 네트워크, 또는 네트워크들의 임의의 적절한 조합일 수 있다. 도 2에 도시된 통신 링크들은 각각 유선 링크들, 광섬유 링크들, 와이파이 링크들, 블루투스 링크들, 셀룰러 링크들 등과 같은 임의의 적절한 통신 링크 또는 통 신 링크들의 조합일 수 있다. 일부 실시예들에서, 통신 네트워크를 제공하기 위한 통신 시스템들은 통신 네트워크 및/또는 임의의 다른 적합한 통신 네트워크들을 통해 정보를 통신하기 위한 임의의 적합한 하드웨어, 펌웨어, 및/또는 소프트웨 어를 포함할 수 있다. 예를 들어, 통신 시스템들은 하나 이상의 트랜시버, 하나 이상의 통신 칩 및/또는 칩 세 트 등을 포함할 수 있다. 보다 구체적인 예에서, 통신 시스템들은 와이파이 연결, 블루투스 연결, 셀룰러 연결, 이더넷 연결 등을 확립하는 데 사용될 수 있는 하드웨어, 펌웨어 및/또는 소프트웨어를 포함할 수 있다. 이제 도 3을 참조하면, 본 발명의 렌즈 검사 시스템의 하나의 구성을 나타내는 흐름도가 도시되어 있다. 흐름도는 이미지 분석 서브시스템에 이미지 데이터를 제공하기 위한 2개의 상이한 입력 경로를 도시하는데, 이들은 훈련 및 확인을 위한 이미지 입력을 제공하기 위한 제1 입력 경로 및 생성 이미지 데 이터 세트들을 입력하는 것과 같이 예측을 위한 이미지 입력을 제공하기 위한 제2 입력 경로를 포함한다. 도 3에서 식별된 상이한 단계들의 구체적인 양태들은 도 4-41을 참조하여 아래에 도시되고 설명된다. 이전에 제기된 바와 같이, 전사 학습은 AI 모델 아키텍처가 실제 객체들을 검출하는 등의 문제에 대해 이미 훈 련되었고 그 모델이 상이한 문제에 대해 재사용되는 기술이다. 상이한 문제에 대해 재사용하기 위해 사전 훈련 된 모델을 훈련하는 동안, 모델의 매우 많은 수의 계층들 또는 블록들이 프리징되며 - 이는 상이한 계층들 또는 블록들의 가중치들이 로킹되어 추가 훈련이 이들을 변경할 수 없다는 것을 의미함 -, 반면에 다른 계층들은 새 로운 작업들을 학습하기 위해 언프리징된다. 전사 학습의 초점은 모델의 최상위 계층들 중 소수만을 훈련하여 재훈련되는 계층들이 그들이 훈련되고 있는 새로운 파라미터들 또는 문제들을 매우 낮은 학습률로 인식하게 함 으로써 어떠한 주요 변화도 급격하게 일어나지 않게 하는 것이다. 따라서, 도 3은 상이한 렌즈 결함들을 분석 하고 분류하도록 모델을 먼저 훈련하고 확인한 다음, 재훈련된 모델을 사용하여 생성 렌즈 이미지 데이터 세트 들의 예측을 수행하기 위한 프로세스 흐름도의 개요를 나타낸다. 도 3을 참조하면, AI 모델, 특히 CNN 모델을 훈련하기 위한 프로세스 흐름이 도시되어 있다. 프로세스는 상이 한 AI 모델들에 적용가능한데, 예컨대 CNN \"에지\" 모델뿐만 아니라 CNN \"표면\" 모델에도 적용가능하다. 단계 206에서, 모델은 AI 모델에 훈련 데이터 세트들을 입력함으로써 훈련될 수 있다. 훈련 데이터 세트들은 도 1의 이미지 획득 시스템과 같은 이미징 소스로부터 또는 이전에 획득한 이미지들의 데이터베이스로부터 획득될 수 있다. 훈련 데이터 세트들로서 사용하기 위해 이미지들에 액세스하는 것은 이미지 획득 시스템으로 이 미지들을 획득하는 것을 포함하거나, 컴퓨터 시스템, 저장 메모리, 또는 예컨대 서버 또는 클라우드 상의 다른 적절한 데이터 저장 디바이스들에 저장된 이전에 획득된 이미지들에 액세스하거나 다른 방식으로 검색하는 것을 포함할 수 있다. 액세스되는 이미지들은 이미지 획득 시스템에 의해 이미징된 콘택트 렌즈들의 렌즈 에지 이미 지들 및 렌즈 표면 이미지들 모두를 포함할 수 있다. 일례로, 제1 CNN 모델과 같은 제1 AI 모델이 렌즈 에지 이미지 데이터 세트들만을 사용하여 훈련되고, 이어서 별개로 제2 CNN 모델과 같은 제2 AI 모델이 렌즈 표면 이 미지 데이터 세트들만에 대해 훈련된다. 훈련 이미지 데이터 세트들은 아래에서 더 설명하는 바와 같이 렌즈 표면 결함들 및 렌즈 에지 결함들에 대해 상이한 결함 유형들을 갖는 이미지들을 포함한다. 단일 카메라가 렌 즈 에지 이미지와 렌즈 표면 이미지를 모두 캡처하는 예들에서, 2개의 개별 모델 대신 단일 AI 모델을훈련하여, 렌즈 표면 결함들, 렌즈 에지 결함들 또는 이들 모두를 분석하여, 렌즈 표면 결함 클래스들, 렌즈 에 지 결함 클래스들 또는 이들 모두를 생성할 수 있다. 따라서, 각각의 훈련 데이터세트는 렌즈 표면 결함들 및 렌즈 에지 결함들을 갖는 렌즈 에지 이미지들 및 렌즈 표면 이미지들 모두를 포함할 것이다. 일례로, 아래에서 더 설명하는 바와 같이, 이전에 획득된 이미지들의 라이브러리는 여러 에포크 또는 단계에 걸쳐 모델을 훈련하 는 데 사용되었다. 일례로, 모델 아키텍처는 이미지 분류를 위한 컨볼루션 신경망(CNN), 특히 VGG Net이며, 이 미지 처리를 위한 다른 심층 신경망들, 예를 들어 LeNet, AlexNet, GoogLeNet/Inception, ResNet, ZFNet도 고 려된다. 단계 208에서, 이미지들을 전처리하여 모델에 사용 가능한 입력 이미지들을 획득한다. 전처리의 목적은 분류 문제의 복잡성, 및 이미지의 폭 및 높이와 같은 입력의 공간 또는 크기를 감소시켜 훈련 및 예측 지속기간, 및 훈련에 필요한 이미지들의 수를 줄이는 것이다. 렌즈 표면 이미지의 전처리와 렌즈 에지 이미지의 전처리는 아 래에서 더 설명하는 바와 같이 유사하거나 상이한 요건들을 포함할 수 있다. 다른 예들에서, CNN 모델들에 입 력하기 위해 데이터 세트들이 액세스될 수 있기 전에, 동일한 입력 파일 크기들을 생성하기 위한 정규화를 제외 하고는, 이미지 데이터 세트들의 전처리는 필요하지 않다. CNN 모델들은 입력 이미지들의 어떠한 전처리도 필 요로 하지 않는다. 단계 210에서, 이미지 데이터 세트들 내의 이미지들 중 적어도 일부, 그러나 바람직하게는 전부에 대해 데이터 증강을 수행하여, CNN 모델들의 훈련에 사용할 풀(pool) 내의 이미지들의 총 수를 증가시킨다. 데이터 증강은 각각의 실제, 현실 또는 원본 이미지에 다양한 동작들을 수행하여 인공 이미지들을 생성한 다음에 이들을 데이 터 세트에 추가하는 것을 포함한다. 동작들은 뒤집기, 회전, 이미지의 컬러 및 밝기 조정, 리스케일링, 잡음 제거, 센터링 조정을 위한 크로핑 등을 포함한다. 일부 예들에서, 데이터 증강은 전처리된 이미지들이 AI 네트 워크에 입력되기 전에 이들에 대해 실시간으로 수행될 수 있다. 원본 이미지는 데이터 세트에 포함되거나 제외 될 수 있다. 도 4a는 좌측 원본 이미지, 및 좌측 이미지의 수직 뒤집기를 수행함으로써 증강된 우측 이미지를 도시한다. 도 4b는 좌측 원본 이미지, 및 좌측 이미지의 수평 뒤집기를 수행함으로서 증강된 우측 이미지를 도시한다. 따라 서, 동일한 원본 이미지로부터, 원본 이미지를 수평으로 그리고 수직으로 뒤집음으로써 총 3개의 이미지를 얻을 수 있다. 이어서, 단계 212에서, 데이터 증강으로부터 도출된 이미지들을 포함하는 데이터 세트들로부터의 이미지들을 CNN 모델에 입력하여 전사 학습이라는 프로세스에서 모델을 훈련한다. CNN 모델은 로컬 컴퓨터, 네트워크 컴퓨 터, 원격 서버 또는 클라우드에 상주할 수 있으며, 앱 또는 인터넷 대시보드를 통해 액세스 가능하다. 아래에 서 더 설명하는 바와 같이, 이 단계는 모델의 낮은 레벨들 중 여러 개를 로킹하고, 학습률로 모델을 훈련하고, 모델의 상이한 계층들을 언프리징하고, 모델의 빠르고 급격한 변화들을 피하기 위해 또 다른 학습률로 모델을 재훈련하고, 모델 성능을 평가하고, 훈련 기간 동안의 정확도 또는 다른 인자들에 기초하여 필요에 따라 재훈련 하는 것을 포함한다. 예를 들어, 아래에서 더 설명하는 바와 같이, 컨볼루션 베이스는 사전 훈련된 가중치들로 미리 초기화될 수 있는 반면, CNN 모델의 밀집 연결된 계층들은 무작위로 초기화될 수 있다. 컨볼루션 베이스 의 가중치들은 그들의 값들이 현재 데이터 세트에 대한 훈련에 의해 영향을 받는 것이 허용되지 않도록 훈련 동 안 프리징될 수 있다. 본 발명의 CNN 모델은 아래에 더 설명하는 바와 같이 3개의 유형의 계층들을 가지며, 이들은 컨볼루션 계층들, 풀링 계층들 및 완전 연결된 계층들을 포함한다. 단계 216에서, 완전 연결된 계층들은 네트워크의 마지막 몇 개의 계층을 형성하며, 종종 피드 포워드 신경망들로서 설명된다. 완전 연결된 계층들에 대한 입력은 최종 풀 링 또는 컨볼루션 계층으로부터의 출력이며, 이 출력은 평탄화된 다음 완전 연결된 계층들에 공급된다. 완전 연결된 계층들을 통과한 후, 단계 218에서, 모델은 활성화 함수를 사용하여 입력이 특정 클래스 또는 분류에 있 을 확률들을 구한다. 즉, 분석될 이미지가 CNN 모델을 통해 공급될 때, 단계 218에서의 출력은 \"스크래치\" 분 류 또는 \"버블\" 분류와 같은 분류일 수 있다. CNN 모델로부터의 분류된 이미지들, 즉 단계 218에서의 분류된 이미지들은 CNN 모델에 의해 분석된 전처리된 이미지들의 배치(batch)에 대해 제1 분류된 이미지, 제2 분류된 이미지, 제3 분류된 이미지 등으로 식별되거나 지칭될 수 있다. 그러나, 단계 218에서의 최종 출력은 통상적으로 스크래치 또는 버블이 분석된 이미지 상에서 발견된 위치 또는 방법에 대한 주석이 아니다. 따라서, 단계 214에서, 본 발명의 렌즈 검사 시스템은 사용자가 모델의 중간 활성 화들을 검토하여 예측 클래스의 활성화를 위해 완전 연결된 계층들 전의 모델의 다양한 계층들이 이미지의 어떤 부분 또는 얼마의 부분인지에 대한 표시들을 수집할 수 있게 한다. 이러한 중간 활성화들로부터의 이미지들을이용하는 것은 트레이너 또는 사용자에게 아래에서 더 설명하는 바와 같이 최적의 성능을 위해 모델을 더 잘 훈 련하는 방법에 대한 귀중한 지식을 제공할 수 있다. 프롬프트(prompt)될 때, 단계 220에서, 본 렌즈 검사 시스템은 사용자가 모델의 다양한 계층들로부터 클래스 활 성화 맵들 또는 이미지들을 생성하도록 모델들을 실행하는 컴퓨터 시스템에 토글 또는 요청할 수 있게 한다. 이러한 이미지들은 일반적으로 사실상 추상적이지만, 예측 클래스의 활성화에 대해 CNN 모델의 상이한 계층들이 가중치를 부여한 각각의 이미지의 상이한 영역들을 보여준다. 클래스 활성화 맵 또는 CAM은 모델이 사용자 인 터페이스에서 사용자들에게 시각적 피드백을 제공하기 위해 결함들의 진정한 표시자들을 학습하는 데 성공했는 지를 이해하기 위해 훈련 및 생성 동안 사용될 수 있다. 클래스 활성화 맵들은 입력 이미지 내의 모든 위치에 대해 계산된 특정 출력 클래스와 관련된 점수들의 2D 그리드들이다. 이들은 입력 이미지가 각각의 클래스를 얼 마나 강하게 활성화했는지를 보여주므로, 이미지의 어느 부분들이 네트워크로 하여금 그의 최종 분류 결정을 내 리게 했는지를 이해하는 것을 돕는다. 단계 222에서, 시스템은 이미지들을 히트맵들 또는 CAM들로서 출력할 수 있으며, 각각의 히트맵은 픽셀들에게 예측 클래스의 활성화에서의 그들의 중요도에 비례하여 컬러들을 할당한다. 각각의 이미지의 상대적으로 더 밝 은 컬러들은 네트워크가 그것의 최종 분류 결정을 내리게 한 이미지의 부분들을 나타내는 위치들을 나타낸다. 대안적으로 또는 추가적으로, 각각의 출력 CAM 이미지는 네트워크가 그것의 최종 분류 결정을 내리게 한 이미지 의 영역 또는 영역들 위에 정사각형, 원형 또는 직사각형 형상과 같은 윤곽선 또는 경계 상자로 라벨링될 수 있 다. 출력 CAM을 사용하는 것은 알고리즘이 각각의 결함 카테고리 또는 분류에 대해 올바른 예측자들을 학습하 고 있는지를 평가하는 데 도움이 될 수 있다. AI 네트워크의 최종 분류 또는 출력은 \"양호한 렌즈\"를 분류로서 포함하므로, \"결함 영역\"이라는 용어는 컨볼루션 계층들이 분석하여 모델의 최종 분류에 고려한 영역을 광범위 하게 의미하는 것으로 이해되며, 버블 또는 스크래치와 같은 물리적 결함을 갖는 렌즈, 또는 물리적 결함이 없 는 양호한 렌즈를 포함할 수 있다. 생성 동안, 생성된 렌즈의 이미지들은 프로세스를 통해 이제 훈련된 CNN 모델에서 분석될 수 있다. 단계 230에서, 생성 렌즈들을 이미징하며, 이는 검사될 각각의 렌즈의 렌즈 에지 이미지 및 렌즈 표면 이미지를 이미 징하는 것을 포함한다. 이어서, 단계 232에서, 이러한 이미지들이 전처리되고, 전처리된 이미지들은 CNN 모델 에 대한 입력 이미지들의 역할을 한다. 전처리의 목적은 분류 문제의 복잡성, 및 이미지의 폭 및 높이와 같은 입력의 공간을 감소시켜 예측 지속기간을 줄이는 것이다. 모델에 입력된 이미지들은 단계 212에서 컨볼루션 및 풀링 계층들을 사용하여 이미지들을 처리하는 모델에 의해 분석된다. 이어서, 이러한 계층들로부터의 출력은 완전 연결된 계층들에 공급되어 단계 216에서 이미지에 대한 데이터를 상이한 결함 클래스들 중 하나로 분류한 다. 단계 218에서, 모델은 아래에 더 설명되는 바와 같이 이미지를 양호, 스크래치, 버블 등으로 분류하는 것 과 같이, 분석된 이미지의 최종 분류를 출력한다. 이제 도 5를 참조하면, 표면 및 에지 이미지들이 생성될 수 있는 템플릿들을 수동으로 생성하기 위한 프로세스 가 도시되어 있다. 템플릿 생성 프로세스는 이미지들의 임의의 전처리(208, 232)를 수행하기 전에 선호된다. 템플릿들은 다수의 이미지 획득 디바이스 또는 카메라(도 1)에 의해 촬영된 이미지들의 잠재적 변화들을 정규화하기 위한 수단의 역할을 한다. 예를 들어, 8개의 카메라를 이용하여 렌즈 에지 이미지들을 캡 처하고 8개의 카메라를 이용하여 렌즈 표면 이미지들을 캡처하는 경우, 카메라들과 렌즈들의 지지대들로 사용되 는 사파이어들 사이의 거리에는 약간의 차이들이 있을 수 있다. 이러한 차이들은 렌즈가 16개의 카메라에 걸쳐 일관되지 않고 몇 픽셀 더 크거나 작게 보이게 할 수 있다. 템플릿 생성 프로세스는 단계 242에서 표면 또는 에지 이미지일 수 있는 원시 이미지로부터 시작한다. 이 어서, 단계 244에서, 이미지를 수동으로 크로핑하여 관심 영역(ROI)을 강화하고 이미지의 덜 중요한 주변 영역 들을 삭제한다. 이어서, 크로핑된 이미지에 대해 강도 분석을 수행하여 렌즈의 블롭 또는 렌즈의 에지 윤곽을 격리하기 위한 적절한 임계값들을 결정한다. 단계 246에서, 이미지의 수평 중심선의 강도 프로파일이 플로팅되 고, 단계 248에서, 이미지의 수직 중심선의 강도 프로파일이 플로팅된다. 단계 250에서, 단계 246 및 248의 임계값들을 사용하여 이미지를 임계화한다. 즉, 단계 250에서 렌즈의 블롭 또는 윤곽을 나타내는 임계값들을 격리하여 렌즈의 블롭을 정의한다. 이어서, 단계 252에서 렌즈의 윤곽 주위 에 타원을 피팅하고, 그의 중심 좌표들, 축들의 길이들, 및 배향 각도를 전처리 동안 판독될 텍스트 파일, 예를 들어 \"csv\" 파일에 기입한다. 단계 252에서 형성된 이미지 템플릿, 이미지들을 캡처하는 데 사용된 다른 카메라들(도 1)에 대해 개발된 유사한 이미지 템플릿들, 및 템플릿에 대해 개발된 좌표들을 동일한 카메라 로 촬영된 이미지들에 적용하여 본 발명의 CNN 모델들과 함께 사용하기 위한 입력 데이터의 균일성 및 일관성을보장할 수 있다. 이제 도 6을 참조하면, 표면 이미지들을 전처리하기 위한 프로세스가 도시되어 있다. 전처리 프로세스 는 본 발명의 렌즈 검사 시스템에 의해 검사될 각각의 이미지에 적용되어 분류 문제의 복잡성과 입력의 공 간을 감소시킴으로써, CNN 모델의 훈련 및 예측 지속기간과 훈련에 필요한 이미지들의 수를 감소시킬 수 있다. 전처리 프로세스는 단계 262에서 이미지 내에서 콘택트 렌즈를 찾는 것으로부터 시작한다. 본 명세서에서 사용되는 이미지는 훈련 이미지 또는 생성 이미지일 수 있으며, 이는 광학 교정들을 위해 사용자가 착용하기 위 해 생성된 렌즈의 이미지로 이해된다. 템플릿 매칭을 사용하여 원본 이미지 내에서 훈련 이미지 또는 생성 이 미지의 렌즈 중심을 찾는다. 템플릿 이미지는 도 5의 템플릿 프로세스에 의해 획득된다. 일례로, 이미지 의 좌상 코너에 대한 렌즈의 중심의 위치는 전처리 중에 획득된다. 단계 264에서, 이미지는 각각의 변이 900 픽셀과 동일한 정사각형 이미지를 생성하도록 크로핑되고, 관심 영역 (ROI)이 정사각형 이미지에 대해 중앙에 위치하거나, 또는 이미지는 정사각형 형상 이미지가 렌즈의 중앙에 위 치하도록 크로핑될 수 있다. 일례로, 렌즈의 반경이 450 픽셀 미만이라는 관찰에 기초하여 ROI의 폭과 높이 모 두에 대한 900 픽셀 값을 경험적으로 선택할 수 있다. 이어서, 단계 266에서, 크로핑된 이미지의 각각의 픽셀의 강도가 반전되며, 이는 더 밝은 음영들이 더 어둡게 보이고 더 어두운 음영들이 더 밝게 보이도록 이미지를 변경한다. 반전은 높은 강도들의 픽셀들이 선택되고 모 델의 후속 계층들로 이월되는 반면 어두운 픽셀들이 폐기될 수 있게 한다. 본 명세서에서 설명하는 분류 프로 세스에 의미 있는 정보를 나타내는 결함들을 나타내는 픽셀들은 일반적으로 어둡기 때문에, 원본 이미지의 강도 들을 반전시키는 것은 네트워크에 걸친 결함들의 신경망의 더 깊은 계층들로의 확산을 돕는다. 또한, CNN 모델 은 컬러 이미지들을 처리하도록 프로그래밍되므로, 단일 채널을 나타내는 단계 266에서의 반전된 이미지는 RGB 컬러들을 나타내기 위해 3중으로 재생되며, 이는 단계 268에서 3채널 이미지가 획득되게 한다. 단일 채널의 콘 텐츠를 2개의 추가 채널에 복제함으로써 모델에 대한 컬러 입력 요건이 인위적으로 충족된다. 전처리 프로세스 은 본 발명의 렌즈 검사 시스템에 의해 분석될 각각의 렌즈 표면 이미지에 대해 반복된다. 이제 도 7을 참조하면, 렌즈 에지 이미지들을 전처리하기 위한 프로세스가 도시되어 있다. 전처리 프로세 스는 도 6의 단계 262에서의 프로세스와 유사하게 단계 272에서 이미지 내에서 렌즈를 찾는 것으로부터 시 작한다. 템플릿 매칭을 사용하여 원본 이미지 내에서 훈련 이미지 또는 생성 이미지의 렌즈 중심을 찾는다. 일례로, 이미지의 좌상 코너에 대한 렌즈의 중심의 위치가 전처리 중에 획득된다. 다음으로, 단계 272에서, 렌즈의 이미지가 직교 좌표계에서 극좌표계로 변환된다. 극좌표는 렌즈 에지를 수직 컬러 구배에 접하는 영역들로서 강조하며, 이는 극좌표에서 더 자명하다. 에지 이미지는 에지 안쪽과 바깥쪽을 향하는 몇몇 픽셀과 같은 에지 주변의 좁은 영역에만 초점이 맞춰진 정보를 포함하므로, 좌표계를 변경하는 것 은 렌즈 에지의 ROI를 간단하게 줄일 수 있다. 900x900 픽셀의 렌즈 ROI로부터, CNN 모델에 대한 입력은 900 픽셀 x 50 픽셀로 감소될 수 있다. 도 8은 직교 좌표의 이미지 및 극좌표로 변환된 동일 이미지를 도시한다. 단계 276에서, 도 9에 도시된 바와 같이, 극좌표 이미지로부터 에지의 안쪽과 바깥쪽을 향하는 미리 결정된 영 역이 크로핑된다. 이 단계는 유지해야 할 이미지의 크로핑된 부분이 타겟 이미지 내부의 렌즈의 정확한 위치 파악과 관련이 있기 때문에 민감하다. 템플릿 이미지의 렌즈 크기와 타겟 이미지의 렌즈 크기 간에 불일치들은 결정된 중심이 렌즈의 실제 중심과 약간 상이하게 할 수 있다. 이어서, 이것은 에지의 프로파일이 크로핑된 ROI 이미지 내에서 핀치드 렌즈의 프로파일처럼 보이거나 그것으로부터 부분적으로 제외되게 할 수 있다. 다음으로, 단계 278에서, 각각의 픽셀의 이미지 강도가 반전된다. 이러한 반전은 도 10에 도시된 바와 같이 단 일 채널을 나타내는 흑백 이미지를 생성한다. CNN 모델이 컬러 이미지들을 처리하도록 프로그래밍되므로, 단계 278에서의 반전된 이미지는 RGB 컬러들을 나타내기 위해 3중으로 재생되며, 이는 단계 279에서 3채널 이미지를 갖게 한다. 전처리 프로세스은 예측을 위해 CNN 모델에 공급될 각각의 렌즈 에지 이미지에 대해 반복된다. 이제 도 11을 참조하면, 2개의 컨볼루션 계층, 2개의 풀링 계층 및 완전 연결된 계층(FCL)를 포 함하는 본 발명의 양태들에 따른 단순화된 컨볼루션 신경망이 도시되어 있다. 상이한 계층들은 2개의 컨 볼루션 블록(블록 1 및 블록 2)으로 그룹화될 수 있으며, 각각의 블록은 하나의 컨볼루션 계층 및 하나의 풀링 계층을 포함한다. 본 발명에서는 12개 이상의 계층, 예를 들어 16개 계층, 19개 계층 또는 그 이상의 계층을 포함하는 보다 정교한 CNN 모델들을 이용하여 상이한 결함 카테고리들을 갖는 렌즈 이미지들을 분석하고 특성화한다. 도 11의 단순화된 CNN 모델과 달리, 본 발명의 CNN 모델들은 다수의 컨볼루션 블록을 포함할 수 있으며, 각각의 블록은 1개보다 많은 컨볼루션 계층, 예컨대 2개 이상의 컨볼루션 계층, 3개 이상의 컨볼루션 계층 또는 4개 이상의 컨볼루션 계층을 가질 수 있다. 본 발명의 CNN 모델들은 상이한 렌즈 결함 카테고리들을 분류하고, 옵션으로서 라벨링된 중간 활성화 이미지들을 생성하도록 훈련된다. 본 발명의 예시적인 실시예들에서, 선택된 모델은 도 11의 CNN 모델과 유사하지만 26개의 계층을 갖는 컨볼루션 신경망(CNN)이다. 도 12는 CNN의 \"표면\" 모델인 선택된 모델의 개념적 블록들을 도시한다. 모델의 제1 계층은 형상(900, 900, 3)을 갖는 입력 계층을 나타낸다. 따라서, 모델은 RGB 이미지와 동일한, 900픽셀의 높이, 900 픽셀의 폭, 및 3개의 채널을 갖는 이미지들만을 입력으로 수신할 것이다. 도 6의 단계 268 및 도 7의 단계 279 를 참조하여 위에서 설명한 바와 같이, 본 데이터 세트들의 그레이스케일 이미지들은 모델의 3채널 입력 요건을 충족시키기 위해 각각의 이미지를 복제하여 동일한 이미지 3개를 생성함으로써 인위적으로 확장되었다. 모델의 다음 21개의 계층은 블록 1 내지 블록5로 그룹화되며, 잘 알려진 VGG19 CNN 모델로부터 추출되었다. 원 래의 VGG19 모델은 224x224x3의 입력 형상을 가지며 1000개의 상이한 클래스에 대한 예측 확률들을 출력하는 ImageNet 데이터 세트에 대해 사전 훈련되었다. 본 발명에서는 사전 훈련된 VGG19 모델의 최상위 계층들을 삭 제하여, 모델이 원래 훈련된 것과 상이한 수의 클래스 또는 카테고리에 대한 그리고 입력 이미지의 상이한 형상 에 대한 재훈련을 가능하게 했다. 이러한 21개의 계층은 개념적으로 5개의 블록으로 그룹화되며, 각각의 블록은 여러 개의 컨볼루션 계층으로 구 성되고 블록 내의 마지막 계층은 풀링 계층이다. 예를 들어, 블록 2는 2개의 컨볼루션(block2_conv1 및 block2_conv2)과 하나의 풀링(block2_pool)으로 구성된다. 5개의 블록은 모델의 컨볼루션 베이스를 나타낸다. 컨볼루션 블록들의 끝에는, 평탄 계층(flatten_1) 및 2개의 밀집 연결된 계층(dense_1 및 dense_2)이 추가되었 다. 평탄 계층은 풀링된 전체 특징 맵 행렬을 단일 열로 변환한 다음에 처리를 위해 신경망에 공급하는 것을 수반한다. 평탄 계층은 컨볼루션 계층과 클래식 NN 계층들 사이에서 전이를 수행하며, 클래식 NN 계층들은 계 층의 각각의 뉴런이 그의 이전 및 후속 계층들의 각각의 뉴런과 연결되기 때문에 밀집 연결된 계층들로 지칭된 다. flatten_1의 입력은 512 채널 28x28 이미지이며, 이는 401408(512x28x28) 벡터로 변환된다. 2개의 밀집 연결된 계층은 완전 연결된 계층이라고도 한다. dense_1 계층은 벡터를 256개의 뉴런으로 줄이고, dense_2는 그것을 8개로 더 줄이며, 8개는 도 17-24에 도시된 바와 같이 모델이 분류할 수 있는 렌즈 표면 결함 들에 대한 클래스들의 수를 나타낸다. 도 13은 도 12와 유사하지만 \"에지\" 모델의 개념적 블록들을 도시한다. \"에지\" 모델의 아키텍처는 \"표면\" 모델 의 아키텍처와 동일하다. 하지만, 입력 이미지 형상과 클래스 수가 상이하기 때문에 각각의 계층의 입력 및 출 력 형상들이 상이하며, 따라서 훈련 가능한 파라미터들의 수도 상당히 상이하다. \"에지\" 모델의 2개의 밀집 연 결된 계층은 벡터를 256개의 뉴런으로 줄이는 dense_1 계층을 포함하고, dense_2는 그것을 3개로 더 줄이며, 3 개는 모델이 분류할 수 있는 렌즈 \"에지\" 결함들에 대한 클래스들의 수를 나타낸다는 점에 유의한다. 훈련 동안, 컨볼루션 신경망, 더 구체적으로는 VGG16 및/또는 VGG19 모델일 수 있는 소스 모델의 컨볼루션 베이 스 또는 후속 계층들은 사전 훈련된 가중치들로 미리 초기화될 수 있다. Keras 라이브러리로부터 렌즈 결함들 을 분류하는 데 사용할 수 있는 다른 모델들은 Xception, ResNet50, InceptionV3을 포함한다. 밀집 연결된 계 층들은 무작위로 초기화될 수 있다. 컨볼루션 베이스의 가중치들은 훈련 중에 프리징될 수 있으므로 새 모델이 훈련될 때 업데이트되지 않는다. 각각의 CNN 계층은 점점 더 복잡해지는 필터들을 학습한다. 제1 계층들은 에 지들, 코너들 등과 같은 기본적인 특징 검출 필터들을 학습한다. 중간 계층들은 객체들의 부분들을 검출하는 필터들을 학습한다. 일례로, 얼굴들에 대해, 그들은 눈들, 코들 등에 응답하도록 학습할 수 있다. 마지막 계 층들은 더 높은 표현을 갖는다. 그들은 상이한 형상들, 위치들, 및 카테고리들의 전체 객체들을 인식하도록 학 습한다. 도 14는 전사 훈련에 사용되는 설정들을 도시한다. 렌즈 \"표면\" 분석을 위한 모델 훈련에 총 3,973개의 이미지 가 사용되었다. 훈련은 500개의 에포크 또는 단계에 대해 수행되었다. 각각의 에포크 동안, CNN 모델은 상이 한 훈련 데이터 세트로 다시 훈련되거나 동일한 데이터 세트로 훈련될 수 있어서, 데이터의 특징들에 대해 계속 학습할 것이다. 이어서, 훈련은 확인 세트에 의해 확인된다. 확인 세트는 훈련 세트와 별개이고 훈련 중에 모 델을 확인하는 데 사용되는 데이터의 세트이다. 이러한 확인 프로세스는 모델의 파라미터들을 조정하는 데 도 움이 될 수 있는 정보를 제공한다. 일 실시예에서, 모델은 또한 확인 세트의 데이터에 대해 동시에 확인된다. 훈련 프로세스 동안, 모델은 훈련 세트의 각각의 입력에 대한 출력을 분류할 것이다. 이러한 분류가 발생한 후, 손실 값이 계산되고, 모델의 가중치들이 조정될 수 있다. 이어서, 다음 에포크 동안, 모델은 다음 훈련 세 트에 대한 입력을 다시 분류할 것이다. 모델은 확인 세트로부터의 각각의 입력도 분류할 것이다. 모델은 그가 훈련 세트에서 훈련되고 있는 데이터에 대해 학습한 내용에만 기초하여 분류를 수행할 수 있다. 확인 세트를 사용하는 이유들 중 하나는 모델이 훈련 세트의 데이터에 오버피팅되지 않는 것을 보장하는 것이다. 훈련 동안, 모델이 확인 세트로 확인되고, 확인 데이터에 대한 결과들이 모델이 훈련 데이터에 대해 제공하는 결과들을 따름에 따라, 모델이 오버피팅되지 않는다는 높은 신뢰가 존재한다. 반면에, 훈련 데이터에 대한 결과들이 정말 양호하지만, 확인 데이터에 대한 결과들이 열악할 경우, 모델이 오버피팅될 확률이 높다. 전사 학습은 하나의 문제에 대해 구축된 모델을 일부 인자들에 기초하여 다른 문제에 재사용하는 프로세스이다. 일례로, VGG16 Net 및 VGG19 Net과 같은 VGG 네트워크는 렌즈 결함들의 유형들을 분석하고 분류하도록 훈련된다. 도 14a는 본 발명의 CNN 모델들에 대한 예시적인 전사 훈련 프로토콜을 묘사하는 흐름도로서, 이는 일반적으로 320으로 지정된다. 단계 322에서, 모델은 렌즈 결함들을 분석하고 분류하기 위해 개발된 컨볼루션 및 밀집 계층들을 갖는 사전 훈련된 컨볼루션 베이스로부터 구축될 수 있다. 다음으로, 단계 324에서, 사전 훈 련된 베이스는 로킹되거나 프리징되며, 모델의 나머지, 즉 상이한 신경 계층들은 무작위로 초기화된다. 일부 예들에서는 1-4개의 컨볼루션 계층과 같은 몇 개의 계층만이 한 번에 초기화된다. 단계 326에서, 모델은 학습 률 learn_rate1로 훈련된다. 바람직하게, 학습률은 모델이 빠르게 변하고 훈련해제 또는 재훈련이 어려울 수 있을 정도로 빠르지는 않다. 이어서, 단계 328에서, 모델의 제1 프리징된 계층 위의 모든 계층이 언로킹되거나 언프리징된다. 이어서, 단계 330에서, 모델은 더 낮은 학습률 learn_rate2로 재훈련된다. 단계 330에서 모델 이 재훈련된 후, 단계 332에서, 유지된 모델의 결과들 또는 성능이 평가된다. 도 15와 관련하여 설명된 바와 같은 정확도, 도 16과 관련하여 설명된 바와 같은 손실 함수, 도 28과 관련하여 설명된 바와 같은 예측 대 실측 자료 및/또는 도 29와 관련하여 설명된 바와 같은 정밀도 및 리콜 값들과 같은 인자들로부터 결과들이 만족스러 운 경우, 훈련은 단계 336에서 중지될 수 있다. 재훈련된 모델이 언급된 인자들에 비해 여전히 평균 이하를 수 행하고 있는 경우, 훈련은 단계 324에서 시작하여 반복될 수 있다. 추가 재훈련을 위해 단계들이 반복되는 경 우, 단계 328로부터의 계층만이 변경되어 계층별로 모델의 루트를 향한다. 성능이 저하되기 시작하는 지점이 있다. 훈련 데이터 세트의 이미지들의 수를 늘려도 모델의 성능이 개선되지 않으면 단계 336에서 재훈련을 종 료할 수 있다. 도 15는 훈련 데이터 세트(좌측 그래프)와 확인 데이터 세트(우측 그래프) 모두에 대한 500개의 에포크에 걸친 훈련 기간 동안의 정확도의 변화를 도시한다. 위에서 설명한 바와 같이, 모델은 확인 데이터 세트로 확인되고, 확인 데이터 세트에 대한 결과들은 일반적으로 모델이 훈련 데이터 세트에 대해 제공하는 결과들을 따른다. 도 15는 여러 번의 훈련 반복 동안 획득된 예이지만, 반드시 최종 또는 최상 정확도는 아니다. 정확도는 분류 모 델들을 평가하기 위한 하나의 메트릭이다. 정확도는 모델이 정확하게 획득한 예측들의 비율이다. 정확도는 정 확한 예측들의 수를 총 예측 수로 나눈 값으로 계산될 수 있으며, 1은 완벽하게 정확하다. 도 16은 훈련(좌측 그래프) 및 확인(우측 그래프) 데이터 세트들에 대한 훈련 에포크들에 걸친 손실 함수 값의 값들을 도시하는 그래프들이다. 손실 함수의 출력은 기계 학습 알고리즘을 최적화하는 데 사용될 수 있다. 손 실 함수는 예상 결과 예측 가능성 면에서 모델이 얼마나 양호한 예측을 수행하고 있는지에 대한 측정치로 사용 될 수 있다. 손실은 훈련 및 확인 동안 계산되며, 그 해석은 모델이 이 두 세트에서 얼마나 양호하게 수행하고 있는지에 기초한다. 이는 훈련 또는 확인 데이터 세트들에서 각각의 예에 대해 발생한 에러들의 합이다. 손실 값은 최적화의 각각의 반복 후에 모델이 얼마나 불량하게 또는 양호하게 거동하는지를 암시한다. 이는 0 내지 1의 확률 값을 출력으로 하는 분류 모델의 성능을 측정한다. 크로스-엔트로피 손실은 예측 확률이 실제 라벨과 차이가 날수록 증가한다. 따라서, 예를 들어 실제 관찰 라벨이 1일 때 0.023의 확률을 예측하는 것은 좋지 않 을 것이고, 높은 손실 값을 초래할 것이다. 완벽한 모델은 0의 로그 손실을 가질 것이다. 도 17 내지 도 24는 본 발명의 AI 모델들, 예컨대 CNN 모델들이 검출 및 출력하도록 훈련되는 상이한 렌즈 표면 결함 유형들, 카테고리들 또는 클래스들을 도시한다. 도 17로부터 시작하여, 이미지는 \"브레이닝(braining)\" 또는 \"브레인\" 표면 결함 패턴을 도시하고, 도 18은 \"버블\" 결함 패턴을 도시하고, 도 19는 \"파편\" 패턴을 도시 하고, 도 20은 콘택트 렌즈를 지지하는 지지 구조(도 1)에 사용되는 크리스탈인 \"더티 사파이어\" 패턴을 도시한다. 도 21은 \"더블 렌즈\" 결함 패턴을 도시하고, 이는 2개의 렌즈가 동일한 지지대 상에 배치되는 경우 이며, 도 22는 \"양호한\" 렌즈 표면 이미지(따라서 물리적 결함들이 없거나 최소인 렌즈)를 도시하고, 도 23은 \"스크래치\" 표면 결함 패턴을 도시하고, 도 24는 \"보이드\" 표면 결함 패턴을 도시한다. 본 발명의 CNN 모델들과 같은 AI 모델들이 상이한 렌즈 표면 결함들에 대해 출력할 수 있는 결함 클래스들은 텍 스트 대신에 숫자들로 또는 숫자들을 사용하여 지정될 수 있다. 예를 들어, \"브레인들\"은 \"0\"과 같은 정수 (whole integer)를 갖는 클래스로 지정될 수 있고, \"버블\"은 \"1\"과 같은 정수를 갖는 클래스로 지정될 수 있고, \"파편\"은 \"2\"와 같은 정수를 갖는 클래스로 지정될 수 있고, \"더티 사파이어\"는 \"3\"과 같은 정수를 갖는 클래스 로 지정될 수 있고, \"더블 렌즈\"는 \"4\"와 같은 정수를 갖는 클래스로 지정될 수 있고, \"양호한 렌즈\"는 \"5\"와 같은 정수를 갖는 클래스로 지정될 수 있고, \"스크래치\"는 \"6\"과 같은 정수를 갖는 클래스로 지정될 수 있고, \"보이드\"는 \"7\"과 같은 정수를 갖는 클래스로 지정될 수 있다. 다른 예들에서, 클래스들에 대한 숫자들은 바 뀔 수 있고, 표시된 것과 상이한 값을 할당받을 수 있다. 예를 들어, \"스크래치\"는 \"6\" 대신 \"2\"의 정수를 갖 는 클래스로 지정될 수 있다. 또 다른 예들에서, AI 모델들이 상이한 렌즈 표면 결함들에 대해 출력할 수 있는 결함 클래스들은 렌즈 표면 결함 \"버블\"에 대한 LS1과 같은 영숫자 식별자를 사용하여 지정될 수 있다. 도 25 내지 도 27은 본 발명의 CNN 모델들과 같은 AI 모델들이 검출 및 출력하도록 훈련되는 상이한 렌즈 에지 결함 유형들, 카테고리들 또는 클래스들을 도시한다. 도 25로부터 시작하여, 이미지는 \"파편\" 에지 결함 패턴 을 도시하고, 도 26은 \"양호한 렌즈\" 에지 이미지(따라서, 결함이 없음)를 도시하고, 도 27은 \"핀치드\" 에지 결 함 패턴을 도시한다. AI 모델들이 상이한 렌즈 에지 결함들에 대해 출력할 수 있는 결함 클래스들은 텍스트 대 신 숫자들로 또는 숫자들을 사용하여 지정될 수 있다. 예를 들어, \"파편\"은 \"20\"과 같은 정수를 갖는 클래스를 지정될 수 있고, \"양호한 렌즈\"는 \"21\"과 같은 정수를 갖는 클래스로 지정될 수 있으며, \"핀치드\"는 \"22\"와 같 은 정수를 갖는 클래스로 지정될 수 있다. 다른 예들에서, 클래스들에 대한 숫자들은 바뀔 수 있고, 표시된 것 과 상이한 값을 할당받을 수 있다. 예를 들어, \"파편\"는 \"20\" 대신 \"50\"의 정수를 갖는 클래스로 지정될 수 있 다. 또 다른 예들에서, AI 네트워크들이 상이한 렌즈 에지 결함들에 대해 출력할 수 있는 결함 클래스들은 렌 즈 표면 결함 \"파편\"에 대한 LE20과 같은 영숫자 지정 또는 식별자를 사용하여 지정될 수 있다. 일례로, 훈련 및 확인 데이터 세트들은 2개의 이미지 그룹, 즉 렌즈 표면 이미지들만을 포함하는 이미지 그룹과 렌즈 에지 이미지들만을 포함하는 이미지 그룹으로 분리된다. CNN \"표면\" 모델들의 훈련 및 확인을 위한 데이 터 세트들은 렌즈 표면 이미지들만을 포함하는 반면, CNN \"에지\" 모델들의 훈련 및 확인을 위한 데이터 세트들 은 렌즈 에지 이미지들만을 포함한다. 일례로, 렌즈 표면 이미지 데이터 세트들은 \"브레인들\", \"버블\", \"파 편\", \"더티 사파이어\", \"더블 렌즈\", \"양호한 렌즈\", \"스크래치\" 및 \"보이드\"를 포함하는 8개의 결함 유형 카테 고리를 포함하는 도 17-24에 도시된 결함 유형들을 갖는 복수의 이미지를 포함한다. 그러나 표면 모델들은 8개 보다 많거나 적은 표면 결함 유형에 대해 훈련될 수 있다. 예를 들어, 표면 모델들은 렌즈를 갖지 않는 이미지 들, 너무 작은 렌즈를 갖는 이미지들, 너무 큰 렌즈를 갖는 이미지들 및/또는 너무 편심인 렌즈를 갖는 이미지 들로 훈련될 수 있다. 일례로, 렌즈 에지 이미지 데이터 세트들은 \"파편\", \"양호한 렌즈\" 및 \"핀치드\"를 포함하는 3개의 결함 유형 카 테고리를 포함하는 도 25-27에 도시된 결함 유형들을 갖는 복수의 이미지를 포함한다. 그러나 에지 모델들은 3 개보다 많거나 적은 에지 결함 유형에 대해 훈련될 수 있다. 예를 들어, 에지 모델들은 렌즈를 갖지 않는 이미 지들, 너무 작은 렌즈를 갖는 이미지들, 너무 큰 렌즈를 갖는 이미지들 및/또는 너무 편심인 렌즈를 갖는 이미 지들로 훈련될 수 있다. 도 28은 훈련 데이터 세트들에 대한 예측 대 실측 자료에 대한 표 포맷의 목록들을 도시한다. 좌측에는 실측 자료가, 우측에는 모델의 예측이 라벨링되어 있다. 실측 자료들로 라벨링된 이미지들은 사람의 검증 또는 검사 를 통해 확인된 결함들을 나타낸다. 예를 들어, 전처리된 또는 원본 이미지들이 개별적으로 수동으로 검사된 다음, 하나 이상의 결함 분류로 각각 라벨링될 수 있다. 일례로, 결함 분류들은 각각의 이미지 데이터 파일의 파일 이름의 일부로서 저장된다. 원본 이미지들의 경우, 이미지에 대해 수동으로 식별된 각각의 결함 유형은 각각의 분류 폴더들에 개별적으로 저장된다. 렌즈 에지 이미지 및 렌즈 표면 이미지와 같은 2개의 이미지 유형 은 렌즈 에지 결함 유형들 및 렌즈 표면 결함 유형들로 분류될 수 있고, 이미지들이 특정 이미지 유형 및 특정 결함 유형인지에 따라 별개로 저장될 수 있다. 큰 피사계 심도 및 큰 조리개 또는 큰 f 수를 갖는 이미징 시스 템으로 이미지가 촬영되고, 이미지가 초점이 맞춰진 렌즈 에지와 렌즈 표면 모두를 갖는 경우, 동일한 이미지가 수동으로 평가되고, 렌즈 에지 결함들 및 렌즈 표면 결함들 모두로 분류될 수 있다. 이러한 제3 이미지 카테고 리는 상이한 실측 자료 카테고리로서 별개로 저장될 수 있다. 이어서, 이러한 분류 및 카테고리화된 이미지들은 훈련, 확인 및 테스트 세트들이 선택되는 이미지들의 풀에 추 가될 수 있다. 따라서, 적어도 일부 이미지들, 바람직하게는 훈련, 확인 및 테스트에 사용되는 모든 이미지들 을 먼저 결함 유형들에 대해 검사한 다음, 수동 평가를 거쳐 이들을 렌즈 표면 결함 유형들 또는 클래스들, 또 는 렌즈 에지 결함 유형들 또는 클래스들, 또는 렌즈 표면 결함 및 렌즈 에지 결함 유형들 또는 클래스들 모두 로 분류할 수 있다. 일례로, 확인 동안, \"스크래치\"로 라벨링된 이미지를 폴더에서 가져와 \"버블\" 분류를 반환하는 AI 모델에 공급하면, 에러가 즉시 알려질 것이다. 도 28의 표 포맷으로 도시된 바와 같이, \"브레인\", \"버블\", 및 \"보이드\" 표면 결함 패턴들의 경우, 모델의 예측 은 수동으로 분류된 전처리된 이미지들에 비해 100% 정확하고, 실측 자료로 간주된다. \"파편\" 및 \"스크래치\" 표면 결함 패턴들의 경우, 모델의 예측은 우수하고, 100%에 가깝다. 모델은 \"양호한 렌즈들\"을 예측하는 데에 도 양호하게 작동한다. \"더티 사파이어\" 및 \"더블 렌즈\" 결함 패턴들의 경우, 도 29를 참조하여 아래에서 설명 하는 바와 같이 모델은 덜 우수하지만 여전히 양호한 점수를 받는다. 그럼에도 불구하고, 아래에서 더 설명하 는 바와 같이 모델을 재훈련하거나 미세 조정하여 개선할 수 있다. 도 29는 도 28의 훈련 데이터 세트에 대한 표면 모델의 성능 메트릭들을 나타내기 위해 표 포맷으로 목록화된 데이터를 도시한다. 메트릭들은 약어들을 사용하여 다음과 같은 정의들을 갖는 상이한 측정치들을 나타낸다: a. 참 양성들(true positives: TP)의 카운트는 클래스 A에 속하는 인스턴스들 중에서 해당 클래스에 속하는 것으로 올바르게 분류된 인스턴스들의 수이고; b. 거짓 양성들(false positives: FP)의 카운트는 클래스 A를 제외한 다른 클래스들에 속하는 인스턴스들 중에 서 클래스 A에 속하는 것으로 잘못 분류된 인스턴스들의 수이고; c. 거짓 음성들(FN)의 카운트는 클래스 A에 속하지만 다른 클래스들에 속하는 것으로 잘못 분류된 인스턴스들의 수이고; d. 참 음성들(TN)의 카운트는 클래스 A를 제외한 다른 클래스들에 속하는 인스턴스들 중에서 클래스 A로 분류되 지 않은 인스턴스들의 수이고; e. 정확도는 잘못 분류된 인스턴스들의 수에 대한 올바르게 분류된 인스턴스들의 수이며, 다음과 같이 계산된다: i. 정확도 = (TP + TN) / (TP + FP + TN + FN) f. 정밀도는 다음과 같이 정의되는 참 양성률이고: i. 정밀도 = TP / (TP + FP) ii. 잘못 검출된 인스턴스들의 수가 증가함에 따라 정밀도는 감소한다. \"양호한 렌즈\" 클래스에 대한 정밀도를 최적화하는 것은 검사 표준을 강화하는 것과 동등하므로 제품의 품질을 증가시킨다. g. 리콜은 다음과 같이 정의되는 참 양성률이고: i. 리콜 = TP / (TP + FN) ii. 누락된 인스턴스들의 수가 증가함에 따라 리콜은 감소한다. \"양호한 렌즈\" 클래스에 대한 리콜을 최적화하 는 것은 생성 수율을 높이는 것과 동등하다. 도 29는 \"양호한 렌즈\"에 대한 모델의 예측이 정밀도 카테고리에서 0.910점이고, 리콜 카테고리에서 0.994점인 것을 도시하며, 이러한 점수들은 모두 우수한 수치들이다. 그러나, 모델을 미세 조정하여 정밀도 수치를 훨씬 더 높은 수치로 개선하면, 검사 표준을 강화하여 \"양호한 렌즈\"의 폐기 수(number of disposals)를 줄일 것이다. 도 30은 \"에지\" 모델에 대한 훈련 데이터 세트에 대한 예측들 대 실측 자료들에 대한 표 포맷의 목록들을 도시 한다. 좌측에는 실측 자료가, 우측에는 모델의 예측이 라벨링되어 있다. 실측 자료들로 라벨링된 이미지들은 사람의 검증 또는 검사를 통해 확인된 결함들을 나타낸다. 표 포맷으로 도시된 바와 같이, \"핀치드\" 표면 결함 패턴의 경우, 모델의 예측은 100% 정확하다. 모델은 \"양호한 렌즈들\"을 예측하는 데 있어서도 양호하게 작동하 며, 100%에 가까운 점수를 받는다. \"파편\" 결함 패턴의 경우, 도 31을 참조하여 아래에서 설명하는 바와 같이 모델은 덜 우수하지만 여전히 양호한 점수를 받는다. 그럼에도 불구하고, 아래에서 더 설명하는 바와 같이, 모 델을 재훈련하거나 미세 조정하여 개선할 수 있다. 도 31은 도 30의 훈련 데이터 세트에 대한 \"에지\" 모델의 성능 메트릭들을 나타내기 위해 표 포맷으로 플로팅된 데이터를 도시한다. 메트릭들은 도 29를 참조하여 위에서 설명한 \"표면\" 모델의 측정치와 상이한 측정치들을 나타내기 위해 동일한 약어들을 사용한다. 도 31은 \"양호한 렌즈\"에 대한 모델의 예측이 정밀도 카테고리에서 0.92점이고, 리콜 카테고리에서 0.99점이라는 것을 도시하며, 이러한 점수들은 모두 우수한 수치들이다. 그러 나, 모델을 미세 조정하여 정밀도 수치를 훨씬 더 높은 수치로 개선하면, 검사 표준이 강화하여 \"양호한 렌즈\"의 폐기 수를 감소시킬 것이다. 확인 데이터 세트에 대한 표면 모델의 정확도는 훈련 데이터 세트에 대한 정확도와 비교하여 처음 150개의 에포 크 후에 매우 느린 속도로 증가한다. 이는 오버피팅의 표시일 수 있다. 표면 모델의 오버피팅의 다른 표시는 이미지에 결함이 두 개 이상 존재할 때 하나의 카테고리에서의 높은 신뢰도이다. 이는 드롭아웃 계층들을 추가 하고 훈련 데이터 세트를 증가시킴으로써 해결될 수 있다. 드롭아웃 기술은 훈련 동안 선택된 뉴런들을 무작위로 무시하는 것을 수반한다. 이는 다운스트림 뉴런들의 활 성화에 대한 그들의 기여가 포워드 패스에서 일시적으로 제거되고 임의의 가중치 업데이트들이 백워드 패스에서 뉴런에 적용되지 않는다는 것을 의미한다. 드롭아웃들은 모델에서 오버피팅을 방지하는 데 사용되는 규칙화 기 술이다. 드롭아웃들은 네트워크의 뉴런들 중 소정 비율을 무작위로 스위치 오프하기 위해 추가된다. 뉴런들이 스위치 오프될 때, 그러한 뉴런들에 대한 들어오고 나가는 연결들도 스위치 오프된다. 이는 모델의 학습을 향 상시키기 위해 수행될 수 있다. 컨볼루션 계층들 이후에는 드롭아웃들이 사용되지 않아야 한다. 드롭아웃들은 주로 네트워크의 밀집 계층들 또는 평탄 계층들 이후에 사용된다. 일례로, 한 번에 약 10% 내지 50%의 뉴런들 만이 스위치 오프된다. 한 번에 50% 넘게 스위치 오프되는 경우, 모델의 성향(leaning)이 열악하고, 예측들이 만족스럽지 못할 수 있다. 도 32는 도 12와 유사하며, 도 12의 VGG19 Net 모델 대신 VGG16 Net 모델을 사용하여 각각의 계층의 출력 형상 들과 함께 \"표면\" 모델의 개념적 블록들을 도시한다. 본 표면 모델의 아키텍처는 도 12의 표면 모델과 유사하 지만, 더 적은 계층을 갖는다. 도 33은 도 32의 모델에 추가된 드롭아웃 계층을 도시한다. 드롭아웃 계층은 네트워크의 뉴런들 중 소정 비율을 무작위로 스위치 오프하기 위해 추가될 수 있다. 뉴런들이 스위치 오프될 때, 그러한 뉴런들에 대한 들어오고 나가는 연결들도 스위치 오프된다. 이는 모델에 대한 학습을 향상시키기 위해 수행될 수 있다. 도 32는 도 12와 유사하며, 도 12의 VGG19 Net 모델 대신 VGG16 Net 모델을 사용하여 각각의 계층의 출력 형상 들과 함께 \"표면\" 모델의 개념적 블록들을 도시한다. 본 표면 모델의 아키텍처는 도 12의 표면 모델과 유사하 지만, 더 적은 계층을 갖는다. 도 33은 도 12의 모델에서 사용된 드롭아웃 계층을 도시한다. 드롭아웃 계층은 네트워크의 뉴런들 중 소정 비율을 무작위로 스위치 오프하기 위해 추가될 수 있다. 뉴런들이 스위치 오프될 때, 그러한 뉴런들에 대한 들어오고 나가는 연결들도 스위치 오프된다. 이는 모델 학습을 향상시키기 위해 수 행될 수 있다. 상이한 심층 신경망 모델들이 시도되고 훈련되었다. 또한, 모델들은 드롭아웃 계층들로 그리고 드롭아웃 계층 들 없이 훈련되었다. 도 34는 VGG19 Net 모델인 도 12의 모델에서 사용된 출력 계층 이전의 계층들을 도시한다. 모델은 드롭아웃 계층 없이 훈련되었다. 대신, 평탄화 동작 전에, VGG19 Net 모델 위에 다른 컨볼 루션 계층이 적용되었다. 일례로, CNN 모델들의 정밀도 및 리콜 값들을 개선하기 위해, 작업에 이용가능한 입력-출력 쌍 데이터를 조정하 거나 개선하는 미세 조정을 수행할 수 있다. 미세 조정은 CNN 아키텍처를 업데이트하고 이를 재훈련하여 상이 한 클래스들의 새로운 또는 상이한 특징들을 학습시키는 것을 포함할 수 있다. 미세 조정은 다단계 프로세스이 며, 다음 단계들: 네트워크의 끝(즉, 실제 클래스 라벨 예측들이 이루어지는 곳)에서 완전 연결된 노드들을 제거하는 단계; 완전 연결된 노드들을 새로 초기화된 노드들로 교체하는 단계; 모델이 학습한 임의의 이전의 강건한 특징들이 덮어쓰기 또는 폐기되지 않는 것을 보장하기 위해 네트워크 내의 더 이른 또는 최상위 컨볼루션 계층들을 프리징하는 단계; 특정 학습률로 완전 연결된 계층들만을 훈련하는 단계; 및 네트워 크 내의 컨볼루션 계층들의 일부 또는 전체를 언프리징하고, 상대적으로 더 낮은 학습률로 동일하거나 새로운 데이터 세트들로 추가 훈련을 수행하는 단계 중 하나 이상을 포함한다. 일례로, 미세 조정은 렌즈 에지 모델과 렌즈 표면 모델 모두에 대해 양호한 렌즈들에 대한 정밀도 및 리콜 값들을 개선하는 데 사용된다. 모델이 각각의 카테고리에 대한 올바른 예측자들을 학습하고 있는지를 평가하기 위해, 클래스 활성화 맵(CAM)들 이 사용될 수 있다. CAM들은 각각의 클래스에 대한 출력을 활성화한 이미지 영역들이 각각의 결함 카테고리와 관련되는 것을 보장하기 위해 사용될 수 있다. CAM들을 사용하는 것은 트레이너가 이미지에서 분류를 유발하는 결함이 발견된 곳을 시각화할 수 있게 한다. CNN 모델은 각각의 활성화 단계 이후에 최종 단계에 가까워질 때 까지 입력 이미지의 처리 효과를 시각화할 수 있으므로, 이러한 중간 단계들의 이미지들을 조작하여 네트워크의 능력과 예측의 이유에 대한 직관적인 표시를 제공할 수 있다. 이러한 시각적 표시자들은 트레이너에게 훈련과 예측이 얼마나 양호하게 거동하고 있는지에 대한 피드백을 제공하여 필요한 경우 모델을 미세 조정하거나 조정 할 수 있게 한다.중간 활성화들을 시각화하는 프로세스는 CNN의 하나 이상의 중간 컨볼루션 계층의 출력을 이미지들로서 생성하 는 것으로 구성된다. 이어서, 이러한 이미지들을 조작하여, 예를 들어 히트 활성화 맵들을 생성하고/하거나 이 미지들의 부분들에 윤곽선들 또는 마크들을 주석으로 첨부하여, 각각의 결함 카테고리와 관련된 출력을 활성화 한 이미지 영역들을 보여줌으로써 이미지들을 해석하는 방법에 관하여 트레이너를 도울 수 있다. 본 발명의 렌즈 검사 시스템과 함께 중간 활성화들 및 CAM들을 통합 또는 구현할 수 있는 방법을 보여 주기 위 해, 먼저 도 35를 참조한다. \"버블\" 표면 결함들의 3개의 예에 대한 전처리 단계에서 생성된 3개의 상이한 출 력이 도시되어 있으며, 버블 1, 버블 2 및 버블 3으로 주석이 첨부되어 있다. 도 3의 프로세스와 관련하여 설 명한 바와 같이, 이 이미지들은 CNN 모델에 대한 입력들을 나타내며, 각각 900x900 픽셀의 형상을 갖는다. 모 델에 대한 입력은 (900,900,3)의 형상을 가질 수 있으며, 여기서 숫자 \"3\"은 그레이스케일이 아니라 RGB 이미지 들에 대해 사전 훈련된 모델에 대한 채널들의 수를 나타낸다. 따라서, 그레이 채널을 다른 두 채널에 인위적으 로 복사함으로서, 그레이스케일 이미지들이 모델에 대한 입력으로 사용될 수 있다. 도 35로부터의 이미지들이 모델에 입력되고 상이한 컨볼루션 계층들(예를 들어, 도 12의 블록 1 또는 블록 2)을 통과한 후, 이러한 계층들로부터의 출력을 이미지들로서 볼 수 있다. 이제 도 36a, 36b 및 36c를 참조하면, 도 35의 3개의 입력 이미지에 대한 제1 컨볼루션 블록(\"블록 1\")의 제1 컨볼루션 동작(\"conv1\")의 64 채널-출력 간 의 비교가 도시되어 있다. 제1 컨볼루션 동작(\"conv1\")은 CNN 모델 내부의 제1 처리 단계를 나타낸다. 64개 채널 각각의 출력은 900x900 픽셀의 이미지 형상을 갖는다. 이 이미지들은 모델이 훈련되는 동안 또는 생성 이 미지들의 경우 모델이 클래스 카테고리를 예측하는 동안 CNN 모델이 무엇을 보고 있는지를 보여준다. 이미지들 은 개발자와 트레이너에게 통찰력들을 제공하며, 이는 모델의 효과와 수율에 매우 중요할 수 있다. 개발자와 트레이너는 CAM들을 사용하여, 모델이 이미지에서 어느 영역을 보고 있었는지 알 수 있으며, 이를 바탕으로 모 델의 편향성에 대한 이유들을 결정할 수 있다. 따라서, 모델은 CAM들에 기초하여 수정 또는 미세 조정될 수 있 어서, 모델은 더 강건해질 수 있고, 기계 학습을 사용하는 생성 검사를 위해 배치될 수 있다. 도 37은 도 36a-36c의 3개의 출력 예 각각에 대한 64개 채널 중 하나의 확대도들 또는 이미지들을 나타낸다. 단지 제1 처리 단계 후에, 도시된 CAM들에 기초하여, 모델은 이미 각각의 입력 이미지 내부의 결함을 격리하는 데 성공하고 있다. 각각의 입력 이미지가 상이한 커널들 또는 필터들을 사용하여 상이한 컨볼루션 계층들에 의 해 처리되기 때문에, 이미지의 상이한 영역들 및 양태들이 사용된다. 특징들 중 일부는 쉽게 인식할 수 있는 반면, 다른 특징들은 특히 후자의 컨볼루션 계층들에 따라 더 추상적일 수 있다. 이러한 상이한 계층들로부터 의 출력 이미지들은 개발자와 트레이너가 모델을 프로그래밍하고 미세 조정하는 것을 돕기 위해 이용할 수 있다. CAM들은 입력 이미지의 모든 위치에 대해 계산된 특정 출력 클래스와 관련된 점수들의 2D 그리드들이다. 이들 은 마지막 컨볼루션 계층이 출력한 이미지의 각각의 픽셀이 특정 출력 클래스를 얼마나 강하게 활성화하는지를 보여 주므로, 이미지의 어느 부분 또는 부분들이 모델로 하여금 최종 분류 결정을 내리도록 유도했는지를 이해 하는 것을 돕는다. CAM들은 8개의 렌즈 표면 분류와 3개의 렌즈 에지 분류를 위해 생성된 것과 같은 평가할 클 래스들 각각에 대해 계산될 수 있다. 도 38은 버블을 갖는 렌즈의 원본 입력 이미지(좌측)와 마지막 컨볼루션 계층의 출력에 기초하여 계산된 최종 예측 클래스의 CAM 이미지(가운데 작은 것)를 도시한다. 이어서, CAM 이 미지는 \"버블\" 표면 결함 이미지(즉, 좌측 이미지)에 대한 전처리된 이미지 위에 외삽 및 중첩되며, 이는 히트 맵(우측 이미지)으로 도시하고, 라벨링된 CAM을 정의한다. 도 38과 마찬가지로, 도 39는 \"스크래치\" 표면 결함 이미지에 대해 전처리된 이미지에 중첩된 최종 예측 클래스의 CAM을 도시한다. AI 네트워크에 의해 생성된 히 트맵은 이미지의 모든 픽셀들에게 예측 클래스의 활성화에서의 그들의 중요도에 비례하여 컬러를 할당한다. 모델을 개선하거나 미세 조정하기 위해 CAM들이 어떻게 사용될 수 있는지의 일례로서, 도 39의 \"스크래치\" 표면 결함 이미지에 대한 CAM 이미지를 고려한다. 알고리즘이 \"스크래치\" 카테고리에 대한 예측자로서 에지를 사용 하는 경향이 뚜렷하게 나타났다. 이는 이미지에서 렌즈의 외부 윤곽 또는 에지 주변의 히트 맵에서 알 수 있다. 이러한 경향은 예를 들어 훈련 데이터 세트를 늘려 \"스크래치\" 카테고리의 예측 정확도를 높임으로써 감 소될 수 있다. CAM들은 알고리즘이 도시된 바와 같이 \"스크래치\" 카테고리뿐만 아니라 여러 카테고리 각각에 대해 올바른 예측자를 학습하고 있는지를 평가하는 데 사용될 수 있다. 도 40a 및 40b는 동일한 이미지에 대한 그러나 상이한 훈련 프로토콜들 하에서의 \"스크래치\" 카테고리에 대한 CAM 이미지들을 도시한다. 도 40a의 \"스크래치\" 카테고리에 대한 CAM 이미지는 500개의 이미지에 대해 훈련된 모델에 대해 획득되었고, 도 40b에 도시된 것은 700개의 이미지에 대해 훈련된 동일한 모델에 대해 획득되었다. 도 40a와 도 40b를 나란히 비교하여 알 수 있듯이, CNN 모델은 도 40b의 이미지에서 \"스크래치\"를 찾기 위한 예측자로서 렌즈 에지를 덜 사용했다. 이는 클래스 카테고리들 각각에 대해서도 동일하게 수행될 수 있다. 따라 서, 훈련 데이터 세트를 늘리는 것은, 예를 들어 추가 이미지 획득이나 데이터 증강을 통해 분류 정확도를 향상 시키는 데 이용될 수 있다. 이제 도 41(A)를 참조하면, 렌즈 표면의 스크래치 주위에 경계 상자를 갖는 전처리된 이미지가 도시되어 있으며, 관심 영역 주위에 경계 상자를 갖는 스크래치를 갖는 전처리된 이미지 상에 최종 예측 클래스의 CAM이 중첩되어 있다. 라벨링된 CAM이라고도 하는 CAM 상의 경계 상자는 이미지 상의 관심 영역에 기초하 여, 예를 들어 CAM 이미지의 히트 맵의 프로파일에 기초하여 계산된 후에 검토를 용이하게 하기 위해 관심 영역 주변의 경계를 정의하기 위해 생성될 수 있다. 본 실시예에서, 경계 상자는 일반적으로 정사각형 형상이 다. 이어서, CAM에 대해 도출된 경계 상자를 전처리된 이미지 상에 중첩하여 흑백일 수 있는 전처리된 이 미지 상의 관심 영역 주변의 경계 상자를 보다 쉽게 관찰할 수 있다. 즉, 전처리된 이미지는 관심 영역 주위에 경계 상자로 라벨링되고, 전처리된 이미지 상의 관심 영역 주위의 경계 상자는 라벨링된 CAM 이미지에 기초한다. 예를 들어, 전처리된 이미지 상의 경계 상자의 위치 및 형상은 CAM 이미지 상의 경계 상자의 위치 및 형상에 기초할 수 있다. 일부 예들에서, 전처리된 이미지의 경계 상자와 CAM 이미지 상의 경계 상자는 동일 하거나 상이한 형상일 수 있다. 예를 들어, 전처리된 이미지는 어떠한 히트 맵도 포함하지 않으므로, 전처리된 이미지 상의 경계 상자의 크기는 CAM 이미지 상의 경계 상자의 크기에 비해 더 작게 크기가 조정될 수 있다. 경계 상자의 형상은 상이한 다각형 형상들, 삼각형 형상 또는 불규칙한 형상을 포함하여 다양할 수 있으며, 이 미지당 2개 이상의 경계 상자를 포함하여 이미지 내의 2개 이상의 관심 영역에 주석을 달 수 있다. 경계 상자 의 형상은 관심 결함 영역의 윤곽과 매칭될 필요는 없다. 일부 예들에서, 결함 영역의 실제 윤곽을 강화하여 결함에 주석을 첨부한다. 일부 예들에서, 분석 또는 훈련될 복수의 이미지 각각에 대해 원본 이미지 상의 결함 영역은 예를 들어 경계 상자로 또는 결함 영역의 윤곽을 강조함으로써 라벨링된다. 전처리된 이미지와 같은 라 벨링된 원본 이미지는 훈련, 디스플레이, 마케팅 등에 사용될 수 있다. CAM은 사용자나 프로그래머가 카테고리화될 이미지를 검사하고 해당 이미지의 어떤 부분들/픽셀들이 모델의 최 종 출력에 더 많이 기여했는지를 이해할 수 있게 한다. 이는 일례로, 어떤 계층들을 수정해야 하는지 또는 훈 련 세트 이미지들을 상이하게 전처리할지를 이해하는 데 CAM이 도움이 되므로, AI 모델의 정확도를 향상시키는 데 매우 유용할 수 있다. 이는 신경망이 이미지의 적절한 부분들을 보고 있는지 또는 신경망이 패턴에 기초하 여 이미지를 분류하고 있는지를 이해하는 데 도움이 되므로 신경망이 어디를 보고 있는지를 시각화하는 데 유용 하다. 이제 도 41(B)를 참조하면, 렌즈 표면 상의 영역들 주위에 경계 상자들(350, 352)을 갖는 전처리된 이미지가 도 시되어 있으며, 관심 영역들 주위에 경계 상자들(350, 352)을 갖는 전처리된 이미지 상에는 최종 예측 클래스의 CAM이 중첩되어 있다. 본 실시예에서, 관심 영역들은 이미지 획득 중에 렌즈가 배치된 더티 사파이어를 갖는 영역들이다. CAM 상의 경계 상자들(350, 352)은 이미지 상의 관심 영역들에 기초하여, 예를 들어 CAM 이미지의 히트 맵의 프로파일에 기초하여 계산될 수 있다. 계산된 경계 상자들(350, 352)은 관심 영역들 주위의 경계들 을 정의하여 영역들의 검토를 용이하게 할 수 있다. 본 실시예에서, 제1 경계 상자는 일반적으로 타원형 또는 계란형이고, 제2 경계 상자는 불규칙한 형상을 갖는다. 이어서, CAM을 위해 도출된 경계 상자들 (350, 352)은 전처리된 이미지 상에 중첩되어, 흑백일 수 있는 전처리된 이미지 상의 관심 영역들 주위의 경계 상자들(350, 352)은 쉽게 관찰될 수 있다. 일부 예들에서, 전처리된 이미지 상의 경계 상자들과 CAM 이미지 상 의 경계 상자들은 동일하거나 상이할 수 있다. 위에서 설명된 바와 같이, AI 네트워크에 의해 생성된 히트맵은 이미지의 모든 픽셀들에게 예측 클래스의 활성 화에서의 그들의 중요도에 비례하여 컬러를 할당한다. 히트맵을 출력하는 대신 또는 히트맵에 더하여, 결함 영 역으로 보거나 지칭될 수 있는 관심 영역에 대한 임계치가 확립될 수 있고, 결함 영역은 도 41(A)-41(B)에 도시 된 바와 같은 경계 객체로 주석이 달릴 수 있다. 본 명세서에서 사용되는 CNN 모델들은 다중 클래스 단일 라벨 분류기들이므로, 출력은 확률들의 벡터로 구성된 다. 즉, 하나의 모델의 출력은 \"표면\" 모델이 훈련된 각각의 클래스에 대해 하나씩 크기(1,8)의 하나의 벡터를 생성하고, 다른 모델의 출력은 \"에지\" 모델이 훈련된 각각의 클래스에 대해 하나씩 크기(1,3)의 하나의 벡터를 생성한다. 각각의 모델에 대한 최종 출력은 각각의 분석된 이미지에 대해 가장 높은 확률을 갖는 클래스의 인 덱스이다. 일례로, \"표면\" 모델의 출력 벡터는 8개의 확률로 구성된다. 클래스들의 인덱스는 \"파편\"을 갖는 도 42에 도시 된 이미지 예에 대해 도 43에 도시된 순서에 대응하도록 프로그래밍될 수 있다. 도시된 바와 같이, 도 42의 \"파편\"을 갖는 이미지에 대해, 모델은 도 43에 도시된 출력 확률들을 생성한다. 출력은 이미지가 \"브레인들\"일 가능성이 20%이고, \"파편\"일 가능성이 74%이고, \"더블 렌즈\"일 가능성이 6%이고, 다른 것일 가능성이 거의 없는 것으로 해석될 수 있다. 최종 출력은 가장 높은 확률을 갖는 클래스일 것이며, 이 경우에서는 \"파편\"이다. 옵 션으로서, 렌즈 검사 시스템의 출력은 도 43에 도시된 확률들의 표일 수 있다. 양호하게 훈련된 모델이 시간이 지남에 따라 겪는 데이터 드리프트를 방지하기 위해, 모델은 이미지 데이터에 대해 \"자동 인코더\" 또는 \"컨볼루션 자동 인코더\"로 훈련될 수 있다. 일례로, 생성 프로세스의 변화로 인해 새 로운 결함이 발생할 수 있다. 모델이 이러한 특정 유형의 결함에 대해 훈련되지 않은 경우, 훈련된 모델은 이 를 렌즈 불합격 사유로 검출하지 못해 새로운 결함을 갖는 렌즈를 \"양호한 렌즈\"로 식별할 가능성이 있다. 재 훈련은 이러한 상황을 해결하기 위한 궁극적인 해결책일 수 있다. 자동 인코더는 입력 데이터의 표현을 학습하여, 내부 표현에 기초하여, 입력으로 수신된 이미지에 최대한 가까 운 이미지를 출력할 수 있다. 따라서, 이 기능은 입력 데이터의 대표적인 특징들을 학습한다. 원칙은 VGG 16 Net 또는 VGG19 Net과 같은 CNN 모델일 수 있는 예측 모델 개발에 사용되는 훈련 데이터에 대해 자동 인코더를 훈련하는 것이다. 자동 인코더가 훈련 데이터에 대해 훈련되면, 출력 이미지들이 입력 이미지들에 얼마나 가까 운지에 대한 일부 메트릭들을 계산하여 입력 이미지와 재구성된 이미지가 얼마나 유사할 수 있는지를 검증할 수 있다. 게다가, 생성 환경에서는 착신 데이터가 또한 인코더로 전달될 수 있고, 전술한 확립된 메트릭들이 계산된다. 재구성된 이미지들의 품질이 예상보다 현저히 낮다면, 이는 적색 플래그이며 입력의 변화가 발생했음을 나타낼 수 있다. 데이터 드리프트 문제가 식별된 경우 재훈련을 돕기 위해, 생성 라인으로부터 주기적으로 이미지를 수집하고 라이브 데이터 세트를 유지하는 것은 모델에 자동 인코더를 공급하기 위해 실시될 수 있다. 본 명세서에 설명된 AI 네트워크들은 다중 클래스 단일 라벨 분류기로서 훈련되고 구현되었다. 즉, 네트워크들 은 설명된 클래스들 각각에 대한 신뢰도를 출력할 수 있지만, 동일한 입력 이미지에서 발견된 여러 결함을 식별 할 수는 없다. 그러나, AI 네트워크들은 다중 클래스 다중 라벨 분류기로 동작하도록 훈련될 수 있는 것이 고 려된다. 즉, 모델들은 동일한 이미지에 두 개 이상의 결함을 가질 수 있는 동일한 입력 이미지에서 발견된 여 러 결함을 식별하도록 훈련될 수 있다. 다중 결함 예측을 달성하기 위해서는 \"버블\" 및 \"스크래치\" 모두와 같 은 다수의 결함을 갖는 이미지들의 훈련 데이터 세트들 및 확인 데이터 세트들을 획득하여 본 발명의 CNN 모델 들과 같은 AI 네트워크들, 특히 몇 가지 예로서 VGG16, VGG19, AlexNet, Inception 및 GoogleNet을 훈련 및 확 인하는 데 사용해야 한다. 훈련, 확인 및 예측 프로세스들은 본 명세서의 다른 곳에 설명된 프로세스들을 따를 수 있다. 전술한 바와 같이, 본 발명의 CNN 모델들은 렌즈들이 식염수 또는 다른 포장 용액들로 채워진 블리스터 팩들에 들어 있을 때와 같이 젖은 상태에서 렌즈들을 분석하고 분류하도록 훈련될 수 있다. 블리스터 팩들을 박리 가 능한 커버들로 밀봉하기 전에, 렌즈들은 젖은 상태에서 이미징될 수 있다. 이어서, 젖은 상태의 렌즈들의 이미 지들은 모델들을 훈련하고 확인하는 데 사용될 수 있다. 이미지들은 동일한 초점 심도 설정들을 갖는 카메라들 로 촬영될 수 있으므로, 동일한 이미지에서 에지 및 표면 결함들이 검사될 수 있다. 이는 렌즈 검사 시스템이 단일 CNN 모델을 사용하여 동작할 수 있게 한다. 또한, 렌즈들 상의, 블리스터들 상의 또는 식염수 수조에 떠 있는 특징들을 구별하는 것을 돕기 위해, 동일한 렌즈에 대해 제1 위치에서 이미지들을 촬영한 다음 제2 위치로 회전 또는 이동시킬 수 있다. 상이한 2개의 위치에서의 동일한 렌즈의 2개의 이미지는 CNN 모델들에 의해 블리 스터 팩, 렌즈 또는 수조와 관련된 것으로 픽업될 수 있는, 서로에 대해 움직이는 특징들을 캡처할 수 있다. 옵션으로서, 제1 CNN 모델을 사용하여 회전 전에 또는 이동 전에 이미지들을 분석할 수 있고, 제2 CNN 모델을 사용하여 회전 후에 또는 이동 후에 이미지들을 분석할 수 있다. 본 명세서에 제시된 렌즈 검사 시스템들 및 그 컴포넌트들의 훈련 및 사용 방법들은 본 발명의 범위 내에 있다. 렌즈 검사 시스템들 및 그 컴포넌트들의 제한된 실시예들이 본 명세서에 구체적으로 설명 및 예시되었지만, 이 분야의 기술자들에게는 많은 수정 및 변형이 명백할 것이다. 따라서, 개시된 디바이스들, 시스템들 및 방법들 의 원리들에 따라 구성된 렌즈 검사 시스템들은 본 명세서에 구체적으로 설명된 것 이외의 것으로 구현될 수 있 다는 것을 이해해야 한다. 본 개시는 또한 이하의 청구항들에서 정의된다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면14a 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34 도면35 도면36a 도면36b 도면36c 도면37 도면38 도면39 도면40a 도면40b 도면41 도면42 도면43"}
{"patent_id": "10-2024-7000620", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 디바이스들, 시스템들 및 방법들의 이들 및 다른 특징들 및 장점들은 본 명세서, 청구항들 및 첨부 도면들을 참조하여 보다 잘 이해됨에 따라 인식될 것이다. 도면들에서: 도 1은 본 발명의 양태들에 따른 렌즈 검사 시스템의 하나의 구성에 대한 개략도이다. 도 2는 컴퓨터 시스템을 사용하는 본 개시의 하나의 구성에 대한 다른 개략도이다. 도 3은 렌즈들의 결함을 식별하고 결함들의 클래스 및 옵션으로서 라벨링된 중간 활성화 이미지들을 출력하기 위한 본 개시의 하나의 구성을 묘사하는 흐름도이다. 도 4a는 원본 이미지를 수직으로 뒤집어 2개의 이미지를 생성하는 것에 의한 예시적인 이미지 증강을 도시하고, 도 4b는 원본 이미지를 수평으로 뒤집어 원본 이미지로부터 제3 이미지를 생성하는 것에 의한 예시적인 이미지 증강을 도시한다. 도 5는 훈련 데이터 세트들, 확인 데이터 세트들 및 생성 데이터 세트들이 생성될 수 있는 템플릿을 생성하기 위한 본 개시의 하나의 구성을 묘사하는 흐름도이다. 도 6은 컴퓨터 시스템에 대한 입력 준비 이미지를 생성하기 위해 렌즈 표면 이미지를 전처리하는 하나의 구성을 묘사하는 흐름도이다.도 7은 컴퓨터 시스템에 대한 입력 준비 이미지를 생성하기 위해 렌즈 에지 이미지를 전처리하는 하나의 구성을 묘사하는 흐름도이다. 도 8은 렌즈를 직교 좌표계로 묘사하는 이미지 및 이미지의 극좌표계로의 변환을 도시한다. 도 9는 극좌표계의 이미지가 렌즈 에지의 안쪽 및 바깥쪽에 대한 이미지를 획득하기 위해 크로핑(cropping)되는 것을 도시한다. 도 10은 도 9의 크로핑된 이미지가 이미지 강도들의 제1 세트로부터 이미지 강도들의 제2 세트로 반전되는 것을 도시한다. 도 11은 AI 네트워크, 특히 컨볼루션 신경망(CNN)의 개략도이다. 도 12는 CNN의 \"표면\" 모델의 개념적 블록들을 각각의 계층의 입력 및 출력 형상들과 함께 도시한다. 도 13은 \"에지\" 모델의 개념적 블록들을 각각의 계층의 입력 및 출력 형상들과 함께 도시한다. 도 14는 사전 훈련된 CNN 모델의 전사 훈련에 사용되는 예시적인 설정들을 도시한다. 도 14a는 본 발명의 CNN 모델들의 예시적인 전사 훈련 프로토콜을 묘사하는 흐름도이다. 도 15는 훈련 데이터 세트들 및 확인 데이터 세트들 모두에 대한 에포크(epoch)들의 범위에 걸쳐 정확도가 어떻 게 변하는지를 도시한다. 도 16은 훈련 및 확인 데이터 세트들에 대한 훈련 에포크들에 걸친 손실 함수의 출력을 묘사하는 그래프들을 도 시한다. 도 17-24는 양호한 렌즈뿐만 아니라 물리적 결함들도 광범위하게 커버하는 렌즈 표면 결함들의 8개의 상이한 클 래스 또는 카테고리를 나타내는 이미지들이다. 도 25-27은 양호한 렌즈뿐만 아니라 물리적 결함들도 광범위하게 커버하는 렌즈 에지 결함들의 3개의 상이한 클 래스 또는 카테고리를 나타내는 이미지들이다. 도 28은 훈련 데이터 세트에 관한 예측 대 실측 자료에 대한 표 포맷의 목록(tabulation)들을 도시한다. 도 29는 훈련 데이터 세트에 관한 본 발명의 표면 모델의 성능 메트릭들을 보여주기 위하여 표 포맷으로 목록화 된 데이터를 도시한다. 도 30은 본 발명의 \"에지\" 모델에 대한 훈련 데이터 세트에 관한 예측 대 실측 자료에 대한 표 포맷의 목록들을 도시한다. 도 31은 훈련 데이터 세트에 관한 본 발명의 에지 모델의 성능 메트릭들을 보여주기 위해 표 포맷으로 목록화된 데이터를 도시한다. 도 32는 대안적인 CNN을 사용하는 각각의 계층의 출력 형상들과 함께 \"에지\" 모델의 개념적 블록들을 도시하고, 도 33은 모델에 추가된 드롭아웃 계층(dropout layer)을 도시한다. 도 34는 드롭아웃 계층을 갖지 않는 도 12의 모델에 추가된 추가 컨볼루션 계층을 도시한다. 도 35는 전처리 단계의 렌즈 영역 크로핑 단계의 출력의 예들로서 3개의 이미지를 도시한다. 도 36a, 도 36b 및 도 36c는 도 35의 3개의 입력 이미지에 대한 본 발명의 CNN 모델의 제1 컨볼루션 블록의 제1 컨볼루션 동작의 64 채널-출력의 3개의 상이한 세트를 도시한다. 도 37은 도 36a-36c의 3개의 출력 예 각각에 대한 64개 채널 중 하나의 확대 이미지들을 도시한다. 도 38은 \"버블\" 표면 결함 이미지에 대한 전처리된 이미지 상에 중첩된 최종 예측 클래스의 CAM을 도시한다. 도 39는 \"스크래치\" 표면 결함 이미지에 대한 전처리된 이미지 상에 중첩된 최종 예측 클래스의 CAM을 도시한다. 도 40a 및 40b는 동일한 이미지에 대한 그러나 상이한 훈련 프로토콜들 하에서의 \"스크래치\" 카테고리에 대한 CAM 이미지들을 도시한다. 도 41(A)는 경계 상자를 갖는 전처리된 이미지 및 경계 상자를 갖는 전처리된 이미지 상에 중첩된 최종 예측 클래스의 CAM을 도시하고, 도 41(B)는 2개의 경계 상자를 갖는 전처리된 이미지 및 경계 상자들을 갖는 전처리된 이미지 상에 중첩된 최종 예측 클래스의 CAM을 도시한다. 도 42는 \"파편\"을 갖는 렌즈를 보여주는 렌즈 표면 이미지의 일례이다. 도 43은 도 42의 렌즈 표면 이미지에 대한 상이한 결함 클래스들의 확률들을 보여주는 표 포맷의 렌즈 검사 시 스템의 예시적인 출력이다."}
