{"patent_id": "10-2023-7022464", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0129410", "출원번호": "10-2023-7022464", "발명의 명칭": "신경망 모델들을 사용한 가변 비트 레이트 압축", "출원인": "퀄컴 인코포레이티드", "발명자": "루, 야동"}}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 신경망(ANN: artificial neural network)을 동작시키기 위한 컴퓨터-구현 방법으로서,상기 ANN에 의해 입력을 수신하는 단계;상기 ANN을 통해 상기 입력의 잠재적 표현을 생성하는 단계; 및학습된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따라 상기 잠재적 표현을 전달하는 단계를 포함하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 잠재적 스케일링 파라미터는 채널 인덱스 및 트레이드오프(tradeoff) 파라미터에 기초하여 학습되는, 인공신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 잠재적 스케일링 파라미터는 상기 잠재적 스케일링 파라미터가 채널의 잠재적 표현들의 값에 비해 사전 정의된 임계값 초과인 것에 응답하여 상기 채널을 드롭핑(dropping)하도록 구성되는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 트레이드오프 파라미터는 상기 비트 레이트와 왜곡을 밸런싱(balancing)하는 값에 대응하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 트레이드오프 파라미터는 상기 ANN의 훈련 동안 함께 훈련된 상이한 트레이드오프 파라미터들의 어레이를포함하고, 상기 상이한 트레이드오프 파라미터들 각각에 대응하는 손실이 등화(equalizing)되는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,낮은 비트 레이트 포인트들의 제1 손실 값들과 높은 비트 레이트 포인트들의 제2 손실 값들이 등화되도록 등화를 적용하는 단계를 더 포함하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 등화는 플레인(plain) 등화를 포함하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,공개특허 10-2023-0129410-3-상기 등화는 탄젠트(tangent) 등화를 포함하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법으로서,상기 ANN에 의해 입력 비트 스트림을 수신하는 단계;입력의 잠재적 표현을 복구하기 위해 학습된 잠재적 스케일링 파라미터를 상기 입력 비트 스트림에 적용하는 단계; 및상기 입력의 재구성을 생성하기 위해 상기 ANN을 통해 상기 잠재적 표현을 디코딩하는 단계를 포함하는, 인공신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 잠재적 스케일링 파라미터는 채널 인덱스 및 트레이드오프 파라미터에 기초하여 학습되는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 트레이드오프 파라미터는 상기 비트 레이트와 왜곡을 밸런싱하는 값에 대응하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "인공 신경망(ANN)을 동작시키기 위한 장치로서,메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는,상기 ANN에 의해 입력을 수신하고;상기 ANN을 통해 상기 입력의 잠재적 표현을 생성하고; 그리고학습된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따라 상기 잠재적 표현을 전달하도록 구성되는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 적어도 하나의 프로세서는 채널 인덱스 및 트레이드오프 파라미터에 기초하여 상기 잠재적 스케일링 파라미터를 학습하도록 추가로 구성되는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 잠재적 스케일링 파라미터는 상기 잠재적 스케일링 파라미터가 채널의 잠재적 표현들의 값에 비해 사전 정의된 임계값 초과인 것에 응답하여 상기 채널을 드롭핑하도록 구성되는, 인공 신경망(ANN)을 동작시키기 위한장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13 항에 있어서,상기 트레이드오프 파라미터는 상기 비트 레이트와 왜곡을 밸런싱하는 값에 대응하는, 인공 신경망(ANN)을 동작시키기 위한 장치.공개특허 10-2023-0129410-4-청구항 16 제15 항에 있어서,상기 트레이드오프 파라미터는 상기 ANN의 훈련 동안 함께 훈련된 상이한 트레이드오프 파라미터들의 어레이를포함하고, 상기 상이한 트레이드오프 파라미터들 각각에 대응하는 손실이 등화되는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 적어도 하나의 프로세서는 낮은 비트 레이트 포인트들의 제1 손실 값들과 높은 비트 레이트 포인트들의 제2 손실 값들이 등화되도록 등화를 적용하도록 추가로 구성되는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서,상기 등화는 플레인 등화를 포함하는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17 항에 있어서,상기 등화는 탄젠트 등화를 포함하는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "인공 신경망(ANN)을 동작시키기 위한 장치로서,메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는,상기 ANN에 의해 입력 비트 스트림을 수신하고;입력의 잠재적 표현을 복구하기 위해 학습된 잠재적 스케일링 파라미터를 상기 입력 비트 스트림에 적용하고;그리고상기 입력의 재구성을 생성하기 위해 상기 ANN을 통해 상기 잠재적 표현을 디코딩하도록 구성되는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20 항에 있어서,상기 적어도 하나의 프로세서는 채널 인덱스 및 트레이드오프 파라미터 값에 기초하여 상기 잠재적 스케일링 파라미터를 학습하도록 추가로 구성되는, 인공 신경망(ANN)을 동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21 항에 있어서,상기 트레이드오프 파라미터 값은 상기 비트 레이트와 왜곡을 밸런싱하는 값에 대응하는, 인공 신경망(ANN)을동작시키기 위한 장치."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법은 ANN에 의해 입력을 수신하는 단계를 포함한다. ANN은 입력의 잠재적 표현을 생성한다. 잠재적 표현은 학습된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따 라 전달된다. 잠재적 스케일링 파라미터는 트레이드오프 파라미터 값 및 채널 인덱스에 기초하여 학습되고, 트 레이드오프 파라미터 값은 비트 레이트와 왜곡을 밸런싱하는 값에 대응한다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2021년 1월 12일에 \"VARIABLE BIT RATE COMPRESSION USING NEURAL NETWORK MODELS\"이란 명칭 으로 출원된 미국 가특허 출원 번호 제63/136,607호의 이익을 주장하는, 2022년 1월 11일에 \"VARIABLE BIT RATE COMPRESSION USING NEURAL NETWORK MODELS\"이란 명칭으로 출원된 미국 특허 출원 번호 제17/573,568호에대해 우선권을 주장하며, 그 출원들의 개시내용은 그 전체가 인용에 의해 명백히 통합된다. 본 개시내용의 양상들은 일반적으로 신경망들에 관한 것으로, 보다 구체적으로, 인공 신경망들을 사용한 이미지 압축에 관한 것이다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망들은 인공 뉴런(neuron)들의 상호 연결된 그룹들(예를 들어, 뉴런 모델들)을 포함할 수 있다. 인공 신경망은 컴퓨테이션 디바이스일 수 있거나, 컴퓨테이션 디바이스에 의해 수행되는 방법으로 표현 될 수도 있다. 컨벌루션(convolution) 신경망들은 피드-포워드(feed-forward) 인공 신경망의 한 유형이다. 컨 벌루션 신경망들은 각각 수용 필드를 갖고 집합적으로 입력 공간을 타일링(tiling)하는 뉴런들의 집합들을 포함 할 수 있다. 심층 컨벌루션 신경망(DCN: deep convolutional neural network)들과 같은 컨벌루션 신경망(CNN: Convolutional neural network)들은 수많은 애플리케이션들을 갖는다. 특히, 이러한 신경망 아키텍처들은 이미 지 인식, 패턴 인식, 음성 인식, 자율 주행 및 다른 분류 작업들과 같은 다양한 기술들에 사용된다. 신경망들은 비디오 압축 및 이미지 압축과 같은 멀티미디어 압축에 성공적인 적용을 갖는다. 이미지 압 축은 이미지들 및 비디오들과 같은 멀티미디어 통신에 유용하다. 그러나, 사용자들은 상이한 컴퓨트 능력들을 갖는 상이한 컴퓨터 아키텍처들을 가질 수 있으며 상이한 네트워크 조건들 하에서 이러한 디바이스들을 동작시 킬 수 있다. 복수의 비트 레이트들을 제공하는 것은 더 많은 컴퓨트 능력들이 이용 가능하거나 더 나은 네트워 크 조건들 하에 있을 때 더 많은 데이터 또는 더 높은 품질의 이미지가 전송되도록 허용하거나, 컴퓨트 능력들 이 제한되거나 네트워크 조건이 열악할 때 더 적은 데이터 또는 더 낮은 품질의 이미지가 전송되도록 허용할 수 있다. 종래의 기법들 하에서는, 복수의 비트 레이트들을 제공하기 위해 별도의 모델들이 상이한 비트 레이트들 에 대해 훈련되므로 저장 관점에서 볼 때 컴퓨테이션이 비효율적이고 비용이 많이 들 수 있다. 본 개시내용은 독립항들에 각각 제시되어 있다. 본 개시내용의 일부 양상들은 종속항들에 설명되어 있 다. 본 개시내용의 일 양상에서, 인공 신경망(ANN: artificial neural network)을 동작시키기 위한 컴퓨터- 구현 방법이 제공된다. 컴퓨터-구현 방법은 ANN에 의해 입력을 수신하는 단계를 포함한다. 컴퓨터-구현 방법 은 또한 ANN을 통해 입력의 잠재적 표현을 생성하는 단계를 포함한다. 컴퓨터-구현 방법은 학습된 잠재적 스케 일링 파라미터에 기초하여 비트 레이트에 따라 잠재적 표현을 전달하는 단계를 추가로 포함한다. 본 개시내용의 다른 양상에서, 인공 신경망(ANN)을 동작시키기 위한 장치가 제공된다. 본 장치는 메모 리 및 메모리에 커플링된 하나 이상의 프로세서들을 포함한다. 프로세서(들)는 ANN에 의해 입력을 수신하도록 구성된다. 프로세서(들)는 또한 ANN을 통해 입력의 잠재적 표현을 생성하도록 구성된다. 프로세서(들)는 학습 된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따라 잠재적 표현을 전달하도록 추가로 구성된다. 본 개시내용의 다른 양상에서, 인공 신경망(ANN)을 동작시키기 위한 장치가 제공된다. 본 장치는 ANN에 의해 입력을 수신하기 위한 수단을 포함한다. 본 장치는 또한 ANN을 통해 입력의 잠재적 표현을 생성하기 위한 수단을 포함한다. 본 장치는 학습된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따라 잠재적 표현을 전달하기 위한 수단을 추가로 포함한다. 본 개시내용의 다른 양상에서, 비일시적 컴퓨터 판독 가능 매체가 제공된다. 컴퓨터 판독 가능 매체는 인공 신경망(ANN)을 동작시키기 위해 인코딩된 프로그램 코드를 갖는다. 프로그램 코드는 프로세서에 의해 실 행되며, ANN에 의해 입력을 수신하는 코드를 포함한다. 프로그램 코드는 또한 ANN을 통해 입력의 잠재적 표현 을 생성하는 코드를 포함한다. 프로그램 코드는 학습된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따라 잠재적 표현을 전달하는 코드를 추가로 포함한다. 본 개시내용의 다른 양상에서, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법이 제공된다. 컴 퓨터-구현 방법은 ANN에 의해 입력 비트 스트림을 수신하는 단계를 포함한다. 컴퓨터-구현 방법은 또한 입력의 잠재적 표현을 복구하기 위해 학습된 잠재적 스케일링 파라미터를 입력 비트 스트림에 적용하는 단계를 포함한 다. 컴퓨터-구현 방법은 입력의 재구성을 생성하기 위해 ANN을 통해 잠재적 표현을 디코딩하는 단계를 추가로 포함한다. 본 개시내용의 다른 양상에서, 인공 신경망(ANN)을 동작시키기 위한 장치가 제공된다. 본 장치는 메모 리 및 메모리에 커플링된 하나 이상의 프로세서들을 포함한다. 프로세서(들)는 ANN에 의해 입력 비트 스트림을 수신하도록 구성된다. 프로세서(들)는 또한 입력의 잠재적 표현을 복구하기 위해 학습된 잠재적 스케일링 파라 미터를 입력 비트 스트림에 적용하도록 구성된다. 프로세서(들)는 입력의 재구성을 생성하기 위해 ANN을 통해 잠재적 표현을 디코딩하도록 추가로 구성된다. 본 개시내용의 다른 양상에서, 인공 신경망(ANN)을 동작시키기 위한 장치가 제공된다. 본 장치는 ANN에 의해 입력 비트 스트림을 수신하기 위한 수단을 포함한다. 본 장치는 또한 입력의 잠재적 표현을 복구하기 위 해 학습된 잠재적 스케일링 파라미터를 입력 비트 스트림에 적용하기 위한 수단을 포함한다. 본 장치는 입력의 재구성을 생성하기 위해 ANN을 통해 잠재적 표현을 디코딩하기 위한 수단을 추가로 포함한다. 본 개시내용의 다른 양상에서, 비일시적 컴퓨터 판독 가능 매체가 제공된다. 컴퓨터 판독 가능 매체에 는 인공 신경망(ANN)을 동작시키기 위해 인코딩된 프로그램 코드를 갖는다. 프로그램 코드는 프로세서에 의해 실행되며, ANN에 의해 입력 비트 스트림을 수신하는 코드를 포함한다. 프로그램 코드는 또한 입력의 잠재적 표 현을 복구하기 위해 학습된 잠재적 스케일링 파라미터를 입력 비트 스트림에 적용하는 코드를 포함한다. 프로 그램 코드는 입력의 재구성을 생성하기 위해 ANN을 통해 잠재적 표현을 디코딩하는 코드를 추가로 포함한다. 본 개시내용의 추가적인 특징들 및 이점들이 아래에서 설명될 것이다. 본 기술 분야의 통상의 기술자는 본 개시내용이 본 개시내용의 동일한 목적을 수행하기 위해 다른 구조들을 수정하거나 설계하기 위한 기초로서 용이하게 이용될 수 있음을 이해해야 한다. 또한, 본 기술 분야의 통상의 기술자는 이러한 등가 구성들이 첨부 된 청구항들에 제시된 개시내용의 교시로부터 벗어나지 않는다는 것을 이해해야 한다. 추가의 목적들 및 이점 들과 함께, 그 조직 및 동작 방법 모두에 있어서 본 개시내용의 특성이라고 생각되는 새로운 특징들은 첨부된 도면들과 관련하여 고려될 때 다음 설명으로부터 더 잘 이해될 것이다. 그러나, 도면들의 각각은 예시 및 설명 의 목적으로만 제공되며 본 개시내용의 한계를 정의하려고 의도되지 않았음을 분명히 이해해야 한다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부된 도면들과 함께 아래에 제시되는 상세한 설명은 다양한 구성들의 설명을 위해 의도되며, 설명된 개념들이 실시될 수 있는 유일한 구성들을 나타내도록 의도되는 것은 아니다. 상세한 설명은 다양한 개념들에 대한 완전한 이해를 제공할 목적으로 특정 상세 사항들을 포함한다. 그러나, 이러한 개념들이 이러한 특정 상 세 사항들 없이도 실시될 수 있다는 것은 본 기술 분야의 통상의 기술자에게 명백할 것이다. 일부 경우들에 있 어서, 이러한 개념들이 모호해지는 것을 피하기 위해 공지된 구조들 및 구성 요소들이 블록도 형태로 도시된다. 본 교시들에 기초하여, 본 기술 분야의 통상의 기술자는 본 개시내용의 범위가 본 개시내용의 임의의 다 른 양상과 결합되어 구현되든지 또는 독립적으로 구현되든지 간에 본 개시내용의 임의의 양상을 포함하도록 의 도된다는 것을 이해해야 한다. 예를 들어, 제시된 임의의 개수의 양상들을 사용하여 장치가 구현될 수 있거나 방법이 실시될 수 있다. 또한, 본 개시내용의 범위는 제시된 본 개시내용의 다양한 양상들에 추가하여 또는 이 외에 다른 구조, 기능, 또는 구조 및 기능을 사용하여 실시되는 이러한 장치 또는 방법을 포함하도록 의도된다. 개시된 본 개시내용의 임의의 양상은 청구항의 하나 이상의 요소들에 의해 구현될 수 있음을 이해해야 한다. \"예시적인\"이라는 단어는 \"예, 실례 또는 예증으로서의 역할을 하는 것\"을 의미하기 위해 사용된다. \" 예시적인\" 것으로 설명된 임의의 양상이 반드시 다른 양상들에 비해 바람직하거나 유리한 것으로 해석되지는 않 는다. 특정 양상들이 설명되지만, 이러한 양상들의 많은 변형들 및 순열들이 본 개시내용의 범위 내에 속한다. 바람직한 양상들의 일부 이점들 및 이익들이 언급되지만, 본 개시내용의 범위는 특정 이점들, 용도들 또는 목적 들로 제한되도록 의도되지는 않는다. 오히려, 본 개시내용의 양상들은 상이한 기술들, 시스템 구성들, 네트워 크들 및 프로토콜들에 광범위하게 적용 가능하도록 의도되며, 이들 중 일부는 도면 및 바람직한 양상들의 이하 의 설명에서 예시의 방식으로 예시된다. 상세한 설명 및 도면들은 본 개시내용을 제한하는 것이 아니라 단지 예시하는 것이며, 본 개시내용의 범위는 첨부된 청구항들 및 그 등가물들에 의해 정의된다. 신경망들은 비디오 압축 및 이미지 압축과 같은 멀티미디어 압축에 성공적인 적용을 갖는다. 이미지 압 축은 이미지들 및 비디오들과 같은 멀티미디어 통신에 유용하다. 그러나, 사용자들은 상이한 컴퓨트 능력들을 갖는 상이한 컴퓨터 아키텍처를 가질 수 있으며, 상이한 네트워크 조건들 하에서 이러한 디바이스들을 동작시킬 수 있다. 가변 비트 레이트들을 제공하는 것은 더 많은 컴퓨트 능력들이 이용 가능하거나 더 나은 네트워크 조 건들 하에 있을 때 더 많은 데이터 또는 더 높은 품질의 이미지가 전송되도록 허용하거나, 컴퓨트 능력들이 제 한되거나 네트워크 조건이 열악할 때 더 적은 데이터 또는 더 낮은 품질의 이미지가 전송되도록 허용할 수 있다. 종래의 기법들 하에서는, 가변 비트 레이트들을 제공하기 위해 별도의 모델들이 상이한 비트 레이트들에 대해 훈련되므로 저장 관점에서 볼 때 컴퓨테이션이 비효율적이고 비용이 많이 들 수 있다. 본 개시내용의 양상들은 인공 신경망을 통해 가변 비트 레이트를 제공하기 위한 정렬된 표현을 학습하는 것에 관한 것이다. 학습된 정렬 표현은 최고 레이트의 코딩된 비트들이 낮은 레이트의 코딩된 비트를 포함하는 임베디드(embedded) 코딩을 가능하게 한다. 즉, 높은 비트 레이트의 스트림을 잘라서 낮은 비트 레이트의 코드 를 획득할 수 있다. 따라서, 일부 양상들에서, 학습된 정렬 표현은 단일 비트 스트림으로 상이한 사용자들에 대한 브로드캐스트를 가능하게 할 수 있다. 불균등 오류 보호(UEP: unequal error protection)로, 더 좋거나 깨끗한 채널 조건들을 갖는 사용자들은 더 많은, 또는 일부 경우들에서 모든 잠재적 채널들을 디코딩할 수 있는 반면, 열악한 채널 조건들을 갖는 사용자들은 더 적은, 그리고 일부 양상들에서 단지 중요한 채널들만을 디코딩 할 수 있다. 도 1은 이미지 압축 및 통신을 제공하기 위해 인공 신경망(예를 들어, 신경 엔드-투-엔드(end-to-end) 망)을 동작시키도록 구성된 중앙 처리 장치(CPU: central processing unit) 또는 멀티-코어 CPU를 포함할 수 있는 시스템-온-어-칩(SOC: system-on-a-chip)의 예시적인 구현을 예시한다. 변수(예를 들어, 신경 신 호 및 시냅틱(synaptic) 가중치들), 컴퓨테이션 디바이스(예를 들어, 가중치들을 갖는 신경망)와 연관된 시스템 파라미터들, 지연들, 주파수 빈(bin) 정보 및 작업 정보는 신경 프로세싱 유닛(NPU: neural processing unit)과 연관된 메모리 블록, CPU와 연관된 메모리 블록, 그래픽 처리 장치(GPU: graphics processing unit)와 연관된 메모리 블록, 디지털 신호 프로세서(DSP: digital signal processor)와 연관된 메모리 블록, 메모리 블록에 저장될 수 있거나, 복수의 블록들에 걸쳐 분산될 수 있다. CPU 에서 실행되는 명령들은 CPU와 연관된 프로그램 메모리로부터 로딩될 수 있거나 메모리 블록으로부터로딩될 수 있다. SOC는 또한 GPU, DSP, 5세대(5G) 연결, 4세대 롱 텀 이볼루션(4G LTE(long term evolution)) 연결, Wi-Fi 연결, USB 연결, 블루투스 연결 등을 포함할 수 있는 연결 블록, 및 예를 들어, 제스처들을 검출하고 인식할 수 있는 멀티미디어 프로세서와 같이 특정 기능들에 맞추어진 추가의 프로세 싱 블록들을 포함할 수 있다. 일 구현에서, NPU는 CPU, DSP 및/또는 GPU에서 구현된다. SOC는 또한 센서 프로세서, 이미지 신호 프로세서(ISP: image signal processor)들 및/또는 글 로벌 포지셔닝 시스템을 포함할 수 있는 내비게이션 모듈을 포함할 수 있다. SOC는 ARM 명령 세트에 기초할 수 있다. 본 개시내용의 일 양상에서, 범용 프로세서에 로딩 된 명령들은 인공 신경망(ANN)에 의해 입력을 수신하는 코드를 포함할 수 있다. 범용 프로세서는 또한 ANN을 통해 입력의 잠재적 표현을 생성하는 코드를 포함할 수 있다. 범용 프로세서는 학습된 잠재적 스케 일링 파라미터에 기초하여 비트 레이트에 따라 잠재적 표현을 전달하는 코드를 추가로 포함할 수 있다. 본 개시내용의 다른 양상에서, 범용 프로세서에 로딩된 명령들은 인공 신경망(ANN)에 의해 입력 비 트 스트림을 수신하는 코드를 포함할 수 있다. 범용 프로세서는 또한 입력의 잠재적 표현을 복구하기 위 해 학습된 잠재적 스케일링 파라미터를 입력 비트 스트림에 적용하는 코드를 포함할 수 있다. 범용 프로세서 는 입력의 재구성을 생성하기 위해 ANN을 통해 잠재적 표현을 디코딩하는 코드를 추가로 포함할 수 있다. 심층 학습 아키텍처들은 각각의 계층에서 연속적으로 더 높은 레벨의 추상에서 입력들을 나타내도록 학 습함으로써 객체 인식 작업을 수행할 수 있으며, 이에 의해 입력 데이터의 유용한 특징 표현을 구축할 수 있다. 이러한 방식으로, 심층 학습은 종래의 기계 학습의 주요 병목 현상을 해결한다. 심층 학습의 등장 전에, 객체 인식 문제에 대한 기계 학습 접근법은 아마도 얕은 분류기와 결합하여 인간이 엔지니어링한 특징들에 크게 의존 했을 수 있다. 얕은 분류기는 예를 들어, 특징 벡터 구성 요소들의 가중 합이 입력이 어떤 클래스에 속하는지 예측하기 위해 임계값과 비교될 수 있는 2-클래스 선형 분류기일 수 있다. 인간이 엔지니어링한 특징들은 도메 인 전문 지식을 갖춘 엔지니어들에 의해 특정 문제 영역에 맞춤화된 템플릿들 또는 커널들일 수 있다. 반대로, 심층 학습 아키텍처들은 인간 엔지니어가 설계할 수 있는 것과 유사하지만 훈련을 통해 특징들을 표현하는 것을 학습할 수 있다. 추가로, 심층 네트워크는 인간이 고려하지 않았을 수 있는 새로운 유형의 특징들을 표현하고 인식하는 것을 학습할 수 있다. 심층 학습 아키텍처는 특징들의 계층 구조를 학습할 수 있다. 예를 들어, 시각적 데이터가 제시되는 경 우, 제1 계층은 입력 스트림에서 에지(edge)들과 같은 비교적 간단한 특징들을 인식하는 것을 학습할 수 있다. 다른 예에서, 청각 데이터가 제시된 경우, 제1 계층은 특정 주파수들에서 스펙트럼 전력을 인식하는 것을 학습 할 수 있다. 제1 계층의 출력을 입력으로 취하는 제2 계층은 시각적 데이터에 대한 단순한 형상들 또는 청각 데이터에 대한 소리들의 조합과 같은 특징들의 조합들을 인식하는 것을 학습할 수 있다. 예를 들어, 상위 계층 들은 시각적 데이터의 복잡한 형상들이나 청각 데이터의 단어들을 표현하기 위해 학습할 수 있다. 더 높은 계 층들은 일반적인 시각적 객체들 또는 구술 문구들을 인식하기 위해 학습할 수 있다. 심층 학습 아키텍처들은 자연스러운 계층 구조를 갖는 문제들에 적용될 때 특히 잘 수행될 수 있다. 예 를 들어, 동력 차량들의 분류는 휠(wheel)들, 윈드실드(windshield)들 및 다른 특징들을 인식하는 제1 학습으로 부터 이점을 얻을 수 있다. 이러한 특징들은 자동차들, 트럭들 및 비행기들을 인식하기 위해 상이한 방식들로 상위 계층들에서 조합될 수 있다. 신경망들은 다양한 연결 패턴들로 설계될 수 있다. 피드-포워드(feed-forward) 네트워크들에서, 정보는 하위 계층들로부터 상위 계층들로 전달되며, 주어진 계층의 각각의 뉴런은 상위 계층들의 뉴런들에 전달한다. 상술한 바와 같이, 계층적 표현은 피드-포워드 네트워크의 연속적인 계층들에서 구축될 수 있다. 신경망들은 또한 순환 또는 피드백(톱-다운(top-down)이라고도 칭함) 연결들을 가질 수 있다. 순환 연결에서, 주어진 계층 의 뉴런으로부터의 출력은 동일한 계층의 다른 뉴런으로 전달될 수 있다. 순환 아키텍처는 시퀀스에서 신경망 에 전달되는 하나 초과의 입력 데이터 청크(chunk)들에 걸쳐 있는 패턴들을 인식하는 데 도움이 될 수 있다. 주어진 계층의 뉴런으로부터 하위 계층의 뉴런으로의 연결을 피드백(또는 톱-다운) 연결이라고 칭한다. 다수의 피드백 연결들을 갖는 네트워크는 높은 레벨의 개념의 인식이 입력의 특정 낮은 레벨의 특징들을 구분하는 것을 지원할 수 있을 때 도움이 될 수 있다. 신경망의 계층들 사이의 연결들은 완전히 연결되거나 부분적으로 연결될 수 있다. 도 2a는 완전히 연결 된 신경망의 일 예를 예시한다. 완전히 연결된 신경망에서, 제1 계층의 뉴런은 제2 계층의 모든 뉴런에 그 출력을 전달할 수 있어, 제2 계층의 각각의 뉴런은 제1 계층의 모든 뉴런으로부터 입력을 수신할 것이다. 도 2b는 국부적으로 연결된 신경망의 일 예를 예시한다. 국부적으로 연결된 신경망에서, 제1 계층의 뉴런은 제2 계층의 제한된 개수의 뉴런들에 연결될 수 있다. 보다 일반적으로, 국부적으로 연결된 신경 망의 국부적으로 연결된 계층은 계층의 각각의 뉴런이 동일하거나 유사한 연결 패턴을 갖지만 상이한 값들 (예를 들어, 210, 212, 214 및 216)을 가질 수 있는 연결 강도들을 갖도록 구성될 수 있다. 국부적으로 연결된 연결 패턴은, 주어진 영역의 상위 계층 뉴런들이 네트워크에 대한 전체 입력의 제한된 부분의 특성들에 대한 훈 련을 통해 튜닝된 입력들을 수신할 수 있기 때문에, 상위 계층에서 공간적으로 구별되는 수용 필드들을 생성할 수 있다. 국부적으로 연결된 신경망의 일 예는 컨벌루션 신경망이다. 도 2c는 컨벌루션 신경망의 일 예를 예시한다. 컨벌루션 신경망은 제2 계층의 각각의 뉴런에 대한 입력들과 연관된 연결 강도들이 공유되도록 (예를 들어, 208) 구성될 수 있다. 컨벌루션 신경망들은 입력들의 공간적 위치가 의미 있는 문제에 매우 적합 할 수 있다. 컨벌루션 신경망의 하나의 유형은 심층 컨벌루션 네트워크(DCN: deep convolutional network)이다. 도 2d는 자동차-장착 카메라와 같은 이미지 캡처 디바이스로부터 입력된 이미지로부터 시각적 특징들을 인식하도록 설계된 DCN의 상세한 예를 예시한다. 본 예의 DCN은 교통 표지판들 및 교통 표지판 상에 제공된 번호를 식별하도록 훈련될 수 있다. 물론, DCN은 차선 표시 식별 또는 신호등 식별과 같은 다른 작업들을 위해 훈련될 수 있다. DCN은 지도 학습으로 훈련될 수 있다. 훈련 동안, DCN은 속도 제한 표지판의 이미지와 같은 이미지를 제공받을 수 있고, 출력을 생성하기 위해 순방향 전달이 컴퓨팅될 수 있다. DCN은 특 징 추출 섹션 및 분류 섹션을 포함할 수 있다. 이미지 수신 시, 컨벌루션 계층은 컨벌루션 커널들 (미도시)을 이미지에 적용하여 특징 맵들의 제1 세트를 생성할 수 있다. 예를 들어, 컨벌루션 계층 에 대한 컨벌루션 커널은 28x28 특징 맵들을 생성하는 5x5 커널일 수 있다. 본 예에서, 4 개의 상이한 특 징 맵들이 특징 맵들의 제1 세트에서 생성되므로, 4 개의 상이한 컨벌루션 커널들이 컨벌루션 계층에 서 이미지에 적용되었다. 컨벌루션 커널들은 필터들 또는 컨벌루션 필터들이라고도 지칭될 수 있다. 특징 맵들의 제1 세트는 최대 풀링(pooling) 계층(미도시)에 의해 서브샘플링되어 특징 맵들의 제2 세트를 생성할 수 있다. 최대 풀링 계층은 특징 맵들의 제1 세트의 크기를 감소시킨다. 14x14와 같 은 특징 맵들의 제2 세트의 크기는 28x28과 같은 특징 맵들의 제1 세트의 크기보다 작다. 감소된 크 기는 메모리 소비를 감소시키면서 후속 계층에 유사한 정보를 제공한다. 특징 맵들의 제2 세트는 하나 이 상의 후속 컨벌루션 계층들(미도시)을 통해 추가로 컨벌루션되어 특징 맵들의 하나 이상의 후속 세트들(미도 시)을 생성할 수 있다. 도 2d의 예에서, 특징 맵들의 제2 세트는 제1 특징 벡터를 생성하기 위해 컨벌루션된다. 추 가로, 제1 특징 벡터는 제2 특징 벡터를 생성하기 위해 추가로 컨벌루션된다. 제2 특징 벡터의 각각의 특징은 \"부호\", \"60\" 및 \"100\"과 같은 이미지의 가능한 특징에 대응하는 숫자를 포함할 수 있다. 소프트맥스(softmax) 함수(미도시)는 제2 특징 벡터의 숫자를 확률로 변환할 수 있다. 이와 같이, DCN의 출력은 하나 이상의 특징들을 포함하는 이미지의 확률이다. 본 예에서, \"부호\" 및 \"60\"에 대한 출력의 확률들은 \"30\", \"40\", \"50\", 70\", \"80\", \"90\" 및 \"10 0\"과 같은 출력 중 다른 것들의 확률들보다 더 높다. 훈련 전에, DCN에 의해 생성된 출력은 부 정확할 가능성이 있다. 따라서, 출력과 타깃 출력 사이에 오차가 계산될 수 있다. 타깃 출력은 이미지 의 실측 자료(예를 들어, \"부호\" 및 \"60\")이다. 그 후 DCN의 가중치들이 조정될 수 있어 DCN 의 출력이 타깃 출력에 더 가깝게 정렬된다. 가중치들을 조정하기 위해, 학습 알고리즘은 가중치들에 대한 기울기 벡터를 컴퓨팅할 수 있다. 기울기 는 가중치가 조정된 경우 오류가 증가하거나 감소하는 양을 나타낼 수 있다. 최상위 계층에서 기울기는 끝에서 두 번째 계층의 활성화된 뉴런과 출력 계층의 뉴런을 연결하는 가중치 값에 직접적으로 대응할 수 있다. 하위 계층들에서, 기울기는 가중치들의 값과 상위 계층들의 컴퓨팅된 오류 기울기들에 따를 수 있다. 그 후, 가중치 들이 조정되어 오류를 줄일 수 있다. 가중치들을 조정하는 이러한 방식은 신경망을 통한 \"역전달\"을 포함하므 로 \"역전파\"라고 칭할 수 있다. 실제로, 가중치들의 오류 기울기가 적은 수의 예들에 대해 계산될 수 있어, 계산된 기울기가 실제 오류 기울기 근사한다. 이러한 근사 방법은 스토캐스틱(stochastic) 기울기 하강법이라고 칭할 수 있다. 전체 시스 템의 달성 가능한 오류 레이트가 감소를 멈추거나 오류 레이트가 타깃 레벨에 도달할 때까지 스토캐스틱 기울기 하강법이 반복될 수 있다. 학습 후, DCN에 새로운 이미지들이 제시될 수 있고 네트워크를 통한 순방향 전달은 DCN의 추론 또는 예측으로 간주될 수 있는 출력을 산출할 수 있다. 심층 신뢰 네트워크(DBN: Deep belief network)들은 숨겨진 노드들의 복수의 계층들을 포함하는 확률 모 델들이다. DBN들은 훈련 데이터 세트들의 계층적 표현을 추출하는 데 사용될 수 있다. DBN은 제한된 볼츠만 기계(RBM: Restricted Boltzmann Machine)들의 계층들을 적층하여 획득될 수 있다. RBM은 입력들의 세트에 걸 친 확률 분포를 학습할 수 있는 인공 신경망의 유형이다. RBM은 각각의 입력이 카테고리화되어야 하는 클래스 에 대한 정보가 없을 때 확률 분포를 학습할 수 있기 때문에, RBM들은 비지도 학습에 자주 사용된다. 하이브리 드 비지도 및 지도 패러다임을 사용하여, DBN의 바닥 RBM들은 비지도 방식으로 훈련될 수 있으며 특징 추출기들 로서의 역할을 할 수 있고, 최상위 RBM은 (이전 계층 및 타깃 클래스들로부터의 입력들의 공동 분포에 대해) 지 도 방식으로 훈련될 수 있으며, 분류기로서의 역할을 할 수 있다. 심층 컨벌루션 네트워크(DCN)들은 추가 풀링 및 정규화 계층들로 구성된 컨벌루션 네트워크들의 네트워 크들이다. DCN들은 많은 작업들에서 최신 기술 성능을 달성했다. DCN들은 지도 학습을 사용하여 훈련될 수 있 으며, 여기서 입력 및 출력 타깃들 모두는 많은 예들에 대해 알려져 있으며 기울기 하강 방법들을 사용하여 네 트워크의 가중치들을 수정하는 데 사용된다. DCN들은 피드-포워드 네트워크들일 수 있다. 또한, 상술한 바와 같이, DCN의 제1 계층의 뉴런으로부터 다음 상위 계층의 뉴런들의 그룹으로의 연결들은 제1 계층의 뉴런들에 걸쳐 공유된다. DCN들의 피드-포워드 및 공유된 연결들은 빠른 프로세싱을 위해 이용될 수 있다. 예를 들어, DCN의 컴퓨테이션 부담은 순환 또는 피드 백 연결들을 포함하는 비슷한 크기의 신경망보다 훨씬 적을 수 있다. 컨벌루션 네트워크의 각각의 계층의 프로세싱은 공간적으로 불변의 템플릿 또는 기본 프로젝션 (projection)으로 간주될 수 있다. 입력이 먼저 컬러 이미지의 적색, 녹색 및 청색 채널들과 같은 복수의 채널 들로 분해되면, 해당 입력에 대해 훈련된 컨벌루션 네트워크는 이미지 축들을 따라 2 개의 공간 차원들을 갖는 3차원 및 컬러 정보를 캡처하는 3차원으로 간주될 수 있다. 컨벌루션 연결들의 출력들은 후속 계층에서 특징 맵을 형성하는 것으로 간주될 수 있으며, 특징 맵의 각각의 요소(예를 들어, 220)는 이전 계층의 뉴런들의 범위 (예를 들어, 특징 맵들)로부터 그리고 복수의 채널들의 각각으로부터 입력을 수신한다. 특징 맵의 값들은 렉티피케이션(rectification), max(0, x)와 같은 비선형성으로 추가로 프로세싱될 수 있다. 인접한 뉴런들로부 터의 값들은 추가로 풀링될 수 있으며, 이는 다운 샘플링에 대응하며 추가적인 로컬 불변성 및 차원 감소를 제 공할 수 있다. 화이트닝(whitening)에 대응하는 정규화는 특징 맵에서 뉴런들 간의 측면 억제를 통해 적용될 수도 있다. 심층 학습 아키텍처들의 성능은 더 많은 라벨링된 데이터 포인트들이 이용 가능해지거나 컴퓨테이션 능 력이 증가할수록 증가할 수 있다. 현대의 심층 신경망들은 15년 전 통상의 연구원이 사용할 수 있었던 것보다 수천 배 더 큰 컴퓨팅 자원들로 일상적으로 훈련된다. 새로운 아키텍처들과 훈련 패러다임들은 심층 학습의 성 능을 추가로 부스팅(boosting)할 수 있다. 정류된 선형 유닛들은 기울기 소실로 알려진 훈련 문제를 감소시킬 수 있다. 새로운 훈련 기법들은 오버-피팅(over-fitting)을 감소시켜 더 큰 모델들이 더 나은 일반화를 달성할 수 있게 한다. 캡슐화 기법들은 주어진 수용 필드에서 데이터를 추출하고 전반적인 성능을 추가로 부스팅할 수 있다. 도 3은 심층 컨벌루션 네트워크를 예시하는 블록도이다. 심층 컨벌루션 네트워크는 연결성 및 가중치 공유에 기초한 복수의 상이한 유형의 계층들을 포함할 수 있다. 도 3에 도시된 바와 같이, 심층 컨 벌루션 네트워크는 컨벌루션 블록들(354A, 354B)을 포함한다. 컨벌루션 블록들(354A, 354B)의 각각은 컨 벌루션 계층(CONV), 정규화 계층(LNorm) 및 최대 풀링 계층(MAX POOL)으로 구성될 수 있다. 컨벌루션 계층들은 특징 맵을 생성하기 위해 입력 데이터에 적용될 수 있는 하나 이상의 컨벌루션 필터들을 포함할 수 있다. 컨벌루션 블록들(354A, 354B) 중 2 개만이 도시되었지만, 본 개시내용은 이에 제한 되지 않고, 대신에 설계 선호도에 따라 임의의 개수의 컨벌루션 블록들(354A, 354B)이 심층 컨벌루션 네트워크 에 포함될 수 있다. 정규화 계층은 컨벌루션 필터들의 출력을 정규화할 수 있다. 예를 들어, 정규 화 계층은 화이트닝 또는 측면 억제를 제공할 수 있다. 최대 풀링 계층은 로컬 불변성 및 차원 감소 를 위해 공간에 대한 다운 샘플링 집합을 제공할 수 있다. 예를 들어, 심층 컨벌루션 네트워크의 병렬 필터 뱅크들은 SOC의 CPU 또는 GPU에 로딩되 어 고성능 및 저전력 소모를 달성할 수 있다. 대안적인 실시예들에서, 병렬 필터 뱅크들은 SOC의 DSP 또는 ISP 상에 로딩될 수 있다. 또한, 심층 컨벌루션 네트워크는 각각 센서 및 내비게이션 에 전용인 센서 프로세서 및 내비게이션 모듈과 같이 SOC 상에 존재할 수 있는 다른 프로세싱 블록들에 액세스할 수 있다. 심층 컨벌루션 네트워크는 또한 하나 이상의 완전 연결 계층들(FC1 및 FC2)을 포함할 수 있다. 심층 컨벌루션 네트워크는 로지스틱(logistic) 회귀(LR: logistic regression) 계층을 추가 로 포함할 수 있다. 심층 컨벌루션 네트워크의 각각의 계층(356, 358, 360, 362, 364) 사이에는 업데이트 될 가중치들(미도시)이 있다. 계층들(예를 들어, 356, 358, 360, 362, 364)의 각각의 출력은 컨벌루션 블록들 (354A)의 첫 번째에서 공급되는 입력 데이터(예를 들어, 이미지들, 오디오, 비디오, 센서 데이터 및/또는 다른 입력 데이터)로부터 계층적 특징 표현들을 학습하기 위해 심층 컨벌루션 네트워크에서 계층들(예를 들어, 356, 358, 360, 362, 364)의 다음 것으로의 입력으로서의 역할을 할 수 있다. 심층 컨벌루션 네트워크 의 출력은 입력 데이터에 대한 분류 스코어이다. 분류 스코어는 확률들의 세트일 수 있으 며, 여기서 각각의 확률은 특징들의 세트로부터의 특징을 포함하는 입력 데이터의 확률이다. 도 4는 인공 지능(AI) 기능들을 모듈화할 수 있는 예시적인 소프트웨어 아키텍처를 예시하는 블록 도이다. 아키텍처를 사용하여, SOC(예를 들어, CPU, DSP, GPU 및/또는 NPU)의 다양 한 프로세싱 블록들로 하여금 본 개시내용의 양상들에 따라 AI 애플리케이션에 대한 사후-훈련 양자화를 위해 개시된 적응형 반올림(rounding)을 지원하게 할 수 있는 애플리케이션들이 설계될 수 있다. AI 애플리케이션은 예를 들어, 디바이스가 현재 동작하는 위치를 나타내는 장면의 검출 및 인식을 제공할 수 있는 사용자 공간에 정의된 기능들을 호출하도록 구성될 수 있다. AI 애플리케이션은 예 를 들어, 인식된 장면이 사무실인지, 강의실인지, 식당인지 또는 호수와 같은 야외 환경인지에 따라 마이크로폰 과 카메라를 상이하게 구성할 수 있다. AI 애플리케이션은 AI 기능 애플리케이션 프로그래밍 인터페이스 (API: application programming interface)에 정의된 라이브러리와 연관된 컴파일된 프로그램 코드에 요 청할 수 있다. 이러한 요청은 예를 들어, 비디오 및 포지셔닝 데이터에 기초한 추론 응답을 제공하도록 구성된 심층 신경망의 출력에 궁극적으로 의존할 수 있다. 런타임 프레임워크의 컴파일된 코드일 수 있는 런-타임 엔진은 AI 애플리케이션에 추가로 액 세스할 수 있다. AI 애플리케이션은 예를 들어, 런-타임 엔진으로 하여금 특정 시간 간격으로 또는 애플 리케이션의 사용자 인터페이스에 의해 검출된 이벤트에 의해 트리거링되어 추론을 요청하게 할 수 있다. 추론 응답을 제공하게 되면, 런-타임 엔진은 결국 SOC 상에서 실행되는 커널과 같은 운영 체제(OS) 공간 의 운영 체제에 신호를 송신할 수 있다. 결국, 운영 체제는 양자화의 연속 완화가 CPU, DSP, GPU, NPU 또는 이들의 일부 조합에서 수행되게 할 수 있다. CPU는 운영 체제에 의해 직접 액세 스될 수 있고, DSP, GPU 또는 NPU 각각에 대한 드라이버(414, 416 또는 418)와 같은 드라이버 를 통해 다른 프로세싱 블록들이 액세스될 수 있다. 예시적인 예에서, 심층 신경망은 CPU, DSP 및 GPU와 같은 프로세싱 블록들의 조합에서 실행되도록 구성되거나 NPU에서 실행될 수 있다. 애플리케이션(예를 들어, AI 애플리케이션)은 예를 들어 디바이스가 현재 동작하는 위치를 나타내 는 장면의 검출 및 인식을 제공할 수 있는 사용자 공간에 정의된 기능들을 호출하도록 구성될 수 있다. 애플리케이션은 예를 들어, 인식된 장면이 사무실, 강의실, 식당 또는 호수와 같은 야외 환경인지에 따라 마이크로폰과 카메라를 상이하게 구성할 수 있다. 애플리케이션은 현재 장면의 추정치를 제공하기 위해 장면 검출(SceneDetect) 애플리케이션 프로그래밍 인터페이스(API)에 정의된 라이브러리와 연관된 컴파일 된 프로그램 코드에 요청할 수 있다. 이러한 요청은 궁극적으로 예를 들어, 비디오 및 포지셔닝 데이터에 기초 하여 장면 추정치들을 제공하도록 구성된 차동 신경망의 출력에 의존할 수 있다. 런-타임 프레임워크의 컴파일된 코드일 수 있는 런-타임 엔진은 애플리케이션에 추가로 액세 스할 수 있다. 애플리케이션은 예를 들어, 런-타임 엔진으로 하여금 특정 시간 간격에서 또는 애플리케이 션의 사용자 인터페이스에 의해 검출된 이벤트에 의해 트리거링되어 장면 추정치를 요청하게 할 수 있다. 장면 을 추정하게 되면, 런-타임 엔진은 결국 SOC에서 실행되는 커널과 같은 운영 체제에 신호를 송 신할 수 있다. 운영 체제는 결국 CPU, DSP, GPU, NPU 또는 이들의 일부 조합에서 컴퓨테이션이 수행되게 할 수 있다. CPU는 운영 체제에 의해 직접 액세스될 수 있고, DSP, GPU 또는 NPU에 대한 드라이버(414-418)와 같은 드라이버를 통해 다른 프로세싱 블록들이 액세스될 수 있다.예시적인 예에서, 차동 신경망은 CPU 및 GPU와 같은 프로세싱 블록의 조합에서 실행되도록 구성되거 나 NPU에서 실행될 수 있다. 본 개시내용의 양상들은 소프트 네스팅된(nested) 드롭아웃(dropout)을 통한 신경 가변 비트 레이트 모 델에 관한 것이다. 도 5는 본 개시내용의 양상들에 따른 가변 비트 레이트 모델의 예시적인 아키텍처를 예시하는 블록 도이다. 도 5를 참조하면, 예시적인 아키텍처는 인코더 및 디코더를 포함한다. 입력은 인코더에 의해 수신될 수 있다. 입력은 예를 들어, 비디오 또는 이미지와 같은 시각적 입력일 수 있 다. 인코더는 예를 들어, 컨벌루션 신경망(CNN)일 수 있다. 인코더는 이미지를 프로세싱하고 CNN의 계층들을 통해 파라미터화된 비선형 변환을 수행하여 입력의 잠재적 표현 y를 생성할 수 있다. 입력(50 2)의 잠재적 표현 y는 양자화되어(예를 들어, 부동 소수점 수를 정수로 반올림) 양자화된 잠재적 표현 를 생 성할 수 있다. 양자화된 잠재적 표현 는 산술 인코딩(AE: arithmetic encoding)을 거칠 수 있고 비트 스트림 을 통해 전달될 수 있다. 그 후 디코더 측에서, 수신된 비트 스트림은 산술 디코딩(AD: arithmetic decoding)을 거쳐 양자화된 잠재적 를 재생할 수 있으며, 는 CNN의 몇몇 계층들에 의해 파라미터화될 수 있는 디코더를 통해 감지 변환된다. 따라서, 디코더는 재구성된 이미지를 생성한다. 본 개시내용의 양상들에 따르면, 아키텍처(예를 들어, 인공 신경망(ANN))는 D + βR에 의해 주어진 목적 함수에 따라 훈련될 수 있으며, 여기서 D는 왜곡이고, R은 레이트이고, β는 라그랑주(LaGrange) 승수이다. 목적 함수를 사용하여, ANN은 레이트 R(비트들의 양)과 왜곡 D를 밸런싱하도록 훈련될 수 있다. 레 이트 R은 엔트로피 코딩 페이즈(phase)로부터의 비트들의 개수에 대응하며 얼마나 많은 정보를 송신할지 결정한 다. 왜곡 D는 재구성된 이미지와 원본 입력(예를 들어, 원본 이미지) 사이의 차이로서 계산될 수 있 다. 라그랑주 승수 β는 두 가지 목적들 - 왜곡 감소 및 입력 전송에 사용되는 비트 레이트 감소 -의 트레이드 오프를 밸런싱하는 데 사용되는 트레이드-오프 파라미터일 수 있다. 도 6a는 본 개시내용의 양상들에 따른 가변 비트 레이트 모델에 대한 예시적인 아키텍처를 예시하 는 블록도이다. 도 6a를 참조하면, 예시적인 아키텍처는 인공 신경망일 수 있다. 일부 양상들에서, 아키 텍처는 예를 들어, 오토인코더로서 구성될 수 있다. 아키텍처는 잠재적 스케일링을 통해 가변 비트 레이트로 비트 스트림을 제공하도록 구성된다. 그렇게 함으로써, 아키텍처는 잠재적 용량 또는 레이트를 지속적으로 제어하기 위한 방법을 제공한다. 아키텍처는 인코더 및 디코더를 포함한다. 인코 더는 입력을 수신하고 이미지와 같은 입력을 잠재적 표현 y로 변환한다. 잠재적 표현은 스케일링 블록 에 공급될 수 있으며, 여기서 학습 가능한 잠재적 스케일링 파라미터 s가 잠재적 표현 y에 적용된다. 잠 재적 스케일링 파라미터 s는 정렬된 표현의 학습을 용이하게 할 수 있다. 일부 양상들에서, 잠재적 스케일링 파라미터 s는 채널 인덱스 c에 의존할 수 있다. 채널은 잠재적 표현 y의 일부로 볼 수 있다. 채널들의 각각은 결합되어 이미지를 완전히 재구성할 수 있다. 그러나, 이미지의 채널들 간에 약간의 리던던시(redundancy)가 있을 수 있다. 리던던시는 프로세싱 지연들로 이어질 수 있다. 프로세싱 지연들을 줄이기 위해, 하나 이상의 리던던트 채널들이 지능적으로 드롭핑(dropping)될 수 있다. 잠재적 스케일링 파라미터 s와 채널 인덱스 c 사이의 매핑은 채널 인덱스 c가 더 클 때(예를 들어, 더 많은 채널들을 송신하기 위해), 잠재적 스케일링 파라미터 s가 예를 들어, 더 커지도록 학습될 수 있다. 주어 진 임의의 잠재적 채널에 대해, 잠재적 스케일링 파라미터 s는 채널의 정보량을 제어한다. 잠재적 스케일링 파 라미터 s가 클수록 채널의 정보가 적다. 반대로, 종래의 신경망 코덱(codec) 훈련에서, 채널의 스케일링 팩터 를 임의의 잠재적 값보다 크게 설정하는 것은 해당 채널의 모든 잠재적 값이 0으로 양자화되는 것을 초래하며, 이는 잠재적 채널이 효과적으로 드롭핑 아웃(dropping out)되는 것을 의미한다. 일부 양상들에서, 스케일링 파라미터 s는 트레이드-오프 파라미터 β에 기초하여 학습될 수 있고, 여기 서 β는 왜곡과 비트 레이트를 밸런싱한다. 따라서, 학습된 잠재적 스케일링 파라미터 s, 채널 인덱스 및 트레 이드오프 파라미터 값 β는 큰 β(예를 들어, 더 작은 비트 레이트 모델을 달성하기 위해 레이트에 더 많은 페 널티)가 큰 드롭아웃 레이트(예를 들어, 더 많은 채널을 드롭핑)에 대응할 수 있도록 관련될 수 있으며, 이는 큰 잠재적 스케일링 파라미터 s에 대응한다. 한편, 큰 채널 인덱스 c는 큰 잠재적 스케일링 파라미터 s에 대응 할 수 있다. 잠재적 스케일링 파라미터 s는 소프트 드롭아웃을 사용하여 결정된 비트 레이트를 지속적으로 제어할 수 있다. 즉, 상이한 잠재적 공간 차원들에 대해 동일한 레이트 페널티를 부과하는 대신, 레이트 페널티는 잠재적 스케일링 파라미터 s에 따라 변경되거나 조정될 수 있다. 예를 들어, 스케일링된 잠재적 표현 y/s의 절대값이 사전 정의된 값(예를 들어, 0.5)보다 작으면, 잠재적 표현의 채널이 효과적으로 드롭핑될 수 있다. 일부 양상 들에서, 사전 정의된 값은 양자화 임계값일 수 있거나 이에 대응할 수 있다. 극단적인 경우, s가 무한대로 가 면, 모든 잠재적 공간들 0이 되고 모든 채널들이 드롭핑될 것이다. 훈련 동안, 트레이드오프 파라미터 값 β는 균일하게(예를 들어, 선형 공간 또는 로그 공간에서 균일하 게) (예를 들어, 연속적으로 또는 카테고리 변수로서) 샘플링될 수 있다. 상이한 트레이드오프 파라미터 값 β 는 상이한 목적 함수들(D + β * R)을 초래할 수 있다. 따라서, 더 작은 트레이드오프 파라미터 값들 β에 대 해 훈련된 모델들이 더 큰 비트 레이트를 가질 수 있도록 더 작은 트레이드오프 파라미터 값들 β가 비트 레이 트에 대해 더 적게 페널티를 줄 수 있으므로 상이한 비트 레이트를 갖는 모델들이 생성될 수 있다. 반대로, 더 큰 트레이드오프 파라미터 값들 β는 비트 레이트에 더 많은 페널티를 줄 수 있어 결과적인 비트 레이트는 더 작을 것이다. 일부 양상들에서, 잠재적 스케일링 파라미터 s는 인코더 및 디코더 가중치들의 훈련과 공동으로 학습될 수 있다. 대안적으로, 인코더 및 디코더의 가중치들은 잠재적 스케일링 파라미터 s의 학습 중에 고정될 수 있 다. 일부 양상들에서, 트레이드오프 파라미터 값들 β는 또한 잠재적 스케일링 파라미터 s의 학습 동안 고정될 수 있다. 스케일링된 잠재적 y/s는 양자화 블록에 공급될 수 있다. 양자화 블록은 양자화 출력 [y/s] 을 생성하기 위해 예를 들어, 반올림과 같은 양자화 함수를 사용하여 스케일링된 잠재적 y/s를 양자화할 수 있 다. 양자화된 출력 [y/s]는 그 후 산술 인코딩을 위해 엔트로피 모델에 공급되며, 이는 그 후 비트 스트 림을 통해 전달된다. 엔트로피 모델은 잠재적 표현의 비트 레이트를 결정하는 데 결국 사용될 수 있는 잠 재적 표현의 확률 질량을 컴퓨팅한다. 하이퍼 코덱 블록들은 잠재적 표현에 포함된 정보에 대한 보완으로서 사 이드 정보를 인코딩할 수 있다. 디코더 측에서, 비트 스트림의 수신된 비트들에 대해 산술 디코딩이 수행되어 양자화된 출력 [y/s]를 복 구한다. 스케일링 파라미터 s를 사용하는 리스케일링(rescaling)은 리스케일링 블록을 통해 s[y/s](본질 적으로 s를 곱함)로서 양자화된 출력에 적용된다. 디코더는 재구성된 입력(예를 들어, 이미지)을 생성하 기 위해 복구된 잠재적 표현을 프로세싱할 수 있다. 잠재적 스케일링 파라미터 s를 학습한 아키텍처는 예를 들어, 채널 조건들에 기초하여 가변 비트 레이트로 이미지와 같은 입력을 사용자에게 전달하도록 동작될 수 있다. 도 6b는 본 개시내용의 양상들에 따라 입력을 나타내기 위한 잠재적 공간의 채널들을 예시하는 도 면이다. 도 6b를 참조하면, 잠재적 공간은 예를 들어, 이미지 또는 비디오와 같은 입력을 나타낼 수 있다. 잠재적 공간은 채널들 0-N의 세트를 포함할 수 있다. 채널들의 각각은 상이한 비트 레이트에 대응 할 수 있다. 입력을 전달하기 위한 가장 높은 비트 레이트는 입력을 나타내는 잠재적 공간의 N 개의 채널 들 모두를 전달하는 것에 대응할 수 있다. 비트 레이트는 잠재적 공간의 하나 이상의 채널들을 드롭핑(예 를 들어, 전송하지 않음)함으로써 감소될 수 있다. 본 개시내용의 양상들에 따르면, 비트 레이트는 잠재적 스 케일링 파라미터 s에 기초하여 지속적으로 제어된다. 즉, 잠재적 스케일링 파라미터 s가 스케일링된 잠재적 표 현 y/s의 절대값이 사전 정의된 값(예를 들어, 0.5)보다 작도록 되는 경우, 잠재적 공간의 채널은 효과적 으로 드롭핑되거나 절단될 수 있다. 일부 양상들에서, 사전 정의된 값은 양자화 임계값일 수 있거나 이에 대응 할 수 있다. 하드(hard) 드롭 아웃에서와 같이 임의의 인덱스 b 위의 채널을 단순히 드롭핑하는 대신, 채널 인 덱스와 트레이드오프 파라미터의 함수인 학습된 확장성에 기초하여 채널들을 드롭핑함으로써, 다중-레이트 모델 타깃이 상이한 레이트-왜곡 목적들을 위해 달성될 수 있다. 도 6c는 본 개시내용의 양상들에 따른 예시적인 잠재적 공간을 예시하는 블록도이다. 도 6c를 참 조하면, 잠재적 공간은 N 개의 채널로 분할된다. N 개의 채널의 각각은 상이한 개수의 비트들을 포함할 수 있다. 가장 높은 비트 레이트는 잠재적 공간의 모든 채널들의 비트들을 포함한다. 이와 같이, 가장 높은 비트 레이트는 낮은 레이트의 비트들을 포함한다. 예를 들어, 가장 높은 비트 레이트는 채널 0의 비트들을 포 함한다. 가장 낮은 비트 레이트는 채널 0의 비트들만을 포함할 수 있다. 따라서, 비트 레이트는 채널들을 드롭핑 또는 절단함으로써, 따라서 잠재적 스케일링 파라미터에 기초하 여 잠재적 공간의 비트들을 드롭핑함으로써 수정될 수 있다. 도 6d는 본 개시내용의 양상들에 따른 가변 비트 레이트에 대한 아키텍처를 예시하는 블록도이다. 도 6d를 참조하면, 아키텍처는 인코더 및 디코더를 포함하고 도 6a의 아키텍처와 유사하게 구성될 수 있다. 그러나, 인코더 및 디코더의 가중치 훈련과 함께 잠재적 스케일링 파라미터를 공동 으로 학습하는 대신, 인코더 및 디코더의 가중치들은 가역 매핑 훈련 동안 고정될 수 있다. 즉, 잠재성의 1x1 변환 및 1x1 역 변환이 학습될 수 있다. 그렇게 함으로써, 잠재적 공간이 정렬될 수 있고 스 케일링 파라미터 s가 학습될 수 있다. 이와 같이, 변환 yt 후 잠재적 표현이 주어지면, 잠재적 스케일링 파라 미터 s는 인코더 측(예를 들어, 672)에서 [yt/s]로 양자화되는 스케일링된 잠재적 yt/s를 형성하도록 적용될 수 있다. 그 후 디코더 측(예를 들어, 674)에서, 양자화된 출력 [yt/s]가 수신된다. 스케일링 파라미터 s는 양자 화된 출력에 s[y/s](본질적으로 s를 곱함)로서 적용된다. 그 후 역 변환이 수행되고 그 결과는 출력을 생성하 기 위해 디코더에 공급된다. 일부 양상들에서, 트레이드오프 파라미터 값들 β는 또한 가역 매핑만이 훈 련되도록 고정될 수 있다. 도 7a 및 도 7b는 본 개시내용의 양상들에 따라 양자화 비트 폭을 스케일링하기 위한 예시적인 벨(bell) 곡선들(700 및 750)을 예시하는 도면들이다. 도 7a를 참조하면, 벨 곡선 및 양자화 반올림 포인트들의 세 트(702a-n)가 도시되어 있다. 스케일링 파라미터 s=1이 잠재적 표현에 적용된다. 스케일링된 잠재적 표현 y는 양자화 임계값(예를 들어, 0.5)에 따라 양자화 반올림 포인트들(702a-n) 중 하나로 양자화되거나 반올림될 수 있다. 도 7a에 도시된 바와 같이, 스케일링된 잠재적 표현 y는 양자화 확률(이는 엔트로피 모델(예를 들 어, 도 6a의 610)에 대한 사전 확률에 대응) 내에 속하고, 양자화 반올림 포인트 [y]로 반올림될 수 있다. 도 7b는 잠재적 스케일링 파라미터(s=2)가 적용된 후의 벨 곡선을 도시한다. 도 7b에 도시된 바와 같이, 잠재적 스케일링 파라미터(s=2)를 적용한 후, 양자화 빈(bin) 폭들은 더 커진다. 즉, 양자화 반올림 포 인트들(752a-n) 사이의 분리는 양자화 반올림 포인트(702a-n)(도 7a에 도시) 사이의 분리보다 크다. 추가로, 잠재적 스케일링 파라미터(s=2)를 적용함으로써, 양자화 확률은 양자화 확률(도 7a)보다 더 큰 영역 을 갖는다. 이와 같이, 입력을 정확하게 전달하는 가능성은 도 7a의 시나리오에 비해 증가될 수 있다. 따라서, 도 7b의 시나리오에 대해, 입력을 인코딩하는데 더 적은 비트 레이트가 사용될 수 있다. 따라서, 표현 된 잠재적 공간 y의 더 많은 채널들이 드롭핑될 수 있다. 도 8은 본 개시내용의 양상에 따른 손실 등화의 일 예를 예시하는 그래프이다. 도 8을 참조하면, 상이한 트레이드오프 파라미터 값들 β에 대해 예시적인 비트 레이트-왜곡 곡선들이 도시되어 있다. 훈련 동안, 낮은 비트 레이트 포인트들의 손실 값이 높은 비트 레이트 포인트들의 손실 값들보다 클 수 있다. 일부 경우들에 있어서, 트레이드오프 파라미터 β가 클 때의 손실이 트레이드오프 파라미터 β가 작을 때의 손실보다 훨씬 크다. 이것은 최적화를 어렵게 만들 수 있다. 도 8에 도시된 바와 같이, 이러한 어려움을 극복하고 훈련 을 용이하게 하기 위해 손실 등화 기법들이 적용될 수 있다. 이 예에서, 탄젠트(tangent) 등화(예를 들어, 802a, 802b)가 성능을 개선하기 위해 적용된다(예를 들어, 레이트-왜곡 평면 상의 등화). 상이한 트레이드오프 파라미터들로 생성된 레이트-왜곡 곡선들을 밸런싱하기 위해 스케일링 팩터가 적용될 수 있다. 가변 비트 레이 트 모델을 훈련하는 데 사용되는 손실은 β 값들의 고정된 세트에 대한 레이트-왜곡의 집합일 수 있다. 손실 등화는 이러한 레이트-왜곡 손실들(즉, 예를 들어, Di + βiRi,i = 1,..., N)(여기서 N)을 얼마나 수집할 수 있 는지를 의미한다. 도 8에서, 해당 손실들을 결합하는 세 가지 유형의 계수들이 도시되어 있다. 예시를 쉽게 하기 위해, 여기에서 N = 2이며, 탄젠트 등화는 사례 3(밸런싱됨)이다. 처음 두 경우는 더 낮은 비트 레이트 또는 더 높은 비트 레이트를 선호한다. 즉, 사례 1은 통상적으로 dl > ds인 경우 dl + ds의 합을 효과적으로 최소화하므로 낮은-레이트를 선호한다. 일부 양상들에서, 플레인(plain) 등화가 적용될 수 있다. 일 예에서, 훈련 전 손실은 L = l1 + l2 + ...+ I8로 주어질 수 있다. 플레인 등화는 각각의 훈련 반복의 손실들 균등화될 수 있도록 상이한 상수가 각각 의 손실 항들에 연결될 수 있도록 훈련 중에 적용될 수 있다: L = l1*c1 + l2*c2 + ...+ l8*c8, 여기서 ci는 임의 의 i 및 j에 대해 lj*cj = li*ci인 상수이다. 따라서, 훈련 후에, 동작 포인트들의 각각(예를 들어, li에 대응) 에서의 손실을 등화된다. 도 9는 본 개시내용의 양상들에 따라 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법을 예 시하는 흐름도이다. 도 9에 도시된 바와 같이, 블록 902에서, 입력이 ANN에 의해 수신된다. 도 5를 참조하여 설명된 바와 같이, 입력은 인코더에 의해 수신될 수 있다. 입력은 예를 들어, 비디오 또는 이미지와 같은 시각적 입력일 수 있다. 블록 904에서, 입력의 잠재적 표현이 ANN을 통해 생성된다. 도 5를 참조하여 설명된 바와 같이, 인코더 는 이미지를 프로세싱하고 입력의 잠재적 표현 y를 생성하기 위해 CNN의 계층들을 통해 파라미터화된 비선형 변환을 수행할 수 있다. 블록 906에서, 잠재적 표현은 학습된 잠재적 스케일링 파라미터에 기초한 비트 레이트에 따라 전달된다. 도 6a를 참조하여 설명된 바와 같이, 아키텍처는 잠재적 스케일링을 통해 가변 비트 레이트를 제공하도록 구성된다. 그렇게 함으로써, 아키텍처는 잠재적 용량 또는 레이트를 지속적으로 제어하기 위한 방법을 제 공한다. 아키텍처는 인코더 및 디코더를 포함한다. 인코더는 입력을 수신하고 이미지와 같은 입력을 잠재적 표현 y로 변환한다. 잠재적 표현 y는 학습된 잠재적 스케일링 파라미터 s에 기초하여 스케 일링 블록 606을 통해 스케일링된다. 스케일링된 잠재적 y/s는 양자화 블록에 공급될 수 있다. 양자화 블록은 예를 들어, 양자화 출력 [y/s]를 생성하기 위해 반올림과 같은 양자화 함수를 사용하여 스케일링된 잠재적 y/s를 양자화할 수 있다. 양자화된 출력 [y/s]는 그 후 산술 인코딩을 위해 엔트로피 모델에 공급되며, 이는 그 후 비트 스 트림을 통해 전달된다. 일부 양상들에서, 스케일링 파라미터는 트레이드오프 파라미터 값 β에 기초하여 학습될 수 있으며, 여 기서 β는 왜곡과 비트 레이트(D + β*R)를 밸런싱한다. 따라서, 학습된 잠재적 스케일링 파라미터 s, 채널 인 덱스 및 트레이드오프 파라미터 값 β는 큰 β(예를 들어, 더 작은 비트 레이트 모델을 달성하기 위해 레이트에 더 많은 페널티)가 큰 드롭아웃 레이트(예를 들어, 더 많은 채널을 드롭핑)에 대응할 수 있도록 관련될 수 있으 며, 이는 큰 잠재적 스케일링 파라미터 s에 대응한다. 한편, 큰 채널 인덱스 c는 큰 잠재적 스케일링 파라미터 s에 대응할 수 있다. 도 10은 본 개시내용의 양상들에 따라 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법을 예시하는 흐름도이다. 도 10에 도시된 바와 같이, 블록 1002에서, 입력 비트 스트림이 ANN에 의해 수신된다. 도 5를 참조하여 설명된 바와 같이, 디코더는 비트 스트림을 수신한다. 블록 1004에서, 학습된 잠재적 스케일링 파라미터는 입력의 잠재적 표현을 형성하기 위해 입력 비트 스 트림에 적용된다. 도 6a를 참조하여 설명된 바와 같이, 디코더 측(예를 들어, 674)에서, 양자화된 출력 [y/s] 를 복구하기 위해 비트 스트림의 수신된 비트에 대해 산술 디코딩이 수행된다. 스케일링 파라미터 s를 사용하 는 리스케일링은 리스케일링 블록을 통해 수신된 잠재적 표현을 복구하기 위해 s[y/s](본질적으로 s를 곱 함)로서 양자화된 출력에 로 적용된다. 블록 1006에서, 잠재적 표현은 입력의 재구성을 생성하기 위해 ANN을 통해 디코딩된다. 도 6a를 참조하 여 설명된 바와 같이, 디코더는 입력(이미지)을 재구성하기 위해 복구된 잠재적 표현을 프로세싱할 수 있 다. 따라서, 입력(예를 들어, 이미지)은 채널 조건들에 기초하여 그리고 왜곡과 비트 레이트를 밸런싱하는 방 식으로 전달될 수 있다. 스케일링 파라미터 s가 β의 함수로 파라미터화되는 경우, β 파라미터는 잠재적 표현 의 비트들 전에 전송기에서 수신기로 전달되어 디코더가 각각의 잠재적 표현에 대한 확률 질량 함수를 정 확하게 계산하여 엔트로피 디코딩을 수행할 수 있다. 구현 예들은 이하의 번호의 항들에 설명되어 있다. 1. 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법으로서, ANN에 의해 입력을 수신하는 단계; ANN을 통해 입력의 잠재적 표현을 생성하는 단계; 및 학습된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따라 잠재적 표현을 전달하는 단계를 포함하는, 인 공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 2. 제1 항의 컴퓨터-구현 방법에 있어서, 잠재적 스케일링 파라미터는 채널 인덱스 및 트레이드오프 파라미터에 기초하여 학습되는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 3. 제1 항 또는 제2 항의 컴퓨터-구현 방법에 있어서, 잠재적 스케일링 파라미터는 잠재적 스케일링 파라미터가 채널의 잠재적 표현들의 값에 비해 사전 정의된 임계값 초과인 것에 응답하여 채널을 드롭핑하도록 구성되는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법.4. 제1 항 내지 제3 항 중 어느 하나의 컴퓨터-구현 방법에 있어서, 트레이드오프 파라미터는 비트 레이트와 왜 곡을 밸런싱하는 값에 대응하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 5. 제1 항 내지 제4 항 중 어느 하나의 컴퓨터-구현 방법에 있어서, 트레이드오프 파라미터는 ANN의 훈련 동안 함께 훈련된 상이한 트레이드오프 파라미터들의 어레이를 포함하고, 상이한 트레이드오프 파라미터들 각각에 대 응하는 손실이 등화되는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 6. 제1 항 내지 제5 항 중 어느 하나의 컴퓨터-구현 방법에 있어서, 낮은 비트 레이트 포인트들의 제1 손실 값 들과 높은 비트 레이트 포인트들의 제2 손실 값들이 등화되도록 등화를 적용하는 단계를 더 포함하는, 인공 신 경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 7. 제1 항 내지 제6 항 중 어느 하나의 컴퓨터-구현 방법에 있어서, 등화는 플레인 등화를 포함하는, 인공 신경 망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 8. 제1 항 내지 제6 항 중 어느 하나의 컴퓨터-구현 방법에 있어서, 등화는 탄젠트 등화를 포함하는, 인공 신경 망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 9. 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법으로서, ANN에 의해 입력 비트 스트림을 수신하는 단계; 입력의 잠재적 표현을 복구하기 위해 학습된 잠재적 스케일링 파라미터를 입력 비트 스트림에 적용하는 단계; 및 입력의 재구성을 생성하기 위해 ANN을 통해 잠재적 표현을 디코딩하는 단계를 포함하는, 인공 신경망(ANN)을 동 작시키기 위한 컴퓨터-구현 방법. 10. 제9 항의 컴퓨터-구현 방법에 있어서, 잠재적 스케일링 파라미터는 채널 인덱스 및 트레이드오프 파라미터 에 기초하여 학습되는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 11. 제9 항 또는 제10 항의 컴퓨터-구현 방법에 있어서, 트레이드오프 파라미터는 비트 레이트와 왜곡을 밸런싱 하는 값에 대응하는, 인공 신경망(ANN)을 동작시키기 위한 컴퓨터-구현 방법. 12. 인공 신경망(ANN)을 동작시키기 위한 장치로서, 메모리; 및 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는, ANN에 의해 입력을 수신하고; ANN을 통해 입력의 잠재적 표현을 생성하고; 그리고 학습된 잠재적 스케일링 파라미터에 기초하여 비트 레이트에 따라 잠재적 표현을 전달하도록 구성되는, 인공 신 경망(ANN)을 동작시키기 위한 장치. 13. 제12 항의 장치에 있어서, 적어도 하나의 프로세서는 채널 인덱스 및 트레이드오프 파라미터에 기초하여 잠 재적 스케일링 파라미터를 학습하도록 추가로 구성되는, 인공 신경망(ANN)을 동작시키기 위한 장치. 14. 제12 항 또는 제13 항의 장치에 있어서, 잠재적 스케일링 파라미터는 잠재적 스케일링 파라미터가 채널의 잠재적 표현들의 값에 비해 사전 정의된 임계값 초과인 것에 응답하여 채널을 드롭핑하도록 구성되는, 인공 신 경망(ANN)을 동작시키기 위한 장치. 15. 제12 항 내지 제14 항 중 어느 하나의 장치에 있어서, 트레이드오프 파라미터는 비트 레이트와 왜곡을 밸런 싱하는 값에 대응하는 인공 신경망(ANN)을 동작시키기 위한 장치. 16. 제12 항 내지 제15 항 중 어느 하나의 장치에 있어서, 트레이드오프 파라미터는 ANN의 훈련 동안 함께 훈련 된 상이한 트레이드오프 파라미터들의 어레이를 포함하고, 상이한 트레이드오프 파라미터들 각각에 대응하는 손 실이 등화되는, 인공 신경망(ANN)을 동작시키기 위한 장치. 17. 제12 항 내지 제16 항 중 어느 하나의 장치에 있어서, 적어도 하나의 프로세서는 낮은 비트 레이트 포인트 들의 제1 손실 값들과 높은 비트 레이트 포인트들의 제2 손실 값들이 등화되도록 등화를 적용하도록 추가로 구 성되는, 인공 신경망(ANN)을 동작시키기 위한 장치.18. 제12 항 내지 제17 항 중 어느 하나의 장치에 있어서, 등화는 플레인 등화를 포함한다. 19. 제12 항 내지 제17 항 중 어느 하나의 장치에 있어서, 등화는 탄젠트 등화를 포함하는, 인공 신경망(ANN)을 동작시키기 위한 장치. 20. 인공 신경망(ANN)을 동작시키기 위한 장치로서, 메모리; 및 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는, ANN에 의해 입력 비트 스트림을 수신하고; 입력의 잠재적 표현을 복구하기 위해 학습된 잠재적 스케일링 파라미터를 입력 비트 스트림에 적용하고; 그리고 입력의 재구성을 생성하기 위해 ANN을 통해 잠재적 표현을 디코딩하도록 구성되는, 인공 신경망(ANN)을 동작시 키기 위한 장치. 21. 제20 항의 장치에 있어서, 적어도 하나의 프로세서는 채널 인덱스 및 트레이드오프 파라미터 값에 기초하여 잠재적 스케일링 파라미터를 학습하도록 추가로 구성되는, 인공 신경망(ANN)을 동작시키기 위한 장치. 22. 제20 항 또는 제21 항의 장치에 있어서, 트레이드오프 파라미터 값은 비트 레이트와 왜곡을 밸런싱하는 값 에 대응하는, 인공 신경망(ANN)을 동작시키기 위한 장치. 일 양상에서, 수신 수단, 디코딩 수단, 생성 수단, 학습 수단, 통신 수단, 동작 수단 및/또는 적용 수단 은 CPU, CPU와 연관된 프로그램 메모리, 전용 메모리 블록, 완전히 연결된 계층들, NPU 및/또는 인용된 기능들을 수행하도록 구성된 라우팅 연결 프로세싱 유닛일 수 있다. 다른 구성 에서, 위에 언급된 수단은 위에 언급된 수단에 의해 인용된 기능들을 수행하도록 구성된 임의의 모듈 또는 임의 의 장치일 수 있다. 상술한 방법들의 다양한 동작들은 대응하는 기능들을 수행할 수 있는 임의의 적절한 수단에 의해 수행될 수 있다. 해당 수단은 회로, 주문형 집적 회로(ASIC: application specific integrated circuit) 또는 프로세 서를 포함하지만 이에 제한되지 않는 다양한 하드웨어 및/또는 소프트웨어 구성 요소(들) 및/또는 모듈(들)을 포함할 수 있다. 일반적으로, 도면들에 예시된 동작들이 있는 경우, 해당 동작들은 유사한 넘버링을 갖는 대응 하는 카운터파트(counterpart) 수단-플러스-기능(means-plus-function) 구성 요소들을 가질 수 있다. 본원에서 사용되는 바와 같이, \"결정하는\"이라는 용어는 광범위하게 다양한 작용들을 포함한다. 예를 들어, \"결정하는\"은 계산, 컴퓨팅, 프로세싱, 도출, 조사, 조회(예를 들어, 테이블, 데이터베이스 또는 다른 데 이터 구조에서 조회), 확인 등을 포함할 수 있다. 또한 \"결정하는\"은 수신(예를 들어, 정보 수신), 액세스(예 를 들어, 메모리의 데이터에 액세스) 등을 포함할 수 있다. 추가로, \"결정하는\"은 해결, 선택, 고르기, 확립 등을 포함할 수 있다. 본원에서 사용되는 바와 같이, 항목들의 목록의 \"적어도 하나\"를 지칭하는 문구는 단일 멤버들을 포함하 여 이러한 항목들의 임의의 조합을 지칭한다. 예를 들어, \"a, b 또는 c 중 적어도 하나\"는 a, b, c, a-b, a-c, b-c 및 a-b-c를 포함하도록 의도된다. 본 개시내용과 관련하여 설명된 다양한 예시적인 논리 블록들, 모듈들 및 회로들은 범용 프로세서, 디지 털 신호 프로세서(DSP: digital signal processor), 주문형 집적 회로(ASIC), 필드 프로그램 가능 게이트 어레 이 신호(FPGA: field programmable gate array) 또는 다른 프로그램 가능 로직 디바이스(PLD: programmable logic device), 이산 게이트 또는 트랜지스터 로직, 이산 하드웨어 구성 요소들, 또는 설명된 기능들을 수행하 도록 설계된 이들의 임의의 조합으로 구현되거나 수행될 수 있다. 범용 프로세서는 마이크로프로세서일 수 있 지만, 대안으로, 프로세서는 임의의 상업적으로 이용 가능한 프로세서, 제어기, 마이크로컨트롤러 또는 상태 기 계일 수 있다. 프로세서는 또한 컴퓨팅 디바이스들의 조합, 예를 들어, DSP와 마이크로프로세서, 복수의 마이 크로프로세서들, DSP 코어와 결부된 하나 이상의 마이크로프로세서들, 또는 임의의 다른 이러한 구성의 조합으 로 구현될 수 있다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[00100] 본 개시내용과 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접, 프로세서에 의해 실 행되는 소프트웨어 모듈로, 또는 둘의 조합으로 구현될 수 있다. 소프트웨어 모듈은 본 기술 분야에 알려진 임 의의 형태의 저장 매체에 상주할 수 있다. 사용될 수 있는 저장 매체의 일부 예들은 랜덤 액세스 메모리(RAM:random access memory), 판독 전용 메모리(ROM: read only memory), 플래시 메모리, 소거 가능 프로그램 가능 판독-전용 메모리(EPROM: erasable programmable read-only memory), 전기적 소거 가능 프로그램 가능 판독-전 용 메모리(EEPROM: electrically erasable programmable read-only memory), 레지스터들, 하드 디스크, 제거 가능 디스크, CD-ROM 등을 포함한다. 소프트웨어 모듈은 단일 명령 또는 많은 명령들을 포함할 수 있으며, 몇 몇 상이한 코드 세그먼트들에 걸쳐, 상이한 프로그램들 중에서, 그리고 복수의 저장 매체에 걸쳐 분산될 수 있 다. 저장 매체는 프로세서가 저장 매체로부터 정보를 판독하고 저장 매체에 정보를 기입할 수 있도록 프로세서 에 커플링될 수 있다. 대안으로, 저장 매체는 프로세서에 통합될 수 있다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[00101] 본원에 개시된 방법들은 설명된 방법을 달성하기 위한 하나 이상의 단계들 또는 작용들을 포함한다. 방법 단계들 및/또는 작용들은 청구항들의 범위를 벗어나지 않고 서로 교환될 수 있다. 즉, 단계들 또는 작용 들의 특정 순서가 지정되지 않는 한, 특정 단계들 및/또는 작용들의 순서 및/또는 사용은 청구항들의 범위를 벗 어나지 않고 수정될 수 있다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[00102] 설명된 기능들은 하드웨어, 소프트웨어, 펌웨어 또는 이들의 임의의 조합으로 구현될 수 있다. 하드웨 어로 구현되는 경우, 예시적인 하드웨어 구성은 디바이스의 프로세싱 시스템을 포함할 수 있다. 프로세싱 시스 템은 버스 아키텍처로 구현될 수 있다. 버스는 프로세싱 시스템의 특정 애플리케이션 및 전체 설계 제약들에 따라 임의의 개수의 상호 연결 버스들 및 브릿지들을 포함할 수 있다. 버스는 프로세서, 기계-판독 가능 매체 및 버스 인터페이스를 포함하는 다양한 회로들을 함께 연결할 수 있다. 버스 인터페이스는 특히 버스를 통해 프로세싱 시스템에 네트워크 어댑터를 연결하는 데 사용될 수 있다. 네트워크 어댑터는 신호 프로세싱 기능들 을 구현하는 데 사용될 수 있다. 특정 양상들에 있어서, 사용자 인터페이스(예를 들어, 키패드, 디스플레이, 마우스, 조이스틱 등)도 버스에 연결될 수 있다. 버스는 또한 타이밍 소스들, 주변 장치들, 전압 레귤레이터들, 전원 관리 회로들 등과 같은 다양한 다른 회로들을 연결할 수 있으며, 이는 본 기술 분야에 공지 되어 있으므로, 더 이상 설명하지 않을 것이다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[00103] 프로세서는 기계-판독 가능 매체 상에 저장된 소프트웨어의 실행을 포함하여 일반 프로세싱 및 버스 관 리를 담당할 수 있다. 프로세서는 하나 이상의 범용 및/또는 특수-목적 프로세서들로 구현될 수 있다. 예들은 마이크로프로세서들, 마이크로컨트롤러들, DSP 프로세서들 및 소프트웨어를 실행할 수 있는 다른 회로를 포함한 다. 소프트웨어는 소프트웨어, 펌웨어, 미들웨어, 마이크로코드, 하드웨어 설명 언어 등으로 지칭되든지 상관 없이 명령들, 데이터 또는 이들의 임의의 조합을 의미하는 것으로 광범위하게 해석되어야 한다. 기계-판독 가 능 매체는 예를 들어, 랜덤 액세스 메모리(RAM), 플래시 메모리, 판독 전용 메모리(ROM), 프로그램 가능 판독- 전용 메모리(PROM: Programmable Read-Only Memory), 소거 가능 프로그램 가능 판독-전용 메모리(EPROM), 전기 적 소거 가능 프로그램 가능 판독-전용 메모리(EEPROM), 레지스터들, 자기 디스크들, 광학 디스크들, 하드 드라 이브들 또는 임의의 다른 적절한 저장 매체 또는 이들의 임의의 조합을 포함할 수 있다. 기계-판독 가능 매체 는 컴퓨터-프로그램 제품으로 구현될 수 있다. 컴퓨터-프로그램 제품은 패키징 재료들을 포함할 수 있다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[00104] 하드웨어 구현에서, 기계-판독 가능 매체는 프로세서와 별개인 프로세싱 시스템의 일부일 수 있다. 그 러나, 본 기술 분야의 통상의 기술자가 쉽게 이해할 수 있는 바와 같이, 기계-판독 가능 매체 또는 그 임의의 일부는 프로세싱 시스템 외부에 있을 수 있다. 예를 들어, 기계-판독 가능 매체는 전송 라인, 데이터에 의해 변조된 반송파, 및/또는 디바이스와 별개인 컴퓨터 제품을 포함할 수 있으며, 이들 모두는 버스 인터페이스를 통해 프로세서에 의해 액세스될 수 있다. 대안적으로 또는 추가로, 기계-판독 가능 매체 또는 임의의 그 일부 는 캐시 및/또는 일반 레지스터 파일들이 있는 경우와 같이 프로세서에 통합될 수 있다. 논의된 다양한 구성 요소들이 로컬 구성 요소와 같이 특정 위치를 갖는 것으로 설명될 수 있지만, 분산 컴퓨팅 시스템의 일부로 구 성되는 특정 구성 요소들과 같이 다양한 방식으로 구성될 수도 있다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "[00105] 프로세싱 시스템은 모두 외부 버스 아키텍처를 통해 다른 지원 회로와 함께 연결되는, 프로세서 기능을 제공하는 하나 이상의 마이크로프로세서들 및 기계-판독 가능 매체의 적어도 일부를 제공하는 외부 메모리를 갖 는 범용 처리 시스템으로 구성될 수 있다. 대안적으로, 프로세싱 시스템은 설명된 뉴런 모델들 및 신경 시스템 들의 모델들을 구현하기 위한 하나 이상의 뉴로모픽(neuromorphic) 프로세서들을 포함할 수 있다. 다른 대안으 로서, 프로세싱 시스템은 프로세서, 버스 인터페이스, 사용자 인터페이스, 지원 회로, 및 단일 칩으로 통합된 기계-판독 가능 매체의 적어도 일부를 갖는 주문형 집적 회로(ASIC), 또는 하나 이상의 필드 프로그램 가능 게 이트 어레이(FPGA)들, 프로그램 가능 로직 디바이스(PLD)들, 제어기들, 상태 기계들, 게이팅된 로직, 이산 하드 웨어 구성 요소들 또는 임의의 다른 적절한 회로, 또는 본 개시내용의 전반에 걸쳐 설명된 다양한 기능을 수행 할 수 있는 회로들의 임의의 조합으로 구현될 수 있다. 본 기술 분야의 통상의 기술자는 특정 애플리케이션 및 전체 시스템에 부과된 전체 설계 제약들에 따라 프로세싱 시스템에 대해 설명된 기능을 가장 잘 구현하는 방법을 인식할 것이다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "[00106] 기계-판독 가능 매체는 다수의 소프트웨어 모듈들을 포함할 수 있다. 소프트웨어 모듈들은 프로세서에 의해 실행될 때 프로세싱 시스템으로 하여금 다양한 기능들을 수행하게 하는 명령들을 포함한다. 소프트웨어 모듈들은 전송 모듈과 수신 모듈을 포함할 수 있다. 각각의 소프트웨어 모듈은 단일 저장 디바이스에 상주하거 나 복수의 저장 디바이스들에 걸쳐 분산될 수 있다. 예를 들어, 트리거링 이벤트가 발생할 때 소프트웨어 모듈 은 하드 드라이브로부터 RAM으로 로딩될 수 있다. 소프트웨어 모듈을 실행하는 동안, 프로세서는 액세스 속도 를 높이기 위해 명령들의 일부를 캐시에 로딩할 수 있다. 그 후, 프로세서에 의한 실행을 위해 하나 이상의 캐 시 라인들이 일반 레지스터 파일로 로딩될 수 있다. 아래에서 소프트웨어 모듈의 기능을 참조할 때, 이러한 기 능은 해당 소프트웨어 모듈로부터 명령들을 실행할 때 프로세서에 의해 구현된다는 것을 이해할 것이다. 추가 로, 본 개시내용의 양상들은 프로세서, 컴퓨터, 기계, 또는 이러한 양상들을 구현하는 다른 시스템의 기능에 대 한 개선을 가져온다는 것을 이해해야 한다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "[00107] 소프트웨어로 구현되는 경우, 기능들은 컴퓨터-판독 가능 매체 상에 하나 이상의 명령들 또는 코드로 저장되거나 전송될 수 있다. 컴퓨터-판독 가능 매체는 컴퓨터 저장 매체와 한 장소에서 다른 장소로의 컴퓨터 프로그램의 전달을 용이하게 하는 임의의 매체를 포함하는 통신 매체 모두를 포함한다. 저장 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체일 수 있다. 제한이 아니라 예를 들어, 이러한 컴퓨터-판독 가 능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 광 디스크 저장, 자기 디스크 저장 또는 다른 자기 저장 디바이 스, 또는 명령들 또는 데이터 구조들의 형태로 원하는 프로그램 코드를 전달하거나 저장하는 데 사용될 수 있고 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 또한, 임의의 연결들이 컴퓨터-판독 가 능 매체로 적절히 칭해질 수 있다. 예를 들어, 소프트웨어가 웹사이트, 서버 또는 다른 원격 소스로부터 동축 케이블, 광섬유 케이블, 트위스티드 페어(twisted pair), 디지털 가입자 회선(DSL: digital subscriber line), 또는 적외선(IR), 라디오 및 마이크로파와 같은 무선 기술들을 사용하여 전송되는 경우, 동축 케이블, 광섬유 케이블, 트위스티드 페어, DSL 또는 적외선, 라디오 및 마이크로파와 같은 무선 기술들이 매체의 정의에 포함된 다. 본원에서 사용되는 디스크(disk) 및 디스크(disc)는 컴팩트 디스크(CD: compact disc), 레이저 디스크, 광 디스크, 디지털 버서타일 디스크(DVD: digital versatile disc), 플로피 디스크 및 Blu-ray® 디스크를 포함하 며, 여기서 디스크(disk)들은 일반적으로 데이터를 자기적으로 재생하는 반면, 디스크(disc)들은 데이터를 레이 저들로 광학적으로 재생한다. 따라서, 일부 양상들에서 컴퓨터-판독 가능 매체는 비일시적 컴퓨터-판독 가능 매체(예를 들어, 유형의 매체)를 포함할 수 있다. 또한, 다른 양상들에 있어서 컴퓨터-판독 가능 매체는 일시 적인 컴퓨터-판독 가능 매체(예를 들어, 신호)를 포함할 수 있다. 위의 조합들도 컴퓨터-판독 가능 매체의 범 위 내에 포함되어야 한다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "[00108] 따라서, 특정 양상들은 본원에 제시된 동작들을 수행하기 위한 컴퓨터 프로그램 제품을 포함할 수 있다. 예를 들어, 이러한 컴퓨터 프로그램 제품은 명령어들이 저장(및/또는 인코딩)된 컴퓨터-판독 가능 매체 를 포함할 수 있으며, 명령들은 설명된 동작들을 수행하기 위해 하나 이상의 프로세서들에 의해 실행 가능하다. 특정 양상들에 있어서, 컴퓨터 프로그램 제품은 패키징 재료를 포함할 수 있다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "[00109] 추가로, 설명된 방법들 및 기법들을 수행하기 위한 모듈들 및/또는 다른 적절한 수단이 적용 가능한 경 우 사용자 단말 및/또는 기지국에 의해 다운로드 및/또는 다르게 획득될 수 있음을 이해해야 한다. 예를 들어, 이러한 디바이스는 설명된 방법들을 수행하기 위한 수단의 전달을 용이하게 하기 위해 서버에 커플링될 수 있다. 대안적으로, 설명된 다양한 방법들은 사용자 단말 및/또는 기지국이 디바이스에 저장 수단을 커플링하거 나 제공할 때 다양한 방법들을 획득할 수 있도록 저장 수단(예를 들어, RAM, ROM, 컴팩트 디스크(CD) 또는 플로 피 디스크와 같은 물리적 저장 매체 등)을 통해 제공될 수 있다. 또한, 설명된 방법들 및 기법들을 디바이스에 제공하기 위한 임의의 다른 적절한 기법이 이용될 수 있다."}
{"patent_id": "10-2023-7022464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "[00110] 청구항들은 위에 예시된 정확한 구성 및 구성 요소들로 제한되지 않음을 이해해야 한다. 청구항들의 범위를 벗어나지 않고 설명된 방법들 및 장치의 배열, 동작 및 상세 사항들에 다양한 수정들, 변경들 및 변형들 이 이루어질 수 있다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면3 도면4 도면5 도면6a 도면6b 도면6c 도면6d 도면7a 도면7b 도면8 도면9 도면10"}
{"patent_id": "10-2023-7022464", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시내용의 특징들, 특성 및 이점들은 동일한 참조 문자들이 전체에 걸쳐 대응적으로 식별하는 도면 들과 함께 고려될 때 아래에 제시되는 상세한 설명으로부터 더욱 명백해질 것이다. 도 1은 본 개시내용의 특정 양상들에 따라 범용 프로세서를 포함하는 시스템-온-어-칩(SOC: system-on- a-chip)을 사용하는 신경망의 예시적인 구현을 예시한다. 도 2a, 도 2b 및 도 2c는 본 개시내용의 양상들에 따른 신경망을 예시하는 도면들이다. 도 2d는 본 개시내용의 양상들에 따른 예시적인 심층 컨벌루션 네트워크(DCN: deep convolutional network)를 예시하는 도면이다. 도 3은 본 개시내용의 양상에 따른 예시적인 심층 컨벌루션 네트워크(DCN)를 예시하는 블록도이다. 도 4는 본 개시내용의 양상들에 따라 인공 지능(AI: artificial intelligence) 기능들을 모듈화할 수 있는 예시적인 소프트웨어 아키텍처를 예시하는 블록도이다. 도 5는 본 개시내용의 양상들에 따른 가변 비트 레이트 모델의 예시적인 아키텍처를 예시하는 블록도이 다. 도 6a는 본 개시내용의 양상들에 따른 가변 비트 레이트 모델에 대한 예시적인 아키텍처를 예시하는 블 록도이다. 도 6b는 본 개시내용의 양상들에 따라 입력을 나타내기 위한 잠재적 공간의 채널들을 예시하는 도면이다. 도 6c는 본 개시내용의 양상들에 따른 예시적인 잠재적 공간을 예시하는 블록도이다. 도 6d는 본 개시내용의 양상들에 따른 가변 비트 레이트에 대한 아키텍처를 예시하는 블록도이다. 도 7a 및 도 7b는 본 개시내용의 양상들에 따라 양자화 비트 폭을 스케일링하기 위한 예시적인 벨(bell) 곡선들을 예시하는 도면들이다. 도 8은 본 개시내용의 양상들에 따른 손실 등화(equalization)의 예를 예시하는 그래프이다. 도 9 및 도 10은 본 개시내용의 양상들에 따라 인공 신경망을 동작시키기 위한 컴퓨터-구현 방법들을 예시하는 흐름도들이다."}
