{"patent_id": "10-2020-0030331", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0111106", "출원번호": "10-2020-0030331", "발명의 명칭": "합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템 및 그것의 동작 방법", "출원인": "한국전자통신연구원", "발명자": "홍승태"}}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "경량 지능형 소프트웨어 프레임워크(Lightweight Intelligent Software Framework; LISF)로 프로그래밍된 가속처리 기능(accelerated processing function)을 수행하는 임베디드 시스템의 동작 방법에 있어서,병렬 관리 기능 엔터티(Parallelization Managing Function Entity)에서 병렬로 수학적 연산들을 구동하는 리소스들의 내부에 존재하는 엔터티들을 초기화 및 구성시키는 단계; 및 가속 관리 기능 엔터티(Acceleration Managing Function Entity)에서 상기 구성된 엔터티들을 이용하여 상기수학적 연산들을 병렬 처리하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 엔터티들은 플랫폼, 장치, 콘텍스트, 커맨드 큐, 및 커널을 포함하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 플랫폼은 적어도 하나의 CPU(Central Processing Unit) 및 GPU(Graphic Processing Unit) 에 의해 구성된이종의 플랫폼인 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 장치는 상기 수학적 연산들을 수행하는 실제의 프로세서들을 포함하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 콘텍스트는 장치 세트에서 상기 리소스들을 관리하는 엔터티를 포함하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 2 항에 있어서,상기 커맨드 큐는 커널을 실행하고 메모리 맵핑/언맵핑 및 동기화를 수행하는 엔터티를 포함하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2 항에 있어서,상기 커널은 상기 장치에서 구동하는 코드를 포함하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 수학적 연산들은 합성곱 계층의 연산들인 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 병렬 관리 기능 엔터티는 장치 메모리를 할당하고, 호스트로부터 장치로 데이터를 복사하고, 커널을 설정공개특허 10-2020-0111106-3-하고, 연산 결과들을 다시 복사하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 커널의 인스턴스들은 상기 인스턴스들 각각이 단일 작업 항목(single work item)을 처리하는 동안, 병렬로실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9 항에 있어서,상기 커널의 인스턴스들은 작업 그룹의 일부로써 멀티플 작업 항목들(multiple work items)로 함께 실행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 작업 그룹에서 각 커널의 인스턴스는 다른 인스턴스와 통신하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9 항에 있어서,상기 병렬 관리 기능 엔터티는 상기 임베디드 시스템의 장치의 개수에 따라 병렬 처리를 수행하기 위한 병렬 처리 큐를 관리하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서,상기 병렬 관리 기능 엔터티는 다중 장치 환경에서 병렬성을 극대화하기 위해, 장치의 병렬 처리 성능을 고려하여 가중치 및 편향 값을 갖는 행렬을 각 장치에 분할하되,상기 병렬 처리 성능은 각 장치에서 한번에 수행 가능한 커널 인스턴스의 수에 의해 결정되고,상기 커널 인스턴스의 수는 각 연산 장치의 최대 작업 그룹의 크기 또는 최대 작업 항목의 크기에 의하여 결정되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1 항에 있어서,상기 가속 관리 기능 엔터티는 상기 분할된 행렬에 따라 대응하는 장치에서 상기 분할될 행렬과 입력 데이터에대하여 행렬 곱셈(General Matrix Multiply; GEMM) 연산을 수행하도록 상기 리소스들을 제어하는 것을 특징으로하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 GEMM 연산은 C = αAB + βC 의 수학식으로 표현되고,여기서 A, B, C는 행렬이고, α, β는 스칼라이고,행렬 A, B, C 각각의 크기는 M, N, K로 구성되고,행렬 A의 크기는 M * K의 크기이고,행렬 B의 크기는 K * N의 크기이고행렬 C의 크기는 M * N의 크기인 것을 특징으로 하는 방법.공개특허 10-2020-0111106-4-청구항 17 제 16 항에 있어서,상기 병렬 관리 기능 엔터티는 행렬 A의 행을 상기 OpenCL 장치의 개수만큼 분할하고, 상기 분할된 행렬의 크기는 대응하는 OpenCL 장치의 개수와 사용 가능한 OpenCL 장치의 개수에 따라 결정되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 16 항에 있어서,상기 가속 관리 기능 엔터티는 행렬 곱셈(General Matrix Multiply; GEMM) 연산 수행 비용을 최소화하기 위해호스트와 장치간에 메모리를 공유하며, 각 장치는 메모리 주소를 통해 호스트의 벡터 및 행렬에 접근하여 호스트와 장치간 데이터 복사 없이 수학 루틴들(mathematical routines)을 수행하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 16 항에 있어서,상기 가속 관리 기능 엔터티는 각 OpenCL 장치의 커널별 작업량을 극대화하기 위하여 행렬 B를 벡터로 그룹화하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 가속 관리 기능 엔터티는 OpenCL 장치에서 병렬 처리를 수행하기 위해 로컬 워크 그룹(local work group)의 크기와 글로벌 워크 그룹(global work group)의 크기를 결정하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "임베디드 시스템의 합성곱 계층 가속 장치에 있어서,적어도 하나의 프로세서 및 상기 적어도 하나의 프로세서에 실행되는 적어도 하나의 인스트럭션을 저장하는 메모리를 포함하고,상기 적어도 하나의 인스트럭션은,합성곱 계층 응용부에서 합성곱 신경망의 합성곱 계층 정보를 수신하고;합성곱 계층 분석부에서 상기 합성곱 계층 정보를 분석하고, OpenCL 장치 정보와 대응하는 합성곱 계층의 독립성 여부를 근거로 하여 계층 병렬 처리 수행 여부를 결정하고;합성곱 계층 병렬 처리부에서 상기 합성곱 계층이 독립적일 경우 각 OpenCL 장치의 성능을 고려하여 합성곱 계층에 대응하는 행렬을 분할하고, 상기 분할될 행렬을 이용하여 상기 합성곱 계층에 대응하는 연산들을 병렬 처리하고;상기 합성곱 계층 병렬 처리부에서 상기 합성곱 계층이 독립적이지 않을 경우, 단일 OpenCL 장치를 통해 커널을근거로 하여 상기 대응하는 연산들을 병렬 처리하도록 상기 적어도 하나의 프로세서를 실행시키는 것을 특징으로 하는 합성곱 계층 가속 장치."}
{"patent_id": "10-2020-0030331", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "리소스들; 및합성곱 계층 가속 장치를 포함하고,상기 합성곱 계층 가속 장치는,병렬 관리 기능 엔터티에서 병렬로 수학적 연산들을 구동하는 상기 리소스들의 내부에 존재하는 엔터티들을 초기화 및 구성시키고; 및 가속 관리 기능 엔터티에서 상기 구성된 엔터티들을 이용하여 상기 수학적 연산들을 병렬 처리하는 것을 특징으공개특허 10-2020-0111106-5-로 하는 임베디드 시스템."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 경량 지능형 소프트웨어 프레임워크(Lightweight Intelligent Software Framework; LISF)로 프 로그래밍된 가속 처리 기능(accelerated processing function)을 수행하는 임베디드 시스템의 동작 방법은, 병 렬 관리 기능 엔터티에서 병렬로 수학적 연산들을 구동하는 리소스들의 내부에 존재하는 엔터티들을 초기화 및 구성시키는 단계, 및 가속 관리 기능 엔터티에서 상기 구성된 엔터티들을 이용하여 상기 수학적 연산들을 병렬 처리하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템 및 그것의 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 합성곱 신경망(CNN: Convolutional Neural Network)은 심층 신경망(DNN: Deep Neural Network)의 한 종류로써, 영상 내 객체 분류 등 다양한 시각적 이미지 분석 분야에서 이용되고 있다. 합성곱 신경망은 일반 적으로 하나의 입력 계층과 출력 계층, 및 다수의 은닉 계층으로 구성된다. 은닉 계층은 주로 합성곱 계층 (convolutional layer)과 통합 계층(pooling layer), 및 완전 연결 계층(fully connected layer)들로 구성된다. 입력 계층은 이미지(image) 혹은 데이터셋(dataset)으로부터 데이터를 입력 받으며, 주로 배열 형태 의 부동소수점 자료형이 사용된다. 합성곱 계층은 입력 데이터에서 특징들(features)을 추출하기 위해 사용되며, 입력 데이터에 대한 가중치(weight)와 편향(bias)을 가진다. 통합 계층은 이전 계층에서 입력된 값들 에서 정해진 크기의 영역 내 최대값 혹은 평균값을 추출하여 다음 계층으로 전달한다. 완전 연결 계층은 연산 결과를 분류(classification)하기 위해 사용되며, 합성곱 계층과 동일하게 가중치와 편향을 가진다. 출력 계층 은 주로 완전 연결 계층 뒤에 구성되며, 입력 데이터에 대한 추론(inference) 확률을 값으로 가진다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허: 10-1847874, 등록일: 2018년 4월 25일, 제목: 합성곱 신경망을 이용한 이미지 인식 방법 및 그 기록매체. (특허문헌 0002) 일본공개특허: JP 2018-67154, 공개일: 2018년 4월 26일, 제목: 연산 처리 회로 및 인식 시스 템. (특허문헌 0003) 중국공개특허: CN 109086867, 공개일: 2018년 12월 5일, 제목: A kind of convolutional neural networks acceleration system based on FPGA."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 임베디드 시스템에서 합성곱 계층의 특징을 자동으로 분석하고, 분석된 합성곱 계층 정보를 기반으로 다중 OpenCL 장치를 이용해 다수 합성곱 계층에 대한 계층 병렬 처리를 제공함으로써, 임베디드 시스 템과 OpenCL에 대한 전문적인 지식이 없더라도 합성곱 신경망의 순전파에서 대부분의 연산 시간을 차지하는 합 성곱 계층에 대한 가속 장치를 이용하는 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템, 및 그것의 동작 방법을 제공하는데 있다."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 경량 지능형 소프트웨어 프레임워크(Lightweight Intelligent Software Framework; LISF)로 프로그래밍된 가속 처리 기능(accelerated processing function)을 수행하는 임베디드 시스템의 동작 방법은, 병렬 관리 기능 엔터티(Parallelization Managing Function Entity)에서 병렬로 수학적 연산들을 구동 하는 리소스들의 내부에 존재하는 엔터티들을 초기화 및 구성시키는 단계; 및 가속 관리 기능 엔터티에서 상기 구성된 엔터티들을 이용하여 상기 수학적 연산들을 병렬 처리하는 단계를 포함할 수 있다. 실시 예에 있어서, 상기 엔터티들은 플랫폼, 장치, 콘텍스트, 커맨드 큐, 및 커널을 포함할 수 있다. 실시 예에 있어서, 상기 플랫폼은 적어도 하나의 CPU(Central Processing Unit), 적어도 하나의 GPU(Graphic Processing Unit), 적어도 하나의 프로세서, 혹은 적어도 하나의 하드웨어 가속기에 의해 구성된 이종의 플랫폼인 것을 특징으로 한다. 실시 예에 있어서, 상기 장치는 상기 수학적 연산들을 수행하는 실제의 프로세서들을 포함할 수 있다. 실시 예에 있어서, 상기 콘텍스트는 장치 세트에서 상기 리소스들을 관리하는 엔터티를 포함할 수 있다. 실시 예에 있어서, 상기 커맨드 큐는 커널을 실행하고 메모리 맵핑/언맵핑 및 동기화를 수행하는 엔터티를 포함 할 수 있다. 실시 예에 있어서, 상기 커널은 상기 장치에서 구동하는 코드를 포함할 수 있다. 실시 예에 있어서, 상기 수학적 연산들은 합성곱 계층에서의 연산들일 수 있다. 실시 예에 있어서, 상기 병렬 관리 기능 엔터티는 장치 메모리를 할당하고, 호스트에서 장치로 데이터를 복사하 고, 커널을 설정하고, 연산 결과를 다시 복사하는 것을 특징으로 한다. 실시 예에 있어서, 상기 커널의 인스턴스들은 각각 단일 작업 항목(single work item)을 처리하면서 병렬로 구 동하는 것을 특징으로 한다. 실시 예에 있어서, 상기 커널의 인스턴스들은 작업 그룹의 일부로써 멀티플 작업 항목들(multiple work items) 로 함께 실행되는 것을 특징으로 한다. 실시 예에 있어서, 상기 작업 그룹에서 각 커널의 인스턴스는 다른 인스턴스(additional instance)와 통신하는 것을 특징으로 한다. 실시 예에 있어서, 상기 병렬 관리 기능 엔터티는 상기 임베디드 시스템의 OpenCL 장치의 개수에 따라 병렬 처 리를 수행하기 위한 병렬 처리 큐를 관리하는 것을 특징으로 한다. 실시 예에 있어서, 상기 병렬 관리 기능 엔터티는 다중 장치 환경에서 병렬성을 극대화하기 위해, 장치의 병렬 처리 성능을 고려하여 가중치 및 편향 값을 갖는 행렬을 각 장치에 분할하되, 상기 병렬 처리 성능은 각 장치에 서 한번에 수행 가능한 커널 인스턴스의 수에 의해 결정되고, 상기 커널 인스턴스의 수는 각 연산 장치의 최대 작업 그룹의 크기 또는 최대 작업 항목의 크기에 의하여 결정될 수 있다. 이 때, 상기 가속 관리 기능 엔터티는 상기 분할된 행렬에 따라 대응하는 OpenCL 장치에서 상기 분할될 행렬과 입력 데이터에 대하여 행렬 곱셈(General Matrix Multiply; GEMM) 연산을 수행하도록 상기 리소스들을 제어할 수 있다. 실시 예에 있어서, 상기 GEMM 연산은 C = αAB + βC 의 수학식으로 표현되고, 여기서 A, B, C는 행렬이고, α, β는 스칼라이고, 행렬 A, B, C 각각의 크기는 M, N, K로 구성되고, 행렬 A의 크기는 M * K의 크기이고, 행렬 B 의 크기는 K * N의 크기이고, 및 행렬 C의 크기는 M * N의 크기인 것을 특징으로 한다. 실시 예에 있어서, 상기 병렬 관리 기능 엔터티는 행렬 A의 행을 상기 OpenCL 장치의 개수만큼 분할하고, 상기 분할된 행렬의 크기는 대응하는 OpenCL 치의 연산 장치의 개수와 사용 가능한 OpenCL 장치의 개수에 따라 결정 되는 것을 특징으로 한다. 실시 예에 있어서, 상기 가속 관리 기능 엔터티는 각 OpenCL 장치의 커널별 작업량을 극대화하기 위하여 행렬 B 를 벡터로 그룹화하는 것을 특징으로 한다. 실시 예에 있어서, 상기 가속 관리 기능 엔터티는 OpenCL 장치에서 병렬 처리를 수행하기 위해 로컬 워크 그룹 (local work group)의 크기와 글로벌 워크 그룹(global work group)의 크기를 결정하는 것을 특징으로 한다. 본 발명의 실시 예에 따른 임베디드 시스템의 합성곱 계층 가속 장치는, 적어도 하나의 프로세서 및 상기 적어 도 하나의 프로세서에 실행되는 적어도 하나의 인스트럭션을 저장하는 메모리를 포함하고, 상기 적어도 하나의 인스트럭션은, 합성곱 계층 응용부에서 합성곱 신경망의 합성곱 계층 정보를 수신하고; 합성곱 계층 분석부에서 상기 합성곱 계층 정보를 분석하고, OpenCL 장치 정보와 대응하는 합성곱 계층의 독립성 여부를 근거로 하여 계 층 병렬 처리 수행 여부를 결정하고; 합성곱 계층 병렬 처리부에서 상기 합성곱 계층이 독립적일 경우 각 OpenCL 장치의 성능을 고려하여 합성곱 계층에 대응하는 행렬을 분할하고, 상기 분할될 행렬을 이용하여 상기 합성곱 계층에 대응하는 연산들을 병렬 처리하고; 상기 합성곱 계층 병렬 처리부에서 상기 합성곱 계층이 독립 적이지 않을 경우, 단일 OpenCL 장치를 통해 커널을 근거로 하여 상기 대응하는 연산들을 병렬 처리하도록 상기 적어도 하나의 프로세서를 실행시키는 것을 특징으로 한다.본 발명의 실시 예에 따른 임베디드 시스템은, 리소스들; 및 합성곱 계층 가속 장치를 포함하고, 상기 합성곱 계층 가속 장치는, 병렬 관리 기능 엔터티에서 병렬로 수학적 연산들을 구동하는 상기 리소스들의 내부에 존재 하는 엔터티들을 초기화 및 구성시키고; 및 가속 관리 기능 엔터티에서 상기 구성된 엔터티들을 이용하여 상기 수학적 연산들을 병렬 처리하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따른 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템, 및 그것의 동작 방법은, 다중 OpenCL 장치를 가진 임베디드 시스템에서 합성곱 신경망의 순전파 수행 시 합성곱 신경망의 합성곱 계층 정보를 자동으로 분석하고, 이를 통해 OpenCL이나 임베디드 시스템에 대한 전문적인 지식이 없더라도 다수 OpenCL 장치를 기반으로 합성곱 계층의 순전파에 대한 가속 기능을 이용할 수 있다."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 도면들을 이용하여 본 발명의 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있을 정"}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "도로 본 발명의 내용을 명확하고 상세하게 기재할 것이다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 형 태를 가질 수 있는바, 특정 실시 예들을 도면에 예시하고 본문에 상세하게 설명하고자 한다. 그러나 이는 본 발 명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하 는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로 사용될 수 있다. 예를 들어, 본 발명 의 권리 범위로부터 이탈되지 않은 채 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요 소도 제 1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다 고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 혹은 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이 해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 혹은 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 혹은 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 혹은 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구 성요소, 부분품 혹은 이들을 조합한 것들의 존재 혹은 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한 다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미이다. 일반적으 로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미인 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석 되지 않는다. 일반적으로 합성곱 신경망(Convolutional Neural Network)은 입력 계층에서 출력 계층 방향으로 연산을 수행하 면서 입력 데이터에 대한 추론을 수행하는 순전파(forward propagation)와 출력 계층에서 입력 계층 방향으로 연산을 수행하면서 학습을 수행하는 역전파(propagation)를 포함한다. 추론 시에는 순전파만 수행되며, 학습 시 에는 순전파에서 획득한 추론 결과와 실제 값과의 오차를 통해 경사도(gradient)를 계산한다. 계산된 경사도는 실제 값과의 오차가 최소가 되도록 은닉 계층의 값을 보정하는데 사용된다. 일반적으로 학습은 메모리와 같은 시스템 자원이 많이 요구되기 때문에 서버급의 고사양 시스템 환경에서 수행되며, 제한적인 시스템 자원을 가진 임베디드 시스템에서는 단일 이미지 혹은 소수 이미지에 대해 추론을 수행하기 위한 순전파가 주로 이용된다. 한편, 이미지로부터 추출된 특징들을 다수의 은닉 계층을 통해 추론 확률을 계산하는 합성곱 신경망 순전파의 특징으로 인하여, 합성곱 계층은 합성곱 신경망의 순전파에서 대부분의 연산을 차지한다. 본 발명의 실시 예에 따른 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템, 및 그것의 동작 방법은, 합성곱 신경망의 순전파를 가속화하기 위해 합성곱 신경망에서 가장 높은 연산 복잡도를 가진 합성곱 계층에 대 한 병렬 처리를 수행할 수 있다. 또한, 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템, 및 그것의 동작 방법은 합성곱 신경망에서 독립적으로 구성되어 있는 다수 합성곱 계층에 대한 계층 병렬 처리를 제공할 수 있다. 또한, 임베디드 시스템은 다양한 종류의 하드웨어 플랫폼으로 구성되기 때문에 다양한 이기종 하드웨어 환경에 서 병렬 처리를 수행할 수 있는 병렬 컴퓨팅 프레임워크가 필수적이다. 본 발명의 실시 예에 따른 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템, 및 그것의 동작 방법은, 복수의 OpenCL(Open Computing Language) 장치들(devices)를 이용하여 병렬 처리를 수행할 수 있다. 여기서 OpenCL은 개방형 범용 컴퓨팅 프레 임워크(framework)로써, CPU(Central Processing Unit)와 GPU(Graphic Processing Unit) 뿐만 아니라 기타 프 로세서들의 조합으로 구성된 이기종 플랫폼에 대한 병렬 컴퓨팅을 제공할 수 있다. 한편, 본 발명은 OpenCL에 제한되지 않는다고 이해되어야 할 것이다. 본 발명은 커널을 위한 프레임워크(framework for kernel)에 적용 가 능하다. 본 발명의 실시 예에 따른 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템, 및 그것의 동작 방법은, OpenCL의 특징을 이용하여 각 OpenCL 장치의 성능을 기반으로 각 합성곱 계층을 분할하고, 분할된 합성곱 계층 을 다수의 OpenCL 장치를 통해 병렬 처리할 수 있다. 본 발명의 실시 예에 따른 합성곱 계층 가속 장치, 그것을 포함하는 임베디드 시스템, 및 그것의 동작 방법은, 임베디드 시스템에서 합성곱 계층의 특징을 자동으로 분석 하고, 분석된 합성곱 계층 정보를 기반으로 다중 OpenCL 장치를 이용해 다수 합성곱 계층에 대한 계층 병렬 처 리를 제공함으로써, 임베디드 시스템과 OpenCL에 대한 전문적인 지식이 없더라도 합성곱 신경망의 순전파에서 대부분의 연산 시간을 차지하는 합성곱 계층에 대한 가속 장치를 이용할 수 있다. 실시 예에 있어서, 다수 합성곱 계층에 대한 계층 병렬 처리는 대응하는 합성곱 신경망이 다른 합성곱 신경망에 영향을 주지 않는 독립된 계층일 경우, 대응하는 합성곱 계층들을 다중 OpenCL 장치를 이용하여 병렬 처리할 수 있다. 또한, 본 발명의 실시 예에 따른 임베디드 시스템은, 통합 메모리 구조(unified memory architecture)를 제공하 고 다수의 OpenCL 장치를 가지는 하나의 OpenCL 플랫폼(platform) 환경에서 단일 혹은 소수 이미지를 추론하는 합성곱 신경망의 순전파에 대한 병렬 처리를 제공할 수 있다. 도 1은 본 발명의 실시 예에 따른 합성곱 계층 가속 장치를 예시적으로 보여주는 도면이다. 도 1을 참조하 면, 합성곱 계층 가속 장치는 합성곱 계층 응용부, 합성곱 계층 분석부, 및 합성곱 계층 병렬 처리부를 포함할 수 있다. 합성곱 계층 응용부는 합성곱 신경망에서 합성곱 계층 가속 장치를 사용하기 위한 사용자 인터페 이스를 제공하고, 합성곱 계층 분석부에 합성곱 계층 정보를 전달할 수 있다. 또한, 합성곱 계층 응용부는 합성곱 계층 가속 장치의 기능을 사용하기 위한 사용자 인터페이스를 제 공할 수 있다. 이때 각 합성곱 계층에 대한 메모리 공간은 합성곱 계층 응용부의 사용자 인터페이스 호출 전 모 두 할당된 것으로 가정하겠다.실시 예에 있어서, 합성곱 계층 응용부의 사용자 인터페이스에서 입력 받는 정보는 특징 추출을 위한 필터 (filter)의 수, 필터의 크기, 필터 패딩(padding) 크기, 필터 스트라이드(stride) 크기, 편향 사용 여부, 입력 데이터의 메모리 주소, 출력 데이터의 메모리 주소를 포함할 수 있다. 여기서 필터는 가로와 세로의 크기가 동 일한 형태를 가정하며, 패딩 및 스트라이드의 크기는 필터에서 가로와 세로에 각각 동일하게 적용될 수 있다. 실시 예에 있어서, 합성곱 계층 응용부의 사용자 인터페이스를 통해 입력된 합성곱 계층의 정보는 합성곱 계층 분석부로 전달될 수 있다. 합성곱 계층 분석부는 합성곱 계층 응용부를 통해 전달된 합성곱 계층 정보를 분석하고, 각 합성곱 계층의 독립성 여부를 검사할 수 있다. 또한, 합성곱 계층 분석부는 합성곱 계층 응용부를 통해 전달된 정보와 OpenCL 장치 정보를 기반으로 각 합성곱 계층에 대한 독립성 여부를 검사함으로써 계층 병렬 처리 수행 여부를 결정할 수 있다. 실시 예에 있어서, 합성곱 계층 분석부는 병렬 처리를 수행하기 위한 계층 병렬 처리 큐(queue)를 관리할 수 있다. 여기서 큐의 최대 크기는 한번에 최대 병렬 처리 가능한 합성곱 계층의 수를 의미한다. 예를 들어, 큐 의 최대 크기는 임베디드 시스템에서 제공하는 OpenCL 장치의 수로 결정될 수 있다. 만일 임베디드 시스템 에서 사용 가능한 OpenCL 장치의 수가 1이라면, 계층 병렬 처리 큐는 생성되지 않는다. 실시 예에 있어서, 합성곱 계층 분석부는 입력 데이터 혹은 출력 데이터의 메모리 주소가 다른 합성곱 계 층에 존재하지 않는 경우(혹은 다른 합성곱 계층에 영향을 주지 않는 경우), 및 입력 데이터 주소가 가리키는 메모리 공간에 값이 비어있지 않은(not NULL) 경우, 대응하는 합성곱 계층들을 계층 병렬 처리 큐에 삽입할 수 있다. 실시 예에 있어서, 합성곱 계층 분석부는 계층 병렬 처리 큐에 저장된 합성곱 계층을 합성곱 계층 병렬 처 리부에 전달하고, 전달된 합성곱 계층들이 합성곱 계층 병렬 처리부를 통해 수행 완료된 경우 계층 병렬 처리 큐에서 삭제할 수 있다. 실시 예에 있어서, 합성곱 계층 분석부는 독립적이지 않은 합성곱 계층을 합성곱 계층 병렬 처리부를 통해 단일 OpenCL 장치 기반의 병렬 처리를 수행할 수 있다. 실시 예에 있어서, 합성곱 계층 분석부는 합성곱 계층들이 모두 수행되기까지 상술된 과정을 반복하여 수 행할 수 있다. 합성곱 계층 병렬 처리부는 다중 OpenCL 장치(21, .. 2n, n은 2 이상의 정수)를 이용하여 병렬 처리를 수 행하고, 수행 결과를 합성곱 계층 응용부를 통해 사용자에게 전달할 수 있다. 본 발명의 실시 예에 따른 합성곱 계층 가속 장치는, 다중 OpenCL 장치를 가진 임베디드 시스템에서 합성곱 신경망의 순전파 수행 시 합성곱 신경망의 합성곱 계층 정보를 자동으로 분석하고, 이를 통해 OpenCL이나 임베디드 시스템에 대한 전문적인 지식이 없더라도 다수 OpenCL 장치를 기반으로 합성곱 계층의 순전파에 대한 가속 기능을 이용할 수 있다. 도 2는 본 발명의 실시 예에 따른 합성곱 계층 분석부의 동작 방법을 예시적으로 보여주는 흐름도이다. 도 1 및 도 2를 참조하면, 합성곱 계층 분석부의 동작은 다음과 같이 진행될 수 있다. 합성곱 계층 분석부는 합성곱 계층 정보 및 OpenCL 장치 정보를 근거로 하여 합성곱에 대한 병렬 처리를 수행하기 위한 커맨드 큐(command queue)를 생성할 수 있다(S110). 합성곱 계층 분석부는 다른 합성곱 계 층에 영향을 주지 않으면서 입력 데이터가 NULL 데이터가 아닌 합성곱 계층들을 병렬 처리를 위해 생성된 커맨 드 큐에 삽입할 수 있다(S120). 합성곱 계층 분석부는 합성곱 계층 병렬 처리부에서 수행 완료된 합 성곱 계층을 병렬 처리를 위해 생성된 커맨드 큐에서 삭제할 수 있다(S130). 실시 예에 있어서, 합성곱 계층 분 석부는 모든 합성곱 계층들이 수행될 때까지 S120 및 S130을 반복할 수 있다. 도 3은 본 발명의 실시 예에 따른 합성곱 계층 병렬 처리부의 동작 방법을 예시적으로 보여주는 흐름도이 다. 도 1 내지 도 3을 참조하면, 합성곱 계층 병렬 처리부의 동작은 다음과 같이 진행될 수 있다. 합성곱 계층 병렬 처리부는 Open CL 장치 정보를 근거로 하여 행렬을 분할 수 있다. 예를 들어, 합성곱 계 층 병렬 처리부는 각 OpenCL 장치의 성능을 고려하여 가중치 및 편향 값을 가지는 행렬을 분할할 수 있다 (S210). 실시 예에 있어서, 행렬 분할 이후에 추가적으로 분할된 행렬 내에서 별도의 그룹핑을 수행할 수 있다.이후에, 각 OpenCL 장치에서 분할된 행렬과 입력 데이터에 대해 행렬 곱셈(GEMM: General Matrix Multiply, 이 하 GEMM) 연산을 수행함으로써 각 합성곱 계층에 대한 계층 병렬 처리를 수행할 수 있다(S220). 합성곱 계층 병렬 처리부는 병렬 처리 큐를 통해 전달된 각 합성곱 계층에 대해 계층 병렬 처리를 수행할 수 있다. 한편, 합성곱 계층의 GEMM 연산은 C = αAB + βC (A, B, C는 행렬, α, β는 스칼라)와 같은 연산을 포함할 수 있다. 여기서, 행렬 A, B, C의 크기는 M, N, K로 구성되고, 행렬 A는 M * K의 크기, 행렬 B는 K * N의 크기, 행렬 C는 M * N의 크기일 수 있다. 이때 합성곱 계층의 가중치 혹은 편향은 행렬 A(혹은 제 1 행렬)에 대응하고, 입력 데이터는 행렬 B(혹은 제 2 행렬)에 대응하고, 출력 데이터는 행렬 C(혹은 제 3 행렬)에 대응할 수 있다. 실시 예에 있어서, 합성곱 계층 병렬 처리부는 행렬 A 의 행을 다중 OpenCL 장치의 수만큼 분할할 수 있다. 실시 예에 있어서, 분할되는 행렬의 행 크기는 수학식 1과 수학식 2를 통해 결정될 수 있다. 수학식 1은 행렬 분할 기본 단위 결정식을 나타내고 있다. 수학식 1"}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2는 분할되는 행렬의 행 크기 결정식을 나타내고 있다. 수학식 2"}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "아래에서는 설명의 편의를 위하여 수학식 1과 수학식 2는 사용 가능한 최대 OpenCL 장치의 수가 2 이상인 경우 를 가정하겠다. 수학식 1과 수학식 2에서 n은 행렬 분할 기준이 적용될 OpenCL 장치의 번호를 의미한다. D는 사용 가능한 최대 OpenCL 장치의 수를 의미한다. OpenCL 장치의 번호는 OpenCL 장치 정보 중 CL_DEVICE_MAX_COMPUTE_UNITS의 값 을 기준으로 값이 큰 OpenCL 장치부터 순서대로 부여될 수 있다. 또한, 수학식 1에서 CU는 대응하는 OpenCL 장 치의 연산 장치(compute unit)수를 의미한다. CU는 OpenCL 장치 정보 중 CL_DEVICE_MAX_COMPUTE_UNITS의 값으 로 결정될 수 있다. 또한, 수학식 1에서 M은 행렬 A의 행 크기를 의미한다. floor은 계산된 값보다 작거나 가장 큰 정수를 반환하는 함수를 의미한다. 수학식 2에서 SubMn은 n번째 OpenCL 장치의 분할되는 행렬의 행 크기를 의미한다. 수학식 2에서 WS는 대응하는 OpenCL 장치에서 한번의 명령어로 병렬 처리 가능한 데이터의 수를 고려하여 결정될 수 있다. 실시 예에 있어서, OpenCL 장치 정보 중 CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLE의 값 혹은 16의 배수로 결정될 수 있다. 수학식 2에서 MinSubM은 분할되는 행렬의 행 크기의 최소값을 의미한다. MinSubM은 대응하는 OpenCL 장치의 CL_DEVICE_MAX_WORK_GROUP_SIZE의 값 혹은 CL_DEVICE_MAX_WORK_ITEM_SIZES의 값과 A 행렬의 행 크기(M) 등을 고려하여 결정될 수 있다. 행렬 A는 첫 번째 OpenCL 장치에서부터 수학식 2의 SubMn(n은 대응하는 OpenCL 장치의 번호)의 크기만큼 행 단 위로 분할될 수 있다. 분할되는 각 행렬 An의 크기는 (SubMn * K)와 같을 수 있다. 본 발명의 실시 예에 따른 합성곱 계층 병렬 처리부는 행렬 분할 및 GEMM 결과 결합 시의 오버헤드를 최소 화하기 위하여 OpenCL의 보조 버퍼 기능을 이용하여 분할되는 행렬에 대한 메모리 객체(memory object)를 생성 할 수 있다. 즉, 합성곱 계층 병렬 처리부는 OpenCL의 메모리 객체 생성 API(Application Programming Interface)인 clCreateBuffer를 이용하여 행렬 A에 대한 메모리 객체를 생성한 후, 행렬 A에 대한 메모리 객체 를 기반으로 보조 버퍼 생성 API인 clCreateSubBuffer를 이용하여 각 OpenCL 장치에 분할되는 행렬 An의 메모리 객체를 생성할 수 있다. 실시 예에 있어서, 행렬 B는 각 OpenCL 장치에서 GEMM 연산 수행 시 공통적으로 사용될 수 있다. 각 OpenCL 장 치는 행렬 B에 대한 하나의 메모리 객체를 공유하여 사용할 수 있다. 실시 예에 있어서, 행렬 C는 각 OpenCL 장치에서 GEMM 연산 결과를 저장하고 있는 행렬 Cn(n은 대응하는 OpenCL 장치의 번호)을 결합하여 생성될 수 있다. 여기서 행렬 Cn의 크기는 (SubMn * N)과 같다. 또한, 합성곱 계층 병렬 처리부는 병렬 처리 시 데이터 복사 비용을 최소화하기 위해 OpenCL의 메모리 메 모리 객체 매핑(mapping) API인 clEnqueueMapBuffer와 매핑 해제 API인 clEnqueueUnmapMemObject를 사용하여 행렬 데이터를 각 OpenCL 장치가 데이터 복사 없이 공유 가능하다. 또한, 합성곱 계층 병렬 처리부는 각 OpenCL 장치의 커널별 작업량을 극대화하기 위하여 행렬 B를 벡터로 그룹화하고, 각 OpenCL 장치에 할당된 An의 각 원소와 GEMM 연산을 수행할 수 있다. 실시 예에 있어서, 벡터 그 룹화 수는 OpenCL 장치 정보 중 CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLE을 고려하여 결정될 수 있다. 예를 들어, CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLE는 일반적으로 4의 배수의 값을 가질 수 있다. 아래 에서는 설명의 편의를 위하여 벡터 그룹화 수를 4로 설정하겠다. 실시 예에 있어서, 합성곱 계층 병렬 처리부는 각 OpenCL 장치에서 병렬 처리를 수행하기 위해 로컬 작업 그룹(local work group)의 크기와 글로벌 작업 그룹(global work group)의 크기를 결정할 수 있다. 본 발명의 실시 예에 따른 합성곱 계층 병렬 처리부는 2차원 공간 인덱스를 구성하여 커널(kernel)을 병렬 처리 수행할 수 있다. 이에 따라 로컬 작업 그룹과 글로벌 작업 그룹은 2차원 공간의 행과 열을 가질 수 있다. 합성곱 계층 병렬 처리부는 행렬 B의 4개 원소를 벡터로 그룹화하여 수행하기 때문에, 로컬 작업 그룹의 크기는 (4, 4)로 설정될 수 있다. 글로벌 작업 그룹의 크기는 수학식 3을 통해 결정될 수 있다. 수학식 3은 계 층 병렬 처리 시 글로벌 작업 그룹의 크기 결정을 나타내고 있다. 수학식 3"}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3에서 i, j는 2차원 공간의 행과 열을 의미하며, GZn은 n번째 OpenCL 장치의 글로벌 작업 그룹의 크기, RoundUP(A, B)는 A를 B로 나눌 때 나머지가 0이 아닌 경우 나머지가 0이 되도록 올림하는 함수를 의미한다. 또한, 합성곱 계층 병렬 처리부는 병렬 처리 큐를 통해 전달되지 않는 비독립적 합성곱 계층에 대해 단일 OpenCL 장치 기반 병렬 처리를 수행할 수 있다. 합성곱 계층 병렬 처리부는 단일 OpenCL 장치 기반 병렬 처리 수행 시, 계층 병렬 처리 수행 시와 동일하게 행렬 B를 그룹화하여 행렬 A의 각 원소와 GEMM 연산을 수행 할 수 있다. 단일 OpenCL 장치 기반 병렬 처리 수행 시, 벡터 그룹화 수와 로컬 작업 그룹의 크기는 계층 병렬 처리 수행 시와 동일하다. 단일 OpenCL 장치 기반 병렬 처리 수행 시의 글로벌 작업 그룹의 크기는 수학식 4와 같다. 수학식 4는 단일 OpenCL 장치 기반 병렬 처리 시 글로벌 작업 그룹의 크기 결정을 나타내고 있다.수학식 4"}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 6, "content": "도 4는 본 발명의 실시 예에 따른 합성곱 계층 가속 장치의 동작 방법을 예시적으로 보여주는 흐름도이다. 도 1 내지 도 4를 참조하면, 합성곱 계층 가속 장치는 다음과 같이 동작할 수 있다. 아래에서는 설명의 편 의를 위하여, 합성곱 계층 가속 장치에서 사용 가능한 OpenCL 장치의 수는 2 이상이라고 가정하겠다. 합성곱 계층 응용부를 통해 사용자로부터 합성곱 신경망의 합성곱 계층 정보가 입력될 수 있다(S310). 합성곱 계층 분석부는 합성곱 계층 응용부에서 전달된 합성곱 계층의 정보를 분석할 수 있다(S320). 합성곱 계층 분석부는 OpenCL 장치 정보와 대응하는 합성곱 계층의 독립성 여부를 기반으로 계층 병렬 처 리 수행 여부를 결정할 수 있다(S330). 만일 대응하는 합성곱 계층이 독립적일 경우, 합성곱 계층 병렬 처리부는 대응하는 합성곱 계층을 각 OpenCL 장치의 성능을 고려하여 분할하고, 각 OpenCL 장치에서 계층 병렬 처리를 수행할 수 있다(S340). 반면에 대응하는 합성곱 계층이 독립적이지 아닌 경우, 합성곱 계층 병렬 처리부는 단일 OpenCL 장치에 기 반한 커널을 근거로 하여 병렬 처리를 수행할 수 있다(S350). 모든 합성곱 계층이 수행 완료될 때까지 S320, S330, S340 및 S350 과정을 반복 수행될 수 있다(S360). 본 발명의 실시 예에 따른 합성곱 계층 가속 장치 및 그것의 동작 방법은, 다중 OpenCL 장치를 가진 임베 디드 시스템에서 합성곱 신경망의 순전파 수행 시 합성곱 신경망의 합성곱 계층 정보를 자동으로 분석하고, 이를 통해 OpenCL이나 임베디드 시스템에 대한 전문적인 지식이 없더라도 다수 OpenCL 장치를 기 반으로 합성곱 계층의 순전파에 대한 가속 기능을 이용할 수 있다. 본 발명의 실시예에 따른 합성곱 계층 가속 장치는 실제 서비스를 위해 프레임워크에 적용 가능하다. 도 5는 본 발명의 실시 예에 따른 합성곱 계층 가속 장치의 실제 서비스 적용 예를 나타낸다. 도 5를 참조하면, 합성곱 계층 가속 장치는 IoT(internet of things)을 위한 소프트웨어 프레임워크에 포함하여 운영될 수 있다. 또한, 본 발명의 실시 예에 따른 합성곱 계층 가속 장치는 IoT(internet of things)을 위한 LISF(Lightweight intelligent software framework)에 적용 가능하다. IoT 기술의 발달에 따라, 지능형 기술(intelligent technologies)은 다양한 ICT(Information and Communications Technology) 서비스 도메인에서 빠르게 개발 및 출시(developing and launching)되고 있다. 자원이 제한된 IoT 장치에서 지능적인 기능(intelligent capability)을 지원하기 위해서는 어플리케이션 계층과 하드웨어 자원 계층간의 지능적인 기능을 가능하게 하는 IoT 소프트웨어 프레임워크가 중요한 역할을 한다. 일반적으로, ISF(Intelligent Software Framework)는 주로 자원이 풍부한 서버 측 클라우드 컴퓨팅 및 고성능 컴퓨팅 환경에서 수행된다. 프레임워크는 개념적으로 프리-프로세싱 엔터티, 학습 엔터티 및 정보 처리를 위한 추론 엔터티로 구성된다. 또한, 훈련 데이터와 실제 데이터가 필요하다. ISF는 프리-프로세싱 엔터티를 통해 고품질 학습 데이터를 얻고, 데이터를 통해 학습할 수 있는 학습 엔터티를 사용하여 학습 모델을 생성하고, 모 델 기반 추론 엔터티를 사용하여 새로운 데이터에 대한 다양한 추론을 예측한다. - 프리-프로세싱 엔터티: 데이터 필터링 또는 데이터를 다른 형식으로 변환 - 학습 엔터티: 데이터에서 규칙성 및 패턴 검색 - 추론 엔터티: 새로운 데이터에 대한 분류 및 추정 수행 최근에는 많은 종류의 IoT 장치가 처리 능력이 충분하지 않지만 GPGPU(General-Purpose Computing on Graphics Processing Unit) 및 멀티 코어 CPU(Central Processing Unit)와 임베디드된다(embedded with). 그러나, 이러 한 IoT 장치를 사용하면 거의 실시간 IoT 데이터 처리, 개인 정보(privacy) 처리 및 로우 레이턴시(low- latency)를 제공하기 위해 지능형 IoT 서비스의 새로운 요구 사항이 요구된다. 제한된 시스템 자원을 가진 임베디드 시스템에서 인텔리전스 기능(intelligence capability)을 달성하기 위해 하드웨어 및 소프트웨어 측면에 서 해결해야 할 몇 가지 문제가 있다. - HW: 많은 다른 유형의 프로그램들뿐 아니라 하나의 지정된 작업 또는 일련의 작업들을 지원하기 위한 CPU 및 GPGPU에 대한 높은 클럭 속도/코어 수 및 효율적인 전력 관리 - SW: 지능형 소프트웨어 프레임워크의 최적화를 통한 GPU 및 GPGPU 기반 병렬 처리 및 경량 기술(parallelism and lightweight technology)을 이용한 가속 기술 HW 및 SW에 대한 이러한 문제를 해결 또는 개선하는 것은 매우 중요하다. 그 이유는 일반적으로 임베디드 시스 템은 하나의 특정 작업 또는 일련의 작업들에 전념하기 때문에 지능적인 서비스(이를 CPU 인텐시브 프로그램이 라 한다)와 같은 많은 작업량의 복잡한 프로그램을 작업하기가 쉽지 않기 때문이다. 이러한 프로그램들이 임베 디드 시스템들에서 실행될 때, 다른 유형들의 오버헤드(예를 들어, 높은 CPU/GPGPU 사용량, GPU/GPGPU 열, 메모 리 리크 등)가 발생한다. 이러한 오버헤드로 인해, 이러한 프로그램이 갑자기 종료되거나 전체 시스템이 충돌 할 수 있다. 그러나, 최근 임베디드 시스템들은 지능적인 서비스(예를 들어, 얼굴 인식, 진공 청소기, 자윺ㄹ 주행 자동차/드론 운전)를 제공하기 위해 작업량이 많은 복잡한 프로그램을 실행하는 경향이 있다. 따라서, 자 원-제한된 IoT 장치들에서 인텔리전스를 지원하기 위해서는 LISF(Lightweight Intelligent Software Framework)가 필요하다. 이 LISF를 통해, IoT 장치들은 자원 제한적인 환경에서 지능형 IoT 어플리케이션 처리 를 수행할 수 있고, 표준화된 방식으로 크로스-도메인 IoT 어플리케이션들의 지능형 기능(intelligent capability)에 액세스하도록 지원할 수 있다. LISF가 적용된 IoT 장치는 사용자에게 지능형 서비스를 제공할 수 있다. 임베디드 시스템에서 작업되는 LISF는 IoT 장치와 같은 제한적인 시스템 자원에 대한 일부 제한을 고려할 필요 가 있다. 기계 학습 및 딥 러닝(예를 들어, 학습 및 추론)과 같은 지능적인 작업은 많은 계산을 필요로 한다. 그러나, IoT 장치의 CPU 및 GPGPU 성능이 고성능 컴퓨터(예를 들어, 서버 측 컴퓨터)의 성능보다 훨씬 낮기 때 문에 임베디드 시스템에서 과도한 계산을 지원하는 것은 거의 불가능하다. 따라서, CPU 및 GPGPU 용량을 최대 한 활용할 수 있는 접근 방식을 지원하는 것이 중요하다. 이 접근 방식은 소프트웨어(예를 들어, OpenCL 및 CUDA) 기반의 가속 기술(accelerating technology)이다. 임베디드 시스템에서 작동하는 다양한 지능형 응용 프 로그램 및 서비스는 고성능 컴퓨팅 환경을 필요로 하고, 결국 일반적으로 임베디드 시스템에 적용되기 위해 가 속화 기술이 필요하다. 그러므로, LISF는 임베디드 시스템을 운영하여 가속화 처리 기능(accelerated processing capability)을 수행하는 방법을 제공한다. 이 방법은, 초기화(initializing), 구성(configuring) 및 병렬 처리(processing in parallel)의 셋으로 구성된다. 첫 번째는, 병렬로 존재하는 초기화 및 구성 엔터 티들, 병렬 관리 기능 엔터티(parallel managing function entity)에 의해 병렬적으로 수학적 연산들 (mathematical operations)을 수행하는 것이다. 병럴 관리 기능 엔터티는 장치 메모리를 할당하고, 호스트로부 터 장치로 데이터를 복사(copy)하고, 커널을 설정하고, 연산 결과들을 다시 복사(copy)한다. 상기 커널의 인스 턴스들은 인스턴스들 각각이 단일 작업 항목(single work item)을 처리하는 동안 병렬로 실행되고, 작업 그룹의 일부로 멀티플 작업 아이템들(multiple work items)로서 함께 실행된다. 두 번째는, 병렬 처리, 가속 관리 기 능 엔터티에 의하여 구성된 엔터티들을 이용한 수학적 연산들이다. 이 경우에, 이들 대부분은 정확도(예를 들 어, 객체 인식률)와 실시간성(예를 들어, FPS) 사이의 트레이드 오프(trade-off)를 가진다. 예를 들어, 만약 객체 인식을 위한 정확도(accuracy)가 높다면, 객체를 감지 또는 추론하는 시간은 느려질 수 있다. 임베디드 시스템이 많은 계산으로 인한 오버헤드를 가져서, 어플리케이션들이나 서비스들은 제대로 동작하지 않을 수 있 다. 도 6는 본 발명의 실시 예에 따른 LISF를 개념적으로 보여주는 도면이다. 도 6를 참조하면, LISF은 어플리 케이션 계층과 리소스 계층 사이에 존재할 수 있다. LISF는 온-라인 파셜 러닝(on-line partial learning), 근사 추론(approximate inference), 성능 모니터링(performance monitoring), 및 가속 처리 (acceleration processing)를 수행할 수 있다. 어플리케이션들은 임베디드 시스템에서 실행되는 경량 IoT 어플리케이션들을 포함할 수 있다. 경량 어플리케이 션은 임베디드 시스템에서 짧은 레이턴시 및 효율적인 전력으로 동작할 수 있다. 지능형 IoT는, 머신 러닝 혹은 딥 러닝과 같은 지능형 컴퓨팅을 실시간으로 수행하고, 제한된 자원 환경에서 효율적이고 확장 가능한 지능형 컴퓨팅을 제공하고, 짧은 레이턴시와 가속기를 처리하는 향상된 기능을 제공하고, 리소스 사용 상태(resource usage status)를 모니터링 할 수 있다. LISF는 학습, 추론, 성능 모니터링, 및 가속화 처리와 관련된 기능들을 수행할 수 있다. LISF는 임베디드 시스 템에 최적화된 인공 지능을 제공하고, 실시간 동작에서 저전력 성능을 극대화하는 리소스가 제한된 임베디드 환 경에서 처리할 수 있다. 실시 예에 있어서, 온-라인 파셜 러닝 기능은, 지능형 IoT 어플리케이션들에서 온-라인 부분 학습을 수행할 수 있다. 리소스 제한 환경에서 부분 학습 처리의 메커니즘이 수행되어야 한다. 온-디바이스 환경(on-device environment)을 위한 경량 학습 모델이 제공될 수 있다. 빠른 학습을 위하여 고밀도 압축 모델(high-density compression model) 및 처리 성능이 제공될 수 있다. 머신 러닝의 매트릭스 연산을 가속하기 위하여 병렬 컴퓨 팅 처리 프레임워크(parallel computing handling framework)가 사용되어야 한다. 실시 예에 있어서, 근사 추론 기능은, 지능형 IoT 어플리케이션들에 대한 실시간 추론을 수행할 수 있다. 추론 (inference)을 위한 실시간 처리가 제공될 수 있다. 온-라인 파셜 러닝을 위하여 최적화된 네트워크 플로우가 제공될 수 있다. 인공 지능 어플리케이션을 위하여 네트워크 연결 없는 연산(operation without network connection)과 간단한 구성(simple configuration)이 제공될 수 있다. 실시 예에 있어서, 성능 모니터링 기능은, 리소스 사용에 대한 모니터링을 수행할 수 있다. 프로파일링 기능 (profiling function)과 데이터 파싱 분석(data parsing analysis)을 위한 성능이 모니터링 되어야 한다. GPGPU 가속 성능 데이터 수집을 위한 정보가 제공될 수 있다. 리소스 실행을 위한 상태 정보가 제공될 수 있다. 실시 예에 있어서, 가속 처리 기능은, 지능형 IoT 어플리케이션을 위한 가속화 기술을 제공할 수 있다. 머신 러 닝을 가속화하기 위하여, 예를 들어, 기본 선형 대수(basic linear algebra)와 같은 GPU-기반의 적응형 가속 연 산들이 제공될 수 있다. 최적의 성능 파라미터들을 설정하고 바이너리 포맷으로 커널을 생성하기 위하여 병렬 처리 연산 가속 장치(parallel processing operation acceleration unit)가 제공될 수 있다. 임베디드 시스템 에서 가속-기반 연산 및 커널 연산을 위한 버퍼에서 병렬 처리 가능한 실행 유닛(parallel processing enabled execution unit)이 제공될 수 있다. 머신 러닝 알고리즘에 가속-기반 연산의 결과를 반환(return)하기 위하여 가속기 어플리케이션(accelerator application)이 제공될 수 있다. 병렬 컴퓨팅 관련 장치 정보를 생성하기 위 하여 가속기 분석 장치(accelerator analysis unit)가 제공될 수 있다. 리소스는, 예를 들어, CPU/GPU, 메모리, 네트워크 등을 포함할 수 있다. 지능형 IoT 어플리케이션의 실시간 처 리를 위하여 하드웨어 리소스가 제공될 수 있다. 임베디드 시스템들의 LISF는 성능, 전력 및 메모리 측면에서 실행될 수 있다. LISF 기반 인공지능 서비스들(예 를 들어, 드론 임대 서비스)은 서비스의 실시간(real-time) 및 심리스(seamless) 실행을 지원해야 할 수 있다. 그러나, 실행을 제공하기 위해 다음 세 가지 상황을 피해야 할 수 있다. - 서비스 응답 시간이 느려짐 - 실행 중에 갑자기 정지하거나, - 비정상적인 실행으로 인한 서비스 종료 이 세 가지 상황은 임베디드 시스템들의 자원 부족으로 인해 야기된다. 따라서, LISF 기반 서비스들이 임베디 스 시스템에서 수행될 때, 시스템 지원이 효율적으로 사용된다. 이 이슈를 해결하기 위해, LISF는 몇 가지 특 징들을 필요로 한다. - CPU, GPGPU 및 메모리를 위한 경량(lightweight) 및 가속(accelerated) 기술이 있는 효율적인 임베디드 시스 템 자원을 위해 사용된다. - 자원 제한적인 임베디드 시스템에 기인한 온라인 부분 학습(online partial learning)을 지원한다. 완전 학 습(fully learning)은 일반적으로 서버 시스템에서 작동한다. - 온라인 부분 학습을 위해 시스템 환경에 맞는 개인화된 학습 모델을 생성한다. - 클라이언트가 자원이 부족한 시스템(예를 들어, 스마트폰)이고, 서버가 지원이 풍부한 시스템(예를 들어, 고 성능 컴퓨터)인 클라이언트-서버 모델과 함께 동작한다. LISF의 클라이언트 및 서버 매커니즘에서, 서버 시스템 및 IoT 장치는 각각 인공지능 프레임워크를 가질 수 있 다. 이 시스템은 장치(device), 플랫폼, 컨텍스트(context), 커맨드 큐 및 커널로 이루어질 수 있다. 장치는 수학적 연산들을 수행하기 위한 실제(actual) 프로세서들을 포함한다. 플랫폼은 적어도 하나의 CPU, 적어도 하 나의 GPU, 적어도 하나의 프로세서 또는 적어도 하나의 하드웨어 가속기(hardware acceleration unit)를 포함할수 있다. 컨텍스트는 장치 집합의 리소스들을 관리하기 위한 엔터티를 포함한다. 커맨드 큐는 커널을 실행하 고, 메모리 맵핑/언맵핑 및 동기화(memory mapping/unmapping and synchronization)를 수행하기 위한 엔터티를 포함한다. 커널은 장치에서 수행되는 코드를 포함한다. 서버 시스템에서 인공지능 프레임워크는 전처리(pre- processing) 및 완전 학습(fully learning)을 수행한다. 완전 학습은 최적화된 학습 모델을 생성하기 위해 프 루닝(pruning)을 활용할 수 있다. 프루닝은 학습 데이터를 학습하는 동안 불필요한 가중치를 지속적으로 0으로 변경하는 것이다. 전처리(pre-processing) 및 완전 학습은 학습 데이터를 사용하여 초기 학습 모델을 생성하므 로 많은 계산을 필요로 하고, 따라서 서버 시스템이 고성능 컴퓨팅 환경을 가진다. 초기 학습 모델은 IoT 장치 의 인공지능 프레임워크로 전송된다. 도 7은 도 6에 도시된 LISF의 가속 처리 기능을 좀 더 자세하게 보여주는 도면이다. 도 7을 참조하면, 가속 처 리 기능은 주어진 학습 모델을 위한 리소스 이용을 최적화할 수 있다. 학습 모델의 모든 계층은 학습 및 추론을 위한 다양한 수학 연산이 필요하다. 가속 처리 기능은 기본 하드웨어 자원에 대해 최적화되고 병렬 수학 연산들 을 제공할 수 있다. 또한 가속 처리 기능은 병목 현상을 식별하기 위하여 성능 모니터링 기능에 의해 제공되는 성능 통계를 검사할 수 있다. 이러한 검사 결과들에 따라, 하드웨어 리소스 사용의 구성은 온-라인 파셜 러닝 기능과 근사 추론 기능을 가속하도록 업데이트될 수 있다. 가속 처리 기능은 학습 모델의 구성 계층들 (constituent layers)에서 사용된 수학 연산들을 가속하기 위하여 필요하다. 수학 연산들은, 예를 들어, 벡터 덧셈, 스칼라 곱셈, 내적 곱, 선형 결합 및 행렬 곱셈 등과 같은 일반적인 선형 대수 연산들을 포함할 수 있다. 이 때, 수학 연산들은 행렬 곱셈(GEMM: General Matrix Multiply) 연산을 포함할 수 있다. 또한, 가속 처리 기능은 병렬 관리 기능 엔터티(parallelization managing FE)과 가속 관리 기능 엔터티 (acceleration managing FE) 로 구성될 수 있다. 병렬 관리 기능 엔터티는 계층의 실행 속도를 향상시키기 위하여 병렬로 수학 연산들을 수행하도록 리소스 내에 서 아래의 엔터티들(entities)을 초기화하고 구성할 수 있다. 예를 들어, 플랫폼은 CPU, GPU 및 기타 프로세서 혹은 하드웨어 가속기들로 구성된 특정한 이종 플랫폼 (heterogeneous platform)을 포함할 수 있다. 장치는 계산을 수행하는 실제 프로세서들, 예를 들어, CPU, GPU, 등을 포함할 수 있다. 컨텍스트(context)는 장치 세트(device set)에 리소스들을 관리하는 엔터티이다. 커맨드 큐(command queue)는 커널(kernel)을 실행하고, 메모리 맵핑/언맵핑(mapping/unmapping) 및 동기화 (synchronization)를 수행하는 엔터티이다. 커널은 장치에 동작하는 코드이다. 이러한 엔터티(FE)는 장치 메모리를 할당하고, 호스트로부터 장치로 데이터를 복사하고, 커널을 설정하고, 및 그 결과를 복사할 수 있다. 이는 병렬 어플리케이션들을 위한 설계에 필요하다. 기본적인 가정은 커널의 많은 인스턴스들(instances)이 각각 단일 작업 항목(single work item)을 처리하면서, 병렬로 실행되는 것이다. 멀티 플 작업 항목들(multiple work items)은 작업 그룹(work group)의 일부로써 함께 실행될 수 잇다. 작업 그룹 내에서, 각각의 커널 인스턴스는 서로 다른 인스턴스와 통신할 수 있다. 병렬 관리 기능 엔터티(Parallelization Managing Function Entity)는 계층 실행 속도를 높이기 위해(to speed up layer execution) 수학적 연산들을 병렬로 실행하기 위하여 다음 엔터티들을 초기화하고 구성한다. 또한, 병렬 관리 기능 엔터티는 OpenCL 장치들과 같은 다수의 임베디드 시스템 장치들에 따라 병렬 처리를 수행하기 위한 병렬 처리 큐(parallel-processing queue)를 관리한다. 또한, 병렬 관리 기능 엔터티는 멀티플 장치 환경 에서 병렬성을 극대화하기 위해, 장치의 병렬 처리 성능을 고려하여 가중치 및 편향 값을 갖는 행렬을 분할 (divide)한다. 이 때, 병렬 처리 기능(parallel processing capability) 또는 병렬 처리 성능은 한번에 실행 되는 커널 인스턴스들의 수, 장치의 최대 작업 그룹 사이즈 또는 최대 작업 항목 사이즈에 의하여 결정된다. - 플랫폼: CPU, GPU 및 기타 프로세서 또는 하드웨어 가속기로 구성된 특정 타겟 이종 플랫폼; - 장치: 계산을 수행하는 실제 프로세서들(예를 들어, CPU, GPU 등); - 컨텍스트: 장치 집합(device set) 상의 리소스를 관리하는 엔터티; - 커맨드 큐: 커널을 실행하고 메모리 맵핑/언맵핑 및 동기화를 수행하는 엔터티; - 커널: 장치에서 실행되는 코드 병렬 관리 기능 엔터티는 장치 메모리를 할당하고, 호스트로부터 장치로 데이터를 복사하고, 커널을 설정하고, 결과를 다시 복사한다. 이것은 병렬 어플리케이션들을 설계하기 위해 필요하다. 기본 가정은 커널의 많은 인스턴스들이 병렬로 실행되고, 각각 단일 작업 항목을 처리한다는 것이다. 여러 작업 항목들(work items)이 작 업 그룹(work group)의 일부로 함께 실행된다. 작업 그룹의 각 커널의 인스턴스는 추가 인스턴스(additional instance)와 통신한다. 한편, 가속 관리 기능 엔터티는 일련의 수학 연산들을 지원하는 커널 프레임워크(framework for kernel, 예를 들어, OpenCL)를 관리할 수 있다. 가속 관리 기능 엔터티는 기본 벡터 및 행렬 연산을 수행하기 위한 표준 빌딩 블록들(standard building blocks)을 제공하는 수학 루틴들(mathematical routines)을 지원할 수 있다. 여기서 수학 연산들은, 스칼라, 벡터, 및/혹은 벡터에 대한 연산들, 행렬과 벡터에 대한 연산들, 및 행렬과 행렬의 연 산들을 포함할 수 있다. 가속 관리 기능 엔터티는 수학 연산들의 집합을 지원하는 커널의 프레임워크를 관리할 수 있다. 수학 연산들의 집합은 합성곱 신경망(Convolutional Neural Network) 과 같은 신경망에서의 연산을 포함할 수 있다. 가속 관 리 기능 엔터티는 기본 벡터 및 행렬 연산들을 위한 표준 빌딩 블록들(standard building blocks)을 제공하는 수학적 루틴들(mathematical routines)을 지원할 수 있다. 가속 관리 기능 엔터티는 자원들을 제어하여 OpenCL 장치와 같은 장치가 분할된 행렬 및 분할된 행렬에 의존하는 입력 데이터에서 GEMM 연산을 수행하도록 한다. 또한, 가속 관리 기능 엔터티는 각 커널을 위한 워크로드(workload)를 최대화하기 위해 행렬을 벡터들로 그룹화 하고, 각 장치가 병렬 처리를 수행할 수 있도록 작업 그룹의 사이즈를 결정한다. 또한, 가속 관리 기능 엔터티 는 GEMM 연산의 비용(cost)을 최소화하기 위해, 호스트와 장치들 사이의 메모리를 공유하고, 각 장치는 메모리 어드레스를 이용하여 호스트의 벡터 및 행렬에 액세스함으로써 호스트와 장치 사이의 데이터 복사 없이 수학적 루틴들을 수행한다. - 스칼라 및 벡터 및/또는 벡터 및 벡터를 이용한 연산, - 행렬 및 벡터를 이용한 연산, 및 - 매트릭스 사이의 연산 도 8은 본 발명의 실시 예에 따른 전자 장치를 예시적으로 보여주는 도면이다. 도 8을 참조하면, 전자 장 치는 적어도 하나의 프로세서, 네트워크 인터페이스, 메모리, 디스플레이, 및 입출력 장치를 포함할 수 있다. 프로세서는 도 1 내지 도 7을 통하여 적어도 하나의 장치를 포함하거나, 도 1 내지 도 7을 통하여 전술한 적어도 하나의 방법으로 구현될 수 있다. 프로세서는, 상술된 바와 같이, 임베디드 시스템에서 합성곱 계 층의 특징을 자동으로 분석하고, 분석된 합성곱 계층 정보를 기반으로 다중 OpenCL 장치를 이용해 다수 합성곱 계층에 대한 계층 병렬 처리를 제공함으로써, 임베디드 시스템과 OpenCL에 대한 전문적인 지식이 없더라도 합성 곱 신경망의 순전파에서 대부분의 연산 시간을 차지하는 합성곱 계층에 대한 가속 장치를 이용하도록 인스럭션 들(instructions)을 실행할 수 있다. 프로세서는 프로그램을 실행하고, 전자 장치을 제어할 수 있다. 전자 장치는 입출력 장치를 통하여 외부 장치(예를 들어, 퍼스널 컴퓨터 혹은 네트워크)에 연결되고, 데이터를 교환할 수 있다. 전자 시스 템은 이동 전화, 스마트 폰, PDA, 태블릿 컴퓨터, 랩톱 컴퓨터 등 모바일 장치, 퍼스널 컴퓨터, 태블릿 컴퓨터, 넷북 등 컴퓨팅 장치, 혹은 텔레비전, 스마트 텔레비전, 게이트 제어를 위한 보안 장치 등 전자 제품 등 다양한 전자 시스템들을 포함할 수 있다. 네트워크 인터페이스는 외부의 네트워크와 다양한 유/무선 방식에 의해 통신을 수행하도록 구현될 수 있 다. 메모리는 컴퓨터에서 읽을 수 있는 명령어(instruction)를 포함할 수 있다. 프로세서는 메모리 에 저장된 명령어가 프로세서에서 실행됨에 따라 앞서 언급된 동작들을 수행할 수 있다. 메모리 는 휘발성 메모리 혹은 비휘발성 메모리일 수 있다. 메모리는 사용자의 데이터를 저장하도록 저장 장치를 포함할 수 있다. 저장 장치는 eMMC(embedded multimedia card), SSD(solid state drive), UFS(universal flash storage) 등 일 수 있다. 저장 장치는 적어 도 하나의 비휘발성 메모리 장치를 포함할 수 있다. 비휘발성 메모리 장치는, 낸드 플래시 메모리(NAND Flash Memory), 수직형 낸드 플래시 메모리(Vertical NAND; VNAND), 노아 플래시 메모리(NOR Flash Memory), 저항성 램(Resistive Random Access Memory: RRAM), 상변화 메모리(Phase-Change Memory: PRAM), 자기저항 메모리 (Magnetoresistive Random Access Memory: MRAM), 강유전체 메모리(Ferroelectric Random Access Memory:FRAM), 스핀주입 자화반전 메모리(Spin Transfer Torque Random Access Memory: STT-RAM) 등이 될 수 있다. 이상에서 설명된 실시 예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/혹은 하드웨어 구성요소 및 소프트 웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(Arithmetic Logic Unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(Programmable Logic Unit), 마이크로프로세서, 혹 은 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 혹은 특 수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하 나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이"}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 대응하는 기술분야에서 통상 의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/혹은 복수 유형의 처리 요소 를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수의 프로세서 혹은 하나의 프로세서 및 하나의 콘 트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 혹은 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 혹은 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/혹은 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 혹은 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 혹은 장치, 혹은 전송되는 신호파(signal wave)에 영구적으로, 혹 은 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분 산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체 에 저장될 수 있다. 본 발명의 실시 예에 따른 전자 장치는, 적어도 하나의 프로세서 및 적어도 하나의 프로세서(110 0)에 의해 실행되는 적어도 하나의 인스트럭션을 저장하는 메모리를 포함하고, 적어도 하나의 인스트럭션 은, 합성곱 계층 응용부에서 합성곱 신경망의 합성곱 계층 정보를 수신하고; 합성곱 계층 분석부에서 상기 합성 곱 계층 정보를 분석하고, OpenCL 장치 정보와 대응하는 합성곱 계층의 독립성 여부를 근거로 하여 계층 병렬 처리 수행 여부를 결정하고; 합성곱 계층 병렬 처리부에서 상기 합성곱 계층이 독립적일 경우 각 OpenCL 장치의 성능을 고려하여 합성곱 계층에 대응하는 행렬을 분할하고, 상기 분할될 행렬을 이용하여 상기 합성곱 계층에 대응하는 연산들을 병렬 처리하고; 상기 합성곱 계층 병렬 처리부에서 상기 합성곱 계층이 독립적이지 않을 경 우, 단일 OpenCL 장치를 통해 커널을 근거로 하여 상기 대응하는 연산들을 병렬 처리하도록 상기 적어도 하나의 프로세서 프로세서에서 실행될 수 있다. 실시 예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 혹은 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시 예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하 도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 본 발명에서 사물인터넷(Internet Of Things; IoT) 기기는 접근 가능한 유선 또는 무선 인터페이스를 가지며, 유선/무선 인터페이스를 통하여 적어도 하나 이상의 다른 기기와 통신하여, 데이터를 송신 또는 수신하는 기기 들을 포함할 수 있다. 상기 접근 가능한 인터페이스는 유선 근거리통신망(Local Area Network; LAN), Wi- fi(Wireless Fidelity)와 같은 무선 근거리 통신망 (Wireless Local Area Network; WLAN), 블루투스 (Bluetooth)와 같은 무선 개인 통신망(Wireless Personal Area Network; WPAN), 무선 USB (Wireless Universal Serial Bus), Zigbee, NFC (Near Field Communication), RFID (Radio-frequency identification), PLC(PowerLine communication), 또는 3G (3rd Generation), 4G (4th Generation), LTE (Long Term Evolution) 등 이동 통신망(mobile cellular network)에 접속 가능한 모뎀 통신 인터페이스 등을 포함할 수 있다. 블루투스 인터페 이스는 BLE(Bluetooth Low Energy)를 지원할 수 있다. IoT 기기의 전자 구성요소들은, 이에 제한되지 않고, 웨어러블 하우징 내에서 다양한 형태들의 패키지를 이용하 여 실장될 수 있다. 예시적인 실시 예들에 따른 IoT 기기의 전자 구성요소들은 Package On Package(POP), Ball grid arrays(BGAs), Chip scale packages(CSPs), Plastic Leaded Chip Carrier(PLCC), Plastic Dual In-Line Package(PDIP), Chip On Board(COB), Ceramic Dual In-Line Package(CERDIP), Plastic Metric Quad Flat Pack(MQFP), Thin Quad Flatpack(TQFP), Small Outline(SOIC), Shrink Small Outline Package(SSOP), Thin Small Outline(TSOP), Thin Quad Flatpack(TQFP), System In Package(SIP), Multi Chip Package(MCP), Wafer- level Fabricated Package(WFP), Wafer-Level Processed Stack Package(WSP) 등과 같은 패키지들을 이용하여 실장 될 수 있다."}
{"patent_id": "10-2020-0030331", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "한편, 상술 된 본 발명의 내용은 발명을 실시하기 위한 구체적인 실시 예들에 불과하다. 본 발명은 구체적이고 실제로 이용할 수 있는 수단 자체뿐 아니라, 장차 기술로 이용할 수 있는 추상적이고 개념적인 아이디어인 기술 적 사상을 포함할 것이다."}
{"patent_id": "10-2020-0030331", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하에 첨부되는 도면들은 본 실시 예에 관한 이해를 돕기 위한 것으로, 상세한 설명과 함께 실시 예들을 제공 한다. 다만, 본 실시예의 기술적 특징이 특정 도면에 한정되는 것은 아니며, 각 도면에서 개시하는 특징들은 서 로 조합되어 새로운 실시 예로 구성될 수 있다. 도 1은 본 발명의 실시 예에 따른 합성곱 계층 가속 장치를 예시적으로 보여주는 도면이다. 도 2는 본 발명의 실시 예에 따른 합성곱 계층 분석부의 동작 방법을 예시적으로 보여주는 흐름도이다. 도 3은 본 발명의 실시 예에 따른 합성곱 계층 병렬 처리부의 동작 방법을 예시적으로 보여주는 흐름도이 다. 도 4는 본 발명의 실시 예에 따른 합성곱 계층 가속 장치의 동작 방법을 예시적으로 보여주는 흐름도이다. 도 5는 본 발명의 실시 예에 따른 합성곱 계층 가속 장치의 실제 서비스 적용 예를 나타낸 도면이다. 도 6는 본 발명의 실시 예에 따른 LISF를 개념적으로 보여주는 도면이다. 도 7은 도 6에 도시된 LISF의 가속 처리 기능을 좀 더 자세하게 보여주는 도면이다. 도 8은 본 발명의 실시 예에 따른 전자 장치를 예시적으로 보여주는 도면이다."}
