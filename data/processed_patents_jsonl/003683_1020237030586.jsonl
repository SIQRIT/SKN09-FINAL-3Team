{"patent_id": "10-2023-7030586", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0142597", "출원번호": "10-2023-7030586", "발명의 명칭": "비디오 프레임 렌더링 방법 및 장치, 디바이스 및 저장 매체", "출원인": "텐센트 테크놀로지", "발명자": "위안 준샤오"}}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오 프레임 렌더링 방법으로서,서버에 의해, 제1 단말기에 대응하는 제1 비디오 프레임을 획득하는 단계 ― 상기 제1 비디오 프레임은 타깃 가상 장면의 피제어 가상 객체(controlled virtual object)의 시점으로부터 상기 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임이고, 그리고 상기 피제어 가상 객체는 상기 제1 단말기에 의해 제어되는 가상 객체임 ―;상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃가상 객체를 렌더링하는 단계 ― 상기 타깃 가상 객체는 상기 제1 단말기에 의해 재-렌더링될 가상 객체임 ―;및상기 서버에 의해, 상기 제2 비디오 프레임을 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제2비디오 프레임을 디스플레이하도록 구성됨 ―를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃가상 객체를 렌더링하는 단계는,상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제1렌더링 파라미터를 획득하는 단계 ― 상기 제1 렌더링 파라미터는 상기 제1 파라미터의 제1 각도 및 제1 거리에대응하는 렌더링 파라미터이고, 상기 제1 각도는 상기 피제어 가상 객체와 상기 타깃 가상 객체 사이의 각도이고, 그리고 상기 제1 거리는 상기 피제어 가상 객체와 상기 타깃 가상 객체 사이의 거리임 ―; 및상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 렌더링 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 렌더링 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계는,상기 서버에 의해, 상기 제1 렌더링 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체의 복수의 타깃 픽셀 포인트의 타깃 픽셀 값을 결정하는 단계; 및상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 타깃 픽셀 값을 사용함으로써 상기 제1 비디오 프레임 내의 상기 복수의 타깃 픽셀 포인트의 픽셀 값을 업데이트하는 단계를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,공개특허 10-2023-0142597-3-상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃가상 객체를 렌더링하는 단계는,상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우 상기제1 파라미터로부터, 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 획득하는 단계; 및상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 렌더링 파라미터 및 상기 제2 렌더링 파라미터를 사용함으로써, 각각, 상기 제1 비디오 프레임 내의 타깃 가상 객체 및 상기 피제어 가상 객체를 렌더링하는 단계를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃가상 객체를 렌더링하는 단계는,상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 상기타깃 가상 장면의 상기 피제어 가상 객체의 포지션을 결정하는 단계;상기 서버에 의해, 상기 피제어 가상 객체가 상기 타깃 가상 장면의 타깃 서브-장면에 위치되는 경우, 상기 제2비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를렌더링하는 단계를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 서버에 의해, 상기 피제어 가상 객체가 상기 타깃 가상 장면의 타깃 서브-장면에 위치되지 않는 경우, 상기 제1 비디오 프레임을 상기 제2 비디오 프레임으로서 결정하는 단계를 더 포함하는 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃가상 객체를 렌더링하는 단계 이전에, 상기 비디오 프레임 렌더링 방법은,상기 서버에 의해, 상기 제1 비디오 프레임의 타입을 결정하기 위해, 상기 제1 비디오 프레임에 대한 이미지 인식(image recognition)을 수행하는 단계를 더 포함하고, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를렌더링하는 단계는,상기 서버에 의해, 상기 제1 비디오 프레임이 상기 타깃 가상 객체를 디스플레이한다는 것을 상기 제1 비디오프레임의 타입이 지시하는 경우, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기타깃 가상 객체를 렌더링하는 단계를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2023-0142597-4-제1항에 있어서, 상기 서버에 의해, 상기 제1 단말기에 대응하는 제3 비디오 프레임을 획득하는 단계 ― 상기 제3 비디오 프레임은, 상기 타깃 가상 장면에서 타깃 이벤트가 발생한 후, 상기 피제어 가상 객체의 시점으로부터 상기 타깃 가상장면을 렌더링함으로써 획득되는 비디오 프레임이고, 그리고 상기 타깃 이벤트는, 상기 피제어 가상 객체가 상기 타깃 가상 장면의 상기 제1 가상 객체를 물리치는 것(defeat)을 지시함 ―;상기 서버에 의해, 상기 타깃 이벤트에 대응하는 제1 애니메이션(animation) 및 상기 타깃 이벤트에 대응하는제1 오디오를 획득하는 단계 ― 상기 제1 오디오는 상기 제1 단말기의 오디오임 ―;상기 서버에 의해, 상기 제3 비디오 프레임에서 상기 제1 가상 객체가 패배한(defeated) 구역을 결정하는 단계;상기 서버에 의해, 제4 비디오 프레임을 획득하기 위해 상기 구역에 상기 타깃 이벤트에 대응하는 제1 애니메이션을 추가하는 단계; 및상기 서버에 의해, 상기 제4 비디오 프레임 및 상기 제1 오디오를 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제4 비디오 프레임을 디스플레이하면서 상기 제1 오디오를 플레이하도록 구성됨―를 더 포함하는 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 타깃 가상 장면은 제2 가상 객체를 더 포함하고, 상기 제2 가상 객체는 제2 단말기에 의해 제어되는 가상객체이고, 상기 제2 단말기 및 상기 제1 단말기는 상이한 단말기이고, 상기 비디오 프레임 렌더링 방법은,상기 서버에 의해, 상기 제2 단말기에 대응하는 제5 비디오 프레임을 획득하는 단계 ― 상기 제5 비디오 프레임은 상기 제2 가상 객체의 시점으로부터 상기 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임임 ―;상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 상기 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하는 단계; 및상기 서버에 의해, 상기 제6 비디오 프레임을 상기 제2 단말기에 전송하는 단계 ― 상기 제2 단말기는 상기 제6비디오 프레임을 디스플레이하도록 구성됨 ―를 더 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 상기 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하는 단계는,상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 제6 비디오 프레임을 획득하기 위해 상기 제2 단말기의 제2 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계;상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 제6 비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계; 및상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 제6 비디오 프레임을 획득하기 위해 상기 제5 비디오 프레임에 상기 타깃 가상 객체에 대응하는 제2 애니메이션을 추가하는단계중 적어도 하나를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2023-0142597-5-제9항에 있어서, 상기 피제어 가상 객체 및 상기 제2 가상 객체 둘 다가 상기 타깃 가상 장면의 타깃 서브-장면에 위치되고; 그리고 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 상기 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하는 단계는,상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 피제어 가상객체의 가상 레벨을 상기 제2 가상 객체의 가상 레벨과 비교하는 단계;상기 서버에 의해, 상기 피제어 가상 객체의 가상 레벨이 상기 제2 가상 객체의 가상 레벨보다 높은 경우, 상기제6 비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계;상기 서버에 의해, 상기 피제어 가상 객체의 가상 레벨이 상기 제2 가상 객체의 가상 레벨보다 낮은 경우, 상기제6 비디오 프레임을 획득하기 위해 상기 제2 단말기의 제2 파라미터에 기반하여 상기 제5 비디오 프레임 내의타깃 가상 객체를 렌더링하는 단계; 및상기 서버에 의해, 상기 피제어 가상 객체의 가상 레벨이 상기 제2 가상 객체의 가상 레벨과 동일한 경우, 상기제6 비디오 프레임을 획득하기 위해 제3 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객체를렌더링하는 단계를 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃가상 객체를 렌더링하는 단계 이후에, 상기 비디오 프레임 렌더링 방법은,상기 서버에 의해, 상기 타깃 가상 객체에 대응하는 제2 애니메이션 및 제2 오디오를 획득하는 단계;상기 서버에 의해, 제7 비디오 프레임을 획득하기 위해 상기 제2 비디오 프레임에 상기 타깃 가상 객체에 대응하는 제2 애니메이션을 추가하는 단계; 및상기 서버에 의해, 상기 제7 비디오 프레임 및 상기 제2 오디오를 상기 제1 단말기에 전송하는 단계 ― 상기 제2 단말기는 상기 제7 비디오 프레임을 디스플레이하면서 상기 제2 오디오를 플레이하도록 구성됨―를 더 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제12항 중 어느 한 항에 있어서, 상기 서버에 의해, 상기 제2 비디오 프레임을 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제2비디오 프레임을 디스플레이하도록 구성됨 ― 후에, 상기 비디오 프레임 렌더링 방법은,상기 서버에 의해, 복수의 제2 비디오 프레임을 제1 비디오 프레임 세트로 합산(aggregating)하고, 그리고 상기제1 비디오 프레임 세트를 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제1 비디오 프레임 세트를 다른 단말기와 공유하도록 구성됨 ―;상기 서버에 의해, 스티칭된 비디오 프레임을 획득하기 위해 상기 제2 비디오 프레임 및 상기 제1 비디오 프레임을 스티칭하는 단계; 및 상기 서버에 의해, 복수의 스티칭된 비디오 프레임을 제2 비디오 프레임 세트로 합산하고, 그리고 상기 서버에의해, 상기 제2 비디오 프레임 세트를 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제2 비디오프레임 세트를 다른 단말기와 공유하도록 구성됨 ―중 적어도 하나를 더 포함하는, 비디오 프레임 렌더링 방법."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2023-0142597-6-비디오 프레임 렌더링 시스템으로서,제1 단말기, 제1 서버, 및 제2 서버를 포함하고,상기 제1 단말기, 상기 제1 서버, 및 상기 제2 서버는 서로 통신 가능하게 연결되고,상기 제1 서버는, 상기 제1 단말기에 대응하는 제1 비디오 프레임을 획득하기 위해 상기 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 상기 타깃 가상 장면을 렌더링하도록, 그리고 상기 제1 비디오 프레임을 상기 제2서버에 전송하도록 구성되고, 상기 피제어 가상 객체는 상기 제1 단말기에 의해 제어되는 가상 객체이고;상기 제2 단말기는 상기 제1 비디오 프레임을 수신하도록 구성되고;상기 제2 서버는 추가로, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우,제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의타깃 가상 객체를 렌더링하도록 구성되고;상기 제2 서버는 추가로, 상기 제2 비디오 프레임을 상기 제1 단말기에 전송하도록 구성되고; 상기 제1 단말기는 상기 2 비디오 프레임을 수신하는 것에 응답하여 상기 제2 비디오 프레임을 디스플레이하도록 구성되는, 비디오 프레임 렌더링 시스템."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "서버로서, 하나 이상의 프로세서 및 하나 이상의 메모리를 포함하고,상기 하나 이상의 메모리는 적어도 하나의 컴퓨터 프로그램을 저장하고, 그리고 상기 컴퓨터 프로그램은, 제1항내지 제12항 중 어느 한 항에 따른 비디오 프레임 렌더링 방법을 구현하기 위해, 상기 하나 이상의 프로세서에의해 로딩되고 실행되는, 서버."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터-판독가능 저장 매체로서, 적어도 하나의 컴퓨터 프로그램을 저장하고,상기 컴퓨터 프로그램은, 제1항 내지 제12항 중 어느 한 항에 따른 비디오 프레임 렌더링 방법을 구현하기 위해프로세서에 의해 로딩되고 실행되는, 컴퓨터-판독가능 저장 매체."}
{"patent_id": "10-2023-7030586", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 프로그램 제품으로서,프로그램 코드를 포함하고, 상기 프로그램 코드는, 제1항 내지 제12항 중 어느 한 항에 따른 비디오 프레임 렌더링 방법을 구현하기 위해 프로세서에 의해 실행되는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2023-7030586", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은, 컴퓨터"}
{"patent_id": "10-2023-7030586", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 속하는, 비디오 프레임 렌더링 방법 및 장치, 디바이스, 및 저장 매체를 개시한 다. 방법은, 서버가 제1 단말기에 대응하는 제1 비디오 프레임을 획득하는 단계 ― 제1 비디오 프레임은 타깃 가상 장면의 피제어 가상 객체의 화각(view angle)으로 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레 임이고, 그리고 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체임―; 제1 비디오 프레임이 제1 단말 기의 타깃 가상 객체를 디스플레이할 때, 서버가, 제2 비디오 프레임을 획득하기 위해 제1 단말기의 제1 파라미 터에 기초하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계; 및 서버가 제2 비디오 프레임을 제1 단말기에 전송하는 단계를 포함하고, 제1 단말기는 제2 비디오 프레임을 디스플레이하는 데 사용된다. 대 표 도 - 도2"}
{"patent_id": "10-2023-7030586", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2023-0142597 CPC특허분류 G06T 19/00 (2013.01) A63F 2300/308 (2013.01) A63F 2300/66 (2013.01)명 세 서 청구범위 청구항 1 비디오 프레임 렌더링 방법으로서, 서버에 의해, 제1 단말기에 대응하는 제1 비디오 프레임을 획득하는 단계 ― 상기 제1 비디오 프레임은 타깃 가 상 장면의 피제어 가상 객체(controlled virtual object)의 시점으로부터 상기 타깃 가상 장면을 렌더링함으로 써 획득되는 비디오 프레임이고, 그리고 상기 피제어 가상 객체는 상기 제1 단말기에 의해 제어되는 가상 객체 임 ―; 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계 ― 상기 타깃 가상 객체는 상기 제1 단말기에 의해 재-렌더링될 가상 객체임 ―; 및 상기 서버에 의해, 상기 제2 비디오 프레임을 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제2 비디오 프레임을 디스플레이하도록 구성됨 ― 를 포함하는, 비디오 프레임 렌더링 방법. 청구항 2 제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계는, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제1 렌더링 파라미터를 획득하는 단계 ― 상기 제1 렌더링 파라미터는 상기 제1 파라미터의 제1 각도 및 제1 거리에 대응하는 렌더링 파라미터이고, 상기 제1 각도는 상기 피제어 가상 객체와 상기 타깃 가상 객체 사이의 각도이 고, 그리고 상기 제1 거리는 상기 피제어 가상 객체와 상기 타깃 가상 객체 사이의 거리임 ―; 및 상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 렌더링 파라미터에 기반하여 상기 제1 비 디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계 를 포함하는, 비디오 프레임 렌더링 방법. 청구항 3 제2항에 있어서, 상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 렌더링 파라미터에 기반하여 상기 제1 비 디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계는, 상기 서버에 의해, 상기 제1 렌더링 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체의 복수 의 타깃 픽셀 포인트의 타깃 픽셀 값을 결정하는 단계; 및 상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 타깃 픽셀 값을 사용함으로써 상기 제1 비디 오 프레임 내의 상기 복수의 타깃 픽셀 포인트의 픽셀 값을 업데이트하는 단계 를 포함하는, 비디오 프레임 렌더링 방법. 청구항 4 제1항에 있어서,상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계는, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우 상기 제1 파라미터로부터, 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 획득하는 단계; 및 상기 서버에 의해, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 렌더링 파라미터 및 상기 제2 렌더링 파 라미터를 사용함으로써, 각각, 상기 제1 비디오 프레임 내의 타깃 가상 객체 및 상기 피제어 가상 객체를 렌더 링하는 단계 를 포함하는, 비디오 프레임 렌더링 방법. 청구항 5 제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계는, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 상기 타깃 가상 장면의 상기 피제어 가상 객체의 포지션을 결정하는 단계; 상기 서버에 의해, 상기 피제어 가상 객체가 상기 타깃 가상 장면의 타깃 서브-장면에 위치되는 경우, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계 를 포함하는, 비디오 프레임 렌더링 방법. 청구항 6 제5항에 있어서, 상기 서버에 의해, 상기 피제어 가상 객체가 상기 타깃 가상 장면의 타깃 서브-장면에 위치되지 않는 경우, 상 기 제1 비디오 프레임을 상기 제2 비디오 프레임으로서 결정하는 단계를 더 포함하는 비디오 프레임 렌더링 방 법. 청구항 7 제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계 이전에, 상기 비디오 프레임 렌더링 방법은, 상기 서버에 의해, 상기 제1 비디오 프레임의 타입을 결정하기 위해, 상기 제1 비디오 프레임에 대한 이미지 인 식(image recognition)을 수행하는 단계를 더 포함하고, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계는, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 타깃 가상 객체를 디스플레이한다는 것을 상기 제1 비디오 프레임의 타입이 지시하는 경우, 상기 제2 비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 타깃 가상 객체를 렌더링하는 단계를 포함하는, 비디오 프레임 렌더링 방법. 청구항 8 제1항에 있어서, 상기 서버에 의해, 상기 제1 단말기에 대응하는 제3 비디오 프레임을 획득하는 단계 ― 상기 제3 비디오 프레임 은, 상기 타깃 가상 장면에서 타깃 이벤트가 발생한 후, 상기 피제어 가상 객체의 시점으로부터 상기 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임이고, 그리고 상기 타깃 이벤트는, 상기 피제어 가상 객체가 상 기 타깃 가상 장면의 상기 제1 가상 객체를 물리치는 것(defeat)을 지시함 ―; 상기 서버에 의해, 상기 타깃 이벤트에 대응하는 제1 애니메이션(animation) 및 상기 타깃 이벤트에 대응하는 제1 오디오를 획득하는 단계 ― 상기 제1 오디오는 상기 제1 단말기의 오디오임 ―; 상기 서버에 의해, 상기 제3 비디오 프레임에서 상기 제1 가상 객체가 패배한(defeated) 구역을 결정하는 단계; 상기 서버에 의해, 제4 비디오 프레임을 획득하기 위해 상기 구역에 상기 타깃 이벤트에 대응하는 제1 애니메이 션을 추가하는 단계; 및 상기 서버에 의해, 상기 제4 비디오 프레임 및 상기 제1 오디오를 상기 제1 단말기에 전송하는 단계 ― 상기 제 1 단말기는 상기 제4 비디오 프레임을 디스플레이하면서 상기 제1 오디오를 플레이하도록 구성됨― 를 더 포함하는 비디오 프레임 렌더링 방법. 청구항 9 제1항에 있어서, 상기 타깃 가상 장면은 제2 가상 객체를 더 포함하고, 상기 제2 가상 객체는 제2 단말기에 의해 제어되는 가상 객체이고, 상기 제2 단말기 및 상기 제1 단말기는 상이한 단말기이고, 상기 비디오 프레임 렌더링 방법은, 상기 서버에 의해, 상기 제2 단말기에 대응하는 제5 비디오 프레임을 획득하는 단계 ― 상기 제5 비디오 프레임 은 상기 제2 가상 객체의 시점으로부터 상기 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임임 ―; 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임 을 획득하기 위해 상기 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하는 단계; 및 상기 서버에 의해, 상기 제6 비디오 프레임을 상기 제2 단말기에 전송하는 단계 ― 상기 제2 단말기는 상기 제6 비디오 프레임을 디스플레이하도록 구성됨 ― 를 더 포함하는, 비디오 프레임 렌더링 방법. 청구항 10 제9항에 있어서, 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임 을 획득하기 위해 상기 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하는 단계는, 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 제6 비디오 프 레임을 획득하기 위해 상기 제2 단말기의 제2 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객 체를 렌더링하는 단계; 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 제6 비디오 프 레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하 는 단계; 및 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 제6 비디오 프 레임을 획득하기 위해 상기 제5 비디오 프레임에 상기 타깃 가상 객체에 대응하는 제2 애니메이션을 추가하는 단계 중 적어도 하나를 포함하는, 비디오 프레임 렌더링 방법. 청구항 11 제9항에 있어서, 상기 피제어 가상 객체 및 상기 제2 가상 객체 둘 다가 상기 타깃 가상 장면의 타깃 서브-장면에 위치되고; 그 리고 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프 레임을 획득하기 위해 상기 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하는 단계는, 상기 서버에 의해, 상기 제5 비디오 프레임이 상기 타깃 가상 객체를 디스플레이하는 경우, 상기 피제어 가상 객체의 가상 레벨을 상기 제2 가상 객체의 가상 레벨과 비교하는 단계; 상기 서버에 의해, 상기 피제어 가상 객체의 가상 레벨이 상기 제2 가상 객체의 가상 레벨보다 높은 경우, 상기 제6 비디오 프레임을 획득하기 위해 상기 제1 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객 체를 렌더링하는 단계; 상기 서버에 의해, 상기 피제어 가상 객체의 가상 레벨이 상기 제2 가상 객체의 가상 레벨보다 낮은 경우, 상기 제6 비디오 프레임을 획득하기 위해 상기 제2 단말기의 제2 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계; 및 상기 서버에 의해, 상기 피제어 가상 객체의 가상 레벨이 상기 제2 가상 객체의 가상 레벨과 동일한 경우, 상기 제6 비디오 프레임을 획득하기 위해 제3 파라미터에 기반하여 상기 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계 를 포함하는, 비디오 프레임 렌더링 방법. 청구항 12 제1항에 있어서, 상기 서버에 의해, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단계 이후에, 상기 비디오 프레임 렌더링 방법은, 상기 서버에 의해, 상기 타깃 가상 객체에 대응하는 제2 애니메이션 및 제2 오디오를 획득하는 단계; 상기 서버에 의해, 제7 비디오 프레임을 획득하기 위해 상기 제2 비디오 프레임에 상기 타깃 가상 객체에 대응 하는 제2 애니메이션을 추가하는 단계; 및 상기 서버에 의해, 상기 제7 비디오 프레임 및 상기 제2 오디오를 상기 제1 단말기에 전송하는 단계 ― 상기 제 2 단말기는 상기 제7 비디오 프레임을 디스플레이하면서 상기 제2 오디오를 플레이하도록 구성됨― 를 더 포함하는, 비디오 프레임 렌더링 방법. 청구항 13 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 서버에 의해, 상기 제2 비디오 프레임을 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제2 비디오 프레임을 디스플레이하도록 구성됨 ― 후에, 상기 비디오 프레임 렌더링 방법은, 상기 서버에 의해, 복수의 제2 비디오 프레임을 제1 비디오 프레임 세트로 합산(aggregating)하고, 그리고 상기 제1 비디오 프레임 세트를 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제1 비디오 프레임 세 트를 다른 단말기와 공유하도록 구성됨 ―; 상기 서버에 의해, 스티칭된 비디오 프레임을 획득하기 위해 상기 제2 비디오 프레임 및 상기 제1 비디오 프레 임을 스티칭하는 단계; 및 상기 서버에 의해, 복수의 스티칭된 비디오 프레임을 제2 비디오 프레임 세트로 합산하고, 그리고 상기 서버에 의해, 상기 제2 비디오 프레임 세트를 상기 제1 단말기에 전송하는 단계 ― 상기 제1 단말기는 상기 제2 비디오 프레임 세트를 다른 단말기와 공유하도록 구성됨 ― 중 적어도 하나를 더 포함하는, 비디오 프레임 렌더링 방법. 청구항 14 비디오 프레임 렌더링 시스템으로서, 제1 단말기, 제1 서버, 및 제2 서버를 포함하고, 상기 제1 단말기, 상기 제1 서버, 및 상기 제2 서버는 서로 통신 가능하게 연결되고, 상기 제1 서버는, 상기 제1 단말기에 대응하는 제1 비디오 프레임을 획득하기 위해 상기 타깃 가상 장면의 피제 어 가상 객체의 시점으로부터 상기 타깃 가상 장면을 렌더링하도록, 그리고 상기 제1 비디오 프레임을 상기 제2 서버에 전송하도록 구성되고, 상기 피제어 가상 객체는 상기 제1 단말기에 의해 제어되는 가상 객체이고; 상기 제2 단말기는 상기 제1 비디오 프레임을 수신하도록 구성되고; 상기 제2 서버는 추가로, 상기 제1 비디오 프레임이 상기 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 상기 제1 단말기의 제1 파라미터에 기반하여 상기 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하도록 구성되고; 상기 제2 서버는 추가로, 상기 제2 비디오 프레임을 상기 제1 단말기에 전송하도록 구성되고; 상기 제1 단말기는 상기 2 비디오 프레임을 수신하는 것에 응답하여 상기 제2 비디오 프레임을 디스플레이하도 록 구성되는, 비디오 프레임 렌더링 시스템. 청구항 15 서버로서, 하나 이상의 프로세서 및 하나 이상의 메모리를 포함하고, 상기 하나 이상의 메모리는 적어도 하나의 컴퓨터 프로그램을 저장하고, 그리고 상기 컴퓨터 프로그램은, 제1항 내지 제12항 중 어느 한 항에 따른 비디오 프레임 렌더링 방법을 구현하기 위해, 상기 하나 이상의 프로세서에 의해 로딩되고 실행되는, 서버. 청구항 16 컴퓨터-판독가능 저장 매체로서, 적어도 하나의 컴퓨터 프로그램을 저장하고, 상기 컴퓨터 프로그램은, 제1항 내지 제12항 중 어느 한 항에 따른 비디오 프레임 렌더링 방법을 구현하기 위해 프로세서에 의해 로딩되고 실행되는, 컴퓨터-판독가능 저장 매체. 청구항 17 컴퓨터 프로그램 제품으로서, 프로그램 코드를 포함하고, 상기 프로그램 코드는, 제1항 내지 제12항 중 어느 한 항에 따른 비디오 프레임 렌 더링 방법을 구현하기 위해 프로세서에 의해 실행되는, 컴퓨터 프로그램 제품. 발명의 설명 기 술 분 야 본 출원은 2021년 8월 31일자로 \"비디오 프레임 렌더링 방법, 장치, 및 디바이스, 및 저장 매체\"라는 명칭으로 출원된 중국 특허 출원 제202111010058.0호의 우선권을 주장하며, 이 특허 출원은 그 전체가 참조로 포함된다. 본 개시내용은 컴퓨터의 기술 분야에 관한 것으로, 특히 비디오 프레임 렌더링 방법, 장치, 디바이스 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2023-7030586", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "클라우드 컴퓨팅 기술의 발달로, 사용자는 클라우드 컴퓨팅을 통해 단말기가 완료하기 어려운 업무(task)를 완 료할 수 있다. 예를 들어, 클라우드 게임의 분야에서, 사용자는 클라우드 컴퓨팅 기술을 통해 단말기가 원활하 게 구동할 수 없는 게임을 플레이할 수 있다. 게임과 관련된 백그라운드 프로세싱은 모두 클라우드 게이밍 서 버에 의해 완료되며, 단말기는 제어 정보를 클라우드 게이밍 서버에 전송하기만 하면 된다. 제어 정보는 게임장면에서 게임 객체를 제어하는 데 사용된다. 클라우드 게이밍 서버(cloud gaming server)는 비디오 프레임을 획득하기 위해 제어 정보에 기반하여 백그라운드 프로세싱을 수행할 수 있다. 클라우드 게이밍 서버는 비디오 프레임을 단말기에 전송한다. 단말기는 비디오 프레임을 디스플레이한다. 선행 기술에서, 게임 장면의 특정 게임 객체의 경우, 게임 객체의 디스플레이 효과는 게임을 설계하는 프로세스 동안 기술자에 의해 사전에(in advance) 구성된다. 예를 들어, 게임 장면의 차량의 경우, 차량의 컬러와 스타 일은 기술자에 의해 사전에 구성된다. 본 개시내용의 실시예에 따라, 클라우드 애플리케이션에서 가상 객체에 대한 2차 렌더링을 수행하는 기능을 달 성하기 위한, 비디오 프레임 렌더링 방법, 장치, 디바이스 및 저장 매체가 제공된다. 본 개시내용의 기술적 솔 루션은 다음과 같다. 일 양상에서, 비디오 프레임 렌더링 방법이 제공된다. 이 방법은, 서버에 의해, 제1 단말기에 대응하는 제1 비디오 프레임을 획득하는 단계 ― 제1 비디오 프레임은 타깃 가상 장 면의 피제어 가상 객체(controlled virtual object)의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임이고, 그리고 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체임 ―; 서버에 의해, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임을 획득하기 위해 제1 단말기의 제1 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 단 계 ― 타깃 가상 객체는 제1 단말기에 의해 재-렌더링될 가상 객체임 ―; 및 서버에 의해, 제2 비디오 프레임을 제1 단말기에 전송하는 단계 ― 제1 단말기는 제2 비디오 프레임을 디스플레 이하도록 구성됨 ― 를 포함한다. 일 양상에서, 비디오 프레임 렌더링 시스템이 제공된다. 이 시스템은, 제1 단말기, 제1 서버, 제2 서버를 포함한다. 제1 단말기, 제1 서버, 및 제2 서버는 서로 통신하게 연결된다. 제1 서버는, 제1 단말기에 대응하는 제1 비디오 프레임을 획득하기 위해 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링하도록, 그리고 제1 비디오 프레임을 제2 서버에 전송하도록 구성된다. 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체이다. 제2 서버는 제1 비디오 프레임을 수신하도록 구성된다. 제2 서버는 추가로, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프 레임을 획득하기 위해 제1 단말기의 제1 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링 하도록 구성된다. 제2 서버는 추가로, 제2 비디오 프레임을 제1 단말기에 전송하도록 구성된다. 제1 단말기는 제2 비디오 프레임을 수신하는 것에 응답하여 제2 비디오 프레임을 디스플레이하도록 구성된다. 일 양상에서, 비디오 프레임 렌더링 장치가 제공된다. 장치는 제1 비디오 프레임 획득 모듈, 렌더링 모듈 및 전송 모듈을 포함한다. 제1 비디오 프레임 획득 모듈은 제1 단말기에 대응하는 제1 비디오 프레임을 획득하도록 구성된다. 제1 비디오 프레임은 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되는 비디 오 프레임이고, 그리고 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체이다. 렌더링 모듈은, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프레임 을 획득하기 위해 제1 단말기의 제1 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링하도 록 구성된다. 타깃 가상 객체는 제1 단말기에 의해 재-렌더링되어야 할 가상 객체이다. 전송 모듈은 제2 비디오 프레임을 제1 단말기에 전송하도록 구성된다. 제1 단말기는 제2 비디오 프레임을 디스 플레이하도록 구성된다. 다른 양상에서, 서버가 제공된다. 서버는 하나 이상의 프로세서 및 하나 이상의 메모리를 포함한다. 하나 이 상의 메모리는 적어도 하나의 컴퓨터 프로그램을 저장하고, 그리고 컴퓨터 프로그램은 비디오 프레임 렌더링 방법을 구현하기 위해 하나 이상의 프로세서에 의해 로딩되고 실행된다. 일 양상에서, 컴퓨터-판독가능 저장 매체가 제공된다. 컴퓨터-판독가능 저장 매체는 적어도 하나의 컴퓨터 프 로그램을 저장하고, 그리고 컴퓨터 프로그램은 비디오 프레임 렌더링 방법을 구현하기 위해 프로세서에 의해 로 딩되고 실행된다. 일 양상에서, 컴퓨터 프로그램 제품이 제공된다. 컴퓨터 프로그램 제품은 컴퓨터 프로그램 코드를 포함한다. 프로그램 코드는 비디오 프레임 렌더링 방법을 구현하기 위해 프로세서에 의해 실행된다. 본 개시내용의 실시예에 의해 제공되는 기술적 솔루션에 따라, 특정 가상 객체의 디스플레이 효과를 변경하고자 하는 경우, 가상 객체에 대해, 제1 파라미터가 제1 단말기에 의해 결정된다. 제2 비디오 프레임을 획득하기 위 해 제1 파라미터에 기반하여 제1 비디오 프레임에 대해 2차 렌더링이 수행된다. 제1 비디오 프레임과 비교하여, 제2 비디오 프레임에 디스플레이되는 가상 객체의 디스플레이 효과는 또한, 가상 객체에 대해 제1 단 말기에 의해 구성된 디스플레이 효과이기도 하다. 상기 기술적 솔루션에 따라, 가상 객체에 대한 2차 렌더링을 수행하는 기능이 클라우드 애플리케이션에서 달성되고, 따라서 사용자가 가상 장면의 특정 가상 객체의 디스플 레이 효과를 빠르고 효율적으로 조정할 수 있으며, 이로써 클라우드 애플리케이션의 기능 범위가 확장되고 클라 우드 애플리케이션의 개인화(personalization)가 개선된다. 따라서, 클라우드 애플리케이션이 더 광범위하게 전파된다."}
{"patent_id": "10-2023-7030586", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시내용의 목적, 기술적 솔루션 및 이점을 더 명확하게 예시하기 위해, 본 개시내용의 실시예가 도면을 참 조하여 추가로 상세하게 설명된다. 본 개시내용에서 \"제1\", \"제2\" 등의 용어는 실질적으로 동일한 효과 및 기능을 갖는 동일한 또는 유사한 항목을 구별하는 데 사용된다. \"제1\", \"제2\", 및 \"제n\"이라는 용어가 서로 논리적 또는 연대적 종속성을 갖지 않으며 실행 횟수 및 순서를 제한하지 않는다는 것이 이해되어야 한다. 본 개시내용에서 \"적어도 하나\"라는 용어는 하나 이상을 지칭하고, \"다수\"의 의미는 2개 이상을 지칭하며, 예를 들어, 다수의 기준 페이스 이미지는 2개 이상의 기준 페이스 이미지를 지칭한다. 클라우드 애플리케이션(cloud application): 이는, 통상적 애플리케이션 \"로컬 설치 및 로컬 운영\"의 사용 모드 를 \"온-디맨드\" 서비스로 바꾸고 그리고 인터넷 또는 근거리 네트워크를 통해 원격 서버 클러스터를 연결하고 조작하여, 비즈니스 로직이나 컴퓨팅 업무를 완성하는 새로운 애플리케이션이다. 클라우드 애플리케이션은 원 격 서버 클러스터에서 구동되지만, 클라우드 애플리케이션의 인터페이스가 단말기 상에 디스플레이되며, 이는 단말기의 운영 비용을 감소시키고 작업 효율성을 크게 개선할 수 있다. 게이밍 온 디멘드(Gaming on Demand)로 또한 알려진 클라우드 게이밍은, 클라우드 컴퓨팅-기반 온라인 게이밍 기술이다. 클라우드 게이밍 기술은, 상대적으로 제한된 그래픽 프로세싱 및 데이터 컴퓨팅 능력을 갖는 씬 클 라이언트(Thin Client)가 고품질 게임을 구동하게 한다. 클라우드 게이밍 장면에서, 게임은 플레이어 게이밍 단말기에서 구동되는 것이 아니라, 클라우드 서버에서 구동된다. 게임 장면은, 클라우드 게이밍 서버에 의해 비디오 및 오디오 스트림으로 렌더링되고 그리고 네트워크를 통해 플레이어 게이밍 단말기에 전송된다. 플레이 어 게임 단말기가 기본적 스트리밍 미디어 플레이 능력 및 플레이어 입력 명령을 획득하고 이를 클라우드 게이 밍 서버에 전송하는 능력을 갖는 한, 플레이어 게임 단말기는 강력한 그래픽 컴퓨팅 및 데이터 프로세싱 능력을 가질 필요가 없다. 가상 장면(virtual scene): 이는 애플리케이션이 구동될 때 디스플레이(또는 제공)되는 가상 장면이다. 가상 장면은 실세계 시뮬레이션 환경, 반-시뮬레이션 반-허구적(semi-simulation semi-fictional) 가상 환경, 또는 순전 허구적(purely fictional) 가상 환경일 수 있다. 가상 장면은 2-차원 가상 장면, 2.5-차원 가상 장면, 또 는 3-차원 가상 장면 중 임의의 하나일 수 있으며, 본 개시내용의 실시예에서 가상 장면의 차원은 제한되지 않 는다. 예를 들어, 가상 장면은 하늘, 땅, 바다 등을 포함할 수 있다. 땅은 사막 및 도시와 같은 환경적 엘리 먼트를 포함할 수 있고, 사용자는 가상 장면에서 가상 객체가 움직이도록 제어할 수 있다. 가상 객체(virtual object): 이는 가상 장면에서의 이동가능한 객체를 지칭한다. 이동가능한 객체는 가상 캐릭 터, 가상 동물, 애니메이션 캐릭터 등일 수 있으며, 예를 들어, 가상 장면에 디스플레이되는 캐릭터, 동물, 식 물, 오일 통(oil bucket), 벽, 돌 등일 수 있다. 가상 객체는 가상 장면에 사용자를 표현하기 위한 가상 아바 타일 수 있다. 가상 장면에는 다수의 가상 객체가 포함될 수 있다. 각각의 가상 객체는, 가상 장면에서 고유 한 형상과 부피를 갖고 그리고 가상 장면에서 공간의 일부를 차지한다. 일부 실시예에서, 가상 객체는 클라이언트에서의 조작에 의해 제어되는 플레이어 캐릭터이거나, 또는 가상 장면 전투에 설정된 인공 지능(AI), 또는 가상 장면에 설정된 논-플레이어 캐릭터(NPC: non-player character)일 수 있다. 일부 실시예에서, 가상 객체는 가상 장면에서 경합하는 가상 캐릭터이다. 일부 실시예에서, 가상 장면 에서 상호작용에 참여하는 가상 객체의 수량은 미리 설정되거나 또는 상호작용에 참여하는 클라이언트의 수량에 기반하여 동적으로 결정된다. 슈팅 게임(shooting game)을 예로 들면, 사용자는 가상 장면의 하늘에서 자유롭게 낙하하거나, 활공하거나 또는 낙하산 펴서 낙하하는 등을 하도록, 땅에서 달리고, 점프하고, 기어가고, 앞으로 구부리는 등을 하도록 가상 객 체를 제어할 수 있고, 그리고 또한, 바다에서 수영하고, 물에 뜨고, 다이빙하는 것 등을 하도록 가상 객체를 제 어할 수 있다. 물론, 사용자는 또한, 가상 장면에서 가상 캐리어에 탑승하여 이동하도록 가상 객체를 제어할 수 있고, 예를 들어 가상 캐리어는 가상 차량, 가상 항공기 또는 가상 요트일 수 있다. 앞선 장면은 단지 본원 에서 예로서만 취해진 것이며, 장면은 본 개시내용의 실시예에서 제한되지 않는다. 사용자는 또한, 상호작용 소품(prop)에 의해 가상 객체와 다른 가상 객체의 상호작용, 이를테면 결투를 제어할 수 있다. 예를 들어, 상 호작용 소품은 투척 상호작용 소품, 이를테면, 가상 수류탄(virtual hand grenade), 가상 클러스터 지뢰 (virtual cluster mine), 및 가상 점착 수류탄(virtual sticky hand grenade)(이하 \"가상 점착 소화탄(virtual sticky grenade)\"일 수 있고, 그리고 또한, 슈팅 상호작용 소품, 이를테면, 가상 기관총, 가상 권총, 가상 소총 일 수 있다. 상호작용 소품의 타입은 본 개시내용의 실시예에서 제한되지 않는다. 안드로이드 컨테이너(Android container): 안드로이드는 컨테이너 이미지로 패키징된 다음, 표준 컨테이너 이미 지를 통해 게시된다. 캐리어는 OCI(open container initiative)를 지원하는 임의의 컨테이너 셸(shell)일 수 있고, 따라서 캐리어는 kubernetes(k8s, 컨테이너 오케스트레이션 엔진(container orchestration engine))를 통해 쉽게 유지 관리될 수 있다. k8s의 강력한 유지 관리 도구에 의해 수천 개의 서버 클러스터가 클라우드 상 에 쉽게 배포될 수 있다. 도 1은 본 개시내용의 실시예에 따른 비디오 프레임 렌더링 방법의 구현 환경의 개략적 다이어그램이다. 도 1 을 참조하면, 구현 환경은 제1 단말기, 클라이언트 서버, 제1 서버, 게임 서버, 및 제2 서 버를 포함할 수 있다. 일부 실시예에서, 제1 단말기, 클라이언트 서버, 제1 서버, 게임 서버, 및 제2 서버는 블록 체인 시스템의 노드이고, 그리고 제1 단말기, 클라이언트 서버, 제1 서버, 게임 서버, 그리고 제2 서버 사이에서 전송되는 데이터가 또한 블록 체인 상에 저장 된다. 제1 단말기는 무선 네트워크 또는 유선 네트워크를 통해 클라이언트 서버에 연결된다. 일 예에서, 제1 단말기는 스마트 폰, 태블릿 컴퓨터, 노트북 컴퓨터, 데스크톱 컴퓨터, 스마트 워치 등일 수 있지만, 이로 제한되지는 않는다. 제1 단말기에는 가상 장면 디스플레이를 지원하는 클라이언트가 설치되고, 제1단말기는 이 클라이언트를 구동시킨다. 클라이언트 서버는 클라이언트에게 서비스를 제공하는 서버이다. 클라이언트 서버는 독립적인 물리 적 서버, 또는 다수의 물리적 서버로 구성된 분산 시스템 또는 서버 클러스터, 또는 기본적인 클라우드 컴퓨팅 서비스, 이를테면, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 저장, 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 네임 서비스, 보안 서비스, CDN(Content Delivery Network), 빅 데이 터, 인공지능 플랫폼 등을 제공하는 서버이다. 제1 단말기는 구동 클라이언트를 통해 클라이언트 서버 에 로그인한다. 클라이언트 서버는 사용자 계정과 관련된 서비스를 제공하는데, 예를 들면, 사용자 계정 검증과 관련된 서비스를 제공하거나, 또는 사용자 계정에 대응하는 클라우드 게이밍 지속기간을 결정하기 위한 서비스를 제공하거나, 또는 사용자 계정에 대응하는 개인화된 설정을 저장하기 위한 서비스를 제공한다. 클라이언트 서버에 의해 제공되는 서비스는 본 개시내용의 실시예에서 제한되지 않는다. 클라이언트 서버 는 제1 단말기 상에서 구동되는 클라이언트와 제1 서버를 연결하는 매개체이다. 제1 서버는 독립적인 물리적 서버, 또는 다수의 물리적 서버로 구성된 분산 시스템 또는 서버 클러스터, 또는 기본적인 클라우드 컴퓨팅 서비스, 이를테면, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 저장, 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 네임 서비스, 보안 서비스, CDN, 빅 데이터, 인공지능 플랫폼 등을 제공하는 서버이다. 제1 서버는 가상 장면을 디스플레이하는 것과 관련된 백그라운드 서비스에 연결되고, 그리고 제1 단말기는 무선 네트워크 또는 유선 네트워크를 통해 제1 서버 에 연결된다. 제1 단말기는 제어 정보를 제1 서버에 전송할 수 있다. 제어 정보는 가상 장면 에서 가상 객체를 제어하는 데 사용된다. 제1 서버는 제어 정보에 기반하여 가상 장면을 렌더링한다. 제 1 서버는 무선 네트워크 또는 유선 네트워크를 통해 클라이언트 서버에 연결된다. 제1 서버는, 클라이언트 서버로부터 사용자 계정에 관한 관련 정보를 획득하고, 그리고 관련 정보에 기반하여 게임 초 기화와 같은 관련 조작을 수행할 수 있다. 실시예에서, 제1 서버는 클라우드 서버이다. 게임 서버는 독립적인 물리적 서버, 또는 다수의 물리적 서버로 구성된 분산 시스템 또는 서버 클러스터, 또는 기본적인 클라우드 컴퓨팅 서비스, 이를테면, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 저장, 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 네임 서비스, 보안 서비스, CDN, 빅 데이터, 인공지능 플랫폼 등을 제공하는 서버이다. 게임 서버는 무선 네트워크 또는 유선 네트워크를 통 해 제1 서버에 연결된다. 게임 서버는 게임 캐릭터와 관련된 정보, 이를테면, 게임 캐릭터의 친구, 주소록, 게임 캐릭터의 레벨, 게임 캐릭터의 이름을 저장한다. 제1 서버는 게임 서버로부터 게임 캐 릭터와 관련된 정보를 획득할 수 있다. 하나의 사용자 계정이 다수의 게임 캐릭터에 대응할 수 있다. 클라이 언트 서버는 사용자 계정과 관련된 정보를 저장하도록 구성된다. 게임 서버는 게임 캐릭터와 관련된 정보를 저장하도록 구성된다. 제2 서버는 독립적인 물리적 서버, 또는 다수의 물리적 서버로 구성된 분산 시스템 또는 서버 클러스터, 또는 기본적인 클라우드 컴퓨팅 서비스, 이를테면, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 저장, 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 네임 서비스, 보안 서비스, CDN, 빅 데이터, 인공지능 플랫폼 등을 제공하는 서버이다. 제2 서버는 가상 장면의 2차 렌더링과 관련된 서비스 를 제공한다. 제2 서버는 무선 네트워크 또는 유선 네트워크를 통해 제1 서버에 연결된다. 제1 서 버는 가상 장면이 렌더링된 후 비디오 프레임을 제2 서버에 전송할 수 있다. 제2 서버는 사용 자의 개인화된 프로세싱을 실현하기 위해 비디오 프레임에 대해 2차 렌더링을 수행한다. 제2 서버는 2차 렌더링을 거친 비디오 프레임을 제1 단말기에 전송할 수 있고, 그리고 제1 단말기는 2차 렌더링을 거 친 비디오 프레임을 디스플레이한다. 또한, 제2 서버는 무선 네트워크 또는 유선 네트워크를 통해 클라이 언트 서버에 연결된다. 제2 서버는, 클라이언트 서버로부터 사용자 계정에 대응하는 개인화된 설정을 획득하고, 그리고 개인화된 설정에 기반하여 제1 서버에 의해 전송된 비디오 프레임에 대해 2차 렌 더링을 수행하여, 2차 렌더링을 거친 비디오 프레임을 획득할 수 있다. 일부 실시예에서, 제2 서버는 제1 서버에 통합된다. 제2 서버의 기능은 제1 서버 상에서 구동되는 시스템에 의해 구현된다. 실 시예에서, 제2 서버는 장면 관리 서버일 수 있다. 당업자는, 제1 단말기의 수량이 더 많을 수도 또는 더 적을 수도 있다는 것을 알 수 있다. 예를 들어, 단지 하 나의 제1 단말기만 있거나, 수십 또는 수백 개의 제1 단말기가 있거나, 또는 그보다 더 많은 제1 단말기가 존재 한다. 제1 단말기의 수량이 2개 이상 이상인 경우, 상기 구현 환경은 다른 제1 단말기를 더 포함한다. 제1 단 말기의 수량 및 타입은 본 개시내용의 실시예에서 제한되지 않는다.본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 방법의 적용 장면이 설명된 후, 본 개시내용의 실 시예에 의해 제공되는 비디오 프레임 렌더링 방법의 적용 장면이 상기 구현 환경과 결합하여 아래에서 설명될 것이다. 이하의 설명 프로세스에서, 제1 단말기는 상기 구현 환경에서 제1 단말기이고, 클라이언트 서버 는 상기 구현 환경에서 클라이언트 서버이고, 제1 서버는 상기 구현 환경에서 제1 서버이고, 그리고 게임 서버는 상기 구현 환경에서 게임 서버이다. 제2 서버는 상기 구현 환경에서의 제2 서버이다. 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 방법은, 다양한 타입의 클라우드 게이밍 장면에 적용될 수 있는데, 이를테면, 1인칭 슈팅(FPS) 게임, 3인칭 슈팅(TPS) 게임, 멀티플레이어 온라인 배틀 아레나 (MOBA), 또는 체스 게임이나 자동 체스 게임에 적용될 수 있다. 적용 장면은 본 출원의 실시예에서 제한되지 않는다. 예를 들어, 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 방법이 FPS 게임에 적용된다고 가정된 다. 사용자는, 제1 단말기 상에서 클라우드 게임 클라이언트를 시작하고, 그리고 클라우드 게이밍 클라이언트 에 사용자 계정으로 로그인한다. 즉, 사용자는, 클라우드 게이밍 클라이언트에 사용자 계정과 해당 패스워드를 입력하고, 그리고 로그인 컨트롤을 클릭하여 로그인을 수행한다. 로그인 컨트롤에 대한 클릭 조작이 검출되는 것에 응답하여, 제1 단말기는 클라이언트 서버로 로그인 요청을 전송한다. 로그인 요청은 사용자 계정과 해당 비밀번호를 보유한다. 로그인 요청을 수신한 후, 클라이언트 서버는, 로그인 요청으로부터 사용자 계정과 해당 패스워드를 획득하고, 그리고 사용자 계정과 해당 비밀번호를 확인한다. 사용자 계정과 해당 비밀번호를 확인 한 후, 클라이언트 서버는 로그인 성공 정보를 제1 단말기에 전송한다. 제1 단말기는, 로그인 성공 정보를 수 신한 후, 클라우드 게이밍 획득 요청을 클라이언트 서버에 전송한다. 클라우드 게이밍 획득 요청은 사용자 계 정을 보유한다. 클라우드 게이밍 획득 요청을 수신한 후, 클라이언트 서버는, 클라우드 게이밍 획득 요청에 포 함된 사용자 계정에 기반하여 쿼리(query)를 수행하고, 사용자 계정에 해당하는 다수의 클라우드 게임을 획득하 고, 그리고 다수의 클라우드 게임의 식별자를 제1 단말기에 전송한다. 제1 단말기는 클라우드 게이밍 클라이언 트에서 다수의 클라우드 게임의 식별자를 제시한다. 사용자는, 제1단말기를 통해, 클라우드 게이밍 클라이언트 에 디스플레이되는 다수의 클라우드 게임의 식별자 중에서, 플레이될 FPS 게임의 식별자를 선택하는데, 즉, 플 레이될 FPS 게임을 선택한다. 사용자가 클라우드 게이밍 클라이언트에서 FPS 게임을 선택한 후, 제1 단말기는 게임 시작 명령을 클라이언트 서버에 전송한다. 게임 시작 명령은 사용자 계정, FPS 게임의 식별자, 및 제1 단 말기의 하드웨어 정보를 보유한다. 제1 단말기의 하드웨어 정보는 제1 단말기의 화면 해상도, 제1 단말기의 모 델 등을 포함한다. 게임 명령의 콘텐츠는 본 개시내용의 실시예에서 제한되지 않는다. 게임 시작 명령을 수신 한 후, 클라이언트 서버는 게임 시작 명령을 제1 서버에 전송한다. 게임 시작 명령을 수신한 후, 제1 서버는 게임 시작 명령으로부터 사용자 계정, FPS 게임의 식별자, 및 제1 단말기의 하드웨어 정보를 획득한다. 제1 서 버는, 렌더링된 게임 픽처(picture)와 제1 단말기 간의 매칭을 실현하기 위해 제1 단말기의 하드웨어 정보에 기 반하여 FPS 게임을 초기화하고, 그리고 사용자 계정을 FPS 게임에 대응하는 게임 서버에 전송한다. 사용자 계 정을 수신한 후, 게임 서버는 게임 계정에 대응하는 정보를 제1 서버에 전송한다. 제1 서버는 게임 계정에 대 응하는 정보에 기반하여 FPS 게임을 시작한다. FPS 게임을 구동하는 프로세스에서, 사용자는 FPS 내의 피제어 가상 객체가 제1 단말기를 통해 이동하도록 제어할 수 있다. 즉, 제1 단말기는 피제어 가상 객체의 제어 정보 를 제1 서버에 전송한다. 제1 서버는, 제1 비디오 프레임을 획득하기 위해 제어 정보에 기반하여 FPS의 가상 장면을 렌더링한다. 제1 서버는 제1 비디오 프레임을 제2 서버에 전송한다. 사용자가, 게임 시작 이전에, FPS 게임에서 특정 가상 객체를 개인화하는 경우, 예를 들어, FPS 게임에서 차량의 컬러가 빨간색이 되게 설정하면, 제2 서버는 제1 비디오 프레임이 차량을 포함하는지 여부를 결정하기 위해 제1 비디오 프레임에 대해 이미지 인 식을 수행할 수 있다. 제1 비디오 프레임이 차량을 디스플레이한다고 제2 서버가 결정하면, 차량의 제1 파라미 터가 클라이언트 서버로부터 획득된다. 사용자에 의해 차량에 대해 설정된 파라미터에 기반하여 제1 파라미터 가 클라이언트 서버에 의해 결정된다. 제2 서버는, 제2 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하 여 제1 비디오 프레임 내의 차량을 렌더링하고, 그리고 제2 비디오 프레임을 제1 단말기에 전송한다. 사용자는 제1 단말기를 통해 제2 비디오 프레임을 시청할 수 있다. 기술자가 FPS 게임에서 차량 컬러를 파란색이 되게 구성하면, 차량의 컬러는 상기 단계를 거쳐 사용자에 의해 설정된 빨간색으로 조정될 수 있고, 이로써 차량에 대한 개인화된 구성이 달성된다 상기 내용은 제1 비디오 프레임의 프로세싱을 예로 들어 설명했다. FPS 게임을 구동하는 프로세스에서는, 다수 의 연속적인 비디오 프레임이 있다. 다수의 비디오 프레임은 모두, 제1 단말기에 의한 디스플레이를 위해 상기 모드에서 프로세싱된다. 또한, MOBA 게임, TPS 게임, 체스 게임, 및 자동 체스 게임의 경우, 상기 단계 모두는 프로세싱에 사용될 수 있 다. 예를 들어, MOBA 게임에서, 사용자는 제1 단말기를 통해 MOBA 게임에서의 나무를 복숭아 꽃으로 설정할 수 있고, 그런 다음, 제2 서버는, 제1 비디오 프레임으로부터 나무를 인식하고, 나무에 대해 2차 렌더링을 수행하 여 복숭아 꽃을 획득하고 이에 따라 제2 비디오 프레임을 획득하고, 그리고 디스플레이를 위해 제2 비디오 프레 임을 제1 단말기에 전송할 수 있다. 또한, 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 방법은, 상기 FPS 게임, MOBA 게임, 체스 게임, 자동 체스 게임 외에, 다른 타입의 클라우드 게임에 또한 적용될 수 있다. 클라우드 게임의 타입은 본 개시내용의 실시예에서 제한되지 않는다. 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 방법의 구현 환경 및 적용 장면을 소개한 후, 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 방법이 아래에서 설명될 것이다. 도 2는, 본 개시내용의 실시예에 따른, 비디오 프레임 렌더링 방법의 흐름도이다. 도 2를 참조하면, 이 방법은 제2 서버에 의해 수행되는 것으로 가정된다. 이 방법은 다음의 단계(201 내지 203)를 포함한다. 단계에서, 제2 서버는 제1 단말기에 대응하는 제1 비디오 프레임을 획득한다. 제1 비디오 프레임은 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임이고, 그리고 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체이다. 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링하는 조작은, 피제어 가상 객체에 의해 관찰되는 픽처를 타깃 가상 장면에 렌더링하는 단계를 포함한다. 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체이므로, 타깃 가상 장면의 피제어 가상 객체에 의해 관찰되는 픽처는 타깃 가상 장면에서 제 1 단말기의 사용자에 의해 보여지는 픽처를 시뮬레이션할 수 있다. 상이한 제1 단말기는 상이한 피제어 가상 객체를 갖는다. 동일한 타깃 가상 장면에서, 상이한 피제어 가상 객 체에 의해 관찰되는 픽처는 상이해야 하며, 따라서 상이한 제1 단말기에 의해 디스플레이되는 픽처도 또한 상이 해야 한다. 이러한 이유로, 타깃 가상 장면은 제1 단말기의 피제어 가상 객체의 시점으로부터 렌더링되어야 하 며, 획득된 비디오 프레임은 제1 단말기에 대응한다. 일 예에서, 제1 비디오 프레임은 제1 서버에 의해 렌더링된 다음, 제2 서버에 전송된다. 단계에서, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비 디오 프레임을 획득하기 위해 제1 단말기의 제1 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 타깃 가상 객체는, 제1 단말기에서 설정된 가상 객체이고 그리고 제1 단말기에 의해 재-렌더링되어야 할 가상 객체이다. 예를 들어, 타깃 가상 객체는 제1 단말기를 통해 사용자에 의해 선택된 가상 객체, 피제어 가상 객 체의 포지션에 따라 제1 단말기에 의해 선택된 가상 객체, 또는 다른 모드에서 설정된 가상 객체일 수 있다. 제1 파라미터는 제1 단말기의 제1 파라미터이며, 예를 들어, 제1 파라미터는 제1 단말기를 통해 사용자에 의해 결정된 제1 파라미터이거나, 또는 제1 단말기에 의해 디폴트로 설정된 제1 파라미터이다. 제1 파라미터는 제2 비디오 프레임을 획득하기 위해 제1 비디오 프레임 내의 타깃 가상 객체를 재-렌더링하는 데 사용된다. 타깃 가상 객체와 제1 파라미터는 둘 다는 제1 단말기를 통해 구성되고 다른 단말기에 의해 영향을 받지 않기 때문에, 이로써 가상 장면에 대한 개인화된 구성이 달성된다. 가상 장면의 특정 가상 객체의 디스플레이 효과 를 변경하고자 하는 경우, 기술자가 기본 코드 및 파일을 변경하지 않고 제1 단말기를 통해 구성이 직접 수행될 수 있고, 이로써 프로세싱 효율성이 개선된다. 단계에서, 제2 서버는 제2 비디오 프레임을 제1 단말기에 전송하고, 그리고 제1 단말기는 제2 비디오 프레 임을 디스플레이하도록 구성된다. 일 예에서, 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 방법은, 클라우드 게이밍 장면에 적용 되고, 그리고 가상 장면을 렌더링하고, 그리고 비디오 프레임을 렌더링하는 프로세스 둘 다가 클라우드에서 구 현된다. 여기서 클라우드는 제2 서버(이를테면, 장면 관리 서버), 제1 서버(이를테면, 클라우드 서버) 및 다른 관련 서버의 일반 용어이다. 제1 비디오 프레임에 대해 2차 렌더링을 수행한 후, 제2 서버는 획득된 제2 비디 오 프레임을 제1 단말기에 전송한다. 제1 단말기는 백그라운드 프로세싱을 수행하지 않고 제2 비디오 프레임을 직접 디스플레이하며, 이로써 프로세싱 효율성이 개선된다. 본 개시내용의 상기 실시예에서, 방법은 예로서 제2 서버에 의해 수행된다. 다른 실시예에서, 방법은 다른 서 버에 의해 수행될 수 있다. 본 개시내용의 실시예에 의해 제공되는 기술적 솔루션에 따라, 특정 가상 객체의 디스플레이 효과를 변경하고자 하는 경우, 가상 객체에 대해, 제1 파라미터가 제1 단말기에 의해 결정된다. 제2 비디오 프레임을 획득하기 위 해 제1 파라미터에 기반하여 제1 비디오 프레임에 대해 2차 렌더링이 수행된다. 제1 비디오 프레임과 비교하여, 제2 비디오 프레임에 디스플레이되는 가상 객체의 디스플레이 효과는 또한, 가상 객체에 대해 제1 단 말기에 의해 구성된 디스플레이 효과이기도 하다. 상기 기술적 솔루션에 따라, 가상 객체에 대한 2차 렌더링을 수행하는 기능이 클라우드 애플리케이션에서 달성되어, 사용자가 가상 장면의 특정 가상 객체의 디스플레이 효 과를 빠르고 효율적으로 조정할 수 있고, 이로써 클라우드 애플리케이션의 기능 범위가 확장되고 클라우드 애플 리케이션의 개인화가 개선된다. 따라서, 클라우드 애플리케이션이 더 광범위하게 전파된다. 상기 단계(201 단계 내지 203)를 통해, 본 개시내용의 실시예가 간략하게 설명된다. 본 개시내용의 실시예에 의해 제공되는 기술적 솔루션은 일부 예를 결합하여 아래에서 더욱 명확하게 설명될 것이다. 제2 서버에 의해 수행되는 방법을 예로 들어, 도 3을 참조로, 방법이 다음의 단계(301 내지 308)를 포함한다. 단계에서, 제2 서버는 제1 단말기에 대응하는 제1 비디오 프레임을 획득한다. 제1 비디오 프레임은 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임이고, 그리고 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체이다. 실시예에서, 게임 장면에서, 타깃 가상 장면은 클라우드 게이밍의 게임 장면이고, 그리고 피제어 가상 객체의 시점은 피제어 가상 객체의 가상 카메라의 시점이다. FPS 게임에서, 피제어 가상 객체의 가상 카메라는 피제어 가상 객체의 헤드에 위치된다. 제1 단말기를 통해 피제어 가상 객체가 타깃 가상 장면 내에서 이동하도록 사용 자가 제어하는 경우, 가상 카메라도 또한 피제어 가상 객체의 움직임에 따라 움직이며, 가상 카메라에 의해 캡 처된 픽처는 타깃 가상 장면의 피제어 가상 객체에 의해 관찰되는 픽처이다. TPS 게임에서, 피제어 가상 객체 의 가상 카메라는 피제어 가상 객체 위에 위치된다. 제1 단말기를 통해 피제어 가상 객체가 타깃 가상 장면 내 에서 이동하도록 사용자가 제어하는 경우, 가상 카메라도 또한 피제어 가상 객체의 움직임에 따라 움직이며, 가 상 카메라에 의해 캡처된 픽처는 피제어 가상 객체의 위쪽 포지션으로부터 관찰된 픽처이다. 클라우드 게이밍 장면에서, 가상 카메라에 의해 캡처된 픽처는 클라우드 게이밍 서버에 의해 렌더링된다. 게임 동안의 타이밍에 는 연속적인 다수의 픽처가 있으므로, 다수의 픽처는 또한 비디오 프레임으로 지칭된다. 유사하게, 다른 장면 에서, 제1 서버는 픽처를 획득하기 위해 가상 카메라를 통해 타깃 가상 장면을 캡처할 수 있고, 그리고 캡처된 픽처가 또한 비디오 프레임으로 지칭된다. 실시예에서, 제1 서버는 클라우드 서버이다. 하나의 가능한 구현에서, 제1 단말기는 피제어 가상 객체에 대한 제어 정보를 제1 서버에 전송한다. 제어 정보 를 수신한 후, 제1 서버는 제어 정보에 기반하여 타깃 가상 장면의 피제어 가상 객체의 시점을 결정한다. 제1 서버는 제1 비디오 프레임을 획득하기 위해 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링한다. 제1 비디오 프레임은 제1 단말기에 대응하는 비디오 프레임이다. 제1 서버는 제1 비디오 프레임을 제2 서버에 전송한다. 제2 서버는 제1 비디오 프레임을 획득한다. 피제어 가상 객체의 제어 정보는 타깃 장면의 피제어 가상 객체의 포지션, 배향, 및 동작을 변경하는 데 사용된다. 예를 들어, 제어 정보는, 피제어 가상 객체가 타 깃 가상 장면에서 전후, 좌우로 이동하도록 제어하거나, 피제어 가상 객체가 타깃 가상 장면에서 좌측 또는 우 측으로 회전하도록 제어하거나, 또는 피제어 가상 객체가 타깃 가상 장면에서 스쿼트하기(squatting), 포복하기 (creeping), 그리고 가상 소품 사용하기와 같은 동작을 수행하도록 제어할 수 있다. 실질적으로, 제1 서버가 제어 정보에 기반하여 피제어 가상 객체가 타깃 가상 장면에서 이동하거나 동작을 수행하도록 제어하는 경우, 피제어 가상 객체에 바인딩된 가상 카메라도 또한 피제어 가상 객체의 움직임에 따라 움직인다. 피제어 가상 객체에 의해 수행되는 움직임이나 동작은 타깃 가상 장면을 관찰하기 위한 피제어 가상 객체의 시점에서의 변화 를 초래하며, 피제어 가상 객체에 바인딩된 가상 카메라는 이러한 변화를 기록할 수 있다. 실시예에서, 제1 서 버는 장면 관리 서버이다. 이 구현에서, 피제어 가상 객체의 제어 정보는 제1 단말기를 통해 제1 서버에 전송된다. 제1 서버는, 제어 정 보에 기반하여 타깃 가상 장면의 피제어 가상 객체의 시점을 결정하고, 그리고 제1 단말기에 의한 렌더링 없이, 제1 비디오 프레임을 획득하기 위해 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더 링할 수 있고, 이로써 렌더링 효율성이 개선된다. 제2 서버는 제1 비디오 프레임에 대한 후속 프로세싱을 바로 수행한다. 예를 들어, 제1 단말기는 타깃 가상 장면을 디스플레이한다. 피제어 가상 객체는 타깃 가상 장면에 디스플레이 된다. 제1 단말기와 제1 서버 사이에 긴 연결(long connection)이 확립된다. 피제어 가상 객체에 대한 조작에응답하여, 제1 단말기는 이 조작에 대응하는 제어 정보를 제1 서버에 전송한다. 긴 연결은 하나의 연결에서 다 수의 데이터 패킷이 연속적으로 전송될 수 있다는 것을 의미한다. 연결 유지 기간 동안, 어떠한 데이터 패킷도 전송되지 않는 경우, 제1 단말기와 제1 서버는 링크 검출 패킷을 전송해야 한다. 일부 실시예에서, 피제어 가 상 객체에 대한 조작은 클릭 조작 및 드래그 조작을 포함한다. 클릭 조작은, FPS 게임에서의 파이어 컨트롤 (fire control)에 대한 클릭 조작과 같은, 조작 컨트롤에 대한 클릭 조작이다. 드래그 조작은, MOBA 게임에서 의 스킬 컨트롤에 대한 드래그 조작과 같은, 조작 컨트롤, 피제어 가상 객체 등에 대한 드래그 조작이다. 제어 정보를 수신한 후, 제1 서버는 제어 정보에 기반하여 타깃 가상 장면의 피제어 가상 객체의 포지션, 자세, 및 동작을 결정한다. 제1 서버는, 타깃 가상 장면의 피제어 가상 객체의 포지션, 자세, 및 동작에 기반하여 피제 어 가상 객체의 시점을 결정한다. 제1 서버는 제1 단말기에 대응하는 제1 비디오 프레임을 획득하기 위해 피제 어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링한다. 제1 비디오 프레임은 제1 단말기에 의해 전송된 제어 정보에 기반하여 렌더링된 비디오 프레임이다. 예를 들어, 피제어 가상 객체에 대한 사용자에 의한 조작 이 클릭-스쿼트 컨트롤(click-to-squat control)인 경우, 제1 단말기에 의해 제1 서버에 전송되는 제어 정보는 피제어 가상 객체가 스쿼트하도록 제어하는 데 사용된다. 제1 서버는 피제어 가상 객체가 타깃 가상 장면에서 스쿼트하도록 제어하고, 그리고 스쿼트한 후, 피제어 가상 객체의 시점을 결정한다. 타깃 가상 장면은, 제1 비 디오 프레임을 획득하기 위해 스쿼트한 후 피제어 가상 객체의 시점으로부터 렌더링된다. 제1 서버는 제1 비디 오 프레임을 제2 서버에 전송한다. 제2 서버는 제1 비디오 프레임을 획득한다. 단계에서, 제2 서버는, 제1 비디오 프레임의 타입을 결정하기 위해, 제1 비디오 프레임에 대한 이미지 인 식을 수행한다. 하나의 가능한 구현에서, 제2 서버는 타깃 가상 객체의 템플릿 이미지를 사용함으로써 제1 비디오 프레임에서 검출을 수행한다. 제1 비디오 프레임 내의 타깃 가상 객체의 템플릿 이미지와 매칭하는 구역이 있음을 검출하 는 것에 응답하여, 제2 서버는 제1 비디오 프레임의 타입을 제1 타입으로서 결정한다. 제1 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 지시한다. 제1 비디오 프레임 내의 타깃 가상 객체의 템플 릿 이미지와 매칭하는 구역이 없음을 검출하는 것에 응답하여, 제2 서버는 제1 비디오 프레임의 타입을 제2 타 입으로서 결정한다. 제2 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하지 않는다는 것을 지시한 다. 타깃 가상 객체의 식별자는 처음에 클라이언트 서버에 의해 제2 서버에 전송된다. 제2 서버는, 타깃 가상 객체의 식별자에 기반하여 인식이 필요한 타깃 가상 객체를 결정할 수 있다. 예를 들어, 제2 서버는, 타깃 가 상 객체의 식별자에 기반하여 식별자에 대응하여 저장된 템플릿 이미지, 즉 타깃 가상 객체의 템플릿 이미지를 검색한다. 후속하여, 제1 단말기에 대응하는 비디오 프레임이 획득될 때마다, 템플릿 이미지를 사용함으로써 검출이 수행된다. 타깃 가상 객체는 제1 단말기에 의해 설정된 가상 객체이다. 타깃 가상 객체는 타깃 가상 장면의 임의의 가상 객체이다. 예를 들어, 타깃 가상 객체는 타깃 가상 장면의 가상 차량이거나, 타깃 가상 객체는 타깃 가상 장면 의 가상 나무이거나, 타깃 가상 객체는 가상 장면의 가상 하우스이거나, 또는 타깃 가상 객체는 가상 총이다. 타겟 가상 객체의 타입은 본 개시내용의 실시예에서 제한되지 않는다. 이 구현에서, 제2 서버는 템플릿 매칭에 의해 제1 비디오 프레임의 타입을 결정할 수 있는데, 즉, 타깃 가상 객 체가 제1 비디오 프레임에 디스플레이되는지 여부를 결정할 수 있다. 템플릿 매칭 속도가 비교적 빠르기 때문 에, 제1 비디오 프레임의 타입이 템플릿 매칭에 의해 결정될 때 효율성이 비교적 높다. 상기 구현은 아래에서 2개의 예에 의해 설명된다. 예 1, 제2 서버는, 타깃 가상 객체의 템플릿 이미지를 사용함으로써, 타깃 가상 객체의 템플릿 이미지와 제1 비 디오 프레임 내의 다수의 구역 간의 유사성을 획득한다. 다수의 구역 중 타깃 가상 객체의 템플릿 이미지와의 유사성이 타깃 유사성 조건을 만족하는 구역이 있는 경우, 제2 서버는, 구역이 타깃 가상 객체의 템플릿 이미지 와 매칭한다는 것을 결정하고, 그리고 제1 비디오 프레임의 타입을 제1 타입으로서 결정한다. 다수의 구역과 타깃 가상 객체의 템플릿 이미지 사이의 유사성 중 어느 것도 타깃 유사성 조건을 만족하지 않는 경우, 제2 서 버는, 제1 비디오 프레임 내의 타깃 가상 객체의 템플릿 이미지와 매칭하는 구역이 없다는 것을 결정하고, 그리 고 제1 비디오 프레임의 타입을 제2 타입으로서 결정한다. 예를 들어, 제2 서버는, 제1 비디오 프레임 상에서 타깃 가상 객체의 템플릿 이미지를 슬라이딩함으로써, 타깃 가상 객체의 템플릿 이미지와 제1 비디오 프레임의 다수의 구역 간의 유사성을 획득한다. 다수의 구역은, 타깃 가상 객체의 템플릿 이미지가 제1 비디오 프레임 상에서 슬라이딩할 때 커버되는 구역이다. 일부 실시예에서, 제2 서버는, 컬러 값 유사성 또는 그레이 값(gray value) 유사성을 사용함으로써, 타깃 가상 객체의 템플릿 이미지와 다수의 구역 간의 유사성을 결정할 수 있다. 유사성을 결정하기 위한 방식은 본 개시내용의 실시예에 제한되지 않는다. 다수의 구역 중 타깃 가상 객체의 템플릿 이미지와의 유사성이 유사성 임계치 이상인 구역이 있는 경우, 제2 서버는, 구역이 타깃 가상 객체의 템플릿 이미지와 매칭한다는 것을 결정하고, 그리고 제1 비디 오 프레임의 타입을 제1 타입으로서 결정하는데, 즉, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다. 다수의 구역과 타깃 가상 객체의 템플릿 이미지 간의 유사성 각각이 유사성 임계치 미만인 경우, 제2 서버는, 제1 비디오 프레임 내의 타깃 가상 객체의 템플릿 이미지와 매칭하는 구역이 없다는 것을 결정하고, 그리고 제1 비디오 프레임의 타입을 제2 타입으로서 결정하는데, 즉, 제1 비디오 프레임은 타깃 가상 객체를 디스플레이하 지 않는다. 예 2, 제2 서버는, 다양한 크기의 타깃 가상 객체를 갖는 템플릿 이미지를 획득하기 위해 타깃 가상 객체의 템 플릿 이미지에 대해 스케일링 프로세싱을 수행한다. 제2 서버는, 다양한 크기를 갖는 템플릿 이미지에 기반하 여 타깃 가상 객체의 템플릿 이미지와 제1 비디오 프레임 상의 다수의 구역 간의 유사성을 획득한다. 다수의 구역은 상이한 크기를 갖는 구역을 포함한다. 다수의 구역 중 타깃 가상 객체의 템플릿 이미지와의 유사성이 타깃 유사성 조건을 만족하는 구역이 있는 경우, 제2 서버는, 구역이 타깃 가상 객체의 템플릿 이미지와 매칭한 다는 것을 결정하고, 그리고 제1 비디오 프레임의 타입을 제1 타입으로서 결정한다. 다수의 구역과 타깃 가상 객체의 템플릿 이미지 사이의 유사성 중 어느 것도 타깃 유사성 조건을 만족하지 않는 경우, 제2 서버는, 제1 비디오 프레임 내의 타깃 가상 객체의 템플릿 이미지와 매칭하는 구역이 없다는 것을 결정하고, 그리고 제1 비 디오 프레임의 타입을 제2 타입으로서 결정한다. 피제어 가상 객체가 타깃 가상 장면에서 이동하기 때문에, 피제어 가상 객체와 타깃 가상 객체 사이의 거리는 상이한 비디오 프레임마다 상이할 수 있고, 따라서, 타깃 가상 객체의 크기는 상이한 비디오 프레임마다 상이할 수 있다. 타깃 가상 객체의 템플릿 이미지가 템플릿 매칭을 수행하기 위해 다양한 크기를 갖는 템플릿 이미지 로 스케일링되며, 이로써 템플릿 매칭의 정확도가 개선된다. 예를 들어, 제2 서버는, 다양한 크기의 타깃 가상 객체를 갖는 템플릿 이미지를 획득하기 위해 타깃 가상 객체 의 템플릿 이미지에 대해 스케일링 프로세싱을 수행한다. 제2 서버는, 다양한 크기를 갖는 템플릿 이미지와 제 1 비디오 프레임 상의 다수의 구역 간의 유사성을 획득하기 위해, 다양한 크기를 갖는 템플릿 이미지가 제1 비 디오 프레임 상에서 슬라이딩하도록 제어한다. 다수의 구역은, 타깃 가상 객체의 템플릿 이미지가 제1 비디오 프레임 상에서 슬라이딩할 때 커버되는 구역이다. 일부 실시예에서, 제2 서버는, 컬러 값 유사성 또는 그레이 값 유사성을 사용함으로써, 다양한 크기를 갖는 템플릿 이미지와 다수의 구역 간의 유사성을 결정할 수 있다. 유사성을 결정하기 위한 방식은 본 개시내용의 실시예에 제한되지 않는다. 다수의 구역 중 다양한 크기를 갖는 템플릿 이미지 중 임의의 템플릿 이미지와의 유사성이 유사성 임계치 이상인 구역이 있는 경우, 제2 서버는, 구 역이 타깃 가상 객체의 템플릿 이미지와 매칭한다는 것을 결정하고, 그리고 제1 비디오 프레임의 타입을 제1 타 입으로서 결정하는데, 즉, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다. 다수의 구역과 타깃 가상 객체의 템플릿 이미지 간의 유사성 각각이 유사성 임계치 미만인 경우, 제2 서버는, 제1 비디오 프레임 내의 타 깃 가상 객체의 템플릿 이미지와 매칭하는 구역이 없음을 결정하고, 그리고 제1 비디오 프레임의 타입을 제2 타 입으로서 결정하는데, 즉, 제1 비디오 프레임은 타깃 가상 객체를 디스플레이하지 않는다. 하나의 가능한 구현에서, 제2 서버는 제1 비디오 프레임을 이미지 인식 모델에 입력한다. 제2 서버는, 제1 비 디오 프레임의 타입을 출력하기 위해 이미지 인식 모델을 통해 제1 비디오 프레임에 대해 특징 추출 및 분류를 수행한다. 이미지 인식 모델은 샘플 비디오 프레임 세트에 기반하여 트레이닝함으로써 획득된다. 샘플 비디오 프레임 세 트는 포지티브 샘플 비디오 프레임(positive sample video frame) 및 네거티브 샘플 비디오 프레임(negative sample video frame)을 포함한다. 포지티브 샘플 비디오 프레임은 타깃 가상 객체를 디스플레이하는 비디오 프 레임이고, 그리고 네거티브 샘플 비디오 프레임은 타깃 가상 객체를 디스플레이하지 않는 비디오 프레임이다. 샘플 비디오 프레임 세트에 의해 트레이닝된 이미지 인식 모델은, 타깃 가상 객체가 비디오 프레임 내에 디스플 레이되는지 여부를 결정할 수 있다. 일부 실시예에서, 이미지 인식 모델은 제2 서버에 의해 사전에 트레이닝된 다. 게임 동안 이미지 인식 모델을 사용함으로써, 비디오 프레임 타입이 직접 결정될 수 있다. 상기 구현은 아래에서 2개의 예에 의해 설명된다. 예 1, 제2 서버는 제1 비디오 프레임을 이미지 인식 모델에 입력한다. 제2 서버는, 제1 비디오 프레임에 대응 하는 확률을 획득하기 위해 이미지 인식 모델을 통해 제1 비디오 프레임에 대해 특징 추출 및 완전 연결 프로세 싱을 수행한다. 확률은 제1 비디오 프레임이 타깃 가상 객체를 디스플레이할 확률이다. 확률이 확률 임계치이상인 것에 응답하여, 제2 서버는 제1 비디오 프레임의 타입을 제1 타입으로서 결정한다. 제1 타입은, 제1 비 디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 지시한다. 확률이 확률 임계 값 미만인 것에 응답하여, 제2 서버는 제1 비디오 프레임의 타입을 제2 타입으로서 결정한다. 제2 타입은, 제1 비디오 프레임 이 타깃 가상 객체를 디스플레이하지 않는다는 것을 지시한다. 예를 들어, 제2 서버는, 제1 비디오 프레임을 이미지 인식 모델에 입력하고, 그리고 이미지 인식 모델을 통해 제1 비디오 프레임에 대해 컨볼루션 프로세싱을 수행하여, 제1 비디오 프레임의 특징 맵을 획득한다. 제2 서버 는, 제1 비디오 프레임에 대응하는 확률 분포를 획득하기 위해 이미지 인식 모델을 통해 제1 비디오 프레임의 특징 맵에 대해 완전 연결 프로세싱 및 정규화 프로세싱을 수행한다. 정규화 프로세싱은, S자 형상 성장 곡선 (Sigmoid) 또는 소프트맥스(Softmax) 함수를 사용함으로써 수행될 수 있다. 채택되는 함수는 본 개시내용의 실 시예에서 제한되지 않는다. 확률 분포에서 제1 타입에 대응하는 확률이 확률 임계치 이상인 것에 응답하여, 제 2 서버는 제1 비디오 프레임의 타입을 제1 타입으로서 결정하는데, 즉, 제1 비디오 프레임은 타깃 가상 객체를 디스플레이한다. 확률 분포에서 제2 타입에 대응하는 확률이 확률 임계치 이상인 것에 응답하여, 제2 서버는 제1 비디오 프레임의 타입을 제2 타입으로서 결정하는데, 즉, 제1 비디오 프레임은 타깃 가상 객체를 디스플레 이하지 않는다. 예 2, 제2 서버는, 제1 비디오 프레임을 다수의 이미지 블록으로 분할하고, 그리고 다수의 이미지 블록을 이미 지 인식 모델에 입력한다. 제2 서버는, 다수의 이미지 블록에 각각 대응하는 다수의 확률을 획득하기 위해 이 미지 인식 모델을 통해 다수의 이미지 블록에 대해 특징 추출 및 완전 연결 프로세싱을 수행한다. 확률은 이미 지 블록이 타깃 가상 객체를 포함할 확률이다. 다수의 확률 중 임의의 확률이 확률 임계치 이상인 것에 응답하 여, 제2 서버는 제1 비디오 프레임의 타입을 제1 타입으로서 결정한다. 제1 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 지시한다. 복수의 확률 각각이 확률 임계치 미만인 것에 응답하여, 제2 서 버는 제1 비디오 프레임의 타입을 제2 타입으로서 결정한다. 제2 타입은, 제1 비디오 프레임이 타깃 가상 객체 를 디스플레이하지 않는다는 것을 지시한다. 예를 들어, 제2 서버는, 제1 비디오 프레임을 동일한 크기를 갖는 다수의 이미지 블록으로 분할하고, 다수의 이 미지 블록을 이미지 인식 모델에 입력하고, 그리고 이미지 인식 모델을 통해 다수의 이미지 블록에 대해 컨볼루 션 프로세싱을 수행하여, 다수의 이미지 블록의 특징 맵을 획득한다. 제2 서버는, 다수의 이미지 블록에 대응 하는 다수의 확률을 획득하기 위해 이미지 인식 모델을 통해 다수의 이미지 블록의 특징 맵에 대해 전체 연결 프로세싱 및 정규화 프로세싱을 수행한다. 확률은 대응하는 이미지 블록이 타깃 가상 객체를 디스플레이할 확 률이다. 정규화 프로세싱은, S자 형상 성장 곡선(Sigmoid) 또는 소프트맥스 함수를 사용함으로써 수행될 수 있 다. 채택되는 함수는 본 개시내용의 실시예에서 제한되지 않는다. 확률 중 임의의 확률이 확률 임계치 이상인 것에 응답하여, 제2 서버는 제1 비디오 프레임의 타입을 제1 타입으로서 결정하는데, 즉, 제1 비디오 프레임은 타깃 가상 객체를 디스플레이한다. 다수의 확률 각각이 확률 임계치 미만인 것에 응답하여, 제2 서버는 제1 비 디오 프레임의 타입을 제2 타입으로서 결정하는데, 즉, 제1 비디오 프레임은 타깃 가상 객체를 디스플레이하지 않는다. 단계 이후, 제2 서버는, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 타입이 지시하는 경우, 다음 단계를 수행하고; 그리고 제2 서버는, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하지 않는다는 것을 타입이 지시하는 경우, 다음 단계를 수행한다. 단계에서, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이한다는 것을 타입 이 지시하는 경우, 제2 비디오 프레임을 획득하기 위해 제1 단말기의 제1 파라미터에 기반하여 제1 비디오 프레 임 내의 타깃 가상 객체를 렌더링한다. 가능한 일 구현에서, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 서버는 제 1 렌더링 파라미터를 획득한다. 제1 렌더링 파라미터는 제1 파라미터 중 제1 각도 및 제1 거리에 대응하는 렌 더링 파라미터이다. 제1 각도는 피제어 가상 객체와 타깃 가상 객체 사이의 각도를 지시하고, 그리고 제1 거리 는 피제어 가상 객체와 타깃 가상 객체 사이의 거리를 지시한다. 제2 서버는, 제2 비디오 프레임을 획득하기 위해 제1 렌더링 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 이 구현에서, 제2 서버는, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 타깃 가상 객체의 디스 플레이 효과를 변경하기 위해, 제1 렌더링 파라미터에 기반하여 타깃 가상 객체에 대한 2차 렌더링을 수행할 수 있다. 게임 동안, 피제어 가상 객체와 타깃 가상 객체 사이의 거리 및 각도는 언제든지 변경될 수 있다. 상이 한 거리 및 각도는 상이한 렌더링 파라미터에 대응한다. 제2 서버는, 제1 각도 및 제1 거리에 기반하여 제1 파라미터로부터 제1 렌더링 파라미터를 직접 획득할 수 있고, 그리고 제1 각도 및 제1 거리에 기반하여 2차 조작 을 수행함으로써 제1 렌더링 파라미터를 획득할 필요가 없고, 이로써 프로세싱 효율성이 개선된다. 예를 들어, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 피제어 가 상 객체와 타깃 가상 객체 사이의 제1 각도 및 제1 거리를 제1 서버로부터 획득한다. 제2 서버는 제1 각도, 제 1 거리, 및 타깃 가상 객체의 식별자를 클라이언트 서버에 전송한다. 제1 각도, 제1 거리, 및 타깃 가상 객체 의 식별자를 수신한 후, 클라이언트 서버는 타깃 가상 객체의 식별자에 기반하여 제1 파라미터를 결정한다. 클 라이언트 서버는, 제1 렌더링 파라미터를 획득하기 위해 제1 각도 및 제1 거리에 기반하여 제1 파라미터에 대한 검색을 수행하고, 그리고 제1 렌더링 파라미터를 제2 서버에 전송한다. 제2 서버는 제1 렌더링 파라미터에 기 반하여 제1 비디오 프레임 내의 타깃 가상 객체의 다수의 타깃 픽셀 포인트의 타깃 픽셀 값을 결정한다. 제2 서버는, 제2 비디오 프레임을 획득하기 위해 타깃 픽셀 값을 사용함으로써 제1 비디오 프레임 내의 다수의 타깃 픽셀 포인트의 픽셀 값을 업데이트한다. 타깃 픽셀 포인트는 제1 비디오 프레임 내의 타깃 가상 객체의 픽셀 포인트를 지칭한다. 타깃 픽셀 포인트는 제1 비디오 프레임에 픽셀 값을 갖는다. 타깃 픽셀 값은 타깃 픽셀 포인트를 업데이트함으로써 획득되어야 하 는 픽셀 값을 지칭한다. 따라서, 타깃 픽셀 값을 사용함으로써 타깃 픽셀 포인트의 오리지널 픽셀 값이 업데이 트된다. 피제어 가상 객체와 타깃 가상 객체 사이의 각도는 피제어 가상 객체의 배향과 타깃 가상 객체의 배향 사이의 각도일 수 있다. 예를 들어, 피제어 가상 객체가 게임 장면에서 가상 총을 들고 있는 게임 캐릭터인 경우, 피 제어 가상 객체의 배향은 가상 총의 조준 방향이다. 타깃 가상 객체가 가상 차량인 경우, 타깃 가상 객체의 배 향은 가상 차량 바로 앞이다. 피제어 가상 객체와 타깃 가상 객체 사이의 거리는, 피제어 가상 객체의 중심 포 인트와 타깃 가상 객체의 중심 포인트 사이의 거리이다. 하나의 가능한 구현에서, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우 제1 파라미터로부터, 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 획득한다. 제2 서버는, 제2 비디오 프 레임을 획득하기 위해 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 사용함으로써, 각각, 제1 비디오 프레임 내의 타깃 가상 객체 및 피제어 가상 객체를 렌더링한다. 이 구현에서, 제1 파라미터는 제1 단말기의 파라미터이기 때문에, 제1 파라미터는 타깃 가상 객체를 렌더링하기 위한 제1 렌더링 파라미터와 피제어 가상 객체를 렌더링하기 위한 제2 렌더링 파라미터 둘 다를 보유한다. 이 는, 사용자가 가상 장면의 타깃 가상 객체에 대해 2차 렌더링을 수행할 수 있을 뿐만 아니라, 제1 단말기에 의 해 제어되는 피제어 가상 객체에 대해 2차 렌더링을 수행할 수 있고, 이로써 개인화 및 플레이 능력 (playability)이 개선된다는 것을 지시한다. 예를 들어, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 피제어 가 상 객체와 타깃 가상 객체 사이의 제1 각도 및 제1 거리를 제1 서버로부터 획득한다. 제2 서버는 제1 각도, 제 1 거리, 및 타깃 가상 객체의 식별자를 클라이언트 서버에 전송한다. 제1 각도, 제1 거리, 및 타깃 가상 객체 의 식별자를 수신한 후, 클라이언트 서버는 타깃 가상 객체의 식별자에 기반하여 제1 파라미터를 결정한다. 클 라이언트 서버는, 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 획득하기 위해 제1 각도 및 제1 거리에 기반 하여 제1 파라미터에 대해 검색하고, 그리고 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 제2 서버에 전송한 다. 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 수신한 후, 제2 서버는, 제1 렌더링 파라미터를 사용함으 로써 타깃 가상 객체를 렌더링하고, 그리고 제1 비디오 프레임에서 제2 렌더링 파라미터를 사용함으로써 피제어 가상 객체를 렌더링하여, 제2 비디오 프레임을 획득한다. 예를 들어, 상기 구현에 의해, 타깃 가상 객체의 디스플레이 효과가 개인화될 수 있고, 그리고 사용자에 의해 제어되는 피제어 가상 객체의 디스플레이 효과가 타깃 가상 객체를 디스플레이할 때 개인화될 수 있다. 타깃 가상 객체가 가상 차량인 것을 예로 들면, 사용자가 가상 차량의 컬러를 빨간색인 것으로 설정하길 원하고, 그 리고 또한, 타깃 가상 장면에 가상 차량이 등장할 때 제1 단말기에 의해 제어되는 게임 캐릭터(가상 객체)의 의 복 컬러를 파란색으로 디스플레이하길 원할 경우, 제1 렌더링 파라미터 및 제2 렌더링 파라미터는 상기 구현에 의해 제1 파라미터에 구성될 수 있다. 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제2 서버 는, 제1 렌더링 파라미터를 사용함으로써 타깃 가상 객체에 대한 2차 렌더링을 수행하면서, 제1 렌더링 파라미 터를 사용함으로써 피제어 가상 객체에 대한 2차 렌더링을 수행할 수 있고, 이로써 개인화가 개선된다. 하나의 가능한 구현에서, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우, 타깃 가상 장면에서 피제어 가상 객체의 포지션을 결정한다. 제2 서버는, 피제어 가상 객체가 타깃 가상 장면의 타깃 서브-장면에 위치되는 경우, 제2 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 제1 비 디오 프레임 내의 타깃 가상 객체를 렌더링한다. 제2 서버는, 피제어 가상 객체가 타깃 가상 장면의 타깃 서브 -장면에 위치되지 않는 경우, 제1 비디오 프레임을 제2 비디오 프레임으로서 결정한다. 타깃 가상 장면은 다수의 서브-장면을 포함하고, 그리고 다수의 서브-장면은 타깃 가상 장면을 구성한다. 예를 들어, 다수의 서브-장면은 가상 소셜 장면(virtual social scene) 및 가상 전투 장면을 포함한다. 가상 소셜 장면은 가상 낚시 장면, 가상 채팅 룸, 가상 댄스 룸, 가상 체스 및 카드 룸을 포함한다. 가상 소셜 장면에서, 사용자는 가상 객체를 제어함으로써 다른 사용자와 소통한다. 가상 전투 장면은, 사용자가 가상 객체를 제어하 여 전투를 벌이는 장면이다. 타깃 서브-장면은, 제1 단말기에 의해 결정되고, 그리고 가상 소셜 장면 또는 가 상 전투 장면일 수 있다. 서브-장면의 타입은 본 개시내용의 실시예에서 제한되지 않는다. 상기 구현에서, 사용자는 제1 단말기를 통해 타깃 가상 객체를 렌더링하기 위한 제1 파라미터와 타깃 서브-장면 둘 다를 결정할 수 있고, 이로써 개인화 정도가 크게 개선되고 사용자 점도(user viscosity)가 개선된다. 예를 들어, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제1 서버로 부터 타깃 가상 장면에서 피제어 가상 객체의 포지션을 획득한다. 즉, 제2 서버는 포지션 획득 요청을 제1 서 버에 전송한다. 포지션 획득 요청은, 제1 비디오 프레임의 타임 스탬프 및 피제어 가상 객체의 식별자를 보유 한다. 포지션 획득 요청을 획득한 후, 제1 서버는, 포지션 획득 요청으로부터 제1 비디오 프레임의 타임 스탬 프 및 피제어 가상 객체의 식별자를 획득하고, 그리고 제1 비디오 프레임의 타임 스탬프 및 피제어 가상 객체의 식별자에 기반하여 검색을 수행하여, 제1 비디오 프레임의 타임 스탬프에 의해 지시되는 시점에 타깃 가상 장면 에서의 피제어 가상 객체의 포지션을 획득한다. 제1 서버는 타깃 가상 장면에서의 피제어 가상 객체의 포지션 을 제2 서버에 전송한다. 포지션은, 피제어 가상 객체가 타깃 가상 장면에 위치되는 서브-장면을 지시하는 데 사용된다. 제2 서버는, 포지션 획득 요청을 제1 서버에 전송하면서 파라미터 획득 요청을 클라이언트 서버에 전송한다. 파라미터 획득 요청은 타깃 가상 객체의 식별자를 보유한다. 파라미터 획득 요청을 수신한 후, 클 라이언트 서버는 파라미터 획득 요청으로부터 타깃 가상 객체의 식별자를 획득한다. 클라이언트 서버는, 타깃 가상 객체에 대응하는 제1 파라미터 및 타깃 서브-장면의 식별자를 획득하기 위해 타깃 가상 객체의 식별자에 기반하여 검색을 수행하고, 그리고 제1 파라미터 및 타깃 서브-장면의 식별자를 제2 서버에 전송한다. 제2 서 버는, 제1 서버에 의해 전송된 포지션, 클라이언트 서버에 의해 전송된 타깃 서브-장면의 식별자 및 제1 파라미 터를 획득한다. 제2 서버는, 포지션에 의해 지시되는 서브-장면이 타깃 서브-장면인 경우, 제2 비디오 프레임 을 획득하기 위해 제1 파라미터를 사용함으로써 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 제2 서 버는, 제1 비디오 프레임을 렌더링하지 않고, 그리고 포지션에 의해 지시되는 서브-장면이 타깃 서브-장면이 아 닌 경우, 제1 비디오 프레임을 제2 비디오 프레임으로서 직접 결정하며, 즉, 제2 서버는 제1 비디오 프레임을 제1 단말기로 직접 전송할 수 있고, 그리고 제1 단말기는 제1 비디오 프레임을 디스플레이한다. 예를 들어, 타깃 서브-장면은 가상 낚시 장면이고, 타깃 가상 객체는 가상 차량이다. 제1 비디오 프레임이 가 상 차량을 표시하고 그리고 피제어 가상 객체가 가상 낚시 장면에 위치된다고 결정되면, 제2 서버는, 가상 차량 의 디스플레이 효과를 변경하기 위해, 제1 파라미터를 사용함으로써 가상 차량에 대한 2차 렌더링을 수행할 수 있다. 제1 비디오 프레임에 가상 차량이 표시되어 있으나 피제어 가상 객체가 가상 낚시 장면에 위치하지 않는 것으로 판단되면, 제2 서버는, 제1 렌더링 파라미터를 사용함으로써, 제1 비디오 프레임에 대한 2차 렌더링을 수행하지 않고 제1 비디오 프레임을 제2 비디오 프레임으로서 직접 결정한다. 단계에서, 제1 비디오 프레임의 타입을 판단하는 것 외에, 제2 서버는, 제1 비디오 프레임의 타입이 제1 타입인 경우, 제1 비디오 프레임 내의 타깃 가상 객체의 포지션을 결정할 수 있다. 제2 서버가 템플릿 매칭 방 법에 의해 제1 비디오 프레임의 타입을 결정하는 경우, 장면 서버는 제1 비디오 프레임 내의 타깃 가상 객체의 템플릿 이미지와 매칭하는 구역을 제1 비디오 프레임 내의 타깃 가상 객체의 포지션으로서 결정할 수 있다. 제 2 서버가 이미지 인식 모델을 사용함으로써 제1 비디오 프레임의 타입을 결정하는 경우, 이미지 인식 모델은 제 1 비디오 프레임에서 검출 박스를 출력할 수 있다. 검출 박스는, 타깃 가상 객체가 제1 비디오 프레임에서 위 치되는 포지션을 지시한다. 제1 비디오 프레임에서 타깃 가상 객체의 포지션을 결정한 후, 제2 서버는, 제2 비 디오 프레임을 획득하기 위해 제1 렌더링 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체의 포지 션에 대해 2차 렌더링을 수행할 수 있다. 예를 들어, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 상대적 포 지션 획득 요청을 제1 서버에 전송한다. 상대적 포지션 위치 획득 요청은 피제어 가상 객체와 타깃 가상 객체사이의 거리를 획득하는 데 사용된다. 상대적 포지션 획득 요청은 피제어 가상 객체의 식별자 및 타깃 가상 객 체의 식별자를 보유한다. 상대적 포지션 획득 요청을 수신한 후, 제1 서버는, 상대적 포지션 획득 요청으로부 터 피제어 가상 객체의 식별자 및 타깃 가상 객체의 식별자를 획득하고, 그리고 피제어 가상 객체의 식별자 및 타깃 가상 객체의 식별자에 기반하여 피제어 가상 객체와 타깃 가상 객체 사이의 제1 각도 및 제1 거리를 결정 한다. 제1 서버는 피제어 가상 객체와 타깃 가상 객체 사이의 제1 각도 및 제1 거리를 제2 서버에 전송한다. 피제어 가상 객체와 타깃 가상 객체 사이의 제1 각도 및 제1 거리를 수신한 후, 제2 서버는 렌더링 파라미터 획 득 요청을 클라이언트 서버에 전송한다. 렌더링 파라미터 획득 요청은 제1 각도, 제1 거리, 및 타깃 가상 객체 의 식별자를 보유한다. 렌더링 파라미터 획득 요청을 수신한 후, 클라이언트 서버는, 렌더링 파라미터 획득 요 청으로부터, 제1 각도, 제1 거리, 및 타깃 가상 객체의 식별자를 획득하고, 그리고 타깃 가상 객체의 식별자에 기반하여 제1 파라미터를 결정한다. 클라이언트 서버는, 제1 렌더링 파라미터를 획득하기 위해 제1 각도 및 제 1 거리에 기반하여 제1 파라미터를 검색하고, 그리고 제1 렌더링 파라미터를 제2 서버에 전송한다. 제2 서버는 제1 렌더링 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체의 다수의 타깃 픽셀 포인트의 타깃 픽 셀 값을 결정한다. 제2 서버는, 제2 비디오 프레임을 획득하기 위해 타깃 픽셀 값을 사용함으로써 제1 비디오 프레임 내의 다수의 타깃 픽셀 포인트의 픽셀 값을 업데이트하는데, 즉, 다수의 타깃 픽셀 포인트의 픽셀 값을 타깃 픽셀 값으로 대체한다. 일부 실시예에서, 타깃 픽셀 값은 텍스처 데이터로 또한 지칭된다. 도 4를 참조하면, 제1 서버는, 제1 비디오 프레임을 획득하기 위해 타깃 가상 장면 내의 피제어 가상 객체 의 시점으로부터 타깃 가상 장면을 렌더링한다. 제1 비디오 프레임은 가상 차량을 포함한다. 가상 차량은 또한 타깃 가상 객체이다. 제2 서버는, 제2 비디오 프레임을 획득하기 위해 제1 렌더링 파라 미터를 사용함으로써 가상 차량에 대한 2차 렌더링을 수행한다. 제2 비디오 프레임 내의 가상 차량 이 제1 비디오 프레임 내의 것과 상이한 디스플레이 효과를 갖는 것을 볼 수 있다. 일부 실시예에서, 제1 서버에는 안드로이드 컨테이너가 있다. 렌더링은 안드로이드 컨테이너 내부에서 수행된 다. 이의 원리는 GPU(graphics processing unit)가 안드로이드 컨테이너 내부에 직접 액세스될 수 있다는 것이다. GPU는 높은 동시적 컴퓨팅 능력(high concurrent computing power)을 갖고, 그리고 안드로이드 컨테이너 내에서 직접 렌더링을 완료할 수 있다. 렌더링 성능이 개선될 수 있고, 그리고 과도한 렌더링으로 인해 유발되 는 지연이 크게 감소된다. 하나의 안드로이드 컨테이너는, 완벽한 호환성을 또한 가지며 게임의 렌더링을 실현 할 수 있는 하나의 완벽한 안드로이드 시스템이다. 게임이 시작되면, 제1 서버는 렌더링-완료 명령(rendering- completed instruction)을 클라이언트 서버에 전송할 수 있다. 클라이언트 서버는 현재 사용자 계정의 게임 지 속기간 정보를 실시간으로 기록할 수 있다. 지속기간이 불충분하면, 클라이언트 서버는 시그널링 등을 통해 프 로세싱하도록 클라이언트에게 지시할 수 있다(예를 들어, 지속기간이 불충분하면, 박스가 팝업되어 지속기간이 충분하지 않다는 것을 프롬프트하고; 클라우드 게임이 비정상적인 경우, 클라이언트는 박스를 팝업하여 사용자 에게 비정상에 대해 프롬프트한다). 클라이언트 서버에 의해 타깃 가상 객체의 제1 파라미터를 생성하기 위한 방법이 아래에서 설명된다. 하나의 가능한 구현에서, 제1 단말기는 타깃 가상 객체의 구성 인터페이스(configuration interface)를 디스플 레이한다. 구성 인터페이스는 타깃 가상 객체의 구성 정보를 획득하는 데 사용된다. 구성 인터페이스의 조작 에 응답하여 타깃 가상 객체의 구성 정보가 클라이언트 서버에 전송된다. 클라이언트 서버는, 타깃 가상 객체 의 구성 정보를 수신하고, 타깃 가상 객체의 구성 정보에 기반하여 타깃 가상 객체의 3-차원 모델을 생성하고, 그리고 3-차원 모델의 제1 파라미터를 획득한다. 일부 실시예에서, 클라이언트 서버는, 제1 단말기에 의해 로 그인된 사용자 계정(사용자 ID), 타깃 가상 장면의 식별자(게임 ID), 타깃 가상 객체의 식별자(객체 ID), 및 제 1 파라미터를 바인딩하여 저장할 수 있어, 제1 파라미터가 후속 호출 프로세스에서 식별자에 기반하여 결정될 수 있고, 이로써 처리 효율성이 개선된다. 예를 들어, 제1 단말기는 타깃 클라우드 게임의 구성 인터페이스를 디스플레이한다. 구성 인터페이스는 타깃 클라우드 게임에 다수의 가상 객체를 디스플레이한다. 타깃 클라우드 게임은 사용자에 의해 선택된 클라우드 게임이다. 타깃 클라우드 게임의 게임 장면도 또한 타깃 가상 장면이다. 복수의 가상 객체 중의 타깃 가상 객 체가 선택되는 것에 응답하여, 제1 단말기는 타깃 가상 객체의 구성 인터페이스를 디스플레이한다. 구성 인터 페이스는 다수의 구성 옵션을 디스플레이한다. 제1 단말기는, 다수의 구성 옵션 중 선택된 옵션에 기반하여 타 깃 가상 객체의 구성 정보를 생성하고, 그리고 타깃 가상 객체의 구성 정보를 클라이언트 서버에 전송한다. 타 깃 가상 객체의 구성 정보를 수신한 후, 클라이언트 서버는 타깃 가상 객체의 3-차원 모델을 획득하기 위해 타 깃 가상 객체의 구성 정보에 기반하여 타깃 가상 객체의 초기 3-차원 모델을 렌더링한다. 클라이언트 서버는 가상 카메라의 렌더링 파라미터 및 타깃 가상 객체의 3-차원 모델을 상이한 각도 및 상이한 거리에서 획득한다.상이한 각도 및 상이한 거리에서의 렌더링 파라미터는 3-차원 모델의 제1 파라미터를 구성한다. 예를 들어, 제1 단말기는, 클라우드 게임 클라이언트를 시작하고, 그리고 클라우드 게임 클라이언트의 구동 인 터페이스를 디스플레이한다. 구동 중인 인터페이스는 선택될 다수의 클라우드 게임을 디스플레이한다. 복수의 클라우드 게임 중의 타깃 클라우드 게임이 선택되는 것에 응답하여, 제1 단말기는 타깃 클라우드 게임의 구성 인터페이스를 디스플레이한다. 구성 인터페이스는 타깃 클라우드 게임에서 개인화 프로세싱으로 처리될 수 있 는 다수의 가상 객체를 디스플레이하고, 예를 들어, 다수의 가상 객체는 가상 차량, 가상 나무, 또는 가상 하우 스를 포함한다. 타깃 가상 객체가 가상 차량이라고 가정된다. 복수의 가상 객체 중의 타깃 가상 객체가 선택 되는 것에 응답하여, 도 5에 도시된 바와 같이, 제1 단말기는 가상 차량의 구성 인터페이스를 디스플레이 한다. 구성 인터페이스는 다수의 제1-레벨 구성 옵션을 디스플레이한다. 제1-레벨 구성 옵션은 가 상 차량의 타입을 선택하는 데 사용된다. 일부 실시예에서, 제1 단말기는 차량의 브랜드를 사용함으로써 가상 차량의 타입을 표현한다 다수의 제1-레벨 구성 옵션 중 임의의 하나가 선택되는 것에 응답하여, 제1 단말기는 제1-레벨 구성 옵션에 대응하는 다수의 제2-레벨 구성 옵션을 디스플레이한다. 제2-레벨 구성 옵션은 가 상 차량의 스타일을 선택하는 데 사용된다. 일부 실시예에서, 제1 단말기는 차량의 모델을 사용함으로써 가상 차량의 스타일을 표현한다. 다수의 2차 구성 옵션 중 임의의 하나가 선택되는 것에 응답하여, 제1 단말기는 제 2-레벨 구성 옵션에 대응하는 다수의 제3-레벨 구성 옵션을 디스플레이한다. 제3-레벨 구성 옵션은, 빨간 색, 검정색, 파란색과 같은, 가상 차량의 컬러를 선택하는 데 사용된다. 일부 실시예에서, 다수의 3-레벨 구성 옵션 중 임의의 하나가 선택되는 것에 응답하여, 제1 단말기는 다수의 4-레벨 구성 옵션을 디스플레이한다. 4-레벨 구성 옵션은 타깃 가상 객체의 구성 정보의 적용 범위를 선택하는 데 사용된다. 적용 범위는 \"자신에게만 보임\", \"모두에게 보임\", \"영구적 사용\" 및 \"일회 사용\"을 포함한다. \"자신에게만 보임\"은, 게임 동안 제1 단말기에 대응하는 비디오 프레임에 대해서만 2차 렌더링을 수행하고 다른 단말기에 대 응하는 비디오 프레임에 대해서는 2차 렌더링을 수행하지 않도록 제2 서버에게 명령하는 데 사용된다. \"모두에 게 보임\"은, 게임 동안 제2 서버가 모든 단말기에 대응하는 비디오 프레임에 대해 2차 렌더링을 수행한다는 것 을 지시하는 데 사용된다. 예를 들어, 타깃 가상 장면의 가상 차량은 기본적으로 타입 A-스타일 B-빨간색으로 디스플레이된다. 제1 단말기의 사용자는 가상 차량의 구성 인터페이스를 통해 가상 차량을 타입 C-스타일 D-흰 색으로 설정한다. 제1 단말기의 사용자가 \"자신에게만 보임\"을 선택하면, 가상 차량은 게임 동안 제1 단말기에 의해 디스플레이되는 타깃 가상 장면에서 타입 C-스타일 D-흰색으로 디스플레이된다. 타깃 가상 장면을 디스플 레이하는 다른 단말기의 경우, 가상 차량은 여전히 타입 A-스타일 B-빨간색으로 디스플레이된다. 물론, 제1 단 말기의 사용자가 \"모두에게 보임\"을 선택하면, 타깃 가상 장면을 디스플레이하는 모든 단말기는 게임 동안 가상 차량을 타입 C-스타일 D-흰색으로 디스플레이한다. \"영구적 사용\" 옵션의 경우, 제2 서버는 현시점에 결정되는 구성 정보에 따라 렌더링 파라미터를 매번 결정한다. \"일회 사용\" 옵션의 경우, 제2 서버는 현 게임 프로세스 에서 현재 결정되는 구성 정보에 따라 렌더링 파라미터를 한 번만 결정한다. 제1 단말기는, 상기 제1-레벨 구 성 옵션, 제2-레벨 구성 옵션, 제3-레벨 구성 옵션, 및 제4-레벨 구성 옵션에 기반하여 타깃 가상 객체의 설정 파라미터를 결정하고, 그리고 설정 파라미터를 클라이언트 서버에 전송한다. 클라이언트 서버는 타깃 가상 객 체의 설정 파라미터에 기반하여 개방형 그래픽 라이브러리(OpenGL)에 의해 타깃 가상 객체의 3-차원 모델을 생 성한다. 클라이언트 서버는 가상 카메라의 렌더링 파라미터 및 타깃 가상 객체의 3-차원 모델을 상이한 각도 및 상이한 거리에서 획득한다. 상이한 각도 및 상이한 거리에서의 렌더링 파라미터는 3-차원 모델의 제1 파라 미터를 구성한다. 일부 실시예에서, 타깃 가상 장면이 가상 차량을 포함하는 것을 예로 들면, 기술자가 클라이언트 서버를 통해 차량의 기본 정보(CarType, CarStyle, CarColor 등)에 기반하여 가상 차량의 다수의 3-차원 모델을 사전에 생성 할 수 있어, 대응하는 3-차원 모델이 게임 동안 직접 호출될 수 있고, 이로써 프로세싱 효율성이 개선된다. 실시예에서, 제2 비디오 프레임을 획득한 후, 제2 서버는 다음의 단계를 수행한다. 하나의 가능한 구현에서, 제2 서버는 타깃 가상 객체에 대응하는 제2 애니메이션 및 제2 오디오를 획득한다. 제2 서버는 제7 비디오 프레임을 획득하기 위해 제2 비디오 프레임 내의 타깃 가상 객체에 대응하는 제2 애니메 이션을 추가한다. 제2 서버는 제7 비디오 프레임 및 제2 오디오를 제1 단말기에 전송한다. 제1 단말기는, 제7 비디오 프레임을 디스플레이하면서 제2 오디오를 플레이한다. 제2 비디오 프레임에 제2 애니메이션이 추가되는 포지션은, 사용자 또는 기술자에 의해 결정된다. 예를 들어, 타깃 가상 객체에 인접한 포지션에, 이를테면, 타 깃 가상 객체의 위 또는 옆 포지션에 제2 애니메이션이 추가될 수 있다. 포지션은 본 개시내용의 실시예에서 제한되지 않는다. 이 구현에서, 제2 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 제1 비디오 프레임에 대해 2차 렌더 링을 수행한 후, 제2 서버는, 제7 비디오 프레임을 획득하기 위해 제2 비디오 프레임에 대해 추가의 렌더링을 수행할 수 있는데, 즉, 타깃 가상 객체에 대응하는 제2 애니메이션을 제2 비디오 프레임에 추가할 수 있다. 추 가로, 타깃 가상 객체에 대응하는 제2 오디오가 또한 획득된다. 제7 비디오 프레임 및 제2 오디오가 제1 단말 기에 동시에 전송된 후, 제1 단말기는, 제7 비디오 프레임을 디스플레이하면서 제2 오디오를 플레이할 수 있다. 제1 파라미터, 제2 애니메이션, 및 제2 오디오가 모두 제1 단말기를 통해 사용자에 의해 결정되기 때문에, 동일 한 제1 비디오 프레임은 상이한 설정을 통해 제2 서버에 의해 상이한 제7 비디오 프레임으로 렌더링될 수 있고, 그리고 상이한 제7 비디오 프레임에 대해 상이한 제2 오디오가 구성되고, 이로써 개인화가 개선된다. 예를 들어, 제2 서버는 클라이언트 서버로부터 타깃 가상 객체에 대응하는 제2 애니메이션 및 제2 오디오를 획 득한다. 제2 애니메이션과 제2 오디오 둘 다는 제1 단말기에 의해 결정된다. 즉, 제2 서버는 제1 애니메이션 획득 요청을 클라이언트 서버에 전송한다. 제1 애니메이션 획득 요청은 타깃 가상 객체의 식별자를 보유한다. 제1 애니메이션 획득 요청을 수신한 후, 클라이언트 서버는, 제1 애니메이션 획득 요청으로부터 타깃 가상 객체 의 식별자를 획득하고, 타깃 가상 객체에 대응하는 제2 애니메이션 및 제2 오디오를 획득하기 위해, 타깃 가상 객체의 식별자에 기반하여 검색을 수행하고, 그리고 제2 애니메이션 및 제2 오디오를 제2 서버에 전송한다. 제 2 애니메이션 및 제2 오디오를 수신한 후, 제2 서버는 제2 비디오 프레임에 제2 애니메이션을 추가하고, 예를 들어, 제7 비디오 프레임을 획득하기 위해 제2 비디오 프레임에 제2 애니메이션의 제1 프레임을 추가한다. 제2 서버는 제7 비디오 프레임 및 제2 오디오를 제1 단말기에 전송한다. 제1 단말기는, 제7 비디오 프레임 및 제2 오디오를 수신하고, 그리고 제7 비디오 프레임을 디스플레이하면서 제2 오디오를 플레이한다. 사용자의 시점으로부터, 타깃 가상 객체가 가상 차량인 경우, 제2 애니메이션은 엄지 손가락이 점차적으로 나타 나는 것이며, 제1 파라미터는 가상 차량의 컬러를 빨간색으로 조정하게 명령한다. 그런 다음, 제1단말기에 의 해 디스플레이되는 제7 비디오 프레임에서는, 가상 차량의 컬러가 빨간색이고, 엄지 손가락은 가상 차량 옆에 디스플레이되고, 그리고 제2 오디오가 동시에 플레이된다. 단계에서, 제2 서버는, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하지 않는다는 것 을 타입이 지시하는 경우, 제1 비디오 프레임을 제1 단말기에 전송한다. 제1 단말기는 제1 비디오 프레임을 디 스플레이하도록 구성된다. 단계를 통해, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하지 않는 경우, 제2 서버는 제1 비디오 프레임에 대해 2차 렌더링을 수행할 필요가 없고 제1 비디오 프레임을 제1 단말기에 직접 전달하며, 제1 단말기 는 제1 비디오 프레임을 디스플레이한다. 단계에서, 제2 서버는 제2 비디오 프레임을 제1 단말기에 전송한다. 제1 단말기는 제2 비디오 프레임을 디스플레이하도록 구성된다. 단계를 거쳐, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제2 서버는, 제2 비디오 프레 임을 획득하기 위해 제1 파라미터에 기반하여 제1 비디오 프레임에 대해 2차 렌더링을 수행하고, 그리고 제2 비 디오 프레임을 제1 단말기에 전송한다. 제1 단말기 상에 디스플레이된 제2 비디오 프레임 내의 타깃 가상 객체 는 제1 단말기에 의해 구성된 디스플레이 효과로 디스플레이되고, 이로써 타깃 가상 객체의 디스플레이 효과의 빠른 조정이 달성된다. 실시예에서, 제2 비디오 프레임을 제1 단말기에 전송한 후, 제2 서버는 다음의 단계 중 임의의 단계를 수행한다. 하나의 가능한 구현에서, 제2 서버는, 다수의 제2 비디오 프레임을 제1 비디오 프레임 세트에 합산하고 (aggregate), 그리고 제1 비디오 프레임 세트를 제1 단말기에 전송한다. 제1 단말기는 제1 비디오 프레임 세트 를 다른 단말기와 공유하도록 구성된다. 이 구현에서, 제2 비디오 프레임은 사용자 설정에 기반하여 제2 서버에 의해 2차 렌더링을 수행함으로써 획득되 는 비디오 프레임이므로, 제2 비디오 프레임의 디스플레이 효과가 개인화된다. 제2 서버는, 제2 비디오 프레임 을 제1 비디오 프레임 세트에 합산하고, 그리고 제1 비디오 프레임 세트를 제1 단말기에 전송할 수 있다. 제1 단말기는 제1 비디오 프레임 세트를 다른 단말기와 공유할 수 있는데, 즉, 사용자는 클라우드 애플리케이션에 대한 자신의 개인화를 다른 사용자와 공유하여, 다른 사용자가 클라우드 애플리케이션을 플레이하도록 자극하고, 따라서 클라우드 애플리케이션이 더 광범위하게 전파된다. 일부 실시예에서, 제1 비디오 프레임 세트를 획득한 후, 제1 단말기는 소셜 네트워크를 통해 제1 비디오 프레임 세트를 공유할 수 있고, 따라서 제1 비디오 프레임 세트가 더 광범위하게 전파된다. 하나의 가능한 구현에서, 제2 서버는 스티칭된 비디오 프레임을 획득하기 위해 제2 비디오 프레임을 제1 비디오 프레임과 스티칭한다. 제2 서버는, 스티칭된 다수의 비디오 프레임을 제2 비디오 프레임 세트에 합산하고, 그 리고 제2 비디오 프레임 세트를 제1 단말기에 전송한다. 제1 단말기는 제2 비디오 프레임 세트를 다른 단말기 와 공유하도록 구성된다. 이 구현에서, 제2 비디오 프레임은 사용자 설정에 기반하여 제2 서버에 의해 2차 렌더링을 수행함으로써 획득되 는 비디오 프레임이다. 제1 비디오 프레임은 기본적으로 제1 서버에서 렌더링되는 비디오 프레임이다. 사용자 는, 제2 비디오 프레임 및 제1 비디오 프레임이 스티칭된 비디오 프레임으로 스티칭된 후, 스티칭된 비디오 프 레임을 시청함으로써 사용자의 개인화를 보다 명확하게 볼 수 있다. 제2 서버는, 스티칭된 비디오 프레임을 제 2 비디오 프레임 세트에 합산하고, 그리고 제2 비디오 프레임 세트를 제1 단말기에 전송할 수 있다. 제1 단말 기는 제2 비디오 프레임 세트를 다른 단말기와 공유할 수 있는데, 즉, 클라우드 애플리케이션에 대한 자신의 개 인화를 다른 사용자와 공유하여, 다른 사용자가 클라우드 애플리케이션을 플레이하도록 자극하고, 따라서 클라 우드 애플리케이션이 더 광범위하게 전파된다. 상기 단계(301 내지 305)에서는, 제2 서버가 제2 비디오 프레임을 획득하기 위해 제1 비디오 프레임에 대해 프 로세싱을 수행한다는 것을 가정하여, 설명이 이루어졌다. 게임 동안, 제1 서버는 일련의 비디오 프레임을 획득 하기 위해 타깃 장면에 대한 실시간 렌더링을 수행한다. 일련의 비디오 프레임 모두가 제1 단말기에 대응한다. 제1 비디오 프레임은 일련의 비디오 프레임 중 하나의 비디오 프레임이다. 일련의 비디오 프레임 각각에 대해, 제2 서버는 상기 단계(301 내지 305)를 수행할 수 있다. 실시예에서, 제1 단말기가 \"모두에게 보임\"을 선택하는 경우, 제2 서버는 또한 다음 단계(306 내지 308)를 수행 할 수 있고, 따라서 제2 서버는 가상 장면의 타깃 가상 객체의 디스플레이 효과를 변경하기 위해 다른 단말기에 대응하는 비디오 프레임에 대해 2차 렌더링을 수행한다. 단계에서, 제2 서버는 제2 단말기에 대응하는 제5 비디오 프레임을 획득한다. 제5 비디오 프레임은 제2 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임이다. 제2 서버에 의해 제2 단말기에 대응하는 제5 비디오 프레임을 획득하기 위한 방법은, 제2 서버에 의해 제1 단말 기에 대응하는 제1 비디오 프레임을 획득하기 위한 방법과 동일한 개념을 공유한다. 구현 프로세스에 대해서는 상기 단계의 관련 설명을 참조할 수 있으며, 상세사항은 여기서 설명되지 않는다. 단계에서, 제2 서버는, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제5 비디오 프레임에 대해 타깃 프로세싱을 수행한다. 제5 비디오 프레임이 제2 서버에 의해 타깃 가상 객체를 디스플레이하는지 여부를 결정하기 위한 방법은, 제1 비디오 프레임이 제2 서버에 의해 타깃 가상 객체를 디스플레이하는지 여부를 결정하기 위한 방법과 동일한 개 념을 공유한다. 구현 프로세스에 대해서는 상기 단계의 관련 설명을 참조할 수 있으며, 상세사항은 여기 서 설명되지 않는다. 하나의 가능한 구현에서, 제2 서버는, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제2 단말기의 제2 파라미터에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더 링한다. 실시예에서, 제2 파라미터는 제2 단말기에 의해 결정된다. 이 경우, 제2 단말기가 타깃 가상 객체에 대한 제2 파라미터를 설정하면, 제2 서버는, 제6 비디오 프레임을 획 득하기 위해 제2 파라미터를 사용함으로써 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하고, 그리고 제2 단말기에 의해 디스플레이하기 위해 후속적으로 제6 비디오 프레임을 제2 단말기에 전송할 수 있다. 즉, 제2 서버는 제1 파라미터를 사용함으로써 타깃 가상 객체를 포함하는 비디오 프레임에 대해 2차 렌더링을 수행하고, 그리고 2차 렌더링 처리된 비디오 프레임을 제1 단말기에 전송할 수 있다. 제2 서버는, 제2 파라미터를 사용함 으로써 타깃 가상 객체를 포함하는 비디오 프레임에 대해 2차 렌더링을 수행하고, 그리고 2차 렌더링 처리된 비 디오 프레임을 제2 단말기에 전송한다. 타깃 가상 객체는 제1 단말기 및 제2 단말기 상에 디스플레이되는 비디 오 프레임에서 상이한 디스플레이 효과를 가질 수 있다. 예를 들어, 타깃 가상 객체가 가상 차량인 것을 예로 들면, 가상 차량이 빨간색으로 렌더링됨을 제1 파라미터가 지시하고 그리고 가상 차량이 파란색으로 렌더링됨을 제2 파라미터가 지시하는 경우, 가상 차량은 제1 단말기에 의해 디스플레이되는 비디오 프레임에서 빨간색이고, 그리고 가상 차량은 제2 단말기에 의해 디스플레이되는 비디오 프레임에서 파란색이다.예를 들어, 제2 단말기가 타깃 가상 객체에 대한 제2 파라미터를 결정하면, 제2 서버는, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우 제2 가상 객체와 타깃 가상 객체 사이의 제2 각도 및 제2 거리를 제1 서 버로부터 획득한다. 제2 서버는 제2 각도, 제2 거리, 및 타깃 가상 객체의 식별자를 클라이언트 서버에 전송한 다. 제2 각도, 제2 거리, 및 타깃 가상 객체의 식별자를 수신한 후, 클라이언트 서버는 타깃 가상 객체의 식별 자에 기반하여 제2 파라미터를 결정한다. 클라이언트 서버는, 제3 렌더링 파라미터를 획득하기 위해 제2 각도 및 제2 거리에 기반하여 제2 파라미터를 검색하고, 그리고 제3 렌더링 파라미터를 제2 서버에 전송한다. 제3 렌더링 파라미터를 수신한 후, 제2 서버는, 제6 비디오 프레임을 획득하기 위해 제3 렌더링 파라미터를 사용함 으로써 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 하나의 가능한 구현에서, 제2 서버는, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 이 경우, 제2 단말기가 타깃 가상 객체에 대한 제2 파라미터를 설정하지 않으면, 제2 서버는, 제6 비디오 프레 임을 획득하기 위해 제1 파라미터를 사용함으로써 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하고, 그리 고 제2 단말기에 의해 디스플레이하기 위해 후속적으로 제6 비디오 프레임을 제2 단말기에 전송할 수 있다. 즉, 타깃 가상 객체는 제1 단말기 및 제2 단말기 상에 디스플레이되는 비디오 프레임에서 동일한 디스플레이 효 과를 갖는다. 예를 들어, 제2 단말기가 타깃 가상 객체에 대한 제2 파라미터를 결정하지 않으면, 서버는, 제5 비디오 프레임 이 타깃 가상 객체를 디스플레이하는 경우, 제2 가상 객체와 타깃 가상 객체 사이의 제2 각도 및 제2 거리를 제 1 서버로부터 획득한다. 제2 서버는 제2 각도, 제2 거리, 및 타깃 가상 객체의 식별자를 클라이언트 서버에 전 송한다. 제2 각도, 제2 거리, 및 타깃 가상 객체의 식별자를 수신한 후, 클라이언트 서버는 타깃 가상 객체의 식별자에 기반하여 제1 파라미터를 결정한다. 클라이언트 서버는, 제3 렌더링 파라미터를 획득하기 위해 제2 각도 및 제2 거리에 기반하여 제1 파라미터를 검색하고, 그리고 제3 렌더링 파라미터를 제2 서버에 전송한다. 제3 렌더링 파라미터를 수신한 후, 제2 서버는, 제6 비디오 프레임을 획득하기 위해 제3 렌더링 파라미터를 사 용함으로써 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 하나의 가능한 구현에서, 제2 서버는, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제5 비디오 프레임에 타깃 가상 객체에 대응하는 제2 애니메이션을 추가한다. 이 구현에서, 제2 서버는 제5 비디오 프레임에 타깃 가상 객체에 대응하는 제2 애니메이션을 추가할 수 있고, 이로써 개인화가 개선된다. 하나의 가능한 구현에서, 피제어 가상 객체와 제2 가상 객체 둘 다가 타깃 가상 장면의 타깃 서브-장면에 위치 되고, 그리고 제2 서버는, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 피제어 가상 객체와 제 2 가상 객체의 가상 레벨을 비교한다. 제2 서버는, 피제어 가상 객체의 가상 레벨이 제2 가상 객체의 가상 레 벨보다 높은 경우, 제6 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 제2 서버는, 피제어 가상 객체의 가상 레벨이 제2 가상 객체의 가상 레벨보다 낮은 경우, 제6 비디오 프레임을 획득하기 위해 제2 단말기의 제2 파라미터에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 제2 서버는, 피제어 가상 객체의 가상 레벨이 제2 가상 객체의 가상 레벨과 동일한 경우, 제6 비디오 프레임을 획득하기 위해 제3 파라미터에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 실시예에서, 제3 파라미터는 제1 서버에 의해 설정된다. 타깃 가상 장면은 다수의 서브-장면을 포함하고, 그리고 다수의 서브-장면은 타깃 가상 장면을 구성한다. 예를 들어, 다수의 서브-장면은 가상 소셜 장면 및 가상 전투 장면을 포함한다. 가상 소셜 장면은 가상 낚시 장면, 가상 채팅 룸, 가상 댄스 룸, 가상 체스 및 카드 룸을 포함한다. 가상 소셜 장면에서, 사용자는 가상 객체를 제어함으로써 다른 사용자와 소통한다. 가상 전투 장면은, 사용자가 가상 객체를 제어하여 전투를 벌이는 장면 이다. 타깃 서브-장면은, 제1 단말기에 의해 결정되고, 그리고 가상 소셜 장면 또는 가상 전투 장면일 수 있다. 타깃 서브-장면은 본 개시내용의 실시예에서 제한되지 않는다. 가상 레벨은 타깃 가상 장면에서 가상 객체의 레벨이다. 가상이 높다는 것은 가상 객체의 강력한 전투 능력을 지시한다. 실시예에서, 가상 레벨은 가상 객체에 대응하는 게임 계정의 멤버 레벨이다. 멤버 레벨이 높을수록 클라우드 애플리케이션에서 더 많은 서비스를 즐길 수 있다. 이 구현에서, 피제어 가상 객체와 제2 가상 객체 둘 다가 타깃 서브-장면에 위치되는 경우, 제2 서버는, 피제어 가상 객체 및 제2 가상 객체의 가상 레벨에 기반하여, 제1 단말기에 의해 설정되는 제1 파라미터 또는 제2 단말기에 의해 설정되는 제2 파라미터를 사용함으로써, 타깃 가상 객체에 대한 2차 렌더링을 수행하도록 결정할 수 있고, 이로써, 사용자가 가상 객체의 가상 레벨을 개선하도록 장려되고, 따라서 사용자의 게임 열정이 개선된다. 예를 들어, 제2 서버는, 피제어 가상 객체와 제2 가상 객체 둘 다가 타깃 가상 장면의 타깃 서브-장면에 위치되 는 경우, 가상 레벨 획득 요청을 클라이언트 서버에 전송한다. 가상 레벨 획득 요청은 피제어 가상 객체의 식 별자 및 제2 가상 객체의 식별자를 보유한다. 가상 레벨 획득 요청을 획득한 후, 클라이언트 서버는, 가상 레 벨 획득 요청으로부터 피제어 가상 객체의 식별자 및 제2 가상 객체의 식별자를 획득하고, 그리고 피제어 가상 객체의 제1 가상 레벨 및 제2 가상 객체의 제2 가상 레벨을 획득하기 위해 피제어 가상 객체의 식별자 및 제2 가상 객체의 식별자에 기반하여 검색을 수행한다. 클라이언트 서버는 피제어 가상 객체의 제1 가상 레벨 및 제 2 가상 객체의 제2 가상 레벨을 제2 서버에 전송한다. 제2 서버가 피제어 가상 객체의 제1 가상 레벨 및 제2 가상 객체의 제2 가상 레벨을 수신한 후, 제2 서버는, 클라이언트 서버로부터 제1 파라미터를 획득하고, 그리고 제1 가상 레벨이 제2 가상 레벨보다 높은 경우, 제6 비디오 프레임을 획득하기 위해 제1 파라미터를 사용함으로 써 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 제2 서버는, 클라이언트 서버로부터 제2 파라미터를 획득하고, 그리고 제1 가상 레벨이 제2 가상 레벨보다 낮은 경우, 제6 비디오 프레임을 획득하기 위해 제2 파라 미터를 사용함으로써 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 제2 서버는, 클라이언트 서버로부 터 제3 파라미터를 획득하고, 그리고 제1 가상 레벨이 제2 가상 레벨과 동일한 경우, 제6 비디오 프레임을 획득 하기 위해 제3 파라미터를 사용함으로써 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링한다. 일부 실시예에 서, 제3 파라미터는 제1 가상 레벨에 기반하여 결정된다. 단계에서, 제2 서버는 제6 비디오 프레임을 제2 단말기에 전송한다. 제2 단말기는 제6 비디오 프레임을 디스플레이하도록 구성된다. 본 개시내용의 선택적 실시예는 전술한 모든 선택적인 기술적 솔루션의 임의의 조합을 사용하여 형성될 수 있고, 상세사항은 여기서 설명되지 않는다. 본 개시내용의 상기 실시예에서, 방법은 예로서 제2 서버에 의해 수행된다. 다른 실시예에서, 방법은 다른 서 버에 의해 수행될 수 있다. 본 발명의 실시예에 의해 제공되는 기술적 솔루션에 따라, 특정 가상 객체의 디스플레이 효과를 변경하고자 하 는 경우, 제1 파라미터가 가상 객체에 대해 제1 단말기에 의해 결정되고, 그리고 서버는 제2 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 제1 비디오 프레임에 대해 2차 렌더링을 수행한다. 제1 비디오 프레임 과 비교하여, 제2 비디오 프레임에 디스플레이되는 가상 객체의 디스플레이 효과는 또한, 가상 객체에 대해 제1 단말기에 의해 구성된 디스플레이 효과이기도 하다. 이러한 기술적 솔루션에 따라, 가상 객체에 대해 2차 렌더 링을 수행하는 기능이 클라우드 애플리케이션에서 달성되고, 그리고 사용자가 가상 장면의 특정 가상 객체의 디 스플레이 효과를 빠르고 효율적으로 조정할 수 있고, 이로써 클라우드 애플리케이션의 기능 범위가 확장되고 클 라우드 애플리케이션의 개인화가 개선된다. 따라서, 클라우드 애플리케이션이 더 광범위하게 전파된다. 상기 단계(301 내지 308) 외에, 본 개시내용의 실시예에 따라 다른 비디오 프레임 렌더링 방법이 추가로 제공된 다. 비디오 프레임 렌더링 방법은 타깃 가상 장면에서 타깃 이벤트가 발생하는 경우 적용 가능하다. 도 6을 참조하면, 방법은 다음의 단계(601 내지 603)를 포함한다. 단계에서, 제2 서버는 제1 단말기에 대응하는 제3 비디오 프레임을 획득한다. 제3 비디오 프레임은, 타깃 가상 장면에서 타깃 이벤트가 발생한 후, 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임이고, 그리고 타깃 이벤트는 피제어 가상 객체와 연관된 이벤트이다. 가능한 구현에서, 제1 서버는 타깃 가상 장면에서 타깃 이벤트가 발생하는 것에 응답하여, 제1 단말기에 대응하 는 제3 비디오 프레임을 제2 서버에 전송한다. 제1 서버는, 제3 비디오 프레임을 제2 서버에 전송하면서, 제3 비디오 프레임에 바인딩된 프롬프트 정보를 제2 서버에 전송한다. 프롬프트 정보는 타깃 이벤트의 식별자를 보 유한다. 제2 서버는, 제3 비디오 프레임을 획득하면서, 프롬프트 정보에 기반하여 타깃 이벤트가 타깃 가상 장 면에서 발생한다는 것을 결정하여, 제3 비디오 프레임의 후속 렌더링을 트리거할 수 있다. 예를 들어, 타깃 이벤트는 피제어 가상 객체가 타깃 가상 장면의 제1 가상 객체를 물리치는 것(defeat)이다. 여기서 물리친다라는 것은, 타깃 가상 장면에서 피제어 가상 객체의 행위로 인해 제1 가상 객체의 수명 값이 0 으로 감소되는 것을 의미이다. 예를 들어, 피제어 가상 객체는 가상 총/가상 단검/가상 수류탄 등을 사용함으 로써 제1 가상 객체를 공격하여, 제1 가상 객체의 생명 값을 0으로 감소시킨다. 제1 가상 객체는 피제어 가상객체와 다른 팀의 객체이거나, 또는 제1 가상 객체는 피제어 가상 객체에 적대적인 가상 객체이다. 피제어 가 상 객체가 타깃 가상 장면의 제1 가상 객체를 물리치는 것에 응답하여, 제1 서버는 제3 비디오 프레임을 제2 서 버에 실시간으로 전송한다. 제3 비디오 프레임은 제1 가상 객체가 패배한(defeated) 후의 제1 비디오 프레임이 다. 제1 서버는, 제3 비디오 프레임을 제2 서버에 전송하면서, 제3 비디오 프레임에 바인딩된 프롬프트 정보를 제2 서버에 전송한다. 프롬프트 정보는, 타깃 이벤트의 식별자를 보유하는 것 외에, 제1 가상 객체가 패배한 포지션도 또한 보유한다. 후속하여, 제2 서버는 또한, 프롬프트 정보에 기반하여 피제어 가상 객체가 타깃 가 상 장면의 제1 가상 객체를 물리친다는 것을 결정하는 것 외에, 제3 비디오 프레임에서 제1 가상 객체가 패배하 는 구역을 결정할 수 있다. 일부 실시예에서, 타깃 가상 장면에서 발생하는 타깃 이벤트에 응답하여, 제1 서버 는, 후크(Hook) 기능을 사용함으로써 타깃 이벤트를 후킹하고, 그리고 타깃 이벤트를 제2 서버에 통지할 수 있 는데, 즉, 프롬프트 정보에 의해 타깃 가상 장면에서 타깃 이벤트가 발생한다는 것을 제2 서버에 통지할 수 있 다. 상기 예는, 피제어 가상 객체가 타깃 가상 장면의 제1 가상 객체를 물리치는 것이 타깃 이벤트라는 것을 가정함 으로써 설명된다. 다른 가능한 구현에서, 타깃 이벤트는, 피제어 가상 객체가 타깃 가상 장면에서 타깃 가상 소품을 픽업(picks up)하는 것, 피제어 가상 객체가 타깃 가상 장면에서 타깃 가상 캐리어를 시작하는 것, 또는 피제어 가상 객체가 타깃 가상 장면에서 다수의 가상 객체를 연속적으로 물리치는 것 등일 수 있다. 타깃 이벤 트는 실제 상황에 따라 기술자에 의해 설정된다. 타깃 이벤트의 타입은 본 개시내용의 실시예에서 제한되지 않 는다. 단계에서, 제2 서버는, 제4 비디오 프레임을 획득하기 위해 타깃 이벤트에 대응하는 제1 애니메이션을 제3 비디오 프레임에 추가한다. 가능한 구현에서, 타깃 이벤트는 피제어 가상 객체가 타깃 가상 장면에서 제1 가상 객체를 물리치는 것이고, 그 리고 제2 서버는 제3 비디오 프레임에서 제1 가상 객체가 패배한 구역을 결정한다. 제2 서버는 제4 비디오 프 레임을 획득하기 위해 타깃 이벤트에 대응하는 제1 애니메이션을 이 구역에 추가한다. 타깃 이벤트와 애니메이 션 간의 대응관계는 제1 단말기를 통해 설정된다. 예를 들어, 타깃 이벤트가 제1 단말기에 의해 선택되고, 그 리고 타깃 이벤트에 바인딩된 애니메이션이 클라이언트 서버에 의해 제공되는 다수의 애니메이션 중에서 선택되 거나; 또는 타깃 이벤트에 대응하는 제1 애니메이션이 제1 단말기에 의해 클라이언트 서버에 업로딩되고, 그리 고 클라이언트 서버가 제1 단말기에 의해 업로딩된 애니메이션을 수신한 후 애니메이션을 타깃 이벤트에 바인딩 한다. 예를 들어, 제1 서버는, 제3 비디오 프레임을 제2 서버에 전송하면서, 제3 비디오 프레임에 바인딩된 프롬프트 정보를 제2 서버에 전송한다. 제2 서버는, 프롬프트 정보로부터, 제1 가상 객체가 패배한 포지션 및 타깃 이벤 트의 식별자를 획득한다. 제2 서버는, 타깃 이벤트의 식별자에 기반하여 타깃 이벤트에 대응하는 제1 애니메이 션을 결정하고, 그리고 제1 가상 객체가 패배한 포지션에 기반하여 제1 가상 객체가 패배한 구역을 결정한다. 제2 서버는 제4 비디오 프레임을 획득하기 위해 타깃 이벤트에 대응하는 제1 애니메이션을 이 구역에 추가한다. 예를 들어, 제1 서버는, 제3 비디오 프레임을 제2 서버에 전송하면서, 제3 비디오 프레임에 바인딩된 프롬프트 정보를 제2 서버에 전송한다. 제2 서버는, 프롬프트 정보로부터, 제1 가상 객체가 패배한 포지션 및 타깃 이벤 트의 식별자를 획득한다. 제2 서버는 제2 애니메이션 획득 요청을 클라이언트 서버에 전송한다. 제2 애니메이 션 획득 요청은 타깃 이벤트의 식별자를 보유한다. 제2 애니메이션 획득 요청을 수신한 후, 클라이언트 서버는, 제2 애니메이션 획득 요청으로부터 타깃 이벤트의 식별자를 획득하고, 타깃 이벤트에 대응하는 제1 애 니메이션을 획득하기 위해 타깃 이벤트의 식별자에 기반하여 검색을 수행하고, 그리고 타깃 이벤트에 대응하는 제1 애니메이션을 제2 서버에 전송한다. 타깃 이벤트에 대응하는 제1 애니메이션을 수신한 후, 제2 서버는 제4 비디오 프레임을 획득하기 위해 제1 가상 객체가 패배한 구역에 애니메이션을 추가한다. 일부 실시예에서, 제2 서버는 제4 비디오 프레임을 획득하기 위해 애니메이션의 제1 프레임을 제3 비디오 프레임에 추가할 수 있다. 단계에서, 제2 서버는 제4 비디오 프레임을 제1 단말기에 전송한다. 제1 단말기는 제4 비디오 프레임을 디스플레이하도록 구성된다. 실시예에서, 단계 이전에, 제2 서버는 타깃 이벤트에 대응하는 제1 오디오를 획득할 수 있다. 제1 오디오 는 제1 단말기의 오디오이다. 제2 서버는 제1 오디오를 제1 단말기에 전송하고, 그리고 제1 단말기는 제4 비디 오 프레임을 디스플레이하면서 제1 오디오를 플레이하도록 구성된다. 타깃 이벤트와 제1 오디오 간의 대응관계 는 제1 단말기를 통해 설정된다. 예를 들어, 타깃 이벤트가 제1 단말기에 의해 선택되고, 그리고 타깃 이벤트 에 바인딩된 제1 오디오가 클라이언트 서버에 의해 제공되는 다수의 제1 오디오 피스(pieces) 중에서 선택되거나; 또는 타깃 이벤트에 대응하는 제1 오디오가 제1 단말기에 의해 클라이언트 서버에 업로딩되고, 그리고 클라 이언트 서버가 제1 단말기에 의해 업로딩된 제1 오디오를 수신한 후 제1 오디오를 타깃 이벤트에 바인딩한다. 예를 들어, 제1 서버는, 제3 비디오 프레임을 제2 서버에 전송하면서, 제3 비디오 프레임에 바인딩된 프롬프트 정보를 제2 서버에 전송한다. 제2 서버는 프롬프트 정보로부터 타깃 이벤트의 식별자를 획득한다. 제2 서버는 애니메이션 및 오디오 획득 요청을 클라이언트 서버에 전송한다. 애니메이션 및 오디오 획득 요청은 타깃 이벤 트의 식별자를 보유한다. 제2 애니메이션 획득 요청을 수신한 후, 클라이언트 서버는, 제2 애니메이션 획득 요 청으로부터 타깃 이벤트의 식별자를 획득하고, 타깃 이벤트에 대응하는 제1 애니메이션 및 제1 오디오를 획득하 기 위해 타깃 이벤트의 식별자에 기반하여 검색을 수행하고, 그리고 타깃 이벤트에 대응하는 제1 애니메이션 및 제1 오디오를 제2 서버에 전송한다. 타깃 이벤트에 대응하는 제1 애니메이션 및 제1 오디오를 수신한 후, 제2 서버는 제4 비디오 프레임을 획득하기 위해 애니메이션을 제3 비디오 프레임에 추가한다. 제2 서버는, 제4 비 디오 프레임을 제1 단말기에 전송하면서 제1 오디오를 제1 단말기에 전송한다. 제4 비디오 프레임 및 제1 오디 오를 수신한 후, 제1 단말기는 제4 비디오 프레임을 디스플레이하면서 제1 오디오를 플레이한다. 피제어 가상 객체가 타깃 가상 장면의 제1 가상 객체를 물리치는 것이 타깃 이벤트라는 것이 여전히 가정된다. 피제어 가상 객체가 가상 장면의 제1 가상 객체를 물리치는 것에 응답하여, 제1 서버는 제3 비디오 프레임 및 제3 비디오 프레임에 바인딩된 프롬프트 정보를 제2 서버에 전송한다. 프롬프트 정보는 제1 가상 객체가 패배 한 포지션 및 타깃 이벤트의 식별자를 보유한다. 제2 서버는, 프롬프트 정보로부터, 제1 가상 객체가 패배한 포지션 및 타깃 이벤트의 식별자를 획득한다. 제2 서버는 애니메이션 및 오디오 획득 요청을 클라이언트 서버 에 전송한다. 애니메이션 및 오디오 획득 요청은 타깃 이벤트의 식별자를 보유한다. 애니메이션 및 오디오 획 득 요청을 수신한 후, 클라이언트 서버는, 애니메이션 및 오디오 획득 요청으로부터 타깃 이벤트의 식별자를 획 득하고, 타깃 이벤트에 대응하는 제1 애니메이션 및 제1 오디오를 획득하기 위해 타깃 이벤트의 식별자에 기반 하여 검색을 수행하고, 그리고 타깃 이벤트에 대응하는 제1 애니메이션 및 제1 오디오를 제2 서버에 전송한다. 타깃 이벤트에 대응하는 제1 애니메이션 및 제1 오디오를 수신한 후, 제2 서버는 제4 비디오 프레임을 획득하기 위해 제1 가상 객체가 제3 비디오 프레임에서 패배한 포지션에 포지셔닝 애니메이션을 추가한다. 제2 서버는, 제4 비디오 프레임을 제1 단말기에 전송하면서 제1 오디오를 제1 단말기에 전송한다. 제4 비디오 프레임 및 제 1 오디오를 수신한 후, 제1 단말기는 제4 비디오 프레임을 디스플레이하면서 제1 오디오를 플레이한다. 애니메 이션이 작은 사람이 춤추는 애니메이션이라면, 제4 비디오 프레임에서 제1 가상 객체가 패배한 포지션에 작은 사람이 춤추는 애니메이션을 디스플레이하면서 제1 오디오가 플레이되고, 그리고 사용자는 애니메이션 및 제1 오디오에 의해 게임에서 더 나은 성능을 달성하도록 스스로를 자극한다. 도 7을 참조하면, 제2 서버는 제4 비 디오 프레임에서 제1 가상 객체가 패배한 포지션에 애니메이션을 추가한다. 본 개시내용의 실시예에 의해 제공되는 기술적 솔루션에 따라, 타깃 가상 장면에서 타깃 이벤트를 전송하면서 지정된 애니메이션을 플레이하고자 하는 경우, 제1 단말기에 의해 타깃 이벤트에 대한 타깃 애니메이션이 선택 된다. 제2 서버는 제4 비디오 프레임을 획득하기 위해 비디오 프레임에 대해 2차 렌더링을 수행한다. 제3 비 디오 프레임과 비교하여, 제1 단말기에 의해 설정된 애니메이션이 제4 비디오 프레임에 디스플레이될 수 있다. 이러한 기술적 솔루션에 따라, 애니메이션에 대해 2차 렌더링을 수행하는 기능이 클라우드 애플리케이션에서 달 성되고, 그리고 사용자가 가상 장면의 디스플레이 효과를 빠르고 효율적으로 조정할 수 있으며, 이로써 클라우 드 애플리케이션의 기능 범위가 확장되고 클라우드 애플리케이션의 개인화가 개선된다. 따라서, 클라우드 애플 리케이션이 더 광범위하게 전파된다. 상기 설명 프로세스에서, 제1 단말기, 클라이언트 서버, 제1 서버, 제2 서버, 및 게임 서버는 하나의 비디오 프 레임 렌더링 시스템을 구성한다. 도 1에서는 비디오 프레임 렌더링 방법의 구현 환경이 소개되었고, 위에서는 다양한 컴포넌트의 기능이 간략히 소개되었다. 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 시스템은 상기 방법 실시예와 결합하여 아래에서 소개된다. 도 1을 참조하면, 시스템은, 제1 단말기, 제1 서버, 및 제2 서버를 포함한다. 제1 단말기, 제1 서버, 및 제2 서버는 서로 통신하게 연결된다. 예에서, 제1 서버는 클라우드 서버이다. 예에서, 제2 서버는 장면 관리 서버이다. 제1 서버는, 제1 단말기에 대응하는 제1 비디오 프레임을 획득하기 위해 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링하도록, 그리고 제1 비디오 프레임을 제2 서버에 전송하도록 구성된다. 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체이다.제2 서버는 제1 비디오 프레임을 수신하도록 구성된다. 제2 서버는 추가로, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프 레임을 획득하기 위해 제1 단말기의 제1 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링 하도록 구성된다. 제2 서버는 추가로, 제2 비디오 프레임을 제1 단말기에 전송하도록 구성된다. 제1 단말기는 제2 비디오 프레임을 수신하는 것에 응답하여 제2 비디오 프레임을 디스플레이하도록 구성된다. 가능한 구현에서, 제1 단말기는 추가로, 제어 정보를 제1 서버에 전송하도록 구성된다. 제어 정보는 타깃 가상 장면에서 피제어 가상 객체의 동작을 제어하는 데 사용된다. 제1 서버는 추가로, 제어 정보에 기반하여 타깃 가상 장면의 피제어 가상 객체의 시점을 결정하도록, 그리고 제 1 비디오 프레임을 획득하기 위해 타깃 가상 장면 내의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌 더링하도록 구성된다. 가능한 구현에서, 시스템은 클라이언트 서버를 더 포함한다. 클라이언트 서버는 제1 단말기, 제1 서버, 및 제2 서버 각각과 통신하게 연결된다. 제1 단말기는 추가로, 타깃 가상 객체의 구성 인터페이스를 디스플레이하도록 구성된다. 구성 인터페이스는 타 깃 가상 객체의 구성 정보를 획득하는 데 사용된다. 제1 단말기는 추가로, 구성 인터페이스에 대한 조작에 응답하여 타깃 가상 객체의 구성 정보를 클라이언트 서버 에 전송하도록 구성된다. 클라이언트 서버는, 타깃 가상 객체의 구성 정보를 수신하도록, 타깃 가상 객체의 구성 정보에 기반하여 타깃 가상 객체의 3-차원 모델을 생성하도록, 그리고 3-차원 모델의 제1 파라미터를 획득하도록 구성된다. 가능한 구현에서, 제2 서버는 추가로, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우 제1 렌더링 파라미터를 획득하도록 구성된다. 제1 렌더링 파라미터는 제1 파라미터 중 제1 각도 및 제1 거 리에 대응하는 렌더링 파라미터이다. 제1 각도는 피제어 가상 객체와 타깃 가상 객체가 사이의 각도이다. 제1 거리는 피제어 가상 객체와 타깃 가상 객체 사이의 거리이다. 제1 비디오 프레임 내의 타깃 가상 객체는 제2 비디오 프레임을 획득하기 위해 제1 렌더링 파라미터에 기반하여 렌더링된다. 가능한 구현에서, 제2 서버는 추가로, 제1 렌더링 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체 의 다수의 타깃 픽셀 포인트의 타깃 픽셀 값을 결정하도록 구성된다. 제2 비디오 프레임을 획득하기 위해 타깃 픽셀 값을 사용함으로써 제1 비디오 프레임 내의 다수의 타깃 픽셀 포인트의 픽셀 값이 업데이트된다. 가능한 구현에서, 제2 서버는 추가로, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우, 제1 파라미터로부터 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 획득하도록 구성된다. 제1 비디오 프 레임에서, 제2 비디오 프레임을 획득하기 위해 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 사용함으로써 타 깃 가상 객체 및 피제어 타깃 가상 객체가 각각 렌더링된다. 가능한 구현에서, 제2 서버는 추가로, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우, 타깃 가상 장면에서 피제어 가상 객체의 포지션을 결정하도록 구성된다. 제1 비디오 프레임 내의 타깃 가 상 객체는, 피제어 가상 객체가 타깃 가상 장면의 타깃 서브-장면에 위치되는 경우, 제2 비디오 프레임을 획득 하기 위해 제1 파라미터에 기반하여 렌더링된다. 피제어 가상 객체가 타깃 가상 장면의 타깃 서브-장면에 위치 되지 않는 경우, 제1 비디오 프레임이 제2 비디오 프레임으로서 결정된다. 가능한 구현에서, 제2 서버는 추가로, 제1 비디오 프레임의 타입을 결정하기 위해 제1 비디오 프레임에 대한 이 미지 인식을 수행하도록 구성된다. 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하는 것을 타입이 지시하 는 경우, 제2 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 타깃 가상 객체가 렌더링된다. 가능한 구현에서, 제2 서버는 추가로, 타깃 가상 객체의 템플릿 이미지를 사용함으로써 제1 비디오 프레임에서 검출을 수행하도록 구성된다. 제1 비디오 프레임 내의 타깃 가상 객체의 템플릿 이미지와 매칭하는 구역이 있 음을 검출하는 것에 응답하여, 제1 비디오 프레임의 타입이 제1 타입으로서 결정된다. 제1 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 지시한다. 제1 비디오 프레임 내의 타깃 가상 객체의 템플 릿 이미지와 매칭하는 구역이 없음을 검출하는 것에 응답하여, 제1 비디오 프레임의 타입이 제2 타입으로서 결정된다. 제2 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하지 않는다는 것을 지시한다. 가능한 구현에서, 제2 서버는 추가로, 제1 비디오 프레임을 이미지 인식 모델에 입력하도록 구성된다. 제1 비 디오 프레임의 타입을 출력하기 위해, 이미지 인식 모델을 통해 제1 비디오 프레임에 대해 특징 추출 및 분류가 수행된다. 가능한 구현에서, 제2 서버는 추가로, 제1 비디오 프레임을 다수의 이미지 블록으로 분할하도록, 그리고 다수의 이미지 블록을 이미지 인식 모델에 입력하도록 구성된다. 제1 비디오 프레임의 타입을 출력하기 위해 이미지 인식 모델을 통해 제1 비디오 프레임에 대해 특징 추출 및 분류를 수행하는 프로세스는, 다수의 이미지 블록에 각각 대응하는 다수의 확률을 획득하기 위해 이미지 인식 모델에 의해 다수의 이미지 블록에 대해 특징 추출 및 완전 연결 프로세싱을 수행하는 것을 포함하고, 확률은 대응하는 이미지 블록이 타깃 가상 객체를 포함할 확률 이다. 다수의 확률 중 임의의 확률이 확률 임계치 이상인 것에 응답하여, 제1 비디오 프레임의 타입이 제1 타 입으로서 결정된다. 제1 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 지시한다. 다 수의 확률 각각이 확률 임계치 미만인 것에 응답하여, 제1 비디오 프레임의 타입이 제2 타입으로서 결정된다. 제2 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하지 않는다는 것을 지시한다. 가능한 구현에서, 제2 서버는 추가로, 클라이언트 서버로부터 제1 파라미터를 획득하도록 구성된다. 클라이언 트 서버는, 타깃 가상 객체에 대해 제1 단말기에 의해 업로딩된 설정 파라미터에 기반하여 타깃 가상 객체의 3- 차원 모델을 생성하도록 구성된다. 제1 파라미터는 3-차원 모델의 다수의 렌더링 파라미터를 포함한다. 가능한 구현에서, 제1 서버는 추가로, 타깃 가상 장면에서 발생하는 타깃 이벤트에 응답하여, 제1 단말기에 대 응하는 제3 비디오 프레임을 획득하기 위해 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링하도록, 그리고 제3 비디오 프레임을 제2 서버에 전송하도록 구성된다. 타깃 이벤트는, 피제어 가상 객체가 타깃 가상 장면의 제1 가상 객체를 물리치는 것이다. 제2 서버는 추가로, 타깃 이벤트에 대응하는 제1 애니메이션 및 타깃 이벤트에 대응하는 제1 오디오를 획득하도 록 구성된다. 제1 오디오는 제1 단말기의 오디오이다. 제2 서버는 추가로, 제3 비디오 프레임에서 제1 가상 객체가 패배한 구역을 결정하도록 구성된다. 제4 비디오 프레임을 획득하기 위해 타깃 이벤트에 대응하는 제1 애니메이션이 구역에 추가된다. 제4 비디오 프레임 및 제 1 오디오가 제1 단말기에 전송된다. 제1 단말기는 추가로, 제4 비디오 프레임 및 제1 오디오를 수신하는 것에 응답하여, 제4 비디오 프레임을 디스 플레이하면서 제1 오디오를 플레이하도록 구성된다. 가능한 구현에서, 시스템은 제2 단말기를 더 포함한다. 제2 단말기, 제1 서버, 및 제2 서버는 서로 통신하게 연결된다. 제2 단말기 및 제1 단말기는 상이한 단말기이다. 제1 서버는 추가로, 제2 단말기에 대응하는 제5 비디오 프레임을 획득하기 위해 타깃 가상 장면의 제2 가상 객 체의 시점으로부터 타깃 가상 장면을 렌더링하도록, 그리고 제5 비디오 프레임을 제2 서버에 전송하도록 구성된 다. 제2 가상 객체는 제2 단말기에 의해 제어되는 가상 객체이다. 제2 서버는 추가로, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하 기 위해 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하도록, 그리고 제6 비디오 프레임을 제2 단말기에 전 송하도록 구성된다. 제2 단말기는 제6 비디오 프레임을 수신하는 것에 응답하여 제6 비디오 프레임을 디스플레이하도록 구성된다. 가능한 구현에서, 제2 서버는 추가로, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제2 단말기의 제2 파라미터에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 조작; 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제1 파라미터 에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 조작; 및 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제5 비디오 프레임에 타깃 가상 객체에 대응하는 제2 애니메이션을 추가하는 조작 중 임의의 조작을 수행하도록 구성된다. 가능한 구현에서, 제2 서버는 추가로, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 피제어 가 상 객체 및 제2 가상 객체의 가상 레벨을 비교하도록 구성된다. 제5 비디오 프레임 내의 타깃 가상 객체는, 피 제어 가상 객체의 가상 레벨이 제2 가상 객체의 가상 레벨보다 높은 경우, 제6 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 렌더링된다. 제5 비디오 프레임 내의 타깃 가상 객체는, 피제어 가상 객체의 가상 레 벨이 제2 가상 객체의 가상 레벨보다 낮은 경우, 제6 비디오 프레임을 획득하기 위해 제2 단말기의 제2 파라미 터에 기반하여 렌더링된다. 제5 비디오 프레임 내의 타깃 가상 객체는, 피제어 가상 객체의 가상 레벨이 제2 가상 객체의 가상 레벨과 동일한 경우, 제6 비디오 프레임을 획득하기 위해 제3 파라미터에 기반하여 렌더링된 다. 가능한 구현에서, 제2 서버는 추가로, 타깃 가상 객체에 대응하는 제2 애니메이션 및 제2 오디오를 획득하도록 구성된다. 제7 비디오 프레임을 획득하기 위해 타깃 가상 객체에 대응하는 제2 애니메이션이 제2 비디오 프레 임에 추가된다. 제7 비디오 프레임 및 제2 오디오가 제1 단말기에 전송된다. 제1 단말기는 제7 비디오 프레임 을 디스플레이하면서 제2 오디오를 플레이하도록 구성된다. 가능한 구현에서, 제2 서버는 추가로, 다수의 제2 비디오 프레임을 제1 비디오 프레임 세트로 합산하고, 그리고 제1 비디오 프레임을 제1 단말기에 전 송하는 조작 ― 제1 단말기는 제1 비디오 프레임 세트를 다른 단말기와 공유하도록 구성됨 ―; 스티칭된 비디오 프레임을 획득하기 위해 제2 비디오 프레임 및 제1 비디오 프레임을 스티칭하는 조작; 및 스티 칭된 다수의 비디오 프레임을 제2 비디오 프레임 세트에 합산하고, 그리고 제2 비디오 프레임 세트를 제1 단말 기에 전송하는 조작 ― 제1 단말기는 제2 비디오 프레임 세트를 다른 단말기와 공유하도록 구성됨― 중 임의의 조작을 수행하도록 구성된다. 가능한 구현에서, 제2 서버는 추가로, 클라이언트 서버로부터 제1 파라미터를 획득하도록 구성된다. 클라이언 트 서버는, 타깃 가상 객체에 대해 제1 단말기에 의해 업로딩된 설정 파라미터에 기반하여 타깃 가상 객체의 3- 차원 모델을 생성하도록 구성된다. 제1 파라미터는 3-차원 모델의 다수의 렌더링 파라미터를 포함한다. 본 개시내용의 실시예에 의해 제공되는 비디오 프레임 렌더링 시스템은, 도 1 및 상기 단계(301 내지 308 및 601 내지 603)를 참조하여 아래에서 설명된다. 제1 단말기는 타깃 가상 객체의 구성 인터페이스를 디스플레이한다. 구성 인터페이스는 타깃 가상 객체의 구성 정보를 획득하는 데 사용된다. 구성 인터페이스의 조작에 응답하여 타깃 가상 객체의 구성 정보가 클라이언트 서버에 전송된다. 클라이언트 서버는, 타깃 가상 객체의 구성 정보를 수신하고, 타깃 가상 객체의 구성 정보에 기반하여 타깃 가상 객체의 3-차원 모델을 생성하고, 그리고 3-차원 모델의 제1 파라미터를 획득한다. 게임 장 면을 예로 들면, 제1 단말기는, 타깃 클라우드 게임을 시작하고, 클라이언트 서버와 긴 연결을 유지하고, 그리 고 게임 시작 명령을 클라이언트 서버에 전송한다. 게임 시작 명령은 사용자 계정, 타깃 클라우드 게임의 식별 자, 및 제1 단말기의 하드웨어 정보를 보유한다. 게임 시작 명령을 수신한 후, 클라이언트 서버는 게임 시작 명령을 제1 서버에 전송한다. 게임 시작 명령을 수신한 후, 제1 서버는 게임 시작 명령으로부터 사용자 계정, 타깃 클라우드 게임의 식별자, 및 제1 단말기의 하드웨어 정보를 획득한다. 제1 서버는, 렌더링된 게임 픽처와 제1 단말기 간의 매칭을 실현하기 위해 제1 단말기의 하드웨어 정보에 기반하여 타깃 클라우드 게임을 초기화하 고, 그리고 사용자 계정을 타깃 클라우드 게임에 대응하는 게임 서버에 전송한다. 사용자 계정을 수신한 후, 게임 서버는 게임 계정에 대응하는 정보를 제1 서버에 전송한다. 제1 서버는 게임 계정에 대응하는 정보에 기 반하여 타깃 클라우드 게임을 시작한다. 타깃 클라우드 게임을 구동하는 프로세스에서, 타깃 클라우드 게임의 타깃 가상 장면이 디스플레이되고, 그리고 타깃 가상 장면은 피제어 가상 객체를 디스플레이한다. 제1 단말기 는 피제어 가상 객체의 제어 정보를 제1 서버에 전송한다. 제어 정보를 수신한 후, 제1 서버는 제어 정보에 기 반하여 타깃 가상 장면의 피제어 가상 객체의 시점을 결정한다. 제1 서버는 제1 비디오 프레임을 획득하기 위 해 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링한다. 제1 비디오 프레임은 또한, 제1 단말기에 대응하는 비디오 프레임이다. 제1 서버는 제1 비디오 프레임을 제2 서버에 전송한다. 사용자가, 게임 시작 이 전에, 타깃 클라우드 게임에서 특정 가상 객체를 개인화하는 경우, 예를 들어, 타깃 클라우드 게임에서 차량이 빨간색이 되게 설정하면, 제2 서버는 제1 비디오 프레임이 차량을 포함하는지 여부를 결정하고 그리고 제1 비디 오 프레임에 대해 이미지 인식을 수행할 수 있다. 제1 비디오 프레임이 차량을 디스플레이한다고 제2 서버가 결정하면, 차량에 대한 제1 파라미터가 클라이언트 서버로부터 획득된다. 사용자에 의해 차량에 대해 설정된 파라미터에 기반하여 제1 파라미터가 클라이언트 서버에 의해 결정된다. 제2 서버는, 제2 비디오 프레임을 획 득하기 위해 제1 파라미터에 기반하여 제1 비디오 프레임 내의 차량을 렌더링하고, 그리고 제2 비디오 프레임을 제1 단말기에 전송한다. 사용자는 제1 단말기를 통해 제2 비디오 프레임을 시청할 수 있다. 기술자가 타깃 클라우드 게임에서 차량의 컬러를 파란색으로 구성하면, 차량의 컬러는 상기 단계를 통해 사용자에 의해 빨간색으 로 설정되게 조정되어, 차량에 대한 개인화된 구성이 획득된다. 본 발명의 실시예에 의해 제공되는 기술적 솔루션에 따라, 특정 가상 객체의 디스플레이 효과를 변경하고자 하 는 경우, 제1 파라미터가 제1 단말기에 의해 가상 객체에 대해 결정되고, 그리고 서버는 제2 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 제1 비디오 프레임에 대해 2차 렌더링을 수행한다. 제1 비디오 프레임 과 비교하여, 제2 비디오 프레임에 디스플레이되는 가상 객체의 디스플레이 효과는 또한, 가상 객체에 대해 제1 단말기에 의해 구성된 디스플레이 효과이기도 하다. 이러한 기술적 솔루션에 따라, 가상 객체에 대해 2차 렌더 링을 수행하는 기능이 클라우드 애플리케이션에서 달성되고, 그리고 사용자가 가상 장면의 특정 가상 객체의 디 스플레이 효과를 빠르고 효율적으로 조정할 수 있고, 이로써 클라우드 애플리케이션의 기능 범위가 확장되고 클 라우드 애플리케이션의 개인화가 개선된다. 따라서, 클라우드 애플리케이션이 더 광범위하게 전파된다. 도 8은 본 개시내용의 실시예에 따른 비디오 프레임 렌더링 장치의 개략적 구조 다이어그램이다. 도 8을 참조 하면, 장치는 제1 비디오 프레임 획득 모듈, 렌더링 모듈, 및 전송 모듈을 포함한다. 제1 비디오 프레임 획득 모듈은 제1 단말기에 대응하는 제1 비디오 프레임을 획득하도록 구성된다. 제1 비디오 프레임은 타깃 가상 장면의 피제어 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되 는 비디오 프레임이다. 피제어 가상 객체는 제1 단말기에 의해 제어되는 가상 객체이다. 렌더링 모듈은, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경우, 제2 비디오 프 레임을 획득하기 위해 제1 단말기의 제1 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객체를 렌더링 하도록 구성된다. 전송 모듈은 제2 비디오 프레임을 제1 단말기에 전송하도록 구성된다. 제1 단말기는 제2 비디오 프레임을 디스플레이하도록 구성된다. 가능한 구현에서, 렌더링 모듈은, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우, 제1 렌더링 파라미터를 획득하도록 구성된다. 제1 렌더링 파라미터는 제1 파라미터 중 제1 각도 및 제1 거 리에 대응하는 렌더링 파라미터이다. 제1 각도는 피제어 가상 객체와 타깃 가상 객체가 사이의 각도이다. 제1 거리는 피제어 가상 객체와 타깃 가상 객체 사이의 거리이다. 제1 비디오 프레임 내의 타깃 가상 객체는 제2 비디오 프레임을 획득하기 위해 제1 렌더링 파라미터에 기반하여 렌더링된다. 가능한 구현에서, 렌더링 모듈은, 제1 렌더링 파라미터에 기반하여 제1 비디오 프레임 내의 타깃 가상 객 체의 다수의 타깃 픽셀 포인트의 타깃 픽셀 값을 결정하도록 구성된다. 제2 비디오 프레임을 획득하기 위해 타 깃 픽셀 값을 사용함으로써 제1 비디오 프레임 내의 다수의 타깃 픽셀 포인트의 픽셀 값이 업데이트된다. 가능한 구현에서, 렌더링 모듈은, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우, 제1 파라미터로부터 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 획득하도록 구성된다. 제1 비디오 프 레임에서, 제2 비디오 프레임을 획득하기 위해 제1 렌더링 파라미터 및 제2 렌더링 파라미터를 사용함으로써 타 깃 가상 객체 및 피제어 타깃 가상 객체가 각각 렌더링된다. 가능한 구현에서, 렌더링 모듈은, 제1 비디오 프레임이 제1 단말기의 타깃 가상 객체를 디스플레이하는 경 우, 타깃 가상 장면에서 피제어 가상 객체의 포지션을 결정하도록 구성된다. 제1 비디오 프레임 내의 타깃 가 상 객체는, 피제어 가상 객체가 타깃 가상 장면의 타깃 서브-장면에 위치되는 경우, 제2 비디오 프레임을 획득 하기 위해 제1 파라미터에 기반하여 렌더링된다. 가능한 구현에서, 렌더링 모듈은 추가로, 피제어 가상 객체가 타깃 가상 장면의 타깃 서브-장면에 위치되 지 않는 경우, 제1 비디오 프레임을 제2 비디오 프레임으로서 결정하도록 구성된다. 가능한 구현에서, 장치는, 제1 비디오 프레임의 타입을 결정하기 위해, 제1 비디오 프레임에 대해 이미지 인식을 수행하도록 구성된 이미 지 인식 모듈을 더 포함한다. 렌더링 모듈은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 타입이 지시하는 경우, 제2 비디오 프레임을 획득하기 위해 제1 파라미터에 기반하여 타깃 가상 객체를 렌더링하도록 구성된다. 가능한 구현에서, 이미지 인식 모듈은, 타깃 가상 객체의 템플릿 이미지를 사용함으로써 제1 비디오 프레임에서 검출을 수행하도록 구성된다. 제1 비디오 프레임 내의 타깃 가상 객체의 템플릿 이미지와 매칭하는 구역이 있음을 검출하는 것에 응답하여, 제1 비디오 프레임의 타입이 제1 타입으로서 결정된다. 제1 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 지시한다. 제1 비디오 프레임 내의 타깃 가상 객체의 템플 릿 이미지와 매칭하는 구역이 없음을 검출하는 것에 응답하여, 제1 비디오 프레임의 타입이 제2 타입으로서 결 정된다. 제2 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하지 않는다는 것을 지시한다. 가능한 구현에서, 이미지 인식 모듈은, 제1 비디오 프레임을 이미지 인식 모델에 입력하도록, 그리고 제1 비디 오 프레임의 타입을 출력하기 위해 이미지 인식 모델을 통해 제1 비디오 프레임에 대해 특징 추출 및 분류를 수 행하도록 구성된다. 가능한 구현에서, 이미지 인식 모듈은, 제1 비디오 프레임을 다수의 이미지 블록으로 분할하도록, 그리고 다수 의 이미지 블록을 이미지 인식 모델에 입력하도록 구성된다. 다수의 이미지 블록에 각각 대응하는 다수의 확률 을 획득하기 위해 이미지 인식 모델에 의해 다수의 이미지 블록에 대해 특징 추출 및 완전 연결 프로세싱이 수 행된다. 확률은 대응하는 이미지 블록이 타깃 가상 객체를 포함할 확률이다. 다수의 확률 중 임의의 확률이 확률 임계치 이상인 것에 응답하여, 제1 비디오 프레임의 타입이 제1 타입으로서 결정된다. 제1 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이한다는 것을 지시한다. 다수의 확률 각각이 확률 임계치 미만인 것에 응답하여, 제1 비디오 프레임의 타입이 제2 타입으로서 결정된다. 제2 타입은, 제1 비디오 프레임이 타깃 가상 객체를 디스플레이하지 않는다는 것을 지시한다. 가능한 구현에서, 장치는, 제1 단말기에 대응하는 제3 비디오 프레임을 획득하도록 구성된 제3 비디오 프레임 획득 모듈을 더 포함한다. 제3 비디오 프레임은, 타깃 가상 장면에서 타깃 이벤트가 발생한 후, 피제어 가상 객체의 시점으로부터 타깃 가 상 장면을 렌더링함으로써 획득되는 비디오 프레임이다. 타깃 이벤트는, 피제어 가상 객체가 타깃 가상 장면의 제1 가상 객체를 물리치는 것이다. 렌더링 모듈은 추가로, 타깃 이벤트에 대응하는 제1 애니메이션 및 타깃 이벤트에 대응하는 제1 오디오를 획득하도록 구성된다. 제1 오디오는 제1 단말기의 오디오이다. 제1 가상 객체가 패배하는 영역이 제3 비디오 프레임에서 결정된다. 제4 비디오 프레임을 획득하기 위해 타깃 이벤트에 대응하는 제1 애니메이션이 구역에 추가된다. 전송 모듈은 추가로, 제4 비디오 프레임 및 제1 오디오를 제1 단말기에 전송하도록 구성된다. 제1 단말기 는 제4 비디오 프레임을 디스플레이하면서 제1 오디오를 플레이하도록 구성된다. 가능한 구현에서, 타깃 가상 장면은 제2 가상 객체를 더 포함한다. 제2 가상 객체는 제2 단말기에 의해 제어되 는 가상 객체이다. 제2 단말기 및 제2 단말기는 상이한 단말기이다. 장치는, 제2 단말기에 대응하는 제5 비디오 프레임을 획득하도록 구성된 제5 비디오 프레임 획득 모듈을 더 포함한다. 제5 비디오 프레임은 제2 가상 객체의 시점으로부터 타깃 가상 장면을 렌더링함으로써 획득되는 비디오 프레임 이다. 렌더링 모듈은 추가로, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제5 비디오 프레임에 대해 타깃 프로세싱을 수행하도록 구성된다. 전송 모듈은 추가로, 제6 비디오 프레임을 제2 단말기에 전송하도록 구성된다. 제2 단말기는 제6 비디오 프레임을 디스플레이하도록 구성된다. 가능한 구현에서, 렌더링 모듈은 추가로, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제2 단말기의 제2 파라미터에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 조작; 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제1 파라미터 에 기반하여 제5 비디오 프레임 내의 타깃 가상 객체를 렌더링하는 조작; 및 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 제6 비디오 프레임을 획득하기 위해 제5 비디오 프레임에 타깃 가상 객체에 대응하는 제2 애니메이션을 추가하는 조작 중 임의의 조작을 수행하도록 구성된다. 가능한 구현에서, 피제어 가상 객체 및 제2 가상 객체는 타깃 가상 장면의 타깃 서브-장면에 동시에 위치된다. 렌더링 모듈은 추가로, 제5 비디오 프레임이 타깃 가상 객체를 디스플레이하는 경우, 피제어 가상 객체 및제2 가상 객체의 가상 레벨을 비교하도록 구성된다. 제5 비디오 프레임 내의 타깃 가상 객체는, 피제어 가상 객체의 가상 레벨이 제2 가상 객체의 가상 레벨보다 높은 경우, 제6 비디오 프레임을 획득하기 위해 제1 파라미 터에 기반하여 렌더링된다. 제5 비디오 프레임 내의 타깃 가상 객체는, 피제어 가상 객체의 가상 레벨이 제2 가상 객체의 가상 레벨보다 낮은 경우, 제6 비디오 프레임을 획득하기 위해 제2 단말기의 제2 파라미터에 기반 하여 렌더링된다. 제5 비디오 프레임 내의 타깃 가상 객체는, 피제어 가상 객체의 가상 레벨이 제2 가상 객체 의 가상 레벨과 동일한 경우, 제6 비디오 프레임을 획득하기 위해 제3 파라미터에 기반하여 렌더링된다. 가능한 구현에서, 렌더링 모듈은 추가로, 타깃 가상 객체에 대응하는 제2 애니메이션 및 제2 오디오를 획 득하도록 구성된다. 제7 비디오 프레임을 획득하기 위해 타깃 가상 객체에 대응하는 제2 애니메이션이 제2 비 디오 프레임에 추가된다. 전송 모듈은 추가로, 제7 비디오 프레임 및 제2 오디오를 제1 단말기에 전송하도록 구성된다. 제1 단말기 는 제7 비디오 프레임을 디스플레이하면서 제2 오디오를 플레이하도록 구성된다. 가능한 구현에서, 장치는 비디오 프레임 세트 생성 모듈을 더 포함한다. 비디오 프레임 세트 생성 모듈은, 다수의 제2 비디오 프레임을 제1 비디오 프레임 세트로 합산하고, 그리고 제1 비디오 프레임을 제1 단말기에 전 송하는 조작 ― 제1 단말기는 제1 비디오 프레임 세트를 다른 단말기와 공유하도록 구성됨 ―; 스티칭된 비디오 프레임을 획득하기 위해 제2 비디오 프레임 및 제1 비디오 프레임을 스티칭하는 조작; 및 다수 의 스티칭된 비디오 프레임을 제2 비디오 프레임 세트로 합산하고, 그리고 제2 비디오 프레임 세트를 제1 단말 기에 전송하는 조작 - 제1 단말기는 제2 비디오 프레임 세트를 다른 단말기와 공유하도록 구성됨 - 중 임의의 조작을 수행하도록 구성된다. 가능한 구현에서, 장치는, 클라이언트 서버로부터 제1 파라미터를 획득하도록 구성된 파라미터 획득 모듈을 더 포함한다. 클라이언트 서 버는, 타깃 가상 객체에 대해 제1 단말기에 의해 업로딩된 설정 파라미터에 기반하여 타깃 가상 객체의 3-차원 모델을 생성하도록 구성된다. 제1 파라미터는 3-차원 모델의 다수의 렌더링 파라미터를 포함한다. 상기 실시예에서 제공되는 비디오 프레임 렌더링 장치에 의해 비디오 프레임에 대해 수행되는 2차 렌더링은 비 디오 프레임 렌더링 장치의 상기 기능 모듈에 의해 예시된다. 실제 적용에서, 상기 기능은 완료를 위해 상이한 기능 모듈에 할당될 수 있는데, 즉, 서버는 위에서 설명된 기능의 전부 또는 일부를 완료하기 위해 상이한 기능 모듈로 분할될 수 있다. 또한, 상기 실시예에 의해 제공되는 비디오 프레임 렌더링 장치 및 비디오 프레임 렌 더링 방법은 동일한 개념을 공유한다. 특정 구현 프로세스에 대해서는 방법 실시예를 참조할 수 있으며, 세부 사항은 여기서 다시 설명되지 않는다. 본 개시내용의 실시예들에 의해 제공되는 기술적 솔루션에 따라, 특정 가상 객체의 디스플레이 효과를 변경하고 자 하는 경우, 제1 파라미터가 가상 객체에 대해 제1 단말기에 의해 결정되고, 그리고 서버는 제2 비디오 프레 임을 획득하기 위해 제1 파라미터에 기반하여 제1 비디오 프레임에 대해 2차 렌더링을 수행한다. 제1 비디오 프레임과 비교하여, 제2 비디오 프레임에 디스플레이되는 가상 객체의 디스플레이 효과는 또한, 가상 객체에 대 해 제1 단말기에 의해 구성된 디스플레이 효과이기도 하다. 이러한 기술적 솔루션에 따라, 가상 객체에 대해 2 차 렌더링을 수행하는 기능이 클라우드 애플리케이션에서 달성되고, 그리고 사용자가 가상 장면의 특정 가상 객 체의 디스플레이 효과를 빠르고 효율적으로 조정할 수 있고, 이로써 클라우드 애플리케이션의 기능 범위가 확장 되고 클라우드 애플리케이션의 개인화가 개선된다. 따라서, 클라우드 애플리케이션이 더 광범위하게 전파된다. 서버의 구조가 아래에서 설명된다. 도 9는 본 개시내용의 실시예에 따른 서버의 개략적 구조 다이어그램이다. 서버는 상이한 구성 또는 성능 을 가질 수 있으며, 하나 이상의 CPU(central processing unit) 및 하나 이상의 메모리를 포함할 수 있다. 하나 이상의 메모리는 적어도 하나의 컴퓨터 프로그램을 저장한다. 적어도 하나의 컴퓨터 프로그 램은 각각의 방법 실시예에 의해 제공되는 방법을 구현하기 위해 하나 이상의 프로세서에 의해 로딩되고 실행된다. 물론, 서버는 또한, 입력 및 출력을 수행하기 위해, 유선 또는 무선 네트워크 인터페이스, 키 보드, 및 입력/출력 인터페이스 등을 가질 수 있다. 서버는 디바이스 기능을 구현하기 위해 다른 컴포넌 트를 더 포함할 수 있으며, 이에 대해서는 여기서 상세히 설명되지 않는다. 예시적 실시예에 있어서, 컴퓨터-판독가능 저장 매체에는, 예를 들어, 컴퓨터 프로그램을 포함하는 메모리가 제 공된다. 상기 실시예에서의 비디오 프레임 렌더링 방법을 수행하기 위해, 상기 컴퓨터 프로그램이 프로세서에의해 실행될 수 있다. 예를 들어, 컴퓨터-판독가능 저장 매체는, ROM(read-only memory), RAM(random-access memory), CD-ROM(compact disc read-only memory), 자기 테이프, 플로피 디스크, 광학 데이터 저장 디바이스 등일 수 있다. 예시적 실시예에서, 컴퓨터 프로그램 제품 또는 컴퓨터 프로그램이 제공된다. 컴퓨터 프로그램 제품 또는 컴퓨 터 프로그램은 프로그램 코드를 포함한다. 프로그램 코드는 컴퓨터-판독가능 저장 매체에 저장된다. 컴퓨터 디바이스의 프로세서는 컴퓨터-판독가능 저장 매체로부터 프로그램 코드를 판독한다. 컴퓨터 디바이스가 비디 오 프레임 렌더링 방법을 수행하도록, 프로세서가 프로그램 코드를 실행한다. 즉, 프로그램 코드는 비디오 프 레임 렌더링 방법을 구현하기 위해 프로세서에 의해 실행된다. 일부 실시예들에서, 본 개시내용의 실시예들에 관여된 컴퓨터 프로그램은, 하나의 컴퓨터 디바이스 상에서, 또 는 한 포지션에 위치된 다수의 컴퓨터 디바이스 상에서, 또는 다수의 포지션에 분산되고 통신 네트워크를 통해 상호연결된 다수의 컴퓨터 디바이스 상에서 실행되도록 배포될 수 있다. 다수의 포지션에 분산되고 통신 네트 워크를 통해 상호연결된 다수의 컴퓨터 디바이스는 블록 체인 시스템을 형성할 수 있다. 당업자는, 전술한 실시예의 단계 중 전부 또는 일부가 하드웨어를 사용하여 구현될 수도 있거나, 또는 관련 하 드웨어에 명령하는 프로그램에 의해 구현될 수 있다는 것을 이해할 수 있다. 프로그램은 컴퓨터-판독가능 저장 매체에 저장될 수 있다. 상기 저장 매체는 판독-전용 메모리, 자기 디스크, 광 디스크 등일 수 있다. 전술한 설명은 단지 본 개시내용의 선택적 실시예일 뿐이며, 본 개시내용을 제한하려는 의도가 아니다. 본 개 시내용의 사상 및 원리를 벗어남 없이 이루어지는 임의의 수정, 등가 교체, 개선은 본 개시내용의 보호 범위 내 에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2023-7030586", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시내용의 실시예의 기술적 솔루션을 보다 명확하게 설명하기 위해, 실시예의 설명에 사용되는 데 필요한 도면이 아래에서 간단히 소개될 것이다. 분명히, 다음 설명에서의 도면은 본 개시내용의 일부 실시예만을 도시 한다. 당업자는 창의적인 작업 없이도 이들 도면에 따라 다른 도면을 추가로 얻을 수 있다. 도 1은 본 개시내용의 실시예에 따른 비디오 프레임 렌더링 방법의 구현 환경의 개략적 다이어그램이다. 도 2는 본 개시내용의 실시예에 따른 비디오 프레임 렌더링 방법의 흐름도이다. 도 3은 본 개시내용의 실시예에 따른 비디오 프레임 렌더링 방법의 흐름도이다. 도 4는 본 개시내용의 실시예에 따른 인터페이스의 개략적 다이어그램이다. 도 5는 본 개시내용의 실시예에 따른 인터페이스의 개략적 다이어그램이다. 도 6은 본 개시내용의 실시예에 따른 비디오 프레임 렌더링 방법의 흐름도이다. 도 7은 본 개시내용의 실시예에 따른 인터페이스의 개략적 다이어그램이다. 도 8은 본 개시내용의 실시예에 따른 비디오 프레임 렌더링 장치의 개략적 구조 다이어그램이다. 도 9는 본 개시내용의 실시예에 따른 서버의 개략적 구조 다이어그램이다."}
