{"patent_id": "10-2024-0064227", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0167585", "출원번호": "10-2024-0064227", "발명의 명칭": "동적 영상 데이터 기반 대상체 상태 예측 방법 및 이를 수행하는 컴퓨팅 장치", "출원인": "재단법인 아산사회복지재단", "발명자": "김재승"}}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해 수행되는 방법으로서,학습 대상체에 약품이 주입된 후 미리 설정된 시점까지의 초기 구간에 대응하는 초기 동적 영상 데이터를 획득하는 단계;상기 초기 구간 중 제1 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 상기 제1 구간 보다 앞선 시점에 대응하는 상기 학습 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내는 제1 영상 데이터를 예측하는제1 예측 모델을 학습하는 단계; 및 상기 초기 구간 중 제2 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 상기 초기 구간 이후 기준 시점에 대응하는 상기 학습 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이터를 예측하는 제2 예측 모델을 학습하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,진단 대상체에 상기 약품이 주입된 후 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 획득하는 단계; 및상기 진단 대상체의 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제1 예측 모델에입력하여, 상기 앞선 시점에 대응하는 상기 진단 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내는 제1 영상 데이터를 예측하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 진단 대상체에 상기 약품이 주입된 후 상기 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하는 단계;및상기 진단 대상체의 상기 제2 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제2 예측 모델에입력하여, 상기 기준 시점에 대응하는 상기 진단 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이터를 예측하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,미리 설정된 양만큼 감소한 상기 약품이 상기 진단 대상체에 주입되고, 이에 기반하여 상기 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고 가공하여, 상기 가공된제1 구간에 대응하는 초기 동적 영상 데이터 및 상기 가공된 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고,상기 가공된 제1 구간에 대응하는 초기 동적 영상 데이터를 상기 제1 예측 모델에 입력하고, 상기 가공된 제2구간에 대응하는 초기 동적 영상 데이터를 제2 예측 모델에 입력하도록 구성되는, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 학습 대상체에 주입된 약품의 양은 기준량 보다 감소한 양이며,공개특허 10-2024-0167585-3-상기 제1 예측 모델은 상기 제1 영상 데이터에 대응하는 제1 레이블 영상 데이터에 기반하여 학습되고, 상기 제2 예측 모델은 상기 제2 영상 데이터에 대응하는 제2 레이블 영상 데이터에 기반하여 학습되되, 상기 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터는, 상기 학습 대상체의 약품 주입량에 따라 가공된 레이블 영상 데이터인, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 학습 대상체 및 진단 대상체의 제1 구간에 대응하는 초기 동적 영상 데이터가 제1 예측 모델에 입력되기전에 공간 정규화(spatial normalization)를 수행하는 단계; 및상기 학습 대상체 및 진단 대상체의 제2 구간에 대응하는 초기 동적 영상 데이터가 제2 예측 모델에 입력되기전에 공간 정규화를 수행하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서,상기 프로세서는,상기 학습 대상체 및 상기 진단 대상체의 상기 초기 구간 중 제1 구간에 대응하는 초기 동적 영상 데이터의 획득 타임 구간을 설정하고,상기 학습 대상체 및 상기 진단 대상체의 상기 초기 구간 중 제2 구간에 대응하는 초기 동적 영상 데이터의 획득 타임 구간을 설정하도록 구성되는, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서,상기 프로세서는,상기 진단 대상체에 약품이 주입되는 경우 상기 초기 구간을 확인하고, 확인된 초기 구간에 기초하여 제1 구간및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하도록 구성되는, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 획득된 초기 동적 영상 데이터, 상기 제1 영상 데이터 및 상기 제2 영상 데이터는 양전자 방출 단층 촬영(PET: Positron Emission Tomography) 영상 데이터인, 방법."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "동적 영상 데이터 기반 대상체 상태 예측 장치로서,메모리;및 상기 메모리와 통신을 수행하는 적어도 하나의 프로세서를 포함하고,상기 프로세서는,학습 대상체에 약품이 주입된 후 미리 설정된 시점까지의 초기 구간에 대응하는 초기 동적 영상 데이터를 획득하고, 상기 초기 구간 중 제1 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 상기 제1 구간 보다 앞선 시점에 대응하는 상기 학습 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내는 제1 영상 데이터를예측하는 제1 예측 모델을 학습하며, 상기 초기 구간 중 제2 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 상기 초기 구간 이후 기준 시점에 대응하는 상기 학습 대상체에 대한 질병 특이적 정보를 나타내는 제2영상 데이터를 예측하는 제2 예측 모델을 학습하도록 구성되는, 장치."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0167585-4-제10항에 있어서,상기 프로세서는,진단 대상체에 상기 약품이 주입된 후 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 획득하고,상기 진단 대상체의 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제1 예측 모델에입력하여, 상기 앞선 시점에 대응하는 상기 진단 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내는 제1 영상 데이터를 예측하도록 구성되는, 장치."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는,상기 진단 대상체에 상기 약품이 주입된 후 상기 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고,상기 진단 대상체의 상기 제2 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제2 예측 모델에입력하여, 상기 기준 시점에 대응하는 상기 진단 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이터를 예측하도록 구성되는, 장치."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는,미리 설정된 양만큼 감소한 상기 약품이 상기 진단 대상체에 주입되고, 이에 기반하여 상기 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고 가공하여, 상기 가공된제1 구간에 대응하는 초기 동적 영상 데이터 및 상기 가공된 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고,상기 가공된 제1 구간에 대응하는 초기 동적 영상 데이터를 상기 제1 예측 모델에 입력하고, 상기 가공된 제2구간에 대응하는 초기 동적 영상 데이터를 제2 예측 모델에 입력하도록 구성되는, 장치."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 학습 대상체에 주입된 약품의 양은 기준량 보다 감소한 양이며,상기 제1 예측 모델은 상기 제1 영상 데이터에 대응하는 제1 레이블 영상 데이터에 기반하여 학습되고, 상기 제2 예측 모델은 상기 제2 영상 데이터에 대응하는 제2 레이블 영상 데이터에 기반하여 학습되되, 상기 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터는, 상기 학습 대상체의 약품 주입량에 따라 가공된 레이블 영상 데이터인, 장치."}
{"patent_id": "10-2024-0064227", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 프로세서는,상기 학습 대상체 및 진단 대상체의 제1 구간에 대응하는 초기 동적 영상 데이터가 제1 예측 모델에 입력되기전에 공간 정규화를 수행하고, 상기 학습 대상체 및 진단 대상체의 제2 구간에 대응하는 초기 동적 영상 데이터가 제2 예측 모델에 입력되기전에 공간 정규화를 수행하도록 구성되는, 장치."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "동적 영상 데이터 기반으로 대상체의 상태를 예측하는 장치가 개시된다. 본 장치는, 메모리 및 메모리와 통신을 수행하는 적어도 하나의 프로세서를 포함한다. 프로세서는, 학습 대상체에 약품이 주입된 후 미리 설정된 시점까 지의 초기 구간에 대응하는 초기 동적 영상 데이터를 획득하고, 초기 구간 중 제1 구간에 대응하는 초기 동적 영 상 데이터를 입력으로 하여 제1 구간 보다 앞선 시점에 대응하는 학습 대상체에 대한 해부학적 정보를 나타내는 제1 영상 데이터를 예측하는 제1 예측 모델을 학습하며, 초기 구간 중 제2 구간에 대응하는 초기 동적 영상 데이 터를 입력으로 하여 초기 구간 이후 기준 시점에 대응하는 학습 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이터를 예측하는 제2 예측 모델을 학습할 수 있다. 이에 따라, 사용자 편의가 제고될 수 있다."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 의료 관련 기술에 관한 것이다. 보다 상세하게는, 본 개시는 동적 영상 데이터 기반으로 진단 대상자 의 상태를 예측하는 방법 및 이를 수행하는 컴퓨팅 장치에 관한 것이다."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "PET(Positron Emission Tomography) 검사는 양전자 방출 방사성 동위원소를 대상자에 투여하고, 이때 몸 밖으로 방출되는 방사선을 획득하여 인체의 대사 변화 및 수용체 분포에 관련된 유용한 진단적 정보들을 얻어내는 최첨 단의 핵의학 영상 검사법이다. 최근에는 단순한 PET 영상만을 획득하는 것에서 한발 더 나아가 CT(Computed Tomography) 혹은 MRI(Magnetic Resonance Image) 기술까지 융합한 하이브리드 스캐너(Hybrid Scanner) 형태로 더욱 발전하고 있다. 이에, 최근의 PET 검사에서는 PET 장치와 CT 장치를 하나로 결합한 PET/CT 스캐너를 사용하여, CT 영상의 해부 학적 정보를 얻게 되어 PET 영상에서 확인된 병변의 정확한 위치 및 깊이 정보까지 제공할 수 있게 되었다. 통상적으로 PET 검사는 방사성 동위원소가 표지된 트레이서(Tracer)를 인체 내에 주사한 후 트레이서 특이 결합 과 비특이 결합이 안정 상태에 도달하거나 그 차이가 최대가 되는 특정한 시간(예를 들어, 1시간 30분 내지 3시 간)이 경과된 이후에 획득되는 PET 영상을 기반으로 환자 진단을 수행한다. 다만, PET 영상 기반의 진단이 트레이서 주사 후 비교적 늦은 시점에 수행되게 되므로, 이를 개선하는 방법이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2024-0016368호(공개일: 2020.01.06)"}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서 해결하고자 하는 일 과제는 동적 영상 데이터 기반으로 진단 대상자의 상태를 예측하는 방법을 제 공하는 데에 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 동적 영상 데이터 기반 대상체 상태 예측을 위해 적어도 하나의 프로세서에 의해 수행되는 방법은, 학습 대상체에 약품이 주입된 후 미리 설정된 시점까지의 초기 구간에 대응하는 초기 동적 영 상 데이터를 획득하는 단계; 상기 초기 구간 중 제1 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 상기 제1 구간 보다 앞선 시점에 대응하는 상기 학습 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내 는 제1 영상 데이터를 예측하는 제1 예측 모델을 학습하는 단계; 및 상기 초기 구간 중 제2 구간에 대응하는 초 기 동적 영상 데이터를 입력으로 하여 상기 초기 구간 이후 기준 시점에 대응하는 상기 학습 대상체에 대한 질 병 특이적 정보를 나타내는 제2 영상 데이터를 예측하는 제2 예측 모델을 학습하는 단계를 포함한다. 상기 방법은, 진단 대상체에 상기 약품이 주입된 후 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 획득하 는 단계; 및 상기 진단 대상체의 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제1 예측 모 델에 입력하여, 상기 앞선 시점에 대응하는 상기 진단 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내 는 제1 영상 데이터를 예측하는 단계를 더 포함할 수 있다. 상기 방법은, 상기 진단 대상체에 상기 약품이 주입된 후 상기 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하는 단계; 및 상기 진단 대상체의 상기 제2 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제2 예 측 모델에 입력하여, 상기 기준 시점에 대응하는 상기 진단 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이터를 예측하는 단계를 더 포함할 수 있다. 상기 프로세서는, 미리 설정된 양만큼 감소한 상기 약품이 상기 진단 대상체에 주입되고, 이에 기반하여 상기 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고 가공하 여, 상기 가공된 제1 구간에 대응하는 초기 동적 영상 데이터 및 상기 가공된 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고, 상기 가공된 제1 구간에 대응하는 초기 동적 영상 데이터를 상기 제1 예측 모델에 입 력하고, 상기 가공된 제2 구간에 대응하는 초기 동적 영상 데이터를 제2 예측 모델에 입력할 수 있다. 상기 학습 대상체에 주입된 약품의 양은 기준량 보다 감소한 양이며, 상기 제1 예측 모델은 상기 제1 영상 데이 터에 대응하는 제1 레이블 영상 데이터에 기반하여 학습되고, 상기 제2 예측 모델은 상기 제2 영상 데이터에 대 응하는 제2 레이블 영상 데이터에 기반하여 학습되되, 상기 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터 는, 상기 학습 대상체의 약품 주입량에 따라 가공된 레이블 영상 데이터일 수 있다. 상기 방법은, 보다 소수의 학습 대상체 자료를 통한 기계 학습이 가능하도록 상기 학습 대상체 및 진단 대상체 의 제1 구간에 대응하는 초기 동적 영상 데이터가 제1 예측 모델에 입력되기 전에 공간 정규화(spatial normalization)를 수행하는 단계; 및 상기 학습 대상체 및 진단 대상체의 제2 구간에 대응하는 초기 동적 영상 데이터가 제2 예측 모델에 입력되기 전에 공간 정규화(spatial normalization)를 수행하는 단계를 더 포함할 수 있다. 상기 프로세서는, 상기 학습 대상체 및 상기 진단 대상체의 상기 초기 구간 중 제1 구간에 대응하는 초기 동적 영상 데이터의 획득 타임 구간을 설정하고, 상기 학습 대상체 및 상기 진단 대상체의 상기 초기 구간 중 제2 구 간에 대응하는 초기 동적 영상 데이터의 획득 타임 구간을 설정할 수 있다. 상기 프로세서는, 상기 진단 대상체에 약품이 주입되는 경우 상기 초기 구간을 확인하고, 확인된 초기 구간에 기초하여 제1 구간 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득할 수 있다. 상기 획득된 초기 동적 영상 데이터, 상기 제1 영상 데이터 및 상기 제2 영상 데이터는 양전자 방출 단층 촬영 (PET) 영상데이터일 수 있다. 본 발명의 일 실시예에 따른 동적 영상 데이터 기반 대상체 상태 예측 장치는, 메모리; 및 상기 메모리와 통신 을 수행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 프로세서는, 학습 대상체에 약품이 주입된 후 미리 설정된 시점까지의 초기 구간에 대응하는 초기 동적 영 상 데이터를 획득하고, 상기 초기 구간 중 제1 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 상기 제1 구간 보다 앞선 시점에 대응하는 상기 학습 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내는 제1 영상 데이터를 예측하는 제1 예측 모델을 학습하며, 상기 초기 구간 중 제2 구간에 대응하는 초기 동적 영상 데 이터를 입력으로 하여 상기 초기 구간 이후 기준 시점에 대응하는 상기 학습 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이터를 예측하는 제2 예측 모델을 학습할 수 있다. 상기 프로세서는, 진단 대상체에 상기 약품이 주입된 후 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 획 득하고, 상기 진단 대상체의 상기 제1 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제1 예측 모델에 입력하여, 상기 앞선 시점에 대응하는 상기 진단 대상체에 대한 해부학적 정보 또는 혈류적 정보를 나타내는 제 1 영상 데이터를 예측할 수 있다. 상기 프로세서는, 상기 진단 대상체에 상기 약품이 주입된 후 상기 제2 구간에 대응하는 초기 동적 영상 데이터 를 획득하고, 상기 진단 대상체의 상기 제2 구간에 대응하는 초기 동적 영상 데이터를 학습된 상기 제2 예측 모 델에 입력하여, 상기 기준 시점에 대응하는 상기 진단 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데 이터를 예측할 수 있다. 상기 프로세서는, 미리 설정된 양만큼 감소한 상기 약품이 상기 진단 대상체에 주입되고, 이에 기반하여 상기 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고 가공하 여, 상기 가공된 제1 구간에 대응하는 초기 동적 영상 데이터 및 상기 가공된 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고, 상기 가공된 제1 구간에 대응하는 초기 동적 영상 데이터를 상기 제1 예측 모델에 입 력하고, 상기 가공된 제2 구간에 대응하는 초기 동적 영상 데이터를 제2 예측 모델에 입력할 수 있다. 상기 학습 대상체에 주입된 약품의 양은 기준량 보다 감소한 양이며, 상기 제1 예측 모델은 상기 제1 영상 데이 터에 대응하는 제1 레이블 영상 데이터에 기반하여 학습되고, 상기 제2 예측 모델은 상기 제2 영상 데이터에 대 응하는 제2 레이블 영상 데이터에 기반하여 학습되되, 상기 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터는, 상기 학습 대상체의 약품 주입량에 따라 가공된 레이블 영상 데이터일 수 있다. 상기 프로세서는, 상기 학습 대상체 및 진단 대상체의 제1 구간에 대응하는 초기 동적 영상 데이터가 제1 예측 모델에 입력되기 전에 공간 정규화(spatial normalization)를 수행하고, 상기 학습 대상체 및 진단 대상체의 제 2 구간에 대응하는 초기 동적 영상 데이터가 제2 예측 모델에 입력되기 전에 공간 정규화(spatial normalization)를 수행할 수 있다."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "핵의학 분자 영상의 특징인 약품 주입 후 영상 추적자(트레이서)의 체내 분포를 위해 대기하는 섭취 시간이 길 게는 수시간 소요될 수 밖에 없는데, 본 개시의 다양한 실시예에 따르면, 약품 주입 후 초기 동적 영상 데이터 만으로 초기 혈류 영상 데이터 및 지연 섭취 영상 데이터가 동시에 생성될 수 있으며, 진단 대기의 시간이 비약 적으로 감소함으로써, 사용자 편의가 크게 제고될 수 있다."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명한다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 게시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현"}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "될 수 있으며, 단지 본 실시예들은 본 발명의 게시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다.다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 본 명세서에서 '컴퓨팅 장치'은 연산처리를 수행하는 다양한 장치들이 모두 포함된다. '컴퓨팅 장치'은 하나 이 상의 컴퓨터를 포함할 수 있다. 예를 들어, 컴퓨터는 데스크 탑 PC, 노트북(Note Book) 뿐만 아니라 스마트폰 (Smart phone), 태블릿 PC, 셀룰러폰(Cellular phone), 피씨에스폰(PCS phone; Personal Communication Service phone), 동기식/비동기식 IMT-2000(International Mobile Telecommunication-2000)의 이동 단말기, 팜 PC(Palm Personal Computer), 개인용 디지털 보조기(PDA; Personal Digital Assistant) 등도 해당될 수 있다. 또한, 컴퓨터는 의료영상을 획득하거나 관찰하는 의료장비도 해당될 수 있다. 또한, 컴퓨터는 다양한 클라이언 트 컴퓨터와 연결되는 서버 컴퓨터가 해당될 수 있다. 본 명세서에서 '영상 데이터'는 의료 영상 촬영 장치에 의해 획득되는 영상을 의미한다. 본 명세서에서 '의료 영상 촬영 장치'는 의료 영상 획득에 이용되는 기기를 의미한다. 예를 들어, '의료 영상 촬영 장치'는 양전자 방출 단층촬영(Positron Emission Tomography) 영상 촬영 기기, 자기 공명 영상(Magnetic Resonance Imaging; MRI) 촬영 기기 등을 포함할 수 있다. 본 명세서에서 '딜레이(Delay) 영상 데이터'는 기준 시간 후에 획득되는 것으로서, 환자 진단에 이용되는 진단 용 영상을 의미한다. 본 명세서에서 '기준 시간'은 약품(예를 들어, 조영제 또는 트레이서)을 인체에 주입한 최초 시점으로부터 환자 상태가 진단 가능한 영상데이터를 획득 가능한 시점(즉, 기준 시점)까지의 시간을 의미한다. 본 명세서에서 '약품'은 의료 영상 데이터 촬영 시에 신체 내부에 주입되는 것을 의미한다. 예를 들어, '약품' 은 자기 공명 영상(Magnetic Resonance Imaging; MRI) 촬영 또는 컴퓨터 단층 촬영(Computed Tomography; CT) 에 이용되는 조영제, 양전자 방출 단층 촬영(Positron Emission Tomography) 시에 이용되는 트레이서(Tracer) 등이 해당될 수 있다. 본 명세서에서 '초기 동적 영상 데이터'는 연속적인 복수의 영상 프레임을 포함하는 영상 데이터로, '초기 동적 영상 데이터'는 딜레이 영상 데이터가 획득되는 기준 시점보다 이전에 획득되는 것으로서, 초기 시간범위(예를 들어, 영상 촬영 시에 투여되는 조영제 또는 트레이서를 삽입한 후 짧은 시간 이후의 시간 범위)에 획득되는 것 이다. 본 명세서에서 동적 영상 데이터는 영상 데이터에서 초기 동적 영상 데이터와 딜레이 영상 데이터를 제외한 영 상 데이터를 의미할 수 있다. 구체적으로 동적 영상 데이터는 복수의 영상 데이터 내에 각각 포함된 학습 대상체의 약품 주입 시점 이후, 혈 류 영향이 감소하기 시작하는 시간부터 미리 결정된 기준 시점까지의 재생 구간 영상을 의미할 수 있다. 본 명세서에서 해부학적 정보는, 대상체의 구조와 기능에 관한 정보일 수 있으며, 대상체의 혈류의 흐름이 나타 난 혈류적 정보를 포함하는 영상 데이터를 포함할 수 있다. 본 명세서에서 질병 특이적 정보는, 약품이 특정 목표 위치(가령, 장기나 조직 등)에 남아 대상체의 상태 판단 에 이용될 수 있는 영상 데이터를 의미할 수 있다. 이하, 도면을 참조하여 본 발명의 실시예들에 따른 초기 동적 영상데이터 기반 진단용 영상 생성방법 및 프로그 램에 대한 상세한 설명을 기재한다. 도 1은 본 개시에 따른 동적 영상 데이터 기반으로 대상체의 상태를 예측하는 방법을 나타내는 전체 개요도이며, 동적 영상 데이터 기반 대상체 상태 예측 장치(100, 이하 '대상체 상태 예측 장치')에 의해 수행될 수 있다.대상체 상태 예측 장치는 초기 동적 영상 데이터를 획득할 수 있다. 초기 동적 영상 데이터는 약 품이 트레이서를 통해 대상체에 주입된 후, 미리 설정된 시점까지의 초기 구간에 대응할 수 있다. 초기 동적 영 상 데이터는 복수의 영상 프레임을 포함할 수 있으며, 복수의 영상 프레임 각각은 1분 또는 2분 주기로 획 득될 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 여기서, 미리 설정된 시점은 대상체의 혈류에 포함된 방사선량의 피크(peak)를 기준으로 소정 범위의 시점일 수 있다. 또한, 초기 구간은 트레이서의 종류에 다를 수 있으며, 진단 대상체의 기질적 요인에 따라 다를 수 있다. 대상체 상태 예측 장치는 획득된 초기 동적 영상 데이터를 제1 예측 모델(EM1) 및 제2 예측 모델(EM 2)에 입력할 수 있다(S11, S12). 이 경우, 제1 예측 모델(EM1)에는 초기 동적 영상 데이터 중 제1 구간에 대응하는 초기 동적 영상 데이터가 입력될 수 있고, 제2 예측 모델(EM2)에는 초기 동적 영상 데이터 중 제2 구간에 대응하는 초기 동적 영상 데이터가 입력될 수 있으나, 실시예에 따라, 대상체 상태 예측 장치는 동일한 초기 동적 영상 데이터 를 제1 예측 모델(EM1) 및 제2 예측 모델(EM2)에 입력할 수 있다. 제1 예측 모델(EM1)은 입력된 초기 동적 영상 데이터에 기초하여 극초기(True Early) 영상 데이터를 예측할 수 있다(S21). 극초기 영상 데이터는 약품 주입 후 미리 설정된 짧은 기간에 대응하는 동적 영상 데이터 또는 특정 시점의 영상 데이터일 수 있다. 또한, 제2 예측 모델(EM2)은 입력된 초기 동적 영상 데이터에 기초하여 딜레이 영상 데이터를 예측할 수 있 다(S21). 딜레이 영상 데이터는 초기 기간 이후 기준 시점에 대응하는 동적 영상 데이터 또는 특정 시점의 영상 데이터일 수 있다. 또한, 제1 구간에 대응하는 초기 동적 영상 데이터, 제2 구간에 대응하는 초기 동적 영상 데이터, 극초기 영상 데이터, 딜레이 영상 데이터는 모두 양전자 방출 단층 촬영(PET: Positron Emission Tomography) 영상 데이터 일 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 도 2는 본 개시에 따른 대상체 상태 예측 장치의 구성을 나타내는 블록도이다. 도 2를 참고하면, 대상체 상태 예측 장치는 의료 영상 촬영 장치를 포함하거나 의료 영상 촬영 장치로부터 촬영된 영상 데이터를 이용할 수 있으며, 통신부, 입력부, 디스플레이, 메모리 및 적어도 하나의 프로세서를 포함할 수 있다. 도 2에 도시된 대상체 상태 예측 장치의 구성요소들은 본 개시에 따른 대상체 상태 예측 장치를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 대 상체 상태 예측 장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 상기 구성요소들 중 통신부는, 통신 장치를 구비한 다양한 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으며, 예를 들어, 인공위성 장치, 유선통신 장치, 셀룰러 기반의 무선통신 장치, IEEE 802.11 기반(예를 들어, Wifi로 명명될 수도 있음)의 무선 통신 장치, 근거리 통신(예를 들어, 블루투스, 블루 투스 저에너지, UWB, 지그비일 수 있지만 제한이 없음) 기반의 통신 장치, 위치정보 모듈 중 적어도 하나를 포 함할 수 있다. 입력부는 영상 정보(또는 신호), 오디오 정보(또는 신호), 데이터, 또는 사용자로부터 입력되는 정보의 입 력을 위한 것으로서, 적어도 하나의 카메라, 터치 스크린에 구비된 터치 입력 장치 및/또는 적어도 하나의 마이 크로폰을 포함할 수 있으나, 제한은 없다. 입력부에서 수집한 터치 스크린에 대한 터치 입력, 음성 데이터, 및/또는 이미지 데이터는 분석되어 사용자의 제어 명령으로서 처리될 수 있다. 입력부는 각종 입 력을 위한 기기(inputter)를 포함할 수 있다. 카메라는 촬영 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화상 프레임을 처리한다. 처 리된 화상 프레임은 디스플레이(130, 또는 본 개시의 대상체 상태 예측 장치의 화면)에 표시되거나 메모리 에 저장될 수 있다. 마이크로폰은 외부의 음향 신호를 전기적인 음성 데이터로 처리한다. 처리된 음성 데이터는 본 장치에서 수행 중인 기능(또는 실행 중인 응용 프로그램)에 따라 다양하게 활용될 수 있다. 한편, 마이크는 외부의 음향 신호 를 입력 받는 과정에서 발생되는 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알고리즘이 구현될 수 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이, 적어도 하나의 스피커, 햅틱 모듈 및 광 출력 기기 중 적어도 하나를 포함할 수 있다. 디스플레이는 터치 입력 장치와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 출력 기능 및/또는 입력 기능을 수행할 수 있다. 출력 장치는 각종 출력을 위한 기기(outputter)를 포함할 수 있다. 메모리는 대상체 상태 예측 장치의 다양한 기능의 수행을 야기하도록 하는 적어도 하나의 인스트럭션 을 저장할 수 있다. 메모리는, 콘텐츠 표현을 위한 데이터들(예를 들어, 음악 파일, 정지영상, 동영상 등)을 저장할 있다. 메모리는, 대상체 상태 예측 장치에서 구동되는 본 개시의 다양한 실시예들에 의 하여 수행되는 동작들을 수행하도록 야기하는 적어도 하나의 응용 프로그램(application program 또는 애플리케 이션(application)), 대상체 상태 예측 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 대상체 상태 예측 장치는, 예를 들어 어플리케이션을 다운로드하여, 메모리에 저장할 수 있다. 대상체 상태 예측 장치 는, 어플리케이션을 실행함으로써, 본 개시의 다양한 실시예들에 의하여 수행되는 동작들을 수행할 수 있 다. 또는, 대상체 상태 예측 장치는, 서버로부터 본 개시의 다양한 실시예들에 의하여 수행되는 동작들을 수행하도록 야기하는 데이터를 (예를 들어) 일시적으로 다운로드하여 메모리에 저장할 수도 있다. 이러한, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입 (Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입에 해당하는 저장 매체를 포함할 수 있다. 메모리는, 예를 들어 프로세서와 연계를 위한 캐시 메모리 및/또는 프로세서에 포함되는 캐시 메모리 및/또는 레지스터를 의미할 수도 있음을 당업자는 이해할 것이다. 또한, 메모리는 대상체 상태 예 측 장치와는 분리되어 있으나 유선 또는 무선으로 연결된 데이터베이스가 될 수도 있으며, 데이터 베이스 시스템으로 구현될 수도 있다. 프로세서는 하나 이상의 프로세서를 포함하고, 적어도 하나의 코어를 포함할 수 있다. 프로세서는 메 모리에 저장된 인스트럭션을 실행할 수 있다. 프로세서는 대상체 상태 예측 장치 내 구성요소들 의 동작을 제어하기 위한 알고리즘 또는 알고리즘을 재현한 프로그램에 대한 데이터를 저장하는 메모리, 및 메 모리에 저장된 데이터를 이용하여 전술한 동작을 수행하는 적어도 하나의 프로세서(미도시)로 구현될 수 있다. 이때, 메모리와 프로세서는 각각 별개의 칩으로 구현될 수 있다. 또는, 메모리와 프로세서는 단일 칩으로 구현 될 수도 있다. 실시예에서, 대상체 상태 예측 장치는 다양한 UI를 플랫폼 기반으로 웹 서비스 형태로 제공할 수 있는데, 가령, 웹 사이트, 웹 어플리케이션 형태로 제공할 수 있으나, 이에 한정되는 것은 아니다. 또한, 해당 플랫폼은 PC 어플리케이션, 모바일 어플리케이션 등의 형태로 제공될 수 있으나, 실시예가 이에 한정되는 것은 아니다. 이 경우, 다양한 사용자 단말은 대상체 상태 예측 장치가 제공하는 다양한 UI를 플랫폼 기반으로 이용할 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network),BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련데이터로서 입력데이터와 출력데이터가 같이 제공됨으로써 문제(입력데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출력데 이터 없이 입력데이터만 제공되어 문제(입력데이터)의 해답(출력데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과 (output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 도 2에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구 성 요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상 의 지식을 가진 자에게 용이하게 이해될 것이다. 한편, 도 2에서 도시된 각각의 구성요소는 소프트웨어 및/또는 Field Programmable Gate Array(FPGA) 및 주문 형 반도체(ASIC, Application Specific Integrated Circuit)와 같은 하드웨어 구성요소를 의미한다.도 3은 본 개시에 따른 동적 영상 데이터 기반 대상체 상태 예측 방법(S300, S310 단계 내지 S330 단계 포함)을 나타내는 시퀀스도이고, 도 4는 본 개시에 따른 초기 동적 영상 데이터에 기반하여 제1 예측 모델(EM1) 및 제2 예측 모델(EM2)을 학습하는 과정을 설명하기 위한 도면이다. 도 3을 설명하면서 필요한 부분에서 도 4를 함께 참고하기로 한다. S310 단계에서, 프로세서는 학습 대상체에 약품이 주입된 후 미리 설정된 시점까지의 초기 구간에 대응하 는 초기 동적 영상 데이터를 획득할 수 있다. 여기서, 약품은 트레이서일 수 있다. 트레이서는 목표 조직이나 장기에 따라 다양한 종류를 가질 수 있다. 가령, 종양의 위치나 크기를 확인하거나 뇌의 기능적 활동을 조사하거나 심장 혈류 및 대사 활동을 진단할 때 서로 다른 종류의 트레이서가 적용될 수 있다. 또한, 미리 설정된 시점은 목적 조직이나 장기가 아닌 부위의 방사선량이 피크가 되는 지점에서 미리 설정된 범 위 내의 시점일 수 있으며, 실시예에 따라 디폴트값으로 사용될 수도 있다. S320 단계에서, 프로세서는 초기 구간 중 제1 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 제 1 구간 보다 앞선 시점에 대응하는 학습 대상체에 대한 해부학적 정보(또는 혈류적 정보)를 나타내는 제1 영상 데이터를 예측하는 제1 예측 모델(EM1)을 학습할 수 있다. 여기서, 제1 영상 데이터는 극초기 영상 데이터일 수 있다. 도 4를 참고하면, 제1 예측 모델(EM1)은 생성 모델(EM1G) 및 판별 모델(EM1D)를 포함할 수 있다. 프로세서는 제1 구간에 대응하는 초기 동적 영상 데이터(710a)를 제1 예측 모델(EM1)의 생성 모델(EM1G)에 입력하는 경우 중간 극초기 영상 데이터(710b)를 예측(생성)할 수 있다. 프로세서는 생성된 중간 극초기 영상 데이터(710b) 및 극초기 영상 데이터의 레이블 영상 데이터(710c, 제 1 레이블)를 판별 모델(EM1D)에 입력하여, 생성 모델(EM1G)을 통해 생성된 중간 극초기 영상 데이터(710b) 및 제1 레이블(710c)을 비교하여 검증할 수 있다. 프로세서는 예측 모델(EM1)이 미리 설정된 조건(가령, 유사 도가 95% 이상)을 만족하기까지 생성 및 판별을 반복적으로 수행할 수 있다. 제1 예측 모델(EM1)은 GAN 모델 기반으로 생성될 수 있으며, 컨디션 정보(가령, 레이블)를 추가로 이용하는 Conditional GAN 모델이 적용될 수 있으나, 본 개시가 이에 한정되는 것은 아니다. S330 단계에서, 프로세서는 초기 구간 중 제2 구간에 대응하는 초기 동적 영상 데이터를 입력으로 하여 초 기 구간 이후 기준 시점에 대응하는 학습 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이터를 예측 하는 제2 예측 모델(EM2)을 학습할 수 있다. 여기서, 제2 영상 데이터는 딜레이 영상 데이터일 수 있다. 도 4를 참고하면, 프로세서는 제2 구간에 대응하는 초기 동적 영상 데이터(720a)를 제2 예측 모델(EM2)의 생성 모델(EM2G)에 입력하는 경우 중간 딜레이 영상 데이터(720b)를 예측할 수 있다. 프로세서는 생성된 중간 딜레이 영상 데이터(720b) 및 딜레이 영상 데이터의 레이블 영상 데이터(720c, 제 2 레이블)을 판별 모델(EM2D)에 입력하여, 생성 모델(EM2G)을 통해 생성된 중간 딜레이 영상 데이터(720b) 및 제2 레이블(730c)을 비교하여 검증할 수 있다. 프로세서는 예측 모델(EM2)이 미리 설정된 조건(가령, 유사 도가 95% 이상)을 만족하기까지 생성 및 판별을 반복적으로 수행할 수 있다. 제2 예측 모델(EM2)은 GAN 모델 기반으로 생성될 수 있으며, 컨디션 정보(가령, 레이블)를 추가로 이용하는 Conditional GAN 모델이 적용될 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 실시예에서, 학습 대상체에 주입된 약품의 양은 기준량 보다 감소한 양일 수 있다. 가령, 기준량 보다 감소한 양은 기준량의 절반일 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 제1 예측 모델(EM1)은 극초기 영상 데이터에 대응하는 제1 레이블 영상 데이터에 기반하여 학습되고, 제2 예측 모델(EM2)은 딜레이 영상 데이터에 대응하는 제2 레이블 영상 데이터에 기반하여 학습될 수 있다. 이때, 제1 레 이블 영상 데이터 및 제2 레이블 영상 데이터는, 학습 대상체의 약품 주입량에 따라 가공된 레이블 영상 데이터 일 수 있다. 프로세서는 학습 대상체에 주입되는 약품의 주입량이 기준량의 절반인 경우, 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터를 기준량의 절반에 해당되는 레이블 영상 데이터로 사용하는 것이 필요하다. 실시예에서, 프로세서는 약품 주입량이 기준량보다 적은 경우에 대한 제1 레이블 영상 데이터 및 제2 레이 블 영상 데이터를 임상 실험을 통해 다이렉트로 확보하여, 이를 학습에 사용할 수도 있다. 다만, 기준량보다 약품을 소량 주입하는 경우도 국가 기관의 허가가 필요하여 확보가 어려울 수 있으므로, 프로 세서는 약품 주입량이 기준량인 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터를 생성할 때, 프레임 생성 시간을 단축하여 약품 주입량이 기준량보다 적은 경우에 대응하는 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터를 생성할 수 있다. 가령, 프로세서는 2분 단위로 5장의 영상 데이터를 생성하는 경우, 1 분 단위로 영상 데이터를 생성한 후, 2분씩 사이를 두어 프레임을 획득하고(원래 2분마다 생성하는 영상 데이터를 사용하지 않음), 획득된 영상 데이 터를 제1 레이블 영상 데이터 및 제2 영상 데이터로 사용할 수 있다. 즉, 프로세서는 기준량의 절반에 해 당되는 주입량에 대응하는 제1 레이블 영상 데이터 및 제2 레이블 영상 데이터를 생성할 수 있다. 즉, 프로세서 는 List mode data 를 이용하여 약품 주입량이 감소한 영상을 생성하도록 가공하거나 근사적인 방법을 적 용하여 2분 단위로 영상 프레임을 생성하던 것을 1분 단위의 인터리빙(interleaving) 방식으로 영상 프레임을 생성할 수 있다. 구현 예에 따라 S320 단계 및 S330 단계 간 순서 변경하여 수행될 수 있다. 도 5는 본 개시에 따른 진단 대상자의 해부학적 정보를 나타내는 제1 영상 데이터 및 질병 특이적 정보를 나타 내는 제2 영상 데이터를 예측하는 방법(S400)을 나타내는 시퀀스도이다. S410 단계에서, 프로세서는 진단 대상체에 약품이 주입된 후 제1 구간에 대응하는 초기 동적 영상 데이터 를 획득할 수 있다. S420 단계에서, 프로세서는 진단 대상체의 제1 구간에 대응하는 초기 동적 영상 데이터를 학습된 제1 예측 모델(EM1)에 입력하여, 앞선 시점에 대응하는 진단 대상체에 대한 해부학적 정보(또는 혈류적 정보)를 나타내는 제1 영상 데이터를 예측할 수 있다. 여기서, 제1 영상 데이터는 극초기 영상 데이터일 수 있으며, 제1 구간은 약품 주입 후 10분 내지 30분일 수 있 으나, 실시예가 이에 한정되는 것은 아니다. 앞선 시점은 극초기 영상 데이터에 대응하는 시점으로, 약품 주입 후 미리 설정된 범위 내(가령, 1분)일 수 있으나, 실시예가 이에 한정되는 것은 아니다. S430 단계에서, 프로세서는 진단 대상체에 약품이 주입된 후 제2 구간에 대응하는 초기 동적 영상 데이터 를 획득할 수 있다. 제2 구간은 약품 주입 후 10분 내지 20분일 수 있으나, 본 개시가 이에 한정되는 것은 아니다. S440 단계에서, 프로세서는 진단 대상체의 제2 구간에 대응하는 초기 동적 영상 데이터를 학습된 제2 예측 모델(EM2)에 입력하여, 기준 시점에 대응하는 진단 대상체에 대한 질병 특이적 정보를 나타내는 제2 영상 데이 터를 예측할 수 있다. 실시예에서, 프로세서는 미리 설정된 양만큼 감소한 약품이 진단 대상체에 주입되고, 이에 기반하여 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하고 가공할 수 있다. 여기서, 약품은 기준량보다 미리 설정된 양만큼 감소한 양이 주입될 수 있는데, 주입 방사선량을 줄이기 위함이 다. 프로세서는 예측 모델(EM1, EM2)에 입력하기 전에 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구 간에 대응하는 초기 동적 영상 데이터를 가공할 수 있는데, 기준량보다 주입 방사선량이 적으므로 기준량이 주 입된 경우에 대응하는 초기 동적 영상 데이터로 가공하기 위함이다. 프로세서는 제1 구간에 대응하는 초기 동적 영상 데이터에서 약품의 인체 내 이동 경로를 보다 진하고 명 학하게 가공할 수 있는데, 스무딩 필터(가령, 가우시안 필터)를 이용하여 각 픽셀값을, 기준량이 주입된 경우의 각 픽셀값으로 가공할 수 있다. 즉, 프로세서는 스무딩 기법(가령, spatial smooting method)을 이용하여 각 픽셀값을 가공할 수 있다. 실시예에서, 프로세서는 가공 모델에 약품이 소량 투입된 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구간에 대응하는 초기 동적 영상 데이터를 입력하는 경우, 기준량이 투입된 제1 구간에 대응하는 초기 동적 영상 데이터 및 제2 구간에 대응하는 초기 동적 영상 데이터를 가공 모델을 통해 출력하여 이용할 수도 있다. 프로세서는 가공된 제1 구간에 대응하는 초기 동적 영상 데이터 및 상기 가공된 제2 구간에 대응하는 초기 동적 영상 데이터를 획득한 후, 가공된 제1 구간에 대응하는 초기 동적 영상 데이터를 제1 예측 모델(EM1)에 입 력하여 이에 대응하는 해부학적 정보를 나타내는 제1 영상 데이터를 예측할 수 있으며, 가공된 제2 구간에 대응 하는 초기 동적 영상 데이터를 제2 예측 모델(EM2)에 입력하여, 이에 대응하는 질병 특이적 정보를 나타내는 제 2 영상 데이터를 예측할 수 있다. 도 6은 본 개시에 따른 공간 정규화(spatial normalization)를 수행하는 전처리 과정(S500, S510 단계 내지 S520 단계 포함)을 나타내는 시퀀스도이다. 도 7은 본 개시에 따른 인공신경망 모델 학습 전 전처리 단계에서 수행하는 공간 정규화(spatial normalization)를 설명하기 위한 도면이다. S510 단계에서, 프로세서는 보다 소수의 학습 대상체 자료를 통한 기계 학습이 가능하도록 학습 대상체 및 진단 대상체의 제1 구간에 대응하는 초기 동적 영상 데이터가 제1 예측 모델(EM1)에 입력되기 전 공간 정규화를 수행할 수 있다. S520 단계에서, 프로세서는 학습 대상체 및 진단 대상체의 제2 구간에 대응하는 초기 동적 영상 데이터가 제2 예측 모델(EM2)에 입력되기 전 공간 정규화를 수행할 수 있다. 도 7을 참고하면, 프로세서는 제1 예측 모델(EM1)에 학습 대상체 및 진단 대상체의 제1 구간에 대응하는 초기 동적 영상 데이터를 입력하기 전 또는 제2 예측 모델(EM2)에 학습 대상체 및 진단 대상체의 제2 구간에 대 응하는 초기 동적 영상 데이터를 입력하기 전, 초기 동적 영상 데이터에 대한 공간 정규화를 수행하여, 제1 이 미지, 제2 이미지, 제3 이미지을 기준 부위를 기준으로 공간 정규화를 수행할 수 있다. 가령, 프로세서는 제1 이미지를 수평선(D1a) 및 수직선(D2a)를 이용하여 기준 중심 기준으로 공간 배치하고, 제2 이미지를 수평선(D1b) 및 수직선(D2a)를 이용하여 기준 중심 기준으로 공간 배치할 수 있 으며, 제3 이미지를 수평선(D1a) 및 수직선(D2b)을 이용하여 기준 중심 기준으로 공간 배치할 수 있다. 이에 따라, 학습 효율이 향상될 수 있으며, 진단에 효과적일 수 있다. 프로세서는, 장비 운용성 및 진단 대상자들의 예측 가능성을 고려하기 위해, 학습 대상체 및 진단 대상체 의 초기 구간 중 제1 구간 및/또는 제2 구간에 대응하는 초기 동적 영상 데이터의 획득 타임 구간을 설정할 수 있다. 프로세서는 진단 대상체에 약품이 주입되는 경우 초기 구간을 확인하고, 확인된 초기 구간에 기초하여 제1 구간 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득할 수 있다. 프로세서는 개개인의 특성에 따라 제1 구간 및 제2 구간에 대응하는 초기 동적 영상 데이터를 획득하는 시 간을 설정할 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 도 8은 본 개시에 따른 약품 주입 후 시간에 따른 방사선량 변화를 나타내는 도면이다. 도 8을 참고하면, 약물(즉, 트레이서)로 FP-CIT를 사용하는 경우, 약물이 투여된 초기 시간범위에서는 혈류 영 향에 의해 뇌의 전체 영역에서 방사선량이 높게 나타나서 진단이 어려울 수 있다. 그러나 시간이 경과됨에 따라 약물이 소변으로 배출되거나 간으로 대사되어, 혈장 내 농도가 떨어지게 되면서, 혈액 내에는 약물이 감소하는 것이 확인될 수 있다. 또한, 혈액 내 약물 감소의 균형을 맞추기 위해 뇌 조직에서 혈액 쪽으로 약물이 빠져나 가게 된다. 프로세서은 뇌조직 내의 방사선량이 변화하는 초기 구간에서 초기 동적 영상데이터를 획득할 수 있다. 그 후, FP-CIT는 도파민(Dopamine)과 결합력이 강해 파킨슨병을 감별하는데 효과적이므로, FP-CIT가 타겟 부위 인 도파민 신경 운반체에 결합되는 경우, 다른 영역(610~630)은 혈류 영향이 감소하여 농도가 낮아지더라도 타 겟 부위(640, 650)는 높은 농도를 유지하게 된다. 프로세서는 다른 영역(가령, 레퍼런스 영역(610~630))의 선량 농도가 피크가 되는 지점을 기준으로 초기 동적 영상 데이터의 초기 구간을 결정할 수 있다. 프로세서는 약물 투여 후 기준시간이 경과되어 혈류 영향이 감소된 시점에 딜레이 영상 데이터을 획득할 수 있다. 딜레이 영상 데이터는 기존에 의료진에 의해 타겟 부위의 크기, 형태 등을 진단하는데 이용되는 영상 데이터일 수 있다. 실시예에서, 영상 데이터 촬영에 이용되는 약품이 특정한 타겟 영역에 결합하는 트레이서인 경우, 초기 동적 영 상데이터를 획득하는 초기 구간은 다양한 기준을 바탕으로 결정될 수 있다. 예를 들어, 상기 초기 구간는 레퍼 런스 영역에서 혈류에 의한 영향이 감소되기 시작하는 시점 이후의 시간 범위로 설정될 수 있다. 레퍼런스 영역 은, 일반적으로 트레이서가 결합하는 물질이 없거나 적어서 질병 간에 차이가 없는 뇌의 특정 부위일 수 있다.레퍼런스 영역은, 트레이서 종류와 특성에 따라 달라진다. 예를 들어, 트레이서가 FP-CIT인 경우, 레퍼런스 영 역은, 소뇌나 후두엽 피질(OC) 등의 도파민 신경 운반체가 적은 부위가 된다. 또한, 다른 예로, 초기 구간은 타 겟 영역과 레퍼런스 영역의 선량 비율 차이값이 특정값 이상이 되거나 비율 차이값이 최대가 되는 시점 주변으 로 설정될 수 있다. 영상 데이터 촬영에 이용되는 약품이 시간 경과에 따라 계속해서 타겟 영역에 결합되는 양이 증가되는 트레이서 (예를 들어, Fluorodeoxyglucose(이하, FDG) PET)인 경우, 피크 지점이 없이 뇌의 각 영역의 선량이 증가하므로, 프로세서는 방사선량의 차이가 크지 않은 초기 구간에서 초기 동적 영상데이터를 획득하고, 영역 간의 방사선량 차이 비율(Ratio)이 커진 기준시점에 딜레이 영상데이터를 획득한다. 도 9a는 본 개시에 따른 기준선량으로 생성한 딜레이 영상 데이터와 레이블 영상 데이터를 비교하기 위한 그래 프이고, 도 9b는 본 개시에 따른 저선량으로 생성한 딜레이 영상 데이터와 레이블 영상 데이터를 비교하기 위한 그래프이며, 도 9c는 본 개시에 따른 기준선량으로 생성한 딜레이 영상 데이터와 저선량으로 생성한 딜레이 영 상 데이터를 비교하기 위한 그래프이다. 도 9a를 참고하면, AP(Anterior Putamen, 기저핵의 앞부분)에 대해서, 기준선량으로 생성한 딜레이 영상 데이터 와 레이블 영상 데이터 간의 DAT(Dopamine Transporter) 섭취를 비교하면 0.95 상관도가 산출될 수 있으며, PP(posterior putamen, 기저핵의 뒷부분)에 대해서, 0.96 상관도가 산출될 수 있다. 도 9b를 참고하면, AP에 대해서, 저선량(기준선량의 절반)으로 생성한 딜레이 영상 데이터와 레이블 영상 데이 터 간의 DAT 섭취를 비교하면 0.93 상관도가 산출될 수 있으며, PP(posterior putamen, 기저핵의 뒷부분)에 대 해서, 0.95 상관도가 산출될 수 있다. 도 9c를 참고하면, AP에 대해서, 기준선량으로 생성한 딜레이 영상 데이터과 저선량으로 생성한 딜레이 영상 데 이터 간의 DAT 섭취를 비교하면 0.99의 상관도가 산출될 수 있으며, PP에 대해서, 기준선량으로 생성한 딜레이 영상 데이터과 저선량으로 생성한 딜레이 영상 데이터 간에 1.00 의 상관도가 산출될 수 있다. 도 9a 내지 도 9c를 참고하면, 핵의학 분자 영상의 특징인 반감기에 의한 감약이 덜한 상태에서 영상을 얻으므 로 동위원소 주사량을 줄인 저선량 영상을 통해서도 동일한 품질의 지연섭취영상(딜레이 영상)이 예측될 수 있 다. 도 10a는 본 개시에 따른 AP(Anterior Putamen) 및 PP(Posterior Putamen) 각각에 대한 학습 및 테스트 단계에 서 사용된 아날로그 PET 데이터를 나타내고, 도 10b는 본 개시에 따른 AP 및 PP 각각에 대한 테스트 단계에서 사용된 디지털 PET 데이터를 나타낸다. 도 10a를 참고하면, 아날로그 PET 데이터에 대해, 테스트 셋 결과는 AP 에 대해서 0.95 의 상관도가 확인될 수 있으며, PP 에 대해서는 0.96 의 상관도가 확인될 수 있다. 도 10b를 참고하면, 디지털 PET 데이터에 대해, 독립적인 테스트 셋에 대해, AP 에 대해서 0.93 의 상관도가 확 인될 수 있으며, PP 에 대해서 0.97 의 상관도가 확인될 수 있다. 도 11은 본 개시에 따른 극초기 영상 데이터를 획득하기 위한 방법을 설명하기 위한 도면이다. 초기 구간 내에서 약품 주입 후 10분 후의 동적 영상 데이터와 극초기 영상 데이터 간에 0.94 의 상관도가 확인 될 수 있으며, 약품 주입 후 20분 후의 동적 영상 데이터와 극초기 영상 데이터 간에 0.77 의 상관도가 확인될 수 있으며, 약품 주입 후 30분 후의 동적 영상 데이터와 극초기 영상 데이터 간에 0.53의 상관도가 확인 될 수 있다. 이와 같이, 극초기 영상 데이터와 가장 시간적으로 인접한 약품 주입 후 10분 후의 동적 영상 데이 터의 경우, 상관도가 가장 높게 확인될 수 있다. 프로세서는 약품 주입 후 10분 내지 30분의 동적 영상 데이터에 기초하여 극초기 영상 데이터를 예 측할 수 있다. 즉, 초기 동적 영상 데이터(가령, 초기 구간의 제1 구간)를 이용하여 극초기 영상 데이터 의 예측이 효과적일 수 있다. 도 12는 본 개시에 따른 딜레이 영상 데이터를 획득하기 위한 방법을 설명하기 위한 도면이다. 초기 구간 내에서 약품 주입 후 10분 후의 동적 영상 데이터와 딜레이 영상 데이터 간에 0.80 의 상관도가 확인 될 수 있으며, 약품 주입 후 20분 후의 동적 영상 데이터와 딜레이 영상 데이터 간에 0.94 의 상관도가 확인될 수 있다. 이와 같이, 딜레이 영상 데이터와 가장 시간적으로 인접한 약품 주입 후 20분 후의 동적 영상 데이터의 경우, 상관도가 가장 높게 확인될 수 있다.프로세서는 약품 주입 후 10분 내지 20분의 동적 영상 데이터에 기초하여 딜레이 영상 데이터를 예 측할 수 있다. 즉, 초기 동적 영상 데이터(가령, 초기 구간의 제2 구간)를 이용하여 딜레이 영상 데이터 의 예측이 효과적일 수 있다. 한편, 동적 영상 데이터는, 요구되는 프레임의 개수에 따라 동적 영상 프레임의 화질이 설정될 수 있다. 즉, 동 일한 양의 약물을 사용하면 외부로 방출되는 방사선 최대량이 제한되어 영상 프레임을 생성하는데 이용되는 신 호량이 제한되므로, 컴퓨팅 장치는 동일한 신호량을 기반으로 영상 프레임 개수에 따라 각 영상프레임의 화질을 달리 설정할 수 있다. 예를 들어, 영상 프레임 개수를 늘리면 각 영상 프레임 생성에 이용되는 시간 길이가 짧아지므로 하나의 영상 프레임을 생성하는데 이용 가능한 신호량이 줄어들게 되고, 컴퓨팅 장치는 각 영상 프레임의 화질을 낮게 생성 한다. 일실시예로, 컴퓨팅 장치는 시간 경과에 따른 동적 영상 데이터 내의 각 픽셀의 변화와 초기 영상 데이터 및 딜 레이 영상 데이터 내의 각 픽셀을 매칭하여 학습할 수 있다. 즉, 특정한 환자에 대한 영상 데이터 조합(즉, 초기 동적 영상데이터, 동적 영상 데이터와 딜레이 영상데이터의 조합)에서, 컴퓨팅 장치는 신체 조직(예를 들어, 뇌조직)의 각 지점(즉, 픽셀)에 대해 동적 영상 데이터로부터 초기 동적 영상 데이터 및 딜레이 영상 데이터를 예측하고, 초기 동적 영상 데이터 내에서의 해부학적 정보와 딜레이 영상 데이터 내에서의 질병 특이적 정보를 매칭하여 영상데이터 조합별 데이터셋을 구축하고, 각 지점 (즉, 픽셀)별로 복수의 환자에 대한 데이터셋을 학습하여 진단용 영상 예측 모델을 구축한다. 실시예에서, 진단용 영상 예측모델은 심층신경망(Deep Neural Network; DNN)으로 구축된다. 즉, 진단용 영상 예 측 모델은 딥러닝 알고리즘을 적용하여 하나 이상의 환자에 대한 동적 영상데이터를 학습한다. 프로세서는 동적 영상데이터의 밝기를 최대값 또는 평균값을 기준으로 정규화(normalization)하여 생성될 수 있 다. 실시예에서, 영상 데이터 촬영에 이용되는 약품이 시간경과에 따라 계속해서 타겟영역에 결합되는 양이 증가되 는 트레이서(예를 들어, Fluorodeoxyglucose(이하, FDG) PET)인 경우, 약물의 투여량에 비례하여 섭취되는 PET 추적자(tracer)의 특성 때문에 레퍼런스 영역과 타겟영역의 밝기 비율은 약물 투여량에 의해 달라지지 않으므로, 컴퓨팅 장치는 동적 영상데이터의 밝기의 최대값 또는 평균값을 기준으로 정규화(normalization)하여 영상데이터를 생성한다. 한편, 본 개시에서는 PET를 이용하여 동작을 설명하나 상술한 동작은 PET뿐만 아니라 MR의 경우에도 적용될 수 있으며 의료 영상 전반에 적용될 수 있다. 다만 MR의 경우는 초기 동적 영상 데이터를 통하여 질병 특이적 정보를 도출할 수 있고, 딜레이 영상 데이터를 통하여 해부학적 정보를 도출할 수 있다. 영상 데이터 촬영에 이용되는 약품이 특정한 타겟영역에 결합하는 트레이서인 경우(FP-CIT를 트레이서로 이용하 는 경우), 레퍼런스 영역을 입력으로 하고 타겟 영역을 출력으로 하는 선형 추적자 동역학 모델(Tracer Kinetic Model)에서 입력과 출력이 동시에 선형적으로 증감하여도 추적자 모델의 매개변수들은 동일하기 때문에, 컴퓨팅 장치는 학습용 초기 동적 영상데이터와 진단용 초기 동적 영상데이터의 밝기를 최대값 또는 평균값을 기준으로 정규화(count normalization 또는 intensity normalization)하여 신규 딜레이 영상데이터를 생성할 수 있다. 즉, 영상 데이터의 촬영에 이용되는 약품이 특정한 타겟 영역에 결합하는 트레이서인 경우, 학습용 동적 영상 데이터는, 타겟 영역과 레퍼런스 영역의 선량 비율 차이 값이 특정 값 이상이 되거나 비율 차이 값이 최대가 되 는 시점 이후부터 혈류에 의한 영향이 배제된 시점 이전까지 획득되는 영상 데이터로 형성될 수 있다. 또한 학습용 동적 영상 데이터는 타겟 영역과 레퍼런스 영역의 선량 비율 차이 값이 특정 값 이상이 되거나 혈 류에 의한 레퍼런스 영역의 선량 변화량이 감소하는 시점부터 타겟 영역과 레퍼런스 영역의 선량 비율 차이가 최대 값이 되는 시점까지 획득되는 영상데이터로 형성될 수 있다. 선량 비율 값은 초기 시점의 방사선량과 특정 측정 시점의 방사선 량의 비율을 의미할 수 있다. 따라서 선량 비율 차이 값은 타겟 영역의 선량 비율과 레퍼런스 영역의 선량 비율의 차이 값을 의미할 수 있다. 구체적으로 프로세서는 타겟 영상과 레퍼런스 영상의 선량에 대한 정보를 획득할 수 있다. 또한 프로세서는 타겟 영상에 대응되는 선량과 레퍼런스에 대응되는 선량을 획득할 수 있고 각 선량의 비율 값 을 산출하고 각각 선량 비율의 차이 값을 연산할 수 있다. 또한 프로세서는 레퍼런스의 선량 변화량이 감소하는 시점 및 선량 비율 차이가 최대가 되는 시점을 결정할 수 있다. 일반적으로 딜레이 영상 데이터를 기반으로 의료진이 진단을 수행하는 경우, 의료진은 방사성 동위원소가 물리 적 반감기와 배뇨/배변 등 체외배출에 의한 감소(즉, 생리학적 감소)에 따라 감소한 후에도 충분한 방사선량으 로 촬영된 딜레이 영상 데이터로 진단을 수행할 수 있도록 초기시점에 많은 양의 약품을 투여하게 된다. 이 때, 환자 신체에 제공되는 방사선량이 높아지게 되는 문제가 있다. 따라서, 본 발명의 일실시예를 이용하여, 진단용 동적 영상데이터를 획득할 때 충분한 방사선량이 획득될 수 있 는 정도의 트레이서만을 삽입한 후에 진단용 동적 영상데이터를 획득하고, 진단용 동적 영상데이터를 예측모델 에 삽입하여 초기 동적 영상 데이터 및 최종적인 진단용 딜레이 영상데이터를 획득함에 따라, 환자에게 주입되 는 방사선물질의 양을 줄여서 환자 신체에 제공되는 방사선량을 줄일 수 있다. 미리 결정된 기준 시간은, 트레이서의 종류에 기초하여 결정될 수 있다. 한편, 프로세서는 초기 동적 영상 데이터 및 상기 딜레이 영상 데이터를 이용하는 제2 진단용 영상 예측 모델을 기초로 초기 동적 영상 데이터 및 상기 딜레이 영상 데이터로부터 해부학적 정보와 질병 특이정 정보를 예측하 는 제2 학습 데이터를 형성할 수 있다. 정리하면, 제1진단용 예측 모델은 동적 영상 데이터로부터 초기 동적 영상 데이터 및 딜레이 영상 데이터를 예 측하고 이에 대응되는 해부학적 정보 및 질병 특이적 정보를 학습 및 예측하는 반면, 제2진단용 예측 모델은 동 적 영상 데이터와 대응되는 초기 동적 영상 데이터와 딜레이 영상 데이터를 기초로 학습을 수행하고 추후 진단 용 초기 동적 영상 데이터 또는 딜레이 영상 데이터가 입력되면 해부학적 정보와 질병 특이적 정보 통합적으로 예측할 수 있다. 한편, 프로세서는 해부학적 정보 및 질병 특이적 정보를 기초로 대상체의 상태를 판단할 수 있다. 구체적으로 프로세서는 상술한 방법으로 도출된 대상체의 질병 특이적 정보와 해부학적 정보를 이용하여 대상체 가 파킨슨 병이나 치매에 해당되는지에 대한 정보를 도출할 수 있다. 구체적으로 대상체의 도파민 신경 운반체에 트레이서가 잔존하는 경우 해당 대상체를 파킨슨 병의 상태로 판단 할 수 있다. 또한 아밀로이드의 트레이서가 잔존하는 경우 해당 대상체를 치매 상태로 판단할 수 있다. 프로세서는 제1 진단용 영상 예측 모델의 정확도 제2 진단용 영상 예측 모델의 정확도 중 높은 정확도를 갖는 진단용 영상 예측 모델을 결정할 수 있다. 예를 들어 진단자가 초기 동적 영상 데이터로 진단을 수행하는 경우 제1 진단용 예측 모델의 파킨슨 평에 대한 정확도와 제2 진단용 예측 모델에 대한 정확도를 산출할 수 있다. 이 경우 프로세서는 각 진단용 예측 모델 중 높은 정확도를 갖는 진단용 예측 모델을 선택하여 대상체의 상태를 판단할 수 있다. 적절한 동적 영상 획득 시점 등의 세부 검사 조건 이상에서 전술한 본 발명의 일 실시예에 따른 초기 동적 영상 데이터 기반 진단용 영상 생성방법은, 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 어플리케이 션)으로 구현되어 매체에 저장될 수 있다. 이상에서 전술한 본 발명의 일 실시예에 따른 초기 동적 영상데이터 기반 진단용 영상 생성방법은, 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 어플리케이션)으로 구현되어 매체에 저장될 수 있다. 상기 전술한 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, 기 계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필요 한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들을 상기 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있다. 또한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨 터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠 한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어 떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는지 등 에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다."}
{"patent_id": "10-2024-0064227", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2024-0064227", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 동적 영상 데이터 기반으로 대상체의 상태를 예측하는 방법을 나타내는 전체 개요도이다. 도 2는 본 개시에 따른 동적 영상 데이터 기반 대상체 상태 예측 장치의 구성을 나타내는 블록도이다. 도 3은 본 개시에 따른 동적 영상 데이터 기반 대상체 상태 예측 방법을 나타내는 시퀀스도이다. 도 4는 본 개시에 따른 초기 동적 영상 데이터에 기반하여 제1 예측 모델 및 제2 예측 모델을 학습하는 과정을 설명하기 위한 도면이다. 도 5는 본 개시에 따른 진단 대상자의 해부학적 정보 또는 혈류적 정보를 나타내는 제1 영상 데이터 및 질병 특 이적 정보를 나타내는 제2 영상 데이터를 예측하는 방법을 나타내는 시퀀스도이다. 도 6은 본 개시에 따른 공간 정규화(spatial normalization)를 수행하는 전처리 과정을 나타내는 시퀀스도이다. 도 7은 본 개시에 따른 인공신경망 모델 학습 전 전처리 단계에서 수행하는 공간 정규화를 설명하기 위한 도면 이다. 도 8은 본 개시에 따른 약품 주입 후 시간에 따른 방사선량 변화를 나타내는 도면이다. 도 9a는 본 개시에 따른 기준선량으로 생성한 딜레이 영상 데이터와 레이블 영상 데이터를 비교하기 위한 그래 프이고, 도 9b는 본 개시에 따른 저선량으로 생성한 딜레이 영상 데이터와 레이블 영상 데이터를 비교하기 위한 그래프이며, 도 9c는 본 개시에 따른 기준선량으로 생성한 딜레이 영상 데이터와 저선량으로 생성한 딜레이 영 상 데이터를 비교하기 위한 그래프이다. 도 10a는 본 개시에 따른 AP(Anterior Putamen) 및 PP(Posterior Putamen) 각각에 대한 학습 및 테스트 단계에 서 사용된 아날로그 PET 데이터를 나타내고, 도 10b는 본 개시에 따른 AP 및 PP 각각에 대한 테스트 단계에서 사용된 디지털 PET 데이터를 나타낸다. 도 11은 본 개시에 따른 극초기 영상 데이터를 획득하기 위한 방법을 설명하기 위한 도면이다. 도 12는 본 개시에 따른 딜레이 영상 데이터를 획득하기 위한 방법을 설명하기 위한 도면이다."}
