{"patent_id": "10-2020-0037774", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0120710", "출원번호": "10-2020-0037774", "발명의 명칭": "경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법", "출원인": "동명대학교산학협력단", "발명자": "이동명"}}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "감시영역에 설치된 적어도 하나 이상의 음원감지모듈로부터 해당 감시영역에서 감지한 음원을 수신하는 음원 수신부; 및상기 수신한 음원을 복수의 학습모델에 적용하여, 상기 감시영역에서, 사전에 정의한 비정상적인 상황의 발생을인식하는 상황 인식부;를 포함하며,상기 복수의 학습모델은, 상기 감시영역에서 발생된 비정상적인 상황과, 상기 비정상적인 상황에 따라 복합적으로 발생되는 음원간의 관계를 경험적으로 학습하여 생성되는 것을 특징으로 하는 경험적 학습기반 음원을 이용한 상황인식 시스템."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 경험적으로 학습하는 것은,상기 감시영역에서 발생된 비정상적인 상황에 따라 발생된 복수의 음원을 복수의 학습용 음원으로 하여 사전에수집하고, 상기 수집한 각 학습용 음원과 상기 비정상적인 상황을 각각 나타내는 음원의 명칭간 매핑관계를 각각 학습하는 것이며,상기 수집한 학습용 음원은, 스펙트로그램으로 각각 변환하여 상기 학습에 이용하는 것을 특징으로 하는 경험적학습기반 음원을 이용한 상황인식 시스템."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 상황인식 시스템은,상기 비정상적인 상황을 인식한 경우, 해당 음원을 전송한 음원감지모듈의 위치정보와 상기 감시영역에 설치되는 복수의 감시 카메라에 대한 위치정보에 따라 해당 음원감지모듈에 인접한 적어도 하나 이상의 감시 카메라를해당 음원감지모듈이 위치하는 방향으로 회전시켜, 상기 음원이 발생한 영역을 촬영하도록 제어하는 감시 카메라 제어부; 및상기 제어한 적어도 하나 이상의 카메라로부터 상기 음원이 발생한 영역을 촬영한 영상을 수신하는 영상수신부;를 더 포함하는 것을 특징으로 하는 경험적 학습기반 음원을 이용한 상황인식 시스템."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 상황 인식부는,상기 음원감지모듈로부터 수신한 상기 음원을 변환한 스펙트로그램을 상기 생성한 복수의 학습모델에 각각 적용하여, 상기 각 학습모델에서 출력한 음원의 명칭 중 제일 높은 확률을 가지는 음원의 명칭을 선택함으로써, 상기 비정상적인 상황을 인식하는 것을 특징으로 하는 경험적 학습기반 음원을 이용한 상황인식 시스템."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서,상기 상황인식 시스템은,상기 비정상적인 상황을 인식한 결과와 상기 제어한 적어도 하나 이상의 감시 카메라로부터 수신된 영상을 포함공개특허 10-2021-0120710-3-하는 상황정보를 디스플레이에 출력하는 상황정보 출력부;를 더 포함하는 것을 특징으로 하는 경험적 학습기반음원을 이용한 상황인식 시스템."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "감시영역에 설치된 적어도 하나 이상의 음원감지모듈로부터 해당 감시영역에서 감지한 음원을 수신하는 음원 수신 단계; 및상기 수신한 음원을 복수의 학습모델에 적용하여, 상기 감시영역에서 사전에 정의한 비정상적인 상황의 발생을인식하는 상황 인식 단계;를 포함하며,상기 복수의 학습모델은, 상기 감시영역에서 발생된 비정상적인 상황과, 상기 비정상적인 상황에 따라 복합적으로 발생되는 음원간의 관계를 경험적으로 학습하여, 생성되는 것을 특징으로 하는 경험적 학습기반 음원을 이용한 상황인식 방법."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 경험적으로 학습하는 것은,상기 감시영역에서 발생된 비정상적인 상황에 따라 발생된 복수의 음원을 복수의 학습용 음원으로 하여 사전에수집하고, 상기 수집한 각 학습용 음원과 상기 비정상적인 상황을 각각 나타내는 음원의 명칭간 매핑관계를 각각 학습하는 것이며,상기 수집한 학습용 음원은, 스펙트로그램으로 각각 변환하여 상기 학습에 이용하는 것을 특징으로 하는 경험적학습기반 음원을 이용한 상황인식 방법."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 6에 있어서,상기 상황인식 방법은,상기 비정상적인 상황을 인식한 경우, 해당 음원을 전송한 음원감지모듈의 위치정보와 상기 감시영역에 설치되는 복수의 감시 카메라에 대한 위치정보에 따라 해당 음원감지모듈에 인접한 적어도 하나 이상의 감시 카메라를해당 음원감지모듈이 위치하는 방향으로 회전시켜, 상기 음원이 발생한 영역을 촬영하도록 제어하는 감시 카메라 제어 단계; 및상기 제어한 적어도 하나 이상의 카메라로부터 상기 음원이 발생한 영역을 촬영한 영상을 수신하는 영상 수신단계;를 더 포함하는 것을 특징으로 하는 경험적 학습기반 음원을 이용한 상황인식 방법."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 상황 인식 단계는,상기 음원감지모듈로부터 수신한 상기 음원을 변환한 스펙트로그램을 상기 생성한 복수의 학습모델에 각각 적용하여, 상기 각 학습모델에서 출력한 음원의 명칭 중 제일 높은 확률을 가지는 음원의 명칭을 선택함으로써, 상기 비정상적인 상황을 인식하는 것을 특징으로 하는 경험적 학습기반 음원을 이용한 상황인식 방법."}
{"patent_id": "10-2020-0037774", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 8에 있어서,상기 상황인식 방법은,상기 비정상적인 상황을 인식한 결과와 상기 제어한 적어도 하나 이상의 감시 카메라로부터 수신된 영상을 포함하는 상황정보를 디스플레이에 출력하는 상황정보 출력 단계;를 더 포함하는 것을 특징으로 하는 경험적 학습기반 음원을 이용한 상황인식 방법.공개특허 10-2021-0120710-4-"}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법에 관한 것으로, 감시영역에서 발생한 다 양한 사건, 사고를 포함하여 사전에 정의한 비정상적인 상황에 대한 음원을 경험적으로 학습하여 학습모델을 생 성하고, 상기 감시영역에서 감지되는 실제 음원을 상기 생성한 학습모델에 적용함으로써, 해당 감시영역에서 발 생한 비정상적인 상황을 실시간으로 인식하여, 상기 비정상적인 상황에 대한 대처를 신속하게 수행할 수 있도록 하는 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법에 관한 것으로, 더욱 상세하게는 감시영 역별로 발생될 수 있는 다양한 사건, 사고를 포함하여 사전에 정의한 비정상적인 상황에 대한 음원을 경험적으 로 학습하여 학습모델을 생성하고, 상기 감시영역에서 감지되는 실제 음원을 상기 생성한 학습모델에 적용함으 로써, 해당 감시영역에서 발생한 비정상적인 상황을 실시간으로 인식하여, 상기 비정상적인 상황에 대한 대처를 신속하게 수행할 수 있도록 하는 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술과 IoT(Internet of Things) 기술이 급속하게 발전하면서, 특정 서비스를 제공하기 위한 최 소한의 관리자만 두거나, 무인화한 매장이 증가하고 있으며, 이에 비례하여, 상기 매장에서 다양한 사건, 사고 가 증가하고 있는 실정이다. 이에 따라, 복수의 감시 카메라(CCTV)를 특정 지역이나 매장 내부 등을 포함하는 다수의 감시영역에 설치하여, 상기 감시영역을 실시간으로 모니터링함으로써, 상기 사건, 사고에 대한 대응을 수행할 수 있도록 하는 감시 카 메라를 이용한 감시 시스템에 대한 대중의 관심이 증대되고 있다. 일반적으로 감시 카메라를 이용한 감시 시스템은, 감시영역에 설치되는 복수의 감시 카메라, 상기 복수의 감시 카메라에서 촬영된 영상을 수신하는 서버를 포함하여 구성된다. 이때, 상기 서버는 상기 영상을 디스플레이하여, 관리자가 확인할 수 있도록 함으로써, 적은수의 인원으로도 상기 감시영역을 모니터링할 수 있 는 장점이 있다. 그러나 상기 감시영역에 설치되는 상기 감시 카메라는, 촬영 화각이 제한 적이고, 촬영 방향이 고정되어 있거나, 사전에 설정한 시간 주기에 따라 회전하는 구조로 구성되기 때문에, 상기 감시 카메라에 대한 사각지대 가 필연적으로 발생하여, 상기 사각지대에서 발생하는 사건이나 사고와 같은 비정상적인 상황에 대해서는 모니 터링할 수 없는 문제점이 있다. 이에 따라 최근에는 다수의 감시 카메라간의 촬영 범위를 중첩하여 설치함으로써, 상기 감시 카메라의 사각지대 가 발생하지 않도록 하고 있으나, 이러한 경우, 상기 감시영역의 범위에 따라 너무 많은 감시 카메라를 설치해 야 하기 때문에, 상기 감시 카메라의 설치를 위한 많은 비용이 소모되는 문제점이 있다. 따라서 본 발명에서는, 상기 감시영역에서 발생될 수 있는 사건, 사고 또는 이들의 조합을 포함하여, 사전에 정 의한 비정상적인 상황에 따른 학습용 음원을 경험적으로 학습하여 학습모델을 생성하고, 상기 감시영역에서 감 지되는 음원을 상기 생성한 학습모델에 적용하여, 해당 감시영역에서 발생되는 비정상적인 상황의 발생을 실시 간으로 인식함으로써, 비정상적인 상황에 대한 대처를 신속하게 수행할 수 있도록 함과 동시에, 상기 감시 카메 라의 사각지대에 대한 문제점을 극복할 수 있도록 하는 방안을 제안하고자 한다. 또한 본 발명은, 상기 비정상적인 상황의 발생을 인식한 경우, 상기 비정상적인 상황이 발생한 영역을 적어도 하나 이상의 감시 카메라로 촬영하도록 하여, 상기 인식한 비정상적인 상황에 대한 원인이나, 객체 등을 파악할 수 있도록 함으로써, 상기 비정상적인 상황의 발생에 대한 인식의 효율성을 극대화할 수 있도록 하는 것을 포함 한다."}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "다음으로 본 발명의 기술분야에 존재하는 선행기술에 대하여 간단하게 설명하고, 이어서 본 발명이 상기 선행기 술에 비해서 차별적으로 이루고자 하는 기술적 사항에 대해서 기술하고자 한다. 먼저 한국공개특허 제2010-0121086호(2010.11.17.)는, 음원인식을 이용한 촬영영상 추적 PTZ 카메라 운용시스템 및 그 방법에 관한 것으로, 복수개의 음원 검출수단을 통해 2차원 공간의 어느 한 지점에서 360도 기 설정된 거 리로부터 음원에 대한 각도와 음원발생 지점간의 거리를 측정하여, 음원발생 위치정보를 생성하고, 상기 생성한 위치정보에 부합하는 방향으로 PTZ 카메라를 회동시켜 동영상을 촬영하는 음원인식을 이용한 촬영영상 추적 PTZ 카메라 운용 시스템 및 그 방법에 관한 것이다. 그러나 상기 선행기술은, 단순히 음원을 인식하는 개념만을 기재하고 있을 뿐이다. 반면에 본 발명은, 감시영역 에서 발생되는 음원을 감지하고, 상기 감지한 음원을 토대로 상기 감시영역에서 발생되는 비정상적인 상황을 실 시간으로 인식하는 것으로, 상기 선행기술과 본 발명은 현저한 차이점이 있다.또한 한국등록특허 제1107120호(2012.01.11.)는 음원 추적 및 객체 인식 장치와 음원 추적 및 객체 인식 방법에 관한 것으로, 복수개의 마이크로폰이 구비된 마이크로폰 어레이를 이용하여, 음원이 발생한 방향을 계산하고, 해당 방향으로 카메라를 회전시켜 객체를 확인할 수 있는 음원 추적 및 객체 인식 장치와 음원 추적 및 객체 인 식 방법에 관한 것이다. 즉, 상기 선행기술은, 카메라와 마이크로폰 어레이를 일체형으로 구성하여, 음원이 발생한 방향을 인식한 후, 상기 카메라를 상기 음원이 발생한 방향으로 회전시켜, 해당 음원을 발생시킨 객체를 촬영할 수 있도록 하는 것 이다. 반면에 본 발명은, 감시영역별로 발생될 수 있는 비정상적인 상황에 대한 학습용 음원을 수집하고, 상기 수집한 학습용 음원을 토대로 상기 비정상적인 상황에 대한 경험적 학습을 통해 학습모델을 생성하며, 상기 감시영역에 서 감지된 음원이 수신되는 경우, 상기 수신한 음원을 상기 생성한 학습모델에 적용하여, 해당 음원으로부터 상 기 비정상적인 상황을 실시간으로 인식하여 디스플레이함으로써, 상기 비정상적인 상황에 대한 즉각적인 대처가 가능하도록 하는 것으로, 상기 선행기술은 본 발명의 이러한 기술적 특징을 기재하거나 시사 혹은 암시도 없음 이 분명하다."}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위해 창작된 것으로서, 감시영역에 복수의 음원감지모듈을 설치하고, 상기 설치한 음원감지모듈을 통해 감지되는 음원을 토대로 상기 감시영역에서 발생된 비정상적인 상황을 실시간 으로 인식함으로써, 상기 비정상적인 상황에 대한 대처를 신속하게 수행할 수 있도록 하는 경험적 학습기반 음 원을 이용한 상황인식 시스템 및 그 방법을 제공하는 것을 그 목적으로 한다. 여기서, 상기 비정상적인 상황은, 특정 사건이나, 사고 등과 같이 사전에 정의한 상황을 의미한다. 또한 본 발명은, 상기 감시영역에서 발생되는 비정상적인 상황에 따라 발생되는 학습용 음원을 수집하고, 상기 수집한 학습용 음원을 토대로 상기 비정상적인 상황에 대한 경험을 학습하여 학습모델을 생성하고, 상기 감시영 역에서 감지한 음원을 상기 생성한 학습모델에 적용함으로써, 상기 감지한 음원으로부터 상기 비정상적인 상황 을 신속하게 인식할 수 있도록 하는 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법을 제공하는 것 을 또 다른 목적으로 한다. 또한 본 발명은, 상기 음원을 통해 상기 비정장적인 상황을 인식함으로써, 상기 감시영역에 설치되는 복수의 감 시 카메라에 대한 사각지대에 발생되는 비정상적인 상황을 인식할 수 있도록 하는 경험적 학습기반 음원을 이용 한 상황인식 시스템 및 그 방법을 제공하는 것을 또 다른 목적으로 한다. 또한 본 발명은, 비정상적인 상황을 인식하면, 해당 음원을 전송한 음원감지모듈의 위치정보에 따라 상기 음원 감지모듈에 인접한 적어도 하나 이상의 감시 카메라를 상기 음원감지모듈이 위치하는 방향으로 회전시켜, 상기 감지한 음원이 발생한 영역을 촬영하여 디스플레이함으로써, 상기 인식한 비정상적인 상황에 대한 발생요인(객 체)을 즉각적이고 시각적으로 인식할 수 있도록 하는 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방 법을 제공하는 것을 또 다른 목적으로 한다."}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템은, 감시영역에 설치된 적어도 하 나 이상의 음원감지모듈로부터 해당 감시영역에서 감지한 음원을 수신하는 음원 수신부 및 상기 수신한 음원을 복수의 학습모델에 적용하여, 상기 감시영역에서 사전에 정의한 비정상적인 상황의 발생을 인식하는 상황 인식 부를 포함하며, 상기 복수의 학습모델은, 상기 감시영역에서 발생된 비정상적인 상황과, 상기 비정상적인 상황 에 따라 복합적으로 발생되는 음원간의 관계를 경험적으로 학습함으로써, 생성되는 것을 특징으로 한다. 또한 상기 경험적으로 학습하는 것은, 상기 감시영역에서 발생된 비정상적인 상황에 따라 음원을 학습용 음원으 로 하여 사전에 수집하고, 상기 수집한 각 학습용 음원과 상기 비정상적인 상황을 각각 나타내는 음원의 명칭간 의 매핑관계를 각각 학습함으로써, 수행되며, 상기 수집한 복수의 학습용 음원을 스펙트로그램으로 각각 변환하 여 상기 학습에 이용하는 것을 특징으로 한다. 또한 상기 상황인식 시스템은, 상기 비정상적인 상황을 인식한 경우, 해당 음원을 전송한 음원감지모듈의 위치 정보와 상기 감시영역에 설치되는 복수의 감시 카메라에 대한 위치정보에 따라 해당 음원감지모듈에 인접한 적어도 하나 이상의 감시 카메라를 해당 음원감지모듈이 위치하는 방향으로 회전시켜, 상기 음원이 발생한 영역을 촬영하도록 제어하는 감시 카메라 제어부 및 상기 제어한 적어도 하나 이상의 카메라로부터 상기 음원이 발생한 영역을 촬영한 영상을 수신하는 영상 수신부를 더 포함하는 것을 특징으로 한다. 또한 상기 상황 인식부는, 상기 음원감지모듈로부터 수신한 상기 음원을 변환한 스펙트로그램을 상기 생성한 복 수의 학습모델에 각각 적용하여, 상기 각 학습모델에서 출력한 음원의 명칭 중 제일 높은 확률을 가지는 음원의 명칭을 선택함으로써, 상기 비정상적인 상황을 인식하는 것을 특징으로 한다. 또한 상기 상황인식 시스템은, 상기 비정상적인 상황을 인식한 결과와 상기 제어한 적어도 하나 이상의 감시 카 메라로부터 수신된 영상을 포함하는 상황정보를 디스플레이에 출력하는 상황정보 출력부를 더 포함하는 것을 특 징으로 한다. 아울러 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 방법은, 감시영역에 설치된 적어 도 하나 이상의 음원감지모듈로부터 해당 감시영역에서 감지한 음원을 수신하는 음원 수신 단계 및 상기 수신한 음원을 복수의 학습모델에 적용하여, 상기 감시영역에서 사전에 정의한 비정상적인 상황의 발생을 인식하는 상 황 인식 단계를 포함하며, 상기 학습모델은, 상기 감시영역에서 발생된 비정상적인 상황에 따라 복합적으로 발 생되는 음원을 경험적으로 학습함으로써, 생성되는 것을 특징으로 한다. 또한 상기 경험적으로 학습하는 것은, 상기 감시영역에서 발생된 비정상적인 상황에 따른 복수의 음원을 학습용 음원으로 하여 사전에 수집하고, 상기 수집한 각 학습용 음원과 상기 비정상적인 상황을 나타내는 음원의 명칭 간의 매핑관계를 각각 학습함으로써, 수행되며, 상기 수집한 복수의 학습용 음원을 스펙트로그램으로 각각 변환 하여 상기 학습에 이용하는 것을 특징으로 한다. 또한 상기 상황인식 방법은, 상기 비정상적인 상황을 인식한 경우, 해당 음원을 전송한 음원감지모듈의 위치정 보와 상기 감시영역에 설치되는 복수의 감시 카메라에 대한 위치정보에 따라 해당 음원감지모듈에 인접한 적어 도 하나 이상의 감시 카메라를 해당 음원감지모듈이 위치하는 방향으로 회전시켜, 상기 음원이 발생한 영역을 촬영하도록 제어하는 감시 카메라 제어 단계 및 상기 제어한 적어도 하나 이상의 카메라로부터 상기 음원이 발 생한 영역을 촬영한 영상을 수신하는 영상 수신 단계를 더 포함하는 것을 특징으로 한다. 또한 상기 상황 인식 단계는, 상기 음원감지모듈로부터 수신한 상기 음원을 변환한 스펙트로그램을 상기 생성한 복수의 학습모델에 각각 적용하여, 상기 각 학습모델에서 출력한 음원의 명칭 중 제일 높은 확률을 가지는 음원 의 명칭을 선택함으로써, 상기 비정상적인 상황을 인식하는 것을 특징으로 한다. 또한 상기 상황인식 방법은, 상기 비정상적인 상황을 인식한 결과와 상기 제어한 적어도 하나 이상의 감시 카메 라로부터 수신된 영상을 포함하는 상황정보를 디스플레이에 출력하는 상황정보 출력 단계를 더 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같이 본 발명의 경험적 학습기반 음원을 이용한 상황인식 시스템은, 감시영역에 따라 발생되는 비정 상적인 상황에 대한 학습용 음원을 경험적으로 학습하여 학습모델을 생성하고, 상기 감시영역에서 설치된 복수 의 음원감지모듈을 통해 감지된 음원을 상기 학습모델에 적용하여, 상기 감시영역에서 발생된 비정상적인 상황 을 실시간으로 인식함으로써, 상기 비정상적인 상황에 대한 신속한 대처가 가능하도록 하는 효과가 있다. 또한 본 발명은, 상기 비정상적인 상황이 인식된 경우, 적어도 하나 이상의 감시 카메라를 해당 음원을 감지한 상기 음원감지모듈이 위치하는 방향으로 회전시켜, 상기 감지한 음원이 발생한 영역을 촬영하여, 해당 영역을 촬영한 영상을 상기 관리자에게 제공함으로써, 상기 인식한 비정상적인 상황의 요인이 되는 객체를 즉각적으로 인식할 수 있도록 하는 효과가 있다."}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 발명의 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법에 대한 바람직한 실시예를 상세히 설명한다. 각 도면에 제시된 동일한 참조부호는 동일한 부재를 나타낸다. 또한 본 발 명의 실시예들에 대해서 특정한 구조적 내지 기능적 설명들은 단지 본 발명에 따른 실시예를 설명하기 위한 목 적으로 예시된 것으로, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모"}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "든 용어들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지 는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적 이거나 과도하게 형식적인 의미로 해석되지 않는 것이 바람직하다. 본 발명에서는 데이터는 디지털 정보로 해석 할 수 있다. 도 1은 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법을 설명하기 위 해 나타낸 도면이다. 도 1에 도시한 바와 같이, 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템 (이하, 상황인식 시스템이라 칭함)은, 사전에 설정된 복수의 감시영역에 각각 설치되는 복수의 음원감지모듈 을 통해 감지된 음원을 토대로 상기 감시영역에서의 비정상적인 상황의 발생을 인식함으로써, 관리자로 하 여금 상기 발생한 비정상적인 상황에 대한 대처를 신속하게 수행하도록 한다. 여기서, 상기 비정상적인 상황은, 상기 감시영역에서 발생될 수 있는 사건(예: 사람들 간의 다툼)이나 사고(예: 특정 물건의 파손 등) 등을 포함하여 사전에 정의된 특정 상황을 의미한다. 즉, 상기 비정상적인 상황은, 상기 감시영역에서 발생될 수 있는 다양한 상황 중에서 예상하지 못한 의외의 상황을 의미하는 것이다. 또한 상기 상황인식 시스템은, 상기 비정상적인 상황의 발생이 인식된 경우, 상기 감시영역에 설치된 적어 도 하나 이상의 감시 카메라를 통해 상기 비정상적인 상황이 발생한 영역을 촬영하도록 하고, 상기 비정상 적인 상황을 인식한 결과와 상기 촬영한 영상을 포함하는 상황정보를 디스플레이에 출력한다. 이를 통해 상기 관리자는, 상기 비정상적인 상황의 발생요인이 되는 객체를 시각적으로 인식할 수 있으며, 상기 비정상적인 상황에 대해 신속하게 대처할 수 있다. 상기 감시영역은, 상기 적어도 하나 이상의 음원감지모듈과 상기 적어도 하나 이상의 감시 카메라가 설치되는 곳으로, 쇼핑몰, PC 방 등과 같은 매장이나, 지하철, 병원, 공원 등의 실내외 특정 장소 등을 포함하 는 개념이다. 또한 상기 음원감지모듈은, 적어도 하나 이상의 마이크로폰을 구비하여 구성된다. 또한 상기 음원감지모듈 은, 상기 마이크로폰을 통해 상기 감시영역에서 발생되는 음원을 감지하는 기능을 수행한다. 또한 상기 음원감지모듈은, 상기 음원을 감지한 경우, 상기 감지한 음원과 함께 해당 음원감지모듈에 부여된 위치정보, 식별정보(ID) 또는 이들의 조합을 상기 상황인식 시스템으로 전송한다. 또한 상기 감시 카메라는, CCTV, 가시광 카메라, 적외선 카메라 또는 이들의 조합을 포함하여 구성되며, 상기 감시영역을 실시간으로 촬영한 영상을 상기 상황인식 시스템으로 전송하는 기능을 수행한다. 이때, 상기 감시 카메라는, 상기 획득한 영상과 함께 해당 감시 카메라의 위치정보, 식별정보(ID) 또는 이 들이 조합을 상기 상황인식 시스템으로 전송하여, 상기 영상을 통해 해당 감시영역에 대한 모니터링을 수 행할 수 있도록 한다. 또한 상기 상황인식 시스템은, 상기 감시영역별로 설치된 적어도 하나 이상의 음원감지모듈과 상기 적어도 하나 이상의 감시 카메라에 대한 위치정보와 식별정보를 각각 매핑하여 데이터베이스에 저장 하여 관리한다. 또한 상기 상황인식 시스템은, 상기 감시영역에 설치된 적어도 하나 이상의 음원감지모듈에서 감지한 음원이 수신되는 경우, 상기 감시영역에 대해 생성한 복수의 학습모델에, 상기 수신한 각각 음원을 적용하여, 상기 감시영역에서 발생된 비정상적인 상황의 발생을 인식한다. 상기 복수의 학습모델은, 상기 감시영역 및 비정상적인 상황에 따라 각각 구비되며, 상기 감시영역에 따라 사전 에 수집한 복수의 학습용 음원을 이미지화하여 각각 학습함으로써, 생성된다. 이때, 상기 복수의 학습용 음원은, 상기 감시영역에서 발생된 상기 비정상적인 상황에 따라 발생된 음원을 각각 수집한 것으로, 상기 학습용 음원은 상기 비정상적인 상황을 나타내는 음원의 명칭과 매핑되어, 상기 데이터베 이스에 저장되며, 상기 학습모델은, 상기 학습용 음원과 상기 음원의 명칭간의 매핑관계를 학습함으로써, 생성된다. 예를 들어, 특정 학습용 음원이 상기 비정상적인 상황이 누군가 특정 물건(예: 유리창)을 부수는 상황에 대한 음원이라고 하면, 해당 학습용 음원에 매핑되는 상기 비정상적인 상황을 나타내는 음원의 명칭은 \"물건 파쇄 음 (예: 유리창 파쇄 음)\"이 될 수 있다. 즉, 상기 학습모델은, 상기 감시영역에서 상기 사전에 정의한 비정상적인 상황에 따라 발생되는 학습용 음원을 경험적으로 학습함으로써, 생성되는 것이다. 또한 상기 수집한 복수의 학습용 음원이나, 상기 음원감지모듈 로부터 수신되는 음원은, 특정 비정상적인 상황에 따라 복합적으로 발생되는 소리들이 포함된 것을 의미한 다. 또한 상기 학습은, 이미지를 토대로 특정 결과를 도출하는 데 최적화된 학습네트워크인 CNN(Convolutional Neural Network)을 통해 수행되며, 상기 학습모델의 입력은 상기 적어도 하나 이상의 음원감지모듈에서 감 지한 음원을 이미지화한 이미지이며, 출력은, 특정 비정상적인 상황에 대한 확률이다. 상기 학습네트워크의 구 조는 도 2를 참조하여 상세히 설명하도록 한다. 상기 학습모델은, 상기 상황인식 시스템에서 상기 감시영역에 따라 발생될 수 있는 비정상적인 상황별로 생성된다. 한편, 도 1에는, 상기 비정상적인 상황을 인식하는 것은, 상기 상황인식 시스템에서 수행되는 것으로 나타 나 있으나, 상기 감시영역별로 생성한 적어도 하나 이상의 학습모델을 상기 음원감지모듈에 전송하여, 상 기 음원감지모듈에서 상기 비정상적인 상황을 인식할 수 있도록 구현될 수 있다. 이때, 상기 음원감지모듈 은, 비정상적인 상황의 발생을 인식한 경우, 인식한 결과를 상기 상황인식 시스템으로 전송하여, 상 기 디스플레이에 출력할 수 있도록 함으로써, 상기 관리자가 이를 시각적이고 즉각적으로 확인할 수 있도록 한 다. 또한 상기 학습모델은, 새롭게 정의된 비정상적인 상황 또는 사전에 정의한 비성장적인 상황에 따른 음원이 추 가될 때 마다, 새롭게 생성되거나 또는 업데이트되며, 상기 학습모델을 이용하여 상기 비정상적인 상황을 인식 하는 것은, 본 발명의 핵심적인 기술적 특징으로써, 도 3 및 도 4를 참조하여 상세히 설명하도록 한다. 또한 상기 상황인식 시스템은, 상기 감시구역에 설치되는 복수의 감시 카메라로부터, 사전에 설정한 범위에 따라 상기 감시구역을 각각 촬영한 영상을 실시간으로 수신하여, 상기 수신한 각 영상을 상기 디스플레 이에 출력하여, 상기 관리자로 하여금 해당 감시구역을 모니터링할 수 있도록 하는 것은 당연하다. 또한 상기 데이터베이스는, 상기 생성한 복수의 학습모델을 저장하여 관리하는 학습모델 데이터베이스 , 수집한 복수의 학습용 음원을 저장하여 관리하는 학습용 음원 데이터베이스, 상기 적어도 하나 이 상의 음원감지모듈로부터 수신되는 음원을 저장하여 관리하는 음원 데이터베이스 및 상기 적어도 하 나 이상의 감시 카메라로부터 수신되는 영상을 저장하여 관리하는 영상 데이터베이스를 포함하여 구 성된다. 또한 상기 생성한 복수의 학습모델은, 상기 감시영역별로 상기 비정상적인 상황에 따라 분류되어 저장되며, 또 한 상기 복수의 학습용 음원도 상기 감시영역별로 상기 비정상적인 상황에 따라 분류되어 저장된다. 이때, 상기 수집한 복수의 학습용 음원은, 상기 비정상적인 상황을 나타내는 음원의 명칭과 각각 매핑되어 저장된다. 도 2는 본 발명의 일 실시예에 따른 학습네트워크의 구조를 나타낸 도면이다. 도 2에 도시한 바와 같이, 본 발명의 일 실시예에 따른 감시영역에서 비정상적인 상황을 인식하기 위해 생성되 는 학습모델은, 이미지 처리에 최적화된 학습네트워크인 CNN을 통해 생성될 수 있다. 상기 CNN으로 구성되는 본 발명의 학습네트워크는, 상기 감시영역과 상기 비정상적인 상황에 따라 각각 준비되 어, 상기 수집한 복수의 학습용 음원과 상기 비정상적인 상황을 각각 나타내는 음원의 명칭간의 매핑관계를 각 각 학습하여, 복수의 학습모델을 생성하게 된다. 이때, 상기 학습네트워크는, 상기 학습용 음원을 변환한 스펙트로그램(Spectrogram)을 입력하는 입력 레이어 (Input Layer), 상기 입력한 스펙트로그램에 대한 컨볼루션을 수행하는 컨볼루션 레이어(Convolution Layer), 상기 컨볼루션한 결과를 풀링하는 풀링 레이어(Pooling Layer) 및 완전연관 레이어(Fully Connected Layer)를 포함하여 구성된다. 상기 컨볼루션 레이어는, 특정 가중치를 가지는 커널을 사전에 설정한 스트라이드에 따라 상기 입력한 학습용 음원의 스펙트로그램 상에서 이동시켜가며, 상기 스펙트로그램의 특정 부분과 상기 커널의 가중치를 컨볼루션하 여, 복수의 특징맵을 생성하여 출력하며, 상기 풀링 레이어는, 상기 특징맵을 최대값 또는 평균값으로 풀링함으 로써, 복수의 서브 이미지로 서브 샘플링한다. 이때, 상기 컨볼루션 레이어와 상기 풀링 레이어는 하나의 쌍으 로 구성되어 적어도 하나 이상으로 구현될 수 있다. 상기 완전연관 레이어는, 상기 서브 샘플링한 복수의 서브 이미지를 연결시켜, 상기 스펙트로그램으로 변환하여 입력한 학습용 음원에 대해 비정상적인 상황을 나타내는 음원의 명칭에 대한 확률을 출력한다. 여기서 상기 확 률은 0 내지 1 사이의 값을 가진다. 또한 상기 완전연관 레이어는, 상기 복수의 서브 이미지를 각각 입력하는 입력노드, 상기 각 입력노드 연결되는 복수의 히든노드 및 상기 복의 히든노드에서 출력되는 결과를 소프트 맥스를 통해 정규화하여, 상기 음원의 명 칭에 대한 확률을 출력하는 출력노드를 포함하여 구성된다. 한편, 상기 학습네트워크를 통해 학습을 수행할 때, 상기 학습이 상기 학습용 음원에만 치우쳐 수행되어, 실제 생성한 학습모델에 실제 음원을 적용하였을 때, 상기 실제 음원에 대한 상기 학습모델의 출력결과에서 오차가 현저하게 증가하는 현상인 과적합(Overfitting)이 발생될 수 있다. 이를 방지하기 위해 본 발명은, 상기 학습을 수행할 때, 상기 완전연관 레이어의 적어도 하나 이상의 히든 노드 를 일정 확률로 선택하여, 상기 선택한 적어도 하나 이상의 히든 노드의 출력을 0으로 설정하는 드롭아웃(Drop out) 기법을 적용하여, 상기 과적합을 방지할 수 있도록 한다. 이러한 드롭아웃 기법을 통해, 상기 학습의 결과로 발생될 수 있는 과적합을 방지하여, 상기 생성한 학습모델의 출력결과에 대한 오차를 줄여 상기 음원감지모듈로부터 감지한 음원에 따른 비정상적인 상황을 정확하게 인식할 수 있도록 한다. 도 3은 본 발명의 일 실시예에 따른 학습모델을 설명하기 나타낸 도면이다. 도 3에 도시한 바와 같이, 본 발명의 일 실시예에 따른 감시구역에 설치된 적어도 하나 이상의 음원감지모듈 로부터 수신한 음원을 토대로 상기 감시구역에서 발생한 비정상적인 상황을 인식하기 위한 학습모델은, 상 기 수집한 복수의 학습용 음원을 각각 학습하여, 비정상적인 상황에 따라 각각 생성된다. 즉, 상기 학습모델은, 상기 감시구역에서 사전에 정의한 비정상적인 상황이 발생될 때, 상기 발생된 비정상적인 상황에 따라 발생되는 복합적인 음원을 학습용 음원으로 수집하여, 상기 비정상적인 상황에 따라 상기 수집한 학습용 음원을 경험적으로 각각 학습함으로써, 생성되는 것이다. 이때, 상기 수집한 각각의 학습용 음원은, 상기 비정상적인 상황을 나타내는 음원의 명칭이 각각 매핑되어 저장 된다. 즉, 상기 학습모델은 상기 수집한 복수의 학습용 음원과 상기 비정상적인 상황을 나타내는 음원의 명칭간 의 매핑관계를 학습하여, 생성되는 것이다. 이때, 상기 복수의 학습용 음원은, 각 학습용 음원을 상기 시간에 따른 상기 학습용 음원의 진폭의 변화, 상기 학습용 음원의 주파수 변화에 따른 상기 학습용 음원의 진폭의 변화를 시간에 따라 시각화하여 이미지화한 스펙 트로그램으로 변환되어 상기 학습에 이용된다. 또한 상기 상황인식 시스템은, 상기 감시영역에 설치된 적어도 하나 이상의 음원감지모듈에서 감지한 음원이 상기 음원감지모듈로부터 수신되는 경우, 상기 수신한 음원을 스펙트로그램으로 변환한다.이후, 상기 상황인식 시스템은, 상기 변환한 음원의 스펙트로그램을 상기 생성한 복수의 학습모델에 각각 적용함으로써, 상기 감시영역에서 발생한 비정상적인 상황을 인식한다. 이때, 상기 비정상적인 상황을 인식하는 것은, 상기 각 학습모델에서 출력하는 특정 비정상적인 상황을 나타내 는 음원의 명칭일 확률 중 제일 높은 확률을 가지는 음원의 명칭을 선택함으로써, 수행된다. 한편, 상기 상황인식 시스템은, 상기 각 학습모델의 출력에서, 사전에 설정한 임계값(예: 0.8 이상)을 초 과하는 확률 중 제일 높은 확률을 가지는 음원의 명칭을 선택하여, 상기 비정상적인 상황을 인식하는 것이 바람 직하다. 이때, 상기 상황인식 시스템은, 상기 모든 학습모델의 출력이, 사전에 설정한 임계값을 초과하지 않는 경 우에는, 상기 감시영역에서 상기 비정상적인 상황인 발생하지 않는 것으로 판단한다. 도 4는 본 발명의 일 실시예에 따른 음원을 이용하여 비정상적인 상황을 인식하기 위한 상황인식 시스템의 동작 을 설명하기 위해 나타낸 도면이다. 도 4에 도시한 바와 같이, 본 발명의 일 실시예에 따른 상황인식 시스템은, 감시영역에 설치된 적어도 하 나 이상의 음원감지모듈로부터, 상기 감시영역에서 감지한 음원이 수신(①)되면, 상기 수신한 음원을 스펙 트로그램으로 변환한다(②). 상기 스펙트로그램은, 상기 수신한 음원을 시간의 변화에 따른 해당 음원의 진폭, 주파수, 진폭의 변화를 이미 지화한 것임은 상술한 바와 같다. 또한 상기 음원감지모듈은, 상기 음원을 상기 상황인식 시스템으로 전송할 때, 해당 음원감지모듈 에 부여된 식별정보, 위치정보 또는 이들의 조합을 전송한다. 또한 상기 상황인식 시스템은, 상기 수신한 음원을 변환한 스펙트로그램을 상기 생성한 복수의 학습모델에 각각 적용하여, 상기 감시영역에서 발생한 비정상적인 상황을 실시간으로 인식한다(③). 이때, 상기 상황인식 시스템은, 해당 감시영역에 대해 생성한 복수의 학습모델을 상기 학습모델 데이터베 이스로부터 로딩하고, 상기 로딩한 복수의 학습모델에 상기 수신한 음원을 변환한 스펙트로그램을 각각 적 용한다. 또한 상기 상황인식 시스템은, 상기 복수의 학습모델에 대한 각 출력결과를 확인하여, 제일 높은 확률을 가지는 비정상적인 상황을 나타내는 음원의 명칭을 선택함으로써, 상기 비정상적인 상황을 인식한다. 또한 상기 상황인식 시스템은, 상기 비정상적인 상황이 인식된 경우, 데이터베이스에 저장된 감시 카 메라의 위치정보를 참조하여, 상기 참조한 감시 카메라의 위치정보와, 해당 음원을 전송한 음원감지 모듈의 위치정보에 따라, 해당 음원을 전송한 음원감지모듈에 인접한 적어도 하나 이상의 감시 카메 라를 선택한다. 이후, 상기 상황인식 시스템은, 상기 선택한 적어도 하나 이상의 감시 카메라를 상기 음원을 전송한 음원감지모듈이 위치하는 방향으로 회전시켜, 상기 음원을 전송한 음원감지모듈이 위치하는 방향으로, 상기 감시영역에 대한 영상을 촬영하도록 상기 선택한 적어도 하나 이상의 감시 카메라에 대한 제어명령을 생성하여, 상기 선택한 적어도 하나 이상의 감시 카메라로 전송한다. 즉, 상기 상황인식 시스템은, 상기 선택한 적어도 하나 이상의 감시 카메라를 제어(④)하여, 상기 제 어를 통해 상기 적어도 하나 이상의 감시 카메라로부터 상기 음원이 발생한 영역을 촬영한 영상을 수신하 도록 하는 것이다. 또한 상기 상황인식 시스템은, 상기 비정상적인 상황을 인식한 결과와 상기 제어를 통해 상기 음원이 발생 한 영역을 촬영한 상기 적어도 하나 이상의 감시 카메라로부터 수신한 적어도 하나 이상의 영상을 포함하 는 상황정보를 디스플레이에 출력한다(⑤). 이를 통해, 상기 관리자는, 상기 감시영역에서 발생한 비정상적인 상황과 상기 비정상적인 상황의 원인이 되는 객체를 즉각적으로 인식할 수 있으며, 이에 대한 대처를 신속하게 수행할 수 있다. 또한 상기 상황인식 시스템 은, 상기 비정상적인 상황이 인식된 경우, 사전에 등록한 관리자의 관리자 단말로 상기 상황정보를 제공할 수 있음은 당연하다. 도 5는 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템의 구성을 나타낸 블록도이 다. 도 5에 도시한 바와 같이, 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템은, 학습용 음원을 수집하는 학습용 음원 수집부, 감시영역에 설치된 적어도 하나 이상의 음원 감지모듈로부터, 상기 감시영역에서 발생한 음원을 수신하는 음원 수신부, 상기 수집한 복수의 학습 용 음원과, 상기 음원감지모듈로부터 수신한 상기 음원을 스펙트로그램으로 변환하는 스펙트로그램 변환부 , 상기 수집한 복수의 학습용 음원을 각각 학습하여 복수의 학습모델을 생성하는 학습모델 생성부, 상기 수신한 음원을 토대로 상기 감시영역에서 발생한 비정상적인 상황을 인식하는 상황 인식부, 상기 비 정상적인 상황이 인식되면, 상기 감시영역에 설치되는 적어도 하나 이상의 감시 카메라를 제어하는 감시 카메라 제어부, 상기 제어한 적어도 하나 이상의 감시 카메라로부터 영상을 수신하는 영상 수신부 및 상기 인식한 비정상적인 상황과, 상기 수신한 영상을 포함하는 상황정보를 디스플레이에 출력하는 상 황정보 출력부를 포함하여 구성된다. 상기 학습용 음원 수집부는, 상기 감시영역에 발생된 비정상적인 상황에 따라 복합적으로 발생되는 음원을 학습용 음원으로 사전에 수집하여, 상기 학습용 음원 데이터베이스에 저장한다. 이때, 상기 수집한 복수의 학습용 음원은, 상기 감시영역을 관리하는 관리자에 의해 수집되어, 상기 학습용 음 원을 수집한 상기 관리자의 관리자 단말을 통해 제공받거나, 상기 감시영역에 사전에 설치된 적어도 하나 이상의 음원감지모듈을 통해 제공받음으로써, 수집될 수 있다. 즉, 상기 수집한 학습용 음원은, 상기 학습을 위해 상기 감시영역에서 발생된 비정상적인 상황에 따른 복수의 음원을 복수의 학습용 음원으로 하여 사전에 수집하는 것이다. 또한 상기 수집한 복수의 학습용 음원은, 상기 비정상적인 상황을 나타내는 음원의 명칭과 매핑되어 상기 학습 용 음원 데이터베이스에 저장된다. 또한 상기 스펙트로그램 변환부는, 상기 수집한 복수의 학습용 음원을 스펙트로그램으로 변환하여, 상기 복수의 학습용 음원을 변환한 스펙트로그램을 상기 학습을 수행할 때 이용하도록 한다. 또한 상기 스펙트로그램 변환부는, 상기 음원감지모듈로부터 수신한 음원을 스펙트로그램으로 변환하 는 기능을 수행한다. 또한 상기 학습모델 생성부는, 상기 수집한 복수의 학습용 음원을 각각 학습하여, 상기 비정상적인 상황을 인식하기 위한 복수의 학습모델을 생성한다. 이때, 상기 학습모델 생성부는, 상기 수집한 복수의 학습용 음원과 상기 각 학습용 음원별로 비정상적인 상황을 나타내는 음원의 명칭간 매핑관계를 학습함으로써, 상기 복수의 학습모델을 생성한다. 또한 상기 복수의 학습용 음원은, 상기 스펙트로그램 변환부에 의해 스펙트로그램으로 변환되어 상기 학습 에 이용된다. 즉, 상기 학습모델 생성부는, 상기 비정상적인 상황이 발생할 때의 경험(즉, 비정상적인 상황이 발생될 때, 발생되는 음원)을 학습함으로써, 상기 비정상적인 상황에 따른 복수의 학습모델을 생성하는 것이며, 상기 생성한 각 학습모델의 입력은 상기 음원감지모듈로부터 수신한 음원을 변환한 스펙트로그램이 되며, 출력 은, 특정 비정상적인 상황을 나타내는 음원의 명칭이 된다. 또한 상기 상황 인식부는, 상기 스펙트로그램 변환부를 통해 상기 음원감지모듈로부터 수신한 음원을 변환한 스펙트로그램을 이용하여, 상기 감시영역에서 발생한 비정상적인 상황을 인식한다. 이때, 상기 상황 인식부는, 해당 감시영역에 대해 생성한 복수의 학습모델을 상기 학습모델 데이터베이스 로부터 로딩하고, 상기 변환한 음원의 스펙트로그램을 상기 로딩한 복수의 학습모델에 각각 적용하여, 상 기 각 학습모델의 출력으로부터 특정 비정상적인 상황을 나타내는 음원의 명칭일 확률 중 제일 높은 확률을 가 지는 음원의 명칭을 선택함으로써, 상기 비정상적인 상황을 인식한다. 한편, 상기 상황 인식부는, 상기 각 학습모델의 출력에서, 사전에 설정한 임계값(예: 0.8)을 초과한 확률 중에 제일 높은 확률을 가지는 음원의 명칭을 선택함으로써, 상기 비정상적인 상황을 인식하는 것이 바람직하다. 또한 상기 감시 카메라 제어부는, 상기 비정상적인 상황이 인식된 경우, 상기 음원을 전송한 음원감지모듈 에 인접한 적어도 하나 이상의 감시 카메라를 제어하여, 상기 제어한 적어도 하나 이상의 감시 카메 라를 통해 상기 음원이 발생한 영역을 촬영한 영상을 수신할 수 있도록 하는 기능을 수행한다. 이때, 상기 카메라 제어부는, 상기 해당 음원을 전송한 음원감지모듈의 위치정보와, 상기 감시영역에 설치된 적어도 하나 이상의 감시 카메라의 위치정보에 따라 상기 음원감지모듈에 인접한 적어도 하나 이상의 감시 카메라를 선택한다. 이후, 상기 카메라 제어부는, 상기 음원감지모듈이 위치하는 방향으로 상기 선택한 적어도 하나 이상의 감시 카메라를 회전시켜 촬영하기 위한 제어정보를 생성하여, 상기 선택한 적어도 하나 이상의 감시 카메라로 상기 생성한 제어정보를 전송함으로써, 상기 음원감지모듈 에 인접한 적어도 하나 이상의 감시 카메라를 제어한다. 또한 상기 영상 수신부는, 상기 제어한 결과에 따라 상기 적어도 하나 이상의 감시 카메라로부터 상 기 음원이 발생한 영역을 촬영한 영상을 각각 수신하는 기능을 수행한다. 다만, 상기 영상 수신부는, 상기 감시영역에 설치된 적어도 하나 이상의 감시 카메라로부터 상기 감 시영역을 각각 촬영한 영상을 실시간으로 수신하여 디스플레이에 출력함으로써, 관리자로 하여금 상기 감시영역 을 모니터링할 수 있도록 함은 당연할 것이다. 또한 상기 상황정보 출력부는, 상기 비정상적인 상황을 인식한 인식결과와 상기 선택한 적어도 하나 이상 의 감시 카메라로부터 수신한 상기 음원이 발생한 영역(즉, 비정상적인 상황이 발생한 영역)을 촬영한 영 상을 포함하는 상황정보를 디스플레이에 출력하여 표시하는 기능을 수행한다. 즉, 상기 상황정보 출력부는, 상기 인식한 비정상적인 상황을 나타내는 음원의 명칭과, 상기 비정상적인 상황이 발생한 영역을 상기 디스플레이에 출력함으로써, 상기 관리자가 상기 감시영역에서 발생한 비정상적인 상황과 상기 비정상적인 상황의 발생요인(예: 객체)을 즉각적이고 시각적으로 인식할 수 있도록 한다. 도 6은 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템을 통해 비정상적인 상황을 인식하는 절차를 나타낸 흐름도이다. 도 6에 도시한 바와 같이, 본 발명의 일 실시예에 따른 상황인식 시스템을 통해 감시영역에서 발생한 비정 상적인 상황을 인식하는 절차는 우선, 상기 상황인식 시스템은, 상기 감시영역에 설치된 적어도 하나 이상 의 음원감지모듈로부터 상기 감시영역에서 감지한 음원을 수신하는 음원 수신 단계를 수행한다(S110). 상기 음원감지모듈은, 상기 감지한 음원을 상기 상황인식 시스템으로 전송할 때, 해당 음원감지모듈 에 부여된 식별정보, 위치정보 또는 이들의 조합을 함께 전송함은 상술한 바와 같다. 다음으로 상기 상황인식 시스템은, 상기 수신한 음원을 스펙트로그램으로 변환하는 스펙트로그램 변환 단 계를 수행(S120)하고, 상기 변환한 음원의 스펙트로그램을 상기 생성한 복수의 학습모델에 적용하여, 상기 감시 영역에서 발생한 비정상적인 상황을 인식하는 상황 인식 단계를 수행한다(S130). 여기서, 상기 복수의 학습모델은, 상기 감시영역에서 발생된 비정상적인 상황에 대한 경험을 학습함으로써, 생 성됨은 상술한 바와 같다. 또한 상기 비정상적인 상황을 인식하는 것은, 상기 각 학습모델의 출력 중에서, 제일 높은 확률을 가지는 특정 비정상적인 상황을 나타내는 음원의 명칭을 선택함으로써, 수행된다. 다음으로 상기 상황인식 시스템은, 상기 인식한 결과, 비정상적인 상황이 인식된 경우(S140), 상기 음원을 전송한 음원감지모듈의 위치정보에 따라 해당 음원감지모듈에 인접한 적어도 하나 이상의 카메라 를 제어하는 카메라 제어 단계를 수행한다(S140). 즉, 상기 상황인식 시스템은, 상기 음원감지모듈에 인접한 적어도 하나 이상의 카메라를 제어하 여, 상기 비정상적인 상황이 발생한 영역(음원이 발생한 영역)을 촬영하도록 하는 것이다. 다음으로 상기 상황인식 시스템은, 상기 제어한 적어도 하나 이상의 감시 카메라로부터 상기 비정상 적인 상황이 발생한 영역을 촬영한 영상을 수신하는 영상 수신 단계를 수행한다(S150). 이후, 상기 상황인식 시스템은, 상기 비정상적인 상황을 인식한 결과와, 상기 수신한 영상을 포함하는 상 황정보를 디스플레이에 출력하는 상황정보 출력 단계를 수행한다(S160). 도 7은 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템의 하드웨어 구조를 나타낸 도면이다.도 7에 도시한 것과 같이, 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템에 대한 하드웨어 구조는, 중앙처리장치, 메모리, 사용자 인터페이스, 데이터베이스 인터페이스 , 네트워크 인터페이스, 웹서버 등을 포함하여 구성된다. 상기 사용자 인터페이스는 그래픽 사용자 인터페이스(GUI, graphical user interface)를 사용함으로써, 사용자(관리자)에게 입력과 출력 인터페이스를 제공한다. 상기 데이터베이스 인터페이스는 데이터베이스와 하드웨어 구조 사이의 인터페이스를 제공한다. 상기 네 트워크 인터페이스는 사용자가 보유한 장치간의 네트워크 연결을 제공한다. 상기 웹 서버는 관리자가 네트워크를 통해 하드웨어 구조로 액세스하기 위한 수단을 제공한다. 대부분의 사용자들은 원격에서 웹 서버로 접속하여 상황인식 시스템에서 제공하는 기능을 이용할 수 있다. 상술한 구성 또는 방법의 각 단계는, 컴퓨터 판독 가능한 기록매체 상의 컴퓨터 판독 가능 코드로 구현되거나 전송 매체를 통해 전송될 수 있다. 컴퓨터 판독 가능한 기록매체는, 컴퓨터 시스템에 의해 읽혀질 수 있는 데이 터를 저장할 수 있는 데이터 저장 디바이스이다. 컴퓨터 판독 가능한 기록매체의 예로는 데이터베이스, ROM, RAM, CD-ROM, DVD, 자기 테이프, 플로피 디스크 및 광학 데이터 저장 디바이스가 있으나 이에 한정되는 것은 아니다. 전송매체는 인터넷 또는 다양한 유형의 통신 채널을 통해 전송되는 반송파를 포함할 수 있다. 또한 컴퓨터 판독 가능한 기록매체는, 컴퓨터 판독 가능 코드 가 분산 방식으로 저장되고, 실행되도록 네트워크 결합 컴퓨터 시스템을 통해 분배될 수 있다. 또한 본 발명에 적용된 적어도 하나 이상의 구성요소는, 각각의 기능을 수행하는 중앙처리장치(CPU), 마이크로 프로세서 등과 같은 프로세서를 포함하거나 이에 의해 구현될 수 있으며, 상기 구성요소 중 둘 이상은 하나의 단일 구성요소로 결합되어 결합된 둘 이상의 구성요소에 대한 모든 동작 또는 기능을 수행할 수 있다. 또한 본 발명에 적용된 적어도 하나 이상의 구성요소의 일부는, 이들 구성요소 중 다른 구성요소에 의해 수행될 수 있다. 또한 상기 구성요소들 간의 통신은 버스(미도시)를 통해 수행될 수 있다. 이상에서 설명한 바와 같이, 본 발명은 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법은, 상기 감 시영역에서 사전에 정의한 비정상적인 상황에 따라 발생되는 복수의 음원(즉, 학습용 음원)을 경험적으로 학습 하여, 생성한 복수의 학습모델을 통해 상기 감시영역에서 감지한 음원을 토대로 상기 감시영역에서 발생된 비정 상적인 상황을 실시간으로 인식할 수 있는 효과가 있다. 상기에서는 본 발명에 따른 바람직한 실시예를 위주로 상술하였으나, 본 발명의 기술적 사상은 이에 한정되는 것은 아니며 본 발명의 각 구성요소는 동일한 목적 및 효과의 달성을 위하여 본 발명의 기술적 범위 내에서 변 경 또는 수정될 수 있을 것이다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2020-0037774", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형 실시들은 본 발명 의 기술적 사상이나 전망으로부터 개별적으로 이해되어서는 안 될 것이다."}
{"patent_id": "10-2020-0037774", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템 및 그 방법을 설명하기 위 해 나타낸 도면이다. 도 2는 본 발명의 일 실시예에 따른 학습네트워크의 구조를 나타낸 도면이다. 도 3은 본 발명의 일 실시예에 따른 학습모델을 설명하기 나타낸 도면이다. 도 4는 본 발명의 일 실시예에 따른 음원을 이용하여 비정상적인 상황을 인식하기 위한 상황인식 시스템의 동작을 설명하기 위해 나타낸 도면이다. 도 5는 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템의 구성을 나타낸 블록도이 다. 도 6은 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템을 통해 비정상적인 상황을 인식하는 절차를 나타낸 흐름도이다. 도 7은 본 발명의 일 실시예에 따른 경험적 학습기반 음원을 이용한 상황인식 시스템의 하드웨어 구조를 나타낸 도면이다."}
