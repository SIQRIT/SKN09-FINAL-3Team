{"patent_id": "10-2022-0052778", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0153054", "출원번호": "10-2022-0052778", "발명의 명칭": "사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법, 이를 수행하는 장치 및", "출원인": "연세대학교 산학협력단", "발명자": "이경호"}}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "레이블링된 데이터세트(labeled dataset)를 기반으로 사전-학습 언어 모델(pre-trained language model)과 태스크 분류기(task classifier)를 초기화하는 단계; 및상기 사전-학습 언어 모델 및 상기 태스크 분류기를 이용하여 트리플 로스(triplet loss)를 기반으로 레이블링되지 않은 데이터세트(unlabeled dataset)를 대상으로 액티브 러닝(active learning)을 수행하는 단계;를 포함하는 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 액티브 러닝 수행 단계는,상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터세트에서 획득한 문장 표현(sentencerepresentation) 및 상기 태스크 분류기를 이용하여 상기 레이블링되지 않은 데이터세트에서 획득한 태스크-관련 특징(task-related feature)을 기반으로 상기 트리플 로스를 획득하고, 상기 트리플 로스를 이용하여 상기레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링(labeling)하는 것으로 이루어지는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 액티브 러닝 수행 단계는,상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터세트의 샘플에 대한 상기 문장 표현을 획득하고,상기 태스크 분류기를 이용하여 상기 레이블링되지 않은 데이터세트의 샘플에 대한 상기 태스크-관련 특징을 획득하며,상기 문장 표현 및 상기 태스크-관련 특징을 기반으로 통합 데이터 샘플 특징(integrated data sample feature)을 획득하고,상기 통합 데이터 샘플 특징을 기반으로 목표 태스크 로스(target task loss) 및 상기 트리플 로스를 획득하며,상기 목표 태스크 로스 및 상기 트리플 로스를 기반으로 획득된 최종 로스(final loss)를 이용하여 상기 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링하는 것으로 이루어지는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서,상기 액티브 러닝 수행 단계는,레이블링된 샘플을 기반으로 상기 사전-학습 언어 모델과 상기 태스크 분류기를 업데이트하고,레이블링된 샘플을 상기 레이블링된 데이터세트에 추가하는 것으로 이루어지는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0153054-3-제4항에서,상기 액티브 러닝 수행 단계는,[식 1]을 이용하여 상기 트리플 로스 Ltriplet를 획득하는 것으로 이루어지며,상기 [식 1]은,이고,상기 D(·)는, 유클리드 거리(Euclidian distance)를 나타내며,상기 m은, 마진(margin)을 나타내고,상기 k는, 트리플 배치 크기(triplet batch size)를 나타내며,상기 는, 앵커 샘플(anchor sample)을 나타내고,상기 는, 상기 앵커 샘플 와 동일한 레이블(label)을 가지는 포지티브 샘플(positive sample)을 나타내며,상기 는, 상기 앵커 샘플 와 상이한 레이블을 가지는 네거티브 샘플(negative sample)을 나타내는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에서,상기 액티브 러닝 수행 단계는,[식 2]를 이용하여 상기 최종 로스 Lfinal를 획득하는 것으로 이루어지며,상기 [식 2]는,이고,상기 Ltarget은, 상기 태스크 분류기에서 예측되는 레이블(predicted label)의 로스로, 상기 목표 태스크 로스를나타내고,상기 Ltriplet은, 상기 트리플 로스를 나타내며,상기 λ는, 스케일링 파라미터(scaling parameter)를 나타내는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 기재된 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법을 컴퓨터에서 실행시키기 위하여 컴퓨터 판독 가능한 저장 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "사전-학습 언어 모델(pre-trained language model)과 트리플 로스(triplet loss)를 활용한 태스크-독립적(task-independent) 배치 샘플링(batch sampling) 알고리즘을 이용하여 액티브 러닝(active learning)을 수행하는 액티브 러닝 장치로서,상기 사전-학습 언어 모델과 상기 트리플 로스를 이용하여 액티브 러닝을 수행하기 위한 하나 이상의 프로그램을 저장하는 메모리; 및공개특허 10-2023-0153054-4-상기 메모리에 저장된 상기 하나 이상의 프로그램에 따라 상기 사전-학습 언어 모델과 상기 트리플 로스를 이용하여 액티브 러닝을 수행하기 위한 동작을 수행하는 하나 이상의 프로세서;를 포함하며,상기 프로세서는,레이블링된 데이터세트(labeled dataset)를 기반으로 사전-학습 언어 모델(pre-trained language model)과 태스크 분류기(task classifier)를 초기화하고,상기 사전-학습 언어 모델 및 상기 태스크 분류기를 이용하여 트리플 로스(triplet loss)를 기반으로 레이블링되지 않은 데이터세트(unlabeled dataset)를 대상으로 액티브 러닝(active learning)을 수행하는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에서,상기 프로세서는,상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터세트에서 획득한 문장 표현(sentencerepresentation) 및 상기 태스크 분류기를 이용하여 상기 레이블링되지 않은 데이터세트에서 획득한 태스크-관련 특징(task-related feature)을 기반으로 상기 트리플 로스를 획득하고, 상기 트리플 로스를 이용하여 상기레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링(labeling)하는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에서,상기 프로세서는,상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터세트의 샘플에 대한 상기 문장 표현을 획득하고,상기 태스크 분류기를 이용하여 상기 레이블링되지 않은 데이터세트의 샘플에 대한 상기 태스크-관련 특징을 획득하며,상기 문장 표현 및 상기 태스크-관련 특징을 기반으로 통합 데이터 샘플 특징(integrated data sample feature)을 획득하고,상기 통합 데이터 샘플 특징을 기반으로 목표 태스크 로스(target task loss) 및 상기 트리플 로스를 획득하며,상기 목표 태스크 로스 및 상기 트리플 로스를 기반으로 획득된 최종 로스(final loss)를 이용하여 상기 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링하는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에서,상기 프로세서는,레이블링된 샘플을 기반으로 상기 사전-학습 언어 모델과 상기 태스크 분류기를 업데이트하고,레이블링된 샘플을 상기 레이블링된 데이터세트에 추가하는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에서,공개특허 10-2023-0153054-5-상기 프로세서는,[식 1]을 이용하여 상기 트리플 로스 Ltriplet를 획득하며,상기 [식 1]은,이고,상기 D(·)는, 유클리드 거리(Euclidian distance)를 나타내며,상기 m은, 마진(margin)을 나타내고,상기 k는, 트리플 배치 크기(triplet batch size)를 나타내며,상기 는, 앵커 샘플(anchor sample)을 나타내고,상기 는, 상기 앵커 샘플 와 동일한 레이블(label)을 가지는 포지티브 샘플(positive sample)을 나타내며,상기 는, 상기 앵커 샘플 와 상이한 레이블을 가지는 네거티브 샘플(negative sample)을 나타내는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치."}
{"patent_id": "10-2022-0052778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에서,상기 프로세서는,[식 2]를 이용하여 상기 최종 로스 Lfinal를 획득하며,상기 [식 2]는,이고,상기 Ltarget은, 상기 태스크 분류기에서 예측되는 레이블(predicted label)의 로스로, 상기 목표 태스크 로스를나타내고,상기 Ltriplet은, 상기 트리플 로스를 나타내며,상기 λ는, 스케일링 파라미터(scaling parameter)를 나타내는,사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법, 이를 수행하는 장치 및 컴퓨터 프로그램은, 사전-학습 언어 모델(pre-trained language model)과 트리플 로스 (triplet loss)를 활용한 태스크-독립적(task-independent) 배치 샘플링(batch sampling) 알고리즘을 이용하여 액티브 러닝(active learning)을 수행함으로써, 샘플 데이터의 정보 효율성 및 다양성을 보장할 뿐만 아니라, 대 상 태스크에 독립적으로 적용 가능하므로 딥러닝 데이터 문제를 해결할 수 있다."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법, 이를 수행하는 장치 및 컴퓨터 프로그램에 관한 것으로서, 더욱 상세하게는 액티브 러닝(active learning)을 수행하는, 방법, 장치 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "효과적인 액티브 러닝(active learning)을 위해서는 선택된 데이터 샘플의 풍부함(informativeness)과 다양성 (diversity)이 보장되어야 한다.기존 기술 [1]은 베이지안 신경망을 활용한 몬테 카를로 드랍아웃(Monte Carlo dropout) 방법을 활용하였으며, 기존 기술 [2]에서는 손실 예측 모듈을 사용하여 top-k 예측 손실로 불확실한 데이터 샘플을 선택한다. 이러한 불확실성 기반 방법은 다양한 태스크에 대해 적용될 수 있지만, 데이터의 다양성을 충분히 반영할 수 없으며, 대상 데이터의 레이블이 많을 수록 샘플링 성능이 떨어지는 경향이 있다. 기존 기술 [3]은 앙상블 기법을 활용하여 데이터 분포를 기반으로 훈련 하위 집합을 구축하고, CNN 레이어를 활 용하여 불확실성을 측정한다. 그러나, 이러한 분포 기반 방법은 다양한 태스크에 적용하기 힘들다는 단점이 있 다. 불확실성 기반 방법과 다양성 기반 방법을 결합하기 위해 기존 기술 [4]는 그래디언트 임베딩 및 K-means++ 시 드 알고리즘을 활용하였으며, 기존 기술 [5]에서는 사전-훈련된 언어 모델에서 만들어진 로스를 활용하여 불확 실한 샘플을 분류한다. 그러나, 두 방법 모두 클러스터링 기반의 K-means++ 알고리즘을 활용하기 때문에, 클러 스터의 중심에서 벗어나 있는 하드 샘플을 추출하는데 어려움이 있다."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "[1] Gal, Y.; Islam, R.; and Ghahramani, Z. 2017. Deep Bayesian Active Learning with Image Data. In International Conference on Machine Learning, 1183-1192."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "[2] Yoo, D.; and Kweon, I. S. 2019. Learning loss for active learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 93-102."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 4, "content": "[3] Chitta, K.; Alvarez, J. M.; Haussmann, E.; and Farabet, C. 2019. Training Data Distribution Search with Ensemble Active Learning. arXiv preprint arXiv:1905.12737."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 5, "content": "[4] Ash, J. T.; Zhang, C.; Krishnamurthy, A.; Langford, J.; and Agarwal, A. 2019. Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds. In International Conference on Learning Representations."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 6, "content": "[5] Yuan, M.; Lin, H.-T.; and Boyd-Graber, J. 2020. Cold-start Active Learning through Self-Supervised Language Modeling. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, 7935-7948."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 목적은, 사전-학습 언어 모델(pre-trained language model)과 트리플 로스(triplet loss)를 활용한 태스크-독립적(task-independent) 배치 샘플링(batch sampling) 알고리즘을 이용하여 액티브 러닝(active learning)을 수행하는, 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법, 이를 수행하는 장치 및 컴퓨터 프로그램을 제공하는 데 있다. 본 발명의 명시되지 않은 또 다른 목적들은 하기의 상세한 설명 및 그 효과로부터 용이하게 추론할 수 있는 범 위 내에서 추가적으로 고려될 수 있다."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기의 기술적 과제를 달성하기 위한 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로 스를 이용한 액티브 러닝 방법은, 레이블링된 데이터세트(labeled dataset)를 기반으로 사전-학습 언어 모델 (pre-trained language model)과 태스크 분류기(task classifier)를 초기화하는 단계; 및 상기 사전-학습 언어 모델 및 상기 태스크 분류기를 이용하여 트리플 로스(triplet loss)를 기반으로 레이블링되지 않은 데이터세트 (unlabeled dataset)를 대상으로 액티브 러닝(active learning)을 수행하는 단계;를 포함한다. 여기서, 상기 액티브 러닝 수행 단계는, 상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터 세트에서 획득한 문장 표현(sentence representation) 및 상기 태스크 분류기를 이용하여 상기 레이블링되지 않 은 데이터세트에서 획득한 태스크-관련 특징(task-related feature)을 기반으로 상기 트리플 로스를 획득하고, 상기 트리플 로스를 이용하여 상기 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링(labeling)하는 것으로 이루어질 수 있다. 여기서, 상기 액티브 러닝 수행 단계는, 상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터 세트의 샘플에 대한 상기 문장 표현을 획득하고, 상기 태스크 분류기를 이용하여 상기 레이블링되지 않은 데이 터세트의 샘플에 대한 상기 태스크-관련 특징을 획득하며, 상기 문장 표현 및 상기 태스크-관련 특징을 기반으 로 통합 데이터 샘플 특징(integrated data sample feature)을 획득하고, 상기 통합 데이터 샘플 특징을 기반으 로 목표 태스크 로스(target task loss) 및 상기 트리플 로스를 획득하며, 상기 목표 태스크 로스 및 상기 트리 플 로스를 기반으로 획득된 최종 로스(final loss)를 이용하여 상기 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링하는 것으로 이루어질 수 있다. 여기서, 상기 액티브 러닝 수행 단계는, 레이블링된 샘플을 기반으로 상기 사전-학습 언어 모델과 상기 태스크 분류기를 업데이트하고, 레이블링된 샘플을 상기 레이블링된 데이터세트에 추가하는 것으로 이루어질 수 있다. 여기서, 상기 액티브 러닝 수행 단계는, [식 1]을 이용하여 상기 트리플 로스 Ltriplet를 획득하는 것으로 이루어 지며, 상기 [식 1]은, 이고, 상기 D(·)는, 유클리드 거리 (Euclidian distance)를 나타내며, 상기 m은, 마진(margin)을 나타내고, 상기 k는, 트리플 배치 크기(triplet batch size)를 나타내며, 상기 는, 앵커 샘플(anchor sample)을 나타내고, 상기 는, 상기 앵커 샘플 와 동일한 레이블(label)을 가지는 포지티브 샘플(positive sample)을 나타내며, 상기 는, 상기 앵커 샘플 와 상이한 레이블을 가지는 네거티브 샘플(negative sample)을 나타낼 수 있다. 여기서, 상기 액티브 러닝 수행 단계는, [식 2]를 이용하여 상기 최종 로스 Lfinal를 획득하는 것으로 이루어지며, 상기 [식 2]는, 이고, 상기 Ltarget은, 상기 태스크 분류기에서 예측되 는 레이블(predicted label)의 로스로, 상기 목표 태스크 로스를 나타내고, 상기 Ltriplet은, 상기 트리플 로스를 나타내며, 상기 λ는, 스케일링 파라미터(scaling parameter)를 나타낼 수 있다. 상기의 기술적 과제를 달성하기 위한 본 발명의 바람직한 실시예에 따른 컴퓨터 프로그램은 컴퓨터 판독 가능한 저장 매체에 저장되어 상기한 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 중 어느 하 나를 컴퓨터에서 실행시킨다. 상기의 기술적 과제를 달성하기 위한 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로 스를 이용한 액티브 러닝 장치는, 사전-학습 언어 모델(pre-trained language model)과 트리플 로스(triplet loss)를 활용한 태스크-독립적(task-independent) 배치 샘플링(batch sampling) 알고리즘을 이용하여 액티브 러닝(active learning)을 수행하는 액티브 러닝 장치로서, 상기 사전-학습 언어 모델과 상기 트리플 로스를 이 용하여 액티브 러닝을 수행하기 위한 하나 이상의 프로그램을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상의 프로그램에 따라 상기 사전-학습 언어 모델과 상기 트리플 로스를 이용하여 액티브 러닝을 수행하 기 위한 동작을 수행하는 하나 이상의 프로세서;를 포함하며, 상기 프로세서는, 레이블링된 데이터세트(labeled dataset)를 기반으로 사전-학습 언어 모델(pre-trained language model)과 태스크 분류기(task classifier)를 초기화하고, 상기 사전-학습 언어 모델 및 상기 태스크 분류기를 이용하여 트리플 로스(triplet loss)를 기반으 로 레이블링되지 않은 데이터세트(unlabeled dataset)를 대상으로 액티브 러닝(active learning)을 수행할 수 있다. 여기서, 상기 프로세서는, 상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터세트에서 획득 한 문장 표현(sentence representation) 및 상기 태스크 분류기를 이용하여 상기 레이블링되지 않은 데이터세트 에서 획득한 태스크-관련 특징(task-related feature)을 기반으로 상기 트리플 로스를 획득하고, 상기 트리플 로스를 이용하여 상기 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링(labeling)할 수 있다. 여기서, 상기 프로세서는, 상기 사전-학습 언어 모델을 이용하여 상기 레이블링되지 않은 데이터세트의 샘플에 대한 상기 문장 표현을 획득하고, 상기 태스크 분류기를 이용하여 상기 레이블링되지 않은 데이터세트의 샘플에 대한 상기 태스크-관련 특징을 획득하며, 상기 문장 표현 및 상기 태스크-관련 특징을 기반으로 통합 데이터 샘플 특징(integrated data sample feature)을 획득하고, 상기 통합 데이터 샘플 특징을 기반으로 목표 태스크 로 스(target task loss) 및 상기 트리플 로스를 획득하며, 상기 목표 태스크 로스 및 상기 트리플 로스를 기반으 로 획득된 최종 로스(final loss)를 이용하여 상기 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블 링할 수 있다. 여기서, 상기 프로세서는, 레이블링된 샘플을 기반으로 상기 사전-학습 언어 모델과 상기 태스크 분류기를 업데 이트하고, 레이블링된 샘플을 상기 레이블링된 데이터세트에 추가할 수 있다. 여기서, 상기 프로세서는, [식 1]을 이용하여 상기 트리플 로스 Ltriplet를 획득하며, 상기 [식 1]은, 이고, 상기 D(·)는, 유클리드 거리(Euclidian distance)를 나타내며, 상기 m은, 마진(margin)을 나타내고, 상기 k는, 트리플 배치 크기(triplet batch size)를 나타내며, 상기 는, 앵커 샘플(anchor sample)을 나타내고, 상기 는, 상기 앵커 샘플 와 동일한 레이블 (label)을 가지는 포지티브 샘플(positive sample)을 나타내며, 상기 는, 상기 앵커 샘플 와 상이한 레 이블을 가지는 네거티브 샘플(negative sample)을 나타낼 수 있다. 여기서, 상기 프로세서는, [식 2]를 이용하여 상기 최종 로스 Lfinal를 획득하며, 상기 [식 2]는, 이고, 상기 Ltarget은, 상기 태스크 분류기에서 예측되는 레이블(predicted label) 의 로스로, 상기 목표 태스크 로스를 나타내고, 상기 Ltriplet은, 상기 트리플 로스를 나타내며, 상기 λ는, 스케 일링 파라미터(scaling parameter)를 나타낼 수 있다."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법, 이를 수행하는 장치 및 컴퓨터 프로그램에 의하면, 사전-학습 언어 모델(pre-trained language model)과 트리플 로스 (triplet loss)를 활용한 태스크-독립적(task-independent) 배치 샘플링(batch sampling) 알고리즘을 이용하여 액티브 러닝(active learning)을 수행함으로써, 샘플 데이터의 정보 효율성 및 다양성을 보장할 뿐만 아니라, 대상 태스크에 독립적으로 적용 가능하므로 딥러닝 데이터 문제를 해결할 수 있다."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세히 설명한다. 본 발명의 이점 및 특징, 그리고 그것들 을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그 러나, 본 발명은 이하에서 게시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으 며, 단지 본 실시예들은 본 발명의 게시가 완전하도록 하고, 본 발명이 속하는 기술 분야에서 통상의 지식을 가 진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐 이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 본 명세서에서 \"제1\", \"제2\" 등의 용어는 하나의 구성 요소를 다른 구성 요소로부터 구별하기 위한 것으로, 이 들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예컨대, 제1 구성 요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 본 명세서에서 각 단계들에 있어 식별부호(예컨대, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별 부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이 상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적 으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 명세서에서, \"가진다\", \"가질 수 있다\", \"포함한다\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예컨대, 수치, 기능, 동작, 또는 부품 등의 구성 요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 이하에서 첨부한 도면을 참조하여 본 발명에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러 닝 방법, 이를 수행하는 장치 및 컴퓨터 프로그램의 바람직한 실시예에 대해 상세하게 설명한다. 먼저, 도 1을 참조하여 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치에 대하여 설명한다. 도 1은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치 를 설명하기 위한 블록도이다. 도 1을 참조하면, 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치(이하 '액티브 러닝 장치'라 한다)는 사전-학습 언어 모델(pre-trained language model)과 트리 플 로스(triplet loss)를 활용한 태스크-독립적(task-independent) 배치 샘플링(batch sampling) 알고리즘을 이용하여 액티브 러닝(active learning)을 수행할 수 있다. 이를 위해, 액티브 러닝 장치는 하나 이상의 프로세서, 컴퓨터 판독 가능한 저장 매체 및 통신 버스를 포함할 수 있다. 프로세서는 액티브 러닝 장치가 동작하도록 제어할 수 있다. 예컨대, 프로세서는 컴퓨터 판독 가능한 저장 매체에 저장된 하나 이상의 프로그램을 실행할 수 있다. 하나 이상의 프로그램은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 컴퓨터 실행 가능 명령어는 프로세서에 의해 실행되는 경우 액티브 러닝 장치로 하여금 사전-학습 언어 모델과 트리플 로스를 이용하여 액티브 러닝을 수행하기 위한 동작을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능한 저장 매체는 사전-학습 언어 모델과 트리플 로스를 이용하여 액티브 러닝을 수행하기 위한 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다른 적합한 형태의 정보를 저장 하도록 구성된다. 컴퓨터 판독 가능한 저장 매체에 저장된 프로그램은 프로세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능한 저장 매체는 메모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자기 디스크 저장 디 바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 액티브 러닝 장치에 의해 액 세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능한 저장 매체를 포함하여 액티브 러닝 장치의 다 른 다양한 컴포넌트들을 상호 연결한다. 액티브 러닝 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인 터페이스 및 하나 이상의 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 통신 인터 페이스는 통신 버스에 연결된다. 입출력 장치(도시하지 않음)는 입출력 인터페이스를 통해 액 티브 러닝 장치의 다른 컴포넌트들에 연결될 수 있다. 그러면, 도 2를 참조하여 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법에 대하여 설명한다. 도 2는 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 을 설명하기 위한 흐름도이다. 도 2를 참조하면, 액티브 러닝 장치의 프로세서는 레이블링된 데이터세트(labeled dataset)를 기반으 로 사전-학습 언어 모델과 태스크 분류기(task classifier)를 초기화할 수 있다(S110). 그런 다음, 프로세서는 사전-학습 언어 모델 및 태스크 분류기를 이용하여 트리플 로스를 기반으로 레이블 링되지 않은 데이터세트(unlabeled dataset)를 대상으로 액티브 러닝(active learning)을 수행할 수 있다 (S120). 즉, 프로세서는 사전-학습 언어 모델을 이용하여 레이블링되지 않은 데이터세트에서 획득한 문장 표현 (sentence representation) 및 태스크 분류기를 이용하여 레이블링되지 않은 데이터세트에서 획득한 태스크-관 련 특징(task-related feature)을 기반으로 트리플 로스를 획득할 수 있다. 그리고, 프로세서는 트리플 로스를 이용하여 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링(labeling)할 수 있다. 보다 자세히 설명하면, 프로세서는 사전-학습 언어 모델을 이용하여 레이블링되지 않은 데이터세트의 샘플 에 대한 문장 표현을 획득할 수 있다. 그리고, 프로세서는 태스크 분류기를 이용하여 레이블링되지 않은 데이터세트의 샘플에 대한 태스크-관련 특징을 획득할 수 있다. 그리고, 프로세서는 문장 표현 및 태스크 -관련 특징을 기반으로 통합 데이터 샘플 특징(integrated data sample feature)을 획득할 수 있다. 그리고, 프로세서는 통합 데이터 샘플 특징을 기반으로 목표 태스크 로스(target task loss) 및 트리플 로스를 획 득할 수 있다. 그리고, 프로세서는 목표 태스크 로스 및 트리플 로스를 기반으로 획득된 최종 로스(final loss)를 이용하여 레이블링되지 않은 데이터세트에서 샘플을 선택하여 레이블링할 수 있다. 이때, 프로세서는 레이블링된 샘플을 기반으로 사전-학습 언어 모델과 태스크 분류기를 업데이트할 수 있 다. 그리고, 프로세서는 레이블링된 샘플을 레이블링된 데이터세트에 추가할 수 있다.그러면, 도 3을 참조하여 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법에 대하여 보다 자세히 설명한다. 도 3은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 을 설명하기 위한 도면이다. A. 사전-학습 언어 모델 사전-학습 언어 모델은 수백만 또는 수십억 개의 비지도 데이터(unsupervised data)로 학습되어, 일반적인 언어 특징(generic linguistic features)을 캡처(capture)할 수 있다. 사전-학습 언어 모델은 언어 모델링 목표 (language modeling objectives)를 이용하고 다양한 다운스트림 태스크(downstream tasks)에서 강력한 성능을 보여줄 수 있다. 사전-학습 언어 모델의 입력은 시퀀스 길이(sequence length) l을 가지는 일련의 단어 토큰 (word tokens) x=(x1,x2,…,xl)일 수 있다. 사전-학습 언어 모델은 가중치 파라미터 θe를 가지는 히든 상태 표 현(hidden state representations)을 이용하여 문장 표현 s(x,θe)를 계산할 수 있다. B. 태스크 분류기 사전-학습 언어 모델은 다운스트림 태스크를 통해 파인-튜닝(fine-tune)될 수 있다. 태스크 분류기는 사전-학 습 언어 모델에 의해 획득된 문장 표현 s에 대한 레이블(label)을 예측할 수 있다. 목표 레이블(target labe l)에 대한 분포는 아래의 [수학식 1]과 같이 정의될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 문장 x와 가중치 파라미터 θc=(W,b)가 주어지면, f(x,θc)는 후보 레이블(candidate labels)에 할당된 점수(score)의 확률 벡터(probability vector)를 나타낼 수 있다. hC는 태스크 분류기의 최종 레이어(final layer)의 히든 표현(hidden representation)을 나타낼 수 있다. 그후, 예측되는 레이블(predicted label) y^는 아래의 [수학식 2]와 같이 정의될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "학습 도중, 목표 레이블 y와 예측되는 레이블 y^ 간의 목표 태스크 로스 Ltarget가 최소화되어야 한다. 레이블링 된 데이터세트를 가지고 태스크 분류기를 초기화할 때, 목표 레이블 y와 예측되는 레이블 y^를 전부 알고 있기 때문에 정확한 목표 태스크 로스를 획득하는 것은 문제가 아니다. 그러나, 레이블링되지 않은 데이터세트에서 샘플에 대한 목표 레이블 y를 알지 못하기 때문에, 본 발명은 액티브 러닝 과정 도중 목표 태스크 로스로 예측 되는 레이블의 로스를 이용할 수 있다. C. 액티브 러닝 시나리오(active learning scenario) 먼저 일반적인 액티브 러닝 시나리오에 대해 살펴보면, 액티브 러닝의 핵심(key)은 레이블링(labeling)되고 학 습을 위해 레이블링된 데이터세트에 추가될 때 모델 성능을 향상시키는 가장 유익하고(informative) 레이블링되 지 않은 샘플을 찾는 것이다. 레이블링되지 않은 데이터세트는 Du로 나타내고, 레이블링된 데이터세트는 Dl로 나타낸다. 먼저, 초기 레이블링된 데이터세트 를 기반으로 사전-학습 언어 모델과 태스크 분류기를 학습할 수 있다. 유익한 샘플(informative samples)의 배치(batch)는 획득 함수(acquisition function)를 이용하여매 반복(iteration)마다 선택되고, 레이블링되지 않은 데이터세트와 레이블링된 데이터세트를 업데이트할 수 있 다. 그후, 레이블링 예산(labeling budget)이 소진되거나 기준(criterion)을 충족할 때까지 사전-학습 언어 모 델과 태스크 분류기는 레이블링된 데이터를 이용하여 업데이트될 수 있다. D. 트리플 로스를 통한 배치 획득(batch acquisition with triplet loss, BATL) 도 3을 참조하면, 본 발명에 따른 트리플 로스를 통한 태스크-독립적(task-independent) 배치 획득 방법(BATL) 은 사전-학습 언어 특징(pre-trained linguistic features)과 태스크-관련 특징 전부를 고려하고, 레이블링되지 않은 데이터세트에서 불확실성(uncertainty)과 다양성(diversity)을 탐구(explorer)할 수 있다. 본 발명에 따른 획득 함수는 문장 표현과 태스크-관련 특징을 입력으로 취할 수 있다. 문장 표현 s(x,θe)는 사전-학습 언어 모델로부터 학습되고, 태스크-관련 특징은 태스크 분류기로부터 추출될 수 있다. 특히, 본 발 명에 따른 방법은 태스크 분류기의 최종 레이어의 히든 상태 표현 hC를 태스크-관련 특징으로 이용할 수 있다. 본 발명에 따른 방법은 문장 표현과 태스크-관련 특징을 결합(concatenate)하고, 통합 데이터 샘플 특징을 획득 하기 위해 결합한 데이터를 완전 연결 레이어(fully connected layer)에 넣을 수 있다. 태스크 분류기는 액티 브 러닝의 초기 단계(early stage)에서 충분한 레이블링된 데이터세트로 학습되지 못한다. 따라서, 목표 태스 크 로스 Ltarget은 아직 샘플의 정보량을 측정하는 신뢰할 수 없는 지표(unreliable indicator)이다. 또한, 태스 크 분류기에 의해 추론된 예측되는 레이블 y^에 크로스-엔트로피 로스(cross-entropy loss)를 직접 사용하면, 태스크 분류기의 잘못된 최적화로 이어질 수 있다. 정답 레이블(ground-truth labels)없이 태스크 분류기를 최적화하기 위한 종래의 연구들이 있다. Yoo and Kweon은 로스 예측 모듈(loss prediction module)에 의해 에측된 2개의 로스 간의 페어와이즈 로스 (pairwise loss)를 이용한다. 페어와이즈 로스는 일반적으로 고차원 공간(high-dimensional space)에서 서로 다른 샘플 간의 거리를 최대화하는 데 유용하다. 그러나, 페어와이즈 로스는 유사한 샘플 간의 거리를 최소화 할 때 상당한 단점에 직면하게 된다. 즉, 배치 샘플의 다양성은 잘 고려되지 않는다. 다양한 배치 샘플을 포 착하기 위해 심플 클러스터링 알고리즘(simple clustering algorithm)이 적용될 수 있다(Ash et al. 2019; Yuan, Lin, and Boyd-Graber 2020). 그러나, 클러스터의 중심에 가까운 샘플만 추출하는 방식이기 때문에 여러 클러스터에 닫힌 이상값(outliers)을 동시에 처리하는 것은 쉽지 않다. 위와 같은 문제를 극복하기 위해, 본 발명에 따른 방법은 트리플 로스(Schroff, Kalenichenko, and Philbin 2015)를 사용하여 샘플의 다양성을 고려하여 유익한 배치 샘플을 정교하게 찾을 수 있다. 트리플은 앵커 샘플 (anchor sample), 포지티브 샘플(positive sample) 및 네거티브 샘플(negative sample)로 구성될 수 있다. 특 정 레이블의 앵커 샘플은 임베딩 공간(embedding space)에서 네거티브 샘플보다 포지티브 샘플에 가깝다. 포지 티브 샘플은 앵커 샘플과 동일한 레이블을 가지는 반면, 네거티브 샘플은 앵커 샘플과 상이한 레이블을 가지고 있다. 트리플 제약(triplet constraint)은 아래의 [수학식 3]과 같이 정의될 수 있다. 수학식 3"}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 앵커 샘플을 나타낼 수 있다. 는 앵커 샘플 와 동일한 레이블을 가지는 포지티브 샘플 을 나타낼 수 있다. 는 앵커 샘플 와 상이한 레이블을 가지는 네거티브 샘플을 나타낼 수 있다. 레이 블링되지 않은 데이터세트에서 후보 샘플에 대한 레이블 정보를 가지고 있지 않기 떄문에, 본 발명은 태스크 분 류기에서 예측되는 레이블을 이용할 수 있다. 모든 샘플은 임베딩 공간에서 표현될 수 있다. D(·)는 유클리 드 거리(Euclidian distance)를 나타낼 수 있다. m은 마진(margin)을 나타낼 수 있다. 모든 가능한 트리플의 생성은 액티브 러닝에서 배치 샘플의 퀄리티(quality)를 향상시킬 수 없기 때문에, 모델 을 학습시키기 위해 유용한 트리플을 선택하는 것이 중요하다. 즉, 트리플 제약을 위반하는 트리플을 찾아야한다. 하드 샘플(hard sample)은 를 충족하는 하드 포지티브 샘플(hard positive sample) 및 를 충족하는 하드 네거티브 샘플(hard negative sample)로 구성될 수 있다. 본 발명에 따른 방법은 이러한 유용한 트리플을 마이닝(mine)하기 위해 즉석에서(on the fly) 미니-배치(mini- batch) 내의 하드 샘플을 계산할 수 있다. 본 발명에 따른 방법은 배치에서 각각의 샘플을 앵커 샘플로 이용할 수 있다. 하드 네거티브 샘플은 온라인 트리플 생성으로 로컬 최적(local optima)을 초래할 수 있기 때문에 본 발명은 앵커 샘플에서 가장 멀리 떨어진 하드 포지티브 샘플과 세미-하드 네거티브 샘플(semi-hard negative sample)을 선택할 수 있다. 세미-하드 네거티브 샘플 는 아래의 [수학식 4]와 같다. 수학식 4"}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "세미-하드 네거티브 샘플은 포지티브 샘플보다 앵커 샘플로부터 더 멀리 떨어져 있지만, 마진 m 내부에 있다. 트리플 로스 Ltriplet은 아래의 [수학식 5]와 같이 정의될 수 있다. 수학식 5"}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, k는 트리플 배치 크기(triplet batch size)를 나타낼 수 있다. 목표 태스크 로스와 액티브 러닝을 위한 트리플 로스를 결합하는 것에 의해, 본 발명에 따른 최종 로스 Lfinal은 아래의 [수학식 6]과 같다. 수학식 6"}
{"patent_id": "10-2022-0052778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, Ltarget은 태스크 분류기에서 예측되는 레이블(predicted label)의 로스로, 목표 태스크 로스를 나타낼 수 있다. Ltriplet은 트리플 로스를 나타낼 수 있다. λ는 스케일링 파라미터(scaling parameter)를 나타낼 수 있다. 본 발명에 따른 전반적인 액티브 러닝 프로세스는 아래의 [표 1]에 기재된 알고리즘과 같다. 표 1 Algorithm : Active learning with BATL Input: unlabeled dataset Du, labeled dataset Dl, initial task classifier F with pre-trained language model E, batch size k, iteration number T Initialize: train an initial model F and E on Dl 1: while Ti in T do 2: For all samples x in Du: 3: compute sentence representation s(x, ) from E 4: compute task-related feature f(x, ) from F 5: concatenate s(x, ) and f(x, ) 6: compute target task loss Ltarget and triplet loss Ltriplet 7: select k samples in order of high final loss Lfinal and query for labels 8: receive newly labeled data Dnew 9: fine-tune parameters of E and F using Dnew 10: Dl ← Dl ∪ Dnew , Du ← Du ＼ Dnew 11: end while 정리하면, 본 발명은 사전-학습 언어 모델과 트리플 로스를 활용한 태스크-독립적 배치 샘플링 알고리즘을 이용 하여 액티브 러닝을 수행할 수 있다. 즉, 사전-학습된 언어 특징과 태스크-관련 특징을 고려하고, 레이블링되지 않은 데이터세트에서 불확실성과 다 양성을 탐색하는 트리플 로스를 가지는 태스크-독립적인 배치 수집 방법에 대한 것이다. 보다 자세히 설명하면, 액티브 러닝은 레이블링되지 않은 데이터세트에서 가장 효과적이며 정보가 많은 (informative) 샘플을 찾아내어 레이블링하는 과정을 통해 모델의 성능을 향상시키는 학습 방법이다. 액티브 러닝은 레이블링된 데이터가 충분하기 않은 태스크의 자원 부족 문제를 해결하기 위한 방법으로 크게 각광 받고 있다. 기존의 액티브 러닝 방법은 샘플을 선택하는 과정에서 특정 태스크 또는 알고리즘에 의존하는 태스크-종 속성(task-dependency)으로 인해 다양한 다른 태스크에 활용하기 어렵다는 문제가 있다. 또한, 각 샘플의 정보 성만 고려하기 때문에 배치 샘플의 다양성이 충분하지 않다는 문제점이 있다. 본 발명에서는 사전-학습 언어 모델과 트리플 로스를 활용한 태스크-독립적인 배치 샘플링 알고리즘 기반의 액 티브 러닝 방법을 제안한다. 언어 모델의 자기 지도(self-supervision) 학습 능력을 활용하여 초기 샘플링 과 정에서 유익한 샘플을 찾고, 태스크-독립적인 샘플링 과정을 위해 언어 모델의 지식과 태스크 분류기의 로스를 함께 활용한다. 또한, 기존 방법으로는 찾아내기 힘든 하드 샘플 탐색을 위해 트리플 로스를 활용하여, 서로 다른 샘플 사이의 거리를 늘리고 유사한 샘플 사이의 거리를 줄일 수 있다. 그러면, 도 4 내지 도 8을 참조하여 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로 스를 이용한 액티브 러닝 방법의 성능에 대하여 설명한다. 도 4는 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 의 성능을 설명하기 위한 도면으로, 다양한 배치 크기에서 NYT-10 데이터세트의 관계 추출의 액티브 러닝 결과 를 나타내고, 도 5는 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액 티브 러닝 방법의 성능을 설명하기 위한 도면으로, 다양한 배치 크기에서 Wiki-KBP 데이터세트의 관계 추출의 액티브 러닝 결과를 나타내며, 도 6은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플로스를 이용한 액티브 러닝 방법의 성능을 설명하기 위한 도면으로, 문장 분류의 액티브 러닝 결과를 나타내고, 도 6의 (a)는 AG News 데이터세트이고, 도 6의 (b)는 PubMed 데이터세트이며, 도 7은 본 발명의 바람직한 실시 예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법의 성능을 설명하기 위한 도면으 로, 성능 평가 결과를 나타내고, 도 7의 (a)는 다양성이고, 도 7의 (b)는 불확실성이며, 도 7의 (c)는 밀도이고, 도 8은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법의 성능을 설명하기 위한 도면으로, 스케일링 파라미터의 영향을 나타내고, 도 8의 (a)는 다양성이고, 도 8의 (b)는 불확실성이며, 도 8의 (c)는 밀도이다. A. 실험 환경 설정(experimental settings) - 목표 태스크 관계 추출(relation extraction) : 언어 모델 GPT를 이용 문장 분류(sentence classification) : 언어 모델 BERT를 이용 - 데이터세트 표 2 Dataset Target Task Train Test #Labels NYT-10 Relation Extraction 522,611 172,448 53 Wiki-KBP Relation Extraction 23,884 289 13 AG NewsSentence Classification 110,000 7,600 4 PubMed Sentence Classification 180,040 30,135 5 - 베이스라인(baselines) RAND : random sampling CONF : least confidence sampling ENTROPY D-AL : select sample undistinguishable(Gissin and Shalev-Shwartz, 2019) BatchBALD : use parameters and predictions of a classifier(Kirschetal., 2019) CORESET : use greedy furthest-first traversal(Sener and Savarese, 2018) BADGE : use gradient loss of a classifier(Ashetal., 2019) ALPS : use the pre-trained knowledge(Yuanetal., 2020) 본 발명(BATL) : 트리플 로스를 통한 태스크-독립적 배치 획득 방법 B. 실험 결과(experimental results) 도 4 및 도 5를 참조하면, 본 발명에 따른 트리플 로스를 통한 태스크-독립적 배치 획득 방법(BATL)이 액티브 러닝 프로세서의 매 반복에서 가장 좋은 성능을 보이는 것을 확인할 수 있다. 도 6의 (a)를 참조하면, 본 발명에 따른 트리플 로스를 통한 태스크-독립적 배치 획득 방법(BATL)이 AG News 데 이터세트에 대한 실험에서 BADGE 및 ALPS와 거의 동일한 정확도를 보이는 것을 확인할 수 있다. 도 6의 (b)를 참조하면, 본 발명에 따른 트리플 로스를 통한 태스크-독립적 배치 획득 방법(BATL)이 PubMed 데이터세트에 대 한 실험에서 가장 높은 테스트 정확도를 보이는 것을 확인할 수 있다. 도 7을 참조하면, 본 발명에 따른 트리플 로스를 통한 태스크-독립적 배치 획득 방법(BATL)이 밀도(density)에 서 가장 높은 점수를 보이는 것을 확인할 수 있다. 이러한 결과는 본 발명의 최적화 목표가 유사한 샘플 간의 거리를 최소하하는데 유효함을 보여준다.도 8을 참조하면, 스케일링 파라미터가 높을수록 트리플 로스의 영향이 커지는 것을 확인할 수 있다. 시장성 및 기대효과 딥러닝 및 인공지능 기술의 발전에 따라, 다양한 태스크를 학습하고 실제 서비스에 적용하기 위한 고품질의 데 이터 수집의 중요성이 대두되고 있다. 그러나, 학습 데이터의 품질 향상을 위해서는 레이블링된 데이터를 인간 이 직접 확인하고 검수하는 과정이 필요하다. 이러한 과정을 효율적으로 진행하고, 학습 모델의 성능을 향상시 키기 위한 액티브 러닝 방법이 각광받고 있다. 본 발명이 제안하는 액티브 러닝 방법은 샘플 데이터의 정보 효율성 및 다양성을 보장할 뿐만 아니라, 대상 태 스크에 독립적으로 적용 가능하므로 딥러닝 데이터 문제를 해결을 위한 핵심 기술이 될 수 있다. 본 실시예들에 따른 동작은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨 터 판독 가능한 저장 매체에 기록될 수 있다. 컴퓨터 판독 가능한 저장 매체는 실행을 위해 프로세서에 명령어 를 제공하는데 참여한 임의의 매체를 나타낸다. 컴퓨터 판독 가능한 저장 매체는 프로그램 명령, 데이터 파일, 데이터 구조 또는 이들의 조합을 포함할 수 있다. 예컨대, 자기 매체, 광기록 매체, 메모리 등이 있을 수 있다. 컴퓨터 프로그램은 네트워크로 연결된 컴퓨터 시스템 상에 분산되어 분산 방식으로 컴퓨터가 읽을 수 있 는 코드가 저장되고 실행될 수도 있다. 본 실시예를 구현하기 위한 기능적인(Functional) 프로그램, 코드, 및 코드 세그먼트들은 본 실시예가 속하는 기술 분야의 프로그래머들에 의해 용이하게 추론될 수 있을 것이다. 본 실시예들은 본 실시예의 기술 사상을 설명하기 위한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상 의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0052778", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 장치 를 설명하기 위한 블록도이다. 도 2는 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 을 설명하기 위한 흐름도이다. 도 3은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 을 설명하기 위한 도면이다. 도 4는 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 의 성능을 설명하기 위한 도면으로, 다양한 배치 크기에서 NYT-10 데이터세트의 관계 추출의 액티브 러닝 결과 를 나타낸다. 도 5는 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 의 성능을 설명하기 위한 도면으로, 다양한 배치 크기에서 Wiki-KBP 데이터세트의 관계 추출의 액티브 러닝 결 과를 나타낸다. 도 6은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 의 성능을 설명하기 위한 도면으로, 문장 분류의 액티브 러닝 결과를 나타내고, 도 6의 (a)는 AG News 데이터세 트이고, 도 6의 (b)는 PubMed 데이터세트이다.도 7은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 의 성능을 설명하기 위한 도면으로, 성능 평가 결과를 나타내고, 도 7의 (a)는 다양성이고, 도 7의 (b)는 불확 실성이며, 도 7의 (c)는 밀도이다. 도 8은 본 발명의 바람직한 실시예에 따른 사전-학습 언어 모델 기반의 트리플 로스를 이용한 액티브 러닝 방법 의 성능을 설명하기 위한 도면으로, 스케일링 파라미터의 영향을 나타내고, 도 8의 (a)는 다양성이고, 도 8의 (b)는 불확실성이며, 도 8의 (c)는 밀도이다."}
