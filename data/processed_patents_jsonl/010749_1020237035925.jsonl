{"patent_id": "10-2023-7035925", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0157503", "출원번호": "10-2023-7035925", "발명의 명칭": "동기화 방법 및 장치", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "쥬 샹이"}}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동기화 방법으로서,상기 동기화 방법은,제1 프로세서가, 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성하는 단계 - 상기 제1 동기화 객체는 제1 동기화 레지스터의 식별자를 포함하고, 상기 제1 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함하며, 상기제1 값은 상기 제1 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 상기 제2 값은 상기 제1 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제1 프로세서는 제1 중앙 처리 유닛(central processing unit,CPU)을 포함함 -; 및제2 프로세서가, 상기 제1 동기화 레지스터의 값에 기반하여 상기 제1 동기화 이벤트가 발생하는지를 판정하는단계 - 상기 제2 프로세서는 제1 신경망 처리 유닛(neural-network processing unit, NPU)을 포함함 -를 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 프로세서가, 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성하는 단계는,상기 제1 프로세서가, 제1 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를호출하는 것에 의해, 상기 제2 프로세서에 포함된 복수의 동기화 레지스터 중 상기 제1 동기화 레지스터를 상기제1 동기화 이벤트에 할당하고, 상기 제1 동기화 레지스터의 식별자를 상기 제1 동기화 객체에 저장하는 단계를 포함하는, 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서,상기 동기화 방법은, 상기 제1 프로세서가, 제2 API를 호출하는 것에 의해 상기 제1 동기화 이벤트에 대응하는 대기 태스크를 상기제2 프로세서에 송신하는 단계 - 상기 제1 동기화 이벤트에 대응하는 대기 태스크는 상기 제1 동기화 이벤트가발생하기를 대기하는 데 사용되며, 상기 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 큐 식별자 및 상기제1 동기화 레지스터의 식별자를 포함하고, 상기 제1 큐 식별자는 상기 대기 태스크가 위치된 큐의 식별자임 -;및상기 제2 프로세서가, 상기 제1 동기화 이벤트에 대응하는 대기 태스크를 수신하는 단계를 더 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제2 프로세서가, 상기 제1 동기화 레지스터의 값에 기반하여 상기 제1 동기화 이벤트가 발생하는지를 판정하는 단계는,상기 제2 프로세서가, 상기 제1 동기화 레지스터의 값이 상기 제1 값일 때, 상기 제1 동기화 이벤트가 발생하지않은 것으로 결정하는 단계; 상기 제2 프로세서가, 상기 제1 동기화 이벤트가 발생하기를 계속해서 대기하는 단계; 및 공개특허 10-2023-0157503-2-상기 제2 프로세서가, 상기 제1 동기화 레지스터의 값이 상기 제2 값이 될 때까지 상기 제1 동기화 이벤트가 발생한 것으로 결정하고, 상기 제2 프로세서가, 상기 제1 동기화 레지스터의 값을 상기 제1 값으로 재설정하는 단계를 포함하는, 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 제2 프로세서가, 상기 제1 동기화 레지스터의 값에 기반하여 상기 제1 동기화 이벤트가 발생하는지를 판정하는 단계는,상기 제2 프로세서가, 상기 제1 동기화 레지스터의 값이 상기 제2 값일 때, 상기 제1 동기화 이벤트가 발생한것으로 결정하고, 상기 제2 프로세서가 상기 제1 동기화 레지스터의 값을 상기 제1 값으로 재설정하는 단계를 더 포함하는, 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 동기화 방법은, 상기 제1 프로세서가, 제3 API를 호출하는 것에 의해 상기 제1 동기화 이벤트에 대응하는 기록 태스크를 상기제2 프로세서에 송신하는 단계 - 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 상기 제1 동기화 이벤트가발생함을 지시하는 데 사용되며, 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 상기 제1동기화 레지스터의 식별자를 포함하고, 상기 제2 큐 식별자는 상기 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자임 -; 및상기 제2 프로세서가, 상기 제1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 상기 제1 동기화 레지스터의 식별자에 기반하여 상기 제1 동기화 레지스터의 값을 상기 제2 값으로 재설정하는 단계를 더 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 동기화 방법은, 상기 제1 프로세서가, 제3 API를 호출하는 것에 의해 상기 제1 동기화 이벤트에 대응하는 기록 태스크를 제3 프로세서에 송신하는 단계 - 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 상기 제1 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 상기 제1 동기화 레지스터의 식별자를 포함하고, 상기 제2 큐 식별자는 상기 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이며, 상기 제3 프로세서는 제2 NPU를 포함함 -; 및상기 제3 프로세서가, 상기 제1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 상기 제1 동기화 레지스터의 식별자에 기반하여 상기 제1 동기화 레지스터의 값을 상기 제2 값으로 재설정하는 단계를 더 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 제1 동기화 이벤트가 인터 프로세스 동기화 이벤트이면, 상기 동기화 방법은,상기 제1 프로세서가, 제1 애플리케이션의 제4 API를 호출하는 것에 의해 상기 제1 동기화 객체의 이름을 미리설정된 이름으로 설정하는 단계; 및상기 제1 프로세서가, 제2 애플리케이션의 제5 API를 호출하는 것에 의해 상기 미리 설정된 이름에 대응하는 제1 동기화 레지스터의 식별자를 획득하는 단계공개특허 10-2023-0157503-3-를 더 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 제1 동기화 이벤트는 상기 제1 애플리케이션과 상기 제2 애플리케이션 간의 동기화 이벤트이고, 상기 미리설정된 이름은 상기 제1 애플리케이션과 상기 제2 애플리케이션에 의해 사전에 합의된 이름인, 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서,상기 동기화 방법은, 상기 제1 프로세서가, 제6 API를 호출하는 것에 의해 제2 동기화 레지스터의 가상 주소를 획득하는 단계 - 상기제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이고, 상기 제2 동기화 레지스터의 서로 다른 값은 상기 제2 동기화 이벤트가 발생하는지를 지시하는 데 사용됨 -; 및상기 제1 프로세서가, 상기 제2 동기화 레지스터의 가상 주소를 제4 프로세서에 송신하는 단계 - 상기 제1 프로세서와 상기 제4 프로세서는 서로 다른 AI 서버의 프로세서이고, 상기 제4 프로세서는 제2 CPU를 포함함 -를 더 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서,상기 동기화 방법은, 상기 제1 프로세서가, 제7 API를 호출하여 상기 제1 동기화 레지스터와 상기 제1 동기화 이벤트 사이의 대응 관계를 해제하고, 상기 제1 동기화 레지스터의 값을 상기 제1 값으로 재설정하는 단계 - 상기 제7 API는 상기 제1동기화 레지스터를 해제하도록 구성됨 -를 더 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제11항 중 어느 한 항에 있어서,상기 제1 동기화 레지스터의 물리적 주소는 글로벌 어드레싱 방식으로 주소 지정되는, 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "동기화 방법으로서, 상기 동기화 방법은,제4 프로세서가, 제1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신하는 단계 - 상기 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이고, 상기 제2 동기화 레지스터의 값은 제1 값 또는 제2 값을포함하며, 상기 제1 값은 상기 제2 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 상기 제2 값은 상기 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제1 프로세서와 상기 제4 프로세서는 서로 다른AI 서버의 프로세서이고, 상기 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을포함하며, 상기 제4 프로세서는 제2 CPU를 포함함 -;상기 제4 프로세서가, 상기 제2 동기화 이벤트에 대응하는 원격 직접 메모리 액세스(remote direct memoryaccess, RDMA) 태스크를 제5 프로세서에 송신하는 단계 - 상기 제2 동기화 이벤트에 대응하는 RDMA 태스크는 상기 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제2 동기화 이벤트에 대응하는 RDMA 태스크는 상기 제2 동기화 레지스터의 가상 주소를 포함하고, 상기 제5 프로세서는 제3 NPU를 포함함 -; 및상기 제5 프로세서가, 상기 제2 동기화 이벤트에 대응하는 RDMA 태스크를 수신하고, RDMA 장치를 통해 상기 제2동기화 레지스터의 가상 주소에 기반하여 상기 제2 동기화 레지스터의 값을 상기 제2 값으로 재설정하는 단계공개특허 10-2023-0157503-4-를 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "동기화 방법으로서, 상기 동기화 방법은,제4 프로세서가, 제1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신하는 단계 - 상기 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이고, 상기 제2 동기화 레지스터의 값은 제1 값 또는 제2 값을포함하며, 상기 제1 값은 상기 제2 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 상기 제2 값은 상기 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제1 프로세서와 상기 제4 프로세서는 서로 다른AI 서버의 프로세서이고, 상기 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을포함하며, 상기 제4 프로세서는 제2 CPU를 포함함 -; 및상기 제4 프로세서가, 원격 직접 메모리 액세스(remote direct memory access, RDMA) 장치를 통해 상기 제2 동기화 레지스터의 가상 주소에 기반하여 상기 제2 동기화 레지스터의 값을 상기 제2 값으로 재설정하는 단계를 포함하는 동기화 방법."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "동기화 장치로서,상기 동기화 장치는 제2 프로세서를 포함하고, 상기 제2 프로세서가 복수의 동기화 레지스터를 포함하며, 각 동기화 레지스터는 하나의 동기화 이벤트에 대응하도록 구성되고, 각 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함하며, 상기 제1 값은 상기 동기화 레지스터에 대응하는 동기화 이벤트가 발생하지 않음을 지시하는 데사용되고, 상기 제2 값은 상기 동기화 레지스터에 대응하는 동기화 이벤트가 발생함을 지시하는 데 사용되며,상기 제2 프로세서는 제1 신경망 처리 유닛(neural-network processing unit, NPU)을 포함하는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 동기화 장치는 제1 프로세서를 더 포함하고;상기 제1 프로세서가 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성하도록 구성되며, 상기 제1 동기화 객체는 제1 동기화 레지스터의 식별자를 포함하고, 상기 제1 동기화 레지스터의 서로 다른 값은 상기 제1 동기화 이벤트가 발생하는지를 지시하는 데 사용되며, 상기 제1 프로세서는 제1 중앙 처리 유닛(central processingunit, CPU)을 포함하고; 그리고상기 제2 프로세서가 상기 제1 동기화 레지스터의 값에 기반하여 상기 제1 동기화 이벤트가 발생하는지를 판정하도록 구성되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 제1 프로세서는 구체적으로, 제1 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 호출하는 것에 의해 상기 제2 프로세서에 포함된 복수의 동기화 레지스터 중 상기 제1 동기화 레지스터를 상기 제1 동기화 이벤트에할당하고, 상기 제1 동기화 레지스터의 식별자를 상기 제1 동기화 객체에 저장하도록 구성되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항 또는 제17항에 있어서,상기 제1 프로세서는 추가로, 제2 API를 호출하는 것에 의해 상기 제1 동기화 이벤트에 대응하는 대기 태스크를 상기 제2 프로세서에 송신하도록 구성되며, 상기 제1 동기화 이벤트에 대응하는 대기 태스크는 상기 제1 동기화 이벤트가 발생하기를 대기공개특허 10-2023-0157503-5-하는 데 사용되고, 상기 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 큐 식별자 및 상기 제1 동기화 레지스터의 식별자를 포함하고, 상기 제1 큐 식별자는 상기 대기 태스크가 위치된 큐의 식별자이며; 그리고상기 제2 프로세서는 추가로, 상기 제1 동기화 이벤트에 대응하는 대기 태스크를 수신하도록 구성되는, 동기화장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항 내지 제18항 중 어느 한 항에 있어서,상기 제2 프로세서는 구체적으로, 상기 제1 동기화 레지스터의 값이 상기 제1 값일 때, 상기 제1 동기화 이벤트가 발생하지 않은 것으로 결정하도록 구성되고; 상기 제2 프로세서가 상기 제1 동기화 이벤트가 발생하기를 계속 대기하며; 상기 제1 동기화 레지스터의 값이 상기 제2 값이 될 때까지, 상기 제2 프로세서는 상기 제1 동기화 이벤트가 발생한 것으로 결정하고, 상기 제1 동기화 레지스터의 값을 상기 제1 값으로 재설정하는, 동기화장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항 내지 제18항 중 어느 한 항에 있어서,상기 제2 프로세서는 구체적으로, 상기 제1 동기화 레지스터의 값이 상기 제2 값일 때, 상기 제1 동기화 이벤트가 발생한 것으로 결정하고, 상기제1 동기화 레지스터를 상기 제1 값으로 재설정하도록 구성되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제16항 내지 제20항 중 어느 한 항에 있어서,상기 제1 프로세서는 추가로, 제3 API를 호출하는 것에 의해 상기 제1 동기화 이벤트에 대응하는 기록 태스크를상기 제2 프로세서에 송신하도록 구성되며, 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 상기 제1 동기화이벤트가 발생함을 지시하는 데 사용되고, 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및상기 제1 동기화 레지스터의 식별자를 포함하며, 상기 제2 큐 식별자는 상기 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이고; 그리고상기 제2 프로세서는 추가로, 상기 제1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 상기 제1 동기화 레지스터의 식별자에 기반하여 상기 제1 동기화 레지스터의 값을 상기 제2 값으로 재설정하도록 구성되는, 동기화장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제16항 내지 제20항 중 어느 한 항에 있어서,상기 동기화 장치는 제3 프로세서를 더 포함하고, 상기 제3 프로세서가 제2 NPU를 포함하며;상기 제1 프로세서는 추가로, 제3 API를 호출하는 것에 의해 상기 제1 동기화 이벤트에 대응하는 기록 태스크를상기 제3 프로세서에 송신하도록 구성되고, 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 상기 제1 동기화이벤트가 발생함을 지시하는 데 사용되며, 상기 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및상기 제1 동기화 레지스터의 식별자를 포함하고, 상기 제2 큐 식별자는 상기 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이며; 그리고상기 제3 프로세서는 상기 제1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 상기 제1 동기화 레지스터의식별자에 기반하여 상기 제1 동기화 레지스터의 값을 상기 제2 값으로 재설정하도록 구성되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제16항 내지 제20항 중 어느 한 항에 있어서,상기 제1 동기화 이벤트가 인터 프로세스 동기화 이벤트이면,상기 제1 프로세서는 추가로, 제1 애플리케이션의 제4 API를 호출하는 것에 의해 상기 제1 동기화 객체의 이름공개특허 10-2023-0157503-6-을 미리 설정된 이름으로 설정하도록 구성되고; 그리고상기 제1 프로세서는 추가로, 제2 애플리케이션의 제5 API를 호출하는 것에 의해 상기 미리 설정된 이름에 대응하는 제1 동기화 레지스터의 식별자를 획득하도록 구성되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 제1 동기화 이벤트는 상기 제1 애플리케이션과 상기 제2 애플리케이션 간의 동기화 이벤트이고, 상기 미리설정된 이름은 상기 제1 애플리케이션과 상기 제2 애플리케이션에 의해 사전에 합의된 이름인, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제16항 내지 제24항 중 어느 한 항에 있어서,상기 제1 프로세서는 추가로, 제6 API를 호출하는 것에 의해 제2 동기화 레지스터의 가상 주소를 획득하도록 구성되며, 상기 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이고, 상기 제2 동기화 레지스터의서로 다른 값은 상기 제2 동기화 이벤트가 발생하는지를 지시하는 데 사용되며; 그리고상기 제1 프로세서는 추가로, 상기 제2 동기화 레지스터의 가상 주소를 제4 프로세서에 송신하도록 구성되고,상기 제1 프로세서와 상기 제4 프로세서는 서로 다른 AI 서버의 프로세서이며, 상기 제4 프로세서는 제2 CPU를포함하는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제16항 내지 제25항 중 어느 한 항에 있어서,상기 제1 프로세서는 추가로, 제7 API를 호출하여, 상기 제1 동기화 레지스터와 상기 제1 동기화 이벤트 간의대응 관계를 해제하고, 상기 제1 동기화 레지스터의 값을 상기 제1 값으로 재설정하도록 구성되며, 상기 제7API는 상기 제1 동기화 레지스터를 해제하도록 구성되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제16항 내지 제26항 중 어느 한 항에 있어서,상기 제1 동기화 레지스터의 물리적 주소는 글로벌 어드레싱 방식으로 주소 지정되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "동기화 장치로서, 상기 동기화 장치는 제4 프로세서 및 제5 프로세서를 포함하고;상기 제4 프로세서는 추가로, 제1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신하도록 구성되며, 상기 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이고, 상기 제2 동기화 레지스터의 값은 제1값 또는 제2 값을 포함하며, 상기 제1 값은 상기 제2 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고,상기 제2 값은 상기 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제1 프로세서와 상기 제4 프로세서는 서로 다른 AI 서버의 프로세서이고, 상기 제1 프로세서는 제1 중앙 처리 유닛(central processing unit,CPU)을 포함하며, 상기 제4 프로세서는 제2 CPU를 포함하고;상기 제4 프로세서는 추가로, 상기 제2 동기화 이벤트에 대응하는 원격 직접 메모리 액세스(remote directmemory access, RDMA) 태스크를 상기 제5 프로세서에 송신하도록 구성되고, 상기 제2 동기화 이벤트에 대응하는RDMA 태스크는 상기 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제2 동기화 이벤트에 대응하는RDMA 태스크는 상기 제2 동기화 레지스터의 가상 주소를 포함하고, 상기 제5 프로세서가 제3 NPU를 포함하며;그리고상기 제5 프로세서는, 상기 제2 동기화 이벤트에 대응하는 RDMA 태스크를 수신하고, RDMA 장치를 통해 상기 제2동기화 레지스터의 가상 주소에 기반하여 상기 제2 동기화 레지스터의 값을 상기 제2 값으로 재설정하도록 구성되는, 동기화 장치.공개특허 10-2023-0157503-7-청구항 29 동기화 장치로서, 상기 동기화 장치는 제4 프로세서를 포함하고;상기 제4 프로세서는 제1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신하도록 구성되며, 상기 제2동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이고, 상기 제2 동기화 레지스터의 값은 제1 값 또는제2 값을 포함하며, 상기 제1 값은 상기 제2 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 상기 제2값은 상기 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 상기 제1 프로세서와 상기 제4 프로세서는 서로 다른 AI 서버의 프로세서이고, 상기 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을포함하며, 상기 제4 프로세서는 제2 CPU를 포함함 -; 그리고상기 제4 프로세서는 추가로, 원격 직접 메모리 액세스(remote direct memory access, RDMA) 장치를 통해 상기제2 동기화 레지스터의 가상 주소에 기반하여 상기 제2 동기화 레지스터의 값을 상기 제2 값으로 재설정하도록구성되는, 동기화 장치."}
{"patent_id": "10-2023-7035925", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "전자 디바이스로서,메모리 및 제15항 내지 제29항 중 어느 한 항에 따른 동기화 장치를 포함하는 전자 디바이스."}
{"patent_id": "10-2023-7035925", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원의 실시예는 AI 서버 간 동기화가 지원되지 않는 기존 기술 문제를 해결하기 위해, 동기화 방법 및 장치 를 개시하며 인공지능 분야에 관한 것이다. 구체적인 솔루션은 다음과 같다: 제1 프로세서가 제1 동기화 이벤트 에 대한 제1 동기화 객체를 생성한다. 제1 동기화 객체는 제1 동기화 레지스터의 식별자를 포함한다. 제1 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 제1 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 제1 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 프로세서는 제1 중앙 처리 유닛 (CPU)을 포함한다. 제2 프로세서는 제1 동기화 레지스터의 값에 기반하여 제1 동기화 이벤트가 발생하는지를 판 정한다. 제2 프로세서는 제1 신경망 처리 유닛(NPU)을 포함한다."}
{"patent_id": "10-2023-7035925", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원의 실시예는 인공 지능 분야에 관한 것으로, 특히 동기화 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-7035925", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(Artificial Intelligence, AI) 시나리오에서는 일반적으로 높은 컴퓨팅 파워가 요구된다. 단일 AI 가 속기(예를 들어, 신경망 처리 유닛(neural-network process unit, NPU) 또는 단일 AI 서버(예를 들어, 복수의 AI 가속기를 포함하는 AI 서버)의 컴퓨팅 파워는 제한되어 있기 때문이며, 따라서 AI 시나리오의 컴퓨팅 파워 요건을 충족할 수 없다. 따라서 AI 시나리오에서 요구되는 컴퓨팅 파워를 제공하기 위해서는 클러스터를 형성하 기 위해 복수의 AI 서버가 필요하다. 복수의 AI 서버가 클러스터를 형성하여 AI 트레이닝을 수행할 때, AI 가속 기 내, AI 서버의 서로 다른 AI 가속기 간 그리고 AI 서버 간의 동기화 전송(transmission) 및 동기화 대기 시 간을 줄이기 위한 적절한 동기화 메커니즘을 제공하는 것이 필요하다. 본 출원의 실시예는 AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, AI 서버 간의 동기화를 구현하기 위한 동기화 방법 및 장치를 제공한다. 전술한 목적을 달성하기 위해, 본 출원의 실시예에서는 다음과 같은 기술 솔루션이 사용된다. 본 출원 실시예의 제1 측면에 따르면, 동기화 방법이 제공된다. 이 방법은 다음을 포함한다: 제1 프로세서가 제 1 동기화 이벤트(synchronization event)에 대한 제1 동기화 객체(synchronization object)를 생성한다. 제1 동기화 객체는 제1 동기화 레지스터(synchronization register)의 식별자를 포함한다. 제1 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 제1 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 제1 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제2 프로세서는 제1 동기화 레지스터의 값에 기 반하여 제1 동기화 이벤트가 발생하는지를 판정한다. 선택적으로, 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을 포함하고, 제2 프로세서는 제1 신경망 처리 유닛(neural-network processing unit, NPU)을 포함한다. 예를 들어, 제1 프로세서는 AI 서버 의 CPU일 수 있고, 제2 프로세서는 AI 서버의 AI 가속기일 수 있다. CPU와 AI 가속기는 동일한 AI 서버에 위치 된다. 제2 프로세서는 제1 동기화 이벤트가 발생하기를 대기하는 AI 가속기이다. 선택적으로, 제1 동기화 이벤트는 NPU에서 발생할 수도 있고, AI 서버의 서로 다른 NPU 간에 발생할 수도 있으 며, 서로 다른 AI 서버 간에 발생할 수도 있다. 이 솔루션에 기반하여, 동기화 이벤트에 대한 동기화 객체가 생성되고, 각 동기화 객체는 하나의 동기화 레지스 터에 대응하므로, AI 가속기는 동기화 레지스터의 값에 기반하여, 동기화 레지스터에 대응하는 동기화 이벤트가 발생하는지를 판정할 수 있다. 이러한 방식으로 AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간 그리고 AI 서 버 간의 동기화를 구현할 수 있다. 제1 측면을 참조하여, 가능한 구현에서, 제1 프로세서가 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성하는 것은 다음을 포함한다: 제1 프로세서가 제1 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 호출하는 것에 의해, 제2 프로세서에 포함된 복수의 동기화 레지스터 중 제1 동기화 레지스 터를 제1 동기화 이벤트에 할당하고, 제1 동기화 레지스터의 식별자를 제1 동기화 객체에 저장한다. 선택적으로, 제1 API는 동기화 이벤트에 대한 동기화 객체를 생성하도록 구성된다. 제1 API는 NotifyCreat(deviceID, notify)일 수 있으며, 여기서 입력 deviceID는 AI 가속기의 ID이고, 출력 notify는 동 기화 객체이며, NotifyCreat 인터페이스는 동기화 객체를 생성하도록 구성된다. deviceID는 동기화 이벤트가 발 생하기를 대기하는 AI 가속기의 ID이다. 이 솔루션에 기반하여, 동기화 레지스터 그룹이 AI 가속기에 배치되므로(disposed), 동기화가 수행되어야 할 때, CPU가 동기화 이벤트가 발생하기를 대기하는 AI 가속기에 포함된 복수의 동기화 레지스터 중 제1 동기화 레 지스터를 제1 동기화 이벤트에 할당할 수 있다. 이러한 방식으로, 제1 동기화 레지스터의 값이 변경되면, AI 가 속기는 제1 동기화 레지스터의 값에서의 변경을 즉시 검출할 수 있고, 제1 동기화 이벤트가 발생하는지를 비교 적 빠르게 판정할 수 있다. 이러한 방식으로 AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, 서로 다른 AI 서버 간의 동기화가 구현된다. 또한 본 출원의 실시예에서 솔루션에 제공되는 API 인터페이스는 상대적으로 간 단하며 동기화 오버헤드도 상대적으로 작다. 따라서 AI 트레이닝 효율성을 높일 수 있다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 이 방법은 다음을 더 포함한다: 제1 프 로세서가 제2 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 대기 태스크(wait task)를 제2 프로세서 에 송신한다. 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 동기화 이벤트가 발생하기를 대기하는 데 사용 되며, 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 큐(queue) 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제1 큐 식별자는 대기 태스크가 위치된 큐의 식별자이다. 제2 프로세서는 제1 동기화 이벤트에 대응 하는 대기 태스크를 수신한다. 이 솔루션에 기반하여, CPU는 동기화 이벤트가 발생하기를 대기하는 데 사용되는 대기 태스크를 간단한 API를 사용하여 AI 가속기에 전달하고(deliver), 동기화 레지스터의 식별자를 대기 태스크에 추가하므로, AI 가속기는 동기화 레지스터의 서로 다른 값에 기반하여 동기화 이벤트가 발생하는지를 판정할 수 있다. 이러한 방식으로, AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, AI 서버 간의 동기화를 구현할 수 있다. 선택적으로, 제2 API는 동기화 이벤트에 대응하는 대기 태스크를 전달하도록 구성된다. 제2 API는 NotifyWait(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에 대응하는 동기화 이벤트가 발생하기를 대기하도록 구성된다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제2 프로세서가 제1 동기화 레지스터의 값에 기반하여 제1 동기화 이벤트가 발생하는지를 판정하는 것은 다음을 포함한다: 제1 동기화 레지스터의 값이 제1 값일 때, 제2 프로세서는 제1 동기화 이벤트가 발생하지 않은 것으로 결정한다. 제2 프로세서는 제1 동기화 이벤트가 발생하기를 계속 대기한다. 제2 프로세서는 제1 동기화 레지스터의 값이 제2 값이 될 때까지 제1 동기 화 이벤트가 발생한 것으로 결정한다. 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정한다 (reset). 이 솔루션에 기반하여, 제1 동기화 이벤트가 발생하지 않을 때, AI 가속기는 제1 동기화 이벤트가 발생할 때까 지 제1 동기화 이벤트가 발생하기를 대기하며, 그런 다음 제1 동기화 레지스터의 값을 제1 값으로 재설정하고, 후속 태스크를 계속 실행할 수 있다. 이러한 방식으로, AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, 서로 다른 AI 서버 간의 동기화가 구현될 수 있다. 제1 동기화 이벤트가 발생할 때, 제1 레지스터의 값이 제1 값에서 제2 값으로 변경되는 것으로 이해될 수 있다. 제1 동기화 레지스터가 제2 프로세서의 동기화 레지스터이기 때문에, 제2 프로세서의 컨트롤러는 제1 동기화 레 지스터 값에서의 변경을 즉시 검출할 수 있고, 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정할 수 있다. 제2 프로세서가 제1 동기화 레지스터의 값을 제1 값으로 재설정하므로, 제1 동기화 레지스터가 동기화 작동(synchronization operation)을 계속해서 수행할 수 있다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제2 프로세서가 제1 동기화 레지스터의 값에 기반하여 제1 동기화 이벤트가 발생하는지를 판정하는 것은 다음을 더 포함한다: 제1 동기화 레지스터의 값이 제2 값일 때, 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정하고, 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정한다. 이 솔루션에 기반하여, 제2 프로세서가 제1 동기화 레지스터의 값이 제2 값인 것을 검출할 때, 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정하고, 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정 한다. 그런 다음 제2 프로세서는 후속 태스크를 계속해서 실행할 수 있다. 이러한 방식으로 정확한 동기화가 보 장될 수 있으며, AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, 서로 다른 AI 서버 간의 동기화가 구현될 수 있다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 이 방법은 다음을 더 포함한다: 제1 프 로세서가 제3 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크(record task)를 제2 프로세 서에 송신한다. 제1 동기화 이벤트에 대응하는 기록 태스크는 제1 동기화 이벤트가 발생함을 지시하는 데 사용 되고, 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한 다. 제2 큐 식별자는 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이다. 제2 프로세서는 제 1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레 지스터의 값을 제2 값으로 재설정한다. 이 솔루션에 기반하여 CPU는 동기화 이벤트가 발생함을 지시하는 데 사용되는 기록 태스크를 간단한 API를 이용 하여 AI 가속기(제2 프로세서)에 전달하고, 동기화 레지스터의 식별자를 대기 태스크에 추가할 수 있으므로, AI 가속기는 동기화 레지스터의 식별자에 기반하여 제2 값을 기록한다(write). 이러한 방식으로, 동기화 레지스터 의 값은 제1 동기화 이벤트의 발생 상태(occurrence status)에 대응될 수 있다. 제1 동기화 레지스터는 제2 프 로세서의 동기화 레지스터이다. 따라서 제2 프로세서의 컨트롤러는 제1 동기화 레지스터의 값에서의 변화를 즉 시 검출하고, 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정하므로, 제2 프로세서가 후속 태스크를 계속해서 실행하여 제2 프로세서에서 정확한 동기화를 보장할 수 있다. 선택적으로, 제3 API는 동기화 이벤트에 대응하는 기록 태스크를 전달하도록 구성된다. 제3 API는 NotifyRecord(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에 대응하는 동기 화 이벤트의 발생을 설정하도록 구성된다. 선택적으로, 제1 동기화 이벤트가 AI 가속기에서 발생할 때, 제2 프로세서가 대기 태스크와 기록 태스크를 모두 실행한다. 제2 프로세서가 대기 태스크와 기록 태스크를 모두 실행할 때, 대기 태스크와 기록 태스크는 각각 두 개의 스트림에 있는 태스크일 수 있다. 선택적으로, 제1 동기화 이벤트가 AI 서버의 두 AI 가속기 간에 발생할 때, 제2 프로세서가 대기 태스크를 실행 하고 제3 프로세서가 기록 태스크를 실행한다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 이 방법은 다음을 더 포함한다: 제1 프 로세서가 제3 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크를 제3 프로세서에 송신한다. 제1 동기화 이벤트에 대응하는 기록 태스크는 제1 동기화 이벤트가 발생함을 지시하는 데 사용되고, 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제2 큐 식별자는 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이다. 제3 프로세서는 제2 NPU를 포함한다. 제3 프로세서는 제1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 제1 동기화 레지스터의 식별 자에 기반하여 제1 동기화 레지스터의 값을 제2 값으로 재설정한다. 선택적으로, 제3 프로세서와 제2 프로세서는 AI 서버에서 서로 다른 NPU일 수 있다. 이 솔루션에 기반하여 CPU는 동기화 이벤트가 발생함을 지시하는 데 사용되는 기록 태스크를 간단한 API를 이용 하여 AI 가속기(제3 프로세서)에 전달하고, 동기화 레지스터의 식별자를 대기 태스크에 추가할 수 있으므로, AI 가속기는 동기화 레지스터의 식별자에 기반하여 제2 값을 기록한다. 이러한 방식으로, 동기화 레지스터의 값은 제1 동기화 이벤트의 발생 상태에 대응될 수 있다. 제1 동기화 레지스터는 제2 프로세서의 동기화 레지스터이다. 따라서 제2 프로세서의 컨트롤러는 제1 동기화 레지스터 값에서의 변화를 즉시 검출할 수 있고, 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정하므로, 제2 프로세서가 후속 태스크를 계속해서 실행하여 AI 서버에서 제2 프로세서와 제3 프로세서 간의 정확한 동기화를 보장할 수 있다. 본 솔루션에서 제공하는 동기화 방법에서 동기화 오버헤드는 AI 가속기의 컨트롤러가 버스를 통해 레지스터를 기록하는 오버헤드이며, 동기화 오버헤드는 상대적으로 작은 것으로 이해될 수 있다. 예를 들어, 이 솔루션에서 제공하는 동기화 방법을 사용하는 것에 의해, NPU에서 동기화의 동기화 오버헤드는 50ns보다 작고, AI 서버에서 서로 다른 NPU 간의 동기화 오버헤드는 1μs보다 작다. 또한 본 솔루션에서는 간단한 API 인터페이스를 제공하 며 이 인터페이스는 일반 OS의 세마포어(semaphore) 인터페이스와 유사하여 개발자가 AI 가속기를 사용하는 것 을 크게 용이하게 할 수 있다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 동기화 이벤트가 인터 프로세스 동 기화 이벤트(inter-process synchronization event)이면, 이 방법은 다음을 더 포함한다: 제1 프로세서가 제1 애플리케이션의 제4 API를 호출하는 것에 의해 제1 동기화 객체의 이름(name)을 미리 설정된 이름으로 설정한다. 제1 프로세서는 제2 애플리케이션의 제5 API를 호출하는 것에 의해 미리 설정된 이름에 대응하는 제1 동기화 레지스터의 식별자를 획득한다. 이 솔루션에 기반하여 동기화 이벤트가 인터 프로세스 동기화 이벤트이면, 동기화 객체의 글로벌(global) 이름 이 미리 설정되어 있으므로, 서로 다른 프로세스 간의 동기화 객체가 동일한 동기화 레지스터에 대응될 수 있다. 그러면 제2 API와 제3 API를 호출하는 것에 의해 인터 프로세스 동기화를 구현할 수 있다. 선택적으로, 제4 API는 동기화 객체의 글로벌 이름을 설정하도록 구성된다. 제4 API는 IpcSetNotifyName(notify, name)일 수 있으며, 동기화 객체 notify의 글로벌 이름을 설정하도록 구성된다. 제5 API는 미리 설정된 이름에 대응하는 레지스터의 식별자를 획득하도록 구성된다. 제5 API는 IpcOpenNotify(notify, name)일 수 있으며, 동기화 객체의 글로벌 이름 name에 기반하여 동기화 객체 notify를 열도록(open) 구성된다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 동기화 이벤트는 제1 애플리케이션 과 제2 애플리케이션 사이의 동기화 이벤트이고, 미리 설정된 이름은 제1 애플리케이션과 제2 애플리케이션에 의해 사전에 합의된 이름이다. 이 솔루션에 기반하여, 동기화 이벤트가 인터 프로세스 동기화를 위한 것일 때, 동기화 객체의 글로벌 이름은 서로 다른 애플리케이션에 의해 미리 설정되므로, 서로 다른 프로세스 간의 동기화 객체가 동일한 동기화 레지 스터에 대응하여, 인터 프로세스 동기화를 구현한다. 선택적으로, 제1 동기화 이벤트가 하나의 APP의 동기화 이벤트인지, 복수의 APP 간의 동기화 이벤트인지에 상관 없이, 제1 동기화 이벤트는 AI 가속기에서 발생할 수도 있고, AI 서버의 서로 다른 AI 가속기 간에 발생할 수도 있다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 이 방법은 다음을 더 포함한다: 제1 프 로세서가 제6 API를 호출하는 것에 의해 제2 동기화 레지스터의 가상 주소를 획득한다. 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이다. 제2 동기화 레지스터의 서로 다른 값이 제2 동기화 이벤트가 발생 하는지를 지시하는 데 사용된다. 제1 프로세서는 제2 동기화 레지스터의 가상 주소를 제4 프로세서에 송신한다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이고, 제4 프로세서는 제2 CPU를 포함한다. 선택적으로, 제1 프로세서와 제4 프로세서는 각각 두 개의 AI 가속기의 CPU일 수 있다. 이 솔루션에 기반하여, 동기화 레지스터의 물리적 주소를 가상 주소로 변환하므로, AI 가속기 간의 동기화를 구 현하기 위해, 가상 주소에 대응하는 동기화 레지스터에 값을 기록하여 동기화 이벤트가 발생함을 지시한다. 또 한 본 솔루션에서 AI 서버 간 동기화를 수행할 때, 동기화 오버헤드는 네트워크 통신의 시간 오버헤드일 뿐이며, 그 외 추가적인 오버헤드는 없다. 따라서 동기화 오버헤드가 상대적으로 작다. 또한 본 출원의 실시예 에서는 간단한 API 인터페이스가 제공되며, 이 인터페이스는 일반 OS의 세마포어 인터페이스와 유사하여 개발자 가 AI 가속기를 사용하는 것을 크게 용이하게 할 수 있다. 선택적으로, 제6 API는 동기화 객체에 대응하는 레지스터의 가상 주소를 획득하도록 구성된다. 제6 API는 NotifyGetAddr(notify, addr)일 수 있으며, 입력은 동기화 객체 notify이고, 출력은 동기화 객체 notify에 대 응하는 동기화 레지스터의 가상 주소이다. 제1 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 이 방법은 다음을 더 포함한다: 제1 프 로세서가 제7 API를 호출하여 제1 동기화 레지스터와 제1 동기화 이벤트 사이의 대응 관계를 해제하고(release), 제1 동기화 레지스터의 값을 제1 값으로 설정한다. 제7 API는 제1 동기화 레지스터를 해제하도록 구 성된다. 이러한 솔루션에 기반하여, 제1 동기화 레지스터와 제1 동기화 이벤트 사이의 대응 관계가 해제되므로, 제1 동 기화 레지스터가 재활용될 수 있다. 이러한 방식으로, 이후에 동기화를 수행해야 할 때, 동기화 레지스터를 다 른 동기화 객체에 할당하여 동기화 레지스터의 활용도를 향상시킬 수 있다. 선택적으로, 제7 API는 제1 동기화 레지스터를 해제하도록 구성된다. 제7 API는 NotifyDestroy(notify)일 수 있 으며, 인터페이스는 동기화 객체 notify를 파기하고(destroy), 동기화 객체에 대응하는 동기화 레지스터를 해제 하도록 구성될 수 있다. 제1 측면 및 전술한 가능한 구현을 참조하면, 또 다른 가능한 구현에서, 제1 동기화 레지스터의 물리적 주소는 글로벌 어드레싱(addressing) 방식으로 주소 지정된다. 이 솔루션에 기반하여, 동기화 레지스터는 글로벌 어드레싱 방식으로 주소 지정되므로, 각 AI 가속기의 컨트롤 러는 AI 서버의 다른 AI 가속기에 있는 동기화 레지스터의 물리적 주소를 알게 될(learn) 수 있고, 물리적 주소 를 이용하여 다른 AI 가속기의 동기화 레지스터에도 액세스할 수 있다. 이런 방식으로, AI 가속기 내 및 AI 가 속기 간의 동기화를 구현할 수 있다. 본 출원의 실시예의 제2 측면에 따르면, 동기화 방법이 제공된다. 이 방법은 다음을 포함한다: 제4 프로세서가 제1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신한다. 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이다. 제2 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 제2 동기화 이 벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 제2 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이다. 제1 프로세서는 제1 중앙 처리 유닛 (central processing unit, CPU)을 포함하고, 제4 프로세서는 제2 CPU를 포함한다. 제4 프로세서는 제2 동기화 이벤트에 대응하는 원격 직접 메모리 액세스(remote direct memory access, RDMA) 태스크를 제5 프로세서에 송 신한다. 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 제 2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 레지스터의 가상 주소를 포함한다. 제5 프로세서는 제2 동기화 이벤트에 대응하는 RDMA 태스크를 수신하고, RDMA 장치를 통해 제2 동기화 레지스터의 가상 주소에 기반 하여 제2 동기화 레지스터의 값을 제2 값으로 재설정한다. 제5 프로세서는 제3 NPU를 포함한다. 선택적으로, 제1 프로세서와 제4 프로세서는 각각 서로 다른 AI 가속기의 CPU일 수 있다. 제4 프로세서와 제5 프로세서는 동일한 AI 가속기의 서로 다른 프로세서이다. 예를 들어, 제4 프로세서는 AI 가속기의 CPU이고, 제5 프로세서는 AI 가속기의 NPU이다. 이 솔루션에 기반하여, AI 서버의 AI 가속기는 동기화 레지스터의 가상 주소를 획득하므로, 동기화 이벤트가 발 생할 때, AI 가속기는 RDMA 장치를 통해 가상 주소에 대응하는 동기화 레지스터에 값을 써서 동기화 이벤트가 발생함을 지시할 수 있다. 이러한 방식으로, 다른 AI 서버의 AI 가속기는 동기화 레지스터 값에서의 변화를 즉 시 검출하고, 동기화 이벤트가 발생한 것으로 결정할 수 있다. 따라서 서로 다른 AI 가속기 간의 동기화를 구현 할 수 있다. 선택적으로, 제4 프로세서는 제8 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 호출하는 것에 의해 제2 동기화 이벤트에 대응하는 RDMA 태스크를 제5 프로세서에 송신할 수 있다. 제8 API는 동기화 이벤트에 대응하는 RDMA 태스크를 전달하도록 구성된다. 제8 API는 RDMAsend(addr, 1)일 수 있으 며, 제2 값 1을 가상 주소 addr에 기록하기를 지시하도록 구성된다. 본 출원 실시예의 제3 측면에 따르면, 동기화 방법이 제공된다. 이 방법은 다음을 포함한다: 제4 프로세서가 제 1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신한다. 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이다. 제2 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 제2 동기화 이 벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 제2 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이다. 제1 프로세서는 제1 중앙 처리 유닛 (central processing unit, CPU)을 포함하고, 제4 프로세서는 제2 CPU를 포함한다. 제4 프로세서는 원격 직접 메모리 액세스(remote direct memory access, RDMA) 장치를 통해 제2 동기화 레지스터의 가상 주소에 기반하여 제2 동기화 레지스터의 값을 제2 값으로 재설정한다. 선택적으로, 제1 프로세서와 제4 프로세서는 각각 두 개의 AI 가속기의 CPU일 수 있다. 이 솔루션에 기반하여, AI 서버의 CPU는 동기화 레지스터의 가상 주소를 획득하므로, 동기화 이벤트가 발생할 때, CPU는 RDMA를 통해 가상 주소에 대응하는 동기화 레지스터에 값을 기록하여 동기화 이벤트가 발생함을 지시 할 수 있다. 이러한 방식으로, 다른 AI 서버의 AI 가속기가 동기화 레지스터 값에서의 변화를 즉시 검출하고, 동기화 이벤트가 발생한 것으로 결정할 수 있다. 따라서 서로 다른 AI 가속기 간의 동기화를 구현할 수 있다. 본 출원 실시예의 제4 측면에 따르면, 동기화 장치가 제공된다. 동기화 장치는 제2 프로세서를 포함한다. 제2 프로세서는 복수의 동기화 레지스터를 포함한다. 각 동기화 레지스터는 하나의 동기화 이벤트에 대응하도록 구 성되며, 각 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 동기화 레지스터에 대응하는 동 기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 동기화 레지스터에 대응하는 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제2 프로세서는 제1 신경망 처리 유닛(neural-network processing unit, NP U)을 포함한다. 제4 측면을 참조하면, 가능한 구현에서, 동기화 장치는 제1 프로세서 - 제1 프로세서는 제1 동기화 이벤트에 대 한 제1 동기화 객체를 생성하도록 구성되며, 제1 동기화 객체는 제1 동기화 레지스터의 식별자를 포함하고, 제1 동기화 레지스터의 서로 다른 값이 제1 동기화 이벤트가 발생하는지를 지시하는 데 사용됨 - 및 제1 동기화 레 지스터의 값에 기반하여, 제1 동기화 이벤트가 발생하는지를 판정하도록 구성된 제2 프로세서를 더 포함하고, 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을 포함한다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 구체적으로, 제1 애플 리케이션 프로그래밍 인터페이스(application programming interface, API)를 호출하는 것에 의해, 제2 프로세 서에 포함된 복수의 동기화 레지스터 중 제1 동기화 레지스터를 제1 동기화 이벤트에 할당하고, 제1 동기화 레 지스터의 식별자를 제1 동기화 객체에 저장하도록 구성된다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제2 API를 호 출하는 것에 의해 제1 동기화 이벤트에 대응하는 대기 태스크를 제2 프로세서에 송신하도록 구성된다. 제1 동기 화 이벤트에 대응하는 대기 태스크는 제1 동기화 이벤트가 발생하기를 대기하는 데 사용되며, 제1 동기화 이벤 트에 대응하는 대기 태스크는 제1 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제1 큐 식별자는 대 기 태스크가 위치된 큐의 식별자이다. 제2 프로세서는 추가로, 제1 동기화 이벤트에 대응하는 대기 태스크를 수 신하도록 구성된다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제2 프로세서는 구체적으로, 제1 동기 화 레지스터의 값이 제1 값일 때, 제1 동기화 이벤트가 발생하지 않은 것으로 결정하도록 구성된다. 제2 프로세 서는 제1 동기화 이벤트가 발생하기를 계속 대기한다. 제2 프로세서는 제1 동기화 레지스터의 값이 제2 값이 될 때까지 제1 동기화 이벤트가 발생한 것으로 결정하고, 제1 동기화 레지스터의 값을 제1 값으로 재설정한다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제2 프로세서는 구체적으로, 제1 동기 화 레지스터의 값이 제2 값일 때, 제1 동기화 이벤트가 발생하는 것으로 결정하고, 제1 동기화 레지스터의 값을 제1 값으로 재설정하도록 구성된다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제3 API를 호 출하는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크를 제2 프로세서에 송신하도록 구성된다. 제1 동기 화 이벤트에 대응하는 기록 태스크는 제1 동기화 이벤트가 발생함을 지시하는 데 사용되고, 제1 동기화 이벤트 에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제2 큐 식별자는 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이다. 제2 프로세서는 추가로, 제1 동기화 이벤트 에 대응하는 기록 태스크를 수신하고, 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레지스터의 값을 제2 값으로 재설정하도록 구성된다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 동기화 장치는 제3 프로세서를 더 포함 하고, 제3 프로세서는 제2 NPU를 포함한다. 제1 프로세서는 추가로, 제3 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크를 제3 프로세서에 송신하도록 구성된다. 제1 동기화 이벤트에 대응하는 기록 태 스크는 제1 동기화 이벤트가 발생함을 지시하는 데 사용되고, 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제2 큐 식별자는 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이다. 제3 프로세서는 제1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레지스터의 값을 제2 값으로 재설정하도록 구성된다. 제4 측면 및 전술한 가능한 구현을 참조하면, 또 다른 가능한 구현에서, 제1 동기화 이벤트가 인터 프로세스 동 기화 이벤트이면, 제1 프로세서는 추가로, 제1 애플리케이션의 제4 API를 호출하는 것에 의해 제1 동기화 객체 의 이름을 미리 설정된 이름으로 설정하도록 구성된다. 제1 프로세서는 추가로, 제2 애플리케이션의 제5 API를 호출하는 것에 의해 미리 설정된 이름에 대응하는 제1 동기화 레지스터의 식별자를 획득하도록 구성된다. 제4 측면 및 전술한 가능한 구현을 참조하면, 또 다른 가능한 구현에서, 제1 동기화 이벤트는 제1 애플리케이션 과 제2 애플리케이션 사이의 동기화 이벤트이고, 미리 설정된 이름은 제1 애플리케이션과 제2 애플리케이션에 의해 사전에 합의된 이름이다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제6 API를 호 출하는 것에 의해 제2 동기화 레지스터의 가상 주소를 획득하도록 구성된다. 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이다. 제2 동기화 레지스터의 서로 다른 값이 제2 동기화 이벤트가 발생하는지를 지 시하는 데 사용된다. 제1 프로세서는 추가로, 제2 동기화 레지스터의 가상 주소를 제4 프로세서에 송신하도록 구성된다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이고, 제4 프로세서는 제2 CPU를 포함 한다. 제4 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제7 API를 호 출하여 제1 동기화 레지스터와 제1 동기화 이벤트 사이의 대응 관계를 해제하며, 제1 동기화 레지스터의 값을 제1 값으로 설정하도록 구성된다. 제7 API는 제1 동기화 레지스터를 해제하도록 구성된다. 제4 측면 및 전술한 가능한 구현을 참조하면, 또 다른 가능한 구현에서, 제1 동기화 레지스터의 물리적 주소는 글로벌 어드레싱 방식으로 주소 지정된다. 본 출원의 실시예의 제5 측면에 따르면, 동기화 장치가 제공된다. 동기화 장치는 제4 프로세서와 제5 프로세서 를 포함한다. 제4 프로세서는 제1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신하도록 구성된다. 제 2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이다. 제2 동기화 레지스터의 값은 제1 값 또는 제 2 값을 포함한다. 제1 값은 제2 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 제2 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이다. 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을 포함하고, 제4 프로세서는 제2 CPU를 포 함한다. 제4 프로세서는 추가로, 제2 동기화 이벤트에 대응하는 원격 직접 메모리 액세스(remote direct memory access, RDMA) 태스크를 제5 프로세서에 송신하도록 구성된다. 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제 2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 레지스터의 가상 주소를 포함한다. 제5 프로세서는 제3 NPU를 포함한다. 제5 프로세서는 제2 동기화 이벤트에 대응하는 RDMA 태스크를 수신하고, RDMA 장치를 통해 제2 동기화 레지스터의 가상 주소에 기반하여 제2 동기화 레지스터의 값을 제2 값으로 재설정하도록 구성된다. 선택적으로, 제4 프로세서는 제8 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 호출하는 것에 의해 제2 동기화 이벤트에 대응하는 RDMA 태스크를 제5 프로세서에 송신할 수 있다. 본 출원의 실시예의 제6 측면에 따르면, 동기화 장치가 제공된다. 동기화 장치는 제4 프로세서를 포함한다. 제4 프로세서는 제1 프로세서로부터 제2 동기화 레지스터의 가상 주소를 수신하도록 구성된다. 제2 동기화 레지스터 는 제2 동기화 이벤트에 대응하는 레지스터이다. 제2 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 제2 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 제2 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이다. 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을 포함하고, 제4 프로세서는 제2 CPU를 포함한다. 제4 프로세 서는 추가로, 원격 직접 메모리 액세스(remote direct memory access, RDMA) 장치를 통해 제2 동기화 레지스터 의 가상 주소에 기반하여 제2 동기화 레지스터의 값을 제2 값으로 재설정하도록 구성된다. 제4 측면의 효과 설명은 제1 측면의 효과 설명을 참조한다. 제5 측면의 효과 설명은 제2 측면의 효과 설명을 참 조한다. 제6 측면의 효과 설명은 제3 측면의 효과 설명을 참조한다. 자세한 내용은 여기서 다시 설명하지 않는 다. 본 출원의 실시예의 제7 측면에 따르면, 제1 프로세서가 제공된다. 제1 프로세서는 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성하도록 구성된다. 제1 동기화 객체는 제1 동기화 레지스터의 식별자를 포함한다. 제1 레 지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되 고, 제2 값은 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을 포함한다.선택적으로, 제1 프로세서는 추가로, 제1 레지스터의 값을 제1 값으로 재설정하도록 구성된다. 제7 측면을 참조하면, 가능한 구현에서, 제1 프로세서는 구체적으로, 제1 애플리케이션 프로그래밍 인터페이스 (application programming interface, API)를 호출하는 것에 의해 제2 프로세서에 포함된 복수의 동기화 레지 스터 중 제1 동기화 레지스터를 제1 동기화 이벤트에 할당하고, 제1 동기화 레지스터의 식별자를 제1 동기화 객 체에 저장하도록 구성된다. 제7 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제2 API를 호 출하는 것에 의해 제1 동기화 이벤트에 대응하는 대기 태스크를 제2 프로세서에 송신하도록 구성된다. 제1 동기 화 이벤트에 대응하는 대기 태스크는 제1 동기화 이벤트가 발생하기를 대기하는 데 사용되며, 제1 동기화 이벤 트에 대응하는 대기 태스크는 제1 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제1 큐 식별자는 대 기 태스크가 위치된 큐의 식별자이다. 제7 측면 및 전술한 가능한 구현을 참조하여, 다른 가능한 구현에서, 제1 프로세서는 추가로, 제3 API를 호출하 는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크를 제2 프로세서에 송신하도록 구성된다. 제1 동기화 이벤트에 대응하는 기록 태스크는 제1 동기화 이벤트가 발생함을 지시하는 데 사용되고, 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제2 큐 식별자는 제1 동 기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이다. 제7 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제3 API를 호 출하는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크를 제3 프로세서에 송신하도록 구성된다. 제1 동기 화 이벤트에 대응하는 기록 태스크는 제1 동기화 이벤트가 발생함을 지시하는 데 사용되고, 제1 동기화 이벤트 에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제2 큐 식별자는 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이다. 제7 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 동기화 이벤트가 인터 프로세스 동 기화 이벤트이면, 제1 프로세서는 추가로, 제1 애플리케이션의 제4 API를 호출하는 것에 의해 제1 동기화 객체 의 이름을 미리 설정된 이름으로 설정하도록 구성된다. 제1 프로세서는 추가로, 제2 애플리케이션의 제5 API를 호출하는 것에 의해 미리 설정된 이름에 대응하는 제1 동기화 레지스터의 식별자를 획득하도록 구성된다. 제7 측면 및 전술한 가능한 구현을 참조하면, 또 다른 가능한 구현에서, 제1 동기화 이벤트는 제1 애플리케이션 과 제2 애플리케이션 사이의 동기화 이벤트이고, 미리 설정된 이름은 제1 애플리케이션과 제2 애플리케이션에 의해 사전에 합의된 이름이다. 제7 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제6 API를 호 출하는 것에 의해 제2 동기화 레지스터의 가상 주소를 획득하도록 구성된다. 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지스터이다. 제2 동기화 레지스터의 서로 다른 값이 제2 동기화 이벤트가 발생하는지를 지 시하는 데 사용된다. 제1 프로세서는 추가로, 제2 동기화 레지스터의 가상 주소를 제4 프로세서에 송신하도록 구성된다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이고, 제4 프로세서는 제2 CPU를 포함 한다. 제7 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제1 프로세서는 추가로, 제7 API를 호 출하고, 제1 동기화 레지스터와 제1 동기화 이벤트 사이의 대응 관계를 해제하며, 제1 동기화 레지스터의 값을 제1 값으로 설정하도록 구성된다. 제7 API는 제1 동기화 레지스터를 해제하도록 구성된다. 제7 측면 및 전술한 가능한 구현을 참조하면, 또 다른 가능한 구현에서, 제1 동기화 레지스터의 물리적 주소는 글로벌 어드레싱 방식으로 주소 지정된다. 본 출원의 실시예의 제8 측면에 따르면, 제2 프로세서가 제공된다. 제2 프로세서는 복수의 동기화 레지스터를 포함한다. 각 동기화 레지스터는 하나의 동기화 이벤트에 대응하도록 구성되며, 각 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 동기화 레지스터에 대응하는 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 동기화 레지스터에 대응하는 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제2 프로 세서는 제1 신경망 처리 유닛(neural-network processing unit, NPU)을 포함한다. 제8 측면을 참조하면, 가능한 구현에서, 제2 프로세서는 제1 동기화 레지스터의 값에 기반하여, 제1 동기화 이 벤트가 발생하는지를 판정하도록 구성된다. 제8 측면 및 전술한 가능한 구현을 참조하여, 다른 가능한 구현에서, 제2 프로세서는 구체적으로, 제1 동기화 레지스터의 값이 제1 값일 때, 제1 동기화 이벤트가 발생하지 않은 것으로 결정하도록 구성된다. 제2 프로세서 는 제1 동기화 이벤트가 발생하기를 계속 대기한다. 제2 프로세서는 제1 동기화 레지스터의 값이 제2 값이 될 때까지 제1 동기화 이벤트가 발생한 것으로 결정하고, 제1 동기화 레지스터의 값을 제1 값으로 재설정한다. 제8 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제2 프로세서는 구체적으로 추가로, 제 1 동기화 레지스터의 값이 제2 값일 때, 제1 동기화 이벤트가 발생하는 것으로 결정하고, 제1 동기화 레지스터 의 값을 제1 값으로 재설정하도록 구성된다. 제8 측면 및 전술한 가능한 구현을 참조하면, 또 다른 가능한 구현에서, 제2 프로세서는 추가로, 제1 동기화 이 벤트에 대응하는 대기 태스크를 수신하도록 구성된다. 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 동기화 이벤트가 발생하기를 대기하는 데 사용되며, 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 큐 식별자 및 제 1 동기화 레지스터의 식별자를 포함한다. 제1 큐 식별자는 대기 태스크가 위치된 큐의 식별자이다. 제8 측면 및 전술한 가능한 구현을 참조하여, 또 다른 가능한 구현에서, 제2 프로세서는 추가로, 제1 동기화 이 벤트에 대응하는 기록 태스크를 수신하고, 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레지스터의 값 을 제2 값으로 재설정하도록 구성된다. 제1 동기화 이벤트에 대응하는 기록 태스크는 제1 동기화 이벤트가 발생 함을 지시하는 데 사용되고, 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스 터의 식별자를 포함한다. 제2 큐 식별자는 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이 다. 본 출원의 실시예의 제9 측면에 따르면, 제4 프로세서가 제공된다. 제4 프로세서는 제1 프로세서로부터 제2 동 기화 레지스터의 가상 주소를 수신하도록 구성된다. 제2 동기화 레지스터는 제2 동기화 이벤트에 대응하는 레지 스터이고, 제2 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 제2 동기화 이벤트가 발생하 지 않음을 지시하는 데 사용되고, 제2 값은 제2 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 프로세서 와 제4 프로세서는 서로 다른 AI 서버의 프로세서이다. 제1 프로세서는 제1 중앙 처리 유닛(central processing unit, CPU)을 포함하고, 제4 프로세서는 제2 CPU를 포함한다. 제4 프로세서는 추가로, 제2 동기화 이벤트에 대 응하는 원격 직접 메모리 액세스(remote direct memory access, RDMA) 태스크를 제5 프로세서에 송신하도록 구 성된다. 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 제 2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 레지스터의 가상 주소를 포함한다. 제5 프로세서는 제3 NPU를 포함한다. 본 출원의 실시예의 제10 측면에 따르면, 제5 프로세서가 제공된다. 제5 프로세서는 제2 동기화 이벤트에 대응 하는 RDMA 태스크를 수신하고, RDMA 장치를 통해 제2 동기화 레지스터의 가상 주소에 기반하여 제2 동기화 레지 스터의 값을 제2 값으로 재설정하도록 구성된다. 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 이벤 트가 발생함을 지시하는 데 사용되며, 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 레지스터의 가 상 주소를 포함한다. 제5 프로세서는 제3 NPU를 포함한다. 제2 동기화 레지스터의 값은 제1 값 또는 제2 값을 포함한다. 제1 값은 제2 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 제2 동기화 이벤트 가 발생함을 지시하는 데 사용된다. 본 출원의 실시예의 제11 측면에 따르면, 전자 디바이스가 제공된다. 전자 디바이스는 메모리 및 제4 측면, 제5 측면 또는 제6 측면 중 어느 하나에 따른 동기화 장치를 포함한다. 본 출원의 실시예의 제12 측면에 따르면, 칩이 제공된다. 칩은 제1 측면에 따른 제1 프로세서 및 인터페이스 회 로를 포함한다. 제1 프로세서는 인터페이스 회로를 통해 다른 장치와 통신하여 제1 측면에 따른 방법을 구현한 다. 본 출원의 실시예의 제13 측면에 따르면, 칩이 제공된다. 칩은 제1 측면에 따른 제1 프로세서 및 제2 프로세서 그리고 인터페이스 회로를 포함한다. 제1 프로세서는 인터페이스 회로를 통해 제2 프로세서와 통신하여 제1 측 면에 따른 방법을 구현한다. 본 출원의 실시예의 제14 측면에 따르면, 칩이 제공된다. 칩은 제1 측면에 따른 제1 프로세서, 제2 프로세서 및 제3 프로세서 그리고 인터페이스 회로를 포함한다. 제1 프로세서, 제2 프로세서 및 제3 프로세서는 인터페이스 회로를 통해 서로 통신하여 제1 측면에 따른 방법을 구현한다. 본 출원의 실시예의 제15 측면에 따르면, 칩이 제공된다. 칩은 제2 측면 또는 제3 측면에 따른 제4 프로세서 및 제5 프로세서 그리고 인터페이스 회로를 포함한다. 제4 프로세서는 인터페이스 회로를 통해 제5 프로세서와 통신하여 전술한 측면 중 어느 하나에 따른 방법을 구현한다. 본 출원의 실시예의 제16 측면에 따르면, AI 서버가 제공된다. AI 서버는 CPU 및 하나 이상의 AI 가속기를 포함 한다. CPU는 전술한 측면 중 어느 하나에 따른 제1 프로세서이고, 하나 이상의 AI 가속기는 전술한 측면 중 어 느 하나에 따른 제2 프로세서 또는 제3 프로세서 중 적어도 하나를 포함한다. 본 출원의 실시예의 제17 측면에 따르면, AI 서버가 제공된다. AI 서버는 CPU 및 하나 이상의 AI 가속기를 포함 한다. CPU는 전술한 측면 중 어느 하나에 따른 제4 프로세서이고, AI 가속기는 전술한 측면 중 어느 하나에 따 른 제5 프로세서이다. 본 출원의 실시예의 제18 측면에 따르면, AI 클러스터가 제공된다. AI 클러스터는 복수의 AI 서버를 포함하고, AI 서버는 CPU와 하나 이상의 AI 가속기를 포함한다. CPU는 전술한 측면 중 어느 하나에 따른 제1 프로세서를 포함하고, AI 가속기는 전술한 측면 중 어느 하나에 따른 제2 프로세서 또는 제3 프로세서 중 적어도 하나를 포 함한다. 본 출원의 실시예의 제19 측면에 따르면, AI 클러스터가 제공된다. AI 클러스터는 복수의 AI 서버를 포함하고, AI 서버는 CPU와 하나 이상의 AI 가속기를 포함한다. CPU는 전술한 측면 중 어느 하나에 따른 제4 프로세서를 포함하고, AI 가속기는 전술한 측면 중 어느 하나에 따른 제5 프로세서를 포함한다. 본 출원의 실시예의 제20 측면에 따르면, 통신 시스템이 제공된다. 통신 시스템은 AI 가속기, 제11 측면에 따른 AI 서버, 제12 측면에 따른 AI 서버, 제13 측면에 따른 AI 클러스터, 또는 제14 측면에 따른 AI 클러스터 중 적 어도 하나를 포함한다. AI 가속기는 전술한 측면 중 어느 하나에 따른 제2 프로세서, 제3 프로세서, 또는 제5 프로세서 중 적어도 하나를 포함한다. 본 출원의 실시예의 제21 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되고(deployed), API는 동기화 이벤트에 대한 동기화 객체 를 생성하도록 구성된다. 선택적으로, API는 NotifyCreat(deviceID, notify)일 수 있으며, 입력 deviceID는 AI 가속기의 ID이고 출력 notify는 동기화 객체이다. 본 출원의 실시예의 제22 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되며, API는 동기화 이벤트에 대응하는 대기 태스크를 전달 하도록 구성된다. 선택적으로, API는 NotifyWait(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에 대응하는 동기화 이벤트가 발생하기를 대기하도록 구성된다. 본 출원 실시예의 제23 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되며, API는 동기화 이벤트에 대응하는 기록 태스크를 전달 하도록 구성된다. 선택적으로, API는 NotifyRecord(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에 대응하는 동기화 이벤트의 발생을 설정하도록 구성된다. 본 출원의 실시예의 제24 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되며, API는 동기화 객체의 글로벌 이름을 설정하도록 구성 된다. 선택적으로, API는 IpcSetNotifyName(notify, name)일 수 있으며 동기화 객체 notify의 글로벌 이름을 설정하도록 구성된다. 본 출원 실시예의 제25 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되고, API는 동기화 객체를 열도록 구성된다. 선택적으로, API는 IpcOpenNotify(notify, name)일 수 있으며, 동기화 객체의 글로벌 이름 name에 기반하여 동기화 객체 notify를 열도록 구성된다. 본 출원의 실시예의 제26 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되며, API는 동기화 객체에 대응하는 레지스터의 가상 주소 를 획득하도록 구성된다. 선택적으로, API는 NotifyGetAddr(notify, addr)일 수 있으며, 여기서 입력은 동기화 객체 notify이고, 출력은 동기화 객체 notify에 대응하는 동기화 레지스터의 가상 주소이다. 본 출원의 실시예의 제27 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되고, API는 동기화 레지스터를 해제하도록 구성된다. 선택 적으로, API는 NotifyDestroy(notify)일 수 있으며, 인터페이스는 동기화 객체 notify를 파기하고, 동기화 객체에 대응하는 동기화 레지스터를 해제하도록 구성될 수 있다. 본 출원의 실시예의 제28 측면에 따르면, 애플리케이션 프로그래밍 인터페이스(application programming interface, API)가 제공된다. API는 프로세서에 배치되며, API는 동기화 이벤트에 대응하는 RDMA 태스크를 전달 하도록 구성된다. 선택적으로, API는 RDMAsend(addr, 1)일 수 있으며, 제2 값 1을 가상 주소 addr에 기록하기를 지시하도록 구성된다."}
{"patent_id": "10-2023-7035925", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음은 본 출원 실시예의 첨부 도면을 참조하여 본 출원 실시예의 기술적 솔루션을 설명한다. 본 출원에서 \"적 어도 하나\"는 하나 이상을 의미하고, \"복수\"는 둘 이상을 의미한다. \"및/또는\"은 연관된 객체 사이의 연관 관계 만을 기술하며, 세 가지 관계가 있을 수 있음을 나타낸다. 예를 들어, A 및/또는 B는 A만 존재하는 경우, A와 B 가 모두 존재하는 경우, B만 존재하는 경우인 세 가지 경우를 지시할 수 있다. 문자 \"/\"는 일반적으로 연관된 객체 간의 \"또는\" 관계를 지시한다. \"다음 항목(조각(piece)) 중 적어도 하나\" 또는 이와 유사한 표현은 단수 항목(조각) 또는 복수 항목(조각)의 조합을 포함하여, 이러한 항목의 모든 조합을 의미한다. 예를 들어, a, b 또는 c 중 적어도 하나는 a, b, c, a 및 b, a 및 c, b 및 c 또는 a, b 및 c를 지시할 수 있으며, 여기서 a, b 및 c는 단수 또는 복수일 수 있다. 또한 본 출원의 실시예에서의 솔루션을 명확하게 설명하기 위해, 본 출원의 실시예에서는 \"제1\", \"제2\" 등의 용어를 사용하여 기본적으로 동일한 기능이나 목적을 제공하는 동일한 항목 또 는 유사한 항목을 구별한다. 당업자는 \"제1\" 및 \"제2\"와 같은 용어가 수량 및 실행 시퀀스를 제한하지 않는다는 것을 이해할 수 있다. 예를 들어, 본 출원의 실시예에서 제1 프로세서의 \"제1\"과 제2 프로세서의 \"제2\"는 서로 다른 프로세서를 구별하는 데에만 사용된다. 본 출원의 실시예에서 \"제1\", \"제2\"와 같은 설명은 단지 설명된 객 체를 지시하고 구별하기 위해 사용된 것일 뿐, 시퀀스를 나타내지 않고, 본 출원의 실시예에서 디바이스의 수량 에 대한 구체적인 제한을 지시하지 않으며, 본 출원의 실시예에 대한 어떠한 제한도 구성하지 않는다. 본 출원에서, \"예를 들어\" 또는 \"~와 같은\"이라는 단어는 예, 예시 또는 설명을 제공하는 것을 나타내는 데 사 용된다는 점에 유의해야 한다. 본 출원에서 \"예\" 또는 \"예를 들어\"로 설명된 임의의 실시예 또는 설계 방식은 다른 실시예 또는 설계 방식보다 더 바람직하거나 더 많은 이점을 갖는 것으로 설명되어서는 안 된다. 정확히말하면, \"예\", \"예를 들어\" 등의 단어를 사용하는 것은 관련된 개념을 특정한 방식으로 제시하려는 의도이다. 인공 지능 시나리오(예: 신경망 트레이닝)에서는 필요한 컴퓨팅 파워를 제공하도록 클러스터를 형성하기 위해 복수의 AI 서버가 필요한 경우가 많다. 일반적으로 AI 서버에는 하나 이상의 AI 가속기가 포함될 수 있다. 컴퓨 팅 디바이스로서, AI 가속기는 지능형 컴퓨팅이나 다른 데이터 집약적이거나 센서 중심적인 태스크에 사용되는 기계 학습 프로세스나 알고리즘과 같은 전용 태스크를 가속화하는 일종의 마이크로프로세서일 수 있으며, 마이 크로프로세서의 유형에 관련된 명령어 세트를 더 포함할 수 있다. 전용 태스크는 AI 처리 예를 들어, 인공 신경 망, 기계 학습(machine learning, ML) 트레이닝, ML 최적화/학습, 추론, 분류, 시각적 데이터 처리, 네트워크 데이터 처리, 객체 검출, 규칙 분석, 콘텐츠 처리 또는 다른 연산을 포함할 수 있다. AI 가속기는 신경망 처리 유닛(neural-network processing unit, NPU)일 수 있으며, 그래픽 처리 유닛(graphics processing unit, GPU), 디지털 신호 프로세서(digital signal processor, DSP), 시스템 온 칩(system on chip, SOC), 필드 프로그래밍 가능 게이트 어레이(Field-Programmable Gate Array, FPGA), 애플리케이션 특정 집적 회로(application- specific integrated circuit, ASIC) 등 중 하나 이상을 포함할 수 있다. AI 가속기는 전용 태스크를 완료하기 위해 가중치, 편향, 트레이닝 데이터, 코드 등을 로딩하여 관련 AI 명령어 세트를 실행할 수 있다. 본 출원의 실시예에서는 AI 가속기의 구체적인 형태가 제한되지 않는다. 이하의 실시예에서는 AI 가속기가 NPU인 예를 사 용하여 설명한다. 도 1a에 도시된 바와 같이, 신경망의 트레이닝 프로세스는 일반적으로 복수의 반복(iteration)을 포함하며, 각 반복은 순방향 계산(forward calculation), 역방향(backward) 계산 및 그레이디언트 수렴(gradient convergence)의 세 페이즈(phase)를 포함한다. 각 AI 가속기는 순방향 계산과 역방향 계산을 독립적으로 수행한 다. 계산된 그레이디언트는 복수의 AI 가속기에서 수렴되어야 한다. 역방향 계산은 일반적으로 에러(error)의 역전파이다. 따라서 에러(신경망의 인식값과 대응하는 모니터링 데이터의 차이)를 획득한 후 그레이디언트 하강 법에 따라 신경망의 가중치를 조정한다. 따라서 역방향 계산은 '에러값을 구하는 프로세스'와 '에러값에 기반하 여 역전파를 수행하는 프로세스'를 포함하며, 후자의 프로세스(에러 역전파 프로세스)는 그레이디언트에 기반하 여 신경망의 계층간 가중치를 조정하는 프로세스를 포함한다. 현재 일반적인 AI 모델(예를 들어, 이미지 인식에 사용되는 콘볼루셔널 신경망)은 대개 복수의 뉴런 '레이어(layer)'를 포함하며, 역전파 프로세스는 신경망의 출 력 레이어에서 입력 레이어로 에러 값을 순차적으로 역전파하는 것이다. 역전파 프로세스에서, 에러값에 기반하 여 가중치 파라미터의 그레이디언트를 계산하고, 가중치 파라미터의 그레이디언트 방향에 기반하여 신경망의 가 중치를 추가로 업데이트한다. 따라서 역방향 계산 프로세스에서, 일부 뉴런 계층의 그레이디언트 값을 계산한 후 그레이디언트 수렴이 시작될 수 있다. 예를 들어, 100-레이어 신경망의 경우, 100번째~80번째 레이어의 그레 이디언트 계산이 완료된 후 그레이디언트 수렴이 시작될 수 있다. 이러한 방식으로, 모든 역방향 계산이 완료된 후, 나머지 데이터에 대해 그레이디언트 수렴을 수행하는 시간이 전체 데이터에 대해 그레이디언트 수렴을 수행 하는 시간보다 짧아지므로, 트레이닝 효율이 향상될 수 있다. 전술한 순방향 계산 및 역방향 계산 프로세스는 각 AI 가속기에 의해 실행된다. 그레이디언트 수렴은 주로 AI 서버에서 복수의 AI 가속기 간 데이터 전송, AI 서버 간 네트워크 전송, AI 가속기 간 동기 대기, AI 가속기 간 그레이디언트 데이터 누적 등을 포함한다. 그레이디언트 수렴은 AI 가속기의 컴퓨팅 유닛의 참여를 요구하지 않 는다. 따라서 그레이디언트 수렴 중에 AI 가속기의 컴퓨팅 디바이스는 유휴 모드에 있다. 예를 들어, 도 1a에 도시된 바와 같이, AI 가속기는 T0 순간(moment)부터 T1 순간까지 순방향 계산을 수행하고, T1 순간부터 T2 순간까지 역방향 계산을 수행한다. 역방향 계산 프로세스에서, 트레이닝 효율을 높이기 위해, T1 순간부터 T4 순간까지 일부 데이터를 계산한 후, T4 순간부터 그레이디언트 수렴을 수행할 수 있다. 구체적 으로, T4 순간부터 T2 순간까지 역방향 계산과 그레이디언트 수렴 1이 동시에 수행된다. 역방향 계산이 완료된 후, T2 순간부터 T3 순간까지 나머지 데이터에 대한 그레이디언트 수렴만 수행된다. 따라서 T0 순간부터 T2 순 간까지가 계산 지속 기간(duration)이고, AI 가속기의 컴퓨팅 유닛은 T2 순간부터 T3 순간까지 순방향 계산이나 역방향 계산을 수행하지 않으며 유휴 모드이다. AI 클러스터에 대해서는 그레이디언트 수렴만 수행되기 때문에, T2 순간부터 T3 순간까지를 그레이디언트 수렴 시간이라고도 할 수 있다. 예를 들어, 전술한 그래디언트 수렴 프로세스에서, All-reduce 알고리즘이 사용될 수 있다. All-reduce 알고리 즘은 서로 다른 AI 가속기의 데이터를 효율적으로 통합한 후, 그 결과를 각 AI 가속기에 분배하는 데 사용되는 알고리즘의 일종이다. 그레이디언트 수렴 성능은 클러스터 트레이닝 성능을 평가하는 핵심 팩터이다. 그래디언트 수렴 시간이 짧을수 록; 클러스터 선형성이 높아진다. 클러스터 선형성 L은 다음 수식을 사용하여 계산될 수 있다:L = (계산 지속 기간)/(계산 지속 기간 + Tidle) Tidle은 AI 가속기의 컴퓨팅 유닛이 유휴 모드에 있는 시간이며, 즉 Tidle은 그레이디언트 수렴 시간(예를 들어, All-reduce 시간)이다. 그레이디언트 수렴 시간이 길수록 AI 가속기의 컴퓨팅 유닛이 유휴 모드에 있는 시간이 길고 클러스터 선형성 L이 낮다는 것을 지시한다. 그레이디언트 수렴 시간이 짧을수록 AI 가속기의 컴퓨팅 유닛 이 유휴 모드에 있는 시간이 짧고 클러스터 선형성 L이 높다는 것을 지시한다. 예를 들어, 도 1a에 도시된 바와 같이 T2 순간부터 T3 순간까지 수행되는 그레이디언트 수렴 2는 AI 가속기의 컴퓨팅 유닛의 참여를 요구하지 않기 때문에, AI 가속기의 컴퓨팅 유닛은 유휴 모드이다. 달리 말하면, 그레이 디언트 수렴 시간은 T2 순간부터 T3 순간까지이다. 따라서 T2 순간부터 T3 순간까지의 지속 기간이 짧을수록 클 러스터 선형성이 높음을 지시하고, T2 순간부터 T3 순간까지의 지속 기간이 길수록 클러스터 선형성이 낮다는 것을 지시한다. 따라서 그레이디언트 수렴 동안 동기화 전송 및 동기화 대기 시간을 줄여서 클러스터 선형성을 향상시킬 수 있다. 예를 들어 클러스터의 그래디언트 수렴 알고리즘은 단일 AI 서버의 링(Ring) 알고리즘이다. AI 서버는 예를 들 어 GPU 0부터 GPU 4까지 5개의 AI 가속기를 포함할 수 있다. 링 알고리즘에는 감소 산란 페이즈(reduce-scatter phase)와 전체 수집 페이즈(all-gather phase)의 두 페이즈가 포함된다. 감소 산란 페이즈에서, GPU 간에 데이 터가 교환되므로 각 GPU는 최종 결과의 일부를 최종적으로 획득한다. 전체 수집 페이즈에서, GPU는 이러한 블록 을 교환하므로, 모든 GPU가 최종적으로 완성된 최종 결과를 획득한다. 선택적으로, 링 알고리즘에서, 각 GPU는 하나의 왼쪽 이웃과 하나의 오른쪽 이웃을 가지며, 각 GPU는 데이터를 GPU의 오른쪽 이웃에만 송신하고 GPU의 왼쪽 이웃으로부터 데이터를 수신한다. 예를 들어, 도 1b에 도시된 바와 같이, AI 서버는 각각 GPU 0부터 GPU 4까지인 5개의 GPU를 포함하고, 각 GPU는 하나의 왼쪽 이웃과 하나의 오른 쪽 이웃을 갖는다. GPU 0은 GPU 0의 오른쪽 이웃 GPU 1로만 데이터를 송신하고 GPU 0의 왼쪽 이웃 GPU 4로부터 데이터를 수신한다. GPU 1은 GPU 1의 오른쪽 이웃 GPU 2로만 데이터를 송신하고 GPU 1의 왼쪽 이웃 GPU 0으로부 터 데이터를 수신한다. GPU 2는 GPU 2의 오른쪽 이웃 GPU 3에만 데이터를 송신하고 GPU 2의 왼쪽 이웃 GPU 1로 부터 데이터를 수신한다. GPU 3은 GPU 3의 오른쪽 이웃 GPU 4로만 데이터를 송신하고 GPU 3의 왼쪽 이웃 GPU 2 로부터 데이터를 수신한다. GPU 4는 GPU 4의 오른쪽 이웃 GPU 0에만 데이터를 송신하고 GPU 4의 왼쪽 이웃 GPU 3으로부터 데이터를 수신한다. 예를 들어, AI 서버에는 각각 GPU 0부터 GPU 4까지인 총 5개의 GPU가 포함되어 있으며, 각 GPU는 데이터를 상대 적으로 작은 5개의 데이터 블록으로 나눈다. 도 1b를 참조하면, 도 1c 내지 도 1g에 도시된 바와 같이, 감소 산 란 페이즈에서 각 GPU는 감소-산란을 4번 반복한다. 각 반복에서 각 GPU는 데이터 블록 중 하나를 GPU의 오른쪽 이웃에 송신하고 GPU의 왼쪽 이웃으로부터 하나의 데이터 블록을 수신하여 이 데이터 블록을 데이터 블록들 중 다른 데이터 블록에 누적한다. 각 반복마다 서로 다른 데이터 블록이 송신되고 수신된다. 예를 들어, GPU 0은 데이터 블록 a0을 GPU 0의 오른쪽 이웃 GPU 1에 송신하고, GPU 0의 왼쪽 이웃 GPU 4로부터 데이터 블록 e4를 수 신하여 데이터 블록 e4를 데이터 블록 e0에 누적하며; GPU 1은 데이터 블록 b1을 GPU 1의 오른쪽 이웃 GPU 2에 송신하고, GPU 1의 왼쪽 이웃 GPU 0으로부터 데이터 블록 a0을 수신하여 데이터 블록 a0을 데이터 블록 a1에 누 적하는 등이다. 도 1c 내지 도 1g에 도시된 바와 같이, 감소 산란 페이즈에서는 GPU 0 내지 GPU 4가 각각 4번의 반복을 수행한 후, 각 GPU의 데이터 블록별로 최종 값을 획득할 수 있다. All-reduce를 구현하기 위해 도 1b를 참조하면, 도 1h 내지 도 1l에 도시된 바와 같이, 전체 수집 페이즈에서, GPU 0 내지 GPU 4 각각은 다시 4번의 반복을 수행한다. 그러나 각 반복에서, GPU는 데이터 블록 중 하나를 GPU 의 오른쪽 이웃에 송신하고 GPU의 왼쪽 이웃으로부터 데이터 블록을 수신하여 이 데이터 블록으로 데이터 블록 들 중 다른 데이터 블록을 덮어쓴다. 예를 들어, GPU 0은 데이터 블록 b2+b1+b3+b4+b0을 GPU 0의 오른쪽 이웃 GPU 1에 송신하고, GPU 0의 왼쪽 이웃 GPU 4로부터 데이터 블록 a1+a0+a2+a3+a4를 수신하여 데이터 블록 a0을 데이터 블록 a1+a0+a2+a3+a4로 덮어쓰고; GPU 1은 데이터 블록 c3+c2+c4+c0+c1을 GPU 1의 오른쪽 이웃 GPU 2에 송신하고, GPU 1의 왼쪽 이웃 GPU 0으로부터 데이터 블록 b2+b1+b3+b4+b0를 수신하여 데이터 블록 b1을 데이터 블록 b2+b1+b3+b4+b0으로 덮어쓰는 등이다. 도 1h 내지 도 1l에 도시된 바와 같이, 전체 수집 페이즈에서, GPU 0 내지 GPU 4 각각은 4번의 반복을 수행한 후, 모든 GPU는 전체 어레이에 대한 전체 누적 값(full cumulative value)을 갖는다. 도 1b, 도 1c ~ 도 1l로부터 그레이디언트 수렴 알고리즘에서는 동기화 메커니즘이 GPU 간에 필요하므로, All- reduce를 통해 획득한 결과가 정확함을 알 수 있다. 예를 들어 GPU 1은 GPU 0이 a0을 GPU 1에 전달한(transfer) 후에야 a0+a1을 GPU 2에 전달할 수 있다. GPU 1이 미리 결과를 GPU 2에 전달하면, All-reduce 결과 가 정확하지 않다. GPU 1이 결과를 GPU 2에 송신하는 것을 지연시키면, All-reduce는 상대적으로 더 오랜 시간 을 필요로 하므로 GPU의 컴퓨팅 파워를 낭비하게 된다. 따라서 AI 알고리즘의 정확한 실행을 보장하고 AI 가속 기의 컴퓨팅 파워를 향상시키기 위해서는 적절한 동기화 메커니즘이 필요하다. 본 출원의 일부 실시예에서, AI 트레이닝 시나리오에서 알고리즘이 정확하게 실행되도록 보장하기 위해 동기화 메커니즘이 필요하다는 것을 보여주기 위해, 단일 AI 서버에서의 링 알고리즘이 예로서 사용됨을 이해할 것이다. 본 출원의 실시예에서는 동기화 메커니즘의 특정 애플리케이션 시나리오가 제한되지 않는다. 복수의 AI 서버가 클러스터를 형성하여 AI 트레이닝을 수행하는 실제 애플리케이션에서, AI 가속기 내, AI 서버의 서로 다 른 AI 가속기 간, 그리고 AI 서버 간 동기화 전송 및 동기화 대기 시간을 줄이기 위해 적절한 동기화 메커니즘 을 제공해야 한다. 하나의 동기화 메커니즘은 인트라 프로세스 동기화와 인터 프로세스 동기화가 상호 배타적임을 보장하기 위해 세마포어(semaphore) 메커니즘을 사용하는 것이다. 하지만 이 방법은 표준 프로세서 아키텍처(예를 들어, X86 또는 ARM)에서만 동기화를 지원하며, AI 가속기에 탑재된 칩 간 동기화는 지원하지 않으며, AI 서버 간 동기화 는 지원하지 않는다. 또 다른 동기화 방법으로는 Nvidia의 컴퓨트 통합 디바이스 아키텍처(compute unified device architecture, CUDA)에서 제공하는 이벤트 동기화 메커니즘이 있다. 이벤트 동기화 메커니즘은 인트라 프로세스 동기화, 인터 프로세스 동기화, 그래픽 처리 유닛(graphics processing unit, GPU)에서의 인트라 칩 동기화, GPU 간의 인터 칩 동기화에 사용된다. 그러나 이 이벤트 메커니즘은 AI 서버 간 동기화를 지원하지 않으며, GPU 칩 간 동기화 를 수행할 때 시간 비용이 상대적으로 높으며, 10μs가 필요할 수 있다. 또한 인터 프로세스 동기화를 위해 이 벤트 메커니즘을 사용할 때, 애플리케이션 프로그래밍 인터페이스(application program interface, API) 설계가 상대적으로 복잡하고 개발자가 사용하기 불편하다. 본 출원의 실시예는 동기화 방법을 제공한다. 이 방법은 AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간 그리 고 AI 서버 간의 동기화를 구현할 수 있다. 또한 동기화 비용이 상대적으로 낮고, API 설계가 상대적으로 단순 하여 개발자가 사용하기 편리하다. 본 출원의 일부 실시예에서 제공되는 동기화 방법은 컴퓨팅 아키텍처에 적용될 수 있으며, 컴퓨팅 아키텍처는 AI 서버의 컴퓨팅 아키텍처일 수 있다. AI 서버의 컴퓨팅 아키텍처는 이기종 컴퓨팅 하드웨어 아키텍처이며, 중 앙 처리 유닛((central processing unit, CPU) 및 하나 이상의 AI 가속기를 포함한다. CPU는 AI 컴퓨팅 태스크 를 AI 가속기에 송신할 수 있다. AI 가속기는 CPU가 송신한 AI 컴퓨팅 태스크를 수신한 후, AI 컴퓨팅 태스크를 실행하고 실행 결과를 CPU에 보고한다. 도 2a는 본 출원의 일부 실시예에 따른 AI 가속기이다. 도 2a에 도시된 바와 같이, AI 가속기는 컨트롤러, 연산 로직(operation logic) 유닛 및 복수의 동기화 레지스터를 포함한다. 컨트롤러는 CPU가 송신한 AI 컴퓨팅 태스크를 수신하고, 컴퓨팅 태스크의 실행 결과를 CPU에 보고하도록 구성된 다. 연산 로직 유닛은 컨트롤러에 의해 전달된 컴퓨팅 태스크를 실행하고, 각 컴퓨팅 태스크의 실행 결과를 컨트롤 러로 반환하도록 구성된다. 도 2a에 도시된 바와 같이, AI 가속기는 복수의 동기화 레지스터를 포함하며, 복수의 동기화 레지스터는 각각 Reg 0, Reg 1,..., Reg n이다. 각 동기화 레지스터는 하나의 동기화 이벤트에 대응하도록 구성되며, 동기화 레 지스터의 서로 다른 값이 동기화 레지스터에 대응하는 동기화 이벤트가 발생하는지를 지시하는 데 사용될 수 있 다. 선택적으로, 도 2a에 도시된 바와 같이, 복수의 동기화 레지스터는 AI 가속기의 컨트롤러에 배치될 수 있다. 예를 들어, 각 동기화 레지스터의 값은 제1 값과 제2 값을 포함할 수 있다. 제1 값은 동기화 레지스터에 대응하 는 동기화 이벤트가 발생하지 않음을 지시하는 데 사용되고, 제2 값은 동기화 레지스터에 대응하는 동기화 이벤 트가 발생함을 지시하는 데 사용된다. 제1 값과 제2 값은 서로 다른 값이다. 본 출원의 실시예에서는 제1 값과 제2 값의 구체적인 값이 제한되지 않는다. 이하의 실시예에서는 제1 값이 0이고, 제2 값이 1인 예를 들어 설명 한다. 선택적으로, 동기화 레지스터에 대응하는 동기화 이벤트는 AI 가속기 내에서 발생할 수도 있고, AI 서버의 서로 다른 AI 가속기 간에 발생할 수도 있고, 서로 다른 AI 서버 간에 발생할 수도 있다(각 AI 서버는 적어도 하나의 AI 가속기를 포함함). 동기화 레지스터에 대응하는 동기화 이벤트가 AI 가속기에서 발생할 때, AI 가속기는 동 기화 레지스터의 값에 기반하여 동기화 이벤트가 발생하는지를 판정하여, AI 가속기 내에서 동기화를 구현할 수 있음을 알 수 있다. 동기화 레지스터에 대응하는 동기화 이벤트가 AI 서버의 서로 다른 AI 가속기 간에 발생할 때, AI 가속기는 동기화 레지스터의 값에 기반하여 동기화 이벤트가 발생하는지를 판정하여, AI 서버에서 서로 다른 AI 가속기 간의 동기화를 구현할 수 있다. 동기화 레지스터에 대응하는 동기화 이벤트가 서로 다른 AI 서 버 간에 발생할 때, AI 서버의 AI 가속기는 동기화 레지스터의 값에 기반하여 동기화 이벤트가 발생하는지를 판 정하여 AI 가속기 간 동기화를 구현할 수 있다. 선택적으로, 각 AI 가속기에 배치된 동기화 레지스터의 특정 수량은 본 출원의 실시예에서 제한되지 않는다. 예 를 들어 AI 가속기는 동시에 최대 1024개의 동기화 이벤트를 지원한다. AI 가속기에는 1024개의 동기화 레지스 터가 배치될 수 있으며, 하나의 동기화 레지스터는 하나의 동기화 이벤트에 대응할 수 있다. 본 출원의 실시예에서 제공되는 AI 가속기의 경우, 복수의 동기화 레지스터가 AI 가속기에 배치되고, 각 동기화 레지스터가 하나의 동기화 이벤트에 대응하도록 구성되므로, AI 가속기가 동기화 레지스터의 값에 기반하여, 동 기화 레지스터에 대응하는 동기화 이벤트가 발생하는지를 판정할 수 있다는 것을 이해할 수 있다. 이러한 방식 으로, AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, AI 서버 간의 동기화가 구현될 수 있다. 본 출원의 실시예에서 제공되는 동기화 방법은 도 2b에 도시된 AI 서버에 적용될 수 있다. 도 2b에 도시된 바와 같이, AI 서버는 CPU 및 복수의 AI 가속기를 포함할 수 있다. 각 AI 가속기는 동기화 레지스터 그룹을 포함하며, 각 동기화 레지스터는 하나의 동기화 이벤트에 대응할 수 있다. 동기화 레지스터의 서로 다른 값이 동기화 이벤트가 발생하는지를 지시하는 데 사용될 수 있다. 도 2b에 도시된 바와 같이, CPU 내의 드라이버는 AI 가속기에 대한 드라이버 기능을 제공하도록 구성된다. 사용 자 모드 드라이버 레이어 런타임(runtime)은 애플리케이션(application, App)에 배포되고, 런타임은 AI 가속기 의 사용자 모드 드라이버 기능을 제공하도록 구성된다. 예를 들어 런타임에는 복수의 API가 포함되어 있다. APP 를 실행할 때, CPU는 소프트웨어와 하드웨어 간의 상호 작용을 구현하기 위해 서로 다른 API 인터페이스를 호출 할 수 있다. CPU는 API를 호출하는 것에 의해 AI 컴퓨팅 태스크를 AI 가속기에 송신할 수 있다. AI 가속기의 컨 트롤러는 CPU가 송신한 AI 컴퓨팅 태스크를 수신한 후, AI 컴퓨팅 태스크를 실행하고 실행 결과를 CPU에 보고한 다. 선택적으로, APP의 사용자 모드 드라이버 레이어 런타임이 API를 제공한다. 상위 레이어 서비스 APP는 AI 모델 (컴퓨팅 그래프)을 분할하고, AI 모델을 AI 가속기에서 처리할 수 있는 스트림, 태스크, 이벤트와 같은 태스크 로 변환하고, 태스크를 런타임에 의해 제공되는 API를 통해 AI 가속기에 전달할 수 있다. 예를 들어, 태스크는 컴퓨팅 태스크이며 일반적으로 AI 가속기의 연산 로직 유닛에 의해 처리된다. 이벤트는 이벤트 동기화 메커니즘 이며 일반적으로 컨트롤러에 의해 처리된다. AI 가속기의 컨트롤러는 실행을 위해 복수의 스트림의 태스크를 동 시에 스케줄링할 수 있지만, 동일한 스트림의 태스크는 시퀀스대로만 실행될 수 있다. 선택적으로, AI 서버가 복수의 AI 가속기를 포함할 때, 서로 다른 AI 가속기에 배치된 동기화 레지스터의 수량 은 동일하거나 상이할 수 있다. 이는 본 출원의 실시예에 제한되지 않는다. 도 2b에서, AI 서버가 m+1개의 AI 가속기를 포함하고, AI 가속기 0과 AI 가속기 m 모두에 n개의 동기화 레지스터가 배치된 예를 예시적으로 사용 한다. 선택적으로, AI 서버가 복수의 AI 가속기를 포함할 때, 각각의 AI 가속기에는 복수의 동기화 레지스터가 배치될 수 있다. AI 서버의 서로 다른 AI 가속기에 배치된 동기화 레지스터의 물리적 주소는 글로벌 어드레싱 방식으로 주소 지정될 수 있다. 예를 들어, AI 서버의 동기화 레지스터는 AI 가속기의 식별자(identity, ID)와 오프셋에 기반하여 또는 다른 방식으로 글로벌적으로 주소 지정될 수 있다. AI 서버에서 복수의 AI 가속기의 동기화 레지 스터가 글로벌적으로 주소 지정되기 때문에, 각 AI 가속기의 컨트롤러는 AI 서버에서 다른 AI 가속기의 동기화 레지스터의 물리적 주소를 알게 될 수 있으며, 또한 물리적 주소를 사용하여 다른 AI 가속기의 동기화 레지스터 에 액세스할 수 있다. 예를 들어, AI 서버가 하나의 AI 가속기만 포함할 때, AI 가속기와 CPU는 하나의 칩에 통합될 수도 있고, 서로 다른 칩에 개별적으로 통합될 수도 있다. 컴퓨팅 아키텍처가 복수의 AI 가속기를 포함할 때, 복수의 AI 가속기 는 하나 이상의 칩에 통합되고, CPU는 다른 칩에 통합될 수도 있으며, CPU와 AI 가속기가 하나의 칩에 통합될 수도 있다. AI 서버에서 CPU와 AI 가속기를 포함하는 이종 컴퓨팅 하드웨어 형태는 본 출원의 실시예에서 제한되지 않으며, 여기서의 설명은 예이다. 본 출원의 실시예에서, 동기화 레지스터 그룹은 AI 서버의 AI 가속기에 배치되고, 각 동기화 레지스터는 하나의 동기화 이벤트에 대응할 수 있으므로, AI 가속기가 동기화 레지스터의 값에 기반하여, 동기화 레지스터에 대응 하는 동기화 이벤트가 발생하는지를 판정할 수 있다는 것을 이해할 수 있다. 이러한 방식으로, AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, AI 서버 간의 동기화가 구현될 수 있다. 도 2a 및 도 2b를 참조하여, 도 3은 본 출원의 실시예에 따른 동기화 방법을 도시한다. 이 방법은 다음 단계를 포함한다. S301: 제1 프로세서가 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성한다. 제1 프로세서는 AI 서버의 중앙 제어 유닛, 예를 들어 CPU일 수 있다. 제1 프로세서는 제1 CPU를 포함한다. 선택적으로, 단계(S301)에서 제1 프로세서가 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성하는 것은 다음 을 포함할 수 있다: 제1 프로세서가 제1 API를 호출하는 것에 의해 제2 프로세서에 포함된 복수의 동기화 레지 스터 중 제1 동기화 레지스터를 제1 동기화 이벤트에 할당하고, 제1 동기화 레지스터의 식별자를 제1 동기화 객 체에 저장한다. 제2 프로세서는 제2 NPU를 포함하고, 제2 프로세서는 제1 동기화 이벤트가 발생하기를 대기하는 NPU이다. 달리 말하면, 본 출원의 실시예에서 동기화 이벤트에 할당된 동기화 레지스터는 동기화 이벤트가 발생 하기를 대기하는 NPU의 동기화 레지스터이다. 제1 API는 동기화 이벤트에 대한 동기화 객체를 생성하도록 구성된다. 예를 들어, 제1 API는 NotifyCreat(deviceID, notify)일 수 있으며, 여기서 입력 deviceID는 AI 가속기의 ID이고, 출력 notify는 동 기화 객체이며, NotifyCreat 인터페이스는 동기화 객체를 생성하도록 구성된다. NotifyCreat 인터페이스의 deviceID는 제2 프로세서의 ID이다. 선택적으로, 제1 동기화 레지스터를 제1 동기화 이벤트에 할당할 때, 제1 프로세서는 추가로, 제1 동기화 레지 스터의 값을 제1 값으로 재설정할 수 있으므로, 제1 동기화 레지스터의 값이 제1 동기화 이벤트의 현재 상태에 대응한다. 제1 동기화 레지스터의 값을 제1 값으로 재설정하는 것은 다르게는 제1 동기화 레지스터의 값을 제1 값으로 설정하는 것일 수도 있다. 이는 본 출원의 실시예에 제한되지 않는다. 실제 애플리케이션에서, 동기화 레지스터의 값이 설정 방식 또는 재설정(Reset) 방식으로 변경될 수 있다. 선택적으로, 제1 프로세서는 AI 서버의 CPU일 수 있고, 제2 프로세서는 AI 서버의 AI 가속기일 수 있다. 제1 프 로세서와 제2 프로세서는 이종 컴퓨팅 아키텍처를 형성하고, AI 서버는 이종 서버일 수 있다. 예를 들어, 제1 프로세서는 AI 서버의 호스트 CPU일 수 있고, 제2 프로세서는 AI 서버의 NPU일 수 있다. 호스트 CPU는 제1 API 를 호출하는 것에 의해, 동기화 이벤트가 발생하기를 대기하는 NPU에 포함된 복수의 동기화 레지스터 중 제1 동 기화 레지스터를 제1 동기화 이벤트에 할당할 수 있다. 선택적으로, 제1 동기화 이벤트는 NPU에서 발생할 수도 있고, AI 서버의 서로 다른 NPU 간에 발생할 수도 있으 며, 서로 다른 AI 서버 간에 발생할 수도 있다. 이는 본 출원의 실시예에 제한되지 않는다. 예를 들어, 도 4는 AI 서버의 컴퓨팅 아키텍처 구조의 개략도이다. 도 4에 도시된 바와 같이, AI 가속기가 NPU 이고, AI 서버는 CPU와 2개의 NPU를 포함하며, 2개의 NPU는 각각 NPU 0과 NPU 1을 사용하는 예를 사용한다. CPU 는 컴퓨팅 태스크, 기록 태스크, 대기 태스크를 NPU 0과 NPU 1에 전달할 수 있다. 컴퓨팅 태스크(Task)는 연산 로직 유닛에 의해 처리되는 컴퓨팅 태스크이며, 기록(record) 태스크는 동기화 이벤트가 발생함을 지시하는 데 사용되고, 대기(wait) 태스크는 동기화 이벤트가 발생하기를 대기하는 데 사용된다. 예를 들어, AI 가속기에서 동기화 이벤트가 발생한다. 도 4를 참조하면, 도 5a에 도시된 바와 같이, NPU 0의 큐 (queue) 1은 NPU 0의 큐 0이 컴퓨팅 태스크 01의 실행을 완료한 후에만 컴퓨팅 태스크 12를 실행할 수 있다. 동 기화를 위해서는 NPU 0의 큐 1이 동기화 이벤트 1이 발생하기를 대기해야 하며, 동기화 이벤트 1은 NPU 0의 큐 0이 컴퓨팅 태스크 01의 실행을 완료하고 실행 결과를 송신하는 것이다. 동기화 이벤트 1이 발생하지 않을 때, NPU 0의 큐 1은 컴퓨팅 태스크 11을 실행한 후 계속 대기한다. 동기화 이벤트 1이 발생할 때(NPU 0의 큐 0이 컴 퓨팅 태스크 01의 실행을 완료하고 실행 결과를 송신함), NPU 0의 큐 0은 컴퓨팅 태스크 12를 계속해서 실행할 수 있다. 동기화 이벤트 1은 AI 가속기 NPU 0의 서로 다른 두 개의 큐 사이에서 발생하는 것으로 이해될 수 있 다. 또 다른 예로, AI 서버의 서로 다른 AI 가속기 간에 동기화 이벤트가 발생한다. 도 4를 참조하면, 도 5b에 도시 된 바와 같이, NPU 1의 큐 1은 NPU 0의 큐 2가 컴퓨팅 태스크 3n의 실행을 완료한 후에만 컴퓨팅 태스크 2n을실행할 수 있다. 동기화를 위해서는 NPU 1의 큐 1이 동기화 이벤트 2가 발생하기를 대기해야 하며, 동기화 이벤 트 2는 NPU 0의 큐 2가 컴퓨팅 태스크 3n의 실행을 완료하고 실행 결과를 송신하는 것이다. 동기화 이벤트 2가 발생하지 않을 때, NPU 1의 큐 1은 계속 대기한다. 동기화 이벤트 2가 발생할 때, NPU 1의 큐 1은 컴퓨팅 태스 크 2n을 계속 실행할 수 있다. 동기화 이벤트 2는 AI 서버의 서로 다른 AI 가속기 간(NPU 0과 NPU 1 사이)에서 발생하는 것으로 이해될 수 있다. 예를 들어, 동기화 이벤트 1의 경우, NPU 0의 큐 1은 동기화 이벤트 1이 발생하기를 대기한다. 따라서 CPU는 NPU 0에 포함된 복수의 동기화 레지스터 중 동기화 레지스터를 동기화 이벤트 1에 할당하고, 동기화 레지스터의 식별자를 동기화 객체 1에 저장할 수 있다. 동기화 객체 1은 notify 1로 표시될 수 있다. 동기화 이벤트 2의 경 우, NPU 1의 큐 1은 동기화 이벤트 2가 발생하기를 대기한다. 따라서 CPU는 NPU 1에 포함된 복수의 동기화 레지 스터 중 동기화 레지스터를 동기화 이벤트 2에 할당하고, 동기화 레지스터의 식별자를 동기화 객체 2에 저장할 수 있다. 동기화 객체 2는 notify 2로 표시될 수 있다. 선택적으로, 본 출원의 실시예에서는 동기화 레지스터 그룹이 각 NPU에 배치된다. 따라서 동기화가 수행되어야 한다고 결정될 때, APP는 NotifyCreat(deviceID, notify) 인터페이스를 호출하여, 하나의 동기화 레지스터를 동 기화 이벤트가 발생하기를 대기하는 NPU의 각 동기화 이벤트에 할당할 수 있다. 예를 들어, 도 5a에 도시된 동기화 이벤트 1의 경우, APP는 NotifyCreate API를 전달하고 NPU 0에 동기화 객체 notify 1을 생성하며, 런타임은 NPU 드라이버의 인터페이스를 호출하여 NPU 드라이버에게 NPU 0 상의 동기화 이 벤트에 대한 동기화 레지스터를 할당하도록 요청한다. 도 4에 도시된 바와 같이, NPU 드라이버는 NPU 0에서 복 수의 동기화 레지스터 중 동기화 레지스터 Reg 0을 할당하고, 동기화 레지스터 Reg 0의 식별자를 기록하며, 동 기화 레지스터의 값을 제1 값 0으로 재설정할 수 있다. NPU 드라이버는 동기화 레지스터 Reg 0의 ID를 런타임에 반환한다. 런타임은 동기화 객체 notify 1을 구성하고, 동기화 레지스터 Reg 0의 ID를 notify 1에 저장한 다음 notify 1을 APP에 반환한다. 또 다른 예를 들어, 도 5b에 도시된 동기화 이벤트 2의 경우, APP는 NotifyCreate API를 전달하고, NPU 1에 동 기화 객체 notify 2를 생성하며, 런타임은 NPU 드라이버의 인터페이스를 호출하여 NPU 드라이버에게 NPU 1 상의 동기화 이벤트에 대한 동기화 레지스터를 할당하도록 요청한다. 도 4에 도시된 바와 같이, NPU 드라이버는 NPU 1에서 복수의 동기화 레지스터 중 동기화 레지스터 Reg 1을 할당하고, 동기화 레지스터 Reg 1의 식별자를 기록 하며, 동기화 레지스터 Reg 1의 값을 제1 값 0으로 재설정할 수 있다. NPU 드라이버는 동기화 레지스터 Reg 1의 ID를 런타임에 반환한다. 런타임은 동기화 객체 notify 2를 구성하고, 동기화 레지스터 Reg 1의 ID를 notify 2 에 저장한 다음 notify 2를 APP에 반환한다. 선택적으로, 동기화 레지스터를 동기화 이벤트에 할당할 때, NPU 드라이버는 NPU에서 유휴 모드에 있는 동기화 레지스터를 동기화 이벤트에 할당할 수 있다. NPU에서 유휴 모드에 있는 동기화 레지스터는 다른 동기화 이벤트 와 연관되지 않은 동기화 레지스터이거나, 다른 동기화 이벤트와 연관되어 있었지만 재활용된 동기화 레지스터 (즉, 다른 동기화 이벤트 또는 동기화 객체와 연관이 해제된 동기화 레지스터)로 이해될 수 있다. 본 출원의 실시예에서 동기화 이벤트는 NPU에서 발생할 수도 있고, AI 서버의 서로 다른 NPU 간에 발생할 수도 있으며, 서로 다른 AI 서버의 NPU 간에 발생할 수도 있다(각 AI 서버는 적어도 하나의 NPU를 포함함). 본 실시 예에서, 도 5a의 동기화 이벤트 1이 NPU에서 발생하고, 도 5b의 동기화 이벤트 2가 AI 서버의 서로 다른 NPU 사 이에서 발생하는 예를 사용하여 설명한다. S302: 제2 프로세서가 제1 동기화 레지스터의 값에 기반하여 제1 동기화 이벤트가 발생하는지를 판정한다. 선택적으로, 제1 동기화 이벤트가 발생하는지를 지시하기 위해 제1 동기화 레지스터의 서로 다른 값이 사용된다. 따라서 제2 프로세서는 제1 동기화 레지스터의 값에 기반하여 다음의 두 가지 구현에서, 제1 동기화 이벤트가 발생하는지를 판정할 수 있다. 제1 구현에서, 단계(S302)는 다음을 포함할 수 있다: 제1 동기화 레지스터의 값이 제1 값일 때, 제2 프로세서는 제1 동기화 이벤트가 발생하지 않은 것으로 결정한다. 제2 프로세서는 제1 동기화 이벤트가 발생하기를 계속 대 기한다. 제2 프로세서는 제1 동기화 레지스터의 값이 제2 값이 될 때까지 제1 동기화 이벤트가 발생한 것으로 결정하고, 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정한다. 예를 들어, 제1 동기화 레지스터의 값이 제1 값이면, 제1 동기화 이벤트가 발생하지 않음을 지시한다. 이 경우, 제2 프로세서는 제1 동기화 이벤트가 발생하기를 계속 대기한다. 제1 동기화 레지스터의 값이 제2 값이 될 때까 지, 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정하고 후속 태스크를 실행하여 정확한 동기화를 보장한다. 선택적으로, 제1 동기화 레지스터의 값이 제1 값일 때, 제2 프로세서의 컨트롤러는 항상 제1 동기화 레지스터의 값을 확인한다. 제1 동기화 레지스터의 값이 0에서 1로 변경될 때, 제1 동기화 레지스터는 제2 프로세서에서의 동기화 레지스터이기 때문에, 제2 프로세서의 컨트롤러가 제1 동기화 레지스터의 값에서의 변경을 즉시 검출할 수 있다. 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정하고, 제1 동기화 레지스터를 0으로 클리어하 므로(clear), 제1 동기화 레지스터가 계속해서 동기화 작동을 수행할 수 있다. 제2 구현에서, 단계(S302)는 다음을 포함할 수 있다: 제1 동기화 레지스터의 값이 제2 값일 때, 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정하고, 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정 한다. 예를 들어, 제1 동기화 레지스터의 값이 제2 값이면, 제2 프로세서는 제1 동기화 이벤트가 발생한 것으로 결정 하며, 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정한다. 그런 다음, 제2 프로세서는 후속 태 스크를 계속 실행하여 정확한 동기화를 보장할 수 있다. 본 출원의 실시예에서 제공되는 동기화 방법에 따르면, 제1 동기화 이벤트에 대한 제1 동기화 객체가 생성되므 로, 제1 동기화 이벤트는 제1 동기화 레지스터에 대응할 수 있고, AI 가속기는 동기화 레지스터의 값에 기반하 여, 동기화 레지스터에 대응하는 동기화 이벤트가 발생하는지를 판정할 수 있다. 이러한 방식으로, AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간, 그리고 AI 서버 간의 동기화가 구현될 수 있다. 도 6은 본 출원의 실시예에 따른 동기화 방법이다. 도 6에 도시된 바와 같이, 이 방법은 다음 단계를 포함할 수 있다. S601: 제1 프로세서가 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성한다. 선택적으로, 제1 동기화 이벤트는 NPU에서 발생할 수도 있고, AI 서버의 서로 다른 NPU 간에 발생할 수도 있다. 단계(S601)의 구체적인 구현에 대해서는 단계(S301)를 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다 시 설명하지 않는다. S602: 제1 프로세서가 제2 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 대기 태스크를 제2 프로세 서에 송신한다. 제2 API는 동기화 이벤트에 대응하는 대기 태스크를 전달하도록 구성된다. 예를 들어, 제2 API는 NotifyWait(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에 대응하는 동기화 이벤트가 발생하기를 대기하도록 구성된다. 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 동기화 이벤트가 발생하기를 대기하는 데 사용되며, 제1 동기 화 이벤트에 대응하는 대기 태스크는 제1 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제1 큐 식별 자는 대기 태스크가 위치된 큐의 식별자이다. 달리 말하면, 제1 동기화 이벤트에 대응하는 대기 태스크는 제1 큐에 있는 태스크이다. 선택적으로, 제1 큐 식별자는 대기 태스크가 위치된 스트림의 식별자일 수 있다. 예를 들어, 도 4를 참조하면, 도 5a에 도시된 바와 같이, 동기화 이벤트 1의 경우, CPU는 NotifyWait(notify 1, queue 1)를 호출하는 것에 의해 대기(Wait) 태스크 1을 NPU 0에 전달하여, 큐 1에서 notify 1에 대응하는 동기화 이벤트 1이 발생하기를 대기하도록 NPU 0에게 지시한다. 또 다른 예를 들어, 도 4를 참조하면, 도 5b에 도시된 바와 같이, 동기화 이벤트 2의 경우, CPU는 NotifyWait(notify 2, 큐 1)를 호출하는 것에 의해 대기 태스크 2를 NPU 1에 전달하여, 큐 1에서 notify 2에 대응하는 동기화 이벤트 2가 발생하기를 대기하도록 NPU 1에게 지시한다. S603: 제2 프로세서가 제1 동기화 이벤트에 대응하는 대기 태스크를 수신한다. S604: 제2 프로세서가 제1 동기화 레지스터의 값에 기반하여 제1 동기화 이벤트가 발생하는지를 판정한다. 선택적으로, 제2 프로세서는 제1 동기화 이벤트에 대응하는 대기 태스크를 수신한 후, 대기 태스크에서 운반된 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레지스터의 값을 읽을 수 있다. 제1 동기화 레지스터의 서로 다른 값이 제1 동기화 이벤트가 발생했는지를 지시하는 데 사용된다. 따라서 제2 프로세서는 제1 동기화 레지스터의 값에 기반하여 제1 동기화 이벤트가 발생하는지를 판정한다. 단계(S604)의 특정 구현에 대해서는 단계(S302)를 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다시 설명하지 않는다. 예를 들어, 도 4 및 도 5a를 참조하면, 동기화 이벤트 1의 경우, CPU는 NotifyWait를 통해 대기 태스크 1을 NPU 0에 전달한다. 대기 태스크 1을 수신한 후, NPU 0은 대기 태스크 1의 동기화 레지스터 Reg 0의 식별자에 기반하 여 Reg 0의 값을 읽는다. Reg 0의 값이 0이면, notify 1에 대응하는 동기화 이벤트 1이 발생하지 않음을 지시한 다. 이 경우, NPU 0은 계속해서 동기화 이벤트 1이 발생하기를 대기하며, NPU 0의 컨트롤러는 항상 Reg 0의 값 을 확인한다. Reg 0의 값이 0에서 1로 변경될 때, notify 1에 대응하는 동기화 이벤트 1이 발생함을 지시한다. NPU 0의 컨트롤러는 Reg 0의 값에서의 변경을 즉시 검출하고, 동기화 이벤트 1이 발생한 것으로 결정한다. NPU 0의 컨트롤러는 Reg 0의 값을 0으로 클리어한다. 또 다른 예를 들어, 도 4 및 도 5a를 참조하면, 동기화 이벤트 1의 경우, CPU는 NotifyWait를 통해 대기 태스크 1을 NPU 0에 전달한다. 대기 태스크 1을 수신한 후, NPU 0은 대기 태스크 1의 동기화 레지스터 Reg 0의 식별자 에 기반하여 Reg 0의 값을 읽는다. Reg 0의 값이 1이면, NPU 0은 notify 1에 대응하는 동기화 이벤트 1이 발생 한 것으로 결정하고, NPU 0의 컨트롤러는 Reg 0의 값을 0으로 클리어한다. 선택적으로, 제1 동기화 이벤트가 발생한 후, 제2 프로세서는 제1 동기화 레지스터의 값을 제1 값으로 재설정하 므로, 제1 동기화 레지스터가 다른 동기화 작동을 계속 수행할 수 있다. 예를 들어, 제1 동기화 객체에 대응하 는 동기화 이벤트가 주기적으로 발생할 때, 제2 프로세서는 제1 동기화 객체에 대응하는 동기화 이벤트가 발생 하는 다음 번에, 제1 동기화 레지스터의 값에 기반하여 동기화를 수행할 수 있다. S605: 제1 프로세서가 제3 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크를 제3 프로세 서에 송신한다. 제3 프로세서는 NPU일 수 있고, 제3 프로세서와 제2 프로세서는 동일한 NPU일 수도 있고, 동일한 AI 서버에서의 서로 다른 NPU일 수도 있다. 제3 API는 동기화 이벤트에 대응하는 기록 태스크를 전달하도록 구성된다. 예를 들어, 제3 API는 NotifyRecord(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에 대응하는 동기 화 이벤트의 발생을 설정하도록 구성된다. 제1 동기화 이벤트에 대응하는 기록 태스크는 제1 동기화 이벤트가 발생함을 지시하는 데 사용된다. 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐 식별자 및 제1 동기화 레지스터의 식별자를 포함한다. 제2 큐 식별자 는 제1 동기화 이벤트에 대응하는 기록 태스크가 위치된 큐의 식별자이다. 달리 말하면, 제1 동기화 이벤트에 대응하는 기록 태스크는 제2 큐에 있는 태스크이다. 선택적으로, 제2 큐 식별자는 기록 태스크가 위치된 스트림 의 식별자일 수 있다. 선택적으로, AI 가속기에서 제1 동기화 이벤트가 발생할 때, 제2 프로세서와 제3 프로세서는 동일한 AI 가속기 (예를 들어, NPU)일 수 있다. 달리 말하면, 동일한 AI 가속기가 대기 태스크와 기록 태스크를 모두 실행한다. AI 서버의 두 개의 AI 가속기 간에 제1 동기화 이벤트가 발생할 때, 제2 프로세서와 제3 프로세서는 AI 서버의 두 개의 서로 다른 AI 가속기이다. 달리 말하면, 하나의 AI 가속기는 대기 태스크를 실행하고, 다른 AI 가속기 는 기록 태스크를 실행한다. 선택적으로, AI 가속기가 대기 태스크와 기록 태스크를 모두 실행할 때, 대기 태스 크와 기록 태스크는 각각 두 개의 스트림에 있는 태스크일 수 있다. 예를 들어, 도 4를 참조하면, 도 5a에 도시된 바와 같이, 제1 동기화 이벤트는 동기화 이벤트 1이고, 동기화 이 벤트 1은 NPU에서 발생한다. 동기화 이벤트 1의 경우, 제2 프로세서와 제3 프로세서는 동일하며 둘 다 NPU 0이 다. 달리 말하면, NPU 0은 대기 태스크와 기록 태스크를 모두 실행한다. CPU는 NotifyRecord(notify 1, 큐 0) 를 호출하는 것에 의해 기록 태스크 1을 NPU 0에 전달하여, NPU0의 큐 0에 있는 동기화 객체 Notify 1에 대응하 는 동기화 이벤트 1이 발생함을 지시한다. 선택적으로, NPU 0이 컴퓨팅 태스크 01의 실행을 완료하고 컴퓨팅 태 스크 01의 실행 결과를 CPU에 송신한 후, CPU는 기록 태스크 1을 NPU 0에 전달하여 notify 1에 대응하는 동기화 이벤트 1이 발생함을 지시한다. 또 다른 예를 들어, 도 4를 참조하면, 도 5b에 도시된 바와 같이, 제1 동기화 이벤트는 동기화 이벤트 2이고, 동기화 이벤트 2는 AI 서버의 서로 다른 NPU 간에 발생한다. 동기화 이벤트 2의 경우, 제2 프로세서는 NPU 1이 고 제3 프로세서는 NPU 0이며, CPU는 NotifyRecord(notify 2, 큐 2)를 호출하는 것에 의해 기록 태스크 2를 NPU 0에 전달하여, 큐 2의 동기화 객체 notify 2에 대응하는 동기화 이벤트 2가 발생함을 NPU 0에게 지시한다. 선택적으로, NPU 0이 컴퓨팅 태스크 3n의 실행을 완료하고 컴퓨팅 태스크 3n의 실행 결과를 CPU에 송신한 후,CPU는 기록 태스크 2를 NPU 0에 전달하여 notify 2에 대응하는 동기화 이벤트 2가 발생함을 지시한다. S606: 제3 프로세서가 제1 동기화 이벤트에 대응하는 기록 태스크를 수신한다. 예를 들어, 제3 프로세서는 제1 동기화 이벤트에 대응하는 기록 태스크를 수신하고, 제1 동기화 이벤트가 발생 했음을 알게 될 수 있다. S607: 제3 프로세서가 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레지스터의 값을 제2 값으로 재설 정한다. 제1 동기화 이벤트가 발생하기 때문에, 제3 프로세서는 제1 동기화 이벤트에 대응하는 기록 태스크에서의 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레지스터의 값을 제2 값으로 재설정할 수 있으므로, 제1 동기 화 레지스터의 값은 제1 동기화 이벤트의 발생 상태에 대응한다. 예를 들어, 도 4 및 도 5a를 참조하면, 동기화 이벤트 1의 경우, NPU 0은 Reg 0의 식별자에 기반하여 NPU 0의 Reg 0 값을 1로 재설정할 수 있으므로, NPU 0의 컨트롤러가 Reg 0의 값에서의 변경을 즉시 검출하며, NPU 0은 동기화 이벤트 1이 발생한 것으로 결정하고, Reg 0의 값을 0으로 클리어한다. 또 다른 예를 들어, 도 4 및 도 5b를 참조하면, 동기화 이벤트 2의 경우, NPU 0은 Reg 1의 식별자에 기반하여 NPU 1의 Reg 1 값을 1로 재설정할 수 있으므로, NPU 1의 컨트롤러는 Reg 1의 값에서의 변화를 즉시 검출하며, NPU 1은 동기화 이벤트 2가 발생한 것으로 결정하고, Reg 1의 값을 0으로 클리어한다. 본 출원의 실시예에서 NotifyWait 및 NotifyRecord는 일대일 대응 관계에 있음을 이해할 수 있다. 기록 태스크 를 수신한 후, 제3 프로세서는 동기화 객체에 대응하는 동기화 이벤트가 발생했음을 알게 되고, 동기화 객체에 대응하는 동기화 레지스터의 값을 1로 재설정한다. 대기 태스크를 수신한 후, 제2 프로세서는 동기화 객체에 대 응하는 동기화 레지스터의 값을 읽는다. 동기화 레지스터의 값이 0이면, 동기화 이벤트가 발생하지 않은 것으로 결정하고, 제2 프로세서는 동기화 이벤트가 발생하기를 계속 대기한다. 제3 프로세서가 동기화 객체에 대응하는 동기화 레지스터의 값을 1로 설정할 때까지, 제2 프로세서는 동기화 레지스터의 값이 1인 것을 즉시 검출한다. 이 경우, 제2 프로세서는 동기화 이벤트가 발생한 것으로 결정하고 동기화 레지스터의 값을 0으로 재설정하므로, 동기화 레지스터는 이후의 또 다른 동기화 작동을 계속 수행할 수 있다. 본 실시예에서 제공되는 동기화 방법에서, 동기화 오버헤드는 AI 가속기의 컨트롤러가 버스를 통해 레지스터를 기록하는 오버헤드이며, 동기화 오버헤드는 상대적으로 작다는 점에 유의해야 한다. 예를 들어, 본 실시예에서 제공되는 동기화 방법을 사용하는 것에 의해, NPU에서 동기화의 동기화 오버헤드는 50ns보다 작고, AI 서버의 서로 다른 NPU 간의 동기화 오버헤드는 1μs보다 작다. 또한 본 출원의 실시예에서는 간단한 API 인터페이스가 제공되며, 인터페이스는 일반 OS의 세마포어 인터페이스와 유사하여 개발자가 AI 가속기를 사용하는 것을 크게 용이하게 할 수 있다. 본 출원의 실시예에서는 단계(S601 내지 S607)의 구체적인 실행 시퀀스가 제한되지 않는다는 것을 이해할 수 있 다. 도 6은 단지 설명을 위한 예시일 뿐이다. 선택적으로, 이 방법은 단계(S608)를 더 포함할 수 있다. S608: 제1 프로세서가 제7 API를 호출하여 제1 동기화 레지스터와 제1 동기화 객체 사이의 대응 관계를 해제하 고, 제1 동기화 레지스터의 값을 제1 값으로 재설정한다. 제7 API는 제1 동기화 레지스터를 해제하도록 구성된다. 예를 들어, 제7 API는 NotifyDestroy(notify)일 수 있 으며, 인터페이스는 동기화 객체 notify를 파기하고, 동기화 객체에 대응하는 동기화 레지스터를 해제하도록 구 성될 수 있다. 예를 들어, 도 4에 도시된 바와 같이, APP는 생성된 동기화 객체 notify 1을 파기하기 위해 NotifyDestroy API 를 전달한다. 런타임은 NPU 드라이버의 인터페이스를 호출하여 NPU 0에서 notify 1을 해제한다. NPU 드라이버는 NPU 0의 notify 1을 재활용하고, notify 1에 대응하는 동기화 레지스터 Reg 0의 값을 0으로 재설정한다. 동기화 객체에 대응하는 동기화 레지스터는 NotifyDestroy를 통해 동기화 객체를 파기하는 것에 의해 재활용될 수 있으므로, 이후에 동기화를 수행해야 할 때, 이 동기화 레지스터를 다른 동기화 이벤트에 할당할 수 있는 것으로 이해될 수 있다. 본 출원의 실시예에서 제공되는 동기화 방법에 따르면, 동기화 레지스터 그룹이 AI 가속기에 배치된다. 각 레지 스터는 하나의 동기화 이벤트에 대응할 수 있으며, 레지스터의 서로 다른 값은 레지스터에 대응하는 동기화 이 벤트가 발행하는지를 지시하는 데 사용된다. AI 가속기는 대기 태스크를 수신할 때, 동기화 레지스터의 값을 읽 으므로, 동기화 이벤트가 발생하지 않을 때 AI 가속기는 항상 동기화 이벤트가 발생하기를 대기할 수 있으며, 동기화 이벤트가 발생할 때 AI 가속기는 동기화 레지스터의 값을 제1 값으로 재설정할 수 있다. AI 가속기는 기 록 태스크를 수신할 때, 동기화 레지스터에 값을 써서 동기화 이벤트가 발생함을 지시하므로, 동기화가 필요한 AI 가속기 간의 동기화가 정확하게 구현될 수 있다. 본 출원의 실시예에서 제공되는 동기화 방법에 따르면, AI 가속기 내에서의 동기화뿐만 아니라 AI 서버의 서로 다른 AI 가속기 간의 동기화도 동기화 레지스터를 사용하여 구현될 수 있다는 것을 이해할 수 있다. 또한 간단한 API 인터페이스를 제공하고, 동기화 오버헤드가 상대적으 로 적으므로, AI 트레이닝 효율성을 향상시킬 수 있다. 선택적으로, 제1 동기화 이벤트는 APP의 동기화 이벤트일 수도 있고, 서로 다른 APP 간의 동기화 이벤트일 수도 있다. 동기화 이벤트가 하나의 APP에 대한 동기화 이벤트인지, 복수의 APP 간의 동기화 이벤트인지에 관계없이, 동기화 이벤트는 AI 가속기에서 발생할 수도 있고, AI 서버의 서로 다른 AI 가속기 간에 발생할 수도 있다. 다 만, 제1 동기화 이벤트가 복수의 APP 간의 동기화 이벤트일 때, 인터 프로세스 동기화를 구현하기 위해서는 복 수의 APP가 동기화 객체의 이름을 사전에 합의해야 한다. 예를 들어, 도 7에 도시된 바와 같이, 제1 동기화 이 벤트가 APP 1과 APP 3 간의 동기화인 예를 사용한다. APP 1과 APP 3 간에 동기화를 수행해야 할 때, APP 1과 APP 3은 사전에 동기화 객체의 이름을 합의하여 서로 다른 프로세스 간의 동기화를 구현할 수 있다. 본 출원의 실시예는 동기화 방법을 더 제공한다. 도 8a 및 도 8b에 도시된 바와 같이, 본 실시예에서 제1 동기 화 이벤트는 인터 프로세스 동기화 이벤트이고, 이 방법은 다음 단계를 포함한다. S801: 제1 프로세서가 제1 동기화 이벤트에 대한 제1 동기화 객체를 생성한다. 제1 동기화 이벤트는 인터 프로세스 동기화 이벤트이다. 제1 동기화 이벤트는 AI 가속기 내에서 발생할 수도 있 고, AI 서버의 서로 다른 AI 가속기 간에 발생할 수도 있다. 이는 본 출원의 실시예에 제한되지 않는다. 단계(S801)의 구체적인 구현에 대해서는 단계(S301)의 구체적인 구현을 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다시 설명하지 않는다. S802: 제1 프로세서가 제1 애플리케이션의 제4 API를 호출하는 것에 의해 제1 동기화 객체의 이름을 미리 설정 된 이름으로 설정한다. 제4 API는 동기화 객체의 글로벌 이름을 설정하도록 구성된다. 예를 들어, 제4 API는 IpcSetNotifyName(notify, name)일 수 있으며, 동기화 객체 notify의 글로벌 이름을 설정하도록 구성된다. 선택적으로, 제1 동기화 이벤트는 제1 애플리케이션과 제2 애플리케이션 간의 동기화일 수 있으며, 미리 설정된 이름은 제1 애플리케이션과 제2 애플리케이션이 사전에 합의한 이름일 수 있다. 예를 들어, 제1 동기화 이벤트는 APP 1과 APP 3 간의 동기화이고, APP 1과 APP 3가 사전에 합의한 동기화 객체 의 이름은 NotifyForTest1이다. 도 7에 도시된 바와 같이, APP 1은 NotifyCreate 인터페이스를 호출하는 것에 의해 동기화 객체 A를 생성할 수 있다. 동기화 객체 A는 notify A로 표시될 수 있다. NPU 드라이버는 NPU 1의 동기화 레지스터 Reg n을 APP 1의 런타임에 할당하고, notify A는 동기화 레지스터 Reg n의 식별자를 저장한다. 도 7에서는 동기화 레지스터 Reg n의 식별자가 1-n인 예를 들어 설명한다. APP 1은 IpcSetNotifyName 인터페이 스를 호출하여 notify A를 인터 프로세스 통신(inter-process communication, IPC)을 위한 동기화 객체로 설정 한다. NPU 드라이버는 동기화 객체 notify A의 이름에 NotifyForTest1이라는 레이블을 지정한다. S803: 제1 프로세서가 제2 애플리케이션의 제5 API를 호출하는 것에 의해 미리 설정된 이름에 대응하는 제1 동 기화 레지스터의 식별자를 획득한다. 제5 API는 미리 설정된 이름에 대응하는 레지스터의 식별자를 획득하도록 구성된다. 예를 들어, 제5 API는 IpcOpenNotify(notify, name)일 수 있으며, 동기화 객체의 글로벌 이름에 기반하여 동기화 객체 notify를 열도 록 구성된다. 예를 들어, 제1 동기화 이벤트는 APP 1과 APP 3 간의 동기화이며, APP 1과 APP 3가 사전에 합의한 동기화 객체 의 이름은 NotifyForTest1이다. 도 7에 도시된 바와 같이, APP 3은 IpcOpenNotify를 호출하고 런타임은 NPU 드 라이버의 인터페이스를 호출하여, NotifyForTest1을 NPU 드라이버로 전달한다. NPU 드라이버는 NotifyForTest1 에 기반하여 동기화 객체 notify A를 찾고, notify A에 있는 동기화 레지스터의 식별자 Reg 1-n을 런타임에 반 환한다. 런타임은 APP 3에 대한 동기화 객체 B를 생성한다. 동기화 객체 B는 notify B로 표시될 수 있으며,notify B는 동기화 레지스터의 식별자 Reg 1-n을 저장한다. 이러한 방식으로, 동일한 동기화 레지스터 Reg 1- n이 APP 1의 notify A 및 APP 3의 notify B에 개별적으로 대응할 수 있다. 그러면 APP 1과 APP 3은 NotifyRecord 및 NotifyWait 인터페이스를 사용하여 동기화를 수행할 수 있다. S804: 제1 프로세서가 제2 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 대기 태스크를 제2 프로세 서에 송신한다. 예를 들어, 도 7에 도시된 바와 같이, APP 1은 NotifyWait(notify A, 큐 1) 인터페이스를 호출하여 대기 태스크 를 NPU 1에 전달하여, NPU 1이 큐 1에서, notify A에 대응하는 동기화 이벤트가 발생하기를 대기하도록 지시할 수 있다. S805: 제2 프로세서가 제1 동기화 이벤트에 대응하는 대기 태스크를 수신한다. S806: 제2 프로세서가 제1 동기화 레지스터의 값에 기반하여 제1 동기화 이벤트가 발생하는지를 판정한다. 예를 들어, 도 7을 참조하면, CPU는 NotifyWait를 통해 대기 태스크를 NPU 1에 전달한다. 대기 태스크를 수신한 후, NPU 1은 대기 태스크의 동기화 레지스터 Reg 1-n의 식별자에 기반하여 Reg 1-n의 값을 읽는다. Reg 1-n의 값이 0이면, notify A에 대응하는 동기화 이벤트가 발생하지 않음을 지시한다. 이 경우, NPU 1은 계속 대기하며, NPU 1의 컨트롤러는 항상 Reg 1-n의 값을 확인한다. Reg 1-n의 값이 0에서 1로 변경될 때, 이는 notify A에 대응하는 동기화 이벤트가 발생함을 지시한다. NPU 1의 컨트롤러는 Reg 1-n의 값에서의 변경을 즉시 검출하며, NPU 1의 컨트롤러는 대기를 중지하고, Reg 1-n의 값을 0으로 클리어한다. S807: 제1 프로세서가 제3 API를 호출하는 것에 의해 제1 동기화 이벤트에 대응하는 기록 태스크를 제3 프로세 서에 송신한다. 선택적으로, AI 가속기에서 제1 동기화 이벤트가 발생할 때, 제3 프로세서와 제2 프로세서는 동일한 AI 가속기 이다. AI 서버의 서로 다른 AI 가속기 간에 제1 동기화 이벤트가 발생할 때, 제3 프로세서와 제2 프로세서는 AI 서버에서의 두 개의 서로 다른 AI 가속기이다. 이하의 실시예에서는 AI 서버의 서로 다른 AI 가속기 간에 제1 동기화 이벤트가 발생하는 예를 들어 설명한다. 예를 들어, 도 7에 도시된 바와 같이, APP 2는 NotifyRecord(notify B, 큐 0) 인터페이스를 호출하여 기록 태 스크를 NPU 0에 전달하여, 큐 0에서 동기화 객체 Notify B에 대응하는 동기화 이벤트가 발생함을 NPU 0에게 지 시할 수 있다. S808: 제3 프로세서가 제1 동기화 이벤트에 대응하는 기록 태스크를 수신한다. S809: 제3 프로세서가 제1 동기화 레지스터의 식별자에 기반하여 제1 동기화 레지스터의 값을 제2 값으로 재설 정한다. 예를 들어, 도 7에 도시된 바와 같이, NPU 0은 Reg 1-n의 식별자에 기반하여 NPU 1의 Reg 1-n의 값을 1로 재설 정할 수 있으므로, NPU 1의 컨트롤러가 Reg 1-n의 값에서의 변경을 즉시 검출하고, Reg 1-n, NPU 1의 컨트롤러 는 대기를 중지하며, Reg 1-n의 값을 0으로 클리어한다. 단계(S804 내지 S809)의 구체적인 구현에 대해서는 전술한 실시예의 단계(S602 내지 S607)의 구현을 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다시 설명하지 않는다. 본 출원의 실시예에서는 단계(S801 내지 S809)의 구체적인 실행 시퀀스가 제한되지 않는다는 것을 이해할 수 있 다. 도 8a 및 도 8b는 설명을 위한 예시일 뿐이다. 선택적으로, 이 방법은 단계(S810)를 더 포함할 수 있다. S810: 제1 프로세서가 제7 API를 호출하여 제1 동기화 레지스터와 제1 동기화 이벤트 사이의 대응 관계를 해제 하고, 제1 동기화 레지스터의 값을 제1 값으로 재설정한다. 단계(S810)의 구체적인 구현에 대해서는 단계(S608)를 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다 시 설명하지 않는다. 본 출원의 실시예에서 제공되는 동기화 방법에 따르면, 동기화에 사용되는 레지스터 그룹이 AI 가속기에 배치되 고, 각 레지스터는 하나의 동기화 이벤트에 대응하도록 구성될 수 있다. 레지스터의 서로 다른 값은 이 레지스 터에 대응하는 동기화 이벤트가 발생하는지를 지시하는 데 사용된다. 또한 동기화 이벤트가 인터 프로세스 동기 화를 위한 것일 때, 동기화 이벤트의 글로벌 이름을 미리 설정하므로, 서로 다른 프로세스 간의 동기화 이벤트가 동일한 레지스터에 대응되어, 인터 프로세스 동기화를 구현할 수 있다. 본 출원의 실시예는 칩 동기화 방법을 더 제공한다. 본 실시예에서는 서로 다른 AI 서버 간에 제2 동기화 이벤 트가 발생한다. 도 9a 및 도 9b에 도시된 바와 같이, 이 방법은 다음 단계를 포함한다. S901: 제1 프로세서가 제2 동기화 이벤트에 대한 제2 동기화 객체를 생성한다. 단계(S901)의 구체적인 구현에 대해서는 단계(S301)를 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다 시 설명하지 않는다. 제2 동기화 이벤트는 서로 다른 AI 서버 간의 동기화 이벤트이다. 예를 들어, 제2 동기화 이벤트는 AI 서버 1과 AI 서버 2 간의 동기화이다. 도 10에 도시된 바와 같이, APP 1은 AI 서버 1에서 실행되고, APP 2는 AI 서버 2에서 실행되며, APP 1과 APP 2는 동기화되어야 한다. APP 1은 APP 2가 데이터를 APP 1에 전송하기를 대기한다. 데이터 전송이 완료된 후, APP 2는 전송이 완료되었음을 APP 1에 알리고, 후속 태스크를 실행하도록 APP 1에게 지시한다. 동기화를 위해, CPU 1은 AI 서버 1의 NPU 0에 포함된 복수의 동기화 레지스터 중 동기화 레지스터 Reg m을 동기화 이벤트에 할당하고, 동기화 레지스터 Reg m의 식별 자 Reg 0-m을 동기화 객체 K에 저장할 수 있다. 동기화 객체 K는 notify K로 표시될 수 있다. 예를 들어, AI 서 버 1의 CPU 1는 NotifyCreat 인터페이스를 호출하는 것에 의해 동기화 객체 notify K를 생성할 수 있다. 동기화 객체 notify K는 NPU 드라이버에 의해 동기화 이벤트에 할당된 동기화 레지스터의 식별자 Reg 0-m을 저장한다. S902: 제1 프로세서가 제2 API를 호출하는 것에 의해 제2 동기화 이벤트에 대응하는 대기 태스크를 제2 프로세 서에 송신한다. 제1 프로세서와 제2 프로세서는 동일한 AI 서버의 프로세서이다. 예를 들어, 도 10에 도시된 바와 같이, 제1 프 로세서는 AI 서버 1의 CPU 1일 수 있고, 제2 프로세서는 AI 서버 1의 AI 가속기 NPU 0일 수 있다. S903: 제2 프로세서가 제2 동기화 이벤트에 대응하는 대기 태스크를 수신한다. S904: 제2 프로세서가 제2 동기화 레지스터의 값에 기반하여 제2 동기화 이벤트가 발생하는지를 판정한다. 단계(S902 내지 S904)의 구체적인 구현에 대해서는 단계(S602 내지 S604)의 구체적인 구현을 참조하는 것이 이 해될 수 있다. 자세한 내용은 여기서 다시 설명하지 않는다. S905: 제1 프로세서가 제6 API를 호출하는 것에 의해 제2 동기화 레지스터의 가상 주소를 획득한다. 제6 API는 동기화 객체에 대응하는 레지스터의 가상 주소를 획득하도록 구성된다. 예를 들어, 제6 API는 NotifyGetAddr(notify, addr)일 수 있으며, 여기서 입력은 동기화 객체 notify이고, 출력은 동기화 객체 notify에 대응하는 동기화 레지스터의 가상 주소이다. 예를 들어, 도 10에 도시된 바와 같이, AI 서버 간 동기화 중에, APP 1은 NotifyGetAddr 인터페이스를 호출하는 것에 의해, 동기화 객체 notify K에 대응하는 동기화 레지스터 Reg 0-m의 물리적 주소를 APP1의 가상 주소 (Virtual Address, VA)에 매핑하며, 가상 주소는 VA 1로 표시된다. 예를 들어, APP 1은 런타임의 NotifyGetAddr 인터페이스를 호출하고 동기화 객체 notify K를 런타임으로 전달한다. 런타임은 동기화 객체 notify K에 기반하여 동기화 레지스터 Reg 0-m의 식별자를 획득한다. NPU 드라이버는 동기화 레지스터 Reg 0- m의 식별자에 기반하여 동기화 레지스터의 물리적 주소를 획득하고 물리적 주소를 APP 1의 가상 주소에 매핑한 다. NPU 드라이버는 가상 주소를 런타임에 반환하고. 런타임은 가상 주소를 APP에 반환하여 동기화 레지스터의 가상 주소 매핑 프로세스를 완료한다. 선택적으로, 동기화 레지스터의 물리적 주소를 가상 주소에 매핑하는 특정 구현은 본 출원의 이 실시예에서 제 한되지 않는다. 자세한 내용은 기존 기술을 참조한다. 자세한 내용은 여기서 다시 설명하지 않는다. S906: 제1 프로세서가 제2 동기화 레지스터의 가상 주소를 제4 프로세서에 송신한다. 제4 프로세서는 AI 서버의 중앙 제어 유닛, 예를 들어 CPU일 수 있다. 제4 프로세서는 제2 CPU를 포함한다. 제1 프로세서와 제4 프로세서는 서로 다른 AI 서버의 프로세서이다. 선택적으로, 제1 프로세서와 제4 프로세서 는 서로 다른 AI 서버의 CPU일 수도 있다. 예를 들어, 도 10에 도시된 바와 같이, 제1 프로세서는 AI 서버 1의 CPU 1일 수 있고, 제4 프로세서는 AI 서버 2의 CPU 2일 수 있다. AI 서버 1의 CPU 1은 동기화 객체 notify K에 대응하는 동기화 레지스터 Reg 0-m의 가상주소 VA 1을 AI 서버 2의 CPU 2에 송신한다. S907: 제4 프로세서가 제2 동기화 레지스터의 가상 주소를 수신한다. S908: 제4 프로세서가 제2 동기화 이벤트에 대응하는 원격 직접 메모리 액세스(Remote Direct Memory Access, RDMA) 태스크를 제5 프로세서에 송신한다. 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 이벤트가 발생함을 지시하는 데 사용되며, 제2 동기화 이벤트에 대응하는 RDMA 태스크는 제2 동기화 레지스터의 가상 주소를 포함한다. 제4 프로세서와 제5 프로세서는 동일한 AI 서버의 프로세서이다. 제4 프로세서는 AI 서버의 CPU일 수 있고, 제5 프로세서는 AI 서버의 AI 가속기(예를 들어, NPU)일 수 있다. 예를 들어, 도 10에 도시된 바와 같이, 제4 프로세서는 AI 서버 2의 CPU 2이고, 제5 프로세서는 AI 서버 2의 NPU 1일 수 있다. CPU 2는 RDMAsend(VA 1, 1)를 호출하는 것에 의해 RDMA 태스크를 NPU 1에 전달할 수 있다. 선택적으로, 제4 프로세서는 제8 API를 호출하는 것에 의해 제2 동기화 이벤트에 대응하는 RDMA 태스크를 제5 프로세서에 송신할 수 있다. 제8 API는 동기화 이벤트에 대응하는 RDMA 태스크를 전달하도록 구성된다. 예를 들 어, 제8 API는 RDMAsend(addr, 1)이며, 제2 값 1을 가상 주소 addr에 기록하도록 구성된다. S909: 제5 프로세서가 제2 동기화 이벤트에 대응하는 RDMA 태스크를 수신한다. S910: 제5 프로세서가 RDMA 장치를 통해 제2 동기화 레지스터의 가상 주소에 기반하여 제2 동기화 레지스터의 값을 제2 값으로 재설정한다. 제2 동기화 이벤트가 발생하였기 때문에, 제5 프로세서가 제2 동기화 이벤트에 대응하는 RDMA 태스크에서의 제2 동기화 레지스터의 가상 주소에 기반하여 제2 동기화 레지스터의 값을 제2 값으로 재설정하므로, 제2 동기화 레 지스터의 값은 제2 동기화 이벤트의 발생 상태에 대응한다. 예를 들어, 도 10을 참조하면, AI 서버 2의 NPU 1은 VA 1을 기반하여 NPU 0의 Reg 0-m 값을 1로 재설정할 수 있으므로, NPU 0의 컨트롤러가 Reg 0-m의 값에서의 변경을 즉시 검출하고, NPU 0의 컨트롤러는 대기를 중지하며, Reg 0-m의 값을 0으로 클리어한다. 본 출원의 이 실시예에서 NotifyWait 및 RDMAsend는 일대일 대응이라는 것을 이해할 수 있다. RDMAsend 태스크 를 수신한 후, 제5 프로세서는 동기화 객체에 대응하는 동기화 이벤트가 발생했음을 알게 되고, RDMA 장치를 통 해 동기화 객체에 대응하는 동기화 레지스터의 값을 1로 재설정한다. 대기 태스크를 수신한 후, 제2 프로세서는 동기화 객체에 대응하는 동기화 레지스터의 값을 읽는다. 동기화 레지스터의 값이 0이면 동기화 이벤트가 발생 하지 않은 것으로 결정하고, 제2 프로세서는 계속 대기한다. 제5 프로세서가 동기화 객체에 대응하는 동기화 레 지스터의 값을 1로 설정할 때까지, 제2 프로세서는 동기화 레지스터의 값이 1인 것으로 검출하고, 동기화 이벤 트가 발생한 것으로 결정한다. 이 경우, 제2 프로세서가 대기를 중지하고 동기화 레지스터의 값을 0으로 재설정 하므로, 동기화 레지스터는 다음 후속 동기화 태스크를 계속 수행할 수 있다. 본 출원의 실시예에서는 단계(S901 내지 S910)의 실행 시퀀스가 제한되지 않는다는 점에 유의해야 한다. 도 9a 및 도 9b는 설명을 위한 예시일 뿐이다. 본 출원의 본 실시예의 동기화 방법에 따르면, AI 서버 간 동기화의 경우, 동기화 오버헤드는 네트워크 통신의 시간 오버헤드일 뿐이며 다른 추가 오버헤드는 없다. 따라서 동기화 오버헤드가 상대적으로 작다. 또한 본 출원 의 실시예에서는 간단한 API 인터페이스가 제공되며, 이 인터페이스는 일반 OS의 세마포어 인터페이스와 유사하 며 개발자가 AI 가속기를 사용하는 것을 크게 용이하게 할 수 있다. 선택적으로, 이 방법은 단계(S911)를 더 포함할 수 있다. S911: 제1 프로세서가 제7 API를 호출하여 제2 동기화 레지스터와 제2 동기화 이벤트 사이의 대응 관계를 해제 하고 제2 동기화 레지스터의 값을 제1 값으로 재설정한다. 단계(S911)의 구체적인 구현에 대해서는 단계(S608)를 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다 시 설명하지 않는다. 본 출원의 실시예에서 제공되는 동기화 방법에 따르면, 동기화 레지스터 그룹이 AI 가속기에 배치된다. 각 레지 스터는 하나의 동기화 객체에 대응할 수 있으며, 레지스터의 서로 다른 값은 동기화 객체에 대응하는 동기화 이 벤트가 발생하는지를 지시하는 데 사용된다. AI 가속기는 대기 태스크를 수신할 때, 대응하는 동기화 레지스터의 값을 읽으므로, AI 가속기는 동기화 이벤트가 발생하지 않을 때 계속 대기하고, 동기화 이벤트가 발생할 때 대기를 중지할 수 있다. AI 가속기는 RDMA 태스크를 수신할 때, 가상 주소에 대응하는 동기화 레지스터에 값을 기록하여 동기화 이벤트가 발생함을 지시하므로, 동기화가 필요한 AI 가속기 간의 동기화가 정확하게 구현될 수 있다. 또한 이 솔루션에 기반하여, 동기화 레지스터의 물리적 주소를 가상 주소로 변환하고, RDMA를 통해 가상 주소에 값을 기록함으로써, 서로 다른 노드(AI 서버) 간 동기화를 구현할 수 있다. 또한 간단한 API 인터페이스 를 제공하고, 동기화 오버헤드가 상대적으로 적으므로, AI 트레이닝 효율성이 향상된다. 본 출원의 실시예는 칩 동기화 방법을 더 제공한다. 도 11a 및 도 11b에 도시된 바와 같이, 본 실시예에서는 AI 서버 간에 제2 동기화 이벤트가 발생하며, 이 방법은 다음 단계를 포함한다. S1101: 제1 프로세서가 제2 동기화 이벤트에 대한 제2 동기화 객체를 생성한다. S1102: 제1 프로세서가 제2 API를 호출하는 것에 의해 제2 동기화 이벤트에 대응하는 대기 태스크를 제2 프로세 서에 송신한다. S1103: 제2 프로세서가 제2 동기화 이벤트에 대응하는 대기 태스크를 수신한다. S1104: 제2 프로세서가 제2 동기화 레지스터의 값에 기반하여 제2 동기화 이벤트가 발생하는지를 판정한다. S1105: 제1 프로세서가 제6 API를 호출하는 것에 의해 제2 동기화 레지스터의 가상 주소를 획득한다. S1106: 제1 프로세서가 제2 동기화 레지스터의 가상 주소를 제4 프로세서에 송신한다. S1107: 제4 프로세서가 제2 동기화 레지스터의 가상 주소를 수신한다. 단계(S1101) 내지 단계(S1107)의 구체적인 구현에 대해서는 전술한 단계의 구현을 참조하는 것이 이해될 수 있 다. 자세한 내용은 여기서 다시 설명하지 않는다. S1108: 제4 프로세서가 RDMA 장치를 통해 제2 동기화 레지스터의 가상 주소에 기반하여 제2 동기화 레지스터의 값을 제2 값으로 재설정한다. 예를 들어, 도 10에 도시된 바와 같이, AI 서버 1과 AI 서버 2 사이에 제2 동기화 이벤트가 발생할 때, AI 서버 2의 CPU 2가 동기화 레지스터 Reg 0-m의 가상 주소 VA 1을 수신한 후, CPU 2는 제2 동기화 이벤트가 발생할 때 RDMA 장치를 통해 제2 동기화 레지스터의 값을 제2 값으로 직접 재설정할 수 있다. AI 서버 2의 CPU 2는 도 9a 및 도 9b에 도시된 실시예에서와 같이 RDMA 태스크를 NPU 1에 송신할 필요가 없다. 그러면, NPU 1은 RDMA 장치 를 통해 제2 동기화 레지스터의 값을 제2 값으로 재설정한다. CPU 2가 제2 동기화 이벤트 발생할 때 RDMA 장치 를 통해 동기화 레지스터 Reg 0-m의 값을 1로 재설정한 후, NPU 0의 컨트롤러는 Reg 0-m의 값에서의 변경을 즉 시 검출할 수 있음을 알 수 있다. NPU 0의 컨트롤러는 대기를 중지하고 Reg 0-m의 값을 0으로 클리어하여, AI 서버 간의 정확한 동기화를 구현한다. 본 출원의 실시예에서는 단계(S1101 내지 S1108)의 실행 시퀀스가 제한되지 않는다는 점에 유의해야 한다. 도 11a 및 도 11b는 설명을 위한 예시일 뿐이다. 선택적으로, 이 방법은 단계(S1109)를 더 포함할 수 있다. S1109: 제1 프로세서가 제7 API를 호출하여 제2 동기화 레지스터와 제2 동기화 이벤트 사이의 대응 관계를 해제 하고, 제2 동기화 레지스터의 값을 제1 값으로 재설정한다. 단계(S1109)의 구체적인 구현에 대해서는 단계(S608)를 참조하는 것이 이해될 수 있다. 자세한 내용은 여기서 다시 설명하지 않는다. 본 출원의 실시예에서 제공되는 동기화 방법에 따르면, 동기화 레지스터 그룹이 AI 가속기에 배치된다. 각 레지 스터는 하나의 동기화 객체에 대응할 수 있으며, 레지스터의 서로 다른 값은 동기화 객체에 대응하는 동기화 이 벤트가 발행하는지를 지시하는 데 사용된다. AI 가속기는 대기 태스크를 수신할 때, 대응하는 동기화 레지스터 의 값을 읽으므로, AI 가속기는 동기화 이벤트가 발생하지 않을 때 계속 대기하고, 동기화 이벤트가 발생할 때 대기를 중지할 수 있다. 동기화 이벤트가 발생할 때, 프로세서는 동기화 레지스터의 가상 주소에 기반하여 동기 화 레지스터에 직접 값을 기록하여 동기화 이벤트가 발생함을 지시하므로, 동기화가 필요한 AI 서버 간에 동기 화가 정확하게 구현될 수 있다. 본 출원의 실시예에서는 제1 API 내지 제8 API가 구체적으로 속하는 APP가 제한되지 않는다는 점에 유의해야 한 다. 실제 애플리케이션에서, 각 APP은 AI 가속기 내, AI 서버의 서로 다른 AI 가속기 간 또는 AI 서버 간 동기화를 구현하기 위해 APP의 서비스 요건에 기반하여 전술한 API 중 하나 이상을 호출할 수 있다. 본 출원의 실시예는 칩을 더 제공한다. 칩은 전술한 제1 프로세서와 인터페이스 회로를 포함한다. 제1 프로세서 는 인터페이스 회로를 통해 다른 장치와 통신하여 도 3, 도 6, 도 8a 및 도 8b, 도 9a 및 도 9b 또는 도 11a 및 도 11b에 도시된 동기화 방법을 구현하도록 구성된다. 선택적으로, 칩은 메모리를 더 포함할 수 있고, 메모리는 컴퓨터 명령어를 저장하도록 구성된다. 본 출원의 실시예는 칩을 더 제공한다. 칩은 전술한 제2 프로세서와 인터페이스 회로를 포함한다. 제2 프로세서 는 인터페이스 회로를 통해 다른 장치와 통신하여 도 3, 도 6, 도 8a 및 도 8b, 도 9a 및 도 9b 또는 도 11a 및 도 11b에 도시된 동기화 방법을 구현하도록 구성된다. 본 출원의 실시예는 칩을 더 제공한다. 칩은 전술한 제3 프로세서와 인터페이스 회로를 포함한다. 제3 프로세서 는 인터페이스 회로를 통해 다른 장치와 통신하여 도 6 또는 도 8a 및 도 8b에 도시된 동기화 방법을 구현하도 록 구성된다. 본 출원의 실시예는 칩을 더 제공한다. 칩은 전술한 제4 프로세서와 인터페이스 회로를 포함한다. 제4 프로세서 는 인터페이스 회로를 통해 다른 장치와 통신하여 도 9a 및 도 9b 또는 도 11a 및 도 11b에 도시된 동기화 방법 을 구현하도록 구성된다. 본 출원의 실시예는 칩을 더 제공한다. 칩은 전술한 제5 프로세서와 인터페이스 회로를 포함한다. 제5 프로세서 는 인터페이스 회로를 통해 다른 장치와 통신하여 도 11a 및 도 11b에 도시된 동기화 방법을 구현하도록 구성된 다. 본 출원의 실시예는 AI 서버를 더 제공한다. AI 서버는 제1 프로세서, 제2 프로세서 및 인터페이스 회로를 포함 한다. 제1 프로세서는 인터페이스 회로를 통해 제2 프로세서와 통신하여 도 3, 도 6, 도 8a 및 도 8b, 도 9a 및 도 9b 또는 도 11a 및 도 11b에 도시된 동기화 방법을 구현한다. 본 출원의 실시예는 AI 서버를 더 제공한다. AI 서버는 제1 프로세서, 제2 프로세서, 제3 프로세서 및 인터페이 스 회로를 포함한다. 제1 프로세서, 제2 프로세서 및 제3 프로세서는 인터페이스 회로를 통해 서로 통신하여 도 6 또는 도 8a 및 도 8b에 도시된 동기화 방법을 구현한다. 본 출원의 실시예는 AI 서버를 더 제공한다. AI 서버는 제4 프로세서, 제5 프로세서 및 인터페이스 회로를 포함 한다. 제4 프로세서는 인터페이스 회로를 통해 제5 프로세서와 통신하여 도 9a 및 도 9b에 도시된 동기화 방법 을 구현한다. 본 출원의 실시예는 AI 클러스터를 제공한다. AI 클러스터는 복수의 AI 서버를 포함하고, AI 서버는 CPU와 하나 이상의 AI 가속기를 포함한다. CPU는 제1 프로세서를 포함할 수 있고, AI 가속기는 제2 프로세서 또는 제3 프로 세서 중 적어도 하나를 포함할 수 있다. 본 출원의 실시예는 AI 클러스터를 제공한다. AI 클러스터는 복수의 AI 서버를 포함하고, AI 서버는 CPU와 하나 이상의 AI 가속기를 포함한다. CPU는 제4 프로세서를 포함할 수 있고, AI 가속기는 제5 프로세서를 포함할 수 있다. 본 출원의 실시예는 통신 시스템을 제공한다. 통신 시스템은 전술한 AI 가속기, 전술한 AI 서버, 또는 전술한 AI 클러스터 중 적어도 하나를 포함한다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되고 API는 동기화 이벤트에 대한 동기화 객체를 생성하도록 구성된다. 선택적으로, API는 NotifyCreat(deviceID, notify)일 수 있다. 여기서 입력 deviceID는 AI 가속기의 ID이고 출력 notify는 동기화 객체이다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되며 API는 동기화 이벤트에 대응하는 대기 태스크를 전달하도록 구성된다. 선택적으 로, API는 NotifyWait(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에 대응 하는 동기화 이벤트가 발생하기를 대기하도록 구성된다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되며, API는 동기화 이벤트에 대응하는 기록 태스크를 전달하도록 구성된다. 선택적 으로, API는 NotifyRecord(notify, stream) 인터페이스일 수 있으며, 인터페이스는 stream에서 동기화 객체에대응하는 동기화 이벤트의 발생을 설정하도록 구성된다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되며 API는 동기화 객체의 글로벌 이름을 설정하도록 구성된다. 선택적으로, API는 IpcSetNotifyName(notify, name)일 수 있으며 동기화 객체 notify의 글로벌 이름을 설정하도록 구성된다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되고, API는 동기화 객체를 열도록 구성된다. 선택적으로, API는 IpcOpenNotify(notify, name)일 수 있으며 동기화 객체의 글로벌 이름 name에 기반하여 동기화 객체 notify를 열도록 구성된다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되며, API는 동기화 객체에 대응하는 레지스터의 가상 주소를 획득하도록 구성된다. 선택적으로, API는 NotifyGetAddr(notify, addr)일 수 있으며, 여기서 입력은 동기화 객체 notify이고, 출력은 동기화 객체 notify에 대응하는 동기화 레지스터의 가상 주소이다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되고, API는 동기화 레지스터를 해제하도록 구성된다. 선택적으로, API는 NotifyDestroy(notify)일 수 있으며, 인터페이스는 동기화 객체 notify를 파기하고, 동기화 객체에 대응하는 동 기화 레지스터를 해제하도록 구성될 수 있다. 본 출원의 실시예는 애플리케이션 프로그래밍 인터페이스(application programming interface, API)를 제공한 다. API는 프로세서에 배치되며, API는 동기화 이벤트에 대응하는 RDMA 태스크를 전달하도록 구성된다. 선택적 으로, API는 RDMAsend(addr, 1)일 수 있으며, 가상 주소 addr에 제2 값 1을 기록하기를 지시하도록 구성된다. 본 출원의 실시예는 컴퓨터가 판독 가능한 저장 매체를 더 제공한다. 컴퓨터가 판독 가능한 저장 매체는 컴퓨터 프로그램 코드를 저장한다. 전술한 프로세서가 컴퓨터 프로그램 코드를 실행할 때, 전자 디바이스는 도 3, 도 6, 도 8a 및 도 8b, 도 9a 및 도 9b 또는 도 11a 및 도 11b에 도시된 동기화 방법을 수행한다. 본 출원의 실시예는 컴퓨터 프로그램 제품을 더 제공한다. 컴퓨터 프로그램 제품이 컴퓨터에서 실행될 때, 컴퓨 터는 도 3, 도 6, 도 8a 및 도 8b, 도 9a 및 도 9b 또는 도 11a 및 도 11b에 도시된 동기화 방법을 수행하도록 이네이블된다. 본 출원에 개시된 내용을 참조하여 설명한 방법이나 알고리즘 단계는 하드웨어로 구현될 수도 있고, 소프트웨어 명령어를 실행하여 프로세서로 구현될 수도 있다. 소프트웨어 명령어에는 대응하는 소프트웨어 모듈이 포함될 수 있다. 소프트웨어 모듈은 랜덤 액세스 메모리(random access memory, RAM), 플래시 메모리, 소거 가능한 프 로그램 가능 읽기 전용 메모리(erasable programmable ROM, EPROM), 전기적으로 소거 가능한 프로그램 가능한 읽기 전용 메모리(electrically EPROM, EEPROM), 레지스터, 하드 디스크, 이동식 하드 디스크, 콤팩트 디스크 읽기 전용 메모리(compact disc read-only memory, CD-ROM), 또는 해당 기술 분야에 잘 알려진 임의의 다른 형 태의 저장 매체를 포함할 수 있다. 예를 들어, 저장 매체는 프로세서에 결합되므로, 프로세서는 저장 매체로부 터 정보를 읽거나 저장 매체에 정보를 쓸 수 있다. 물론, 저장 매체는 프로세서의 구성 요소일 수도 있다. 프로 세서와 저장 매체는 ASIC에 위치될 수 있다. 또한 ASIC는 코어 네트워크 인터페이스 디바이스에 위치될 수도 있 다. 물론, 프로세서와 저장 매체는 코어 네트워크 인터페이스 디바이스에 개별 구성 요소로서 존재할 수 있다. 당업자는 전술한 하나 이상의 예에서, 본 발명에 설명된 기능이 하드웨어, 소프트웨어, 펌웨어 또는 이들의 임 의의 조합에 의해 구현될 수 있다는 것을 인식해야 한다. 기능이 소프트웨어로 구현될 때, 전술한 기능은 컴퓨 터가 판독 가능한 매체에 저장되거나, 컴퓨터가 판독 가능한 매체에서 하나 이상의 명령어 또는 코드의 형태로 전송될 수 있다. 컴퓨터가 판독 가능한 매체는 컴퓨터 저장 매체와 통신 매체를 포함한다. 통신 매체에는 컴퓨 터 프로그램을 한 곳에서 다른 곳으로 전송할 수 있는 임의의 매체가 포함된다. 저장 매체는 범용 컴퓨터나 전 용 컴퓨터에서 액세스 가능한 임의의 이용 가능한 매체일 수 있다. 본 발명의 목적, 기술 솔루션 및 이점은 전술한 특정 구현에서 더 자세히 설명된다. 전술한 설명은 단지 본 발 명의 특정 구현일 뿐이고, 본 발명의 보호 범위를 제한하려는 의도가 아니라는 점을 이해해야 한다. 본 발명의 기술적 솔루션에 기반하여 이루어진 모든 수정, 등가 교체, 개선은 본 발명의 보호 범위에 속한다.도면 도면1a 도면1b 도면1c 도면1d 도면1e 도면1f 도면1g 도면1h 도면1i 도면1j 도면1k 도면1l 도면2a 도면2b 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9a 도면9b 도면10 도면11a 도면11b"}
{"patent_id": "10-2023-7035925", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 출원의 실시예에 따른 AI 트레이닝 프로세스의 개략도이다. 도 1b는 본 출원의 실시예에 따른 단일 AI 서버의 링 알고리즘 구조의 개략도이다. 도 1c 내지 도 1g는 본 출원의 실시예에 따른 단일 AI 서버의 링 알고리즘에서 산란 감소 페이즈의 계산 프로세 스의 개략도이다. 도 1h 내지 도 1l는 본 출원의 실시예에 따른 단일 AI 서버의 링 알고리즘의 전체 수집 페이즈의 계산 프로세스 의 개략도이다. 도 2a는 본 출원의 실시예에 따른 AI 가속기 구조의 개략도이다. 도 2b는 본 출원의 실시예에 따른 컴퓨팅 아키텍처 구조의 개략도이다. 도 3은 본 출원의 실시예에 따른 동기화 방법의 개략적인 흐름도이다. 도 4는 본 출원의 실시예에 따른 AI 서버의 컴퓨팅 아키텍처 구조의 개략도이다. 도 5a 및 도 5b는 본 출원의 실시예에 따른 컴퓨팅 태스크의 개략도이다. 도 6은 본 출원의 실시예에 따른 다른 동기화 방법의 개략적인 흐름도이다. 도 7은 본 출원의 실시예에 따른 인터 프로세스 동기화 컴퓨팅 아키텍처의 구조의 개략도이다. 도 8a 및 도 8b는 본 출원의 실시예에 따른 다른 동기화 방법의 개략적인 흐름도이다. 도 9a 및 도 9b는 본 출원의 실시예에 따른 다른 동기화 방법의 개략적인 흐름도이다. 도 10은 본 출원의 실시예에 따른 AI 서버 간의 동기화를 위한 컴퓨팅 아키텍처 구조의 개략도이다. 도 11a 및 도 11b는 본 출원의 실시예에 따른 다른 동기화 방법의 개략적인 흐름도이다."}
