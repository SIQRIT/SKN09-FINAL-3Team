{"patent_id": "10-2019-0120294", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0037857", "출원번호": "10-2019-0120294", "발명의 명칭": "관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템", "출원인": "주식회사 오투오", "발명자": "안성민"}}
{"patent_id": "10-2019-0120294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에서, 상기 관계 설정부는 상기 영상 처리부에서 획득한 사용자 상황 정보 및 감정 정보를 기초로 결정한 음성 대화 객체의 감정표현을 결정하는 객체 감정표현 결정부를 포함하는 것을 특징으로 하는 관계 설정을이용한 실감형 인공지능기반 음성 비서시스템."}
{"patent_id": "10-2019-0120294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에서, 상기 관계 설정부는 획득한 음성 명령에 매칭되는 객체 후보군 및 주변환경 후보군을 도출하는객체 후보군 도출부 및 주변환경 후보군 도출부; 사용자 정보를 기초로 상기 객체 후보군 및 주변환경 후보군의인공지능 학습을 통해 최종 음성 대화 객체 및 주변환경을 결정하는 객체 및 주변환경 결정부를 포함하는 것을특징으로 하는 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템."}
{"patent_id": "10-2019-0120294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에서, 상기 객체 및 주변환경 결정부는 인공지능 학습을 통해 음성 대화 객체를 결정하되, 사용자와 동일 연령대 및 동일 성별대의 선호도가 높은 음성 대화 객체를 우선순위로 결정하는 것을 특징으로 하는 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템."}
{"patent_id": "10-2019-0120294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에서, 상기 관계 설정부는 결정된 음성 대화 객체의 음성 특징이 음성 데이터베이스에 없을 경우, 미리설정된 기본 음성 특징을 적용하여 음성 피드백을 출력하는 것을 특징으로 하는 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템."}
{"patent_id": "10-2019-0120294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에서, 상기 관계 설정부는 결정된 음성 대화 객체의 캐릭터를 표시부를 통해 표출한 상태에서, 사용자가 입력부를 통해 캐릭터 변경을 요청하면 음성 대화 객체에 관한 연관 인물을 통해 관계 설정을 변경하여, 음성 대화 객체를 새롭게 생성하는 것을 특징으로 하는 관계 설정을 이용한 실감형 인공지능기반 음성비서시스템.공개특허 10-2021-0037857-3-청구항 6"}
{"patent_id": "10-2019-0120294", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에서, 상기 관계 설정부는 호출어 인식을 통해 사용자의 목소리 특색을 파악하고, 호출어가 인식되면표시부에 전체 화면으로 초기 응답 객체를 디스플레이해주거나, 팝-업 형태로 초기 응답 객체를 디스플레이해주어 음성 대화시 멀티태스킹 작업을 구현해주는 것을 특징으로 하는 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템."}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자의 정보를 입력하고 호출어 인식에 따른 초기 응답 캐릭터를 설정한 후, 호출어 또는 음성 명령을 입력하 면 호출어를 인식하고, 음성 명령어를 분석하고, 음향 분석을 통해 사용자의 감정을 파악하며, 카메라를 통해 촬 영된 사용자의 얼굴 이미지를 인식하고 제스처 인식을 통해 사용자의 상황 및 감정을 파악한 후, 인식된 호출어 를 기초로 설정된 초기 응답 캐릭터를 설정하여 표시부를 통해 디스플레이하고, 음성 명령과 사용자 정보와 감정 표현 정보의 관계 설정을 통해 음성 대화 객체 및 주변환경을 결정하고, 결정된 음성 대화 객체를 캐릭터화한 후 음성 특징을 적용하여 사용자 맞춤형 영상 및 음성피드백을 하여, 관계설정에 의해 음성명령에 대응하는 최적의 음성 대화 객체(Object)를 생성하고, 객체별 음성특징을 제공하여 더욱 실감나고 흥미로운 음성 대화 서비스를 제공한다."}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템에 관한 것으로, 특히 사용자 정보입력을 통한 관계설정에 의해 음성명령에 대응하는 최적의 음성 대화 객체(Object)를 생성하고, 객체별 음성특징을 제 공하여 더욱 실감나고 흥미로운 음성 대화 서비스를 제공하는 관계 설정을 이용한 실감형 인공지능기반 음성 비 서시스템에 관한 것이다."}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 국내외에서는 음성 인식 기술을 이용한 인공 지능 서비스가 다양하게 출시되고 있다. 인공 지능 서비스의 일종인 인공 지능 스피커의 세계 시장 규모는 2020년 약 2조 5천억 원에 달할 것으로 전망되는 등 향후 관련 시 장 규모는 급격하게 증가할 것으로 예상된다. 일반적인 개인 비서 서비스는 사용자의 음성 명령을 다양한 음성 인식 기술을 이용하여 텍스트 명령으로 인식한 후, 그 인식 결과에 따라 사용자의 음성 명령을 처리하는 방식이 일반적이다. 한국 공개 특허공보 제2003- 0033890호에는 이와 같은 음성 인식 기술을 이용하여 개인 비서 서비스를 제공하는 시스템이 개시되어 있다. 이와 같은 일반적인 개인 비서 서비스는 사용자의 음성 명령에 포함된 단어의 의미를 통해서 음성 명령을 텍스 트로 변환하여 명령으로서의 정보만 인식할 뿐 사용자의 감정을 인식하지는 않는다. 그로 인해 슬픔, 분노, 기 쁨 등의 사용자의 감정에 관계없이 모바일 개인 비서 서비스의 응답은 동일하다. 상기와 같은 일반적인 모바일 개인 비서 서비스는 사용자에게 무미건조하게 느껴질 수 있고, 이는 곧 사용의 흥 미를 잃을 수 있는 문제점이 있다. 이로 인해 사용자의 사용빈도가 감소하고 사용자의 사용욕구도 감소하는 문 제점이 있다. 이러한 일반적인 모바일 개인 비서 서비스의 문제를 개선하기 위해서, 종래에 제안된 기술이 하기의 <특허문헌 1> 및 <특허문헌 2> 에 개시되어 있다. <특허문헌 1> 에 개시된 종래기술은 평소 고인이 생활했던 장소 혹은 고인을 추억할 수 있는 공간을 가상현실 속에 구현함은 물론 고인의 음성 및 영상을 통해서 고인과 교감할 수 있는 가상현실 기반의 고인 맞춤형 추모 시스템을 제공한다. 이러한 종래기술은 사용자와 고인과의 관계설정은 이용하나, 이는 미리 등록된 고인과의 관계 설정만을 이용할 뿐, 사용자의 감정을 파악하여 최적의 응대 객체를 제공해주지 못하며, 사용자 단말에 설치된 애플리케이션 등 을 분석하여 사용자의 관심사를 파악하는 것도 불가능한 단점이 있다. 또한, <특허문헌 2> 에 개시된 종래기술은 휴대용 단말기의 상태별로 표시되는 캐릭터의 모습에 대한 정보를 메 모리에 복수로 저장하고, 사용자의 취향이나 연령에 따라 다양한 캐릭터 등을 디스플레이의 배경 화면(즉, 대기 화면이나 아이들 화면)에 표시하는 휴대용 단말기를 제공한다. 이러한 종래기술은 배터라 상태, 연결 상태, 수신 상태, 작동 상태 등에 따른 캐릭터의 표정변화를 휴대용 단말 기의 디스플레이에 다양한 모습으로 표현할 수 있으나, 사용자 정보입력을 통한 관계설정이 불가능하고, 음성명령에 대응하는 최적의 응대 객체를 생성하는 것이 불가능한 단점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 10-2019-0014895(2019.02.13. 공개)(가상현실 기반의 고인 맞춤형 추모 시 스템) (특허문헌 0002) 대한민국 공개특허 10-2008-0078333(2008.08.27. 공개)(상태 변화에 따라 배경 화면이 변하는 휴대용 단말기 및 그 제어방법)"}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명은 상기와 같은 종래기술에서 발생하는 제반 문제점을 해결하기 위해서 제안된 것으로서, 사용자 정보입력을 통한 관계설정에 의해 음성명령에 대응하는 최적의 음성 대화 객체(Object)를 생성할 수 있도록 한 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템을 제공하는 데 그 목적이 있다. 본 발명의 다른 목적은 객체별 음성특징을 제공하여 더욱 실감나고 흥미로운 음성 대화 서비스를 제공하는 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템을 제공하는 것이다. 본 발명의 또 다른 목적은 웨이크업 신호 호출 시 디스플레이 화면 전체가 음성 명령 대기화면으로 전환하는 것 이 아니고, 팝-업 창 형태로 전환되어 음성 대화시 멀티태스킹 작업이 가능하도록 한 관계 설정을 이용한 인공 지능기반 음성 비서시스템을 제공하는 것이다."}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 목적을 달성하기 위하여, 본 발명에 따른 \"관계 설정을 이용한 인공지능기반 음성 비서시스템\"은, 사용자의 정보를 입력하며, 호출어 인식에 따른 초기 응답 캐릭터를 설정하는 사용자 기본정보 입력부; 음성명령 호출어를 설정하는 호출어 설정부; 사용자로부터 발화된 음성 명령어를 분석하며, 음향 분석 을 통해 사용자의 감정을 파악하는 음성 명령어 분석부; 카메라를 통해 촬영된 사용자의 얼굴 이미지를 인식하 고 제스처 인식을 통해 사용자의 상황 및 감정을 파악하는 영상 처리부; 상기 사용자 기본정보 입력부로부터 획 득된 사용자 관심 정보 및 음성 명령 키워드에 기반한 영상정보를 머신러닝 알고리즘으로 학습하여 음성 대화 객체를 도출하고, 도출한 음성대화 객체에 매칭되는 음성 특징을 적용하며, 영상 처리부로부터 획득된 사용자 감정상태를 반영하여 음성 대화 객체를 캐릭터화하여, 사용자 맞춤형 영상 및 음성피드백을 출력하는 관계 설정 부를 포함하는 것을 특징으로 한다. 상기에서 관계 설정부는 획득한 음성 명령에 매칭되는 객체 후보군 및 주변환경 후보군을 도출하는 객체 후보군 도출부 및 주변환경 후보군 도출부; 사용자 정보를 기초로 상기 객체 후보군 및 주변환경 후보군의 인공지능 학 습을 통해 최종 음성 대화 객체 및 주변환경을 결정하는 객체 및 주변환경 결정부를 포함하는 것을 특징으로 한 다. 상기에서 객체 및 주변환경 결정부는 인공지능 학습을 통해 음성 대화 객체를 결정하되, 사용자와 동일 연령대 및 동일 성별대의 선호도가 높은 음성 대화 객체를 우선순위로 결정하는 것을 특징으로 한다. 상기에서 관계 설정부는 결정된 음성 대화 객체의 음성 특징이 음성 데이터베이스에 없을 경우, 미리 설정된 음 성 특징을 적용하여 음성 피드백을 출력하는 것을 특징으로 한다. 상기에서 관계 설정부는 결정된 음성 대화 객체의 캐릭터를 표시부를 통해 표출한 상태에서, 사용자가 입력부를 통해 캐릭터 변경을 요청하면 음성 대화 객체에 관한 연관 인물을 통해 관계 설정을 변경하여, 음성 대화 객체 를 새롭게 생성하는 것을 특징으로 한다. 상기에서 관계 설정부는 상기 영상 처리부에서 획득한 사용자 상황 정보 및 감정 정보를 기초로 결정한 음성 대 화 객체의 감정표현을 결정하는 객체 감정표현 결정부를 포함하는 것을 특징으로 한다.상기에서 관계 설정부는 호출어 인식을 통해 사용자의 목소리 특색을 파악하고, 호출어가 인식되면 표시부에 팝 -업 형태로 초기 응답 객체를 디스플레이해주어, 음성 대화시 멀티태스킹 작업을 구현해주는 것을 특징으로 한 다."}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 사용자 정보입력을 통한 관계설정에 의해 음성명령에 대응하는 최적의 음성 대화 객체 (Object)를 생성할 수 있는 효과가 있다. 또한, 본 발명에 따르면 객체별 음성특징을 제공하여 더욱 실감나고 흥미로운 음성 대화 서비스를 제공해주는 효과도 있다. 또한, 본 발명에 따르면 웨이크업 신호 호출 시 디스플레이 화면 전체가 음성 명령 대기화면으로 전환하는 것이 아니고, 팝-업 창 형태로 전환되어 음성 대화시 멀티태스킹 작업을 도모해주는 효과도 있다."}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 바람직한 실시 예에 따른 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템을 첨부된 도면을 참조하여 상세하게 설명한다. 이하에서 설명되는 본 발명에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서는 안 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념으로 적절하게 정의할 수 있 다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 바람직한 실시 예에 불과할 뿐이고, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원 시점에서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 도 1은 본 발명의 바람직한 실시 예에 따른 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템의 블록도 로서, 사용자 기본정보 입력부, 마이크, 음성 전처리부, 호출어 설정부, 음성 명령어 분석 부, 카메라, 영상 처리부, 관계 설정부, 객체 데이터베이스(DB), 환경정보 데이터베 이스(DB), 음성 데이터베이스(DB), 표시부, 스피커 및 GPS 모듈을 포함한다. 사용자 기본정보 입력부는 사용자의 정보를 입력하며, 호출어 인식에 따른 초기 응답 캐릭터를 설정하는 키패드와 같은 입력장치를 의미한다. 마이크는 사용자의 음성을 입력받기 위한 장치이며, 음성 전처리부는 마이크를 통해 입력되는 음성을 전처리하여 끝점 및 특징을 출력하는 역할을 한다. 호출어 설정부는 음성명령 호출어를 설정하는 역할을 하며, 음성 명령어 분석부는 상기 음성 전처리 부를 통해 전달되는 사용자로부터 발화된 음성 명령어를 분석하며, 음향 분석을 통해 사용자의 감정을 파 악하는 역할을 한다. 카메라는 사용자의 영상을 촬영하고, 제스처를 촬영하는 역할을 하며, 영상 처리부는 상기 카메라 를 통해 촬영된 사용자의 얼굴 이미지를 인식하고 제스처 인식을 통해 사용자의 상황 및 감정을 파악하는 역할을 한다. 객체 데이터베이스는 사용자가 입력한 음성명령에 매칭되는 음성 대화 객체(Object) 후보군 및 실감형 인 공지능(AI)비서 캐릭터를 저장하는 역할을 하며, 환경정보 데이터베이스는 상기 객체 후보군에 대응하는 주변 환경 정보를 저장하는 역할을 하며, 음성 데이터베이스는 도출한 음성 대화 객체의 음성 특징 정보를 저장하는 역할을 한다. 표시부는 호출어 인식어에 따른 초기 응대 화면을 표시해주고, 음성 대화 객체의 표현 영상 및 제스처 정 보를 화면에 표시해주는 역할을 한다. 호출어 인식에 따른 음성 대화 객체가 팝-업 창 형태로 디스플레이되는 응대 화면을 디스플레이하여, 음성 대화 시 멀티태스킹 작업 화면을 구현해준다. 스피커는 응대 음성을 출력하는 역할을 하며, GPS 모듈은 인공위성을 통해 시간 및 위치 정보를 획득 하는 역할을 한다. 관계 설정부는 상기 호출어 인식부를 통해 인식된 호출어를 기초로 설정된 초기 응답 캐릭터를 설정 하여 표시부를 통해 디스플레이하고, 상기 사용자 기본정보 입력부로부터 획득된 사용자 관심 정보 및 음성 명령 키워드에 기반한 영상정보를 머신러닝 알고리즘으로 학습하여 음성 대화 객체를 도출하며 도출한 음성 대화 객체에 매칭되는 음성 특징을 적용하고, 영상 처리부로부터 획득된 사용자 감정상태를 반영하여 음성 대화 객체를 캐릭터화하여, 사용자 맞춤형 영상 및 음성피드백을 출력하는 역할을 한다. 상기 관계 설정부는 도 2에 도시한 바와 같이, 입력부를 통해 사용자의 기본 정보를 획득하고, 사용 자 보유 애플리케이션을 분석하여 사용자의 관심사를 파악하는 관심 정보를 획득하는 사용자 정보 획득부, 획득한 음성 명령에 매칭되는 객체 후보군을 객체 데이터베이스로부터 탐색하는 객체 후보군 도출부, 상기 객체 후보군 도출부에서 도출한 후보군에 대응하는 주변환경 후보군을 환경정보 데이터베이스로 부터 탐색하는 주변환경 후보군 도출부를 포함할 수 있다. 또한, 상기 관계 설정부는 사용자 정보를 기초로 상기 객체 후보군 및 주변환경 후보군의 인공지능 학습을 통해 최종 음성 대화 객체 및 주변환경을 결정하는 객체 및 주변환경 결정부를 더 포함할 수 있다. 이러한 객체 및 주변환경 결정부는 인공지능 학습을 통해 음성 대화 객체를 결정하되, 사용자와 동일 연령대 및 동일 성별대의 선호도가 높은 음성 대화 객체를 우선순위로 결정할 수 있다. 또한, 상기 관계 설정부는 결정된 음성 대화 객체의 음성 특징을 음성 데이터베이스로부터 추출하는 음성 특징 검색부를 더 포함할 수 있다. 음성 특징 검색부는 음성 대화 객체의 음성 특징이 음성 데 이터베이스에 없을 경우, 상기 음성 데이터베이스의 검색을 통해 미리 설정된 음성 특징을 적용한다. 또한, 상기 관계 설정부는 상기 영상 처리부에서 획득한 사용자 상황 정보 및 감정 정보를 기초로 결 정한 객체의 감정표현을 결정하는 객체 감정표현 결정부, 결정된 음성 대화 객체를 캐릭터화하고, 결정된 음성 대화 객체에 대응하는 주변 환경을 포함한 사용자 맞춤형 영상 및 응대 음성을 출력해주는 맞춤형 영상 및 응대 음성 출력부를 더 포함할 수 있다. 상기와 같이 구현되는 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템은 사용자가 사용하는 스마트폰 을 이용하여 구현하거나, AI 스피커를 이용하여 구현될 수 있다. 본 발명에서는 스마트폰을 이용하는 것을 가정 하여 설명하나, 이것에 한정되는 것은 아님을 당해 분야의 통상의 지식을 가진 사람이라면 자명하다 할 것이다. 이와 같이 구성된 본 발명의 바람직한 실시 예에 따른 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스 템의 동작을 첨부한 도면을 참조하여 구체적으로 설명하면 다음과 같다. 먼저, 사용자는 사용자 기본정보 입력부를 통해 사용자의 기본 정보를 입력한다. 여기서 기본 정보는 연령, 성별, 혈액형, 직장, 취미, 선호음식, 선호색상, 좋아하는 유명인, 선호 브랜드 등을 포함할 수 있다. 아 울러 호출어 응답 초기 화면을 설정한다. 호출어 응답 초기화면은 호출어 인식에 따른 초기 응답 캐릭터가 설정 되면 해당 초기 응답 캐릭터가 표시부를 통해 표출된다. 도 3은 호출어 응답 초기화면 설정을 위한 초기 응답 캐릭터를 설정하는 화면 예시이다. 도 3과 같은 초기 응답 캐릭터 화면에서 사용자는 호출어 인식에 따른 초기 응답 캐릭터를 사용자 기본정보 입력부를 통해 선택한다. 선택된 초기 응답 캐릭터는 관계 설정부 를 통해 저장부에 저장된다. 다음으로, 사용자는 사용자 기본정보 입력부를 통해 호출어 설정 항목을 선택하게 된다. 호출어 설정 항목 이 선택되면 관계 설정부는 표시부를 통해 사용할 호출어를 말씀하라는 화면을 표시해준다. 이후, 사용자는 마이크를 통해 음성 비서 서비스를 호출하기 위한 호출어를 입력한다. 입력된 호출어 음성은 음성 전처리부를 통해 음성 인식을 위한 전처리가 이루어진다. 여기서 음성 전처리는 통상의 음성 인식에서 수 행하는 끝점 검출, 특징 검출 등을 수행하는 것을 의미한다. 이어, 호출어 설정부는 상기 음성 전처리부 에서 전처리된 끝점 및 특징을 이용하여 호출어를 음성인식으로 인식하고, 인식한 호출어 정보를 관계 설 정부에 전달한다. 여기서 음성 인식은 일반적으로 알려진 음성 인식 기술을 이용할 수 있다. 음성 인식 관 계 설정부는 호출어가 인식되면 사용자의 목소리 특색 등을 파악하기 위해서, 표시부를 통해 한 번 더 호출어를 입력하도록 유도하고, 호출어가 입력되면 상기와 같은 호출어 인식 과정을 통해 호출어를 인식한다. 호출어가 인식되면 표시부를 통해 인식된 호출어를 표시해주고 맞는지를 확인한다. 사용자가 맞 는다는 음성을 입력하면, 상기 인식한 호출어를 최종 호출어로 저장부에 등록한다. 이러한 과정을 통해 음성 비서 서비스 구현을 위한 기초적인 과정이 이루어진 상태에서, 실제 사용자가 음성 비 서 서비스를 사용하기 위해 마이크를 통해 호출어를 입력하면, 음성 전처리부, 호출어 설정부를 순차 통해 호출어 인식이 이루어진다. 관계 설정부는 호출어 설정부를 통해 설정된 호출어를 저장부에 저장된 호출어와 비교하여 일치 하면, 저장부에 저장된 초기 응대 캐릭터를 추출하여 표시부를 통해 표출하여 음성명령 대기화면으로 전환한다. 여기서 초기 응대 캐릭터는 도 4와 같이 화면 전체에 초기 설정 캐릭터를 표출하는 방법과 도 5와 같이 팝-업 형태로 표출해줄 수 있다. 화면 전체에 초기 설정된 응대 캐릭터를 표출하여 음성명령 대기화면으로 전환하면 다른 작업은 불가능한 상태가 된다. 상기 2가지 화면을 음성명령 대기화면으로 사용할 수 있으나, 사용자가 음 성 대화 서비스시에 멀티태스킹 작업이 가능하도록 도 5와 같이 초기 응대 캐릭터를 팝-업 형태로 표출하는 것 이 바람직하다. 이어, 음성명령 대기화면 상태에서 사용자가 음성 명령을 하면, 음성 명령은 마이크 및 음성 전처리부 를 순차 통해 음성 명령어 분석부에 전달된다. 음성 명령어 분석부는 상기 음성 전처리부 에서 전처리된 끝점 및 특징을 기초로 음성 명령어를 분석하고, 음향 분석을 통해 사용자의 감정을 파악한다. 여기서 음성 명령어 분석부는 입력된 명령 음향의 어조, 빠르기, 평소의 음성 정보와 비교한 음고(음의 높 이) 정보를 분석하여 사용자 감정을 추측한다. 다음으로, 음성 비서 서비스시 영상 처리부는 카메라를 통해 촬영한 사용자의 이미지(특히, 얼굴 이 미지) 및 제스처 등을 분석하여, 사용자의 상황 및 감정을 파악한다. 여기서 카메라 및 영상 처리부 는 호출어 인식에 따른 음성 비서 서비스시 음성 인식 동작과 동시에 자동으로 활성화된다. 얼굴 이미지의 표정 인식이나 제스처 인식 역시 기존에 알려진 이미지 인식 기법 및 제스처 인식 기법을 그대로 채택하여 표정 인식 이나 제스처 인식을 수행한다. 이어, 관계 설정부는 상기 호출어 설정부를 통해 설정된 호출어를 기초로 설정된 초기 응답 캐릭터를 설정하여 표시부를 통해 디스플레이하고, 상기 사용자 기본정보 입력부로부터 획득된 사용자 관심 정 보 및 음성 명령 키워드에 기반한 영상정보를 머신러닝 알고리즘으로 학습하여 음성 대화 객체를 도출하며, 도 출한 음성 대화 객체에 매칭되는 음성 특징을 적용하고, 영상 처리부로부터 획득된 사용자 감정상태를 반 영하여 음성 대화 객체를 캐릭터화하여, 사용자 맞춤형 영상 및 음성피드백을 출력한다. 즉, 객체 후보군 도출부에서 사용자 정보와 획득한 음성 명령에 매칭되는 객체 후보군을 객체 데이터베이 스로부터 탐색하여 객체 후보군을 도출한다. 여기서 객체 후보군 종류는 친구, 연인, 정치인, 연예인, 유 명인, 교육자, 반려동물 등과 같이 다양하다. 아울러 주변환경 후보군 도출부는 상기 객체 후보군 도출부에서 도출한 후보군에 대응하는 주변환경 후보군을 환경정보 데이터베이스로부터 탐색하여 도출한다. 여기서 주변환경 후보군은 상기 객체 후보군에 대응하게 미리 설정된 주변환경 정보로부터 추출하는 것으로서, 객체 후보가 프로야구 선수인 경우 야구와 관련 된 정보일 수 있으며, 연예인일 경우 해당 연예인이 광고한 상품일 수 있으며, 요리사일 경우 해당 요리사를 대 표하는 다양한 음식 종류일 수 있다. 도 6은 객체 후보군 및 그에 대응하는 주변환경 후보군의 예시이다. 음성 명령, 사용자 정보에 따른 객체 후보군 및 주변환경 후보군을 도출한 상태에서, 객체 및 주변환경 결정부 는 사용자 정보를 기초로 상기 객체 후보군 및 주변환경 후보군을 인공지능 알고리즘으로 학습하여 최종 음성 대화 객체 및 주변환경을 결정한다. 여기서 인공지능 학습은 당해 분야에 이미 잘 알려진 머신러닝 학습 알고리즘, 딥-러닝 학습 알고리즘을 이용할 수 있다. 머신러닝이나 딥-러닝은 다양한 정보를 입력으로 최적의결과물을 획득하는 인공지능(Artificial Intelligence; AI) 알고리즘이다. 인공지능 학습을 통해 음성 대화 객 체를 결정할 때, 사용자와 동일 연령대 및 동일 성별대의 선호도가 높은 음성 대화 객체를 우선순위로 결정하는 것이 바람직하다. 다음으로, 객체 감정표현 결정부는 상기 영상 처리부에서 획득한 사용자 상황 정보 및 감정 정보를 기초로 결정한 음성 대화 객체의 감정표현을 결정한다. 즉, 사용자의 얼굴 이미지가 웃는 얼굴이면 현재 기분이 좋은 감정상태로 예측하고, 음성 대화 객체의 감정도 기분 좋은 상태가 되도록 감정표현을 결정한다. 또한, 음성 특징 검색부는 최종적으로 결정된 음성 대화 객체의 음성 특징을 음성 데이터베이스를 검 색하여 추출한다. 여기서 음성 특징은 말투나 사투리 등의 특징을 의미한다. 음성 특징 검색부는 음성 대 화 객체의 음성 특징이 음성 데이터베이스에 없으면, 음성 데이터베이스의 검색을 통해 미리 설정된 기본 음성을 적용한다. 이후, 맞춤형 영상 및 응대 음성 출력부는 결정된 음성 대화 객체에 감정 표현을 적용하여 캐릭터화한다. 도 7은 감정 표현을 포함한 음성 대화 객체를 표현한 예시이다. 사용자의 감정 표현이 기분이 좋은 상태이므로, 캐릭터화된 음성 대화 객체도 기분이 좋은 상태로 표출된다. 이어, 결정된 음성 대화 객체의 캐릭터에 추출한 음성 특징을 적용하여 사용자 맞춤형 영상 및 음성을 출력한다. 응대 캐릭터는 표시부를 통해 디스플레이되고, 음성은 스피커를 통해 송출된다. 이에 따라 음성 명령에 대응하여 결정한 음성 대화 객체의 캐릭터가 자신의 현재 감정을 내포하는 것과 동일한 감정 표현을 하고, 결정된 캐릭터의 음성 특징(말투)을 포함하는 음성이 송출되어 음성명령에 대해 응답을 함으 로써, 최적의 맞춤형 영상 및 음성을 통해 음성 비서 서비스를 구현하게 되는 것이다. 한편, 결정된 음성 대화 객체의 캐릭터를 표시부를 통해 표출한 상태에서, 사용자는 출력된 음성 대화 객 체에 만족하지 못하면 사용자 기본정보 입력부를 통해 캐릭터 변경을 요청한다. 음성 대화 객체의 변경 요 청이 발생하면 맞춤형 영상 및 응대 음성 출력부는 음성 대화 객체에 관한 연관 인물을 통해 관계 설정을 변경한다. 여기서 관계 설정의 변경이 발생하면 음성 대화 객체도 변경된다. 표시부를 통해 객체 캐릭터를 통해 음성 명령에 따른 음성 비서 서비스를 받는 도중에, 사용자는 화면에 디스플레이된 영상의 특정 부분을 터치하면 디스플레이 화면 전체에 터치된 특정 부분의 관련 정보가 표현된다. 이때, 음성 대화 객체는 팝-업 형태로 변환되어 음성명령 대기 상태가 된다. 도 8은 음성 비서 서비스 상태에서 화면의 특정 부분을 선택하여 화면 전체에 터치된 특정 부분의 관련 정보를 디스플레이한 상태에서, 음성 대화 객체가 팝-업 형태로 변환되어 음성명령 대기 상태를 보인 화면 예시이다. 한편, 상기와 같은 관계 설정을 통해 음성 비서 서비스를 구현할 때, 음성 명령어를 분석한 결과 주변 지리정보 가 필요한 경우, GPS 모듈을 통해 현재 위치 정보를 추출한다. 이어, 주변환경 정보를 제공할 때 획득한 위치정보를 기반으로 지도데이터를 탐색하여 주변 지리 정보의 제공을 통해 음성 비서 서비스를 구현할 수도 있 다. 이것은 사용자가 음식점 등과 같은 장소를 찾는 음성 명령을 한 경우, 유용하게 사용되어 질 수 있다. 이와 같이 본 발명은 사용자 정보 입력을 통한 관계설정에 의해 음성명령에 대응하는 최적의 음성 대화 객체를 생성하고 이를 캐릭터화하며, 캐릭터별 음성 특징을 제공하여, 더욱 실감나고 흥미로운 음성 대화 서비스를 제 공해줄 수 있게 되는 것이다. 이상 본 발명자에 의해서 이루어진 발명을 상기 실시 예에 따라 구체적으로 설명하였지만, 본 발명은 상기 실시"}
{"patent_id": "10-2019-0120294", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되는 것은 아니고 그 요지를 이탈하지 않는 범위에서 여러 가지로 변경 가능한 것은 이 기술분야에서 통상의 지식을 가진 자에게 자명하다 할 것이다."}
{"patent_id": "10-2019-0120294", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 관계 설정을 이용한 실감형 인공지능기반 음성 비서시스템의 블록도, 도 2는 도 1의 관계 설정부의 실시 예 블록도, 도 3은 본 발명에서 실감형 AI비서 선택화면 예시도, 도 4는 본 발명에서 호출어 인식시 초기 응답 캐릭터의 화면 표출 제1 예시도, 도 5는 본 발명에서 호출어 인식시 초기 응답 캐릭터의 화면 표출 제2 예시도 도 6은 본 발명에서 관계설정 예시도, 도 7은 본 발명에서 관계 설정과 감정 표현을 통해 생성된 캐릭터의 예시도, 도 8은 본 발명에서 사용자 음성 명령에 따른 음성 및 영상 피드백 화면 예시도이다."}
