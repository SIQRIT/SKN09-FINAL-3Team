{"patent_id": "10-2019-0124008", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0121720", "출원번호": "10-2019-0124008", "발명의 명칭": "웨어러블 디바이스 및 웨어러블 디바이스에서 정보를 제공하기 위한 방법", "출원인": "엘지전자 주식회사", "발명자": "허정"}}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "웨어러블 디바이스에서 정보를 제공하기 위한 방법으로서,제1 시점에 카메라에 의해 획득된 이미지에 나타나는 객체를 식별하는 단계;상기 객체의 정보를 저장하는 단계;제2 시점에 사용자의 음성을 검출하는 단계;상기 사용자의 음성에 포함된 단어를 식별하는 단계; 및상기 식별된 단어와 연관된 객체의 정보를 상기 사용자에게 제공하는 단계를 포함하는,방법."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 사용자의 음성은 상기 객체의 정보를 요청하는 음성 쿼리인,방법."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 객체의 정보는 상기 객체의 종류, 상기 객체의 이름, 상기 객체와 상기 사용자와의 관계, 상기 제1 시점에서의 상기 객체의 위치, 또는 상기 제1 시점의 시간 정보 중 적어도 하나를 포함하는,방법."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,제3 시점에 상기 사용자의 동공의 이미지 또는 생체측정 신호 중 적어도 하나를 포함하는 적어도 하나의 센서신호를 획득하는 단계;상기 적어도 하나의 센서 신호로부터 사용자의 심리 상태를 인식하도록 미리 훈련된 인공 신경망을 이용하여,상기 사용자가 당황했다고 결정하는 단계; 및상기 사용자가 당황했다는 결정에 응답하여 상기 객체의 정보를 상기 사용자에게 제공하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 사용자가 당황했다는 결정에 응답하여 상기 객체의 정보를 상기 사용자에게 제공하는 단계는,상기 제3 시점에 상기 카메라에 의해 획득된 이미지에 나타나는 객체를 식별하는 단계; 및상기 제3 시점에 식별된 객체의 정보를 상기 사용자에게 제공하는 단계공개특허 10-2019-0121720-3-를 포함하는,방법."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 객체의 정보를 제공하는 단계는,상기 웨어러블 디바이스의 위치를 결정하는 단계; 및상기 결정된 위치로부터 상기 제1 시점에 상기 객체가 식별된 위치까지의 내비게이션 정보를 제공하는 단계를 포함하는,방법."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "웨어러블 디바이스로서,사용자의 시야의 적어도 일부를 포함하는 이미지를 포착하도록 구성된 카메라;상기 사용자의 음성을 검출하도록 구성된 마이크로폰;시각적으로 또는 청각적으로 사용자에게 정보를 제공하도록 구성된 출력 디바이스; 및제어부를 포함하고,상기 제어부는,제1 시점에 상기 카메라로부터 포착된 이미지에 나타나는 객체를 식별하고;상기 객체의 정보를 저장하고;제2 시점에 상기 마이크로폰을 이용하여 사용자의 음성을 검출하고;상기 사용자의 음성에 포함된 단어를 식별하고; 그리고상기 식별된 단어와 연관된 객체의 정보를 상기 출력 디바이스를 이용하여 상기 사용자에게 제공하도록구성되는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 사용자의 음성은 상기 객체의 정보를 요청하는 음성 쿼리인,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 객체의 정보는 상기 객체의 종류, 상기 객체의 이름, 상기 객체와 상기 사용자와의 관계, 상기 제1 시점에서의 상기 객체의 위치, 또는 상기 제1 시점의 시간 정보 중 적어도 하나를 포함하는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 사용자의 동공의 이미지를 캡쳐하도록 구성된 동공 카메라; 또는공개특허 10-2019-0121720-4-상기 사용자의 생체측정 신호를 검출하도록 구성된 생체측정 센서중 적어도 하나를 더 포함하고,상기 제어부는,상기 동공의 이미지 또는 생체측정 신호 중 적어도 하나로부터 사용자의 심리 상태를 인식하도록 미리 훈련된인공 신경망을 이용하여, 제3 시점에 상기 사용자가 당황했다고 결정하고; 그리고상기 사용자가 당황했다는 결정에 응답하여 상기 객체의 정보를 제공하도록 추가로 구성되는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제어부는,상기 제3 시점에 상기 카메라에 의해 획득된 이미지에 나타나는 객체를 식별하고; 그리고상기 제3 시점에 식별된 객체의 정보를 상기 사용자에게 제공하도록추가로 구성되는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 웨어러블 디바이스의 위치를 결정하기 위해 위치결정 신호를 수신하도록 구성된 위치결정 신호 수신기를더 포함하고,상기 제어부는 상기 웨어러블 디바이스의 위치로부터 상기 제1 시점에 상기 객체가 식별된 위치까지의 내비게이션 정보를 제공하도록 추가로 구성되는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제7항에 있어서,상기 출력 디바이스는,상기 웨어러블 디바이스가 상기 사용자에 의해 착용될 때 상기 사용자의 시야 내에 놓이고, 실제 세상의 이미지상에 시각적 콘텐츠를 중첩하여 표시하도록 구성된 증강현실 디스플레이; 또는상기 웨어러블 디바이스가 상기 사용자에 의해 착용될 때 상기 사용자에게 청각적 자극을 제공하도록 구성된 음향 출력기중 적어도 하나를 포함하는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제7항에 있어서,상기 웨어러블 디바이스는 상기 사용자의 머리에 장착되기 위한 증강현실 안경을 포함하는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2019-0121720-5-웨어러블 디바이스로서,사용자의 시야의 적어도 일부를 포함하는 이미지를 포착하도록 구성된 카메라;시각적으로 또는 청각적으로 사용자에게 정보를 제공하도록 구성된 출력 디바이스; 및제어부를 포함하고,상기 웨어러블 디바이스는,상기 사용자의 동공의 이미지를 캡쳐하도록 구성된 동공 카메라; 또는상기 사용자의 생체측정 신호를 검출하도록 구성된 생체측정 센서중 적어도 하나를 더 포함하고,상기 제어부는,제1 시점에 상기 카메라로부터 포착된 이미지에 나타나는 객체를 식별하고;상기 객체의 정보를 저장하고;제2 시점에 상기 사용자의 동공의 이미지 또는 상기 사용자의 생체측정 신호 중 적어도 하나를 포함하는 적어도하나의 센서 신호를 획득하고; 그리고상기 적어도 하나의 센서 신호로부터 결정된 상기 사용자의 심리 상태에 기초하여, 상기 객체의 정보를 상기 사용자에게 제공하도록구성되는웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 제어부는, 동공의 이미지 또는 생체측정 신호 중 적어도 하나로부터 사람의 심리 상태를 결정하도록 미리훈련된 인공 신경망을 이용하여 상기 사용자의 심리 상태를 결정하도록 추가로 구성되는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 제어부는,상기 제2 시점에 상기 카메라에 의해 획득된 이미지에 나타나는 객체를 식별하고; 그리고상기 제2 시점에 식별된 객체의 정보를 상기 사용자에게 제공하도록추가로 구성되는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,사용자의 음성을 검출하도록 구성된 마이크로폰을 더 포함하고,상기 제어부는,상기 제2 시점에 상기 마이크로폰을 이용하여 상기 사용자의 음성을 검출하고;상기 사용자의 음성에 포함된 단어를 식별하고; 그리고상기 식별된 단어와 연관된 객체의 정보를 상기 사용자에게 제공하도록공개특허 10-2019-0121720-6-추가로 구성되는,웨어러블 디바이스."}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능(artificial intelligence, AI) 알고리즘 및/또는 기계학습(machine learning) 알고리즘을 이용하는 웨 어러블 디바이스가 제공된다. 웨어러블 디바이스는, 사용자의 시야(field of view)의 적어도 일부를 포함하는 이 미지를 포착(capture)하도록 구성된 카메라, 사용자의 음성을 검출하도록 구성된 마이크로폰, 시각적으로 또는 청각적으로 사용자에게 정보를 제공하도록 구성된 출력 디바이스를 포함하고, 상기 웨어러블 디바이스는, 제1 시 점에 카메라로부터 포착된 이미지에 나타나는 객체를 식별하고, 객체의 정보를 저장하고, 제2 시점에 상기 마이 크로폰을 이용하여 사용자의 음성을 검출하고, 사용자의 음성에 포함된 단어를 식별하고, 그리고 식별된 단어와 연관된 객체의 정보를 출력 디바이스를 이용하여 사용자에게 제공하도록 구성된다."}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 웨어러블 디바이스에 관한 것으로, 보다 상세하게는, 사용자의 기억을 보조하기 위한 웨어러블 디바 이스에 관한 것이다."}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실을 이용하는 웨어러블 디바이스들이 개발되고 있다. 증강 현실 디바이스는 가상의 객체들이 현실 세계 의 이미지 상에 중첩되어 표시되는 증강 현실 이미지를 제공한다. 증강 현실 디바이스는 사용자가 위치한 환경 과 관련된 증강 현실 데이터를 증강 현실 서버로부터 획득하고, 획득된 증강 현실 데이터를 사용자에게 제공한 다. 국제공개특허 WO 2009/086234호(특허문헌 1)는 사용자에게 실시간으로 사람들 또는 사물들에 대한 주석을 제공 하는 증강 현실 시스템을 개시한다. 특허문헌 1에서의 증강 현실 시스템에 의해 제공되는 실시간 주석 데이터는 때론 사용자가 필요로 하는 데이터와 무관할 수 있다. 사용자가 필요로 하지 않는 정보의 지속적인 제공은 증강 현실 디바이스를 사용하는 사용자를 피곤하게 할 수 있다."}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 과제는 사용자의 시야 내에 존재하는 객체의 정보를 자동으로 수집하고 사용자가 필요로 할 때 수 집된 객체의 정보를 제공할 수 있는 웨어러블 디바이스를 제공하기 위한 것이다. 본 개시의 추가의 과제는 사용자의 명시적인 쿼리에 응답하여 객체의 정보를 제공할 수 있는 웨어러블 디바이스 를 제공하기 위한 것이다. 본 개시의 추가의 과제는 사용자의 명시적인 쿼리가 없이도 사용자가 필요로 하는 객체의 정보를 제공할 수 있 는 웨어러블 디바이스를 제공하기 위한 것이다. 본 개시의 추가의 과제는 사용자가 객체의 위치 정보를 필요로 할 때, 객체에 도달하기 위한 내비게이션 정보를 제공할 수 있는 웨어러블 디바이스를 제공하기 위한 것이다. 본 개시의 목적은 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 개시의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시 의 목적 및 장점들은 특허 청구범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시예들은, 카메라에 의해 획득된 이미지 내의 객체를 식별하고, 식별된 객체의 정보를 저장하고, 그리고 사용자가 객체의 정보를 필요로 할 때, 객체의 정보를 사용자에게 제공한다. 본 개시의 일 실시예에 따른 웨어러블 디바이스에서 정보를 제공하기 위한 방법은, 제1 시점에 카메라에 의해 획득된 이미지에 나타나는 객체를 식별하는 단계, 객체의 정보를 저장하는 단계, 제2 시점에 사용자의 음성에 포함된 단어를 식별하는 단계, 및 식별된 단어와 연관된 객체의 정보를 사용자에게 제공하는 단계를 포함한다. 본 개시의 다른 실시예에 따른 웨어러블 디바이스는, 사용자의 시야의 적어도 일부를 포함하는 이미지를 포착하 도록 구성된 카메라, 사용자의 음성을 검출하도록 구성된 마이크로폰, 시각적으로 또는 청각적으로 사용자에게 정보를 제공하도록 구성된 출력 디바이스, 및 제어부를 포함하고, 제어부는, 제1 시점에 카메라로부터 포착된 이미지에 나타나는 객체를 식별하고, 객체의 정보를 저장하고, 제2 시점에 마이크로폰을 이용하여 사용자의 음 성을 검출하고, 사용자의 음성에 포함된 단어를 식별하고, 그리고 식별된 단어와 연관된 객체의 정보를 출력 디 바이스를 이용하여 상기 사용자에게 제공하도록 구성된다.본 개시의 임의의 다른 실시예들과 결합될 수 있는 추가 실시예에 따르면, 검출되는 사용자의 음성은 객체의 정 보를 요청하는 음성 쿼리이다. 본 개시의 임의의 다른 실시예들과 결합될 수 있는 추가 실시예에 따르면, 객체의 정보는, 객체의 종류, 객체의 이름, 객체와 사용자와의 관계, 제1 시점에서의 객체의 위치, 또는 제1 시점의 시간 정보 중 적어도 하나를 포 함한다. 본 개시의 임의의 다른 실시예들과 결합될 수 있는 추가 실시예에 따르면, 제3 시점에 사용자의 동공의 이미지 또는 생체측정 신호 중 적어도 하나를 포함하는 적어도 하나의 센서 신호가 사용자가 당황했음을 나타내면, 객 체의 정보가 사용자에게 제공된다. 본 개시의 임의의 다른 실시예들과 결합될 수 있는 추가 실시예에 따르면, 제3 시점에 카메라에 의해 획득된 이 미지에 나타나는 객체가 식별되고, 식별된 객체의 정보가 사용자에게 제공된다. 본 개시의 임의의 다른 실시예들과 결합될 수 있는 추가 실시예에 따르면, 웨어러블 디바이스는 상기 사용자의 머리에 장착되기 위한 증강현실 안경을 포함한다."}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예들에 따른 웨어러블 디바이스는 사용자의 시야 내에 존재하는 객체의 정보를 자동으로 수집하 고 사용자가 필요로 할 때 수집된 객체의 정보를 제공할 수 있다. 본 개시의 실시예들에 따른 웨어러블 디바이스는 사용자의 명시적인 쿼리에 있을 때뿐만 아니라, 사용자의 명시 적인 쿼리가 없이도 사용자가 필요로 하는 객체의 정보를 제공할 수 있다. 본 개시의 실시예들에 따른 웨어러블 디바이스는 사용자가 필요로 하는 위치 정보를 내비게이션 방식으로 제공 함으로써 사용자 편의성을 높일 수 있다. 그 외의 다양한 효과는 후술될 본 개시의 실시예들에 따른 상세한 설명에서 명시적으로 또는 함축적으로 설명될 것이다."}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2019-0124008", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다.본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 명세서에서 설명되는 인공신경망은 생물학적 뉴런의 동작원리와 뉴런간의 연결 관계를 모델링한 것으로 노드 또는 처리 요소(processing element)라고 하는 다수의 뉴런들이 레이어(layer) 구조의 형태로 연결된 정보처리 시스템이다. 인공 신경망은 기계 학습에서 사용되는 모델로서, 기계학습과 인지과학에서 생물학의 신경망(동물 의 중추신경계 중 특히 뇌)에서 영감을 얻은 통계학적 학습 알고리즘이다. 구체적으로 인공신경망은 시냅스 (synapse)의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공신경망은 복수의 레이어(layer)를 포함할 수 있고, 레이 어들 각각은 복수의 뉴런(neuron)을 포함할 수 있다. 또한 인공신경망은 뉴런과 뉴런을 연결하는 시냅스를 포함 할 수 있다. 인공 신경망은 일반적으로 다음의 세가지 인자, 즉 다른 레이어의 뉴런들 사이의 연결 패턴, 연결의 가 중치를 갱신하는 학습 과정, 및 이전 레이어로부터 수신되는 입력에 대한 가중 합으로부터 출력값을 생성하 는 활성화 함수에 의해 정의될 수 있다. 인공 신경망은, 예를 들어, 컨볼루션 신경망(Convolution Neural Network; CNN), 순환 신경망(Recurrent Neural Network; RNN), 심층 신뢰 신경망(Deep Belief Network; DBN) 등의 심층신경망(Deep Neural Network; DNN)을 포함할 수 있으나, 이에 한정되는 것은 아니다. 인공신경망은 계층 수에 따라 단층 신경망(Single-Layer Neural Networks)과 다층 신경망(Multi-Layer Neural Networks)으로 구분된다. 일반적인 단층 신경망은, 입력층과 출력층으로 구성된다. 또한 일반적인 다층 신경망은 입력층(Input Layer)과 하나 이상의 은닉층(Hidden Layer), 출력층(Output Layer)으로 구성된다. 입력층은 외부의 자료들을 받아들이는 층으로서, 입력층의 뉴런 수는 입력되는 변수의 수와 동일하며, 은닉층은 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추출하여 출력층으로 전달한다. 출력층은 은닉층으로부터 신호를 받고, 수신한 신호에 기반한 출력 값을 출력한다. 뉴런간의 입력신호는 각각의 연결강도 (가중치)와 곱해진 후 합산되며 이 합이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 획득 한 출력값을 출력한다. 한편 입력층과 출력 층 사이에 복수의 은닉층을 포함하는 심층 신경망은, 기계 학습 기술의 한 종류인 딥 러닝 을 구현하는 대표적인 인공 신경망일 수 있다. 한편 용어 '딥 러닝'은 용어 '심층 학습'과 혼용되어 사용될 수 있다. 인공 신경망은 훈련 데이터(training data)를 이용하여 학습(training)될 수 있다. 여기서 학습이란, 입력 데이 터를 분류(classification)하거나 회귀분석(regression)하거나 군집화(clustering)하는 등의 목적을 달성하기 위하여, 학습 데이터를 이용하여 인공 신경망의 파라미터(parameter)를 결정하는 과정을 의미할 수 있다. 인공 신경망의 파라미터의 대표적인 예시로써, 시냅스에 부여되는 가중치(weight)나 뉴런에 적용되는 편향(bias)을 들 수 있다. 훈련 데이터에 의하여 학습된 인공 신경망은, 입력 데이터를 입력 데이터가 가지는 패턴에 따라 분류하거나 군 집화 할 수 있다. 한편 훈련 데이터를 이용하여 학습된 인공 신경망을, 본 명세서에서는 학습 모델(a trained model)이라 명칭 할 수 있다.다음은 인공 신경망의 학습 방식에 대하여 설명한다. 인공 신경망의 학습 방식은 크게, 지도 학습, 비 지도 학습, 준 지도 학습(Semi-Supervised Learning), 강화 학 습(Reinforcement Learning)으로 분류될 수 있다. 지도 학습은 훈련 데이터로부터 하나의 함수를 유추해내기 위한 기계 학습의 한 방법이다. 그리고 이렇게 유추되는 함수 중, 연속 적인 값을 출력하는 것을 회귀분석(Regression)이라 하고, 입력 벡터의 클래스(class)를 예측하여 출력하는 것을 분류(Classification)라고 할 수 있다. 지도 학습에서는, 훈련 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시킨다. 여기서 레이블이란, 훈련 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결 과 값)을 의미할 수 있다. 본 명세서에서는 훈련 데이터가 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과값)을 레이블 또 는 레이블링 데이터(labeling data)이라 명칭 한다. 또한 본 명세서에서는, 인공 신경망의 학습을 위하여 훈련 데이터에 레이블을 설정하는 것을, 훈련 데이터에 레 이블링 데이터를 레이블링(labeling) 한다고 명칭 한다. 이 경우 훈련 데이터와 훈련 데이터에 대응하는 레이블)은 하나의 트레이닝 셋(training set)을 구성하고, 인공 신경망에는 트레이닝 셋의 형태로 입력될 수 있다. 한편 훈련 데이터는 복수의 특징(feature)을 나타내고, 훈련 데이터에 레이블이 레이블링 된다는 것은 훈련 데 이터가 나타내는 특징에 레이블이 달린다는 것을 의미할 수 있다. 이 경우 훈련 데이터는 입력 객체의 특징을 벡터 형태로 나타낼 수 있다. 인공 신경망은 훈련 데이터와 레이블링 데이터를 이용하여, 훈련 데이터와 레이블링 데이터의 연관 관계에 대한 함수를 유추할 수 있다. 그리고, 인공 신경망에서 유추된 함수에 대한 평가를 통해 인공 신경망의 파라미터가 결정(최적화)될 수 있다. 비 지도 학습은 기계 학습의 일종으로, 훈련 데이터에 대한 레이블이 주어지지 않는다. 구체적으로, 비 지도 학습은, 훈련 데이터 및 훈련 데이터에 대응하는 레이블의 연관 관계 보다는, 훈련 데이터 자체에서 패턴을 찾아 분류하도록 인공 신경망을 학습시키는 학습 방법일 수 있다. 비 지도 학습의 예로는, 군집화 또는 독립 성분 분석(Independent Component Analysis)을 들 수 있다. 본 명세서에서 용어 '군집화'는 용어 '클러스터링'과 혼용되어 사용될 수 있다. 비지도 학습을 이용하는 인공 신경망의 일례로 생성적 적대 신경망(Generative Adversarial Network; GAN), 오 토 인코더(Autoencoder; AE)를 들 수 있다. 생성적 적대 신경망이란, 생성기(generator)와 판별기(discriminator), 두 개의 서로 다른 인공지능이 경쟁하며 성능을 개선하는 머신 러닝 방법이다. 이 경우 생성기는 새로운 데이터를 창조하는 모형으로, 원본 데이터를 기반으로 새로운 데이터를 생성할 수 있 다. 또한 판별기는 데이터의 패턴을 인식하는 모형으로, 입력된 데이터가 원본 데이터인지 또는 생성기에서 생성한 새로운 데이터인지 여부를 감별하는 역할을 수행할 수 있다. 그리고 생성기는 판별기를 속이지 못한 데이터를 입력 받아 학습하며, 판별기는 생성기로부터 속은 데이터를 입 력 받아 학습할 수 있다. 이에 따라 생성기는 판별기를 최대한 잘 속이도록 진화할 수 있고, 판별기는 원본 데 이터와 생성기에 의해 생성된 데이터를 잘 구분하도록 진화할 수 있다. 오토 인코더는 입력 자체를 출력으로 재현하는 것을 목표로 하는 신경망이다. 오토 인코더는 입력층, 적어도 하나의 은닉층 및 출력층을 포함한다. 이 경우 은닉 계층의 노드 수가 입력 계층의 노드 수보다 적으므로 데이터의 차원이 줄어들게 되며, 이에 따라 압축 또는 인코딩이 수행되게 된다.또한 은닉 계층에서 출력한 데이터는 출력 계층으로 들어간다. 이 경우 출력 계층의 노드 수는 은닉 계층의 노 드 수보다 많으므로, 데이터의 차원이 늘어나게 되며, 이에 따라 압축 해제 또는 디코딩이 수행되게 된다. 한편 오토 인코더는 학습을 통해 뉴런의 연결 강도를 조절함으로써 입력 데이터가 은닉층 데이터로 표현된다. 은닉층에서는 입력층보다 적은 수의 뉴런으로 정보를 표현하는데 입력 데이터를 출력으로 재현할 수 있다는 것 은, 은닉층이 입력 데이터로부터 숨은 패턴을 발견하여 표현했다는 것을 의미할 수 있다. 준 지도 학습은 기계 학습의 일종으로, 레이블이 주어진 훈련 데이터와 레이블이 주어지지 않은 훈련 데이터를 모두 사용하는 학습 방법을 의미할 수 있다. 준 지도 학습의 기법 중 하나로, 레이블이 주어지지 않은 훈련 데이터의 레이블을 추론한 후 추론된 라벨을 이 용하여 학습을 수행하는 기법이 있으며, 이러한 기법은 레이블링에 소요되는 비용이 큰 경우에 유용하게 사용될 수 있다. 강화 학습은, 에이전트(Agent)가 매 순간 어떤 행동을 해야 좋을지 판단할 수 있는 환경이 주어진다면, 데이터 없이 경험으로 가장 좋을 길을 찾을 수 있다는 이론이다. 강화 학습은 주로 마르코프 결정 과정(Markov Decision Process; MDP)에 의하여 수행될 수 있다. 마르코프 결정 과정을 설명하면, 첫 번째로 에이전트가 다음 행동을 하기 위해 필요한 정보들이 구성된 환경이 주어지며, 두 번째로 그 환경에서 에이전트가 어떻게 행동할지 정의하고, 세 번째로 에이전트가 무엇을 잘하면 보상(reward)을 주고 무엇을 못하면 벌점(penalty)을 줄지 정의하며, 네 번째로 미래의 보상이 최고점에 이를 때까지 반복 경험하여 최적의 정책(policy)을 도출하게 된다. 인공 신경망은 모델의 구성, 활성 함수(Activation Function), 손실 함수(Loss Function) 또는 비용 함수(Cost Function), 학습 알고리즘, 최적화 알고리즘 등에 의해 그 구조가 특정되며, 학습 전에 하이퍼파라미터 (Hyperparameter)가 미리 설정되고, 이후에 학습을 통해 모델 파라미터(Model Parameter)가 설정되어 내용이 특 정될 수 있다. 예컨대, 인공 신경망의 구조를 결정하는 요소에는 은닉층의 개수, 각 은닉층에 포함된 은닉 노드의 개수, 입력 특징 벡터(Input Feature Vector), 대상 특징 벡터(Target Feature Vector) 등이 포함될 수 있다. 하이퍼파라미터는 모델 파라미터의 초기값 등과 같이 학습을 위하여 초기에 설정하여야 하는 여러 파라미터들을 포함한다. 그리고, 모델 파라미터는 학습을 통하여 결정하고자 하는 여러 파라미터들을 포함한다. 예컨대, 하이퍼파라미터에는 노드 간 가중치 초기값, 노드 간 편향 초기값, 미니 배치(Mini-batch) 크기, 학습 반복 횟수, 학습률(Learning Rate) 등이 포함될 수 있다. 그리고, 모델 파라미터에는 노드 간 가중치, 노드 간 편향 등이 포함될 수 있다. 손실 함수는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표(기준)로 이용될 수 있다. 인공 신경망에서 학습은 손실 함수를 줄이기 위하여 모델 파라미터들을 조작하는 과정을 의미하며, 학습 의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수는 주로 평균 제곱 오차(Mean Squared Error; MSE) 또는 교차 엔트로피 오차(Cross Entropy Error; EPP)를 사용할 수 있으며, 본 발명이 이에 한정되지는 않는다. 교차 엔트로피 오차는 정답 레이블이 원 핫 인코딩(one-hot encoding)된 경우에 사용될 수 있다. 원 핫 인코딩 은 정답에 해당하는 뉴런에 대하여만 정답 레이블 값을 1로, 정답이 아닌 뉴런은 정답 레이블 값이 0으로 설정 하는 인코딩 방법이다. 머신 러닝 또는 딥 러닝에서는 손실 함수를 최소화하기 위하여 학습 최적화 알고리즘을 이용할 수 있으며, 학습 최적화 알고리즘에는 경사 하강법(Gradient Descent; GD), 확률적 경사 하강법(Stochastic Gradient Descent; SGD), 모멘텀(Momentum), NAG(Nesterov Accelerate Gradient), Adagrad, AdaDelta, RMSProp, Adam, Nadam 등 이 있다. 경사 하강법은 현재 상태에서 손실 함수의 기울기를 고려하여 손실 함수값을 줄이는 방향으로 모델 파라미터를 조정하는 기법이다. 모델 파라미터를 조정하는 방향은 스텝(step) 방향, 조정하는 크기는 스텝 사이즈(size)라고 칭한다. 이때, 스텝 사이즈는 학습률을 의미할 수 있다. 경사 하강법은 손실 함수를 각 모델 파라미터들로 편미분하여 기울기를 획득하고, 모델 파라미터들을 획득한 기 울기 방향으로 학습률만큼 변경하여 갱신할 수 있다. 확률적 경사 하강법은 학습 데이터를 미니 배치로 나누고, 각 미니 배치마다 경사 하강법을 수행하여 경사 하강 의 빈도를 높인 기법이다. Adagrad, AdaDelta 및 RMSProp는 SGD에서 스텝 사이즈를 조절하여 최적화 정확도를 높이는 기법이다. SGD에서 모멘텀 및 NAG는 스텝 방향을 조절하여 최적화 정확도를 높이는 기법이다. Adam은 모멘텀과 RMSProp를 조합하여 스텝 사이즈와 스텝 방향을 조절하여 최적화 정확도를 높이는 기법이다. Nadam은 NAG와 RMSProp를 조합하여 스 텝 사이즈와 스텝 방향을 조절하여 최적화 정확도를 높이는 기법이다. 인공 신경망의 학습 속도와 정확도는 인공 신경망의 구조와 학습 최적화 알고리즘의 종류뿐만 아니라, 하이퍼파 라미터에 크게 좌우되는 특징이 있다. 따라서, 좋은 학습 모델을 획득하기 위하여는 적당한 인공 신경망의 구조 와 학습 알고리즘을 결정하는 것뿐만 아니라, 적당한 하이퍼파라미터를 설정하는 것이 중요하다. 통상적으로 하이퍼파라미터는 실험적으로 다양한 값으로 설정해가며 인공 신경망을 학습시켜보고, 학습 결과 안 정적인 학습 속도와 정확도를 제공하는 최적의 값으로 설정한다. 한편, 인공신경망의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight)를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공신경망은 학습에 의해 웨이 트(weight) 값을 지속적으로 업데이트시킬 수 있다. 또한, 인공신경망의 학습에는 역전파(back propagation) 등 의 방법이 사용될 수 있다. 이하, 본 발명에 따른 실시예들을 첨부된 도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설명 함에 있어, 동일하거나 대응하는 구성 요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하기 로 한다. 도 1은 본 개시의 일 실시예에 따른 웨어러블 디바이스를 제1 방향에서 바라본 사시도를 도시하고, 도 2는 본 개시의 일 실시예에 따른 웨어러블 디바이스를 제2 방향에서 바라본 사시도를 도시한다. 본 개시의 일 실시예에 따른 웨어러블 디바이스는 증강현실 안경으로서 구성될 수 있다. 웨어러블 디바이스 는 사용자의 머리에 착용되도록 구성된 프레임을 포함한다. 프레임은 사용자의 이마 또는 눈썹 을 가로지르도록 구성된 전방 프레임 및 전방 프레임의 양단으로부터 사용자의 귀로 연장되는 한 쌍 의 다리 프레임들을 포함한다. 전방 프레임은 사용자의 코 위에 놓이도록 구성된 코받이 (nosepad)를 포함한다. 웨어러블 디바이스는 사용자의 시야의 적어도 일부를 포함하는 이미지를 포착하도록 구성된 전방 카메라 를 포함한다. 전방 카메라는 사용자의 얼굴이 향하는 방향을 향하도록 프레임 상에 장착된다. 전방 카메라는, 예를 들어, 전방 프레임과 다리 프레임을 연결하는 엔드피스(endpiece) 상 에 장착된다. 웨어러블 디바이스는 사용자에 의해 착용될 때 사용자의 시야 내에 놓이는 증강 현실(AR) 디스플레이(13 0)를 포함한다. AR 디스플레이는, 예를 들어, 투명 디스플레이를 포함한다. 투명 디스플레이는 전기 신호 가 인가되지 않을 때에는 투명하게 유지되고, 전기 신호가 인가될 때 일부 영역에서 시각적인 콘텐츠를 표시하 도록 구성된다. 본원에서, 용어 \"투명(transparent)\"은 광을 100% 투과하는 것만이 아니라 광의 일부(예를 들어, 10% 이상)를 투과하는 것을 포함하는 의미로 사용된다. 즉, 투명 디스플레이는 반투명(translucent) 디스 플레이를 포함한다. AR 디스플레이는 프로젝터 및 투명한 프리즘을 포함한다. 프로젝터는 프레임의 엔드 피스 상에 장착되고, 전기 신호에 응답하여 프리즘을 향하여 광을 투사하도록 구성된다. 프리즘(13 2)은 사용자의 시야 내에 배치되고, 프로젝터에 의해 방출되는 광의 적어도 일부를 사용자의 눈을 향하여 반사하도록 구성된다. 프로젝터가 광을 방출하지 않을 때 프리즘은 외부의 광을 투과하고, 프로젝터 가 광을 방출할 때 프리즘은 투과된 외부의 광과 프로젝터로부터의 광을 결합시킨다. 이러한 방식으로, AR 디스플레이는 실제 세상의 이미지 상에 프로젝터에 의해 생성된 시각적 콘텐츠(visual contents)를 중첩하여 표시할 수 있다. 웨어러블 디바이스는 전기 신호를 음향파(acoustic wave)로 변환하여 사용자에게 소리를 제공하도록 구성 된 음향 출력기를 포함한다. 음향 출력기는 예를 들어 사용자에 의해 착용될 때 사용자의 귀에 삽입 가능하게 구성된 이어폰을 포함한다. 음향 출력기는 사용자의 귀에 삽입되지 않는 골전도 이어폰이거나, 또는 스피커일 수도 있다. 웨어러블 디바이스는 사용자의 음성을 검출하여 음향 신호를 생성하도록 구성된 마이크로폰를 포함한 다. 마이크로폰는 예를 들어 한 쌍의 다리 프레임들 중 하나에 배열될 수 있다. 웨어러블 디바이스는 사용자의 터치 입력를 수신하도록 구성된 터치 입력기를 포함한다. 터치 입력기 는 예를 들어 우측 다리 프레임의 외측 표면 상에 배열될 수 있다. 터치 입력기는 버튼 또는 터 치 패드 중 적어도 하나를 포함한다. 웨어러블 디바이스는 사용자에 의해 착용될 때 동공(pupil)의 이미지를 검출하여 동공 이미지 신호를 생성 하도록 구성된 동공 카메라를 포함한다. 동공 카메라는 예를 들어 전방 프레임의 뒷면에서 사용 자의 눈에 대응하는 위치에 장착된다. 동공 카메라는 동공의 방향 및 동공의 움직임을 검출할 수 있다. 웨어러블 디바이스는 하나 이상의 생체측정 센서들을 포함한다. 생체측정 센서는 사용자의 관자 놀이와 접촉하여 맥박을 감지하고, 맥박 신호를 생성하도록 구성된 맥박 센서를 포함할 수 있다. 맥박 센 서는 한 쌍의 다리 프레임에서 사용자의 관자놀이에 대응하는 위치에 장착된다. 생체측정 센서는 뇌파를 감지하여 뇌파 신호를 생성하도록 구성된 뇌전도(electroencephalography; EEG) 센서를 포함할 수 있다. EEG 센서는 예를 들어 다리 프레임의 단부(temple tip)에 위치될 수 있 다. 웨어러블 디바이스는 웨어러블 디바이스의 동작을 위한 전력을 제공하기 위한 배터리(미도시)를 포함 한다. 배터리는 예를 들어 다리 프레임의 내부에 내장(embed)될 수 있다. 웨어러블 디바이스는 프레임의 내부에 내장된 무선 트랜시버, 위치신호 수신기, 및 제어기를 포함한 다. 무선 트랜시버, 위치신호 수신기, 및 제어기의 상세한 설명은 도 3을 참조하여 아래에 설명된다. 도 3은 본 개시의 일 실시예에 따른 웨어러블 디바이스의 개략적인 블록도를 도시한다. 웨어러블 디바이스(10 0)는 무선 트랜시버, 위치결정 신호 수신기, 및 제어기를 포함한다. 무선 트랜시버는 하나 이상의 무선 통신 기술을 이용하여 원격의 디바이스, 원격의 서버, 액세스 포인트, 기지국, 또는 이동통신 코어 네트워크와 통신하도록 구성된다. 특히, 무선 트랜시버는 이미지, 음성, 생체 신호 중 적어도 하나를 분석하도록 구성된 인공 신경망 및 객체 정보 데이터베이스를 포함하는 원격의 클라우드 서버와 통신할 수 있다. 무선 트랜시버는, 예를 들어, 롱-텀 에볼루션(LTE), 5세대(5G) 셀룰러 네트워크, 블루투스, 적외선 데이터 협회(Infrared Data Association; IrDA), 사물 인터넷(Internet of Things; IoT), 로컬 영역 네트워크(Local Area Network; LAN), 저전력 네트워크(Low Power Network; LPN), 저전력 광역 네트워크(Low Power Wide Area Network; LPWAN), 개인 영역 네트워크(Personal Area Network; PAN), 무선 주파수 식별(Radio Frequency Identification; RFID), 초광대역(Ultra-wide Band; UWB), Wi-Fi(Wireless Fidelity), 무선 LAN(WLAN), 또는 ZigBee 통신 기술들 중 하나 이상을 이용할 수 있으나, 이에 한정되는 것은 아니다. 위치결정 신호 수신기는 웨어러블 디바이스의 위치를 결정하기 위해 위치결정 신호를 수신하도록 구 성된다. 위치결정 신호 수신기는, 예를 들어, 글로벌 위치결정 시스템(Global Positioning System)으로부 터 GPS 신호를 수신하는 GPS 수신기를 포함한다. 위치결정 신호 수신기는 무선 트랜시버 내에 통합되 어, 위치를 결정하기 위해 액세스 포인트 또는 기지국으로부터 신호를 수신할 수도 있다. 제어기는, 전방 카메라, AR 디스플레이, 음향 출력기, 마이크로폰, 터치 입력기 , 동공 카메라, 생체측정 센서, 무선 트랜시버, 및 위치결정 신호 수신기와 상호 작 용하여 웨어러블 디바이스의 동작을 제어하도록 구성된다. 예를 들어, 제어기는, 전방 카메라, 마이크로폰, 터치 입력기, 동공 카메라, 및 생체측정 센서로부터 신호를 수신하고, 그리고사용자에게 시각적으로 또는 음향적으로 정보를 제공하도록 AR 디스플레이 또는 음향 출력기의 동작 을 제어한다. 후술하는 웨어러블 디바이스의 동작들은, 명시적으로 기재되어 않는 한, 제어기에 의해 수행되는 것으로 이해될 수 있다. 제어기는, 예를 들어 메모리에 저장된 프로그램에 포함된 코드들 또는 명령어들로 표현된 기능들을 수행하 기 위해 구조화된 회로를 갖는 하나 이상의 프로세서를 포함할 수 있다. 하나 이상의 프로세서는, 예를 들어, 마이크로프로세서, 중앙처리장치(Central Processing Unit; CPU), 프로세서 코어, 멀티프로세서, 이미지 프로세 서, 신경 프로세서, 주문형 집적회로(Application-Specific Integrated Circuit; ASIC), 또는 현장 프로그래머 블 게이트 어레이(Field Programmable Gate Array; FPGA) 중 하나 이상을 포함할 수 있으나, 이에 한정되는 것 은 아니다. 메모리에 저장된 프로그램에 포함된 코드들 또는 명령어들은, 하나 이상의 프로세서에 의해 실행될 때, 제어기의 동작을 수행하도록 구현될 수 있다. 제어기는 객체 식별기, 안면 인식기, 음성 인식기, 감정 인식기, 내비게이션 기능 , 및 객체 정보 데이터베이스를 포함한다. 객체 식별기는 전방 카메라로부터 수신한 이미지 신호를 분석하고, 이미지 신호 내에 포함된 객체를 식별하도록 구성된다. 도 4는 본 개시의 일 실시예에 따른 객체 식별기의 예시적인 동작을 도시한다. 객체 식별 기는 전방 카메라로부터 수신한 이미지 내의 객체의 종류를 식별하도록 머신 러닝을 이용하여 미리 훈련되어 있는 인공 신경망을 포함한다. 예를 들어, 객체 식별기의 인공 신경망은 전방 카 메라로부터 수신한 이미지 내에 존재하는 객체들, 예를 들어, 사람, 자동차, 간판, 시계 등을 식별하 도록 훈련되어 있다. 안면 인식기는 전방 카메라로부터 수신한 사람의 얼굴 이미지를 분석하고, 얼굴 이미지에 해당하는 사람의 신원을 식별하도록 구성된다. 안면 인식기는 얼굴 이미지로부터 사람의 신원을 식별하도록 머신 러 닝을 이용하여 미리 훈련된 인공 신경망을 포함한다. 안면 인식기는 인식된 사람이 예전에 식별되었던 적 이 있는 사람인 경우 인식된 사람의 식별자를 출력할 수 있다. 안면 인식기는 인식된 사람이 새롭게 식별 된 사람인 경우, 인식된 사람에 대해 새로운 식별자를 부여할 수 있다. 음성 인식기(speech recognizer)는 마이크로폰으로부터 수신한 사용자의 음성의 의미를 인식하도록 구성된다. 음성 인식기는 입력된 음성 신호 내에 포함된 단어들을 인식하고 단어들의 배치로부터 음성의 의미를 인식하도록 머신 러닝을 이용하여 미리 훈련된 인공 신경망을 포함한다. 예를 들어, 음성 인식기는 심층 신경망-은닉 마르코프 모델(DNN-HMM)을 이용하여 음성을 인식할 수 있다. 음성 인식기는 음성 내에 포함된 단어들을 출력할 수 있고, 음성의 의미를 미리 결정된 의미 패턴들 중 하나로서 식별할 수도 있다. 감정 인식기는 마이크로폰으로부터 수신한 사용자의 음성, 동공 카메라로부터 수신한 동공의 이 미지, 또는 생체측정 센서로부터 수신한 생체측정 신호(예를 들어, 맥박 및 뇌파) 중 적어도 하나에 기초 하여, 사용자의 심리 상태를 추정하도록 구성된다. 감정 인식기는, 머신 러닝을 이용하여 음성 신호, 동공 이미지, 또는 생체측정 신호 중 적어도 하나로부터 사람의 심리 상태를 결정하도록 미리 훈련된 인공 신경망을 포함한다. 특히, 감정 인식기는 음성, 동공 이미지, 생체측정 신호 중 2 이상으로부터 사람의 감정을 인식 하는 멀티모달(multi-modal) 딥러닝을 이용할 수 있다. 도 5는 본 개시의 일 실시예에 따른 감정 인식기를 위한 멀티모달 심층 신경망의 예시를 도시한다. 멀티모달 딥 러닝은 성질이 다른 복수의 입력을 처리하는 딥러닝 알고리즘으로 각각의 신호 모달리티에서 부족한 정보를 상 호 보완하여 인식 성능을 향상하고자 하는데 목적이 있다. 멀티모달 심층 신경망은 마이크로폰, 동공 카메라, 및 생체측정 센서에 대한 별개의 입력층들(511, 512, 513)을 가진다. 멀티모달 심층 신경망 의 은닉층들은, 상이한 신호 모달리티들에 대한 입력층들 또는 은닉층들과 서로 연결된 적어도 하나 의 은닉층들을 가진다. 멀티모달 심층 신경망은 상이한 신호 모달리티들에 대한 공통의 출력층을 가 진다. 내비게이션 기능은 목적지까지의 경로를 결정하고 결정된 경로를 안내하도록 구성된다. 내비게이션 기능 은 적어도 웨어러블 디바이스의 주변의 영역의 지도를 포함한다. 내비게이션 기능 위치결정 신 호 수신기에 의해 수신된 위치결정 신호에 기초하여 지도 상에서의 웨어러블 디바이스의 위치를 결정 하고, 웨어러블 디바이스의 위치로부터 목적지까지 최단으로 또는 최적으로 이동할 수 있는 경로를 결정한 다. 객체 정보 데이터베이스는 객체 식별기에 의해 식별된 객체의 정보를 저장한다. 객체의 정보는, 객체 의 종류, 객체와 사용자와의 관계, 객체가 식별된 위치, 및 객체가 식별된 날짜 및 시간을 포함한다. 객체가 사 람인 경우, 객체의 정보는 사람의 신원(예를 들어, 이름 또는 식별자)을 더 포함할 수 있다. 상술한 객체 식별기, 안면 인식기, 음성 인식기, 감정 인식기, 내비게이션 기능, 또 는 객체 정보 데이터베이스 중 적어도 하나는 원격의 클라우드 서버에 구현되어 있을 수 있다. 제어 기는, 객체 식별기, 안면 인식기, 음성 인식기, 감정 인식기, 내비게이션 기능 , 또는 객체 정보 데이터베이스 중 적어도 하나를 대신하여 원격의 클라우드 서버를 이용하기 위해 원격의 클라우드 서버와 통신할 수 있다. 도 6은 본 발명의 일 실시예에 따라 웨어러블 디바이스에서 객체의 정보를 수집하기 위한 예시적인 방법의 흐름 도를 도시한다. 단계 S610에서, 웨어러블 디바이스는 전방 카메라로부터 이미지를 획득한다. 전방 카메라로부터 획득되는 이미지는 사용자의 시야의 적어도 일부를 포함한다. 동시에, 웨어러블 디바이스는 동공 카메라 로부터의 동공 이미지 신호를 획득한다. 웨어러블 디바이스는 동공의 이미지에 기초하여 사용자의 응 시 방향을 결정할 수 있다. 단계 S620에서, 웨어러블 디바이스는 전방 카메라로부터 획득된 이미지에 나타나는 객체를 식별한다. 전방 카메라로부터 획득된 이미지는 객체 식별기에 의해 분석된다. 객체 식별기는 이미지에 포 함된 객체를 식별하도록 미리 훈련된 인공 신경망에 전방 카메라로부터 획득된 이미지를 입력하고, 인공 신경망으로부터의 출력에 기초하여 이미지 내에 나타나는 객체들의 종류들을 식별한다. 본 개시의 임의의 다른 실시예들과 결합될 수 있는 추가 실시예에 따르면, 웨어러블 디바이스는 전방 카메 라로부터 획득된 이미지 내에서 사용자의 응시 방향에 존재하는 객체를 식별할 수 있다. 사용자의 응시 방 향은 동공 카메라로부터의 동공의 이미지에 기초하여 결정될 수 있다. 예를 들어, 웨어러블 디바이스(10 0)는 전방 카메라로부터 획득된 이미지 내의 모든 객체들을 식별하는 것이 아니라, 사용자가 응시하는 특 정 영역의 객체만을 식별할 수 있다. 전방 카메라로부터 획득된 이미지가 사람인 경우, 웨어러블 디바이스는 사람의 신원을 식별한다. 사 람의 얼굴의 이미지는 안면 인식기에 의해 분석된다. 안면 인식기는, 얼굴 이미지로부터 사람의 신원 을 식별하도록 미리 훈련된 인공 신경망에 획득된 얼굴의 이미지를 입력하고, 인공 신경망으로부터의 출력에 기 초하여 이미지 내의 사람의 신원을 식별한다. 단계 S630에서, 웨어러블 디바이스는 웨어러블 디바이스의 위치를 결정한다. 제어기는 위치측정 신호 수신기에 의해 수신된 위치측정 신호에 기초하여 웨어러블 디바이스의 위치를 결정한다. 예를 들어, 제어기는 실외의 환경에서 GPS 위성으로부터의 GPS 신호 또는 이동통신 기지국으로부터의 신호 중 적어도 하나에 기초하여 웨어러블 디바이스의 위치를 결정한다. 제어기는 실내 환경에서 이동통신 기지국으 로부터의 신호 또는 Wi-Fi 액세스 포인트로부터의 비콘 신호 중 적어도 하나에 기초하여 웨어러블 디바이스 의 위치를 결정한다. 단계 S640에서, 웨어러블 디바이스는 식별된 객체의 정보를 객체 정보 데이터베이스에 저장한다. 객 체의 정보는 객체의 종류, 객체와 사용자와의 관계, 객체가 식별된 위치, 및 객체가 식별된 날짜 및 시간, 객체 의 이미지을 포함한다. 웨어러블 디바이스는 위치결정 신호 수신기로부터의 위치결정 신호에 기초하 여 객체가 식별된 위치(예를 들어, 위도 및 경도)를 결정하고, 내부 시계에 기초하여 객체가 식별된 시간 정보 (예를 들어, 날짜 및 시간)을 결정한다. 객체가 사람인 경우, 객체의 정보는 사람의 신원을 더 포함한다. 사람 의 신원은 사람의 식별자, 이름, 또는 식별된 사람과 사용자와의 관계 중 적어도 하나를 포함한다. 웨어러블 디바이스는 객체 식별기 또는 안면 인식기 에 의해 식별될 수 없는 부가적인 정보를 사용자에게 문의할 수 있다. 예시적인 시나리오에서, 웨어러블 디바이스는 검출된 객체와 사용자와의 관계 를 결정하기 위해, \"이것은 당신의 지갑입니까?\"라고 문의할 수 있다. 사용자의 음성 응답은 음성 인식기 에 의해 인식될 수 있다. 다른 예시적인 시나리오에서, 웨어러블 디바이스는 새로운 사람이 식별되는 경우, \"이 사람은 누구입니까?\"라고 문의하고, 사용자의 응답으로부터 식별된 사람의 이름 또는 식별된 사람과 사용자와의 관계(예를 들어, 가족 관계 또는 동료 관계)를 결정할 수 있다. 웨어러블 디바이스는 객체의 종류, 객체의 이름, 객체와 사용자와의 관계, 위치, 시간 정보, 및 전방 카메 라에 의해 획득된 객체의 이미지를 객체 정보 데이터베이스에 저장한다. 객체 정보 데이터베이스는 원격의 클라우드 서버에 위치할 수도 있다. 제어기는 객체의 정보를 객체 정보 데이터베이스에 저장하기 위해, 무선 트랜시버를 이용하여 객체의 정보를 원격의 클라우드 서버로 전송한다. 본 개시의 임의의 다른 실시예들과 결합될 수 있는 추가 실시예에 따르면, 제어기는 사용자의 요청이 있을 때 이미지 내의 객체의 정보를 저장할 수 있다. 예를 들어, 제어기는 사용자가 터치 입력기를 터치할 때 이미지 내에 나타나는 객체의 정보를 객체 정보 데이터베이스에 저장한다. 도 7은 본 개시의 일 실시예에 따른 웨어러블 디바이스에서 정보를 제공하기 위한 예시적인 방법의 흐름도를 도 시한다. 단계 S710에서 웨어러블 디바이스는 마이크로폰으로부터 음향 신호에 기초하여, 사용자의 음성을 검 출한다. 웨어러블 디바이스는 사람의 음성의 주파수 대역에서 임계 크기(magnitude)보다 큰 소리가 마이크 로폰에 의해 검출될 때, 사용자의 음성이 검출된다고 결정할 수 있다. 예시적인 시나리오에서, 웨어러블 디바이스는 \"하이, 엘지. 내 랩탑 컴퓨터 어디있지?\"라는 사용자의 음성을 검출할 수 있다. 단계 S720에서 웨어러블 디바이스는 검출된 사용자의 음성이 특정 객체에 대한 사용자의 쿼리라고 결정한 다. 제어기는 마이크로폰으로부터 수신한 음향 신호로부터 사람의 음성의 주파수 대역 밖의 성분들을 제거하여 사용자의 음성 신호를 추출한다. 추출된 사용자의 음성 신호는 음성 인식기(speech recognizer) 에 의해 분석된다. 음성 인식기는, 음성 인식 모델로부터의 출력에 기초하여 사람의 음성이 사용자의 랩탑 컴퓨터의 위치에 대한 쿼리라고 결정한다. 단계 S730에서, 웨어러블 디바이스는 쿼리의 대상이 되는 객체의 정보를 객체 정보 데이터베이스로부터 검 색(retrieve)한다. 예를 들어, 제어기는 사용자의 랩탑 컴퓨터의 정보를 로컬 객체 정보 데이터베이스 또는 원격의 클라우드 서버로부터 검색한다. 단계 S740에서, 웨어러블 디바이스는 검색된 객체의 정보, 특히 쿼리와 관련된 정보를 AR 디스플레이 또는 음향 출력기 중 적어도 하나를 이용하여 출력한다. 예를 들어, 웨어러블 디바이스는 AR 디스플 레이 상에서 랩탑 컴퓨터의 이미지와 함께 사용자의 랩탑이 최종적으로 식별된 위치를 지도 상의 점 또는 화살표로 표시할 수 있다. 웨어러블 디바이스는 음향 출력기를 이용하여, 예를 들어, \"랩탑 컴퓨터는 3번 미팅룸의 테이블 위에 있어요\"와 같이 음성으로 객체의 정보를 출력할 수 있다. 도 8은 본 개시의 추가 실시예에 따른 웨어러블 디바이스에서 정보를 제공하기 위한 예시적인 방법의 흐름도를 도시한다. 단계 S810에서 웨어러블 디바이스는 적어도 하나의 센서로부터 센서 신호를 모니터링한다. 적어도 하나의 센서는, 전방 카메라, 마이크로폰, 동공 카메라, 및 생체측정 센서를 포함한다. 웨어러블 디바이스는 마이크로폰으로부터 음향 신호에 기초하여, 사용자의 음성을 검출한다. 웨어러 블 디바이스는 사람의 음성의 주파수 대역에서 임계 크기(magnitude)보다 큰 소리가 마이크로폰에 의 해 검출될 때, 사용자의 음성이 검출된다고 결정할 수 있다. 예시적인 시나리오에서, 웨어러블 디바이스는 \"아! 내 지갑!\"이라는 사용자의 음성을 검출할 수 있다. 동시에, 웨어러블 디바이스는 동공 카메라를 이용하여 사용자의 동공의 이미지를 검출할 수 있고, 생체측정 센서를 이용하여 사용자의 생체측정 신호 (예를 들어, 맥박 또는 뇌파)를 검출할 수 있다. 단계 S620에서 웨어러블 디바이스는 사용자의 음성의 톤(tone), 사용자의 동공의 움직임, 맥박의 변화, 또 는 뇌파의 변화 중 적어도 하나에 기초하여, 사용자가 당황했다는 것을 결정한다. 예를 들어, 웨어러블 디바이 스는 사용자의 동공의 크기가 확장되고 맥박이 증가할 때 사용자가 당황했다고 결정할 수 있다. 사용자가 당황했다는 사실은 사용자가 객체를 잃어버렸다는 것, 즉 객체의 위치 정보를 필요로 한다는 것을 의미할 수 있 다. 사용자가 당황했는지 여부는 감정 인식기에 의해 분석된다. 감정 인식기는 마이크로폰으로부터 의 음성 신호, 동공 카메라로부터의 동공 이미지, 또는 생체측정 센서로부터의 생체측정 신호 중 적어도 하나를, 예를 들어, 멀티모달 심층 신경망에 입력함으로써 사용자의 심리 상태를 분석할 수 있다. 단계 S830에서 웨어러블 디바이스는 사용자가 정보를 필요로 하는 객체를 특정한다. 사용자가 정보를 필요 로 하는 객체는 사용자의 음성에 의해 특정될 수 있다. 예시적인 시나리오에서, 웨어러블 디바이스는 마이 크로폰에 의해 \"아! 내 지갑!\"이라는 사용자의 음성을 검출하면, 웨어러블 디바이스는 사용자가 지갑 을 잃어버렸고 지갑의 위치 정보를 필요로 한다고 결정할 수 있다. 사용자가 정보를 필요로 하는 객체는 전방 카메라로부터의 이미지에 의해 특정될 수도 있다. 다른 예시적 인 시나리오에서, 사용자는 예전에 만난적이 있는 사람의 이름을 기억하지 못할 수 있다. 웨어러블 디바이스 는 전방 카메라와 동공 카메라로부터의 이미지 신호들에 기초하여, 사용자가 당황한 채 특정 사 람을 응시하고 있다는 것을 결정하고, 그리고 사용자가 특정 사람의 정보(예를 들어, 이름)를 필요로 한다고 결 정할 수 있다. 단계 S840에서 웨어러블 디바이스는 특정된 객체의 정보를 객체 정보 데이터베이스로부터 검색(retrieve) 한다. 예시적인 시나리오에서, 사용자가 지갑의 위치 정보를 필요로 하는 경우, 웨어러블 디바이스는 \"사용자의 지갑\"을 검색 쿼리로 하여, 객체 정보 데이터베이스로부터 사용자의 지갑의 정보를 검색한다. 웨어러블 디바이 스는 객체 정보 데이터베이스로부터의 사용자의 지갑의 최종적으로 식별된 위치, 날짜 및 시간, 및 최종적 으로 획득된 이미지를 획득할 수 있다. 다른 예시적인 시나리오에서, 사용자가 응시하고 있는 사람의 이름을 필요로 하는 경우, 웨어러블 디바이스 는 전방 카메라를 통해 획득된 사람의 이미지를 검색 쿼리로 이용하여, 객체 정보 데이터베이스로부 터 사람의 정보를 검색한다. 이때, 웨어러블 디바이스는 전방 카메라를 통해 획득된 이미지로부터, 사용자가 응시하는 것으로 결정된 영역 내의 사람의 이미지만을 크롭하고, 크롭된 이미지를 검색 쿼리로 이용할 수 있다. 웨어러블 디바이스는 객체 정보 데이터베이스로부터 이미지에 대응하는 사람의 이름, 사용자와의 관계, 최종적으로 식별된 위치, 날짜 및 시간의 정보를 획득할 수 있다. 단계 S850에서, 웨어러블 디바이스는 검색된 객체의 정보를 AR 디스플레이 또는 음향 출력기 중 적어도 하나를 이용하여 출력한다. 예를 들어, 웨어러블 디바이스는 AR 디스플레이 상에서 최종적으 로 획득된 지갑의 이미지와 함께 사용자의 지갑이 최종적으로 식별된 위치를 지도 상의 점 또는 화살표로 표시 할 수 있다. 다른 예로서, 웨어러블 디바이스는 AR 디스플레이 상에서 사람의 정보를 사람의 실제의 이미지 상에 중첩하여 표시할 수 있다. 예를 들어, 웨어러블 디바이스는 실제 사람의 얼굴이 투과되는 AR 디스플레이 의 영역에 사람의 이름, 사용자와의 관계, 및 부가 정보들을 표시할 수 있다. 도 9는 본 개시의 일 실시예에 따른 웨어러블 디바이스에서 위치 정보를 제공하기 위한 예시적인 방법의 흐름도 를 도시한다. 사용자가 객체의 위치 정보를 필요로 하는 경우, 웨어러블 디바이스는 객체가 최종적으로 식 별된 위치까지의 내비게이션 정보를 제공한다. 단계 S910에서, 웨어러블 디바이스는 사용자가 찾고 있는 객체의 최종적으로 식별된 위치를 결정한다. 객 체의 위치는 객체 정보 데이터베이스로부터 획득될 수 있다. 단계 S920에서, 웨어러블 디바이스는 웨어러블 디바이스의 현재 위치를 결정한다. 웨어러블 디바이스 의 위치는 위치결정 신호 수신기에 의해 수신된 위치결정 신호에 기초하여 결정될 수 있다. 단계 S930에서, 웨어러블 디바이스 웨어러블 디바이스의 위치로부터 객체의 위치까지의 경로를 결정한다. 웨어러블 디바이스의 내비게이션 기능은 지도 정보를 이용하여 객체의 위치까지의 최단 경로 또는 최 적 경로를 결정할 수 있다. 단계 S940에서, 웨어러블 디바이스는 AR 디스플레이 및 음향 출력기 중 적어도 하나를 이용하여 객체의 위치까지의 내비게이션 정보를 출력한다. 웨어러블 디바이스는 사용자가 진행하여야 할 방향 및 거 리를, 예를 들어 화살표로, AR 디스플레이 상에 표시하여, 사용자가 효과적으로 객체의 위치까지 도달할 수 있도록 도울 수 있다. 이상 설명된 본 발명의 실시예들에 따른 방법은 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨 터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기 록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래 시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 디바이스를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 개시에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값 을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 개시에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명의 실시예를 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발 명의 범위가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2019-0124008", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 웨어러블 디바이스를 제1 방향에서 바라본 사시도를 도시한다. 도 2는 본 개시의 일 실시예에 따른 웨어러블 디바이스를 제2 방향에서 바라본 사시도를 도시한다. 도 3은 본 개시의 일 실시예에 따른 웨어러블 디바이스의 개략적인 블록도를 도시한다. 도 4는 본 개시의 일 실시예에 따른 객체 식별기의 예시적인 동작을 도시한다. 도 5는 본 개시의 일 실시예에 따른 감정 인식기를 위한 멀티모달 심층 신경망의 예시를 도시한다. 도 6은 본 발명의 일 실시예에 따라 웨어러블 디바이스에서 객체의 정보를 수집하기 위한 예시적인 방법의 흐름 도를 도시한다. 도 7은 본 개시의 일 실시예에 따른 웨어러블 디바이스에서 정보를 제공하기 위한 예시적인 방법의 흐름도를 도 시한다. 도 8은 본 개시의 추가 실시예에 따른 웨어러블 디바이스에서 정보를 제공하기 위한 예시적인 방법의 흐름도를 도시한다. 도 9는 본 개시의 일 실시예에 따른 웨어러블 디바이스에서 위치 정보를 제공하기 위한 예시적인 방법의 흐름도 를 도시한다."}
