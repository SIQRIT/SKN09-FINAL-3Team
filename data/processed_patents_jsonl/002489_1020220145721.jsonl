{"patent_id": "10-2022-0145721", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0064086", "출원번호": "10-2022-0145721", "발명의 명칭": "전이학습을 기반으로 한 의료 영상 정합 장치 및 그 방법", "출원인": "가톨릭관동대학교산학협력단", "발명자": "최안렬"}}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "환자 공간의 영상 데이터와 의료 영상 데이터를 정밀 정합하는 의료 영상 정합 장치에 있어서,상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 수신하는 입력부;프로브를 통해 수집되는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 기반으로 정밀 정합을 위한회전 및 병진 변환 행렬 값을 추정하는 전이학습 기반 소스 인공 지능 모델 및 타겟 인공 지능 모델이 저장된인공 지능 모델 저장부; 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 정밀 정합하는 정합부; 및 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터의 정합 결과물을 출력하는 출력부;를 포함하며상기 정합부는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 개략적으로 정합하여 제1정합 좌표점을 생성하는 제1정합부;상기 제1정합 좌표점과 상기 의료 영상 데이터의 표면 좌표점을 정합하여 제2 정합 좌표점을 생성하는 제2정합부; 및상기 제2정합 좌표점을 상기 타겟 인공 지능 모델의 입력으로 하여 추정된 상기 회전 및 병진 변환 행렬을 기반으로 정밀 정합하는 제3정합부를 포함하는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 소스 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴표면 좌표점에 대응되는 상기 의료 영상 데이터의 표면 좌표점, 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위치좌표점을 포함하는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 팬텀 병변 위치 좌표점은 가상의 병변 구조물에 임의로 지정한 병변 후보군의 위치 좌표점이며, 상기 팬텀 영상 병변 위치 좌표점은 상기 병변 구조물을 촬영한 영상 데이터에서 상기 병변 후보군의 위치 정보와 대응되는 위치 좌표점을 포함하는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 타겟 인공 지능 모델은 상기 의료 영상 데이터를 3D 형태로 형성하고, 상기 형성된 3D 의료 영상 데이터를분할하여 상기 병변의 위치를 확인하고, 상기 확인된 병변 위치를 기반으로 상기 소스 인공 지능 모델의 학습 데이터 세트를 재구성함으로써, 상기 타겟인공 지능 모델의 학습 데이터를 추출하는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0064086-3-제1항에 있어서, 상기 타겟 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴표면 좌표점에 대응되는 의료 영상 데이터로 설정되는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 타겟 인공 지능 모델은 상기 소스 인공 지능 모델의 특정 레이어에서 상기 타겟 인공 지능 모델의 특정 레이어로 가중치와 편향을 전이 받거나 전이 받지 않고 재학습되는 것인 의료 영상 정합 장치."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "환자 공간의 영상 데이터와 의료 영상 데이터를 정밀 정합 하는 의료 영상 정합 방법에 있어서, a) 프로브를 통해 수집되는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 획득하는 단계;b) 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터로부터 개략적으로 좌표점을 추출하여 정합하고, 개략적인 회전 및 병진 변환 행렬을 추출하는 단계;c) 상기 개략적으로 정합된 좌표점과 상기 환자 공간의 영상 데이터로부터 추출된 얼굴 표면 좌표점을 추출된상기 개략적인 회전 및 병진 변환 행렬을 이용하여 제1정합하고 제1정합 좌표점을 생성하는 단계;d) 상기 제1정합 데이터를 증강시키고, 증강된 제 1정합 좌표점을 상기 의료 영상 데이터로부터 추출된 표면 좌표점과 정합하여 제2정합 좌표점을 생성하는 단계;및e) 상기 제2정합 좌표점을 타겟 인공 지능 모델의 입력으로 하여 추정된 상기 회전 및 병진 변환 행렬을 기반으로 정밀 정합하는 단계;를 포함하며, 상기 인공 지능 모델은 전이학습 기반 소스 인공 지능 모델 및 상기 타겟 인공 지능 모델을 포함하는 것인 의료영상 정합 방법."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 소스 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴표면 좌표점에 대응되는 상기 의료 영상 데이터의 표면 좌표점, 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위치좌표점을 포함하는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 팬텀 병변 위치 좌표점은 가상의 병변 구조물에 임의로 지정한 병변 후보군의 위치 좌표점이며, 상기 팬텀 영상 병변 위치 좌표점은 상기 병변 구조물을 촬영한 영상 데이터에서 상기 병변 후보군의 위치 정보와 대응되는 위치 좌표점을 포함하는 것인 의료 영상 정합 방법"}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 타겟 인공 지능 모델은 상기 의료 영상 데이터를 3D 형태로 형성하고, 상기 형성된 3D 의료 영상 데이터를공개특허 10-2024-0064086-4-분할하여 상기 병변의 위치를 확인하고, 상기 확인된 병변 위치를 기반으로 상기 소스 인공 지능 모델의 학습 데이터 세트를 재구성함으로써, 상기 타겟인공 지능 모델의 학습 데이터를 추출하는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 타겟 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴표면 좌표점에 대응되는 의료 영상 데이터로 설정되는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2022-0145721", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 타겟 인공 지능 모델은 상기 소스 인공 지능 모델의 특정 레이어에서 상기 타겟 인공 지능 모델의 특정 레이어로 가중치와 편향을 전이 받거나 전이 받지 않고 재학습되는 것인 의료 영상 정합 방법."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 환자 공간의 영상 데이터와 의료 영상 데이터를 정밀 정합하는 의료 영상 정합 장치에 있어서, 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 수신하는 입력부; 프로브를 통해 수집되는 상 기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 기반으로 정밀 정합을 위한 회전 및 병진 변환 행렬 값 (뒷면에 계속)"}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 의료 영상 정합 장치에 관한 것으로, 상세하게는 내시경의 증강 현실의 정밀도를 향상시키고 심부 병 변 오차를 최소화하여 의료 영상 데이터의 데이터와 환자 공간의 데이터를 정밀 정합을 할 수 있는 의료 영상 정합 장치 및 그 방법에 관한 것이다. 더욱 상세하게는, 본 발명은 환자 공간의 데이터, 의료 영상 데이터 및 팬텀의 병변 위치 정보를 기반으로 회전 및 병진 변환 행렬값을 추정하는 소스 인공 지능 모델로부터 가중치 및 편향을 전이받아 학습된 타겟 인공 지능 모델을 이용하여 의료 영상 데이터와 환자 공간의 데이터를 정밀 정합할 수 있는 의료 영상 정합 장치 및 그 방 법에 관한 것이다."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 유도 수술 시스템은 수술 도구의 3차원 위치를 수술 전 촬영한 환자의 의료 영상에 가시화하여 병변 및 주 변의 위치를 실시간으로 제공하는 의료 시스템이다. 영상 유도 수술 시스템은 수술 전 환자의 의료 영상을 획득하고, 수술 중 공간 정합을 수행한 후, 수술 도구의 좌표 변환을 통한 가상의 수술 도구를 의료 영상 내에 겹쳐서 표시한다. 여기서, 공간 정합은 수술 전 촬영한 의료 영상의 좌표와 수술 중 획득한 환자 공간 좌표를 동일한 공간으로 정렬시키는 과정을 의미한다. 두 좌표의 정합이 정확하게 수행되지 않으면 실제 수술도구의 위치와 가상의 수술도구의 위치간 이격이 발생할 수 있다. 따라서 준비된 의료 영상과 환자 공간의 영상을 정확하게 정합하는 기술이 필요하다. 한편, 이와 같은 공간 정합은 점 정합과 표면 정합으로 구분된다. 먼저, 점 정합은 의료 영상 및 환자 공간에서 하나의 직선 위에 존재하지 않는 최소 3개의 표식자 마커 좌표를 획득한다. 또한, 각 의료 영상 및 환자 공간의 지역 좌표계를 기초로하여 두 공간의 정렬이 일치될 수 있도록 좌표계간 회전과 선형 변환을 수행한다. 따라서, 점 정합을 수행하기 위해서는 미리 환자 얼굴에 표식자 마커를 부착해야 하며, 추가적으로 CT(computed tomography) 촬영을 해야하는 번거로움이 발생한다. 또한, 환자 얼굴에 부착된 표식자 마커에 의해 신체의 국부 가 부어오르는 종착이 발생할 가능성이 높으며, 이로 인해 표식자 마커가 움직일 경우 정확도가 저하된다는 한 계가 존재한다. 한편, 도1은 종래의 표면 정합을 설명하기 위한 도면이다. 도 1에 도시된 바와 같이 환자(P)의 표면에 대한 정보는 프로브를 통해 획득될 수 있다. 일 예로, 집도의는 프로브가 환자(P)의 신체에 인접한 상태에서 프로브를 천천히 이동시키게 되며, 수 술용 내비게이션 장치는 환자(P)의 표면에 대한 정보를 반영하는 프로브 좌표 데이터(C)들을 획득하게 된다. 그리고, 수술용 내비게이션 장치는 획득한 프로브 좌표 데이터(C)들을 회전 또는 이동시켜 기 촬영한 환자(P)의 의료 영상으로부터 획득한 표면 좌표 데이터들과 정합하고 정합한 결과물을 단일의 공간에 위치시키게 된다. 한편, 표면 좌표 데이터들은 의료영상 장비를 통해 획득한 고해상도의 영상 정보를 기반으로 하기 때문에 수천 에서 수십만개의 좌표 데이터로 구성될 수 있다. 따라서, 표면 정합은 환자 공간과 의료 영상간 지정된 표식자 마커 없이 각 공간의 좌표 군집으로 변환 행렬을 찾아낸다. 또한, 표면 정합은 추가적인 CT 촬영을 진행하지 않으며 임상의의 편의성이 있다. 그러나, 표면 정합은 환자 공간 좌표 군집을 획득하는 지역인 얼굴 표면에서 환부가 멀어지면서 증가되는 병변 오차 문제가 발생된다. 일 예로, 얼굴 표면에서 약간의 회전 오차가 발생한 경우, 얼굴 표면에서 멀리 떨어진 심부 병변 측에서는 증폭된다. 즉, 표면 정합은 얼굴 표면의 좌표만으로 정합을 수행하기 때문에 심부 병변 측 에서 오차가 발생하여 타 병변으로 오인될 수 있다는 한계가 있다."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 의료 영상 정합 장치에 관한 것으로, 더욱 상세하게는, 전이 학습을 기반으로 한 인공 지능 모델을 이용하여 심부 병변 오차를 최소화하여 의료 영상의 데이터와 환자 공간의 데이터를 정밀 정합을 할 수 있는 의 료 영상 정합 장치 및 그 방법을 제공하는 것이다. 또한, 환자 공간의 데이터 및 팬텀의 병변 위치 정보를 기반으로 회전 및 병진 변환 행렬값을 추정하는 소스 인 공 지능 모델로부터 가중치 및 편향을 전이받아 학습된 타겟 인공 지능 모델을 이용하여 의료 영상의 데이터와 환자 공간의 데이터를 정밀 정합할 수 있는 기술을 제공한다. 본 발명이 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다 른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위하여, 본 발명의 일 실시예에 따른 환자 공간의 영상 데이터와 의료 영상 데이 터를 정밀 정합하는 의료 영상 정합 장치에 있어서, 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 수신하는 입력부; 프로브를 통해 수집되는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 기반으로 정밀 정합을 위한 회전 및 병진 변환 행렬 값을 추정하는 전이학습 기반 소스 인공 지능 모델 및 타겟 인공 지능 모델이 저장된 인공 지능 모델 저장부; 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 정밀 정합하는 정합부; 및 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터의 정합 결과물을 출력하는 출력부;를 포함하며 상기 정 합부는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 개략적으로 정합하여 제1정합 좌표점을 생성 하는 제1정합부; 상기 제1정합 좌표점과 상기 의료 영상 데이터의 표면 좌표점을 정합하여 제2 정합 좌표점을 생성하는 제2정합부; 및 상기 제2정합 좌표점을 상기 타겟 인공 지능 모델의 입력으로 하여 추정된 상기 회전 및 병진 변환 행렬을 기반으로 정밀 정합하는 제3정합부를 포함할 수 있다. 상기 소스 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴 표면 좌표점에 대응되는 상기 의료 영상 데이터의 표면 좌표점, 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위치 좌표점을 포함할 수 있다. 상기 팬텀 병변 위치 좌표점은 가상의 병변 구조물에 임의로 지정한 병변 후보군의 위치 좌표점이며, 상기 팬텀 영상 병변 위치 좌표점은 상기 병변 구조물을 촬영한 영상 데이터에서 상기 병변 후보군의 위치 정보와 대응되 는 위치 좌표점을 포함할 수 있다. 상기 타겟 인공 지능 모델은 상기 의료 영상 데이터를 3D 형태로 형성하고, 상기 형성된 3D 의료 영상 데이터를 분할하여 상기 병변의 위치를 확인하고, 상기 확인된 병변 위치를 기반으로 상기 소스 인공 지능 모델의 학습 데이터 세트를 재구성함으로써, 상기 타겟 인공 지능 모델의 학습 데이터를 추출할 수 있다. 상기 타겟 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상 데이터로 설정될 수 있다. 상기 타겟 인공 지능 모델은 상기 소스 인공 지능 모델의 특정 레이어에서 상기 타겟 인공 지능 모델의 특정 레 이어로 가중치와 편향을 전이 받거나 전이 받지 않고 재학습될 수 있다. 환자 공간의 영상 데이터와 의료 영상 데이터를 정밀 정합 하는 의료 영상 정합 방법에 있어서, a) 프로브를 통 해 수집되는 상기 환자 공간의 영상 데이터와 상기 의료 영상 데이터를 획득하는 단계; b) 상기 환자 공간의 영 상 데이터와 상기 의료 영상 데이터로부터 개략적으로 좌표점을 추출하여 정합하고, 개략적인 회전 및 병진 변 환 행렬을 추출하는 단계; c) 상기 개략적으로 정합된 좌표점과 상기 환자 공간의 영상 데이터로부터 추출된 얼 굴 표면 좌표점을 추출된 상기 개략적인 회전 및 병진 변환 행렬을 이용하여 제1정합하고 제1정합 좌표점을 생 성하는 단계; d) 상기 제1정합 데이터를 증강시키고, 증강된 제 1정합 좌표점을 상기 의료 영상 데이터로부터 추출된 표면 좌표점과 정합하여 제2정합 좌표점을 생성하는 단계;및 e) 상기 제2정합 좌표점을 타겟 인공 지능 모델의 입력으로 하여 추정된 상기 회전 및 병진 변환 행렬을 기반으로 정밀 정합하는 단계;를 포함하며, 상기 인공 지능 모델은 전이학습 기반 소스 인공 지능 모델 및 상기 타겟 인공 지능 모델을 포함할 수 있다. 상기 소스 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴 표면 좌표점에 대응되는 상기 의료 영상 데이터의 표면 좌표점, 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위치 좌표점을 포함할 수 있다. 상기 팬텀 병변 위치 좌표점은 가상의 병변 구조물에 임의로 지정한 병변 후보군의 위치 좌표점이며, 상기 팬텀 영상 병변 위치 좌표점은 상기 병변 구조물을 촬영한 영상 데이터에서 상기 병변 후보군의 위치 정보와 대응되 는 위치 좌표점을 포함할 수 있다. 상기 타겟 인공 지능 모델은 상기 의료 영상 데이터를 3D 형태로 형성하고, 상기 형성된 3D 의료 영상 데이터를 분할하여 상기 병변의 위치를 확인하고, 상기 확인된 병변 위치를 기반으로 상기 소스 인공 지능 모델의 학습 데이터 세트를 재구성함으로써, 상기 타겟 인공 지능 모델의 학습 데이터를 추출할 수 있다. 상기 타겟 인공 지능 모델의 입력 정보 특징점은 상기 환자 공간의 얼굴 표면 좌표점, 상기 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상 데이터로 설정될 수 있다. 상기 타겟 인공 지능 모델은 상기 소스 인공 지능 모델의 특정 레이어에서 상기 타겟 인공 지능 모델의 특정 레 이어로 가중치와 편향을 전이 받거나 전이 받지 않고 재학습될 수 있다."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 환자 공간의 영상 데이터와 의료 영상 데이터를 인공 지능 모델을 기반으로 추출된 회전 및 병진 변환 행렬을 이용하여 정합을 진행하기 때문에, 표면 정합 시 발생하는 심부 병변 오차를 최소화 할 수 있다. 또한, 본 발명의 실시예에 따르면, 환자 공간의 영상 데이터와 의료 영상 데이터로부터 대략적으로 좌표점을 추 출하여 코스 정합을 먼저 수행함으로써 정합 정확도를 향상시킬 수 있다. 또한, 본 발명의 실시예에 따르면, 가상의 병변 구조물의 병변 위치 좌표점을 포함한 데이터 세트를 확보하고, 이를 기반으로 소스 인공 지능 모델 입력 정보의 특징점을 설정하여 학습을 수행하므로, 얼굴 표면에서 멀리 떨 어진 심부 병변 측에서도 최적화된 회전 및 병진 변환 행렬을 추정할 수 있다. 또한, 본 발명의 실시예에 따르면, 타겟 인공 지능 모델은 소스 인공 지능 모델의 가중치와 편향을 전이받아 학 습할 수 있다. 즉, 타겟 인공 지능 모델은 소스 인공 지능 모델의 학습 데이터 세트를 기반으로 타겟 인공 지능 모델의 학습 데이터 세트를 추출하는 것이 가능하다. 이로써, 타겟 인공 지능 모델은 환자 공간의 영상 데이터 와 의료 영상 데이터만을 입력하여도 심부 병변 오차의 증폭을 효과적으로 감소시킬 수 있다. 또한, 타겟 인공 지능 모델은 비교적 적은 학습 데이터 세트를 사용해도 높은 정확도를 가진 결과를 출력하는 것이 가능하다. 또한, 본 발명의 실시예에 따르면, 사용자는 심부 병변 측의 오차가 최소화된 의료 영상 데이터와 환자 공간의 영상 데이터 정합 결과물을 인지할 수 있다. 이로써, 사용자는 정확하게 심부 병변을 파악할 수 있으며, 효율 적으로 심부 병변의 수술을 진행할 수 있다."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명을 설명하기로 한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 따라서 여기에서 설명하는 실시예로 한정되는 것은 아니다. 그리고 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유 사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉, 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연 결\"되어 있는 경우뿐 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 구비할 수 있다는 것을 의미한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하 첨부된 도면을 참고하여 본 발명의 실시예를 상세히 설명하기로 한다. 도2는 본 발명의 실시예에 따른 의료 영상 정합 장치를 도시하는 도면이다. 도2에 도시된 바와 같이, 본 발명의 실시예에 따른 의료 영상 정합 장치는 입력부, 좌표점 생성부 , 증강부, 인공 지능 모델부, 정합부 및 출력부를 포함할 수 있다. 먼저, 입력부는 환자 공간의 영상 데이터와 의료 영상 데이터를 수신한다. 환자 공간은 환자가 위치한 공 간이며, 수술 시 환자 공간으로부터 획득될 수 있다. 또한, 환자 공간의 영상 데이터와 의료 영상 데이터는 3차 원 형태일 수 있다. 일 예로, 입력부는 프로브(미도시)를 포함할 수 있다. 프로브는 환자 공간의 영상 데이터를 획득할 수 있 다. 프로브는 막대 형상의 의료도구일 수 있으며, 단부가 환자의 신체 표면과 접촉되거나 인접하게 배치된 상태 로 사용될 수 있다. 프로브는 환자의 신체 표면을 따라 이동하며 환자 공간의 신체 표면에 대한 영상데이터를 획득한다. 프로브는 환자의 신체를 향한 일측에 배치되는 센서를 포함할 수 있다. 센서는 광학식 센서일 수 있 다. 한편, 의료 영상 데이터는 수술 전에 획득된 환자의 영상으로 CT, MRI 또는 초음파 등을 통해 촬영된 것일 수 있다. 또한, 좌표점 생성부는 제1좌표점 생성부 및 제2좌표점 생성부를 포함할 수 있다. 제1좌표점 생성부는 의료 영상 데이터로부터 표면 좌표점 세트를 획득할 수 있다. 또한, 제1좌표점 생성부 는 획득한 표면 좌표점 세트를 기초로 하여 코스 정합(Coarse matching)을 위한 기준 좌표점인 제1좌표점 생성을 할 수 있다. 여기서, 제1좌표점은 대략적인 정합을 위하여 추출된 의료 영상 데이터의 표면 좌표점이다. 제2좌표점 생성부는 프로브로부터 입력된 환자의 신체 표면에 대한 좌표점을 획득하여 코스 정합을 위한 기준 좌표점인 제2좌표점을 생성할 수 있다. 여기서, 제2좌표점은 프로브가 환자 얼굴의 표면을 접촉할 시, 획 득된 환자 얼굴 표면 좌표점을 포함할 수 있다. 일 예로, 제2좌표점은 프로브가 환자의 이마, 코끝, 눈끝 및 이 마 등을 접촉할 시 환자 공간의 얼굴 표면 좌표점을 포함할 수 있다. 증강부는 제1정합된 표면 좌표점을 증강시킨다. 후술하겠지만, 증강부는 보간법을 이용하여 제1정합 좌표점을 증강시킬 수 있다. 여기서, 제1정합 좌표점을 증강시킨다는 것은 제1 정합 좌표점을들의 수를 증가시 키는 것으로 이해될 수 있다. 일 예로, 증강부는 3차 다항식 형태로 각 점들을 연결하는Cubic Spline을 이 용하여 제1 정합 좌표점을 증강시킬 수 있다. 또한, 증강부는 제1정합 좌표점을 5%씩 증강시킬 수 있다. 제1정합 좌표점을 5% 증강시키는 과정을 1회의 스텝으로 가정하면, 증강부는 1회 이상의 스텝을 반복 실시 할 수 있다. 증강부는 제한된 시간 내에서 획득된 제1정합 좌표점의 좌표점 수를 증강시키므로 정합 정확 도를 높일 수 있다. 인공 지능 모델부는 인공 지능 모델은 의료 영상 데이터 및 환자 공간의 영상 데이터를 입력으로 하여 정 밀 정합을 위한 회전 및 병진 변환 행렬 값을 추정할 수 있다. 또한, 인공 지능 모델부는 소스 인공 지능 모델 및 타켓 인공 지능 모델을 포함할 수 있다. 즉, 인공 지능 모델부는 기존에 학습된 모델을 전이하여 새로운 모델을 학습하는 전이 학습 기반으로 한 CNN (합성곱신경망: Convolution Neural Network)으로 구현될 수 있다. CNN 인공 지능 모델의 정확도를 향상시키기 위해서는 많은 양의 데이터를 이용하여 학습해야 한다. 그러나, 많은 학습 데이터를 확보하기 위해서는 많은 비 용과 시간이 필요하고, 학습 데이터를 과하게 학습하는 과적합(오버피팅, Overfitting)이 발생할 수 있다. 전이 학습을 기반으로 한 인공 지능 모델은 소스 인공 지능 모델과 타겟 인공 지능 모델로 구성된다. 소스 인공 지능 모델은 큰 데이터 세트를 활용하여 훈련된 모델이다. 소스 인공 지능 모델은 타겟 인공 지 능 모델의 특정 CNN레이어로 가중치와 편향을 전이하거나 전이하지 않고 재학습함으로써 타겟 인공 지능 모델을 학습할 수 있다. 이로써, 타겟 인공 지능 모델은 비교적 적은 학습 데이터 세트를 사용해도 높은 정확도를 가진 결과를 출력하는 것이 가능하다. 한편, 정합부는 제1정합부, 제2정합부 및 제3정합부를 포함할 수 있다. 제1정합부는 개략적으로 제1좌표점과 제2좌표점을 정합할 수 있다. 정합은 각자의 공간에 위치한 좌표점 세트들을 하나의 좌표계에 배치하는 것을 의미한다. 즉, 제1정합부는 정합된 결과물을 하나의 공간 좌표계 에 배치할 수 있다. 이 때, 제1정합부는 코스 정합을 하는 경우의 회전 및 병진 변환 행렬 값을 추출할 수 있다. 또한, 제1정합부는 추출된 회전 및 병진 변환 행렬값을 이용하여 환자 공간의 얼굴 표면 좌표점을 코스 정 합된 좌표점과 정합할 수 있다. 제1정합부는 환자 공간의 얼굴 표면 좌표점을 이동시키거나 회전시켜 코스 정합된 좌표점과 정합을 구현할 수 있다. 또한, 제1정합부는 코스 정합된 좌표점을 이동시키거나 회전시켜 환자 공간의 얼굴 표면 좌표점과 코스 정합할 수 있다. 그리고, 이 때, 환자 공간의 얼굴 표면 좌표점은 입력부 에서 프로브의 이동 경로에 따라 입력된 환자의 신체 표면에 대한 좌표점들을 포함할 수 있다. 그리고, 제 1정합부는 정합 결과물인 코스 정합된 표면 좌표점을 제1정합 좌표점으로 하여 하나의 공간 좌표계에 배치 할 수 있다. 제2정합부는 증강부에서 증강된 제1정합 좌표점과 의료 영상 데이터의 표면 좌표점을 정합할 수 있다. 일 예로, 제2정합부는 ICP(iterative closest point) 알고리즘을 이용하여 정합할 수 있다. ICP 알 고리즘은 두 공간의 좌표간 위치의 평균 차이가 최소가 될 수 있는 회전 및 이동 행렬을 계산하여 매칭하는 방 법이다. 또한, 제2정합부는 정합 결과물에 대한 정확도를 분석할 수 있다. 제2정합부는 표면 정합 오차 (Surface registration error; SRE) 분석을 통해 정합 오차나 정합 정확도를 분석할 수 있다. 표면 정합 오차 는 하나의 표면 좌표점 세트와 다른 표면 좌표점 세트 간 거리를 계산하고 이를 평균하여 획득된다. 제2정합부 는 계산된 표면 정합 오차가 종료 조건 만족 여부를 판단할 수 있다. 제2정합부는 표면 정합 오차가 종료 조건을 만족하는 경우, 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상의 표면 좌표점과 최종 증강된 환자 공간의 얼굴 표면 좌표점을 추출할 수 있다. 한편, 제2정합부는 정합 결과물에 대한 정확도를 분석할 수 있다. 제2정합부는 표면 정합 오차 (Surface registration error; SRE) 분석을 통해 정합 오차나 정합 정확도를 분석할 수 있다. 표면 정합 오차 는 하나의 표면 좌표점 세트와 다른 표면 좌표점 세트 간 거리를 계산하고 이를 평균하여 획득된다. 표면 정합 오차는 아래의 수학식 1에 의해 계산될 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 1]에서 는 i번째 의료 영상의 표면 좌표점을 의미하고 는 ICP 알고리즘을 통 해 획득된 변환행렬이 적용된 i번째 환자 공간의 얼굴 표면 좌표점을 의미한다. 이 때, 환자 공간의 얼굴 표면 좌표점은 i 번째 증강된 제1정합 좌표점을 포함한다. 제2정합부는 계산된 표면 정합 오차가 종료 조건 만족 여부를 판단할 수 있다. 제2정합부는 표면 정 합 오차가 종료 조건을 만족하는 경우, 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상의 표면 좌표점과 최종 증강된 환자 공간의 얼굴 표면 좌표점을 추출할 수 있다. 또한, 제2정합부는 표면 정합 오차가 종료 조건을 만족하지 않는 경우, 제1정합 좌표점을 증강부에서 스텝을 반복하여 증강시킬 수 있다. 제3정합부는 타겟 인공 지능 모델을 기반으로 ICP정합을 진행할 수 있다. 여기서, 제3정합부는 타겟 인공 지능 모델으로부터 추출된 회전 및 병진 행렬값을 기반으로 정합을 할 수 있다. 타겟 인공 지능 모델은 제2정합 데이터를 입력으로 하여 회전 및 병진 행렬을 추출할 수 있다. 한편, 소스 인공 지능 모델은 제2정합 데이터, 팬텀 병변 위치 좌표점 및 팬텀 영상 위치 좌표점을 입력으 로 하여 회전 및 병진 행렬을 추출할 수 있다. 여기서 팬텀은 얼굴 모양 모형으로, 가상의 병변 구조물이 구비 될 수 있다. 이 때, 팬텀의 병변 위치 좌표점은 가상의 병변 구조물에 임의로 지정된 병변 후보군을 의미한다. 소스 인공 지능 모델은 팬텀 병변 위치 좌표점 및 팬텀 영상 위치 좌표점을 추가적으로 포함하여 이동 및 병진 변환 행렬을 추출할 수 있기 때문에, 심부 병변 오차 증폭을 감소시킬 수 있다. 따라서, 타겟 인공 지능 모델은 소스 인공 지능 모델의 가중치 및 편향을 전이받음으로써, 제2정합 데이터만을 입력하여도 높 은 정확도를 가진 회전 및 병진 행렬을 출력하는 것이 가능하다. 출력부는 제3정합부에서 배치된 결과물을 출력한다. 출력부는 정합 결과물을 디스플레이 장치를 통해 영상으로 표시할 수 있다. 도3은 본 발명의 실시예에 따른 의료 영상 데이터의 표면 데이터와 환자 공간의 얼굴 표면 데이터를 정합하는 방법을 도시하는 도면이다. 도3을 참조하면, 단계(S110)에서 의료 영상 정합 장치는 의료 영상 데이터 및 환자 공간의 영상 데이터를 수신 할 수 있다. 의료 영상 정합 장치는 의료 영상 데이터로부터 환자를 촬영한 의료 영상 데이터의 표면 좌표점을 추출하여 획득할 수 있다. 일 예로, 의료 영상 데이터의 표면 좌표점을 환자의 신체 표면에 대한 좌표점들을 포함한다. 한편, 의료 영상 정합 장치는 환자 공간의 영상 데이터로부터 프로브가 센싱한 환자 공간의 얼굴 표면 좌표점을 추출하여 획득할 수 있다. 의료 영상 정합 장치는 프로브를 이용하여 프로브의 위치 정보를 나타내는 환자 공간 의 영상 데이터를 수집한다. 다음으로, 단계(S120)에서, 의료 영상 정합 장치는 획득된 의료 영상 데이터의 표면 좌표점과 환자 의료 영상 공간의 얼굴 표면 좌표점의 코스 정합용 좌표점을 추출할 수 있다. 일 예로, 의료 영상 정합 장치는 의료 영상의 공간의 표면 좌표점으로부터 개략적인 정합인 코스 정합을 위해 제1좌표점을 추출할 수 있다. 또한, 의료 영 상 정합 장치는 환자 공간의 얼굴 표면 좌표점으로부터 코스 정합용 제2좌표점을 추출할 수 있다. 여기서, 제2 좌표점은 프로브가 환자의 이마, 코끝, 눈끝 및 이마 등을 접촉할 시 환자 공간의 얼굴 표면 좌표점을 포함할 수 있다. 이 때, 의료 영상 정합 장치는 추출된 제1좌표점 및 제2좌표점을 코스 정합하여 코스 정합된 좌표점을 획득할 수 있다. 또한, 의료 영상 정합 장치는 코스 정합을 하는 경우의 회전 및 병진 변환 행렬값을 추출할 수 있다. 또한, 의료 영상 정합 장치는 추출된 회전 및 병진 변환 행렬값을 이용하여 환자 공간의 얼굴 표면 좌표점을 코 스 정합된 좌표점과 정합할 수 있다. 이 때, 환자 공간의 얼굴 표면 좌표점은 프로브의 이동 경로에 따라 입력 된 환자의 신체 표면에 대한 좌표점들을 포함할 수 있다. 그리고, 의료 영상 정합 장치는 정합 결과물인 코스 정합된 표면 좌표점을 제1정합 좌표점으로 하여 하나의 공간 좌표계에 배치할 수 있다. 단계(S130)에서, 의료 영상 정합 장치는 제1정합 좌표점을 증강할 수 있다. 제1정합 좌표점을 증강하는 단계는 복수 회 반복 실시될 수 있다. 일 예로, 제1정합 좌표점은 5%씩 증강될 수 있다. 제1정합 좌표점을 5% 증강시키 는 과정을 1회의 스텝으로 가정하면, 의료 영상 정합 장치는1회 이상의 스텝을 반복 실시할 수 있다. 의료 영상 정합 장치는 제한된 시간 내에서 획득된 제1정합 좌표점의 좌표점 수를 증강시키므로 정합 정확도를 높일 수 있 다. 또한, 의료 영상 정합 장치는 증강된 제1 정합 좌표점을 의료 영상 데이터의 표면 좌표점과 정합할 수 있다. 일 예로, 의료 영상 정합 장치는 ICP(iterative closest point) 알고리즘을 이용하여 정합할 수 있다. ICP 알고리 즘은 두 공간의 좌표간 위치의 평균 차이가 최소가 될 수 있는 회전 및 이동 행렬을 계산하여 매칭하는 방법이 다. 한편, 의료 영상 정합 장치는 표면 정합 오차 분석을 통해 정합 오차나 정합 정확도를 분석할 수 있다. 표면 정 합 오차는 하나의 표면 좌표점 세트와 다른 표면 좌표점 세트 간 거리를 계산하고 이를 평균하여 획득된다. 또한, 의료 영상 정합 장치는 계산된 표면 정합 오차가 종료 조건 만족 여부를 판단할 수 있다. 의료 영상 정합 장치는 표면 정합 오차가 종료 조건을 만족하는 경우, 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상 데 이터의 표면 좌표점과 최종 증강된 환자 공간의 얼굴 표면 좌표점을 추출할 수 있다. 추출된 결과물은 제2정합 좌표점을 의미한다. 그리고, 의료 영상 정합 장치는 표면 정합 오차가 종료 조건을 만족하지 않는 경우, 스텝을 반복하여 제1정합 좌표점을 증강시킬 수 있다. 단계(S140)에서, 의료 영상 정합 장치는 인공 지능 모델을 기반으로 정합을 진행할 수 있다. 이 때, 의료 영상 정합 장치는 소스 인공 지능 모델과 타겟 인공 지능 모델로 구성될 수 있다. 여기서, 의료 영상 정합 장치는 타 겟 인공 지능 모델로부터 추출된 회전 및 병진 행렬을 기반으로 정합을 할 수 있다. 타겟 인공 지능 모델은 제2 정합 데이터를 입력으로 하여 회전 및 병진 행렬을 추출할 수 있다. 즉, 의료 영상 정합 장치는 제2정합 좌표점 을 타겟 인공 지능 모델의 입력으로하여 추출된 회전 및 병진 변환 행렬을 기반으로 최적화된 정합을 할 수 있 다. 단계(S150)에서 의료 영상 정합 장치는 최종 정합된 결과물을 하나의 공간 좌표계에 배치하여 출력할 수 있다. 일 예로, 의료 영상 정합 장치는 실시간 의료 영상 데이터 좌표계에 제3정합 좌표점을 배치하고, 디스플레이 장 치를 통해 영상으로 표시할 수 있다. 도4는 본 발명의 실시예에 따른 의료 영상 정합 장치가 제1정합 및 제2정합을 진행하는 방법을 구체적으로 도시 하는 도면이다. 도4에 도시된 바와 같이, 단계(S210)에서 의료 영상 정합 장치는 의료 영상 데이터로부터 표면 좌표 데이터인 표면 좌표점 세트를 획득할 수 있다. 일 예로, 의료 영상 데이터는 수술 전에 획득된 환자의 영상으로 CT, MRI 또는 초음파 등을 통해 촬영된 것일 수 있다. 또한, 의료 영상 정합 장치는 획득된 표면 좌표점 세트로부터 코스 정합을 위한 제1좌표점을 생성할 수 있다. 즉, 의료 영상 정합 장치는 정확도를 향상시키기 위하여 표면 좌표점 세트로부터 대략적으로 좌표점을 추출한다. 단계(S220)에서, 의료 영상 정합 장치는 환자 공간의 영상 데이터로부터 얼굴 표면 데이터를 추출할 수 있다. 구체적으로, 의료 영상 정합 장치는 코스 정합을 하기 위하여 환자 공간의 영상 데이터로부터 프로브가 센싱한 환자 공간의 얼굴 표면 좌표점을 추출하여 획득할 수 있다. 의료 영상 정합 장치는 프로브를 이용하여 프로브의위치 정보를 나타내는 표면 좌표점을 획득할 수 있다. 의료 영상 정합 장치는 프로브가 접촉하거나 인접한 환자 얼굴 표면 일부의 표면 좌표점을 획득할 수 있다. 또한, 의료 영상 정합 장치는 획득한 표면 좌표점을 제2좌표 점으로 생성할 수 있다. 일 예로, 제2좌표점은 환자의 이마, 코끝, 눈끝 및 이마 등을 접촉할 시 환자 공간의 얼굴 표면 좌표점을 포함할 수 있다. 단계(S230)에서, 의료 영상 정합 장치는 제1좌표점을 제2좌표점과 코스 정합하여 코스 정합 좌표점을 생성할 수 있다. 또한, 의료 영상 정합 장치는 코스 정합을 하는 경우의 회전 및 병진 변환 행렬을 추출할 수 있다. 의료 영상 정합 장치는 초기에 코스 정합을 수행하므로 정확도를 향상시킬 수 있다. 단계(S240)에서, 의료 영상 정합 장치는 환자 공간의 얼굴 표면 좌표점을 코스 정합된 표면 좌표점으로 변환할 수 있다. 의료 영상 정합 장치는 추출된 회전 및 병진 변환 행렬을 이용하여 제1정합 좌표점을 생성할 수 있다. 여기서 환자 공간의 얼굴 표면 좌표점은 프로브의 위치 정보를 나타낸다. 프로브는 10초 내외의 시간동안 환자 의 피부 표면을 따라 접촉 또는 근접한 상태로 이동하며 환자의 신체 표면에 대한 데이터를 수집한다. 일례로, 프로브는 10초 내지 20초의 시간 동안 데이터를 수집할 수 있다. 의료 영상 정합 장치는 추출된 코스 정합을 하는 경우의 회전 및 병진 변환 행렬을 기반으로 환자 공간의 얼굴 표면 좌표점과 코스 정합된 좌표점을 정합한다. 그리고, 의료 영상 정합 장치는 정합 결과물인 표면 좌표점을 제1정합 좌표점으로 하여 하나의 공간 좌표계에 배치할 수 있다. 단계(S250)에서, 의료 영상 정합 장치는 제1정합 좌표점을 증강할 수 있다. 제1정합 좌표점을 증강하는 단계는 복수 회 반복 실시될 수 있다. 제1정합 좌표점은 5%씩 증강될 수 있다. 제1정합 좌표점을 5% 증강시키는 과정을 1회의 스텝으로 가정하면, 의료 영상 정합 장치는1회 이상의 스텝을 반복 실시할 수 있다. 의료 영상 정합 장치 는 제한된 시간 내에서 획득된 제1정합 좌표점의 좌표점 수를 증강시키므로 정합 정확도를 높일 수 있다. 또한, 의료 영상 정합 장치는 증강된 제1정합 좌표점을 의료 영상 데이터의 표면 좌표점과 정합할 수 있다. 이 때, 의료 영상 정합 장치는 ICP알고리즘을 이용하여 정합할 수 있다. 또한, 의료 영상 정합 장치는 제 2정합을 진행하는 경우의 회전 및 병진 변환 행렬을 도출할 수 있다. 단계(S260)에서, 의료 영상 정합 장치는 표면 정합 오차 분석을 통해 정합 오차나 정합 정확도를 분석할 수 있 다. 표면 정합 오차는 하나의 표면 좌표점 세트와 다른 표면 좌표점 세트 간 거리를 계산하고 이를 평균하여 획 득된다. 또한, 의료 영상 정합 장치는 분석된 표면 정합 오차가 기 설정된 종료 조건 만족 여부를 판단할 수 있다. 이 때, 의료 영상 정합 장치는 표면 정합 오차가 종료 조건을 만족하지 않을 시, 단계(S250) 및 단계(S260)를 반복 실시할 수 있다. 즉, 의료 영상 정합 장치는 제1정합 좌표점을 재증강시키고 정합하는 단계 및 표면 정합 오차 판단 단계를 반복 실시할 수 있다. 단계(S270)에서, 의료 영상 정합 장치는 표면 정합 오차가 기설정된 종료 조건을 만족하는 경우, 정합 결과로부 터 환자 공간의 얼굴 표면 좌표점에 대응되는 의료 영상 데이터의 표면 좌표점과 최종 증강된 환자 공간의 얼굴 표면 좌표점을 추출할 수 있다. 추출된 결과물은 제2정합 좌표점을 의미한다. 도5는 본 발명의 실시예에 따른 인공 지능 모델을 구축하는 방법을 도시하는 도면이다. 단계(S310)에서, 의료 영상 정합 장치는 제2정합 좌표점 데이터, 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위 치 좌표점을 기반으로한 소스 인공 지능 모델의 데이터 세트를 확보할 수 있다. 이 때, 팬텀의 병변 위치 좌표 점은 가상의 병변 구조물에 임의로 지정된 병변 후보군을 의미한다. 또한, 팬텀 영상 병변 위치 좌표점은 팬텀 을 촬영한 CT영상에서 추출된 좌표점을 포함할 수 있다. 후술하겠지만, 의료 영상 정합 장치는 소스 인공 지능 모델이 팬텀 병변 위치 좌표점 및 병변 영상 위치 좌표점을 추가적으로 포함함으로써 보다 정확한 회전 및 병진 변환 행렬을 도출할 수 있다. 여기서, 타겟 인공 지능 모델은 소스 인공 지능 모델로부터 가중치 및 편향을 전 이받음으로써, 팬텀을 고려하지 않아도 최적화된 정합을 하는 것이 가능하다. 단계(S320)에서, 소스 인공 지능 모델은 추출된 특징점을 학습하여 회전 및 병진 변환 행렬을 추정할 수 있다. 먼저, 소스 인공 지능 모델의 입력 및 출력이 설정될 수 있다. 일 예로, 소스 인공 지능 모델의 입력의 특징점 은 환자 공간의 얼굴 표면 좌표점과 그 좌표점에 대응되는 의료 영상 데이터의 표면 좌표점으로 설정될 수 있다. 추가적으로, 소스 인공 지능 모델의 입력의 특징점은 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 좌표점으 로 설정될 수 있다. 이 때, 좌표점은 3차원 좌표점으로, (x, y, z) 형태로 표시될 수 있다. 그리고, 소스 인공지능 모델의 출력은 ICP 정합을 통하여 추출된 회전 및 병진 변환 행렬로 설정될 수 있다. 또한, 소스 인공 지능 모델은 학습과 테스트를 위하여 확보된 데이터 세트를 분할할 수 있다. 여기서, 학습 데 이터 세트와 검증 데이터 세트를 분할함으로써 학습 데이터에서만 높은 예측력을 보이는 과적합(overfitting)을 방지할 수 있다. 또한, 소스 인공 지능 모델은 학습 성능을 높이기 위하여 충분한 학습 데이터를 확보하도록 데이터 증강을 수행 할 수 있다. 일 예로, 인공 지능 모델은 랜덤 노이즈를 추가하는 지터링(Jittering)과 기존 데이터 세트를 변환 하는 와핑(Warping) 기법을 활용하여, 학습 데이터를 증강할 수 있다. 또한, 소스 인공 지능 모델은 회전 및 병진 변환 행렬을 추정하기 위하여 데이터의 특징을 추출하고 특징들의 패턴을 파악하여 학습하는 CNN(합성곱신경망, Convolution Neural Network)으로 구현될 수 있다. CNN은 일반적 으로 컨볼루션 레이어, 완전 연결 레이어로 구성된다. CNN은 컨볼루션 레이어를 통해 입력된 데이터의 특징을 추출하여 필터링하고, 완전 연결 레이어로 분류할 수 있다. 이로써, CNN은 불필요한 데이터는 제외한 중요한 데 이터만 남길 수 있다. 또한, 학습된 소스 인공 지능 모델은 검증 데이터 세트를 이용하여 평가될 수 있다. 일 예로, 소스 인공 지능 모델은 교차 검증(Cross validation)으로 테스트될 수 있다. 교차 검증은 과적합(Over fitting)을 방지하기 위 하여 최적의 매개 변수를 찾기 위한 검증 방법이다. 인공 지능 모델이 교차 검증으로 테스트되는 경우, 학습 데 이터 세트 중 일부를 검증 데이터 세트로 분할할 수 있다. 소스 인공 지능 모델은 학습 데이터 세트 및 검증 데 이터 세트를 부분적으로 번갈아 바꿔가며 여러 개의 학습 데이터 세트와 검증 데이터 세트를 만들고, 이로 인해 만들어진 각각의 데이터 세트에 대한 결과를 출력하여 인공 지능 모델을 검증하는 것에 활용할 수 있다. 또한, 인공 지능 모델은 분할된 검증 데이터 세트를 이용하여 최적화된 파라미터를 추정하고, 인공 지능 모델의 오차 가 감소되도록 인공 지능 모델을 수정할 수 있다. 또한, 최종적으로 인공 지능 모델이 형성될 시, 인공 지능 모델은 테스트 데이터 세트를 활용하여 인공 지능 모 델을 평가할 수 있다. 단계(S330)에서, 의료 영상 정합 장치는 환자를 촬영한 의료 영상을 기반으로 타겟 인공 지능 모델의 데이트 세 트를 추출할 수 있다. 일 예로, 환자를 촬영한 의료 영상은 3D 형상으로 재구성될 수 있다. 여기서, 의료 정합 장치는 의료 영상의 3D 형상을 가상으로 분할하여 병변의 위치를 확인할 수 있다. 또한, 의료 정합 장치는 분할 된 의료 영상의 3D 형상에서 확인된 병변 위치를 기반으로 소스 인공 지능 모델의 학습 데이터 세트를 재구성할 수 있다. 재구성된 소스 인공 지능 모델의 학습 데이터 세트는 타겟 인공 지능 모델의 학습 데이터 세트로 사용 될 수 있다. 즉, 소스 인공 지능 모델은 환자 두상 전체에 위치하는 병변의 좌표를 활용하였지만, 단계(S330)를 통해 타겟 인공 지능 모델은 확인된 환자의 병변 위치의 병변만으로 학습 데이터 세트를 추출하여 활용할 수 있 다. 단계(S340)에서, 타겟 인공 지능 모델의 입력 및 출력이 설정될 수 있다. 일 예로, 입력 정보의 특징점은 환자 공간의 얼굴 표면 좌표점과 그 좌표점에 대응되는 의료 영상 데이터의 표면 좌표점으로 설정될 수 있다. 또한, 타겟 인공 지능 모델의 출력 정보는 ICP 정합을 통하여 추출된 회전 및 병진 변환 행렬로 설정될 수 있다. 또한, 타겟 인공 지능 모델은 학습과 테스트를 위하여 확보된 데이터 세트를 분할할 수 있다. 여기서, 학습 데 이터 세트와 검증 데이터 세트를 분할함으로써 학습 데이터에서만 높은 예측력을 보이는 과적합(overfitting)을 방지할 수 있다. 또한, 타겟 인공 지능 모델의 학습 성능을 높이기 위하여 충분한 학습 데이터를 확보하도록 데이터 증강을 수행 될 수 있다. 일 예로, 타겟 인공 지능 모델은 랜덤 노이즈를 추가하는 지터링(Jittering)과 기존 데이터 세트를 변환하는 와핑(Warping) 기법을 활용하여, 학습 데이터를 증강할 수 있다. 여기서, 테스트 데이터 세트는 증강 기법을 적용하지 않았다. 또한, 타겟 인공 지능 모델은 단계(S320)에서 학습된 소스 인공 지능 모델의 특정 CNN 레이어에서 타겟 인공 지 능 모델의 특정 CNN 레이어로 가중치와 바이어스를 전이하여 재학습함으로써, 타겟 인공 지능 모델을 학습할 수 있다. 여기서, 타겟 인공 지능 모델은 단계(S330)에서 재구성된 소스 인공 지능 모델의 학습 데이터 세트를 활 용하여 학습할 수 있다. 즉, 타겟 인공 지능 모델은 병변의 위치 정보를 활용하여 훈련된 소스 인공 지능 모델로부터 가중치 및 편향을 전이 받았기 때문에 심부 병변 오차가 증폭되는 문제를 효과적으로 감소시킬 수 있다. 도6은 본 발명의 실시예에 따른 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위치 좌표점을 도시하는 도면이다. 먼저, 팬텀은 얼굴 모양 모형으로, 가상의 병변 구조물을 포함할 수 있다. 이 때, 팬텀 병변 위치 좌표점은 가 상의 병변 구조물에 임의로 지정된 병변 후보군을 의미한다. 또한, 팬텀의 병변 위치 좌표점은 (x, y, z) 형태 로 표현할 수 있다. 한편, 팬텀 영상 병변 위치 좌표점은 팬텀을 촬영한 CT 영상에서 추출된 병변 위치 좌표점 을 포함할 수 있다. 팬텀 영상 병변 위치 좌표점은 (x, y, z)으로 표현될 수 있다. 즉, 팬텀 영상 병변 위치 좌 표점은 임의로 지정한 병변 후보군의 위치 좌표점에 대응되는 위치의 위치 좌표점이다. 도6에 도시된 바와 같이, 팬텀 병변 위치 좌표점은 (x'', y'', z'') 좌표로 설정되고, 이에 대응되는 팬텀 영상 위치 좌표점은 (x''', y''', z''')로 설정될 수 있다. 즉, 팬텀을 활용한 입력 정보의 특징점은 6개의 차원 (dimension)으로 설정될 수 있다. 이 때, 팬텀 영상 병변 위치 좌표점의 길이가 150일 시, 입력 정보의 사이즈 는 6 by 150으로 설정될 수 있다. 도 7은 본 발명의 실시예에 따른 타겟 인공 지능 모델의 학습 데이터 세트를 추출하는 과정을 도시하는 도면이 다. 도7을 참조하면, 단계(S410)에서, 영상 정합 장치는 환자를 촬영한 의료 영상을 3D 두상 형상으로 재구성할 수 있다. 영상 정합 장치는 CT(컴퓨터단층촬영,Computed Tomography) 의료 영상을 모델링하여 3D 형태로 표현할 수 있다. 단계(S420)에서, 영상 정합 장치는 3D 두상 형상을 가상으로 분할하여 병변 위치를 확인할 수 있다. 일 예로, 영상 정합 장치는 3D 두상 형상을 횡단면 방향으로 4분할 또는 9분할을 수행할 수 있다. 3D 두상 형상은 횡단면 방향으로 4분할될 경우 8개의 공간이 형성되며, 9분할될 경우 27개의 공간이 형성될 수 있다. 단계(S430)에서, 영상 정합 장치는 분할된 3D 두상 형상에서 확인된 병변 위치를 기반으로 소스 인공 지능 모델 의 데이터 세트를 재구성할 수 있다. 재구성된 소스 인공 지능 모델의 데이터 세트는 타겟 인공 지능 모델의 학 습 데이터 세트로 추출될 수 있다. 즉, 소스 인공 지능 모델은 환자 두상 전체에 위치하는 병변의 좌표를 활용 하였지만, 타겟 인공 지능 모델은 확인된 환자의 병변 위치의 병변만으로 학습 데이터 세트를 추출하여 활용할 수 있다. 또한, 타겟 인공 지능 모델은 소스 인공 지능의 팬텀에 대한 병변 위치 정보가 반영된 학습 데이터 세 트를 기반으로 효율적으로 학습 데이터 세트를 추출하는 것이 가능하다. 도8은 본 발명의 일 실시예에 따른 전이 학습 기반 인공 지능 모델을 도시하는 도면이다. 도8에 도시된 바와 같이, 환자 공간의 얼굴 표면 좌표점은(x, y, z) 좌표로 설정되고, 이에 대응되는 의료 영상 데이터의 표면 좌표점은 (x', y', z')로 설정될 수 있다. 얼굴 표면 좌표점과 이에 대응되는 의료 영상 데이터 의 표면 좌표점에 의한 입력 정보의 특징점은 6개의 차원(dimension)으로 설정될 수 있다. 이 때, 의료 영상 데 이터의 표면 좌표점의 길이가 150일 시, 입력 정보의 사이즈는 6 by 150으로 설정될 수 있다. 또한, 팬텀 병변 위치 좌표점은 임의로 지정한 병변 후보군의 위치 좌표점이며, (x'', y'', z'')로 설정될 수 있다. 팬텀 영상 병변 위치 좌표점은 팬텀을 촬영한 영상에서 병변 후보군에 대응되는 위치의 위치 좌표점을 포 함하며, (x''', y''', z''')로 설정될 수 있다. 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위치 좌표점은 6개의 차원으로 구성될 수 있다. 마찬가지로 의료 영상 데이터의 표면 좌표점의 길이가 150일 시, 팬텀을 활용한 입력 정보의 사이즈는 6 by 150으로 설정될 수 있다. 여기서, 환자 공간의 얼굴 표면 좌표점, 이에 대응되는 의료 영상 데이터의 표면 좌표점, 팬텀 병변 위치 좌표 점 및 팬텀 병변 위치 좌표점을 기반으로한 데이터 세트를 소스 인공 지능 모델에 입력할 수 있다. 소스 인공 지능 모델의 컨볼루션 레이어에서 출력된 결과값들은 완전 연결 레이어(Fully connected layer)로 입력될 수 있 다. 완전 연결 레이어는 1차원 배열의 형태로 평탄화된 행렬을 통해 분류를 결정하는 레이어이다. 즉, 완전 연 결 레이어에 입력된 결과값 중에 일부 결과값을 추출할 수 있다. 여기서, 완전 연결 레이어는 과적합(Over fitting)을 방지하기 위하여 드롭 아웃(Drop out) 형태로 구현될 수 있다. 드롭 아웃 비율에 따라 다른 특정 결 과값이 출력될 수 있다. 또한, 소스 인공 지능 모델이 복잡할 경우 드롭 아웃 비율을 늘리고, 단순할 경우 드롭 아웃 비율을 낮추면서 조절할 수 있다. 그리고, 회귀 레이어(Regression layer)를 통해 회전 및 병진 변환 행렬 값을 출력할 수 있다. 회귀 레이어는 종속 변수와 독립 변수간의 상관 관계를 예측하는 것이다. 또한, 회전 및 병진 변환 행렬값의 회전 행렬은 3 by 3(R) 차원이고 병진 행렬은 3 by 1 (T) 차원으로 출력될 수 있다. 따라서, 소스 인공 지능 모델을 통해 출력되는 회전 및 병진 변환 행렬 값은 12개의 차원을 포함할 수 있다. 한편, 타겟 인공 지능 모델에 환자 공간의 얼굴 표면 좌표점 및 이에 대응되는 의료 영상 데이터의 표면 좌표점 을 기반으로한 데이터 세트가 입력될 수 있다. 타겟 인공 지능 모델은 소스 인공 지능 모델로부터 가중치 및 편 향을 전이받음으로써 학습을 진행할 수 있다. 즉, 타겟 인공 지능 모델은 팬텀의 병변 위치 정보를 포함하여 최 적화된 소스 인공 지능 모델로부터 가중치와 편향을 전이 받았기 때문에 출력된 회전 및 병진 변환 행렬이 심부 병변 오차의 증폭을 줄일 수 있는 방법으로 학습할 수 있다. 타겟 인공 지능 모델의 회전 및 병진 변환 행렬값 회전 행렬은 3 by 3(R) 차원이고 병진 행렬은 3 by 1 (T) 차원으로 출력될 수 있다. 따라서, 타겟 인공 지능 모 델을 통해 출력되는 회전 및 병진 변환 행렬 값은 12개의 차원을 포함할 수 있다."}
{"patent_id": "10-2022-0145721", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 후술하는 청구범위에 의하여 나타내어지며, 청구범위의 의미 및 범위 그리고 그 균등 개념으 로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0145721", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 종래의 표면 정합을 설명하기 위한 도면이다. 도2는 본 발명의 실시예에 따른 의료 영상 정합 장치를 도시하는 도면이다. 도3은 본 발명의 실시예에 따른 의료 영상 데이터의 표면 데이터와 환자 공간의 얼굴 표면 데이터를 정합하는 방법을 도시하는 도면이다. 도4는 본 발명의 실시예에 따른 의료 영상 정합 장치가 제1정합 및 제2정합을 진행하는 방법을 구체적으로 도시 하는 도면이다. 도5는 본 발명의 실시예에 따른 인공 지능 모델을 구축하는 방법을 도시하는 도면이다. 도6은 본 발명의 실시예에 따른 팬텀 병변 위치 좌표점 및 팬텀 영상 병변 위치 좌표점을 도시하는 도면이다. 도 7은 본 발명의 실시예에 따른 타겟 인공 지능 모델의 학습 데이터 세트를 추출하는 과정을 도시하는 도면이 다. 도8은 본 발명의 일 실시예에 따른 전이 학습 기반 인공 지능 모델을 도시하는 도면이다."}
