{"patent_id": "10-2023-7024724", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0137316", "출원번호": "10-2023-7024724", "발명의 명칭": "다수의 심도들에서의 객체들을 갖는 장면들을 위한이미지 융합", "출원인": "퀄컴 인코포레이티드", "발명자": "펑 원-춘"}}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제 1 초점 거리에서 캡처된 장면을 나타내는 제 1 이미지 프레임을 수신하는 단계; 상기 장면의 제 1 부분에 대한 상기 제 1 초점 거리에 대응하는 제 1 심도와 상기 장면의 제 2 부분에 대한 제2 심도 사이의 차이가 임계치를 초과하는지 여부를 결정하는 단계; 및 상기 차이가 상기 임계치를 초과하는 때:상기 제 1 초점 거리와 상이한 제 2 초점 거리에서 캡처된 장면을 나타내는 제 2 이미지 프레임을 수신하는 단계; 및 상기 제 1 이미지 프레임 및 상기 제 2 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 차이가 상기 임계치를 초과하는 때:상기 출력 이미지 프레임을 상기 제 1 부분 및 상기 제 2 부분으로 세그먼트화하는 단계; 및상기 제 1 부분이 아니라 상기 제 2 부분의 픽셀들에 블러링 알고리즘을 적용하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 출력 이미지 프레임을 결정하는 단계는, 상기 제 2 심도에 대응하는 상기 제 2 이미지 프레임의 세그먼트를 결정하는 것; 및상기 세그먼트를 상기 제 1 이미지 프레임과 병합하여 출력 이미지 프레임을 획득하는 것을 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 세그먼트를 상기 제 1 이미지 프레임과 병합하는 것은, 상기 제 1 이미지 프레임의 제 1 부분으로부터 제 1 세트의 픽셀들에 대응하는 제 1 이미지 데이터를 상기 출력이미지 프레임에 복사하는 단계; 상기 세그먼트로부터 제 2 세트의 픽셀들에 대응하는 제 2 이미지 데이터를 상기 출력 이미지 프레임에 복사하는 단계; 및 상기 제 1 세트의 픽셀들과 상기 제 2 세트의 픽셀들 사이의 경계 영역 내의 제 3 세트의 픽셀들에 대응하는 상기 출력 이미지 프레임의 제 3 이미지 데이터를 결정하는 단계로서, 상기 제 3 이미지 데이터는 상기 제 1 이미지 프레임, 상기 제 2 이미지 프레임, 및 가중치에 기초하여 결정되는, 상기 제 3 이미지 데이터를 결정하는 단계를 포함하는, 방법.공개특허 10-2023-0137316-3-청구항 5 제 4 항에 있어서, 상기 제 3 세트의 픽셀들 내의 픽셀에 대응하는 상기 제 1 이미지 프레임 내의 콘트라스트 값;상기 제 3 세트의 픽셀들 내의 픽셀에 대응하는 상기 제 2 이미지 프레임 내의 콘트라스트 값; 또는상기 제 3 세트의 픽셀들 내의 픽셀로부터 상기 제 1 세트의 픽셀들 또는 상기 제 2 세트의 픽셀들 중 적어도하나 내의 픽셀까지의 거리에 대응하는 거리 값중 적어도 하나에 기초하여 상기 가중치를 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서, 상기 제 1 이미지 프레임의 제 1 그래디언트 및 상기 제 2 이미지 프레임의 제 2 그래디언트에 기초하여 상기가중치를 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 4 항에 있어서, 상기 가중치는, 상기 제 1 세트의 픽셀들 내의 제 1 대응 픽셀 또는 상기 제 2 세트의 픽셀들 내의 제 2 대응픽셀로부터, 상기 제 1 대응 픽셀에서의 그래디언트가 상기 제 2 대응 픽셀보다 큰지 여부에 기초하여, 상기 제3 세트의 픽셀들의 픽셀에 대한 값을 선택하는 것에 대응하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 상기 제 1 심도를 결정하는 것은 상기 심도 데이터에 기초하여 히스토그램의 제 1 피크에 대응하는 심도를 결정하는 것을 포함하고,상기 제 2 심도를 결정하는 것은 상기 히스토그램의 제 2 피크에 대응하는 심도를 결정하는 것을 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 상기 제 2 심도에 대응하는 제 2 초점 거리에서 상기 제 2 이미지 프레임을 캡처하라는 커맨드를 송신하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 상기 커맨드를 송신하는 단계는 상기 제 2 초점 거리로 자동초점 알고리즘을 시딩 (seeding) 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서, 상기 제 1 이미지 프레임의 제 3 부분에 대한 제 3 심도를 결정하는 단계;상기 제 2 심도와 상기 제 3 심도 사이의 제 2 차이가 제 2 임계치를 초과하는지 여부를 결정하는 단계;상기 제 2 차이가 상기 제 2 임계치를 초과할 때 상기 제 2 초점 거리와 상이한 제 3 초점 거리에서 제 3 이미지 프레임을 수신하는 단계; 및 상기 제 1 이미지 프레임, 상기 제 2 이미지 프레임, 및 상기 제 3 이미지 프레임에 기초하여 출력 이미지 프레공개특허 10-2023-0137316-4-임을 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항에 있어서, 상기 제 1 이미지 프레임을 수신하는 단계는 f/2.2보다 큰 애퍼처 (aperture) 를 갖는 이미지 센서로부터 상기제 1 이미지 프레임을 수신하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1 항에 있어서, 상기 제 2 이미지 프레임을 수신하는 단계는 제 2 센서에 의해 촬영된 상기 제 2 이미지 프레임을 수신하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 1 항에 있어서, 상기 제 1 심도와 상기 제 2 심도의 차이가 상기 임계치를 초과하는지 여부를 결정하는 단계 전에,객체 검출 알고리즘에 기초하여 상기 제 1 이미지 프레임 내의 제 1 관심 객체 및 제 2 관심 객체를 결정하는단계;상기 제 1 관심 객체의 심도를 상기 제 1 심도로서 결정하는 단계; 및상기 제 2 관심 객체의 심도를 상기 제 2 심도로서 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "디바이스로서, 프로세서, 및상기 프로세서에 커플링되고 명령들을 저장하는 메모리를 포함하고, 상기 명령들은, 상기 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 제 1 초점 거리에서 캡처된 장면을 나타내는 제 1 이미지 프레임을 수신하는 것; 상기 장면의 제 1 부분에 대한 상기 제 1 초점 거리에 대응하는 제 1 심도와 상기 장면의 제 2 부분에 대한 제2 심도 사이의 차이가 임계치를 초과하는지 여부를 결정하는 것; 및 상기 차이가 상기 임계치를 초과하는 때:상기 제 1 초점 거리와 상이한 제 2 초점 거리에서 캡처된 장면을 나타내는 제 2 이미지 프레임을 수신하는 것;및 상기 제 1 이미지 프레임 및 상기 제 2 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 것을 포함하는 동작들을 수행하게 하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서, 상기 명령들은 상기 디바이스로 하여금, 상기 출력 이미지 프레임을 상기 제 1 부분 및 상기 제 2 부분으로 세그먼트화하는 것; 및상기 제 1 부분이 아니라 상기 제 2 부분의 픽셀들에 블러링 알고리즘을 적용하는 것공개특허 10-2023-0137316-5-을 포함하는 동작들을 수행하게 하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 15 항에 있어서, 상기 출력 이미지 프레임을 결정하는 것은, 상기 제 2 심도에 대응하는 상기 제 2 이미지 프레임의 세그먼트를 결정하는 것; 및상기 세그먼트를 상기 제 1 이미지 프레임과 병합하여 출력 이미지 프레임을 획득하는 것을 포함하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서, 상기 세그먼트를 상기 제 1 이미지 프레임과 병합하는 것은, 상기 제 1 이미지 프레임의 제 1 부분으로부터 제 1 세트의 픽셀들에 대응하는 제 1 이미지 데이터를 상기 출력이미지 프레임에 복사하는 것;상기 세그먼트로부터 제 2 세트의 픽셀들에 대응하는 제 2 이미지 데이터를 상기 출력 이미지 프레임에 복사하는 것; 및 상기 제 1 세트의 픽셀들과 상기 제 2 세트의 픽셀들 사이의 경계 영역 내의 제 3 세트의 픽셀들에 대응하는 상기 출력 이미지 프레임의 제 3 이미지 데이터를 결정하는 것으로서, 상기 제 3 이미지 데이터는 상기 제 1 이미지 프레임, 상기 제 2 이미지 프레임, 및 가중치에 기초하여 결정되는, 상기 제 3 이미지 데이터를 결정하는 것을 포함하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서, 상기 명령들은 상기 디바이스로 하여금, 상기 제 3 세트의 픽셀들 내의 픽셀에 대응하는 상기 제 1 이미지 프레임 내의 콘트라스트 값;상기 제 3 세트의 픽셀들 내의 픽셀에 대응하는 상기 제 2 이미지 프레임 내의 콘트라스트 값; 또는상기 제 3 세트의 픽셀들 내의 픽셀로부터 상기 제 1 세트의 픽셀들 또는 상기 제 2 세트의 픽셀들 중 적어도하나 내의 픽셀까지의 거리에 대응하는 거리 값중 적어도 하나에 기초하여 상기 가중치를 결정하는 것을 포함하는 동작들을 수행하게 하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 18 항에 있어서, 상기 명령들은 상기 디바이스로 하여금, 상기 제 1 이미지 프레임의 제 1 그래디언트 및 상기 제 2 이미지 프레임의 제 2 그래디언트에 기초하여 상기 가중치를 결정하는 것을 포함하는 동작들을 수행하게 하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 18 항에 있어서, 상기 가중치는, 상기 제 1 세트의 픽셀들 내의 제 1 대응 픽셀 또는 상기 제 2 세트의 픽셀들 내의 제 2 대응픽셀로부터, 상기 제 1 대응 픽셀에서의 그래디언트가 상기 제 2 대응 픽셀보다 큰지 여부에 기초하여, 상기 제3 세트의 픽셀들의 픽셀에 대한 값을 선택하는 것에 대응하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "공개특허 10-2023-0137316-6-제 15 항에 있어서, 상기 제 1 심도를 결정하는 것은 상기 심도 데이터에 기초하여 히스토그램의 제 1 피크에 대응하는 심도를 결정하는 것을 포함하고,상기 제 2 심도를 결정하는 것은 상기 히스토그램의 제 2 피크에 대응하는 심도를 결정하는 것을 포함하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 22 항에 있어서, 상기 명령들은 상기 디바이스로 하여금, 상기 제 2 심도에 대응하는 제 2 초점 거리에서 상기 제 2 이미지 프레임을 캡처하라는 커맨드를 송신하는 단계를 포함하는 동작들을 수행하게 하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 23 항에 있어서, 상기 커맨드를 송신하는 단계는 상기 제 2 초점 거리로 자동초점 알고리즘을 시딩하는 단계를 포함하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 15 항에 있어서, 상기 명령들은 상기 디바이스로 하여금, 상기 제 1 이미지 프레임의 제 3 부분에 대한 제 3 심도를 결정하는 것;상기 제 2 심도와 상기 제 3 심도 사이의 제 2 차이가 제 2 임계치를 초과하는지 여부를 결정하는 것;상기 제 2 차이가 상기 제 2 임계치를 초과할 때 상기 제 2 초점 거리와 상이한 제 3 초점 거리에서 제 3 이미지 프레임을 수신하는 것; 및 상기 제 1 이미지 프레임, 상기 제 2 이미지 프레임, 및 상기 제 3 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 것을 포함하는 동작들을 수행하게 하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 15 항에 있어서, 이미지 센서 및 상기 이미지 센서에 커플링된 렌즈를 더 포함하고, 상기 이미지 센서는 f/2.2보다 큰 애퍼처를포함하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 15 항에 있어서, 상기 제 2 이미지 프레임을 수신하는 것은 제 2 센서에 의해 촬영된 상기 제 2 이미지 프레임을 수신하는 것을포함하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제 15 항에 있어서, 상기 명령들은 상기 디바이스로 하여금, 객체 검출 알고리즘에 기초하여 상기 제 1 이미지 프레임 내의 제 1 관심 객체 및 제 2 관심 객체를 결정하는것;상기 제 1 관심 객체의 심도를 상기 제 1 심도로서 결정하는 것; 및공개특허 10-2023-0137316-7-상기 제 2 관심 객체의 심도를 상기 제 2 심도로서 결정하는 것을 포함하는 동작들을 수행하게 하는, 디바이스."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "명령들을 포함하는 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금,제 1 초점 거리에서 캡처된 장면을 나타내는 제 1 이미지 프레임을 수신하는 것; 상기 장면의 제 1 부분에 대한 상기 제 1 초점 거리에 대응하는 제 1 심도와 상기 장면의 제 2 부분에 대한 제2 심도 사이의 차이가 임계치를 초과하는지 여부를 결정하는 것; 및 상기 차이가 상기 임계치를 초과하는 때:상기 제 1 초점 거리와 상이한 제 2 초점 거리에서 캡처된 장면을 나타내는 제 2 이미지 프레임을 수신하는 것;및 상기 제 1 이미지 프레임 및 상기 제 2 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 것을 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 29 항에 있어서, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 출력 이미지 프레임을 상기 제 1 부분 및 상기 제 2 부분으로 세그먼트화하는 것; 및상기 제 1 부분이 아니라 상기 제 2 부분의 픽셀들에 블러링 알고리즘을 적용하는 것을 포함하는 동작들을 수행하게 하는 명령들을 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제 29 항에 있어서, 상기 출력 이미지 프레임을 결정하는 것은, 상기 제 2 심도에 대응하는 상기 제 2 이미지 프레임의 세그먼트를 결정하는 것; 및상기 세그먼트를 상기 제 1 이미지 프레임과 병합하여 출력 이미지 프레임을 획득하는 것을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제 31 항에 있어서, 상기 세그먼트를 상기 제 1 이미지 프레임과 병합하는 것은, 상기 제 1 이미지 프레임의 제 1 부분으로부터 제 1 세트의 픽셀들에 대응하는 제 1 이미지 데이터를 상기 출력이미지 프레임에 복사하는 것;상기 세그먼트로부터 제 2 세트의 픽셀들에 대응하는 제 2 이미지 데이터를 상기 출력 이미지 프레임에 복사하는 것; 및 상기 제 1 세트의 픽셀들과 상기 제 2 세트의 픽셀들 사이의 경계 영역 내의 제 3 세트의 픽셀들에 대응하는 상기 출력 이미지 프레임의 제 3 이미지 데이터를 결정하는 것으로서, 상기 제 3 이미지 데이터는 상기 제 1 이미지 프레임, 상기 제 2 이미지 프레임, 및 가중치에 기초하여 결정되는, 상기 제 3 이미지 데이터를 결정하는 것을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.공개특허 10-2023-0137316-8-청구항 33 제 32 항에 있어서, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 제 3 세트의 픽셀들 내의 픽셀에 대응하는 상기 제 1 이미지 프레임 내의 콘트라스트 값;상기 제 3 세트의 픽셀들 내의 픽셀에 대응하는 상기 제 2 이미지 프레임 내의 콘트라스트 값; 또는상기 제 3 세트의 픽셀들 내의 픽셀로부터 상기 제 1 세트의 픽셀들 또는 상기 제 2 세트의 픽셀들 중 적어도하나 내의 픽셀까지의 거리에 대응하는 거리 값중 적어도 하나에 기초하여 상기 가중치를 결정하는 것을 포함하는 동작들을 수행하게 하는 명령들을 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제 32 항에 있어서, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 제 1 이미지 프레임의 제 1 그래디언트및 상기 제 2 이미지 프레임의 제 2 그래디언트에 기초하여 상기 가중치를 결정하는 것을 포함하는 동작들을 수행하게 하는 명령들을 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제 32 항에 있어서, 상기 가중치는, 상기 제 1 세트의 픽셀들 내의 제 1 대응 픽셀 또는 상기 제 2 세트의 픽셀들 내의 제 2 대응픽셀로부터, 상기 제 1 대응 픽셀에서의 그래디언트가 상기 제 2 대응 픽셀보다 큰지 여부에 기초하여, 상기 제3 세트의 픽셀들의 픽셀에 대한 값을 선택하는 것에 대응하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제 29 항에 있어서, 상기 제 1 심도를 결정하는 것은 상기 심도 데이터에 기초하여 히스토그램의 제 1 피크에 대응하는 심도를 결정하는 것을 포함하고,상기 제 2 심도를 결정하는 것은 상기 히스토그램의 제 2 피크에 대응하는 심도를 결정하는 것을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제 36 항에 있어서, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 제 2 심도에 대응하는 제 2 초점 거리에서 상기 제 2 이미지 프레임을 캡처하라는 커맨드를 송신하는 단계를 포함하는 동작들을 수행하게 하는 명령들을 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제 37 항에 있어서, 상기 커맨드를 송신하는 단계는 상기 제 2 초점 거리로 자동초점 알고리즘을 시딩하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제 29 항에 있어서, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 공개특허 10-2023-0137316-9-상기 제 1 이미지 프레임의 제 3 부분에 대한 제 3 심도를 결정하는 것;상기 제 2 심도와 상기 제 3 심도 사이의 제 2 차이가 제 2 임계치를 초과하는지 여부를 결정하는 것;상기 제 2 차이가 상기 제 2 임계치를 초과할 때 상기 제 2 초점 거리와 상이한 제 3 초점 거리에서 제 3 이미지 프레임을 수신하는 것; 및 상기 제 1 이미지 프레임, 상기 제 2 이미지 프레임, 및 상기 제 3 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 것을 포함하는 동작들을 수행하게 하는 명령들을 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제 29 항에 있어서, 상기 제 2 이미지 프레임을 수신하는 것은 제 2 센서에 의해 촬영된 상기 제 2 이미지 프레임을 수신하는 것을포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제 29 항에 있어서, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 객체 검출 알고리즘에 기초하여 상기 제 1 이미지 프레임 내의 제 1 관심 객체 및 제 2 관심 객체를 결정하는것;상기 제 1 관심 객체의 심도를 상기 제 1 심도로서 결정하는 것; 및상기 제 2 관심 객체의 심도를 상기 제 2 심도로서 결정하는 것을 포함하는 동작들을 수행하게 하는 명령들을 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2023-7024724", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 캡처 디바이스들로 캡처된 이미지들에 대해 수행된 이미지 프로세싱은, 더 큰 애퍼처 렌즈들을 갖는 디바 이스들, 및 일부 특정 예들에서, 더 큰 애퍼처 렌즈들을 갖는 모바일 디바이스들로부터 캡처된 이미지들을 포함 하는, 디바이스들로부터 캡처된 이미지들에 대한 문제점들 중 일부를 개선하기 위해 사용될 수도 있다. 복수 의 이미지들은 캡처 디바이스에 의해 캡처될 수도 있고, 프로세싱은 복수의 이미지들의 융합을 통해 단일 이미지 를 생성하기 위해 적용될 수도 있다. 다수의 이미지들의 융합으로 획득되는 하나의 잠재적인 이점은 캡처 디 바이스로부터 획득된 단일 이미지에서 이용가능한 것보다 큰 유효 초점 심도 (DOF) 를 갖는 단일 이미지이다. 융합된 이미지의 DOF는 단일 이미지보다 클 수도 있고 그리고/또는 다수의 별개의 인-포커스 초점 거리들을 포 함할 수도 있는 반면, 단일 캡처 디바이스로부터의 단일 이미지는 단일 인-포커스 초점 거리만을 갖는다."}
{"patent_id": "10-2023-7024724", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원에 대한 상호 참조 본 출원은 \"IMAGE FUSION FOR SCENES WITH OBJECTS AT MULTIPLE DEPTHS\" 라는 명칭으로 2021년 1월 28일에 출 원된 미국 특허출원 제17/161,355호의 이익을 주장하며, 그 전체 내용은 참조에 의해 명시적으로 본원에 포함된 다. 본 개시의 양태들은 일반적으로 이미지 프로세싱에 관한 것이다. 본 개시의 일부 특징들은 이미지 캡처 디 바이스로부터의 출력의 이미지 신호 프로세서에 의한 프로세싱의 개선들을 가능하게 하고 제공할 수 있다."}
{"patent_id": "10-2023-7024724", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지 캡처 디바이스들은 사진들에 대한 스틸 이미지 또는 비디오들에 대한 이미지들의 시퀀스들이든 간에, 하 나 이상의 디지털 이미지들을 캡처할 수 있는 디바이스들이다. 캡처 디바이스들은 매우 다양한 디바이스들 에 통합될 수 있다. 예로서, 이미지 캡처 디바이스들은 독립형 디지털 카메라들 또는 디지털 비디오 캠코더 들, 모바일 전화기들, 셀룰러 또는 위성 라디오 전화기들과 같은 카메라 장착 무선 통신 디바이스 핸드셋들, 개 인 휴대 정보 단말기들 (PDA들), 패널들 또는 태블릿들, 게이밍 디바이스들, 웹캠들과 같은 컴퓨터 디바이스들, 비디오 감시 카메라들, 또는 디지털 이미징 또는 비디오 능력들을 갖는 다른 디바이스들을 포함할 수도 있다. 이미지 캡처 디바이스에 의해 캡처된 이미지들의 품질은 이미지 캡처 디바이스의 하나 이상의 이미지 센서들 상 에 큰 애퍼처 렌즈들을 사용함으로써 개선될 수 있다. 더 큰 애퍼처 렌즈들은 더 양호한 저조도 성능 (실내 및 야간 사진에 유리할 수 있음) 및 더 양호한 보케 블러 (Bokeh blur) (인물 사진에 유리할 수 있음) 를 비롯 한 많은 이점을 갖는다. 그러나, 큰 애퍼처 렌즈들은 또한 짧은 초점 심도 (depth of focus, DOF) 를 가지 며, 이는 캡처된 이미지의 제한된 부분들이 인-포커스 (in focus) 이고 이미지의 나머지 부분은 다양한 정도의 흐릿함을 갖는다. 장면이 다양한 거리들에서 많은 객체들을 포함할 때, 큰 애퍼처 렌즈를 갖는 이미지 캡처디바이스는 이 객체들 중 일부가 아웃-포커스 (out of focus) 인 이미지를 캡처할 것이다. 이는 특히 아웃- 포커스 객체들이 다른 사람들을 포함할 때 바람직하지 않을 수 있다. 여기서 언급된 단점들은 단지 대표적이며, 본 발명자들이 기존 디바이스들에 관하여 식별하였고 개선하고자 했 던 문제들을 강조하기 위해 포함된다. 아래에서 설명되는 디바이스들의 양태들은 단점들의 일부 또는 전부 뿐만 아니라 당업계에 알려진 다른 것들을 다룰 수도 있다. 아래에서 설명되는 개선된 디바이스들의 양태들 은 전술한 것들 이외의 다른 이점들을 제시할 수도 있고, 다른 애플리케이션들에서 사용될 수도 있다. 이미지 캡처 디바이스들로 캡처된 이미지들에 대해 수행된 이미지 프로세싱은, 더 큰 애퍼처 렌즈들을 갖는 디 바이스들, 및 일부 특정 예들에서, 더 큰 애퍼처 렌즈들을 갖는 모바일 디바이스들로부터 캡처된 이미지들을 포 함하는, 디바이스들로부터 캡처된 이미지들에 대한 문제점들 중 일부를 개선하기 위해 사용될 수도 있다. 복수의 이미지들은 캡처 디바이스에 의해 캡처될 수도 있고, 프로세싱은 복수의 이미지들의 융합을 통해 단일 이미지를 생성하기 위해 적용될 수도 있다. 다수의 이미지들의 융합으로 획득되는 하나의 잠재적인 이점은 캡처 디바이스로부터 획득된 단일 이미지에서 이용가능한 것보다 큰 유효 초점 심도 (DOF) 를 갖는 단일 이미지 이다. 융합된 이미지의 DOF는 단일 이미지보다 클 수도 있고 그리고/또는 다수의 별개의 인-포커스 초점 거 리들을 포함할 수도 있는 반면, 단일 캡처 디바이스로부터의 단일 이미지는 단일 인-포커스 초점 거리만을 갖는 다. 다수의 이미지들의 융합은 병합, 복사, 세그먼트화, 및 블렌딩과 같은 설명된 하나 이상의 이미지 프로 세싱 기법들을 포함할 수도 있다. 다수의 이미지의 융합은 캡처된 이미지 내에서 충족되는 특정 조건을 포 함하는 기준들에 기초하여 개시될 수도 있다. 일 실시형태에서, 디폴트 이미지 캡처는 캡처 디바이스로부터 의 제 1 입력 프레임을 프로세싱하는 것을 포함할 수도 있다. 심도 데이터 히스토그램에서 충분한 임계치에 의해 분리된 2 이상의 피크들과 같은 조건들이 제 1 이미지 프레임에서 식별될 때, 제 1 이미지 프레임을 추가 적인 이미지 프레임들과 융합하는 것을 포함하는, 프로세싱을 위해 추가적인 이미지 프레임들이 검색된다. 추가적인 프레임들의 검색은 이미지 캡처 디바이스로부터의 추가적인 이미지 캡처들을 트리거할 수도 있다."}
{"patent_id": "10-2023-7024724", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "다음은 논의된 기술의 기본 이해를 제공하기 위해 본 개시의 일부 양태들을 요약한다. 이 개요는 본 개시의 모든 고려된 특징들의 광범위한 개관이 아니며, 본 개시의 모든 양태들의 핵심적인 또는 결정적인 엘리먼트들을 식별하도록 의도된 것도 아니고 본 개시의 임의의 또는 모든 양태들의 범위를 기술하도록 의도된 것도 아니다. 유일한 목적은 하기에 제시되는 상세한 설명에 대한 서두로서 본 개시의 하나 이상의 양태들의 몇몇 개념들 을 단순화된 형태로 제공하는 것이다. 상이한 실시형태들에서, 디지털 카메라의 하드웨어 및/또는 소프트웨어는 이미지들을 캡처하고, 이미지들을 프 로세싱하고, 이미지 융합을 트리거하고, 그리고/또는 캡처된 이미지들을 융합할 수도 있으며, 일부 하드웨어 및 /또는 소프트웨어는 이미지들의 캡처와 융합된 이미지의 생성 사이에 다수의 단계들을 수행한다. 일부 실시 형태들에서, 디지털 카메라의 하드웨어는 캡처된 이미지들을 프로세싱하고, 융합 프로세싱이 트리거되어야 한다 고 결정하고, 추가적인 이미지들을 캡처하고, 이미지들을 융합함으로써 프로세싱하는 것을 포함하는 추가적인 프로세싱을 위해 이러한 추가적인 이미지들을 이미지 신호 프로세서 및/또는 애플리케이션 프로세서에 전달할 수도 있다. 융합 프로세싱의 트리거링은 하드웨어에 의해 결정된 미리 결정된 기준들 (예를 들어, 임계치를 초과하는 관심 객체들에 대한 초점 거리들의 차이) 에 기초하여 수행될 수도 있으며, 이는 고정 기능 하드웨어 및/또는 일반 프로세서에서 수행될 수도 있다. 다른 실시형태들에서, 융합 프로세싱의 트리거링은 대안적으 로, 예컨대 CPU 상에서 실행되는 이미지 프로세싱 기능들에 응답하여, 융합 프로세싱 캡처 모드를 활성화하는 사용자 입력에 응답하여, 고정 기능 융합 노드에 의한 결정들에 응답하여, 또는 이미지 신호 프로세서에 의한 결정들에 응답하여 CPU에 의해, 디바이스 내의 다른 컴포넌트로부터의 요청에 기초하여 수행될 수도 있다. 일부 실시형태들에서, 이미지 신호 프로세서는 실제 이미지 캡처 컴포넌트들 (예를 들어, 이미지 센서들 및 렌 즈) 과 별개의 디바이스에 있을 수도 있고, 융합 노드, 중앙 처리 유닛, 메모리, 및/또는 저장부 중 하나 이상 과 함께 시스템 온 칩 (SoC) 에 통합될 수 있다. 장면을 나타내는 출력 프레임이 다수의 이미지 프레임들을 융합함으로써 생성된 후, 장면의 뷰가 디바이스 디스 플레이 상에 디스플레이되고, 픽처로서 또는 비디오로서 픽처들의 시퀀스로서 저장 디바이스에 저장되고, 네트 워크를 통해 송신되고, 그리고/또는 출력 매체에 인쇄될 수도 있다. 예를 들어, 이미지 신호 프로세서는 하 나 이상의 이미지 센서들로부터의 하나 이상의 이미지 프레임들로부터 이미지 데이터의 입력 프레임들 (예를 들 어, 픽셀 값들) 을 획득하고, 차례로, 이미지 데이터의 대응하는 출력 프레임들 (예를 들어, 미리보기 디스플레 이 프레임들, 정지 이미지 캡처들, 비디오에 대한 프레임들 등) 을 생성하도록 구성될 수도 있다. 다른 예들에서, 이미지 신호 프로세서는 3A 파라미터 동기화, 출력 프레임들을 통해 비디오 파일을 생성하는 것, 디스 플레이를 위한 프레임들을 구성하는 것, 저장을 위한 프레임들을 구성하는 것 등과 같은 추가 프로세싱을 위해 이미지 데이터의 프레임들을 다양한 출력 디바이스들 및/또는 카메라 모듈들에 출력할 수도 있다. 즉, 이미 지 신호 프로세서는 하나 이상의 카메라 렌즈들에 각각 커플링된 하나 이상의 이미지 센서들로부터 들어오는 프 레임들을 획득할 수도 있고, 차례로, 출력 프레임들의 흐름을 생성하여 다양한 출력 목적지들에 출력할 수도 있 다. 본 개시의 일 양태에서, 방법은 제 1 초점 거리에서 제 1 초점으로 캡처된 장면을 나타내는 제 1 이미지 프레임 을 수신하는 단계; 및 장면의 제 1 부분에 대한 제 1 심도와 장면의 제 2 부분에 대한 제 2 심도 사이의 차이가 임계치를 초과하는지 여부를 결정하는 단계를 포함한다. 차이가 임계치를 초과하는 때, 방법은 제 1 초점 거리와 상이한 제 2 초점 거리에서 캡처된 제 2 이미지 프레임을 수신하는 단계; 및 제 1 이미지 프레임 및 제 2 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 단계를 계속 수행할 수도 있다. 출력 이미지 프레임을 결정하기 위한 방법은 출력 이미지 프레임을 제 1 부분 및 제 2 부분으로 세그먼트화하는 단계; 및/또 는 제 1 부분이 아니라 제 2 부분의 픽셀들에 블러링 알고리즘을 적용하는 단계를 포함할 수도 있다. 출력 이미지 프레임을 결정하기 위한 방법은 추가적으로 또는 대안적으로, 제 2 심도에 대응하는 제 2 이미지 프레임 의 세그먼트를 결정하는 단계; 및/또는 출력 이미지 프레임을 획득하기 위해 세그먼트를 제 1 이미지 프레임과 병합하는 단계를 포함할 수도 있다. 출력 이미지 프레임을 결정하기 위한 방법은 추가적으로 또는 대안적으 로, 제 1 세트의 픽셀들에 대응하는 제 1 이미지 데이터를 제 1 이미지 프레임의 제 1 부분으로부터 출력 이미 지 프레임으로 복사하는 단계; 제 2 세트의 픽셀들에 대응하는 제 2 이미지 데이터를 제 2 이미지 프레임의 세 그먼트로부터 출력 이미지 프레임으로 복사하는 단계; 및/또는 제 1 세트의 픽셀들과 제 2 세트의 픽셀들 사이 의 제 3 세트의 픽셀들에 대응하는 출력 이미지 프레임의 제 3 이미지 데이터를 결정하는 단계를 포함할 수도 있고, 제 3 이미지 데이터는 제 1 이미지 프레임, 제 2 이미지 프레임, 및 가중치에 기초하여 결정된다. 가 중치들은 제 1 이미지 프레임의 콘트라스트 값; 제 3 세트의 픽셀들 내의 픽셀로부터 제 1 세트의 픽셀들 또는 제 2 세트의 픽셀들 중 적어도 하나 내의 픽셀까지의 거리에 대응하는 거리 값; 제 1 이미지 프레임의 제 1 그 래디언트; 및/또는 제 2 이미지 프레임의 제 2 그래디언트 중 적어도 하나에 기초하여 결정될 수도 있다. 일부 실시형태들에서, 가중치는 제 1 세트의 픽셀들 내의 제 1 대응 픽셀 또는 제 2 세트의 픽셀들 내의 제 2 대응 픽셀로부터 제 3 세트의 픽셀들의 픽셀에 대한 값을, 제 1 대응 픽셀에서의 그래디언트가 제 2 대응 픽셀 보다 큰지 여부에 기초하여 선택하는 것에 대응한다. 방법은 2 초과의 이미지 프레임들에 대해 유사한 동작들을 수행하는 단계를 포함할 수도 있다. 예를 들어, 방법은, 심도 데이터에 기초하여, 제 1 이미지 프레임의 제 3 부분에 대한 제 3 심도를 결정하는 단계; 제 2 심 도와 제 3 심도 사이의 제 2 차이가 제 2 임계치를 초과하는지 여부를 결정하는 단계; 제 2 차이가 제 2 임계치 를 초과할 때, 제 2 초점 거리와 상이한 제 3 초점 거리에서 제 3 이미지 프레임을 캡처하라는 커맨드를 송신하 는 단계; 제 3 초점 거리에서 캡처된 제 3 이미지 프레임을 수신하는 단계; 및/또는 제 1 이미지 프레임, 제 2 이미지 프레임 및 제 3 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 단계를 포함할 수도 있다. 본 개시의 추가의 양태에서, 적어도 하나의 프로세서, 및 적어도 하나의 프로세서에 커플링된 메모리를 포함하 는 장치가 개시된다. 적어도 하나의 프로세서는 본 명세서에 설명된 방법들 또는 기법들 중 임의의 것을 수 행하도록 구성된다. 예를 들어, 적어도 하나의 프로세서는 캡처 디바이스로부터의 제 1 이미지 프레임을 분 석하는 단계, 추가적인 이미지 프레임들의 캡처를 검색 및/또는 트리거할지 여부를 결정하는 단계, 및/또는 출 력 프레임을 생성하기 위해 2 이상의 이미지 프레임들을 융합하는 단계를 포함하는 단계들을 수행하도록 구성될 수도 있다. 적어도 하나의 프로세서는 이미지 신호 프로세서 또는 카메라 제어 및/또는 프로세싱을 위한 특 정 기능을 포함하는 프로세서를 포함할 수도 있다. 적어도 하나의 프로세서는 또한 또는 대안적으로 애플리 케이션 프로세서를 포함할 수도 있다. 본 명세서에 설명된 방법들 및 기법들은 이미지 신호 프로세서 또는 애플리케이션 프로세서에 의해 전체적으로 수행될 수도 있거나, 또는 다양한 동작들은 이미지 신호 프로세서와 애플리케이션 프로세서, 그리고 일부 실시형태들에서 추가적인 프로세서 사이에서 분할될 수도 있다. 본 개시의 추가적인 양태에서, 이미지 캡처를 위해 구성된 디바이스가 개시된다. 장치는 제 1 초점 거리에 서 제 1 초점으로 캡처된 장면을 나타내는 제 1 이미지 프레임을 수신하기 위한 수단, 장면의 제 1 부분에 대한 제 1 심도와 장면의 제 2 부분에 대한 제 2 심도 사이의 차이가 임계치를 초과하는지 여부를 결정하기 위한 수 단, 제 1 초점 거리와 상이한 제 2 초점 거리로 캡처된 장면을 나타내는 제 2 이미지 프레임을 수신하기 위한 수단; 및/또는 제 1 이미지 프레임 및 제 2 이미지 프레임에 기초하여 출력 이미지 프레임을 결정하기 위한 수 단을 포함한다. 출력 이미지 프레임을 결정하기 위한 수단은 세그먼트화하기 위한 수단, 병합하기 위한 수단, 그래디언트 맵들을 결정하기 위한 수단, 히스토그램 심도 데이터를 결정하기 위한 수단, 및/또는 블렌딩하 기 위한 수단을 포함할 수도 있다. 장치는 이미지 센서들 (전하 결합 소자들 (CCD들), Bayer-필터 센서들, 적외선 (IR) 검출기들, 자외선 (UV) 검출기들, 상보형 금속 산화물 반도체 (CMOS) 센서들을 포함함), 비행 시간 검출기들과 같은, 장면을 나타내는 데이터를 캡처하기 위한 하나 이상의 수단을 더 포함한다. 장치는 광선 을 하나 이상의 이미지 센서에 축적 및/또는 포커싱하기 위한 하나 이상의 수단 (단순 렌즈, 복합 렌즈, 구면 렌즈 및 비구면 렌즈를 포함함) 을 더 포함할 수도 있다. 본 개시의 추가적인 양태에서, 비일시적 컴퓨터 판독가능 매체는, 프로세서에 의해 실행될 때, 프로세서로 하여 금, 본 명세서에 설명된 방법 및 기법들에서 설명된 것들을 포함하는 동작들을 수행하게 하는 명령들을 저장한 다. 예를 들어, 동작들은 제 1 초점 거리에서 제 1 초점으로 캡처된 장면을 나타내는 제 1 이미지 프레임을 수신하는 것; 및 장면의 제 1 부분에 대한 제 1 심도와 장면의 제 2 부분에 대한 제 2 심도 사이의 차이가 임계 치를 초과하는지 여부를 결정하는 것을 포함할 수도 있고; 차이가 임계치를 초과할 때, 명령들은 제 1 초점 거 리와 상이한 제 2 초점 거리에서 캡처된 제 2 이미지 프레임을 수신하는 것; 및 제 1 이미지 프레임 및 제 2 이 미지 프레임에 기초하여 출력 이미지 프레임을 결정하는 것을 계속 수행할 수도 있다. 본 개시의 부가적인 양태에 따르면, 모바일 디바이스가 이미지 센서, 이미지 신호 프로세서, 고정 기능 융합 노 드, 및 애플리케이션 프로세서 (AP) 로서 기능하는 중앙 처리 유닛 (CPU) 를 포함할 수도 있다. 장면 검출 스킴(scheme)은 모바일 디바이스 상에서 실행되는 카메라 애플리케이션의 프리뷰 동작 동안, 본 명세서에 설명 된 바와 같은 심도 정보를 사용하는 것과 같이, 다수의 관심 영역들의 존재를 검출하기 위해 AP 상에서 실행될 수도 있다. 사용자가 셔터 버튼을 클릭하는 것과 같은 캡처 요청이 이루어질 때, 심도 히스토그램 상의 다 수의 피크들이 검출될 때, AP는 추가 처리를 위해 다수의 이미지들 및 다수의 초점면들을 캡처하기 위해 카메라 하드웨어에 신호를 송신한다. 이미지 센서, 렌즈 및 자동초점 (AF) 시스템과 같은 카메라 하드웨어가 AF 브 래키팅(bracketing) 스킴을 실행하여 2개의 이미지들을 캡처한다. 이 이미지들은 개별 이미지들을 강화하기 위해 이미지 신호 프로세서에 의해 프로세싱될 수도 있으며, 쌍방의 이미지들은 ISP로부터 융합 노드로 송신된 다. 융합 노드는 예를 들어, 본 명세서에 설명된 연합 윤곽 맵, 가중, 및 조합에 기초하여 대응하는 심도 데이터로 이들 2개의 이미지들을 프로세싱한다. 그 후, 융합 노드는 카메라 애플리케이션에서의 디스플레이, 갤러리 애플리케이션에서의 추후 디스플레이를 위해 모바일 디바이스의 저장부에 저장, 또는 그렇 지 않으면 송신, 저장, 또는 추가 프로세싱을 위해 단일 이미지 파일을 AP에 출력한다. 본 개시의 추가적인 양태에서, 장치는 이미지 센서 및 이미지 센서에 커플링된 자동초점 (AF) 회로부를 포함하 는 디지털 카메라를 포함할 수도 있고, AF 회로부는 이미지 센서를 제 1 초점면에 포커싱하고, 제 1 초점면에서 이미지 센서로부터 제 1 이미지 데이터를 수신하고, 제 1 이미지 데이터 내의 객체들 사이의 거리를 결정하고, 거리가 임계치를 초과한다고 결정하고, 이미지 센서를 제 2 초점면에 포커싱하고, 제 2 초점면에서 이미지 센서 로부터 제 2 이미지 데이터를 수신하도록 구성된다. 일부 양태들에서, 객체들 사이의 거리는 심도 데이터 히스토그램에서 피크들을 결정하고 피크들 사이의 거리를 객체들 사이의 거리로서 결정함으로써 결정될 수도 있 다. 심도 데이터 히스토그램은, 예를 들어, 이미지 센서와 별개인 심도 센서로부터, 상이한 시야로 장면을 캡처하는 제 2 이미지 센서로부터의 대응하는 제 2 이미지 데이터, 및/또는 이미지 센서의 비중첩 부분으로부터 의 대응하는 제 2 이미지 데이터로부터 수신될 수도 있다. 제 1 및 제 2 이미지 데이터는 제 1 및 제 2 이 미지 데이터에 대해 융합 프로세싱을 수행하기 위한 이미지 신호 프로세서 및/또는 애플리케이션 프로세서와 같 은 다른 프로세싱 회로부에 전달될 수도 있다. 다른 양태들, 특징들, 및 구현들은, 첨부 도면들과 함께 특정한 예시적인 양태들의 다음의 설명을 검토할 시, 당업자에게 자명하게 될 것이다. 특징들이 하기의 특정 양태들 및 도면들에 대해 논의될 수도 있지만, 다양 한 양태들이 본 명세서에서 논의된 유리한 특징들 중 하나 이상을 포함할 수도 있다. 즉, 하나 이상의 양태 들이 특정한 유리한 특징들을 갖는 것으로서 논의될 수도 있지만, 그러한 특징들의 하나 이상이 또한, 다양한 양태들에 따라 사용될 수도 있다. 유사한 방식으로, 예시적인 양태들이 디바이스, 시스템, 또는 방법 양태 들로서 하기에서 논의될 수도 있지만, 예시적인 양태들은 다양한 디바이스들, 시스템들, 및 방법들로 구현될 수 있다. 전술한 것은 후속하는 상세한 설명이 더 잘 이해될 수도 있도록 본 발명의 실시형태들의 특정 특징들 및 기술적 이점들을 다소 폭넓게 개괄하였다. 본 발명의 청구항들의 주제를 형성하는 부가적인 특징들 및 이점들이 이 하에서 설명될 것이다. 개시된 개념 및 특정 실시형태가 동일한 또는 유사한 목적들을 수행하기 위한 다른 구조들을 수정 또는 설계하기 위한 기반으로서 용이하게 활용될 수도 있음을 당업자는 인식하여야 한다. 또 한 당업자는 그러한 균등 구성들이 첨부된 청구항들에 기재된 바와 같은 본 발명의 정신 및 범위로부터 벗어나지 않음을 이해하여야 한다. 추가적인 특징들은 첨부 도면과 관련하여 고려될 때 이하의 설명으로부터 더 잘 이해될 것이다. 그러나, 도면들 각각은 단지 예시 및 설명의 목적을 위해 제공되고, 본 발명을 제한하려 는 것이 아님을 분명히 이해하여야 한다."}
{"patent_id": "10-2023-7024724", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부된 도면들과 관련하여, 이하에 기재된 상세한 설명은, 다양한 구성들의 설명으로서 의도되고, 본 개시의 범 위를 한정하도록 의도되지 않는다. 오히려, 상세한 설명은 발명의 주제의 철저한 이해를 제공할 목적으로 특정 상세들을 포함한다. 이들 특정 상세들이 모든 경우에 요구되지는 않으며 일부 사례들에 있어서 널리 공지된 구조들 및 컴포넌트들은 제시의 명료화를 위해 블록 다이어그램 형태로 도시됨이 당업자에게 자명할 것 이다. 본 개시는 장면의 다수의 이미지들을 캡처함으로써 이미지 캡처 디바이스로부터의 개선된 이미지 품질을 지원하 는 시스템들, 장치, 방법들, 및 컴퓨터 판독가능 매체들을 제공한다. 개선된 방법들은 장면의 캡처된 다수 의 이미지들을 조합하기 위해 융합 로직을 사용하여 프로세싱하는 것을 설명한다. 이 이미지들은 동일한 디 바이스 설정들을 갖는 동일한 캡처 디바이스, 상이한 디바이스 설정들을 갖는 동일한 캡처 디바이스를 사용하여 캡처될 수도 있고, 및/또는 상이한 캡처 디바이스들을 사용하여 캡처되어, 장면의 다른 캡처된 이미지들과는 장 면에 관한 상이한 정보를 제공하는 각각의 이미지를 초래할 수 있다. 상이한 이미지 캡처들에 대한 상이한 설정들은 제 1 센서가 장면의 상이한 뷰들을 캡처하도록 캡처 동안 디바이스를 재구성한 결과일 수도 있다. 예를 들어, 제 1 센서는 2개의 상이한 초점 거리들에 초점을 갖도록 구성될 수도 있다. 일부 실시형태들에 서, 본 명세서에 설명된 융합 프로세싱에 대한 이미지 프레임 입력은 이미지 캡처 디바이스의 다수의 센서들로 부터 출력된 이미지들의 융합 자체이다. 본 개시의 양태들은 이미지 캡처 디바이스의 다수의 이미지 센서들을 사용하여 이미지 프레임들을 캡처하기 위 해 사용될 수도 있다. 복수의 이미지 센서들은 울트라-와이드 (high field-of-view (FOV)), 와이드, 텔레, 및 울트라-텔레 (low FOV) 센서들의 조합을 포함할 수도 있다. 즉, 각각의 이미지 센서는 인-포커스인 이미지의 상이한 부분들을 갖는 장면의 이미지들을 획득하기 위해 하드웨어 구성 및/또는 소프트웨어 설정들을 통해 구성될 수도 있다. 이미지 신호 프로세서 및/또는 프로세서 내에서와 같은 이미지 캡처 디바이 스 내의 융합 로직은 장면의 다수의 이미지들을 결합하여 다수의 초점 거리들을 갖는 개선된 이미지를 획득하여, 상이한 초점 거리들에 있는 객체들이 융합된 이미지에서 인-포커스되게 할 수도 있다. 이는, 이 미지 캡처 디바이스가 단일 이미지 캡처에서 장면의 일부 객체들이 아웃-포커스로 보이는 것을 초래하는 큰 애 퍼처 렌즈들을 가질 때와 같이, 이미지 품질을 향상시키는 데 유리할 수도 있다. 스마트폰과 같은 이미지 프레임들을 캡처하기 위한 예시적인 디바이스는 디바이스의 후면 (예를 들어, 사용자 디스플레이의 반대측) 또는 전면 (예를 들어, 사용자 디스플레이와 동일한 측면) 상에 하나, 둘, 셋, 넷 이상의 카메라들의 구성을 포함할 수도 있다. 디바이스들은 하나 이상의 이미지 신호 프로세서들, 컴퓨터 비전 프 로세서들 (CVP들), 또는 하나 이상의 이미지 센서들에 의해 캡처된 이미지들을 프로세싱하기 위한 다른 적합한 회로부를 포함할 수도 있다. 하나 이상의 이미지 신호 프로세서는, 인코딩 또는 다른 조작과 같은, 추가 프 로세싱을 위해, 프로세싱된 이미지 프레임들을 메모리 및/또는 프로세서 (예컨대, 애플리케이션 프로세서, 이미 지 프론트 엔드 (IFE), 이미지 프로세싱 엔진 (IPE), 또는 다른 적절한 프로세싱 회로부) 에 제공할 수도 있다. 본 명세서에서 사용된 바와 같이, 이미지 센서는 이미지 센서 자체 및 이미지 센서에 커플링된 임의의 다른 적 절한 컴포넌트들을 지칭할 수도 있다. 예를 들어, 이미지 센서는 또한 셔터, 버퍼, 또는 다른 판독 회로부 를 포함하는 카메라의 다른 컴포넌트들을 지칭할 수도 있다. 이미지 센서는 또한 아날로그 신호들을 프레임 에 대한 디지털 표현들로 변환하기 위한 아날로그 프론트 엔드 또는 다른 회로부를 지칭할 수도 있다. 따라 서, 본 명세서에서의 용어 \"이미지 센서\"는 메모리, 프로세서, 이미지 신호 프로세서, 또는 다른 로직이나 메모 리 회로부 중 적어도 하나에 대한 이미지 프레임의 캡처 및 판독을 위한 임의의 적절한 컴포넌트들을 지칭할 수 도 있다. 다음의 설명에서, 본 개시의 철저한 이해를 제공하기 위해 특정 컴포넌트들, 회로들, 및 프로세스들의 예들과 같은 많은 특정 상세들이 기술된다. 본 명세서에 사용된 바와 같은 용어 \"커플링된\" 은 하나 이상의 개재 컴포넌트들 또는 회로들에 직접 접속되거나 또는 이를 통해 접속된 것을 의미한다. 또한, 다음의 기재에서 그리고 설명의 목적으로, 본 개시의 철저한 이해를 제공하기 위해 특정 명명법이 제시된다. 그러나, 이 특 정 상세들은 본 명세서에 개시된 기법들을 실시하는데 필요하지 않을 수도 있음이 당업자에게 명백할 것이다. 다른 경우들에서, 잘 알려진 회로들 및 디바이스들은 본 개시의 교시들을 모호하게 하는 것을 회피하기 위해 블록 다이어그램 형태로 나타낸다. 다음에 이어지는 상세한 설명들의 일부 부분들은 절차들, 로직 블록들, 프로세싱, 및 컴퓨터 메모리 내에서의 데이터 비트들에 대한 동작들의 다른 심볼 표현들의 관점에서 제시된다. 본 개시에 있어서, 절차, 로직 블록, 프로세스 등은 원하는 결과로 이끄는 단계들 또는 명령들의 자기-일관 성있는 시퀀스인 것으로 인식된다. 단계들은 물리량들의 물리적 조작들을 요구하는 것들이다. 필수적인 것은 아니지만 통상적으로, 이들 양들은 컴퓨터 시스템에서 저장되고, 전송되고, 결합되고, 비교되고, 그렇지 아니면 조작되는 것이 가능한 전기적 또는 자기적 신호들의 형태를 취한다. 하지만, 이들 용어 및 유사한 용어들 모두는 적절한 물리량들과 연관되어야 하고, 이들 양들에 적용된 단지 편 리한 라벨들임을 명심해야 한다. 다음의 논의로부터 명백한 바와 같이 달리 구체적으로 언급되지 않는 한, 본 출원 전체에 걸쳐, \"액세스하는것\", \"수신하는 것\", \"전송하는 것\", \"사용하는 것\", \"선택하는 것\", \"결정하 는 것\", \"정규화하는 것\", \"승산하는 것\", \"평균화하는 것\", \"모니터링하는 것\", \"비교하는 것\", \"적용하는 것\", \"업데이트하는 것\", \"측정하는 것\", \"도출하는 것\", \"정산하는 것 (settling) \", \"생성하는 것\" 등과 같은 용어들을 활용한 논의는, 컴퓨터 시스템의 레지스터 및 메모리 내의 물리적 (전자적) 양으로서 표현된 데이터를 컴퓨터 시스템 메모리 또는 레지스터 또는 다른 그러한 정보 저장, 송신 또는 디스플레이 디바이스 내의 물리적 양으로서 유사하게 표현된 다른 데이터로 조작 또는 변환하는, 컴퓨터 시스템, 또는 유사한 전자 컴퓨팅 디바이 스의 액션들 및 프로세스들을 지칭한다고 이해된다. 도면들에서, 단일 블록은 기능 또는 기능들을 수행하는 것으로 설명될 수도 있다; 그러나, 실제 실시에 있어서 는, 블록에 의해 수행된 기능 또는 기능들은 단일 컴포넌트에서 또는 다중 컴포넌트들에 걸쳐 수행될 수도 있고, 및/또는 하드웨어, 소프트웨어, 또는 하드웨어와 소프트웨어의 조합을 사용하여 수행될 수도 있다. 하드웨어와 소프트웨어의 이러한 상호교환 가능성을 분명히 예시하기 위해, 다양한 예시적인 컴포넌트들, 블록 들, 모듈들, 회로들, 및 단계들이 일반적으로 그들의 기능성의 관점에서 하기에서 설명된다. 그러한 기능성 이 하드웨어로서 구현될지 또는 소프트웨어로서 구현될지는 전체 시스템에 부과된 설계 제약들 및 특정 어플리 케이션에 의존한다. 당업자는 설명된 기능성을 각각의 특정 어플리케이션에 대하여 다양한 방식들로 구현할 수도 있지만, 그러한 구현의 결정들이 본 개시의 범위로부터의 일탈을 야기하는 것으로서 해석되지는 않아야 한다. 또한, 예시적인 디바이스들은, 프로세서, 메모리 등과 같은 널리 공지된 컴포넌트들을 포함하여, 도시 된 것들 이외의 컴포넌트들을 포함할 수도 있다. 본 개시의 양태들은 이미지 프레임들 (또는 \"프레임들\") 을 캡처할 수 있는 2 이상의 이미지 센서들을 포함하거 나 이에 커플링되는 임의의 적절한 전자 디바이스에 적용가능하다. 또한, 본 개시의 양태들은 동일하거나 상이한 능력들 및 특성들 (예컨대, 해상도, 셔터 속도, 센서 타입 등) 의 이미지 센서들을 갖거나 이에 커플링 된 디바이스들에서 구현될 수도 있다. 용어들 \"디바이스\" 및 \"장치\"는 하나 또는 특정 수의 물리적 객체 (예컨대, 하나의 스마트폰, 하나의 카메라 제 어기, 하나의 프로세싱 시스템 등) 로 제한되지 않는다. 본 명세서에서 사용된 바와 같이, 디바이스는 본 개시의 적어도 일부 부분들을 구현할 수도 있는 하나 이상의 부분을 갖는 임의의 전자 디바이스일 수도 있다. 하기 설명 및 예들은 본 개시의 다양한 양태들을 설명하기 위해 용어 \"디바이스\"를 사용하지만, 용어 \"디바 이스\"는 특정 구성, 타입 또는 객체들의 수로 제한되지 않는다. 본 명세서에서 사용된 바와 같이, 장치는 설명된 동작들을 수행하기 위한 디바이스 또는 디바이스의 일부를 포함할 수도 있다. 도 1은 다수의 이미지 센서들로부터의 이미지 캡처를 수행하기 위한 예시적인 디바이스 의 블록도를 도시 한다. 디바이스 는 제 1 이미지 센서 및 제 2 이미지 센서 와 같은 다수의 이미지 센서 들로부터의 이미지 프레임들을 프로세싱하기 위한 이미지 신호 프로세서 를 포함하거나, 그렇지 않으면 그에 커플링될 수도 있다. 일부 구현들에서, 디바이스 는 또한 프로세서 및 명령들 을 저장하는 메모리 를 포함하거나 또는 이에 커플링된다. 디바이스 는 또한 디스플레이 및 다수의 입력/출력 (I/O) 컴포넌트들 을 포함하거나 이에 커플링될 수도 있다. 디바이스 는 또 한 디바이스 를 에너지원에 커플링하기 위한 컴포넌트 또는 배터리와 같은 디바이스 를 위한 전력 공급부 를 포함하거나 이에 커플링될 수도 있다. 디바이스 는 또한 도시되지 않은 부가 특징부 들 또는 컴포넌트들을 포함하거나 이에 커플링될 수도 있다. 일 예에서, 다수의 트랜시버들 및 기저대역 프 로세서를 포함할 수도 있는 무선 인터페이스가, 무선 통신 디바이스를 위해 포함될 수도 있다. 다른 예에서, (자이로스코프 또는 글로벌 포지셔닝 시스템 (GPS) 수신기와 같은) 하나 이상의 센서가 디바이스에 포 함되거나 커플링될 수도 있다. 추가 예에서, 아날로그 이미지 프레임 데이터를 디지털 이미지 프레임 데이 터로 변환하기 위한 아날로그 프론트 엔드가 이미지 센서들 (101 및 102) 과 이미지 신호 프로세서 사이 에 커플링될 수도 있다. 이미지 신호 프로세서 는 이미지 센서들 (101 및/또는 102) 에 대한 로컬 버스 접속으로부터 또는 외부 이미지 센서에 대한 유선 인터페이스 또는 원거리 이미지 센서에 대한 무선 인터페이스와 같은 다른 접속들에 의해 이미지 데이터를 수신할 수도 있다. 일부 실시형태들에서, 디바이스 는 제 1 이미지 센서 및 대응하는 제 1 렌즈 및 자동초점 로직 을 포함하는 제 1 카메라 , 및 제 2 이미지 센서 및 대응하는 제 2 렌즈 및 자동초점 로직 을 포함하는 제 2 카메라 를 포함할 수도 있 다. 자동초점 로직 (141, 142) 은 자동초점 로직 (141, 142) 의 알고리즘에 의해 결정된 특정 초점면에 각 각 포커싱되는 이미지 프레임을 이미지 센서들 (101, 102) 로부터 획득하기 위해 각각 렌즈들 (131, 132) 을 조 정하기 위한 전용 하드웨어일 수도 있다. 일부 실시형태들에서, 디바이스 는 디바이스 로부터 떨어져 위치된 이미지 센서들 (101 및 102) 로부터 이미지 데이터를 수신하기 위한 인터페이스를 포함할 수도 있다. 디바이스 는 디바이스 내에 위치된 또는 디바이스 로부터 분리된 이미지 센서들의 조합으로부터 이미지 데이터에 대한 이미지 프로세싱을 수행할 수도 있다. 제 1 이미지 센서 및 제 2 이미지 센서 는 하나 이상의 이미지 프레임을 캡처하도록 구성된다. 예를 들어, 제 1 이미지 센서 및 제 2 이미지 센서 는 하나 또는 다수의 카메라 구성 (예컨대, 스 마트폰 또는 다른 적절한 디바이스를 위한 듀얼 카메라 구성, 트리플 카메라 구성 등) 에 포함될 수도 있다. 이미지 센서들 (101 및 102) 은 또한 광을 포커싱하기 위한 하나 이상의 렌즈, 광을 수신하기 위한 하나 이상 의 애퍼처, 노출 윈도우 외부에 있을 때 광을 차단하기 위한 하나 이상의 셔터, 특정 주파수 범위들 외부의 광 을 필터링하기 위한 하나 이상의 컬러 필터 어레이 (CFA), 아날로그 측정들을 디지털 정보로 변환하기 위한 하 나 이상의 아날로그 프론트 엔드, 또는 이미징을 위한 다른 적절한 컴포넌트들을 포함하거나 이에 커플링될 수 도 있다. 예를 들어, 제 1 이미지 센서 는 제 1 렌즈 에 커플링될 수도 있고, 제 2 이미지 센 서 는 제 2 렌즈 에 커플링될 수도 있다. 제 1 렌즈 가 UW (ultra wide) 렌즈이고 제 2 렌즈 가 W (wide) 렌즈인 경우와 같이, 제 1 렌즈 와 제 2 렌즈 는 상이한 시야를 가질 수 도 있다. 디바이스 는 또한 플래시, 심도 센서, GPS, 또는 이미징을 위한 다른 적절한 컴포넌트들을 포함하거나 이에 커플링될 수도 있다. 다중-이미지 캡처 디바이스에서 센서들 (101 및 102) 을 포함하는 센서들에 대한 하나의 예시적인 구성은 UT 센서보다 큰 FOV를 갖는 T 센서보다 큰 FOV를 갖는 W 센서보다 큰 FOV 를 갖는 UW 센서이다. 예를 들어, 넓은 FOV를 위해 구성된 센서는 64-84도 범위의 시야들을 캡처할 수 있고, 울트라-사이드 FOV를 위해 구성된 센서는 100-140도 범위의 시야들을 캡처할 수 있고, 텔레 FOV를 위해 구성된 센서는 10-30도 범위의 시야들을 캡처할 수 있고, 울트라-텔레 FOV를 위해 구성된 센서는 1-8도 범위의 시야들을 캡처할 수 있다. 이미지 신호 프로세서 는 이미지 센서들 (101, 102) 에 의해 캡처된 이미지 프레임들을 프로세싱한다. 도 1이 이미지 신호 프로세서 에 커플링된 2개의 이미지 센서들 (101 및 102) 을 포함하는 것으로 디바 이스 를 예시하지만, 임의의 수의 이미지 센서들이 이미지 신호 프로세서 에 커플링될 수도 있다. 또한, 디바이스 에 대해 임의의 수의 추가적인 이미지 센서들 또는 이미지 신호 프로세서들이 존재할 수도 있다. 일부 실시형태들에서, 이미지 신호 프로세서 는 메모리로부터의 명령들, 예컨대 메모리 로부터의 명령들 , 이미지 신호 프로세서 에 커플링되거나 포함된 별도의 메모리에 저장된 명 령들, 또는 프로세서 에 의해 제공된 명령들을 실행할 수도 있다. 추가적으로, 또는 대안적으로, 이 미지 신호 프로세서 는 소프트웨어를 실행할 수도 있고/있거나 본 개시에서 설명된 하나 이상의 동작을 수행하기 위해 특정 하드웨어 (예컨대, 하나 이상의 집적 회로 (IC)) 를 포함할 수도 있다. 일부 구현들에서, 메모리 는 본 개시에서 설명된 하나 이상의 동작들의 전부 또는 일부분을 수행하기 위 한 컴퓨터 실행가능 명령들 을 저장하는 비순간적 또는 비일시적인 컴퓨터 판독가능 매체를 포함할 수도 있다. 일부 구현들에서, 명령들 은 이미지들 또는 비디오들을 생성하기 위해 디바이스 에 의해 실행될 카메라 애플리케이션 (또는 다른 적절한 애플리케이션) 을 포함한다. 명령들 은 또한 이미지 또는 비디오 생성을 위한 것 이외의 운영 체제 및 특정 애플리케이션들과 같은, 디바이스 에 의해 실행되 는 다른 애플리케이션들 또는 프로그램들을 포함할 수도 있다. 프로세서 에 의한 것과 같은 카메라 애플리케이션의 실행은 디바이스 로 하여금 이미지 센서들 (101 및 102) 및 이미지 신호 프로세서 를 사용하여 이미지들을 생성하게 할 수도 있다. 메모리 는 또한 프로세싱된 프레임들을 저장하기 위 해 이미지 신호 프로세서 에 의해 액세스될 수도 있거나, 프로세싱된 프레임들을 획득하기 위해 프로세서 에 의해 액세스될 수도 있다. 일부 실시형태들에서, 디바이스 는 메모리 를 포함하지 않 는다. 예를 들어, 디바이스 는 이미지 신호 프로세서 를 포함하는 회로일 수도 있고, 메모리는 디바이스 의 외부에 있을 수도 있다. 디바이스 는 메모리에 커플링될 수도 있고, 디스플레이 또는 장기 저장을 위해 출력 프레임들을 기록하기 위해 메모리에 액세스하도록 구성될 수도 있다. 일부 실시형태들에서, 프로세서 는 메모리 내에 저장된 명령들 과 같은, 하나 이상의 소프트 웨어 프로그램들의 스크립트들 또는 명령들을 실행할 수 있는, \"코어들\"로 종종 지칭되는, 하나 이상의 범용 프 로세서를 포함할 수도 있다. 예를 들어, 프로세서 는 메모리 에 저장된 카메라 애플리케이션 (또는 이미지 또는 비디오를 생성하기 위한 다른 적절한 애플리케이션) 을 실행하도록 구성된 하나 이상의 애플 리케이션 프로세서를 포함할 수도 있다. 카메라 애플리케이션을 실행할 때, 프로세서 는 이미지 센서 들 (101 또는 102) 을 참조하여 하나 이상의 동작을 수행하도록 이미지 신호 프로세서 에 지시하도록 구 성될 수도 있다. 예를 들어, 프로세서 상에서 실행되는 카메라 애플리케이션은 그래픽 사용자 인터페 이스 (GUI) 의 버튼 상의 탭을 통해 셔터 캡처 커맨드를 수신할 수도 있고, 하나 이상의 이미지 프레임들을 캡 처하도록 이미지 신호 프로세서 에 명령할 수도 있다. 프로세서 에 의한 카메라 애플리케이션 외부의 명령들 의 실행은 또한 디바이스 로 하여금 임의의 수의 기능 또는 동작을 수행하게 할 수 도 있다. 일부 구현들에서, 프로세서 는 디바이스 로 하여금 다수의 기능들 또는 동작들, 예컨 대 본 명세서에 설명된 동작들을 수행하게 하도록 소프트웨어를 실행하는 능력에 부가하여 IC들 또는 다른 하드 웨어를 포함할 수도 있다. 일부 다른 실시형태들에서, 디바이스 는, 예컨대 설명된 기능 모두가 이미 지 신호 프로세서 에서 구성될 때, 프로세서 를 포함하지 않는다. 일부 실시형태들에서, 일부 이미지 프로세싱 및/또는 카메라 기능은 본 명세서에 설명된 실시형태들에 따라 다수의 이미지들을 융합하기 위 해, 프로세서 에 통합되거나 디바이스 내의 다른 곳에 포함될 수도 있는 융합 노드 와 같은 고정 기능 회로에 통합될 수도 있다. 일부 실시형태들에서, 이미지 신호 프로세서 또는 프로세서 중 적어도 하나는 본 명세서에 설명된 다양한 동작들을 수행하기 위한 명령들을 실행할 수 있다. 예를 들어, 명령들의 실행은 이미지 신호 프로세 서 에게 제 1 초점 거리에서 제 1 줌에서 제 1 이미지 프레임을 캡처하고, 이어서 제 2 초점 거리에서 제 1 줌에서 제 2 이미지 프레임을 캡처하도록 명령할 수 있다. 특정 초점 거리들에서 이미지 프레임들을 캡처 하기 위한 명령들은 이미지 프레임을 캡처하기 전에 명령된 초점 거리로 자동초점 알고리즘을 시딩하기 위해 이미지 신호 프로세서 에 의해 해석될 수도 있다. 일부 실시형태들에서, 디스플레이 는 사용자 상호작용을 허용하고 및/또는 이미지 센서들 (101 및 102) 에 의해 캡처되는 이미지 프레임들의 프리뷰와 같은 아이템들을 사용자에게 제시하기 위한 하나 이상의 적절한 디스플레이들 또는 스크린들을 포함할 수도 있다. 일부 양태들에서, 디스플레이 는 접촉 감지 디스플 레이이다. I/O 컴포넌트들 은 사용자로부터 (커맨드들과 같은) 입력을 수신하고 사용자에게 출력을 제공하기 위한 임의의 적절한 메커니즘, 인터페이스 또는 디바이스이거나 이를 포함할 수도 있다. 예를 들 어, I/O 컴포넌트들 은 그래픽 사용자 인터페이스 (GUI), 키보드, 마우스, 마이크로폰, 스피커들, 압착가 능한 베젤, 하나 이상의 버튼 (예컨대, 전력 버튼), 슬라이더, 스위치 등을 포함할 수도 있다 (그러나 이에 제 한되지 않음). 프로세서 를 통해 서로 커플링되는 것으로 도시되지만, 프로세서 , 메모리 , 이미지 신호 프로 세서 , 디스플레이 , 및 I/O 컴포넌트들 은, 단순화를 위해 도시되지 않은 하나 이상의 로컬 버스들을 통하는 것과 같이, 다른 다양한 배열로 서로 커플링될 수도 있다. 이미지 신호 프로세서 가 프로세서 와 별개인 것으로 도시되어 있지만, 이미지 신호 프로세서 는 APU (application processor unit) 이거나, SoC (system on chip) 에 포함되거나, 또는 그렇지 않으면 프로세서 와 함께 포함되는 프로세서 의 코어일 수도 있다. 본 개시의 양태들을 수행하기 위해 본 명세서의 예들에서 디바이스 가 참조되지만, 본 개시의 양태들을 모호하게 하는 것을 방지하기 위해 일부 디바이스 컴포넌트 들이 도 1 에 도시되지 않을 수도 있다. 추가적으로, 다른 컴포넌트들, 컴포넌트들의 수들, 또는 컴포넌트 들의 조합들은 본 개시의 양태들을 수행하기 위한 적절한 디바이스에 포함될 수도 있다. 이와 같이, 본 개 시는 디바이스 를 포함하는 특정 디바이스 또는 컴포넌트들의 구성에 제한되지 않는다. 도 1의 실시형태들과 같은 본 개시의 실시형태들에서 설명된 이미지 캡처 디바이스로부터 캡처된 이미지 프레임 들을 프로세싱하는 방법들은 장면 및 장면에서의 객체들의 개선된 이미지들을 획득하는 데 사용될 수도 있다. 예를 들어, 이미지 프레임들을 융합하기 위한 방법들은 인-포커스인 이미지 캡처 디바이스로부터 상이한 거 리들에 있는 다수의 객체들을 갖는 더 큰 초점 심도를 갖는 장면의 이미지들을 획득하는 것을 초래할 수도 있다. 이러한 융합 프로세싱의 하나의 이점은 융합이 더 큰 애퍼처 및 더 짧은 초점 심도를 갖는 캡처 디바 이스들을 갖는 이미지 캡처 디바이스의 사용을 허용할 수도 있다는 것이다. f/2.2보다 큰 애퍼처들 (f/2.0, f/1.8, f/1.4, 및/또는 f/1.2의 애퍼처들을 포함함) 을 갖는 렌즈들과 같은 이러한 더 큰 애퍼처 렌즈들은 초점 심도의 손실에서 저광 상황들과 같은 특정 상황들에서 개선된 이미지 품질을 제공할 수도 있다. 본 명세서 의 실시형태들에 개시된 융합 프로세싱은, 예컨대 관심 객체들이 초점이 맞은 출력 이미지 프레임을 생성함으로 써, 초점 심도의 손실이 감소되거나 없는 개선된 이미지 품질을 획득하는 것을 허용한다. 이는 다수의 관심 사람들이 있는 장면을 캡처할 때 특히 바람직할 수도 있는데, 이는 본 명세서에 설명된 융합 로직이 다수의 또 는 모든 사람들이 초점이 맞은 이미지들을 생성할 수 있기 때문이다. 또한, 큰 애퍼처 렌즈의 사용은 때때 로 보케 블러 또는 얕은 피사계 심도 효과 (shallow depth-of-field effect) 로 지칭되는 흐릿한 배경을 갖는 이미지를 생성한다. 더 큰 애퍼처 렌즈로부터 여러 이미지를 융합하면 많은 사진작가들이 원하는 흐릿한 배 경과 함께 인-포커스인 여러 객체를 가진 이미지를 생성할 수 있다. 본 개시의 일부 실시형태들에서의 융합 로직은 특정 조건들 하에서 트리거될 수도 있으며, 이는 이미지들의 불 필요한 프로세싱을 감소시킨다. 프로세싱의 양을 감소시키는 것은 배터리와 같은 제한된 전력 공급으로부터 동작하는 모바일 디바이스들에 특히 유리할 수도 있다. 융합 로직은 장면의 제 1 캡처된 이미지에 다수의 관심 대상들이 존재한다는 것을 나타내는 기준들에 기초하여 다수의 이미지들의 추가 이미지 캡처 및 프로세싱 및 병합을 트리거할 수도 있다. 예를 들어, 다수의 관심 대상을 나타내는 하나의 기준은 장면으로부터의 심 도 데이터의 히스토그램이 다수의 관심 대상이 있음을 나타낸다고 결정하는 것이다. 히스토그램은 다수의 히스토그램 피크들이 검출되고 현재 카메라 구성에 대한 예상된 초점 심도보다 큰 임계치만큼 분리될 때 다수의 대상들을 나타낼 수도 있다. 다른 예로서, 복수의 관심 대상을 나타내는 기준은 인공지능 (AI) 머신 러닝 알고리즘을 통한 복수의 얼굴 또는 복수의 객체 검출이다. 추가의 예로서, 다수의 관심 대상을 나타내는 하 나의 기준은 융합 로직이 적용되어야 함을 특정하고/하거나 장면에서 다수의 관심 대상을 특정하는 사용자 입력 의 수신이다. 예를 들어, 사용자는 모바일 디바이스 상에 디스플레이된 장면의 제 1 이미지 상의 여러 위치 들을 탭핑할 수도 있고, 이 탭핑된 위치들에 대응하는 초점 심도들이 장면의 추가적인 이미지 프레임들을 캡처 하기 위한 초점 심도들로서 사용될 수도 있다. 일부 실시형태들에서, 이러한 기준들의 조합들이 융합 이미 지 프로세싱을 트리거하기 위해 사용될 수도 있다. 하나의 예시적인 조합으로서, 심도 데이터의 히스토그램 은 복수의 잠재적인 관심 객체들을 결정하기 위해 사용될 수도 있고, 그러한 잠재적인 관심 객체들 각각은 잠재적인 관심 객체들이 사람들에 대응하는지를 결정하기 위해 얼굴 검출 알고리즘에 입력되고, 그 다음, 검출된 얼 굴들 주위의 제 1 이미지 프레임의 디스플레이 상에 박스들을 디스플레이하여 사용자가 검출된 얼굴들 중 어느 것이 실제 관심 객체들에 대응하는지를 특정하는 사용자 입력을 제공할 수 있게 한다. 다른 예시적인 조합 으로서, 얼굴 또는 객체 검출 알고리즘은 잠재적인 관심 객체들 및 잠재적인 객체들이 추가 이미지들을 캡처하 는 것을 트리거하기에 충분한 거리로 떨어져 있는지를 결정하기 위해 심도 데이터의 히스토그램 상의 피크들에 비교된 그러한 잠재적인 관심 객체들의 초점 심도들을 결정하는 데 사용될 수도 있다. 추가의 예시적인 조 합으로서, 심도 정보에 기초한 화상 세그먼트화 (portrait segmentation) 알고리즘 (화상 인식 (portrait recognition) 을 포함함) 은 잠재적인 관심 객체들 및 심도 데이터의 히스토그램 상의 피크들과 비교된 그러한 잠재적인 관심 객체들의 초점 심도들을 결정하여 잠재적인 객체들이 추가적인 이미지들을 캡처하는 것을 트리거 하기에 충분한 거리로 떨어져 있는지를 결정하기 위해 사용될 수도 있다. 다수의 잠재적인 관심 대상들이 검출된 후, 융합 로직은 장면 및/또는 자동 포커싱 시스템들에 대한 심도 데이터의 조합을 사용하여 결정된 추 가적인 초점 거리들에서 추가적인 이미지들의 캡처를 명령할 수도 있다. 이러한 기준들이 충족되지 않을 때, 융합 로직은 이미지 캡처 디바이스 및 연관된 프로세싱 및 메모리 회로에 의해 수행되는 동작들의 수를 감 소시키기 위해 추가적인 이미지들의 캡처 및 이러한 이미지들의 후속 프로세싱을 트리거하지 않는다. 추가 적인 이미지들 중 어느 것을 함께 융합할지를 결정하기 위해 추가적인 이미지들을 캡처한 후에 유사한 기준들이 재평가될 수도 있다. 예를 들어, 상이한 초점 거리들에서 모든 캡처된 이미지들이 디스플레이 상에 디스플 레이될 수도 있고, 사용자는 융합을 위해 특정 이미지들을 선택하도록 허용될 수도 있다. 다른 예로서, 상 이한 초점 거리들에서 캡처된 이미지들은 잠재적인 관심 객체들을 인식된 얼굴들 또는 객체들로서 확인 또는 거 부하기 위해 얼굴 또는 객체 검출 프로세싱에 다시 입력될 수도 있다. 도 2는 본 개시의 실시형태들에 따른 출력 이미지 프레임을 획득하기 위한 복수의 이미지들의 융합을 예시하는 블록도이다. 장면 202 는 이미지 캡처 디바이스로부터 상이한 거리들에 있는 다수의 객체들 (204, 206, 및 208) 을 포함할 수도 있다. 이미지 캡처 디바이스 는 장면 202 를 캡처하는 제 1 이미지 프레임 을 생성할 수도 있다. 제 1 이미지 프레임 은 객체 204 근처의 초점 거리에 포커싱될 수도 있 다. 그 결과, 객체 204 는 초점이 맞고, 객체 206 은 흐릿하게 보인다. 이미지 캡처 디바이스 는 장면 202 를 캡처하는 제 2 이미지 프레임 을 생성할 수도 있다. 제 2 이미지 프레임 은 객체 206 근처의 초점 거리에 포커싱될 수도 있다. 그 결과, 객체 206 은 초점이 맞고, 객체 204 는 흐릿하거나 또는 초점이 안 맞게 보인다. 객체들 (204, 206) 에 대응하는 초점 거리들을 갖는 이미지 캡처 디바이스 의 자동초점 (AF) 알고리즘에 시딩함으로써, 상이한 이미지 프레임들 (210, 220) 이 상이한 초점 거리들 로 캡처될 수도 있다. 이미지 캡처 디바이스 의 AF 알고리즘은 객체들 (204 및 206) 근처의 초점 거 리에서 이미지 프레임들 (210 및 220) 을 획득하기 위해, 로컬 콘트라스트 또는 심도 데이터와 같은 다른 기준 들을 프로세싱할 수도 있다. 동일한 이미지 캡처 디바이스 가 이미지 프레임들 (210 및 220) 을 캡처 하는 것으로 제시되지만, 상이한 이미지 캡처 디바이스들이 2개의 이미지 프레임들 (210 및 220) 을 캡처하는 데 사용될 수도 있다. 융합 로직 은 이미지 프레임들 (210 및 220) 을 결합하여, 추가로 프로세싱되고, 사용자에게 디스플레이 되고, 메모리에 저장되고, 그리고/또는 다른 사용자들에게 송신될 수 있는 출력 이미지 프레임 을 획득하 는 데 사용될 수도 있다. 융합 로직 에 의해 생성된 출력 프레임 은 인-포커스인 객체 및 인-포커스인 객체 를 가질 수도 있다. 출력 프레임 은 이미지 프레임들 (210 및 220) 중 어 느 것도 인-포커스인 객체들 (204 및 206) 둘 모두를 갖지 않음에도 불구하고, 다수의 초점 거리들에서 인-포커 스 객체들을 포함한다. 인-포커스인 객체 를 갖는 이미지 프레임 을 프로세싱하는 것은 객체 를 추출하기 위해 이미지 프레임 을 세그먼트화하는 것 및 세그먼트화된 객체 를 이미지 프 레임 에 병합하는 것을 포함할 수도 있다. 융합 로직 은 카메라들 (130 및/또는 140) 내의 하 드웨어 (예컨대, AF (141 및/또는 142)), 이미지 신호 프로세서 , 프로세서 , 고정 기능 회로부를 포 함하는 융합 노드 , 및/또는 프로세서 상에서 실행되는 소프트웨어 중 하나 이상으로부터의 기능을 포함할 수도 있다. 도 2를 참조하여 설명된 바와 같은 다수의 이미지 프레임들 및 융합 프로세스들에 기초하여 장면을 나타내는 이 미지 프레임을 생성하는 것은 더 오래 걸리고, 추가적인 프로세싱 시간 및 배터리 충전 레벨을 소비한다. 도 2의 융합 프로세스는 일부 장면들의 이미지 프레임을 캡처하는 데 유리할 수도 있다. 일부 실시형태들에 따르면, 동일한 장면의 다수의 이미지들이 유익한지 여부는, 캡처된 이미지 프레임에 대응하는 데이터를 검사하 고 추가적인 이미지 프레임들 및 추가적인 이미지 프레임들의 수가 출력 이미지를 개선할 수 있는지 여부를 결 정함으로써 결정될 수도 있다. 장면의 추가적인 이미지 프레임들을 캡처할지 여부를 결정하는 하나의 방식은 이미지 내의 객체들 사이의 거리들을 결정하는 것이다. 도 3은 본 개시의 일부 실시형태들에 따른 융합 로직을 실행하기 위한 예시적인 결정을 예시하는 블록도이다. 이미지 캡처 디바이스 는 장면 에 대응하는 심도 데이터 를 캡처한다. 예를 들어, 심 도 데이터 는 상이한 뷰포인트들로부터 장면 을 캡처하는 다수의 이미지 프레임들로부터 결정될 수 도 있다. 다른 예로서, 심도 데이터 는 TOF (time of flight) 센서와 같은 심도 센서, 상이한 위치 들에서의 2개의 상이한 이미지 센서들로부터의 것과 같은 상이한 시점들 (points of view) 로부터 캡처된 장면 의 2 이상의 이미지 프레임들을 포함하는 스테레오 이미지들, 및/또는 레이저 조명원을 사용하는 라이다 (light detection and ranging; lidar) 로부터 결정될 수도 있다. 일부 실시형태들에서, 심도 데이터 를 캡 처하는 이미지 캡처 디바이스 는 도 2의 이미지 프레임들 (210 및 220) 을 캡처하는 동일한 이미지 캡처 디바이스일 수도 있다. 이러한 실시형태들에서, 자동초점 로직 (141 및 142) 은 심도 데이터 로부터 추가적인 이미지들을 캡처할지 여부를 결정할 수도 있고, 제 2 또는 다른 후속 이미지 프레임들을 포커싱 및 캡 처하기 위한 새로운 초점면을 선택하기 위해 심도 데이터 를 자동초점 로직에 대한 입력으로서 사용할 수 도 있다. 일부 실시형태들에서, 심도 데이터 를 캡처하기 위한 이미지 캡처 디바이스는 상이한 캡처 디바이스일 수도 있거나, 또는 심도 데이터 는, 예컨대 메모리로부터 저장된 심도 데이터 를 검색 하고/하거나 다른 디바이스들로부터 심도 데이터 를 수신함으로써, 이미지 캡처 디바이스의 사용 없이 수 신될 수도 있다. 이러한 실시형태들에서, 이미지 신호 프로세서 (ISP) 및/또는 애플리케이션 프로세서 (AP) 는 심도 데이터 를 사용하여 추가 이미지들이 캡처되어야 함을 결정하고 하나 이상의 카메라 (130 및/또 는 140) 를 제어하여 출력 이미지 프레임을 획득하기 위해 융합 프로세싱에서 사용될 제 2 또는 후속 이미지 프 레임을 획득할 수도 있다. 심도 데이터 는 융합 로직 에 입력되고, 이미지 프레임들을 캡처하기 위한 관심 초점 거리들을 결 정하기 위해 분석될 수도 있다. 예를 들어, 심도 데이터 의 히스토그램은 이미지 캡처 디바이스로부 터 다양한 거리들에 있는 다수의 픽셀들을 결정함으로써 또는 이미지 캡처 디바이스에 의해 캡처된 이미지에 기 초하여 이미지 또는 다운샘플링된 이미지 내의 이미지 픽셀들의 특정 비율을 결정함으로써 결정될 수도 있다. 융합 로직 은 관심 초점 거리들을 결정하기 위해 히스토그램 내의 피크들을 결정할 수도 있다. 예 를 들어, 심도 데이터 는 히스토그램 피크들 (302 및 304) 을 가질 수도 있다. 피크들 (302 및 304) 의 중심은 피크들이 임계 폭 및/또는 값을 초과하는 것과 같은 특정 기준들을 충족시킬 때 사람과 같은 객체에 대한 초점 거리를 나타낼 수도 있다. 피크들 (302 및 304) 사이의 거리는 다수의 이미지 프레임들이 캡처되 어야 하는지 부를 결정하는 데 사용될 수도 있다. 예를 들어, 융합 로직 은 검출된 피크들 (302 및 304) 사이의 거리의 차이가 임계값보다 큰지 여부를 결정할 수도 있다. 거리의 차이는 피크들 (302 및 304) 에 대응하는 장면 내의 객체들이 둘 다 이미지 캡처 디바이스 로부터 캡처된 단일 이미지 프레임 내에서 초점이 맞지 않을 수도 있음을 나타낼 수도 있다. 제 1 이미지 프레임은 이미지 캡처 디바이스 로부터 캡처될 수도 있고, 융합 로직 에서 분석되어, 융합 로직 이 다수의 이미지 프레임들을 캡처하는 것을 트리거해야 하는지 여부를 결정할 수도 있다. 결정은 장면에 대한 심도 데이터로부터 획득된 히스토그램에서의 피크들에서의 거리에 기초할 수도 있다. 도 4는 본 개시의 일부 실시형태들에 따른 융합 로직으로 이미지 프레임을 프로세싱하는 방법에 대한 흐름도를 예시한다. 방법 은, 블록 402 에서, 장면에 대한 제 1 이미지 데이터 및 장면에 대한 심도 데이터를 수신하는 것으로 시작한다. 제 1 이미지 데이터는 제 1 초점 거리에서 캡처된 장면에 대응할 수도 있다. 예를 들어, 자동초점 (AF) 알고리즘은 이미지 캡처 디바이스로 하여금 콘트라스트 검출 및/또는 거리 검출에 기초하여 장면 내의 객체에 초점을 맞추게 할 수도 있다. 블록 402 에서 수신된 심도 데이터는 제 1 이미지 데이터에 대응할 수도 있다. 예를 들어, 심도 데이터는 제 1 이미지 데이터 내의 각각의 픽셀에 대한 심도 들의 2차원 맵일 수도 있다. 블록 404 에서, 심도 데이터 히스토그램에서의 피크들이 피크들 사이의 거리와 함께 결정된다. 일부 이미지 들에서, 각각의 피크는 제 1 이미지 데이터에서 캡처된 장면 내의 관심 객체를 나타낼 수도 있다. 일부 이 미지들에서, 최고 피크는 배경과 같은 가장 먼 영역을 나타낼 수도 있고, 나머지 피크들은 각각 장면 내의 관심 객체를 나타낼 수도 있다. 따라서, 피크들의 수는 장면의 추가적인 이미지 프레임들이 캡처되는지 여부, 그 리고 얼마나 많은 추가적인 이미지 프레임들이 캡처되어야 하는지를 결정하는 데 사용될 수도 있다. 제 1 예로서, 히스토그램에서의 2개의 피크들이 결정될 수도 있고, 피크들 사이의 거리가 결정될 수도 있다. 다 른 예로서, 히스토그램에서의 3개의 피크가 결정될 수도 있고, 각 피크와 다른 피크들 사이의 거리가 결정되어, 총 6개의 거리가 결정된다.블록 406 에서, 임의의 쌍의 피크들에 대한 거리가 융합 임계값을 초과하는지 여부를 결정하기 위해 피크들 사 이의 거리가 평가된다. 블록 404 에서 계산된 거리들 각각은 융합 임계값과 비교될 수도 있다. 융합 임 계값은 미리 결정된 값일 수도 있다. 융합 임계값은 블록 402 에서 검색된 제 1 이미지 데이터를 생성한 이 미지 캡처 디바이스의 특성들에 기초하여 미리 결정될 수도 있다. 예를 들어, 융합 임계값은 이미지 캡처 디바이스로부터 획득된 이미지 프레임의 초점 심도 (DOF) 에 대응하는 값일 수도 있다. 이미지 캡처 디바이 스 상에서 다수의 렌즈들이 이용가능할 때, 융합 임계값은 블록 402 의 제 1 이미지 데이터를 획득하는 데 사용 되는 렌즈에 기초하여 결정될 수도 있다. 따라서, 망원 (T) 렌즈로부터 캡처된 이미지들에 대한 융합 임계 치는 UW 렌즈로부터 캡처된 이미지들에 대한 융합 임계치보다 낮을 수도 있다. 융합 임계값들은 테이블에 저장될 수도 있고, 테이블은 블록 402 에서 제 1 이미지 데이터를 수신하고 블록 406 에서 데이터를 평가할 때 룩업 동작에서 사용된다. 블록 404 에서 결정된 장면 내의 피크들 사이의 거리는 추가적인 이미지 프레임들이 캡처되어야 하는지 여부 및 이미지 프레임들이 어떤 초점 거리들에서 캡처되어야 하는지를 결정하는 데 사용될 수도 있다. 융합 로직이 융합 임계값을 초과하는 거리에 기초하여 활성화될 때, 방법 은 블록들 408 및 410 로 계속된다. 블 록 408 에서, 제 2 초점 거리에서 캡처된 장면에 대응하는 제 2 이미지 데이터가 수신된다. 제 2 이미지 데 이터는 블록 402 에서 수신된 제 1 이미지 데이터에 대응하는 제 1 초점 거리와 상이한 제 2 초점 거리에서 장 면의 제 2 이미지 프레임을 획득하기 위해 이미지 캡처 디바이스에 송신된 커맨드에 응답하여 수신될 수도 있다. 예를 들어, 커맨드는 블록 404 에서 결정된 히스토그램의 피크들 중 하나에 대응할 수도 있는 제 2 초점 거리를 갖는 이미지 캡처 디바이스에서의 자동초점 (AF) 알고리즘을 시딩할 수도 있다. 일부 실시형태 들에서, AF 알고리즘은 블록 408 에서 수신된 제 2 이미지 데이터를 캡처하기 전에 제 2 초점 거리를 정제할 수 도 있다. 일부 실시형태들에서, 커맨드는 제 2 이미지 프레임을 캡처하기 위한 동일한 또는 상이한 이미지 센서를 특정할 수도 있다. 블록 410 에서, 제 1 이미지 데이터 및 제 2 이미지 데이터에 기초하여 융합 로직에 의해 출력 이미지 프레임이 생성된다. 예를 들어, 융합 로직은 제 1 이미지 데이터 및 제 2 이미지 데이터로부터 객체들을 세그먼트화 하고, 제 1 및 제 2 이미지 데이터로부터의 인-포커스 객체들을 제 1 및 제 2 이미지 데이터 중 하나 또는 둘 다로부터의 배경과 조합할 수도 있다. 융합 로직은 본 명세서에 설명된 바와 같이 출력 이미지 프레임을 출 력하기 위한 다른 동작들을 수행할 수도 있다. 융합 로직에 의해 및/또는 융합 로직 외부에서 출력 이미지 프레임에 대해 추가적인 프로세싱이 수행될 수 있다. 예시적인 추가적인 프로세싱은 출력 이미지 프레임의 부분들에 대한 블러의 적용을 포함할 수도 있다. 세그먼트화 데이터, 심도 데이터, 및/또는 입력 이미지 프레임들 중 하나 이상의 다른 특성들에 기초 하여 출력 이미지 프레임의 특정 부분들에 블러링 알고리즘이 적용될 수도 있다. 예를 들어, 심도 데이터에 기초하여 식별된 배경 픽셀들에 블러링이 적용될 수도 있다. 다른 예로서, 전경 세그먼트가 얼굴에 대응할 때와 같이, 입력 이미지 프레임들 중 하나의 전경 세그먼트에 대응하는 픽셀들의 일부에 블러링이 적용될 수도 있다. 블러링은 얼굴을 가리기 위해 수행되는 헤비 블러 또는 얼굴의 심미감을 향상시키기 위해 수행되는 라이트 블러일 수도 있다. 추가적인 프로세싱의 다른 예들은 컬러 필터링, 컬러 맵핑, 렌즈 효과들, 변환들, 및/또는 조명 효과들을 포함할 수도 있다. 일부 실시형태들에서, 블러링은 제 1 부분이 아니라 제 2 부분의 픽셀들에 적용될 수도 있다. 2개의 입력 이미지 프레임들로부터 출력 이미지 프레임을 결정하는 하나의 방법이 도 5 에 도시되어 있다. 도 5는 본 개시의 일부 실시형태들에 따른 출력 이미지 프레임을 결정하기 위한 2개의 이미지 프레임들로부터의 이미지 데이터의 세그먼트화 및 병합을 예시하는 블록도이다. 제 1 입력 프레임 및 제 2 입력 프레임 이 캡처되어 융합 로직 에 입력될 수도 있다. 일부 실시형태들에서, 융합 로직 은 제 1 입력 프레임 및/또는 제 2 입력 프레임 의 캡처를 명령할 수도 있다. 입력 프레임들 (210 및 220) 은 출력 이미지 프레임 을 획득하기 위해 융합 로직 내에서 프로세싱될 수도 있다. 출력 이미지 프레임 은 이미지 캡처 디바이스로부터 상이한 초점 심도들에서 다수의 인-포커스 영역들을 가질 수도 있다. 예를 들어, 출력 이미지 프레임 은 입력 이미지 프레임들 (210 및 220) 중 어느 하나 또 는 둘 다를 획득하는 이미지 캡처 디바이스의 초점 심도를 초과하는 상이한 심도들에서 2개의 인-포커스 객체들 을 가질 수도 있다. 융합 로직 은 입력 이미지 프레임들 (210 및 220) 로부터 출력 이미지 프레임 을 결정하기 위해 세 그먼트화 및 병합 동작들을 사용할 수도 있다. 예를 들어, 세그먼트화 동작은 이미지 프레임 으로 병합하기 위한 이미지 프레임 의 픽셀들의 일부를 결정할 수도 있다. 픽셀들의 결정된 부분은이미지 프레임 내의 특정 객체에 대응하는 것으로 식별된 픽셀들, 이미지 프레임 의 전경 부분으로 서 식별된 픽셀들, 및/또는 이미지 프레임 의 인-포커스 부분으로서 식별된 픽셀들을 포함할 수도 있다. 픽셀들의 결정된 부분은 이미지 프레임 으로부터 추출되어, 예를 들어, 픽셀들의 결정된 부분으로 구 성된 세그먼트 를 초래할 수도 있다. 일부 실시형태들에서, 세그먼트 는 픽셀들의 단일 연속 영역으로 제한될 수도 있다. 다른 실시형태들에서, 세그먼트 는 픽셀들의 다수의 영역들을 포함할 수 도 있고, 각각의 영역은 세그먼트화 동작 동안 적용되는 특정 기준들을 충족한다. 세그먼트화 동작은, 로컬 콘트라스트 값들을 분석하고, 이미지 프레임 이 획득되는 장면에 대응하는 심도 데이터를 분석하고, 이미지 프레임 에 대해 얼굴, 객체 또는 화상 인식을 수행하고, 및/또는 인공 지능 (AI) 머신 러닝 알고리즘들을 이미지 프레임 에 적용함으로써, 세그먼트 와 이미지 프레임 의 나머지 사이의 경계들을 결정할 수도 있다. 세그먼트 는 세그먼트 를 이미지 프레임 상에 병합하기 위한 병합 동작에 입력될 수도 있다. 일부 실시형태들에서, 병합 동작은 세그먼트 로부터의 데이터로 이미지 프레임 의 대응하는 픽셀들을 겹쳐 쓸 수 있다. 일부 실시형태들에서, 병합 동작은 다른 병합 알고리즘들을 수 행할 수도 있으며, 이는 세그먼트 로부터 이미지 프레임 으로 픽셀들을 복사하는 것, 세그먼트 로부터 이미지 프레임 으로 픽셀들을 블렌딩하는 것, 세그먼트 와 이미지 프레임 의 나머지 사이의 시임들을 감소시키기 위해 세그먼트 에 기초하여 이미지 프레임 에서 세그먼트 주위의 픽셀들을 블렌딩하는 것, 및/또는 다른 동작들의 조합들을 포함할 수도 있다. 병합 동 작은 다수의 인-포커스 객체들을 갖는 출력 이미지 프레임 을 생성할 수도 있다. 예를 들어, 세그먼 트화 동작은 인-포커스 객체 를 포함하는 세그먼트 를 생성할 수도 있고, 후속 병합 동작은 이미지 프레임 에서의 아웃-포커스 객체 를 인-포커스 세그먼트 로 겹쳐 쓸 수도 있 다. 따라서, 출력 이미지 프레임 은 객체들 (204 및 206) 을 갖는 2개의 인-포커스 영역들을 포함한 다. 도 5의 예는 상이한 초점 거리들에 대응하는 추가적인 입력 프레임들로 확장될 수 있다. 예를 들어, 이미지 프레임들 (210 및 220) 의 프로세싱은 임계 차이를 초과하는 심도 데이터 히스토그램에서의 2개의 피크들의 검 출에 의해 트리거될 수도 있다. 심도 데이터 히스토그램에서 제 3 피크를 검출하면, 장면의 제 3 이미지 프 레임이 캡처될 수 있다. 예를 들어, 장면은 객체들 (204 및 206) 과 상이한 초점 거리에 있는 제 3 객체를 포함할 수도 있다. 제 3 이미지 프레임은 제 3 객체가 제 3 이미지 프레임에서 인-포커스이도록 제 3 객체 에 대한 초점 거리와 대략 동일하거나 동일한 초점 거리에서 캡처될 수도 있다. 세그먼트 에서의 객 체 의 세그먼트화 및 병합 과 유사하게, 제 3 이미지 프레임의 인-포커스 부분은 세그먼트화 되고 제 1 입력 프레임과 병합될 수도 있다. 도 5의 실시형태 또는 본 개시의 다른 실시형태들에서의 세그먼트화 동작을 수행하는 하나의 예시적인 방 법은 윤곽 맵들에 기초한 세그먼트화를 포함할 수도 있다. 도 6은 본 개시의 일부 실시형태들에 따른 윤곽 맵들을 사용한 이미지 데이터의 세그먼트화를 예시하는 흐름도이다. 세그먼트화 방법 은, 블록 602 에서, 제 1 이미지 프레임에 대응하는 제 1 심도 데이터를 수신하는 단계, 및 블록 604 에서, 제 2 이미지 프레 임에 대응하는 제 2 심도 데이터를 수신하는 단계로 시작할 수도 있다. 블록 606 에서, 제 1 심도 맵 윤곽 들 및 제 2 심도 맵 윤곽들이 각각 제 1 및 제 2 심도 데이터로부터 추출될 수도 있다. 블록 606 의 윤곽 추출은 이진화 맵을 결정하기 위해 제 1 및 제 2 심도 데이터 각각에 임계화를 적용하는 것을 포함할 수도 있다. 블록 608 에서, 제 1 및 제 2 심도 맵 윤곽들이 통합된다. 블록 608 의 통합은, 융합 로직에서의 다른 동작 들 동안 인공물들을 회피할 수도 있는, 픽셀들의 전경 부분 또는 다른 부분의 추출된 윤곽들을 확대하기 위해 블록 606 의 2개의 이진화된 심도 맵들을 결합하는 것을 포함할 수도 있다. 블록 610 에서, 픽셀들의 일부 는 블록 608 의 통합된 심도 맵 윤곽들에 기초하여 제 1 이미지 프레임의 제 1 이미지 데이터로부터 세그먼트화 될 수도 있다. 2개의 심도 맵들의 연합은 255 및 0 으로 이진화된 2개의 세그먼트화된 심도를 입력으로 서 수신하는 AND 연산들에 기초할 수도 있으며, 여기서 '1'은 백색 영역 (배경에 대응함) 을 나타낼 수도 있고, '0'은 흑색 영역 (전경 또는 포트레이트 (portrait) 에 대응함) 을 나타낼 수도 있다. 연합 AND 연산들의 출력은, 2개의 심도 맵들로부터의 대응하는 픽셀들이 모두 배경이고 다른 영역들은 전경, 블랙 영역으로서 통합 될 때, '1'일 수도 있다. 픽셀들의 세그먼트화된 부분은 도 5의 세그먼트 에 대응할 수도 있다. 세그먼트화는 블록들 606 및 608 로부터 생성된 정제된 심도 맵 윤곽들 및/또는 심도 데이터에 대한 다른 동작 들에 기초할 수도 있다.도 5의 실시형태 또는 본 개시의 다른 실시형태들에서 병합 동작을 수행하는 하나의 예시적인 방법은 2 이상의 입력 이미지 프레임들로부터의 데이터를 정렬하여 2개의 이미지 프레임들 사이의 대응하는 픽셀들이 식 별될 수 있게 하는 등록 동작들을 포함할 수도 있다. 도 7은 본 개시의 일부 실시형태들에 따른 가중치에 기초하여 융합된 출력 이미지 프레임을 결정하기 위한 이미지 데이터의 병합을 예시하는 흐름도이다. 병합 방법 은 블록 702 에서 호모그래피 행렬을 사용하여 제 2 이미지 프레임으로부터의 제 2 이미지 데이터를 제 1 이미지 프레임으로부터의 제 1 이미지 데이터에 등록하는 것으로 시작할 수도 있다. 일부 실시형태들 에서, 제 2 이미지 데이터는 도 5의 실시형태에서의 세그먼트 와 같은, 제 2 이미지 프레임의 단지 일부 일 수도 있다. 일부 실시형태들에서, 제 2 이미지 데이터는 제 2 이미지 프레임의 전체 데이터 세트일 수도 있다. 제 2 이미지 데이터에 대한 제 1 이미지 데이터의 등록은 제 2 이미지 데이터의 대응하는 픽셀들을 제 1 이미지 데이터의 픽셀들과 상관시킬 수도 있다. 등록은, 예를 들어, 장면 내의 객체들이 제 1 이미지 데이터의 캡처로부터 제 2 이미지 데이터의 캡처로 프레임에서 이동한 경우에 유용할 수도 있다. 블록 704 에서, 블록 702 의 등록에 기초하여 픽셀들의 전경 부분 또는 픽셀들의 다른 부분을 식별하기 위해 세그먼트화 맵이 생성된다. 블록 706 에서, 제 1 이미지 데이터는 세그먼트화 맵에 기초하여 제 2 이미지 데이터와 병 합된다. 블록 706 의 하나의 예시적인 병합 동작이 블록들 712, 714, 및 716 에 제시된다. 출력 이미지 프레임을 결 정할 때, 블록 712 에서, 제 1 장면의 제 1 부분으로부터의 픽셀들의 제 1 세트에 대응하는 제 1 이미지 데이터 가 출력 이미지 프레임에 복사된다. 이 제 1 이미지 데이터는, 예를 들어, 배경 내의 픽셀들과 같은 세그먼 트 외부에 있는 그리고/또는 객체 주위에 인-포커스인 입력 이미지 프레임 의 영역들에 대응 할 수도 있다. 블록 714 에서, 단편 으로서 식별된 픽셀들의 제 2 세트에 대응하는 제 2 이미지 데이 터가 출력 이미지 프레임에 복사된다. 블록들 712 및 714 에서의 데이터의 복사는 제 1 및 제 2 입력 이미 지 프레임들로부터의 병합된 포커스 영역들을 갖는 출력 이미지 프레임을 생성할 수도 있다. 그러나, 일부 인공물들은 픽셀들의 제 1 및 제 2 세트들의 경계에서 그리고 그 주위에서 픽셀들에 남아 있을 수도 있다. 인공물들이 제거되기를 원하는 경우, 인공물들을 감소시키거나 제거하기 위해 추가적인 프로세싱이 수행될 수도 있다. 예를 들어, 경계의 또는 경계 근처의 픽셀들에 대응하는 제 3 이미지 데이터는 제 1 이미지 데이터, 제 2 이미지 데이터, 및 가중치에 기초하여 결정될 수도 있다. 일부 실시형태들에서, 제 3 이미지 데이터는 경계의 또는 그 근처의 각각의 픽셀에 대해, 가중치에 따라 제 1 이미지 데이터 및 제 2 이미지 데이터로부터의 대응하는 픽셀 값들을 조합함으로써 블렌딩된 값들로서 계산될 수도 있다. 예를 들어, 경계 영역 픽셀 pb 는 로서 계산될 수도 있으며, 여기서 p1 은 제 1 이미지 데이터 내의 대응하는 픽셀로부 터의 값이고, p2 는 제 2 이미지 데이터 내의 대응하는 픽셀로부터의 값이고, α는 가중치이다. 일부 실시 형태들에서, 경계 영역 픽셀 pb 는 제 1 이미지 데이터 및 매칭된 픽셀 주위의 픽셀들을 포함하는 제 2 이미지 데이터로부터의 대응하는 픽셀들에 기초하여 계산될 수도 있으며, 이는 융합 결과를 더 자연스럽게 보이게 하는 경계에서의 블러 또는 시임 연결성 (seam connectivity) 을 추가할 수도 있다. 예를 들어, (x,y) 에서의 경 계 픽셀 pb 는 제 1 이미지 데이터로부터의 픽셀 (x,y), 제 2 이미지 데이터로부터의 픽셀 (x,y), 제 1 이미지 데이터로부터의 픽셀 (x-1,y), 제 1 이미지 데이터로부터의 픽셀 (x+1,y), 제 1 이미지 데이터로부터의 픽셀 (x,y-1), 제 1 이미지 데이터로부터의 픽셀 (x,y+1), 제 2 이미지 데이터로부터의 픽셀 (x-1,y), 제 2 이미지 데이터로부터의 픽셀 (x+1,y), 제 2 이미지 데이터로부터의 픽셀 (x,y-1), 및/또는 제 2 이미지 데이터로부터의 픽셀 (x,y+1) 에 기초하여 결정될 수도 있다. 제 3 이미지 데이터를 계산할 때, 제 1 이미지 데이터로부터 의 픽셀들 각각은 가중치 α와 곱해질 수도 있고, 제 2 이미지 데이터로부터의 픽셀들 각각은 (1-α) 와 곱해질 수 있다. 블록 716 에서 결정된 제 3 이미지 데이터는 출력 이미지 프레임에 복사될 수도 있고, 그렇지 않으면 출력 이미 지 프레임에 포함될 제 1 또는 제 2 이미지 데이터를 겹쳐 쓰는 데 사용될 수도 있다. 일부 실시형태들에서, 이 기술들로부터 결정된 출력 이미지 프레임은 전경에 포커싱된 입력 이미지 프레임으로부터의 픽셀 값들을 복사함으로써 전경에 포커싱하는 제 1 영역, 배경에 포커싱된 입력 이미지 프레임으로부터의 픽셀 값들을 복사함으로써 배경에 포커싱하는 제 2 영역, 및 전경에 포커싱된 입력 이미지 프레임 및 배경에 포커싱 된 입력 이미지 프레임으로부터의 픽셀 값들이 융합되는 제 3 영역을 포함할 수도 있다. 가중치 α는 일부 실시형태들에서, 제 1 및 제 2 입력 이미지 프레임들로부터의 그래디언트 맵들에 기초하여 결 정될 수도 있다. 가중치를 결정하는 하나의 방법이 도 8 에 제시되어 있다. 도 8은 본 개시의 일부 실시형태들에 따른 2개의 이미지 프레임들을 융합하기 위한 그래디언트 맵들에 기초한 가중치들의 생성을 예시하 는 흐름도이다. 블록 802 에서, 제 1 그래디언트 맵이 제 1 이미지 데이터에 기초하여 결정된다. 블록 804 에서, 제 2 그래디언트 맵이 제 2 이미지 데이터에 기초하여 결정된다. 블록 802 및/또는 블록 804 에 서와 같이, 이미지 데이터로부터 그래디언트 맵을 결정하기 위한 하나의 방법은, 전경 이미지 및/또는 배경 이 미지의 그래디언트 맵을 결정하기 위해 라플라시안 필터 및/또는 박스 필터를 적용하는 단계를 포함한다. 블록 806 에서, 제 1 그래디언트 맵 및 제 2 그래디언트 맵에 기초하여 출력 이미지 프레임의 픽셀들에 대한 가 중치가 결정된다. 가중치는, 예를 들어, 제 1 및 제 2 그래디언트 맵 값들 사이의 차이를 [0 ... 1] 사이의 값들 또는 [0 ... 255] 와 같은 다른 정규화 값으로 정규화함으로써 그래디언트 맵들로부터 결정될 수도 있다. 가중치는 대안적으로 가중치가 제 1 그래디언트 맵으로부터의 정규화된 값 또는 제 2 그래디언트 맵으로부터 의 정규화된 값이어야 하는지 여부를 나타내는, 0 또는 1과 같은 이진 값일 수도 있다. 이진 값은 이미지 데이터의 세트들 중 하나로부터의 기여도를 0으로서 효과적으로 가중시킴으로써, 제 1 이미지 데이터 또는 제 2 이미지 데이터로부터의 이미지 데이터를 사용할지 여부를 나타낼 수도 있다. 이러한 이진화는 제 1 이미지 데이터 내의 대응하는 픽셀에서의 그래디언트가 제 2 이미지 데이터 내의 대응하는 픽셀에서의 그래디언트보다 큰지 여부에 기초하여 제 1 세트의 픽셀들 내의 대응하는 픽셀 또는 제 2 세트의 픽셀들 내의 대응하는 픽셀로 부터 제 3 세트의 픽셀들의 픽셀에 대한 값을 선택하는 것을 초래할 수도 있다. 즉, 이진화는 픽셀 근처에 서 가장 높은 변화율을 갖는 것에 기초하여 제 1 이미지 데이터 또는 제 2 이미지 데이터로부터 픽셀에 대한 데 이터를 선택할 수도 있다. 다른 예에서, 가중치는 그래디언트 맵 내의 값들과 픽셀로부터의 이 값들의 거리 의 조합에 기초하여 결정될 수도 있다. 일부 실시형태들에서, 다수의 가중치들이 출력 이미지 프레임 픽셀 값들의 결정에 사용될 수도 있다. 예를 들어, 출력 이미지 프레임 내의 픽셀 Y 는 다음 식:"}
{"patent_id": "10-2023-7024724", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "에 의해 결정될 수도 있으며, 여기서 W0 는 전경 픽셀의 정규화된 그래디언트 (예컨대, '0'과 '1' 사이) 를 나 타내고, W1 은 배경 픽셀의 정규화된 그래디언트 (예컨대, '0'과 '1' 사이) 를 나타내고, Wa 는 출력 이미지 프 레임 내의 융합된 픽셀과 세그먼트화 경계 사이의 거리에 비례하고, Wb 는 융합된 픽셀과 세그먼트화 경계 사이 의 거리에 비례한다. 융합 프로세싱은 Threshold 수의 픽셀들에 의해 결정되는 전경과 배경 사이의 연합 심 도 맵 윤곽들에 적용될 수도 있다. 가중치들 W0, W1, Wa, 및 Wb 는 다음 식들:"}
{"patent_id": "10-2023-7024724", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "에 따라 결정될 수도 있으며, 여기서 Dist(P) 는 경계로부터의 픽셀 P의 거리이고, Grad(BG) 는 배경 이미지 프 레임으로부터의 픽셀 P에서의 그래디언트 맵 값이고, Grad(FG) 는 전경 이미지 프레임으로부터의 픽셀 P에서의 그래디언트 맵 값이고, Threshold 는 세그먼트화된 연합 전경들의 윤곽과 함께 융합 영역의 폭에 대응하는, 20 픽셀들과 같은, 값일 수도 있다. 다른 2개의 영역들, 전경 및 배경 상의 픽셀들은 결합 없이 원래의 제 1 및 제 2 이미지 프레임들로부터 복사될 수도 있다. 이 예시적인 식들에서 가중치들 Wa 및 Wb 에 대한 계산들 은 다른 식들에 기초할 수도 있다. 다른 예시적인 식들은 마찬가지로, Wa 가 1에 접근하고 Wb 가 연결된 전 경 픽셀들과 유사한 전경 근처의 융합된 픽셀들에 대해 0에 가깝도록, 그리고 융합된 픽셀이 융합 영역 상의 배 경 픽셀들의 이웃일 때 Wb 가 1에 접근하고 Wa 가 0에 가깝도록, 0과 1 사이에서 정규화된 융합 프로세싱에 대한가중치를 결정할 수도 있다. 본 개시의 실시형태들에서 설명된 이미지 캡처 디바이스로부터 캡처된 이미지 프레임들을 프로세싱하는 방법들 은 장면 및 장면에서의 객체들의 개선된 이미지들을 획득하는 데 사용될 수도 있다. 예를 들어, 이미지 프 레임들을 융합하기 위한 방법들은 인-포커스인 이미지 캡처 디바이스로부터 상이한 거리들에 있는 다수의 객체 들을 갖는 더 큰 초점 심도를 갖는 장면의 이미지들을 획득하는 것을 초래할 수도 있다. 이러한 융합 프로 세싱의 하나의 이점은 융합이 더 큰 애퍼처 및 더 짧은 초점 심도를 갖는 캡처 디바이스들을 갖는 이미지 캡처 디바이스의 사용을 허용할 수도 있다는 것이다. f/2.2보다 큰 애퍼처들 (f/2.0, f/1.8, f/1.4, 및/또는 f/1.2의 애퍼처들을 포함함) 을 갖는 렌즈들과 같은 이러한 더 큰 애퍼처 렌즈들은 초점 심도의 손실에서 저광 상황들과 같은 특정 상황들에서 개선된 이미지 품질을 제공할 수도 있다. 본 명세서의 실시형태들에 개시된 융합 프로세싱은, 예컨대 관심 객체들이 초점이 맞은 출력 이미지 프레임을 생성함으로써, 초점 심도의 손실이 감소되거나 없는 개선된 이미지 품질을 획득하는 것을 허용한다. 이는 다수의 관심 사람들이 있는 장면을 캡처할 때 특히 바람직할 수도 있는데, 이는 본 명세서에 설명된 융합 로직이 다수의 또는 모든 사람들이 초점 이 맞은 이미지들을 생성할 수 있기 때문이다. 또한, 큰 애퍼처 렌즈의 사용은 때때로 보케 블러로 지칭되 는 흐릿한 배경을 갖는 이미지를 생성한다. 더 큰 애퍼처 렌즈로부터 여러 이미지를 융합하면 많은 사진작 가들이 원하는 흐릿한 배경과 함께 인-포커스인 여러 객체를 가진 이미지를 생성할 수 있다. 본 개시의 일부 실시형태들에서의 융합 로직은 특정 조건들 하에서 트리거될 수도 있으며, 이는 이미지들의 불 필요한 프로세싱을 감소시킨다. 프로세싱의 양을 감소시키는 것은 배터리와 같은 제한된 전력 공급으로부터 동작하는 모바일 디바이스들에 특히 유리할 수도 있다. 융합 로직은 장면의 제 1 캡처된 이미지에 다수의 관심 대상들이 존재한다는 것을 나타내는 기준들에 기초하여 다수의 이미지들의 추가 이미지 캡처 및 프로세싱 및 병합을 트리거할 수도 있다. 예를 들어, 현재 카메라 구성에 대한 예상 초점 심도보다 큰 임계치만큼 분 리된 히스토그램 피크들이 존재할 때와 같이, 장면으로부터의 심도 데이터의 히스토그램이 다수의 관심 객체들 이 존재함을 나타낼 때, 융합 로직은 장면 및/또는 자동초점 시스템들에 대한 심도 데이터의 조합을 사용하여 결정된 추가적인 초점 거리들에서 추가적인 이미지들의 캡처를 명령할 수도 있다. 이러한 기준들이 충족되 지 않을 때, 융합 로직은 이미지 캡처 디바이스 및 연관된 프로세싱 및 메모리 회로에 의해 수행되는 동작들의 수를 감소시키기 위해 추가적인 이미지들의 캡처 및 이러한 이미지들의 후속 프로세싱을 트리거하지 않는다. 당업자들은 정보 및 신호들이 다양한 상이한 기술들 및 기법들 중 임의의 것을 사용하여 표현될 수도 있다는 것 을 이해할 것이다. 예를 들어, 상기 설명 전반에 걸쳐 참조될 수도 있는 데이터, 명령들, 커맨드 (command) 들, 정보, 신호들, 비트들, 심볼들, 및 칩들은 전압, 전류, 전자기파, 자계 또는 자성 입자, 광계 또는 광학 입 자, 또는 이들의 임의의 조합에 의해 표현될 수도 있다. 도 1 과 관련하여 본 명세서에 설명된 컴포넌트들, 기능 블록들, 및 모듈들은 다른 예들 중에서도 프로세서들, 전자 디바이스들, 하드웨어 디바이스들, 전자 컴포넌트들, 논리 회로들, 메모리들, 소프트웨어 코드들, 펌웨어 코드들, 또는 이들의 임의의 조합을 포함한다. 부가적으로, 본 명세서에서 논의된 특징들은 특수화된 프로 세서 회로부를 통해, 실행가능 명령들을 통해, 또는 이들의 조합들을 통해 구현될 수도 있다. 당업자는 또한, 본 명세서의 개시와 관련하여 설명된 다양한 예시적인 논리 블록, 모듈, 회로, 및 알고리즘 단 계가 전자 하드웨어, 컴퓨터 소프트웨어, 또는 이 양자의 조합으로 구현될 수도 있음을 인식할 것이다. 하 드웨어 및 소프트웨어의 이러한 상호교환가능성을 명백하게 예시하기 위하여, 다양한 예시적인 컴포넌트들, 블 록들, 모듈들, 회로들, 및 단계들이 일반적으로 그들의 기능성의 관점에서 설명되었다. 그러한 기능성이 하 드웨어 또는 소프트웨어로 구현될지 여부는, 전체 시스템에 부과된 특정 애플리케이션 및 설계 제약에 달려 있 다. 당업자는 설명된 기능성을 각각의 특정 어플리케이션에 대하여 다양한 방식들로 구현할 수도 있지만, 그러한 구현의 결정들이 본 개시의 범위로부터의 일탈을 야기하는 것으로서 해석되지는 않아야 한다. 당업 자는 또한, 본 명세서에서 설명되는 컴포넌트들, 방법들, 또는 상호작용들의 순서 또는 조합이 단지 예들일 뿐 이고 그리고 본 개시의 다양한 양태들의 컴포넌트들, 방법들, 또는 상호작용들이 본 명세서에서 예시되고 설명 된 것들 이외의 방식들로 결합되거나 수행될 수도 있음을 용이하게 인식할 것이다. 본 명세서에 개시된 구현들과 관련하여 설명된 다양한 예시적인 로직들, 논리 블록들, 모듈들, 회로들 및 알고 리즘 프로세스들은 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양자의 조합들로서 구현될 수도 있다. 하드웨 어와 소프트웨어의 상호교환가능성은 일반적으로 기능성의 관점에서 설명되었고, 위에 설명된 다양한 예시적인 컴포넌트들, 블록들, 모듈들, 회로들 및 프로세스들로 예시되었다. 그러한 기능성이 하드웨어에서 구현되는 지 또는 소프트웨어에서 구현되는지는 전체 시스템에 부과된 설계 제약들 및 특정 애플리케이션에 의존한다.본 명세서에 개시된 양태들과 관련하여 설명된 다양한 예시적인 로직들, 논리 블록들, 모듈들 및 회로들을 구현 하는데 사용되는 하드웨어 및 데이터 프로세싱 장치는 범용 단일- 또는 멀티-칩 프로세서, 디지털 신호 프로세 서 (DSP), 주문형 집적 회로 (ASIC), 필드 프로그램가능 게이트 어레이 (FPGA) 또는 다른 프로그램가능 로직 디 바이스, 이산 게이트 또는 트랜지스터 로직, 이산 하드웨어 컴포넌트들, 또는 본 명세서에서 설명된 기능들을 수행하도록 설계된 이들의 임의의 조합으로 구현 또는 수행될 수도 있다. 범용 프로세서는 마이크로프로세 서, 또는 임의의 종래의 프로세서, 제어기, 마이크로제어기, 또는 상태 머신일 수도 있다. 일부 구현들에서, 프로세서는 컴퓨팅 디바이스들의 조합, 예컨대 DSP 와 마이크로프로세서의 조합, 복수의 마이크로 프로세서들, DSP 코어와 결합된 하나 이상의 마이크로프로세서, 또는 임의의 다른 그러한 구성으로서 구현될 수 도 있다. 일부 구현들에서, 특정 프로세스들 및 방법들은 주어진 기능에 특정되는 회로부에 의해 수행될 수 도 있다. 하나 이상의 양태에서, 설명된 기능들은, 본 명세서에 개시된 구조들 및 이들의 그 구조적 균등물들을 포함하여, 하드웨어, 디지털 전자 회로부, 컴퓨터 소프트웨어, 펌웨어, 또는 이들의 임의의 조합에서 구현될 수 도 있다. 본 명세서에서 설명된 주제의 구현들은 또한, 하나 이상의 컴퓨터 프로그램들, 즉, 데이터 프로세 싱 장치에 의한 실행을 위해 또는 데이터 프로세싱 장치의 동작을 제어하기 위해 컴퓨터 저장 매체들 상에서 인 코딩된 컴퓨터 프로그램 명령들의 하나 이상의 모듈들로서 구현될 수도 있다. 소프트웨어에서 구현되는 경우, 기능들은 하나 이상의 명령 또는 코드로서 컴퓨터 판독가능 매체 상에서 저장 또는 송신될 수도 있다. 본 명세서에 개시된 방법 또는 알고리즘의 프로세스들은 컴퓨터 판독가능 매체 상 에 상주할 수도 있는 프로세서 실행가능 소프트웨어 모듈에서 구현될 수도 있다. 컴퓨터 판독가능 매체들은 컴퓨터 프로그램을 일 장소로부터 다른 장소로 전송하도록 인에이블될 수도 있는 임의의 매체를 포함하는 통신 매체들 및 컴퓨터 저장 매체들 양자 모두를 포함한다. 저장 매체는, 컴퓨터에 의해 액세스될 수도 있는 임 의의 가용 매체일 수도 있다. 한정이 아닌 예로서, 그러한 컴퓨터 판독가능 매체들은 RAM (random-access memory), ROM (read-only memory), EEPROM (electrically erasable programmable read-only memory), CD-ROM 또는 다른 광학 디스크 스토리지, 자기 디스크 스토리지 또는 다른 자기 스토리지 디바이스들, 또는 원하는 프 로그램 코드를 명령들 또는 데이터 구조들의 형태로 저장하는데 사용될 수도 있고 컴퓨터에 의해 액세스될 수도 있는 임의의 다른 매체를 포함할 수도 있다. 또한, 임의의 연결이 컴퓨터 판독가능 매체로 적절히 명명될 수 있다. 디스크 (disk) 및 디스크 (disc) 는, 본 명세서에서 사용된 바와 같이, 컴팩트 디스크 (CD), 레이 저 디스크, 광학 디스크, 디지털 다기능 디스크 (DVD), 플로피 디스크, 및 블루레이 디스크를 포함하며, 여기서 디스크 (disk) 들은 보통 데이터를 자기적으로 재생 (reproduce) 하는 한편, 디스크 (disc) 들은 레이저들로 데 이터를 광학적으로 재생한다. 상기의 조합들이 또한 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 추가적으로, 방법 또는 알고리즘의 동작들은 코드들 및 명령들 중 하나 또는 임의의 조합 또는 세트로서 머 신 판독가능 매체 및 컴퓨터 판독가능 매체 상에 상주할 수도 있으며, 이들은 컴퓨터 프로그램 제품에 통합될 수도 있다. 본 개시에서 설명된 구현들에 대한 다양한 수정들은 당업자에게 용이하게 자명할 수도 있으며, 본 명세서에서 정의된 일반적인 원리들은 본 개시의 사상 또는 범위로부터 일탈함없이 일부 다른 구현들에 적용될 수도 있다. 따라서, 청구항들은 본 명세서에 나타낸 구현들에 제한되도록 의도되지 않으며, 본 명세서에 개시된 본 개시, 원리들 및 신규한 특징들과 부합하는 최광의 범위를 부여받아야 한다. 추가적으로, 당업자는, 용어들 \"상부\" 및 \"하부\" 가 도면들을 쉽게 설명하기 위해 때때로 사용되고 적절히 배향 된 페이지 상에서 도면의 배향에 대응하는 상대적 포지션들을 표시하며, 구현된 바와 같이 임의의 디바이스의 적절한 배향을 반영하지 않을 수도 있음을 용이하게 이해할 것이다. 별도의 구현들의 컨텍스트에서 본 명세서에서 설명되는 소정의 특징들은 또한 단일 구현의 조합으로 구현될 수 도 있다. 반면, 단일 구현의 컨텍스트에 있어서 설명된 다양한 특징들은 또한, 다수의 구현들에서 별개로 또는 임의의 적합한 하위조합으로 구현될 수도 있다. 더욱이, 비록 특징들이 소정의 조합들로 작용하는 것으로서 위에 설명되고 심지어 그와 같이 초기에 청구될 수도 있지만, 청구된 조합으로부터의 하나 이상의 특징 은 일부 경우들에서 그 조합으로부터 삭제될 수도 있으며, 청구된 조합은 하위조합 또는 하위조합의 변형으로 지향될 수도 있다. 유사하게, 동작들이 도면들에 있어서 특정 순서로 도시되지만, 이는, 바람직한 결과들을 달성하기 위해, 그러한 동작들이 나타낸 특정 순서로 또는 순차적인 순서로 수행되어야 하거나 또는 예시된 모든 동작들이 수행되어야 할 것을 요구하는 것으로서 이해되지 않아야 한다. 또한, 도면들은 하나 이상의 예시적인 프로세스들을 플로우 다이어그램의 형태로 개략적으로 도시할 수도 있다. 하지만, 도시되지 않은 다른 동작들이 개략적으로 도시되는 예시의 프로세스들에 통합될 수도 있다. 예를 들어, 하나 이상의 추가 동작이 도시된 동작들 중 임의의 동작들 이전에, 그 이후에, 그와 동시에, 또는 그들 사이에서 수행될 수도 있다. 소정의 상황들에 있어서, 멀티태스킹 및 병렬 프로세싱이 유리할 수도 있다. 더욱이, 위에서 설명된 구현들에서 다양한 시스 템 컴포넌트들의 분리가 그러한 분리를 모든 구현들에서 요구하는 것으로 이해되지 않아야 하며, 설명된 프로그 램 컴포넌트들 및 시스템들은 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다중 소프트웨어 제품들로 패키징될 수도 있음이 이해되어야 한다. 추가적으로, 일부 다른 구현들은 다음의 청구항들의 범위 내에 있 다. 일부 경우들에서, 청구항들에 인용된 액션들은 상이한 순서로 수행되며 여전히 바람직한 결과들을 달성 할 수도 있다. 청구항들을 포함하여 본 명세서에서 사용된 바와 같이, 용어 \"또는\" 은, 2 이상의 아이템들의 리스트에서 사용 될 경우, 리스팅된 아이템들 중 임의의 아이템이 홀로 채용될 수 있거나 또는 리스팅된 아이템들 중 2 이상의 임의의 조합이 채용될 수 있음을 의미한다. 예를 들어, 장치가 컴포넌트들 A, B, 또는 C 를 포함하는 것으 로서 설명되면, 장치는 A 만; B 만; C 만; A 와 B 의 조합; A 와 C 의 조합; B 와 C 의 조합; 또는 A, B 와 C 의 조합을 포함할 수 있다. 또한, 청구항들을 포함하여 본 명세서에서 사용된 바와 같이, \"중 적어도 하나\" 에 의해 시작된 아이템들의 리스트에서 사용되는 바와 같은 \"또는\" 은, 예를 들어, \"A, B, 또는 C 중 적어도 하 나\" 의 리스트가 A 또는 B 또는 C 또는 AB 또는 AC 또는 BC 또는 ABC (즉, A 와 B 와 C) 또는 이들의 임의의 조 합에서의 이들 중 임의의 것을 의미하도록 하는 이접적 리스트를 표시한다. 용어 \"실질적으로\" 는 당업자에 의해 이해되는 바와 같이, 특정된 것 (특정된 것을 포함하고; 예를 들어, 실질적으로 90 도는 90 도를 포함하고 실질적으로 평행은 평행을 포함) 을 대체로 그러나 반드시 전체가 아닌 것으로 규정된다. 임의의 개시된 구 현들에서, 용어 \"실질적으로\"는 특정된 것의 \"[백분율] 이내\"로 대체될 수도 있으며, 여기서 백분율은 .1, 1, 5 또는 10%를 포함한다. 본 개시의 전술된 설명은 임의의 당업자로 하여금 본 개시를 제조 또는 사용하게 할 수 있도록 제공된다. 본 개시에 대한 다양한 수정들은 당업자들에게 용이하게 명백할 것이며, 본 명세서에서 정의된 일반적인 원리들 은 본 개시의 사상 또는 범위로부터 일탈함없이 다른 변경들에 적용될 수도 있다. 따라서, 본 개시는 본 명 세서에 설명된 예시들 및 설계들로 제한되지 않고, 본원에 개시된 원리들 및 신규한 특징들과 일치하는 최광의 범위에 부합되고자 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2023-7024724", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 특성 및 이점들의 추가의 이해는 다음의 도면들을 참조하여 실현될 수도 있다. 첨부 도면들에서, 유사한 컴포넌트들 또는 피처들은 동일한 참조 라벨을 가질 수도 있다. 또한, 동일한 유형의 다양한 컴포넌 트들은 참조 라벨 다음에 대시 및 유사한 컴포넌트들 간을 구별하는 제 2 라벨을 오게 함으로써 구별될 수도 있 다. 제 1 참조 라벨만이 명세서에서 사용되는 경우, 설명은 제 2 참조 라벨과 관계없이 동일한 제 1 참조 라벨을 갖는 유사한 컴포넌트들 중 임의의 하나에 적용 가능하다. 도 1 은 본 개시에서 설명된 예시적인 기법들 중 하나 이상을 수행하도록 구성된 컴퓨팅 디바이스의 블록도이다. 도 2 는 본 개시의 실시형태들에 따른 출력 이미지 프레임을 획득하기 위한 복수의 이미지들의 융합을 예시하는 블록도이다. 도 3 은 본 개시의 일부 실시형태들에 따른 융합 로직의 실행에 관한 예시적인 결정을 예시하는 블록도이다. 도 4 는 본 개시의 일부 실시형태들에 따른 융합 로직으로 이미지 프레임을 프로세싱하는 방법에 대한 흐름도이 다. 도 5 는 본 개시의 일부 실시형태들에 따른 출력 이미지 프레임을 결정하기 위한 2개의 이미지 프레임들로부터 의 이미지 데이터의 세그먼트화 및 병합을 예시하는 블록도이다. 도 6 은 본 개시의 일부 실시형태들에 따른 윤곽 맵들을 사용한 이미지 데이터의 세그먼트화를 예시하는 흐름도 이다. 도 7 은 본 개시의 일부 실시형태들에 따른 가중치에 기초하여 융합된 출력 이미지 프레임을 결정하기 위한 이 미지 데이터의 병합을 예시하는 흐름도이다. 도 8 은 본 개시의 일부 실시형태들에 따른 2개의 이미지 프레임들을 융합하기 위한 그래디언트 맵들에 기초한 가중치들의 생성을 예시하는 흐름도이다. 다양한 도면들에서 동일한 참조 부호들 및 지정들은 동일한 엘리먼트들을 표시한다."}
