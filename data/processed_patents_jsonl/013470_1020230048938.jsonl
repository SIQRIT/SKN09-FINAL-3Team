{"patent_id": "10-2023-0048938", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0045068", "출원번호": "10-2023-0048938", "발명의 명칭": "퍼소나 기반의 아바타 매칭 화상 미팅 시스템 및 이의 동작 방법", "출원인": "이다커뮤니케이션즈", "발명자": "박성훈"}}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "화상 미팅에 참여하는 복수의 참여자 단말; 화상 미팅에 참여하는 참여자의 퍼소나를 진단하여 퍼소나 진단 정보를 생성하는 퍼소나 진단 정보 생성부; 및 상기 복수의 참여자 단말을 화상 미팅으로 연결하는 화상 미팅 서버를 포함하며, 상기 화상 미팅 서버는 상기 퍼소나 진단 정보에 기반하여 적어도 하나의 아바타를 생성하고, 상기 아바타를 상기 참여자 단말로 전달하는 아바타 생성부; 상기 참여자 단말에 연결된 촬영 장치에서 촬영된 영상 정보를 프레임 단위로 분석하여 3D 좌표화된 안면 정보를 추출하는 영상 정보 분석부; 상기 참여자 단말에서 선택된 상기 아바타의 이미지를 상기 영상 정보 분석부에서 추출된 상기 3D 좌표화된 안면 정보에 맵핑시키는 안면 맵핑부; 및 상기 촬영 장치에서 촬영된 영상 정보 내에 상기 아바타의 이미지가 포함되는 아바타 영상을 생성하는 아바타영상 생성부를 포함하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 안면 맵핑부는 상기 아바타의 이미지를 상기 3D 좌표화된 안면 정보에 맵핑하여 3D 모델링된 아바타 이미지를 생성하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 아바타 영상 생성부는 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정보가 일치하지 않는 경우, 상기 3D 모델링된 아바타 이미지를 이동시키는 3D 모델 컨트롤러; 및 상기 촬영 장치에서 촬영된 영상 정보의 배경을 3D 가상 공간으로 변경하는 3D 가상 공간 생성부를 포함하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 화상 미팅 서버는 상기 퍼소나 진단 정보 생성부에서 생성된 상기 퍼소나 진단 정보를 수신하는 퍼소나 진단 정보 수신부; 상기 촬영 장치에서 촬영된 상기 영상 정보를 수신하는 영상 정보 수신부; 및 상기 상기 아바타 영상 생성부에서 생성된 상기 아바타 영상을 상기 참여자 단말로 출력하는 아바타 영상 출력부를 더 포함하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3 항에 있어서, 공개특허 10-2024-0045068-3-상기 복수의 참여자 단말은 화상 미팅을 통하여 상담을 요청하는 고객의 단말인 적어도 하나의 제1 참여자 단말; 및 고객의 상담 요청에 의해 상담을 진행하는 상담사의 단말인 적어도 하나의 제2 참여자 단말을 포함하는 퍼소나기반의 아바타 매칭 화상 미팅 시스템."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 촬영 장치는 상기 제1 참여자 단말에 연결되는 제1 촬영 장치; 및 상기 제2 참여자 단말에 연결되는 제2 촬영 장치를 포함하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3 항에 있어서, 상기 화상 미팅 서버는 웹 브라우저 기반의 화상 미팅 서비스를 제공하는 퍼소나 기반의 아바타 매칭 화상 미팅시스템."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "퍼소나 진단 정보 생성부에서 화상 미팅에 참여하는 참여자의 퍼소나 진단 정보를 생성하는 퍼소나 진단 정보생성 단계; 화상 미팅 서버의 아바타 생성부가 상기 퍼소나 진단 정보에 기반하여 적어도 하나의 아바타를 생성하고, 상기아바타를 참여자 단말로 전달하는 아바타 생성 단계; 상기 화상 미팅 서버의 안면 정보 분석부가 촬영 장치에서 촬영된 영상 영보를 프레임 단위로 분석하여 3D 좌표화된 안면 정보를 추출하는 영상 정보 분석 단계; 상기 화상 미팅 서버의 안면 맵핑부가 상기 참여자 단말에서 선택된 상기 아바타의 이미지를 상기 3D 좌표화된안면 정보에 맵핑시키는 아바타 이미지 및 안면 좌표 맵핑 단계; 상기 영상 정보 내에 상기 아바타 이미지가 포함되는 아바타 영상을 생성하는 아바타 영상 정보 생성 단계; 및 상기 참여자의 참여자 단말을 화상 미팅에 연결하는 화상 미팅 연결 단계를 포함하고, 상기 아바타 이미지 및 안면 좌표 맵핑 단계에서, 상기 아바타 이미지는 참여자의 안면에 대응할 수 있는 3D 모델링된 아바타 이미지로 변경되는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서, 상기 아바타 이미지 및 안면 좌표 맵핑 단계 이후에, 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정보가일치하는지 판단하는 좌표 일치 판단 단계; 및 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정보가 일치하지 않는 경우, 아바타 영상 생성부의 3D 모델 컨트롤러는 상기 3D 모델링된 아바타 이미지를 이동시켜 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정보가일치시키는 아바타 이미지 이동 단계를 더 포함하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 영상 정보 분석 단계는 상기 화상 미팅 서버의 영상 정보 수신부가 상기 영상 정보를 수신하는 영상 정보 수신 단계; 상기 화상 미팅 서버의 영상 정보 분석부가 상기 영상 정보를 프레임 단위로 분석하여 참여자의 안면 정보를 추공개특허 10-2024-0045068-4-출하는 프레임 영상 분석 단계; 및 상기 영상 정보 분석부가 상기 안면 정보를 상기 3D 좌표화된 안면 정보로 추출하는 안면 좌표 정보 추출 단계를 포함하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법."}
{"patent_id": "10-2023-0048938", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서, 상기 영상 정보 내의 배경이 노출될 필요가 있는지 판단하는 배경 노출 판단 단계; 및 배경의 노출이 불필요한 경우, 상기 아바타 영상 생성부의 3D 가상 공간 생성부가 상기 안면 정보 이외의 배경을 가상의 3D 공간으로 변경시키는 3D 가상 공간 생성 단계를 더 포함하는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법."}
{"patent_id": "10-2023-0048938", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 퍼소나 기반의 아바타 매칭 화상 미팅 시스템은 화상 미팅에 참여하는 복수의 참여자 단말; 화상 미팅 에 참여하는 참여자의 퍼소나를 진단하여 퍼소나 진단 정보를 생성하는 퍼소나 진단 정보 생성부; 및 상기 복수 의 참여자 단말을 화상 미팅으로 연결하는 화상 미팅 서버를 포함하며, 상기 화상 미팅 서버는 상기 퍼소나 진단 정보에 기반하여 적어도 하나의 아바타를 생성하고, 상기 아바타를 상기 참여자 단말로 전달하는 아바타 생성부; 상기 참여자 단말에 연결된 촬영 장치에서 촬영된 영상 정보를 프레임 단위로 분석하여 3D 좌표화된 안면 정보를 추출하는 영상 정보 분석부; 상기 참여자 단말에서 선택된 상기 아바타의 이미지를 상기 영상 정보 분석부에서 추출된 상기 3D 좌표화된 안면 정보에 맵핑시키는 안면 맵핑부; 및 상기 촬영 장치에서 촬영된 영상 정보 내에 상기 아바타 이미지가 포함되는 아바타 영상을 생성하는 아바타 영상 생성부를 포함할 수 있다."}
{"patent_id": "10-2023-0048938", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 퍼소나 기반의 아바타 매칭 화상 미팅 시스템 및 이의 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0048938", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 코로나19와 같은 감염성 질병으로 인해, 오프라인 미팅이 어려워짐에 따라 온라인(on-line)을 이용한 화상 미팅이 증가하고 있다. 화상 미팅은 사람들 사이의 직접 접촉을 방지한다는 점에서 코로나19와 같은 감염성 질 병의 예방에 우수한 효과가 있다. 화상 미팅은 사용자의 영상 및 음성 정보를 선명하고 빠르게 미팅 참석자에게 전달하는 것을 목표로 하고 있으 며, 서비스에 따라 다수의 참여자가 참석할 수도 있다. 또한, 화상 미팅은 카메라에서 획득한 영상을 전송하는 것에 그치지 않고, 동영상 등의 다양한 컨텐츠를 공유할 수도 있다. 하지만, 일반적인 화상 미팅은 참여자의 안면 영상이 바로 노출될 수 있다. 참여자의 안면이 노출되는 경우, 참 여자의 프라이버시가 침해될 수 있다. 이에 참여자의 안면 노출을 방지하기 위한 다양한 방법이 연구되고 있다."}
{"patent_id": "10-2023-0048938", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 종래 기술의 문제점을 해결하고자 창출된 것으로서, 본 발명의 일 목적은 참여자의 안면 위치에 3D 모델링된 아바타 이미지를 적용하여 화상 미팅 참여자의 안면 또는 배경이 타 참여자에게 노출되는 것을 방지할 수 있는 퍼소나 기반의 아바타 매칭 화상 미팅 시스템 및 이의 동작 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2023-0048938", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템은 화상 미팅에 참여하는 복수의 참여자 단말; 화상 미팅에 참여하는 참여자의 퍼소나를 진단하여 퍼소나 진단 정보를 생성하는 퍼소나 진단 정보 생성 부; 및 상기 복수의 참여자 단말을 화상 미팅으로 연결하는 화상 미팅 서버를 포함하며, 상기 화상 미팅 서버는 상기 퍼소나 진단 정보에 기반하여 적어도 하나의 아바타를 생성하고, 상기 아바타를 상기 참여자 단말로 전달 하는 아바타 생성부; 상기 참여자 단말에 연결된 촬영 장치에서 촬영된 영상 정보를 프레임 단위로 분석하여 3D 좌표화된 안면 정보를 추출하는 영상 정보 분석부; 상기 참여자 단말에서 선택된 상기 아바타의 이미지를 상기 영상 정보 분석부에서 추출된 상기 3D 좌표화된 안면 정보에 맵핑시키는 안면 맵핑부; 및 상기 촬영 장치에서 촬영된 영상 정보 내에 상기 아바타 이미지가 포함되는 아바타 영상을 생성하는 아바타 영상 생성부를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 안면 맵핑부는 상기 아바타의 이미지를 상기 3D 좌표화된 안면 정보에 맵 핑하여 3D 모델링된 아바타 이미지를 생성할 수 있다. 본 발명의 일 실시예에 있어서, 상기 아바타 영상 생성부는 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정 보가 일치하지 않는 경우, 상기 3D 모델링된 아바타 이미지를 이동시키는 3D 모델 컨트롤러; 및 상기 촬영 장치 에서 촬영된 영상 정보의 배경을 3D 가상 공간으로 변경하는 3D 가상 공간 생성부를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 화상 미팅 서버는 상기 퍼소나 진단 정보 생성부에서 생성된 상기 퍼소나 진단 정보를 수신하는 퍼소나 진단 정보 수신부; 상기 촬영 장치에서 촬영된 상기 영상 정보를 수신하는 영상 정보 수신부; 및 상기 상기 아바타 영상 생성부에서 생성된 상기 아바타 영상을 상기 참여자 단말로 출력하는 아바타 영상 출력부를 더 포함할 수 있다. 본 발명의 일 실시예에 있어서, 본 발명의 일 실시예에 있어서, 상기 복수의 참여자 단말은 화상 미팅을 통하여 상담을 요청하는 고객의 단말인 적어도 하나의 제1 참여자 단말; 및 고객의 상담 요청에 의해 상담을 진행하는 상담사의 단말인 적어도 하나의 제2 참여자 단말을 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 촬영 장치는 상기 제1 참여자 단말에 연결되는 제1 촬영 장치; 및 상기 제 2 참여자 단말에 연결되는 제2 촬영 장치를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 화상 미팅 서버는 웹 브라우저 기반의 화상 미팅 서비스를 제공할 수 있다. 본 발명의 일 측면에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법은 퍼소나 진단 정보 생성 부에서 화상 미팅에 참여하는 참여자의 퍼소나 진단 정보를 생성하는 퍼소나 진단 정보 생성 단계; 화상 미팅 서버의 아바타 생성부가 상기 퍼소나 진단 정보에 기반하여 적어도 하나의 아바타를 생성하고, 상기 아바타를 참여자 단말로 전달하는 아바타 생성 단계; 상기 화상 미팅 서버의 안면 정보 분석부가 촬영 장치에서 촬영된 영상 영보를 프레임 단위로 분석하여 3D 좌표화된 안면 정보를 추출하는 영상 정보 분석 단계; 상기 화상 미팅 서버의 안면 맵핑부가 상기 참여자 단말에서 선택된 상기 아바타의 이미지를 상기 3D 좌표화된 안면 정보에 맵 핑시키는 아바타 이미지 및 안면 좌표 맵핑 단계; 상기 영상 정보 내에 상기 아바타 이미지가 포함되는 아바타 영상을 생성하는 아바타 영상 정보 생성 단계; 및 상기 참여자의 참여자 단말을 화상 미팅에 연결하는 화상 미 팅 연결 단계를 포함하고, 상기 아바타 이미지 및 안면 좌표 맵핑 단계에서, 상기 아바타 이미지는 참여자의 안 면에 대응할 수 있는 3D 모델링된 아바타 이미지로 변경될 수 있다. 본 발명의 일 실시예에 있어서, 상기 아바타 이미지 및 안면 좌표 맵핑 단계 이후에, 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정보가 일치하는지 판단하는 좌표 일치 판단 단계; 및 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정보가 일치하지 않는 경우, 상기 아바타 영상 생성부의 3D 모델 컨트롤러는 상기 3D 모델링된 아바타 이미지를 이동시켜 상기 아바타의 이미지 및 상기 3D 좌표화된 안면 정보가 일치시키는 아바타 이미지 이동 단계를 더 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 영상 정보 분석 단계는 상기 화상 미팅 서버의 영상 정보 수신부가 상기 영상 정보를 수신하는 영상 정보 수신 단계; 상기 화상 미팅 서버의 영상 정보 분석부가 상기 영상 정보를 프레 임 단위로 분석하여 참여자의 안면 정보를 추출하는 프레임 영상 분석 단계; 및 상기 영상 정보 분석부가 상기 안면 정보를 상기 3D 좌표화된 안면 정보로 추출하는 안면 좌표 정보 추출 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0048938", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템 및 이의 동작 방법은 참여자의 안면 위치에 3D 모 델링된 아바타 이미지를 적용하여 화상 미팅 참여자의 안면 또는 배경이 타 참여자에게 노출되는 것을 방지할 수 있다."}
{"patent_id": "10-2023-0048938", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적, 특정한 장점들 및 신규한 특징들은 첨부된 도면들과 연관되는 이하의 상세한 설명과 바람직한 실시예로부터 더욱 명백해질 것이다. 본 명세서에서 각 도면의 구성요소들에 참조번호를 부가함에 있어서, 동일 한 구성 요소들에 한해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 번호를 가지도록 하고 있음에 유의하여야 한다. 또한, 본 발명을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지 를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명은 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 또한, 제 1, 제 2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템을 설명하기 위한 도면이며, 도 2는 도 1에 도시된 화상 미팅 서버의 구성을 설명하기 위한 도면이며, 도 3은 도 2에 도시된 아바타 영상 생 성부를 설명하기 위한 도면이며, 도 4는 도 1에 도시된 퍼소나 진단 정보 생성부의 구성을 설명하기 위한 도면 이며, 도 5는 1차 퍼소나, 2차 퍼소나 및 3차 퍼소나를 설명하기 위한 도면이며, 도 6은 본 발명의 일 실시예에 따른 제1 퍼소나 분류 동작을 설명하기 위한 도면이다. 도 1 내지 도 6을 참조하면, 본 발명의 퍼소나 기반의 아바타 매칭 화상 미팅 시스템은 화상 미팅 서버 , 퍼소나 진단 정보 생성부, 및 참여자 단말(310, 320)을 포함할 수 있다. 이러한 퍼소나 기반의 아 바타 매칭 화상 미팅 시스템은 참여자의 안면이 타 참여자에게 노출되는 것을 방지할 수 있다. 또한, 퍼소나 기반의 아바타 매칭 화상 미팅 시스템은 물품 또는 서비스 구매를 위한 고객과 고객의 상담 요청에 의해 상담을 진행하는 상담사를 연결하고, 화상 미팅을 진행하도록 할 수 있다. 화상 미팅 서버, 퍼소나 진단 정보 생성부, 및 참여자 단말(310, 320)은 네트워크를 통하여 연결될 수 있다. 여기서, 네트워크는, 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미할 수 있다. 이러한 네트워크에는 RF, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5GPP(5rd Generation Partnership Project) 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스 (Bluetooth) 네트워크, NFC 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 않을 수 있다. 이러한 네트워크는 참여자 단말(310, 320) 및 화상 미팅 서버 사이와, 퍼소나 진단 정보 생성부 및 화상 미팅 서버 사이를 통신으로 연결하며, 서로 간에 데이터 송수신이 가능하도록 할 수 있다. 화상 미팅 서버는 네트워크를 통하여 퍼소나 진단 정보 생성부 및 참여자 단말(310, 320)에 연결될 수 있다. 특히, 화상 미팅 서버는 고객과 상담사의 화상 미팅이 진행될 수 있는 링크를 생성하고, 참여자 단말(310, 320)이 화상 미팅을 위한 웹 브라우저의 특정 주소에 참여하도록 유도할 수 있다. 즉, 화상 미팅 서 버는 복수의 참여자 단말(310, 320)이 화상 미팅에 참여할 수 있게 한다. 화상 미팅 서버는 참여자 단말(310, 320)에 webRTC(Web Real-Time Communication)와 같이 웹 브라우저 기 반의 화상 미팅 서비스를 제공할 수 있다. 여기서, webRTC는 별도의 소프트웨어를 설치없이 웹 브라우저를 통하 여 화상 미팅을 제공하는 기술일 수 있다. 한편, 본 발명의 일 실시예에서는 화상 미팅 서버가 웹 브라우저 기반의 화상 미팅 서비스를 제공함을 예 로서 설명하였으나, 이에 한정되는 것은 아니다. 예를 들면, 화상 미팅 서버는 별도의 소프트웨어 또는 어 플을 이용하여 화상 미팅 서비스를 제공할 수도 있다. 화상 미팅 서버는 퍼소나 진단 정보 생성부 및 참여자 단말(310, 320)로부터 다양한 데이터를 수신할 수 있다. 예를 들면, 화상 미팅 서버는 퍼소나 진단 정보 생성부로부터 화상 미팅에 참여하는 참여자 의 퍼소자 진단 정보를 포함하는 데이터를 수신할 수 있다. 또한, 화상 미팅 서버는 참여자 단말(310, 320)로부터 화상 미팅에 참여하는 참여자의 개인 정보 및 화상 정보를 수신할 수 있다. 화상 미팅 서버는 퍼소나 진단 정보 생성부 및 참여자 단말(310, 320)에 다양한 데이터를 전달할 수 도 있다. 예를 들면, 화상 미팅 서버는 퍼소나 진단 정보 생성부로부터 화상 미팅에 참여하는 참여자 의 퍼소자 진단 정보를 포함하는 데이터를 참여자 단말(310, 320)로 송신할 수 있다. 또한, 화상 미팅 서버 는 화상 미팅을 수행하는 페이지의 웹 주소등을 포함하는 정보를 참여자 단말(310, 320)에 송신할 수 있다. 화상 미팅 서버는 도 2에 도시된 바와 같이, 퍼소나 진단 정보 수신부, 아바타 생성부, 영상 정 보 수신부, 영상 정보 분석부, 안면 맵핑부, 아바타 영상 생성부 및 아바타 영상 출력부 를 포함할 수 있다. 퍼소나 진단 정보 수신부는 퍼소나 진단 정보 생성부에서 생성된 고객 및 상담사의 퍼소나 진단 정보 를 수신하고, 저장할 수 있다. 아바타 생성부는 퍼소나 진단 정보 생성부에서 생성된 고객 및 상담사의 퍼소나 진단 정보에 기반하 여 적어도 하나의 아바타를 생성할 수 있다. 아바타 생성부에서 생성된 아바타는 참여자 단말(310, 320)로 전송되며, 고객 및 상담사 각각의 참여자 단말(310, 320)은 원하는 아바타를 선택할 수 있다. 여기서, 아바타는 참여자의 안면에 대응될 수 있는 이미지 형태로 구현될 수 있다. 영상 정보 수신부는 참여자 단말(310, 320)에 연결된 촬영 장치(410, 420)에서 촬영된 영상 정보를 수신하 고 저장할 수 있다. 영상 정보 분석부는 영상 정보 수신부에서 수신한 영상 정보를 AI와 같은 인공 지능을 이용하여 프레 임 단위로 분석함으로써 3D 좌표화된 안면 정보를 추출할 수 있다. 예를 들면, 영상 정보 분석부는 영상 정보 수신부에서 수신한 영상 정보를 프레임 단위로 분석하여 참여자의 안면을 인식하고, 안면 형태를 안면 정 보로 추출하며, 안면 정보를 좌표화할 수 있다. 여기서, 죄표화된 안면 정보는 안면의 3D 좌표 정보로, 안면 정 보 내의 각 지점은 (x,y,z)와 같이 3D 좌표로 추출될 수 있다. 안면 맵핑부는 아바타 생성부에서 생성되고 참여자 단말(310, 320)에서 선택된 아바타의 이미지를 3D 좌표화된 안면 정보에 맵핑시킬 수 있다. 즉, 안면 맵핑부는 아바타 이미지를 촬영 장치(410, 420)에서 촬 영된 영상 정보 내의 안면에 대응하도록 맵핑할 수 있다. 따라서, 아바타 이미지는 참여자의 안면에 대응할 수 있는 3D 모델링된 아바타 이미지로 변경될 수 있다. 아바타 영상 생성부는 촬영 장치(410, 420)에서 촬영된 영상 정보와 상술한 3D 모델링된 아바타 이미지를 포함하는 아바타 영상을 생성할 수 있다. 예를 들면, 아바타 영상 생성부는 촬영 장치(410, 420)에서 촬영 된 영상 정보에서 참여자의 안면 위치에 아바타 이미지가 적용된 아바타 영상을 생성할 수 있다. 따라서, 화상 미팅 참여자의 안면 노출이 방지될 수 있다. 아바타 영상 생성부는 도 3에 도시된 바와 같이, 3D 모델 컨트롤러 및 3D 가상 공간 생성부를 포함할 수 있다. 3D 모델 컨트롤러는 아바타 생성부에서 생성되고 선택된 아바타의 3D 모델링된 이미지가 3D 좌표화된 참여자의 안면 정보와 일치하지 않는 경우, 아바타의 3D 모델링된 이미지를 이동시킬 수 있다. 즉, 3D 모델 컨 트롤러는 3D 모델링된 아바타 이미지와 3D 좌표화된 참여자의 안면 정보를 세밀하게 일치시킬 수 있다. 3D 가상 공간 생성부는 참여자의 안면 정보 이외의 배경을 가상의 공간으로 변경시킬 수 있다. 예를 들면, 3D 가상 공간 생성부는 참여자 단말(310, 320)에 연결된 촬영 장치(410, 420)에서 촬영된 영상 정보에서 배경 노출이 불필요한 참여자의 안면 정보 이외의 배경을 가상의 3D 공간으로 변경시킬 수 있다. 아바타 영상 출력부는 아바타 영상 생성부에서 생성된 아바타 영상을 화상 미팅 참여자의 단말, 즉, 참여자 단말(310, 320)로 출력할 수 있다. 예를 들면, 물품 및 서비스를 구매하고자 하는 고객의 참여자 단말 (310, 320)에는 상담사의 안면 위치에 아바타가 중첩된 상담사의 아바타 영상이 제공될 수 있다. 또한, 상담사 의 참여자 단말(310, 320)에는 고객의 안면 위치에 아바타가 중첩된 고객의 아바타 영상이 제공될 수 있다. 따 라서, 고객은 상담사에게 자신의 안면이 노출될 우려가 해소되며, 상담사는 고객에게 자신의 안면이 노출될 우 려가 해소될 수 있다. 퍼소나 진단 정보 생성부는 네트워크를 통하여 화상 미팅 서버에 연결되며, 입력된 참여자 정보를 통 하여 참여자에 적합한 퍼소나를 생성 또는 결정하여, 퍼소나 진단 정보를 생성할 수 있다. 퍼소나 진단 정보 생성부는 도 4에 도시된 바와 같이, 인증부, 설문 조사부, 퍼소나 분류부 및 퍼소나 매칭부를 포함할 수 있다. 인증부는 참여자 단말(310, 320)과 상호 작용하여 회원 가입 동작 및 로그인을 통한 인증 동작을 수행할 수 있다. 인증부는 회원 가입에 따른 회원 정보를 사참여자 단말(310, 320) 별로 저장할 수 있다. 이후에, 참여자 단말(310, 320)이 네트워크를 통하여 퍼소나 진단 정보 생성부와 연동된 플랫폼으로 로그인할 경우, 인증부는 저장한 회원 정보에 기초하여 참여자 단말(310, 320)을 인증할 수 있다. 설문 조사부는 참여자 단말(310, 320)에 퍼소나를 분류하기 위한 복수의 질문을 요청하고, 참여자 단말 (310, 320)로부터 복수의 문항에 대한 선택 정보를 수집할 수 있다. 여기서, 복수의 질문 각각은 복수의 문항을 포함할 수 있으며, 복수의 문항은 복수의 퍼소나 속성과 매칭될 수 있다. 퍼소나 속성에 대한 상세한 설명은 후 술하기로 한다. 예를 들면, 참여자 단말(310, 320)이 고객의 단말인 경우, 고객인 참여자의 이름, 연령대, 성별, 결혼상태, 자 녀 유무, 연소득, 나의 라이프 스타일을 설명하는 것, 내 인생에서 가장 관심 있는 것, 취미, '평소 사람들과의 관계에서 나는?', '어떤 일을 추진(결정)할 때의 나는?', '나의 커뮤니케이션 스타일은?', '지금 내게 필요한 것은?' 등의 질문이 퍼소나 분석을 위한 복수의 질문으로서 제공될 수 있다. 예를 들면, 참여자 단말(310, 320)이 상담사의 단말인 경우, 이름, 연령대, 성별, 결혼상태, 자녀 유무, 나의 라이프스타일을 설명하는 것, 내 인생에서 가장 관심있는 것, 취미, '평소 사람들과의 관계에서 나는?', '업무 에 대해 어떤 태도로 임하나요?', '나의 커뮤니케이션 스타일은?', 경력, 자격증, 상담 분야(전문 분야), 주 활 동 지역 등이 복수의 질문으로서 제공될 수 있으며, 상담사의 경력, 주력 세일즈 분야, 지역 등 상담사의 특성 에 따라 추가될 수 있다. 상술한 다양한 실시예들에 따른 복수의 질문 각각은 참여자 단말(310, 320)의 선택을 위한 복수의 문항을 포함 할 수 있고, 설문 조사부는 각 질문에 대하여 어떠한 문항이 선택되었는지를 나타내는 선택 정보를 수집할 수 있다. 퍼소나 분류부는 설문 조사부의 선택 정보에 기초하여 제1 퍼소나 분류 동작 및 제2 퍼소나 분류 동 작 중 하나를 선택적으로 수행하여 퍼소나를 분류할 수 있다. 퍼소나 분류부는 각각의 동작을 수행하기 위 하여, 제1 퍼소나 분류 동작 수행부, 제2 퍼소나 분류 동작 수행부 및 제어부를 포함할 수 있다. 제1 퍼소나 분류 동작 수행부는 복수의 퍼소나 속성에 대한 점수 산출 방식에 기초하여 퍼소나에서 상위 퍼소나로 분류되는 1차 퍼소나, 및 1차 퍼소나의 하위 퍼소나로 분류되는 2차 퍼소나를 분류하는 제1 퍼소나 분 류 동작을 수행할 수 있다. 다시 말해서, 제1 퍼소나 분류 동작은 복수의 질문에 포함된 복수의 문항 각각과 매 칭된 퍼소나 속성에 대한 점수를 산출하는 방식에 따라 퍼소나를 분류하는 동작으로 정의될 수 있다. 본 발명의 일 실시예에 있어서, 제1 퍼소나 분류 동작은 퍼소나 로직(logic)으로 칭해질 수도 있다. 제2 퍼소나 분류 동작 수행부는 인공지능 모델에 기반하여 1차 퍼소나, 2차 퍼소나 및 2차 퍼소나의 하위 퍼소나로 분류되는 3차 퍼소나를 분류하는 제2 퍼소나 분류 동작을 수행할 수 있다. 다시 말해서, 제2 퍼소나분류 동작은 인공지능 모델에 기반하여 퍼소나를 분류하는 동작으로 정의될 수 있다. 상술한 1차 퍼소나 내지 3차 퍼소나는 도 5에 도시된 바와 같은 관계를 가질 수 있다. 이를 보다 상세히 설명하 면, 1차 퍼소나는 1차 퍼소나 내지 3차 퍼소나 중 상위 퍼소나로 분류되며, 2차 퍼소나는 1차 퍼소나의 하위 퍼 소나로 분류되며, 3차 퍼소나는 2차 퍼소나의 하위 퍼소나로 분류될 수 있다. 여기서, 1차 퍼소나 및 2차 퍼소나는 제1 퍼소나 분류 동작에 따라 분류될 수 있다. 또한, 1차 퍼소나 내지 3차 퍼소나는 제2 퍼소나 분류 동작에 따라 분류될 수 있다. 즉, 인공 지능 모델 기반의 제2 퍼소나 분류 동작은 세 밀한 3차 퍼소나까지 분류할 수 있다. 제어부는 인공지능 모델의 정확도를 산출하고, 산출된 정확도에 따라 제1 퍼소나 분류 동작 및 제2 퍼소나 분류 동작 중 하나를 선택적으로 수행하도록 제1 퍼소나 분류 동작 수행부 및 제2 퍼소나 분류 동작 수행 부를 제어할 수 있다. 상술한 바와 같은 퍼소나 진단 정보 생성부는 퍼소나 매칭부를 더 포함할 수 있다. 퍼소나 매칭부는 상담사의 퍼소나 진단 정보를 조회하여 고객과 매칭에 필요한 정보를 호출할 수 있다. 이 후, 퍼소나 매칭부는 고객 퍼소나 진단 정보와 상담사의 퍼소나 진단 정보를 이용하여 고객의 퍼소나에 잘 맞는 상담사를 매칭 및 추천할 수 있다. 상술한 본 발명의 실시예들에 따르면, 퍼소나 로직 방식을 통해 정형적인 퍼소나의 분류가 가능하며, 인공지능 모델을 통해 세부적인 퍼소나의 분류도 가능하다. 특히, 인공지능 모델의 정확도를 산출하고 정확도에 따라 퍼 소나 로직 방식이나 인공지능 모델 방식을 선택적으로 사용함으로써 서로가 상호 보완적으로 퍼소나 분류에 사 용될 수 있다. 참여자 단말(310, 320)은 화상 미팅에 참여하는 단말이며, 네트워크를 통하여 화상 미팅 서버에 연결될 수 있다. 참여자 단말(310, 320)은 적어도 하나의 제1 참여자 단말 및 적어도 하나의 제2 참여자 단말을 포함할 수 있다. 제1 참여자 단말 및 제2 참여자 단말 중 하나, 예를 들면, 제1 참여자 단말은 화상 미팅을 통해 상담을 원하는 고객이 사용하는 단말일 수 있다. 고객이 사용하는 제1 참여자 단말은 네트워크를 통하여 화상 미팅 서버에 연결될 수 있는 컴퓨팅 장치로 구현될 수도 있다. 여기서, 컴퓨팅 장치는 네비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 또한, 제1 참여자 단말은 네트워크를 통하여 화상 미팅 서버에 연결될 수 있는 모바일 단말로 구현될 수도 있다. 여기서, 모바일 단말은 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 등과 같은 무선 통신 단말, 스마트폰(smartphone), 스마트 패드 (smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함 할 수 있다. 본 발명의 일 실시예에서는 제1 참여자 단말이 컴퓨팅 장치 또는 모바일 단말로 구현됨을 예로서 설명하였 으나, 이에 한정되는 것은 아니며, 네트워크를 통해 화상 미팅 서버에 연결되는 다양한 장치로 구현될 수 있다. 본 발명의 일 실시예에 있어서, 제1 참여자 단말에 연결된 카메라와 같은 제1 촬영 장치를 더 포함할 수 있다. 제1 촬영 장치는 화상 미팅에 참여하는 고객의 영상을 촬영할 수 있다. 제1 촬영 장치는 제 1 참여자 단말과 일체화된 형태로 구현될 수 있으나, 이에 한정되는 것은 아니다. 예를 들면, 제1 촬영 장 치는 제1 참여자 단말에 네트워크 방식 또는 유선 방식으로 연결되고 별도로 구비되는 형태로 구현될 수도 있다. 제1 참여자 단말 및 제2 참여자 단말 중 다른 하나, 예를 들면, 제2 참여자 단말은 화상 미팅을 통해 고객 상담을 진행하는 상담사의 단말일 수 있다. 상담사가 사용하는 제2 참여자 단말은 네트워크를 통하여 화상 미팅 서버에 연결될 수 있는 컴퓨팅 장치로 구현될 수도 있다. 여기서, 컴퓨팅 장치는 네비게 이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 또한, 제2 참여자 단말은 네트워크를 통하여 화상 미팅 서버에 연결될 수 있는 모바일 단말로 구현될 수도 있다. 여기서, 모바일 단말은 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 등과 같은 무선 통신 단말, 스마트폰(smartphone), 스마트 패드 (smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함 할 수 있다. 본 발명의 일 실시예에서는 제2 참여자 단말이 컴퓨팅 장치 또는 모바일 단말로 구현됨을 예로서 설명하였 으나, 이에 한정되는 것은 아니며, 네트워크를 통해 화상 미팅 서버에 연결되는 다양한 장치로 구현될 수 있다. 본 발명의 일 실시예에 있어서, 제2 참여자 단말에 연결된 카메라와 같은 제2 촬영 장치를 더 포함할 수 있다. 제2 촬영 장치는 화상 미팅에 참여하는 상담사의 영상을 촬영할 수 있다. 제2 촬영 장치는 제2 참여자 단말과 일체화된 형태로 구현될 수 있으나, 이에 한정되는 것은 아니다. 예를 들면, 제2 촬영 장치는 제2 참여자 단말에 네트워크 방식 또는 유선 방식으로 연결되고 별도로 구비되는 형태로 구현 될 수도 있다. 하기에서는 도 6을 참조하여, 퍼소나 분류부에 포함된 각 구성의 동작을 보다 상세히 설명한다. 도 6은 본 발명의 일 실시예에 따른 제1 퍼소나 분류 동작을 설명하기 위한 것이다. 도 6을 참조하면, 제1 퍼소나 분류 동작은 퍼소나 속성에 기반하여 수행되는 것이며, 퍼소나 속성은 상술한 복 수의 질문에 포함된 복수의 문항에 매칭될 수 있다. 다시 말해서, 복수의 질문 각각은 m(m은 자연수) 개의 문항 과 연결이 되어있으며, 문항은 k(k는 자연수) 개의 퍼소나 속성을 가질 수 있다. 퍼소나 속성은 질문에 대한 특 정 정보 및 연동되는 퍼소나 정보를 포함할 수 있다. 퍼소나 로직은 1차 퍼소나를 분류하는 동작 및 2차 퍼소나를 분류하는 동작을 포함할 수 있다. 제1 퍼소나 동작 수행부는 1차 퍼소나를 분류하기 위한 질문을 구성하고, 설문 수집부에 전달하고, 설문 수집부로부터 대응되는 선택 정보를 전달받을 수 있다. 또는, 2차 퍼소나를 분류하기 위한 질문을 구성하고, 설문 수집부에 전달하고, 설문 수집부로부터 대응되는 선택 정보를 전달받을 수 있다. 각각의 동작에서, 질문에 포함되는 문항이 서로 다 르게 구성될 수 있다. 퍼소나 로직을 퍼소나 분류부의 관점에서 설명하면, 제1 퍼소나 분류 동작 수행부는, 복수의 문항 중 에서 선택 정보에 따라 선택된 복수의 제1 선택 문항을 추출하고, 복수의 제1 선택 문항 각각에 매칭된 복수의 퍼소나 속성을 취합하여 퍼소나 별 점수를 산출하고, 산출된 퍼소나 별 점수가 가장 높은 퍼소나를 1차 퍼소나 로 분류할 수 있다. 예를 들면, 사용자가 특정 퍼소나와 연관된 퍼소나 속성이 매칭된 문항을 가장 많이 선택하 였을 경우, 해당 특정 퍼소나가 가장 높은 점수를 받을 수 있다. 이후, 제1 퍼소나 분류 동작 수행부는 복수의 문항 중에서 1차 퍼소나와 연관된 문항을 추출하고, 1차 퍼 소나와 연관된 문항에 기초하여 복수의 질문에 포함되는 2차 퍼소나 분류를 위한 재구성 질문을 생성할 수 있다. 제1 퍼소나 분류 동작 수행부는 1차 퍼소나와 연관된 문항 중에서 선택 정보에 따라 선택된 복수의 제2 선택 문항을 추출하고, 복수의 제2 선택 문항 각각에 매칭된 복수의 퍼소나 속성을 취합하여 퍼소나 별 점 수를 산출하고, 산출된 퍼소나 별 점수가 가장 높은 퍼소나를 2차 퍼소나로 분류할 수 있다. 상술한 제1 퍼소나 분류 동작과 달리, 제2 퍼소나 분류 동작은 인공지능 모델을 기반으로 수행되며, 특히 1차 퍼소나 및 2차 퍼소나뿐만 아니라 3차 퍼소나까지 분류가 가능하도록 구성될 수 있다. 제2 퍼소나 분류 동작 수행부에 의해 제2 퍼소나 분류 동작을 수행하는 인공지능 모델은, 예를 들면 선택 정보에 더하여, 분류를 위한 세부 정보(예를 들면, 사용자가 서버를 통해 이용하는 플랫폼에서 제공하는 컨텐츠 의 열람 로그, 플랫폼 내의 활동 로그, 사용자가 가입한 보험 종류 및 관심 보장 종류) 중 적어도 하나에 기초 하여 정의되는 퍼소나 별 데이터를 군집 알고리즘에 기초하여 1차 퍼소나, 2차 퍼소나 및 3차 퍼소나 중 적어도 하나를 분류하도록 구성될 수 있다. 여기서, 군집 알고리즘은 K-means 알고리즘, 평균 이동 알고리즘, 가우시안 분포 모델을 활용한 GMM(Gaussian Mixture model) 및 DBSCAN(Density Based Spatial Clustering ofApplications with Noise) 등을 포함할 수 있다. 인공지능 모델은 상술한 선택 정보 및 세부 정보를 훈련 데이터로 하는 학습 동작을 통해 학습될 수 있으며, 학 습에 따라 인공지능 모델의 분류 정확도는 증대될 수 있다. 예를 들면, 제2 퍼소나 분류 동작 수행부는 선 택 정보, 열람 로그, 활동 로그, 보험 종류 및 관심 보장 종류 중 적어도 하나를 훈련 데이터로 하고, 실제 클 래스를 라벨(label)로 하여 인공지능 모델을 학습시키는 학습 동작을 수행할 수 있다. 도 7a 내지 도 7d는 제2 퍼소나 분류 동작에 따른 퍼소나 분류의 예들이다. 도 7a 내지 도 7d와 같이, 3차 퍼소나의 경우 예를 들면 상술한 세부 정보에서 컨텐츠의 열람 로그에 기반하여 분류될 수 있으며, 컨텐츠의 열람 로그는 컨텐츠 별 태그와 매칭되어 있을 수 있다. 예를 들면, 재테크 태그, 소비라이프 태그를 주로 열어본 사람은 3차 퍼소나가 경제추구형으로 분류될 수 있다. 자기계발, 자기관리 태그, 커리어관리 태그를 주로 열어본 사람은 3차 퍼소나가 자기개발형으로 분류될 수 있다. 자녀교육 태그, 입시정보 태그를 주로 열어본 사람은 3차 퍼소나가 에듀형으로 분류돨 수 있다. 인생2라 운드 태그, 노후건강관리 태그를 주로 열어본 사람은 3차 퍼소나가 미래준비형으로 분류될 수 있다. 상술한 제1 퍼소나 분류 동작 및 제2 퍼소나 분류 동작에 따르면, 1차 퍼소나 및 2차 퍼소나 분류는 퍼소나 로 직을 기반으로 진단 및 결과까지 제시하게 되지만, 3차 퍼소나 분류를 할 때는 로직으로 진단을 하더라도 결과 는 인공지능 모델을 기반으로 자동 제시될 수 있다. 한편, 본 발명의 일 실시예에 있어서, 인공지능 모델의 학습을 위하여 제공되는 정보와 퍼소나 로직에 따라 퍼 소나를 분석하기 위하여 제공되는 정보는 서로 다를 수 있다. 즉, 퍼소나 로직에 따라 퍼소나를 분석하기 위하 여 제공되는 정보 중 일부 정보는 인공지능 모델의 학습을 위하여는 제공되지 않을 수 있다. 예를 들면, 매칭 이후 섬세한 financial planning(보험세일즈)을 위한 고객의 취미, 라이프관심사, 연봉, 필요 하다고 생각하는 보험보장 등 추가적인 메타 정보가 존재하는데, 인공지능 모델의 학습 시 이러한 메타정보는 제외하고 퍼소나 분석을 위한 정보만 추출하여 학습 진행하는 것이 가능할 수 있다. 상술한 제1 퍼소나 분류 동작 및 제2 퍼소나 분류 동작은, 제어부에 의해 선택적으로 수행될 수 있다. 구체적으로, 제어부는 제2 퍼소나 분류 동작을 위한 인공지능 모델의 정확도를 산출하는 것에 기초하여 어 느 하나의 동작을 선택할 수 있다. 정확도 산출을 위하여, 제어부는 제1 퍼소나 분류 동작에 따른 1차 퍼 소나 및 2차 퍼소나의 분류 결과를 실제 클래스로 설정하고, 제2 퍼소나 분류 동작에 따른 1차 퍼소나 및 2차 퍼소나의 분류 결과를 예측 클래스로 설정할 수 있다. 제어부는 설정한 예측 클래스가 실제 클래스와 일치하는지 여부에 기초하여 인공지능 모델의 정확도를 산 출한다. 도 8은 인공지능 모델의 정확도 산출 동작을 설명하기 위한 것이다. 도 8을 참조하면, 제어부는 인공지능 모델의 정확도를 산출하기 위하여 recall, precision, f1 score, auc 방식 등을 사용할 수 있다. 예를 들면, f1 score 방식이 사용되는 경우, 도 8에 기초하여 정확도가 산출될 수 있다. 도 8에 도시된 바와 같이, True Positive(TP)는 실제 True인 정답을 True라고 예측(정답)한 것이고, False Positive(FP)는 실제 False인 정답을 True라고 예측(오답)한 것이며, False Negative(FN)는 실제 True인 정답을 False라고 예측(오답)한 것이고, True Negative(TN)는 실제 False인 정답을 False라고 예측(정답)한 것 이다. 제어부는, 산출한 인공지능 모델의 정확도가 기 설정된 임계값 이상이면 제2 퍼소나 분류 동작 수행부 가 제2 퍼소나 분류 동작을 수행하도록 제어하고, 인공지능 모델의 정확도가 기 설정된 임계값 미만이면 제1 퍼소나 분류 동작 수행부가 제1 퍼소나 분류 동작을 수행하도록 제어한다. 즉, 초기에는 퍼소나에 대 하여 인공지능 모델이 학습이 안 되어 있으므로, 퍼소나 분류부는 퍼소나 로직 기반의 제1 퍼소나 분류 동 작에 따라 퍼소나를 분류한다. 퍼소나 분류부는 퍼소나 로직으로 분석한 정보(예, 실제 클래스)를 인공지 능 모델에서 학습을 시키고 지속적인 인공지능 모델 학습을 통하여 사용자의 세부 퍼소나 정보를 분석하고 초기 에 분류되는 퍼소나 보다 인공지능 모델 기반의 분석을 통한 세밀한 퍼소나(예, 3차 퍼소나)를 분류할 수 있다.이후, 퍼소나 분류 서버는 분류가 완료된 퍼소나 정보를 별도의 데이터베이스(DB)에 저장할 수 있다. 또한, 일 실시예에 따르면, 제어부는 배치(batch) 동작에 기초하여 제2 퍼소나 분류 동작 수행부가 인공지능 모델에 대한 학습 동작을 수행하도록 제어할 수 있다. 배치 동작은 기 설정된 주기 마다 제2 퍼소나 분류 동작 수행부가 학습 동작을 수행하도록 정의된다. 따라서, 제어부는 제2 퍼소나 분류 동작 수행 부가 기 설정된 주기마다 학습 동작을 수행하도록 제어할 수 있다. 학습 동작은 상술한 바와 같이 제2 퍼소나 분류 동작 수행부가 선택 정보, 열람 로그, 활동 로그, 기 보험 종류 및 관심 보장 종류 중 적어도 하나를 훈련 데이터로 하고, 실제 클래스를 라벨로 하여 기 인공지능 모델을 학습시키도록 정의될 수 있다. 상술한 본 발명의 다른 일 실시예에서와 같이, 퍼소나 로직과 인공지능 모델에 기반한 퍼소나 분류 동작에 따라 1차 퍼소나 내지 3차 퍼소나가 분류될 수 있으며, 이때 1차 퍼소나 내지 3차 퍼소나 중 적어도 두 개는 상술한 일반 소비자 퍼소나 및 개별 소비자 퍼소나에 대응될 수도 있다. 즉, 상술한 일반 소비자 퍼소나 및 개별 소비 자 퍼소나는 상술한 바와 같이 행렬 기반으로 분류될 수 있을 뿐만 아니라, 퍼소나 로직과 인공지능 모델에 기 반하여 분류될 수도 있다. 상술한 퍼소나 분류 서버에 포함된 구성에 더하여, 퍼소나 분류 서버는 매칭부를 더 포함할 수 있 다. 매칭부는 상담사의 퍼소나 정보를 조회하여 사용자, 즉 고객과 매칭에 필요한 정보를 호출할 수 있다. 이 후, 매칭부는 고객 퍼소나 정보와 상담사의 퍼소나 정보를 이용하여 고객에 퍼소나에 잘 맞는 상담사를 매 칭 및 추천할 수 있다. 상술한 본 발명의 실시예들에 따르면, 퍼소나 로직 방식을 통해 정형적인 퍼소나의 분류가 가능하며, 인공지능 모델을 통해 세부적인 퍼소나의 분류도 가능하다. 특히, 인공지능 모델의 정확도를 산출하고 정확도에 따라 퍼 소나 로직 방식이나 인공지능 모델 방식을 선택적으로 사용함으로써 서로가 상호 보완적으로 퍼소나 분류에 사 용될 수 있다. 하기에서는 도 9 내지 도 10을 참조하여, 도 1 내지 도 8에 도시된 퍼소나 기반의 아바타 매칭 화상 미팅 시스 템의 동작 방법을 설명한다. 도 9는 본 발명의 일 실시예에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법을 설명하기 위한 도면이며, 도 10은 도 9에 도시된 영상 정보 분석 단계를 설명하기 위한 도면이며, 도 11 내지 도 19는 본 발명 의 일 실시예에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 작동에 따른 참여자 단말에 표시되는 화면 을 설명하기 위한 도면이다. 도 9 내지 도 19를 참조하면, 본 발명의 일 실시예에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법은 퍼소나 진단 정보 생성 단계(S110), 아바타 생성 단계(S120), 영상 정보 분석 단계(S130), 아바타 이미 지 및 안면 좌표 맵핑 단계(S140), 좌표 일치 판단 단계(S150), 아바타 이미지 이동 단계(S160), 배경 노출 판 단 단계(S170), 3D 가상 공간 생성 단계(S180), 아바타 영상 정보 생성 단계(S190), 아바타 영상 정보 출력 단 계(S200), 및 화상 미팅 연결 단계(S210)를 포함할 수 있다. 상술한 바와 같은 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법은 참여자의 안면이 타 참여자에게 노출되는 것을 방지할 수 있다. 우선, 퍼소나 진단 정보 생성 단계(S110) 이전에, 퍼소나 진단 정보 생성부의 인증부는 제1 참여자 단말 및 제2 참여자 단말과 상호 작용하여 회원 가입 동작 및 로그인을 통해 인증 동작을 수행할 수 있다. 예를 들면, 인증부는 제1 참여자 단말 및 제2 참여자 단말에 도 11에 도시된 바와 같은 로그인 화면을 제공하고, 고객 및 상담사가 회원 가입 및 로그인을 수행하도록 할 수 있다. 여기서, 상담사는 별도의 회원 가입을 수행하지 않을 수도 있다. 그런 다음, 고객은 자신이 필요로 하는 상품 또는 서비스를 선택할 수 있다. 예를 들면, 고객은 자신이 필요로 하는 제품 또는 서비스를 선택할 수 있으며, 고객이 선택한 제품의 구매 현황 또는 서비스의 예약 상황은 도 12a 및 도 12b에 도시된 바와 같이 표시될 수 있다. 고객은 자신이 선택한 상품 또는 서비스의 문의 사항 또는 예약 상황과 같은 상담을 판매자 또는 서비스 제공자 에게 문의할 수 있으며, 이러한 문의는 상담 예약을 통하여 수행될 수 있다. 상담 일정과 관련된 내용은 도 13 에 도시된 바와 같이 표시될 수 있다. 또한, 상담사는 고객의 상담 요청에 의한 상담 예약 일정을 확인할 수 있으며, 상담 예약 일정과 관련된 정보는 도 14a 및 도 14b에 도시된 바와 같이 표시될 수 있다. 퍼소나 진단 정보 생성 단계(S110)에서는, 퍼소나 진단 정보 생성부가 제1 참여자 단말 및 제2 참여 자 단말에서 입력된 참여자 정보를 통하여 고객 및 상담사와 같은 참여자에게 적합한 퍼소나를 생성 또는 결정하여, 퍼소나 진단 정보를 생성할 수 있다. 또한, 퍼소나 매칭부는 상담사의 퍼소나 진단 정보를 조회 하여 고객과 매칭에 필요한 정보를 호출할 수 있다. 이후, 퍼소나 매칭부는 고객 퍼소나 진단 정보와 상담 사의 퍼소나 진단 정보를 이용하여 고객의 퍼소나에 잘 맞는 상담사를 매칭 및 추천할 수 있다. 아바타 생성 단계(S120)에서는, 아바타 생성부가 퍼소나 진단 정보 생성부에서 생성된 고객 및 상담 사의 퍼소나 진단 정보에 기반하여 적어도 하나의 아바타를 생성할 수 있다. 아바타 생성부는 생성된 아바 타를 참여자 단말(310, 320)로 전송하고, 고객 및 상담사 각각은 원하는 아바타를 선택할 수 있다. 여기서, 아 바타는 참여자의 안면에 대응할 수 있는 3D 모델링된 아바타 이미지일 수 있다. 고객의 아바타는 도 15a에 도시 된 바와 같이 표시되고, 상담사의 아바타는 도 15b에 도시된 바와 같이 표시될 수 있다. 영상 정보 분석 단계(S130)에서는, 제1 촬영 장치 및 제2 촬영 장치에서 촬영된 참여자의 안면 정보 를 포함하는 영상 정보를 수신하고, 수신한 영상 정보를 AI와 같은 인공 지능을 이용하여 분석하여 참여자 안면 의 좌표 정보를 추출할 수 있다. 이를 보다 상세히 설명하면, 영상 정보 분석 단계(S130)는 영상 정보 수신 단계(S131), 프레임 영상 분석 단계 (S132), 및 안면 좌표 정보 추출 단계(S133)를 포함할 수 있다. 연상 정보 수신 단계(S131)에서는, 화상 미팅 서버의 영상 정보 수신부가 제1 촬영 장치 및 제2 촬영 장치에서 촬영된 참여자의 안면 정보를 포함하는 영상 정보를 수신하고 저장할 수 있다. 프레임 영상 분석 단계(S132)에서는, 화상 미팅 서버의 영상 정보 분석부가 영상 정보 수신부에 서 수신한 영상 정보를 AI와 같은 인공 지능을 이용하여 프레임 단위로 분석함으로써, 화상 미팅에 참여하는 참 여자의 안면 정보를 추출할 수 있다. 예를 들면, 화상 미팅 서버의 영상 정보 분석부는 영상 정보 수 신부에서 수신한 영상 정보를 프레임 정보를 추출할 수 있다. 그런 다음, 영상 정보 분석부는 각 프 레임 정보에서 참여자의 안면을 인식하고, 안면 형태를 안면 정보로 추출할 수 있다. 안면 좌표 정보 추출 단계(S133)에서는, 영상 정보 분석부가 추출된 안면 정보를 AI와 같은 인공 지능을 이용하여 분석함으로써, 참여자 안면의 각 지점을 좌표화된 안면 정보로 추출할 수 있다. 여기서, 좌표화된 안 면 정보는 참여자 안면의 3D 좌표 정보로, 안면 정보 내의 각 지점은 (x,y,z)와 표현될 수 있는 3D 좌표로 추출 될 수 있다. 즉, 영상 정보 분석부는 영상 정보 수신부에서 수신한 영상 정보를 분석하여 3D 좌표화 된 참여자의 안면 정보를 추출할 수 있다. 아바타 이미지 및 안면 좌표 맵핑 단계(S140)에서는, 안면 맵핑부가 아바타 생성부에서 생성되고 선 택된 아바타의 3D 모델링된 이미지를 촬영 장치(410, 420)에서 촬영된 영상 정보 내의 안면에 맵핑시킬 수 있다. 여기서, 안면 맵핑부는 3D 좌표화된 안면 정보를 이용하여, 아바타의 3D 모델링된 이미지와 영상 정 보 내의 안면을 맵핑시킬 수 있다. 아바타의 3D 모델링된 이미지와 영상 정보 내의 안면이 맵핑되면, 화상 미팅 참여자의 안면 노출이 방지될 수 있다. 좌표 일치 판단 단계(S150)에서는, 아바타 이미지 및 안면 좌표 맵핑 단계(S140)에서 수행된 맵핑의 결과물에서, 아바타의 3D 모델링된 이미지와 3D 좌표화된 안면 정보가 일치하는지 판단할 수 있다. 아바타 이미지 이동 단계(S160)에서는, 좌표 일치 판단 단계(S150)에서 아바타의 3D 모델링된 이미지와 3D 좌표 화된 안면 정보가 일치하지 않는 것으로 판단되면, 아바타 영상 생성부의 3D 모델 컨트롤러가 아바타 의 3D 모델링된 이미지를 이동시킬 수 있다. 여기서, 아바타의 3D 모델링된 이미지와 3D 좌표화된 안면 정보가 일치할 때까지, 3D 모델 컨트롤러는 아바타의 3D 모델링된 이미지를 이동시킬 수 있다. 배경 노출 판단 단계(S170)에서는, 아바타의 3D 모델링된 이미지와 3D 좌표화된 안면 정보가 일치하는 경우, 촬 영 장치(410, 420)에서 촬영된 영상 정보 내의 배경이 노출될 필요가 있는지 판단할 수 있다. 3D 가상 공간 생성 단계(S180)에서는, 배경 노출 판단 단계(S170)에서 배경의 노출이 불필요한 것으로 판단되면, 아바타 영상 생성부의 3D 가상 공간 생성부가 참여자의 안면 정보 이외의 배경을 가상의 3D 공간으로 변경시킬 수 있다. 참여자의 안면 정보 이외의 배경을 가상의 3D 공간으로 변경되면, 촬영 장치 (410, 420)에서 촬영된 영상 정보에서 배경 노출이 방지될 수 있다. 아바타 영상 정보 생성 단계(S190)에서, 아바타 영상 생성부는 촬영 장치(410, 420)에서 촬영된 영상 정보 내에 아바타 이미지가 포함되는 아바타 영상을 생성할 수 있다. 또한, 아바타 영상 생성부는 필요에 따라 참여자의 안면 정보 이외의 배경을 가상의 3D 공간으로 변경된 아바타 영상을 생성할 수도 있다. 아바타 영상 정보 출력 단계(S200)에서는, 아바타 영상 출력부가 아바타 영상 생성부에서 생성된 아 바타 영상을 제1 참여자 단말 및 제2 참여자 단말로 출력할 수 있다. 여기서, 고객의 단말인 제1 참 여자 단말에서 구현되는 아바타 영상은 도 16a에 도시된 바와 같이 표시될 수 있다. 즉, 물품 및 서비스를 구매하고자 하는 고객의 참여자 단말(310, 320)에는 상담사의 안면 위치에 아바타가 중첩된 상담사의 아바타 영 상이 제공될 수 있다. 따라서, 고객은 상담사에게 자신의 안면이 노출될 우려가 해소될 수 있다. 또한, 상담사의 단말인 제2 참여자 단말에서 구현되는 아바타 영상은 도 16b에 도시된 바와 같이 표시될 수 있다. 즉, 상담사의 참여자 단말(310, 320)에는 고객의 안면 위치에 아바타가 중첩된 고객의 아바타 영상이 제공될 수 있다. 따라서, 상담사는 고객에게 자신의 안면이 노출될 우려가 해소될 수 있다. 화상 미팅 연결 단계(S210)에서, 화상 미팅 서버는 고객과 상담사의 화상 미팅이 진행될 수 있는 화상 미 팅룸의 링크를 생성할 수 있다. 화상 미팅룸의 링크는 화상 미팅을 위한 웹 브라워저의 특정 주소 정보를 포함 하며, 제1 참여자 단말 및 제2 참여자 단말에 전달될 수 있다. 이를 보다 상세히 설명하면, 상담사는 도 17a에 도시된 바와 같은 제2 참여자 단말의 화면을 통하여 화상 미팅 서버에 화상 미팅룸 링크의 생성을 요청하고, 화상 미팅 서버는 도 17b와 같은 화면을 제2 참여자 단말에 표시하여 화상 미팅룸 링크를 제1 참여자 단말에 전달하도록 하며, 화상 미팅 서버는 도 17c에 도시된 바와 같이 생성된 화 상 미팅룸 링크를 통한 미팅룸 입장 요청을 고객의 제1 참여자 단말에 표시할 수 있다. 제1 참여자 단말 및 제2 참여자 단말은 상술한 화상 미팅룸의 링크를 통하여 화상 미팅 서버가 제공하는 화상 미팅룸에 입장할 수 있다. 제1 참여자 단말 및 제2 참여자 단말을 통하여 고객 및 상담사가 화상 미팅룸에 입장하면, 화상 미팅 을 진행할 수 있다. 만약 고객 및 상담사 중 일측이 화상 미팅룸에 입장하기 전이라면, 화상 미팅룸에 입장한 참여자 단말(310, 320)에는 도 18에 도시된 바와 같은 화면이 표시될 수 있다. 화상 미팅 중, 고객 및 상담사는 도 19a에 도시된 바와 같은 파일 불러 오기 기능을 통하여 상대방에게 필요한 정보를 제공할 수 있으며, 도 19b에 도시된 바와같은 채팅 기능을 통하여 상대방에게 문의 또는 답변을 전달할 수 있다. 본 발명은 상기에서 설명된 실시예로 한정되지 않으며, 상기 실시예들 중 적어도 둘 이상을 조합한 것이나 상기 실시예들 중 적어도 어느 하나와 공지기술을 조합한 것을 새로운 실시예로 포함할 수 있음은 물론이다. 이상 본 발명을 구체적인 실시예를 통하여 상세히 설명하였으나, 이는 본 발명을 구체적으로 설명하기 위한 것으로, 본 발명은 이에 한정되지 않으며, 본 발명의 기술적 사상 내에서 당해 분야의 통상의 지식을 가진 자에 의해 그 변형이나 개량이 가능함은 명백하다고 할 것이다. 본 발명의 단순한 변형 내지 변경은 모두 본 발명의 영역에 속하는 것으로 본 발명의 구체적인 보호 범위는 첨 부된 특허청구범위에 의하여 명확해질 것이다."}
{"patent_id": "10-2023-0048938", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템을 설명하기 위한 도면이다. 도 2는 도 1에 도시된 화상 미팅 서버의 구성을 설명하기 위한 도면이다. 도 3은 도 2에 도시된 아바타 영상 생성부를 설명하기 위한 도면이다. 도 4는 도 1에 도시된 퍼소나 진단 정보 생성부의 구성을 설명하기 위한 도면이다. 도 5는 1차 퍼소나, 2차 퍼소나 및 3차 퍼소나를 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시예에 따른 제1 퍼소나 분류 동작을 설명하기 위한 도면이다. 도 7a 내지 도 7d는 제2 퍼소나 분류 동작에 따른 퍼소나 분류의 예들이다. 도 8은 인공지능 모델의 정확도 산출 동작을 설명하기 위한 것이다. 도 9는 본 발명의 일 실시예에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 동작 방법을 설명하기 위한 도면이다. 도 10은 도 9에 도시된 영상 정보 분석 단계를 설명하기 위한 도면이다. 도 11 내지 도 19는 본 발명의 일 실시예에 따른 퍼소나 기반의 아바타 매칭 화상 미팅 시스템의 작동에 따른 참여자 단말에 표시되는 화면을 설명하기 위한 도면이다."}
