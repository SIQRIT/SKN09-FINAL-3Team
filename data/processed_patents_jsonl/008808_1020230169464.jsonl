{"patent_id": "10-2023-0169464", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0152205", "출원번호": "10-2023-0169464", "발명의 명칭": "레이턴시 프로세싱 유닛", "출원인": "주식회사 하이퍼엑셀", "발명자": "김정훈"}}
{"patent_id": "10-2023-0169464", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 모델을 구현하는 복수의 파티션들 중 적어도 하나의 파티션을 위한 행렬 곱 연산을 수행하는 복수의MAC(Multipliers-Accumulators) 트리; 및상기 복수의 MAC 트리 각각을 상기 적어도 하나의 파티션이 저장된 고대역 메모리와 복수의 채널을 통해 연결시키는 간소화 메모리 액세스를 포함하고,상기 복수의 MAC 트리 각각은 상기 고대역 메모리의 복수의 채널과 일대일로 대응하여 연결되는 것을 특징으로하는 레이턴시 프로세싱 유닛."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "레이턴시 프로세싱 유닛이 제공된다. 일실시예에 따른 레이턴시 프로세싱 유닛은 인공지능 모델을 구현하는 복 수의 파티션들 중 적어도 하나의 파티션을 위한 행렬 곱 연산을 수행하는 복수의 MAC(Multipliers- Accumulators) 트리, 상기 복수의 MAC 트리 각각을 상기 적어도 하나의 파티션이 저장된 고대역 메모리와 복수의 채널을 통해 연결시키는 간소화 메모리 액세스, 상기 복수의 MAC 트리의 연산 결과에 대해 추가적인 연산을 수행 하는 벡터 실행 엔진, 상기 벡터 실행 엔진의 연산 결과 및 활성화 값을 저장하는 로컬 메모리 유닛 및 상기 복 수의 MAC 트리와 상기 벡터 실행 엔진의 연산을 스케쥴링하는 명령어 스케줄링 유닛을 포함할 수 있다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은 레이턴시 프로세싱 유닛에 관한 것으로, 더욱 구체적으로는 간소화 메모리 액세스 (Streamlined Memory Access) 및 간소화 실행 엔진(Streamlined eXecution Engine)을 통하여 외부 메모리 대역 폭 사용을 극대화함으로써 초거대 인공지능 모델의 연산을 위한 연산 처리량 및 지연시간을 최적화할 수 있는 레이턴시 프로세싱 유닛에 관한 것이다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 기계 학습 기술이 발전함에 따라 인공지능 애플리케이션의 적용 범위가 늘어나고 있다. 이러한 인공지능 모델은 더 높은 정확도를 얻기 위하여 다양하고 복잡한 연산들을 요구하며 모델의 크기가 점차 커져 초거대 인 공지능 모델이 등장하고 있다. 이에 따라, 이런 초거대 인공지능 모델을 처리하는 가속기의 중요성이 대두된다. 특히 인공지능 번역기, 챗봇 등과 같은 자연어 처리 애플리케이션들은 어텐션(attention) 연산을 사용하는 트랜 스포머 모델 기반의 생성 모델을 주로 사용한다. 트랜스포머 모델 기반의 생성 모델들은 시간에 종속성을 가지 며 주로 사용하는 어텐션 연산은 각 연산 사이의 종속성을 가지기 때문에 해당 모델을 병렬화하여 가속하는데 어려움이 있다. 또한 이런 생성 모델을 사용하는 애플리케이션들은 실시간 서비스가 매우 중요하기 때문에 연 산 처리량뿐만 아니라 지연시간 역시 매우 중요하다. 하지만 기존의 GPU(Graphics Processing Unit) 같이 데이터 병렬성을 이용하여 연산 처리량을 극대화한 하드웨 어 가속기들은 초거대 인공지능 모델을 사용하는 애플리케이션 가속을 처리하기에는 적합하지 않다. 또한 초거 대 인공지능 모델들은 데이터의 크기가 매우 크기 때문에 기존의 하드웨어 가속기 구조에서는 데이터 병목현상 이 발생할 수도 있다. 따라서 초거대 인공지능 모델을 가속하기 위해 새로운 하드웨어 가속기 구조가 필요하다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "간소화 메모리 액세스(Streamlined Memory Access) 및 간소화 실행 엔진(Streamlined eXecution Engine)을 통 하여 외부 메모리 대역폭 사용을 극대화함으로써 초거대 인공지능 모델의 연산을 위한 연산 처리량 및 지연시간 을 최적화할 수 있는 레이턴시 프로세싱 유닛을 제공할 수 있다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "인공지능 모델을 구현하는 복수의 파티션들 중 적어도 하나의 파티션을 위한 행렬 곱 연산을 수행하는 복수의 MAC(Multipliers-Accumulators) 트리; 상기 복수의 MAC 트리 각각을 상기 적어도 하나의 파티션이 저장된 고대 역 메모리와 복수의 채널을 통해 연결시키는 간소화 메모리 액세스; 상기 복수의 MAC 트리의 연산 결과에 대해 추가적인 연산을 수행하는 벡터 실행 엔진; 상기 벡터 실행 엔진의 연산 결과 및 활성화 값을 저장하는 로컬 메 모리 유닛; 및 상기 복수의 MAC 트리와 상기 벡터 실행 엔진의 연산을 스케쥴링하는 명령어 스케줄링 유닛을 포 함하는 레이턴시 프로세싱 유닛을 제공한다. 일측에 따르면, 상기 복수의 MAC 트리 각각은 상기 고대역 메모리의 복수의 채널과 일대일로 대응하여 연결되는 것을 특징으로 할 수 있다. 다른 측면에 따르면, 상기 간소화 메모리 액세스는, 상기 복수의 MAC 트리와 상기 고대역 메모리 사이의 읽기 인터페이스만을 구성하고, 상기 로컬 메모리 유닛과 상기 고대역 메모리 사이의 쓰기 인터페이스만을 구성하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 로컬 메모리 유닛은, 상기 고대역 메모리로부터 활성화 값과 모델 매개변수를 읽 어와 상기 복수의 MAC 트리 및 상기 벡터 실행 엔진으로 전달하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 로컬 메모리 유닛은, 상기 복수의 MAC 트리 각각에 동일한 활성화 값을 복사하여 전달하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 고대역 메모리에는, 가중치 행렬이 열 방향으로 상기 복수의 MAC 트리의 개수만큼 상기 복수의 채널에 매핑되도록 저장되는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 명령어 스케줄링 유닛은, 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러 및 다중 뱅크 버퍼 주소 상태 테이블을 포함하고, 상기 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러는 상 기 다중 뱅크 버퍼 주소 상태 테이블에 저장된 명령어의 연산자 주소 및 결과 주소를 참조하여 상기 복수의 MAC 트리와 상기 벡터 실행 엔진의 명령어의 종속성을 판단하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 레이턴시 프로세싱 유닛은 호스트 컴퓨터로부터 명령어, 입력값 및 가중치 중 적 어도 하나를 입력받기 위해, 상기 호스트 컴퓨터와의 상기 레이턴시 프로세싱 유닛을 연결하는 PCIe(Peripheral Component Interconnect express) 인터페이스를 더 포함할 수 있다. 또 다른 측면에 따르면, 상기 레이턴시 프로세싱 유닛은 상기 복수의 파티션들 중 각기 다른 적어도 하나의 파 티션에 대응되는 복수의 레이턴시 프로세싱 유닛들과의 연결을 위한 P2P(Peer to Peer) 인터페이스를 더 포함할 수 있다. 또 다른 측면에 따르면, 상기 레이턴시 프로세싱 유닛은 상기 고대역 메모리의 내부에서 연산 가능한 PIM(Processing-in-memory) 구조의 칩으로 구현되는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 레이턴시 프로세싱 유닛은 상기 복수의 파티션들이 각각 저장된 복수의 고대역 메 모리들에 대해 연산 가능한 PNM(Processing-near-memory) 구조의 버퍼 칩으로 구현되는 것을 특징으로 할 수 있 다. 또 다른 측면에 따르면, 상기 복수의 MAC 트리는 상기 고대역 메모리의 내부에서 연산 가능한 PIM 구조의 칩에 구현되고, 상기 간소화 메모리 액세스, 상기 벡터 실행 엔진, 상기 로컬 메모리 유닛 및 상기 명령어 스케줄링 유닛은 상기 복수의 파티션들이 각각 저장된 복수의 고대역 메모리들에 대해 연산 가능한 PNM 구조의 버퍼 칩에 구현되는 것을 특징으로 할 수 있다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "간소화 메모리 액세스(Streamlined Memory Access) 및 간소화 실행 엔진(Streamlined eXecution Engine)을 통 하여 외부 메모리 대역폭 사용을 극대화함으로써 초거대 인공지능 모델의 연산을 위한 연산 처리량 및 지연시간 을 최적화할 수 있다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 하나의 구성 요소가 다른 구성 요소와 \"연결된(connected to)\" 또는 \"커플링된(coupled to)\" 이라고 지칭되는 것은, 다른 구성 요소와 직접 연결 또는 커플링된 경우 또는 중간에 다른 구성 요소를 개재한 경우를 모두 포함 한다. 반면, 하나의 구성 요소가 다른 구성 요소와 \"직접 연결된(directly connected to)\" 또는 \"직접 커플링된 (directly coupled to)\"으로 지칭되는 것은 중간에 다른 구성 요소를 개재하지 않은 것을 나타낸다. \"및/또는\" 은 언급된 아이템들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성 요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 비록 제1, 제2 등이 다양한 구성 요소들을 서술하기 위해서 사용되나, 이들 구성 요소들은 이들 용어에 의해 제 한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성 요소를 다른 구성 요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성 요소 일 수도 있 음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 도 1은 본 발명의 실시예에 따른 레이턴시 프로세싱 유닛의 구조의 예를 도시한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 LPU(레이턴시 프로세싱 유닛(Latency Processing Unit), 100)은 SMA(간소화 메모리 액세스(Streamlined Memory Access), 110), OIU(피연산자 발행 유닛(Operand Issue Unit), 120), SXE(간소화 실행 엔진(Streamlined eXecution Engine), 130), VXE(벡터 실행 엔진(Vector eXecution Engine), 140), LMU(로컬 메모리 유닛(Local Memory Unit)), 150), ISU(명령어 스케줄링 유닛(Instruction Scheduling Unit)), 160), PCIe 인터페이스(PCIe(Peripheral Component Interconnect express) Interface, 170), P2P 인터페이스(P2P(Peer to Peer) Interface, 180)를 포함할 수 있다. SMA는 특수 DMA(Direct Memory Access)일 수 있다. 일례로, SMA는 HBM의 모든 채널(일례로, 32개)을 실행 엔진(일례로, SEE)에 연결하여 최대 대역폭에서 FP16(half precision floating point) 데이 터를 전송할 수 있다. SMA는 사전 로드된 메모리(MEM) 명령어를 기반으로 연속 메모리 요청을 전송하기 위해 심층 FIFO(First In First Out)로 설계될 수 있다. 하드웨어를 고려한 메모리 매핑은 행렬의 변경 혹은 전치 작업을 제거함으로써 지연시간을 단축시킬 수 있다. 따라서 SMA는 최대 버스트 크기로 수신된 데이 터를 최소한의 지연으로 실행 엔진으로 스트리밍할 수 있다. SMA는 또한 스트로브(strobe) 신호를 사용하 여 행렬의 전치(transpose)를 효율적으로 실행할 수 있다. 스트리밍 데이터는 벡터 매트릭스 실행(예: 가중치, 편향) 및 기타 벡터 관련 실행(예: 감마/베타, 임베딩)을 위한 매개변수를 포함할 수 있다. OIU는 실행 엔진에 발행하기 전에 SMA에서 스트리밍된 데이터(일례로, 제1 피연산자)와 온칩 메모리 에서의 입력(일례로, 제2 피연산자)을 조정할 수 있다. 실행(EXE) 명령을 기반으로 OIU는 실행 엔진을 구 성하고 피연산자의 대상 엔진을 결정하는 마이크로코드를 생성할 수 있다. 또한 OIU에는 정적 피연산자 (예: 입력 벡터)의 읽기 대기 시간을 제거하기 위해 재사용 버퍼가 배치되고 스칼라(예: 바이어스)로 사용되는 벡터화된 데이터를 유지하기 위해 비대칭 버퍼가 배치될 수 있다. 따라서 적절한 피연산자는 거의 항상 프리페 치되어 실행 엔진에 즉시 발행될 준비가 된다. SXE는 LPU의 주요 컴퓨팅 하드웨어로서, 어텐션, 1D 컨볼루션, 피드포워드 네트워크와 같은 벡터-매 트릭스 곱셈(vector-matrix multiplication, V·M)을 실행하기 위해 들어오는 대역폭을 최대한 활용하도록 설계 될 수 있다. SXE는 HBM의 수신 대역폭과 연산 대역폭을 일치시킬 수 있는 수의 MAC(Multiply- Accumulate) 트리(MAC Tree, 131)를 포함할 수 있다. 예를 들어, HBM으로부터 매 사이클마다 1024개의 요소를 수신한다면 64개의 입력 벡터를 가진 MAC 트리 16개를 통해 수신 대역폭과 연산 대역폭을 일치시킬 수 있다. 그리고 64개의 입력 벡터를 가진 MAC 트리는 64개의 곱셈기와 63개의 덧셈기로 구성될 수 있다. 복수의 MAC 트리는 행렬 곱 연산을 수행할 수 있으며, 외부 메모리인 고대역 메모리인 HBM과 SMA를 통해 채널별로 연결될 수 있다. 구체적으로, 복수의 MAC 트리 중 하나는 하나의 채널을 통해 HBM과 연결됨으로써 LPU와 HBM 사이의 전송 대역폭을 극대화하며 초거대 인공지능 모델에 필요 한 행렬 곱 연산을 병목현상 없이 수행할 수 있다. 따라서 복수의 MAC 트리의 개수와 HBM의 메모리 채널의 개수는 동일하게 구성될 수 있다. 복수의 MAC 트리의 행렬 곱 연산 결과는 VXE으로 제공될 수 있다. VXE는 사용자 지정 저지연 ALU(Arithmetic Logic Unit)를 사용하여 구현될 수 있으며, 토큰 임베딩, 소프트맥스, 정규화 및 잔차 연산과 같은 벡터 작업을 실행할 수 있다. 이러한 벡터 작업은 상대적으로 덜 자주 발생하므로 OIU에서 이 경로 로의 팬인(fan-in)을 조정하여 무시할 수 있는 성능 손실로 하드웨어 리소스를 줄일 수 있다. VXE는 복수 의 MAC 트리의 연산 결과를 제공받는 한편 LMU로부터 활성화 값을 전달받아 후속 연산을 수행할 수 있다. VXE는 복수의 다기능 연산 데이터패스를 포함함으로써 다양한 연산기 조합을 포함하도록 구성될 수 있다. LMU는 복수의 MAC 트리와 VXE으로 활성화 값을 전달할 수 있다. 이때 LMU는 복수의 MAC 트리에 대하여 동일한 활성화 값을 전달하기 위하여 활성화 값을 복사하여 전송할 수 있다. 또한, LMU는 복수의 MAC 트리와 VXE이 연산한 결과값을 저장할 수 있다. 다시 말해, LMU는 HBM에 대응하는 내부 버퍼로서 LPU 내에서 기능할 수 있다. 이때 LPU는 행렬 곱셈 연산에 있어 서 재사용율이 높은 활성화 값 또는 모델의 매개변수를 LMU에 저장하고 재사용율이 낮은 가중치를 HBM에 저장할 수 있다. LMU는 입력, 출력 및 중간 데이터의 빠른 고대역폭 액세스를 위해 스칼라 벡 터 분리가 있는 4MB 다중 뱅크 레지스터 파일로 구현될 수 있다. 또한 LMU는 OIU와 실행 엔진의 쓰 기 저장 단계에서 동시 읽기 및 쓰기를 지원하는 다중 포트일 수 있다. ISU는 LPU의 전체 실행 흐름을 제어할 수 있다. ISU는 PIC(Parallel Instruction Chaining) 방식을 이용할 수 있으며, 명령어 체이닝을 사용하면 종속 명령어를 연속적으로 실행할 수 있다. PIC는 독립적 인 하드웨어가 필요한 명령을 종속 명령의 그룹(예: 메모리(MEM) 명령, 실행(EXE) 명령, 네트워크(NET) 명령)으 로 분리하므로 모든 명령이 각 그룹의 명령 체인과 병렬로 실행되어 낮은 제어 오버헤드 및 대기 시간 절약을 달성할 수 있다. ISU는 또한 엔진 실행을 위해 제어 레지스터(예: 토큰 및 계층 번호)를 업데이트할 수 있다. 내부 스케줄러는 하드웨어 활용도를 최대화하기 위해 SXE 및 VXE의 비순차적 실행을 지원하며 강력한 스코어보드는 데이터 위험을 처리하도록 설계될 수 있다. 예를 들어, ISU는 복수의 MAC 트리(13 1)와 VXE가 동시에 연산을 수행할 수 있도록 스케쥴링할 수 있다. 또한 ISU는 병렬 연산을 최대화하 기 위해 종속성이 없는 명령어를 미리 실행함으로써, 각각의 연산 장치와 메모리 접근 장치의 쉬는 시간(idletime)을 최소화함으로써 연산 처리량 및 지연 시간을 향상시킬 수 있다. LPU는 PCIe 인터페이스를 통해 호스트 컴퓨터와 연결될 수 있으며, 호스트 컴퓨터로부터 LPU의 동작에 필요한 명령어, 초거대 인공지능 모델의 입력값 및 가중치를 전달받아 연산을 수행한 후 그 결과를 호스 트 컴퓨터로 전달할 수 있다. LPU는 P2P 인터페이스를 통해 연결된 복수의 LPU들의 클러스터로 스케일 아웃(scale-out)될 수 있다. 확장된 클러스터 구조는 초거대 인공지능 모델의 연산의 가속을 더욱 향상시킬 수 있다. 도 2 내지 도 5는 본 발명의 실시예들에 따른 LPU들의 구현 모델의 예를 도시한 도면들이다. 앞서 도 1의 실시 예에서는 HBM의 외부 메모리를 사용하는 구현 모델의 예를 설명하였다. 외부 메모리로는 HBM 대신 DDR(Double Data Rate)이 이용될 수도 있다. 이때, 거대 모델은 하나의 디바이스에 저장되기 어렵기 때문에 복 수의 파티션으로 분리될 수 있으며, 복수의 디바이스들(복수의 LPU들)을 위한 외부 메모리들에 파티션별로 저장 될 수 있다. 이 경우, 거대 모델의 추론을 위해 복수의 디바이스들간의 동기화가 요구될 수 있다. 도 2의 실시예에서는 앞서 도 1의 실시예에서 설명한 것과 유사하게, 거대 모델의 복수의 파티션들을 저장 하는 복수의 외부 메모리들, 그리고 복수의 외부 메모리들과 병렬적으로 연결되는 복수의 LPU들(23 0)을 나타내고 있다. 하나의 LPU는 하나의 FPGA(Field Programmable Gate Array)에 구현될 수 있으며, 하나의 파티션이 하나의 FPGA에 병렬적으로 연결될 수 있다. 트랜스포머 구조가 디코더 레이어 안에 멀티헤드 어텐션, 레이어 노멀라이제이션, 피드 포워드 등을 포함하고 있는데, 멀티헤드 어텐션과 피드 포워드를 모델 병렬화시킬 수 있다. 이 경우 멀티헤드 어텐션이 종료되면, 임베딩 벡터 하나가 결과로 출력될 수 있다. 하나의 디바이스 에서는 임베딩 벡터의 포션만을 갖고 있기 때문에 다음 연산으로 넘어가기 위해서는 복수의 디바이스들이 각 임 베딩 벡터를 공유할 필요가 있기 때문에 동기화가 요구될 수 있다. 이때, 확장성을 고려하면, 하나의 LPU가 복 수의 외부 메모리(일례로, 2개나 4개 등)를 갖는 형태로 구현될 수도 있다. 일례로, 도 1의 실시예에서는 각각 하나의 파티션이 저장된 두 개의 HBM이 사용된 예를 나타내고 있다. 도 3의 실시예에서는 PIM(Processing-in-Memory) 모델의 예로서, 하나의 LPU가 PIM 칩으로 구현되어 파티션과 LPU 연산부가 모두 하나의 칩에 집적되는 형태로 구현된 예를 나타내고 있다. 도 3의 실시예에서는 각각 PIM 칩으로 구현될 수 있는 복수의 LPU, 복수의 파티션들, 그리고 복수의 LPU 연산부들을 나타내고 있다. 이때, 복수의 LPU 각각이 하나의 파티션과 하나의 LPU 연산부를 포함할 수 있다. 도 4의 실시예에서는 PNM(Processing-near-Memory) 모델의 예를 나타내고 있다. 하나의 PIM 칩 안에 모든 LPU 연산의 처리를 위한 구성이 포함되기 어려울 수 있다. 도 4의 실시예에서는 복수의 메모리 칩에는 복수의 파티션들을 저장하고, PNM 칩과 같은 버퍼 칩에서 LPU의 연산을 위한 LPU 연산부를 포함하는 형 태의 모델을 나타내고 있다. 도 5의 실시예에서는 PIM과 PNM이 결합된 모델의 예를 나타내고 있다. 일례로, 복수의 메모리 칩에는 복 수의 파티션들이 저장될 수 있다. 또한, 복수의 메모리 칩 각각에는 MAC 트리와 같은 축적부로서의 PIM 방식 LPU 연산부들이 구현될 수 있다. 이때, 버퍼 칩에 LPU의 나머지 하이-레벨 오퍼레이션을 위한 LPU 연산부가 PNM 방식으로 구현될 수 있다. 도 6은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛의 행렬 곱 연산을 위한 고대역 메모리의 가중치 행 렬 데이터 매핑을 설명하기 위한 도면이다. 도 6을 참조하면, 본 실시예에 따른 LPU는 복수의 MAC 트리를 구성하는 MAC 트리의 개수와 SMA 의 메모리 채널의 개수가 동일한 점으로부터 각각의 MAC 트리의 행렬 곱 연산 시 다른 메모리 채널에 접근하지 않고도 가중치 데이터를 불러올 수 있도록 HBM과 같은 고대역 메모리에 매핑된 가중치 행렬 데이터를 저장할 수 있다. 구체적으로, 가중치 행렬의 열 방향(D1)으로 복수의 MAC 트리의 개수만큼 각 채널(620-n)에 매핑되도록 고 대역 메모리에 가중치 행렬 데이터가 저장될 수 있다. 가중치 행렬에서 열 방향은 행렬 곱 연산이 병렬적 으로 수행될 수 있기 때문에 복수의 MAC 트리는 각각의 할당된 메모리 채널(620-n)에서 열 방향 데이터를 읽어와 행렬 곱 연산을 진행할 수 있다. 그 다음 복수의 MAC 트리가 가중치 행렬의 행 방향(D2)으로 축적하여 최종 연산 결과를 완성할 수 있도록 가중치 행렬 데이터를 매핑할 수 있다. 고대역 메모리의 대역폭에 의해 한번에 매핑되는 행 데이터의 개수 가 결정될 수 있으며, 이는 복수의 MAC 트리가 한번에 처리할 수 있는 타일의 크기로 결정될 수 있다. 도 7은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 고대역 메모리 인터페이스를 설명하기 위 한 도면이다. 도 7을 참조하면, SMA는 LMU, 복수의 MAC 트리 및 고대역 메모리를 연결할 수 있다. SMA는 LPU의 다른 연산 유닛들과는 연결되지 않으며, 따라서 고대역 메모리 인터페이스를 하드웨어 리소스 측면에서 최소화할 수 있다. 복수의 MAC 트리와 메모리 채널(620-n)은 각각 일대일 대응으로 연결될 수 있다. 즉, 복수의 MAC 트리 는 직접적으로 할당된 채널 이외의 다른 채널에 접근할 필요가 없어 리소스를 많이 사용하여 지연 시간이 큰 복잡한 예를 들어 크로스바(cross-bar)와 같은 인터페이스를 사용하지 않고 행렬 곱 연산을 수행할 수 있다. SMA는 복수의 MAC 트리가 고대역 메모리에 저장된 가중치 행렬 데이터를 불러오는 읽기 인터페 이스 만을 구성할 수 있다. 다시 말해, 뒤에서 설명하는 것과 같이 연산의 결과는 LMU를 통해 고대역 메 모리에 저장되므로, 복수의 MAC 트리의 고대역 메모리에 대한 쓰기 인터페이스는 구성되지 않고 하드웨어 리소스가 그만큼 감소될 수 있다. 이와는 반대로 SMA는 LMU와 고대역 메모리 사이에 쓰기 인터페이스만을 구성할 수 있다. SMA를 통해 내부 버퍼로써의 LMU에 저장된 연산 결과가 고대역 메모리에 기록되기 위해 전송될 수 있으며, 디멀티플렉서를 이용하여 기록 대상의 메모리 채널을 선택할 수 있다. 도 8은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 재구성 가능한 다기능 연산 유닛을 설명하 기 위한 도면이다. 도 8을 참조하면, VXE는 복수의 다기능 연산 데이터패스(810, 820)를 포함할 수 있으며, 복수의 다기능 연 산 데이터패스(810, 820)는 연산자/결과값 체인 네트워크와 연결되어 다양한 연산기 조합을 구성할 수 있 다. 도 8에 도시된 것과 같이 복수의 다기능 연산 데이터패스(810, 820)는 예를 들어 룩업 테이블 기반 비선형 활성 화 함수, 마스킹 연산 등에 필요한 다양한 연산 유닛을 포함할 수 있으며, 다만 도 8에 도시된 재구성 가능한 다기능 연산 데이터패스(810, 820)의 연산 유닛의 구성은 예시적인 것으로 거대 모델 연산에 필요한 추가적인 연산 유닛도 얼마든지 다기능 연산 데이터패스(810, 820)에 포함될 수 있음은 물론이다. VXE에 의해 연산 된 결과는 LMU로 전달될 수 있다. 도 9는 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 주소 기반 비순차적 다중유닛 스케쥴러의 구성을 설명하기 위한 도면이다. 도 9를 참조하면, 본 실시예에 따른 LPU에 포함된 주소 기반 비순차적 다중유닛 스케쥴러로서의 ISU 는 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러, 복수의 명령어 이슈 컨트롤러들(921, 922, 923, 924), 다중 뱅크 버퍼 주소 상태 테이블, 명령어 버퍼 및 결과 주소 상태 업데이트 로직, 다중 유닛 명렁어 디스패처를 포함할 수 있다. ISU는 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러와 복수의 명령어 이슈 컨트롤러들(921, 922, 923, 924)을 통해 각 연산 장치들과 데이터 이동 유닛들을 동시에 동작시킬 수 있다. 이때, ISU는 각 연산 장치에서 수행되는 명령어에 대한 다중 뱅크 버퍼 주소 상태 테이블의 연산자 주소 및 결과 주소 의 상태를 1로 바꿀 수 있다. 다중 뱅크 버퍼 주소 상태 테이블은 결과 주소 상태 업데이트 로직을 통해 수행이 끝난 명령어의 결 과 주소의 상태를 0으로 바꿀 수 있다. 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러는 다중 뱅크 버퍼 주소 상태 테이블을 통해 주 소의 상태들을 참조하여 수행해야 할 명령어와 수행 중인 명령어 사이의 종속성과, 수행해야 할 명령어들 사이 의 종속성을 판단할 수 있다. 이를 통해 종속성이 없는 명령어를 미리 처리할 수 있게 함으로써 각 연산 장치 및 데이터 이동 유닛의 쉬는 시간을 최소화할 수 있다. ISU에 포함된 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러는 명령어 버퍼로부터 명령어 를 로딩하여 처리할 수 있다. 이때, 주소 기반 명령어 종속성 판단 및 스케쥴링 컨트롤러는 루프(loop) 명령어를 수행하며, 이 외의 명령어들은 디코딩하여 명령어들을 구분해 다중유닛 명령어 디스패처를 통해 디바이스 투 디바이스 명령어 이슈 컨트롤러, 직접 메모리 접근 명령어 이슈 컨트롤러, MAC 트리 명령어 이슈 컨트롤러 및 재구성 가능한 다기능 연산 유닛 명령어 이슈 컨트롤러로 전달할 수 있다. ISU는 PCIe 인터페이스를 통해 호스트 컴퓨터로부터 LPU의 명령어들을 입력 받아 저장하며, 현 재 LPU의 상태를 상태 레지스터(register)에 저장할 수 있다. 호스트 컴퓨터는 PCIe 인터페이스를 통해 해당 상태 레지스터를 확인할 수 있다."}
{"patent_id": "10-2023-0169464", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있 다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적 이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0169464", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 레이턴시 프로세싱 유닛의 구조의 예를 도시한 도면이다. 도 2 내지 도 5는 본 발명의 실시예들에 따른 LPU들의 구현 모델의 예를 도시한 도면들이다. 도 6은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛의 행렬 곱 연산을 위한 고대역 메모리의 가중치 행 렬 데이터 매핑을 설명하기 위한 도면이다. 도 7은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 고대역 메모리 인터페이스를 설명하기 위 한 도면이다. 도 8은 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 재구성 가능한 다기능 연산 유닛을 설명하 기 위한 도면이다. 도 9는 본 발명의 일실시예에 따른 레이턴시 프로세싱 유닛에 포함된 주소 기반 비순차적 다중유닛 스케쥴러의 구성을 설명하기 위한 도면이다."}
