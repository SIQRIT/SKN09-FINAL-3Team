{"patent_id": "10-2024-7008766", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0051173", "출원번호": "10-2024-7008766", "발명의 명칭": "라이브, 가상 또는 원격 눈 수술 훈련 장치 및 방법을 위한 안구 시뮬레이션된 카메라 보조", "출원인": "에이스 비전 그룹 인코포레이티드", "발명자": "힙슬리 앤마리"}}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법으로서,프로세서에 의해, 로봇 어셈블리를 초기화하는 단계;상기 프로세서에 의해, 상기 로봇 어셈블리를 하나 이상의 컴퓨팅 디바이스에 연결하는 단계;상기 프로세서에 의해, 상기 로봇 어셈블리를 동작시키는 단계;상기 프로세서에 의해, 사람 또는 동물의 눈 움직임을 시뮬레이션하는 단계를 포함하며, 상기 시뮬레이션은,상기 하나 이상의 컴퓨팅 디바이스의 사용자 인터페이스를 통한, 상기 눈의 특정 영역들의 강조, 시각화, 진단및 치료, 및상기 사용자 인터페이스 상의 제어들에 응답한 상기 눈의 동적 실시간 현실적인 움직임을 포함하는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "시스템으로서,베이스 플레이트(base plate);상기 베이스 플레이트에 결합된 페이스 플레이트(face plate);적어도 하나의 프로세서에 전자적으로 연결되고 눈의 위치를 제어하는 입력을 수신하도록 구성된 제어기;상기 페이스 플레이트 내에 배치된 눈 홀더(eye holder);상기 적어도 하나의 프로세서와 상기 눈 홀더 사이에 전자 연결을 제공하도록 구성된 인터페이스 보드;상기 눈 홀더에 배치된 눈;상기 눈의 움직임을 제어하는 사용자 입력을 수신하도록 구성된 사용자 인터페이스; 및상기 베이스 플레이트에 결합된 상기 적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는,상기 눈의 위치를 초기화하고;하나 이상의 컴퓨팅 디바이스 또는 모바일 또는 웨어러블 디바이스에 연결하고;상기 하나 이상의 컴퓨팅 디바이스, 모바일 또는 웨어러블 디바이스에 의해, 상기 눈의 위치를 제어하고;사람 또는 동물의 눈 움직임을 시뮬레이션하고;상기 눈에 대해 레이저 시술을 수행하도록구성되는, 시스템."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 시스템은 레이저를 더 포함하는, 시스템.공개특허 10-2024-0051173-3-청구항 4 제1항에 있어서,상기 눈 홀더는 상기 눈 안의 안압을 초기화, 모니터링, 조정 및 측정하는 장치로 구성되는, 시스템."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 눈 홀더는 상기 사용자 인터페이스에 의해 제어되는 흡입 컵을 포함하는, 시스템."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 페이스 플레이트는 제거가능하고 동물 종들 또는 사람의 형상인, 시스템."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "방법으로서,프로세서에 의해, 로봇 어셈블리를 초기화하는 단계;상기 프로세서에 의해, 하나 이상의 컴퓨팅 디바이스에 연결하는 단계;상기 프로세서에 의해, 상기 로봇 어셈블리를 동작시키는 단계;상기 프로세서에 의해, 사람 또는 동물의 눈 움직임을 시뮬레이션하는 단계; 및상기 프로세서에 의해, 상기 로봇 어셈블리의 눈에 대해 결정된 실습(exercise)을 수행하도록 레이저를 동작시키는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 결정된 실습은 시뮬레이션된 백내장 수술, 시뮬레이션된 라식 수술, 시뮬레이션된 망막 치료, 공막 시술,시력 치료 또는 눈 측정을 포함하는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 눈 움직임을 시뮬레이션하는 단계는 사용자 인터페이스를 통해 상기 움직임을 제어하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 로봇 어셈블리를 초기화하는 단계는 상기 로봇 어셈블리의 눈 홀더 내에 눈을 설치하는 단계를 포함하는,방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 눈은 유리 눈, 나무 눈, 사체 눈, 동물 눈, 가상 소재(phantom material) 및 인공 눈 중 하나를 포함하는,방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2024-0051173-4-제9항에 있어서,상기 사용자 인터페이스는 실제 사람 또는 동물 눈 움직임 또는 비정상적인 움직임들을 시뮬레이션하는 하나 이상의 모드를 포함하는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 눈 홀더는 상기 눈에서의 압력을 변경하고/하거나 상기 눈 홀더 내에서의 상기 눈의 위치를 변경하도록 구성되는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 눈 홀더는 상기 눈에서의 압력을 변경하고/하거나 상기 눈 홀더 내에서의 상기 눈의 위치를 변경하도록 구성되는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제7항에 있어서,상기 눈의 위치를 추적하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 추적하는 단계에 응답하여, 피드백 루프를 통해 상기 위치가 타겟 위치와 일치하고 타겟 상에 고정됨을 검증하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7008766", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,실생활 눈 기능들을 시뮬레이션하는 깜빡임 메커니즘 및 홍채 셔터를 더 포함하는, 방법."}
{"patent_id": "10-2024-7008766", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "안구 시뮬레이션된 카메라 보조 로봇 훈련을 위한 방법이 제공된다. 일부 구현들에서, 이 방법은 프로세서에 의 해 로봇 어셈블리를 초기화하는 단계를 포함한다. 이 방법은 프로세서에 의해 하나 이상의 컴퓨팅 디바이스에 연결하는 단계를 더 포함한다. 이 방법은 프로세서에 의해 로봇 어셈블리를 동작시키는 단계를 더 포함한다. 이 방법은 프로세서에 의해 사람 또는 동물의 눈 움직임을 시뮬레이션하는 단계를 더 포함한다. 이 방법은 프로 세서에 의해 로봇 어셈블리의 눈에 대해 결정된 실습을 수행하도록 레이저를 동작시키는 단계를 더 포함한다. 관련 시스템들, 방법들, 및 제조 물품들이 또한 설명된다."}
{"patent_id": "10-2024-7008766", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원에 대한 상호 참조 본 출원은 \"OCULAR SIMULATED CAMERA ASSISTED ROBOT FOR LIVE, VIRTUAL OR REMOTE EYE SURGERY TRAINING APPARATUS AND METHOD\"라는 명칭으로 2021년 8월 20일자로 출원된 미국 특허 출원 제63/235,574호에 대한 우선 권을 주장하며, 그 내용 전체가 본 명세서에 참조로 포함된다. 본 명세서에서 설명되는 주제는 원격 눈 수술 훈련에 관한 것이며, 보다 구체적으로는 눈 수술 훈련을 위한 안 구 시뮬레이션 카메라 아날로그 로봇(ocular simulation camera analog robot)(OSCAR)에 관한 것이다."}
{"patent_id": "10-2024-7008766", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "눈 상의 다양한 위치들에 시행되는 레이저 눈 치료들(예로서, 수술) 및 안과 치료들은 그 상태를 치료하기 위한 치료 솔루션을 현재 갖지 않는 10억명보다 많은 노안인들에 대해 더 양호한 근거리, 중간 및 원거리 시력을 위 해 자연스런 시각적 조절을 복원하기 위해 높은 레벨의 정확도 및 정밀도를 필요로 할 수 있다. 성공적인 수술 들, 치료들, 치유들 등을 위해서는 수시간 내지 수년의 교육 및 훈련이 필수적이다. 현재의 수술 훈련은 살아 있는 동물들 또는 사람들에 대한 경험을 요구한다. 살아 있는 동물 또는 사람의 행동 을 모방할 수 있는 애니매트로닉 로봇 시뮬레이션들(animatronic robotic simulations)은 동물 희생들과 초기 단계 수술 경험으로 인한 사람 눈들에서의 잠재적인 합병증으로부터 보호하면서 실제 환경이나 원격 환경에서 외과의들을 훈련시키는 능력을 제공할 것이다.따라서, 중요한 해부학적 구조들을 식별, 관찰 및 조작하여 눈에 대한 원격 시술들을 수행하기 위해 각막, 홍채, 섬유주대(trabecular meshwork), 망막, 모양체근, 수정체, 소대(zonules), 공막 및 맥락막을 포함하는 로봇 안구 구조들을 포함하지만 이에 제한되지 않는 시뮬레이션 안구 시술들을 수행하기 위한 개선된 시스템들, 디바이스들 및 방법들을 제공하는 것이 바람직하다. 일부 양태들에서, 방법, 컴퓨터 프로그램 제품 및 시스템이 제공된다. 구현에서, 원격 눈 수술 훈련 시스템이 제공된다. 시스템은 베이스 플레이트를 포함한다. 시스템은 베이스 플레이트에 결합된 페이스 플레이트를 더 포함한다. 시스템은 복수의 외부 입력과 통신할 수 있는 데이터 저장소 및 데이터베이스를 더 포함한다. 시스템은 또한 원격 측정 데이터를 수집하고, 다양한 극단 디바이스에 대한 출력들을 생성할 수 있다. 시스템은 적어도 하나 의 프로세서에 전자적으로 연결되고 눈의 위치를 제어하는 입력을 수신하도록 구성된 제어기를 포함할 수 있다. 시스템은 페이스 플레이트 내에 배치된 눈 홀더를 더 포함한다. 시스템은 적어도 하나의 프로세서와 눈 홀더 사이에 전자 연결을 제공하도록 구성된 인터페이스 보드를 더 포함한다. 시스템은 눈 홀더에 배치된 눈을 더 포함한다. 시스템은 눈의 움직임을 제어하는 사용자 입력을 수신하도록 구성된 사용자 인터페이스를 더 포함한 다. 시스템은 베이스 플레이트에 결합된 적어도 하나의 프로세서를 더 포함한다. 적어도 하나의 프로세서 및/ 또는 메모리는 눈의 위치를 초기화하는 것을 포함하는 동작들을 수행하도록 구성된다. 적어도 하나의 프로세서 는 하나 이상의 컴퓨팅 디바이스에 연결하도록 추가로 구성된다. 적어도 하나의 프로세서는 하나 이상의 컴퓨 팅 디바이스에 의해 눈의 위치를 제어하도록 추가로 구성된다. 적어도 하나의 프로세서는 사람 또는 동물의 눈 움직임을 시뮬레이션하도록 추가로 구성된다. 적어도 하나의 프로세서는 눈에 대해 레이저 시술을 수행하여 정 상 및 비정상 둘 다의 복수의 눈 움직임을 시뮬레이션하도록 추가로 구성된다. 시뮬레이터는 실제로 가능하지 않을 수 있는 해부학적 극단들까지 이동할 수 있다. 시스템의 일부 변형들에서, 시스템은 다양한 자극 및 광 반복들에 기계적으로 반응하는 \"홍채\" 셔터를 더 포함 한다. 시스템은 또한 복수의 홍채 크기에 기계적으로 고정될 수 있다. 시스템은 또한 눈이 사람 또는 동물 눈 의 기능과 병행하여 작업할 수 있게 하는 콘트라스트를 위해 설계된다. 시스템은 또한 정상적인 사람의 눈 기 능을 시뮬레이션하도록 설계된다. 시스템은 가능한 한 현실에 가까운 눈 데이터의 수집을 허용하는 정상적인 눈 깜빡임을 기계적으로 시뮬레이션 하는 \"깜빡임\" 기능을 포함한다. 시스템의 일부 변형들에서, 시스템은 레이저를 더 포함한다. 눈 홀더는 사용자 인터페이스에 의해 제어되는 흡 입 컵을 포함한다. 눈 홀더는 눈 안의 안압을 초기화, 모니터링, 조정, 및 측정하는 장치를 포함할 수 있다. 일 양태에서, 방법이 제공된다. 이 방법은 프로세서에 의해 로봇 어셈블리를 초기화하는 단계를 포함한다. 이 방법은 프로세서에 의해 하나 이상의 컴퓨팅 디바이스에 연결하는 단계를 더 포함한다. 이 방법은 프로세서에 의해 로봇 어셈블리를 동작시키는 단계를 더 포함한다. 이 방법은 프로세서에 의해 복수의 사람 또는 동물 눈 움직임들을 시뮬레이션하는 단계를 더 포함한다. 이 방법은 프로세서에 의해 로봇 어셈블리의 눈에 대해 결정 된 실습을 수행하도록 레이저를 동작시키는 단계를 더 포함한다. 이 방법의 일부 변형들에서, 결정된 실습은 시뮬레이션된 백내장 수술, 시뮬레이션된 라식 수술, 시뮬레이션된 망막 치료, 시뮬레이션된 이식 시술, 시력 치료 또는 눈 측정을 포함하지만 이에 제한되지 않는 복수의 시뮬레 이션된 눈 시술 및 수술을 포함할 수 있다. 눈 움직임을 시뮬레이션하는 단계는 사용자 인터페이스 하드웨어 명령들, 원격 명령들, 또는 음성 명령들을 통해 움직임을 제어하는 단계를 포함할 수 있다. 로봇 어셈블리를 초기화하는 단계는 로봇 어셈블리의 눈 홀더 내에 눈을 설치하는 단계를 포함할 수 있다. 눈은 유리 눈, 나무 눈, 사체 눈, 가상 소재 및 인공 눈 중 하나를 포함할 수 있다. 사용자 인터페이스는 실제 사람 또는 동물의 눈 움직임 또는 비정상적인 극단 움직임을 시뮬레이션하는 하나 이상의 모드를 포함할 수 있다. 하나 이상의 모드는 지향성 시선 모드(directed gaze mode), 요동 모드(flutter mode), 안진 모드(nystagmus mode), 경련성 모드(saccadic mode), 미소안운동 모드(microsaccades mode), 떨림 모드(tremor mode) 및 드리프트 모드(drift mode), 동물 모드 및 사람 모드를 포함할 수 있다. 눈 홀더는 눈에서의 압력을 변경하고/하거나 눈 홀더 내에 서의 눈의 위치를 변경하도록 구성될 수 있다. 이 방법은 눈의 위치를 추적하는 단계를 더 포함할 수 있다. 이 방법은 추적하는 단계에 응답하여, 위치가 타겟 위치와 일치하는지를 검증하는 단계를 더 포함할 수 있다. 이 방법은 특정 타겟에 대한 눈의 고정을 더 포함할 수 있다.본 주제의 구현들은, 설명되는 바와 같은 하나 이상의 피처를 포함하는, 본 설명과 일치하는 시스템들 및 방법 들뿐만 아니라, 하나 이상의 기계(예를 들어, 컴퓨터 등)로 하여금 본 명세서에 설명되는 동작들을 초래하게 하 도록 동작가능한 유형적으로 구현되는 기계 판독가능한 매체를 포함하는 물품들을 포함할 수 있다. 유사하게, 하나 이상의 프로세서 및 하나 이상의 프로세서에 결합된 하나 이상의 메모리를 포함할 수 있는 컴퓨터 시스템 들도 설명된다. 컴퓨터 판독가능한 저장 매체를 포함할 수 있는 메모리는 하나 이상의 프로세서로 하여금 본 명세서에 설명된 동작들 중 하나 이상을 수행하게 하는 하나 이상의 프로그램을 포함, 인코딩, 저장 등을 할 수 있다. 본 주제의 하나 이상의 구현과 일치하는 컴퓨터 구현 방법들은 단일 컴퓨팅 시스템 또는 다수의 컴퓨팅 시스템들에 상주하는 하나 이상의 데이터 프로세서에 의해 구현될 수 있다. 이러한 다수의 컴퓨팅 시스템들은 네트워크(예를 들어, 인터넷, 무선 광역 네트워크, 로컬 영역 네트워크, 광역 네트워크, 유선 네트워크 등)를 통한 연결을 포함하지만 이에 제한되지 않는 하나 이상의 연결을 통해, 다수의 컴퓨팅 시스템들 중 하나 이상 사이의 직접 연결 등을 통해 연결될 수 있고 데이터 및/또는 명령들 또는 다른 명령어들 등을 교환할 수 있다. 본 명세서에 설명된 주제의 하나 이상의 변형의 상세들은 첨부 도면들 및 아래의 설명에서 제시된다. 본 명세 서에 설명된 주제의 다른 피처들 및 이점들은 설명 및 도면들로부터, 그리고 청구항들로부터 명백할 것이다. 개시된 본 주제의 특정 피처들이 기업 리소스 플래닝(ERP 기업 리소스 플래닝 소프트웨어) 시스템 또는 다른 비 즈니스 소프트웨어 솔루션 또는 아키텍처와 관련하여 예시적인 목적으로 설명되지만, 이러한 피처들은 제한적인 것으로 의도되지 않는다는 것이 쉽게 이해되어야 한다. 본 개시내용에 후속하는 청구항들은 보호되는 주제의 범위를 정의하도록 의도된다."}
{"patent_id": "10-2024-7008766", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "앞서 살펴본 바와 같이 그리고 이하에서 상세히 설명되는 바와 같이, 본 명세서에 설명되는 방법들 및 디바이스 들의 실시예들은 조합하여 또는 개별적으로 유용하게 이용될 수 있고, 눈 및 신체의 다른 영역들 둘 다에서, 일 정 범위의 질환 상태들을 치료하는데 유리하게 이용될 수 있는 다수의 양태들을 포함한다. 특히 상세히 설명된 예들 중 적어도 일부는 노인성 녹내장, 백내장 형성, 및 노인성 황반 변성과 같은 다른 노인성 안구 질환들 등 의 치료와 같은 눈의 상태들의 치료에 초점을 맞추고 있다. 특히, 본 명세서에 설명된 실시예들은 원격 눈 수술 훈련에 이용되는 하드웨어, 소프트웨어, 펌웨어, 계산 회로, 또는 다른 시스템 솔루션에 관한 것이다. 훈련 시스템은 종 의존적일 수 있는 애니매트로닉스의 사람 유 사 및/또는 동물 유사 움직임을 제공할 수 있다. 이러한 움직임은 사체 또는 다른 눈 시뮬레이션보다 수술 동 안 더 현실적인 눈 움직임을 적어도 제공함으로써 수술 훈련을 개선할 수 있다. 도 1은 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련을 위한 시스템을 도시한다. 도시된 바와 같이, 시스템은 로봇 어셈블리 및 제어기를 포함한다. 일부 양태들에서, 제어기는 로봇 어셈블 리의 적어도 일부 부분들(예로서, 하나 이상의 눈)의 움직임을 제어하도록 구성될 수 있다. 제어기 는 조이스틱, 키패드, 마우스, 게임 제어기, 터치스크린 등을 포함할 수 있다. 도 2a는 일부 예시적인 구현들에 따른, 원격 훈련 환경을 도시한다. 도시된 바와 같이, 예시적인 훈련 환 경은 서버와 통신하는 적어도 하나의 사용자를 포함한다. 일부 양태들에서, 서버는 웨비 나, 프리젠테이션, 가상 웨트랩(wetlab) 등을 호스팅할 수 있다. 사용자는 서버의 프리젠테이션에 로그인된 클라이언트 디바이스와 연관될 수 있다. 일부 양태들에서, 서버는 또한 로봇 어셈블리 와 통신할 수 있고, 로봇 어셈블리에 대한 원격 제어를 제공할 수 있다. 일부 구현들에서, 클라이언트 디바이스는 또한 로봇 어셈블리의 일부분들을 이동시키도록 구성된 제어부들을 포함할 수 있다. 일부 양태들에서, 사용자에 대한 원격 훈련은 서버와 통신하는 원격 데모 디바이스(예를 들어, 로봇 어셈블리)를 이용하여 행해질 수 있다. 예시적인 훈련 환경은 유익하게도 사용자의 편의에 따 라 완료될 수 있는 훈련 세미나가 다수의 사용자에 의해 개최되게 할 수 있다. 도 2b는 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련을 위한 시스템의 블록도를 도시한다. 도 2b는 사용자들(예를 들어, 사용자들)과 컴퓨팅 디바이스들(예를 들어, 클라이언트 디바이스, 서버, 로봇 어셈블리 등) 사이의 예시적인 연결들을 도시한다. 도시된 바와 같이, 모든 사용자들 및 디바이스들 은 상업적으로 이용가능한 영상 회의 소프트웨어를 통한 무선 연결(예를 들어, 인터넷 연결)로 직접 또는 간접 적으로 연결된다. 인터넷 연결이 도시되지만, 사용자들과 디바이스들 사이의 연결은 유선이거나, 다른 무선 기 술로 달성될 수 있다. 특정 사용자들 및 디바이스들이 도시되지만, 다른 사용자들 및 다른 디바이스들이 또한 가능하다. 영상 회의 소프트웨어는 임의의 영상 전화, 채팅, 홀로그래픽, 또는 임의의 다른 유형의 영상 회의 또는 회의 소프트웨어를 포함할 수 있다. 도 2c는 일부 예시적인 구현들에 따른 예시적인 무선 네트워크에 대한 다이어그램을 도시한다. 도시된 바 와 같이, 원격 로봇 시스템(예를 들어, 시스템)은 의료 전문가/전문의(예를 들어, 클라이언트 디바이스 , 서버 등을 통한 사용자)와의 통신을 통한 복수의 네트워크 링크를 통해 동작할 수 있다. 복 수의 네트워크 링크들은 ISDN(integrated services digital network), LAN(local area network), 및 전용 T-1 회선 인터넷 및/또는 낮은 광대역폭 링크들과 같은 광대역 네트워크 링크들을 포함할 수 있다. 도 2c에 추가로 도시된 바와 같이, 무선 네트워크는 시스템과 사용자 사이의 통신을 용이하게 하는 위성 링크 , 지상 링크를 포함한다. 원격 조작 의료 로봇 시스템들(예를 들어, 시스템)은 수술, 치료 및 진단과 같은 시술들이 유선 및/또는 무선 통신 네트워크들을 이용하면서 단거리 또는 장거리에 걸쳐 수행되게 할 수 있다. 또한, 원격 조작 의료 로봇 시스템들은 원격 실시간 수술 상담에 수술실 환경을 제공할 수 있다. 연결 허용 비디오 및 오디오 원격 회의는 실시간 상담은 물론 상담가 패널에 의한 관찰을 위한 실시간 이미지들 및 저장후 전달 이미지들의 전송을 지원할 수 있다. 예를 들어, 사용자는 무선 네트워크를 통해 시스템의 동작을 제어할 수 있다. 강건하고 적응적 인 제어를 포함하는 진보된 제어 기술들은 특히 양방향 원격 조작 시스템들(예를 들어, 시스템)에 관련된 다. 강건한 제어는 시스템에 영향을 미치는 불확실성 또는 교란에도 불구하고 안정성 및 성능을 보존할 수 있 다. 일반적으로, 적응적 제어는 알려지지 않은 또는 변화하는 파라미터들을 갖는 제어된 시스템들에 적응하는 능력을 가지며, 여기서 적응적 제어 방식은 통신 지연들 또는 에러들이 또한 고려되면서 원격 조작 시스템에 관 한 동적 및 운동학적 불확실성들 둘 다를 다루도록 제안된다. 도 2d는 일부 예시적인 구현들에 따른 클라우드 기반 시스템 아키텍처를 도시한다. 도시된 바와 같이, 클라우 드 처리 센터는 로봇 어셈블리의 실행 결정을 제어하고, 로봇 어셈블리의 위치 데이터(예를 들어, 눈 의 위치 데이터)에 대한 계산을 수행하고, 로봇 어셈블리와의 이전 훈련 세션의 이력 데이터 분석을 수행하고, 데이터를 저장하고, 인공 지능(AI) 훈련을 수행하고, 연구 및 개발 기반구조를 제공하고, 분석 및 건 강 정보를 제공할 수 있다. 도 3a는 일부 예시적인 구현들에 따른 로봇 어셈블리의 사시도이다. 도시된 바와 같이, 로봇 어셈블리 는 페이스 플레이트, 로봇 눈 어셈블리, 베이스 플레이트 및 프로세서를 포함한다. 일부 양태들에서, 로봇 어셈블리는 대안의 예시적인 눈 홀더를 포함할 수 있다. 일부 실시예들에서, 페이스 플레이트는 연결 핀들을 통해 베이스 플레이트에 결합될 수 있다. 페이스 플레이트가 사람의 얼굴로 도시되어 있지만, 페이스 플레이트는 임의의 종의 동물(예를 들어, 돼지, 원숭이 등) 또는 사람의 형상으로 몰딩되고 제거가능할 수 있다. 도 3b 내지 도 3e는 동물(예를 들어, 돼지) 페이스 플레이트를 갖는 페이스 플레이트의 예시적인 프로파일 뷰들을 도시한다. 도 4a는 일부 예시적인 구현들에 따른, 차폐부를 갖는 로봇 어셈블리의 사시도이다. 도 4b는 일부 예시적인 구현들에 따른, 차폐부를 갖는 로봇 어셈블리의 측면도이다. 도 4c는 차폐부를 갖는 로봇 어셈블리의 사시도이다. 도 4c의 예에 도시된 바와 같이, 차폐부는 리세스들을 포함한다. 일부 양태들에서, 리세스들은 로봇 어셈블리, 눈 수술 훈련 시술 등에 관련된 물체들을 유지하도록 구성될 수 있다. 예를 들어, 리세스들은 눈 병들, 다른 눈 컵들, 교체 부품들, 눈물들을 위한 병들 등을 유지하도록 크기가 정해지고 구성될 수 있다.도 5a는 일부 예시적인 구현들에 따른 예시적인 로봇 눈 어셈블리의 분해도이다. 도시된 바와 같이, 로봇 눈 어셈블리는 리테이닝 링, 눈 홀더 및 O-링, 및 눈 컵, 스페이서, 눈, 클램핑 링, 및 클램핑 나사들을 포함할 수 있다. 리테이닝 링은 눈 컵을 제자리에 유지하 도록 구성될 수 있다. 리테이닝 링은 눈 컵을 눈 홀더에서 더 낮게 또는 더 높게 이동시키는 능력을 가질 수 있다. 눈 홀더는 눈 컵을 제자리에 유지할 수 있고, 서보 및 눈 컵으로의 연결 로부터의 움직임 입력을 변환할 수 있다. 눈 홀더는 좌측 및 우측(L/R) 움직임을 위한 대향 측면들 상의 2개의 피봇 포인트를 포함할 수 있다. 눈 홀더는 L/R 서보로의 연결에 대한 연결 포인트인 플랜지 또는 보스를 포함할 수 있다. 눈 홀더는 O-링(예를 들어, O-링)을 포함하는 홈을 포함할 수 있다. O-링은 제자리에 유지되도 록 눈 컵보다 약간 작게 설계될 수 있다. O-링은 컵과 홀더 사이에 장력을 제공할 수 있 고, 눈 컵을 홀더에 중심을 두고 유지되게 하도록 설계될 수 있다. 눈 홀더는 눈 안의 안 압을 초기화, 모니터링, 조정, 및 측정하는 장치(도시되지 않음)를 포함할 수 있다. 장치는 압력계, 또는 안압 을 측정, 계량, 모니터링 및 표시하는 홀더의 장치에 부착, 분리 또는 통합되는 트랜스듀서를 포함할 수 있다. 눈 홀더는 (덴탈 댐과 같은) 고무 오염 차폐부를 유지하도록 설계되는 상단(top) 상의 립을 포함할 수 있 다. 이 차폐부는 아래에 있는 임의의 애니매트로닉스 또는 전자기기로부터 액체를 멀리 떨어뜨릴 수 있다. 눈 컵은 눈을 유지하도록 설계될 수 있다. 눈은 유리 눈, 나무 눈, 사체 눈, 인공 눈, 동물(예를 들어, 돼지, 원숭이 등) 눈 등을 포함할 수 있다. 눈 컵은 돼지 눈보다 약간 더 큰 직경을 갖도록 구성될 수 있다. 눈 컵은 호스에 부착하기 위해 하단(bottom)에 부착된 작은 파이프를 포함할 수 있다. 눈 컵 은 상단 상에 립을 가질 수 있고, 이에 의해 임의의 액체들이 이로부터 떨어져 컵 내부에 또는 오염 차폐 부 상에 착지될 것이다. 눈 컵은 클램프 링(예를 들어, 클램프 링)을 장착하기 위한 하나 이상의 홀 을 포함할 수 있다. 클램핑 링은 컵에 눈을 유지하는 하나의 방식일 수 있다(예를 들어, 컵 은 홀더에 배치된다). 클램핑 링은 눈보다 약간 더 작은 ID를 포함할 수 있고, 따라서 나사들 (예를 들어, 클램핑 나사들)로 이를 아래로 유지하는 것은 눈 상에서 아래로 클램핑하고 이를 제자리 에 유지할 것이다. 눈 컵은 쉽게 세정가능한 소재(예를 들어, 실리콘, 플라스틱 등)로 만들어질 수 있다. 하단에 연결된 호스 및 스페이서(예를 들어, 스페이서)와 함께 이용될 때, 호스에 진공이 가해질 수 있고, 눈은 스페이서에 대해 밀봉될 수 있고 진공을 통해 제자리에 유지될 수 있다. 따라서, 눈 컵은 눈 내의 압력을 변경할 수 있는 섹션 컵을 포함할 수 있다. 일부 양태들에서, 눈, 눈 컵 등에 가해지는 진공 또는 섹션의 양은 사용자 인터페이스(예를 들어, GUI)에 의해 제어될 수 있다. 스페이서 는 모든 사분면들이 치료될 수 있도록 정확한 높이로 눈을 유지할 수 있다(예를 들어, 상이한 형상의 눈들에 대해 상이한 길이의 스페이서들이 필요할 수 있다). 사체 눈의 경우, 시신경은 하단의 안구로부터 2-6mm 돌출될 수 있다. 스페이서는 시신경이 컵의 하단 위에 머무를 수 있도록 중앙에 홀을 포함할 수 있다. 그렇지 않은 경우, 눈은 컵 내에서 기울어질 수 있고, 이것이 올바르게 정확히 위치되는 것을 허용하지 않을 수 있다. 도 5b는 일부 예시적인 구현들에 따른 로봇 눈 어셈블리의 측면도이다. 도시된 바와 같이, 로봇 눈 어셈 블리는 스페이서를 포함할 수 있다. 스페이서는 시신경을 수용하도록 구성되거나 또는 시신경 이 로봇 눈 어셈블리의 개구를 통과하게 하도록 구성될 수 있다. 추가로 도시된 바와 같이, 로봇 눈 어셈 블리는 피봇 축을 포함할 수 있다. 일부 양태들에서, 피봇 축은 눈의 축과 동일할 수 있 다. 도 5c 및 도 5d에 도시된 것과 같은, 시스템의 일부 변형들에서, 눈 홀더는 사용자 인터페이스에 의해 제 어되는 흡입 컵을 포함한다. 눈 홀더는 눈 안의 안압을 초기화, 모니터링, 조정, 및 측정하는 장치를 포함할 수 있다. 도 6은 일부 예시적인 구현들에 따른, 애니매트로닉스 어셈블리의 사시도이다. 도시된 바와 같이, 애니매 트로닉스 어셈블리는 눈 홀더, 눈, 클램핑 링, 피봇 프레임, 제어 암, Y 링크 를 포함한다. 피봇 프레임은 눈 홀더 내의 대응하는 홀들에 배치되는 2개의 핀을 통해 눈들(예 를 들어, 눈)을 유지하도록 구성될 수 있다. 피봇 프레임은 눈을 좌우로 이동시키기 위한 베이스를 제공할 수 있고, 서보에 의해 상하로 이동되는 다른 프레임 상에 장착될 수 있다. 제어 암은 좌측/우측 (L/R) 서보에 결합될 수 있는 중앙에서의 피봇 포인트를 포함할 수 있다. 일부 양태들에서, 제어 암의 각 각의 단부는 좌안 및 우안의 눈 홀더들에 각각 결합될 수 있다. Y 링크는 중앙 서보와 눈 홀더를 연결할 수 있다. Y 링크는 또한 중앙 서보 움직임을 애니매트로닉스 어셈블리의 프레임 에 전송하도록 구성될 수 있다. 프레임은 피봇 포인트로서 양측에 장착될 수 있기 때문에, 서보가 이동될 때,눈들은 상향 및/또는 하향 이동할 수 있다. 도 7은 일부 예시적인 구현들에 따른 로봇 어셈블리의 분해도이다. 도시된 바와 같이, 로봇 어셈블리 는 베이스 플레이트, 연결 핀, 제1 스탠드오프, 프로세서, 제1 볼트, 소켓 , 캡, 펌프, 인터페이스 보드, 제2 스탠드오프, 제2 볼트, 차폐부 및 페 이스 플레이트를 포함한다. 일부 양태들에서, 제1 스탠드오프는 전자기기들을 베이스 플레이트(30 6)로부터 떨어지게 유지하도록 구성될 수 있다. 제1 볼트는 프로세서를 베이스 플레이트에 장 착하기 위한 2.5mm 볼트를 포함할 수 있다. 프로세서는 라즈베리 파이(Raspberry Pi) 또는 다른 프로세서 를 포함할 수 있다. 소켓은 입력 전력 소켓으로서 12V 소켓을 포함할 수 있다. 캡은 8mm 볼트 위에 끼워지도록 구성된 고무 캡을 포함할 수 있고, 페이스 플레이트의 하단 상의 하나 이상의 홀에 끼워지도록 구성될 수 있다. 펌프는 눈을 원하는 위치에 유지하기 위해 눈 홀더에 진공을 제공하도록 구성 된 수족관 펌프를 포함할 수 있다. 인터페이스 보드는 프로세서와 애니매트로닉스 어셈블리(예를 들 어, 애니매트로닉스 어셈블리)의 서보들 사이의 연결들을 제공할 수 있다. 제2 스탠드오프는 인터페 이스 보드를 브래킷에 장착하도록 구성될 수 있다. 제2 볼트는 브래킷을 베이스 플레이트에 장 착하도록 구성된 4mm 볼트를 포함할 수 있다. 차폐부는 로봇 어셈블리의 하단 부분을 적어도 부분적 으로 둘러싸도록 크기 및 형상이 정해질 수 있으며, 로봇 어셈블리의 전자기기로부터 사용자를 보호하도록 구성 될 수 있다. 차폐부는 또한 냉각 팬을 위한 장착을 제공할 수 있고, 케이블들이 통과하는 것을 허용하기 위한 하나 이상의 홀을 포함할 수 있다. 페이스 플레이트는 로봇 눈 어셈블리가 보이도록 하나 이상 의 애퍼처를 포함할 수 있다. 페이스 플레이트는 로봇 어셈블리에 현실성을 제공하기 위해 사람 얼 굴과 동일하거나 유사한 비율들이 되도록 설계될 수 있다. 페이스 플레이트는 임의의 액체들을 수집하도 록 구성된 하단부 근처의 트레이를 포함할 수 있다. 일부 양태들에서, 로봇 어셈블리는 카메라 또는 이미 지 캡처 디바이스(도시되지 않음)를 포함할 수 있다. 일부 실시예들에서, 카메라 또는 이미지 캡처 디바이스는 로봇 어셈블리 외부에 있어서 눈의 외부 뷰를 제공하고, 로봇 어셈블리를 제어하는 사용자(예를 들어, 사 용자)에게 실시간 이미지 피드백 및/또는 안내를 제공할 수 있다. 카메라 또는 이미지 캡처 디바이스는 또한 눈 위치 또는 눈(예를 들어, 눈)의 고정 포인트의 눈 추적에 관한 피드백을 제공할 수 있다. 일부 양태들에서, 원격 로봇 시스템들(예를 들어, 시스템들(100, 250 등))의 제어는 주로 이미지 및 비디오 안 내에 기반할 수 있다. 관련된 이미지 획득 프로세스는 원격 로봇 시스템의 휴대성 및 수송성에 영향을 주는 한 편, 인코딩된 이미지 및 비디오의 연관된 대역폭 요구들은 또한 원격 통신 요건들을 대부분 정의한다. 도 8a는 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련을 위한 시스템의 블록도를 도시한다. 도시된 바와 같이, 시스템은 프로세서, 메모리, 제어기, 드라이버, 드라이브, 하나 이 상의 로봇 눈 어셈블리, 및 무선 연결을 포함할 수 있다. 일부 양태들에서, 프로세서는 운영 체제(예를 들어, 라즈베리 파이 컴퓨터)를 실행하는 프로세서를 포함할 수 있다. 메모리는 프로세서(81 0)로 하여금 시스템과 통신하는 로봇 어셈블리(예를 들어, 로봇 어셈블리)에 영향을 미치는 동작들을 수행하게 할 수 있는 그래픽 사용자 인터페이스 애플리케이션을 위한 명령어들을 저장할 수 있다. 일부 양태들 에서, 제어기는 로봇 어셈블리의 눈 움직임을 제어하도록 구성되는 게임 콘솔 제어기를 포함할 수 있다. 제어기는 USB 제어기 드라이버를 통해 프로세서에 결합될 수 있다. 프로세서는 집적 회로를 통 해 드라이버에 결합될 수 있다. 드라이버는 드라이브에 전자적으로 결합될 수 있다. 도 8의 예에 도시된 바와 같이, 시스템은 2개의 드라이브를 포함하지만, 더 많거나 더 적은 드라이브가 가능하다. 드라이브들은 하나 이상의 눈 어셈블리에 움직임을 제공하도록 구성되는 서보 드라이브들 을 포함할 수 있다. 일부 양태들에서, 시스템 및/또는 프로세서는 시스템에 그리고 시스템으로부터 피드백을 제공하기 위 해 신경망을 구현할 수 있다. 도 8b는 일부 예시적인 구현들에 따른 예시적인 신경망을 도시한다. 도시 된 바와 같이, 신경망은 입력 계층, 하나 이상의 은닉 계층, 및 출력 계층을 포함하고, 하 나 이상의 입력 노드를 포함한다. 하나 이상의 은닉 계층은 하나 이상의 은닉 노드를 포함하고, 출력 계층은 출력 노드들을 포함한다. 일부 양태들에서, 입력 계층에 대한 입력들은 디지털 이미지들, 디지털 비디오들, 수학 방정식들, 지형 이미지들, 파면 이미지들, 광학 이미지들 등을 포함할 수 있다. 일부 구현들에서, 하나 이상의 은닉 계층은 계산을 수행하고, 물리 툴을 이용하고, 변조기, 알 고리즘, 디지털 코드, 트리거 기능을 포함하고, 촉매 및 모듈식 전달 기능을 수행하는 등을 할 수 있다. 출력 계층으로의 출력들은 물리적 표시자들, 수학적 표시자들, 광학적 표시자들, 모션 표시자들 등을 포함할 수 있다.도 9a는 일부 예시적인 구현들에 따른, 로봇 시스템(예를 들어, 시스템)에서 로봇 동작들을 제어하기 위한 예시적인 프로그램 실행의 흐름도를 도시한다. 일부 양태들에서, 흐름도는 프로세서(310, 810), 신 경망 등에 의해 실행될 수 있다. 도 9b는 일부 예시적인 구현들에 따른, 예시적인 작업흐름 및 자동 피드백 루프들을 도시한다. 도시된 바 와 같이, 작업흐름 및 피드백 루프들은 레이저 또는 기구, 인공 지능 제어기, 시뮬레이션된 환자(예를 들 어, 동물 또는 사람, 로봇 어셈블리), 의사 또는 다른 사용자, 및 온보드 눈 추적 카메라 사이의 예시적인 상호작용들을 도시한다. 일부 양태들에서, 로봇 어셈블리(예를 들어, 어셈블리)는 자율, 반자율, 원격 로봇 상태에서 동작할 수 있 다. 원격 로봇 시스템들(예를 들어, 도 2c 참조)에서, 원격 조작기(예를 들어, 제어기)는 (예를 들어, 로 봇 어셈블리 내부 또는 외부의 카메라로부터) 시각적 및 다른 감각 피드백 정보를 수신하면서 위치 명령들 을 전송함으로써 조작자(예를 들어, 사용자)의 사이트로부터 제어될 수 있다. 로컬 및 원격 시스템들은 각각 \"마스터\" 및 \"슬레이브\" 시스템들로서 지칭될 수 있고, 전체 시스템(예를 들어, 시스템)은 \"마스터- 슬레이브 시스템\"으로서 지칭될 수 있다. 원격 조작기는 조작자(예를 들어, 사용자)의 제어들을 추적하도 록 프로그래밍될 수 있다. 일부 양태들에서, 로봇 어셈블리는 어셈블리의 눈(예로서, 눈)이 예 를 들어 시각적 카메라를 통해 원하는 위치에 있는지를 나타내는 위치 트리거들 및/또는 피드백을 제공할 수 있 는 하나 이상의 센서를 포함할 수 있다. 이미지 처리는 훈련 또는 시술 동안 발생할 수 있다. 이미지 처리는 디지털 캡처된 이미지들 및 라이브 비디오 획득 둘 다를 포함할 수 있다. 동기화는 둘 이상의 카메라 사이에서 발생할 수 있다. 동기화는 동기화 및 데이터 획득을 확인하기 위해 피드백 루프 제어를 구현하는 양방향 내비 게이션 시스템(BNS)을 수반할 수 있다. 이것은 인공 지능 시스템(예를 들어, 신경망, 프로세서 등) 에 의해 제어될 수 있고, 자율 상태에서 동작하는 시스템에 대응하여 자동화될 수 있다. 반자율 상태에서, 프 로세서는 로봇 어셈블리에 대한 모든 기능들 및 제어들을 수행할 수 있지만, (예를 들어, 사용자 로부터) 사용자 입력을 수신할 수도 있다. 프로그램 실행은 프로그램 실행을 위한 스크립트를 시작할 수 있는 단계에서 시작할 수 있다. 단계 에서, 프로세서는 제어기가 원격 눈 수술 훈련 시스템에 연결되어 있는지를 결정하기 위해 제어기 루프를 실행 할 수 있다. 단계에서, 프로세서는 제어기(예를 들어, 제어기)가 검출되는지를 결정할 수 있다. 제 어기가 검출되지 않는 경우, 프로그램은 단계로 복귀할 수 있다. 제어기가 검출되면, 프로그램은 단계 로 진행할 수 있다. 단계에서, 검출된 제어기는 로봇 어셈블리(예로서, 로봇 어셈블리)를 제어 하도록 구성될 수 있다. 검출된 제어기가 로봇 어셈블리를 제어하게 된 후, 단계에서, 프로세서는 검출된 제어기를 무효화할 수 있는 착신 연결(예로서, 무선 연결)이 존재하는지를 결정하기 위해 체크할 수 있다. 일부 양태들에서, 프로세서가 단계에서 제어기 루프를 실행할 때, 프로세서는 또한 단계에서 병렬 무 선 연결 루프를 계속 실행할 수 있다. 일부 양태들에서, 무선 연결 루프는 임의의 누락된 신호들, 지연들 및 통신 등을 정정하기 위한 적응적 피드백을 포함할 수 있다. 단계에서, 프로세서는 착신 무선 연결이 있는 지를 결정한다. 그래픽 사용자 인터페이스(GUI)가 일치하는 IP 주소 및 포트를 통해 연결되는 경우, 제어기 실 행이 차단될 수 있다. 로봇 어셈블리는 원격 GUI를 통해 제어될 수 있다. 이것은 GUI가 닫히거나 연결이 상실 될 때까지 일어날 수 있다. 착신 무선 연결(예를 들어, 무선 연결, 무선 페어링 등)이 존재하는 경우, 프 로그램은 프로세서가 클라이언트 디바이스(예를 들어, 랩톱, 태블릿, 컴퓨터 등)로부터 메시지들을 수신할 수 있는 단계로 진행한다. 일부 양태들에서, 메시지들은 로봇 어셈블리를 이동시키거나 달리 제어하기 위한 명령들을 포함할 수 있다. 메시지들이 수신되는 경우, 단계에서, 프로세서는 (예를 들어, 결정 엔진을 통 해) 메시지들이 유효한지를 결정하기 위해 체크할 수 있다. 그렇지 않다면, 프로그램은 단계로 복귀할 수 있다. 메시지들이 유효한 경우, 단계에서, 프로세서는 명령을 실행할 수 있다. 단계에서 착신 무선 연결이 검출된 후에, 단계에서, 프로세서는 연결이 상실되었는지를 결정하기 위해 타임아웃 카운터를 시작 할 수 있다. 단계에서, 프로세서는 타임아웃을 나타내는 타임아웃 값이 충족되었는지를 결정할 수 있다. 그렇다면, 단계에서 프로세서는 타임아웃 카운터가 타임아웃 카운터 임계치(예를 들어, 10) 이하인지를 결 정할 수 있다. 그렇지 않은 경우, 프로세서는 카운터를 증가시키고 단계로 복귀할 수 있다. 타임아웃 카 운터가 임계치를 충족한 경우, 프로그램은 단계로 진행하여, 클라이언트 디바이스로부터 로봇 어셈블리를 분리하고, 임의의 무선 연결(예를 들어, 무선 연결, 무선 페어링 등)을 해제할 수 있다. 일부 양태들에서, 로봇 어셈블리를 제어하기 위해, 그래픽 사용자 인터페이스(GUI)는 로봇 어셈블리 에 대한 사용자 경험 및 제어를 개선하도록 설계될 수 있다. 도 10a 내지 도 10c는 일부 예시적인 구현들에 따 른, 원격 눈 수술 훈련 시스템과 상호작용하는 예시적인 그래픽 사용자 인터페이스들을 도시한다. 도 10a는GUI의 예시적인 스크린샷이다. 도시된 바와 같이, GUI는 IP 주소 필드를 포함한다. 일부 양태들에서, 이 필드는 클라이언트 디바이스의 IP 주소로 자동으로 채워질 수 있다. 일부 구현들에서, 사용자 는 로봇 어셈블리에 연결하기 위해 IP 주소를 입력할 수 있다. 일부 양태들에서, 필드가 유효한 IP 주소로 채워지는 경우, 이것은 로봇 어셈블리가 무선 연결을 확립하였고, GUI에 의해 제어될 수 있 음을 나타낸다. 도 10b는 GUI 애플리케이션의 스타트업 후의 GUI의 스크린샷을 도시한다. 도시된 바와 같이, GUI의 특정 피처들은 스크린의 상단부에서 강조된다. 예를 들어, 스크린샷은 설정 피처, 모 드 피처, 진저 피처(ginger feature), 랜덤 지터 피처, 및 연결되지 않은 피처를 포 함한다. 일부 실시예들에서, 설정 피처는 GUI의 임의의 설정들을 조정하는 메뉴를 열 수 있다. 예를 들어, 설정 메뉴는 타겟 시스템(예를 들어, 클라이언트 시스템)에 연결하도록 구성된 연결 요소를 포 함할 수 있다. 설정 메뉴는 타겟으로부터 분리되도록 구성된 분리 요소를 더 포함할 수 있다. 설정 메뉴는 눈 부분(예컨대, 눈 부분(1060 및/또는 1070))의 하나 이상의 사분면에 대한 지터 설정을 조정하도록 구성된 사분 면 지터 기능을 위한 간격을 더 포함할 수 있다. 설정 메뉴는 프로파일 서브-윈도우를 열도록 구성된 프로파일 요소를 더 포함할 수 있다. 본 명세서에서는 특정 설정들이 설명되지만, 더 많거나 적은 설정 요소들이 가능하 다. 일부 양태들에서, 모드 피처는 GUI의 동작 모드에서 조정하기 위해 모드 메뉴를 열도록 선택 될 수 있다. 예를 들어, 모드 메뉴는 하나 이상의 눈의 랜덤 움직임 루프를 시작할 수 있는 랜덤 지터 모드를 포함할 수 있다. 모드 메뉴는 사용자가 드라이브 프로파일을 갖는 파일을 선택할 수 있는 파일 다이얼로그를 열 수 있는 시작 프로파일 요소를 포함할 수 있다. 특정 설정들 및 모드들이 본 명세서에 설명되지만, 추가적 인 또는 더 적은 모드들 및 설정들이 또한 가능하다. 도 10b에 추가로 도시된 바와 같이, GUI는 우안 부분 및 좌안 부분을 더 포함한다. 일부 양 태들에서, 눈 부분들(1060 및 1070) 중 하나 이상은 4개의 사분면을 포함할 수 있다. 도 10b의 예에서, 좌안 부분은 제1 사분면, 제2 사분면, 제3 사분면 및 제4 사분면을 포함한다. 또한, 해부학적 구역들, 중심, 상위, 코, 하위, 및 관자놀이(temporal) 구역을 포함한다. 일부 구현들에서, 눈 사분면들은 의사 또는 의료 전문가가 생체외에서 사체 눈으로 현실적인 라이브 수술 또는 진단 경험을 용이하게 하는 정적 방법들로 가능하지 않은 눈 해부구조의 특정 영역들을 강조, 시각화, 진단 및 치료하게 할 수 있다. 도 10c에 추가로 도시된 바와 같이, GUI는 우안 각막 및 좌안 각막을 더 포함한다. 일부 양 태들에서, 이것은 각막, 윤부, 중심, 중심옆, 주변 등의 하나 이상의 구역을 포함할 수 있다. 예를 들어, 도 10d 및 도 10e는 각막, 전이 구역, 원거리 구역, 중간 구역, 및 근거리 구역과 같은 다양한 광학 구역들을 도시 한다. 추가로 도시된 바와 같이, 광학 구역들은 해부학적 구역들, 즉 중심, 상위, 코, 하위, 및 관자놀이를 포함할 수 있다. 일부 구현들에서, 눈 구역들은 의사 또는 의료 전문가가 생체외에서 사체 눈으 로 현실적인 라이브 수술 또는 진단 경험을 용이하게 하는 정적 방법들로 가능하지 않은 눈 해부구조의 특정 영 역들을 강조, 시각화, 진단 및 치료하게 할 수 있다. 도 10e1에 추가로 도시된 바와 같이, GUI는 우안 공막 사분면들 및 좌안 공막 사분면들을 더 포함한다. 일부 양태들에서, 사분면들은 상위 코, 하위 코, 상위 관자놀이, 하위 관자놀이 또는 전체 360 원주를 포함하는 하나 이상의 사분면을 포함할 수 있다. 추가로 도시된 바와 같이, 광학 구역들은 해부학적 구역들, 즉 중심 , 상위, 코, 하위, 및 관자놀이를 포함할 수 있다. 일부 구현들에서, 눈 구역들은 의사 또는 의료 전문가가 생체외에서 사체 눈으로 현실적인 라이브 수술 또는 진단 경험을 용이하게 하는 정적 방법들로 가능하지 않은 눈 해부구조의 특정 영역들을 강조, 시각화, 진단 및 치료하게 할 수 있다. 도 10e에 추가로 도시된 바와 같이, GUI는 우안 망막 및 좌안 망막을 더 포함할 수 있다. 일부 양태들에서, 망막은 하나 이상의 구역을 포함할 수 있다. 도 10f는 하나 이상의 예시적인 망막 구역을 도 시한다. 도시된 바와 같이, · 구역 I은 시신경 주위의 망막의 작은 원이다. 원의 반경은 황반으로부터 시신경의 중심까지의 거리의 2배일 수 있다. · 구역 II는 구역 I을 둘러싸는 망막의 링 형상 섹션이며, 이는 코 쪽의 거상연(ora serrata)까지 연장 된다. · 구역 III은 관자놀이 망막의 초승달 형상 영역이다. 도 10f는 중심(중심와(Fovea), 황반 시신경 원반), 중간 주변부(와류 정맥들), 먼 주변부(거상연)를 포함하는 망막 랜드마크들을 더 포함한다. 일부 구현들에서, 눈 구역들은 의사 또는 의료 전문가가 눈 해부구조의 특정 영역들을 강조하고 생체외에서 사체 눈으로 현실적인 라이브 수술 또는 진단 경험을 용이하게 할 수 있다. 도 10f는 중심와, 중심와주위 상위, 중심와주위 코, 중심와주위 하위, 중심와주위 관자놀이; 중심와주위 상위, 중심와주위 코, 중심와주위 하위, 중심와주위 관자놀이를 포함하는 해부학적 구역들을 더 포함한다. 일부 구현들에서, 눈 구역들은 의사 또는 의료 전문가가 생체외에서 사체 눈으로 현실적인 라이브 수술 또는 진 단 경험을 용이하게 하는 정적 방법들로 가능하지 않은 눈 해부구조의 특정 영역들을 강조, 시각화, 진단 및 치 료하게 할 수 있다. 도 10g는 GUI 애플리케이션의 스타트업 후의 GUI의 예시적인 스크린샷을 도시한다. 도시된 바와 같이, GUI는 가상 조이스틱 영역을 포함한다. 가상 조이스틱 영역은 눈의 이동 영역을 보여 줄 수 있다. 사용자는 이 영역 내의 어딘가를 클릭할 수 있고, 로봇 어셈블리의 눈들은 그 위치로 이동할 수 있다. GUI는 곡선 슬라이더들을 포함하는 우안 부분을 더 포함한다. 곡선 슬라이더들 은 슬라이더들의 값들을 변경하고 눈의 움직임을 시작하기 위해 마우스 선택을 통해 미세 조정들을 제공 하도록 구성될 수 있다. GUI는 4개의 사분면(1071, 1072, 1073, 및 1074)을 더 포함한다. 사용자는 특 정 사분면의 일부를 클릭할 수 있고, 대응하는 눈은 할당된 사분면으로 이동할 수 있다. 도 10c의 예에 추가로 도시된 바와 같이, 사용자가 사분면들 중 하나 이상에 대해 우측 클릭을 수행하는 경우, 사분면 지터 버튼 이 사분면 지터 모드를 시작하는 것으로 보일 수 있다. 도 11a 및 도 11b는 일부 예시적인 구현들에 따른, 그래픽 사용자 인터페이스의 예시적인 프로파일 윈도우들을 도시한다. 예를 들어, 설정 메뉴로부터 프로파일 요소를 선택한 후에, 새로운 윈도우가 나타날 수 있다. 도 11a는 예시적인 프로파일 윈도우을 도시한다. 도시된 바와 같이, 프로파일 윈도우는 설정 메뉴 , 이동 영역, 수치 필드(들) 영역, 버튼(들) 영역, 및 데이터 포인트(들) 영역(111 0)을 포함할 수 있다. 일부 양태들에서, 설정 메뉴는 사용자가 현재 드라이빙 프로파일에 다수의 지연을 추가할 수 있게 하는 지연 추가 요소를 포함할 수 있다. 예를 들어, 사용자가 대략 100개의 포인트로 드라이빙 프로파일을 그리는 경우, 사용자는 움직임을 위한 엔진 시간을 제공할 필요가 있을 수 있다. 지연 추가 기능을 이용하여, 사용자는 리스트 내의 모든 포인트 사이의 지연 제어에서 현재 설정 지연을 추가할 수 있다. 설정 메뉴는 사용자가 현재 드라이빙 프로파일을 저장할 수 있게 하도록 구성된 저장 프로파일 요소를 더 포함 할 수 있다. 설정 메뉴는 사용자가 저장된 드라이빙 프로파일을 로딩할 수 있게 하도록 사용자가 파일 다이얼로그를 열 수 있게 하는 로딩 프로파일 요소를 더 포함할 수 있다. 설정 메뉴는 현재 셋업을 클리 어하도록 구성된 클리어 요소를 더 포함할 수 있다. 설정 메뉴는 사용자가 마우스 또는 다른 입력 디바이스로 드라이빙 경로를 그릴 수 있게 하도록 구성된 프리스타일 요소를 더 포함할 수 있다. 일부 양태들에서, 그래픽 사용자 인터페이스의 프로파일 윈도우와 관련하여, 양방향 내비게이션 시스템(BNS)은 동기화 및 데이터 획득을 확인하기 위해 피드백 루프 제어를 구현할 수 있다. BNS는 또한 로봇 어셈블리 및/또는 눈이 그래픽 사용자 인터페이스 상의 제어들에 따라 움직이고 있음을 확인할 수 있다. BNS는 로 봇 어셈블리 및/또는 눈의 위치를 확인하기 위해 하나 이상의 카메라 또는 이미지 캡처 디바이스를 포함할 수 있다. 하나 이상의 카메라 또는 이미지 캡처 디바이스는 또한 로봇 어셈블리를 제어하는 의료 전문가 또는 사용자에게 제어들의 정확성 및 진실성을 확인하기 위한 안내를 제공할 수 있다. 일부 구현들에서, 이동 영역은 사용자가 마우스를 이용한 선택을 통해 타겟 포인트를 선택하는 것을 가능 하게 하도록 구성될 수 있다. 선택 후에, X 및 Y 좌표들은 선택된 타겟 포인트로 변경될 수 있다. 프리스타일 모드 옵션이 선택되었다면, 사용자는 드라이빙 경로를 자유롭게 그릴 수 있다. 수치 필드(들) 영역은 X 좌표들, Y 좌표들, 지연(밀리초) 등에 대한 필드를 포함할 수 있다. 특정 필드들이 도 11a의 예에서 도시되지 만, 다른 필드들이 가능하다. 많은 경우에, 사용자는 지연 필드의 값만을 변경할 수 있다. 버튼(들) 영역 은 데이터 포인트를 추가하거나 지연을 추가하기 위한 버튼들을 포함할 수 있다. 일부 양태들에서, 이들 버튼들 중 하나를 누른 후에, 그 값이 리스트 박스(예를 들어, 데이터 포인트 영역)에 전송될 수 있다. 데이터 포인트 영역은 데이터 포인트들의 리스트 박스를 포함할 수 있다. 모든 할당된 위치들 및 지연들 이 이 리스트에 나타날 수 있다. 하나 이상의 요소에 대한 우측 클릭으로 리스트 박스 내의 데이터 포인트들을 삭제하는 것이 가능할 수 있다. 데이터 포인트 영역의 이 리스트 내의 데이터로, XML 파일이 나중에 생 성될 수 있다. 도 11b는 예시적인 프로파일 윈도우를 도시한다. 도시된 바와 같이, 프로파일 윈도우는 이동 영역 , 수치 필드(들) 영역, 버튼(들) 영역, 및 데이터 포인트(들) 영역을 포함한다. 추가로 도시된 바와 같이, 데이터 포인트(예를 들어, 37; 62)는 데이터 포인트(들) 영역에서 선택되었고 이 동 영역에서 강조된다. 도 12는, 일부 예시적인 구현들에 따라, 설명되는 디바이스들 및/또는 구성요소들 중 하나 이상을 구현하는데 이용될 수 있는 예시적인 컴퓨팅 장치를 도시한다. 예를 들어, 컴퓨팅 장치의 적어도 일부는 클라 이언트 디바이스, 서버, 프로세서 등의 적어도 일부를 구현하는데 이용될 수 있다. 컴퓨팅 장 치는 본 명세서에 설명된 프로세스들 중 하나 이상을 수행할 수 있다. 도시된 바와 같이, 컴퓨팅 장치는 본 명세서에 설명된 것들과 일치하는 동작들을 구현할 수 있는 명령어 들을 실행하기 위해 프로세서와 같은 하나 이상의 프로세서를 포함할 수 있다. 장치는 실행가능한 명령어들 및/또는 정보를 저장하는 메모리를 포함할 수 있다. 메모리는 솔리드 스테이트 메모리, 솔리드 스테이트 디스크 드라이브들, 자기 디스크 드라이브들, 또는 임의의 다른 정보 저장 디바이스를 포함할 수 있다. 일부 양태들에서, 메모리는 데이터베이스의 적어도 일부를 위한 저장소를 제공할 수 있다. 장 치는 유선 네트워크 또는 무선 네트워크(예를 들어, 무선 연결)에 대한 입력/출력 디바이스들(124 0)을 포함할 수 있다. 무선 네트워크들은 라디오 안테나, Wi-Fi, WiMax, WAN, WAP 블루투스, 위성, 및 셀룰러 네트워크들(2G/3G/4G/5G), 및/또는 임의의 다른 무선 네트워크를 포함할 수 있다. 무선 통신을 실행하기 위해, 입력/출력 디바이스들은, 예를 들어, 하나 이상의 안테나를 이용할 수 있다. 장치는 그래픽 사용자 인터페이스와 같은 하나 이상의 사용자 인터페이스를 포함할 수 있다. 사용 자 인터페이스는 하드웨어, 소프트웨어, 또는 펌웨어 인터페이스들, 예컨대 키보드, 마우스, 또는 다른 인터페 이스를 포함할 수 있으며, 그 중 일부는 디스플레이와 통합된 터치스크린을 포함할 수 있다. 디스플레이는 판 촉 제안들 또는 현재 재고와 같은 정보를 표시하고, 사용자에게 프롬프트들을 제공하고, 사용자 입력을 수신하 는 것 등에 이용될 수 있다. 다양한 구현들에서, 사용자 인터페이스는 하나 이상의 주변 디바이스를 포함할 수 있고/있거나, 사용자 인터페이스는 이러한 주변 디바이스들과 통신하도록 구성될 수 있다. 일부 양태들에서, 사용자 인터페이스는 본 명세서에 설명된 센서들 중 하나 이상을 포함할 수 있고/있거나 본 명세서에 설명된 센서들 중 하나 이상에 대한 인터페이스를 포함할 수 있다. 이러한 센서들의 동작은 센서 모 듈에 의해 적어도 부분적으로 제어될 수 있다. 장치는 또한 센서들 또는 다른 사용자 인터페이스들로부 터 수신된, 네트워크 인터페이스에 의해 수신된 및/또는 전송된 것 등의 정보를 필터링할 수 있는 입력 및 출력 필터를 포함할 수 있다. 예를 들어, 센서들을 통해 검출된 신호들은 적절한 신호 조정을 위해 필터를 통과할 수 있고, 필터링된 데이터는 그 후 (예를 들어, 입력/출력 디바이스들을 통해 결과들 또는 표시를 전송하 기 전에) 검증 및 처리를 위해 프로세서에 전달될 수 있다. 일부 양태들에서, 필터는 본 명세서에 설명 된 적응적 피드백 루프의 일부일 수 있다. 장치는 하나 이상의 전원의 이용을 통해 전력을 공급받을 수 있다. 예시된 바와 같이, 장치의 구성요소들 중 하나 이상은 시스템 버스를 통해 전력을 통신 및/ 또는 수신할 수 있다. 도 13은 일부 예시적인 구현들에 따른 원격 눈 수술 훈련을 위한 방법의 흐름도를 도시한다. 다양한 구현들에 서, 방법(또는 그 적어도 일부)은 로봇 어셈블리, 클라이언트 디바이스, 서버, 프로세서 , 컴퓨팅 장치, 다른 관련 장치들 및/또는 그 일부 중 하나 이상에 의해 수행될 수 있다. 방법은, 예를 들어, 장치가 로봇 어셈블리를 초기화할 수 있는 동작 블록에서 시작할 수 있다. 일부 양태들에서, 로봇 어셈블리를 초기화하는 것은 눈 수술을 위한 레이저가 배치되는 위치에 서 로봇 어셈블리를 초기화하는 것을 포함할 수 있다. 로봇 어셈블리를 초기화하는 것은 또한 (예를 들어, 로봇 눈 어셈블리를 통해) 로봇 어셈블리 내에 유리 눈, 나무 눈, 사체 눈 등(예를 들어, 눈 )을 설치하는 것을 포함할 수 있다. 로봇 어셈블리를 초기화하는 것은 또한 눈 추적 시스템을 이용 하여 눈의 위치를 추적하고, 그 위치가 원하는 위치에 있음을 확인하는 것을 포함할 수 있다. 예를 들어, 의사, 조정자, 기술자 또는 다른 의료 전문가는 주어진 훈련 실습을 찾을 위치로 사람 또는 동물 또는 시뮬레이 션된 사람 또는 동물을 지향시킬 수 있다. 사용자(예를 들어, 사용자)는 하나 이상의 눈을 타겟 위 치로 이동시키도록 로봇 어셈블리에 명령할 수 있다. 눈 추적 시스템은 하나 이상의 눈이 타겟 위치에 있 는지를 검증할 수 있다. 눈 추적 시스템이 하나 이상의 눈이 타겟 위치에 있지 않다고 결정하면, 사용자 는 조정을 행할 수 있거나, 또는 로봇 어셈블리는 결정된 눈 위치가 타겟 위치의 임계치 내에 있을 때까지 하나 이상의 눈의 눈 위치를 (예를 들어, AI, 신경망 등을 이용하여 자율 상태에서) 자동으로 조정할 수 있다. 눈 추적 인공 지능 또는 신경망은 임의의 생체외 동물 또는 사람 연구에 이용되도록 훈 련될 수 있다. 일부 양태들에서, 눈 추적 인공 지능 또는 신경망은 특정 타겟을 찾거나 보도록 훈련될 수있다. 예를 들어, 눈 홀더 내부의 카메라 레이저 포인터 또는 미러는 스크린 상의 외부 포인트 소스 또는 스폿을 검출하거나 따를 수 있다. 눈 추적 피드백 시스템은 하나 이상의 눈이 제시된 임의의 타겟을 추적 할 수 있을 때까지 눈을 향하게 하고 스폿을 제어할 수 있다. 눈 추적기는 눈을 따라갈 수 있고, 카메라(또는 미러)는 눈들이 보고 있는 곳을 추적하고, 이들이 일치할 때까지 정정할 수 있다. 이 시스템은 하나 이상 의 눈의 눈 방향의 미세, 동적, 실시간 조정들을 허용한다. 로봇 어셈블리는 눈 추적 시스템에 그리고 그로부터 피드백을 제공하기 위해 관계형 데이터베이스, 신경망 (예로서, 신경망) 등과 함께 이용될 수 있다. 이것은 눈 추적기 및 로봇 어셈블리의 눈 움직임들이 양방향 피드백과 실시간으로 동기화되는 것을 허용할 수 있다. 도 14a 및 도 14b는 일부 예시적인 구현들에 따 른 예시적인 로봇 어셈블리(예를 들어, 로봇 어셈블리) 및 눈 추적기를 도시한다. 자연스런 또는 다른 사람의 눈 움직임은 신경망(예를 들어, 신경망 또는 다른 AI) 제어기를 이용하여 로봇 어셈블리 및/또는 애니매트로닉스 어셈블리로 시뮬레이션될 수 있다. 자연적인 사람의 눈 움직임의 비디오 이미지들은 AI 시스템에 대한 훈련 세트로서 이용될 수 있다. 스코어링은 눈 추적 또는 다른 외부 시스 템 및 주석부기를 통해 달성될 수 있다. 이는 로봇 눈 시스템(예를 들어, 로봇 어셈블리)에 의한 고충실 도 시뮬레이션의 자연스런 눈 움직임을 제공할 것이다. 살아 있는 사람에 대해 눈 추적기를 이용하면, 로봇 눈 시뮬레이터는 직접 또는 기록된 연결로 자연스런 눈 모션을 모방할 수 있다. 방법은, 예를 들어, 장치가 하나 이상의 컴퓨팅 디바이스에 연결할 수 있는 동작 블록으로 진행할 수 있다. 일부 양태들에서, 하나 이상의 컴퓨팅 디바이스에 연결하는 것은 원격 훈련 환경(예로서, 원 격 훈련 환경)에 연결하는 것을 포함할 수 있다. 예를 들어, 의사(예를 들어, 사용자)는 눈 수술 훈 련이 수행될 수 있는 그룹 회의(예를 들어, 영상 회의)에 로그인할 수 있다. 일부 양태들에서, 다른 디바이스 들 또는 사용자들(예를 들어, 레이저, 카메라, 컴퓨터들, 조정자, 다른 의사들 등)은 그룹 회의(예를 들어, 원 격 훈련 환경)에 로그인할 수 있다. 그룹 회의는 사용자들이 서로 통신하고/하거나 가장 원격의 훈 련 환경에 연결된 하나 이상의 컴퓨팅 디바이스(예를 들어, 레이저, 로봇 어셈블리, 서버, 클라이언 트 디바이스 등) 목표를 제어하는 것을 허용할 수 있다. 하나 이상의 컴퓨팅 디바이스는 클라이언트 디바 이스, 서버, 컴퓨팅 장치 등을 포함할 수 있다. 일부 양태들에서, 원격 훈련 환경은 눈 수술 을 위한 로봇 어셈블리 및/또는 레이저에 대한 연결을 포함할 수 있다. 방법은 동작 블록으로 진행할 수 있으며, 여기서 장치는 예를 들어 하나 이상의 컴퓨팅 디바 이스에 의해 로봇 어셈블리를 동작시킬 수 있다. 일부 양태들에서, 로봇 어셈블리를 동작시키는 것은 치료 훈 련, 수술 훈련, 시술 훈련, 치료 계획, 치료후 검토 등을 수행하는 것을 포함할 수 있다. 예를 들어, 조정자 (예를 들어, 의사 훈련자 또는 강사)는 의사 사용자(예를 들어, 사용자)와 함께 결정된 훈련 실습을 진행 할 수 있다. 조정자는 결정된 훈련 실습을 수행하기 위해 의사 사용자에게 눈 수술을 위한 로봇 어셈블리 및/또는 레이저에 대한 제어를 제공할 수 있다. 일부 양태들에서, 결정된 훈련 실습은 백내장 수술, 백내장 라 식, 펨토초 수술, MIGS 이식 수술, 원추각막 수술, 레이저 공막 미세 천공 등과 같은 시뮬레이션된 수술을 수행 하는 것을 포함할 수 있다. 도 15 내지 도 20은 본 명세서에서 설명되는 일부 예시적인 구현들에 따른, 로봇 어셈블리(예로서, 로봇 어셈블리)를 이용하는 예시적인 이용 사례의 수술들/시술들을 나타낸다. 특정 수 술들/시술들이 본 명세서에서 설명되고 도시되지만, 라이브, 가상 또는 원격 눈 수술 훈련을 위한 방법들 및 장 치는 다른 수술들, 시술들, 연구들 등에 적용될 수 있다. 시스템의 일부 변형들에서, 도 21a 내지 도 21c에 도시된 바와 같이, 시스템은 다양한 자극 및 광 반복에 기계 적으로 반응하는 \"홍채\" 셔터를 더 포함한다. 시스템은 또한 복수의 홍채 크기에 기계적으로 고정될 수 있다. 시스템은 또한 눈이 사람 또는 동물 눈의 기능과 병행하여 작업할 수 있게 하는 콘트라스트를 위해 설계된다. 시스템은 또한 정상적인 사람의 눈 기능을 시뮬레이션하도록 설계된다. 방법은 동작 블록으로 진행할 수 있으며, 여기서 장치는 예를 들어 결정된 훈련 실습 동안 사람 또는 동물의 눈 움직임을 시뮬레이션할 수 있다. 사람 또는 동물의 눈 움직임을 시뮬레이션하는 것은 로 봇 어셈블리의 눈의 움직임을 제어하는 것을 포함할 수 있다. 일부 양태들에서, 눈 수술들 또는 눈 시술 들은, 사람 또는 동물의 눈을 수술 또는 시술을 위한 원하는 위치(예를 들어, 앞을 보고 있는 눈들, 오른쪽을 보고 있는 눈들, 왼쪽을 보고 있는 눈들, 위를 보고 있는 눈들, 아래를 보고 있는 눈들 등)에 위치시키기 위해, 사람 또는 동물에게 그 시선을 고정시키거나 또는 물체 상에 그 눈들을 포커싱하도록 지시하는 것을 포함할 수 있다. 예를 들어, 눈의 움직임을 제어하는 것은 스크린 또는 다른 위치(예를 들어, GUI) 상에 표시되는 타겟을 보도록 눈(예를 들어, 눈)을 지향시키는 것을 포함할 수 있다. 일부 양태들에서, 눈의 움직임을제어하는 것은 눈에 대한 랜덤 지터 움직임을 개시하는 것을 포함할 수 있다. 눈의 움직임을 제어하는 것은 사 용자 인터페이스(예를 들어, GUI)를 통해 움직임을 제어하는 것을 포함할 수 있다. 눈의 움직임을 제어 하는 것은 제어기(예를 들어, 제어기)를 동작시키는 것을 포함할 수 있다. 방법은 동작 블록으로 진행할 수 있으며, 여기서 장치는 예를 들어 눈 수술을 위해 레이저를 동작시켜 결정된 훈련 실습을 수행할 수 있다. 눈 수술을 위해 레이저를 동작시키는 것은 하나 이상의 레이저 를 이용하여 로봇 어셈블리의 눈(예를 들어, 눈)의 일부를 재성형하는 것을 포함할 수 있다. 일부 양태들 에서, 레이저를 동작시키는 것은 눈이 결정된 훈련 실습을 위한 원하는 위치에 있는 것으로 결정하는 것을 포함 할 수 있다. 일부 구현들에서, 방법은 추가적으로 또는 대안적으로 장치가 예를 들어 로봇 어셈블리를 동작시켜, 눈 추적 검증, 치료 각도 검증, 스크린 교정, 실험실 전개, 파면 측정, 눈 측정, 망막 치료, 시뮬레 이션된 눈 수술 등을 수행하는 단계를 포함할 수 있다. 일부 양태들에서, 눈 추적 검증은 레이저를 이용하여 눈의 초점을 결정하는 것을 포함할 수 있다. 일부 양태들에서, 눈 홀더(예를 들어, 눈 홀더)는 홀더 내의 눈의 깊이 제어를 유익하게 제공할 수 있다. 예를 들어, 눈 홀더는 폴더 내의 눈 의 위치에 대한 수정들을 허용할 수 있다. 일부 양태들에서, 방법은 치료후 검토 또는 실습후 검토 를 수행하는 단계를 포함할 수 있으며, 훈련 실습의 결과들이 측정되고 분석될 수 있다. 눈 추적 및/또는 눈 추적 검증은 온보드 카메라를 이용하여 하나 이상의 눈의 위치를 추적하는 것을 포함 할 수 있다. 눈 추적 데이터는 데이터를 해석하고 하나 이상의 눈의 위치를 결정하기 위해 인공 지능(AI) 피드백 루프(예를 들어, 신경망)에 입력될 수 있다. 일부 양태들에서, 레이저는 눈 홀더에 배치된 하나 이상의 눈의 초점 또는 시선을 시뮬레이션하기 위해 눈 홀더에 배치될 수 있다. 하나 이상의 미러는 레이저 빔을 반사하고 하나 이상의 눈의 눈 움직임의 각도를 나타내도록 배치될 수 있다. 원하는 위치에 대한 타겟은 사람 또는 동물이 보고 있어야 하는 곳에 대해 선택될 수 있다. 눈이 올바른 위치로 이동될 때, 레이저 빔은 미러에서 반사되어 원하는 위치에서 타겟에 부딪칠 수 있다. 이 위치는 기록될 수 있 고, X 및 Y 축에 대한 좌표들은 메모리에 저장될 수 있다. 방법 및/또는 그 일부의 수행은 눈 수술들을 위한 의사들의 개선된 실생활의 현실적인 시뮬레이션 및 훈 련을 허용할 수 있다. 예를 들어, 로봇 어셈블리의 설정들 및/또는 모드들은 사람 또는 동물의 동적 실시 간 및 현실적인 눈 움직임(예를 들어, 지향된 시선 모드, 요동, 지터 모드, 사람 모드 등)을 시뮬레이션할 수 있다. 본 명세서에 설명된 주제의 하나 이상의 양태 또는 피처는 디지털 전자 회로, 집적 회로, 특수 설계된 주문형 집적 회로(ASIC), 필드 프로그래밍가능한 게이트 어레이(FPGA), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합으로 실현될 수 있다. 이러한 다양한 양태들 또는 피처들은 저장 시스템, 적어도 하나의 입력 디바 이스, 및 적어도 하나의 출력 디바이스로부터 데이터 및 명령어들을 수신하고, 이들에 데이터 및 명령어들을 전 송하도록 결합되는, 특수 목적 또는 범용일 수 있는, 적어도 하나의 프로그래밍가능한 프로세서를 포함하는 프 로그래밍가능한 시스템 상에서 실행가능하고/하거나 해석가능한 하나 이상의 컴퓨터 프로그램에서의 구현을 포 함할 수 있다. 프로그래밍가능한 시스템 또는 컴퓨팅 시스템은 클라이언트들 및 서버들을 포함할 수 있다. 클 라이언트 및 서버는 일반적으로 서로 떨어져 있고, 통상적으로 통신 네트워크를 통해 상호작용한다. 클라이언 트와 서버의 관계는 각각의 컴퓨터들 상에서 실행되고 서로 클라이언트-서버 관계를 갖는 컴퓨터 프로그램들에 의해 발생한다. 프로그램들, 소프트웨어, 소프트웨어 애플리케이션들, 애플리케이션들, 구성요소들, 또는 코드라고도 지칭될 수 있는 이러한 컴퓨터 프로그램들은 프로그래밍가능한 프로세서에 대한 기계 명령어들을 포함하고, 상위 레벨 절 차 및/또는 객체 지향 프로그래밍 언어로, 그리고/또는 어셈블리/기계 언어로 구현될 수 있다. 본 명세서에서 이용될 때, \"기계 판독가능한 매체\"라는 용어는 기계 명령어들을 기계 판독가능한 신호로서 수신하는 기계 판독 가능한 매체를 포함하는 프로그래밍가능한 프로세서에 기계 명령어들 및/또는 데이터를 제공하는데 이용되는 예 를 들어 자기 디스크, 광학 디스크, 메모리 및 프로그래밍가능한 로직 디바이스(PLD)와 같은 임의의 컴퓨터 프 로그램 제품, 장치 및/또는 디바이스를 지칭한다. 용어 \"기계 판독가능한 신호\"란 기계 명령어 및/또는 데이터 를 프로그래밍가능한 프로세서에 제공하는데 이용되는 임의의 신호를 말한다. 기계 판독가능한 매체는, 예를 들어, 비일시적 솔리드 스테이트 메모리 또는 자기 하드 드라이브 또는 임의의 등가의 저장 매체와 같이, 이러 한 기계 명령어들을 비일시적으로 저장할 수 있다. 기계 판독가능한 매체는, 예를 들어, 하나 이상의 물리적 프로세서 코어와 연관된 프로세서 캐시 또는 다른 랜덤 액세스 메모리에서와 같이, 일시적 방식으로 이러한 기계 명령어들을 대안적으로 또는 추가적으로 저장할 수 있다. 사용자와의 상호작용을 제공하기 위해, 본 명세서에 설명된 주제의 하나 이상의 양태 또는 피처는, 예를 들어 사용자에게 정보를 표시하기 위한 음극선관(CRT) 또는 액정 디스플레이(LCD) 또는 발광 다이오드(LED) 모니터와 같은 디스플레이 디바이스, 및 예를 들어 사용자가 컴퓨터에 입력을 제공할 수 있는 조이스틱, 터치스크린, 음 성 명령 프로세서, 마우스 또는 트랙볼과 같은 포인팅 디바이스 및 키보드를 갖는 컴퓨터 상에서 구현될 수 있 다. 다른 종류의 디바이스들이 또한 사용자와의 상호작용을 제공하는데 이용될 수 있다. 예를 들어, 사용자에 게 제공되는 피드백은 예를 들어 시각 피드백, 청각 피드백, 촉각 피드백, 데이터 피드백, 디지털 피드백, 가상 피드백 등과 같은 임의의 형태의 감각 피드백일 수 있고; 사용자로부터의 입력은 음향 입력, 음성 입력, 촉각 입력 등을 포함하는 임의의 형태로 수신될 수 있다. 다른 가능한 입력 디바이스들은 터치 스크린들 또는 다른 터치 감응 디바이스들, 예컨대 단일 또는 멀티-포인트 저항성 또는 용량성 트랙패드들, 음성 인식 하드웨어, 소 프트웨어, 계산 회로들, 광학 스캐너들, 광학 포인터들, 디지털 이미지 캡처 디바이스들 및 연관된 해석 소프트 웨어 등을 포함한다. 본 명세서에 설명된 주제는 원하는 구성에 따라 시스템들, 장치, 방법들, 및/또는 물품들로 구현될 수 있다. 전술한 설명에 제시된 구현들은 본 명세서에 설명된 주제와 일치하는 모든 구현들을 나타내지 않는다. 그 대신 에, 이들은 설명된 주제에 관련된 양태들과 일치하는 일부 예들에 불과하다. 몇몇 변형들이 위에서 상세히 설 명되었지만, 다른 수정들 또는 추가들이 가능하다. 특히, 본 명세서에 제시된 것들에 더하여 추가 피처들 및/ 또는 변형들이 제공될 수 있다. 예를 들어, 위에 설명된 구현들은 개시된 피처들의 다양한 조합들 및 하위 조 합들 및/또는 위에 개시된 몇 개의 추가 피처들의 조합들 및 하위 조합들에 관한 것일 수 있다. 위의 설명들 및 청구항들에서, 요소들 또는 피처들의 결합 리스트가 선행하는 \"~ 중 적어도 하나\" 또는 \"~ 중 하나 이상\"과 같은 문구들이 발생할 수 있다. 용어 \"및/또는\"은 또한 2개 이상의 요소 또는 피처의 리스트에서 발생할 수 있다. 그것이 이용되는 문맥에 의해 달리 암시적으로 또는 명시적으로 모순되지 않는 한, 이러한 문 구들은 열거된 요소들 또는 피처들 중 임의의 것을 개별적으로 또는 다른 열거된 요소들 또는 피처들 중 임의의 것과 조합하여 열거된 요소들 또는 피처들 중 임의의 것을 의미하는 것으로 의도된다. 예를 들어, 문구들 \"A 및 B 중 적어도 하나\"; \"A 및 B 중 하나 이상\"; 및 \"A 및/또는 B\"는 각각 \"A 단독, B 단독, 또는 A와 B 함께\"를 의미하도록 의도된다. 유사한 해석은 또한 3개 이상의 항목을 포함하는 리스트들을 위해 의도된다. 예를 들어, 문구들 \"A, B, 및 C 중 적어도 하나\"; \"A, B, 및 C 중 하나 이상\"; 및 \"A, B, 및/또는 C\"는 각각 \"A 단 독, B 단독, C 단독, A와 B 함께, A와 C 함께, B와 C 함께, 또는 A와 B와 C 함께\"를 의미하도록 의도된다. 위 에서 그리고 청구항들에서 용어 \"~에 기반하여\"의 이용은 \"~에 적어도 부분적으로 기반하여\"를 의미하도록 의도 되어, 열거되지 않은 피처 또는 요소가 또한 허용가능하다. 예시된 방법들은 단지 예시적이다. 방법들이 특정 동작 흐름을 갖는 것으로서 예시되지만, 2개 이상의 동작들 이 단일 동작으로 결합될 수 있고, 단일 동작이 2개 이상의 별도의 동작들에서 수행될 수 있고, 예시된 동작들 중 하나 이상이 다양한 구현예들에서 존재하지 않을 수 있고/있거나, 예시되지 않은 추가적인 동작들이 방법들 의 일부일 수 있다. 또한, 첨부 도면들에 도시되고/되거나 본 명세서에 설명된 로직 흐름들은 바람직한 결과들 을 달성하기 위해 도시된 특정 순서, 또는 순차적 순서를 반드시 요구하지는 않는다. 다른 구현들은 이하의 청 구항들의 범위 내에 있을 수 있다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면3a 도면3b 도면3c 도면3d 도면3e 도면4a 도면4b 도면4c 도면5a 도면5b 도면5c 도면5d 도면6 도면7 도면8a 도면8b 도면9a 도면9b 도면10a 도면10b 도면10c 도면10d 도면10ee 도면10ea 도면10f 도면10g 도면11a 도면11b 도면12 도면13 도면14a 도면14b 도면15 도면16 도면17 도면18 도면19 도면20 도면21a 도면21b 도면21c 도면22"}
{"patent_id": "10-2024-7008766", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 포함되어 그 일부를 구성하는 첨부 도면들은 본 명세서에 개시된 주제의 특정 양태들을 보여주며, 설명과 함께, 개시된 구현들과 연관된 원리들 중 일부를 설명하는 것을 돕는다. 도 1은 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련을 위한 시스템을 도시한다. 도 2a는 일부 예시적인 구현들에 따른, 원격 훈련 환경을 도시한다. 도 2b는 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련을 위한 시스템의 블록도를 도시한다. 도 2c는 일부 예시적인 구현들에 따른, 예시적인 무선 네트워크에 대한 다이어그램을 도시한다. 도 2d는 일부 예시적인 구현들에 따른, 클라우드 기반 시스템 아키텍처를 도시한다. 도 3a는 일부 예시적인 구현들에 따른, 로봇 어셈블리의 사시도이다. 도 3b 내지 도 3e는 일부 예시적인 구현들에 따른, 동물 얼굴을 갖는 페이스 플레이트의 예시적인 프로파일 뷰 들을 도시한다. 도 4a 내지 도 4c는 일부 예시적인 구현들에 따른, 차폐부를 갖는 예시적인 로봇 어셈블리를 도시한다. 도 5a는 일부 예시적인 구현들에 따른, 로봇 눈 어셈블리의 분해도이다. 도 5b는 일부 예시적인 구현들에 따른, 눈 흡입 홀더 메커니즘을 포함하는 로봇 눈 어셈블리의 측면도이다. 도 5c 및 도 5d는 눈 홀더를 포함하는 흡입 컵 배열을 도시한다. 도 6은 일부 예시적인 구현들에 따른, 애니매트로닉스 어셈블리의 사시도이다. 도 7은 일부 예시적인 구현들에 따른, 로봇 어셈블리의 분해도이다. 도 8a는 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련을 위한 시스템의 블록도를 도시한다. 도 8b는 일부 예시적인 구현들에 따른, 예시적인 신경망을 도시한다. 도 9a는 일부 예시적인 구현들에 따른, 예시적인 프로그램 실행의 흐름도를 도시한다. 도 9b는 일부 예시적인 구현들에 따른, 눈 추적 피처를 포함하는, 예시적인 작업흐름 및 자동 피드백 루프들을 도시한다. 도 10a 내지 도 10c는 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련 시스템과 상호작용하는 예시적인 그래픽 사용자 인터페이스들을 도시한다. 도 10d 및 도 10e는 일부 예시적인 구현들에 따른, 다양한 광학 구역들을 도시한다. 도 10e1은 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련 시스템과 상호작용하는 예시적인 그래픽 사용자 인 터페이스를 도시한다. 도 10f는 일부 예시적인 구현들에 따른, 하나 이상의 예시적인 망막 구역을 도시한다. 도 10g는 GUI의 예시적인 스크린샷을 도시한다. 도 11a 및 도 11b는 일부 예시적인 구현들에 따른, 그래픽 사용자 인터페이스의 예시적인 프로파일 윈도우들을 도시한다. 도 12는 일부 예시적인 구현들에 따른, 예시적인 컴퓨팅 장치의 블록도를 도시한다. 도 13은 일부 예시적인 구현들에 따른, 원격 눈 수술 훈련을 위한 방법의 예를 도시한다. 도 14a 및 도 14b는 일부 예시적인 구현들에 따른, 예시적인 로봇 어셈블리 및 눈 추적기를 도시한다. 도 15는 일부 예시적인 구현들에 따른, 백내장 라식 수술을 위한 예시적인 이용 사례를 도시한다. 도 16은 일부 예시적인 구현들에 따른, 펨토초 수술을 위한 예시적인 이용 사례를 도시한다. 도 17은 일부 예시적인 구현들에 따른, 백내장 수술을 위한 예시적인 이용 사례를 도시한다. 도 18은 일부 예시적인 구현들에 따른, 미소 침습 녹내장 수술(MIGS) 이식을 위한 예시적인 이용 사례를 도시한 다. 도 19는 일부 예시적인 구현들에 따른, 원추 각막 수술을 위한 예시적인 이용 사례를 도시한다. 도 20은 레이저 공막 미세 천공을 위한 예시적인 이용 사례를 도시한다. 도 21a 내지 도 21c는 홍채 셔터 피처의 구현들을 나타낸다. 도 22는 복수의 외부 입력과 통신할 수 있는 데이터 저장소 및 데이터베이스의 표현을 나타낸다. 시스템은 또 한 원격 측정 데이터를 수집하고, 다양한 극단 디바이스에 대한 출력들을 생성할 수 있다. 실용적일 때, 유사한 참조 번호들은 유사한 구조들, 피처들, 또는 요소들을 나타낸다."}
