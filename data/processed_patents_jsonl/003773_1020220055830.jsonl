{"patent_id": "10-2022-0055830", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0156461", "출원번호": "10-2022-0055830", "발명의 명칭": "지식 증류를 활용한 그룹 기반의 학습을 수행하는 전자장치 및 방법", "출원인": "아주대학교산학협력단", "발명자": "황원준"}}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "지식 증류(knowledge distillation)를 활용한 그룹 기반의 학습을 수행하는 전자장치에 있어서,복수의 학생 네트워크를 학습 데이터를 이용하여 학습한 후 각 학생 네트워크의 학습 능력을 식별하고,상기 학습 능력을 기준으로 상기 복수의 학생 네트워크 중 제1복수의 학생 네트워크를 복수의 교사 네트워크로전환하고,상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터에 기초하여 상기 복수의 교사 네트워크를 학습시키고,상기 학습된 복수의 교사 네트워크를 이용하여 상기 복수의 학생 네트워크 중 나머지 제2복수의 학생 네트워크를 학습시키는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 학생 네트워크의 손실에 대한 각 학생 네트워크의 손실의 비율을 나타내는 제어 가중치에 기초하여상기 오류 데이터의 수를 식별하고, 상기 오류 데이터 별 손실을 기반으로 상기 복수의 학생 네트워크에 대한 오류 데이터의 수만큼 상기 복수의 교사 네트워크를 학습시키는 전자장치."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 각 학생 네트워크에 대한 오류 데이터의 수를 합산하여 상기 복수의 학생 네트워크에 대한 오류 데이터의수를 식별하는 전자장치."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 교사 네트워크 중 상기 학습 능력이 기 정의된 값 이상인 적어도 하나의 교사 네트워크를 고정 교사 네트워크로 식별하고,상기 고정 교사 네트워크를 이용하여 나머지 상기 복수의 교사 네트워크를 학습시키는 전자장치."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는,상기 학습 능력이 높은 순으로 상기 복수의 학생 네트워크를 나열하여 상기 제1복수의 학생 네트워크를 식별하는 전자장치."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0156461-3-제1항에 있어서,상기 프로세서는,상기 제2복수의 학생 네트워크를 학습시킨 후 상기 복수의 교사 네트워크를 상기 복수의 학생 네트워크에 포함되도록 다시 전환하는 전자장치."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "전자장치가 지식 증류(knowledge distillation)를 활용한 그룹 기반의 학습을 수행하는 방법에 있어서,복수의 학생 네트워크를 학습 데이터를 이용하여 학습한 후 각 학생 네트워크의 학습 능력을 식별하는 단계;상기 학습 능력을 기준으로 상기 복수의 학생 네트워크 중 제1복수의 학생 네트워크를 복수의 교사 네트워크로전환하는 단계;상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터에 기초하여 상기 복수의 교사 네트워크를 학습시키는 단계;상기 학습된 복수의 교사 네트워크를 이용하여 상기 복수의 학생 네트워크 중 나머지 제2복수의 학생 네트워크를 학습시키는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 복수의 교사 네트워크를 학습시키는 단계는,상기 복수의 학생 네트워크의 손실에 대한 각 학생 네트워크의 손실의 비율을 나타내는 제어 가중치에기초하여, 상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터의 수를 식별하는 단계;상기 오류 데이터 별 손실을 기반으로 상기 복수의 학생 네트워크에 대한 오류 데이터의 수만큼 상기 복수의 교사 네트워크를 학습시키는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 복수의 교사 네트워크를 학습시키는 단계는,상기 각 학생 네트워크에 대한 오류 데이터의 수를 합산하여 상기 복수의 학생 네트워크에 대한 오류 데이터의수를 식별하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 복수의 교사 네트워크를 학습시키는 단계는,상기 복수의 교사 네트워크 중 상기 학습 능력이 기 정의된 값 이상인 적어도 하나의 교사 네트워크를 고정 교사 네트워크로 식별하는 단계;상기 고정 교사 네트워크를 이용하여 나머지 상기 복수의 교사 네트워크를 학습시키는 단계를 더 포함하는방법."}
{"patent_id": "10-2022-0055830", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 복수의 교사 네트워크로 전환하는 단계는,상기 학습 능력이 높은 순으로 상기 복수의 학생 네트워크를 나열하여 상기 제1복수의 학생 네트워크를 식별하는 단계를 포함하는 방법.공개특허 10-2023-0156461-4-청구항 12 제7항에 있어서,상기 제2복수의 학생 네트워크를 학습시키는 단계 이후에,상기 복수의 교사 네트워크를 상기 복수의 학생 네트워크에 포함되도록 다시 전환하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 지식 증류(knowledge distillation)를 활용한 그룹 기반의 학습을 수행하는 전자장 치에 있어서, 복수의 학생 네트워크를 학습 데이터를 이용하여 학습한 후 각 학생 네트워크의 학습 능력을 식별 하고, 상기 학습 능력을 기준으로 상기 복수의 학생 네트워크 중 제1복수의 학생 네트워크를 복수의 교사 네트워 크로 전환하고, 상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터에 기초하여 상기 복수의 교사 네트워크를 학습시키고, 상기 학습된 복수의 교사 네트워크를 이용하여 상기 복수의 학생 네트워크 중 나머지 제 2복수의 학생 네트워크를 학습시키는 프로세서를 포함한다."}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 지식 증류를 활용한 그룹 기반의 학습을 수행하는 전자장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "지식 증류(Knowledge Distillation) 기술은 교사-학생 프레임워크로 학생 네트워크가 학습하는 과정에서 교사 네트워크의 지식(피쳐맵, 로짓 등)을 모방하며 성능을 높이는 기술이다. 지식 증류 기술이 제안된 이후로 딥러닝 기술과 함께 다양한 형태의 지식 증류 기술이 연구되고 있다. 그 중 하 나로, 지식 증류 기술에서 교사와 학생 간 성능 격차가 큰 경우 학생이 교사의 지식을 온전히 받아들이지 못하 고, 교사 네트워크가 단일하게 존재함에 따라 학생의 성과 향상에 한계가 있는 등 모든 문제를 해결할 수 없는 바, 복수의 교사 네트워크 기반 지식 증류 방법에 관한 연구가 진행되고 있다. 보다 구체적으로, 교사-학생 사이의 성능을 가진 조교를 이용하여 해결하는 TAKD(Teacher Assistant based KD) 방법이 제안되었다. 그러나, 이 또한 여러 단계를 거쳐 각 네트워크를 순차적으로 훈련하기 어렵고, 온라인 지 식 증류 방법은 네트워크의 크기가 다를 경우 서로 발산하거나 충돌하는 문제점이 있다. 또한, 조교 네트워크를 학습하는 과정에서 교사 네트워크로부터 시작된 잘못된 지식이 조교 네트워크로 퍼지고 결과적으로 학생 네트워 크는 교사와 조교 네트워크의 잘못된 지식을 모방하여 학생 네트워크의 성능이 크게 향상되지 못하는 새로운 문 제점이 발견되었다. 따라서, 이러한 한계를 극복하고 다중 네트워크의 효율성을 얻을 수 있는 새로운 지식 증류 방법에 대한 연구가 필요한 실정이다."}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 온라인 역할 변경(Online Rule Change)에 따른 지식 증류를 활용한 그룹 기반의 학습을 수행 하는 전자장치 및 방법을 제공하는 것이다. 본 발명의 목적은 보다 효과적으로 교사 그룹에서 학생 그룹으로 지식 증류가 가능한 그룹 기반의 학습을 수행 하는 전자장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 지식 증류(knowledge distillation)를 활용한 그룹 기반의 학습을 수행하는 전자장 치에 있어서, 복수의 학생 네트워크를 학습 데이터를 이용하여 학습한 후 각 학생 네트워크의 학습 능력을 식별 하고, 상기 학습 능력을 기준으로 상기 복수의 학생 네트워크 중 제1복수의 학생 네트워크를 복수의 교사 네트 워크로 전환하고, 상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터에 기초하여 상기 복수의 교 사 네트워크를 학습시키고, 상기 학습된 복수의 교사 네트워크를 이용하여 상기 복수의 학생 네트워크 중 나머 지 제2복수의 학생 네트워크를 학습시키는 프로세서를 포함한다. 상기 프로세서는, 상기 복수의 학생 네트워크의 손실에 대한 각 학생 네트워크의 손실의 비율을 나타내는 제어 가중치에 기초하여 상기 오류 데이터의 수를 식별하고, 상기 오류 데이터 별 손실을 기반으로 상기 복수의 학생 네트워크에 대한 오류 데이터의 수만큼 상기 복수의 교사 네트워크를 학습시킬 수 있다. 상기 프로세서는, 상기 각 학생 네트워크에 대한 오류 데이터의 수를 합산하여 상기 복수의 학생 네트워크에 대 한 오류 데이터의 수를 식별할 수 있다. 상기 프로세서는, 상기 복수의 교사 네트워크 중 상기 학습 능력이 기 정의된 값 이상인 적어도 하나의 교사 네 트워크를 고정 교사 네트워크로 식별하고, 상기 고정 교사 네트워크를 이용하여 나머지 상기 복수의 교사 네트 워크를 학습시킬 수 있다. 상기 프로세서는, 상기 학습 능력이 높은 순으로 상기 복수의 학생 네트워크를 나열하여 상기 제1복수의 학생 네트워크를 식별할 수 있다. 상기 프로세서는, 상기 제2복수의 학생 네트워크를 학습시킨 후 상기 복수의 교사 네트워크를 상기 복수의 학생 네트워크에 포함되도록 다시 전환할 수 있다. 본 발명의 일 실시예에 다른 전자장치가 지식 증류(knowledge distillation)를 활용한 그룹 기반의 학습을 수행 하는 방법에 있어서, 복수의 학생 네트워크를 학습 데이터를 이용하여 학습한 후 각 학생 네트워크의 학습 능력 을 식별하는 단계; 상기 학습 능력을 기준으로 상기 복수의 학생 네트워크 중 제1복수의 학생 네트워크를 복수 의 교사 네트워크로 전환하는 단계; 상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터에 기초하 여 상기 복수의 교사 네트워크를 학습시키는 단계; 상기 학습된 복수의 교사 네트워크를 이용하여 상기 복수의 학생 네트워크 중 나머지 제2복수의 학생 네트워크를 학습시키는 단계를 포함한다. 상기 복수의 교사 네트워크를 학습시키는 단계는, 상기 복수의 학생 네트워크의 손실에 대한 각 학생 네트워크 의 손실의 비율을 나타내는 제어 가중치에 기초하여, 상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터의 수를 식별하는 단계; 상기 오류 데이터 별 손실을 기반으로 상기 복수의 학생 네트워크에 대한 오류 데이터의 수만큼 상기 복수의 교사 네트워크를 학습시키는 단계를 포함할 수 있다. 상기 복수의 교사 네트워크를 학습시키는 단계는, 상기 각 학생 네트워크에 대한 오류 데이터의 수를 합산하여 상기 복수의 학생 네트워크에 대한 오류 데이터의 수를 식별하는 단계를 포함할 수 있다. 상기 복수의 교사 네트워크를 학습시키는 단계는, 상기 복수의 교사 네트워크 중 상기 학습 능력이 기 정의된 값 이상인 적어도 하나의 교사 네트워크를 고정 교사 네트워크로 식별하는 단계; 상기 고정 교사 네트워크를 이 용하여 나머지 상기 복수의 교사 네트워크를 학습시키는 단계를 더 포함할 수 있다. 상기 복수의 교사 네트워크로 전환하는 단계는, 상기 학습 능력이 높은 순으로 상기 복수의 학생 네트워크를 나 열하여 상기 제1복수의 학생 네트워크를 식별하는 단계를 포함할 수 있다. 상기 제2복수의 학생 네트워크를 학습시키는 단계 이후에, 상기 복수의 교사 네트워크를 상기 복수의 학생 네트 워크에 포함되도록 다시 전환하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 교사 네트워크와 학생 네트워크 간 지식 전달이 효율적으로 수행될 수 있으며, 학생 네트워크의 학습 능력을 크게 향상 시킬 수 있다. 본 발명의 일 실시예에 따르면, 교사 네트워크는 학생 네트워크의 오류에 대해 집중적으로 보완함으로써 학생 네트워크로의 지식 증류를 효과적으로 수행할 수 있다. 본 발명의 일 실시예에 따르면, 학습 능력이 상위 수준인 교사 네트워크 간에도 편차를 줄여 더욱 정밀하게 밀 도 높은 학습 능력의 지식 증류 방법을 구현할 수 있다."}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 바람직한 실시 형태를 첨부된 도면을 참조하여 상세하게 설명한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 발명의 예시적인 실시형태를 설명하고자 하는 것이며, 본 발명이 실시될 수 있 는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략할 수 있고, 명세서 전체를 통하여 동일 또는 유사한 구성 요소에 대해서는 동일한 참조 부 호를 사용할 수 있다. 도 1은 본 발명의 일 실시예에 따른 지식 증류를 활용한 그룹 기반의 학습을 도시한 개략도이다. 본 발명에서는 다중 네트워크를 이용한 그룹 기반의 지식 증류를 제안한다. 도 1을 참조하면, 다중 네트워크를 역할에 따라 교사 그룹(teacher group, 20)과 학생 그룹(student group, 30)에 분배한다. 이때, 다중 네트워크는 분배 전 같은 레벨 선상에 놓이는 학생 네트워크로써, 각 학생 네트워크의 학습 능 력에 따라 교사 그룹과 학생 그룹으로 분배된다. 교사 그룹의 주요 역할은 집단 지식을 사용하여 학생 그룹에 지식을 전달하는 것이고, 학생 그룹의 역할은 교사 그룹으로부터 지식을 전달받는 것이다. 이때, 교사 그룹은 학생 그룹과의 편차를 줄이기 위해, 학생 그룹의 오류 데이터를 기초로 피드백 을 수행하고, 교사 그룹 내의 교사 네트워크 간의 편차를 줄이기 위해 내부 지식 증류 과정을 수행한다. 따라서, 본 발명의 일 실시예에 따른 교사 그룹 내 복수의 교사 네트워크는 학습 대상에 대해 가지고 있는 지식 간 편차가 적고, 피드백 과정을 통해 학생 네트워크의 부족한 부분을 파악하여 학생 네트워크로 지식 증류 를 함으로써, 효과적으로 교사 그룹의 지식을 학생 네트워크로 전달할 수 있다. 도 1은 오슬롯(Ocelot)의 사진에 오슬롯 라벨이 붙어서 교사 그룹의 복수의 교사 네트워크에 입력하고, 복 수의 교사 네트워크에서 학생 네트워크로 지식을 증류하는 모습을 도시한다. 학생 네트워크는 높은 성능으로 입 력된 데이터에 대해 오슬롯으로 예측하는 것을 알 수 있다. 이때, 다중 네트워크를 교사 그룹과 학생 그룹으로 분리하여, 성능이 좋지 않은 학생 그룹의 학생 네트워크가 잘못된 지식을 전달하는 것을 사전 에 방지할 수 있다. 또한, 본 발명의 일 실시예에 따르면 다중 네트워크가 교사 그룹과 학생 그룹으로 분리되더라도, 각 그룹에 고정되어 역할 분담을 하는 것이 아니고 학습 능력에 따라 지속적으로 역할을 변경할 수 있다. 역할 은 즉석에서 변경하거나, 한번의 지식 증류 과정이 끝났을 때 변경하는 등 일정 기준을 두고 변경할 수 있다. 본 발명에서는 교사 네트워크와 학생 네트워크 개념을 가변적으로 적용하여 잘못된 지식 이전을 효과적으로 방 지하는 새로운 메커니즘, 이른바 온라인 역할 변경(Online Role Change)을 제안한다. 본 발명에서는 최적의 그룹 수업을 제공하고, 학습 능력에 관한 격차를 성공적으로 해소하기 위해 집중 교육과 개인 교육의 방법을 제안한다. 이하, 도면들을 참조하여 본 발명의 일 실시예에 따른 지식 증류를 수행하는 전자장치 및 그 방법에 대해 보다 구체적으로 설명한다. 도 2는 본 발명의 일 실시예에 따른 전자장치의 구성을 도시한 블럭도이다. 본 발명의 일 실시예에 따른 전자장치는 지식 증류를 활용한 그룹 기반의 학습을 수행하는 장치로써, 컴퓨 터, 서버 등으로 구현될 수 있다. 본 발명의 일 실시예에 따른 전자장치는 입력부, 통신부, 표시부, 메모리 및 프로세 서를 포함한다. 입력부는 전자장치의 사용자 입력에 대응하여 입력데이터를 발생시킨다. 예를 들어, 사용자 입력은 전자장치가 지식 증류 과정을 수행하기 위한 사용자 입력일 수 있다. 입력부는 적어도 하나의 입력수단을 포함한다. 입력부는 키보드(key board), 키패드(key pad), 돔 스 위치(dome switch), 터치패널(touch panel), 터치 키(touch key), 마우스(mouse), 메뉴 버튼(menu button) 등을 포함할 수 있다. 통신부는 학습 데이터, 다중 네트워크, 사전 훈련된 고정 교사 네트워크 등을 수신하기 위해 외부장치와의 통신을 수행한다. 이를 위해, 통신부는 5G(5th generation communication), LTE-A(long term evolution- advanced), LTE(long term evolution), Wi-Fi(wireless fidelity) 등의 통신을 수행할 수 있다. 표시부는 전자장치의 동작에 따른 표시 데이터를 표시한다. 표시부는 지식 증류를 수행하기 위 한 표시 데이터, 예를 들면 지식 증류 수행에 따른 학생 네트워크의 학습 능력을 표시하는 화면, 오류 데이터를 표시하는 화면 등을 표시할 수 있다. 표시부는 액정 디스플레이(LCD; liquid crystal display), 발광 다이오드(LED; light emitting diode) 디 스플레이, 유기 발광 다이오드(OLED; organic LED) 디스플레이, 마이크로 전자기계 시스템(MEMS; micro electro mechanical systems) 디스플레이 및 전자 종이(electronic paper) 디스플레이를 포함한다. 표시부 는 입력부와 결합되어 터치 스크린(touch screen)으로 구현될 수 있다. 메모리는 전자장치의 동작 프로그램들을 저장한다. 메모리는 전원의 제공 유무와 무관하게 데이 터(정보)를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터 가 로딩되며 전원이 제공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리(memory)를 포함한다. 스토 리지에는 플래시메모리(flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등이 있으며, 메모리에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 메모리는 외부장치로부터 수집한 데이터를 저장하거나, 학습 능력을 식별하거나, 지식을 전달하는데 필요 한 연산 프로그램 등을 저장할 수 있다. 프로세서는 프로그램 등 소프트웨어를 실행하여 전자장치의 적어도 하나의 다른 구성요소(예: 하드웨 어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 프로세서는 복수의 학생 네트워크를 학습 데이터를 이용하여 학습한 후 각 학생 네트워크의 학습 능력을 식별하고, 상기 학습 능력을 기준으로 상기 복수의 학생 네트워크 중 제1복수의 학생 네트워크를 복수의 교사 네트워크로 전환하고, 상기 학습 데이터 중 상기 각 학생 네트워크에 대한 오류 데이터에 기초하여 상기 복수의 교사 네트워크를 학습시키고, 상기 학습된 복수의 교사 네트워크를 이용하여 상기 복수의 학생 네트워크 중 나 머지 제2복수의 학생 네트워크를 학습시킨다. 한편, 프로세서는 상기 동작들을 수행하기 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능(Artificial Intelligence) 알고리즘으로서 기계학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network)과 같은 모델 을 포함할 수 있다. 도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 본 발명의 일 실시예에 따르면, 프로세서는 복수의 학생 네트워크를 학습 데이터를 이용하여 학습한 후 각 학생 네트워크의 학습 능력을 식별한다(S10). 본 발명의 일 실시예에 따르면, 학습 능력은 각 네트워크를 학습 데이터를 이용하여 학습 시 발생하는 손실의 정도, 즉 각 네트워크의 성능을 의미한다. 프로세서는 다양한 손실 함수에 기초하여 학습 능력을 식별할 수 있다. 본 발명에서는 손실이 낮을수록 학습 능력이 높은 것으로 서술한다. 학습 능력을 식별하는 것에 관하여는 아래 수학식 1 내지 수학식 3을 참조하여 설명한다. 지식 증류의 프레임워크는 수학식 1을 이용하여 설명할 수 있다. 수학식 1 zT와 zS 를 각각 교사 네트워크와 학생 네트워크의 로짓(logit)이라고 하면, 각 네트워크의 클래스 확률은 상기 수학식 1에서 정의된 PT 및 PS가 된다. τ는 클래스 확률의 연화(softening)를 제어하는 온도 매개변수이다. 이 때, 수학식 1에서는 소프트맥스 함수를 이용하였으나, MSE(Mean Squared Error), 교차 엔트로피 등 다중 클래스 에 적용 가능한 함수이면 제한 없이 적용 가능하다. 수학식 2"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "Kullback-Leibler(KL) 발산은 손실을 계산하는 데 사용된다. 감독 교차-엔트로피 손실(감독 손실)(LCE), 교차 엔트로피(H) 및 지식 증류 손실(Ldistill)은 수학식 2를 이용하여 설명할 수 있다. 이때, y는 원-핫 벡터 레이블 (one-hot vector label)이고, P(x)는 softmax(z)로 클래스 확률 분포를 의미한다. 수학식 3"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "학생의 총 손실(Lstudent)은 수학식 3과 같이 감독 손실(LCE)과 지식 증류 손실(Ldistill)의 조합으로 나타낼 수 있다. 이때, α는 감독 손실(LCE)과 지식 증류 손실(Ldistill)의 균형 계수(balance parameter)이다. 본 발명의 일 실시예에 따르면, 프로세서는 학습 능력을 기준으로 복수의 학생 네트워크 중 제1복수의 학 생 네트워크를 복수의 교사 네트워크로 전환한다(S20). 프로세서는 학습 능력이 높은 순으로 복수의 학생 네트워크를 나열하여 제1복수의 학생 네트워크를 식별할 수 있다. 이때, 학습 능력이 높은 순이란 앞서 S10에서 식별한 손실의 정도가 낮은 순을 의미할 수 있다. 본 발명에서는, 매 반복마다 복수의 학생 네트워크의 학습 능력을 식별하여 학습 능력이 일정 수준 이상인 네트 워크들은 교사 네트워크로 전환한다. 이때, 추후 설명하는 수학식 8을 이용하여 복수의 학생 네트워크 중 학습 능력이 가장 좋은 네트워크를 식별할 수 있다. 본 발명의 일 실시예에 따르면, 프로세서는 학습 데이터 중 각 학생 네트워크에 대한 오류 데이터에 기초 하여 복수의 교사 네트워크를 학습시킨다(S30). 본 발명에서는 복수의 교사 네트워크가 제2복수의 학생 네트워크에 보다 효율적으로 지식 전달을 하기 위해 복 수의 학생 네트워크의 오류 데이터를 기초로 피드백을 수행한다. 이를 집중 교육이라고 하고, 집중 교육과 관련 하여는 도 5를 참조하여 구체적으로 설명한다. 이 외에도 본 발명에서는 교사 그룹을 이루는 복수의 교사 네트워크 간 학습 능력의 편차를 줄이기 위해, 복수 의 교사 네트워크 중에서도 학습 능력이 우수한 적어도 하나의 교사 네트워크를 추출하여 나머지 교사 네트워크 에 대해 학습을 수행한다. 이를 개인 교육이라고 하고, 개인 교육과 관련하여는 도 6을 참조하여 구체적으로 설 명한다. 본 발명의 일 실시예에 따르면, 프로세서는 학습된 복수의 교사 네트워크를 이용하여 복수의 학생 네트워 크 중 나머지 제2복수의 학생 네트워크를 학습시킨다(S40). 본 발명에서는 앞서 S10, S20을 통해 선정된 복수의 교사 네트워크로 이루어진 교사 그룹이 제2복수의 학생 네 트워크에 지식을 전달한다. 이를 그룹 교육이라고 하고, 로짓, 피쳐맵 등 교사 네트워크로부터 증류할 수 있는 모든 지식을 전이 가능 지식으로 정의할 수 있고, 앙상블(ensemble), 개별 모형(individual model) 등 모든 형 태로 그룹 교육을 진행할 수 있다. 이때, 프로세서는 제2복수의 학생 네트워크를 학습시킨 후 복수의 교사 네트워크를 복수의 학생 네트워크 에 포함되도록 다시 전환할 수 있다. 즉, 그룹 교육 후 복수의 교사 네트워크는 교사 역할에서 사임하고 학생 그룹으로 이전된다. 다음 반복 시 각 학생 네트워크의 학습 능력에 따라 교사 그룹과 학생 그룹을 다시 배분하기 위함이다. 본 발명의 일 실시예에 따르면, 네트워크의 크기들이 서로 다르더라도 적용이 가능하여 교사 네트워크와 학생 네트워크 간 지식 전달이 효율적으로 수행될 수 있으며, 학생 네트워크의 학습 능력을 크게 향상 시킬 수 있다. 도 4는 본 발명의 일 실시예에 따른 교사 네트워크와 학생 네트워크를 그룹화하는 모습을 도시한 도면이다. 도 4는 도 3의 S10, S20과 관련하여 학습 능력에 따른 교사 그룹과 학생 그룹의 분리 및 그룹 교육에 대해서 설 명한다. 도 4에는 복수의 학생 네트워크와, 복수의 교사 네트워크를 포함하는 교사 그룹, 제2복수의 학생 네트 워크를 포함하는 학생 그룹이 도시되어 있다. 프로세서는 복수의 학생 네트워크 각각의 학습 능력을 식별하여, 학습 능력이 높은 순으로 나열하고, 학습 능력이 높은 제1복수의 학생 네트워크를 복수의 교사 네트워크로 전환한다. 그리고, 복수의 학생 네트워크 중 제1복수의 학생 네트워크를 제외한 나머지 제2복수의 학생 네트워크는 학생 그룹에 포함시켜, 교사 그룹으로부터 그룹 교육을 받도록 한다. 이때, 교사 그룹에 포함된 복수의 교사 네트워크나 학생 그룹에 포함된 제2복수의 학생 네트워크들은 지식 증류 과정에서 언제든지 그 역할이 변경될 수 있다. 이를 위해, 프로세서는 복수의 교사 네트워크에 의해 제2복수의 학생 네트워크를 학습시킨 후, 복수의 교사 네트워크를 복수의 학생 네트워크에 포함되도록 다 시 전환할 수 있다. 따라서, 전체 학생 네트워크를 동일 선상에 놓고, 학습 능력에 따라 교사 그룹과 학생 그룹으로 분리시킴으로써 지식 증류의 과정을 반복하여 학습 능력의 상향 평준화 효과를 낼 수 있다. 도 5는 본 발명의 일 실시예에 따른 집중 교육의 모습을 도시한 도면이다. 도 5는 도 3의 S30과 관련하여 집중 교육에 대해서 설명한다. 교사 그룹은 학생 그룹에 적절한 지식을 제공하는 것을 목표로 하므로, 교사 그룹은 학생 그룹(3 0)이 제대로 예측하지 못하는 부분을 집중적으로 지도해야 한다. 학생 그룹이 제대로 예측하지 못하는 부분 을 피드백 하위 집합(feedback subset)이라고 하고, 프로세서는 교사 그룹이 학생 그룹에 좀 더 집중할 수 있도록 피드백 하위 집합을 사용하여 교사 그룹에 포함된 복수의 교사 네트워크를 추가로 훈련한 다. 피드백 하위 집합을 구성하는 프로세스는 두 부분으로 나눌 수 있다. 첫 번째 부분은 네트워크 손실을 기반으로 각 학생 네트워크에 대한 오류 데이터의 순위를 정하는 것이다. 두 번째 부분은 각 네트워크가 추출하는 오류 데이터의 수를 식별하는 것이다. 즉, 각 학생 네트워크 별로 오류 데 이터의 순위 및 오류 데이터의 수를 식별하고 전체 학생 네트워크에 대해서 합산하게 되면, 학생 네트워크가 학 습 데이터 중 어떤 학습 데이터에서 손실이 많이 발생하는지 알 수 있다. 또한, 교사 네트워크는 이렇게 추출한 피드백 하위 집합을 학습함으로써 학생 네트워크의 오류에 대해 집중적으로 보완할 수 있다. 보다 구체적으로 살펴보면, 프로세서는 각 학생 네트워크에 미니 배치 데이터(mini-batch data)를 공급하 고 수학식 2의 감독 손실 LCE를 사용하여 각 오류 데이터의 순위를 정할 수 있다. 이때, 미니 배치 데이터는 복 수의 학습 데이터를 분할한 데이터를 의미하며, 프로세서는 하나의 미니 배치 데이터를 학습시킬 때마다 각 학생 네트워크의 학습 능력을 식별할 수 있다. 본 발명의 일 실시예에 따르면, 프로세서는 제어 가중치에 기초하여 학습 데이터 중 각 학생 네트워크에 대한 오류 데이터의 수를 식별할 수 있다. 제어 가중치(ωc)란 복수의 학생 네트워크의 손실에 대한 각 학생 네트워크의 손실의 비율을 나타내는 것으로 수 학식 4를 이용하여 계산할 수 있다. 수학식 4"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "제어 가중치(ωc)는 각 네트워크에 대한 오류 데이터의 수를 제어하는 데 사용된다. 이때, 모든 학생 네트워크에 대한 제어 가중치의 합은 1이어야 한다. Ls는 학생 그룹 교차 엔트로피 손실이고, n은 학생 수이다. 고손실 네트워크는 많은 양의 오류 데이터를 제공하고 저손실 네트워크는 그 반대이므로 훈련 중 오류 데이터를 유연하게 제어한다. 수학식 5"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 Di는 네트워크 i번째 인스턴스 수이고 B는 미니 배치 크기이다. 미니 배치에서 손실이 큰 네트워크가 네 트워크 비율을 통해 더 많은 피드백 인스턴스를 추출할 수 있도록 하는 메커니즘을 설계한다. 본 발명의 일 실시예에 따르면, 프로세서는 각 학생 네트워크에 대한 오류 데이터의 수를 합산하여 복수의 학생 네트워크에 대한 오류 데이터의 수를 식별할 수 있다. 복수의 학생 네트워크에 대한 오류 데이터의 수는 Dsubset으로 수학식 6을 이용하여 계산할 수 있다. Dsubset을 피드백 하위 집합으로 설정한다. 수학식 6"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "본 발명의 일 실시예에 따르면, 프로세서는 오류 데이터 별 손실을 기반으로 복수의 학생 네트워크에 대한 오류 데이터의 수만큼 복수의 교사 네트워크를 학습시킬 수 있다. 즉 오류 데이터 별 손실이 큰 순서대로 Dsubset 만큼 복수의 교사 네트워크를 학습시킬 수 있다. 도 5를 참조하면, 복수의 학생 네트워크에 포함된 각 학생 네트워크(Student Network 1, Student Network 2, ..., Student Network n)는 미니 배치 데이터를 학습하고, 오류 데이터 별 손실 및 오류 데이터 의 수를 식별한다. 각 학생 네트워크의 오류 데이터의 수는, 예를 들어, Student Network 1은 3개, Student Network 2는 4개, Student Network n은 8개이다. 각 네트워크 별로 오류 데이터들의 손실에 따른 순위 를 지정하여 피드백 하위 집합을 구성할 수 있다. 프로세서는 피드백 하위 집합에 포함된 오류 데이 터를 이용하여 복수의 교사 네트워크를 학습시킬 수 잇다. 본 발명의 일 실시예에 따르면, 복수의 교사 네트워크를 학습시키는 과정에서 수학식 7과 같이 혼합(mix-up) 방 법을 사용할 수 있다. 수학식 7"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "혼합 방법은 데이터 증대 접근 방식의 일종으로, 미니 배치 데이터와 오류 데이터의 두 이미지를 하나로 결합하 여 데이터를 보강하는 방법이다. xi를 훈련 데이터의 미니 배치라고 하고, xfeed를 학생 그룹의 오류 데이터로 설정한다. 여기서 λ는 두 이미지 가 하나의 혼합 샘플을 생성하도록 샘플 혼합 비율을 결정하고, λ는 베타 분포를 사용하여 무작위로 선택된다. 다만, 복수의 교사 네트워크를 학습시키는 방법은 이 외에도 다양하게 적용될 수 있으며, 혼합 방법에 의해 한 정되는 것은 아니다. 본 발명의 일 실시예에 따르면, 교사 네트워크는 학생 네트워크의 오류에 대해 집중적으로 보완함으로써 학생 네트워크로의 지식 증류를 효과적으로 수행할 수 있다. 도 6은 본 발명의 일 실시예에 따른 개인 교육의 모습을 도시한 도면이다. 도 6은 도 3의 S30과 관련하여 교사 네트워크 간 편차를 줄이는 개인 교육에 대해서 설명한다. 본 발명의 일 실시예에 따르면, 프로세서는 복수의 교사 네트워크 중 학습 능력이 기 정의된 값 이상인 적 어도 하나의 교사 네트워크를 고정 교사 네트워크로 식별하고, 식별한 고정 교사 네트워크를 이용하여 나머지 복수의 교사 네트워크를 학습시킬 수 있다. 이때, 고정 교사 네트워크는 사전 훈련된 교사 네트워크일 수 있으 며, 이 경우 별도의 고정 교사 네트워크 선별 과정 없이 사전 훈련된 교사 네트워크가 복수의 교사 네트워크를 학습시킬 수 있다. 본 발명의 일 실시예에 따르면, 고정 교사 네트워크를 포함하는 복수의 교사 네트워크는 적절한 지식을 학생 그 룹에 전달해야 한다. 따라서, 앞서 도 4와 관련하여 서술한 바와 같이, 열악한 지식 전달을 줄이기 위해 고성능 학생 네트워크가 각 미니 배치의 교사 네트워크로 선택된다. 또한 고정 교사 네트워크를 제외한 나머지 복수의 교사 네트워크는 훈련 과정에서 학생 네트워크와 잘 훈련된 고정 교사 네트워크 사이의 능력 격차를 해소하는 데 도움이 될 수 있다. 고정 교사 네트워크는 적어도 하나의 교사 네트워크가 될 수 있으며, 수학식 8을 이용하여 식별할 수 있다. 수학식 8"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 8에서 Ls는 미니 배치 데이터에 대한 학생 그룹 교차 엔트로피 손실이고, i*는 복수의 교사 네트워크 중 학습 능력이 가장 좋은 네트워크의 인덱스이다. 수학식 8은 앞서 서술한 바와 같이, 복수의 학생 네트워크에서 교사 네트워크로 전환할 제1복수의 학생 네트워크를 식별하는 과정에서도 이용될 수 있다. 수학식 9"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "수학식 10"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "수학식 9의 Lpivot-T는 고정 교사 네트워크의 손실을 의미하고, 수학식 10의 Ltemp-T는 고정 교사 네트워크 이외의 나머지 교사 네트워크의 손실을 의미한다. Ppivot-T와 Ptemp-T는 각각 연화 클래스 확률이다. 본 발명에서 나머지 교사 네트워크는 학생 그룹에 대한 효과적인 지식전수를 위한 가교역할을 하기 위해 고정 교사 네트워크로부터 전수받은 지식에 집중하는 전략으로 설계하였다. 따라서, 각 반복에서 고정 교사 네트워크 는 상대적으로 지식 격차가 적은 나머지 교사 네트워크를 학습시킨다. 수학식 11"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "수학식 12"}
{"patent_id": "10-2022-0055830", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "Lgroup-distill은 수학식 11과 같이 정의할 수 있고, 학생 총 손실 LS는 수학식 12와 같이 정의할 수 있다. 도 6을 참조하면, 교사 그룹에서 상위의 학습 능력을 가진 적어도 하나의 교사 네트워크를 고정 교사 네트 워크로 식별하고, 고정 교사 네트워크를 이용하여 나머지 교사 네트워크를 학습시킬 수 있다. 이때, 도 6에서는 고정 교사 네트워크가 Teacher Network 1 하나로 선정되었으나, 2 이상의 고정 교사 네트 워크를 이용하여 나머지 교사 네트워크를 학습시키는 설계가 얼마든지 가능할 것이다. 본 발명의 일 실시예에 따르면, 학습 능력이 상위 수준인 교사 네트워크 간에도 편차를 줄여 더욱 정밀하게 밀 도 높은 학습 능력의 지식 증류 방법을 구현할 수 있다."}
{"patent_id": "10-2022-0055830", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 지식 증류를 활용한 그룹 기반의 학습을 도시한 개략도이다. 도 2는 본 발명의 일 실시예에 따른 전자장치의 구성을 도시한 블럭도이다. 도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 도 4는 본 발명의 일 실시예에 따른 교사 네트워크와 학생 네트워크를 그룹화하는 모습을 도시한 도면이다. 도 5는 본 발명의 일 실시예에 따른 집중 교육의 모습을 도시한 도면이다. 도 6은 본 발명의 일 실시예에 따른 개인 교육의 모습을 도시한 도면이다."}
