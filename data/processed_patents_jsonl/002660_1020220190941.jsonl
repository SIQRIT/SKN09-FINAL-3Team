{"patent_id": "10-2022-0190941", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0107889", "출원번호": "10-2022-0190941", "발명의 명칭": "인공신경망 기반의 이미지 캡션 생성을 통한 이미지 확장 방법 및 그 장치", "출원인": "서강대학교산학협력단", "발명자": "강석주"}}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "캡션 기반 광범위한 페인팅 작업을 수행하는 컴퓨팅 장치로서,마스킹 처리된 영역을 포함하는 이미지를 입력받아 입력 이미지를 설명하는 상기 마스킹 처리된 영역에 대한 언어 힌트를 생성하는 이미지 캡션 모듈, 그리고상기 입력 이미지와 상기 언어 힌트를 입력받아 상기 언어 힌트의 가이드에 따라 상기 마스킹 처리된 영역의 이미지를 예측하고, 예측한 이미지로 상기 마스킹 처리된 영역을 채운 확장 이미지를 출력하는 텍스트-가이드 이미지 조작 모듈를 포함하는, 컴퓨팅 장치."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 이미지 캡션 모듈은,입력 이미지로부터 시각적 특징을 추출하는 인코더, 그리고상기 시각적 특징으로부터 일련의 단어들을 생성하는 디코더를 포함하는, 컴퓨팅 장치."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에서,상기 이미지 캡션 모듈은,입력 이미지로부터 상기 입력 이미지를 설명하는 자연어로 이루어진 텍스트를 출력하도록 사전 학습된 언어 모델을 랜덤하게 마스킹된 이미지들로 구성된 학습 데이터를 이용하여 학습되는, 컴퓨팅 장치."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서,상기 이미지 캡션 모듈은,상기 학습 데이터와 SCST(self-critical sequence training) 방법을 사용하여 학습되는, 컴퓨팅 장치."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에서,상기 이미지 캡션 모듈은,교차 엔트로피 손실(cross entropy loss)과 강화 학습(reinforcement learning)을 이용하여 학습되는, 컴퓨팅장치."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에서,상기 텍스트-가이드 이미지 조작 모듈은,텍스트와 이미지가 쌍으로 이루어진 학습 데이터를 이용하여 텍스트에 상응하는 이미지를 출력하도록 학습되는,컴퓨팅 장치.공개특허 10-2024-0107889-3-청구항 7 제1항에서,상기 이미지 캡션 모듈과 상기 텍스트-가이드 이미지 조작 모듈은,인공신경망 모델인 컴퓨팅 장치."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "컴퓨팅 장치에 의해 수행되는 이미지 아웃페인팅 방법으로서,임의의 영역이 마스킹 처리된 이미지를 입력받는 단계,입력 이미지로부터 일련의 단어들을 생성하도록 학습된 이미지 캡션 모듈을 이용하여, 상기 마스킹된 이미지에서 마스킹 처리되지 않은 이미지에 대한 의미 및 텍스트 정보를 자연 언어로 설명한 언어 힌트를 생성하는단계, 상기 언어 힌트를 이용하여 상기 임의의 영역의 이미지를 예측하는 단계, 그리고상기 예측한 이미지를 포함하는 확장 이미지를 출력하는 단계를 포함하는, 이미지 아웃 페인딩 방법."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에서,상기 예측하는 단계는,입력 텍스트에 상응하는 이미지를 생성하도록 학습된 텍스트-가이드 이미지 조작 모듈에 상기 마스킹 처리된 이미지와 상기 언어 힌트를 입력하여, 상기 언어 힌트의 가이드에 따라 상기 마스킹 처리된 임의의 영역의 이미지를 예측하는, 이미지 아웃 페인딩 방법."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에서,상기 텍스트-가이드 이미지 조작 모듈은,텍스트와 이미지가 쌍으로 이루어진 학습 데이터를 이용하여 텍스트에 상응하는 이미지를 출력하도록 학습된 인공신경망 모델인, 이미지 아웃 페인딩 방법."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에서,상기 이미지 캡션 모듈은,사전 학습된 언어 모델이 랜덤하게 마스킹된 이미지들로 구성된 학습 데이터를 이용하여 학습된 인공신경망 모델이고,상기 사전 학습된 언어 모델은, 입력 이미지로부터 상기 입력 이미지를 설명하는 자연어로 이루어진 텍스트를 출력하는 모델인, 이미지 아웃 페인팅 방법."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "컴퓨팅 장치에 의해 수행되는 광범위한 이미지 블렌딩 방법으로서,제1 이미지와 제2 이미지가 연결되는 지점을 마스킹 영역으로 설정하는 단계,상기 마스킹 영역을 기준으로 양측에 상기 제1 이미지와 상기 제2 이미지가 각각 배치된 이미지를 생성하는 단계, 공개특허 10-2024-0107889-4-입력 이미지로부터 일련의 단어들을 생성하도록 학습된 이미지 캡션 모듈을 이용하여, 상기 생성한 이미지에서마스킹 처리되지 않은 이미지에 대한 의미 및 텍스트 정보를 자연 언어로 설명한 언어 힌트를 생성하는 단계, 상기 언어 힌트를 이용하여 상기 마스킹 영역의 이미지를 예측하는 단계, 그리고상기 제1 이미지, 상기 예측한 이미지, 및 상기 제2 이미지가 순차적으로 배치된 파노라마 이미지를 출력하는단계를 포함하는, 광범위한 이미지 블렌딩 방법."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에서,상기 설정하는 단계 이전에,이전 단계에서 예측된 출력을 다음 단계의 입력으로 사용하는 이미지 아웃페인팅을 반복하여 상기 제1 이미지를생성하는 단계, 그리고상기 제1 이미지와 반대 방향으로 상기 이미지 아웃페인팅을 반복하여 제2 이미지를 생성하는 단계를 포함하고,상기 이미지 아웃페인팅은,마스킹 영역에 대한 이미지를 예측하는 작업인, 광범위한 이미지 블렌딩 방법."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에서,상기 이미지 아웃페인팅은,상기 마스킹 영역이 포함된 이미지에서 마스킹되지 않은 영역에 대한 의미 및 텍스트 정보를 자연 언어로 설명한 언어 힌트를 사용하여 상기 마스킹 영역의 이미지를 예측하고, 상기 마스킹 영역을 예측한 이미지로 채운 확장 이미지를 생성하는 작업을 포함하는, 광범위한 이미지 블렌딩 방법."}
{"patent_id": "10-2022-0190941", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에서,상기 이미지 아웃페인팅은,텍스트에 상응하는 이미지를 출력하도록 학습된 인공신경망 모델에 상기 언어 힌트와 상기 마스킹 영역이 포함된 이미지를 입력하여 상기 언어 힌트의 가이드에 따라 상기 마스킹 영역의 이미지를 예측하는 작업을포함하는, 광범위한 이미지 블렌딩 방법."}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에 따르면, 캡션 기반 광범위한 페인팅 작업을 수행하는 컴퓨팅 장치로서, 마스킹 처리된 영역을 포함하 는 이미지를 입력받아 입력 이미지를 설명하는 상기 마스킹 처리된 영역에 대한 언어 힌트를 생성하는 이미지 캡 션 모듈, 그리고 상기 입력 이미지와 상기 언어 힌트를 입력받아 상기 언어 힌트의 가이드에 따라 상기 마스킹 처리된 영역의 이미지를 예측하고, 예측한 이미지로 상기 마스킹 처리된 영역을 채운 확장 이미지를 출력하는 텍 스트-가이드 이미지 조작 모듈을 포함할 수 있다."}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공신경망 기반의 이미지 캡션 생성을 통한 이미지 확장 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지 완성은 이미지에서 누락된 영역에 적절한 이미지를 생성하는 연구 분야로서, 대표적으로 이미지 아웃페 인팅(Image outpainting)과 광역 이미지 블렌딩(wide-rage image blending)이 있다. 이미지 아웃 페인팅은 주어진 이미지의 경계 밖을 생성하여 이미지를 확장하는 연구 분야이다. 이미지 아웃 페 인팅은 원본 이미지 왜곡을 최소화하며 각기 다른 디스플레이 종횡비에 맞게 이미지 크기를 조정하는 이미지 리 타겟팅(image retargeting)에 활용될 수 있다. 더불어, 이미지 아웃페인팅과 광역 이미지 블렌딩은 파노라마 이 미지 생성에도 적용될 수 있다. 광역 이미지 블렌딩은 각기 다른 두 이미지 사이를 채워 넣어 하나의 자연스러운 이미지를 생성하는 연구 분야 이다.이미지 완성에서 두 과업이 처리하는 누락된 영역의 크기가 상대적으로 크기 때문에 난도가 높은 것으로 평가받 고 있다. 기존의 일부 딥러닝 기반 이미지 아웃페인팅 알고리즘들은 누락된 영역의 큰 크기를 보완하기 위하여 이미지 형 태의 힌트를 생성하였다. 종래의 어떤 방법은 입력 이미지를 반으로 나눈 뒤 양옆을 서로 뒤바꾸어 힌트로 사용 하고, 이와 비슷하게 종래의 다른 방법은 입력 이미지를 뒤집어 힌트로 사용한다. 하지만 이러한 방법들은 대칭 이미지에만 적용되며, 비대칭 이미지에 대하여는 부자연스러운 결과물을 생성한다. 이러한 한계를 보완하기 위 해, 종래의 또 다른 방법은 이미지에서 적절한 패치를 골라 힌트 이미지를 생성한다. 하지만 이 방법은 다른 방 법들과 마찬가지로 이미지 아웃페인팅에 제한되고, 광역 이미지 블렌딩과 같은 다른 다양한 이미지 완성 분야에 대하여는 적용할 수 없다. 광역 이미지 블렌딩은 최근에 새롭게 제시된 연구 분야이기 때문에 딥러닝 기반의 모델만 존재하며, 힌트를 사 용하지 않는다. 종래의 이미지 아웃 페인팅 기술들은 이미지 형태의 힌트를 생성하기 위해 주어진 이미지의 일부를 뒤집는 등의 방법으로 사용하여 누락된 영역에 대한 예측을 수행했다. 하지만 해당 이미지 힌트들은 주어진 이미지 구조에 의존적이기 때문에 다양한 형태의 누락된 영역에 적용하지 못한다는 한계가 있다. 예를 들어, 주어진 이미지를 뒤집어서 이미지와 일정한 간격으로 정렬하여 영상을 수평으로 확장하는 방법은 수직으로 이미지를 확장하거나, 다른 두 이미지가 입력으로 주어지는 광역 이미지 블렌딩에 적용할 수 없다. 이와 같이, 종래의 이미지 아웃 페 인팅 기술들은 적용할 수 있는 조건이 까다롭다는 한계점이 존재한다."}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 텍스트 형태의 이미지 힌트를 사용하여 이미지를 확장하는 방법 및 그 장치를 제공하는 것이다. 본 개시는, 인공신경망 네트워크인 이미지 캡션 모듈과 텍스트-가이드 이미지 조작 모듈을 포함하며, 이미지 캡 션 모듈에 의해 마스킹된 영역에 대한 언어 힌트를 생성하고 텍스트-가이드 이미지 조작 모듈에 의해 언어 힌트 의 가이드에 따라 마스킹된 영역의 이미지를 예측함으로써, 이미지를 확장하는 방법 및 그 장치를 제공하는 것 이다. 본 개시는, 마스킹 영역에 대한 언어 힌트를 사용하여 마스킹 영역의 이미지를 예측하는 동작을 통해 이미지 아 웃페인팅 작업을 지원하는 이미지 확장 방법 및 그 장치를 제공하는 것이다. 본 개시는, 마스킹 영역에 대한 언어 힌트를 사용하여 마스킹 영역의 이미지를 예측하는 이미지 아웃페인팅 작 업을 좌우 방향으로 반복하고, 이미지 아웃페인팅 작업을 통해 확장된 이미지를 결합하여 결합된 영역을 마스킹 영역으로 설정한 후 이미지 아웃페인팅 작업을 거쳐 파노라마 이미지를 생성하는 광범위한 이미지 블렌딩 작업 을 지원하는 이미지 확장 방법 및 그 장치를 제공하는 것이다."}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "한 특징에 따르면, 캡션 기반 광범위한 페인팅 작업을 수행하는 컴퓨팅 장치로서, 마스킹 처리된 영역을 포함하 는 이미지를 입력받아 입력 이미지를 설명하는 상기 마스킹 처리된 영역에 대한 언어 힌트를 생성하는 이미지 캡션 모듈, 그리고 상기 입력 이미지와 상기 언어 힌트를 입력받아 상기 언어 힌트의 가이드에 따라 상기 마스 킹 처리된 영역의 이미지를 예측하고, 예측한 이미지로 상기 마스킹 처리된 영역을 채운 확장 이미지를 출력하 는 텍스트-가이드 이미지 조작 모듈을 포함한다. 상기 이미지 캡션 모듈은, 입력 이미지로부터 시각적 특징을 추출하는 인코더, 그리고 상기 시각적 특징으로부 터 일련의 단어들을 생성하는 디코더를 포함할 수 있다. 상기 이미지 캡션 모듈은, 입력 이미지로부터 상기 입력 이미지를 설명하는 자연어로 이루어진 텍스트를 출력하 도록 사전 학습된 언어 모델을 랜덤하게 마스킹된 이미지들로 구성된 학습 데이터를 이용하여 학습될 수 있다. 상기 이미지 캡션 모듈은, 상기 학습 데이터와 SCST(self-critical sequence training) 방법을 사용하여 학습 될 수 있다. 상기 이미지 캡션 모듈은, 교차 엔트로피 손실(cross entropy loss)과 강화 학습(reinforcement learning)을 이용하여 학습될 수 있다. 상기 텍스트-가이드 이미지 조작 모듈은, 텍스트와 이미지가 쌍으로 이루어진 학습 데이터를 이용하여 텍스트에 상응하는 이미지를 출력하도록 학습될 수 있다. 상기 이미지 캡션 모듈과 상기 텍스트-가이드 이미지 조작 모듈은, 인공신경망 모델일 수 있다. 다른 특징에 따르면, 컴퓨팅 장치에 의해 수행되는 이미지 아웃페인팅 방법으로서, 임의의 영역이 마스킹 처리 된 이미지를 입력받는 단계, 입력 이미지로부터 일련의 단어들을 생성하도록 학습된 이미지 캡션 모듈을 이용하 여, 상기 마스킹된 이미지에서 마스킹 처리되지 않은 이미지에 대한 의미 및 텍스트 정보를 자연 언어로 설명한 언어 힌트를 생성하는 단계, 상기 언어 힌트를 이용하여 상기 임의의 영역의 이미지를 예측하는 단계, 그리고 상기 예측한 이미지를 포함하는 확장 이미지를 출력하는 단계를 포함한다. 상기 예측하는 단계는, 입력 텍스트에 상응하는 이미지를 생성하도록 학습된 텍스트-가이드 이미지 조작 모듈에 상기 마스킹 처리된 이미지와 상기 언어 힌트를 입력하여, 상기 언어 힌트의 가이드에 따라 상기 마스킹 처리된 임의의 영역의 이미지를 예측할 수 있다. 상기 텍스트-가이드 이미지 조작 모듈은, 텍스트와 이미지가 쌍으로 이루어진 학습 데이터를 이용하여 텍스트에 상응하는 이미지를 출력하도록 학습된 인공신경망 모델일 수 있다. 상기 이미지 캡션 모듈은, 사전 학습된 언어 모델이 랜덤하게 마스킹된 이미지들로 구성된 학습 데이터를 이용 하여 학습된 인공신경망 모델이고, 상기 사전 학습된 언어 모델은, 입력 이미지로부터 상기 입력 이미지를 설명 하는 자연어로 이루어진 텍스트를 출력하는 모델일 수 있다. 또 다른 특징에 따르면, 컴퓨팅 장치에 의해 수행되는 광범위한 이미지 블렌딩 방법으로서, 제1 이미지와 제2 이미지가 연결되는 지점을 마스킹 영역으로 설정하는 단계, 상기 마스킹 영역을 기준으로 양측에 상기 제1 이미 지와 상기 제2 이미지가 각각 배치된 이미지를 생성하는 단계, 입력 이미지로부터 일련의 단어들을 생성하도록 학습된 이미지 캡션 모듈을 이용하여, 상기 생성한 이미지에서 마스킹 처리되지 않은 이미지에 대한 의미 및 텍 스트 정보를 자연 언어로 설명한 언어 힌트를 생성하는 단계, 상기 언어 힌트를 이용하여 상기 마스킹 영역의 이미지를 예측하는 단계, 그리고 상기 제1 이미지, 상기 예측한 이미지, 및 상기 제2 이미지가 순차적으로 배치 된 파노라마 이미지를 출력하는 단계를 포함한다. 상기 설정하는 단계 이전에, 이전 단계에서 예측된 출력을 다음 단계의 입력으로 사용하는 이미지 아웃페인팅을 반복하여 상기 제1 이미지를 생성하는 단계, 그리고 상기 제1 이미지와 반대 방향으로 상기 이미지 아웃페인팅 을 반복하여 제2 이미지를 생성하는 단계를 포함하고, 상기 이미지 아웃페인팅은, 마스킹 영역에 대한 이미지를 예측하는 작업일 수 있다. 상기 이미지 아웃페인팅은, 상기 마스킹 영역이 포함된 이미지에서 마스킹되지 않은 영역에 대한 의미 및 텍스 트 정보를 자연 언어로 설명한 언어 힌트를 사용하여 상기 마스킹 영역의 이미지를 예측하고, 상기 마스킹 영역 을 예측한 이미지로 채운 확장 이미지를 생성하는 작업을 포함할 수 있다. 상기 이미지 아웃페인팅은, 텍스트에 상응하는 이미지를 출력하도록 학습된 인공신경망 모델에 상기 언어 힌트 와 상기 마스킹 영역이 포함된 이미지를 입력하여 상기 언어 힌트의 가이드에 따라 상기 마스킹 영역의 이미지 를 예측하는 작업을 포함할 수 있다."}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 종래와 같이 단순히 주어진 이미지를 재배열하거나 비슷한 내용의 이미지 힌트를 생성해 내 어 이미지에 이어 붙이는 것이 아니라, 주어진 이미지의 내용을 담은 텍스트 형태의 이미지 힌트, 즉, 언어 힌 트를 사용하고 언어 힌트의 가이드에 따라 마스킹된 영역의 이미지를 예측함으로써, 이미지 구조에 의존적이지 않기 때문에, 방향 또는 영상 완성 과업에 대한 제약 없이 모든 영상 완성 상황에 적용이 가능하다."}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였 다. 설명에서, 도면 부호 및 이름은 설명의 편의를 위해 붙인 것으로서, 장치들이 반드시 도면 부호나 이름으로 한 정되는 것은 아니다. 설명에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"…부\", \"…기\", \"…모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 본 개시의 장치는 적어도 하나의 프로세서가 명령어들(instructions)을 실행함으로써, 본 개시의 동작을 수행할 수 있도록 구성 및 연결된 컴퓨팅 장치이다. 컴퓨터 프로그램은 프로세서가 본 개시의 동작을 실행하도록 기술 된 명령어들(instructions)을 포함하고, 비일시적-컴퓨터 판독가능 저장매체(non-transitory computer readable storage medium)에 저장될 수 있다. 컴퓨터 프로그램은 네트워크를 통해 다운로드되거나, 제품 형태로 판매될 수 있다. 본 개시의 인공지능 모델(Artificial Intelligence model, AI model)은 적어도 하나의 태스크(task)를 학습하 는 기계학습모델로서, 프로세서에 의해 실행되는 컴퓨터 프로그램으로 구현될 수 있다. 인공지능 모델이 학습하 는 태스크란, 기계 학습을 통해 해결하고자 하는 과제 또는 기계 학습을 통해 수행하고자 하는 작업을 지칭할 수 있다. 인공지능 모델은 컴퓨팅 장치에서 실행되는 컴퓨터 프로그램으로 구현될 수 있고, 네트워크를 통해 다 운로드되거나, 제품 형태로 판매될 수 있다. 또는 인공지능 모델은 네트워크를 통해 다양한 장치들과 연동할 수 있다. 이미지 아웃페인팅(image outpainting)은 주어진 이미지를 원래의 경계 너머로 확장하는 것을 목표로 하는 작업 이다. 광역 이미지 블렌딩(wide-range image blending)은 서로 다른 두 이미지 사이에 중간 이미지를 생성하여 하나의 파노라마 이미지를 형성하는 것을 목표로 하는 작업이다. 도 1은 한 실시예에 따른 캡션 기반 광범위한 페인팅(Captioning-based Extensive Painting, 이하, 'CEP'라 통 칭함) 모듈의 구성을 나타낸 블록도이고, 도 2는 도 1에서 이미지 캡션 모듈의 구성을 나타낸 블록도이다. 도 1에 따르면, CEP 모듈은 적어도 하나의 프로세서에 의해 동작하는 컴퓨팅 장치로서, 본 개시에서 설명 하는 동작을 위한 컴퓨터 프로그램을 탑재하고, 컴퓨터 프로그램은 프로세서에 의해 실행된다. CEP 모듈은 이미지 캡션(image captioning) 모듈 및 텍스트-가이드 이미지 조작(text-guided image manipulation) 모듈을 포함할 수 있다.이미지 캡션 모듈과 텍스트-가이드 이미지 조작 모듈은 각각의 인공지능(AI) 네트워크 또는 인공지능 모델일 수 있다. 이미지 캡션 모듈은 임의의 일부 영역이 누락된 마스킹된 이미지를 입력받아, 입력 이미지의 의미 및 텍스 트 정보를 캡쳐하여 자연어로 이루어진 언어 힌트를 생성한다. 이미지 캡션 모듈은 마스킹된 이미지가 입 력되면 마스킹된 이미지에 자막을 넣음(captioning)으로써 언어 힌트를 생성한다. 확장 페인팅(extensive painting) 동안 언어 힌트를 생성하는 목적은 입력 이미지에 대해 가능한 자세한 정보를 제공하는 것이다. 따라서, 이미지 캡션 모듈은 이미지의 내용을 자연어로 설명하도록 학습된다. 실시예에 따르면, 이미지 캡션 모듈은 OFA(One For ALL), ClipCap와 같은 알고리즘이 사용될 수 있다. 이미지 캡션 모듈은 무작위 마스크를 사용하여 대규모 캡션 데이터 세트로 이미지 캡션 모델을 최적화할 수 있다. 이미지 캡션 모듈은 마스킹된 이미지에 적절한 캡션, 즉, 언어 힌트를 생성하기 위해 무작위 마 스크를 사용하는 SCST(self-critical sequence training) 방법을 사용하여 최적화될 수 있다. 종래의 캡션 모델은 완전한 이미지에서 대해서만 훈련되었기 때문에 마스킹된 이미지를 위한 적절한 캡션을 생 성하지 못하는 문제가 있다. 예컨대, 종래의 캡션 모델은 두개의 다른 이미지들의 결합 이미지로서 마스킹된 이 미지를 반복적으로 인식하고 \"두개의 사진(two pictures of)\"과 같은 부적절한 접두사(Prefix)를 생성하여 결국 의미론적으로 어색한 이미지를 생성한다. 그러나, 이미지 캡션 모듈은 랜덤하게 마스킹된 이미지와 그에 매칭되는 캡션을 가진 SCST를 사용하는 최적화 프로세스를 통해 마스크 형태에 관계없이 적절한 캡션을 예측할 수 있다. 따라서, 이미지 캡션 모듈은 종래의 의미론적으로 어색한 이미지를 생성하는 문제를 해결할 수 있다. 도 2를 참조하면, 이미지 캡션 모듈은 인코더 및 디코더를 포함하는 구조로 이루어진다. 인코더는 입력 이미지로부터 시각적 특징(visual features)을 추출한다. 디코더는 시각적 특징으로부 터 일련의 단어들을 생성한다. 이미지 캡션 모듈은 교차 엔트로피 손실(cross entropy loss)과 강화 학습(reinforcement learning)을 사 용하여 훈련될 수 있다. 이러한 훈련을 통해 이미지 캡션 모듈은 미분할 수 없는 캡션 메트릭을 최적화 목 표로 사용할 수 있다. 텍스트-가이드 이미지 조작 모듈은 마스킹된 이미지, 그리고 언어 힌트를 입력받아 마스킹된 영역의 이미 지를 예측하고 예측을 통해 마스킹된 영역의 이미지를 생성한다. 텍스트-가이드 이미지 조작 모듈은 언어 힌트의 안내에 따라 마스킹되지 않은 영역의 콘텐츠에 맞춘 마스킹된 영역의 시각적 콘텐츠를 생성한다. 즉, 텍 스트-가이드 이미지 조작 모듈은 언어 힌트를 사용하여 이미지의 마스킹된 영역을 채울 수 있다. IGT를 정답(ground-truth) 이미지라 하고, M을 이진(Binary) 이미지라 하면, 미완성 이미지, 즉, IIC를 수학 식 1과 같이 나타낼 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, ⊙는 아다마르 곱(Hadamard product) 연산을 나타낸다. 이미지 캡션 모듈은 미완성 이미지를 입력으로 사용하여 언어 힌트, 즉, Thint를 생성하며, 이를 수식화하면, 수학식 2와 같이 나타낼 수 있다. [수학식 2]"}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "GCAP는 이미지 캡션 모듈을 의미한다. 이미지 캡션 모듈은 수학식 3과 같이 랜덤하게 마스킹된 데이터셋(Dataset), 즉, Irand로 추가 훈련될 수 있다.[수학식 3]"}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 은 랜덤 마스크이다. 이미지 캡션 모듈은 SCST 접근 방식으로 대용량 데이터셋에 대해 사전 훈련된 언어 모델을 이용하여 최적 화된 모델일 수 있다. SCST 접근 방식은 보상이 테스트 시간에 사용되는 메트릭(metric)으로 설정되는 강화 학 습(REINFORCE) 알고리즘에 기초할 수 있다. 훈련 동안 정책(policy)으로부터 샘플링된 문장( )과 매개변수(θ)가 주어지면 부정적인 예상 보상 (negative expected reward)을 최소화할 수 있으며, 이를 수식화하면, 수학식 4와 같다. [수학식 4]"}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, LR(θ)은 그래디언트(gradient)를 의미한다. r은 생성된 시퀀스를 정답 시퀀스와 비교하여 평가 메트릭 (예, CIDEr)에 의해 계산된다. 훈련을 통해 수학식 4의 그래디언트는 수학식 5와 같이 근사화될 수 있다. [수학식 5]"}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, r( )은 모델, 즉, 이미지 캡션 모듈을 탐욕스럽게(greedily) 디코딩하여 얻은 기본 보상 (baseline reward)이다. 그래디언트는 현재 모델의 보상보다 훈련 중에서 정책에서 캡션 샘플링의 확률을 높이는 경향이 있다. 이러한 과정을 통해 최적화된 이미지 캡션 모듈은 마스크 형태에 관계없이 적절한 캡션을 예측할 수 있다. 본 발명의 실시예에서 획득하는 언어 힌트는 종래의 이미지 헌트에 비해 이미지 완성 작업과 관계없이 잘 작동 하는 장점이 있다. 종래에 이미지 힌트 기반의 방식들, 예컨대, BR(Bidirectional Rearrange), MR(Mirror Arrange), IAH(Image- Adaptive Hint)은 이미지 구조에 대한 의존도가 크다. BR은 입력 이미지의 반대되는 부분을 왼쪽과 오른쪽으로 전환하여 힌트로 활용하고, 두 분할된 이미지 사이의 간격을 채워준다. MR은 미러 플립 입력 영상을 힌트로 사 용하여 누락된 영역을 예측한다. 이처럼, BR과 MR은 입력 영상을 왼쪽과 오른쪽을 전환하여 재정렬하거나 가려 진 영역 옆에 입력 영상을 미러링하기 때문에 대칭 영상에만 적용할 수 있다. 또한, IAH는 힌트 기반 방법을 비 대칭 이미지로 확장한 기술로서, Vision Transformer를 사용하여 이미지 적응 방식으로 이미지 힌트를 생성하며, 출력 힌트는 이미지 형식으로 제한되어 고정 크기 힌트만 생성할 수 있다. 하지만, 본 발명의 이미지 캡쳐 모듈은 다른 모달리티(modality)를 힌트로 사용, 즉, 누락된 영역에 대한 텍스트 형태의 언어 힌트를 사용하기 때문에 제한없이 어떠한 형태의 이미지 완성에도 적용할 수 있다. 종래의 방식은 기본적으로 이미지 구조에 대해 종속적이기 때문에 본 발명에서와 같은 언어 힌트를 생성할 수 없는 구조라는 점에서 본 발명과 차 별된다. 텍스트-가이드 이미지 조작 모듈은 이미지 캡쳐 모듈에 의해 생성된 언어 힌트를 사용하여 마스킹된 영역에 대한 이미지를 생성한다. 실시예에 따르면, 텍스트-가이드 이미지 조작 모듈은 GLIDE, Imagen, DALL-E, textdrive blended diffusion과 같은 대규모(large-scale) 언어(language)-비전(vision) 모델을 사용할 수 있다. 이러한 모델은 대규모 텍스트-이미지 쌍 데이터 셋을 이용하여 훈련되므로, 특정 데이터 세트에서 훈련된 모델과 비교해도 광 범위한 도메인에서 제로(zero)-샷(shot) 이미지 생성에 능숙한 장점이 있어 전례없는 수준의 일반화를 달성한 모델이다.텍스트-가이드 이미지 조작 모듈은 마스킹된 이미지(IIC)와 언어 힌트(Thint)를 입력으로 사용하여 누락된 영역이 채워진 완전한 이미지, 즉, Ipred를 생성하며, 이를 수식화하면 수학식 6과 같다. [수학식 6]"}
{"patent_id": "10-2022-0190941", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "GIM는 텍스트-가이드 이미지 조작 모듈을 의미한다. 이와 같이, CEP 모듈은 이미지 캡션 모듈과 텍스트-가이드 이미지 조작 모듈은 한쌍으로 작동하 여 이미지 아웃페인팅(image outpainting) 작업 또는 광범위한 이미지 블렌딩(wide-range image blending) 작 업을 수행할 수 있다. 도 3은 한 실시예에 따른 이미지 캡션 모듈의 학습 과정을 설명하는 순서도이다. 도 3에 따르면, CEP 모듈은 랜덤하게 마스킹된 이미지들로 구성된 마스킹된 데이터 셋을 훈련 데이터로 입 력받는다(S101). CEP 모듈은 훈련 동안 정책으로부터 샘플링된 문장, 그리고 훈련 데이터를 이용하여 부정적인 예상 보상을 최소화하도록 매개변수를 포함하는 이미지 캡션 모듈을 학습시킨다(S102). 도 4는 한 실시예에 따른 CEP 모듈의 동작을 설명하는 순서도이다. 도 4에 따르면, CEP 모듈은 누락된 영역이 있는 마스킹된 이미지 입력받는다(S201). CEP 모듈의 이미지 캡션 모듈은 S201에서 입력받은 이미지의 의미 및 텍스트 정보를 자연 언어로 설 명한 언어 힌트를 생성한다(S202). CEP 모듈의 텍스트-가이드 이미지 조작 모듈은 S201에서 입력받은 마스킹된 이미지와 S202에서 입력 받은 언어 힌트를 입력으로 사용하여 마스킹된 영역의 이미지를 예측하고, 예측한 이미지가 포함된 완성된 확장 이미지를 출력할 수 있다(S203). 도 5는 한 실시예에 따른 이미지 아웃페인팅 동작을 설명한다. 도 5에 따르면, CEP 모듈은 마스킹 영역(빗금친 부분)이 포함된 마스킹된 이미지(P1)를 입력받아 마스킹 영역이 채워진 완성된 이미지(P2)를 출력한다. CEP 모듈은 주어진 정보가 이미지 내부 뿐일 때, 이미지 외부를 생성할 수 있다. CEP 모듈은 가로 방 향으로 이미지의 단면 또는 양면을 예측할 수 있다. CEP 모듈은 랜덤하게 마스킹된 이미지들에 대해 최적화되었으므로, 누락된 영역, 즉, 확장하고자 하는 영 역에 해당하는 마스킹한 영역을 입력받아 이미지 아웃페인팅을 수행할 수 있다. 이미키 캡션 모듈은 마스킹된 이미지(P1)를 입력받아 언어 힌트를 생성한다. 언어 힌트는 마스킹된 이미지 (P1)에서 마스킹되지 않은 영역의 콘텐츠를 설명하는 자연 언어로 된 텍스트로서, 예를 들어, \"The skyline of the city on a cloudy day\"일 수 있다. 텍스트-가이드 이미지 조작 모듈은 마스킹된 이미지(P1)와 언어 힌트를 입력받고, 언어 힌트를 사용하여 마스킹된 영역(빗금친 부분)의 이미지를 예측한다. 도 6은 한 실시예에 따른 광범위한 이미지 블렌딩(Wide-range Image Blending) 동작을 설명한다. 도 6에 따르면, 광범위한 이미지 블렌딩 동작은 크게 세가지 단계(Stage)로 이루어진다. 단계 1은 이전 단계에서 예측된 출력을 다음 단계의 입력으로 사용하여 아웃페인팅을 반복하는 다단계 예측을 수행한다. 구체적으로, 단계 1은 이미지 아웃페인팅 제1 방향의 마스킹 영역(빗금친 부분)을 포함하는 마스킹된 이미지를 입력으로 사용하여 도 1 ~ 도 5에서 설명한 CEP 모듈의 동작을 N번 반복한다. CEP 모듈의 N 회 반복 동작을 통해 제1 방향으로 이미지를 확장할 수 있다. 단계 2는 외삽된 두 이미지가 연결될 때까지 단계 1과 반대 방향인 제2 방향으로 아웃페인팅을 반복한다. 구체 적으로, 단계 2는 제2 방향의 마스킹 영역(빗금친 부분)을 포함하는 마스킹된 이미지를 입력으로 사용하여 도 1 ~ 도 5에서 설명한 CEP 모듈의 동작을 N번 반복한다. CEP 모듈의 N회 반복 동작을 통해 제2 방향으로 이미지를 확장할 수 있다. 단계 3은 단계 1과 단계 2를 통해 확장된 각각의 이미지를 연결시키는데, 연결이 끊어진 영역에 마스크를 적용 하여 마스킹된 이미지를 CEP 모듈의 입력으로 사용하여 마스킹 영역을 채울 수 있다. 단계 1과 단계 2를 통해 확장된 각각의 이미지는 서로 확장한 방향에서 마주하게 되고, 마주한 지점을 연결하는 데, 연결된 지점은 완전히 이어지지 못하고 끊어질 수 있다. 이러한 끊어진 지점의 콘텐츠를 생성하기 위해 끊 어진 지점을 마스킹 영역(빗금친 부분)으로 생성하고 마스킹 영역의 좌측에 단계 1을 통해 확장된 이미지를 배 치하고 마스킹 영역의 우측에 단계 2를 통해 확장된 이미지를 배치한 이미지를 CEP 모듈에 입력한다. CEP 모듈은 입력받은 이미지에 대해 언어 힌트를 생성하고, 생성한 언어 힌트의 가이드에 따라 마스킹 영 역을 예측하고, 예측한 이미지를 포함하는 완성된 이미지를 생성하게 된다. 도 7은 한 실시예에 따른 광범위한 이미지 블렌딩 절차를 설명하며, 도 6의 동작을 순차적으로 설명한 도면이다. 도 7에 따르면, CEP 모듈은 제1 방향으로 누락된 영역이 있는 마스킹된 이미지를 입력받아 마스킹된 영역 을 예측한 이미지로 채운 제1 이미지를 생성한다(S301). 여기서, 누락된 영역은 확장하고자 하는 영역에 해당한 다. CEP 모듈은 S301의 예측 횟수가 N번 반복하였는지 판단(S302)하고, N번 반복되지 않았다면, S301에서 예측 을 통해 생성된 제1 이미지에서 타겟 방향, 즉, 제1 방향으로 누락 영역을 추가한 마스킹된 이미지를 생성한다 (S303). CEP 모듈은 S303에서 생성한 마스킹된 이미지를 입력으로 사용하여 S301을 수행한다. S302에서 N번 반복으로 판단되면, CEP 모듈은 제1 방향과 반대 방향으로 누락된 영역이 있는 마스킹된 이 미지를 입력받아 누락된 영역을 예측하고, 예측한 영역이 포함된 제2 이미지를 생성한다(S304). CEP 모듈은 S304의 예측 횟수가 N번 반복하였는지 판단(S305)하고, N번 반복되지 않았다면, S304에서 예측 을 통해 생성된 제1 이미지에서 타겟 방향, 즉, 제2 방향으로 누락 영역을 추가한 마스킹된 이미지를 생성한다 (S306). CEP 모듈은 S306에서 생성한 마스킹된 이미지를 입력으로 사용하여 S304를 수행한다. CEP 모듈은 N번 반복으로 판단되면, S301을 통해 생성한 제1 이미지, 그리고 S304을 통해 생성한 제2 이미 지를 연결시키고, 연결 부위의 끊어진 지점을 마스킹 처리한 이미지를 입력 이미지로 사용하여 마스킹된 영역의 이미지를 예측하며, 마스킹된 부분을 예측한 이미지로 채운 제3 이미지를 생성한다(S307). 즉, 제3 이미지는 좌 우 방향으로 확장된 이미지를 블렌딩한 파노라마 이미지로 생성될 수 있다. 도 8은 본 발명의 실시예와 종래 기술에 따라 수행된 이미지 아웃페인팅 작업 결과를 비교한 도면이다. 이미지 아웃페인팅은 기본적으로 주어진 이미지를 원래의 경계 너머로 확장하는 작업을 말한다. 도 8의 (a)는 이미지 캡션 모듈을 통해 생성한 언어 힌트(\"A view of the ocean with rocks in the water\")를 사용하여 텍스트-가이드 조작 모듈에 의해 누락된 영역의 이미지를 예측하고, 예측한 이미지로 채워진 확장 이미지를 나타낸다. 도 8의 (b)는 종래의 방식으로 이미지 아웃 페인팅 작업이 수행되어 확장된 이 미지를 나타낸다. 종래의 방식은 pallette 알고리즘이 사용되었다. 도 8의 (c)는 이미지 캡션 모듈을 통해 생성한 언어 힌트(\"A city street with a tree in front of a building\")를 사용하여 텍스트-가이드 조작 모듈에 의해 누락된 영역의 이미지를 예측하고, 예측한 이미지 로 채워진 확장 이미지를 나타낸다. 도 8의 (d)는 종래의 방식으로 이미지 아웃 페인팅 작업이 수행되어 확장된 이미지를 나타낸다. 도 8의 (a)와 도 8의 (b), 도 8의 (c)와 도 8의 (d)를 비교하면, 본 발명을 적용한 확장 이미지가 원래의 이미 지와 동일하게 연장된 자연스러운 이미지를 연출함을 확인할 수 있다. 도 9는 본 발명의 실시예와 종래 기술에 따라 수행된 광범위한 이미지 블렌딩 작업 결과를 비교한 도면이다. 광범위한 이미지 블렌딩 작업은 서로 다른 두개의 이미지 사이에 중간 이미지를 생성하여 하나의 파노라마 이미 지를 생성하는 작업이다. 도 9의 (a)는 이미지 캡션 모듈을 통해 생성한 언어 힌트(\"An aerial view of a city and a body of water\")를 사용하여 텍스트-가이드 조작 모듈에 의해 누락된 영역의 이미지를 예측하고, 예측한 이미지로 채워진 확장 이미지를 나타낸다. 도 9의 (b)는 종래의 방식으로 이미지 블렝딩 작업이 수행되어 확장된 이미지 를 나타낸다. 종래의 방식은 BRIDGE 알고리즘이 사용되었다. 도 9의 (c)는 이미지 캡션 모듈을 통해 생성한 언어 힌트(\"A view of the city at night with mountaions in the background\")를 사용하여 텍스트-가이드 조작 모듈에 의해 누락된 영역의 이미지를 예측하고, 예측 한 이미지로 채워진 확장 이미지를 나타낸다. 도 9의 (d)는 종래의 방식으로 이미지 블렝딩 작업이 수행되어 확 장된 이미지를 나타낸다. 도 9의 (a)와 도 9의 (b), 도 9의 (c)와 도 9의 (d)를 비교하면, 본 발명을 적용한 파노라마 이미지가 원래의 이미지와 동일하게 연장된 자연스러운 이미지를 연출함을 확인할 수 있다. 이상 기재한 바에 따르면, CEP 모듈은 종래와 같이 단순히 주어진 이미지를 재배열하거나 비슷한 내용의 이미지 힌트를 생성해 내어 이미지에 이어 붙이는 것이 아니라, 주어진 이미지의 내용을 담은 텍스트 형태의 이 미지를 생성한다. 텍스트 형태의 힌트, 즉, 언어 힌트는 이미지 구조에 의존적이지 않기 때문에, 방향 또는 영 상 완성 과업에 대한 제약 없이 모든 영상 완성 상황에 적용이 가능하다. 이러한 언어 힌트를 사용하기 위해 CEP 모듈은 이미지 캡션 모듈을 통해 주어진 이미지의 캡션인 언 어 힌트를 생성한 뒤, 텍스트-가이드 조작 모듈을 통해 언어 힌트의 가이드에 따라 누락된 영역의 이미지 를 예측한다. 종래의 이미지 캡션 모델들은 이미지 일부가 누락되었을 때 잘못된 캡션을 생성할 수 있지만, 본 발명의 이미지 캡션 모듈은 랜덤 마스크로 최적화되었으므로, 누락 영역에 대한 정확한 캡션, 즉, 언어 힌 트를 예측할 수 있다. 이미지 캡션 모듈과 텍스트-가이드 조작 모듈은 텍스트-이미지 데이터 셋으로 사전 학습되어 뛰어난 성능을 나타냄을 도 8과 도 9를 통해 증명하였다. 한편, 도 10은 실시예에 따른 컴퓨팅 장치의 하드웨어 구성을 나타낸 블록도로서, 도 1 ~ 도 9에서 설명한 CEP 모듈은 컴퓨팅 장치로 구현될 수 있다. 도 10을 참조하면, 컴퓨팅 장치는 하나 이상의 프로세서, 프로세서에 의하여 수행되는 프로그램 을 로드하는 메모리, 프로그램 및 각종 데이터를 저장하는 스토리지, 및 통신 인터페이스를 포 함하고, 이들은 버스를 통해 연결된다. 다만, 상술한 구성 요소들은 본 개시에 따른 컴퓨팅 장치를 구현하는데 있어서 필수적인 것은 아니어서, 컴퓨팅 장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 예컨대 컴퓨팅 장치는 출력부 및/또는 입력부(미도시)를 더 포함하거나, 또는 스토리지가 생략될 수도 있다. 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법/동작을 수 행하게끔 하는 명령어들(instructions)을 포함할 수 있다. 프로세서는 도 1 ~ 도 9에서 설명한 이미지 캡션 모듈 및 텍스트-가이드 조작 모듈의 동작을 수 행하는 명령어들을 실행함으로써, 본 개시의 다양한 실시예에 따른 방법/동작들을 수행할 수 있다. 프로그램은기능을 기준으로 묶인 일련의 컴퓨터 판독가능 명령어들로 구성되고, 프로세서에 의해 실행되는 것을 가리킨다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또 한, 프로세서는 본 개시의 다양한 실시예들에 따른 방법/동작을 실행하기 위한 적어도 하나의 애플리케이 션 또는 프로그램에 대한 연산을 수행할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 개시의 다양한 실시예들에 따른 방법/동작을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드할 수 있다. 메모리는 RAM 과 같은 휘발성 메모리로 구현될 수 있을 것이나, 본 개시의 기술적 범위는 이에 한정되지 않는다. 스토리지는 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 통신 인터페이스는 유/무선 통신 모 듈일 수 있다. 이상에서 설명한 본 발명의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 발명의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2022-0190941", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 한 실시예에 따른 캡션 기반 광범위한 페인팅(Captioning-based Extensive Painting, CEP) 모듈의 구성 을 나타낸 블록도이다. 도 2는 도 1에서 이미지 캡션 모듈의 구성을 나타낸 블록도이다.도 3은 한 실시예에 따른 이미지 캡션 모듈의 학습 과정을 설명하는 순서도이다. 도 4는 한 실시예에 따른 CEP 모듈의 동작을 설명하는 순서도이다. 도 5는 한 실시예에 따른 이미지 아웃페인팅 동작을 설명한다. 도 6은 한 실시예에 따른 광범위한 이미지 블렌딩(Wide-range Image Blending) 동작을 설명한다. 도 7은 한 실시예에 따른 광범위한 이미지 블렌딩 절차를 설명한다. 도 8은 본 발명의 실시예와 종래 기술에 따라 수행된 이미지 아웃페인팅 작업 결과를 비교한 도면이다. 도 9는 본 발명의 실시예와 종래 기술에 따라 수행된 광범위한 이미지 블렌딩 작업 결과를 비교한 도면이다. 도 10은 실시예에 따른 컴퓨팅 장치의 하드웨어 구성을 나타낸 블록도이다."}
