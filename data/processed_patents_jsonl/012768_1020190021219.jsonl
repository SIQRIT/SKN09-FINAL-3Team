{"patent_id": "10-2019-0021219", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0109714", "출원번호": "10-2019-0021219", "발명의 명칭": "증강 현실 기반의 학습 서비스 제공 방법, 단말, 및 컴퓨터 판독 가능한 기록 매체에 저장된", "출원인": "주식회사 매트릭스나인", "발명자": "이종옥"}}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라로부터 수신한 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 디스플레이에 표시하는단계;상기 가상 공간에 캐릭터를 표시하는 단계;사용자의 입력이 있는 경우, 상기 캐릭터에 의해 상기 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 상기 가상 공간에 출력하는 단계;상기 학습 아이템에 대한 응답을 상기 사용자로부터 수신하는 단계; 및상기 응답을 기초로 상기 캐릭터의 상태를 업데이트하는 단계를 포함하는,증강 현실 기반 학습 서비스 제공 방법."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 가상 공간을 표시하는 단계는,상기 수신한 영상에서 상기 사물을 인식하는 단계;상기 가상 공간에서의 상기 사물의 위치를 추정하는 단계; 및상기 추정된 위치에 상기 오브젝트를 생성하는 단계를 포함하는,증강 현실 기반 학습 서비스 제공 방법."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 시각적 피드백을 출력하는 단계는,상기 캐릭터에 대한 상기 사용자의 입력이 있는 경우, 상기 캐릭터가 상기 오브젝트와 인터랙션하게 끔 상기 캐릭터를 제어하는 단계를 포함하는,증강 현실 기반 학습 서비스 제공 방법."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,특정 입력 및 인공 감정 모델을 통해 상기 캐릭터의 인공 감정을 결정하는 단계; 및 상기 캐릭터가 상기 결정된 인공 감정을 표현하도록 상기 캐릭터를 제어하는 단계공개특허 10-2019-0109714-3-를 더 포함하는,증강 현실 기반 학습 서비스 제공 방법."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 인공 감정을 결정하는 단계는,상기 사용자의 발화 음성을 입력받은 경우, 상기 발화 음성에 대응되는 음성 신호를 서버로 전송하는 단계;상기 서버로부터 상기 음성 신호에 대응되는 행위(action) 정보를 수신하는 단계; 및상기 수신된 행위 정보 및 상기 인공 감정 모델을 이용하여 상기 인공 감정을 결정하는 단계를 포함하는,증강 현실 기반 학습 서비스 제공 방법."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 업데이트하는 단계는,상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터의 경험치를 업데이트하는 단계를 포함하는, 증강 현실 기반 학습 서비스 제공 방법."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 업데이트하는 단계는,상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터에게 보상 아이템을 제공하는 단계를 포함하는,증강 현실 기반 학습 서비스 제공 방법."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어에 있어서,상기 소프트웨어는,카메라 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 디스플레이에 표시하는 단계;상기 가상 공간에 캐릭터를 표시하는 단계;사용자의 입력이 있는 경우, 상기 캐릭터에 의해 상기 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 상기 가상 공간에 출력하는 단계;상기 학습 아이템에 대한 응답을 상기 사용자로부터 수신하는 단계; 및상기 응답을 기초로 상기 캐릭터의 상태를 업데이트하는 단계공개특허 10-2019-0109714-4-를 수행하도록 구현되는,컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 가상 공간을 표시하는 단계는,상기 수신한 영상에서 상기 사물을 인식하는 단계;상기 가상 공간에서의 상기 사물의 위치를 추정하는 단계; 및상기 추정된 위치에 상기 오브젝트를 생성하는 단계를 포함하는,컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 시각적 피드백을 출력하는 단계는,상기 캐릭터에 대한 상기 사용자의 입력이 있는 경우, 상기 캐릭터가 상기 오브젝트와 인터랙션하게 끔 상기 캐릭터를 제어하는 단계를 포함하는,컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 소프트웨어는,특정 입력 및 인공 감정 모델을 통해 상기 캐릭터의 인공 감정을 결정하는 단계; 및 상기 캐릭터가 상기 결정된 인공 감정을 표현하도록 상기 캐릭터를 제어하는 단계를 더 수행하도록 구현되는,컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인공 감정을 결정하는 단계는,상기 사용자의 발화 음성을 입력받은 경우, 상기 발화 음성에 대응되는 음성 신호를 서버로 전송하는 단계;상기 서버로부터 상기 음성 신호에 대응되는 행위(action) 정보를 수신하는 단계; 및상기 수신된 행위 정보 및 상기 인공 감정 모델을 이용하여 상기 인공 감정을 결정하는 단계를 포함하는,공개특허 10-2019-0109714-5-컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 업데이트하는 단계는,상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터의 경험치를 업데이트하는 단계를 포함하는, 컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 업데이트하는 단계는,상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터에게 보상 아이템을 제공하는 단계를 포함하는,컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "디스플레이; 및카메라로부터 수신한 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 상기 디스플레이에표시하고, 상기 가상 공간에 캐릭터를 표시하며, 사용자의 입력이 있는 경우, 상기 캐릭터에 의해 상기 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 상기 가상 공간에 출력하고, 상기 학습 아이템에 대한 응답을 상기 사용자로부터 수신하고, 상기 응답을 기초로 상기 캐릭터의 상태를 업데이트하는 컨트롤러를 포함하는,단말."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 컨트롤러는,상기 수신한 영상에서 상기 사물을 인식하고, 상기 가상 공간에서의 상기 사물의 위치를 추정하며, 상기 추정된위치에 상기 오브젝트를 생성하는,단말."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 컨트롤러는,상기 캐릭터에 대한 상기 사용자의 입력이 있는 경우, 상기 캐릭터가 상기 오브젝트와 인터랙션하게 끔 상기 캐공개특허 10-2019-0109714-6-릭터를 제어하는,단말."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 컨트롤러는,특정 입력 및 인공 감정 모델을 통해 상기 캐릭터의 인공 감정을 결정하고, 상기 캐릭터가 상기 결정된 인공 감정을 표현하도록 상기 캐릭터를 제어하는,단말."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 컨트롤러는,상기 사용자의 발화 음성을 입력받은 경우, 상기 발화 음성에 대응되는 음성 신호를 서버로 전송하고, 상기 서버로부터 상기 음성 신호에 대응되는 행위(action) 정보를 수신하며, 상기 수신된 행위 정보 및 상기 인공 감정모델을 이용하여 상기 인공 감정을 결정하는,단말."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서,상기 컨트롤러는,상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터의 경험치를 업데이트 하는, 단말."}
{"patent_id": "10-2019-0021219", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항에 있어서,상기 컨트롤러는,상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터에게 보상 아이템을 제공하는,단말."}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "증강 현실 기반 학습 서비스 제공 방법이 개시된다. 일 실시예는 카메라로부터 수신한 영상 내의 사물에 대응되 는 오브젝트를 포함하는 가상 공간을 디스플레이에 표시하고, 상기 가상 공간에 캐릭터를 표시하며, 상기 사용자 의 입력이 있는 경우, 상기 캐릭터에 의해 상기 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 상기 가상 공간에 출력하고, 상기 학습 아이템에 대한 응답을 상기 사용자로부터 수신하고, 상기 응답을 기초로 상기 캐릭터의 상태를 업데이트한다."}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 증강 현실 기반의 학습 서비스 제공에 관한 것이다."}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 학습자는 증강 현실 기기를 통해 현실에 덧씌워진 교육 콘텐츠를 제공받을 수 있다. 관련 선행기술로, 한국 공개특허공보 제10-2017-0064026호(발명의 명칭: 가상현실, 증강현실 기반의 3차원 실감 형 천체교육용 스마트 교육서비스 제공방법, 출원인: 주식회사 포디비전)가 있다. 해당 공개특허공보에는 학습 대상에 대한 천체 이미지 교재부를 단말기 또는 서버부에 등록하는 과정 및 단말기로부터 학습대상에 대한 영상 이 수집되면 상기 영상에 대응되는 3차원 가상현실, 증강현실 콘텐츠를 보여주기 위한 이미지 매칭 정보 처리과 정이 개시된다."}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측에 따른 증강 현실 기반 학습 서비스 제공 방법은 카메라 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 디스플레이에 표시하는 단계; 상기 가상 공간에 캐릭터를 표시하는 단계; 사용자의 입력이 있는 경 우, 상기 캐릭터에 의해 상기 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 상기 가상 공간에 출력 하는 단계; 상기 학습 아이템에 대한 응답을 상기 사용자로부터 수신하는 단계; 및 상기 응답을 기초로 상기 캐 릭터의 상태를 업데이트하는 단계를 포함한다. 상기 가상 공간을 표시하는 단계는 상기 수신한 영상에서 상기 사물을 인식하는 단계; 상기 가상 공간에서의 상 기 사물의 위치를 추정하는 단계; 및 상기 추정된 위치에 상기 오브젝트를 생성하는 단계를 포함할 수 있다. 상기 시각적 피드백을 출력하는 단계는 상기 캐릭터에 대한 상기 사용자의 입력이 있는 경우, 상기 캐릭터가 상 기 오브젝트와 인터랙션하게 끔 상기 캐릭터를 제어하는 단계를 포함할 수 있다. 상기 증강 현실 기반 학습 서비스 제공 방법은 특정 입력 및 인공 감정 모델을 통해 상기 캐릭터의 인공 감정을 결정하는 단계; 및 상기 캐릭터가 상기 결정된 인공 감정을 표현하도록 상기 캐릭터를 제어하는 단계를 더 포함 할 수 있다. 상기 인공 감정을 결정하는 단계는 상기 사용자의 발화 음성을 입력받은 경우, 상기 발화 음성에 대응되는 음성 신호를 서버로 전송하는 단계; 상기 서버로부터 상기 음성 신호에 대응되는 행위(action) 정보를 수신하는 단계; 및 상기 수신된 행위 정보 및 상기 인공 감정 모델을 이용하여 상기 인공 감정을 결정하는 단계를 포함할 수 있다. 상기 업데이트하는 단계는 상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터의 경험치를 업데이트하는 단계를 포함할 수 있다. 상기 업데이트하는 단계는 상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터에게 보상 아이템을 제공 하는 단계를 포함한다. 일 측에 따른 컴퓨터 판독 가능한 기록 매체에 저장되는 소프트웨어에 있어서, 상기 소프트웨어는 카메라 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 디스플레이에 표시하는 단계; 상기 가상 공간에 캐릭터 를 표시하는 단계; 사용자의 입력이 있는 경우, 상기 캐릭터에 의해 상기 오브젝트에 관한 학습 아이템이 제공 되는 시각적 피드백을 상기 가상 공간에 출력하는 단계; 상기 학습 아이템에 대한 응답을 상기 사용자로부터 수 신하는 단계; 및 상기 응답을 기초로 상기 캐릭터의 상태를 업데이트하는 단계를 수행하도록 구현된다. 상기 가상 공간을 표시하는 단계는 상기 수신한 영상에서 상기 사물을 인식하는 단계; 상기 가상 공간에서의 상 기 사물의 위치를 추정하는 단계; 및 상기 추정된 위치에 상기 오브젝트를 생성하는 단계를 포함할 수 있다. 상기 시각적 피드백을 출력하는 단계는 상기 캐릭터에 대한 상기 사용자의 입력이 있는 경우, 상기 캐릭터가 상 기 오브젝트와 인터랙션하게 끔 상기 캐릭터를 제어하는 단계를 포함할 수 있다. 상기 소프트웨어는 특정 입력 및 인공 감정 모델을 통해 상기 캐릭터의 인공 감정을 결정하는 단계; 및 상기 캐 릭터가 상기 결정된 인공 감정을 표현하도록 상기 캐릭터를 제어하는 단계를 더 수행하도록 구현될 수 있다.상기 인공 감정을 결정하는 단계는 상기 사용자의 발화 음성을 입력받은 경우, 상기 발화 음성에 대응되는 음성 신호를 서버로 전송하는 단계; 상기 서버로부터 상기 음성 신호에 대응되는 행위(action) 정보를 수신하는 단계; 및 상기 수신된 행위 정보 및 상기 인공 감정 모델을 이용하여 상기 인공 감정을 결정하는 단계를 포함할 수 있다. 상기 업데이트하는 단계는 상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터의 경험치를 업데이트하는 단계를 포함할 수 있다. 상기 업데이트하는 단계는 상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터에게 보상 아이템을 제공 하는 단계를 포함할 수 있다. 일 측에 따른 단말은 디스플레이; 및 카메라로부터 수신한 영상 내의 사물에 대응되는 오브젝트를 포함하는 가 상 공간을 상기 디스플레이에 표시하고, 상기 가상 공간에 캐릭터를 표시하며, 상기 사용자의 입력이 있는 경우, 상기 캐릭터에 의해 상기 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 상기 가상 공간에 출 력하고, 상기 학습 아이템에 대한 응답을 상기 사용자로부터 수신하고, 상기 응답을 기초로 상기 캐릭터의 상태 를 업데이트하는 컨트롤러를 포함한다. 상기 컨트롤러는 상기 수신한 영상에서 상기 사물을 인식하고, 상기 가상 공간에서의 상기 사물의 위치를 추정 하며, 상기 추정된 위치에 상기 오브젝트를 생성할 수 있다. 상기 컨트롤러는 상기 캐릭터에 대한 상기 사용자의 입력이 있는 경우, 상기 캐릭터가 상기 오브젝트와 인터랙 션하게 끔 상기 캐릭터를 제어할 수 있다. 상기 컨트롤러는 특정 입력 및 인공 감정 모델을 통해 상기 캐릭터의 인공 감정을 결정하고, 상기 캐릭터가 상 기 결정된 인공 감정을 표현하도록 상기 캐릭터를 제어할 수 있다. 상기 컨트롤러는 상기 사용자의 발화 음성을 입력받은 경우, 상기 발화 음성에 대응되는 음성 신호를 서버로 전 송하고, 상기 서버로부터 상기 음성 신호에 대응되는 행위(action) 정보를 수신하며, 상기 수신된 행위 정보 및 상기 인공 감정 모델을 이용하여 상기 인공 감정을 결정할 수 있다. 상기 컨트롤러는 상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터의 경험치를 업데이트할 수 있다. 상기 컨트롤러는 상기 학습 아이템에 대한 정답이 입력된 경우, 상기 캐릭터에게 보상 아이템을 제공할 수 있다."}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들은 실제 사물을 비출 때 마다 나타나는 오브젝트를 통해 사물에 대한 호기심을 자극하고 이를 자연스럽 게 학습으로 연결 시켜 줄 수 있다. 또한, 실시예들은 생활 속의 사물을 사용하기 때문에 생활 공간과 학습 공 간이 하나로 통합되어, 사용자가 더 쉽게 배우고 학습한 것을 더 오래동안 기억하게 할 수 있다. 실시예들은 사용자가 캐릭터와 협동 및/또는 경쟁을 하게 함으로써 사용자가 학습을 공부가 아닌 놀이로서 인식 하고 즐기게 해줄 수 있다. 또한, 실시예들은 사용자가 학습하는 것이 아닌 사용자보다 미약한 존재를 가르쳐 주는 스토리텔링 활용함으로써 사용자의 학습 효과를 상승 시킬 수 있다."}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면을 참조하여 실시예들을 상세하게 설명한다. 그러나, 실시예들에는 다양한 변경이 가해 질 수 있어서 특허출원의 권리 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 실시예들에 대한 모든 변경, 균등물 내지 대체물이 권리 범위에 포함되는 것으로 이해되어야 한다. 실시예에서 사용한 용어는 단지 설명을 목적으로 사용된 것으로, 한정하려는 의도로 해석되어서는 안된다. 단 수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조부호를 부여 하고 이에 대한 중복되는 설명은 생략하기로 한다. 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적 인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 도 1은 일 실시예에 따른 단말을 설명하기 위한 도면이다. 도 1을 참조하면, 일 실시예에 따른 단말은 카메라를 통해 사물을 촬영할 수 있고 카메라 영상에서 사물을 인식할 수 있다. 사물 인식 방식에는 크게 마크 기반 사물 인식과 딥러닝 방식을 이용한 사물 인식이 있다. 마크 기반 사물 인식은 어플리케이션에 등록되거나 어플리케이션의 서버에 등록할 때 사용한 이미지(또는 사물 의 형상)와 동일한 이미지를 비추었을 때 사물을 인식할 수 있다. 마크 기반 사물 인식은 학습을 위해 미리 만 들어진 교재나 교구에만 의존해서 학습을 진행하게 된다. 딥러닝 방식을 이용한 사물 인식은 사물에 대한 보편 적인 형상을 딥러닝 네트워크를 통해 학습시킨 결과로서 사물을 인식한다. 일 실시예에는 딥러닝 방식을 이용 한 사물 인식이 적용될 수 있다. 이에 따라, 일 실시예는 사용자 주변에서 찾을 수 있는 사물을 활용해서 학습 을 진행할 수 있다. 또한, 일 실시예는 사용자가 학습한 내용을 이미 사용자에게 익숙해져 있는 사물, 직접 보 고 만지고 체험할 수 있는 사물과 연관 지어 기억할 수 있게 함으로써 사용자가 학습 내용을 더 오래 기억하고, 더 재미있게 기억할 수 있게 해 줄 수 있다. 또한, 일 실시예는 교재(또는 교구)를 필요로 하지 않아, 보다 많 은 사용자에게 서비스를 보급할 수 있다. 단말은 사물 인식 결과를 기초로 가상 공간에서 오브젝트를 생성할 수 있다. 오브젝트는 카메 라를 통해 인식된 사물의 정보(예를 들어, 교육적 정보 등)를 포함하고 있는 디지털 오브젝트이다. 오브젝트 는 가상 오브젝트로 달리 표현될 수 있다. 이 때, 사물은 현실 오브젝트로 달리 표현될 수 있다. 단말은 오브젝트를 포함하는 가상 공간을 디스플레이에 표시할 수 있다. 달리 표현하면, 단말 은 증강 현실을 디스플레이에 표시할 수 있다. 단말은 가상 공간(또는 증강 현실)에 캐릭터를 노출할 수 있다. 캐릭터는 인공 지능 캐릭터에 해당한다. 캐릭터는 가상 공간(또는 증강 현실)에서 사용자와 커뮤니케이션하고 콘텐츠(예를 들어, 학습 콘텐츠)의 진행을 가이드할 수 있다. 또한, 캐릭터는 오브젝트와 인터렉션하고, 이러한 인터렉션을 통해 오브젝트에 포함된 교육적 정보(예를 들어, 오브젝트에 해당하는 영어 단어)를 사용자에게 제공 할 수 있다. 또한, 캐릭터는 오브젝트와의 인터렉션을 통해 사물에 대해 학습할 수 있고, 보상(예를 들어, 아이템)을 획득할 수 있다. 또한, 캐릭터는 오브젝트와의 인터랙션을 통해 감정을 표현할 수 있다. 사용자는 입력(예를 들어, 음성 입력, UI(user interface)를 통한 입력)을 통해 캐릭터에게 명령을 전달하 거나 캐릭터와 대화할 수 있다. 캐릭터는 사용자의 입력에 따라 자신의 감정을 표현할 수 있다. 일 실시예에 따르면, 단말은 증강 현실을 이용한 캐릭터 및 캐릭터를 활용한 학습 서비스를 사 용자에게 제공할 수 있어, 사용자가 보다 쉽게 학습하도록 할 수 있다. 또한, 단말은 사용자가 캐릭터 와 협동 또는 경쟁하게 함으로써 사용자가 학습을 놀이로 인식하게 할 수 있고 즐기게 해 줄 수 있다. 또 한, 단말은 사용자가 공부하는 것이 아닌 사용자보다 미약한 존재(예를 들어, 캐릭터)를 가르쳐 주는 스토리텔링을 활용함으로써 사용자의 학습 효과를 향상시킬 수 있다. 도 2는 일 실시예에 따른 단말이 영상 내의 사물을 가상 공간 상의 오브젝트로 표현하는 것을 설명하기 위한 순 서도이다. 도 2를 참조하면, 단말은 영상을 분석한다. 달리 표현하면, 단말은 영상 내의 사물을 인식한다. 일례로, 단말은 카메라 영상에서 사물을 인식할 수 있다. 단말은 가상 공간 내의 사물의 위치를 추정한다. 다시 말해, 단말은 카메라 영상 속의 사물이 카메라 영상에 기반한 가상 공간 상에서 어디쯤 위치할 것인지를 추정할 수 있다. 일례로, 단말은 Object Detection 알고리즘과 Plane Anchor를 활용하여 가상 공간 상에서의 사물의 위치를 추정할 수 있다. 보다 구체 적으로, 단말은 Object Detection 알고리즘을 통해 카메라 영상에서 사물의 영역을 식별할 수 있고, 사용 자가 서 있는 평면에 대응되는 가상 평면 위에 식별된 영역의 사물을 투영(projection)으로써 사물이 가상 공간 상에서 어디쯤 위치하는지를 추정할 수 있다. 다른 일례로, 단말은 Image Classification 알고리즘과 Point Cloud를 활용하여 가상 공간 상에서의 사물의 위치를 추정할 수 있다. 보다 구체적으로, 단말은 Image Classification 알고리즘을 통해 영상 속의 사물의 명칭을 식별할 수 있고, Point Cloud를 통해 사물이 카메라로부터 떨어진 거리를 파악함으로써 사물이 가상 공간 상에서 어디쯤 위치하는지를 추정할 수 있다. 단말은 사물의 정보를 생성한다. 보다 구체적으로, 단말은 여러 사물들 각각의 교육적 정보를 저장하는 데이터베이스에 접속할 수 있고, 인식된 사물의 교육적 정보(또는 학습 아이템)를 해당 데이터베이스 로부터 수신할 수 있다. 일례로, 영상에서 인식된 사물이 노트북이면, 단말은 데이터베이스에 접속하여 노트북의 교육적 정보(예를 들어, 노트북의 영어 단어 \"notebook\"을 학습하기 위한 학습 콘텐츠 또는 학습 아이 템)를 수신할 수 있다. 단말은 가상 공간에 사물에 대응되는 오브젝트를 생성한다. 일례로, 단말은 추정된 위치 에 오브젝트를 생성할 수 있다. 이 때, 오브젝트는 데이터베이스로부터 수신한 사물의 교육적 정보 를 포함할 수 있다. 도 3 내지 도 5는 일 실시예에 따른 단말이 오브젝트를 이용하여 사물을 캐릭터에게 알려주는 것을 설명하기 위 한 순서도이다. 도 3을 참조하면, 단말은 가상 공간에 캐릭터를 노출한다. 다시 말해, 단말은 증강 현실 (또는 증강 현실 영상)에 캐릭터를 노출한다. 이에 대한 일례가 도 4에 도시된다. 도 4에 도시된 예를 참조하면, 단말은 노트북의 오브젝트를 포함하는 가상 공간에 캐릭터를 노출할 수 있다. 다시 도 3으로 돌아와서, 단말은 캐릭터가 사용자에게 오브젝트에 대해 질문하게 끔 캐릭터 를 제어하고, 사용자로부터 입력 받은 답을 기초로 캐릭터의 상태를 업데이트한다. 일례 로, 도 5에 도시된 예를 참조하면, 캐릭터에 사용자 입력(예를 들어, 터치)이 있으면, 캐릭터는 노트 북의 오브젝트와 인터랙션할 수 있고 해당 인터랙션을 통해 노트북에 해당하는 영어 단어가 notebook이 맞 는지 여부를 사용자에게 질문할 수 있다. 사용자는 화면 하단의 Yes 버튼 및 No 버튼 중에서 Yes 버튼에 입력 을 인가할 수 있다. 사용자 입력이 있으면, 단말은 캐릭터의 상태(예를 들어, 캐릭터의 경험치 등)를 변경할 수 있다. 또한, 사용자 입력이 있으면, 단말은 노트북 촬영 이미지를 서버로 전송할 수 있 고, 서버는 노트북 촬영 이미지를 저장할 수 있다. 여러 촬영 이미지들이 서버에 누적되면, 서버는 여러 촬영 이미지들을 활용하여 사물 인식 딥러닝 네트워크를 트레이닝함으로써 사물 인식률을 개선할 수 있다. 또한, 사 용자는 노트북의 영어 단어가 notebook에 해당한다고 학습할 수 있다. 도 5에 도시된 예와 같이, 단말은 사물을 비출 때 마다 나타나는 오브젝트를 통해 사물에 대한 호기 심을 자극하고 이를 자연스럽게 학습으로 연결 시켜 줄 수 있다. 또한, 단말은 인공 지능의 캐릭터를 통해 사용자가 학습을 놀이로 인식하게 할 수 있고, 사용자가 캐릭터를 가르치는 것처럼 학습 콘텐츠를 진행할 수 있어, 사용자의 학습 효과를 향상시킬 수 있다. 도 6은 일 실시예에 따른 캐릭터의 인공 감정을 설명하기 위한 도면이다. 도 6을 참조하면, 단말은 음성 입력 인터페이스(예를 들어, 마이크)를 통해 사용자 음성을 수신한다. 단말 내의 전처리기는 사용자 음성을 전처리하여 음성 신호를 생성하고, 해당 음성 신호를 서버(62 0)로 전송한다. 서버는 단말로부터 수신한 음성 신호를 텍스트로 변환하고, 해당 텍스트를 기초로 자연어 분석을 수 행하며, 자연어 분석 결과에 해당하는 행위(action) 정보를 단말로 전송할 수 있다. 일례로, 사용자가 \" 생일이 언제야?\"를 발화한 경우, 단말은 \"생일이 언제야?\"에 해당하는 음성 신호를 서버로 전송할 수 있고 서버는 해당 음성 신호를 처리하여 행위 정보를 단말로 전송할 수 있다. 단말는 행위 정 보를 수신하는 경우, 행위 정보를 기초로 \"2019년 1월 1일이야\"의 텍스트 또는 사운드를 출력할 수 있다. 실시예에 있어서, 단말 내의 인공 감정 시스템은 입력을 기초로 캐릭터의 인공 감정을 결정할 수 있다. 여기서, 입력은 사용자 음성에 기반한 행위 정보 및/또는 UI를 통한 사용자 입력(예를 들어, 사용자 가 캐릭터를 쓰다듬는 입력)을 포함할 수 있다. 보다 구체적으로, 인공 감정 시스템은 P.A.D(Pleasure, Arousal, Dominance) 감정 모델(Emotion Model)과 OCC(Ortony, Clore, Collins) 감정 모델을 포함할 수 있고, 상술한 입력, P.A.D 감정 모델, 및 OCC 감정 모델을 통해 캐릭터의 인공 감정을 결정할 수 있다. 인공 감정 시스템은 캐릭터의 인공 감정을 결정한 경우, 캐릭터가 해당 인공 감정을 표현하게 끔 할 수 있다. 일례로, 인공 감정 시스템은 캐릭터의 인공 감정을 \"즐겁다\"로 결정하면, 가상 공간 상의 캐릭터가 즐거운 표정을 짓게끔 하거나 \"즐거워요\"의 대화창을 가상 공간에 노출시킬 수 있다. 이에 따라, 사용자는 캐릭터가 현재 즐겁다고 인식할 수 있다. 도 7은 일 실시예에 따른 단말의 증강 현실 기반 학습 서비스 제공 방법을 설명하기 위한 순서도이다. 도 7을 참조하면, 단말은 카메라로부터 수신한 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 디스플레이에 표시한다. 일례로, 단말은 카메라에 의해 촬영된 영상에서 사물을 인식할 수 있고, 가상 공간에서의 사물의 위치를 추정할 수 있으며, 추정된 위치에 오브젝트를 생성할 수 있다. 이 에 대해선 도 2를 통해 설명하였으므로, 자세한 설명을 생략한다. 단말은 가상 공간에 캐릭터를 표시한다. 이에 대한 일례를 도 4를 통해 설명하였으므로, 자세 한 설명을 생략한다. 단말은 사용자의 입력이 있는 경우, 캐릭터에 의해 오브젝트에 관한 학습 아이템이 제공되는 시 각적 피드백을 가상 공간에 출력한다. 달리 표현하면, 단말은 캐릭터를 제어하여 캐릭터 가 학습 아이템을 사용자에게 제공하게 할 수 있다. 일례로, 도 5를 통해 설명한 것과 같이, 단말은 캐릭 터에 대한 사용자 입력 또는 증강 현실 상에 대한 사용자 입력이 있으면, 오브젝트에 대한 학습 아이 템 \"notebook 맞아?\"를 증강 현실에 노출할 수 있다. 구현에 따라, 단말은 사용자로부터 오브젝트의 영어 단어를 입력할 수 있게 끔 UI를 노출할 수 있다. 단말은 학습 아이템에 대한 응답을 사용자로부터 수신한다. 일례로, 도 6을 통해 설명한 것과 같이, 단말은 사용자로부터 Yes 또는 No를 입력 받을 수 있다. 단말은 사용자의 응답을 기초로 캐릭터의 상태를 업데이트한다. 일례로, 단말은 학습 아 이템에 대한 정답이 입력된 경우(예를 들어, 도 5에 도시된 예에서 yes 버튼에 대한 사용자 입력이 있는 경우), 캐릭터의 경험치를 업데이트할 수 있다. 또한, 단말은 학습 아이템에 대한 정답이 입력된 경우, 캐 릭터에게 보상 아이템(예를 들어, 캐릭터의 레벨을 증가시키는데 필요한 아이템)을 제공할 수 있고, 캐릭터의 인공 감정을 변경시켜 캐릭터가 기뻐하는 시각적 효과를 가상 공간에 표현할 수 있다. 도 1 내지 도 6을 통해 기술된 사항들은 도 7을 통해 기술된 사항들에 적용될 수 있으므로, 상세한 설명을 생략 한다. 도 8은 일 실시예에 따른 단말을 설명하기 위한 블록도이다. 도 8을 참조하면, 일 실시예에 따른 단말은 카메라, 컨트롤러, 디스플레이, 및 메모리 를 포함한다. 메모리는 상술한 증강 현실 기반 학습 서비스 제공 방법을 구현하는 소프트웨어를 저장한다. 이러한 소프 트웨어는 카메라로부터 수신한 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 디스플 레이에 표시하고, 가상 공간에 캐릭터를 표시하며, 캐릭터에 의해 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 가상 공간에 출력하고, 학습 아이템에 대한 응답을 사용자로부터 수신하는 경우, 해당 응답을 기초로 캐릭터의 상태를 업데이트하기 위한 하나 이상의 명령어를 포함한다. 상술한 소프트웨어는 어플리케이션 또는 클라이언트로 달리 표현될 수 있다. 컨트롤러는 메모리에 저장된 소프트웨어를 실행한다. 이에 따라, 컨트롤러는 카메라로부 터 수신한 영상 내의 사물에 대응되는 오브젝트를 포함하는 가상 공간을 디스플레이에 표시하고, 가 상 공간에 캐릭터를 표시한다. 또한, 컨트롤러는 사용자의 입력이 있는 경우, 캐릭터에 의해 오브젝트에 관한 학습 아이템이 제공되는 시각적 피드백을 가상 공간에 출력한다. 또한, 컨트롤러는 학습 아이템에 대한 응답을 사용자로부터 수신하고, 해당 응답을 기초로 캐릭터의 상태를 업데이트한다. 도 1 내지 도 7을 통해 기술된 사항들은 도 8을 통해 기술된 사항들에 적용될 수 있으므로, 상세한 설명을 생략 한다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2019-0021219", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2019-0021219", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 단말을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 단말이 영상 내의 사물을 가상 공간 상의 오브젝트로 표현하는 것을 설명하기 위한 순 서도이다. 도 3 내지 도 5는 일 실시예에 따른 단말이 오브젝트를 이용하여 사물을 캐릭터에게 알려주는 것을 설명하기 위 한 순서도이다. 도 6은 일 실시예에 따른 캐릭터의 인공 감정을 설명하기 위한 도면이다.도 7은 일 실시예에 따른 단말의 증강 현실 기반 학습 서비스 제공 방법을 설명하기 위한 순서도이다. 도 8은 일 실시예에 따른 단말을 설명하기 위한 블록도이다."}
