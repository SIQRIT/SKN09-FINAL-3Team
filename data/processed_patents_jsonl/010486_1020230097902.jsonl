{"patent_id": "10-2023-0097902", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0017325", "출원번호": "10-2023-0097902", "발명의 명칭": "인터랙션 디자인을 구현하는 장치 및 방법", "출원인": "한국로봇융합연구원", "발명자": "김주현"}}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인터랙션 디자인을 기반으로 구동하는 서비스 로봇과 연동되는 인터랙션 디자인 구현장치에 있어서,상기 서비스 로봇과 사용자 간의 상호작용을 지원하기 위한 인터랙션 디자인이 수집되면 상기 서비스 로봇과 동일한 가상 로봇을 생성하고, 상기 가상 로봇 및 상기 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가포함된 제스처인 인터랙션 제스처를 생성하는 인터랙션 제스처 생성부;상기 서비스 로봇의 상황인지 상태를 기반으로 상기 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍하는 인터랙션 프로그래밍부; 및상기 프로그래밍된 인터랙션 시나리오를 상기 가상 로봇에 적용하여 시뮬레이션하고, 상기 시뮬레이션을 통해해당 인터랙션 시나리오가 상기 서비스 로봇에서 구동될 수 있는지 검증하며, 상기 검증이 완료되면 해당 인터랙션 시나리오를 상기 서비스 로봇에 제공하는 인터랙션 시뮬레이션부;를 포함하는 인터랙션 디자인 구현장치."}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 인터랙션 제스처 생성부는,상기 가상 로봇의 상체 모션, 하체 주행, 음성, 영상 및 표정 중 적어도 하나의 표현 요소를 포함하는 인터랙션제스처를 생성하는 것을 특징으로 하는 인터랙션 디자인 구현장치."}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 인터랙션 제스처 생성부는,상기 인터랙션 디자인이 기 설정된 의도에 맞는 표현을 나타내지 판단하고, 상기 판단된 결과가 기 설정된 의도와 다른 표현을 나타낸다고 판단되면 상기 인터랙션 디자인을 재수집하거나, 수정하는 것을 특징으로 하는 인터랙션 디자인 구현장치."}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 인터랙션 제스처 생성부는,상기 인터랙션 제스처가 상기 가상 로봇에서 구동이 가능한지 판단하고, 상기 판단된 결과가 상기 가상 로봇에서 구동이 불가능하다고 판단되면 상기 구동이 불가능한 이유를 검출하며, 상기 검출된 이유를 기반으로 상기인터랙션 제스처를 수정하는 것을 특징으로 하는 인터랙션 디자인 구현장치."}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 인터랙션 프로그래밍부는,상기 상황인지 상태에 대응하는 적어도 하나의 인터랙션 제스처를 노드로 생성하고, 상기 생성된 노드를 상관관계가 있는 노드와 연결하여 상기 인터랙션 시나리오를 프로그래밍하는 것을 특징으로 하는 인터랙션 디자인 구현장치.공개특허 10-2025-0017325-3-청구항 6 제 5항에 있어서,상기 인터랙션 시뮬레이션부는,상기 시뮬레이션을 통해 각 노드에 포함된 인터랙션 제스처가 연속 동작으로 구현이 가능한지 판단하고, 상기판단된 결과에서 상기 연속 동작이 불가능하다고 판단되면 상기 연속 동작이 불가능한 이유를 검출하며, 상기검출된 이유를 기반으로 상기 인터랙션 시나리오를 수정시키는 것을 특징으로 하는 인터랙션 디자인 구현장치."}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,상기 인터랙션 시뮬레이션부는,3차원 가상 공간에서 상기 가상 로봇과 가상 사용자 간의 상호작용하는 과정을 상기 인터랙션 시나리오 기반으로 시뮬레이션하는 것을 특징으로 하는 인터랙션 디자인 구현장치."}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인터랙션 디자인을 기반으로 구동하는 서비스 로봇과 연동되는 인터랙션 디자인 구현장치에 의해 수행되는 인터랙션 디자인 구현방법에 있어서,상기 서비스 로봇과 사용자 간의 상호작용을 지원하기 위한 인터랙션 디자인을 수집하는 단계;상기 서비스 로봇과 동일한 가상 로봇을 생성하고, 상기 가상 로봇 및 상기 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함된 제스처인 인터랙션 제스처를 생성하는 단계;상기 서비스 로봇의 상황인지 상태를 기반으로 상기 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍하는 단계;상기 프로그래밍된 인터랙션 시나리오를 상기 가상 로봇에 적용하여 시뮬레이션하고, 상기 시뮬레이션을 통해해당 인터랙션 시나리오가 상기 서비스 로봇에서 구동될 수 있는지 검증하는 단계; 및 상기 검증이 완료되면 해당 인터랙션 시나리오를 상기 서비스 로봇에 제공하는 단계;를 포함하는 인터랙션 디자인 구현방법."}
{"patent_id": "10-2023-0097902", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인터랙션 디자인을 기반으로 구동하는 서비스 로봇; 및상기 서비스 로봇과 연동되는 인터랙션 디자인 구현장치;를 포함하되,상기 인터랙션 디자인 구현장치는,상기 서비스 로봇과 사용자 간의 상호작용을 지원하기 위한 인터랙션 디자인이 수집되면 상기 서비스 로봇과 동일한 가상 로봇을 생성하고, 상기 가상 로봇 및 상기 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가포함된 제스처인 인터랙션 제스처를 생성하는 인터랙션 제스처 생성부;상기 서비스 로봇의 상황인지 상태를 기반으로 상기 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍하는 인터랙션 프로그래밍부; 및상기 프로그래밍된 인터랙션 시나리오를 상기 가상 로봇에 적용하여 시뮬레이션하고, 상기 시뮬레이션을 통해해당 인터랙션 시나리오가 상기 서비스 로봇에서 구동될 수 있는지 검증하며, 상기 검증이 완료되면 해당 인터랙션 시나리오를 상기 서비스 로봇에 제공하는 인터랙션 시뮬레이션부;를 포함하는 것을 특징으로 하는 인터랙션 디자인 구현시스템."}
{"patent_id": "10-2023-0097902", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인터랙션 디자인을 구현하는 장치 및 방법이 개시된다. 인터랙션 디자인을 기반으로 구동하는 서비스 로봇과 연 동되는 인터랙션 디자인 구현장치는 서비스 로봇과 사용자 간의 상호작용을 지원하기 위한 인터랙션 디자인이 수 집되면 서비스 로봇과 동일한 가상 로봇을 생성하고, 가상 로봇 및 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함된 제스처인 인터랙션 제스처를 생성하는 인터랙션 제스처 생성부, 서비스 로봇의 상황인지 상 태를 기반으로 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍하는 인터랙션 프로그래밍부 및 프로그 래밍된 인터랙션 시나리오를 가상 로봇에 적용하여 시뮬레이션하고, 시뮬레이션을 통해 해당 인터랙션 시나리오 가 서비스 로봇에서 구동될 수 있는지 검증하며, 검증이 완료되면 해당 인터랙션 시나리오를 서비스 로봇에 제공 하는 인터랙션 시뮬레이션부를 포함한다."}
{"patent_id": "10-2023-0097902", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인터랙션 디자인 구현에 관한 것으로, 더욱 상세하게는 서비스 로봇과 사용자의 상호작용을 위한 인 터랙션 구현과정을 단축하는 인터랙션 디자인을 구현하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0097902", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "노인 인구의 증가 및 부양 인력의 감소, 1인 가구 수의 증가 및 가구원 수의 감소, 출산율 감소 및 맞벌이 가구 의 증가, 반려동물 양육가구 수의 증가 등 미래 라이프 스타일의 변화에 대응하여 다양한 서비스 및 콘텐츠를 제공하는 로봇의 필요성이 대두되고 있다. 하지만 현재 제공되는 로봇은 서비스의 대상자인 사용자와 공감하기 위한 상호작용 관련 기능이 좀 더 보강되어 야 하며, 이러한 기능을 보강하기 위해서는 많은 개발 시간을 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-2497042호(2023.02.02.)"}
{"patent_id": "10-2023-0097902", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 서비스 로봇과 사용자 간의 상호작용을 위한 인터랙션 디자인을 구현하는 개발시간을 단축하는 인터랙션 디자인을 구현하는 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2023-0097902", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위해 본 발명에 따른 인터랙션 디자인을 기반으로 구동하는 서비스 로봇과 연동되는 인터 랙션 디자인 구현장치는, 상기 서비스 로봇과 사용자 간의 상호작용을 지원하기 위한 인터랙션 디자인이 수집되 면 상기 서비스 로봇과 동일한 가상 로봇을 생성하고, 상기 가상 로봇 및 상기 인터랙션 디자인을 이용하여 인 터랙션을 위한 표현 요소가 포함된 제스처인 인터랙션 제스처를 생성하는 인터랙션 제스처 생성부, 상기 서비스 로봇의 상황인지 상태를 기반으로 상기 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍하는 인터랙 션 프로그래밍부 및 상기 프로그래밍된 인터랙션 시나리오를 상기 가상 로봇에 적용하여 시뮬레이션하고, 상기 시뮬레이션을 통해 해당 인터랙션 시나리오가 상기 서비스 로봇에서 구동될 수 있는지 검증하며, 상기 검증이 완료되면 해당 인터랙션 시나리오를 상기 서비스 로봇에 제공하는 인터랙션 시뮬레이션부를 포함한다. 또한 상기 인터랙션 제스처 생성부는, 상기 가상 로봇의 상체 모션, 하체 주행, 음성, 영상 및 표정 중 적어도 하나의 표현 요소를 포함하는 인터랙션 제스처를 생성하는 것을 특징으로 한다. 또한 상기 인터랙션 제스처 생성부는, 상기 인터랙션 디자인이 기 설정된 의도에 맞는 표현을 나타내지 판단하 고, 상기 판단된 결과가 기 설정된 의도와 다른 표현을 나타낸다고 판단되면 상기 인터랙션 디자인을 재수집하 거나, 수정하는 것을 특징으로 한다. 또한 상기 인터랙션 제스처 생성부는, 상기 인터랙션 제스처가 상기 가상 로봇에서 구동이 가능한지 판단하고, 상기 판단된 결과가 상기 가상 로봇에서 구동이 불가능하다고 판단되면 상기 구동이 불가능한 이유를 검출하며, 상기 검출된 이유를 기반으로 상기 인터랙션 제스처를 수정하는 것을 특징으로 한다. 또한 상기 인터랙션 프로그래밍부는, 상기 상황인지 상태에 대응하는 적어도 하나의 인터랙션 제스처를 노드로 생성하고, 상기 생성된 노드를 상관관계가 있는 노드와 연결하여 상기 인터랙션 시나리오를 프로그래밍하는 것 을 특징으로 한다. 또한 상기 인터랙션 시뮬레이션부는, 상기 시뮬레이션을 통해 각 노드에 포함된 인터랙션 제스처가 연속 동작으 로 구현이 가능한지 판단하고, 상기 판단된 결과에서 상기 연속 동작이 불가능하다고 판단되면 상기 연속 동작 이 불가능한 이유를 검출하며, 상기 검출된 이유를 기반으로 상기 인터랙션 시나리오를 수정시키는 것을 특징으로 한다. 또한 상기 인터랙션 시뮬레이션부는, 3차원 가상 공간에서 상기 가상 로봇과 가상 사용자 간의 상호작용하는 과 정을 상기 인터랙션 시나리오 기반으로 시뮬레이션하는 것을 특징으로 한다. 본 발명에 따른 인터랙션 디자인을 기반으로 구동하는 서비스 로봇과 연동되는 인터랙션 디자인 구현장치에 의 해 수행되는 인터랙션 디자인 구현방법은, 상기 서비스 로봇과 사용자 간의 상호작용을 지원하기 위한 인터랙션 디자인을 수집하는 단계, 상기 서비스 로봇과 동일한 가상 로봇을 생성하고, 상기 가상 로봇 및 상기 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함된 제스처인 인터랙션 제스처를 생성하는 단계, 상기 서비 스 로봇의 상황인지 상태를 기반으로 상기 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍하는 단계, 상기 프로그래밍된 인터랙션 시나리오를 상기 가상 로봇에 적용하여 시뮬레이션하고, 상기 시뮬레이션을 통해 해당 인터랙션 시나리오가 상기 서비스 로봇에서 구동될 수 있는지 검증하는 단계 및 상기 검증이 완료되 면 해당 인터랙션 시나리오를 상기 서비스 로봇에 제공하는 단계를 포함한다. 본 발명에 따른 인터랙션 디자인 구현시스템은 인터랙션 디자인을 기반으로 구동하는 서비스 로봇 및 상기 서비 스 로봇과 연동되는 인터랙션 디자인 구현장치를 포함하되, 상기 인터랙션 디자인 구현장치는, 상기 서비스 로 봇과 사용자 간의 상호작용을 지원하기 위한 인터랙션 디자인이 수집되면 상기 서비스 로봇과 동일한 가상 로봇 을 생성하고, 상기 가상 로봇 및 상기 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함된 제스처 인 인터랙션 제스처를 생성하는 인터랙션 제스처 생성부, 상기 서비스 로봇의 상황인지 상태를 기반으로 상기 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍하는 인터랙션 프로그래밍부 및 상기 프로그래밍된 인터랙션 시나리오를 상기 가상 로봇에 적용하여 시뮬레이션하고, 상기 시뮬레이션을 통해 해당 인터랙션 시나 리오가 상기 서비스 로봇에서 구동될 수 있는지 검증하며, 상기 검증이 완료되면 해당 인터랙션 시나리오를 상 기 서비스 로봇에 제공하는 인터랙션 시뮬레이션부를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0097902", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 다양한 형상을 가진 서비스 로봇에 멀티모달 상호작용 제스처 생성 및 생성된 제스 처를 활용한 상호작용 시나리오를 개발하고, 검증함으로써, 장시간 소요되는 서비스 로봇과 사용자의 인터랙션 디자인을 실제 로봇에 구현하기까지의 개발시간을 단축할 수 있다."}
{"patent_id": "10-2023-0097902", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서 및 도면(이하 '본 명세서')에서, 동일한 구성요소에 대해서 중복된 설명은 생략한다. 또한 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어' 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존 재할 수도 있다고 이해되어야 할 것이다. 반면에 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '직접 연결 되어' 있다거나 '직접 접속되어' 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되 어야 할 것이다. 또한, 본 명세서에서 사용되는 용어는 단지 특정한 실시예를 설명하기 위해 사용되는 것으로써, 본 발명을 한정 하려는 의도로 사용되는 것이 아니다. 또한 본 명세서에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 또한 본 명세서에서, '포함하다' 또는 '가지다' 등의 용어는 명세서에 기재된 특징, 숫자, 단계, 동작, 구성요 소, 부품, 또는 이들을 조합한 것이 존재함을 지정하려는 것일 뿐, 하나 또는 그 이상의 다른 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이 해되어야 할 것이다. 또한 본 명세서에서, '및/또는' 이라는 용어는 복수의 기재된 항목들의 조합 또는 복수의 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서, 'A 또는 B'는, 'A', 'B', 또는 'A와 B 모두'를 포함할 수 있다. 또한 본 명세서에서, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략될 것 이다. 도 1은 본 발명의 실시예에 따른 인터랙션 디자인 구현시스템을 설명하기 위한 구성도이고, 도 2는 본 발명의 실시예에 따른 서비스 로봇과 사용자 간의 상호작용을 설명하기 위한 도면이다. 도 1 및 도 2를 참조하면, 인터랙션 디자인 구현시스템(이하 '구현시스템'이라 함)은 서비스 로봇과 사용자(U) 간의 상호작용을 위한 인터랙션 디자인을 구현하는 개발시간을 단축한다. 구현시스템은 인터랙 션 디자인 구현장치(이하 '구현장치'라 함) 및 서비스 로봇를 포함하고, 인터랙션 디자인 제공서버 (이하 '제공서버'라 함) 및 관리자 단말를 더 포함할 수 있다. 구현장치는 서비스 로봇과 연동하며, 서비스 로봇의 동작과 관련된 인터랙션 디자인이 구현될 수 있도록 지원한다. 구현장치는 서비스 로봇과 사용자(U) 간의 상호작용을 지원하기 위한 인터랙션 디자인을 수집한다. 이때 구현장치는 인터랙션 디자인 제공서버 또는 관리자 단말로부터 인터랙 션 디자인을 수집할 수 있다. 구현장치는 인터랙션 디자인이 수집되면 서비스 로봇과 동일한 가상 로봇을 생성하고, 가상 로봇 및 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함된 제스처인 인터랙션 제스처를 생성한다. 구현장치는 서비스 로봇의 상황인지 상태를 기반으로 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍한다. 구현장치는 프로그래밍된 인터랙션 시나리오를 가상 로봇에 적용하 여 시뮬레이션을 한다. 구현장치는 시뮬레이션을 통해 해당 인터랙션 시나리오가 서비스 로봇에서 구 동할 수 있는지 검증하고, 검증이 완료되면 해당 인터랙션 시나리오를 서비스 로봇에 제공한다. 서비스 로봇은 사용자(U)와의 공감을 위한 서비스를 제공하기 위해 상호작용 기능을 포함한다. 이를 위해 서비스 로봇은 인터랙션 디자인을 기반으로 구동한다. 서비스 로봇은 구현장치로부터 검증된 인 터랙션 시나리오를 수신하고, 수신된 인터랙션 시나리오를 기반으로 사용자(U)와의 상호작용을 수행한다. 이때 서비스 로봇은 마이크, 카메라, 라이다 센서 등이 포함된 센서 모듈, 사용자(U)의 음성 인식, 제스처 인식, 얼굴 인식 등을 수행하는 인식 모듈 및 현재 상황을 인지하는 상황 인지 모듈을 포함할 수 있 다. 즉 서비스 로봇은 센서 모듈, 인식 모듈 및 상황 인지 모듈을 기반으로 로봇 표현 요 소인 디스플레이, 말하기, 모션, 주행 등을 수행함으로써, 사용자(U)와의 상호작용이 이루어지도록 한다. 여기 서 상황 인지 모듈은 인공지능 기술이 접목된 인식 알고리즘을 포함할 수 있으나, 이에 한정하지 않는다. 서비스 로봇은 사용자(U)와의 상호작용 관련 모니터링 정보를 생성할 수 있으며, 생성된 모니터링 정보를 관리자 단말로 전송할 수 있다. 서비스 로봇은 미래 라이프 스타일에 부합하는 모듈러형 플랫폼을 가 지는 생활 서비스 로봇일 수 있으며, 하체가 자율 주행 모빌리티 플랫폼을 포함할 수 있고, 상체가 용도에 따라 다양한 자유도를 가지는 로봇 플랫폼을 포함할 수 있다. 제공서버는 인터랙션 디자인을 구현장치에 제공한다. 제공서버는 다양한 인터랙션 디자인을 저 장한다. 여기서 제공서버는 구현장치로부터 인터랙션 디자인을 요청하는 요청 신호가 수신되면 요청 신호와 관련된 인터랙션 디자인을 검색한다. 제공서버는 검색된 인터랙션 디자인을 구현장치로 전송 한다. 관리자 단말는 관리자(예: 연구자, 엔지니어 등)가 사용하는 단말로써, 서비스 로봇 및 사용자(U) 간 의 상호작용을 하는 과정을 모니터링한다. 관리자 단말는 서비스 로봇으로부터 모니터링 정보를 수신 하면 수신된 모니터링 정보를 이용하여 서비스 로봇과 사용자(U) 간의 상호작용이 원활하게 이루어지고 있 는지 모니터링한다. 만약 상호작용이 원활히 이루어지지 않으면 관리자 단말은 알림 신호 또는 경보 신호 를 출력할 수 있다. 또한 관리자 단말은 구현장치로부터 인터랙션 디자인을 요청하는 요청신호를 수 신하면 기 저장된 인터랙션 디자인을 구현장치로 전송할 수 있다. 한편 구현시스템은 구현장치, 서비스 로봇, 제공서버 및 관리자 단말 사이에 통신망 을 구축하여 서로 간에 통신이 이루어지도록 지원한다. 통신망은 백본망과 가입자망으로 구성될 수 있다. 백본망은 X.25 망, Frame Relay 망, ATM망, MPLS(Multi-Protocol Label Switching) 망 및 GMPLS(Generalized Multi-Protocol Label Switching) 망 등 중에 하나 또는 복수의 통합된 망으로 구성될 수 있다. 가입자망은 FTTH(Fiber To The Home), ADSL(Asymmetric Digital Subscriber Line), 케이블망, 지그비 (zigbee), 블루투스(bluetooth), Wireless LAN(IEEE 802.11b, IEEE 802.11a, IEEE 802.11g, IEEE 802.11n), Wireless Hart(ISO/IEC62591-1), ISA100.11a(ISO/IEC 62734), CoAP(Constrained Application Protocol), MQTT(Message Queuing Telemetry Transport), WIBro(Wireless Broadband), Wimax, 3G, HSDPA(High Speed Downlink Packet Access), 4G, 5G 및 6G 등일 수 있다. 일부 실시예로, 통신망은 인터넷망일 수 있고, 이 동 통신망일 수 있다. 또한 통신망은 기타 널리 공지되었거나 향후 개발될 모든 무선통신 또는 유선통신 방식을 포함할 수 있다. 도 3은 본 발명의 실시예에 따른 인터랙션 디자인 구현장치를 설명하기 위한 블록도이고, 도 4는 본 발명의 실 시예에 따른 제어부를 설명하기 위한 블록도이며, 도 5는 본 발명의 실시예에 따른 인터랙션 제스처 생성을 설 명하기 위한 도면이고, 도 6는 본 발명의 실시예에 따른 인터랙션 프로그래밍을 설명하기 위한 도면이며, 도 7 은 본 발명의 실시예에 따른 인터랙션 시뮬레이션을 설명하기 위한 도면이다. 도 1 내지 도 7을 참조하면, 구현장치는 통신부, 제어부, 출력부 및 저장부를 포함한 다. 통신부는 서비스 로봇, 제공서버 및 관리자 단말과 통신을 수행한다. 통신부는 서비 스 로봇로부터 상황인지 상태 관련 정보를 수신하고, 검증된 인터랙션 시나리오 관련 정보를 서비스 로봇 으로 전송한다. 통신부는 제공서버 또는 관리자 단말로부터 인터랙션 디자인 관련 정보를 수신한다. 제어부는 구현장치의 전반적인 제어를 수행한다. 제어부는 인터랙션 디자인을 기반으로 인터랙 션 제스처를 생성하고, 생성된 인터랙션 제스처를 기반으로 인터랙션 시나리오를 프로그래밍하며, 프로그래밍된 인터랙션 시나리오를 검증한다. 이를 위해 제어부는 인터랙션 제스처 생성부, 인터랙션 프로그래밍부 및 인터랙션 시뮬레이션부를 포함한다. 인터랙션 제스처 생성부는 인터랙션 디자인이 수집되면 서비스 로봇과 동일한 가상 로봇을 생성한다. 이때 가상 로봇은 실제 서비스 로봇과 동일한 형태로 형성된 3차원 공간의 로봇일 수 있다. 인터랙션 제스처 생성부 는 가상 로봇 및 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함된 제스처인 인터랙션 제 스처를 생성한다. 여기서 인터랙션 제스처는 가상 로봇의 상체 모션, 하체 주행, 음성(또는 효과음), 영상 및 표정(예: LED, 디스플레이) 중 적어도 하나의 표현 요소를 포함한다. 이를 위해 인터랙션 제스처는 로봇 생성 모듈(131a), 하체 주행 모듈(131b), 상체 모션 모듈(131c), 음성 모듈(131d), 영상 모듈(131e), 기타 모듈(131f), 제스처 통합 모듈(131g) 및 애니메이터 모듈(131h)을 포함하고, 각 모듈들은 대응되는 데이터베이스를 가짐으로써, 해당 데이터베이스에 저장된 데이터를 저장, 불러 오기 등의 편집이 가능하다. 로봇 생성 모듈(131a)은 서비스 로봇과 동일한 관절과 링크의 제원 및 결합구조와 LED 등을 포함한 인터랙 션 표현 요소들을 3차원 모델링한다. 또한 로봇 생성 모듈(131a)는 음성(Text to Speech, TTS), 영상(코덱) 등도 실제 서비스 로봇과 동일한 환경을 가질 수 있도록 모델링하여 가상 로봇을 생성한다. 하체 주행 모듈(131b)은 서비스 로봇의 하체에 대한 주행 모션을 생성한다. 이때 하체 주행 모듈(131b)은 실제 서비스 로봇의 제원(예: 최대속도, 모터 토크, 주행 알고리즘 등)과 동일하도록 주행 모션을 생성할 수 있다. 상체 모션 모듈(131c)은 서비스 로봇의 상체에 대한 관절 모션을 생성한다. 이때 상체 모션 모듈 (131c)은 실제 서비스 로봇의 제원(예: 최대속도, 정격 토크, 모션 알고리즘 등)과 동일하도록 관절 모션 을 생성할 수 있다. 음성 모듈(131d)은 TTS를 이용하여 서비스 로봇의 발화 및 효과음을 생성한다. 이때 음성 모듈(131d)은 실제 서비스 로봇에 적용된 TTS 모델 및 오디오 코덱을 이용하여 발화 및 효과음을 생 성할 수 있다. 영상 모듈(131e)은 서비스 로봇이 디스플레이를 탑재한 경우, 서비스와 콘텐츠 영상에 대한 시연을 지원하고, 실제 서비스 로봇에 적용된 동영상 코덱을 이용한다. 기타 모듈(131f)은 하체 주행 모듈 (131b), 상체 모션 모듈(131c), 음성 모듈(131e), 영상 모듈(131e)을 제외한 멀티모달 인터랙션을 표현하기 위 한 모듈로써, 실제 서비스 로봇에 적용된 인터랙션 장치 등을 이용한다. 제스처 통합 모듈(131g)은 각 모 듈에서 생성된 인터랙션 요소들을 하나로 통합하여 인터랙션 제스처를 생성한다. 예를 들어 인사 제스처를 생성 하는 경우, 제스처 통합 모듈(131g)는 제스처의 총 시간을 설정하고, 설정된 총 시간 내에서 하체 주행, 상체 모션, 음성, 영상, 기타 인터랙션 등이 복합적으로 수행되도록 제스처를 생성할 수 있다. 애니메이터 모듈 (131h)은 생성된 인터랙션 제스처를 가상 로봇을 통해 가시화 시뮬레이션을 하고, 사전 검증을 한다. 상세하게 는 애니메이터 모듈(131h)은 인터랙션 디자인이 기 설정된 의도에 맞는 표현을 나타내지 판단한다. 애니메이터 모듈(131h)은 판단된 결과가 기 설정된 의도와 다른 표현을 나타낸다고 판단되면 인터랙션 디자인을 재수집하거 나, 수정한다. 또한 애니메이터 모듈(131h)은 인터랙션 제스처가 가상 로봇에서 구동이 가능한지 판단한다. 애 니메이터 모듈(131h)은 판단된 결과가 가상 로봇에서 구동이 불가능하다고 판단되면 구동이 불가능한 이유를 검 출하고, 검출된 이유를 기반으로 인터랙션 제스처를 수정한다. 인터랙션 프로그래밍부는 서비스 로봇의 상황인지 상태 관련 정보가 수신되면 수신된 상황인지 상태 관련 정보를 기반으로 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍한다. 이때 인터랙션 프로그래 밍부는 상태 머신(State Machine)을 기반으로 하는 GUI(Graphical User Interface)일 수 있다. 인터랙션 프로그래밍부는 서비스 로봇의 상황인지 상태에 대응하는 적어도 하나의 인터랙션 제스처를 노드로 생성한다. 노드는 활성화 노드(133a), 제스처 노드(133b1, 133b2, 133b3), 자율주행 노드(133c), 상황인지 노드 (133d), 조건 노드(133e) 등을 포함할 수 있다. 활성화 노드(133a)는 전개되는 노드의 결합들을 활성화하는 노드이고, 제스처 노드(133b1, 133b2, 133b3)는 인터 랙션 제스처 생성부에서 생성된 인터랙션 제스처를 불러오고, 서비스 로봇의 발화와 같은 잦은 수정 이 필요한 부분을 직접 수정하는 노드이다. 자율주행 노드(133c)는 목적지의 입력을 통해 서비스 로봇이 자율주행으로 목적지로 이동하도록 지원하는 노드이고, 상황인지 노드(133d)는 인공지능 기술이 접목된 인식 알 고리즘에 대한 결과를 전이 조건으로 줄 수 있는 노드이며, 조건 노드(133e)는 인터랙션 제스처를 연계하기 위 해 시간 변화 등을 전이 조건으로 줄 수 있는 노드이다. 인터랙션 프로그래밍부는 생성된 노드를 상관관계(또는 종속관계)가 있는 노드와 연결하면서 인터랙션 프 로그래밍을 할 수 있다. 즉 인터랙션 프로그래밍부는 트리(tree) 구조 형태로 노드들을 연결할 수 있다. 예를 들어 인터랙션 프로그래밍부는 상태(state) 노드를 활성화 노드와 제스처 노드로 구분하고, 전이 (Transition) 노드를 상황인지 노드로 분류할 수 있다. 이때 인터랙션 프로그래밍부는 상태 노드가 전이 노드를 수행한 후, 다음 순서의 상태 노드로 넘어가도록 하고, 마지막 노드가 제스처 노드가 되도록 프로그래밍 을 할 수 있다. 인터랙션 시뮬레이션부는 프로그래밍된 인터랙션 시나리오를 가상 로봇에 적용하여 시뮬레이션을 수행한다. 인터랙션 시뮬레이션부는 3차원 가상 공간에서 가상 로봇과 가상 사용자 간의 상호작용하는 과 정을 인터랙션 시나리오 기반으로 시뮬레이션할 수 있다. 이때 인터랙션 시뮬레이션부는 시뮬레이션을 통 해 해당 인터랙션 시나리오가 서비스 로봇에서 구동될 수 있는지 검증한다. 인터랙션 시뮬레이션부는 시뮬레이션을 통해 각 노드에 포함된 인터랙션 제스처가 연속 동작으로 구현이 가능한지 판단하고, 판단된 결과 에서 연속 동작이 불가능하다고 판단되면 연속 동작이 불가능한 이유를 검출한다. 인터랙션 시뮬레이션부 는 검출된 이유를 기반으로 인터랙션 시나리오를 수정시킬 수 있다. 출력부는 인터랙션 디자인을 기반으로 인터랙션 시나리오 생성 및 검증하는 과정을 출력한다. 출력부(15 0)는 디스플레이일 수 있으며, 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레 이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emittingdiode, OLED), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display) 중에서 적어도 하나를 포함할 수 있다. 저장부는 구현장치가 구동되기 위한 프로그램 또는 알고리즘이 저장된다. 저장부는 인터랙션 디 자인, 인터랙션 제스처, 인터랙션 시나리오 등과 관련된 정보가 저장된다. 저장부는 플래시 메모리 타입 (flash memory type), 하드디스크 타입(hard disk type), 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(Random Access Memory, RAM), SRAM(Static Random Access Memory), 롬(Read-Only Memory, ROM), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기메모리, 자기 디스크 및 광디스크 중 적어도 하나의 저장 매체를 포함할 수 있다. 도 8은 본 발명의 실시예에 따른 인터랙션 디자인 구현방법을 설명하기 위한 순서도이다. 도 8을 참조하면, 인터랙션 디자인 구현방법(이하 '구현방법'이라 함)은 다양한 형상을 가진 서비스 로봇에 멀 티모달 상호작용 제스처 생성 및 생성된 제스처를 활용한 상호작용 시나리오를 개발하고, 검증한다. 이를 통해 구현방법은 장시간 소요되는 서비스 로봇과 사용자의 인터랙션 디자인을 실제 로봇에 구현하기까지의 개발시간 을 단축시킬 수 있다. S101 단계에서, 구현장치는 인터랙션 디자인 관련 요청 신호를 제공서버로 전송한다. 여기서 요청 신 호는 서비스 로봇을 통해 인터랙션 디자인을 구현하기 위해 필요한 인터랙션 디자인을 요청하는 신호일 수 있다. S103 단계에서, 제공서버는 요청 신호에 관련된 인터랙션 디자인을 검색한다. 제공서버는 기 저장된 인터랙션 디자인 중 요청 신호에 대응되는 인터랙션 디자인을 검색할 수 있다. S105 단계에서, 제공서버는 인터랙션 디자인 관련 정보를 구현장치로 전송한다. S107 단계에서, 구현장치는 인터랙션 제스처를 생성한다. 구현장치는 서비스 로봇과 사용자 간 의 상호작용을 지원하기 위한 인터랙션 디자인이 수집되면 서비스 로봇과 동일한 가상 로봇을 생성한다. 구현장치는 가상 로봇 및 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함된 제스처인 인터 랙션 제스처를 생성한다. S109 단계에서, 서비스 로봇은 상황인지 상태를 추정한다. 서비스 로봇은 주변 환경에 대한 정보가 수집되면 수집된 정보를 기반으로 현재 상황에 대해 추정한다. 서비스 로봇는 추정된 상황을 이용하여 상 황인지 상태 관련 정보를 생성한다. S111 단계에서, 서비스 로봇은 상황인지 상태 관련 정보를 구현장치로 전송한다. S113 단계에서, 구현장치는 인터랙션 프로그래밍을 수행한다. 구현장치는 서비스 로봇의 상황인 지 상태를 기반으로 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍한다. S115 단계에서, 구현장치는 인터랙션 시뮬레이션을 수행한다. 구현장치는 프로그래밍된 인터랙션 시 나리오를 가상 로봇에 적용하여 시뮬레이션한다. 구현장치는 시뮬레이션을 통해 해당 인터랙션 시나리오가 서비스 로봇에서 구동될 수 있는지 검증한다. S117 단계에서, 구현장치는 검증된 인터랙션 시나리오를 서비스 로봇에 전송한다. S119 단계에서, 서비스 로봇는 검증된 인터랙션 시나리오를 기반으로 모션을 구동한다. 서비스 로봇 은 검증된 인터랙션 시나리오를 저장한다. 서비스 로봇는 상황인지 상태에 맞는 인터랙션 시나리오를 불러 오고, 불러온 인터랙션 시나리오에 따라 모션을 구동한다. 도 9는 본 발명의 실시예에 따른 인터랙션 디자인 구현방법을 인터랙션 디자인 구현장치 시점에서 설명하기 위 한 순서도이다. 도 1 및 도 9를 참조하면, 구현장치에 의해 수행되는 인터랙션 디자인 구현방법은 서비스 로봇과 사 용자(U) 사이에서 양질의 상호작용이 수행되도록 지원한다. S201 단계에서, 구현장치는 인터랙션 디자인을 수집한다. 구현장치는 제공서버 또는 관리자 단 말로부터 서비스 로봇과 사용자(U) 간의 상호작용을 지원하기 위한 인터랙션 디자인을 수집한다. S203 단계에서, 구현장치는 인터랙션 제스처를 생성한다. 구현장치는 서비스 로봇과 동일한 가상 로 봇을 생성한다. 구현장치는 가상 로봇 및 인터랙션 디자인을 이용하여 인터랙션을 위한 표현 요소가 포함 된 제스처인 인터랙션 제스처를 생성한다. 이때 구현장치는 가상 로봇의 상체 모션, 하체 주행, 음성, 영 상 및 표정 중 적어도 하나의 표현 요소를 포함하는 인터랙션 제스처를 생성할 수 있다. S205 단계에서, 구현장치는 인터랙션 디자인의 수정이 필요한지 판단한다. 구현장치는 인터랙션 디자 인이 기 설정된 의도에 맞는 표현을 나타내지 판단하고, 판단된 결과가 기 설정된 의도와 다른 표현을 나타내므 로, 수정이 필요하다고 판단하면 인터랙션 디자인이 재수집되거나, 수정되도록 S201 단계를 수행한다. 구현장치 는 인터랙션 디자인의 수정이 필요하지 않다고 판단하면 S207 단계를 수행한다. S207 단계에서, 구현장치는 인터랙션 제스처의 수정이 필요한지 판단한다. 구현장치는 인터랙션 제스 처가 가상 로봇에서 구동이 가능한지 판단하고, 판단된 결과가 가상 로봇에서 구동이 불가능하여 인터랙션 제스 처의 수정이 필요하다고 판단하면 S203 단계를 수행한다. 이때 구현장치는 구동이 불가능한 이유를 검출하 고, 검출된 이유를 기반으로 인터랙션 제스처가 수정되도록 제어할 수 있다. 구현장치는 인터랙션 제스처 의 수정이 필요하지 않으면 S209 단계를 수행한다. S209 단계에서, 구현장치는 인터랙션 프로그래밍을 수행한다. 구현장치는 서비스 로봇의 상황인지 상 태를 기반으로 인터랙션 제스처가 포함된 인터랙션 시나리오를 프로그래밍한다. 구현장치는 상황인지 상태 에 대응하는 적어도 하나의 인터랙션 제스처를 노드로 생성하고, 생성된 노드를 상관관계가 있는 노드와 연결하 여 인터랙션 시나리오를 프로그래밍한다. S211 단계에서, 구현장치는 인터랙션 시뮬레이션을 수행한다. 구현장치는 프로그래밍된 인터랙션 시 나리오를 가상 로봇에 적용하여 시뮬레이션을 한다. 구현장치는 3차원 가상 공간에서 가상 로봇과 가상 사 용자 간의 상호작용하는 과정을 인터랙션 시나리오 기반으로 시뮬레이션을 한다. S213 단계에서, 구현장치는 인터랙션 시나리오의 수정이 필요한지 판단한다. 구현장치는 시뮬레이션 을 통해 해당 인터랙션 시나리오가 서비스 로봇에서 구동될 수 있는지 검증한다. 즉 구현장치는 시뮬 레이션을 통해 각 노드에 포함된 인터랙션 제스처가 연속 동작으로 구현이 가능한지 판단하고, 판단된 결과에서 연속 동작이 불가능하다고 판단되면 S209 단계를 수행한다. 이때 구현장치는 연속 동작이 불가능한 이유를 검출하고, 검출된 이유를 기반으로 인터랙션 시나리오가 수정되도록 제어할 수 있다. 구현장치는 각 노드 에 포함된 인터랙션 제스처가 연속 동작으로 구현이 가능하면 S215 단계를 수행한다. S215 단계에서, 구현장치는 검증된 인터랙션 시나리오를 서비스 로봇으로 제공한다. 구현장치는 서비스 로봇을 통해 검증된 인터랙션 시나리오가 구현되도록 지원한다. 도 10은 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다. 도 10을 참조하면, 컴퓨팅 장치(TN100)는 본 명세서에서 기술된 장치(예를 들면 인터랙션 디자인 구현장치, 서 비스 로봇, 디자인 제공서버, 관리자 단말 등) 일 수 있다. 컴퓨팅 장치(TN100)는 적어도 하나의 프로세서(TN110), 송수신 장치(TN120), 및 메모리(TN130)를 포함할 수 있 다. 또한, 컴퓨팅 장치(TN100)는 저장 장치(TN140), 입력 인터페이스 장치(TN150), 출력 인터페이스 장치 (TN160) 등을 더 포함할 수 있다. 컴퓨팅 장치(TN100)에 포함된 구성 요소들은 버스(bus)(TN170)에 의해 연결 되어 서로 통신을 수행할 수 있다. 프로세서(TN110)는 메모리(TN130) 및 저장 장치(TN140) 중에서 적어도 하나에 저장된 프로그램 명령(program command)을 실행할 수 있다. 프로세서(TN110)는 중앙 처리 장치(CPU: central processing unit), 그래픽 처리 장치(GPU: graphics processing unit), 또는 본 발명의 실시예에 따른 방법들이 수행되는 전용의 프로세서를 의 미할 수 있다. 프로세서(TN110)는 본 발명의 실시예와 관련하여 기술된 절차, 기능, 및 방법 등을 구현하도록 구성될 수 있다. 프로세서(TN110)는 컴퓨팅 장치(TN100)의 각 구성 요소를 제어할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 프로세서(TN110)의 동작과 관련된 다양한 정보를 저장할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 구성될 수 있다. 예를 들어, 메모리(TN130)는 읽기 전용 메모리(ROM: read only memory) 및 랜덤 액세스 메모리 (RAM: random access memory) 중에서 적어도 하나로 구성될 수 있다. 송수신 장치(TN120)는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 송수신 장치(TN120)는 네트워크 에 연결되어 통신을 수행할 수 있다. 한편, 본 발명의 실시예는 지금까지 설명한 장치 및/또는 방법을 통해서만 구현되는 것은 아니며, 본 발명의 실 시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있으며, 이러한 구현은 상술한 실시예의 기재로부터 본 발명이 속하는 기술 분야의 통상의 기술자라면 쉽게 구 현할 수 있는 것이다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 통상의 기술자의 여러 변형 및 개량 형태 또 한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2023-0097902", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 인터랙션 디자인 구현시스템을 설명하기 위한 구성도이다. 도 2는 본 발명의 실시예에 따른 서비스 로봇과 사용자 간의 상호작용을 설명하기 위한 도면이다. 도 3은 본 발명의 실시예에 따른 인터랙션 디자인 구현장치를 설명하기 위한 블록도이다. 도 4는 본 발명의 실시예에 따른 제어부를 설명하기 위한 블록도이다. 도 5는 본 발명의 실시예에 따른 인터랙션 제스처 생성을 설명하기 위한 도면이다. 도 6는 본 발명의 실시예에 따른 인터랙션 프로그래밍을 설명하기 위한 도면이다. 도 7은 본 발명의 실시예에 따른 인터랙션 시뮬레이션을 설명하기 위한 도면이다. 도 8은 본 발명의 실시예에 따른 인터랙션 디자인 구현방법을 설명하기 위한 순서도이다. 도 9는 본 발명의 실시예에 따른 인터랙션 디자인 구현방법을 인터랙션 디자인 구현장치 시점에서 설명하기 위 한 순서도이다. 도 10은 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다."}
