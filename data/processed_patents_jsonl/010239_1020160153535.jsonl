{"patent_id": "10-2016-0153535", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0055571", "출원번호": "10-2016-0153535", "발명의 명칭": "이동 로봇 시스템, 이동 로봇 및 이동 로봇 시스템의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "곽노산"}}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이동 공간에 대한 주행 정보를 생성하고 저장하는 서버와 상기 이동 공간을 주행하는 이동 로봇을 포함하고상기 이동 로봇은,상기 이동 로봇을 이동시키는 주행부;상기 서버로부터 상기 주행 정보를 수신하는 통신부;상기 통신부에서 수신한 주행 정보를 기초로 상기 주행부를 제어하는 제어부;를 포함하고상기 서버는 적어도 하나의 다른 외부 로봇으로부터 상기 이동 공간에 대한 정보를 수신하고 이를 기초로 상기주행 정보를 생성하는 이동 로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 이동 공간에 대한 정보는,상기 이동 공간의 주행 시뮬레이션을 기초로 생성된 정보인 이동 로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 상기 이동 공간에 대한 정보는,상기 외부 로봇이 상기 이동 공간을 주행하면서 취득한 주행 관련 정보인 이동 로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 주행 관련 정보는,상기 이동 공간을 주행하면서 취득한 상기"}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 서버는,상기 이동 공간에 대한 정보를 기초로 심층 학습(Deep Learning)을 하여 상기 주행 정보를 생성하는 이동 로봇시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 주행 정보는 제 1주행 정보를 포함하고상기 제어부는 상기 제 1주행 정보를 기초로 제 2주행 정보를 생성하고 생성된 상기 제 2주행 정보에 따라 상기주행부를 제어하는 이동 로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,공개특허 10-2018-0055571-3-상기 통신부는,상기 이동 로봇이 주행하면서 취득한 상기 이동 공간에 관한 정보를 상기 서버로 송신하는 이동 로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서,상기 이동 공간 내에 존재하는 물체들을 감지하는 센서부;상기 물체들을 운반하는 동작부;를 더 포함하고,상기 서버는 상기 물체들에 대한 정보를 상기 로봇 및 상기 외부 로봇 중 적어도 하나로부터 수신하고 저장하는로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 통신부는 감지된 상기 물체들에 대한 정보가 존재하지 않는 경우 상기 서버로부터 상기 물체들에 대한 정보를 수신하고,상기 제어부는 수신한 상기 물체들에 대한 정보를 기초로 상기 주행부 및 상기 동작부 중 적어도 하나를 제어하는 이동 로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서,상기 서버는,사용자가 미리 설정해 놓은 물체들에 대한 정보는 수신하지 않는 이동 로봇 시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "본체;상기 본체를 이동시키는 주행부;이동 공간에 대한 정보를 외부 서버로부터 수신하는 통신부;상기 통신부에서 수신한 정보를 기초로 상기 이동 공간에 대한 주행 정보를 생성하고 생성된 주행 정보에 따라상기 주행부를 제어하는 제어부;를 포함하고상기 주행 정보는 적어도 하나의 다른 외부 로봇으로부터 수신한 상기 이동 공간에 대한 정보를 기초로 생성된정보인 이동 로봇."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 이동 공간에 대한 정보는,상기 이동 공간의 주행 시뮬레이션을 기초로 생성된 정보인 이동 로봇."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1항에 있어서, 상기 이동 공간에 대한 정보는,상기 외부 로봇이 상기 이동 공간을 주행하면서 취득한 주행 관련 정보인 이동 로봇."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 3항에 있어서,공개특허 10-2018-0055571-4-상기 주행 관련 정보는,상기 이동 공간을 주행하면서 취득한 상기 외부 로봇의 센서의 동작 정보, 주행 속도 정보 및 주행 방향 정보중 적어도 하나를 포함하는 이동 로봇."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1항에 있어서,상기 제어부는,상기 이동 공간에 대한 정보를 기초로 심층 학습(Deep Learning)을 하여 상기 주행 정보를 생성하는 이동 로봇시스템."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "적어도 하나의 외부 로봇으로부터 이동 공간에 대한 정보를 수신하는 단계;상기 수신한 주행 정보를 기초로 상기 이동 공간에 대한 주행 정보를 생성하는 단계;상기 주행 정보를 수신 하고 이를 기초로 이동 로봇의 이동을 제어하는 단계를 포함하는 이동 로봇 시스템의 제어 방법."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서,상기 이동 공간에 대한 정보는,상기 이동 공간의 주행 시뮬레이션을 기초로 생성된 정보인 이동 로봇 시스템의 제어 방법."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17항에 있어서,상기 외부 로봇이 상기 이동 공간을 주행하면서 취득한 주행 관련 정보인 이동 로봇 시스템의 제어 방법."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18항에 있어서,상기 주행 정보를 생성하는 단계는,상기 이동 공간에 대한 정보를 기초로 심층 학습(Deep Learning)을 하여 상기 주행 정보를 생성하는 단계를 포함하는 이동 로봇 시스템의 제어 방법."}
{"patent_id": "10-2016-0153535", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 16항에 있어서,상기 이동 로봇이 주행하면서 취득한 상기 이동 공간에 대한 정보를 서버로 송신하는 단계를 더 포함하는 이동로봇 시스템의 제어 방법."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이동 로봇 시스템에 있어서, 이동 공간에 대한 주행 정보를 생성하고 저장하는 서버와 상기 이동 공간 을 주행하는 이동 로봇을 포함하고 상기 이동 로봇은 상기 이동 로봇을 이동시키는 주행부와 상기 서버로부터 상 기 주행 정보를 수신하는 통신부와 상기 통신부에서 수신한 주행 정보를 기초로 상기 주행부를 제어하는 제어부 를 포함하고 상기 서버는 적어도 하나의 다른 외부 로봇으로부터 상기 이동 공간에 대한 정보를 수신하고 이를 기초로 상기 주행 정보를 생성할 수 있다. 본 발명의 경우 다른 이동 로봇으로부터 학습된 주행 정보를 통하여 주행을 할 수 있으므로 경험해 보지 못한 새 로운 공간에 이동 로봇이 배치되어도 보다 안전적으로 새로운 공간에서 주행을 할 수 있는 장점이 있다. 또한, 주행 정보에 관하여 지속적인 학습을 함으로써, 더욱 더 지능적인 주행을 할 수 있는 효과가 있다."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이동 로봇 시스템, 이동 로봇 및 이동 로봇 시스템의 제어 방법에 관한 발명으로서, 보다 상세하게는 이동 공간에 대한 정보를 외부 로봇으로부터 수신하고 이를 기초로 심층학습을 하여 주행 정보를 생성하는 기술 에 관한 발명이다."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 과거 로봇은 산업 기술 분야용으로 많이 개발되어 공장 자동화의 일부분으로 많이 사용되어 왔다. 그러나 최근에는 로봇을 응용한 분야가 더욱 확대되어 의료용 로봇, 우주 항공 로봇 등이 개발되었고, 일반 가 정에서 사용할 수 있는 가정용 이동 로봇 또한 만들어지고 있다. 이동 로봇은 사용자의 조작 없이도 주행하고자 하는 영역을 자율적으로 이동하면서 사용자로부터 명령 받은 작 업을 수행하는 로봇을 말한다. 그 예로는 청소 로봇, 텔레프레전스 로봇(telepresence robot), 경비 로봇 (security robot) 등이 있으며, 근래에는 이동 로봇을 이용한 응용 기술이 개발되고 있다. 예를 들어, 네트워크 기능을 가지고 있어 사용자와 이동 로봇이 멀리 떨어져 있어도 사용자가 이동 로봇에게 제 어 명령을 내릴 수 있거나 이동 로봇을 통하여 사용자가 모니터 할 수 없는 지역을 모니터할 수 있는 기능들이 개발되고 있다. 또한, 이동 로봇들이 특정 구역내에서 자유롭고 안전하게 주행할 수 있도록 많은 기술들이 개발되고 있는데 최 근에는 심층 학습의 일종으로서 딥 러닝(Deep Learning)이 많이 개발되고 있다. 이는 컴퓨터가 여러 데이터를 이용해 마치 사람처럼 스스로 학습할 수 있게 하기 위해 인공 신경망(ANN: artificial neural network)을 기반 으로 한 기계 학습을 말한다. 심층 학습의 핵심은 분류를 통한 예측이다. 수많은 데이터 속에서 패턴을 발견해 인간이 사물을 구분하듯 컴퓨 터가 데이터를 나눈다. 이와 같은 분별 방식은 크게 '지도 학습(Supervised Learning)'과 '비지도 학습 (Unsupervised Learning)' 방식으로 나뉠 수 있다. 지도 학습 방식은 기존의 기계 학습 알고리즘은 대부분을 차지하였던 방식으로서, 이동 로봇에 이동 로봇에 관 한 정보 및 환경 정보를 직접 입력하여 가르치는 방법을 말한다. 그에 반해 비지도 학습은 컴퓨터가 기존의 자 료를 이용하여 스스로 학습하여 주행 능력을 개발하는 방법을 말한다. 비지도 학습의 경우 학습 자료의 양이 많을수록, 학습의 단계가 세분화될수록 성능이 좋아지며, 사용자가 모든 환경에 대한 정보를 입력할 필요가 없는 장점이 존재한다. 다만, 기존의 지도 학습 방식을 이용하는 이동 로봇의 경우, 외부 서버와 연계하여 주행에 필요한 정보를 외부 서버로부터 수신하고 이를 기초로 주행을 하는 하는데, 기존 방식의 경우 단순히 이동 로봇이 요구한 정보를 외 부 서버로부터 수신하는 정도에 지나지 않았다. 따라서, 종래의 기술만으로는 이동 로봇이 주행에 필요한 실제 정보를 능동적으로 수신하고 이를 반영할 수 없 어 주행 기술이 향상이 어려운 문제가 있었으며, 이러한 문제는 이동 로봇이 새로운 이동 공간으로 이동하였을 때 새로운 공간에 대한 정보가 부족하여 효율적으로 주행을 하는데 많은 어려움이 존재하였다."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 상기 설명한 문제점을 해결하기 위해 고안된 발명으로서, 다른 이동 로봇으로부터 수신한 이 동 공간에 관한 정보를 외부 서버로부터 수신한 후, 이를 기초로 스스로 심층학습을 하여 보다 다양한 환경에서 안전하고 유연하게 주행을 할 수 있는 이동 로봇 시스템 및 이동 로봇을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 이동 로봇 시스템은 이동 공간에 대한 주행 정보를 생성하고 저장하는 서버와 상기 이동 공간을 주행하는 이동 로봇을 포함하고 상기 이동 로봇은 상기 이동 로봇을 이동시키는 주행부와 상기 서 버로부터 상기 주행 정보를 수신하는 통신부와 상기 통신부에서 수신한 주행 정보를 기초로 상기 주행부를 제어 하는 제어부를 포함하고 상기 서버는 적어도 하나의 다른 외부 로봇으로부터 상기 이동 공간에 대한 정보를 수 신하고 이를 기초로 상기 주행 정보를 생성할 수 있다. 상기 이동 공간에 대한 정보는, 상기 이동 공간의 주행 시뮬레이션을 기초로 생성된 정보일 수 있다. 상기 이동 공간에 대한 정보는, 상기 외부 로봇이 상기 이동 공간을 주행하면서 취득한 주행 관련 정보일 수 있 다. 상기 주행 관련 정보는, 상기 이동 공간을 주행하면서 취득한 상기 외부 로봇의 센서의 동작 정보, 주행 속도 정보 및 주행 방향 정보 중 적어도 하나를 포함할 수 있다. 상기 서버는, 상기 이동 공간에 대한 정보를 기초로 심층 학습(Deep Learning)을 하여 상기 주행 정보를 생성할 수 있다. 상기 주행 정보는, 제 1주행 정보를 포함하고 상기 제어부는 상기 제 1주행 정보를 기초로 제 2주행 정보를 생 성하고 생성된 상기 제 2주행 정보에 따라 상기 주행부를 제어할 수 있다. 상기 통신부는, 상기 이동 로봇이 주행하면서 취득한 상기 이동 공간에 관한 정보를 상기 서버로 송신할 수 있 다. 상기 이동 로봇 시스템은, 상기 이동 공간 내에 존재하는 물체들을 감지하는 센서부와 상기 물체들을 운반하는 동작부를 더 포함할 수 있고 상기 서버는 상기 물체들에 대한 정보를 상기 로봇 및 상기 외부 로봇 중 적어도 하나로부터 수신하고 저장할 수 있다. 상기 통신부는, 감지된 상기 물체들에 대한 정보가 존재하지 않는 경우 상기 서버로부터 상기 물체들에 대한 정 보를 수신할 수 있고 상기 제어부는 수신한 상기 물체들에 대한 정보를 기초로 상기 주행부 및 상기 동작부 중 적어도 하나를 제어할 수 있다. 상기 서버는, 사용자가 미리 설정해 놓은 물체들에 대한 정보는 수신하지 않을 수 있다. 본 발명의 다른 실시예에 따른 이동 로봇은 본체와 상기 본체를 이동시키는 주행부와 이동 공간에 대한 정보를 외부 서버로부터 수신하는 통신부와 상기 통신부에서 수신한 정보를 기초로 상기 이동 공간에 대한 주행 정보를 생성하고 생성된 주행 정보에 따라 상기 주행부를 제어하는 제어부를 포함하고 상기 주행 정보는 적어도 하나의 다른 외부 로봇으로부터 수신한 상기 이동 공간에 대한 정보를 기초로 생성된 정보일 수 있다. 상기 이동 공간에 대한 정보는, 상기 이동 공간의 주행 시뮬레이션을 기초로 생성된 정보일 수 있다. 상기 이동 공간에 대한 정보는, 상기 외부 로봇이 상기 이동 공간을 주행하면서 취득한 주행 관련 정보일 수 있 다. 상기 주행 관련 정보는, 상기 이동 공간을 주행하면서 취득한 상기 외부 로봇의 센서의 동작 정보, 주행 속도 정보 및 주행 방향 정보 중 적어도 하나를 포함할 수 있다. 상기 제어부는, 상기 이동 공간에 대한 정보를 기초로 심층 학습(Deep Learning)을 하여 상기 주행 정보를 생성 할 수 있다. 본 발명의 또 다른 실시예에 따른 이동 로봇의 제어 방법은 적어도 하나의 외부 로봇으로부터 이동 공간에 대한 정보를 수신하는 단계와 상기 수신한 주행 정보를 기초로 상기 이동 공간에 대한 주행 정보를 생성하는 단계와 상기 주행 정보를 수신 하고 이를 기초로 이동 로봇의 이동을 제어하는 단계를 포함할 수 있다. 상기 이동 공간에 대한 정보는 상기 이동 공간의 주행 시뮬레이션을 기초로 생성된 정보일 수 있다. 상기 이동 공간에 대한 정보는 외부 로봇이 상기 이동 공간을 주행하면서 취득한 주행 관련 정보일 수 있다. 상기 주행 정보를 생성하는 단계는, 상기 이동 공간에 대한 정보를 기초로 심층 학습(Deep Learning)을 하여 상 기 주행 정보를 생성하는 단계를 포함할 수 있다. 상기 이동 로봇의 제어 방법은 상기 이동 로봇이 주행하면서 취득한 상기 이동 공간에 대한 정보를 서버로 송신 하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 경우 다른 이동 로봇으로부터 학습된 주행 정보를 외부 서버로부터 수신하여 이를 기초로 주행을 할 수 있어, 이동 로봇이 경험해 보지 못한 새로운 공간에 배치되어도 보다 안전적으로 주행을 할 수 있는 장점이 있다. 또한, 주행 정보에 관하여 지속적인 학습을 함으로써, 더욱더 지능적인 주행을 할 수 있는 효과가 있다."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기재된 실시 예와 도면에 도시된 구성은 개시된 발명의 바람직한 일 예이며, 본 출원의 출원 시점 에 있어서 본 명세서의 실시 예와 도면을 대체할 수 있는 다양한 변형 예들이 있을 수 있다. 또한, 본 명세서에서 사용한 용어는 실시 예를 설명하기 위해 사용된 것으로, 개시된 발명을 제한 및/또는 한정 하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\", \"구비하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들 이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않 는다. 또한, 본 명세서에서 사용한 \"제 1\", \"제 2\" 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는 데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되지는 않으며, 상기 용어들은 하나의 구성 요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으 면서 제 1구성 요소는 제 2구성 요소로 명명될 수 있고, 유사하게 제2 구성요소도 제 1구성 요소로 명명될 수 있다. \"및/또는\" 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략한다. 또한, 이하 도면들은 설명의 편의를 위해 청소 로봇을 기준으로 도시하였지만 본 발명의 구성 및 작동 원리는 청소 로봇에 한정되는 것은 아니고 이동할 수 있는 모든 로봇에 적용될 수 있다. 도 1은 개시된 발명의 일 실시예에 의한 이동 로봇 시스템의 전체 구성을 도시한 도면이다. 도 1에서, 개시된 발명의 일 실시예에 의한 이동 로봇 시스템은 일정 영역을 자율적으로 이동하면서 작업을 수행하는 이동 로봇과, 이동 로봇과 분리되어 이동 로봇을 원격으로 제어하는 디바이스와, 이동 로봇과 분리되어 이동 로봇의 배터리 전원을 충전하는 충전 스테이션 및 주행 공간에 대한 각종 정보가 저장되어 있는 서버를 포함할 수 있다. 이동 로봇은 디바이스의 제어 명령을 전달받아 제어 명령에 대응하는 동작을 수행하는 장치로, 충전 가능한 배터리(미도시)를 구비하고, 주행 중 장애물을 피할 수 있는 장애물 센서를 구비하여 작업 영역을 자율 적으로 주행하며 작업할 수 있다. 또한, 이동 로봇은 센서부를 통해 주변 환경에 대한 사전 정보 없이 자신의 위치를 인식하고, 환경에 대한 정보로부터 지도를 작성하는 위치 인식(Localization)과 지도 작성(Map-building)의 과정, 즉 Visual SLAM을 수행할 수 있다. 디바이스는 이동 로봇의 이동을 제어하거나 이동 로봇의 작업을 수행하기 위한 제어 명령을 무 선으로 송신하는 원격 제어 장치로, 휴대폰(Cellphone, PCS phone), 스마트 폰(smart phone), 휴대 단말기 (Personal Digital Assistants: PDA), 휴대용 멀티미디어 플레이어(Portable Multimedia Player: PMP), 노트북 컴퓨터(laptop computer), 디지털 방송용 단말기, 넷북, 태블릿, 네비게이션(Navigation) 등을 포함할 수 있다. 이외에도, 디바이스는 유무선 통신 기능이 내장된 디지털 카메라, 캠코더 등과 같이 여러 응용 프로그램을 이용한 다양한 기능의 구현이 가능한 모든 장치를 포함한다. 또한, 디바이스는 간단한 형태의 일반적인 리모컨일 수 있다. 리모컨은 일반적으로 적외선 통신(IrDA, infrared Data Association)을 이용하여 이동 로봇과 신호를 송수신한다. 또한, 디바이스는 RF(Radio Frequency), 와이파이(Wireless Fidelity, Wi-Fi), 블루투스(Bluetooth), 지 그비(Zigbee), 엔에프씨(near field communication: NFC), 초광대역(Ultra-Wide Band: UWB) 통신 등 다양한 방 식을 이용하여 이동 로봇과 무선 통신 신호를 송수신할 수 있으며, 디바이스와 이동 로봇이 무 선 통신 신호를 주고 받을 수 있는 것이면, 어느 방식을 사용하여도 무방하다. 또한, 디바이스는 이동 로봇의 전원을 온/오프 제어하기 위한 전원 버튼과, 이동 로봇의 배터리 충전을 위해 충전 스테이션으로 복귀하도록 지시하기 위한 충전 복귀 버튼과, 이동 로봇의 제어 모드 를 변경하기 위한 모드 버튼과, 이동 로봇의 동작을 시작/정지하거나 제어 명령의 개시, 취소 및 확인을 위한 시작/정지 버튼과, 다이얼 등을 포함할 수 있다. 충전 스테이션은 이동 로봇의 배터리 충전을 위한 것으로, 이동 로봇이 도킹되는 것을 안내하는 가이드 부재(미 도시)가 마련되어 있고, 가이드 부재(미 도시)에는 이동 로봇에 구비된 전원부를 충전시키 기 위해 접속 단자(미 도시)가 마련되어 있을 수 있다. 서버는 이동 로봇 및 외부의 다른 이동 로봇으로부터 이동 공간에 대한 정보를 수신하고 저장하 는 역할을 할 수 있다. 또한 수신한 이동 공간에 대한 정보를 기초로 심층학습을 하여 이동 공간에 대한 주행 정보를 생성하고 이를 이동 로봇으로 송신할 수 있다. 심층학습과 서버에 대한 구체적인 설명은 도 3 과 도 4에서 설명하도록 한다. 도 2는 개시된 발명의 일 실시예에 의한 이동 로봇의 외관을 개략적으로 도시한 도면이다. 도 2를 참조하면, 이동 로봇은 외관을 형성하는 본체와, 본체의 상부를 덮는 커버와, 본체 를 구동시키기 위한 구동 전원을 공급하는 전원부와, 본체를 이동시키는 주행부를 포함할 수 있다. 본체는 이동 로봇의 외관을 형성하는 한편, 그 내부에 설치되는 각종 부품들을 지지할 수 있다. 전원부는 주행부 및 그 외 본체를 구동시키기 위한 각 부하와 전기적으로 연결되어 구동 전원을 공급하는 배터리를 포함할 수 있다. 배터리는 재충전이 가능한 2차 배터리로 마련되며, 본체가 작업을 완 료하고 충전 스테이션에 결합된 경우 충전 스테이션으로부터 전력을 공급받아 충전될 수 있다. 또한, 전원부는 충전 잔량이 부족하면 충전 스테이션으로부터 충전 전류를 공급받아 충전할 수 있다. 또한, 본체의 전방에는 이동 로봇이 이동하는 바닥 면의 상태에 따라 회전하는 각도가 변화하는 캐스 터 휠(Wheel)이 설치될 수 있다. 캐스터 휠은 이동 로봇의 자세 안정 및 추락 방지 등에 활용되어 이동 로 봇을 지지하며, 롤러나 캐스터 형상의 휠로 구성될 수 있다. 도 3은 개시된 발명의 일 실시예에 의한 이동 로봇 시스템의 구성도이다. 도 3에서, 개시된 발명의 일 실시예에 의한 이동 로봇 시스템은은 도 1에 도시한 구성 요소 이외에 제어부 , 유저 인터페이스, 센서부, 통신부, 위치 검출부, 주행부, 동작부 및 저 장부를 더 포함할 수 있다. 유저 인터페이스는 이동 로봇의 본체 상면에 마련될 수 있으며, 사용자로부터 제어 명령을 수신 하는 입력 버튼과 이동 로봇의 동작 정보를 표시하는 디스플레이를 포함할 수 있다. 입력 버튼은 이동 로봇를 턴온 또는 턴오프시키는 전원 버튼, 이동 로봇를 동작시키거나 정지시 키는 동작/정지 버튼, 이동 로봇를 충전 스테이션으로 복귀시키는 복귀 버튼 등을 포함할 수 있다. 또한, 입력 버튼은 사용자의 가압을 감지하는 푸시 스위치(push switch), 멤브레인 스위치(membrane) 또는 사용자의 신체 일부의 접촉을 감지하는 터치 스위치(touch switch)를 채용할 수 있다. 디스플레이는 사용자가 입력한 제어 명령에 대응하여 이동 로봇의 정보를 표시한다, 예를 들어, 디스 플레이는 이동 로봇의 동작 상태, 전원의 상태, 사용자가 선택한 청소 모드, 충전 스테이션으로의 복귀 여부 등을 표시할 수 있다. 또한, 디스플레이는 자체 발광이 가능한 발광 다이오드(Light Emitting Diode: LED)와 유기 발광 다이오드 (Organic Light Emitting Diode: OLED) 또는 별도의 발원을 구비하는 액정 디스플레이(Liquid Crystal Display) 등을 채용할 수 있다. 또한, 도면에는 도시되지 않았으나, 실시 형태에 따라 유저 인터페이스는 사용자로부터 제어 명령을 입력 받고, 입력 받은 제어 명령에 대응하는 동작 정보를 표시하는 터치 스크린 패널(Touch Screen Panel: TSP)을 포 함할 수 있다. 터치 스크린 패널은 동작 정보 및 사용자가 입력할 수 있는 제어 명령을 표시하는 디스플레이, 사용자의 신체 일부가 접촉한 좌표를 검출하는 터치 패널(touch panel), 터치 패널이 검출한 접촉 좌표를 기초로 사용자가 입 력한 명령을 판단하는 터치 스크린 컨트롤러를 포함할 수 있다. 센서부는 적어도 하나의 카메라와 센서를 포함하고 있고 이동 로봇이 현재 위치하고 있는 환경의 각종 데이터를 획득하는 역할을 할 수 있다. 카메라는 외부의 영상 이미지인 프레임을 포착(capture)하여 이를 디지털 신호로 변환해주는 장치이며, CCD(Charge Coupled Device) 모듈이나 CMOS(Complementary Metal Oxide Semiconductor) 모듈을 포함하여 구성 될 수 있다. 특히, 도 3에서 도시되지 않았지만, 센서부는 이동 로봇 주변의 영상을 제어부가 처리할 수 있 는 전기적 신호로 변환하고, 상방 영상에 대응하는 전기적 신호를 제어부에 전달하는 모듈을 포함할 수 있 다. 또한, 개시된 발명에서 카메라가 제공한 영상은 제어부가 이동 로봇의 위치를 검출하는데 이용 될 수 있다. 센서는 이동 로봇이 주행하는 공간의 물체를 인식하는 장치로서, 측정 대상까지의 거리를 측정하여 이동 로봇이 위치한 실제 환경의 거리 데이터를 획득할 수 있다. 따라서, 센서는 데이터를 획득하기 위한 다양한 센서 예를 들어, 2D 센서 또는 3D 센서 등을 포함할 수 있 다. 3D 공간 인식 센서로는 KINECT(RGB-D 센서), TOF(Structured Light Sensor), 스테레오 카메라(Stereo Camera) 등이 사용될 수 있으며 이에 한정되지 않고 이와 유사한 기능을 할 수 있는 다른 장치들도 포함될 수 있다. 또한, 개시된 발명은 이동 로봇의 현재 위치에 대한 데이터를 입력 받는 수단으로 카메라와 센서 를 예시하고 있으나, 주위의 영상을 획득할 수 있는 다른 장치면 이에 포함될 수 있다. 통신부는 외부에 존재하는 서버와 이동 로봇의 정보 및 주행과 관련된 각종 정보를 무선으로 송 수신하는 역할을 할 수 있다. 구체적으로, 통신부는 서버에 저장되어 있는 다른 외부 로봇에 의해 수신된 이동 공간에 대한 정보 또는 이를 기초로 서버가 생성한 주행 정보를 수신할 수 있으며, 동시에 이동 로봇이 주행하면서 취 득한 주행 정보를 서버로 송신하는 역할을 할 수 있다. 따라서, 통신부는 RF(Radio Frequency), 와이파이(Wireless Fidelity, Wi-Fi), 블루투스(Bluetooth), 지 그비(Zigbee), 엔에프씨(near field communication: NFC), 초광대역(Ultra-Wide Band: UWB) 통신 등 다양한 방 식을 이용하여 서버와 무선 통신 신호를 송수신할 수 있으며, 서버와 이동 통신부가 무선 통신 신호를 주고 받을 수 있는 것이면, 어느 방식을 사용하여도 무방하다. 위치 검출부는 센서부에서 촬영한 영상을 통해서 시각적 주행거리를 측정한다. 또한 위치 검출부 는 이러한 시각적 주행거리 측정을 위해서 촬영된 영상의 모션 블러를 제거하고, 선명해진 영상을 비교하 여 이동 로봇의 위치를 검출한다. 주행부는 본체의 중앙부 양측에 각각 마련되어 본체가 작업을 수행하는 과정에서 전진, 후진 및 회전주행 등의 이동 동작이 가능하도록 하며 주행부의 전반적인 동작은 제어부의 명령에 기초하여 움 직일 수 있다. 양 주행부는 후술하는 제어부의 명령에 따라 전진 또는 후진 방향으로 각각 회전하여 이동 로봇(10 0)이 전진 또는 후진하거나 회전할 수 있도록 한다. 예를 들면 양 주행부를 전진 또는 후진 방향으로 회전시켜 이동 로봇이 전진 또는 후진 주행하도록 한다. 또한 좌측 주행부를 후진 방향으로 회전시키는 동안 우측 주행부를 전진 방향으로 회전시켜 이 동 로봇이 전방을 기준으로 좌측 방향으로 회전하도록 하고, 우측 주행부를 후진 방향으로 회전시키 는 동안 좌측 주행부를 전진 방향으로 회전시켜 이동 로봇이 전방을 기준으로 우측 방향으로 회전하 도록 한다. 주행부는 이동 로봇를 이동시키며, 도 2 에 도시된 바와 같이 바퀴 구동 모터, 주행 바퀴 를 포함할 수 있다. 주행 바퀴는 본체 저면의 양단에 마련될 수 있으며, 이동 로봇의 전방을 기준으로 이동 로봇 의 좌측에 마련되는 좌측 주행 바퀴와 이동 로봇의 우측에 마련되는 우측 주행 바퀴를 포함할 수 있 다. 한편, 주행 바퀴는 바퀴 구동 모터로부터 회전력을 제공받아 이동 로봇를 이동시킨다. 바퀴 구동 모터는 주행 바퀴를 회전시키는 회전력을 생성하며, 좌측 주행 바퀴를 회전시키는 좌측 구 동 모터와 우측 주행 바퀴를 회전시키는 우측 구동 모터를 포함한다. 좌측 구동 모터와 우측 구동 모터는 각각 제어부로부터 구동 제어 신호를 수신하여 독립적으로 동작할 수 도 있다. 이와 같이 독립적으로 동작하는 좌측 구동 모터와 우측 구동 모터에 의하여 좌측 주행 바퀴와 우측 주 행 바퀴는 서로 독립적으로 회전할 수 있다. 또한, 좌측 주행 바퀴와 우측 주행 바퀴가 독립적으로 회전할 수 있으므로 이동 로봇은 앞서 언급한 전진 주행, 후진 주행, 회전 주행 및 제자리 회전 등 다양한 주행이 가능하다. 또한, 이외에도 주행부는 제어부의 제어 신호에 따라 바퀴 구동 모터에 구동 전류를 공급하는 모터 구동 회로(미도시), 바퀴 구동 모터의 회전력을 주행 바퀴에 전달하는 동력 전달 모듈(미도시), 바퀴 구동 모터 또는 주행 바퀴의 회전 변위 및 회전 속도를 검출하는 회전 감지 센서(미 도시) 등을 더 포함할 수 있다. 동작부는 이동 로봇을 특정 위치로 이동시키는 주행부의 역할을 제외한, 사용자의 명령에 따른 각종 동작을 수행하는 역할을 할 수 있다. 따라서, 이동 로봇이 청소 로봇이라면 청소 동작을 수행하는 역 할을 할 수 있고 이동 로봇이 물체를 운반하는 로봇이라면 물체를 이동시키는 수단, 예를 들어 사람의 팔 과 같은 구성이 이에 해당할 수 있다. 동작부의 전반적인 동작은 제어부에 의해 제어되며, 제어부는 통신부를 통하여 수신 받은 물체에 대한 정보를 기초로 동작부를 제어하여 사용자의 명령을 수행할 수 있다. 구체적으로, 센서부가 이동 공간 내에 인식 가능한 물체가 존재하면, 통신부는 서버에 인식한 물체에 대한 정보를 요청하고 서버는 인식한 물체에 대한 정보가 서버에 존재하는지 판단하고 이를 통신부로 송신한다. 만약, 요청된 물체에 대한 정보가 존재하지 않는다면 서버다른 다른 외부 이동 로봇으로부터 상 기 물체에 대한 정보를 수신하고 수신된 정보들을 기초로 가장 최적화된 물체의 사용 방법을 결정하고 이를 통 신부로 송신한다. 그 후 제어부는 통신부가 수신한 물체에 가장 최적화된 사용 방법을 기초로 동작부를 제어하여 사용자의 명령을 수행한다. 이에 대한 자세한 설명은 도 10에서 다시 후술하도록 한다. 저장부는 카메라가 촬영한 영상을 실 시간으로 저장하고, 이동 로봇이 동작하는 환경의 지도와 이동 로봇의 동작을 위한 운영 프로그램과 주행 패턴, 주행 과정에서 획득한 이동 로봇의 위치 정보 와 장애물 정보 등을 저장하는 메모리이다. 또한, 저장부는 이동 로봇의 동작을 제어하기 위한 제어 데이터, 이동 로봇의 동작 제어 중 사 용되는 기준 데이터, 이동 로봇이 소정의 동작을 수행하는 중에 발생되는 동작 데이터, 이동 로봇이 소정 동작을 수행하도록 디바이스에 의해 입력된 설정 데이터 등과 같은 사용자 입력 정보가 저장될 수 있 다. 한편, 저장부는 아래에서 설명할 제어부에 포함된 메모리를 보조하는 보조 기억 장치로서 동작 할 수 있으며, 이동 로봇가 전원이 차단되더라도 저장된 데이터가 소멸되지 않는 비 휘발성 저장 매체로 구성될 수 있다. 이와 같은 저장부는 반도체 소자에 데이터를 저장하는 반도체 소자 드라이브, 자기 디스크에 데이터 를 저장하는 자기 디스크 드라이브 등을 포함할 수 있다. 서버는 이동 로봇 및 외부의 다른 이동 로봇으로부터 이동 공간에 대한 정보를 수신하고 저장하 는 역할을 할 수 있다. 또한 수신한 이동 공간에 대한 정보를 기초로 이동 로봇이 이동하는 이동 공간에 대한 주행 정보를 심층 학습(Deep-Learning)을 하여 생성할 수 있다. 그리고 생성된 정보는 통신부로 송신 할 수 있다. 또한, 서버는 이동 로봇이 송신한 이동 공간에 관한 정보 및 다른 외부 로봇이 송신한 이동 공간에 정보 중 적어도 하나를 이용하여 심층 학습을 하여 주행 정보를 생성할 수 있고 동시에 주행 시뮬레이션 정보를 기초로 심층 학습을 하여 주행 정보를 생성할 수 있다. 심층 학습은 학습 데이터가 많을수록 그 정확성이 증가 할 수 있다. 따라서 개시된 서버는 이동 로봇 또는 다른 외부 로봇들과 네트워크로 연결되고, 심층 학습에 필요한 데이터를 수집할 수 있다. 일 예에 따른 서버는 클라우드(Cloud) 서버를 포함할 수 있다. 클라우드 서버는 가상 사설 서버(Virtual private server)를 의미하며, 하나의 물리적 서버를 나누어 여러 개의 가상 서버로 사용하는 가상화 방법의 한 형태이다. 심층학습에 관한 자세한 설명은 도 7 ~ 도 9에서 설명하도록 한다. 또한, 서버는 이동 공간에 관한 정보와 주행 정보를 제외하고 이동 공간 내에 존재하는 물체들에 대한 각 종 정보를 저장할 수 있다. 구체적으로, 서버는 사용자로부터 혹은 다른 외부 로봇으로부터 받은 특정 물체에 대한 정보, 예를 들어 물체를 다룰 때 유의해야 하는 사항, 물체를 보관하는 방법 등 물체에 관한 다양한 정보 등을 수신하고 저장할 수 있다. 또한, 서버는 이러한 정보들을 통신부를 송신하고 제어부는 수신한 정보들을 기초로 사용자의 명령을 최적으로 수행할 수 있다. 이데 대한 자세한 설명은 도 10에서 설명하도록 한다. 제어부는 이동 로봇을 포함한 이동 로봇 시스템의 동작을 전반적으로 제어하는 역할을 할 수 있 다. 구체적으로, 제어부는 이동 로봇에 포함된 각종 구성 장치와 제어부 사이에서 데이터 출입을 매 개하는 입출력 인터페이스, 프로그램 및 데이터를 기억하는 메모리, 영상 처리를 수행하는 그래픽 프 로세서 및 메모리에 기억된 프로그램 및 데이터에 따라 연산 동작을 수행하고 이동 로봇의 제1 위치 정보를 보정하는 메인 프로세서, 입출력 인터페이스, 메모리, 그래픽 프로세서 및 메 인 프로세서 사이의 데이터 송수신의 통로가 되는 시스템 버스를 포함할 수 있다. 입출력 인터페이스는 센서부로부터 수신된 영상, 위치 검출부가 검출한 위치 정보 및 결과 등을 수신하고, 이를 시스템 버스를 통하여 메인 프로세서, 그래픽 프로세서, 메모리 등으로 전 송한다. 뿐만 아니라, 입출력 인터페이스는 메인 프로세서가 출력하는 각종 제어 신호를 주행부 및 이동 로봇의 각종 제어 구성에 전달할 수 있다. 메모리는 이동 로봇의 동작을 제어하기 위한 제어 프로그램 및 제어 데이터를 저장부로부터 불 러와 기억하거나, 센서부가 획득한 영상 또는 위치 검출부의 위치 정보 및 결과 등을 임시로 기억할 수 있다. 메모리는 S램, D랩 등의 휘발성 메모리를 포함할 수 있다. 다만, 이에 한정되는 것은 아니며, 경우에 따라 서 메모리는 플래시 메모리, 롬(Read Only Memory), 이피롬(Erasable Programmable Read Only Memory: EPROM), 이이피롬(Electrically Erasable Programmable Read Only Memory: EEPROM) 등의 비휘발성 메모리를 포 함할 수도 있다. 그래픽 프로세서는 센서부가 획득한 영상을 메모리 또는 저장부에 저장할 수 있는 포맷으 로 변환하거나, 센서부가 획득한 영상의 해상도 또는 크기를 변경할 수 있다.메인 프로세서는 메모리에 저장된 프로그램 및 데이터에 따라 센서부, 위치 검출부의 감지 결과를 처리하고 주행부를 제어하며, 이동 로봇의 위치를 보정하거나 이에 따른 지도를 보정하기 위 한 연산동작을 수행할 수 있다. 또한, 제어부는 통신부에서 수신한 이동 공간에 대한 주행 정보와 물체에 대한 정보를 기초로 주행부 와 동작부를 제어할 수 있다. 구체적으로, 제어부는 서버에서 심층 학습을 통해 생성된 주행 정보를 통신부을 통하여 수신 받 고, 이를 기초로 이동 공간 내에 가장 적합한 주행 경로를 산출하여 주행부를 제어 할 수 있다. 또한, 센 서부에 의해 감지된 물건에 대한 정보를 통신부를 통하여 수신 받고, 이를 기초로 동작부를 제 어하여 사용자의 명령을 수행할 수 있다. 또한, 제어부는 서버가 수행하는 심층 학습을 동시에 수행할 수 도 있다. 지금까지는 서버가 심 층 학습을 하여 주행 정보를 생성하는 것으로 설명하였지만, 이동 로봇의 제어부 또한 스스로 심층 학습을 하여 주행 정보를 생성할 수 있다. 이러한 경우 외부와 통신이 되지 않아 이동 공간에 대한 정보 또는 심층학습에 의해 생성된 주행 정보를 서버로부터 수신할 수 없는 경우, 스스로 심층학습을 하여 주행 정보 를 생성할 수 있는 장점이 존재한다. 이러한 특징은 도 5와 도 6에서 설명할 이동 로봇의 특징과 유사하다. 또한, 서버와 제어부가 이러한 구조를 갖는 경우 제어부가 분담해야 하는 심층 학습의 업무를 서버와 분담하여 수행할 수 있다. 일반적으로 제어부는는 상대적으로 서버보다 낮은 하드웨어 및 소프트웨어를 가지고 있으므로 제어부가 심층학습을 하는 것보다 서버가 심층 학습을 수행하는 것 이 조금 더 효율적일 수 있다. 따라서, 제어부가 심층 학습을 수행하는 경우 고차원적인 부분에 대해서는 서버가 이를 수행하여 제어부의 부담을 경감시킬 수 있다. 예를 들어, 서버는 외부 로봇으로부터 수신한 이동 공간에 대한 정보를 기초로 제 1주행 정보를 생성하고, 제어부는 통신부를 통하여 수신한 제 1주행 정보를 기초로 제 2주행 정보를 생성할 수 있다. 그리고 제어부는 생성된 제 2주행 정보를 기초로 주행부를 제어할 수 있다. 여기서 제 1주행 정보는 일차적으로 심층 학습을 통하여 생성된 정보로서 제 2주행 정보보다 상위 개념의 정보 를 의미한다. 예를 들어, 제 1주행 정보는 청소 영역을 효율적으로 하게 하는 주행 경로에 대한 정보라면, 제 2주행 정보는 장애물을 회피하는 부분과 같은, 주행 시 빠르게 처리해야 하는 상황에 대한 정보를 말한다. 이러한 경우, 심층 학습 시 많은 작업을 수행해야 하는 부분은 서버가 담당하고, 세세한 작업을 수행해야 하는 부분은 제어부 가 수행함으로써, 보다 효율적인 이동 로봇을 제어할 수 있는 장점이 존재한다. 따라서, 이러한 경우 서버의 제어부와 이동 로봇의 제어부 서로 동일한 심층 학습 네트워크로 구성되어 있어야 하며, 이동 로봇의 제어부에는 상대적으로 낮은 로우 레벨(Low Level)의 학습기 기 반의 제어기가 탑재되어 있을 수 있고, 서버에는 상대적으로 높은 하이 레벨(High Level)의 학습기 기반의 제어기가 탑재되어 있을 수 있다. 지금까지 도면을 통하여 이동 로봇 시스템의 구성에 대해 알아보았다. 이하 도면을 통하여 이동 로봇 시스템 의 동작 흐름에 대해 알아본다. 도 4는 본 발명의 일 실시예에 따른, 이동 로봇 시스템의 제어 방법 순서를 나타낸 순서도이다. 도 4를 참조하면, 이동 로봇는 주행할 이동 공간 내를 실제로 주행하거나 시뮬레이션 주행을 한 후 취득한 결과를 서버로 송신한다. (S110, S120, S130) 상기 주행 결과는 이동 로봇이 실제 주행하면서 얻은 각종 정보를 포함할 수 있다. 예를 들어, 센서의 동 작 정보, 주행 속도 정보 및 주행 방향 정보 중 적어도 하나를 포함할 수 있으며, 시뮬레이션 주행 결과는 스스 로 가상의 시뮬레이션 주행을 하여 취득한 이동 공간에 관한 각종 정보를 포함할 수 있다. 서버는 이동 로봇으로 송신된 주행 결과 즉, 이동 공간에 대한 정보를 수신하고 저장한 후, 외부 로 봇으로부터 상기 이동 공간에 대한 정보를 수신한다. (S140, S150) 상기 이동 공간에 대한 정보는 S110, S120 단계에서 설명한 바와 마찬가지로 외부 로봇이 이동 공간에서 주행하 면서 얻은 각종 정보 예들 들어, 센서의 동작 정보, 주행 속도 정보 및 주행 방향 정보 중 적어도 하나를 포함할 수 있으며, 외부 로봇이 가상 시뮬레이션을 하여 획득한 주행 결과 또한 포함될 수 있다. 서버가 주행 결과를 수신하였으면, 서버는 수신된 정보들을 기초로 심층 학습을 하여 이동 공간에 대 한 주행 정보를 생성하고 저장한다. 그리고 생성된 정보는 이동 로봇으로 송신한다. (S160, S170) 이동 로봇은 서버로부터 수신한 주행 정보를 이동 로봇의 저장부에 저장함과 동시에 이를 기초로 이동 로봇의 주행을 제어할 수 있다. (S180, S190) 도 4는 서버가 외부 로봇으로부터 이동 공간에 대한 정보를 수신하는 단계 및 주행 정보를 생성하는 단계 를(S150, 160) 이동 로봇이 이동 공간을 주행하는 단계와 시뮬레이션 주행을 수행하는 단계(S110, S120) 이후에 시작하는 단계로 도시하였지만 이에 한정되는 것은 아니고 S110, S120 단계를 거치지 않고 처음부터 바 로 외부 로봇으로부터 이동 공간에 대한 정보를 수신할 수 있다. 즉, 이동 로봇이 과거 경험해보지 못한 환경에 들어섰고 바로 실 주행을 해야 한다면, 서버로부터 바로 심 층 학습을 하여 생성된 주행 정보를 수신 하고 이를 기초로 주행을 할 수 있다. 지금까지 본 발명의 일 실시예인 이동 로봇 시스템의 구성과 동작 흐름에 대해 알아보았다. 이하 본 발명의 다른 실시예인 이동 로봇의 구성과 동작에 대해 알아본다. 도 5는 이동 로봇의 구성을 나타낸 블럭도이고 도 6은 이동 로봇의 제어 방법을 나타낸 순서도이다. 도 5를 참고하면, 이동 로봇은은 제어부, 유저 인터페이스, 센서부, 통신부, 위치 검 출부, 주행부, 동작부 및 저장부를 포함할 수 있다. 도 5에 개시된 이동 로봇은 도 3에 개시된 이동 로봇 시스템에서 서버가 제외되었으며, 통신부와 제어부를 제외한 다른 구성 요소의 특징은 도 3에서 설명한 바와 같다. 따라서, 이에 대한 설명은 생략하 고 이하 통신부와 제어부에 대해 알아보도록 한다. 통신부는 외부 서버로부터 이동 로봇이 주행할 이동 공간에 대한 정보를 수신할 수 있다. 외부 서버 는 무선 통신을 이용하여 다른 외부 로봇으로부터 수신한 이동 공간에 대한 정보가 저장되어 있다. 통신부가 외부 서버로부터 이동 공간에 대한 정보를 수신하면, 제어부는 이를 기초로 하여 이동 로봇 이 주행할 이동 공간에 대한 주행 정보를 생성할 수 있다. 구체적으로, 제어부는 수신 받은 이동 공간에 대한 정보를 기초로 심층학습(Deep-Learning)을 하여 주행정 보를 생성한다. 그리고 생성된 주행 정보를 기초로 이동 로봇의 주행부 또는 동작부를 제어할 수 있다. 도 3과 도 4에 개시된 이동 로봇 시스템의 경우 서버가 외부 로봇으로부터 받은 이동 공간에 관한 정 보를 기초로 심층학습을 하여 주행 정보를 생성하나, 도 5에 개시된 이동 로봇은 외부 서버로부터 이동 공 간에 관한 정보만을 수신하고 이를 기초로 직접 심층학습을 하여 주행정보를 생성한다는 것에 그 차이점이 존재 한다. 도 6은 도 5에 개시된 이동 로봇의 제어 방법의 흐름을 나타낸 순서도이다. 도 6을 참조하면, 이동 로봇은 외부 서버로부터 외부 서버에 저장되어 있는 주행 공간에 대한 정보를 수신 한다. (S210) 상기 주행 정보는, 외부 로봇이 이동 공간에서 주행하면서 얻은 각종 정보 예들 들어, 센서의 동작 정보, 주행 속도 정보 및 주행 방향 정보 중 적어도 하나를 포함할 수 있으며, 외부 로봇이 가상 시뮬레이션을 하여 획득한 주행 결과 또한 포함될 수 있다. 주행 공간에 대한 정보를 수신하면, 이동 로봇은 수신한 정보를 기초로 심층학습을 하여 이동 공간에 대한 주행 정보를 생성하고 이를 저장한다. (S220) 그 후, 이동 로봇은 생성된 주행 정보를 기초로 이동 로봇의 주행을 제어한다. (S230) 또한, 도면에는 도시하지 않았지만, 심층학습을 통하여 생성된 주행 정보는 이동 로봇에 저장될 수 있으며, 외부 서버로 전송하여 저장할 수 있다. 외부 서버에 전송한 경우, 이동 로봇에 저장되어 있는 주행 정 보가 삭제되었거나 사용자가 이동 로봇을 교체한 경우 서버에 저장되어 있는 결과를 수신한 후 바로 이를 활용 할 수 있어 보다 빠르게 이동 로봇을 제어할 수 있는 장점이 존재한다.지금까지 도면들을 통하여 이동 로봇 시스템과 이동 로봇의 구성 및 동작 흐름에 대해 알아보았다. 이 하 도면들을 통하여 본 발명에 적용되는 원리인 심층학습(Deep Learning)에 대해 알아본다. 도 7은 심층학습에 대한 개략적인 개념도를 도시한 도면이고, 도 8은 심층학습의 일 과정으로서, 거리 센서 데 이터로 2D 이미지 데이터를 생성하는 방법을, 도 9는 도 8에 따라 생성된 이미지를 기초로 심층학습을 하는 과 정을 나타낸 도면이다. 심층 학습(Deep Learning)은 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화(abstractions, 다량의 데"}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이터나 복잡한 자료들 속에서 핵심적인 내용 또는 기능을 요약하는 작업)를 시도하는 기계학습(machine learning)에 관한 알고리즘의 집합을 의미한다. 구체적으로, 심층 학습은 어떠한 학습 데이터를 컴퓨터가 이해할 수 있는 형태(예를 들어 이미지의 경우는 픽셀 (Pixel)정보를 열 벡터로 표현하는 등)로 표현(Representation)하고 이를 학습에 적용하기 위해 많은 연구(어떻 게 하면 더 좋은 표현기법을 만들고 또 어떻게 이것들을 학습할 모델을 만들지에 대한)에 대한 학습 기법으로, DNN(Deep Neural Networks) 및 DBN(Deep Belief Networks)등을 포함한다. 따라서, 심층학습은 입력 데이터에 대한 명확한 출력데이터가 주어지지 않는다. 즉, 비지도식 학습 비지도식 과 정이지만 행동에 대한 보상함수에 따라 보상치가 정해지는 방법이다. 도 7을 참조하면, 심층학습은 먼저 주변 환경을 인지하고 현재 환경 상태를 프로세서에 전달한다. 프로세서는 이에 맞는 행동(Action)을 수행하고 환경은 다시 그 행동에 따른 보상치를 프로세서에게 알려준다. 그리고 프로 세서는 보상치를 최대로 하는 행동을 택하게 된다. 이러한 과정에 통해 학습 과정이 진행된다. 앞서 설명한대로 심층학습을 하면서 이용되는 학습 데이터는, 실제 로봇이 주행하면서 얻은 결과일 수도 있으며, 시뮬레이션 주행을 통하여 얻은 데이터 일 수도 있다. 시뮬레이션 과정을 수행하는 경우 시뮬레이션 속 도를 조정함으로써 보다 빠르게 데이터를 획득할 수 있다. 또한, 심층 학습은 심층 신경망(Deep Neural Network, DNN)이라는 알고리즘을 통해 수행된다. 도 8와 도 9는 이 를 설명하기 위한 도면이다. 심층 학습을 통하여 주행 정보를 생성하기 위해서는 먼저 이동 공간에 대한 정보를 취득하여야 한다. 따라서, 일 예로서, 도 8에 도시된 바와 같이 이동 로봇은 1D 거리 센서 데이터로 2D 이미지 데이터를 생성할 수 있다. 즉. 주행 정보를 생성하기 위해서는 입력 데이터를 설계하여야 하는데, 입력 데이터로는 이동 로봇의 속도, 주 행 방향, 거리 센서 값 등이 사용될 수 있다. 거리 센서에 의해 측정된 값은 보통 Polar Coordinate 즉, 거리와 방향 값으로 주어지는데 이것을 각각 1차원으로 해서 네트워크에 입력할 수 있고 도 8에 도시된 바와 같이 2D 이미지로 만들어서 입력할 수 있다. 도 9는 심층 학습은 심층 신경망(Deep Neural Network, DNN) 알고리즘을 설명하기 위한 도면이다. 심층 신경망(DNN)은 입력층(input layer)과 출력층(output layer) 사이에 다중의 은닉층(hidden layer)이 존재 하는 심층(deep) 신경망, 동물의 시각 피질의 구조와 유사하게 뉴런 사이의 연결 패턴을 형성하는 컨볼루션 (convolutional) 신경망, 시간에 따라 매순간마다 신경망을 쌓아올리는 재귀(recurrent) 신경망으로 구체화될 수 있다. 구체적으로 CNN은 컨볼루션(Convolution)과 서브 샘플링(Sub-Sampling)을 반복하여 데이터의 양을 줄이고, 왜곡 시켜 신경망을 분류한다. 즉, CNN은 특징 추출과 분류 행위를 통해 부류 결과를 출력하는데, 주로 이미지를 분 석하는데 사용된다. 컨볼루션은 영상 필터링을 의미하며, 가중치를 갖는 마스크를 이용한다. 도 9를 참조하면, 컨벌류션은 입력 영상에서 마스크를 씌운 후, 입력 영상의 픽셀값과 마 스크의 가중치를 각각 곱하고, 그 합을 출력 영상의 픽셀값으로 산출한다. 마스크는 입력 영상의 각 부분마다 복수 개로 씌여지며, 마스크가 이동하면서 산출된 결과값을 합한 결과가 추출된다. 추출되는 영상은 적어도 하나 이상의 영상이 추출되는데, 강인한 특징(왜곡, 변형과 같 은 환경변화에 적응하는)을 유도한다. 도 9의 일 예에 따라 제 1 컨벌루션에 의해서 추출되는 출력 영상(feature maps, 312)은 4장이다. 서브 샘플링은 영상의 크기를 줄이는 과정을 의미한다. 일 예로 서브 샘플링은 맥스-풀(Max Pool)을 사용한다. 맥스-풀은 해당 영역에서 최대치를 선택하는 기법인데 뉴런이 가장 큰 신호에 반응하는 것과 유사하다. 서브 샘 플링은 노이즈를 감소시키고, 학습의 속도를 증가시킨다. 일 예로 제 1 컨벌루션에서 출력된 출력 영상에 서브 샘플링은 맥스-풀을 위한 해당 영역을 선 택하고, 해당 영역의 픽셀값에서 최대값만이 출력된다. 도 9에서 제 1서브 샘플링에 의해서 출력되는 출력 영상은 4장이다. 한편, CNN은 컨벌루션(310, 330) 및 서브 샘플링(320, 340)을 반복적으로 수행한다. 반복과정의 횟수는 제한이 없다. 즉, 도 10에서는 2번 반복과정을 도시하였지만, 이에 제한되지 않는다. 마지막으로 CNN은 완전 연결(Fully-Connected MLP, 350)를 수행한다. 완전 연결은 학습 증가 시간을 단축 시키고, 망의 크기 및 변수의 개수를 줄이기 위한 것으로, 수많이 출력될 수 있는 출력 영상(312, 322)을 1차원 행렬으로 변환한다. 행렬은 입력단에서 맵핑(Mapping)된다. 일 예로 수많은 고양이 영상이 CNN을 거치면, 개와 고양이 영상 중에서 고양이 영상을 구분할 수 있다. 지금까지는 서버를 통해 심층학습을 하고 이를 통하여 주행을 효율적으로 하는 특징에 대해 설명하였다. 이하 실시 예는 서버를 이용하여 물체를 효율적으로 다루는 특징에 대해 알아본다. 도 10은 본 발명의 또 다른 실시예인 이동 로봇 시스템의 제어 흐름을 나타낸 순서도로서, 본 실시예에 해당 하는 이동 로봇 시스템의 구조는 도 3에서 설명한 구조와 동일하다. 따라서 이하 제어 흐름에 대해서만 알아 본다. 도 10을 참조하면, 이동 로봇은 이동하고자 하는 이동 공간 내에 물체가 존재하는지 판단하고 물체가 존재 한다면 물체에 접근하여 이동 로봇이 인식 가능한 물체인지 판단한다. (S310. S320) 물체를 인식하는 과정은 물체에 부착된 식별표(identifier)을 통해 감지하거나 식별표와 관련된 다른 정보 예를 들어, 이미지 정보, 음향 정보 등을 통하여 물체에 대한 정보를 인식할 수 있다. 이동 로봇이 인식 가능한 물체가 존재한다면, 인식된 정보를 서버로 송신한다. (S330) 서버가 인식된 정보를 수신하였다면, 서버는 물체에 대한 정보가 서버 내에 존재하는지 판단한다. 물체에 대한 정보는 물체가 가지고 있는 여러 특징 및 사용자들로부터 받은 물체에 대한 정보를 포함할 수 있다. 이러한 정보들은 다시 이동 로봇에 송신되는데, 이동 로봇은 이러한 정보를 기초로 물체를 효 율적으로 다룰 수 있다. 예를 들어, 물체를 운반할 때 주의해야 하는 사항, 물체의 무게 및 크기 등이 포함될 수 있으며, 사용자가 직접 입력해 놓은 물체에 대한 정보 등이 이에 포함될 수 있다. 이러한 특징을 갖는 경우 물체에 대한 사용 정보를 사용자들끼리 공유할 수 있어 물체에 대한 정보와 지식을 늘 려갈 수 있는 장점이 존재한다. 만약, 물체에 대한 정보가 존재하지 않는다면 다른 로봇으로부터 물체에 대한 정보를 수신할 수 있다. (S350) 이러한 정보는 다른 사용자가 상기 물체에 대해 입력한 정보 또는 다른 이동 로봇이 물체를 다루면서 취득한 정 보 등이 포함될 수 있다. 만약, S350 과정을 거치기 전에 서버가 미리 다른 외부 로봇으로부터 물체에 대 한 정보를 수신하여 저장하고 있었다면 S350 과정은 생략할 수 있다. S340, S350 과정에 의해 물체에 대한 정보를 수신하였다면, 서버는 이를 기초로 하여 물체에 최적화된 사 용 방법을 결정하고 결정된 사용 방법을 이동 로봇에 송신한다. (S360, S370) 이동 로봇은 수신된 정보를 기초하여 사용자의 명령을 수행할 수 있다. (S380) 예를 들어, 사용자가 특정 물건을 이동시키는 명령을 받은 경우 이동 로봇은 서버로부터 받은 물체에 대한 정보를 기초로 사용자의 명령을 수행할 수 있다. 상기 물체에 대한 정보는 물체가 가지고 있는 특성 또는 크기 무게 또는 운반시 주의 사항 등이 포함될 수 있으므로 이동 로봇을 이를 기초로 하여 사용자의 명령을 보다 효 율적으로 수행할 수 있다.S380 과정에 의해 동작이 수행되었는데 만약 오류가 존재한다면, 이동 로봇은 오류 결과를 서버에 송신할 수 있다. (S400) 수신된 결과는 서버에 저장되며, 다른 사용자들은 이를 참고할 수 있고 오류를 업데이트하여 나중에 다시 활용할 수 도 있다. 도 10에 따른 이동 로봇 시스템의 경우, 물체에 대한 정보를 다른 사용자와 공유함으로써, 보다 효율적으로 물체를 다룰 수 있는 장점이 존재한다. 그러나, 무불별한 물체에 대한 정보를 공유하는 경우 사용자의 사생활 침해 문제가 발생할 수 있다. 따라서, 본 발명은 사용자가 미리 설정해 놓은 물체에 대한 정보는 서버에 송신하지 않음으로써, 이러한 문제를 사전 에 방지할 수 있다. 즉, 사용자는 특정 물체에 대해 로봇이 이를 인지하지 못하도록 설정해 놓으면, S310, S320 과정에 의해 이동 로봇이 물체에 접근하여도 물체를 인지하지 못하므로 물체에 대한 정보를 서버로 송신할 수 없다. 따 라서 사생활 침해를 막을 수 있는 효과가 존재한다. 또 다른 실시예로, 청소 로봇에 있어서, 자동 청소를 하지 말아야 할 구역 또는 물체에 대해 사전에 지정해 놓 아 사용자가 원하는 지역 또는 물체만 청소를 할 수 있게 할 수도 있다. 지금까지 도면을 통하여 본 발명에 해당하는 이동 로봇 시스템 및 이동 로봇의 구성과 특징 및 효과에 대해 알아보았다. 기존의 지도 학습 방식의 이동 로봇 시스템의 경우, 단순히 이동 로봇이 요구한 정보를 외부 서버로부터 수신하 는 정도에 지나지 않아 이동 로봇이 주행에 필요한 실제 정보를 능동적으로 수신하고 이를 반영할 수 없어 주행 기술이 향상이 어려운 문제가 있었으며, 이러한 문제는 이동 로봇이 새로운 이동 공간으로 이동하였을 때 새로 운 공간에 대한 정보가 부족하여 주행 능력에 많은 어려움이 존재하였다. 그러나 본 발명은 다른 이동 로봇으로부터 학습된 주행 정보를 통하여 주행을 할 수 있으므로 경험해 보지 못한 새로운 공간에 이동 로봇이 배치되어도 보다 안전적으로 새로운 공간에서 주행을 할 수 있는 장점이 있다. 또한, 주행 정보에 관하여 지속적인 학습을 함으로써, 더욱 더 지능적인 주행을 할 수 있는 효과가 있다."}
{"patent_id": "10-2016-0153535", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "지금까지 실시 예들이 비록 한정된 실시 예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및 / 또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형 태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성 될 수 있다. 그러므로, 다른 구현들, 다른 실시 예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위 의 범위에 속한다."}
{"patent_id": "10-2016-0153535", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 이동 로봇 시스템의 전체 구성 외관을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 이동 로봇의 외관을 도시한 도면이다. 세탁물이 내부로 유입되는 과정을 도 시한 도면이다. 도 3은 본 발명의 일 실시예에 따른 이동 로봇 시스템의 구성을 나타낸 블럭도이다.도 4는 본 발명의 일 실시예에 따라 이동 로봇 시스템의 제어 방법을 나타낸 순서도이다. 도 5는 본 발명의 일 실시예에 따른 이동 로봇의 구성을 나타낸 도면이다. 도 6은 본 발명의 일 실시예에 따라 이동 로봇의 제어 방법을 나타낸 순서도이다. 도 7은 심층학습의 기본 개념 순서를 도시한 도면이다. 도 8은 심층학습의 일 과정으로서, 거리 센서 데이터로 2D 이미지 데이터를 생성하는 방법을 나타낸 도면이다. 도 9는 도 8에 따라 생성된 이미지를 기초로 심층학습을 하는 과정을 나타낸 도면이다. 도 10은 본 발명의 또 다른 실시예인 이동 로봇 시스템의 제어 흐름을 나타낸 순서도이다."}
