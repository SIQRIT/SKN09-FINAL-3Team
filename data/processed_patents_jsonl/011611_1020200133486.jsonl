{"patent_id": "10-2020-0133486", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0049855", "출원번호": "10-2020-0133486", "발명의 명칭": "분산 뉴럴 네트워크의 제어 방법 및 장치", "출원인": "국방과학연구소", "발명자": "박종성"}}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크의 수보다 적은 수의 파트로 상기 복수의 필터를분류하는 단계;하나의 파트를 이용하여 둘 이상의 학생 네트워크를 학습시키기 위해, 상기 둘 이상의 학생 네트워크에 동일한파트에 관한 정보를 전송하는 단계; 상기 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신하는 단계; 및상기 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성하는 단계를 포함하는, 분산 뉴럴 네트워크의 제어 방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 파트의 수는 상기 학생 네트워크의 수를 2로 나눈 값에 기초하여 결정되는 것인, 분산 뉴럴 네트워크의 제어 방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,각 파트를 통해 학습되는 학생 네트워크의 수가 상이할 경우,상기 각 파트에 포함된 필터의 수에 기초하여, 상기 각 파트를 통해 학습되는 학생 네트워크의 수가 결정되는것인, 분산 뉴럴 네트워크의 제어 방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,디바이스의 통신 안정성에 대한 정보에 기초하여, 상기 학생 네트워크가 탑재될 디바이스를 결정하는 단계를 더포함하는, 분산 뉴럴 네트워크의 제어 방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 학생 네트워크가 탑재될 디바이스를 결정하는 단계는,각 학생 네트워크가 통신 실패된 경우 뉴럴 네트워크 전체 추론 정확도에 관한 정보에 기초하여, 상기 학생 네트워크가 탑재될 디바이스를 결정하는 것인, 분산 뉴럴 네트워크의 제어 방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 학생 네트워크가 탑재될 디바이스를 결정하는 단계는,상기 학생 네트워크를 학습시키는데 이용된 파트에 기초하는 것인, 분산 뉴럴 네트워크의 제어 방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 복수의 필터를 분류하는 단계는 공개특허 10-2022-0049855-3-각 파트로 분류된 필터의 수가 균일하도록 분류하는 것인, 분산 뉴럴 네트워크의 제어 방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 분산 뉴럴 네트워크는 NONN(Network of Neural Network) 기반으로 하는 것인, 분산 뉴럴 네트워크의 제어방법."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 명령어(instruction)를 저장하는 메모리(memory); 및상기 적어도 하나의 명령어를 실행하여, 복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크의 수보다 적은 수의 파트로 상기 복수의 필터를분류하고,하나의 파트를 이용하여 둘 이상의 학생 네트워크를 학습시키기 위해, 상기 둘 이상의 학생 네트워크에 동일한파트에 관한 정보를 전송하고,상기 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신하고,상기 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성하는 프로세서(processor)를 포함하는, 분산 뉴럴 네트워크 제어 장치."}
{"patent_id": "10-2020-0133486", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "분산 뉴럴 네트워크의 제어 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 비일시적 기록매체로서,상기 분산 뉴럴 네트워크의 제어 방법은,복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크의 수보다 적은 수의 파트로 상기 복수의 필터를분류하는 단계;하나의 파트를 이용하여 둘 이상의 학생 네트워크를 학습시키기 위해, 상기 둘 이상의 학생 네트워크에 동일한파트에 관한 정보를 전송하는 단계; 상기 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신하는 단계; 및상기 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성하는 단계를 포함하는, 비일시적 기록매체."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크의 수보다 적은 수의 파트로 상기 복수의 필터를 분류하는 단계, 하나의 파트를 이용하여 둘 이상의 학생 네트워크를 학습시키기 위해, 상기 둘 이상의 학생 네트 워크에 동일한 파트에 관한 정보를 전송하는 단계, 상기 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신하는 단계 및 상기 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성하 는 단계를 포함하는, 분산 뉴럴 네트워크의 제어 방법을 제공한다."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 분산 뉴럴 네트워크(Distributed Neural Network)에 관한 것으로, 더 상세하게는 데이터 전송률이 낮 은 디바이스를 이용하는 분산 뉴럴 네트워크의 제어 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 다양한 사물인터넷(Internet of Things) 디바이스의 확산과 함께, 스마트 워치, 스마트 고글과 같이 다양 한 웨어러블 디바이스가 개발되고 있다. 이러한 웨어러블 디바이스들은 저전력 요구사항으로 인해, 사람의 몸을 매질로 하는 인체 통신이나 블루투스 통신 등과 같이 낮은 데이터 전송률을 갖는다. 한편 인공지능 기술이 발전함에 따라, 상술한 웨어러블 디바이스와 같이 데이터 전송률이 낮은 디바이스에서도 이미지 분류, 음성인식 등과 같은 뉴럴 네트워크 기반 응용프로그램을 구동할 필요성이 대두되고 있다. 데이터 전송률이 낮은 디바이스에서 뉴럴 네트워크 기반 응용프로그램을 구동하기 위해, 오프로딩 방식으로 뉴 럴 네트워크를 구동하는 기법이 개발되었다. 이는, 디바이스로부터 고성능 CPU, GPU 그리고 가속기와 같은 하드 웨어를 사용하는 클라우드 시스템으로 데이터가 전송되어 원격으로 뉴럴 네트워크가 수행된 후, 데이터 처리 결과가 다시 클라우드 시스템에서 디바이스로 전송되는 방식이다. 그러나, 이러한 오프로딩 구동 방식은 원격 서버 상태 및 네트워크 통신 상태에 따라 뉴럴 네트워크 추론 속도 가 저하될 수 있으므로, 실시간성을 해칠 수 있다. 또한, 디바이스의 수가 증가할수록 빈번한 통신이 수반되어 추가적인 지연이 발생할 수 있고, 디바이스의 전력 소모가 증가할 수 있다. 따라서, 데이터 전송률이 낮은 디바 이스에 뉴럴 네트워크를 탑재하여 구동하는 방법의 필요성이 존재한다."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 실시 예가 해결하고자 하는 과제는, 데이터 전송률이 낮은 디바이스에 학생 네트워크를 탑재하는, 분산 뉴럴 네트워크의 제어 방법 및 장치를 제공하는데 있다. 본 실시 예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 이하의 실시 예들로부터 또 다른 기술적 과제들이 유추될 수 있다."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1 실시 예에 따라, 분산 뉴럴 네트워크의 제어 방법은, 복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크의 수보다 적은 수의 파트로 상기 복수의 필터를 분류하는 단계, 하나의 파트를 이용하여 둘 이상의 학 생 네트워크를 학습시키기 위해, 상기 둘 이상의 학생 네트워크에 동일한 파트에 관한 정보를 전송하는 단계, 상기 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신하는 단계 및 상기 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성하는 단계를 포함할 수 있다. 제2 실시 예에 따라, 분산 뉴럴 네트워크의 제어 장치는 적어도 하나의 명령어(instruction)를 저장하는 메모리 (memory) 및 상기 적어도 하나의 명령어를 실행하여, 복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트 워크의 수보다 적은 수의 파트로 상기 복수의 필터를 분류하고, 하나의 파트를 이용하여 둘 이상의 학생 네트워 크를 학습시키기 위해, 상기 둘 이상의 학생 네트워크에 동일한 파트에 관한 정보를 전송하고, 상기 동일한 파 트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신하고, 상기 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성하는 프로세서(processor)를 포함할 수 있다. 제3 실시 예에 따라, 컴퓨터로 읽을 수 있는 기록매체는 분산 뉴럴 네트워크의 제어 방법을 컴퓨터에서 실행시 키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 비일시적 기록매체로서, 상기 분산 뉴럴 네트워크의 제어 방법은, 복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크의 수보다 적은 수의 파트로 상기 복수의 필터를 분류하는 단계, 하나의 파트를 이용하여 둘 이상의 학생 네트워크를 학습시키기 위해, 상기 둘 이상의 학생 네트워크에 동일한 파트에 관한 정보를 전송하는 단계, 상기 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신하는 단계 및 상기 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성하는 단계를 포함할 수 있다. 기타 실시 예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 분산 뉴럴 네트워크의 제어 방법 및 장치는, 학생 네트워크가 탑재된 디바이스 중 일부의 통신 이 불안정하더라도 일정한 추론 정확도를 유지할 수 있는 효과가 있다."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "발명의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부 터 당해 기술 분야의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시 예들에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 명세서 전체에서 기재된 \"a, b, 및 c 중 적어도 하나\"의 표현은, 'a 단독', 'b 단독', 'c 단독', 'a 및 b', 'a 및 c', 'b 및 c', 또는 'a, b, 및 c 모두'를 포괄할 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 개시의 실시 예들을 상세히 설명한다. 도 1은 분산 뉴럴 네트워크 구조의 일례를 설명하기 위한 도면이다. 도 1을 참고하면, 뉴럴 네트워크는 필터를 통해 지식을 추출하여 메모리 요구량과 연산량이 큰 교사 네트 워크의 최종결과를 학습한 단일 학생 네트워크를 생성할 수 있다. 여기서, 교사 네트워크는 비 교적 고성능의 네트워크일 수 있고, 학생 네트워크는 교사 네트워크의 일부 지식을 이용하여 학습하 는 서브 네트워크로 지칭될 수 있다. 하지만 도 1의 학생 네트워크의 경우, 여전히 요구되는 연산량 및 메모리 용량이 크기 때문에, 데이터 전 송률이 낮은 단일 디바이스에서 구동하기에 어려울 수 있다. 따라서, 학생 네트워크는 레이어 단위로 여러 디바이스(131 내지 133)에 분산하여 탑재될 수 있다. 이러한 경우, 제2 디바이스는 학생 네트워크의 일부 지식 및 제1 디바이스의 추론 결과를 이용하여 학습할 수 있다. 또한, 제3 디바이스는 학생 네 트워크의 일부 지식 및 제2 디바이스의 추론 결과에 기초하여 학습하고, 최종 특징 맵을 생성할 수 있다. 즉, 도 1의 분산 뉴럴 네트워크는 하나의 추론 결과를 얻기 위해서 모든 디바이스(131 내지 133) 간의 데 이터 송수신이 불가피하므로, 디바이스간 요구되는 통신량 및 통신 빈도가 높을 수 있다. 또한, 제1 디바이스 내지 제3 디바이스 중 어느 하나의 디바이스의 통신이 두절되는 경우, 추론 결과의 도출이 불가능할 수 있다. 따라서, 도 1의 분산 뉴럴 네트워크는 웨어러블 디바이스와 같은 데이터 전송률이 낮은 디바이스 에 탑재하기는 어려울 수 있다. 도 2a, 도 2b 및 도 3은 NONN 기반 분산 뉴럴 네트워크 구조의 일례를 설명하기 위한 도면이다. 분산 뉴럴 네트워크의 다른 일례로, NONN(Network of Neural Network) 기반 분산 뉴럴 네트워크가 있다. 도 2a 를 참고하면, NONN 기반의 분산 뉴럴 네트워크는 교사 네트워크와 다수의 학생 네트워크(221 내지 223)를 포함할 수 있다. 그리고 교사 네트워크에 포함된 각각의 독립적인 필터를 이용하여 다수의 학생 네 트워크(221 내지 223)를 학습시킬 수 있고, 다수의 학생 네트워크(221 내지 223)는 각각 별개의 디바이스(231 내지 233)에 탑재될 수 있다. 분산 뉴럴 네트워크의 최종 추론 결과는 별개의 디바이스(231 내지 233)의 각각의 출력에 기초하여 생성될 수 있다. 한편, 교사 네트워크에서 다수의 학생 네트워크(221 내지 223)에 지식을 전달하는 방법은 도 2b를 통해 설 명될 수 있다. 먼저 메모리 사용량과 연산량이 큰 교사 네트워크의 최종 컨볼루션 레이어에 포함된 필터를 복수의 그룹으로 분류할 수 있다. 이후, 복수의 그룹에 포함된 필터는 다시 복수의 파트로 분류될 수 있다. NONN 기반의 분산 뉴럴 네트워크는, 복수의 파트로 분류된 각각의 필터를 복수의 학생 네트워크(제1 학생 네트워크 및 제2 학생 네트워크)에 전달할 수 있다. 여기서, 복수의 학생 네트워크(제1 학생 네트워크 및 제2 학생 네트워크)는 모두 독립적일 수 있다. 이후, NONN 기반의 분산 뉴럴 네트워크는 각각 의 학생 네트워크(제1 학생 네트워크 및 제2 학생 네트워크)의 최종 결과들을 연결(concatenate)하여 결과를 도 출할 수 있다. 한편, 도 2b에는 교사 네트워크에 복수의 그룹 및 복수의 파트가 생성되는 것으로 도시되어"}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있으나, 복수의 그룹 및 복수의 파트가 생성되는 장소가 달라질 수 있음은 해당 기술분야의 통상의 기술자에게 자명하다. 이러한 NONN 기반의 분산 뉴럴 네트워크는 디바이스의 통신이 안정된 경우, 교사 네트워크의 모든 지 식을 활용하기 때문에 높은 추론 정확도를 제공할 수 있다. 또한, 학생 네트워크가 탑재되는 디바이스의 통신이 불안정한 경우, 도 1의 분산 뉴럴 네트워크와 달리 결과 도출이 가능하다. 그러나, 통신이 두절된 디바이 스에 의해 학습된 결과를 수신하기 어려운 경우, NONN 기반의 분산 뉴럴 네트워크는 교사 네트워크의 일부 지식만을 사용하기 때문에, 추론 정확도가 크게 저하될 수 있다. 한편, NONN 기반의 분산 뉴럴 네트워크는 추론 정확도를 향상시키기 위하여 최종 컨볼루션 레이어에 포함된 필터들을 AH(Activation Hub) 규칙에 기초하여 복수의 그룹으로 분류할 수 있다. 일 실시 예에 따르면, NoNN 기반의 분산 뉴럴 네트워크는 교사 네트워크의 최종 컨볼루션 레이어 에 포함된 필터를 통해 추출된 지식들이 특정 그룹에 편향되지 않도록 AH 규칙에 의거하여 필터를 복 수의 그룹으로 분류할 수 있다. AH 규칙은 동일한 종류의 입력에 대하여 큰 중요도를 가지는 필터를 분류 하는 규칙으로, 교사 네트워크의 최종 컨볼루션 레이어에서 i번째 필터의 출력 평균을 ai, j번째 필 터의 출력 평균을 aj라고 할 때, AH 규칙은 수학식 1과 같이 표현할 수 있다. [수학식 1]"}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "최종 컨볼루션 레이어의 필터를 그룹으로 분류하기 위해, 각 필터를 정점(Vertex)으로 하고, 필 터 간의 간선(Edge)들의 가중치를 AH 값으로 가지는 그래프 형태의 자료구조를 생성할 수 있다. 이후, AH 값과 Newman, Mark EJ. \"Modularity and community structure in networks.\" Proceedings of the national academy of sciences 103.23 : 8577-8582.에 개시된 분할 알고리즘에 기초하여, 필터를 복수의 그 룹으로 분류할 수 있고, 이를 커뮤니티 구조(Community Structure)로 지칭할 수 있다. AH 규칙에 기초하여, 각 필터가 복수의 그룹으로 분류될 때, 동일한 입력에 대해 출력 값이 큰 필터들은 AH 값이 작기 때문에, 서로 다른 그룹으로 분류될 수 있다. 예를 들어, 이미지 내의 객체에서 개를 판별할 수 있는 필터가 여러 개 존재하는 경우, 각각의 필터는 서로 다른 그룹으로 분류될 수 있다. 이러한 과정은 중요도 가 높은 필터들을 분산시키는 과정으로도 볼 수 있다. 한편, AH 규칙으로 분류된 각각 그룹들에 포함된 필터의 수가 상이할 수 있으므로, NoNN 기반 분산 뉴럴 네트워 크는 도 2b에 도시된 바와 같이 복수의 그룹(제1 그룹 내지 제4 그룹)에 포함된 필터들을 다시 파트(제1 파트 및 제2 파트)로 분류할 수 있다. 이 때 각 파트들에 포함된 필터의 수가 균일할 수 있도록 필터들이 분류 될 수 있다. 이후, NoNN 기반 분산 뉴럴 네트워크는 각 파트를 이용하여 학생 네트워크를 훈련시킬 수 있 다. 한편, NoNN 기반 분산 뉴럴 네트워크는 학생 네트워크가 탑재되는 디바이스가 통신에 실패한 경우, 교사 네트워 크의 일부 필터를 통해 학습된 학생 네트워크의 결과를 사용할 수 없으므로 추론 정확도가 저하될 수 있다. 한편, 도 3은 4개의 학생 네트워크를 학습시키는 NONN 기반의 분산 뉴럴 네트워크를 설명하기 위한 도면이다. 만약, 교사 네트워크의 최종 컨볼루션 레이어에 포함된 필터들이 도 3과 같이 제1 그룹 내지 제5 그룹으로 분류 되고, 학생 네트워크가 탑재될 디바이스의 수가 4개 인 경우, NONN 기반의 분산 뉴럴 네트워크는 학생 네트워크 의 수와 동일한 수의 파트로 필터를 분류할 수 있다. 도 3의 각 그룹, 파트 및 학생 네트워크에 포함된 필터의 수는 괄호 안에 도시되어 있다. 한편, 각 파트에 포함되는 필터의 수를 최대한 균일하게 하기 위하여, 제4 그룹에 포함된 필터(7개)와 제5 그룹 에 포함된 필터(5개)가 제4 파트로 분류될 수 있다. 만약 도 3의 기재와 같이 구성된 NoNN 기반의 분산 뉴럴 네트워크에서 제1 학생 네트워크가 탑재된 디바이스의 통신에 오류가 발생한 경우, 제1 파트에 기초하여 학습된 결과를 사용할 수 없으므로, 최종 특징 맵(Final Feature Map)의 0~9번 요소는 0 값을 가지게 된다. 따라서, 추론 정확도가 저하될 수 있다. 한편, 웨어러블 디바이스는 인체의 움직임이 많고 무선 통신이나 인체 통신을 활용하기 때문에 통신 상태가 불 안정할 수 있다. 따라서, 웨어러블 디바이스 포함한, 데이터 전송률이 낮은 디바이스들에 학생 네트워크가 탑재 되기 위해서는, 분산 뉴럴 네트워크가 통신 에러에 강인할 수 있도록 분산 뉴럴 네트워크를 제어하는 것이 필요 하다. 도 4는 일 실시 예에 따른 분산 뉴럴 네트워크 구조를 설명하기 위한 도면이다. 일 실시 예에 따른 분산 뉴럴 네트워크는 NONN 기반으로 할 수 있다. 따라서, 교사 네트워크의 최종 컨볼루션 레이어에 포함된 필터들이 제1 그룹 내지 제5 그룹으로 분류되는 과정은 도 2b 및 도 3의 분류 과정과 대응될 수 있다. 한편, 일 실시 예에 따른 분산 뉴럴 네트워크의 경우, 학생 네트워크의 수보다 적은 수의 파트로 필터를 분류할 수 있다. 예를 들어, 디바이스의 수 및 디바이스에 탑재될 학생 네트워크의 수가 4개인 경우, 파트의 수는 4개 보다 적은 2개일 수 있다. 제1 그룹 내지 제5 그룹에 포함된 필터들은 제1 파트와 제2 파트에 최대한 균일하게 수로 분류될 수 있다. 따라서, 제1 그룹 및 제3 그룹에 포함된 필터는 제1 파트로 분류될 수 있고, 제2 그룹, 제4 그룹 및 제5 그룹에 포함된 필터는 제2 파트로 분류될 수 있다. 이렇게 파트의 수가 디바이스의 수보다 적 은 경우, 하나의 파트를 이용하여 학습하는 학생 네트워크가 다수가 되기 때문에, 어느 한 디바이스가 통신 두 절되더라도, 모든 파트의 필터를 이용한 학습 결과로 최종 특징 맵을 생성할 수 있다. 도 4를 참고하면, 제1 파트를 이용하여 학습하는 학생 네트워크는 제1 학생 네트워크 및 제3 학생 네트워크일 수 있고, 제2 파트를 이용하여 학습하는 학생 네트워크는 제2 학생 네트워크 및 제4 학생 네트워크일 수 있다. 이후, 분산 뉴럴 네트워크 제어 방법은 동일한 파트를 이용하여 학습된 학생 네트워크의 결과의 평균을 계산할 수 있다. 도 4를 참고하면, 제1 학생 네트워크 및 제3 학생 네트워크의 결과의 평균 값인 제1 파트 평균이 계산 될 수 있고, 제2 학생 네트워크 및 제4 학생 네트워크의 결과의 평균 값인 제2 파트 평균이 계산될 수 있다. 마지막으로, 분산 뉴럴 네트워크 제어 방법은 제1 파트 평균 및 제2 파트 평균을 연결(concatenate)하여, 최종 특징 맵을 생성할 수 있다. 이러한 경우, 제1 학생 네트워크가 탑재된 디바이스에서 통신 오류가 발생하여도, 제3 학생 네트워크를 통해 제1 파트에 포함된 필터를 이용한 학습 결과를 반영하여 최종 특징 맵을 생성할 수 있으므로, 통신 오류로 인한 최종 특징 맵의 변화는 미미할 수 있다. 도 5는 일 실시 예에 따른 분산 뉴럴 네트워크 제어 방법을 설명하기 위한 흐름도이다. 단계 S510에서, 분산 뉴럴 네트워크 제어 방법은 복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크 의 수보다 적은 수의 파트로 복수의 필터를 분류할 수 있다. 여기서, 파트의 수는 학생 네트워크의 수를 2로 나 눈 값에 기초하여 결정되는 것일 수 있다. 일 실시 예에 따른 분산 뉴럴 네트워크 제어 방법은 수학식 2에 기초 하여, 파트의 수를 결정할 수 있다. [수학식 2]"}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, N은 파트의 수를 의미하고, M은 학생 네트워크의 수를 의미한다. 은 내림(버림) 값을 의미한다. 예 를 들어, 학생 네트워크가 탑재될 디바이스의 수가 5개인 경우, 학생 네트워크의 수(M)는 5이고, 파트의 수(N) 는 2.5의 내림 값인 2 이하일 수 있다. 다시 말해, 학생 네트워크가 5개이면 파트의 수는 1개 또는 2개일 수 있 다. 한편, 각 파트를 통해 학습되는 학생 네트워크의 수가 상이할 경우 각 파트에 포함된 필터의 수에 기초하여, 각 파트를 통해 학습되는 학생 네트워크의 수가 결정될 수 있다. 일 실시 예에 따라, N개의 파트 및 M개의 디바이 스를 포함하는 분산 뉴럴 네트워크의 제어 방법은, 파트 중에서 i번째로 많은 필터가 포함된 파트를 이용하여 학습하게 되는 학생 네트워크의 수(Si)를 수학식 3을 통해 구할 수 있다.[수학식 3]"}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "예를 들어, 학생 네트워크의 수(M) 및 파트의 수(N)가 각각 5 및 2이고, 제1 파트에 포함된 필터의 수는 30개, 제2 파트에 포함된 필터의 수가 29개일 수 있다. 이때, i=1이면, 제1 파트 및 제2 파트 중, 필터가 더 많이 포 함된 파트는 제1 파트이므로, 제1 파트를 이용하여 학습하게 되는 학생 네트워크의 수(S1)는 5/2의 올림 값, 즉 3개 일 수 있다. 그리고 i=2이면, 제1 파트 및 제2 파트 중, 필터가 2번째로 많이 포함된 파트는 제2 파트이므 로, 제2 파트를 이용하여 학습하게 되는 학생 네트워크의 수(S2)는 5/2의 내림 값, 즉 2개 일 수 있다. 따라서, 제1 파트를 통해 학습하는 학생 네트워크의 수를 3개로 할 수 있고, 제2 파트를 통해 학습하는 학생 네트워크의 수를 2개로 할 수 있다. 또한, 단계 S510은 각 파트로 분류된 필터의 수가 균일하도록 분류하는 것일 수 있다. 단계 S520에서, 분산 뉴럴 네트워크 제어 방법은 하나의 파트를 이용하여 둘 이상의 학생 네트워크를 학습시키 기 위해, 둘 이상의 학생 네트워크에 동일한 파트에 관한 정보를 전송할 수 있다. 단계 S530에서, 분산 뉴럴 네트워크 제어 방법은 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과를 수신할 수 있다. 단계 S540에서, 분산 뉴럴 네트워크 제어 방법은 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성할 수 있다. 일 실시 예에 따른 분산 네트워크의 제어 방법은 학생 네트워크의 결과의 평균값 을 연결하여 최종 특징 맵을 생성할 수 있다. 따라서, 본 개시의 분산 네트워크의 제어 방법은 파트 간의 중복성을 강화함으로써, 특정 디바이스의 통신 실패 로 인하여 일부 학생 네트워크의 결과가 전달되지 않더라도 추론 정확도를 유지할 수 있다. 도 6a 및 도 6b는 다른 일 실시 예에 따른 분산 뉴럴 네트워크 제어 방법을 설명하기 위한 도면이다. 다른 일 실시 예에 따른 분산 뉴럴 네트워크의 제어 방법은 각 디바이스의 통신 안정성에 관한 정보에 기초하여, 각 디바이스에 탑재될 학생 네트워크를 결정할 수 있다. 이러한 경우, 분산 뉴럴 네트워크의 제어 방 법은 각 학생 네트워크가 통신 실패된 경우의 뉴럴 네트워크 전체 추론 정확도에 관한 정보에 기초하여, 학생 네트워크가 탑재될 디바이스를 결정할 수 있다. 도 6a를 참고하면, 제1 학생 네트워크 내지 제5 학생 네트워크는 각각 제1 디바이스 내지 제5 디바이스 중 하나 에 탑재될 수 있다. 도 6a의 제1 목록은 각 학생 네트워크를 독자적으로 사용하였을 때 추론 정확도가 높 은 순으로 나열한 목록이고, 제2 목록은 각 디바이스의 통신 안정성이 높은 순으로 나열한 목록이다. 다시 말해, 제3 학생 네트워크는 다른 학생 네트워크를 독자적으로 사용하는 경우에 비해, 높은 추론 정확도를 제공 할 수 있는 학생 네트워크이고, 제1 디바이스는 디바이스 중에서 가장 안정된 데이터 송수신을 제공하는 디바이 스일 수 있다. 한편, 학생 네트워크를 독자적으로 사용했을 때의 추론 정확도는 도 7b 및 도 8b와 같은 실험 결 과를 통해 얻을 수 있고, 각 디바이스의 통신 안정성에 관한 정보는 디바이스 제조사 또는 시험기관에서 얻을 수 있으나, 이에 제한되지 않는다. 일 실시 예에 따른 분산 뉴럴 네트워크의 제어 방법은 제1 목록의 순서와 제2 목록의 순서에 따라 각 학생 네트워크를 각 디바이스에 탑재할 수 있다. 이러한 경우, 가장 높은 추론 정확도를 제공하는 학생 네트워 크가 가장 안정된 데이터 송수신을 제공하는 디바이스에 탑재되므로, 통신 상태에 따른 추론 정확도의 저하가 감소될 수 있다. 또한, 다른 일 실시 예에 따른 분산 뉴럴 네트워크의 제어 방법은 학생 네트워크를 학습시키는데 이용된 파트에 기초하여 학생 네트워크가 탑재될 디바이스를 결정할 수 있다. 도 6b를 참고하면, 제3 목록은 제1 파트에 기초하여 학습된 학생 네트워크를 독자적으로 사용했을 때의 추 론 정확도가 높은 순으로 나열한 목록이고, 제4 목록은 제2 파트에 기초하여 학습된 학생 네트워크를 독자 적으로 사용했을 때의 추론 정확도가 높은 순으로 나열한 목록이다. 이러한 경우, 제2 목록에 포함된 각 디바이스에 제1 파트를 통해 학습된 학생 네트워크와 제2 파트를 통해 학습된 학생 네트워크를 서로 교차하여 탑재하도록 결정할 수 있다. 예를 들어, 제1 디바이스에 제1 파트를 통해 학습된 제1 학생 네트워크를 탑재하도록 결정할 수 있고, 제2 디바이스에 제2 파트를 통해 학습된 제2 학생 네트워크를 탑재하도록 결정할 수 있다. 즉, 일 실시 예에 따른 분산 뉴럴 네트워크의 제어 방법은 제n 파트에 기초하여 학습된 학생 네트워크들을 각각 독자적으로 사용하였을 때 추론 정확도가 높은 순으로 정렬한 목록의 x번째 원소를 Pn,x 라고 할 때, 통신 안정성 이 i번째 높은 디바이스에 탑재될 학생 네트워크의 집합(Di)을 수학식 4에 기초하여 결정할 수 있다. [수학식 4]"}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 4에 의하면, 통신 안정성이 제일 높은 디바이스에 탑재될 학생 네트워크의 집합(D1)은 제1 파트에 기초하 여 학습된 네트워크 중 가장 추론 정확도가 높은 학생 네트워크(P1,1)를 포함할 수 있다. 이러한 기준에 기초하 여 학생 네트워크가 탑재될 디바이스를 결정하면, 동일한 파트에 기초하여 학습된 학생 네트워크에서 동시에 통 신 오류가 발생할 확률을 최소화하기 때문에, 통신 상태가 좋지 않은 환경에서도 분산 뉴럴 네트워크의 추론 정 확도의 저하 정도가 감소될 수 있다. 즉, 일부 디바이스에서 통신 에러가 발생하여 일부 학생 네트워크의 결과만 이용하여도, 기존 교사 네트워크와 비슷한 정확도의 추론이 가능하다. 또한, 일 실시 예에 따른 분산 뉴럴 네트워크의 경우, 각 학생 네트워크의 최종 결과만 전송하기 때문에, 웨어러블 디바이스를 포함하는 데이터 전송률이 낮은 디바이스에도 탑재가 가능 하다. 도 7a, 도 7b, 도 8a 및 도 8b는 일 실시 예에 따른 분산 뉴럴 네트워크의 성능을 설명하기 위한 도면이다. 일 실시 예에 따른 분산 뉴럴 네트워크 제어 방법의 성능을 확인하기 위하여, NONN 기반의 종래 분산 뉴럴 네트 워크와 일 실시 예에 따른 분산 뉴럴 네트워크를 각각 8개의 학생 네트워크를 이용하여 학습시켰다. 그리고 나 서 8개의 학생 네트워크가 탑재된 8개의 디바이스 각각에 대하여, 통신 에러가 발생한 경우 해당 디바이스의 출 력 값을 0으로 설정하여, 추론 정확도를 측정하였다. 한편, 통신 에러를 가정한 실험은 8개의 학생 네트워크에 서 일어날 수 있는 모든 경우의 수 대해 실험을 진행하였다. 도 7a는 Cifar10 데이터세트를 이용한 NONN 기반의 종래 분산 뉴럴 네트워크의 추론 정확도를 나타낸 그래프이 고, 도 7b는 Cifar10 데이터세트를 이용한 일 실시 예에 따른 분산 뉴럴 네트워크의 추론 정확도를 나타낸 그래 프이다. 도 7a 및 도 7b의 분산 뉴럴 네트워크에 포함된 교사 네트워크는 WRN40-4이다. 도 7a 및 도 7b를 참고하면, Cifar10 데이터세트를 이용할 때 통신 실패한 디바이스의 수가 3개인 경우, 일 실 시 예에 따른 분산 뉴럴 네트워크는 NONN 기반의 종래 분산 뉴럴 네트워크에 비해 평균 추론 정확도가 1.164%, 최저 추론 정확도는 11.22% 개선된 것을 확인할 수 있다. 이러한 개선은 통신 실패한 디바이스의 수가 증가할수 록 더 뚜렷하게 나타난다. 도 7a 및 도 7b에 의하면, 통신 실패한 디바이스의 수가 7개인 경우 일 실시 예에 따 른 분산 뉴럴 네트워크는 NONN 기반의 종래 분산 뉴럴 네트워크에 비해 평균 추론 정확도가 18.741%, 최저 추론 정확도는 54.22% 개선된 것을 확인할 수 있다. 한편, 도 8a는 Cifar100 데이터세트를 이용한 NONN 기반의 분산 뉴럴 네트워크의 추론 정확도를 나타낸 그래프 이고, 도 8b는 Cifar100 데이터세트를 이용한 일 실시 예에 따른 분산 뉴럴 네트워크의 추론 정확도를 나타낸 그래프이다. 도 8a 및 도 8b의 분산 뉴럴 네트워크에 포함된 교사 네트워크는 WRN28-10이다. 도 8a 및 도 8b를 참고하면, Cifar100 데이터세트를 이용할 때 통신 실패한 디바이스의 수가 3개인 경우, 일 실 시 예에 따른 분산 뉴럴 네트워크는 NONN 기반의 종래 분산 뉴럴 네트워크에 비해 평균 추론 정확도가 15.072% 개선된 것을 확인할 수 있다. 또한, 통신 실패한 디바이스의 수가 7개인 경우 일 실시 예에 따른 분산 뉴럴 네 트워크는 NONN 기반의 종래 분산 뉴럴 네트워크에 비해 평균 추론 정확도가 18.742% 개선된 것을 확인할 수 있 다. 도 7a, 도 7b, 도 8a 및 도 8b를 참고하면, 일 실시 예에 따른 분산 뉴럴 네트워크가 Cifar10 데이터세트 및 Cifar100 데이터세트를 이용하는 모든 경우에서 종래 NoNN 기반의 분산 뉴럴 네트워크보다 디바이스의 통신 실 패에 대해 강인한 것을 확인할 수 있다. 도 9는 일 실시 예에 따른 분산 뉴럴 네트워크 제어 장치를 설명하기 위한 블록도이다. 분산 뉴럴 네트워크 제어 장치는 일 실시 예에 따라, 메모리(memory) 및 프로세서(processor) 를 포함할 수 있다. 도 9에 도시된 분산 뉴럴 네트워크 제어 장치는 본 실시 예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 9에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 본"}
{"patent_id": "10-2020-0133486", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "실시 예와 관련된 기술분야에서 통상의 지식을 가진 자라면 이해할 수 있다. 메모리는 분산 뉴럴 네트워크 제어 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 예를 들어, 메모리는 분산 뉴럴 네트워크 제어 장치에서 처리된 데이터들 및 처리될 데이터들을 저장 할 수 있다. 메모리는 프로세서의 동작을 위한 적어도 하나의 명령어(instruction)를 저장할 수 있다. 또한, 메모리는 분산 뉴럴 네트워크 제어 장치에 의해 구동될 프로그램 또는 애플리케이션 등 을 저장할 수 있다. 메모리는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플래시 메모리를 포함할 수 있다. 프로세서는 분산 뉴럴 네트워크 제어 장치의 전반의 동작을 제어하고 데이터 및 신호를 처리할 수 있 다. 프로세서는 메모리에 저장된 적어도 하나의 명령어 또는 적어도 하나의 프로그램을 실행함으로써, 분산 뉴럴 네트워크 제어 장치를 전반적으로 제어할 수 있다. 프로세서는 CPU(central processing unit), GPU(graphics processing unit), AP(application processor) 등으로 구현될 수 있으나, 이 에 제한되지 않는다. 프로세서는 복수의 필터를 포함한 복수의 그룹이 수신되면, 학생 네트워크의 수보다 적은 수의 파트로 복 수의 필터를 분류하고, 하나의 파트를 이용하여 둘 이상의 학생 네트워크를 학습시키기 위해, 둘 이상의 학생 네트워크에 동일한 파트에 관한 정보를 전송하고, 동일한 파트를 통해 학습된 둘 이상의 학생 네트워크의 결과 를 수신하고, 수신된 둘 이상의 학생 네트워크의 결과의 평균값에 기초하여 최종 특징을 생성할 수 있다. 이때, 파트의 수는 학생 네트워크의 수를 2로 나눈 값에 기초하여 결정될 수 있고, 각 파트를 통해 학습되는 학 생 네트워크의 수가 상이할 경우 각 파트에 포함된 필터의 수에 기초하여, 각 파트를 통해 학습되는 학생 네트 워크의 수가 결정될 수 있다. 한편, 프로세서는 학생 네트워크가 탑재될 디바이스의 통신 안정성에 대한 정보에 기초하여, 학생 네트워 크가 탑재될 디바이스를 결정할 수 있다. 이때, 프로세서는 각 학생 네트워크가 통신 실패된 경우 뉴럴 네 트워크 전체 추론 정확도에 관한 정보에 기초하여, 학생 네트워크가 탑재될 디바이스를 결정할 수 있다. 또한, 프로세서는 학생 네트워크를 학습시키는데 이용된 파트에 기초하여, 학생 네트워크가 탑재될 디바이스를 결정할 수 있다. 한편, 프로세서는 복수의 필터를 파트로 분류할 때, 각 파트로 분류된 필터의 수가 균일하도록 분류할 수 있다. 또한, 분산 뉴럴 네트워크는 NONN 기반으로 하는 것일 수 있다. 전술한 실시 예들에 따른 프로세서는 프로세서, 프로그램 데이터를 저장하고 실행하는 메모리, 디스크 드라이브 와 같은 영구 저장부(permanent storage), 외부 장치와 통신하는 통신 포트, 터치 패널, 키(key), 버튼 등과 같 은 사용자 인터페이스 장치 등을 포함할 수 있다. 소프트웨어 모듈 또는 알고리즘으로 구현되는 방법들은 상기 프로세서상에서 실행 가능한 컴퓨터가 읽을 수 있는 코드들 또는 프로그램 명령들로서 컴퓨터가 읽을 수 있는 기록 매체 상에 저장될 수 있다. 여기서 컴퓨터가 읽을 수 있는 기록 매체로 마그네틱 저장 매체(예컨대, ROM(read-only memory), RAM(random-Access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판독 매체(예 컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있는 기록 매체 는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행 될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 본 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들은 특정 기능들을 실행하는 다양한 개수의 하드웨어 또는/및 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 실시 예 는 하나 이상의 마이크로프로세서들의 제어 또는 다른 제어 장치들에 의해서 다양한 기능들을 실행할 수 있는, 메모리, 프로세싱, 로직(logic), 룩 업 테이블(look-up table) 등과 같은 직접 회로 구성들을 채용할 수 있다. 구성 요소들이 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행될 수 있는 것과 유사하게, 본 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조합으로 구현되는 다양한 알고리즘을 포함하 여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기 능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 실시 예는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. “매커니즘”, “ 요소”, “수단”, “구성”과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 상기 용어는 프로세서 등과 연계하여 소프트웨어의 일련의 처리들(routines)의 의미를 포함할 수 있다. 전술한 실시 예들은 일 예시일 뿐 후술하는 청구항들의 범위 내에서 다른 실시 예들이 구현될 수 있다."}
{"patent_id": "10-2020-0133486", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 분산 뉴럴 네트워크 구조의 일례를 설명하기 위한 도면이다. 도 2a, 도 2b 및 도 3은 NONN(Network of Neural Network) 기반 분산 뉴럴 네트워크 구조의 일례를 설명하기 위한 도면이다. 도 4는 일 실시 예에 따른 분산 뉴럴 네트워크 구조를 설명하기 위한 도면이다.도 5는 일 실시 예에 따른 분산 뉴럴 네트워크 제어 방법을 설명하기 위한 흐름도이다. 도 6a 및 도 6b는 다른 일 실시 예에 따른 분산 뉴럴 네트워크 제어 방법을 설명하기 위한 도면이다. 도 7a, 도 7b, 도 8a 및 도 8b는 일 실시 예에 따른 분산 뉴럴 네트워크의 성능을 설명하기 위한 도면이다. 도 9는 일 실시 예에 따른 분산 뉴럴 네트워크 제어 장치를 설명하기 위한 블록도이다."}
