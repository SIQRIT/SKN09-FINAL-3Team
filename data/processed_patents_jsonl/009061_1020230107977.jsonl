{"patent_id": "10-2023-0107977", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0026904", "출원번호": "10-2023-0107977", "발명의 명칭": "확산 확률 모델에서 생성한 잠재 피쳐를 활용한 음성 인식 방법 및 시스템", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "확산 확률 모델을 이용한 음성 인식 방법에 있어서,CTC(connectionist temporal classification) 모델을 이용하여 입력된 음성 신호의 중간피쳐(intermediatefeature)를 추출하는 단계;상기 중간피쳐를 이용하여 상기 확산 확률 모델을 컨디셔닝하는 단계;상기 확산 확률 모델을 통해 잠재피쳐(latent feature)를 생성하는 단계;상기 CTC 모델의 CTC 레이어에 상기 잠재피쳐를 입력하여 상기 음성 신호의 전사(transcription)를 인식하는 단계;를 포함하는확산 확률 모델을 이용한 음성 인식 방법."}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 CTC 모델의 인코더를 통해 추출된 클린 데이터(clean data)를 이용하여 상기 확산 확률 모델을 학습하는단계;를 더 포함하는,확산 확률 모델을 이용한 음성 인식 방법."}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 확산 확률 모델의 학습 단계는,상기 클린 데이터(clean data)에 노이즈를 더하여 가우시안 분포의 노이즈로 만드는 확산(diffusion) 단계;상기 가우시안 분포의 노이즈에서 노이즈를 제거하여 클린 데이터를 만드는 역(reverse)단계;를 포함하는,확산 확률 모델을 이용한 음성 인식 방법."}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 CTC 모델은,하기 식에 따른 손실 함수(loss function)를 가지는 것을 특징으로 하는,확산 확률 모델을 이용한 음성 인식 방법.공개특허 10-2025-0026904-3-λ는 하이퍼파라미터, L 손실함수, l번째 레이어(0<l<L)"}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 중간피쳐(intermediate feature)는,상기 CTC 모델 내의 각각의 인코더 레이어로부터 추출된 복수개의 피쳐이며,상기 클린 데이터(clean data)는,상기 CTC 모델의 마지막 인코터 레이어로부터 추출된 피쳐인 것을 특징으로 하는,확산 확률 모델을 이용한 음성 인식 방법."}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 컨디셔닝 단계는,상기 중간피쳐(intermediate feature)를 이용하여 상기 확산 확률 모델의 t번째 타임 스텝(0=<t=<T)의 피쳐를정제하는 단계;를 포함하며,확산 확률 모델을 이용한 음성 인식 방법."}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,장기 정제단계는,하기의 수식을 따르는 것을 특징으로 하는, 확산 확률 모델을 이용한 음성 인식 방법.η하이퍼파라미터, Hl l번째 레이어(0<l<L), ht-1 추정한 노이즈를 제거한 후의 이전 타임 스텝에서의 데이터, t 스텝에서 확산 확률 모델에 의해 생성된 데이터"}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "CTC 레이어와 복수개의 인코더 레이터를 포함하는 인코더로 구성되며, 중간피쳐 및 클린 데이터를 생성하는 CTC모델;상기 인코더로부터 출력된 클린 데이터를 이용하여 학습하고, 상기 중간피쳐를 이용하여 컨디셔닝하는 확산 확률 모델;을 포함하며,상기 CTC 모델은,상기 확산 확률 모델을 통해 출력된 잠재피쳐를 상기 CTC 레이어에 입력하여 전사(transcription)를 인식하는것을 특징으로 하는, 공개특허 10-2025-0026904-4-음성 인식 시스템."}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 확산 확률 모델은,상기 클린 데이터(clean data)에 노이즈를 더하여 가우시안 분포의 노이즈로 만드는 확산(diffusion) 단계 및상기 가우시안 분포의 노이즈에서 노이즈를 제거하여 클린 데이터를 만드는 역(reverse)단계를 통해 학습하는,음성 인식 시스템."}
{"patent_id": "10-2023-0107977", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터를 이용하여 제1 항 내지 제7 항 방법 중 어느 하나의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 음성 인식 시스템은 CTC 모델에서 추출된 노이즈가 제거된 클린 데이터(clean dat a)를 이용하여 확산 확률 모델을 학습시키고, CTC 모델 내의 인코딩 레이어에서 추출된 중간피쳐를 이용하여 확 산 확률 모델을 컨디셔닝하며, 최종적으로 확산 확률 모델을 이용하여 정제된 잠재피쳐(latent feature)를 생성 하고, 이를 CTC 레이어에 입력하여 더 정확한 전사(transcription)를 인식하기 위한 시스템이다. 본 발명의 일 실시예에 따른 음성 인식 시스템은 확산 확률 모델로부터 생성된 잠재피쳐를 이용하여 보다 강인한 (robust)한 피쳐를 생성할 수 있도록 하며, 본 발명의 일 실시예에 따라 획득된 전사 신호는 음성 인식도의 정확 도 및 견고성이 향상되는 특징을 보인다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 확산 확률 모델을 이용한 음성 인식 방법 및 시스템에 관한 것으로서, 더욱 상세하게는 확산 확률 모 델과 CTC 모델을 이용하여 정제된 피쳐를 생성하고, 이를 CTC 모델에 입력하여 음성 인식 시스템의 성능을 확인 하기 위한 음성 인식 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 정보 통신 기술 중 음성을 인식하는 음성 인식기술에 대한 발전이 두드러지고 있다. 특히 화자의 음성을 정확하게 인식하기 위해서 화자의 음성과 주변의 노이즈를 구별하고, 노이즈를 제거하는 기술에 대한 연구가 활발히 이루어지고 있다. 최근 E2E(End-to-End) 방식의 음성 인식 기술이 빠르게 발전하고 있다. E2E 방식이란 하나의 모듈로 음향 모델, 언어 모델, 발음 사전 등 음성 인식의 전체 과정을 처리하는 기술을 의미한다. 기존 방법과 달리, 이러한 E2E 방식의 경우 각 구성간의 상호 보완적인 기능을 기대할 수 있다는 장점이 있다. 이러한 E2E 방식의 하나인 CTC(connectionist temporal classification) 모델은 입력 음성 프레임 시퀀스와 타 겟 단어/음소 시퀀스 간에 명시적인 얼라인먼트(alignment) 정보 없이도 음성 인식 모델을 학습할 수 있는 기법 이다. CTC 기반 ASR(automatic speech recognition) 모델은 주요한 엔드 투 엔드(end to end) ASR 유형으로, 입력과 출력 사이에 명시적인 강제 정렬 없이 길이 T의 입력 시퀀스로부터 목표 시퀀스를 예측하도록 설계된 모 델이다. 다만, 음성 인식의 정확도 향상을 위해 CTC 모델의 노이즈 제거 효율을 향상시키기 위한 연구가 활발하게 진행 되고 있다. 종래 국내특허 10-2344218호에서는 트랜스듀서(transducer) 기반의 종단간(end-to-end) 음성 인식 시스템에 CTC 모델 및 언어 모델을 결합하여, 음성 인식의 성능을 향상시키기 위한 모델을 개발하였다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 설명한 문제점을 해결하기 위해 고안된 발명으로서, 음성 인식의 정확도 향상을 위해 CTC 모델 과 확산 확률 모델을 결합하여 음성 내의 노이즈를 제거함으로써 음성 인식의 정확도를 향상시킬 수 있는 음성 인식 방법 및 시스템을 제공한다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 확산 확률 모델을 이용한 음성 인식 방법은 CTC(connectionist temporal classification) 모델을 이용하여 입력된 음성 신호의 중간피쳐(intermediate feature)를 추출하는 단계, 중간 피쳐를 이용하여 확산 확률 모델을 컨디셔닝하는 단계, 확산 확률 모델을 통해 잠재피쳐(latent feature)를 생 성하는 단계, CTC 모델의 CTC 레이어에 잠재피쳐를 입력하여 음성 신호의 전사(transcription)를 인식하는 단계 를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에서는 노이즈 확산 확률 모델(Denoising diffusion probabilistic model, 이하, 확산 확률 모델)을 이 용하여 잠재 피쳐를 정제함으로써 강인한 자동 음성 인식(Automatic speech recognition, ASR) 시스템을 구현하 였으며, 기존의 ASR 특성을 사용하여 확산 확률 모델로부터 더 견고한 ASR 특성을 생성하도록 하였으며, 확산 확률 모델을 ASR 파이프라인에 통합함으로써 음성 인식의 정확성과 견고성이 향상된 음성 인식 시스템을 제공한 다. 본 발명의 일 실시예에 따른 음성 인식 방법은 확산 확률 모델로부터 생성된 잠재피쳐를 이용하여 보다 강인한 (robust)한 피쳐를 생성할 수 있도록 하며, 이에 따라 노이즈가 제거된 음성 신호는 음성 인식도의 정확도 및 견고성이 향상되는 특징을 보인다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 명세서의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 명세서의 일 실시예에 따른 AI 장치의 블록도이다. AI 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 상기 AI 모듈을 포함하는 서 버 등을 포함할 수 있다. 또한, AI 장치는 전자기기의 적어도 일부의 구성으로 포함되어 AI 프로세싱 중 적 어도 일부를 함께 수행하도록 구비될 수도 있다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함할 수 있다. AI 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, AI 프로세서(2 1)는 주식 종목의 할당 비중인 액션 예측 정보를 추정하기 위한 인공지능 모델을 생성할 수 있고, 수집된 주식 가격 데이터 및 기술적 지표 데이터를 이용하여, 이러한 인공지능 모델을 강화학습시킬 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 AI 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공 지능 학습을 위한 AI 전용 프로세서(예를 들어, GPU, graphics processing unit)일 수 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발 성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드 라이브(SDD) 등으로 구현할 수 있다. 메모리는 AI 프로세서에 의해 액세스되며, AI 프로세서에 의 한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 본 명세서의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경 망 모델(예를 들어, 딥 러닝 모델)을 저장할 수 있다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 예를 들어, 데이터 학습부는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습데이터를 딥러닝 모델에 적용함으로 써, 딥러닝 모델을 학습할 수 있다. 통신부는 AI 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 여기서 외부 전자 기기는 다른 단말, 서버를 포함할 수 있다. 한편, 도 1에 도시된 AI 장치는 AI 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설 명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈 또는 인공지능(AI) 모델로 호칭될 수도 있다. 이하에서는 도 2 내지 도 4를 참고하여, 본 발명의 확산 확률 모델을 이용한 음성 인식 방법 및 음성 인식 시스 템에 관하여 설명한다. 도 2는 본 명세서의 일 실시예에 따른 음성 인식 시스템의 구성도이다. 본 발명의 일 실시예에 따른 음성 인식 시스템은 CTC 모델에서 추출된 노이즈가 제거된 클린 데이터(clean data)를 이용하여 확산 확률 모델을 학습시키고, CTC 모델 내의 인코딩 레이어에서 추출된 중간피쳐를 이용하여 확산 확률 모델을 컨디셔닝하며, 최종적으로 확산 확률 모델을 이용하여 정제된 잠재피쳐(latent feature)를 생 성하고, 이를 CTC 레이어에 입력하여 음성 신호의 전사(transcription)를 인식하기 위한 시스템이다. 본 발명의 일 실시예에 따른 음성 인식 시스템은 확산 확률 모델로부터 생성된 잠재피쳐를 이용하여 보다 강인한(robust) 한 피쳐를 생성할 수 있도록 하며, 본 발명의 일 실시예에 따라 인식된 음성 신호는 음성 인식도의 정확도 및 견고성이 향상되는 특징을 보인다. 본 발명에 따른 클린 데이터(clean data)란, CTC 모델 내의 인코터 또는 마지막 인코더 레이어에서 출력되는 데 이터로, 클린 표현(clean representation)을 의미한다. 본 발명은 CTC 모델에서 출력된 클린 데이터를 이용하여 확산 확률 모델을 학습시킴으로써 두 모델이 더욱 효율적으로 병합되도록 설계되었다. 중간피쳐란, CTC 모델의 인코더 레이더에서 추출되는 피쳐를 의미한다. 본 발명은 각 인코더 레이어의 출력을 ASR 출력으로 매핑하는 중간 손실을 강화함으로써 중간피쳐는 유사한 특성을 획득하게 되어 ASR 출력을 향해 수 렴하게 됩니다. 따라서 중간피쳐는 컨디셔닝 피쳐로서의 역할을 제공하게 되며, 이를 통해 확산 확률 모델은 점 차 ASR 출력과 더 유사한 정제된 특성을 생성할 수 있게 된다. 잠재피쳐란, 컨디셔닝된 확산 확률 모델을 통해 생성된 피쳐로, 본 발명은 이를 CTC레이어에 적용함으로써 보다 우수한 성능을 가지는 음성 인식 시스템을 제공한다. 본 발명에서는 노이즈 확산 확률 모델(Denoising diffusion probabilistic model, 이하, 확산 확률 모델)을 이 용하여 잠재피쳐를 정제함으로써 강인한 자동 음성 인식(Automatic speech recognition, ASR) 시스템을 구현하 였으며, 기존의 ASR 특성을 사용하여 확산 확률 모델로부터 더 견고한 ASR 특성을 생성하도록 하였다. 즉, 본 발명에서는 CTC(Connectionist temporal classification)모델의 마지막 인코더 레이어에서 클린 데이터(clean data)를 추출하고 이를 이용하여 확산 확률 모델을 훈련시킨다. 또한, 확산 확률 모델은 컨포머 기반 (conformer-based) CTC 인코더 레이어에서 생성된 중간피쳐를 조건부 특성으로 채택하여 컨디셔닝함으로써 정제 된 잠재피쳐를 생성하였다. 즉, 본 발명은 확산 확률 모델을 ASR 파이프라인에 통합함으로써 음성 인식의 정확 성과 견고성이 향상된 음성 인식 시스템을 제공한다. 본 발명의 일 실시예에 따른 음성 인식 시스템은 CTC모델 및 확산 확률 모델을 포함할 수 있다. CTC(connectionist temporal classification) 모델이란, 입력 음성 프레임 시퀀스와 타겟 단어/음소 시퀀스 간 에 명시적인 얼라인먼트(alignment) 정보 없이도 음성 인식 모델을 학습할 수 있는 기법이다. CTC 기반 ASR(automatic speech recognition) 모델은 주요한 엔드 투 엔드(end to end) ASR 유형으로, 입력과 출력 사이 에 명시적인 강제 정렬 없이 길이 T의 입력 시퀀스로부터 목표 시퀀스를 예측하도록 설계되었다. 본 발명의 CTC 모델은 CTC 레이어와 복수개의 인코더 레이터를 포함하는 인코더로 구성되며, 중간피쳐 및 클린 데이터를 생성 한다. 즉, CTC모델은 L개의 인코더 레이어의 출력이 있으며, 출력은 하기 식에 따른다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "X는 입력 시퀀스를, H0는 입력 레이어를 통과한 음성 인식 피쳐이다. 이는 인코더에 입력으로 사용되며 L개의 인 코더 레이어로 구성된 인코더는 Hl-1의 중간 피쳐를 입력으로 받아 Hl의 중간 피쳐를 출력한다. 여기서 X와 Hl은 각각 입력 레이어에 의해 임베딩된 입력 시퀀스를 나타내는 H0와 l번째 인코더 레이어의 출력 이다. CTC 손실 함수는 입력 시퀀스 X에서 출력 시퀀스 Y로의 모든 가능한 정렬 경로에 대한 음의 로그 가능성 (negative log-likelihood)으로 정의되며, B(Y, X)로 표기된다. 손실함수의 수식은 과 같다"}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "는 길이 T인 프레임에 대한 예측 레이블 시퀀스를 나타낸다. 본 발명에서는 CTC 모델 학습의 규제화와 성능 향상을 위해 중간 CTC(InterCTC)가 도입되었으며, InterCTC는 중 간 인코더의 출력 시퀀스에 보조 손실을 적용함으로써 도입되었다. 따라서 컨포머 기반(confermer-based) CTC 인코더는 기존 CTC 손실에 추가로 여러 개의 중간 CTC 손실을 가지고 훈련된다. 각 l번째 레이어에서의 InterCTC 손실은 다음과 같이 식에 따라 계산된다. 기존 CTC 모델의 학습을 더 안정화 시키고 성능을 향상시 키기 위해 인코더 각 레이어의 중간피쳐와 타겟 시퀀스 간에 auxiliary loss가 도입되었으며, 수식은 와 같 다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "따라서 수식의 손실로만 학습되던 기존 CTC 모델과 달리 본 발명인 InterCTC 모델의 최종 손실함수 수식 과 같이 정의된다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "λ는 0 내지 1 사이의 값으로 설정된 하이퍼파라미터이다. 본 발명에서는 모든 인코더 레이어에 중간 CTC loss를 적용하여 각 중간 피쳐들이 모두 유사한 특성을 지니도록 모델을 학습하였다. 모든 레이어에 auxiliary loss를 도입함으로써 각 레이어의 중간 피쳐가 최종 타겟 시퀀스 Y에 매핑되도록 학습이 되면 모든 중간 피쳐들이 유사한 특성을 지닐 수 있기 때문이다. 본 발명에 따른 모델링 접근 방식에서는 모든 레이어의 중간 CTC 손실을 채택하여 각 출력 Hl 간에 유사한 연관 성을 도출한다. 각 인코더 레이어의 출력을 ASR 출력으로 매핑하는 중간 손실을 강화함으로써 중간피쳐는 유사 한 특성을 획득하게 되어 ASR 출력을 향해 수렴하게 된다. 따라서 중간피쳐는 컨디셔닝 피쳐로서의 역할을 제공 하게 되며, 이를 통해 확산 확률 모델은 점차 ASR 출력과 더 유사한 잠재피쳐를 생성할 수 있다. 따라서 중간 손실을 통해 중간피쳐 간 유사한 특성을 유도하는 것이 견고한 ASR 시스템을 구현하는 접근 방식에서 중요하다. 본 발명의 CTC 모델은 확산 확률 모델을 통해 출력된 잠재피쳐를 CTC 레이어에 입력하여 음성 신호의 전사 (transcription)를 인식한다. 확산 확률 모델은 마르코프 체인(Markov chain) 샘플링을 채택하여 노이즈 분포로부터 데이터 분포를 생성하는 고급 생성 모델이다. 확산 확률 모델은 도 2(b)에 나와 있는 것처럼 확산(diffusion)과 역방향(reverse process) 두 가지 프로세스로 구성된다. 확산 과정은 깨끗한 입력 데이터를 점진적으로 가우시안 노이즈로 변환 시키는 과정이며, 역방향 과정은 확산 과정의 각 단계에서 들어오는 노이즈를 추정하고 제거하여 깨끗한 입력 데이터를 복원하는 과정이다. 본 발명의 확산 확률 모델은 CTC 모델의 인코더로부터 출력된 클린 데이터를 이용 하여 학습하고, CTC 모델의 중간피쳐를 이용하여 컨디셔닝한다. 확산 과정에서 CTC 인코더의 마지막 레이어 출력값은 ASR 특성 생성을 위해 클린 데이터(clean data)로 채택된 다. 즉, InterCTC ASR의 마지막 레이어의 출력값인 HL이 확산 과정에서 클린 데이터(clean data) h0이 되며, 확 산 과정은 확산 타임 스텝 단계 t∈ {0, 1, ..., T}에 따라 점진적으로 가우시안 노이즈를 추가하여 잠재 변수 ht, ..., hT ∈ RDХF를 얻게 된다. 여기서 D와 F는 각각 잠재 특성의 차원과 프레임 길이를 나타낸다. t번째 확 산 단계에서 입력 데이터와 동일한 차원을 갖는 변수 ht ∈ RDХF를 얻는다. h0부터 변수 ht까지의 전체 확산 과정 은 마르코브 과정(Markov process)에 기반하여 정의되며, 이는 마르코브 전이 확률(Markov transition probability)의 곱셈으로 표현된다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "h0는 실제 데이터이며 ht는 노이즈가 점차 더해진 t 번째 스텝에서의 데이터를 나타낸다. 노이즈가 더해진 피쳐 는 가우시안 분포를 따르면 평균과 분산은 과 같이 결정된다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "마르코브 전이 확률은 각각 q(ht|ht-1) =N(ht;√1 βtht1, βtI)로 정의된다. 여기서 미리 정의된 노이즈 분산 스케줄 β1, ...βT이 채택된다. 본 발명의 모델링 접근 방식에서 βt의 스케줄은 코사인 곡선을 따라가며, 0에 서 시작하여 주기적으로 0.999까지 증가한다. 이 주기적인 증가 패턴은 코사인 함수에 의해 결정되며, 훈련 과 정에서 시간 단계에 따라 βt의 값을 점진적으로 변화시킨다. 따라서 가우시안 분포의 특성을 기반으로 h0에 대 한 hT의 샘플링 분포를 정의할 수 있다. 평균과 분산에 활용되는 βt의 값은 하이퍼파라메터 값이며 타임스텝에 따라 점차 증가하는 형태를 지닌다. 본 발명에서는 코사인 함수에 의해 해당 값이 설정되도록 정하였다. 입력 데이터 h0가 완전한 가우시안 분포 형태인 hT가 될 때 까지 해당 과정을 반복하게 된다. 역(Reverse) 단계는 노이즈분포 (hT)로부터 추정한 노이즈를 제거하여 데이터 h0로 복원하는 과정이다. 추정한 노이즈를 제거하여 이전 형태의 데이터로 복원하는 과정은 과 같다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "역방향 과정에서는 클린 데이터(clean data)가 역방향 확산 과정을 통해 복원된다. 이 과정은 시간 단계 t를 기 반으로 가우시안 노이즈에서 초기 표현 h0을 반복적으로 복구하려고 시도하며, 역방향 과정은 다음과 같이 표현 되며, 이는 마르코브 전이 확률의 곱으로 표현될 수 있다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "조건부 확률 밀도 함수 pθ(ht1|ht)를 계산하기 위해 평균과 분산을 가진 정규 분포가 정의된다. 평균 μθ(ht, t)는 다음과 같이 주어진다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "또한, 분산 σ2는 다음과 같다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "잠재 변수 ht-1은 분포 p(ht-1|ht) 에서 모델 추정 잡음 및 z ∼ N(0, I) N(0, I)에 의해 샘플링 된다.구 체적으로 ht-1은 수식 에 의해 계산된다. ht 는 현재 타임 스텝 t 에서의 데이터를, ht-1은 추정한 잡음 를 제거한 후의 이전 타임 스텝에서의 데이터 를 나타낸다. 본 발명에서는 음성 인식을 위한 잠재 피쳐를 생성해 내기 위해 음성 인식의 잠재 피쳐 HL을 이용 하여 디퓨전 모델을 학습하였다. 확산 확률 모델을 훈련시키기 위해 음의 로그 가능성의 변동 경계를 최소화하는 것이 훈련 목표이다. 이 경계는 모델이 생성한 샘플과 실제 데이터 분포 사이의 차이를 측정하며, 순방향과 역방향 과정 사이의 KL 다이버전스 로 정의된다. 이 손실은 간단한 형태로 재매개화되고 더 높은 생성 품질을 도와준다. 훈련 목표는 다음과 같이 표현된다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "여기서 θ와 는 각각 모델 매개변수와 확산된 가우시안 노이즈를 나타낸다. 본 발명에 따른 방법은 확산 확률 모델을 활용하여 원래의 ASR 특성을 개선하고 견고성을 향상시킨다. 본 발명 에 따른 모델은 훈련 단계와 추론 단계의 두 가지 단계로 구성된다. 훈련 단계에서는, 깨끗한 데이터에서만 훈 련된 InterCTC 모델에서 추출한 깨끗한 표현을 사용하여 확산 확률 모델을 훈련한다. 그런 다음, 사전 훈련된 확산 확률 모델을 사용하여 잠재적인 특성을 생성하고 원래의 ASR 특성을 대체한다. 추론 단계에서는 중간 InterCTC 인코더 레이어의 출력을 활용하여 조건부 특성으로 사용하여 비조건적 특성 생성기 DDPM을 향상시킨다. 개선된 특성은 그림 2(c)에 나와 있는 것처럼 원래의 ASR 특성 대신에 InterCTC 모델에 의해 디코 딩된다. 본 발명은 추론 단계에서 ASR 파이프라인에 도입되기 때문에 훈련 단계에서 ASR 모델을 추가로 훈련할 필요가 없다. 조건부 특성은 InterCTC 인코더 레이어의 출력으로 결정되며, 확산 시간 단계에 따라 사용된다. 이 조건부 특성 은 그림 2(c)에 나와 있는 것처럼 첫 번째 인코더 레이어 출력부터 마지막 인코더 레이어 출력까지의 T/L 간격 으로 활용된다. 잠재적인 특성은 이후 인코더 레이어 출력을 순차적으로 따라가도록 설계되며, 확산 확률 모델 에게 궤적을 제공하여 더 정제된 ASR 특성을 생성한다. 여기서 T는 확산 확률 모델의 전체 시간 단계를 나타내 며, L은 조건부 특성의 개수로서 InterCTC 모델의 인코더 레이어 수와 동일하며, 개선 절차는 도 3의 알고리즘 에 종합적으로 제시되었다. 도 3은 디퓨전 모델로부터 음성 인식 잠재 피쳐를 생성하는 과정을 나타내는 알고리즘이다. ASR 파이프라인에 확산 확률 모델을 적용하여 잠재적인 특성을 개선하는 경우, 하이퍼파라미터 η는 원래의 ASR 특성과 조건화되어야 한다. 개선 강도 매개변수인 η는 원래 특성과 개선된 특성 사이의 균형을 조절한다. 확산 확률 모델은 입력 데이터의 분포를 명시적으로 모델링할 수 있으므로 변동성과 복잡성을 효과적으로 포착할 수 있다. 확산 확률 모델을 채택함으로써 ASR 개선기는 더 견고한 특성을 생성하고 ASR 시스템의 정확성과 견고성 을 향상시킬 수 있으며, ASR 성능을 향상시키는 유망한 기회를 제공한다. 본 발명에 따라 생성된 ASR 특성은 종래기술 ASR 특성 대비 개선된 ASR 성능을 보였으며, 이는 본 발명에 따라 생성된 ASR이 확률적 확산 기반 메서드로 모델링하는 것이 데이터 분포의 변동성과 복잡성을 더 잘 표현하기 때 문인 것으로 판단된다. 본 발명에 따른 음성 인식 방법은 깨끗한 데이터셋에서 성능이 개선되었다는 점으로부터 원래 특성에 대한 개선 효과를 갖고 있으며, 또한 노이즈 보상 효과를 갖고 있으며 다른 데이터셋의 성능도 향 상되었다. 이러한 결과는 본 발명에 따른 방법이 더 정확한 전사를 생성하여 ASR 시스템의 견고성을 크게 향상시킨다는 것 을 의미한다. 확산 확률 모델이 노이즈를 노이즈 분포로부터 제거하도록 설계되었기 때문에 잠재 특성의 견고성 이 향상되었다. 각 CTC 인코더 레이어의 출력으로 확산 프로세스를 조정함으로써 모델은 원래의 ASR 특성보다 더 개선된 특성을 생성할 수 있습니다. 확산 확률 모델이 아직 ASR 분야에서 사용되지 않은 것을 고려하면, 확 산 확률 모델은 ASR 특성의 잠재 특성을 생성하고 개선함으로써 ASR 성능을 향상시키는 데 유용할 것으로 보이 며, 본 방법은 다양한 작업에 적용될 수 있을 것으로 보인다. 이하, 본 발명의 또 다른 실시예인 확산 확률 모델을 이용한 음성 인식 방법에 대해 설명한다. 도 4를 참고하면, 본 발명의 일 실시예에 따른 확산 확률 모델을 이용한 음성 인식 방법은 음성 신호의 중간피 쳐(intermediate feature)를 추출하는 단계(S1000), 확산 확률 모델을 컨디셔닝하는 단계(S2000), 잠재피쳐 (latent feature)를 생성하는 단계(S3000), 노이즈가 제거된 음성 신호를 획득하는 단계(S4000)를 포함할 수 있 다. 중간피쳐(intermediate feature)를 추출하는 단계는 CTC(connectionist temporal classification) 모델을 이용 하여 입력된 음성 신호의 중간피쳐(intermediate feature)를 추출하는 단계를 의미한다. 즉, CTC 모델의 인코더 레이어에서 중간피쳐를 추출할 수 있다. 중간피쳐는 인코더 레이어의 수만큼 추출될 수 있다. 본 발명에 따른 시스템은 추출한 중간피쳐를 이용하여 확산 확률 모델을 컨디셔닝할 수 있다. 이를 통해 확산 확률 모델이 ASR 출력과 더 유사한 잠재피쳐를 생성할 수 있도록 한다. 필요에 따라, 컨디셔닝단계는 중간피쳐(intermediate feature)를 이용하여 확산 확률 모델의 t번째 타임 스텝 (0=<t=<T)의 피쳐를 정제하는 단계를 포함할 수 있다. 이 때, 정제단계는, 하기의 수식을 따르는 것을 특징으로 한다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "해당 수식에서 η하이퍼파라미터, Hl l번째 레이어(0<l<L), ht-1 추정한 노이즈를 제거한 후의 이전 타임 스텝에 서의 데이터, t 스텝에서 확산 확률 모델에 의해 생성된 데이터를 의미한다. 필요에 따라, 본 발명에 따른 음성 인식 방법은 CTC 모델의 인코더를 통해 추출된 클린 데이터(clean data)를 이용하여 확산 확률 모델을 학습하는 단계를 더 포함할 수 있다. 보다 구체적으로, 확산 확률 모델을 학습하는 단계는 클린 데이터(clean data)에 노이즈를 더하여 가우시안 분 포의 노이즈로 만드는 확산(diffusion) 단계, 가우시안 분포의 노이즈에서 노이즈를 제거하여 클린 데이터를 만 드는 역(reverse)단계를 포함할 수 있다. 데이터를 복원하는 과정인 역단계(T-> ... t ->t-1 -> ... -> 1)는 확산단계(1->... t-1->t -> ... T)와 달리 T 스텝부터 1 스텝까지 과정이 진행된다.. 즉, t 스텝에서 t-1스텝으로 데이터를 복원 하게 된다. t-1는 t 스텝 에서 디퓨전 모델에 의해 생성된 데이터를 나타낸다. 디퓨전 모델에 의해 생성된 데이터와 기존 음성 인식 잠재 피쳐 Hl이 linear interpolation 되는 과정이 반복된다. 는 하이퍼파라메터이다. z는 가우시안 노이즈이고 σt 는 디퓨전 모델에서의 표준편차를 나타낸다. 확산 확률 모델을 통해 잠재피쳐(latent feature)를 생성하는 단계는 학습 및 컨디셔닝 된 확산 확률 모델을 통 해 잠재 피쳐를 생성하는 단계를 의미한다. CTC 모델의 CTC 레이어에 잠재피쳐를 입력하여 노이즈가 제거된 음성 신호의 전사(transcription)를 인식하는 단계를 포함한다. 필요에 따라, CTC모델은 하기 식에 따른 손실 함수(loss function)를 가질 수 있다. CTC 모델은 하기 손실 함수 를 통해 학습할 수 있다."}
{"patent_id": "10-2023-0107977", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "본 발명의 또 다른 실시예는 본 발명의 음성 인식 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체일 수 있다. 이상에서 실시 형태들에 설명된 특징, 구조, 효과 등은 본 발명의 적어도 하나의 실시 형태에 포함되며, 반드시 하나의 실시 형태에만 한정되는 것은 아니다. 나아가, 각 실시 형태에서 예시된 특징, 구조, 효과 등은 실시 형 태들이 속하는 분야의 통상의 지식을 가지는 자에 의해 다른 실시 형태들에 대해서도 조합 또는 변형되어 실시 가능하다. 따라서 이러한 조합과 변형에 관계된 내용들은 본 발명의 범위에 포함되는 것으로 해석되어야 할 것 이다. 또한, 이상에서 실시 형태를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니 며, 본 발명이 속하는 분야의 통상의 지식을 가진 자라면 본 실시 형태의 본질적인 특성을 벗어나지 않는 범위 에서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 즉, 실시 형태에 구체적으 로 나타난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2023-0107977", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 AI 장치의 블록도이다. 도 2(a)는 InterCTC기반의 음성 인식 시스템의 구조이며, 도2(b)는 디퓨전 모델의 도면이며, 도 2(c)는 본 발명 의 일 실시예에 따른 음성 인식 시스템을 보여주는 도면이다. 도 3은 디퓨전 모델로부터 음성 인식 잠재 피쳐를 생성하는 과정을 나타내는 알고리즘이다. 도 4는 본 발명의 일 실시예에 따른 음성 인식 방법의 순서도이다."}
