{"patent_id": "10-2020-0143003", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0058745", "출원번호": "10-2020-0143003", "발명의 명칭": "대용어를 포함하는 텍스트에 관한 보이스 어시스턴트 서비스를 제공하는 시스템 및 방법", "출원인": "삼성전자주식회사", "발명자": "이연호"}}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법에 있어서,사용자의 제1 입력으로부터 생성된 제1 텍스트를 획득하는 동작;제1 NLU 모델을 이용하여, 상기 제1 텍스트 내의 타겟 단어를 검출하고 상기 검출된 타겟 단어에 관한 공통 정보를 생성하는 동작;상기 사용자의 제2 입력으로부터 생성된 제2 텍스트를 획득하는 동작;상기 공통 정보 및 상기 제2 텍스트를 제2 NLU 모델에 입력하는 동작;상기 제2 NLU 모델을 이용하여, 상기 제2 텍스트에 포함된 대용어를 검출하고 상기 검출된 대용어에 대응되는공통 정보에 기초하여 인텐트 및 파라미터를 출력하는 동작; 및상기 인텐트 및 파라미터에 관련된 응답 정보를 생성하는 동작;을 포함하는, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 제1 NLU 모델을 이용하여 상기 제1 텍스트에 대응되는 도메인을 식별하는 동작; 및상기 공통 정보를 상기 도메인에 매칭하여 저장하는 동작;을 더 포함하며,상기 공통 정보 및 상기 제2 텍스트를 제2 NLU 모델에 입력하는 동작은, 상기 도메인에 매칭하여 저장된 공통정보 및 상기 제2 텍스트를 상기 제2 NLU 모델에 입력하는 것인, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 제1 NLU 모델을 이용하여 상기 제2 텍스트의 도메인을 식별하는 동작;을 더 포함하며,상기 공통 정보 및 상기 제2 텍스트를 제2 NLU 모델에 입력하는 동작은, 상기 제2 텍스트의 도메인에 연관된 공통 정보 및 상기 제2 텍스트를 상기 제2 NLU 모델에 입력하는 것인, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 제1 NLU 모델은 공통 정보의 종류가 태깅된 텍스트 및 텍스트의 도메인을 학습 데이터로 사용하여 훈련된인공지능 모델인 것인, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0058745-3-제1 항에 있어서,상기 제1 NLU 모델을 이용하여 상기 제2 텍스트의 도메인을 식별하는 동작; 및복수의 제2 NLU 모델들 중에서, 상기 식별된 제2 텍스트의 도메인에 대응되는 상기 제2 NLU 모델을 선택하는 동작;을 더 포함하는, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 타겟 단어는, 대용어의 지시 대상이 될 수 있는 단어로서, 위치, 날짜, 시간, 또는 사람 중 적어도 하나를나타내는 단어를 포함하며,상기 공통 정보는, 상기 타겟 단어를 나타내는 상세 데이터를 포함하며,상기 상세 데이터는 상기 복수의 제2 NLU 모델에 대응되는 복수의 보이스 어시스턴트 모듈에서 공통으로 식별될수 있는 포맷을 가지는 것인, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3 항에 있어서,상기 제2 텍스트에 연관된 공통 정보를 상기 식별된 상기 제2 텍스트의 도메인에 대응되는 보이스 어시스턴트모듈이 이용할 수 있는 포맷으로 변환하는 동작;을 더 포함하며,상기 제2 텍스트를 해석하는 동작은, 상기 포맷이 변환된 공통 정보를 이용하여, 상기 제2 텍스트를 해석하는것인, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 제2 텍스트가 획득되기 이전에 획득된 텍스트들에 포함된 타겟 단어들에 관한 공통 정보들이 누적되어 저장되는 것인, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 제2 NLU 모델을 이용하여, 상기 제1 텍스트 내의 상기 타겟 단어를 검출하는 동작;상기 타겟 단어에 대응되는 상기 공통 정보를 수정하는 동작;을 더 포함하는, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,상기 제1 NLU 모델을 이용하여, 상기 제2 텍스트 내의 타겟 단어를 검출하는 동작;상기 제1 텍스트 내의 타겟 단어에 대응되는 공통 정보를 상기 제2 텍스트 내의 타겟 단어에 대응되는 공통 정공개특허 10-2022-0058745-4-보로 대체하는 동작;을 더 포함하는, 방법."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "보이스 어시스턴트 서비스를 제공하는 전자 장치에 있어서,다른 전자 장치와 통신하는 통신 인터페이스;하나 이상의 명령어를 저장하는 저장부;상기 저장된 하나 이상의 명령어를 실행하여, 상기 디바이스에 입력된 사용자의 제1 입력으로부터 생성된 제1텍스트를 획득하고, 제1 NLU 모델을 이용하여, 상기 제1 텍스트 내의 타겟 단어를 검출하고 상기 타겟 단어에관한 공통 정보를 생성하고, 상기 사용자의 제2 입력으로부터 생성된 제2 텍스트를 획득하고, 상기 공통 정보및 상기 제2 텍스트를 제2 NLU 모델에 입력하고, 상기 제2 NLU 모델을 이용하여, 상기 제2 텍스트에 포함된 대용어를 검출하고 상기 검출된 대용어에 대응되는 공통 정보에 기초하여 인텐트 및 파라미터를 획득하고, , 상기인텐트 및 파라미터에 관련된 응답 정보를 생성하는, 프로세서;를 포함하는, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 프로세서는, 상기 저장된 하나 이상의 명령어를 실행함으로써, 상기 제1 NLU 모델을 이용하여 상기 제1 텍스트에 대응되는 도메인을 식별하고, 상기 공통 정보를 상기 도메인에 매칭하여 저장하며,상기 프로세서는 상기 도메인에 매칭하여 저장된 공통 정보 및 상기 제2 텍스트를 상기 제2 NLU 모델에 입력하는 것인, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 프로세서는, 상기 저장된 하나 이상의 명령어를 실행하여, 상기 제1 NLU 모델을 이용하여 상기 제2 텍스트의 도메인을 식별하며, 상기 제2 텍스트의 도메인에 연관된 공통 정보 및 상기 제2 텍스트를 상기 제2 NLU 모델에 입력하는 것인, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12 항에 있어서,상기 제1 NLU 모델은 공통 정보의 종류가 태깅된 텍스트 및 텍스트의 도메인을 학습 데이터로 사용하여 훈련된인공지능 모델인 것인, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 프로세서는, 상기 저장된 하나 이상의 명령어를 실행하여, 상기 제1 NLU 모델을 이용하여 상기 제2 텍스트의 도메인을 식별하고, 복수의 제2 NLU 모델들 중에서, 상기 식별된 제2 텍스트의 도메인에 대응되는 상기 제2NLU 모델을 선택하는 것인, 서버.공개특허 10-2022-0058745-5-청구항 16 제11 항에 있어서,상기 타겟 단어는, 대용어의 지시 대상이 될 수 있는 단어로서, 위치, 날짜, 시간, 또는 사람 중 적어도 하나를나타내는 단어를 포함하며,상기 공통 정보는, 상기 타겟 단어를 나타내는 상세 데이터를 포함하며,상기 상세 데이터는 상기 복수의 제2 NLU 모델에 대응되는 복수의 보이스 어시스턴트 모듈에서 공통으로 식별될수 있는 포맷을 가지는 것인, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13 항에 있어서,상기 프로세서는, 상기 저장된 하나 이상의 명령어를 실행하여, 상기 제2 텍스트에 연관된 공통 정보를 상기 식별된 상기 제2 텍스트의 도메인에 대응되는 보이스 어시스턴트 모듈이 이용할 수 있는 포맷으로 변환하고, 상기포맷이 변환된 공통 정보를 이용하여, 상기 제2 텍스트를 해석하는 것인, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 항에 있어서,상기 제2 텍스트가 획득되기 이전에 획득된 텍스트들에 포함된 타겟 단어들에 관한 공통 정보들이 누적되어 저장되는 것인, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11 항에 있어서,상기 프로세서는, 상기 저장된 하나 이상의 명령어를 실행하여, 상기 제2 NLU 모델을 이용하여, 상기 제1 텍스트 내의 상기 타겟 단어를 검출하고, 상기 타겟 단어에 대응되는 상기 공통 정보를 수정하는 것인, 서버."}
{"patent_id": "10-2020-0143003", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2020-0143003", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "대용어를 포함하는 텍스트에 관한 보이스 어시스턴트 서비스를 제공하는 시스템 및 방법이 제공된다. 전자 장치 가 보이스 어시스턴트 서비스를 제공하는 방법은, 사용자의 제1 입력으로부터 제1 텍스트를 획득하는 동작; 제1 NLU 모델을 이용하여, 상기 제1 텍스트 내의 타겟 단어를 검출하고 상기 검출된 타겟 단어에 관한 공통 정보를 생성하는 동작; 상기 사용자의 제2 입력으로부터 제2 텍스트를 획득하는 동작; 상기 공통 정보 및 상기 제2 텍스 트를 제2 NLU 모델에 입력하는 동작; 상기 제2 NLU 모델을 이용하여, 상기 제2 텍스트에 포함된 대용어를 검출하 고 상기 검출된 대용어에 대응되는 공통 정보에 기초하여 인텐트 및 파라미터를 출력하는 동작; 및 상기 인텐트 및 파라미터에 관련된 응답 정보를 생성하는 동작을 포함한다."}
{"patent_id": "10-2020-0143003", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 대용어를 포함하는 텍스트에 관한 보이스 어시스턴트 서비스를 제공하는 시스템 및 방법에 관한 것으 로서, 보다 상세하게는 타겟 단어에 대한 공통 정보에 기초하여 대용어를 포함하는 텍스트에 관한 보이스 어시 스턴트 서비스를 제공하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0143003", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "멀티 미디어 기술 및 네트워크 기술이 발전함에 따라, 사용자는 디바이스를 이용하여 다양한 서비스를 제공받을 수 있게 되었다. 특히, 음성 인식 기술이 발전함에 따라, 사용자는 디바이스에 음성(예를 들어, 발화)을 입력하 고, 음성 입력에 따른 응답을 제공받을 수 있게 되었다. 하지만, 종래에는, 사용자의 입력에 대용어가 포함된 경우, 대용어가 포함된 사용자의 입력으로부터 사용자의 의도를 정확하게 파악하기 힘든 문제가 있었으며, 대용어의 의미를 고려하면서 여러 도메인에 특화된 보이스 어 시스턴트 서비스를 제공하기 힘든 문제가 있었다. 이에 따라, 대용어를 포함하는 사용자의 입력으로부터 사용자 의 의도를 정확히 파악하고, 사용자의 의도에 따른 응답을 사용자에게 효과적으로 제공할 수 있는 기술이 요구 되고 있다."}
{"patent_id": "10-2020-0143003", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 복수의 NLU 모델을 이용하여, 사용자의 텍스트에 포함된 타겟 단어를 나타내는 공통 정 보를 다른 텍스트 내의 대용어를 해석하는데 이용할 수 있는, 대용어를 포함하는 텍스트에 관한 보이스 어시스 턴트 서비스를 제공하는 시스템 및 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예는, 텍스트의 도메인을 식별하는데 이용되는 NLU 모델을 이용하여 텍스트 내의 타겟 단어를 식별하고, 식별된 타겟 단어를 나타내는 공통 정보를 이용하여 도메인에 특화된 보이스 어시스턴트 서비 스를 제공할 수 있는, 대용어를 포함하는 텍스트에 관한 보이스 어시스턴트 서비스를 제공하는 시스템 및 방법 을 제공할 수 있다. 또한, 본 개시의 일 실시예는, 텍스트의 도메인을 식별하는데 이용되는 NLU 모델을 이용하여 텍스트 내의 타겟 단어를 식별하고, 식별된 타겟 단어를 나타내는 공통 정보가 복수의 다른 NLU 모델에서 이용되도록 할 수 있는, 대용어를 포함하는 텍스트에 관한 보이스 어시스턴트 서비스를 제공하는 시스템 및 방법을 제공할 수 있다. 또한, 본 개시의 일 실시예는, 텍스트를 해석하는데 이용되는 NLU 모델을 이용하여 타겟 단어를 나타내는 공통 정보를 수정할 수 있는, 대용어를 포함하는 텍스트에 관한 보이스 어시스턴트 서비스를 제공하는 시스템 및 방 법을 제공할 수 있다."}
{"patent_id": "10-2020-0143003", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 사용자의 제1 입력으로부터 생 성된 제1 텍스트를 획득하는 동작; 제1 NLU 모델을 이용하여, 상기 제1 텍스트 내의 타겟 단어를 검출하고 상기 검출된 타겟 단어에 관한 공통 정보를 생성하는 동작; 상기 사용자의 제2 입력으로부터 생성된 제2 텍스트를 획 득하는 동작; 상기 공통 정보 및 상기 제2 텍스트를 제2 NLU 모델에 입력하는 동작; 상기 제2 NLU 모델을 이용 하여, 상기 제2 텍스트에 포함된 대용어를 검출하고 상기 검출된 대용어에 대응되는 공통 정보에 기초하여 인텐 트 및 파라미터를 출력하는 동작; 및 상기 인텐트 및 파라미터에 관련된 응답 정보를 생성하는 동작;을 포함하 는, 전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 다른 전자 장치와 통신하는 통신 인터페이스; 하나 이상의 명령어를 저장하는 저 장부; 상기 저장된 하나 이상의 명령어를 실행하여, 상기 디바이스에 입력된 사용자의 제1 입력으로부터 생성된 제1 텍스트를 획득하고, 제1 NLU 모델을 이용하여, 상기 제1 텍스트 내의 타겟 단어를 검출하고 상기 타겟 단어 에 관한 공통 정보를 생성하고, 상기 사용자의 제2 입력으로부터 생성된 제2 텍스트를 획득하고, 상기 공통 정 보 및 상기 제2 텍스트를 제2 NLU 모델에 입력하고, 상기 제2 NLU 모델을 이용하여, 상기 제2 텍스트에 포함된 대용어를 검출하고 상기 검출된 대용어에 대응되는 공통 정보에 기초하여 인텐트 및 파라미터를 획득하고, , 상 기 인텐트 및 파라미터에 관련된 응답 정보를 생성하는, 프로세서;를 포함하는, 보이스 어시스턴트 서비스를 제 공하는 전자 장치를 제공할 수 있다. 또한, 본 개시의 제3 측면은, 제1 측면의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다."}
{"patent_id": "10-2020-0143003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 보이스 어시스턴트 서비스는, 사용자와의 대화를 제공하는 서비스일 수 있다. 보이스 어시스턴트 서비스에서는 디바이스가 사용자의 상황, 디바이스의 상황 등을 고려하여 사람이 사용자와 직접 대화하는 것처 럼 사용자에게 응답 메시지를 제공할 수 있다. 또한, 보이스 어시스턴트 서비스에서는, 사용자의 개인 비서처럼 사용자가 필요한 정보가 적절하게 생성되어 사용자에게 제공될 수 있다. 보이스 어시스턴트 서비스는, 예를 들 어, 방송 서비스, 콘텐트 공유 서비스, 콘텐트 제공 서비스, 전력 관리 서비스, 게임 제공 서비스, 채팅 서비스, 문서 작성 서비스, 검색 서비스, 통화 서비스, 사진 촬영 서비스, 교통 수단 추천 서비스 및 동영상 재 생 서비스 등과 같은 다양한 서비스와 연계되어, 사용자가 필요한 정보 또는 기능을 사용자에게 제공할 수 있다. 또한, 도메인은 디바이스에 입력된 사용자 입력이 관련된 분야를 나타내며, 예를 들어, 사용자 입력의 의미, 사 용자 입력의 속성 등에 따라 미리 설정될 수 있다. 도메인은, 예를 들어, 사용자 입력과 관련된 서비스에 따라 분류되거나, 사용자 입력에 관련된 동작을 수행하는 애플리케이션에 따라 분류될 수 있다. 또한, 도메인 별로 NLU 모델 및 NLG 모델이 훈련될 수 있다. 사용자 입력은, 예를 들어, 음성 입력, 텍스트 입력, 영상 입력을 포 함할 수 있으나, 이에 제한되지 않으며 보이스 어시스턴트 서비스를 위하여 사용자로부터 입력될 수 있는 모든 종류의 입력을 포함할 수 있다. 또한, 타겟 단어는 대용어의 지시 대상이 될 수 있는 단어이며, 예를 들어, 위치를 나타내는 단어, 날짜를 나타 내는 단어, 시간을 나타내는 단어, 사람을 지칭하는 단어를 포함할 수 있으나, 이에 제한되지 않는다. 또한, 타겟 단어에 대응되는 공통 정보는, 타겟 단어를 식별하기 위한 세부적인 데이터로서 복수의 보이스 어시 스턴트 모듈에서 공통으로 식별될 수 있는 데이터일 수 있다. 공통 정보는, 예를 들어, 복수의 보이스 어시스턴 트 모듈에 의해 공통으로 식별될 수 있는 포맷을 가질 수 있다. 예를 들어, 타겟 단어가 “서울”이고 공통 정 보의 종류가 “location”인 경우에, “서울”에 대응되는 공통 정보는 서울의 위치를 나타내는 GPS 좌표 값을 나타내는 데이터일 수 있다. 또한, 타겟 단어가 “Tom”이고 공통 정보의 종류가 “person”인 경우에, “Tom” 에 대응되는 공통 정보는 Tom을 식별할 수 있는 식별자(예를 들어, User ID, 전화 번호, 이름 등)를 나타내는 데이터일 수 있다. 또한, 예를 들어, 타겟 단어가 “크리스마스”이고 공통 정보의 종류가 “Time/Date”인 경 우에, “크리스마스”에 대응되는 공통 정보는 12월 25일을 나타내는 데이터일 수 있다. 이러한 공통 정보는 기설정된 대용어들에 따라 복수의 종류들로 분류될 수 있다. 예를 들어, 타겟 단어에 대응 되는 공통 정보의 종류는, “Location”, “Date/Time” 및 “Person”을 포함할 수 있으나, 이에 제한되지 않 는다. 또한, 타겟 단어에 대응되는 공통 정보의 종류는, 기 설정된 기준에 따라 분류될 수 있으며, 공통 정보의 종류에 대응되는 대용어들이 미리 설정될 수 있다. 예를 들어, 공통 정보의 종류가 “Location”인 경우에, “ Location”에 대응되는 대용어들은 거기(there), 거기 근처(near), 그 장소(that place) 등을 포함할 수 있다. 또한, 예를 들어, 공통 정보의 종류가 “Date/Time”인 경우에, “Date/Time” 에 대응되는 대용어들은 그 때 (that time), 그 날(the date) 등을 포함할 수 있다. 또한, 예를 들어, 공통 정보의 종류가 “Person”인 경우 에, “Person”에 대응되는 대용어들은 그 사람(he, him, his), 그녀(she, her) 등을 포함할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일실시예에 따른 보이스 어시스턴트 서비스를 제공하는 시스템의 예시를 나타내는 도면이다. 도 1을 참조하면 보이스 어시스턴트 서비스를 제공하는 시스템은 제1 전자 장치 및 제2 전자 장치 를 포함할 수 있다. 제1 전자 장치는 사용자의 입력에 따른 텍스트를 제2 전자 장치에게 제공하고, 제2 전자 장치 로부터 제공되는 응답 정보를 수신하며, 사용자에게 응답 정보를 제공할 수 있다. 제1 전자 장치는 보이스 어시스턴트 서비스를 제공하는 애플리케이션을 실행하고, 실행된 애플리케이션에 의해 제공되는 기능들 을 통하여 사용자의 입력을 수신하고 사용자에게 응답 메시지 및 응답 동작을 제공할 수 있다. 제2 전자 장치는 제1 전자 장치로부터 사용자 입력에 따른 제1 텍스트를 수신하고, 제1 텍스트에 포함된 타겟 단어를 검출하며, 검출된 타겟 단어를 나타내는 공통 정보를 생성하고 저장할 수 있다. 타겟 단어 를 나타내는 공통 정보는 제2 전자 장치 내의 복수의 보이스 어시스턴트 모듈에 의해 이용될 수 있으며, 제2 전자 장치 내의 복수의 보이스 어시스턴트 모듈은 보이스 어시스턴트 서비스를 위한 복수의 도메인에 특화된 모듈일 수 있다. 또한, 제2 전자 장치는 제1 텍스트 이후의 사용자 입력에 따른 제2 텍스트로부터 제2 텍스트 내에 포함된 대용어를 검출하고, 대용어에 대응되는 타겟 단어를 나타내는 공통 정보를 이용하여 제2 텍스트의 도메인에 특 화된 보이스 어시스턴트 모듈을 통해 보이스 어시스턴트 서비스를 제공할 수 있다. 제1 전자 장치 및 제2 전자 장치는, 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라, 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 또한, 제1 전자 장치 및 제2 전자 장치 는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 디바이스 일 수 있다. 또한, 제1 전자 장치 또는 제2 전자 장치 중 적어도 하나는 서버 장치일 수 있다. 그 러나, 이에 제한되지 않으며, 제1 전자 장치 및 제2 전자 장치는 서로 연동하여 보이스 어시스턴트 서비스를 제공할 수 있는 모든 종류의 장치를 포함할 수 있다. 제1 전자 장치 및 제2 전자 장치를 통신 연결하는 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN) 또는 부가가치 통신망(Value Added Network; VAN) 등과 같은 유선 네트워크나 이동 통신망(mobile radio communication network) 또는 위성 통신망 등과 같은 모든 종류의 무선 네트워크로 구현될 수 있다. 또한, 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(WideArea Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network) 또는 위성 통신망 중 적어도 둘 이상의 상호 조합을 포함할 수 있으며, 도 1에 도시된 각 네트워크 구 성 주체가 서로 원활하게 통신을 할 수 있도록 하는 포괄적인 의미의 데이터 통신망이며, 유선 인터넷, 무선 인 터넷 및 모바일 무선 통신망을 포함한다. 무선 통신은 예를 들어, 무선 랜(Wi-Fi), 블루투스, 블루투스 저 에너지(Bluetooth low energy), 지그비, WFD(Wi-Fi Direct), UWB(ultra wideband), 적외선 통신(IrDA, infrared Data Association), NFC(Near Field Communication) 등이 있을 수 있으나, 이에 한정되는 것은 아니 다. 도 2는 본 개시의 일 실시예에 따른 제2 전자 장치의 블록도이다. 도 2를 참조하면, 제2 전자 장치는 통신 인터페이스, 프로세서 및 저장부를 포함하며, 저장부는 공통 정보 관리 모듈, 적어도 하나의 보이스 어시스턴트 모듈 및 DB를 포함 할 수 있다. 통신 인터페이스는, 제1 전자 장치와의 통신을 위한 하나 이상의 구성 요소를 포함할 수 있다. 통 신 인터페이스는 제1 전자 장치에게 보이스 어시스턴트 서비스를 제공하기 위해 필요한 정보를 제1 전자 장치와 송수신할 수 있다. 또한, 통신 인터페이스는 보이스 어시스턴트 서비스를 제공하기 위 하여 다른 디바이스(미도시) 및 다른 서버(미도시)와 통신할 수 있다. 예를 들어, 통신 인터페이스는, 근 거리 통신부, 이동 통신부 및 방송 수신부를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비(Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디 어 메시지 송수신에 따른 다양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로 부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 프로세서는 제2 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 후술할 저 장부에 저장된 프로그램들을 실행함으로써, 본 명세서에서의 보이스 어시스턴트 서비스를 제공하기 위한 제2 전자 장치의 기능을 제어할 수 있다. 저장부는 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있다. 저장부는 플래시 메 모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 저장부에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, 공통 정보 관리 모듈 및 보이스 어시스턴트 모듈을 포함할 수 있다. 공통 정보 관리 모듈은 사용자 입력으로부터 생성된 텍스트를 분석하여, 텍스트에 관련된 도메인 및 텍스 트 내의 타겟 단어를 식별하고, 식별된 타겟 단어에 관련된 공통 정보를 생성하고 관리할 수 있다. 공통 정보 관리 모듈은 생성된 공통 정보를 후술할 공통 정보 DB에 누적하여 저장할 수 있으며, 후술할 보이 스 어시스턴트 모듈이 제2 텍스트를 해석하는데 공통 정보를 이용하도록 할 수 있다. 타겟 단어는 대용 어의 지시 대상이 될 수 있는 단어로서, 예를 들어, 위치를 나타내는 단어, 날짜를 나타내는 단어, 시간을 나타 내는 단어 및 사람을 지칭하는 단어를 포함할 수 있으나, 이에 제한되지 않는다. 또한, 공통 정보 관리 모듈 은 도메인 식별 모듈, 타겟 단어 식별 모듈, 제1 NLU 모델, 공통 정보 생성 모듈 , 공통 정보 선택 모듈 및 공통 정보 수정 모듈를 포함할 수 있다. 제2 전자 장치가 제1 전자 장치로부터 사용자의 음성 데이터를 수신하는 경우에, 제2 전자 장치는 사용자의 음성을 인식하기 위한 ASR (Automatic Speech Recognition) 모델(미도시)을 더 포함할 수도 있다. 도메인 식별 모듈은 텍스트에 관련된 도메인을 식별할 수 있다. 도메인 식별 모듈은 사용자 입력으 로부터 생성된 텍스트를 후술할 제1 NLU 모델을 이용하여 분석함으로써 텍스트의 도메인을 식별할 수 있다. 도메인 식별 모듈은 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 텍스트의 도메인을 식별 할 수 있다. 예를 들어, \"런던 날씨 어때?\"라는 제1 텍스트가 제1 NLU 모델에 입력되고, 제1 NLU 모델로부터 제 1 텍스트의 도메인이 “Weather”라는 출력 값이 출력될 수 있으며, 도메인 식별 모듈은 제1 NLU 모델 로부터 출력되는 출력 값에 기초하여 제1 텍스트의 도메인이 “Weather”임을 식별할 수 있다. 또한, 예 를 들어, \"거기 지금 몇시야?\"라는 제2 텍스트가 제1 NLU 모델에 입력되고, 제1 NLU 모델로부터 제 2 텍스트의 도메인이 “Time”이라는 출력 값이 출력될 수 있으며, 도메인 식별 모듈은 제1 NLU 모델 로부터 출력되는 출력 값에 기초하여 제2 텍스트의 도메인이 “Time”임을 식별할 수 있다. 타겟 단어 식별 모듈은 텍스트 내의 타겟 단어 및 타겟 단어에 관련된 정보를 식별할 수 있다. 타겟 단어 식별 모듈은 사용자 입력으로부터 생성된 텍스트를 후술할 제1 NLU 모델을 이용하여 분석함으로써 타겟 단어 및 타겟 단어에 대응되는 공통 정보의 종류를 식별할 수 있다. 타겟 단어 식별 모듈은 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 타겟 단어 및 타겟 단어에 대응되는 공통 정보의 종류를 식별할 수 있다. 예를 들어, \"런던 날씨 어때?\"라는 제1 텍스트가 제1 NLU 모델에 입력되면, 제1 NLU 모델(231 3)로부터 제1 텍스트 내의 타겟 단어가 “런던”이며 “런던”의 공통 정보의 종류가 “location”임은 나타내 는 출력 값이 출력될 수 있으며, 타겟 단어 식별 모듈은 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제1 텍스트 내의 타겟 단어가 “런던”이며, “런던”에 대응되는 공통 정보의 종류가 “location”임 을 식별할 수 있다. 또한, 상기에서는 도메인 식별 모듈 및 타겟 단어 식별 모듈이 별개의 모듈인 것으로 설명되었지만, 이에 제한되지 않는다. 예를 들어, 하나의 모듈에 의해, 텍스트에 관련된 도메인, 타겟 단어 및 타겟 단어에 대응되는 공통 정보의 종류가 식별될 수도 있다. 제1 NLU 모델은 사용자 입력으로부터 생성된 텍스트를 분석하고, 분석 결과에 기초하여 텍스트의 도메인 및 타겟 단어를 출력할 수 있다. 또한, 제1 NLU 모델은, 사용자 입력으로부터 생성된 텍스트로부터, 텍스 트에 포함된 타겟 단어에 대응되는 공통 정보의 종류를 출력할 수도 있다. 제1 NLU 모델로부터 출력되는 출력 값은, 도메인 식별 모듈 및 타겟 단어 식별 모듈에 의해 이용될 수 있다. 제1 NLU 모델(231 3)은, 텍스트를 해석하여 텍스트에 대응하는 도메인 및 타겟 단어를 식별하도록 훈련된 인공 지능 모델일 수 있 다. 제1 NLU 모델은, 예를 들어, 공통 정보의 종류가 태깅된 텍스트 및 텍스트의 도메인을 학습 데이터를 사용하여 훈련된 모델일 수 있다. 예를 들어, 제1 NLU 모델의 입력 값은 사용자 입력으로부터 생성된 텍 스트일 수 있으며, 제1 NLU 모델의 출력 값은 공통 정보의 종류가 태깅된 타겟 단어 및 텍스트의 도메인 일 수 있으나, 이에 제한되지 않는다. 공통 정보 생성 모듈은 타겟 단어에 대응되는 공통 정보를 생성할 수 있다. 공통 정보 생성 모듈은 타겟 단어를 나타내는 세부적인 데이터를 공통 정보로서 생성할 수 있으며, 공통 정보는 복수의 보이스 어시스 턴트 모듈에서 공통으로 식별될 수 있는 포맷에 따라 생성될 수 있다. 예를 들어, 타겟 단어가 “서울” 이고 공통 정보의 종류가 “location”인 경우에, 공통 정보 생성 모듈은 “서울”에 대응되는 공통 정보 로서 서울의 위치를 나타내는 GPS 좌표 값을 복수의 NLU 모델에서 공통으로 식별될 수 있는 포맷으로 생성할 수 있다. 예를 들어, 타겟 단어가 “Tom”이고 공통 정보의 종류가 “person”인 경우에, 공통 정보 생성 모듈 은 “Tom”에 대응되는 공통 정보로서 Tom을 식별할 수 있는 식별자를 복수의 NLU 모델에서 공통으로 식 별될 수 있는 포맷으로 생성할 수 있다. 예를 들어, 타겟 단어가 “크리스마스”이고 공통 정보의 종류가 “ Time/Date”인 경우에, 공통 정보 생성 모듈은 “크리스마스”에 대응되는 공통 정보로서 12월 25일을 복 수의 NLU 모델에서 공통으로 식별될 수 있는 포맷으로 생성할 수 있다. 한편, 예를 들어, 텍스트 내에 하나의 공통 정보의 종류에 대응되는 복수의 타겟 단어들이 포함된 경우에, 공통 정보 생성 모듈은 기 설정된 기준에 따라, 공통 정보의 종류에 대응될 하나의 타겟 단어를 선택하고, 선 택된 타겟 단어에 대한 공통 정보를 생성할 수 있다. 예를 들어, “서울역에서 부산역으로 가는 길을 알려줘.” 라는 텍스트는, 공통 정보의 종류인 “location”에 대응되는 타겟 단어들로서 “서울역” 및 “부산역”을 포 함할 수 있다. 이 경우, 출발지보다 도착지에 대해 높은 우선 순위가 부여되도록 공통 정보 생성 기준이 설정될 수 있으며, 공통 정보 생성 모듈은 출발지인 “서울역”보다 도착지인 “부산역”에 대하여 공통 정보를 생성할 수 있다. 하지만, 이에 제한되지 않으며, 공통 정보 생성 모듈은 복수의 타겟 단어들에 각각 대응 되는 복수의 공통 정보를 생성하고, 다음 텍스트에 포함된 대용어에 대응되는 공통 정보로서, 복수의 공통 정보 중 적어도 하나가 선택되도록 할 수도 있다.한편, 예를 들어, 공통 정보 생성 모듈은 하나의 타겟 단어에 대응되는 복수의 공통 정보를 생성할 수도 있다. 예를 들어, 공통 정보의 종류가 “Time/Date”인 타겟 단어 “크리스마스”에 대하여, 공통 정보 생성 모 듈은 “크리스마스”를 나타내는 식별 값 및 “12월 25”일을 “크리스마스”에 대응되는 공통 정보로서 생성할 수 있다. 공통 정보 생성 모듈은 생성된 공통 정보를 공통 정보 DB에 저장할 수 있다. 공통 정보 생성 모듈 은 텍스트가 획득된 순서에 따라, 텍스트 내의 타겟 단어에 관련된 공통 정보를 누적하여 저장할 수 있다. 또한, 예를 들어, 공통 정보 생성 모듈은 생성된 공통 정보를 공통 정보의 종류, 공통 정보가 관련 된 도메인, 공통 정보에 대응되는 타겟 단어 및 공통 정보의 속성과 연관지어 저장할 수 있다. 또한, 공통 정보 가 저장된 순서, 공통 정보가 관련된 도메인, 공통 정보에 대응되는 타겟 단어 및 공통 정보의 속성 중 적어도 하나는, 후술할 공통 정보 선택 모듈이 이후에 획득되는 텍스트에 포함된 대용어에 대응되는 공통 정보를 선택하는데 이용될 수 있다. 한편, 예를 들어, 공통 정보 생성 모듈은 하나의 공통 정보 종류에 대하여 기설정된 개수의 타겟 단어에 대응되는 공통 정보를 저장할 수 있다. 예를 들어, 공통 정보의 종류 “location”에 대응되는 공통 정보가 하 나만 저장되도록 하고, “location”에 대응되는 공통 정보가 저장된 이후에 입력되는 텍스트로부터 “location ”에 대응되는 다른 타겟 단어에 대응되는 공통 정보가 생성된 경우에, 이전에 저장된 공통 정보를 삭제하고 다 른 타겟 단어에 대응되는 공통 정보를 저장할 수 있다. 공통 정보 선택 모듈은 공통 정보 DB에 저장된 공통 정보 중에서 제2 텍스트의 해석을 위한 공통 정보를 선택할 수 있다. 제2 텍스트의 도메인이 도메인 식별 모듈에 의해 식별되면, 공통 정보 선택 모듈은 식별된 도메인 에 관련하여 저장된 공통 정보들을 공통 정보 DB로부터 선택하고, 선택된 공통 정보들을 후술할 공통 정 보 변환 모듈에게 제공할 수 있다. 또는, 예를 들어, 공통 정보 선택 모듈은 제2 텍스트의 도메인 과 무관하게 공통 정보 DB에 저장된 모든 또는 일부의 공통 정보들을 공통 정보 변환 모듈에게 제 공할 수 있다. 공통 정보 선택 모듈이 일부의 공통 정보들을 선택하는 경우에, 공통 정보 선택 모듈 은 공통 정보 DB에 저장된 공통 정보들 중에서 최근에 저장된 기설정된 개수의 공통 정보들을 공통 정보 변환 모듈에게 제공하기 위하여 선택할 수 있다. 이 경우, 공통 정보 변환 모듈에게 제공된 공통 정보는, 공통 정보 변환 모듈에 의해 변환되어 제2 텍스트와 함께 제2 NLU 모델에 입력될 수 있다. 일 실시예에 따르면, 후술할 대용어 식별 모듈에 의해 제2 텍스트 내의 대용어가 식별되면, 공통 정보 선 택 모듈은 식별된 대용어에 대응되는 공통 정보를 공통 정보 DB로부터 선택하고, 선택된 공통 정보 를 공통 정보 변환 모듈에게 제공할 수도 있다. 이 경우, 예를 들어, 공통 정보는 변환되어 제2 텍스트와 함께 제2 NLU 모델에 입력되거나, 제2 텍스트를 입력으로 하여 제2 NLU 모델로부터 출력되는 출력 값 중에서 대용어에 해당하는 값을 대체하는데 공통 정보가 이용될 수 있다. 공통 정보 수정 모듈은 공통 정보 DB에 저장된 공통 정보를 수정할 수 있다. 공통 정보 수정 모듈 은 공통 정보 DB에 저장된 공통 정보를 제1 NLU 모델 의 출력 값을 바탕으로 수정할 수 있다. 타겟 단어 식별 모듈에 의해 제2 텍스트로부터 타겟 단어가 식별되면, 공통 정보 생성 모듈 에 의해 제2 텍스트 내의 타겟 단어에 대응되는 공통 정보가 생성될 수 있다. 또한, 공통 정보 수정 모듈(231 6)은 공통 정보 DB에 저장된 공통 정보를 제2 텍스트 내의 타겟 단어에 대응되는 공통 정보로 대체할 수 있다. 예를 들어, 공통 정보 수정 모듈은, 제2 텍스트 내의 타겟 단어의 도메인 및 공통 정보 종류와 동 일한 도메인 및 공통 정보 종류를 가지는 공통 정보를 수정할 수 있다. 예를 들어, 제1 텍스트가 “런던 날씨 어때?”이면, 타겟 단어인 ‘런던’에 대응되는 공통 정보가 weather 도메인 및 공통 정보 종류 location 에 연 관되어 공통 정보 DB에 저장될 수 있다. 이후, “거기 대신에 서울 날씨는 어때?”라는 제2 텍스트가 제1 NLU 모델에 입력될 수 있다. 이 경우, 제2 텍스트 내의 타겟 단어 ‘서울’에 대응되는 공통 정보가 weather 도메인 및 공통 정보 종류 location에 연관되어 생성될 수 있다. 또한, 공통 정보 수정 모듈은 공통 정보 DB에 저장된 ‘런던’에 대응되는 공통 정보를 ‘서울’에 대응되는 공통 정보로 대체할 수 있 다. 또한, 공통 정보 수정 모듈은 공통 정보 DB에 저장된 공통 정보를 제2 NLU 모델의 출력 값을 바탕으로 수정할 수 있다. 공통 정보 수정 모듈은 제2 NLU 모델로부터 출력되는 출력 값을 이용하 여 텍스트 내의 타겟 단어를 식별하고, 타겟 단어를 나타내는 공통 정보가 공통 정보 DB에 저장된 공통정보와 동일한 지를 판단할 수 있다. 공통 정보 수정 모듈이 식별한 타겟 단어를 나타내는 공통 정보가, 공통 정보 DB에 저장된 공통 정보와 상이한 경우에, 공통 정보 수정 모듈은 공통 정보 DB에 저장된 공통 정보를 수정할 수 있다. 이 경우, 제2 NLU 모델로부터 출력되는 타겟 단어에 관련된 파라미 터들을 바탕으로, 타겟 단어에 대응되는 공통 정보가 수정될 수 있다. 예를 들어, 제2 NLU 모델로부터 출 력되는 타겟 단어의 의미 및 타겟 단어에 대응되는 공통 정보의 종류를 바탕으로, 타겟 단어에 대응되는 공통 정보가 수정될 수 있다. 예를 들어, 제1 NLU 모델에서는 텍스트 내에 포함된 타겟 단어 “서울”에 대응 되는 공통 정보의 종류가 “Location”으로 출력되고, 제2 NLU 모델에서는 텍스트 내에 포함된 타겟 단어 “서울”에 대응되는 공통 정보의 종류가 “Person”으로 출력되는 경우에, 공통 정보 수정 모듈은 타겟 단어 “서울”에 대응되는 공통 정보를 추가 또는 수정할 수 있다. 이 경우, 제2 NLU 모델은 텍스트에 관 련된 도메인에 특화된 모델일 수 있으며, 제2 NLU 모델을 이용하여 공통 정보를 생성 또는 수정함으로써, 텍스트 내의 타겟 단어에 관하여 보다 정확한 공통 정보가 공통 정보 DB에 저장될 수 있게 된다. 또한, 공통 정보 수정 모듈은 보이스 어시스턴트 서비스를 통해 사용자와 송수신한 데이터를 바탕으로, 공통 정보 DB에 저장된 공통 정보를 추가 또는 수정할 수도 있다. 공통 정보 수정 모듈은, 예를 들 어, 사용자 입력으로부터 생성된 텍스트, 후술할 NLG 모델을 통해 생성된 응답 메시지, 사용자의 의도에 따른 제1 전자 장치 또는 다른 디바이스(미도시)의 기능 중 적어도 하나에 기초하여, 공통 정보 DB(234 1)에 저장된 공통 정보를 추가 또는 수정할 수 있다. 보이스 어시스턴트 모듈은 사용자 입력으로부터 생 성된 텍스트를 해석하고, 텍스트에 대한 응답 정보를 생성할 수 있다. 보이스 어시스턴트 모듈은 특정 도 메인에 특화된 모듈로서, 제2 전자 장치는 복수의 도메인들에 대한 복수의 보이스 어시스턴트 모듈들 을 포함할 수 있다. 또한, 제2 전자 장치는 텍스트의 도메인에 특화된 보이스 어시스턴트 모듈 을 이용하여 텍스트를 해석할 수 있다. 예를 들어, 도메인 식별 모듈에 의해 텍스트의 도메인이 “ Weather”로 결정되면, 도메인 “Weather”에 특화된 보이스 어시스턴트 모듈이 텍스트를 해석하는데 이 용될 수 있다. 또한, 도메인 식별 모듈 에 의해 텍스트의 도메인이 “Clock”으로 결정되면, “Clock”에 특화된 보이스 어시스턴트 모듈이 텍스트를 해석하는데 이용될 수 있다. 보이스 어시스턴트 모듈은 공통 정보 변환 모듈, 제2 NLU 모델, 대용어 식별 모듈, 응 답 정보 생성 모듈 및 NLG 모델을 포함할 수 있다. 공통 정보 변환 모듈은 제2 텍스트의 해석을 위해 공통 정보를 변환할 수 있다. 공통 정보 변환 모듈 은 공통 정보 DB에 저장된 공통 정보 중 적어도 일부를, 보이스 어시스턴트 모듈에 의해 처 리될 수 있는 포맷으로 공통 정보를 변환할 수 있다. 또한, 변환된 공통 정보는, 대용어를 포함하는 제2 텍스트 를 해석하는데 이용될 수 있다. 보이스 어시스턴트 모듈은 제2 NLU 모델을 이용하여 사용자 입력으로부터 생성된 텍스트를 해석할 수 있다. 제2 NLU 모델은 텍스트를 해석하여 사용자의 의도에 관련된 인텐트 및 파라미터를 출력할 수 있 다. 인텐트는 제2 NLU 모델을 이용하여 텍스트를 해석함으로써 결정되는 정보로서, 예를 들어, 사용자의 의도를 나타낼 수 있다. 인텐트는, 사용자의 의도를 나타내는 의도 정보뿐 아니라, 사용자의 의도를 나타내는 정보에 대응하는 수치 값을 포함할 수 있다. 수치 값은, 텍스트가 특정 의도를 나타내는 정보와 관련될 확률을 나타낼 수 있다. 예를 들어, 제2 NLU 모델을 이용하여 텍스트를 해석한 결과, 사용자의 의도를 나타내는 정보가 복수 개 획득되는 경우, 각 의도 정보에 대응되는 수치 값이 최대인 의도 정보가 인텐트로 결정될 수 있 다. 또한, 파라미터는 인텐트와 관련된 세부 정보를 나타낼 수 있다. 파라미터는 인텐트와 관련된 정보로서, 하 나의 인텐트에 복수 종류의 파라미터가 대응될 수 있다. 일 실시예에 따르면, 보이스 어시스턴트 모듈은 제2 텍스트 내에 대용어가 존재하는 지를 판단하지 않고 제2 NLU 모델을 통해 제2 텍스트를 해석할 수 있다. 이 경우, 제2 NLU 모델은 공통 정보 및 제2 텍 스트를 입력받아 제2 텍스트를 해석할 수 있으며, 제2 NLU 모델은 공통 정보 및 대용어를 포함하는 텍스 트를 이용하여 훈련된, 대용어를 포함하는 텍스트를 해석하기 위한 인공지능 모델일 수 있다. 예를 들어, 제2 텍스트 내에 대용어가 존재하는 지가 판단되지 않은 상태에서, 제2 텍스트의 도메인이 도메인 식별 모듈 에 의해 식별되고 제2 텍스트의 도메인에 연관된 공통 정보들이 공통 정보 변환 모듈에 의해 변환되면, 변환된 공통 정보 및 제2 텍스트가 제2 NLU 모델에 입력될 수 있다. 또한, 제2 NLU 모델은 제2 텍 스트 내의 대용어에 대응되는 공통 정보를 고려하여 제2 텍스트를 해석할 수 있게 된다. 예를 들어, 제2 텍스트 가 “거기 오늘 날씨 어때?”인 경우에, 날씨 도메인에 연관된 공통 정보 및 제2 텍스트가 제2 NLU 모델 에 입력될 수 있으며, 제2 NLU 모델은 ‘날씨 정보 제공’이라는 인텐트, ‘오늘(date)’, ‘부산(location)’과 같은 파라미터들을 출력할 수 있다. 또는, 예를 들어, 제2 텍스트 내에 대용어가 존재하는 지가 판단되지 않은 상태에서, 제2 텍스트의 도메인과 무 관하게 공통 정보 DB에 저장된 모든 또는 일부의 공통 정보들이 공통 정보 변환 모듈에 의해 변환 되고, 변환된 공통 정보는 제2 텍스트와 함께 제2 NLU 모델에 입력될 수 있다. 이에 따라, 제2 NLU 모델 은 제2 텍스트 내의 대용어에 대응되는 공통 정보를 고려하여 제2 텍스트를 해석할 수 있게 된다. 예를 들어, 제2 텍스트가 “거기 오늘 날씨 어때?”인 경우에, 제2 텍스트의 도메인과 무관하게, 공통 정보 DB(234 1)에 최근에 저장된 공통 정보 및 제2 텍스트가 제2 NLU 모델에 입력될 수 있으며, 제2 NLU 모델은 ‘날씨 정보 제공’이라는 인텐트, ‘오늘(date)’, ‘부산(location)’과 같은 파라미터들을 출력할 수 있다. 한편, 일 실시예에 따르면, 보이스 어시스턴트 모듈은 제2 텍스트 내의 대용어를 식별하고, 식별된 대용 어에 관련된 공통 정보를 이용하여 제2 텍스트를 해석할 수 있다. 이 경우, 대용어 식별 모듈은 프로세서에 의해 실행됨으로써 제2 텍스트 내의 대용어를 식별할 수 있다. 예를 들어, 대용어 식별 모듈은 룰 기반으로 제2 텍스트 내의 대용어를 식별할 수 있다. 대용어 식 별 모듈은, 예를 들어, 기 설정된 대용어들을 제2 텍스트와 비교함으로써 제2 텍스트 내의 대용어를 식별 할 수 있다. 이 경우, 제2 텍스트 내의 대용어를 식별하기 위하여 기 설정된 대용어들이 DB에 미리 저장 되어 있을 수 있다. 또는, 예를 들어, 대용어 식별 모듈은 대용어 식별을 위한 인공지능 모델을 이용하여 제2 텍스트 내의 대 용어를 식별할 수 있다. 이 경우, 대용어 식별을 위한 인공지능 모델은 대용어의 식별을 위하여 미리 훈련된 모 델일 수 있으며, 대용어 식별 모듈은 대용어 식별을 위한 인공지능 모델로부터 출력된 출력 값에 기초하 여 제2 텍스트에 포함된 대용어를 식별할 수 있다. 예를 들어, 제2 텍스트가 대용어 식별을 위한 인공지능 모델 에 입력되면 인공지능 모델로부터 파라미터 ‘거기(Anaphora)’가 출력될 수 있으며, 대용어 식별 모듈은 출력된 파라미터 ‘거기(Anaphora)’로부터, 텍스트 내의 ‘거기’가 대용어임을 식별할 수 있다. 대용어 식별 을 위한 인공지능 모델은, 예를 들어, 제1 NLU 모델, 제2 NLU 모델 또는 별개의 모델(미도시)을 포함할 수 있으나, 이에 제한되지 않는다. 대용어 식별 모듈에 의해 제2 텍스트 내의 대용어가 식별되는 경우에, 공통 정보 선택 모듈은 식별 된 대용어에 관련된 공통 정보를 선택하여 공통 정보 변환 모듈에게 제공할 수 있다. 이 경우, 공통 정보 선택 모듈은 공통 정보 DB에 저장된 공통 정보 중에서 텍스트로부터 식별된 대 용어에 대응되는 공통 정보를 선택할 수 있다. 공통 정보 선택 모듈은 텍스트에 포함된 대용어에 관련된 공통 정보의 종류 및/또는 텍스트에 관련된 도메인에 기초하여, 대용어가 나타내는 공통 정보를 공통 정보 DB로부터 식별할 수 있다. 예를 들어, 제1 텍스트로부터 생성된 “Weather” 도메인의 “location”에 대 한 공통 정보가 런던의 GPS 좌표 값이며, 제1 텍스트 이후에 획득된 제2 텍스트에 포함된 대용어가 “거기”인 경우에, 공통 정보 선택 모듈은 공통 정보의 종류 “location”에 기초하여, 대용어 “거기”에 대응되는 공통 정보인 런던의 GPS 좌표 값을 공통 정보 DB로부터 선택할 수 있다. 공통 정보 선택 모듈은 대용어에 대응되는 타겟 단어를 식별하고, 타겟 단어에 대응되는 공통 정보를 선 택할 수도 있다. 이 경우, 공통 정보 선택 모듈은 대용어를 포함하는 제2 텍스트가 획득되기 이전에 획득 된 텍스트들로부터 식별된 타겟 단어들 중에서, 대용어에 대응되는 타겟 단어를 선택할 수 있다. 또한, 공통 정 보 선택 모듈은 선택된 타겟 단어에 대응되는 공통 정보를 선택할 수 있다. 하지만, 이에 제한되지 않으 며, 공통 정보 선택 모듈은, 예를 들어, 공통 정보가 저장된 순서, 공통 정보가 관련된 도메인, 공통 정 보에 대응되는 타겟 단어 및 공통 정보의 속성 중 적어도 하나를 고려하여, 다양한 기준에 따라 공통 정보를 선 택할 수 있다. 한편, 예를 들어, 타겟 단어에 관련된 복수의 공통 정보가 공통 정보 DB에 저장된 경우, 공통 정보 선택 모듈은 다음 텍스트에 포함된 타겟 단어에 대응되는 공통 정보를 저장된 복수의 공통 정보 중에서 선택할 수 있다. 이 경우, 공통 정보 선택 모듈은 후술할 제2 NLU 모델의 출력 값을 고려하여, 텍스트에 포함된 대용어에 대응되는 공통 정보를 공통 정보 DB에 저장된 복수의 공통 정보 중에서 선택할 수 있다. 또한, 공통 정보 선택 모듈에 의해 선택된 공통 정보는, 후술할 보이스 어시스턴트 모듈이 이용할 수 있는 포맷으로 변환될 수 있다. 예를 들어, 공통 정보 선택 모듈에 의해 선택된 공통 정보가 후술할 보이스 어시스턴트 모듈에 의해 그대로 이용되기 힘든 경우에, 보이스 어시스턴트 모듈이 이용할 수 있는 포맷으로 변환될 수 있다.일 실시예에 따르면, 보이스 어시스턴트 모듈은 공통 정보 및 제2 텍스트를 제2 NLU 모델에 입력하 여 제2 텍스트를 해석할 수 있다. 보이스 어시스턴트 모듈은 제2 텍스트 및 제2 텍스트 내의 대용어에 대 응되는 공통 정보를 제2 NLU 모델에 입력하고, 제2 NLU 모델로부터 출력되는 출력 값을 획득할 수 있다. 이 경우, 제2 NLU 모델은 제2 텍스트 내의 대용어에 대응되는 공통 정보 및 제2 텍스트를 입력받아 제2 텍스트를 해석할 수 있으며, 제2 NLU 모델은 대용어에 대응되는 공통 정보 및 대용어를 포함하는 텍 스트를 이용하여 훈련된, 대용어를 포함하는 텍스트를 해석하기 위한 인공지능 모델일 수 있다. 예를 들어, 제 2 텍스트 내의 대용어에 대응되는 공통 정보가 공통 정보 변환 모듈에 의해 변환되면, 변환된 공통 정보 및 제2 텍스트가 제2 NLU 모델에 입력될 수 있다. 또한, 제2 NLU 모델은 제2 텍스트 내의 대용어에 대응되는 공통 정보를 고려하여 제2 텍스트를 해석할 수 있게 된다. 예를 들어, 제2 텍스트가 “거기 오늘 날씨 어때?”인 경우에, ‘거기’에 대응되는 공통 정보 및 제2 텍스트가 제2 NLU 모델에 입력될 수 있으며, 제2 NLU 모델은 ‘날씨 정보 제공’이라는 인텐트, ‘오늘(date)’, ‘부산(location)’과 같은 파라미터 들을 출력할 수 있다. 상기에서는, 제2 텍스트 및 제2 텍스트 내의 대용어에 대응되는 공통 정보가 모두 제2 NLU 모델에 입력되 는 것으로 설명되었지만, 이에 제한되지 않는다. 예를 들어, 제2 텍스트 내의 대용어가 공통 정보로 대체되고, 대용어가 공통 정보로 대체된 제2 텍스트가 제2 NLU 모델에 입력될 수도 있다. 일 실시예에 따르면, 보이스 어시스턴트 모듈은 제2 텍스트를 제2 텍스트를 제2 NLU 모델에 입력하 고, 제2 NLU 모델로부터 출력된 파라미터 중 대용어에 대응되는 파라미터를 대용어에 대응되는 공통 정보 로 대체할 수도 있다. 이 경우, 제2 NLU 모델은 제2 텍스트를 입력받아 제2 텍스트를 해석하는 인공지능 모델일 수 있다. 예를 들어, 제2 텍스트가 “거기 오늘 날씨 어때?”인 경우에, 제2 텍스트가 제2 NLU 모델 에 입력될 수 있으며, 제2 NLU 모델은 ‘날씨 정보 제공’이라는 인텐트, ‘오늘(date)’, ‘거기 (Anaphora)’과 같은 파라미터들을 출력할 수 있다. 또한, 보이스 어시스턴트 모듈은 대용어를 나타내는 파라미터인 ‘거기(Anaphora)’를 ‘부산(location)’으로 대체할 수 있다. 응답 정보 생성 모듈은 제2 텍스트의 해석 결과에 기초하여 텍스트에 대한 응답 정보를 생성할 수 있다. 응답 정보는, 텍스트에 대한 응답에 관련된 데이터로서, 예를 들어, 제1 전자 장치, 다른 디바이스(미도 시) 및 다른 서버(미도시)에게 제공되는 데이터 및 제2 전자 장치의 동작을 위한 데이터를 포함할 수 있 다. 응답 정보 생성 모듈은 제2 NLU 모델의 출력 값에 기초하여 사용자의 의도에 따른 제2 전자 장치 , 제1 전자 장치 또는 다른 디바이스(미도시)의 액션들을 플래닝할 수 있다. 예를 들어, 응답 정보 생성 모듈은 텍스트의 해석 결과, 후술할 발화 데이터 DB에 저장된 발화 데이터, 및 후술할 액션 데이터 DB에 저장된 액션 데이터를 이용하여, 사용자의 의도에 따른 제2 전자 장치, 제1 전자 장치 또는 다른 디바이스(미도시)의 액션들을 플래닝할 수 있다. 또한, 응답 정보 생성 모듈은 사용자 의 의도에 따른 제2 전자 장치, 제1 전자 장치 또는 다른 디바이스(미도시)의 액션들을 플래닝함으 로써, 텍스트에 대한 응답 정보를 생성할 수 있다. 예를 들어, 응답 정보 생성 모듈은 NLG 모델을 이용하여 사용자의 의도에 따른 응답 메시지를 생성 할 수 있다. 또한, 예를 들어, 응답 정보 생성 모듈은 텍스트, 이미지, 동영상 등과 같이, 사용자에 제공 할 응답 컨텐츠를 획득할 수 있다. 또한, 예를 들어, 응답 정보 생성 모듈은 사용자의 제1 전자 장치 또는 다른 디바이스(미도시)의 동작들을 결정하고, 제1 전자 장치 또는 다른 디바이스(미도시)를 를 제어하기 위한 제어 명령을 생성할 수 있다. DB는 보이스 어시스턴트 서비스를 위하여 필요한 정보를 저장할 수 있다. DB는 공통 정보 DB, 발화 데이터 DB 및 액션 데이터 DB를 포함할 수 있다. 공통 정보 DB는 타겟 단어에 대응되는 공통 정보를 저장할 수 있다. 공통 정보 DB는 텍스트가 획득 된 순서에 따라, 텍스트 내의 타겟 단어에 관련된 공통 정보를 누적하여 저장할 수 있다. 또한, 예를 들어, 공 통 정보 DB는 생성된 공통 정보를 공통 정보의 종류, 공통 정보가 관련된 도메인, 공통 정보에 대응되는 타겟 단어 및 공통 정보의 속성과 연관지어 저장할 수 있다. 발화 데이터 DB는 제1 전자 장치 및 다른 디바이스(미도시)의 기능들에 관련된 발화 데이터를 저장 할 수 있다. 저장된 발화 데이터는, 텍스트의 해석 결과에 관련된 제1 전자 장치 또는 다른 디바이스(미 도시)의 기능을 식별하는데 이용될 수 있다.액션 데이터 DB는 제1 전자 장치 및 다른 제1 전자 장치의 기능들에 관련된 액션 데이터를 저장할 수 있다. 액션 데이터는, 소정의 발화 데이터에 대응되는 제1 전자 장치의 일련의 세부 동작들에 관한 데이터일 수 있다. 예를 들어, 액션 데이터는, 소정의 발화 데이터에 대응하여 디바이스가 수행할 세부 동 작들, 각 세부 동작들과 다른 세부 동작과의 연관 관계, 및 세부 동작들의 실행 순서에 관련된 정보를 포함할 수 있다. 세부 동작과 다른 세부 동작과의 연관 관계는, 하나의 세부 동작을 실행하기 위해서 그 세부 동작을 실행하기 전에 실행되어야 할 다른 세부 동작에 대한 정보를 포함한다. 예를 들어, 수행할 동작이 “음악 재생 ”인 경우, “전원 온(on)”은 “음악 재생” 동작 이전에 실행되어야 하는 다른 세부 동작이 될 수 있다. 또한, 액션 데이터는 예를 들어, 특정 동작의 수행을 위하여 타겟 디바이스가 실행해야 할 기능들, 기능들의 실 행 순서, 기능들을 실행하기 위하여 필요한 입력 값 및 기능들의 실행 결과로서 출력되는 출력 값을 포함할 수 있으나, 이에 한정되지 않는다. 발화 데이터 DB에 저장된 발화 데이터 및 액션 데이터 DB에 저장된 액션 데이터는 서로 매핑될 수 있으며, 제2 전자 장치가 텍스트의 해석 결과로부터 사용자의 의도에 관련 된 제2 전자 장치의 동작들, 제1 전자 장치의 동작들 및 다른 디바이스(미도시)의 동작들을 플래닝 하는데 이용될 수 있다. 한편, 도 2에서는 제2 전자 장치가 제1 전자 장치로부터 사용자의 입력에 기초한 텍스트를 바탕으 로 타겟 단어에 대응되는 공통 정보를 관리하고 보이스 어시스턴트 서비스를 제공하는 것으로 설명되었지만 이 에 제한되지 않는다. 예를 들어, 제2 전자 장치는 제1 전자 장치로부터 텍스트를 수신하지 않고, 제2 전자 장치에 입력되는 사용자 입력에 기초하여 텍스트 내의 타겟 단어에 대응되는 공통 정보를 관리 하고 보이스 어시스턴트 서비스를 제공할 수도 있다. 또한, 제2 전자 장치는 서버 장치 또는 사용자의 디 바이스일 수 있으며, 도 2에서의 제2 전자 장치의 동작들 중 적어도 일부가 제1 전자 장치에 의해 수행될 수도 있다. 또한, 제2 전자 장치가 사용자의 디바이스인 경우에 제2 전자 장치는 사용자 입 력부(미도시), 디스플레이부(미도시) 및 센서부(미도시) 등의 구성을 더 포함할 수도 있다. 도 3은 본 개시의 일 실시예에 따른 공통 정보 관리 모듈이 제1 텍스트로부터 공통 정보를 생성하는 예시 를 나타내는 도면이다. 도 3을 참조하면, 사용자 입력에 따른 제1 텍스트인 “런던 날씨 어때?”가 제2 전자 장치에 의해 수신되 면, 제2 전자 장치의 공통 정보 관리 모듈은 제1 텍스트를 제1 NLU 모델에 입력하고, 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제1 텍스트의 도메인 및 타겟 단어를 식별할 수 있다. 예를 들어, 공통 정보 관리 모듈은 “런던 날씨 어때?”의 도메인이 “Weather”이며, 타겟 단어가 “런던”이 며, 공통 정보의 종류가 “Geo”임을 식별할 수 있다. 또한, 공통 정보 관리 모듈은 런던의 GPS 좌표를 나타내는 값을 “런던”이라는 타겟 단어에 대응되는 공통 정보로 생성할 수 있다. 도 4는 본 개시의 일 실시예에 따른 타겟 단어를 포함하는 텍스트에 대응되는 도메인의 예시를 나타내는 도면이 다. 도 4를 참조하면, “부산 날씨 어때?”, “LA 지금 몇 도야?”, 및 “일요일 날씨 알려줘.”의 도메인이 “ Weather”로 식별되고, “상하이 시간 알려줘.” 및 “브라질 지금 몇 시야?”의 도메인이 “Clock”으로 식별 되고, “런던 맛 집 찾아줘.” 및 “내일 여는 맛 집 알려줘.”의 도메인이 “Restaurant”으로 식별될 수 있다. 또한, 타겟 단어들인 “부산”, “LA”, “상하이”, “브라질”, 및 “런던”에 대응되는 공통 정보의 종류가 “location”으로 식별되고, 타겟 단어들인 “내일” 및 “일요일”에 대응되는 공통 정보의 종류가 “date”로 식별될 수 있다. 또한, 타겟 단어에 대응되는 공통 정보가 생성될 수 있으며, 생성된 공통 정보는 도메인 또는 공통 정보의 종류 에 따라 분류되어 저장될 수 있다. 도 5는 본 개시의 일 실시예에 따른 타겟 단어에 대응되는 공통 정보의 예시를 나타내는 도면이다. 도 5를 참조하면, 타겟 단어 “20.04.19” 및 “2020/04/19”에 대응되는 공통 정보로서, “common.BaseDate{ year{common.Integer}, month{common.Integer}, day {common.Integer}}” 가 생성되고, 타겟 단어 “LA” 및 “Los Angeles”에 대응되는 공통 정보로서, “common.BaseGeoPoint {latitude {common.decimal(34.052235)}, longitude{common.decimal(-118.243683)}}”가 생성될 수 있다. 또한, 도 5에서 예시된 공통 정보는 복수의 보이스 어시스턴트 모듈에 의해 공통으로 식별될 수 있는 포맷일 수 있다. 도 6은 본 개시의 일 실시예에 따른 제2 텍스트 내의 대용어에 대응되는 공통 정보가 획득되는 예시를 나타내는 도면이다. 도 6을 참조하면, 사용자의 “런던 날씨 어때?”라는 제1 텍스트가 제1 전자 장치로부터 수신되면, 제2 전자 장치는 제1 텍스트 내의 타겟 단어 “런던”에 대응되는 공통 정보를 생성하여, 공통 정보 DB(234 3)에 저장할 수 있다. 이후, 제1 전자 장치가 제1 텍스트에 대한 응답으로서, “지금은 화창하고 맑은 날씨네요.”를 출력하면, 사용자는 “거기는 지금 몇시야?”라는 질의를 제1 전자 장치에 입력할 수 있다. 이후, 제1 전자 장치 가 “거기는 지금 몇시야?”라는 제2 텍스트를 제2 전자 장치에게 제공되면, 제2 전자 장치 는 제2 텍스트 내의 대용어인 “거기”를 검출하고, 검출된 대용어에 대응되는 공통 정보를 공통 정보 DB(234 3)로부터 추출하여, 제2 텍스트의 의미를 해석할 수 있다. 도 7은 본 개시의 일 실시예에 따른 제2 전자 장치가 제1 텍스트에 대한 공통 정보를 생성하고 제1 텍스 트에 대한 응답을 제공하는 방법의 흐름도이다. 동작 S700에서 제2 전자 장치는 사용자의 제1 텍스트를 획득할 수 있다. 보이스 어시스턴스 서비스를 이 용하는 사용자의 제1 전자 장치는 사용자의 제1 음성 입력을 수신할 수 있으며, 수신된 제1 음성 입력을 제1 텍스트로 변환할 수 있다. 제1 전자 장치는 제1 텍스트를 제2 전자 장치로 전송할 수 있으며, 제2 전자 장치는 제1 전자 장치로부터 전송된 제1 텍스트를 수신할 수 있다. 예를 들어, 사용자가 “런던 날씨 어때?”라는 음성을 제1 전자 장치에 입력하면, 제1 전자 장치는 사용자의 음성을 제1 텍스트인 “런던 날씨 어때?”로 변환하고, 변환된 제1 텍스트를 제2 전자 장치에게 제공할 수 있다. 또 는, 예를 들어, 사용자가 제1 전자 장치에 텍스트 입력을 하는 경우에, 제1 전자 장치는 사용자에 의해 입력된 제1 텍스트를 제2 전자 장치에게 제공하고, 제2 전자 장치가 제1 전자 장치로부 터 제공된 제1 텍스트를 수신할 수도 있다. 또는, 제2 전자 장치는 제2 전자 장치에 대한 사용자의 음성 입력으로부터 제1 텍스트를 획득할 수 도 있다. 이 경우, 제2 전자 장치는 서버가 아닌 사용자의 디바이스일 수 있다. 동작 S705에서 제2 전자 장치는 제1 NLU 모델을 이용하여 제1 텍스트로부터 도메인, 타겟 단어 및 타겟 단어에 관련된 정보를 식별할 수 있다. 제2 전자 장치는 사용자 입력의 제1 텍스트를 제1 NLU 모델을 이용하여 분석함으로써 제1 텍스트의 도메인을 식별할 수 있다. 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제1 텍스트의 도메인을 식별할 수 있다. 예를 들어, \"런던 날씨 어때?\"라는 제1 텍스트가 제1 NLU 모델에 입 력되고, 제1 NLU 모델로부터 제1 텍스트의 도메인이 “Weather”라는 출력 값이 출력될 수 있으며, 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제1 텍스트의 도메인이 “Weather” 임을 식별할 수 있다. 제2 전자 장치는 텍스트 내의 타겟 단어 및 타겟 단어에 관련된 정보를 식별할 수 있다. 제2 전자 장치 는 사용자의 제1 텍스트를 제1 NLU 모델을 이용하여 분석함으로써 타겟 단어 및 타겟 단어에 대응 되는 공통 정보의 종류를 식별할 수 있다. 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값 에 기초하여 타겟 단어 및 타겟 단어에 대응되는 공통 정보의 종류를 식별할 수 있다. 예를 들어, \"런던 날씨 어때?\"라는 제1 텍스트가 제1 NLU 모델에 입력되면, 제1 NLU 모델로부터 제1 텍스트 내의 타겟 단 어가 “런던”이며 “런던”의 공통 정보의 종류가 “location”임은 나타내는 출력 값이 출력될 수 있으며, 제 2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제1 텍스트 내의 타겟 단어가 “ 런던”이며, “런던”에 대응되는 공통 정보의 종류가 “location”임을 식별할 수 있다. 동작 S710에서 제2 전자 장치는 제1 텍스트 내의 타겟 단어에 대한 공통 정보의 생성이 필요한지를 결정 할 수 있다. 제2 전자 장치는 제1 텍스트 내에 타겟 단어가 포함되어 있는지 여부, 제1 텍스트 이전에 입력된 텍스트들의 의미 및 공통 정보 DB에 저장된 공통 정보를 고려하여 제1 텍스트 내의 타겟 단어에 대 한 공통 정보의 생성이 필요한지를 결정할 수 있다. 예를 들어, 제1 텍스트에 포함된 타겟 단어 및 타겟 단어에 대응되는 공통 정보가 공통 정보 DB에 저장되어 있지 않다고 판단되면, 제2 전자 장치는 제1 텍스 트 내의 타겟 단어에 대응되는 공통 정보를 저장할 것을 판단할 수 있다. 또는, 예를 들어, 제1 텍스트에 포함 된 타겟 단어 및 타겟 단어에 대응되는 공통 정보가 공통 정보 DB에 이미 저장되어 있다고 판단되면, 제2 전자 장치는 제1 텍스트 내의 타겟 단어에 대응되는 공통 정보를 저장하지 않을 것을 판단할 수 있다. 동작 S710에서의 판단 결과, 공통 정보의 생성이 필요하다고 판단되면, 동작 S715에서 제2 전자 장치는 타겟 단어에 대응되는 공통 정보를 생성할 수 있다. 제2 전자 장치는 타겟 단어를 나타내는 세부적인 데 이터를 공통 정보로서 생성할 수 있으며, 복수의 보이스 어시스턴트 모듈에서 공통으로 식별될 수 있는 포맷에 따라 공통 정보를 생성할 수 있다. 예를 들어, 타겟 단어가 “서울”이고 공통 정보의 종류가 “ location”인 경우에, 제2 전자 장치는 “서울”에 대응되는 공통 정보로서 서울의 위치를 나타내는 GPS 좌표 값을 복수의 NLU 모델에서 공통으로 식별될 수 있는 포맷으로 생성할 수 있다. 예를 들어, 타겟 단어가 “Tom”이고 공통 정보의 종류가 “person”인 경우에, 제2 전자 장치는 “Tom”에 대응되는 공통 정보로 서 Tom을 식별할 수 있는 식별자를 복수의 NLU 모델에서 공통으로 식별될 수 있는 포맷으로 생성할 수 있다. 예 를 들어, 타겟 단어가 “크리스마스”이고 공통 정보의 종류가 “Time/Date”인 경우에, 제2 전자 장치는 “크리스마스”에 대응되는 공통 정보로서 12월 25일을 복수의 NLU 모델에서 공통으로 식별될 수 있는 포맷으로 생성할 수 있다. 한편, 예를 들어, 텍스트 내에 하나의 공통 정보의 종류에 대응되는 복수의 타겟 단어들이 포함된 경우에, 제2 전자 장치는 기 설정된 기준에 따라, 공통 정보의 종류에 대응될 하나의 타겟 단어를 선택하고 선택된 타 겟 단어에 대한 공통 정보를 생성할 수 있다. 예를 들어, “서울역에서 부산역으로 가는 길을 알려줘.”라는 텍 스트는, 공통 정보의 종류인 “location”에 대응되는 타겟 단어들로서 “서울역” 및 “부산역”을 포함할 수 있다. 이 경우, 출발지보다 도착지에 대해 높은 우선 순위가 부여되도록 공통 정보 생성 기준이 설정될 수 있으 며, 제2 전자 장치는 출발지인 “서울역”보다 도착지인 “부산역”에 대하여 공통 정보를 생성할 수 있 다. 하지만, 이에 제한되지 않으며, 제2 전자 장치는 복수의 타겟 단어들에 각각 대응되는 복수의 공통 정보를 생성하고, 다음 텍스트에 포함된 대용어에 대응되는 공통 정보로서, 복수의 공통 정보 중 적어도 하나가 선택되도록 할 수도 있다. 한편, 예를 들어, 제2 전자 장치는 하나의 타겟 단어에 대응되는 복수의 공통 정보를 생성할 수도 있다. 예를 들어, 공통 정보의 종류가 “Time/Date”인 타겟 단어 “크리스마스”에 대하여, 공통 정보 생성 모듈 은 “크리스마스”를 나타내는 식별 값 및 “12월 25”일을 “크리스마스”에 대응되는 공통 정보로서 생 성할 수 있다. 동작 S720에서 제2 전자 장치는 생성된 공통 정보를 누적하여 저장할 수 있다. 제2 전자 장치는 생 성된 공통 정보를 공통 정보 DB에 저장할 수 있다. 제2 전자 장치는 텍스트가 획득된 순서에 따라, 텍스트 내의 타겟 단어에 관련된 공통 정보를 누적하여 저장할 수 있다. 또한, 예를 들어, 제2 전자 장치(200 0)는 생성된 공통 정보를, 공통 정보의 종류, 공통 정보가 관련된 도메인, 공통 정보에 대응되는 타겟 단어 및 공통 정보의 속성과 연관지어 저장할 수 있다. 한편, 예를 들어, 제2 전자 장치는 하나의 공통 정보 종류에 대하여 기설정된 개수의 타겟 단어에 대응되 는 공통 정보를 저장할 수 있다. 예를 들어, 공통 정보의 종류 “location”에 대응되는 공통 정보가 하나만 저 장되도록 하고, “location”에 대응되는 공통 정보가 저장된 이후에 입력되는 텍스트로부터 “location”에 대 응되는 다른 타겟 단어에 대응되는 공통 정보가 생성된 경우에, 이전에 저장된 공통 정보를 삭제하고 다른 타겟 단어에 대응되는 공통 정보를 저장할 수 있다. 동작 S725에서 제2 전자 장치는 제2 NLU 모델을 이용하여 제1 텍스트를 해석할 수 있다. 제2 전자 장치는 제1 텍스트를 제2 NLU 모델에 입력하고 제2 NLU 모델로부터 출력되는 인텐 트 및 파라미터를 획득할 수 있다. 또한, 제2 전자 장치는 사용자의 의도를 나타내는 인텐트 및 인텐트에 관련된 세부 정보를 나타내는 파라미터에 기초하여, 제1 텍스트를 해석할 수 있다. 만약, 제1 텍스트 내에 대용 어가 포함된 경우에, 제2 전자 장치는 제1 텍스트 이전에 획득된 텍스트로부터 생성된 공통 정보를 이용 하여 제1 텍스트를 해석할 수 있다. 제2 전자 장치는 제1 텍스트의 도메인에 특화된 보이스 어시스턴트 모듈을 선택하고, 선택된 보이 스 어시스턴트 모듈을 제어하여 제1 텍스트를 해석할 수 있다. 제2 전자 장치는 제1 텍스트의 도메 인에 특화된 보이스 어시스턴트 모듈 내의 제2 NLU 모델을 이용하여 제1 텍스트를 해석할 수 있다. 동작 S710에서의 판단 결과, 공통 정보의 생성이 필요하지 않다고 판단되면, 제2 전자 장치는 제1 텍스트 에 대한 공통 정보를 생성하지 않고 동작 S725에서 제2 전자 장치는 제2 NLU 모델을 이용하여 제1 텍스트를 해석할 수 있다. 동작 S730에서 제2 전자 장치는 제1 텍스트에 대한 응답 정보를 생성할 수 있다. 제2 전자 장치는 제1 텍스트의 해석 결과에 기초하여 제1 텍스트에 대한 응답 정보를 생성할 수 있다. 응답 정보는, 텍스트에 대 한 응답에 관련된 데이터로서, 예를 들어, 제1 전자 장치, 다른 디바이스(미도시) 및 다른 서버(미도시) 에게 제공되는 데이터 및 제2 전자 장치의 동작을 위한 데이터를 포함할 수 있다. 제2 전자 장치는 제2 NLU 모델의 출력 값에 기초하여 사용자의 의도에 따른 제2 전자 장치, 제1 전자 장치 또 는 다른 디바이스(미도시)의 액션들을 플래닝할 수 있다. 예를 들어, 제2 전자 장치는 제1 텍스트의 해석 결과, 발화 데이터 DB에 저장된 발화 데이터, 및 액션 데이터 DB에 저장된 액션 데이터를 이용하여, 사용자의 의도에 따른 제2 전자 장치, 제1 전자 장치 또는 다른 디바이스(미도시)의 액 션들을 플래닝할 수 있다. 또한, 제2 전자 장치는 사용자의 의도에 따른 제2 전자 장치, 제1 전자 장치 또는 다른 디바이스(미도시)의 액션들을 플래닝함으로써, 텍스트에 대한 응답 정보를 생성할 수 있 다. 예를 들어, 제2 전자 장치는 NLG 모델을 이용하여 사용자의 의도에 따른 응답 메시지를 생성할 수 있다. 또한, 예를 들어, 제2 전자 장치는 텍스트, 이미지, 동영상 등과 같이, 사용자에 제공할 응답 컨텐 츠를 획득할 수 있다. 또한, 예를 들어, 제2 전자 장치는 사용자의 제1 전자 장치 또는 다른 디바 이스(미도시)의 동작들을 결정하고, 제1 전자 장치 또는 다른 디바이스(미도시)를 를 제어하기 위한 제어 명령을 생성할 수 있다. 동작 S735에서 제2 전자 장치는 생성된 응답 정보를 제공할 수 있다. 제2 전자 장치는 생성된 응답 정보를 제1 전자 장치, 다른 디바이스(미도시) 또는 다른 서버(미도시) 중 적어도 하나에게 제공할 수 있 다. 응답 정보를 수신한 제1 전자 장치 및 다른 디바이스(미도시)는 응답 정보에 따른 동작을 수행할 수 있다. 예를 들어, 응답 정보가 응답 메시지인 경우에, 제1 전자 장치 및 다른 디바이스(미도시)는 응답 메시지를 출력할 수 있다. 또한, 예를 들어, 응답 메시지가 제어 명령인 경우에, 제1 전자 장치, 다른 디 바이스(미도시)는 제어 명령에 따른 기능을 실행할 수 있다. 또한, 예를 들어, 응답 정보를 수신한 다른 서버 (미도시)는 응답 정보에 따라 제1 전자 장치 및 다른 디바이스(미도시)를 제어할 수 있다. 도 8은 본 개시의 일 실시예에 따른 제2 전자 장치가 제2 텍스트에 대한 공통 정보를 생성하고 제2 텍스 트에 대한 응답을 제공하는 방법의 흐름도이다. 동작 S800에서 제2 전자 장치는 사용자의 제2 텍스트를 획득할 수 있다. 제1 전자 장치는 사용자의 제1 음성을 수신한 이후에 사용자의 제2 음성을 수신할 수 있으며, 수신된 제2 음성을 제2 텍스트로 변환할 수 있다. 제1 전자 장치는 제2 텍스트를 제2 전자 장치로 전송할 수 있으며, 제2 전자 장치는 제1 전자 장치로부터 전송된 제2 텍스트를 수신할 수 있다. 예를 들어, 사용자가 “런던 날씨 어때?”라 는 제1 음성 이후에, 사용자는 “ 거기는 지금 몇 시야?”라는 제2 음성을 제1 전자 장치에 입력할 수 있 으며, 제1 전자 장치는 사용자의 제2 음성을 제1 텍스트인 “거기는 지금 어디야?”로 변환하고, 변환된 제2 텍스트를 제2 전자 장치에게 제공할 수 있다. 또는, 예를 들어, 사용자가 제1 전자 장치에 텍 스트 입력을 하는 경우에, 제1 전자 장치는 사용자에 의해 입력된 제2 텍스트를 제2 전자 장치에게 제공하고, 제2 전자 장치가 제1 전자 장치로부터 제공된 제2 텍스트를 수신할 수도 있다. 또는, 제2 전자 장치는 제2 전자 장치에 대한 사용자의 음성 입력으로부터 제2 텍스트를 획득할 수 도 있다. 이 경우, 제2 전자 장치는 서버가 아닌 사용자의 디바이스일 수 있다. 동작 S805에서 제2 전자 장치는 제1 NLU 모델을 이용하여 제2 텍스트로부터 도메인 및 타겟 단어를 식별 할 수 있다. 제2 전자 장치는 사용자의 제2 텍스트를 제1 NLU 모델을 이용하여 분석함으로써 제2 텍스트의 도메인을 식별할 수 있다. 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초 하여 텍스트의 도메인을 식별할 수 있다. 예를 들어, \"거기는 지금 몇 시야?\"라는 제2 텍스트가 제1 NLU 모델 에 입력되고, 제1 NLU 모델로부터 제2 텍스트의 도메인이 “Time”이라는 출력 값이 출력될 수 있으며, 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제2 텍스트의 도메인이 “Time”임을 식별할 수 있다. 제2 전자 장치는 제2 텍스트 내의 타겟 단어 및 타겟 단어에 관련된 정보를 식별할 수 있다. 제2 전자 장 치는 사용자의 제2 텍스트를 제1 NLU 모델을 이용하여 분석함으로써 타겟 단어 및 타겟 단어에 대 응되는 공통 정보의 종류를 식별할 수 있다. 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 타겟 단어 및 타겟 단어에 대응되는 공통 정보의 종류를 식별할 수 있다. 예를 들어, \"거기는 지 금 몇 시야?\"라는 제2 텍스트가 제1 NLU 모델에 입력되면, 제1 NLU 모델로부터 제1 텍스트 내의 타 겟 단어가 없음을 나타내는 출력 값이 출력될 수 있으며, 제2 전자 장치는 제1 NLU 모델로부터 출 력되는 출력 값에 기초하여 제1 텍스트 내의 타겟 단어가 없음을 식별할 수 있다. 또는 예를 들어, “거기는 12월 25일이 공휴일이야?”라는 제2 텍스트가 제1 NLU 모델에 입력되면, 제2 텍스트 내의 타겟 단어가 “12월 25일”이며 “12월 25일”의 공통 정보의 종류가 “date”임은 나타내는 출력 값이 출력될 수 있으며, 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제2 텍 스트 내의 타겟 단어가 “12월 25일”이며, “12월 25일”에 대응되는 공통 정보의 종류가 “date”임을 식별할 수 있다. 동작 S810에서 제2 전자 장치는 공통 정보의 생성이 필요한지를 판단할 수 있다. 제2 전자 장치는 제2 텍스트 내에 타겟 단어가 포함되어 있는지 여부, 제2 텍스트 이전에 입력된 텍스트들의 의미, 및 공통 정보 DB에 저장된 공통 정보를 고려하여 제2 텍스트 내의 타겟 단어에 대한 공통 정보의 생성이 필요한지를 결 정할 수 있다. 예를 들어, 제2 텍스트 내에 타겟 단어가 포함되지 않은 경우에, 제2 전자 장치는 공통 정 보를 생성하지 않을 것을 결정할 수 있다. 또한, 예를 들어, 제2 텍스트 내의 타겟 단어와 동일한 타겟 단어에 대응되는 공통 정보가 공통 정보 DB에 이미 저장되어 있는 경우에, 제2 전자 장치는 공통 정보를 생성하지 않을 것을 결정할 수 있다. 또한, 예를 들어, 제2 텍스트 내의 타겟 단어가 신규의 타겟 단어인 경우 에, 제2 전자 장치는 공통 정보를 생성할 것을 결정할 수 있다. 동작 S810에서의 판단 결과, 공통 정보의 생성이 필요하다고 판단되면, 동작 S815에서 제2 전자 장치는 제2 텍스트 내의 타겟 단어에 대응되는 공통 정보를 생성할 수 있다. 제2 전자 장치는 타겟 단어를 나타 내는 세부적인 데이터를 공통 정보로서 생성할 수 있으며, 복수의 보이스 어시스턴트 모듈에서 공통으로 식별될 수 있는 포맷에 따라 공통 정보를 생성할 수 있다. 예를 들어, “거기 대신에 서울 날씨는 어때?”라는 제2 텍스트가 제1 NLU 모델에 입력될 수 있다. 이 경 우, 제2 텍스트 내의 타겟 단어 ‘서울’에 대응되는 공통 정보가 weather 도메인 및 공통 정보 종류 location 에 연관되어 생성될 수 있다. 동작 S820에서 제2 전자 장치는 공통 정보 DB에 저장된 공통 정보를 추가 또는 수정할 수 있다. 제 2 전자 장치는 제2 텍스트 내의 타겟 단어에 대응되는 공통 정보를 공통 정보 DB에 추가할 수 있다. 예를 들어, 제2 텍스트 내의 타겟 단어가 신규의 단어이면, 제2 전자 장치는 제2 텍스트 내의 타겟 단어에 대응되는 공통 정보를 제2 텍스트가 획득된 순서에 따라 이전에 저장된 공통 정보에 누적하여 저장할 수 있다. 예를 들어, 제2 전자 장치는 공통 정보 DB에 저장된 공통 정보의 일부를 삭제할 수 있다. 공통 정 보 DB에 저장될 공통 정보의 수가 미리 설정되어 있으며, 미리 설정된 수의 공통 정보가 공통 정보 DB에 이미 저장되어 있는 경우에, 제2 전자 장치는 제2 텍스트 내의 타겟 단어에 대응되는 공통 정 보를 저장하기 위하여 공통 정보 DB에 저장되어 있는 공통 정보 중에서 가장 먼저 저장되어 있는 공통 정 보를 삭제할 수 있다. 예를 들어, 제2 전자 장치는 공통 정보 DB에 저장된 공통 정보를 제2 텍스트 내의 타겟 단어에 대 응되는 공통 정보로 대체할 수 있다. 제2 텍스트 내의 타겟 단어의 공통 정보와 동일한 종류의 공통 정보가 공 통 정보 DB에 저장되어 있는 경우에, 제2 전자 장치는 공통 정보 DB에 저장되어 있는 동일한 종류의 공통 정보를 삭제를 제2 텍스트 내의 타겟 단어의 공통 정보로 대체할 수 있다. 예를 들어, 제1 텍스트가 “런던 날씨 어때?”이면, 타겟 단어인 ‘런던’에 대응되는 공통 정보가 weather 도 메인 및 공통 정보 종류 location 에 연관되어 공통 정보 DB에 저장되고, 그 이후, “거기 대신에 서울 날씨는 어때?”라는 제2 텍스트 내의 타겟 단어 ‘서울’에 대응되는 공통 정보가 weather 도메인 및 공통 정보 종류 location에 연관되어 생성될 수 있다. 또한, 제2 전자 장치는 공통 정보 DB에 저장된 ‘런던’에 대응되는 공통 정보를 ‘서울’에 대응되는 공통 정보로 대체할 수 있다. 하지만, 제2 전자 장치가 제2 텍스트 내의 타겟 단어에 대응되는 공통 정보를 공통 정보 DB에 추가 하는 기준은 이에 한정되지 않으며, 다양한 기준에 따라 공통 정보 DB가 수정될 수 있다. 동작 S825에서 제2 전자 장치는 제2 텍스트의 해석을 위한 공통 정보를 추출할 수 있다. 일 실시예에 따르면, 제2 전자 장치는 제 2 텍스트의 도메인에 관련하여 저장된 공통 정보들을 공통 정보 DB로부터 추출할 수 있다. 제2 전자 장치는 동작 S805에서 식별된 제2 텍스트의 도메인에 기초하여, 제2 텍스트의 도메인과 동일한 도메인에 대응되는 공통 정보들을 공통 정보 DB로부터 추출할 수 있다. 예를 들어, 제2 텍스트의 도메인이 “time”이면, 제2 전자 장치는 공통 정보 DB에 저장 된 공통 정보들 중에서 도메인 “time”에 대응되는 공통 정보들을 공통 정보 DB로부터 추출할 수 있다. 또는, 일 실시예에 따르면, 제2 전자 장치는 제2 텍스트의 도메인과 무관하게 공통 정보 DB에 저장 된 모든 또는 일부의 공통 정보들을 공통 정보 DB로부터 추출할 수 있다. 이 경우에, 제2 전자 장치 는 공통 정보 DB에 저장된 공통 정보들 중에서 최근에 저장된 기설정된 개수의 공통 정보들을 추출 할 수 있으나, 이에 제한되지 않는다. 또는, 일 실시예에 따르면, 제2 전자 장치는 제2 텍스트 내의 대용어에 대응되는 공통 정보만 공통 정보 DB로부터 추출할 수 있다. 동작 S805에서 제1 NLU 모델로부터 출력된 출력 값은 대용어 및 대용어 에 대응되는 공통 정보의 종류를 포함할 수 있다. 이 경우, 제2 전자 장치는 제1 NLU 모델로부터 출력되는 출력 값에 기초하여 제2 텍스트 내의 대용어 및 대용어에 대응되는 공통 정보의 종류를 식별할 수 있 다. 예를 들어, 제1 NLU 모델로부터 “거기\" 및 “location”이 출력되면, 제2 전자 장치는 제2 텍 스트 내의 대용어가 “거기”이며, 대용어 “거기”에 대응되는 공통 정보의 종류가 “location”임을 식별할 수 있다. 또한, 제2 전자 장치는 제2 텍스트 내의 대용어에 대응되는 공통 정보의 종류와 동일한 공통 정 보의 종류를 가지는 공통 정보들을 공통 정보 DB로부터 추출할 수 있다. 예를 들어, 제2 전자 장치(200 0)는 공통 정보의 종류가 “location”로 분류된 공통 정보를 공통 정보 DB로부터 추출할 수 있다. 동작 S830에서 제2 전자 장치는 제2 NLU 모델을 이용하여 제2 텍스트를 해석할 수 있다. 일 실시예에 따르면, 제2 전자 장치는 추출된 공통 정보 및 제2 텍스트를 제2 NLU 모델에 입력할 수 있다. 제2 전자 장치는 추출된 공통 정보를 제2 NLU 모델에 적합한 포맷으로 변환하고, 변환된 공통 정보를 제2 텍스트와 함께 제2 NLU 모델에 입력할 수 있다. 이 경우, 제2 NLU 모델은 대용어 를 포함하는 텍스트 및 공통 정보에 기초하여 텍스트의 의미를 해석하도록 훈련된 모델일 수 있으며, 제2 NLU 모델은 대용어에 대응되는 공통 정보의 의미를 고려하여 제2 텍스트를 해석한 결과를 출력 값으로 출력할 수 있다. 예를 들어, 공통 정보 DB에 저장된 공통 정보들 및 “거기는 지금 몇 시야?”라는 제2 텍스트가 제2 NLU 모델에 입력되면, 제1 텍스트 내의 타겟 단어인 “런던”의 GPS 좌표 값을 고려하여 제2 텍스트 를 해석한 인텐트 및 파라미터들이 제2 NLU 모델로부터 출력될 수 있다. 또는, 일 실시예에 따르면, 제2 전자 장치는 제2 텍스트를 입력으로 하여 제2 NLU 모델로부터 출력 되는 출력 값 중에서 대용어에 대응하는 값을 추출된 공통 정보로 대체할 수 있다. 이 경우, 제2 NLU 모델 은 텍스트를 입력으로 하여 텍스트의 의미를 해석하도록 훈련된 모델일 수 있으며, 제2 NLU 모델은 대용어에 대응되는 공통 정보의 의미를 고려하지 않고 제2 텍스트를 해석한 결과를 출력 값으로 출력할 수 있다. 또한, 제2 전자 장치는 제2 NLU 모델에 의해 출력된 출력 값들 중에서 대용어에 대응되는 값 을 추출된 공통 정보로 대체할 수 있다. 이 경우, 추출된 공통 정보는 제2 NLU 모델의 출력 값이 가지는 포맷으로 변환되고, 변환된 공통 정보가 제2 NLU 모델에 의해 출력된 출력 값들 중에서 대용어에 대응되 는 값을 대체할 수 있다. 예를 들어, “거기는 지금 몇 시야?”라는 제2 텍스트가 제2 NLU 모델에 입력되 면 제2 텍스트를 해석한 결과로서 인텐트 및 파라미터들이 제2 NLU 모델로부터 출력되고, 대용어 제2 NLU 모델로부터 출력된 인텐트 및 파라미터들 중에서 대용어 “거기”에 관련된 파라미터가 “거기”에 대응 되는 “런던”의 GPS 좌표 값으로 대체될 수 있다. 동작 S835에서 제2 전자 장치는 공통 정보의 수정이 필요한 지를 판단하고, 공통 정보의 수정이 필요하다 고 판단되면, 동작 S840에서 제2 전자 장치는 공통 정보 DB를 수정할 수 있다. 제2 전자 장치는 제2 NLU 모델 의 출력 값을 바탕으로 공통 정보 DB에 저장된 공통 정보의 수정이 필요한 지를 판단할 수 있다. 제2 전자 장치는 제2 NLU 모델로부터 출력되는 출력 값을 이 용하여 텍스트 내의 타겟 단어를 식별하고, 타겟 단어를 나타내는 공통 정보가 공통 정보 DB에 저장된 공통 정보와 동일한 지를 판단할 수 있다. 제2 전자 장치는 식별한 타겟 단어를 나타내는 공통 정보가, 공 통 정보 DB에 저장된 공통 정보와 상이한 경우에, 공통 정보 수정 모듈은 공통 정보 DB에 저 장된 공통 정보를 수정할 수 있다. 이 경우, 제2 NLU 모델로부터 출력되는, 타겟 단어에 관련된 파라미터 들을 바탕으로, 타겟 단어에 대응되는 공통 정보가 수정될 수 있다. 예를 들어, 제2 전자 장치는 제2 NLU 모델로부터 출력되는 타겟 단어의 의미 및 타겟 단어에 대응되는 공통 정보의 종류를 바탕으로, 공통 정 보 DB에 저장된 공통 정보들 중에서 타겟 단어에 대응되는 공통 정보를 추가 또는 수정할 수 있다. 예를 들어, 제1 NLU 모델에서는 제2 텍스트 내에 포함된 타겟 단어 “서울”에 대응되는 공통 정보의 종류가 “Location”으로 출력되고, 제2 NLU 모델에서는 제2 텍스트 내에 포함된 타겟 단어 “서울”에 대응되는 공통 정보의 종류가 “Person”으로 출력되는 경우에, 제2 전자 장치는 타겟 단어 “서울”에 대응되는 공통 정보를 수정할 수 있다. 이 경우, 제2 NLU 모델은 제2 텍스트의 도메인에 특화된 모델일 수 있으며, 제2 전자 장치가 제2 NLU 모델을 이용하여 공통 정보를 생성 또는 수정함으로써, 제2 텍스트 내의 타겟 단어에 관하여 보다 정확한 공통 정보가 공통 정보 DB에 저장될 수 있게 된다. 또한, 제2 전자 장치는 보이스 어시스턴트 서비스를 통해 사용자와 송수신한 데이터를 바탕으로, 공통 정 보 DB에 저장된 공통 정보를 수정할 수도 있다. 공통 정보 수정 모듈은, 예를 들어, 사용자 입력으 로부터 생성된 텍스트, 후술할 NLG 모델을 통해 생성된 응답 메시지, 사용자의 의도에 따른 제1 전자 장 치 또는 다른 디바이스(미도시)의 기능 중 적어도 하나에 기초하여, 공통 정보 DB에 저장된 공통 정보를 수정할 수 있다. 동작 S845에서 제2 전자 장치는 제2 텍스트에 대한 응답 정보를 생성하고 동작 S850에서 제2 전자 장치 는 생성된 응답 정보를 제공할 수 있다. 동작 S845 및 동작 S850은 동작 S730 및 동작 S735에 대응되며, 이에 대한 설명은 편의상 생략하도록 한다. 도 9는 본 개시의 일 실시예에 따른 공통 정보를 고려한 제2 텍스트의 해석 결과가 제2 NLU 모델로부터 출력되는 예시를 나타내는 도면이다. 도 9를 참조하면, 대용어가 포함된 제2 텍스트인 “거기는 지금 몇 시야?” 및 추출된 공통 정보가 제2 NLU 모 델에 입력되면, 제2 NLU 모델은 대용어에 대응되는 공통 정보에 기초한, 제2 텍스트의 해석 결과를 나타내는 인텐트 및 파라미터들을 출력할 수 있다. 예를 들어, 제2 NLU 모델은 인텐트인 ‘시간 정보 제 공’을 출력하고, 파라미터들인 ‘현재(time)’ 및 ‘런던(GeoPoint(Lat:51.50853, long:-0.12574))’을 출력 할 수 있다. 도 9에서는 추출된 공통 정보가 제2 NLU 모델에 그대로 입력되는 것으로 설명되었지만 이에 제한되지 않는다. 추출된 공통 정보는 제2 NLU 모델이 해석할 수 있는 포맷으로 전처리되고, 전처리된 공 통 정보가 제2 NLU 모델에 입력될 수도 있다. 또한, 도 9에서는 런던의 GPS 값이 제2 NLU 모델로부 터 출력되는 것으로 설명되었지만, 이에 제한되지 않는다. 제2 전자 장치가 사용자에게 보이스 어시스턴 트 서비스를 제공하기 위하여 텍스트의 해석 결과로서 이용하는 기설정된 포맷의 값이 제2 NLU 모델로부 터 출력될 수 있다. 도 10은 본 개시의 일 실시예에 따른 제2 NLU 모델의 출력 값의 일부를 공통 정보로 대체하는 예시를 나 타내는 도면이다. 도 10을 참조하면, 대용어가 포함된 제2 텍스트인 “거기는 지금 몇 시야?” 가 제2 NLU 모델에 입력되면, 제2 NLU 모델은 대용어에 대응되는 공통 정보가 반영되지 않은, 제2 텍스트의 해석 결과를 나 타내는 인텐트 및 파라미터들을 출력할 수 있다. 예를 들어, 제2 NLU 모델은 인텐트인 ‘시간 정보 제공 ’을 출력하고, 파라미터들인 ‘현재(time)’ 및 ‘거기(location)’을 출력할 수 있다. 이후, 제2 전자 장치는 제2 NLU 모델의 출력 값들 중에서 대용어인 ‘거기(location)’에 대응되는 공통 정보를 공통 정보 DB로부터 추출하고, 대용어인 ‘거기(location)’를 추출된 공통 정보로 대체할 수 있다. 예를 들어, 제2 전자 장치는 대용어인 ‘거기(location)’를 ‘런던(GeoPoint(Lat:51.50853, long:-0.12574))’로 대체할 수 있다. 도 10에서는 제2 NLU 모델로부 터 출력된 값이 GPS 값으로 대체되는 것으로 설명되었지만, 이에 제한되지 않는다. 제2 전자 장치가 사용 자에게 보이스 어시스턴트 서비스를 제공하기 위하여 텍스트의 해석 결과로서 이용하는 기설정된 포맷의 값이 제2 NLU 모델로부터 출력된 값을 대체할 수 있다.도 11은 본 개시의 일 실시예에 따른 공통 정보가 생성되고 이용되는 예시를 나타내는 도면이다. 도 11을 참조하면, 날씨 뉴스를 제공하는 보이스 어시스턴트 모듈에서 9.26.16 버전의 기설정된 형식을 가 지는 날씨와 관련된 위치 값인 GeoPoint가 식별되고, 식별된 위치 값인 GeoPoint를 나타내는 소정의 포맷의 공통 정보인 BaseGeoPoint가 생성되어 저장될 수 있다. 또한, 세계 시계를 제공하는 보이스 어시스턴트 모듈은 공통 정보인 BaseGeoPoint로부터 9.26.28 버 전의 기설정된 형식을 가지는 위치 값인 GeoPoint을 식별하고, 위치에 대응되는 시간 정보를 제공하는데 위치 값 GeoPoint을 이용할 수 있다. 또한, 위치 값 GeoPoint은 세계 시계를 제공하는 보이스 어시스턴트 모듈이 이용할 수 있는 값으로 변환될 수 있다. 예를 들어, 세계 시계를 제공하는 보이스 어시스턴트 모듈은 위치 값 GeoPoint에 대 응되는 지도 상의 장소 값인 BaseLocation을 생성하고, 생성된 장소 값 BaseLocation이 해당 장소에 서의 현재 날짜 및 현재 시각을 제공하는데 이용되도록 할 수 있다. 이 경우, 예를 들어, GeoPoint는 9.26.16 버전의 지리 정보를 관리하는 보이스 어시스턴트 모듈에 의해 운 용되는 데이터이며, GeoPoint는 9.26.28 버전의 지리 정보를 관리하는 보이스 어시스턴트 모듈에 의해 운 용되는 데이터일 수 있으나, 이에 제한되지 않는다. 또한, 상기에서는, 위치 값 GeoPoint이, 보이스 어시스턴트 모듈에 의해, 보이스 어시스턴트 모듈 이 이용할 수 있는 값으로 변환되는 것으로 설명되었지만, 이에 제한되지 않는다. 위치 값 GeoPoint 이 다른 보이스 어시스턴트 모듈에 의해 변환될 수도 있다. 예를 들어, 위치 값 GeoPoint에 대응되는 지도 상의 장소 값인 BaseLocation가, 9.26.28 버전의 지리 정보를 관리하는 보이스 어시스턴트 모듈에 의해 생 성되고, 생성된 장소 값이 세계 시계를 제공하는 보이스 어시스턴트 모듈에 의해 이용될 수도 있다. 도 12a는 본 개시의 일 실시예에 따른 보이스 어시스턴트 서비스의 제공 결과를 고려하여 동일한 종류의 공통 정보들 중 일부가 선택되어 저장되는 예시를 나타내는 도면이다. 도 12a를 참조하면, “종로에서 가까운 기차역을 알려줘.”라는 사용자의 텍스트로부터 “종로”의 위치를 나타 내는 공통 정보가 생성될 수 있다. 또한, 사용자의 텍스트에 대한 응답 메시지인 “서울역이 가까워요.” 가 사 용자에게 제공될 수 있다. 이후, “고마워.”라는 사용자의 텍스트가 획득되면, 제2 전자 장치는 사용자의 의도에 관한 올바른 응답 메시지가 사용자에게 제공되었음을 식별하고, “서울역”의 위치를 나타내는 공통 정보를 공통 정보 DB에 저장할 수 있다. 또는, “다른 곳을 알려줘.”라는 사용자의 텍스트가 획득되면, 제2 전자 장치는 사용자의 의도에 관한 잘못된 응답 메시지가 사용자에게 제공되었음을 식별하고, “종로”의 위치를 나타내는 공통 정보를 공통 정보 DB에 저장할 수 있다. 도 12b는 본 개시의 일 실시예에 따른 보이스 어시스턴트 서비스의 제공 결과를 고려하여 상이한 종류의 공통 정보들 중 일부가 선택되어 저장되는 예시를 나타내는 도면이다. 도 12b를 참조하면, “내일 오후 3시의 일정을 알려줘.”라는 사용자의 텍스트로부터 “오후 3시”를 나타내는 공통 정보가 생성될 수 있다. 또한, 사용자의 텍스트에 대한 응답 메시지인 “오후 3시에 삼성 R&D 센터에서 미 팅이 있어요.”가 사용자에게 제공될 수 있다. 이후, “고마워.”라는 사용자의 텍스트가 획득되면, 제2 전자 장치는 사용자의 의도에 관한 올바른 응답 메시지가 사용자에게 제공되었음을 식별하고, “오후 3시”를 나타내는 공통 정보 및 “삼성 R&D 센터”의 위치 를 나타내는 공통 정보를 공통 정보 DB에 저장할 수 있다. 또는, “좀 더 구체적으로 알려줘.”라는 사용자의 텍스트가 획득되면, 제2 전자 장치는 사용자의 의도에 관한 잘못된 응답 메시지가 사용자에게 제공되었음을 식별하고, “오후 3시”를 나타내는 공통 정보를 공통 정 보 DB에 저장할 수 있다.도 12c는 본 개시의 일 실시예에 따른 보이스 어시스턴트 서비스의 제공 결과 및 사용자의 추가 입력을 바탕으 로 공통 정보들 중 일부가 선택되어 저장되는 예시를 나타내는 도면이다. 도 12c를 참조하면, “서울역 근처의 맛집을 알려줘.”라는 사용자의 텍스트로부터 “서울역”의 위치를 나타내 는 공통 정보가 생성될 수 있다. 또한, 사용자의 텍스트에 대한 응답 메시지인 “50개의 맛집이 검색되었어요. 관심있는 맛집을 선택해 주세요.”가 사용자에게 제공될 수 있다. 이후, 사용자가 50개의 맛집 중에서 관심을 가지는 적어도 하나의 맛집을 선택하면, 제2 전자 장치는 사용자에 의해 선택된 맛집의 위치를 나타내는 공통 정보를 생성할 수 있다. 또한, 제2 전자 장치는 “서울역”의 위치를 나타내는 공통 정보 및 사용자 에 의해 선택된 맛집의 위치를 나타내는 공통 정보를 공통 정보 DB에 저장할 수 있다. 도 12a 내지 도 12c에서는 보이스 어시스턴트 서비스의 제공 결과를 바탕으로 공통 정보들을 생성하고 저장하는 예시들을 설명하였지만, 공통 정보를 생성하고 저장하는 예시는 이에 제한되지 않는다. 공통 정보를 생성하고 저장하고 선택하기 위한 규칙이, 예를 들어, 사용자 질의의 종류, 보이스 어시스턴트 서비스의 특성, 및 사용자 의 피드백 등에 따라 다양하게 설정될 수 있다. 본 개시의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함 하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘 발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 본 명세서에서, “a, b 또는 c 중 적어도 하나를 포함한다”는 “a만 포함하거나, b만 포함하거나, c만 포함하거나, a 및 b를 포함하거나, b 및 c를 포함하거나, a 및 c를 포함하거나, a, b 및 c를 모두 포함하는 것 을 의미할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시에 따른 대용어를 포함하는 텍스트에 관련된 보이스 어시스턴트 서비스를 제공하는 방법에 있어서, 사용 자의 음성을 인식하고 의도를 해석하기 위한 방법으로, 디바이스는, 예를 들어, 마이크를 통해 아날로그 신호인 음성 신호를 수신하고, ASR(Automatic Speech Recognition)모델을 이용하여 음성 부분을 컴퓨터로 판독 가능한 텍스트로 변환할 수 있다. 또한, 자연어 이해(Natural Language Understanding, NLU) 모델을 이용하여 변환된 텍스트를 해석하여, 사용자의 발화 의도가 획득될 수 있다. 여기서 ASR 모델 또는 NLU 모델은 인공지능 모델일 수 있다. 인공지능 모델은 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전용 프로세서에 의해 처리될 수 있다. 인공지능 모델은 학습을 통해 만들어 질 수 있다. 여기서, 학습을 통해 만들어진다는 것 은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특 성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 인공지 능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산 을 수행한다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리(Natural Language Processing), 기계 번역(Machine Translation), 대화 시스템(Dialog System), 질의 응답(Question Answering), 음성 인식/합성(Speech Recognition/Synthesis) 등을 포함한다. 본 개시에 따른 대용어를 포함하는 텍스트에 관련된 보이스 어시스턴트 서비스를 제공하는 방법에 있어서, 텍스 트로부터 타겟 단어에 대응되는 공통 정보를 결정하기 위해 인공지능 모델이 이용할 수 있다. 프로세서는 텍스 트에 대해 전처리 과정을 수행하여 인공지능 모델의 입력으로 사용하는 데에 적합한 형태로 변환할 수 있다. 인 공지능 모델은 학습을 통해 만들어 질 수 있다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도 록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술로서, 지식/확률 기반 추론(Knowledge based Reasoning), 최적화 예측(Optimization Prediction), 선호 기반 계획(Preference-based Planning), 추천 (Recommendation) 등을 포함한다"}
{"patent_id": "10-2020-0143003", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2020-0143003", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일실시예에 따른 보이스 어시스턴트 서비스를 제공하는 시스템의 예시를 나타내는 도면이다. 도 2는 본 개시의 일 실시예에 따른 제2 전자 장치의 블록도이다. 도 3은 본 개시의 일 실시예에 따른 공통 정보 관리 모듈이 제1 텍스트로부터 공통 정보를 생성하는 예시 를 나타내는 도면이다. 도 4는 본 개시의 일 실시예에 따른 타겟 단어를 포함하는 텍스트에 대응되는 도메인의 예시를 나타내는 도면이다. 도 5는 본 개시의 일 실시예에 따른 타겟 단어에 대응되는 공통 정보의 예시를 나타내는 도면이다. 도 6은 본 개시의 일 실시예에 따른 제2 텍스트 내의 대용어에 대응되는 공통 정보가 획득되는 예시를 나타내는 도면이다. 도 7은 본 개시의 일 실시예에 따른 제2 전자 장치가 제1 텍스트에 대한 공통 정보를 생성하고 제1 텍스 트에 대한 응답을 제공하는 방법의 흐름도이다. 도 8은 본 개시의 일 실시예에 따른 제2 전자 장치가 제2 텍스트에 대한 공통 정보를 생성하고 제2 텍스 트에 대한 응답을 제공하는 방법의 흐름도이다. 도 9는 본 개시의 일 실시예에 따른 공통 정보를 고려한 제2 텍스트의 해석 결과가 제2 NLU 모델로부터 출력되는 예시를 나타내는 도면이다. 도 10은 본 개시의 일 실시예에 따른 제2 NLU 모델의 출력 값의 일부를 공통 정보로 대체하는 예시를 나 타내는 도면이다. 도 11은 본 개시의 일 실시예에 따른 공통 정보가 생성되고 이용되는 예시를 나타내는 도면이다. 도 12a는 본 개시의 일 실시예에 따른 보이스 어시스턴트 서비스의 제공 결과를 고려하여 동일한 종류의 공통 정보들 중 일부가 선택되어 저장되는 예시를 나타내는 도면이다. 도 12b는 본 개시의 일 실시예에 따른 보이스 어시스턴트 서비스의 제공 결과를 고려하여 상이한 종류의 공통 정보들 중 일부가 선택되어 저장되는 예시를 나타내는 도면이다. 도 12c는 본 개시의 일 실시예에 따른 보이스 어시스턴트 서비스의 제공 결과 및 사용자의 추가 입력을 바탕으 로 공통 정보들 중 일부가 저장되는 예시를 나타내는 도면이다."}
