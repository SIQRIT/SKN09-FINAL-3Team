{"patent_id": "10-2020-0135407", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0051690", "출원번호": "10-2020-0135407", "발명의 명칭": "단말 장치, 이에 의해 수행되는 방법 및 인터페이싱 장치", "출원인": "에스케이텔레콤 주식회사", "발명자": "장병순"}}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터망과 연결되는 통신부와,사용자 인터페이스부와,텍스트 타입의 통화 서비스에 대한 요청 신호가 상기 데이터망을 통해 송신된 뒤, 상대방 측 단말 장치로부터의음성을 변환한 텍스트 및 상기 상대방의 감정을 포함하는 부가 정보가 상기 데이터망을 통해 상기 통신부에서수신되면, 상기 수신된 텍스트 및 부가 정보가 상기 사용자 인터페이스부에서 표시되도록 제어하는 프로세서를포함하는단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 부가 정보는,상기 음성에 기반하여 도출된 것인단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 요청 신호의 송신은,상기 통신부와 연결되는 통화망을 통해 상기 단말 장치와 상기 상대방 측 단말 장치가 음성 통화를 시도하거나또는 수행하는 중, 상기 단말 장치의 입장에서 요청이 있으면 수행되는단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 사용자 인터페이스부는,상기 부가 정보를 그에 대응되는 이모티콘, 특수문자 또는 텍스트의 형태로서 표시하는단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 통신부는,상기 텍스트 및 상기 부가 정보와 함께 상기 음성을 추가적으로 수신하고,상기 단말 장치는,상기 수신된 음성을 출력하는 스피커를 더 포함하는단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2022-0051690-3-제 1 항에 있어서,상기 통신부는,상기 텍스트 및 상기 부가 정보에 대한 상기 단말 장치 입장에서의 추천 응답 텍스트를 수신하고,상기 사용자 인터페이스부는,상기 추천 응답 텍스트를 표시하는단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 추천 응답 텍스트는,상기 단말 장치가 상기 텍스트에 대응하여 응답했었던 각 사례의 빈도에 기반한 것인단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 사용자 인터페이스부는 상기 단말 장치의 사용자로부터 텍스트 및 상기 사용자의 감정 정보를 입력받고,상기 프로세서는, 상기 사용자로부터의 텍스트 및 상기 사용자의 감정 정보가 상기 데이터망을 통해 송신되도록제어하며, 상기 사용자 인터페이스부는,상기 사용자로부터의 텍스트 및 감정에 기반한 음성이 상기 상대방 측 단말 장치에서 출력 완료되었는지 여부를표시하는단말 장치."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "단말 장치가 수행하는 방법으로서,텍스트 타입의 통화 서비스에 대한 요청 신호를 데이터망을 통해 송신하는 단계와,상대방 측 단말 장치로부터의 음성을 변환한 텍스트 및 상기 상대방의 감정을 포함하는 부가 정보가 상기 데이터망을 통해 수신되는 단계와,상기 수신된 텍스트 및 부가 정보를 표시하는 단계를 포함하는방법."}
{"patent_id": "10-2020-0135407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 서비스의 인터페이싱 장치가 수행하는 인공지능 서비스의 인터페이싱 방법으로서,통화망과 연결된 상대방 측 단말 장치로부터 음성이 수신되면, 상기 음성을 인공지능 서비스 제공 서버에게 전달하는 단계와,상기 음성을 변환한 텍스트 및 상기 음성에 기반하여 도출된 상기 상대방 측 단말 장치의 사용자 감정을 나타내는 부가 정보가 상기 인공지능 서비스 제공 서버로부터 수신되면, 상기 상대방 측 단말 장치에게 상기 텍스트및 상기 부가 정보를 전달하는 단계를 포함하는인공지능 서비스의 인터페이싱 방법."}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 단말 장치는 데이터망과 연결되는 통신부와, 사용자 인터페이스부와, 텍스트 타입의 통화 서비 스에 대한 요청 신호가 상기 데이터망을 통해 송신된 뒤, 상대방 측 단말 장치로부터의 음성을 변환한 텍스트 및 상기 상대방의 감정을 포함하는 부가 정보가 상기 데이터망을 통해 상기 통신부에서 수신되면, 상기 수신된 텍스 트 및 부가 정보가 상기 사용자 인터페이스부에서 표시되도록 제어하는 프로세서를 포함한다"}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 단말 장치, 이에 의해 수행되는 방법 및 인터페이싱 장치에 관한 것이다."}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트폰 또는 스마트 패드와 같은 스마트 기기는 음성/영상 통화 기능, 그리고 데이터 통신 기능을 제공한다. 사용자는 스마트 기기가 제공하는 데이터 통신 기능을 통해서, 상대방과 메시지를 이용한 채팅을 할 수 있으며, 또한 실시간으로 지도, 음악, 뉴스 또는 사진과 같은 컨텐츠를 공유할 수도 있다. 한편 최근에는 인공지능 서비스를 제공하는 서버가 등장하고 있다. 이러한 인공지능 서비스 제공 서버는 학습 기능을 갖추고 있기에, 사용될수록 수준 높은 서비스를 제공할 수 있다. 스마트 기기는 인공지능 서비스 제공 서버에 데이터 통신 기능을 이용하여 접속하여서 다양한 서비스를 제공받 을 수 있다. 예컨대, 사용자는 스마트 기기를 통해 인공지능 서비스 제공 서버에게 날씨나 개인 스케쥴에 대한 간단한 질문 뿐 아니라 보다 복잡하고 고도한 정보에 대한 질의까지도 할 수 있으며, 이에 대한 응답을 제공받 을 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국특허공개공보, 제 2011-0041322호 (2011.04.21. 공개)"}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "사용자가 스마트 기기를 통해 상대방과 음성 또는 영상 통화를 시도하거나 진행함에 있어서, 상황에 따라 통화 가 곤란한 상황이 발생될 수 있다. 예컨대 영화가 상영 중인 극장 내에서 또는 어린 아기가 자고 있는 방에서, 사용자는 상대방과 음성 또는 영상 통화를 하기가 곤란할 수 있다. 이 때 사용자와 상대방과 통화를 종료하고 메시지를 통한 채팅을 수행할 수 있다. 그런데 통화를 하기 곤란한 대상은 사용자이지 상대방은 아니다. 상대방으로서는 메시지를 통한 채팅보다 통화가 편함에도 불구하고, 사용 자가 겪는 곤란함으로 인해 메시지를 통해 채팅을 해야 하는 상황일 수도 있다. 이에, 본 발명의 해결하고자 하는 과제는, 사용자가 스마트 기기를 통해 상대방과 통화를 시도하거나 통화를 진 행함에 있어서, 상황에 따라 통화가 곤란한 상황이 발생되었을 때, 사용자는 통화를 종료하지 않고도 메시지를 통한 채팅으로 상대방과 대화를 수행할 수 있을 뿐 아니라, 상대방 역시 통화를 종료하지 않음은 물론 메시지를 통한 채팅이 아닌 통화를 그대로 수행할 수 있도록 하는 기술을 제공하는 것이다. 또한, 이러한 기술이 제공되도록 하는 데에 있어서, 스마트 기기만에 구현되어 있는 시스템이 아닌, 공중망에 구현되어 있는 시스템을 통해 이러한 기술이 제공되도록 하는 것이 본 발명의 해결하고자 하는 과제에 포함될 수 있다. 다만, 본 발명의 해결하고자 하는 과제는 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 해 결하고자 하는 과제는 아래의 기재로부터 본 발명이 속하는 통상의 지식을 가진 자에게 명확하게 이해될 수 있 을 것이다"}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 예에 따른 단말 장치는 데이터망과 연결되는 통신부와, 사용자 인터페이스부와, 텍스트 타입의 통화 서비스 에 대한 요청 신호가 상기 데이터망을 통해 송신된 뒤, 상대방 측 단말 장치로부터의 음성을 변환한 텍스트 및 상기 상대방의 감정을 포함하는 부가 정보가 상기 데이터망을 통해 상기 통신부에서 수신되면, 상기 수신된 텍 스트 및 부가 정보가 상기 사용자 인터페이스부에서 표시되도록 제어하는 프로세서를 포함한다. 일 예에 따른 방법은 단말 장치가 수행하며, 텍스트 타입의 통화 서비스에 대한 요청 신호를 데이터망을 통해 송신하는 단계와, 상대방 측 단말 장치로부터의 음성을 변환한 텍스트 및 상기 상대방의 감정을 포함하는 부가 정보가 상기 데이터망을 통해 수신되는 단계와, 상기 수신된 텍스트 및 부가 정보를 표시하는 단계를 포함하여 수행된다. 일 예에 따른 인터페이싱 방법은 인공지능 서비스의 인터페이싱 장치가 수행하며, 통화망과 연결된 상대방 측 단말 장치로부터 음성이 수신되면, 상기 음성을 인공지능 서비스 제공 서버에게 전달하는 단계와, 상기 음성을 변환한 텍스트 및 상기 음성에 기반하여 도출된 상기 상대방 측 단말 장치의 사용자 감정을 나타내는 부가 정보 가 상기 인공지능 서비스 제공 서버로부터 수신되면, 상기 상대방 측 단말 장치에게 상기 텍스트 및 상기 부가 정보를 전달하는 단계를 포함하여 수행된다."}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따르면 단말 장치와 단말 장치가 서로 간에 음성 또는 영상 통화를 시도하거나 진행하는 중에, 어 느 하나의 단말 장치는 음성 또는 영상 통화를 유지하지만 다른 하나의 단말 장치는 메시지를 통한 채팅 방식으 로 단말 장치와 소통을 할 수 있다,"}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2020-0135407", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 일 실시예에 따른 인공지능 인터페이싱 장치가 적용된 이동통신망을 개념적으로 도시한 도면이 다. 다만, 도 1은 예시적인 것에 불과하므로, 인공지능 인터페이싱 장치(이하, 인터페이싱 장치라고 지칭)가 도 1에 도시된 이동통신망에만 적용되는 것으로 한정 해석되지는 않는다. 도 1을 참조하면, 이동통신망은 인터페이싱 장치, 인공지능 서비스 제공 서버, 통화망 및 데이터망을 포함할 수 있다. 제1 단말 장치(300/1)와 제2 단말 장치(300/2)는 각각 이러한 이동통신망(의 통화망이나 데이터망)에 접속하는 단말을 예시적으로 도시한 것이며, 각 단말 장치 (300/1,300/2)는 이들 이동통신망에 접속하여서 음성/영상 통화나, 또는 인공지능 서비스와 같은 데이터 서 비스를 제공받을 수 있다. 먼저, 인공지능 서비스 제공 서버는 인공지능 서비스를 제공하는 서버를 지칭한다. 인공지능 서비스 제공 서버는 단말 장치(300/1,300/2) 이외에도 다양한 단말이나 서버와 연결될 수 있으며, 이들 각각에게 다양 한 인공지능 서비스를 제공할 수 있다. 이러한 인공지능 서비스 제공 서버의 구성은 도 2에 도시되어 있다. 도 2를 참조하면, 인공지능 서비스 제공 서버는 인공지능 처리를 수행하는 인공지능 처리부(intelligence workflow, IWF), 자연어를 처 리하는 자연어 처리부(natural language understand), 음성 합성을 수행하는 음성 합성부(text to speech, TTS) 모듈 및 텍스트 합성을 수행하는 텍스트 합성부(speech to text, STT)를 포함할 수 있 다. 아울러, 이러한 인공지능 서비스 제공 서버는 복수 개의 서버로 이루어진 서버군으로서 형성될 수 있 다. 이 중, 인공지능 처리부는 인간의 사고 처리 방식을 모방해서 인공지능 서비스를 제공하도록 마련된 구성 이다. 예컨대 인공지능 처리부는 이미지 인식, 이미지 캡션, 언어 인식 또는 대화 등와 같은 기능을 수행 할 수 있으며, 이를 위해 머신러닝이나 딥러닝와 같은 방식에 의해 사전에 학습된 것일 수 있다. 다음으로, 자연어 처리부는, 질문을 입력받으면 이를 인지하고 분석한 뒤, 그에 대한 추천 응답을 제공하 는 알고리즘을 채용할 수 있다. 여기서 추천 응답이란, 예컨대 과거에 동일 사용자가 동일 또는 유사한 질문에 대답한 사례의 빈도에 기반한 것이거나 또는 타 사용자라고 하더라도 동일 또는 유사한 질문에 대답한 다양한 사례를 기반으로 추천된 응답일 수 있다. 다음으로, TTS 모듈은 사용자가 입력한 텍스트를 음성으로 합성 내지 변환해서 제공하는 모듈이다. 이 때, 텍스트를 음성으로 변환하는 알고리즘으로는 공지된 다양한 것들이 채용될 수 있다. 한편, 이러한 TTS 모듈은 음성을 합성할 때, 사용자에 대해 획득된 감정이나 기분 등을 반영할 수 있다. 이하에서 이러한 감정이나 기분 등을 나타내는 정보는 '부가 정보'라고 지칭하기로 하자. 예컨대 동일한 '안녕 하세요'라는 음성이라도 기쁘거나 반가운 감정인 경우는 소리의 크기나 톤을 상대적으로 높인다던가, 슬프거나 우울한 경우는 소리의 크기나 톤을 상대적으로 낮춘다던가 등의 방법으로, TTS 모듈은 음성을 합성할 수 있다. 이러한 예시는 도 3에 도시되어 있다. 도 3을 참조하면, TTS 모듈에 텍스트와 이모티콘이 입력되면, 이모티콘에 대응되는 기분이나 감정이 음성에 반영되어서 TTS 모듈로부터 출력될 수 있다. 이를 위해, TTS 모듈은 사용자의 감정이나 기분 등을 파악할 수 있어야 하는데, 이는 이하에서의 실시예 중 어느 하나를 채용함으로써 구현 가능하다. 첫째, TTS 모듈은, 사용자가 텍스트와 함께 입력한 이모티콘 등을 인지 내지 해석하는 모듈을 추가로 구비 할 수 있다. 예컨대 TTS 모듈에는 각각의 이모티콘마다 감정이 매핑되어 있는 테이블이 구비되어 있을 수 있다. 텍스트와 함께 웃는 이모티콘, 우는 이모티콘, 화내는 이모티콘 또는 당황한 이모티콘 등이 수신되면, TTS 모듈은 이러한 이모티콘에 대응되는 감정을 전술한 테이블로부터 획득할 수 있다. 둘째, TTS 모듈은 사람의 감정이나 기분 (또는 뉘앙스) 등을 나타내는 별도의 정보를, 단말 장치로부터 획 득할 수도 있다. 이를 위해, 예컨대, 단말 장치(300/2)에는 사용자 자신의 감정이나 기분 등을 입력하는 별도의 버튼 등이 마련되어 있을 수 있다. 만약 사용자가 소정의 텍스트를 입력하면서 자신의 감정이나 기분 등을 나타 내는 버튼을 누르면, 눌러진 버튼에 해당되는 그 사용자의 감정이나 기분 등에 대한 정보가 TTS 모듈에게 전달될 수 있다. 셋째, TTS 모듈은 텍스트에 나타난 맥락이나 분위기를 인지하는 별도의 모듈을 포함할 수도 있다. 이를 위 해 TTS 모듈에는 자연어를 이해하고 인지하는 알고리즘이 채용되어 있을 수 있다. 한편, 이러한 TTS 모듈은 채팅의 당사자로부터 텍스트가 입력되기 시작했는데 소정 시간 동안 텍스트의 입 력이 종료, 즉 완료가 되지 않을 경우, 이러한 텍스트의 입력 완료가 지연되고 있음을 나타내는 소리를 음성 사 이에 또는 음성 중간에 삽입할 수 있다. 이러한 소리의 종류에는 예컨대 '음...', '그러니까....', '잠깐 만....'과 같이, 대화에서 일반적으로 지연을 나타내는 단어가 포함될 수 있다. 다음으로, STT 모듈은 사용자가 발한 음성을 텍스트로 합성 내지 변환해서 제공하는 모듈이다. 이 때, 음 성을 텍스트로 변환하는 알고리즘으로는 공지된 다양한 것들이 채용될 수 있다. 한편, 일 실시예에 따른 STT 모듈은 사용자가 입력한 음성으로부터 사용자의 감정이나 기분 등을 판단하도 록 학습된 모듈을 포함할 수 있다. 예컨대 STT 모듈은 사용자의 음성의 주파수나 높낮이, 단어와 단어 사 이의 간격 또는 음성으로부터 파악된 문맥(context) 등에 기초해서, 음성을 발하고 있는 사용자의 상태를 기쁨, 슬픔, 우울함, 화남, 즐거움, 당황함 또는 흥분함 등으로 분류할 수 있다. 아울러, 이러한 STT 모듈은 텍스트를 합성할 때, 사용자에 대해 판단된 전술한 감정이나 기분 등을 반영할 수 있다. 예컨대 합성된 '안녕하세요'라는 텍스트에 대해, 사용자가 기쁘거나 반가운 감정인 경우에 그에 대응 되는 이모티콘 등을 텍스트의 앞이나 중간 또는 끝에 부가할 수 있고, 또한 슬프거나 우울한 감정이 경우에 그 에 대응되는 이모티콘 등을 텍스트에 동일/유사한 방식으로 부가할 수도 있다. 이러한 예시는 도 4에 도시되어 있다. 도 4를 참조하면 STT 모듈에 음성이 입력되면, 음성으로부터 파악된 기분이나 감정이 이모티콘의 형 태로 변환되어서 텍스트와 함께 STT 모듈로부터 출력될 수 있다. 다시 도 1을 참조하면, 통화망과 데이터망은 단말 장치(300/1,300/2)들이 접속하는 통신망이다. 도 5는 통화망과 데이터망에 대한 구성을 개념적으로 도시한 도면이다. 도 5를 참조하면, 통화망은 지능망이라고 지칭될 수 있으며, 예컨대 IMS(IP multimedia subsystem)일 수 있다. 이러한 통화망은 교환기망(Call Session Control Function,CSCF), 응용 서비스 노드(telephony application server, TAS) 또는 미디어 리소스 서버(media resource function, MRF)를 포함하며, 그 외에 HLR(Home Location Register), MGCF(Media Gateway Control Function), MGW(Media Gateway), SCC AS(Service Centralization and Continuity Application Server) 등을 포함할 수 있 다. 아울러, 이하에서 설명할 각 구성들이 수행하는 기능은 예시적인 것에 불과하다. 따라서, 각 구성들은 이 하에서 기술되는 기능 이외의 다른 기능들을 추가적으로 수행할 수 있다. 이 중 교환기망은 각 단말 장치(300/1,300/2)의 위치, 즉 해당 단말 장치가 어떠한 기지국에 연결되어 있 는지에 대한 정보를 획득한다. 응용 서비스 노드는 전화와 관련된 기본 기능 및 전화와 관련된 부가 서비스(call hold, swap, forward) 등을 처리한다. 예컨대 응용 서비스 노드는 단말 장치(300/2)로부터 수신된 '텍스트 타입의 통화 서비스 에 대한 요청'을 처리할 수 있다. 텍스트 타입의 통화 서비스란, 단말 장치(300/1)와 단말 장치(300/2)가 서로 간에 음성 또는 영상 통화를 시도하거나 진행하는 중에, 어느 하나의 단말 장치(300/1)는 음성 또는 영상 통화 를 유지하지만 다른 하나의 단말 장치(300/2)는 메시지를 통한 채팅 방식으로 단말 장치(300/1)와 소통을 하는 서비스를 지칭한다. 이에 대해서는 뒤에 보다 자세하게 살펴보기로 한다. 또한, 응용 서비스 노드는 단말 장치 상호 간에 통화가 연결되거나 끊긴 경우, 이를 이하에서 설명할 인터 페이싱 장치에게 통보할 수 있다. 미디어 리소스 서버는 코덱 변환을 수행한다. 코덱 변환을 통해, 서로 상이한 사양의 단말 장치 간의 패 킷 교환이 가능하다. 이를 위해, 미디어 리소스 서버는 코덱 변환 모듈을 포함할 수 있다. 미디어 리소스 서버는 미디어 데이터를 전달(forking)한다. 예컨대 미디어 리소스 서버는 제1 단말 장치(300/1)와 제2 단말 장치(300/2) 간에 음성/영상이 전달되도록 할 수 있다. 또한 미디어 리소스 서버(41 3)는 각 단말 장치(300/1,300/2)로부터 전달받은 미디어 데이터를 인터페이싱 장치에게 전달할 수 있으며, 또한 반대 방향으로 전달할 수도 있다. 이를 위해, 미디어 리소스 서버는 각 단말 장치(300/1,300/2) 또 는 인터페이싱 장치와의 통신을 위한 통신 모듈을 포함할 수 있다. 미디어 리소스 서버는 미디어 데이터를 믹싱(mixing)(또는 먹싱(muxing))한다. 미디어 데이터란 각 단말 장치(300/1,3002)에게 제공되는 음성/영상 통화, 데이터 패킷 또는 DTMF(dual tone multiple frequency) 신호 등을 포함할 수 있으며 다만 이에 한정되는 것은 아니다. 믹싱에 있어서, 미디어 리소스 서버는 다양한 객체로부터 전달받은 음원들을 서로 믹싱할 수 있다. 예컨 대, 미디어 리소스 서버는 각 단말 장치(300/1,300/2)에게 전달될 음성/영상에 인공지능 서비스 제공 서버 로부터 전달받은 음성 신호를 믹싱할 수 있으며, 또한 각 단말 장치(300/1,300/2)에게 전달될 음성/영상에 기 정의된 음원이나 영상(이하에서는 대기 음원 또는 대기 영상이라고 지칭)을 믹싱할 수 있다. 아울러, 미디 어 리소스 서버는 믹싱되는 음원들의 크기를 조절할 수 있는데, 이러한 조절은 응용 서비스 노드로부터 전달받은 명령에 의해 수행 가능하다. 이를 위해, 미디어 리소스 서버는 믹싱 모듈을 포함할 수 있다. 한편, 도시된 HLR(Home Location Register), MGCF(Media Gateway Control Function), MGW(Media Gateway), SCC AS(Service Centralization and Continuity Application Server)의 경우 이미 공지 된 구성과 동일하므로 이에 대한 설명은 생략하기로 한다. 다음으로, 데이터망은 레거시 호처리망이라고도 지칭되며, 예컨대 WCDMA와 같은 이동통신망을 의미할 수 있다. 이러한 데이터망은 각 단말 장치(300/1,300/2)에게 음성/영상 서비스를 제공할 수 있다. 또한 이러 한 데이터망은 각 단말 장치(300/1,300/2)에게 앱 기반의 소정의 서비스를 제공할 수도 있다. 데이터망은 MSC(mobile switching center) 또는 홈 위치 등록기(home location register, HLR)(42 2)를 포함하고, 그 외에 GGSN(Gateway General packet radio service Support Node), NodeB, RNC(Radio Network Controller), SGSN(Serving General packet radio service Support Node), CGS(Cellular Gateway Switch), MME(mobility management entity), PGW(packet data network gateway)를 포함하며, 이외에도 eNodeB, SGW(Serving Gateway), PCRF(Policy & Charging Rule Function), HSS(Home Subscriber Server) 등을 포함하거나 이들과 연결될 수 있다. 이러한 데이터 망은 공지된 망과 동일한 구성을 가질 수 있는 바, 이러한 데이터망에 대한 자세한 설명은 생략하기 로 한다. 다시 도 1을 참조하면, 각 단말 장치(300/1,300/2)는 통화망이나 데이터망을 구성하는 복수 개의 셀 중의 어느 하나(또는 둘 이상)의 셀에 위치하여서 음성/영상 통화 또는 인공지능 서비스와 같은 데이터 서비스 를 제공받을 수 있다. 이러한 단말 장치(300/1,300/2)는 스마트폰이나 스마트 패드 또는 태블릿 패드와 같이 다양한 형태로 구현 가능하다. 도 1에 도시된 단말 장치(300/1,300/2) 중 어느 하나의 단말 장치가 발신 단말 이면 다른 하나의 단말 장치는 수신 단말일 수 있다. 이러한 단말 장치(300/1,300/2)에 대해서는 이하의 도 6에서 보다 자세하게 살펴보기로 한다. 도 6은 일 실시예에 따른 단말 장치(300/2)의 구성에 대해 개념적으로 도시한 도면이다. 다만, 도 6에 도시된 도면은 예시적인 것에 불과한 바, 단말 장치(300/2)의 구성이 도 6에 도시된 것으로 한정 해석되지는 않는다. 아울러, 도 6에 도시된 도면 및 이에 대한 설명은 단말 장치(300/1)에 대해서도 동일하게 적용 가능하다. 도 6을 참조하면, 단말 장치(300/2)는 통신부, 사용자 인터페이스부, 스피커부, 메모리 및 프로세서를 포함하며, 또한 도시되지 않은 구성을 더 포함할 수 있다. 통신부는 3G나 4G, 5G, Wi-Fi, NFC 등의 무선 통신 모듈을 포함할 수 있다. 이러한 통신부는 도 1에 도시된 통화망 또는 데이터망과 연결된다. 사용자 인터페이스부는 입력부와 출력부를 포함한다. 입력부는 사용자로부터의 터치 등을 입력받는 구성이며, 터치 인터페이스 등을 포함할 수 있다. 이러한 입력부 를 통해 사용자는 자신이 원하는 텍스트를 입력하거나 자신이 원하는 어플리케이션 등을 터치함으로써 실행시킬 수 있으며, 특정 어플리케이션에서 특정 기능을 활성화 내지 비활성화 시킬 수 있다. 출력부는 사용자에게 다양한 정보를 제공해주는 구성이며, LED나 LCD과 같은 다양한 종류의 구성을 이용하여 구 현 가능하다. 사용자는 이러한 출력부를 통해서, 현재 단말 장치(300/2)에서 어떤 어플리케이션이 실행되고 있 는지, 해당 어플리케이션과 관련하여 어떠한 메시지가 표출되고 있는지 등을 확인 가능하다. 이 때 전술한 입력부와 출력부는 하나의 터치 인터페이스 모듈의 형태로 구현 가능하다. 스피커부는 음성을 출력하는 구성이다. 이러한 스피커부는 다양한 형태의 스피커 모듈을 통해 구현 가능하다. 사용자는 이러한 스피커부를 통해, 상대방의 음성을 듣거나 또는 어플리케이션에서 출력하는 다 양한 음향을 들을 수 있다. 메모리는 다양한 종류의 정보를 저장하는 구성이다. 또한, 메모리에는 다양한 종류의 어플리케이션이 설치될 수 있다. 프로세서는 이하에서 설명될 다양한 기능을 실행되도록 하는 구성으로서, 예컨대 마이크로프로세서에 의해 구현 가능하다. 프로세서에 대해 보다 구체적으로 살펴보면, 프로세서는 텍스트 타입의 통화 서비스에 대한 전반적인 제어를 수행한다. 예컨대 프로세서는 텍스트 타입의 통화 서비스에 대한 요청 신호가 데이터망을 통 해 송신되도록 제어한다. 이러한 제어는, 단말 장치(300/1)와 단말 장치(300/2)가 음성호를 수행하거나 음성호 를 시도하는 중, 단말 장치(300/2)의 사용자 인터페이스부를 통해 텍스트 타입의 통화 서비스에 대한 요청 이 입력되면 수행 가능하다. 한편, 전술한 요청 신호는 인공지능 서비스의 인터페이싱 장치를 통해서 인공지능 서비스 제공 서버 에게 전달된다. 이후부터는 단말 장치(300/1)로부터의 음성이나 그에 대한 부가 정보, 즉 단말 장치(300/1)의 사용자의 기분이나 감정을 나타내는 부가 정보가, 단말 장치(300/1)의 사용자 인터페이스부에서는 그에 대 응되는 텍스트나 이모티콘 또는 특수문자 등의 형태로 표시될 수 있다. 또한, 프로세서는 전술한 텍스트 타입의 통화 서비스가 진행 중에도, 단말 장치(300/1)의 사용자에 대한 음성이 스피커부(에서 출력되도록 제어할 수 있다. 한편, 텍스트 타입의 통화 서비스가 제공되는 경우, 단말 장치(300/2)의 사용자는 사용자 인터페이스부를 통해 텍스트 또는 자신의 기분이나 감정 등을 입력할 수 있다. 그러면 이러한 텍스트, 그리고 기분이나 감정 등 을 포함하는 부가 정보가 단말 장치(300/1)에게 음성 형태로 전환되어서 전달되어서 출력된다. 이 때 프로세서 는 이러한 음성이, 단말 장치(300/1)에서 출력 중인지 또는 출력 완료되었는지 여부를 추정할 수 있거나, 또는 단말 장치(300/1)로부터 출력 완료되었다는 신호를 수신받음으로써 인지할 수 있다. 그러면 프로세서(35 0)는 이렇게 추정된 것 또는 수신받은 정보를 기초로, 단말 장치(300/1)에서 음성이 출력 중이거나 출력 완료되 었다는 정보가 사용자 인터페이스부에서 표시되도록 제어할 수 있다. 도 7은 일 실시예에 단말 장치(300/2)에서 수행되는 방법에 대한 절차의 순서를 도시한 순서도이다. 다만 도 7 은 예시적인 것에 불과하다. 도 7을 참조하면, 텍스트 타입의 통화 서비스에 대한 요청 신호를 데이터망을 통해 송신하는 단계(S100)가 수행 된다. 또한, 상대방 측 단말 장치로부터의 음성을 변환한 텍스트 및 상기 상대방의 감정을 포함하는 부가 정보가 상기 데이터망을 통해 수신되는 단계(S110)가 수행된다. 또한, 상기 수신된 텍스트 및 부가 정보를 표시하는 단계(S120)가 수행된다. 다음으로, 인터페이싱 장치에 대해 살펴보기로 하자. 도 8은 도 1에 도시된 인터페이싱 장치의 구성을 도시한 도면이다. 먼저, 인터페이싱 장치는 이하에 서 설명할 기능을 수행하는 서버군에서 구현 가능하다. 아울러, 인터페이싱 장치는 ACS(Augmented Communication System) 또는 ACP(Augmented Communicatin Platform)라고 지칭될 수도 있다. 이러한 인터페이싱 장치는 전술한 메시지를 통한 채팅 방식의 통화 서비스(이하, '텍스트 타입의 통화 서 비스'라고 지칭될 수도 있음)를 지원할 수 있다. 즉, 인터페이싱 장치는, 단말 장치(300/1)와 단말 장치 (300/2)가 서로 간에 음성 또는 영상 통화를 시도하거나 진행하는 중에, 어느 하나의 단말 장치(300/1)는 음성 또는 영상 통화를 유지하지만 다른 하나의 단말 장치(300/2)는 메시지를 통한 채팅 방식으로 단말 장치(300/1) 와 소통을 하도록 지원할 수 있다. 이를 위해, 인터페이싱 장치는 단말 장치(300/1)로부터의 음성을 인공 지능 서비스 제공 서버에게 제공하여서 그에 대응되는 텍스트를 제공받을 수 있고, 이렇게 제공받은 텍스 트를 단말 장치(300/2)에게 제공할 수 있다. 뿐만 아니라, 인터페이싱 장치는 단말 장치(300/2)로부터의 텍스트를 인공지능 서비스 제공 서버에게 제공하여서 그에 대응되는 음성을 제공받을 수 있고, 이렇게 제 공받은 음성을 단말 장치(300/1)에게 제공할 수 있다. 이러한 인터페이싱 장치는, 도 8을 참조하면 인공지능망 인터페이싱부, 통화망 인터페이싱부, 데이터망 인터페이싱부 및 프로세서를 포함한다. 다만, 도 8은 예시적인 것에 불과한 바, 인터페이싱 장치는 도 8에 도시된 것으로 한정 해석되지 않는다. 예컨대 인터페이싱 장치는 메모리를 더 포함할 수도 있고, 또는 도 8에 도시된 구성 중 적어도 하나를 포함하지 않을 수도 있다. 인공지능망 인터페이싱부, 통화망 인터페이싱부 및 데이터망 인터페이싱부 각각은 음성이나 영 상 데이터 또는 채팅 메시지와 같은 패킷 데이터를 인공지능 서비스 제공 서버, 통화망 및 데이터망 각각과 송수신한다. 이를 위해, 각각의 인터페이싱부(110 내지 130)는 유선 또는 무선 통신 모듈을 포함 할 수 있다.프로세서는 이하에서 설명할 기능을 수행하도록 프로그램된 명령어를 저장하는 메모리와, 이러한 명령어를 실행하는 마이크로프로세서에 의해 구현 가능하다. 보다 구체적으로 살펴보면, 프로세서는 통화망이나 데이터망 각각에 대한 설정을 수행할 수 있 다. 또한 프로세서는 통화망으로부터 수신받은 음성, 또는 데이터망으로부터 수신받은 텍스트와 같은 패킷이 인공지능 서비스 제공 서버에게 전달되도록 제어할 수 있다. 또한 프로세서는 인공지능 서비스 제공 서버로부터 수신받은 음성이나 텍스트와 같은 패킷이 통화망이나 데이터망에게 전 달되도록 제어할 수 있다. 또한. 프로세서는 각 단말 장치(300/1,300/2) 중 어느 한 단말 장치, 예컨대 단말 장치(300/1)에게 전달된 음성이 해당 단말 장치(300/1)에서 출력이 완료되었는지 여부를 추정할 수 있고, 출력 완료된 것으로 추정되면 이를 타 단말 장치(300/2)에게 알림이 전달되도록 제어할 수 있다. 이를 위해 프로세서는 단말 장치 (300/1)에게 전달된 음성이, 단말 장치(300/1)에서 출력 완료되기까지 소요되는 시간을 계산하는 알고리즘을 채 용하고 있을 수 있다. 이를 통해, 어느 단말 장치의 사용자는 타 단말 장치에게 음성이 출력 중인지 아니면 출 력이 완료되었는지 여부를 인식할 수 있다. 또한, 프로세서는 전술한 TTS 모듈에 채용되어 있는 알고리즘, 즉 텍스트의 입력이 시작되었는데 소 정 시간 동안 완료가 되지 않을 경우, 이러한 텍스트의 입력 완료가 지연되고 있음을 나타내는 소리를 음성 사 이에 또는 음성 중간에 삽입하는 알고리즘을 채용하고 있을 수도 있다. 여기서, 실시예에 따라, 만약 TTS 모듈 에 전술한 알고리즘이 채용되어 있지 않다면 프로세서가 이러한 알고리즘을 채용할 수 있고, 이와 달 리 TTS 모듈에 전술한 알고리즘이 채용되어 있다면 프로세서는 이러한 알고리즘을 채용하지 않을 수 있다. 이상에서 살펴본 바와 같이, 일 실시예에 따르면 단말 장치(300/1)와 단말 장치(300/2)가 서로 간에 음성 또는 영상 통화를 시도하거나 진행하는 중에, 어느 하나의 단말 장치(300/1)는 음성 또는 영상 통화를 유지하지만 다 른 하나의 단말 장치(300/2)는 메시지를 통한 채팅 방식으로 단말 장치(300/1)와 소통을 할 수 있다. 이하 단말 장치들(300/1,300/2)이 서로 음성 또는 영상 통화 중에, 전술한 텍스트 타입의 통화 서비스에 대한 요청이 단말 장치(300/2)로부터 있을 경우에 대한 동작 흐름에 대해 살펴보기로 하자. 도 9를 참조하면, 단말 장치들(300/1,300/2) 간에는 음성 또는 영상 통화가 통화망을 통해 수행된다(①,②). 수행 중 단말 장치(300/2)로부터 텍스트 타입의 통화 서비스에 대한 요청이 통화망에 수신될 수 있다(③). 이러한 요청은 도 10에 도시된 것과 같이 단말 장치(300/2)의 화면 상에서, 소정의 아이콘을 사용자 가 터치할 경우, 단말 장치(300/2)로부터 통화망으로 전달된 것일 수 있으며, 다만 이외의 상황에서도 이 러한 요청이 수신될 수 있는데, 이에 대해서는 후술하기로 한다. 다시 도 9를 참조하면, 통화망의 응용 서비스 노드, 즉 TAS는 이러한 요청을 인터페이싱 장치에 게 전달한다(④). 그러면 인터페이싱 장치는 프로세서를 통해서, 단말 장치(300/1)로부터의 음성이 텍스트로 변환되어 서 단말 장치(300/2)에게 전달되도록 제어할 뿐 아니라, 단말 장치(300/2)로부터의 텍스트가 음성으로 변환되어 서 단말 장치(300/1)에게 전달되도록 제어를 수행한다. 이에 대해서는 도 9에 도시된 ⑤ 내지 ⑭를 참조해서 살 펴보기로 하자. 앞서 살펴본 바와 같이, ④에 대응되는 요청이 TAS로부터 인터페이싱 장치에 수신되었다고 전제하자. 이 후부터, 단말 장치(300/1)의 사용자의 음성이 통화망을 통해 인터페이싱 장치에게 전달되면(⑤, ⑥), 인터페이싱 장치는 이러한 음성을 인공지능 서비스 제공 서버에게 전달한다(⑦). 인공지능 서비스 제공 서버는 STT 모듈를 이용해서 ⑦에서 전달받은 음성을 텍스트로 변환한 뒤, 이 러한 텍스트를 인터페이싱 장치에게 전달한다(⑧). 이 때, 이러한 텍스트에는 단말 장치(300/1)의 사용자 에 대해 STT 모듈이 파악한 전술한 기분이나 감정 등을 나타내는 이모티콘 등이 포함될 수 있다. 그러면 인터페이싱 장치는 ⑧에서 전달받은 텍스트를 데이터망을 통해 단말 장치(300/2)에게 전달한 다(⑨,⑩). 이로써 단말 장치(300/2)의 사용자는 단말 장치(300/1)의 사용자가 발한 음성에 대응되는 텍스트를 채팅 방식의 메시지로서 수신받을 수 있다.한편, ⑩에서 수신받은 텍스트를 근거로, 단말 장치(300/2)의 사용자는 그러한 텍스트에 대한 응답 메시지를 단 말 장치(300/2)에 입력할 수 있다. 이렇게 입력된 응답 메시지에 대한 텍스트는 데이터망을 통해 인터페이 싱 장치에게 전달된다(⑪, ⑫). 그러면 인터페이싱 장치는 ⑫에서 전달받은 텍스트를 인공지능 서비스 제공 서버에게 전달한다(⑬). 그러면, 인공지능 서비스 제공 서버는 TTS 모듈를 이용해서 ⑬에서 전달받은 텍스트를 음성으로 변환 한 뒤, 이러한 음성을 인터페이싱 장치에게 전달한다(⑭). 이 때, 이렇게 변환된 음성에는, TTS 모듈(23 0)에 의해 획득된, 단말 장치(300/2)의 사용자의 기분이나 감정 등이 반영되어 있을 수 있으며, 이에 따라 그 음성의 톤이나 크기 등이 변환되어 있을 수 있다. 그러면 인터페이싱 장치는 ⑭에서 전달받은 음성을 통화망을 통해 단말 장치(300/1)에게 전달한다(⑮,16). 이로써 단말 장치(300/21의 사용자는 단말 장치(300/2)의 사용자가 입력한 텍스트에 대응되는 음성을 수신받을 수 있다. 즉, 일 실시예에 따르면, 단말 장치(300/1)와 단말 장치(300/2)가 서로 간에 음성 또는 영상 통화를 시도하거나 진행하는 중에, 어느 하나의 단말 장치(300/1)는 음성 또는 영상 통화를 유지하지만 다른 하나의 단말 장치 (300/2)는 메시지를 통한 채팅 방식으로 단말 장치(300/1)와 소통을 할 수 있다. 한편, 도 10에서 살펴본 바로는 단말 장치(300/2)의 사용자가 직접 단말 장치(300/2)의 화면에서 소정의 아이콘을 터치한 경우에 전술한 텍스트 타입의 통화 서비스가 가능하지만, 텍스트 타입의 통화 서비스는 다른 방식에 의해서도 시작될 수 있다. 예컨대 단말 장치(300/2)의 사용자가 단말 장치(300/2)를 '휴식 모드(무 음, 무진동 모드 등)'로서 설정한 경우, 단말 장치(300/2)가 음성 또는 영상 통화를 소정의 시간 동안 수행한 이후에는, 사용자가 아이콘을 터치하지 않아도 자동으로 전술한 텍스트 타입의 통화 서비스가 시작될 수 있다. 다른 한편, 단말 장치(300/2)의 사용자는 ⑪에서 텍스트를 전달받을 뿐 아니라, 단말 장치(300/1)의 사용자가 발한 음성, 즉 ⑤와 ⑥의 과정을 통해 인터페이싱 장치에게 전달된 음성까지도 이러한 텍스트와 함께 전달 받을 수 있다. 이 때, 단말 장치(300/2)의 사용자는 텍스트만 받고 음성은 받지 않길 원할 수도 있다. 이를 위해, 단말 장치 (300/2)의 화면에는 텍스트만 수신되도록 하고 음성은 수신되지 않도록, 즉 음소거를 하는 토글 버튼이 배치되 어 있을 수 있으며, 이는 도 11에서 식별번호 312로 도시되어 있다. 사용자가 이러한 토글 버튼을 누를 때마다, 단말 장치(300/1)의 사용자의 음성이 출력되거나 출력되지 않을 수 있다. 또 다른 한편으로, 인공지능 서비스 제공 서버의 자연어 처리부(또는 자연언어 처리부)는 ⑦에서 전 달받은 질문을 인지하고 분석한 뒤, 그에 대한 추천 응답을 제공할 수 있다. 이렇게 제공되는 추천 응답은, 인 터페이싱 장치를 거쳐서 데이터망을 통해 단말 장치(300/2)에게 제공된다. 그러면, 단말 장치(300/ 2)의 사용자는 이러한 추천 응답을 선택하는 것만으로도, 자신이 원하는 텍스트가 상대방인 단말 장치(300/1)의 사용자에게 전달되도록 할 수 있다. 즉, 단말 장치(300/2)의 사용자가 텍스트를 입력하는데에 시간이 소요되는 바, 이러한 시간을 단축하기 위해 단말 장치(300/2)의 사용자에게 추천 응답 텍스트가 제공될 수 있는 것이다. 이를 통해 보다 원활하게 단말 장치(300/2)의 사용자는 텍스트 타입의 통화 서비스를 제공받을 수 있다. 또한, 실시예에 따라 단말 장치(300/2)의 화면에는 텍스트 타입의 통화 서비스와 음성/영상 방식의 통화 서비스 사이에서 서로 간에 전환이 가능한 방식 토글 버튼이 마련되어 있을 수 있으며, 이는 도 11에서 식별번호 313으 로 도시되어 있다. 사용자가 이러한 토글 버튼을 누를 때마다, 단말 장치(300/2)에서는 텍스트 타입의 통화 서 비스가 제공되거나 또는 음성/영상 방식의 통화 서비스가 제공될 수 있다. 또 한편, 텍스트 타입의 통화 서비스가 단말 장치(300/2)에 제공되는 상황을 가정해보면, 단말 장치(300/2)의 사용자가 텍스트를 입력하는 속도가, 단말 장치(300/1)의 사용자가 음성을 발하는 속도보다 상대적으로 느린 경 우가 많다. 이에, 인공지능 서비스 제공 서버의 TTS 모듈은, 텍스트의 입력이 시작되었는데 소정 시 간 동안 완료가 되지 않을 경우, 이러한 텍스트의 입력이 지연되고 있음을 나타내는 소리를 음성 사이에 또는 음성 중간에 삽입할 수 있다. 도 12를 참조하면, 텍스트의 입력이 시작된 시점부터 소정 시간이 경과되어도 종 점이 오지 않았으면, 이러한 소정 시간이 경과된 이후부터 종점의 직전까지 소정의 소리가 상대방의 단말 장치 에서 출력될 수 있다. 여기서, 이러한 소리의 종류에는 예컨대 '음...', '그러니까....', '잠깐만....'과 같이, 대화에서 일반적으로 지연을 나타내는 단어가 포함될 수 있다.도 13은 일 실시예에 따른 인공지능 인터페이싱 방법의 흐름을 도시한 도면이다. 다만, 도 13은 예시적인 것에 불과한 바, 본 발명의 사상이 도 13에 도시된 것으로 한정 해석되지는 않는다. 도 13을 참조하면, 단말 장치들(300/1,300/2) 간에는 음성 또는 영상 통화가 통화망을 통해 수행된다 (S10). 수행 중 단말 장치(300/2)로부터 텍스트 타입의 통화 서비스에 대한 요청이 통화망 인터페이싱부 또는 데 이터망 인터페이싱부에 수신될 수 있다. 이러한 요청은 도 10에 도시된 것과 같이 단말 장치(300/2)의 화 면 상에서, 소정의 아이콘을 사용자가 터치할 경우, 단말 장치(300/2)로부터 전달된 것일 수 있다. 이 후, 데이터망 인터페이싱부에 수신된 S11에서의 요청은 프로세서에게 전달된다(S12). 그러면 프로 세서는 통화망 인터페이싱부를 통해 단말 장치(300/1)와 단말 장치(300/2) 각각에게 re-invite를 요 청한다(S13 내지 S15). 각 단말 장치(300/1,300/2)는 re-invite가 완료되면, 완료되었다는 응답을 준다 (S16,S17) 이후부터 인터페이싱 장치는 프로세서를 통해서, 단말 장치(300/1)로부터의 음성이 텍스트로 변환되 어서 단말 장치(300/2)에게 전달되도록 제어할 뿐 아니라, 단말 장치(300/2)로부터의 텍스트가 음성으로 변환되 어서 단말 장치(300/1)에게 전달되도록 제어를 수행한다. 이에 대해서는 도 13에 도시된 S20 내지 S43을 참조해 서 살펴보기로 하자. 단말 장치(300/1)의 사용자의 음성, 예컨대 '여보세요'가 단말 장치(300/1)로부터 통화망 인터페이싱부를 거쳐서 인공지능망 인터페이싱부를 통해 인공지능 서비스 제공 서버의 STT 모듈에게 전달된다 (S20 내지 S22). 그러면 STT 모듈은 이러한 음성 '여보세요'에 대응되는 텍스트를 출력한다. 출력된 텍스 트는 인공지능망 인터페이싱부에게 전달된다(S24)한다. 뿐만 아니라 자연언어 처리부는 S22에서 수신된 음성에 대한 추천 응답 텍스트를 도출한 뒤 인공지능망 인 터페이싱부에게 전달한다(S23, S25) 그러면 S24와 S25에서 전달받은 텍스트는 데이터망 인터페이싱부를 통해 단말 장치(300/2)에게 전달된다 (S27). 이로써 단말 장치(300/2)에는 단말 장치(300/1)의 사용자가 발한 음성에 대응되는 텍스트가 표시된다 (S28). 이 때, 단말 장치(300/2)에는 추천 응답 텍스트도 표시된다. 단말 장치(300/2)의 사용자는 이러한 추천 응답 텍스트를 선택하는 것만으로도, 자신이 원하는 응답을 상대방에게 전달할 수 있다. 한편, S28에서 표시된 텍스트를 근거로, 단말 장치(300/2)의 사용자는 그러한 텍스트에 대한 응답 메시지를 단 말 장치(300/2)에 입력할 수 있다. 이렇게 입력된 응답 메시지에 대한 텍스트는 데이터망 인터페이싱부를 거쳐서 인공지능망 인터페이싱부에게 전달된다(S30, S31). 아울러, 이러한 텍스트는 인공지능망 인터페이 싱부를 통해 인공지능 서비스 제공 서버의 TTS 모듈에게 전달된다(S32). 그러면 TTS 모듈은 이러한 텍스트에 대응되는 음성을 출력한다. 출력된 음성은 인공지능망 인터페이싱부 에게 전달된다(S33)한다. S33에서 전달받은 음성은, 인공지능망 인터페이싱부로부터 통화망 인터페이싱부를 거쳐서 단말 장치 (300/1)에게 전달된다(S34 내지 S35). 이로써 단말 장치(300/1)에는 단말 장치(300/2)의 사용자가 입력한 텍스 트에 대응되는 음성이 출력된다(S36). 이 후, S36에서의 음성의 출력이 완료되었음이 인터페이싱 장치에서 인식되는데, 이러한 인식은 단말 장치 (300/1)로부터 수신받은 정보를 기초로 되거나 또는 프로세서가 이를 계산할 수도 있다. 이 후, S36에서의 음성의 출력이 완료되었음이 데이터망 인터페이싱부를 통해서 단말 장치(300/2)에게 전달된다(S42). 그러 면 단말 장치(300/2)에서는, 단말 장치(300/2)의 사용자가 입력한 텍스트가, 상대방에게 음성의 형태로 출력이 완료되었음이 소정의 방식으로 표시된다(S43). 이상에서 살펴본 바와 같이, 일 실시예에 따르면 단말 장치(300/1)와 단말 장치(300/2)가 서로 간에 음성 또는 영상 통화를 시도하거나 진행하는 중에, 어느 하나의 단말 장치(300/1)는 음성 또는 영상 통화를 유지하지만 다 른 하나의 단말 장치(300/2)는 메시지를 통한 채팅 방식으로 단말 장치(300/1)와 소통을 할 수 있다. 또한, 이 경우 단말 장치(300/2)의 사용자가 채팅을 입력하는데에 시간이 소요되는 바, 이러한 시간을 단축하기 위해 단 말 장치(300/2)의 사용자에게는 추천 응답 텍스트가 제공될 수도 있다. 이를 통해 보다 원활하게 단말 장치 (300/2)의 사용자는 텍스트 타입의 통화 서비스를 제공받을 수 있다.한편, 본 발명의 사상에 따른 전술한 방법은, 이러한 방법에 포함된 각 단계를 수행하도록 프로그램된 컴퓨터 프로그램을 저장하는 컴퓨터 판독가능한 기록매체, 또는 이러한 컴퓨터 판독가능한 기록매체에 저장된 컴퓨터 프로그램에 의해 구현 가능하다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 품질에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 균등한 범위 내에 있는 모든 기술사상은 본 발명의 권 리범위에 포함되는 것으로 해석되어야 할 것이다. 산업상 이용가능성 일 실시예에 따르면, 사용자는 자신이 원할 때 텍스트 타입의 통화 서비스를 제공받을 수 있다."}
{"patent_id": "10-2020-0135407", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인공지능 인터페이싱 장치가 적용된 이동통신망을 개념적으로 도시한 도면이다. 도 2는 도 1에 도시된 인공지능 서비스 제공 서버의 구성을 도시한 도면이다. 도 3은 TTS 모듈에서 변환된 결과에 대한 예시를 도시하고 있다. 도 4는 STT 모듈에서 변환된 결과에 대한 예시를 도시하고 있다. 도 5은 도 1에 도시된 호처리망의 구성을 도시한 도면이다. 도 6은 일 실시예에 따른 단말 장치의 구성을 도시한 도면이다. 도 7은 일 실시예에 따라 단말 장치에 의해 수행되는 방법의 순서를 도시한 도면이다. 도 8은 도 1에 도시된 인공지능 인터페이싱 장치의 구성을 도시한 도면이다. 도 9는 일 실시예에 따른 인공지능 인터페이싱 방법의 흐름을 도시한 도면이다. 도 10과 11 각각은 일 실시예에서 단말 장치의 화면에 대한 예시이다. 도 12는 텍스트 타입의 통화 서비스에서 텍스트 입력이 지연될 때 이를 보완하기 위해 채용되는 알고리즘을 설 명하기 위한 도면이다. 도 13은 일 실시예에 따른 인공지능 인터페이싱 방법의 흐름을 도시한 도면이다."}
