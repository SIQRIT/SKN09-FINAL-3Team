{"patent_id": "10-2023-0104489", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0023615", "출원번호": "10-2023-0104489", "발명의 명칭": "인공지능을 이용한 음악 교수 장치", "출원인": "이동원", "발명자": "이동원"}}
{"patent_id": "10-2023-0104489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 뉴럴 네트워크로 구성되는 인공 지능을 이용하여 음악에 관련된 교육을 제공하는 음악 교수 장치에 있어서,미리 생성된 기준 비디오, 미리 생성된 기준 오디오 상기 음악의 교수자에 의해 생성되는 제1 움직임 및 제1 오디오 신호를 포함하는 제1 비디오 또는 상기 음악의 교수자로부터 음악 교습을 받는 학습자가 발생시키는 제2움직임 및 제2 오디오 신호를 포함하는 제2 비디오 중에서 적어도 하나를 수신하는 수신기; 및상기 기준 비디오, 상기 제1 비디오 또는 상기 제2 비디오를 제1 뉴럴 네트워크에 입력함으로써 상기 학습자의자세를 제1 평가하고,상기 기준 오디오, 상기 제1 오디오 신호 또는 상기 제2 오디오 신호를 제2 뉴럴 네트워크에 입력함으로써 상기학습자의 음정 또는 박자를 제2 평가하고,상기 제1 평가의 결과, 상기 제2 평가의 결과에 기초하여 상기 학습자에게 제공하기 위한 교습 데이터를 생성하는 프로세서를 포함하는 음악 교수 장치."}
{"patent_id": "10-2023-0104489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 제1 비디오 및 제2 비디오에 기초하여 상기 제1 오디오 신호 및 상기 제2 오디오 신호의 동기화를 수행하거나,상기 제1 비디오 및 제2 비디오에 기초하여 상기 제1 움직임과 상기 제2 오디오 신호를 동기화(synchronize)하거나, 또는,상기 제1 비디오 및 상기 제2 비디오에 기초하여 상기 제2 움직임과 상기 제1 오디오 신호를 동기화하는음악 교수 장치."}
{"patent_id": "10-2023-0104489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 제1 뉴럴 네트워크를 이용하여 상기 교수자 및 상기 학습자의 얼굴 및 자세를 인식하고,상기 얼굴을 인식한 결과에 기초하여 상기 교수자와 상기 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임을 비교하고,상기 자세를 인식한 결과에 기초하여 상기 교수자 상기 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임을 비교함으로써 상기 제1 평가를 수행하는,음악 교수 장치.공개특허 10-2025-0023615-3-청구항 4 제3항에 있어서,상기 프로세서는,상기 교수자와 상기 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임의 차이가 미리 설정된 얼굴 임계값 이내인지 여부를 제1 판단하고,상기 교수자와 상기 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이가 미리 설정된 자세 임계값이내인지 여부를 제2 판단하는,음악 교수 장치."}
{"patent_id": "10-2023-0104489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는,상기 제2 뉴럴 네트워크를 이용하여 상기 교수자 및 상기 학습자의 음정 및 박자를 인식하고,상기 교수자의 음정과 상기 학습자의 음정의 차이가 미리 설정된 음정 임계값 이내인지 여부를 제3 판단하고,상기 교수자의 박자와 상기 학습자의 박자의 차이가 미리 설정된 박자 임계값 이내인지 여부를 제4 판단하는,음악 교수 장치."}
{"patent_id": "10-2023-0104489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 프로세서는,상기 눈썹, 눈, 코, 입 및 귀의 움직임의 차이에 기초하여 상기 제1 뉴럴 네트워크를 학습시킴으로써 상기눈썹, 눈, 코, 입 및 귀의 움직임에 대응하는 제1 가중치를 결정하고,상기 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이에 기초하여 상기 제1 뉴럴 네트워크를 학습시킴으로써 상기 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임에 대응하는 제2 가중치를 결정하고,상기 음정의 차이 및 상기 박자의 차이에 기초하여 상기 제2 뉴럴 네트워크를 학습시킴으로써 제3 가중치를 결정하고,상기 제1 가중치, 상기 제2 가중치 및 상기 제3 가중치에 기초하여 상기 교습 데이터를 생성하는,음악 교수 장치."}
{"patent_id": "10-2023-0104489", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,상기 교수자 또는 상기 학습자의 음성의 크기 및 주파수를 조절하는 음성 버튼;상기 교수자 또는 상기 학습자의 움직임이 포함된 비디오를 조절하는 화면 버튼;상기 학습자의 자세, 음정 및 박자를 평가하기 위한 AI 버튼;상기 학습자의 비디오 또는 교수자의 비디오를 업로드하기 위한 연습 버튼;공개특허 10-2025-0023615-4-상기 교육을 위한 자료를 상기 교수자 또는 상기 학습자에게 디스플레이하는 공유 버튼;상기 교육에 대한 기록을 저장하는 일지 버튼; 및상기 교육을 위한 언어를 변경하기 위한 언어 버튼을 포함하는 사용자 인터페이스를 제공하는,음악 교수 장치."}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능을 이용한 음악 교수 장치가 개시된다. 복수의 뉴럴 네트워크로 구성되는 인공 지능을 이용하여 음악 에 관련된 교육을 제공하는 음악 교수 장치에 있어서, 일 실시예에 따른 음악 교수 장치는, 미리 생성된 기준 비 디오, 미리 생성된 기준 오디오, 상기 음악의 교수자에 의해 생성되는 제1 움직임 및 제1 오디오 신호를 포함하 (뒷면에 계속)"}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예들은 인공지능을 이용한 음악 교수 장치에 관한 것이다."}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 음악 교습은 하나의 장소에서 동시에 여러 사람이 수업을 받는 형태로 이루어지고, 교습 비용 역시 다른 교육에 비하여 상대적으로 비싸다. 여러 사람을 동시에 교습할 경우에 한 사람이 받을 수 있는 교육 시간은 짧을 수밖에 없고, 큰 교육 공간을 필 요로 하기 때문에 학습의 효율이 떨어질 수밖에 없다. 교습자와 학습자 사이의 소통이 부족한 음악 교습 방식은 지속적인 흥미를 제공하지 않고, 즉각적인 성취감을 제공하지 않음으로 하여 교육 효과에 일정한 한계가 존재한다. 음악 교습자와 학습자가 충분한 소통을 하기 위 해서는 교습자의 숫자가 충분히 확보되거나, 시간 및 공간을 보다 자유롭게 활용할 수 있어야 한다. 따라서, 시간 및 공간의 제약을 해소하기 위해서는 교습자와 강습자가 원활하게 소통할 수 있는 음악 교습 시스 템의 개발이 요구된다."}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "복수의 뉴럴 네트워크로 구성되는 인공 지능을 이용하여 음악에 관련된 교육을 제공하는 음악 교수 장치에 있어 서, 일 실시예에 따른 음악 교수 장치는, 미리 생성된 기준 비디오, 미리 생성된 기준 오디오, 상기 음악의 교 수자에 의해 생성되는 제1 움직임 및 제1 오디오 신호를 포함하는 제1 비디오 또는 상기 음악의 교수자로부터 음악 교습을 받는 학습자가 발생시키는 제2 움직임 및 제2 오디오 신호를 포함하는 제2 비디오 중에서 적어도 하나를 수신하는 수신기와, 상기 기준 비디오, 상기 제1 비디오 또는 상기 제2 비디오를 제1 뉴럴 네트워크에 입력함으로써 상기 학습자의 자세를 제1 평가하고, 상기 기준 오디오, 상기 제1 오디오 신호 또는 상기 제2 오 디오 신호를 제2 뉴럴 네트워크에 입력함으로써 상기 학습자의 음정 또는 박자를 제2 평가하고, 상기 제1 평가 의 결과, 상기 제2 평가의 결과에 기초하여 상기 학습자에게 제공하기 위한 교습 데이터를 생성하는 프로세서를 포함한다. 상기 프로세서는, 상기 제1 비디오 및 제2 비디오에 기초하여 상기 제1 오디오 신호 및 상기 제2 오디오 신호의 동기화를 수행하거나, 상기 제1 비디오 및 제2 비디오에 기초하여 상기 제1 움직임과 상기 제2 오디오 신호를 동기화(synchronize)하거나, 또는, 상기 제1 비디오 및 상기 제2 비디오에 기초하여 상기 제2 움직임과 상기 제 1 오디오 신호를 동기화할 수 있다. 상기 프로세서는, 상기 제1 뉴럴 네트워크를 이용하여 상기 교수자 및 상기 학습자의 얼굴 및 자세를 인식하고, 상기 얼굴을 인식한 결과에 기초하여 상기 교수자와 상기 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임을 비교하 고, 상기 자세를 인식한 결과에 기초하여 상기 교수자 상기 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움 직임을 비교함으로써 상기 제1 평가를 수행할 수 있다. 상기 프로세서는, 상기 교수자와 상기 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임의 차이가 미리 설정된 얼굴 임계값 이내인지 여부를 제1 판단하고, 상기 교수자와 상기 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움 직임의 차이가 미리 설정된 자세 임계값 이내인지 여부를 제2 판단할 수 있다. 상기 프로세서는, 상기 제2 뉴럴 네트워크를 이용하여 상기 교수자 및 상기 학습자의 음정 및 박자를 인식하고, 상기 교수자의 음정과 상기 학습자의 음정의 차이가 미리 설정된 음정 임계값 이내인지 여부를 제3 판단하고, 상기 교수자의 박자와 상기 학습자의 박자의 차이가 미리 설정된 박자 임계값 이내인지 여부를 제4 판단할 수 있다. 상기 프로세서는, 상기 눈썹, 눈, 코, 입 및 귀의 움직임의 차이에 기초하여 상기 제1 뉴럴 네트워크를 학습시 킴으로써 상기 눈썹, 눈, 코, 입 및 귀의 움직임에 대응하는 제1 가중치를 결정하고, 상기 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이에 기초하여 상기 제1 뉴럴 네트워크를 학습시킴으로써 상기 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임에 대응하는 제2 가중치를 결정하고, 상기 음정의 차이 및 상기 박자의 차이에 기 초하여 상기 제2 뉴럴 네트워크를 학습시킴으로써 제3 가중치를 결정하고, 상기 제1 가중치, 상기 제2 가중치 및 상기 제3 가중치에 기초하여 상기 교습 데이터를 생성할 수 있다. 상기 프로세서는, 상기 교수자 또는 상기 학습자의 음성의 크기 및 주파수를 조절하는 음성 버튼과, 상기 교수 자 또는 상기 학습자의 움직임이 포함된 비디오를 조절하는 화면 버튼과, 상기 학습자의 자세, 음정 및 박자를 평가하기 위한 AI 버튼과, 상기 학습자의 비디오 또는 교수자의 비디오를 업로드하기 위한 연습 버튼과, 상기 교육을 위한 자료를 상기 교수자 또는 상기 학습자에게 디스플레이하는 공유 버튼과, 상기 교육에 대한 기록을 저장하는 일지 버튼과, 상기 교육을 위한 언어를 변경하기 위한 언어 버튼을 포함하는 사용자 인터페이스를 제 공할 수 있다."}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들은 인공지능을 이용하여 음악 관련 교육을 수행함으로써 교수자와 학습자의 음악 교육의 편의성을 향상 시킬 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에 대한 특정한 구조적 또는 기능적 설명들은 단지 예시를 위한 목적으로 개시된 것으로서, 다양한 형 태로 변경되어 구현될 수 있다. 따라서, 실제 구현되는 형태는 개시된 특정 실시예로만 한정되는 것이 아니며, 본 명세서의 범위는 실시예들로 설명한 기술적 사상에 포함되는 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 해석되어야 한다. 예를 들어, 제1 구성요소는 제2 구성요소로 명 명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어 는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또 는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구 성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 예 를 들면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있 다. 본 문서에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미하며, '~부'는 어떤 역할들을 수행한다. 그렇지만, '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 예를 들어, '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로 시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베 이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함할 수 있다. 구성요소들과 '~부'들 안에서 제공되 는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 또한, '~부'는 하나 이상의 프로세서를 포함할 수 있다. 이하, 실시예들을 첨부된 도면들을 참조하여 상세하게 설명한다. 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부여하고, 이에 대한 중복되는 설명은 생략하기로 한 다. 도 1은 일 실시예에 따른 음악 교수 장치의 개략적인 블록도를 나타낸다. 도 1을 참조하면, 음악 교수 장치는 음악 교육의 교수자 및 학습자와 연동하여 음악 교육 플랫폼을 제공할 수 있다. 음악 교육은 악기를 이용한 음악, 사람의 목소리를 이용한 음악 및/또는 사람의 몸을 이용한 동작에 대한 교육을 포함할 수 있다. 음악 교수 장치는 학습자로부터 발생되는 음성 신호 또는 학습자의 자세에 기초하여 음악 교육을 수행할 수 있다. 음악 교수 장치는 마더보드(motherboard)와 같은 인쇄 회로 기판(printed circuit board(PCB)), 집적 회로 (integrated circuit(IC)), 또는 SoC(system on chip)로 구현될 수 있다. 소셜 네트워킹 서비스 제공 장치 는 애플리케이션 프로세서(application processor)로 구현될 수 있다. 또한, 음악 교수 장치는 PC(personal computer), 데이터 서버, 키오스크(kiosk) 또는 휴대용 장치 내에 구 현될 수 있다. 휴대용 장치는 랩탑(laptop) 컴퓨터, 이동 전화기, 스마트 폰(smart phone), 태블릿(tablet) PC, 모바일 인터 넷 디바이스(mobile internet device(MID)), PDA(personal digital assistant), EDA(enterprise digital assistant), 디지털 스틸 카메라(digital still camera), 디지털 비디오 카메라(digital video camera), PMP(portable multimedia player), PND(personal navigation device 또는 portable navigation device), 휴대 용 게임 콘솔(handheld game console), e-북(e-book), 또는 스마트 디바이스(smart device)로 구현될 수 있다. 스마트 디바이스는 스마트 와치(smart watch), 스마트 밴드(smart band), 또는 스마트 링(smart ring)으로 구 현될 수 있다. 음악 교수 장치는 인공 지능(Artificial Intelligence(AI)))를 이용하여 음악 교수 서비스를 제공할 수 있 다. 인공 지능은 학습, 추론 또는 판단과 같은 기능을 갖춘 컴퓨터 시스템을 의미할 수 있다. 인공 지능은 뉴럴 네 트워크(neural network)를 이용하여 구현될 수 있다. 뉴럴 네트워크(또는 인공 신경망)는 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘 을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시 냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 뉴럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력으로부터 예측하고자 하는 결과를 추론할 수 있다. 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론 (multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network), 트랜스포머(transformer) 및 AN(Attention Network)을 포함할 수 있다. 뉴럴 네트워크는 생성형 AI(Generative Artificial Intelligence)를 포함할 수 있다. 생성형 AI는 파운데이션 모델(foundation model)을 포함할 수 있다. 파운데이션 모델은 LLM(Large Language Model)를 포함할 수 있다. 음악 교수 장치는 수신기 및 프로세서를 포함한다. 음악 교수 장치는 메모리를 더 포 함할 수 있다. 수신기는 수신 인터페이스를 포함할 수 있다. 수신기는 외부 또는 메모리로부터 데이터를 수신 할 수 있다. 수신기는 수신한 데이터를 프로세서로 출력할 수 있다. 수신기는 미리 생성된 기준 비디오, 미리 생성된 기준 오디오, 음악의 교수자에 의해 생성되는 제1 움직임 및 제1 오디오 신호를 포함하는 제1 비디오 및 음악의 교수자로부터 음악 교습을 받는 학습자가 발생시키는 제2 움직임 및 제2 오디오 신호를 포함하는 제2 비디오를 수신할 수 있다. 미리 생성된 기준 비디오 및 미리 생성된 기준 오디오는 교습의 기준이 될 수 있다. 미리 생성된 기준 비디오 는 임의의 교수자에 의해 수행된 음악 관련 활동을 포함하는 비디오를 의미할 수 있고, 미리 생성된 기준 오디 오는 임의의 교수자에 의해 수행된 음악 관련 오디오 신호를 포함하는 오디오를 의미할 수 있다. 미리 생성된 기준 비디오 및 미리 생성된 기준 오디오는 메모리 또는 외부로부터 수신될 수 있다. 프로세서는 메모리에 저장된 데이터를 처리할 수 있다. 프로세서는 메모리에 저장된 컴퓨 터로 읽을 수 있는 코드(예를 들어, 소프트웨어) 및 프로세서에 의해 유발된 인스트럭션(instruction)들을 실행할 수 있다. 프로세서는 목적하는 동작들(desired operations)을 실행시키기 위한 물리적인 구조를 갖는 회로를 가지는 하드웨어로 구현된 데이터 처리 장치일 수 있다. 예를 들어, 목적하는 동작들은 프로그램에 포함된 코드(code) 또는 인스트럭션들(instructions)을 포함할 수 있다. 예를 들어, 하드웨어로 구현된 데이터 처리 장치는 마이크로프로세서(microprocessor), 중앙 처리 장치(central processing unit), 프로세서 코어(processor core), 멀티-코어 프로세서(multi-core processor), 멀티프로세서 (multiprocessor), ASIC(Application-Specific Integrated Circuit), FPGA(Field Programmable Gate Array)를 포함할 수 있다. 프로세서는 복수의 뉴럴 네트워크로 구성되는 인공 지능을 이용하여 음악에 관련된 교육을 제공할 수 있다. 프로세서는 수신기로부터 미리 생성된 기준 비디오, 미리 생성된 기준 오디오, 음악의 교수자에 의해 생성되는 제1 움직임 및 제1 오디오 신호를 포함하는 제1 비디오 또는 음악의 교수자로부터 음악 교습을 받는 학습자가 발생시키는 제2 움직임 및 제2 오디오 신호를 포함하는 제2 비디오를 수신할 수 있다. 프로세서는 미리 생성된 기준 비디오, 제1 비디오 또는 제2 비디오를 제1 뉴럴 네트워크에 입력함으로써 학습자의 자세를 제1 평가할 수 있다. 프로세서는 제1 뉴럴 네트워크를 이용하여 교수자 및 학습자의 얼굴 및 자세를 인식할 수 있다. 프로세서는 얼굴을 인식한 결과에 기초하여 교수자와 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임을 비교할 수 있다. 프로세서는 자세를 인식한 결과에 기초하여 교수자 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임을 비교함으로써 제1 평가를 수행할 수 있다. 프로세서는 교수자와 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임의 차이가 미리 설정된 얼굴 임계값 이내 인지 여부를 제1 판단할 수 있다. 프로세서는 교수자와 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이가 미리 설정된 자세 임계값 이내인지 여부를 제2 판단할 수 있다. 프로세서는 미리 생성된 기준 오디오, 제1 오디오 신호 또는 제2 오디오 신호를 제2 뉴럴 네트워크에 입력 함으로써 학습자의 음정 또는 박자를 제2 평가할 수 있다. 프로세서는 제2 뉴럴 네트워크를 이용하여 교수자 및 학습자의 음정 및 박자를 인식할 수 있다. 프로세서 는 교수자의 음정과 학습자의 음정의 차이가 미리 설정된 음정 임계값 이내인지 여부를 제3 판단할 수 있 다. 프로세서는 교수자의 박자와 학습자의 박자의 차이가 미리 설정된 박자 임계값 이내인지 여부를 제4 판단 할 수 있다. 프로세서는 눈썹, 눈, 코, 입 및 귀의 움직임의 차이에 기초하여 제1 뉴럴 네트워크를 학습시킴으로써 눈 썹, 눈, 코, 입 및 귀의 움직임에 대응하는 제1 가중치를 결정할 수 있다. 프로세서는 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이에 기초하여 제1 뉴럴 네트워크를 학습시 킴으로써 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임에 대응하는 제2 가중치를 결정할 수 있다. 프로세서는 음정의 차이 및 박자의 차이에 기초하여 제2 뉴럴 네트워크를 학습시킴으로써 제3 가중치를 결 정할 수 있다. 프로세서는 제1 가중치, 제2 가중치 및 제3 가중치에 기초하여 교습 데이터를 생성할 수 있다. 프로세서는 제1 비디오 및 제2 비디오에 기초하여 제1 오디오 신호 및 제2 오디오 신호의 동기화를 수행할 수 있다. 프로세서는 제1 비디오 및 제2 비디오에 기초하여 제1 움직임과 제2 오디오 신호를 동기화 (synchronize)할 수 있다. 또는, 프로세서는 제1 비디오 및 제2 비디오에 기초하여 제2 움직임과 제1 오 디오 신호를 동기화할 수 있다. 프로세서는 제1 움직임 및 제1 오디오 신호의 동기화를 수행할 수 있다. 프로세서는 제2 움직임 및 제2 오디오 신호의 동기화를 수행할 수 있다. 프로세서는 제1 평가의 결과, 제2 평가의 결과에 기초하여 학습자에게 제공하기 위한 교습 데이터를 생성 할 수 있다. 프로세서는 사용자 인터페이스를 제공할 수 있다. 프로세서는 사용자 인터페이스를 별도의 디스플레 이 장치를 통해 제공할 수 있다. 사용자 인터페이스는 교수자 또는 학습자의 음성의 크기 및 주파수를 조절하는 음성 버튼, 교수자 또는 학습자 의 움직임이 포함된 비디오를 조절하는 화면 버튼, 학습자의 자세, 음정 및 박자를 평가하기 위한 AI 버튼, 학 습자의 비디오 또는 교수자의 비디오를 업로드하기 위한 연습 버튼, 교육을 위한 자료를 교수자 또는 학습자에 게 디스플레이하는 공유 버튼, 교육에 대한 기록을 저장하는 일지 버튼 및 교육을 위한 언어를 변경하기 위한 언어 버튼을 포함할 수 있다. 메모리는 프로세서에서 수행되는 연산을 위한 데이터 또는 프로세서의 연산 결과를 저장할 수 있다. 메모리는 프로세서에 의해 실행가능한 인스트럭션들(또는 프로그램)을 저장할 수 있다. 예를 들어, 인스트럭션들은 프로세서의 동작 및/또는 프로세서의 각 구성의 동작을 실행하기 위한 인스트 럭션들을 포함할 수 있다. 메모리는 휘발성 메모리 장치 또는 비휘발성 메모리 장치로 구현될 수 있다. 휘발성 메모리 장치는 DRAM(dynamic random access memory), SRAM(static random access memory), T- RAM(thyristor RAM), Z-RAM(zero capacitor RAM), 또는 TTRAM(Twin Transistor RAM)으로 구현될 수 있다. 비휘발성 메모리 장치는 EEPROM(Electrically Erasable Programmable Read-Only Memory), 플래시(flash) 메모 리, MRAM(Magnetic RAM), 스핀전달토크 MRAM(Spin-Transfer Torque(STT)-MRAM), Conductive Bridging RAM(CBRAM), FeRAM(Ferroelectric RAM), PRAM(Phase change RAM), 저항 메모리(Resistive RAM(RRAM)), 나노 튜브 RRAM(Nanotube RRAM), 폴리머 RAM(Polymer RAM(PoRAM)), 나노 부유 게이트 메모리(Nano Floating Gate Memory(NFGM)), 홀로그래픽 메모리(holographic memory), 분자 전자 메모리 소자(Molecular Electronic Memory Device), 또는 절연 저항 변화 메모리(Insulator Resistance Change Memory)로 구현될 수 있다. 메모리는 내비게이션 정보 및 보험의 정보를 저장할 수 있다. 메모리는 프로세서의 요청에 응 답하여 저장된 내비게이션 정보 및 보험의 정보를 프로세서 또는 외부로 출력할 수 있다. 도 2는 도 1에 도시된 음악 교수 장치의 동작을 설명하기 위한 도면이다. 도 2를 참조하면, 음악 교수 장치의 프로세서(예: 도 1의 프로세서)는 제1 단말 및 제2 단말 과 연동하여 음악 교수 서비스를 제공할 수 있다. 프로세서는 서버와 연동하여 음악 교수 서비 스를 제공할 수 있다. 실시예에 따라 서버가 없이 음악 교수 장치가 직접 제1 단말과 제2 단말 간의 데이터 전송을 중개할 수 있다. 제1 단말은 교수자의 단말을 포함할 수 있다. 제2 단말은 학습자의 단말을 포함할 수 있다. 제1 단말 및 제2 단말은 PC(personal computer), 데이터 서버, 키오스크(kiosk) 또는 휴대용 장치 내에 구현 될 수 있다. 휴대용 장치는 랩탑(laptop) 컴퓨터, 이동 전화기, 스마트 폰(smart phone), 태블릿(tablet) PC, 모바일 인터 넷 디바이스(mobile internet device(MID)), PDA(personal digital assistant), EDA(enterprise digital assistant), 디지털 스틸 카메라(digital still camera), 디지털 비디오 카메라(digital video camera), PMP(portable multimedia player), PND(personal navigation device 또는 portable navigation device), 휴대 용 게임 콘솔(handheld game console), e-북(e-book), 또는 스마트 디바이스(smart device)로 구현될 수 있다. 스마트 디바이스는 스마트 와치(smart watch), 스마트 밴드(smart band), 또는 스마트 링(smart ring)으로 구 현될 수 있다. 제1 단말은 서버에 교수자의 오디오 신호(예: MR(Music Recorded) 또는 악기 소리)를 서버로 전송할 수 있다. 제2 단말은 서버로 학습자의 오디오 신호(예: 음성)을 전송할 수 있다. 프로세서는 서버와 교수자 비디오 또는 학습자 비디오를 주고받을 수 있다. 프로세서는 서버와 연동하여 교수자의 오디오 신호와 학습자의 오디오 신호의 동기화를 수행할 수 있 다. 프로세서는 서버를 통해 교수자 비디오를 제2 단말로 전송할 수 있다. 프로세서는 서버 를 통해 학습자 비디오를 제1 단말로 전송할 수 있다. 프로세서는 제2 단말로부터 자기 학습 비디오를 수신하고, 제1 단말로부터 피드백을 수신할 수 있다. 프로세서는 자기 학습 비디오 및 피드백에 기초하여 인공 지능을 이용한 평가를 수행할 수 있다. 프로세 서는 평가 결과를 제2 단말로 전송할 수 있다. 프로세서는 사용자(예: 교수자 또는 학습자)의 얼굴을 탐지할 수 있다. 프로세서는 임의의 학습 데 이터셋의 얼굴 영역에 대하여 라벨링을 수행할 수 있다. 프로세서는 뉴럴 네트워크(예: 제1 뉴럴 네트워 크)가 예측한 얼굴 영역과 라벨링된 얼굴 영역을 비교함으로써 손실을 계산할 수 있다. 프로세서는 손실 을 최소화하는 방향으로 뉴럴 네트워크를 학습시킴으로써 얼굴을 탐지할 수 있다. 프로세서는 뉴럴 네트워크가 예측한 얼굴 영역과 라벨링된 얼굴 영역의 IOU(Intersection Over Union)을 계산함으로써 손실을 계산할 수 있다. 예를 들어, 프로세서는 두 영역의 교집합을 두영역의 합집함으로 나눔으로써 IOU를 계산할 수 있다. 프로세서는 IOU를 1에 가깝도록 학습시킴으로써 손실을 최소화할 수 있다. 프로세서는 TinaFace 또는 SCRFD(Sample and Computation Redistribution for Efficient FaceDetection) 알고리즘을 이용하여 얼굴을 탐지할 수 있다. 프로세서는 탐지한 얼굴에 대하여 정규화(normalize)를 수행할 수 있다. 프로세서는 탐지한 얼굴을 정렬함으로써 정규화를 수행할 수 있다. 프로세서는 탐지된 얼굴의 랜드마크(예: 눈, 코 또는 입)을 정렬 함으로써 정규화를 수행할 수 있다. 프로세서는 얼굴의 특징을 추출할 수 있다. 프로세서는 얼굴 특징을 숫자로 변환함으로써 얼굴 템플 릿을 생성할 수 있다. 프로세서는 얼굴 템플릿에 기초하여 교습 데이터를 생성할 수 있다. 프로세서는 학습자의 얼굴의 눈썹의 움직임 및/또는 눈썹의 위치를 인식하고, 인식한 움직임 및/또는 위치 에 기초하여 교습 데이터를 생성할 수 있다. 프로세서는 교습자의 제1 움직임과 제1 오디오 신호를 포함 하는 제1 비디오에 기초하여 기준 눈썹의 움직임 및/또는 기준 눈썹의 위치를 결정할 수 있다. 프로세서는 학습자의 눈썹의 위치가 미리 결정된 임계값 보다 높은(또는, 기준 위치로부터 임계값 이상의 높이 이상 높은) 위치로 움직인 경우에, 눈썹의 위치를 낮추라는 지시를 포함한 교습 데이터를 생성하여 학습자 에게 제공할 수 있다. 프로세서는 학습자의 눈썹의 위치가 미리 결정된 임계값 보다 높은 위치로 움직인 경우에, 자신의 손가락 을 눈썹위에 올려 놓음으로써 눈썹의 위치를 고정시킬 수 있도록 하는 지시를 포함한 교습 데이터를 생성하여 학습자에게 제공할 수 있다. 이를 통해, 프로세서는 학습자가 다양한 표정을 가지고 풍성한 감정이 표현 되도록 노래를 하게 만들 수 있다. 프로세서는 학습자의 눈이 깜빡이는 횟수 및/또는 깜빡이는 주기에 기초하여 교습 데이터를 생성할 수 있 다. 프로세서는 학습자의 눈이 미리 결정된 임계값 이상의 주기로 깜빡이는 경우 또는 학습자의 눈이 미 리 결정된 임계값 이상의 횟수로 깜빡이는 경우, 학습자가 응시하기 위한 점을 학습자 단말의 디스플레이 장치 에 디스플레이할 수 있다. 프로세서는 학습자에게 점을 응시하라는 지시를 포함한 교습 데이터를 제공할 수 있다. 이를 통해, 학습자의 시선처리를 안정화시키고, 노래에 집중할 수 있도록 만들 수 있다.프로세서 는 학습자의 입술 모양을 인식하여 입꼬리가 미리 결정된 임계값 이상 아래로 움직이거나, 입술에 과도한 힘이 들어갔는지 여부를 판단할 수 있다. 프로세서는 입꼬리가 미리 결정된 임계값 이상 아래로 내려가거 나 과도한 힘이 들어갔다고 판단된 경우, 입술을 터는 동작을 수행하도록 지시할 수 있다. 이를 통해, 프로세 서는 발성을 할 때, 입술, 입, 턱 및 혀를 자유롭게 움직일 수 있도록 만들어서 성대에 무리가 가는 것을 방지할 수 있다. 프로세서는 학습자의 목의 움직임을 감지하여 목에 힘이 들어가는 것을 방지하도록 하는 지시, 기마 자세 를 취하라는 지시 또는 벽에 기대서 노래를 하라는 지시를 포함하는 교습 데이터를 제공할 수 있다. 프로세서 는 목의 면적, 목의 피부 색, 목의 근육 또는 혈관의 움직임을 분석함으로써 목에 힘이 들어가는지 여부를 판단할 수 있다. 이를 통해, 프로세서는 소리가 납작하게 들리거나, 불편한 소리가 나오는 것을 방지할 수 있다. 프로세서는 어깨의 높이가 미리 결정된 이상의 높이로 올라간 경우에 벽에 기대에 노래를 하라는 지시 또 는 배에 힘을 주라는 지시를 포함하는 교습 데이터를 제공할 수 있다. 프로세서는 가슴의 높이가 미리 결정된 이상의 높이로 올라간 경우, 흉식 호흡을 하는 경우로 판단하여 배 와 가슴 사이에 손을 교차하도록 하는 지시를 포함하는 교습 데이터를 생성하여 제공할 수 있다. 프로세서는 학습자의 손가락의 움직임을 인식하고, 손가락에 힘이 들어가 있는지 여부를 판단할 수 있다. 프로세서는 손가락들 사이의 거리, 손바닥, 손가락 또는 손톱의 색 또는 손의 모양에 기초하여 손가락에 힘이 들어가 있는지 여부를 판단할 수 있다. 프로세서는 손가락에 힘이 들어가 있다고 판단한 경우, 어깨 를 움직이도록 하는 지시, 고개를 돌리라는 지시 또는 손을 털으라는 지시를 포함한 교습 데이터를 학습자에게 제공할 수 있다. 도 3은 도 1에 도시된 음악 교수 장치의 평가 과정의 흐름도의 예를 나타낸다. 도 3을 참조하면, 프로세서(예: 도 1의 프로세서)는 교수자의 화상 강의를 학습자에게 제공할 수 있다 . 프로세서는 학습자가 수행하는 음악에 관한 연주 또는 노래를 녹화하고, 학습자의 퍼포먼스에 대한 평가를 진행할 수 있다. 프로세서는 학습자의 퍼포먼스에 대한 교수자의 피드백을 수신할 수 있 다. 프로세서는 별도의 종료 버튼의 선택 또는 종료 음성의 인식에 응답하여 화상을 종료할 수 있다. 프로세서는 학습자의 동영상(또는, 비디오) 및 교수자의 피드백을 분석할 수 있다. 프로세서는 학습자의 비디오, 교수자의 비디오 및/또는 피드백에 기초하여 인공 지능을 학습시킬 수 있다. 프로세서는 학습된 인공 지능에 기초하여 학습자에게 자기 화상 강의를 제공할 수 있다. 프로세서 는 인공지능에 기초하여 학습자를 평가할 수 있다. 프로세서는 제1 비디오 및 제2 비디오를 제1 뉴럴 네트워크에 입력함으로써 학습자의 자세를 제1 평가할 수 있다. 프로세서는 제1 뉴럴 네트워크를 이용하여 교수자 및 학습자의 얼굴 및 자세를 인식할 수 있다. 프로세서는 얼굴을 인식한 결과에 기초하여 교수자와 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임을 비교할 수 있다. 프로세서는 자세를 인식한 결과에 기초하여 교수자 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임을 비교함으로써 제1 평가를 수행할 수 있다. 프로세서는 교수자와 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임의 차이가 미리 설정된 얼굴 임계값 이내 인지 여부를 제1 판단할 수 있다. 프로세서는 교수자와 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이가 미리 설정된 자세 임계값 이내인지 여부를 제2 판단할 수 있다. 프로세서는 제1 오디오 신호 및 제2 오디오 신호를 제2 뉴럴 네트워크에 입력함으로써 학습자의 음정 또는 박자를 제2 평가할 수 있다. 프로세서는 제2 뉴럴 네트워크를 이용하여 교수자 및 학습자의 음정 및 박자를 인식할 수 있다. 프로세서 는 교수자의 음정과 학습자의 음정의 차이가 미리 설정된 음정 임계값 이내인지 여부를 제3 판단할 수 있 다. 프로세서는 교수자의 박자와 학습자의 박자의 차이가 미리 설정된 박자 임계값 이내인지 여부를 제4 판단 할 수 있다. 프로세서는 눈썹, 눈, 코, 입 및 귀의 움직임의 차이에 기초하여 제1 뉴럴 네트워크를 학습시킴으로써 눈 썹, 눈, 코, 입 및 귀의 움직임에 대응하는 제1 가중치를 결정할 수 있다. 프로세서는 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이에 기초하여 제1 뉴럴 네트워크를 학습시 킴으로써 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임에 대응하는 제2 가중치를 결정할 수 있다. 프로세서는 음정의 차이 및 박자의 차이에 기초하여 제2 뉴럴 네트워크를 학습시킴으로써 제3 가중치를 결 정할 수 있다. 프로세서는 제1 가중치, 제2 가중치 및 제3 가중치에 기초하여 교습 데이터를 생성할 수 있다. 도 4는 도 1에 도시된 음악 교수 장치가 제공하는 사용자 인터페이스의 예를 나타낸다. 도 4를 참조하면, 프로세서(예: 도 1의 프로세서)는 사용자 인터페이스를 제공할 수 있다. 프로세서(20 0)는 사용자 인터페이스를 별도의 디스플레이 장치를 통해 제공할 수 있다. 사용자 인터페이스는 녹화 버튼, 교수자 비디오 인터페이스, 공유 인터페이스, 학습자 비디오 인터페이스, 음성 버튼, 화면 버튼, AI 버튼, 연습 버튼, 공유 버튼, 일지 버 튼 및/또는 언어 버튼을 포함할 수 있다. 프로세서는 녹화 버튼의 선택에 응답하여 교수자 또는 학습자에 대한 촬영을 수행할 수 있다. 교수 자 비디오 인터페이스는 교수자를 촬영한 비디오 또는 이미지를 디스플레이하는 인터페이스를 의미할 수 있다. 학습자 인터페이스는 학습자를 촬영한 비디오 또는 이미지를 디스플레이하는 인터페이스를 의미할 수 있다. 공유 인터페이스는 교수자 또는 학습자가 서로에게 공유하고자 하는 파일, 악보, 오선지 및/또는 비디오 파일을 전달하거나 디스플레이하기 위한 인터페이스를 의미할 수 있다. 프로세서는 음성 버튼의 선택에 응답하여 교수자 또는 학습자의 음성의 크기 및 주파수를 조절할 수 있다. 프로세서는 화면 버튼의 선택에 응답하여 교수자 또는 학습자의 움직임이 포함된 비디오를 조 절할 수 있다. 예를 들어, 프로세서는 화면 버튼의 선택에 응답하여 비디오의 줌 인, 줌 아웃, 화질 변경, 재생 속도의 변경 재생 시점의 조절 기능을 제공할 수 있다. 프로세서는 AI 버튼의 선택에 응답하여 학습자의 자세, 음정 및 박자를 평가할 수 있다. 프로세서 는 연습 버튼의 선택에 응답하여 학습자의 비디오 또는 교수자의 비디오를 업로드할 수 있다. 프로세서는 공유 버튼의 선택에 응답하여 공유 인터페이스에 교육을 위한 자료를 디스플레이함 으로써 교수자 또는 학습자에게 제공할 수 있다. 프로세서는 일지 버튼의 선택에 응답하여 교육에 대한 기록을 저장할 수 있다. 프로세서는 언 어 버튼의 선택에 응답하여 교육을 위한 언어를 변경할 수 있다. 프로세서는 별도의 로그인 인터페이스를 사용자에게 제공할 수 있다. 프로세서는 학습자가 원하는 교수자를 선택할 수 있는 교수자 리스트를 제공할 수 있다. 프로세서는 학습자에게 인공 지능을 이용하여 생성한 교습 데이터를 무료 또는 유료로 제공할 수 있다. 프로세서는 사용자로부터 사용 요금을 징수하기 위한 결제 인터페이스를 제공할 수 있다. 도 5는 도 1에 도시된 음악 교수 장치의 동작의 흐름도를 나타낸다. 도 5를 참조하면, 수신기(예: 도 1의 수신기)는 미리 생성된 기준 비디오, 미리 생성된 기준 오디오, 음악 의 교수자에 의해 생성되는 제1 움직임 및 제1 오디오 신호를 포함하는 제1 비디오 또는 음악의 교수자로부터 음악 교습을 받는 학습자가 발생시키는 제2 움직임 및 제2 오디오 신호를 포함하는 제2 비디오 중에서 적어도 하나를 수신할 수 있다. 프로세서는 기준 비디오, 제1 비디오 또는 제2 비디오를 제1 뉴럴 네트워크에 입력함으로써 학습자의 자세 를 제1 평가할 수 있다. 프로세서는 제1 뉴럴 네트워크를 이용하여 교수자 및 학습자의 얼굴 및 자 세를 인식할 수 있다. 프로세서는 얼굴을 인식한 결과에 기초하여 교수자와 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임을 비교할 수 있다. 프로세서는 자세를 인식한 결과에 기초하여 교수자 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임을 비교함으로써 제1 평가를 수행할 수 있다. 프로세서는 교수자와 학습자의 눈썹, 눈, 코, 입 및 귀의 움직임의 차이가 미리 설정된 얼굴 임계값 이내 인지 여부를 제1 판단할 수 있다. 프로세서는 교수자와 학습자의 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이가 미리 설정된 자세 임계값 이내인지 여부를 제2 판단할 수 있다. 프로세서는 기준 오디오, 제1 오디오 신호 또는 제2 오디오 신호를 제2 뉴럴 네트워크에 입력함으로써 학 습자의 음정 또는 박자를 제2 평가할 수 있다. 프로세서는 제2 뉴럴 네트워크를 이용하여 교수자 및 학습자의 음정 및 박자를 인식할 수 있다. 프로세서 는 교수자의 음정과 학습자의 음정의 차이가 미리 설정된 음정 임계값 이내인지 여부를 제3 판단할 수 있 다. 프로세서는 교수자의 박자와 학습자의 박자의 차이가 미리 설정된 박자 임계값 이내인지 여부를 제4 판단 할 수 있다. 프로세서는 눈썹, 눈, 코, 입 및 귀의 움직임의 차이에 기초하여 제1 뉴럴 네트워크를 학습시킴으로써 눈 썹, 눈, 코, 입 및 귀의 움직임에 대응하는 제1 가중치를 결정할 수 있다. 프로세서는 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임의 차이에 기초하여 제1 뉴럴 네트워크를 학습시 킴으로써 머리, 목, 어깨, 팔, 손, 가슴 및 배의 움직임에 대응하는 제2 가중치를 결정할 수 있다. 프로세서는 음정의 차이 및 박자의 차이에 기초하여 제2 뉴럴 네트워크를 학습시킴으로써 제3 가중치를 결 정할 수 있다.프로세서는 제1 가중치, 제2 가중치 및 제3 가중치에 기초하여 교습 데이터를 생성할 수 있다. 프로세서는 제1 비디오 및 제2 비디오에 기초하여 제1 오디오 신호 및 제2 오디오 신호의 동기화를 수행할 수 있다. 프로세서는 제1 비디오 및 제2 비디오에 기초하여 제1 움직임과 제2 오디오 신호를 동기화 (synchronize)할 수 있다. 또는, 프로세서는 제1 비디오 및 제2 비디오에 기초하여 제2 움직임과 제1 오 디오 신호를 동기화할 수 있다. 프로세서는 제1 평가의 결과, 제2 평가의 결과에 기초하여 학습자에게 제공하기 위한 교습 데이터를 생성 할 수 있다. 프로세서는 사용자 인터페이스를 제공할 수 있다. 프로세서는 사용자 인터페이스를 별도의 디스플레 이 장치를 통해 제공할 수 있다. 사용자 인터페이스는 교수자 또는 학습자의 음성의 크기 및 주파수를 조절하는 음성 버튼, 교수자 또는 학습자 의 움직임이 포함된 비디오를 조절하는 화면 버튼, 학습자의 자세, 음정 및 박자를 평가하기 위한 AI 버튼, 학 습자의 비디오 또는 교수자의 비디오를 업로드하기 위한 연습 버튼, 교육을 위한 자료를 교수자 또는 학습자에 게 디스플레이하는 공유 버튼, 교육에 대한 기록을 저장하는 일지 버튼 및 교육을 위한 언어를 변경하기 위한 언어 버튼을 포함할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 저장할 수 있으며 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구 성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 위에서 설명한 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 또는 복수의 소프트웨어 모듈로서 작동하"}
{"patent_id": "10-2023-0104489", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "도록 구성될 수 있으며, 그 역도 마찬가지이다.이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 이를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2023-0104489", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 음악 교수 장치의 개략적인 블록도를 나타낸다. 도 2는 도 1에 도시된 음악 교수 장치의 동작을 설명하기 위한 도면이다. 도 3은 도 1에 도시된 음악 교수 장치의 평가 과정의 흐름도의 예를 나타낸다. 도 4는 도 1에 도시된 음악 교수 장치가 제공하는 사용자 인터페이스의 예를 나타낸다. 도 5는 도 1에 도시된 음악 교수 장치의 동작의 흐름도를 나타낸다."}
