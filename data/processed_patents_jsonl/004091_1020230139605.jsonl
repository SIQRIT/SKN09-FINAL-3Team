{"patent_id": "10-2023-0139605", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0057177", "출원번호": "10-2023-0139605", "발명의 명칭": "이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝시", "출원인": "재단법인 지능형자동차부품진흥원", "발명자": "성재호"}}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에 있어서, 제1 특징 추출부(210)는 3D 객체 인지를 위한 손실 함수로서 RoI(Region of Interest)의 산출이 가능한 IoU(Intersection over Union)가 적용되는 것; 을 특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 제2 특징 추출부(220)는 N-1 레이어에서 출력된 제2 특징 데이터와 제1 특징 추출부(210)의이전 레이어에서 출력된 제1 특징 데이터를 융합하고, 융합된 데이터를 합성곱 신경망(CNN) 및 비전트랜스 포머(ViT)를 이용하여 제2 특징 데이터를 추출하고, 제1 특징 추출부(210)의 N 레이어에 출력하는 것; 특징으로 하는"}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 제1 특징 추출부(210)는 제2 특징 추출부(220)에서 추출된 라이다 센서 위치와 라이다 센서 특성이 포함된 제2 특징 데이터와 원시 라이다 포인트 클라우드 데이터를 융합하여 새로운 차량과 센서에 대한 정보를 학습하여 객체 인지 정보가 포함된제1 특징 데이터를 추출하는 것; 을 특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한라이다 센서 특성 기반 딥러닝 시스템."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서, 제1 특징 추출부(210)는 원시 라이다 포인트 클라우드 데이터를 격자 형태의 복셀로 변환하여 3D 공간을 그리드로 분할하고, 복셀화된데이터를 합성곱 신경망(CNN)을 이용하여 복수의 레이어 별로 순차적으로 3D 객체 인지 정보를 추출하는 것; 을특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템.공개특허 10-2025-0057177-3-청구항 5"}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서, 제2 특징 추출부(220)는 제1 특징 출력부의 각 레이어별 출력을 입력으로 받아 라이다 센서의 위치와 각도, 라이다 센서의 수직 해상도,수평 해상도, 탐지 범위, 수직 시야각, 라이다 채널 수 중 적어도 하나가 포함된 멀티-스케일 정보를 추출하는것; 을 특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 제2 특징 추출부(220)는 라이다 센서의 위치와 특성을 추출하기 위해 CNN(Convolutional Neural Network)과 ViT(Vison Transfomer)를통해 공간 데이터를 추출하여 시간에 따라 시계열 특징 추출을 위한 BiLSTM(Bidirectional Long Short TermMemory) 구조를 적용하는 것; 을 특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 제2 특징 추출부(220)는Many to Many 입출력 구조 인 것; 을 특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한라이다 센서 특성 기반 딥러닝 시스템."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서, 제2 출력부(320)는 라이다 센서의 위치 및 특성을 학습하기 위한 손실함수로서 MAE(MeanAbsolute Error)와 RMSE(Root Mean Squared Error)를 사용하는 것; 을 특징으로 하는 이종 자율주행 자동차의인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "a)원시 라이다 포인트 클라우드 데이터가 입력되는 단계;b)제1 특징 추출부(210)에서 복셀 데이터로 변환하는 단계;c)제1 특징 추출부(210) 및 제2 특징 추출부(220)에서 복수 레이어를 거쳐 제1 특징 데이터와 제2 특징 데이터를 추출하는 단계;d)제1 출력부(310)에서 제1 특징 데이터를 출력하는 단계; 및 e)제2 출력부(320)에서 제2 특징 데이터를 출력하는 단계;를 포함하고,c) 단계에서, 공개특허 10-2025-0057177-4-제1 특징 추출부(210)는 제2 특징 추출부(220)의 제2 특징 데이터에 포함된 라이다 센서의 특성 정보를 참조하여 3D 객체 인지(3D object detection)를 하고, 제2 특징 추출부(220)는 각 레이어 마다 제1 특징 추출부(210)의 3D 객체 인지(3D object detion)의 특징 정보가 입력됨에 따라 포인트 클라우드 갯수나 객체가 감지되는 특징 정보를 참조하여 라이다의 특성을 학습하는것; 을 특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 방법."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10항에 있어서, c)단계는제2 특징 추출부(220)가 N-1 레이어에서 출력된 제2 특징 데이터와 제1 특징 추출부(210)의 이전 레이어에서 출력된 제1 특징 데이터를 융합하고, 융합된 데이터를 합성곱 신경망(CNN) 및 비전트랜스 포머(ViT)를 이용하여제2 특징 데이터를 추출하고, 제1 특징 추출부(210)의 N 레이어에 출력하는 단계와, 제1 특징 추출부(210)가 제2 특징 추출부(220)에서 추출된 라이다 센서 위치와 라이다 센서 특성이 포함된 제2특징 데이터와 원시 라이다 포인트 클라우드 데이터를 융합하여 새로운 차량과 센서에 대한 정보를 학습하여 객체 인지 정보가 포함된 제1 특징 데이터를 추출하는 단계; 를 포함하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 10에 있어서, b) 단계는제1 특징 추출부(210)가 원시 라이다 포인트 클라우드 데이터를 격자 형태의 복셀로 변환하여 3D 공간을 그리드로 분할하는 것; 을 특징으로 하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 방법."}
{"patent_id": "10-2023-0139605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 10에 있어서, c)단계는c-1)제1 특징 추출부(210)가 N-1 레이어의 데이터로부터 합성곱 신경망을 통해 제1 특징 데이터를 추출하여 N레이어의 제1 특징 추출부(210)와, N-1 레이어의 제2 특징 추출부(220)에 출력하는 단계;c-2)제2 특징 추출부(220)가 N-1 레이어의 제1 특징 추출부(210)의 제1 특징 데이터를 입력받아 N-1 레이어의제2 특징 데이터를 추출하고 N 레이어의 제1 특징 추출부(210)로와 제2 특징 추출부(220)로 각각 출력하는단계;c-3)제1 특징 추출부(210)가 N-1 레이어의 제1 특징 데이터와, 제2 특징 데이터를 융합하여 N 레이어의 제1 특징 데이터를 추출하여 제1 출력부(310)로 출력 또는 N 레이어의 제2 특징 추출부(220)로 출력하는 단계; 및 c-4)제2 특징 추출부(220)가 N 레이어의 제1 특징 데이터와 N-1 레이어의 제2 특징 데이터를 융합하여 N 레이어의 제2 특징 데이터를 추출하여 제2 출력부(320)로 출력하는 단계; 를 포함하는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 방법."}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 원시 라이다 포인트 클라우드 데이터가 입력되는 입력부; 입력부에서 출력된 원시 라이다 포인트 클라우드 데이터에서 3D 객체 인지 정보가 포함된 제1 특징 데이터를 추출하는 제1 특징 추출부; 제 1 특징 추출부에서 추출된 제1 특징 데이터로부터 라이다 센서의 위치 및 특성이 포함된 제2 특징 데이터를 추출하는 제2 특징 추출부; 제1 특징 추출부에서 추출된 제1 특징 데이터를 출력하는 제1 출력부 ; 및 제2 특징 추출부에서 추출된 제2 특징 데이터를 출력하는 제2 출력부; 를 포함한다."}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이종 자율주행 자동차의 인공지능인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이종 자율주행차량의 인공지능 인지 모델 간 호환성 보장은 학습데이터 수집에 소요되는 시간과 노력을 줄이기 위한 중요한 과제이다. 여기서 자율주행차량의 인지 알고리즘은 주변 환경을 파악하기 위해 인공지능 학습을 활용한다. 그리고 학습데 이터는 주변 환경을 나타내며, 주로 실제 개발 차량에 장착된 센서에서 획득한 데이터를 사용하여 모델을 개발 한다. 그러나 종래의 기술은 자율주행차량의 개발 환경이 변경되면 이종 차량 간의 센서 위치나 종류의 차이로 새로운 입력 데이터 특성을 반영하지 못하며, 이는 학습데이터와 실제 입력 데이터의 특성 불일치 문제로 인지 모델의 성능저하 결과를 초래하는 문제점이 있었다. 또한, 라이다 센서는 차량 주변을 인식하는 데 중요한 역할을 하며, 차량 간 인공지능 모델 호환성을 향상시키 기 위해 데이터 특성을 활용할 수 있다. 종래에는 차량 간 인지 모델 호환성을 위해 라이다 데이터 분석, 특징 추출 및 딥러닝 기술을 결합하여 통합 인 식 모델을 만드는 포괄적인 프레임워크를 제안하였다. 또한, 종래의 3D 라이다 데이터의 객체 인식을 위한 딥러닝 아키텍처는 포인트 클라우드 데이터를 입력으로 받 아들이고, 이를 처리하여 주변 환경에서 객체를 감지하고 분류한다. 특히, 복셀 기반의 접근법은 입력 포인트 클라우드 데이터를 3D 공간 내 작은 복셀로 분할하고, 각 블록 내의 포인트들의 특징 데이터를 추출하여 처리하는 방식을 채택한다. 이후 합성곱 신경망과 같은 구조를 활용하여 특 징 데이터를 학습하고, 객체를 인식한다. 또한, 종래의 3D 객체 검출 네트워크는 객체 인식 알고리즘 중 하나로, 특히 3D 라이다 객체 인식을 위해 개발 되었다. 이 네트워크는 3D 박스 예측과 같은 특수한 기능을 수행하도록 설계되며, 복셀 기반 네트워크에 추가적 인 모듈을 통합하여 3D 객체의 위치 크기, 방향 등을 정확하게 예측한다. 그러나 이와 같은 종래의 기술들은 특정 차량 및 센서에 의존하여 학습되기 때문에 기존 데이터 내에서는 우수 한 성능을 보이지만, 개발 환경 변화 시 모델의 일반화 능력이 저하됨에 따라 이종 차량간에 데이터 불일치 문 제가 발생할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2023-0045696 A(2023.04.05 공개)"}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "그러므로 본 발명은 자율주행차 개발 환경이 바뀜에도 새로운 데이터 취득 없이 이미 취득된 데이터의 개발 환 경 특성을 고려한 인공지능 학습 모델을 설계하여 이종 차량 간의 데이터 불일치 문제를 해결할 수 있는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝시스템 및 방법을 제공함에 있다."}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 위와 같은 목적을 달성하기 위하여 하기와 같은 실시예를 포함할수 있다. 본 발명의 실시예는 원시 라이다 포인트 클라우드 데이터가 입력되는 입력부와, 입력부에서 출력된 원시 라이다 포인트 클라우드 데이터에서 3D 객체 인지 정보가 포함된 제1 특징 데이터를 추출하는 제1 특징 추출부와, 제1 특징 추출부에서 추출된 제1 특징 데이터로부터 라이다 센서의 위치 및 특성이 포함된 제2 특징 데이터를 추출 하는 제2 특징 추출부와, 제1 특징 추출부에서 추출된 제1 특징 데이터를 출력하는 제1 출력부 및 제2 특징 추출부에서 추출된 제2 특징 데이터를 출력하는 제2 출력부를 포함하고, 제1 특징 추출부는 제2 특징 추출부의 제 2 특징 데이터에 포함된 라이다 센서의 특성 정보를 참조하여 3D 객체 인지(3D object detection)를 하고, 제2 특징 추출부는 각 레이어 마다 제1 특징 추출부의 3D 객체 인지(3D object detion)의 특징 정보가 입력됨에 따 라 포인트 클라우드 갯수나 객체가 감지되는 특징 정보를 참조하여 라이다의 특성을 학습하는 것을 특징으로 하 는 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템을 제공할 수 있다. 또한, 제2 특징 추출부는 N-1 레이어에서 출력된 제2 특징 데이터와 제1 특징 추출부의 이전 레이어에서 출력된 제1 특징 데이터를 융합하고, 융합된 데이터를 합성곱 신경망(CNN) 및 비전트랜스 포머(ViT)를 이용하여 제2 특 징 데이터를 추출하고, 제1 특징 추출부의 N 레이어에 출력할 수 있다. 또한, 제1 특징 추출부는 제2 특징 추출부에서 추출된 라이다 센서 위치와 라이다 센서 특성이 포함된 제2 특징 데이터와 원시 라이다 포인트 클라우드 데이터를 융합하여 새로운 차량과 센서에 대한 정보를 학습하여 객체 인 지 정보가 포함된 제1 특징 데이터를 추출할 수 있다. 또한, 제1 특징 추출부는 원시 라이다 포인트 클라우드 데이터를 격자 형태의 복셀로 변환하여 3D 공간을 그리 드로 분할하고, 복셀화된 데이터를 합성곱 신경망(CNN)을 이용하여 복수의 레이어 별로 순차적으로 3D 객체 인 지 정보를 추출할 수 있다. 또한, 제1 특징 추출부는 3D 객체 인지를 위한 손실 함수로서 RoI(Region of Interest)의 산출이 가능한 IoU(Intersection over Union)가 적용될 수 있다. 또한, 제2 특징 추출부는 제1 특징 출력부의 각 레이어별 출력을 입력으로 받아 라이다 센서의 위치와 각도, 라 이다 센서의 수직 해상도, 수평 해상도, 탐지 범위, 수직 시야각, 라이다 채널 수 중 적어도 하나가 포함된 멀 티-스케일 정보를 추출할 수 있다. 또한, 제2 특징 추출부는 라이다 센서의 위치와 특성을 추출하기 위해 CNN(Convolutional Neural Network)과 ViT(Vison Transfomer)를 통해 공간 데이터를 추출하여 시간에 따라 시계열 특징 추출을 위한 BiLSTM(Bidirectional Long Short Term Memory) 구조를 적용할 수 있다. 또한, 제2 특징 추출부는 Many to Many 입출력 구조일 수 있다. 또한, 제2 출력부는 라이다 센서의 위치 및 특성을 학습하기 위한 손실함수로서 MAE(Mean Absolute Error)와 RMSE(Root Mean Squared Error)를 사용할 수 있다. 본 발명은 다른 실시예로서 a)원시 라이다 포인트 클라우드 데이터가 입력되는 단계와, b)제1 특징 추출부에서 복셀 데이터로 변환하는 단계와, c)제1 특징 추출부 및 제2 특징 추출부에서 복수 레이어를 거쳐 제1 특징 데이 터와 제2 특징 데이터를 추출하는 단계와, d)제1 출력부에서 제1 특징 데이터를 출력하는 단계 및 e)제2 출력부 에서 제2 특징 데이터를 출력하는 단계를 포함하고, c) 단계에서 제1 특징 추출부는 제2 특징 추출부의 제2 특 징 데이터에 포함된 라이다 센서의 특성 정보를 참조하여 3D 객체 인지(3D object detection)를 하고, 제2 특징 추출부는 각 레이어 마다 제1 특징 추출부의 3D 객체 인지(3D object detion)의 특징 정보가 입w력됨에 따라 포 인트 클라우드 갯수나 객체가 감지되는 특징 정보를 참조하여 라이다의 특성을 학습할 수 있다. 여기서 c)단계는 제2 특징 추출부가 N-1 레이어에서 출력된 제2 특징 데이터와 제1 특징 추출부의 이전 레이어 에서 출력된 제1 특징 데이터를 융합하고, 융합된 데이터를 합성곱 신경망(CNN) 및 비전트랜스 포머(ViT)를 이 용하여 제2 특징 데이터를 추출하고, 제1 특징 추출부의 N 레이어에 출력하는 단계와, 제1 특징 추출부가 제2 특징 추출부에서 추출된 라이다 센서 위치와 라이다 센서 특성이 포함된 제2 특징 데이터와 원시 라이다 포인트 클라우드 데이터를 융합하여 새로운 차량과 센서에 대한 정보를 학습하여 객체 인지 정보가 포함된 제1 특징 데 이터를 추출하는 단계를 포함할 수 있다. 또한, b) 단계는 제1 특징 추출부가 원시 라이다 포인트 클라우드 데이터를 격자 형태의 복셀로 변환하여 3D 공 간을 그리드로 분할할 수 있다. 또한, c)단계는 c-1)제1 특징 추출부가 N-1 레이어의 데이터로부터 합성곱 신경망을 통해 제1 특징 데이터를 추 출하여 N 레이어의 제1 특징 추출부와, N-1 레이어의 제2 특징 추출부에 출력하는 단계와, c-2)제2 특징 추출부 가 N-1 레이어의 제1 특징 추출부의 제1 특징 데이터를 입력받아 N-1 레이어의 제2 특징 데이터를 추출하고 N 레이어의 제1 특징 추출부와 제2 특징 추출부로 각각 출력하는 단계와, c-3)제1 특징 추출부가 N-1 레이어의 제 1 특징 데이터와, 제2 특징 데이터를 융합하여 N 레이어의 제1 특징 데이터를 추출하여 제1 출력부로 출력 또는N 레이어의 제2 특징 추출부로 출력하는 단계 및 c-4)제2 특징 추출부가 N 레이어의 제1 특징 데이터와 N-1 레 이어의 제2 특징 데이터를 융합하여 N 레이어의 제2 특징 데이터를 추출하여 제2 출력부로 출력하는 단계를 포 함할 수 있다."}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 다양한 이종 차량 및 라이다 센서에서 수집한 데이터의 특성을 학습하므로, 추가적인 데이터 수집 없 이 기존 대용량의 오픈 데이터 셋을 모델 학습에 활용함으로써 차량 및 센서별로 개별적으로 데이터를 수집하고 라벨링하는 비용과 시간을 절감할 수 있다. 또한, 본 발명은 3D 라이다 데이터의 특성을 최대한 활용하여 객체 인식을 수행하므로, 객체의 속성을 정확하게 파악하고 분류하는 능력이 향상될 수 있다. 또한, 본 발명은 개발 환경이 변화하더라도, 이미 존재하는 오픈 데이터셋을 활용하여 모델을 업데이트하고 새 로운 환경에 빠르게 대응할 수 있다. 또한, 본 발명은 본 발명은 자율주행차의 핵심 기술인 객체 인식의 성능과 안정성을 높여, 다양한 환경에서의 안전하고 신뢰성 있는 자율주행 시스템을 구축하는 데 기여할 수 있다."}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성 요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 발명의 실시 예에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시 예들의 설 명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 실시 예들에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 실시 예들의 전반에 걸친 내용을 토대로 정의되어야 한다. 이하부터는 본 발명에 따른 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 시스템 및 방법의 바람직한 실시예를 설명한다. 도 1은 본 발명에 따른 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러 닝시스템을 도시한 블럭도이다. 도 1 및 도 2를 참조하면, 본 발명은 입력부와, 제1 특징 추출부와, 제1 출력부, 제2 특징 추출 부와 제2 출력부를 포함할 수 있다. 입력부는 라이다 센서로부터 수집되는 원시 라이다 포인트 클라우드 데이터(Point Cloud Data)를 입력 받 는다. 제1 특징 추출부는 원시 라이다 포인트 클라우드 데이터에서 3D 객체 인지에 관한 정보를 학습하기 위한 제1 특징 데이터를 추출한다. 제1 특징 데이터는 3D 객체 인지에 관한 손실함수로서 학습된다. 제2 특징 추출부는 원시 라이다 포인트 클라우드 데이터 및 제1 특징 추출부에서 추출된 출력값에서 라이다 센서의 위치와 특성 정보가 포함된 제2 특징 데이터를 추출한다. 제2 특징 데이터는 라이다 센서의 위치 및 특성을 학습하기 위한 손실함수로서 학습된다. 또한, 제2 특징 추출부는 제1 특징 추출부에서 각 레이어의 출력 특징 맵(CNN의 차원)이 입력되면, 합성곱 신경망(CNN)에 의한 제2 특징 맵 추출 ->합성곱 신경망(CNN)에서 비전트랜스 포머(ViT)로 입력 차원 변 환 -> 비전 트랜스포머(ViT)에서 합성곱 신경망(CNN)으로 입력변환 과정을 거쳐 추출된 데이터를 다음 레이어의 제1 특징 추출부로 추출하는 과정을 진행한다. 여기서 제1 특징 추출부는 제2 특징 추출부에서 추출된 라이다 센서 위치와 라이다 센서 특성이 포함 된 정보를 입력받아 새로운 차량과 센서에 대한 정보를 통해 객체 인지 정보를 추출할 수 있고, 그 결과값을 다 시 제2 특징 추출부로 출력한다. 즉, 본 발명은 제1 특징 추출부와 제2 특징 추출부와 같이 딥러닝 네트워크를 2개로 분할하고, 서로 독립적으로 특징 데이터를 학습하되, 이종 차량이나 신규 센서에 관한 추론 및 학습을 위하여 상호 간의 출력값 을 융합하는 과정을 거칠 수 있도록 하여 정확성을 높일 수 있고, 라이다 센서의 위치 및 특성과, 객체 인지에 관한 특징이 상충되는 것을 방지한다. 보다 구체적으로 설명하자면, 제1 특징 추출부는 입력부에서 출력된 원시 라이다 포인트 클라우드를 효율적으로 처리하기 위한 복셀화를 적용 후 복수의 레이어별로 제1 특징 데이터를 추출 및 융합할 수 있다. 여기서 복셀화는 3D 포인트 클라우드 데이터를 격자 형태의 복셀로 변환하는 과정으로, 이를 통해 3D 공간을 그 리드로 분할하고 객체를 효과적으로 표현할 수 있다. 복셀화 과정은 다음과 같이 나타낼 수 있다. 예를 들면, 제1 특징 추출부는 입력된 원시 라이다 포인트 데 이터의 복셀 크기를 로 정의하고 복셀 중심을 계산한다. 각 복셀 의 중심좌표 는 아래의 수학식을 통해 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, 복셀 내부에 여러 개의 점 데이터가 있는 경우, 그것을 하나의 점으로 취급하여 계산 및 처리를 효율적으 로 수행한다. 그리고, 제1 특징 추출부는 복셀화된 데이터를 합성곱 신경망(CNN)을 이용하여 복수의 레이어 별로 순차적 으로 3D 공간 특징(예를 들면, 3D 객체 인지)을 추출하여 제1 출력부로 출력한다. 여기서 제1 특징 추출부 는 복수의 레이어별로 순차 적으로 제1 특징 데이터를 추출하되, 각 계층(Layer)에서 제2 특징 추출부 의 결과값과 융합되어 다음 계층에 결과값을 출력한다. 즉, 제1 특징 추출부는 복셀화 이후 복수의 레이어별로 순차적으로 합성곱 신경망을 이용한 3D 공간 내의 특징 데이터를 추출하되, 제2 특징 추출부의 결과값과 융합되어 다음 계층으로 출력되는 결과값을 추출한 다. 그리고 제1 특징 추출부는 3D 객체 감지를 위한 손실 함수로서 RoI(Region of Interest)의 산출이 가능한 IoU(Intersection over Union)가 적용될 수 있다. 여기서 IoU(Intersection over Union)는 예측된 바운딩 박스 와 타겟 바운딩 박스 간의 겹치는 영역의 비율을 측정하여 IoU(Intersection over Union)를 최대화하도록 모델을 학습시키는 손실함수이다. 또한, 손실함수는 RoI(Region of Interest) 내의 객체 분류를 위하여 엔트로피와 소프트맥스 함수가 적용될 수 있다. 엔트로피와 소프트맥스 함수가 적용되는 손실함수는 모델의 예측값과 실제 클래스 레이블 간의 차이를 측정하여 모델을 학습시킨다. 그러므로 다중 클래스 분류에서는 소프트맥스 함수를 통해 클래스 확률을 계산하고, 이를 실제 클레스 레이블과 비교하여 손실을 계산한다. 제2 특징 추출부는 제1 특징 출력부의 각 레이어별 출력을 입력으로 받아 단계에서 나온 출력을 입력으로 받아 라이다 센서의 위치와 특성에 대한 정보(예를 들면, 라이다 위치(x, y, z)와 각도(roll, pitch, yaw),라이 다 센서의 수직 해상도, 수평 해상도, 탐지 범위, 수직 시야각, 라이다 채널 수)가 포함된 멀티-스케일 정보를 추출한다. 이를 위하여 제2 특징 추출부는 위와 같은 라이다 센서의 위치와 특성을 추출하기 위해 CNN(Convolutional Neural Network)과 ViT(Vison Transfomer)를 통해 공간적인 데이터를 추출한다. 그리고 데이터는 시간에 따라 시계열 특징 추출을 위한 BiLSTM(Bidirectional Long Short Term Memory)을 이용한다. 예를 들면, 제2 특징 추출부는 CNN과 ViT, BiLSTM을 결합하여 지역적 특징과 전역적 특징, 시퀀스 데이터 를 아래와 같은 수학식 2로서 처리한다. 수학식 2"}
{"patent_id": "10-2023-0139605", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 는 입력 시퀀스, 는 CNN과 ViT의 입력 차원을 맞추기 위한 과정을 의미한다. CNN은 더 작은 지역적 정보 추출에 강점이 있으며, ViT는 전역적인 정보를 잘 추출할 수 있다. 그러므로 제2 특징 추출부는 이와 같은 CNN과 ViT의 결합을 통해 포인트 클라우드 데이터 내에서 멀티-스 케일 정보를 추출할 수 있다. 여기서 멀티-스케일 정보는 CNN의 각 레이어에서 추출된 특징맵(feature map)에 대해서 각 레이어 마다 추출된 특징(정보)을 의미한다. 이때, 멀티 스케일 정보는 CNN에서 각 레이어 마다 특징 데이터를 국소적인 영역에 대해 더 자세히 추출하기 위 해 CNN의 각 레이어 마다 제1 특징 추출부의 출력을 다운 샘플링을 하게 되므로 각 레이어 마다 추출되는 정보가 다를 수 있다. 이는 데이터의 다양한 측면을 고려한다는 점에서 더 풍부한 특성을 추출하고 높은 성능을 얻을 수 있기 위한 것 이다. 즉, ViT는 비교적 경량적인 구조이므로 CNN과 결합 시 더 경량화된 모델을 만들 수 있으며, 이는 모델 배포와 메모리 사용량을 줄이는 효과가 있다. 또한, 제2 특징 추출부는 마지막 레이어의 출력값에 BiLSTM 방식을 적용하여 공간적 특징뿐만 아니라, 시 퀀스 데이터의 시간적 특징 데이터를 모두 고려한 포인트 클라우드의 이전 프레임에 대한 정보를 이용한다. 즉, 제2 특징 추출부는 포인트 클라우드 데이터의 특징 데이터를 시간의 순방향과 역방향 모두에 대해서 특징 데이터를 추출하기 위해 마지막 레이어의 출력값에 BiLSTM(Bidirectional Long Short-Term Memory) 구조를 사 용한다. 여기서 BiLSTM은 LSTM(Long Short Term Memory)의 순방향과 역방향의 결합으로 구성된다. 또한, 제2 특징 추출 부는 BiLSTM(Bidirectional Long Short-Term Memory)을 사용했을 때 시퀀스 데이터를 지정된 갯수를 받아 하나를 출력하는 것이 아닌 하나의 시퀀스를 받아도 바로 출력할 수 있는 Many to Many 입출력 구조로 설계됨이 바람직하다. 즉, 본 발명은 제1 특징 추출부의 출력값이 제2 특징 추출부로 입력되고, 제2 특징 추출부의 출 력값은 제1 특징 추출부의 다음 레이어서 입력되어 이전 레이어의 출력값과 융합된다. 그리고 제1 특징 추출부는 제2 특징 추출부와 이전 레이어의 출력값이 융합된 데이터를 통하여 다음 레이어를 진행하여 제1 특징 데이터를 추출한다. 이와 같은 방식으로 최종 레이어까지 제1 특징 추출부와 제2 특징 추출부의 입력이 이루어진다. 그리고 제1 특징 추출부는 최종 레이어 이후의 결과값을 제1 출력부로 출력하고, 제2 특징 추출부 는 최종 레이어 이후의 출력값을 BiLSTM 구조에 적용하여 포인트 클라우드 데이터의 특징 데이터를 시간의 순방향과 역방향 모두에 대해서 특징 데이터를 추출하여 제2 출력부로 출력한다. 여기서 제1 특징 추출부는 원시 라이다 포인트 클라우드 데이터에서 객체 인지에 관한 정보를 추출하고, 제2 특징 추출부는 원시 라이다 포인트 클라우드 데이터 및 제1 특징 추출부에서 추출된 출력값에서 라이다 센서의 위치와 특성 정보를 추출하여 제1 특징 출력부로 입력한다. 따라서 제1 특징 추출부는 복수의 레이어의 특징맵을 통해 3D 객체 인지(3D object detection)하기 위한 모델을 학습할 때 제2 특징 추출부의 각 레이어에 해당하는 특징 맵이 결합됨에 따라 라이다 센서의 위치 및 특성 정보를 참조하는 효과가 있다. 더 자세히 설명하자면, 제1 특징 추출부는 제2 특징 추출부에서 학습하는 프로세스가 라이다 특성이 기 때문에 점차 학습이 진행됨에 따라 라이다가 몇 채널이고 x, y, z 축 방향과 크키는 몇임을 참조하여 3D 객 체 인지(3D object detection)을 할 수 있다. 반대로 제2 특징 추출부는 각 레이어 마다 제1 특징 추출부의 3D 객체 인지(3D object detion)의 특 징 정보가 입력됨에 따라 포인트 클라우드 갯수나 객체가 감지되는 특징 정보를 참조하여 라이다의 특성을 학습 할 수 있다. 또한, 제2 출력부는 라이다 센서의 위치 및 특성을 학습하기 위한 손실함수로서 MAE(Mean Absolute Erro r)와 RMSE(Root Mean Squared Error)를 사용한다. MAE(Mean Absolute Error)는 비교적 에러 값을 구하기 쉬운 수직 해상도, 수평 해상도, 수직 시야각, 라이다 채 널 수에 대해 사용된다. RMSE(Root Mean Squared Error)는 MAE(Mean Absolute Error)가 적용되지 않는 나머지 더 민감한 평가지표가 필요한 항목에 대해서를 사용한다. 전체 손실함수는 제1 출력부와 제2 출력부의 전체 손실함수의 합으로 구성되며, 각 손실함수에 적절 한 계수 값을 곱하여 손실함수가 한 곳에 편향되어 학습되지 않도록 계수 값을 조정함이 바람직하다. 제1 출력부는 제1 특징 추출부에서 추출된 객체 인식 정보를 출력한다. 제2 출력부는 제2 특징 추출부에서 추출된 라이다 센서의 위치 및 특성에 관한 정보를 출력한다. 구 체적으로, 제2 출력부는 라이다 위치(x, y, z)와 각도(roll, pitch, yaw),라이다 센서의 수직 해상도, 수 평 해상도, 탐지 범위, 수직 시야각, 라이다 채널 수에 대한 정보를 출력한다. 아울러, 제2 출력부는 복수의 프레임별로 입력된 횟수를 카운트 하여 설정된 횟수가 감지하여 입력 프레임 이 마지막 프레임 이면 제2 특징 추출부에서 출력된 제2 특징 데이터를 출력한다. 또는 제2 출력부는 설정된 입력 횟수에 도달되지 않으면, 카운트를 초기화 한 뒤에 제2 특징 추출부에서 추출된 제2 특징 데 이터를 출력한다. 본 발명은 위와 같은 구성을 포함하며 이하에서는 본 발명에 따른 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러닝 방법을 설명한다. 도 3은 본 발명에 따른 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러 닝방법을 도시한 순서도이고, 도 4는 도 3의 S30 단계를 도시한 순서도이다. 도 3 및 도 4를 참조하면, 본 발명은 포인트 클라우드 데이터가 입력되는 S10 단계와, 복셀 데이터로 변환하는 S20 단계와, 복수 레이어를 거쳐 제1 특징 데이터와 제2 특징 데이터를 각각 추출하는 S30 단계와, 제1 특징 데 이터를 출력하는 S40 단계와, 제2 특징 추출부에서 출력된 출력값의 입력 회수를 감지하는 S50 단계와, 제 2 특징 추출부의 입력 프레임을 카운트 또는 카운트를 초기화하는 S60 단계와, 제2 특징 데이터를 출력하 는 S70 단계를 포함한다. S10 단계는 입력부가 원시 라이다 포인트 클라우드 데이터를 수신하는 단계이다. 여기서 원시 라이다 포인 트 클라우드 데이터는 라이다 센서의 실시간 감지 데이터와 기존 저장 데이터 중 적어도 하나일 수 있다. S20 단계는 제1 특징 추출부가 입력부에서 출력된 원시 라이다 포인트 클라우드 데이터를 복셀화하는 단계이다. S30 단계는 원시 라이다 포인트 클라우드 데이터에서 제1 특징 추출부가 3D 객체 인지 정보가 포함된 제1 특징 데이터와, 제2 특징 추출부가 라이다 센서의 위치 및 특성을 포함하는 제2 특징 데이터를 추출하는 단계이다. 여기서 S30 단계는 도 4를 참조하면, 제1 특징 추출부와 제2 특징 추출부가 N개의 레이어 별로 각각 특징 맵을 추출하되, 제1 특징 추출부의 특징 맵은 제2 특징 추출부로 입력되고, 제2 특징 추출부 의 특징 맵은 제1 특징 추출맵의 다음 레이어에 입력되는 정보와 융합된다. 구체적으로 설명하자면, S30 단계는 제1 특징 추출부가 N-1 레이어의 제1 특징 데이터를 추출하는 S311 내 지 S312 단계와, N 레이어의 제1 특징 데이터를 추출하는 S331 및 S332 단계를 포함한다. 또한, S30 단계는 제2 특징 추출부가 N-1 레이어의 제2 특징 데이터를 추출하는 S321 내지 S326 단계와, N 레이어의 제2 특징 데이터를 추출하는 S341 내지 S345 단계를 포함한다. 이중, S311 단계는 제1 특징 추출부가 N-1 레이어의 데이터(원시 라이다 포인트 클라우드 데이터 또는 이 전 제1 특징 추출부와 제2 특징 추출부의 융합된 데이터)로부터 제1 특징 데이터를 추출하는 단계이 다. 여기서 제1 특징 추출부는 합성곱 신경망을 통해 제1 특징 데이터를 추출한다. S321 단계는 제2 특징 추출부가 N-1 레이어의 제1 특징 추출부의 제1 특징 데이터를 입력받는 단계이 다. S322 단계는 제2 특징 추출부가 N-1 레이어의 제2 특징 데이터를 비전 트랜스포머로 입력 변환하는 단계이 다. S323 단계는 제2 특징 추출부가 비전 트랜스포머를 통해 N-1 레이어의 제2 특징 데이터를 추출하는 단계이 다. S324 단계는 제2 특징 추출부가 제2 특징 데이터를 합성곱 신경망으로 입력 변환하여제1 특징 추출부(21 0)의 N-1 레이어로 출력하는 단계이다. S312 단계는 제1 특징 추출부가 N-1 레이어의 제1 특징 데이터와, 제2 특징 추출부이 제2 특징 데이 터를 융합하는 단계이다. 여기서 제1 특징 추출부는 융합된 데이터를 제1 특징 추출부의 N 레이어와, 제2 특징 추출부의 N-1 레이어에 각각 출력한다. S325 단계는 제2 특징 추출부가 N-1 레이어의 제1 특징 추출부에서 입력되는 융합 데이터와 S325 단 계의 제2 특징 데이터를 융합하는 단계이다. S331 단계는 제1 특징 추출부가 N 레이어에서 N-1 레이어의 융합 데이터에서 3D 객체 인식 정보가 포함된 제1 특징 데이터를 추출하는 단계이다. 여기서 제1 특징 추출부는 합성곱 신경망(CNN)을 적용할 수 있다. S341 내지 S344 단계는 제2 특징 추출부가 N-1 레이어에서 출력된 제2 특징의 융합 데이터와, S331 단계의 제1 특징 데이터를 융합하여 입력변환 후 비전 트랜스포머를 통해 제2 특징 데이터를 추출하고, N 레이어의 제1 특징 추출부로 출력한다. S332 단계는 제1 특징 추출부가 N 레이어에서 S331 단계와 S344 단계에서 각각 입력된 데이터를 융합하여 제1 출력부로 출력 또는 N 레이어의 제2 특징 추출부로 출력하는 단계이다. S345 단계는 제2 특징 추출부가 S344 단계의 제2 특징 데이터와 S332 단계의 융합 데이터를 융합하여 제2 출력부로 출력하는 단계이다. 여기서 제2 특징 추출부는 마지막 레이어의 출력값에 LSTM(Long Short Term Memory)의 순방향과 역방향의 결합으로 구성된 BiLSTM(Bidirectional Long Short-Term Memory) 방식을 적 용하여 공간적 특징뿐만 아니라, 시퀀스 데이터의 시간적 특징 데이터를 모두 고려한 포인트 클라우드의 이전 프레임에 대한 정보를 이용한다. S40 단계는 제1 출력부가 제1 특징 추출부에서 추출된 3D 객체 인지 정보를 출력하는 단계이다. S50 단계는 제2 출력부가 제2 특징 추출부를 구성하는 복수의 입력 프레임으로부터 입력되는 제2 특 징의 입력 횟수를 감지하는 단계이다. S60 단계는 제2 출력부가 제2 특징 추출부의 N개의 입력 프레임들로부터 출력되는 제2 특징의 입력 횟수가 N개이면 카운트를 초기화 또는 입력 횟수가 설정 횟수에 도달되지 않으면 입력 횟수를 카운트 하는 단계 이다. S70 단계는 제2 출력부가 제2 특징 추출부로부터 입력된 제2 특징 데이터를 추출하는 단계이다. 여기 서 제2 출력부는 제2 특징 추출부를 구성하는 N개의 입력 프레임으로부터 또는 설정된 갯수의 입력 프레임으로부터 추출된 제2 특징 데이터를 출력한다. 여기서 제2 특징 데이터는 라이다 센서의 위치와 특성 정 보가 포함되었다. 이와 같이 본 발명은 자율주행차의 주행 중 감지되는 주변 정보를 제1 특징 추출부와 제2 특징 추출부 로 분리된 네트워크를 통해 3D 객체 인지와 라이다 센서의 위치 및 특성 정보를 각각 별도의 딥러닝 네트 워크를 통해 학습 및 추론할 수 있기에 이종 차량 간 또는 다른 센서와의 호환성 문제를 해결할 수 있다."}
{"patent_id": "10-2023-0139605", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러 닝시스템을 도시한 블럭도이다. 도 2는 본 발명에 의한 딥러닝 아키텍처를 도시한 도면이다. 도 3은 본 발명에 따른 이종 자율주행 자동차의 인공지능 인지 모델 호환성을 위한 라이다 센서 특성 기반 딥러 닝방법을 도시한 순서도이다. 도 4는 특징 추출 과정을 상세 도시한 순서도이다."}
