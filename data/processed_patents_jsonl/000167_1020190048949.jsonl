{"patent_id": "10-2019-0048949", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0125131", "출원번호": "10-2019-0048949", "발명의 명칭": "인공지능 기반 영상 두께 측정 방법 및 시스템", "출원인": "(주)제이엘케이", "발명자": "김원태"}}
{"patent_id": "10-2019-0048949", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모델을 생성하는데 필요한 정보를 생성하는 모델 생성부;데이터를 학습하고 학습된 데이터를 평가하는 모델 학습 및 평가부; 및학습된 결과를 기반으로 수치화 및 시각화를 진행하는 수치화 및 시각화부를 포함하며,상기 수치화 및 시각화부는, 상기 모델 학습 및 평가부에서 나온 영상 영역의 두께의 비율 결과값을 3차원 시각화시키고 상기 비율 결과값과 하나의 영역의 복셀 거리 결과값을 측정한 후 이들을 결합하여 수치화하는, 인공지능 기반 영상 두께 측정 시스템."}
{"patent_id": "10-2019-0048949", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 모델 생성부는, 2차원 혹은 3차원 영상 데이터 중 확인하고자 하는 영역 혹은 전체를 검출한 후 상기 영역의 두께를 측정 및 분류하고 원본 데이터 공간에 표기함으로써 실지검증(ground truth) 데이터를 생성하는, 인공지능 기반 영상 두께 측정 시스템."}
{"patent_id": "10-2019-0048949", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1 또는 2에 있어서,상기 모델 학습 및 평가부는, 3차원 뇌 영상과 상기 모델 생성부에서 생성된 실지검증(ground truth)을 활용하여 3차원 합성곱신경망(convolutional neural network, CNN) 기반 인공신경망을 적용하여 학습하고 모델의 정확도 및 안정성에 대해 평가하는, 인공지능 기반 영상 두께 측정 시스템."}
{"patent_id": "10-2019-0048949", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "모델을 생성하는데 필요한 영상 정보를 생성하는 단계;검출된 각 관심 영역 두께를 측정하고 분류하는 단계;분류된 영역을 원본 데이터 공간에 표기함으로써 실지검증(ground truth) 데이터를 생성하는 단계;3차원 뇌 영상과 상기 생성하는 단계에서 생성된 실지검증을 활용하여 3차원 CNN 기반 인공신경망을 적용하고학습하는 단계;상기 학습하는 단계에서 생성된 모델에 대하여 데이터논증(data augmentation) 데이터와 학습에 사용하지 않은데이터를 사용하여 모델의 정확도 및 안정성에 대해 평가하는 단계; 및상기 평가하는 단계에서 나온 영상 영역 혹은 관심 영역의 두께의 비율 결과값을 3차원 시각화시키거나, 3차원시각화와 함께 상기의 비율 결과값과 하나의 영역의 복셀 거리 결과값을 측정한 후 결합하여 수치화하는 단계를포함하는, 인공지능 기반 영상 두께 측정 방법."}
{"patent_id": "10-2019-0048949", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "2차원 혹은 3차원 영상 정보를 인공신경망을 활용하여 영상 정보 내 관심 영상 또는 관심 영역의 두께나 부피를 측정하고 이를 시각화하는 방법 및 시스템이 개시된다. 인공지능 기반 뇌 영역 분류 시스템은, 인공지능 기반 영 상 두께 측정 시스템은 모델을 생성하는데 필요한 정보를 생성하는 모델 생성 부, 데이터를 학습하고 이를 평가 하는 모델 학습 및 평가부, 학습된 결과를 기반으로 수치화 및 시각화를 진행하는 수치화 및 시각화부를 포함하 여 이루어지며, 여기서 수치화 및 시각화부는, 모델 학습 및 평가부에서 나온 영상 영역의 두께의 비율 결과값을 3차원 시각화시키고 이 비율 결과값과 하나의 영역의 복셀(voxel) 거리 결과값을 측정한 후 결합하여 수치화한다."}
{"patent_id": "10-2019-0048949", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 2차원 혹은 3차원 영상 정보를 인공신경망을 활용하여 영상 정보 내 관심 영상 또는 관심 영역의 두 께나 부피를 측정하고 이를 시각화하는 시스템에 관한 것이다."}
{"patent_id": "10-2019-0048949", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래 기술에서 영상 내 관심 영상 부분이나 관심 영역의 두께를 측정하는 방법에는 특정 영역의 검출, 특정 영 역의 두께 측정, 시각화의 3가지 단계를 수행하는 것이 일반적이다. 특정 영역의 검출의 경우, 밝기(intensity)와 연속성 기반의 비교, 히스토그램(histogram) 기반의 특징 비교 등 을 통하여 검출하며, 특정 영역의 두께 측정의 경우 다양한 알고리즘을 통해 검출된 영역의 테두리 사이의 최단 거리를 측정하거나 각 복셀(voxel)이 갖는 영역내 최단 거리를 측정하는 방식으로 구성된다. 또한, 특정 영역의 두께 측정의 경우, 각 복셀 혹은 각 포인트(point) 별로 분석을 진행해야 하기 때문에 해당 3차원 영상의 크기가 커질수록 소요되는 시간이 크게 증가하는 단점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-1957811호(2019.03.13)"}
{"patent_id": "10-2019-0048949", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 문제점을 해결할 수 있고 영상 정보 내 관심 영역의 두께 혹은 부피 측정을 위한 방법 및 시스템을 제공하는데 그 목적이 있다. 본 발명의 다른 목적은, 2차원 혹은 3차원 영상 정보를 인공신경망을 활용하여 영상 정보 내 관심 영상 또는 관 심 영역의 두께나 부피를 측정하고 이를 시각화하는 방법 및 시스템을 제공하는데 있다."}
{"patent_id": "10-2019-0048949", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 측면에 따른 인공지능 기반 영상 두께 측정 시스템은 모델을 생성하는데 필요한 정보를 생성하는 모델 생성 부, 데이터를 학습하고 이를 평가하는 모델 학습 및 평가부, 학 습된 결과를 기반으로 수치화 및 시각화를 진행하는 수치화 및 시각화부를 포함하여 이루어지며, 여기서 수치화 및 시각화부는, 모델 학습 및 평가부에서 나온 영상 영역의 두께의 비율 결과값을 3차원 시각화시키고 이 비율 결과값과 하나의 영역의 복셀(voxel) 거리 결과값을 측정한 후 결합하여 수치화한다. 일실시예에서, 모델 생성부는, 2차원 혹은 3차원 영상 데이터 중 확인하고자 하는 영역 혹은 전체를 검출한후 이 영역의 두께를 측정 및 분류하고 원본 데이터 공간에 표기함으로써 실지검증(ground truth) 데이터를 생성한 다. 일실시예에서, 모델 학습 및 평가부는, 모델 학습 및 평가부의 경우 3차원 뇌 영상과 모델 생성부에서 생성된 실지검증(ground truth)을 활용하여 3차원 합성곱신경망(convolutional neural network, CNN) 기반 인공 신경 망을 적용하여 학습하고 모델의 정확도 및 안정성에 대해 평가한다. 상기 기술적 과제를 해결하기 위한 본 발명의 다른 측면에 따른 인공지능 기반 영상 두께 측정 방법은, 모델을 생성하는데 필요한 영상 정보를 생성하는 단계; 검출된 각 관심 영역 두께를 측정하고 분류하는 단계; 분류된 영역을 원본 데이터 공간에 표기함으로써 실지검증(ground truth) 데이터를 생성하는 단계; 3차원 뇌 영상과 상 기 생성하는 단계에서 생성된 실지검증을 활용하여 3차원 CNN 기반 인공신경망을 적용하고 학습하는 단계; 상기 학습하는 단계에서 생성된 모델에 대하여 데이터논증(data augmentation) 데이터와 학습에 사용하지 않은 데이 터를 사용하여 모델의 정확도 및 안정성에 대해 평가하는 단계; 및 상기 평가하는 단계에서 나온 영상 영역 혹 은 관심 영역의 두께의 비율 결과값을 3차원 시각화시키거나, 3차원 시각화와 함께 상기의 비율 결과값과 하나 의 영역의 복셀 거리 결과값을 측정한 후 결합하여 수치화하는 단계를 포함한다."}
{"patent_id": "10-2019-0048949", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 실시예의 인공지능 기반 영상 두께 측정 방법 및 시스템을 사용하는 경우에는, 2차원 혹은 3차원 영 상 정보를 인공신경망을 활용하여 영상 정보 내 관심 영상 또는 관심 영역의 두께나 부피를 측정하고 이를 시각 화하는 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2019-0048949", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아 니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 이하, 본 발명에 따른 바람직한 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명의 일실시예에 따른 인공지능 기반 영상 두께 측정 시스템을 설명하기 위한 블록도이다. 도 1을 참조하면, 본 실시예에 따른 인공지능 기반 영상 두께 측정 시스템은, 모델을 생성하는데 필요한 정보를 생성하는 모델 생성부와, 데이터를 학습하고 이를 평가하는 모델 학습 및 평가부와, 학습된 결 과를 기반으로 수치화 및 시각화를 진행하는 수치화 및 시각화부를 포함하여 이루어진다. 모델 생성부, 모델 학습 및 평가부, 및 수치화 및 시각화부는 프로세서에 탑재되어 프로세서 의 신호 처리 동작에 따라 해당 기능을 수행할 수 있다. 그 경우, 프로세서는 메모리에 연결되어 메모리에 저장된 제1 모듈, 제2 모듈 및 제3 모듈 등을 읽어들여 인공지능 기반 영상 두께 측정을 위한 일 련의 과정을 수행할 수 있다. 또한, 프로세서는 메모리나 다른 저장매체에 저장되거나 탑재되어 있는 인공신경망과 연동하여 2차원 혹은 3차원 영상 정보를 학습하고, 학습된 상태에서 영상 정보 내 관심 영상 이나 관심 영역의 두께나 부피에 대한 측정 작업 등을 수행할 수 있다. 각 구성요소를 좀더 구체적으로 설명하면, 모델 생성부는, 2차원 혹은 3차원 영상 데이터 중 확인하고자 하 는 영역 혹은 전체를 검출한 후 이 영역의 두께를 측정 및 분류하고 원본 데이터 공간에 표기함으로써 실지검증 (ground truth) 데이터를 생성한다. 이를 위해, 모델 생성부는 관심 영역을 추출하는 추출 유닛, 추출 된 관심 영역의 두께를 측정 및 분류하는 측정분류 유닛, 및 측정분류된 영역을 원본 데이터 공간에 표기하 는 실지검증 데이터 생성 유닛을 구비할 수 있다. 모델 생성부는 입력되는 영상 데이터를 대상 영상의 규격, 위치 등의 정보에 맞추어서 변형시켜 대상 영상과 유사한 형태를 띄게 만들 수 있다. 모델 학습 및 평가부는, 모델 학습 및 평가부의 경우 3차원 뇌 영상과 모델 생성부에서 생성된 실지검증 (ground truth)을 활용하여 3차원 합성곱신경망(convolutional neural network, CNN) 기반 인공신경망을 적용 하여 학습하고 모델의 정확도 및 안정성에 대해 평가한다. 이를 위해, 모델 학습 및 평가부는, 상기의 각 기능을 수행하는 인공신경망 적용 학습 유닛 및 평가 유닛을 구비할 수 있다. 실지검증(ground truth, GT)는 데이터 모델을 학습시킬 때 정답이 되는 데이터로써 학습 데이터 내에 대응되는 공간 혹은 값을 갖는 데이터를 나타낸다. 또한, 모델 학습 및 평가부는 데이터 논증(data argumentation)을 이용하여 학습 데이터 형성시 변형, 회전, 왜곡 등을 통하여 기존 틀을 탈피하지 않으면서 다른 데이터의 형태로 변형시켜 학습데이터 수를 증가시 킬 수 있다. 수치화 및 시각화부는, 모델 학습 및 평가부에서 나온 영상 영역의 두께의 비율 결과값을 3차원 시각화시키 고 이 비율 결과값과 한 영역의 복셀(voxel) 거리 결과값을 측정 후 결합하여 수치화할 수 있다. 이를 위해, 수치화 및 시각화부는 비율 결과값을 3차원 시각화시키는 영상 시각화 유닛, 비율 및 거리 결과값을 결합 하여 수치 정량화를 수행하는 수치 정량화 유닛을 구비할 수 있다. 전술한 모듈이나 유닛은 프로그램 혹은 소프트웨어 모듈로 구현되어 메모리나 저장매체에 저장될 수 있다. 도 2는 도 1의 시스템에 의한 모델 생성 과정을 설명하기 위한 흐름도이다. 도 3은 도 1의 시스템에 채용할 수 있는 3차원 CNN 기반 인공신경망에 대한 예시도이다. 도 4는 도 1의 시스템에 채용할 수 있는 시각화 및 수치화 과정을 설명하기 위한 예시도이다. 도 5는 본 발명에 따른 방법 및 시스템에 채용할 수 있는 두께 측정 방법에 대한 예시도이다. 도 2를 참조하면, 본 실시예에 따른 시스템에 채용가능한 모델 생성은 2차원 혹은 3차원의 원본 영상 데이터 중 확인하고자 하는 특정 영역 혹은 전체를 검출한 후 이 특정 영역의 두께를 측정 및 분류하고 원본 데이터 공간 에 이미지 매핑(image mappng)된 영상 데이터를 표기함으로써 실지검증(ground truth) 데이터를 생성한다. 도 3을 참조하면, 본 실시예에 따른 시스템에 채용가능한, 합성곱 신경망(convolutional neural network, CN N)은, 디컨볼루션(deconvolution), 스킵 컨넥션(skip connection) 등을 사용하여 CNN 기반 인공신경망으로 의 료 정보 내 영상 영역의 부피나 두께를 분류하도록 구현될 수 있다. CNN은 컨볼루션 네트워크와 디컨볼루션 네트워크 및 숏컷(shortcut)을 포함한 형태를 구비할 수 있다. CNN는 의 료 영상(X)의 특징을 추출하기 위하여 3x3 크기의 컬러 컨볼루션 레이어(convolution layer)와 액티베이션 레이 어(ReLU)를 쌓고 2x2 크기의 필터를 스트라이드(stride) 1로 적용하여 다음 하위 깊이 레벨로 연결되는 컨볼루 션 블록의 연산을 4회 반복하여 수행하고, 그 다음에 2x2 크기의 디컨볼루션 레이어(deconvolution layer)와 액 티베이션 레이어(ReLU)를 적용하여 다음 상위 깊이 레벨로 연결한 후 3x3 크기의 컬러 컨볼루션 레이어와 액티 베이션 레이어를 쌓는 역컨볼루션 블록의 연산을 4회 반복하여 수행하며, 여기서 각 레벨의 컨볼루션 블록의 연 산을 포함한 컨볼루션 네트워크의 각 레벨의 컨볼루션 블록의 이미지에 동일 레벨의 역컨볼루션 네트워크의 대 응 레벨의 컨볼루션 결과를 갖다 붙이고(copy and contatenate) 각 블록에서 컨볼루션 연산을 각각 수행하도록 이루어질 수 있다. 컨볼루션 네트워크와 디컨볼루션 네트워크 내 컨볼루션 블록은 conv-ReLU-conv 레이어들의 조합으로 구현될 수 있다. 그리고, 딥러닝 아키텍처의 출력은 컨볼루션 네트워크이나 디컨볼루션 네트워크에 연결되는 분류기를 통 해 얻어질 수 있으나, 이에 한정되지는 않는다. 분류기는 FCN(fully connectivity network) 기법을 이용하여 영 상에서 국소적인 특징을 추출하는데 이용될 수 있다. 또한, 딥러닝 아키텍처는 구현에 따라서 컨볼루션 블록 내에 인셉션 모듈(inseption module) 또는 멀티 필터 경 로(multi filter pathway)를 추가로 사용하도록 구현될 수 있다. 인셉션 모듈 또는 멀티 필터 경로 내 서로 다 른 필터는 1x1 필터를 포함할 수 있다. 참고로, 딥러닝 아키텍처에서 입력(input) 이미지가 가로 32, 세로 32, 그리고 RGB 채널을 가지는 경우, 의료 영상에 대응하는 입력 이미지(X)의 크기는 [32x32x3]일 수 있다. 딥러닝 아키텍처의 CNN(convloultional neural network)에서 콘볼루션(convolutional, CONV) 레이어는 입력 이미지의 일부 영역과 연결되며, 이 연결 된 영역과 자신의 가중치의 내적 연산(dot product)을 계산하도록 설계될 수 있다. 여기서, ReLU(rectified linear unit) 레이어는 max(0,x)와 같이 각 요소에 적용되는 액티베이션 함수 (activation function)이다. ReLU 레이어는 볼륨의 크기를 변화시키지 않는다. POOLING 레이어는 (가로, 세 로)로 표현되는 차원에 대해 다운샘플링(downsampling) 또는 서브샘블링(subsampling)을 수행하여 감소된 볼륨 을 출력할 수 있다. 그리고, 전연결(fully-connected, FC) 레이어는 클래스 점수들을 계산하여 예컨대 [1x1x10]의 크기를 갖는 볼륨 을 출력할 수 있다. 이 경우, 10개 숫자들은 10개 카테고리에 대한 클래스 점수에 해당한다. 전연결 레이어는 이전 볼륨의 모든 요소와 연결된다. 거기서, 어떤 레이어는 모수(parameter)를 갖지만 어떤 레이어는 모수를 갖 지 않을 수 있다. CONV/FC 레이어들은 액티베이션 함수로서 단순히 입력 볼륨만이 아니라 가중치(weight)와 바 이어스(bias)를 포함할 수 있다. 한편, ReLU/POOLING 레이어들은 고정된 함수로서, CONV/FC 레이어의 모수들은 각 이미지에 대한 클래스 점수가 해당 이미지의 레이블과 같아지도록 그라디언트 디센트(gradient descent)로 학습될 수 있다. 도 4를 참조하면, 본 실시예에 따른 시스템에서는 기존의 다양한 두께 측정 방법들에서 선택되는 어느 하나의 방법을 채용할 수 있다. 예를 들면, 본 실시예의 시스템에 채용가능한 두께 측정 방법으로는 결합 표면 방법(coupled surface methods), 최근접 포인트 방법(closest point methods), 라플라스 방법(laplace method) 등 이 있다. 도 5를 참조하면, 본 실시예에 따른 시스템에 채용할 수 있는 시각화 및 수치화 방법은, 학습된 결과를 기반으 로 수치화 및 시각화를 진행할 수 있다. 이를 위해, 시각화 및 수치화는 영상 시각화 유닛 및 수치 정량화 유닛 을 구비할 수 있다. 수치화 및 시각화부는, 모델 학습 및 평가부에서 나온 영상 영역의 두께의 비율 결과값을 3차원 시각화시키 고 이 비율 결과값과 한 영역의 복셀(voxel) 거리 결과값을 측정 후 결합하여 수치화할 수 있다. 이를 위해, 수 치화 및 시각화부는 비율 결과값을 3차원 CNN을 통해 3차원 시각화시키고, 비율 및 거리 결과값을 결합하여 수치 정량화를 수행할 수 있다. 도 6은 본 발명의 다른 실시예에 따른 인공지능 기반 영상 두께 측정 방법을 설명하기 위한 흐름도이다. 도 6을 참조하면, 본 실시예에 따른 인공지능 기반 영상 두께 측정 방법은, 먼저 모델을 생성하는데 필요한 영 상 정보를 생성한다(S51). 다음, 검출된 각 관심 영역 두께를 측정하고 분류하며, 분류된 영역을 원본 데이터 공간에 표기함으로써 실지검 증(ground truth) 데이터를 생성한다(S52). 이때 데이터의 다양성 및 학습 검증을 위하여 뇌의 대칭성을 이용한 반전 및 회전 왜곡 등을 사용하여 데이터 논증(data augmentation) 과정을 진행할 수 있다. 다음, 3차원 뇌 영상과 이전 과정에서 생성된 실지검증(ground truth)을 활용하여 3차원 CNN 기반 인공신경망을 적용하여 학습한다(S53). 이러한 학습 과정을 통해 학습된 모델이 생성될 수 있다. 다음, 이전 과정에서 생성된 모델에 대하여 데이터논증(data augmentation) 데이터, 및 학습에 사용하지 않은 데이터를 사용하여 모델의 정확도 및 안정성에 대해 평가한다(S54). 다음, 이전 과정에서 생성된 영상 영역(관심 영역)의 두께의 비율 결과값을 3차원 시각화시킨다(S55). 또한, 상 기의 비율 결과값과 한 영역의 복셀 거리 결과값을 측정한 후 결합하여 수치화할 수 있다(S56). 도 7은 본 발명의 실시예에 따른 영상의 특정 부위의 추출, 측정 및 시각화하는 일련의 과정이 실시간 거의 동 시적으로 수행되는 것을 보여주는 도면이다. 도 7의 (a) 내지 (c)에 도시한 바와 같이, 본 실시예의 시스템에 의한 대뇌 피질의 추출, 측정 및 시각화 과정 을 거치면, 대뇌 피질은 특정 색상의 그라데이션 형태로 시각화될 수 있고, 대뇌 피질이 두꺼울수록 진한 특정 색상(예컨대, 노란색)에 가깝게 표현되도록 시각화될 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2019-0048949", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 인공지능 기반 영상 두께 측정 시스템을 설명하기 위한 블록도이다. 도 2는 도 1의 시스템에 의한 모델 생성 과정을 설명하기 위한 흐름도이다. 도 3은 도 1의 시스템에 채용할 수 있는 3차원 CNN 기반 인공신경망에 대한 예시도이다. 도 4는 본 발명에 따른 방법 및 시스템에 채용할 수 있는 두께 측정 방법에 대한 예시도이다. 도 5는 도 1의 시스템에 채용할 수 있는 시각화 및 수치화에 대한 예시도이다. 도 6은 본 발명의 다른 실시예에 따른 인공지능 기반 영상 두께 측정 방법에 대한 흐름도이다. 도 7은 본 발명의 실시예에 따른 영상의 특정 부위의 추출, 측정 및 시각화하는 일련의 과정이 실시간 거의 동 시적으로 수행되는 것을 보여주는 도면이다."}
