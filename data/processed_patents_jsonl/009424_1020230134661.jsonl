{"patent_id": "10-2023-0134661", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0088558", "출원번호": "10-2023-0134661", "발명의 명칭": "메타버스를 통한 거래를 위한 안면 모션 캡처 시스템", "출원인": "(주) 텔로스", "발명자": "황큰별"}}
{"patent_id": "10-2023-0134661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 얼굴의 안면 움직임을 촬영하는 영상입력 장치;상기 영상입력 장치에서 입력된 영상을 머신러닝 모델에 적용하여 학습하고, 학습 결과에 기초하여 상기 영상입력 장치의 영상으로부터 사용자의 안면 움직임을 3차원 스켈레톤 값으로 변환하고, 변환된 3차원 스켈레톤 값에따라 아바타의 안면 움직임을 제어하는 머신러닝 장치; 및상기 머신러닝 장치에 의해 동작 제어된 아바타의 안면 움직임이 출력되는 출력 장치를 포함하는 안면 모션 캡처 시스템."}
{"patent_id": "10-2023-0134661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 머신러닝 장치는,상기 영상입력장치에서 입력된 영상을 2차원 영상의 프레임 단위로 나누고, 상기 머신러닝 모델의 학습 결과에기초하여 2차원 영상에 표시되는 사용자의 안면에 대한 특징점을 기준으로 하나 이상의 키 조인트를 설정하는인공지능부;상기 인공지능부에서 설정된 키 조인트의 위치를 2차원 좌표로 설정하는 좌표부;상기 좌표부에서 설정된 키 조인트의 좌표를 3차원 스켈레톤 값으로 변환하는 변환부; 및상기 변환부에서 변환된 3차원 스켈레톤 값에 따라 아바타의 안면 움직임을 제어하는 제어부를 포함하는 안면 모션 캡처 시스템."}
{"patent_id": "10-2023-0134661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 인공지능부는 사용자의 안면 근육에 따라 키 조인트를 설정하는 안면 모션 캡처 시스템."}
{"patent_id": "10-2023-0134661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 인공지능부는 MobileNet 및 SqueezeNet 중 하나 이상의 모델을 이용하여 사용자의 안면의 움직임을 학습하는 안면 모션 캡처 시스템."}
{"patent_id": "10-2023-0134661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 키 조인트는 사용자의 눈, 코, 입, 입술, 미간, 눈썹 중 하나 이상의 위치에 배치되는 안면 모션 캡처 시스템.공개특허 10-2024-0088558-3-청구항 6 제 2 항에 있어서,상기 키 조인트는 사용자의 얼굴에 가상의 수직선 및 수평선이 복수 개가 형성되고, 상기 가상의 수직선 및 수평선이 교차되는 지점 일부에 설정되는 안면 모션 캡처 시스템."}
{"patent_id": "10-2023-0134661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2 항에 있어서,상기 인공지능부는 2차원 영상에서 사용자의 얼굴을 크롭(crop), 이미지 증식(augmentation) 및 이미지 분류 중하나 이상을 수행하는 안면 모션 캡처 시스템."}
{"patent_id": "10-2023-0134661", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 메타버스를 통한 거래를 위한 안면 모션 캡처 시스템에 관한 것으로, 사용자의 얼굴의 안면 움직임을 촬영하는 영상입력 장치; 상기 영상입력 장치에서 입력된 영상을 머신러닝 모델에 적용하여 학습하고, 학습 결과 에 기초하여 상기 영상입력 장치의 영상으로부터 사용자의 안면 움직임을 3차원 스켈레톤 값으로 변환하고, 변환 된 3차원 스켈레톤 값에 따라 아바타의 안면 움직임을 제어하는 머신러닝 장치; 및 상기 머신러닝 장치에 의해 동작 제어된 아바타의 안면 움직임이 출력되는 출력 장치를 포함하는 안면 모션 캡처 시스템을 제공한다."}
{"patent_id": "10-2023-0134661", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 메타버스를 통한 거래를 위한 안면 모션 캡처 시스템에 관한 것으로, 보다 상세하게는 실시간으로 사 용자의 안면을 모션 캡처하여 메타버스에서 사용 간에 얼굴을 드러내지 않고 거래할 수 있는 메타버스를 통한 거래를 위한 안면 모션 캡처 시스템에 관한 것이다."}
{"patent_id": "10-2023-0134661", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "4차 산업혁명 및 지능정보사회에 진입에 따라 ICT 융복합 기술 발전이 급격하게 이루어지며, 그에 따라 인공지 능, 빅데이터, 사물인터넷, 3D 모델링 및 클라우드 등 기반 기술에 대한 영향력이 증가하고 있다. 국가적 차원에서 신산업 창출 및 핵심 산업인 인공지능 산업 발전을 위해 대규모 투자를 지원하고 AI 허브 플랫 폼 구축을 통해 인공지능 학습 데이터를 개방하여 AI 데어터 활용 인프라 구축을 위해 노력하는 추세이다. 특히 인공지능은 자율주행, 챗봇, 음성인식, 컴퓨터 비전과 같은 다양한 분야에서 활용된다. 그 중 3D 모델링, AR/VR 기술과 함께 메타버스(metaverse) 산업이 부상하는 추세이다. 메타버스는 현실에서의 상호작용을 가상공간에서 구현한 가상 세계로. 메타버스 내에 사용자를 대체하는 아바타가 존재한다. 이러한 메타버스 기술은 5G 기술을 기반으로 가상현실, 증강현실 및 혼합현실을 통해 구현될 수 있지만, 메쉬 데이터의 용량 문제로 실감도가 낮은 문제가 있다. 더욱이, 메타버스 내에서 아바타 간의 거래가 이루어지는 경우에 사용자의 표정이나 움직임이 명확하지 않아 실 제 사람 간의 거래와 같은 거래가 원활하게 이루어지기 어려운 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내공개특허 제10-2019-0048507호"}
{"patent_id": "10-2023-0134661", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래 기술의 문제점을 해결하기 위해 발명한 것으로서, 본 발명의 목적은 메타버스 내에서 아바타 간 의 거래 등 아바타 상호 간의 교류 활동이 일어나는 경우, 아바타 상호 간에 서로의 동작과 표정을 확인하면서 교류 활동이 이루어질 수 있도록 하는 안면 모션 캡처 시스템을 제공하는 것이다. 본 발명의 다른 목적은 모션 캡처를 위한 별도의 특수 장비 없이 단순히 카메라와 같은 영상입력 장치를 통해 간편하게 사용자의 안면 표정을 인식할 수 있고, 이를 통해 아바타의 안면 움직임을 용이하게 표현할 수 있는 안면 모션 캡처 시스템을 제공하는 것이다."}
{"patent_id": "10-2023-0134661", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은, 사용자의 얼굴의 안면 움직임을 촬영하는 영상입력 장치; 상기 영상입력 장치에서 입력된 영상을 머 신러닝 모델에 적용하여 학습하고, 학습 결과에 기초하여 상기 영상입력 장치의 영상으로부터 사용자의 안면 움 직임을 3차원 스켈레톤 값으로 변환하고, 변환된 3차원 스켈레톤 값에 따라 아바타의 안면 움직임을 제어하는 머신러닝 장치; 및 상기 머신러닝 장치에 의해 동작 제어된 아바타의 안면 움직임이 출력되는 출력 장치를 포함 하는 안면 모션 캡처 시스템을 제공한다. 상기 머신러닝 장치는, 상기 영상입력장치에서 입력된 영상을 2차원 영상의 프레임 단위로 나누고, 상기 머신러 닝 모델의 학습 결과에 기초하여 2차원 영상에 표시되는 사용자의 안면에 대한 특징점을 기준으로 하나 이상의 키 조인트를 설정하는 인공지능부; 상기 인공지능부에서 설정된 키 조인트의 위치를 2차원 좌표로 설정하는 좌 표부; 상기 좌표부에서 설정된 키 조인트의 좌표를 3차원 스켈레톤 값으로 변환하는 변환부; 및 상기 변환부에 서 변환된 3차원 스켈레톤 값에 따라 아바타의 안면 움직임을 제어하는 제어부를 포함할 수 있다. 상기 인공지능부는 사용자의 안면 근육에 따라 키 조인트를 설정할 수 있다. 상기 인공지능부는 MobileNet 및 SqueezeNet 중 하나 이상의 모델을 이용하여 사용자의 안면의 움직임을 학습할 수 있다. 상기 키 조인트는 사용자의 눈, 코 입, 입술, 미간, 눈썹 중 하나 이상의 위치에 배치될 수 있다. 상기 키 조인트는 사용자의 얼굴에 가상의 수직선 및 수평선이 복수 개가 형성되고, 상기 가상의 수직선 및 수 평선이 교차되는 지점 일부에 설정될 수 있다. 상기 인공지능부는 2차원 영상에서 사용자의 얼굴을 크롭(crop), 이미지 증식(augmentation) 및 이미지 분류 중 하나 이상을 수행할 수 있다."}
{"patent_id": "10-2023-0134661", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 메타버스 내에서 아바타 간의 거래가 이루어질 때 실제 사용자의 표정 변화 등을 확인할 수 있어, 보다 정확하고 명확하게 거래가 이루어질 수 있는 효과가 있다. 또한, 아바타의 표정에 사용자의 표정 변화가 나타남에 따라 거래를 위한 대화를 하거나 판매를 위한 방송을 하 는 경우에 상대 사용자에게 신뢰감을 높일 수 있는 효과가 있다. 또한, 모션 캡처를 위한 별도의 특수 장비 없이 단순히 카메라와 같은 영상입력 장치를 통해 간편하게 사용자의 안면 표정을 인식할 수 있고, 이를 통해 아바타의 안면 움직임을 용이하게 표현할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0134661", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명을 구현하기 위한 구체적인 실시예에 대하여 도면을 참조하여 상세히 설명하도록 한다. 아울러 본 발명을 설명함에 있어서 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략한다. 또한, 어떤 구성요소가 다른 구성요소에 '연결', '지지', '접속', '공급', '전달', '접촉'된다고 언급된 때에는 그 다른 구성요소에 직접적으로 연결, 지지, 접속, 공급, 전달, 접촉될 수도 있지만 중간에 다른 구성요소가 존 재할 수도 있다고 이해되어야 할 것이다.본 명세서에서 사용된 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로 본 발명을 한정하려는 의도로 사용된 것은 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 또한, 본 명세서에서 상측, 하측, 측면 등의 표현은 도면에 도시를 기준으로 설명한 것이며 해당 대상의 방향이 변경되면 다르게 표현될 수 있음을 미리 밝혀둔다. 마찬가지의 이유로 첨부 도면에 있어서 일부 구성요소는 과 장되거나 생략되거나 또는 개략적으로 도시되었으며, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것 이 아니다. 또한, 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구 성요소들은 이와 같은 용어들에 의해 한정되지는 않는다. 이 용어들은 하나의 구성요소들을 다른 구성요소로부 터 구별하는 목적으로만 사용된다. 명세서에서 사용되는 \"포함하는\"의 의미는 특정 특성, 영역, 정수, 단계, 동작, 요소 및/또는 성분을 구체화하 며, 다른 특정 특성, 영역, 정수, 단계, 동작, 요소, 성분 및/또는 군의 존재나 부가를 제외시키는 것은 아니다. 도 1은 본 발명의 일 실시예에 따른 안면 모션 캡처 시스템을 도시한 블록도이고, 도 2는 본 발명의 일 실 시예에 따른 영상입력 장치에서 촬영된 영상에서 사용자의 안면에 대한 키 조인트 값을 생성하기 위한 예 시도이다. 도 3은 본 발명의 일 실시예에 따른 영상입력 장치에서 촬영된 영상을 맵핑하여 키 조인트 값을 생성하기 위한 예시도이다. 본 발명의 일 실시예에 따른 안면 모션 캡처 시스템에 대해 도 1에 도시된 블록을 참조하여 설명하고, 필 요에 따라 도 2 및 도 3에 도시된 도면을 참조하여 설명한다. 본 발명의 일 실시예에 따른 안면 모션 캡처 시스템은 영상입력 장치, 머신러닝 장치 및 출력장 치를 포함한다. 영상입력 장치는 사용자의 얼굴을 촬영하여 영상으로 변환하기 위한 장치이다. 이러한 영상입력 장치(11 0)는 웹캠이나 사용자 단말기에 포함된 카메라일 수 있으며, 그 외에도 다양한 장치가 이용될 수 있다. 이러한 영상입력 장치는 사용자의 얼굴을 촬영하여 촬영된 영상을 머신러닝 장치로 출력할 수 있다. 영상입력 장치는 사용자의 얼굴을 촬영하기 위해 사용자를 향해 고정된 상태로 배치될 수 있고, 또한, 필 요에 따라 사용자의 머리가 움직이는 경우에 해당 움직임에 따라 이동되거나 회전될 수 있다. 영상입력 장치 의 동작은 사용자의 동작이나 이동에 맞춰 자동으로 이루어지도록 할 수 있으며, 영상입력 장치가 특 정 사용자의 얼굴에 초점이 맞춰지는 경우 해당 초점이 유지되도록 영상입력 장치가 사용자의 움직임에 따 라 동작하는 방식으로 수행될 수 있다. 머신러닝 장치는 영상입력 장치에서 촬영된 영상을 수신하여 해당 영상을 분석하고, 분석된 영상을 이용하여 아바타의 동작에 맞게 변환하여 아바타의 표정을 제어하기 위한 다양한 명령어를 생성할 수 있다. 본 실시예에서, 머신러닝 장치는 사용자가 이용하는 PC나 태블릿 PC 또는 스마트폰과 같은 사용자 단말기 에 포함될 수 있지만, 이에 한정되는 것은 아니다. 머신러닝 장치는 별도의 서버에 설치될 수 있으며, 그 에 따라 사용자가 이용하는 사용자 단말기의 영상입력 장치에서 촬영된 영상이 이동통신망이나 인터넷만을 통해 서버로 전송되어 머신러닝 장치에 입력될 수 있다. 이러한 머신러닝 장치는 인공지능부, 좌표부, 변환부 및 제어부를 포함할 수 있다. 인공지능부는 영상입력 장치에서 수신된 영상을 2차원 영상의 프레임 단위로 나누고, 나뉜 복수 개의 2차원 영상에 표시되는 사용자 얼굴의 특징점을 기준으로 키 조인트(KJ)를 설정한다. 키 조인트(KJ)는 사용자의 얼굴에서 주요 포인트에 설정될 수 있는데, 사용자의 얼굴 중 눈, 코, 입, 눈썹, 입 주변, 광대 등에 설정될 수 있다. 예컨대, 도 2에 도시된 바와 같이, 사용자의 얼굴 중 주요 위치에 키 조인트(KJ)가 7개가 설정될 수 있다. 또는 도 3에 도시된 바와 같이, 인공지능부는 사용자의 얼굴에 가상의 수직선 및 수평선을 복수 개 형성하 고, 수직선과 수평선의 교차점 중 일부에 키 조인트(KJ)를 설정할 수 있다. 여기서, 복수 개의 수직선 및 수평선의 개수는 필요에 따라 달라질 수 있지만, 많이 형성될수록 사용자의 얼굴 표정을 정밀하게 캡처할 수 있다. 그렇다고 가상의 수직선 및 수평선을 필요 이상으로 많이 형성되는 경우 서버의 연산속도가 느려질 수 있다. 인공지능부는 2차원 영상에 포함된 사용자의 얼굴에 설정된 키 조인트(KJ)를 기준으로 사용자의 표정 변화 를 학습할 수 있다. 인공지능부는 사용자의 얼굴에 설정된 키 조인트(KJ)의 이동에 따라 안면의 표정 변화 에 대해 학습할 수 있다. 앞서 설명한 바와 같이, 키 조인트(KJ)는 사용자의 얼굴에 복수 개가 배치될 수 있으 며, 사용자의 안면이 움직이는 안면 근육의 위치에 배치될 수 있다. 이러한 인공지능부는 2차원 영상에서 사용자의 얼굴을 크롭(crop)하고 이미지를 증식(augmentation)하며, 또한, 이미지 별로 분류한다. 또한, 인공지능부는 MobileNet, SqueezeNet 등 백본활용 AI 모델이 이용될 수 있다. MobileNet은 합성곱 신경망(CNN)기반의 딥러닝 모델 중 하나로, 모바일 기기와 임베디드 시스템에서 효율적으로 동작할 수 있는 경량 신경망 아키텍처 중 하나이다. 이러한 MobileNet은 이미지 분류, 객체 감지, 얼굴 인식, 세그멘테이션 등의 작업에 이용될 수 있다. SqueezeNet은 이미지 분류와 객체 인식 작업을 위해 설계된 딥러닝 네트워크 아키텍처로 상대적으로 적은 파라 미터를 사용하여 높은 정확도를 가진다. 좌표부는 2차원 영상에 가상의 좌표를 설정한다. 가상의 좌표는 사용자의 신체에 설정된 복수 개의 키 조 인트(KJ) 중 하나를 원점으로 설정하여 소정의 길이를 단위로 하여 설정될 수 있으며, 필요에 따라 설정되는 원 점의 위치는 달라질 수 있다. 그에 따라 좌표부는 복수 개의 키 조인트(KJ)에 대해 2차원 영상에서 각각의 좌표를 설정할 수 있다. 예컨 대, 본 실시예에서, 사용자의 코 위치에 해당하는 키 조인트(KJ)를 원점으로 설정하고, 코 위치를 중심으로 인 체에 설정된 키 조인트(KJ)에 대한 좌표를 설정할 수 있다. 그에 따라 좌표부는 사용자의 인공지능부(12 1)에서 학습된 키 조인트(KJ)에 대한 구체적인 움직임을 좌표화할 수 있다. 변환부는 좌표부에서 설정된 키 조인트(KJ)의 좌표를 따라 사용자의 2차원 영상에서의 움직임을 3차 원으로 변환한다. 이러한 변환부는 PC, Mobile, HMD 등 다양한 H/W 플랫폼에서 활용 가능한 Low-poly 모델 링을 이용하여 애니메이션 매핑을 위한 인체 와이어 프레임을 형성하고, 3차원 아바타 모델링 페이스 리깅 (rigging) 진행을 통해 애니메이션 모델을 생성할 수 있다. 그리고 변환부는 스켈레톤 IK/FK를 생성할 수 있다. 또한, 변환부는 좌표부에서 설정된 키 조인트(KJ)의 좌표 변화를 이용하여 안면 근육의 변화량을 확 인하고, 확인된 변화량에 따라 아바타의 표정에 연동될 수 있게 스켈레톤 IK/FK를 생성할 수 있다. 3차원 스켈레톤은 3차원 공간에서 인간이나 동물의 뼈 구조를 나타내는 3차원 모델이다. 3차원 스켈레톤은 사용 자의 움직임을 추적하고 기록하는데 이용되고, 이를 통해 사용자의 움직임을 재현하거나 분석할 수 있다. 그에 따라 본 실시예에서, 3차원 스켈레톤 값을 이용하여 사용자의 움직임을 보다 정밀하게 분석할 수 있다. 본 실시예에서, 스켈레톤은 눈, 코 입, 입술, 미간, 눈썹 등과 같이 얼굴 부분의 뼈대를 나타내고, 각 뼈는 모 델의 얼굴 부분을 움직일 수 있게 제어된다. 스켈레톤 FK는 각 뼈를 개별적으로 회전시켜 모델의 움직임을 제어하는데, 예컨대, 눈을 깜빡이거나 입술을 움 직이려면 해당 뼈를 회전시켜 표정을 만들 수 있다. 스켈레톤 IK는 특수한 경우에 표정 일부가 자동으로 조절되는데 이용될 수 있다. 이러한 변환부는 2차원 좌표값을 3차원 스켈레톤 값으로 변환할 수 있으며, 또한 필요에 따라서는 복수개 키 조인트(KJ)의 2차원 좌표값 변화와 2차원 좌표값을 기준으로 한 복수개 키 조인트(KJ)의 사이 거리 변화를 분석하여 2차원 좌표값으로부터 3차원 좌표값을 생성할 수 있다. 예를 들면, 변환부는 복수개 키 조인트(KJ)의 사이 거리가 2차원 좌표의 변화와 함께 증가하는 경우, 2차 원 영상에서 사용자가 영상입력 장치에 가까워지는 것으로 인식하고, 그에 대한 3차원 좌표 값을 생성할 수 있다. 그리고 복수개 키 조인트(KJ)의 사이 거리가 2차원 좌표의 변화와 함께 감소하는 경우, 2차원 영상에 서 사용자가 영상입력 장치로부터 멀어지는 것으로 인식하고, 그에 대한 3차원 좌표 값을 생성할 수 있다. 제어부는 변환부에서 변환된 3차원 스켈레톤 값을 이용하여 아바타의 움직임을 제어한다. 변환부 에서 생성된 3차원 스켈레톤 값이 제어부에 입력되고, 그에 따라 제어부는 3차원 스켈레톤 값을이용하여 아바타의 움직임에 대한 모션을 구현한다. 특히, 복수개 키 조인트(KJ)의 2차원 좌표값 변화와 2차원 좌표값을 기준으로 한 복수개 키 조인트(KJ)의 사이 거리 변화의 상호 관계에 따라 사용자가 영상입력 장치에 근접하는지 멀어지는지 여부를 인식하여 변환부 가 3차원 좌표값을 생성하고, 이를 기초로 제어부는 아바타의 동작 제어, 예를 들면, 출력 장치에서 아바타의 전후 방향 이동에 대한 동작 제어를 수행할 수 있다. 이상에서 설명한 바와 같이, 머신러닝 장치는 사용자의 다양한 동작에 대해 좌표부와 변환부에 의해 생성된 3차원 좌표값을 다양하게 학습하고, 해당 학습 정보를 별도의 저장부에 저장할 수 있다. 즉, 사용 자의 특정 동작에 대해 이에 대응되는 키 조인트(KJ)의 3차원 좌표값 변화들이 학습 결과에 따라 서로 매칭되게 저장될 수 있다. 따라서, 영상입력 장치의 촬영 영상 중 저장부에 저장된 키 조인트(KJ)의 3차원 좌표값 변화 상태가 인공지능부에 의해 감지되면, 제어부는 해당 3차원 좌표값 변화에 대응하는 특정 동작을 아바타가 수행하도록 제어하고, 이에 따라 아바타의 동작이 출력장치를 통해 출력된다. 출력장치는 사용자가 아바타의 움직임을 확인할 수 있는 장치로, 모니터나 VR 장치와 같은 디스플레이 장 치일 수 있다. 이러한 출력장치는 사용자의 움직임이 실시간으로 반영되어 아바타의 움직임이 출력될 수 있다. 이러한 출력장치는 사용자가 이용하는 PC나 테블릿 PC 또는 스마트폰와 같은 사용자 단말기에 포함될 수 있다. 따라서 서버에 설치된 머신러닝 장치로부터 아바타의 움직임이 제어되어 사용자 단말기의 출력장치 에 출력될 수 있다. 이상에서 설명한 안면 모션 캡처 시스템은 영상입력 장치와 같은 영상입력 장치를 통해 입력된 영상을 이용하여 사용자의 움직임을 인식할 수 있다. 이를 위해 머신러닝 장치에서 입력된 영상을 2차원으 로 변환한 다음, 사용자의 움직임을 인식할 수 있는 키 조인트(KJ)를 설정한다. 그리고 키 조인트(KJ)를 2차원 영상에서 좌표화한 상태에서 사용자의 움직임에 따라 위치가 변하는 키 조인트(KJ)의 위치를 3차원 스켈레톤 값 으로 변환하고, 변환값을 기초로 아바타의 움직임을 제어한다. 이러한 과정에서 머신러닝 장치는 사용자의 움직임을 지속적으로 학습하고, 다양한 모델 및 엔진을 이용하 여 사용자의 움직임을 분석할 수 있다. 그에 따라 본 실시예에 따른 안면 모션 캡처 시스템은 특정 명령어를 입력하지 않고 영상입력 장치를 통해 전달되는 동작을 인식시켜 실시간으로 정밀하게 아바타의 동작을 제어할 수 있다. 즉, 안면 모션 캡처 시스템은 아바타와의 행동을 동기화하여 메타버스 내에서 실재감 및 몰입도를 향상시 킬 수 있고, 모션캡쳐를 위한 특수 장비를 별도로 이용하지 않고, 영상입력 장치만으로 아바타와 동기화된 VR 시뮬레이션을 구현할 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0134661", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 안면 모션 캡처 시스템을 도시한 블록도이다. 도 2는 본 발명의 일 실시예에 따른 영상입력 장치에서 촬영된 영상에서 사용자의 안면에 대한 키 조인트 값을 생성하기 위한 예시도이다. 도 3은 본 발명의 일 실시예에 따른 영상입력 장치에서 촬영된 영상을 좌표화하여 키 조인트 값을 생성하기 위 한 예시도이다."}
