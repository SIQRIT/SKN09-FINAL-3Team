{"patent_id": "10-2022-7020832", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0112791", "출원번호": "10-2022-7020832", "발명의 명칭": "비행시간 대상 검출 회로부 및 비행시간 대상 검출 방법", "출원인": "소니 세미컨덕터 솔루션즈 가부시키가이샤", "발명자": "카모비치 알렉산드르"}}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비행시간 대상 검출 회로부로서,장면의 반사율을 나타내는 반사율 데이터를 획득하고;상기 장면의 반사율을 결정하고;결정된 반사율에 기초하여 상기 장면에서 대상의 영역을 결정하고; 그리고상기 대상을 검출하기 위해 상기 대상의 결정된 영역에 기초하여 비행시간 이미지 데이터를 생성하도록구성되는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 비행시간 이미지 데이터를 생성하기 위해 상기 결정된 반사율에 기초하여 노출 시간을 조정하도록 추가로 구성되는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 비행시간 이미지 데이터를 생성하기 위해 상기 결정된 반사율에 기초하여 이득을 조정하도록 추가로 구성되는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 생성된 비행시간 이미지 데이터는 현재 이미지 프레임과 적어도 하나의 후속 이미지 프레임 중적어도 하나를 포함하는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 결정된 반사율에 기초하여 상기 대상을 검출하도록 추가로 구성되는, 비행시간 대상 검출회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 반사율에 기초하여 그리고 생성된 비행시간 이미지 데이터에 기초하여 상기 대상을 인식하도록 추가로 구성되는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 인식은 미리 결정된 대상 클래스에 기초하는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 미리 결정된 대상 클래스는 상기 대상의 미리 결정된 반사율 범위에 기초하여 정의되는,비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 대상은 신체 부위를 포함하는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 신체 부위는 얼굴을 포함하는, 비행시간 대상 검출 회로부."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2022-0112791-3-비행시간 대상 검출 방법으로서,장면의 반사율을 나타내는 반사율 데이터를 획득하는 단계;상기 장면의 반사율을 결정하는 단계;결정된 반사율에 기초하여 상기 장면에서 대상의 영역을 결정하는 단계; 및상기 대상을 검출하기 위해 상기 대상의 결정된 영역에 기초하여 비행시간 이미지 데이터를 생성하는 단계를 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 비행시간 이미지 데이터를 생성하기 위해 상기 결정된 반사율에 기초하여 노출 시간을조정하는 단계를 더 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 비행시간 이미지 데이터를 생성하기 위해 상기 결정된 반사율에 기초하여 이득을 조정하는 단계를 더 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 생성된 비행시간 이미지 데이터는 현재 이미지 프레임과 적어도 하나의 후속 이미지 프레임중 적어도 하나를 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 결정된 반사율에 기초하여 상기 대상을 검출하는 단계를 더 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 반사율에 기초하여 그리고 생성된 비행시간 이미지 데이터에 기초하여 상기 대상을 인식하는 단계를 더 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 인식은 미리 결정된 대상 클래스에 기초하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 미리 결정된 대상 클래스는 상기 대상의 미리 결정된 반사율 범위에 기초하여 정의되는,비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 대상은 신체 부위를 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 신체 부위는 얼굴을 포함하는, 비행시간 대상 검출 방법."}
{"patent_id": "10-2022-7020832", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 대체로, 장면의 반사율을 나타내는 반사율 데이터를 획득하고; 장면의 반사율을 결정하고; 결정된 반 사율에 기초하여 장면에서 대상의 영역을 결정하고; 그리고 대상을 검출하기 위해 대상의 결정된 영역에 기초하 여 비행시간 이미지 데이터를 생성하도록 구성되는 비행시간 대상 검출 회로부에 관한 것이다."}
{"patent_id": "10-2022-7020832", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 대체로 비행시간(time-of-flight) 대상 검출 회로부와 비행시간 대상 검출 방법에 관한 것이다."}
{"patent_id": "10-2022-7020832", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 대상 검출 방법들 및 시스템이 알려져 있다. 이러한 시스템들은 통상적으로 RGB 데이터에, 휘도 분포(예컨대, 그레이스케일) 등에 기초하여 대상 검출(또는 대상 인식)을 수행한다. 더구나, 비행시간 시스템들은 알려져 있다. 통상적으로, 비행시간에서, 장면에서 반사되는 방출된 광의 실행 시간이 장면까지의 거리를 결정하기 위해 측정된다. 이는 일반적으로 dToF(direct time-of-flight)로서 알려진 광의 방출부터 반사된 광의 검출까지의 시간을 직접 측정함으로써 행해질 수 있다. 한편, iToF(indirect time-of-flight)의 경우, 실행 시간을 나타내는 위상 변이가 측정된다. 대상 검출을 위한 기법들이 존재하지만, 비행시간 대상 검출 회로부와 비행시간 대상 검출 방법을 제공하는 것 이 일반적으로 바람직하다. 제1 양태에 따르면, 본 개시는, 장면의 반사율을 나타내는 반사율 데이터를 획득하고; 장면의 반사율을 결정하 고; 결정된 반사율에 기초하여 장면에서 대상의 영역을 결정하고; 그리고 대상을 검출하기 위해 대상의 결정된 영역에 기초하여 비행시간 이미지 데이터를 생성하도록 구성되는 비행시간 대상 검출 회로부를 제공한다. 제2 양태에 따르면, 본 개시는, 장면의 반사율을 나타내는 반사율 데이터를 획득하는 단계; 장면의 반사율을 결 정하는 단계; 결정된 반사율에 기초하여 장면에서 대상의 영역을 결정하는 단계; 및 대상을 검출하기 위해 대상 의 결정된 영역에 기초하여 비행시간 이미지 데이터를 생성하는 단계를 포함하는 비행시간 대상 검출 방법을 제 공한다. 추가의 양태들이 종속 청구항들, 다음의 설명 및 도면들에서 언급된다."}
{"patent_id": "10-2022-7020832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1의 참조 하의 실시예들의 상세한 설명 전에, 일반적인 설명들이 이루어진다. 서두에 언급된 바와 같이 비행시간 이미징 시스템들이 알려져 있다. 비행시간 센서로부터의 비행시간 이미징 신호에서, 액티브 광 반사율(ctive light reflectance)(ALR) 신호가 획 득될 수 있다는 것이 인식되었다. 그러나, 공지된 시스템들에서, 이러한 신호는 대상까지의 거리에 기초하여 열화될 수 있다. 예를 들어, 대상이 카메라에 가까이 있으면, 카메라로부터 더 멀리 떨어져 있을 때보다 더 밝게 보일 수 있다. 그러므로, 이러한 신호는 통상적으로 대상 인식과 같은 컴퓨터 비전에 적합하지 않다. 더구나, 비행시간의 경우, 이러한 대상까지의 실제 거리는 ALR 신호에 추가로 획득될 수 있다는 것이 인식되었 다. 그래서, 반사율의 이러한 열화는 거리(또는 깊이)를 앎으로써 보상될 수 있거나 또는, 역으로, 거리 측정 이 반사율에 기초하여 개선될 수 있다는 것이 인식되었다. 액티브 광 반사율 데이터(또는 ALR 데이터)와 깊이 데이터에 추가하여, 비행시간 이미징 시스템은 휘도 정보(이 를테면 단색 카메라의 Y 채널이며, 이는 일반적으로 공지된 바와 같음)를 포함할 수 있는 YSC 신호(Y 채널 및 표면 특성)와 대상(또는 재료)의 반사 및/또는 흡광을 나타낼 수 있는 표면 특성을 제공할 수 있다.그래서, 비행시간 이미징 시스템의 이러한 신호들(이는 ALR 신호와 함께 YSC-D 신호(Y-채널, 표면 특성, 및 깊"}
{"patent_id": "10-2022-7020832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이)로 요약될 수 있음)을 활용함으로써, 대상 영역 검출, 대상 검출, 및 대상 인식이 수행될 수 있다는 것이 인 식되었다. 공지된 시스템들에서, 이러한 신호들은 최적으로 사용 또는 결합되지 않을 수 있다. 예를 들어, 공지된 시스템 들에서의 비행시간 신호가 거리 의존적일 수 있거나, 증가된 모션 블러(motion blur)를 가질 수 있거나, 최적의 노출 제어를 갖지 않을 수 있거나, 증가된 경면 반사를 가질 수 있다는 등등이다. 그래서, 공지된 시스템들에 서, 대상의 반사율에 기초한 동적 노출 및/또는 이득 제어가 구상되지 않고, 비행시간의 분야에서 동적 노출/이 득 제어를 제공하는 것이 바람직하다는 것이 인식되었다. 그러므로, 공지된 시스템들에서, 대상 검출 또는 인식이 최적이 아닐 수 있다. 더욱이, 얼굴 인식 및/또는 얼굴 인증을, 예를 들어 자동차 분야에서 또는 모바일 애플리케이션에서, 본 개시를 그 점에서 제한하는 일 없이, 개선하는 것이 바람직하다는 것이 인식되었다. 그러므로, 일부 실시예들은 장면의 반사율을 나타내는 반사율 데이터를 획득하며; 장면의 반사율을 결정하며; 결정된 반사율에 기초하여 장면에서 대상의 영역을 결정하며; 그리고 대상을 검출하기 위해 대상의 결정된 영역 에 기초하여 비행시간 이미지 데이터를 생성하도록 구성되는 비행시간 대상 검출 회로부에 관한 것이다. 본 개시에 따르면, 결정된 깊이(또는 거리) 신호와 함께 사용될 수 있는 또는 깊이 결정의 기초가 될 수 있는 거리 독립적인 반사율 신호를 생성하는 것이 가능할 수 있어서, 대상의 영역의 검출, 특징 추출, 대상 인식 등 이 효율적으로 수행될 수 있다. 비행시간 대상 검출 회로부는 간접 비행시간(iToF), 직접 비행시간(direct time-of-flight)(dToF) 등과 같은 임의의 비행시간 기술에 적용 가능할 수 있다. 일반적으로, iToF에서, 깊이 또는 거리가 방출된 변조된 광의 적어도 하나의 위상 변이를 평가함으로써 결정된 다. 그리하여, 그것은 대상 또는 장면까지의 거리를 나타내는 광의 실행 시간인 것으로 결론 내려질 수 있다. dToF에서, 깊이가 방출된 광의 실행 시간을 직접 측정함으로써 결정된다. 통상적으로, 실행 시간은 방출된 광 의 (반사로 인한) 복귀에 의해 야기된 이벤트를 검출하고 이벤트가 검출되는 시점과 광이 방출되는 시점을 비교 함으로써 결정될 수 있다. 기본적으로, 비행시간의 범위에서, 장면 및/또는 대상의 반사율(또는 반사계수)는, 위에서 논의된 바와 같이, 획득될 수 있다. 생성된 비행시간 이미지 데이터는 반사율에 관한 정보를 포함하거나, 또는 별도의 측정으로 결정될 수 있다. 일반적으로, 반사율은 비행시간 기술과는 상이한 기술에 의해 또한 획득될 수 있다. 반사율은, 예를 들어 방출된 (변조된) 광의 양(예컨대, 세기)과 수신된 광의 양을 비교함으로써, 결정될 수 있 다. 더구나, 반사율은, 비행시간의 분야에서 일반적으로 공지된 바와 같이, 신뢰도 데이터에 의해 나타내어질 수 있다. 예를 들어, 신뢰도 데이터는, iToF의 경우, 생성된 광 신호의 상이한 위상들의 거친(빠른) 측정결과일 수 있다. 그리하여, 반사율이 결론 내려질 수 있게 하는 액티브 광 반사율(ALR) 신호가 획득될 수 있다. 더구나, 반사율은 미리 결정된 파장 범위에 기초할 수 있다. 통상적으로, 미리 결정된 파장 범위는 방출된 광 의 파장 범위에 해당할 수 있다. 그리하여, 하나의 측정으로 반사율과 깊이를 획득하는 것이 가능할 수 있다. 미리 결정된 파장 범위는 가시광선(예컨대, 미리 결정된 컬러 채널, 예컨대, 적색, 청색 등), 적외선, 자외선 등을 포함할 수 있다. 일반적으로, 본 개시는 임의의 파장 범위로 제한되지 않는다. 일반적으로 공지된 바와 같이, 대상의 반사율이 파장 범위에 따라 달라질 수 있다. 예를 들어, 대상이 미리 결 정된 적외선 파장 범위에서 80 퍼센트의 반사율을 가질 수 있는 반면, 동일한 대상은 미리 결정된 가시 파장 범 위에서(예컨대, 녹색 컬러 채널에서) 40 퍼센트의 반사율을 가질 수 있다. 그래서, 일부 대상들은 더 잘 보이고, 따라서, 해당 파장 범위들에서 검출 가능할 수 있거나, 또는, 다르게 말 하면, 각각의 파장 범위에 대해, 상이한 대상들의 반사율들은 알려질 수 있다. 예를 들어, 미리 결정된 파장 범위(예컨대, 적외선)에서, (본 개시를 상이한 두 개의 반사율들 또는 대상들로 제한하는 일 없이) 제1 대상이 제1 반사율을 가질 수 있고 제2 대상이 제2 반사율을 가질 수 있어서, 제1 반사율을 검출함으로써, 제1 대상은 검출될 수 있고 제2 반사율을 검출함으로써, 제2 대상은 검출될 수 있다.비행시간 대상 검출 회로부는, 이 맥락에서, 비행시간 데이터, 반사율 데이터 등과 같은 데이터를 평가하는데 적합한 임의의 회로부를 포함할 수 있다. 그래서, 회로부는 CPU(Central Processing Unit), GPU(Graphic Processing Unit), FPGA(Field Programmable Gate Array) 등과 같은 프로세서를 포함할 수 있다. 또한, 다수의 명명된 프로세서들(또는 다른 프로세서들)이 본 개시에 따라 회로부를 형성하도록 연결될 수 있다. 더구나, 회로부는, 일반적으로 알려진 바와 같이, 컴퓨터, 서버, 다수의 컴퓨터들 및/또는 서버들 등을 포함할 수 있다. 비행시간 대상 검출 회로부는, 일부 실시예들에서, 장면의 반사율을 나타내는 반사율 데이터를 획득하도록 구성 된다. 반사율은, 위에서 논의된 바와 같이, 장면의 (예컨대, 대상의) 적어도 하나의 재료의 적어도 하나의 재료 성질 등을 나타낸 것일 수 있다. 일반적으로, 반사율은, 일반적으로 알려진 바와 같이, 입사하는 광의 양과 비교하 여, 흡수되는 광의 양과 비교하여, 송신되는 광의 양과 비교하여 등으로 장면, 대상, 재료 등에서 반사된 광의 양을 나타낼 수 있다. 반사율 데이터는, 예를 들어 반사율 데이터를 생성하도록 구성될 수 있는, 이미징 회로부로부터 획득될 수 있다. 이미징 회로부는 이미지 센서, 데이터 저장소 등에 관한 것이거나 또는 그러한 것을 포함할 수 있고, 반사율 데 이터를 비행시간 대상 검출 회로부에 능동적으로 제공하도록 구성될 수 있어서, 비행시간 대상 검출 회로부는 반사율 데이터를 (수동적으로) 수신하도록 구성될 수 있다. 더구나, 이미징 회로부는 비행시간 대상 검출 회로 부의 요청에 기초하여 반사율 데이터를 제공하도록 구성될 수 있어서, 비행시간 대상 검출 회로부는 반사율 데 이터를 (능동적으로) 취득할 수 있다. 더구나, 반사율 데이터는 비행시간 대상 검출 회로부에 의해 이미지 데이터(예컨대, 광전 변환에 기초하여 생성 되는 전기 신호)로부터 (중에서) 직접 획득될 수 있다. 이러한 실시예들에서, 비행시간 대상 검출 회로부는 이미지 센서에 커플링되거나, 그것에 포함되거나, 또는 그 것을 포함할 수 있어서, 이미지 데이터는 반사율 데이터를 결정하기 위해 직접 프로세싱될 수 있다. 일부 실시예들에서, 비행시간 대상 검출 회로부는 장면의 반사율을 결정하도록 추가로 구성된다. 예를 들어, 비행시간 대상 검출 회로부는 방출된 광의 광 세기와 이미지 센서의 각각의 이미징 엘리먼트(예컨대, 화소)에 대한 검출된 광의 광 세기를 비교할 수 있어서, 모든 이미징 엘리먼트에 대해, 반사 율은 결정될 수 있다. 그리하여, 2차원 공간 또는 3차원 공간에서의 반사율 이미지 또는 반사율 분포가 결정될 수 있어서, 상이한 반 사율들을 갖는 영역들이 국소화될 수 있다. 예를 들어, 대상이 장면의 배경과는 상이한 반사율을 가질 수 있어서, 일부 실시예들에서, 장면에서의 대상의 영역이 결정된 반사율에 기초하여 결정될 수 있다. 그러나, 본 개시는 임의의 관심 영역(region of interest)(ROI)이 반사율에 기초하여 결정될 수 있으므로 대상 의 영역으로 제한되지 않는다. 그리하여, 대상까지의 또는 장면까지의 거리와는 독립적인 반사율 값이 획득될 수 있으며, 이는 깊이 정보 및 반사율 데이터(또는 본 개시에서 논의되는 바와 같은 ALR)의 함수일 수 있다. 일부 실시예들에서, 깊이 측정이 깊이 정보를 획득하기 위해 추가적으로 수행될 수 있거나, 또는, 이미지 데이 터에 기초하여, 깊이 데이터는 (반사율 데이터와는 유사한 또는 상이한 방식으로) 획득될 수 있어서, 대상의 영 역은 결정된 깊이에 기초하여 결정되거나 또는 결정 가능할 수 있다. 일부 실시예들에서, 깊이 정보는 (예컨대, 가우시안 필터에 의해) 평활화될 수 있다. 예를 들어, 대상 및 그것의 배경은 동일하거나 또는 유사한 반사율을 가질 수 있거나 또는 그것들의 각각의 반 사율의 차이는 (미리 결정된) (검출 가능한) 임계값 미만일 수 있어서, 반사율에 기초하여 대상의 영역을 검출 하는 것이 가능하지 않을 수 있다.이러한 실시예들에서, 대상의 영역은, 예를 들어 깊이 임계값에 기초하여, 결정될 수 있다. 예를 들어, 적어도 두 개의 이미징 엘리먼트들에 의해 검출되는 미리 결정된 차이가 깊이 임계값 위이면, 대상과 배경 사이의 경계 가 결정될 수 있다. 그리하여, 대상의 영역 또한 결정될 수 있다. 일부 실시예들에서, 대상의 결정된 영역에 기초하여, 비행시간 이미지 데이터는 대상을 검출하기 위해 생성될 수 있다. 일반적으로 알 수 있는 바와 같이, 대상의 인지가 사용된 광학 시스템에 따라 달라질 수 있다. 예를 들어, 대 상이 광학 시스템에 더 가까울 때 더 밝게 그리고 더 멀리 있을 때 더 어둡게 보일 수 있다. 이는 비행시간 이 미지들의 경우에 또한 적용될 수 있어서, 대상이 이상적인 초점면에서 벗어날 때 깊이 측정이 열화될 수 있다. 더구나, 3차원 대상의 깊이가 측정되므로, 초점면의 범위가 대상의 범위보다 더 작을 수 있어서, 대상의 일부가 적절히 이미지화될 수 있는 반면, 적어도 하나의 다른 일부에서, 깊이 측정이 열화될 수 있다. 이러한 인지는 또한 대상의 반사율에 따라 달라질 수 있다. 그래서, 컴퓨터 비전(예컨대, 대상 인식)을 위한"}
{"patent_id": "10-2022-7020832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "반사율 또는 반사율 데이터의 직접적인 사용은 해당 기술분야에서 일반적으로 구상되지 않고, 통상적으로, 컴퓨 터 비전은 대상의 RGB, 휘도(예컨대, 그레이스케일) 등에 기초한다. 그러므로, 대상의 결정된 영역은 깊이의 가정을 하기 위해 고려될 수 있다. 더구나, 결정된 반사율은 현존 깊 이 측정을 정정하기 위해 채택될 수 있다. 일반적으로, 비행시간 이미지 데이터는 생성될 수 있다. 이는 (현재 이미지 프레임의) 기존의 이미지 데이터 (위에서 설명된 바와 같음)의 적응을 포함할 수 있고, 이는 이득, 노출 시간 등과 같은 후속 측정을 위한 측정 파라미터들의 적응을 더 포함할 수 있다. 그래서, 일부 실시예들에서, 비행시간 대상 검출 회로부는 비행시간 이미지 데이터를 생성하기 위해 결정된 반 사율에 기초하여 노출 시간을 조정하도록 추가로 구성된다. 노출 시간은, 일반적으로 공지된 바와 같이, 시간(그 시간 후에 셔터(전자 및/또는 기계)가 트리거될 수 있음) 을 포함할 수 있어서, 이미지 취득의 시작에 비해, 이미지 취득이 중지될 수 있다. 일부 실시예들에서, 비행시간 대상 검출 회로부는 비행시간 이미지 데이터를 생성하기 위해 결정된 반사율에 기 초하여 이득을 조정하도록 추가로 구성된다. 일반적으로, 노출 시간과 이득은 둘 다가 조정될 수 있는 반면, 일부 실시예들에서, 노출 시간 및 이득 중 하나 만이 조정된다. 일반적으로, 본 개시는 노출 시간 및 이득의 경우로 제한되지 않아서, ISO 값(ISO 5800에 기초하며, 일반적으로 공지된 바와 같음) 등과 같은 임의의 이미징 파라미터 또는 측정 파라미터가 적응될 수 있다. 일반적으로, 본 개시에 따르면, 이득 및/또는 노출 시간의 적응은, 특히 대상 영역 검출, 대상 검출 및 대상 인 식의 측면에서 개선될 수 있다. 더구나, 위에서 논의된 바와 같이, 그리고 일반적으로 공지된 바와 같이, 이미지 취득이 복수의 이미징 프레임 들(또는 서브프레임들)을 포함할 수 있다. 예를 들어, 제1 프레임(또는 현재 프레임)에서 이미지 데이터는 반사율 데이터와 비행시간 이미지 데이터를 포 함할 수 있어서, 비행시간 이미지 데이터는 동일한 프레임의 반사율 데이터에 기초하여 생성 또는 정정될 수 있 다. 더구나, 임의의 후속 프레임(즉, 반사율 데이터를 획득한 후에 조정되는 임의의 프레임)에서 비행시간 이미지 데이터는, 본 개시에서 논의되는 바와 같이, 반사율 데이터에 기초하여 (또는 대상의 영역에 기초하여) 생성될 수 있다. 더구나, 모든 프레임에서(또는 다수의 프레임들에서), 반사율 데이터는 비행시간 이미지 데이터를 생성하기 위 해 획득될 수 있다. 그러나, 일부 실시예들에서, 대략 일정한 환경적 상황(예컨대, 일정한 조명, 카메라 및/또 는 대상의 일정한 위치)에서, 반사율 데이터를 한 번 획득하는 것으로 충분할 수 있다. 일부 실시예들에서, 비행시간 대상 검출 회로부는 결정된 반사율에 기초하여 대상을 검출하도록 추가로 구성된 다.대상을 검출하는 것은 대상의 영역에 기초하여 대상의 존재를 검출하는 것에 관계가 있을 수 있다. 예를 들어, 미리 결정된 반사율을 (위에서 논의된 바와 같이) 결정하고 대상의 영역을 로케이팅함으로써, 대상은 검출될 수 있으며, 어떤 종류의 대상이 검출되는지가 인식되지 않을 수 있으며, 즉, 대상은 인식되지 않을 수 있다. 예를 들어, 대상의 검출은 대상 클래스에 대한 미리 결정된 반사율의 배정을 참조할 수 있다. 예를 들어, 대상 클래스는 저 적외선 범위에서 대략 80 퍼센트의 인간 피부의 반사율과 같은 대상의 미리 결정된 반사율 범위의 반사율을 참조할 수 있다. 그래서, 80 퍼센트의 반사율을 결정함으로써, 대상 클래스 인간 신체 부위는 결정될 수 있으며, 정확한 신체 부위(예컨대, 얼굴, 손)는 아직 인식되지 않을 수 있다. 그러나, 일부 실시예들에서, 비행시간 대상 검출 회로부는 반사율에 기초하여 그리고 생성된 비행시간 이미지 데이터에 기초하여 대상을 인식하도록 추가로 구성된다. 위에서 언급된 바와 같이, 비행시간 이미지 데이터는 검출된 대상의 깊이 정보 또는 깊이 이미지를 나타낼 수 있다. 그리하여, 적어도 하나의 특징이 인식될 수 있는 검출된 대상의 깊이 구조가 결정될 수 있어서, 대상은 인식될 수 있다. 대상 인식은 인공지능(artificial intelligence) 등과 같은 공지된 방법들에 기초할 수 있다. 인공지능(AI)은, 예를 들어 에지 검출, 히스토그램 기반 방법들, 템플릿 매치 기반 방법들, 컬러 매치 기반 방 법들 등에 의해, 형상 매칭과 같은 머신 러닝 기반 방법들 또는 명시적 특징 기반 방법들을 사용할 수 있다. 일부 실시예들에서, 머신 러닝 알고리즘이 대상 인식을 수행하기 위해, 예컨대, 검출된 미리 정의된 대상과 인 식된 대상을 비교하여 검출의 정확도를 증가시키기 위해, 사용될 수 있으며, 이는 다음 중 적어도 하나에 기초 할 수 있다: SIFT(Scale Invariant Feature Transfer), GLCM(Gray Level Co-occurrence Matrix), 가보 특징들 (Gabor Features), 튜브니스(Tubeness) 등. 더구나, 머신 러닝 알고리즘은 분류기 기법에 기초할 수 있으며, 이러한 머신 러닝 알고리즘은 다음 중 적어도 하나에 기초할 수 있다: 랜덤 포레스트; 지원 벡터 머신; 뉴럴넷 (Neural Net), 베이즈 넷(Bayes Net) 등. 더욱이, 머신 러닝 알고리즘은 딥 러닝 기법들을 적용할 수 있는데, 이러한 딥 러닝 기법들은 다음 중 적어도 하나에 기초할 수 있다: 오토인코더들(Autoencoders), 생성적 적대 네 트워크(Generative Adversarial Network), 약 지도 학습(weakly supervised learning), 부트-스트랩핑 등. 지도 학습은 회귀 알고리즘, 퍼셉트론 알고리즘, 베이즈 분류(Bayes-classification), 나이브 베이즈 분류 (Naiver Bayer classification), 다음 이웃 분류(next-neighbor classification), 인공 신경망 등에 추가로 기 초할 수 있다. 인공지능에는, 이러한 실시예들에서, 미리 정의된 대상에 대응할 또는 그것에 기초할 수 있는 지상 실측(ground truth) 데이터가 피드될 수 있어서, 인공지능은 대상을 인식하도록 학습할 수 있다. 일부 실시예들에서, 인식은, 본 개시에서 논의되는 바와 같이, 미리 결정된 대상 클래스에 기초한다. 일부 실시예들에서, 미리 결정된 대상 클래스는, 본 개시에서 논의되는 바와 같이, 대상의 미리 결정된 반사율 범위에 기초하여 정의된다. 일부 실시예들에서, 대상은 신체 부위를 포함한다. 일반적으로, 본 개시는 인간 신체 부위로 제한되지 않는데, (동물 등의) 임의의 신체의 임의의 일부가 인식될 수 있기 때문이다. 더구나, 본 개시는 어떠한 대상이라도 검출될 수 있으므로 대상을 신체 부위인 것으로 제한 되지 않는다. 일부 실시예들에서, 신체 부위는, 본 개시에서 논의되는 바와 같이, 얼굴을 포함한다. 일부 실시예들은, 본 개시에서 논의되는 바와 같이, 장면의 반사율을 나타내는 반사율 데이터를 획득하는 단계; 장면의 반사율을 결정하는 단계; 결정된 반사율에 기초하여 장면에서 대상의 영역을 결정하는 단계; 및 대상을 검출하기 위해 대상의 결정된 영역에 기초하여 비행시간 이미지 데이터를 생성하는 단계를 포함하는 비행시간 대상 검출 방법에 관한 것이다. 비행시간 대상 검출 방법은 본 개시에 따른 비행시간 대상 검출 회로부로 수행될 수 있다. 일부 실시예들에서, 비행시간 대상 검출 방법은, 본 개시에서 논의되는 바와 같이, 비행시간 이미지 데이터를 생성하기 위해 결정된 반사율에 기초하여 노출 시간을 조정하는 단계를 더 포함한다. 일부 실시예들에서, 비행 시간 대상 검출 방법은, 본원에서 논의되는 바와 같이, 비행시간 이미지 데이터를 생성하기 위해 결정된 반사율에 기초하여 이득을 조정하는 단계를 더 포함한다. 일부 실시예들에서, 생성된 비행시간 이미지 데이터는, 본 개시에서 논의되는 바와 같이, 현재 이미지 프레임과 적어도 하나의 후속 이미지 프레임 중 적어도 하나를 포함 한다. 일부 실시예들에서 비행시간 대상 검출 방법은, 본 개시에서 논의되는 바와 같이, 결정된 반사율에 기초 하여 대상을 검출하는 단계를 더 포함한다. 일부 실시예들에서, 청구항 15의 비행시간 대상 검출 방법은, 본 개시에서 논의되는 바와 같이, 반사율에 기초하여 그리고 생성된 비행시간 이미지 데이터에 기초하여 대상을 인 식하는 단계를 더 포함한다. 일부 실시예들에서, 인식은, 본 개시에서 논의되는 바와 같이, 미리 결정된 대상 클래스에 기초한다. 일부 실시예들에서, 미리 결정된 대상 클래스는 대상의 미리 결정된 반사율 범위에 기초하 여 정의된다. 일부 실시예들에서, 대상은, 본 개시에서 논의되는 바와 같이, 신체 부위를 포함한다. 일부 실 시예들에서, 신체 부위는, 본 개시에서 논의되는 바와 같이, 얼굴을 포함한다. 본 개시에서 설명되는 바와 같은 방법들은 또한, 컴퓨터 및/또는 프로세서 상에서 수행될 때, 컴퓨터 및/또는 프로세서가 방법을 수행하게 하는 컴퓨터 프로그램으로서 일부 실시예들에서 구현된다. 일부 실시예들에서, 또 한 위에서 설명된 프로세서와 같은 프로세서에 의해 실행될 때, 본 개시에서 설명되는 방법들이 수행되게 하는 컴퓨터 프로그램 제품을 내부에 저장하는 비일시적 컴퓨터 판독가능 기록 매체가 제공된다. 도 1로 되돌아 가면, 본 개시에 따른 비행시간 이미징 방법이 블록도로 묘사되어 있다. 비행시간 이미지 센서는 대상을 포함하는 장면을 나타내는 이미지 데이터(M1 및 M2)를 제공한다. 3에서, 이미지 데이터(M2)로부터 액티브 광 반사 데이터(ALR 데이터)(또는 본 개시에서 논의되는 바와 같은 반사율 데이터)와 깊이 데이터(또는 본 개시에서 논의되는 바와 같은 비행시간 데이터)는 필터링되고 추출된 다. 6에서, ALR 데이터와 깊이 데이터는 상수 k에 제곱된 깊이 신호(d*d)를 곱하고 ALR 신호를 곱함으로써 결 합된다. 이 공식 k*d*d*ALR에서, 깊이(d)는 거리 종속 ALR 신호를 보상하여서, 그 결과는 거리와는 독립적이다. 이 공식은, 이 실시예에서, 실험식이다. 그러나, 본 개시는 그 점에서 제한되는 것은 아니고 임의의 공식이 적 용될 수 있다. 그리하여, 7에서, 휘도와 표면 특성을 나타내는 YSC 신호가 생성된다. YSC 신호는, 근사적으로, 단색 카메라(즉, Y 채널)의 출력과 유사하다. 그러나, 단색 정보에 추가적으로, 장면 (및/또는 대상)의 반사 및/또는 흡광도에 관한 (또는 일반적으로 표면 특성에 관한) 정보는 YSC 신호에 의해 표 현된다. 본 개시에서 논의되는 바와 같이, YSC 신호는 표면 특성과 휘도를 포함한다. 이 신호에 기초하여, 클러스터링 접근법이 대상과 주변 자료(또는 장면) 간을 구별(즉, 8에서 관심 영역을 결정)하기 위해 채택될 수 있으며, YSC 신호의 휘도는 (아래에서 논의되는 바와 같이) 대상의 검출 및/또는 인식을 위해 사용될 수 있다. 8에서, 대상의 영역을 나타내는 관심 영역(ROI)이, 위에서 논의된 바와 같이, 깊이 데이터 및 YSC 신호에 기초 하여 결정된다. 이에 기초하여, 대상 ROI 마스크가 생성되며, 이 마스크는, 9에서, 노출 시간 및 이득 제어에 대한 통계의 컴퓨 테이션을 위해 사용된다. 더구나, 센서의 신호(M1)에 기초하는 MAAR 신호(혼합된 주변 광 및 액티 브 광 반사 신호)가 11에서 컴퓨테이션을 위해 사용된다. ROI 마스크에 기초한 통계의 컴퓨테이션은 예를 들어 ROI 신호 세기 추정(예컨대, 평균)을 포함할 수 있으며, 이는 (아래에서 설명되는 바와 같이) 노출 및 이득을 조정하기 위해 사용될 수 있다. MAAR 신호는 미지의 양의 주변 광(또는, 다른 실시예들에서 알려진 (정확한) 양의 주변 광 및 액티브 광 기여분)을 포함한다. 그러므로, MAAR 신호는, 프로세싱되지 않았으면, 예컨대, 최적의 밝기 및 콘트라스트의 측면에서, 낮은 품질을 가질 수 있다. 그러나, 본 개시에서 (추가로 아래에) 논의되는 바와 같이, MAAR 신호는 대상의 모션 블러 아티팩트를 감소시키 는데 적합할 수 있다. 12에서, 노출 시간 및 이득에 대한 제어 값이 결정되며, 이는 센서(노출 시간 및 이득을 제어하는 제어 회로 부를 포함하지만, 묘사되지 않음)에, 재귀 방식으로 피딩된다.따라서, 각각의 프레임에 대해, 이전 프레임의 정보는 프레임의 이미징 품질을 개선하기 위해 사용된다. 더구 나, 미리 결정된 임계값 위에 있을 밝기에서의 변화(밝기 플리커)가 회피된다. 그리하여, 최적화되는 밝기 및 콘트라스트의 측면에서, (후속) 이미지 프레임은 생성될 수 있으며, 즉, 후속 프 레임에서, (최적화된) MAAR 신호는 이미지 신호(M1)로부터 생성되며, 이는 대상 인식을 위해 사용된다. 더구나, ALR 데이터와 깊이 데이터는 대상 인식을 위해 사용된다. 도 2는 비행시간 대상 검출 방법의 추가의 실시예를 블록도로 묘사하며, 그 방법은 얼굴 ROI 검출이 대상 ROI 검출(8에서임) 대신 21에서 수행된다는 점에서, 그리고 얼굴 인식이 대상 인식(14에서임) 대신 22에서 수행 된다는 점에서 도 1의 비행시간 대상 검출 방법과는 상이하여서, 8 및 14는 각각 21 및 22로 대체되고, 블록 도의 나머지 블록들의 반복 설명은 해당 단계들이 도 1의 제1 실시예에서와 동일하므로 생략된다. 도 3은 비행시간 대상 검출 방법의 추가 실시예를 블록도로 도시한다. 31에서, 장면의 반사율을 나타내는 반사율 데이터가 비행시간 이미지 센서의 신뢰도 측정으로부터 획득된다. 32에서, 반사율 데이터에 기초하여, 장면의 반사율이 획득된다. 33에서, 결정된 반사율에 기초하여, 그리고 반사율 범위에 기초하여, 위에서 논의된 바와 같이, 장면에서 대상 의 영역이 결정된다. 34에서, 이미지의 반사율 및 영역에 기초하여, 비행시간 이미지 데이터가 본 개시에서 논의되는 바와 같이 생성 된다. 35 및 36에서, 노출 시간과 이득이 각각 본 개시에서 논의되는 바와 같이 조정된다. 37에서, 대상이 본 개시에서 논의되는 바와 같이 검출된다. 38에서, 대상은 본 개시에서 논의되는 바와 같이 인식된다. 도 4는 본 개시에 따른 비행시간 이미징 시스템을 블록도로 묘사하며, 그 시스템은 도 1, 도 2 및 도 3의 방법들(10, 20 및 30) 중 적어도 하나를 각각 구현 및/또는 실행하도록 구성될 수 있다. 비행시간 이미징 시스템은 복수의 화소들을 포함하는 비행시간 이미지 센서 상으로 광을 포커싱하 도록 구성되는 렌즈 스택을 갖는 비행시간 카메라로서 적응된다. 화소들은 CAPD들(current assisted photonic demodulators)을 포함하고 각각의 화소는, 본 개시에서 논의되는 바와 같이, 반사율 데이터와 깊 이 데이터를 생성하도록 구성된다. 비행시간 이미징 시스템은 변조된 광을 방출하도록 구성되는 복수의 VCSEL들(vertical cavity surface emitting lasers)을 포함하는 광원을 더 갖는다. 이 실시예에서, 비행시간 이미징 시스템은 방출된 광의 위상 변이를 측정하고 있다. 그러나, 본 개시는, 위에 서 논의된 바와 같이, 이 경우(즉, iToF)로 제한되지 않는데, 임의의 비행시간 기술이 적용될 수 있기 때문이다. 비행시간 이미징 시스템은 본 개시에 따른 비행시간 대상 검출 회로부를 더 포함하며, 그 회로부는, 이 실 시예에서 CPU로서 채택되고, 본 개시에 따른 비행시간 대상 검출 방법, 이를테면 도 1의 참조 하에 설명된 바와 같은 비행시간 대상 검출 방법을, 본 개시를 그 점에 있어서 제한하는 일 없이, 실행하도록 구성되는데, 다 른 실시예들에서, 해당 비행시간 대상 회로부가 도 2의 비행시간 대상 검출 방법 또는 도 3의 비행시간 대 상 검출 방법 등을 실행하도록 적응되기 때문이다. 도 5는, 예를 들어, 도 1의 참조 하에 설명된 바와 같이 반사율 데이터 또는 ALR 데이터, MAAR 데이터(또는 신 호) 및 깊이 데이터를 획득하기 위한 방법의 일 실시예를 묘사하며, 여기서 비행시간 이미징 시스템, 이를 테면 도 4의 참조 하에 설명되는 비행시간 이미징 시스템이 사용된다. 51에서, 비행시간 측정은 시작된다. 참조 부호들(52 내지 55)은 iToF의 경우 컴포넌트들 또는 위상들을 의미할 수 있고 dToF의 경우 측정결과들을 의미할 수 있는 네 개의 후속 서브프레임들을 나타낸다. 서브프레임들은 차례로 취득되어서, 스케일이 시간을 나타낸다. 하나의 비행시간 측정에서, 즉, 두 개의 시작점들 사이에서, 하나의 프레임이 취득된다. 하나의 서브프레임, 예컨대 서브프레임은, 단일 컴포넌트(iToF 경우임)에 대한 통합 시간을 나타내며, 두 개의 서브프레임들 사이, 예컨대, 프레임들(52 및 53) 사이의 시간이 각각의 컴포넌트, 즉, 이 예에서 프레임 에 대한 판독 시간을 나타낸다. ALR 데이터를 획득하기 위해, 적어도 두 개의 위상들(또는 서브프레임들)이, 이 실시예에서 사용된다. 그러나, 대상 및/또는 비행시간 이미징 시스템이 두 개의 서브프레임들 사이에서 이동하면 (그리고 이동 속력이 미리 결정된 임계값보다 높으면), 서브프레임들이 상이한 시간 인스턴스들에서 측정되기 때문에 모션 블러 아티 팩트가 생성될 수 있다. 그리하여, 컴퓨터 비전(예컨대, 대상 인식, 얼굴 인식 등) 등이 열화될 수 있다. 그러므로, 이러한 모션 블러 아티팩트는 제거되어야 할 수 있다. 통상적으로, 하나의 서브프레임, 예컨대, 서브프레임에서부터, MAAR 신호가, 위에서 논의된 바와 같이, 획 득될 수 있다. MAAR 신호는, 그러나, 주변 광뿐만 아니라 ALR을 포함하고, 주변 광의 양은 미지이다. 그래서, MAAR 신호는 하나의 단일 프레임(또는 적어도 하나의 단일 프레임)에서부터 판독될 수 있는 반면, ALR 데이터의 경우, 적어도 두 개의 프레임들이 필요하다. 더구나, 일반적으로 공지된 바와 같이, 깊이 데이터를 획득하기 위해, 통상적으로 모든 네 개의 서브프레임들 (또는 위상들)이 이용된다. 따라서, 서브프레임들(52 내지 55)을 판독함으로써, 방법, 이를테면 방법이 수행될 수 있다. 도 6을 참조하면, 특히 본 개시에서 논의되는 바와 같은 기술을 위해, 깊이 감지 또는 또는 거리 측정을 제공하 기 위해 사용될 수 있는 비행시간(ToF) 이미징 장치의 일 실시예가 예시되어 있으며, ToF 이미징 장치 는 iToF 카메라로서 구성된다. ToF 이미징 장치는 본 개시에서 논의되는 바와 같은 방법들을 수행하도록 구성되는 그리고 ToF 이미징 장치의 제어를 형성하는 비행시간 대상 검출 회로부를 갖는다(그리고, 통 상의 기술자에게 일반적으로 공지된 바와 같이, 도시되지 않은, 대응하는 프로세서들, 메모리 및 스토리지를 포 함을 포함한다). ToF 이미징 장치는 변조 광원을 갖고 (레이저 다이오드들에 기초한) 발광 엘리먼트들을 포함하며, 본 실시예에서, 발광 엘리먼트들은 협대역 레이저 엘리먼트들이다. 광원은 본 개시에서 논의되는 바와 같은 광, 즉, 변조된 광을 장면(관심 영역 또는 대상)에 방출하며, 그 장면은 그 광을 반사한다. 반사된 광은 광학적 스택에 의해 광 검출기에 포커싱된다. 광 검출기는 본 개시에서 논의되는 바와 같은 비행시간 이미징 부를 가지며, 비행시간 이미징 부는 화소들 의 어레이에 형성된 다수의 CAPD들 및 장면에서 반사된 광을 비행시간 이미징 부에 (이미지 센서의 각각의 화소에) 포커싱하는 마이크로 렌즈 어레이에 기초하여 구현된다. 광 방출 시간 및 변조 정보는, 장면에서 반사되는 광이 검출될 때, 비행시간 이미징 부로부터 각각의 정보를 또한 수신하는 비행시간 측정 유닛을 포함하는 비행시간 대상 검출 회로부 또는 컨트롤에 피딩 된다. 광원으로부터 수신된 변조된 광과 거친 및/또는 정밀한 이미징 모드에서 취득되는 거친 깊이 데이터 및/또는 정밀한 깊이 데이터에 기초하여, 비행시간 측정 유닛은 광원으로부터 방출되고 장면에 의 해 반사된 수신된 변조된 광의 위상 변이를 컴퓨팅하고 그것에 기초하여 이미지 센서와 장면 사이의 거 리(d)(깊이 정보)를 컴퓨팅한다. 더구나, 본 개시에서 논의되는 바와 같이, 두 개의 위상들이 반사율 데이터(ALR 데이터)를 획득하는데 사용되고 단일 위상이 MAAR 데이터를 획득하는데 사용된다. 깊이 정보는 비행시간 측정 유닛에서부터 비행시간 대상 검출 회로부의 3D 이미지 복원 유닛으로 피드되며, 3D 이미지 복원 유닛은 비행시간 측정 유닛으로부터 수신된 깊이 데이터, ALR 데이터, MAAR 데이 터 정보에 기초하여 장면의 3D 이미지를 복원(생성)한다. 더구나, 본 명세서에서 논의되는 바와 같은 대상 ROI 검출, 대상 검출, 및 대상 인식이 수행된다. 실시예들은 예시적인 순서의 방법 단계들을 갖는 방법들을 설명한다는 것이 인식되어야 한다. 특정 순서의 방 법 단계들은 그러나 단지 예시적인 목적만으로 주어지고 속박(binding)으로서 해석되지 않아야 한다. 예를 들 어 도 1 및 도 2의 실시예에서 4 및 5의 순서는 교환될 수 있다. 방법 단계들의 순서의 다른 변경들은 통상의 기술자에게 명백할 수 있다. 비행시간 이미징 시스템의 유닛들(41 및 45)로의 분할은 예시 목적만을 위한 것이라는 것과 본 개시는 특정 유닛들에서의 임의의 특정 기능 분할로 제한되지 않는다는 것에 주의한다. 예를 들면, 이미지 센서와 비행 시간 이미징 회로부는 각각의 프로그래밍된 이미지 센서, 필드 프로그램가능 게이트 어레이(FPGA) 등에 의 해 구현될 수 있다. 그 방법들은 컴퓨터 및/또는 프로세서, 이를테면 위에서 논의된 CPU로 하여금, 컴퓨터 및/또는 프로세서 상 에서 실행되고 있을 때 그 방법을 수행하게 하는 컴퓨터 프로그램으로서 또한 구현될 수 있다. 일부 실시예들 에서, 또한 위에서 설명된 프로세서와 같은 프로세서에 의해 실행될 때, 설명되는 방법들이 수행되게 하는 컴퓨 터 프로그램 제품을 내부에 저장하는 비일시적 컴퓨터 판독가능 기록 매체가 제공된다. 본 명세서에서 설명되고 첨부의 청구항들에서 청구되는 모든 유닛들 및 엔티티들은, 달리 언급되지 않으면, 예 를 들어 칩 상의 집적 회로 로직으로서 구현될 수 있고, 이러한 유닛들 및 엔티티들에 의해 제공되는 기능은, 달리 언급되지 않으면, 소프트웨어에 의해 구현될 수 있다. 위에서 설명된 본 개시의 실시예들이 구현되는 한, 적어도 부분적으로는, 소프트웨어 제어식 데이터 프로세싱 장치를 사용하여, 이러한 소프트웨어 제어 및 송신을 제공하는 컴퓨터 프로그램, 이러한 컴퓨터 프로그램이 제 공되는 스토리지 또는 다른 매체는 본 개시의 양태들로서 구상된다는 것이 이해될 것이다. 본원의 기술은 아래에서 설명되는 바와 같이 또한 구성될 수 있다는 것에 주의한다. 장면의 반사율을 나타내는 반사율 데이터를 획득하고; 장면의 반사율을 결정하고; 결정된 반사율에 기초하여 장면에서 대상의 영역을 결정하고; 그리고 대상을 검출하기 위해 대상의 결정된 영역에 기초하여 비행시간 이미지 데이터를 생성하도록 구성되는, 대상 검 출 회로부. 에 있어서, 비행시간 이미지 데이터를 생성하기 위해 결정된 반사율에 기초하여 노출 시간을 조정하도록 추가로 구성되는, 비행시간 대상 검출 회로부. 또는 에 있어서, 비행시간 이미지 데이터를 생성하기 위해 결정된 반사율에 기초하여 이득을 조정하 도록 추가로 구성되는, 비행시간 대상 검출 회로부. 내지 중 어느 하나에 있어서, 생성된 비행시간 이미지 데이터는 현재 이미지 프레임과 적어도 하나 의 후속 이미지 프레임 중 적어도 하나를 포함하는, 비행시간 대상 검출 회로부. 내지 중 어느 하나에 있어서, 결정된 반사율에 기초하여 대상을 검출하도록 추가로 구성되는, 비행 시간 대상 검출 회로부. 에 있어서, 반사율에 기초하여 그리고 생성된 비행시간 이미지 데이터에 기초하여 대상을 인식하도록 추 가로 구성되는, 비행시간 대상 검출 회로부. 에 있어서, 인식은 미리 결정된 대상 클래스에 기초하는, 비행시간 대상 검출 회로부. 에 있어서, 미리 결정된 대상 클래스는 대상의 미리 결정된 반사율 범위에 기초하여 정의되는, 비행시간 대상 검출 회로부. 내지 중 어느 하나에 있어서, 대상은 신체 부위를 포함하는, 비행시간 대상 검출 회로부. 에 있어서, 신체 부위는 얼굴을 포함하는, 비행시간 대상 검출 회로부. 장면의 반사율을 나타내는 반사율 데이터를 획득하는 단계; 장면의 반사율을 결정하는 단계; 결정된 반사율에 기초하여 장면에서 대상의 영역을 결정하는 단계; 및 대상을 검출하기 위해 대상의 결정된 영역에 기초하여 비행시간 이미지 데이터를 생성하는 단계를 포함하는, 비 행시간 대상 검출 방법. 에 있어서, 비행시간 이미지 데이터를 생성하기 위해 결정된 반사율에 기초하여 노출 시간을 조정하는 단계를 더 포함하는, 비행시간 대상 검출 방법. 또는 에 있어서, 비행시간 이미지 데이터를 생성하기 위해 결정된 반사율에 기초하여 이득을 조 정하는 단계를 더 포함하는, 비행시간 대상 검출 방법. 내지 중 어느 하나에 있어서, 생성된 비행시간 이미지 데이터는 현재 이미지 프레임과 적어도 하나의 후속 이미지 프레임 중 적어도 하나를 포함하는, 비행시간 대상 검출 방법. 내지 중 어느 하나에 있어서, 결정된 반사율에 기초하여 대상을 검출하는 단계를 더 포함하는, 비행시간 대상 검출 방법. 에 있어서, 반사율에 기초하여 그리고 생성된 비행시간 이미지 데이터에 기초하여 대상을 인식하는 단 계를 더 포함하는, 비행시간 대상 검출 방법. 에 있어서, 인식은 미리 결정된 대상 클래스에 기초하는, 비행시간 대상 검출 방법. 에 있어서, 미리 결정된 대상 클래스는 대상의 미리 결정된 반사율 범위에 기초하여 정의되는, 비행시 간 대상 검출 방법. 내지 중 어느 하나에 있어서, 대상은 신체 부위를 포함하는, 비행시간 대상 검출 방법. 에 있어서, 신체 부위는 얼굴을 포함하는, 비행시간 대상 검출 방법. 컴퓨터 상에서 실행되고 있을 때, 컴퓨터로 하여금, 내지 중 어느 하나에 따라 방법을 수행하게 하는 프로그램 코드를 포함하는, 컴퓨터 프로그램. 프로세서에 의해 실행될 때, 내지 중 어느 하나에 따른 방법이 수행되게 하는 컴퓨터 프로그램 제품을 저장하는, 비일시적 컴퓨터 판독가능 기록 매체.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2022-7020832", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예들이 다음의 첨부 도면들에 관해 예로서 설명되며, 도면들 중에서: 도 1은 본 개시에 따른 비행시간 이미징 방법을 블록도로 묘사하며; 도 2는 본 개시에 따른 비행시간 이미징 방법의 추가 실시예를 블록도로 묘사하며; 도 3은 본 개시에 따른 비행시간 이미징 방법의 추가 실시예를 블록도로 도시하며; 도 4는 본 개시에 따른 비행시간 이미징 시스템을 블록도로 묘사하며; 도 5는 본 개시에 따른 ALR 데이터, MAAR 데이터, 및 깊이 데이터를 획득하기 위한 방법의 일 실시예를 묘사하 며; 그리고 도 6은 본 개시에 따른 비행시간 이미징 장치의 일 실시예를 도시한다."}
