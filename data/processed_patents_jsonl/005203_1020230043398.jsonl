{"patent_id": "10-2023-0043398", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0148075", "출원번호": "10-2023-0043398", "발명의 명칭": "노이즈 환경에서의 대화서비스 제공방법 및 그 장치", "출원인": "주식회사 케이티", "발명자": "정재훈"}}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의해 수행되는 대화서비스 제공방법에 있어서,마이크를 통해 오디오 신호가 입력되는 단계;대상 화자에 의해 호출된 상태인지 여부를 지시하는 호출어 플래그를 식별하는 단계;상기 호출어 플래그가 제1 값으로 설정된 경우, 상기 오디오 신호에 호출어가 존재하는지 여부를 확인하는단계; 및상기 오디오 신호에 호출어가 존재하는 경우, 상기 호출어 플래그의 값을 상기 제1 값에서 제2 값으로 변경하는단계를 포함하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 오디오 신호는, 대상 화자의 음성 신호, 비대상 화자의 음성 신호 및 노이즈 신호 중 적어도 하나를 포함하는 것을 특징으로 하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 호출어 플래그가 제2 값으로 설정된 경우, 대화서비스를 종료하는 이벤트가 검출될 때까지, 상기 오디오신호에 호출어가 존재하는지 여부를 확인하지 않는 단계를 더 포함하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 확인 단계는, 미리 학습된 KWS(Keyword Spotting) 모델을 이용하여 상기 호출어를 검출하는 것을 특징으로 하는 대화서비스제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 마이크를 통해 입력된 오디오 신호로부터 상기 대상 화자의 음성 신호를 검출하는 단계를 더 포함하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 검출 단계는, 미리 학습된 PVAD(Personal Voice Activity Detection) 모델을 이용하여 상기 대상 화자의 음성 신호를 검출하는 것을 특징으로 하는 대화서비스 제공방법.공개특허 10-2024-0148075-3-청구항 7 제6항에 있어서, 상기 검출 단계는, 상기 오디오 신호의 특징 벡터를 추출하는 단계;상기 추출된 특징 벡터와 미리 저장된 임베딩 벡터(d-vector)를 연접하여 입력 벡터를 생성하는 단계; 및상기 생성된 입력 벡터를 상기 PVAD 모델에 적용하여 상기 대상 화자의 음성 신호를 검출하는 단계를 포함하는것을 특징으로 하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 임베딩 벡터(d-vector)는, 상기 대상 화자의 음성에 대한 특징 정보를 포함하는 특징 벡터 데이터임을 특징으로 하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,대화서비스의 종료를 지시하는 이벤트를 검출하는 단계; 및상기 이벤트 검출 시, 상기 호출어 플래그의 값을 상기 제2 값에서 상기 제1 값으로 변경하는 단계를 더 포함하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 이벤트는 상기 마이크를 통해 일정 시간 동안 음성 신호가 입력되지 않는 이벤트이거나 혹은 상기 대상 화자에 의해 서비스 종료를 지시하는 음성 신호를 입력 받는 이벤트임을 특징으로 하는 대화서비스 제공방법."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 제1항 내지 제10항 중 어느 하나의 항에 따른 방법이 컴퓨터 상에서 수행될 수 있도록 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "오디오 신호를 입력 받는 오디오 입력부;상기 오디오 신호 입력 시, 대상 화자에 의해 호출된 상태인지 여부를 지시하는 호출어 플래그를 식별하고, 상기 식별된 호출어 플래그가 제1 값으로 설정된 경우, 상기 오디오 신호에 호출어가 존재하는지 여부를 확인하는호출어 인식부; 및상기 오디오 신호에 호출어가 존재하는 경우, 상기 호출어 플래그의 값을 상기 제1 값에서 제2 값으로 변경하는플래그 설정부를 포함하는 대화서비스 제공장치."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2024-0148075-4-제12항에 있어서,대화서비스의 종료를 지시하는 이벤트가 검출되는 경우, 상기 플래그 설정부는 상기 호출어 플래그의 값을 상기제2 값에서 상기 제1 값으로 변경하는 것을 특징으로 하는 대화서비스 제공장치."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 마이크를 통해 입력된 오디오 신호로부터 상기 대상 화자의 음성 신호를 검출하는 음성구간 검출부를 더포함하는 대화서비스 제공장치."}
{"patent_id": "10-2023-0043398", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 음성구간 검출부는, 미리 학습된 PVAD(Personal Voice Activity Detection) 모델을 이용하여 상기 대상화자의 음성 신호를 검출하는 것을 특징으로 하는 대화서비스 제공장치."}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 AI 단말에 의해 수행되는 대화서비스 제공방법에 관한 것으로, 마이크를 통해 오디오 신호가 입력되는 단계; 대상 화자에 의해 호출된 상태인지 여부를 지시하는 호출어 플래그를 식별하는 단계; 상기 호출어 플래그 가 제1 값으로 설정된 경우, 상기 오디오 신호에 호출어가 존재하는지 여부를 확인하는 단계; 및 상기 오디오 신 호에 호출어가 존재하는 경우, 상기 호출어 플래그의 값을 상기 제1 값에서 제2 값으로 변경하는 단계를 포함한 다."}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 대화 서비스를 제공하는 방법에 관한 것으로서, 보다 구체적으로는 노이즈 환경에서 연속적인 대화 서비스를 제공하는 방법에 관한 것이다."}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능(Artificial Intelligence, AI) 기술에 대한 연구가 활발히 진행되면서, 그 시장 또한 기하급수 적으로 커지고 있다. 이러한 AI 기술을 쉽게 접할 수 있는 것이 바로 AI 스피커(AI 단말)이다. 2016년에 최초로 개발된 후 점점 시장이 확대되고 있으며, 2017년 글로벌 25억 달러 규모에서 2032년 252억 달러 규모까지 성장 할 것으로 예측하고 있다. 이러한 추세에 따라, 국내 대다수의 IT 기업 및 통신사들이 앞다투어 AI 스피커의 기 술 개발 및 성능 향상을 위해 노력하고 있다. 일반적으로 AI 스피커는 단말 형태로 댁내 거실에 주로 배치하여 사용하고 있다. 댁내에서는 가족 또는 친구들 간 대화가 주로 이뤄지기 때문에, AI 스피커에게 직접 명령을 내리기 위해서는 AI 스피커를 깨울 수 있는(wake up) 호출어(keyword)가 필요하다. 사용자는 호출어 발화로 AI 스피커를 깨운 뒤 음성으로 원하는 명령을 내리고 이 음성 신호는 AI 스피커를 통해 서버로 전달되어 음성인식, 자연어 처리, 음성합성을 거친 후 AI 스피커를 통 해 시스템 응답을 듣게 된다. 사용자는 원하는 명령을 내리고 싶을 때마다 항상 호출어를 발화하여 우선적으로 AI 스피커를 깨우는 과정이 필 요하다. 하지만, 이러한 방식은 사용자가 명령을 내릴 때 마다 선제적으로 AI 스피커를 깨우는 작업이 필요하기 때문에 명령어를 연달아 말하고 싶을 때는 불편한 점이 있다. 즉, 사용자가 \"OO야 오늘 날씨 어때\" 라고 말하면, \"오늘 날씨는 맑음입니다\"로 대화 서비스가 바로 종료되어, 사용자가 추가 명령을 하고 싶을 경우, 호 출어를 다시 불러야 하는 불편함이 있다. 이제는 점점 사용자들이 AI 스피커와의 자연스러운 대화를 추구하기 때문에 이에 대한 해결책이 필요한 상황이다. 또한, 실내 환경에서는 주변 대화 소리, TV 소리, 기타 배경잡음 등 여러 가지 소음이 발생하는데, 이때 원하는 화자에 대한 음성을 검출해야만 자연스러운 대화가 가능하다. 따 라서, 실내 노이즈 환경에서 사용자와 AI 스피커 간에 자연스럽고 연속적인 대화 서비스를 제공할 수 있는 방안 이 필요하다."}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제 및 다른 문제를 해결하는 것을 목적으로 한다. 또 다른 목적은 단 한번의 호출어를 사용 하여 AI 단말과 사용자 간에 연속적인 대화 서비스를 제공할 수 있는 방법 및 그 장치를 제공함에 있다. 또 다른 목적은 실내 노이즈 환경에서 대상 화자의 음성 신호만을 정확하게 검출하여 AI 단말과 사용자 간에 자 연스러운 대화 서비스를 제공할 수 있는 방법 및 그 장치를 제공함에 있다."}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 목적을 달성하기 위해 본 발명의 일 측면에 따르면, 마이크를 통해 오디오 신호가 입력되는 단 계; 대상 화자에 의해 호출된 상태인지 여부를 지시하는 호출어 플래그를 식별하는 단계; 상기 호출어 플래그가 제1 값으로 설정된 경우, 상기 오디오 신호에 호출어가 존재하는지 여부를 확인하는 단계; 및 상기 오디오 신호 에 호출어가 존재하는 경우, 상기 호출어 플래그의 값을 상기 제1 값에서 제2 값으로 변경하는 단계를 포함하는 대화서비스 제공방법을 제공한다. 본 발명의 다른 측면에 따르면, 오디오 신호를 입력 받는 오디오 입력부; 상기 오디오 신호 입력 시, 대상 화자 에 의해 호출된 상태인지 여부를 지시하는 호출어 플래그를 식별하고, 상기 식별된 호출어 플래그가 제1 값으로 설정된 경우, 상기 오디오 신호에 호출어가 존재하는지 여부를 확인하는 호출어 인식부; 및 상기 오디오 신호에 호출어가 존재하는 경우, 상기 호출어 플래그의 값을 상기 제1 값에서 제2 값으로 변경하는 플래그 설정부를 포 함하는 대화서비스 제공장치를 제공한다. 본 발명의 또 다른 측면에 따르면, 마이크를 통해 오디오 신호가 입력되는 과정; 상기 오디오 신호 입력 시, 대 상 화자에 의해 호출된 상태인지 여부를 지시하는 호출어 플래그를 식별하는 과정; 상기 호출어 플래그가 제1 값으로 설정된 경우, 상기 오디오 신호에 호출어가 존재하는지 여부를 확인하는 과정; 및 상기 오디오 신호에 호출어가 존재하는 경우, 상기 호출어 플래그의 값을 상기 제1 값에서 제2 값으로 변경하는 과정이 컴퓨터 상에 서 실행 가능하도록 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따른 대화서비스 제공방법 및 그 장치에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 호출어를 여러 번 사용할 필요없이, 호출어 플래그를 이용하여 단 한번의 호출어를 사용하도록 함으로써, AI 단말과 사용자 간에 자연스럽고 연속적인 대화 서비스를 제공할 수 있는 장점이 있다. 또한, 본 발명의 실시 예들 중 적어도 하나에 의하면, 미리 학습된 PVAD(Personal Voice Activity Detection) 모델을 이용하여 실내 노이즈 환경에서 대상 화자의 음성 신호만을 정확하게 검출함으로써, AI 단말과 사용자 간에 자연스럽고 연속적인 대화 서비스를 제공할 수 있는 장점이 있다. 다만, 본 발명의 실시 예들에 따른 대화서비스 제공방법 및 그 장치가 달성할 수 있는 효과는 이상에서 언급한"}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "것들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0043398", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 즉, 본 발명에서 사용되는 '부' 라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미하며, '부'는 어떤 역할들을 수행한 다. 그렇지만 '부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '부'는 어드레싱할 수 있는 저장 매 체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요 소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들을 포함한다. 구성요소들과 '부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '부'들 로 결합되거나 추가적인 구성요소들과 '부'들로 더 분리될 수 있다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포 함하는 것으로 이해되어야 한다. 본 발명은 단 한번의 호출어를 사용하여 AI 단말과 사용자 간에 연속적인 대화 서비스를 제공할 수 있는 방법 및 그 장치를 제안한다. 또한, 본 발명은 실내 노이즈 환경에서 대상 화자의 음성 신호만을 정확하게 검출하여 AI 단말과 사용자 간에 자연스러운 대화 서비스를 제공할 수 있는 방법 및 그 장치를 제안한다. 이하에서는, 본 발명의 다양한 실시 예들에 대하여, 도면을 참조하여 상세히 설명한다. 도 1은 본 발명의 일 실시 예에 따른 대화서비스 제공시스템의 구성을 나타내는 도면이다. 도 1을 참조하면, 본 발명의 일 실시 예에 따른 대화서비스 제공시스템은 AI 단말, 음성인식 플랫폼 및 통신 네트워크를 포함할 수 있다. AI 단말과 음성인식 플랫폼은 통신 네트워크를 통해 서로 연결될 수 있다. 통신 네트워크 는 유선 네트워크와 무선 네트워크를 포함할 수 있으며, 구체적으로 근거리 네트워크(LAN: Local Area Network), 도시권 네트워크(MAN: Metropolitan Area Network), 광역 네트워크(WAN: Wide Area Network) 등 다 양한 네트워크를 포함할 수 있다. 또한, 통신 네트워크는 공지의 월드 와이드 웹(WWW: World Wide Web)을 포함할 수도 있다. 그러나, 본 발명에 따른 통신 네트워크는 상기 열거된 네트워크에 국한되지 않고, 공지 의 무선 데이터 네트워크, 공지의 전화 네트워크, 공지의 유/무선 텔레비전 네트워크 중 적어도 하나를 포함할 수도 있다. AI 단말(또는 AI 스피커, 110)은 음성인식 플랫폼과 연동하여 연속적인 대화 서비스를 사용자에게 제 공할 수 있다. 이때, AI 단말은 사용자의 발화 데이터에 대응하는 발화 응답 데이터를 음성인식 플랫 폼으로부터 획득하여 제공할 수 있다. AI 단말은 마이크를 통해 사용자의 발화 데이터를 수신할 수 있다. AI 단말은 스피커를 통해 사 용자의 발화 데이터에 대응하는 발화 응답 데이터를 출력할 수 있다. AI 단말은 미리 학습된 KWS(Keyword Spotting) 모델을 이용하여 호출어 인식 기능을 수행할 수 있다. 즉, AI 단말은 마이크를 통해 입력되는 오디오 신호(데이터)로부터 미리 정해진 핵심어(keywork)를 검출함으로 써, 해당 사용자가 단말을 호출했는지 여부를 확인하는 호출어 인식 과정을 수행할 수 있다. 이때, AI 단말 은 사전에 등록된 화자의 정보를 이용하여 특정 사용자가 단말을 호출했는지 여부를 확인할 수 있다. 이러한 호출어 인식 과정을 통해 AI 단말은 깨어나게(wake up) 되고, 그 이후에 사용자의 음성 명령을 수신할 준비를 하게 된다. AI 단말은, 호출어 인식 시, 사용자와의 대화 서비스가 종료될 때까지, 호출어 인식 과정을 생략할 수 있다. 이에 따라, 사용자는 호출어를 처음 한번만 부르면 되고 그 이후부터는 호출어 발화없이 음성 명령만 발화함으로써, AI 단말과 연속적인 대화를 수행할 수 있다. AI 단말은 미리 학습된 PVAD(Personal Voice Activity Detection) 모델을 이용하여 대상 화자(target speaker)의 음성 구간을 검출할 수 있다. AI 단말은 검출된 음성 구간에 대응하는 음성 데이터를 음성인식 플랫폼으로 제공할 수 있다. 해당 과정을 수행하는 이유는 대상 화자의 음성 데이터만을 추출하여 음성인식 플랫폼에 전송함으로써, 노이즈 환경에서의 음성인식 성능을 개선할 수 있을 뿐만 아니라, 음성인식을 처리하기 위한 연산량이 증가하는 것을 방지하기 위함이다. 한편, 본 실시 예에서는, AI 단말에서 대상 화자의 음성 구간을 검출하는 것을 예시하고 있으나 반드시 이 에 제한되지는 않으며, 음성인식 플랫폼에서 대상 화자의 음성 구간을 검출할 수 있음은 당업자에게 자명 할 것이다. 음성인식 플랫폼(또는 음성인식 서버, 120)은 AI 단말로부터 수신된 음성 데이터에 대해 음성인식을 수행 할 수 있다. 이때, 음성인식 플랫폼은 미리 학습된 음성인식모델을 이용하여 음성 데이터에 대한 음성인식 을 수행할 수 있다. 음성인식 플랫폼은 음성인식 결과를 기반으로 사용자의 의도를 파악하고, 사용자의 의도에 대응하는 발화 응답 데이터를 생성할 수 있다. 음성인식 플랫폼은 생성된 발화 응답 데이터를 AI 단말로 제공 할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 대화서비스 제공시스템의 시그널링 프로세스를 설명하는 흐름도이다. 도시 된 흐름도에서는 대화서비스 제공시스템의 시그널링 프로세스를 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들 로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가되어 수행될 수 있다. 도 2를 참조하면, AI 단말은 마이크를 통해 외부의 오디오 데이터를 수신할 수 있다(S205). 이때, 상기 오 디오 데이터는 발화 데이터와 노이즈 데이터를 포함할 수 있다. AI 단말은, 오디오 데이터 수신 시, 호출어 플래그(flag)를 확인할 수 있다(S210). 여기서, 호출어 플래그 는 현재 사용자에 의해 호출어가 불린 상태인지 여부를 지시하는 정보이다. 상기 확인 결과, 호출어 플래그가 '0'으로 설정된 경우(S215), AI 단말은 마이크를 통해 입력된 오디오 데 이터에 호출어가 존재하는지 여부를 확인하는 호출어 인식 기능을 수행할 수 있다(S220). 이때, AI 단말은 미리 학습된 KWS 모델을 이용하여 호출어 인식 기능을 수행할 수 있다. 한편, 상기 확인 결과, 호출어 플래그가 '1'로 설정된 경우(S215), AI 단말은 사용자와의 대화 서비스 가 종료될 때까지 호출어 인식 과정을 생략할 수 있다. AI 단말은 마이크를 통해 입력된 오디오 데이터로부터 대상 화자의 음성 구간을 검출할 수 있다(S225). 이 때, AI 단말은 미리 학습된 PVAD 모델을 이용하여 대상 화자의 음성 구간을 검출할 수 있다. 대상 화자는 호출어를 사용하여 대화 서비스를 제공받고자 하는 사용자를 의미한다. AI 단말은 검출된 음성 구간에 대응하는 음성 데이터를 음성인식 플랫폼으로 제공할 수 있다(S230). 음성인식 플랫폼은 AI 단말로부터 수신된 음성 데이터에 대해 음성인식을 수행할 수 있다(S235). 이 때, 음성인식 플랫폼은 미리 학습된 음성인식모델을 이용하여 대상 화자의 음성 데이터를 텍스트 데이 터로 변환할 수 있다. 음성인식 플랫폼은 음성인식 결과를 기반으로 자연어 처리(Natural Language Processing, NLP) 과정을 수 행할 수 있다(S240). 여기서, 자연어란 사람이 의사소통을 하기 위해 사용하는 언어를 의미하고, 자연어 처리란 컴퓨터가 자연어를 분석하여 이해하고 처리하는 기술을 의미한다. 해당 과정에서는 자연어에 대한 형태소 분석, 구문 해석, 의미 분석, 화용 분석 등을 통해 컴퓨터가 문장에 담긴 의도를 파악하게 된다. 상기 자연어 처리 과정은 미리 학습된 기계학습 모델을 통해 수행될 수 있다. 음성인식 플랫폼은 자연어 처리 결과를 기반으로 사용자의 발화 데이터에 대응하는 발화 응답 데이터 를 생성할 수 있다(S245). 음성인식 플랫폼은 생성된 발화 응답 데이터를 AI 단말로 제공할 수 있다(S250). AI 단말은 스피커를 통해 음성인식 플랫폼으로부터 수신된 발화 응답 데이터를 출력할 수 있다 (S255). 도 3은 본 발명의 일 실시 예에 따른 대화서비스 제공장치의 구성을 나타내는 도면이다. 도 3을 참조하면, 본 발명의 일 실시 예에 따른 대화서비스 제공장치는 오디오 입력부, 호출어 인식 부, 플래그 설정부, 음성구간 검출부, 서버 연동부 및 오디오 출력부를 포함할 수 있 다. 도 3에 도시된 구성요소들은 대화서비스 제공장치를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 대화서비스 제공장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 본 실시 예에 따른 대화서비스 제공장치는 AI 단말이거나 혹은 AI 단말 내에 구축될 수 있다. 오디오 입력부는, 일종의 마이크로서, 외부로부터 입력되는 오디오 데이터를 수신할 수 있다. 상기 오디오 데이터는 대상 화자(target speaker)의 발화 데이터, 비대상 화자(non-target speaker)의 발화 데이터, 노이즈 데이터 등을 포함할 수 있다. 호출어 인식부는, 오디오 데이터 수신 시, 호출어 플래그(flag)를 확인할 수 있다. 여기서, 호출어 플래그 는 현재 사용자에 의해 호출어가 불린 상태인지 아닌지를 지시하는 정보이다. 호출어 인식부는 호출어 플래그(flag)의 값에 따라 호출어 인식 과정을 수행하거나 혹은 호출어 인식 과정 을 생략할 수 있다. 가령, 호출어 플래그가 '0'으로 설정된 경우, 호출어 인식부는 미리 학습된 KWS 모델 을 이용하여 마이크를 통해 입력된 오디오 데이터에 호출어가 존재하는지 여부를 확인할 수 있다. 한편, 호출어 플래그가 '1'로 설정된 경우, 호출어 인식부는 사용자와의 대화 서비스가 종료될 때까지 호출어 인식 과정 을 생략할 수 있다. 플래그 설정부는 호출어 인식 여부에 따라 호출어 플래그를 설정할 수 있다. 가령, 도 4에 도시된 바와 같 이, 호출어 플래그의 초기값이 '0'으로 설정된 상태에서, 사용자의 호출어가 인식되면, 플래그 설정부는 호출어 플래그를 '0'에서 '1'로 설정하게 된다. 반면, 사용자의 호출어가 인식되지 않으면, 플래그 설정부(23 0)는 호출어 플래그를 그대로 유지하게 된다. 플래그 설정부는 대화 서비스의 종료 여부에 따라 호출어 플래그를 설정할 수 있다. 가령, 도 4에 도시된 바와 같이, 호출어 플래그의 값이 '1'로 설정된 상태에서, 대화 서비스가 종료되면, 플래그 설정부는 호출 어 플래그를 '1'에서 '0'으로 설정하게 된다. 반면, 대화 서비스가 종료되지 않으면, 플래그 설정부는 호 출어 플래그를 그대로 유지하게 된다. 여기서, 대화 서비스의 종료는 사용자로부터 일정 시간 동안 음성 신호가 입력되지 않은 이벤트나 혹은 사용자로부터 '종료해줘'라는 음성 신호가 입력된 이벤트를 통해 감지될 수 있으 며 반드시 이에 제한되지는 않는다. 음성구간 검출부는 미리 학습된 PVAD 모델을 이용하여 마이크를 통해 입력된 오디오 데이터로부터 대상 화 자의 음성 구간을 검출할 수 있다. 이때, 음성구간 검출부는 입력 신호의 매 프레임마다 대상 화자의 음성 신호인지, 비대상 화자의 음성 신호인지, 기타 노이즈 신호인지를 판별하는 PVAD 모델을 통해 대상 화자의 음성 구간을 검출할 수 있다. 한번의 호출어만 사용하여 자연스러운 대화 서비스를 제공하기 위해 가장 문제가 될 수 있는 부분은 노이즈 환 경에서의 음성 검출 성능이다. 기존 방식에서는 한 번의 명령어만 말하면 짧게 끝나기 때문에 큰 문제가 없지만, 연속적인 발화를 통한 자연스러운 대화는 다소 시간이 길어 지기 때문에 노이즈 환경에 따라 음성 검출 성능에 큰 영향을 줄 수 있다. 따라서, 본 실시 예에서는 TV 소리, 주변 사람들의 대화 등 시끄러운 환경에서도 현재 대화하고 있는 화자에만 타겟팅하여 음성을 검출할 수 있는 개인화 음성 검출 기법을 적용할 수 있다. 개인화 음성 검출 기법은 미리 학습된 PVAD 모델을 이용하여 실내 노이즈 환경에서 대상 화자의 음성 신호를 검 출하는 방법이다. 일 예로, 도 5에 도시된 바와 같이, 대상 화자의 음성에 대한 특징 정보가 담긴 임베딩 벡터 (d-vector)를 스토리지에 미리 저장해 놓는다(S510). 그런 다음 마이크를 통해 입력 신호(즉, 오디오 신호)가 들어오면(S520), 음성구간 검출부는 입력 신호의 특징 벡터(Log-Mel feature)를 추출할 수 있다(S530). 그리고, 음성구간 검출부는 입력 신호로부터 추출된 특징 벡터와 미리 저장된 d-vector를 연접 (concatenation)하여 입력 벡터를 생성할 수 있다(S540). 음성구간 검출부는 생성된 입력 벡터를 미리 학 습된 PVAD 모델에 적용할 수 있다(S550). 음성구간 검출부는 PVAD 모델을 이용하여 입력 벡터가 대상 화자 의 음성 신호인지, 비대상 화자의 음성 신호인지, 기타 노이즈 신호인지를 결정하는 분류(triple classification)를 수행할 수 있다(S560). 이처럼, 대상 화자의 음성 정보를 이용함으로써 실내 노이즈 환경에서 대상 화자의 음성만을 정확하게 검출할 수 있다. 즉, 배경잡음 형태의 노이즈 뿐만 아니라 사람들끼리 대화하는 상황에서도 대상 화자의 음성 신호만을 정확하게 검출할 수 있다. 또한, 단순한 구조의 순환 신경망(Recurrent Neural Network)을 사용하여 PVAD 모델을 구현하기 때문에, 모델 사이즈가 굉장히 작아 모바일 임베디드 환경에서도 연산량 문제없이 적용이 가능하다. 만약, 이진 분류(binary classification)를 수행하는 기존 VAD를 적용한다면, 마이크를 통해 입력되는 신호가 음성인지 아니면 노이즈인지 여부만을 구분하기 때문에 여러 사람의 목소리가 혼재하는 상황에서는 대상 화자의 음성 신호를 잘못 검출할 수 있게 된다. 하지만, PVAD 모델은 다양한 노이즈 환경에서 대상 화자의 음성 신호만 을 정확하게 검출함으로써, 사용자와 AI 단말 간에 자연스럽고 연속적인 대화가 가능하다. 서버 연동부는 AI 단말과 음성인식 플랫폼 간에 데이터를 송수신하기 위한 통신 인터페이스를 제공할 수 있다. 상기 통신 인터페이스는 유/무선 통신 인터페이스를 포함할 수 있다. 서버 연동부는 대상 화자의 음성 신호를 음성인식 플랫폼으로 제공할 수 있다. 서버 연동부는 대상 화자의 음성 신호(즉, 발화 데이터)에 대응하는 응답 음성 신호(즉, 합성 음성 신호 또는 발화 응답 데이 터)를 음성인식 플랫폼으로부터 수신할 수 있다. 오디오 출력부는, 일종의 스피커로서, 음성인식 플랫폼으로부터 수신된 응답 음성 신호를 출력할 수 있다. 이상, 상술한 바와 같이, 본 발명의 일 실시 예에 따른 대화서비스 제공장치는, 호출어를 여러 번 사용할 필요없이, 호출어 플래그를 이용하여 단 한번의 호출어를 사용하도록 함으로써, AI 단말과 사용자 간에 자연스 럽고 연속적인 대화 서비스를 제공할 수 있다. 또한, 대화서비스 제공장치는 미리 학습된 PVAD 모델을 이 용하여 실내 노이즈 환경에서 대상 화자의 음성 신호만을 정확하게 검출함으로써, AI 단말과 사용자 간에 자연 스럽고 연속적인 대화 서비스를 제공할 수 있다. 도 6은 본 발명의 일 실시 예에 따라 대화서비스 제공방법을 설명하는 흐름도이다. 본 실시 예에 따른 대화서비 스 제공방법은 대화서비스 제공장치에 의해 수행될 수 있다. 도시된 흐름도에서는 대화서비스 제공방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합 되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가되어 수행될 수 있다. 도 6을 참조하면, 본 발명의 일 실시 예에 따른 대화서비스 제공장치는 외부의 오디오 신호(데이터)가 마 이크를 통해 입력되는지 여부를 확인할 수 있다(S605). 상기 605 단계의 확인 결과, 외부의 오디오 데이터가 입력되는 경우, 대화서비스 제공장치는 현재 사용자 에 의해 호출어가 불린 상태인지 여부를 지시하는 호출어 플래그를 확인(식별)할 수 있다(S610). 상기 610 단계의 확인 결과, 호출어 플래그의 값이 '0'으로 설정된 경우(S615), 대화서비스 제공장치는 마 이크를 통해 입력된 오디오 데이터에 호출어가 존재하는지 여부를 확인하는 호출어 인식 기능을 수행할 수 있다 (S620). 대화서비스 제공장치는, 호출어 인식 시, 호출어 플래그의 값을 '0'에서 '1'로 변경할 수 있다(S625). 한편, 상기 610 단계의 확인 결과, 호출어 플래그의 값이 '1'로 설정된 경우(S615), 대화서비스 제공장치 는 사용자와의 대화 서비스가 종료될 때까지 호출어 인식 과정을 생략할 수 있다. 대화서비스 제공장치는 미리 학습된 PVAD 모델을 이용하여 마이크를 통해 입력된 오디오 데이터로부터 대 상 화자의 음성 신호를 검출할 수 있다(S630). 대화서비스 제공장치는 대상 화자의 음성 신호를 음성인식 플랫폼으로 전송할 수 있다(S635). 대화서비스 제공장치는 대상 화자의 음성 신호(즉, 발화 데이터)에 대응하는 응답 음성 신호(즉, 합성 음 성 신호 또는 발화 응답 데이터)를 음성인식 플랫폼으로부터 수신할 수 있다(S640). 대화서비스 제공장치는 스피커를 통해 음성인식 플랫폼으로부터 수신된 응답 음성 신호를 출력할 수 있다(S645). 대화서비스 제공장치는 대화 서비스의 종료 여부를 확인할 수 있다(S650). 이때, 대화서비스 제공장치 는 마이크를 통해 일정 시간 동안 음성 신호가 입력되지 않은 경우 대화 서비스가 종료된 것으로 판단할 수 있다. 또한, 대화서비스 제공장치는 음성인식 플랫폼으로부터 대화 서비스 종료를 지시하는 신호를 수신한 경우 대화 서비스가 종료된 것으로 판단할 수 있다. 이때, 음성인식 플랫폼은 사용자로부터 '종 료해줘'라는 음성 명령이 인식된 경우, 대화 서비스 종료를 지시하는 신호를 생성하여 대화서비스 제공장치 로 제공할 수 있다. 상기 650 단계의 확인 결과, 대화 서비스가 종료된 경우, 대화서비스 제공장치는 호출어 플래그를 '1'에서 '0'으로 변경할 수 있다(S655). 한편, 상기 650 단계의 확인 결과, 대화 서비스가 종료되지 않은 경우, 대화서비스 제공장치는 상술한 605 단계 내지 650 단계의 동작을 반복적으로 수행할 수 있다. 이상, 상술한 바와 같이, 본 발명의 일 실시 예에 따른 대화서비스 제공방법은, 호출어를 여러 번 사용할 필요 없이, 호출어 플래그를 이용하여 단 한번의 호출어를 사용하도록 함으로써, AI 단말과 사용자 간에 자연스럽고 연속적인 대화 서비스를 제공할 수 있다. 또한, 대화서비스 제공방법은 미리 학습된 PVAD 모델을 이용하여 실내 노이즈 환경에서 대상 화자의 음성 신호만을 정확하게 검출함으로써, AI 단말과 사용자 간에 자연스럽고 연속적 인 대화 서비스를 제공할 수 있다. 도 7은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 구성 블록도이다. 도 7을 참조하면, 본 발명의 일 실시 예에 따른 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 상기 컴퓨팅 장치는 상술한 대화서비스 제공장치 또 는 상기 대화서비스 제공장치를 구성하는 요소들에 포함되는 하나 이상의 컴포넌트일 수 있다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시 예에 따라 동작하도록 할 수 있다. 예 컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시 예에 따른 동작들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프 로세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시 예에서, 컴퓨터 판독 가능 저장 매체(72 0)는 메모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이 상의 자기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합 일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양 한 컴포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인 터페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예 시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터 치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/ 또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있 고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장 수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한 적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해 석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2023-0043398", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 대화서비스 제공시스템의 구성을 나타내는 도면; 도 2는 본 발명의 일 실시 예에 따른 대화서비스 제공시스템의 시그널링 프로세스를 설명하는 흐름도; 도 3은 본 발명의 일 실시 예에 따른 대화서비스 제공장치의 구성을 나타내는 도면; 도 4는 호출어 플래그를 설정하는 방법을 설명하기 위해 참조되는 도면; 도 5는 대상 화자의 음성 신호를 검출하는 방법을 설명하기 위해 참조되는 도면; 도 6은 본 발명의 일 실시 예에 따라 대화서비스 제공방법을 설명하는 흐름도; 도 7은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 구성 블록도."}
