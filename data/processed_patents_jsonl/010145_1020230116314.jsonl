{"patent_id": "10-2023-0116314", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0039585", "출원번호": "10-2023-0116314", "발명의 명칭": "인공 지능 및 기계 학습에 기초한 통신 채널 정보의 리포팅 시스템, 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "사브르 하미드"}}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "채널을 이용하여 참조 신호를 수신하도록 구성되는 수신기;상기 참조 신호에 기초하여 채널 정보를 결정하고,제1 기계 학습 모델을 사용하여 상기 채널 정보에 기초하는 표현을 생성하고,상기 표현에 기초하여, 제2 기계 학습 모델을 사용하여 프리코딩 정보를 생성하고,상기 프리코딩 정보에 기초하여 채널 품질 정보를 생성하도록 구성된 적어도 하나의 프로세서: 및상기 표현 및 상기 채널 품질 정보를 전송하도록 구성된 송신기를 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 제2 기계 학습 모델을 수신하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 참조 모델에 기초하여 상기 제2 기계 학습 모델을 훈련하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 채널 품질 정보는 채널 품질 표시자(CQI)를 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 채널 정보는 채널 행렬을 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 표현과 상기 채널 품질 정보를 결합하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "채널을 이용하여 신호를 수신하도록 구성되는 수신기;상기 채널에 관련된 채널 정보의 표현을 전송하도록 구성되는 송신기; 및상기 신호에 기초하여 상기 채널 정보를 결정하고,압축 방식을 사용하여, 적어도 하나의 기계 학습 모델을 사용하여 상기 채널 정보에 기초하여 상기 채널 정보의상기 표현을 생성하도록 구성된 적어도 하나의 프로세서를 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 적어도 하나의 기계 학습 모델은 공간 압축을 수행하도록 구성된 인코더를 포함하는, 장치.공개특허 10-2024-0039585-3-청구항 9 제8항에 있어서, 상기 인코더는 부대역에 대해 공간 압축을 수행하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 인코더는 제1 인코더이고, 상기 부대역은 제1 부대역이고, 상기 적어도 하나의 기계 학습 모델은 제2 부대역에 대해 공간 압축을 수행하도록 구성된 제2 인코더를 더 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 적어도 하나의 기계 학습 모델은 상기 제1 부대역 및 상기 제2 부대역에 대해 주파수 압축을 수행하도록구성된 제3 인코더를 더 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 적어도 하나의 기계 학습 모델은 공간 압축 및 주파수 압축을 수행하도록 구성된 인코더를 포함하는,장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 인코더는 제1 부대역에 대해 공간 압축 및 주파수 압축을 수행하고 제2 부대역에 대해 공간 압축 및 주파수 압축을 수행하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제7항에 있어서, 상기 적어도 하나의 기계 학습 모델은 공간 압축을 사용하여 상기 채널 정보의 상기 표현을 생성하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제7항에 있어서, 상기 적어도 하나의 기계 학습 모델은 주파수 압축을 사용하여 상기 채널 정보의 상기 표현을 생성하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제7항에 있어서, 상기 적어도 하나의 기계 학습 모델은 공간 압축 및 주파수 압축을 사용하여 상기 채널 정보의 상기 표현을 생성하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "채널을 이용하여 참조 신호를 수신하는 수신기;상기 참조 신호에 기초하여 채널 정보를 결정하고,공개특허 10-2024-0039585-4-상기 채널 정보에 기초하여 채널 품질 정보를 생성하고,기계 학습 모델을 사용하여, 상기 채널 정보와 상기 채널 품질 정보의 공동 표현을 생성하도록 구성된 적어도하나의 프로세서; 및상기 공동 표현을 전송하도록 구성된 송신기를 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 채널 정보는 채널 행렬을 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 상기 채널 정보는 프리코딩 행렬을 포함하는, 장치."}
{"patent_id": "10-2023-0116314", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서, 적어도 하나의 프로세서는,상기 채널 정보에 기초하여 프리코딩 정보를 생성하고,상기 프리코딩 정보에 기초하여 상기 채널 품질 정보를 생성하도록 구성되는, 장치."}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "장치는 채널을 사용하여 기준 신호를 수신하도록 구성된 수신기, 기준 신호에 기초하여 채널 정보를 결정하고, 제1 머신 러닝 모델을 사용하여 채널 정보에 기초하여 표현을 생성하고, 표현에 기초하여 제2 머신 러닝 모델을 사용하여 프리코딩 정보를 생성하고, 프리코딩 정보에 기초하여 채널 품질 정보를 생성하도록 구성된 적어도 하 나의 프로세서, 및 표현과 채널 품질 정보를 전송하도록 구성된 송신기를 포함할 수 있다."}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 통신 시스템에 관한 것으로, 특히 통신 시스템의 물리 계층에 대한 인공 지능 및 기계 학 습을 위한 시스템, 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무선 통신 시스템에서, 수신기는 송신기와 수신기 사이의 채널 조건에 기초하여 채널 상태 정보 또는 프리코딩 정보를 송신기에 제공할 수 있다. 송신기는 수신기로의 전송을 수행하기 위해 채널 상태 정보 또는 프리코딩 정 보를 사용할 수 있다."}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이 배경기술 단락에 개시된 상기 정보는 본 발명의 배경에 대한 이해의 향상을 위한 것일 뿐이므로 선행 기술을 구성하지 않는 정보를 포함할 수 있다."}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일부 무선 통신 시스템에서, 사용자 장치(UE)는 기지국에 의해 채널을 통해 전송된 참조 신호를 기반으로 채널 측정을 수행하여 기지국에 보고할 채널 정보를 결정할 수 있다. UE는 UE가 기지국에 보고할 수 있는 프리코딩 행렬을 계산하기 위해 채널 측정치를 사용할 수 있다. 기지국은 보고된 프리코딩 행렬을 채널을 통해 후속 다운 링크 전송에 적용할 수 있다. 기지국이 UE에 의해 보고된 프리코딩 행렬을 사용할 필요는 없지만, 많은 상황에 서, UE에 의해 보고된 프리코딩 행렬은 후속 다운링크 전송을 위해 최상의 성능을 제공할 수 있다. UE는 또한 기지국에 의한 후속 전송을 위해, 변조 차수, 코드율(code rate) 등을 선택하기 위해 기지국에 의해 사용될 수 있는 채널 품질 표시자(CQI)를 계산하도록 프리코딩 행렬을 사용하면서, 예를 들어 보고된 프리코딩 행렬을 사용할 수 있다. 따라서 CQI를 정확하게 결정하기 위해서, UE는 기지국에 보고할 수 있는 프리코딩 행렬 에 대한 지식을 요구할 수 있다. 이러한 지식은 UE가 알고리즘을 사용하여 프리코딩 행렬을 계산할 수 있는 채 널 정보(예를 들어, 코드북)를 보고하기 위한 기술을 사용하는 UE에 존재할 수 있다. 그러나, 후술되는 바와 같이 인공지능 및/또는 기계 학습을 이용하여 채널 정보를 보고할 수 있는 UE에서, UE는 기지국에 보고할 수 있는 프리코딩 행렬에 대한 지식을 갖지 않을 수 있다. 예를 들어, UE는 채널 상태 정보(CSI) 생성의 출력에만 액세 스할 수 있다. CSI 생성 모델의 출력은 프리코딩 행렬의 압축된 표현일 수 있다. 프리코딩 행렬 자체는 기지국 에 배치될 수 있으며 반드시 UE와 공유될 필요는 없는 CSI 복원 모델의 출력에 구성될 수 있다. 상술된 바와 같이, 채널 정보를 보고하는 한 가지 접근 방법은 UE와 기지국 모두에서 사용할 수 있는 코드북을 사용하여, 기지국이 UE에 의해 보고된 프리코딩 행렬을 사용할 수 있는(또는 적어도 액세스할 수 있는) 것을 보 장하는 방식으로 UE가 프리코딩 행렬을 기지국에 보고할 수 있게 하는 것이다. 이 접근 방법의 문제는 코드북의 사용이 적절한 정확성을 제공하지 못할 수 있고/또는 업링크 채널에서 상당한 양의 오버헤드 데이터 전송을 포 함할 수 있다는 것이다. 이러한 문제를 극복하기 위해, 채널 정보를 압축할 수 있는 하나 이상의 인공 지능 및/또는 기계 학습 모델을 사용하여 UE가 프리코딩 행렬 및/또는 CQI와 같은 채널 정보를 보고할 수 있도록 하는 시스템 및 방법이 본 명 세서에서 설명되어 있다. 압축을 위해 인공 지능 및/또는 기계 학습 모델을 사용할 수 있는 일부 실시예에서, UE는 프리코딩 행렬을 복원하기 위해 기지국에 의해 사용되는 디코더 모델에 액세스할 수 없다. 따라서, UE는 기지국에 의해 사용되는 프리코딩 행렬에 접근하지 못할 수도 있다. 본 명세서에 기술된 일부 추가 실시예에서, UE는 기지국에 의해 사용되는 프리코딩 행렬을 디코더 모델을 사용하여 복원함으로써 프리코딩 행렬을 결정할 수 있다. 다양한 실시예에서, UE는 참조 모델을 훈련함으로써 및/또는 다른 방식으로, 기지국으로부터 디코더 모델을 수신함으로써 디코더 모델을 얻을 수 있다. 이러한 접근 방법은 향상된 성능 및/또는 유연성, 감소된 복잡성 등을 제공할 수 있기 때문에 이전 방법 보다 향상된다."}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "장치는 채널을 이용하여 참조 신호를 수신하도록 구성되는 수신기; 상기 참조 신호에 기초하여 채널 정보를 결 정하고; 제1 기계 학습 모델을 사용하여 상기 채널 정보에 기초하는 표현을 생성하고; 상기 표현에 기초하여, 제2 기계 학습 모델을 사용하여 프리코딩 정보를 생성하고; 상기 프리코딩 정보에 기초하여 채널 품질 정보를 생성하도록 구성된 하나 이상의 프로세서: 및 상기 표현 및 상기 채널 품질 정보를 전송하도록 구성된 송신기를 포함한다. 상기 적어도 하나의 프로세서는 상기 제2 기계 학습 모델을 수신하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 상기 제2 기계 학습 모델을 훈련하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 참 조 모델에 기초하여 제2 기계 학습 모델을 훈련하도록 구성될 수 있다. 상기 채널 정보는 채널 행렬을 포함할 수 있다. 상기 채널 품질 정보는 채널 품질 표시자(CQI)를 포함할 수 있다. 적어도 하나의 프로세서는 상기 표 현과 상기 채널 품질 정보를 결합하도록 구성될 수 있다. 장치는 채널을 이용하여 신호를 수신하는 수신기; 채널에 관련된 채널 정보의 표현을 전송하도록 구성된 송신기; 및 신호에 기초하여 채널 정보를 결정하고, 기계 학습 모델을 사용하여 채널 정보에 기초하여 채널 정 보의 표현을 생성하도록 구성된 적어도 하나의 프로세서를 포함하며, 상기 채널 정보는 제1 부대역에 대한 제1 채널 정보 및 제2 부대역에 대한 제2 채널 정보를 포함할 수 있다. 상기 적어도 하나의 프로세서는 압축을 사용 하여 상기 채널 정보의 표현을 생성하도록 구성될 수 있다. 상기 채널 정보는 채널 품질 정보를 포함할 수 있다. 상기 채널 품질 정보는 이산 값에 기초할 수 있다. 채널 품질 정보는 테이블 값에 기초할 수 있다. 상기 채널 품질 정보는 연속적 값에 기초할 수 있다. 상기 채널 품질 정보는 코드율에 기초할 수 있다. 장치는 채널을 이용하여 신호를 수신하도록 구성되는 수신기; 상기 채널에 관련된 채널 정보의 표현을 전송하도 록 구성되는 송신기; 및 상기 신호에 기초하여 상기 채널 정보를 결정하고; 압축 방식을 사용하여, 적어도 하나 의 기계 학습 모델을 사용하여 상기 채널 정보에 기초하여 상기 채널 정보의 상기 표현을 생성하도록 구성된 하 나 이상의 프로세서를 포함할 수 있다. 상기 적어도 하나의 기계 학습 모델은 공간 압축을 수행하도록 구성된 인코더를 포함할 수 있다. 상기 인코더는 부대역에 대해 공간 압축을 수행하도록 구성될 수 있다. 상기 인코더 는 제1 인코더일 수 있고, 상기 부대역은 제1 부대역일 수 있고, 상기 적어도 하나의 기계 학습 모델은 제2 부 대역에 대해 공간 압축을 수행하도록 구성된 제2 인코더를 포함할 수 있다. 상기 적어도 하나의 기계 학습 모델 은 상기 제1 부대역 및 상기 제2 부대역에 대해 주파수 압축을 수행하도록 구성된 제3 인코더를 포함할 수 있다. 상기 적어도 하나의 기계 학습 모델은 공간 압축 및 주파수 압축을 수행하도록 구성된 인코더를 포함할 수 있다. 상기 인코더는 제1 부대역에 대해 공간 압축 및 주파수 압축을 수행하고 제2 부대역에 대해 공간 압축 및 주파수 압축을 수행하도록 구성될 수 있다. 상기 적어도 하나의 기계 학습 모델은 공간 압축을 사용하여 상 기 채널 정보의 상기 표현을 생성하도록 구성될 수 있다. 상기 적어도 하나의 기계 학습 모델은 주파수 압축을사용하여 상기 채널 정보의 상기 표현을 생성하도록 구성될 수 있다. 상기 적어도 하나의 기계 학습 모델은 공 간 압축 및 주파수 압축을 사용하여 상기 채널 정보의 상기 표현을 생성하도록 구성될 수 있다. 장치는 채널을 이용하여 참조 신호를 수신하는 수신기; 상기 참조 신호에 기초하여 채널 정보를 결정하고; 상기 채널 정보에 기초하여 채널 품질 정보를 생성하고; 기계 학습 모델을 사용하여, 상기 채널 정보와 상기 채널 품 질 정보의 결합 표현을 생성하도록 구성된 하나 이상의 프로세서; 및 상기 결합 표현을 전송하도록 구성된 송신 기를 포함할 수 있다. 상기 채널 정보는 채널 행렬을 포함할 수 있다. 상기 채널 정보는 프리코딩 행렬을 포함 할 수 있다. 적어도 하나의 프로세서는 상기 채널 정보에 기초하여 프리코딩 정보를 생성하고; 상기 프리코딩 정보에 기초하여 상기 채널 품질 정보를 생성하도록 구성될 수 있다. 장치는 채널을 이용하여 신호를 수신하도록 구성된 수신기, 상기 채널에 관련된 채널 정보의 표현을 전송하도록 구성된 송신기, 및 신호에 기초하여 채널의 상태를 결정하고, 기계 학습 모델을 사용하여 채널의 상태에 기초하 여 채널 정보의 표현을 생성하도록 구성된 적어도 하나의 프로세서를 포함한다. 상기 채널 정보는 채널 추정을 포함할 수 있다. 상기 채널 정보는 프리코딩 정보를 포함할 수 있다. 상기 적어도 하나의 프로세서는 기계 학습 모델의 선택을 수행하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 채널의 상태에 기초하여 기계 학습 모델의 선택을 수행하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 수신기를 통해 수신된 모델 식별 정 보에 기초하여 기계 학습 모델을 활성화하도록 구성될 수 있다. 상기 장치는 매체 액세스 제어(MAC) 신호 또는 무선 자원 제어(RRC) 신호 중 하나 이상을 이용하여 모델 식별 정보를 수신하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 송신기를 이용하여 기계 학습 모델의 선택을 지시하도록 구성될 수 있다. 상기 적어도 하나 의 프로세서는 기계 학습 모델을 수신하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 기계 학습 모델에 대응하는 양자화 함수를 수신하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 기계 학습 모델을 훈련하 도록 구성될 수 있다. 적어도 하나의 프로세서는 양자화 함수를 이용하여 기계 학습 모델을 훈련하도록 구성될 수 있다. 상기 양자화 함수는 미분 가능한 양자화 함수를 포함할 수 있다. 상기 양자화 함수는 근사 양자화 함 수를 포함할 수 있다. 상기 적어도 하나의 프로세서는 기계 학습 모델에 대한 구성 정보를 전송하도록 구성될 수 있다. 상기 구성 정보는 하나 이상 또는 가중치나 하이퍼파라미터를 포함할 수 있다. 상기 기계 학습 모델은 생성 모델일 수도 있고, 상기 적어도 하나의 프로세서는 표현에 기초하여 채널 정보를 복원하도록 구성될 수 있 는 복원 모델을 사용하여 생성 모델을 훈련하도록 구성될 수 있다. 상기 생성 모델은 인코더를 포함할 수 있고, 복원 모델은 디코더를 포함할 수 있다. 상기 적어도 하나의 프로세서는 복원 모델에 대한 구성 정보를 수신하고, 구성 정보에 기초하여 생성 모델을 훈련하도록 구성될 수 있다. 상기 구성 정보는 하나 이상 또는 가 중치나 하이퍼파라미터를 포함할 수 있다. 상기 적어도 하나의 프로세서는 생성 모델과 복원 모델의 결합 훈련 을 수행하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 결합 훈련에 기초하여 복원 모델을 전송하도록 구성될 수 있다. 적어도 하나의 프로세서는 채널을 기반으로 기계 학습 모델에 대한 훈련 데이터를 수집하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 자원 윈도우에 기초하여 훈련 데이터를 수집하도록 구성될 수 있다. 자원 윈도우는 시간 차원과 주파수 차원을 갖는다. 채널 정보는 채널 행렬을 포함할 수 있다. 채널 정보 는 특이값과 결합된 특이값 행렬을 포함할 수 있다. 채널 정보는 유니터리 행렬을 포함할 수 있다. 적어도 하나 의 프로세서는 변환된 채널 정보를 생성하기 위해 채널 정보를 전처리하고, 변환된 채널 정보에 기초하여 채널 정보의 표현을 생성하도록 구성될 수 있다. 적어도 하나의 프로세서는 변환에 기초하여 채널 정보를 전처리하고, 훈련 데이터에 기초하여 기계 학습 모델을 훈련시키도록 구성될 수 있으며, 상기 훈련 데이터는 변 환에 기초하여 처리될 수 있다. 상기 적어도 하나의 프로세서는 변환에 기초하여 훈련 데이터를 처리하도록 구 성될 수 있다. 상기 적어도 하나의 프로세서는 처리 허용량을 이용하여 기계 학습 모델을 훈련하도록 구성될 수 있다. 처리 허용량은 처리 시간을 포함할 수 있다. 처리 허용량은 신호를 기반으로 시작될 수 있다. 처리 허용 량은 제어 신호에 기초하여 개시될 수 있다. 제어 신호는 매체 액세스 제어(MAC) 신호 또는 무선 자원 제어 (RRC) 신호 중 하나 이상을 포함할 수 있다. 상기 적어도 하나의 프로세서는 채널 정보의 표현을 링크 제어 정 보로서 전송하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 링크 제어 정보를 업링크 제어 정보(UCI)로 서 전송하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 양자화된 표현을 생성하기 위해 채널 정보의 표 현을 양자화하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 코딩된 표현을 생성하기 위해 양자화된 표 현에 코딩 방식을 적용하도록 구성될 수 있다. 상기 코딩 방식은 폴라 코딩 방식을 포함할 수 있으며, 상기 적 어도 하나의 프로세서는 물리적 제어 채널을 사용하여 코딩된 표현을 전송하도록 구성될 수 있다. 상기 코딩 방 식은 저밀도 패리티 체크(LDPC) 코딩 방식을 포함할 수 있으며, 상기 적어도 하나의 프로세서는 물리적 공유 채 널을 사용하여 상기 코딩된 표현을 전송하도록 구성될 수 있다. 장치는 채널을 사용하여 신호를 전송하도록 구성된 송신기, 상기 채널과 관련된 채널 정보의 표현을 수신하도록 구성된 수신기, 및 기계 학습 모델을 이용하여 표현에 기초하여 채널 정보를 구성하도록 구성된 적어도 하나의프로세서를 포함할 수 있다. 상기 기계 학습 모델은 복원 모델일 수 있으며, 상기 적어도 하나의 프로세서는 채 널 정보의 표현을 생성하도록 구성될 수 있는 생성 모델을 사용하여 복원 모델을 훈련하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 기계 학습 모델을 전송하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 기계 학습 모델에 대응하는 역양자화 함수를 전송하도록 구성될 수 있다. 상기 채널 정보의 표현은 변환된 채널 정보의 표현을 포함할 수 있고, 상기 적어도 하나의 프로세서는 기계 학습 모델의 출력을 후처리하여 변환된 채 널 정보에 기초하여 채널 정보를 구성하도록 구성될 수 있다. 상기 변환된 채널 정보의 표현은 변환에 기초할 수 있으며, 상기 기계 학습 모델은 복원 모델일 수 있고, 상기 적어도 하나의 프로세서는 변환된 채널 정보의 표현을 생성하도록 구성될 수 있는 생성 모델을 사용하여 복원 모델을 훈련하도록 구성될 수 있으며, 상기 적어 도 하나의 프로세서는 변환에 기초하여 처리될 수 있는 훈련 데이터를 사용하여 복원 모델을 훈련하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 기계 학습 모델의 선택을 수행하고, 송신기를 이용하여 기계 학습 모 델의 선택을 지시하도록 구성될 수 있다. 방법은 무선 장치에서, 무선 장치에 대한 물리 계층 정보를 결정하는 단계, 기계 학습 모델을 사용하여 물리 계 층 정보의 표현을 생성하는 단계, 및 무선 장치로부터 물리 계층 정보의 표현을 전송하는 단계를 포함한다. 상 기 기계 학습 모델은 생성 모델일 수 있고, 상기 방법은 표현에 기초하여 물리 계층 정보를 복원하도록 구성될 수 있는 복원 모델을 사용하여 생성 모델을 훈련하는 단계를 더 포함한다. 상기 방법은 무선 장치가 자원 윈도 우에 기초하여 기계 학습 모델에 대한 학습 데이터를 수집하는 단계를 더 포함할 수 있다. 상기 물리 계층 정보 는 채널 행렬을 포함할 수 있다. 상기 방법은 상기 물리계층 정보를 전처리하여 변환된 물리계층 정보를 생성하 는 단계, 및 변환된 물리 계층 정보에 기초하여 물리 계층 정보의 표현을 생성하는 단계를 더 포함할 수 있다. 생성하는 단계는 처리 허용량에 따라 수행될 수 있다. 상기 방법은 상기 무선장치에서 수신된 모델 식별정보에 기초하여 기계학습 모델을 활성화하는 단계를 더 포함할 수 있다. 상기 물리 계층 정보의 표현은 업링크 제어 정보를 포함할 수 있다."}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 상세한 설명에서, 본 개시의 완전한 이해를 제공하기 위해 다수의 특정 세부 사항이 설명된다. 그러나, 당 업자라면 개시된 측면은 이러한 특정 세부 사항 없이 실시될 수 있다는 것이 이해될 것이다. 다른 예에서, 잘 알려진 방법, 절차, 구성 요소 및 회로는 본 명세서에 개시된 본 개시을 모호하게 하지 않기 위해 상세하게 설 명되지 않았다. 본 명세서 전반에 걸쳐 \"일 실시 예\" 또는 \"실시 예\"에 대한 언급은 실시 예와 관련하여 설명된 특정 특징, 구 조 또는 특성이 본 명세서에 개시된 적어도 하나의 실시 예에 포함될 수 있음을 의미한다. 따라서, 본 명세서 전반에 걸쳐 다양한 곳에서 \"일 실시 예에서\" 또는 \"실시 예에서\" 또는 \"일 실시 예에 따른\" (또는 유사한 의미 를 갖는 다른 어구)의 언급은 반드시 모두 동일한 실시 예를 지칭하는 것은 아닐 수 있다. 또한, 특정 특징, 구 조 또는 특성은 하나 이상의 실시 예에서 임의의 적절한 방식으로 결합될 수 있다. 이와 관련하여, 본 명세서에 서 사용된 바와 같이, \"예시적인\"이라는 단어는 \"예시, 실례 또는 예시로서의 역할을 한다\"를 의미한다. 본 명 세서에서 \"예시적인\" 것으로 설명된 임의의 실시 예는 다른 실시 예에 비해 반드시 바람직하거나 유리한 것으로 해석되어서는 안된다. 추가로, 특정 특징, 구조 또는 특성은 하나 이상의 실시 예에서 임의의 적절한 방식으로 결합될 수 있다. 또한, 본 명세서에서 논의한 내용에 따라, 단수형 용어는 대응하는 복수형을 포함할 수 있고 복수형 용어는 대응하는 단수형을 포함할 수 있다. 유사하게, 하이픈으로 연결된 용어(예를 들어, \"2-차원\", \" 미리-결정된\", \"픽셀-특정\" 등)는 때때로 해당하는 하이픈 없는 버전(예를 들어 \"2차원\", \"미리 결정된\", \"픽셀 특정\" 등)과 상호 교환적으로 사용될 수 있으며, 대문자 항목(예를 들어, \"Counter Clock\", \"Row Select\", \"PIXOUT\" 등)은 해당하는 비 대문자 버전(예를 들어, \"counter clock\", \"row select\", \"pixout\" 등)과 상호 교 환적으로 사용될 수 있다. 이러한 상호 교환하여 사용하는 것을 서로 불일치하다고 간주해서 안된다. 또한, 본 명세서의 문맥에 따라, 단수형은 대응하는 복수형을 포함할 수 있고, 복수형은 대응하는 단수형을 포 함할 수 있다. 본 명세서에 도시되고 논의된 다양한 도면(구성 요소도 포함함)은 단지 예시를 위한 것으로, 비 율대로 그련지는 것은 아니라는 것에 유의한다. 예를 들어, 일부 요소의 치수는 명확하게 하기 위해 다른 요소 에 비해 과장될 수 있다. 또한, 적절하다고 간주되는 경우, 도면간에 참조 번호가 반복되어 대응 및/또는 유사 한 요소를 표시한다. 본 명세서에서 사용된 용어는 일부 예시적인 실시 예를 설명하기 위한 것이며 청구된 본 개시의 요지를 제한하 려는 것은 아니다. 본 명세서에서 사용된 바와 같이, 단수 형태는 문맥 상 명백하게 달리 나타내지 않는 한 복 수 형태도 포함하는 것이다. 본 명세서에서 사용될 때 \"포함하다\" 및/또는 \"포함하는\" 이라는 용어는 언급된 특 징, 정수, 단계, 연산, 요소 및/또는 구성 요소의 존재를 명시하지만, 하나 이상의 다른 특징, 정수, 단계, 연산, 요소, 구성 요소 및/또는 그 그룹의 존재 또는 추가를 배제하지 않는다는 것이 이해될 것이다. 하나의 요소 또는 층이 다른 요소 또는 층에 \"연결되거나\" \"결합되는\" 것으로 언급될 때, 다른 요소 또는 층에 대해 바로 위에 있거나, 연결되거나 결합될 수 있거나, 중간 요소 또는 층이 존재할 수도 있다. 대조적으로, 하 나의 요소가 다른 요소 또는 층의 \"바로 위에 있거나\", \"직접 연결되거나\", \"직접 결합되는\" 것으로 언급될 때, 중간 요소 또는 층이 존재하지 않는다. 동일한 숫자는 전체에 걸쳐 동일한 요소를 나타낸다. 본 명세서에서 사 용되는 용어 \"및/또는\"은 하나 이상의 연관된 열거된 항목의 임의의 및 모든 조합을 포함한다. 본 명세서에서 사용되는 용어 \"제1\", \"제2\" 등은 명사에 선행하는 라벨로 사용되며, 명시적으로 정의하지 않는 한, 어떤 유형의 순서(예를 들어, 공간적, 시간적, 논리적 등)도 암시하지 않는다. 또한, 동일하거나 유사한 기 능을 갖는 부품, 구성 요소, 블록, 회로, 유닛 또는 모듈을 지칭하기 위해 동일한 참조 번호가 둘 이상의 도면 에 걸쳐 사용될 수 있다. 그러나 이러한 사용법은 설명의 단순성과 논의의 용이성을 위한 것이고; 그러한 구성 요소 또는 유닛의 구조 또는 구조적 세부 사항이 모든 실시 예에 걸쳐 동일하거나 일반적으로 참조되는 부품/모 듈이 본 명세서에 개시된 예시적인 실시 예의 일부를 구현하는 유일한 방법이라는 것을 의미하지는 않는다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함하여 본 명세서에서 사용되는 모든 용어는 이 주 제가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 갖는다. 일 반적으로 사용되는 사전에 정의된 것과 같은 용어는 관련 기술의 맥락에서 그 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며 본 명세서에서 명확하게 정의되지 않는 한 이상화되거나 지나치게 형식적인 의미로 해석 되지 않는다는 것이 이해될 것이다. 본 명세서에서 사용되는 용어 \"모듈\"은 모듈과 관련하여 본 명세서에 설명된 기능을 제공하도록 구성된 소프트 웨어, 펌웨어 및/또는 하드웨어의 임의의 조합을 지칭한다. 예를 들어, 소프트웨어는 소프트웨어 패키지, 코드 및/또는 명령어 세트 또는 명령어로 구현될 수 있으며, 본 명세서에 설명된 임의의 구현에서 사용되는 용어 \"하 드웨어\"는 예를 들어, 단일 또는 임의의 조합으로, 어셈블리, 하드 와이어드 회로, 프로그래밍 가능 회로, 상태 기계 회로 및/또는 프로그래밍 가능 회로에 의해 실행되는 명령어를 저장하는 펌웨어를 포함할 수 있다. 모듈은 집합적으로 또는 개별적으로, 예를 들어, 집적 회로(IC), 시스템 온칩(SoC), 어셈블리 등과 같은 더 큰 시스템 의 일부를 형성하는 회로로 구현될 수 있다. 개론 일부 무선 통신 시스템에서, 전송 디바이스는 전송 디바이스가 채널을 통해 수신 디바이스에 보다 효과적으로 전송할 수 있도록 하기 위해 채널 조건에 대한 피드백 정보를 제공하기 위해 수신 디바이스에 의존할 수 있다. 예를 들어, 5G 뉴라디오(NR) 시스템에서, 기지국(예를 들어, gNodeB 또는 gNB)은 다운링크(DL) 채널을 통해 참 조 신호를 사용자 장치(UE)로 전송할 수 있다. UE는 DL 채널에 대한 채널 상태를 결정하기 위해 참조 신호를 측 정할 수 있다. 그런 다음, UE는 업링크(UL) 채널을 통해 DL 채널 상의 채널 상태를 나타내는 피드백 정보(예를 들어, 채널 상태 정보(CSI))를 기지국으로 전송할 수 있다. 기지국은 피드백 정보를 사용하여 DL 채널을 통해, 예를 들어 빔포밍을 사용하여 UE에 전송하는 방식을 개선할 수 있다. 그러나, 채널 상태에 대한 피드백 정보를 전송하는 것은 오버헤드로서 비교적 많은 양의 자원을 소모할 수 있다. 피드백 정보를 전송하는 데 사용되는 데이터의 양을 줄이기 위해, 일부 무선 통신 시스템은 수신 디바이 스가 묵시적 및/또는 명시적 채널 조건 피드백을 전송 디바이스에 보낼 수 있도록 하기 위해 하나 이상의 유형 의 코드북을 사용할 수 있다. 예를 들어 5G NR 시스템에서, 유형 I 코드북은 DL 채널 조건에 기초하여 UE에 의 해 선택된 미리 정의된 프리코딩 행렬 표시자(PMI)를 가리킬 수 있는 인덱스의 형태로 gNB에 암시적 CSI 피드백 을 제공하는 데 사용될 수 있다. 그러면 gNB는 DL 채널에서 빔포밍을 위해 PMI를 사용할 수 있다. 다른 예로, 유형 II 코드북은 UE가 DL 채널에서 빔포밍을 위해 PMI를 사용할 수 있는 gNB에 피드백될 수 있는 PMI를 유도할 수 있는 명시적 CSI 피드백을 제공하는 데 사용될 수 있다. 그러나 유형 I 코드북을 사용하게 되면 적절한 정확 도로 CSI 피드백을 제공하지 못할 수 있다. 또한, 유형 II 코드북을 사용하게 되면 UL 채널 상에서 상당한 양의 오버헤드 데이터의 전송을 여전히 수반할 수 있다. 본 개시에 따른 피드백 방식은 인공 지능(AI), 기계 학습(ML), 딥 러닝 등(이 중 일부 또는 전부는 개별적으로 및/또는 집합적으로 기계 학습 또는 ML로 지칭될 수 있음)을 사용하여 무선 통신 시스템에 대한 물리 계층 정보 의 표현을 생성할 수 있다. 예를 들어, 일부 실시 예에서, 피드백 방식은 채널 조건에 대한 피드백 정보의 표현 (예를 들어, 채널 행렬, 프리코딩 행렬 등의 표현)을 생성하기 위해 ML 모델을 사용할 수 있다. 표현은 피드백 정보의 압축, 인코딩 또는 그렇지 않으면 수정된 형태일 수 있으며, 이는 구현 세부 사항에 따라 장치 사이에서피드백 정보를 전송하는 데 관련된 자원을 줄일 수 있다. 본 개시에 따른 피드백 방식은 또한 기계 학습을 사용하여 표현으로부터 물리 계층 정보를 복원할 수 있다. 예 를 들어, 일부 실시 예에서, 피드백 방식은 ML 모델을 사용하여 채널 조건에 대한 피드백 정보의 표현으로부터 피드백 정보, 또는 피드백 정보의 근사치를 복원할 수 있다. 편의상, ML 모델을 간단히 모델이라고 칭할 수 있 다. 입력의 표현(representation of input)(예를 들어, 채널 조건에 대한 피드백 정보와 같은 물리 계층 정보)을 생 성하는 모델은 생성 모델로 지칭될 수 있다. 입력의 표현으로부터 입력 또는 입력의 근사를 복원하는 모델은 복 원 모델로 지칭될 수 있다. 복원 모델의 출력은 복원된 입력으로 지칭될 수 있다. 따라서 복원된 입력은 생성 모델에 적용된 입력이거나 생성 모델에 적용된 입력의 근사, 추정, 예측 등이 될 수 있다. 생성 모델과 해당 복 원 모델은 한 쌍의 ML 모델 또는 한 쌍의 모델로 통칭될 수 있다. 일부 실시 예에서, 생성 모델은 인코더 모델 로 구현될 수 있고/있거나 복원 모델은 디코더 모델로 구현될 수 있다. 따라서 인코더 모델 및 디코더 모델은 한 쌍의 ML 모델 또는 한 쌍의 모델이라고도 할 수 있다. 임의의 모델은 하나 이상의 다른 모델과 모델을 구별하기 위해 제1 모델, 제2 모델, 모델 A, 모델 B 등으로 지 칭될 수 있으며, 모델에 사용된 레이블은 문맥에서 달리 명백하지 않는 한 모델의 유형을 암시하는 것은 아니다. 예를 들어, 한 쌍의 모델과 관련하여, 모델 A가 생성 모델을 참조한다면, 모델 B는 복원 모델을 참조할 수 있다. 노드는 기지국, UE, 또는 본 명세서에 개시된 바와 같은 하나 이상의 ML 모델을 사용할 수 있는 임의의 다른 장 치를 지칭할 수 있다. 노드의 추가 예는 논리적 노드, 물리 노드, 또는 이들의 조합이든지. UE 측 서버, 기지국 측 서버(예를 들어, gNB 측 서버), eNodeB, 마스터 노드, 보조 노드 등을 포함할 수 있다. 임의의 노드는 노드 를 하나 이상의 다른 노드와 구별하기 위해 제1 노드, 제2 노드, 노드 A, 노드 B 등으로 지칭될 수 있으며, 문 맥상 다르게 명백하지 않는 한 노드에 사용된 레이블은 노드 유형을 의미하지 않는다. 예를 들어, 일부 실시 예 에서, 제1 노드는 UE를 지칭할 수 있고 제2 노드는 기지국을 지칭할 수 있다. 그러나 일부 다른 실시 예에서, 제1 노드는 제1 UE를 지칭할 수 있고, 제2 노드는 제1 UE와의 사이드링크 통신을 위해 구성된 제2 UE를 지칭할 수 있다. 일부 예시적인 실시 예에서, 제1 노드는 제2 노드에 전송될 수 있는 특징 벡터를 생성하기 위해서, 채널 행렬, 프리코딩 행렬 등을 인코딩하는 제1 모델(예를 들어, 생성 모델)을 사용할 수 있다. 제2 노드는 원본 정보(예를 들어, 채널 행렬, 프리코딩 행렬 등) 또는 원본 정보의 근사를 복원하기 위해 특징 벡터를 디코딩하는 제2 모델 (예를 들어, 복원 모델)을 사용할 수 있다. 본 개시에 따른 일부 실시 예는 모델이 쌍으로 훈련될 수 있는 2-모델 훈련 방식을 구현할 수 있다. 예를 들어, 복원 모델은 생성 모델을 훈련하는 데 사용될 수 있고/있거나 생성 모델은 복원 모델을 훈련하는 데 사용될 수 있다. 일부 예시적인 구현에서, 한 쌍의 모델은 (예를 들어, 제1 노드에 대한) 인코더 모델이 (예를 들어, 제2 노드에 대한) 디코더 모델로 훈련될 수 있는 자동 인코더를 구현하도록 구성될 수 있다. 일부 실시 예에서, 제1 노드에 의한 추론에 사용될 수 있는 제1 모델(예를 들어, 생성 모델)은 제2 노드에 의한 추론을 위해 실제로 사용될 수 있는 제2 모델(예를 들어, 복원 모델)을 사용하여 훈련될 수 있다. 훈련은 예를 들어, 모델을 훈련(예를 들어, 오프라인)하고 추론에 사용하도록 훈련된 모델 중 하나 이상을 노드 중 하나 이 상으로 전송할 수 있는 서버에 의해, 제1 노드, 제2 노드 및/또는 임의의 다른 장치에 의해 수행될 수 있다. 대안적으로, 또는 추가적으로, 제2 모델이 제2 노드에 의해 추론에 사용될 수 있는 실제 모델이 아니더라도, 제 1 모델은 제1 모델과 제2 모델 사이에 어느 정도의 매칭을 제공할 수 있는 제2 모델을 사용하여 훈련될 수 있다. 대안적으로, 또는 추가적으로, 제1 모델은 제2 모델에 대한 참조 모델을 사용하여 훈련될 수 있다. 대안 적으로, 또는 추가적으로, 제1 모델은 미리 결정된 값, 무작위 값 등으로 초기화될 수 있는 가중치, 하이퍼매개 변수 등의 값으로 구성될 수 있는 제2 모델을 사용하여 훈련될 수 있다. 일부 실시 예에서, 한 쌍의 모델은 동일하거나 상이한 훈련 데이터 세트를 사용하여, 동시에, 순차적(예를 들어, 제2 모델을 고정하는 동안 제1 모델을 훈련하고, 다음에 제1 모델을 고정하는 동안 제2 모델을 훈련하는 것을 번갈아 가며) 등으로 훈련될 수 있다. 일부 실시 예에서, 노드는 양자화기를 사용하여 물리 계층 정보의 표현을 통신 채널을 통해 더 쉽게 전송될 수 있는 형태로 변환할 수 있다. 예를 들어, 양자화기는 물리 계층 정보의 실수(예를 들어, 정수) 표현을 물리 업 링크 또는 다운링크 채널을 통한 전송을 위해 극성 인코더 또는 그 외 장치에 적용될 수 있는 이진 비트 스트림으로 변환할 수 있다. 비슷하게, 노드는 비트스트림을 물리 계층 정보를 복원하는데 사용될 수 있는 물리 계층 정보의 표현으로 변환하기 위해 역양자화기를 사용할 수 있다. 일부 실시 예에서, 양자화기 또는 역양자화기는 ML 모델의 일부로 간주될 수 있다. 예를 들어, 생성 모델은 인코더 및 해당 양자화기를 포함할 수 있고/있거나, 복원 모델은 대응하는 역양자화기를 포함할 수 있다. 본 개시에 따른 일부 실시 예는 모델을 훈련 및/또는 노드 간에 모델을 전송하기 위한 하나 이상의 프레임워크 를 구현할 수 있다. 예를 들어, 제1 유형의 프레임워크에서, 제1 노드(노드 A)는 한 쌍의 모델(모델 A 및 모델 B)을 공동으로 훈련할 수 있다. 노드 A는 훈련된 모델 A를 추론에 사용할 수 있고 훈련된 모델 B를 추론에 훈련 된 모델 B를 사용할 수 있는 제2 노드(노드 B)로 전달할 수 있다. 제1 유형의 프레임워크의 변형에서, 노드 A는 훈련된 모델 A를 노드 B로 전달할 수 있으며, 노드 B는 훈련된 모델 A를 사용하여 추론에 사용하도록 자체 모델 B를 훈련할 수 있다. 제2 유형의 프레임워크에서, 참조 모델은 노드 A에 대한 모델 A로 설정되고 노드 B는 모델 A로 참조 모델을 사 용하여 모델 B를 훈련할 수 있다(예를 들어, 노드 A가 참조 모델을 추론을 위해 모델 A로 사용한다고 가정). 그 런 다음 노드 A는 추가 훈련 없이 참조 모델을 모델 A로 사용하거나, 노드 A는 모델 A로 사용하도록 참조 모델 을 훈련할 수 있다. 일부 실시 예에서, 다수의 참조 모델이 모델 A에 대해 설정될 수 있고, 노드 B는 모델 A에 대한 참조 모델 중 하나 이상에 해당하는 모델 B의 하나 이상의 버전을 훈련할 수 있다. 모델 A에 대한 다수의 참조 모델이 있는 실시 예에서, 노드 B는 모델 A에 대한 다수의 참조 모델을 기반으로 하나 이상의 모델 B 버전 을 훈련할 수 있고, 노드 B는 사용을 위해 모델 B의 어느 버전을 선택하여 사용할지 모델 B의 어떤 버전이 최고 의 성능을 제공하는지 등을 노드 A에 표시한다. 노드 B의 표시에 따라, 노드 A는 노드 B가 지시하는 모델 B에 해당하는 참조 모델을 진행할 수 있거나, 노드 A는 모델 A로 사용할 다른 모델을 선택할 수 있다. 제3 유형의 프레임워크에서, 노드 A는 예를 들어 사전 훈련된(예를 들어, 오프라인으로 훈련된), 훈련되지 않았 지만 초기 값으로 구성된 등의 임의의 초기 상태에 있을 수 있는 모델 A로 시작할 수 있다. 노드 B는 초기 상태 에 있을 수도 있는 모델 B로 시작할 수 있다. 일부 실시 예에서, 그들 자신의 모델을 훈련시키기 전에, 노드 A 및/또는 노드 B는 서로 매칭되는 (예를 들어, 함께 훈련되는) 모델을 가질 수 있다. 하나 또는 두 개의 노드는 일정 기간 동안 각자의 모델을 훈련할 수 있으며, 다음에 하나 또는 두 개의 노드는 훈련된 모델 값 및/또는 훈 련된 모델을 다른 노드와 공유할 수 있다. 예시적인 실시 예는 제1 노드(예를 들어, UE) 및 제2 노드(예를 들어, 기지국)가 한 쌍의 모델(e0,d0)을 가지고 있는 도 10과 관련하여 아래에 더 상세히 설명되며, 여기서 e0은 UE에서 초기 상태의 인코더 모델일 수 있고 d0은 기지국에서 초기 상태의 디코더 모델일 수 있다. 제3 유형의 프레임워크의 변형에서, 하나 또는 두 노드는 하나 이상의 추가 기간 동안 각각의 모델을 훈련할 수 있으며, 하 나 또는 두 노드는 예를 들어, 각 기간의 종료시, 교대하는 기간의 종료시, 및/또는 이와 유사한 때에, 훈련된 모델 값 및/또는 훈련된 모델을 다른 노드와 공유할 수 있다. 본 명세서에 개시된 임의의 프레임워크에서, 모델이 노드로 또는 노드로부터 전송될 때, 대응하는 양자화기 또 는 역양자화기가 이 모드와 함께 전송될 수 있다. 일부 실시 예에서, 훈련 데이터는 자원 윈도우(예를 들어, 시간 및/또는 주파수 자원의 윈도우)에 기초하여 수 집될 수 있다. 예를 들어, 노드는 특정 범위의 주파수(예를 들어, 부반송파, 부대역 등) 및 특정 시간 범위(예 를 들어, 심볼, 슬롯 등)에 대한 훈련 데이터(예를 들어, 채널 추정치)를 수집하도록 구성될 수 있다. 윈도우의 크기는, 예를 들어, 노드가 메모리에 저장할 수 있는 훈련 데이터의 양에 기초하여 결정될 수 있다. 수집된 훈 련 데이터는 하나 이상의 노드에서 온라인 훈련에 사용하거나 오프라인 훈련을 위해 저장할 수 있다. 일부 실시 예에서, 사전 처리 및/또는 사후 처리는 한 쌍의 모델이 보다 효과적으로 작동하는 것을 가능하게 할 수 있다. 예를 들어, 하나 이상의 입력의 도메인 지식(예를 들어, 주파수 도메인 지식)은 하나 이상의 변환된 입력을 생성하기 위해 하나 이상의 입력의 적어도 일부에 대한 사전 처리 연산을 수행하는 데 사용될 수 있다. 하나 이상의 변환된 입력은 하나 이상의 변환된 입력의 표현을 생성하기 위해 생성 모델에 적용될 수 있다. 하 나 이상의 변환된 입력의 표현은 복원된 변환된 입력(예를 들어, 하나 이상의 변환된 입력, 또는 그 근사)을 생 성할 수 있는 복원 모델에 적용될 수 있다. 도메인 지식은 또한 원래의 하나 이상의 입력 또는 그 근사를 복구 하기 위해 복원된 변환된 입력에 대한 사후 처리 동작(예를 들어, 사전 처리 동작의 역)을 수행하는 데 사용될 수 있다. 구현 세부 사항에 따라, 변환 입력 및/또는 출력(예를 들어, 도메인 지식 기반)은 하나 이상의 입력 요소 간의 하나 이상의 상관 관계를 활용할 수 있으며, 이에 의해 생성 모델 및/또는 복원 모델의 처리 부담, 메모리 사용, 전력 소비 등을 감소시킬 수 있다.일부 실시 예에서, 노드에는 모델에 대한 처리 시간이 제공될 수 있다. 예를 들어, 노드가 (예를 들어, 노드에 제공되거나 노드에 의해 수집되는 훈련 데이터 세트를 사용하여) 모델의 온라인 훈련을 수행하도록 구성된 경우, 노드는 미리 결정된 심볼 수 또는 그 외 시간 측정 내에서 모델을 업데이트할 것으로 예상될 수 있다. 본 개시에 따른 일부 실시 예는 모델의 다수의 모델 쌍이 하나 이상의 노드(예를 들어, 한 쌍의 노드)에 의한 사용을 위해 훈련, 전개 및/또는 활성화될 수 있는 방식을 구현할 수 있다. 예를 들어, 상이한 훈련된 모델 쌍 은 (예를 들어, 채널 행렬, 프리코딩 행렬 등의 경우) 상이한 채널 환경, 상이한 행렬 차원 등을 처리하도록 활 성화될 수 있다. 일부 실시 예에서, 한 쌍의 모델은 시그널링(예를 들어, RRC 시그널링, MAC-CE 시그널링 등)에 의해 활성화될 수 있다. 일부 실시 예에서, 제1 노드(예를 들어, gNB)는 또한 예를 들어 RRC, MAC CE 또는 동적 시그널링을 통해 현재 활성 모델을 전환하거나 비활성화하도록 제2 노드(예를 들어, UE)에 지시할 수 있다. 한 쌍의 모델은 모델 중 하나 이상을 훈련하고, 추론에 모델 중 하나 이상을 사용하는 등을 위해 활성화될 수 있다. 본 개시에 따른 일부 실시 예는 제1 노드에서 생성 모델에 의해 생성될 수 있고 복원을 위해 제2 노드로 전송될 수 있는 피드백 정보의 표현을 위한 하나 이상의 포맷을 구현할 수 있다. 예를 들어, 피드백 정보의 표현을 위 한 포맷은 업링크 제어 정보(UCI)의 일종으로 설정될 수 있다. 포맷은 예를 들어 UCI를 전송하는 데 사용되는 물리 채널의 유형에 따라 달라질 수 있는 하나 이상의 유형의 코딩(예를 들어, 극성 코딩, 저밀도 패리티 체크 (LDPC) 코딩 등)을 포함할 수 있다. 일부 실시 예에서, CSI 압축 성능은 예를 들어, 시간, 주파수 및/또는 공간 도메인에서 하나 이상의 상관 관계 를 활용함으로써, 및/또는 시간, 빈도 및/또는 공간에 걸쳐 훈련 데이터 세트를 정의함으로써, AI 및/또는 ML을 사용하여 개선될 수 있다. 본 개시에 따른 일부 실시 예는 제1 노드(예를 들어, UE)가 제2 노드(예를 들어, 기지국)에 의해 사용될 수 있 는 프리코딩 정보를 결정하는 것을 가능하게 할 수 있다. 프리코딩 정보는 예를 들어, 프리코딩 정보가 사용될 수 있는 채널에 대한 채널 품질 정보를 결정하는 데 사용될 수 있다. 구현 세부 사항에 따라, 제1 노드가 제2 노드에 의해 사용되는 프리코딩 정보를 결정하는 것이 가능하게 되면 프리코딩 정보와 프리코딩 정보에 기초하 여 결정될 수 있는 채널 품질 정보 사이의 불일치를 감소시키거나 제거할 수 있다. 예를 들어, 기지국은 기지국 에 의해 사용되는 프리코딩 행렬을 결정하기 위해 모델을 사용할 수 있는 UE와 디코더 모델을 공유할 수 있다. 또 다른 예로, UE는 기지국에 의해 사용되는 프리코딩 행렬을 복원하기 위해 디코더(예를 들어, 아래 설명되는 기준 디코더)를 훈련시킬 수 있다. 본 개시에 따른 일부 실시 예에서, 한 쌍의 인코더 및 디코더 모델은 채널 정보와 채널 품질 정보 사이의 불일 치를 줄이거나 제거하기 위해 채널 정보(예를 들어, CQI)에 기초하여 결정될 수 있는 채널 품질 정보 및 채널 정보(예를 들어, 채널 행렬, 프리코딩 행렬 등)를 공동으로 압축하도록 훈련될 수 있다. 예를 들어, 인코더 및 디코더는 대응하는 채널 품질 정보와 일치할 수 있는 프리코딩 정보를 포함할 수 있는 훈련 데이터 세트로 훈련 될 수 있다. 구현 세부 사항에 따라, 이는 프리코딩 정보(예를 들어, 프리코딩 행렬)와 프리코딩 정보에 기초하 여 결정될 수 있는 채널 품질 정보(예를 들어, CQI) 사이의 불일치를 줄이거나 제거할 수 있다. 본 개시에 따른 일부 실시 예는 하나 이상의 부대역에 걸쳐 채널 정보를 압축하기 위해 하나 이상의 기계 학습 모델을 사용할 수 있다. 예를 들어, 제1 노드는 다수의 부대역에 대한 채널 정보(예를 들어, 채널 품질 정보)를 벡터로 결합(예를 들어, 연결)하고 벡터를 압축함으로써 다수의 부대역에 대한 채널 정보의 표현을 생성하기 위 해 인코더 모델을 사용할 수 있다. 제2 노드는 표현으로부터 다수의 부대역에 대한 채널 정보를 복원하기 위해 디코더를 사용할 수 있다. 구현 세부 사항에 따라, 하나 이상의 부대역에 걸쳐 채널 정보를 압축하게 되면 성능 이 향상되고 복잡성이 줄어들 수 있다. 본 개시에 따른 일부 실시 예는 일부 구현에서 프리코딩 정보를 포함할 수 있는 채널 정보의 표현을 생성하고 및/또는 이를 보고하기 위한 하나 이상의 압축 방식을 구현하기 위해 하나 이상의 디코더 모델을 사용할 수 있 다. 구현 세부사항에 따라, 이러한 실시 예는 향상된 성능 및/또는 유연성, 감소된 복잡성 등을 제공하면서 코 드북 방식을 모방할 수 있다. 일부 예시적인 실시 예에서, 한 쌍의 기계 학습 모델(예를 들어, 인코더 및 디코 더)은 채널 정보로부터 프리코딩 정보를 생성하도록 구성 및/또는 훈련될 수 있다. 예를 들어, 제1 노드(예를 들어, UE)는 압축 방식을 사용하여 채널 정보에 기초한 표현(예를 들어, 코드워드)을 생성할 수 있는 인코더에 채널 정보(예를 들어, 하나 이상의 참조 신호 측정치)를 적용할 수 있다. 제2 노드(예를 들어, 기지국)는 상기 표현에 기초하는 프리코딩 정보(예를 들어, 프리코딩 행렬)를 구성할 수 있는 디코더에 상기 표현을 적용할 수 있다. 다른 예시적인 실시 예에서, 한 쌍의 기계 학습 모델은 채널 상태 정보(예를 들어, 채널 품질 정보), 프리코딩 정보(예를 들어, 프리코딩 행렬), 순위 정보 등과 같은 모든 유형의 정보를 입력으로 수신하고, 하나 이 상의 압축 방식을 적용하고, 프리코딩 정보를 결정하는 데 사용될 수 있는 모든 유형의 정보를 출력으로 제공할 수 있다. 하나 이상의 압축 방식을 구현하기 위해 하나 이상의 디코더 모델을 사용할 수 있는 일부 실시 예는, 공간 압축, 주파수 압축, 공간 압축과 주파수 압축의 조합 등을 제공할 수 있다. 구현 세부 사항에 따라, 압축 방식 은 개별 부대역에 대한 개별 압축, 개별 부대역에 대한 결합 압축, 및/또는 이들의 조합을 제공할 수 있다. 예를 들어, 제1 노드(예를 들어, UE)는 하나 이상의 부대역에 대한 채널 정보의 하나 이상의 표현(예를 들어, 별도의 표현)을 생성하기 위해 하나 이상의 부대역에 대한 채널 정보를 공간적으로 압축하기 위해 하나 이상의 인코더를 사용할 수 있다. 제2 노드(예를 들어, 기지국)는 (예를 들어, 하나 이상의 별도의 표현을 사용하여) 하나 이상의 부대역에 대한 채널 정보를 복구하기 위해 하나 이상의 디코더를 사용할 수 있다. 또 다른 예로서, 제1 노드는 하나 이상의 부대역에 대한 채널 정보의 하나 이상의 표현(예를 들어, 단일 표현) 을 생성하기 위해서 하나 이상의 부대역에 대한 채널 정보에 대해 별도의 공간 압축 및 결합된 주파수 압축을 제공하기 위해 하나 이상의 공간 인코더 및 하나 이상의 주파수 인코더를 사용할 수 있다. 제2 노드는 하나 이 상의 표현으로부터 별도의 공간 압축해제 및 결합된 주파수 압축해제를 사용하여 하나 이상의 부대역에 대한 채 널 정보를 복구하기 위해 하나 이상의 공간 디코더 및 하나 이상의 주파수 디코더를 사용할 수 있다. 추가 예로서, 제1 노드는 하나 이상의 부대역에 대한 채널 정보의 결합된 표현을 생성하기 위해 하나 이상의 부 대역에 대한 채널 정보의 결합된 공간 및 주파수 압축을 제공하기 위해 결합 공간 및 주파수 인코더를 사용할 수 있다. 제2 노드는 결합된 표현으로부터 하나 이상의 부대역에 대한 채널 정보를 복구하기 위해 공동 공간 및 주파수 디코더를 사용할 수 있다. 따라서, 일부 실시 예에서, 디코더 모델은 하나 이상의 디코더 모델을 지칭할 수 있고, 인코더 모델은 하나 이 상의 인코더 모델을 지칭할 수 있고, 모델 쌍은 하나 이상의 디코더 모델 및 하나 이상의 인코더 모델을 지칭할 수 있다. 구현 세부 사항에 따라, 프리코딩 정보, 및/또는 프리코딩 정보를 결정하는 데 사용될 수 있는 다른 정보를 생 성하기 위해 하나 이상의 디코더 모델을 사용하는 실시 예는 성능 및/또는 유연성의 향상, 복잡성의 감소 등을 제공할 수 있다. 본 개시는 통신 시스템의 물리 계층에 대한 인공 지능 및 기계 학습에 관한 많은 발명 원리를 포함한다. 이러한 원리는 독립적인 유용성을 가지며 개별적으로 구현될 수 있으며, 모든 실시 예가 모든 원리를 활용할 수 있는 것은 아니다. 또한 원리는 다양한 조합으로 구현될 수 있으며, 그 중 일부는 시너지 방식으로 개별 원칙의 이점 을 증폭시킬 수 있다. 예시를 위해, 일부 실시 예는 5G NR 시스템에서, 하나 이상의 UE, 기지국(예를 들어, gNB) 등 사이에서 채널 피 드백 정보를 압축, 압축해제 및/또는 전송하는 것과 같은, 일부 특정 구현 세부사항 및/또는 애플리케이션의 맥 락에서 설명될 수 있다. 하지만, 본 발명의 원리는 이러한 세부 사항 및/또는 애플리케이션으로 제한되지 않으 며 물리 계층 정보가 장치 중 임의의 것이 기지국, UE, 피어 디바이스 등인지에 관계없이, 및 채널이 UL 채널, DL 채널, 피어 채널 등인지에 관계없이 처리 및/또는 무선 장치 간에 전송될 수 있는 임의의 다른 컨텍스트에 적용될 수 있다. 더욱이, 본 발명의 원리는 다른 유형의 셀룰러 네트워크(예를 들어, 4G LTE, 6G 및/또는 미래 세대의 셀룰러 네트워크), 블루투스, Wi-Fi 등과 같은 물리 계층 정보를 처리 및/또는 교환할 수 있는 모든 유 형의 무선 통신 시스템에 적용될 수 있다. 물리 계층을 위한 기계 학습 모델 도 1은 본 개시에 따른 무선 통신 장치의 실시 예를 도시한다. 장치는 입력으로서 물리 계층 정보를 수신하고 출력으로서 물리 계층 정보의 표현을 생성할 수 있는 기계 학습 모델을 포함할 수 있다. 일부 구현에서, 장치는 화살표에 의해 도시된 바와 같 이 물리 계층 정보의 표현을 하나 이상의 다른 장치에 전송할 수 있다. 물리 계층 정보의 표현은 물리 계층 정보의 압축, 인코딩, 암호화, 매핑, 또는 다르게 수정된 형태일 수 있다. 구현 세부 사항에 따라, 물리 계층 정보의 표현을 생성하기 위해 기계 학습 모델에 의한 물 리 계층 정보의 수정은 장치 사이에서 물리 계층 정보를 전송하는데 수반되는 자원을 감소시킬 수 있다. 기계 학습 모델은 신경망(예를 들어, 심층 신경망), 선형 회귀, 로지스틱 회귀, 결정 트리, 선형 판별 분 석, 나이브 베이즈(naive Bayes), 지원 벡터 기계, 학습 벡터 양자화 등을 포함하여, 임의의 유형의 AI 및/또는 ML 모델 중 하나 이상으로 구현될 수 있다. 기계 학습 모델은 예를 들어, 생성 모델로 구현될 수 있다. 물리 계층 정보는 무선 통신 장치의 물리 계층의 동작과 관련된 임의의 정보를 포함할 수 있다. 예를 들어, 물리 계층 정보는 하나 이상의 물리 계층 채널, 신호, 빔 등에 관한 정보(예를 들어, 상태 정보, 프 리코딩 정보 등)를 포함할 수 있다. 물리 계층 채널의 예는 물리 방송 채널(PBCH), 물리 랜덤 액세스 채널 (PRACH), 물리 다운링크 제어 채널(PDCCH), 물리 다운링크 공유 채널(PDSCH), 물리 업링크 공유 채널(PUSCH) 중 하나 이상을 포함할 수 있다. 물리 업링크 제어 채널(PUCCH), 물리 사이드링크 공유 채널(PSSCH), 물리 사이드 링크 제어 채널(PSCCH), 물리 사이드링크 피드백 채널(PSFCH) 등 중 하나 이상을 포함할 수 있다. 물리 계층 신 호의 예는 1차 동기화 신호(PSS), 2차 동기화 신호(SSS), 채널 상태 정보 참조 신호(CSI-RS), 추적 참조 신호 (TRS), 사운딩 참조 신호(SRS) 등 중 하나 이상을 포함할 수 있다. 도 2는 본 발명에 따른 무선 통신 장치의 다른 실시 예를 도시한다. 장치는 물리 계층 정보의 표현을 입력으로서 수신하고, 표현이 기반으로 할 수 있는 물리 계층 정보의 복원을 출력으로서 생성할 수 있는 기계 학습 모델을 포함할 수 있다. 일부 구현들에서, 장치 는 화살표로 나타낸 바와 같이 하나 이상의 다른 장치로부터 물리 계층 정보의 표현을 수신할 수 있다. 복원(복원된 입력으로 지칭될 수 있음)은 표현이 기반으로 할 수 있는 물리 계층 정보일 수 있거나, 표현이 기반으로 할 수 있는 물리 계층 정보의 근사, 추정, 예측 등일 수 있다. 복원은 표현이 기반으로 할 수 있는 물리 계층 정보의 압축해제, 디코딩, 복호화, 역-매핑 또는 수정된 형태일 수 있다. 기계 학습 모델은 신경망(예를 들어, 심층 신경망), 선형 회귀, 로지스틱 회귀, 결정 트리, 선형 판별 분 석, 나이브 베이즈, 지원 벡터 머신, 학습 벡터 양자화 등을 포함하는 임의의 유형의 AI 및/또는 ML 모델 중 하 나 이상으로 구현될 수 있다. 기계 학습 모델은 예를 들어, 복원 모델로 구현될 수 있다. 복원된 물리 계층 정보는 무선 통신 장치의 물리 계층의 동작에 관한 임의의 정보, 예를 들어, 도 1에 도 시된 실시 예와 관련하여 위에서 설명된 바와 같은 하나 이상의 채널, 신호 등을 포함할 수 있다. 특정 용도로 제한되지는 않지만, 도 1 및 도 2에 각각 도시된 무선 통신 장치(101 및 202)는 장치 사이로부터 물리 계층 정보의 전송을 용이하게 하기 위해 함께 사용될 수 있다. 예를 들어, 일부 실시 예에서, 장치는 모델이 생성 모델로서 구현되는 UE로서 구현될 수 있고, 장치는 모델이 복원 모델로서 구현될 수 있는 기지국으로서 구현될 수 있다. 이러한 실시 예에서, 생성 모델은 (예를 들어, 기지국에서 UE로의 DL 채널에 관한) 물리 계층 정보를 압축함으로써 표현을 생성할 수 있다. UE는 표현을 (예를 들 어, UL 채널을 사용하여) 기지국에 전송할 수 있다. 기지국은 복원된 물리 계층 정보를 생성할 수 있는 복 원 모델에 표현(208으로 표시됨)을 입력할 수 있다. 기지국은, 예를 들어 기지국으로부터 UE로의 DL 전송 을 용이하게 하기 위해 복원된 물리 계층 정보를 사용할 수 있다. 구현 세부 사항에 따라, 압축된 표현 의 형태로 물리 계층 정보를 전송하는 것은 물리 계층 정보를 전송하는 것과 연관된 UL 자원의 양을 감소시킬 수 있다. 2-모델 훈련 도 3은 본 개시에 따른 2-모델 훈련 방식의 실시 예를 예시한다. 도 3에 예시된 실시 예는 예를 들어, 도 1 및 도 2에 도시된 모델 중 하나 이상, 또는 본 명세서에서 개시 된 임의의 다른 실시 예와 함께 사용될 수 있다. 도 3을 참조하면, 훈련 데이터는 훈련 데이터의 표현을 생성할 수 있는 생성 모델에 적용될 수 있다. 복원 모델은 훈련 데이터의 표현에 기초하여 훈련 데이터의 복원을 생성할 수 있다. 일부 실시 예에서, 생성 모델은 표현을 통신 채널을 통해 전송될 수 있는 양자화된 형태(예를 들어, 비트 스트림)로 변환하기 위한 양자화기를 포함할 수 있다. 유사하게, 일부 실시 예에서, 복원 모델은 양자화된 표현(예를 들어, 비트 스트림)을 복원된 훈련 데이터를 생성하기 위해 사용될 수 있는 형태로 변환할 수 있는 역양자화기를 포함할 수 있다.생성 모델 및 복원 모델은, 예를 들어 생성 모델 및/또는 복원 모델에 훈련 피드백을 제공하기 위해 손실 함수를 사용함으로써 쌍으로 훈련될 수 있다. 훈련 피드백은 예를 들어, 경사 하 강법, 역전파 등을 사용하여 구현될 수 있다. 생성 모델 및 복원 모델 중 하나 또는 둘 모두가 하나 이상의 신경망으로 구현될 수 있는 실시 예에서, 훈련 피드백은 생성 모델 및/또는 복원 모델에 서 가중치, 하이퍼매개변수 등의 하나 이상의 값을 업데이트할 수 있다. 일부 실시 예에서, 손실 함수(예를 들어, 복원 손실로 적어도 부분적으로 구현될 수 있음)는 생성 모델 및 복원 모델을 훈련하여 원래 훈련 데이터에 근접하도록 복원된 훈련 데이터를 생성하도 록 동작할 수 있다. 이것은 예를 들어 손실 함수의 손실 출력을 줄이거나 최소화함으로써 달성될 수 있다. 예를 들어, 훈련 데이터가 x로 표현되고, 복원된 훈련 데이터가 로 표현된다면, 생성 모델은 함수 f(x)로 표현될 수 있고, 복원 모델은 함수 g(f(x))로 표현될 수 있으므로, 이 된다. 손실 함수는 로 표현될 수 있다. 따라서, 일부 실시 예에서, 한 쌍의 모델(303, 304)을 훈련하는 것은 훈 련 피드백을 사용하여 L을 감소시키거나 최소화하는 것을 포함할 수 있다. 훈련 데이터의 임의의 특정 유형의 표현에 제한되지는 않지만, 일부 실시 예에서, 한 쌍의 모델(303, 30 4)은 원래 훈련 데이터에 대한 훈련 데이터의 표현의 차원을 감소시키려고 할 수 있다. 예를 들어, 생성 모델은 표현을 저장 및/또는 전송하는 것과 연관된 오버헤드를 감소시킬 수 있는 훈련 데이터의 하나 이상의 특징(예를 들어, 잠재 특징)을 식별하거나 분리할 수 있는 특징 벡터를 생성하도록 훈련될 수 있다. 복원 모델은 표현에 기초하여, 원본 훈련 데이터 또는 그 근사를 복원하도록 유사하게 훈 련될 수 있다. 일단 훈련되면, 생성 모델 및/또는 복원 모델은 예를 들어, 도 1 및 도 2에 각각 도시된 무선 통신 장치(101 및 202) 중 하나 또는 둘 다, 또는 본 명세서에 개시된 임의의 다른 실시 예에서 추론을 위해 사용될 수 있다. 더구나, 도 3과 관련하여 설명된 2-모델 훈련 방식은 본 명세서에 개시된 바와 같이 모델을 훈련 및/ 또는 무선 장치 사이에서 모델을 전달하기 위한 하나 이상의 프레임워크와 함께 사용될 수 있다. 도 3과 관련하 여 설명된 훈련은 예를 들어, 무선 장치에서, 무선 장치에서, 다른 위치에서 (예를 들어, 장치(101 및 202) 둘 다의 원격 서버에서), 또는 이러한 위치의 조합에서와 같이, 어디에서나 수행될 수 있다. 더욱이, 일단 훈련되면, 생성 모델 및/또는 복원 모델 중 하나 또는 둘 모두가 추론에 사용하기 위해 다른 위 치로 전송될 수 있다. 일부 실시 예에서, 일단 훈련되면, 모델 중 하나는 폐기될 수 있고 나머지 모델은 예를 들어 별도로 훈련된 모델과 쌍으로 사용될 수 있다. 채널 정보 피드백을 위한 기계 학습 모델 도 4는 본 개시에 따른 채널 정보 피드백을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 도시한다. 도 4에 예시된 시스템은 도 1, 도 2, 및 도 3에 예시된 것들을 포함하여, 본 명세서에서 개시된 임의의 장 치, 모델, 훈련 방식 등을 구현하도록 사용되거나, 이들에 의해 구현될 수 있다. 도 4를 참조하면, 시스템은 제1 무선 장치 및 제2 무선 장치를 포함할 수 있다. 제1 무선 장치 는 채널을 통해 제2 무선 장치로부터의 전송을 수신하도록 구성될 수 있다. 채널을 통한 전송의 효율성(예를 들어, 효율성, 신뢰성, 대역폭 등)을 개선하기 위해, 제1 무선 장치는 예를 들어, 채 널을 통해 제2 무선 장치에 의해 전송된 하나 이상의 신호(예를 들어, 참조 신호)를 측정함으로써 획 득될 수 있는 채널 정보의 형태로 제2 무선 장치에 피드백을 제공할 수 있다. 제1 무선 장치는 채널 정보의 표현을 생성하기 위해, 이 예에서 생성 모델로서 구현될 수 있는 제1 기계 학습 모델을 사용할 수 있다. 제1 무선 장치는 예를 들어, 다른 채널, 신호 등을 사용 하여 표현을 제2 무선 장치로 전송할 수 있다. 표현은 채널 정보의 압축, 인코딩, 암호화, 매핑 또는 수정된 형태일 수 있다. 구현 세부 사항에 따라,표현을 생성하기 위해 기계 학습 모델에 의한 채널 정보의 수정은 채널 정보를 제2 무선 장치로 전송하는데 수반되는 자원을 감소시킬 수 있다. 제2 무선 장치는 이 예에서 복원 모델로서 구현될 수 있는 제2 기계 학습 모델에 채널 정보의 표현 을 적용할 수 있다. 복원 모델은 채널 정보의 복원을 생성할 수 있다. (복원된 입력으로 지칭될 수 있는) 복원은 표현이 기초할 수 있는 채널 정보, 또는 채널 정보의 근사, 추정,예측 등일 수 있다. 복원은 채널 정보의 압축해제, 디코딩, 복호화, 역-매핑, 또는 달리 수정된 형태 일 수 있다. 제2 무선 장치는 채널 정보를 이용하여 채널을 통해 제1 무선 장치로 전송하 는 방식을 개선할 수 있다. 도 4에 도시된 시스템은 임의의 특정 장치(예를 들어, UE, 기지국, 피어 장치 등), 애플리케이션(예를 들 어, 4G, 5G, 6G, Wi-Fi, 블루투스 등) 및/또는 구현 세부 사항에 제한되지 않는다. 그러나 본 발명의 원리 중 일부를 설명하기 위해, 일부 예시적인 실시 예는 UE가 gNB로부터 상이한 DL 신호를 수신할 수 있는 5G NR 시스 템의 맥락에서 설명될 수 있다. 업링크 및 다운링크 전송 NR 시스템에서, UE는 gNB로부터 다양한 정보를 포함하는 DL 전송을 수신할 수 있다. 예를 들어, UE는 물리 다운 링크 공유 채널(PDSCH)로 지칭되는 시간 및 주파수 자원의 특정 구성으로 gNB로부터 사용자 데이터를 수신할 수 있다. gNB의 다중 접속(MAC) 계층은 UE 측의 해당 MAC 계층에 전달되도록 의도된 사용자 데이터를 제공할 수 있 다. UE의 물리(PHY) 계층은 PDSCH를 통해 수신된 물리 신호를 수신하고 이를 PDSCH 처리 체인에 대한 입력으로 적용할 수 있고, 그 출력은 UE에서 MAC 계층에 대한 입력으로서 공급될 수 있다. 유사하게, UE는 물리 다운링크 제어 채널(PDCCH))를 사용하여 gNB로부터 제어 데이터를 수신할 수 있다. 제어 데이터는 다운링크 제어 정보 (DCI)로 지칭될 수 있으며, gNB 측의 PDCCH 처리 체인을 통해 PDCCH 신호로 변환될 수 있다. UE는 물리 업링크 공유 채널(PUSCH) 및 물리 업링크 제어 채널(PUCCH)를 각각 사용하여 사용자 데이터 및 제어 정보를 전달하기 위해 UL 신호를 gNB에 보낼 수 있다. PUSCH는 데이터를 gNB에 전달하기 위해 UE MAC 계층에 의 해 사용될 수 있다. PUCCH는 업링크 제어 정보(UCI)로 지칭될 수 있는 제어 정보를 전달하는 데 사용될 수 있으 며, 이는 UE 측에서 PUCCH 처리 체인을 통해 PUCCH 신호로 변환될 수 있다. 채널 상태 정보 NR 시스템에서, UE는 채널 품질 표시자(CQI), 프리코딩 행렬 표시자(PMI), CSI 참조 신호 자원 표시자(CRI) 및/ 또는 순위 표시(RI)를 계산할 수 있는 채널 상태 정보(CSI) 생성기를 포함할 수 있으며, 이들 중 일부 또는 전 부는 UE에 서비스를 제공하는 하나 이상의 gNB에 보고될 수 있다. CQI는 적응 변조 및 코딩 및/또는 주파수 선 택적 자원 할당을 위한 변조 및 코딩 방식(MCS)과 연관될 수 있으며, PMI는 채널 종속 폐쇄 루프 다중 입력 다 중 출력 시스템에 사용될 수 있으며, RI는 유용한 전송 계층의 수에 해당할 수 있다. NR 시스템에서, CSI 생성은 gNB가 전송하는 CSI 참조 신호(CSI RS)를 기반으로 수행될 수 있다. UE는 예를 들어, CSI-RS 신호의 측정에 기초하여 채널 추정 및/또는 잡음 분산 추정을 수행함으로써, 다운링크 채널 상태 를 측정하고 CSI를 생성하기 위해 CSI-RS를 사용할 수 있다. NR 시스템에서, CSI는 미리 정의된 PMI를 가리킬 수 있는 인덱스의 형태로 gNB에 암시적 CSI 피드백을 제공할 수 있는 유형 I 코드북을 사용하여 서빙 gNB에 보고될 수 있다. 대안적으로, 또는 추가적으로, CSI는 UE가 DL 채널 조건에 기초하여 하나 이상의 지배적 고유 벡터 또는 특이 벡터를 결정할 수 있는 명시적 CSI 피드백을 제 공할 수 있는 유형 II 코드북을 사용하여 서빙 gNB에 보고될 수 있다. 그 다음, UE는 DL 채널에서 빔포밍을 위 해 PMI를 사용할 수 있는 gNB에 피드백될 수 있는 PMI를 유도하기 위해 지배적 고유 벡터 또는 특이 벡터를 사 용할 수 있다. 코드북의 사용은 예를 들어 제한된 수의 안테나 포트 및/또는 사용자가 있는 실시 예에서, 적절한 성능을 제공 할 수 있다. 그러나, 다수의 안테나 포트 및/또는 사용자가 있는 시스템(예를 들어, MIMO(다중 입력 다중 출력) 시스템)에서, 특히 주파수 분할 이중화(FDD)를 사용하는 시스템에서는, 유형 I 코드북의 상대적으로 낮은 해상 도로는 적절한 정확도로 CSI 피드백을 제공할 수 없다. 더욱이, 유형 II 코드북의 사용은 여전히 UL 채널 상에 서 상당한 양의 오버헤드 데이터의 전송을 수반할 수 있다. 구현 세부 사항에 따라, 본 개시에 따른 기계 학습에 기초한 채널 정보 피드백 방식의 일부 실시 예는 UE가 gNB 로의 UL 전송과 관련된 오버헤드를 감소시키면서 전체 CSI 정보를 gNB로 전송하는 것을 가능하게 할 수 있다. 더욱이, 본 발명의 원리는 UE가 CSI를 gNB에 보내는 것에 제한되는 것이 아니고, 제1 장치가 제2 장치에 채널 정보 피드백을 보낼 수 있는 임의의 상황에 적용될 수 있다(예를 들어, UE에서 gNB로의 업링크 채널에 대한 채 널 조건의 보고, UE 간의 사이드링크 채널에 대한 채널 조건 보고 등). 예시적인 실시 예 도 5는 본 개시에 따른 다운링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 시스템은 UE(노드 B로 지정될 수 있음) 및 gNB(노드 A로 지정될 수 있음)를 포함할 수 있다. gNB는 DL 신호의 전송(예를 들어, 참조 신호(RS) 전송)을 UE에 전송할 수 있으며, UE는 이 전송으로부터 측정을 추출할 수 있다. UE는, 예를 들어, 측정을 DL 물리 계층에 관한 특징 벡터로 인코딩하기 위한 인코더로서 구성될 수 있는 모델을 포함할 수 있다. 인코딩된 측정은 그 다음 양 자화기에 의해 양자화되고 UL 신호(예를 들어, 비트스트림)로서 gNB에 다시 전송될 수 있다. 일 부 실시 예에서, 노드에서 모델의 설명은 또한 양자화기 및/또는 역양자화기 설명, 예를 들어, 인코더 모델의 출력에서의 채널 정보(예를 들어, 실제 CSI 코드워드)를 양자화된 값 또는 비트 스트림에 매핑할 수 있고 다른 노드의 디코더 모델에서는 그 반대로 매핑할 수 있는 기능을 포함할 수 있다. gNB는 수신된 UL 신호 를 역양자화기에 적용하여 DL 물리 계층에 관한 정보(예를 들어, 필수 또는 선택적 정보)를 추출하기 위해 모델에 공급될 수 있는 등가 특징 벡터를 생성할 수 있다. 도 6은 본 개시에 따른 업링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 일부 측면에서, 도 6에 예시된 시스템은 도 5에 예시된 시스템과 유사할 수 있지만, 시스템은 다운링크 물리 계층 정보 대신에 업링크 물리 계층 정보를 보고하도록 구성될 수 있다. 구체적으로, 시스템은 (노드 B로 지정될 수 있는) gNB 및 (노드 A로 지정될 수 있는) UE를 포 함할 수 있다. UE는 UL 신호의 전송(예를 들어, 참조 신호(RS) 전송)을 상기 전송으로부터 측정(61 8)을 추출할 수 있는 gNB에 전송할 수 있다. gNB는, 예를 들어, UL 물리 계층에 관한 특징 벡터로 측 정을 인코딩하기 위한 인코더로서 구성될 수 있는 모델을 포함할 수 있다. 그 다음 인코딩된 측정은 양자화기에 의해 양자화되고 DL 신호(예를 들어, 비트스트림)로서 UE에 다시 전송될 수 있다. UE는 수신된 DL 신호를 역양자화기에 적용하여 UL 물리 계층에 관한 정보(예를 들어, 필수 또는 선택적 정보)를 추출하기 위해 모델에 공급될 수 있는 등가 특징 벡터를 생성할 수 있다. 도 7은 본 개시에 따른 다운링크 물리 계층 채널 상태 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시 한다. 구현 세부 사항에 따라, 도 7에 예시된 시스템은 ML 모델을 사용하여 (예를 들어, 비교적 적은 수의 비트 로) CSI를 압축하면서, gNB 또는 다른 기지국이 UE로부터의 전체 CSI 정보를 검색하도록 할 수 있고(대조적으로, 예를 들어, 코드북 기반 포인터, 프리코딩 행렬 표시자 등에 대해), 따라서 CSI 전송과 관련 된 업링크 자원 오버헤드를 줄일 수 있다. 시스템은 UE 및 gNB를 포함할 수 있다. gNB는 UE가 DL 채널에 대한 CSI를 결정할 수 있도록 하는 CSI-RS 또는 복조 참조 신호(DMRS)와 같은 DL 참조 신호를 전송할 수 있다. UE는 CSI를 특징 벡터로 인코딩하기 위한 인코더로서 구성될 수 있는 ML 모델을 포함할 수 있다. UE는 또한 UL 신호를 사용하여 gNB에 전송될 수 있는 비트 스트림으로 특징 벡터를 양자 화할 수 있는 양자화기를 포함할 수 있다. gNB는 비트 스트림으로부터 특징 벡터를 복원할 수 있는 역양자화기를 포함할 수 있다. 그 다음, 특징 벡터는 CSI의 추정을 복원하기 위한 디코더로서 구성될 수 있는 ML 모델에 공급될 수 있다. 일부 실시 예에서, 성능 메트릭 은 인코더 모델, 디코더 모델, 양자화기, 및/또는 역양 자화기의 설계, 구성 및/또는 훈련의 정확도를 평가하는 데 사용될 수 있다. 예를 들어, 성능 메트릭 은 다음과 같이 채널 추정치 간의 오차 측정으로 구현될 수 있다. 수학식 1"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기에서 H 및 는 각각 UE 및 gNB에서의 채널 추정(예를 들어, CSI)를 나타낼 수 있다. 이러한 성 능 메트릭은 예를 들어 gNB에 의해 추출된 채널 상태 정보의 정확도를 평가하는 데 유용할 수 있다.추가적으로 또는 대안적으로, 시스템은 UE가 현재 채널 조건에 기초하여 프리코딩 행렬을 결정하기 위해 DL 참조 신호를 사용할 수 있게 하도록 구성될 수 있다. 그 다음, 프리코딩 행렬은 인코더 모델(70 3)에 의해 특징으로 인코딩되고, 양자화기에 의해 양자화되고, UL 신호를 사용하여 gNB로 전송 될 수 있다. gNB에서, 역양자화기는 프리코딩 행렬의 추정치를 복원하기 위해 디코더 모델에 적 용될 수 있는 특징 벡터를 복구할 수 있다. 예를 들어, 채널 실현 H의 경우, 적절한 프리코딩 행렬은 H=SΣD로 주어질 수 있는 H의 특이값 분해(SVD)를 사용하여 특이 벡터 S의 세트로 구현될 수 있고, 여기서 Σ는 대각 행 렬이고 D는 단일 행렬일 수 있다. 그러한 실시 예에서, 인코더 모델, 디코더 모델, 양자화기, 및/또는 역양자화기는 gNB가 단일 벡터(예를 들어, 행렬) S의 세트를 추출할 수 있도록 구성될 수 있 고, 그에 따라 성능 메트릭이 구현될 수 있다. 도 7에 도시된 실시 예는 다운링크 물리 계층 정보를 보고하지만, 다른 실시 예는 본 개시에 따른 유사한 원리를 사용하여 업링크 물리 계층 정보, 사이드링크 물리 정보 등을 보고하도록 구성될 수 있다. 모델 개발, 훈련 및 동작 인공 지능(AI), 기계 학습(ML), 딥 러닝 등(위에서 언급한 바와 같이 이들 중 일부 또는 전부는 개별적으로 및/ 또는 집합적으로 기계 학습 또는 ML로 지칭될 수 있음)은 본 개시에 따라 데이터의 하나 이상의 함수(예를 들어, 복소수 함수)를 추론하기 위한 기술을 제공할 수 있다. 기계 학습 과정에서, 데이터의 샘플이 ML 모델에 제공될 수 있으며, 이는 차례로 제공된 데이터 샘플을 사용하여 하나 이상의 함수를 결정하는 방법을 학습하기 위해 다양한 기계 학습 기술 중 하나를 적용할 수 있다. 예를 들어, 기계 학습 프로세스는 ML 모델이 데이터 샘 플 입력 x의 함수 f(x)를 학습하도록 허용할 수 있다. 앞서 언급한 바와 같이, ML 모델은 또한 모델이라고도 할 수 있다. 일부 실시 예에서, 기계 학습 프로세스(개발 프로세스라고도 함)는 훈련, 검증, 테스트 및/또는 추론(응용 단계 라고도 함)과 같은 하나 이상의 단계(단계라고도 함)에서 진행할 수 있다. 일부 실시 예는 이러한 단계 중 하나 이상을 생략하고/하거나 하나 이상의 추가 단계를 포함할 수 있다. 일부 실시 예에서, 하나 이상의 스테이지의 전부 또는 일부는 하나의 스테이지로 결합될 수 있고, 스테이지는 다중 스테이지로 분할될 수 있다. 또한, 단계 또는 그 일부의 순서는 변경될 수 있다. 훈련 단계에서, 모델은 하나 이상의 목표 작업을 수행하도록 훈련될 수 있다. 훈련 단계는 i) 데이터 샘플, 및 ii) 훈련 데이터 세트의 샘플(예를 들어, 각 샘플)에 대한 함수 f(x)의 결과를 포함할 수 있는 훈련 데이터 세 트의 사용을 포함할 수 있다. 훈련 단계에서, 하나 이상의 훈련 기술은 모델이 함수 f(x)처럼 동작하거나 이를 밀접하게 따를 수 있는 근사 관계(예를 들어, 근사 함수)를 학습할 수 있도록 한다. 검증 단계에서, 모델은 하나 이상의 목표 작업에 대한 훈련된 모델의 적합성을 평가하기 위해 (예를 들어, 초기 훈련을 수행한 후에) 테스트될 수 있다. 검증 결과가 만족스럽지 않은 경우 모델은 추가 훈련을 받을 수 있다. 검증 단계가 성공적인 결과를 제공하면 훈련 단계가 성공적으로 완료된 것으로 간주될 수 있다. 테스트 단계에서, 훈련된 모델은 하나 이상의 목표 작업에 대해 훈련된 ML 모델의 적합성을 평가하기 위해 테스 트될 수 있다. 일부 실시 예에서, 훈련된 모델은 훈련이 완료되고 검증이 성공적인 결과를 제공하지 않는 한 테 스트 단계로 진행하지 않을 수 있다. 추론 단계에서, 훈련된 모델은 하나 이상의 목표 태스크를 수행하기 위해 (예를 들어, 실제 애플리케이션에서) 사용된다. 테스트 및/또는 추론 단계에서, 모델은 훈련 단계의 샘플과 다를 수 있는 다른 데이터 샘플의 함수 값 f(x)를 결정하기 위해 훈련 단계를 통해 얻은 학습된 근사 함수를 사용할 수 있다. 일부 실시 예에서, 기계 학습 프로세스의 성공 및/또는 성능은 함수 f(x)에 대한 충분한 정보를 포함할 수 있는 충분히 큰 훈련 데이터 세트의 사용을 포함할 수 있으므로, 모델이 훈련 단계를 통해 함수 f(x)의 허용 가능하 게 근접한 근사값을 얻을 수 있도록 한다. 도 8은 본 개시에 따른 기계 학습 모델을 위한 학습 프로세스의 실시 예를 예시한다. 프로세스는 훈련 프로세스가 초기화될 수 있는 단계에서 시작할 수 있다. 예를 들어, 모델의 구조가 결정될 수 있으며, 모델의 값(예를 들어, 신경망 가중치, 하이퍼매개변수 등)이 초기화될 수 있으며, 적절한 수 의 샘플로 훈련 데이터 세트가 구성될 수 있는 등이다. 단계에서, 초기화된 모델은 예를 들어, 경사 하강법, 역전파 등을 사용하여 신경망 가중치, 하이퍼매개변 수 등의 값을 업데이트함으로써, 훈련된 후보 모델의 구성을 결정하기 위해 훈련 데이터 세트를 사용하여 훈련 될 수 있다. 일부 실시 예에서, 훈련 데이터 세트의 구성과 훈련 단계 사이에는 상호 관계가 있을 수 있다. 예를 들어, 훈련 단계는 완료하는 데 비교적 긴 시간이 소요될 수 있으며, 기간은 훈련 데이터 세트의 샘플 수에 따라 달라질 수 있다. 기간은 차례로 훈련 유형에 따라 달라질 수 있다. 예를 들어, 전체 훈련 및/또는 초기 훈련의 경우, 모델 이 초기화될 수 있고 많은 샘플(예를 들어, 모델 훈련을 위해 이전에 사용되지 않았을 수 있는 샘플)로 구성될 수 있는 큰 데이터 세트를 사용하여 훈련이 수행될 수 있다. 다른 예로, 부분 훈련 및/또는 업데이트 훈련의 경 우, 모델은 이전에 훈련되고 (또는 부분적으로 훈련되고), 이벤트(예를 들어, 새로운 데이터 샘플 획득, 모델의 성능 저하, 모델 업데이트 이벤트 등)는 모델의 수정 또는 적응을 프롬프트할 수 있다. 부분 훈련 및/또는 업데 이트 훈련의 경우, 모델은 전체 훈련 및/또는 초기 훈련에 사용되는 대규모 훈련 데이터 세트와 다를 수 있는 수정된 데이터 세트를 사용하여 훈련될 수 있다. 예를 들어, 수정된 훈련 데이터 세트는 초기 훈련에 사용된 전 체 데이터 세트의 하위집합, 새로 획득된 새로운 데이터 샘플의 세트, 또는 이들의 조합일 수 있다. 단계에서, 훈련된 후보 모델이 검증될 수 있다. 일부 실시 예에서, 검증 단계는 훈련 단계와 반 복적으로 수행될 수 있다. 예를 들어, 후보 모델이 검증 단계에서 실패하면, 새로운 후보 모델을 생성할 수 있는 훈련 단계로 돌아갈 수 있다. 일부 실시 예에서, 검증 성공 또는 실패(예를 들어, 분류 정확도, 최소 평균 제곱 오차(MMSE) 등)를 결정하기 위해 상이한 기준이 설정될 수 있다. 일부 실시 예에서, (예를 들어, 임계값을 초과하여 여러 번 실패한 후 또는 성능 기준이 특정 기간 또는 특정 수의 검증 단계 동안 임계값을 통과하지 못한 경우) 실패한 후보 모델은 훈련 단계로 돌아가는 것이 허용 되지 않고, 방법은 단계에서 종료될 수 있다. 다만, 검증 데이터를 이용한 후보 모델의 성능이 (예를 들어, 성공 또는 실패를 결정하는 기준에 따라) 적합하다고 판단되는 경우, 검증은 성공적인 것으로 간주될 수 있고 훈련된 후보 모델은 단계에서 테스트 단계로 전달될 수 있다. 단계에서, 검증 단계를 통과한 훈련된 모델 후보의 성능이 평가될 수 있다. 개발의 테스트 단계 동안 모델 의 성공 테스트 및/또는 실패를 선언하는 기준은 검증 단계에서 사용된 기준과 유사할 수 있다. 하지만, 테스트 단계 동안 기준과 함께 사용되는 하나 이상의 매개변수(예를 들어, 단계 수, 성능 임계값 등)는 검증 단계에서 사용된 것과 다를 수도 있고 다르지 않을 수 있다. 테스트가 성공적이면, 최종 모델로 지정되어 단계로 진행할 수 있다. 일부 실시 예에서, 모델이 테스트 단 계에 실패하면, 프로세스는 추가 훈련을 위해 단계에서 훈련 단계로 돌아갈 수 있다. 그러나 일부 실시 예 에서, 추가 훈련은 (예를 들어, 검증 단계 동안 사용된 것과 유사한 기준에 기초하여) 허용되지 않을 수 있고, 프로세스는 단계에서 종료될 수 있다. 모델 훈련 및 배포 프레임워크 본 개시에 따른 일부 실시 예는 모델을 훈련 및/또는 전개하기 위한 하나 이상의 프레임워크를 구현할 수 있다. 본 명세서에 개시된 프레임워크의 일부 실시 예에서, 노드에 의해 훈련 및/또는 개발된 하나 이상의 모델은 예 를 들어, 해당 애플리케이션에 대해 지정될 수 있는 하나 이상의 잠재적 테스트 사례에 대한 모델의 준수를 평 가하기 위해, 노드에 대한 하나 이상의 참조 모델에 대해 테스트될 수 있다. 본 명세서에 개시된 프레임워크의 임의의 실시 예에서, 양자화 함수는 양자화기 범위의 일부 또는 전체에 걸쳐 (예를 들어, 본질적으로 전체 범위에 걸쳐) 본질적으로 0의 도함수 값(예를 들어, 확률 1을 가짐)으로 미분 가 능하다. 구현 세부 사항에 따르면, 이로 인해 인코더 가중치 업데이트가 거의 또는 전혀 제공되지 않을 수 있는 역전파가 발생할 수 있다. 따라서, 일부 실시 예에서, 양자화 함수는 훈련 단계에서 로 지 칭될 수 있는 미분 가능한 함수(예를 들어, 참조 미분 가능한 양자화 함수)로 근사화될 수 있고, 실제 양자화 함수는 추론 단계에서 사용될 수 있다. 유사하게, 역양자화 함수는 훈련 단계에서 fdequantizer,approx(x)로 지칭될 수 있는 미분 가능 함수(예를 들어, 참조 미분 가능한 역양자화 함수)로 근사화될 수 있는 반면, 실제 역양자화 함 수는 추론 단계에서 사용될 수 있다. 일부 실시 예에서, 모델과 함께 사용되는 양자화기 또는 역양자화 함수는 해당 모델에 대한 완전한 설명의 일부로 간주될 수 있으며, 모델과 함께 또는 모델의 일부로 양도될 수 있다. 따라서, 본 명세서에서 공개된 프레임워크 중 하나를 사용하여, 제1 노드가 제2 노드와 훈련된 모델을 공유하는 경우 (예를 들어, 노드 A가 모델 A와 모델 B의 쌍을 훈련하면, 훈련된 모델 B를 노드 B로 보냄), 제1 모델은 또 한 예를 들어 RRC 시그널링을 통해, 제2 노드와 근사된 양자화 함수 및/또는 근사된 역양자화 함수 중 하나 또는 둘 다를 공유할 수 있다. 본 명세서에 개시된 프레임워크는 임의의 특정 애플리케이션 및/또는 구현 세부사항으로 제한되지 않지만, 일부 실시 예에서, 및 구현 세부사항에 따라, 프레임워크는 CSI 피드백 오버헤드를 줄일 수 있는 모델을 훈련 및/또 는 테스트하는 데 사용될 수 있다. 공동 훈련 프레임워크 일부 실시 예에서, 한 쌍의 모델(예를 들어, 모델 A 및 모델 B)은 두 노드(노드 A 또는 노드 B) 중 하나에 의해 공동으로 훈련될 수 있으며, 비훈련 노드에 대한 훈련된 모델은 추론에 사용하기 위해 비훈련 노드로 전달될 수 있다(예를 들어, 공동 훈련이 노드 A에 의해 수행되는 경우, 훈련된 모델 B가 노드 B로 전달될 수 있음). 예를 들어, CSI 압축의 맥락에서, 기지국은 한 쌍의 인코더 및 디코더 모델의 공동 훈련을 수행한 다음, 인코더 모델 을 UE에 전달할 수 있다. 인코더 모델은 또한 인코더로 지칭될 수 있고, 디코더 모델은 또한 디코더로 지칭될 수 있다. 공동 훈련 프레임워크의 일부 실시 예에서, 훈련된 모델 중 하나 또는 둘 모두의 추가 훈련(예를 들어, 미세 조 정)은 (예를 들어, 모델 중 하나 또는 둘 모두를 개선하거나 최적화하기 위해) 모델이 추론에 사용될 수 있는 노드에 의해 수행될 수 있다. 일부 실시 예에서, 추가 훈련은 예를 들어 진행 중인 통신 중에 하나 이상의 노드 에 의해 획득될 수 있는 온라인 데이터에 기반할 수 있다. 공동 훈련 프레임워크의 일부 실시 예에서, 훈련 노드는 대응하는 양자화기 및/또는 역양자화 함수(예를 들어, 근사 및/또는 미분 양자화 및/또는 역양자화 함수)을 사용하여 하나 또는 둘 모두의 모델을 훈련할 수 있다. 훈 련된 모델을 수신하는 노드는 또한 추가 훈련, 검증, 테스트, 추론 등을 위해 해당 양자화기 및/또는 역양자화 함수를 수신하여 사용할 수 있다. 일부 구현에서, 노드에 의한 모델의 공동 훈련은 대상 작업에 공동으로 매칭될 수 있는 모델을 생성할 수 있고, 따라서 개선되거나 최적화된 성능을 제공할 수 있다. 구현 세부 사항에 따라, 이러한 성능 향상은 모델을 다른 노드로 전달하는 것과 관련된 통신 오버헤드 및/또는 예를 들어, 다른 노드와 다른 제조업체에서 생산할 수 있 는 한 노드에서의 공동 훈련으로 인해 발생하는 모델 및/또는 노드 간의 불일치를 보충할 수 있다. 공동 훈련 프레임워크의 변형에서, 예를 들어, 하나의 노드는 기지국은 한 쌍의 인코더 및 디코더 모델을 공동 으로 훈련할 수 있다. 인코더 및 디코더 쌍은, 예를 들어, 위에서 설명된 바와 같은 참조 미분 양자화 및 역양 자화 함수를 사용하여 훈련될 수 있다. 그 다음, 기지국은 예를 들어 RRC 시그널링을 통해 훈련된 디코더 모델 을 UE와 공유할 수 있다. 그러나 기지국은 훈련된 인코더 모델을 UE와 공유할 수도 있고 공유하지 않을 수도 있 다. 기지국이 훈련된 인코더 모델을 UE와 공유하는 경우, UE는 훈련된 인코더 모델을 참조 인코더 모델로 사용 할 수 있다. 기지국이 훈련된 인코더 모델을 UE와 공유하지 않는 경우, UE는, 예를 들어, 무작위로 초기화된 가 중치, UE 구현을 위해 선택될 수 있는 가중치, 또는 임의의 다른 기반에 기초하여 참조 인코더 모델을 설정할 수 있다. UE는 다음에 기지국으로부터 수신한 훈련된 디코더 모델을 사용하여 참조 인코더 모델을 훈련할 수 있다. 참조 인코더 모델은 온라인으로 학습될 수 있다(동작 중에 수행될 수 있는 학습을 참조할 수 있음). 일부 구현에서, 온라인 훈련이 즉석에서 수행될 수 있다(동작 동안 수집될 수 있는 훈련 데이터(예를 들어, 채널 추정 H)를 사 용하여 수행된 훈련을 참조할 수 있음). 따라서, UE는 시간에 걸쳐 수집될 수 있는 채널 추정치 H를 사용하여 참조 인코더 모델을 훈련할 수 있다. 수집된 채널 추정치는 예를 들어 훈련 중 특정 지점에서 새로운 훈련 데이 터 세트로 사용될 수 있다. 더욱이, 수집된 채널 추정치 H는 또한 UE 또는 임의의 다른 장치에 의한 미래의 온 라인 및/또는 오프라인 훈련을 위해 저장될 수 있다. 그 다음 UE는 추론을 위해 훈련된 인코더 모델을 사용할 수 있다. UE는 또한 훈련된 인코더 모델을 기지국과 공 유할 수 있다. 훈련 절차는 더 많은 훈련 샘플, 예를 들어 채널 추정치 H가 훈련을 위해 UE에 의해 수집되고 사 용됨에 따라 계속될 수 있다. 도 9는 본 개시에 따른 한 쌍의 인코더 및 디코더 모델의 공동 훈련을 위한 방법의 예시적인 실시 예를 도시한 다. 단계에서 기지국은 Encref 및 Decref로 지칭될 수 있는 훈련 데이터 세트를 이용하여 한 쌍의 참조 인코더 및 디코더 모델을 공동으로 훈련할 수 있다. 단계에서, 기지국은 참조 디코더 모델 Decref를 UE와 공유할수 있다. 단계에서, 기지국은 참조 인코더 모델을 UE와 공유할지 여부를 결정한다. 기지국이 UE와 참조 인 코더를 공유하는 경우, 단계에서, UE는 공유된 참조 인코더를 훈련을 위해 참조 인코더로 사용할 수 있다. 기지국이 UE와 참조 인코더를 공유하지 않는 경우, 단계에서, UE는 예를 들어 랜덤 가중치를 사용하거나 UE 구현에 기초한 가중치를 사용하는 등의 참조 인코더 모델을 설정할 수 있다. 단계에서 UE는 시점 ti에 서 참조 인코더 모델을 훈련할 수 있다. [UE는 시점 ti에서 참조 인코더 모델을 학습한다.] 시점 ti는 예를 들 어, UE가 이전 시점 이후 충분한 채널 추정을 수행하고 수집한 시점으로 결정될 수 있다. 이것은 예를 들어 알 고리즘 1에 도시된 바와 같이 구현될 수 있으며, 여기서 각 시점 ti에 대해, UE는 새로운 온라인 훈련 세트 Si를 즉석에서 수집할 수 있고, 여기서 Si는 ti-1에서 ti까지의 채널 추정치를 포함할 수 있고, N은 UE 측에서 최대 온 라인 훈련 수일 수 있다. 일부 구현에서는 알고리즘 1을 완료한 후, UE는 훈련된 인코더 모델을 기지국과 공유 할 수 있다. 알고리즘 1"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 명세서에 개시된 훈련 및 전개 프레임워크 중 임의의 것은 장치의 임의의 유형 및/또는 조합 및 임의의 유형 의 모델 및/또는 물리 계층 정보와 함께 사용될 수 있다. 예를 들어, 도 8에 도시된 실시 예에서, 기지국이 초 기 조인트 훈련을 수행하고 인코더 및 디코더가 훈련되고 채널 추정과 함께 사용될 수 있지만, 다른 실시 예에 서 공동 훈련은 UE 또는 임의의 다른 장치에 의해 수행될 수 있고 모델은 훈련되고 프리코딩 행렬 또는 임의의 다른 유형의 물리 계층 정보와 함께 사용될 수 있다. 일부 실시 예에서, UE 또는 기지국과 같은 노드는 윈도우 (예를 들어, 명시적 시간 및/또는 주파수 윈도우) 내에서 새로운 훈련 데이터를 수집할 수 있다. 수집된 데이터 는 예를 들어 노드가 모델을 훈련하는 데 사용할 수 있는 훈련 데이터 세트를 구성하는 데 사용될 수 있다. 윈 도우는 예를 들어 기지국에 의해 결정될 수 있는 시작 및/또는 종료 시간으로 구성될 수 있다. 일부 실시 예에 서, 데이터 수집 윈도우를 결정하기 위해 사용되는 타임라인은, 예를 들어, 하나 이상의 CSI-RS 자원으로부터 측정될 수 있다. 대안적으로, 또는 추가적으로, 온라인 훈련은 다음과 같이 수행될 수 있다. 제1 노드 기지국은 제1 모델을 가질 수 있고, 제2 노드는 제1 모델과 쌍을 형성할 수 있는 제2 모델을 가질 수 있다. 일부 실시 예에서, 제1 및 제2 노드는 연결 모드(예를 들어, RRC 연결 모드)에서 동작할 수 있다. 노드 중 하나 또는 둘 모두는 다른 노드에 의한 공유를 통해 모델을 획득할 수 있다. 이 예에서, 노드들 중 하나는 기지국일 수 있고 다른 노드는 UE일 수 있다. 기지국은 미리 결정된 온라인 훈련 데이터 세트로 UE를 구성할 수 있고, 두 노드는 각각의 모델을 업데이트하기 위해 미리 결정된 온라인 훈련 데이터 세트를 사용할 수 있다. 노드가 자신의 모델을 업데이트할 때, 다른 노드 의 다른 모델은 고정된 것으로 가정할 수 있다. 일부 실시 예에서, 하나 이상의 온라인 훈련 데이터 세트는 (예 를 들어, 사양의 일부로서) 지정될 수 있고/있거나, 제3 노드에 의해 UE 및/또는 기지국에 제공될 수 있다. 제1 노드가 제1 모델 (예를 들어, 인코더 또는 디코더)을 업데이트하면, 업데이트된 제1 모델을 제2 노드와 공유할 수 있다. 제2 노드는 제1 모델이 고정되었다고 가정하여 제2 모델을 훈련시키기 시작할 수 있다. 모델은 예를 들어 종료 시간에 도달할 때까지 주기적으로 모델을 훈련하고 고정하는 작업을 계속할 수 있다. 상술된 실시 예는 UE가 인코더를 업데이트하고 사용할 수 있는 맥락에서 설명될 수 있지만, 온라인 훈련에 따른 일부 실시 예에서, UE와 기지국 모두(또는 측대역 통신을 위해 구성된 두 개의 UE와 같은 한 쌍의 모델을 가진 두 개의 다른 노드)는 새로운 훈련 데이터를 수집하고 자신의 모델(예를 들어, 인코더 또는 디코더) 또는 두 모 델(예를 들어, 자동 인코더로 구성될 수 있는 인코더 및 디코더 모두)를 업데이트하는 데 사용할 수 있다. 일부 실시 예에서, 제1 노드는 훈련 데이터를 데이터 또는 제어 정보로 전송함으로써 새로 수집된 훈련 데이터 (예를 들어, 채널 행렬)를 제2 노드와 공유할 수 있다. 예를 들어, UE는 하나 이상의 채널 행렬의 이진 표현을 생성하고 업링크 전송, 즉 인코딩, 변조 등을 위한 일반적인 절차에 따라 PUSCH 또는 PUCCH를 사용하여 표현을 전송할 수 있다.대안적으로, 또는 추가적으로, UE는 인코더를 현재 훈련된대로 사용하여 획득한 채널 행렬을 인코딩할 수 있다. UE는 CSI 코드워드로 지칭될 수 있는 인코딩된 채널 행렬을 기지국으로 전송할 수 있다. 기지국은 다음에 현재 훈련된 디코더를 사용하여 채널 행렬을 복구할 수 있다. 이 때 기지국은 기지국에서 추가의 (예를 들어, 온라인) 훈련에 사용될 수 있는 새로운 훈련 데이터 세트에 복구된 채널 행렬을 포함할 수 있다. 일부 실시 예에서, 노드 간에 훈련 데이터를 교환하는 것 외에, 하나 이상의 노드는 최신 훈련 모델(예를 들어, 인코더 및/또는 디코더)을 다른 노드와 공유할 수도 있다. 훈련 데이터 및/또는 모델의 공유는 이러한 공유와 관련된 통신 오버헤드의 양을 관리할 수 있는 간격으로 수행될 수 있다(예를 들어, 모델이 업데이트될 때 전송 될 수 있음). 모델의 온라인 훈련이 있는 프레임워크에서, 노드는 수집된 물리 계층 정보(예를 들어, 시간 ti-1에서 시간 ti까 지의 CSI 행렬)를 저장하기 위해 메모리 버퍼를 사용할 수 있다. 구현 세부 사항에 따라, 노드는 모델을 업데이 트하기 위해 새로운 훈련 데이터를 사용하기 시작하기 전에 새로운 훈련 데이터 세트의 일부 또는 전부를 수집 할 수 있다. 그러나, 노드가 훈련 데이터 세트를 저장하기 위해 전용 메모리 버퍼를 사용하고 시간 ti-1와 시간 ti 사이의 간격이 특정 값을 초과하면, 시간 윈도우에서 CSI-RS의 수가 너무 커질 수 있으므로 훈련 데이터를 저장하는 데 관련된 메모리 양이 사용 가능한 버퍼 크기를 초과할 수 있다. 또한, 시간 ti-1과 시간 ti 사이의 간 격이 일반적으로 버퍼 오버플로를 방지할 만큼 충분히 짧은 경우에도, 노드는 비교적 짧은 주기를 가진 일부 참 조신호를 만날 수 있다(예를 들어, 상대적으로 많은 수의 참조 신호(예를 들어, CSI-RS)가 윈도우에서 구성될 수 있음), 이에 따라 참조신호에 기초하여 수집된 CSI 행렬은 사용 가능한 전용 메모리 버퍼를 초과할 수 있다. 일부 실시 예에서, 노드는 예를 들어 수집된 훈련 데이터로부터 구성된 훈련 데이터 세트의 크기와 관련될 수 있는 데이터 버퍼링 능력을 선언할 수 있다. 구현 세부 사항에 따라, 이것은 새로운 훈련 데이터에 대한 메모리 버퍼의 용량을 초과하는 문제를 줄이거나 방지할 수 있다. 예를 들어, 노드는 훈련 데이터를 획득하고/하거 나 획득된 훈련 데이터에 기초하여 모델을 업데이트하기 위한 시간 간격(예를 들어, 최대 시간 간격); 노드 가 훈련 세트를 구성하는 데 사용할 것으로 예상되는 시간 윈도우 내의 참조신호(예를 들어, CSI-RS)의 최대 수; 또는 훈련 데이터 세트를 구성하는 데 사용되는 참조 신호(예를 들어, CSI-RS)의 단락 주기성에 기초하 여 미리 결정된 메모리 버퍼 능력을 선언하거나 할당될 수 있다. 노드가 미리 결정된 메모리 버퍼 능력을 위반 할 수 있는 하나 이상의 참조신호 및/또는 시간 윈도우으로 구성되는 상황을 오류 경우로 간주할 수 있다. 대안적으로, 또는 추가적으로, 노드의 미리 결정된 메모리 버퍼 능력의 위반이 발생할 때 디폴트 동작이 정의될 수 있다. 예를 들어, 참조신호 및/또는 시간 윈도우의 구성이 노드의 메모리 버퍼 용량을 위반하는 경우, 노드 는 모델을 업데이트하기 위해 수집된 훈련 데이터의 하위집합을 저장 및/또는 사용할 수 있다. 예를 들어, UE가 윈도우 내에서 최대 Nmax CSI-RS를 보고하고, gNB가 윈도우 내에서 더 많은 수의 NCSI-RS CSI-RS를 구성하는 경우, UE는 모델을 업데이트하기 위해 NCSI-RS CSI-RS중에서 Nmax CSI-RS만을 사용할 수 있다. UE가 사용할 CSI-RS를 선 택하는 방법은 UE 구현 및/또는 하나 이상의 구성되고/되거나 고정된 규칙에 따라 결정될 수 있다(예를 들어, UE는 NCSI-RS 자원 중 최신 Nmax 자원을 사용할 수 있다). 일부 실시 예에서, 수집된 훈련 데이터에 대한 버퍼 크기는 예를 들어 사양을 포함하지 않고 노드 구현을 기반 으로 할 수 있다. 예를 들어, UE의 훈련 데이터 버퍼가 오버플로되면, UE는 새로 수집된 데이터(예를 들어, 행 렬) 저장을 중단하고 버퍼의 데이터로 모델 업데이트를 진행할 수 있다. 일부 실시 예에서, UE는 모델이 업데이 트되면 버퍼를 플러시한 다음에, 새로운 훈련 데이터를 다시 수집하기 시작한다. 일부 실시 예에서, UE는 새로운 훈련 데이터를 저장하기 위해 공유 버퍼를 사용할 수 있다. 공유 버퍼의 예는 다른 채널, 예를 들어 PDSCH 버퍼, 마스터 CCE LLR 버퍼 등을 저장하기 위해 이미 사용된 하나 이상의 버퍼를 포함할 수 있다. 이 실시 예에서, 공유 버퍼 공간은 다른 전용 용도에 따라 이미 완전히 또는 부분적으로 점유 되어 있을 수 있으므로 가용성에 따라 사용될 수 있다. 일부 실시 예에서, 수집된 훈련 데이터의 버퍼링은 노드 구현에 기초할 수 있다. 참조 모델을 사용한 훈련 프레임워크 본 개시에 따른 일부 프레임워크에서, 참조 모델은 노드 A에 대해 모델 A로 설정될 수 있으며, 노드 B는 (예를 들어, 노드 A가 참조 모델을 추론을 위해 모델 A로 사용한다고 가정하고) 참조 모델을 모델 A로 사용하여 모델 B를 훈련할 수 있다. 노드 A는 다음에 추가 훈련 없이 참조 모델을 모델 A로 사용하거나, 노드 A는 모델 A로 사용하도록 참조 모델을 훈련할 수 있다. 일부 실시 예에서, 노드 A에 대해 하나 또는 다수의 모델 A가 제공 및/ 또는 지정될 수 있으며, 노드 B는 노드 A에 대한 참조 모델 중 하나 또는 다수개라고 가정될 수 있는 노드 B에 서 모델 A를 사용하여 하나 이상의 모델 B를 훈련할 수 있다. 예를 들어, 노드 B는 모델 A에 대해 지정된 하나 의 참조 모델로 가정되는 모델 A를 사용하여 모델 B의 제1 버전을 훈련할 수 있다. 노드 B는 모델 A를 다른 참 조 모델 등으로 가정하여 모델 B의 제2 버전을 훈련할 수도 있다. 예를 들어, 참조 모델은 사양, 시그널링(예를 들어, UE가 RRC-연결된 후 기지국에서 UE로의 RRC 시그널링) 등을 통해 설정될 수 있다. 일부 실시 예에서, 노드 B는 모델 A의 다른 버전을 훈련하기 위해 어느 참조 모델을 선택했지에 대해 노드 A에 알릴 수 있다. 모델 A에 사용할 수 있는 참조 모델이 하나뿐인 경우, 참조 모델이 암시적으로 알려져 있기 때문 에 통신이 포함될 수 없다. 노드 B는 모델 B의 학습 버전에 사용할 수 있는 다수의 참조 모델 중 하나의 참조 모델을 노드 A에 알릴 수 있으며; 이 모델은 예를 들어 최상의 성능을 제공한 참조 모델에 해당할 수 있다. 대 안적으로, 또는 추가적으로, 노드 B는 노드 A에게 다수의 참조 모델 중 참조 모델의 하위집합을 알릴 수 있으며; 이 하위 집합은 최고 성능의 참조 모델의 모음을 포함할 수 있다. 노드 B에서 노드 A로의 임의의 시그널링에 관계없이, 노드 A는 어느 참조 모델을 선택했는지를 노드 B에 표시하 거나 표시하지 않을 수 있다. 참조 모델을 표시하게 되면 예를 들어 노드 A와 노드 B 사이에 공통된 이해를 설 정하는 데 유용할 수 있는 반면, 참조 모델을 표시하지 않으면 시그널링 오버헤드를 줄일 수 있다. 다수의 참조 모델이 있는 구현에서, 최고 성능 모델의 하위 집합이 하나의 참조 모델만 포함하면(예를 들어, 하나의 참조 모 델만이 노드 B에서 노드 A로 가장 성능이 좋은 참조 모델로 표시되면), 노드 A에 의한 선택이 노드 B에 의해 암 시적으로 알려질 수 있기 때문에 노드 A는 노드 B에 표시를 제공하지 않을 수 있다. 일단 노드 A에 대한 참조 모델이 설정되면, 노드 A는 모델 A로서 참조 모델을 사용하거나 참조 모델을 훈련시키 는 것을 진행할 수 있다. 구현 세부 사항에 따라, 참조 모델을 (예를 들어, 추가 훈련 또는 조정이 거의 또는 전혀 없이) 모델 A로 사용하게 되면 노드 B는 모델 A에 대한 참조 모델의 사용을 가정하여 모델 B를 훈련할 수 있기 때문에 두 모델 간에 비교적 높은 수준의 일치(예를 들어, 최상의 일치)를 제공할 수 있다. 다양한 버전의 모델 B를 학습하기 위해 노드 B에서 다수의 참조 모델을 사용하면, 노드 A는 모델 B의 훈련된 버전에 해당하는 참조 모델을 사용할 수 있으며; 이는 모델 B의 훈련된 버전 중 어느 것이 사용될지에 대한 노드 A와 노드 B 사 이에 공통된 이해를 확립하는 것을 포함할 수 있다(예를 들어, 노드 B는 모델 B의 어느 훈련된 버전이 사용되는 지를 노드 A와 통신할 수 있거나, 노드 A는 어느 모델을 사용할지에 대해 노드 B에 알릴 수 있음). 추가 훈련 없이 모델 A로 참조 모델을 사용하는 대신, 노드 A는 모델 A의 훈련을 지속할 수 있다. 이것은 예를 들어 참조 모델이 현재 네트워크 상태에 적합하지 않은 경우 유용할 수 있다(예를 들어, 모델이 CSI 압축 및 압 축해제에 사용되는 경우 무선 환경). 따라서, 노드 A가 모델 A를 추가로 훈련(예를 들어, 조정 또는 최적화)하 도록 허용하면 모델이 현재 네트워크 상태와 일치할 수 있다. 하지만, 모델 B를 훈련할 때 모드 A를 노드 B에 의해 가정된 참조 모델로부터 변경하게 되면 두 모델 간에 잠재적인 불일치가 발생하여 성능이 저하될 수 있다. 일부 실시 예에서, 모델 A는 이러한 잠재적인 불일치를 극복하도록 훈련될 수 있다. 예를 들어, 모델 A를 훈련 하기 위해, 노드 B는 모델 B를 노드 A로 보낼 수 있으므로 모델 A의 훈련은 노드 B에 의해 모델 B로 사용되는 실제 모델을 기반으로 할 수 있다. 모델 B의 다수의 훈련된 버전이 있는 경우, 노드 B는 모델 B의 훈련된 버전의 하위 집합을 통신할 수 있고, 노 드 A는 모델 B의 통신된 버전에 대해 다수의 해당하는 모델 A를 훈련할 수 있다. 그러한 실시 예에서, 모델 A와 모델 B는 어느 쌍의 모델 A와 모델 B를 선택하여 사용할 것인지에 대한 공통된 이해를 구축하기 위해 통신할 수 있다. 구현 세부 사항에 따라, 모델 A의 다수의 버전을 공유하면 통신된 모델 중에서 가장 성능이 좋을 수 있는 모델 A와 모델 B의 최상의 쌍을 선택하여, 노드 A 및/또는 노드 B가 성능을 향상(예를 들어, 최적화)할 수 있도 록 한다. 또는, 통신 오버헤드를 줄이기 위해서, 노드 B는 모델 B의 다수의 버전 중 하나와 통신할 수 있고, 노 드 A는 통신된 버전의 모델 B에 해당하는 모델 A를 훈련할 수 있다. 대안적으로, 또는 추가적으로, 노드 A가 모델 A의 훈련을 진행하면, 노드 A는 노드 B가 사용하는 실제 모델 B를 모방하기 위해 모델 B의 평가판을 훈련할 수 있다. 시험 모델 B와 실제 모델 B 간의 유사성 수준은 모델 B의 설 계 및/또는 아키텍처, 모델 B의 평가판을 훈련하는 데 사용되는 훈련 데이터 세트, 및/또는 모델 B의 평가판을 훈련하는 데 사용되는 훈련 절차(예를 들어, 가중치, 초매개변수 등의 초기화)에 따라 달라질 수 있다. 노드 B 에서 훈련된 모델 B의 다수의 훈련된 버전이 있는 경우, 노드 A는 모델 B의 다수의 해당 평가 버전을 훈련할 수있다. 또는, 노드 A는 모델 A에 대해 사용 가능한 참조 모델 각각에 해당하는 모델 B의 평가 버전을 사용하여 다수의 모델 A를 훈련할 수 있으며; 이것은 특히 노드 B가 어느 참조 모델이나 모델을 선택했는지를 노드 B가 알려주기 전에 노드 A가 모델 A를 훈련하도록 할 수 있기 때문에 유용할 수 있다. 그러한 실시 예에서, 모델 A 와 모델 B는 어느 쌍의 모델 A와 모델 B를 선택하여 사용할 것인지에 대한 공통된 이해를 구축하기 위해 통신할 수 있다. 시험 모델 B와 실제 모델 B 사이의 불일치를 더 줄이기 위해, 노드 B는 노드 A와 일부 보조 정보를 공유할 수 있다. 구현 세부 사항에 따라, 보조 정보를 공유하면 노드 A가 실제 모델 B와 유사한 시험 모델 B를 생성하는 방식으로 시험 모델 B를 훈련하는 데 도움이 될 수 있다. 보조 정보의 예에는 초기화 값(예를 들어, 실제 모델 B를 훈련하기 위해 노드 B에서 사용하는 랜덤 시드, 초기 네트워크 가중치 등), 하나 이상의 최적화 알고리즘, 기능 선택에 사용되는 하나 이상의 알고리즘, 데이터 사전 처리에 사용되는 하나 이상의 알고리즘, 신경망 유형 에 대한 정보(예를 들어, 순환 신경망(RNN), 컨볼루션 신경망(CNN) 등), 모델 구조에 대한 정보(예를 들어, 계 층의 수, 계층 당 노드의 수 등), 훈련 데이터 세트에 대한 정보 등을 포함할 수 있다. 이 정보를 사용하는 것 은 노드의 구현에 (예를 들어 사양을 통해) 위임되거나 맡겨질 수 있다. 일부 실시 예에서, 노드 A 및/또는 노드 B에 대한 참조 모델은 예를 들어 테스트 목적으로 (예를 들어, 사양에 서) 지정될 수 있다. 이러한 실시 예는 노드 A 및/또는 노드 B에 의해 사용되는 모델의 표시를 포함하지 않을 수 있다. 예를 들어, UE는 gNB가 하나 이상의 참조 모델을 사용할 때 하나 이상의 성능 사양을 충족할 것으로 예상될 수 있다. 구현 세부 사항에 따라, 이것은 기계 학습 동작에 적합한 성능을 얻기 위해 노드에서 사용할 모델에 대한 배포 지침을 제공할 수 있다. 일부 실시 예에서, 예를 들어 사양의 일부로서 기계 학습 CSI 압축 태스크에 대해 하나 이상의 성능 요구사항이 설정될 수 있다. 참조 모델이 있는 프레임워크의 일부 실시 예에서, 노드는 대응하는 양자화기 및/또는 역양자화 함수(예를 들어, 근사 및/또는 미분 가능 양자화 및/또는 역양자화 함수)을 사용하여, 참조 모델을 포함한 모든 모델을 훈 련할 수 있으며, 임의의 모델은 또한 추가 훈련, 검증, 테스트, 추론 등을 위해 대응하는 양자화기 및/또는 역 양자화 함수를 사용할 수 있다. 최신 공유 값을 갖는 훈련 프레임워크 본 개시에 따른 일부 프레임워크에서, 노드 A는 초기 상태에 있을 수 있는 (예를 들어, 사전 훈련되고(예를 들 어, 오프라인 훈련되고), 훈련되지 않았지만 초기 값으로 구성되는 등) 모델 A로 시작할 수 있다. 노드 B는 초 기 상태에 있을 수도 있는 모델 B로 시작할 수 있다. 하나 또는 두 노드는 일정 기간 동안 각각의 모델을 훈련 할 수 있으며(훈련 주기 또는 반복이라고 할 수 있음), 하나 또는 두 노드는 훈련된 모델 값 및/또는 훈련된 모 델을 다른 노드와 공유하거나 공유하지 않을 수 있다. 일부 실시 예에서, 새로운 훈련 데이터 세트는 예를 들어 사이클의 시작 또는 끝에서 하나 또는 양쪽 노드에 직접 또는 간접적으로 제공될 수 있다. 노드 A와 노드 B는 예를 들어, 모델 교환 없이, 다른 노드에서 모델의 가중치에 대한 최신 지식으로 각자의 모델을 훈련할 수 있다. 제1 노드는 제2 노드(예를 들어, 기지국의 디코더)의 모델이 (예를 들어, 제2 노드에 의해 피드백되는) 최신 가 중치로 고정되어 있다고 가정하고 자신의 모델을 학습할 수 있다(예를 들어, UE는 인코더를 학습할 수 있음). 제1 노드는 자신의 모델을 훈련하고 가중치, 예를 들어 최대 횟수(예를 들어, 인코더의 경우 Ke 회) 업데이트한 다음에 업데이트된 모델 가중치를 제2 노드와 공유할 수 있다. 제2 노드에서도 동일한 절차가 구현될 수 있다. 구체적으로, 제2 노드가 제1 노드로부터 업데이트된 모델 가중치를 수신하면, 제2 노드는 모델을 훈련하고 그 가중치를 최대 횟수(예를 들어, 디코더의 경우 Kd 회) 업데이트할 수 있다, 제1 노드에서 모델의 모델 가중치가 제1 노드에서 공유된 최신 상태에서 고정된다고 가정한다. 그러면 제2 노드는 업데이트된 모델 가중치를 제1 노 드와 공유할 수 있다. 따라서, 제1 및/또는 제2 노드는 각각의 모델을 최대 횟수로 훈련한 다음 업데이트된 모 델 값을 다른 노드와 공유할 수 있다(이를 공유 주기 또는 반복이라고 할 수 있음). 이 프레임워크의 변형에서, 노드 중 하나 이상이 다른 노드와 모델 상태 정보(예를 들어, 가중치)를 공유한 후, 예를 들어 공유 주기가 끝날 때, 노드 중 하나 또는 둘 모두가 다른 공유 주기를 시작할 수 있다. 예를 들어, 두 노드는 다른 노드의 모델 값이 다른 노드가 공유하는 최신 값으로 고정되어 있다고 가정하여 모델을 훈련할 수 있다. 특정 시점에서 또는 특정 수의 훈련 주기가 (예를 들어, 다른 공유 주기의 끝에서) 제1 및/또는 제2 노드에 의해 수행된 후, 하나 또는 두 노드 모두 학습을 중지하고 최신 학습 모델을 서로 공유할 수 있다. 일부 실시 예에서, 초기에, 공유 모델(예를 들어, 오프라인 학습, 핸드 쉐이킹 등을 통해 초기화될 수 있는 완전 공유 모델)은 최근 공유 가중치의 초기 값으로 사용될 수 있다. 도 10은 본 개시에 따른 최신 공유 값으로 모델을 훈련시키는 방법의 예시적인 실시 예를 도시한다. 설명을 위해, 도 10에 도시된 방법은 CSI에 대한 인코딩 모델을 갖는 UE 및 CSI에 대한 디코딩 모델을 갖는 기 지국의 컨텍스트에서 설명될 수 있지만, 원리는 임의의 유형의 노드 및/또는 물리 계층 정보에 적용될 수 있다. 도 10을 참조하면, 제1 공유 주기(1035-1)의 시작에서, 인코더 모델은 초기 상태 e0에 있을 수 있으며, 디코더 모델은 공유 포인트(1036-0)에 도시된 바와 같이 초기 상태 d0에 있을 수 있다. 초기 상태(e0,d0)의 인코딩 및 디코더 모델은 모두 UE 및 기지국에 제공될 수 있다. 따라서 UE와 기지국은 모두 동일한 초기 상태에서 인코더 및 디코더 모델로 시작한다. UE는 다음에 M회의 훈련 사이클을 수행할 수 있다(예를 들어, 디코더 모델이 초기 상태 d0에서 유지되는 동안 인코더를 M회 훈련할 수 있음). UE가 M회의 훈련 사이클을 수행하는 동안, 기지국은 N회의 훈련 사이클을 수행할 수 있다(예를 들어, 인코더 모델이 초기 상태 e0에서 유지되는 동안 인코더를 N회 훈련한다). 예를 들어, M 번째 훈련 사이클 이후에 UE의 인코더 및 디코더 모델이 상태(eM,d0)를 가질 때까지, UE에 의한 제 1 훈련 주기 후 UE의 인코더 및 디코더 모델이 상태(e1,d0)를 가질 수 있고, UE에 의한 제2 훈련 주기 후 UE의 인코더 및 디코더 모델이 상태(e2,d0)를 가질 수 있는 등이다. 유사하게, N 번째 훈련 사이클 이후에 기지국의 인코더 및 디코더 모델은 상태(e0,dN)를 가질 때 까지, 기지국에 의한 제1 훈련 주기 후 기지국의 인코더 및 디코더 모델이 상태(e0,d1)를 가질 수 있고, 기지국에 의한 제2 훈련 주기 후 기지국의 인코더 및 디코더 모델이 상태(e0,d2) 등을 가질 수 있는 등이다. 공유 주기(1035-1)의 종료시 공유 지점(1036-1)에서, UE는 훈련된 인코더 모델을 기지국에 보낼 수 있고, 기지 국은 훈련된 디코더 모델을 UE에 보낼 수 있다. 따라서, UE와 기지국 모두 상태(eM,dN)를 갖는 인코더 및 디코더 모델을 가질 수 있다. 일부 실시 예에서, UE 및/또는 기지국은 이 시점에서 훈련을 중지하고 추론을 위해 훈련된 인코더 및 디코더 모 델을 사용하기 시작할 수 있다. 그러나, 일부 다른 실시 예에서, UE 및/또는 기지국 중 하나 또는 둘 모두는 다 른 공유 사이클(1035-2)을 시작할 수 있다. 예를 들어, UE는 다음에 디코더 모델이 상태 dN에 남아 있는 동안 인코더를 P회 훈련함으로써 P회 훈련 사이클을 수행할 수 있고, 기지국은 인코더 모델이 상태 eM에 유지되는 동 안 디코더를 Q회 훈련함으로써 Q회 훈련 사이클을 수행할 수 있다. 공유 주기(1035-2)의 종료시 공유 지점(1036-2)에서, UE는 훈련된 인코더 모델을 기지국에 보낼 수 있고, 기지 국은 훈련된 디코더 모델을 UE에 보낼 수 있다. 따라서, UE와 기지국 모두는 상태(eP,dQ)를 갖는 인코더 및 디코 더 모델을 가질 수 있다. UE 및/또는 기지국은 공유 사이클의 수와 공유 사이클당 훈련 사이클의 수를 수행할 수 있다. 도 10에 도시된 실시 예의 특별한 경우는 M≫N, 또는 N≫M이든, M 또는 N=0일 때이다. 예를 들어, N=0 및 M>0인 경우, 기지국은 공유 사이클 동안 디코더 모델을 업데이트하지 않을 수 있다(예를 들어, 임의의 훈련 사이클을 수행하지 않을 수 있음). 그러나 UE는 기지국과 공유하기 전에 인코더를 M회 훈련할 수 있다. 유사하게, M=0 및 N>0일 때, UE는 인코더 모델을 업데이트하지 않을 수 있는 반면 기지국은 디코더 모델을 UE와 공유하기 전에 N 회 업데이트할 수 있다. 구현 세부 사항에 따라, 이러한 특별한 경우 중 하나 이상은 예를 들어 노드 중 하나에 문제가 있거나 노드에서 온라인 훈련을 위한 훈련 데이터 세트를 얻을 수 없는 경우에 유용할 수 있다. 그러한 상황에서, 훈련 데이터에 대한 액세스(또는 더 준비된 액세스)가 있는 노드는 온라인 훈련을 계속할 수 있으며, 이를 통해 훈련을 계속하는 노드가 훈련 데이터에 대한 액세스가 없거나 제한된 다른 노드에 훈련된 모델을 제 공하는 것을 가능하게 할 수 있다. 특별한 경우는 교차 및/또는 교대의 방식으로 수행될 수도 있다. 예를 들어, 두 노드는 변수 M 또는 N 중 하나 가 0인 상태에서 시작할 수 있고 다른 변수는 0보다 클 수 있다. 해당 모델이 있는 모델이 0이 아닌 변수에 의 해 결정된 횟수만큼 업데이트되고 다른 노드와 공유되면, 0이 아닌 변수는 0 값을 가질 수 있지만 다른 변수는 0이 아니다. 이 프로세스는 M과 N이 교대로 0 값을 취하면서 계속될 수 있다. 이러한 교차되는 훈련 절차에 의 하면 제1 노드(예를 들어, UE 또는 gNB)는 제2 노드에서의 모델이 고정된 동안 자신의 모델(예를 들어, 인코더또는 디코더)을 여러번 훈련할 수 있다. 그 다음에, 제1 노드가 훈련된 모델을 제2 노드와 공유한 후, 제2 노드 는 제1 노드의 모델이 고정된 동안 그 모델을 여러번 학습할 수 있는 등이다. 일부 실시 예에서, 0이 아닌 변수의 값은 훈련된 모델 쌍의 성능에 영향을 미칠 수 있다. 예를 들어, 공유 지점 간의 시간이 상대적으로 크면, 훈련된 모델(eM,dN)은 예를 들어, 각 노드가 다음 공유 지점에서 공유될 모델과 크게 다를 수 있는 다른 쪽의 모델 가중치를 가정하여 학습하고 있는 경우, 상대적으로 성능이 좋지 않을 수 있 다. 예를 들어, 도 10에 도시된 실시 예에서, 기지국은 가중치 e0을 갖는 인코더를 가정하여 자신의 디코더를 훈련할 수 있고, 나중에 훈련된 디코더를 e0로부터 상당히 발산할 수 있는 새로운 인코더 모델 eM과 페어링할 수 있다. 따라서, 일부 실시 예에서 비교적 높은 빈도로 모델을 공유하는 것은 훈련된 모델의 성능을 향상시킬 수 있다. 본 명세서에 개시된 임의의 프레임워크에서, 노드는 대응하는 양자화 및/또는 역양자화 함수(예를 들어, 근사 및/또는 미분 양자화 및/또는 역양자화 함수)을 사용하여 참조 모델을 포함한 모든 모델을 훈련할 수 있으며, 임의의 모델은 또한 추가 훈련, 검증, 테스트, 추론 등을 위해 대응하는 양자화 및/또는 역양자화 함수를 사용 할 수 있다. 본 명세서에 개시된 임의의 프레임워크로, 하나 이상의 노드는 수집된 훈련 데이터 및/또는 데이터 세트(예를 들어, 채널 추정, 프리코딩 행렬 등)를 하나 이상의 모델을 훈련할 수 있는 다른 장치로 전송할 수 있다. 예를 들어, UE 및/또는 기지국은 수집된 온라인 훈련 데이터 및/또는 하나 이상의 모델을 업로드된 훈련 데이터를 사 용하여 모델 중 하나 이상을 훈련하고 하나 이상의 훈련된 모델을 UE 및/또는 기지국에 다운로드할 수 있는 서 버(예를 들어, 클라우드 기반 서버)에 업로드할 수 있다. 본 명세서에 개시된 프레임워크 중 임의의 것은 제1 유형의 노드가 다른 유형의 노드에 대한 모델을 훈련시키고 훈련된 모델을 제2 유형의 노드의 다수의 인스턴스와 공유할 수 있도록 수정될 수 있다. 예를 들어, 기지국은 그 디코더에 대한 인코더를 훈련할 수 있고 훈련된 인코더를 다수의 UE와 공유할 수 있다. UE 중 하나 이상은 공유 인코더를 적용하여 UE에서 CSI를 압축하고/하거나 추가 온라인 훈련을 위해 공유 인코더를 사용할 수 있다. 더욱이, 본 명세서에서 개시된 프레임워크 중 임의의 것은 노드 중 하나가 기지국이 아닌 시스템에서 구 현될 수 있으며, 예를 들어 사이드링크 통신을 위해 구성된 2개의 UE 또는 다른 피어 디바이스가 있다. 그러한 구현에서, UE는 자신의 인코더에 대한 디코더를 훈련하고 훈련된 디코더를 직접 추론 및/또는 추가 온라인 훈련 을 위한 (예를 들어, 가중치의) 초기 값의 소스로 사용할 수 있는 하나 이상의 다른 UE와 훈련된 디코더를 공유 할 수 있다. 모델 공유 메커니즘 일부 실시 예에서, 노드는 하나 이상의 업링크 및/또는 다운링크 채널, 신호 등과 같은 임의 유형의 통신 메커 니즘을 사용하여 모델, 가중치 등을 전송할 수 있다. 예를 들어 인코더 모델의 공유를 트리거하면, UE는 인코더 모델 및/또는 가중치를 gNB에 전송하기 위해 하나 이상의 MAC 제어 요소(MAC CE) PUSCH를 사용할 수 있다. 유사 하게, gNB는 하나 이상의 MAC CE PDSCH를 사용하여 하나 또는 다수의 UE에서 디코더 모델 및/또는 가중치를 전 송할 수 있다. 구현 세부 사항에 따라, 전체 가중치 세트를 공유하게 되면 모델이 상대적으로 클 수 있고 공유를 위해 상대적 으로 많은 양의 다운링크 및/또는 업링크 자원을 소비할 수 있기 때문에 비효율적일 수 있다. 일부 실시 예는 모델 북으로 지칭될 수 있는 양자화된 모델의 하나 이상의 세트를 설정할 수 있다. 노드가 모델 을 학습시킬 때, 공유가 요청되면 노드는 모델 북에 있는 양자화된 모델 중 하나에 모델을 매핑할 수 있다. 하 나 이상의 모델 북은 노드 간에 일반적으로 공유될 수 있다. 모드를 보내는 것보다, 노드는 모델 북에 매핑된 모델의 인덱스를 보낼 수 있다. 구현 세부 사항에 따라 모델 공유와 관련된 통신 자원이 줄어들 수 있다. 일부 실시 예에서, 모델에 대한 매개변수의 세트가 알려지면, 훈련의 최종 결과가 결정적으로 알려질 수 있다. 예를 들어, 훈련 세트, 초기 가중치를 결정하는 초기 랜덤 시드, 최적화 매개변수(예를 들어, 완전 히 정의된 최적화 매개변수) 및/또는 훈련 절차가 주어지면, 특정 수의 훈련 에포크(예를 들어, 훈련 주기)의 종료시 훈련된 모델은 고유하게 결정될 수 있다. 이러한 매개변수는 예를 들어 최소 기술 매개변수로 지칭될 수 있다. 최소 기술의 크기가 모델에 대한 가중치의 크기보다 작으면, 노드는 가중치가 아닌 최소한의 설명 매개변 수를 공유할 수 있다. 구현 세부 사항에 따라, 이것은 공유 모델과 관련된 통신 오버헤드를 줄일 수 있다. 일부 실시 예에서, 모델의 하나 이상의 값(예를 들어, 노드에서 CSI 인코딩 및/또는 결정 모델의 가중치)은 벡 터 W(예를 들어, 가중치 요소의 벡터)에 배열될 수 있다. 전용 압축 자동 인코더 모델(예를 들어, 인코더 및 디 코더 모델 쌍)은 한 노드의 인코더 및 다른 노드의 디코더로 W를 압축하도록 훈련될 수 있다. CSI 모델의 공유 가 트리거 및/또는 요청되면, 노드는 CSI 모델의 벡터 W를 구성하고 이를 모델 압축 인코더로 인코딩하고 인코 딩된 벡터를 다른 노드로 보낼 수 있다. 다른 노드는 모델 압축 디코더를 사용하여 가중치 벡터 W를 복구할 수 있다. 구현 세부 사항에 따라 공유 모델과 관련된 통신 오버헤드를 줄일 수 있다. 온라인 훈련 처리 시간 노드가 모델의 온라인 훈련을 수행할 수 있는 실시 예에서, 노드는 훈련을 수행하기 위한 자원 허용(예를 들어, 처리 시간, 처리 자원 등의 허용)을 제공받을 수 있다. 이러한 허용은 노드에 의해 수집될 수 있는 온라인 훈련 데이터 세트(예를 들어, 노드에 의해 수행된 측정에 기초한 채널 추정) 또는 RRC가 구성(또는 복원)되거나 MAC- CE가 활성화될 수 있는 온라인 훈련 데이터 세트에 의한 훈련을 위해 제공될 수 있다. 자원 처리 시간 허용은 예를 들어 업데이트된 모델을 다른 노드와 공유하기 위해 노드가 업데이트를 완료할 것으로 예상되기 전에 노드 가 온라인 훈련 데이터 세트를 사용하여 모델을 업데이트하기에 충분한 시간을 가질 수 있도록 보장할 수 있다. 그러나 일부 실시 예에서, 노드는 처리 후 훈련된 모델을 공유할 것으로 예상되는지와 관계없이 처리 시간 여유 가 제공될 수 있다. 예를 들어, UE가 채널 추정치를 계산함으로써 온라인 훈련 데이터 세트를 수집할 수 있는 실시 예에서, UE는 온 라인 훈련 세트에 사용된 최신 CSI-RS의 마지막 심볼의 종료부터 NAIML,upadte 심볼로 결정되는 (예를 들어, 인코더 모델을 업데이트하기 위한) 일정량의 시간을 제공받을 수 있다. UE가 업데이트된 모델을 다른 노드(예를 들어, gNB)에 보고하도록 구성된 경우, UE는 훈련 세트의 최신 CSI-RS의 마지막 심볼부터 NAIML,report 심볼 보다 이전에 모델을 gNB에 보고할 것으로 예상되지 않는다. 다른 예로, UE가 UE에 대해 RRC 구성(또는 복원)되거나 MAC-CE 활성화된 온라인 훈련 데이터 세트를 사용하여 인코더의 온라인 훈련을 수행할 수 있는 실시 예에서, UE는 대응하는 RRC (재)구성이 완료되거나 MAC-CE 활성화 명령이 수신되는 최신 심볼부터 N개의 심볼 보다 이전에 인코더를 업데이트 및/또는 보고할 것으로 예상되지 않 을 수 있다. 도메인 지식을 기반으로 한 사전 처리 압축을 위해, 기계 학습 인코더는 입력 신호를 수신하고 디코더가 입력 신호를 복원하는 데 사용할 수 있는 출 력 특징 세트를 생성할 수 있다. 최대 압축으로, 출력 함수는 서로 독립적일 것으로 예상될 수 있으며, 그렇지 않으면 더 압축될 수 있다. 한 쌍의 기계 학습 모델이 입력으로부터 특징 벡터를 생성하고 특징 벡터로부터 입력을 복원할 수 있지만, 본 개시에 따른 일부 실시 예에서, 생성 모델로의 입력 및/또는 복원 모델로부터의 출력에 대해 하나 이상의 사전 처리 및/또는 사후 처리 동작이 수행될 수 있다. 구현 세부 사항에 따라, 이것은 모델 중 하나 또는 둘 모두의 처리 부담 및/또는 메모리 사용량을 감소하고, 모델 중 하나 또는 둘 모두의 정확도 및/또는 효율성을 개선하고, 및/또는 이와 유사한 것과 같은, 하나 이상의 잠재적인 이점을 제공할 수 있다. 일부 실시 예에서, 사전 처리 및/또는 사후 처리는 입력 신호의 도메인 지식에 기초할 수 있다. 일부 실시 예에 서, 사전 처리 및/또는 사후 처리는 구현 세부 사항에 따라 인코더에 대한 처리 부담을 줄일 수 있는 도메인 지 식으로부터의 보조 정보를 인코더에 제공할 수 있다. 예를 들어, 인코더에 의해 압축되어야 하는 벡터가 비교적 작은 변동을 갖는 저역 통과 신호로 특징지어질 수 있는 경우, 이산 푸리에 변환(DFT) 및/또는 역 DFT(IDFT)가 벡터의 주파수 도메인 표현을 분석하기 위해 수행될 수 있다. DFT 벡터의 DC 성분이 다른 성분보다 큰 경우(예 를 들어, 상당히 큰 경우), 신호는 변동이 낮으므로, 인코더/디코더 쌍에 대한 부담을 줄이기 위해 인코더에 의 한 압축 전에 사전 처리(디코더에 의한 압축해제 후에 사후 처리)될 수 있는 것을 나타낼 수 있다. 일부 실시 예에서, DFT 및/또는 IDFT와 같은 변환 및/또는 역변환을 수행하게 되면 입력 벡터의 요소들 간의 상 관 수준에 대한 더 명확한 이해를 갖는 기계 학습 모델을 제공할 수 있다. 예를 들어, 일부 실시 예에서 (예를 들어, 본원에 개시된 임의의 프레임워크를 사용하여), CSI 행렬은 변환 (예를 들어, DFT/IDFT, 이산 코사인 변 환(DCT)/역 DCT(IDCT) 등)을 입력의 전체 또는 일부, 예를 들어 다른 CSI-RS 포트에 적용할 수 있는 사전 처리 기에 입력될 수 있다. 변환된 신호는 인코더에 입력되고 압축될 수 있다. 디코더 측에서, 디코더의 출력은 복원 된 입력 신호를 생성하기 위해 (예를 들어 사후 처리기로 구현될 수 있는) 사전 처리기 변환의 역 연산자에 적 용될 수 있다.도 11은 본 개시에 따른 사전 처리 및 사후 처리를 갖는 2-모델 훈련 방식의 예시적인 실시 예를 도시한다. 일부 측면에서, 도 11에 예시된 실시 예는 도 3에 예시된 실시 예와 유사할 수 있고, 유사한 구성 요소는 동일한 숫자로 끝나는 참조 지정자로 식별될 수 있다. 하지만, 도 11에 도시된 실시 예는 사전 처리기 및 사후 처리기를 포함할 수 있다. 사전 처리기는 생성 모델에 적용되기 전에 훈련 데이터 에 임의의 유형의 변환을 적용할 수 있다. 유사하게, 사후 처리기는 최종 복원된 훈련 데이터 를 생성하기 위해 임의의 유형의 역변환(예를 들어, 사전 처리기에 의해 적용된 변환의 역)을 복원 모델의 출력에 적용할 수 있다. 일부 실시 예에서, 모델(1103 및 1104)을 훈련하기 위한 손실 함수는 실선(1139 및 1140)으로 도시된 바 와 같이 생성 모델의 입력과 복원 모델의 출력 사이에 정의될 수 있다. 그러나 일부 실시 예에서, 손실 함수는 점선(1141 및 1142)으로 도시된 바와 같이 사전 처리기의 입력과 사후 처리기의 출력 사이에 정의될 수 있다. 모델(1103, 1104)이 도 11에 도시된 바와 같이 훈련되면, 추론에 사용될 수 있다. 사전 처리 및/또는 사후 처리와 관련된 원리는 특정 구현 세부사항으로 제한되지 않지만, 본 발명의 원리를 설 명하기 위해, 도메인 지식에 기반한 사전 처리 및 사후 처리 CSI 행렬을 위한 방식의 예시적인 실시 예는 다음 과 같이 구현될 수 있다. Nrx×Ntx 크기의 채널 행렬을 사용하여, RX 및 TX 안테나의 각 쌍 (i,j)에 대해, 시간 및 주파수 윈도우 내의 모든 자원 요소(RE)에 대한 쌍에 대응하는 채널 요소는 크기 M×N의 결합 행렬 Hi,j를 얻 기 위해 연결될 수 있으며, 여기서 M 및 N은 윈도우의 CSI-RS의 부반송파 및 직교 주파수 분할 멀티플렉싱 (OFDM) 심볼의 수일 수 있다. 일부 실시 예에서, 행렬은 복소수로 가정될 수 있다. 사전 처리 방식의 예시적인 실시 예에서, Hi,j는 예를 들어 DFT 행렬을 사용하여 변환될 수 있다. Ufreq 및 Utime이 각각 M×M 및 N×N DFT 행 렬인 경우, 행렬 Hi,j는 다음과 같이 Xi,j로 변환될 수 있으며: 수학식 2"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이것은 Hi,j의 지연-도플러 표현(DDR)으로 지칭될 수 있다. 행렬 Hi,j는 다음과 같이 DDR에서 복원될 수 있다: 수학식 3"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "일부 실시 예에서, DDR 변환을 사용하면 희소 X 행렬이 생성될 수 있으며, 이는 차례로 학습 및 추론 복잡성을 완화할 수 있다. 일부 실시 예에서, 사전 처리 및/또는 사후 처리 변환을 사용하면 원래 훈련 세트가 해당 DDR 행렬을 변환할 수 있다. 이러한 실시 예에서, CSI 압축은 변환된 훈련 세트를 압축할 수 있는 있다. UE 측에서 사전 처리(예를 들 어, DDR 변환)가 수행될 수 있는 반면, 사후 처리(예를 들어, H를 복구하기 위한 DDR의 역)는 gNB 측에서 수행 될 수 있다. 일부 실시 예에서, 손실 함수는 (예를 들어, 인코더에 대한 변환된 행렬 입력과 도 11에 예시된 바와 같이 디코 더의 변환된 행렬 출력 사이에서) 변환된 행렬에 기초하여 정의될 수 있다. 일부 실시 예에서, 행렬 H는 각 공 간 채널, 예를 들어 각 전송 안테나(포트) 및 각 수신 안테나(포트) 쌍에 대한 시간 및/또는 주파수 도메인에서 개별 CSI 행렬의 합집합에 기초하여 구성될 수 있다. 하나 또는 여러 개의 모델이 각 공간 채널에 대해 훈련되 고 테스트될 수 있다. 일부 실시 예에서, H는 RE의 채널 행렬에 기초하여 구성될 수 있고, 예를 들어, 각각의 행렬은 Nr×Nt의 크기를 가질 수 있으며, 이 때 Nr 및 Nt는 각각 UE에서의 수신 안테나의 개수 및 gNB에서의 전 송 안테나의 개수일 수 있다. CSI 행렬 공식 일부 실시 예에서, UE가 압축할 수 있는 RE 또는 RE의 그룹의 CSI 정보는 CSI 행렬로 지칭될 수 있다. 다중입력 다중출력(MIMO) 채널을 분석한 결과, 용량 분포는 전송 안테나에 걸쳐 가능한 다른 전력 할당을 갖는 가우스 분 포일 수 있다. 채널 행렬이 Hr×t=UΣVH로서 분해되면, 용량 달성 분포는 먼저 를 설정하고 (여기서 x는 평 균과 단위 분산이 0인 독립적으로 동일한 확률 분포되는 가우스 랜덤 벡터) 다음에 수학식 4"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "의 각 요소를 물 채우기 알고리즘에 의해 주어진 전력 할당으로 곱하여 획득된다. i번째 채널에 대한 전력 할당 은 Pi, i=1,…, t일 수 있으며, 여기서 Pi는 채널 행렬 H의 특이값 분해로부터 획득될 수 있다. 그러므로, gNB에 서 사용되는 정보(예를 들어, gNB에서 요구하는 전체 정보)는 오른쪽 특이값 행렬 V와 특이값 자체 모두일 수 있다. 따라서, 일부 실시 예에서, CSI 행렬은 다음 중 임의의 하나 이상으로 공식화(예를 들어, 정의)될 수 있 다: (a) CSI 행렬은 채널 행렬 H로 공식화될 수 있다; (b) CSI 행렬은 V와 특이값의 연결로 공식화될 수 있다; 및/또는 (c) CSI 행렬은 행렬 U로 공식화될 수 있다. 일부 실시 예에서, UE는 RRC (재)구성, MAC-CE 명령을 통해 또는 DCI를 통해 동적으로 상술된 임의의 CSI 행렬 을 보고하도록 구성될 수 있다. CSI 행렬이 (b)(예를 들어, V와 특이값의 연결)에 따라 공식화되는 실시 예에서, UE는 또한 특이값만 보고하도록 구성될 수 있다. 모델 훈련을 위해, UE가 특정 CSI 행렬을 보고하도록 구성될 때 훈련 세트 및/또는 손실 함수는 적용 가능한 CSI 행렬에 기초하여 공식화될 수 있다. 예를 들어, UE가 V를 보고하도록 구성될 때, 훈련 세트는 추정된 채널 행렬들로부터 획득된 V 행렬들을 포함할 수 있고, 손실은 인코더에 입력된 V 행렬 및 디코더의 출력에서 복원된 V 행렬에 기초하여 공식화될 수 있다. 노드 능력 본 명세서에 공개된 프레임워크 중 하나의 구현은 예를 들어, 새로운 훈련 데이터를 저장하고, 노드 간에 모델 을 공유하고, 특정 유형의 신경망 아키텍처(예를 들어, 모델에 대한 CNN 또는 RNN)를 훈련 및/또는 적용하기 위 해, 메모리, 처리 및/또는 통신 자원와 같은 자원의 사용이 포함될 수 있다. UE와 같은 다른 노드는 신경망을 구현하기 위한 다른 능력을 가질 수 있다. 예를 들어, UE는 CNN을 지원할 수도 있고 지원할 수도 있지만 RNN은 지원하지 않을 수 있다. 일부 실시 예에서, UE는 특정 유형, 예를 들어, CNN, RNN 등과 같은 네트워크 유형의 신경망 아키텍처를 지원하기 위한 능력 및/또는 인코더 모델을 적용하기 위한 제한 및 능력을 반영하는 임의의 다른 측면을 보고할 수 있다. 일부 실시 예에서, 노드(예를 들어, UE)는 다음 중 임의의 수를 포함할 수 있는 목록을 사용하여 자신의 능력 및/또는 제한을 보고할 수 있다: (a) 하나 이상의 네트워크 유형, 예를 들어 CNN, RNN, 특정 유형의 RNN, 게이 트 순환 유닛(GRU), 장기 기억 장치(LSTM), 변환기 등; (b) 모델의 크기, 예를 들어 다수의 계층, CNN의 다수의 입력 및/또는 출력 채널, RNN의 다수의 은닉 상태 등과 관련된 하나 이상의 측면; 및/또는 (c) 기타 유형의 구 조적 제한. 보고된 능력에 따라, 노드(예를 들어, UE)는 노드의 보고된 제약 조건을 위반하고/하거나 노드의 선언된 능력을 초과하여 능력을 요구하는 인코더 모델을 훈련하거나 테스트할 것으로 예상되지 않을 수 있다. 일부 실시 예에 서, 이는 적용 가능한 프레임워크 및/또는 모델의 훈련/추론 위치에 관계없이 보장될 수 있다. 예를 들어, gNB 가 인코더 및 디코더를 사전 훈련시키고 인코더 및/또는 디코더를 UE와 공유할 수 있도록 프레임워크가 구현되 는 경우, UE는 인코더 모델이 자신의 능력을 위반할 것으로 예상하지 않을 수 있다. 또 다른 예로, 인코더 및 디코더의 하나 또는 여러 쌍이 오프라인으로 훈련되고 해당 사양(예를 들어, NR 사양)에 지정된 경우, UE는 해 당 모델이 자신의 능력을 위반할 것으로 예상하지 않을 수 있다. 일부 실시 예에서, UE는 시그널링을 통해 하나 이상의 모델을 활성화하는 능력을 보고할 수 있고 어떤 특정 인코더/디코더 쌍, 또는 그것이 지원할 수 있는 개 별 인코더 또는 디코더를 선언할 수 있다. 그 다음, gNB는 어떤 인코더/디코더 쌍이 UE에 적용 가능한지를 UE에지시할 수 있다. 표시는 예를 들어, 시스템 정보, RRC 구성, DCI의 동적 시그널링 등에 의해 제공될 수 있다. 온라인 훈련을 통한 조정 일부 프레임워크에서, UE와 같은 노드는 예를 들어, 새로운 훈련 데이터(예를 들어, 샘플)를 즉석에서 수집하거 나 오프라인 프로비저닝 및 하나 이상의 모델 업데이트를 기반으로 하여, 인코더 모델 또는 인코더 모델과 디코 더 모델 모두를 온라인으로 훈련할 것으로 예상될 수 있다. 노드가 인코더 모델만 업데이트하면 손실 함수도 디 코더 가중치에 따라 달라질 수 있으므로, 인코더 모델 튜닝 및/또는 최적화는 디코더 가중치 및/또는 모델에 따 라 달라질 수도 있다. 그러한 구현에서, 인코더가 gNB 측에서 사용될 수 있더라도, 노드는 디코더 모델의 제한 을 처리하는 능력을 선언할 수도 있다. 이러한 제한 사항은 다음과 같이 하나 이상 적용될 수 있다: 하나 이상의 온라인 훈련 기능 및/또는 미세 조정은 노드에 의해 능력으로 선언될 수 있다; 온라인 훈련을 지원 하는 능력을 보고하는 노드는 인코더 모델에 대해 지원되는 구조에 대한 제한을 추가로 보고할 수 있다; 온 라인 훈련을 지원하는 능력을 보고하는 노드는 디코더 모델에 대해 지원되는 구조에 대한 제한을 추가로 보고할 수 있다; 및/또는 인코더 및 디코딩 쌍을 포함하는 여러 모델이 사양에 지정된 경우, 노드는 인코더 및 디 코더 쌍 또는 노드가 지원할 수 있는 개별 인코더 및/또는 디코더를 나타내는 능력을 선언할 수 있다. 다수 쌍의 모델 일부 실시 예에서, 다수 쌍의 모델(예를 들어, 인코더/디코더 쌍)은 2개의 노드(예를 들어, UE 및 gNB)에서 동 작(예를 들어, 동시 동작)을 위해 훈련 및/또는 배치될 수 있다. 쌍은 a) 인코더와 디코더 모두, b) 인코더만, 또는 c) 디코더만 서로 다를 수 있다. 일부 실시 예에서, 여러 쌍의 모델은 다양한 채널 환경을 처리하도록 지 정될 수 있는 다양한 경우를 처리하도록 구성(예를 들어, 최적화)될 수 있으며 이는 차례로 훈련 및/또는 테스 트 데이터 세트의 다른 분포를 초래할 수 있다. 예를 들어 훈련 데이터의 다른 차원을 수용하기 위해 여러 쌍의 모델이 사용될 수 있다. 예를 들어, CSI 행렬의 차원은 CSI-RS 포트의 개수에 따라 결정될 수 있다. 일부 실시 예에서, UE가 상이한 차원을 갖는 제1 CSI 행렬 H1 및 제2 행렬 H2를 보고하는 경우, 단일 인코더 및 디코더 쌍은 서로 다른 크기의 행렬을 처리하는 데 사용될 수 있다. 그러한 실시 예에서 인코더 및 디코더는 다음과 같이 훈련될 수 있다. 인코더에 입력되는 행렬은 UE와 gNB 사이에서 일반적으로 이해될 수 있는 구성에서 0을 추가함으로써 고정된 크기를 갖도록 복원될 수 있다. 따 라서, 훈련 세트는 행렬을 하나의 고정된 행렬 크기로 변환하기 위해 위에서 설명된 바와 같이 0을 추가함으로 써 수정될 수 있는 상이한 크기의 행렬을 원래 포함할 수 있다. 통신 메커니즘은 예를 들어 UE에 의한 보고에서, 요청되는 CSI 행렬의 크기에 대해 gNB와 UE가 동일한 이해를 공유할 수 있도록 구현될 수 있다. 구현 세부 사항에 따라, 행렬 재차원화 기술이 모든 행렬 크기에 대해 작동할 수 있다. 대안적으로, 또는 추가적으로, 다수의 모델 쌍(예를 들어, 인코더/디코더 쌍)이 훈련될 수 있고, 여기서 상이한 모델 쌍은 상이한 CSI 행렬 크기를 처리하도록 구성될 수 있다. 일부 실시 예에서, 그리고 구현 세부사항에 따라, 복잡성을 증가시키지 않으면서 다수 쌍의 모델을 구현할 수 있다. 예를 들어, 다수 쌍의 모델이 있는 경우, CSI 보고가 특정 수의 CSI-RS 포트에 해당하는 CSI 행렬을 포함 하면, CSI 보고를 계산하기 위한 추론 시간은 단일 쌍보다 다중 쌍에서 더 작을 수 있다. 더구나, 각 RRC 구성 또는 MAC-CE 활성화가 특정 쌍에 해당하는 특정 경우에 대한 CSI 보고를 포함하면, UE는 UE 컨트롤러에 다른 모 델 중 하나 이상을 유지하면서 적용 가능한 모델을 모뎀에 로드할 수 있다. 구현 세부 사항에 따라 모뎀 내부 메모리 사용량을 줄일 수 있다. 다중 쌍을 갖는 실시 예에서, 다음 구성 중 임의의 것에 따라 상이한 쌍이 분류 될 수 있다: (a) 모델의 각 쌍은 특정 CSI 행렬 크기를 처리하도록 구성될 수 있다. 예를 들어, 한 쌍의 모델은 UE에 의해 특정 수의 수신 안테나와 연관되고 또한 특정 수의 포트를 갖는 CSI-RS에 기초하여 추정된 CSI 행렬 을 수신할 수 있다. UE는 자신의 수신 안테나 수를 하나의 보고로 또는 다른 수의 CSI-RS 포트에 대해 별도로 gNB에 보고할 수 있다. (b) 모델의 각 쌍은 훈련 및/또는 테스트 데이터 세트에 대해 상이한 분포를 처리하도록 구성될 수 있다. (c) 모델의 각 쌍은 훈련 및/또는 테스트 데이터 세트에 대해 서로 다른 채널 환경을 처리하도 록 구성될 수 있다. 훈련 세트 연결 및 모델 쌍 구성 모델 쌍이 서로 다른 경우를 처리하도록 구성될 수 있는 실시 예에서, 노드(예를 들어, UE 또는 기지국)는 상이 한 훈련 데이터 세트, 예를 들어 특정 케이스 또는 모델의 쌍(예를 들어, 인코더/디코더 쌍)에 대한 상이한 훈 련 데이터 세트로 구성될 수 있다. 따라서, UE 및/또는 기지국은 상이한 훈련 데이터 세트, 예를 들어 상이한 쌍에 대한 각각의 데이터 세트를 소유할 수 있다. 노드(예를 들어, UE 또는 gNB)에 대한 트리거링이 발생하면,노드는 또한 어떤 쌍의 모델이 훈련되어야 하는지에 대해 신호를 받을 수 있다. 예를 들어, 온라인 훈련을 통해, gNB는 특정 쌍 모델의 훈련을 시작하도록 UE에 지시할 수 있다. 새로운 데이터 세트를 수집함으로써 즉석 에서 온라인 훈련이 수행되면, 예를 들어, CSI-RS 포트의 수를 통해 CSI-RS와 인코더/디코더 쌍 사이에 연관이 제공될 수 있다. 여러 쌍의 모델이 학습되고 추론 단계에서 배포할 준비가 되면, 노드(예를 들어, UE)는 채널 행렬을 인코딩하는 데 어느 쌍을 사용할지를 알아야 할 필요가 있다. 예를 들어, 각 쌍은 인코딩할 CSI 행렬에 대한 특정 차원과 연관될 수 있다. 차원은 인코더 모델에 대한 입력 차원이라고 할 수 있다. 일부 실시 예에서, UE는 다음과 같이 CSI 행렬을 인코딩하기 위해 사용할 모델 쌍을 결정할 수 있다. CSI-RS는 암시적으로 또는 명시적으로 한 쌍의 모델과 연관될 수 있다. UE는 CSI-RS와 관련된 모델 쌍을 사용하여 CSI 행렬을 인코딩한다. 암묵적인 연관성으 로, CSI-RS는 UE에서 CSI-RS 포트의 수 및/또는 수신 안테나의 수에 기초하여 특정 쌍에 매핑될 수 있다. 따라 서, CSI RS로부터 획득된 CSI 행렬의 차원이 쌍의 입력 차원과 동일한 경우 CSI-RS는 쌍으로 매핑될 수 있다. 다수의 쌍이 동일한 적격 입력 차원을 갖는 경우, 참조 쌍은 예를 들어 UE와 gNB 사이에 설정될 수 있는 규칙에 기초하여 선택될 수 있다. 명시적 연관과 함께, CSI 행렬이 보고되는 CSI-RS는 RRC를 통해 구성되거나 예를 들 어 쌍 인덱스를 사용하여, DCI에서 동적으로 표시될 수 있다. 위에 설명된 구현들 중 임의의 것에서, UE가 입력 차원이 다른 한 쌍의 모델을 통해 CSI 행렬을 보고하도록 신 호를 받는 경우, UE는 행렬의 크기를 입력 차원에 일치시키기 위해 0을 추가할 수 있다. 그러나, UE는 CSI 행렬 보다 작은 입력 차원을 갖는 모델 쌍을 사용하여 CSI 행렬을 보고하도록 신호 보내는 것을 예측하지 않을 수 있 다. 축소된 모델 크기로 압축 일부 실시 예에서, 한 쌍의 모델은 CSI 행렬을 압축하고/하거나 CSI 행렬 요소 간의 중복성 및/또는 상관을 활 용하기 위해 자동 인코더로 구성될 수 있다. RE별로 CSI 행렬이 보고되면, 상관은 상이한 쌍의 전송 안테나(예 를 들어, CSI-RS 포트)와 수신 안테나 사이의 상이한 경로들 간의 공간적 상관일 수 있다. 구현 세부 사항에 따 라, 이러한 상관관계의 양은 제한될 수 있고, 따라서 자동 인코더는 CSI 행렬을 충분히 압축하지 못할 수 있다. 일부 실시 예에서, 자동 인코더의 압축 능력은 공간 상관으로 지칭될 수 있는, CSI 행렬의 요소들 간의 상관 및 /또는 중복성의 양과 관련될 수 있다. 무선 채널은 또한 시간 및/또는 주파수 도메인에서 상관될 수 있기 때문 에, 시간 및/또는 주파수 상관도 존재할 수 있다. 그러므로, 다수의 OFDM 심볼 및/또는 다수의 자원 요소(RE), 자원 블록(RB) 또는 부대역에 대한 추정된 채널이 단일 훈련 샘플로서 입력될 수 있다. 예를 들어, 여러 RE에 해당하는 채널 행렬은 자동 인코더에 대한 입력으로 지정될 수 있다. 본 개시에 따른 하나의 그러한 방법에서, UE는 훈련 데이터 세트를 형성하기 위한 시간 및/또는 주파수 자원 번들링을 지정할 수 있는 구성으로 RRC를 통 해 구성될 수 있다. 구현 세부 사항에 따라, 자동 인코더의 압축 성능은 상이한 주파수 및/또는 시간 자원에 걸쳐 다중 RE에 대한 CSI를 압축함으로써 개선될 수 있다. 따라서, 다중 RE의 결합된 CSI 행렬은 시간 및 주파수 윈도우에서 입력될 수 있다. 결합된 CSI 행렬은 그 다음 윈도우에서 RE의 개별 CSI 행렬을 연결함으로써 획득될 수 있다. 구현 세 부 사항에 따라 결합된 CSI 행렬은 채널의 시간 및 주파수 평탄도로 인해 요소 간에 상당한 상관 관계를 가질 가능성이 더 높을 수 있다. 따라서 모델이 결합된 CSI 행렬을 입력으로 사용하면, 개별 RE 행렬에서 작업하는 여러 모델보다 더 높은 수준으로 압축할 수 있다. 일부 실시 예에서, UE는 결합된 CSI 행렬을 결정하기 위해 UE 가 채용할 수 있는 RE를 표시할 수 있는 시간 및/또는 주파수 윈도우 및 하나 이상의 구성으로 구성될 수 있다. 이러한 구성은 결합된 행렬을 얻기 위해 훈련 및/또는 테스트 단계 모두에서 사용될 수 있다. CSI 행렬의 하위집합을 통한 입력 크기 감소 일부 실시 예에서, 자동 인코더는 특정 시간 및 주파수 윈도우에서 상이한 RE의 CSI 행렬을 인코딩할 수 있다. 채널이 채널 행렬의 요소 간의 상관 관계가 존재하지 않거나 특정 도메인(예를 들어, 시간 또는 주파수)에서 강 하지 않도록 되어 있는 경우, CSI 행렬의 합집합의 요소 세트는 상대적으로 강한 하위집합 내 요소 상관 관계 및 상대적으로 약한 하위집합 간 요소 상관 관계를 갖는 하위집합으로 분할될 수 있다. 예를 들어, 자동 인코더 가 동일한 OFDM 심볼에서 4개의 RE의 4개의 CSI 행렬을 압축하는 경우, 행렬은 다음과 같이 표시될 수 있다.수학식 5"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "주파수 도메인의 상관관계가 강하고, 공간 도메인(즉, 한 행렬의 요소 간)에 상관관계가 거의 없거나 전혀 없는 경우, 자동 인코더는 길이 4의 벡터를 압축하도록 구성되고, 자동 인코더는 다음 하위 집합에 대해 네 번 적용 될 수 있다: 하위집합 1(a1,b1,c1,d1); 하위집합 2(a2,b2,c2,d2); 하위집합 3(a3,b3,c3,d3); 및 하위집합 4(a4,b4,c4,d4). 그 다음, CSI 행렬은 예를 들어 동일한 디코더를 사용하여 4개의 벡터를 복원함으로써 디코더에서 복원될 수 있 다. 위에서 언급한 바와 같이, 하위집합은 하나 이상의 도메인에서 하나 이상의 상관관계를 활용할 수 있도록 선택될 수 있다. 추가 설명을 위해 위의 예에서, 공간 영역의 요소 사이에 상관 관계가 있는 경우, 상술된 하위 집합 선택은 네트워크가 CSI 행렬을 추가로 압축하기 위해 상관 관계를 이용하는 것을 방지할 수 있다. 대조적 으로, 다음 하위 집합 선택을 통해 주파수 및 공간 영역 모두에서 상관 관계를 활용할 수 있다: 하위집합 1(a1,a2,b1,b2); 하위집합 2(c1,c2,d1,d2); 하위집합 3(a3,a4,b3,b4); 및 하위집합 4(c3,c4,d3,d4). 일부 실시 예에서, 다음 프레임워크는 이 접근 방식을 기반으로 Nfeatures 입력 차원을 사용하여 축소된 모델 크기 에 사용될 수 있다. UE는 동일하거나 상이한 OFDM 심볼 상에 있을 수 있고 시간 및/또는 주파수 윈도우 내 에 있을 수 있는 M개의 RE의 CSI 행렬을 보고하도록 구성될 수 있다. 각각의 CSI 행렬은 N개의 요소를 가질 수 있다. UE는 M×N개의 요소를 (M×N)/Nfeatures개의 하위집합으로 나눌 수 있다. 하위집합 선택을 위해 UE와 gNB 간에 공통 규칙이 설정될 수 있다. 자동 인코더(예를 들어, 단일 자동 인코더)를 사용하여 각 하위 집 합의 Nfeature 개의 요소를 압축 및 복구할 수 있다. 위에서 설명한 예시적인 하위집합에서, M=N=4 및 Nfeatures=4이 다. 자원 요소 선택을 통한 입력 크기 축소 결합된 입력 행렬의 크기를 줄임으로써 인코더 네트워크의 크기를 줄일 수 있다. 일부 실시 예에서, 예를 들어 동일한 차원의 CSI 행렬 H1 및 H2을 갖는 윈도우에 두 개의 RE가 있는 경우, 결합된 행렬의 크기는 (a) 개별적인 RE별 행렬의 특정 요소를 제거하는 것으로 감소될 수 있다. 결합된 행렬은 H1 또는 H2와 동일한 차원을 갖도록 구성될 수 있지만, H1 또는 H2에서 (i,j) 요소를 선택적으로 선택하는 것에 의해서 이루어진다. 대안적으로, 또 는 추가적으로, 결합 행렬의 크기는 (b) 윈도우의 특정 RE에 대한 CSI 행렬을 배제할 수 있는 행렬을 구성하는 것으로 감소될 수 있다. 이들 예는 2개의 RE 및 2개의 CSI 행렬을 갖는 윈도우가 예시된 표 1에 예시되어 있다. 접근 방식 (a)를 사용하 면 결합된 행렬이 표 1에서와 같이 구성될 수 있는 반면, 접근 방식 (b)에 의하면 결합된 행렬은 두 행렬 중 하 나를 선택하여 구성될 수 있다. 표 1"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "CSI-RS 포트의 수 및 훈련 세트Nport 포트를 갖는 CSI-RS와 UE에서 Nr개의 수신 안테나를 통한 수신으로부터 추정 된 채널 행렬은 Nr×Mport의 차원을 가질 수 있다. 자동 인코더를 사용하여 행렬에서 중복성을 제거할 수 있다.일부 실시 예에서, 중복 패턴을 식별하고/하거나 이를 제거한다는 것은, 훈련 세트가 예를 들어 포트 수가 다른 CSI-RS에 해당하는, 다른 차원의 행렬을 포함하는 경우, 더 어려울 수 있다. 따라서 일부 실시 예에서, 본 명세 서에 개시된 임의의 방법에 대한 훈련 세트는 동일한 차원의 행렬을 유일하게 또는 대부분 포함할 수 있고/있거 나 동일한 수의 CSI-RS 포트와 연관될 수 있다. 따라서, UE는 훈련 세트, 또는 훈련 데이터 세트 행렬의 차원과 다른 차원을 갖는 훈련 세트를 초래하는 CSI 보고 및 측정 구성으로 구성될 것으로 예상되지 않을 수 있다. UCI 포맷 본 명세서에 개시된 임의의 프레임워크로, 생성 모델(예를 들어, ML 인코더)의 출력은 UCI의 유형으로 간주될 수 있다(예를 들어, 인공 지능, 기계 학습(AIML) CSI로 지칭될 수 있음). 일부 실시 예에서, AIML CSI는 연관된 CSI-RS 자원 및 보고 설정과 함께 CSI 보고 및 측정 구성으로부터 획득될 수 있다. 일부 실시 예에서, AIML CSI 는 PUCCH 또는 PUSCH를 통해 gNB로 전송될 수 있다(예를 들어, Rel-15 동작에 이어). 따라서, 업링크 UCI의 일 종으로 물리 계층 정보에 대한 피드백 정보의 표현 포맷이 정해질 수 있다. 포맷은 예를 들어 UCI를 전송하는 데 사용되는 물리 채널의 유형에 따라 달라질 수 있는, 하나 이상의 유형의 코딩(예를 들어, 극성 코딩, 저밀도 패리티 체크(LDPC) 코딩 등)을 포함할 수 있다. 일부 실시 예에서, PUCCH로 업링크 UCI의 유형(예를 들어, AIML CSI)을 전송할 때는 극성 코딩을 사용할 수 있는 반면, PUSCH로 전송할 때는 LDPC 코딩을 사용할 수 있다. 또한, CSI는 코딩 전에 양자화될 수 있다. 따라서 AIML CSI는 비트스트림(0 및 1)으로 양자화되고 극성 코더 또 는 LDPC 코더에 입력될 수 있다. 다양한 네트워크 벤더에 대한 적응성 UE가 네트워크에 접속할 때, 어떤 네트워크 벤더가 연결된 네트워크를 생성했는지 알지 못할 수 있다. 다른 벡 더는 기계 학습 모델에 대해 다른 훈련 기술 및/또는 네트워크 아키텍처를 사용할 수 있으므로, 이 정보의 가용 성은 UE 측의 훈련 모델에 영향을 미칠 수 있다. 따라서, 일부 실시 예에서, 네트워크 표시 또는 AI/ML 인덱스 는 시스템 정보를 통해 (예를 들어, SIB 중 하나를 통해) UE에 제공될 수 있다. 그런 다음 UE는 이 정보를 사용 하여 자신의 훈련을 특정 네트워크 벤더 구성에 적용할 수 있다. ML 모델 수명 주기 관리 일부 ML 애플리케이션에서, ML 모델의 성능은 시간이 지남에 따라 저하될 수 있으며, 훈련된 애플리케이션의 기 간 동안 적절하게 수행되지 않을 수 있다. 따라서, ML 모델은 동작 환경에서 발생할 수 있는 일시적인 변화, 예 를 들어, CSI 압축의 경우 무선 채널의 통계적 변화에 적응하기 위해 자주 업데이트될 수 있다. 본 개시에 따른 일부 실시 예는 수용 가능한 오버헤드를 갖는 하나 이상의 ML 모델의 효율적 및/또는 시기적절 한 업데이트를 가능하게 하는 관리 프레임워크를 제공할 수 있다. 그러한 프레임워크를 용이하게 하기 위해, 일 실시 예는 노드가 ML 모델의 성능을 추적할 수 있는 모델 모니터링을 구현할 수 있다. 일부 실시 예에서, 이것 은 노드가 ML 모델의 성능을 추적할 수 있는 모델 모니터링이 포함될 수 있다. 모델 모니터링은 다음과 같이 하 나 이상의 성능 메트릭을 기반으로 할 수 있다. 작업 기반 메트릭은 ML 모델에 의해 수행되는 작업의 성능 을 (예를 들어, 직접) 평가하는 데 사용할 수 있다. 예를 들어, 이러한 메트릭은 정확도, 평균 제곱 오차(MSE) 성능 등을 포함할 수 있다. 시스템 기반 메트릭을 사용하여 시스템의 전체 성능, 예를 들어, 시스템의 노드 에 의해 사용되는 ML 모델의 성능에 대한 덜 직접적인 측정을 제공할 수 있는 전송의 정확한 디코딩 또는 기타 시스템 수준 핵심 성과 지표(KPI)를 추적할 수 있다. ML 모델의 성능이 합의 및/또는 구성된 메트릭에 따라 수용할 수 없는 것으로 간주되는 경우, 관리 프레임워크 는 ML 모델 업데이트 절차를 시작할 수 있다. 예를 들면, 하나 이상의 합의 및/또는 구성된 메트릭에 따라 ML 모델 성능이 허용되지 않는 경우; 및/또는 ML 모델의 성능이 임계 시간보다 긴 특정 기간 동안 허용되지 않는 경우, 성능은 허용 불가능한 것으로 간주될 수 있다. 허용 불가능한 성능을 결정하기 위한 임계값은 구성된 및/또는 지정된 매개변수로 구현될 수 있다. 지속 시간은 i) 누적적으로 측정되어, 예를 들어 허용 불가능한 성능의 기간이 전역 카운터에 추가될 수 있으며, 전역 카운 터 값이 임계값과 비교되거나, ii) 연속적으로 측정되어, 예를 들어 임계값보다 더 큰 허용 불가능한 성능의 연 속적인 기간만이 고려될 수 있다. ML 모델의 성능이 허용할 수 없는 것으로 간주되는 경우, 관리 프레임워크는 다음 방식 중 하나로 구현될 수 있 는 업데이트 절차를 트리거할 수 있다. 관리 프레임워크는 예를 들어 도 8과 관련하여 설명된 대로 전체 훈 련 절차를 요구할 수 있다. 이 경우, ML 모델을 처음부터 다시 학습하거나 현재 ML 모델부터 다시 학습할 수 있 다. 이 경우 훈련은 최근에 획득했을 수 있는 추가 데이터 샘플의 유무에 관계없이 전체 훈련 데이터 세트를 사용할 수 있다. 관리 프레임워크는 ML 모델이 현재 ML 모델에서 시작하여 아마도 최근에 획득한 새로운 데이 터 샘플을 사용하여 재학습될 수 있는 부분적인 훈련을 요구할 수 있다. 훈련 및 테스트의 성능 지표 CSI 압축 작업에 대한 상이한 모델의 성능을 평가하기 위해, 본 개시에 따른 일부 실시 예는 CSI 압축의 양상에 초점을 맞출 수 있다. 그러한 실시 예에서, 상이한 모델들은 CSI 행렬을 압축하고 CSI 행렬을 복구하여 복구된 행렬이 실제 CSI 행렬에 가능한 한 근접하도록 각각의 능력에 기초하여 비교될 수 있다. 근접성의 결정은 CSI 행렬을 갖는 gNB의 동작과 관련될 수 있다. 예를 들어 gNB가 채널 행렬의 SVD를 Hr×t=UΣVH을 계산하여 오른쪽 특이 벡터 V를 사용하여 프리코더를 결정하면, 근접도는 인코더의 입력에서 V 와 디코더의 출력에서 복구된 V 사이에서 결정될 수 있다. 일부 실시 예에서, 두 행렬 간의 근접성 메트릭은 요소별로 구현될 수 있으며, 평균은 단일 손실 값을 제공하기 위해 일부 또는 모든 요소에 대해 취해질 수 있다. 대안적으로, 또는 추가적으로, 행렬에 하나 또는 몇 개의 잘 못된 요소를 갖게 되면 많은 잘못된 요소를 갖는 것만큼 해로울 수 있다. 이 경우, 손실 함수는 예를 들어, 행 렬의 모든 요소에 대한 요소별 오류의 최대값과 같은 행렬 방식 기반으로 결정될 수 있다. 일부 실시 예에서, CSI 인코더 및 디코더 모델의 성능은 시스템의 다른 블록과 함께 평가될 수도 있다. 예를 들 어, 블록 오류율(BLER)이 시스템 성능 메트릭으로 사용되는 경우, 서로 다른 CSI 모델 간의 비교는 결과 BLER를 기반으로 할 수 있다. 처리량, 자원 사용률 등과 같은 다른 시스템 KPI도 이 용도로 사용할 수 있다. BLER가 관심 메트릭인 실시 예에서, CSI 행렬에 의해 제공되는 정보를 사용하도록 gNB를 구성하는 것은 시스템 성능에 영향을 미칠 수 있다. 예를 들어, UE가 전송한 채널 행렬이 gNB에서 완전히 복구되고 채널 행렬이 순위 1 채널을 나타낸다는 점에서 CSI 모델이 완벽하다고 가정하면, gNB가 순위 2 PDSCH를 스케줄링하는 경우 디코딩 이 실패할 가능성이 있다. 그러므로, CSI 모델의 압축 기능과 시스템 성능 간의 연결을 설정하기 위해서, gNB 동작과 관련한 가정이 사용될 수 있다. 일부 실시 예에서, 함수 fgNB를 처리하는 gNB는 디코더의 출력, 예를 들 어 를 취하고 결과 BLER의 추정치를 로 제공하도록 정의될 수 있다. 훈련 중 손실 함수는 CSI 압축 및 gNB 운영 측면을 모두 고려하여 정의될 수 있다. 예를 들어, 손실은 다음과 같이 두 항의 가중 합으로 정의될 수 있다: 수학식 6"}
{"patent_id": "10-2023-0116314", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기에서 α와 β는 훈련을 위한 하이퍼매개변수이다. 업링크 채널의 신뢰성 측면 일부 실시 예에서, CSI 코드워드라고도 하는 인코더의 출력은 디코더 측에서 오류 없이 이용 가능한 것으로 가 정될 수 있다. 따라서, CSI 코드워드는 PUCCH 및/또는 PUSCH 디코딩이 실패하지 않도록 무한 신뢰도로 업링크 채널에서 PUCCH 또는 PUSCH를 통해 전송될 수 있다. 그러나 어떤 경우에는 추론 단계에서, CSI 코드워드는 예를 들어 PUSCH/PUCCH 디코딩이 실패할 때 하나 이상의 오류와 함께 gNB(디코더)에 전달될 수 있다. 그러한 경우에, CSI 코드워드의 잡음 버전이 디코더에서 이용가능할 수 있다. 훈련 단계 동안 업링크 채널의 불완전성의 영향은 다음과 같이 모델링될 수 있다. 인코더에 대한 각 훈련 예제 입력에 대해, 인코더의 출력에서 CSI 코드워드는 x로 표시될 수 있다. 업링크 채널 의 불완전성을 고려할 때, 디코더 y에 대한 입력은 다음과 같이 모델링될 수 있다: 수학식 7 여기에서 ω는 업링크 채널의 디코딩 후 잔여 오차를 모델링할 수 있는 가산 잡음이다. 훈련 단계에서 가산 잡 음은 다음과 같이 생성될 수 있다. 방법 1에서, ω는 평균이 0이고 분산이 σ2인 가우스 랜덤 벡터로 모델링될 수 있다. 분산은 RRC 구성을 통해 UE에 표시되거나 UE 구현에 남겨질 수 있다. 방법 2에서, x와 y 사이의 채널은 각 훈련 예에 대해 PUCCH 및/또 는 PUSCH 디코딩을 수행하고, 잔차 오차 벡터 ω를 구하고, 다음에 벡터가 x에 추가되어 y를 얻는다고 가정함으 로써 모델링될 수 있다. 연합 학습 측면 연합 학습(FL)에 의하면, 서버의 전역 모델은 서버에 연결된 여러 노드에서 개별 학습을 통해 학습하고 학습된 모델을 서버와 공유할 수 있다. 서버는 다음에 수신된 모델에 대해 하나 이상의 작업을 수행하여 최종 모델을 얻을 수 있다. 그러한 배열은, 예를 들어, 프라이버시 측면 및/또는 노드의 데이터를 서버와 공유하지 않기 위 한 요구 사항에 동기를 부여할 수 있다. CSI 압축 사용 사례에서, 서버는 gNB로 간주될 수 있고 gNB에 연결된 다른 UE는 모델 업데이트 노드로 간주될 수 있다. 상이한 UE는 동일하거나 상이한 분포를 갖는 상이한 훈련 세트를 가질 수 있다. 분포가 동일하면, 각 UE는 모델을 자체 훈련 세트로 업데이트하고 모델을 gNB와 공유할 수 있다. 그 다음, gNB는 예를 들어 최종 모 델을 획득하기 위해 모델을 평균화하는 것과 같은 하나 이상의 동작을 수행할 수 있다. gNB는 획득한 최종 모델 을 자신의 모델을 공유한 UE와 공유할 수 있다. 최종 모델은 모든 참가자 UE에 대한 모든 훈련 세트의 합집합을 기반으로 훈련되기 때문에 개별 수신 모델보다 성능이 좋을 것으로 예상될 수 있다. 따라서 CSI 압축 성능을 향 상시키기 위해 FL이 사용될 수 있다. 다른 UE에서 사용 가능한 다른 분포의 경우, FL은 분포를 본 UE가 공유하 는 모델을 통해 특정 UE가 아직 보지 못한 분포를 캡처하는 데 도움이 될 수 있다. 어쨌든, FL은 UE가 관찰하는 다양한 환경을 고려한 모델을 얻는 데 사용될 수 있다. 본 개시에 따른 FL 프레임워크로, gNB는 UE의 그룹이 FL 그룹에 있도록 구성할 수 있다. 동일한 FL 그룹의 UE는 동일한 인코더 및/또는 디코더(예를 들어, 자동 인코더 또는 AE) 아키텍처를 갖도록 구성될 수 있다. 따라서, 인코더와 디코더는 실제로 훈련된 가중치는 서로 다를 수 있지만 계층 수, 단위 수, 활성화 기능 및 네트워크 구조를 정의하는 기타 매개변수 측면에서 동일한 구성을 갖는다. 인코더 및 디코더 모델에 대한 입력의 크기는 그룹의 UE에 대해 동일하거나 유사할 수 있다. 인코더에 대한 입 력은 또한 UE에 대해 동일하거나 유사한 의미를 가질 수 있다. 예를 들어, UE(예를 들어, 모든 UE)의 인코더에 대한 입력은 채널 행렬 또는 특이값 행렬 V일 수 있다. gNB는 모델을 업데이트하고 gNB와 업데이트를 공유하도 록 RRC, DCI 또는 MAC CE 명령을 통해 UE에 지시할 수 있다. 일부 실시 예에서, 그룹의 모든 UE가 동시에 업데 이트 절차에 참여하는 것은 아니다. gNB는 그룹 공통(GC) DCI를 통해 훈련, 하이퍼매개변수 및/또는 FL의 다른 측면에 관한 정보를 보낼 수 있으며, 여기서 동일한 FL 그룹의 UE는 RRC를 통해 구성된 DCI의 특정 부분을 가질 수 있다. 추가 실시 예 도 12는 본 개시에 따른 2-모델 방식을 사용하기 위한 시스템의 실시 예를 예시한다. 도 12에 예시된 실시 예는 하나 이상의 모델을 테스트하는 맥락에서 설명될 수 있지만, 동일하거나 유사한 실시 예는 본 명세서에서 개시된 모델 중 임의의 것, 예를 들어, 훈련 후 도 3에 예시된 생성 모델 및/또는 복 원 모델로 검증, 추론 등을 위해 사용될 수도 있다. 도 12를 참조하면, 시스템은 생성 모델을 갖는 제1 노드(노드 1) 및 복원 모델을 갖는 제2 노드(노드 B)를 포함할 수 있다. 테스트 데이터는 테스트 데이터의 표현을 생성할 수 있는 생성 모 델에 적용될 수 있다. 복원 모델은 테스트 데이터의 표현에 기초하여 테스트 데이터의 복원 을 생성할 수 있다. 일부 실시 예에서, 생성 모델은 표현을 통신 채널을 통해 전송될 수 있 는 양자화된 형태(예를 들어, 비트 스트림)로 변환하기 위한 양자화기를 포함할 수 있다. 유사하게, 일부 실시 예에서, 복원 모델은 양자화된 표현(예를 들어, 비트 스트림)을 복원된 테스트 데이터를 생 성하기 위해 사용될 수 있는 형태로 변환할 수 있는 역양자화기를 포함할 수 있다. 생성 모델 및 복원 모델은 본 명세서에서 설명된 프레임워크 중 임의의 것을 사용하는 것을 포함하 는 임의의 방식으로 획득될 수 있다. 예를 들어, 공동 훈련 프레임워크를 사용하여, 생성 모델 및 복원 모델은 복원 모델을 노드 B로 전송할 수 있는 노드 A에서 쌍으로 훈련될 수 있다. 다른 실시 예는생성 모델 및 복원 모델을 획득 및/또는 훈련하기 위해서, 참조 모델이 있는 훈련 프레임워크, 최 신 공유 값이 있는 훈련 프레임워크, 또는 임의의 다른 프레임워크 및/또는 기술을 사용할 수 있다. 도 13은 본 개시에 따른 사용자 장치(UE)의 예시적인 실시 예를 예시한다. 도 13에 예시된 실시 예는 무선 송수신기 및 송수신기 및/또는 UE의 임의의 다른 구성 요소의 동작을 제어할 수 있는 제어기를 포함할 수 있다. UE는, 예를 들어, 기지국으로부터의 하나 이상의 참조신호에 기초하여 채널 정보를 결정하는 단계, 기계 학습 모델을 사용하여 채널의 상태에 기초하여 채널 정보의 표현을 생성하는 단계, 채널 정보의 표현을 전송하는 단계, 예를 들어 윈도우 동안 훈련 데이터를 수집하는 단계, 예를 들어, CSI 행렬에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이상의 ML 모델 쌍 을 배포 및/또는 활성화하는 단계를 포함하여, 본 개시에서 설명된 모든 기능을 구현하기 위해 사용될 수 있다. 송수신기는 기지국으로/기지국으로부터 하나 이상의 신호를 전송/수신할 수 있으며, 이러한 전송/수신을 위한 인터페이스 유닛을 포함할 수 있다. 예를 들어, 송수신기는 기지국으로부터 하나 이상의 신호를 수 신할 수 있고/있거나 채널 정보의 표현을 UL 채널을 통해 기지국으로 전송할 수 있다. 제어기는, 예를 들어, 하나 이상의 프로세서 및 본 개시에서 설명된 임의의 기능을 구현하기 위한 코드를 실행하기 위한 하나 이상의 프로세서에 대한 명령을 저장할 수 있는 메모리를 포함할 수 있 다. 예를 들어, 제어기는 본 명세서에 개시된 바와 같이 하나 이상의 기계 학습 모델을 구현할 뿐만 아니 라, 기지국으로부터의 하나 이상의 참조신호에 기초하여 채널 정보를 결정하고, 기계 학습 모델을 사용하여 채 널의 상태에 기초하여 채널 정보의 표현을 생성하고, 채널 정보의 표현을 전송하고, 예를 들어, 윈도우 동안 훈 련 데이터를 수집하고, 예를 들어, CSI 행렬에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이상의 ML 모델 쌍을 배포 및/또는 활성화하는 등을 위해 구성된다. 도 14는 본 개시에 따른 기지국의 예시적인 실시 예를 예시한다. 도 14에 예시된 실시 예는 무선 송수신기 및 송수신기 및/또는 기지국의 임의의 다른 구성요소의 동작을 제어할 수 있는 제어기를 포함할 수 있다. 기지국은 예를 들어, DL 채널을 통해 UE에 하나 이상의 참조 신호를 전송하고, 채널 정보의 표현을 복원하고, 예를 들어, CSI 행렬에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이상의 ML 모델 쌍을 배포 및/또는 활성화하는 단계를 포함하여, 본 개시 에 설명된 모든 기능을 구현하기 위해 사용될 수 있다 송수신기는 사용자 장치로/로부터 하나 이상의 신호를 전송/수신할 수 있고, 이러한 전송/수신을 위한 인 터페이스 유닛을 포함할 수 있다. 예를 들어, 송수신기는 DL 채널을 통해 UE에 하나 이상의 참조 신호를 전송하고/하거나 UL 채널을 통해 UE로부터 프리코딩 정보를 수신할 수 있다. 제어기는, 예를 들어, 하나 이상의 프로세서 및 본 개시에서 설명된 기지국 기능 중 임의의 것을 구현하기 위한 코드를 실행하기 위한 하나 이상의 프로세서에 대한 명령을 저장할 수 있는 메모리 를 포함할 수 있다. 예를 들어, 컨트롤러는 본 명세서에 개시된 하나 이상의 기계 학습 모델을 구현할 뿐 만 아니라, DL 채널을 통해 UE에 하나 이상의 참조 신호를 전송하고, 채널 정보의 표현을 복원하고, 예를 들어, CSI 행렬에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이상의 ML 모델 쌍을 배포 및/또는 활성화하는 등을 위해 사용될 수 있다. 도 13 및 14에 예시된 실시 예에서, 송수신기(1302 및 1402)는 증폭기, 필터, 변조기 및/또는 복조기, A/D 및/ 또는 DA 변환기, 안테나, 스위치, 위상 천이기, 검출기, 커플러, 도체, 전송선 등과 같은 RF 신호를 수신 및/또 는 전송하기 위해 다양한 구성요소로 구현될 수 있다. 제어기(1304 및/또는 1404)는 하드웨어, 소프트웨어, 및/ 또는 이들의 임의의 조합으로 구현될 수 있다. 예를 들어, 전체 또는 부분 하드웨어 구현은 조합 논리, 순차 논 리, 타이머, 카운터, 레지스터, 게이트 어레이, 증폭기, 합성기, 멀티플렉서, 변조기, 복조기, 필터, 벡터 프로 세서, 복합 프로그램 가능 논리 장치(CPLD), 필드 프로그램 가능 게이트 어레이(FPGA), 주문형 집적 회로 (ASIC), 시스템 온 칩(SOC), 상태 머신, ADC 및 DAC와 같은 데이터 변환기 등을 포함한다. 전체 또는 부분 소프 트웨어 구현은 하나 이상의 프로세서 코어, 메모리, 프로그램 및/또는 데이터 저장소 등을 포함할 수 있다. 로 컬 및/또는 원격에 위치할 수 있고 컨트롤러의 하나 이상의 기능을 수행하기 위한 명령을 실행하도록 프로그래 밍될 수 있다. 일부 실시 예는 임의의 유형의 메모리, 그래픽 처리 장치(GPU), 신경 처리 장치(NPU), 텐서 처리 장치(TPU) 등에 저장된 명령어를 실행하는, 마이크로컨트롤러와 같은 하나 이상의 프로세서, x86 프로세서와 같 은 복합 명령 세트 컴퓨터(CISC) 프로세서와 같은 CPU, 및/또는 ARM 프로세서 등과 같은 ㄱ가감소된 명령 세트 컴퓨터(RISC) 프로세서를 포함할 수 있다. 도 15는 본 개시에 따라 물리 계층 정보 피드백을 제공하기 위한 방법의 실시 예를 예시한다. 방법은 단계에서 시작할 수 있다. 단계에서, 방법은 무선 장치에서 무선 장치에 대한 물리 계층 정 보를 결정할 수 있다. 단계에서, 방법은 기계 학습 모델을 사용하여 물리 계층 정보의 표현을 생성할 수 있다. 단계에서, 방법은 사용자 장치로부터, 무선 장치로부터 물리 계층 정보의 표현을 전송할 수 있다. 방법은 단계에서 종료할 수 있다. 도 15에 도시된 실시 예 및 본 명세서에서 개시된 임의의 실시 예에서, 예시된 구성요소 및/또는 동작은 단지 예시일 뿐이다. 일부 실시 예는 다양한 추가 구성요소 및/또는 예시되지 않은 동작을 포함할 수 있으며, 일부 실시 예는 일부 구성요소 및/또는 동작을 생략할 수 있다. 더욱이, 일부 실시 예에서, 구성요소의 배열 및/또는 동작의 시간적 순서가 변경될 수 있다. 일부 구성 요소는 개별 구성 요소로 표시될 수 있지만, 일부 실시 예에 서, 별도로 표시된 일부 구성 요소는 단일 구성 요소로 통합될 수 있고/있거나, 단일 구성 요소로 표시된 일부 구성 요소는 다중 구성 요소로 구현될 수 있다. 프리코딩 및 채널 정보 불일치 NR 시스템에서, UE는 gNB에 의해 전송되는 참조 신호(예를 들어, CSI-RS 또는 DMRS)를 기반으로 다운링크 채널 상태를 측정할 수 있다. UE는 UE가 gNB에 보고할 수 있는 프리코딩 행렬 및/또는 채널 품질 표시자(CQI)와 같은 채널 정보를 결정(예를 들어, 계산)하기 위해 채널 측정을 사용할 수 있다. UE는 gNB가 보고된 프리코딩 행렬을 후속 전송에 적용하는 경우 다운링크 전송을 위한 양호한(예를 들어, 이용 가능한 최상의) 등가 채널이 결과될 수 있는 프리코딩 행렬을 계산할 수 있다. UE가 프리코딩 행렬을 기반으로 계산할 수 있는 CQI는, gNB가 보고된 프리코딩 행렬을 사용할 경우 예상할 수 있는 채널 품질을 나타낼 수 있다. 보고된 CQI는 예를 들어, 보고된 프 리코딩 행렬을 사용하여 gNB에 의한 후속 전송을 위해, 변조 순서, 코드 속도 등을 선택하는 데 사용될 수 있다. 상술한 바와 같이, CQI는 프리코딩 행렬에 기초하여 계산될 수 있다. 따라서, 채널 품질 정보(예를 들어, CQI) 를 정확하게 결정하는 것은 gNB에 의해 적용되는 프리코딩 정보(예를 들어, 프리코딩 행렬)에 대한 UE의 지식 또는 가정을 포함하거나 요구할 수 있다. (예를 들어, UE에 의해 보고된 RI 및/또는 PMI를 사용하여) 프리코딩 행렬을 결정하기 위해 코드북이 사용될 수 있는 NR 시스템에서, UE는 gNB에 의해 CSI-RS에 적용되는 프리코딩 행렬에 대한 지식을 가질 수 있다. 그러나, 채널 정보를 보고하기 위해 기계 학습 프레임워크를 사용하는 시스템에서, UE는 gNB가 적용한 프리코딩 정보에 대한 지식이나 가정을 갖고 있지 않을 수 있다. 예를 들어, 일부 실시 예에서, 한 쌍의 모델(예를 들어, UE의 인코더 및 gNB의 디코더)은, 채널 행렬이 UE의 인코더에 대한 입력으로 적용되는 경우 gNB의 디코더가 프 리코딩 행렬을 직접 출력할 수 있도록 훈련될 수 있다. 이러한 실시 예는 예를 들어, 도 7에 도시된 구성을 사 용하여 구현될 수 있으며, 이 때 채널 상태 정보는 참조 신호를 측정하여 결정된 채널 행렬로 구현되 고 UE의 기계 학습 인코더에 적용될 수 있다. 그러한 실시 예에서, 채널 상태 정보의 복원은 gNB에서 기계 학습 디코더의 출력으로서 (예를 들어, 직접) 획득될 수 있는 프리코딩 행렬로서 구현 될 수 있다. 이러한 실시 예는 예를 들어 훈련 데이터가 데이터 쌍을 포함할 수 있는 도 3에 도시된 구성을 사용하여 훈련될 수 있으며, 여기서 각 쌍은 채널 행렬과 채널 행렬에 기초하여 UE에 의해 계산된 대응 프리코딩 행렬을 포함할 수 있다. 훈련 중에, 채널 행렬은 생성 모델에 대한 입력으로 적용될 수 있고, 대응하는 프리코딩 행렬은 (예를 들어, 손실 함수에 대한) 훈련 목표로 사용될 수 있고, 이에 의해 복원 모델이 출력 데 이터를 프리코딩 행렬로서 생성할 수 있게 된다. 그러나 그러한 실시 예에서, UE는 gNB에 의해 사용되는 훈련된 디코더에 액세스하지 않을 수 있다. 예를 들어, 도 7을 참조하면, 인코더 및 디코더는 인코더만을 UE에 전달하고 디코더만을 gNB에 전달할 수 있는 네트워크에 의해 훈련될 수 있다. 다른 예로, gNB는 인코더 및 디코더 를 훈련하고 인코더만 UE에 전달할 수 있다. 따라서, UE는 UE가 gNB에 (예를 들어, 인코더 의 출력의 형태로) 보고할 수 있고, gNB가 디코더를 사용하여 복원할 수 있는 프리코딩 행렬을 결정할 수 없다. (gNB가 프리코딩 행렬을 복원할 수도 있지만, 일부 시스템에서는 복원된 프리코딩 행렬이 나 UE가 이전에 보고한 프리코딩 행렬을 사용할 필요가 없을 수도 있다.) 따라서, UE는 채널 품질 정 보를 계산하는 데 사용할 프리코딩 행렬에 액세스할 수 없다. 구현 세부 사항에 따라, 프리코딩 정보와 UE가 gNB에 보고하는 채널 품질 정보간의 불일치가 결과될 수 있다. 일부 실시 예에서, 이 맥락에서 사용되는 바와같이, 불일치는 무선 장치에 보고된 채널 품질 정보가 무선 장치에 보고된 해당 프리코딩 정보에 적절하게 기초 하지 못하는 상황을 의미할 수 있다. 본 개시에 따른 일부 실시 예에서, 제1 무선 장치(예를 들어, UE)는 제1 무선 장치가 프리코딩 정보에 기초하여 채널 품질 정보(예를 들어, CQI)를 결정할 수 있도록 하기 위해서 제2 무선 장치(예를 들어, gNB)에 의해 사용 되는 프리코딩 정보(예를 들어, 프리코딩 행렬)를 결정할 수 있다. 구현 세부 사항에 따라, 이는 프리코딩 정보 와 제1 무선 장치에 의해 제2 무선 장치에 보고되는 채널 품질 정보 사이의 불일치를 줄이거나 제거할 수 있다. 도 16은 본 개시에 따라 채널 정보 피드백을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 예시한다. 도 16에 도시된 시스템은 본 명세서에 개시된 장치, 모델, 훈련 방식 등 중 임의의 것을 구현하는 데 사 용될 수 있거나 구현될 수 있다. 시스템은 유사한 요소가 동일한 숫자, 문자 등으로 끝나거나 이를 포함 하는 참조 번호로 표시될 수 있는 도 4 및/또는 도 7에 도시된 실시 예의 것과 유사할 수 있는 하나 이상의 요 소(예를 들어, 구성요소, 동작 등)를 포함할 수 있다. 도 16에 도시된 시스템에서, 제1 무선 장치(예를 들어, UE)는 제1 무선 장치가 채널 의 채널 상태를 결정할 수 있도록 하기 위해, 채널을 통해 제2 무선 장치(예를 들어, 기지국)로부 터 신호(예를 들어, 참조 신호)를 수신할 수 있다. 제2 무선 장치는 후속 송신(예를 들어, PDCCH, PDSCH 등)에 프리코딩 정보(예를 들어, 프리코딩 행렬)를 적용할 수 있다. 제1 무선 장치는 프리코딩 결정 로직을 포함할 수 있다. 추가적으로 또는 대안적으로, 제2 무선 장 치는 공유 로직을 포함할 수 있다. 프리코딩 결정 로직 및/또는 공유 로직은 제1 무선 장치가 프리코딩 정보(또는 그의 복원)를 결정(예를 들어, 계산)할 수 있게 하고, 이어서 제1 무선 장치가 채널 품질 정보를 결정할 수 있게 하는 하나 이상의 방식을 개별적으로 및/또는 협력하여 구현할 수 있다. 구현 세부 사항에 따라, 제1 무선 장치가 제2 무선 장치에 의해 적용된 프리코딩 정보를 결정할 수 있게 되면 프리코딩 정보(또는 그의 복원)와 제1 무선 장치에 의해 제2 무 선 장치에 보고되는 채널 품질 정보 사이의 불일치를 줄이거나 제거하는 데 도움이 될 수 있다. 일부 예시적인 실시 예에서, 제1 무선 장치는 복원 모델(예를 들어, 디코더 모델)을 사용하여 프리코딩 정보의 복원을 생성할 수도 있다. 예를 들어, 제2 무선 장치의 공유 로직은 복원 모델 (예를 들어, 모델 크기, 치수, 가중치 등에 대한 정보)을 전송된 모델이 공유 모델(1604A)로 표시될 수 있는 제1 무선 장치에 전달할 수 있다. 이러한 실시 예는 예를 들어, 인코더로 구현되는 생성 모델 및 디코더로 구현되는 복원 모델을 사 용하여 구현될 수 있다. 제2 무선 장치는 (예를 들어, 자동 인코더 구성에서) 인코더 및 디코더 를 훈련할 수 있다. 제2 무선 장치의 공유 로직은 예를 들어 오버디에어(OTA; over-the- air) 전송을 사용하여 인코더 및 디코더(1604A) 모두를 제1 무선 장치에 전송할 수 있다. 제1 무선 장치는 예를 들어 채널 측정치(예를 들어, 채널 행렬)를 포함할 수 있는 채널 정보에 기초하여 표 현을 생성하기 위해 인코더를 사용할 수 있다. 제2 무선 장치는 표현으로부터 프리코 딩 정보(예를 들어, 프리코딩 행렬)를 생성하기 위해 디코더를 사용할 수 있다. 하지만, 제1 무선 장치는 또한 디코더(1604A)를 수신할 수 있기 때문에, 프리코딩 정보와 동일하거나 유사할 수 있는 복원된 프리코딩 정보(예를 들어, 프리코딩 행렬)를 생성하기 위해 디코더(1604A)를 사용할 수 있다. 다 음에 제1 무선 장치는 채널 품질 정보를 결정하기 위한 계산을 수행하기 위해 복원된 프리코 딩 정보를 사용할 수 있다. 제1 무선 장치는 임의의 적절한 방식으로 채널 품질 정보를 제2 무선 장치에 전송할 수 있다. 예를 들어, 제1 무선 장치는 생성 모델에 의해 생성된 표현과 채널 품질 정보를 (예를 들어, 표현에 채널 품질 정보를 추가하는 것으로) 결합할 수 있고 다른 채널(예를 들어, 업 링크 채널), 신호 등을 사용하여 결합된 채널 품질 정보 및 표현을 제2 무선 장치에 전송할 수 있다. 일부 실시 예에서, 제2 무선 장치는 표현을 복원 모델에 적용하기 전에 결 합된 정보로부터 채널 품질 정보를 제거할 수 있다. 또 다른 예로서, 제1 무선 장치는 제1 및 제2 무선 장치(1601, 1602)가 동작할 수 있는 무선 네트워크 상 의 서버로부터 복원 모델(1604A)을 (예를 들어, OTA 전송을 사용하여) 수신할 수 있다. 그러한 실시 예에서, 복 원 모델(1604A)은 네트워크에 식별 및/또는 등록될 수 있고, 네트워크는 모델 식별자를 사용하여 복원 모델 (1604A)을 활성화할 수 있다. 복원 모델(1604A)이 제2 무선 장치에 의해 제1 무선 장치와 공유되는경우, 제2 무선 장치는 활성화된 생성 모델에 대응하는 복원 모델(1604A)을 공유할 수 있다. 일부 추가 예시적 실시 예에서, 제1 무선 장치는 로컬 훈련 복원 모델을 사용하여 프리코딩 정보 의 복원을 생성할 수 있다. 예를 들어, 제1 무선 장치는 제2 무선 장치에 의해 사용되 는 복원 모델과 일치할 수 있는 참조 모델(예를 들어, 참조 디코더)을 훈련할 수 있다. 그 다음, 제1 무선 장치는 프리코딩 정보를 생성(예를 들어, 복원)하기 위해 국부적으로 훈련된 모델 을 사용할 수 있고, 그런 다음에 채널 품질 정보(예를 들어 CQI)를 결정(예를 들어, 계산)하는 데 사용할 수 있다. 이들 동작 중 하나 이상은 프리코딩 결정 로직에 의해, 개별적으로 및/또는 협력적으로 제어, 지원될 수 있다. 일부 실시 예에서, 제1 무선 장치는 제1 무선 장치가 예를 들어 미세 조정을 통해 정제할 수 있는 참조 디코더 모델(이는 제2 무선 장치에 의해 사용되는 디코더 모델과 동일하거나 다를 수 있음)로서 참 조 모델을 구현할 수 있다. 대안적으로 또는 추가적으로, 제1 무선 장치는 제1 무선 장치가 제2 무 선 장치에 의해 사용되는 디코더 모델과 다르지만, 프리코딩 행렬을 결정하기 위해 여전히 사용하고 다시 제2 무선 장치에 보고할 채널 품질 정보를 결정하기 위해 사용할 수 있는 디코더 모델을 훈련하기 위해 사용할 수 있는 자체 인코더 모델을 사용하여 참조 모델을 구현할 수 있다. 제1 무선 장치(예를 들어, UE)가 채널 정보(예를 들어, 채널 행렬)를 제2 무선 장치에 보고 할 수 있는 일부 추가적인 예시적인 실시 예에서, 제1 무선 장치에 의해 계산된 프리코딩 정보(예를 들어, 하나 이상의 프리코딩 행렬)를 포함하는 훈련 데이터 세트가 사용될 수 있다. 따라서, 제 1 무선 장치는 제2 무선 장치에서 획득된 대응하는 프리코딩 정보를 알 수 있다. 그러나, 프리코딩 행렬의 열의 수는 RI를 이용하여 보고되는 순위에 해당할 수 있으므로, 제2 무선 장치는 프리코딩 행렬의 크기, 및 다음에 대응하는 UCI 페이로드 크기를 인식하지 못할 수도 있다. 그러한 실시 예에서, 제1 무선 장치 는 제2 무선 장치가 프리코딩 정보(예를 들어, 프리코딩 행렬)를 결정할 수 있도록 충분한 행렬(예를 들어, 전체 NT×NT 행렬)을 보고할 수 있다. 예를 들어, 제2 무선 장치는 프리코딩 행렬로서 행 렬의 제1 열의 수를 취할 수 있고, 여기서, 제1 열의 수는 RI에 의해 보고된 순위(예를 들어, 이와 동일한 것) 에 의해 결정될 수 있다. 제1 무선 장치가 UE로 구현되는 일부 실시 예에서, UE는 프리코딩 행렬을 계산 하기 위해 기존 알고리즘을 사용하고 다음에 프리코딩 행렬에 기초하여 CQI를 계산할 수 있다. 이들 동작 중 하 나 이상은 프리코딩 결정 로직에 의해 개별적으로 및/또는 협력적으로 제어, 지원 등이 가능할 수 있다. 본 개시에 따른 일부 추가적인 실시 예는 채널 정보(예를 들어, 채널 행렬(H), 프리코딩 행렬(P) 등과 같은 채 널 정보 행렬)와 채널 정보를 기반으로 결정될 수 있는 채널 품질 정보(예를 들어, CQI)를 공동으로 처리(예를 들어, 압축)함으로써 프리코딩 정보와 채널 품질 정보 사이의 불일치를 감소 또는 제거할 수 있다. 예를 들어, 일부 실시 예에서, 생성 모델과 복원 모델은 채널 정보 및 채널 정보에 기초하여 결정될 수 있는 채널 품질 정 보를 공동으로 압축 및/또는 압축해제하기 위해 (예를 들어, 자동 인코더 구성에서) 훈련될 수 있다. 도 17은 본 개시에 따라 채널 정보와 채널 품질 정보의 공동 압축에 사용될 수 있는 한 쌍의 모델의 예시적인 실시 예를 도시한다. 도 17에 도시된 실시 예는 예를 들어, 도 4에 도시된 생성 모델 및/또는 복원 모델, 뿐만 아니라 도 7에 도시된 인코더 및/또는 디코더를 구현하는 데 사용될 수 있다. 도 17을 참조하면, 생성 모델은 기계 학습 인코더로 구현될 수 있고, 복원 모델은 기계 학습 디코더로 구현될 수 있다. 각 부대역 i에 대한 프리코딩 행렬 및 CQI(i=1,…,N에 대해 각각 Precoderi 및 CQIi로 표시됨, 여기서 N은 부대역의 수를 나타낼 수 있음)은 입력의 공동 표현을 생성할 수 있는 인코더에 대한 입력으로서 적용될 수 있다. 각 부대역 i에 대한 복원된 프리코딩 행렬 및 CQI(i=1,...,N에 대해 각각 RecPrecoderi 및 RecCQIi로 표시됨)는 공동 표현에 기초하여 디코더의 출력으로 생성될 수 있다. 인코더 및 디코더는 하나 이상의 (예를 들어, 각각의) 부대역 i에 대해, 부대역에 대한 프리코딩 행렬 및 해당 프리코딩 행렬에 기초하여 UE에 의해 계산된 CQI일 수 있거나, 이에 기초할 수 있는 목표 채널 정 보(예를 들어, 목표 CQI)를 포함할 수 있는 훈련 데이터를 사용하여 훈련될 수 있다. UE는 프리코딩 행렬 및/또 는 CQI 계산을 위한 하나 이상의 기존 알고리즘을 사용하여 부대역에 대한 프리코딩 행렬 및/또는 해당 CQI를 계산할 수 있다. 모델 쌍이 훈련되면(예를 들어, 추론에 사용되는 경우) 복원된 프리코딩 출력 RecPrecoderi는 해당 복원된 CQI 출력 RecCQIi와 일치할 수 있으며, 이는 예를 들어, 프리코딩 정보와 해당 CQI가 모델 쌍(1703 및 1704)을 훈련하는 데 사용되는 훈련 데이터에서 일치할 수 있기 때문이다. 대안적으로 또는 추가적으로, 모델 쌍(1703 및 1704)을 훈련하는 데 사용되는 훈련 데이터는 프리코딩 정보(예를 들어, 프리코딩 행렬)와 채널 품질 정보(예를 들어, CQI) 간의 적절한 매칭을 포함할 수 있는 훈련 데이터를 제공할 수 있는 임의의 다른 소 스(예를 들어, 네트워크, 기지국 등)에 의해 생성될 수 있다. 이러한 동작 중 하나 이상은 UE, gNB, 네트워크 또는 기타 위치 또는 이들의 조합에 위치할 수 있는 공동 처리 로직에 의해, 개별적으로 및/또는 협력하여 제어, 지원 등이 가능할 수 있다. 인코더 및 디코더의 훈련은 UE, 기지국, 네트워크(예를 들어, 서버) 또는 임의의 다른 위치에서 수 행될 수 있고, 훈련된 인코더 및 디코더는 추론을 위해 사용될 위치로 전송될 수 있다. 예를 들어, 인코더는 (UE에서 훈련되지 않은 경우) UE로 전달될 수 있고 , 디코더는 (기지국에서 훈련되지 않 은 경우) 기지국으로 전달될 수 있다. 도 17에 도시된 실시 예는 하나 이상의 프리코딩 행렬 및/또는 입력 및/또는 출력으로서의 CQI와 관련하여 설명 될 수 있지만, 임의의 유형의 채널 정보, 프리코딩 정보 등이 입력 및/또는 출력으로 사용될 수 있다. 예를 들 어, 일부 실시 예에서, 각각의 부대역에 대해, 채널 행렬은 프리코딩 행렬에 추가로 또는 그에 대한 대안으로서, 인코더에 대한 입력으로서 적용될 수 있다. 그러한 실시 예에서, 각 부대역에 대해, 채널 행 렬의 복원은 복원된 프리코딩 행렬에 추가로 또는 그에 대한 대안으로서, 출력으로 디코더에 의해 복원될 수 있다. 채널 행렬이 각 부대역에 대해, 프리코딩 행렬의 대안으로서 인코더에 대한 입력으로 적용될 수 있는 일부 실시 예에서, UE는 인코더에 적용될 수 있는 해당 CQI를 계산하기 위해 그 중간 결과로서 프리 코딩 행렬을 계산할 수 있다. 또한, 도 17에 도시된 실시 예는 다수의 부대역의 맥락에서 설명될 수 있지만, 이 원리는 다중 및/또는 단일 대 역, 부대역 등에 대한 채널 정보와 프리코딩 정보를 공동으로 압축하기 위해 한 쌍의 모델을 훈련하는 데 적용 될 수 있다. 일부 실시 예에서, CQI와 같은 채널 정보 구성요소와 프리코딩 정보 간의 매칭을 잠재적으로 제공하는 것 외에 도, (예를 들어, 공동 보고를 위한) 공동 압축은 구현 세부 사항에 따라 하나 이상의 다른 잠재적 이점을 제공 할 수 있다. 예를 들어, 각 채널 정보량(예를 들어, RI, CQI, PMI 등)을 보고하기 위해 서로 다른 ML 모델(예를 들어, 인코더 및/또는 디코더)을 사용하게 되면 다양한 모델에 대한 훈련 및/또는 추론과 관련된 시간, 복잡성 등이 증가할 수 있다. 그러나 본 개시에 따른 실시 예는 RI, CQI, PMI, 채널 행렬, 프리코딩 행렬 등과 같은 값 에 대해 결합 압축(및/또는 결합 보고)을 사용할 수 있으며, 이는 구현 세부 사항에 따라 훈련 및/또는 추론과 관련된 시간, 복잡성 등을 줄일 수 있다. 일부 실시 예는 압축 성능을 향상시키기 위해 예를 들어 채널 정보량 의 서로 다른 분포에 기초하여 공동 압축 및/또는 보고에 사용되는 모델의 크기를 증가시킬 수 있다. 일부 실시 예에서, 무선 장치(예를 들어, UE)는 다른 인코더 및/또는 디코더로 구성될 수 있으며, 여기서 각각의 인코더, 디코더, 모델 쌍 등은 식별자(예를 들어, 모델 ID)와 연관될 수 있고 채널 정보량의 특정 조합에 매핑될 수 있 다. 일부 실시 예에서, 둘 이상의 모델이 동일한 수량 세트에 매핑될 수 있으며, 여기서 (상이한 모델 ID로 식 별되는) 서로 다른 인코더, 디코더, 모델 쌍 등이 서로 다른 채널 환경, 구성 등을 처리하는 데 사용될 수 있다. 부대역 전체에 걸친 CQI 압축 NR 시스템에서, UE는 광대역 값 주위에서 벗어나는 서로 다른 부대역의 CQI에 기초할 수 있는 차등 방식의 압축 을 사용하여 CQI를 보고할 수 있다. 예를 들어, 4*N_sb 비트(여기서 N_sb는 부대역 수를 나타낼 수 있음)를 사 용하여 CQI를 보고하는 대신, UE는 부대역당 2비트를 사용하여 CQI의 차분 값과 함께 광대역 CQI 값을 보고할 수 있다. 그러나 이러한 보고 방식은 일부 구현에서, 특히, 예를 들어 주파수 분할 이중화(FDD) 및/또는 상대적 으로 큰 피드백 보고 양을 가질 수 있는 증가된 안테나 크기를 사용할 수 있는 시스템에서, 적절한 압축을 제공 하지 못할 수 있다. 본 개시에 따른 기계 학습을 사용하여 채널 정보를 압축 및/또는 보고하기 위한 방식은 부대역 세트에 대한 채 널 정보의 조합을 압축할 수 있다. 이러한 실시 예는 예를 들어, 채널 정보 보고에 대한 하나 이상의 부대역(예 를 들어, 각각 또는 그 부분 집합)에 대한 부대역 CQI를 보고하도록 UE가 구성될 수 있는 CQI와 같은 수량을 압 축 및/또는 보고하는 데 유익할 수 있다. 구현 세부 사항에 따라, 본 개시에 따라 기계 학습을 사용하여 부대역 기반으로 채널 정보를 압축 및/또는 보고하는 방식은 성능 및/또는 유연성의 향상, 복잡성의 감소 등을 위해서 (예를 들어, 시간, 주파수 및/또는 공간 영역에서) 하나 이상의 상관 관계를 활용할 수 있다. 도 18은 본 개시에 따른 하나 이상의 부대역에 기초한 채널 정보에 대한 한 쌍의 모델을 갖는 시스템의 실시 예 를 예시한다. 도 18에 도시된 시스템은 본 명세서에 개시된 장치, 모델, 훈련 방식 및/또는 이와 유사한 것 중 임의의 것을 구현하는 데 사용될 수 있거나 이에 의해 구현될 수 있다. 시스템은 도 4 및/또는 도 16에 도시된 실시 예의 것과 유사할 수 있는 하나 이상의 요소(예를 들어, 구 성 요소, 동작 등)를 포함할 수 있으며, 여기서 유사한 요소는 동일한 숫자, 문자 등으로 끝나거나 이를 포함하 는 참조 번호로 표시될 수 있다. 그러나, 도 18에 예시된 시스템에서, 제1 무선 장치는 부대역 압 축 로직을 포함할 수 있다. 추가적으로 또는 대안적으로, 제2 무선 장치는 부대역 압축해제 로직 을 포함할 수 있다. 부대역 압축 로직 및/또는 부대역 압축해제 로직은 제1 무선 장치(180 1)가 (예를 들어, 하나 이상의) 부대역 세트에 대한 채널 정보의 조합을 압축하는 것을 가능하게 하기 위해 개 별적으로 및/또는 협력하여 하나 이상의 방식을 구현할 수 있다. 예를 들어, 제1 무선 장치(예를 들어, UE)에서 부대역 압축 로직은 다수의 부대역에 대한 채널 정 보의 값을 생성 모델에 의해 압축될 수 있는 벡터로 연결하여 다수의 부대역에 대한 채널 정보 의 값의 표현을 생성할 수 있다. 제2 무선 장치(예를 들어, 기지국)에서, 복원 모델은, 부대역 압축해제 로직이 다수의 부대역에 대해 복원된 채널 정보 또는 그 근사치를 생성하기 위해 개별 부대역으로 분할할 수 있는, 벡터 또는 벡터의 근사치를 복구할 수 있다. 도 19는 본 개시에 따라 부대역에 걸쳐 CQI 압축을 위해 사용될 수 있는 한 쌍의 모델의 실시 예를 예시한다. 도 19에 도시된 실시 예는 예를 들어, 도 18에 도시된 생성 모델 및/또는 복원 모델을 구현하는 데 사용될 수 있다. 도시의 목적으로, 제1 무선 장치 및 제2 무선 장치는 시스템과 함께 사용될 때, 각각 UE 및 gNB로 구현될 수 있다. 도 19를 참조하면, 생성 모델은 기계 학습 인코더로 구현될 수 있고, 복원 모델은 기계 학습 디코더 로 구현될 수 있다. CQI 벡터(CQI1, CQI2,…, CQIN)는 부대역 1,2,…,N 중 하나 이상(예를 들어 각각)에 대한 CQI 값을 포함할 수 있다(여기서 N은 부대역 수). CQI 벡터(CQI1, CQI2,…, CQIN)는 예를 들어, 부대역에 대해 개별 CQI 값 CQI1, CQI2,…, CQIN를 연결하여 형성될 수 있다. CQI 벡터는 각 값 CQI1, CQI2,…, CQIN이 도 19에 도시된 바와 같이 인코더에 대한 별도의 입력이 될 수 있도록 인코더에 적용될 수 있다. 대안 적으로 또는 추가적으로, 전체 CQI 벡터는 단일 입력으로서 인코더에 적용될 수 있다. 인코더는 다 수의 부대역에 대한 채널 정보 값의 표현을 생성하기 위해 CQI 벡터 및/또는 개별 CQI 값을 사용할 수 있 다. 디코더는 표현을 수신하여 부대역 1,2,...,N에 대해 복원된 CQI 값 RCQI1, RCQI2,…, RCQIN을 별도 의 개별 출력으로서 및/또는 하나 이상의 부대역에 대한 개별 출력을 제공하기 위해 (예를 들어, 부대역 압축해 제 로직에 의해) 분할될 수 있는 복원된 벡터(RCQI1, RCQI2,…, RCQIN)로서 생성할 수 있다. 일부 실시 예에서, CQI 값 CQI1, CQI2,…, CQIN 중 하나 이상은 CQI 테이블 (예를 들어, 0과 15 사이의 스칼라 값일 수 있는 CQI 인덱스)에 대한 입력(예를 들어, 이산 입력)의 형태로 제공될 수 있다. 예를 들어, CQI 테이 블이 16개의 행을 갖는다면 CQI 값 CQIi(여기서 i=1,2,...,N)는 4비트 값일 수 있다. 대안적으로 또는 추가적으 로, CQI 값 CQI1, CQI2,…, CQIN 중 하나 이상은 부호화율 및/또는 변조 차수의 연속된 값(예를 들어, 임의의 실 수 값)의 형태로 제공될 수 있다. 하나 이상의 연속 값을 CQI 값으로 사용하는 실시 예에서, 예를 들어, gNB에 의한 더 미세한 입도 표시를 수용하기 위해, 상대적으로 더 높은 해상도를 갖는 변조 및 코딩 방식(MCS) 테이블 이 사용될 수 있다. 구현 세부 사항에 따라, 도 18 및 도 19와 관련하여 전술한 바와 같이 부대역 단위로 채널 정보(예를 들어, CQI)를 압축 및/또는 보고하는 방식은 성능 및/또는 유연성을 향상시키고 복잡성을 감소시키는 등을 위해 입력 데이터(예를 들어, CQI 벡터의 요소들 사이)에서 하나 이상의 상관 관계를 활용할 수 있다. 예를 들어, 인코더 는 다양한 값을 갖는 CQI 벡터 보다 더 큰 정도로 동일하거나 유사한 값을 갖는 다수의 요소를 가지는 CQI 벡터를 압축할 수 있다. 일부 실시 예에서, 인코더, 디코더, 생성 모델, 및/또는 복원 모델 중 하나 이상은 서 로 다른 상관 특성을 갖는 입력과 작업하도록 적응될 수 있는 기계 학습 모델로 구현될 수 있다. 따라서 예를들어, 부대역 전체에 걸쳐 CQI 값을 압축하는 데 사용되는 모델은 예를 들어, 입력 값의 범위, 벡터 및/또는 행 렬 차원, 가중치 등에 기반하여 압축 성능을 개선하거나 최적화하기 위해 특수화(예를 들어, 일반 ML 모델과 반 대되는 전용 모델)될 수 있다. 채널 정보 압축 NR 시스템에서, UE는 공간 및/또는 주파수 영역에서 프리코딩 행렬을 압축하기 위해 코드북을 사용할 수 있다. 예를 들어, UE는 RI 및 RI와 연관된 PMI를 (예를 들어, gNB에) 보고할 수 있다. RI와 PMI가 지시하는 순위는 프 리코딩 행렬을 결정하는데 함께 사용될 수 있다. 예를 들어, PMI는 코드북으로 지칭될 수 있는 지원되는 행렬 세트에서 선택될 수 있다. 일부 실시 예에서, 코드북은 프리코딩 행렬에 대한 \"i\" 인덱스 세트 간의 매핑 테이 블로서 구현될 수 있다. 예를 들어, UE는 주어진 순위에 대한 프리코딩 행렬을 고유하게 정의할 수 있는 유형 1 단일 패널 코드북과 함께 인덱스 (i1,1,i1,2,i1,3,i2)를 사용할 수 있다. 그러나, 코드북 압축 방식은 일부 구현 에서, 특히 상대적으로 큰 피드백 보고 양을 가질 수 있는 증가된 안테나 크기 및/또는 주파수 분할 듀플렉싱 (FDD)을 사용할 수 있는 시스템에서, 적절한 압축을 제공하지 못할 수 있다. 본 개시에 따른 기계 학습을 사용하여 채널 정보를 압축 및/또는 보고하기 위한 방식은 하나 이상의 디코더 모 델을 사용하여 프리코딩 정보 및/또는 예를 들어 프리코딩 정보를 결정하는 데 사용될 수 있는 다른 정보를 생 성할 수 있다. 일부 실시 예에서, 이러한 방식은 코드북 방식을 모방할 수 있고/있거나 계층적 압축 메커니즘을 구현할 수 있다. 일부 실시 예에서, 이러한 방식은 시간, 주파수, 및/또는 공간 영역에서 압축을 위한 특정 구 조를 갖는 하나 이상의 인코더 및/또는 디코딩을 구현할 수 있다. 구현 세부 사항에 따라, 이러한 방식은 성능 및/또는 유연성을 향상시키고 복잡성을 줄이는 등의 작업을 수행할 수 있다. 도 20은 본 개시에 따라 채널 정보 압축을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 예시한다. 도 20에 도시된 시스템은 본 명세서에 개시된 장치, 모델, 훈련 방식 등 중 임의의 것을 구현하는 데 사 용될 수 있거나 이에 의해 구현될 수 있다. 시스템은 유사한 요소는 동일한 숫자, 문자 등으로 끝나거나 이를 포함하는 참조 번호로 표시될 수 있는 도 4, 도 16 및/또는 도 18에 도시된 실시 예의 것과 유사할 수 있 는 하나 이상의 요소(예를 들어, 구성요소, 동작 등)를 포함할 수 있다. 도 20에 도시된 시스템에서, 제1 무선 장치(예를 들어, UE)는 채널을 통해 제2 무선 장치(예 를 들어, 기지국)로부터 신호(예를 들어, 참조 신호)를 수신할 수 있다. 제2 무선 장치는 프 리코딩 정보(예를 들어, 프리코딩 행렬)를 신호에 적용할 수 있다. 제1 무선 장치는 압축 방 식 로직을 포함할 수 있다. 추가적으로 또는 대안적으로, 제2 무선 장치는 압축 방식 로직을 포함할 수 있다. 압축 방식 로직(2050 및/또는 2051)은 제1 무선 장치 및 제2 무선 장치가 채널 정 보의 표현을 생성하기 위한 하나 이상의 압축 방식을 구현할 수 있도록 하기 위해 개별적으로 및/ 또는 협력하여 하나 이상의 방식을 구현할 수 있다. 도 20에 도시된 실시 예는 생성 모델에 적용되는 임의의 특정 형태의 채널 정보 및/또는 복원 모델 에 의해 생성된 임의의 특정 형태의 복원된 채널 정보로 제한되지 않는다. 예를 들어, 일부 예시적 인 실시 예에서, 생성 모델 및 복원 모델은 각각 (예를 들어, 자동 인코더로서 구성되는) 인코더 및 디코더로 구현될 수 있으며, 이들은 하나 이상의 압축 방식을 사용하여 채널 행렬과 같은 채널 정보로부터 프리코딩 정보를 생성하도록 구성 및/또는 훈련될 수 있다. 그러한 실시 예에서, UE로서 구현될 수 있는 제1 무 선 장치는 하나 이상의 채널 행렬, 고유 벡터 등과 같은 채널 정보를 획득하기 위해 하나 이상의 CSI-RS 측정을 수행할 수 있다. UE는 UE가 기지국(예를 들어, gNB)으로 구현될 수 있는 제2 무선 장치에 전송할 수 있는 코드워드를 생성하기 위해 채널 정보를 인코더에 적용할 수 있다. 기지국은 프리코딩 행렬을 구성하기 위해 디코더에 코드워드를 적용할 수 있다. 그러한 실시 예에서, 코드워드는 하나 이상의 코드북 인덱스를 모방 할 수 있고, 및/또는 디코더는 코드북을 모방할 수 있지만, 구현 세부정보에 따라 전술한 바와 같은 하나 이상 의 디코더를 갖는 방식은 성능 및/또는 유연성을 향상시키고, 복잡성을 감소시키는 등이 가능하다. 그러나 다른 실시 예에서, 채널 정보 및/또는 채널 정보의 복원은 임의의 다른 형태로 구현될 수 있다. 예를 들어, 생성 모델에 대한 입력으로 적용된 채널 정보에 기반하여 생성 모델의 출력으로 프리코딩 행렬을 생성하기 보다는, 생성 모델 및 복원 모델은 복원 모델이 생성 모델 에 대한 입력으로 적용된 채널 정보 또는 그 근사치를 복원할 수 있도록 훈련될 수 있다. 그 다음, 제2 무선 장 치는 프리코딩 행렬을 결정(예를 들어, 계산)하기 위해 복원된 채널 정보를 사용할 수 있다. 또 다른 실 시 예에서, 채널 정보 및/또는 채널 정보의 복원은 CQI, RI 및/또는 임의의 다른 유형의 정보로 구현될 수 있다. UE의 인코더 및 기지국의 디코더가 채널 행렬과 같은 채널 정보로부터 프리코딩 행렬과 같은 프리코딩 정보를 생성하도록 구성 및/또는 훈련될 수 있는 실시 예에서, 디코더의 출력(및 있는 경우, 사후 처리)은 프리코딩 행 렬일 수 있다. 그러한 일부 실시 예에서, UE는 또한 프리코딩 행렬인 출력을 제공하도록 훈련된 디코더로 구성 될 수 있다. UE의 디코더는 예를 들어 가중치, 입력 및/또는 출력 차원 등을 포함하는 디코더 모델을 공유할 수 있는 기지국으로부터 획득될 수 있다. 일부 실시 예에서, UE와 기지국은 디코더 출력 유형에 대한 공통된 이해 (예를 들어, 프리코딩 정보가 디코더 출력으로부터 어떻게 구성될 수 있는지)를 가질 수 있다. 디코더 이후에 후처리 방식이 적용될 수 있는 실시 예에서, 전처리 방식은 UE와 공유될 수 있다. UE는 디코더의 출력(및 있는 경우 임의의 후처리)으로부터 프리코딩 정보(예를 들어, 프리코딩 행렬)를 구성하는 방법에 대한 하나 이상의 암시적 및/또는 명시적 표시를 제공받을 수 있다. 예를 들어, 디코더의 출력 차원이 Nt*ν이고, 여 기서 ν는 RI가 나타내는 순위인 경우, 프리코더는 출력 벡터를 열 방향 및/또는 행 방향 기준으로 Nt×v 행렬 로 재형성함으로써 구성될 수 있다. 도 20에 도시된 시스템에 대한 훈련 및/또는 테스트 방식의 일부 실시 예가 아래에 설명된다. 도시를 위해, 훈 련 및/또는 테스트 방식의 실시 예는 제1 및 제2 무선 장치(2001, 2002)가 각각 UE 및 gNB로 구현될 수 있는 시 스템의 맥락에서 설명될 수 있고, 생성 모델 및 복원 모델은 각각 인코더 및 디코더로 구현될 수 있다. 그러나 원칙은 이러한 구현 세부 사항이나 기타 구현 세부 사항에 제한되지 않는다. 훈련 및/또는 테스트 방식의 제1 실시 예에서, 인코더 및 디코더는 세트 (X,Y)를 포함할 수 있는 훈련 데이터 세트에 기초하여, (예를 들어, 각각 UE 벤더 및 gNB 벤더에 의해) 공동으로 설계, 구성, 훈련 등일 수 있으며, 여기서 X는 예를 들어 시간 및 주파수 윈도우에서 취해진 CSI-RS 세트의 채널 행렬과 같은 하나 이상의 CSI-RS 측정을 나타낼 수 있고, Y는 예를 들어 UE에 의해 계산될 수 있는 프리코딩 행렬을 나타낼 수 있다. 디코더는 추론 동안 사용할 UE와 공유(예를 들어, 전송)되어, 예를 들어 UE가 CSI-RS 측정을 위해 사용할 수 있는 프리코 딩 행렬을 생성할 수 있다. 추론 동안, UE는 훈련 동안 사용된 것과 유사한 방식으로 인코더를 적용할 수 있다. 훈련 및/또는 테스트 방식의 제2 실시 예에서, gNB는 UE로부터 획득될 수도 있거나 획득되지 않을 수 있는 훈련 데이터 세트를 사용하여 디코더를 훈련할 수 있다. gNB는 하나 이상의 가중치, 입력 및/또는 출력 차원, 사후 처리 등을 포함하여 디코더를 UE와 공유할 수 있다. 일부 실시 예에서, 인코더의 훈련뿐만 아니라 하나 이상의 입력 유형 및/또는 차원은 예를 들어 UE의 구현에 기초하여, UE에 의해 결정될 수 있다. 인코더를 훈련할 때, UE는 디코더 Pdec의 출력과 UE에 의해 계산될 수 있는 원하는 타겟 프리코더 Ptarget 사이의 손실 함수를 최소화하 려고 노력할 수 있다. 일부 실시 예에서, gNB는 하나 이상의 시간 및/또는 주파수 윈도우 및 인코더를 훈련하기 위해 훈련 데이터로 사용될 수 있는 윈도우에서 사용되는 CSI-RS로 UE를 구성할 수 있다. 이 때 UE는 추론을 위 해 훈련된 인코더를 사용할 수 있다. 훈련 및/또는 테스트 방식의 제3 실시 예에서, gNB는 UE로부터 획득될 수 있거나 획득되지 않을 수 있는 훈련 데이터 세트에 기초하여 디코더를 훈련할 수 있다. gNB는 하나 이상의 가중치, 입력 및/또는 출력 차원, 사후 처리 등을 포함하여 디코더를 UE와 공유할 수 있다. 일부 실시 예에서, 인코더의 훈련뿐만 아니라 하나 이상의 입력 유형 및/또는 차원은 예를 들어 UE의 구현에 기초하여 UE에 의해 결정될 수 있다. 그러나 이러한 유형의 구현에서, gNB는 또한 하나 이상의 입력 및/또는 라벨을 포함하여, 인코더를 훈련하기 위한 훈련 데이터 세트를 UE와 공유할 수 있다. UE는 추론 동안 사용하기 위해 인코더를 훈련시키기 위해 공유 훈련 데이터 세트를 사용 할 수 있다. 상술된 훈련 및/또는 테스트 계획의 세 가지 실시 예 중 하나에서, 프리코딩 행렬 차원은 보고된 순위에 따라 달라질 수 있으므로, UE는 하나 이상의 서로 다른 보고된 순위에 대해 하나 이상의 서로 다른 모델을 적용할 수 있다. 예를 들어, UE가 RI로 제1 순위를 보고하는 경우, UE는 제1 디코더에 대해 훈련된 제1 인코더 모델을 사 용할 수 있는 반면, UE가 RI로서 제2 순위를 보고하는 경우, UE는 제2 디코더 모델에 대해 훈련된 제2 인코더 모델을 사용할 수 있다. 위에 설명된 훈련 및/또는 테스트 방식의 세 가지 실시 예 중 하나에서, 구현 세부 사항에 따라, 디코더는 NR 코드북과 유사한 역할을 수행하는 것으로 특징지어질 수 있어, 기계 학습 디코더 모델이 코드북을 사용하는 것 과 비교하여 성능 및/또는 유연성을 향상시키고 복잡성을 줄이는 등이 가능한 잠재력이 있다. 도 21은 본 개시에 따른 압축 방식을 구현하기 위해 사용될 수 있는 한 쌍의 모델의 제1 실시 예를 예시한다. 도 21에 도시된 실시 예는 예를 들어, 도 20에 도시된 생성 모델 및 복원 모델을 구현하는 데 사용될 수 있다. 도 21을 참조하면, 실시 예는 예를 들어 자동 인코더로서 동작하도록 구성될 수 있는 생성 모델 및 복원 모델을 포함할 수 있다. 생성 모델(예를 들어 UE에 위치할 수 있음)은 부대역 1, 2, ..., N에 대한 채널 정보에 각각 대응하는, 하나 이상의 공간 인코더 입력 SEI-1 내지 SEI-N을 각각 수신하도록 배열될 수 있는 하나 이상의 공간 인코더(2153-1 내지 2153-N)를 포함할 수 있고, 여기서 N은 부대역의 개수를 의미할 수 있다. 하나 이상의 공간 인코더(2153-1~2153-N)는 각각 해당 인코더 입력(SEI-1 내지 SEI-N)에 기초하여 하 나 이상의 공간적으로 압축된 출력(SEO 1 내지 SEI-N)을 생성할 수 있다. 압축된 출력(SEO-1 내지 SEO-N)는 복원 모델(예를 들어 기지국에 위치할 수 있음)으로 전송될 수 있고, 여기서 이들은 각각 하나 이상의 공간 디코더(2154-1 내지 2154-N)에 대한 부대역 디코더 입력(SDI-1 내지 SDI- N)으로서 적용될 수 있다. 하나 이상의 공간 디코더(2154-1 내지 2154-N)는 각각 디코더 입력(SDI-1 내지 SD1- N)을 공간적으로 압축해제하여, 하나 이상의 압축해제된 출력(SDO-1 내지 SDO-N)을 생성한다. 임의의 특정 구현 세부 사항에 제한되지 않지만, 일부 실시예에서 인코더 입력(SEI-1 내지 SEI-N내는 해당 부대 역에 대한 채널 행렬 (여기서 i=1, 2, …, N)로 구현될 수 있고, 공간 인코더 출력(SEO-1 내지 SEI-N)은 해 당 부대역에 대한 프리코딩 행렬 의 표현 로 구현된다. 그러면 공간 디코더(2154-1 내지 2154-N)는 표현 로부터 복원된 프리코딩 행렬 로서 압축해제된 출력(SDO-1 내지 SDO-N)을 생성할 수 있다. 따라서, 프리코 딩 정보의 보고는 서로 다른 부대역에서 독립적으로 수행될 수 있다. 일부 실시 예에서, 공간 인코더(2153-1 내지 2153-N)는 예를 들어, 공간 인코더(2153-1 내지 2153-N)가 둘 이상 의 하드웨어 세트(예를 들어, 각 인코더에 대한 별도의 프로세서, 회로 등)로 구현될 수 있는 실시 예에서 공간 압축 동작을 병렬로 수행할 수 있다. 일부 다른 실시 예에서, 공간 인코더(2153-1 내지 2153-N) 중 하나 이상은 예를 들어 공간 인코더(2153-1 내지 2153-N)가 N개 미만의 하드웨어 인스턴스(예를 들어, 모든 N개의 인코더에 대한 단일 별도 프로세서, 회로 등)로 구현될 수 있는 실시 예에서, 공간 압축 동작을 순차적으로 수행할 수 있 다. 유사하게, 공간 디코더(2154-1 내지 2154-N)는 예를 들어 디코더를 구현하는 데 사용되는 하드웨어 세트의 수에 따라 공간 압축해제 동작을 병렬 또는 순차적으로 수행할 수 있다. 도 22는 본 개시에 따른 압축 방식을 구현하기 위해 사용될 수 있는 한 쌍의 모델의 제2 실시 예를 예시한다. 도 22에 도시된 실시 예는 예를 들어, 도 20에 도시된 생성 모델 및 복원 모델을 구현하는 데 사용될 수 있다. 실시 예는 유사한 요소가 동일한 숫자, 문자 등으로 끝나거나 이를 포함하는 참조 번 호로 표시될 수 있는 도 21에 도시된 실시 예의 것과 유사할 수 있는 하나 이상의 구성요소(예를 들어, 구성요 소, 동작 등)를 포함할 수 있다. 도 22를 참조하면, 실시 예는 예를 들어 자동 인코더로서 동작하도록 구성될 수 있는 생성 모델 및 복원 모델을 포함할 수 있다. (예를 들어, UE에 위치할 수 있는) 생성 모델은 부대역 1, 2, ..., N 에 대한 채널 정보에 대응하는 하나 이상의 공간 인코더 입력(SEI-1 내지 SEI-N)을 각각 수신하도록 배열될 수 있는 하나 이상의 공간 인코더(2253-1 내지 2253-N)를 포함할 수 있고, 여기서 N은 부대역의 수를 나타낼 수 있 다. 하나 이상의 공간 인코더(2253-1 내지 2253-N)는 대응하는 인코더 입력(SEI-1 내지 SEI-N)에 기초하여 각각 하나 이상의 공간적으로 압축된 출력(SEO 1 내지 SEO-N)을 생성할 수 있다. 생성 모델은 하나 이상의 공간적으로 압축된 출력(SEO-1 내지 SEO-N)을 수신하고 부대역 인코더 입력 (SEI-1 내지 SEI-N)의 공간적 및 주파수 압축된 표현 FEO를 생성하도록 배열될 수 있는 주파수 인코더를 더 포함할 수 있다. 압축된 표현 FEO는 (예를 들어 기지국에 위치될 수 있는) 복원 모델으로 전송될 수 있고, 여기에서 이것 은 주파수 영역에서는 압축이 해제될 수 있지만 공간 영역에서는 여전히 압축될 수 있는 부대역 1, 2, …, N에 각각 해당하는, 하나 이상의 공간적으로 압축해제된 출력(SDI-1 내지 SDI-N)을 생성할 수 있는 주파수 디코더 에 대한 입력으로 적용될 수 있다. 주파수 디코더의 N개의 출력은 각각 하나 이상의 공간 디코더 (2254-1 내지 2254-N)에 대한 입력(SDI-1 내지 SDI-N)으로서 적용될 수 있다. 하나 이상의 공간 디코더(2254- 1~2254-N)는 주파수 및 공간 영역 모두에서 압축해제될 수 있는 하나 이상의 압축해제된 출력(SDO-1 내지 SDO- N)을 각각 생성하기 위해, 디코더 입력(SDI-1 내지 SDI-N)을 각각 공간적으로 압축해제할 수 있다. 따라서, 프리코딩 정보의 공간 압축 및 압축해제는 서로 다른 부대역에서 독립적으로 수행될 수 있는 반면, 주파수 압축과 압축해제는 부대역 전체에 걸쳐 동시에 수행될 수 있다. 임의의 특정 구현 세부사항에 제한되지 않지만, 일부 실시 예에서, 공간 인코더(2253-1 내지 2253-N)의 입력 (SEI-1 내지 SEI-N)은 해당 부대역에 대한 채널 행렬 (여기서 i=1, 2, …, N)로 구현될 수 있으며, 공간 인 코더 출력(SEO-1 내지 SEO-N)은 해당 부대역에 대한 프리코딩 행렬 의 공간적으로 압축된 표현 로 구현될 수 있다. 주파수 인코더는 주파수 도메인에서 표현 를 압축하여 출력 FEO를 표현 벡터 v로서 생성할 수 있으며, 이는 주파수 및 공간 도메인 모두에서 압축될 수 있다. 주파수 디코더는 하나 이상의 공간 디 코더(2154-1 내지 2154-N)에 대한 하나 이상의 입력(SDI-1 내지 SDI-N)으로서 적용될 수 있는 공간적으로 압축 된 표현 를 복원하기 위해 표현 벡터 v를 주파수 영역에서 압축해제할 수 있으며, 다음에 표현 로부터 복원 된 프리코딩 행렬 로서 압축해제된 출력(SDO-1 내지 SDO-N)를 생성할 수 있다. 따라서, 도 22에 도시된 실시 예에서, 생성 모델은 두 단계로 동작할 수 있다. 제1 단계에서, 프리코딩 정보는 공간 도메인 압축을 통해 독립적으로 각 부대역에서 압축될 수 있다. 이 단계에서, N개의 인코더 모델은 예를 들어 각 부대역에 대해 하나의 인코더 모델이 사용될 수 있다. 모델은 예를 들어, 채널 내의 서로 다른 부 대역과 관련된 다양한 매개변수에 따라 동일하거나 다를 수 있다. 제2 단계에서는 하나의 인코딩 모델을 사용하 여 부대역의 공간적으로 압축된 프리코딩 정보를 주파수 영역에서 공동으로 압축할 수 있다. 일부 실시 예에서, 하나 이상의 공간 인코더(2253-1 내지 2253-N)의 출력(SEO-1 내지 SEO-N)은 부대역 간 상관을 사용하지 않고 각 부대역의 프리코딩 행렬을 나타낼 수 있다. 그 다음, 주파수 디코더는 부대역별로 공간적으로 압축된 프 리코딩 행렬을 주파수 압축하고 이를 프리코딩 행렬 모두를 표현하는 정보를 포함할 수 있는 벡터 v로 압축할 있다. 따라서, 도 22에 예시된 실시 예는 각 부대역에 대한 프리코딩 행렬을 복원할 수 있는 주파수 영역 압축 해제 및 부대역별 디코더 모델을 제공할 수 있다. 일부 실시 예에서, 예를 들어, 공간 인코더(2253-1 내지 2253-N) 및/또는 주파수 인코더가 한 세트 이상 의 하드웨어(예를 들어, 각 인코더에 대한 별도의 프로세서, 회로 등)로 구현될 수 있는 실시 예에서, 공간 인 코더(2253-1 내지 2253-N) 및/또는 주파수 인코더는 압축 동작을 병렬로 수행할 수 있다. 일부 다른 실시 예에서, 공간 인코더(2253-1 내지 2253-N) 및/또는 주파수 인코더 중 하나 이상은 예를 들어, 공간 인코 더(2253-1 내지 2253-N) 및/또는 주파수 인코더가 N+1개 미만의 하드웨어 인스턴스(예를 들어, 모든 N+1 인코더에 대한 단일의 별도 프로세서, 회로 및/또는 이와 유사한 것)로 구현될 수 있는 실시 예에서, 압축 동작 을 순차적으로 수행할 수 있다. 유사하게, 공간 디코더(2254-1 내지 2254-N) 및/또는 주파수 디코더는 예 를 들어, 디코더를 구현하는데 사용되는 하드웨어 세트의 수에 따라 공간 압축해제 동작을 병렬로 또는 순차적 으로 수행할 수 있다. 도 23은 본 개시에 따른 압축 방식을 구현하기 위해 사용될 수 있는 한 쌍의 모델의 제3 실시 예를 도시한다. 도 23에 도시된 실시 예는 예를 들어, 도 20에 도시된 생성 모델 및 복원 모델을 구현하는 데 사용될 수 있다. 실시 예는 유사한 요소가 동일한 숫자, 문자 등으로 끝나거나 이를 포함하는 참조 번 호로 표시될 수 있는 도 21 및/또는 도 22에 예시된 실시 예의 것과 유사할 수 있는 하나 이상의 요소(예를 들 어, 구성요소, 동작 등)를 포함할 수 있다. 도 23을 참조하면, 실시 예는 예를 들어 자동 인코더로서 동작하도록 구성될 수 있는 생성 모델 및 복원 모델을 포함할 수 있다. (예를 들어, UE에 위치할 수 있는) 생성 모델은 부대역 1, 2, ..., N 에 대한 채널 정보에 대응하는 하나 이상의 인코더 입력(SFEI-1 내지 SFEI-N)을 각각 수신할 수 있는 공동 공간 및 주파수 인코더를 포함할 수 있고, 여기서 N은 부대역의 개수를 의미할 수 있다. 공동 공간 및 주파수 인코더는 인코더 입력(SFEI-1 내지 SFEI-N)의 공간 및 주파수 압축된 표현일 수 있는 출력 SFEO를 생성할 수 있다. 공간적으로 및 주파수 압축된 표현 SFEO는 (예를 들어 기지국에 위치할 수 있는) 복원 모델로 전송될 수 있고, 여기서 이는 공간 및 주파수 영역 모두에서 압축해제될 수 있는 부대역 1, 2, ..., N에 각각 대응하는, 하나 이상의 디코더 출력(SFDO-1 내지 SFDO-N)을 생성할 수 있는 결합 공간 및 주파수 디코더에 대한 입 력으로 적용될 수 있다. 따라서 공간 압축과 주파수 압축은 부대역 전체에 걸쳐 동시에 수행될 수 있고, 공간 및 주파수 압축해제는 부대역 전체에 걸쳐 동시에 수행될 수 있다.임의의 특정 구현 세부사항에 제한되지 않지만, 일부 실시 예에서는, 입력(SFEI-1 내지 SFEI-N)은 해당 부대역 에 대한 채널 행렬 (여기서 i=1, 2, …, N)로 구현될 수 있으며, 출력 SFEO는 N개의 부대역에 대응하는 N개 의 프리코딩 행렬의 공간적으로 및 주파수 압축된 표현일 수 있는 표현 벡터 v로서 구현될 수 있다. 공동 공간 및 주파수 디코더는 복원된 프리코딩 행렬 를 복구하기 위해 공간 및 주파수 영역에서 표현 벡터 v를 압축해제할 수 있다. 따라서, 일부 구현에서, 도 23에 예시된 실시 예에서, 공동 공간 및 주파수 인코더 는 프리코딩 행렬 을 결합하여 계산하고 이를 벡터 v로 압축하는 것을 특징으로 할 수 있고, 공동 공간 및 주파수 디코더는 행렬을 로 복구하는 것을 특징으로 할 수 있다. 일부 실시 예에서, 공간 상관은 하나 이상의 송신(Tx) 안테나 포트에 걸친 상관을 의미할 수 있다. 위에 개시된 실시 예 중 임의의 것은 공간 압축을 개별적으로(예를 들어, 레이어 단위로) 또는 채널의 여러(예를 들어, 모든) 레이어에 걸쳐 공동으로 구현할 수 있다. 예를 들어, 일부 실시 예에서, 프리코딩 행렬은 인코더에 대한 입력으로서 적용될 수 있다. 예를 들어, 4x3 프리코딩 행렬은 3개의 레이어(예를 들어, 열)를 가질 수 있으며, 각 레이어는 길이 4(예를 들어, 4개의 행)의 프리코딩 벡터를 갖는다. 일부 실시 예에서, 공간 압축은 전체 행 렬을 인코더에 적용함으로써 여러 계층(예를 들어 모든 계층)에 걸쳐 공동으로 구현될 수 있다. 대안적으로 또 는 추가적으로, 공간 압축은 예를 들어, 행렬의 레이어(예를 들어, 열)를 한 번에 한 레이어씩 인코더에 적용하 여 (예를 들어, 한 번에 4개의 요소(행)를 갖는 하나의 벡터(열)) 레이어별로 구현될 수 있다. 레이어의 수는 예를 들어 RI로 표시될 수 있다. NR 시스템에서, 다음 제약 중 하나 이상이 채널 정보 보고에 대해 구현될 수 있다. UE는 CQI 매개변수(보고된 경우) 사이의 다음 종속성을 가정하여 CSI 매개변수(보고된 경우)를 계산할 수 있다: LI는 보고된 CQI, PMI, RI 및 CRI를 조건으로 계산될 수 있고; CQI는 보고된 PMI, RI 및 CRI를 조건으로 계산될 수 있고; PMI는 보고된 RI 및 CRI를 조건으로 계산될 수 있고; 및/또는 RI는 보고된 CRI를 조건으로 계산될 수 있다. 일부 실시 예에서, 본 명세서에 개시된 ML 기반 압축 및/또는 보고 방식 중 하나 이상은 구현 세부 사항에 따라 위에 설명된 것과 유사할 수 있는 하나 이상의 제약 조건을 구현할 수 있다. 따라서, 일부 실시 예에서, UE가 CQI를 보고하는 경우, 하나 이상의 부대역(예를 들어, 각 부대역)에 대한 CQI는 해당 부대역에 대해 보고된 프 리코딩 정보(예를 들어, 프리코딩 행렬)에 기초하여 계산될 수 있다. 예를 들어, 도 21과 관련하여 설명된 실시 예에서, 부대역에 대한 CQI는 디코더를 UE와 공유하는 것을 수반할 수 있는 프리코딩 행렬 에 기초하여 계산 될 수 있다. 디코더가 UE와 공유도리 수 없는 실시 예에서, UE는 각 부대역 #i에 대한 정보를 기초로 CQI를 계 산할 수 있다. 다른 예로서, 도 22 및 도 23과 관련하여 설명된 실시 예를 이용하면, UE는 디코더가 UE와 공유 되는 경우 부대역 PMIi 또는 디코더 출력 에 기초하여 부대역 #i에 대한 CQI를 계산할 수 있다. 일부 실시 예에서, 이 조건을 지정하기 위한 목적으로, 각 부대역의 프리코딩 정보(예를 들어, PMI)는 부대역 인코더 출력 (또는 입력) 또는 해당 디코더 출력을 참조할 수 있으며, 이는 구현 세부 사항에 따라 이들 각각이 부대역 프리 코딩 행렬을 나타내는 것으로 가정할 수 있다. NR 시스템에서는, 보고된 채널 정보량의 비트 폭은 하나 이상의 RRC 매개변수에 따라 달라질 수 있다. 일부 실 시 예에서, 프리코딩 정보(예를 들어, PMI)를 보고하는 데 사용되는 비트 폭은 추가적으로 RI가 보고하는 순위 에 따라 달라질 수 있다. 본 개시에 따라 기계 학습을 사용하여 채널 정보를 보고하기 위한 프레임워크 내에서, RI, CQI 및 인코더 코드워드(예를 들어, 채널 정보를 나타내는 인코더의 출력)가 모두 동일한 PUCCH에서 전송되 는 경우, UCI 페이로드 크기에 관해 UE와 기지국 사이의 동일한 이해를 보장하기 위해 하나 이상의 메커니즘이 구현될 수 있다. 프리코딩 정보(예를 들어, PMI)에 대한 비트 폭은 RI에 따라 달라질 수 있으므로, 일부 실시 예에서 프리코딩 정보는 RI를 전달하는 PUCCH가 아닌 PUCCH에서 별도로 보고될 수 있다. 일부 다른 실시 예에서, UCI 페이로드에는 하나 이상의 요소(예를 들어, 0)가 추가될 수 있으며 이 때 요소 수는 표시된 순위에 따라 달라질 수 있다. 예를 들어, Nmax가 지원되는 모든 순위에 대한 최대 UCI 페이로드 크기인 경우, 주어진 순 위 ν가 N(ν)의 페이로드 크기로 보고하기 위해서 UE는 Nmax-ν개의 0을 UCI 페이로드에 추가할 수 있다. 처리 시간 일부 실시 예에서(예를 들어, 수명주기 관리(LCM)의 일부로서), 기지국은 UE에게 현재 활성 모델을 업데이트(예 를 들어, 새로운 데이터 세트를 미세 조정)하고, 새로운 모델로 전환하고, 새로운 모델을 활성화하고, 모델을비활성화하도록 지시할 수 있다. 모델을 업데이트할 때, UE가 (채널 추정, RRC 구성, MAC-CE 활성화 등을 통해 수집될 수 있는) 온라인 훈련 세트를 기반으로 인코더 모델을 업데이트하라는 지시를 받은 경우, UE는 모델을 업데이트하기 위해 최소 시간을 사용(예를 들어, 요구)할 수 있다. UE는 UE가 업데이트된 모델을 기지국과 공유 할지 여부에 관계없이 최소 시간을 사용(예를 들어, 요구)할 수 있다. 일부 실시 예에서, UE가 온라인 채널 추정을 통해 온라인 훈련 세트를 수집한 경우, UE는 온라인 훈련 세트에 사용되는 최신 CSI-RS의 마지막 기호의 끝부터 예를 들어, (예를 들어 NAIML,upadte 심볼로 지칭될 수 있는) 심볼의 수로 표현될 수 있는 시간이 만료되기 전에 모델을 업데이트하지 않을 것으로 예상될 수 있다. 일부 실시 예에 서, UE가 업데이트된 모델을 기지국에 보고하도록 구성된 경우, UE는 훈련 세트에 사용된 최신 CSI-RS의 마지막 기호부터 예를 들어, (예를 들어 NAIML,report 기호로 지칭될 수 있는) 심볼의 수로 표현될 수 있는 시간보다 일찍 gNB에 모델을 보고할 것으로 예상되지 않을 수 있다. 일부 실시 예에서, 훈련 세트가 UE에 대해 RRC 구성된 경우, UE는 업데이트 명령이 실행되었을 수 있는 최신 기 호부터 예를 들어, (예를 들어, N개의 심볼로 지칭될 수 있는) 심볼 수로 표현될 수 있는 시간보다 더 일찍 인 코더를 업데이트하거나 업데이트하거나 업데이트 및 보고할 것으로 예상되지 않을 수 있다. 일부 실시 예에서, UE가 새로운 모델로의 전환을 지시받은 경우, UE는 모델 업데이트를 위해 제공된 것과 유사 한 처리 시간을 제공받을 수 있다. 예를 들어, UE가 새로운 모델로 전환하라는 명령을 (예를 들어, DCI, MAC CE, RRC 등을 통해) 수신하면, UE는 전환 명령이 UE에게 전달될 수 있는 마지막 심볼(예를 들어, PDCCH의 마지 막 심볼)의 끝부터 (예를 들어 NAIML,switch 심볼로 지칭될 수 있는) 다수의 기호로 표현될 수 있는 기간 이전에 (모델의 활성화를 포함할 수 있는) 모델로 전환할 것으로 예상되지 않을 수 있다. 일부 실시 예에서, 모델을 활성화하기 위해 UE에 유사한 처리 시간이 제공될 수 있다. 예를 들어, UE가 모델을 활성화 및/또는 비활성화하라는 명령을 (예를 들어, DCI, MAC CE, RRC 등을 통해) 수신하면, UE는 전환 명령이 UE에게 전달될 수 있는 마지막 심볼(예를 들어, PDCCH의 마지막 심볼)의 끝부터 (예를 들어, NAIML,activate 및/또는 NAIML,deactivate 기호로 지칭될 수 있는) 다수의 심볼로 표현될 수 있는 기간 이전에 모델을 활성화 및/또는 비활성 화할 것으로 예상되지 않을 수 있다. 일부 실시 예에서, 상술된 처리 시간 중 하나 이상은 명령을 전달하는 셀 및/또는 모델이 테스트될 수 있는 셀 (예를 들어, 해당 CSI 보고가 전송될 수 있는 셀)의 부반송파 간격(SCS) 수비학에 기초하여 시간 단위로 설명될 수 있다. 일부 실시 예에서, 모델이 활성화된 셀의 SCS도 고려될 수 있다. 예를 들어, 시간의 양을 표현하는 데 사용되는 여러 기호(예를 들어, 위에 설명된 방법에서 언급된 기호)는 SCS 값 중 가장 작은 SCS로 설명될 수 있 다. 일부 실시 예에서, UE는 (예를 들어, 기지국에 의한 질의에 기초하여) 처리 시간에 대한 하나 이상의 능력, 예 를 들어 PDSCH 및/또는 PUSCH 처리 시간 능력을 선언할 수 있다. 추가적으로 또는 대안적으로, UE는 본 명세서 에 개시된 임의의 처리 시간에 대한 능력을 선언할 수도 있다. 예를 들어, 일부 실시 예에서, UE는 NAIML,upadte, NAIML,switch 및 NAIML,activate/NAIML,deactivate을 지원(예를 들어, 사용하거나 요구)할 수 있는, 최소 시간 또는 최소 심볼 수를 선언할 수 있다. 예를 들어, UE는 20개 심볼의 모델 전환을 위한 능력(예를 들어, 최소 처리 시간)을 갖는 다는 것을 기지국에 선언할 수 있으며 이는 UE가 전환 명령의 종료 기호 이후 20개의 기호 이전에는 새로운 모 델로 전환할 것으로 예상되지 않는 것을 의미할 수 있다. 별도의 모델로 보고 AI/ML 채널 정보 보고 프레임워크 내에서, UE가 채널 행렬을 보고하는 경우, gNB는 순위, 고유 벡터 및/또는 고 유 값을 포함하는 채널 품질과 그에 따라 SVD 프리코딩 행렬을 추론할 수 있다. 그러나 성능은 AI/ML CSI 보고 프레임워크 내에서, 지원되는 순위에 대한 UE의 능력, 그 UE 특정 프리코딩 정보(예를 들어, 프리코딩 행렬) 계 산 알고리즘을 포함하여, UE 다운링크 신호 처리에 따라 달라질 수 있으므로, UE는 RI 및/또는 CQI와 같은 하나 이상의 다른 값을 또한 보고할 수 있다. 예시의 목적으로, AI/ML(ML이라고도 함)에 기반한 보고 방식의 일부 실 시 예는 자동 인코더를 통해 CSI 행렬(예를 들어, 채널 행렬, 프리코딩 행렬 등)을 보고함으로써 AI/ML CSI 보 고를 수행하는 시스템의 맥락에서 설명될 수 있지만, 원칙은 자동 인코더로 사용하는 것에 제한되지 않는다. 일부 실시 예에서, CSI 행렬 보고 외에도, UE는 기존 보고 또는 AI/ML 프레임워크를 통해 RI 및 CQI를 보고할 수도 있다. AI/ML 프레임워크를 사용하면, UE는 비트맵에 따라 부대역 각각 또는 부대역의 서브세트에 대해 CSI행렬을 보고하기 위해 부대역으로 구성될 수 있다. RI, PMI 및/또는 CQI 보고의 일부 예가 아래에 설명되어 있 다. CSI 보고시에, UE는 CSI 보고 구성에 지정된 모든 부대역에 대해 하나의 RI만 보고할 수 있다. 동일한 접근 방 식이 AI/ML CSI 보고 프레임워크의 일부 실시 예에 대해 채택될 수도 있다. 일부 추가적인 실시 예에서, 하나 이상의(예를 들어, 각각의) 부대역에 대응하는 하나 이상의 RI 값은 이를 벡터로 연결하고 벡터를 압축함으로써 보고될 수 있으며, 이는 구현 세부 사항에 따라 CSI 행렬 압축과 유사할 수 있다. RI 벡터의 상관 속성은 CSI 행렬의 상관 속성과 다를 수 있으므로, CSI 행렬 압축에 사용되는 것과 다를 수 있는 ML 모델(예를 들어, 네트 워크)이 RI 벡터를 압축하는 데 사용될 수 있다. 예를 들어, RI 보고를 위한 ML 모델은 압축 RI 벡터에 대해 맞 춤화될 수 있는 입력 및/또는 출력 차원, 가중치 등을 가질 수 있다. CSI 행렬 보고는 본 명세서에 개시된 방식들 중 임의의 방식에 따라 수행될 수 있다. 일부 실시 예에서, UE는 CSI 보고 구성에 따라 부대역 각각 또는 부대역의 서브세트에 대해 CSI 행렬을 보고하도록 구성될 수 있다. AI/ML 프레임워크에 기초한 CQI 보고는 본 명세서에 개시된 방식 중 임의의 방식에 따라 수행될 수 있다. 일부 실시 예에서, UE가 위에서 논의된 세 가지 수량(예를 들어, RI, CSI 및/또는 CQI) 중 하나 이상을 서로 다 른 PUCCH에서 개별적으로 보고하도록 구성된 경우, 제2 모델(CSI 행렬 보고 모델)의 입력 크기를 줄이기 위해, UE는 시간 영역 다중화(TDM)를 사용하여 PUCCH를 통해 서로 다른 단계에서 서로 다른 수량(예를 들어, 3개)을 보고할 수 있다. 예를 들어, UE는 제1 PUCCH에서 RI를 보고할 수 있다. UE는 보고된 RI에 의존할 수 있는 차원 을 갖는 CSI 행렬을 제2 PUCCH에서 보고할 수 있으며, 예를 들어, gNB는 제1 PUCCH를 성공적으로 디코딩한 후에 만 제2 PUCCH를 디코딩할 수 있기 때문이다. 구현 세부 사항에 따라, 제1 및 제3 PUCCH의 디코딩은 언제든지 수 행될 수 있지만, 제2 PUCCH는 제1 PUCCH 디코딩 이후에만 디코더가 될 수 있다. 이들 양상 중 하나 이상은 PUCCH 디코딩이 gNB에서 자동 인코더의 디코더 모델을 실행하는 것을 포함할 수 있다는 가정에 기초할 수 있다. 도 24는 일 실시 예에 따른 네트워크 환경의 전자 장치의 블록도이다. 도 24에 예시된 실시예는 본 명세서에서 설명된 임의의 시스템, 방법, 장치, 디바이스 등을 구현하는 데 사용될 수 있다. 예를 들어, 전자 장치는 본 명세서에 설명된 임의의 UE 및/또는 기지국을 구현하는 데 사용될 수 있다. 그러한 실시예에서, UE 및/또는 기지국 기능 중 임의의 기능은 무선 통신 모듈을 사용하여 적어 도 부분적으로 구현될 수 있다. 도 24를 참조하면, 네트워크 환경 내의 전자 장치는 제 1 네트워크(예를 들어, 근거리 무선 통신 네트워크)를 통해 전자 장치, 또는 제2 네트워크(예를 들어, 장거리 무선 통신 네트워크)를 통해 전자 장치 또는 서버와 통신할 수 있다. 전자 장치는 서버를 통하여 전자 장치 와 통신할 수 있다. 전자 장치는 프로세서, 메모리, 입력 장치, 출력 장치 , 디스플레이 장치, 오디오 모듈, 센서 모듈, 인터페이스, 햅틱 모듈, 카메라 모듈, 전력 관리 모듈, 배터리, 통신 모듈, 가입자 식별 모듈(SIM) 카드 또는 안테나 모듈를 포함한다. 일 실시 예에서, 구성 요소 중 적어도 하나(예를 들어, 디스플레이 장치 또는 카메라 모듈)는 전자 장치에서 생략되거나, 하나 이상의 다른 구성 요소는 전자 장치에 추가될 수 있다. 구성 요소 중 일부는 단일 집적 회로(IC)로 구현될 수 있다. 예를 들어, 센서 모 듈(예를 들어, 지문 센서, 홍채 센서 또는 조도 센서)은 디스플레이 장치(예를 들어, 디스플레이) 에 내장될 수 있다. 프로세서는 예를 들어, 소프트웨어(예를 들어, 프로그램)를 실행하여 프로세서과 연결된 전 자 장치의 적어도 하나의 다른 구성 요소(예를 들어, 하드웨어 또는 소프트웨어 구성 요소)를 제어할 수 있으며, 다양한 데이터 처리 또는 계산을 수행할 수 있다. 데이터 처리 또는 계산의 적어도 일부로서, 프로세서는 휘발성 메모리의 다른 구성 요소(예를 들어, 센서 모듈 또는 통신 모듈)로부터 수신된 명령 또는 데이터를 로드할 수 있으며, 휘발성 메 모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비 휘발성 메모리에 저장한다. 프로세 서는 메인 프로세서(예를 들어, CPU 또는 애플리케이션 프로세서(AP)), 및 메인 프로세서와 독립적으로 또는 함께 동작할 수 있는 보조 프로세서(예를 들어, GPU, 이미지 신호 프로세서(ISP)), 센서 허브 프로세서 또는 통신 프로세서(CP))를 포함할 수 있다. 추가적으로 또는 대안으로, 보조 프로세서는 메인 프로세서보다 적은 전력을 소비하거나 특정 능력을 실행하도록 구성될 수 있다. 보조 프로세서 는 메인 프로세서와 별개로 구현될 수도 있고, 그 일부로 구현될 수도 있다.보조 프로세서는 메인 프로세서가 비활성(예를 들어, 슬립) 상태에 있는 동안 메인 프로세서 대신에, 또는 메인 프로세서가 활성 상태(예를 들어, 애플리케이션 실행중)에 있는 동안 메인 프로세서 와 함께, 전자 장치의 구성 요소 중 적어도 하나의 구성 요소(예를 들어, 디스플레이 장치, 센서 모듈 또는 통신 모듈)와 관련된 기능 또는 상태 중 적어도 일부를 제어할 수 있다. 보조 프로 세서(예를 들어, 이미지 신호 프로세서 또는 통신 프로세서)는 보조 프로세서와 기능적으로 관련된 다른 구성 요소(예를 들어, 카메라 모듈 또는 통신 모듈)의 일부로 구현될 수 있다. 메모리는 전자 장치의 적어도 하나의 구성 요소(예를 들어, 프로세서 또는 센서 모듈(247 6))에 의해 사용되는 다양한 데이터를 저장할 수 있다. 다양한 데이터는 예를 들어, 소프트웨어(예를 들어, 프 로그램) 및 이와 관련된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 메모리는 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 비휘발성 메모리는 내부 메모리 및/또는 외부 메모리를 포함할 수 있다. 프로그램은 소프트웨어로서 메모리에 저장될 수 있으며, 예를 들어, 운영 체제(OS), 미들웨 어 또는 애플리케이션을 포함할 수 있다. 입력 장치는 전자 장치의 외부(예를 들어, 사용자)로부터 전자 장치의 다른 구성 요소(예를 들어, 프로세서)에 의해 사용될 명령 또는 데이터를 수신할 수 있다. 입력 장치는 예를 들어, 마이 크, 마우스 또는 키보드를 포함할 수 있다. 음향 출력 장치는 전자 장치의 외부로 음향 신호를 출력할 수 있다. 음향 출력 장치는 예를 들어, 스피커 또는 리시버를 포함할 수 있다. 스피커는 멀티미디어 재생 또는 녹음과 같은 일반적인 용도로 사 용될 수 있으며, 수신기는 수신 전화를 수신하는 데 사용될 수 있다. 수신기는 스피커와 분리되거나 스피커의 일부로 구현될 수 있다. 디스플레이 장치는 전자 장치의 외부(예를 들어, 사용자)에게 시각적으로 정보를 제공할 수 있다. 디스플레이 장치는, 예를 들어, 디스플레이, 홀로그램 장치 또는 프로젝터 및 제어 회로를 포함하여 디스 플레이, 홀로그램 장치 및 프로젝터 중 대응하는 것을 제어할 수 있다. 디스플레이 장치는 터치를 탐지하 도록 구성된 터치 회로, 또는 터치에 의해 발생하는 힘의 강도를 측정하도록 구성된 센서 회로(예를 들어, 압력 센서)를 포함할 수 있다. 오디오 모듈은 소리를 전기적 신호로 변환하거나 그 반대로 변환할 수 있다. 오디오 모듈은 입력 장치을 통해 사운드를 획득하거나, 사운드를 음향 출력 장치 또는 외부 전자 장치의 헤드폰 을 통해 전자 장치와 직접(예를 들어, 유선으로) 또는 무선으로 출력한다. 센서 모듈은 전자 장치의 동작 상태(예를 들어, 전원 또는 온도) 또는 전자 장치 외부의 환 경 상태(예를 들어, 사용자의 상태)를 탐지하고, 다음에 탐지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성한다. 센서 모듈은, 예를 들어 제스처 센서, 자이로 센서, 대기압 센서, 자기 센서, 가속도 센서, 그 립 센서, 근접 센서, 컬러 센서, 적외선(IR) 센서, 생체 인식 센서, 온도 센서, 습도 센서 또는 조도 센서일 수 있다. 인터페이스는 전자 장치가 외부 전자 장치와 직접(예를 들어, 유선으로) 또는 무선으로 연결 되는 데 사용될 하나 이상의 지정된 프로토콜을 지원할 수 있다. 인터페이스는 예를 들어, 고 해상도 멀 티미디어 인터페이스(HDMI), 범용 직렬 버스(USB) 인터페이스, 시큐어 디지털(SD) 카드 인터페이스, 또는 오디 오 인터페이스를 포함할 수 있다. 연결 단자는 전자 장치가 외부 전자 장치와 물리적으로 연결될 수 있는 커넥터를 포함할 수 있다. 연결 단자는 예를 들어, HDMI 커넥터, USB 커넥터, SD 카드 커넥터 또는 오디오 커넥터(예를 들어, 헤드폰 커넥터)를 포함할 수 있다. 햅틱 모듈은 전기적 신호를 기계적 자극(예를 들어, 진동 또는 움직임) 또는 촉감 또는 운동 감각을 통해 사용자가 인식할 수 있는 전기적 자극으로 변환할 수 있다. 햅틱 모듈은 예를 들어, 모터, 압전 소자 또 는 전기 자극기를 포함할 수 있다. 카메라 모듈은 정지 영상 또는 동영상을 촬영할 수 있다. 카메라 모듈은 하나 이상의 렌즈, 이미지 센서, ISP 또는 플래시를 포함할 수 있다. 전력 관리 모듈은 전자 장치에 공급되는 전력을 관리할 수 있다. 전력 관리 모듈은 예를 들 어, 전력 관리 집적 회로(PMIC)의 적어도 일부로 구현될 수 있다. 배터리는 전자 장치의 적어도 하나의 구성 요소에 전원을 공급할 수 있다. 배터리는 예를 들 어, 충전이 불가능한 1 차 전지, 충전 가능한 2 차 전지 또는 연료 전지를 포함할 수 있다. 통신 모듈은 전자 장치과 외부 전자 장치(예를 들어, 전자 장치, 전자 장치 또는 서버 ) 간의 직접적인(예를 들어, 유선) 통신 채널 또는 무선 통신 채널 설정을 지원하고, 설정된 통신 채널을 통해 통신을 수행하는 것을 지원할 수 있다. 통신 모듈은 프로세서(예를 들어, AP)와 독립적으로 동작할 수 있는 하나 이상의 CP를 포함할 수 있으며, 직접(예를 들어, 유선) 통신 또는 무선 통신을 지원한다. 통신 모듈은 무선 통신 모듈(예를 들어, 셀룰러 통신 모듈, 근거리 무선 통신 모듈 또는 글로벌 위 성 항법 시스템(GNSS) 통신 모듈) 또는 유선 통신 모듈(예를 들어, 근거리 통신망(LAN) 통신 모듈 또는 전력선 통신(PLC) 모듈)를 포함할 수 있다. 이러한 통신 모듈 중 해당하는 모듈은 제1 네트워크(예를 들 어, Bluetooth®, 무선 피델리티(Wi-Fi) 다이렉트, 또는 적외선 데이터 협회(IrDA) 표준과 같은 단거리 통신 네 트워크) 또는 제2 네트워크(예를 들어, 셀룰러 네트워크, 인터넷, 또는 컴퓨터 네트워크(예를 들어, LAN 또는 광역 네트워크(WAN))와 같은 장거리 통신 네트워크)를 통해 외부 전자 장치와 통신할 수 있다. Bluetooth® 는 워싱턴 커클랜드 소재의 Bluetooth SIG, Inc.의 등록 상표이다. 이러한 다양한 유형의 통신 모듈은 단일 구 성 요소(예를 들어, 단일 IC)로 구현될 수 있으며, 서로 분리된 여러 구성 요소(예를 들어, 다수의 IC)로 구현 될 수 있다. 무선 통신 모듈는 가입자 식별 모듈에 저장된 가입자 정보(예를 들어, 국제 모바일 가 입자 식별자(IMSI))를 사용하여, 제1 네트워크 또는 제2 네트워크와 같은 통신 네트워크에서 전자 장치를 식별하고 인증할 수 있다. 안테나 모듈은 전자 장치의 외부(예를 들어, 외부 전자 장치)와 신호 또는 전원을 송수신할 수 있 다. 안테나 모듈은 하나 이상의 안테나를 포함할 수 있으며, 이중에서, 제1 네트워크 또는 제2 네 트워크와 같은 통신 네트워크에서 사용되는 통신 방식에 적합한 적어도 하나의 안테나를 통신 모듈 (예를 들어, 무선 통신 모듈)에 의해 선택할 수 있다. 그러면 선택된 적어도 하나의 안테나를 통해 통신 모듈과 외부 전자 장치간에 신호 또는 전력이 송수신될 수 있다. 명령 또는 데이터는 제2 네트워크와 결합된 서버를 통해 전자 장치와 외부 전자 장치 사이에서 송수신될 수 있다. 각각의 전자 장치(2402, 2404)는 전자 장치와 동일한 유형 또는 이와 다른 유형의 장치일 수 있다. 전자 장치에서 실행될 동작의 전부 또는 일부는 외부 전자 장치(2402, 2404, 2408) 중 하나 이상에서 실행될 수 있다. 예를 들어, 전자 장치가 자동으로 또는 사용자 또는 다른 장치 의 요청에 따라, 기능 또는 서비스를 수행해야 하는 경우, 전자 장치는 기능 또는 서비스를 실행하는 대 신에, 또는 그에 추가하여, 하나 이상의 외부 전자 장치에 기능 또는 서비스의 적어도 일부를 수행하도록 요청 할 수 있다. 요청을 수신한 하나 이상의 외부 전자 장치는 요청된 기능 또는 서비스의 적어도 일부, 또는 요청 과 관련된 추가 기능 또는 추가 서비스를 수행할 수 있으며, 수행의 결과를 전자 장치로 전달한다. 전자 장치(24는 결과를, 요청에 대한 응답의 적어도 일부로서, 결과의 추가 처리를 포함하거나 포함하지 않고 제 공할 수 있다. 이를 위해, 예를 들어 클라우드 컴퓨팅, 분산 컴퓨팅 또는 클라이언트-서버 컴퓨팅 기술이 사용 될 수 있다. 도 25는 일 실시 예에 따라 UE와 기지국이 서로 통신하는 시스템을 도시한다. UE는 본 명세서에 개시된 다양한 방법, 예를 들어, 도 1 및 2 및/또는 15 내지 23와 관련하여 설명된 방 법 중 하나를 수행할 수 있는 라디오 및 처리 회로(또는 처리 수단)를 포함할 수 있다. 예를 들어, 처리 회로는 라디오를 통해, 예를 들어 기지국(예를 들어, gNB)으로 구현될 수 있는 네트워 크 노드로부터의 송신을 수신할 수 있고, 처리 회로는 라디오를 통해 신호를 기지국에 전송 할 수 있다. 또 다른 예로, 처리 회로는 도 16에 예시된 바와 같이 프리코딩 결정 로직을 구현할 수 있고 기지국은 공유 로직을 구현할 수 있다. 추가 예로서, 처리 회로는 도 17에 도시된 바와 같이 공동 인코더를 구현할 수 있고 기지국은 공동 디코더를 구현할 수 있다. 추가적인 예로, 처리 회로는 도 18에 예시된 바와 같이 부대역 압축 로직을 구현할 수 있고 기지국은 부대역 압축해제 로직을 구현할 수 있다. 또 다른 예로, 처리 회로 및 기지국은 도 20에 예시된 바 와 같이 각각 압축 방식 로직(2050 및 2051)을 구현할 수 있다. 본 명세서에 기술된 주제 및 동작의 실시 예는 본 명세서에서 개시된 구조 및 이들의 구조적 등가물, 또는 이들 중 하나 이상의 조합을 포함하여, 디지털 전자 회로, 또는 컴퓨터 소프트웨어, 펌웨어 또는 하드웨어로 구현될수 있다. 본 명세서에서 설명하는 주제의 실시 예는 하나 이상의 컴퓨터 프로그램, 즉, 데이터 처리 장치에 의 해 실행되거나 데이터 처리 장치의 작동을 제어하기 위해 컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램 명령어 의 하나 이상의 모듈로서 구현될 수 있다. 대안으로 또는 추가적으로, 프로그램 명령어는 인위적으로 생성된 전 파 신호, 예를 들어 기계 생성 전기, 광학 또는 전자기 신호에 인코딩될 수 있으며, 이는 데이터 처리 장치에 의한 실행을 위해 적절한 수신기 장치로 전송하기 위한 정보를 인코딩하도록 생성된다. 컴퓨터 저장 매체는 컴 퓨터 판독 가능 저장 장치, 컴퓨터 판독 가능 저장 기판, 랜덤 또는 직렬 접근 메모리 어레이 또는 장치, 또는 이들의 조합일 수 있거나 이에 포함될 수 있다. 또한, 컴퓨터 저장 매체는 전파 신호가 아니지만, 컴퓨터 저장 매체는 인위적으로 생성된 전파 신호로 인코딩된 컴퓨터 프로그램 명령어의 소스 또는 목적지일 수 있다. 컴퓨 터 저장 매체는 하나 이상의 별도의 물리적 구성 요소 또는 매체(예를 들어, 여러 CD, 디스크 또는 기타 저장 장치)이거나 이에 포함될 수 있다. 또한, 본 명세서에서 설명하는 동작은 하나 이상의 컴퓨터 판독 가능 저장 장치에 저장되거나 다른 소스로부터 수신된 데이터에 대해 데이터 처리 장치에 의해 수행되는 동작으로 구현될 수 있다. 본 명세서는 많은 특정 구현 세부사항을 포함할 수 있지만, 구현 세부 사항은 청구된 주제의 범위에 대한 제한 으로 해석되어서는 안 되며, 오히려 특정 실시 예에 특정한 특징에 대한 설명으로 해석되어야 한다. 별도의 실 시 예의 맥락에서 본 명세서에 설명된 특정 특징은 또한 단일 실시 예에서 조합하여 구현될 수 있다. 역으로, 단일 실시 예의 맥락에서 설명된 다양한 특징이 또한 다수의 실시 예에서 개별적으로 또는 임의의 적절한 하위 조합으로 구현될 수 있다. 더구나, 기능이 특정 조합으로 작용하는 것으로 설명되고 초기에 이와 같이 청구될 수 있지만, 청구된 조합으로부터의 하나 이상의 특징은 경우에 따라 이 조합에서 배제될 수 있고, 청구된 조합 은 하위 조합 또는 하위 조합의 변형에 관한 것일 수 있다. 유사하게, 동작이 특정 순서로 도면에 도시되어 있지만, 이것은 이러한 동작이 바람직한 결과를 달성하기 위해 서 도시된 특정 순서로 또는 순차적인 순서로 수행되거나, 예시된 모든 동작이이 수행되는 것을 요구하는 것으 로 이해되어서는 안 된다. 특정 상황에서, 멀티태스킹 및 병렬 처리가 유리할 수 있다. 또한, 상술된 실시 예에 서 다양한 시스템 구성요소의 분리는 모든 실시 예에서 그러한 분리를 요구하는 것으로 이해되어서는 안되며, 설명된 프로그램 구성 요소 및 시스템은 일반적으로 단일 소프트웨어 제품에 함께 통합되거나 여러 소프트웨어 제품으로 패키지화될 수 있음을 이해해야 한다. 따라서, 본 주제의 특정 실시 예는 본 명세서에 기술되었다. 다른 실시 예는 다음 청구 범위 내에 있다. 경우에 따라, 청구범위에 명시된 조치가 다른 순서로 수행되어도 원하는 결과를 얻을 수 있다. 추가적으로, 첨부된 도 면에 도시된 프로세스는 원하는 결과를 얻기 위해서, 표시된 특정 순서 또는 순차적인 순서를 반드시 요구하지 않는다. 특정 구현에서, 멀티태스킹 및 병렬 처리가 바람직할 수 있다. 본 명세서에 개시된 실시 예는 다양한 구현 세부사항의 맥락에서 설명될 수 있지만, 본 공개의 원칙은 이러한 세부 사항이나 기타 특정 세부 사항에 국한되지 않는다. 일부 기능은 특정 구성 요소에 의해 구현되는 것으로 설명되었지만, 다른 실시 예에서는 기능이 서로 다른 위치에 있는 서로 다른 시스템과 구성요소 사이에 분산될 수 있다. 구성요소 또는 요소에 대한 참조는 해당 구성요소 또는 요소의 일부만을 지칭할 수도 있다. 본 개시 내용 및 청구 범위에서 \"첫 번째\" 및 \"두 번째\"와 같은 용어의 사용은 수정된 사항을 구별하기 위한 목적으로만 사용될 수 있으며 문맥에서 달리 명백하지 않는 한 공간적 또는 시간적 순서를 나타내지 않을 수 있다. 첫 번째 항목에 대한 언급이 두 번째 항목의 존재를 의미하지 않을 수도 있다. 더욱이, 위에서 설명된 다양한 세부사항 및 실시 예는 결합되어 본 특허 개시의 독창적인 원리에 따른 추가적인 실시 예를 생성할 수 있다. 편의에 따라 섹션 제목 등 다양한 구성 보조 기능이 제공될 수 있지만, 이러한 보조 자료에 따라 정리된 주제와 본 특허 개 시의 발명적 원리는 이러한 조직적 보조 자료에 의해 정의되거나 제한되지 않는다. 당업자가 인식하는 바와 같이, 본 명세서에서 설명된 혁신적인 개념은 광범위한 애플리케이션에 걸쳐 수정 및 변경될 수 있다. 따라서, 청구된 주제의 범위는 상술된 특정한 예시적인 교시에 제한되어서는 안되고, 대신 다 음 청구범위에 의해 정의되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25"}
{"patent_id": "10-2023-0116314", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 반드시 일정한 비율로 도시된 것은 아니며 유사한 구조 또는 기능의 요소는 일반적으로 도면 전체에 걸 쳐 예시의 목적으로 유사한 참조 번호 또는 그 부분으로 표시된다. 도면은 본 명세서에서 설명된 다양한 실시 예의 설명을 용이하게 하기 위한 것일 뿐이다. 도면은 본 명세서에서 개시된 교시의 모든 측면을 설명하지 않으 며 청구범위의 범위를 제한하지 않는다. 도면이 불분명하게 되는 것을 방지하기 위해 모든 구성 요소, 연결 등 이 표시되지 않을 수 있으며, 모든 구성 요소에 참조 번호가 있는 것은 아니다. 그러나 구성요소의 구성 패턴은 도면으로부터 명백할 것이다. 첨부된 도면은 본 명세서와 함께 본 발명의 일 실시 예를 도시한 것으로, 상세한 설명과 함께 본 발명의 원리를 설명하기 위한 것이다. 도 1은 본 개시에 따른 무선 통신 장치의 실시 예를 도시한다. 도 2는 본 개시에 따른 무선 통신 장치의 다른 실시 예를 도시한다. 도 3은 본 개시에 따른 2 모델 훈련 방식의 실시 예를 예시한다. 도 4는 본 개시에 따른 채널 정보 피드백을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 도시한다. 도 5는 본 개시에 따른 다운링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 도 6은 본 개시에 따른 업링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 도 7은 본 개시에 따른 다운링크 물리 계층 채널 상태 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시 한다. 도 8은 본 개시에 따른 기계 학습 모델을 위한 학습 프로세스의 실시 예를 도시한다. 도 9는 본 개시에 따른 한 쌍의 인코더 및 디코더 모델의 공동 훈련을 위한 방법의 예시적인 실시 예를 도시한 다. 도 10은 본 개시에 따른 최신 공유 값으로 모델을 훈련시키는 방법의 예시적인 실시 예를 도시한다. 도 11은 본 개시에 따른 사전 처리 및 사후 처리를 갖는 2-모델 훈련 방식의 예시적인 실시 예를 도시한다. 도 12는 본 개시에 따른 2-모델 방식을 사용하기 위한 시스템의 실시 예를 도시한다.도 13은 본 개시에 따른 사용자 장치(UE)의 예시적인 실시 예를 도시한다. 도 14는 본 개시에 따른 기지국의 예시적인 실시 예를 도시한다. 도 15는 본 개시에 따른 물리 계층 정보 피드백을 제공하기 위한 방법의 실시 예를 도시한다. 도 16은 본 개시에 따른 채널 정보 피드백을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 도시한다. 도 17은 본 개시에 따른 채널 정보와 채널 품질 정보의 결합 압축에 사용될 수 있는 한 쌍의 모델의 예시적인 실시 예를 도시한다. 도 18은 본 개시에 따른 하나 이상의 부대역에 기초한 채널 정보에 대한 한 쌍의 모델을 갖는 시스템의 실시 예 를 도시한다. 도 19는 본 개시에 따른 부대역에 걸쳐 CQI 압축을 위해 사용될 수 있는 한 쌍의 모델의 실시 예를 도시한다. 도 20은 본 개시에 따른 채널 정보 압축을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 도시한다. 도 21은 본 개시에 따른 압축 방식을 구현하기 위해 사용될 수 있는 한 쌍의 모델의 제1 실시 예를 도시한다. 도 22는 본 개시에 따른 압축 방식을 구현하기 위해 사용될 수 있는 한 쌍의 모델의 제2 실시 예를 도시한다. 도 23은 본 개시에 따른 압축 방식을 구현하기 위해 사용될 수 있는 한 쌍의 모델의 제3 실시 예를 도시한다. 도 24는 다양한 실시 예에 따른, 네트워크 환경 내의 전자 장치의 블록도이다. 도 25는 일 실시 예에 따른, UE와 기지국이 서로 통신하는 시스템을 나타낸다."}
