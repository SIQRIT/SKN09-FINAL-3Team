{"patent_id": "10-2022-0149791", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0068392", "출원번호": "10-2022-0149791", "발명의 명칭": "디지털휴먼 컨텐츠 스트리밍 시스템 및 이를 이용한 디지털휴먼 컨텐츠 스트리밍 방법", "출원인": "트라이콤텍 주식회사", "발명자": "이상윤"}}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디지털휴먼 서버(100), 컨텐츠관리 서버(200), 메타버스 클라우드 서버(300) 및 이와 네트워크 연결된 메타버스스트리밍 서버(400)를 포함하는, 디지털휴먼 컨텐츠 스트리밍 시스템(1)에서 이뤄지는 디지털휴먼 컨텐츠 스트리밍 방법으로,a) 상기 디지털휴먼 서버(100)가, 미리 설정된 가상 모델 구성방법에 기초하여 2 이상의 가상 모델을 구성하는단계;b) 상기 디지털휴먼 서버(100)가, 미리 설정된 사용자 그룹별로 구분된 사용자 단말(500)에서 선택적으로 수집된 사용자별 모션 정보를 상기 2 이상의 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하는 단계;c) 상기 디지털휴먼 서버(100)가, 상기 사용자별 디지털휴먼 정보를 상기 메타버스 클라우드 서버(300)로 전달하는 단계;d) 상기 메타버스 클라우드 서버(300)가, 상기 컨텐츠관리 서버(200)로부터 수신된 가상 현실 컨텐츠 정보 및상기 사용자별 디지털휴먼 정보를 결합하여 사용자별 디지털휴먼 컨텐츠를 생성하고, 상기 사용자별 디지털휴먼컨텐츠를 메타버스 스트리밍 서버(400)로 전달하는 단계; 및e) 상기 메타버스 스트리밍 서버(400)가 상기 사용자별 디지털휴먼 컨텐츠를 각각의 사용자 단말(500)로 제공하여 스트리밍하는 단계;를 포함하는, 디지털휴먼 컨텐츠 스트리밍 방법."}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 e) 단계에서 스트리밍되는 사용자별 디지털휴먼 컨텐츠는 사용자 그룹별로 스트리밍 범위에 차이가 있도록각각의 사용자 단말(500)로 제공되는 것을 특징으로 하는, 디지털휴먼 컨텐츠 스트리밍 방법."}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에서,상기 미리 설정된 사용자 그룹은,상기 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하는 제1 사용자 모션 정보를 제공하는 제1 사용자그룹과,상기 제1 사용자 그룹에서 제공되는 제1 사용자 모션 정보의 변경이 가능하도록 하는 제2 사용자 모션 정보를제공하는 제2 사용자 그룹을 포함하는 것을 특징으로 하는, 디지털휴먼 컨텐츠 스트리밍 방법."}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서,상기 b) 단계에서, 상기 디지털휴먼 서버(100)는 상기 제2 사용자 모션 정보를 미리 설정된 범위 내에서 상기가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하는 것을 특징으로 하는, 디지털휴먼 컨텐츠 스트리밍방법.공개특허 10-2024-0068392-3-청구항 5 제4항에서,상기 제2 사용자 모션 정보는, 모션 캡쳐 장치를 통해 수집된 제2 사용자 그룹에 포함된 제2 사용자의 움직임 정보이며,얼굴의 움직임을 나타내는 페이스모션 정보와 바디 및 손의 움직임을 나타내는 바디모션 정보 중 적어도 어느하나를 포함하는 것을 특징으로 하는, 디지털휴먼 컨텐츠 스트리밍 방법."}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에서,상기 사용자별 디지털휴먼 컨텐츠는 2 이상의 시점에서 바라본 디지털휴먼 정보를 포함하며,상기 제1 사용자 그룹 및 제2 사용자 그룹의 사용자 단말(500) 중 적어도 어느 하나의 사용자 단말(500)은, 상기 2 이상의 시점에서 바라본 디지털휴먼 정보를 선택적으로 스트리밍할 수 있도록 구성되는 것을 특징으로 하는, 디지털휴먼 컨텐츠 스트리밍 방법."}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에서,상기 미리 설정된 사용자 그룹은,사용자 모션 정보를 제공하지 않는 제3 사용자 그룹을 더 포함하며,상기 제3 사용자 그룹의 사용자 단말(500)은, 상기 제1 사용자 그룹 및 제2 사용자 그룹에서 제공된 사용자 모션 정보에 기초하여 생성된 디지털휴먼 컨텐츠를 단순 스트리밍 하도록 구성되는 것을 특징으로 하는, 디지털휴먼 컨텐츠 스트리밍 방법."}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에서,상기 사용자별 디지털휴먼 정보는,상기 미리 설정된 사용자 그룹별로 구분된 사용자 단말(500)에서 선택적으로 수집된 사용자별 음성 정보를 더포함하는 것을 특징으로 하는, 디지털휴먼 컨텐츠 스트리밍 방법."}
{"patent_id": "10-2022-0149791", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "디지털휴먼 서버(100), 컨텐츠관리 서버(200), 메타버스 클라우드 서버(300) 및 이와 네트워크 연결된 메타버스스트리밍 서버(400)를 포함하는 디지털휴먼 컨텐츠 스트리밍 시스템(1)으로,미리 설정된 가상 모델 구성방법에 기초하여 가상 모델을 구성하고, 미리 설정된 사용자 그룹별로 구분된 사용자 단말(500)에서 선택적으로 수집된 사용자별 모션 정보를 상기 2 이상의 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하며, 상기 사용자별 디지털휴먼 정보를 상기 메타버스 클라우드 서버(300)로 전달하는 기능을 수행하는 디지털휴먼 서버(100);복수의 가상 현실 컨텐츠 정보를 관리하고, 상기 메타버스 클라우드 서버(300)의 요청에 의해 적어도 어느 하나의 가상 현실 컨텐츠 정보를 상기 메타버스 클라우드 서버(300)로 전달하는 기능을 수행하는 컨텐츠관리 서버(200);공개특허 10-2024-0068392-4-상기 컨텐츠관리 서버(200)로부터 수신된 가상 현실 컨텐츠 정보 및 상기 사용자별 디지털휴먼 정보를 결합하여사용자별 디지털휴먼 컨텐츠를 생성하고, 상기 사용자별 디지털휴먼 컨텐츠를 메타버스 스트리밍 서버(400)로전달하는 기능을 수행하는 메타버스 클라우드 서버(300); 및상기 사용자별 디지털휴먼 컨텐츠를 각각의 사용자 단말(500)로 제공하여 스트리밍하는 기능을 수행하는 메타버스 스트리밍 서버(400);를 포함하는, 디지털휴먼 컨텐츠 스트리밍 시스템."}
{"patent_id": "10-2022-0149791", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 디지털휴먼 컨텐츠 스트리밍 시스템 및 이를 이용한 디지털휴먼 컨텐츠 스트리밍 방법에 관한 것으 로, 본 발명의 바람직한 실시예에 따르면, 디지털휴먼 서버, 컨텐츠관리 서버, 메타버스 클라우드 서 버 및 이와 네트워크 연결된 메타버스 스트리밍 서버를 포함하는, 디지털휴먼 컨텐츠 스트리밍 시스템 (뒷면에 계속)"}
{"patent_id": "10-2022-0149791", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디지털휴먼 컨텐츠 스트리밍 시스템 및 이를 이용한 디지털휴먼 컨텐츠 스트리밍 방법으로서, 상세하 게는 사용자 그룹별로 선택적으로 사용자별 모션 정보를 제공하여 사용자별 디지털휴먼 컨텐츠를 생성하고, 사 용자 그룹별로 차별화된 스트리밍이 이뤄지도록 하는 디지털휴먼 컨텐츠 스트리밍 시스템 및 이를 이용한 디지 털휴먼 컨텐츠 스트리밍 방법에 관한 것이다."}
{"patent_id": "10-2022-0149791", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "코로나 등 전세계적인 감염병의 확산으로 인해, 교육, 회의, 전시회 및 대회 등에서 온라인 및 비대면 환경에 대한 요구가 증가되고 있으며, 이에 관한 연구나 수요도 급증하고 있는 실정이다. 이른바 언텍트(untact) 산업으로 대변되는 신산업이 확장되고 있으며, 다양한 컨텐츠를 비대면으로 제공하는 것 에 대한 많은 연구가 이뤄지고 있다. 종래 기술은 주로 특정 컨텐츠를 대상으로 하고 사용자에게 일방적인 컨텐츠를 전달하는데 그치고 있으므로, 가 상현실을 기반으로 하되 사용자의 다양한 참여가 가능하도록 하는 기술로 디지털휴먼 및 관련 컨텐츠를 생성하 고 이를 교육이나 공연 등 다양한 활동에 활용하는 기술이 주목받고 있다. 종래 기술의 일례로서, 대한민국 등록특허 제10-2042159호의 \"가상현실에 기반한 공연 예매 및 관람 서비스 시 스템 및 방법\"이 있다. 상기 종래기술은, 공연장의 실황을 가상현실 형태로 구현하고, 관객이 현장이 아닌 가정 등에서 공연에 대한 예 매부터 관람까지 전 과정을 온라인을 통해 수행할 수 있도록 한 가상현실에 기반한 공연 예매 및 관람 서비스 시스템 및 방법에 관한 것으로, 공연장의 영상을 실시간으로 수신 및 저장하고, 해당 공연에 대한 전자티켓이 발급된 제1 사용자 단말기의 요청에 따라 제2 사용자 단말기가 연결된 제1 사용자 단말기에 공연영상을 송출하 는 미디어 서버와, 상기 미디어 서버와 연계하여 하나 이상의 공연정보를 등록하고, 상기 공연정보를 포함하는 리스트를 웹 페이지상에 게시하며, 상기 웹 페이지를 통한 제1 사용자 단말기의 예매 요청에 따라 상기 전자티 켓을 발급하는 예매 서버를 포함하여 구성된다. 상기 종래기술은 공연장에 대하여 실시간으로 촬영된 공연영상을 개인이 소지한 헤드 마운티드 장치(HMD)를 통 해 실시간 또는 비실시간으로 재생할 수 있도록 함으로써, 사용자가 직접 공연장에 방문하지 않고도 현장감 있 는 공연을 관람할 수 있도록 하는 장점이 있으나, 실제 공연자 및 관람자 모두 직접 공연장에 방문하지 않고도 현장감 있는 공연을 수행하거나 관람할 수 없다는 한계가 있으며, 단순히 HMD에 의해 관람이 이뤄지도록 함으로 써, 관람자의 행동에 따른 공연자의 피드백 등을 전혀 기대할 수 없다는 문제가 있다."}
{"patent_id": "10-2022-0149791", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 종래기술이 가지는 문제점을 해결하기 위한 것으로서, 가상 현실을 구성하는 디지털휴먼 컨텐 츠에 모션 정보를 제공하는 사용자를 그룹별로 분류하여 참여자와 관람자 등으로 차등 구성함으로써 디지털휴먼 컨텐츠의 구성 및 스트리밍을 다양하게 구성할 수 있는 디지털휴먼 컨텐츠 스트리밍 시스템을 제공하고자 한다."}
{"patent_id": "10-2022-0149791", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 과제를 해결하기 위한 본 발명의 바람직한 실시예에 따르면, 디지털휴먼 서버, 컨텐츠관리 서버, 메타버스 클라우드 서버 및 이와 네트워크 연결된 메타버스 스트리밍 서버를 포함하는, 디지털휴먼 컨텐츠 스트 리밍 시스템에서 이뤄지는 디지털휴먼 컨텐츠 스트리밍 방법으로, a) 상기 디지털휴먼 서버가, 미리 설정된 가 상 모델 구성방법에 기초하여 2 이상의 가상 모델을 구성하는 단계; b) 상기 디지털휴먼 서버가, 미리 설정된 사용자 그룹별로 구분된 사용자 단말에서 선택적으로 수집된 사용자별 모션 정보를 상기 2 이상의 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하는 단계; c) 상기 디지털휴먼 서버가, 상기 사용자별 디지털휴먼 정보를 상기 메타버스 클라우드 서버로 전달하는 단계; d) 상기 메타버스 클라우드 서버가, 상기 컨텐츠관리 서 버로부터 수신된 가상 현실 컨텐츠 정보 및 상기 사용자별 디지털휴먼 정보를 결합하여 사용자별 디지털휴먼 컨 텐츠를 생성하고, 상기 사용자별 디지털휴먼 컨텐츠를 메타버스 스트리밍 서버로 전달하는 단계; 및 e) 상기 메 타버스 스트리밍 서버가 상기 사용자별 디지털휴먼 컨텐츠를 각각의 사용자 단말로 제공하여 스트리밍하는 단계;를 포함하는, 디지털휴먼 컨텐츠 스트리밍 방법이 제공된다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 e) 단계에서 스트리밍되는 사용자별 디지털휴먼 컨텐츠는 사용자 그룹별로 스트리밍 범위에 차이가 있도록 각각의 사용자 단말로 제공되는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 미리 설정된 사용자 그룹은, 상기 가상 모델과 매칭하여 사 용자별 디지털휴먼 정보를 생성하는 제1 사용자 모션 정보를 제공하는 제1 사용자 그룹과, 상기 제1 사용자 그 룹에서 제공되는 제1 사용자 모션 정보의 변경이 가능하도록 하는 제2 사용자 모션 정보를 제공하는 제2 사용자 그룹을 포함하는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 b) 단계에서, 상기 디지털휴먼 서버는 상기 제2 사용 자 모션 정보를 미리 설정된 범위 내에서 상기 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하는 것 을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 제2 사용자 모션 정보는, 모션 캡쳐 장치를 통해 수집된 제 2 사용자 그룹에 포함된 제2 사용자의 움직임 정보이며, 얼굴의 움직임을 나타내는 페이스모션 정보와 바디 및 손의 움직임을 나타내는 바디모션 정보 중 적어도 어느 하나를 포함하는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 사용자별 디지털휴먼 컨텐츠는 2 이상의 시점에서 바라본 디지털휴먼 정보를 포함하며, 상기 제1 사용자 그룹 및 제2 사용자 그룹의 사용자 단말 중 적어도 어느 하나의 사용자 단말은, 상기 2 이상의 시점에서 바라본 디지털휴먼 정보를 선택적으로 스트리밍할 수 있도록 구성되는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 미리 설정된 사용자 그룹은, 사용자 모션 정보를 제공하지 않는 제3 사용자 그룹을 더 포함하며, 상기 제3 사용자 그룹의 사용자 단말은, 상기 제1 사용자 그룹 및 제2 사 용자 그룹에서 제공된 사용자 모션 정보에 기초하여 생성된 디지털휴먼 컨텐츠를 단순 스트리밍 하도록 구성되 는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 상기 사용자별 디지털휴먼 정보는, 상기 미리 설정된 사용자 그 룹별로 구분된 사용자 단말에서 선택적으로 수집된 사용자별 음성 정보를 더 포함하는 것을 특징으로 한다. 또 다른 본 발명의 바람직한 실시예에 따르면, 디지털휴먼 서버, 컨텐츠관리 서버, 메타버스 클라우드 서버 및 이와 네트워크 연결된 메타버스 스트리밍 서버를 포함하는 디지털휴먼 컨텐츠 스트리밍 시스템으로, 미리 설정 된 가상 모델 구성방법에 기초하여 가상 모델을 구성하고, 미리 설정된 사용자 그룹별로 구분된 사용자 단말에 서 선택적으로 수집된 사용자별 모션 정보를 상기 2 이상의 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하며, 상기 사용자별 디지털휴먼 정보를 상기 메타버스 클라우드 서버로 전달하는 기능을 수행하는 디지털 휴먼 서버; 복수의 가상 현실 컨텐츠 정보를 관리하고, 상기 메타버스 클라우드 서버의 요청에 의해 적어도 어 느 하나의 가상 현실 컨텐츠 정보를 상기 메타버스 클라우드 서버로 전달하는 기능을 수행하는 컨텐츠관리 서버; 상기 컨텐츠관리 서버로부터 수신된 가상 현실 컨텐츠 정보 및 상기 사용자별 디지털휴먼 정보를 결합하 여 사용자별 디지털휴먼 컨텐츠를 생성하고, 상기 사용자별 디지털휴먼 컨텐츠를 메타버스 스트리밍 서버로 전 달하는 기능을 수행하는 메타버스 클라우드 서버; 및 상기 사용자별 디지털휴먼 컨텐츠를 각각의 사용자 단말로 제공하여 스트리밍하는 기능을 수행하는 메타버스 스트리밍 서버;를 포함하는, 디지털휴먼 컨텐츠 스트리밍 시 스템이 제공된다."}
{"patent_id": "10-2022-0149791", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 사용자 그룹별로 선택적으로 모션 정보를 제공하여 다양한 형태의 디지털휴먼 컨텐츠를 생성 할 수 있고, 사용자 그룹별로 차별화된 스트리밍 정보를 제공하도록 함으로써, 자원사용에 따른 부하를 감소시 키고 효율적인 디지털휴먼 컨텐츠 스트리밍이 이뤄지도록 하는 효과가 있다. 특히 본 발명은 디지털휴먼 컨텐츠의 생성 및 스트리밍과 관련있는 사용자 그룹을 참여자(또는 공연자), 관람자, 시청자 등으로 다양하게 구성함으로써, 현장감 있는 스트리밍이 가능하다는 장점이 있다. 또한 본 발명은 가상 모델을 구성하기 위한 텍스쳐링 및/또는 리깅 등의 후처리 공정이 인공지능에 의해 자동으 로 수행되도록 함으로써, 신속하고 효율적인 가상 모델 구성이 이뤄질 수 있다는 장점이 있다. 또한 본 발명은 시그니처 모션을 통해 디지털휴먼 컨텐츠 구성 및 관리가 용이하게 이뤄질 수 있다는 장점이 있 다."}
{"patent_id": "10-2022-0149791", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명의 실시예를 첨부된 도면을 참조하여 상세히 설명한다. 그러나 본 발명을 설명함에 있어 공 지의 구성을 구체적으로 설명함으로 인하여 본 발명의 기술적 사상을 흐리게 하거나 불명료하게 하는 경우에는 위 공지의 구성에 관하여는 그 설명을 생략하기로 한다. 본 발명에 따른 '사용자 모델'은 가상 모델을 구성하는 기초가 되는 사용자 이미지 정보, 디지털휴먼 정보에 포 함된 모션 정보 및/또는 음성 정보를 수집하는 대상이 되는 현실의 모델로서, 상기 사용자 이미지 정보, 모션 정보 및 음성 정보는 하나의 사용자 모델이 2 이상의 정보를 제공할 수도 있고, 서로 다른 사용자 모델이 각각 의 정보를 제공할 수도 있다. 예를들어, 하나의 사용자 모델이 가상 모델을 구성하는 기초가 되는 사용자 이미 지 정보를 제공하고, 다른 사용자 모델이 모션 정보 및 음성 정보를 제공하도록 구성될 수 있다. 이 때, 상기 다른 사용자 모델은 후술하는 제1 사용자 그룹 및 제2 사용자 그룹에 포함된 어느 하나의 사용자일 수 있다. 이하, 디지털휴먼 컨텐츠 스트리밍 시스템 및 이를 이용한 디지털휴먼 컨텐츠 생성 방법에 대해 도면을 기준 으로 상세히 설명한다.도 1은 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 스트리밍 시스템의 구성도, 도 3은 본 발명의 일실시예에 따른 디지털휴먼 서버의 구성도이다. 본 발명의 일례에 따른 디지털휴먼 컨텐츠 스트리밍 시스템은, 도 1에 도시된 바와 같이, 디지털휴먼 서버 , 컨텐츠관리 서버, 메타버스 클라우드 서버 및 이와 네트워크 연결된 메타버스 스트리밍 서버 를 포함한다. 상기 디지털휴먼 서버는 미리 설정된 가상 모델 구성방법에 기초하여 가상 모델을 구성한다. 상기 디지털 휴먼 서버는 미리 설정된 사용자 그룹별로 구분된 사용자 단말에서 선택적으로 수집된 사용자별 모션 정보를 상기 2 이상의 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하며, 상기 사용자별 디지털휴먼 정보를 상기 메타버스 클라우드 서버로 전달하는 기능을 수행할 수 있다. 본 발명의 일례에 따른 디지털휴먼 서버는, 도 3에 도시된 바와 같이, 가상 모델 생성 스튜디오에서 수집된 사용자 이미지 정보, 사용자 단말에서 수집된 모션 정보는 물론 가상 모델 구성 및 디지털휴먼 생 성 과정에서 일시적으로 발생된 데이터(정보)를 저장하도록 하는 메모리부, 통신모듈을 포함하여 구성되는 통신부, 가상 모델의 구성 및 관리가 이뤄지도록 하는 가상 모델 구성/관리부, 디지털휴먼 정보의 생 성 및 관리가 이뤄지도록 하는 디지털휴먼 정보 생성/관리부 및 서버의 전반적인 운영이 이뤄지도록 하는 운영부를 포함한다. 상기 사용자별 디지털휴먼 정보는 각각의 사용자의 모션 정보와 가상 모델이 매칭하여 형성되는 것으로, 특정 사용자 그룹의 사용자의 경우 해당 사용자의 모든 모션 정보가 가상 모델과 결합될 수도 있고, 다른 사용자 그 룹의 사용자의 경우 해당 사용자의 일부의 모션 정보만 가상 모델과 결합될 수도 있는 등 사용자 그룹별로 가상 모델과 결합할 수 있는 모션 정보의 종류 또는 양(시간)에 차이를 둘 수 있으며, 자세한 내용은 후술한다. 상기 컨텐츠관리 서버는, 복수의 가상 현실 컨텐츠 정보를 관리하고, 상기 메타버스 클라우드 서버의 요청에 의해 적어도 어느 하나의 가상 현실 컨텐츠 정보를 상기 메타버스 클라우드 서버로 전달하는 기능 을 수행할 수 있다. 상기 컨텐츠관리 서버는, 서버 운영의 전반적인 기능을 담당하는 운영모듈, 사용자 모델 관리모듈, 디지털 휴먼 정보 관리모듈, 가상 현실 컨텐츠 정보 관리모듈 및 통신모듈을 구비할 수 있다. 일례로, 상기 컨텐츠관리 서버는, 상기 메타버스 클라우드 서버와 메타버스 스트리밍 서버를 중 계하여 메타버스 클라우드 서버로부터 디지털휴먼 컨텐츠를 메타버스 스트리밍 서버로 전달하도록 구 성될 수도 있으며, 이 경우 상기 디지털휴먼 컨텐츠를 관리하는 디지털휴먼 컨텐츠 관리모듈(미도시)을 더 구비 할 수 있다. 상기 복수의 가상 현실 컨텐츠 정보는 상기 컨텐츠관리 서버에 구비된 저장매체(미도시)에 미리 저장될 수 도 있으나, 바람직하게 상기 컨텐츠관리 서버와 네트워크 연결된 별도의 가상 현실 컨텐츠 정보 DB(미도시)에 저장될 수 있으며, 스트리밍 가능한 영상컨텐츠 형태로 구성되어 유튜브(youtube) 등 다양한 종류 의 외부 스트리밍 서버로부터 전달 받을 수도 있다. 일례로, 상기 가상 현실 컨텐츠 정보는 교육컨텐츠, 전시컨 텐츠 및 공연컨텐츠를 포함 다양한 분야에서 가상 현실을 직접, 간접적으로 체험할 수 있는 영상컨텐츠에 관한 것으로, 다양한 컨텐츠 서버에서 생성 및 저장될 수 있다. 상기 메타버스 클라우드 서버는, 상기 컨텐츠관리 서버로부터 수신된 가상 현실 컨텐츠 정보 및 상기 사용자별 디지털휴먼 정보를 결합하여 사용자별 디지털휴먼 컨텐츠를 생성하고, 상기 사용자별 디지털휴먼 컨텐 츠를 메타버스 스트리밍 서버로 전달하는 기능을 수행할 수 있다. 일례로, 상기 메타버스 클라우드 서버는, 서버 운영의 전반적인 기능을 담당하는 운영모듈, 디지털휴먼 컨 텐츠 DB, 디지털휴먼 컨텐츠 관리모듈, 이벤트 정보 관리모듈 및 통신모듈을 구비할 수 있다. 상기 사용자별 디지털휴먼 컨텐츠는 상기 사용자별 디지털휴먼 정보에 가상 현실 컨텐츠 정보가 결합된 것으로, 일례로, 하나의 상황(예, 콘서트, 전시회, 교육 등)에 하나의 가상 현실 컨텐츠 정보를 수신하고, 동일한 가상 현실 컨텐츠 정보에 각각의 사용자별 디지털휴먼 정보를 위치 및/또는 시간만 달리하여 배치하는 형태로 구성될 수 있다. 다른 예로, 각각의 가상 현실 컨텐츠 정보가 각각의 사용자별 디지털휴먼 정보에 맞춤형으로 별도로 구성되어 각각 결합하도록 함으로써 사용자별로 독창적인 디지털휴먼 컨텐츠가 생성되도록 구성될 수도 있다. 상기 이벤트 정보 관리모듈은 디지털휴먼 컨텐츠 관리모듈에 통합될 수 있으며, 상기 디지털휴먼 컨텐츠 DB에는 미리 설정된 이벤트 정보가 함께 저장될 수 있다. 상기 메타버스 스트리밍 서버는 상기 사용자별 디지털휴먼 컨텐츠를 각각의 사용자 단말로 제공하여 스트리밍하는 기능을 수행할 수 있다. 다양한 사용자들은 각자의 사용자 단말을 통해 상기 메타버스 스트리밍 서버에서 제공되는 사용자별 디지털휴먼 컨텐츠를 시청할 수 있게 된다. 상기 메타버스 스트리밍 서버는 서버 운영의 전반적인 기능을 담당하는 운영모듈, 디지털휴먼 컨텐츠 스트 리밍 모듈, 스트리밍 전환 모듈 및 통신모듈을 구비할 수 있다. 상기 스트리밍 서버는 상기 사용자별 디지털휴먼 컨텐츠의 실시간 스트리밍 서비스 이외에도, 다양한 형태 의 영상컨텐츠를 보유할 수도 있으며, 상기 컨텐츠관리 서버에 영상컨텐츠를 제공할 수도 있다. 상기 메타버스 스트리밍 서버는 사용자 그룹별로 스트리밍되는 사용자별 디지털휴먼 컨텐츠의 범위가 차별 화되도록 구성될 수 있으며 상세한 내용은 후술한다. 상기 메타버스 스트리밍 서버는 사용자별로 서로 다른 다양한 형태의 사용자 단말에 대응하도록 다양 한 스트리밍 프로토콜을 포함하여 구성될 수 있다. 상기 디지털휴먼 컨텐츠 스트리밍 모듈은, RTSP(Real Time Streaming Protocol), RTMP(Real Time Messaging Protocol) 등의 스트리밍 프로토콜이나 HLS(Http Live Streaming) 등의 적응형 HTTP 스트리밍 프로토콜을 동시 에 또는 어느 하나를 포함할 수 있으며, 프로그레시브(Progressive) 다운로드 기능을 부가적으로 구성할 수도 있다. 본 발명의 다른 실시예에 따른 디지털휴먼 컨텐츠 스트리밍 시스템은, 가상 모델을 구성하기 위해 사용자 모 델의 사용자 이미지를 수집할 수 있도록 하는 가상 모델 생성 스튜디오 및/또는 사용자 모델의 모션 정보 를 수집할 수 있도록 하는 모션 정보 수집 스튜디오를 더 구비할 수 있다. 상기 모션 정보 수집 스튜디오는 후술하는 제1 사용자 그룹의 사용자가 직접 방문하여 사용자별 모션 정보 를 수집할 수 있도록 구성될 수도 있다. 상기 사용자 단말은 사용자별 디지털휴먼 컨텐츠를 표시할 수 있는 표시장치로 이해될 수 있으며, 표시장 치가 구비된 스마트폰, 태블릿 등의 휴대단말이나 컴퓨터일 수 있고, HMD(Head Mount Display) 등의 가상 현실 컨텐츠를 표시할 수 있는 VR(Virtual Reality) 장치일 수 있다. 상기 사용자 단말은 이동 가능하도록 구성 함으로써 언제 어디서나 다양한 디지털휴먼 컨텐츠를 활용할 수 있도록 하는 것이 바람직하며, 이를 위해 무선 으로 네트워크를 구성하는 것이 바람직하다. 일례로, 상기 사용자 단말은 사용자의 모션 정보를 수집할 수 있도록 하는 모션 정보 수집 장치를 더 구비 할 수 있으며, 다른 예로, 별도의 모션 정보 수집 장치로부터 수집된 사용자의 모션 정보를 네트워크를 통해 상 기 디지털휴먼 서버로 전달할 수 있도록 유무선 통신으로 모션 정보 수집 장치와 연결될 수도 있다. 상기 사용자 단말은 사용자 그룹별로 다르게 구성될 수 있으며, 상세한 내용은 후술한다. 상기 네트워크는 5G 기반의 네트워크로 구성될 수 있으며, 기존의 저속 네트워크망에 비해 5G 기반의 네트워크 로 구성되는 경우, 상기 가상 현실 컨텐츠 정보는 물론 디지털휴먼 정보의 데이터를 효율적으로 전달하는 과정 에서 데이터 손실이나 시간 지연이 발생할 가능성이 높으므로, 보다 빠르고 대용량의 데이터 전송이 이뤄질 수 있도록 한다는 점에서 5G 기반의 네트워크로 구성되는 것이 바람직하다. 도 2는 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 스트리밍 방법의 순서도, 도 6은 본 발명의 일실시예에 따른 가상 모델 생성 스튜디오의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타내는 모식도, 도 7은 본 발 명의 일실시예에 따른 모션 정보 수집 장치의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타내는 모식도, 도 8은 본 발명의 일실시예에 따른 가상 모델을 구성하는 단계를 설명하는 순서도, 도 9는 본 발명의 다른 실시 예에 따른 가상 모델 생성 스튜디오의 구성을 나타내는 모식도, 도 10은 본 발명의 다른 실시예에 따른 가상 모 델을 구성하는 단계를 설명하는 순서도이다. 본 발명의 바람직한 실시예에 따른 디지털휴먼 컨텐츠 스트리밍 방법은, 상기 디지털휴먼 서버, 컨텐츠관 리 서버, 메타버스 클라우드 서버 및 이와 네트워크 연결된 메타버스 스트리밍 서버를포함하는, 디지털휴먼 컨텐츠 스트리밍 시스템에서 이뤄진다. 일례로 상기 디지털휴먼 컨텐츠 스트리밍 방법은, 가상 모델 구성 단계(a), 사용자별 디지털휴먼 정보 생성 단 계(b), 사용자별 디지털휴먼 정보 전달 단계(c), 사용자별 디지털휴먼 컨텐츠 생성 및 전달 단계(d) 및 사용자 별 디지털휴먼 컨텐츠 스트리밍 단계(e)를 포함하여 이뤄진다. 상기 가상 모델 구성 단계(a)는 상기 디지털휴먼 서버가, 미리 설정된 가상 모델 구성방법에 기초하여 2 이상의 가상 모델을 구성하는 단계이다. 도 8에 도시된 바와 같이, 상기 a 단계의 미리 설정된 가상 모델 구성방법은, 상기 디지털휴먼 서버와 네 트워크 연결된 가상 모델 생성 스튜디오에 구비된 전신 캡쳐 장치를 통해 사용자 모델을 촬영하여 사용자 이미지 정보를 수집하는 단계(a1), 상기 사용자 이미지 정보에 기초하여 가상 모델 기초 모델링 정보를 생성하 는 단계(a2) 및 상기 생성된 가상 모델 기초 모델링 정보를 후처리하여 가상 모델을 구성하는 단계(a3)를 포함 하여 이뤄질 수 있다. 상기 가상 모델 생성 스튜디오는, 도 6에 도시된 바와 같이, 전신 캡쳐 장치를 포함하며, 상기 전신 캡쳐 장치는 적어도 복수개의 카메라와 조명(126, 126')을 구비하며, 상기 복수개의 카메라 및 조명(126, 126')을 제어하고 사용자 이미지 정보를 획득하여 네트워크를 통해 상기 디지털휴먼 서버로 전 달하는 기능을 수행하는, 통신모듈이 구비된 제어부를 포함하여 이뤄진다. 예를 들어, 상기 전신 캡쳐 장치는, 16 내지 64개의 볼류메트릭 카메라(volumetric camera) 또는 32 내지 128개의 포토그래메트릭 카메라(photogrammetric camera)가 사용자 모델이 내부에 수용될 수 있는 철제 프레임 (도면 부호 미도시)의 외부에 고르게 구비되어 사용자 모델의 360도 전신을 촬영할 수 있도록 구성될 수 있다. 예를 들어, 상기 볼류메트릭 카메라는 RGB-D 카메라, 키넥트 센서가 결합된 RGB 카메라 등 깊이값을 생성할 수 있는 카메라일 수 있다. 상기 조명(126, 126')은 사용자 모델에 그림자가 발생하지 않도록 다수개 구비될 수 있으며, 불필요한 그림자로 인해 사용자 이미지의 품질이 저하되는 것을 방지하면서 사용자 모델의 텍스쳐가 잘 드러날 수 있도록 배치 및 설정하는 것이 바람직하다. 상기 조명(126, 126')은 후술하는 텍스쳐링 및 리깅 자동화를 위해 다양한 위치에 구비되거나 2 이상의 파장을 조사할 수 있도록 구성될 수도 있다. 상기 사용자 이미지 정보에 기초하여 가상 모델 기초 모델링 정보를 생성하는 단계(a2)는, 사용자 모델(UM)의 360도 전신에 대한 사용자 이미지를 수집하고, 각각의 이미지를 인공지능을 이용하여 결합시키면서 자동화된 모 델링 과정을 거쳐 가상 모델 기초 모델링 정보를 생성하는 것이다. 일례로, 상기 가상 모델 기초 모델링 정보는 사용자 모델(UM)의 입체감 없는 360도 외형으로 이해될 수 있다. 다른 예로, 상기 가상 모델 기초 모델링 정보는 상기 전신 캡쳐 장치에 볼류메트릭 카메라를 이용하는 경 우 사용자 모델의 사용자 이미지로부터 깊이값을 측정하여 저품질의 텍스쳐링 및/또는 리깅이 이뤄짐으로써 색 상 및 질감이나 관절 및 뼈대가 간단히 부여된 상태의 360도 외형일 수도 있다. 상기 가상 모델 기초 모델링 정보는 텍스쳐링(texturing) 및 리깅(rigging) 등의 후처리를 거쳐 입체감 있는 3 차원의 가상 모델을 구성할 수 있다. 일례로, 상기 a3 단계는, 상기 가상 모델 기초 모델링 정보에 색상 및 질감을 부여하여 입체감이 생기도록 하는 텍스쳐링 단계(a31) 및 상기 가상 모델 기초 모델링 정보에 관절 및 뼈대를 부여함으로써 후술하는 사용자별 모 션 정보와 결합하여 가상 모델의 움직임이 가능하도록 하는 리깅 단계(a32)를 포함할 수 있다. 이 때, 상기 a31 단계(텍스쳐링 단계) 및 a32 단계(리깅 단계) 중 적어도 어느 하나는 인공지능 처리 모듈에 의해 자동으로 이뤄 질 수 있다. 예를 들어, 도 10에 도시된 바와 같이, 사용자 모델(UM)의 사용자 이미지를 수집하고, 상기 사용자 이미지에 기 초하여 가상 모델 기초 모델링 정보(AM1)를 생성할 수 있으며, 텍스쳐링된 가상 모델 기초 모델링 정보(AM2) 및 리깅을 통한 입체화가 이뤄진 가상 모델(AM)을 순차적으로 구성할 수 있다. 미설명된 도면부호 RGM은 상기 텍스 쳐링된 가상 모델 기초 모델링 정보(AM2)에 관절 및 뼈대를 부여하기 위한 리깅 기초 모델이다. 종래 상기 텍스쳐링 단계 및 리깅 단계는 디자이너 또는 그래픽 엔지니어가 가상 모델을 구성(생성)하기 위해 수작업을 통해 후처리하도록 함으로써 디지털휴먼 컨텐츠 생성에 많은 시간과 인력이 소비된다는 문제가 있었으 며, 볼류메트릭 카메라를 이용하는 경우에도 텍스쳐링 및 리깅의 품질이 좋지 않아 추가적인 작업을 필요로 하였다. 그러나 본 발명에 따른 후처리 공정은 상기 텍스쳐링 단계(a31) 및/또는 리깅 단계(a32)를 자동으로 이뤄질 수 있도록 함으로써 효율적으로 디지털휴먼 컨텐츠를 생성할 수 있다. 일례로, 상기 a31 단계는, 상기 전신 캡쳐 장치에 구비된 적어도 하나 이상의 서로 다른 위치 또는 서로 다른 파장을 갖는 복수개의 조명에 의해 촬영된 적어도 2 이상의 사용자 이미지 정보에 기초하여 자동으로 처리될 수 있다. 도 9에 도시된 바와 같이, 우선 사용자 모델(UM)의 그림자가 발생하지 않도록 조명을 제어하면서 사용자 이미지를 획득(도 9 (a) 참고)한 다음, 특정 위치의 조명을 더 켜거나 끈 상태 또는 조명의 파장을 조절하여 일 부 조명(126')이 다른 파장을 갖도록 함으로써 기존 수집된 사용자 이미지에서 변경된 사용자 이미지를 획득(도 9 (b) 참고)하고, 최초의 사용자 이미지와 변경된 사용자 이미지의 차이점 분석을 인공지능 처리 모듈로 수행함 으로써 텍스쳐링이 더욱 부각되고 가상 모델 기초 모델링 정보에 텍스쳐링이 자동으로 처리될 수 있게 된다. 도 11은 본 발명의 일실시예에 따른 사용자 모델의 포즈 이미지를 설명하는 모식도이다. 일례로, 상기 사용자 이미지 정보는, 상기 사용자 모델의 복수개의 미리 설정된 포즈 이미지 정보(PI1, PI2, PI3)를 포함하며, 상기 a32 단계는, 상기 사용자 모델의 포즈 이미지 정보(PI1, PI2, PI3)에 기초하여 자동으로 처리될 수 있다. 예를 들어, 본 발명의 일례에 따른 디지털휴먼 컨텐츠 스트리밍 시스템은 상기 가상 모델 생성 스튜디오 에서 사용자 모델이 미리 설정된 포즈를 취하도록 하면서, 각각의 미리 설정된 포즈에 기초한 사용자 이미 지를 추가적으로 수집하도록 할 수 있다. 이 경우 상기 미리 설정된 포즈를 취하기 전의 사용자 이미지 정보(PI0)와 상기 사용자 모델의 포즈 이미지 정 보(PI1, PI2, PI3)를 비교함으로써 리깅 작업을 위한 사용자 모델의 관절과 뼈대의 형태를 용이하게 파악할 수 있다. 이러한 미리 설정된 포즈를 취하기 전의 사용자 이미지 정보(PI0)와 사용자 모델의 포즈 이미지 정보(PI1, PI2, PI3)를 비교한 데이터 즉, 차이점 분석 정보는 지속적으로 디지털휴먼 서버에 저장될 수 있다. 다양한 크 기 및 형상을 갖는 사용자 모델의 미리 설정된 포즈를 통한 차이점 분석 정보가 누적되면서 가상 모델 기초 모 델링 정보에 대한 리깅작업의 고도화(정밀한 리깅 작업)가 이뤄질 수 있다. 특히 각각의 사용자 이미지 정보 (PI0)와 상기 사용자 모델의 미리 설정된 포즈 이미지 정보(PI1, PI2, PI3)의 비교 분석을 인공지능 처리 모듈 로 수행함으로써 가상 모델 기초 모델링 정보에 리깅이 자동으로 처리될 수 있게 된다. 상기 텍스쳐링 단계 (a31) 및 리깅 단계(a32)는 동시 또는 순차로 이뤄질 수 있으며, a32 단계가 a31 단계 이전에 이뤄질 수도 있다. 본 발명의 일례에 따른 사용자별 모션 정보는 각각의 사용자 그룹의 사용자 단말로부터 수집되도록 하는 것이 바람직하다. 이를 위해 상기 각각의 사용자 그룹의 사용자 단말은 모션 캡쳐 장치(모듈)를 구비할 수 있다. 상기 모션 정보는 각각의 사용자 그룹의 사용자별 움직임 정보(표정 및/또는 움직임)이며, 얼굴의 움직임을 나 타내는 페이스모션 정보와, 바디 및 손의 움직임을 나타내는 바디모션 정보 중 적어도 어느 하나를 포함할 수 있다. 상기 페이스모션 정보는, 사용자 모델(예, 사용자 그룹별 사용자)의 시선이나 표정 등을 통해 사용자 모델의 감 정이나 심리 상태 등이 전달될 수 있도록 하는 것이며, 바디모션 정보는 사용자 모델의 움직임이 전달될 수 있 도록 하는 것이다. 상기 모션 캡쳐 장치는 스마트폰 카메라 등 사용자 단말의 카메라일 수 있으며, 별도로 사용자의 신체에 부착되어 무선통신을 통해 사용자의 모션 정보를 수집하여 사용자 단말로 전달하는 센서일 수 있다. 다른 일례로, 본 발명에 따른 사용자별 모션 정보는, 상기 디지털휴먼 서버와 네트워크 연결된 모션 정보 수집 스튜디오에 구비된 모션 캡쳐 장치를 통해 수집될 수도 있다. 상기 모션 정보 수집 스튜디오는,도 7에 도시된 바와 같이, 모션 캡쳐 장치(142, 142', 144', 146', 148')를 포함하며, 상기 모션 캡쳐 장치 (142, 142', 144', 146', 148')를 제어하고 사용자 모델(UM)의 얼굴(UF)의 움직임을 나타내는 페이스모션 정보 와 사용자 모델(UM)의 손/바디(UB)의 움직임을 나타내는 바디모션 정보 중 적어도 어느 하나를 획득하여 네트워 크를 통해 상기 디지털휴먼 서버로 전달하는 기능을 수행하는, 통신모듈이 구비된 제어부를 포함하여 이뤄진다. 일례로, 상기 모션 캡쳐 장치는 카메라 형태로 이뤄져서 사용자 모델(UM)의 신체 전체를 촬영하면서 얼굴 (UF)의 움직임과 바디(UB)의 움직임을 각각 구분하여 인식, 저장할 수 있도록 구성될 수 있다. 다른 예로, 상기 모션 캡쳐 장치는, 사용자 모델의 얼굴(UF)의 움직임 및/또는 후술하는 사용자 모델의 음성 정 보를 수집하는 페이스모션 캡쳐(감지) 장치(142')나, 사용자 모델의 바디(UB)에 다수개 부착하여 사용자 모델의 바디(UB)의 움직임 정보를 수집하는 센서(144'), 장갑(146'), 스마트 워치(148') 형태의 바디모션 캡쳐(감지) 장치(144', 146', 148')로 나누어 구성될 수도 있다. 상기 카메라 또는 페이스모션 캡쳐 장치(142')는, 사용자 모델의 얼굴의 시선처리, 표정 등을 촬영하고 시 선이나 표졍의 변화에 따른 특징점을 확인할 수 있도록 하며, 상기 디지털휴먼 서버는 이러한 특징점의 변 화를 통해 사용자 모델의 페이스모션 정보를 수집할 수 있다. 예를 들어, 상기 카메라에 의해 사용자 모델의 동작 이전과 이후를 비교하여 사용자 모델의 신체 움직임을 감지함으로써 사용자 모델의 바디모션 정보를 수집할 수 있다. 다른 예로, 상기 모션 정보 수집 스튜디오에 구비된 제어부와 유/무선 연결된 바디모션 캡쳐 장치 (144')를 이용하는 경우, 상기 바디모션 캡쳐 장치(144')는 위치센서, 기울기 센서 등의 다양한 형태의 센서일 수 있으며, 사용자 모델의 신체에 부착되어 사용자 모델의 동작에 따라 위치가 변경되는 경우 변경된 상태 정보 를 제어부에 전달함으로써 사용자 모델의 움직임에 따른 사용자 모델 바디모션 정보를 수집할 수 있게 된 다. 상기 제어부는 통신모듈을 통해 상기 카메라, 페이스모션 감지장치(142') 및/또는 바디모션 감지장치 (144', 146', 148')에 의해 수집된 사용자 모델의 페이스모션 정보 및/또는 사용자 모델의 바디모션 정보를 상 기 디지털휴먼 서버로 전달한다. 도 4는 본 발명의 일실시예에 따른 사용자별 디지털휴먼 컨텐츠의 모식도, 도 5는 본 발명의 또 다른 실시예에 따른 사용자별 디지털휴먼 컨텐츠의 모식도이다. 상기 사용자별 디지털휴먼 정보 생성 단계(b)는 상기 디지털휴먼 서버가, 미리 설정된 사용자 그룹별로 구 분된 사용자 단말에서 선택적으로 수집된 사용자별 모션 정보를 상기 2 이상의 가상 모델과 매칭하여 사용 자별 디지털휴먼 정보를 생성하는 단계이다. 일례로, 상기 미리 설정된 사용자 그룹은, 상기 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성하는 제 1 사용자 모션 정보를 제공하는 제1 사용자 그룹과, 상기 제1 사용자 그룹에서 제공되는 제1 사용자 모션 정보 의 변경이 가능하도록 하는 제2 사용자 모션 정보를 제공하는 제2 사용자 그룹을 포함할 수 있다. 일례로, 상기 b 단계에서, 상기 디지털휴먼 서버는 상기 제2 사용자 모션 정보를 미리 설정된 범위 내에서 상기 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성할 수 있다. 일례로, 상기 제2 사용자 모션 정보는, 모션 캡쳐 장치를 통해 수집된 제2 사용자 그룹에 포함된 제2 사용자의 움직임 정보이며, 얼굴의 움직임을 나타내는 페이스모션 정보와 바디 및 손의 움직임을 나타내는 바디모션 정보 중 적어도 어느 하나를 포함할 수 있다. 상기 사용자 그룹은 가상 현실 내에서 다양한 종류 및/또는 형태의 컨텐츠를 직접 또는 간접으로 경험하도록 하 는 다양성을 제공하기 위해 등급 또는 단계의 형태로 구분하는 것으로 이해될 수 있다. 가상 현실 컨텐츠 정보는 교육, 전시, 공연 등일 수 있으며, 예를 들어, 공연의 경우 공연장에서 직접 공연을 진행하는 참여자와 해당 공연장에서 공연을 관람하는 관람자를 필요로 한다. 이 때, 상기 제1 사용자 그룹과 제2 사용자 그룹은 각각 참여자와 관람자로 이해될 수 있으며, 각각 공연장에서 행하는 동작(예, 공연-관람)과 허용되는 움직임의 범위(예, 무대 위-무대 아래) 등이 다르므로 가상 현실 컨텐츠 정보와 결합하여 디지털휴먼 컨텐츠를 생성하기 위한 디지털휴먼 정보를 구성하는 모션 정보에도 제한(구 분)하는 것이 바람직하다. 일례로, 상기 제1 사용자 그룹에 해당하는 사용자(들)는 실제 공연을 행하는 사람이므로, 사용자의 모든 모션 정보(제1 사용자 모션 정보)를 그대로 제공하여 전술한 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성 할 수 있다. 일례로 상기 제2 사용자 모션 정보는 상기 바디 움직임 중에서 상반신에 대한 바디모션 정보만을 포함하도록 구 성될 수 있다. 즉, 상기 제2 사용자 그룹에 해당하는 사용자(들)는 공연을 관람하는 사람이므로, 무대 아래에서 무대 위로의 이동을 방지하거나 일정한 크기 이상의 소리를 내지 못하도록 제한하는 것이 필요하므로, 사용자의 일부 모션 정보(제2 사용자 모션 정보)만을 제공하여 전술한 가상 모델과 매칭하여 사용자별 디지털휴먼 정보를 생성할 수 있다. 예를 들어, 상기 제2 사용자 그룹에 해당하는 사용자가 제공하는 제2 사용자 모션 정보는 박수를 치거나, 공연 자(예, 제1 사용자 그룹의 사용자)를 응원하는 플래카드를 흔드는 행동일 수 있다. 이 때, 후술하는 사용자별 디지털휴먼 컨텐츠의 스트리밍이 실시간으로 이뤄지는 라이브 공연의 경우 이러한 행동이 상기 제1 사용자 그룹 의 사용자에게 보여질 수 있도록 함으로써 제1 사용자 그룹에서 제공되는 제1 사용자 모션 정보의 변경이 가능 할 수 있으며, 공연자와 관람자간의 다양한 형태의 상호 교감을 이끌어낼 수 있게 된다. 상기 사용자별 디지털휴먼 정보 전달 단계(c)는 상기 디지털휴먼 서버가, 상기 사용자별 디지털휴먼 정보 를 상기 메타버스 클라우드 서버로 전달하는 단계이다. 상기 사용자별 디지털휴먼 컨텐츠 생성 및 전달 단계(d)는, 상기 메타버스 클라우드 서버가, 상기 컨텐츠 관리 서버로부터 수신된 가상 현실 컨텐츠 정보 및 상기 사용자별 디지털휴먼 정보를 결합하여 사용자별 디지털휴먼 컨텐츠를 생성하고, 상기 사용자별 디지털휴먼 컨텐츠를 메타버스 스트리밍 서버로 전달하는 단계이다. 상기 가상 현실 컨텐츠 정보 및 사용자별 디지털휴먼 정보와 결합하여 생성된 사용자별 디지털휴먼 컨텐츠는 상 기 메타버스 클라우드 서버에 저장될 수 있다. 상기 사용자별 디지털휴먼 컨텐츠 스트리밍 단계(e)는, 상기 메타버스 스트리밍 서버가 상기 사용자별 디 지털휴먼 컨텐츠를 각각의 사용자 단말로 제공하여 스트리밍하는 단계이다. 상기 e 단계에서는, 후술하는 미리 설정된 이벤트 정보가 함께 표시될 수 있으며, 사용자는 상기 이벤트 정보를 통해 가상 현실 컨텐츠 정보와 사용자별 디지털휴먼 정보가 포함된 디지털휴먼 컨텐츠를 더욱 실감있게 시청할 수 있다. 일례로, 상기 e 단계에서 스트리밍되는 사용자별 디지털휴먼 컨텐츠는 사용자 그룹별로 스트리밍 범위에 차이가 있도록 각각의 사용자 단말로 제공될 수 있다. 예를 들어, 제2 사용자 그룹의 사용자 단말은 VR 장치 또는 2차원이나 3차원 표시장치일 수 있으며, 도 4 에 도시된 바와 같이, 공연자(제1 사용자 그룹의 사용자)의 모습(디지털휴먼 정보, U1) 및 공연 무대(가상 현실 컨텐츠 정보, MVSC, Metaverse Virtual Space Contents)가 사용자별 디지털휴먼 컨텐츠(MDHC, Metaverse Digital Human Contents)로 스트리밍되도록 구성될 수 있다. 또한 도 5에 도시된 바와 같이, 제2 사용자 그룹의 사용자 단말에 제공되는 사용자별 디지털휴먼 컨텐츠 (MDHC)는 제2 사용자 그룹의 사용자가 공연 무대가 아닌 관람석에 앉아 있는 제2 사용자 그룹의 다른 사용자의 모습(디지털휴먼 정보, U2)일 수도 있다. 예를 들어, 제1 사용자 그룹의 사용자 단말은 VR 장치 또는 2차원이나 3차원 표시장치일 수 있으며, 공연 자의 시점에서 바라보는 공연 무대나 관람자(제2 사용자 그룹의 사용자)의 모습이 사용자별 디지털휴먼 컨텐츠 (MDHC)로 스트리밍되도록 구성될 수 있다. 또한 제1 사용자 그룹의 사용자 단말에서 제1 사용자의 선택에 따라 공연자인 자신의 모습이 어떻게 보여지는지를 확인할 수 있도록, 후술하는 가상 카메라의 각각의 위치에서 바라보는 이미지/영상 정보를 선택하여 스트리밍하도록 구성될 수도 있다.일례로, 상기 사용자별 디지털휴먼 컨텐츠는 2 이상의 시점에서 바라본 디지털휴먼 정보를 포함하며, 상기 제1 사용자 그룹 및 제2 사용자 그룹의 사용자 단말 중 적어도 어느 하나의 사용자 단말은, 상기 2 이상 의 시점에서 바라본 디지털휴먼 정보(U1, U1-1, U1-2)를 선택적으로 스트리밍할 수 있도록 구성될 수 있다. 상기 2 이상의 시점에서 바라본 디지털휴먼 정보는 가상 현실 컨텐츠 내에 구성되는 적어도 하나 이상의 가상 카메라(VCAM1, VCAM2)에서 바라보는 이미지/영상 정보일 수 있다. 일례로, 도 4 및 도 5에서 도시된 바와 같이 다수의 가상 카메라(VCAM1, VCAM2)를 구성하고, 각각의 사용자 그 룹의 사용자 단말에서 다양한 시점에서 바라본 디지털휴먼 정보를 스트리밍할 수 있도록 구성될 수 있다. 예를 들어, 제1 사용자 그룹의 사용자에 의해 제공된 제1 사용자 모션 정보로 형성되는 사용자별 디지털휴먼 정 보(U1, U1-1, U1-2)를 복수의 가상 카메라(VCAM1)의 시점에서 촬영하고 해당 영상을 제1 사용자 그룹의 사용자 단말에서 선택적으로 스트리밍할 수 있도록 구성될 수 있고, 제2 사용자 그룹의 사용자에 의해 제공된 제2 사용자 모션 정보로 형성되는 사용자별 디지털휴먼 정보(U2, U2-1, U2-2, U2-3)를 복수의 가상 카메라(VCAM2)의 시점에서 촬영하고 해당 영상을 제1 사용자 그룹 및/또는 제2 사용자 그룹의 사용자 단말에서 선택적으로 스트리밍할 수 있도록 구성될 수도 있다. 본 발명의 바람직한 실시예에 따르면, 상기 사용자별 디지털휴먼 정보는, 상기 미리 설정된 사용자 그룹별로 구 분된 사용자 단말에서 선택적으로 수집된 사용자별 음성 정보를 더 포함할 수 있다. 상기 사용자별 음성 정보는 제1 사용자 그룹의 경우에는 교육자, 전시 안내자(큐레이팅), 공연자 등의 음성일 수 있으며, 제2 사용자 그룹의 경우에는 응원 구호 등일 수 있다. 상기 제2 사용자 그룹에서 수집되는 사용자별 음성 정보는 공연 등에 방해가 되지 않도록 일정한 크기 이하로 스트리밍이 이뤄지도록 음량을 제한하는 것이 바람직하다. 본 발명의 또 다른 실시예에 따르면, 상기 미리 설정된 사용자 그룹은, 사용자 모션 정보를 제공하지 않는 제3 사용자 그룹을 더 포함할 수 있다. 일례로, 도 5에 도시된 바와 같이, 상기 제3 사용자 그룹의 사용자 단말은 상기 제1 사용자 그룹 및 제2 사용자 그룹에서 제공된 사용자 모션 정보에 기초하여 생성된 디지털휴먼 컨텐츠를 단순 스트리밍 하도록 구성 될 수 있다. 상기 제3 사용자 그룹은 전술한 공연자 및 관람자에 각각 해당하는 제1 사용자 그룹 및 제2 사용자 그룹과는 다 른 일반 시청자로 이해될 수 있으며, 공연 실황이나 공연을 녹화한 영상을 스트리밍할 수 있는 사용자일 수 있 다. 예를 들어, 상기 제3 사용자 그룹의 사용자는 전술한 가상의 카메라(VCAM1, VCAM2)에서 촬영한 다양한 시점의 디지털휴먼 정보를 포함하는 디지털휴먼 컨텐츠를 선택적으로 스트리밍할 수 없도록 제한할 수 있다. 이 경우 일반 시청자가 방송국에서 중계하는 공연 영상을 그대로 시청할 수 밖에 없는 것처럼, 상기 제3 사용자 그룹의 사용자 단말은 상기 제2 사용자 그룹의 사용자(예, 관람자)와의 차별화를 위해 디지털휴먼 컨텐츠 를 구성하는 기획자에 의해 미리 계획된 영상(디지털휴먼 컨텐츠)을 그대로 스트리밍하도록 하는 것이 바람직하 다. 이러한 사용자 그룹별 참여, 관람 및 시청에 따른 스트리밍 범위(권한)의 차별화를 통해 단순 시청보다는 적극적인 공연 관람을 유도할 수 있다. 본 발명의 일 실시예에 따른 디지털휴먼 컨텐츠 스트리밍 방법은 다양한 컴퓨터에서 실행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터로 판독 가능한 기록매체에 기록된다. 상기 기록매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있으며, 일 례로, 하드 디스크나 플로피 디스크 등의 자기 기록매체, CD나 DVD 등의 광기록 매체, 플롭티컬 디스크 등의 자 기광 매체, 롬, 램, 플래쉬 메모리 등일 수 있다. 상기 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되거나 구성될 수 있으며, 공지되어 사용 가능한 것일 수 있다. 일례로, 상기 프로그램 명령은 기계어 코드 또는 고급 언어 코드를 포함할 수 있다.이상에서 본 발명은 구체적인 실시예를 참조하여 상세히 설명하였으나, 상기 실시예는 본 발명을 이해하기 쉽도 록 하기 위한 예시에 불과한 것이므로, 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 치환, 부가 및 변 형된 실시 형태들 역시 하기의 청구범위에 의하여 정해지는 본 발명의 보호범위에 속한다고 할 것이다."}
{"patent_id": "10-2022-0149791", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 스트리밍 시스템의 구성도, 도 2는 본 발명의 일실시예에 따른 디지털휴먼 컨텐츠 스트리밍 방법의 순서도, 도 3은 본 발명의 일실시예에 따른 디지털휴먼 서버의 구성도, 도 4는 본 발명의 일실시예에 따른 사용자별 디지털휴먼 컨텐츠의 모식도, 도 5는 본 발명의 또 다른 실시예에 따른 사용자별 디지털휴먼 컨텐츠의 모식도, 도 6은 본 발명의 일실시예에 따른 가상 모델 생성 스튜디오의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타내는 모식도, 도 7은 본 발명의 일실시예에 따른 모션 정보 수집 장치의 구성 및 디지털휴먼 서버와의 네트워크 연결을 나타 내는 모식도, 도 8은 본 발명의 일실시예에 따른 가상 모델을 구성하는 단계를 설명하는 순서도, 도 9는 본 발명의 다른 실시예에 따른 가상 모델 생성 스튜디오의 구성을 나타내는 모식도, 도 10은 본 발명의 다른 실시예에 따른 가상 모델을 구성하는 단계를 설명하는 모식도, 도 11은 본 발명의 일실시예에 따른 사용자 모델의 포즈 이미지를 설명하는 모식도이다."}
