{"patent_id": "10-2022-0063239", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0078536", "출원번호": "10-2022-0063239", "발명의 명칭": "신경망 처리 유닛, 신경망의 처리 방법, 및 장치", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "티엔, 차오"}}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 처리 유닛(NPU)에 있어서, 부동소수점 유형의 입력 데이터를 획득하고, 상기 부동소수점 유형의 입력 데이터를 양자화하여 양자화된 입력데이터를 획득하여, 상기 양자화된 입력 데이터를 연산 유닛에 제공하고, 상기 연산 유닛에서 출력하는 연산 결과를 역양자화하여, 역양자화 결과를 획득하는 양자화 유닛; 및 상기 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 상기 입력 데이터의 연산 결과를 획득하는 상기 연산 유닛;을 포함하는,것을 특징으로 하는 신경망 처리 유닛."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 연산 유닛은 행렬-벡터 조작을 수행하는데 사용되고, 상기 양자화 유닛은, 디지털 신호 프로세서(DSP)의 내부 메모리에 저장된 부동소수점 유형의 입력 데이터에 따라 양자화에 사용하는제1 파라미터 및 역양자화에 사용하는 제2 파라미터를 구하고;상기 부동소수점 유형의 입력 데이터 중 양자화할 부동소수점 값에 제1 파라미터를 곱하고, 반올림한 후 숫자유형으로 변환하여, 숫자 유형의 입력 데이터를 획득하고;상기 숫자 유형의 입력 데이터를 상기 연산 유닛에 송신하고; 상기 연산 유닛에서 획득한 연산 결과를 부동소수점 유형으로 변환하고;부동소수점 유형의 연산 결과에 상기 제2 파라미터를 곱한 후 DSP의 메모리에 송신하여 저장하는데 사용되는, 것을 특징으로 하는 신경망 처리 유닛."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 NPU는 버스의 메인 인터페이스를 더 포함하며, 상기 메인 인터페이스는 상기 버스를 통해 메모리 복사 함수를 상기 DSP에 송신하여, 상기 DSP의 내부 메모리에액세스하여 상기 DSP의 내부 메모리에 저장된 상기 부동소수점 유형의 입력 데이터를 획득하는데 사용되는,것을 특징으로 하는 신경망 처리 유닛."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 연산 유닛은 컨볼루션 조작을 수행하는데 사용되고, 상기 양자화 유닛은, 상기 부동소수점 유형의 입력 데이터에 대해 부동소수점에서 쇼트 유형으로의 변환 조작을 수행하여, 변환 후의쇼트 유형의 입력 데이터에 대해 컨볼루션 조작을 수행하는데 사용되는,것을 특징으로 하는 신경망 처리 유닛."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 공개특허 10-2022-0078536-3-상기 NPU는 고속 액세스 인터페이스를 통해 랜덤 메모리(RAM)에 연결되며;상기 RAM은 상기 쇼트 유형의 입력 데이터를 상기 RAM에 저장하는데 사용되는,것을 특징으로 하는 신경망 처리 유닛."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 연산 유닛은 제1 레지스터, 제2 레지스터 및 누산기를 포함하며;상기 제1 레지스터는 제1 주기에서 상기 RAM으로부터 상기 쇼트 유형의 입력 데이터를 읽는데 사용되고;상기 제2 레지스터는 제1 주기 이후 복수의 후속 주기에서, PSRAM에 저장된 적어도 일부 네트워크 파라미터를읽고, 각 주기에서 읽은 상기 적어도 일부 네트워크 파라미터와 상기 제1 레지스터 중 대응되는 입력 데이터에대해 내적 연산을 수행하는데 사용되고;상기 누산기는 내적 연산의 결과를 획득하여, 상기 내적 연산의 결과에 따라 누산하여, 컨볼루션 조작의 연산결과를 획득하는데 사용되는,것을 특징으로 하는 신경망 처리 유닛."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서, 상기 NPU는,DSP에 저장된 컨볼루션 조작의 연산 결과에 따라 활성화 함수를 사용하여 활성화하고, 활성화 결과를 상기 DSP에 제공하여 저장하는데 사용되는 활성화 유닛을 더 포함하는,것을 특징으로 하는 신경망 처리 유닛."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "처리 장치에 있어서, 버스를 통해 연결되는 제1항 내지 제7항 중 어는 한 항에 따른 신경망 처리 유닛(NPU), 유사 정적 램(PSRAM) 및디지털 신호 프로세서(DSP)를 포함하며;상기 DSP는 처리할 입력 데이터를 내부 메모리에 저장하고, 상기 NPU에서 상기 입력 데이터에 대한 연산 결과를 저장하는데 사용되고;상기 PSRAM은 신경망의 네트워크 파라미터를 저장하는데 사용되는, 것을 특징으로 하는 처리 장치."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "신경망 처리 유닛(NPU)에 적용되는 신경망의 처리 방법에 있어서, 상기 NPU는 양자화 유닛 및 연산 유닛을 포함하며, 상기 처리 방법은,상기 양자화 유닛이 부동소수점 유형의 입력 데이터를 획득하고, 상기 부동소수점 유형의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 상기 양자화된 입력 데이터를 연산 유닛에 제공하는 단계; 상기 연산 유닛이 상기 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 상기 입력 데이터의 연산 결과를 획득하는 단계; 및 상기 양자화 유닛이 상기 연산 유닛에서 출력하는 연산 결과를 역양자화하여, 역양자화 결과를 획득하는 단계;를 포함하는,것을 특징으로 하는 신경망의 처리 방법.공개특허 10-2022-0078536-4-청구항 10 제9항에 있어서, 상기 양자화 유닛이 디지털 신호 프로세서(DSP)의 내부 메모리에 저장된 부동소수점 유형의 입력 데이터에 따라양자화에 사용하는 제1 파라미터 및 역양자화에 사용하는 제2 파라미터를 구하고, 상기 부동소수점 유형의 입력데이터 중 양자화할 부동소수점 값에 제1 파라미터를 곱하고, 반올림한 후 숫자 유형으로 변환하여, 숫자 유형의 입력 데이터를 획득하고, 상기 숫자 유형의 입력 데이터를 상기 연산 유닛에 송신하고; 상기 연산 유닛이 상기 숫자 유형의 입력 데이터에 대해 행렬-벡터 조작을 수행하여, 상기 연산 결과를 획득하고; 상기 양자화 유닛이 상기 연산 결과를 부동소수점 유형으로 변환하고, 부동소수점 유형의 연산 결과에 상기 제2파라미터를 곱한 후 DSP의 메모리에 송신하여 저장하는, 것을 특징으로 하는 신경망의 처리 방법."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 NPU는 버스의 메인 인터페이스를 더 포함하며, 상기 메인 인터페이스는 상기 버스를 통해 메모리 복사 함수를 상기 DSP에 송신하여, 상기 DSP의 내부 메모리에액세스하여 상기 DSP의 내부 메모리에 저장된 상기 부동소수점 유형의 입력 데이터를 획득하는데 사용되는,것을 특징으로 하는 신경망의 처리 방법."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 양자화 유닛이 상기 부동소수점 유형의 입력 데이터에 대해 부동소수점에서 쇼트 유형으로의 변환 조작을수행하고;상기 연산 유닛이 변환 후의 쇼트 유형의 입력 데이터에 대해 컨볼루션 조작을 수행하여 상기 연산 결과를 획득하는,것을 특징으로 하는 신경망의 처리 방법."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 NPU는 고속 액세스 인터페이스를 통해 랜덤 메모리(RAM)에 연결되며;상기 RAM은 상기 쇼트 유형의 입력 데이터를 상기 RAM에 저장하는데 사용되는,것을 특징으로 하는 신경망의 처리 방법."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 연산 유닛은 제1 레지스터, 제2 레지스터 및 누산기를 포함하며;상기 제1 레지스터에 의해 제1 주기에서 상기 RAM으로부터 상기 쇼트 유형의 입력 데이터를 읽고;상기 제2 레지스터에 의해 제1 주기 이후 복수의 후속 주기에서, PSRAM에 저장된 적어도 일부 네트워크 파라미터를 읽고, 각 주기에서 읽은 상기 적어도 일부 네트워크 파라미터와 상기 제1 레지스터 중 대응되는 입력 데이터에 대해 내적 연산을 수행하고;상기 누산기에 의해 내적 연산의 결과를 획득하여, 상기 내적 연산의 결과에 따라 누산하여, 컨볼루션 조작의연산 결과를 획득하는,공개특허 10-2022-0078536-5-것을 특징으로 하는 신경망의 처리 방법."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 상기 NPU는 활성화 유닛을 더 포함하며, 상기 방법은, 활성화 유닛이 DSP에 저장된 컨볼루션 조작의 연산 결과에 따라 활성화 함수를 사용하여 활성화하고, 활성화 결과를 상기 DSP에 제공하여 저장하는 단계를 더 포함하는,것을 특징으로 하는 신경망의 처리 방법."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리;를 포함하고,상기 메모리에 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서가 제9항 내지 제15항 중 어느 한 항에 따른상기 신경망의 처리 방법을 수행하는,것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서,상기 컴퓨터 명령은 상기 컴퓨터가 제9항 내지 제15항 중 어느 한 항에 따른 상기 신경망의 처리 방법을 수행하는데 사용되는,것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-0063239", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행되어, 제9항 내지 제15항 중 어느 한 항에 따른 상기 신경망의 처리 방법을 구현하는,것을 특징으로 하는 컴퓨터 프로그램."}
{"patent_id": "10-2022-0063239", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 신경망 처리 유닛, 신경망의 처리 방법 및 장치를 개시하며, 딥러닝, 음성 기술 등 분야에 관한 것이다. 구체적인 구현 수단은 신경망 처리 유닛(NPU)의 양자화 유닛이 부동소수점 유형의 입력 데이터를 획득하고, 부동소수점 유형의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 양자화된 입력 데이터를 연산 유닛에 제공하며, NPU의 연산 유닛이 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 입력 데이터의 연산 결과를 획득한 다음, 양자화 유닛이 연산 유닛에서 출력하는 연산 결과를 역양자화하여, 역양자화 결과를 획득한다. 이에 따라, 전용 NPU를 사용하여, 행렬 연산 및 컨볼루션 연산 중 적 어도 하나를 구현하므로, 당해 NPU를 음성 칩에 적용할 경우, 음성 칩의 코어의 처리 부담을 덜어 주고, 음성 칩 의 코어의 처리 효율을 향상시킬 수 있다."}
{"patent_id": "10-2022-0063239", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 딥러닝, 음성 기술 등 AI(Artificial Intelligence, 인공지능) 분야에 관한 것으로, 특히 신경망 처 리 유닛, 신경망의 처리 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0063239", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 스마트 스피커 등 전자 기기의 음성 칩에 대해, 듀얼 코어 아키텍처 중의 한 코어는 음성 처리에 사용되 고, 다른 하나는 메인 컨트롤 MCU(Microprogrammed Control Unit, 마이크로컨트롤러)의 기능(예컨대 업무 로직, 제어 로직 등)을 구현하는데 사용된다. 그러나, 단일 코어를 통해 모든 음성을 처리할 경우, 처리 부담이 상대적으로 크다. 본 출원은 신경망 처리 유닛, 신경망의 처리 방법 및 장치를 제공한다. 본 출원의 일 측면에 따르면, NPU(Network Processing Unit, 신경망 처리 유닛)를 제공하며, 부동소수점 유형의 입력 데이터를 획득하고, 상기 부동소수점 유형의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 상기 양자화된 입력 데이터를 연산 유닛에 제공하고, 상기 연산 유닛에서 출력하는 연산 결 과를 역양자화하여, 역양자화 결과를 획득하는 양자화 유닛; 및 상기 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 상기 입력 데 이터의 연산 결과를 획득하는 상기 연산 유닛을 포함한다. 본 출원의 다른 측면에 따르면, 처리 장치를 제공하며, 버스를 통해 연결되는 전술한 측면에서 제공되는 신경망 처리 유닛(NPU), 유사 정적 램(PSRAM) 및 디지털 신호 프로세서(DSP)를 포함하며; 상기 DSP는 처리할 입력 데이터를 내부 메모리에 저장하고, 상기 NPU에서 상기 입력 데이터에 대한 연산 결과 를 저장하는데 사용되고; 상기 PSRAM은 신경망의 네트워크 파라미터를 저장하는데 사용된다. 본 출원의 또 다른 측면에 따르면, 신경망의 처리 방법을 제공하며, 신경망 처리 유닛(NPU)에 적용되고, 상기 NPU는 양자화 유닛 및 연산 유닛을 포함하며, 상기 처리 방법은, 상기 양자화 유닛이 부동소수점 유형의 입력 데이터를 획득하고, 상기 부동소수점 유형의 입력 데이터를 양자화 하여 양자화된 입력 데이터를 획득하여, 상기 양자화된 입력 데이터를 연산 유닛에 제공하는 단계; 상기 연산 유닛이 상기 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행 하여, 상기 입력 데이터의 연산 결과를 획득하는 단계; 및 상기 양자화 유닛이 상기 연산 유닛에서 출력하는 연산 결과를 역양자화하여, 역양자화 결과를 획득하는 단계; 를 포함한다. 본 출원의 또 다른 측면에 따르면, 전자 기기를 제공하며, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리;를 포함하고, 상기 메모리에 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어 도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서가 본 출원의 상기 신경망의 처리 방법을 구 현한다. 본 출원의 또 다른 측면에 따르면, 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공 하며, 상기 컴퓨터 명령은 상기 컴퓨터가 본 출원의 상기 신경망의 처리 방법을 수행하는데 사용된다. 본 출원의 또 다른 측면에 따르면, 컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램을 제공하며, 상기 컴퓨터 프로그램이 프로세서에 의해 수행되는 경우 본 출원의 상기 신경망의 처리 방법을 수행한다. 이해 가능한 바로는, 본 부분에서 설명되는 내용은 본 출원의 실시예의 핵심 또는 중요한 특징을 식별하기 위한 것이 아니며, 본 출원의 범위를 한정하지도 않는다. 본 출원의 기타 특징들은 하기의 명세서에 의해 쉽게 이해 될 것이다."}
{"patent_id": "10-2022-0063239", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 결합하여 본 출원의 예시적인 실시예에 대해 설명하며, 여기에는 이해를 돕기 위해 본 출 원의 실시예의 다양한 세부 사항을 포함하므로, 이는 단지 예시적인 것으로 이해해야 한다. 따라서, 당업자는 본 출원의 범위 및 사상을 벗어나지 않는 한 여기에 설명된 실시예에 대해 다양한 변경 및 수정이 이루어질 수 있음을 인식해야 한다. 마찬가지로, 명확성과 간결성을 위해, 하기의 설명에서는 공지된 기능 및 구조에 대한 설명을 생략한다. 음성 칩의 비용를 절감하고 균형 알고리즘의 요구를 충족시키기 위해, 음성 칩의 온칩 메모리를 줄이고, SIP(System In Package, 시스템 인 패키지)를 사용하여 PSRAM(Pseudo Static Random Access Memory, 유사 정적 램)을 패키징하여 메모리를 확장하는 방법을 통해, 원래의 음성 칩을 ESP32를 통해 PSRAM에 연결하는 방법의 비 용을 절감시킨다. 즉, 기존의 수단에서는 PSRAM을 ESP32의 메인 컨트롤 칩 측에 배치하고, 외부적으로 보드 레 벨에 배치하기 때문에 추가 비용이 필요하므로 PSRAM을 음성 칩에 패키징하여 온칩 메모리를 줄이고, 외부 PSRAM의 비용을 절감할 수 있다. 그러나, 온칩 메모리의 감소 및 고대역폭의 내부 메모리의 감소함에 따라 데이터 로딩 속도가 감소하여 AI 연산 및 모델 데이터의 병렬 로딩의 위험을 유발하여, PSRAM의 대역폭 활용도를 향상시키는 방법이 매우 중요하다. 또한, 음성 칩의 면적을 절약하기 위해, 음성 칩에 있는 메인 컨트롤 MCU(Microprogrammed Control Unit, 마이 크로 컨트롤러)의 기능(음성 업무 로직, 제어 로직 등)을 ESP32에서 음성 칩으로 이동하여, 음성 칩의 듀얼 코 어 아키텍처 중 하나의 코어만 음성 처리에 사용된다. 그러나, 듀얼 코어의 연산량이 하나의 코어에 부담되어, 8x8, 16x8 곱셈 및 덧셈 연산의 해시 레이트가 부족하 여, 단일 코어로 모든 음성을 처리할 경우 처리 압력이 상대적으로 높다. 따라서, 상술한 문제를 감안하여, 본 출원은 신경망 처리 유닛, 신경망의 처리 방법 및 장치를 제공한다. 이하, 첨부된 도면을 참조하며 본 출원의 실시예의 신경망 처리 유닛, 신경망의 처리 방법 및 장치를 설명한다. 도1은 본 출원의 실시예 1에서 제공되는 NPU의 구조 개략도이다. 도1에 도시된 바와 같이, 당해 NPU는 양자화 유닛 및 연산 유닛을 포함할 수 있다. 양자화 유닛은 부동소수점 유형의 입력 데이터를 획득하고, 부동소수점 유형의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 양자화된 입력 데이터를 연산 유닛에 제공하고; 또한, 연산 유닛 에서 출력하는 연산 결과를 역양자화하여, 역양자화 결과를 획득하는데 사용된다. 연산 유닛은 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 입력 데이터의 연산 결과를 획득하는데 사용된다. 본 출원의 실시예에서, NPU를 음성 칩에 사용하는 경우, 부동소수점 유형의 입력 데이터는 사용자가 입력한 음 성 데이터의 특징 벡터에 따라 결정될 수 있다. 상응하게, 역양자화 결과는 음성 데이터에 대응되는 음성 식별 결과를 결정하는데 사용된다. 이해해야 하는 바로는, NPU는 기타 칩에 적용될 수도 잇다. 이 경우, 부동소수점 유형의 입력 데이터는 이미지 의 특징 벡터, 비디오 프레임의 특징 벡터, 텍스트의 특징 벡터 등과 같은 기타 데이터에 따라 결정될 수 있으 나, 본 출원은 이에 대해 한정하지 않는다. 본 출원의 실시예에서, 양자화 유닛에 의해 부동소수점 유형의 입력 데이터를 획득하고, 부동소수점 유형 의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 양자화된 입력 데이터를 연산 유닛에 제 공할 수 있다. 상응하게, 연산 유닛은 양자화된 입력 데이터를 수신한 후 양자화된 입력 데이터에 대해 행 렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 입력 데이터의 연산 결과를 획득하고, 연산 결과를 양자화 유닛에 출력할 수 있다. 양자화 유닛은 연산 결과를 수신한 후, 연산 결과를 역양자화하여, 역양자화 결과를 획득할 수 있다. 이에 따라, 전용 하드웨어 NPU를 사용하여, 행렬 연산 및 컨볼루션 연산 중 적어도 하나를 구현하므로, 당해 NPU를 음성 칩에 적용할 경우, 음성 칩의 코어의 처리 부담을 덜어 주고, 음성 칩의 코어의 처리 효율을 향상시킬 수 있다. 본 출원의 실시예의 NPU는, 양자화 유닛이 부동소수점 유형의 입력 데이터를 획득하고, 부동소수점 유형의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 양자화된 입력 데이터를 연산 유닛에 제공하며, 연산 유닛이 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 입력 데이 터의 연산 결과를 획득한 다음, 양자화 유닛이 연산 유닛에서 출력하는 연산 결과를 역양자화하여, 역양자화 결 과를 획득한다. 이에 따라, 전용 NPU를 사용하여, 행렬 연산 및 컨볼루션 연산 중 적어도 하나를 구현하므로, 당해 NPU를 음성 칩에 적용할 경우, 음성 칩의 코어의 처리 부담을 덜어 주고, 음성 칩의 코어의 처리 효율을 향상시킬 수 있다. 본 출원의 상기 실시예에서 입력 데이터를 양자화시키는 방법 및 연산 유닛에서 출력하는 연산 결과를 역 양자화시키는 방법을 명확하게 설명하기 위해, 이하, 연산 유닛에 의해 행렬-벡터 조작을 수행하는 것을 예로 들어 설명한다. 연산 유닛에 의해 행렬-벡터 조작을 수행하는 경우, 양자화 유닛은 DSP(Digital Signal Processor, 디지털 신호 프로세서)의 내부 메모리에 저장된 부동소수점 유형의 입력 데이터에 따라 양자화에 사용하는 제1 파라미터 및 역양자화에 사용하는 제2 파라미터를 구하고; 부동소수점 유형의 입력 데이터 중 양자화할 부동소 수점 값에 제1 파라미터를 곱하고, 반올림한 후 숫자 유형char으로 변환하여, 숫자 유형의 입력 데이터를 획득 하고; 숫자 유형의 입력 데이터를 연산 유닛에 송신하고; 연산 유닛에서 획득한 연산 결과를 부동소 수점 유형으로 변환하고; 부동소수점 유형의 연산 결과에 제2 파라미터를 곱한 후 DSP의 메모리에 송신하여 저 장한다. 본 출원의 실시예에서, 양자화에 사용하는 제1 파라미터 및 역양자화에 사용하는 제2 파라미터는 부동소수점 유 형의 입력 데이터에 따라 결정된다. 예시로서, 부동소수점 유형의 입력 데이터에 대응되는 벡터 최대값을 결정하여, 벡터 최대값을 fmax로 표기할 수 있으며, 제1 파라미터가 B이고, 제2 파라미터가 A인 경우, B는 127.0f/fmax일 수 있고, A는 fmax/127.0f일 수 있다. 그 중 하나의 char의 값 범위는 -128-127이고, 양자화 과정에서 최대 정밀도를 얻기 위해 fmax를 양자 화 값 127으로 매핑할 수 있으며; f는 float(부동소수점 유형)을 나타낸다. 본 출원의 실시예에서, NPU의 양자화 유닛은 DSP(Digital Signal Processor, 디지털 신호 프로세서) 내부 메모리에 저장된 부동소수점 유형의 입력 데이터에 따라, 양자화에 사용하는 제1 파라미터 및 역양자화에 사용하는 제2 파라미터를 구하여, 부동소수점 유형의 입력 데이터 중 양자화할 부동소수점 값(예컨대 입력 데이 터 중의 모든 부동소수점 값)에 제1 파라미터를 곱하고, 반올림한 후 숫자 유형의 입력 데이터로 변환하여, 숫 자 유형의 입력 데이터를 연산 유닛에 송신하여, 연산 유닛에 의해 숫자 유형의 입력 데이터에 대해 행렬-벡터 조작을 수행하여, 입력 데이터의 연산 결과를 획득하고, 연산 유닛은 연산 결과를 양자화 유닛 에 송신하여, 양자화 유닛에 의해 연산 유닛에서 연산하여 획득한 연산 결과를 부동소수점 유형 으로 변환하고, 부동소수점 유형의 연산 결과에 제2 파라미터를 곱한 후, 역양자화 결과를 획득하여, 역양자화 결과를 DSP의 메모리에 송신하여 저장하며, 후속 조작은 DSP의 소프트웨어에 의해 수행될 수 있다. 이에 따라, 일 측면에서는 전용 양자화 유닛을 통해 양자화 과정을 구현하는 것을 구현할 수 있고, NPU가 행렬 연산 과정을 효과적으로 수행하는 것을 보장할 수 있다. 다른 측면에서는, 부동소수점 유형의 입력 데이터 를 DSP의 메모리에 저장하는 동시에, 행렬-벡터 조작의 연산 결과를 DSP의 메모리에 저장하여, DSP는 NPU와의 Cache(고속 완충 메모리) 일관성 설계를 할 필요가 없으므로, 하드웨어 설계를 크게 단순화하고, DSP 및 NPU의 데이터 일관성 문제를 해결할 수 있다. 데이터 일관성은 DSP가 NPU의 RAM(Random Access Memory, 랜덤 메모리)(NPURAM라고 약칭함)에 액세스할 때 액 세스 데이터가 Cache에 매핑되는 것을 의미하며, NPU가 NPURAM의 데이터를 수정할 경우, DSP는 NPURAM의 수정된 데이터를 볼 수 없고, Cache의 데이터만 볼 수 있으므로 데이터 일관성 문제를 야기한다. 그러나, NPU가 DSP의 내부 메모리에 액세스할 경우, DSP의 내부 메모리가 DSP와 NPU에게 동시 보이기 때문에, 데이터 일관성 문제가 발생하지 않는다. 예시로서, NPU의 양자화 유닛은 부동소수점 유형의 입력 데이터에 대응되는 벡터 최대값(fmax)을 결 정하여, fmax에 따라 양자화에 사용하는 제1 파라미터 B 및 역양자화에 사용하는 제2 파라미터 A를 결정할 수 있고, 행렬-벡터 조작을 수행하는 과정에서 입력 데이터 중의 모든 부동소수점 값에 B를 곱할 수 있고, 그 다음 반올림하고 부동소수점 유형char으로 변환하여, char 유형의 입력 데이터를 연산 유닛에 송신하며, 연산 유닛에 의해 char 유형의 입력 데이터와 char 유형의 신경망 파라미터 weight에 대해 8x8의 행렬-벡터 조 작(행렬-벡터 조작의 입력 벡터를 8bit로 양자화시키고, 행렬-벡터 조작은 8bit 곱하기 8bit의 행렬 연산임)을수행하여, 행렬-벡터 조작의 결과를 누산기 ACC에 출력하고, ACC에서 출력한 결과가 바로 연산 결과이며, ACC에 서 출력한 연산 결과를 부동소수점 유형으로 변환할 수 있고, 부동소수점 유형의 연산 결과에 A를 곱한 후, DSP 의 메모리(예컨대 DRAM(Dynamic Random Access Memory, 동적 랜덤 메모리))에 송신하여 저장한다. 본 출원의 실시예의 가능한 구현 방식에서, PSRAM을 통해 신경망의 네트워크 파라미터를 저장할 수 있고, 연산 유닛은 PSRAM에 저장된 적어도 일부 네트워크 파라미터를 읽을 수 있고, 읽은 적어도 일부 네트워크 파라 미터에 따라 숫자 유형의 입력 데이터에 대해 행렬-벡터 조작을 수행하고, PSRAM 중 남은 네트워크 파라미터를 동시에 계속 읽을 수 있다. 이에 따라, 네트워크 파라미터를 읽는 동시에 행렬-벡터 조작을 수행하는 것을 구현 할 수 있으며, 즉 데이터 읽기/로딩 및 연산의 병렬 수행을 구현할 수 있으며, 연산 효율을 향상시킨다. 응용 시나리오로서, 신경망을 음성 식별 시나리오에 적용하는 경우를 예로 들어, 상기 입력 데이터는 사용자가 입력한 음성 데이터의 특징 벡터에 따라 결정될 수 있고, 연산 유닛에서 출력하는 연산 결과는 음성 데이터에 대응되는 음성 식별 결과를 결정하는데 사용된다. 다른 응용 시나리오로서, 신경망을 이미지 식별 시나리오 또는 비디오 식별 시나리오에 적용하는 경우를 예로 들어, 상기 입력 데이터는 이미지 또는 비디오 프레임의 특징 벡터에 따라 결정될 수 있고, 상응하게, 연산 유 닛에서 출력하는 연산 결과는 이미지 또는 비디오 프레임의 분류 결과를 결정하는데 사용된다. 예시로서, 신경망을 신원 식별에 적용하는 경우를 예로 들어 설명하면, 상기 입력 데이터는 이미지 또는 비디오 프레임의 특징 벡터에 따라 결정될 수 있고, 상응하게, 상기 연산 결과는 이미지 또는 비디오 프레임 중 타겟 객체의 신원 정보를 결정하는데 사용된다. 다른 예시로서, 신경망을 생체 검출에 적용하는 경우를 예로 들어 설명하면, 상기 입력 데이터는 이미지 또는 비디오 프레임의 특징 벡터에 따라 결정될 수 있고, 상응하게, 상기 연산 결과는 이미지 또는 비디오 프레임 중 의 생체 유무를 결정하는데 사용된다. 예를 들어, 신경망에서 출력하는 확률값이 미리 설정된 임계값(예컨대, 미리 설정된 임계값은 0.5일 수 있음)보다 크거나 같을 경우, 분류 결과는 생체가 있는 것이고, 신경망에서 출 력하는 확률값이 미리 설정된 임계값보다 작을 경우, 분류 결과는 생체가 없는 것이다. 또 다른 예시로서, 신경망을 금지된 이미지(예컨대 폭력적인 이미지, 음란한 이미지 등) 검출에 적용하는 경우 를 예로 들어 설명하면, 상기 입력 데이터는 이미지 또는 비디오 프레임의 특징 벡터에 따라 결정될 수 있고, 상응하게, 상기 연산 결과는 이미지 또는 비디오 프레임이 금지된 이미지인지 여부를 결정하는데 사용된다. 예 를 들어, 신경망에서 출력하는 확률값이 미리 설정된 임계값보다 크거나 같을 경우, 분류 결과는 이미지 또는 비디오 프레임이 금지된 이미지인 것이고, 신경망에서 출력하는 확률값이 미리 설정된 임계값보다 작을 경우, 분류 결과는 이미지 또는 비디오 프레임이 정상적인 이미지인 것이다. 또 다른 응용 시나리오로서, 신경망을 음성 번역 시나리오에 적용하는 경우를 예로 들어, 상기 입력 데이터는 사용자가 입력한 음성 데이터의 특징 벡터에 따라 결정될 수 있다. 상응하게, 연산 유닛에서 출력하는 연산 결 과는 음성 번역 결과를 결정하는데 사용된다. 예를 들면, 신경망을 중국어-영어 상호 번역 시나리오에 적용하는 경우를 예로 들어 설명하면, 상기 입력 데이 터는 중국어의 음성 데이터의 특징 벡터에 따라 결정될 수 있고, 상응하게, 상기 연산 결과는 음성 데이터에 대 응되는 영어 번역 결과를 결정하는데 사용되며, 당해 영어 번역 결과는 음성 형태이거나 텍스트 형태일 수 있으 나, 이에 대해 한정하지 않는다. 본 출원의 실시예의 가능한 구현 방식에서, NPU는 버스를 통해 DSP의 내부 메모리에 액세스할 수 있다. 구 체적으로, NPU는 버스의 메인 인터페이스를 더 포함할 수 있으며, 메인 인터페이스는 버스를 통해 메모리 복사 함수(memcpy)를 DSP에 송신하여, DSP의 내부 메모리에 액세스하여 DSP의 내부 메모리에 저장된 부동소수점 유형의 입력 데이터를 획득하는데 사용된다. 이에 따라, DSP의 내부 메모리에 저장된 입력 데이터를 효과적으로 읽을 수 있으므로, NPU가 연산 과정을 효과적으로 수행하도록 보장할 수 있다. 또한, DSP의 내부 메모리가 DSP와 NPU에게 동시 보이기 때문에, 버스를 통해 DSP의 내부 메모리에 액세스하면, 데이터 일관성 문제를 방지 할 수 있다. 본 출원의 실시예의 가능한 구현 방식에서, 연산 유닛이 컨볼루션 조작을 수행할 경우, 양자화 유닛 은 부동소수점 유형의 입력 데이터에 대해 부동소수점에서 쇼트 유형으로의 변환 조작을 수행하는데 사용되어, 연산 유닛에 의해 변환 후의 쇼트 유형의 입력 데이터에 대해 컨볼루션 조작을 수행한다. 이에 따라, 양자 화 과정을 부동소수점 유형에서 쇼트 유형 정점으로의 변환 과정으로 간소화하는 것을 구현할 수 있으므로, 컨볼루션 과정의 정밀도를 보장할 뿐만 아니라, 양자화 과정의 연산 비용도 절감할 수 있다. 부동소수점 유형의 입력 데이터는 DSP의 내부 메모리에 저장될 수 있다. 본 출원의 실시예의 가능한 구현 방식에서, NPU는 고속 액세스 인터페이스를 통해 RAM에 연결될 수 있고, RAM은 NPU로부터 쇼트 유형의 입력 데이터를 획득하여, 쇼트 유형의 입력 데이터를 RAM에 저장할 수 있으므로, 후속 연산 과정에서 연산 유닛은 RAM으로부터 쇼트 유형의 입력 데이터를 효과적으로 획득할 수 있으며, 쇼트 유형의 입력 데이터에 대해 컨볼루션 조작을 수행한다. 즉, 본 출원에서, RAM을 통해 양자화 유닛에 서 출력하는 쇼트 유형의 입력 데이터에 대해 저장할 수 있다. 상기 RAM은 NPU의 RAM이며, NPURAM라고 약칭한다. 본 출원의 상기 실시예에서 쇼트 유형의 입력 데이터에 대해 컨볼루션 조작을 수행하는 방법을 명확하게 설명하 기 위해, 본 출원은 다른 NPU를 제공한다. 도2는 본 출원의 실시예 2에서 제공되는 NPU의 구조 개략도이다. 도2에 도시된 바와 같이, 당해 NPU는 양자화 유닛 및 연산 유닛을 포함할 수 있으며, 연산 유닛 은 제1 레지스터, 제2 레지스터 및 누산기를 포함한다. 양자화 유닛은 부동소수점 유형의 입력 데이터에 대해 부동소수점에서 쇼트 유형으로의 변환 조작을 수행 하여, 변환 후의 쇼트 유형의 입력 데이터에 대해 컨볼루션 조작을 수행하는데 사용된다. NPU는 고속 액세스 인터페이스를 통해 RAM에 연결되며; RAM은 쇼트 유형의 입력 데이터를 RAM에 전잘하여 저장하는데 사용된다. 제1 레지스터는 제1 주기에서 RAM으로부터 쇼트 유형의 입력 데이터를 읽는데 사용된다. 제2 레지스터는 제1 주기 이후 복수의 후속 주기에서, PSRAM에 저장된 적어도 일부 네트워크 파라미터를 읽고, 각 주기에서 읽은 적어도 일부 네트워크 파라미터와 제1 레지스터 중 대응되는 입력 데이터에 대해 내적 연산을 수행하는데 사용된다. 누산기는 내적 연산의 결과를 획득하여, 컨볼루션 조작의 연산 결과를 획득하기 위해, 내적 연산의 결과에 따라 누산하는데 사용된다. 예를 들면, 네트워크 파라미터를 weight'로 표기하면, 네트워크 파라미터 weight'를 8개의 weight\"로 나눌 수 있고, 각각의 weight\"는 버스를 통해 읽고, 컨볼루션 조작은 쇼트 유형의 입력 데이터 및 weight\"에만 대하여, 특정 주기에서 1개의 weight\"를 획득할 경우, 당해 weight\" 및 쇼트 유형의 입력 데이터를 사용하여 컨볼루션 조작을 수행하는 과정에서 연산 유닛은 다음 weight\"를 읽을 수 있으므로, 읽기/로딩 과정 및 컨볼루션 조작 과 정의 병렬 수행을 구현할 수 있으며, 컨볼루션 조작 효율을 향상시킨다. 입력 데이터를 I로 표기하고, 신경망의 네트워크 파라미터를 W로 표기하면, 입력 데이터가 128바이트(bytes)인 경우를 예로 들어, 제1 주기에서 입력 데이터 중 처음 4 byte[0,3]을 읽을 수 있고, 제2 주기 내지 제 33 주기 에서, 32개의 주기의 네트워크 파라미터를 읽는다. 즉, 128byte의 네트워크 파라미터를 읽는 경우, 도3에 도시 된 바와 같이, 입력 데이터의 처음 4개의 byte와 네트워크 파라미터의 128byte에 대해 동시에 내적 연산을 수행 할 수 있으며, 누산기(ACC)는 총 32개의 주기의 내적 연산의 결과를 누산한다. 예를 들어, 도3에서 ACC1의 출력은 W[3]ХI[3]+W[2]ХI[2]+W[1]ХI[1]+W[0]ХI[0]이며, 마찬가지로, ACC2의 출 력은 W[7]ХI[3]+W[6]ХI[2]+W[5]ХI[1]+W[4]ХI[0]이며, 이에 따라 ACC32의 출력은 W[127]ХI[3]+W[126]Х I[2]+W[125]ХI[1]+W[124]ХI[0]이다. 그 다음, 입력 데이터 중의 4개의 byte[4,7]를 다시 읽고, 또한 32개의 주기의 네트워크 파라미터를 읽고, 내적 연산을 수행하여, 내적 연산의 결과를 누산기에 송신하여, 입력 데이터 중의 모든 byte가 소모될 때 까지 누산 하여, 즉 입력 데이터 중의 모든 byte가 연산에 참여할 때 까지 누산하여, 행렬 연산이 종료된다. 이에 따라, 네트워크 파라미터의 로딩 또는 읽는 과정에서, 이미 읽은 네트워크 파라미터를 사용하여 컨볼루션 조작을 수행하는 것을 구현할 수 있고, 데이터 읽기/로딩 및 컨볼루션 조작의 병렬 수행을 구현할 수 있으며, 컨볼루션 조작 효율을 향상시킨다. 본 출원의 실시예의 가능한 구현 방식에서, 당해 NPU를 음성 칩에 적용할 경우, 음성 칩의 코어의 처리 부담을 더 덜어 주기 위해, NPU는 고성능 활성화 유닛을 더 포함할 수 있으며, 활성화 유닛을 통해 컨볼루션 조작의 연산 결과를 활성화한다. 구체적으로, 컨볼루션 조작의 연산 결과를 DSP의 메모리에 송신하여 저장할 수 있고, 활 성화 유닛은 버스를 통해 DSP의 내부 메모리에 액세스할 수 있고, DSP에 저장된 컨볼루션 조작의 연산 결과를 획득하여, 컨볼루션 조작의 연산 결과에 따라 활성화 함수를 사용하여 활성화하고, 활성화 결과를 DSP에 제공하 여 저장하므로, 후속 조작은 DSP의 소프트웨어에 의해 수행될 수 있다. 상기 실시예는 NPU의 구조이되, 본 출원은 처리 장치의 구조를 더 제공한다. 도4는 본 출원의 실시예 3에서 제공되는 처리 장치의 구조 개략도이다. 도4에 도시된 바와 같이, 당해 처리 장치는 버스를 통해 연결되는 전술한 임의의 실시예에서 제공되는 NPU, PSRAM 및 DSP를 포함할 수 있다. DSP는 내부 메모리에 처리할 입력 데이터를저장하고; 및 NPU에서 입력 데이터에 대한 연산 결과를 저장하 는데 사용된다. PSRAM은 신경망의 네트워크 파라미터를 저장하는데 사용된다. 본 출원의 실시예에서, NPU는 버스를 통해 DSP의 내부 메모리에 액세스하여 처리할 입력 데이터를 읽 어 획득할 수 있고, 버스를 통해 PSRAM에 액세스하여 적어도 일부 네트워크 파라미터를 획득하여, 읽은 적 어도 일부 네트워크 파라미터에 따라 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하고, PSRAM 중 남은 네트워크 파라미터를 동시에 계속 읽으며, 계속하여 읽은 남은 네트워크 파라미 터에 따라, 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행하여, 입력 데이터의 연산 결과를 획득할 수 있다. 이에 따라, 데이터를 읽거나 로딩하는 동시에 연산 과정을 수행하는 것을 구현할 수 있으며, 즉 데이터 읽기/로딩 및 연산의 병렬 수행을 구현할 수 있으며, 연산 효율을 향상시킬 수 있다. 설명해야 하는 바로는, 관련 기술에서, PSRAM의 데이터는 Cache에 의해 로딩되어야 하고, Cache가 로딩하는 과 정에 DSP는 대기 상태이며, 데이터 로딩이 완료된 후에만 이미 로딩된 데이터를 사용하여 연산 과정을 수행할 수 있기 때문에, 연산 효율이 상대적으로 낮다. 그러나, 본 출원에서는 PSRAM 중의 네트워크 파라미터의 로딩 과정 및 NPU의 연산 과정은 병렬로 수 행되어, 데이터 로딩의 활용도를 향상시키는 동시에 연산 효율을 크게 향상시킬 수 있다. 신경망을 음성 식별 시나리오에 적용하는 경우를 예로 들어 설명하면, 연산 효율이 크게 향상하는 상황에서 당해 처리 장치로 하여 금 신경망 기반 음성 웨이크업 및 식별 작업에 더 적합할 수 있다. DSP가 HiFi(High Fidelity, 높은 충실도) DSP인 경우를 예시로서, 처리 장치의 구조는 도5에 도시된 바와 같이, NPU는 버스의 메인 인터페이스를 포함할 수 있고, 당해 메인 인터페이스는 버스를 통해 HiFi DSP의 내부 메모리 에 액세스할 수 있고, NPU는 고속 액세스 인터페이스(128byte/주기 cycle)를 더 구비하여, 당해 고속 액세스 인 터페이스를 통해 NPURAM에 연결될 수 있다. 부동소수점 유형의 입력 데이터, 행렬-벡터 조작의 연산 결과 및 컨볼루션 조작의 연산 결과(부동소수점 포맷) 를 HiFi DSP의 내부 메모리에 저장하여, HiFi DSP는 NPU와의 Cache 일관성 설계를 할 필요가 없다. 즉, Cache 구조를 수정하거나 일관성 버스를 추가할 필요가 없으므로 하드웨어의 설계를 간소화할 수 있다. 연산 능력 측면에서, NPU는 128개의 8x8의 곱셈 및 덧셈 연산을 내장하고 있으며, 4x32, 8x16, 16x8의 3가지 행 렬 연산 모드를 지원한다. 64개의 16x8의 곱셈 및 덧셈 연산을 동시에 지원하며, 2x32, 4x16, 8x8의 3가지 컨볼 루션 연산 모드를 지원한다. 이 중에서, 4x32는 128개의 요소를 32개의 그룹으로 나누고, 각 그룹의 4개의 요소 와 입력 데이터의 4개의 요소를 내적하여, 내적 결과를 32개의 누산기에 송신한다. 입력 데이터의 벡터 차원이 N이면, 1xN 및 Nx32의 행렬 연산을 완료하는데 총 N/4개의 주기가 필요한다. 8x16, 16x8도 유사하다. 행렬 연산, 즉 행렬-벡터 조작은 입력 데이터 또는 입력 벡터를 8bit, 8bit 곱하기 8bit의 벡터 곱셈 행렬 연산 으로 양자화시키고, 행렬 연산 결과에 입력 데이터의 양자화 scale 값(제2 파라미터)을 곱한다. 신경망의 네트 워크 파라미터 weight도 양자화해야 하며, 네트워크 파라미터의 양자화 과정은 HiFi DSP의 소프트웨어에 의해 완료될 수 있으며, 즉 weight의 스케일링 계수 및 오프셋 계수(Scale 값 및 Bias 값)의 조작은 HiFi DSP의 소프 트웨어에 의해 완료될 수 있으며, 당해 부분의 연산량의 비율이 낮기 때문이다. 상기 조작은 64x64 요소의 8x8 행렬 연산 과정에서, 양자화의 해시 레이트는 약 30%를 점용하고, 8x8 행렬 연산은 약 67%를 점용하고, 곱셈 scale는 3%를 점용한다. 양자화 과정의 점용 비율이 상대적으로 높은 가장 큰 이유는 부동소수점을 쇼트 유형 정점으로 변환하는 과정에서, 부동소수점의 부호 비트를 판단한 다음 ±0.5를 하여, int8 정수로 변환해야 하며, 그러나 당해 조작에서 HiFi DSP에 특정 가속 명령이 없으며 하나씩만 수행해야 한다. 하지만, 본 출원의상기 하드웨어 가속 방식을 통해, 전용 회로의 방법을 사용할 수 있으며, 즉 NPU를 통해 행렬 연산을 수행하여 당해 부분의 점용 비율을 30%에서 5%로 줄일 수 있다. 행렬 연산을 배합하여, 각 주기에서 8개의 곱셈 및 덧셈 연산을 128개의 곱셈 및 덧셈 연산으로 향상시키며, 연산 효율을 크게 향상시킨다. 컨볼루션 조작에 있어서, 입력이 16bit이므로 양자화 과정을 부동소수점 유형*1024에서 쇼트(short) 유형 정점 으로의 변환 과정으로 간소화한다. 원래의 양자화 과정은 입력 데이터 또는 입력 벡터의 최대값 absmax를 구하 는 것이며, max를 모든 값으로 나눈후 127을 곱하며, 당해 연산은 3개의 단계를 필요하되, 부동소수점 유형 *1024에서 short 유형 정점으로의 변환 과정은 그 중 세번째 단계이다. 이에 따라, 컨볼루션 과정의 정밀도를 보장할 뿐만 아니라, 양자화 과정의 연산 비용도 절감(원래의 양자화 과정은 병렬 연산을 수행할 수 없기 때문 이임)할 수 있다. NPU에 고성능 활성화 유닛을 구비하여, sigmoid/tanh/log/exp 등 조작을 구현하며, 정밀도는 단일 정밀도 부동 소수점 수학 라이브러리와 가깝고, 하나의 주기에서 하나의 유닛의 연산을 완료할 수 있으며, HiFi DSP를 사용 하여 이러한 함수를 연산하는 시간을 크게 줄일 수 있고, 각 유닛의 연산은 약 400-1000 주기를 필요한다. 상술한 전용 양자화 유닛을 사용하여 양자화의 시간 소모를 줄일 수 있고, 본 출원은 또한 메모리에 대한 최대 사용을 통해 연산 효율을 향상시킬 수 있다. 성능을 손실하지 않는 전제 하에서, 온칩 SRAM(Static Random Access Memory, 정적 랜덤 메모리)의 크기는 최 대한 줄일 수 있다. 관련 기술의 음성 칩에 비교해, 1MB+의 저장을 PSRAM에 배치하고, PSRAM의 경우 대역폭이 166MB/s에 불과하며, 10ms에 한 번 호출하면, 당해 1MB의 저장을 읽는데 이론적인 대역폭의 60%가 필요하며, 연 산 효율이 80%일 경우, 당해 점용 비율은 75%로 증가된다. 따라서, 먼저 PSRAM에 호출 횟수가 적은 모델을 넣어 야 하는데, 예를 들어 PSRAM에 넣은 모델은 30ms마다 한 번씩 호출되는 모델이 있다. 또한, 반복적인 로딩을 줄 이기 위해, 데이터 로딩과 동시에 연산을 수행하고, 모델 Layer 수준의 완충은 온칩에서 수행되어야 한다. NPU 하드웨어 가속을 사용할 때, 네트워크 파라미터의 로딩을 온칩 RAM에 저장할 수 있고, 연산 과정이 완전히 병렬 수행되어, 로딩이 완료된 후 연산을 시작하는 제한을 제거하여, 대역폭 활용도를 극대화할 수 있되, 이 것은 HiFi DSP 시스템에 의해 구현될 수 없다. 따라서, 본 출원에서, 하드웨어를 사용하여 로딩 및 연산의 병렬 수행 을 구현하여, NPU는 PSRAM 중의 네트워크 파라미터를 로딩하는 동시에 행렬 연산을 수행한다. 하드웨어 가속은 온칩 RAM에 대해 각 주기당 128Bytes를 읽어, 당해 대역폭은 HiFi DSP의 64bits보다 16배 높다. 전술한 입력 과정은 양자화 과정, 또는 부동소수점 유형에서 쇼트 유형으로의 변환 과정이 있으나, NPU의 하드웨어 가속 유닛의 면적을 고려하여, 상기 두 과정에서 128개의 하드웨어 유닛을 배치할 수 없기 때문에, 128Bytes의 읽기 속도가 필요하지 않는다. 최종적으로 버스의 읽기 대역폭이 64bit로 결정되고, 2개의 수행 유 닛이 배치된다. 따라서, 부동소수점 유형의 입력 데이터 또는 입력 벡터에 대해, 저장 위치가 HiFi DSP의 코어 내(즉, 내부 메모리)에 위치해야 하고; 동시에 행렬 연산 및 컨볼루션 연산의 결과(부동 소수점 형식)도 HiFi DSP의 코어 내에 다시 저장해야 한다. 이에 따라, HiFi DSP는 NPU와의 Cache 일관성 설계를 할 필요가 없으므로, 설계를 크게 단순화한다. 당해 처리 장치의 구조를 사용한 후, 연산 집약형의 부분은 NPU 연산을 사 용하고, HiFi DSP는 범용형 연산 및 음성 신호 처리의 연산을 수행하여, 다양한 음성 작업의 최적 연산 효율, 또한 연산 및 로딩의 병렬 수행을 구현한다. 본 출원의 실시예의 처리 장치는, 전용 NPU를 사용하여, 행렬 연산 및 컨볼루션 연산 중 적어도 하나를 구현하 므로, 당해 NPU를 음성 칩에 적용할 경우, 음성 칩의 코어의 처리 부담을 덜어 주고, 음성 칩의 코어의 처리 효 율을 향상시킬 수 있다. 상기 실시예를 구현하기 위해, 본 출원은 신경망의 처리 방법을 더 제공한다. 도6은 본 출원의 실시예 5에서 제공되는 신경망의 처리 방법의 개략적인 흐름도이다. 본 출원의 실시예의 당해 신경망의 처리 방법은 신경망 처리 유닛(NPU)에 적용되며, NPU는 양자화 유닛 및 연산 유닛을 포함한다. 도6에 도시된 바와 같이, 당해 신경망의 처리 방법은 하기의 단계를 포함할 수 있다. 단계 601, 양자화 유닛이 부동소수점 유형의 입력 데이터를 획득하고, 부동소수점 유형의 입력 데이터를 양자화 하여 양자화된 입력 데이터를 획득하여, 양자화된 입력 데이터를 연산 유닛에 제공한다. 단계 602, 연산 유닛이 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행 하여, 입력 데이터의 연산 결과를 획득한다. 단계 603, 양자화 유닛이 연산 유닛에서 출력하는 연산 결과를 역양자화하여, 역양자화 결과를 획득한다. 본 출원의 실시예의 가능한 구현 방식에서, 연산 유닛이 행렬-벡터 조작을 수행할 경우, 양자화 유닛은 디지털 신호 프로세서(DSP)의 내부 메모리에 저장된 부동소수점 유형의 입력 데이터에 따라 양자화에 사용하는 제1 파 라미터 및 역양자화에 사용하는 제2 파라미터를 구하여, 부동소수점 유형의 입력 데이터 중 양자화할 부동소수 점 값에 제1 파라미터를 곱하고, 반올림한 후 숫자 유형으로 변환하여, 숫자 유형의 입력 데이터를 획득하고, 숫자 유형의 입력 데이터를 연산 유닛에 송신하고; 연산 유닛은 숫자 유형의 입력 데이터에 대해 행렬-벡터 조 작을 수행하여, 연산 결과를 획득하고; 양자화 유닛은 연산 결과를 부동소수점 유형으로 변환하고, 부동소수점 유형의 연산 결과에 제2 파라미터를 곱한 후 DSP의 메모리에 송신하여 저장한다. 가능한 구현 방식으로서, NPU는 버스의 메인 인터페이스를 더 포함할 수 있으며; 메인 인터페이스는 버스를 통 해 메모리 복사 함수를 DSP에 송신하여, DSP의 내부 메모리에 액세스하여 DSP의 내부 메모리에 저장된 부동소수 점 유형의 입력 데이터를 획득하는데 사용된다. 본 출원의 실시예의 다른 가능한 구현 방식에서, 연산 유닛이 컨볼루션 조작을 수행할 경우, 양자화 유닛은 부 동소수점 유형의 입력 데이터에 대해 부동소수점에서 쇼트 유형으로의 변환 조작을 수행하고; 연산 유닛은 변환 후의 쇼트 유형의 입력 데이터에 대해 컨볼루션 조작을 수행하여 연산 결과를 획득한다. 가능한 구현 방식으로서, NPU는 고속 액세스 인터페이스를 통해 RAM에 연결될 수 있고; RAM은 쇼트 유형의 입력 데이터를 RAM에 저장하는데 사용된다. 가능한 구현 방식으로서, 연산 유닛은 제1 레지스터, 제2 레지스터 및 누산기를 포함하며; 제1 레지스터는 제1 주기에서 RAM으로부터 쇼트 유형의 입력 데이터를 읽고; 제2 레지스터는 제1 주기 이후 복수의 후속 주기에서, PSRAM에 저장된 적어도 일부 네트워크 파라미터를 읽고, 각 주기에서 읽은 적어도 일부 네트워크 파라미터와 제 1 레지스터 중 대응되는 입력 데이터에 대해 내적 연산을 수행하고; 누산기는 내적 연산의 결과를 획득하여, 컨 볼루션 조작의 연산 결과를 획득하기 위해, 내적 연산의 결과에 따라 누산한다. 가능한 구현 방식으로서, NPU는 활성화 유닛을 더 포함하며, 활성화 유닛은 DSP에 저장된 컨볼루션 조작의 연산 결과에 따라 활성화 함수를 사용하여 활성화하고, 활성화 결과를 DSP에 제공하여 저장한다. 설명해야 하는 바로는, 전술한 임의의 실시예에서 NPU에 관한 해석과 설명, 그리고 처리 장치에 관한 해석과 설 명은 당해 실시예에도 적용되며, 구현 원리는 유사하므로, 여기서 반복적으로 설명하지 않는다. 본 출원의 실시예의 신경망의 처리 방법은, 양자화 유닛이 부동소수점 유형의 입력 데이터를 획득하고, 부동소 수점 유형의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 양자화된 입력 데이터를 연산 유닛에 제공하며, 연산 유닛이 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행 하여, 입력 데이터의 연산 결과를 획득한 다음, 양자화 유닛이 연산 유닛에서 출력하는 연산 결과를 역양자화하 여, 역양자화 결과를 획득한다. 이에 따라, 전용 NPU를 사용하여, 행렬 연산 및 컨볼루션 연산 중 적어도 하나 를 구현하므로, 당해 NPU를 음성 칩에 적용할 경우, 음성 칩의 코어의 처리 부담을 덜어 주고, 음성 칩의 코어 의 처리 효율을 향상시킬 수 있다. 상기 실시예를 구현하기 위해, 본 출원은 또한 전자 기기를 제공한다. 당해 전자 기기는, 적어도 하나의 프로세 서; 및 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리를 포함할 수 있고; 메모리에는 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 명령은 적어도 하나의 프로세서에 의해 수행되므로, 적어 도 하나의 프로세서에 의해 본 출원의 상기 임의의 실시예에 따른 신경망의 처리 방법을 수행하도록 한다. 상기 실시예를 구현하기 위해, 본 출원은 또한 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공하며, 컴퓨터 명령은 컴퓨터가 본 출원의 상기 임의의 실시예에 따른 신경망의 처리 방법을 수행하 도록 사용된다. 상기 실시예를 구현하기 위해, 본 출원은 또한 컴퓨터 프로그램을 제공하며, 당해 컴퓨터 프로그램은 컴퓨터 프 로그램을 포함하고, 컴퓨터 프로그램이 프로세서에 의해 수행되는 경우 본 출원의 상기 임의의 실시예에 따른 신경망의 처리 방법을 수행하도록 한다. 본 출원의 실시예에 따라 본 출원은 또한 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램을 제공한다. 도7은 본 출원의 실시예를 실시하기 위한 예시적인 전자 기기의 개략적인 블록도이다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크 스테이션, 개인용 디지털 비서, 서버, 블레이드 서버, 메인 프레임 컴퓨터 및 기타 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 나타내기 위한 것이다. 전자 기기는 또한 개인용 디 지털 처리, 셀룰러 폰, 스마트 폰, 웨어러블 기기 및 기타 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장 치를 나타낼 수도 있다. 본 명세서에서 제시된 구성 요소, 이들의 연결 및 관계, 또한 이들의 기능은 단지 예일 뿐이며 본문에서 설명되거나 및/또는 요구되는 본 출원의 구현을 제한하려는 의도가 아니다. 도7에 도시된 바와 같이, 기기는 연산 유닛을 포함하며, ROM(Read-Only Memory, 읽기 전용 메모 리)에 저장된 컴퓨터 프로그램 또는 저장 유닛으로부터 RAM(Random Access Memory, 랜덤 액세스 메 모리)에 로딩된 컴퓨터 프로그램에 의해, 각종 적절한 동작 및 처리를 수행할 수 있다. RAM에는 또한 기기가 조작을 수행하기 위해 필요한 각종 프로그램 및 데이터가 저장되어 있다. 연산 유닛, ROM 및 RAM은 버스를 통해 서로 연결되어 있다. I/O(Input/Output, 입력/출력) 인터페이스 도 버스에 연결되어 있다. 키보드, 마우스 등과 같은 입력 유닛; 각종 유형의 모니터, 스피커 등과 같은 출력 유닛; 자기 디스 크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 트랜시버 등과 같은 통신 유닛 을 포함하는 기기 중의 복수의 부품은 I/O 인터페이스에 연결된다. 통신 유닛은 기기(70 0)가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보/데이터를 교환하 도록 허락한다. 연산 유닛은 처리 및 연산 능력을 구비한 다양한 범용 및/또는 전용 처리 컴포넌트일 수 있다. 연산 유닛 의 일부 예시는 CPU(Central Processing Unit, 중앙 처리 유닛), GPU(Graphic Processing Units, 그래픽 처리 유닛), 다양한 전용 AI(Artificial Intelligence, 인공지능) 연산 칩, 기계 러닝 모델 알고리즘을 수행하 는 다양한 연산 유닛, DSP(Digital Signal Processor, 디지털 신호 프로세서), 및 임의의 적절한 프로세서, 컨 트롤러, 마이크로 컨트롤러 등을 포함하지만, 이에 한정되지 않는다. 연산 유닛은 상기 신경망의 처리 방 법과 같은 윗글에서 설명된 각각의 방법 및 처리를 수행한다. 예를 들면, 일부 실시예에서, 상기 신경망의 처리 방법은 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함되어 있는 컴퓨터 소프트웨어 프로그램으 로 구현될 수 있다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 통해 기기에 로드 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되어 연산 유닛에 의 해 수행되는 경우, 전술한 신경망의 처리 방법의 하나 또는 하나 이상의 단계를 수행할 수 있다. 대안적으로, 기타 실시예에서, 연산 유닛은 임의의 다른 적절한 방식을 통해(예를 들어, 펌웨어에 의해) 구성되어 상기 신경망의 처리 방법을 수행하도록 한다. 여기서 설명되는 시스템 및 기술의 다양한 실시 방식은 디지털 전자 회로 시스템, 집적 회로 시스템, FPGA(Field Programmable Gate Array, 필드 프로그래머블 게이트 어레이), ASIC(Application-Specific Integrated Circuit, 주문형 집적 회로), ASSP(Application Specific Standard Product, 특정 용도 표준 제 품), SOC(System On Chip, 시스템온칩), CPLD(Complex Programmable Logic Device, 복합 프로그래머블 논리 소 자), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및 이들의 조합에서 적어도 하나로 구현될 수 있다. 이러한 다양한 실시 방식은 하나 또는 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있으며, 당해 하나 또는 하나 이 상의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 수행 및/ 또는 해석될 수있고, 당해 프로그램 가능 프로세서는 전용 또는 일반용일 수 있고, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신하고 또한 데이터 및 명령을 당해 저장 시 스템, 당해 적어도 하나의 입력 장치 및 당해 적어도 하나의 출력 장치에 전송할 수 있다. 본 출원의 방법을 구현하기 위해 사용되는 프로그램 코드는 하나 또는 하나 이상의 프로그래밍 언어의 임의의 조합으로 작성될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그래머블 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공될 수 있으므로, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 수행되는 경우, 흐름도 및/또는 블록도에서 규정된 기능/조작을 구현하도록 한다. 프로그램 코드는 전체적으로 기계에서 수행되거나, 부분적으로 기계에서 수행되거나, 독립 소프트웨어 패키지로서 부분적으로 기계에서 수행 되고 부분적으로 원격 기계에서 수행되거나 또는 전체적으로 원격 기계 또는 서버에서 수행될 수 있다. 본 출원의 문맥에서, 기계 판독 가능 매체는 명령 수행 시스템, 장치 또는 기기에 의해 사용되거나 명령 수행 시스템, 장치 또는 기기와 결합하여 사용되는 프로그램을 포함하거나 저장할 수 있는 유형의 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 더욱 구체적인 예시는 하나 또 는 하나 이상의 전선을 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, RAM, ROM, EPROM(Electrically Programmable Read-Only-Memory, 지울 수 있는 프로그래머블 읽기 전용 메모리) 또는 플래시 메모리, 광섬유, CD-ROM(Compact Disc Read-Only Memory, 휴대용 컴팩트 디스크 읽기 전용 메모리), 광학 저장 기기, 자기 저장 기기 또는 상기 내용의 임의의 적절한 조합을 포함할 수 있지만 이에 한정되지 않는다. 사용자와의 인터랙션을 제공하기 위해 여기에 설명된 시스템 및 기술은 컴퓨터에서 실시될 수 있다. 당해 컴퓨 터는 사용자에게 정보를 디스플레이하기 위한 디스플레이 장치(예를 들어, CRT(Cathode-Ray Tube, 음극선관) 또 는 LCD(Liquid Crystal Display, 액정 디스플레이) 모니터); 및 키보드 및 포인팅 장치(예를 들어, 마우스 또는 트랙볼)를 구비하며, 사용자는 당해 키보드 및 당해 포인팅 장치를 통해 컴퓨터에 입력을 제공할 수 있다. 다른 유형의 장치를 사용하여 사용자와의 인터랙션을 제공할 수도 있으며, 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 감지 피드백(예를 들어, 시각적 피드백, 청각적 피드백 또는 촉각적 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력 또는 촉각 입력을 포함)로 사용자로부터의 입력을 수신할 수 있다. 여기서 설명되는 시스템 및 기술은 백엔드 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버), 또는 미들 웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프런트 엔드 부품을 포함하는 컴퓨팅 시스템 (예를 들어, 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 구비하는 사용자 컴퓨터인 바, 사용자는 당해 그래픽 사용자 인터페이스 또는 네트워크 브라우저를 통해 여기서 설명되는 시스템 및 기술의 실시 방식과 인터 랙션할 수 있음), 또는 이러한 백엔드 부품, 미들웨어 부품 또는 프런트 엔드 부품의 임의의 조합을 포한하는 컴퓨팅 시스템에서 실시될 수 있다. 시스템의 부품은 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 서로 연결될 수 있다. 통신 네트워크의 예시는 LAN(Local Area Network, 근거리 통신 망), WAN(Wide Area Network, 광역 통신망), 인터넷 및 블록체인 네트워크를 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통신 네트워크를 통해 인터랙션한다. 서로 클라이언트-서버 관계를 가지는 컴퓨터 프로그램을 대응되는 컴 퓨터에서 수행하여 클라이언트와 서버 간의 관계를 생성한다. 서버는 클라우드 컴퓨팅 서버 또는 클라우드 호스 트라고도 하는 클라우드 서버일 수 있고, 클라우드 컴퓨팅 서비스 시스템에서 일종의 호스트 제품이고, 기존의 물리적 호스트 및 VPS(Virtual Private Server, 가상 사설 서버) 서비스에 존재하고 있는 관리가 어렵고 비즈니 스 확장이 약한 결점을 해결하기 위한 것이다. 서버는 또한 분산 시스템의 서버, 또는 블록체인을 결합한 서버 일 수 있다. 설명 해야하는 바로는, 인공지능은 인간의 특정 사유 과정 및 지능 행위(예컨대, 러닝, 추리, 사고, 계획 등)를 컴퓨터로 시뮬레이션하기 위해 연구하는 학과이며, 하드웨어 층면의 기술 뿐만 아니라 소프트웨어 층면의 기술 도 포함한다. 인공지능 하드웨어 기술은 일반적으로 센서, 전용 인공지능 칩, 클라우드 컴퓨팅, 분산 스토리지, 빅데이터 처리 등 기술을 포함하고; 인공지능 소프트웨어 기술은 주로 컴퓨터 시각 기술, 음성 인식 기술, 자연 언어 처리 기술 및 기계 러닝/딥러닝, 빅데이터 처리 기술, 지식 그래프 기술 등 몇 가지 주요 방향을 포함한다. 본 출원의 실시예의 기술적 수단에 따르면, 양자화 유닛이 부동소수점 유형의 입력 데이터를 획득하고, 부동소 수점 유형의 입력 데이터를 양자화하여 양자화된 입력 데이터를 획득하여, 양자화된 입력 데이터를 연산 유닛에 제공하며, 연산 유닛이 양자화된 입력 데이터에 대해 행렬-벡터 조작 및 컨볼루션 조작 중 적어도 하나를 수행 하여, 입력 데이터의 연산 결과를 획득한 다음, 양자화 유닛이 연산 유닛에서 출력하는 연산 결과를 역양자화하 여, 역양자화 결과를 획득한다. 이에 따라, 전용 NPU를 사용하여, 행렬 연산 및 컨볼루션 연산 중 적어도 하나 를 구현하므로, 당해 NPU를 음성 칩에 적용할 경우, 음성 칩의 코어의 처리 부담을 덜어 주고, 음성 칩의 코어 의 처리 효율을 향상시킬 수 있다. 이해 가능한 바로는, 전술한 다양한 형식의 프로세스에 있어서 단계 재정렬, 추가 또는 삭제를 할 수 있다. 예 를 들어, 본 출원에 개시된 기술 솔루션이 이루고자 하는 결과를 구현할 수 있는 한, 본 출원에 기재된 각 단계 들은 병렬로, 순차적으로 또는 다른 순서로 수행될 수 있으나, 본 명세서에서 이에 대해 한정하지 않는다. 전술한 구체적인 실시 방식들은 본 출원의 보호 범위에 대한 한정을 구성하지 않는다. 당업자라면 본 출원의 설 계 요건 및 기타 요인에 따라 다양한 수정, 조합, 서브 조합 및 대체가 이루어질 수 있음을 이해해야 한다. 본 출원의 정신과 원칙 내에서 이루어진 모든 수정, 동등한 대체 및 향상은 본 출원의 보호 범위에 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2022-0063239", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 수단을 더 잘 이해하기 위한 것으로, 본 출원에 대한 한정이 구성되지 않는다. 도1은 본 출원의 실시예 1에서 제공되는 NPU의 구조 개략도이다. 도2는 본 출원의 실시예 2에서 제공되는 NPU의 구조 개략도이다. 도3은 본 출원의 실시예에서 컨볼루션 연산 과정의 개략도이다. 도4는 본 출원의 실시예 3에서 제공되는 처리 장치의 구조 개략도이다. 도5는 본 출원의 실시예 4에서 제공되는 처리 장치의 구조 개략도이다. 도6은 본 출원의 실시예 5에서 제공되는 신경망의 처리 방법의 개략적인 흐름도이다.도7은 본 출원의 실시예를 구현하기 위한 예시적인 전자 기기의 개략적인 블록도이다."}
