{"patent_id": "10-2023-0066555", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0168772", "출원번호": "10-2023-0066555", "발명의 명칭": "파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법 및 시스템", "출원인": "한동대학교 산학협력단", "발명자": "최희열"}}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법에 있어서,오케스트레이터가 보상함수 매개변수를 샘플링하는 단계;오케스트레이터가 샘플링한 보상함수 매개변수를 서브모듈에 제공하는 단계;서브모듈이 오케스트레이터로부터 보상함수 매개변수를 수신하여 보상함수 매개변수를 학습모델에 입력하는 단계; 및서브모듈이 학습모델을 통해 보상함수를 최적화하도록 학습하는 단계를 포함하는 파라메트릭 보상 강화학습을활용한 네트워크 관리에서의 동적 서브모듈 학습 방법."}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 오케스트레이터는 쉘로우 네트워크(shallow network)를 이용하여 보상함수 매개변수를 서브모듈에 제공하는 것을 특징으로 하는 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법."}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 서브모듈은 보상함수 매개변수에 의해 동적으로 행동양식을 변경하는 동적 서브모듈을 학습하는 것을 특징으로 하는 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법."}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 서브모듈은 SFC 서브모듈, Auto-Scaling 서브모듈, VNF 배치 서브모듈, 전력관리 서브모듈 중 적어도 하나인 것을 특징으로 하는 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법."}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 서브모듈이 Auto-Scaling 서브모듈이면,보상함수는 아래 식에 의해서 계산되는 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈학습 방법.공개특허 10-2024-0168772-3-(α는 서브모듈 매개변수)"}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 서브모듈이 SFC 서브모듈이면,보상함수는 아래 식에 의해서 계산되는 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈학습 방법.(β는 서브모듈 매개변수)"}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 서브모듈이 전력관리 서브모듈이면,보상함수는 아래 식에 의해서 계산되는 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈학습 방법.(γ는 서브모듈 매개변수)"}
{"patent_id": "10-2023-0066555", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "보상함수 매개변수를 샘플링하고, 샘플링한 보상함수 매개변수를 서브모듈에 제공하는 오케스트레이터; 및오케스트레이터로부터 보상함수 매개변수를 수신하고, 수신한 보상함수 매개변수를 학습모델에 입력하고, 학습모델을 통해 보상함수를 최적화하도록 학습하는 서브모듈로 구성되고,상기 오케스트레이터는 쉘로우 네트워크(shallow network)를 이용하여 보상함수 매개변수를 서브모듈에 제공하고,상기 서브모듈은 보상함수 매개변수에 의해 동적으로 행동양식을 변경하는 동적 서브모듈을 학습하는 것을 특징으로 하는 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 시스템."}
{"patent_id": "10-2023-0066555", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법에 있어서, 오케스트레이터가 보상함수 매개변수를 샘플링하는 단계와, 오케스트레이터가 샘플링한 보상함수 매개변수를 서브모듈에 제공하는 단계와, 서브모듈이 오케스트레이터로부터 보상함수 매개변수를 수신하여 보상함수 매개변수를 학습모델에 입력 하는 단계 및 서브모듈이 학습모델을 통해 보상함수를 최적화하도록 학습하는 단계를 포함한다."}
{"patent_id": "10-2023-0066555", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법 및 시스템에 관한 것으로, 인공지능 기반 네트워크 관리시스템의 각 서브모듈의 보상함수를 매개변수화 할 수 있으며, 서브모듈의 구조를 크게 수정하지 않고 매개변수를 변경함으로써 서브모듈의 행동양식을 동적으로 변화시킬 수 있는 파라메 트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0066555", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전통적인 인공지능 기반 네트워크 관리시스템의 각 서브모듈들은 각각의 고정된 보상함수를 최대화하는 방향으 로 학습되어 왔다. 하지만 이 서브모듈을 통합하여 최종 네트워크 관리시스템을 만들게 될 때, 다른 서브모듈의 상황을 고려하지 않고 자기 보상함수만 최대화하도록 동작하여 결과적으로 조화를 이루기 어렵다는 문제가 발생 한다. 따라서 네트워크 상황에 따라 행동양식을 다르게 하는 서브모듈의 학습법이 필요하다. 서브모듈의 한 가지 학습법으로는, 서브모듈에 네트워크의 모든 정보를 입력으로 학습한다면 네트워크 상황에 따라 행동양식이 다를 수 있지만, 근본적인 보상함수가 바뀌지 않는 이상 필요 없는 정보는 무시되도록 학습될 가능성이 농후하다. 이때 만약 서브모듈의 보상함수를 매개변수화하여 외부에서 제공되는 매개변수로 변화하는 학습을 한다면, 기존 서브모듈의 구조를 크게 수정하지 않고 단순히 매개변수를 변경함으로써 서브모듈의 행동 양식을 동적으로 변화시킬 수 있을 것이다. 선행특허로는 공개특허 제10-2022-0071895호(오토 스케일링 방법, 장치 및 시스템)가 있으나, 오토 스케일링 방 법은 심층 Q 네트워크(Deep Q-networks, DQN) 장치를 통해 SFC(Service FunctionChaining)를 구성하는 VNF(Virtual Network Functions) 인스턴스들의 스케일 인아웃(Scale-in/out)을 주기적으로 수행하는 오토 스케 일링 방법에 있어서, 심층 Q 네트워크(Deep Q-networks, DQN) 장치를 통해 SFC(ServiceFunction Chaining)를 구성하는 계층(Tier)들의 상황(Status)을 강화학습의 상태(State)로 정의하여 입력 값으로 받아들인 후, 어떤 물리 서버에서 스케일 인아웃(Scale-in/out)을 수행할지 또는 현재 VNF(Virtual Network Functions) 인스턴스 들을 유지(Maintain)할지를 행동으로 출력하는 단계 및 스케일 인아웃(Scale-in/out)을 수행할 때, 스케일링이 필요한 SFC(Service Function Chaining)의 계층을 선택하여 해당 계층에 스케일링을 적용하는 단계를 포함하고 있을 뿐이다."}
{"patent_id": "10-2023-0066555", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 상기와 같은 종래 기술의 문제점을 해결하기 위해 안출된 것으로, 인공지능 기반 네트워크 관리시스템의 각 서브모듈의 보상함수를 매개변수화 할 수 있으며, 서브모듈의 구조를 크게 수정 하지 않고 매개변수를 변경함으로써 서브모듈의 행동양식을 동적으로 변화시킬 수 있는 데 있다."}
{"patent_id": "10-2023-0066555", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법에 있어서, 오케스트레이터가 보상함수 매개변수를 샘플링하는 단계와, 오케스트레이터가 샘플링한 보상함수 매개변수를 서브모듈에 제공하는 단계와, 서브모듈이 오케스트레이터로부터 보상함수 매개변수를 수신하여 보상함수 매개변수를 학습모델에 입력 하는 단계 및 서브모듈이 학습모델을 통해 보상함수를 최적화하도록 학습하는 단계를 포함한다. 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 시스템에 있어서, 보상함수 매개 변수를 샘플링하고, 샘플링한 보상함수 매개변수를 서브모듈에 제공하는 오케스트레이터 및 오케스트레이터로부 터 보상함수 매개변수를 수신하고, 수신한 보상함수 매개변수를 학습모델에 입력하고, 학습모델을 통해 보상함 수를 최적화하도록 학습하는 서브모듈로 구성되고, 상기 오케스트레이터는 쉘로우 네트워크(shallow network)를 이용하여 보상함수 매개변수를 서브모듈에 제공하고, 상기 서브모듈은 보상함수 매개변수에 의해 동적으로 행동 양식을 변경하는 동적 서브모듈을 학습하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0066555", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 인공지능 기반 네트워크 관리시스템의 각 서브모듈의 보상함수를 매개변수화 할 수 있다. 또한 서브모듈의 구조를 크게 수정하지 않고 매개변수를 변경함으로써 서브모듈의 행동양식이 동적으로 변화하 도록 학습할 수 있다. 또한 다양한 서브모듈들에 학습모델을 추가 적용하여 동적 서브모듈들을 충분히 학습하고 확보함으로써 조화로 운 네트워크 오케스트레이션이 가능하게 할 수 있다."}
{"patent_id": "10-2023-0066555", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명은 단지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예 들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에서 상세하게 설명하고자 한다. 그러나 이는 본 발명의 개념에 따른 실시 예 들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물, 또는 대체물을 포함한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 본 명세서에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구 성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하, 본 명세서에 첨부된 도면들을 참조하여 본 발명의 실시 예들을 상세히 설명한다. 도 1은 본 발명의 실시예에 따른 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 시스템을 설명하기 위한 구성도이다. 도 1을 참조하면, 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 시스템은 오케스트레이터, 서브모듈, 네트워크 관리시스템으로 구성된다. 오케스트레이터는 보상함수 매개변수를 다양한 값으로 변환할 수 있으며, 서브모듈의 학습모델이 보 상함수 매개변수를 인식할 수 있도록 간단한 모델을 통해 보상함수 매개변수를 처리하여 서브모듈에 전달 할 수 있다. 오케스트레이터는 매개변수 샘플링모듈, 매개변수 제공모듈, 데이터베이스로 구성된다.상기 매개변수 샘플링모듈은 각 서브모듈의 보상함수 매개변수를 다양한 값으로 변환할 수 있다. 이 때, 보상함수 매개변수의 변환량이 학습모델의 행동양식 변경에 실효성을 가질 수 있는 정도여야 한다. 따라서 매개변수 샘플링모듈은 다양한 환경에서 실험된 기존 학습모델의 보상함수 매개변수 민감도를 기반으로 보 상함수 매개변수를 무작위 샘플링 할 수 있다. 상기 매개변수 제공모듈은 매개변수 샘플링모듈에서 무작위 샘플링한 보상함수 매개변수를 간단한 모 델을 통해 처리하여 서브모듈에 제공할 수 있다. 매개변수 제공모듈이 이용하는 간단한 모델은 쉘로 우 네트워크(shallow network)일 수 있으나, 반드시 이에 한정하는 것은 아니다. 쉘로우 네트워크(shallow network)는 얕은 신경망으로, 입력 레이어, 히든 레이어, 출력 레이어인 세 가지 레이어으로 되어 있으며, 히든 레이어와 출력 레이어는 전결합(fully-connected) 레이어인 모델을 의미한다. 본 명세서에서 신경망, 네트워크 함수, 뉴럴 네트워크(neural network)는 상호 교환 가능한 의미로 사용될 수 있다. 신경망은 일반적으로 노드라 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이러 한 노드들은 뉴런(neuron)들로 지칭될 수도 있다. 신경망은 적어도 하나 이상의 노드들을 포함하여 구성된다. 신경망들을 구성하는 노드(또는 뉴런)들은 하나 이상의 링크에 의해 상호 연결될 수 있다. 신경망 내에서, 링크 를 통해 연결된 하나 이상의 노드들은 상대적으로 입력 노드 및 출력 노드의 관계를 형성할수 있다. 입력 노드 및 출력 노드의 개념은 상대적인 것으로서, 하나의 노드에 대하여 출력 노드 관계에 있는 임의의 노드는 다른 노드와의 관계에서 입력 노드 관계에 있을 수 있으며, 그 역도 성립할 수 있다. 상술한 바와 같이, 입력 노드 대 출력 노드 관계는 링크를 중심으로 생성될 수 있다. 하나의 입력 노드에 하나 이상의 출력 노드가 링크를 통 해 연결될 수 있으며, 그 역도 성립할 수 있다. 하나의 링크를 통해 연결된 입력 노드 및 출력 노드 관계에서, 출력 노드의 데이터는 입력 노드에 입력된 데이 터에 기초하여 그 값이 결정될 수 있다. 여기서 입력 노드와 출력 노드를 상호 연결하는 링크는 가중치(weigh t)를 가질 수 있다. 가중치는 가변적일 수 있으며, 신경망이 원하는 기능을 수행하기 위해, 사용자 또는 알고리 즘에 의해 가변 될 수 있다. 예를 들어, 하나의 출력 노드에 하나 이상의 입력 노드가 각각의 링크에 의해 상호 연결된 경우, 출력 노드는 상기 출력 노드와 연결된 입력 노드들에 입력된 값들 및 각각의 입력 노드들에 대응 하는 링크에 설정된 가중치에 기초하여 출력 노드 값을 결정할 수 있다. 상술한 바와 같이, 신경망은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호 연결되어 신경망 내에서 입력 노드 및 출력 노드 관계를 형성한다. 신경망 내에서 노드들과 링크들의 개수 및 노드들과 링크들 사이의 연관관 계, 링크들 각각에 부여된 가중치의 값에 따라, 신경망의 특성이 결정될 수 있다. 예를 들어, 동일한 개수의 노 드 및 링크들이 존재하고, 링크들의 가중치 값이 상이한 두 신경망이 존재하는 경우, 두 개의 신경망들은 서로 상이한 것으로 인식될 수 있다. 신경망은 하나 이상의 노드들의 집합으로 구성될 수 있다. 신경망을 구성하는 노드들의 부분 집합은 레이어 (layer)를 구성할 수 있다. 신경망을 구성하는 노드들 중 일부는, 최초 입력 노드로부터의 거리들에 기초하여, 하나의 레이어(layer)를 구성할 수 있다. 예를 들어, 최초 입력 노드로부터 거리가 n인 노드들의 집합은, n 레 이어를 구성할 수 있다. 최초 입력 노드로부터 거리는, 최초 입력 노드로부터 해당 노드까지 도달하기 위해 거 쳐야 하는 링크들의 최소 개수에 의해 정의될 수 있다. 그러나, 이러한 레이어의 정의는 설명을 위한 임의적인 것으로서, 신경망 내에서 레이어의 차수는 상술한 것과 상이한 방법으로 정의될 수 있다. 예를 들어, 노드들의 레이어는 최종 출력 노드로부터 거리에 의해 정의될 수도 있다. 최초 입력 노드는 신경망 내의 노드들 중 다른 노드들과의 관계에서 링크를 거치지 않고 데이터가 직접 입력되 는 하나 이상의 노드들을 의미할 수 있다. 또는, 신경망 네트워크 내에서, 링크를 기준으로 한 노드 간의 관계 에 있어서, 링크로 연결된 다른 입력 노드들을 가지지 않는 노드들을 의미할 수 있다. 이와 유사하게, 최종 출 력 노드는 신경망 내의 노드들 중 다른 노드들과의 관계에서, 출력 노드를 가지지 않는 하나 이상의 노드들을 의미할 수 있다. 또한, 히든 노드는 최초 입력 노드 및 최후 출력 노드가 아닌 신경망을 구성하는 노드들을 의 미할 수 있다. 본 발명의 일 실시예에 따른 신경망은 입력 레이어의 노드의 개수가 출력 레이어의 노드의 개수와 동일할 수 있 으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 감소하다가 다시 증가하는 형태의 신경망일수 있다. 또한, 본 개시의 다른 일 실시예에 따른 신경망은 입력 레이어의 노드의 개수가 출력 레이어의 노드의 개 수 보다 적을 수 있으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 감소하는 형태의 신경망일 수 있다. 또한, 본 개시의 또 다른 일 실시예에 따른 신경망은 입력 레이어의 노드의 개수가 출력 레이어의 노 드의 개수보다 많을 수 있으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 증가하는 형태의 신경망일 수 있다. 본 개시의 또 다른 일 실시예에 따른 신경망은 상술한 신경망들의 조합된 형태의 신경망일수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이 어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(예를 들어, 어떤 물체가 사 진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감정이 무엇인지 등)를 파악할 수 있다. 딥 뉴럴 네 트워크는 컨볼루션 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), 오토 인코더(auto encoder), GAN(Generative Adversarial Networks), 제한 볼츠 만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크, 적대적 생성 네트워크(GAN: Generative Adversarial Network) 등을 포함할 수 있다. 전술한 딥 뉴럴 네트워크의 기재는 예시일 뿐이며 본 개시는 이에 제한되지 않는다. 본 발명의 일 실시예에서 네트워크 함수는 오토 인코더(autoencoder)를 포함할 수도 있다. 오토 인코더는 입력 데이터와 유사한 출력 데이터를 출력하기 위한 인공 신경망의 일종일 수 있다. 오토 인코더는 적어도 하나의 히 든 레이어를 포함할 수 있으며, 홀수 개의 히든 레이어가 입출력 레이어 사이에 배치될 수 있다. 각각의 레이어 의 노드의 수는 입력 레이어의 노드의 수에서 병목 레이어(인코딩)라는 중간 레이어로 축소되었다가, 병목 레이 어에서 출력 레이어(입력 레이어와 대칭)로 축소와 대칭되어 확장될 수도 있다. 오토 인코더는 비선형 차원 감 소를 수행할 수 있다. 입력 레이어 및 출력 레이어의 수는 입력 데이터의 전처리 이후에 차원과 대응될 수 있다. 오토 인코더 구조에서 인코더에 포함된 히든 레이어의 노드의 수는 입력 레이어에서 멀어질수록 감소하는 구조를 가질 수 있다. 병목 레이어(인코더와 디코더 사이에 위치하는 가장 적은 노드를 가진 레이어)의 노드의 수는 너무 작은 경우 충분한 양의 정보가 전달되지 않을 수 있으므로, 특정 수 이상(예를 들어, 입력 레이어의 절반 이상 등)으로 유지될 수도 있다. 뉴럴 네트워크는 교사 학습, 비교사 학습(unsupervised learning), 반교사 학습(semi supervised learning), 또는 강화 학습 중 적어도 하나의 방식으로 학습될 수 있다. 뉴럴 네트워크의 학습은 뉴럴 네트워크가 특정한 동작을 수행하기 위한 지식을 뉴럴 네트워크에 적용하는 과정일 수 있다. 뉴럴 네트워크는 출력의 오류를 최소화하는 방향으로 학습될 수 있다. 뉴럴 네트워크의 학습에서 반복적으로 학 습 데이터를 뉴럴 네트워크에 입력시키고 학습 데이터에 대한 뉴럴 네트워크의 출력과 타겟의 에러를 계산하고, 에러를 줄이기 위한 방향으로 뉴럴 네트워크의 에러를 뉴럴 네트워크의 출력 레이어에서부터 입력 레이어 방향 으로 역전파(backpropagation)하여 뉴럴 네트워크의 각 노드의 가중치를 업데이트 하는 과정이다. 교사 학습의 경우 각각의 학습 데이터에 정답이 라벨링 되어있는 학습 데이터를 사용하며(즉, 라벨링된 학습 데이터), 비교 사 학습의 경우는 각각의 학습 데이터에 정답이 라벨링되어 있지 않을 수 있다. 즉, 예를 들어 데이터 분류에 관한 교사 학습의 경우의 학습 데이터는 학습 데이터 각각에 카테고리가 라벨링 된 데이터 일 수 있다. 라벨링 된 학습 데이터가 뉴럴 네트워크에 입력되고, 뉴럴 네트워크의 출력(카테고리)과 학습 데이터의 라벨을 비교함 으로써 오류(error)가 계산될 수 있다. 다른 예로, 데이터 분류에 관한 비교사 학습의 경우 입력인 학습 데이터 가 뉴럴 네트워크 출력과 비교됨으로써 오류가 계산될 수 있다. 계산된 오류는 뉴럴 네트워크에서 역방향(즉, 출력 레이어에서 입력 레이어 방향)으로 역전파 되며, 역전파에 따라 뉴럴 네트워크의 각 레이어의 각 노드들의 연결 가중치가 업데이트 될 수 있다. 업데이트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따라 변 화량이 결정될 수 있다. 입력 데이터에 대한 뉴럴 네트워크의 계산과 에러의 역전파는 학습 사이클(epoch)을 구 성할 수 있다. 학습률은 뉴럴 네트워크의 학습 사이클의 반복 횟수에 따라 상이하게 적용될 수 있다. 예를 들어, 뉴럴 네트워크의 학습 초기에는 높은 학습률을 사용하여 뉴럴 네트워크가 빠르게 일정 수준의 성능을 확 보하도록 하여 효율성을 높이고, 학습 후기에는 낮은 학습률을 사용하여 정확도를 높일 수 있다. 뉴럴 네트워크의 학습에서 일반적으로 학습 데이터는 실제 데이터(즉, 학습된 뉴럴 네트워크를 이용하여 처리하 고자 하는 데이터)의 부분집합일 수 있으며, 따라서, 학습 데이터에 대한 오류는 감소하나 실제 데이터에 대해 서는 오류가 증가하는 학습 사이클이 존재할 수 있다. 과적합(overfitting)은 이와 같이 학습 데이터에 과하게 학습하여 실제 데이터에 대한 오류가 증가하는 현상이다. 예를 들어, 노란색 고양이를 보여 고양이를 학습한 뉴 럴 네트워크가 노란색 이외의 고양이를 보고는 고양이임을 인식하지 못하는 현상이 과적합의 일종일 수 있다. 과적합은 머신러닝 알고리즘의 오류를 증가시키는 원인으로 작용할 수 있다. 이러한 과적합을 막기 위하여 다양 한 최적화 방법이 사용될 수 있다. 과적합을 막기 위해서는 학습 데이터를 증가시키거나, 레귤라이제이션 (regularization), 학습의 과정에서 네트워크의 노드 일부를 비활성화하는 드롭아웃(dropout), 배치 정규화 레이어(batch normalization layer)의 활용 등의 방법이 적용될 수 있다. 상기 데이터베이스는 매개변수 샘플링모듈에서 다양한 값으로 변환한 보상함수 매개변수를 저장할 수 있다. 또한 데이터베이스는 다양한 환경에서 실험된 기존 학습모델의 보상함수 매개변수 민감도를 저장할 수 있다. 또한 데이터베이스는 매개변수 샘플링모듈에서 무작위 샘플링된 보상함수 매개변수를 저장 할 수 있다. 또한 데이터베이스는 오케스트레이터에서 사용되는 쉘로우 네트워크(shallow network)를 저장하고 있을 수 있으며, 오케스트레이터에서 발생하는 모든 정보를 저장할 수 있다. 서브모듈은 보상함수 매개변수에 의해 동적으로 행동양식을 변경하는 동적 서브모듈을 학습할 수 있으며, 적어도 하나 이상의 서브모듈이 존재할 수 있다. 서브모듈은 SFC(Service Function Chaining) 서브 모듈, Auto-Scaling 서브모듈, VNF 배치 서브모듈, 전력관리 서브모듈 중 적어도 하나일 수 있으나 반드시 이에 한정되는 것은 아니다. SFC(Service Function Chaining) 서브모듈은 데이터 패킷에 적용될 네트워크 기능으로 데이터 패킷을 라우팅 시 키는 서브모듈로, 서비스 만족도( )와 로드밸런싱(LoadBalance)의 두 가지 보상함수(R)을 최적화하도록 학습되고, SFC 서브모듈의 보상함수는 [식 1]과 같이 구성될 수 있다. [식 1] 이 때 은 보상함수를 의미하고, 는 서비스 만족도를, βLoadBalance는 로드밸런스를 의미한다. β는 SFC 서브모듈 보상함수의 매개변수로서, 오케스트레이터로부터 수신한 보상함수 매개변수 값에 따라 변화 할 수 있다. Auto-Scaling 서브모듈은 가상 네트워크 기능함수(VNF)의 개수를 조절하는 서브모듈로, 서비스 만족도 ( )와 자원 사용량 절약( )의 두 가지 보상함수(R)을 최적화하도록 학습되고, Auto-Scaling 서브모듈 의 보상함수는 [식 2]와 같이 구성될 수 있다. [식 2] 이 때 는 보상함수를 의미하고, 는 서비스 만족도를, 는 자원사용량을 의미한다. 는 Auto- Scaling 서브모듈 보상함수의 매개변수로서, 오케스트레이터로부터 수신한 보상함수 매개변수 값에 따라 변화할 수 있다. 일 실시예로, 제공되는 자원이 풍부한 상황이라면 보상함수 매개변수인 는 감소할 것이다. 또 다른 실시예로, 특정 서버의 이상이 발생하여 자원이 부족한 상황이라면 보상함수 매개변수인 는 증가할 것이다. 전력관리 서브모듈은 전력 사용량을 조절하는 서브모듈로, Auto-Scaling 서브모듈의 보상함수( )와 파워콘 (PwerCon(W))의 두 가지 보상함수(R)을 최적화하도록 학습되고, 전력관리 서브모듈의 보상함수는 [식 3]와 같이 구성될 수 있다. [식 3] 이 때 은 보상함수를 의미하고, 는 Auto-Scaling 서브모듈의 보상함수를, 는 파워콘 사용량을 의미한다. γ는 전력관리 서브모듈 보상함수의 매개변수로서, 오케스트레이터로부터 수신한 보상 함수 매개변수 값에 따라 변화할 수 있다. 서브모듈은 서브모듈학습부, 데이터베이스로 구성된다. 상기 서브모듈학습부는 오케스트레이터로부터 수신한 보상함수 매개변수를 기반으로 학습모델을 통해 보상함수를 최적화하도록 학습할 수 있으며, 매개변수 입력모듈과 보상함수 최적화모듈로 구성된다. 상기 매개변수 입력모듈은 오케스트레이터로부터 간단한 모델을 통해 처리된 무작위 샘플링한 보상함 수 매개변수를 수신할 수 있다. 매개변수 입력모듈은 수신한 보상함수 매개변수를 학습모델에 입력할 수있다. 상기 학습모델은 보상함수를 최적화하도록 서브모듈을 학습시키는 모델을 의미한다. 상기 보상함수 최적화모듈은 매개변수 입력모듈이 학습모델에 보상함수 매개변수를 입력하면, 학습모 델을 통해 보상함수를 최적화하도록 학습할 수 있다. 데이터베이스는 서브모듈에서 발생하는 모든 정보를 저장할 수 있다. 도 2는 본 발명의 실시예에 따른 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법을 설명하기 위한 구성도이다. 도 2를 참조하면, 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법은, 오케스 트레이터가 보상함수 매개변수를 샘플링한다(S201). 상기 오케스트레이터는 각 서브모듈의 보상 함수 매개변수를 다양한 값으로 변환할 수 있다. 보상함수 매개변수의 변환량이 학습모델의 행동양식 변경에 실 효성을 가질 수 있는 정도여야 하기 때문에, 오케스트레이터는 다양한 환경에서 실험된 기존 학습모델의 보상함수 매개변수 민감도를 기반으로 보상함수 매개변수를 무작위 샘플링 한다. 오케스트레이터가 샘플링한 보상함수 매개변수를 서브모듈에 제공한다(S203). 상기 오케스트레이터 는 무작위 샘플링한 보상함수 매개변수를 간단한 모델을 통해 처리하여 서브모듈에 제공할 수 있다. 상기 간단한 모델은 쉘로우 네트워크(shallow network)일 수 있으나, 반드시 이에 한정하는 것은 아니다. 쉘로 우 네트워크(shallow network)는 얕은 신경망으로, 입력 레이어, 히든 레이어, 출력 레이어인 세 가지 레이어으 로 되어 있으며, 히든 레이어와 출력 레이어는 전결합(fully-connected) 레이어인 모델을 의미한다. 서브모듈이 오케스트레이터로부터 보상함수 매개변수를 수신하여 보상함수 매개변수를 학습모델에 입 력한다(S205). 상기 서브모듈은 SFC(Service Function Chaining) 서브모듈, Auto-Scaling 서브모듈, VNF 배치 서브모듈, 전력관리 서브모듈 중 적어도 하나일 수 있으나 반드시 이에 한정되는 것은 아니다. 상기 학습 모델은 보상함수를 최적화하도록 서브모듈을 학습시키는 모델을 의미한다. 서브모듈이 학습모델을 통해 보 상함수를 최적화하도록 학습한다(S207). 서브모듈은 학습모델을 통해 보상함수 매개변수에 의해 동적으로 행동양식을 변경하는 동적 서브모듈을 학습할 수 있다. 도 3은 본 발명의 실시예에 따른 보상함수 매개변수에 대한 모델 학습 결과 상관관계에 관한 그래프이다. 도 3을 참조하면, Auto-Scaling 서브모듈의 보상함수 매개변수인 α에 대한 모델 학습 결과 상관관계를 나타낸 다. 트레이닝 상황에서의 VNF Penalty를 확인할 수 있으며, 보상함수 매개변수의 변화에 따라 지연시간과 자원 사용량의 상충 관계를 확인할 수 있다. 도 4 내지 도 5는 본 발명의 실시예에 따른 보상함수 매개변수의 변화에 따른 모델 성능을 확인하는 실험에 대 한 결과값을 나타낸다. 도 4(a)를 참조하면, Auto-Scaling 서브모듈의 보상함수 매개변수인 α의 테스트 값이 0.07인 상황의 실험에서 고정된 α값에 따른 성능(Reward)과 α값이 변화할 때의 성능(Reward)을 비교하여 확인할 수 있다. 도 4(b)를 참조하면, Auto-Scaling 서브모듈의 보상함수 매개변수인 α의 테스트 값이 0.46인 상황의 실험에서 고정된 α 값에 따른 성능(Reward)과 α값이 변화할 때의 성능(Reward)을 비교하여 확인할 수 있다. 도 5(c)를 참조하면, Auto-Scaling 서브모듈의 보상함수 매개변수인 α의 테스트 값이 1.54인 상황의 실험에서 고정된 α값에 따른 성능(Reward)과 α값이 변화할 때의 성능(Reward)을 비교하여 확인할 수 있다. 도 5(d)를 참조하면, Auto- Scaling 서브모듈의 보상함수 매개변수인 α의 테스트 값이 변화하는 상황의 실험에서 고정된 α값에 따른 성능 (Reward)과 α값이 변화할 때의 성능(Reward)을 비교하여 확인할 수 있다. 그 결과, 보상함수 매개변수인 α가 고정된 특정 상황의 실험에서도 본원발명에서 제안하는 학습모델이 기존모델들과 비교하여 준수한 성능(Rewar d)을 보이며, α가 바뀌는 다이나믹한 상황의 실험에서는 가장 우수한 성능을 보이는 것을 확인할 수 있다. 발명은 도면에 도시된 실시 예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지 식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0066555", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 시스템을 설명하기 위한 구성도이다. 도 2는 본 발명의 실시예에 따른 파라메트릭 보상 강화학습을 활용한 네트워크 관리에서의 동적 서브모듈 학습 방법을 설명하기 위한 구성도이다. 도 3은 본 발명의 실시예에 따른 보상함수 매개변수에 대한 모델 학습 결과 상관관계에 관한 그래프이다. 도 4 내지 도 5는 본 발명의 실시예에 따른 보상함수 매개변수의 변화에 따른 모델 성능을 확인하는 실험에 대 한 결과값을 나타낸다."}
