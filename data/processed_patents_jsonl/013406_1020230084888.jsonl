{"patent_id": "10-2023-0084888", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0003005", "출원번호": "10-2023-0084888", "발명의 명칭": "가상 데이터의 특성을 확인할 수 있도록 구현되는 생성 모델을 포함하는 컴퓨팅 장치 및 컴퓨", "출원인": "주식회사 페블러스", "발명자": "이주행"}}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치로서, 메모리; 및상기 메모리에 전자적으로 연결되는 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는, 사전 학습된 생성 모델을 이용하여, 잠재 코드(latent code)를 기초로 제1 가상 데이터 셋을 생성하고, 대상 데이터 셋을 제1 임베딩 공간에 매핑함으로써 상기 대상 데이터 셋에 대응되는 제1 매니폴드를 식별하고, 상기 제1 가상 데이터 셋을 상기 제1 임베딩 공간에 매핑함으로써 상기 제1 가상 데이터 셋에 대응되는 제2 매니폴드를 식별하고, 및상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도가 미리 정해진 조건을 충족하지 않는다는 판단을 기초로, 상기 생성 모델의 파라미터를 조정하도록 설정되는 컴퓨팅 장치."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는, 상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도가 미리 정해진 조건을충족한다는 판단을 기초로, 상기 제1 가상 데이터 셋을 제공하도록 더 설정되는 컴퓨팅 장치."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 제1 매니폴드 및 상기 제2 매니폴드의 매칭 정도에 연관되는 제1 지표를산출하고, 상기 제1 지표를 기반으로 상기 생성 모델의 파라미터를 조정하도록 설정되는 컴퓨팅 장치."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도는 상기 제1 매니폴드에 포함되는 적어도 하나의 데이터포인트 및 상기 제2 매니폴드에 포함되는 적어도 하나의 데이터 포인트 사이의 거리를 기초로 획득되는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도는 상기 제1 매니폴드에 포함되는 적어도 하나의 데이터포인트 및 상기 제2 매니폴드에 포함되는 적어도 하나의 데이터 포인트 사이의 각도를 기초로 획득되는 것을 특징으로 하는 컴퓨팅 장치.공개특허 10-2025-0003005-3-청구항 6 제1항에 있어서, 상기 적어도 하나의 프로세서는 파라미터가 조정된 생성 모델을 이용하여, 잠재 코드를 기초로 제2 가상 데이터셋을 생성하도록 더 설정되는 컴퓨팅 장치."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 잠재 코드는 상기 대상 데이터 셋의 특성을 기초로 결정되는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 잠재 코드는 임의의 노이즈 데이터를 기초로 결정되는 것을 특징으로 하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 프로세서에 의해 수행되는 방법으로서, 상기 적어도 하나의 프로세서에 의해,사전 학습된 생성 모델을 이용하여, 잠재 코드(latent code)를 기초로 제1 가상 데이터 셋을 생성하는 단계;대상 데이터 셋을 제1 임베딩 공간에 매핑함으로써 상기 대상 데이터 셋에 대응되는 제1 매니폴드를 식별하는단계;상기 제1 가상 데이터 셋을 상기 제1 임베딩 공간에 매핑함으로써 상기 제1 가상 데이터 셋에 대응되는 제2 매니폴드를 식별하는 단계; 및상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도가 미리 정해진 조건을 충족하지 않는다는 판단을 기초로, 상기 생성 모델의 파라미터를 조정하는 단계;를 포함하는 방법."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도가 미리 정해진 조건을 충족한다는 판단을 기초로, 상기제1 가상 데이터 셋을 제공하는 단계;를 더 포함하는 방법."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 파라미터를 조정하는 단계는, 상기 제1 매니폴드 및 상기 제2 매니폴드의 매칭 정도에 연관되는 제1 지표를 산출하고, 상기 제1 지표를 기반으로 상기 생성 모델의 파라미터를 조정하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,공개특허 10-2025-0003005-4-상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도는 상기 제1 매니폴드에 포함되는 적어도 하나의 데이터포인트 및 상기 제2 매니폴드에 포함되는 적어도 하나의 데이터 포인트 사이의 거리를 기초로 획득되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도는 상기 제1 매니폴드에 포함되는 적어도 하나의 데이터포인트 및 상기 제2 매니폴드에 포함되는 적어도 하나의 데이터 포인트 사이의 각도를 기초로 획득되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 파라미터가 조정된 생성 모델을 이용하여, 잠재 코드를 기초로 제2 가상 데이터 셋을 생성하는 단계;를 더 포함하는 방법."}
{"patent_id": "10-2023-0084888", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 따른 컴퓨팅 장치를 포함하는 서버; 및상기 서버와의 통신이 연결되고, 대상 데이터 셋을 상기 서버에 전송하는 사용자 장치;를 포함하는 시스템."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에 따르면, 메모리 및 상기 메모리에 전자적으로 연결되는 적어도 하나의 프로세서를 포함하고, 상기 적 어도 하나의 프로세서는, 사전 학습된 생성 모델을 이용하여, 잠재 코드(latent code)를 기초로 제1 가상 데이터 셋을 생성하고, 대상 데이터 셋을 제1 임베딩 공간에 매핑함으로써 상기 대상 데이터 셋에 대응되는 제1 매니폴 드를 식별하고, 상기 제1 가상 데이터 셋을 상기 제1 임베딩 공간에 매핑함으로써 상기 제1 가상 데이터 셋에 대 응되는 제2 매니폴드를 식별하고, 및 상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도가 미리 정해진 조 건을 충족하지 않는다는 판단을 기초로, 상기 생성 모델의 파라미터를 조정하도록 설정되는 컴퓨팅 장치가 제공 될 수 있다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 머신 러닝 모델을 이용하여 데이터를 처리하기 위한 컴퓨팅 장치에 관한 것이다. 보다 상세하게는, 머신 러닝 모델의 능력을 향상시키기 위한 학습 데이터 클리닉 솔루션을 제공하는 컴퓨팅 장치에 관한 것이다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 대부분의 기술 분야에서 딥러닝 기반 인공지능 알고리즘이 활용되고 있다. 특히, 규칙성이 없는 비정형 데이터(unstructured data)가 딥러닝 분야에 이용되기 시작하고 있고, 이에 따라 학습에 사용되는 데이터의 양 적 문제가 대두되었다. 업계에서는 데이터의 양적 문제를 해결하기 위해 다양한 솔루션들을 제안하고 있다. 특히, 가상 데이터 (synthetic data)의 생성 기술이 고도화됨에 따라 다양한 기술 분야에서 딥러닝 모델을 학습시키는 데에 가상 데이터를 활용하고 있다. 다만, 가상 데이터가 무분별하게 생성되고, 최근 인공 신경망 기반 딥러닝 모델들이 고도화됨에 따라, 더 이상 학습 모델의 품질을 강화하기 보다는 데이터의 품질을 향상시키려는 니즈가 강해지고 있는 추세이다. 이러한 이유에서, 딥러닝 모델을 학습시키기 위한 데이터의 품질을 정확하게 평가하는 것이 중요하다. 다만, 시 중의 데이터의 품질 판단 방법은 정형 데이터의 무결성 검증에 그치고 있는 등 한계가 명확하므로, 여러 기술 분야에 활용되는 데이터들에 공통적으로 적용할 수 있는 데이터 솔루션이 필요한 상황이다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 과제는 데이터 셋의 내재적 특성을 유지하는 데이터 처리 모델을 제공하는 것이다. 본 개시의 다른 일 과제는 머신 러닝 모델의 학습 효율을 증진시키기 위한 학습 데이터 처리 모델을 제공하는 것이다. 본 개시의 다른 일 과제는 언어 기반 모델을 이용하여 데이터 클리닉 솔루션을 제공하는 것이다. 한편, 본 개시에서 해결하고자 하는 과제가 상술한 과제로 제한되는 것은 아니며, 언급되지 아니한 과제들은 본"}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "명세서 및 첨부된 도면으로부터 본 개시에 포함된 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확 하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 적어도 하나의 머신 러닝 모듈을 포함하는 메모리; 및 상기 메모리에 전자적으 로 연결되는 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는, 제1 데이터 셋을 획득하고, 제1 인코딩 모듈을 이용하여, 상기 제1 데이터 셋을 기초로 제1 차원의 제1 임베딩 공간에 매핑함으로써 제1 임 베딩 벡터를 식별하고, 제1 어댑터 모듈 또는 제2 어댑터 모듈 중 적어도 하나에 상기 제1 임베딩 벡터를 입력 하고, - 이때, 상기 제1 어댑터 모듈은 제2 차원의 제2 임베딩 공간에 데이터를 매핑하고, 상기 제2 어댑터 모 듈은 제3 차원의 제3 임베딩 공간에 데이터를 매핑하도록 구현됨 - 및 상기 제1 인코딩 모듈 및 상기 제1 어댑 터 모듈 또는 상기 제2 어댑터 모듈 중 적어도 하나를 이용하여, 상기 제1 임베딩 벡터를 기초로 상기 제1 데이 터 셋에 대응되는 제1 데이터 이미지를 획득하도록 설정되는 컴퓨팅 장치가 제공될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 컴퓨팅 장치에 포함되는 적어도 하나의 프로세서에 의해 수행되는 데이터 처리 방법으로서, 상기 적어도 하나의 프로세서에 의해, 제1 데이터 셋을 획득하는 단계; 상기 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별하는 단계; 상기 제1 데이터 포인트 셋에 포함된 복수의 데이터 포인트들 사이의 적어도 하나의 거리 값을 기초로 상기 제1 데이터 셋의 제1 특성을 획득하는 단 계; 상기 제1 특성을 기초로 상기 제1 데이터 포인트 셋 상의 적어도 하나의 응축 공간을 식별하는 단계; 상기 적어도 하나의 응축 공간에 포함된 복수의 데이터 포인트들 중 적어도 일부를 제거하여 제2 데이터 포인트 셋을 획득하는 단계; 및 상기 제2 데이터 포인트 셋을 기초로 가공된 제1 데이터 셋을 획득하는 단계;를 포함하는 방 법이 제공될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 메모리; 및 상기 메모리에 전자적으로 연결되는 적어도 하나의 프로세 서;를 포함하고, 상기 적어도 하나의 프로세서는, 사전 학습된 생성 모델을 이용하여, 잠재 코드(latent code) 를 기초로 제1 가상 데이터 셋을 생성하고, 대상 데이터 셋을 제1 임베딩 공간에 매핑함으로써 상기 대상 데이 터 셋에 대응되는 제1 매니폴드를 식별하고, 상기 제1 가상 데이터 셋을 상기 제1 임베딩 공간에 매핑함으로써 상기 제1 가상 데이터 셋에 대응되는 제2 매니폴드를 식별하고, 및 상기 제1 매니폴드 및 상기 제2 매니폴드 사 이의 유사도가 미리 정해진 조건을 충족하지 않는다는 판단을 기초로, 상기 생성 모델의 파라미터를 조정하도록 설정되는 컴퓨팅 장치가 제공될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서에 의해 수행되는 데이터 처리 방법으로서, 상기 적어도 하나의 프로세서에 의해, 제1 데이터 셋을 획득하는 단계; 사전 학습된 제1 모델을 이용하여, 상기 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별하는 단계; 상기 제1 데이터 포인트 셋을 기초로 상기 제1 데이터 셋의 적어도 하나의 특성에 연관된 제1 진단 데이터를 획득하는 단계; 상기 제1 진단 데이터를 기반으로 프롬프트 데이터를 획득하는 단계; 및 사전 학습된 제2 모델을 이용하여, 상기 프롬프 트 데이터를 기초로 제1 가상 데이터 셋을 생성하는 단계;를 포함하는 방법이 제공될 수 있다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 발명의 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급하지 아니한 해결 수단들은 본 명세서 및 첨부된 도면으로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 데이터 셋의 내재적 특성을 반영하는 데이터 이미지를 제공할 수 있다. 또한, 본 개시에 따르면, 머신 러닝 모델의 학습 효율을 증진시킬 수 있다. 또한, 본 개시에 따르면, 언어 기반 모델과 연동된 데이터 클리닉 솔루션을 제공할 수 있다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들이 상술한 효과들로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도 면으로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시예를 첨부의 도면을 참조하여 상세하게 설명한다. 실시예를 설명함에 있어서 본 개시가 속 하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더욱 명확히 전달하기 위함이다. 본 명세서에 기재된 실시예는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 사상을 명 확히 설명하기 위한 것이므로, 본 발명이 본 명세서에 기재된 실시예에 한정되는 것은 아니며, 본 발명의 범위 는 본 발명의 사상을 벗어나지 아니하는 수정예 또는 변형예를 포함하는 것으로 해석되어야 한다. 본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하여 가능한 현재 널리 사용되고 있는 일반적인 용어 를 선택하였으나 이는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자의 의도, 판례 또는 새로운 기술 의 출현 등에 따라 달라질 수 있다. 다만, 이와 달리 특정한 용어를 임의의 의미로 정의하여 사용하는 경우에는 그 용어의 의미에 관하여 별도로 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가진 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 한다. 본 명세서에 첨부된 도면은 본 발명을 용이하게 설명하기 위한 것으로 도면에 도시된 형상은 본 발명의 이해를 돕기 위하여 필요에 따라 과장되어 표시된 것일 수 있으므로 본 발명이 도면에 의해 한정되는 것은 아니다. 본 명세서에서 본 발명에 관련된 공지의 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있 다고 판단되는 경우에 이에 관한 자세한 설명은 필요에 따라 생략하기로 한다. 또한, 본 명세서의 설명 과정에 서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불 과하다. 또한, 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"부분\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "즉, 본 개시의 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자 에게 본 개시의 범주를 알려주기 위해 제공되는 것이며, 본 개시의 발명은 청구항의 범주에 의해 정의될뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. “제1\" 및/또는 \"제2\" 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상 기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목 적으로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 도면에서 처리 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수 행될 수 있다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설명된 기능들을 수행하는 수단을 생 성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프 로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장 되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 흐름도 블 록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능할 수 있다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능할 수 있다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시에서 사용되는 '~부(unit)'라는 용어는 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미한다. '~부'는 특정한 역할 들을 수행하지만 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체 에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일부 실시예에 따르면 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스 크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~ 부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들 은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 또 한 본 개시의 다양한 실시예에 따르면, '~부'는 하나 이상의 프로세서를 포함할 수 있다. 이하 첨부된 도면을 참조하여 본 개시의 동작 원리를 상세히 설명한다. 하기에서 본 개시를 설명함에 있어 관련 된 공지 기능 또는 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에 는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 개시에서의 기능을 고려하여 정의된 용어들 로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는 메모리; 및 상기 메모리에 전자적으로 연결되는 적어도 하나의 프로 세서;를 포함하고, 상기 적어도 하나의 프로세서는, 사전 학습된 생성 모델을 이용하여, 잠재 코드(latent code)를 기초로 제1 가상 데이터 셋을 생성하고, 대상 데이터 셋을 제1 임베딩 공간에 매핑함으로써 상기 대상 데이터 셋에 대응되는 제1 매니폴드를 식별하고, 상기 제1 가상 데이터 셋을 상기 제1 임베딩 공간에 매핑함으로써 상기 제1 가상 데이터 셋에 대응되는 제2 매니폴드를 식별하고, 및 상기 제1 매니폴드 및 상기 제2 매니폴 드 사이의 유사도가 미리 정해진 조건을 충족하지 않는다는 판단을 기초로, 상기 생성 모델의 파라미터를 조정 하도록 설정될 수 있다. 상기 적어도 하나의 프로세서는, 상기 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도가 미리 정해진 조건을 충족한다는 판단을 기초로, 상기 제1 가상 데이터 셋을 제공하도록 더 설정될 수 있다. 적어도 하나의 프로세서는 상기 제1 매니폴드 및 상기 제2 매니폴드의 매칭 정도에 연관되는 제1 지표를 산출하 고, 상기 제1 지표를 기반으로 상기 생성 모델의 파라미터를 조정하도록 설정될 수 있다. 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도는 상기 제1 매니폴드에 포함되는 적어도 하나의 데이터 포인 트 및 상기 제2 매니폴드에 포함되는 적어도 하나의 데이터 포인트 사이의 거리를 기초로 획득될 수 있다. 제1 매니폴드 및 상기 제2 매니폴드 사이의 유사도는 상기 제1 매니폴드에 포함되는 적어도 하나의 데이터 포인 트 및 상기 제2 매니폴드에 포함되는 적어도 하나의 데이터 포인트 사이의 각도를 기초로 획득될 수 있다. 적어도 하나의 프로세서는 파라미터가 조정된 생성 모델을 이용하여, 잠재 코드를 기초로 제2 가상 데이터 셋을 생성하도록 더 설정될 수 있다. 잠재 코드는 상기 대상 데이터 셋의 특성을 기초로 결정될 수 있다. 잠재 코드는 임의의 노이즈 데이터를 기초로 결정될 수 있다. 도 1은 본 개시의 다양한 실시예에 따른 데이터 클리닉 방법을 수행하기 위한 장치 및 시스템을 설명하기 위한 도면이다. 본 개시의 데이터 클리닉 방법은 통신 네트워크(network) 기반의 플랫폼 시스템 상에서 구현될 수 있다. 구체적으로, 데이터를 취합하여 처리하는 서버 장치, 다양한 목적의 학습 모델을 학습시키는 학습 장치 및 복수 의 클라이언트 장치들이 통신 네트워크 상에서 서로 연결되어 데이터를 송수신할 수 있다. 예를 들어, 서버 장치는 복수의 클라이언트 장치들 중 적어도 하나의 장치로부터 데이터를 수신할 수 있고, 수 신한 데이터를 학습 장치에 송신하여 특정 학습 모델을 학습시킬 수 있다. 또한, 서버 장치는 상기 수신한 데이 터를 처리하여 가공된 데이터를 생성할 수 있고, 상기 가공된 데이터를 상기 복수의 클라이언트 장치들로 전송 할 수 있다. 또한, 예를 들어, 복수의 클라이언트 장치들은 통신 네트워크를 통해 상기 서버 장치에 의해 구현된 서버에 접 속할 수 있고, 상기 서버를 통해 다른 클라이언트 장치와 데이터를 교환하거나 상기 서버에 의해 구현된 기능을 이용할 수 있다. 또한, 상기 서버 장치, 복수의 클라이언트 장치들 및 상기 학습 장치는 하나의 컴퓨팅(computing) 장치로 구현 될 수 있다. 구체적으로, 실시예에 따라 딥러닝 모델을 학습시키는 동작, 데이터를 취합하여 처리하는 동작, 또 는 데이터를 송수신하는 동작 등을 수행하는 컴퓨팅 장치가 제공될 수 있다. 또한, 상기 서버 장치, 학습 장치 및 복수의 클라이언트 장치들은 적어도 하나 이상의 컴퓨팅(computing) 장치 로서, 적어도 하나의 프로세서(또는 컨트롤러)를 포함할 수 있다. 아래에서는, 데이터 클리닉 방법을 제공하기 위한 컴퓨팅 장치에 대해 보다 상세히 설명한다. 도 2는 본 개시의 다양한 실시예에 따른 데이터 클리닉 방법 및 데이터 클리닉을 위한 모델의 학습 방법을 수행 하는 컴퓨팅 장치의 블록도를 도시한 도면이다. 도 2를 참조하면, 컴퓨팅 장치는 데이터 클리닉 방법을 제공하기 위한 다양한 구성들을 포함할 수 있다. 구체적으로, 컴퓨팅 장치는 데이터 및 프로세서에게 전달할 다양한 인스트럭션들(instructions)을 저장하 는 메모리, 상기 메모리로부터 전달받은 인스트럭션들을 기초로 동작을 수행하는 프로세서 및 상기 컴퓨팅 장치 내부적으로 데이터를 통신하게 하거나, 상기 컴퓨팅 장치와 외부 장치 사이의 통신을 가능하게 하는 통신부를 포함할 수 있다. 또한, 선택적으로 혹은 대안적으로, 상기 컴퓨팅 장치는 입력 장치(미도시)를 더 포함할 수 있다. 이때, 상기 입력 장치는 외부로부터의 사용자 입력이 최초로 수신되는 장치로서, 예를 들어, 상기 컴퓨팅 장치 는 키보드, 마우스 등 적어도 하나의 입력 장치를 더 포함할 수 있다. 또한, 선택적으로 혹은 대안적으로, 상기 컴퓨팅 장치는 출력 장치(미도시)를 더 포함할 수 있다. 이때, 상기 출력 장치는 상기 프로세서로부터 외부에 특정 정보를 표시하기 위한 장치로서, 예를 들어, 상기 컴 퓨팅 장치는 디스플레이, VR 기기, AR 글라스, AR 프로젝터 또는 프린팅 장치 등의 적어도 하나의 출력 장치를 더 포함할 수 있다. 도 3은 본 개시의 다양한 실시예에 따른 데이터 클리닉 방법을 수행하는 컴퓨팅 장치에 의해 수행되는 다양한 동작 방법들을 설명하기 위한 도면이다. 도 3을 참조하면, 데이터 클리닉을 위한 컴퓨팅 장치의 적어도 하나의 프로세서는 데이터 클리닉 방법을 수행하기 위해 다양한 동작 방법들을 수행할 수 있다. 이때, 상기 다양한 동작 방법들은 코드화되어 상기 컴퓨 팅 장치의 메모리에 저장되어 있을 수 있다. 구체적으로, 적어도 하나의 프로세서는 입력받은 인풋 데이터 셋을 상기 다양한 동작 방법들을 기초로 처리하여 아웃풋 데이터 셋을 출력할 수 있다. 이때, 상기 인풋 데이터 셋 및 상기 아웃풋 데이터 셋에 포함되는 데이터에 대한 상세한 내용은 아래(도 4 내지 도 33에 대한 설명)에서 설 명한다. 예를 들어, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 데이터 이미징을 위한 동작 방법, 데이터 개선을 위 한 동작 방법, 데이터 생성을 위한 동작 방법, 데이터 특성 추출을 위한 동작 방법, 또는 데이터 평가를 위한 동작 방법을 수행할 수 있으나, 이에 한정되지 않는다. 또한, 상술한 각각의 동작 방법들은 상기 컴퓨팅 장치에 포함되는 적어도 하나의 프로세서의 동작 알고리즘들을 기초로 수행될 수 있다. 예를 들어, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 데이터 이미징 알고리즘, 데이터 개선 알고리즘, 데 이터 생성 알고리즘, 데이터 특성 추출 알고리즘, 또는 데이터 평가 알고리즘 등을 수행할 수 있으나, 이에 한 정되지 않는다. 이때, 각각의 동작 방법 및 알고리즘의 명칭은 설명의 편의를 위해 출력되는 결과에 따라 임의로 명명한 것이므 로, 각각의 동작 방법 또는 알고리즘은 프로세서에 의해 수행되는 동작들을 기초로 정의될 뿐 동작 방법 또는 알고리즘의 명칭 자체로서 발명을 한정하는 것은 아니다. 보다 구체적으로, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는, 데이터 이미징 알고리즘에 따라, 인풋 데이 터 셋을 처리하여 상기 인풋 데이터 셋에 대한 이미지를 생성할 수 있다. 또한, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는, 데이터 개선 알고리즘에 따라 인풋 데이터 셋을 처리하 여 데이터를 개선할 수 있고, 상기 개선의 결과를 생성할 수 있다. 또한, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는, 데이터 생성 알고리즘에 따라, 인풋 데이터 셋을 처리하 여 가상데이터(synthetic data)를 생성할 수 있다. 또한, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는, 데이터 특성 추출 알고리즘에 따라, 인풋 데이터 셋을 처리하여 상기 인풋 데이터 셋의 특성(property)을 추출할 수 있다. 또한, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는, 데이터 평가 알고리즘에 따라, 인풋 데이터 셋을 처리하 여 상기 인풋 데이터 셋의 품질을 평가할 수 있다. 상술한 각각의 알고리즘에 대한 상세한 내용은 아래에서 설명한다. 또한, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 상술한 다양한 동작 방법들 또는 알고리즘들을 병렬적으 로, 연속적으로, 또는 선택적으로 수행할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 동일한 인풋 데이터를 서로 상이한 알고리즘의 입력 값으로 병렬적으로 이용할 수도 있고, 특정 알고리즘에 따라 출력된 결과 값을 다른 알 고리즘의 입력 값으로 연속적으로 이용할 수도 있고, 미리 정해진 방식에 따라 복수의 알고리즘들 중 일부의 알고리즘을 선택적으로 수행할 수도 있다. 또한, 상술한 데이터 클리닉을 위한 다양한 동작 방법 또는 알고리즘은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치에 포함되는 딥러닝 모델에서 수행될 수 있다. 구체적으로, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 상술한 다양한 동작 방법 또는 알고리즘을 수행하기 위한 하나의 딥러닝 모델을 포함할 수 있으나, 이에 한정되 지 않고, 상술한 각각의 동작 방법 또는 알고리즘을 수행하기 위한 다수의 딥러닝 모델들을 포함할 수도 있고, 상술한 다양한 동작 방법 또는 알고리즘들 중 적어도 일부를 수행하기 위한 하나 이상의 딥러닝 모델들을 포함 할 수도 있다. 도 4는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 이미지를 제공하는 방법을 설명하기 위한 도면이 다. 도 4를 참조하면, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 데이터 셋을 입력 받아 데이터 이미지 (Image of Data, IOD)를 제공할 수 있다. 이때, 상기 데이터 셋은 M(M>0)차원의 데이터일 수 있다. 다시 말해, 상기 데이터 셋은 M차원의 인풋 스페이스 상에서 정의되는 데이터 셋일 수 있다. 또한, 상기 데이터 셋은 단일 모달리티(modality)의 데이터 셋일 수 있다. 예를 들어, 상기 데이터 셋은 이미지 데이터 셋일 수 있다. 또한, 상기 데이터 셋은 텍스트 데이터 셋일 수 있다. 또한, 이에 한정되지 않고, 상기 데이터 셋은 모달리티가 서로 상이한 데이터의 집합일 수 있다. 예를 들어, 상 기 데이터 셋은 주석(annotation) 정보를 포함하는 이미지 데이터 셋일 수 있다. 또한, 상기 데이터 셋은 이미 지 및 텍스트의 혼합 데이터 셋일 수 있다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 상술한 이미지 데이터 및 텍스트 데이터뿐만 아니라 시계 열 데이터 셋, 센서 데이터 셋 등 딥러닝 학습에 이용될 수 있는 모든 모달리티의 데이터를 인풋 데이터 셋으로 입력 받아 처리할 수 있다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 제공하는 데이터 이미지(IOD)는 입력받은 데이터 셋을 처 리하여 이미징 공간에 나타낸 것일 수 있다. 여기서 이미지는 2D 이미지를 의미하는 것이 아닌, 데이터를 시각적으로 표현한 것을 통칭하는 표현이다. 구체적으로, 상기 이미징 공간은 2D 공간, 3D 공간, N차원의 가상의 공간을 모두 포함하는 개념으로, 실시예에 따라 제공된 데이터 이미지가 나타나는 공간을 의미한다. 예 를 들어, 컴퓨팅 장치가 입력 받은 데이터 셋을 처리하여 상기 데이터 이미지를 PDF 형태로 출력하는 경우, 2D 또는 3D 이미징 공간에 상기 데이터 이미지를 나타낸 아웃풋을 출력할 수 있으나, 이에 한정되지 않는다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 출력 장치(미도시)를 포함하는 경우, 상기 컴퓨팅 장치는 데이터 이미지를 상기 출력 장치를 통해 제공할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 컴퓨팅 장 치에 연결된 디스플레이를 통해 데이터 이미지를 출력함으로써 상기 데이터 이미지를 제공할 수 있다. 이 경우, 상기 이미징 공간은 상기 디스플레이의 화면일 수 있다. 또한, 예를 들어, 상기 컴퓨팅 장치 는 상기 컴퓨팅 장치에 연결된 프린팅 장치를 통해 데이터 이미지를 출력함으로써 상기 데이터 이미지를 제공할 수 있다. 이 경우, 상기 이미징 공간은 상기 프린팅 장치에 의해 출력되는 용지(paper)일 수 있다. 또한, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 통신부를 통해 외부 디바이스와 통신하는 경우, 상 기 컴퓨팅 장치는 상기 외부 디바이스를 통해 데이터 이미지를 제공할 수 있다. 이 경우, 이미징 공간 은 상기 외부 디바이스의 디스플레이 화면일 수 있다. 예를 들어, 상기 컴퓨팅 장치가 서버 장치인 경우, 상기 서버 장치는 상기 서버 장치에 연결된 네트워크를 통해 상기 서버 장치와 통신하는 적어도 하나의 외부 디바이스로 데이터 이미지를 송신함으로써 상기 데이터 이미지를 제공할 수 있다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 입력된 데이터 셋에 대응되는 포인트 데이터 셋을 포함하 는 데이터 이미지를 제공할 수 있다. 이때, 상기 포인트 데이터 셋은 상기 데이터 셋에 포함되는 각각의 데이터를 포인트로 시각화한 데이터 셋일 수 있다. 이 경우, 시각화되는 포인트의 형상 또는 색상 등은 실시예 에 따라 다양한게 선택될 수 있으므로 '포인트'라는 용어 자체로 발명을 한정하려는 것은 아니다. 또한, 상기 포인트는 실시예에 따라 다양한 용어로 표현될 수 있다. 예를 들어, 상기 포인트는 임베딩 공간 또 는 잠재 공간에 나타나는 벡터(vector) 또는 특징(feature) 등의 용어로 표현될 수 있으나, 이에 한정되지 않는다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 이미지를 제공하기 위해서는, 상술한 바와 같이, 입력받 은 데이터 셋에 대응되는 포인트 데이터 셋을 확인할 필요가 있다. 이때, 상기 컴퓨팅 장치는 입력받은 데이터 셋에 포함되는 데이터가 특정 차원의 임베딩(embedding) 공간(또는 잠재(latent) 공간)에서 형성하는 매니폴드(manifold)를 확인함으로써 상기 포인트 데이터 셋을 획득할 수 있다. 여기서, 상기 매니폴드(manifold)는 입력받은 인풋 데이터 셋이 정의되는 인풋 공간의 차원에서, 실제로 데이터가 존재하는 특정 차원의 가상 공간을 의미할 수 있다. 또한, 상기 매니폴드는 데이터가 특정 차원에서 형성하는 임의의 형상을 의미할 수 있다. 다시 말해, 상기 매니폴드는 입력받은 인풋 데이터 셋을 특정 차원의 임베딩 공간상의 포인트 데이터 셋으로 매핑하는 경우, 상기 포인트 데이터 셋이 확인되는 영역 또는 상기 포인 트 데이터 셋이 형성하는 형상을 의미할 수 있다. 아래에서는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 입력 받은 데이터 셋에 대응되는 포인트 데이터 셋 을 확인하고, 이를 기초로 데이터 이미지를 제공하는 방법에 대해 구체적으로 설명한다. 도 4에 따른 데이터 이미지를 제공하는 컴퓨팅 장치는 포인트 데이터 셋을 확인하기 위한 이미징 매니폴 드 생성 모델(미도시)을 포함할 수 있다. 도 5는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 이미지를 제공하는 방법을 설명하기 위한 흐름도 이다. 도 5를 참조하면, 컴퓨팅 장치는 데이터 이미지에 포함되는 포인트 데이터 셋을 확인하기 위한 이미징 매니폴드 (Imaging Manifold) 생성 모델을 학습할 수 있다(S1001). 이때, 상기 이미징 매니폴드 생성 모델은 인공 신경망 을 포함하는 딥러닝 모델일 수 있다. 컴퓨팅 장치는 데이터 셋의 내재적 특성(intrinsic property)이 보존되는 특정 차원의 매니폴드를 생성 (manifold building)하도록 이미징 매니폴드 생성 모델을 학습시킬 수 있다. 여기서, 상기 데이터 셋의 내재적 특성은 데이터의 모달리티, 데이터가 정의되는 도메인, 데이터의 카테고리 등과 관련없이, 데이터 자체의 분포 와 관련된 특성을 의미한다. 예를 들어, 데이터 셋의 내재적 특성에는 데이터 셋에 포함되는 데이터 사이의 거 리가 포함될 수 있다. 이때, 상기 데이터 사이의 거리는 유클리디언 거리(Euclidean distance)를 의미할 수 있 으나, 이에 한정되지 않고, 당업자 사이에 데이터 사이의 거리로서 통용되는 수학적 개념을 모두 포함할 수 있 다. 본 개시를 통해 정의되는 데이터의 특성에 대해서는 아래(도 10내지 도 15에 대한 설명)에서 보다 자세히 설명 한다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 이미징 매니폴드 생성 모델을 학습하는 방법의 일 예시는 도 6 을 통해 설명한다. 도 6은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 이미징 매니폴드 생성 모델을 학습시키는 방법의 예시를 도시한 도면이다. 도 6을 참조하면, 컴퓨팅 장치는 학습 데이터 셋(D)을 기초로 상기 학습 데이터 셋(D)의 내재적 특성을 유지하는 매니폴드를 찾기 위해 이미징 매니폴드 생성 모델을 학습시킬 수 있다. 또한, 컴퓨팅 장치는 학습 데이터 셋(D)을 기초로 제1 포인트 데이터 셋(P1)을 획득할 수 있다. 이때, 학 습 데이터 셋(D)은 M 차원의 인풋 도메인 상에서 정의될 수 있는 M차원의 데이터 셋일 수 있다. 또한, 컴퓨팅 장치는 상기 학습 데이터 셋(D)을 미리 정해진 조건에 따라 처리하여 상기 제1 포인트 데이터 셋 (P1)을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 매핑 함수( )로 정의된 미리 정해진 조건(예를 들어, 특정차원의 임베딩 공간에 매핑하기 위해 미리 저장된 행렬(matrix))을 기초로 상기 학습 데이터 셋(D)을 N차원의 제1 임베딩 공간 에 매핑함으로써 상기 제1 포인트 데이터 셋(P1)을 획득할 수 있다. 예를 들어, 컴퓨팅 장 치는 상기 학습 데이터 셋(D)을 인코딩함으로써 상기 제1 포인트 데이터 셋(P1)을 획득할 수 있으나, 이에 한정 되지 않는다. 상기 포인트 데이터 셋이 정의되는 매니폴드의 최적의 차원을 결정하는 방법은 도 9를 통해 자세히 설명한다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)을 기초로 복원 데이터 셋(D`)을 획득할 수 있다. 이때, 상 기 복원 데이터 셋(D`)은 상기 학습 데이터 셋(D)과 동일한 M차원의 공간 상에서 정의될 수 있는 M차원의 데이 터 셋일 수 있다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)을 미리 정해진 조건에 따라 처리하여 상기 복원 데이터 셋 (D`)을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 매핑 함수(f)의 역함수( )로 정의된 미리 정해진 조건(예를 들어, 특정 차원의 임베딩 공간에 매핑하기 위해 미리 저장된 행렬(matrix)의 역행렬)을 기초로 상기 제1 포인트 데이터 셋(P1)을 M차원의 아웃풋 도메인( )에 복원함으로써 상기 복원 데이터 셋(D`)을 획득할 수 있다. 이때, 상기 인풋 도메인 및 아웃풋 도메인은 동일한 가상 공간에 포함될 수 있으나, 이에 한정되지 않 는다. 또한, 컴퓨팅 장치는 상기 학습 데이터 셋(D) 및 복원 데이터 셋(D`)을 기초로 이미징 매니폴드 생성 모델을 학 습시킬 수 있다. 구체적으로, 컴퓨팅 장치는 상기 학습 데이터 셋(D) 및 상기 복원 데이터 셋(D`)의 유사도를 기초로 정의된 손실함수(loss function)를 기초로 상기 이미징 매니폴드 생성 모델을 학습시킬 수 있다. 예를 들어, 컴퓨팅 장치는 상기 복원 데이터 셋(D`)이 상기 학습 데이터 셋(D)과 얼마나 유사하게 복원되었는지에 대 한 복원 에러(reconstruction error)를 최소화하는 방향으로 상기 이미징 매니폴드 생성 모델을 학습시킬 수 있 으나, 이에 한정되지 않는다. 도 7은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치의 데이터 이미징 과정을 설명하기 위한 도면이다. 다시 도 5를 참조하면, 상기 컴퓨팅 장치는 상기 학습된 이미징 매니폴드 생성 모델에 상기 데이터 셋을 입력할 수 있다(S1002). 이때, 상기 컴퓨팅 장치는 학습된 외부로부터 수신하여 상기 이미징 매니폴드 생성 모델에 입 력할 수도 있고, 컴퓨팅 장치에 저장된 데이터 셋을 입력받을 수도 있다. 예를 들어, 상기 컴퓨팅 장치는 통신 네트워크를 통해 연결된 외부 디바이스로부터 상기 데이터 셋을 수신하거나, 상기 컴퓨팅 장치의 메모리에 저장 된 데이터 셋을 불러올 수 있으나, 이에 한정되지 않는다. 예를 들어, 도 7을 참조하면, 컴퓨팅 장치는 M차원의 인풋 도메인( ) 상에서 정의되는 데이터 셋(D)을 이미징 매니폴드 생성 모델에 입력할 수 있다. 또한, 다시 도 5를 참조하면, 상기 컴퓨팅 장치는 상기 입력된 데이터 셋을 상기 이미징 매니폴드 생성 모델을 통해 처리함으로써 상기 데이터 셋에 대응되는 포인트 데이터 셋을 확인할 수 있다(S1003). 예를 들어, 다시 도 7을 참조하면, 이미징 매니폴드 생성 모델가 입력 받은 데이터 셋(D)을 기초로 N차원 의 제1 임베딩 공간( )에서 정의되는 제1 포인트 데이터 셋(P1)을 출력함으로써 상기 컴퓨팅 장치는 상 기 제1 포인트 데이터 셋(P1)을 확인할 수 있다. 이때, 상기 제1 포인트 데이터 셋(P1)은 N차원의 제1 매니폴드 를 형성할 수 있다. 또한, 이미징 매니폴드 생성 모델이 출력하는 제1 포인트 데이터 셋(P1)은 상기 이미징 매니폴드 생성 모 델이 입력받는 데이터 셋(D)에 포함되는 데이터 간의 관계를 반영할 수 있다. 보다 구체적으로, 상기 이미 징 매니폴드 생성 모델은 도 6에서 설명한 바와 같이 입력받는 데이터 셋에 포함되는 데이터 간의 관련성 또는 유사도 등의 내재적 특성을 유지하도록 학습될 수 있다. 이에 따라, 학습된 상기 이미징 매니폴드 생성 모 델이 데이터 셋(D)을 입력 받는 경우, N차원의 매니폴드를 생성함으로써 상기 데이터 셋(D)에 포함되는 데 이터의 관계를 나타내는 제1 포인트 데이터 셋(P1)을 출력할 수 있다. 이는, 상기 컴퓨팅 장치가 상기 이미징 매니폴드 생성 모델을 상기 이미징 매니폴드 생성 모델에 입력되는 데이터 셋과 상기 이미징 매니폴드 생성 모 델로부터 복원된 데이터 셋의 오차를 최소화하도록 학습시켰기 때문이다. 또한, 이미징 매니폴드 생성 모델이 출력하는 제1 포인트 데이터 셋(P1)은 상기 입력받은 데이터 셋(D)에 대응될 수 있다. 이때, 상기 제1 포인트 데이터 셋(P1)에 포함되는 각각의 포인트는 상기 데이터 셋(D)에 포함 되는 각각의 데이터에 대응될 수 있다. 예를 들어, 상기 데이터 셋(D)에 포함되는 제1 이미지 데이터는 상 기 포인트 데이터 셋에 포함되는 제1 포인트 데이터에 대응될 수 있고, 제2 이미지 데이터는 제2 포 인트 데이터에 대응될 수 있다. 또한, 이미징 매니폴드 생성 모델이 출력하는 제1 포인트 데이터 셋(P1)에 포함되는 포인트 사이의 거리는 상기 이미징 매니폴드 생성 모델이 입력받는 데이터 셋(D)에 포함되는 데이터 간의 관련성을 기초로 결정 될 수 있다. 즉, 상기 데이터 셋(D)에 포함되는 데이터 사이의 관련성(또는 유사도)이 높을수록, 상기 데이터들 은 상기 제1 임베딩 공간 상에서 보다 가까운 거리에 위치할 수 있다. 또한, 이에 한정되지 않고, 상기 포인트 데이터 셋에 포함되는 각각의 포인트는 상기 데이터 셋에 포함되는 둘 이상의 데이터에 대응될 수 있다. 예를 들어, 상기 데이터 셋에 포함되는 제1 이미지 데이터 및 제2 이미 지 데이터는 상기 포인트 데이터 셋에 포함되는 제1 포인트 데이터에 대응될 수 있다. 또한, 이에 한정되지 않고, 상기 포인트 데이터 셋에 포함되는 둘 이상의 포인트는 상기 데이터 셋에 포함되는 둘 이상의 데이터에 대응될 수 있다. 예를 들어, 상기 데이터 셋에 포함되는 제1 이미지 데이터 및 제2 이 미지 데이터는 상기 포인트 데이터 셋에 포함되는 제1 포인트 데이터 및 제2 포인트 데이터에 대응될 수 있다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)이 정의되는 제1 매니폴드의 시각적 형상을 임의로 결정할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 미리 결정된 형상의 매니폴드 공간에 상기 데이터 셋 (D)의 내재적 특성이 유지되도록 복수의 포인트 데이터들을 매핑함으로써 상기 제1 포인트 데이터 셋(P1)을 획 득할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 제1 매니폴드의 형상에 대한 다양한 템플릿들(예를 들어, 나선 형상 등)을 미리 저장해둘 수 있고, 상기 다양한 템플릿들 중 적어도 하나를 기초로 상기 제1 포인 트 데이터 셋(P1)을 획득할 수 있다. 또한, 다시 도 5를 참조하면, 컴퓨팅 장치는 상기 확인된 포인트 데이터 셋 데이터 이미지를 제공할 수 있다 (S1004). 예를 들어, 다시 도 7을 참조하면, 컴퓨팅 장치는 상기 이미징 매니폴드 생성 모델로부터 출력된 제1 포 인트 데이터 셋(P1)을 이미징 도메인(또는 이미징 공간, 730)에 나타냄으로서 데이터 이미지(IOD)를 획득할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)을 제1 임베딩 공간에서 이미징 공 간으로 매핑함으로써 상기 데이터 이미지(IOD)를 획득할 수 있다. 이때, 상기 컴퓨팅 장치는 미리 정해진 조건에 따라 상기 제1 포인트 데이터 셋(P1)을 매핑할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)을 미리 정해진 방식으로 가공하여 상기 데이터 이미지(IOD)를 획득할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1) 이 그대로 유지되도록 상기 제1 포인트 데이터 셋(P1)을 상기 이미징 공간에 나타낼 수 있으나, 이에 한정되지 않는다. 또한, 예를 들어, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)에 포함된 노이즈 데이터가 제거되 도록 상기 데이터 이미지를 생성할 수 있다. 이때, 상기 노이즈 데이터는 상기 제1 포인트 데이터 셋(P1) 내에서 상기 제1 포인트 데이터 셋(P1)이 형성하는 매니폴드 공간 외에 위치하는 적어도 하나 이상의 포인트 데 이터일 수 있다. 다시 말해, 상기 노이즈 데이터는 상기 제1 포인트 데이터 셋(P1)이 형성하는 매니폴드 공간에 대한 적어도 하나 이상의 아웃라이어 포인트일 수 있다. 상술한 노이즈 데이터 또한 데이터 셋에 포함되는 데이터에 대응되는 데이터일 수 있다. 컴퓨팅 장치가 상기 노 이즈 데이터를 제거하여 데이터 이미지를 제공하는 것은 시각화 관점에서 보다 깔끔한 이미지를 제공하기 위함 일 수 있다. 컴퓨팅 장치가 포인트 데이터 셋의 노이즈 데이터를 제거하여 데이터 이미지를 제공하는 데에 대한 예시는 도 8 을 통해 설명한다. 도 8은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 이미지를 생성하는 예시를 설명하기 위한 흐름도이다. 도 8을 참조하면, 컴퓨팅 장치는 입력 받은 데이터 셋을 기초로 포인트 데이터 셋을 확인할 수 있다(S1005). 단 계 S1005에 대한 기술적 특징은 전술하였으므로 생략하기로 한다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋이 형성되는 매니폴드 영역을 확인할 수 있다(S1006). 이때, 상기 매니폴드 영역은 상기 포인트 데이터 셋이 정의되는 잠재 공간(또는 임베딩 공간)에서 상기 포인트 데이터 셋이 형성하는 가상의 영역을 의미할 수 있다. 또한, 컴퓨팅 장치는 상기 확인된 매니폴드 영역의 경계(Boundary)를 확인할 수 있다(S1007). 이때, 상기 매니 폴드 영역의 경계는 상기 매니폴드 영역의 형상을 의미할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 포인 트 데이터 셋이 위치하는 영역에서 외곽에 위치하는 포인트들로 이어진 매니폴드 영역의 경계를 판단할 수 있다. 또한, 컴퓨팅 장치는 상기 확인된 매니폴드 영역의 경계 외에 위치하는 적어도 하나 이상의 포인트 데이터를 확 인할 수 있다(S1008). 구체적으로, 상기 컴퓨팅 장치는 장치는 상기 확인된 매니폴드 영역의 경계 외에 위치하 는 적어도 하나 이상의 포인트 데이터를 노이즈 데이터(또는 아웃라이어 데이터)로 판단할 수 있다. 또한, 컴퓨팅 장치는 상기 확인된 적어도 하나 이상의 포인트 데이터를 삭제할 수 있다(S1009). 구체적으로, 상 기 컴퓨팅 장치는 상기 노이즈 데이터로 판단된 적어도 하나의 포인트 데이터를 삭제함으로써 데이터 이미지의 시각적 효과를 증진시킬 수 있다. 또한, 컴퓨팅 장치는 단계 S1009에 따라 출력된 포인트 데이터 셋을 기초로 데이터 이미지를 제공할 수 있다 (S1010). 데이터 셋의 내재적 특성을 보다 잘 드러내는 데이터 이미지를 제공하기 위해서는, 포인트 데이터 셋에 의해 형 성되는 매니폴드를 최적화할 필요가 있다. 여기서, 매니폴드의 최적화란 도 6에서 설명한 매니폴드 생성 모델의 학습을 통해 복원 에러가 최소화된 매니폴드를 생성하는 것을 의미할 수 있으나, 이에 한정되지 않고, 상기 학 습의 결과에 따라 생성된 매니폴드를 또 다른 방식을 기초로 최적화하는 과정을 의미할 수도 있다. 구체적으로, 다양한 실시예에 따른 컴퓨팅 장치는 데이터 셋을 미리 정해진 방식에 따라 처리함으로써 상기 데 이터 셋의 내재적 특성을 최적화하여 나타낸 매니폴드를 생성할 수 있다. 예를 들어, 다양한 실시예에 따른 컴퓨팅 장치는 노이즈 데이터가 최소화되도록 포인트 데이터 셋의 매니폴드를 생성할 수 있다. 구체적으로, 컴퓨팅 장치는 노이즈 데이터가 감소하도록 매니폴드 생성 프로세스를 반복 (iteration) 수행할 수 있다. 이때, 상기 컴퓨팅 장치는 매니폴드에 포함되는 노이즈 데이터가 미리 정해진 기 준 이하가 달성될 때까지 상기 매니폴드 생성 프로세스를 반복(iteration) 수행할 수 있다. 데이터 셋의 내재적 특성을 보다 잘 드러내는 데이터 이미지를 제공하기 위해서는, 포인트 데이터 셋에 의해 형 성되는 매니폴드의 최적의 차원을 결정할 필요가 있다. 이는, 데이터 처리의 효율성을 위해 저차원의 매니폴드 를 기초로 데이터 이미지를 생성하는 경우, 데이터 셋의 실제 구조가 왜곡될 수 있고, 정확도를 위해 고차원의 매니폴드를 기초로 데이터 이미지를 생성하는 경우, 데이터 처리의 효율성이 떨어질 수 있기 때문이다. 상술한 문제를 해결하기 위해, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 다양한 매니폴드 차원 결정 방법 을 기초로 데이터 이미징을 위한 최적의 차원을 결정할 수 있다. 아래에서는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 이미징을 위한 최적의 매니폴드 차원을 결정 하기 위한 예시를 설명한다. 도 9는 데이터 이미징을 위한 매니폴드의 최적의 차원을 결정하기 위한 방법의 일 예시를 도시한 흐름도이다. 컴퓨팅 장치는 이미징 매니폴드 생성 모델에 의해 생성되는 매니폴드의 차원에 따른 최소 복원 에러 (reconstruction error)를 기초로 데이터 이미징을 위한 최적의 매니폴드 차원을 결정할 수 있다. 이때, 상기 최소 복원 에러는 상기 이미징 매니폴드 생성 모델의 학습이 완료된 시점에서의 복원 에러 값을 의미할 수 있다. 보다 구체적으로, 상기 컴퓨팅 장치는 차원을 높여가며 매니폴드를 생성할 수 있고, 생성된 매니폴드에 대응되 는 최소 복원 에러 값이 가장 낮은 차원을 최적의 차원으로 결정할 수 있다. 구체적인 예로, 컴퓨팅 장치는 차 원을 미리 정해진 규칙에 따라 증가시킴에 따라 최소 복원 에러가 더 이상 감소하지 않는 시점에서의 차원을 매 니폴드의 최적의 차원으로 결정할 수 있다. 도 9를 참조하면, 컴퓨팅 장치는 제1 차원의 매니폴드 생성 시의 제1 최소 복원 에러를 확인할 수 있다(S1011). 이때, 상기 제1 차원은 상기 컴퓨팅 장치가 최적의 차원을 결정하는 알고리즘을 수행하기 위해 설정된 초기 값 일 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상술한 알고리즘이 수행되는 경우, 3차원의 매니폴드를 최초로 생 성할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 미리 정해진 규칙에 따라 차원을 증가시키면서 최소 복원 에러를 확인할 수 있다(S1012). 이때, 상기 미리 정해진 규칙은 상기 컴퓨팅 장치에 미리 저장된 차원을 증가시키는 로직(logic)을 의미할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 매니폴드의 차원을 미리 정해진 값(예를 들어, 1)씩 증가시키면서 최소 복원 에러를 확인할 수 있으나, 이에 한정되지 않고, 미리 정해진 수열(예를 들어, 등차 수열, 등비 수열 등)에 따라 증가시키면서 최소 복원 에러를 확인할 수 있다. 또한, 이에 한정되지 않고, 상기 미리 정해진 규칙은 상기 제1 최소 복원 에러를 기초로 결정될 수 있다. 보다 구체적으로, 컴퓨팅 장치는 단계 S1011에 따라 계산된 제1 최소 복원 에러가 임계값 이상인지 여부를 기초로 차 원의 증가폭을 결정할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 제1 최소 복원 에러가 임계값 이하인 경우 제1 증가량 만큼 차원을 증가시켜 최소 복원 에러를 확인할 수 있고, 상기 제1 최소 복원 에러가 임계값 이상인 경우 상기 제1 증가량 보다 큰 제2 증가량 만큼 차원을 증가시켜 최소 복원 에러를 확인할 수 있다. 또한, 컴퓨팅 장치는 최소 복원 에러가 더 이상 감소하지 않는 차원을 매니폴드의 차원으로 결정할 수 있다 (S1013). 구체적으로, 컴퓨팅 장치는 차원을 차원을 증가시킴에도 최소 복원 에러가 더 이상 감소하지 않는 시 점의 차원 값을 매니폴드의 차원으로 결정할 수 있다. 또한, 이에 한정되지 않고, 컴퓨팅 장치는 최소 복원 에러의 변화량을 기초로 매니폴드의 차원을 결정할 수 있 다. 구체적으로, 컴퓨팅 장치는 차원에 따른 최소 복원 에러의 변화량을 계산할 수 있고, 상기 최소 복원 에러 의 변화량이 임계치 이하가 되는지 여부를 확인함으로써 매니폴드의 차원을 결정할 수 있다. 예를 들어, 컴퓨팅 장치는 상기 최소 복원 에러의 변화량이 임계치 이하가 되는 시점에서의 차원 값을 생성할 매니폴드의 차원으로 결정할 수 있다. 또한, 이에 한정되지 않고, 컴퓨팅 장치는 최소 복원 에러의 변화량의 변곡점을 기초로 매니폴드의 차원을 결정 할 수 있다. 구체적으로, 컴퓨팅 장치는 최소 복원 에러의 변화량이 증가하다가 감소하기 시작하는 시점에서의 차원 값을 매니폴드의 차원으로 결정할 수 있다. 또한, 컴퓨팅 장치는 매니폴드가 정의되는 최대 차원 값을 미리 저장해둘 수 있다. 구체적으로, 컴퓨팅 장치가 상기 미리 정해진 규칙에 따라 차원을 증가시키면서 최소 복원 에러를 확인하다가, 차원 값이 상기 미리 저장된 최대 차원 값에 도달한 경우, 상기 컴퓨팅 장치는 상기 미리 저장된 최대 차원 값을 매니폴드의 차원으로 결정 할 수 있다. 이때, 상기 최대 차원 값은 컴퓨팅 장치의 처리 용량을 고려하여 설정될 수 있다. 이는, 매니폴드 의 차원이 높아지면 컴퓨팅 장치의 데이터 처리 부하가 증가하므로, 이를 고려한 것이다. 또한, 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 데이터 이미징에 적합한 매니폴드의 차원 값을 입력되는 데이터 셋에 따라 저장할 수 있다. 구체적으로, 상술한 방식에 따라 결정된 매니폴드의 차원 값 및 이에 대응되 는 데이터 셋을 미리 저장할 수 있고, 또한, 임의로 결정된 매니폴드의 차원 값 및 이에 대응되는 데이터 셋을 미리 저장할 수도 있다. 또한, 컴퓨팅 장치는 상기 매니폴드의 차원 값 및 입력 데이터 셋의 관계를 데이터 베 이스(database) 형태로 저장할 수 있다. 또한, 컴퓨팅 장치는 상기 매니폴드의 차원 값 및 입력 데이터 셋의 관계를 데이터 베이스(database)를 기초로 매니폴드의 차원을 결정할 수 있다. 구체적으로, 컴퓨팅 장치는 데이터 셋이 입력되는 경우, 상기 데이터 셋과 유사한 데이터 셋을 데이터 베이스에서 확인할 수 있고, 상기 확인된 데이터 셋에 대응되는 매니폴드의 차원 값 을 선택할 수 있다. 예를 들어, 컴퓨팅 장치는 입력되는 데이터 셋과 유사한 분포를 가지는 데이터 셋을 데이터베이스 내에서 확인함으로써 이에 대응되는 차원 값을 선택할 수 있으나, 이에 한정되지 않는다. 또한, 예를 들 어, 컴퓨팅 장치는 입력되는 데이터 셋과 유사한 차원을 가지는 데이터 셋을 확인함으로써 이에 대응되는 차원 값을 선택할 수 있으나, 이에 한정되지 않는다. 또한, 예를 들어, 컴퓨팅 장치는 입력 데이터 셋 과의 거리가 미리 정해진 임계치 이하인 데이터 셋을 확인함으로써 이에 대응되는 차원 값을 선택할 수 있으나, 이에 한정되 지 않는다. 도 10은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋의 특성을 제공하는 방법을 도시한 도면이다. 도 10을 참조하면, 컴퓨팅 장치는 획득한 데이터 셋을 처리하여 상기 데이터 셋의 특성(property)을 획득 할 수 있다. 이때, 상기 데이터 셋의 특성(property)는 상기 데이터 셋을 나타내는 다양한 정보를 의미할 수 있다. 예를 들 어, 상기 데이터 셋의 특성은 상기 데이터 셋의 밀도, 균질도 또는 분포 등을 포함할 수 있으나, 이에 한정되지 않는다. 즉, 상기 데이터 셋의 특성은 데이터 셋이 활용되는 태스크(task)와 관계없는 데이터의 밀도와 같은 내 재적 특성을 의미할 수 있으나, 이에 한정되지 않고, 데이터 셋이 활용되는 태스크(예를 들어, Classificatio n)에 관련되는, 하드-네거티브(Hard-negative)의 비율등의 태스크에 의존된 특성(task-dependent property)도 포함할 수 있다. 또한, 컴퓨팅 장치는 상기 데이터 셋의 특성들 각각에 대응되는 연산 메트릭을 메모리에 저장하고 있을 수 있다. 보다 구체적으로, 상기 컴퓨팅 장치는 데이터 셋의 밀도를 연산하기 위한 메트릭, 데이터 셋의 균질도를 연산하기 위한 메트릭, 또는 데이터 셋의 분포를 연산하기 위한 메트릭 등을 저장하고 있을 수 있으나, 이에 한 정되지 않는다. 또한, 컴퓨팅 장치는 인공 신경망으로 구축된 데이터 특성 추출 알고리즘에 따라 상기 저장된 연산 메트릭을 기 초로 데이터 셋의 특성을 획득할 수 있다. 구체적으로, 상기 특성 추출 알고리즘은 피드 포워드(feed-forward) 신경망으로 구현될 수 있다. 예를 들어, 상기 컴퓨팅 장치는 데이터 셋의 특성을 연산하기 위한 별도의 인경 신경망을 포함하거나, 상기 데 이터 셋의 특성을 연산하기 위한 레이어(layer)를 포함하는 인경 신경망을 포함할 수 있으나, 이에 한정되지 않 는다. 일 예로, 컴퓨팅 장치는 데이터 셋을 입력받으면 데이터 셋의 특성을 추출하도록 설계된 특성 추출을 위한 인공 신경망을 포함할 수 있다. 이때, 상기 특성 추출을 위한 인공 신경망은 데이터의 특성을 연산하도록 전이 학습 된 인공신경망일 수 있다. 다른 예로, 컴퓨팅 장치는 데이터 셋을 기초로 데이터 이미지를 제공하기 위한 이미징 매니폴드 생성 모델에 데 이터 특성 추출을 위한 레이어(layer)를 추가한 인공 신경망을 구축함으로써 데이터 셋의 특성을 획득할 수 있 다. 구체적으로, 컴퓨팅 장치는 획득한 데이터 셋을 기초로 상술한 이미징 매니폴드 생성 모델을 기초로 포인트 데 이터 셋을 확인하고, 상기 확인된 포인트 데이터 셋을 기초로 데이터 셋의 특성을 획득할 수 있다. 이때, 컴퓨팅 장치는 포인트 데이터 셋에 포함되는 각각의 포인트 데이터를 미리 정해진 알고리즘으로 처리함으 로써 데이터 셋의 특성을 획득할 수 있다. 이 경우, 상기 컴퓨팅 장치는 상기 포인트 데이터 셋에 포함되는 각 각의 포인트 데이터에 대하여 특성 값(value)을 할당할 수 있고, 상기 특성 값들을 기초로 데이터 셋의 특성을 획득할 수 있다. 또한, 이에 한정되지 않고, 컴퓨팅 장치는 포인트 데이터 셋을 미리 정해진 알고리즘으로 처리하여 데이터 셋의 특성을 획득할 수 있다. 도 11은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋에 포함된 포인트 데이터를 기초로 데 이터 셋의 특성을 확인하는 방법을 도시한 흐름도이다. 도 12는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 셋의 특성을 확인하 는 일 예를 도시한 도면이다. 도 12의 잠재 공간은 설명의 편의를 위해 2차원 공간으로 도시하였으나, 실제로는 3차원 이상의 매니폴드 공간일 수 있다. 도 11을 참조하면, 컴퓨팅 장치는 데이터 셋을 기초로 포인트 데이터 셋을 획득할 수 있다(S1014). 이때, 상기 컴퓨팅 장치가 상기 포인트 데이터 셋을 획득하는 구체적인 방법은 상술한 기술적 특징(도 4 내지 도 9)이 그대 로 적용될 수 있으므로 생략하기로한다. 예를 들어, 도 12를 참조하면, 컴퓨팅 장치는 획득한 데이터 셋을 기초로 잠재 공간에서 정의된 포인트 데이터 셋을 획득할 수 있다. 이때, 상기 포인트 데이터 셋은 제1 포인트 데이터 및 제2 포 인트 데이터를 포함하는 복수의 포인트 데이터들을 포함할 수 있다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋에 포함된 각각의 포인트 데이터에 대한 특성 값(property value)을 계산할 수 있다(S1015). 이때, 특성 값은, 상기 컴퓨팅 장치가 데이터 셋의 특성을 획득하기 위하여 포인트 데 이터에 대하여 계산하는 값을 의미할 수 있다. 또한, 상기 특성 값은, 포인트 데이터 셋에 포함된 포인트 데이 터 사이의 거리를 기초로 계산될 수 있다. 예를 들어, 상기 특성 값은 특정 포인트 데이터를 중심으로 미리 정 해진 거리 이내에 존재하는 포인트 데이터의 수를 의미할 수 있으나, 이에 한정되지 않는다. 또한, 예를 들어, 상기 특성 값은 특정 포인트 데이터로부터 가까운 미리 정해진 개수의 포인트 데이터들까지의 거리의 평균 값을 의미할 수 있으나, 이에 한정되지 않는다. 또한, 다시 도 12를 참조하면, 컴퓨팅 장치는 상기 포인트 데이터 셋에 포함된 각각의 포인트 데이터들에 대하여 미리 정해진 방식에 따라 특성 값을 계산할 수 있다. 일 예로, 컴퓨팅 장치는 특정 포인트 데이터를 중심으로 미리 정해진 거리 이내의 영역(1210, 1220)에 위치하는 포인트 데이터의 개수를 기초로 특성 값을 계산할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 포인트 데이터(120 1)에 대하여 미리 정해진 거리 이내의 제1 영역에 위차하는 포인트 데이터의 개수(예를 들어, 7)를 상기 제1 포인트 데이터의 특성 값으로 결정할 수 있다. 또한, 컴퓨팅 장치는 제2 포인트 데이터에 대하 여 미리 정해진 거리 이내의 제2 영역에 위차하는 포인트 데이터의 개수(예를 들어, 1)를 상기 제2 포인 트 데이터의 특성 값으로 결정할 수 있다. 다른 예로, 컴퓨팅 장치는 특정 포인트 데이터에 근접한 미리 정해진 개수의 포인트 데이터들까지의 거리의 평 균 값을 기초로 특성 값을 계산할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 포인트 데이터로부터 근접한 K 개의 포인트 데이터들까지의 거리 값들을 기초로 평균 거리 값을 계산할 수 있고, 상기 계산된 평균 거리 값을 상기 제1 포인트 데이터의 특성 값으로 결정할 수 있으나, 이에 한정되지 않는다. 또 다른 예로, 컴퓨팅 장치는 상기 포인트 데이터 셋에 포함된 각각의 포인트 데이터들에 대하여 분류 (classification)된 클래스를 상기 포인트 데이터들의 특성 값으로 결정할 수 있다. 구체적으로, 컴퓨팅 장치가 획득한 데이터 셋이 주석(annotation) 정보를 포함하는 경우, 상기 컴퓨팅 장치는 상기 데이터 셋을 기초로 획 득한 포인트 데이터 셋에 포함된 각각의 포인트 데이터들의 클래스를 결정할 수 있다. 이 경우, 상기 컴 퓨팅 장치는 k-NN(k-nearest neighbors) 알고리즘을 기초로 특성 값들을 획득할 수 있으나, 이에 한정되지 않는 다. 또한, 다시 도 11을 참조하면, 컴퓨팅 장치는 상기 계산된 특성 값들을 기초로 상기 데이터 셋의 특성을 획득할 수 있다(S1016). 구체적으로, 컴퓨팅 장치는 상기 계산된 특성 값들을 기초로 상기 데이터 셋의 내재적 특성 또 는 태스크 의존적인 특성을 획득할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 포인트 데이터들 각각의 특성 값들을 기초로 데이터 셋의 밀도, 균일도, 또는 클래스의 분포 등을 획득할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 상기 포인트 데이터들 각각의 특성 값들의 분포를 기초로 데이터 셋의 특성을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 포인트 데이터들 각각의 특성 값들의 평균, 편차, 또는 분산 등의 통계 적 분포를 기초로 상기 데이터 셋의 특성을 획득할 수 있으나, 이에 한정되지 않는다. 예를 들어, 다시 도 12를 참조하면, 컴퓨팅 장치는 상기 포인트 데이터 셋에 포함된 포인트 데이터들 각 각의 특성 값들(예를 들어, 미리 정해진 거리 이내의 영역에 포함되는 포인트 데이터의 개수)의 평균을 상기 데 이터 셋의 특성으로 결정할 수 있다. 또한, 예를 들어, 상기 컴퓨팅 장치는 상기 포인트 데이터 셋에 포함된 포인트 데이터들 각각의 클래스들 의 통계적 분포를 상기 데이터 셋의 특성으로 결정할 수 있다. 도 13은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 셋의 특성을 확인하 는 방법을 도시한 흐름도이다. 도 14는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 셋의 특성을 확인하 는 일 예를 도시한 도면이다. 도 14의 잠재 공간은 설명의 편의를 위해 2차원 공간으로 도시하였으나, 실 제로는 3차원 이상의 매니폴드 공간일 수 있다. 도 13을 참조하면, 컴퓨팅 장치는 데이터 셋을 기초로 포인트 데이터 셋을 획득할 수 있다(S1017). 이때, 상기 컴퓨팅 장치가 상기 포인트 데이터 셋을 획득하는 구체적인 방법은 상술한 기술적 특징(도 4 내지 도 9)이 그대 로 적용될 수 있으므로 생략하기로한다. 예를 들어, 도 14를 참조하면, 컴퓨팅 장치는 획득한 데이터 셋을 기초로 잠재 공간에서 정의된 포인트 데이터 셋을 획득할 수 있다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋을 기초로 데이터 셋의 특성을 획득할 수 있다(S1018). 이때, 상기 컴퓨팅 장치는 미리 정해진 알고리즘에 따라 상기 포인트 데이터 셋을 처리함으로써 상기 데이터 셋의 특성을 획득할 수 있다. 예를 들어, 다시 도 14를 참조하면, 컴퓨팅 장치는 잠재 공간 상에 정의된 포인트 데이터 셋을 미 리 정해진 알고리즘에 따라 처리함으로써 데이터 셋의 특성을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 잠재 공간상에 정의된 포인트 데이터 셋을 미리 저장된 필터 를 기초로 처리하여 데이터 셋의 특성을 획득할 수 있다. 이때, 상기 미리 저장된 필터는 미리 정 해진 사이즈(예를 들어, 3*3 또는 5*5의 커널)의 필터일 수 있다. 또한, 상기 컴퓨팅 장치는 상기 미리 저장된 필터를 상기 잠재 공간 상에서 미리 정해진 경로 를 따라 적용할 수 있다. 또한, 컴퓨팅 장치는 상기 잠재 공간 전역에 따라 상기 미리 저장된 필터를 기초로 상기 포인트 데 이터 셋을 처리하여 상기 데이터 셋의 특성을 획득할 수 있다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋에서 상기 미리 저장된 필터가 적용된 위치의 포인트 데이터의 수가 카운팅되도록 상기 포인트 데이터 셋을 처리할 수 있다. 예를 들어, 컴퓨팅 장치는 상기 미리 저장된 필터가 적용된 영역에 포함된 포인트 데이터의 개수를 기초 로 데이터 셋의 특성을 획득할 수 있다. 또한, 컴퓨팅 장치는 상기 미리 저장된 필터를 미리 정해진 경로를 따라 이동시킴에 따라, 상기 미 리 저장된 필터가 적용된 영역에 포함된 포인트 데이터의 개수의 분포를 기초로 데이터 셋의 특성을 획득 할 수 있다. 또한, 컴퓨팅 장치는 상기 미리 저장된 필터가 상기 미리 정해진 경로에 따라 적용되는 경우, 상기 미리 저장된 필터의 이동 범위(또는 스트라이드, stride)를 결정할 수 있다. 이때, 상기 미리 저장된 필 터의 이동 범위는 미리 정해질 수 있으나, 이에 한정되지 않고, 임의로 조정될 수 있다. 예를 들어, 컴퓨팅 장치는 상기 미리 저장된 필터가 적용된 영역에 포함된 포인트 데이터의 개수들의 편 차 또는 분산(통계적 분포)를 기초로 데이터 셋의 균질도를 획득할 수 있다. 이 경우, 상기 데이터 셋의 균질도 는 컴퓨팅 장치에 미리 저장된 룩업 테이블을 기초로 특정 결과 값으로 나타날 수 있으나, 이에 한정되지 않는 다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋을 전처리하여 포인트 데이터가 존재하는 위치에 대한 정보를 획득할 수 있다. 이 경우, 상기 컴퓨팅 장치는 상기 잠재 공간에서 상기 포인트 데이터가 존재하는 위치 에 대응되는 영역에만 상기 미리 저장된 필터를 적용할 수 있다. 또한, 상기 컴퓨팅 장치는 상기 잠재 공간 상에서 상기 포인트 데이터가 존재하는 위치에 대응되는 영역 상에서 정의된 미리 정해진 경로를 따라 상기 미리 저장된 필터를 적용할 수 있다. 구체적인 예로, 상기 컴퓨팅 장치는 커널(kernel)에 기초한 컨볼루션 (convolution) 알고리즘을 이용하여 데이 터 셋의 특성과 관련된 특징 맵(feature map)을 획득할 수 있다. 도 15는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 컨볼루션 알고리즘을 이용하여 데이터 셋의 특성을 획 득하는 방법을 설명하기 위한 도면이다. 도 15를 참조하면, 컴퓨팅 장치는 상술한 포인트 데이터 셋(도 14의 도면 부호 1400 참조)을 복수의 고유 값들 로 정의된 포인트 이미지로 나타낼 수 있다. 이때, 상기 복수의 고유 값들은 상술한 잠재 공간(도 14의 도면 부호 1450 참조) 상의 각 위치에 포인트 데이터가 존재하는지 여부를 기초로 부여된 값일 수 있다. 예를 들어, 상기 포인트 데이터가 존재하는 위치를 1로, 상기 포인트 데이터가 존재하지 않는 위치를 0으로 표현함으 로써 상기 포인트 이미지를 확인할 수 있으나, 이에 한정되지 않는다. 또한, 상기 포인트 이미지의 크기(또는 차원)는 상술한 잠재 공간의 크기(또는 차원)에 대응될 수 있다. 도 15에서 상기 포인트 이미지는 설명의 편의를 위해 2차원 공간으로 도시하였으나, 실제로는 3차 원 이상의 이미지일 수 있다. 또한, 상기 컴퓨팅 장치는 상기 포인트 이미지를 상기 미리 저장된 커널(kernel, 1510)을 적용함으로써 처리하여 데이터 셋의 특성에 관련된 특징 맵(feature map, 1550)을 획득할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 포인트 이미지를 상기 미리 저장된 커널을 기초로 컨볼루션 (convolution)하여 출력 값 산출할 수 있고, 상기 산출된 출력 값들을 기초로 특징 맵을 획득할 수 있다. 이때, 상기 미리 저장된 커널은 데이터 셋의 분포를 판단하기 위해 설계될 수 있다. 구체적으로, 상기 미 리 저장된 커널을 입력된 포인트 이미지의 분포와 관련된 특징 맵을 출력하기 위해 설계된 커널일 수 있다. 이에 따라, 상기 특징 맵은 상기 데이터 셋의 특성에 관련될 수 있다. 예를 들어, 상기 데이터 셋의 특성 과 관련된 특징 맵은 데이터 셋의 분포, 밀도 또는 균질도를 나타내는 특징 맵일 수 있다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 데이터 셋을 획득하여 상기 데이터 셋이 개선되도록 상기 획득 한 데이터 셋을 처리할 수 있다. 여기서, 데이터 셋이 개선된다는 의미는 하술(도 25 내지 도 26)할 데이터 셋 의 등급(quality)이 향상되는 방법을 제공하는 것을 의미할 수 있고, 구체적으로, 데이터 셋을 딥러닝 모델 학 습에 보다 적합한 형태로 개선하는 방법을 제공하는 것을 의미할 수 있다. 예를 들어, 컴퓨팅 장치는 데이터 셋 의 분포를 보다 균일하게 하는 방법을 제공함으로써 데이터를 개선할 수 있으나, 이에 한정되지 않는다. 일 예로, 컴퓨팅 장치는 상술한 방법으로 획득한 데이터 셋의 특성을 기초로 데이터 셋을 개선할 수 있다. 도 16은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋을 개선하는 방법을 설명하기 위한 도면이다. 도 16을 참조하면, 컴퓨팅 장치는 획득된 데이터 셋을 기초로 포인트 데이터 셋을 확인할 수 있다(S1019). 이떄, 상기 컴퓨팅 장치가 데이터 셋을 획득하고 포인트 데이터 셋을 확인하는 구체적인 방법은 상술한 기술적 특징(도 4 내지 도 9)이 그대로 적용될 수 있으므로 생략하기로 한다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋을 기초로 데이터 셋의 특성을 확인할 수 있다(S1020). 이때, 상기 컴퓨팅 장치가 상기 데이터 셋의 특성을 확인하는 구체적인 방법은 상술한 기술적 특징(도 10 내지 도 15)이 그 대로 적용될 수 있으므로 생략하기로 한다. 또한, 컴퓨팅 장치는 상기 확인된 데이터 셋의 특성이 미리 정해진 기준에 부합하는지 여부를 확인할 수 있다 (S1021). 이때, 상기 미리 정해진 기준은 상기 데이터 셋이 개선할 필요가 있는지 여부에 관련될 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 포인트 데이터 셋을 기초로 확인된 데이터 셋의 분포가 미리 정해진 기준에 부 합하는지 여부를 확인할 수 있다. 또한, 컴퓨팅 장치는 상기 확인된 데이터 셋의 특성이 미리 정해진 기준에 부합하지 않는 경우, 데이터 셋의 특 성이 조정되도록 개선된 포인트 데이터 셋을 제공할 수 있다(S1022). 예를 들어, 상기 컴퓨팅 장치는 포인트 데 이터 셋에 포함되는 적어도 하나의 포인트 데이터를 조정하거나, 적어도 하나의 포인트 데이터를 삭제하거나, 또는 상기 포인트 데이터 셋에 적어도 하나의 포인트 데이터를 추가함으로써 상기 개선된 포인트 데이터 셋을 제공할 수 있으나, 이에 한정되지 않는다. 컴퓨팅 장치가 개선된 포인트 데이터 셋을 제공하는 구체적인 예시는 도 17 및 도 18을 통해 보다 자세하게 설 명한다. 도 17은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선된 포인트 데이터 셋을 생성하는 일 예시를 도시한 도면이다. 도 17의 잠재 공간은 설명의 편의를 위해 2차원 공간으로 도시하였으나, 실제로는 3차원 이상 의 매니폴드 공간일 수 있다. 도 17을 참조하면, 컴퓨팅 장치는 포인트 데이터 셋에 포함되는 적어도 하나의 포인트 데이터를 조정함으 로써 개선된 포인트 데이터 셋을 획득할 수 있다. 이때, 상기 컴퓨팅 장치는 상기 포인트 데이터 셋을 기초로 확인된 데이터 셋의 특성이 미리 정해진 기준 에 부합하는지 여부를 확인할 수 있다. 보다 구체적으로, 상기 컴퓨팅 장치는 상기 포인트 데이터 셋이 정의된 잠재 공간상의 적어도 둘 이상의 영역(1710, 1720)에 포함된 포인트 데이터들을 기초로 상기 데이 터 셋의 특성이 미리 정해진 기준에 부합하는지 여부를 확인할 수 있다. 이때, 상기 적어도 둘 이상의 영역 (1710, 1720)의 크기는 모두 동일할 수 있으나, 이에 한정되지 않고, 서로 상이할 수도 있다. 또한, 상기 적어 도 하나의 영역(1710, 1720)은 임의로 선택될 수 있으나, 이에 한정되지 않고, 고정된 위치로 미리 설정될 수도 있다. 또한, 상기 적어도 하나의 영역(1710, 1720)은 도 14 및 도 15의 필터 또는 커널이 적용되는 영역을 의미 할 수 있다. 예를 들어, 컴퓨팅 장치는 상기 잠재 공간 상의 제1 영역에 포함된 포인트 데이터의 수와 상기 잠 재 공간 상의 제2 영역에 포함된 포인트 데이터의 수의 차이가 미리 정해진 기준 이상인 경우, 상 기 포인트 데이터 셋에 포함되는 적어도 하나의 포인트 데이터를 조정할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 제1 영역에 포함된 포인트 데이터의 수(예를 들어, 9)와 상기 제2 영역 에 포함된 포인트 데이터의 수(예를 들어, 5)의 차이가 임계치 이상인 경우, 상기 포인트 데이터 셋 에 포함된 적어도 하나의 포인트 데이터를 조정(예를 들어, 잠재 공간 상의 위치를 조정)할 수 있다. 또한, 예를 들어, 컴퓨팅 장치는 상기 잠재 공간 상의 적어도 하나의 영역(1710, 1720)에 포함된 포인트 데이터의 수의 평균 값과 특정 영역에 포인트 데이터의 수의 차이가 임계치 이상인 경우, 상기 포인트 데이터 셋에 포함된 적어도 하나의 포인트 데이터를 조정할 수 있다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋에 포함되는 적어도 하나의 포인트 데이터의 잠재 공간 상의 위치를 조정함으로써 상기 개선된 포인트 데이터 셋을 획득할 수 있다. 예를 들어, 상기 컴퓨팅 장 치는 상기 제1 영역 상의 위치에 정의된 제1 포인트 및 제2 포인트를 상기 제2 영역 상 의 특정 위치로 조정함으로써 개선된 포인트 데이터 셋을 획득할 수 있다. 또한, 상기 컴퓨팅 장치는 미리 정해진 기준에 따라 잠재 공간 상에서 포인트가 조정될 위치를 결정할 수 있다. 보다 구체적으로, 컴퓨팅 장치는 상기 포인트 데이터 셋의 분포를 기초로 상기 제1 포인트 및 제2 포인트가 조정될 위치를 결정할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 제2 영역 상에서 포 인트가 균일하게 위치하도록 상기 제1 포인트 및 제2 포인트가 조정될 위치를 결정할 수 있다. 구 체적인 예로, 컴퓨팅 장치는 상기 제2 영역에 포함된 포인트 데이터들 중 서로 거리가 먼 적어도 두개의 포인트 데이터들의 중간 위치로 상기 제1 포인트 및 제2 포인트 중 적어도 하나를 이동시킬 수 있 으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋에서 상기 포인트 데이터 셋의 분포가 일정해지도록 조 정할 포인트 데이터의 수를 결정할 수 있다. 도 18은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선된 포인트 데이터 셋을 생성하는 다른 일 예시를 도시한 도면이다. 도 18의 잠재 공간은 설명의 편의를 위해 2차원 공간으로 도시하였으나, 실제로는 3차 원 이상의 매니폴드 공간일 수 있다. 도 18을 참조하면, 컴퓨팅 장치는 포인트 데이터 셋에 적어도 하나의 포인트 데이터를 추가함으로써 개선 된 포인트 데이터 셋을 획득할 수 있다. 이때, 상기 컴퓨팅 장치가 개선된 포인트 데이터 셋을 생성하기 위한 미리 정해진 기준은 도 17에 설명된 기술 적 특징이 그대로 적용될 수 있다. 예를 들어, 컴퓨팅 장치는 잠재 공간 상에서 포인트 데이터의 수가 미리 정해진 기준에 부합되지 않는 제 3 영역에 포인트 데이터를 추가함으로써 개선된 포인트 데이터 셋을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 제3 영역상의 임의의 위치에 제3 포인트 및 제4 포인트를 추가함으로써 개선된 포인트 데이터 셋을 획득할 수 있다. 또한, 상기 컴퓨팅 장치는 미리 정해진 기준에 따라 잠재 공간 상에서 포인트가 추가될 위치를 결정할 수 있다. 보다 구체적으로, 컴퓨팅 장치는 상기 포인트 데이터 셋의 분포를 기초로 상기 제3 포인트 및 제4 포인트가 추가될 위치를 결정할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 상기 제3 영역 상에서 포 인트가 균일하게 위치하도록 상기 제3 포인트 및 제4 포인트가 추가될 위치를 결정할 수 있다. 구 체적인 예로, 컴퓨팅 장치는 상기 제3 영역에 포함된 포인트 데이터들 중 서로 거리가 먼 적어도 두개의 포인트 데이터들의 중간 위치로 상기 제3 포인트 및 제4 포인트 중 적어도 하나를 추가할 수 있으 나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 상기 포인트 데이터 셋에서 추가할 포인트 데이터의 수는 상기 포인트 데이터 셋 의 분포가 일정해지도록 결정할 수 있다. 또한, 이에 한정되지 않고, 컴퓨팅 장치는 포인트 데이터 셋에 포함되는 포인트 데이터들 중 적어도 일부를 제 거함으로써 개선된 포인트 데이터 셋을 획득할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 데이터 셋을 기초로 포인트 데이터 셋에 포함되는 포인트 데이터들 중 미리 정해진 방식으로 결정된 적어도 하나의 포인트 데이터를 제거함으로써 개선된 포인트 데이터 셋을 획득할 수 있다. 예를 들어, 컴퓨팅 장치는 상기 포인트 데이터 셋에서 데이터가 과하게 밀집되어 있는 영역에 포함되어 있는 포 인트 데이터들 중 적어도 일부를 제거할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 포인트 데이터 셋이 정 의되는 매니폴드 영역 상에서, 미리 정해진 개수 이상의 포인트 데이터들이 포함된 영역을 선택할 수 있고, 상 기 선택된 영역에 포함된 적어도 하나의 포인트 데이터를 제거함으로써 개선된 포인트 데이터 셋을 획득할 수 있다. 상술한 바와 같이 컴퓨팅 장치는 포인트 데이터 셋(또는 매니폴드)를 기초로 판단된 데이터 셋의 특성을 딥러닝 모델의 학습에 적합한 방향으로 보정하기 위하여 포인트 데이터를 추가하거나, 조정하거나, 제거함으로써 데이 터 셋을 개선할 수 있다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 딥러닝 모델을 이용하여 상술한 데이터 개선 알고리즘을 수행할 수 있다. 본 명세서에서는 상기 데이터 개선 알고리즘을 수행하기 위한 딥러닝 모델을 \"개선 매니폴드 생성 모 델(Model for generating Modified Manifold)\"이라 한다. 도 19는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선 매니폴드 생성 모델을 학습시켜 개선된 데이터 이 미지를 제공하기 위한 방법을 설명하는 도면이다. 도 19를 참조하면, 컴퓨팅 장치는 개선 매니폴드 생성모델을 학습시킬 수 있다(S1023). 상기 개선 매니폴드 생 성 모델을 학습시키는 구체적인 방법은 도 20 내지 도 22에 대한 설명을 통해 자세히 설명한다. 또한, 컴퓨팅 장치는 획득된 데이터 셋을 기초로 포인트 데이터 셋을 확인할 수 있다(S1024). 이때, 상기 컴퓨 팅 장치가 상기 포인트 데이터 셋을 획득하는 구체적인 방법은 상술한 기술적 특징(도 4 내지 도 9)이 그대로 적용될 수 있으므로 생략하기로한다.또한, 컴퓨팅 장치는 상기 포인트 데이터 셋을 상기 개선 매니폴드 생성 모델에 입력함으로써 개선된 포인트 데 이터 셋을 확인할 수 있다(S1025). 구체적으로, 상기 컴퓨팅 장치는 상기 개선 매니폴드 생성 모델을 이용하여 상기 포인트 데이터 셋에 포함된 포인트 데이터들 사이의 거리 관계가 조정된 개선된 포인트 데이터 셋을 획득 할 수 있다. 또한, 컴퓨팅 장치는 상기 개선된 포인트 데이터 셋을 기초로 개선된 데이터 이미지를 제공할 수 있다(S1026). 상기 컴퓨팅 장치가 상기 개선된 포인트 데이터 셋을 기초로 개선된 데이터 이미지를 제공하는 구체적인 방법은 상술한 기술적 특징(도 4 내지 도 9)이 그대로 적용될 수 있으므로 생략하기로 한다. 도 20은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선 매니폴드 생성 모델을 학습하는 방법의 일 예시를 도시한 도면이다. 컴퓨팅 장치는 획득한 데이터 셋을 딥러닝 모델에 보다 적합한 형태로 개선하는 방법을 제공하기 위해 개 선 매니폴드 생성 모델을 학습시킬 수 있다. 도 20을 참조하면, 컴퓨팅 장치는 획득한 데이터 셋을 기초로 N차원의 임베딩 공간( )에서 정의되는 제 1 포인트 데이터 셋(P1)을 확인할 수 있다. 이때, 상기 제1 포인트 데이터 셋을 확인하는 구체적인 방법은 상술 한 기술적 특징(도 4 내지 도 9)이 그대로 적용될 수 있으므로 생략하기로 한다. 이때, 상기 제1 포인트 데이터 셋(P1)은 N차원의 제1 매니폴드 공간을 정의함으로써 확인될 수 있다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)을 기초로 제2 포인트 데이터 셋(P2)을 확인할 수 있 다. 이때, 상기 제2 포인트 데이터 셋(P2)은 L차원의 제2 매니폴드 공간을 정의함으로써 확인될 수 있다. 구체 적으로, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)을 L차원의 제2 임베딩 공간( )에 나타냄으 로써 상기 제2 포인트 데이터 셋(P2)을 획득할 수 있다. 또한, 상기 컴퓨팅 장치은 상기 제1 포인트 데이터 셋(P1)을 미리 정해진 조건에 따라 처리하여 상기 제2 포인트 데이터 셋(P2)을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 매핑 함수( )에 의해 정의된 미리 정해진 조건(예를 들어, 특정 차원의 임베딩 공간에 매핑하기 위해 미리 저장된 행렬(matrix))을 기초로 상기 제1 포인트 데이터 셋(P1)을 L차원의 제2 임베딩 공간( )에 매핑함으로써 상기 제2 포인트 데이터 셋(P2)을 획득할 수 있다. 예를 들어, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)을 인코딩함으로써 상기 제2 포인트 데이터 셋(P2)을 획득할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 상기 제2 포인트 데이터 셋(P2)을 기초로 개선된 제1 포인트 데이터 셋 (P`1)을 획 득할 수 있다. 이때, 상기 개선된 제1 포인트 데이터 셋 (P`1)은 상기 제1 포인트 데이터 셋(P1)과 동일한 N차 원의 제1 임베딩 공간 상에서 정의될 수 있다. 또한, 컴퓨팅 장치는 상기 제2 포인트 데이터 셋(P2)을 미리 정해진 조건에 따라 처리하여 상기 개선된 제1 포인트 데이터 셋 (P`1)을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 매핑 함수( )의 역함수( ) 로 정의된 미리 정해진 조건(예를 들어, 특정 차원의 임베딩 공간에 매핑하기 위해 미리 저장된 행렬(matrix)의 역행렬)을 기초로 상기 제2 포인트 데이터 셋(P2)을 N차원의 제1 임베딩 공간( )에 복원함으로써 상기 개선된 제1 포인트 데이터 셋 (P`1)을 획득할 수 있다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)에 포함된 포인트 데이터들 사이의 거리 관계가 조정 되도록 상기 개선된 제1 포인트 데이터 셋(P`1)을 획득할 수 있다. 다시 말해, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)에 포함된 포인트 데이터들의 거리 관계가 조정되도록 개선 매니폴드 생성 모델을 학 습시킬 수 있다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)의 분포가 개선되도록 상기 포인트 데이터들 사이의 거리 관계를 조정할 수 있다. 보다 구체적으로, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)에서, 포인트 데이터의 밀도가 높은 영역에 위치한 포인트 데이터를 포인트 데이터의 밀도가 낮은 영역으로 이동시킴으로써 상기 포인트 데이터들사이의 거리 관계를 조정할 수 있다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)에 포함된 포인트 데이터들의 거리를 기초로 정의된 손실 함수(loss function)를 기초로 상기 개선 매니폴드 생성 모델을 학습시킬 수 있다. 예를 들어, 컴퓨팅 장 치는 상기 제1 포인트 데이터 셋(P1)에 포함된 포인트 데이터들 중 거리 관계가 조정될 필요가 있는 적어 도 한쌍(pair)의 포인트 데이터들을 추출하도록 상기 개선 매니폴드 생성 모델을 학습시킬 수 있다. 또한, 예를 들어, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋(P1)에서 거리 관계가 조정될 필요가 있는 영역에 포인트 데이터를 추가(또는 합성)하도록 상기 개선 매니폴드 생성 모델을 학습시킬 수 있다. 도 21은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선 매니폴드 생성 모델을 학습하는 방법의 일 예시를 설명하기 위한 흐름도이다. 도 22는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 하드 네거티브 쌍을 추출함으로써 개선 매니폴드 생성 모델을 학습하는 방법을 도시한 도면이다. 도 22의 잠재 공간은 설명의 편의를 위해 2차원 공간으로 도시 하였으나, 실제로는 3차원 이상의 매니폴드 공간일 수 있다. 도 21을 참조하면, 컴퓨팅 장치는 제1 포인트 데이터 셋을 기초로 초기 클러스터링(initial clustering)을 수행 할 수 있다(S1027). 이때, 상기 초기 클러스터링이란, 상기 제1 포인트 데이터 셋에 포함되는 복수의 포인트 데 이터들을 적어도 하나 이상의 그룹으로 클러스터링하는 것을 의미한다. 구체적으로, 컴퓨팅 장치는 상기 제1 포 인트 데이터 셋에 포함되는 복수의 포인트 데이터들에 대하여, 상기 복수의 포인트 데이터들에 대응되는 데이터 들의 유사도를 기초로 상기 복수의 포인트 데이터들을 적어도 하나 이상의 그룹으로 클러스터링할 수 있다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋에 대한 유사도 정보를 기초로 초기 클러스터링을 수행할 수 있 다. 이때, 상기 컴퓨팅 장치는 상기 유사도 정보를 획득하기 위해, 외부로부터 상기 유사도 정보를 획득하거나, 상기 유사도 정보를 생성할 수 있다. 일 예로, 컴퓨팅 장치는 외부로부터 상기 제1 포인트 데이터 셋에 대한 유사도 정보를 수신할 수 있다. 구체적 으로, 상기 컴퓨팅 장치는 사용자로부터 상기 제1 포인트 데이터 셋에 포함되는 적어도 둘 이상의 포인트 데이 터들의 유사도에 대한 정보를 수신할 수 있다. 즉, 사용자는 상기 컴퓨팅 장치로부터 확인된 제1 포인트 데이터 셋에서 적어도 둘 이상의 포인트 데이터들이 유사한지 여부를 입력할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 외부로부터 수신된 데이터 셋에 대한 주석(annotation) 정보를 기초로 상기 제1 포인트 데이터 셋을 적어도 하 나 이상의 그룹으로 클러스터링할 수 있으나, 이에 한정되지 않는다. 다른 예로, 컴퓨팅 장치는 비지도 학습(unsupervised learning)을 통해 상기 제1 포인트 데이터 셋에 대한 유사 도 정보를 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋에 포함되는 포인트 데이터들 간의 유사도를 스스로 학습함으로써 상기 제1 포인트 데이터 셋을 적어도 하나 이상의 그룹으로 클러스터링할 수 있다. 또한, 상기 제1 포인트 데이터 셋에 대한 유사도 정보는 상기 제1 포인트 데이터 셋에 포함되는 포인 트 데이터들의 특성 값을 기초로 확인될 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 포인트 데이터들 사이 의 특성 값이 유사할수록 유사도가 높은 것으로 결정할 수 있다. 구체적인 예로, 도 22를 참조하면, 컴퓨팅 장치는 제1 포인트 데이터 셋을 기초로 초기 클러스터링을 수 행할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋을 제1 포인트 데이터를 포함하는 제1 그룹 및 제2 포인트 데이터를 포함하는 제2 그룹으로 클러스터링할 수 있다. 이때, 동일한 그룹에 포함되는 포인트 데이터들은 서로 유사한 특징(positive)을 가질 수 있다. 또한, 상기 제1 그룹에 포함 되는 포인트 데이터들 및 상기 제2 그룹에 포함되는 포인트 데이터들은 서로 상이한 특징(negative)을 가질 수 있다. 예를 들어, 동일한 그룹에 포함되는 포인트 데이터들은 특정 태스크(task)를 수행함에 있어서, 유사한 결 과를 도출할 수 있는 잠재 공간 상의 데이터일 수 있으나, 이에 한정되지 않는다. 도 22에서는, 상기 제1 그룹에 포함되는 포인트 데이터들을 원형 포인트로, 상기 제2 그룹에 포함되는 포인트 데이터들을 사각형 포인 트로 표현하였으나, 이는 예시적인 표현에 불과하고, 발명을 도면의 표현으로 한정하려는 것은 아니다. 본 개시에서, 서로 상이한 그룹에 클러스터링된 한 쌍의 포인트 데이터를 네거티브 쌍(negative pair)이라 정의 하고, 동일한 그룹에 클러스터링된 한 쌍의 포인트 데이터들을 포시티브 쌍(positive pair)이라 정의하기로 한 다. 또한, 다시 도 21을 참조하면, 컴퓨팅 장치는 상기 초기 클러스터링된 제1 포인트 데이터 셋을 기초로 하드 네 거티브 쌍을 추출(Hard negative pair mining)을 수행할 수 있다(S1028). 여기서, 상기 하드 네거티브 쌍(hard negative pair)은 상술한 네거티브 쌍들 중 서로의 거리가 가까워서 서로 구분하기 힘든 네거티브 쌍을 의미한 다. 구체적으로, 컴퓨팅 장치는 상기 클러스터링된 제1 포인트 데이터 셋의 거리 관계를 기초로 상기 하드 네거티브 쌍을 추출할 수 있다. 일 예로, 컴퓨팅 장치는 특정 포인트 데이터와 다른 그룹에 포함된 포인트 데이터들 중 상기 특정 포인트 데이 터로부터의 거리가 임계치 이하인 네거티브 포인트 데이터가 존재하는 경우, 상기 특정 포인트 데이터 및 상기 네거티브 포인트 데이터를 하드 네거티브 쌍으로 결정할 수 있다. 다른 예로, 컴퓨팅 장치는 특정 포인트 데이터에 대하여, 동일한 그룹에 포함된 포지티브 포인트 데이터에 비해 보다 다른 그룹에 포함된 네거티브 포인트 데이터가 더 가까운 거리에 위치한 경우, 상기 특정 포인트 데이터 및 상기 네거티브 포인트 데이터를 하드 네거티브 쌍으로 결정할 수 있다. 또한, 컴퓨팅 장치는 동일한 그룹임에도 불구하고 잠재 공간 상에서 서로 먼 거리에 위치하는 포지티브 쌍을 추 출할 수 있다. 일 예로, 컴퓨팅 장치는 특정 포인트 데이터와 동일한 그룹에 포함된 포인트 데이터들 중 상기 특정 포인트 데 이터로부터의 거리가 임계치 이상인 포지티브 포인트 데이터가 존재하는 경우, 상기 특정 포인트 데이터 및 상 기 포지티브 포인트 데이터를 포지티브 쌍으로 결정할 수 있다. 다른 예로, 컴퓨팅 장치는 특정 포인트 데이터에 대하여, 동일한 그룹에 포함된 포지티브 포인트 데이터에 비해 보다 다른 그룹에 포함된 네거티브 포인트 데이터가 더 가까운 거리에 위치한 경우, 상기 특정 포인트 데이터 및 상기 포지티브 포인트 데이터를 포지티브 쌍으로 결정할 수 있다. 구체적인 예로, 다시 도 22를 참조하면, 컴퓨팅 장치는 잠재 공간 상에 정의된 제1 포인트 데이터 셋 에 포함된 포인트 데이터들의 유사도 및 거리 관계를 기초로 하드 네거티브 쌍 및 포지티브 쌍을 추출할 수 있다. 구체적으로, 컴퓨팅 장치는 기준 포인트 데이터와 상이한 그룹에 포함되되, 하드 네거티브 쌍을 추출하기 위해 미리 정해진 거리 조건을 만족하는 제1 포인트 데이터를 확인함으로써 상기 기준 포인트 데이터 및 상기 제1 포인트 데이터를 하드 네거티브 쌍으로 결정할 수 있다. 또한, 컴퓨팅 장치는 상기 기준 포인트 데이터와 상이한 그룹에 포함되되, 포지티브 쌍을 추출하기 위해 미리 정해진 거리 조 건을 만족하는 제2 포인트 데이터를 확인함으로써 상기 기준 포인트 데이터 및 상기 제2 포인트 데 이터를 포지티브 쌍으로 결정할 수 있다. 또한, 다시 도 21을 참조하면, 컴퓨팅 장치는 상기 추출된 하드 네거티브 쌍 사이의 거리를 조정함으로써 개선 된 제1 포인트 데이터 셋을 획득할 수 있다(S1029). 구체적으로, 컴퓨팅 장치는 상기 컴퓨팅 장치는 상기 하드 네거티브 쌍이 이지 네거티브 쌍(easy negative pair)이 되도록 상기 제1 포인트 데이터 셋에 포함되는 적어도 하나의 포인트 데이터의 잠재 공간 상의 위치를 조정할 수 있다. 이때, 상기 이지 네거티브 쌍은 상술한 네거티 브 쌍들 중 서로의 거리가 멀어서 서로 구분하기 쉬운 네거티브 쌍을 의미한다. 또한, 컴퓨팅 장치는 상기 추출된 포지티브 쌍 사이의 거리를 조정함으로써 개선된 제1 포인트 데이터 셋을 획 득할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 포지티브 쌍 사이의 거리가 미리 정해진 거리보다 작아지도록 상기 제1 포인트 데이터 셋에 포함되는 적어도 하나의 포인트 데이터의 잠재 공간 상의 위치를 조정할 수 있다. 구체적인 예로, 다시 도 22를 참조하면, 컴퓨팅 장치는 상기 기준 포인트 데이터에 대하여 하드 네거티브 쌍으로 확인된 상기 제1 포인트 데이터의 잠재 공간 상의 위치를 조정함으로써 개선된 제1 포인트 데이터 셋을 획득할 수 있다. 또한, 컴퓨팅 장치는 상기 기준 포인트 데이터에 대하여 포지티브 쌍으로 확인된 상기 제2 포인트 데이터 의 잠재 공간 상의 위치를 조정함으로써 개선된 제1 포인트 데이터 셋을 획득할 수 있다. 또한, 이에 한정되지 않고, 도 21의 단계 S1028 및 S1029는 아래의 동작(들)으로 대체될 수 있다. 예를 들어, 컴퓨팅 장치는 초기 클러스터링된 제1 포인트 데이터 셋에 적어도 하나의 포인트 데이터를 추가함으 로써 개선된 제1 포인트 데이터 셋을 획득할 수 있다. 이 경우, 상기 컴퓨팅 장치는 상기 적어도 하나의 포인트 데이터를 추가함으로써 상기 제1 포인트 데이터 셋에 포함된 포인트 데이터들 사이의 거리 관계를 조정할 수 있 다. 구체적인 예로, 컴퓨팅 장치는 초기 클러스터링된 제1 포인트 데이터 셋을 기초로 거리 관계를 조정할 필요가 있는 관심 영역을 결정할 수 있다. 이때, 상기 관심 영역은 상술한 하드 네거티브 쌍을 포함하는 영역일 수 있 다. 이 경우, 컴퓨팅 장치는 상기 관심 영역의 적어도 일부분에 적어도 하나의 포인트 데이터를 생성함으로써 상기 관심 영역 및 상기 관심 영역 주변에 위치하는 포인트 데이터들 사이의 거리 관계를 조정할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 하드 네거티브 쌍이 포함된 관심 영역 상에, 상기 하드 네거티브 쌍 사이의 영역에 적어도 하나의 포인트 데이터를 생성함으로써, 상기 하드 네거티브 쌍 사이의 거리가 멀어지도록 조정할 수 있 다. 도 23은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋을 기초로 가상 데이터를 포함하는 개선 데이 터 셋을 제공하는 동작을 도시한 도면이다. 도 24는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋을 기초로 가상 데이터를 포함하는 개선 데이 터 셋을 제공하는 동작의 일 예시를 도시한 도면이다. 도 23을 참조하면, 컴퓨팅 장치는 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인할 수 있다(S1030). 또한, 컴퓨팅 장치는 상기 확인된 포인트 데이터 셋을 기초로 개선된 포인트 데이터 셋을 확인할 수 있다 (S1031). 이때, 상기 동작 S1030 및 동작 S1031은 상술한 기술적 특징(도 16 내지 도 22)이 그대로 적용될 수 있으므로 자세한 설명은 생략한다. 구체적인 예로, 도 24를 참조하면, 컴퓨팅 장치는 획득한 데이터 셋을 기초로 포인트 데이터 셋 을 확인할 수 있다. 이때, 상기 컴퓨팅 장치는 미리 정해진 매핑 함수( )를 기초로 상기 데이터 셋 을 잠재 공간(latent space)로 매핑함으로써 상기 포인트 데이터 셋을 획득할 수 있다. 이때, 상기 포인트 데이터 셋은 제1 포인트 데이터 및 제2 포인트 데이터를 포함할 수 있다. 예를 들어, 상기 제1 포인트 데이터 및 상기 제2 포인트 데이터는 서로 상이한 그룹으로 클러스터링된 데이터 일 수 있으나, 이에 한정되지 않고, 클러스터링되지 않았거나 동일한 그룹으로 클러스터링된 데이터일 수도 있 다. 또한, 컴퓨팅 장치 상기 포인트 데이터 셋을 기초로 개선된 포인트 데이터 셋을 획득할 수 있다. 이때, 상기 컴퓨팅 장치는 미리 저장된 개선 알고리즘을 기초로 상기 포인트 데이터 셋을 처 리함으로써 상기 개선된 포인트 데이터 셋을 획득할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상 기 포인트 데이터 셋을 미리 정해진 조건에 따라 또 다른 잠재 공간에 매핑한 후 이를 잠재 공간에 다시 복원함으로써 상기 개선된 포인트 데이터 셋을 획득할 수 있다. 또한, 상기 개선된 포인트 데이터 셋 은 개선된 제1 포인트 데이터(modified first point data, 2421) 및 개선된 제2 포인트 데이터를 포함할 수 있다. 예를 들어, 상기 개선된 제1 포인트 데이터는 상기 제1 포인트 데이터의 잠재 공 간 상의 위치를 조정함으로써 획득할 수 있고, 상기 개선된 제2 포인트 데이터는 상기 제2 포인트 데이터 의 잠재 공간 상의 위치를 조정함으로써 획득할 수 있다. 즉, 상기 제1 포인트 데이터는 상기 개선 된 제1 포인트 데이터에 대응될 수 있고, 상기 제2 포인트 데이터는 상기 개선된 제2 포인트 데이 터에 대응될 수 있다. 또한, 상기 개선된 포인트 데이터 셋은 제3 포인트 데이터를 더 포함 할 수 있다. 이때, 상기 제3 포인트 데이터는 상기 포인트 데이터 셋에는 포함되지 않는 포인트 데 이터일 수 있다. 다시 말해, 상기 컴퓨팅 장치는 상기 개선 알고리즘을 기초로 임의의 제3 포인트 데이터를 생성할 수 있다. 즉, 상기 포인트 데이터 셋은 상기 제3 포인트 데이터에 대응되는 포인트 데이터를 포함하지 않을 수 있다. 또한, 다시 도 23을 참조하면, 컴퓨팅 장치는 상기 개선된 포인트 데이터 셋을 기초로 가상 데이터(synthetic data)를 획득할 수 있다(S1032). 이때, 상기 가상 데이터는 컴퓨팅 장치가 미리 정해진 알고리즘에 따라 임의로생성한 데이터를 의미할 수 있다. 구체적으로, 상기 가상 데이터는 상기 획득한 데이터 셋과 동일한 모달리티 (modality)를 가지는 데이터이지만, 상기 데이터 셋에는 포함되어 있지 않은 데이터를 의미할 수 있다. 보다 구 체적으로, 상기 컴퓨팅 장치는 상기 개선된 포인트 데이터 셋을 미리 정해진 알고리즘을 기초로 처리하여 상기 가상 데이터를 생성할 수 있다. 또한, 컴퓨팅 장치는 상기 가상 데이터를 포함하는 개선 데이터 셋(modified data set)을 제공할 수 있다 (S1033). 이때, 상기 개선 데이터 셋은 상기 데이터 셋에는 포함되지 않는 적어도 하나의 데이터를 포함할 수 있다. 구체적인 예로, 다시 도 24를 참조하면, 컴퓨팅 장치는 상기 개선된 포인트 데이터 셋을 기초로 개 선 데이터 셋을 제공할 수 있다. 이때, 상기 컴퓨팅 장치는 상기 개선 데이터 셋을 기초로 적어도 하나의 가상 데이터를 생성함으로써 상기 적어도 하나의 가상 데이터를 포함하는 개선 데이터 셋 을 제공할 수 있다. 또한, 상기 컴퓨팅 장치는 상기 포인트 데이터 셋을 획득하기 위해 이용한 매핑 함수의 역함수 ( )를 이용하여 상기 개선된 포인트 데이터 셋을 아웃풋 도메인으로 복원함으로써 상기 개선 데이터 셋 을 제공할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 개선된 포인트 데이터 셋에 포함된 포 인트 데이터를 복원함으로써 가상 데이터를 획득할 수 있고, 상기 가상 데이터를 포함하는 개선된 데이터 셋 을 제공할 수 있다. 또한, 상기 개선 데이터 셋에 포함되는 각각의 데이터는 상기 개선된 포인트 데이터 셋에 포함되는 각각의 포인트 데이터에 대응될 수 있다. 예를 들어, 컴퓨팅 장치는 상기 개선된 제1 포인트 데이터 를 기초로 제1 가상 데이터 획득하고, 상기 개선된 제2 포인트 데이터를 기초로 제2 가상 데 이터 획득하고, 상기 제3 포인트 데이터를 기초로 제3 가상 데이터를 획득할 수 있다. 즉, 상기 제1 가상 데이터는 상기 개선된 제1 포인트 데이터에 대응되고, 상기 제2 가상 데이터 는 상기 개선된 제2 포인트 데이터에 대응되고, 상기 제3 가상 데이터는 상기 제3 포인트 데이터 에 대응될 수 있다. 또한, 상기 개선된 데이터 셋은 상기 데이터 셋에 포함되지 않는 적어도 하나의 데이터가 포함될 수 있다. 또한, 상기 개선된 데이터 셋은 상기 데이터 셋에 포함되는 적어도 하나의 데이터가 포함 되지 않을 수 있다. 또한, 상기 개선된 데이터 셋에 포함된 데이터의 수는 상기 데이터 셋에 포함 된 데이터의 수보다 크거나 같을 수 있다. 상술한 바와 같이, 컴퓨팅 장치는 데이터 개선에 기초한 뉴럴 렌더링(neural rendering) 방식으로 가상 데이터 를 생성할 수 있으나, 이에 한정되는 것은 아니다. 다양한 실시예에 따른 컴퓨팅 장치는 상기 데이터 개선에 기초하여, CG 기반 렌더링 방식으로 가상 데이터를 생 성할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 생성된 개선된 포인트 데이터 셋을 기초로 CG 파라미터를 생성 함으로써 가상 데이터를 생성할 수 있다. 보다 구체적으로, 컴퓨팅 장치는 상기 개선된 포인트 데이터 셋에 포 함된 적어도 하나의 포인트 데이터를 기초로 렌더링 파라미터(rendering parameter)를 획득함으로써 가상 데이 터를 생성할 수 있다. 예를 들어, 컴퓨팅 장치는 매핑 함수의 역함수( )를 CG 렌더링 모델로 구현함으로써 상 기 가상 데이터를 생성할 수 있으나, 이에 한정되지 않는다. 도 25는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 획득한 데이터 셋의 등급을 제공하는 동작을 도시한 도 면이다. 도 25를 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S1034). 또한, 컴퓨팅 장치는 상기 획득한 데이 터 셋을 기초로 데이터 이미지를 획득할 수 있다(S1035). 이때, 상기 동작 S1035는 상술한 기술적 특징(도 4 내 지 도 9)이 그대로 적용될 수 있으므로 자세한 설명은 생략하기로 한다. 또한, 컴퓨팅 장치는 상기 데이터 셋을 기초로 데이터 셋의 특성을 획득할 수 있다(S1036). 이때, 상기 동작 S1036은 상술한 기술적 특징(도 10 내지도 15)이 그대로 적용될 수 있으므로 생략하기로 한다. 또한, 컴퓨팅 장치는 상기 데이터 이미지 및 상기 데이터 셋의 특성 중 적어도 하나를 기초로 데이터 셋의 등급 (quality)을 제공할 수 있다(S1037). 구체적으로, 상기 컴퓨팅 장치는 상기 데이터 이미지 및 상기 데이터 셋의 특성 중 적어도 하나를 기초로 적어도 하나의 지표를 획득할 수 있고, 상기 적어도 하나의 지표를 기초로 상기 데이터 셋의 등급을 제공할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 데이터 셋의 '분포의 적절성', '학습 적합 도', '데이터 간의 유사도' 또는 '데이터 개수의 적절성' 등을 포함하는 지표를 기초로 상기 데이터 셋의 등급 을 제공할 수 있다. 이때, 상기 컴퓨팅 장치는 상기 적어도 하나의 지표를 다양한 점수(grade)로 평가할 수 있 고, 각각의 지표에 부여된 점수들을 기초로 상기 데이터 셋에 대한 최종 등급(quality)를 제공할 수 있다. 일 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지 또는 상기 데이터 셋의 특성을 기초로 '분포의 적절성'을 평 가할 수 있다. 이때, 상기 '분포의 적절성'은 데이터 셋의 분포가 얼마나 균일한지 여부를 의미할 수 있다. 보 다 구체적으로, 상기 컴퓨팅 장치는 상기 데이터 이미지 상에 나타나는 데이터 분포의 균일도 또는 상기 데이터 셋의 특성에 포함되는 데이터 셋의 밀도(또는 균일도)를 기초로 '분포의 적절성'을 평가할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 데이터의 분포가 균일한 경우, 상기 데이터 셋의 '분포의 적절성'에 대한 점수(grade)를 ' 좋음(Great)'으로 평가할 수 있으나, 이에 한정되지 않는다. 다른 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지 또는 상기 데이터 셋의 특성을 기초로 '학습의 적합도'를 평가할 수 있다. 이때, 상기 '학습의 적합도'는 데이터 셋이 특정 딥러닝 모델의 학습시키는 데에 얼마나 적합 한지 여부를 의미할 수 있다. 보다 구체적으로, 상기 컴퓨팅 장치는 상기 데이터 셋의 특성에 포함되는 태스크 의존적 특성을 기초로 '학습의 적합도'를 평가할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 데이터 셋이 이미지 분류 모델의 학습에 적합한지 여부를 상기 데이터 셋이 분류되어야 하는 클래스에 대응되는 데이터를 얼마나 균 일하게 포함하는 지 여부를 판단함으로써 평가할 수 있으나, 이에 한정되지 않는다. 또 다른 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지 또는 상기 데이터 셋의 특성을 기초로 '데이터 간의 유 사도'를 평가할 수 있다. 이때, 상기 '데이터 간의 유사도'는 상기 데이터 셋에 포함된 데이터가 얼마나 유사한 지 여부를 의미할 수 있다. 보다 구체적으로, 상기 컴퓨팅 장치는 상기 데이터 셋에 포함된 데이터 사이의 잠재 공간 상에서의 거리를 기초로 '데이터 간의 유사도'를 평가할 수 있다. 또 다른 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지 또는 상기 데이터 셋의 특성을 기초로 '데이터 개수의 적절성'을 평가할 수 있다. 보다 구체적으로, 상기 컴퓨팅 장치는 상기 데이터 셋이 딥러닝 모델을 학습시키기 에 적절한 수의 데이터를 포함하고 있는지 여부를 평가할 수 있다. 도 26은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 획득한 데이터 셋의 달성 가능 등급을 제공하는 동작을 도시한 도면이다. 도 26을 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S1038). 또한, 컴퓨팅 장치는 상기 획득한 데이 터 셋을 기초로 개선된 데이터 이미지를 획득할 수 있다(S1039). 이때, 상기 동작 S1039는 상술한 기술적 특징 (도 16 내지 도 22)이 그대로 적용될 수 있으므로 자세한 설명은 생략하기로 한다. 또한, 선택적으로, 상기 컴 퓨팅 장치는 상기 데이터 셋을 기초로 개선된 데이터 셋을 획득할 수 있다(S1040). 이때, 상기 동작 S1040는 상 술한 기술적 특징(도 23 내지 도 24)이 그대로 적용될 수 있으므로 자세한 설명은 생략하기로 한다. 또한, 컴퓨 팅 장치는 상기 데이터 셋을 기초로 개선된 데이터 셋의 특성을 획득할 수 있다(S1041). 이때, 상기 동작 S1041 은 상술한 기술적 특징(도 10 내지 도 15)이 그대로 적용될 수 있으므로 생략하기로 한다. 또한, 컴퓨팅 장치는 상기 데이터 이미지 및 상기 데이터 셋의 특성 중 적어도 하나를 기초로 데이터 셋의 등급(quality)을 제공할 수 있다(S1042). 이때, 상기 컴퓨팅 장치가 제공하는 데이터 셋의 달성 가능 등급은, 데이터가 개선된 경우 상 술한 동작 S1037에 따라 등급을 제공하는 방법이 그대로 적용될 수 있다. 본 개시의 다양한 실시예에 따른 컴퓨팅 장치는 데이터 셋을 처리하여 획득한 데이터 셋과 관련된 다양한 정보 들(예를 들어, 데이터 이미지, 특성, 개선된 데이터 이미지, 데이터 셋의 등급 등)을 기초로 진단 레포트를 제 공할 수 있다. 구체적으로, 컴퓨팅 장치는 진단 레포트를 통해, 데이터 셋에 대한 종합적인 진단 결과를 제공할 수 있다. 이 경우, 상기 컴퓨팅 장치는 상기 컴퓨팅 장치에 포함되는 출력 장치(예를 들어, 디스플레이) 또는 상기 컴퓨팅 장치와 통신 가능한 디바이스의 출력 장치를 통해 상기 진단 레포트를 출력할 수 있다. 예를 들어, 상기 출력 장치가 디스플레이인 경우, 상기 컴퓨팅 장치는 상기 진단 레포트를 상기 디스플레이 화면에 출력할수 있다. 또한, 예를 들어, 상기 출력 장치가 VR 기기인 경우, 상기 컴퓨팅 장치는 상기 진단 레포트를 상기 VR 기기에 의해 송출되는 가상의 공간에 상기 진단 레포트를 출력할 수 있다. 도 27은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 제공하는 진단 레포트에 포함된 정보들을 도시한 도면 이다. 도 28은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 제공하는 데이터 이미지에 대한 정보의 일 예시를 도시 한 도면이다. 도 27을 참조하면, 컴퓨팅 장치가 제공하는 진단 레포트는 데이터 셋에 대한 다양한 정보들을 포함할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 데이터 이미지에 대한 정보, 데이터 특성에 대한 정보, 데이터 개선에 대한 정 보 및 데이터 등급에 대한 정보를 포함하는 진단 레포트를 제공할 수 있다. 이때, 상기 데이터 이미지에 대한 정보는 상기 데이터 셋에 대한 데이터 이미지 및 상기 데이터 셋에 대한 개선 된 데이터 이미지를 포함할 수 있다. 또한, 컴퓨팅 장치는 상기 데이터 이미지 및 상기 개선된 데이터 이미지에 관련된 추가 정보를 더 포함하는 진단 레포트를 제공할 수 있다. 구체적인 예로, 도 28을 참조하면, 컴퓨팅 장치가 제공하는 진단 레포트는 이미징 공간에 나타나는 데이 터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD)를 포함하는 데이터 이미지에 대한 정보를 포함할 수 있다. 이 때, 상기 데이터 이미지(IOD)는 데이터 셋이 존재하는 매니폴드를 찾아냄으로써 확인한 포인트 데이터 셋(281 0)을 포함할 수 있다. 이 경우, 상기 컴퓨팅 장치는 도 8에 대한 설명에 따라 상기 포인트 데이터 셋의 노이즈를 제거하여 상기 데이터 이미지(IOD)를 제공할 수 있다. 또한, 상기 개선된 데이터 이미지(MIOD)는 상기 포인트 데이터 셋을 개선 알고리즘을 처리하여 획득한 개선된 포인트 데이터 셋을 포함할 수 있다. 이 경 우, 상기 컴퓨팅 장치는 도 8에 대한 설명에 따라 상기 개선된 포인트 데이터 셋의 노이즈를 제거하여 상 기 개선된 데이터 이미지(MIOD)를 제공할 수 있다. 또한, 컴퓨팅 장치가 제공하는 진단 레포트는 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD)와 관 련된 추가 정보를 포함할 수 있다. 보다 구체적으로, 컴퓨팅 장치는 데이터 셋을 처리하여 상기 데이터 셋이 존 재하는 매니폴드를 찾아냄으로써 포인트 데이터 셋을 확인할 수 있고, 상기 포인트 데이터 셋을 기초로 데이터 셋에 대한 다양한 추가 정보들을 획득할 수 있다. 또한, 컴퓨팅 장치는 상술한 바와 같이 획득한 다양한 추가 정보들을 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD)와 함께 제공할 수 있다. 컴퓨팅 장치는 마커 정보를 제공할 수 있다. 이때, 상기 마커 정보는 상기 데이터 이미지(IOD) 또는 개선된 데 이터 이미지(MIOD)에서 미리 정해진 기준에 따라 특정된 영역에 대한 마커를 포함할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD)에서 상기 미리 정 해진 기준을 만족하는 특정 영역을 선택하여, 상기 특정 영역에 대응되는 영역에 마커를 생성할 수 있다. 이 경 우, 상기 컴퓨팅 장치는 데이터 셋의 특성이 상기 미리 정해진 기준을 만족하는지 여부를 확인함으로써 상기 특 정 영역을 선택할 수 있다. 일 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD)에서 데이터가 비어있 는 공백 영역에 대응되는 마커를 생성함으로써 상기 마커 정보를 제공할 수 있다. 구체적인 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지(IOD)에 포함되는 포인트 데이터 셋의 공백 영역에 대한 마커를 생성함 으로써 마커 정보를 제공할 수 있다. 다른 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD)에서 데이터가 밀집 해있는 밀집 영역에 대응되는 마커를 생성함으로써 상기 마커 정보를 제공할 수 있다. 또 다른 예로, 상기 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD)에서 데이터의 분 포가 특이한 특이 영역에 대응되는 마커를 생성함으로써 상기 마커 정보를 제공할 수 있다. 이때, 상기 컴퓨팅 장치는 미리 정해진 알고리즘을 기초로 상기 포인트 데이터 셋 또는 개선된 포인트 데 이터 셋에서 마커를 생성할 영역을 판단할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 미리 저장된 커널을 기초로 컨볼루션 연산을 통해 포인트 데이터의 존재 위치에 대한 특징 맵을 획득할 수 있고(도 15에 대한 설명 참조), 상기 특징 맵을 기초로 상술한 공백 영역, 밀집 영역, 또는 특이 영역을 판단할 수 있다. 또한, 컴퓨팅 장치는 외부로부터 수신한 입력을 기초로 적어도 하나의 마커를 생성함으로써 상기 마커 정보를 제공할 수 있다. 구체적으로, 상기 컴퓨팅 장치가 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD) 상의 특정 영역에 대한 마커 생성 입력을 수신한 경우, 상기 특정 영역에 마커를 생성할 수 있다. 또한, 컴퓨팅 장치는 외부로부터 적어도 하나의 마커를 선택하는 입력을 수신한 경우, 상기 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 개선된 데이터 이미지(MIOD) 상에서 상기 적어도 하나의 마커에 대응되는 영역에서의 포인트 데이터들의 분포를 확대하여 나타내는 확대 이미지 정보를 제공할 수 있다. 예를 들어, 상기 컴퓨팅 장 치가 사용자로부터 제1 마커를 선택하는 입력을 수신한 경우, 상기 컴퓨팅 장치는 상기 제1 마커에 대응되는 영역에서의 포인트 데이터들의 분포를 확대하여 제1 확대 이미지를 제공할 수 있으나, 이에 한 정되지 않는다. 또한, 실시예에 따라, 컴퓨팅 장치는 외부로부터 개선된 이미지 데이터(MIOD)에 생성된 적어도 하나의 마커를 선택하는 입력을 수신한 경우, 상기 컴퓨팅 장치는 상기 개선된 데이터 이미지(MIOD) 상에서 상기 적어도 하나 의 마커에 대응되는 영역에서의 포인트 데이터들의 분포를 확대하여 나타내는 확대 이미지 정보뿐만 아니라 데 이터 이미지(IOD) 상에서 상기 적어도 하나의 마커에 대응되는 영역과 동일한 영역에서의 포인트 데이터들의 분 포를 확대하여 나타내는 확대 이미지 정보를 함께 제공할 수 있다. 예를 들어, 상기 컴퓨팅 장치가 사용자로부 터 제2 마커를 선택하는 입력을 수신한 경우, 상기 컴퓨팅 장치는 상기 제2 마커에 대응되는 영역 에서의 포인트 데이터들의 분포를 확대한 제2 확대 이미지 및 상기 데이터 이미지(IOD)에서 상기 영역과 동일한 영역(예를 들어, 상기 제1 마커가 표시된 영역)에 대한 제1 확대 이미지를 함께 제공할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 상기 개선된 데이터 이미지(MIOD)의 매니폴드 경계를 표시 함으로써 매니폴드 경계 정보를 제공할 수 있다. 구체적으로, 상기 컴퓨팅 장치는 상기 데이터 셋을 기초 로 확인된 포인트 데이터 셋이 형성되는 매니폴드의 경계 영역을 표시함으로써 상기 매니폴드 경계 정보 를 제공할 수 있다. 또한, 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 상기 개선된 데이터 이미지(MIOD)에 그룹핑 정보(미도시)를 제공할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 포인트 데이터 셋 또는 개선된 포인트 데이터 셋(285 0)에 포함된 포인트 데이터들이 적어도 하나 이상의 그룹으로 클러스터링된 경우, 상기 클러스터링된 포인트 데 이터들을 나타내는 표시를 추가함으로써 상기 그룹핑 정보를 제공할 수 있다. 또한, 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 상기 개선된 데이터 이미지(MIOD)에 시각적 효과를 부가할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 상기 개선된 데이터 이미지(MIOD)의 시각적 효과를 증진시키기 위해, 상기 포인트 데이터 셋 또는 개선된 포인트 데이터 셋에 포함되는 포인트 데이터들을 미리 정해진 색상 또는 모양을 이용하여 나타낼 수 있다. 예를 들어, 컴퓨팅 장치는 데이터 셋의 밀 도를 나타내기 위하여 데이터의 밀집 영역에 포함되는 포인트 데이터들의 색상을 다른 포인트 데이터들의 색상 과 상이하게 나타낼 수 있으나, 이에 한정되지 않는다. 또한, 예를 들어, 컴퓨팅 장치는 서로 상이한 그룹으로 클러스터링된 포인트 데이터들을 상이한 모양을 이용하여 나타낼 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 상기 데이터 이미지(IOD) 또는 상기 개선된 데이터 이미지(MIOD)의 차이를 나타내는 비교 정보(미도시)를 제공할 수 있다. 구체적으로, 컴퓨팅 장치는 데이터 셋을 개선함으로써 기존의 데이터 이미지 (IOD)와 대비하여 개선된 데이터 이미지(MIOD)에서 달라진 부분을 표시할 수 있다. 예를 들어, 컴퓨팅 장치는 상기 포인트 데이터 셋을 기초로 개선된 포인트 데이터 셋을 생성함에 따라, 상기 포인트 데이터 셋을 기초로 개선된 포인트 데이터 셋 상에서 포인트 데이터의 분포가 달라진 영역을 표시할 수 있 으나, 이에 한정되지 않는다. 다시 도 27을 참조하면, 컴퓨팅 장치는 데이터 특성에 대한 정보를 포함하는 진단 레포트를 제공할 수 있다. 이 때, 상기 데이터 특성에 대한 정보는 획득한 데이터 셋의 특성 및 개선된 데이터 셋의 특성을 포함할 수 있으나, 이에 한정되지 않고, 상기 데이터 셋의 특성 및 개선된 데이터 셋의 특성을 기초로 획득 가능한 추가 정보를 더 포함할 수 있다. 또한, 컴퓨팅 장치는 데이터 개선에 대한 정보를 포함하는 진단 레포트를 제공할 수 있다. 이때, 상기 데이터 개선에 대한 정보는 개선된 데이터 셋을 포함할 수 있으나, 이에 한정되지 않고, 상기 개선된 데이터 셋을 기초 로 획득 가능한 추가 정보를 더 포함할 수 있다. 예를 들어, 상기 데이터 개선에 대한 정보는, 상기 개선된 데이터 셋에 포함되는 개선된 포인트 데이터를 기초로 생성된 가상 데이터를 포함할 수 있다. 또한, 예를 들어, 상기 데이터 개선에 대한 정보는, 상기 가상 데이터 중 일부를 추출하여 획득되는 샘플 정보를 포함할 수 있다. 또한, 컴퓨팅 장치는 데이터 등급에 대한 정보를 포함하는 진단 레포트를 제공할 수 있다. 이때, 상기 데이터 등급에 대한 정보는 획득한 데이터 셋의 등급 및 데이터 셋의 달성 가능한 등급을 포함할 수 있으나, 이에 한정 되지 않고, 데이터 셋의 등급 및 데이터 셋의 달성 가능한 등급을 기초로 획득 가능한 추가 정보를 더 포함할 수 있다. 도 29는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋의 데이터 이미지 및 개선된 데이터 이미지를 제공하는 동작을 설명하기 위한 도면이다. 도 29를 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S1043). 또한, 컴퓨팅 장치는 상기 획득된 데이 터 셋을 제1 임베딩 공간에 매핑함으로써 제1 포인트 데이터 셋을 확인할 수 있다(S1044). 이때, 상기 S1043 동 작 및 S1044 동작은 상술한 기술적 특징(도 4 내지 도 9)이 그대로 적용될 수 있으므로 자세한 설명은 생략하도 록 한다. 또한, 컴퓨팅 장치는 상기 확인된 제1 포인트 데이터 셋을 제2 임베딩 공간에 매핑함으로써 제2 포인트 데이터 셋을 확인할 수 있다(S1045). 또한, 상기 컴퓨팅 장치는 상기 확인된 제2 포인트 데이터 셋을 상기 제1 임베딩 공간에 복원함으로써 개선된 제1 포인트 데이터 셋을 확인할 수 있다(S1046). 이때, 상기 S1045동작 및 상기 S1046동작은 상술한 기술적 특징(도 16 내지 도 22)이 그대로 적용될 수 있으므로 자세한 설명은 생략하도록 한 다. 또한, 컴퓨팅 장치는 상기 제1 포인트 데이터 셋을 기초로 데이터 이미지를 제공하고, 개선된 제1 포인트 데이 터 셋을 기초로 개선된 데이터 이미지를 제공할 수 있다(S1047). 이때, 상기 컴퓨팅 장치가 상기 제1 포인트 데 이터 셋을 기초로 데이터 이미지를 제공하는 구체적인 방법은 상술한 기술적 특징(도 4 내지 도 9)이 그대로 적 용될 수 있으므로 생략하기로 한다. 또한, 상기 S1047 동작에서, 상기 컴퓨팅 장치는 상기 개선된 데이터 이미 지를 상기 데이터 이미지와 동일한 이미징 공간에 나타낼 수 있다. 또한, 이에 한정되지 않고, 상기 컴퓨팅 장 치는 상기 개선된 데이터 이미지를 상기 데이터 이미지와 상이한 이미징 공간에 나타낼 수 있다. 대안적으로 또는 추가적으로, 상기 컴퓨팅 장치는 상기 제1 포인트 데이터 셋을 기초로 데이터 셋의 특성을 획 득할 수 있고, 상기 개선된 제1 포인트 데이터 셋을 기초로 상기 데이터 셋의 개선된 특성(modified property) 을 획득할 수 있다. 이때, 상기 데이터 셋의 특성을 획득하는 구체적인 방법은 상술한 기술적 특징(도 10 내지 도 15)이 그대로 적용될 수 있으므로 생략하기로 한다. 대안적으로 또는 추가적으로, 상기 컴퓨팅 장치는 상기 개선된 포인트 데이터 셋을 아웃풋 도메인으로 복원함으 로써 가상 데이터를 포함하는 개선된 데이터 셋을 제공할 수 있다. 이때, 상기 개선된 데이터 셋을 제공하는 구 체적인 방법은 상술한 기술적 특징(도 23 내지 도 24)이 그대로 적용될 수 있으므로 생략하기로 한다. 도 30은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치를 구성하는 알고리즘 수행 모델들을 도시한 도면이다. 도 30을 참조하면, 컴퓨팅 장치는 목적이 상이한 복수의 알고리즘 수행 모델들을 포함할 수 있다. 구체적 으로, 상기 컴퓨팅 장치는 특정 아웃풋을 출력하도록 설계된 복수의 알고리즘 수행 모델들을 포함할 수 있다. 예를 들어, 상기 컴퓨팅 장치는 데이터 이미지를 제공하도록 설계된 이미징 모델, 개선된 포인트 데이터를 제공하도록 설계된 개선 모델, 가상 데이터를 포함하는 개선된 데이터 셋을 생성하도록 설계된 생성 모델, 데이터의 특성을 연산하도록 설계된 특성 추출 모델 및 진단 레포트를 제공하도록 설계 된 진단 모델을 포함할 수 있으나, 이에 한정되지 않는다. 물론, 복수의 알고리즘 수행 모델들은 하나의 통합 모델로 구현될 수도 있다. 또한, 컴퓨팅 장치는 상기 복수의 알고리즘 수행 모델들 중 적어도 일부에 선택적으로 인풋 데이터를 입력함으 로써 아웃풋 데이터를 선택적으로 출력할 수 있다. 이때, 상기 컴퓨팅 장치는 상기 데이터 셋과 함께 입력되는 사용자 입력을 기초로 상기 데이터 셋을 어떤 모델들을 기초로 처리할지 결정할 수 있다. 예를 들어, 상기 컴퓨 팅 장치가 데이터 이미지를 출력하라는 사용자 입력과 함께 데이터 셋을 획득한 경우, 상기 컴퓨팅 장치는 상기 데이터 셋을 상기 이미징 모델에 입력함으로써 데이터 이미지를 출력할 수 있다. 또한, 상기 복수의 알고리즘 모델들 중 특정 모델의 아웃풋 데이터는 다른 모델의 인풋 데이터로 이용될 수 있 다. 예를 들어, 컴퓨팅 장치가 가상 데이터를 생성하라는 사용자 입력과 함께 데이터 셋을 획득한 경우, 상기 컴퓨팅 장치는 상기 데이터 셋을 상기 개선 모델에 입력함으로써 획득된 개선된 포인트 데이터를 획득할 수 있고, 상기 개선된 포인트 데이터 셋이 상기 생성 모델에 입력되어 가상 데이터를 포함하는 개선된 포 인트 데이터 셋을 제공할 수 있다. 또한, 예를 들어, 컴퓨팅 장치가 개선된 데이터 이미지를 생성하라는 사용자 입력과 함께 데이터 셋을 획득한 경우, 상기 컴퓨팅 장치는 상기 데이터 셋을 상기 개선 모델에 입력함으로써 획득된 개선된 포인트 데이 터를 획득할 수 있고, 상기 개선된 포인트 데이터 셋이 상기 이미징 모델에 입력되어 개선된 데이터 이미 지를 제공할 수 있다. 또한, 예를 들어, 컴퓨팅 장치가 진단 레포트를 생성하라는 사용자 입력과 함께 데이터 셋을 획득한 경우, 상기 컴퓨팅 장치는 상기 데이터 셋을 기초로 획득한 데이터 이미지, 개선된 데이터 이미지, 개선된 포인트 데이터 셋, 데이터 셋의 특성 및 데이터 셋의 개선된 특성을 상기 진단 모델에 입력함으로써 진단 레포트를 제공 할 수 있다. 도 31은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치에 포함된 적어도하나의 프로세서가 데이터 셋을 기초로 동작을 선택적으로 수행하는 방법을 나타내는 도면이다. 도 31을 참조하면, 상기 적어도 하나의 프로세서는 데이터 셋을 획득할 수 있다(S1048). 또한, 적어도 하나의 프로세서는 상기 데이터 셋을 미리 정해진 방식에 따라 판단할 수 있다(S1049). 예를 들어, 상기 적어도 하나의 프로세서는 상기 데이터 셋의 용량, 적용 도메인, 모달리티, 종류, 또는 모달리티의 개수 등을 판단할 수 있다. 또한, 상기 적어도 하나의 프로세서는 미리 저장된 알고리즘을 기초로 상기 데이터 셋을 판단할 수 있다. 또한, 적어도 하나의 프로세서는 미리 저장된 데이터 베이스(data base)에서 상기 획득된 데이터 셋과 유사한 데이터 를 서치(search)함으로써 상기 데이터 셋을 판단할 수 있다. 또한, 상기 적어도 하나의 프로세서는 상기 판단 결과에 따라, 상기 컴퓨팅 장치의 메모리에 저장된 복수의 인 스트럭션들 중 적어도 하나를 기초로 동작을 수행할 수 있다(S1050). 구체적으로, 적어도 하나의 프로세서는 상기 데이터 셋을 판단한 결과 확인된 트리거를 기초로 결정된 적어도 하나의 인스트럭션들에 의해 지시되는 프로세스를 수행할 수 있다. 이때, 상기 트리거는 적어도 하나의 프로세 서의 동작을 트리거링(triggering)하는 이벤트일 수 있고, 상기 트리거의 종류에 따라 상기 적어도 하나의 프로 세서가 수행하는 프로세스가 결정될 수 있다. 보다 구체적으로, 상기 트리거는 특정한 아웃풋 데이터를 제공하 도록 지시하는 이벤트일 수 있으나, 이에 한정되지 않는다. 구체적인 예시는 도 32를 통해 설명한다. 도 32는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치의 메모리에 저장된 인스트럭션에 따라 적어도 하나의 프 로세서가 수행하는 다양한 프로세스를 도시한 도면이다. 도 32를 참조하면, 컴퓨팅 장치의 적어도 하나의 프로세서는 트리거가 확인되는 경우, 상기 트리거에 따라 복수 의 프로세스들(데이터 처리 파이프라인) 중 하나를 기초로 동작할 수 있다. 구체적으로, 제1 트리거가 발생한 경우, 적어도 하나의 프로세서는 제1 프로세스를 기초로 동작할 수 있 다. 이때, 상기 적어도 하나의 프로세서는 상기 제1 프로세스에 포함되는 복수의 인스트럭션들 중 적어도 일부를 기초로 동작할 수 있다. 예를 들어, 상기 제1 트리거가 데이터 이미지를 제공하도록 지시하는 경우, 상기 적어도 하나의 프로세서는 상 기 적어도 하나의 프로세서가 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인하는 동작을 수행하도록 지시 하는 인스트럭션 및 상기 적어도 하나의 프로세서가 상기 데이터 셋을 기초로 데이터 이미지를 제공하는 동작을 수행하도록 지시하는 인스트럭션을 기초로 동작할 수 있다. 물론, 상기 적어도 하나의 프로세서가 상기 포인트 데이터 셋을 기초로 데이터 셋의 특성을 획득하는 동작을 수행하도록 지시하는 인스트럭션을 기초로 동작을 더 수행할 수도 있다. 또한, 예를 들어, 상기 제1 트리거가 데이터 셋의 특성을 제공하도록 지시하는 경우, 상기 적어도 하나의 프로 세서는 상기 적어도 하나의 프로세서가 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인하는 동작을 수행하 도록 지시하는 인스트럭션, 상기 적어도 하나의 프로세서가 상기 포인트 데이터 셋을 기초로 데이터 셋의 특성을 획득하는 동작을 수행하도록 지시하는 인스트럭션을 기초로 동작할 수 있다. 또한, 컴퓨팅 장치는 상기 제1 프로세스로 연결되는 상기 제1 트리거에 대한 정보를 미리 저장할 수 있다. 구체적으로, 상기 제1 트리거는 데이터 이미지를 제공하는 것을 지시하는 사용자 입력의 수신 및 데이터 셋에 대한 판단 결과를 포함할 수 있다. 또한, 상기 제1 트리거는 데이터 셋이 입력되는 즉시 발생할 수 있다. 다시 말해, 데이터 이미지를 제공하도록 지시하는 상기 제1 트리거는 데이터 셋이 획득됨과 동시에 발생하는 기 본 트리거일 수 있으나, 이에 한정되지 않는다. 또한, 제2 트리거가 발생한 경우, 적어도 하나의 프로세서는 제2 프로세스를 기초로 동작할 수 있다. 이 때, 상기 적어도 하나의 프로세서는 상기 제2 프로세스에 포함되는 복수의 인스트럭션들 중 적어도 일부 를 기초로 동작할 수 있다. 예를 들어, 상기 제2 트리거가 개선된 포인트 데이터 셋을 제공하도록 지시하는 경우, 상기 적어도 하나의 프로 세서는 상기 적어도 하나의 프로세서가 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인하는 동작을 수행하 도록 지시하는 인스트럭션 및 상기 적어도 하나의 프로세서가 상기 포인트 데이터 셋을 기초로 개선된 포 인트 데이터 셋을 확인하는 동작을 수행하도록 지시하는 인스트럭션을 기초로 동작할 수 있다. 또한, 예를 들어, 상기 제2 트리거가 데이터 셋의 개선된 특성을 제공하도록 지시하는 경우, 상기 적어도 하나 의 프로세서는 상기 적어도 하나의 프로세서가 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인하는 동작을 수행하도록 지시하는 인스트럭션, 상기 적어도 하나의 프로세서가 상기 포인트 데이터 셋을 기초로 개선 된 포인트 데이터 셋을 확인하는 동작을 수행하도록 지시하는 인스트럭션 및 상기 적어도 하나의 프로세 서가 개선된 포인트 데이터 셋을 기초로 데이터 셋의 개선된 특성을 획득하는 동작을 수행하도록 지시하는 인스 트럭션을 기초로 동작할 수 있다. 또한, 예를 들어, 상기 제2 트리거가 데이터 셋의 개선된 데이터 이미지를 제공하도록 지시하는 경우, 상기 적 어도 하나의 프로세서는 상기 적어도 하나의 프로세서가 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인하 는 동작을 수행하도록 지시하는 인스트럭션, 상기 적어도 하나의 프로세서가 상기 포인트 데이터 셋을 기 초로 개선된 포인트 데이터 셋을 확인하는 동작을 수행하도록 지시하는 인스트럭션 및 상기 적어도 하나 의 프로세서가 상기 개선된 포인트 데이터 셋을 기초로 개선된 데이터 이미지를 제공하는 동작을 수행하도록 지 시하는 인스트럭션을 기초로 동작할 수 있다. 또한, 컴퓨팅 장치는 상기 제2 프로세스로 연결되는 상기 제2 트리거에 대한 정보를 미리 저장할 수 있다. 구체적으로, 상기 제2 트리거는 개선된 데이터 이미지를 제공하는 것을 지시하는 사용자 입력의 수신 및 데이터 셋에 대한 판단 결과를 포함할 수 있다. 또한, 제3 트리거가 발생한 경우, 적어도 하나의 프로세서는 제3 프로세스를 기초로 동작할 수 있다. 이 때, 상기 적어도 하나의 프로세서는 상기 제3 프로세스에 포함되는 복수의 인스트럭션들 중 적어도 일부 를 기초로 동작할 수 있다. 예를 들어, 상기 제3 트리거가 데이터 셋의 등급을 제공하도록 지시하는 경우, 상기 적어도 하나의 프로세서는 상기 적어도 하나의 프로세서가 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인하는 동작을 수행하도록 지 시하는 인스트럭션, 및 상기 적어도 하나의 프로세서가 상기 포인트 데이터 셋을 기초로 데이터 셋의 등 급을 획득하는 동작을 수행하도록 지시하는 인스트럭션을 기초로 동작할 수 있다. 또한, 예를 들어, 상기 제3 트리거가 데이터 셋의 달성 가능 등급을 제공하도록 지시하는 경우, 상기 적어도 하 나의 프로세서는 상기 적어도 하나의 프로세서가 획득한 데이터 셋을 기초로 포인트 데이터 셋을 확인하는 동작 을 수행하도록 지시하는 인스트럭션, 상기 적어도 하나의 프로세서가 상기 포인트 데이터 셋을 기초로 개 선된 포인트 데이터 셋을 확인하는 동작을 수행하도록 지시하는 인스트럭션, 및 상기 적어도 하나의 프로 세서가 개선된 포인트 데이터 셋을 기초로 데이터 셋의 달성 가능 등급을 획득하는 동작을 수행하도록 지시하는 인스트럭션을 기초로 동작할 수 있다. 또한, 컴퓨팅 장치는 상기 제3 프로세스로 연결되는 상기 제3 트리거에 대한 정보를 미리 저장할 수 있다. 구체적으로, 상기 제3 트리거는 데이터 셋의 달성 가능 등급을 제공하는 것을 지시하는 사용자 입력의 수 신 및 데이터 셋에 대한 판단 결과를 포함할 수 있다. 상기 적어도 하나의 프로세서의 선택적 동작은 도 32에 도시된 프로세스에 한정되는 것은 아니며, 본 개시의 다 양한 실시예에 따른 컴퓨팅 장치가 출력 가능한 아웃풋을 기초로 발생된 트리거에 따라 프로세서의 동작이 선택 적으로 수행될 수 있다. 예를 들어, 제4 트리거(미도시)가 진단 레포트를 제공하도록 지시하는 경우, 상기 적어 도 하나의 프로세서는 상기 진단 레포트를 생성하는데에 필요한 정보들을 획득하도록 지시하는 적어도 하나의 인스트럭션들을 기초로 동작할 수 있다. 또한, 다양한 실시예에 따른 컴퓨팅 장치는 상술한 바와 같이 복수의 인스트럭션들로 구성된 복수의 프로세스들 을 데이터베이스화함으로써 프리셋 데이터 베이스(preset database)를 구성할 수 있다. 구체적으로, 컴퓨팅 장 치는 상술한 방법(예를 들어, 데이터 이미징, 특성 추출, 개선, 평가 등), 상기 방법에 수반되는 인풋 데이터 및 아웃풋 데이터들, 나아가, 상기 방법에 수반되는 매니폴드의 생성 방법(예를 들어, 차원 결정 방법, 최적화 된 형태 결정 방법 등) 등을 모두 저장하여 프리셋 데이터 베이스를 구성할 수 있다. 또한, 컴퓨팅 장치는 데이터 셋이 입력되는 경우, 상기 프리셋 데이터 베이스에 저장된 복수의 프로세스들 중 적어도 하나를 선택할 수 있고, 상기 선택된 프로세스를 기초로 상기 데이터 셋을 처리할 수 있다. 또한, 컴퓨팅 장치는 상기 프리셋 데이터 베이스를 재구성할 수 있다. 보다 구체적으로, 컴퓨팅 장치는 입력된 데이터 셋을 최초로 결정된 프로세스에 따라 처리하여 최종 아웃풋을 생성하는 것이 아니라, 보다 최적화된 아 웃풋을 생성하도록 반복적인 최적화 과정을 수행할 수 있고, 이에 따라 최적화된 프로세스들을 기초로 프리셋 데이터 베이스를 재구성할 수 있다. 예를 들어, 컴퓨팅 장치는 머신 러닝 방식을 기초로 상기 프리셋 데이터 베 이스를 재구성할 수 있으나, 이에 한정되지 않는다. 도 33은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치의 구현예를 나타낸 도면이다. 도 33을 참조하면, 컴퓨팅 장치는 인풋 도메인 상에 정의되는 데이터 셋을 기초로 다양한 아웃풋 데이터를 출력 하기 위한 다양한 구성들을 포함할 수 있다. 구체적으로, 컴퓨팅 장치는 획득한 데이터 셋을 기초로 제1 매니폴드를 생성하도록 설계된 제1 변환기를 포함할 수 있다. 이때, 상기 제1 매니폴드는 제1 임베딩 공간 상에 정의될 수 있다. 또한, 상기 제1 변환기 는 제1 미리 정해진 함수를 기초로 상기 데이터 셋을 상기 제1 매니폴드로 변환할 수 있다. 또한, 컴퓨팅 장치는 상기 제1 매니폴드를 기초로 제2 매니폴드를 생성하도록 설계된 제2 변환기를 포함할 수 있다. 이 때, 상기 제2 매니폴드는 상기 제1 임베딩 공간과 차원이 상이한 제2 임베딩 공간 상에 정의될 수 있다. 또한, 상기 제2 변환기는 제2 미리 정해진 함수를 기초로 상기 제1 매니폴드를 상기 제2 매니폴드로 변환할 수 있다. 예를 들어, 상기 제1 변환기 및 상기 제2 변환기는 인코더(encoder)를 포함할 수 있으나, 이 에 한정되지 않는다. 또한, 컴퓨팅 장치는 상기 제1 매니폴드를 기초로 제1 복원 데이터를 생성하도록 설계된 제1 복원기를 포 함할 수 있다. 이때, 상기 제1 복원 데이터는 상기 인풋 도메인과 동일한 차원을 가지는 아웃풋 도메인 상에 정 의될 수 있다. 또한, 상기 제1 복원기는 상기 제1 미리 정해진 함수의 역함수를 기초로 상기 제1 매니폴 드를 상기 제1 복원 데이터로 복원할 수 있다. 또한, 컴퓨팅 장치는 상기 제2 매니폴들 기초로 개선된 제1 매니 폴드를 생성하도록 설계된 제2 복원기를 포함할 수 있다. 이때, 상기 개선된 제1 매니폴드는 상기 제1 임 베딩 공간과 차원이 동일한 제3 임베딩 공간 상에 정의될 수 있다. 또한, 상기 제2 복원기는 상기 제2 미 리 정해진 함수의 역함수를 기초로 상기 제2 매니폴들르 상기 개선된 제1 매니폴드로 복원할 수 있다. 또한, 컴퓨팅 장치는 상기 제1 매니폴드를 기초로 데이터 셋의 특성을 생성하고, 상기 제2 매니폴드 또는 상기 개선된 제1 매니폴드를 기초로 데이터 셋의 개선된 특성을 생성하도록 설계된 특성 추출기를 포함할 수 있다. 이때, 상기 데이터 셋의 특성 또는 상기 데이터 셋의 개선된 특성은 피쳐 맵(feature map) 형태로 제공될 수 있다. 또한, 상기 특성 추출기는 피드포워드(feed-forward)신경망 형태로 제공될 수 있다. 또한, 컴퓨팅 장치는 상기 제1 매니폴드를 기초로 데이터 이미지를 생성하고, 상기 개선된 제1 매니폴드를 기초 로 개선된 데이터 이미지를 생성하도록 설계된 이미징 장치를 포함할 수 있다. 이때, 상기 데이터 이미지 및 상기 개선된 데이터 이미지는 미리 정의된 이미징 공간 상에 나타날 수 있다. 또한, 상기 이미징 장치(336 0)는 미리 정해진 데이터 시각화 알고리즘을 기초로 상기 제1 매니폴드 및 상기 개선된 제1 매니폴드를 각각 상 기 데이터 이미지 및 상기 개선된 데이터 이미지로 나타낼 수 있다. 도 34는, 다양한 실시예들에 따른, 데이터 클리닉 서비스를 제공하기 위한 다양한 시스템 및 시스템을 구축하기 위한 인공지능 모델 및 알고리즘들을 도시한 도면이다. 여기서, 시스템은 특정 기능을 수행하기 위해 적어도 하 나의 소프트웨어적 구성 또는 하드웨어적 구성을 포함하는 시스템을 의미할 수 있다. 본 개시에 따른 컴퓨팅 장치는 적어도 하나의 프로세서 및 적어도 하나의 프로세서에 전자적으로 연결된 메모리 에 의해 수행되는 다양한 머신 러닝 프레임워크들을 기반으로 데이터 클리닉 서비스를 제공할 수 있다. 이와 관련하여, 주어진 작업(task)을 수행하도록 학습시킬 수 있는 다양한 유형의 머신 러닝(인공지능) 프레임 워크가 있다. 서포트 벡터 머신, 의사 결정 트리, 신경망 등은 이미지 처리 및 자연어 처리와 같은 다양한 애플 리케이션에서 사용되는 머신 러닝 프레임워크의 몇몇 예시에 불과하다. 신경망과 같은 일부 머신 러닝 프레임워 크는 특정 연산을 수행하는 노드들의 계층들을 이용한다. 신경망에서 노드는 하나 이상의 에지(edge)를 통해 서로 연결된다. 신경망은 입력 계층, 출력 계층 및 하나 이 상의 중간 계층들을 포함할 수 있다. 개별 노드는 미리 정의된 함수에 따라 각각의 입력을 처리하고 후속 계층 또는 경우에 따라 이전 계층에 출력을 제공할 수 있다. 특정 노드에 대한 입력에는 입력과 노드 사이의 에지에 해당하는 가중치 값을 곱할 수 있다. 또한, 노드는 출력을 생성하는 데 사용되는 개별 바이어스 값을 가질 수 있다. 에지 가중치 및/또는 바이어스 값(파라미터)을 학습하기 위해 다양한 학습 절차를 적용할 수 있다. 신경망 구조는 서로 다른 특정 기능을 수행하는 여러 계층들을 가질 수 있다. 예를 들어, 하나 이상의 노드 레 이어는 풀링, 인코딩 또는 컨볼루션 연산과 같은 특정 연산을 집합적으로 수행할 수 있다. 본 개시에서 \"계층 (layer)\"이라는 용어는 외부 소스 또는 네트워크의 다른 레이어와 주고받는 등 입력과 출력을 공유하는 노드 그 룹을 의미할 수 있다. \"연산(calculation)\"이라는 용어는 하나 이상의 노드 레이어에서 수행할 수 있는 기능을 의미할 수 있다. \"모델 구조(model structure)\"라는 용어는 레이어 수, 레이어의 연결성 및 개별 레이어가 수행 하는 작업 유형을 포함하여 계층화된 모델의 전반적인 아키텍처를 의미할 수 있다. \"신경망 구조(neural network structure)\"라는 용어는 신경망의 모델 구조를 의미할 수 있다. \"학습된 모델\" 및/또는 \"튜닝된 모델 (tuned model)\"이라는 용어는 학습 또는 튜닝된 모델 구조에 대한 매개변수와 함께 모델 구조를 의미할 수 있다. 예를 들어, 두 모델이 서로 다른 훈련 데이터에 대해 훈련되거나 훈련 프로세스에 기본 확률론적 프로세 스가 있는 경우와 같이, 훈련된 두 모델은 동일한 모델 구조를 공유하면서도 매개변수에 대해 서로 다른 값을 가질 수 있다. \"전이 학습\"은 특정 작업에 대한 제한된 작업 별 훈련 데이터로 모델을 훈련하는 한 가지 광범위한 접근 방식이 다. 전이 학습에서, 모델은 먼저 중요한 훈련 데이터를 사용할 수 있는 다른 작업에 대해 사전 훈련된 다음, 작 업별 훈련 데이터를 사용하여 특정 작업에 맞게 모델을 조정될 수 있다. 본 개시에서 사용되는 \"사전 훈련\"이라는 용어는, 하나 이상의 특정 작업에 대해 모델을 조정하기 위해 해당 모 델 파라미터의 후속 조정을 허용하는 방식으로 모델 파라미터를 조정하기 위한 사전 훈련 데이터 세트에 대한 모델 훈련을 지칭한다. 경우에 따라 사전 학습에는 레이블이 지정되지 않은 학습 데이터에 대한 자기 지도 학습 프로세스가 포함될 수 있으며, 여기서 '자기 지도' 학습 프로세스는 명시적인(예: 수동으로 제공된) 레이블이 없는 경우 사전 학습 예제의 구조에서 학습하는 것을 포함한다. 사전 학습을 통해 얻은 모델 파라미터의 후속 수정을 여기서는 \"튜닝\"이라고 한다. 튜닝은 명시적으로 레이블이 지정된 학습 데이터에서 지도 학습을 사용하 여 하나 이상의 작업에 대해 수행할 수 있으며, 경우에 따라 사전 학습과 다른 작업을 튜닝에 사용할 수도 있다. 도 34를 참조하면, 본 개시에 따른 컴퓨팅 장치는 클리닉 서비스를 제공하기 위해, 다양한 머신 러닝 모델들로 구성된 데이터 클리닉 시스템을 포함할 수 있다. 예를 들어, 컴퓨팅 장치는 데이터 이미징 시스템, 데이터 진단 시스템 및 데이터 치료 시스템 등을 포함할 수 있으나, 이에 한정되지 않는다. 여기서, 데이터 이미징 시스템은 데이터의 특성을 나타내기 위한 최적의 차원을 결정하기 위한 렌즈 처리 모델, 데이터의 내재적 특성을 반영하는 데이터 이미지를 획득하기 위한 이미징 모델 또는 데이터를 시각적으로 나타 내기 위한 시각화 모델 등을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 데이터 진단 시스템은 데이터의 적어도 하나의 특성을 진단하기 위한 진단 모델 또는 데이터의 품질을 평 가하기 위한 품질 평가 모델 등을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 데이터 치료 시스템은 필요에 따라 타겟팅된 가상데이터를 생성하기 위한 합성 모델(또는 생성 모델), 데 이터의 적어도 일부를 제거하기 위한 데이터 다이어트 모델, 또는 데이터의 적어도 일부의 특성을 조정하기 위 한 데이터 보정 모델 등을 포함할 수 있으나, 이에 한정되지 않는다. 컴퓨팅 장치가 포함하는 다양한 머신 러닝 모델들은 메모리에 저장된 복수의 모듈들로 구성될 수 있다. 본 개시 에서 모듈(Module)은 머신 러닝 모델을 구성하는 기능 단위의 구성을 의미하는 용어로 활용될 수 있다. 예를 들 어, 모듈은 인코더, 디코더, 생성기, 구별기(Discriminator), 어댑터, 자연어 처리 모듈, 또는 대 언어 모델 (LLM) 등을 포함할 수 있으나, 이에 한정되지 않는다. 컴퓨팅 장치는 상술한 복수의 모듈들을 저장할 수 있고, 복수의 모듈들 중 적어도 일부를 기초로 머신 러닝 프 레임워크를 구성하여 데이터 클리닉을 위한 인공지능 모델을 획득할 수 있다. 예를 들어, 데이터 이미징 시스템 에 포함되는 데이터 렌즈(Data lens)는 적어도 하나의 인코더 또는 적어도 하나의 어댑터를 포함하는 머신 러닝 모델로 구현될 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 데이터 클리닉 시스템을 기반으로 획득되는 다양한 데이터를 저장하기 위한 데이터베이스 를 구축할 수 있다. [Improving quality of Imaging - Data Lens Processing] 품질 높은 데이터 이미지(Image of Data)를 획득하기 위해서는, 데이터의 내재적 특성을 보존하도록 설계된 데 이터 렌즈(또는 이미징 장치, 이미징 매니폴드 생성 모델, 인코더 등)가 필요하다. 예를 들어, 컴퓨팅 장치는 입력되는 데이터 셋의 분포를 유지시키기 위한 임베딩 공간의 최적의 차원을 결정할 수 있고, 해당 차원을 기초 로 데이터 셋을 나타냄으로써(예: 투영, 매핑, 차원 축소 등) 데이터 이미지를 획득할 수 있다. 따라서, 아래에서는, 데이터 이미징의 퀄리티를 향상시키기 위한 데이터 렌즈 가공(또는 설계) 방법이 제안된 다. 도 35는, 다양한 실시예들에 따른, 데이터 렌즈 가공 시스템(Lens Processing System) 및 데이터 이미징 시스템 (Imaging System)을 도시한 도면이다. 도 35의 (a)를 참조하면, 컴퓨팅 장치는 데이터 셋을 기초로 데이터 렌즈 시스템(System of Lens)을 획득할 수 있다. 이때, 데이터 렌즈 시스템은 데이터 셋을 특정 임베딩 공간에 매핑하기 위한 적어도 하나의 구성을 의미 하는 용어일 수 있다. 예를 들어, 데이터 렌즈 시스템은 데이터 셋을 특정 차원의 임베딩 공간(또는 잠재 공간 (latent space))에 매핑하기 위한 적어도 하나의 인코더(encoder) 및/또는 파라미터를 조정하기 위한 적어도 하 나의 어댑터(adapter)를 포함할 수 있다. 또한, 예를 들어, 데이터 렌즈 시스템은 데이터 셋에 대응되는 잠재 변수(latent variable 또는 잠재 특징 벡터)를 식별하기 위한 적어도 하나의 노드로 구성된 신경망 레이어를 포 함할 수 있다. 컴퓨팅 장치는 데이터 셋을 기초로 데이터 셋의 내재적 특성을 보존하도록 데이터 셋을 처리하는 데이터 렌즈 시스템을 결정할 수 있다. 일 예로, 컴퓨팅 장치는 데이터베이스를 기초로 데이터 셋에 대응되는 렌즈 시스템을 획득할 수 있다. 구체적으 로, 컴퓨팅 장치는 입력된 데이터 셋의 특성을 기초로 데이터베이스에서 상기 데이터 셋에 대응되는 렌즈 시스 템을 검색할 수 있다. 다른 예로, 컴퓨팅 장치는 렌즈 가공 알고리즘을 기초로 데이터 셋에 대응되는 렌즈 시스템을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 입력된 데이터 셋의 내재적 특성을 보존하는 최적의 차원(dimensionality)을 연산할 수 있다. 렌즈 가공 알고리즘에 대한 상세한 내용은 도 37에 대한 기재에서 설명한다. 도 35의 (b)를 참조하면, 컴퓨팅 장치는 결정된 데이터 렌즈 시스템을 포함하는 데이터 이미징 시스템을 기초로 데이터 셋을 처리하여 데이터 이미지(Image of Data)를 획득할 수 있다. 이때, 이미징 시스템은 적어도 하나의 모듈(예: 인코더, 어댑터 등)로 구성된 렌즈 시스템을 포함할 수 있다. 이 경우, 컴퓨팅 장치는 이미징 시스템을 이용하여 데이터 셋의 내재적 특성을 나타내는 데이터 이미지를 획득할 수 있다. 도 36은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 렌즈 시스템을 획득하는 방법을 도시한 흐름도이다. 도 36을 참조하면, 컴퓨팅 장치는 제1 데이터 셋을 획득할 수 있다(S3601). 이때, 제1 데이터 셋은 인공지능 모 델을 학습하기 위한 학습 데이터 셋을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 데이터베이스를 기초로 제1 데이터 셋에 대응되는 렌즈 시스템을 검색할 수 있다(S3603). 제1 데이터 셋에 대응되는 렌즈 시스템이 검색되는 경우, 컴퓨팅 장치는 데이터베이스로부터 제1 렌즈 시스템을 로딩함으로써 제1 이미징 모델을 획득할 수 있다(S3605). 제1 데이터 셋에 대응되는 렌즈 시스템이 검색되지 않는 경우, 컴퓨팅 장치는 미리 저장된 알고리즘에 따라 제2 렌즈 시스템을 생성함으로써 제2 이미징 모델을 획득할 수 있다(S3607). 또한, 이 경우, 컴퓨팅 장치는 제1 데이터 셋 및 제2 렌즈 시스템에 연관된 정보를 데이터베이스에 저장할 수 있다(S3609). 이를 통해, 제1 데이터 셋과 유사한 제2 데이터 셋이 입력되는 경우, 컴퓨팅 장치는 데이터베이스에 미리 저장 된 제2 렌즈 시스템을 기초로 제2 데이터 셋의 내재적 특성을 반영하는 데이터 이미지를 획득하기 위한 제2 이 미징 모델을 구축할 수 있다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는 데이터 셋을 이미징하는 데에 가장 적합한 렌즈 특성(lens property)을 결정하기 위한 렌즈 가공 알고리즘 및 상기 알고리즘이 구현된 렌즈 가공 모델을 포함할 수 있다. 예를 들어, 컴퓨팅 장치는 데이터 셋을 나타내기에 최적의 차원을 결정하기 위해, 각기 다른 차원 (dimensionality)을 기초로 설정된 복수의 인코더들 중 적어도 하나를 선택함으로써 데이터 렌즈 시스템을 설계 할 수 있다. 도 37은, 다양한 실시예들에 따른, 컴퓨팅 장치가 수행하는 렌즈 가공 알고리즘(Lens Processing Algorithm)의 일 예시를 도시한 흐름도이다. 도 38은, 다양한 실시예들에 따른, 컴퓨팅 장치가 렌즈 가공 알고리즘을 수행하기 위해 구축된 렌즈 가공 모델 의 예시를 도시한 도면이다. 도 37을 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S3701). 또한, 컴퓨팅 장치는 제1 모듈을 이용하여 데이터 셋을 기초로 제1 임베딩 벡터를 획득할 수 있다(S3703). 이때, 제1 모듈은 인코더(또는, 복수의 인코더들)일 수 있다. 또한, 제1 임베딩 벡터는 특정 차원의 임베딩 공 간에 나타나는 데이터 포인트 셋을 포함할 수 있다. 또는, 제1 임베딩 벡터는 특정 차원의 인스턴스 셋(set of instances)을 포함할 수 있다. 예를 들어, 제1 임베딩 벡터는 512 차원의 특징 벡터일 수 있으나, 이에 한정되 지 않는다. 예를 들어, 도 38을 참조하면, 컴퓨팅 장치는 획득된 데이터 셋을 제1 인코더(E0)에 입력할 수 있다. 또한, 제1 인코더(E0)는 입력된 데이터 셋을 기초로 제1 임베딩 벡터를 출력하도록 구현될 수 있다. 이때, 제1 임베 딩 벡터는 N 차원(예: 512)을 가질 수 있다. 제1 인코더(E0)는 데이터 셋을 N 차원의 임베딩으로 차원 축 소하도록 구현된 복수의 신경망 계층(layer)을 포함할 수 있다. 다시 도 37을 참조하면, 컴퓨팅 장치는 제1 임베딩 벡터를 제1 어댑터 모듈 및 제2 어댑터 모듈에 입력할 수 있 다(S3703). 이때, 어댑터 모듈은 인코더의 파라미터를 조정하기 위한 구성일 수 있다. 구체적으로, 컴퓨팅 장치 는 인코더에 어댑터 모듈이 연결되도록 구현됨에 따라 인공 지능 모델의 파라미터를 조정할 수 있다. 또한, 이 경우, 제1 어댑터 모듈 및 제2 어댑터 모듈은 병렬적으로 연결될 수 있다. 구체적으로, 컴퓨팅 장치 (또는 컴퓨팅 장치에 포함되는 렌즈 가공 모델)는 제1 모듈로부터 출력되는 데이터가 상기 제1 어댑터 모듈 및 제2 어댑터 모듈에 각각 입력되도록 구현될 수 있다. 또한, 컴퓨팅 장치(또는 렌즈 가공 모델)는 셋 이상의 어댑터 모듈을 포함하도록 구현될 수 있다. 구체적으로, 컴퓨팅 장치(또는 렌즈 가공 모델)는 제1 모듈로부터 출력되는 데이터가 셋 이상의 어댑터 모듈들에 각각 입력 되도록 구현될 수 있다. 예를 들어, 도 38을 참조하면, 컴퓨팅 장치는 제1 임베딩 벡터를 제1 어댑터 모듈 및 제2 어댑터 모듈을 포함하는 어댑터 모듈 셋에 각각 입력할 수 있다. 이 경우, 어댑터 모듈은 적어도 하나의 인코딩 레이어 및 적어도 하나의 디코딩 레이어를 포함하도록 구현될 수 있다. 구체적으로, 제1 어댑터 모듈은 제1 인코딩 레이어(E1) 및 제1 인코딩 레이어에 대응되는 제1 디코딩 레이어(D1)를 포함할 수 있으나, 이에 한 정되지 않는다. 다시 도 37을 참조하면, 컴퓨팅 장치는 제1 어댑터 모듈을 이용하여, 제1 임베딩 벡터를 기초로 제2 임베딩 벡 터를 획득하고, 제2 어댑터 모듈을 이용하여, 제1 임베딩 벡터를 기초로 제3 임베딩 벡터를 획득할 수 있다 (S3707). 이 경우, 컴퓨팅 장치는 제1 어댑터 모듈에 의한 연산 및 제2 어댑터 모듈에 의한 연산을 동시에 수행 하도록 구현될 수 있다. 컴퓨팅 장치는 복수의 어댑터 모듈들에 입력된 동일한 입력을 기초로 병렬 연산을 수행 하도록 구현될 수 있다. 예를 들어, 도 38을 참조하면, 제1 어댑터 모듈은 제1 인코딩 레이어(E1)를 이용하여 제1 임베딩 벡터 를 처리하여 제2 임베딩 벡터를 식별할 수 있다. 이 경우, 제2 임베딩 벡터는 제1 어댑터 모 듈의 은닉층(hidden layer)에 출력되도록 구현될 수 있다. 또한, 제2 어댑터 모듈은 제2 인코딩 레 이어(E2)를 이용하여 제1 임베딩 벡터를 처리하여 제3 임베딩 벡터를 식별할 수 있다. 이 경우, 제 3 임베딩 벡터는 제2 어댑터 모듈의 은닉층에 출력되도록 구현될 수 있다. 또한, 제2 임베딩 벡터 및 제3 임베딩 벡터는 서로 상이한 차원을 가질 수 있다. 예를 들어, 제2 임베딩 벡터는 a1 차원을 가질 수 있고, 제3 임베딩 벡터는 a2 차원을 가질 수 있으며, 이 경우, a1은 a2 보다 작을 수 있다. 또한, 제1 임베딩 벡터의 차원(N)은 제2 임베딩 벡터의 차원(a1) 및 제3 임베딩 벡터의 차원(a2) 보다 클 수 있다. 컴퓨팅 장치는 출력되는 임베딩 벡터의 차원이 점점 커지도록 복수의 어댑터 모듈들을 구성할 수 있다. 컴퓨팅 장치는 서로 상이한 차원의 임베딩 벡터를 출력하는 복수의 어댑터 모듈들 중 적어도 하나를 선택함으로써 데이 터 셋을 이미징하기 위한 데이터 렌즈를 가공할 수 있다. 다시 도 37을 참조하면, 컴퓨팅 장치는 제1 어댑터 모듈을 이용하여 제2 임베딩 벡터를 기초로 제4 임베딩 벡터 를 출력하고, 제2 어댑터 모듈을 이용하여 제3 임베딩 벡터를 기초로 제5 임베딩 벡터를 출력할 수 있다 (S3709). 구체적으로, 컴퓨팅 장치는 제1 어댑터 모듈을 이용하여 제2 임베딩 벡터를 복원함으로써 제4 임베딩 벡터를 획득할 수 있고, 제2 어댑터 모듈을 이용하여 제3 임베딩 벡터를 복원함으로써 제5 임베딩 벡터를 획득 할 수 있다. 예를 들어, 도 38을 참조하면, 제1 어댑터 모듈은 제1 디코딩 레이어(D1)를 이용하여 제2 임베딩 벡터 를 기초로 제4 임베딩 벡터를 식별할 수 있다. 이 경우, 제4 임베딩 벡터는 제1 어댑터 모 듈의 출력층(output layer)에 출력되도록 구현될 수 있다. 또한, 제2 어댑터 모듈은 제2 디코딩 레 이어(D2)를 이용하여 제3 임베딩 벡터를 기초로 제5 임베딩 벡터를 식별할 수 있다. 이 경우, 제5 임베딩 벡터는 제2 어댑터 모듈의 출력층에 출력되도록 구현될 수 있다. 또한, 이 경우, 제4 임베딩 벡터 및 제5 임베딩 벡터는 동일한 차원을 가질 수 있다. 또한, 제4 임베딩 벡터, 제5 임베딩 벡터 및 제1 임베딩 벡터는 동일한 차원(N)을 가질 수 있다. 이는, 어댑터 모듈이 인코딩 레 이어 및 인코딩 레이어에 쌍 지어진(paired) 디코딩 레이어를 포함하도록 구성되어 있기 때문이다. 다시 도 37을 참조하면, 컴퓨팅 장치는 제1 모듈에 대응되는 제2 모듈을 이용하여, 제4 임베딩 벡터를 기초로 제1 복원 데이터 셋을 획득하고, 제5 임베딩 벡터를 기초로 제2 복원 데이터 셋을 획득할 수 있다(S3711).이때, 제2 모듈은 디코더(또는 복수의 디코더들)일 수 있다. 또는, 제2 모듈은 생성기(generator)또한, 복원 데 이터 셋은 입력된 데이터 셋과 유사한 특성을 가지도록 생성될 수 있다. 예를 들어, 도 38을 참조하면, 컴퓨팅 장치는 제4 임베딩 벡터 및 제5 임베딩 벡터를 제1 인코더 (E0)에 대응되는 제1 디코더(D0)에 입력할 수 있다. 이 경우, 제1 디코더(D0)는 제4 임베딩 벡터를 기초 로 제1 복원 데이터 셋을 출력하고, 제5 임베딩 벡터를 기초로 제2 복원 데이터 셋을 출력하도록 구현될 수 있다. 다시 도 37을 참조하면, 컴퓨팅 장치는 데이터 셋, 제1 복원 데이터 셋 및 제2 복원 데이터 셋을 기초로 정의되 는 제1 파라미터 및 제2 임베딩 벡터 및 제3 임베딩 벡터를 기초로 정의되는 제2 파라미터 중 적어도 하나를 기 초로 적어도 하나의 어댑터 모듈을 선택할 수 있다(S3713). 구체적으로, 컴퓨팅 장치는 임베딩 벡터의 분포 및 데이터 사이의 유사도 중 적어도 하나를 기초로 정의된 파라 미터를 기초로 적어도 하나의 어댑터 모듈을 선택할 수 있고, 선택된 어댑터 모듈을 기초로 이미징 모델을 구축 할 수 있다. 예를 들어, 컴퓨팅 장치는 상기 적어도 하나의 파라미터를 최적화하는 적어도 하나의 차원(dimensionality)에 연관된 특성을 결정할 수 있고, 결정된 특성에 대응되는 어댑터 모듈을 선택할 수 있다. 컴퓨팅 장치가 데이터 이미지의 차원을 최적화하는 구체적인 방법에 대해서는 도 41을 통해 설명한다. 도 39는, 다양한 실시예들에 따른, 컴퓨팅 장치에 포함되는 렌즈 가공 시스템의 신경망 구조의 예시를 도시한 도면이다. 도 39를 참조하면, 컴퓨팅 장치에 포함되는 렌즈 가공 모델은 복수의 레이어(layers)으로 구조화된 인공 신경망 을 포함할 수 있다. 컴퓨팅 장치는 데이터 이미지를 획득하기 위한 적어도 하나의 신경망을 포함할 수 있다. 구체적으로, 컴퓨팅 장 치는 입력 데이터를 기초로 서브 데이터 이미지를 출력하기 위한 서브 이미징 신경망, 서브 데이터 이미 지를 기반으로 메인 데이터 이미지를 출력하기 위한 적어도 하나의 메인 이미징 신경망을 포함할 수 있다. 예를 들어, 컴퓨팅 장치는 서브 이미징 신경망을 이용하여, 입력 데이터 셋을 기초로 N 차원의 임베딩 공 간에 정의되는 제1 데이터 포인트 셋을 획득할 수 있다. 또한, 예를 들어, 컴퓨팅 장치는 메인 이미징 신경망 을 이용하여, N차원의 서브 데이터 이미지(또는 제1 데이터 포인트 셋)을 기초로 M(여기서, M>N)차원의 임베딩 공간에 정의되는 메인 데이터 이미지(또는 제2 데이터 포인트 셋)을 획득할 수 있다. 이때, 메인 이미징 신경망은 인코딩 신경망, 잠재 공간 및 디코딩 신경망을 포함할 수 있다. 메인 이미징 신경망은 디 코딩 신경망을 통해 서브 데이터 이미지와 유사한 특성을 가지는 복원 데이터 이미지를 출력할 수 있다. 이때, 컴퓨팅 장치는 복수의 메인 이미징 신경망들 중 적어도 하나를 기초로 렌즈 시스템을 구축할 수 있다. 예 를 들어, 컴퓨팅 장치는 도 37에 설명된 알고리즘을 기초로 메인 이미징 신경망을 포함하는 렌즈 시스템을 획득 하도록 구현될 수 있다. 또한, 컴퓨팅 장치는 서브 이미징 신경망과 쌍을 이루는 복원 신경망을 포함할 수 있다. 복원 신경 망은 복원 데이터 이미지를 기초로 복원 데이터 셋을 출력할 수 있다. 또한, 렌즈 가공 모델은 복수의 계층들을 포함할 수 있다. 구체적으로, 렌즈 가공 모델은 복수의 노드들로 구성된 복수의 계층들을 포함하는 신경망 모델로 구성될 수 있 다. 예를 들어, 렌즈 가공 모델은 데이터 셋이 입력되는 입력층(input layer, 3901), 서브 데이터 이미지를 식 별하기 위한 제1 잠재층, 메인 데이터 이미지를 식별하기 위한 제2 잠재층, 메인 데이터 이미지를 N차원으로 복원한 데이터를 식별하기 위한 제3 잠재층 및 복원 데이터를 출력하는 출력층(output layer, 3905)을 포함할 수 있다. 이때, 제1 잠재층은 메인 이미징 신경망의 입력층으로 구현될 수 있으나, 이에 한정되지 않는다. 제2 잠재층은 메인 이미징 신경망의 은닉층으로 구현될 수 있으나, 이에 한정되지 않는다. 또한, 제3 잠재층은 메인 이미징 신경망의 출력 층으로 구현될 수 있으나, 이에 한정되지 않는다. 복수의 메인 이미징 신경망 후보들 중 메인 이미징 신경망 후보를 결정하기 위해서는, 입력되는 데이터 셋의 내 재적 특성을 가장 잘 반영하는 임베딩 공간의 차원을 결정해야 한다. 이에 대한 내용은 도 41에 대한 기재에서 자세히 설명한다. 도 40은, 다양한 실시예들에 따른, 컴퓨팅 장치가 보조 네트워크를 활용하여 렌즈 가공 모델을 고도화하는 방법 을 도시한 도면이다. 도 40을 참조하면, 도 37의 S3709 동작 단계 이후에, 컴퓨팅 장치는 제1 모듈 또는 복수의 어댑터 모듈들에 연 결된 적어도 하나의 보조 네트워크를 이용하여, 태스크 수행에 연관되는 적어도 하나의 출력 값을 획득할 수 있 다(S4001). 이때, 보조 네트워크는 입력되는 데이터 셋을 이용하여 태스크를 수행하기 위한 인공지능 모델일 수 있다. 예를 들어, 보조 네트워크는 Fully Connected layer(FC) 및 Softmax layer로 구성된 분류 모델일 수 있 으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 적어도 하나의 출력 값을 기초로 정의되는 태스크 파라미터를 산출할 수 있다(S4003). 또 한, 컴퓨팅 장치는 제1 파라미터, 제2 파라미터 또는 제3 파라미터 중 적어도 하나를 기초로 적어도 하나의 어 댑터 모듈을 선택할 수 있다(S4005). 일 예로, 도 38을 참조하면, 컴퓨팅 장치는 제1 임베딩 벡터가 나타나는 제1 모듈(E0)의 잠재 계층에 연 결된 제1 보조 네트워크(Aux1)를 포함할 수 있다. 이 경우, 컴퓨팅 장치는 제1 임베딩 벡터를 제1 보조 네트워크(Aux1)에 입력하여 태스크를 수행(예: classification)함으로써 태스크 수행 결과를 나타내는 출력 값을 획득할 수 있다. 또한, 이 경우, 컴퓨팅 장치는 상기 출력 값을 최적화하기 위한 태스크 파라미터를 산출할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 보조 네트워크(Aux1)의 태스크 수행 능력을 나타내는 태스크 파라미터를 최소화(또는 최대화)함으로써 출력 값을 최적화할 수 있다. 또한, 이 경우, 컴퓨팅 장치는 데이터 셋, 제1 복원 데이터 셋 및 제2 복원 데이터 셋을 기초로 정의되는 제1 파라미터, 제2 임베딩 벡터 및 제3 임베딩 벡터를 기초로 정의되는 제2 파라미터 또는 태스크 파라미터 중 적어 도 하나를 기초로 적어도 하나의 어댑터 모듈을 선택할 수 있다. 다른 예로, 도 38을 참조하면, 컴퓨팅 장치는 복수의 어댑터 모듈들 각각에 연결된 복수의 보조 네트워크들을 포함할 수 있다. 구체적으로, 컴퓨팅 장치는 제2 임베딩 벡터가 나타나는 제1 어댑터 모듈(E1)의 잠재 계 층에 연결된 제2 보조 네트워크(Aux2) 및 제3 임베딩 벡터가 나타나는 제2 어댑터 모듈(E2)의 잠재 계층 에 연결된 제3 보조 네트워크(Aux3)를 포함할 수 있으나, 이에 한정되지 않는다. 이 경우, 컴퓨팅 장치는 제2 임베딩 벡터를 제2 보조 네트워크(Aux2)에 입력하여 태스크를 수행함으로써 태스크 수행 결과를 나타내는 제1 출력 값을 획득할 수 있다. 또한, 컴퓨팅 장치는 제3 임베딩 벡터를 제 3 보조 네트워크(Aux3)에 입력하여 태스크를 수행함으로써 태스크 수행 결과를 나타내는 제2 출력 값을 획득할 수 있다. 또한, 이 경우, 컴퓨팅 장치는 상기 복수의 출력 값들(제1 출력 값 및 제2 출력 값)을 최적화하기 위한 태스크 파라미터를 산출할 수 있다. 구체적으로, 컴퓨팅 장치는 상기 복수의 출력 값들의 합을 기초로 태스크 파라미터 를 정의할 수 있다. 또한, 이 경우, 컴퓨팅 장치는 데이터 셋, 제1 복원 데이터 셋 및 제2 복원 데이터 셋을 기초로 정의되는 제1 파라미터, 제2 임베딩 벡터 및 제3 임베딩 벡터를 기초로 정의되는 제2 파라미터 또는 태스크 파라미터 중 적어 도 하나를 기초로 적어도 하나의 어댑터 모듈을 선택할 수 있다. 본 개시의 일 실시예에 따르면, 컴퓨팅 장치는 입력되는 학습 데이터 셋의 태스크 수행 능력에 대한 파라미터를 함께 학습하도록 이미징 모델을 구축할 수 있고, 이렇게 구축된 이미징 모델을 통해 태스크 기반의 데이터 이미 지를 획득할 수 있다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는 상술한 적어도 하나의 파라미터와 데이터 이미지가 정의되는 차원 사이의 연관 관계를 기초로 데이터 셋의 내재적 특성을 반영하는 최적의 차원을 연산할 수 있다. 도 41은, 다양한 실시예들에 따른, 컴퓨팅 장치가 파라미터를 최적화하는 차원에 연관된 특성을 결정하기 위한 방법을 도시한 도면이다. 도 41을 참조하면, 컴퓨팅 장치는 서로 다른 차원의 임베딩 벡터를 출력하는 복수의 모듈들을 이용하여, 출력되 는 임베딩 벡터의 차원 및 적어도 하나의 파라미터 사이의 적어도 하나의 연관 관계를 연산할 수 있다(S4101). 예를 들어, 컴퓨팅 장치는 차원에 따른 유사도 파라미터(예: Mean Squared Error 또는 reconstruction error 등)의 제1 연관 관계, 차원에 따른 분포 파라미터(예: KL Divergence 등)의 제2 연관 관계 또는 차원에 따른 태 스크 파라미터(예: Binary cross-entropy 또는 Categorical cross-entropy 등)의 제3 연관 관계 중 적어도 하 나를 연산할 수 있다. 또한, 컴퓨팅 장치는 적어도 하나의 연관 관계를 기반으로 적어도 하나의 파라미터를 최적화하기 위한 차원 범 위(dimensionality range)를 산출할 수 있다(S4103). 또한, 컴퓨팅 장치는 차원 범위를 기반으로 데이터 셋의 내재적 특성을 반영하기 위한 최적 차원(optimal dimensionality)을 결정할 수 있다(S4105). 또한, 컴퓨팅 장치는 데이터 셋을 최적 차원의 임베딩 공간 상에 매핑하기 위한 적어도 하나의 모듈을 포함하는 이미징 모델을 구축할 수 있다(S4107). 본 개시의 일 실시예에 따른 컴퓨팅 장치는 상술한 병렬적 연산 알고리즘을 구현함으로써 데이터 셋을 나타낼 최적 차원을 결정하는 시간을 대폭 감소시키고, 복수의 모듈들로 구성된 인공지능 모델의 학습 효율을 증가시킬 수 있다. 이에 따라, 컴퓨팅 장치에 포함되는 적어도 하나의 프로세서의 연산 비용(calculation cost)를 감소시 킬 수 있는 것이다. 도 42는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋의 내재적 특성을 반영하는 데이터 이미지를 획득하 기 위한 방법을 도시한 흐름도이다. 도 42를 참조하면, 컴퓨팅 장치는 데이터 셋의 내재적 특성을 반영하는 임베딩 공간의 최적 차원을 결정함으로 써 렌즈 시스템을 구축할 수 있다(S4201). 컴퓨팅 장치가 렌즈 시스템을 구축하는 상세 알고리즘은 전술한 바 있으므로 생략하기로 한다. 또한, 컴퓨팅 장치는 구축된 렌즈 시스템을 포함하는 이미징 모델을 로딩하여 데이터 셋을 입력할 수 있다 (S4203). 또한, 컴퓨팅 장치는 이미징 모델을 이용하여, 데이터 셋을 최적 차원의 임베딩 공간에 매핑함으로써 데이터 포 인트 셋을 획득할 수 있다(S4205). 이때, 데이터 포인트 셋은 데이터 셋을 나타내는 매니폴드(manifold)를 형성 할 수 있고, 데이터 셋에 포함되는 데이터 각각에 대응되는 복수의 데이터 포인트(또는 인스턴스)들을 포함할 수 있다. 또한, 컴퓨팅 장치는 데이터 포인트 셋을 이미징 공간에 나타냄으로써 데이터 이미지를 획득할 수 있다(S4207). 이때, 데이터 이미지는 데이터 포인트 셋과 동일할 수 있으나, 이에 한정되지 않는다. 예를 들어, 컴퓨팅 장치 는 데이터 포인트 셋을 시각화 모델(visualization model)을 이용하여 이미징 공간 상에 가시화함으로써 데이터 이미지를 획득할 수 있다. 구체적인 예로, 컴퓨팅 장치는 N차원의 데이터 포인트 셋을 3차원의 공간의 가시화함 으로써 데이터 이미지를 획득할 수 있으나, 이에 한정되지 않는다. 도 43은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 이미징하고 태스크 수행 능력을 판단하기 위한 방법을 도시한 도면이다. 도 43을 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S4301). 또한, 컴퓨팅 장치는 적어도 하나의 사전 학습된 모델을 이용하여, 데이터 셋을 제1 임베딩 공간에 매핑함으로 써 제1 데이터 포인트 셋을 식별할 수 있다(S4303). 이때, 제1 임베딩 공간은 미리 정해진 N차원(예: 512)의 피 처 맵일 수 있다. 또한, 컴퓨팅 장치는 적어도 하나의 사전 학습된 모델을 이용하여, 제1 데이터 포인트 셋을 제2 임베딩 공간에 매핑함으로써 제2 데이터 포인트 셋을 식별할 수 있다(S4305). 이때, 컴퓨팅 장치는 입력된 데이터 셋에 대응되는 최적 차원을 결정할 수 있고, 제1 데이터 포인트 셋을 최적 차원으로 정의된 제2 임베딩 공간에 매핑하여 제 2 데이터 포인트 셋을 식별할 수 있다. 또한, 컴퓨팅 장치는 적어도 하나의 보조 네트워크를 이용하여, 제1 데이터 포인트 셋을 기초로 태스크를 수행 하여 출력 값 획득할 수 있다(S4307). 이 경우, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 데이터 셋의 태스크 수행 능력을 평가(evaluating)할 수 있다. 구체적으로, 컴퓨팅 장치는 데이터 셋이 학습하고자 하는 인공 지능 모델의 태스크를 반영하는 보조 네트워크를 로딩할 수 있고, 로딩된 보조 네트워크에 제1 데이터 포인트 셋 또는 데이터 셋을 입력함으로써 태 스크 수행 능력을 평가할 수 있다. 또한, 컴퓨팅 장치는 적어도 하나의 사전 학습된 모델을 이용하여, 제2 데이터 포인트 셋을 기초로 데이터 이미 지 획득할 수 있다(S4309). [Improving a quality of dataset - Data Diet] 인공 지능 모델의 프레임워크를 최적화하고, 높은 정확도의 결과 값을 도출해내기 위해서, 학습 데이터의 품질 (quality)가 매우 중요하다. 학습 데이터의 품질은 전술한 바와 같이, 양적 품질 및 질적 품질을 모두 포함하는 개념이다. 구체적으로, 인공 지능 모델의 성공적인 학습을 위해서, (i) 인공 지능 모델을 학습시키기에 충분한 양의 학습 데이터의 확보 및 (ii) 고품질의 내재적 특성(예: 편향 없는 분포)을 가지는 학습 데이터의 확보 및 (iii) 학습 목적(예: 인공지 능 모델의 태스크)에 적합한 특성(예: task-dependent property)을 가지는 학습 데이터의 확보가 필요하다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는, 고품질의 학습 데이터를 획득하기 위해, 데이터 셋의 내재적 특성 및 태스크에 의존된 특성을 향상시키는 방향으로 데이터를 합성(synthesis)하거나 수정(또는 조정)할 수 있다. 이와 더불어, 본 개시에 따른 컴퓨팅 장치는, 데이터 셋에서 적어도 일부의 데이터를 제거함으로써 데이터 셋의 전체적인 품질을 향상시킬 수 있다. 일반적으로, 데이터의 다운 샘플링(down-sampling) 또는 언더 샘플링(under-sampling) 기법은 데이터의 불균형 문제를 해결하기 위해 이용된다. 다만, 기존 언더 샘플링 방법에 따르면, 머신 러닝 데이터 셋의 특성을 고려하 지 않고 데이터를 제거함에 따라, 머신 러닝 모델의 학습에 악영향을 끼치는 문제가 있다. 본 개시에 따른 컴퓨팅 장치는, 데이터 셋에서 적어도 일부 데이터를 적절히 제거함으로써 학습되는 인공 지능 모델의 학습 효율을 향상시킬 수 있다. 도 44는 학습 데이터의 양과 인공지능 모델의 학습 효율의 상관 관계에 대한 실험 데이터를 도시한 도면이다. 도 44의 (a) 및 (b)를 참조하면, 학습 데이터 셋의 양(size)을 일정 수준 줄이더라도 학습에 따른 정확도가 높 은 수준으로 유지되고, 학습에 소요되는 시간은 획기적으로 감소하는 것을 확인할 수 있다. 구체적으로, 데이터 의 양을 100%에서 10%로 감소시키더라도, 분류 정확도(도 44의 (a) 및 (b)에 나타나는 두 그래프 중 상단 그래 프)는 0.9925에서 0.9800으로 1% 내외로 완만히 감소한 반면, 학습 시간은 40초에서 5초로 500%이상 감소한 것 을 확인할 수 있다. 본 개시에서는, 학습 데이터의 불균형 문제를 해결하는 것과 더불어, 학습 효율을 유지하면서도 학습에 소요되 는 시간 및 비용을 획기적으로 감소시킴으로써 데이터 셋의 품질을 향상시키는 데이터 다이어트(Data diet) 방 법에 대해 제안한다. 도 45는, 다양한 실시예들에 따른, 컴퓨팅 장치가 사전 학습된 인공 지능 모델을 이용하여 데이터 셋의 적어도 일부를 제거하는 방법을 도시한 도면이다. 도 45를 참조하면, 컴퓨팅 장치는 사전 학습된 인공지능 모델을 이용하여, 데이터 셋에 포함되는 데이터 중 적어도 일부의 데이터를 미리 정해진 방식에 따라 샘플링하여 제거할 수 있다. 예를 들어, 도 45의 (a)를 참조하면, 컴퓨팅 장치는 제1 입력 데이터를 인공 지능 모델에 입력할 수 있고, 인공 지능 모델은 제1 입력 데이터에 포함된 데이터 중 적어도 일부를 제거함으로써 제1출력 데이터를 획득할 수 있다. 이때, 제1 입력 데이터는 제1 데이터 셋 및/또는 제1 데이터 셋에 대응되는 제1 데이터 포인 트 셋(또는 제1 데이터 이미지)을 포함할 수 있다. 여기서, 제1 데이터 포인트 셋은 제1 데이터 셋 을 특정 임베딩 공간에 매핑함으로써 획득된 데이터일 수 있다. 또한, 제1 출력 데이터는 제1 가공된 데이터 셋 및/또는 제1 가공된 데이터 포인트 셋(또는 제1 가공된 데이터 이미지)을 포함할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 데이터 셋에 포함된 데이터 중 적어도 일부를 제거함으로써 제1 가공된 데이터 셋을 획득할 수 있다. 또는 컴퓨팅 장치는 제1 데이터 포인트 셋에 포함된 데이터 포인트들 중 적어도 일부를 제거함으로써 제1 가공된 데이터 포인트 셋을 획득할 수 있고, 제1 가공된 데이터 포인 트 셋을 기초로 제1 가공된 데이터 셋을 획득할 수 있다. 마찬가지로, 도 45의 (b)를 참조하면, 컴퓨팅 장치는 제2 데이터 셋에 포함된 데이터 중 적어도 일부를 제거함으로써 제2 가공된 데이터 셋을 획득할 수 있다. 또는 컴퓨팅 장치는 제2 데이터 포인트 셋 에 포함된 데이터 포인트들 중 적어도 일부를 제거함으로써 제2 가공된 데이터 포인트 셋을 획득할 수 있 고, 제2 가공된 데이터 포인트 셋을 기초로 제2 가공된 데이터 셋을 획득할 수 있다. 도 45를 참조하면, 입력되는 데이터 셋(4511, 4531)은 주석 데이터(annotation data) 또는 라벨링을 포함하는 데이터일 수도 있고, 또는 주석 데이터 또는 라벨링을 포함하지 않는 데이터일 수도 있다. 예를 들어, 제1 데이 터 셋은 라벨 데이터를 포함하는 데이터일 수 있고, 제2 데이터 셋은 라벨 데이터를 포함하지 않는 데이터일 수 있다. 이 경우, 컴퓨팅 장치는 라벨에 따른 주석 정보(예: Class 등)를 반영하여 데이터 다이어트 프로세스를 수행할 수 있다. 이에 대한 자세한 내용은 아래에서 설명한다. 도 46은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 일 실시예 를 도시한 흐름도이다. 도 47은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 일 예시를 도시한 도면이다. 도 46을 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S4601). 또한, 컴퓨팅 장치는 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다(S4603). 예를 들어, 도 47을 참조하면, 컴퓨팅 장치는 제1 사전 학습된 모델을 이용하여, 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 획득할 수 있다. 이때, 제1 임베딩 공간은 제1 사전 학습된 모델의 출력 레이어 또는 은닉 레이어로부터 식별되는 N(N>1)차원의 잠재 공간일 수 있다. 도면에서는 제1 임베딩 공간이 2차원 공간으로 표현되었지만, 이는 설명의 편의를 위한 것으로, 실제로는 4차원 이상의 고차원 공간일 수 있다. 또한, 제1 사전 학습 모델은 데이터 이미징을 하여 제1 임베딩 공간에 나 타내기 위한 적어도 하나의 모듈(예: 인코더)을 포함할 수 있고, 이 경우, 제1 데이터 포인트 셋은 데이 터 셋에 대응되는 데이터 이미지일 수 있으나, 이에 한정되지 않는다. 다시 도 46을 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋에 포함된 복수의 데이터 포인트들 사이의 적어도 하나의 거리 값을 기초로 제1 데이터 셋의 제1 특성 획득할 수 있다(S4605). 이때, 제1 특성은 데이터 셋의 내 재적 특성을 포함할 수 있다. 예를 들어, 제1 특성은 데이터 셋의 밀도, 분포, 편향성, 유사도, 또는 균일성 등 을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 데이터 포인트들 사이의 적어도 하나의 거리 값은 상기 제1 임베딩 공간 상에서 데이터 포인트 사이의 유클리디언 거리를 포함할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 제1 특성을 기초로 제1 데이터 포인트 셋 상의 적어도 하나의 응축 공간(condensed spac e)를 식별할 수 있다(S4607). 본 개시에서 응축 공간은 설명의 편의를 위해 임의로 정의된 개념으로, \"공간\"이 라는 용어로 발명의 한정하려는 것은 아니다. 구체적으로, 응축 공간은 임베딩 공간 상에서 데이터 포인트가 밀 집된 특정 공간을 의미할 수다. 또는, 응축 공간은 임베딩 공간 상에서 밀도가 미리 정해진 조건을 만족하는 적 어도 하나의 데이터 포인트를 의미할 수도 있다. 또는, 응축 공간은 임베딩 공간 상에서 적어도 하나의 특징 값 이 미리 정해진 범위(range) 내에 대응되는 적어도 하나의 데이터 포인트 또는 적어도 하나의 데이터 포인트에대응되는 잠재 공간을 의미할 수도 있다. 이때, 컴퓨팅 장치는 미리 정해진 조건을 기초로 응축 공간을 식별할 수 있다. 구체적으로, 컴퓨팅 장치는 데이터의 밀도가 임계값 이상인 적어도 하나의 데이터 포인트를 기초로 응축 공간을 식별할 수 있다. 이 경우, 컴퓨팅 장치는 데이터의 절대적 밀도의 크기를 기초로 응축 공간을 식별할 수 있다. 또는, 컴퓨팅 장치는 데이터의 밀도의 편차가 임계값 이상인 적어도 하나의 데이터 포인트를 기초로 응축 공간 을 식별할 수 있다. 이 경우, 컴퓨팅 장치는 데이터의 상대적 밀도를 비교하여 응축 공간을 식별할 수 있다. 또한, 이에 한정되지 않고, 컴퓨팅 장치는 제1 임베딩 공간에서 데이터가 편향된(biased) 적어도 일부의 공간을 식별함으로써 응축 공간을 식별할 수 있다. 또한, 이에 한정되지 않고, 컴퓨팅 장치는 제1 임베딩 공간에서 데이터의 불균형을 유발하는 적어도 일부의 공 간을 식별함으로써 응축 공간을 식별할 수 있다. 예를 들어, 도 47을 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 적어도 하나의 응축 공간 을 식별할 수 있다. 이때, 적어도 하나의 응축 공간은 거리가 가까운 복수의 데이터 포인트들을 포 함할 수 있다. 즉, 적어도 하나의 응축 공간은 서로 유사한 복수의 데이터에 대응되는 복수의 데이터 포 인트들을 포함할 수 있다. 다시 도 46을 참조하면, 컴퓨팅 장치는 적어도 하나의 웅축 공간에 포함된 복수의 데이터 포인트들 중 적어도 일부를 제거하여 제2 데이터 포인트 셋을 획득할 수 있다(S4609). 예를 들어, 컴퓨팅 장치는 적어도 하나의 응 축 공간에 포함된 복수의 데이터 포인트들 중 적어도 일부를 랜덤 샘플링할 수 있고, 샘플링된 데이터 포인트를 제거함으로써 제2 데이터 포인트 셋을 획득할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 제2 데이터 포인트 셋을 기초로 가공된 데이터 셋을 획득할 수 있다(S4611). 구체적으로, 컴퓨팅 장치는 제2 데이터 포인트 셋을 복원함으로써 가공된 데이터 셋을 획득할 수 있다. 예를 들어, 도 47을 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋의 응축 공간에 포함되는 적어 도 하나의 데이터 포인트를 제거하여 제2 데이터 포인트 셋을 획득할 수 있다. 이 경우, 컴퓨팅 장치는 제1 데이터 포인트 셋이 형상하는 기하학적 구조(예: 매니폴드)가 유지되도록 적어도 하나의 데이터 포인 트를 제거할 수 있다. 이에 따라, 제2 데이터 포인트 셋의 기하학적 형상은 제1 데이터 포인트 셋 의 기하학적 형상에 대응될 수 있다. 또한, 컴퓨팅 장치는 제2 사전 학습된 모델을 이용하여, 제2 데이터 포인트 셋을 기초로 제1 가공 된 데이터 셋를 획득할 수 있다. 이때, 제2 사전 학습된 모델은 제1 사전 학습된 모델과 쌍 지어진 모델로서, 제1 임베딩 공간에 정의된 데이터를 아웃풋 도메인으로 복원하기 위한 적어도 하나의 모듈(예: 디코더 등)을 포함할 수 있다. 도 48은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 다른 일 실 시예를 도시한 흐름도이다. 도 49는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 다른 일 예 시를 도시한 도면이다. 도 48을 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S4801). 또한, 컴퓨팅 장치는 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다(S4803). 컴퓨팅 장치는 제1 데이터 포인트 셋에 포함된 복수의 데이터 포인트들 사이의 적어도 하나의 거리 값을 기초로 제1 데이터 셋의 제1 특성 획득할 수 있다(S4805). 또한, 컴퓨팅 장치는 제1 특성을 기초로 제1 데이터 포인트 셋 상의 적어도 하나의 응축 공간 (condensed space)를 식별할 수 있다(S4807). 단계 S4801 내지 단계 S4807의 동작에 대한 상세한 설명의 도 46 에 대한 기재에서 설명하였으므로 생략하기로 한다. 예를 들어, 도 49를 참조하면, 컴퓨팅 장치는 제1 사전 학습된 모델을 이용하여, 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 획득할 수 있다. 컴퓨팅 장치는 제1 데이터 포 인트 셋을 기초로 적어도 하나의 응축 공간을 식별할 수 있다. 다시 도 48을 참조하면, 컴퓨팅 장치는 적어도 하나의 응축 공간의 경계에 연관되는 데이터 포인트를 제외한 제 1 서브 데이터 포인트 셋을 식별할 수 있다(S4809). 이때, 응축 공간의 경계에 연관되는 데이터 포인트는, 응축 공간을 정의하는 적어도 하나의 데이터 포인트를 포함할 수 있다. 또는, 응축 공간의 경계에 연관되는 데이터 포인트는, 응축 공간의 경계로부터 미리 정해진 거리 이내에 위치한 적어도 하나의 데이터 포인트를 포함할 수 있다. 이 경우, 컴퓨팅 장치는 응축 공간의 경계를 정의하는 적어도 하나의 특징(또는 임베딩 벡터)의 범위 (range)를 설정할 수 있다. 예를 들어, 도 49를 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋의 응축 공간의 경계에 연관되는 데이 터 포인트를 제외한 제1 서브 데이터 포인트 셋을 식별할 수 있다. 다시 도 48을 참조하면, 컴퓨팅 장치는 제1 서브 데이터 셋에 포함된 데이터 포인트들 중 적어도 일부를 제거하 여 제2 데이터 포인트 셋을 획득할 수 있다(S4811). 또한, 컴퓨팅 장치는 제2 데이터 포인트 셋을 기초로 가공 된 데이터 셋을 획득할 수 있다(S4813). 예를 들어, 도 49를 참조하면, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋에 포함되는 데이터 포인트들 중 적어도 일부를 제거하여 제2 데이터 포인트 셋을 획득할 수 있다. 또한, 컴퓨팅 장치는 제2 사전 학습된 모델을 이용하여, 제2 데이터 포인트 셋을 기초로 제1 가공된 데이터 셋를 획득할 수 있다. 도 50은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 실시예를 도시한 흐름도이다. 도 51는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 예시를 도시한 도면이다. 도 50을 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S5001). 또한, 컴퓨팅 장치는 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다(S5003). 컴퓨팅 장치는 제1 데이터 포인트 셋에 포함된 복수의 데이터 포인트들 사이의 적어도 하나의 거리 값을 기초로 제1 데이터 셋의 제1 특성 획득할 수 있다(S5005). 또한, 컴퓨팅 장치는 제1 특성을 기초로 제1 데이터 포인트 셋 상의 적어도 하나의 응축 공간 (condensed space)를 식별할 수 있다(S5007). 단계 S4801 내지 단계 S4807의 동작에 대한 상세한 설명의 도 46 에 대한 기재에서 설명하였으므로 생략하기로 한다. 예를 들어, 도 51을 참조하면, 컴퓨팅 장치는 제1 사전 학습된 모델을 이용하여, 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 획득할 수 있다. 컴퓨팅 장치는 제1 데이터 포 인트 셋을 기초로 적어도 하나의 응축 공간을 식별할 수 있다. 다시 도 50을 참조하면, 컴퓨팅 장치는 적어도 하나의 응축 공간에 연관되되, 매니폴드의 경계와는 연관되지 않 는 제1 서브 데이터 포인트 셋을 결정할 수 있다(S5009). 이때, 매니폴드는 제1 데이터 포인트 셋이 제1 임베딩 공간 상에서 형성하는 기하학적 형상(또는 형상의 경계)을 의미할 수 있다. 구체적으로, 컴퓨팅 장치는 적어도 하나의 응축 공간에 포함되되, 제1 데이터 포인트 셋의 형상을 정의하는 적 어도 하나의 데이터 포인트를 포함하지 않는 제1 서브 데이터 포인트 셋을 결정할 수 있다. 예를 들어, 도 51을 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋의 매니폴드을 식별할 수 있다. 여기서, 컴퓨팅 장치는 제1 데이터 포인트 셋의 형상을 결정하는 복수의 데이터 포인트들을 연결하는 적 어도 하나의 기하학적 특성을 기초로 매니폴드를 식별할 수 있다. 이때, 컴퓨팅 장치는 적어도 하나의 응축 공간에 연관되되, 매니폴드의 경계와는 연관되지 않는 적 어도 하나의 데이터 포인트를 기초로 제1 서브 데이터 포인트 셋을 결정할 수 있다. 이때, 제1 서브 데이 터 포인트 셋은 적어도 하나의 응축 공간에 포함될 수 있다. 다시 도 50을 참조하면, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋에 포함된 데이터 포인트들 중 적어도 일부를 제거하여 제2 데이터 포인트 셋을 획득할 수 있다(S5011). 또한, 컴퓨팅 장치는 제2 데이터 포인트 셋을 기초로 가공된 데이터 셋을 획득할 수 있다(S5013). 예를 들어, 도 51을 참조하면, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋에 포함되는 데이터 포인트 중 적어도 일부를 제거하여 제2 데이터 포인트 셋을 획득할 수 있다. 또한, 컴퓨팅 장치는 제2 사전 학습된 모델을 이용하여, 제2 데이터 포인트 셋을 기초로 제1 가공된 데이터 셋를 획득할 수 있다.도 52는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 실시예를 도시한 흐름도이다. 도 53은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 예시를 도시한 도면이다. 도 52를 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S5201). 또한, 컴퓨팅 장치는 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다(S5203). 예를 들어, 도 53을 참조하면, 컴 퓨팅 장치는 제1 사전 학습된 모델을 이용하여, 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 획득할 수 있다. 다시 도 52를 참조하면, 컴퓨팅 장치는 상기 제1 데이터 포인트 셋을 클러스터링할 수 있다(S5205). 구체적으로, 컴퓨팅 장치는 미리 저장된 클러스터링 알고리즘(예: 비지도학습 기반 클러스터링 등)을 기초로 제 1 데이터 포인트 셋을 클러스터링할 수 있다. 이를 통해, 컴퓨팅 장치는 제1 데이터 포인트 셋을 복수의 클러스 터들로 구분하여 식별할 수 있다. 예를 들어, 도 53을 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋을 클러스터링하여 제1 클러스터 , 제2 클러스터 및 제3 클러스터을 식별할 수 있다. 이때, 각각의 클러스터에 포함되는 복수 의 데이터 포인트들은 서로 유사한 특성을 나타낼 수 있다. 보다 구체적으로, 컴퓨팅 장치는 제1 데이터 포인트 셋에 포함되는 복수의 데이터 포인트들을 특성의 유사도를 기반으로 클러스터링하여 복수의 클러스터들로 구분할 수 있다. 다시 도 52를 참조하면, 컴퓨팅 장치는 복수의 클러스터들에 포함되는 데이터 포인트들 사이의 적어도 하나의 거리 값을 기초로 복수의 클러스터들에 대응되는 복수의 특성들을 획득할 수 있다(S5207). 구체적으로, 컴퓨팅 장치는 각각의 클러스터에 연관되는 데이터 포인트들의 내재적 특성을 기반으로 클러스터에 대응되는 특성을 획 득할 수 있다. 예를 들어, 컴퓨팅 장치는 클러스터에 포함되는 데이터 포인트들의 수, 클러스터에 포함되는 데 이터 포인트들 사이의 평균 거리, 클러스터의 반경 또는 클러스터의 밀도 등을 획득할 수 있으나, 이에 한정되 지 않는다. 또한, 컴퓨팅 장치는 복수의 특성들 중 적어도 하나를 기초로 복수의 클러스터들 각각에 대하여 수준(level)을 할당할 수 있다(S5209). 여기서, 수준(level)은 데이터 처리 과정 상의 차별성을 부여하기 위한 개념으로서, 데 이터 처리 알고리즘 상의 가중치(weight)와 대응되는 개념일 수 있다. 구체적으로, 컴퓨팅 장치는 복수의 클러 스터들의 적어도 하나의 특성에 의존하여 수준을 설정할 수 있다. 예를 들어, 컴퓨팅 장치는 밀도가 높은(예: 클러스터의 반경 대비 데이터 포인트들의 수) 클러스터에 높은 수준(level)을 부여하도록 설정될 수 있다. 예를 들어, 도 53을 참조하면, 컴퓨팅 장치는 복수의 클러스터들(5321, 5322, 5323)의 적어도 하나의 특성을 식 별할 수 있다. 또한, 컴퓨팅 장치는 복수의 클러스터들에 대응되는 특성을 기초로, 제1 클러스터에 제1 수준을 할당하고, 제2 클러스터에 제2 수준을 할당하고, 제3 클러스터에 제3 수준을 할당할 수 있 다. 예를 들어, 제1 클러스터의 밀도가 제3 클러스터의 밀도보다 높고, 제3 클러스터의 밀도 가 제2 클러스터의 밀도보다 높은 경우, 제1 수준은 제3 수준보다 크고, 제3 수준은 제2 수준보다 클 수 있다. 다시 도 52를 참조하면, 컴퓨팅 장치는 할당된 수준에 따라 데이터를 제거하여 제2 데이터 포인트 셋을 획득할 수 있다(S5211). 구체적으로, 컴퓨팅 장치는 수준이 높게 할당된 클러스터에 대하여, 많은 수의 데이터 포인트 가 제거되도록 설정될 수 있다. 예를 들어, 도 53을 참조하면, 컴퓨팅 장치는 복수의 클러스터들(5321, 5322, 5323) 각각에 할당된 수준에 따라 데이터 포인트를 제거함으로써 제2 데이터 포인트 셋을 획득할 수 있다. 또한, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로, 데이터 포인트 사이의 거리를 기반으로 제1 특성 (예: 밀도)를 획득하고, 제1 특성을 기반으로 적어도 둘 이상의 응축 공간을 식별함으로써 클러스터링을 수행할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 특성이 임계값 이상인 제1 응축 공간, 제2 응축 공간 및 제3 응축 공간 을 식별함으로써 제1 클러스터, 제2 클러스터 및 제3 클러스터를 식별할 수 있다. 다시 도 52를 참조하면, 컴퓨팅 장치는 제2 데이터 포인트 셋을 기초로 가공된 데이터 셋을 획득할 수 있다 (S5213). 예를 들어, 도 53을 참조하면, 컴퓨팅 장치는 제2 사전 학습된 모델을 이용하여, 제2 데이터 포인트 셋을 기초로 제1 가공된 데이터 셋를 획득할 수 있다. 도 54는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 실시예를 도시한 흐름도이다. 도 55는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 예시를 도시한 도면이다. 도 54를 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S5401). 또한, 컴퓨팅 장치는 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다(S5403). 예를 들어, 도 55를 참조하면, 컴 퓨팅 장치는 제1 사전 학습된 모델을 이용하여, 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 획득할 수 있다. 이때, 데이터 셋은 라벨링 데이터(labeled data)를 포함할 수 있다. 구체적으로, 제1 사전 학습 모델 에 입력되는 데이터 셋은 학습 대상 데이터 및 학습 대상 데이터에 대응되는 정답 데이터(예: 주석 (annotation) 정보)를 포함할 수 있다. 다시 도 54를 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 복수의 서브 데이터 포인트 셋들을 식별 할 수 있다(S5405). 구체적으로, 컴퓨팅 장치는 데이터 셋에 포함되는 라벨링 데이터를 기초로 제1 데이터 포인 트 셋을 복수의 서브 데이터 포인트 셋들로 구분할 수 있다. 예를 들어, 도 55를 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 제1 서브 데이터 포인트 셋(55210, 제2 서브 데이터 포인트 셋 및 제3 서브 데이터 포인트 셋을 식별할 수 있다. 이때, 복수의 서브 데이터 포인트 셋들은 서로 상이한 클래스 (class)를 나타낼 수 있다. 다시 도 54를 참조하면, 컴퓨팅 장치는 복수의 서브 데이터 포인트 셋들 사이의 적어도 하나의 경계 영역을 설 정할 수 있다(S5407). 보다 구체적으로, 컴퓨팅 장치는 제1 임베딩 공간 상에서 복수의 서브 데이터 셋들을 구 별하는 적어도 하나의 경계를 식별할 수 있다. 예를 들어, 도 55를 참조하면, 컴퓨팅 장치는 복수의 서브 데이 터 셋들 사이의 경계에 포함되는 적어도 하나의 데이터 포인트를 식별함으로써 적어도 하나의 경계 영역을 설정 할 수 있다. 구체적인 예로, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋 및 제 3 서브 데이터 포인트 셋 사이의 제1 경계 영역, 제1 서브 데이터 포인트 셋 및 제2 서브 데이터 포인트 셋 사 이의 제2 경계 영역 및 제2 서브 데이터 포인트 셋 및 제3 서브 데이터 포인트 셋 사이의 제 3 경계 영역을 식별할 수 있으나, 이에 한정되지 않는다. 다시 도 54를 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 적어도 하나의 경계 영역에 연관되는 데 이터를 제외한 적어도 일부의 데이터 포인트들을 제거하여 제2 데이터 포인트 셋을 획득할 수 있다(S5409). 또 한, 컴퓨팅 장치는 제2 데이터 포인트 셋을 기초로 가공된 데이터 셋을 획득할 수 있다(S5411). 예를 들어, 도 55를 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋에 포함되는 복수의 데이터 포인트들 중 적어도 하나 의 경계 영역(5524, 5525, 5526)에 포함되는 데이터 포인트들을 제외한 적어도 하나의 데이터 포인트를 제거함 으로써 제2 데이터 포인트 셋을 획득할 수 있다. 또한, 컴퓨팅 장치는 제2 사전 학습된 모델을 이 용하여, 제2 데이터 포인트 셋을 기초로 제1 가공된 데이터 셋를 획득할 수 있다. 본 개시의 다양한 실시예들에 따른 컴퓨팅 장치는 상술한 데이터 다이어트 알고즘에 따라, 데이터 셋에서 불필 요한 데이터를 선별적으로 제거함으로써 인공 지능 모델의 학습 효율(예: 학습 소요 시간, 학습 소요 비용 등) 을 향상시킬 수 있다. [Improving a quality of data generation - Generation with Imaging] 컴퓨팅 장치는 적어도 하나 이상의 사전 학습된 생성 모델들을 이용하여 가상 데이터를 생성할 수 있다. 예를 들어, 컴퓨팅 장치는 GAN(Generative adversarial network), diffusion, 또는 VAE(Variational autoencoder) 등의 생성 모델들을 이용하여 가상 데이터를 생성할 수 있다. 인공 지능 모델의 완성도를 높이기 위해서는, 실제 데이터로부터 획득이 어려우면서도 실제 데이터와 유사한 품 질 높은 가상 데이터(synthetic data)를 생성할 필요가 있다. 현재 통용되는 여러 딥러닝 기반 생성 모델들(예: GAN 또는 VAE 등)은 데이터 생성 품질 또는 생성되는 데이터에 대한 예측 가능성 측면에서 약점이 있다. 예시적으로, GAN 모델의 경우, 실제 데이터와 유사한 데이터를 생성할 수 있다는 장점이 있으나, 입력되는 데이 터(noise, feature or instance 등)를 조절할 수 없기 때문에, 생성되는 데이터에 대한 예측 가능성이 떨어진다. 이로 인해, GAN 모델이 생성하는 데이터의 실제 분포를 추정하기 어렵고, 실제 데이터와의 관계가 불 분명한 가상 데이터가 생성될 수밖에 없다. 또한, 예시적으로, VAE 모델의 경우, 임베딩 공간 상에서의 데이터 포인트들(예: feature, instance or latent variable 등)을 식별할 수 있으므로, 생성하려는 데이터에 대한 예측 가능성이 보장된다. 다만, VAE 모델은 디 코더를 통한 데이터의 복원과 임베딩 공간 상의 피쳐맵의 분포를 기초로 학습되므로, 생성하는 데이터의 품질이 보장되지 않는 단점이 있다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는, 고품질의 가상 데이터(synthetic data)를 생성하여, 기존 학습 데 이터의 품질을 향상시키 위해, 상술한 생성 모델들 및 하술할 \"생성형 이미징 모델(Generative Imaging Mode l)\"을 이용하여 가상 데이터를 생성할 수 있다. 본 명세서에서, 생성형 이미징 모델은 적어도 하나의 프로세싱 모듈들(예: 인코더, 디코더, 생성기, 판별기 등)로 구성된 인공 지능 모델을 의미하는 것으로, 용어 그 자체로 발명을 한정하려는 것은 아니다. 도 56은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 이용하여 가상 데이터를 생성하는 방법 을 나타낸 도면이다. 도 56을 참조하면, 컴퓨팅 장치는 생성형 이미징 모델을 이용하여, 입력 데이터를 기초로 가상 데이터 및 가상 데이터에 대응되는 데이터 이미지를 획득할 수 있다. 이때, 입력 데이터는 가상 데이터를 생성하기 위한 적어도 하나의 특징(예: 노이즈 데이터 등)을 포함할 수 있다. 보다 구체적으로, 컴퓨팅 장치는 입력 데이터를 생성형 이미징 모델에 입력할 수 있고, 생성형 이미징 모 델의 적어도 하나의 계층을 통해 가상 데이터 및 가상 데이터에 대응되는 데이터 이미지를 획득할 수 있다. 여기서, 데이터 이미지는 가상 데이터의 내재적 특성을 나타내는 특징 맵으로서, 컴퓨팅 장치는 상 기 가상 데이터를 특정 임베딩 공간에 매핑함으로써 데이터 이미지를 획득할 수 있다. 도 57은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델의 프레임워크를 도식화한 도면이다. 도 57을 참조하면, 컴퓨팅 장치는 제1 모델을 이용하여, 입력 데이터를 기초로 가상 데이터를 생성 할 수 있다. 이때, 제1 모델은 적어도 하나의 생성 모듈(예: Generator 등)을 포함할 수 있으나, 이에 한 정되지 않는다. 또한, 컴퓨팅 장치는 생성된 가상 데이터 및 실제 데이터를 제2 모델에 입력할 수 있다. 이 때, 제2 모델은 적어도 하나의 판별 모듈(예: Discriminator 등) 또는 적어도 하나의 인코딩 모듈(예: Encoder 등)을 포함할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 제2 모델을 이용하여, 가상 데이터를 기초로 제1 매니폴드를 식별할 수 있다. 또한, 컴퓨팅 장치는 제2 모델을 이용하여, 실제 데이터를 기초로 제2 매니폴드를 식 별할 수 있다. 여기서, 제1 매니폴드은 상기 가상 데이터를 특정 임베딩 공간에 매핑함으로써 획득된 복수의 임베 딩 벡터들을 포함할 수 있다. 제1 매니폴드는 가상 데이터의 내재적 특성(예: 밀도, 분포 등)을 반 영하는 데이터일 수 있다. 이 경우, 컴퓨팅 장치는 제2 모델의 적어도 하나의 계층(5702-1)을 이용하여, 제1 매니폴드 및 제2 매니 폴드를 출력할 수 있다. 예를 들어, 제2 모델의 적어도 하나의 계층(5702-1)은 적어도 하나의 임베딩 층 (embedding layer)을 포함할 수 있으나, 이에 한정되지 않는다. 이때, 컴퓨팅 장치는 가상 데이터에 대응되는 매니폴드의 특성 및 실제 데이터에 대응되는 매니폴드의 특성을 기초로 제1 모델 및 제2 모델을 학습함으로써 생성형 이미징 모델을 구축할 수 있다. 또한, 컴퓨팅 장치는 제2 모델을 이용하여 가상 데이터를 실제 데이터와 구별하도록 설정될 수 있다. 이경우, 컴퓨팅 장치는 제2 모델이 가상 데이터와 실제 데이터와 구별하지 못하도록 제2 모델 을 학습할 수 있다. 컴퓨팅 장치는 실제 데이터와 유사한 임베딩을 나타내는 가상 데이터를 생성하도록 제1 모델 및 제2 모델 을 학습할 수 있다. 컴퓨팅 장치는 실제 데이터와 기하학적 특성이 유사한 가상 데이터를 생성하도록 제1 모델을 학습할 수 있다. 또한, 컴퓨팅 장치는 제1 매니폴드 및 제2 매니폴드의 형상이 유사해지도록 제2 모델 을 학습할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 매니폴드의 경계에 위치한 데이터 포인트들이 형성하 는 기하학적 형상이 제2 매니폴드의 경계에 위치한 데이터 포인트들이 형성하는 기하학적 형상에 대응되 도록 제1 모델 및/또는 제2 모델을 학습할 수 있다. 보다 구체적으로, 컴퓨팅 장치는 제1 매니폴드에 포함되는 적어도 하나의 데이터 포인트 및 제2 매니폴드 에 포함되는 적어도 하나의 데이터 포인트 사이의 거리 관계를 조정함으로써 제1 모델 및/또는 제2 모델의 파라미터를 최적화할 수 있다. 예를 들어, 컴퓨팅 장치는 실제 데이터에 대응되는 제2 매니폴드의 경계 및 가상 데이터에 대응되는 제1 매니폴드의 경계에 걸쳐 데이터 포인트들 사이의 거리가 일정하도록 거리 관계를 조정할 수 있다. 구체적 으로, 컴퓨팅 장치는 제1 매니폴드 및 제2 매니폴드 상에서 서로 대응되는 위치에 나타나는 적어도 두 개의 데이터 포인트들 사이의 거리가 매니폴드의 경계에 걸쳐 일정하도록 모델 파라미터를 조정할 수 있다. 구체적인 예로, 실제 데이터의 아웃라이어 데이터에 대응되는 가상 데이터가 생성되도록 하기 위해서, 아웃라이 어 데이터 및 특정 가상 데이터 사이의 거리가 미리 정해진 조건을 만족하도록 가상 데이터를 생성할 수 있다. 또한, 컴퓨팅 장치는 상술한 거리 기반의 학습 조건(예: average hausdorff distance)을 매니폴드 상의 데이터 포인트들 각각에 적용함으로써 제1 모델 및/또는 제2 모델의 파라미터를 최적화할 수 있다. 또한, 컴퓨팅 장치는 실제 데이터와 위치적 특성이 유사한 가상 데이터를 생성하도록 제1 모델을 학습할 수 있다. 또한, 컴퓨팅 장치는 제1 매니폴드 및 제2 매니폴드의 임베딩 상의 위치가 유사해지도록 제2 모델을 학습할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 매니폴드의 중심이 제2 매니폴드(576 0)의 중심에 대응되는 가상 데이터를 생성하도록 제1 모델 및/또는 제2 모델을 학습할 수 있 다. 보다 구체적으로, 컴퓨팅 장치는 제1 매니폴드에 포함되는 적어도 하나의 데이터 포인트 및 제2 매니폴드 에 포함되는 적어도 하나의 데이터 포인트 사이의 기하학적 관계를 조정함으로써 제1 모델 및/또는 제2 모델의 파라미터를 최적화할 수 있다. 예를 들어, 컴퓨팅 장치는 실제 데이터에 대응되는 제2 매니폴드에서 적어도 두개의 샘플 데이터(예: anchor data point, positive data point)를 지정하고, 제1 매니폴드에서 적어도 하나의 샘플 데이터(예: negative data point)를 지정할 수 있다. 또한, 컴퓨팅 장치는 매니폴드 적어도 두개의 샘플 데이터 및 제1 매니폴드의 적어도 하나의 샘플 데이터 사이의 각도를 좁히도록 가상 데이터를 생성할 수 있다. 또한, 컴퓨팅 장치는 상술한 각도 조정 기반의 학습 조건(예: cosine similarity loss)을 매니폴드 상의 데이터 포인트들 각각에 적용함으로써 제1 모델 및/또는 제2 모델의 파라미터를 최적화할 수 있다. 상술한 생성형 이미징 모델 구축 방법을 통해, 컴퓨팅 장치는 실제 데이터와 유사한 임베딩을 나타내면서, 실제 데이터에 존재하지 않는 데이터를 생성하도록 생성형 이미징 모델을 학습할 수 있다. 도 58은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 이용하여 데이터를 처리하는 방법을 도 시한 흐름도이다. 도 58을 참조하면, 컴퓨팅 장치는 제1 데이터 셋 획득할 수 있다(S5801). 또한, 컴퓨팅 장치는 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다(S5803). 또한, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 잠재 코드(latent code)를 결정할 수 있다(S5805). 이때, 잠재 코드(또는 잠재 벡터(latent vector) 또는 잠재 변수(latent variable) 등)는 데이터의 잠재적인 특징을 나타내는 용어로서, 임베딩 공간(또는 잠재 공간(latent space) 또는 특징맵(feature map) 등)에 나타나는 적어 도 하나의 벡터(또는 변수, 파라미터 등)를 의미할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 제1 임베딩 공간 상에 데이터의 생성이 필요한 적어 도 하나의 영역에 대응되는 변수를 결정함으로써 잠재 코드를 결정할 수 있다. 컴퓨팅 장치는 제1 데이터 포인 트 셋을 기초로 적어도 하나의 특성(예: 밀도)이 미리 정해진 조건에 부합하는지 여부에 따라 잠재 코드를 결정 할 수 있다. 예를 들어, 컴퓨팅 장치는 데이터의 밀도를 기초로 제1 데이터 포인트 셋 상에 데이터가 부족한 영 역의 잠재 코드를 예측할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 데이터의 밀도가 미리 정해진 임계 값 이하인 적어도 하나의 영역에 대응되는 잠재 코드를 연산할 수 있으나, 이에 한정되지 않 는다. 또한, 컴퓨팅 장치는 잠재 코드를 기초로 가상 데이터 셋을 생성할 수 있다(S5807). 예를 들어, 컴퓨팅 장치는 생성기(Generator)를 이용하여, 잠재 코드를 기초로 가상 데이터 셋을 생성할 수 있다. 또한, 컴퓨팅 장치는 가상 데이터 셋 및 제1 데이터 셋을 기초로 제2 데이터 포인트 셋 - 제2 데이터 포인트 셋 은 가상 데이터 셋에 대응되는 제1 서브 데이터 포인트 셋 및 제1 데이터 포인트 셋에 대응되는 제2 서브 데이 터 포인트 셋을 포함함 -을 식별할 수 있다(S5809). 구체적으로, 컴퓨팅 장치는 가상 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 서브 데이터 포인트 셋을 식별할 수 있다. 또한, 컴퓨팅 장치는 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제2 서브 데이터 포인트 셋을 식별할 수 있다. 이 경우, 제2 서브 데이터 포인트 셋은 제1 데이터 포인트 셋에 대응될 수 있다. 또한, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋 및 제2 서브 데 이터 포인트 셋을 식별함으로써 제1 임베딩 공간에서 제2 데이터 포인트 셋을 식별할 수 있다. 또한, 컴퓨팅 장치는 제2 데이터 포인트 셋을 기초로 가상 데이터 셋 및 제1 데이터 셋에 대응되는 데이터 이미 지 - 데이터 이미지는 제1 서브 데이터 포인트 셋에 대응되는 제1 서브 데이터 이미지 및 제2 서브 데이터 포인 트 셋에 대응되는 제2 서브 데이터 이미지를 포함함 -를 획득할 수 있다(S5811). 구체적으로, 컴퓨팅 장치는 제 2 데이터 포인트 셋을 이미징 공간에 나타냄으로써 데이터 이미지를 획득할 수 있다. 이 경우, 이미징 공간은 제1 임베딩 공간에 대응될 수 있다. 또는, 이미징 공간은 데이터를 시각화(visualization)하기 위한 공간일 수 있다. 도 59는, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 이용하여 데이터를 처리하는 예시를 도 시한 도면이다. 도 59를 참조하면, 컴퓨팅 장치는 적어도 하나의 (사전 학습된) 인공 지능 모델을 포함하는 생성형 이미징 모델 을 이용하여, 가상 데이터를 생성하고, 데이터를 이미징(또는 시각화)할 수 있다. 컴퓨팅 장치는 제1 데이터 셋을 제1 사전 학습된 모델에 입력할 수 있다. 컴퓨팅 장치는 제1 사전 학습된 모델을 이용하여, 제1 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋 을 식별할 수 있다. 컴퓨팅 장치는 적어도 하나의 연산 장치를 이용하여, 제1 데이터 포인트 셋을 기초로 잠재 코드 (latent code)를 결정할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 데이터 포인트 셋의 분포가 균일해지기 위한 적어도 하나의 특징 값을 도출함으로써 잠재 코드를 결정할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 데이 터 포인트 셋을 기초로 데이터의 불균일성을 야기하는 적어도 하나의 영역(5903-1)(예: 제1 임베딩 공간 상에서 밀도가 상대적으로 낮은 영역 등)에 대응되는 잠재 코드를 연산할 수 있다. 컴퓨팅 장치는 잠재 코드를 제2 사전 학습된 모델에 입력할 수 있다. 컴퓨팅 장치는 제2 사전 학습된 모 델을 이용하여, 잠재 코드를 기초로 가상 데이터 셋을 생성할 수 있다. 이때, 제2 가상 데이터 셋 은 제1 데이터 셋에 대응되는 도메인(domain)을 가질 수 있다. 컴퓨팅 장치는 제1 데이터 셋 및 가상 데이터 셋을 제3 사전 학습된 모델에 입력할 수 있다. 컴퓨팅 장치는 제3 사전 학습된 모델의 적어도 하나의 계층을 이용하여, 가상 데이터 셋을 기초로 제1 서브 데이터 포인트 셋(5907, 또는 제1 서브 데이터 이미지)을 식별할 수 있다. 또한, 컴퓨팅 장치 는 제3 사전 학습된 모델의 적어도 하나의 계층을 이용하여, 제1 데이터 셋을 기초로 제2 서 브 데이터 포인트 셋(5909, 또는 제2 서브 데이터 이미지)을 식별할 수 있다. 이때, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋 및 제2 서브 데이터 포인트 셋을 기초로 제2 사전 학습된 모델 및 제3 사전 학습된 모델의 파라미터를 최적화할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋의 특성 및 제2 서브 데이터 포인트 셋의 특성이 유사해지도록 제2 사전학습된 모델 및 제3 사전 학습된 모델의 파라미터를 최적화할 수 있다. 즉, 컴퓨팅 장치는 제1 데 이터 포인트 셋의 적어도 하나의 영역(5903-1)에 대응되는 가상 데이터 셋을 생성할 수 있다. 또한, 컴퓨팅 장치는 제1 서브 데이터 포인트 셋 및 제2 서브 데이터 포인트 셋을 포함하는 제2 데 이터 포인트 셋을 기초로 데이터 이미지를 획득할 수 있다. 이를 통해, 컴퓨팅 장치는 데이터 셋 상에서 데이터가 필요한 영역을 식별하여 이에 대응되는 가상 데이터를 생 성하는 생성형 이미징 모델을 제공할 수 있고, 잠재 코드의 제어가 가능하면서도 고품질의 데이터를 생성하는 생성 모델을 제공할 수 있다. 도 60은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 최적화하여 데이터를 생성하는 방법을 도시한 흐름도이다. 도 61은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 최적화하여 데이터를 생성하는 예시를 도시한 도면이다. 도 60을 참조하면, 컴퓨팅 장치는 사전 학습된 생성 모델을 이용하여, 잠재 코드(latent code)를 기초로 제1 가 상 데이터 셋 생성할 수 있다(S6001). 이 경우, 잠재 코드는 임의로 설정될 수 있으나, 이에 한정되지 않는다. 예를 들어, 도 61을 참조하면, 컴퓨팅 장치는 제1 모델을 이용하여, 잠재 코드를 기초로 제1 가상 데이터 셋을 생성할 수 있다. 다시 도 60을 참조하면, 컴퓨팅 장치는 대상 데이터 셋을 특정 임베딩 공간에 매핑함으로써 대상 데이터 셋에 대응되는 제1 매니폴드 식별할 수 있다(S6003). 또한, 컴퓨팅 장치는 제1 가상 데이터 셋을 특정 임베딩 공간에 매핑함으로써 가상 데이터 셋에 대응되는 제2 매니폴드 식별할 수 있다(S6005). 예를 들어, 도 61을 참조하면, 컴퓨팅 장치는 대상 데이터 셋 및 제1 가상 데이터 셋을 제2 모델 에 입력할 수 있다. 컴퓨팅 장치는 제2 모델의 적어도 하나의 계층을 통해 대상 데이터 셋 에 대응되는 제1 매니폴드 및 제1 가상 데이터 셋에 대응되는 제2 매니폴드를 식별할 수 있다. 다시 도 60을 참조하면, 컴퓨팅 장치는 제1 매니폴드 및 제2 매니폴드를 기초로 제1 매니폴드 및 제2 매니폴드 의 유사도가 미리 정해진 조건을 만족하는지 여부를 확인할 수 있다(S6007). 이때, 컴퓨팅 장치는 미리 정해진 조건을 만족하지 않는 경우, 제1 매니폴드 및 제2 매니폴드의 매칭 정도에 연관되는 제1 지표를 산출하고, 제1 지표를 기반으로 사전 학습된 생성 모델의 파라미터를 최적화할 수 있다(S6009). 또한, 컴퓨팅 장치는 최적화된 생성 모델을 이용하여, 잠재 코드를 기초로 2 가상 데이터 셋을 생성할 수 있다(S6011). 예를 들어, 도 61을 참조하면, 컴퓨팅 장치는 적어도 하나의 연산기를 이용하여, 제1 매니폴드 및 제2 매니폴드의 유사도를 연산할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 매니폴드에 포함되는 적 어도 하나의 데이터 포인트 및 제2 매니폴드에 포함되는 적어도 하나의 데이터 포인트 사이의 기하학적 연관 관계를 기초로 제1 매니폴드 및 제2 매니폴드 사이의 매칭 정도에 연관되는 제1 지표(예: matching score)를 도출할 수 있으나, 이에 한정되지 않는다. 이 경우, 컴퓨팅 장치는 도출된 제1 지표를 기반으로 제1 모델의 파라미터를 최적화할 수 있다. 구체적으 로, 컴퓨팅 장치는 제1 매니폴드 및 제2 매니폴드가 미리 정해진 기준 이상의 유사도를 나타내도록 제1 모델의 파라미터를 조정함으로써 최적화된 생성 모델을 획득할 수 있다. 컴퓨팅 장치는 상술한 프로세스에 따라, 생성형 이미징 모델의 파라미터를 최적화함으로써, 대상 데이터의 품질 을 향상시키기 위한 가상 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는 인공 지능 학습 데이터의 품질을 향상시키기 위한 다양한 데이터 치 료 알고리즘들(예: 데이터 생성, 데이터 제거, 데이터 보정 등)을 제공할 수 있다. 컴퓨팅 장치는 데이터의 특 성을 정확히 진단함으로써 다양한 데이터 치료 알고리즘들 중 데이터의 품질 향상에 적합한 치료 알고리즘을 선 택적으로 적용할 수 있다. 도 62는, 다양한 실시예들에 따른, 컴퓨팅 장치가 적어도 하나의 데이터 처리 모델을 이용하여 데이터 셋의 품 질을 향상시키기 위한 예시를 도시한 도면이다. 도 62를 참조하면, 컴퓨팅 장치는 제1 모델을 이용하여, 데이터 셋을 기초로 제1 데이터 포인트 셋 (6220, 또는 제1 매니폴드)을 식별할 수 있다. 이때, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 데이터 셋에 포함되는 데이터의 적어도 하나 의 특성을 결정할 수 있고, 결정된 적어도 하나의 특성을 기반으로 데이터 처리 알고리즘을 결정할 수 있다. 구 체적으로, 컴퓨팅 장치는 데이터 셋의 특성을 개선함으로써 데이터 셋의 품질을 향상시키기 위해, 데이터를 생 성하거나, 데이터를 제거하거나, 데이터를 보정할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 데이터 포인트 셋이 나타나는 임베딩 공간 중 제1 서브 공간에 포함 되는 제1 서브 데이터 포인트 셋을 제1 모델(6201, 예: 데이터 다이어트 모델)에 입력할 수 있다. 이 경 우, 제1 서브 공간은 제1 특성(예: 밀도)이 상대적으로 높은 적어도 하나의 데이터 포인트가 나타나는 공 간일 수 있다. 즉, 컴퓨팅 장치는 제1 데이터 포인트 셋 상에서 밀도가 상대적으로 높은 적어도 하나의 서브 공간을 추출함으로써 제1 서브 공간을 식별할 수 있다. 컴퓨팅 장치는 제1 모델을 이용하여 제1 서브 데이터 포인트 셋을 기초로 보정된 제1 서브 데이터 포인트 셋을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 서브 데이터 셋에 포함되는 복수의 데이터 포인트들 중 적어도 일부를 제거함으로써 보정된 제1 서브 데이터 포인트 셋을 획득할 수 있다. 또한, 예를 들어, 컴퓨팅 장치는 제1 데이터 포인트 셋이 나타나는 임베딩 공간 중 제2 서브 공간 에 포함되는 제2 서브 데이터 포인트 셋을 제2 모델(6202, 예: 데이터 생성 모델)에 입력할 수 있다. 이 경우, 제2 서브 공간은 제1 특성(예: 밀도)이 상대적으로 낮은 적어도 하나의 데이터 포인트가 나타나는 공간일 수 있다. 즉, 컴퓨팅 장치는 제1 데이터 포인트 셋 상에서 밀도가 상대적으로 낮은 적어도 하나의 서브 공간을 추출함으로써 제2 서브 공간을 식별할 수 있다. 컴퓨팅 장치는 제2 모델을 이용하여, 제2 서브 데이터 포인트 셋을 기초로 보정된 제2 서브 데이터 포인트 셋을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 제2 서브 공간 상의 임의의 영역에 대응 되는 잠재 코드를 기초로 데이터를 생성함으로써 보정된 제2 서브 데이터 포인트 셋을 획득할 수 있다. 또한, 예를 들어, 컴퓨팅 장치는 제1 데이터 포인트 셋이 나타나는 임베딩 공간 중 제3 서브 공간 에 포함되는 제3 서브 데이터 포인트 셋을 제3 모델(6203, 예: 데이터 조정 모델)에 입력할 수 있다. 이 경우, 제3 서브 공간은 제2 특성(예: 클래스)이 상이한 데이터 그룹들(예: 라벨링 데이터, 클러스터 등) 사이의 경계에 위치한 데이터 포인트가 나타나는 공간일 수 있다. 즉, 컴퓨팅 장치는 제1 데이터 포인트 셋 상에서 클래스가 서로 상이한 데이터 포인트들이 위치하는 적어도 하나의 서브 공간을 추출함으로써 제3 서브 공간을 식별할 수 있다. 컴퓨팅 장치는 제3 모델을 이용하여, 제3 서브 데이터 포인트 셋을 기초로 보정된 제3 서브 데이터 포인트 셋을 획득할 수 있다. 구체적으로, 컴퓨팅 장치는 제3 서브 공간에 포함되는 복수의 데이터 포인트들 중 적어도 하나의 데이터 포인트의 특징 값을 조정함으로써 보정된 제3 서브 데이터 포인트 셋 을 획득할 수 있다. 도 63은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋의 특성을 기초로 적어도 하나의 데이터 처리 모델 에 입력하기 위한 파이프라인을 설명하기 위한 도면이다. 도 63을 참조하면, 컴퓨팅 장치는 데이터 셋을 획득할 수 있다(S6301). 또한, 컴퓨팅 장치는 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다(S6303). 또한, 컴퓨팅 장치는 적어도 하나의 진단 메트릭이 설정된 스크리닝 모듈을 이용하여, 제1 데이터 포인트 셋을 스크리닝할 수 있다(S6305). 구체적으로, 컴퓨팅 장치는 데이터의 적어도 하나의 특성 값을 연산하기 위한 적어 도 하나의 진단 메트릭이 설정된 스크리닝 모듈을 제1 데이터 포인트 셋에 적용할 수 있다. 이를 통해, 컴퓨팅 장치는 제1 데이터 포인트 셋에 포함되는 데이터의 적어도 하나의 특성을 결정할 수 있다. 컴퓨팅 장치는 적어도 하나의 서브 데이터 포인트 셋에 대한 진단 결과를 기초로, 적어도 하나의 서브 데이터 포인트 셋을 데이터 생성에 연관되는 제1 모델, 데이터 제거에 연관되는 제2 모델 또는 데이터 보정에 연관되는제3 모델 중 적어도 하나에 입력할 수 있다(S6307). [Integration Data Clinic Model and Large Language Model] 자연어 처리를 위한 머신 러닝 모델에는 자연어에서 정보를 추론하는 것을 목표로 하는 자연어 이해 모델과 일 부 입력을 기반으로 자연어를 생성하는 것을 목표로 하는 자연어 생성 모델이 있다. 자연어 이해 모델에 대한 훈련 예제는 특정 작업을 지향할 수 있다. 예를 들어, 여러 목적지로의 여행을 요청하는 사용자 발화를 이해하 도록 자연어 이해 모델을 훈련하려면 레이블이 지정된 훈련 예제로 구성된 작업별 코퍼스(corpus)를 사용할 수 있다. 이러한 코퍼스에는 사람이 레이블을 붙인 다양한 사용자 발화 예시가 포함될 수 있으며, 레이블에는 의도 레이블(예: 항공편 예약, 대중교통 찾기 등)과 슬롯 레이블(예: 출발지 및 도착지)이 포함될 수 있다. 본 개시 의 목적상, \"발화(utterance)\" 또는 \"자연어 입력\"이라는 용어는 사용자 또는 기계가 말하는 단어뿐만 아니라 텍스트, 수화 등을 사용하여 전달되는 단어도 포함한다는 점에 유의한다. 많은 경우, 작업 적응형 언어 이해 모델을 훈련하기 위해 불충분한 인간 라벨링 훈련 예제를 쉽게 이용할 수 있 다. 다시 말해, 이용 가능한 예시만을 사용하여 훈련된 모델은 해당 작업에 사용될 때 성능이 저하될 가능성이 높다. 공개된 구현에서는 생성 모델을 사용하여 실제 사용자가 만든 훈련 예제 대신 또는 추가로 사용할 수 있 는 합성 작업별 훈련 예제를 생성하는 접근 방식을 제공합니다. 본 개시에서 \"합성(synthetic)\"이라는 용어는 적어도 부분적으로 기계가 생성한 것을 의미한다. 본 개시에 설명된 바와 같이, 생성 모델을 사용하여 자연어 이해 모델을 위한 훈련 데이터를 생성하는 것은, 합성 훈련 예제에 인간 사용자가 라벨을 붙일 필요가 없기 때 문에, 상대적으로 저렴한 비용으로 적절한 학습 데이터를 대량으로 제공할 수 있다. 생성 모델을 훈련하기 위한 기존의 기법들은 반드시 작업별 훈련 예제를 생성하는 데 특히 유용한 생성 모델을 생성하지는 않는다. 예를 들어, 생성 모델의 비지도 훈련을 수행하는 한 가지 방법은 모델이 이미 본 이전 단어 가 주어진 시퀀스에서 다음 단어를 예측하도록 모델을 훈련하는 것이다. 그러나 이러한 생성 모델에 사용되는 훈련 데이터가 범용 코퍼스(예: Wikipedia 기사, 책, 웹 기사 등)인 경우, 학습된 생성 모델은 범용 코퍼스의 텍스트와 유사한 텍스트를 생성하는 방법을 학습하게 됩니다. 이러한 접근 방식은 합리적인 발화를 생성하는 생 성 모델을 얻는 데 사용될 수 있지만, 그러한 모델은 특정 자연어 시나리오에 대한 유용성이 부족할 수 있다. 예를 들어, \"대화 행위\"는 대화형 봇이나 디지털 비서와 같은 사용자 대면 애플리케이션에 많은 유용성을 가지 고 있다. 이러한 자동화된 애플리케이션은 자연어 이해 모델을 사용하여 수신된 사용자 발화를 해석할 수 있으 며, 예를 들어, 사용자가 말하거나 입력한 단어로부터 의도와 슬롯 값을 유추할 수 있다. 또한, 이러한 자동화 된 애플리케이션은 생성 모델을 사용하여 사용자에 대한 응답 발화를 생성할 수 있다. 그러나, 범용 코퍼스(예컨대, 위키피디아 기사)에 대해 훈련된 생성 모델은 사용자 대면 시나리오에서 대화 행 위에 적합한 합성 발화를 생성하는 데 특히 능숙하지 않을 수 있다. 더욱이, 그러한 모델에 의해 생성된 가상 데이터(예: 합성 발화)는 대화 기반 시스템에 대한 사용자 요청과 매우 유사하지 않을 수 있으며, 따라서 사용 자 대화를 이해하기 위해 사용될 자연어 이해 모델의 합성 훈련 데이터로서 특히 유용하지 않을 수 있다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는 상술한 자연어 처리 모델(예: 자연어 이해 모델 또는 생성 모델)을 이용하여 학습 데이터의 품질을 향상시키기 위한 가상 데이터(synthetic data)를 제공할 수 있다. 도 64는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 진단 데이터를 기반으로 가상 데이터를 생성하는 방법 을 도시한 도면이다. 도 64를 참조하면, 컴퓨팅 장치는 제1 모델을 이용하여, 데이터 셋을 기초로 제1 데이터 포인트 셋 을 식별할 수 있다. 여기서, 제1 모델은 제1 데이터 셋에 포함된 데이터의 분포를 나타내기 위한 데이터 이미징 모델일 수 있다. 또한, 컴퓨팅 장치는 진단 메트릭이 설정된 연산기를 이용하여, 제1 데이터 포인트 셋을 기초로 제 1 진단 데이터를 획득할 수 있다. 이때, 제1 진단 데이터는 제1 데이터 셋의 특성을 나타내는 발화 (utterance) 데이터를 포함할 수 있다. 또는, 제1 진단 데이터는 제1 데이터 셋의 품질(quality)을 나타 내는 발화 데이터를 포함할 수 있다. 또는, 제1 진단 데이터는 제1 데이터 셋의 치료(예: 생성, 제거, 보정 등)가 필요한 사항을 나타내는 발화 데이터를 포함할 수 있다. 예를 들어, 제1 진단 데이터는\"A 클래스를 가 지는 데이터 부족\" \"A 클래스의 데이터 생성 필요\", \"B 클래스 데이터가 과도하게 많음\", \"B 클래스의 데이터 제거 필요\", \"C 클래스의 데이터와 D 클래스의 데이터의 경계가 모호함\", 또는 \"C 클래스 데이터와 D 클래스를 구별하기 위한 데이터 필요\" 등의 데이터 셋의 품질에 대한 진단 결과를 나타내는 발화 데이터를 포함하는 제1 진단 데이터를 획득할 수 있다. 또한, 컴퓨팅 장치는 제1 모델을 이용하여, 제1 진단 데이터를 기초로 프롬프트(prompt) 데이터를 획득할 수 있다. 이때, 제1 모델은 자연어 처리(예: 자연어 이해 또는 추론 등) 모델(NLP) 또는 거대 언어 모델 (LLM) 등을 포함할 수 있다. 여기서, 프롬프트 데이터는 머신 러닝 모델을 이용하여 결과물을 획득하기 위해 구 성되는 입력 데이터를 의미할 수 있다. 예시적으로, 프롬프트 데이터는 데이터 생성 모델로부터 응답을 생성하 기 위해 입력되는 명령어 집합을 의미할 수 있다. 구체적인 예로, 자연어 처리 모델에서, 프롬프트 데이터는 시 퀀스 템플릿(template), 라벨(label) 및 워드(word)를 통칭하는 용어이다. 컴퓨팅 장치는 제2 모델을 이용하여 생성하고자 하는 데이터의 유형(예: 도메인, 모달리티, 클래스 등)에 적합한 프롬프트를 생성하도록 설정될 수 있다. 여기서, 제2 모델은 데이터를 생성하기 위한 생성형 인공 지능 모델(Generative AI)을 포함할 수 있다. 컴퓨팅 장치는 제1 진단 데이터를 기반으로 생성하고자 하는 데이 터의 유형을 결정할 수 있고, 결정된 데이터의 유형에 따라 프롬프트 데이터를 생성할 수 있다. 또한, 컴퓨팅 장치는 생성된 프롬프트 데이터를 제2 모델에 입력할 수 있다. 이에 따라, 컴퓨팅 장치는 제2 모델(644 0)을 이용하여 프롬프트 데이터를 기초로 가상 데이터 셋을 생성할 수 있다. 도 65는, 다양한 실시예들에 따른, 컴퓨팅 장치가 사전 학습된 머신 러닝 모델을 이용하여 가상 데이터를 생성 하는 방법을 도시한 흐름도이다. 도 65를 참조하면, 컴퓨팅 장치는 제1 데이터 셋을 획득할 수 있다(S6501). 또한, 컴퓨팅 장치는 사전 학습된 제1 모델을 이용하여, 데이터 셋을 제1 임베딩 공간에 매핑함으로써 제1 데이터 포인트 셋을 식별할 수 있다 (S6503). 또한, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 제1 데이터 셋의 적어도 하나의 특성에 연관된 제1 진단 데이터를 획득할 수 있다(S6505). 또한, 컴퓨팅 장치는 제1 진단 데이터를 기반으로 프롬프트 데이터 를 생성할 수 있다(S6507). 또한, 컴퓨팅 장치는 사전 학습된 제2 모델을 이용하여, 프롬프트 데이터를 기초로 제1 가상 데이터 셋을 생성할 수 있다(S6509). 다시 도 64를 참조하면, 컴퓨팅 장치는 데이터 셋의 진단 결과에 따라 적합한 데이터가 생성되었는지 여 부를 검증할 수 있다. 구체적으로, 컴퓨팅 장치는 생성된 가상 데이터 셋이 미리 정해진 기준을 만족하는 지 여부를 검증할 수 있다. 예를 들어, 컴퓨팅 장치는 생성된 가상 데이터 셋이 제1 진단 데이터에 따른 결과에 대응되는지 여부를 식별함으로써 상기 검증을 수행할 수 있다. 일 예로, 컴퓨팅 장치는 데이터 이미징 모델을 이용하여 가상 데이터 셋을 이미징함으로써 생성이 요청되는 데이터가 생성되었는지 여부를 검증할 수 있다. 도 66은, 다양한 실시예들에 따른, 컴퓨팅 장치가 가상 데이터 셋의 적합성을 검증하기 위한 방법의 일 예시를 도시한 흐름도이다. 도 66을 참조하면, 컴퓨팅 장치는 도 65의 동작 S6509에 따라 가상 데이터 셋을 생성할 수 있다. 또한, 컴퓨팅 장치는 제1 임베딩 공간 상의 적어도 하나의 타겟팅 영역을 식별할 수 있다(S6601). 구체적으로, 제1 진단 데이터를 기반으로 제1 임베딩 공간 상에서 데이터 생성이 필요한 적어도 하나의 영역을 식별함으로써 타겟팅 영역을 식별할 수 있다. 예를 들어, 도 64를 참조하면, 컴퓨팅 장치는 제1 데이터 포인트 셋에 대응되는 제1 진단 데이터를 기초 로 임베딩 공간 상의 제1 영역(6407a)을 타겟팅 영역으로 식별할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 진단 데이터를 기초로 생성이 필요한 데이터의 특성을 결정할 수 있고, 결정된 특성에 대응되는 적어도 하나의 영역 을 특정함으로써 타겟팅 영역을 식별할 수 있다. 다시 도 66을 참조하면, 사전 학습된 제1 모델을 이용하여, 제1 가상 데이터 셋을 제1 임베딩 공간에 매핑함으 로써 제1 서브 데이터 셋을 식별할 수 있다(S6603). 또한, 컴퓨팅 장치는 제1 서브 데이터 셋 및 상기 적어도 하나의 타겟팅 영역과의 연관성을 확인할 수 있다(S6605). 이 경우, 컴퓨팅 장치는 제1 서브 데이터 셋 및 상기 적어도 하나의 타겟팅 영역과의 연관성이 미리 정해진 기 준을 충족하는 지 여부를 확인할 수 있다(S6607). 예를 들어, 컴퓨팅 장치는 제1 서브 데이터 셋이 타겟팅 영역 에 대응되는 정도를 기초로 미리 정해진 기준을 설정할 수 있다. 또는, 컴퓨팅 장치는 제1 서브 데이터 셋이 제 1 임베딩 공간 상에 차지하는 영역과 타겟팅 영역이 오버랩되는 정도를 기초로 미리 정해진 기준을 설정할 수 있다. 미리 정해진 기준을 충족하는 경우, 컴퓨팅 장치는 적합한 가상 데이터가 생성된 것으로 판단하여 검증 알고리 즘을 종료할 수 있다. 미리 정해진 기준을 충족하지 않는 경우, 컴퓨팅 장치는 사전 학습된 제2 모델의 파라미터 조정하여 조정된 (tuned) 제2 모델을 획득할 수 있다(S6609). 또는, 컴퓨팅 장치는 프롬프트 데이터에 오류가 있는 것으로 판단 할 수 있고, 이 경우, 자연어 처리 모델의 파라미터를 조정할 수 있다. 또한, 컴퓨팅 장치는 조정된 제2 모델을 이용하여, 제1 진단 데이터를 기초로 제2 가상 데이터 셋 생성할 수 있다(S6611). 예를 들어, 도 64를 참조하면, 컴퓨팅 장치는 가상 데이터 셋에 대응되는 서브 데이터 포인트 셋이 제1 임베딩 공간 상에 제2 영역(6407b)에 나타나는 것을 식별할 수 있다. 컴퓨팅 장치는 서브 데이터 포인트 셋이 차지하는 제2 영역(6407b)이 타겟팅 영역인 제1 영역(6407a)과 연관되지 않는다고 결정할 수 있다. 이 경우, 미 리 정해진 기준이 충족되지 않는 것으로 판단하여, 제1 모델 또는 제2 모델 중 적어도 하나의 파라 미터를 조정함으로써 모델을 최적화할 수 있다. 또는, 컴퓨팅 장치는 연산기를 이용하여, 생성된 가상 데이터 셋 및 제1 데이터 셋 사이의 연관성에 관한 지표(예: matching score 등)를 도출할 수 있다. 컴퓨팅 장치는 연관성에 관한 지표를 기반으로 제1 모델 또는 제2 모델 중 적어도 하나의 파라미터를 조정함으로써 모델을 최적화할 수 있다. 다른 예로, 컴퓨팅 장치는 생성된 가상 데이터 셋을 포함하는 데이터 셋의 특성을 판단하여 품질이 향상 되었는지 여부를 검증할 수 있다. 도 67은, 다양한 실시예들에 따른, 컴퓨팅 장치가 가상 데이터 셋의 적합성을 검증하기 위한 방법의 다른 일 예 시를 도시한 흐름도이다. 도 67을 참조하면, 컴퓨팅 장치는 제1 데이터 셋 및 제1 가상 데이터 셋을 포함하는 제2 데이터 셋을 사전 학습 된 제1 모델에 입력할 수 있다(S6701). 또한, 컴퓨팅 장치는 사전 학습된 제1 모델을 이용하여, 제2 데이터 셋 을 제1 임베딩 공간에 매핑함으로써 제2 데이터 포인트 셋을 식별할 수 있다(S6703). 또한, 컴퓨팅 장치는 제2 데이터 포인트 셋을 기초로 제2 데이터 셋의 적어도 하나의 특성에 연관된 제2 진단 데이터를 획득할 수 있다 (S6705). 또한, 컴퓨팅 장치는 제2 진단 데이터를 기초로 미리 정해진 기준을 만족하는지 여부를 판단할 수 있 다(S6707). 미리 정해진 기준이 충족되는 경우, 컴퓨팅 장치는 적합한 가상 데이터가 생성된 것으로 판단하여 검증 알고리 즘을 종료할 수 있다. 미리 정해진 기준을 충족하지 않는 경우, 컴퓨팅 장치는 사전 학습된 제2 모델의 파라미터 조정하여 조정된 (tuned) 제2 모델을 획득할 수 있다(S6709). 또는, 컴퓨팅 장치는 프롬프트 데이터에 오류가 있는 것으로 판단 할 수 있고, 이 경우, 자연어 처리 모델의 파라미터를 조정할 수 있다. 또한, 컴퓨팅 장치는 조정된 제2 모델을 이용하여, 제1 진단 데이터를 기초로 제2 가상 데이터 셋 생성할 수 있다(S6711). 예를 들어, 도 64를 참조하면, 컴퓨팅 장치는 생성된 가상 데이터 셋 및 제1 데이터 셋을 포함하는 제2 데이터 셋을 기초로 제2 진단 데이터를 획득할 수 있다. 컴퓨팅 장치는 제2 진단 데이터를 분석하여 생성된 가상 데이터 셋이 미리 정해진 기준(예: 생성 제약 조 건)을 만족하는지 여부를 판단할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 진단 데이터 및 제2 진단 데이터를 비교하여, 데이터의 품질이 향상되었는지 여부를 판단할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 진단 데이터에 포함되는 데이터의 품질과 연관된 정보 및 제2 진단 데이터에 포함되는 데이터의 품질과 연관된 정보를 비교할수 있다. 이 경우, 컴퓨팅 장치는 제2 진단 데이터를 기반으로 판단되는 데이터의 품질이 제1 진단 데이터를 기 반으로 판단되는 데이터의 품질보다 높은 경우, 미리 정해진 기준을 충족하는 것으로 결정할 수 있다. 컴퓨팅 장치가 가상 데이터 셋이 미리 정해진 기준을 만족하지 않는 것으로 판단한 경우, 이를 기초로 제 1 모델 또는 제2 모델 중 적어도 하나의 파라미터를 조정함으로써 모델을 최적화할 수 있다. 도 68은, 다양한 실시예들에 따른, 컴퓨팅 장치가 언어 입력을 기반으로 데이터 이미지를 수정함으로써 가상 데 이터를 생성하기 위한 방법을 도시한 도면이다. 도 68을 참조하면, 컴퓨팅 장치는 데이터 이미징 모델을 이용하여, 제1 데이터 셋을 이미징 공간에 나타냄으로써 제1 데이터 이미지을 획득할 수 있다. 이때, 제1 데이터 이미지는 제1 데이터 셋 의 내재적 특성을 반영하도록 획득될 수 있다. 컴퓨팅 장치는 사용자 디바이스로부터 발화 입력(예: text input) 및 제1 데이터 이미지에 대한 사용자 입력을 수신할 수 있다. 이때, 제1 데이터 이미지에 대한 사용자 입력은, 제1 데이터 이미지 상에 서 데이터의 생성이 필요한 영역에 연관된 사용자 입력일 수 있다. 예를 들어, 컴퓨팅 장치는 제1 데이터 이미 지의 적어도 일부 영역이 마스킹된 데이터 이미지를 획득할 수 있다. 이 경우, 컴퓨팅 장치는 제1 모델을 이용하여, 입력된 발화 데이터를 기초로 프롬프트를 생성할 수 있다. 이때, 프롬프트는 제1 데이터 이미지 상의 적어도 일부 영역에 대응되는 데이터의 생성에 연관될 수 있다. 구체적으로, 컴퓨팅 장치는 입력된 발화 데이터를 기초로 제1 데이터 이미지의 적어도 일부 영역 에 생성할 데이터의 특성(또는 유형)에 연관되는 프롬프트 데이터를 생성할 수 있다. 예를 들어, 컴퓨팅 장치는 사용자 입력으로부터 \"[라면]을 나타내는 [음식 이미지 데이터]를 [X장][생성]\"하라는 프롬프트를 생성 할 수 있으나, 이에 한정되지 않는다. 또한, 컴퓨팅 장치는 프롬프트 및 적어도 일부 영역이 마스킹된 제1 데이터 이미지를 생성 모델에 입력할 수 있다. 컴퓨팅 장치는 생성 모델을 이용하여, 프롬프트 및 적어도 일부 영역이 마스킹된 제1 데이터 이미 지를 기초로 제2 데이터 이미지를 생성할 수 있다. 이때, 제2 데이터 이미지는 가상 인스턴스들에 대응되는 특정 영역을 포함할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 데이터 이미지의 적어도 일부 영 역에 적어도 하나의 가상 인스턴스(또는 데이터 포인트, 특징 벡터 등)를 생성함으로써 특정 영역 을 포함하는 제2 데이터 이미지를 획득할 수 있다. 예를 들어, 컴퓨팅 장치는 제1 데이터 이미지의 적어도 일부 영역에 대응되는 데이터의 특징 값들을 기반으로 가상 인스턴스들을 생성할 수 있고, 가상 인스턴스들의 임베딩 공간 상의 위치를 표시함으로써 특정 영역을 식별할 수 있다. 이 경우, 컴퓨팅 장치는 제2 데이터 이미지의 특정 영역에 대응되는 가상 인스턴스들에 대응되는 잠재 코드(latent code)를 식별할 수 있다. 구체적으로, 컴퓨팅 장치는 특정 임베딩 공간 상에서 특정 영역 에 대응되는 적어도 하나의 특징 값들을 생성함으로써 잠재 코드를 식별할 수 있으나, 이에 한정되지 않 는다. 또한, 컴퓨팅 장치는 식별된 잠재 코드를 사전 학습된 생성 모델에 입력할 수 있다. 컴퓨팅 장치는 생성 모델을 이용하여, 잠재 코드를 기반으로 가상 데이터 셋을 획득할 수 있다. 이를 통해, 컴퓨팅 장치는 자연어 입력뿐만 아니라, 데이터의 분포가 시각적으로 확인되는 데이터 이미지 상에 서 입력을 기반으로 사용자의 의도(intent)를 정확히 파악할 수 있고, 의도에 대응되는 가상 데이터를 생성할 수 있는 것이다. 도 69는, 다양한 실시예들에 따른, 컴퓨팅 장치가 언어 입력을 기반으로 데이터 이미지를 수정함으로써 가상 데 이터를 생성하기 위한 방법을 도시한 흐름도이다. 도 69를 참조하면, 컴퓨팅 장치는 데이터 셋 획득할 수 있다(S6901). 또한, 컴퓨팅 장치는 사전 학습된 제1 모 델을 이용하여, 데이터 셋에 대응되는 제1 데이터 이미지를 획득할 수 있다(S6903). 또한, 컴퓨팅 장치는 사용자 입력으로부터 획득된 프롬프트 데이터 및 제1 데이터 이미지를 사전 학습된 제2 모 델에 입력할 수 있다(S6905). 이 경우, 제1 데이터 이미지의 적어도 일부분이 마스킹되어 있을 수 있다. 구체적 으로, 컴퓨팅 장치는 사용자 입력으로부터 적어도 일부 영역이 마스킹된 제1 데이터 이미지를 프롬프트 데이터 와 함께 제2 모델에 입력할 수 있다. 또한, 컴퓨팅 장치는 사전 학습된 제2 모델을 이용하여, 제1 데이터 이미지의 적어도 일부가 수정된 제1 수정된 데이터 이미지를 획득할 수 있다(S6907). 또한, 컴퓨팅 장치는 제1 수정된 데이터 이미지를 기초로 잠재 코드를 획득하여, 잠재 코드를 사전 학습된 제3 모델에 입력할 수 있다(S6909). 또한, 컴퓨팅 장치는 제3 모델을 이용하여, 잠재 코드를 기초로 제1 가상 데이 터 셋을 획득할 수 있다(S6911). 본 개시의 일 실시예에 따른 컴퓨팅 장치는 사용자의 자연어 입력을 기반으로 데이터를 생성하기 위한 적어도 하나의 머신러닝 모델을 포함할 수 있다. 이 경우, 컴퓨팅 장치는 보조 네트워크로 활용함으로써 언어를 기반으 로 생성한 가상 데이터의 품질을 평가하고, 향상시킬 수 있다. 도 70은, 다양한 실시예들에 따른, 컴퓨팅 장치가 발화 데이터에 기반하여 가상 데이터를 생성하기 위한 방법을 도시한 도면이다. 도 70을 참조하면, 컴퓨팅 장치는 제1 모델을 이용하여, 발화 데이터를 기반으로 프롬프트 데이터를 생성 할 수 있다. 이때, 컴퓨팅 장치는 발화 데이터를 기반으로 의도(intent)를 파악하여 생성하고자 하는 가상 데이 터의 특성(예: 모달리티, 도메인 등)을 결정할 수 있다. 구체적으로, 컴퓨팅 장치는 발화 데이터에 포함되는 적 어도 하나의 엔티티(entity)를 기반으로 발화 의도를 파악할 수 있고, 이를 기초로 가상 데이터 생성을 위한 프 롬프트 데이터를 생성할 수 있다. 또한, 컴퓨팅 장치는 생성 모델을 이용하여, 프롬프트 데이터를 기초로 가상 데이터 셋을 생성할 수 있다. 이 경우, 컴퓨팅 장치는 적어도 하나의 보조 네트워크(7030, 7040)를 이용하여 가상 데이터 셋의 품질을 평가할 수 있다. 일 예로, 컴퓨팅 장치는 태스크 수행을 위한 제1 보조 네트워크(7030, Aux(t))를 이용하여 가상 데이터 셋 의 품질을 평가할 수 있다. 이때, 제1 보조 네트워크는 가상 데이터 셋을 이용하여 학습시키 고자 하는 머신러닝 모델에 대응되도록 구현될 수 있다. 예를 들어, 컴퓨팅 장치는 특정 태스크를 수행하기 위 해 설계된 머신 러닝 모델을 로드(또는 전이 학습 등의 방법으로 구현)함으로써 제1 보조 네트워크를 저 장할 수 있다. 또는, 컴퓨팅 장치는 발화 데이터와 더불어, 사전 학습된 머신 러닝 모델을 수신할 수 있고, 수 신된 모델을 기초로 제1 보조 네트워크를 획득할 수 있다. 제1 보조 네트워크는 사전 학습 데이터 셋을 이용하여 사전 학습된 머신 러닝 모델일 수 있다. 컴퓨팅 장치는 생성된 가상 데이터 셋을 제1 보조 네트워크에 입력할 수 있다. 컴퓨팅 장치는 제1 보조 네트워크를 이용하여, 가상 데이터 셋을 기반으로 태스크를 수행할 수 있고, 이를 기초로 결 과 값을 출력할 수 있다. 이 경우, 컴퓨팅 장치는 상기 결과 값을 기초로 가상 데이터 셋의 품질을 평가할 수 있다. 예를 들어, 컴 퓨팅 장치는 태스크 수행 결과가 기 설정된 조건을 충족하지 못하는 경우, 가상 데이터 셋의 품질이 떨어 지는 것으로 판단하여, 적어도 하나의 모델(7010, 7020)의 파라미터를 조정할 수 있다. 또는, 컴퓨팅 장치는 가상 데이터 셋을 이용하여 기초로 사전 학습된 제1 보조 네트워크를 평가 (estimation)할 수 있다. 이 경우, 컴퓨팅 장치는 평가 결과를 기초로 사전 학습된 제1 보조 네트워크를 추가 학습할 지 여부를 결정할 수 있다. 예를 들어, 컴퓨팅 장치는 태스크 수행 결과가 기 설정된 조건을 충족 하지 못하는 경우, 제1 보조 네트워크의 학습이 부족한 것으로 판단하여, 가상 데이터 셋을 이용하 여 제1 보조 네트워크를 추가 학습할 수 있다. 다른 예로, 컴퓨팅 장치는 데이터 이미징을 위한 제2 보조 네트워크(7040, Aux(I))를 이용하여 가상 데이터 셋 의 품질을 평가할 수 있다. 이때, 제2 보조 네트워크는 본 개시의 데이터 이미징 모델에 대응되도록 구현될 수 있다. 컴퓨팅 장치는 제2 보조 네트워크를 이용하여 가상 데이터 셋 및 생성하고자 하는(의도에 부합하는) 데이터와의 연관성을 나타내는 비교 정보를 제공할 수 있다. 구체적으로, 컴퓨팅 장치는 생성된 가상 데이터 셋 및 비교 대상 데이터 셋을 제2 보조 네트워크 에 입력할 수 있다. 이때, 비교 대상 데이터 셋은 사용자 디바이스로부터 발화 데이터와 함께 수신 된 데이터 또는 가상 데이터 셋을 이용하여 학습하려는 머신 러닝 모델의 사전 학습 데이터(예: 7001)를 포함할 수 있다. 컴퓨팅 장치는 비교 대상 데이터 셋 및 가상 데이터 셋을 공통된 공간에 나타냄으로써 비교 대상 데이터 셋 및 가상 데이터 셋 사이의 연관성을 식별할 수 있도록 설정될 수 있다. 컴퓨팅 장치는 제2 보조 네트워크를 이용하여, 비교 대상 데이터 셋 및 가상 데이터 셋을 특 정 임베딩 공간에 매핑할 수 있다. 구체적으로, 컴퓨팅 장치는 비교 대상 데이터 셋을 특정 임베딩 공간에 매핑함으로써 비교 대상 데이터 셋의 특성을 반영하는 제1 데이터 포인트 셋을 식별할 수 있다. 또한, 컴퓨팅 장치는 가상 데이터 셋을 상기 특정 임베딩 공간에 매핑함으로써 가상 데이터 셋의 특성을 반영하는 제2 데이터 포인트 셋을 식별할 수 있다. 컴퓨팅 장치는 제1 데이터 포인트 셋 및 제2 데이터 포인트 셋을 공통된 공간에 나타냄으로써 비교 대상 데이터 셋 및 가상 데이터 셋 사이의 비교 정보를 제공할 수 있다. 또한, 컴퓨팅 장치는 제1 데이터 포인트 셋을 기초로 비교 대상 데이터 셋의 적어도 하나의 특성을 획득하고 제2 데이터 포인트 셋을 기초로 가상 데이터 셋의 적어도 하나의 특성을 획득함으로써 비 교 대상 데이터 셋 및 가상 데이터 셋 사이의 특성 비교 정보를 제공할 수 있다. 도 71은, 다양한 실시예들에 따른, 컴퓨팅 장치가 발화 데이터에 기반하여 가상 데이터를 생성하고, 비교 정보 를 제공하기 위한 방법을 도시한 흐름도이다. 도 71을 참조하면, 컴퓨팅 장치는 사용자 입력으로부터 획득된 프롬프트 데이터를 사전 학습된 제1 모델에 입력 할 수 있다(S7101). 또한, 컴퓨팅 장치는 제1 모델을 이용하여, 프롬프트 데이터를 기초로 가상 데이터 셋을 생 성할 수 있다(S7103). 또한, 컴퓨팅 장치는 비교 대상 데이터 셋 가상 데이터 셋을 제1 모델에 전자적으로 연결된 보조 네트워크에 입 력할 수 있다(S7105). 또한, 컴퓨팅 장치는 보조 네트워크를 이용하여, 비교 대상 데이터 셋 및 가상 데이터 셋 을 특정 임베딩 공간에 매핑할 수 있다(S7107). 또한, 컴퓨팅 장치는 비교 대상 데이터 셋에 대응되는 제1 데이터 포인트 셋 및 가상 데이터 셋에 대응되는 제2 데이터 포인트 셋을 식별할 수 있다(S7109). 또한, 컴퓨팅 장치는 제1 데이터 포인트 셋 및 제2 데이터 포인트 셋을 포함하는 데이터 비교 정보를 제공할 수 있다(S7111). 본 개시에 따른 컴퓨팅 장치는 거대 언어 모델을 기반으로 학습 데이터를 생성하려는 사용자에게 생성한 데이터 의 품질에 대한 정보를 정확히 제공함으로써 머신 러닝 모델의 학습 효율을 향상시키고 머신 러닝 모델의 태스 크 수행 능력을 발전시킬 수 있는 것이다. 도 72는, 다양한 실시예들에 따른, 컴퓨팅 장치에 포함되는 언어 기반 생성 모델 및 클리닉 모델을 도시한 도면 이다. 본 개시에 따른 컴퓨팅 장치가 품질 높은 가상 데이터를 생성하기 위해서는, 입력된 발화 데이터의 의도를 정확 히 파악하여 적합한 프롬프트를 생성하는 것이 중요하다. 머신 러닝 모델로부터 높은 수준의 결과물을 얻기 위해 적절한 프롬프트를 구성하는 프롬프트 엔지니어링 (Prompt Engineering)을 자동으로 수행하기 위해서는, 입력되는 발화를 기반으로 요구되는 데이터의 특성들을 결정하여, 해당 특성들을 반영하는 가상 데이터를 생성할 필요가 있다. 도 72의 (a)를 참조하면, 컴퓨팅 장치는 발화 데이터를 기반으로 적합한 프롬프트를 구성하기 위한 프롬프트 엔 지니어링 모델(Prompt Engineering Model) 및 프롬프트를 기반으로 가상 데이터를 생성하기 위한 생성 모델 (Generative Model)을 포함할 수 있다. 컴퓨팅 장치는 발화 데이터 및 생성 대상 데이터를 기반으로 프롬프트 엔지니어링 모델을 학습시킬 수 있다. 구 체적으로, 컴퓨팅 장치는 발화 데이터에 따라 생성해야 할 데이터를 이용하여 프롬프트 엔지니어링 모델을 학습 함으로써 발화 데이터에 연관되는 데이터의 특성에 대응되는 프롬프트를 구성하도록 구현될 수 있다. 컴퓨팅 장치가 발화의 의도에 대응되는 가상 데이터를 생성하기 위한 프롬프트를 구성하기 위해서는, 발화 데이 터를 기반으로 생성하고자 하는 데이터에 연관된 최소한의 정보를 도출해낼 필요가 있다. 예를 들어, 생성 모델 은 가상 데이터의 생성에 필요한 특성들에 대응되는 슬롯들을 채우기 위해, 입력된 프롬프트를 기반으로 데이터 의 적어도 하나의 특성을 결정할 수 있다. 이때, 가상 데이터의 생성에 필요한 슬롯들의 개수는 미리 정해질 수 있으나, 이에 한정되지 않는다. 도 72의 (b)를 참조하면, 본 개시에 따른 컴퓨팅 장치는 클리닉 모델(Clinic Model)의 입출력 데이터를 기반으 로 언어 기반 모델들(예: 거대 언어 모델, 프롬프트 엔지니어링 모델)을 보조 네트워크로 학습시켜서 고도화할 수 있다. 구체적으로, 데이터 클리닉 모델을 사전 학습된 언어 기반 모델들과 연동시키기 위해, 컴퓨팅 장치는 데이터 클 리닉 프로세스 상에서 획득되는 데이터를 기반으로 언어 기반 모델들을 추가 학습(예: fine tuning)할 수 있다. 예를 들어, 도 64에 도시된 실시예와 같이, 컴퓨팅 장치가 진단 데이터를 기반으로 가상 데이터를 생성하기 위 해서, 진단 데이터에 포함되는 적어도 하나의 코퍼스 및 이에 대응되는 데이터를 이용하여 언어 기반 모델들을 추가 학습시킬 수 있다. 또한, 예를 들어, 도 68에 도시된 실시예와 같이, 컴퓨팅 장치가 데이터 이미지를 기반으로 수정된 데이터 이미 지 및 가상 데이터를 생성하기 위해, 데이터 이미지 및 데이터 이미지에 연관되는 적어도 하나의 코퍼스를 이용 하여 언어 기반 모델들을 추가 학습시킬 수 있다. 도 73은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 클리닉 모델 및 언어 기반 모델을 이용하는 예시를 도 시한 도면이다. 도 73을 참조하면, 컴퓨팅 장치는 클리닉 모델을 포함할 수 있다. 클리닉 모델은 적어도 하나의 이 미징 모델(L1, L2) 및 적어도 하나의 생성 모델(Decoder or Generator)을 포함할 수 있다. 또한, 컴퓨팅 장치는 클리닉 모델과 통신하는 적어도 하나의 보조 네트워크(Aux(t). Aux(p))를 포함할 수 있다. 컴퓨팅 장치는 적어도 하나의 보조 네트워크를 이용하여 태스크를 수행하거나, 가상 데이터를 생성하기 위한 프롬프트를 생성하거나, 프롬프트를 기초로 가상 데이터를 생성할 수 있다. 컴퓨팅 장치는 적어도 하나의 데이터 이미징 모델을 이용하여, 입력 데이터(I)를 기초로 제1 데이터 이미지 (IOD1)를 획득할 수 있다. 또한, 컴퓨팅 장치는 태스크를 수행하기 위한 제1 보조 네트워크(Aux(t))를 이용하여, 제1 데이터 이미지를 기반으로 태스크를 수행할 수 있다. 또는, 컴퓨팅 장치는 적어도 하나의 데이터 이미징 모델을 이용하여 제2 데이터 이미지(IOD2)를 더 획득할 수 있다. 또한, 컴퓨팅 장치는 적어도 하나의 생성 모델을 이용하여, 입력 데이터를 기초로 가상 데이터(I`)를 생성할 수 있다. 또한, 컴퓨팅 장치는 프롬프트를 생성하기 위한 제2 보조 네트워크(Aux(p))를 이용하여, 가상 데이터를 기반으로 합성 프롬프트(P`)를 생성할 수 있다. 이때, 컴퓨팅 장치는 생성된 합성 프롬프트(P`) 및 정답 프롬프트(P)를 기초로 제2 보조 네트워크를 학습할 수 있다. 구체적으로, 컴퓨팅 장치는 합성 프롬프트가 정답 프롬프트와 유사해지도록 제2 보조 네트워크의 파라미 터를 최적화할 수 있다. 또한, 컴퓨팅 장치는 프롬프트를 기반으로 데이터를 생성하기 위한 제3 보조 네트워크(Aux(s))를 이용하여, 프 롬프트를 기반으로 가상 데이터를 생성할 수 있다. 구체적으로, 컴퓨팅 장치는 합성 프롬프트(P`)를 제3 보조네트워크에 입력할 수 있고, 제1 합성 데이터(D`)를 생성할 수 있다. 또한, 컴퓨팅 장치는 정답 프롬프트(P)를 제3 보조 네트워크에 입력할 수 있고, 제2 합성 데이터(D)를 생성할 수 있다. 컴퓨팅 장치는 제1 합성 데이터(D`) 및 제2 합성 데이터(D)를 기초로 제3 보조 네트워크 또는 제2 보조 네트워 크 중 적어도 하나를 학습할 수 있다. 구체적으로, 컴퓨팅 장치는 제1 합성 데이터(D`)가 제2 합성 데이터(D)와 유사한 프롬프트를 생성하도록 제2 보조 네트워크를 학습할 수 있다. 또는, 컴퓨팅 장치는 제2 합성 데이터(D) 와 유사한 제1 합성 데이터(D`)를 생성하도록 제3 보조 네트워크를 학습할 수 있다. 본 개시에 따른 컴퓨팅 장치는 인공 지능 학습 데이터의 특성을 정확히 진단하여, 학습 데이터의 품질을 향상하 기 위한 데이터 클리닉 모델을 제공한다. 이와 함께, 데이터 클리닉에 연동되는 언어 기반 모델을 이용하여 자 연어 입력을 정확히 이해하고, 이를 기반으로 데이터 클리닉 서비스를 제공한다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2023-0084888", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34 도면35 도면36 도면37 도면38 도면39 도면40 도면41 도면42 도면43 도면44 도면45 도면46 도면47 도면48 도면49 도면50 도면51 도면52 도면53 도면54 도면55 도면56 도면57 도면58 도면59 도면60 도면61 도면62 도면63 도면64 도면65 도면66 도면67 도면68 도면69 도면70 도면71 도면72 도면73"}
{"patent_id": "10-2023-0084888", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 다양한 실시예에 따른 데이터 클리닉 방법을 수행하기 위한 장치 및 시스템을 설명하기 위한 도면이다. 도 2는 본 개시의 다양한 실시예에 따른 데이터 클리닉 방법 및 데이터 클리닉을 위한 모델의 학습 방법을 수행 하는 컴퓨팅 장치의 블록도를 도시한 도면이다. 도 3은 본 개시의 다양한 실시예에 따른 데이터 클리닉 방법을 수행하는 컴퓨팅 장치에 의해 수행되는 다양한 동작 방법들을 설명하기 위한 도면이다. 도 4는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 이미지를 제공하는 방법을 설명하기 위한 도면이 다. 도 5는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 이미지를 제공하는 방법을 설명하기 위한 흐름도 이다. 도 6은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 이미징 매니폴드 생성 모델을 학습시키는 방법의 예시를 도시한 도면이다. 도 7은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치의 데이터 이미징 과정을 설명하기 위한 도면이다. 도 8은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 이미지를 생성하는 예시를 설명하기 위한 흐름도이다. 도 9는 데이터 이미징을 위한 매니폴드의 최적의 차원을 결정하기 위한 방법의 일 예시를 도시한 흐름도이다. 도 10은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋의 특성을 제공하는 방법을 도시한 도면이다. 도 11은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋에 포함된 포인트 데이터를 기초로 데 이터 셋의 특성을 확인하는 방법을 도시한 흐름도이다. 도 12는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 셋의 특성을 확인하 는 일 예를 도시한 도면이다. 도 13은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 셋의 특성을 확인하 는 방법을 도시한 흐름도이다. 도 14는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 포인트 데이터 셋을 기초로 데이터 셋의 특성을 확인하 는 일 예를 도시한 도면이다. 도 15는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 컨볼루션 알고리즘을 이용하여 데이터 셋의 특성을 획 득하는 방법을 설명하기 위한 도면이다. 도 16은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋을 개선하는 방법을 설명하기 위한 도면이다. 도 17은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선된 포인트 데이터 셋을 생성하는 일 예시를 도시한 도면이다. 도 18은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선된 포인트 데이터 셋을 생성하는 다른 일 예시를 도시한 도면이다. 도 19는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선 매니폴드 생성 모델을 학습시켜 개선된 데이터 이 미지를 제공하기 위한 방법을 설명하는 도면이다. 도 20은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선 매니폴드 생성 모델을 학습하는 방법의 일 예시를도시한 도면이다. 도 21은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 개선 매니폴드 생성 모델을 학습하는 방법의 일 예시를 설명하기 위한 흐름도이다. 도 22는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 하드 네거티브 쌍을 추출함으로써 개선 매니폴드 생성 모델을 학습하는 방법을 도시한 도면이다. 도 23은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋을 기초로 가상 데이터를 포함하는 개선 데이 터 셋을 제공하는 동작을 도시한 도면이다. 도 24는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋을 기초로 가상 데이터를 포함하는 개선 데이 터 셋을 제공하는 동작의 일 예시를 도시한 도면이다. 도 25는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 획득한 데이터 셋의 등급을 제공하는 동작을 도시한 도 면이다. 도 26은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 획득한 데이터 셋의 달성 가능 등급을 제공하는 동작을 도시한 도면이다. 도 27은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 제공하는 진단 레포트에 포함된 정보들을 도시한 도면 이다. 도 28은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 제공하는 데이터 이미지에 대한 정보의 일 예시를 도시 한 도면이다. 도 29는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치가 데이터 셋의 데이터 이미지 및 개선된 데이터 이미지를 제공하는 동작을 설명하기 위한 도면이다. 도 30은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치를 구성하는 알고리즘 수행 모델들을 도시한 도면이다. 도 31은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치에 포함된 적어도하나의 프로세서가 데이터 셋을 기초로 동작을 선택적으로 수행하는 방법을 나타내는 도면이다. 도 32는 본 개시의 다양한 실시예에 따른 컴퓨팅 장치의 메모리에 저장된 인스트럭션에 따라 적어도 하나의 프 로세서가 수행하는 다양한 프로세스를 도시한 도면이다. 도 33은 본 개시의 다양한 실시예에 따른 컴퓨팅 장치의 구현예를 나타낸 도면이다. 도 34는, 다양한 실시예들에 따른, 데이터 클리닉 서비스를 제공하기 위한 다양한 시스템 및 시스템을 구축하기 위한 인공지능 모델 및 알고리즘들을 도시한 도면이다. 도 35는, 다양한 실시예들에 따른, 데이터 렌즈 가공 시스템(Lens Processing System) 및 데이터 이미징 시스템 (Imaging System)을 도시한 도면이다. 도 36은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 렌즈 시스템을 획득하는 방법을 도시한 흐름도이다. 도 37은, 다양한 실시예들에 따른, 컴퓨팅 장치가 수행하는 렌즈 가공 알고리즘(Lens Processing Algorithm)의 일 예시를 도시한 흐름도이다. 도 38은, 다양한 실시예들에 따른, 컴퓨팅 장치가 렌즈 가공 알고리즘을 수행하기 위해 구축된 렌즈 가공 모델 의 예시를 도시한 도면이다. 도 39는, 다양한 실시예들에 따른, 컴퓨팅 장치에 포함되는 렌즈 가공 시스템의 신경망 구조의 예시를 도시한 도면이다. 도 40은, 다양한 실시예들에 따른, 컴퓨팅 장치가 보조 네트워크를 활용하여 렌즈 가공 모델을 고도화하는 방법 을 도시한 도면이다. 도 41은, 다양한 실시예들에 따른, 컴퓨팅 장치가 파라미터를 최적화하는 차원에 연관된 특성을 결정하기 위한 방법을 도시한 도면이다. 도 42는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋의 내재적 특성을 반영하는 데이터 이미지를 획득하기 위한 방법을 도시한 흐름도이다. 도 43은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 이미징하고 태스크 수행 능력을 판단하기 위한 방법을 도시한 도면이다. 도 44는 학습 데이터의 양과 인공지능 모델의 학습 효율의 상관 관계에 대한 실험 데이터를 도시한 도면이다. 도 45는, 다양한 실시예들에 따른, 컴퓨팅 장치가 사전 학습된 인공 지능 모델을 이용하여 데이터 셋의 적어도 일부를 제거하는 방법을 도시한 도면이다. 도 46은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 일 실시예 를 도시한 흐름도이다. 도 47은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 일 예시를 도시한 도면이다. 도 48은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 다른 일 실 시예를 도시한 흐름도이다. 도 49는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 다른 일 예 시를 도시한 도면이다. 도 50은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 실시예를 도시한 흐름도이다. 도 51는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 예시를 도시한 도면이다. 도 52는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 실시예를 도시한 흐름도이다. 도 53은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 예시를 도시한 도면이다. 도 54는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 실시예를 도시한 흐름도이다. 도 55는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋을 기초로 가공된 데이터 셋을 획득하는 또 다른 일 예시를 도시한 도면이다. 도 56은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 이용하여 가상 데이터를 생성하는 방법 을 나타낸 도면이다. 도 57은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델의 프레임워크를 도식화한 도면이다. 도 58은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 이용하여 데이터를 처리하는 방법을 도 시한 흐름도이다. 도 59는, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 이용하여 데이터를 처리하는 예시를 도 시한 도면이다. 도 60은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 최적화하여 데이터를 생성하는 방법을 도시한 흐름도이다. 도 61은, 다양한 실시예들에 따른, 컴퓨팅 장치가 생성형 이미징 모델을 최적화하여 데이터를 생성하는 예시를 도시한 도면이다. 도 62는, 다양한 실시예들에 따른, 컴퓨팅 장치가 적어도 하나의 데이터 처리 모델을 이용하여 데이터 셋의 품 질을 향상시키기 위한 예시를 도시한 도면이다. 도 63은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 셋의 특성을 기초로 적어도 하나의 데이터 처리 모델 에 입력하기 위한 파이프라인을 설명하기 위한 도면이다. 도 64는, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 진단 데이터를 기반으로 가상 데이터를 생성하는 방법을 도시한 도면이다. 도 65는, 다양한 실시예들에 따른, 컴퓨팅 장치가 사전 학습된 머신 러닝 모델을 이용하여 가상 데이터를 생성 하는 방법을 도시한 흐름도이다. 도 66은, 다양한 실시예들에 따른, 컴퓨팅 장치가 가상 데이터 셋의 적합성을 검증하기 위한 방법의 일 예시를 도시한 흐름도이다. 도 67은, 다양한 실시예들에 따른, 컴퓨팅 장치가 가상 데이터 셋의 적합성을 검증하기 위한 방법의 다른 일 예 시를 도시한 흐름도이다. 도 68은, 다양한 실시예들에 따른, 컴퓨팅 장치가 언어 입력을 기반으로 데이터 이미지를 수정함으로써 가상 데 이터를 생성하기 위한 방법을 도시한 도면이다. 도 69는, 다양한 실시예들에 따른, 컴퓨팅 장치가 언어 입력을 기반으로 데이터 이미지를 수정함으로써 가상 데 이터를 생성하기 위한 방법을 도시한 흐름도이다. 도 69는, 다양한 실시예들에 따른, 컴퓨팅 장치가 언어 입력을 기반으로 데이터 이미지를 수정함으로써 가상 데 이터를 생성하기 위한 방법을 도시한 흐름도이다. 도 70은, 다양한 실시예들에 따른, 컴퓨팅 장치가 발화 데이터에 기반하여 가상 데이터를 생성하기 위한 방법을 도시한 도면이다. 도 71은, 다양한 실시예들에 따른, 컴퓨팅 장치가 발화 데이터에 기반하여 가상 데이터를 생성하고, 비교 정보 를 제공하기 위한 방법을 도시한 흐름도이다. 도 72는, 다양한 실시예들에 따른, 컴퓨팅 장치에 포함되는 언어 기반 생성 모델 및 클리닉 모델을 도시한 도면 이다. 도 73은, 다양한 실시예들에 따른, 컴퓨팅 장치가 데이터 클리닉 모델 및 언어 기반 모델을 이용하는 예시를 도 시한 도면이다."}
