{"patent_id": "10-2022-0049146", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0149914", "출원번호": "10-2022-0049146", "발명의 명칭": "인공지능 모델 학습 장치 및 방법", "출원인": "서울시립대학교 산학협력단", "발명자": "오창대"}}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "특성 데이터, 상기 특성 데이터와 연관된 민감 데이터 및 레이블 데이터를 이용하여, 민감 잠재 표현 및 비-민감 잠재 표현을 생성하는 잠재 표현 생성부;상기 민감 잠재 표현 및 상기 비-민감 잠재 표현을 이용하여 복원 특성 데이터 및 복원 민감 데이터를생성하고, 상기 비-민감 잠재 표현을 이용하여 복원 레이블 데이터를 생성하는 데이터 복원부; 및상기 복원 특성 데이터, 상기 복원 민감 데이터 및 상기 복원 레이블 데이터를 이용하여 손실함수를 연산하고,상기 손실함수를 이용하여 잠재 표현 생성부 및 상기 데이터 복원부 중 적어도 하나를 업데이트하는 손실 연산부를 포함하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 데이터 복원부는,상기 민감 잠재 표현 및 상기 비-민감 잠재 표현을 이용하여 상기 복원 특성 데이터 및 상기 복원 민감 데이터를 생성하는 디코더; 및상기 비-민감 잠재 표현을 이용하여 상기 복원 레이블 데이터를 생성하는 예측 모델을 포함하는, 인공지능 모델 학습 장치."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 손실 연산부는,상기 특성 데이터 및 상기 민감 데이터와, 상기 복원 특성 데이터 및 상기 복원 민감 데이터를 비교하여, 제1손실 함수를 계산하고, 상기 레이블 데이터와 상기 복원 레이블 데이터를 비교하여 제2 손실 함수를 계산하고, 상기 제1 손실 함수 및 상기 제2 손실 함수를 이용하여, 상기 잠재 표현 생성부 및 상기 데이터 복원부 중 적어도 하나를 업데이트하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 민감 잠재 표현 및 상기 비-민감 잠재 표현은 각각 평균 및 표준편차로 표현되는, 인공지능 모델 학습 장치.공개특허 10-2023-0149914-3-청구항 5 제1 항에 있어서,상기 잠재 표현 생성부는,제1 특성 데이터, 상기 제1 특성 데이터와 연관된 제1 민감 데이터 및 제1 레이블 데이터를 이용하여, 제1 민감잠재 표현 및 제1 비-민감 잠재 표현을 생성하는 제1 인코더; 및제2 특성 데이터, 상기 제2 특성 데이터와 연관된 제2 민감 데이터 및 제2 레이블 데이터를 이용하여, 제2 민감잠재 표현 및 제2 비-민감 잠재 표현을 생성하는 제2 인코더를 포함하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 데이터 복원부는, 상기 제1 민감 잠재 표현 및 상기 제1 비-민감 잠재 표현을 이용하여, 제1 복원 특성 데이터 및 제1 복원 민감데이터를 생성하는 제1 디코더; 및상기 제1 비-민감 잠재 표현을 이용하여, 제1 복원 레이블 데이터를 생성하는 제1 예측 모델을 포함하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 제1 인코더 및 상기 제2 인코더는, 상기 손실 연산부로부터의 계산에 따라,상기 제1 민감 잠재 표현과 상기 제2 민감 잠재 표현의 유사도가 감소하도록 업데이트되고, 상기 제1 비-민감 잠재 표현과 상기 제2 비-민감 잠재 표현의 유사도가 증가하도록 업데이트되는,인공지능 모델 학습 장치."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,상기 데이터 복원부는 상기 제1 민감 잠재 표현 및 상기 제2 비-민감 잠재 표현을 이용하여, 제3 복원 특성 데이터 및 제3 복원 민감 데이터를 생성하는 제2 디코더를 더 포함하고, 상기 손실 연산부는 상기 제1 특성 데이터 및 상기 제1 민감 데이터와, 상기 제3 복원 특성 데이터 및 상기 제3복원 민감 데이터를 비교하여, 제3 손실 함수를 계산하는, 인공지능 모델 학습 장치."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 특성 데이터, 상기 제1 특성 데이터와 연관된 제1 민감 데이터 및 제1 레이블 데이터를 수신하는 단계;상기 제1 특성 데이터, 상기 제1 민감 데이터 및 상기 제1 레이블 데이터를 이용하여, 제1 민감 잠재 표현 및제1 비-민감 잠재 표현을 생성하는 단계;상기 제1 민감 잠재 표현 및 상기 제1 비-민감 잠재 표현을 이용하여, 제1 복원 특성 데이터 및 제1 복원 민감공개특허 10-2023-0149914-4-데이터를 생성하는 단계;상기 제1 비-민감 잠재 표현을 이용하여, 제1 복원 레이블 데이터를 생성하는 단계; 및상기 제1 민감 잠재 표현, 상기 제1 비-민감 잠재 표현, 상기 제1 복원 특성 데이터 및 상기 제1 복원 민감 데이터 중 적어도 하나에 관한 손실함수를 결정하는 단계를 포함하는, 인공지능 모델 학습 방법."}
{"patent_id": "10-2022-0049146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,제2 특성 데이터, 상기 제2 특성 데이터와 연관된 제2 민감 데이터 및 제2 레이블 데이터를 수신하는 단계;상기 제2 특성 데이터, 상기 제2 민감 데이터 및 상기 제2 레이블 데이터를 이용하여, 제2 민감 잠재 표현 및제2 비-민감 잠재 표현을 생성하는 단계;상기 제1 민감 잠재 표현 및 상기 제2 비-민감 잠재 표현을 이용하여, 제2 복원 특성 데이터 및 제2 복원 민감데이터를 생성하는 단계를 더 포함하는,인공지능 모델 학습 방법."}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델 학습 장치 및 방법이 제공된다. 상기 인공지능 모델 학습 장치는 특성 데이터, 상기 특성 데이터 와 연관된 민감 데이터 및 레이블 데이터를 이용하여, 민감 잠재 표현 및 비-민감 잠재 표현을 생성하는 잠재 표 현 생성부, 상기 민감 잠재 표현 및 상기 비-민감 잠재 표현을 이용하여 복원 특성 데이터 및 복원 민감 데이터 를 생성하고, 상기 비-민감 잠재 표현을 이용하여 복원 레이블 데이터를 생성하는 데이터 복원부 및 상기 복원 특성 데이터, 상기 복원 민감 데이터 및 상기 복원 레이블 데이터를 이용하여 손실함수를 연산하고, 상기 손실함 수를 이용하여 잠재 표현 생성부 및 상기 데이터 복원부 중 적어도 하나를 업데이트하는 손실 연산부를 포함한다."}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델을 학습하는 장치 및 방법에 관한 것이다. 보다 상세하게, 본 발명은 민감 속성을 최소 화한 잠재 표현을 생성하는 인공지능 모델 및 민감 속성을 최소화한 잠재 표현을 이용하여 결과를 예측하는 인 공지능 모델을 학습하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할뿐 종래기술을 구성하는 것은 아니다. 머신 러닝(machine learning)은 인공 지능의 한 분야로서 컴퓨터가 특정 문제에 대한 올바른 답을 도출할 수 있 도록 학습 데이터를 통해 문제와 답 사이의 연관 관계를 스스로 학습하게 하는 기술을 의미한다. 그러나, 머신 러닝을 학습하기 위한 학습 데이터를 수집하는 것은 언제나 균형적으로 수집되는 것은 아니다. 예 를 들어, 웹 상에서 이미지 데이터를 스크래핑하여 인간의 안면 인식에 대한 학습 데이터를 수집한다고 가정할 때, 스크래핑된 이미지 데이터에 포함된 흑인 이미지는, 백인 이미지보다 적게 수집될 수 있다. 이러한 학습 데 이터를 이용하여 훈련된 인공지능 모델은 일종의 편향성을 가지며, 이는 공정한 예측 모델이라고 보기 어려우며 결국 잘못된 예측 모델이 될 수 있다. 따라서, 최근 연구에서는 인공지능 모델의 공정성을 담보하기 위해, 입력 데이터에서 민감한 속성의 데이터와, 비-민감한 속성의 데이터를 분리하는 시도가 이루어지고 있다. 이를 통해, 입력 데이터에서 편향된 정보를 최소 화한, 즉 비-민감한 속성의 데이터만을 이용하여 인공지능 모델을 학습함으로써 인공지능 모델의 공정성을 확보 하고자 한다. 특히, 최근에는 적대적 신경망을 이용하여 입력 데이터에서 민감한 속성의 데이터와 비-민감한 속 성의 데이터를 분리하고자 하는 시도가 있으나, 적대적 신경망은 불안정하다는 단점과, 민감한 속성의 데이터와 비-민감한 속성의 데이터를 분리가 제대로 수행되지 않는다는 단점이 있다. 선행기술문헌 특허문헌(특허문헌 0001) 등록특허공보 제10-2321735호"}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 특성 데이터를 이용하여 민감한 속성을 포함하는 민감 잠재 표현과, 비-민감한 속성을 포함 하는 비-민감 잠재 표현을 분리하는 인공지능 모델 학습 장치 및 방법을 제공하는 것이다. 본 발명의 다른 목적은, 비-민감 잠재 표현을 이용하여 공정한 학습 데이터로 훈련하는 인공지능 모델 학습 장 치 및 방법을 제공하는 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치 특성 데이터, 상기 특성 데 이터와 연관된 민감 데이터 및 레이블 데이터를 이용하여, 민감 잠재 표현 및 비-민감 잠재 표현을 생성하는 잠 재 표현 생성부, 상기 민감 잠재 표현 및 상기 비-민감 잠재 표현을 이용하여 복원 특성 데이터 및 복원 민감 데이터를 생성하고, 상기 비-민감 잠재 표현을 이용하여 복원 레이블 데이터를 생성하는 데이터 복원부 및 상기 복원 특성 데이터, 상기 복원 민감 데이터 및 상기 복원 레이블 데이터를 이용하여 손실함수를 연산하고, 상기 손실함수를 이용하여 잠재 표현 생성부 및 상기 데이터 복원부 중 적어도 하나를 업데이트하는 손실 연산부를 포함한다. 몇몇 실시예에 따르면, 상기 데이터 복원부는, 상기 민감 잠재 표현 및 상기 비-민감 잠재 표현을 이용하여 상 기 복원 특성 데이터 및 상기 복원 민감 데이터를 생성하는 디코더, 및 상기 비-민감 잠재 표현을 이용하여 상 기 복원 레이블 데이터를 생성하는 예측 모델을 포함할 수 있다. 몇몇 실시예에 따르면, 상기 손실 연산부는, 상기 특성 데이터 및 상기 민감 데이터와, 상기 복원 특성 데이터 및 상기 복원 민감 데이터를 비교하여, 제1 손실 함수를 계산하고, 상기 레이블 데이터와 상기 복원 레이블 데 이터를 비교하여 제2 손실 함수를 계산하고, 상기 제1 손실 함수 및 상기 제2 손실 함수를 이용하여, 상기 잠재 표현 생성부 및 상기 데이터 복원부 중 적어도 하나를 업데이트할 수 있다. 몇몇 실시예에 따르면, 상기 민감 잠재 표현 및 상기 비-민감 잠재 표현은 각각 평균 및 표준편차로 표현될 수 있다. 몇몇 실시예에 따르면, 상기 잠재 표현 생성부는, 제1 특성 데이터, 상기 제1 특성 데이터와 연관된 제1 민감 데이터 및 제1 레이블 데이터를 이용하여, 제1 민감 잠재 표현 및 제1 비-민감 잠재 표현을 생성하는 제1 인코 더 및 제2 특성 데이터, 상기 제2 특성 데이터와 연관된 제2 민감 데이터 및 제2 레이블 데이터를 이용하여, 제 2 민감 잠재 표현 및 제2 비-민감 잠재 표현을 생성하는 제2 인코더를 포함할 수 있다. 몇몇 실시예에 따르면, 상기 데이터 복원부는, 상기 제1 민감 잠재 표현 및 상기 제1 비-민감 잠재 표현을 이용 하여, 제1 복원 특성 데이터 및 제1 복원 민감 데이터를 생성하는 제1 디코더 및 상기 제1 비-민감 잠재 표현을 이용하여, 제1 복원 레이블 데이터를 생성하는 제1 예측 모델을 포함할 수 있다. 몇몇 실시예에 따르면, 상기 제1 인코더 및 상기 제2 인코더는, 상기 손실 연산부로부터의 계산에 따라, 상기 제1 민감 잠재 표현과 상기 제2 민감 잠재 표현의 유사도가 감소하도록 업데이트되고, 상기 제1 비-민감 잠재 표현과 상기 제2 비-민감 잠재 표현의 유사도가 증가하도록 업데이트될 수 있다. 몇몇 실시예에 따르면, 상기 데이터 복원부는 상기 제1 민감 잠재 표현 및 상기 제2 비-민감 잠재 표현을 이용 하여, 제3 복원 특성 데이터 및 제3 복원 민감 데이터를 생성하는 제2 디코더를 더 포함하고, 상기 손실 연산부 는 상기 제1 특성 데이터 및 상기 제1 민감 데이터와, 상기 제3 복원 특성 데이터 및 상기 제3 복원 민감 데이터를 비교하여, 제3 손실 함수를 계산할 수 있다. 상기 과제를 해결하기 위한 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 방법은 제1 특성 데이터, 상기 제1 특성 데이터와 연관된 제1 민감 데이터 및 제1 레이블 데이터를 수신하는 단계, 상기 제1 특성 데이터, 상 기 제1 민감 데이터 및 상기 제1 레이블 데이터를 이용하여, 제1 민감 잠재 표현 및 제1 비-민감 잠재 표현을 생성하는 단계, 상기 제1 민감 잠재 표현 및 상기 제1 비-민감 잠재 표현을 이용하여, 제1 복원 특성 데이터 및 제1 복원 민감 데이터를 생성하는 단계, 상기 제1 비-민감 잠재 표현을 이용하여, 제1 복원 레이블 데이터를 생 성하는 단계, 및 상기 제1 민감 잠재 표현, 상기 제1 비-민감 잠재 표현, 상기 제1 복원 특성 데이터 및 상기 제1 복원 민감 데이터 중 적어도 하나에 관한 손실함수를 결정하는 단계를 포함한다. 몇몇 실시예에 따르면, 제2 특성 데이터, 상기 제2 특성 데이터와 연관된 제2 민감 데이터 및 제2 레이블 데이 터를 수신하는 단계, 상기 제2 특성 데이터, 상기 제2 민감 데이터 및 상기 제2 레이블 데이터를 이용하여, 제2 민감 잠재 표현 및 제2 비-민감 잠재 표현을 생성하는 단계, 상기 제1 민감 잠재 표현 및 상기 제2 비-민감 잠 재 표현을 이용하여, 제2 복원 특성 데이터 및 제2 복원 민감 데이터를 생성하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 인공지능 모델 학습 장치 및 방법은, 공정한 학습 데이터를 이용하여, 인공지능 장치의 예측 성능을 향상시킬 수 있다는 장점이 있다. 본 발명의 인공지능 모델 학습 장치 및 방법은, 공정한 학습 데이터를 이용하여, 인공지능 장치의 예측 안정성 을 향상시킬 수 있다는 장점이 있다. 상술한 내용과 더불어 본 발명의 구체적인 효과는 이하"}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0049146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 또한, 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요 소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘 어져서 구현될 수도 있다. 본 발명에서 인공지능, 머신 러닝(Machine Learning) 또는 딥러닝(Deep Learning)은 서로 혼용될 수 있다. 머 신 러닝 기술은 인공지능 기술의 일종이며, 딥러닝 기술은 머신러닝 기술의 일종이다. 딥러닝 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학습하는 것이다. 딥러닝은, 단계를 높여가면서 복수의 데이터들로부터 핵심적인 데이터를 추출하는 머신 러닝(Machine Learning) 알고리즘의 집합을 나타낸다. 본 명세서에서 언급하는 인공지능 모델은 공지의 인공지능 모델을 의미할 수 있다. 예를 들어, 인공지능 모델은 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network), GNN(Graph Neural Network) 등의 구조를 이용할 수 있다. 다만, 본 발명의 실시예들이 이에 제한되는 것은 아니며, 본 발 명의 인공지능 모델 학습 장치 및 방법은 상술한 구조 외에도 다양한 구조에 적용될 수 있는 포괄적인 기술이다. CNN은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출한 다음 뇌 속에서 복잡한 계산을 거쳐 그 결과 를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모사한 모델이다. RNN은 자연어 처리 등에 많이 이용되며, 시간의 흐름에 따라 변하는 시계열 데이터(Time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아올려 인공신경망 구조를 구성할 수 있다. DBN은 딥러닝 기법인 RBM(Restricted Boltzman Machine)을 다층으로 쌓아 구성되는 딥러닝 구조이다. RBM 학습 을 반복하여 일정 수의 레이어가 되면, 해당 개수의 레이어를 가지는 DBN이 구성될 수 있다. GNN(Graphic Neural Network)은 특정 파라미터 간 매핑된 데이터를 기초로 모델링된 모델링 데이터를 이용하여, 모델링 데이터 간의 유사도와 특징점을 도출하는 방식으로 구현된 인공신경망 구조를 나타낸다. 한편, 인공지능 모델의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight) 를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공지능 모델은 학습에 의 해 웨이트(weight) 값을 지속적으로 업데이트 시킬 수 있다. 또한, 인공지능 모델의 학습에는 역전파(Back Propagation) 등의 방법이 사용될 수 있다. 몇몇 실시예에 따른 인공지능 모델 학습 장치는 오토 인코더(AE: AutoEncoder) 및 변이형 오토 인코더(VAE: Variational AutoEncoder ) 중 어느 하나로 구현할 수 있으나, 실시예들이 이에 제한되는 것은 아니다. 이하에 서는 설명의 편의를 위해 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치가 변이형 오토 인코더로 구현 되는 것을 가정하여 설명한다. 도 1은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 구성을 개략적으로 설명하기 위한 도면이다. 도 1을 참조하면, 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치는 잠재 표현 생성부, 데이터 복 원부 및 손실 연산부를 포함할 수 있다. 잠재 표현 생성부는 입력 데이터를 이용하여, 잠재 표현(latent representation)을 생성할 수 있다. 잠재 표현은 입력 데이터로부터 추출된 주요 특성에 관한 데이터일 수 있다. 몇몇 실시예에 따르면, 잠재 표현 생성부는 입력 데이터로, 특성 데이터(FT_D), 민감 데이터(STV_D) 및 레 이블 데이터(LBL_D)를 제공받을 수 있다. 특성 데이터(FT_D)는 용어 그대로, 인공지능 모델을 통한 예측에 이용 하고자 하는 특성에 관한 데이터일 수 있다. 다시 말해서, 인공지능 모델은 특성 데이터(FT_D)를 이용하여, 특 정 결과를 예측하고자 하는 모델이다. 즉, 인공지능 모델은 특성 데이터(FT_D)와 레이블 데이터(LBL_D)의 관계 를 학습하는 모델일 수 있다. 특성 데이터(FT_D)는 텍스트 데이터, 이미지 데이터 등 다양한 형식의 데이터일 수 있다. 민감 데이터(STV_D)는 특성 데이터(FT_D)에 내재되어 있는 민감 속성에 관한 데이터일 수 있다. 즉, 민감 데이 터(STV_D)는 인공지능 모델의 예측에 큰 영향을 끼치는, 특성 데이터(FT_D)에 내재되어 있는 속성에 관한 데이 터일 수 있다. 따라서, 민감 데이터(STV_D)는 특성 데이터(FT_D)와 상대적으로 높은 상관 관계를 가질 수 있다. 레이블 데이터(LBL_D)는 인공지능 모델을 이용하여, 최종적으로 도출하고자 하는 결과 데이터와 연관될 수 있다. 즉, 인공지능 모델은 특성 데이터(FT_D)를 이용하여, 레이블 데이터(LBL_D)를 예측하도록 학습되는 모델 일 수 있다. 예를 들어, 거주지에 따른 범죄율을 예측하는 인공지능 모델을 학습하는 경우를 가정한다. 이때, '거주지'라는 정보는 특성 데이터(FT_D)일 수 있다. 또한, '범죄율'이라는 정보는 레이블 데이터(LBL_D)일 수 있다. 이때, ' 거주지'에 따라 거주하는 인종에 차이가 있다면, '인종'이라는 정보는 민감 데이터(STV_D)일 수 있다. 즉, '거 주지'라는 특성 데이터(FT_D)는 '인종'이라는 민감 데이터(STV_D)가 내재된 정보를 의미할 수 있다. 즉, '거주 지'라는 특성 데이터(FT_D)는 '인종'이라는 민감 데이터(STV_D)와 상대적으로 높은 연관 관계를 가질 수 있다. 이러한 예시에서 볼 수 있듯이, 단순히 '거주지'라는 특성 데이터(FT_D)를 이용하여 '범죄율'이라는 레이블 데 이터(LBL_D)를 예측하도록 학습된 인공지능 모델은 '인종'이라는 민감 데이터(STV_D)를 고려하지 않은 편향된 인공지능 모델으로 학습될 수 있다. 따라서, 이러한 인공지능 모델은 공정한 인공지능 모델이라 할 수 없으며, 이 인공지능 모델이 예측하는 결과에 대한 신뢰도가 확보될 수 없다. 다른 예를 들어, '사람의 관상'에 따른 '소득'을 예측하는 인공지능 모델을 학습하는 경우를 가정한다. 이때, '사람의 관상', 즉 눈, 코, 입의 크기, 형상 등을 포함하는 사람의 얼굴에 대한 이미지는 특성 데이터(FT_D)일 수 있다. 또한, '소득'에 관한 정보는 레이블 데이터(LBL_D)일 수 있다. 이때, 사람의 관상, 즉 눈,코, 입의 크 기 등은 '인종'과 '성별'에 따라 상이할 수 있다. 다시 말해서, '인종' 및 '성별'은 민감 데이터(STV_D)일 수 있다. 앞선 예시와 마찬가지로, '인종'과 '성별'을 고려하지 않은 '사람의 관상'에 따른 '소득'에 관한 인공지 능 모델은 공정하지 않은, 편향된 인공지능 모델일 수 있다. 이러한 문제를 해결하기 위해, 특성 데이터(FT_D) 에서 민감 데이터(STV_D)와 연관된 속성을 분리할 필요가 있다. 몇몇 실시예에 따르면, 특성 데이터(FT_D)는 복수의 데이터를 포함할 수 있으며, 민감 데이터(STV_D) 역시 복수 의 데이터를 포함할 수 있다. 다시 잠재 표현 생성부에 대한 설명으로 돌아와서, 잠재 표현 생성부는 특성 데이터(FT_D), 민감 데 이터(STV_D) 및 레이블 데이터(LBL_D)를 이용하여, 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR) 을 생성할 수 있다. 민감 잠재 표현(STV_LTR)은 잠재 표현 생성부에 입력된 데이터에서, 민감 데이터 (STV_D)와 연관된 속성에 관한 데이터일 수 있다. 비-민감 잠재 표현(NSTV_LTR)은 잠재 표현 생성부에 입 력된 데이터에서, 민감 데이터(STV_D)와 연관된 속성을 최소화한 데이터일 수 있다. 다시 말해서, 잠재 표현 생 성부는 입력 데이터에서, 민감 데이터(STV_D)와 연관된 속성을 분리하여, 민감 데이터(STV_D)와 연관된 속 성을 포함하는 민감 잠재 표현(STV_LTR)과 민감 데이터(STV_D)와 연관된 속성이 최소화된 비-민감 잠재 표현 (NSTV_LTR)을 생성할 수 있다. 잠재 표현 생성부에서 생성된 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표 현(NSTV_LTR)은 데이터 복원부 및 손실 연산부에 제공될 수 있다. 몇몇 실시예에 따르면, 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)은 각각 평균 및 표준 편차로 표현될 수 있다. 즉, 본 발명의 몇몇 실시예에 따른 인공지능 학습 장치가 변이형 오토 인코더로 구현되는 경우, 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)은 각각 평균 및 표준 편차로 표현될 수 있다. 그러나, 실시예들이 이에 제한되는 것은 아니다. 예를 들어, 인공지능 학습 장치가 일반적인 오토 인코더로 구 현되는 경우, 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)은 특정 값을 갖는 벡터값일 수 있다. 데이터 복원부는 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)을 이용하여, 복원 특성 데이터 (rFT_D), 복원 민감 데이터(rSTV_D) 및 복원 레이블 데이터(rLBL_D)를 생성할 수 있다. 복원 특성 데이터 (rFT_D), 복원 민감 데이터(rSTV_D) 및 복원 레이블 데이터(rLBL_D)는 민감 잠재 표현(STV_LTR) 및 비-민감 잠 재 표현(NSTV_LTR) 중 적어도 하나를 이용하여, 각각 특성 데이터(FT_D), 민감 데이터(STV_D) 및 레이블 데이터(LBL_D)를 복원한 데이터일 수 있다. 데이터 복원부에서 생성된 복원 특성 데이터(rFT_D), 복원 민감 데이 터(rSTV_D) 및 복원 레이블 데이터(rLBL_D)는 손실 연산부에 제공될 수 있다. 손실 연산부는 특성 데이터(FT_D), 민감 데이터(STV_D), 레이블 데이터(LBL_D), 복원 특성 데이터 (rFT_D), 복원 민감 데이터(rSTV_D) 및 복원 레이블 데이터(rLBL_D)를 수신할 수 있다. 또한, 손실 연산부(30 0)는 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)을 수신할 수 있다. 손실 연산부는 수신한 데이터들에 대한 손실함수를 계산하고, 이를 잠재 표현 생성부 및 데이터 복원부 중 적어도 하나에 피드백(FB)할 수 있다. 몇몇 실시예에 따르면, 손실 연산부는 복원 특성 데이터(rFT_D)와 특성 데이터(FT_D)를 비교하고, 복원 민 감 데이터(rSTV_D)와 민감 데이터(STV_D)를 비교하여 손실 함수를 계산하고, 복원 레이블 데이터(rLBL_D)와 레 이블 데이터(LBL_D)를 비교하여 손실 함수를 계산하고, 이를 이용하여 잠재 표현 생성부 및 데이터 복원부 중 적어도 하나에 피드백(FB)할 수 있다. 잠재 표현 생성부 및 데이터 복원부 중 적어도 하나 는, 손실 연산부로부터의 피드백(FB)에 따라 내부 파라미터 값들을 업데이트할 수 있다. 또한, 손실 연산부는 민감 잠재 표현(STV_LTR)과 비-민감 잠재 표현(NSTV_LTR)에 대한 손실함수를 계산하 고, 이를 이용하여 잠재 표현 생성부에 피드백(FB)할 수 있다. 잠재 표현 생성부는 손실 연산부(30 0)로부터의 피드백(FB)에 따라 내부 파라미터 값들을 업데이트할 수 있다. 잠재 표현 생성부 및 데이터 복원부에 대한 추가적인 설명을 위해, 도 2를 더 참조하여 설명한다. 도 2는 본 발명의 몇몇 실시예들에 따른 잠재 표현 생성부 및 데이터 복원부의 구조를 설명하기 위한 도면이다. 도 1 및 도 2를 참조하면, 잠재 표현 생성부는 제1 인코더(EC_1)를 포함하고, 데이터 복원부는 제1 디코더(DC_1) 및 제1 예측 모델(PM_1)을 포함할 수 있다. 제1 인코더(EC_1)는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이터(LBL_D1)를 입력 으로 수신할 수 있다. 제1 인코더(EC_1)는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데 이터(LBL_D1)를 이용하여, 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 생성할 수 있다. 다시 말해서, 제1 인코더(EC_1)는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이 터(LBL_D1)를 압축하여, 이를 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 생성할 수 있다. 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)은 제1 디코더(DC_1)에 제공될 수 있다. 제1 디코더(DC_1)는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복 원 특성 데이터(rFT_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 생성할 수 있다. 제1 비-민감 잠재 표현(NSTV_LTR1)은 제1 예측 모델(PM_1)에 제공될 수 있다. 제1 예측 모델(PM_1)은 제1 비-민 감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복원 레이블 데이터(rLBL_D1)를 생성할 수 있다. 다시 말해서, 제1 예측 모델(PM_1)은 제1 민감 데이터(STV_D1)에 관한 속성이 최소화된 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용 하여 학습될 수 있다. 더욱 구체적인 설명을 위해, 도 3 및 도 4를 더 참조한다. 도 3은 본 발명의 몇몇 실시예에 따른 민감 잠재 표현 및 비-민감 잠재 표현이 생성되는 과정을 설명하기 위한 도면이다. 도 4는 본 발명의 몇몇 실시예에 따른 복원 특성 데이터, 복원 민감 데이터 및 복원 레이블 데이터가 생성되는 과정을 설명하기 위한 도면이다. 도 3을 참조하면, 제1 민감 잠재 표현(STV_LTR1)은 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이터(LBL_D1)를 이용하여 생성될 수 있다. 예를 들어, 제1 민감 잠재 표현(STV_LTR1)은 제1 특성 데이 터(FT_D1)와 제1 파라미터(W1)를 연산하고, 제1 민감 데이터(STV_D1)와 제3 파라미터(W3)를 연산하고, 제1 레이 블 데이터(LBL_D1)와 제5 파라미터(W5)를 연산한 결과를 이용하여 생성될 수 있다. 또한, 제1 비-민감 잠재 표현(NSTV_LTR1)은 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이터(LBL_D1)를 이용하여 생성될 수 있다. 예를 들어, 제1 비-민감 잠재 표현(NSTV_LTR1)은 제1 특성 데이터 (FT_D1)와 제2 파라미터(W2)를 연산하고, 제1 민감 데이터(STV_D1)와 제4 파라미터(W4)를 연산하고, 제1 레이블 데이터(LBL_D1)와 제6 파라미터(W6)를 연산한 결과를 이용하여 생성될 수 있다. 제1 파라미터(W1) 내지 제6 파라미터(W6)는 하나 이상의 레이어에 대한 파라미터일 수 있다. 즉, 제1 파라미터 (W1) 내지 제6 파라미터(W6)는 하나 이상의 레이어에 대한 각 파라미터의 집합을 의미할 수 있다. 예를 들어, 제1 파라미터(W1) 내지 제6 파라미터(W6)가 2개의 레이어에 대한 파라미터를 포함하는 것으로 가정 하면, 제1 민감 잠재 표현(STV_LTR1)은 제1 특성 데이터(FT_D1)와 제1 파라미터(W1)에 포함된 첫번째 레이어의 파라미터를 연산하고, 제1 민감 데이터(STV_D1)와 제3 파라미터(W3)에 포함된 첫번째 레이어의 파라미터를 연산 하고, 제1 레이블 데이터(LBL_D1)와 제5 파라미터(W5)에 포함된 첫번째 레이어의 파라미터를 연산한 후, 제1 특 성 데이터(FT_D1)와 제1 파라미터(W1)에 포함된 두번째 레이어의 파라미터를 연산하고, 제1 민감 데이터 (STV_D1)와 제3 파라미터(W3)에 포함된 두번째 레이어의 파라미터를 연산하고, 제1 레이블 데이터(LBL_D1)와 제 5 파라미터(W5)에 포함된 두번째 레이어의 파라미터를 연산한 결과를 이용하여 생성될 수 있다. 마찬가지로, 제 1 비-민감 잠재 표현(NSTV_LTR1)은 제1 특성 데이터(FT_D1)와 제2 파라미터(W2)에 포함된 첫번째 레이어의 파라 미터를 연산하고, 제1 민감 데이터(STV_D1)와 제4 파라미터(W4)에 포함된 첫번째 레이어의 파라미터를 연산하고, 제1 레이블 데이터(LBL_D1)와 제6 파라미터(W6)에 포함된 첫번째 레이어의 파라미터를 연산한 후, 제 1 특성 데이터(FT_D1)와 제2 파라미터(W2)에 포함된 두번째 레이어의 파라미터를 연산하고, 제1 민감 데이터 (STV_D1)와 제4 파라미터(W4)에 포함된 두번째 레이어의 파라미터를 연산하고, 제1 레이블 데이터(LBL_D1)와 제 6 파라미터(W6)에 포함된 두번째 레이어의 파라미터를 연산한 결과를 이용하여 생성될 수 있다. 다만 이러한 설 명은 단순히 예시적인 것이며, 실시예들이 이에 제한되는 것은 아니다. 도 4를 참조하면, 제1 복원 특성 데이터(rFT_D1)는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현 (NSTV_LTR1)을 이용하여 생성될 수 있다. 예를 들어, 제1 복원 특성 데이터(rFT_D1)는 제1 민감 잠재 표현 (STV_LTR1)과 제7 파라미터(W7)를 연산하고, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제9 파라미터를 연산한 결과 를 이용하여 생성될 수 있다. 또한, 제1 복원 민감 데이터(rSTV_D1)는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1) 을 이용하여 생성될 수 있다. 예를 들어, 제1 복원 민감 데이터(rSTV_D1)는 제1 민감 잠재 표현(STV_LTR1)과 제 8 파라미터(W8)를 연산하고, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제10 파라미터(W10)를 연산한 결과를 이용하 여 생성될 수 있다. 또한, 제1 복원 레이블 데이터(rLBL_D1)는 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여 생성될 수 있다. 다시 말해서, 제1 복원 레이블 데이터(rLBL_D1)는 제1 민감 데이터(STV_D1)와 관련된 속성이 최소화된 제1 비-민감 잠재 표현(NSTV_LTR1)만을 이용하여 생성될 수 있다. 예를 들어, 제1 복원 레이블 데이터(rLBL_D1)는 제1 비-민 감 잠재 표현(NSTV_LTR1)과 제11 파라미터(W11)를 연산한 결과를 이용하여 생성될 수 있다. 제7 파라미터(W7) 내지 제11 파라미터(W11)는 하나 이상의 레이어에 대한 파라미터일 수 있다. 즉, 제7 파라미 터(W7) 내지 제11 파라미터(W11)는 하나 이상의 레이어에 대한 각 파라미터의 집합을 의미할 수 있다. 예를 들어, 제7 파라미터(W7) 내지 제11 파라미터(W11)가 2개의 레이어에 대한 파라미터를 포함하는 것으로 가 정하면, 제1 복원 특성 데이터(rFT_D1)는 제1 민감 잠재 표현(STV_LTR1)과 제7 파라미터(W7)에 포함된 첫번째 레이어의 파라미터를 연산하고, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제9 파라미터(W9)에 포함된 첫번째 레이어 의 파라미터를 연산한 후, 제1 민감 잠재 표현(STV_LTR1)과 제7 파라미터(W7)에 포함된 두번째 레이어의 파라미 터를 연산하고, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제9 파라미터(W9)에 포함된 두번째 레이어의 파라미터를 연산한 결과를 이용하여 생성될 수 있다. 또한, 제1 복원 민감 데이터(rSTV_D1)는 제1 민감 잠재 표현 (STV_LTR1)과 제8 파라미터(W8)에 포함된 첫번째 레이어의 파라미터를 연산하고, 제1 비-민감 잠재 표현 (NSTV_LTR1)과 제10 파라미터(W10)에 포함된 첫번째 레이어의 파라미터를 연산한 후, 제1 민감 잠재 표현 (STV_LTR1)과 제8 파라미터(W8)에 포함된 두번째 레이어의 파라미터를 연산하고, 제1 비-민감 잠재 표현 (NSTV_LTR1)과 제10 파라미터(W10)에 포함된 두번째 레이어의 파라미터를 연산한 결과를 이용하여 생성될 수 있 다. 또한, 제1 복원 레이블 데이터(rLBL_D1)는 제1 비-민감 잠재 표현(NSTV_LTR1)과 제11 파라미터(W11)에 포함 된 첫번재 레이어의 파라미터를 연산한 후, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제11 파라미터(W11)에 포함된 두번째 레이어의 파라미터를 연산한 결과를 이용하여 생성될 수 있다. 다만, 이는 예시적인 것이며 실시예들이 이에 제한되는 것은 아니다. 다시 도 1 및 도 2를 참조하면, 손실 연산부는 제1 특성 데이터(FT_D1) 및 제1 복원 특성 데이터(rFT_D1) 를 비교하고, 제1 민감 데이터(STV_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 비교하여, 제1 손실 함수(LF_1)를 계산할 수 있다. 또한, 손실 연산부는 제1 레이블 데이터(LBL_D1)와 제1 복원 레이블 데이터(rLBL_D1)를 비교하여, 제2 손실 함수(LF_2)를 계산할 수 있다. 또한, 손실 연산부는 제1 민감 잠재 표현(STV_LTR1)과 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제3 손실 함수(LF_3)를 계산할 수 있다. 손실 연산부는 제 1 손실 함수(LF_1), 제2 손실 함수(LF_2) 및 제3 손실 함수(LF_3) 중 적어도 하나를 포함하는 피드백(FB)을 잠 재 표현 생성부 및 데이터 복원부 중 적어도 하나에 제공할 수 있다. 몇몇 실시예에 따르면, 손실 연산부는 제1 특성 데이터(FT_D1)와 제1 복원 특성 데이터(rFT_D1)의 유사도 와, 제1 민감 데이터(STV_D1)와 제1 복원 민감 데이터(rSTV_D1)의 유사도에 대한 제1 손실 함수(LF_1)를 계산할 수 있다. 잠재 표현 생성부 및 데이터 복원부 중 적어도 하나는, 제1 손실 함수(LF_1)를 이용하여, 제1 특성 데이터(FT_D1)와 제1 복원 특성 데이터(rFT_D1)의 유사도와, 제1 민감 데이터(STV_D1)와 제1 복원 민 감 데이터(rSTV_D1)의 유사도가 증가되는 방향으로 파라미터가 업데이트될 수 있다. 이와 유사하게, 손실 연산부는 제1 레이블 데이터(LBL_D1)와 제1 복원 레이블 데이터(rLBL_D1)의 유사도에 대한 제2 손실 함수(LF_2)를 계산할 수 있다. 잠재 표현 생성부 및 데이터 복원부 중 적어도 하나는, 제2 손실 함수(LF_2)를 이용하여, 제1 레이블 데이터(LBL_D1)와 제1 복원 레이블 데이터(rLBL_D1)의 유사도가 증가되는 방향으로 파라미터가 업데이트될 수 있다. 한편, 손실 연산부는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)의 유사도에 대 한 제3 손실 함수(LF_3)를 계산할 수 있다. 잠재 표현 생성부는 제3 손실 함수(LF_3)를 이용하여, 제1 민 감 잠재 표현(STV_LTR1)과 제1 비-민감 잠재 표현(NSTV_LTR1)의 유사도가 감소되는 방향으로 파라미터가 업데이 트될 수 있다. 전술한 바와 같이, 제1 민감 잠재 표현(STV_LTR1)은 제1 민감 데이터(STV_D1)에 연관된 속성에 관한 데이터이며, 제1 비-민감 잠재 표현(NSTV_LTR1)은 제1 민감 데이터(STV_D1)에 연관된 속성이 최소화된 데 이터이다. 따라서, 인공지능 학습 장치는 제1 민감 잠재 표현(STV_LTR1)과 제1 비-민감 잠재 표현(NSTV_LTR1)의 유사도가 감소되는 방향으로 잠재 표현 생성부를 학습할 수 있다. 몇몇 실시예에 따르면, 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 생성하는 모델은 인식 모델로서 기능하며, 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여 제1 복원 특성 데이터(rFT_D1), 제1 복원 민감 데이터(rSTV_D1) 및 제1 복원 레이블 데이터(rLBL_D1)를 생성하는 모 델은 생성 모델로서 기능할 수 있다. 도 5는 본 발명의 다른 몇몇 실시예들에 따른 잠재 표현 생성부 및 데이터 복원부의 구조를 설명하기 위한 도면 이다. 도 5를 참조하면, 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치는 인공지능 모델의 학습 정확도 및 안정성을 증가시키기 위해, 대조 학습 기법을 도입할 수 있다. 다시 말해서, 본 발명의 몇몇 실시예에 따른 인 공지능 모델 학습 장치는 기준 모델(RM) 및 대조 모델(CM)을 포함할 수 있다. 잠재 표현 생성부는 제1 인코더(EC_1) 및 제2 인코더(EC_2)를 포함할 수 있다. 제1 인코더(EC_1)는 기준 모델(RM)에 포함될 수 있고, 제2 인코더(EC_2)는 대조 모델(CM)에 포함될 수 있다. 데이터 복원부는 제1 디코더(DC_1), 제2 디코더(DC_2), 제1 예측 모델(PM_1) 및 제2 예측 모델(PM_2)을 포함할 수 있다. 제1 디코더(DC_1) 및 제1 예측 모델(PM_1)은 기준 모델(RM)에 포함될 수 있고, 제2 디코더 (DC_2) 및 제2 예측 모델(PM_2)은 대조 모델(CM)에 포함될 수 있다. 기준 모델(RM)에서, 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이터(LBL_D1)는 제1 인코더(EC_1)에 제공될 수 있다. 제1 인코더(EC_1)는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제 1 레이블 데이터(LBL_D1)를 이용하여, 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 생성할 수 있다. 제1 디코더(DC_1)는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 수신할 수 있다. 제1 디코더(DC_1)는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복 원 특성 데이터(rFT_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 생성할 수 있다. 제1 예측 모델(PM_1)은 제1 비-민감 잠재 표현(NSTV_LTR1)을 수신할 수 있다. 제1 예측 모델(PM_1)은 제1 비-민 감 잠재 표현(NSTV_LTR1)을 이용하여 제1 복원 레이블 데이터(rLBL_D1)를 생성할 수 있다. 대조 모델(CM)에서, 제2 특성 데이터(FT_D2), 제2 민감 데이터(STV_D2) 및 제2 레이블 데이터(LBL_D2)는 제2 인코더(EC_2)에 제공될 수 있다. 제2 인코더(EC_2)는 제2 특성 데이터(FT_D2), 제2 민감 데이터(STV_D2) 및 제 2 레이블 데이터(LBL_D2)를 이용하여, 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 생성할 수 있다. 몇몇 실시예에 따르면, 제2 민감 데이터(STV_D2)는 제1 민감 데이터(STV_D1)와 반대되는 민감 속성일 수 있다. 예를 들어, 제1 민감 데이터(STV_D1)가 '흑인'에 관한 데이터라면, 제2 민감 데이터(STV_D2)는 '백인'에 관한 데이터일 수 있다. 다른 예를 들어, 제1 민감 데이터(STV_D1)가 '남성'에 관한 데이터라면, 제2 민감 데이터(STV_D2)는 '여성'에 관한 데이터일 수 있다. 제2 특성 데이터(FT_D2)는 제1 특성 데이터(FT_D1)와 동일한 종류의 데이터일 수 있다. 제2 디코더(DC_2)는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 수신할 수 있다. 제2 디코더(DC_2)는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여, 제2 복 원 특성 데이터(rFT_D2) 및 제2 복원 민감 데이터(rSTV_D2)를 생성할 수 있다. 제2 예측 모델(PM_2)은 제2 비-민감 잠재 표현(NSTV_LTR2)을 수신할 수 있다. 제2 예측 모델(PM_2)은 제2 비-민 감 잠재 표현(NSTV_LTR2)을 이용하여 제2 복원 레이블 데이터(rLBL_D2)를 생성할 수 있다. 손실 연산부는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1), 제1 복원 특성 데이터(rFT_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 이용하여 제1 손실 함수(LF_1)를 연산할 수 있다. 또한, 손실 연산부는 제1 레이블 데이터(LBL_D1) 및 제1 복원 레이블 데이터(rLBL_D1)를 이용하여, 제2 손실 함수(LF_2)를 연산할 수 있 다. 이와 유사하게, 손실 연산부는 제2 특성 데이터(FT_D2), 제2 민감 데이터(STV_D2), 제2 복원 특성 데 이터(rFT_D2) 및 제2 복원 민감 데이터(rSTV_D2)를 이용하여, 제4 손실 함수(LF_4)를 연산하고, 제2 레이블 데 이터(LBL_D2) 및 제2 복원 레이블 데이터(rLBL_D2)를 이용하여 제5 손실 함수(LF_5)를 연산할 수 있다. 몇몇 실시예에 따르면, 손실 연산부는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현 (NSTV_LTR1)을 이용하여 제3 손실 함수(LF_3)를 연산할 수 있다. 이와 유사하게, 손실 연산부는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여 제6 손실 함수(LF_6)를 연산할 수 있다. 또한, 손실 연산부는 제1 민감 잠재 표현(STV_LTR1), 제1 비-민감 잠재 표현(NSTV_LTR1), 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여, 제9 손실 함수(LF_9)를 연산할 수 있다. 몇몇 실시예에 따르면, 제1 인코더(EC_1), 제1 디코더(DC_1) 및 제1 예측 모델(PM_1) 중 적어도 하나는, 제1 손 실 함수(LF_1), 제2 손실 함수(LF_2) 및 제3 손실 함수(LF_3) 중 적어도 하나를 이용하여 업데이트될 수 있다. 또한, 제2 인코더(EC_2), 제2 디코더(DC_2) 및 제2 예측 모델(PM_2) 중 적어도 하나는, 제4 손실 함수(LF_4), 제5 손실 함수(LF_5) 및 제6 손실 함수(LF_6) 중 적어도 하나를 이용하여 업데이트될 수 있다. 몇몇 실시예에 따르면, 손실 연산부는 제3 손실 함수(LF_3)를 이용하여, 제1 인코더(EC_1)에 피드백할 수 있다. 제1 인코더(EC_1)는 손실 연산부로부터의 피드백에 따라 제1 인코더(EC_1)의 파라미터를 업데이트할 수 있다. 또한, 손실 연산부는 제6 손실 함수(LF_6)를 이용하여, 제2 인코더(EC_2)에 피드백할 수 있다. 제2 인코더(EC_2)는 손실 연산부로부터의 피드백에 따라 제2 인코더(EC_2)의 파라미터를 업데이트할 수 있 다. 또한, 손실 연산부는 제9 손실 함수(LF_9)를 이용하여, 제1 인코더(EC_1) 및 제2 인코더(EC_2)에 피드 백할 수 있다. 제1 인코더(EC_1) 및 제2 인코더(EC_2)는 손실 연산부로부터의 피드백에 따라 제1 인코더 (EC_1) 및 제2 인코더(EC_2)의 파라미터를 업데이트할 수 있다. 손실 연산부에서 제1 인코더(EC_1)로의 피드백은, 제1 민감 잠재 표현(STV_LTR1)과 제1 비-민감 잠재 표현 (NSTV_LTR1) 사이의 유사도가 감소하는 방향으로, 제1 민감 잠재 표현(STV_LTR1)과 제2 민감 잠재 표현 (STV_LTR2) 사이의 유사도가 감소하는 방향으로, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제2 비-민감 잠재 표현 (NSTV_LTR2) 사이의 유사도가 증가하는 방향으로 진행될 수 있다. 이와 유사하게, 손실 연산부에서 제2 인코더(EC_2)로의 피드백은, 제2 민감 잠재 표현(STV_LTR2)과 제2 비 -민감 잠재 표현(NSTV_LTR2) 사이의 유사도가 감소하는 방향으로, 제1 민감 잠재 표현(STV_LTR1)과 제2 민감 잠 재 표현(STV_LTR2) 사이의 유사도가 감소하는 방향으로, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제2 비-민감 잠재 표현(NSTV_LTR2) 사이의 유사도가 증가하는 방향으로 진행될 수 있다. 전술한 바와 같이, 제1 민감 잠재 표현(STV_LTR1)은 제1 민감 데이터(STV_D1)에 연관된 속성에 관한 데이터일수 있다. 또한, 제1 비-민감 잠재 표현(NSTV_LTR1)은 제1 민감 데이터(STV_D1)에 연관된 속성을 최소화한 데이터일수 있다. 이와 마찬가지로, 제2 민감 잠재 표현(STV_LTR2)은 제2 민감 데이터(STV_D2)에 연관된 속성에 관한 데 이터일 수 있다. 또한, 제2 비-민감 잠재 표현(NSTV_LTR2)은 제2 민감 데이터(STV_D2)에 연관된 속성을 최소화 한 데이터일 수 있다. 제1 민감 데이터(STV_D1)와 제2 민감 데이터(STV_D2)는 서로 반대되는 속성을 가지므로, 인공지능 모델 학습 장치는 제1 민감 잠재 표현(STV_LTR1)과 제2 민감 잠재 표현(STV_LTR2)의 유사도가 감소되 는 방향으로 학습될 수 있다. 또한, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제2 비-민감 잠재 표현(NSTV_LTR2)은 각각 제1 민감 데이터(STV_D1) 및 제2 민감 데이터(STV_D2)에 연관된 속성을 최소화한 데이터이므로, 인공지능 모델 학습 장치는 제1 비-민감 잠재 표현(NSTV_LTR1)과 제2 비-민감 잠재 표현(NSTV_LTR2)의 유사도가 증가되는 방향으로 학습될 수 있다. 몇몇 실시예에 따르면, 인공지능 학습 장치는 기준 모델(RM)과 대조되는 데이터를 이용하는 대조 모델(CM)을 추 가로 학습할 수 있다. 이때, 대조 모델(CM)에서 생성되는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)은, 기준 모델(RM)의 제1 인코더(EC_1)를 학습시키기 위한 제3 손실 함수(LF_3)를 연산하기 위 해 이용될 수 있다. 이를 통해, 인공지능 모델의 정확도를 더욱 증가시킬 수 있다. 도 6은 본 발명의 또 다른 몇몇 실시예들에 따른 잠재 표현 생성부 및 데이터 복원부의 구조를 설명하기 위한 도면이다. 설명의 편의를 위해 전술한 내용과 동일하거나 유사한 내용은 생략하거나 간단히 설명한다. 도 6을 참조하면, 잠재 표현 생성부는 제1 인코더(EC_1) 및 제2 인코더(EC_2)를 포함할 수 있다. 제1 인코 더(EC_1)는 기준 모델(RM)에 포함될 수 있고, 제2 인코더(EC_2)는 대조 모델(CM)에 포함될 수 있다. 데이터 복원부는 제1 디코더(DC_1), 제2 디코더(DC_2), 제3 디코더(DC_3), 제4 디코더(DC_4), 제1 예측 모델(PM_1) 및 제2 예측 모델(PM_2)을 포함할 수 있다. 제1 디코더(DC_1), 제3 디코더(DC_3) 및 제1 예측 모델 (PM_1)은 기준 모델(RM)에 포함될 수 있고, 제2 디코더(DC_2), 제4 디코더(DC_4) 및 제2 예측 모델(PM_2)은 대 조 모델(CM)에 포함될 수 있다. 몇몇 실시예에 따르면, 제1 디코더(DC_1)와 제3 디코더(DC_3)는 서로 동일한 디코더로 구현될 수도 있고, 서로 다른 별개의 디코더로 구현될 수도 있다. 마찬가지로, 제2 디코더(DC_2)와 제4 디코더(DC_4)는 서로 동일한 디 코더로 구현될 수도 있고, 서로 다른 별개의 디코더로 구현될 수도 있다. 기준 모델(RM)에서, 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이터(LBL_D1)는 제1 인코더(EC_1)에 제공될 수 있다. 제1 인코더(EC_1)는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제 1 레이블 데이터(LBL_D1)를 이용하여, 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 생성할 수 있다. 제1 디코더(DC_1)는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 수신할 수 있다. 제1 디코더(DC_1)는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복 원 특성 데이터(rFT_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 생성할 수 있다. 제3 디코더(DC_3)는 제1 민감 잠재 표현(STV_LTR1) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 수신할 수 있다. 제3 디코더(DC_3)는 제1 민감 잠재 표현(STV_LTR1) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여, 제3 복 원 특성 데이터(rFT_D3) 및 제3 복원 민감 데이터(rSTV_D3)를 생성할 수 있다. 다시 말해서, 본 발명의 몇몇 실 시예에 따른 인공지능 모델 학습 장치는 기준 모델(RM)에 포함되는 제3 디코더(DC_3)를 학습하기 위해, 대조 모 델(CM)에서 생성되는 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용할 수 있다. 몇몇 실시예에 따르면, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제2 비-민감 잠재 표현(NSTV_LTR2)은 서로 유사도 가 증가하는 방향으로 학습될 수 있다. 다시 말해서, 제1 비-민감 잠재 표현(NSTV_LTR1)과 제2 비-민감 잠재 표 현(NSTV_LTR2)은 상대적으로 유사한 데이터일 수 있다. 따라서, 기준 모델(RM)에 포함되는 제3 디코더(DC_3)를 학습할 때, 제1 비-민감 잠재 표현(NSTV_LTR1)과 상대적으로 유사한 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용 함으로써, 인공지능 모델 학습 장치의 학습률 및 정확도를 증가시킬 수 있다. 제1 예측 모델(PM_1)은 제1 비-민감 잠재 표현(NSTV_LTR1)을 수신할 수 있다. 제1 예측 모델(PM_1)은 제1 비-민 감 잠재 표현(NSTV_LTR1)을 이용하여 제1 복원 레이블 데이터(rLBL_D1)를 생성할 수 있다. 대조 모델(CM)에서, 제2 특성 데이터(FT_D2), 제2 민감 데이터(STV_D2) 및 제2 레이블 데이터(LBL_D2)는 제2 인코더(EC_2)에 제공될 수 있다. 제2 인코더(EC_2)는 제2 특성 데이터(FT_D2), 제2 민감 데이터(STV_D2) 및 제 2 레이블 데이터(LBL_D2)를 이용하여, 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을생성할 수 있다. 제2 디코더(DC_2)는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 수신할 수 있다. 제2 디코더(DC_2)는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여, 제2 복 원 특성 데이터(rFT_D2) 및 제2 복원 민감 데이터(rSTV_D2)를 생성할 수 있다. 제4 디코더(DC_4)는 제2 민감 잠재 표현(STV_LTR2) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 수신할 수 있다. 제4 디코더(DC_4)는 제2 민감 잠재 표현(STV_LTR2) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제4 복 원 특성 데이터(rFT_D4) 및 제4 복원 민감 데이터(rSTV_D4)를 생성할 수 있다. 다시 말해서, 본 발명의 몇몇 실 시예에 따른 인공지능 모델 학습 장치는 대조 모델(CM)에 포함되는 제4 디코더(DC_4)를 학습하기 위해, 기준 모 델(RM)에서 생성되는 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용할 수 있다. 제2 예측 모델(PM_2)은 제2 비-민감 잠재 표현(NSTV_LTR2)을 수신할 수 있다. 제2 예측 모델(PM_2)은 제2 비-민 감 잠재 표현(NSTV_LTR2)을 이용하여 제2 복원 레이블 데이터(rLBL_D2)를 생성할 수 있다. 손실 연산부는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1), 제1 복원 특성 데이터(rFT_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 이용하여 제1 손실 함수(LF_1)를 연산할 수 있다. 또한, 손실 연산부는 제1 레이블 데이터(LBL_D1) 및 제1 복원 레이블 데이터(rLBL_D1)를 이용하여, 제2 손실 함수(LF_2)를 연산할 수 있 다. 이와 유사하게, 손실 연산부는 제2 특성 데이터(FT_D2), 제2 민감 데이터(STV_D2), 제2 복원 특성 데 이터(rFT_D2) 및 제2 복원 민감 데이터(rSTV_D2)를 이용하여, 제4 손실 함수(LF_4)를 연산하고, 제2 레이블 데 이터(LBL_D2) 및 제2 복원 레이블 데이터(rLBL_D2)를 이용하여 제5 손실 함수(LF_5)를 연산할 수 있다. 또한, 손실 연산부는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1), 제3 복원 특성 데이터(rFT_D3) 및 제3 복원 민감 데이터(rSTV_D3)를 이용하여, 제7 손실 함수(LF_7)를 연산할 수 있다. 또한, 손실 연산부는 제2 특성 데이터(FT_D2), 제2 민감 데이터(STV_D2), 제4 복원 특성 데이터(rFT_D4) 및 제4 복원 민감 데이터 (rSTV_D4)를 이용하여, 제8 손실 함수(LF_8)를 연산할 수 있다. 몇몇 실시예에 따르면, 손실 연산부는 제1 민감 잠재 표현(STV_LTR1), 제1 비-민감 잠재 표현(NSTV_LTR1), 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여, 제3 손실 함수(LF_3)를 연산 할 수 있다. 마찬가지로, 손실 연산부는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현 (NSTV_LTR1)을 이용하여, 제6 손실 함수(LF_6)를 연산할 수 있다. 또한, 손실 연산부는 제1 민감 잠재 표 현(STV_LTR1), 제1 비-민감 잠재 표현(NSTV_LTR1), 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현 (NSTV_LTR2)을 이용하여, 제9 손실 함수(LF_9)를 연산할 수 있다. 몇몇 실시예에 따르면, 제1 인코더(EC_1), 제1 디코더(DC_1), 제3 디코더(DC_3) 및 제1 예측 모델(PM_1) 중 적 어도 하나는 제1 손실 함수(LF_1), 제2 손실 함수(LF_2), 제3 손실 함수(LF_3), 제7 손실 함수(LF_7) 및 제9 손실 함수(LF_9) 중 적어도 하나를 이용하여 업데이트될 수 있다. 또한, 제2 인코더(EC_2), 제2 디코더(DC_2), 제4 디코더(DC_4) 및 제2 예측 모델(PM_2) 중 적어도 하나는 제4 손실 함수(LF_4), 제5 손실 함수(LF_5), 제6 손실 함수(LF_6), 제8 손실 함수(LF_8) .및 제9 손실 함수(LF_9) 중 적어도 하나를 이용하여 업데이트될 수 있다. 본 발명의 몇몇 실시예에 따르면, 인공지능 모델을 학습하는 단계에서, 특성 데이터(FT_D), 민감 데이터(STV_D) 및 레이블 데이터(LBL_D)는 잠재 표현 생성부에 입력 데이터로 제공되고, 잠재 표현 생성부는 입력 데이터를 이용하여, 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)을 생성하는 것을 학습할 수 있다. 한편, 인공지능 모델을 검증 또는 실행하는 단계에서, 레이블 데이터(LBL_D)는 최종적으로 도출하고자 하는 결 과 데이터이기 때문에, 레이블 데이터(LBL_D)는 잠재 표현 생성부에 직접 입력 데이터로 제공될 수 없다. 따라서, 인공지능 모델을 검증 또는 실행하는 단계에서는, 미리 학습된 예측 모델을 추가적으로 이용할 수 있다. 미리 학습된 예측 모델은 특성 데이터(FT_D)를 입력으로 하여, 예측 레이블 데이터를 생성할 수 있다. 즉, 인공지능 모델을 검증 또는 실행하는 단계에서는, 특성 데이터(FT_D)를 이용하여 생성된 예측 레이블 데이 터와, 특성 데이터(FT_D) 및 민감 데이터(STV_D)가 잠재 표현 생성부에 입력으로 제공되고, 잠재 표현 생 성부는 예측 레이블 데이터, 특성 데이터(FT_D) 및 민감 데이터(STV_D)를 이용하여 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)을 생성할 수 있다. 특성 데이터(FT_D) 및 민감 데이터(STV_D) 만을 이용하여 학습된 인공지능 모델은, 특성 데이터(FT_D), 민감 데 이터(STV_D) 및 레이블 데이터(LBL_D)를 이용하여 학습된 인공지능 모델보다 예측력이 상대적으로 낮은 결과가도출되었다. 따라서, 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치는, 예측력을 증가시키기 위해 학 습을 위한 입력 데이터로 특성 데이터(FT_D), 민감 데이터(STV_D) 및 레이블 데이터(LBL_D)를 이용하며, 이를 검증 및 실행하는 단계에서는 예측 레이블 데이터를 이용함으로써, 인공지능 모델의 예측력을 증가시킬 수 있다. 도 7은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치를 이용하여, 인공지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 설명의 편의를 위해 전술한 내용과 동일하거나 유사한 내용은 생략하거나 간단히 설명 한다. 도 1, 도 2 및 도 7을 참조하면, 인공지능 모델 학습 장치는 특성 데이터(FT_D), 민감 데이터(STV_D) 및 레이블 데이터(LBL_D)를 수신할 수 있다(S100). 인공지능 모델 학습 장치는 특성 데이터(FT_D), 민감 데이터(STV_D) 및 레이블 데이터(LBL_D)를 이용하여, 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)을 생성할 수 있다(S110). 이어서, 인공지능 모델 학습 장치는 민감 잠재 표현(STV_LTR) 및 비-민감 잠재 표현(NSTV_LTR)을 이용하여, 복 원 특성 데이터(rFT_D) 및 복원 민감 데이터(rSTV_D)를 생성할 수 있다(S120). 또한, 인공지능 모델 학습 장치 는 비-민감 잠재 표현(NSTV_LTR)을 이용하여, 복원 레이블 데이터(rLBL_D)를 생성할 수 있다(S130). 인공지능 모델 학습 장치는 특성 데이터(FT_D), 민감 데이터(STV_D), 레이블 데이터(LBL_D), 민감 잠재 표현 (STV_LTR), 비-민감 잠재 표현(NSTV_LTR), 복원 특성 데이터(rFT_D), 복원 민감 데이터(rSTV_D) 및 복원 레이 블 데이터(rLBL_D) 중 적어도 하나를 이용하여, 적어도 하나의 손실 함수를 결정할 수 있다(S140). 이어서, 인 공지능 모델 학습 장치는 결정된 손실 함수를 이용하여, 인공지능 모델 학습 장치를 업데이트할 수 있다(학습할 수 있다). 도 8은 본 발명의 다른 몇몇 실시예에 따른 인공지능 모델 학습 장치를 이용하여, 인공지능 모델을 학습하는 방 법을 설명하기 위한 도면이다. 설명의 편의를 위해 전술한 내용과 동일하거나 유사한 내용은 생략하거나 간단히 설명한다. 도 1, 도 5 및 도 8을 참조하면, 인공지능 모델 학습 장치는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이터(LBL_D1)를 이용하여, 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현 (NSTV_LTR1)을 생성할 수 있다. 또한, 인공지능 모델 학습 장치는 제2 특성 데이터(FT_D2), 제2 민감 데이터 (STV_D2) 및 제2 레이블 데이터(LBL_D2)를 이용하여, 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현 (NSTV_LTR2)을 생성할 수 있다(S210). 인공지능 모델 학습 장치는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복원 특성 데이터(rFT_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 생성할 수 있다. 또한, 인공지능 모델 학습 장치는 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복원 레이블 데이터(rLBL_D1)를 생성할 수 있다 (S220). 또한, 인공지능 모델 학습 장치는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용 하여, 제2 복원 특성 데이터(rFT_D2) 및 제2 복원 민감 데이터(rSTV_D2)를 생성할 수 있다. 또한, 인공지능 모 델 학습 장치는 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여 제2 복원 레이블 데이터(rLBL_D2)를 생성할 수 있다(S230). 인공지능 모델 학습 장치는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1), 제1 레이블 데이터(LBL_D1), 제 1 복원 특성 데이터(rFT_D1), 제1 복원 민감 데이터(rSTV_D1), 제1 복원 레이블 데이터(rLBL_D1), 제2 특성 데 이터(FT_D2), 제2 민감 데이터(STV_D2), 제2 레이블 데이터(LBL_D2), 제2 복원 특성 데이터(rFT_D2), 제2 복원 민감 데이터(rSTV_D2), 제2 복원 레이블 데이터(rLBL_D2), 제1 민감 잠재 표현(STV_LTR1), 제1 비-민감 잠재 표현(NSTV_LTR1), 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2) 중 적어도 하나를 이용 하여 손실함수를 계산할 수 있다(S240). 인공지능 모델 학습 장치는 계산된 손실함수를 이용하여, 인공지능 모델 학습 장치를 업데이트할 수 있다 (S250).도 9는 본 발명의 또 다른 몇몇 실시예에 따른 인공지능 모델 학습 장치를 이용하여, 인공지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 설명의 편의를 위해 전술한 내용과 동일하거나 유사한 내용은 생략하거나 간단 히 설명한다. 도 1, 도 6 및 도 9를 참조하면, 인공지능 모델 학습 장치는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1) 및 제1 레이블 데이터(LBL_D1)를 이용하여, 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현 (NSTV_LTR1)을 생성할 수 있다. 또한, 인공지능 모델 학습 장치는 제2 특성 데이터(FT_D2), 제2 민감 데이터 (STV_D2) 및 제2 레이블 데이터(LBL_D2)를 이용하여, 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현 (NSTV_LTR2)을 생성할 수 있다(S310). 인공지능 모델 학습 장치는 제1 민감 잠재 표현(STV_LTR1) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복원 특성 데이터(rFT_D1) 및 제1 복원 민감 데이터(rSTV_D1)를 생성할 수 있다. 또한, 인공지능 모델 학습 장치는 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용하여, 제1 복원 레이블 데이터(rLBL_D1)를 생성할 수 있다 (S320). 또한, 인공지능 모델 학습 장치는 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용 하여, 제2 복원 특성 데이터(rFT_D2) 및 제2 복원 민감 데이터(rSTV_D2)를 생성할 수 있다. 또한, 인공지능 모 델 학습 장치는 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용하여 제2 복원 레이블 데이터(rLBL_D2)를 생성할 수 있다(S330). 또한, 인공지능 모델 학습 장치는 제1 민감 잠재 표현(STV_LTR1) 및 제2 비-민감 잠재 표현(NSTV_LTR2)을 이용 하여, 제3 복원 특성 데이터(rFT_D3) 및 제3 복원 민감 데이터(rSTV_D3)를 생성할 수 있다(S340). 또한, 인공지능 모델 학습 장치는 제2 민감 잠재 표현(STV_LTR2) 및 제1 비-민감 잠재 표현(NSTV_LTR1)을 이용 하여, 제4 복원 특성 데이터(rFT_D4) 및 제4 복원 민감 데이터(rSTV_D4)를 생성할 수 있다(S350). 인공지능 모델 학습 장치는 제1 특성 데이터(FT_D1), 제1 민감 데이터(STV_D1), 제1 레이블 데이터(LBL_D1), 제 1 복원 특성 데이터(rFT_D1), 제1 복원 민감 데이터(rSTV_D1), 제1 복원 레이블 데이터(rLBL_D1), 제2 특성 데 이터(FT_D2), 제2 민감 데이터(STV_D2), 제2 레이블 데이터(LBL_D2), 제2 복원 특성 데이터(rFT_D2), 제2 복원 민감 데이터(rSTV_D2), 제2 복원 레이블 데이터(rLBL_D2), 제3 복원 특성 데이터(rFT_D3), 제3 복원 민감 데이 터(rSTV_D3), 제4 복원 특성 데이터(rFT_D4), 제4 복원 민감 데이터(rSTV_D4), 제1 민감 잠재 표현(STV_LTR1), 제1 비-민감 잠재 표현(NSTV_LTR1), 제2 민감 잠재 표현(STV_LTR2) 및 제2 비-민감 잠재 표현(NSTV_LTR2) 중 적어도 하나를 이용하여 손실함수를 계산할 수 있다(S240). 인공지능 모델 학습 장치는 계산된 손실함수를 이용하여, 인공지능 모델 학습 장치를 업데이트할 수 있다 (S250). 도 10은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 하드웨어 구현을 설명하기 위한 도면이다. 도 10을 참조하면, 본 발명의 몇몇 실시예들에 따른 인공지능 모델 학습 장치는 전자 장치로 구현될 수 있다. 전자 장치는 컨트롤러(1010, controller), 입출력 장치(1020, I/O), 메모리 장치(1030, memory device), 인터페이스(1040, interface) 및 버스(1050, bus)를 포함할 수 있다. 컨트롤러, 입출력 장치 , 메모리 장치 및/또는 인터페이스는 버스를 통하여 서로 결합될 수 있다. 이때, 버스 는 데이터들이 이동되는 통로(path)에 해당한다. 구체적으로, 컨트롤러는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit), 디지털 신호 프로세스, 마이 크로컨트롤러, 어플리케이션 프로세서(AP, application processor) 및 이들과 유사한 기능을 수행할 수 있는 논 리 소자들 중에서 적어도 하나를 포함할 수 있다. 입출력 장치는 키패드(keypad), 키보드, 터치스크린 및 디스플레이 장치 중 적어도 하나를 포함할 수 있 다. 메모리 장치는 데이터 및/또는 프로그램 등을 저장할 수 있다. 인터페이스는 통신 네트워크로 데이터를 전송하거나 통신 네트워크로부터 데이터를 수신하는 기능을 수행 할 수 있다. 인터페이스는 유선 또는 무선 형태일 수 있다. 예컨대, 인터페이스는 안테나 또는 유 무선 트랜시버 등을 포함할 수 있다. 도시하지 않았지만, 메모리 장치는 컨트롤러의 동작을 향상시 키기 위한 동작 메모리로서, 고속의 디램 및/또는 에스램 등을 더 포함할 수도 있다. 메모리 장치는 내부 에 프로그램 또는 어플리케이션을 저장할 수 있다. 본 발명의 실시예들에 따른 인공지능 모델 학습 장치는 각각 복수의 전자 장치가 네트워크를 통해서 서로 연결되어 형성된 시스템일 수 있다. 이러한 경우에는 각각의 모듈 또는 모듈의 조합들이 전자 장치로 구 현될 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 추가적으로, 인공지능 모델 학습 장치는 워크스테이션(workstation), 데이터 센터, 인터넷 데이터 센터 (internet data center(IDC)), DAS(direct attached storage) 시스템, SAN(storage area network) 시스템, NAS(network attached storage) 시스템, RAID(redundant array of inexpensive disks, or redundant array of independent disks) 시스템, 및 EDMS(Electronic Document Management) 시스템 중 적어도 하나로 구현될 수 있 으나, 본 실시예가 이에 제한되는 것은 아니다. 또한, 인공지능 모델 학습 장치에 포함된 적어도 일부 구성은 네트워크를 통해서 데이터를 교환할 수 있다. 네 트워크는 유선 인터넷 기술, 무선 인터넷 기술 및 근거리 통신 기술에 의한 네트워크를 포함할 수 있다. 유선 인터넷 기술은 예를 들어, 근거리 통신망(LAN, Local area network) 및 광역 통신망(WAN, wide area network) 중 적어도 하나를 포함할 수 있다. 무선 인터넷 기술은 예를 들어, 무선랜(Wireless LAN: WLAN), DMNA(Digital Living Network Alliance), 와이브 로(Wireless Broadband: Wibro), 와이맥스(World Interoperability for Microwave Access: Wimax), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), IEEE 802.16, 롱 텀 에볼루션(Long Term Evolution: LTE), LTE-A(Long Term Evolution-Advanced), 광대역 무선 이동 통신 서비스 (Wireless Mobile Broadband Service: WMBS) 및 5G NR(New Radio) 기술 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 근거리 통신 기술은 예를 들어, 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신 (Infrared Data Association: IrDA), UWB(Ultra-Wideband), 지그비(ZigBee), 인접 자장 통신(Near Field Communication: NFC), 초음파 통신(Ultra Sound Communication: USC), 가시광 통신(Visible Light Communication: VLC), 와이 파이(Wi-Fi), 와이 파이 다이렉트(Wi-Fi Direct), 5G NR (New Radio) 중 적어도 하 나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 네트워크를 통해서 통신하는 인공지능 모델 학습 장치는 이동통신을 위한 기술표준 및 표준 통신 방식을 준수할 수 있다. 예를 들어, 표준 통신 방식은 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTEA(Long Term Evolution-Advanced) 및 5G NR(New Radio) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2022-0049146", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 구성을 개략적으로 설명하기 위한 도면이다. 도 2는 본 발명의 몇몇 실시예들에 따른 잠재 표현 생성부 및 데이터 복원부의 구조를 설명하기 위한 도면이다. 도 3은 본 발명의 몇몇 실시예에 따른 민감 잠재 표현 및 비-민감 잠재 표현이 생성되는 과정을 설명하기 위한 도면이다. 도 4는 본 발명의 몇몇 실시예에 따른 복원 특성 데이터, 복원 민감 데이터 및 복원 레이블 데이터가 생성되는 과정을 설명하기 위한 도면이다. 도 5는 본 발명의 다른 몇몇 실시예들에 따른 잠재 표현 생성부 및 데이터 복원부의 구조를 설명하기 위한 도면 이다. 도 6은 본 발명의 또 다른 몇몇 실시예들에 따른 잠재 표현 생성부 및 데이터 복원부의 구조를 설명하기 위한 도면이다. 도 7은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치를 이용하여, 인공지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 8은 본 발명의 다른 몇몇 실시예에 따른 인공지능 모델 학습 장치를 이용하여, 인공지능 모델을 학습하는 방 법을 설명하기 위한 도면이다. 도 9는 본 발명의 또 다른 몇몇 실시예에 따른 인공지능 모델 학습 장치를 이용하여, 인공지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 10은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 하드웨어 구현을 설명하기 위한 도면이다."}
