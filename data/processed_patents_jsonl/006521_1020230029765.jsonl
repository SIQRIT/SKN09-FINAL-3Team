{"patent_id": "10-2023-0029765", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0136611", "출원번호": "10-2023-0029765", "발명의 명칭": "인공지능 기반 K-POP 댄스 애플리케이션", "출원인": "비시스 주식회사", "발명자": "문현미"}}
{"patent_id": "10-2023-0029765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 단말기와 결합되어, 상기 댄스 트레이닝을 하는 사용자의 모습을 카메라가 촬영한 영상 데이터를 입력받는 단계; 상기 입력받은 영상 데이터에서 사용자를 인식하여, 배경과 사용자 영역을 분리하는 단계; 상기 분리된 사용자 영역에서, 사용자의 신체 부위 인식 기반의 관절 정보를 이용해 뼈대를 추출하고, 상기 추출한 뼈대를 이용해 포즈를 추정하는 단계; 및 상기 추정된 포즈에 대한 사용자 모션을 분석하는 단계를 포함하는, 매체에 저장된 애플리케이션."}
{"patent_id": "10-2023-0029765", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 사용자 단말기와 결합되어, 상기 댄스 트레이닝을 하는 사용자의 모습을 카메라가 촬영한 영상 데이터를 입력받는 단계; 상기 입력받은 영상 데이터에서 사용자를 인식하여, 배경과 사용자 영역을 분리하는 단계; 상기 분리된 사용자 영역에서, 사용자의 신체 부위 인식 기반의 관절 정보를 이용해 뼈대를 추출 하고, 상기 추출한 뼈대를 이용해 포즈를 추정하는 단계; 및 상기 추정된 포즈에 대한 사용자 모션을 분석하는 단계를 포함하는, 매체에 저장된 애플리케이션이 제공된다."}
{"patent_id": "10-2023-0029765", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반 K-POP 댄스 애플리케이션에 관한 것이다."}
{"patent_id": "10-2023-0029765", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 한류(韓流)는 한국의 대중문화가 해외로 전파되어 대중적으로 소비되고 있는 현상을 말한다. 한류는 한류 생성기(1997년 내지 2000년) 및 한류 심화 2기(2000년대 중반)를 넘어, 한류 다양화의 3기(2000년 중반 이 후)를 맞이하고 있다. 특히, 한류 3기에서 한류는 드라마, 음악, 영화, 게임 등의 콘텐츠를 소비하는 문화에서 직접 참여하거나 체험하고자 하는 문화로까지 발전하고 있다. 한류의 확산에 따라 K-Pop 아카데미 이외에도, 유튜브(Youtube) 등의 영상 스트리밍 서비스를 이용하여 직접 K- Pop 댄스를 트레이닝하고자 하는 사용자가 증가하고 있다. 그러나 이러한 동영상을 이용한 댄스 트레이닝 방식 은 사용자가 업로드된 동영상에서 아이돌(Idol)의 댄스 동작을 단순히 따라 하는 것에 불과하므로, 제대로 된 댄스 트레이닝이 이루어질 수 없다는 문제점이 있다. 사용자는 아무런 피드백 없이 동영상을 통해 일방적으로만 영상 정보를 전달받으면서, 현재 자신이 추고 있는 댄스 동작이 얼마나 정확한지 또는 어느 부분이 일치하지 않 는지를 스스로 판단해야 하기 때문이다. 특히, 동영상을 이용한 댄스 트레이닝 방식에서 사용자는 자신의 동작에 대해 아무런 피드백을 받을 수 없으므 로, 사용자가 댄스 트레이닝을 지속하기가 매우 어렵다는 문제점이 있다. 댄스 트레이닝을 지속할 수 있도록 돕 는 전문 강사 없이 사용자는 동영상만을 보며 정해진 동작을 반복해야 하므로, 댄스 트레이닝에 따른 성취감을 전혀 느낄 수 없기 때문이다."}
{"patent_id": "10-2023-0029765", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 종래 기술의 문제점을 해결하기 위한 것이다. 본 발명의 목적은, 인공지능 기반의 영상 인식을 통해 영상 내 사용자의 관절 정보를 이용해 뼈대를 추출하고, 추출한 뼈대를 이용해 포즈를 추정하여 사용자의 모션을 분석하여 제공하는 것이다. 본 발명의 목적은, 댄스 트레이닝을 하는 사용자의 댄스 동작을 레퍼런스 댄스 동작과 실시간으로 비교할 수 있 으며 댄스별 미션을 제시하여 점차 높은 난이도의 댄스 트레이닝을 진행할 수 있도록 하는 것이다."}
{"patent_id": "10-2023-0029765", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 발명의 일 실시예에 따르면, 사용자 단말기와 결합되어, 상기 댄스 트레이닝을 하는 사용자의 모습을 카메라가 촬영한 영상 데이터를 입력받는 단계; 상기 입력받은 영상 데이터에서 사용자를인식하여, 배경과 사용자 영역을 분리하는 단계; 상기 분리된 사용자 영역에서, 사용자의 신체 부위 인식 기반 의 관절 정보를 이용해 뼈대를 추출하고, 상기 추출한 뼈대를 이용해 포즈를 추정하는 단계; 및 상기 추정된 포 즈에 대한 사용자 모션을 분석하는 단계를 포함하는, 매체에 저장된 애플리케이션이 제공된다."}
{"patent_id": "10-2023-0029765", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 인공지능 기반의 영상 인식을 통해 영상 내 사용자의 관절 정보를 이용해 뼈대 를 추출하고, 추출한 뼈대를 이용해 포즈를 추정하여 사용자의 모션을 분석하여 제공할 수 있다. 본 발명의 일 실시예에 따르면, 댄스 트레이닝을 하는 사용자의 댄스 동작을 레퍼런스 댄스 동작과 실시간으로 비교할 수 있으며 댄스별 미션을 제시하여 점차 높은 난이도의 댄스 트레이닝을 진행할 수 있게 된다."}
{"patent_id": "10-2023-0029765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예 에 대하여 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 도 1은 본 발명의 일 실시예에 따른 인공지능 기반 K-POP 댄스 애플리케이션의 기능을 설명하기 위한 도면이다. 이하에서 설명되는 동작은, 사용자 단말기, 예를 들면, 스마트폰 내에 설치된 애플리케이션이 별도의 서버와 연 동하여 동작되는 것으로 이해될 수 있다. 단계 S100에서는, 댄스 트레이닝을 하는 사용자의 모습을 카메라가 촬영한 영상 데이터를 입력받을 수 있다. 여 기서, 카메라는 사용자 단말기에 장착된 카메라일 수 있다. 실시예에 따라서, 단계 S100에서는, 카메라가 촬영한 2차원의 영상 데이터를 처리하여 뎁스 맵(Depth map)으로 변환할 수 있다. 뎁스 맵은, 3차원 컴퓨터 그래픽스에서 관찰 시점(viewpoint)으로부터 물체 표면과의 거리와 관련된 정보가 담긴 하나의 영상을 의미하는 것으로서, 단계 S100에서는, 카메라가 촬영한 영상 데이터를 흑백 으로 변환하고, 명도 차이에 따라 깊이가 차등화하여 표시되도록 변환하여 뎁스 맵을 생성할 수 있다. 뎁스 맵 을 통해 2차원의 영상 데이터로부터 3차원의 사용자 모션을 파악할 수 있다. 단계 S200에서는, 입력받은 영상 데이터에서 사용자를 인식하여, 배경과 사용자 영역을 분리할 수 있다. 이때, 단계 S200에서는 딥러닝 기반으로 사전 학습된 객체 인식 모델을 통해 사용자를 인식하고, 배경과 사용자 영역 을 분리할 수 있다. 여기서, 단계 S100에서 영상 데이터를 뎁스 맵으로 변환해 사용하는 경우, 단계 S200에서는 뎁스 맵으로부터 사용자 영역을 검출하여 분리할 수 있다. 단계 S200의 사전 학습된 객체 인식 모델은, 사람을 인식해 경계 상자(bounding box)로 구분하도록 대량의 학습 데이터로 학습된 딥러닝 모델로서, ResNet, ResNet50-FPN, Fast R-CNN, Faster R-CNN, Mask R-CNN 등을 이용해 사용자를 인식하고 사용자 영역을 분리할 수 있다. 또한, 단계 S200에서는, 입력받은 영상 데이터에서 인식되는 사용자가 복수이면, 복수의 사용자 영역을 배경과 각각 분리하며, 분리된 사용자 영역에 태깅하여 각각의 사용자를 식별할 수 있다. 즉, 영상 데이터에 복수의 사 용자가 촬영되어 있을 수 있는데, 단계 S200에서는 사용자별로 각각 사용자 영역을 분리하고, 각각의 사용자를 식별할 수 있다. 본 발명의 일실시예에 따른 인공지능 기반의 영상 인식을 이용한 댄스 트레이닝을 위한 사용자 모션 분석 방법 의 단계 S200은, 입력받은 영상 데이터로부터 사용자 모습을 포함하는 복수의 후보 영역을 검출하는 단계 및 이 전 프레임의 사용자 영역과의 관계를 고려하여 복수의 후보 영역 중 현재 프레임의 사용자 영역을 특정하고 배 경과 분리하는 단계를 포함하여 구현될 수 있다. 후보 영역 검출 단계는, 입력받은 영상 데이터로부터 사용자 모습을 포함하는 복수의 후보 영역을 검출할 수 있 다. 여기서, 복수의 후보 영역들은 적어도 일부가 중첩될 수 있다. 객체 인식 모델을 이용해 사용자 영역을 검 출하면, 경계 상자(bounding box) 형태로 후보 영역을 검출하게 되는데, 목표로 하는 하나의 사용자 영역에 대 해 다양한 크기와 형태를 가지는 복수 개의 후보 영역이 검출될 수 있다.현재 프레임의 사용자 영역을 특정하고 배경과 분리하는 단계는, 이전 프레임의 사용자 영역과의 관계를 고려하 여, 복수의 후보 영역 중 현재 프레임의 사용자 영역을 특정하고 배경과 분리할 수 있다. 보다 구체적으로, 단 계 S220에서는, 복수의 후보 영역과 이전 프레임의 사용자 영역 사이의 매칭 점수를 각각 산출하고, 가장 높은 매칭 점수가 산출된 후보 영역을 현재 프레임의 사용자 영역으로 특정할 수 있다. 실시예에 따라서, 후보 영역 검출 단계에서 검출된 각각의 후보 영역의 특징맵과, 이전 프레임에서 특정된 사용 자 영역의 특징맵을 사용해, 유사도를 비교하고 가장 유사도가 높은 후보 영역을 현재 프레임의 사용자 영역으 로 특정할 수 있다. 따라서 연속적인 영상 데이터가 프레임 단위로 입력되는 댄스 트레이닝 영상에서, 댄스 트 레이닝을 하는 사용자의 모습을 정확하게 추적하고 분석할 수 있다. 단계 S300에서는, 분리된 사용자 영역에서, 사용자의 신체 부위 인식 기반의 관절 정보를 이용해 뼈대를 추출하 고, 추출한 뼈대를 이용해 포즈를 추정할 수 있다. 여기서, 단계 S300에서는, 딥러닝 기반으로 사전 학습된 포 즈 추정 모델을 이용해 포즈를 추정할 수 있다. 이때, 딥러닝 기반으로 사전 학습된 포즈 추정 모델은, Mask R- CNN, Faster R-CNN, MNC 등일 수 있다. 본 발명의 일실시예에 따른 인공지능 기반의 영상 인식을 이용한 댄스 트레이닝을 위한 사용자 모션 분석 방법 의 단계 S300은, 사용자 영역을 포즈 추정 모델의 입력으로 하여, 각각의 관절의 좌표 분포 맵을 추정하는 단계, 추정된 관절의 좌표 분포 맵으로부터 각각의 관절의 좌표를 획득하는 단계, 관절의 좌표를 연결하여 뼈대 를 추출하는 단계 및 추출한 뼈대로부터 사용자 포즈를 추정하는 단계를 포함하여 구현될 수 있다. 한편, 단계 S200 및 단계 S300은, 딥러닝 기반으로 사전 학습된 포즈 추정 모델을 이용해 처리될 수도 있다. 예 를 들어, Mask R-CNN은 사용자를 인식해 사용자 영역을 특정하고, 사용자의 포즈를 추정할 수 있는 포즈 추정 모델로서, 단계 S200 및 단계 S300을 모두 수행할 수 있다. 단계 S300에서는, 단계 S200에서 도출된 후보 영역으로부터 RoIAlign을 이용해 특징 맵을 추출할 수 있다. RoIAlign은 이중선형보간법(bilinear interpolation)을 이용해 특징맵의 후보 영역(관심 영역, RoI)을 정확하 게 정렬되도록 하여, 보정된 특징맵을 생성할 수 있다. 보정된 특징맵을 ResNet 등 CNN 기반 포즈 추정 모델의 입력으로 하여 클래스를 분류해 사용자 영역을 특정하고, 사용자의 신체의 키-포인트 즉, 관절의 좌표를 검출하 여 각 관절의 좌표를 연결해 뼈대를 추출할 수 있다. Mask R-CNN은 클래스 분류와 관절 좌표 검출을 동시에 수 행할 수 있다. 단계 S400에서는, 추정된 포즈에 대한 사용자 모션을 분석할 수 있다. 즉, 단계 S400에서는, 추정된 포즈를 사 용해 사용자의 모션을 분석하여 분석 결과를 댄스 트레이닝 제공 장치, 즉, 별도의 서버에 전달함으로써, 사용 자의 댄스 트레이닝에 대한 피드백을 제공하거나 다양한 영상 효과를 제공하도록 할 수 있다. 단계 S400에서는, 인체 레퍼런스 모델과 추정된 포즈를 비교하여, 사용자 모션을 분석할 수 있다. 보다 구체적 으로, 단계 S400에서는, 인체 레퍼런스 모델의 뼈대와 단계 S300에서 추출한 뼈대 사이의 유사도를 측정하여 비 교할 수 있다. 즉, 인체의 댄스 동작 표현을 위해 뼈대 기반의 인체 레퍼런스 모델을 구축하고, 단계 S300에서 추출한 사용자의 뼈대와 비교해 사용자의 댄스 동작을 검증하고 평가할 수 있다. 실시예에 따라서, 인체 레퍼런스 모델은 3차원 모델로 구성하고, 단계 S300에서 추출한 뼈대와 인체 레퍼런스 모델을 비교한 결과를 이용해, 사용자 포즈를 3차원 데이터로 재구성할 수도 있다. 이상에서 본 발명의 바람직한 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것 은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1"}
{"patent_id": "10-2023-0029765", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 기반 K-POP 댄스 애플리케이션의 기능을 설명하기 위한 도면이다."}
