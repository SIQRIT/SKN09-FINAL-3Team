{"patent_id": "10-2021-0003375", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0101403", "출원번호": "10-2021-0003375", "발명의 명칭": "립싱크 영상 생성 장치 및 방법", "출원인": "주식회사 딥브레인에이아이", "발명자": "황금별"}}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 립싱크 영상 생성 장치로서, 인물 배경 영상 및 상기 인물 배경 영상과 대응하는 발화 일치 오디오 신호를 입력으로 하여 발화 일치 합성 영상을 생성하고, 인물 배경 영상 및 상기 인물 배경 영상과 대응하지 않는 발화 불일치 오디오 신호를 입력으로하여 발화 불일치 합성 영상을 생성하는 제1 인공 신경망 모델; 및영상과 음성이 일치하는 입력 쌍 및 영상과 음성이 불일치 하는 입력 쌍을 입력으로 하여 그에 대한 분류 값을출력하는 제2 인공 신경망 모델을 포함하는, 립싱크 영상 생성 장치."}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 인물 배경 영상은, 영상 속 인물의 발화와 관련된 부분이 마스크로 가려진 영상인, 립싱크 영상 생성 장치."}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 상기 제2 인공 신경망 모델은, 상기 영상과 음성이 일치하는 입력 쌍은 참(True)으로 분류하고, 상기 영상과 음성이 불일치 하는 입력 쌍은 거짓(False)으로 분류하도록 학습되는, 립싱크 영상 생성 장치."}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 제2 인공 신경망 모델은, 상기 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상 및 상기 발화 불일치 합성 영상의 생성 시 입력으로 사용된 발화 불일치 오디오 신호를 입력 받고 이를 참(True)으로 분류하도록 하며, 적대적 학습(AdversarialLearning) 방법을 통해 적대적 생성 에러를 상기 제1 인공 신경망 모델로 전파하는, 립싱크 영상 생성 장치."}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서, 상기 제1 인공 신경망 모델은,인물 배경 영상을 입력으로 하고, 상기 입력되는 인물 배경 영상으로부터 영상 특징 벡터를 추출하는 제1 인코더;상기 인물 배경 영상과 대응하는 발화 일치 오디오 신호를 입력으로 하고, 상기 입력되는 발화 일치 오디오 신공개특허 10-2022-0101403-3-호로부터 음성 특징 벡터를 추출하는 제2 인코더;상기 영상 특징 벡터와 상기 음성 특징 벡터를 조합하여 조합 벡터를 생성하는 조합부; 및상기 조합 벡터를 입력으로 하고, 상기 조합 벡터를 기반으로 상기 발화 일치 합성 영상을 생성하는 디코더를포함하는, 립싱크 영상 생성 장치."}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서, 상기 제1 인공 신경망 모델의 상기 발화 일치 합성 영상의 생성을 위한 목적 함수(Lreconstruction)는 다음의 수학식을 통해 표현되는, 립싱크 영상 생성 장치.(수학식): 원래의 발화 영상: 발화 일치 합성 영상: A와 B의 차이를 구하는 함수"}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 제2 인공 신경망 모델의 목적 함수(Ldiscriminator)는 다음의 수학식을 통해 표현되는, 립싱크 영상 생성 장치.(수학식)D : 제2 인공 신경망 모델의 신경망(Ii, Ai) : 영상과 음성이 일치하는 입력 쌍(i번째 영상과 i번째 음성)(Ii, Aj) : 영상과 음성이 불일치 하는 입력 쌍(i번째 영상과 j번째 음성)"}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 제1 인공 신경망 모델의 상기 발화 불일치 합성 영상의 생성을 위한 적대적 목적 함수(Ladversarial)는 다음의수학식을 통해 표현되는, 립싱크 영상 생성 장치.(수학식)G : 제1 인공 신경망 모델을 구성하는 신경망 : 발화와 관련된 부분이 마스킹 처리된 인물 배경 영상(Mi : 마스크)공개특허 10-2022-0101403-4-: 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상Aj : 인물 배경 영상과 대응되지 않는 발화 불일치 오디오 신호"}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 상기 제1 인공 신경망 모델의 상기 발화 일치 합성 영상 및 상기 발화 불일치 합성 영상을 생성하기 위한 최종목적 함수(LT)는 다음의 수학식을 통해 표현되는, 립싱크 영상 생성 장치.(수학식)λ : 가중치"}
{"patent_id": "10-2021-0003375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방법으로서, 제1 인공 신경망 모델에서, 인물 배경 영상 및 상기 인물 배경 영상과 대응하는 발화 일치 오디오 신호를 입력으로 하여 발화 일치 합성 영상을 생성하고, 인물 배경 영상 및 상기 인물 배경 영상과 대응하지 않는 발화 불일치 오디오 신호를 입력으로 하여 발화 불일치 합성 영상을 생성하는 동작; 및제2 인공 신경망 모델에서, 영상과 음성이 일치하는 입력 쌍 및 영상과 음성이 불일치 하는 입력 쌍을 입력으로하여 그에 대한 분류 값을 출력하는 동작을 포함하는, 립싱크 영상 생성 방법."}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "립싱크 영상 생성 방법 및 장치가 개시된다. 개시되는 일 실시예에 따른 립싱크 영상 생성 장치는, 하나 이상의 프로세서들, 및 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 립싱크 영상 생성 장치로서, 인물 배경 영상 및 인물 배경 영상과 대응하는 발화 일치 오디오 신호를 입력으로 하여 발화 일치 합성 영상을 생성하고, 인물 배경 영상 및 인물 배경 영상과 대응하지 않는 발화 불일치 오디오 신호를 입력으로 하여 발화 불일치 합성 영상을 생성하는 제1 인공 신경망 모델 및 영상과 음성이 일치하는 입력 쌍 및 영상과 음성이 불일치 하는 입력 쌍을 입력으로 하여 그에 대한 분류 값을 출력하는 제2 인공 신경망 모델 을 포함한다."}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 립싱크 영상 생성 기술과 관련된다."}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 인공 지능 분야의 기술 발전에 따라 다양한 유형의 콘텐츠가 인공 지능 기술에 기초하여 생성되고 있다. 그 일 예로, 어떤 전달하고자 하는 음 성 메시지가 있을 때, 그 음성 메시지를 유명 인물(예를 들어, 대통령 등)이 말하 는 것과 같은 발화 동영상(립싱크 동영상)을 생성하여 사람들의 주의를 끌고자 하는 경우가 있다. 이는 유명 인물의 영상에서 유명 인물이 특정 메시지를 말하는 것처럼 입 모양 등을 특정 메시지에 맞게 생성하 여 구현하게 된다. 립싱크 영상 생성을 위한 학습 모델은 원본 영상이 있을 때 임의의 음성이 입력되면 입력된 음성과 입 모양이 일치하도록 립싱크 영상을 생성하는 모델로, 인물 배경 영상과 음성을 입력으로 하여 그에 대응하는 타겟 영상 을 학습하게 된다. 이때, 인물 배경 영상과 불일치 하는 음성에 대응하는 타겟 영상은 실제 존재하지 않으므로, 립싱크 영상 생성 모델은 인물 배경 영상과 일치하는 음성만을 사용하여 학습해야 하는 제약이 있으며, 그로 인 해 생성되는 립싱크 영상이 부자연스럽게 되는 문제점이 있다. 선행기술문헌특허문헌 (특허문헌 0001) 한국등록특허공보 제10-1177408호(2012.08.27)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는 자연스러운 립싱크 영상 합성이 가능한 립싱크 영상 생성 장치 및 방법을 제공하기 위한 것 이다."}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시되는 일 실시예에 따른 립싱크 영상 생성 장치는, 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세서 들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 립싱크 영상 생성 장치로서, 인물 배 경 영상 및 상기 인물 배경 영상과 대응하는 발화 일치 오디오 신호를 입력으로 하여 발화 일치 합성 영상을 생 성하고, 인물 배경 영상 및 상기 인물 배경 영상과 대응하지 않는 발화 불일치 오디오 신호를 입력으로 하여 발 화 불일치 합성 영상을 생성하는 제1 인공 신경망 모델; 및 영상과 음성이 일치하는 입력 쌍 및 영상과 음성이 불일치 하는 입력 쌍을 입력으로 하여 그에 대한 분류 값을 출력하는 제2 인공 신경망 모델을 포함한다. 상기 인물 배경 영상은, 영상 속 인물의 발화와 관련된 부분이 마스크로 가려진 영상일 수 있다. 상기 제2 인공 신경망 모델은, 상기 영상과 음성이 일치하는 입력 쌍은 참(True)으로 분류하고, 상기 영상과 음 성이 불일치 하는 입력 쌍은 거짓(False)으로 분류하도록 학습될 수 있다. 상기 제2 인공 신경망 모델은, 상기 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상 및 상기 발화 불일 치 합성 영상의 생성 시 입력으로 사용된 발화 불일치 오디오 신호를 입력 받고 이를 참(True)으로 분류하도록 하며, 적대적 학습(Adversarial Learning) 방법을 통해 적대적 생성 에러를 상기 제1 인공 신경망 모델로 전파 할 수 있다. 상기 제1 인공 신경망 모델은, 인물 배경 영상을 입력으로 하고, 상기 입력되는 인물 배경 영상으로부터 영상 특징 벡터를 추출하는 제1 인코더; 상기 인물 배경 영상과 대응하는 발화 일치 오디오 신호를 입력으로 하고, 상기 입력되는 발화 일치 오디오 신호로부터 음성 특징 벡터를 추출하는 제2 인코더; 상기 영상 특징 벡터와 상 기 음성 특징 벡터를 조합하여 조합 벡터를 생성하는 조합부; 및 상기 조합 벡터를 입력으로 하고, 상기 조합 벡터를 기반으로 상기 발화 일치 합성 영상을 생성하는 디코더를 포함할 수 있다. 상기 제1 인공 신경망 모델의 상기 발화 일치 합성 영상의 생성을 위한 목적 함수(Lreconstruction)는 다음의 수학식 을 통해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": ": 원래의 발화 영상 : 발화 일치 합성 영상 : A와 B의 차이를 구하는 함수 상기 제2 인공 신경망 모델의 목적 함수(Ldiscriminator)는 다음의 수학식을 통해 표현될 수 있다. (수학식) D : 제2 인공 신경망 모델의 신경망 (Ii, Ai) : 영상과 음성이 일치하는 입력 쌍(i번째 영상과 i번째 음성) (Ii, Aj) : 영상과 음성이 불일치 하는 입력 쌍(i번째 영상과 j번째 음성) 상기 제1 인공 신경망 모델의 상기 발화 불일치 합성 영상의 생성을 위한 적대적 목적 함수(Ladversarial)는 다음의 수학식을 통해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "G : 제1 인공 신경망 모델을 구성하는 신경망 : 발화와 관련된 부분이 마스킹 처리된 인물 배경 영상(Mi : 마스크) : 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상 Aj : 인물 배경 영상과 대응되지 않는 발화 불일치 오디오 신호 상기 제1 인공 신경망 모델의 상기 발화 일치 합성 영상 및 상기 발화 불일치 합성 영상을 생성하기 위한 최종 목적 함수(LT)는 다음의 수학식을 통해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "λ : 가중치 개시되는 일 실시예에 따른 립싱크 영상 생성 방법은, 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세서 들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방법으로서, 제1 인공 신경망 모델에서, 인물 배경 영상 및 상기 인물 배경 영상과 대응하는 발화 일치 오디오 신호를 입력으로 하여 발화 일치 합성 영상을 생성하고, 인물 배경 영상 및 상기 인물 배경 영상과 대응하지 않 는 발화 불일치 오디오 신호를 입력으로 하여 발화 불일치 합성 영상을 생성하는 동작; 및 제2 인공 신경망 모 델에서, 영상과 음성이 일치하는 입력 쌍 및 영상과 음성이 불일치 하는 입력 쌍을 입력으로 하여 그에 대한 분 류 값을 출력하는 동작을 포함한다."}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시되는 실시예에 의하면, 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상 및 발화 불일치 오디오 신호 가 입력되는 경우, 제2 인공 신경망 모델을 통해 발화 불일치 합성 영상과 발화 불일치 오디오 신호 간의 일치 정도를 판별하고 그 일치 정도에 대한 적대적 생성 에러를 제1 인공 신경망 모델로 전파하며, 제1 인공 신경망 모델이 발화 불일치 합성 영상과 그에 대응하는 발화 불일치 오디오 신호에 대해 제2 인공 신경망 모델이 참으 로 분류하도록 적대적 학습 방법을 통해 학습함으로써, 제1 인공 신경망 모델에서 인물 배경 영상 및 인물 배경 영상과 일치하지 않는 발화 오디오 신호가 입력되더라도 보다 자연스러운 발화 합성 영상을 생성할 수 있게 된 다."}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 이하의 설명에 있어서, 신호 또는 정보의 \"전송\", \"통신\", \"송신\", \"수신\" 기타 이와 유사한 의미의 용어는 일 구성요소에서 다른 구성요소로 신호 또는 정보가 직접 전달되는 것뿐만이 아니라 다른 구성요소를 거쳐 전달되 는 것도 포함한다. 특히 신호 또는 정보를 일 구성요소로 \"전송\" 또는 \"송신\"한다는 것은 그 신호 또는 정보의 최종 목적지를 지시하는 것이고 직접적인 목적지를 의미하는 것이 아니다. 이는 신호 또는 정보의 \"수신\"에 있 어서도 동일하다. 또한 본 명세서에 있어서, 2 이상의 데이터 또는 정보가 \"관련\"된다는 것은 하나의 데이터(또 는 정보)를 획득하면, 그에 기초하여 다른 데이터(또는 정보)의 적어도 일부를 획득할 수 있음을 의미한다. 또한, 제1, 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로 사용될 수 있다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성 요소로 명 명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 도 1은 본 발명의 일 실시예에 따른 립싱크 영상 생성 장치의 구성을 나타낸 도면이다. 도 1을 참조하면, 립싱크 영상 생성 장치는 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 포함할 수 있다. 제1 인공 신경망 모델은 인물 배경 영상 및 발화 일치 오디오 신호를 입력으로 하여 발화 일치 합성 영상 을 생성하도록 학습되는 모델일 수 있다. 여기서, 인물 배경 영상은 인물이 발화 하는(말을 하는) 영상으로, 영 상에서 인물의 발화와 관련된 부분이 마스킹(Masking) 처리된 영상일 수 있다. 그리고, 발화 일치 오디오 신호 는 인물 배경 영상(즉, 인물이 발화하는 영상) 중 오디오 부분일 수 있다. 즉, 발화 일치 오디오 신호는 인물 배경 영상에서 해당 인물의 발화하는 모습과 일치하는(매칭되는) 음성 신호일 수 있다. 여기서, 제1 인공 신경망 모델은 입력되는 발화 일치 오디오 신호를 통해 인물 배경 영상에서는 마스크로 가려진 발화 관련 부분을 복원하여 발화 일치 합성 영상을 생성하도록 학습될 수 있다. 이때, 제1 인공 신경망 모델은 인물 배경 영상과 일치하는 발화 일치 오디오 신호를 이용하여 발화 일치 합성 영상을 생성하도록 학습되기 때문에, 학습 이후의 추론 과정에서 인물 배경 영상 및 인물 배경 영상과 일 치하지 않는 발화 오디오 신호(즉, 발화 불일치 오디오 신호)를 입력하였을 때 보다 자연스러운 발화 합성 영상 을 생성하기 위해서는, 인물 배경 영상과 발화 오디오 신호 간에 제어 영역을 분리하여 학습하도록 유도할 필요 가 있다. 즉, 제1 인공 신경망 모델에서 발화 관련 부분은 발화 오디오 신호를 통해서 제어되도록 하고, 인물 배경 영상에 의해 제어되는 것을 방지하는 것이 필요하다. 이에 개시되는 실시예에서는, 제1 인공 신경망 모델이 인물 배경 영상 및 발화 불일치 오디오 신호(인물 배경 영상과 불일치 하는 발화 오디오 신호)를 입력으로 하여 발화 불일치 합성 영상을 생성하도록 할 수 있다. 예를 들어, 인물 배경 영상은 영상 속 인물이 \"오늘 날씨는 맑겠습니다\"라는 발화를 하는 모습의 영상이라고 하 면, 발화 불일치 오디오 신호는 \"어제 기분이 우울했어요\"라는 인물 배경 영상과는 매칭되지 않는 음성 신호일 수 있다. 그리고, 제2 인공 신경망 모델은 인물 영상 및 인물 영상과 일치하는 발화 오디오 신호(즉, 영상과 음성이 일치하는 입력 쌍)가 입력되면 이를 참(True)으로 분류하고, 인물 영상 및 인물 영상과 불일치 하는 발화 오디 오 신호(즉, 영상과 음성이 불일치 하는 입력 쌍)가 입력되면 이를 거짓(False)으로 분류하도록 학습될 수 있다. 또한, 제2 인공 신경망 모델은 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상 및 발화 불일 치 오디오 신호(발화 불일치 합성 영상을 생성할 때 입력으로 사용된 발화 불일치 오디오 신호)가 입력되는 경 우, 발화 불일치 합성 영상과 발화 불일치 오디오 신호 간의 일치 정도를 판별하고 그 일치 정도에 대한 적대적 생성 에러를 제1 인공 신경망 모델로 전파할 수 있다. 그리고, 제1 인공 신경망 모델은 발화 불일치 합성 영상과 그에 대응하는 발화 불일치 오디오 신호에 대하여 제2 인공 신경망 모델이 참(True)으로 분류 하도록 적대적 학습(Adversarial Learning) 방법을 통해 학습될 수 있다. 이와 같이, 제1 인공 신경망 모델이 발화 불일치 합성 영상 및 발화 불일치 오디오 신호에 대해 제2 인공 신경망 모델이 그 입력 쌍을 참(True)으로 분류하도록 적대적 학습(Adversarial Learning) 방법을 통해 학 습됨으로써, 제1 인공 신경망 모델에서 인물 배경 영상 및 인물 배경 영상과 일치하지 않는 발화 오디오 신호가 입력되더라도 보다 자연스러운 발화 합성 영상을 생성할 수 있게 된다. 도 2는 본 발명의 일 실시예에서 제1 인공 신경망 모델이 발화 일치 합성 영상을 생성하는 상태를 개략적 으로 나타낸 도면이다. 도 2를 참조하면, 제1 인공 신경망 모델은 제1 인코더, 제2 인코더, 조합부, 및 디코더 를 포함할 수 있다. 예시적인 실시예에서, 제1 인공 신경망 모델은 합성곱 신경망 (Convolutional Neural Network : CNN) 기 반의 머신 러닝 기술로 구현될 수 있으나, 머신 러닝 기술이 이에 한정되는 것은 아니며 그 이외의 다양한 머신 러닝 기술이 적용될 수 있다. 제1 인코더는 인물 배경 영상을 입력으로 하여 영상 특징 벡터를 추출하도록 학습될 수 있다. 이하, \"벡터\"는 \"텐서\"를 포함 하는 의미로 사용될 수 있다. 여기서, 제1 인코더로 입력되는 인물 배경 영상은 인물이 발화 하는(말을 하는) 영상이다. 인물 배경 영상 은 인물의 얼굴과 상반신이 포함된 영상 일 수 있다. 즉, 인물 배경 영상은 해당 인물이 발화 할 때 나타나는 얼굴, 목, 및 어깨 등의 움직임이 보여지도록 얼굴뿐만 아니라 상반신이 포함된 영상일 수 있으나, 이에 한정되 는 것은 아니며 인물의 얼굴을 포함하는 영상일 수도 있다. 제1 인코더로 입력되는 인물 배경 영상에서 발화와 관련된 부분은 마스킹(Masking) 처리될 수 있다. 즉, 인물 배경 영상에서 발화와 관련된 부 분(예를 들어, 입 및 입 주위 부분 등)은 마스크(M)로 가려질 수 있다. 또한, 마스킹 처리 시 인물 배경 영상에서 인물의 발화에 따른 얼굴 움직임, 목 움직임, 및 어깨 움직임 등과 관련된 부분은 마스킹 처리되지 않도록 할 수 있다. 그러면, 제1 인코더에서는 인물 배경 영상에서 발화와 관련된 부분을 제외한 부분의 영상 특징 벡터를 추출하게 된다. 예시적인 실시예에서, 제1 인코더는 하나 이상의 합성곱 층(Convolutional Layer) 및 하나 이상의 풀링 층 (Pooling Layer)를 포함할 수 있다. 합성곱 층은 입력되는 인물 배경 영상에서 기 설정된 크기(예를 들어, 3Х3 픽셀 크기)의 필터를 일정 간격으로 이동시키면서 해당 필터에 대응되는 픽셀들의 특징 값을 추출할 수 있다. 풀링 층은 합성곱 층의 출력을 입력으로 받아 다운 샘플링(Down Sampling)을 수행할 수 있다. 제2 인코더는 발화 일치 오디오 신호를 입력으로 할 수 있다. 제2 인코더는 발화 일치 오디오 신호를 입력으로 하여 음성 특징 벡터를 추출하도록 학습될 수 있다. 여기서, 발화 일치 오디오 신호는 제1 인코더로 입력되는 인물 배경 영상(즉, 인물이 발화하는 영상) 중 오디오 부분에 해당한다. 다시 말하면, 인물이 발화하는 동영상에서 비디오 부분은 제1 인코더로입력되고, 오디오 부분은 제2 인코더로 입력될 수 있다. 제2 인코더는 하나 이상의 합성곱 층 (Convolutional Layer) 및 하나 이상의 풀링 층 (Pooling Layer)를 포함할 수 있으나, 제2 인코더의 신경 망 구조가 이에 한정 되는 것은 아니다. 제1 인코더로 입력되는 인물 배경 영상과 제2 인코더로 입력되는 발화 일치 오디오 신호의 시간은 서 로 동기화 될 수 있다. 즉, 인물이 발화하는 동영상에서 동일한 시간 대의 구간 중 비디오는 제1 인코더로 입력되고, 오디오는 제2 인코더로 입력될 수 있다. 예를 들어, 인물 배경 영상이 특정 시점으로부터 t 시 간의 영상인 경우, 발화 일치 오디오 신호는 동일한 시점으로부터 t 시간의 음성일 수 있다. 이때, 인물 배경 영상 및 발화 일치 오디오 신호는 기 설정된 단위 시간(예를 들어, 하나의 프레임 또는 복수 개의 연속된 프레 임 등)마다 제1 인코더 및 제2 인코더로 입력될 수 있다. 조합부는 제1 인코더에서 출력되는 영상 특징 벡터 및 제2 인코더에서 출력되는 음성 특징 벡터 를 조합하여 조합 벡터를 생성할 수 있다. 예시적인 실시예에서, 조합부는 영상 특징 벡터와 음성 특징 벡 터를 연결(Concatenate)하여 조합 벡터를 생성할 수 있으나, 이에 한정되는 것은 아니다. 디코더는 조합부에서 출력되는 조합 벡터를 입력으로 하여 발화 일치 합성 영상을 생성할 수 있다. 구체적으로, 디코더는 제2 인코더에서 출력되는 음성 특징 벡터(즉, 인물이 발화하는 동영상에서 오 디오 부분의 특징)를 기반으로 제1 인코더에서 출력되는 영상 특징 벡터(즉, 인물이 발화하는 동영상에서 비디오 부분으로, 발화 관련된 부분이 마스크로 가려진 부분의 특징)의 마스크(M)로 가려진 부분(즉, 발화와 관 련된 부분)을 복원하도록 학습될 수 있다. 즉, 디코더는 인물 배경 영상에서 발화와 관련된 부분이 마스킹 된 경우, 발화 일치 오디오 신호를 이용하 여 마스킹 된 영역을 복원하도록 학습되는 모델일 수 있다. 디코더는 생성된 발화 일치 합성 영상과 원래 의 발화 영상(즉, 정답 값)을 비교하여 생성된 발화 일치 합성 영상이 원래의 발화 영상에 가까워지도록(즉, 원 래 발화 영상과의 차이가 최소화되도록) 학습 파라미터(예를 들어, 손실 함수, 소프트맥스 함수 등)를 조절할 수 있다. 한편, 제1 인공 신경망 모델이 인물 배경 영상 및 발화 일치 오디오 신호를 입력으로 하여 발화 일치 합성 영상을 생성하는 것에 대한 목적 함수(Lreconstruction)는 다음의 수학식 1을 통해 나타낼 수 있다. (수학식 1)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": ": 원래의 발화 영상 : 발화 일치 합성 영상 : A와 B의 차이를 구하는 함수로서, 예를 들어, A와 B의 유클리디안 거리(L2 distance) 또는 맨하 튼 거리(L1 distance)를 구하는 함수 등이 포함될 수 있음 도 3은 본 발명의 일 실시예에 따른 립싱크 영상 생성 장치에서 입력되는 영상과 음성이 불일치 하는 경우 학습 하는 상태를 나타낸 도면이다. 도 3을 참조하면, 제1 인공 신경망 모델은 인물 배경 영상 및 인물 배경 영상과 일치하지 않는 발화 오디 오 신호(즉, 발화 불일치 오디오 신호)를 입력으로 하여 발화 불일치 합성 영상을 생성할 수 있다. 구체적으로, 제1 인코더는 인물 배경 영상을 입력으로 하여 영상 특징 벡터를 추출할 수 있다. 제2 인코더 는 발화 불일치 오디오 신호를 입력으로 하여 음성 특징 벡터를 추출할 수 있다. 조합부는 영상 특징 벡터와 음성 특징 벡터를 조합하여 조합 벡터를 생성할 수 있다. 디코더는 조합 벡터를 입력으로 하여 발 화 불일치 합성 영상을 생성할 수 있다. 발화 불일치 합성 영상은 제2 인공 신경망 모델로 입력될 수 있다. 제2 인공 신경망 모델은 영상과 음성이 일치하는 입력 쌍 또는 영상과 음성이 불일치 하는 입력 쌍을 입력 받고, 이를 참(True) 또는 거짓(False)으로 분류하여 분류 값을 출력할 수 있다. 즉, 제2 인공 신경망 모델은 영상과 음성이 일치하는 입력 쌍이 입력되면 이를 참(True)으로 분류하는 분류 값을 출력하고, 영상과 음성이 불일치 하는 입력 쌍이 입력되면 이를 거짓(False)으로 분류하는 분류 값을 출력하도록 학습될 수 있다. 예를 들어, 제2 인공 신경망 모델은 제1 인공 신경망 모델로 입력되는 인물 배경 영상 및 발화 일치 오디오 신호를 영상과 음성이 일치하는 입력 쌍으로 사용하여 학습할 수 있으나, 이에 한정되는 것은 아니며 제 1 인공 신경망 모델이 생성한 발화 일치 합성 영상 및 발화 일치 오디오 신호를 영상과 음성이 일치하는 입력 쌍으로 사용하여 학습할 수도 있다. 예시적인 실시예에서, 제2 인공 신경망 모델은 제3 인코더 및 분류기를 포함할 수 있다. 제3 인 코더는 입력되는 영상 및 음성 쌍으로부터 영상 및 음성 특징 벡터를 추출할 수 있다. 분류기는 제3 인코더에서 출력되는 영상 및 음성 특징 벡터에 기반하여 참 또는 거짓으로 분류하는 분류 값을 출력할 수 있다. 그러나, 이에 한정되는 것은 아니며 제3 인코더는 영상 및 음성을 각각 입력 받고, 입력된 영상으로부터 영상 특징 벡터를 추출하고 입력된 음성으로부터 음성 특징 벡터를 추출하며, 영상 특징 벡터와 음성 특징 벡터 를 조합한 조합 벡터를 분류기로 출력할 수 있다. 그리고, 분류기는 조합 벡터에 기반하여 참 또는 거짓으로 분류하는 분류 값을 출력할 수도 있다. 또한, 제2 인공 신경망 모델은 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상 및 발화 불일 치 오디오 신호(발화 불일치 합성 영상을 생성할 때 입력으로 사용된 발화 불일치 오디오 신호)가 입력되는 경 우, 발화 불일치 합성 영상과 발화 불일치 오디오 신호 간의 일치 정도를 판별하고 그 일치 정도에 대한 적대적 생성 에러를 제1 인공 신경망 모델로 전파할 수 있다. 여기서, 제1 인공 신경망 모델 및 제2 인공 신경망 모델은 적대적 생성 신경망(Generative Adversarial Network)을 이룰 수 있다. 제1 인공 신경망 모델은 적대적 생성 신경망 중 생성자 (Generator)에 해당하고, 제2 인공 신경망 모델은 적대적 생성 신경망 중 판별자(Discriminator)에 해당할 수 있다. 즉, 제1 인공 신경망 모델은 발화 일치 합성 영상을 생성하는 별도의 신경망 모델이면서, 발화 불일치 합성 영상을 생성하는 적대적 생성 신경망의 일부 신경망(즉, 생성자)을 구성할 수 있다. 이때, 제2 인공 신경망 모델의 목적 함수(Ldiscriminator)는 다음의 수학식 2를 통해 나타낼 수 있다. (수학식 2)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "D : 제2 인공 신경망 모델의 신경망 (Ii, Ai) : 영상과 음성이 일치하는 입력 쌍(i번째 영상과 i번째 음성) (Ii, Aj) : 영상과 음성이 불일치 하는 입력 쌍(i번째 영상과 j번째 음성) 그리고, 발화 불일치 합성 영상을 생성하는 제1 인공 신경망 모델의 적대적 목적 함수(Ladversarial)는 다음의 수학식 3을 통해 나타낼 수 있다. (수학식 3)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "G : 제1 인공 신경망 모델을 구성하는 신경망 : 발화와 관련된 부분이 마스킹 처리된 인물 배경 영상(Mi : 마스크) : 제1 인공 신경망 모델이 생성한 발화 불일치 합성 영상 Aj : 인물 배경 영상과 대응되지 않는 발화 불일치 오디오 신호 적대적 목적 함수(Ladversarial)는 제2 인공 신경망 모델에서 제1 인공 신경망 모델이 생성한 발화 불일 치 합성 영상 및 발화 불일치 오디오 신호의 입력 쌍을 참(True)으로 분류하도록 제1 인공 신경망 모델을유도하는 목적 함수 일 수 있다. 그리고, 발화 일치 합성 영상 및 발화 불일치 합성 영상을 생성하는 제1 인공 신경망 모델의 최종 목적 함 수(LT)는 다음의 수학식 4를 통해 나타낼 수 있다. (수학식 4)"}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "λ : 가중치 또한, 제1 인공 신경망 모델의 최적화된 파라미터( )는 다음의 수학식 5를 통해 나타낼 수 있다. (수학식 5) 여기서, argminθg는 LT를 최소화 하는 θg를 찾는 함수를 나타낸다. 그리고, θg는 신경 망 G의 파라미터를 나타낸다. 도 4는 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하 기 위한 블록도이다. 도시된 실시예에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가 질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 립싱크 영상 생성 장치일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다."}
{"patent_id": "10-2021-0003375", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상에서 본 발명의 대표적인 실시예들을 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후술하는 특허 청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2021-0003375", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 립싱크 영상 생성 장치의 구성을 나타낸 도면 도 2는 본 발명의 일 실시예에서 제1 인공 신경망 모델이 발화 일치 합성 영상을 생성하는 상태를 개략적으로 나타낸 도면도 3은 본 발명의 일 실시예에 따른 립싱크 영상 생성 장치에서 입력되는 영상과 음성이 불일치 하는 경우 학습 하는 상태를 나타낸 도면 도 4는 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위 한 블록도"}
