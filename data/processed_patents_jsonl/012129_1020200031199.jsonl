{"patent_id": "10-2020-0031199", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0115428", "출원번호": "10-2020-0031199", "발명의 명칭": "재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 장치 및 이를 위한 방법", "출원인": "줌인터넷 주식회사", "발명자": "이재훈"}}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 장치에 있어서, 무인항공기가 목적 위치로 비행하도록 양력을 발생시키는 구동부; 촬영을 통해 복수의 영상을 생성하는 촬영부; 상기 복수의 영상에서 객체를 검출하는 검출부; 상기 복수의 영상에서 검출부가 검출한 객체를 추적하는 추적부; 상기 복수의 영상을 기초로 재난 상황 여부를 판단하고, 상기 판단 결과, 재난 상황이면, 상기 복수의 영상을기초로 재난 상황 복잡도를 산출하는 분석부; 및 상기 산출된 재난 상황 복잡도에 따라 상기 구동부를 통해 무인항공기의 비행 방향을 제어하고 상기 촬영부의촬영 주기를 제어하는 제어부;를 포함하는 것을 특징으로 하는,무인항공기를 제어하기 위한 장치."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 분석부는 상기 복수의 영상에서 검출된 객체 중 요구조자 존재 여부, 요구조자의 수, 요구조자의 수의 증감 및 요구조자의 밀도에 따라 재난 상황 복잡도를 산출하는 것을 특징으로 하는 무인항공기를 제어하기 위한 장치."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제어부는 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 이상이면, 상기 촬영부의 촬영 주기를 기 설정된 기준치 이상으로 증가시켜 촬영하도록 제어하고, 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 미만이면, 상기 촬영부의 촬영 주기를 기 설정된 기준치 미만으로 감소시켜 촬영하도록 제어하는 것을 특징으로 하는 무인항공기를 제어하기 위한 장치."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제어부는 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 이상이면, 상기 요구조자의 위치가 상기 촬영부가 촬영하는영상의 중심에 위치하도록 상기 구동부를 제어하여 무인항공기를 이동시키는 것을 특징으로 하는 무인항공기를 제어하기 위한 장치. 공개특허 10-2021-0115428-3-청구항 5 제1항에 있어서, 상기 장치는 관제장치와 통신을 위한 통신부; 및 무인항공기의 현재의 위치 정보를 도출하는 항법부;를 더 포함하며, 상기 제어부는 상기 촬영부가 촬영한 영상으로부터 무인항공기를 기준으로 하는 상기 요구조자의 상대적 위치를 검출하고, 상기 항법부를 통해 무인항공기의 지리적 위치를 도출하고, 상기 무인항공기의 지리적 위치를 기초로 상기 요구조자의 상대적 위치를 지리적 위치로 변환한 후, 상기 변환된 지리적 위치를 상기 통신부를 통해 상기 관제장치로 전송하는 것을 특징으로 하는 무인항공기를 제어하기 위한 장치."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 제어부는 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 미만이면, 상기 목적 위치를 중심으로 무인항공기가 선회하도록 상기 구동부를 제어하는 것을 특징으로 하는 무인항공기를 제어하기 위한 장치."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 분석부는 영상이 입력되면, 입력되는 영상이 재난 상황에 속하는지 여부에 대한 확률을 산출하여 출력하도록 학습한 인공신경망 모델인 상황판단모델을 포함하며, 상기 상황판단모델이 상기 촬영부가 촬영한 영상에 대해 산출한 상기 확률에 따라 상기 재난 상황 여부를 판단하는 것을 특징으로 하는 무인항공기를 제어하기 위한 장치."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 검출부는 영상에 포함된 객체가 차지하는 영역을 나타내는 영역박스의 좌표 및 영역박스 내의 객체가 적어도 하나의 기설정된 클래스에 속할 확률을 산출하여 출력하도록 학습된 인공신경망 모델인 객체분류모델을 포함하며, 상기 객체분류모델이 연산을 통해 상기 촬영부가 촬영한 영상에 포함된 객체가 차지하는 영역을 나타내는 영역박스의 좌표 및 영역박스 내의 객체가 적어도 하나의 기 설정된 클래스에 속할 확률을 산출하여 출력하면, 상기 산출된 클래스에 속할 확률이 기 설정된 임계치 이상인 경우, 해당 영역박스 내에 해당 클래스의 객체가존재하는 것으로 인식하는 것을 특징으로 하는 무인항공기를 제어하기 위한 장치."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 방법에 있어서, 공개특허 10-2021-0115428-4-구동부가 무인항공기가 관제장치로부터 수신된 목적 위치로 비행하도록 양력을 발생시키는 단계; 촬영부가 상기 목적 위치에서 촬영을 통해 복수의 영상을 생성하는 단계; 검출부가 상기 복수의 영상에서 객체를 검출하는 단계; 추적부가 상기 복수의 영상에서 검출한 객체를 추적하는 단계; 분석부가 상기 복수의 영상을 기초로 재난 상황 복잡도를 산출하는 단계; 및 제어부가 상기 산출된 재난 상황 복잡도에 따라 상기 무인항공기의 비행 방향을 제어하고 상기 촬영부의 촬영주기를 제어하는 단계; 를 포함하는 것을 특징으로 하는 무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 재난 상황 복잡도를 산출하는 단계는 상기 분석부가 상기 복수의 영상에서 검출된 객체 중 요구조자 존재 여부, 요구조자의 수, 요구조자의 수의 증감 및 요구조자의 밀도에 따라 재난 상황 복잡도를 산출하는 것을 특징으로 하는 무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 제어하는 단계는 상기 제어부가 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 이상이면, 상기 촬영부의 촬영 주기를 기설정된 기준치 이상으로 증가시켜 촬영하도록 제어하고, 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 미만이면, 상기 촬영부의 촬영 주기를 기 설정된 기준치미만으로 감소시켜 촬영하도록 제어하는 것을 특징으로 하는 무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 제어하는 단계는 상기 제어부가 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 이상이면, 상기 요구조자의 위치가 상기 촬영부가 촬영하는 영상의 중심에 위치하도록 상기 구동부를 제어하여 상기 무인항공기를 이동시키는 것을 특징으로하는 무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 제어하는 단계는 상기 제어부가 상기 촬영부가 촬영한 영상으로부터 무인항공기를 기준으로 하는 상기 요구조자의 상대적 위치를검출하고, 상기 무인항공기의 항법부를 통해 무인항공기의 지리적 위치를 도출하고, 상기 무인항공기의 지리적위치를 기초로 상기 요구조자의 상대적 위치를 지리적 위치로 변환한 후, 상기 변환된 지리적 위치를 상기 무인항공기의 통신부를 통해 상기 관제장치로 전송하는 것을 특징으로 하는 공개특허 10-2021-0115428-5-무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 제어하는 단계는 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 미만이면, 상기 제어부가 상기 구동부를 통해 상기 무인항공기가 상기 목적 위치를 중심으로 선회하도록 하는 것을 특징으로 하는 무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 상기 재난 상황 복잡도를 산출하는 단계는 상기 분석부의 상황판단모델이 상기 촬영부가 촬영한 영상이 재난 상황에 속하는지 여부에 대한 확률을 산출하는 단계; 및 상기 분석부가 상기 산출된 확률에 따라 상기 재난 상황 여부를 판단하는 단계;를 포함하는 것을 특징으로 하는 무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서, 상기 객체를 검출하는 단계는 상기 검출부의 객체분류모델이 연산을 통해 상기 촬영부가 촬영한 영상에 포함된 객체가 차지하는 영역을 나타내는 영역박스의 좌표 및 영역박스 내의 객체가 적어도 하나의 기 설정된 클래스에 속할 확률을 산출하여 출력하는 단계; 및 상기 검출부가 상기 산출된 클래스에 속할 확률이 기 설정된 임계치 이상인 경우, 해당 영역박스 내에 해당 클래스의 객체가 존재하는 것으로 인식하는 단계;를 포함하는 것을 특징으로 하는 무인항공기를 제어하기 위한 방법."}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 장치는 무인항공기가 비행하도록 양력을 발생 시키는 구동부와, 촬영을 통해 복수의 영상을 생성하는 촬영부와, 상기 복수의 영상에서 객체를 검출하는 검출부 와, 상기 복수의 영상에서 검출부가 검출한 객체를 추적하는 추적부와, 상기 복수의 영상을 기초로 재난 상황 여 부를 판단하고, 상기 판단 결과, 재난 상황이면, 상기 복수의 영상을 기초로 재난 상황 복잡도를 산출하는 분석 부와, 상기 산출된 재난 상황 복잡도에 따라 상기 구동부를 통해 무인항공기의 비행 방향을 제어하고 상기 촬영 부의 촬영 주기를 제어하는 제어부를 포함한다."}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 무인항공기(UAV: Unmanned Aerial Vehicle) 기술에 관한 것으로, 보다 상세하게는, 재난 상황 복잡도 를 기초로 무인항공기를 제어하기 위한 장치 및 이를 위한 방법에 관한 것이다."}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "지진, 해일, 화재와 같이 사람이 접근하기 어려운 재난 상황에서 드론을 활용한 인명 구조 활동이 주목을 받고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제2020-0002361호 2020년 01월 08일 공개 (명칭: 자율 주행 드론을 이용하여 항"}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "공 영상을 제공하기 위한 시스템 및 그 방법) 발명의 내용"}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 장치 및 이를 위한 방법을 제공함에 있다."}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 바와 같은 목적을 달성하기 위한 본 발명의 바람직한 실시예에 따른 재난 상황 복잡도를 기초로 무인항 공기를 제어하기 위한 장치는 무인항공기가 목적 위치로 비행하도록 양력을 발생시키는 구동부와, 촬영을 통해 복수의 영상을 생성하는 촬영부와, 상기 복수의 영상에서 객체를 검출하는 검출부와, 상기 복수의 영상에서 검 출부가 검출한 객체를 추적하는 추적부와, 상기 복수의 영상을 기초로 재난 상황 여부를 판단하고, 상기 판단 결과, 재난 상황이면, 상기 복수의 영상을 기초로 재난 상황 복잡도를 산출하는 분석부와, 상기 산출된 재난 상 황 복잡도에 따라 상기 구동부를 통해 무인항공기의 비행 방향을 제어하고 상기 촬영부의 촬영 주기를 제어하는 제어부를 포함한다. 상기 분석부는 상기 복수의 영상에서 검출된 객체 중 요구조자 존재 여부, 요구조자의 수, 요구조자의 수의 증 감 및 요구조자의 밀도에 따라 재난 상황 복잡도를 산출하는 것을 특징으로 한다. 상기 제어부는 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 이상이면, 상기 촬영부의 촬영 주기를 기 설정된 기준치 이상으로 증가시켜 촬영하도록 제어하고, 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 미만이면, 상기 촬영부의 촬영 주기를 기 설정된 기준치 미만으로 감소시켜 촬영하도록 제어하는 것을 특징으로 한다. 상기 제어부는 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 이상이면, 상기 요구조자의 위치가 상기 촬영 부가 촬영하는 영상의 중심에 위치하도록 상기 구동부를 제어하여 무인항공기를 이동시키는 것을 특징으로 한다. 상기 장치는 관제장치와 통신을 위한 통신부와, 무인항공기의 현재의 위치 정보를 도출하는 항법부를 더 포함한 다. 이에 따라, 상기 제어부는 상기 촬영부가 촬영한 영상으로부터 무인항공기를 기준으로 하는 상기 요구조자 의 상대적 위치를 검출하고, 상기 항법부를 통해 무인항공기의 지리적 위치를 도출하고, 상기 무인항공기의 지 리적 위치를 기초로 상기 요구조자의 상대적 위치를 지리적 위치로 변환한 후, 상기 변환된 지리적 위치를 상기 통신부를 통해 상기 관제장치로 전송할 수 있다. 상기 제어부는 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 미만이면, 상기 목적 위치를 중심으로 무인항 공기가 선회하도록 상기 구동부를 제어하는 것을 특징으로 한다. 상기 분석부는 영상이 입력되면, 입력되는 영상이 재난 상황에 속하는지 여부에 대한 확률을 산출하여 출력하도 록 학습한 인공신경망 모델인 상황판단모델을 포함한다. 이에 따라, 상기 분석부는 상기 상황판단모델이 상기 촬영부가 촬영한 영상에 대해 산출한 상기 확률에 따라 상기 재난 상황 여부를 판단할 수 있다. 즉, 상기 분석 부는 상기 확률이 기 설정된 수치 이상이면, 재난 상황인 것으로 판단한다. 상기 검출부는 영상에 포함된 객체가 차지하는 영역을 나타내는 영역박스의 좌표 및 영역박스 내의 객체가 적어 도 하나의 기 설정된 클래스에 속할 확률을 산출하여 출력하도록 학습된 인공신경망 모델인 객체분류모델을 포 함한다. 이에 따라, 상기 객체분류모델이 연산을 통해 상기 촬영부가 촬영한 영상에 포함된 객체가 차지하는 영 역을 나타내는 영역박스의 좌표 및 영역박스 내의 객체가 적어도 하나의 기 설정된 클래스에 속할 확률을 산출 하여 출력하면, 상기 산출된 클래스에 속할 확률이 기 설정된 임계치 이상인 경우, 해당 영역박스 내에 해당 클 래스의 객체가 존재하는 것으로 인식할 수 있다. 상술한 바와 같은 목적을 달성하기 위한 본 발명의 바람직한 실시예에 따른 재난 상황 복잡도를 기초로 무인항 공기를 제어하기 위한 방법은 구동부가 무인항공기가 관제장치로부터 수신된 목적 위치로 비행하도록 양력을 발 생시키는 단계와, 촬영부가 상기 목적 위치에서 촬영을 통해 복수의 영상을 생성하는 단계와, 검출부가 상기 복 수의 영상에서 객체를 검출하는 단계와, 추적부가 상기 복수의 영상에서 검출한 객체를 추적하는 단계와, 분석 부가 상기 복수의 영상을 기초로 재난 상황 복잡도를 산출하는 단계와, 제어부가 상기 산출된 재난 상황 복잡도 에 따라 상기 무인항공기의 비행 방향을 제어하고 상기 촬영부의 촬영 주기를 제어하는 단계를 포함한다. 상기 재난 상황 복잡도를 산출하는 단계는 상기 분석부가 상기 복수의 영상에서 검출된 객체 중 요구조자 존재 여부, 요구조자의 수, 요구조자의 수의 증감 및 요구조자의 밀도에 따라 재난 상황 복잡도를 산출하는 것을 특 징으로 한다. 상기 제어하는 단계는 상기 제어부가 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 이상이면, 상기 촬 영부의 촬영 주기를 기 설정된 기준치 이상으로 증가시켜 촬영하도록 제어하는 것이 바람직하다. 또한, 상기 제 어하는 단계는 상기 산출된 재난 상황 복잡도가 기 설정된 임계 수준 미만이면, 상기 촬영부의 촬영 주기를 기 설정된 기준치 미만으로 감소시켜 촬영하도록 제어하는 것이 바람직하다. 상기 제어하는 단계는 상기 제어부가 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 이상이면, 상기 요구조 자의 위치가 상기 촬영부가 촬영하는 영상의 중심에 위치하도록 상기 구동부를 제어하여 상기 무인항공기를 이 동시키는 것을 특징으로 한다. 상기 제어하는 단계는 상기 제어부가 상기 촬영부가 촬영한 영상으로부터 무인항공기를 기준으로 하는 상기 요 구조자의 상대적 위치를 검출하고, 상기 무인항공기의 항법부를 통해 무인항공기의 지리적 위치를 도출하고, 상 기 무인항공기의 지리적 위치를 기초로 상기 요구조자의 상대적 위치를 지리적 위치로 변환한 후, 상기 변환된 지리적 위치를 상기 무인항공기의 통신부를 통해 상기 관제장치로 전송할 수 있다. 상기 제어하는 단계는 상기 산출된 재난 상황 복잡도가 소정의 임계 수준 미만이면, 상기 제어부가 상기 구동부 를 통해 상기 무인항공기가 상기 목적 위치를 중심으로 선회하도록 하는 것을 특징으로 한다. 상기 재난 상황 복잡도를 산출하는 단계는 상기 분석부의 상황판단모델이 상기 촬영부가 촬영한 영상이 재난 상 황에 속하는지 여부에 대한 확률을 산출하는 단계와, 상기 분석부가 상기 산출된 확률에 따라 상기 재난 상황 여부를 판단하는 단계를 포함한다. 상기 분석부가 상기 산출된 확률에 따라 상기 재난 상황 여부를 판단하는 단 계는 상기 분석부가 상기 산출된 확률이 기 설정된 수치 이상이면 재난 상황인 것으로 판단하는 것이 바람직하 다. 상기 객체를 검출하는 단계는 상기 검출부의 객체분류모델이 연산을 통해 상기 촬영부가 촬영한 영상에 포함된 객체가 차지하는 영역을 나타내는 영역박스의 좌표 및 영역박스 내의 객체가 적어도 하나의 기 설정된 클래스에 속할 확률을 산출하여 출력하는 단계와, 상기 검출부가 상기 산출된 클래스에 속할 확률이 기 설정된 임계치 이 상인 경우, 해당 영역박스 내에 해당 클래스의 객체가 존재하는 것으로 인식하는 단계를 포함한다."}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 무인항공기(UAV: Unmanned Aerial Vehicle)가 촬영한 영상을 인공지능 및 컴퓨터비전 기술을 통해 분석함으로써 상황을 인지하고, 재난 상황 복잡도를 판단한다. 그리고 재난 상황 복잡도에 따라 무인항공 기의 이동 및 영상 촬영을 자체적으로 제어함으로써 인력 자원을 최소화 시키며 효율적인 제어가 가능해진다. 결과적으로 본 발명을 통해 무인항공기의 사용 전력을 최소화하면서 동시에 다수의 무인항공기을 활용할 수 있 어 인명 구조 활동을 최대화 할 수 있다."}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 상세한 설명에 앞서, 이하에서 설명되는 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거 나 사전적인 의미로 한정해서 해석되어서는 아니 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명 하기 위해 용어의 개념으로 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의 미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 발명의 가장 바람직한 실시예에 불과할 뿐, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예들을 상세히 설명한다. 이때, 첨부된 도면에서 동일한 구성 요소는 가능한 동일한 부호로 나타내고 있음을 유의해야 한다. 또한, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략할 것이다. 마찬가지의 이유로 첨부 도면에 있어서 일부 구성요소 는 과장되거나 생략되거나 또는 개략적으로 도시되었으며, 각 구성요소의 크기는 실제 크기를 전적으로 반영하 는 것이 아니다. 먼저, 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 시스템에 대해서 설명 하기로 한다. 도 1은 본 발명의 실시예에 따른 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무인항공기 를 제어하기 위한 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 본 발명의 실 시예에 따른 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 시스템(이하, '제어시스템'으로 축약함)은 기본적으로, 관제장치 및 무인항공기를 포함한다. 관제장치는 무선 통신을 통해 무인항공기를 제어하며, 무인항공기로부터 수신되는 요구조자의 위치 등의 정보를 구조자에게 제공한다. 무인항공기는 재난 현장 주변을 비행하며 재난 현장을 촬영한 후, 촬영된 영상으로부터 구조가 요구되는 요구조자의 위치를 탐지하여 관제장치로 전송함으로써, 구난, 구인에 필요한 정보를 제공하는 역할을 수행 한다. 그러면, 보다 상세히, 본 발명의 실시예에 따른 관제장치에 대해서 설명하기로 한다. 도 2는 본 발명의 실 시예에 따른 관제장치의 구성을 설명하기 위한 블록도이다. 도 2를 참조하면, 본 발명의 실시예에 따른 관제장 치는 통신모듈, 입력모듈, 표시모듈, 저장모듈 및 제어모듈을 포함한다. 통신모듈은 무인항공기와 통신을 위한 것이다. 이러한 통신모듈은 송신되는 신호의 주파수를 상 승 변환 및 증폭하는 RF(Radio Frequency) 송신기(Tx) 및 수신되는 신호를 저 잡음 증폭하고 주파수를 하강 변 환하는 RF 수신기(Rx)를 포함할 수 있다. 그리고 통신모듈은 송신되는 신호를 변조하고, 수신되는 신호를 복조하는 모뎀(Modem)을 포함할 수 있다. 통신모듈은 제어모듈로부터 전달 받은 무인항공기를 제어하기 위한 다양한 제어 명령을 수신하여 무인항공기로 전송할 수 있다. 특히, 재난 상황이 발생한 경 우, 무인항공기가 재난 현장으로 이동하도록 재난 현장의 위치를 나타내는 지리적 위치, 즉, GPS 좌표를 무인항공기로 전송할 수 있다. 또한, 통신모듈은 무인항공기로부터 다양한 데이터, 영상 등을 수신하여 제어모듈로 전달할 수 있다. 입력모듈은 관제장치의 각 종 기능, 동작 등을 제어하기 위한 사용자의 키 조작을 입력받고 입력 신 호를 생성하여 제어모듈에 전달한다. 입력모듈은 전원을 켜거나, 끄기 위한 전원 키를 비롯하여, 관 제장치에 특정 입력을 위한 문자 키, 숫자 키, 방향키 등의 다양한 키를 포함할 수 있다. 입력모듈의 기능은 표시모듈이 터치스크린으로 구현된 경우, 표시모듈에서 이루어질 수 있으며, 표시모듈만 으로 모든 기능을 수행할 수 있는 경우, 입력모듈은 생략될 수도 있다. 표시모듈은 제어모듈로부터 화면 표시를 위한 데이터를 수신하여 수신된 데이터를 화면으로 표시할 수 있다. 예컨대, 본 발명의 실시예에 따른 재난 현장의 영상, 요구조자의 영상, 요구조자의 위치 등을 수신하 면 제어모듈은 재난 현장의 영상, 요구조자의 영상, 요구조자의 위치를 표시하도록 하는 데이터를 제공하 고, 표시모듈은 이를 화면으로 표시한다. 또한, 표시모듈은 관제장치의 메뉴, 데이터, 기능 설 정 정보 및 기타 다양한 정보를 사용자에게 시각적으로 제공할 수 있다. 표시모듈이 터치스크린으로 형성 되는 경우, 입력모듈의 기능의 일부 또는 전부를 대신 수행할 수 있다. 표시모듈은 액정표시장치 (LCD, Liquid Crystal Display), 유기 발광 다이오드(OLED, Organic Light Emitting Diodes), 능동형 유기 발 광 다이오드(AMOLED, Active Matrix Organic Light Emitting Diodes) 등으로 형성될 수 있다. 저장모듈은 관제장치의 동작에 필요한 각 종 데이터, 애플리케이션, 관제장치의 동작에 따라 발 생된 각 종 데이터를 저장한다. 이러한 저장모듈은 스토리지, 메모리 등이 될 수 있다. 특히, 저장모듈은 선택적으로, 관제장치의 부팅(booting) 및 운영(operation)을 위한 운영체제(OS, Operating System), 본 발명의 실시예에 따른 애플리케이션을 저장할 수 있다. 저장모듈에 저장되는 각 종 데이터는 사용자의 조작에 따라, 삭제, 변경, 추가될 수 있다. 제어모듈은 관제장치의 전반적인 동작 및 관제장치의 내부 블록들 간 신호 흐름을 제어하고, 데 이터를 처리하는 데이터 처리 기능을 수행할 수 있다. 이러한 제어모듈은 중앙 처리 장치(Central Processing Unit : CPU), 애플리케이션 프로세서(Application Processor), GPU(Graphic Processing Unit) 등이 될 수 있다. 제어모듈은 재난 상황이 발생한 경우, 무인항공기가 재난 현장으로 이동하도록 재난 현 장의 위치를 나타내는 지리적 위치, 즉, GPS 좌표를 포함하는 출동 명령을 통신모듈을 통해 무인항공기 로 전송할 수 있다. 또한, 제어모듈은 통신모듈을 통해 무인항공기로부터 재난 현장의 영 상, 요구조자의 위치 정보 등을 수신하면, 수신된 영상 및 요구조자의 위치 정보 등을 구조자가 식별할 수 있도 록 표시모듈을 통해 표시하도록 제어할 수 있다. 그 밖에 제어모듈의 동작은 아래에서 보다 상세하게 설명될 것이다. 다음으로, 본 발명의 실시예에 따른 무인항공기에 대해서 설명하기로 한다. 도 3은 본 발명의 실시예에 따 른 무인항공기의 구성을 설명하기 위한 블록도이다. 도 4 및 도 5는 본 발명의 실시예에 따른 무인항공기의 구 성을 설명하기 위한 화면 예이다. 도 3을 참조하면, 본 발명의 실시예에 따른 무인항공기는 촬영부, 검출부, 추적부, 분석부 , 항법부, 구동부, 통신부, 저장부 및 제어부를 포함한다. 촬영부는 재난 현장에 대한 영상을 촬영하기 위한 것이다. 촬영부는 촬영을 통해 복수의 영상을 생성 한다. 이러한 촬영부는 렌즈, 이미지센서 및 컨버터를 포함한다. 그 밖에, 소정의 필터 등이 촬영부 의 구성으로 더 포함될 수 있으며, 기구적으로, 렌즈, 이미지 센서 및 컨버터는 액추에이터(actuator)를 포함하 는 하우징 내에 장착되고, 이러한 액추에이터를 구동시키는 드라이버 등이 촬영부에 포함될 수 있다. 렌즈 는 촬영부에 입사되는 가시광선이 이미지 센서 상에 초점이 맺히도록 한다. 이미지 센서는 반도체 소자의 제조 기술을 이용하여 집적된 광전변환소자이다. 이미지 센서는 예컨대, CCD(charge-coupled device) 이미지 센 서 혹은 CMOS(complementary metal-oxide semiconductor) 이미지 센서가 될 수 있다. 이러한 이미지 센서는 가 시광선을 감지하여 영상을 구성하는 아날로그 신호인 아날로그 영상 신호를 출력한다. 그러면, 컨버터는 아날로 그 영상 신호를 영상을 구성하는 디지털 신호인 디지털 영상 신호로 변환하여 제어부로 전달한다. 특히, 본 발명의 실시예에 따른 촬영부는 3D 센서(깊이 센서)를 포함할 수 있다. 3D 센서는 비접촉 방식으로 영 상의 각 픽셀에 대한 3차원 좌표를 획득하기 위한 센서이다. 촬영부는 객체를 촬영함과 동시에 3D 센서를 통해 촬영된 영상의 각 픽셀에 대한 3차원 좌표의 좌표값(예컨대, x, y, z값)을 검출할 수 있다. 이때, 3차원 좌표의 좌표값은 촬영부의 이미지 센서의 초점을 0점으로 하였을 때의 좌표값이다. 3D 센서는 레이저, 적 외선, 가시광 등을 이용하는 다양한 방식의 센서를 이용할 수 있다. 이러한 3D 센서는 TOP(Time of Flight), 위 상변위(Phase-shift) 및 온라인 웨이브폼 분석(Online Waveform Analysis) 중 어느 하나를 이용하는 레이저 방 식 3차원 스캐너, 광 삼각법을 이용하는 레이저 방식 3차원 스캐너, 백색광 혹은 변조광을 이용하는 광학방식 3 차원 스캐너, 핸드헬드 리얼 타임(Handheld Real Time) 방식의 사진촬영(PHOTO), 광학방식 3차원 스캐너, 패턴 프로젝션(Pattern Projection) 혹은 라인 스캐닝(Line Scanning)을 이용하는 광학방식, 레이저 방식 전신 스캐 너, 사진 측량(Photogrammetry)을 이용하는 사진방식 스캐너, 키네틱 퓨전(Kinect Fusion)을 이용하는 실시간 (Real Time) 스캐너 등을 예시할 수 있다. 이에 따라, 촬영부는 촬영된 영상에서 3차원의 좌표를 추출할 수 있으며, 이에 따라, 촬영부의 현재 위치, 즉, 무인항공기의 현재의 지리적 위치(GPS 좌표)로부터 촬영된 영상까지의 실제 거리를 측정할 수 있다. 무인항공기의 현재의 지리적 위치(GPS 좌표)는 항법부 에 의해 획득할 수 있다. 촬영부는 소정 주기로 영상을 촬영한다. 특히, 촬영부는 제어부의 제어에 따라 영상 촬영의 주 기를 조절할 수 있다. 이때, 촬영부는 재난 상황 복잡도가 높을수록 상대적으로 촬영 주기는 짧으며, 재난 상황 복잡도가 낮을수록 상대적으로 촬영 주기가 길게 조절한다. 검출부는 촬영부가 촬영한 복수의 영상으로부터 적어도 하나의 기 설정된 클래스의 객체를 검출한다. 특히, 검출부는 촬영부가 촬영한 영상에서 사람 클래스(person class)의 객체로 요구조자를 검출할 수 있다. 또한, 검출부는 촬영부가 촬영한 영상에서 요구조자와 구조에 도움이 될 만한 객체, 예컨대, 소화기, 소화전, 자동차, 자전거, 오토바이 등을 검출할 수 있다. 예컨대, 검출부는 도 4에 도시된 바와 같이, 영상에서 객체(obj)가 차지하는 영역을 나타내는 영역박스(B: Bounding Box)의 좌표(x, y, w, h) 및 해당 객체(obj)가 적어도 하나의 기 설정된 클래스(예컨대, Person class, Car class, Tree class 등)에 속할 확률(예컨대, Person = 0.88, Car = 0.01, Person = 0.11)을 출력하 도록 학습된 인공신경망 모델인 객체분류모델을 포함한다. 이러한 객체분류모델은 YOLO, YOLOv2, YOLO9000, YOLOv3 등을 예시할 수 있다. 영역박스(B)의 좌표 중 x, y, 는 영상에서 영역박스(B)의 중심 좌표이며, w는 폭, h는 높이를 나타낸다. 검출부는 객체분류모델에 촬영부가 촬영한 영상을 입력하여 객체분류모델이 촬영부가 촬영한 영 상에 대한 연산을 통해 영역박스(B)의 좌표(x, y, w, h) 및 영역박스(B) 내의 객체가 적어도 하나의 기 설정된 클래스에 속할 확률을 출력하면, 출력된 적어도 하나의 기 설정된 클래스에 속할 확률이 기 설정된 임계치(예컨 대, 0.80 = 80%) 이상이면, 영역박스(B) 내에 해당 클래스의 객체가 존재하는 것으로 인식하고, 이를 검출할 수 있다. 또한, 검출부는 제어부의 제어에 따라 영역박스(B)의 중심 좌표(x, y)를 지리적 좌표, 즉, GPS 좌표 로 변환할 수 있다. 즉, 검출부는 항법부를 통해 도출된 무인항공기의 현재의 지리적 위치(GPS 위치) 및 촬영부의 3D 센서(깊이 센서)를 통해 도출되는 무인항공기로부터 촬영된 영역박스(B)의 객 체까지의 거리를 통해 중심 좌표(x, y)를 지리적 좌표(GPS 좌표)로 변환할 수 있다. 추적부는 촬영부가 촬영한 복수의 영상에서 검출부가 검출한 복수의 객체를 추적하기 위한 것이다. 추적부는 촬영부가 촬영한 복수의 영상이 시간 순서로 존재할 때, 이전 영상에서 검출부가 검출한 객체와 현재 영상에서 검출부가 검출한 객체 간의 동일한 객체인지 여부를 판단하고, 일련번호를 부여한다. 이에 따라, 추적부는 개별 객체를 모두 구분하여 객체를 추적할 수 있다. 예컨대, 추적부 는 도 5의 (a)의 영상과 같이, 검출된 사람 객체에 일련번호 ①을 부여하고 차량 두 대에 일련번호 ② 및 ③을 부여한다. 또한, 도 5의 (a)에서 포커스가 변경된 도 5의 (b)와 같은 영상에서와 같이, 동일한 객체인 사람 및 차량 객체에 일련번호 ① 및 ②가 유지되고, 새로 검출된 차량 객체에 일련번호 ④를 할당함으로써 중복을 피할 수 있다. 분석부는 촬영부가 촬영한 복수의 영상으로부터 재난 상황 여부를 확인하기 위한 것이다. 분석부 는 영상이 입력되면, 입력되는 영상이 재난 상황에 속하는지 여부에 대한 확률을 산출하여 출력하도록 학 습한 인공신경망 모델인 상황판단모델을 포함한다. 이러한 상황판단모델은 대표적으로, CNN(convolution neural network)을 통해 생성할 수 있으며, 예컨대 기존에 알려진 딥러닝 기반의 모델로 재난 장면(예를 들어, 화재, 지진, 홍수, 산사태 등)을 학습한 이미지 분류를 이용하여 판별이 가능하다. 분석부는 상황판단모델에 촬 영부가 촬영한 영상을 입력한다. 그러면, 상황판단모델은 촬영부가 촬영한 영상에 대해 연산을 통해 재난 상황에 속하는지 여부에 대한 확률을 산출한다. 예컨대, 상황판단모델은 재난 상황일 확률 및 재난 상황이 아닐 확률을 출력할 수 있다. 그러면, 분석부는 상황판단모델의 출력, 즉, 재난 상황에 속하는지 여부에 대한 확률에 따라 재난 상황 여부를 확인할 수 있다. 이때, 분석부는 재난 상황일 확률이 기 설정된 수치 이상인 경우에 재난 상황인 것으로 판단한다. 예컨대, 기 설정된 수치가 75%라고 가정한다. 일례로, 상황판단모 델의 출력이 재난 상황일 확률 70% 그리고 재난 상황이 아닐 확률이 30%이면, 분석부는 재난 상황이 아닌 것으로 판단한다. 다른 예로, 상황판단모델의 출력이 재난 상황일 확률 76% 그리고 재난 상황이 아닐 확률이 24%이면, 분석부는 재난 상황인 것으로 판단한다. 또한, 분석부는 재난 상황인 경우, 재난 상황 복잡도를 산출할 수 있다. 재난 상황 복잡도는 현재 영상에 존재하는 요구조자의 수와 재난 상황 판별을 통해 복합적으로 계산한다. 일 실시예에 따르면, 분석부는 복 수의 영상에서 검출된 객체 중 요구조자(예컨대, Person class) 존재 여부, 요구조자의 수, 요구조자의 수의 증 감 및 요구조자의 밀도에 따라 재난 상황 복잡도를 산출할 수 있다. 분석부는 예컨대, 재난 상황의 복잡도 를 양호, 주의, 심각, 긴급의 4단계로 구분할 수 있다. 항법부는 무인항공기의 현재의 지리적 위치(위도, 경도, 고도) 및 자세(yaw, roll, pitch) 등을 측정 하기 위한 것이다. 이러한 항법부는 GPS 위성으로부터 GPS 신호를 수신하기 위한 GPS 신호 수신 모듈, 모 션을 측정하기 위한 자이로센서, 각속도, 가속도 등의 센서를 포함한다. 항법부는 GPS 신호 및 센서들이 측정한 센서값을 이용하여 현재의 지리적 위치 및 자세를 측정하고, 측정된 현재 지리적 위치 및 자세를 제어부 로 전송한다. 구동부는 양력을 발생시켜 무인항공기가 비행할 수 있도록 하기 위한 것이다. 이러한 구동부는 프로펠러, 모터 등을 포함한다. 구동부는 제어부의 제어에 따른 방향 및 속도로 무인항공기를 비행하도록 한다. 특히, 구동부는 제어부의 제어에 따라 소정 영역 내에서 무인항공기가 정지비행(hovering)할 수 있도록 프로펠러의 회전 속도를 조절할 수 있다. 특히, 구동부는 제어부의 제어 에 따라 무인항공기가 항법부가 현재 위치로부터 재난 현장의 위치로 설정한 경로를 따라 비행하도록 프로펠러, 모터 등을 구동시킬 수 있다. 구동부는 제어부의 제어에 따라 요구조자의 위치가 촬영부 가 촬영하는 영상의 중심에 위치하도록 프로펠러, 모터 등을 구동시켜 무인항공기를 이동시킬 수 있 다. 또한, 구동부는 제어부의 제어에 따라 무인항공기가 재난 현장을 선회하도록 프로펠러, 모 터 등을 구동시킬 수 있다. 통신부는 관제장치 혹은 다른 무인항공기와 통신하기 위한 것이다. 통신부는 송신하기 위 한 신호의 주파수를 상승 변환 및 증폭하는 RF(Radio Frequency) 송신기(Tx) 및 수신되는 신호를 저 잡음 증폭 하고 주파수를 하강 변환하는 RF 수신기(Rx)를 포함할 수 있다. 그리고 통신부는 송신되는 신호를 변조하 고, 수신되는 신호를 복조하는 모뎀(Modem)을 포함할 수 있다. 통신부는 제어부의 제어에 따라 재난 현장의 영상, 요구조자의 영상, 요구조자의 위치 등을 관제장치로 전송한다. 저장부는 무인항공기의 동작에 필요한 각 종 데이터, 애플리케이션, 무인항공기의 동작에 따라 발생된 각 종 데이터를 저장한다. 이러한 저장부는 스토리지, 메모리 등이 될 수 있다. 특히, 저장부(28 0)는 선택적으로, 무인항공기의 부팅(booting) 및 운영(operation)을 위한 운영체제(OS, Operating System), 본 발명의 실시예에 따른 재난 현장의 영상, 검출된 객체, 요구조자의 영상, 요구조자의 위치 등의 데 이터를 저장할 수 있다. 저장부에 저장되는 각 종 데이터는 사용자의 조작에 따라, 삭제, 변경, 추가될 수 있다. 제어부는 무인항공기의 전반적인 동작 및 무인항공기의 내부 블록들 간 신호 흐름을 제어하고, 데이터를 처리하는 데이터 처리 기능을 수행할 수 있다. 이러한 제어부는 중앙 처리 장치(Central Processing Unit : CPU), 애플리케이션 프로세서(Application Processor), GPU(Graphic Processing Unit) 등이 될 수 있다. 제어부는 재난 상황 복잡도에 따라 구동부를 통해 무인항공기의 비행 방향을 제어할 수 있다. 이때, 제어부는 산출된 재난 상황 복잡도가 소정의 임계 수준 이상이면, 요구조자의 위치가 촬영부가 촬영하는 영상의 중심에 위치하도록 구동부를 제어하여 무인항공기를 이동시킨다. 반면, 제어부(29 0)는 산출된 재난 상황 복잡도가 소정의 임계 수준 미만이면, 구동부를 제어하여 재난 현장을 중심으로 무 인항공기가 선회하도록 할 수 있다. 제어부는 재난 상황 복잡도에 따라 촬영부의 촬영 주기를 제어할 수 있다. 이때, 제어부는 분석 부가 산출한 재난 상황 복잡도가 기 설정된 임계 수준 이상이면, 촬영부의 촬영 주기를 기 설정된 기 준치 미만으로 감소시켜 촬영하도록 제어한다. 반면, 분석부가 산출한 재난 상황 복잡도가 기 설정된 임계 수준 미만이면, 촬영부의 촬영 주기를 기 설정된 기준치 이상으로 증가시켜 촬영하도록 제어한다. 이러한 제어부의 동작은 아래에서 보다 상세하게 설명될 것이다. 다음으로, 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 방법에 대해서 설 명하기로 한다. 도 6은 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 방법 을 설명하기 위한 흐름도이다. 그리고 도 7 및 도 8은 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무 인항공기를 제어하기 위한 방법을 설명하기 위한 화면 예이다. 도 6을 참조하면, 무인항공기의 제어부는 S110 단계에서 통신부를 통해 관제장치로부터 목 적 위치에 대한 위치 정보를 지리적 위치(GPS 좌표)로 수신하고, 항법부를 통해 현재 위치로부터 수신된 목적 위치로 경로를 설정하고 해당 경로를 따라 비행하도록 구동부를 제어하여 수신된 목적 위치로 이동한 다. 여기서, 관제장치로부터 수신된 목적 위치는 재난 현장의 위치가 될 수 있다. 목적 위치에 도착하면 제어부는 S120 단계에서 촬영부를 통해 현장을 촬영한다. 그러면, 검출부(22 0)는 S140 단계에서 촬영부가 촬영한 복수의 영상에서 객체를 검출한다. 예컨대, 검출부는 도 4에 도 시된 바와 같이, 영상에서 객체(obj)가 차지하는 영역을 나타내는 영역박스(B: Bounding Box)의 좌표(x, y, w, h) 및 해당 객체(obj)가 적어도 하나의 기 설정된 클래스(예컨대, Person class, Car class, Tree class 등)에 속할 확률(예컨대, Person = 0.88, Car = 0.01, Person = 0.11)을 출력하도록 학습된 인공신경망 모델인 객체 분류모델을 포함한다. 이에 따라, 검출부는 객체분류모델에 촬영부가 촬영한 영상을 입력하여 객체분 류모델이 촬영부가 촬영한 영상에 대한 연산을 통해 영역박스(B)의 좌표(x, y, w, h) 및 영역박스(B) 내의 객체가 적어도 하나의 기 설정된 클래스에 속할 확률을 출력하면, 출력된 적어도 하나의 기 설정된 클래스에 속할 확률이 기 설정된 임계치(예컨대, 0.80 = 80%) 이상이면, 영역박스(B) 내에 해당 클래스의 객체가 존재하는 것으로 인식하고, 이를 검출한다. 이어서, 추적부는 S150 단계에서 촬영부가 촬영한 복수의 영상에서 검출부가 검출한 객체를 추 적한다. 이때, 추적부는 검출부가 검출한 객체의 일련번호를 할당하고 추적한다. 이에 따라, 모든 객 체를 중복 없이 계수할 수 있다. 예컨대, 추적부는 도 5의 (a)의 영상과 같이, 검출된 사람 객체에 일련번 호 ①을 부여하고 차량 두 대에 일련번호 ② 및 ③을 부여한다. 또한, 도 5의 (a)에서 포커스가 변경된 도 5의 (b)와 같은 영상에서와 같이, 동일한 객체인 사람 및 차량 객체에 일련번호 ① 및 ②가 유지되고, 새로 검출된 차량 객체에 일련번호 ④를 할당함으로써 중복을 피할 수 있다. 다음으로, 분석부는 S160 단계에서 촬영부가 촬영한 복수의 영상을 기초로 재난 상황인지 여부 및 재 난 상황 복잡도를 산출한다. 이때, 분석부는 촬영부가 촬영한 영상으로부터 재난 상황 여부를 확인한 다. 이는 제어부의 제어에 따라 이루어질 수 있다. 전술한 바와 같이, 분석부는 영상이 입력되면, 입 력되는 영상이 재난 상황에 속하는지 여부에 대한 확률을 산출하여 출력하도록 학습한 인공신경망 모델인 상황 판단모델을 포함한다. 이에 따라, 분석부는 상황판단모델에 촬영부가 촬영한 영상을 입력하며, 상황 판단모델이 촬영부가 촬영한 영상에 대해 산출한 재난 상황에 속하는지 여부에 대한 확률에 따라 재난 상황 여 부를 확인할 수 있다. 이와 같이, 재난 상황인 것인 것으로 판단된 경우, 분석부는 복수의 영상에서 검출 된 객체 중 요구조자(예컨대, Person class) 존재 여부, 요구조자의 수, 요구조자의 수의 증감 및 요구조자의 밀도에 따라 재난 상황 복잡도를 산출할 수 있다. 그런 다음, 제어부는 S170 단계에서 분석부가 산출한 재난 상황 복잡도에 따라 무인항공기를 제 어한다. S170 단계의 일례로, 제어부는 재난 상황 복잡도에 따라 구동부를 통해 무인항공기의 비행 방향 을 제어할 수 있다. 보다 구체적으로 설명하면, 제어부는 산출된 재난 상황 복잡도가 소정의 임계 수준 이상이면, 요구조자의 위치가 촬영부가 촬영하는 영상의 중심에 위치하도록 구동부를 제어하여 무인항공기를 이동시킨 다. 예컨대, 도 7의 (c)에 도시된 바에 따르면, 검출된 객체인 요구조자(R)는 화면의 측면에 위치한다. 따라서 제어부는 요구조자(R)의 위치가 도 7의 (d)에 도시된 바와 같이 촬영부가 촬영하는 영상의 중심에 위 치하도록 구동부를 제어하여 무인항공기를 이동시킬 수 있다. 이와 같이, 요구조자(R)의 위치가 도 7의 (d)에 도시된 바와 같이 촬영부가 촬영하는 영상의 중심에 위치 할 때, 제어부는 요구조자의 지리적 위치를 검출하고, 검출된 요구조자의 지리적 위치를 통신부를 통 해 관제장치로 전송할 수 있다. 보다 구체적으로 설명하면 다음과 같다. 제어부는 촬영부가 촬 영한 영상으로부터 무인항공기를 기준으로 하는 요구조자의 상대적 위치를 검출하고, 항법부를 통해 무인항공기의 지리적 위치, 즉, GPS 좌표를 도출한다. 그런 다음, 제어부는 무인항공기의 지리 적 위치를 기초로 요구조자의 상대적 위치를 지리적 위치로 변환한 후, 변환된 지리적 위치를 통신부를 통 해 관제장치로 전송할 수 있다. 반면, 제어부는 산출된 재난 상황 복잡도가 소정의 임계 수준 미만이면, 구동부를 제어하여 목적 위 치(GPS 좌표)를 중심으로 무인항공기가 선회하도록 할 수 있다. 이때, 제어부는 앞서(S110) 수신된 목적 위치(GPS 좌표)를 중심축으로 소정 거리 이격되어 원주의 경로를 생성하고, 생성된 경로를 따라 비행하며 촬영부를 통해 재난 현장을 촬영 및 모니터링할 수 있다. S170 단계의 다른 예로, 제어부는 재난 상황 복잡도에 따라 촬영부의 촬영 주기를 제어할 수 있다. 이는 제어부가 무인항공기의 전력 효율을 높이고 효과적인 구조 활동을 위해 재난 상황 복잡도에 따 라 촬영 주기를 유동적으로 변경하는 것이다. 즉, 제어부는 분석부가 산출한 재난 상황 복잡도가 기 설정된 임계 수준 이상이면, 촬영부의 촬 영 주기를 기 설정된 기준치 미만으로 감소시켜 촬영하도록 제어한다. 반면, 분석부가 산출한 재난 상황 복잡도가 기 설정된 임계 수준 미만이면, 촬영부의 촬영 주기를 기 설정된 기준치 이상으로 증가시켜 촬영 하도록 제어한다. 예컨대, 도 8의 (e)의 제1 영상들을 참조하면, 만일 촬영 주기가 길어 t=2 에 해당하는 영상을 촬영하지 못한다 면 부정확한 객체 검출이 발생할 수 있다. 제1 영상들과 같이, 복수의 요구조자가 밀집해 있는 복잡한 재난 상 황에서는 촬영 주기를 짧게 잡아 최대한 많은 객체들을 검출할 수 있도록 한다. 반대로 도 8의 (f)의 제2 영상들과 같이 상대적으로 재난 상황 복잡도가 낮은 경우에는 충분히 촬영 주기를 길게 잡더라도 오류 없이 정확한 객체 검출 및 추적을 수행할 수 있다. 즉, 도 8의 (f)의 제2 영상들의 경우, t=2에서 촬영한 영상이 없는 경우 에도 객체 검출 및 추적에 문제가 없다. 더욱이, 이러한 경우 촬영 주기를 길게 잡아 불필요한 연산을 제거할 수 있어 무인항공기의 전력 효율이 올라가게 되고, 이는 재난 상황에서 무인항공기의 장시간 비행을 가능하게 해 효과적인 인명 구조 활동을 하는 데 도움이 될 수 있다. 한편, 앞서 설명된 본 발명의 실시예에 따른 방법은 다양한 컴퓨터수단을 통하여 판독 가능한 프로그램 형태로 구현되어 컴퓨터로 판독 가능한 기록매체에 기록될 수 있다. 여기서, 기록매체는 프로그램 명령, 데이터 파일, 데이터구조 등을 단독으로 또는 조합하여 포함할 수 있다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위 하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예컨대 기록매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto- optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 와이 어뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 와이어를 포함할 수 있다. 이러한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상 본 발명을 몇 가지 바람직한 실시예를 사용하여 설명하였으나, 이들 실시예는 예시적인 것이며 한정적인"}
{"patent_id": "10-2020-0031199", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "것이 아니다. 이와 같이, 본 발명이 속하는 기술분야에서 통상의 지식을 지닌 자라면 본 발명의 사상과 첨부된 특허청구범위에 제시된 권리범위에서 벗어나지 않으면서 균등론에 따라 다양한 변화와 수정을 가할 수 있음을 이해할 것이다."}
{"patent_id": "10-2020-0031199", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 시스템을 설명하기 위한 도면이다. 도 2는 본 발명의 실시예에 따른 관제장치의 구성을 설명하기 위한 블록도이다. 도 3은 본 발명의 실시예에 따른 무인항공기의 구성을 설명하기 위한 블록도이다. 도 4 및 도 5는 본 발명의 실시예에 따른 무인항공기의 구성을 설명하기 위한 화면 예이다. 도 6은 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 방법을 설명하기 위한 흐름도이다. 도 7 및 도 8은 본 발명의 실시예에 따른 재난 상황 복잡도를 기초로 무인항공기를 제어하기 위한 방법을 설명 하기 위한 화면 예이다."}
