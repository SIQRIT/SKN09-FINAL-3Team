{"patent_id": "10-2023-0129823", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0046451", "출원번호": "10-2023-0129823", "발명의 명칭": "자율주행을 위한 융복합 영상 식별시스템", "출원인": "(주)노바코스", "발명자": "임광현"}}
{"patent_id": "10-2023-0129823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "레이더 신호를 감지 영역으로 투사하고 감지영역의 차량으로부터 반사된 신호를 레이더 검지 데이터로 출력하는레이더;상기 레이더에서 출력된 레이더 검지 데이터를 레이더 로우 데이터로 수집하는 레이더 데이터 수집부;상기 레이더 데이터 수집부에서 수집한 레이더 로우 데이터를 가공 및 정체 처리하여 테이블 형태로 전처리하는레이더 데이터 가공 및 정제부;상기 레이더 데이터 가공 및 정제부를 통해 전처리된 레이더 데이터에서 레이더 차량 감지 표출에 활용되는 데이터를 추출하는 레이더 데이터 추출부;상기 레이더 데이터 추출부에서 추출된 레이더 데이터에서 시간을 기준으로 추출된 레이더 데이터의 속성 정보를 이용하여 차량의 크기를 기초로 차량 감지를 하고, 감지한 차량 정보를 도로의 차선에 표출하는 객체표출부;상기 감지 영역의 영상을 획득하는 카메라;상기 카메라에 의해 촬영된 영상 데이터를 수집하고, 수집한 영상 데이터를 이미지 형태로 가공하여 출력하는영상 데이터 수집부;상기 영상 데이터 수집부에서 출력된 영상 데이터에서 프레임 단위로 이미지를 추출하여 학습에 필요한 동적,정적 차량의 이미지로 제공하는 이미지 추출부;상기 이미지 추출부에서 제공된 이미지를 JPG 형태로 변환하고, 변환된 이미지를 탐지할 차량별로 Object ID를지정하는 작업을 통해 차량의 영역을 지정하여 이미지 데이터를 라벨링하고, 라벨링된 이미지 데이터를 XML 형태의 포맷으로 저장하는 이미지 라벨링 및 어노테이션부;Pretrained Network와 Training Network로 구성된 Yolo 신경망 학습 모델을 구축하고, 구축된 Yolo 신경망 학습 모델에 영상 데이터를 입력하여 차량을 탐지하는 영상 객체 탐지부;상기 객체 표출부에서 탐지된 레이더 객체 정보와 상기 영상 객체 탐지부를 통해 처리된 영상 객체 정보를 매칭시키는 레이더/영상 매칭부;상기 레이더/영상 매칭부를 통해 매칭된 영상 객체 정보에서 분류 및 탐지를 위한 데이터셋을 구축하는 분류 및탐지 데이터셋 구축부;상기 분류 및 탐지 데이터셋 구축부에서 구축한 데이터셋을 기초로 객체 분류 및 탐지를 위한 신경망 모델을 구축하는 분류 및 탐지 신경망 모델 구축부;상기 분류 및 탐지 신경망 모델 구축부에서 구축한 분류 및 탐지 신경망 모델을 학습하여 검증 데이터셋을 생성하는 분류 및 탐지 신경망 모델 학습부;상기 생성된 검증 데이터 셋을 상기 분류 및 탐지 신경망 모델에 적용하여 목표치에 미도달한 학습 모델을 재학습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지가 되는지를 확인하는 학습모델 검증 및 정확도 평가부; 및상기 학습모델 검증 및 정확도 평가부를 통해 검증된 객체 탐지 결과를 기초로 레이더/카메라 융합 서비스를 수행하는 레이더/카메라 융합 서비스부를 포함하는 것을 특징으로 하는 자율주행을 위한 융복합 영상 식별시스템."}
{"patent_id": "10-2023-0129823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에서, 영상 객체 탐지부는,공개특허 10-2025-0046451-3-Pretrained Network와 Training Network로 구성된 Yolo 신경망 모델을 구축하는 신경망 모델 구축부;상기 이미지 라벨링 및 어노테이션이 이루어진 이미지 데이터를 상기 신경망 모델에 적용하기 위해 훈련 데이터셋, 검증 데이터 셋 및 테스트 데이터 셋으로 분할하고, 분류된 데이터 셋에서 검증 데이터 셋을 구축이 완료된Yolo 신경망 모델에 입력하여 신경망 레이어와 하이퍼 파라미터에 따라 학습을 진행하는 신경망 모델 학습부;상기 신경망 모델 학습부를 통해 생성되는 가중치 파일을 실제로 학습된 신경망 모델의 가중치 값들을 저장한형태로 가중치 정보를 저장하여 가중치 파일을 생성하는 학습모델 및 가중치 파일 생성부;상기 데이터 셋 분류를 통해 생성된 검증 데이터 셋을 학습 모델에 적용하여 목표치에 미도달한 학습 모델을 재학습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지가 되는지를 확인하는 학습모델 검증 및 정확도 평가부;상기 최적화된 Yolo 신경망 학습 모델에 영상 데이터를 입력하여 차량을 탐지하는 객체 추출부를 포함하는 것을특징으로 하는 자율주행을 위한 융복합 영상 식별시스템."}
{"patent_id": "10-2023-0129823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에서, 상기 레이더/영상 매칭부는,카메라에서 추출된 이미지에서 차량의 가시성을 확보하기 위해 최대 밝기 처리를 적용하여 이미지의 화질을 개선하고, 레이더에서 출력된 레이더 데이터는 차량과 노이즈 데이터로 구분하여 타깃 대상을 설정하고, 카메라와레이더 데이터의 동일한 표적에 대한 정보를 매칭하여 좌표축을 일치시킨 후 점 일치 및 하향식 방법을 사용하여 값의 오차를 줄이기 위한 보정을 수행하는 과정을 통해, 레이더와 카메라 차량을 매칭시키는 것을 특징으로하는 자율주행을 위한 융복합 영상 식별시스템."}
{"patent_id": "10-2023-0129823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에서, 상기 레이더/영상 매칭부는,상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요청한 후, 레이더에서 객체 검출 시 검출된 객체의 검출 시간 정보를 상기 영상 객체 탐지부에 전송하고 영상 객체 탐지 정보를 요청하는 것을 특징으로 하는자율주행을 위한 융복합 영상 식별시스템."}
{"patent_id": "10-2023-0129823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에서, 상기 레이더/영상 매칭부는,상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요청하며, 상기 영상 객체 탐지부에서 전송되는객체 검출 정보와 시간정보를 포함하는 객체 식별 정보의 시간 정보를 기초로 레이더 객체 정보와 영상 객체 정보를 매칭시키는 것을 특징으로 하는 자율주행을 위한 융복합 영상 식별시스템."}
{"patent_id": "10-2023-0129823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에서, 상기 레이더/카메라 융합 서비스부는,상기 레이더 및 영상 융합 차량 데이터를 야간/전천후 환경에서도 정확도 높은 차량 인식률과 검출률을 갖는 차량 인식 데이터로 자율주행차량으로 제공하거나, 원천 영상 및 가공 데이터 셋 및 학습 모델을 공공 및 민간 사이트를 통해 공개해주는 것을 특징으로 하는 자율주행을 위한 융복합 영상 식별시스템."}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "머신 러닝과 딥 러닝 알고리즘을 복합적으로 활용하여 실시간으로 객체를 식별하고 분류하여 객체를 정확하게 인 식함으로써, 자율주행 차량의 안전성과 성능 향상을 도모하도록 한 자율주행을 위한 융복합 영상 식별시스템에 관한 것으로서, 레이더 검지 데이터로 출력하는 레이더, 수집한 레이더 로우 데이터를 가공 및 정체 처리하여 테 (뒷면에 계속)"}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율주행을 위한 융복합 영상 식별시스템에 관한 것으로, 특히 머신 러닝과 딥 러닝 알고리즘을 복합 적으로 활용하여 실시간으로 객체를 식별하고 분류하여 객체를 정확하게 인식함으로써, 자율주행 차량의 안전성 과 성능 향상을 도모하도록 한 자율주행을 위한 융복합 영상 식별시스템에 관한 것이다."}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 자율주행 기술은 빠르게 발전하고 있으며, 이는 영상 처리 기술의 중요성을 더욱 부각시키고 있다. 특히, 영상 식별 기술은 자율주행 차량의 안전성과 성능에 매우 중요한 역할을 한다. 자율주행을 위한 융복합 영상 식별 기술은 여러 가지 기술의 결합으로 이루어진 기술이다. 그 중에서도 주요 기 술들은 다음과 같다. 컴퓨터 비전(Computer Vision)은 카메라나 센서 등으로 입력받은 이미지나 영상에서 패턴 이나 물체 등을 인식하고 추출하는 기술이다. 자율주행을 위해서는 주행 환경을 실시간으로 인식해야 하기 때문 에, 컴퓨터 비전 기술은 필수적인 기술 중 하나이다. 딥러닝(Deep Learning)은 인공신경망을 기반으로 한 머신 러닝 기술로, 대량의 데이터를 학습하여 패턴을 파악하고, 이를 기반으로 예측을 수행하는 기술이다. 딥러닝 기 술을 활용하여 이미지나 영상에서 물체를 인식하거나, 주행 환경을 분석하는 등의 작업을 수행할 수 있다. 센서 퓨전(Sensor Fusion)은 여러 종류의 센서를 활용하여 한 가지 작업을 수행하는 기술이다. 예를 들어, 자율주행 을 위해서는 라이다 센서, 카메라, GPS 등의 여러 가지 센서를 사용해야 하며, 이들 센서가 제공하는 정보를 통 합하여 실시간으로 주행 환경을 인식하고, 주행을 제어할 수 있다. 빅데이터 분석 (Big Data Analysis)은 대량 의 데이터를 수집하고, 분석하여 특정 패턴이나 정보를 추출하는 기술이다. 자율주행을 위해서는 주행 환경에 대하여 다양한 정보를 수집하고, 분석하여 주행 환경을 예측하고, 안전한 주행을 수행할 수 있다. 실시간 처리 (Real-time Processing)는 입력된 데이터를 실시간으로 처리하는 기술이다. 자율주행을 위해서는 실시간으로 주 행 환경을 분석하고, 주행을 제어해야 하므로, 실시간 처리 기술이 필수적이다. 이러한 기술들을 융합하여 자율 주행을 위한 영상 식별 기술을 구현할 수 있다. 자율 주행을 위한 융복합 영상 식별 시스템 개발을 위한 선행연구는 하기의 <선행문헌 1> 내지 <선행문헌 4> 에 개시되어 있다. <선행문헌 1> 에 개시된 \"Real-time object detection for autonomous vehicles using deep learning\" 은 자율주행 차량에서 실시간 객체 감지를 위해 딥러닝 알고리즘을 적용하는 방법에 대해 다루었다. Faster R- CNN 알고리즘이 객체 인식 정확도와 처리 속도에서 우수한 결과를 보였다. <선행문헌 2> 에 개시된 \"Development of a sensor fusion system for obstacle detection and tracking in autonomous vehicles\" 는 자율주행 차량에서 센서 융합 시스템을 구축하여 장애물 감지 및 추적에 대한 성능을 향상시키는 것을 목적으로 한다. 레이더 및 카메라 센서를 활용하고, 영상 처리 기술을 적용하여 장애물 을 식별하고 추적한다. <선행문헌 3> 에 개시된 \"Sensor fusion-based autonomous driving using deep learning for obstacle detection and tracking\" 은 센서 융합 및 딥 러닝 기술을 활용하여 자율주행 차량에서 장애물 감지 및 추적 성능을 향상시키는 것을 목적으로 한다. 레이더, 카메라, LIDAR 등 다양한 센서를 활용하며, 딥 러닝 알고 리즘을 적용하여 객체 인식 및 추적 성능을 개선하였다. <선행문헌 4> 에 개시된 \"A review of deep learning-based object detection and semantic segmentation for autonomous driving\" 은 딥 러닝을 활용한 객체 인식 및 시맨틱 세그멘테이션 기술에 대해 살펴보고, 자 율주행 차량에서의 적용 가능성과 한계를 분석하였다. 이를 통해 자율주행 차량의 안전성 및 성능 향상을 위한 방안을 모색하였다. 그러나 선행문헌들로 언급한 종래기술들은 단일의 객체 인식 알고리즘만을 이용하므로 객체 인식에 한계가 있으 며, 레이더와 영상을 이용하여 영상을 식별할 떄 객체 인식률이 저하되는 단점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) (선행문헌 1) Kim, J., Park, H., & Choi, Y. . Real-time object detection for autonomous vehicles using deep learning. Sensors, 17, 1608. (특허문헌 0002) (선행문헌 2) Cho, Y. J., & Park, S. . Development of a sensor fusion system for obstacle detection and tracking in autonomous vehicles. Journal of Institute of Control, Robotics and Systems, 24, 60-66. (특허문헌 0003) (선행문헌 3) Lee, J., Kim, J., Lee, J., Lee, S., & Yang, H. . Sensor fusion- based autonomous driving using deep learning for obstacle detection and tracking. Journal of Institute of Control, Robotics and Systems, 24, 79-86. (특허문헌 0004) (선행문헌 4) Li, Y., & Li, X. . A review of deep learning-based object detection and semantic segmentation for autonomous driving. Sensors, 20, 1797."}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명은 상기와 같은 일반적인 자율주행 차량을 위한 객체 인식 방법 및 선행문헌에서 발생하는 객체 인식의 한계 문제를 개선하기 위해서 제안된 것으로서, 머신 러닝과 딥 러닝 알고리즘을 복합적으로 활용하여 실시간으로 객체를 식별하고 분류하여 객체를 정확하게 인식함으로써, 자율주행 차량의 안전성과 성능 향상을 도모하도록 한 자율주행을 위한 융복합 영상 식별시스템을 제공하는 데 그 목적이 있다. 본 발명의 다른 목적은 다양한 영상 식별 기술을 활용하여 차량 주변 환경의 객체를 인식하고 추적할 수 있도록 한 자율주행을 위한 융복합 영상 식별시스템을 제공하는 것이다. 본 발명의 다른 목적은 다양한 영상 식별 기술을 활용하여 식별한 객체의 정보를 차량 제어 시스템에 전달하여 자율주행 차량이 적절하게 반응하여 자율주행 차량의 안전성과 성능을 향상하도록 한 자율주행을 위한 융복합 영상 식별시스템을 제공하는 것이다."}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 목적을 달성하기 위하여, 본 발명에 따른 \"자율주행을 위한 융복합 영상 식별시스템\"은, 레이더 신호를 감지 영역으로 투사하고 감지영역의 차량으로부터 반사된 신호를 레이더 검지 데이터로 출력하는 레이더; 상기 레이더에서 출력된 레이더 검지 데이터를 레이더 로우 데이터로 수집하는 레이더 데이터 수집부; 상기 레이더 데이터 수집부에서 수집한 레이더 로우 데이터를 가공 및 정체 처리하여 테이블 형태로 전처리하는 레이더 데이터 가공 및 정제부; 상기 레이더 데이터 가공 및 정제부를 통해 전처리된 레이더 데이터에서 레이더 차량 감지 표출에 활용되는 데 이터를 추출하는 레이더 데이터 추출부; 상기 레이더 데이터 추출부에서 추출된 레이더 데이터에서 시간을 기준으로 추출된 레이더 데이터의 속성 정보 를 이용하여 차량의 크기를 기초로 차량 감지를 하고, 감지한 차량 정보를 도로의 차선에 표출하는 객체 표출부; 상기 감지 영역의 영상을 획득하는 카메라; 상기 카메라에 의해 촬영된 영상 데이터를 수집하고, 수집한 영상 데이터를 이미지 형태로 가공하여 출력하는 영상 데이터 수집부; 상기 영상 데이터 수집부에서 출력된 영상 데이터에서 프레임 단위로 이미지를 추출하여 학습에 필요한 동적, 정적 차량의 이미지로 제공하는 이미지 추출부; 상기 이미지 추출부에서 제공된 이미지를 JPG 형태로 변환하고, 변환된 이미지를 탐지할 차량별로 Object ID를 지정하는 작업을 통해 차량의 영역을 지정하여 이미지 데이터를 라벨링하고, 라벨링된 이미지 데이터를 XML 형 태의 포맷으로 저장하는 이미지 라벨링 및 어노테이션부;Pretrained Network와 Training Network로 구성된 Yolo 신경망 학습 모델을 구축하고, 구축된 Yolo 신경망 학 습 모델에 영상 데이터를 입력하여 차량을 탐지하는 영상 객체 탐지부; 상기 객체 표출부에서 탐지된 레이더 객체 정보와 상기 영상 객체 탐지부를 통해 처리된 영상 객체 정보를 매칭 시키는 레이더/영상 매칭부; 상기 레이더/영상 매칭부를 통해 매칭된 영상 객체 정보에서 분류 및 탐지를 위한 데이터셋을 구축하는 분류 및 탐지 데이터셋 구축부; 상기 분류 및 탐지 데이터셋 구축부에서 구축한 데이터셋을 기초로 객체 분류 및 탐지를 위한 신경망 모델을 구 축하는 분류 및 탐지 신경망 모델 구축부; 상기 분류 및 탐지 신경망 모델 구축부에서 구축한 분류 및 탐지 신경망 모델을 학습하여 검증 데이터셋을 생성 하는 분류 및 탐지 신경망 모델 학습부; 상기 생성된 검증 데이터 셋을 상기 분류 및 탐지 신경망 모델에 적용하여 목표치에 미도달한 학습 모델을 재학 습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지가 되는지를 확인하는 학습모 델 검증 및 정확도 평가부; 상기 학습모델 검증 및 정확도 평가부를 통해 검증된 객체 탐지 결과를 기초로 레이더/카메라 융합 서비스를 수 행하는 레이더/카메라 융합 서비스부를 포함하는 것을 특징으로 한다. 상기에서 레이더/카메라 융합 서비스부는 상기 학습모델 검증 및 정확도 평가부를 통해 출력되는 레이더 및 영 상 융합 인식 데이터, 원천 영상, 가공 데이터 셋, 학습 모델을 자율주행차량과 공공/민간 사이트에 공개해주는 것을 특징으로 한다. 상기 영상 객체 탐지부는, Pretrained Network와 Training Network로 구성된 Yolo 신경망 모델을 구축하는 신경망 모델 구축부; 상기 이미지 라벨링 및 어노테이션이 이루어진 이미지 데이터를 상기 신경망 모델에 적용하기 위해 훈련 데이터 셋, 검증 데이터 셋 및 테스트 데이터 셋으로 분할하고, 분류된 데이터 셋에서 검증 데이터 셋을 구축이 완료된 Yolo 신경망 모델에 입력하여 신경망 레이어와 하이퍼 파라미터에 따라 학습을 진행하는 신경망 모델 학습부; 상기 신경망 모델 학습부를 통해 생성되는 가중치 파일을 실제로 학습된 신경망 모델의 가중치 값들을 저장한 형태로 가중치 정보를 저장하여 가중치 파일을 생성하는 학습모델 및 가중치 파일 생성부; 상기 데이터 셋 분류를 통해 생성된 검증 데이터 셋을 학습 모델에 적용하여 목표치에 미도달한 학습 모델을 재 학습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지가 되는지를 확인하는 학습 모델 검증 및 정확도 평가부; 상기 최적화된 Yolo 신경망 학습 모델에 영상 데이터를 입력하여 차량을 탐지하는 객체 추출부를 포함하는 것을 특징으로 한다. 상기 레이더/영상 매칭부는, 카메라에서 추출된 이미지에서 차량의 가시성을 확보하기 위해 최대 밝기 처리를 적용하여 이미지의 화질을 개 선하고, 레이더에서 출력된 레이더 데이터는 차량과 노이즈 데이터로 구분하여 타깃 대상을 설정하고, 카메라와 레이더 데이터의 동일한 표적에 대한 정보를 매칭하여 좌표축을 일치시킨 후 점 일치 및 하향식 방법을 사용하 여 값의 오차를 줄이기 위한 보정을 수행하는 과정을 통해, 레이더와 카메라 차량을 매칭시키는 것을 특징으로 한다. 상기 레이더/영상 매칭부는, 상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요청한 후, 레이더에서 객체 검출 시 검출된 객 체의 검출 시간 정보를 상기 영상 객체 탐지부에 전송하고 영상 객체 탐지 정보를 요청하는 것을 특징으로 한다. 상기 레이더/영상 매칭부는, 상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요청하며, 상기 영상 객체 탐지부에서 전송되는 객체 검출 정보와 시간정보를 포함하는 객체 식별 정보의 시간 정보를 기초로 레이더 객체 정보와 영상 객체 정보를 매칭시키는 것을 특징으로 한다. 상기에서 레이더/카메라 융합 서비스부는, 상기 레이더 및 영상 융합 차량 데이터를 야간/전천후 환경에서도 정확도 높은 차량 인식률과 검출률을 갖는 차 량 인식 데이터로 자율주행차량으로 제공하거나, 원천 영상 및 가공 데이터 셋 및 학습 모델을 공공 및 민간 사 이트를 통해 공개해주는 것을 특징으로 한다."}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 머신 러닝과 딥 러닝 알고리즘을 복합적으로 활용하여 실시간으로 객체를 식별하고 분류하여 객체를 정확하게 인식함으로써, 자율주행 차량의 안전성과 성능 향상을 도모할 수 있는 효과가 있다. 또한, 본 발명에 따르면 다양한 영상 식별 기술을 활용하여 차량 주변 환경의 객체를 인식하고 추적할 수 있는 장점도 있다. 또한, 본 발명에 따르면 다양한 영상 식별 기술을 활용하여 식별한 객체의 정보를 차량 제어 시스템에 전달하여 자율주행 차량이 적절하게 반응하여 자율주행 차량의 안전성과 성능을 향상하도록 도모해주는 효과가 있다."}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 바람직한 실시 예에 따른 자율주행을 위한 융복합 영상 식별시스템을 첨부된 도면을 참조하여 상세하게 설명한다. 이하에서 설명되는 본 발명에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서는 안 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념으로 적절하게 정의할 수 있 다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 바람직한 실시 예에 불과할 뿐이고, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원 시점에서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 도 1은 본 발명의 바람직한 실시 예에 따른 자율주행을 위한 융복합 영상 식별시스템의 구성도로서, 레이더 , 레이더 데이터 수집부, 레이더 데이터 가공 및 정제부, 레이더 데이터 추출부, 객체 표 출부, 카메라, 영상 데이터 수집부, 이미지 추출부, 이미지 라벨링 및 어노테이션부, 영상 객체 탐지부, 레이더/영상 매칭부, 분류 및 탐지 데이터셋 구축부, 분류 및 탐지 신경망 모델 구축부, 분류 및 탐지 신경망 모델 학습부, 학습 모델 검증 및 정확도 평가부, 레이더/카 메라 융합 서비스부를 포함할 수 있다. 레이더(radar)는 레이더 신호를 감지 영역으로 투사하고 감지영역의 차량으로부터 반사된 신호를 레이더 검지 데이터로 출력하는 역할을 한다. 레이더 데이터 수집부는 상기 레이더에서 출력된 레이더 검지 데이터를 레이더 로우 데이터(Raw Signal)로 수집하는 역할을 한다. 레이더 데이터 가공 및 정제부는 상기 레이더 데이터 수집부에서 수집한 레이더 로우 데이터를 가공 및 정체 처리하여 테이블 형태로 전처리하는 역할을 한다. 레이더 데이터 추출부는 상기 레이더 데이터 가공 및 정제부를 통해 전처리된 레이더 데이터에서 레 이더 차량 감지 표출에 활용되는 데이터를 추출하는 역할을 한다. 객체 표출부는 상기 레이더 데이터 추출부에서 추출된 레이더 데이터에서 시간을 기준으로 추출된 레 이더 데이터의 속성 정보를 이용하여 차량의 크기를 기초로 차량 감지를 하고, 감지한 차량 정보를 도로의 차선 에 표출하는 역할을 한다. 카메라는 감지 영역의 영상을 획득하는 역할을 하며, 영상 데이터 수집부는 상기 카메라에 의해 촬영된 영상 데이터를 수집하고, 수집한 영상 데이터를 이미지 형태로 가공하여 출력하는 역할을 한다. 이미지 추출부는 상기 영상 데이터 수집부에서 출력된 영상 데이터에서 프레임 단위로 이미지를 추출 하여 학습에 필요한 동적, 정적 차량의 이미지로 제공하는 역할을 한다. 이미지 라벨링 및 어노테이션부는 상기 이미지 추출부에서 제공된 이미지를 JPG 형태로 변환하고, 변 환된 이미지를 탐지할 차량별로 Object ID를 지정하는 작업을 통해 차량의 영역을 지정하여 이미지 데이터를 라 벨링하고, 라벨링된 이미지 데이터를 XML 형태의 포맷으로 저장하는 역할을 한다. 영상 객체 탐지부는 Pretrained Network와 Training Network로 구성된 Yolo 신경망 학습 모델을 구축하고, 구축된 Yolo 신경망 학습 모델에 영상 데이터를 입력하여 차량을 탐지하는 역할을 한다.이러한 영상 객체 탐지부는 Pretrained Network와 Training Network로 구성된 Yolo 신경망 모델을 구축하 는 신경망 모델 구축부, 상기 이미지 라벨링 및 어노테이션이 이루어진 이미지 데이터를 상기 신경망 모델 에 적용하기 위해 훈련 데이터 셋, 검증 데이터 셋 및 테스트 데이터 셋으로 분할하고, 분류된 데이터 셋에서 검증 데이터 셋을 구축이 완료된 Yolo 신경망 모델에 입력하여 신경망 레이어와 하이퍼 파라미터에 따라 학습을 진행하는 신경망 모델 학습부, 상기 신경망 모델 학습부를 통해 생성되는 가중치 파일을 실제로 학습 된 신경망 모델의 가중치 값들을 저장한 형태로 가중치 정보를 저장하여 가중치 파일을 생성하는 학습모델 및 가중치 파일 생성부, 상기 데이터 셋 분류를 통해 생성된 검증 데이터 셋을 학습 모델에 적용하여 목표치 에 미도달한 학습 모델을 재학습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지 가 되는지를 확인하는 학습 모델 검증 및 정확도 평가부, 상기 최적화된 Yolo 신경망 학습 모델에 영상 데 이터를 입력하여 차량을 탐지하는 객체 추출부를 포함할 수 있다. 레이더/영상 매칭부는 상기 객체 표출부에서 탐지된 레이더 객체 정보와 상기 영상 객체 탐지부(11 0)를 통해 처리된 영상 객체 정보를 매칭시키는 역할을 한다. 이러한 레이더/영상 매칭부는 카메라에서 추출된 이미지에서 차량의 가시성을 확보하기 위해 최대 밝기 처 리를 적용하여 이미지의 화질을 개선하고, 레이더에서 출력된 레이더 데이터는 차량과 노이즈 데이터로 구분하 여 타깃 대상을 설정하고, 카메라와 레이더 데이터의 동일한 표적에 대한 정보를 매칭하여 좌표축을 일치시킨 후 점 일치 및 하향식 방법을 사용하여 값의 오차를 줄이기 위한 보정을 수행하는 과정을 통해, 레이더와 카메 라 차량을 매칭시킬 수 있다. 아울러 상기 레이더/영상 매칭부는 상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요 청한 후, 레이더에서 객체 검출 시 검출된 객체의 검출 시간 정보를 상기 영상 객체 탐지부에 전송하고 영 상 객체 탐지 정보를 요청할 수 있다. 아울러 상기 레이더/영상 매칭부는 상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요 청하며, 상기 영상 객체 탐지부에서 전송되는 객체 검출 정보와 시간정보를 포함하는 객체 식별 정보의 시 간 정보를 기초로 레이더 객체 정보와 영상 객체 정보를 매칭시킬 수 있다. 분류 및 탐지 데이터셋 구축부는 상기 레이더/영상 매칭부를 통해 매칭된 영상 객체 정보에서 분류 및 탐지를 위한 데이터셋을 구축하는 역할을 한다. 분류 및 탐지 신경망 모델 구축부는 상기 분류 및 탐지 데이터셋 구축부에서 구축한 데이터셋을 기초 로 객체 분류 및 탐지를 위한 신경망 모델을 구축하는 역할을 한다. 분류 및 탐지 신경망 모델 학습부는 상기 분류 및 탐지 신경망 모델 구축부에서 구축한 분류 및 탐지 신경망 모델을 학습하여 검증 데이터셋을 생성하는 역할을 한다. 학습모델 검증 및 정확도 평가부는 상기 생성된 검증 데이터 셋을 상기 분류 및 탐지 신경망 모델에 적용 하여 목표치에 미도달한 학습 모델을 재학습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지가 되는지를 확인하는 역할을 한다. 레이더/카메라 융합 서비스부는 상기 학습모델 검증 및 정확도 평가부를 통해 검증된 객체 탐지 결과 를 기초로 레이더/카메라 융합 서비스를 수행하는 역할을 한다. 이러한 레이더/카메라 융합 서비스부는 상기 학습모델 검증 및 정확도 평가부를 통해 출력되는 레이 더 및 영상 융합 인식 데이터, 원천 영상, 가공 데이터 셋, 학습 모델을 자율주행차량과 공공/민간 사이트에 공 개해줄 수 있다. 아울러 레이더/카메라 융합 서비스부는 상기 레이더 및 영상 융합 차량 데이터를 야간/전천후 환경에서도 정확도 높은 차량 인식률과 검출률을 갖는 차량 인식 데이터로 자율주행차량으로 제공하거나, 원천 영상 및 가 공 데이터 셋 및 학습 모델을 공공 및 민간 사이트를 통해 공개해줄 수 있다. 이와 같이 구성된 본 발명의 바람직한 실시 예에 따른 자율주행을 위한 융복합 영상 식별시스템의 동작을 구체 적으로 설명하면 다음과 같다. 차량 감지용으로 설치된 레이더(radar)는 레이더 신호를 미리 지정된 감지 영역으로 투사하고, 감지영역의 객체(차량)로부터 반사된 신호를 레이더 검지 데이터로 레이더 데이터 수집부로 출력한다. 상기 레이더 데이터 수집부는 상기 레이더에서 출력된 레이더 검지 데이터를 레이더 로우 데이터(Raw Signal)로 수집한다. 예컨대, 레이더 데이터 수집부는 상기 레이더로부터 보행자/차량의 6종 객체(보행자, 이륜차, 승용차, 승합차, 버스, 트럭)에 대하여 레이더 감지 영역을 지정하여, 로우 데이터(Raw Signal)를 수집한다. 도 2는 레이더로 수집되는 로우 데이터의 예시이다. 다음으로, 레이더 데이터 가공 및 정제부는 상기 레이더 데이터 수집부에서 수집한 레이더 로우 데이 터를 가공 및 정체 처리하여 테이블 형태로 전처리한다. 즉, 수집된 로우 데이터(신호 형태)를 데이터 가공 및 정제 과정을 거쳐 테이블 형태로 변환하는 전처리 기술이 필요하다. 레이더 기기 내 파싱 모듈(Radar Parsing Module)을 통해 테이블 형태로 변환된 로우 데이터의 신호 를 수신받을 수 있는 서버의 목적지 IP를 설정하고 프로토콜을 이용하여 전송한다. 이어, 레이더 데이터 추출부는 상기 레이더 데이터 가공 및 정제부를 통해 전처리된 레이더 데이터에 서 레이더 차량 감지 표출에 활용되는 데이터를 추출한다. 도 3은 추출된 레이더 데이터의 예시이다. 추출된 데이터의 속성은 ID, Time, Lane, Point x, Point y, Velocity x, Velocity y, RCS로 구성된다. ID : 객체의 고유 순번, Time : 객체가 탐지되었을 때 측정된 날짜와 시간, Lane : 객체가 탐지된 도로의 차선 번호, Point x : 레이더 기기 기준 2차원 형태의 좌표에서 객체가 탐지된 X 좌표 위치값, Point y : 레이더 기 기 기준 2차원 형태의 좌표에서 객체가 탐지된 Y 좌표 위치값, Velocity x : 레이더 기기 기준 2차원 형태의 좌 표에서 객체의 X 좌표 속도값, Velocity y : 레이더 기기 기준 2차원 형태의 좌표에서 객체의 Y 좌표 속도값, RCS(Radar Cross Section): 레이더 반사 면적으로 감지된 객체가 레이더에 반사되어 측정되는 크기의 척도를 각 각 나타낸다. 다음으로, 객체 표출부는 상기 레이더 데이터 추출부에서 추출된 레이더 데이터에서 시간을 기준으로 추출된 레이더 데이터의 속성 정보를 이용하여 차량의 크기를 기초로 차량 감지를 하고, 감지한 차량 정보를 도 로의 차선에 표출한다. 예컨대, 감지된 객체의 시간을 기준으로 도로의 차선에 추출된 레이더 데이터의 속성인 ID, Time, Lane, Point x, Point y, Velocity x, Velocity y를 통해 객체의 크기에 따라 감지할 수 있는 객체의 종류인 6종(보행자 (pedestrian), 이륜차(two-wheeled vehicle), 승용차(car), 승합차(suv), 버스(bus), 트럭(truck))에 대해서 RCS 값인 레이더 반사 면적을 이용하여 표출한다. 도 4는 레이더 데이터 객체 표출 예시이다. 이러한 과정으로 레이더 객체 탐지를 수행한다. 다음으로, 영상의 객체 탐지를 위해, 카메라를 통해 감지 영역의 영상을 획득하고, 영상 데이터 수집부 는 상기 카메라에 의해 촬영된 영상 데이터를 수집하고, 수집한 영상 데이터를 이미지 형태로 가공하 여 출력한다. 예컨대, 도로의 돌발 상황 카메라 영상 데이터를 수집할 수 있는 곳을 사전 조사 후 도로의 표지판, 가로등, 신 호등과 같은 다양한 장소에 카메라 기기를 설치한다. 높은 탐지율과 정확도를 위해 최소 10만 건 이상의 카메라 영상 데이터를 수집하며 딥러닝 기반 학습 모델에 사용할 수 있는 샘플 데이터인 이미지 형태로 가공한다. 이어, 이미지 추출부는 상기 영상 데이터 수집부에서 출력된 영상 데이터에서 프레임 단위로 이미지 를 추출하여 학습에 필요한 동적, 정적 차량의 이미지로 제공한다. 예컨대, 이미지 추출부는 학습에 활용할 수 있도록 획득한 영상 데이터에서 학습에 필요한 동적, 정적객체 의 이미지를 추출하기 위한 방법으로, Python 프로그래밍 언어 기반 영상 처리 라이브러리 중 OpenCV를 활용하 여 수집된 영상 데이터에서 프레임(Default: 30fps) 단위로 이미지를 추출한다. 도 5는 이미지 추출 예시이다. 이어, 이미지 라벨링 및 어노테이션부는 상기 이미지 추출부에서 제공된 이미지를 JPG 형태로 변환하 고, 변환된 이미지를 탐지할 차량별로 Object ID를 지정하는 작업을 통해 차량의 영역을 지정하여 이미지 데이 터를 라벨링하고, 라벨링된 이미지 데이터를 XML 형태의 포맷으로 저장한다. 예컨대, 이미지 라벨링 및 어노테이션 과정은 이미지의 의미를 확장하고, 메타 데이터를 구성하여 고품질의 학 습 데이터를 확보하고 라벨링 및 어노테이션에서 경계 상자(Bounding Box)로 그려지는 객체 종류는 6종으로 보 행자, 이륜차, 승용차, 승합차, 버스, 트럭으로 구성한다.Yolo 신경망 모델 학습을 위해 이미지에서 객체의 경계 상자를 표시하기 위한 오픈소스 기반 프로그램을 이용하 고 추출한 이미지를 대상으로 JPG 형태로 변환 후 이미지를 불러와 탐지할 객체 별로 ObJect ID를 지정하는 손 수 작업을 통해 객체의 영역을 지정하여 데이터를 라벨링할 수 있다. 도 6은 Yolo_Mark를 이용한 이미지 라벨링 마킹 예시이다. 유명한 이미지 라벨링 도구로 Object Detection 학습을 위해 영상에서 Bounding Box를 지정하여 라벨링을 수행 하고, Bounding Box 정보들을 XML 형태의 포맷으로 저장한다. 어노테이션 파일 저장 방식은 Object Detection Dataset 중 하나인 PASCAL VOC 포맷을 사용한다. XML 파일 안 에는 수많은 태그(Tag)들이 존재하지만, Object Detection 모델을 학습하기 위해 사용되는 태그들은 정해져 있 으며, XML 파일들 구조의 예시는 도 8과 같다. 다음으로, 영상 객체 탐지부는 Pretrained Network와 Training Network로 구성된 Yolo 신경망 학습 모델 을 구축하고, 구축된 Yolo 신경망 학습 모델에 영상 데이터를 입력하여 차량을 탐지한다. 예컨대, 영상 객체 탐지부는 신경망 모델 구축부를 통해 Pretrained Network와 Training Network로 구성된 Yolo 신경망 모델을 구축한다. 도 8은 구축된 Yolo 신경망 모델 레이어의 예시이다. 도 8에서 주황색 테두리로 표현한 부분인 Pretrained Network는 GoogLeNet Layer를 이용하여 ImageNet 1000- class Dataset을 사전에 학습한 결과를 저장하고 있는 Layer이고, 파란색 테두리로 표현한 부분인 Training Network는 Pretrained Network에서 학습한 특징을 이용하여 클래스 확률(Class probability)과 경계상자 (Bounding box)를 학습하고 예측하는 Layer이다. Yolo 신경망 모델 구축을 위해 Yolo 신경망 모델을 최적화하기 위한 하이퍼 파라미터 설정한다. Yolo 신경망 모 델의 하이퍼 파라미터로 설정할 수 있는 값들은 객체를 감지할 클래스 개수, 학습률(Learning Rate), 손실 함수 (Cost Function), 활성화 함수(Activation Function)를 설정한다. 여기서 클래스 개수는 신경망 모델을 통해 탐지할 객체의 개수, 학습률은 신경망 모델이 확률적 경사 하강법 (SGD : Stochastic Gradient Descent)을 이용하여 오차를 줄여나갈 때 필요한 학습 비율, 활성화 함수는 레이 어에 구성되어있는 노드에서 다음 레이어의 노드로 이동할 때 사용한다. 클래스로 분류될 확률에 필요한 연산의 오차를 줄이는 비선형 함수 신경망 모델을 학습하고, 검증 데이터 셋을 이용하여 학습 모델을 검증하고 정확도 를 평가하고, 낮은 수치가 측정되면 히든 레이어의 개수 및 하이퍼 파라미터를 조정하여 최적화하는 과정이 필 요하다. 즉, 신경망 모델 학습부는 상기 이미지 라벨링 및 어노테이션이 이루어진 이미지 데이터를 상기 신경망 모 델에 적용하기 위해 훈련 데이터 셋, 검증 데이터 셋 및 테스트 데이터 셋으로 분할하고, 분류된 데이터 셋에서 검증 데이터 셋을 구축이 완료된 Yolo 신경망 모델에 입력하여 신경망 레이어와 하이퍼 파라미터에 따라 학습을 진행한다. 학습모델 및 가중치 파일 생성부는 상기 신경망 모델 학습부를 통해 생성되는 가중치 파일을 실제로 학습된 신경망 모델의 가중치 값들을 저장한 형태로 가중치 정보를 저장하여 가중치 파일을 생성한다. 상기 학습 모델 검증 및 정확도 평가부는 상기 데이터 셋 분류를 통해 생성된 검증 데이터 셋을 학습 모델 에 적용하여 목표치에 미도달한 학습 모델을 재학습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지가 되는지를 확인한다. 객체 추출부는 상기 최적화된 Yolo 신경망 학습 모델에 영상 데이터를 입력하여 차량(객체)을 탐지한다. 예컨대, Yolo 신경망 모델의 신경망 모델을 학습하고, 검증 데이터 셋을 이용하여 학습 모델을 검증하고 정확도 를 평가하고, 낮은 수치가 측정되면 히든 레이어의 개수 및 하이퍼 파라미터를 조정하여 최적화하는 과정이 필 요하다. 상기 이미지 라벨링 및 어노테이션이 이루어진 이미지 데이터를 상기 신경망 모델에 적용하기 위해 훈련 데이터 셋, 검증 데이터 셋 및 테스트 데이터 셋으로 분할한다. 전체 라벨링된 어노테이션 이미지 데이터 중 15%를 테 스트 데이터 셋에 할당하고(1차 분할), 다음 나머지 85% 중 70%를 훈련 데이터 셋에 사용하며(2차 분할), 나머 지 15%를 검증 데이터 셋에 할당한다(3차 분할). 여기서 중요한 사항은 데이터를 무작위로 나누어야 하며, 무작 위가 아닌 방법으로 데이터를 나누면(예를 들어, 순서대로 상위 70%를 훈련 데이터 셋에 사용) 편향된 훈련 데이터 셋과 테스트 데이터 셋이 구성되고, 가령 시간 순서대로 저장된 원본 데이터의 상위 70%를 훈련 데이터 셋 으로 사용하면, 모델이 특정 날짜만 학습하게 되어 편향이 커지고 탐지 정확도가 낮게 측정된다. 분류된 데이터 셋에서 검증 데이터 셋을 구축이 완료된 Yolo 신경망 모델에 입력하여 신경망 레이어와 하이퍼 파라미터에 따라 학습을 진행한다. 상기 레이더/영상 매칭부는 상기 객체 표출부에서 탐지된 레이더 객체 정보와 상기 영상 객체 탐지부 를 통해 처리된 영상 객체 정보를 매칭시켜 객체를 정확하게 인식한다. 즉, 레이더/영상 매칭부는 1단계로 카메라에서 추출된 이미지에서 차량의 가시성을 확보하기 위해 최대 밝 기 처리를 적용하여 이미지의 화질을 개선한다. 다음 단계로 레이더에서 출력된 레이더 데이터는 차량과 노이즈 데이터로 구분하여 타깃 대상을 설정한다. 즉, 레이더로 측정한 데이터는 6종에 해당하는 객체와 이외 노이즈(Noise) 데이터로 구분하여 타깃 대상을 설정한다. 마지막 단계로, 카메라의 좌표를 레이더와 일치시키는 과정으로, 카메라와 레이더 데이터의 동일한 표적에 대한 정보를 매칭하여 좌표축을 일치시킨 후 점 일치 및 하향식 방법을 사용하여 값의 오차를 줄이기 위한 보정을 수 행하는 과정을 통해, 레이더와 카메라 차량(객체)을 매칭시킨다. 도 9는 레이더/카메라 매칭 알고리즘의 예시이 다. 여기서 레이더/영상 매칭부는 상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요청한 후, 레이더에서 객체 검출 시 검출된 객체의 검출 시간 정보를 상기 영상 객체 탐지부에 전송하고 영상 객 체 탐지 정보를 요청할 수 있다. 상기 레이더/영상 매칭부와 영상 객체 탐지부 간에는 TCP/IP 방식의 패킷 통신 방식을 따르며, 현장 제어기인 레이더/영상 매칭부는 서버(server) 모드, 인공지능 영상 식별기 인 영상 객체 탐지부는 클라이언트(Client) 모드로 동작한다. 아울러 상기 레이더/영상 매칭부는 상기 영상 객체 탐지부에 시스템 정보를 전송하고 시간 동기를 요 청하며, 상기 영상 객체 탐지부에서 전송되는 객체 검출 정보와 시간정보를 포함하는 객체 식별 정보의 시 간 정보를 기초로 레이더 객체 정보와 영상 객체 정보를 매칭시킬 수 있다. 제어기인 레이더/영상 매칭부는 레이다에서 검출된 객체의 정보(검출시간)를 영상 객체 탐지부에 전 송하고, 인공지능 영상 식별기인 영상 객체 탐지부는 Passive AI 영상 식별기에서 영상의 객체 위치 중심 에서 식별된 정보를 전송하고, Scheduling AI 영상식별기에서 자체 카메라 위치 순환 중 검출된 객체의 정보를 전송한다. 디바이스 ID는 0..255(할당 IP 하위숫자를 사용)이다. 도 10은 제어기인 레이더/영상 매칭부와 인공지능 영상 식별기인 영상 객체 탐지부 간의 데이터 전송 흐름도이다. 전송되는 메시지 프레임은 도 11에 도시한 바와 같이, 고정길이를 가지는 헤더부(Header-part)와 헤더 내의 명 령어 코드에 따라 가변길이를 가지는 데이터부(Data-part), 고정길이를 가지는 종료부(End-part)로 구성된다. 또한, 모든 패킷에 걸쳐 바이트 정렬(Network Ordering: Little-Endian)을 따라야 한다. 패킷을 구성하는 각 필드들에 대한 데이터형과 그 길이를 표시함에 따른 표기법은 도 12와 같이 정하며, 본 발명도 이러한 표기법에 따라 작성되었다. 정수형 숫자로 표시되는 것이 일반적이며, 가변길이를 표현한 경우에는 도 13과 같이 표현된다. 프레임 구조는 도 14와 같으며, OPCode 및 응답코드(Result Code)는 도 15와 같다. 제어기 시스템 정보 전송 및 시간 동기화를 요청한다. 제어기와 AI 영상식별기의 시간을 동기화하고 시스템 설 정 정보를 송/수신하는 명령어이다. connect 후 첫 번째로 송/수신한다(임의의 시점에서도 가능). 수신된 ID들 을 가지고 송/수신에 활용하며 전송된 제어기의 현재시각 정보로 AI 영상식별기의 시간을 갱신하고 결과를 응답 한다. 도 16은 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 데이터 필드의 예시이며, 도 17은 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 데이터 필드 예시이다. 레이더에서 객체가 검출되면 제어기가 PTZ 명령을 전송한다. 그리고 PTZ 이동시간 영상 안정화 시간 후 객체 식 별 정보 요청한다. 제어기는 객체의 검출시간, 레이더 번호, 카메라 번호, AI 식별기 번호를 전송하고, AI 영상식별기에서 수신된 정보를 검사하여 해당 영상의 식별 결과를 응답한다. 도 18은 객체 식별 정보 요청 및 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 데이터 필드 의 예시이며, 도 19는 객체 식별 정보 요청에 대하여 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 데이터 필드 예시이다. 스케줄링 카메라에서 영상 객체 검출 시 AI 영상식별기에서 제어기로 검출 시점에 전송한다. 레이더 검출실패이 므로 RadarID = 0, 제어기는 정상수신 되었음을 응답한다. 도 20은 객체 식별 정보 전송 및 수신 응답 시 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 데이터 필드의 예시이며, 도 21은 객체 식별 정보 전송 및 수신 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 응답 데이터 필드의 예시이다. 관제용 schedule AI 식별기(client)에 카메라 이동 시작을 알린다. 그리고 응답 메시지를 전송하고 10초 간격으 로 preset 위치를 이동한다. 수신 후 영상식별을 시작하며 식별 결과를 0xA1 명령어로 제어기에 1번만 전송한다. 그리고 실영상, 열영상카메라에 각각 전송한다. 도 22는 영상 객체 탐지 제어시작 전송 및 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 전 송 데이터 필드 예시이며, 도 23은 영상 객체 탐지 제어시작 전송 및 응답 시 영상 객체 탐지부에서 레이더/카 메라 매칭부로 전송되는 전송 데이터 필드 예시이다. AI 식별기(client)가 제어기(server) 측으로 통신 연결 세션 상태가 정상인지 여부를 확인한다. 10초 간격으로 서버에 통신 연결 세션 유효성 확인 요청을 수행하고 송신시 에러가 나거나 수신이 없으면 연결 무효화 한다. 도 24는 통신 연결 유효성 검사 전송 및 응답 시 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 전송 데이터 필드 예시이며, 도 25는 통신 연결 유효성 검사 전송 및 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 전송 데이터 필드 예시이다. 이러한 과정으로 딥러닝 알고리즘을 이용한 레이더와 카메라의 매칭을 통해 1차적으로 영상 객체를 인식하고, 이어, 2차적으로 머신 러닝을 이용하여 레이더와 카메라의 매칭을 수행하여 최종적으로 정확하게 영상 객체를 식별한다. 즉, 분류 및 탐지 데이터셋 구축부는 상기 레이더/영상 매칭부를 통해 매칭된 영상 객체 정보에서 분 류 및 탐지를 위한 데이터셋을 구축한다. 이어, 분류 및 탐지 신경망 모델 구축부는 상기 분류 및 탐지 데이터셋 구축부에서 구축한 데이터셋 을 기초로 객체 분류 및 탐지를 위한 신경망 모델을 구축한다. 다음으로, 분류 및 탐지 신경망 모델 학습부는 상기 분류 및 탐지 신경망 모델 구축부에서 구축한 분 류 및 탐지 신경망 모델을 학습하여 검증 데이터셋을 생성한다. 아울러 학습모델 검증 및 정확도 평가부는 상기 생성된 검증 데이터 셋을 상기 분류 및 탐지 신경망 모델 에 적용하여 목표치에 미도달한 학습 모델을 재학습하여 학습 모델 최적화를 진행하고, 목표치로 지정한 정확도 이상 인식 및 검지가 되는지를 확인한다. 마지막으로, 레이더/카메라 융합 서비스부는 상기 학습모델 검증 및 정확도 평가부를 통해 검증된 객 체 탐지 결과를 기초로 레이더/카메라 융합 서비스를 수행한다. 이러한 레이더/카메라 융합 서비스부는 상기 학습모델 검증 및 정확도 평가부를 통해 출력되는 레이 더 및 영상 융합 인식 데이터, 원천 영상, 가공 데이터 셋, 학습 모델을 자율주행차량과 공공/민간 사이트에 공 개해줄 수 있다. 아울러 레이더/카메라 융합 서비스부는 상기 레이더 및 영상 융합 차량 데이터를 야간/전천후 환경에서도 정확도 높은 차량 인식률과 검출률을 갖는 차량 인식 데이터로 자율주행차량으로 제공하거나, 원천 영상 및 가 공 데이터 셋 및 학습 모델을 공공 및 민간 사이트를 통해 공개해줄 수 있다. 이상 상술한 본 발명에 따르면 다양한 영상 식별 기술을 활용하였고, 머신 러닝과 딥 러닝 알고리즘을 이용하여 객체를 인식하고 추적하는 시스템을 구축하였다. 또한, 영상 처리 기술과 차량 제어 시스템을 융합하여 자율주 행 차량의 안전성과 성능을 높였다. 결과적으로, 개발된 융복합 영상 식별시스템은 자율주행 차량의 안전성과 성능을 크게 향상시킬 것으로 기대되 며 이를 통해 자율주행 차량의 상용화가 더욱 가속화될 것으로 예상된다. 또한, 본 발명에서는 영상 처리 기술 과 차량 제어 시스템을 융합하는 방법을 제시하였으며, 이는 자율주행 분야에서 융합 기술의 중요성을 강조하는 데 기여할 것이다. 이상 본 발명자에 의해서 이루어진 발명을 상기 실시 예에 따라 구체적으로 설명하였지만, 본 발명은 상기 실시"}
{"patent_id": "10-2023-0129823", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되는 것은 아니고 그 요지를 이탈하지 않는 범위에서 여러 가지로 변경 가능한 것은 이 기술분야에서 통상의 지식을 가진 자에게 자명하다."}
{"patent_id": "10-2023-0129823", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 자율주행을 위한 융복합 영상 식별시스템의 전체 구성도, 도 2는 도 1에서 레이더로 수집되는 로우 데이터의 예시이고, 도 3은 레이더 로우 데이터에서 추출된 레이더 데이터의 예시이며, 도 4는 레이더 데이터의 객체 표출 예시이며, 도 5는 영상 데이터에서 이미지 추출 예시이며, 도 6은 Yolo_Mark를 이용한 이미지 라벨링 마킹 예시이며, 도 7은 XML파일의 예시이며, 도 8은 본 발명에 적용된 Yolo 신경망 모델 레이어 구성도이며, 도 9는 본 발명에서 레이더/카메라 매칭 알고리즘 예시이며, 도 10은 레이더/카메라 매칭부와 영상 객체 탐지부 간의 신호 전송 흐름이며, 도 11은 전송되는 프로토콜 패킷의 구조이며, 도 12는 필드 타입 종류이며, 도 13은 필드 타입 중 N의 설명이며, 도 14는 프레임 구조이고, 도 15는 OP코드와 응답 코드의 예시이며, 도 16은 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 데이터 필드의 예시이며, 도 17은 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 데이터 필드 예시이며, 도 18은 객체 식별 정보 요청 및 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 데이터 필드 의 예시이며, 도 19는 객체 식별 정보 요청에 대하여 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 데이터 필드 예 시이며, 도 20은 객체 식별 정보 전송 및 수신 응답 시 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 데이터 필드의 예시이며, 도 21은 객체 식별 정보 전송 및 수신 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 응답 데 이터 필드의 예시이며,도 22는 영상 객체 탐지 제어시작 전송 및 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 전 송 데이터 필드 예시이며, 도 23은 영상 객체 탐지 제어시작 전송 및 응답 시 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 전 송 데이터 필드 예시이며, 도 24는 통신 연결 유효성 검사 전송 및 응답 시 영상 객체 탐지부에서 레이더/카메라 매칭부로 전송되는 전송 데이터 필드 예시이며, 도 25는 통신 연결 유효성 검사 전송 및 응답 시 레이더/카메라 매칭부에서 영상 객체 탐지부로 전송되는 전송 데이터 필드 예시이다."}
