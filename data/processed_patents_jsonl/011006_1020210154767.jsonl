{"patent_id": "10-2021-0154767", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0068698", "출원번호": "10-2021-0154767", "발명의 명칭": "인공 신경망 모델을 구동하기 위한 연산 방법 및 연산 장치", "출원인": "삼성전자주식회사", "발명자": "유승주"}}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성된 인공 신경망 모델을 구동하기 위한연산 장치에 있어서,상기 베이직 블록의 구동을 위한 제1 연산과, 상기 트랜지션 블록의 구동을 위한 제2 연산을 수행하는 프로세서를 포함하고,상기 프로세서는입력 데이터에 대하여, 제1 배치 정규화(batch normalization)를 수행하고,상기 제1 배치 정규화된 입력 데이터를 양자화하고,상기 양자화된 입력 데이터에 기초하여, 컨볼루션 연산을 수행하고,상기 컨볼루션 연산 수행 결과 데이터에 대하여, 활성화 함수를 적용하여 출력 데이터를 결정하고,상기 출력 데이터에 대하여, 제2 배치 정규화를 수행하여 상기 제1 연산을 수행하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 베이직 블록은제1 배치 정규화 레이어;양자화 레이어;컨볼루션 레이어;활성 레이어; 및제2 배치 정규화 레이어를 포함하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 트랜지션 블록은풀링 레이어;채널 업스캐일링(channel upscaling) 레이어; 및제3 배치 정규화 레이어를 포함하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,공개특허 10-2023-0068698-3-상기 활성화 함수는ReLU 함수를 포함하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는상기 제1 배치 정규화된 입력 데이터에 대하여, 부호 함수(sign function)을 적용하여 상기 입력 데이터를 이진화하여 상기 제1 연산을 수행하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 프로세서는상기 제1 배치 정규화된 입력 데이터에 대하여, 스텝 함수(step function)을 적용하여 상기 입력 데이터를 양자화하여 상기 제1 연산을 수행하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 베이직 블록은상기 입력 데이터와 상기 제2 배치 정규화된 출력 데이터를 연결하는 레지듀얼 커넥션(residual connection)을포함하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는상기 베이직 블록의 출력 데이터에 대하여, 풀링(pooling)을 수행하고,상기 인공 신경망 모델의 채널을 복제하고,상기 채널이 복제된 인공 신경망 모델의 입력 데이터에 대하여, 제3 배치 정규화를 수행하여 상기 제2 연산을수행하는, 연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프로세서는상기 베이직 블록의 출력 데이터에 대하여, 평균 풀링(average pooling)을 수행하여 상기 제2 연산을 수행하는,연산 장치."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2023-0068698-4-하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성된 인공 신경망 모델을 구동하기 위한연산 방법에 있어서,상기 베이직 블록의 구동을 위한 제1 연산 방법은입력 데이터에 대하여, 제1 배치 정규화(batch normalization)를 수행하는 단계;상기 제1 배치 정규화된 입력 데이터를 양자화하는 단계;상기 양자화된 입력 데이터에 기초하여, 컨볼루션 연산을 수행하는 단계;상기 컨볼루션 연산 수행 결과 데이터에 대하여, 활성화 함수를 적용하여 출력 데이터를 결정하는 단계; 및상기 출력 데이터에 대하여, 제2 배치 정규화를 수행하는 단계를 포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 베이직 블록은제1 배치 정규화 레이어;양자화 레이어;컨볼루션 레이어;활성 레이어; 및제2 배치 정규화 레이어를 포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 트랜지션 블록은풀링 레이어;채널 업스캐일링(channel upscaling) 레이어; 및제3 배치 정규화 레이어를 포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 활성화 함수는ReLU 함수를 포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,공개특허 10-2023-0068698-5-상기 양자화하는 단계는상기 제1 배치 정규화된 입력 데이터에 대하여, 부호 함수(sing function)을 적용하여 상기 입력 데이터를 이진화하여 상기 제1 연산을 수행하는 단계를 포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 양자화하는 단계는상기 제1 배치 정규화된 입력 데이터에 대하여, 스텝 함수(step function)을 적용하여 상기 입력 데이터를 양자화하여 상기 제1 연산을 수행하는 단계를 포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 베이직 블록은상기 입력 데이터와 상기 제2 배치 정규화된 출력 데이터를 연결하는 레지듀얼 커넥션(residual connection)을포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 트랜지션 블록의 구동을 위한 제2 연산 방법은상기 베이직 블록의 출력 데이터에 대하여, 풀링(pooling)을 수행하는 단계;상기 인공 신경망 모델의 채널을 복제하는 단계; 및상기 채널이 복제된 인공 신경망 모델의 입력 데이터에 대하여, 제3 배치 정규화를 수행하여 상기 제2 연산을수행하는 단계를 포함하는, 연산 방법."}
{"patent_id": "10-2021-0154767", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "하드웨어와 결합되어 제10항 내지 제17항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2021-0154767", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 신경망 모델을 구동하기 위한 연산 방법 및 연산 장치가 개시된다. 일 실시예에 따른 하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성된 인공 신경망 모델을 구동하기 위한 연산 장치는 상기 베이 직 블록의 구동을 위한 제1 연산과, 상기 트랜지션 블록의 구동을 위한 제2 연산을 수행하는 프로세서를 포함하 고, 상기 프로세서는 입력 데이터에 대하여, 제1 배치 정규화(batch normalization)를 수행하고, 상기 제1 배치 정규화된 입력 데이터를 이진화(binarize)양자화하고, 상기 이진양자화된 입력 데이터에 기초하여, 컨볼루션 연 산을 수행하고, 상기 컨볼루션 연산 수행 결과 데이터에 대하여, 활성화 함수를 적용하여 출력 데이터를 결정하 고, 상기 출력 데이터에 대하여, 제2 배치 정규화를 수행하여 상기 제1 연산을 수행한다."}
{"patent_id": "10-2021-0154767", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성된 인공 신경망 모델을 구동하기 위한 연산 방법 및 연산 장치에 관한 것이다."}
{"patent_id": "10-2021-0154767", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 분야에서 각광받고 있는 컨볼루션 뉴럴 네트워크(Convolutional Neural Networks)은 기존의 인공지능 기술보다 압도적으로 우월한 성능을 보이며 나날이 다르게 발전하고 있다. 하지만 합성곱 인공 신경망은 보다 더 많은 데이터를 훈련해서 더 높은 성능을 내기 위해서는 보다 깊어지고 넓어져야 하는데, 이러한 현상이 진행 될수록 사용되는 모델의 크기가 커지고, 처리하는 데 필요한 연산이 늘어남에 따라 연산 시간이 늘어나게 되는 단점이 있다. 이러한 단점을 보완하고자, 컨볼루션 뉴럴 네트워크의 모델 크기를 줄이는 기법들이 제안되었다. 예를 들어, 합성곱 인공 신경망의 구조 자체를 슬림하게 설계(Lightweight)하거나, 인공 신경망의 가지 자체를 임의로 삭제 (Pruning)해서 훈련을 진행시키거나, 아니면 웨이트의 값을 더 적은 비트로 양자화(n-bit quantization)하는 기 법들이 있다."}
{"patent_id": "10-2021-0154767", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성된 인공 신경망 모델 을 구동하기 위한 연산 장치는 상기 베이직 블록의 구동을 위한 제1 연산과, 상기 트랜지션 블록의 구동을 위한 제2 연산을 수행하는 프로세서를 포함하고, 상기 프로세서는 입력 데이터에 대하여, 제1 배치 정규화(batch normalization)를 수행하고, 상기 제1 배치 정규화된 입력 데이터를 이진화(binarize)양자화하고, 상기 이진양 자화된 입력 데이터에 기초하여, 컨볼루션 연산을 수행하고, 상기 컨볼루션 연산 수행 결과 데이터에 대하여, 활성화 함수를 적용하여 출력 데이터를 결정하고, 상기 출력 데이터에 대하여, 제2 배치 정규화를 수행하여 상 기 제1 연산을 수행한다. 상기 베이직 블록은 제1 배치 정규화 레이어; 양자화 레이어; 컨볼루션 레이어; 활성 레이어; 및 제2 배치 정규 화 레이어를 포함할 수 있다. 상기 트랜지션 블록은 풀링 레이어; 채널 업스캐일링(channel upscaling) 레이어; 및 제3 배치 정규화 레이어를 포함할 수 있다. 상기 활성화 함수는 ReLU 함수를 포함할 수 있다. 상기 프로세서는 상기 제1 배치 정규화된 입력 데이터에 대하여, 부호 함수(sign function)을 적용하여 상기 입 력 데이터를 이진화하여 상기 제1 연산을 수행할 수 있다. 상기 프로세서는 상기 제1 배치 정규화된 입력 데이터에 대하여, 스텝 함수(step function)을 적용하여 상기 입 력 데이터를 양자화하여 상기 제1 연산을 수행할 수 있다. 상기 베이직 블록은 상기 입력 데이터와 상기 제2 배치 정규화된 출력 데이터를 연결하는 레지듀얼 커넥션 (residual connection)을 포함할 수 있다. 상기 프로세서는 상기 베이직 블록의 출력 데이터에 대하여, 풀링(pooling)을 수행하고, 상기 인공 신경망 모델 의 채널을 복제하고, 상기 채널이 복제된 인공 신경망 모델의 입력 데이터에 대하여, 제3 배치 정규화를 수행하 여 상기 제2 연산을 수행할 수 있다. 상기 프로세서는 상기 베이직 블록의 출력 데이터에 대하여, 평균 풀링(average pooling)을 수행하여 상기 제2 연산을 수행할 수 있다. 일 실시예에 따른 하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성된 인공 신경망 모델 을 구동하기 위한 연산 방법에 있어서, 상기 베이직 블록의 구동을 위한 제1 연산 방법은 입력 데이터에 대하여, 제1 배치 정규화(batch normalization)를 수행하는 단계; 상기 제1 배치 정규화된 입력 데이터를 양자 화하는 단계; 상기 양자화된 입력 데이터에 기초하여, 컨볼루션 연산을 수행하는 단계; 상기 컨볼루션 연산 수행 결과 데이터에 대하여, 활성화 함수를 적용하여 출력 데이터를 결정하는 단계; 및 상기 출력 데이터에 대하 여, 제2 배치 정규화를 수행하는 단계를 포함한다. 상기 베이직 블록은 제1 배치 정규화 레이어; 양자화 레이어; 컨볼루션 레이어; 활성 레이어; 및 제2 배치 정규 화 레이어를 포함할 수 있다. 상기 트랜지션 블록은 풀링 레이어; 채널 업스캐일링(channel upscaling) 레이어; 및 제3 배치 정규화 레이어를 포함할 수 있다. 상기 활성화 함수는 ReLU 함수를 포함할 수 있다. 상기 양자화하는 단계는 상기 제1 배치 정규화된 입력 데이터에 대하여, 부호 함수(sing function)을 적용하여 상기 입력 데이터를 이진화하여 상기 제1 연산을 수행하는 단계를 포함할 수 있다. 상기 양자화하는 단계는 상기 제1 배치 정규화된 입력 데이터에 대하여, 스텝 함수(step function)을 적용하여 상기 입력 데이터를 양자화하여 상기 제1 연산을 수행하는 단계를 포함할 수 있다. 상기 베이직 블록은 상기 입력 데이터와 상기 제2 배치 정규화된 출력 데이터를 연결하는 레지듀얼 커넥션 (residual connection)을 포함할 수 있다. 상기 트랜지션 블록의 구동을 위한 제2 연산 방법은 상기 베이직 블록의 출력 데이터에 대하여, 풀링(pooling) 을 수행하는 단계; 상기 인공 신경망 모델의 채널을 복제하는 단계; 및 상기 채널이 복제된 인공 신경망 모델의 입력 데이터에 대하여, 제3 배치 정규화를 수행하여 상기 제2 연산을 수행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0154767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면을 참 조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1a는 인공신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 딥러닝(Deep Learning) 등을 포함하는 인공지능(AI) 알고리즘은 인공신경망(Artificial Neural Network, ANN) 에 입력 데이터를 입력시키고, 컨볼루션 등의 연산을 통해 출력 데이터를 학습하는 것을 특징으로 한다. 인공신경망은 생물학적 뇌를 모델링한 컴퓨터 과학적 아키텍쳐(Computational Architecture)를 의미할 수 있다. 인공신경망 내에서, 뇌의 뉴런들에 해당되는 노드들은 서로 연결되어 있고, 입력 데이터를 처리하기 위하여 집합적으로 동작한다. 다양한 종류의 뉴럴 네트워크들을 예로 들면, 컨볼루션 뉴럴 네트워크 (Convolutional Neural Network, CNN), 회귀 뉴럴 네트워크(Recurrent Neural Network, RNN), 딥 빌리프 네트 워크(Deep Belief Network, DBN), 제한된 볼츠만 기계(Restricted Boltzman Machine, RBM) 방식 등이 있으나, 이에 제한되지 않는다. 피드-포워드(feed-forward) 뉴럴 네트워크에서, 뉴럴 네트워크의 뉴런들은 다른 뉴런들 과의 연결들(links)을 갖는다. 이와 같은 연결들은 뉴럴 네트워크를 통해, 한 방향으로, 예를 들어 순방향 (forward direction)으로 확장될 수 있다. 도 1a를 참조하면, 인공신경망에 입력 데이터가 입력되고, 하나 이상의 레이어(layer)를 포함하는 인공 신 경망(예를 들어, 컨볼루션 뉴럴 네트워크(Convolution Neural Network, CNN))를 통해 출력 데이터가 출력되는 구조가 도시된다. 인공신경망은 2개 이상의 레이어를 보유한 딥 뉴럴 네트워크(deep neural networ k)일 수 있다. 컨볼루션 뉴럴 네트워크는 입력 데이터로부터 테두리, 선 색 등과 같은 \"특징들(features)\"을 추출하기 위해 이용될 수 있다. 컨볼루션 뉴럴 네트워크는 복수의 레이어를 포함할 수 있다. 각각의 레이어는 데이 터를 수신할 수 있고, 해당 레이어에 입력되는 데이터를 처리하여 해당 레이어에서 출력되는 데이터를 생성할 수 있다. 레이어에서 출력되는 데이터는, 컨볼루션 뉴럴 네트워크에 입력된 이미지 또는 입력된 특징맵 (feature map)을 하나 이상의 필터(filter)의 웨이트(weight) 값과 컨볼루션 연산하여 생성한 특징맵일 수 있다. 컨볼루션 뉴럴 네트워크의 초기 레이어들은 입력으로부터 에지들 또는 그레디언트들과 같은 낮은 레 벨의 특징들을 추출하도록 동작될 수 있다. 컨볼루션 뉴럴 네트워크의 다음 레이어들은 이미지 내의 눈, 코 등과 같은 점진적으로 더 복잡한 특징들을 추출할 수 있다. 도 1b는 딥러닝 연산에서 입력으로 제공되는 입력 특징맵의 데이터와 필터를 설명하기 위한 도면이다. 도 1b를 참조하면, 입력 특징맵은 인공신경망에 입력되는 이미지의 픽셀 값 또는 수치 데이터의 집합일 수 있으나, 이에 제한되지 않는다. 도 1b에서 입력 특징맵은 인공신경망을 통해 학습할 대상이 되는 이미지 의 픽셀 값으로 정의될 수 있다. 예를 들어, 입력 특징맵은 256×256의 픽셀과 K의 깊이(depth)를 가질 수 있다. 그러나, 상기 값은 예시적인 것이고, 입력 특징맵의 픽셀 크기가 상기 예시로 한정되는 것은 아 니다. 필터(110-1 내지 110-n)는 N개로 형성될 수 있다. 복수의 필터(110-1 내지 110-n) 각각은 n by n(n×n)의 웨 이트(weight) 값을 포함할 수 있다. 예를 들어, 복수의 필터(110-1 내지 110-n) 각각은 3×3의 픽셀과 K의 깊 이값을 가질 수 있다. 그러나, 상기 필터의 크기는 예시적인 것이고, 복수의 필터(110-1 내지 110-n) 각각의 크기가 상기 예시로 한정되는 것은 아니다.도 1c는 딥러닝 기반에서 컨볼루션 연산을 수행하는 과정을 설명하기 위한 도면이다. 도 1c를 참조하면, 인공신경망에서 컨볼루션 연산을 수행하는 과정은, 각각의 레이어에서 입력 특징맵과 필터와의 곱셈 및 덧셈 연산을 하여 출력 값을 생성하고, 출력 값을 누적하여 합산함으로써, 출력 특징맵 을 생성하는 과정을 의미할 수 있다. 컨볼루션 연산 수행 과정은, 현재 레이어에서 입력 특징맵의 좌측 상단으로부터 우측 하단까지 일정한 크 기, 즉 n×n 크기의 필터를 적용하여 곱셈 및 덧셈 연산을 수행하는 과정이다. 이하에서는, 필터의 크기가 3×3인 경우에 컨볼루션 연산을 수행하는 과정을 설명하기로 한다. 예를 들어, 먼저 입력 특징맵의 좌측 상단 제1 영역에서 3×3, 즉 제1 방향으로 3개의 데이터와 제2 방향으로 3개의 데이터를 포함한 총 9개의 데이터(x11 내지 x33)를 각각 필터의 웨이트 값(weight)(w11 내 지 w33)과 곱하는 연산을 수행한다. 이후, 곱셈 연산의 출력 값, 즉 x11*w11, x12*w12, x13*w13, x21*w21, x22*w22, x23*w23, x31*w31, x32*w32, x33*w33을 모두 누적하여 합산하면 출력 특징맵의 제1-1 출력 데이 터(y11)가 생성된다. 이후, 입력 특징맵의 좌측 상단의 제1 영역에서 제2 영역으로 데이터의 단위만큼 이동하면서 연 산한다. 이 때, 컨볼루션 연산 과정에서 입력 특징맵 내의 데이터가 이동하는 개수를 스트라이드(strid e)라고 하며, 스트라이드의 크기에 따라 생성되는 출력 특징맵의 크기가 결정될 수 있다. 예를 들어, 스 트라이드가 1인 경우, 제2 영역에 포함된 총 9개의 입력 데이터(x12 내지 x34)를 필터의 웨이트 값 (w11 내지 w33)과 곱하는 연산을 수행하고, 곱셈 연산의 출력 값인 x12*w11, x13*w12, x14*w13, x22*w21, x23*w22, x24*w23, x32*w31, x33*w32, x34*w33을 모두 누적하여 합산하면 출력 특징맵의 제1-2 출력 데이 터(y12)가 생성된다. 도 2는 일 실시예에 따른 인공 신경망 모델의 구조를 설명하기 위한 도면이다. 대표적인 경량 뉴럴 네트워크의 일종으로 이진 인공신경망이 있다. 이진 인공신경망은 기존 인공신경망의 속도 를 대폭적으로 상승시키고 인공신경망 모델의 메모리 용량을 대폭 줄일 수 있다는 점에서 획기적인 방식이나, 기존의 부동소수점인 웨이트와 활성화 함수를 -1과 1로 표현하기 때문에 정보의 손실이 발생한다는 단점이 있다. 이러한 정보 손실은 결과적으로 정확도 저하로 이어지며, 사물을 인식하거나 물건을 탐지하는 데 있어 성능 저하를 가져올 수 있다. 예를 들어, 1.4와 0.2 둘 다 양수이기 때문에 1로 매핑하게되는 경우, 크기가 7배나 차이나는 두 값들이 같은 값으로 매핑된다면 양자화 에러(quantization error)가 매우 커질 수 있다. 이에, 종래 이진 인공 신경망에서 는 스케일 팩터(scale factor)를 이용하여 데이터들의 크기(magnitude)를 고려한 이진 양자화를 수행하였다. 그러나, 스케일 팩터 역시 학습을 통해 결정해야한다는 제한이 있다. 나아가, 종래 이진 인공 신경망의 경우 스케일 인베리언트 특징(scale-invariant feature)를 사용하기 때문에 깊이에 확장 가능하지 않는 문제가 있을 수 있다. 일 실시예에 따른 인공 신경망 모델은 깊이에 확장 가능하고, 스케일 팩터를 사용하지 않으면서, 정보 손실을 줄일 수 있다. 도 2를 참조하면, 일 실시예에 따른 인공 신경망 모델을 설명하기 위한 예시가 도시된다. 일 실시예에 따른 인 공 신경망 모델은 하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성될 수 있다. 보다 구체적으로, 인공 신경망 모델은 복수의 단위 블록들로 구성될 수 있고, 단위 블록은 하나 이상의 베이직 블록과 하나 이상의 트랜지션 블록의 조합으로 구성될 수 있다. 다만, 도 2에는 인공 신경망 모델이 4개의 단 위 블록으로 구성되고, 단위 블록은 3개의 베이직 블록과 하나의 트랜지션 블록으로 구성된 것으로 도시되어 있 으나, 이는 일 례에 불과할 뿐, 인공 신경망 모델을 구성하는 단위 블록과 베이직 블록 및 트랜지션 블록의 수 는 변경될 수 있다. 아래에서 도 3을 참조하여, 베이직 블록의 상세한 동작 방법이 설명되고, 도 4를 참조하여 트랜지션 블록의 상 세한 동작 방법이 설명된다.도 3은 일 실시예에 따른 베이직 블록의 동작 방법을 설명하기 위한 도면이다. 도 3을 참조하면, 일 실시예에 따른 베이직 블록은 제1 배치 정규화 레이어(batch normalization layer), 양자화 레이어, 컨볼루션 레이어, 활성 레이어 및 제2 배치 정규화 레이어를 포함할 수 있 다. 일 실시예에 따른 제1 배치 정규화 레이어는 입력 데이터의 분포를 안정화 시킬 수 있다. 일 실시예에 따 른 입력 데이터는 입력 특징맵 및 웨이트 중 적어도 하나를 포함할 수 있다. 보다 구체적으로, 일반적인 그래디언트 디센트(gradient descent)에서는 그래디언트를 한번 업데이트 하기 위하 여 모든 학습 데이터를 사용한다. 즉, 학습 데이터 전부에 대한 그래디언트를 구하고, 그 모든 그래디언트를 평균하여 한번에 인공 신경망 모델을 업데이트 한다. 그러나, 이런 방식에 따르면 대용량의 데이터를 한번에 처리하기 어렵기 때문에, 데이터를 배치 단위로 나눠서 학습을 할 수 있다. 배치 단위로 학습을 하게 되면, 학습 과정에서 레이어 별로 입력의 데이터 분포가 달라지는 인터벌 코베리언트 시프트(interval covariant shift)가 발생할 수 있다. 즉, 배치 별로 데이터가 상이하게 될 수 있는데, 배치 정규화 레이어를 사용하여 해당 문제를 해결할 수 있다. 일 실시예에 따른 배치 정규화는 각 배치 단위 별로 데이터가 다양한 분포를 갖더라도, 각 배치 별로 평균과 분 산을 이용하여 정규화하는 것을 의미하고, 배치 정규화 레이어는 배치 정규화를 수행하는 레이어를 의미할 수 있다. 일 실시예에 따른 양자화 레이어는 제1 배치 정규화된 입력 데이터를 양자화할 수 있다. 일 실시예에 따 른 제1 배치 정규화된 입력 데이터는 제1 배치 정규화 레이어를 통해 안정화된 입력 데이터를 의미할 수 있다. 양자화 레이어는 제1 배치 정규화된 입력 데이터에 대하여, 부호 함수(sign function)을 적용하여 입력 데 이터를 이진화할 수 있다. 보다 구체적으로, 양제화 레이어는 제1 배치 정규화된 입력 데이터에 부호 함 수를 적용하여, 제1 배치 정규화된 입력 데이터가 양수일 경우 1로 매핑하고, 제1 배치 정규화된 입력 데이터가 음수일 경우 -1로 매핑할 수 있다. 다른 실시예에서, 양자화 레이어는 제1 배치 정규화된 입력 데이터에 대하여, 스텝 함수(step function)을 적용하여 입력 데이터를 양자화할 수도 있다. 일 실시예에 따른 컨볼루션 레이어는 도 1c를 참조하여 설명한 컨볼루션 연산을 수행하는 레이어일 수 있 다. 예를 들어, 컨볼루션 레이어는 3X3 컨볼루션 레이어일 수 있다. 일 실시예에 따른 활성 레이어는 활성화 함수(Activation function)를 이용하여 입력된 데이터의 가중 합 을 출력 데이터로 변환하는 레이어일 수 있다. 예를 들어, 활성 레이어는 ReLU(Rectified Linear Unit) 함수를 사용하여, 입력된 데이터가 0보다 작으면 0을, 0보다 크면 입력된 데이터 그대로(선형 함수) 출력할 수 있다. 일 실시예에 따른 제2 배치 정규화 레이어는 출력 데이터에 대하여, 제2 배치 정규화를 수행할 수 있다. 일 실시예에 따른 베이직 블록은 제2 배치 정규화 레이어를 추가로 사용함으로써, 스케일 팩터 없이도 출 력 데이터의 분포를 안정적으로 만들 수 있다. 나아가, 제2 배치 정규화 레이어는 출력 데이터의 분포를 0 중심(zere-centered)으로 조정할 수 있다. 일 실시예에 따른 베이직 블록은 입력 데이터와 제2 배치 정규화된 출력 데이터를 연결하는 레지듀얼 커넥션 (residual connection)을 포함할 수 있다. 일 실시예에 따른 레지듀얼 커넥션은 스킵 커넥션(skip connection), 숏컷 커넥션(shortcut connection)으로 지칭될 수도 있다. 베이직 블록은 레지듀얼 커넥션을 통 해 입력 데이터는 그대로 가져오고, 나머지 잔여 정보만 추가적으로 학습을 할 수 있다. 도 4는 일 실시예에 따른 트랜지션 블록의 동작 방법을 설명하기 위한 도면이다. 도 4를 참조하면, 일 실시예에 따른 트랜지션 블록은 풀링 레이어(pooling layer), 채널 업스캐일링 (channel upscaling) 레이어 및 제3 배치 정규화 레이어를 포함할 수 있다. 높은 차원을 다루려면 그 차원을 다룰 수 있는 많은수의 파라미터들을 필요로 할 수 있다. 그러나, 파라미터가 너무 많아지면 학습 시 오버 피팅(over fitting)이 발생할 수 있다. 따라서 필터에 사용된 파라미터 수를 줄여서 차원을 감소시킬 방법이 필요하다. 일 실시예에 따른 베이직 블록은 데이터의 크기를 변화시키지 않기 때문에, 인공 신경망 모델이 스케일 인베리 언트하기 위해서는 데이터의 크기를 줄여줄 수 있는 레이어가 필요하다. 일 실시예에 따른 풀링 레이어는 베이직 블록의 출력 데이터의 너비(width)와 높이(height)에 대해 다운샘 플링(downsampling) 수행할 수 있다. 예를 들어, 일 실시예에 따른 풀링 레이어는 평균 풀링(average pooling)을 수행하여 정해진 크기 안의 값들의 평균을 뽑아낼 수 있다. 일 실시예에 따른 채널 업스캐일링(channel upscaling) 레이어는 채널을 미리 정해진 배수로 복제하는 레 이어로, 채널 복제(duplicate) 레이어로 지칭될 수도 있다. 일 실시예에 따른 트랜지션 블록은 제3 배치 정규화 레이어를 통해 분산을 1로 재설정할 수 있다. 도 5은 일 실시예에 따른 전자 장치를 설명하기 위한 블록도이다. 도 5을 참조하면, 일 실시예에 따른 연산 장치는 프로세서, 메모리 및 통신 인터페이스 포 함할 수 있다. 프로세서, 메모리 및 통신 인터페이스는 통신 버스를 통해 서로 통신할 수 있다. 일 실시예에 따른 프로세서는 베이직 블록의 구동을 위한 제1 연산과, 트랜지션 블록의 구동을 위한 제2 연산을 수행한다. 제1 연산은 입력 데이터 에 대하여, 제1 배치 정규화(batch normalization)를 수행하는 단계, 제1 배치 정규화된 입력 데이터를 이진화(binarize)양자화하는 단계, 이진양자화된 입력 데이터에 기초하 여, 컨볼루션 연산을 수행하는 단계, 컨볼루션 연산 수행 결과 데이터에 대하여, 활성화 함수를 적용하여 출력 데이터를 결정하는 단계 및 출력 데이터에 대하여, 제2 배치 정규화를 수행하는 단계를 포함할 수 있다. 일 실시예에 따른 제2 연산은 베이직 블록의 출력 데이터에 대하여, 풀링(pooling)을 수행하는 단계, 인공 신경 망 모델의 채널을 복제하는 단계, 채널이 복제된 인공 신경망 모델의 입력 데이터에 대하여, 제3 배치 정규화를 수행하는 단계를 포함할 수 있다. 메모리는 휘발성 메모리 또는 비 휘발성 메모리일 수 있고, 프로세서는 프로그램을 실행하고, 연산 장치를 제어할 수 있다. 프로세서에 의하여 실행되는 프로그램 코드는 메모리에 저장될 수 있 다. 전자 장치는 입출력 장치(미도시)를 통하여 외부 장치(예를 들어, 퍼스널 컴퓨터 또는 네트워크)에 연결되고, 데이터를 교환할 수 있다. 연산 장치는 스마트 폰, 테블릿 컴퓨터, 랩톱 컴퓨터, 데스크톱 컴 퓨터, 텔레비전, 웨어러블 장치, 보안 시스템, 스마트 홈 시스템 등 다양한 컴퓨팅 장치 및/또는 시스템에 탑재 될 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2021-0154767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtualequipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2021-0154767", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2021-0154767", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 인공신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 도 1b는 딥러닝 연산에서 입력으로 제공되는 입력 특징맵의 데이터와 필터를 설명하기 위한 도면이다. 도 1c는 딥러닝 기반에서 컨볼루션 연산을 수행하는 과정을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 인공 신경망 모델의 구조를 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 베이직 블록의 동작 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 트랜지션 블록의 동작 방법을 설명하기 위한 도면이다. 도 5은 일 실시예에 따른 전자 장치를 설명하기 위한 블록도이다."}
