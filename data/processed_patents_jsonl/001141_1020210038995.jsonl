{"patent_id": "10-2021-0038995", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0134811", "출원번호": "10-2021-0038995", "발명의 명칭": "인공지능 웨어러블 플랫폼의 동작 방법", "출원인": "한국전자통신연구원", "발명자": "박형준"}}
{"patent_id": "10-2021-0038995", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "웨어러블 디바이스, 스마트 단말, 및 인공지능 서버를 포함하는 인공지능 웨어러블 플랫폼의 동작 방법에 있어서,상기 웨어러블 디바이스에 의해, 음성 명령을 수집하는 단계;상기 스마트 단말에 의해, 상기 음성 명령을 상기 웨어러블 디바이스로부터 상기 인공지능 서버로 전달하는 단계;상기 웨어러블 디바이스에 의해, 시각 정보를 수집하는 단계;상기 스마트 단말에 의해, 상기 시각 정보를 상기 웨어러블 디바이스로부터 상기 인공지능 서버로 전달하는 단계;상기 인공지능 서버에 의해, 상기 음성 명령에 따라 상기 시각 정보에 대한 사물 인식 또는 문자 인식을 수행하는 단계;상기 스마트 단말에 의해, 상기 사물 인식의 결과 또는 상기 문자 인식의 결과를 음성 합성하는 단계; 및상기 웨어러블 디바이스에 의해, 상기 음성 합성의 결과를 사용자에게 음성으로 출력하는 단계를 포함하고, 상기 웨어러블 디바이스에 의해 시각 정보를 수집하고, 상기 스마트 단말에 의해 상기 시각 정보를 상기 웨어러블 디바이스로부터 상기 인공지능 서버로 전달하고, 상기 인공지능 서버에 의해 상기 시각 정보를 기반으로 사용자의 위험이 감지된 경우: 상기 인공지능 서버에 의해 경고 신호를 생성하는 단계; 상기 스마트 단말에 의해, 상기 경고 신호를 상기 웨어러블 디바이스로 전달하는 단계; 및상기 웨어러블 디바이스에 의해, 상기 경고 신호에 응답하여, 상기 사용자에게 음성 또는 진동으로 경고하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2021-0038995", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 웨어러블 디바이스, 스마트 단말, 및 인공지능 서버를 포함하는 인공지능 웨어러블 플랫폼의 동작 방 법에 관한 것이다. 본 개시의 인공지능 웨어러블 플랫폼의 동작 방법은 웨어러블 디바이스에 의해, 음성 명령을 수집하는 단계, 스마트 단말에 의해, 음성 명령을 웨어러블 디바이스로부터 인공지능 서버로 전달하는 단계, 웨 (뒷면에 계속)"}
{"patent_id": "10-2021-0038995", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 웨어러블 플랫폼의 동작 방법에 관한 것이다. 상세하게는, 본 개시는 카메라와 인공지능 서버를 결합 하여 시각장애인의 생활 편의와 안전을 지원하는 인공지능 웨어러블 플랫폼의 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0038995", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 시각장애인들은 신체적인 제약으로 인해 주변 상황 및 사물에 대한 인지력이 낮기 때문에, 대다수의 시각장애인들은 점자 보도블록, 지팡이, 또는 안내견에 의존하여 야외 활동을 해왔다. 하지만, 현존하는 시각장 애인을 위한 장비 및 사회 기반 시설은 시각장애인들에게 많은 정보를 제공하지 못하는 한계가 있다. 예를 들어, 초음파 센서를 이용한 보행 보조기기는 장애물의 유무를 감지할 수는 있지만, 주변 상황을 판단할 수는 없다. 시각장애인용 GPS(global positioning system)는 전체적인 이동경로를 안내해 주지만, 좁은 공간에서 정 확한 보행 경로를 안내할 정도로 해상도가 높지 않다."}
{"patent_id": "10-2021-0038995", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 기술적 과제를 해결하기 위한 것이다. 본 개시는 웨어러블 디바이스, 스마트 단말 및 인공지 능 서버를 포함하는, 시각장애인의 생활 편의와 안전을 지원하는 인공지능 웨어러블 플랫폼의 동작 방법을 제공할 수 있다."}
{"patent_id": "10-2021-0038995", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 인공지능 웨어러블 플랫폼은, 웨어러블 디바이스, 스마트 단말, 및 인공지능 서버를 포함할 수 있다. 본 개시의 인공지능 웨어러블 플랫폼의 동작 방법은 상기 웨어러블 디바이스에 의해, 음성 명령을 수집하는 단 계, 상기 스마트 단말에 의해, 상기 음성 명령을 상기 웨어러블 디바이스로부터 상기 인공지능 서버로 전달하는 단계, 상기 웨어러블 디바이스에 의해, 시각 정보를 수집하는 단계, 상기 스마트 단말에 의해, 상기 시각 정보 를 상기 웨어러블 디바이스로부터 상기 인공지능 서버로 전달하는 단계, 상기 인공지능 서버에 의해, 상기 음성 명령에 따라 상기 시각 정보에 대한 사물 인식 또는 문자 인식을 수행하는 단계, 상기 스마트 단말에 의해, 상 기 사물 인식의 결과 또는 상기 문자 인식의 결과를 음성 합성하는 단계, 및 상기 웨어러블 디바이스에 의해, 상기 음성 합성의 결과를 사용자에게 음성으로 출력하는 단계를 포함하고, 상기 웨어러블 디바이스에 의해 시각 정보를 수집하고, 상기 스마트 단말에 의해 상기 시각 정보를 상기 웨어러블 디바이스로부터 상기 인공지능 서 버로 전달하고, 상기 인공지능 서버에 의해 상기 시각 정보를 기반으로 사용자의 위험이 감지된 경우, 상기 인 공지능 서버에 의해 경고 신호를 생성하는 단계, 상기 스마트 단말에 의해, 상기 경고 신호를 상기 웨어러블 디 바이스로 전달하는 단계, 및 상기 웨어러블 디바이스에 의해, 상기 경고 신호에 응답하여, 상기 사용자에게 음 성 또는 진동으로 경고하는 단계를 더 포함한다."}
{"patent_id": "10-2021-0038995", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 시각장애인의 생활 편의 및 안전성을 향상시키는 인공지능 웨어러블 플랫폼의 동작 방법이 제공된다."}
{"patent_id": "10-2021-0038995", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 본 개시의 기술 분야에서 통상의 지식을 가진 자가 본 개시를 용이하게 실시할 수 있을 정도로, 본 개시의 실시 예들이 명확하고 상세하게 기재될 것이다. 상세한 구성들 및 구조들과 같은 세부적인 사항들은 단 순히 본 개시의 실시 예들의 전반적인 이해를 돕기 위하여 제공된다. 그러므로 본 개시의 기술적 사상 및 범위 로부터의 벗어남 없이 본문에 기재된 실시 예들의 변형들은 당업자에 의해 수행될 수 있다. 더욱이, 잘 알려진 기능들 및 구조들에 대한 설명들은 명확성 및 간결성을 위하여 생략된다. 상세한 설명에서 사용되는 부, 모듈(module) 등의 용어를 참조하여 설명되는 구성 요소들은 소프트웨어, 또는 하드웨어, 또는 그것들의 조합의 형태로 구현될 수 있다. 본문에서 사용된 용어들은 본 개시의 기능들을 고려하여 정의된 용어들이며, 특정 기능에 한정되지 않는다. 용 어들의 정의는 상세한 설명에 기재된 사항을 기반으로 결정될 수 있다. 이하의 도면들 또는 상세한 설명에서의 모듈들은 도면에 도시되거나 또는 상세한 설명에 기재된 구성 요소 이외 에 다른 것들과 연결될 수 있다. 모듈들 또는 구성 요소들 사이의 연결은 각각 직접적 또는 비직접적일 수 있다. 모듈들 또는 구성 요소들 사이의 연결은 각각 통신에 의한 연결이거나 또는 물리적인 접속일 수 있다. 도 1은 본 개시의 실시 예에 따른 인공지능 웨어러블 플랫폼을 보여주는 블록도이다. 도 1을 참조하면, 인공지 능 웨어러블 플랫폼은 웨어러블 디바이스, 스마트 단말, 및 인공지능 서버를 포함할 수 있 다. 웨어러블 디바이스는 제어부, 하드웨어 인터페이스, 전원 모듈, 카메라 모듈, 음성 모듈, 및 통신 모듈을 포함할 수 있다. 제어부는 하드웨어 인터페이스, 전원 모듈, 카메라 모듈, 음성 모듈, 및 통신 모듈 의 동작을 제어할 수 있다. 예를 들어, 제어부는 8051, AVR(advanced virtual reduced instruction set computer), PIC(peripheral interface controller), ARM(advanced reduced instruction set computer machine) 등을 기반으로 하는 마이크로컨트롤러(MCU; micro controller unit)를 포함할 수 있다. 하드웨어 인터페이스는 전원 버튼, 음량 조절 버튼, 및 비상 알림 버튼 등을 포함할 수 있다. 하드웨어 인 터페이스는 사용자에게 경고 등을 전달하기 위한 진동 모듈을 더 포함할 수 있다. 예를 들어, 하드웨 어 인터페이스에 포함된 진동 모듈은, 사용자의 위험이 감지되면 진동으로 사용자에게 경고할 수 있다. 전원 모듈은 제어부, 하드웨어 인터페이스, 카메라 모듈, 음성 모듈, 및 통신 모듈 에 전원을 제공할 수 있다. 예를 들어, 전원 모듈은 배터리 팩을 포함할 수 있다. 배터리 팩은 유선 또는 무선으로 충전될 수 있다. 카메라 모듈은 시각 정보를 수집할 수 있다. 예를 들어, 카메라 모듈은 사용자의 설정에 따라, 일시적 또는 상시적으로 시각 정보를 수집할 수 있다. 카메라 모듈을 통해 수집된 정보는, 통신 모듈(11 6)을 통해 스마트 단말을 경유하여 인공지능 서버로 전달될 수 있다. 음성 모듈은 마이크 및 스피커를 포함하는 다양한 형태로 구현될 수 있다. 마이크는 사용자의 음성을 수집할 수 있다. 스피커는 인공지능 서버의 처리 결과를 사용자에게 출력할 수 있다. 예를 들어, 마 이크는 사용자의 음성을 통신 모듈을 통해, 스마트 단말로 전달할 수 있다. 스피커는 인공지능 서버의 처리 결과를 음성으로 사용자에게 안내할 수 있다. 통신 모듈은 웨어러블 디바이스에서 수집된 정보를 스마트 단말로 전송하고, 스마트 단말 로부터 인공지능 서버의 처리 결과를 수신할 수 있다. 웨어러블 디바이스는 스마트 단말을 경유하여 인공지능 서버와 통신할 수 있다. 또는 웨어러블 디바이스는 스마트 단말을 경유하지 않고, 인공지능 서버와 직접 통신할 수 있다. 이 경우, 웨 어러블 디바이스는 스마트 단말의 일부 기능을 직접 수행하도록 구성될 수 있다. 예를 들어, 웨어러 블 디바이스는 인공지능 서버와의 통신, 정보 압축, 서비스 시나리오 설정 등의 기능들을 수행하도록 구성될 수 있다. 웨어러블 디바이스의 구조는 도 2를 참조하여 더욱 상세하게 설명된다. 스마트 단말은 스마트 폰, 스마트 워치 등과 같은 전자 통신 장비일수 있다. 스마트 단말은 통신부 , 데이터부, 및 서비스부를 포함할 수 있다. 통신부, 데이터부, 및 서비스부 각각은 하드웨어 또는 소프트웨어 방식으로 구현될 수 있다. 예를 들어, 통신부, 데이터부, 및 서비 스부 각각은 스마트 단말과 호환되는 어플리케이션을 통해 구현될 수 있다. 통신부는, 웨어러블 디바이스 또는 인공지능 서버와 통신할 수 있다. 예를 들어, 통신부는 웨어러블 디바이스로부터 수신된 정보를 인공지능 서버로 전달하거나, 인공지능 서버로부터 인 공지능 서버의 처리 결과를 수신할 수 있다. 일 실시 예에서, 통신부는 음성 합성 기능(TTS; text to speech)을 수행할 수 있다. 스마트 단말은 음성 합성 기능(TTS; text to speech)을 통해 인공지능 서버의 처리 결과를 사용자에게 음성으로 안 내할 수 있다. 예를 들어, 스마트 단말은 인공지능 서버로부터 인공지능 서버의 처리 결과를 텍 스트 형태로 수신할 수 있다. 스마트 단말은 음성 합성(TTS; text to speech)을 통해, 텍스트 형태의 인공 지능 서버의 처리 결과를 음성 신호로 변환하고, 변환된 음성 신호를 웨어러블 디바이스로 전달할 수 있다. 이 경우, 웨어러블 디바이스가 복잡한 연산을 처리하지 않아도 되므로, 웨어러블 디바이스의 전력소모가 감소될 수 있다. 데이터부는 웨어러블 디바이스로부터 수신된 정보를 저장 또는 압축할 수 있다. 예를 들어, 데이터부 는 웨어러블 디바이스로부터 수신된 정보를 일시적으로 저장하거나 압축할 수 있다. 스마트 단말 은 압축된 정보를 인공지능 서버로 전송할 수 있다. 이 경우, 무선 데이터망 사용량의 감소로 인해 통신 비용이 절약될 수 있다. 일 실시 예에서, 사용자의 비상 호출이 있는 경우, 스마트 단말에 일시 적으로 저장된 정보는 보호자에게 전송될 수 있다. 서비스부는 서비스 시나리오를 포함할 수 있다. 서비스부는 서비스 시나리오에 따라, 인공지능 웨어 러블 플랫폼의 동작을 변경할 수 있다. 서비스 시나리오는 사용자의 요구에 따라 다르게 설정될 수 있다. 일 실시 예에서, 사용자는 서비스 시나리오의 수정을 통해, 인공지능 서버가 사용자에게 안내할 정보의 범위를 한정할 수 있다. 예를 들어, 인공지능 서버가 문자 인식(OCR; optical character recognition) 또는 사물 인식을 하는 경우, 사용자에게 안내할 사물 또는 문자의 범위를 제한할 수 있다. 일 실시 예에서, 사용자는 하드웨어 인터페이스 또는 스마트 단말의 어플리케이션 등을 통해 서 비스 시나리오를 변경하여, 인공지능 웨어러블 플랫폼의 동작을 변경할 수 있다. 예를 들어, 인공지능 웨 어러블 플랫폼은 사용자의 일시적인 요구에 의해 문자 인식(OCR; optical character recognition), 사물 인식 등과 같은 동작들을 수행할 수 있다. 사용자는 인공지능 웨어러블 플랫폼이 상시적으로 사 물 인식을 수행하여, 위험을 감지하도록, 서비스 시나리오를 변경할 수 있다. 서비스 시나리오의 변경에 따른 인공지능 웨어러블 플랫폼의 동작은 도 3 및 도 4를 참조하여 더욱 상세하게 설명된다. 인공지능 서버는 인터넷 또는 웹 상에서 운영될 수 있다. 인공지능 서버는 스마트 단말로부터 수신된 정보를 저장할 수 있다. 인공지능 서버는 서비스 인터페이스부, 서비스 프로세스부, 데 이터 처리부, 및 인공지능 엔진부를 포함할 수 있다. 서비스 인터페이스부는 스마트 단말과 통신할 수 있다. 예를 들어, 서비스 인터페이스부는 스마 트 단말의 통신부로부터 정보를 수신하거나, 스마트 단말의 통신부로 정보를 전송할 수 있 다. 예를 들어, 서비스 인터페이스부는 스마트 단말의 통신부로부터 서비스 시나리오, 음성 정 보, 시각 정보 등을 수신할 수 있다. 서비스 인터페이스부는 스마트 단말의 통신부로 문자 인식 (OCR; optical character recognition) 결과, 사물 인식 결과, 경고 신호, 시각 정보 요청 신호 등을 전송할 수 있다. 서비스 프로세스부는 스마트 단말로부터 제공받은 서비스 시나리오에 따른 동작을 수행한다. 예를 들 어, 서비스 프로세스부는 스마트 단말로부터 서비스 시나리오를 수신할 수 있다. 일 실시 예에서, 서비스 시나리오는 스마트 단말에 의해 서비스가 변경된 이후, 웨어러블 디바이스의 초기 동작에서, 스마트 단말로부터 제공될 수 있다. 이 경우, 서비스 시나리오가 변경되기 전까지, 서비스 프로세스부는 서비스 시나리오에 따라, 사용자가 요구하는 정보만을 제공할 수 있다. 간결한 설명을 위하여, 앞서 설명된 서비스 시나리오에 대한 설명은 생략된다. 데이터 처리부는 스마트 단말로부터 수신된 시각 정보 또는 음성 정보를 일시적으로 저장하거나, 압 축된 정보를 압축 해제할 수 있다. 예를 들어, 데이터 처리부는 스마트 단말로부터 압축된 음성 또는 압축된 시각 정보를 수신할 수 있다. 데이터 처리부는 압축된 정보를 압축 해제하고, 인공지능 엔진부 로 전달할 수 있다. 인공지능 엔진부는 웨어러블 디바이스로부터 수신된 정보를 기반으로, 사물 인식 기능, 문자 인식 기 능(OCR; optical character recognition), 및 음성 인식 기능(STT; speech to text) 중 적어도 하나 이상의 기 능을 수행할 수 있다. 예를 들어, 사용자로부터 음성이 수신된 경우, 인공지능 엔진부는 음성 인식 기능(STT; speech to text)을 통해, 수신된 음성을 텍스트 형태로 변환하고, 서비스 시나리오에 따라 명령을 수 행할 수 있다. 일 실시 예에서, 인공지능 엔진부는 웨어러블 디바이스의 카메라 모듈에서 수집된 정보를 기반 으로 사물 인식 또는 문자 인식(OCR; optical character recognition)을 수행할 수 있다. 사물 인식 또는 문자 인식(OCR; optical character recognition) 처리 결과는 텍스트 형태로 스마트 단말로 제공된다. 스마트 단말은 수신된 텍스트 형태의 사물 인식 결과 또는 문자 인식(OCR; optical character recognition) 결과 를, 음성 합성 기능(TTS; text to speech)을 통해 웨어러블 디바이스에 오디오 형태로 변환하여 전달할 수 있다. 웨어러블 디바이스는 수신된 사물 인식 결과 또는 문자 인식(OCR; optical character recognition) 결과를, 사용자에게 오디오 형태로 출력할 수 있다. 일 실시 예에서, 인공지능 엔진부는 사물 인식 기능을 통해, 웨어러블 디바이스의 카메라 모듈 에서 수집된 정보를 기반으로, 사용자에게 전방의 물체 또는 위험 요소를 안내할 수 있다. 예를 들어, 인 공지능 엔진부에서 사물 인식 기능을 통해 사용자에게 차량 접근, 낙상 등의 위험이 있다고 인식한 경우, 인공지능 서버는 스마트 단말을 경유하여 웨어러블 디바이스에 위험 신호를 전달할 수 있다. 이 경우 웨어러블 디바이스는 소리 또는 진동으로 사용자에게 경고할 수 있다. 인공지능 웨어러블 플랫폼의 동작은 도 3 및 도 4를 참조하여 더욱 상세하게 후술된다. 도 2는 도 1의 웨어러블 디바이스를 보여주는 사시도이다. 도 1 및 도 2를 참조하면, 웨어러블 디바이스는 제어부, 하드웨어 인터페이스, 전원모듈, 카메라 모듈, 음성 모듈, 및 통신 모듈 을 포함할 수 있다. 간결한 설명을 위해, 앞서 설명된 구성 요소들에 대한 상세한 설명은 생략된다. 웨어러블 디바이스의 일단에는 카메라 모듈이 포함될 수 있다. 웨어러블 디바이스의 타단에는 음성 모듈이 포함될 수 있다. 웨어러블 디바이스의 중앙에는 제어부와, 전원 모듈, 통신 모듈 등이 포함될 수 있다. 웨어러블 디바이스에는 하드웨어 인터페이스가 더 포함될 수 있다. 웨어러블 디바이스는 통신 모듈을 통해, 유선 또는 무선으로 스마트 단말과 연결될 수 있다. 예 를 들어, 웨어러블 디바이스에 포함된 통신 모듈은, ATA(advanced technology attachment), SCSI(small computer small interface), PCI(peripheral component interconnection) 등과 같은 직렬 유선 통 신 또는 병렬 유선 통신 모듈이거나, 와이파이(wi-fi), 블루투스(bluetooth) 등과 같은 근거리 무선 통신 모듈 일 수 있다. 웨어러블 디바이스는 사용자의 착용 편의성과 사물 인식 기능 효율을 높이기 위해 리버스 넥밴드 구 조로 구현될 수 있다. 도 2의 웨어러블 디바이스의 구성은 하나의 예시로서, 본 개시의 웨어러블 디바이스는 반드시 이에 한정되는 것은 아니다. 즉, 도 2의 각 구성들 이외에 웨어러블 디바이스에 다른 구성이 추가되거나 도 2의 각 구성들 중 적어도 하나가 포함되지 않을 수도 있다. 웨어러블 디바이스의 구성 및 구성의 배치는 도 2 와 같은 형태에 반드시 한정되는 것은 아니며, 본 개시의 기술적 사상 및 범위로부터의 벗어남 없이 당업자에 의해 변형이 수행될 수 있다. 도 3은 본 개시의 일 실시 예에 따른, 인공지능 웨어러블 플랫폼의 동작을 보여주는 흐름도이다. 도 3의 실시 예는 사용자의 요구에 따라 사물 인식 또는 문자 인식(OCR; optical character recognition)을 수행 하는 인공지능 웨어러블 플랫폼의 동작을 보여준다. 도 1 및 도 3을 참조하면, S100 단계에서 스마트 단 말은 인공지능 서버로 서비스 시나리오를 전송한다. 일 실시 예에서, 인공지능 웨어러블 플랫폼(10 0)은 이하의 S110 단계 내지 S190 단계들을 반복하여 수행할 수 있으나, S100 단계는 서비스 시나리오의 갱신 이후, 최초 1회에 한해 수행할 수 있다. S110 단계에서, 웨어러블 디바이스는 사용자로부터 음성 명령을 수신할 수 있다. 예를 들어, 웨어러 블 디바이스의 음성 모듈은 사용자의 음성 명령을 수신할 수 있다. S120 단계에서, 웨어러블 디바이스는 사용자의 음성 명령을 스마트 단말로 전송할 수 있다. 예 를 들어, 웨어러블 디바이스는 통신 모듈을 통해, 음성 명령을 스마트 단말의 통신부로 전 송할 수 있다. S121 단계에서, 스마트 단말은 웨어러블 디바이스로부터 수신된 음성 명령을 인공지능 서버로 전송할 수 있다. 예를 들어, 스마트 단말은 통신부를 통해, 웨어러블 디바이스로부터 수신된 음 성 명령을, 인공지능 서버의 서비스 인터페이스부로 전송할 수 있다. S130 단계에서, 인공지능 서버는 수신된 음성 명령을 기반으로, 음성 인식(STT; speech to text)을 수행할 수 있다. 예를 들어, 수신된 음성 명령은 오디오 형태의 데이터일 수 있다. 인공지능 서버의 인공지능 엔 진부는 오디오 형태의 음성 명령에 대해 음성 인식(STT; speech to text)을 수행할 수 있다. S140 단계에서 인공지능 서버은 음성 명령에 대한 음성 인식(STT; speech to text) 결과에 따라, 스마트 단말로 시각 정보를 요청 할 수 있다. 예를 들어, 인공지능 서버은 수신된 서비스 시나리오에 따라, 스마트 단말로 시각 정보를 요청하거나 하지 않을 수 있다. 인공지능 서버가 시각 정보를 요청하는 경우, 인공지능 서버는 서비스 인터페이스부를 통해, 스마트 단말의 통신부로 시각 정보 요청 신호를 전송할 수 있다. S141 단계에서 스마트 단말은 수신된 시각 정보 요청 신호를 웨어러블 디바이스으로 전달할 수 있다. 예를 들어, 스마트 단말은 통신부를 통해, 웨어러블 디바이스의 통신 모듈로 시각 정보 요 청 신호를 전달할 수 있다.S150 단계에서 웨어러블 디바이스는 스마트 단말로 시각 정보를 전송할 수 있다. 예를 들어, 웨어러 블 디바이스는 시각 정보 요청 신호를 수신한 경우, 카메라 모듈을 통해 시각 정보를 수집할 수 있다. 웨어러블 디바이스는 통신 모듈을 통해, 스마트 단말의 통신부로 수집된 시각 정보 를 전송할 수 있다. S160 단계에서 스마트 단말은, 수신된 시각 정보를 저장 또는 압축할 수 있다. 예를 들어, 데이터부 는, 수신된 시각 정보를 저장 또는 압축할 수 있다. 일 실시 예에서, 수신된 시각 정보의 용량에 따라 S160 단 계는 생략될 수 있다. S161 단계에서, 스마트 단말은 저장 또는 압축된 시각 정보를 인공지능 서버로 전송한다. 예를 들어, 스마트 단말은 통신부를 통해, 인공지능 서버의 서비스 인터페이스부로 시각 정보를 전송 할 수 있다. 이 경우, 스마트 단말과 인공지능 서버의 통신은 무선 통신 또는 유선 통신일 수 있다. S170 단계에서 인공지능 서버는 사용자의 음성 명령 및 서비스 시나리오를 기반으로, 사물 인식 또는 문자 인식(OCR; optical character recognition)을 수행할 수 있다. 예를 들어, 인공지능 서버의 인공지 능 엔진부는, 음성 명령에 따라, 서비스 시나리오에서 정해진 결과만을 출력할 수 있다. S171 단계에서 인공지능 서버는 스마트 단말로 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과를 전송한다. 예를 들어, 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과는 텍스트 형태일 수 있다. 인공지능 서버는 서비스 인터페이스부를 통해, 스마트 단말의 통신부로 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과를 전송할 수 있다. S180 단계에서 스마트 단말은 수신된 사물 인식 또는 문자 인식(OCR; optical character recognition) 결 과에 대해 음성 합성(TTS; text to speech)을 수행할 수 있다. 예를 들어, 수신된 사물 인식 또는 문자 인식 (OCR; optical character recognition) 결과는 텍스트 형태의 데이터일 수 있다. 스마트 단말은 텍스트 형태의 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과에 대해 음성 합성(STT; speech to text)을 수행할 수 있다. S181 단계에서 스마트 단말은 음성 합성(STT; speech to text)된 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과를, 웨어러블 디바이스로 전송한다. 예를 들어, 스마트 단말은 통신부 를 통해 웨어러블 디바이스의 통신 모듈로 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과를 전송할 수 있다. 스마트 단말이 전송하는 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과는 오디오 형태의 데이터일 수 있다. S190 단계에서 웨어러블 디바이스는, 사용자에게 오디오 형태로 사물 인식 또는 문자 인식(OCR; optical character recognition) 결과를 출력한다. 예를 들어, 음성 모듈은 사용자에게 인식 또는 문자 인식(OCR; optical character recognition) 결과를 오디오 형태로 안내할 수 있다. 도 4는 본 개시의 다른 실시 예에 따른, 인공지능 웨어러블 플랫폼의 동작을 보여주는 흐름도이다. 도 4의 실시 예는, 상시적으로 사물 인식을 수행하여 사용자에게 위험을 경고할 수 있는, 인공지능 웨어러블 플랫폼 의 동작을 보여준다. 이하의 S200 내지 S250단계는, 인공지능 웨어러블 플랫폼에서 S100 내지 S190 단계가 수행되는 중, 인터럽트 방식으로 구현될 수 있다. 그러나, 본 개시의 범위는 이에 한정되지 않는다. 도 1 및 도 4을 참조하면, S200 단계에서 스마트 단말은 인공지능 서버로 서비스 시나리오를 전송한 다. S200 단계는 상술한 S100 단계와 실질적으로 동일할 수 있다. S210 단계에서 웨어러블 디바이스는 스마트 단말로 시각 정보를 제공할 수 있다. 예를 들어, 웨어러 블 디바이스는 카메라 모듈을 통해, 시각 정보를 수집할 수 있다. 웨어러블 디바이스는 통신 모 듈을 통해, 수집된 시각 정보를 스마트 단말의 통신부로 전송할 수 있다. S211 단계에서 스마트 단말은 수신된 시각 정보를 인공지능 서버로 전달 할 수 있다. 예를 들어, 스 마트 단말은 통신부를 통해, 인공지능 서버의 서비스 인터페이스부로 시각 정보를 전달 할 수 있다. 이 경우, 스마트 단말이 인공지능 서버로 전달하는 시각 정보는 스마트 단말의 데이터 부를 통해 압축된 시각 정보일 수 있다. S220 단계에서 인공지능 서버는 수신된 시각 정보를 기반으로 사물 인식을 수행한다. 예를 들어, 사물 인 식은 인공지능 서버로 수신된 서비스 시나리오에 따라 수행될 수 있다.S230 단계에서 인공지능 서버는 인공지능 엔진부가 수행한 사물 인식 결과를 기반으로, 사용자 에게 위험이 있는지 여부를 판단할 수 있다. 예를 들어, 인공지능 서버은 사용자에게 차량 접근, 낙 상 등의 위험이 있는지 여부를 감지할 수 있다. 인공지능 서버에 의해 사용자에게 위험이 있다고 판 단된 경우, S240 단계가 진행될 수 있다. 인공지능 서버에 의해 사용자에게 위험이 없다고 판단된 경 우, S100 단계 내지 S190 단계가 진행될 수 있다. S240 단계 인공지능 서버는 스마트 단말로 경고 신호를 전송할 수 있다. 예를 들어, 인공지능 서버 은 서비스 인터페이스부을 통해, 스마트 단말의 통신부로 경고 신호를 전송할 수 있다. S241 단계에서, 스마트 단말은 수신된 경고 신호를 웨어러블 디바이스로 전달할 수 있다. 예를 들어, 스마트 단말은 통신부를 통해 웨어러블 디바이스의 통신 모듈로 경고 신호를 전달할 수 있 다. S250 단계에서 웨어러블 디바이스는 수신된 경고 신호를 기반으로, 사용자에게 위험을 안내할 수 있 다. 예를 들어, 위험 안내는 음성 또는 진동을 통해 수행될 수 있다. 웨어러블 디바이스는 경고 신호가 수 신되면, 사용자에게 음성 모듈을 통해 음성으로 경고하거나, 하드웨어 인터페이스에 포함될 수 있는 진동 모듈을 통해 진동으로 경고할 수 있다. 도 5 내지 도 6은 본 개시의 실시 예에 따라 구현된 인공지능 웨어러블 플랫폼의 성능을 설명하기 위한 도 면들이다. 도 1, 및 도 5 내지 도 6을 참조하여, 본 개시의 인공지능 웨어러블 플랫폼의 성능이 설명된다. 이하의 가정들은 상세한 설명을 위한 것으로, 본 개시의 범위는 이하의 가정들에 한정되지 않는다. 이하의 기술 적 용어들 및 파라미터들은 당업자가 통상적으로 이해하는 것과 동일한 의미를 갖는다. 본 개시의 실시 예에 따른 인공지능 서버는 3.6GHz 8core CPU, 16GB RAM, GTX-1080Ti GPU 환경으로 구현 되는 웹 기반 인공지능 서버인 것으로 가정한다. 문자 인식(OCR; optical character recognition)은 Google Vision API를 사용하여 인공지능 서버에서 수행되고, 사물 인식은 YOLO v3를 활용하여 인공지능 서버(13 0)에서 수행되는 것으로 가정한다. 도 5는 본 개시의 실시 예에 따른 인공지능 서버의 문자 인식(OCR; optical character recognition) 수행 성능 을 설명하기 위한 도면이다. 인공지능 서버는 사용자의 일상 생활에서 접하는 물품의 라벨, 표지판 문구 등을 인식할 수 있다. 이 경우 본 개시에 따른 인공지능 웨어러블 플랫폼은 사용자에게, 인식한 문자열을 음성으로 안내할 수 있다. 도 1 및 도 5를 참조하면, 웨어러블 디바이스를 통해 촬영된 제 1이미지(IMG1)는 스마트 단말을 경유 하여 인공지능 서버로 전송된다. 일 실시 예에서, 인공지능 서버는 제 1 이미지(IMG1)의 인식 영역들(RNG1, RNG2)을 설정할 수 있다. 인공 지능 서버는 문자 인식(OCR; optical character recognition) 기능 수행을 통해, 제 1 인식 영역(RNG1)에 포함된 문자열 “SHAMPOO”, 및 제 2 인식 영역(RNG2)에 포함된 문자열 “BODY WASH”를 인식할 수 있다. 일 실시 예에서, 인공지능 서버은 인식한 문자열들을 스마트 단말로 전송할 수 있다. 스마트 단말 은 음성 합성(TTS; text to speech) 기능 수행을 통해, 수신된 문자열을 음성으로 변환하여 사용자에 게 출력할 수 있다. 도 6은 본 개시의 실시 예에 따른 인공지능 서버의 사물 인식 수행 성능을 설명하기 위한 도면이다. 인공지능 서버는, Microsoft COCO (Common objects in context) 2014의 훈련 데이터 셋으로 학습된 가중치(weigh t)를 기반으로, 사물의 영상을 사용하여 전이 학습(transfer learning)된 것으로 가정한다. 인공지능 서버(13 0)는 40개의 class에 Batch size=16 및 Epoch=273로 학습된 것으로 가정한다. 본 개시의 실시 예에 따른 인공지능 서버가 사물 인식을 수행한 경우, 영상의 객체 인식 파라미터들은 각 각 mAP=0.561, Recall=0.834, F1-score=0.895, Precision=0.966으로 나타난다. 도 1 및 도 6을 참조하면, 웨어러블 디바이스를 통해 촬영된 이미지들(IMG2, IMG3)은 스마트 단말을 경유하여 인공지능 서버로 전송된다. 일 실시 예에서, 인공지능 서버는 제 2 이미지(IMG2)의 인식 영역들(RNG3, RNG4, RNG5, RNG6, RNG7)을 설 정할 수 있다. 인공지능 서버는 사물 인식 기능 수행을 통해, 제 3 인식 영역(RNG3)에 포함된 keyboard, 제 4 인식 영역(RNG4)에 포함된 mouse, 제 5 인식 영역(RNG5) 및 제 6 인식 영역(RNG6)에 포함된 tvmonitor,및 제 7 인식 영역(RNG7)에 포함된 cup을 인식할 수 있다. 일 실시 예에서, 인공지능 서버는 제 3 이미지(IMG3)의 인식 영역들(RNG8, RNG9)을 설정할 수 있다. 인공 지능 서버는 사물 인식 기능 수행을 통해, 제 8 인식 영역(RNG8)에 포함된 cell phone, 및 제 9 인식 영역 (RNG9)에 포함된 person을 인식할 수 있다. 일 실시 예에서, 인공지능 서버는 웨어러블 디바이스의 카메라 모듈로 촬영된 이미지에서, 모니 터, 키보드 및 마우스를 100%, 컵을 82 %, 핸드폰을 94%의 정확도로 인식할 수 있다. 이 경우, 인공지능 웨어러 블 플랫폼은 사용자에게, 인식한 사물의 종류를 음성으로 안내할 수 있다. 인공지능 웨어러블 플랫폼 이 사물 인식 기능을 수행하여 사용자에게 음성으로 안내하는 과정은, 전술한 인공지능 웨어러블 플 랫폼이 문자 인식(OCR; optical character recognition) 기능을 수행하여, 사용자에게 음성으로 안 내하는 과정과 실질적으로 동일하다. 상술된 내용은 본 개시를 실시하기 위한 구체적인 실시 예들이다. 본 개시는 상술된 실시 예들뿐만 아니라, 단 순하게 설계 변경되거나 용이하게 변경할 수 있는 실시 예들 또한 포함할 것이다. 또한, 본 개시는 실시 예들을 이용하여 용이하게 변형하여 실시할 수 있는 기술들도 포함될 것이다. 따라서, 본 개시의 범위는 상술된 실시 예들에 국한되어 정해져서는 안되며 후술하는 특허청구범위뿐만 아니라 본 개시의 특허청구범위와 균등한 것들 에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0038995", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시 예에 따른 인공지능 웨어러블 플랫폼을 보여주는 블록도이다. 도 2는 도 1의 웨어러블 디바이스를 보여준다. 도 3은 도 1의 인공지능 웨어러블 플랫폼의 동작 단계를 보여주는 흐름도이다. 도 4는 도 1의 인공지능 웨어러블 플랫폼의 동작 단계의 다른 실시예를 보여주는 흐름도이다. 도 5 내지 도 6은 본 개시의 실시 예에 따른 인공지능 웨어러블 플랫폼의 성능을 보여주는 도면들이다."}
