{"patent_id": "10-2022-0166397", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0083224", "출원번호": "10-2022-0166397", "발명의 명칭": "컨텐츠의 상호작용을 위한 기능요소의 개발 방법", "출원인": "안성현", "발명자": "안성현"}}
{"patent_id": "10-2022-0166397", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능서버에 포함되며, 작품을 장면 단위 또는 작품 전체 단위로 학습하되 특히 등장인물, 각 인물의 동선과대사와 행동, 각 인물간 관계, 배경, 사건의 진행경과를 학습하는 학습모듈,실감형 사용자기기로부터 전송받은 사용자 선택 결과에 따라 NPC로 지정된 등장인물의 대사, 행동, 동선, 표정,시선처리에 관한 정보를, 학습모듈에서 학습한 내용과 실감형 사용자기기로부터 전송받은 정보에 대응하여 인공지능을 이용하여 실시간으로 생성하여 영상정보생성모듈로 전송하는 NPC조정 모듈,학습모듈에서 학습한 내용과 실감형 사용자기기 및 NPC조정 모듈로부터 전송받은 정보에 맞춰, 장면을 만드는데필요한 영상정보를 인공지능을 이용하여 실시간으로 생성하는 영상정보생성모듈을 포함하도록 개발하는 컨텐츠의 상호작용을 위한 기능요소의 개발 방법."}
{"patent_id": "10-2022-0166397", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 영상정보생성모듈은,사용자가 임의의 장면을 선택하고 그 장면에 등장하는 인물중 임의의 일인을 선택하고 관찰자로 지정하면, 사용자가 그 인물의 시점으로 그 장면을 보고 듣고 느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간 생성하는 기능,사용자가 임의의 장면을 선택하고 그 장면에 등장하는 인물 중 임의의 일인을 선택하고 행위자로 지정하면, 사용자가 그 인물의 역할을 대신하여 대사와 행동을 하는 장면, 그리고 이 대사와 행동에 따라 해당장면에 등장하는 또 다른 행위자로 지정된 인물이나 NPC와 상호작용하는 장면을 사용자가 선택한 인물의 시점으로 보고 듣고느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간 생성하는 기능,사용자가 임의의 장면을 선택하고 자신을 그 장면 내 임의의 동선 및 시점으로 관찰할 수 있는 관찰자로 선택하면, 사용자가 임의의 동선 및 시점에서 그 장면을 보고 듣고 느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간 생성하는 기능을 포함하도록 개발하는 방법."}
{"patent_id": "10-2022-0166397", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, NPC조정 모듈은,사용자가 임의의 장면에서 임의의 일인을 행위자로 선택하였는데 그 장면에 제3자에 의해서도 행위자로 선택되지 않은 인물이 있다면, 그 선택되지 않은 인물을 NPC로 자동 지정하며, 학습모듈에서 학습한 내용을 기반으로사용자가 선택한 행위자의 대사와 행동에 맞춰 반응하도록 NPC의 대사와 행동을 조정하는 기능을 포함하도록 개발하는 방법."}
{"patent_id": "10-2022-0166397", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능과 실시간 렌더링 기술을 이용하여 2차원 영상 컨텐츠를 상호작용형 컨텐츠로 개발하는 방법 에 관한 것이다. 사용자는 이렇게 개발된 컨텐츠를 VR기기 등의 실감형 사용자기기로 이용함으로써, 컨텐츠에 등 장하는 인물의 시점으로 컨텐츠를 보고 듣고 느끼는 체험을 할 수 있거나, 등장하는 인물을 대신하여 대사와 행 동을 하여 컨텐츠의 전개를 바꿀 수 있는 행위자로 참여할 수 있는 등 높은 몰입감과 심리적 만족감, 성취감을 느낄 수 있게 된다. 또한 본 발명의 방법을 따르면, 기존의 잘 만들어지고 풍부하게 존재하는 2차원 영상 컨텐츠를 상호작용형 컨텐 츠로 용이하게 개발할 수 있음으로써 실감형 사용자기기를 위한 컨텐츠를 풍부하게 제공할 수 있게 된다."}
{"patent_id": "10-2022-0166397", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컨텐츠의 상호작용을 위한 기능요소를 개발하는 방법에 관한 것으로 더욱 상세하게는 2차원으로 제작 된 영상을 상호작용이 가능한 컨텐츠로 개발하는 방법에 관한 것이다"}
{"patent_id": "10-2022-0166397", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "VR(Virtual Reality)기기용 상호작용 컨텐츠를 제작하는데는 별도의 장비, 별도의 소프트웨어, 숙련된 고급인력 이 필요하고 이에 비례하여 높은 제작비와 긴 제작기간 등이 소요되어 양질의 컨텐츠를 충분히 공급하는데 어려 움이 있어 왔다. 이에 2차원 화면용 영상을 VR용 영상으로 변환해 주는 소프트웨어가 다수 개발되었지만 단순히 화면만 변환할 뿐이어서 여전히 일방향으로만 영상을 관람하는데 그치기 때문에 VR기기의 특성인 상호작용 체험이나 몰입감을 살리지 못하고 있다. 한편 인공지능을 활용하는 분야에서는 말뭉치, 그림, 사진, 영상 등의 비정형 데이터를 대량으로 인공지능에 학 습시킴으로써 번역과 대화는 물론 얼굴인식, 사물인식, 몇 개의 단어 제시만으로 그림 그리기 그리고 도로에서 의 자율주행에 이르기까지 그 응용분야를 넓혀가고 있다. 또한, 컴퓨터그래픽 분야에서는 실사(實寫) 수준의 실시간 렌더링 기술이 보급되어 카메라로 촬영한 것 같은 화 면을 실시간으로 만들어 낼 수 있는 수준에 이르렀다. 그리고 이 두 기술의 조합으로 가상인간을 개발하여 생방송의 뉴스앵커나 생방송의 쇼호스트 등으로 활동시키고 있는데, 가상인간의 움직임과 대사에 따른 얼굴 피부의 잔주름 변화, 머리카락의 찰랑거림까지 실시간으로 표현 하고 있다. 이러한 이웃 기술의 발달로 가상공간, 메타버스, VR 등은 더욱 활성화될 것이고 이에 따라 양질의 상호작용형 컨텐츠가 더욱 절실해진 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-1521595호"}
{"patent_id": "10-2022-0166397", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 과제는 상기의 문제를 해결하기 위한 것으로써, 기존의 잘 만들어지고 풍부하게 존재하는 2차원 영상 컨텐츠를 인공지능과 실시간 렌더링 기술을 이용하여 상호작용형 컨텐츠로 개발함으로써 상호작용형 컨텐츠를 풍부하게 제공하며, 상호작용 체험을 누구나 쉽게 할 수 있도록 하기 위한 것이다."}
{"patent_id": "10-2022-0166397", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 과제를 해결하기 위한 본 발명의 일실시 예에 따른 컨텐츠의 상호작용을 위한 기능요소의 개발 방법은, 인공지능서버에 포함되며, 작품을 장면 단위 또는 작품 전체 단위로 학습하되 특히 등장인물, 각 인물의 동선과 대사와 행동, 각 인물간 관계, 배경, 사건의 진행경과를 학습하는 학습모듈, 실감형 사용자기기로부터 전송받은 사용자 선택 결과에 따라 NPC로 지정된 등장인물의 대사, 행동, 동선, 표정, 시선처리에 관한 정보를, 학습모듈 에서 학습한 내용과 실감형 사용자기기로부터 전송받은 정보에 대응하여 인공지능을 이용하여 실시간으로 생성 하여 영상정보생성모듈로 전송하는 NPC조정 모듈, 학습모듈에서 학습한 내용과 실감형 사용자기기 및 NPC조정 모듈로부터 전송받은 정보에 맞춰, 장면을 만드는데 필요한 영상정보를 인공지능을 이용하여 실시간으로 생성하 는 영상정보생성모듈을 포함하도록 개발하는 방법을 포함한다. 본 발명의 바람직한 실시예에 따르면, 학습모듈은, 학습할 때, 영화, 드라마, 광고, 애니메이션, 웹툰, 스포츠 경기, 뮤지컬 등 작품을 종류별로 학습시키는 기능, 로맨스, 판타지, 공포, 스릴러, 액션, 축구, 야구 등 작품의 장르별 또는 하위구분별로 학습시키는 기능, 제작자별, 감독별, 배역별, 배우별 혹은 운동선수별로 학습시키 는 기능, 상기 실시예에서 임의의 둘 이상을 선택하여 임의의 조합으로 구성하여 학습시키는 기능, 작품을 어떠 한 구별없이 학습시키는 기능을 포함할 수 있다. 본 발명의 바람직한 실시 예에 따르면, 영상정보생성모듈은, 사용자가 임의의 장면을 선택하고 그 장면에 등장 하는 인물 중 임의의 일인을 선택하고 관찰자로 지정하면, 사용자가 그 인물의 시점으로 그 장면을 보고 듣고 느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간으로 생성하 는 기능을 포함할 수 있다. 일 실시예에 따르면, 영상정보생성모듈은, 사용자가 임의의 장면을 선택하고 그 장면에 등장하는 인물 중 임의 의 일인을 선택하고 행위자로 지정하면, 사용자가 그 인물의 역할을 대신하여 대사와 행동을 하는 장면, 그리고 이 대사와 행동에 따라 해당장면에 등장하는 또 다른 행위자로 지정된 인물이나 NPC와 상호작용하는 장면을 사 용자가 선택한 인물의 시점으로 보고 듣고 느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간 생성하는 기능을 포함할 수 있다. 일 실시예에 따르면, 영상정보생성모듈은, 사용자가 임의의 장면을 선택하고 자신을 그 장면 내 임의의 동선 및 시점으로 관찰할 수 있는 관찰자로 선택하면, 사용자가 임의의 동선 및 시점에서 그 장면을 보고 듣고 느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간 생성하는 기능을 포 함할 수 있다. 본 발명의 바람직한 실시 예에 따르면, NPC조정 모듈은, 사용자가 임의의 장면에서 임의의 일인을 행위자로 선 택하였는데 그 장면에 제3자에 의해서도 행위자로 선택되지 않은 인물이 있다면, 그 선택되지 않은 인물을 NPC 로 지정하며, 학습모듈에서 학습한 내용을 기반으로 사용자가 선택한 행위자의 대사와 행동에 맞춰 반응하 도록 NPC의 대사와 행동을 조정하는 기능을 포함한다. 본 발명의 바람직한 실시예에 따르면, 영상정보생성모듈은 학습한 내용을 바탕으로 NPC조정모듈과 실감형 사용 자기기로부터 정보를 전송받아, 영상정보를 실시간으로 생성하여 렌더링 서버로 전송하는 기능을 포함한다. 예 를 들면 영상정보생성모듈은 사용자가 선택한 행위자 또는 관찰자 그리고 NPC가 있다면 NPC를 포함하여 이들의 위치, 동작, 동선이나 시선, 조명의 위치, 배경 등 화면의 구성에 관한 동태적 정보를 생성하여 렌더링 서버로 전달한다. 본 발명의 바람직한 실시 예에 따르면, 영상정보 생성모듈은 실감형 사용자기기를 통해 사용자에게 선택 가능한 정보를 제시하고 사용자가 선택한 정보를 전달 받을 수 있도록, 사용자가 작품, 장면, 인물, 관찰자 또는 행위 자 등을 선택할 수 있는 기능, 사용자가 행위자를 선택하는 경우, 그 장면에서 사용가능한 대사 및 행동목록을 제공하는 기능, 사용자가 제3자를 중복되지 않는 인물로 참여하도록 초대하거나 임의의 제3자가 중복되지 않는 인물로 참여하는 것을 허용하는 기능, 사용자, 초대받은 사용자, 임의로 참여한 제3의 사용자 각각이 지정한 언 어로 대사를 주고 받을 수 있도록 번역되어 자막 또는 음성으로 들려주는 기능, 사용자가 임의의 동선과 시선으 로 참여하는 관찰자를 선택한 경우 임의의 프레임에서 일시멈춤을 한 후 동선과 시선을 변경할 수 있는 기능, 사용자가 본 장면 그대로를 녹화, 공유, 재생할 수 있는 기능, 사용자가 하나 이상의 작품에서 둘 이상의 장면 을 선택하여 임의로 배열하고 이어붙여 더 긴 장면을 만들 수 있도록 장면을 편집하는 기능, 사용자가 둘 이상 의 장면을 이어붙일 때 이어붙이려는 장면별로 인물을 선택하거나 관찰자 또는 행위자를 선택할 수 있는 기능, 사용자가 작품명이나 주요 대사, 주요 등장인물을 기준으로 장면을 검색할 수 있도록 하는 장면 검색기능, 사용 자가 자신의 희망사항이나 이용행태 또는 유사 이용자의 선택, 평점 등에 기반하여 장면을 추천받을 수 있는 기 능을 포함하여 개발할 수 있다."}
{"patent_id": "10-2022-0166397", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "첫째, 본 발명의 사용자가, 장면에 등장하는 인물의 1인칭 시점을 선택하면 마치 사용자가 장면 내에 참여한 것 처럼 장면내에서 보고 듣고 느끼는 체험을 할 수 있기 때문에 높은 몰입과 심미적, 정서적 만족을 할 수 있다. 둘째, 본 발명의 사용자가, 행위자를 선택하여 행위자로 참여할 경우 장면의 전개를 원작과 다르게, 사용자가 희망하는 대로 전개할 수 있기 때문에 성취감, 만족감, 몰입감을 느낄 수 있으며 동일 장면이라도 여러 번 반복 해서 즐길 수 있게 된다. 셋째, 제작 당시에 만들어진 고정된 시선으로 관람하던 장면을, 사용자가 장면 안으로 들어가 특정 인물의 시점 또는 자유로운 시점으로 보고 듣고 느끼는 새로운 체험을 할 수 있게 된다. 넷째, 기존에 잘 만들어진 풍부한 2D 작품을 이용하므로 우수한 품질의 상호작용형 컨텐츠를 빠르고 용이하게 개발할 수 있다. 다섯째, 원하는 지인을 초대하거나 또는 낯선 사람과도 함께 즐길 수 있다. 여섯째, 심리상담이나 교육상담, 인사상담 등 인간관계 개선의 보조자료로 활용될 수 있다. 일곱째, 역지사지가 가능하기 때문에 갈등해소의 기능을 가질 수 있다. 여덟째, 동일한 장면일지라도 인물 선택을 달리함으로써 여러 번 반복하여 볼 수 있다."}
{"patent_id": "10-2022-0166397", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 바람직한 실시예를 설명하지만 본 발명이 후술하는 실시예에 의해 제한되거나 한정되는 것은 아 니다. 본 출원에서 '포함한다', '포함할 수 있다'는 표현은 해당 특징(예: 기능, 동작, 구성요소)의 존재를 가리키며 추가적인 특징의 존재를 배제하지 않는다. 본 출원에서 'A 또는 B'라는 표현은 함께 나열된 항목들의 모든 가능한 조합을 포함한다. 즉 적어도 하나의 A를 포함 적어도 하나의 B를 포함 적어도 하나의 A 및 적어도 하나의 B를 모두 포함하는 경우를 모두 지 칭한다. 본 출원에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 의미를 포함할 수 있다. 본 출원에서 사용되는 모든 용어들은 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이 해되는 것과 동일한 의미를 가지나 다음의 용어들에 대해서는 그 의미를 명확히 하기 위해 그리고 본 출원서의 문장을 간결하게 작성하기 위해 다음과 같이 정의한다. 작품이란 영화, 드라마, 광고, 만화, 웹툰, 애니메이션, 뮤지컬, 연극, 음악공연, 뮤직비디오, 스포츠 경기 등 의 영상작품을 말하며, 미발표 작품이나 공개하기 전의 작품까지 통칭하는 용어로 사용한다. 장면이란 사용자 또는 서비스 제공자가 임의의 작품에서 임의의 시점(時點)부터 임의의 시점까지 지정한 영상들 의 총합이라는 용어로 사용한다. 배경이란 시간, 공간 뿐만 아니라 인물들의 의상과 패션소품, 의자, 찻잔, 만년필 등 장면을 구성하는 모든 시 각적 구성요소의 합을 뜻하는 용어로 사용한다. 영상정보란 영상을 만드는데 필요한 모든 구성요소, 예를 들면 지정된 시점(視點)에서 보이는 배경, 등장인물, 인물들 간의 대사와 동작과 감정 및 그에 따르는 맥박, 호흡, 동공 등의 변화, 그리고 관객들을 위해 추가 삽입 된 자막, 배경음악, 음향 등을 통칭하는 용어로 사용한다. 렌더링이란 영상정보에 포함된 디지털 정보유형으로부터 사람이 인지할 수 있는 형태의 시각적, 청각적, 촉각적 결과물을 만들어 내는 기능이라는 용어로 사용한다. 관찰자란 장면이 원작대로 전개되는 것을 지켜보는 자를 뜻하는 용어로 사용한다. 행위자란 대사와 행동을 통해 장면의 전개를 바꿀 수 있는 자를 뜻하는 용어로 사용한다. NPC(Non-player character)란, 그 어원이 컴퓨터 게임 내에서 사용자가 조정하지 않는 캐릭터라는 뜻이지만, 본 명세서에서는 인공지능이 운영하고 조정하는 캐릭터라는 확대된 정의로 사용한다. VR이란 VR 뿐만 아니라 AR(Augmented Reality), MR(Mixed Reality), XR(eXtended Reality), SR(Substitutional Reality) 등을 통칭하는 용어로 사용한다.실감형 사용자 기기란 사용자가 컨텐츠와 상호작용을 할 수 있도록 인체의 오감의 변화를 인지 및 추적하고 오 감에 정보를 출력하는 기기들을 통칭하는 용어로 사용하며, 구체적으로 HMD(Head Mounted Display), 헤드셋, 안 경, 동작 감지 수트, 모션체어(Motion Chair) 등을 포함한다. 모듈이란 하드웨어, 소프트웨어, 펌웨어 중 하나 또는 둘 이상의 조합을 포함하는 단위를 의미하며, 하나 또는 그 이상의 기능을 수행하는 최소단위 또는 그 일부로써 유닛, 로직, 논리블록, 부품 등의 용어와 바꾸어 사용될 수 있다. 예를 들어 학습모듈이라고 할 때는 인공지능 학습모델을 내장하여 학습에 특화시켜 개발한 학습용 AI전용 칩이 될 수도 있고, 클라우드 서비스로 제공하는 인공지능 플랫폼을 이용하여 소프트웨어적으로 학습모델을 구현한 것일 수도 있다. 최근에 개발되는 거대 인공지능은, 기존의 범용 CPU나 GPU로 학습시키거나 결과값을 얻는데 시간이 너무 많이 걸리기 때문에 학습용 AI칩, 추론용 AI칩, 다양한 용도로 사용할 수 있는 AI가속기 등 AI전용칩을 사용하기 시 작하였다. 예를 들어 삼성, 인텔, AMD, IBM 등 반도체 개발업체들은 학습모델을 내장한 FPGA(Field Programmable Gate Array), ASIC, 뉴로모픽칩 등을 출시했거나 출시 예정이라고 발표하고 있으므로, 본 발명을 실제 구현하는 시점 에서는 데이터 처리속도와 개발비, 운영비 등 총비용을 종합적으로 고려하여 본 출원에서 제시하는 각 모듈을 소프트웨어만으로 또는 AI모델을 내장한 전용칩 중심으로 또는 그 조합으로 개발할 수 있을 것이다. 이들 용어 외에 본 출원에서 사용하는 용어들은 본 발명이 속하는 분야의 관련 기술의 문맥상 의미와 일치하는 것으로 해석되어야 하며 과도하게 이상적이거나 형식적인 의미를 지니는 것으로 해석될 수 없다. 도면에 있어 식별부호(예를 들어 100, 200, 300 등)는 설명의 편의를 위하여 사용하는 것으로 식별부호는 순서 를 규정하는 것이 아니며, 명백하게 특정 순서를 기재하지 않는 이상 기술된 순서와 다르게 일어날 수 있다. 즉 각 모듈들의 작동순서는 식별부호와 동일하게 일어날 수도 있고 동시에 수행될 수도 있으며 임의의 순서 또는 반대의 순서로 작동될 수도 있다. 도1은 본 발명의 바람직한 실시예에 따른 컨텐츠의 상호작용을 위한 기본 시스템을 도시한 블록도이다. 도1을 참조하면, 본 발명의 바람직한 실시예는, 인공지능서버에 포함되며, 작품을 장면 단위 또는 작품 전체 단 위로 학습하되 특히 등장인물, 각 인물의 동선과 대사와 행동, 각 인물간 관계, 배경, 사건의 진행경과를 학습 하는 학습모듈, 실감형 사용자기기로부터 전송받은 사용자 선택 결과에 따라 NPC로 지정된 등장인물의 대사, 행동, 동선, 표정, 시선처리에 관한 정보를, 학습모듈에서 학습한 내용과 실감형 사용자기기로부터 전송받은 정보에 대응하여 인공 지능을 이용하여 실시간으로 생성하여 영상정보생성모듈로 전송하는 NPC조정 모듈, 학습모듈에서 학습한 내용과 실감형 사용자기기 및 NPC조정 모듈로부터 전송받은 정보에 맞춰, 장면을 만드는데 필요한 영상정보를 인공지능을 이용하여 실시간으로 생성하는 영상정보생성모듈을 포함하도록 개발하는 방 법을 포함한다. 본 발명의 바람직한 실시예에 따르면, 학습모듈은, 학습할 때, 영화, 드라마, 광고, 애니메이션, 웹툰, 스 포츠경기, 뮤지컬 등 작품을 종류별로 학습시키는 기능을 포함할 수 있다. 일 실시예에 따르면, 학습모듈은, 로맨스, 판타지, 공포, 스릴러, 액션, 축구, 야구 등 작품의 장르별 또 는 하위구분별로 학습시키는 기능을 포함할 수 있다. 일 실시예에 따르면, 학습모듈은, 제작자별, 감독별, 배역별, 배우별 혹은 운동선수별로 학습시키는 기능 을 포함할 수 있다. 일 실시예에 따르면, 학습모듈은, 상기 실시예에서 임의의 둘 이상을 선택하여 임의의 조합으로 구성하여 학습시키는 기능을 포함할 수 있다. 일 실시예에 따르면, 학습모듈은, 작품을 어떠한 구별없이 학습시키는 기능을 포함할 수 있다. 본 발명의 바람직한 실시 예에 따르면, 영상정보생성모듈은, 사용자가 임의의 장면을 선택하고 그 장면에 등장하는 인물 중 임의의 일인을 선택하고 관찰자로 지정하면, 사용자가 그 인물의 시점으로 그 장면을 보고 듣 고 느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간으로 생성하는 기능을 포함할 수 있다. 예를 들면, 사용자가 영화 벤허의 마차경주 장면을 선택하고 그 장면에 등장하는 인물 중 벤허를 선택하고 관찰 자로 지정하면, 영상정보생성모듈은 사용자가 벤허의 시선으로 마차경주 장면의 모든 전개과정, 모든 인물 과 배경을 보고 듣고 느끼도록 영상정보를 실시간으로 생성하게 된다. 이로써 사용자는 마차의 속도감, 바람소 리, 바람이 스치는 촉감, 휙휙 지나가는 배경, 말 발굽소리, 관중들의 환호성 등을 벤허의 시선으로 보고 듣고 느낄 수 있게 되며, 이때 관찰자로 지정했기 때문에 장면의 전개는 원작 그대로 전개된다. 일 실시예에 따르면, 영상정보생성모듈은, 사용자가 임의의 장면을 선택하고 그 장면에 등장하는 인물 중 임의의 일인을 선택하고 행위자로 지정하면, 사용자가 그 인물의 역할을 대신하여 대사와 행동을 하는 장면, 그 리고 이 대사와 행동에 따라 해당장면에 등장하는 또 다른 행위자로 지정된 인물이나 NPC와 상호작용하는 장면 을 사용자가 선택한 인물의 시점으로 보고 듣고 느끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보 를, 학습한 내용을 기반으로 실시간 생성하는 기능을 포함할 수 있다. 예를 들면, 사용자가 2022년 12월 6일 브라질과의 월드컵 16강 경기의 전반전을 선택하고, 골키퍼 김승규를 선 택하고, 행위자로 지정한 후, 브라질 선수의 슛을 모두 막아내는 행동을 하면 영상정보생성모듈은 행위자 의 행동에 맞추어 브라질 선수들의 슛을 모두 막아내어 한국이 승리하게 하고, 승리 세레모니, 관중들과 동료들 의 축하, 기자회견 등을 김승규의 시선으로 보고 듣고 느끼게 하는 영상정보를 실시간으로 생성하게 되는 것이다. 이때 행위자로 지정했기 때문에 장면의 전개에 개입할 수 있게 되고 장면은 원작과 다르게 전개될 수 있게 되는 것이다. 일 실시예에 따르면, 영상정보생성모듈은, 사용자가 임의의 장면을 선택하고 자신을 그 장면 내 임의의 동 선 및 시점으로 관찰할 수 있는 관찰자로 선택하면, 사용자가 임의의 동선 및 시점에서 그 장면을 보고 듣고 느 끼게 할 수 있도록 그 장면을 다시 만드는데 필요한 영상정보를, 학습한 내용을 기반으로 실시간 생성하는 기능 을 포함할 수 있다. 예를 들면, 사용자가 이효석의 “메밀꽃 필 무렵”의 “산허리는 온통 메밀밭이어서 피기 시작한 꽃이 소금을 뿌린 듯이 흐믓한 달빛에 숨이 막힐 지경이다”로 묘사된 장면을 선택하고 자신을 관찰자로 지정한 후, 이 장면 내의 구석구석을 다니며 다양한 시선으로 바라보면 영상정보생성모듈은 사용자의 동선과 시선에 맞춘 메밀 꽃 밭 영상정보를 실시간으로 생성하게 되는 것이다. 그리고 이때는 임의의 등장 인물의 시선으로 보는 것이 아 니라 사용자가 마치 투명인간처럼 장면 내에서 자유로이 돌아다니며 자유로운 시선으로 장면을 볼 수 있게 되며, 장면의 전개에는 개입하지 않기 때문에 장면은 원작과 동일하게 전개된다. 본 발명의 바람직한 실시 예에 따르면, NPC조정 모듈은, 사용자가 임의의 장면에서 임의의 일인을 행위자 로 선택하였는데 그 장면에 제3자에 의해서도 행위자로 선택되지 않은 인물이 있다면, 그 선택되지 않은 인물을 NPC로 지정하며, 학습모듈에서 학습한 내용을 기반으로 사용자가 선택한 행위자의 대사와 행동에 맞춰 반 응하도록 NPC의 대사와 행동을 조정하는 기능을 포함한다. 이때 사용자가 선택한 행위자의 대사나 행동에 인공지능이 조정하는 NPC는 예상되는 반응을 보일 수도 있고 뜻 밖의 반응을 보일 수도 있기 때문에 장면은 더 흥미롭게 전개될 수 있고 또한 사용자가 선택한 행위자의 대사나 행동과 이에 대응하는 NPC의 반응 간의 조합의 경우의 수가 매우 많기 때문에 결과적으로 매우 많은 버전의 평 행장면이 만들어 질 수 있게 된다. 본 발명의 바람직한 실시예에 따르면, 영상정보생성모듈은 학습한 내용을 바탕으로 NPC조정모듈과 실감형 사용자기기로부터 정보를 전송받아, 영상정보를 실시간으로 생성하여 렌더링 서버로 전송하는 기능을 포함한다. 예를 들면 영상정보생성모듈은 사용자가 선택한 행위자 또는 관찰자 그리고 NPC가 있다면 NPC를 포함하여 이들의 위치, 동작, 동선이나 시선, 조명의 위치, 배경 등 화면의 구성에 관한 동태적 정보를 생성하여 렌더링 서버로 전달한다. 이 정보를 받은 렌더링 서버는 투영, 은면처리, 셰이딩, 클리핑, 매핑 등을 통해 실시간 영상 을 만들어 실감형 사용자기기에 전달한다. 실시간으로 실사 수준의 영상을 렌더링하는 상용 소프트웨어는 다수 가 공개되어 있으므로 적합한 소프트웨어를 선정하여 구현하면 될 것이다. 본 발명의 바람직한 실시 예에 따르면, 영상정보 생성모듈은 실감형 사용자기기를 통해 사용자에게 선택 가능한 정보를 제시하고 사용자가 선택한 정보를 전달 받을 수 있도록, 사용자가 작품, 장면, 인물, 관찰자 또 는 행위자 등을 선택할 수 있는 기능, 사용자가 행위자를 선택하는 경우, 그 장면에서 사용가능한 대사 및 행동 목록을 제공하는 기능, 사용자가 제3자를 중복되지 않는 인물로 참여하도록 초대하거나 임의의 제3자가 중복되 지 않는 인물로 참여하는 것을 허용하는 기능, 사용자, 초대받은 사용자, 임의로 참여한 제3의 사용자 각각이지정한 언어로 대사를 주고 받을 수 있도록 번역되어 자막 또는 음성으로 들려주는 기능, 사용자가 임의의 동선 과 시선으로 참여하는 관찰자를 선택한 경우 임의의 프레임에서 일시멈춤을 한 후 동선과 시선을 변경할 수 있 는 기능, 사용자가 본 장면 그대로를 녹화, 공유, 재생할 수 있는 기능, 사용자가 하나 이상의 작품에서 둘 이 상의 장면을 선택하여 임의로 배열하고 이어붙여 더 긴 장면을 만들 수 있도록 장면을 편집하는 기능, 사용자가 둘 이상의 장면을 이어붙일 때 이어붙이려는 장면별로 인물을 선택하거나 관찰자 또는 행위자를 선택할 수 있는 기능, 사용자가 작품명이나 주요 대사, 주요 등장인물을 기준으로 장면을 검색할 수 있도록 하는 장면 검색기능, 사용자가 자신의 희망사항이나 이용행태 또는 유사 이용자의 선택, 평점 등에 기반하여 장면을 추천 받을 수 있는 기능을 포함하여 개발할 수 있다."}
{"patent_id": "10-2022-0166397", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1 : 컨텐츠의 상호작용을 위한 기본 시스템 개념도"}
