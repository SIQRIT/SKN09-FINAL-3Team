{"patent_id": "10-2023-0120567", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0038016", "출원번호": "10-2023-0120567", "발명의 명칭": "객체 추적 장치 및 그 방법", "출원인": "현대자동차주식회사", "발명자": "허세종"}}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량의 주변 정보를 획득하는 센서부; 및상기 센서부가 획득한 주변 정보를 바탕으로, 차량 외부의 객체를 추적하는 프로세서;를 포함하고,상기 프로세서는상기 주변 정보를 바탕으로 격자 지도를 생성하고,상기 격자 지도를 딥러닝하여 분류 객체를 획득하며,상기 격자 지도에서 점유 격자를 검출하고, 상기 점유 격자의 군집화를 바탕으로 격자 객체를 획득하며,상기 분류 객체와 상기 격자 객체를 융합하여 객체를 추적하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 프로세서는탑-뷰 이미지 형식으로 상기 격자 지도를 생성하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 프로세서는상기 격자 지도에서 객체 추적 영역을 한정하는 관심 영역을 설정하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 프로세서는상기 분류 객체를 둘러싸는 바운딩 박스, 상기 바운딩 박스에 매칭되는 클래스, 및 상기 분류 객체의 속도 정보를 획득하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 프로세서는상기 격자 지도의 격자들 각각에 객체가 존재할 점유 확률을 바탕으로 점유 격자를 추출하고,상기 점유 격자와 인접한 하나 이상의 주변 격자를 추출하며,공개특허 10-2025-0038016-3-상기 점유 격자 및 상기 주변 격자를 포함하는 상기 격자 객체를 획득하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 프로세서는상기 격자 객체에 속하는 격자들 각각의 속도를 바탕으로, 상기 격자 객체를 둘 이상의 서로 다른 격자 객체들로 구분하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 프로세서는제1 프레임에서 상기 격자 객체 내부에서 추격점을 결정하고, 상기 추격점의 이동 상태의 예측점을 중심으로 유효범위를 설정하며,제1 프레임 이후 획득된 제2 프레임에서 측정된 상기 추격점이 상기 유효범위 이내에 위치하는지를 판단하여,상기 격자 객체의 추적을 진행하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 프로세서는상기 격자 객체가 차지하는 군집 영역을 계산하고,상기 바운딩 박스의 영역과 상기 군집 영역 간의 중첩 영역을 계산하며,상기 군집 영역에 대비한 상기 중첩 영역의 크기가 미리 설정된 임계값 이상인 것을 바탕으로, 상기 분류 객체와 상기 격자 객체를 동일한 객체로 판단하는 것을 특징으로 하는 객체 추적 장치. 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 프로세서는상기 프로세서는볼록 껍질 알고리즘을 이용하여 상기 격자 객체를 둘러싸는 볼록 껍질을 획득하고,상기 볼록 껍질 내부 영역을 상기 군집 영역으로 결정하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8 항에 있어서,상기 프로세서는상기 바운딩 박스와 상기 볼록 껍질이 교차하는 하나 이상의 교차 포인트를 획득하고,상기 볼록 껍질에 포함되는 경계 포인트들 중에서 상기 바운딩 박스 내부에 위치하는 하나 이상의 제1 내부 포공개특허 10-2025-0038016-4-인트를 획득하며,상기 바운딩 박스의 꼭지점에 해당하는 격자들 중에서 상기 볼록 껍질 내부에 위치한 하나 이상의 제2 내부 포인트를 획득하고,상기 교차 포인트, 상기 제1 내부 포인트, 및 상기 제2 내부 포인트를 잇는 영역을 상기 중첩 영역으로 결정하는 것을 특징으로 하는 객체 추적 장치."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "차량 외부의 주변 정보를 바탕으로 격자 지도를 생성하는 단계;상기 격자 지도를 딥러닝하여 분류 객체를 획득하는 단계;상기 격자 지도에서 점유 격자를 검출하고, 상기 점유 격자의 군집화를 바탕으로 격자 객체를 획득하는 단계;및상기 분류 객체와 상기 격자 객체를 융합하여 객체를 추적하는 단계;를 포함하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 격자 지도를 생성하는 단계는탑-뷰 이미지 형식으로 상기 격자 지도를 생성하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 주변 정보를 상기 격자 지도로 변환하는 단계는객체 추적 영역을 한정하는 관심 영역을 설정하는 단계를 더 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서,상기 분류 객체를 획득하는 단계는상기 분류 객체를 둘러싸는 바운딩 박스를 획득하는 단계; 상기 바운딩 박스에 매칭되는 클래스를 획득하는 단계; 및상기 분류 객체의 속도 정보를 획득하는 단계;를 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서,상기 격자 객체를 획득하는 단계는상기 격자 지도의 격자들 각각에 객체가 존재할 점유 확률을 바탕으로 점유 격자를 추출하는 단계;상기 점유 격자와 인접한 하나 이상의 주변 격자를 추출하는 단계; 및공개특허 10-2025-0038016-5-상기 점유 격자 및 상기 주변 격자를 포함하는 상기 격자 객체를 획득하는 단계;를 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 격자 객체를 획득하는 단계는상기 격자 객체에 포함되는 격자들 각각의 속도를 바탕으로 상기 격자 객체를 둘 이상의 서로 다른 격자 객체들로 구분하는 단계;를 더 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11 항에 있어서, 상기 격자 객체를 획득하는 단계는제1 프레임에서 상기 격자 객체 내부에서 추격점을 결정하는 단계;상기 추격점의 이동 상태의 예측점을 중심으로 유효범위를 설정하는 단계;제1 프레임 이후 획득된 제2 프레임에서 측정된 상기 추격점이 상기 유효범위 이내에 위치하는지를 판단하여,상기 격자 객체의 추적을 진행하는 단계;를 더 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 11 항에 있어서,상기 분류 객체와 상기 격자 객체를 융합하여 객체를 추적하는 단계는상기 격자 객체가 차지하는 군집 영역을 계산하는 단계;상기 바운딩 박스의 영역과 상기 군집 영역 간의 중첩 영역을 계산하는 단계; 및상기 군집 영역에 대비한 상기 중첩 영역의 크기가 미리 설정된 임계값 이상인 것을 바탕으로, 상기 분류 객체와 상기 격자 객체를 동일한 객체로 판단하는 단계;를 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 군집 영역을 계산하는 단계는볼록 껍질 알고리즘을 이용하여 상기 격자 객체를 둘러싸는 볼록 껍질을 획득하는 단계;상기 볼록 껍질 내부 영역을 상기 군집 영역으로 결정하는 단계;를 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 18 항에 있어서,상기 분류 객체와 상기 격자 객체를 융합하여 객체를 추적하는 단계는상기 바운딩 박스와 상기 볼록 껍질이 교차하는 하나 이상의 교차 포인트를 획득하는 단계;공개특허 10-2025-0038016-6-상기 볼록 껍질에 포함되는 경계 포인트들 중에서 상기 바운딩 박스 내부에 위치하는 하나 이상의 제1 내부 포인트를 획득하는 단계;상기 바운딩 박스의 꼭지점에 해당하는 격자들 중에서 상기 볼록 껍질 내부에 위치한 하나 이상의 제2 내부 포인트를 획득하는 단계; 및상기 교차 포인트, 상기 제1 내부 포인트, 및 상기 제2 내부 포인트를 잇는 영역을 상기 중첩 영역으로 결정하는 단계;를 포함하는 것을 특징으로 하는 객체 추적 방법."}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 객체 추적 장치 및 그 방법에 관한 것으로, 본 발명의 실시 예에 의한 객체 추적 장치는 차량의 주변 정보를 획득하는 센서부, 및 센서부가 획득한 주변 정보를 바탕으로, 차량 외부의 객체를 추적하는 프로세서;를 포함할 수 있다. 프로세서는 주변 정보를 바탕으로 격자 지도를 생성하고, 격자 지도를 딥러닝하여 분류 객체를 획득하며, 격자 지도에서 점유 격자를 검출하고, 점유 격자의 군집화를 바탕으로 격자 객체를 획득하며, 분류 객 체와 격자 객체를 융합하여 객체를 추적할 수 있다."}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 객체 추적 장치 및 그 방법에 관한 것으로, 보다 상세하게는 차량 외부의 객체를 검출하고, 검출된 객체를 추적하는 기술에 관한 것이다."}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율주행 자동차(Autonomous Vehicle)란 운전자 또는 승객의 조작 없이 자동차 스스로 운행이 가능한 자동차를 말하며, 자율주행시스템(Autonomous Driving Systems)은 이러한 자율주행자동차가 스스로 운행될 수 있도록 모 니터링하고 제어하는 시스템을 말한다. 자율주행 자동차는 넓은 의미로는 운전자의 운전 보조를 위해서 차량의 외부를 모니터링하고, 모니터링 된 차량 외부 환경을 바탕으로 다양한 운전 보조 수단을 장착한 차량을 의미할 수 있다. 자율주행 자동차 또는 주행보조장치를 탑재한 자동차는 차량 외부를 모니터링하여 객체를 검출하고, 검출된 객 체에 따라 결정되는 시나리오를 바탕으로 차량을 제어한다. 즉, 자율주행 또는 주행보조장치에 따른 주행은 차 량 외부의 객체 종류를 판단하는 과정이 전제되는 것이 일반적이다. 차량 외부의 객체를 인식하기 위해서 센서들이 획득한 정보를 딥러닝하는 방식이 일반적으로 이용되지만, 객체 검출 성능에는 여전히 한계가 있다. 따라서, 객체 인식 성능을 보다 높일 수 있는 기술이 요구되고 있다."}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 딥러닝을 통해서 검출하지 못한 객체마저 인식할 수 있는 객체 추적 장치, 및 그 방법을 제공하기 위 한 것이다. 또한, 본 발명은 객체의 형상이나 종류를 정확하게 파악하면서, 객체의 인식 성능을 높일 수 있는 객체 추적 장 치, 및 그 방법을 제공하기 위한 것이다. 또한, 본 발명은 객체를 보다 정확하게 추적할 수 있는 객체 추적 장치, 및 그 방법을 제공하기 위한 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 의한 객체 추적 장치는 차량의 주변 정보를 획득하는 센서부, 및 센서부가 획득한 주변 정 보를 바탕으로, 차량 외부의 객체를 추적하는 프로세서;를 포함할 수 있다. 프로세서는 주변 정보를 바탕으로 격자 지도를 생성하고, 격자 지도를 딥러닝하여 분류 객체를 획득하며, 격자 지도에서 점유 격자를 검출하고, 점유 격자의 군집화를 바탕으로 격자 객체를 획득하며, 분류 객체와 격자 객체를 융합하여 객체를 추적할 수 있 다. 실시 예에 의하면, 상기 프로세서는 탑-뷰 이미지 형식으로 상기 격자 지도를 생성할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 격자 지도에서 객체 추적 영역을 한정하는 관심 영역을 설정할 수 있 다. 실시 예에 의하면, 상기 프로세서는 상기 분류 객체를 둘러싸는 바운딩 박스, 상기 바운딩 박스에 매칭되는 클 래스, 및 상기 분류 객체의 속도 정보를 획득할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 격자 지도의 격자들 각각에 객체가 존재할 점유 확률을 바탕으로 점유 격자를 추출하고, 상기 점유 격자와 인접한 하나 이상의 주변 격자를 추출하며, 상기 점유 격자 및 상기 주변 격자를 포함하는 상기 격자 객체를 획득할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 격자 객체에 속하는 격자들 각각의 속도를 바탕으로, 상기 격자 객체 를 둘 이상의 서로 다른 격자 객체들로 구분할 수 있다. 실시 예에 의하면, 상기 프로세서는 제1 프레임에서 상기 격자 객체 내부에서 추격점을 결정하고, 상기 추격점 의 이동 상태의 예측점을 중심으로 유효범위를 설정하며, 제1 프레임 이후 획득된 제2 프레임에서 측정된 상기 추격점이 상기 유효범위 이내에 위치하는지를 판단하여, 상기 격자 객체의 추적을 진행할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 격자 객체가 차지하는 군집 영역을 계산하고, 상기 바운딩 박스의 영 역과 상기 군집 영역 간의 중첩 영역을 계산하며, 상기 군집 영역에 대비한 상기 중첩 영역의 크기가 미리 설정 된 임계값 이상인 것을 바탕으로, 상기 분류 객체와 상기 격자 객체를 동일한 객체로 판단할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 프로세서는 볼록 껍질 알고리즘을 이용하여 상기 격자 객체를 둘러싸 는 볼록 껍질을 획득하고, 상기 볼록 껍질 내부 영역을 상기 군집 영역으로 결정할 수 있다. 실시 예에 의하면, 상기 프로세서는 상기 바운딩 박스와 상기 볼록 껍질이 교차하는 하나 이상의 교차 포인트를 획득하고, 상기 볼록 껍질에 포함되는 경계 포인트들 중에서 상기 바운딩 박스 내부에 위치하는 하나 이상의 제 1 내부 포인트를 획득하며, 상기 바운딩 박스의 꼭지점에 해당하는 격자들 중에서 상기 볼록 껍질 내부에 위치 한 하나 이상의 제2 내부 포인트를 획득하고, 상기 교차 포인트, 상기 제1 내부 포인트, 및 상기 제2 내부 포인 트를 잇는 영역을 상기 중첩 영역으로 결정할 수 있다. 본 발명의 실시 예에 의한 객체 추적 방법은 차량 외부의 주변 정보를 바탕으로 격자 지도를 생성하는 단계, 상 기 격자 지도를 딥러닝하여 분류 객체를 획득하는 단계, 상기 격자 지도에서 점유 격자를 검출하고, 상기 점유 격자의 군집화를 바탕으로 격자 객체를 획득하는 단계, 및 상기 분류 객체와 상기 격자 객체를 융합하여 객체를 추적하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 격자 지도를 생성하는 단계는 탑-뷰 이미지 형식으로 상기 격자 지도를 생성할 수 있다. 실시 예에 의하면, 상기 주변 정보를 상기 격자 지도로 변환하는 단계는 객체 추적 영역을 한정하는 관심 영역 을 설정하는 단계를 더 포함할 수 있다. 실시 예에 의하면, 상기 분류 객체를 획득하는 단계는 상기 분류 객체를 둘러싸는 바운딩 박스를 획득하는 단계, 상기 바운딩 박스에 매칭되는 클래스를 획득하는 단계, 및 상기 분류 객체의 속도 정보를 획득하는 단계 를 포함할 수 있다. 실시 예에 의하면, 상기 격자 객체를 획득하는 단계는 상기 격자 지도의 격자들 각각에 객체가 존재할 점유 확 률을 바탕으로 점유 격자를 추출하는 단계, 상기 점유 격자와 인접한 하나 이상의 주변 격자를 추출하는 단계, 및 상기 점유 격자 및 상기 주변 격자를 포함하는 상기 격자 객체를 획득하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 격자 객체를 획득하는 단계는 상기 격자 객체에 포함되는 격자들 각각의 속도를 바탕으 로 상기 격자 객체를 둘 이상의 서로 다른 격자 객체들로 구분하는 단계를 더 포함할 수 있다. 실시 예에 의하면, 상기 격자 객체를 획득하는 단계는 제1 프레임에서 상기 격자 객체 내부에서 추격점을 결정 하는 단계, 상기 추격점의 이동 상태의 예측점을 중심으로 유효범위를 설정하는 단계, 제1 프레임 이후 획득된 제2 프레임에서 측정된 상기 추격점이 상기 유효범위 이내에 위치하는지를 판단하여 상기 격자 객체의 추적을 진행하는 단계를 더 포함할 수 있다. 실시 예에 의하면, 상기 분류 객체와 상기 격자 객체를 융합하여 객체를 추적하는 단계는 상기 격자 객체가 차 지하는 군집 영역을 계산하는 단계, 상기 바운딩 박스의 영역과 상기 군집 영역 간의 중첩 영역을 계산하는 단 계 및 상기 군집 영역에 대비한 상기 중첩 영역의 크기가 미리 설정된 임계값 이상인 것을 바탕으로, 상기 분류 객체와 상기 격자 객체를 동일한 객체로 판단하는 단계를 포함할 수 있다. 실시 예에 의하면, 상기 군집 영역을 계산하는 단계는 볼록 껍질 알고리즘을 이용하여 상기 격자 객체를 둘러싸 는 볼록 껍질을 획득하는 단계, 상기 볼록 껍질 내부 영역을 상기 군집 영역으로 결정하는 단계를 포함할 수 있 다. 실시 예에 의하면, 상기 분류 객체와 상기 격자 객체를 융합하여 객체를 추적하는 단계는 상기 바운딩 박스와 상기 볼록 껍질이 교차하는 하나 이상의 교차 포인트를 획득하는 단계, 상기 볼록 껍질에 포함되는 경계 포인트 들 중에서 상기 바운딩 박스 내부에 위치하는 하나 이상의 제1 내부 포인트를 획득하는 단계, 상기 바운딩 박스 의 꼭지점에 해당하는 격자들 중에서 상기 볼록 껍질 내부에 위치한 하나 이상의 제2 내부 포인트를 획득하는 단계, 및 상기 교차 포인트, 상기 제1 내부 포인트, 및 상기 제2 내부 포인트를 잇는 영역을 상기 중첩 영역으 로 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 의하면, 딥러닝 기반의 분류 객체 검출과 더불어 격자 지도를 바탕으로 객체를 인식하기 때문에, 딥러닝 기반으로만 객체 인식을 진행할 때 보다 인식 성능을 높일 수 있다. 또한, 본 발명의 딥러닝 기반으로 객체의 클래스 및 형상을 판단할 수 있기 때문에, 격자 지도 기반으로 객체 인식 과정에서 객체의 형상 및 클래스를 파악하기 곤란한 점을 극복할 수 있다. 또한, 본 발명은 딥러닝 기반의 분류 객체와 격자 지도의 격자 객체를 융합하여 객체를 추적하기 때문에, 연속 되는 프레임에서 동일 객체를 보다 정확하게 추적할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시 예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시 예를 설명함에 있어, 관련된 공지 구성 또는 기능 에 대한 구체적인 설명이 본 발명의 실시 예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 발명의 실시 예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있 다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어 를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일 반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의 하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 도 1 내지 도 16을 참조하여, 본 발명의 실시 예들을 구체적으로 설명하기로 한다. 도 1은 본 발명의 실시 예에 의한 객체 추적 장치 및 이를 포함한 차량 제어 장치의 구성을 나타내는 블록도이 다. 도 2는 본 발명의 실시 예에 의한 객체 추적 장치의 센서부가 장착된 차량을 나타내는 도면이다. 도 1 및 도 2를 참조하면, 객체 추적 장치(TM)는 센서부, 프로세서, 메모리를 포함할 수 있다. 본 발명의 실시 예에 의한 차량 제어 장치(CM)는 객체 추적 장치(TM), 구동 제어기, 통신부 및 알림 부를 포함하며, 차량(VEH)에 장착될 수 있다. 센서부는 차량(VEH)의 외부 객체를 검출하기 위한 카메라, 라이다(Light Imaging Detection and Ranging; LIDAR), 레이더(Radio Detection and Ranging; RADAR) 중에서 적어도 어느 하나 이상을 포 함할 수 있다. 카메라는 차량(VEH)의 외부 이미지를 획득하기 위한 것으로, 차량(VEH)의 전방 이미지 또는 전측방 이미지 를 획득할 수 있다. 예를 들어, 카메라는 차량(VEH)의 전방 이미지를 획득하기 위해, 프런트 윈드 쉴드 주 위에 배치될 수 있다. 라이다는 레이저를 송출하고 객체로부터 반사되는 레이저의 반사파를 이용하여 객체를 판단하기 위한 것으 로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는 차 량의 외부에 노출되도록 장착될 수 있으며, 전면 범퍼 또는 전면 그릴 주위에 배치될 수 있다. 레이더는 전자파 송신 모듈, 수신 모듈을 포함할 수 있다. 레이더는 전파 발사 원리상 펄스 레이더 (Pulse Radar) 방식 또는 연속파 레이더(Continuous Wave Radar) 방식으로 구현될 수 있다. 레이더는 연 속파 레이더 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keying) 방식으로 구현될 수 있다. 레이더는 차량(VEH)의 전면 중심부에 위치한 전 면 레이더, 전면 범퍼의 양 끝에 위치한 전측방 레이더, 및 차량(VEH)의 후방에 위치한 후방 레이더 를 포함할 수 있다. 카메라, 라이다, 및 레이더의 위치는 도 2에 도시된 실시 예에 한정되지 않을 수 있다. 도면에 도시된 이외에, 센서부는 초음파 센서 및 적외선 센서를 포함할 수 있다. 초음파 센서는 초음파 송신 모 듈, 수신 모듈을 포함할 수 있다. 초음파 센서는, 초음파를 기초로 객체를 검출하고, 검출된 객체의 위치, 검출 된 객체와의 거리 및 상대 속도를 검출할 수 있다. 초음파 센서는 차량의 전방, 후방 또는 측방에 위치하는 객 체를 감지하기 위해 차량의 외부의 적절한 위치에 배치될 수 있다. 적외선 센서는 적외선 송신 모듈, 수신 모듈 을 포함할 수 있다. 적외선 센서는, 적외선 광을 기초로 객체를 검출하고, 검출된 객체의 위치, 검출된 객체와 의 거리 및 상대 속도를 검출할 수 있다. 적외선 센서는 차량의 전방, 후방 또는 측방에 위치하는 객체를 감지 하기 위해 차량의 외부에 배치될 수 있다. 또한, 센서부는 차량의 변속을 위한 속도 제어 명령을 생성하는 브레이크 페달 위치 센서(Brake-pedal Position Sensor; BPS), 및 가속 페달 위치 센서(Accelerator Position Sensor; APS)를 더 포함할 수 있다. 브레이크 페달 위치 센서는 차량에 구비된 브레이크 페달의 눌림 정도에 따라 BPS 신호를 출력할 수 있다. 일례 로, BPS 신호는 브레이크 페달의 눌림에 따라 0~100의 데이터를 출력할 수 있고, 0의 값은 브레이크 페달의 눌 림이 없을 경우이며, 100의 값은 브레이크 페달의 눌림이 최대인 경우일 수 있다. 가속 페달 위치 센서는 차량에 구비된 가속 페달의 눌림 정도에 따라 APS 신호를 출력할 수 있다. 일례로, APS 신호는 가속 페달의 눌림에 따라 0~100의 데이터를 출력할 수 있고, 0의 값은 가속 페달의 눌림이 없을 경우이 며, 100의 값은 가속 페달의 눌림이 최대인 경우일 수 있다.프로세서는 차량 외부의 주변 정보를 획득하고, 획득된 주변 정보를 바탕으로 격자 지도를 생성할 수 있다. 주변 정보는 센서부에서 획득한 정보들일 수 있다. 격자 지도는 센서부의 출력값을 이용하여 격자에 객체 정보를 표현한 것일 수 있다. 격자 지도에서 각각의 격자들은 점유 확률에 따라 구분될 수 있다. 또한 프로세서는 각각의 격자들의 속도 정보를 획득할 수 있다. 격자 지도는 탑-뷰 이미지 형식으로 생성 될 수 있다. 프로세서는 격자 지도를 학습하여 분류 객체를 획득할 수 있다. 이를 위해서, 프로세서는 이미지 학 습을 위한 딥러닝 네트워크를 포함할 수 있다. 분류 객체는 바운딩 박스 형태로 출력될 수 있다. 또한, 프로세 서는 분류 객체들의 클래스(class)를 획득할 수 있으며, 분류 객체의 속도 정보를 추정할 수 있다. 프로세서는 격자 지도에서 점유 격자를 검출하고, 점유 격자의 군집화를 바탕으로 격자 객체를 획득할 수 있다. 점유 격자는 격자의 점유 확률이 일정 수준 이상인 격자들을 의미할 수 있다. 프로세서는 점유 격자 와 인접한 주변 격자들을 추출하고, 점유 격자와 주변 격자들을 포함하는 격자 객체를 획득할 수 있다. 프로세서는 분류 객체와 격자 객체를 융합하여 객체를 추적할 수 있다. 실시 예에 의하면, 프로세서 는 격자 객체가 차지하는 군집 영역에 대비한 중첩 영역의 크기가 미리 설정된 임계값 이상인 것을 바탕으로, 분류 객체와 격자 객체를 동일한 객체로 판단할 수 있다. 중첩 영역은 바운딩 박스의 영역과 군집 영역 간의 중 첩된 영역을 의미할 수 있다. 프로세서는 객체 추적을 수행하는 각각의 절차들 중에서 적어도 어느 하나의 절차를 수행하기 위해서, 인 공지능(artificial intelligence; 이하, AI) 프로세서를 포함할 수 있다. AI 프로세서는 미리 저장된 프로그램 을 이용하여 신경망을 학습할 수 있다. 타겟 차량 및 위험 차량을 검출하기 위한 신경망은 인간의 뇌 구조를 컴 퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데이터를 주고 받을 수 있다. 신경망은 신경망 모델 에서 발전한 딥러닝 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고받을 수 있다. 신경망 모델의 예는 심층 신 경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망 (RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신(RBM, Restricted Boltzmann Machine), 심층 신뢰 신경 망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함할 수 있다. 메모리는 프로세서의 동작을 위한 알고리즘 및 AI 프로세서를 저장할 수 있다. 메모리는 하드 디스크 드라이브, 플래시 메모리, EEPROM(Electrically erasable programmable read-only memory), SRAM(Static RAM), FRAM (Ferro-electric RAM), PRAM (Phase-change RAM), MRAM(Magnetic RAM), DRAM(Dynamic Random Access Memory), SDRAM(Synchronous Dynamic Random Access Memory), DDR-SDRAM(Double Date Rate- SDRAM) 등을 이용할 수 있다. 구동 제어기는 프로세서로부터의 제어 신호에 응답하여 차량의 조향 및 감가속을 제어하기 위한 것으 로, 조향 제어기, 엔진 제어기, 제동 제어기 및 변속 제어기(Transmission Control Module)를 포함할 수 있다. 조향 제어기는 유압펌프에 의해 형성된 유압을 이용하여 조향을 제어하는 유압식 조향(HPS; Hydraulic Power Steering) 시스템 및 전동모터의 출력 토크를 이용하여 조향을 제어하는 전동식 조향(MDPS; Motor Driven Power Steering System, 이하 'MDPS'라 함)으로 구분될 수 있다. 엔진 제어기는 차량의 엔진을 제어하는 액추에이터로, 차량의 가속을 제어한다. 엔진 제어기는 EMS(Engine Management System)으로 구현될 수 있다. 엔진 제어기는 가속 페달 위치 센서로부터 출력되는 가속 페달 위치 정보에 따라 엔진의 구동토크를 제어한다. 엔진 제어기는 자율주행시 또는 주행보조조장치에 따른 주행시 프 로세서로부터 요청받은 차량의 주행속도를 추종하기 위해 엔진 출력을 제어한다. 제동 제어기는 차량의 감속을 제어하는 액추에이터로, 전자식 주행 안정화 컨트롤(Electronic Stability Control, ESC)로 구현될 수 있다. 제동 제어기는 프로세서로부터 요청받은 목표 속도를 추종하기 위해 제동 압력을 제어한다. 즉, 제동 제어기는 차량의 감속을 제어한다. 변속 제어기는 차량의 변속기를 제어하기 위한 액추에이터로, 전기식 시프터(Shift By Wire, SBW)로 구현될 수 있다. 변속 제어기는 기어 위치 및 기어 상태 범위에 따라 차량의 변속을 제어한다. 통신부는 사용자 단말기, 다른 차량 또는 외부 서버와 통신을 수행할 수 있고, 기상 정보 또는 주변 차량 들의 차량 정보를 수신할 수 있다. 통신부는 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless- Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 근 거리 통신을 지원할 수 있다. 통신부는 위치 정보를 획득하기 위한 GPS(Global Positioning System) 모듈 또는 DGPS(Differential Global Positioning System) 모듈을 포함할 수 있다. 또한 통신부는 V2X 통신 모듈을 포함할 수 있다. V2X 통신 모듈은 서버(Vehicle to Infra; V2I), 타 차량 (Vehicle to Vehicle; V2V) 또는 보행자(Vehicle to Pedestrian; V2P)와의 무선 통신 프로토콜을 위한 RF 회로 를 포함할 수 있다. 통신부는 V2X 통신 모듈을 통해서, 다른 차량의 센서부가 획득한 센싱 데이터를 수신 하고, 이를 프로세서에 제공할 수 있다. 알림부는 프로세서에 의한 차량 추적 상황 및 차량 회피 상황을 탑승자에게 알릴 수 있다. 알림부 는 디스플레이, 스피커 등을 포함할 수 있다. 도 3은 본 발명의 실시 예에 의한 객체 추적 방법을 설명하기 위한 순서도이다. 도 3에 도시된 절차들은 도 1에 도시된 프로세서에 의해서 수행될 수 있다. 이하, 도 1 내지 도 3을 바탕으로 본 발명의 실시 예에 의한 객체 추적 방법을 살펴보면 다음과 같다. S310에서, 프로세서는 차량 외부의 주변 정보를 바탕으로, 격자 지도를 생성할 수 있다. 이를 위해서, 프로세서는 센서부가 획득한 출력값을 제공받을 수 있다. 또는, 프로세서는 통신 부를 통해서 차량(VEH)의 외부로부터 차량이 주행하는 지역의 정밀 지도를 제공받을 수 있다. 프로세서는 차량 외부의 주변 정보를 바탕으로, 탑-뷰 이미지 형식의 격자 지도를 생성할 수 있다. S320에서, 프로세서는 격자 지도를 딥러닝하여 분류 객체를 획득할 수 있다. 이를 위해서 프로세서는 이미지 학습을 위한 딥러닝 네트워크를 이용할 수 있다. 프로세서는 딥러닝 네트워크의 출력으로 분류 객체를 둘러싸는 바운딩 박스 및 바운딩 박스에 매칭되는 클 래스를 획득할 수 있다. 또한, 프로세서는 분류 객체의 속도 정보를 획득할 수 있다. 분류 객체의 속도 정 보는 동적 격자 지도의 속도 예측 정보를 이용할 수 있다. S330에서, 프로세서는 격자 지도에서 점유 격자를 검출하고, 점유 격자의 군집화를 바탕으로 격자 객체를 획득할 수 있다. 프로세서는 격자에 객체가 존재할 점유 확률을 바탕으로 점유 격자를 추출할 수 있다. 또한, 프로세서 는 점유 격자와 인접한 하나 이상의 주변 격자를 추출할 수 있다. 또한, 프로세서는 점유 격자 및 주 변 격자를 포함하는 격자 객체를 획득할 수 있다. S340에서, 프로세서는 분류 객체와 격자 객체를 융합하여 객체를 추적할 수 있다. 프로세서는 격자 객체가 차지하는 군집 영역을 계산할 수 있다. 또한, 프로세서는 바운딩 박스의 영 역과 군집 영역 간의 중첩 영역을 계산할 수 있다. 프로세서는 군집 영역에 대비한 중첩 영역의 크기가 미 리 설정된 임계값 이상인 것을 바탕으로, 분류 객체와 격자 객체를 동일한 객체로 판단할 수 있다. 이하, 본 발명의 다른 실시 예에 의한 객체 추적 방법 및 각각의 절차들에 대한 세부적인 실시 예를 살펴보면 다음과 같다. 도 4는 본 발명의 다른 실시 예에 의한 객체 추적 방법을 설명하기 위한 순서도이다. 도 5 내지 도 14들은 도 4 에 도시된 세부적인 절차들을 설명하기 위한 도면들이다. 도 4에 도시된 절차들은 도 1에 도시된 프로세서에 의 해서 수행될 수 있다. 이하, 도 4 내지 도 14를 참조하여, 본 발명의 다른 실시 예에 의한 객체 추적 방법을 살 펴보면 다음과 같다. S401에서, 프로세서는 주변 정보를 바탕으로, 격자 지도를 생성할 수 있다. 프로세서는 주변 정보를 제공받을 수 있다. 주변 정보는 카메라, 라이다, 레이더 등이 획 득한 센싱 데이터일 수 있다. 또한, 주변 정보는 통신부를 통해서 수신된 정밀 지도일 수 있다. 프로세서 는 주변 정보를 바탕으로 격자 지도를 생성할 수 있다. 도 5는 격자 지도의 일례를 나타내는 도면이다. 도 5를 참조하면, 프로세서는 센서부의 출력값을 독립된 격자에 표현할 수 있다. 각각의 격자들은 객 체의 점유 확률에 따라 구분될 수 있다. 예를 들어, 비점유 격자는 점유 확률이 제1 임계 확률 미만인 격자일 수 있고, 점유 격자는 점유 확률이 제2 임계 확률 이상인 격자일 수 있다. 알 수 없는 격자는 점유 확률이 제1 임계 확률 이상이며 제2 임계 확률 미만인 격자일 수 있다. 제2 임계 확률은 제1 임계 확률 보다 큰 크기로 설 정될 수 있다. 격자 지도에서 각각의 격자들은 서로 독립적인 정보를 포함하고 있으며, 격자들의 정보는 프레임마다 갱신될 수 있다. 도 6 및 도 7은 격자 지도의 일례를 나타내는 도면들이다. 도 6은 점유 확률을 격자 지도로 표현한 것을 나타내 는 도면이고, 도 7은 비점유 확률을 격자 지도로 표현한 것을 나타내는 도면이다. 도 6 및 도 7을 참조하면, 프로세서는 점유 확률 또는 비점유 확률을 격자 지도로 표현할 수 있다. 점유 확률 또는 비점유 확률은 센서부의 측정 모델을 바탕으로 획득될 수 있다. 또한, 프로세서는 격자 속력을 표현한 격자 지도 형태를 생성할 수 있다. 격자 속력은 파티클 필터를 이용 하여 획득한 동적 격자 지도의 결과일 수 있다. 또한, 프로세서는 격자 최대 높이를 표현한 격자 지도를 생성할 수도 있다. 격자 최대 높이는 격자에 존재 하는 가장 높은 객체 높이를 의미할 수 있으며, 센서부의 센싱 결과를 바탕으로 획득될 수 있다. 또한, 프로세서는 격자 최소 높이를 표현한 격자 지도를 생성할 수도 있다. 격자 최소 높이는 격자에 존재 하는 가장 낮은 객체 높이를 의미할 수 있으며, 센서부의 센싱 결과를 바탕으로 획득될 수 있다. S402에서, 프로세서는 관심 영역을 설정할 수 있다. 관심 영역은 객체 추적 영역을 한정하는 것일 수 있다. 예를 들어, 관심 영역은 도로, 교차로, 보도와 같은 차 량 및 보행자가 출몰할 수 있는 영역 및 차량 운행을 보조하는 시설물이 설치될 수 있는 영역을 포함할 수 있다. S403에서, 프로세서는 딥러닝 기반으로 분류 객체를 획득할 수 있다. 프로세서는 이미지 데이터인 격자 지도를 학습하기 위해서, 이미지 학습용 네트워크를 이용할 수 있다. 예 를 들어, 프로세서는 SSD(Single Shot multibox Detector) 모델 또는 YOLO(You Only Look Once) 모델을 이용할 수 있다. 도 8은 SSD 모델을 이용하여 획득한 분류 객체들의 일례를 나타내는 도면이다. 도 8을 참조하면, 프로세서는 SSD 모델을 이용하여 CAR와 같은 분류 객체를 획득할 수 있다. 이를 위해서 SSD 모델은 복수의 특성 맵에서 각 셀마다 서로 다른 디폴트 박스(Default box)를 생성하고, 디폴트 박스를 이 용하여 객체를 인식할 수 있다. S404에서, 프로세서는 분류 객체를 추적할 수 있다. 분류 객체를 추적하는 일례를 도 9를 참조하여 살펴보 면 다음과 같다. 도 9는 분류 객체를 추적하는 방법을 설명하는 도면이다. 도 9를 참조하면, 프로세서는 동적 격자 지도를 생성하는 과정에서 각 격자들의 속도 정보를 바탕으로 분 류 객체들을 추적할 수 있다. 점유 격자들 각각은 x축 방향의 속력 성분인 Vx와 y축 방향의 속력 성분인 Vy를 포함할 수 있다. 이를 바탕으로, 프로세서는 분류 객체들의 이동 방향 및 속력을 계산할 수 있고, 분류 객체의 이동을 예측할 수 있다. 또한, 프로세서는 예측된 분류 객체의 위치 및 실제 검출된 분류 객체의 위치를 바탕으로 분류 객체 를 추적할 수 있다. S405에서, 프로세서는 격자 정보를 바탕으로 격자 객체를 획득할 수 있다. 격자 객체를 획득하는 방법을 도 10을 참조하여 설명하면 다음과 같다. 도 10은 격자 객체를 획득하는 방법을 설명하는 도면이다. 도 10을 참조하면, 프로세서는 격자들의 점유 확률을 바탕으로 점유 격자를 검출할 수 있다. 점유 격자를 검출하는 방법은 도 5에 도시된 실시 예를 이용할 수 있다. 프로세서는 점유 격자와 인접한 주변 격자들을 검출할 수 있다. 그리고 프로세서는 점유 격자와 주변 격자를 포함하는 격자 객체를 검출할 수 있다. 서로 맞닿는 격자 객체는 동일한 객체로 추정될 수 있다. 또한, 프로세서는 서로 맞닿는 하나의 군집 상태의 격자들일지라도 속도가 다른 격자들은 서로 다른 격자 객체로 구분할 수 있다. 즉, 프로세서는 격자 객체에 포함되는 격자들 각각의 속도를 판단하고, 속도가 다 른 격자들은 서로 다른 격자 객체로 구분할 수 있다. S406에서, 프로세서는 격자 객체를 추적할 수 있다. 도 11은 격자 객체의 추적 방법을 설명하는 도면이다. 도 11을 참조하여, 격자 객체의 추적 방법을 살펴보면 다음과 같다. S1에서, 프로세서는 제(n-1) 프레임(n은 자연수)에서 점유 격자를 포함하는 격자 객체의 ID를 확인할 수 있다. 프로세서는 신규 격자 객체에 대해서는 신규 ID를 부여할 수 있다. 도 11은 ID가 1로 부여된 격자 객체를 도시하고 있다. 프로세서는 격자 객체 영역 내에서 추격점(tracking point; TP)을 결정할 수 있다. 추격점(TP)은 점유 격자 중에서 선택될 수 있고, 점유 격자들의 꼭지점에 대응하는 포인트일 수 있다. S2에서, 프로세서는 추격점(TP)의 예측점을 계산할 수 있다. 프로세서는 점유 격자의 속도 정보를 바탕으로 예측점을 계산할 수 있다. 또한, 프로세서는 예측점을 중심으로 하는 유효범위를 계산할 수 있다. 유효범위는 예측점을 중심으로 하는 원(circle)일 수 있다. 유효 범위는 추격점의 이동방향을 장축으로 하는 타원형일 수 있다. S3에서, 프로세서는 제n 프레임에서 격자 객체들의 추격점들(TP1, TP2, TP3, TP4)을 획득할 수 있다. 그리 고, 프로세서는 복수의 추격점들(TP1, TP2, TP3, TP4) 중에서 유효범위 내에 속하는 추격점들(TP1, TP2)을 추출할 수 있다. 프로세서는 유효범위 내에 속하는 추격점들 중에서 예측점과 가장 가까운 추격점(TP1)을 ID가 1로 부여된 격자 객체의 추격점으로 판단할 수 있다. 즉, 프로세서는 제n 프레임에서 획득된 추격점 (TP1)이 제(n-1) 프레임에서 획득된 추격점(TP)이 이동한 것으로 판단할 수 있다. 따라서, 프로세서는 추 격점(TP1)에 대응하는 격자 객체의 ID를 1로 유지할 수 있다. S407에서, 프로세서는 추적 결과를 융합할 수 있다. 도 12 내지 도 14를 참조하여, 추적 결과를 융합하는 방법을 살펴보면 다음과 같다. 도 12는 바운딩 박스 영역을 나타내는 도면이다. 도 12를 참조하면, 프로세서는 바운딩 박스(Bbox)의 꼭지점(bp)들을 획득할 수 있다. 바운딩 박스(Bbox)의 꼭지점(bp)들 각각은 하나의 격자일 수 있다. 도 13은 군집 영역을 나타내는 도면이다. 도 13을 참조하며, 군집 영역은 격자 객체를 둘러싸는 볼록 껍질(CH) 내부 영역을 의미할 수 있다. 군집 영역을 구성하는 군집 포인트(cp)들은 격자 단위일 수 있다. 즉, 하나의 군집 포인트(cp)는 하나의 격자일 수 있다. 볼록 껍질(CH)은 볼록 껍질 알고리즘(convex hull algorithm)을 이용하여 획득될 수 있다. 도 14는 바운딩 박스 영역과 군집 영역 간의 교차 영역을 계산하는 방법을 설명하기 위한 도면이다. 도 14에 도 시된 각각의 포인트들은 격자일 수 있다. 도 14를 참조하면, 프로세서는 군집 영역의 볼록 껍질(CH)에 속하는 경계 포인트(Pconv.)들을 획득할 수 있다. 경계 포인트(Pconv.)들은 볼록 껍질(CH) 상에 위치한 격자들일 수 있다. 프로세서는 군집 영역의 면적을 계산할 수 있다. 프로세서는 경계 포인트(Pconv.)들 내부에 포함되는 격자의 개수를 바탕으로 군집 영역의 면적을 계산할 수 있다. 프로세서는 바운딩 박스(Bbox)와 볼록 껍질(CH)의 교차 포인트(Pinter.)를 획득할 수 있다. 그리고, 프로세서는 경계 포인트(Pconv.)들 중에서 바운딩 박스(Bbox) 내부에 위치하는 하나 이상의 제1 내부 포인트(Pinbox)들을 획득할 수 있다. 프로세서는 바운딩 박스(Bbox)의 꼭지점(bp)에 해당하는 격자들 중에서 볼록 껍질 내부에 위치한 하나 이 상의 제2 내부 포인트(Pinconv.)들을 획득할 수 있다. 프로세서는 교차 포인트(Pinter.), 제1 내부 포인트(Pinbox), 및 제2 내부 포인트(Pinconv.)를 잇는 영역 을 중첩 영역으로 결정할 수 있다. 프로세서는 군집 영역에 대비한 중첩 영역의 크기가 임계값 이상인 것을 바탕으로, 분류 객체와 격자 객체 가 서로 동일한 객체라고 판단할 수 있다. 즉, 프로세서는 다음의 [수학식 1]에 표현된 조건을 성립될 경 우, 분류 객체와 점유 객체가 동일한 객체라고 판단할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0120567", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 프로세서는 격자 객체의 중점(center_p)을 획득하고, 격자 객체의 중점(center_p)을 이용하여 객체 를 추적할 수 있다. S408에서, 프로세서는 추적 결과를 바탕으로 구동 제어기를 제어할 수 있다. 도 15는 본 발명의 실시 예에 의한 객체 추적 방법의 일례를 설명하기 위한 도면이다. 도 15를 참조하면, 프로세서는 주변 정보를 바탕으로 생성된 탑-뷰 이미지 형식의 격자 지도를 딥러닝하여 바운딩 박스를 획득할 수 있다. 바운딩 박스들 각각은 분류 객체를 나타내는 것일 수 있다. 그리고, 프로세서 는 바운딩 박스들을 추적할 수 있다. 본 발명의 실시 예에 의하면, 프로세서는 이미지 형식의 동적 격자 지도를 학습하기 때문에, 동적 격자 지도의 속도 정보를 활용하여 바운딩 박스로 검출된 객체들의 이동 위 치를 예측하고, 예측된 위치와 측정된 위치를 비교하여 보다 정확하게 객체 추적을 수행할 수 있다. 프로세서는 격자 지도에서 점유 격자를 추출하고, 점유 격자를 군집화하여 격자 객체를 획득할 수 있다. 또한, 프로세서는 격자 격체들을 추적할 수 있다. 본 발명의 실시 예에 의하면, 프로세서는 격자 객 체들의 격자 정보에 포함되는 속도 정보를 바탕으로, 격자 객체들의 위치를 예측할 수 있다. 그리고, 프로세서 는 예측된 격자 객체와 측정된 격자 객체를 일치시켜서, 보다 정확하게 객체 추적을 수행할 수 있다. 프로세서는 분류 객체들과 격자 객체들의 추적 정보를 융합하여, 보다 정확한 객체 인식을 수행할 수 있다. 도 16은 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 도시한다. 도 16을 참조하면, 컴퓨팅 시스템은 버스를 통해 연결되는 적어도 하나의 프로세서, 메모리 , 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치, 스토리지, 및 네트워 크 인터페이스를 포함할 수 있다. 프로세서는 중앙 처리 장치(CPU) 또는 메모리 및/또는 스토리지에 저장된 명령어들에 대한 처리를 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 종류의 휘발성 또는 불휘발 성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(Read Only Memory) 및 RAM(Random Access Memory)을 포함할 수 있다. 따라서, 본 명세서에 개시된 실시 예들과 관련하여 설명된 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM과 같은 저장 매체(즉, 메모리 및/또는 스토리지)에 상주할 수도 있다. 예시적인 저장 매체는 프로세서에 커플링되며, 그 프로세서는 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 저장 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 저장 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수 도 있다. 다른 방법으로, 프로세서 및 저장 매체는 사용자 단말기 내에 개별 컴포넌트로서 상주할 수도 있다.이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아 래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0120567", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 의한 객체 추적 장치 및 이를 포함한 차량 제어 장치의 구성을 나타내는 블록도이 다. 도 2는 본 발명의 실시 예에 의한 객체 추적 장치의 센서부가 장착된 차량을 나타내는 도면이다. 도 3은 본 발명의 실시 예에 의한 객체 추적 방법을 설명하기 위한 순서도이다. 도 4는 본 발명의 다른 실시 예에 의한 객체 추적 방법을 설명하기 위한 순서도이다. 도 5는 격자 지도의 일례를 나타내는 도면이다. 도 6은 점유 확률을 격자 지도로 표현한 것을 나타내는 도면이다. 도 7은 비점유 확률을 격자 지도로 표현한 것을 나타내는 도면이다. 도 8은 SSD 모델을 이용하여 획득한 분류 객체들의 일례를 나타내는 도면이다. 도 9는 분류 객체를 추적하는 방법을 설명하는 도면이다. 도 10은 격자 객체를 획득하는 방법을 설명하는 도면이다. 도 11은 격자 객체의 추적 방법을 설명하는 도면이다. 도 12는 바운딩 박스 영역을 나타내는 도면이다. 도 13은 군집 영역을 나타내는 도면이다. 도 14는 바운딩 박스 영역과 군집 영역 간의 교차 영역을 계산하는 방법을 설명하기 위한 도면이다. 도 15는 본 발명의 실시 예에 의한 객체 추적 방법의 일례를 설명하기 위한 도면이다. 도 16은 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 나타내는 도면이다."}
