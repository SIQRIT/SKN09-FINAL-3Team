{"patent_id": "10-2022-7038636", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0168258", "출원번호": "10-2022-7038636", "발명의 명칭": "이미지 처리 방법 및 장치, 컴퓨터 기기, 저장 매체 그리고 프로그램 제품", "출원인": "텐센트 테크놀로지", "발명자": "뤄 위천"}}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 기기에 의해 수행되는 이미지 처리 방법으로서, 수신된 얼굴 변경 요청에 응답하여 소스 이미지(source image)의 식별 특징(identity feature) 및 타깃 이미지(target image)의 하나 이상의 스케일의 초기 속성 특징(attribute feature)을 취득하는 단계 - 상기 얼굴 변경 요청은 상기 타깃 이미지에서의 타깃 얼굴을 상기 소스 이미지에서의 소스 얼굴로 교체하도록 요청하는 데사용되고, 상기 식별 특징은 상기 소스 얼굴이 속한 객체를 나타내고, 상기 초기 속성 특징은 상기 타깃 얼굴의3차원 속성을 나타냄 -; 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하는 단계; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융합을 반복적으로 수행하여 융합 특징을 획득하는 단계; 및 상기 얼굴 변경 모델을 사용하여 상기 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 상기 타깃 얼굴변경 이미지를 출력하는 단계 - 상기 타깃 얼굴 변경 이미지에서의 얼굴은 상기 소스 얼굴의 식별 특징 및 상기타깃 얼굴의 타깃 속성 특징과 융합됨 -를 포함하는 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 얼굴 변경 모델은 각각이 하나의 스케일에 대응하는 하나 이상의 컨볼루션 계층(convolutional layer)을포함하고; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융합을 반복적으로 수행하여 융합 특징을 획득하는 단계는, 상기 얼굴 변경 모델의 각각의 컨볼루션 계층을 사용하여 상기 식별 특징과 대응하는 스케일의 초기 속성 특징에 대해, 현재 컨볼루션 계층의 이전 컨볼루션 계층에 의해 출력되는 제1 특징 맵(feature map)을 취득하는 처리; 상기 식별 특징 및 상기 제1 특징 맵에 기초하여 제2 특징 맵을 생성하고, 상기 하나 이상의 스케일의 초기 속성 특징으로부터 타깃 속성 특징을 선택하는 처리 - 상기 타깃 속성 특징은 상기 타깃 얼굴의 식별 특징 이외의특징임 -; 상기 타깃 속성 특징 및 상기 제2 특징 맵에 기초하여 제3 특징 맵을 생성하는 처리 - 상기 제3 특징 맵은 상기현재 컨볼루션 계층의 다음 컨볼루션 계층의 제1 특징 맵임 -; 및 상기 하나 이상의 컨볼루션 계층 중 마지막 컨볼루션 계층에 의해 출력되는 제3 특징 맵을 융합 특징으로 결정하는 처리를 개별적으로 수행하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 하나 이상의 스케일의 초기 속성 특징으로부터 타깃 속성 특징을 선택하는 처리는, 상기 제2 특징 맵 및 상기 초기 속성 특징에 기초하여 대응하는 스케일에서 상기 타깃 이미지의 제어 마스크(control mask)를 결정하는 처리 - 상기 제어 마스크는 상기 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는픽셀을 표현하는 데 사용됨 -; 및 공개특허 10-2023-0168258-3-상기 제어 마스크에 기초하여 상기 하나 이상의 스케일의 초기 속성 특징을 스크리닝하여 상기 타깃 속성 특징을 획득하는 처리를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제2 특징 맵 및 상기 초기 속성 특징에 기초하여 대응하는 스케일에서 상기 타깃 이미지의 제어 마스크를결정하는 처리는, 상기 제2 특징 맵과 상기 초기 속성 특징에 대해 특징 연결(feature concatenation)을 수행하여 연결된 특징 맵을 획득하는 처리; 및 미리 구성된 매핑 컨볼루션 커널(mapping convolution kernel) 및 활성화 함수에 기초하여 상기 연결된 특징 맵을 상기 제어 마스크에 매핑하는 처리를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 초기 속성 특징과 컨볼루션 계층의 수량은 모두 타깃 수량이고, 상기 타깃 수량의 컨볼루션 계층은 직렬로연결되고, 서로 다른 초기 속성 특징은 서로 다른 스케일에 대응하고, 각각의 컨볼루션 계층은 하나의 스케일의초기 속성 특징에 대응하고, 상기 타깃 수량은 2 이상이며; 상기 현재 컨볼루션 계층의 이전 컨볼루션 계층에 의해 출력되는 제1 특징 맵을 취득하는 처리는, 상기 현재 컨볼루션 계층이 상기 타깃 수량의 컨볼루션 계층 중 첫 번째 컨볼루션 계층인 경우 초기 특징 맵을취득하고, 상기 초기 특징 맵을 상기 현재 컨볼루션 계층에 입력되는 제1 특징 맵으로 사용하는 처리를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 식별 특징 및 상기 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 처리는, 상기 식별 특징에 대해 아핀 변환을 수행하여 제1 제어 벡터를 획득하는 처리; 상기 제1 제어 벡터에 기초하여 상기 현재 컨볼루션 계층의 제1 컨볼루션 커널을 제2 컨볼루션 커널에 매핑하는처리; 및 상기 제2 컨볼루션 커널에 기초하여 상기 제1 특징 맵에 대해 컨볼루션 연산을 수행하여 제2 특징 맵을 생성하는 처리를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하는 단계 전에, 상기이미지 처리 방법은, 샘플 이미지 쌍에서 샘플 소스 이미지의 샘플 식별 특징 및 샘플 타깃 이미지의 하나 이상의 스케일의 샘플 초기 속성 특징을 취득하는 단계; 초기 얼굴 변경 모델의 생성기를 사용하여 상기 샘플 식별 특징 및 상기 하나 이상의 스케일의 샘플 초기 속성특징에 대해 특징 융합을 반복적으로 수행하여 샘플 융합 특징을 획득하는 단계; 상기 초기 얼굴 변경 모델의 생성기를 사용하여 상기 샘플 융합 특징에 기초한 샘플 생성 이미지를 생성하는 단계; 상기 초기 얼굴 변경 모델의 판별기(discriminator)를 사용하여 상기 샘플 생성 이미지와 상기 샘플 소스 이미지를 판별하여 판별 결과를 획득하는 단계; 및 공개특허 10-2023-0168258-4-상기 판별 결과에 기초하여 상기 초기 얼굴 변경 모델의 손실을 결정하고, 상기 손실에 기초하여 상기 초기 얼굴 변경 모델을 훈련시켜 상기 얼굴 변경 모델을 획득하는 단계를 더 포함하는 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 판별 결과는 샘플 소스 이미지에 대한 제1 판별 결과 및 상기 샘플 생성 이미지에 대한 제2 판별 결과를포함하고; 상기 판별 결과에 기초하여 상기 초기 얼굴 변경 모델의 손실을 결정하는 단계는, 상기 샘플 타깃 이미지의 하나 이상의 스케일의 샘플 마스크를 취득하고, 상기 하나 이상의 스케일의 샘플 마스크에 기초하여 제1 손실 값을 결정하는 단계; 상기 제1 판별 결과 및 상기 제2 판별 결과에 기초하여 제2 손실 값을 결정하는 단계; 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하는 단계; 및 타깃 조건이 충족되고 훈련이 중지될 때까지 상기 총 훈련 손실에 기초하여 상기 초기 얼굴 변경 모델을 훈련하여 상기 얼굴 변경 모델을 획득하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 샘플 소스 이미지와 상기 샘플 타깃 이미지는 동일한 객체에 대응하고; 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하는 단계는, 상기 샘플 생성 이미지 및 상기 샘플 타깃 이미지에 기초하여 제3 손실 값을 취득하는 단계; 및 상기 제3 손실 값, 상기 제1 손실 값 및 상기 제2 손실 값에 기초하여 상기 총 훈련 손실을 획득하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 판별기는 하나 이상의 컨볼루션 계층을 포함하고; 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련손실을 획득하는 단계는, 제1 판별 특징 맵의 비얼굴 영역과 제2 판별 특징 맵의 비얼굴 영역 사이의 제1 유사도를 결정하는 단계 - 상기제1 판별 특징 맵은 상기 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 타깃 이미지의 특징 맵이고, 상기 제2 판별 특징 맵은 상기 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 생성 이미지의 특징 맵임 -;제3 판별 특징 맵과 제4 판별 특징 맵 사이의 제2 유사도를 결정하는 단계 - 상기 제3 판별 특징 맵은 컨볼루션계층의 제2 부분에 의해 출력되는 샘플 타깃 이미지의 특징 맵이고, 상기 제4 판별 특징 맵은 상기 컨볼루션 계층의 제2 부분에 의해 출력되는 샘플 생성 이미지의 특징 맵임 -; 상기 제1 유사도 및 상기 제2 유사도에 기초하여 제4 손실 값을 결정하는 단계; 및 상기 제1 손실 값, 상기 제2 손실 값 및 상기 제4 손실 값에 기초하여 상기 총 훈련 손실을 획득하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하는 단계는, 상기 샘플 소스 이미지의 제1 식별 특징, 상기 샘플 타깃 이미지의 제2 식별 특징 및 상기 샘플 생성 이미지의제3 식별 특징을 추출하는 단계; 상기 제1 식별 특징 및 상기 제3 식별 특징에 기초하여 상기 샘플 소스 이미지와 상기 샘플 생성 이미지 사이의제1 식별 유사도(identity similarity)를 결정하는 단계; 공개특허 10-2023-0168258-5-상기 제2 식별 특징 및 상기 제3 식별 특징에 기초하여 상기 샘플 생성 이미지와 상기 샘플 타깃 이미지 사이의제1 식별 거리(identity distance)를 결정하는 단계; 상기 제1 식별 특징 및 상기 제2 식별 특징에 기초하여 상기 샘플 소스 이미지와 상기 샘플 타깃 이미지 사이의제2 식별 거리를 결정하는 단계; 상기 제1 식별 거리 및 상기 제2 식별 거리에 기초하여 거리 차이를 결정하는 단계; 상기 제1 식별 유사도 및 상기 거리 차이에 기초하여 제5 손실 값을 결정하는 단계; 및상기 제1 손실 값, 상기 제2 손실 값 및 상기 제5 손실 값에 기초하여 총 훈련 손실을 획득하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "이미지 처리 장치로서, 특징 취득 모듈 및 얼굴 변경 모듈을 포함하고,상기 특징 취득 모듈은, 수신된 얼굴 변경 요청에 응답하여 소스 이미지의 식별 특징 및 타깃 이미지의 하나 이상의 스케일의 초기 속성특징을 취득하도록 구성되고; 상기 얼굴 변경 요청은 상기 타깃 이미지에서의 타깃 얼굴을 상기 소스 이미지에서의 소스 얼굴로 교체하도록요청하는 데 사용되고, 상기 식별 특징은 상기 소스 얼굴이 속한 객체를 나타내고, 상기 초기 속성 특징은 상기타깃 얼굴의 3차원 속성을 나타내며; 상기 얼굴 변경 모듈은, 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하고; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융합을 반복적으로 수행하여 융합 특징을 획득하고; 상기 얼굴 변경 모델을 사용하여 상기 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 상기 타깃 얼굴변경 이미지를 출력하도록 구성되며, 상기 타깃 얼굴 변경 이미지에서의 얼굴은 상기 소스 얼굴의 식별 특징 및 상기 타깃 얼굴의 타깃 속성 특징과융합되는, 이미지 처리 장치."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "메모리 및 프로세서를 포함하는 컴퓨터 기기로서, 상기 메모리는 컴퓨터 프로그램을 저장하도록 구성되고;상기 프로세서는 상기 메모리에 저장된 컴퓨터 프로그램을 실행하여, 제1항 내지 제11항 중 어느 한 항에 따른이미지 처리 방법을 수행하도록 구성되는, 컴퓨터 기기."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 프로그램을 저장하는, 컴퓨터로 판독 가능한 저장 매체로서, 상기 컴퓨터 프로그램은 프로세서에 의해 실행될 때, 제1항 내지 제11항 중 어느 한 항에 따른 이미지 처리 방법을 구현하는, 컴퓨터로 판독 가능한 저장 매체."}
{"patent_id": "10-2022-7038636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2023-0168258-6-컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램은 프로세서에 의해 실행될 때, 제1항 내지 제11항 중 어느 한 항에 따른 이미지 처리 방법을 수행하는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 이미지 처리 방법 및 장치, 컴퓨터 기기, 저장 매체 그리고 프로그램 제품을 제공하며, 인공 지능, 기 계 학습 및 지능형 교통과 같은"}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 얼굴 변경 요청에 응답하여, 소스 이미지의 식별 특징 과 타깃 이미지의 하나 이상의 스케일의 초기 속성 특징이 얼굴 변경 모델에 입력되고 - 상기 얼굴 변경 요청은 상기 타깃 이미지에서의 타깃 얼굴을 상기 소스 이미지에서의 소스 얼굴로 변경하도록 요청하는 데 사용됨 -; 융 합 특징을 획득하기 위해 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융합이 반복적으로 수행된다. 상기 얼굴 변경 모델을 사용하여 상기 융합 특징에 기초한 타깃 얼굴 변경 이미지가 생성되고, 상기 타깃 얼굴 변경 이미지가 출력된다. 상기 타깃 얼굴 변경 이미지에서 얼굴은 상기 소스 얼굴의 식별 특징 및 상기 타깃 얼굴의 타깃 속성 특징과 융합된다. 대 표 도 - 도2"}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2023-0168258 CPC특허분류 G06N 3/08 (2023.01) G06T 3/0006 (2013.01) G06T 3/4038 (2013.01) G06T 3/4046 (2013.01) G06T 2207/20081 (2013.01) G06T 2207/30201 (2013.01) 발명자 허 커커 중국 518057 광동 센젠 난산 디스트릭트 미드웨스 트 디스트릭트 오브 하이-테크 파크 커지중이 로드 텐센트 빌딩 35층 추 원칭 중국 518057 광동 센젠 난산 디스트릭트 미드웨스 트 디스트릭트 오브 하이-테크 파크 커지중이 로드 텐센트 빌딩 35층타이 잉 중국 518057 광동 센젠 난산 디스트릭트 미드웨스 트 디스트릭트 오브 하이-테크 파크 커지중이 로드 텐센트 빌딩 35층 왕 청제 중국 518057 광동 센젠 난산 디스트릭트 미드웨스 트 디스트릭트 오브 하이-테크 파크 커지중이 로드 텐센트 빌딩 35층명 세 서 청구범위 청구항 1 컴퓨터 기기에 의해 수행되는 이미지 처리 방법으로서, 수신된 얼굴 변경 요청에 응답하여 소스 이미지(source image)의 식별 특징(identity feature) 및 타깃 이미지 (target image)의 하나 이상의 스케일의 초기 속성 특징(attribute feature)을 취득하는 단계 - 상기 얼굴 변 경 요청은 상기 타깃 이미지에서의 타깃 얼굴을 상기 소스 이미지에서의 소스 얼굴로 교체하도록 요청하는 데 사용되고, 상기 식별 특징은 상기 소스 얼굴이 속한 객체를 나타내고, 상기 초기 속성 특징은 상기 타깃 얼굴의 3차원 속성을 나타냄 -; 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하는 단계; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융 합을 반복적으로 수행하여 융합 특징을 획득하는 단계; 및 상기 얼굴 변경 모델을 사용하여 상기 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 상기 타깃 얼굴 변경 이미지를 출력하는 단계 - 상기 타깃 얼굴 변경 이미지에서의 얼굴은 상기 소스 얼굴의 식별 특징 및 상기 타깃 얼굴의 타깃 속성 특징과 융합됨 - 를 포함하는 이미지 처리 방법. 청구항 2 제1항에 있어서, 상기 얼굴 변경 모델은 각각이 하나의 스케일에 대응하는 하나 이상의 컨볼루션 계층(convolutional layer)을 포함하고; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대 해 특징 융합을 반복적으로 수행하여 융합 특징을 획득하는 단계는, 상기 얼굴 변경 모델의 각각의 컨볼루션 계층을 사용하여 상기 식별 특징과 대응하는 스케일의 초기 속성 특징 에 대해, 현재 컨볼루션 계층의 이전 컨볼루션 계층에 의해 출력되는 제1 특징 맵(feature map)을 취득하는 처리; 상기 식별 특징 및 상기 제1 특징 맵에 기초하여 제2 특징 맵을 생성하고, 상기 하나 이상의 스케일의 초기 속 성 특징으로부터 타깃 속성 특징을 선택하는 처리 - 상기 타깃 속성 특징은 상기 타깃 얼굴의 식별 특징 이외의 특징임 -; 상기 타깃 속성 특징 및 상기 제2 특징 맵에 기초하여 제3 특징 맵을 생성하는 처리 - 상기 제3 특징 맵은 상기 현재 컨볼루션 계층의 다음 컨볼루션 계층의 제1 특징 맵임 -; 및 상기 하나 이상의 컨볼루션 계층 중 마지막 컨볼루션 계층에 의해 출력되는 제3 특징 맵을 융합 특징으로 결정 하는 처리 를 개별적으로 수행하는 단계를 포함하는, 이미지 처리 방법. 청구항 3 제2항에 있어서, 상기 하나 이상의 스케일의 초기 속성 특징으로부터 타깃 속성 특징을 선택하는 처리는, 상기 제2 특징 맵 및 상기 초기 속성 특징에 기초하여 대응하는 스케일에서 상기 타깃 이미지의 제어 마스크 (control mask)를 결정하는 처리 - 상기 제어 마스크는 상기 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는 픽셀을 표현하는 데 사용됨 -; 및 상기 제어 마스크에 기초하여 상기 하나 이상의 스케일의 초기 속성 특징을 스크리닝하여 상기 타깃 속성 특징 을 획득하는 처리를 포함하는, 이미지 처리 방법. 청구항 4 제3항에 있어서, 상기 제2 특징 맵 및 상기 초기 속성 특징에 기초하여 대응하는 스케일에서 상기 타깃 이미지의 제어 마스크를 결정하는 처리는, 상기 제2 특징 맵과 상기 초기 속성 특징에 대해 특징 연결(feature concatenation)을 수행하여 연결된 특징 맵 을 획득하는 처리; 및 미리 구성된 매핑 컨볼루션 커널(mapping convolution kernel) 및 활성화 함수에 기초하여 상기 연결된 특징 맵 을 상기 제어 마스크에 매핑하는 처리를 포함하는, 이미지 처리 방법. 청구항 5 제2항에 있어서, 상기 초기 속성 특징과 컨볼루션 계층의 수량은 모두 타깃 수량이고, 상기 타깃 수량의 컨볼루션 계층은 직렬로 연결되고, 서로 다른 초기 속성 특징은 서로 다른 스케일에 대응하고, 각각의 컨볼루션 계층은 하나의 스케일의 초기 속성 특징에 대응하고, 상기 타깃 수량은 2 이상이며; 상기 현재 컨볼루션 계층의 이전 컨볼루션 계층에 의해 출력되는 제1 특징 맵을 취득하는 처리는, 상기 현재 컨볼루션 계층이 상기 타깃 수량의 컨볼루션 계층 중 첫 번째 컨볼루션 계층인 경우 초기 특징 맵을 취득하고, 상기 초기 특징 맵을 상기 현재 컨볼루션 계층에 입력되는 제1 특징 맵으로 사용하는 처리를 포함하 는, 이미지 처리 방법. 청구항 6 제2항에 있어서, 상기 식별 특징 및 상기 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 처리는, 상기 식별 특징에 대해 아핀 변환을 수행하여 제1 제어 벡터를 획득하는 처리; 상기 제1 제어 벡터에 기초하여 상기 현재 컨볼루션 계층의 제1 컨볼루션 커널을 제2 컨볼루션 커널에 매핑하는 처리; 및 상기 제2 컨볼루션 커널에 기초하여 상기 제1 특징 맵에 대해 컨볼루션 연산을 수행하여 제2 특징 맵을 생성하 는 처리를 포함하는, 이미지 처리 방법. 청구항 7 제1항에 있어서, 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하는 단계 전에, 상기 이미지 처리 방법은, 샘플 이미지 쌍에서 샘플 소스 이미지의 샘플 식별 특징 및 샘플 타깃 이미지의 하나 이상의 스케일의 샘플 초 기 속성 특징을 취득하는 단계; 초기 얼굴 변경 모델의 생성기를 사용하여 상기 샘플 식별 특징 및 상기 하나 이상의 스케일의 샘플 초기 속성 특징에 대해 특징 융합을 반복적으로 수행하여 샘플 융합 특징을 획득하는 단계; 상기 초기 얼굴 변경 모델의 생성기를 사용하여 상기 샘플 융합 특징에 기초한 샘플 생성 이미지를 생성하는 단 계; 상기 초기 얼굴 변경 모델의 판별기(discriminator)를 사용하여 상기 샘플 생성 이미지와 상기 샘플 소스 이미 지를 판별하여 판별 결과를 획득하는 단계; 및 상기 판별 결과에 기초하여 상기 초기 얼굴 변경 모델의 손실을 결정하고, 상기 손실에 기초하여 상기 초기 얼 굴 변경 모델을 훈련시켜 상기 얼굴 변경 모델을 획득하는 단계를 더 포함하는 이미지 처리 방법. 청구항 8 제7항에 있어서, 상기 판별 결과는 샘플 소스 이미지에 대한 제1 판별 결과 및 상기 샘플 생성 이미지에 대한 제2 판별 결과를 포함하고; 상기 판별 결과에 기초하여 상기 초기 얼굴 변경 모델의 손실을 결정하는 단계는, 상기 샘플 타깃 이미지의 하나 이상의 스케일의 샘플 마스크를 취득하고, 상기 하나 이상의 스케일의 샘플 마스 크에 기초하여 제1 손실 값을 결정하는 단계; 상기 제1 판별 결과 및 상기 제2 판별 결과에 기초하여 제2 손실 값을 결정하는 단계; 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하는 단계; 및 타깃 조건이 충족되고 훈련이 중지될 때까지 상기 총 훈련 손실에 기초하여 상기 초기 얼굴 변경 모델을 훈련하 여 상기 얼굴 변경 모델을 획득하는 단계를 포함하는, 이미지 처리 방법. 청구항 9 제8항에 있어서, 상기 샘플 소스 이미지와 상기 샘플 타깃 이미지는 동일한 객체에 대응하고; 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하는 단계는, 상기 샘플 생성 이미지 및 상기 샘플 타깃 이미지에 기초하여 제3 손실 값을 취득하는 단계; 및 상기 제3 손실 값, 상기 제1 손실 값 및 상기 제2 손실 값에 기초하여 상기 총 훈련 손실을 획득하는 단계를 포 함하는, 이미지 처리 방법. 청구항 10 제8항에 있어서, 상기 판별기는 하나 이상의 컨볼루션 계층을 포함하고; 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하는 단계는, 제1 판별 특징 맵의 비얼굴 영역과 제2 판별 특징 맵의 비얼굴 영역 사이의 제1 유사도를 결정하는 단계 - 상기 제1 판별 특징 맵은 상기 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 타깃 이미지의 특징 맵이고, 상기 제 2 판별 특징 맵은 상기 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 생성 이미지의 특징 맵임 -; 제3 판별 특징 맵과 제4 판별 특징 맵 사이의 제2 유사도를 결정하는 단계 - 상기 제3 판별 특징 맵은 컨볼루션 계층의 제2 부분에 의해 출력되는 샘플 타깃 이미지의 특징 맵이고, 상기 제4 판별 특징 맵은 상기 컨볼루션 계 층의 제2 부분에 의해 출력되는 샘플 생성 이미지의 특징 맵임 -; 상기 제1 유사도 및 상기 제2 유사도에 기초하여 제4 손실 값을 결정하는 단계; 및 상기 제1 손실 값, 상기 제2 손실 값 및 상기 제4 손실 값에 기초하여 상기 총 훈련 손실을 획득하는 단계를 포 함하는, 이미지 처리 방법. 청구항 11 제8항에 있어서, 상기 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하는 단계는, 상기 샘플 소스 이미지의 제1 식별 특징, 상기 샘플 타깃 이미지의 제2 식별 특징 및 상기 샘플 생성 이미지의 제3 식별 특징을 추출하는 단계; 상기 제1 식별 특징 및 상기 제3 식별 특징에 기초하여 상기 샘플 소스 이미지와 상기 샘플 생성 이미지 사이의 제1 식별 유사도(identity similarity)를 결정하는 단계; 상기 제2 식별 특징 및 상기 제3 식별 특징에 기초하여 상기 샘플 생성 이미지와 상기 샘플 타깃 이미지 사이의 제1 식별 거리(identity distance)를 결정하는 단계; 상기 제1 식별 특징 및 상기 제2 식별 특징에 기초하여 상기 샘플 소스 이미지와 상기 샘플 타깃 이미지 사이의 제2 식별 거리를 결정하는 단계; 상기 제1 식별 거리 및 상기 제2 식별 거리에 기초하여 거리 차이를 결정하는 단계; 상기 제1 식별 유사도 및 상기 거리 차이에 기초하여 제5 손실 값을 결정하는 단계; 및 상기 제1 손실 값, 상기 제2 손실 값 및 상기 제5 손실 값에 기초하여 총 훈련 손실을 획득하는 단계를 포함하 는, 이미지 처리 방법. 청구항 12 이미지 처리 장치로서, 특징 취득 모듈 및 얼굴 변경 모듈을 포함하고, 상기 특징 취득 모듈은, 수신된 얼굴 변경 요청에 응답하여 소스 이미지의 식별 특징 및 타깃 이미지의 하나 이상의 스케일의 초기 속성 특징을 취득하도록 구성되고; 상기 얼굴 변경 요청은 상기 타깃 이미지에서의 타깃 얼굴을 상기 소스 이미지에서의 소스 얼굴로 교체하도록 요청하는 데 사용되고, 상기 식별 특징은 상기 소스 얼굴이 속한 객체를 나타내고, 상기 초기 속성 특징은 상기 타깃 얼굴의 3차원 속성을 나타내며; 상기 얼굴 변경 모듈은, 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하고; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융 합을 반복적으로 수행하여 융합 특징을 획득하고; 상기 얼굴 변경 모델을 사용하여 상기 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 상기 타깃 얼굴 변경 이미지를 출력하도록 구성되며, 상기 타깃 얼굴 변경 이미지에서의 얼굴은 상기 소스 얼굴의 식별 특징 및 상기 타깃 얼굴의 타깃 속성 특징과 융합되는, 이미지 처리 장치. 청구항 13 메모리 및 프로세서를 포함하는 컴퓨터 기기로서, 상기 메모리는 컴퓨터 프로그램을 저장하도록 구성되고; 상기 프로세서는 상기 메모리에 저장된 컴퓨터 프로그램을 실행하여, 제1항 내지 제11항 중 어느 한 항에 따른 이미지 처리 방법을 수행하도록 구성되는, 컴퓨터 기기. 청구항 14 컴퓨터 프로그램을 저장하는, 컴퓨터로 판독 가능한 저장 매체로서, 상기 컴퓨터 프로그램은 프로세서에 의해 실행될 때, 제1항 내지 제11항 중 어느 한 항에 따른 이미지 처리 방 법을 구현하는, 컴퓨터로 판독 가능한 저장 매체. 청구항 15 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램은 프로세서에 의해 실행될 때, 제1항 내지 제11항 중 어느 한 항에 따른 이미지 처리 방 법을 수행하는, 컴퓨터 프로그램 제품. 발명의 설명 기 술 분 야 관련 출원 본 출원은 2022년 6월 2일에 출원된 중국 특허출원 제202210626467.1호 대한 우선권을 주장하며, 그 전체가 참 조에 의해 본 출원에 통합된다. 본 출원은 인공 지능(artificial intelligence, AI), 기계 학습(machine learning) 및 지능형 교통 (intelligent transportation)과 같은 기술 분야에 관한 것으로, 특히 이미지 처리 방법 및 장치, 컴퓨터 기기, 저장 매체 그리고 프로그램 제품에 관한 것이다."}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴 변경(face change)은 컴퓨터 비전 분야에서 중요한 기술이다. 얼굴 변경은 콘텐츠 제작, 비디오 인물 사진 제작, 엔터테인먼트 비디오 제작, 가상 이미지 또는 개인 정보 보호와 같은 시나리오에서 널리 사용된다. 얼굴 변경은 이미지에서 객체의 얼굴을 다른 얼굴로 바꾸는 것을 의미한다. 관련 기술에서, 얼굴 변경은 일반적으로 신경망 모델을 사용하여 구현되는데, 예를 들어 얼굴 변경에 사용되는 신경망 모델에 이미지가 입력되고, 신경망 모델의 출력을 사용하여 이미지에 대한 얼굴 변경을 수행하여 이미지 를 획득한다. 그러나, 관련 기술에서 얼굴 변경 기술을 사용하여 획득되는 이미지는 이상적인 얼굴 변경 후에 획득된 이미지와 비교적 차이가 있으며 얼굴 변경 효과가 좋지 않다. 본 출원의 실시예는 얼굴 변경 후 이미지 품질을 개선할 수 있는 이미지 처리 방법 및 장치, 컴퓨터 기기, 컴퓨 터로 판독 가능한 저장 매체 그리고 컴퓨터 프로그램 제품을 제공한다. 본 출원의 실시예는 이미지 처리 방법을 제공하며, 상기 이미지 처리 방법은, 수신된 얼굴 변경 요청에 응답하여 소스 이미지(source image)의 식별 특징(identity feature) 및 타깃 이미지 (target image)의 하나 이상의 스케일의 초기 속성 특징(attribute feature)을 취득하는 단계 - 상기 얼굴 변 경 요청은 상기 타깃 이미지에서의 타깃 얼굴을 상기 소스 이미지에서의 소스 얼굴로 교체하도록 요청하는 데 사용되고, 상기 식별 특징은 상기 소스 얼굴이 속한 객체를 나타내고, 상기 초기 속성 특징은 상기 타깃 얼굴의 3차원 속성을 나타냄 -; 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하는 단계; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융 합을 반복적으로 수행하여 융합 특징을 획득하는 단계; 및 상기 얼굴 변경 모델을 사용하여 상기 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 상기 타깃 얼굴 변경 이미지를 출력하는 단계 - 상기 타깃 얼굴 변경 이미지에서의 얼굴은 상기 소스 얼굴의 식별 특징 및 상기 타깃 얼굴의 타깃 속성 특징과 융합됨 -를 포함한다. 본 출원의 실시예는 이미지 처리 장치를 더 제공하며, 상기 이미지 처리 장치는 특징 취득 모듈 및 얼굴 변경 모듈을 포함하고, 상기 특징 취득 모듈은, 수신된 얼굴 변경 요청에 응답하여 소스 이미지의 식별 특징 및 타깃 이미지의 하나 이상의 스케일의 초기 속성 특징을 취득하도록 구성되고; 상기 얼굴 변경 요청은 상기 타깃 이미지 내의 타깃 얼굴을 상기 소스 이미지 내의 소스 얼굴로 교체하도록 요 청하는 데 사용되고, 상기 식별 특징은 상기 소스 얼굴이 속한 객체를 나타내고, 상기 초기 속성 특징은 상기 타깃 얼굴의 3차원 속성을 나타내며; 상기 얼굴 변경 모듈은, 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하고; 상기 얼굴 변경 모델을 사용하여 상기 식별 특징 및 상기 하나 이상의 스케일의 초기 속성 특징에 대해 특징 융 합을 반복적으로 수행하여 융합 특징을 획득하고; 상기 얼굴 변경 모델을 사용하여 상기 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 상기 타깃 얼굴 변경 이미지를 출력하도록 구성되며, 상기 타깃 얼굴 변경 이미지에서의 얼굴은 상기 소스 얼굴의 식별 특징 및 상기 타깃 얼굴의 타깃 속성 특징과 융합된다. 본 출원의 일 실시예는 메모리 및 프로세서를 포함하는 컴퓨터 기기를 더 제공하며, 상기 메모리는 컴퓨터 프로그램을 저장하도록 구성되고; 상기 프로세서는 상기 메모리에 저장된 컴퓨터 프로그램을 실행하여, 본 출원의 실시예에서 제공되는 이미지 처 리 방법을 수행하도록 구성된다. 본 출원의 일 실시예는 컴퓨터로 판독 가능한 저장 매체를 더 제공한다. 상기 컴퓨터로 판독 가능한 저장 매체 는 컴퓨터 프로그램을 저장하고, 상기 컴퓨터 프로그램은 프로세서에 의해 실행될 때, 본 출원의 실시예에서 제 공되는 이미지 처리 방법을 구현한다. 본 출원의 일 실시예는 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품을 더 제공하며, 상기 컴퓨터 프로그 램은 프로세서에 의해 실행될 때, 본 출원의 실시예에서 제공되는 이미지 처리 방법을 구현한다. 본 출원의 실시예에서 제공되는 기술적 방안 다음과 같은 유익한 효과를 달성한다: 본 출원의 실시예에서의 이미지 처리 방법에서, 소스 이미지의 식별 특징 및 타깃 이미지의 초기 속성 특징이 얼굴 변경 모델에 입력되고, 식별 특징과 하나 이상의 스케일의 초기 속성 특징은 얼굴 변경 모델을 사용하여 반복적으로 융합되어 융합 특징을 획득한다. 즉, 얼굴 변경 모델의 입력단에서, 식별 특징과 속성 특징에 대해 디스플레이 디커플링(display decoupling)을 수행하여, 획득된 융합 특징이 소스 이미지 내의 객체의 식별 특징 및 타깃 이미지 내의 객체 얼굴의 3차원 속성과 융합되도록 한다. 얼굴 변경 모델을 사용하여 융합 특징에 기초하여 타깃 얼굴 변경 이미지가 생성되고, 타깃 얼굴 변경 이미지가 출력된다. 타깃 얼굴 변경 이미지에서의 얼굴은 소스 얼굴의 식별 특징 및 타깃 얼굴의 대상 속성 특징과 융합 된다. 이러한 방식으로, 특징 융합을 통해 획득된 융합 특징에 기초하여 타깃 얼굴 변경 이미지가 생성되고, 타 깃 얼굴 변경 이미지에서의 얼굴과 소스 이미지에서의 얼굴 사이의 식별 일관성 보장에 기초하여, 타깃 얼굴 변 경 이미지에서의 타깃 얼굴의 속성 및 세부 특징이 효과적으로 보존되어, 얼굴 변경 이미지에서 얼굴의 선명도, 정확도 및 신뢰성(authenticity)이 크게 향상되고, 고화질 얼굴 변경을 구현한다."}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 출원의 실시예에서의 첨부 도면을 참조하여 본 출원의 실시예를 설명한다. 첨부 도면을 참조하여 설명되는 하기 실시예는 본 출원의 실시예에서의 기술적 방안을 설명하기 위해 사용된 예시적인 설명이며, 본 출원의 실시예에서의 기술적 방안은 이에 한정되지 않는다는 것을 이해해야 한다. 이하의 설명에서, 관련된 \"일부 실시예\"는 모든 가능한 실시예의 부분집합을 설명한다. 그러나, \"일부 실시예\" 는 모든 가능한 실시예의 동일한 부분집합 또는 다른 부분집합일 수 있으며, 충돌 없이 서로 결합될 수 있음을 이해할 수 있을 것이다. 본 명세서에서 사용된 단수형은 문맥상 명백하게 달리 지시하지 않는 한 복수형도 포함할 수 있음을 당업자는 이해할 수 있을 것이다. 본 출원의 실시예에서 사용된 \"포함한다\"라는 용어는 대응하는 특징에 의해 제시될 수"}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있는 기능, 정보, 데이터, 단계 및 동작을 의미하지만, 해당 기술분야에서 지원되는 다른 특징, 정보, 데이터 및 동작으로 구현되는 것을 배제하지 않는다. 본 출원의 특정 구현에서, 소스 이미지, 타깃 이미지, 소스 얼굴, 및 모델 훈련에 사용되는 샘플 데이터 세트의 적어도 한 쌍의 샘플과 같은 객체와 관련된 임의의 데이터와, 얼굴 변경을 위해 얼굴 변경 모델을 사용할 때 사 용되는 변경될 얼굴 이미지, 타깃 얼굴의 얼굴 특징, 및 속성 파라미터와 같은 객체와 관련된 임의 데이터는 관 련 객체의 동의 또는 허가를 받은 후 획득된다. 본 출원의 다음 실시예를 특정 제품 또는 기술에 적용하는 경우, 객체의 허가 또는 동의를 받아야 하며, 관련 데이터의 수집, 사용 및 처리는 관련 국가 및 지역의 관련 법령 및 표준을 준수해야 한다. 또한, 본 출원에서의 이미지 처리 방법을 사용하여 임의의 객체의 얼굴 이미지 에 대해 수행되는 얼굴 변경 프로세스는 관련 객체에 의해 트리거되는 얼굴 변경 서비스 또는 얼굴 변경 요청에 기초하여 트리거되는 얼굴 변경 프로세스이며, 관련 객체의 허가 또는 동의를 받은 후 수행된다. 본 출원의 실시예에서 제공되는 이미지 처리 방법은 인공 지능 및 컴퓨터 비전(computer vision)와 같은 다음 기술과 관련이 있는데, 예를 들어 인공 지능 기술에서의 클라우드 컴퓨팅 및 빅 데이터 처리와 같은 기술을 사 용하여 이미지에서의 얼굴 변경 모델 훈련을 구현하고 다중 스케일 속성 특징을 추출하는 프로세스와 관련이 있 다. 예를 들어, 컴퓨터 비전 기술을 사용하여 이미지에 대한 얼굴 인식을 수행하여 이미지에서의 얼굴에 대응하 는 식별 특징(신원 특징)을 획득한다. 인공 지능(AI)은 인간 지능을 시뮬레이션, 확대 및 확장하고, 환경을 인식하고, 지식을 습득하고, 지식을 사용 하여 최적의 결과를 획득하기 위해 디지털 컴퓨터 또는 디지털 컴퓨터로 제어되는 기계를 사용하는 이론, 방법, 기술 및 애플리케이션 시스템이다. 다시 말해, AI는 컴퓨터 과학의 종합 기술로서 지능의 본질을 이해하고 인간 의 지능과 유사한 방식으로 반응할 수 있는 새로운 지능형 기계를 생산하는 것이다. AI는 다양한 지능형 기계의 설계 원리와 구현 방법을 연구하여, 기계가 인식, 추론 및 의사 결정의 기능들을 갖도록 하는 것이다. AI 기술은 하드웨어 레벨의 기술과 소프트웨어 레벨의 기술을 모두 포함하는 광범위한 분야를 포괄하는 종합적 인 분야이다. 기본 AI 기술은 일반적으로 센서, 전용 AI 칩, 클라우드 컴퓨팅, 분산 스토리지, 빅 데이터 처리 기술, 운영/상호작용 시스템, 전자 기계 통합(electromechanical integration)과 같은 기술을 포함한다. AI 소 프트웨어 기술은 주로 CV 기술, 음성 처리 기술, 자연어 처리 기술, 기계 학습/심화 학습(deep learning, DL), 자율 주행(automatic driving), 지능형 교통 등의 분야를 포함한다. 이해해야 할 것은, CV는 기계를 사용하여 \"보는\" 방법을 연구하고, 카메라와 컴퓨터를 사용하여 사람의 눈을 대 신하여 타깃에 대한 인식 및 측정과 같은 머신 비전(machine vision)을 수행하는 과학이며, 더 나아가 그래픽 처리를 수행하여, 컴퓨터가 타깃을 사람의 눈이 관찰하기에 더 적합한 이미지로 처리하거나 탐지를 위해 기기에 송신되는 이미지로 처리하도록 한다. 과학 분야로서의 컴퓨터 비전은 이미지 또는 다차원 데이터에서 정보를 획 득할 수 있는 인공 지능 시스템을 만들기 위한 시도에서 관련 이론 및 기술을 다룬다. CV 기술은 일반적으로 이 미지 처리, 이미지 인식, 이미지 시맨틱 이해, 이미지 검색, 광학 문자 인식(optical character recognition, OCR), 비디오 처리, 비디오 시맨틱 이해, 비디오 콘텐츠/행동 인식, 3D 객체 재구축, 3D 기술, 가상 현실, 증강 현실, 동기식 측위(synchronous positioning), 지도 구축, 자율 주행 및 지능형 교통과 같은 기술을 포함하고, 공통 얼굴 인식 및 지문 인식과 같은 생체 특징 인식 기술을 더 포함한다. 도 1은 본 출원에 따른 이미지 처리 방법의 구현 환경의 개략도이다. 도 1에 도시된 바와 같이, 구현 환경은 서 버 및 단말기를 포함한다.서버는 훈련된 얼굴 변경 모델로 구성되며, 서버는 얼굴 변경 모델에 기초하여 단말기에 얼굴 변경 기능을 제공할 수 있다. 얼굴 변경 기능은 소스 이미지와 타깃 이미지에 기초한 얼굴 변경 이미지를 생성하는 데 사용될 수 있다. 생성된 얼굴 변경 이미지는 소스 이미지에서의 소스 얼굴의 식별 특징과 타깃 이미지에서의 타깃 얼굴의 속성 특징을 포함한다. 식별 특징은 소스 얼굴이 속한 객체를 나타내고, 초기 속성 특징은 타깃 얼 굴의 3차원 속성을 나타낸다. 일부 실시예에서, 단말기에는 애플리케이션 프로그램이 설치되고, 애플리케이션 프로그램에는 얼굴 변경 기 능이 미리 구성될 수 있고, 서버는 애플리케이션 프로그램의 백엔드 서버일 수 있다. 단말기와 서버 는 애플리케이션 프로그램에 기초하여 데이터를 교환하여, 얼굴 변경 프로세스를 구현할 수 있다. 예를 들 어, 단말기눈 얼굴 변경 요청을 서버에 전송할 수 있으며, 여기서 얼굴 변경 요청은 타깃 이미지에서의 타깃 얼굴을 소스 이미지에서의 소스 얼굴로 교체하도록 요청하는 데 사용된다. 서버는 얼굴 변경 요청에 기초하여, 본 출원에서의 이미지 처리 방법을 수행하여 타깃 얼굴 변경 이미지를 생성하고, 타깃 얼굴 변경 이 미지를 단말기에 회신할 수 있다. 예를 들어, 애플리케이션 프로그램은 얼굴 변경 기능을 지원하는 임의의 애플리케이션이다. 예를 들어, 애플리케이션 프로그램은 비디오 클리핑(video clipping) 애플리케이션, 이미지 처리 도구, 비디오 애플리케이션, 라이브 스트리밍 애플리케이션, 소셜 애플리케이션, 콘텐츠 상호작용 플랫폼, 게임 애플리케이션 등을 포함하지만 이에 한정되지 않는다. 클라우드 서버는 독립된 물리적 서버일 수 있거나, 복수의 물리 서버로 구성된 서버 클러스터 또는 분산 시스템 일 수 있거나, 클라우드 서비스, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 스토리지, 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 네임 서비스, 보안 서비스, 콘텐츠 전달 네트워크 (content delivery network, CDN), 빅데이터, 및 인공 지능 플랫폼과 같은 기본적인 클라우드 컴퓨팅 서비스를 제공하는 클라우드 서버 또는 서버 클러스터일 수 있다. 전술한 네트워크는 유선 네트워크 및 무선 네트워크를 포함할 수 있지만 한정되지 않으며, 여기서 유선 네트워크로는 근거리 통신망, 대도시 통신망 및 광역 통신망을 포함하고, 무선 네트워크로는 블루투스, Wi-Fi, 및 무선 통신을 구현하는 또 다른 네트워크를 포함한다. 단말기 는 스마트폰(안드로이드 이동 전화(휴대폰이라고도 함) 또는 iOS 이동 전화 등), 태블릿 컴퓨터, 노트북 컴퓨터, 디지털 방송 수신기, 이동 인터넷 기기(mobile Internet device, MID), 개인 정보 단말기(personal digital assistant, PDA), 데스크톱 컴퓨터, (차량용 내비게이션 단말기 또는 차량용 컴퓨터와 같은) 차량용 단 말기, 스마트 가전제품, 항공기, 스마트 스피커, 스마트 워치 등일 수 있다. 단말기와 서버는 유선 또는 무선 통신 방식으로 직접 또는 간접적으로 연결될 수 있으나, 이에 한정되는 것은 아니다. 세부 사항은 실제 애플리 케이션 시나리오 요구 사항을 기반으로 구체적으로 결정되며, 여기에 한정되지 않는다. 본 출원의 목적, 기술적 방안 및 이점을 보다 명확하게 하기 위해, 이하에서는 첨부 도면을 참조하여 본 출원의 실시예를 더욱 상세하게 설명한다. 이 본출에서 사용되는 기술 용어를 먼저 설명한다. 얼굴 변경: 이미지에 있는 얼굴을 다른 얼굴로 변경하는 것이다. 예를 들어, 소스 이미지 및 타깃 이미지"}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "가 주어지면, 본 출원의 이미지 처리 방법을 사용하여 얼굴 변경 이미지 가 생성된다. 얼굴 변경 이미지 는 소스 이미지 의 식별 특징을 갖고; 또한 타깃 이미지 에서의 신원 독립적(identity-independent) 속성 특징을 보존한다. 얼굴 변경 모델: 타깃 이미지에서의 타깃 얼굴을 소스 이미지의 소스 얼굴로 교체하는 데 사용된다. 소스 이미지: 식별 특징을 제공하는 이미지이며, 생성된 얼굴 변경 이미지에서의 얼굴은 소스 이미지에서의 얼 굴의 식별 특징을 갖는다. 타깃 이미지: 속성 특징을 제공하는 이미지로서, 생성된 얼굴 변경 이미지에서의 얼굴은 타깃 이미지에서의 얼 굴의 속성 특징을 갖는다. 예를 들어, 소스 이미지는 객체 A의 이미지이고, 타깃 이미지는 객체 B의 이미지이며, 얼굴 변경 이미지를 획득하기 위해 타깃 이미지에서의 객체 B의 얼굴이 객체 A의 얼굴로 교체된다. 얼굴 변경 이미지에서의 얼굴의 신원(identity)는 객체 A의 얼굴이며, 얼굴 변경 이미지에서 얼굴의 눈 모양, 눈 간격, 코 크기 등의 식별 특징은 객체 A와 동일하고, 얼굴 변경 이미지에서의 얼굴은 객체 B 물체의 표정, 머리카락, 빛, 주름, 포즈, 얼굴 폐색(face occlusion) 등의 속성 특징을 가지고 있다. 도 2는 본 출원의 일 실시예에 따른 이미지 처리 방법의 개략적인 흐름도이다. 이 이미지 처리 방법은 컴퓨터 기기(단말기 또는 서버일 수 있음)에 의해 수행될 수 있다. 도 2에 도시된 바와 같이, 이 이미지 처리 방법은 다음 단계를 포함한다. 단계 201: 컴퓨터 기기가 수신된 얼굴 변경 요청에 응답하여 소스 이미지의 식별 특징 및 타깃 이미지의 적어도 하나의 스케일의 초기 속성 특징을 취득한다. 얼굴 변경 요청은 타깃 이미지에서의 타깃 얼굴을 소스 이미지에서의 소스 얼굴로 교체하도록 요청하는 데 사용 된다. 실제 애플리케이션에서, 얼굴 변경 요청은 소스 이미지와 타깃 이미지를 실어 전달한다. 컴퓨터 기기는 얼굴 변경 요청을 파싱하여 소스 이미지와 타깃 이미지를 획득한다. 대안적으로, 얼굴 변경 요청은 소스 이미지 의 식별자와 타깃 이미지의 식별자를 실어 전달하고, 얼굴 변경 요청을 파싱한 후, 컴퓨터 기기는 소스 이미지 의 식별자와 타깃 이미지의 식별자를 획득하고, 식별자에 기초하여 이미지 라이브러리에서 소스 이미지와 타깃 이미지를 찾아낸다. 컴퓨터 기기는 훈련된 얼굴 변경 모델을 사용하여 얼굴 변경 이미지를 획득함으로써 얼굴 변경 기능을 제공할 수 있다. 식별 특징은 소스 얼굴이 속한 객체를 나타낸다. 예를 들어, 식별 특징은 객체를 식별할 수 있게 하는 특징일 수 있으며, 식별 특징은 타깃 얼굴의 오감 기관(five sense organ) 특징 또는 객체의 타깃 얼굴의 윤곽 특징 중 적어도 하나를 포함할 수 있다. 타깃 얼굴의 오감 특징은 오감기관에 대응하는 특징이고, 타깃 얼굴의 윤곽 특징은 타깃 얼굴의 윤곽에 대응하는 특징이다. 예를 들어, 식별 특징은 눈 모양, 눈 간격, 코 크기, 눈썹 모양, 얼굴 윤곽 등을 포함할 수 있지만 이에 한정되지 않는다. 초기 속성 특징은 타깃 얼굴의 3차원 속성을 나 타낸다. 예를 들어, 초기 속성 특징은 3차원 공간에서의 타깃 얼굴의 포즈 및 공간적 환경과 같은 속성을 나타 낼 수 있다. 예를 들어, 초기 속성 특징은 배경, 빛, 주름, 포즈, 표정, 머리카락, 얼굴 폐색 등을 포함할 수 있지만 이에 한정되지 않는다. 일부 실시예에서, 얼굴 변경 모델은 얼굴 폐색을 포함할 수 있고, 컴퓨터 기기는 소스 이미지를 얼굴 변경 모델 에 입력하여, 얼굴 변경 모델에서의 신원 인식 네트워크(identity recognition network)를 사용하여 소스 이미 지에 대한 얼굴 인식을 수행할 수 있다. 예를 들어, 신원 인식 네트워크는 입력된 이미지에 기초하여 이미지가 속한 얼굴의 신원을 인식하도록 구성된다. 예를 들어, 신원 인식 네트워크는 얼굴 변경 모델에서의 고정된 얼굴 인식 네트워크(Fixed FR Net)일 수 있다. 예를 들어, 소스 이미지가 얼굴 이미지인 경우, 신원 인식 네트워크는 훈련된 얼굴 인식 모델일 수 있고, 얼굴 인식 모델이 소스 이미지에서의 얼굴이 속한 객체를 인식하여 객체를 식별하는 데 사용되는 식별 특징을 획득하는 데 사용될 수 있다. 식별 특징은 눈 모양 특징, 눈 간격 특징, 코 크기 특징, 눈썹 모양 특징 및 얼굴 윤곽 특징 중 적어도 하나를 포함할 수 있다. 식별 특징은 얼굴 인식 모델 에 의해 출력되는 고정된 차원의 특징 벡터, 예를 들어, 출력되는 512차원 특징 벡터일 수 있다. 512차원 특징 벡터는 눈 모양, 눈 간격, 코 크기, 눈썹 모양, 얼굴 윤곽 등과 같은 특징을 나타낼 수 있다. 일부 실시예에서, 얼굴 변경 모델은 인코더 및 디코더를 포함할 수 있는 속성 특징 추출 네트워크를 더 포함한 다. 인코더는 적어도 하나의 인코딩 네트워크 계층을 포함하고(예컨대, 적어도 2개의 인코딩 네트워크 계층을 포함함), 디코더는 적어도 하나의 디코딩 네트워크 계층(예컨대, 적어도 2개의 디코딩 네트워크 계층을 포함 함)을 포함한다. 예를 들어, 속성 특징 추출 네트워크는 인코더와 디코더를 포함하는 U자형 심층 네트워크(U- shaped deep network)이다. 실제 애플리케이션에서, 컴퓨터 기기는 다음과 같은 방식으로 타깃 이미지의 적어도 하나의 스케일의 초기 속성 특징을 획득할 수 있다: 컴퓨터 기기는 인코더의 적어도 하나의 인코딩 네트워크 계층을 사용하여, 타깃 이미지에 대해 계층별 다운샘플 링을 수행하여 인코딩 특징을 획득하고; 디코더의 적어도 하나의 디코딩 네트워크 계층을 사용하여, 인코딩 특 징에 대해 계층별 업샘플링을 수행하여 상이한 스케일의 디코딩 특징을 출력하고, 적어도 하나의 디코딩 네트워 크 계층에 의해 출력된 상이한 스케일의 디코딩 특징을 초기 속성 특징으로 상용한다. 각각의 디코딩 네트워크 계층은 하나의 스케일에 대응한다. 예를 들어, 각 인코딩 네트워크 계층은 타깃 이미지에 대해 인코딩 동작을 수행하여 인코딩 특징을 획득하도록 구성되고, 각각의 디코딩 네트워크 계층은 인코딩 특징에 대해 디코딩 동작을 수행하여 초기 속성 특징을 획득 하도록 구성된다. 디코더는 인코더의 동작 원리에 따라 런타임에 역동작을 수행할 수 있는데, 예를 들어, 인코 더는 타깃 이미지에 대해 다운샘플링을 수행하고, 디코더는 다운샘플링된 인코딩 특징에 대해 업샘플링을 수행 할 수 있다. 예를 들어, 인코더는 AE(autoencoder)일 수 있고, 디코더는 오토인코더에 대응하는 디코더일 수 있 다. 일부 실시예에서, 각각의 인코딩 네트워크 계층은 이전 인코딩 네트워크 계층에 의해 출력된 인코딩 특징에 대 해 다운샘플링을 수행하여 적어도 하나의 스케일의 인코딩 특징을 획득하도록 구성되며, 여기서 각각의 인코딩 네트워크 계층은 하나의 스케일에 대응하고; 각각의 디코딩 네트워크 계층은 이전 디코딩 네트워크 계층에 의해 출력된 디코딩 특징에 대해 업샘플링을 수행하여 적어도 하나의 스케일의 초기 속성 특징을 획득하도록 구성되 며, 각각의 디코딩 네트워크 계층은 하나의 스케일에 대응하고, 동일한 계층에서 인코딩 네트워크 계층과 디코 딩 네트워크 계층은 동일한 스케일을 가질 수 있다. 각각의 디코딩 네트워크 계층은 대응하는 스케일의 인코딩 네트워크 계층의 인코딩 특성을 참조하여 이전 디코딩 네트워크 계층에 의해 출력되는 초기 속성 특징을 추가로 업샘플링할 수 있다. 도 3에 도시된 바와 같이, U자형 심층 네트워크는 타깃 이미지 Xt 대한 특징 추출을 수행 하고, 예를 들어 타깃 이미지를 인코더에 입력하도록 구성된다. 인코더는 복수(즉, 적어도 2개)의 인코딩 네트 워크 계층을 포함하고, 각각의 인코딩 네트워크 계층은 하나의 특징 맵의 해상도(즉, 스케일)에 대응한다. 출력 되는 타깃 이미지 Xt의 인코딩 특징의 특징 맵의 해상도는 연속적으로 1024×1024, 512×512, 256×256, 128× 128, 64×64이다. 이 경우, 64×64의 특징 맵이 디코더의 첫 번째 디코딩 네트워크 계층에 입력되어 128×128의 디코딩된 특징 맵을 획득하고, 128×128의 디코딩된 특징 맵이 128×128의 인코딩된 특징 맵과 연결되며, 그 다 음 연결된 특징 맵이 업샘플링되어 256×256의 디코딩된 특징 맵을 획득한다. 유추적으로, U자형 심층 네트워크 의 네트워크 구조를 디코딩하여 획득되는 다양한 해상도의 특징 맵을 초기 속성 특징으로서 사용한다. 초기 속 성 특징에서, 각 스케일의 초기 속성 특징은 타깃 이미지의 속성 특징을 대응하는 스케일으로 표현하는 데 사용 되며, 서로 다른 스케일의 초기 속성 특징에 대응하는 속성 특징은 서로 다를 수 있다. 비교적 작은 스케일의 초기 속성 특징은 타깃 이미지에서의 타깃 얼굴의 전역 위치(global position) 및 자세와 같은 정보를 나타낼 수 있고, 비교적 큰 스케일의 초기 속성 특징은 타깃 이미지에서의 타깃 얼굴의 국부적인 세부사항(local detail)을 나타낼 수 있어, 적어도 하나의 스케일의 초기 속성 특징이 객체의 복수 레벨의 속성 특징을 포함할 수 있도록 한다. 예를 들어, 적어도 하나의 스케일의 초기 속성 특징은 작은 것부터 큰 것까지의 해상도를 갖는 복수의 특징 맵일 수 있고, 해상도 R1의 특징 맵은 타깃 이미지에서의 타깃 얼굴의 얼굴 위치를 나타낼 수 있고, 해상도 R2의 특징 맵은 타깃 이미지에서의 타깃 얼굴의 포즈 표현을 나타낼 수 있고, 해상도 R3의 특징 맵은 타깃 이미지에서의 타깃 얼굴의 얼굴 위치의 얼굴 세부사항을 나타낼 수 있다. 해상도 R1은 R2보다 작고, R2는 R3보다 작다. 단계 202: 컴퓨터 기기는 얼굴 변경 모델을 사용하여 적어도 하나의 스케일의 식별 특징 및 초기 속성 특징에 대해 특징 융합을 반복적으로 수행하여 융합 특징을 획득한다. 단계 203: 컴퓨터 기기는 얼굴 변경 모델을 사용하여 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 타깃 얼굴 변경 이미지를 출력한다. 여기서, 타깃 얼굴 변경 이미지에서의 얼굴은 소스 얼굴의 식별 특징 및 타깃 얼굴의 타깃 속성 특징과 융합된 다. 일부 구현에서, 얼굴 변경 모델은 적어도 하나의 컨볼루션 계층를 포함(예컨대, 적어도 2개의 컨볼루션 계층을 포함)하는 생성기를 포함하고, 적어도 하나의 컨볼루션 계층은 직렬로 연결되고, 각각의 컨볼루션 계층은 스케 일에 대응한다. 얼굴 변경 모델을 사용함으로써, 컴퓨터 기기는 다음과 같은 방식으로 식별특징과 적어도 하나 의 스케일의 초기 속성 특징에 대해 특징 융합을 반복적으로 수행할 수 있다: 컴퓨터 기기는 얼굴 변경 모델의 각각의 컨볼루션 계층을 사용하여 대응하는 스케일의 식별 특징 및 초기 속성 특징에 대해 다음과 같은 처리를 개별적으로 수행한다: 현재 컨볼루션 계층의 이전 컨볼루션 계층에 의해 출력 되는 제1 특징 맵(feature map)을 취득하는 처리; 식별 특징 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하 고, 적어도 하나의 스케일의 초기 속성 특징으로부터 타깃 속성 특징을 선택하는 처리 - 타깃 속성 특징은 타깃 얼굴의 식별 특징 이외의 특징임 -; 타깃 속성 특징 및 제2 특징 맵에 기초하여 제3 특징 맵을 생성하는 처리 - 제3 특징 맵은 현재 컨볼루션 계층의 다음 컨볼루션 계층의 제1 특징 맵임 -; 및 적어도 하나의 컨볼루션 계층 중 마지막 컨볼루션 계층에 의해 출력되는 제3 특징 맵을 융합 특징으로 결정하는 처리. 실제 애플리케이션에서, 초기 속성 특징과 컨볼루션 계층의 수량은 모두 타깃 수량이고, 타깃 수량의 컨볼루션 계층은 직렬로 연결되어 있으며, 서로 다른 초기 속성 특징은 서로 다른 스케일에 대응하고, 각각의 컨볼루션 계층은 하나의 스케일의 초기 속성 특징에 대응하고, 타깃 수량은 2 이상이며; 현재 컨볼루션 계층이 타깃 수량 의 컨볼루션 계층 중 첫 번째 컨볼루션 계층인 경우, 초기 특징 맵이 취득되며, 초기 특징 맵은 현재 컨볼루션 계층에 입력되는 첫 번째(제1) 특징 맵으로 사용된다. 여기서, 실제 애플리케이션에서 초기 특징 맵은 고정된 차원에서의 모든 영(all-0)인 특징 벡터일 수 있다.일부 실시예에서, 컴퓨터 기기는 다음 방식으로 적어도 하나의 스케일의 초기 속성 특징으로부터 타깃 속성 특 징을 선택할 수 있다: 특징 맵 및 속성 특징에 기초하여, 대응하는 스케일에서 이미지의 제어 마스크를 결정하 고 - 여기서 제어 마스크가 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는 픽셀을 표현하는 데 사용됨 - ; 제어 마스크에 기초하여 적어도 하나의 스케일의 초기 속성 특징을 스크리닝하여 타깃 속성 특징을 획득한다. 예를 들어, 컴퓨터 기기는 생성기의 각 컨볼루션 계층에 식별 특징을 입력할 수 있다. 컴퓨터 기기는 적어도 하 나의 스케일의 초기 속성 특징을 생성기에 있고 초기 속성 특징의 스케일과 매칭되는 컨볼루션 계층에 입력한다. 생성기의 컨볼루션 계층에 의해 출력되는 특징 맵들의 스케일은 상이하며, 컨볼루션 계층이 초기 속 성 특징의 스케일과 매칭된다는 것은 컨볼루션 계층에 의해 출력될 특징 맵의 스케일이 초기 속성 특징의 스케 일과 동일하다는 것을 의미한다. 예를 들어, 생성기에서의 컨볼루션 계층은 이전 컨볼루션 계층으로부터의 64× 64의 특징 맵을 처리하여, 128×128의 특징 맵을 출력하는데 사용되며, 128×128의 초기 속성 특징은 컨볼루션 계층에 입력될 수 있다. 일부 실시예에서, 생성기에서, 컴퓨터 기기는 적어도 하나의 스케일의 식별 특징 및 초기 속성 특징에 기초하여 타깃 이미지의 적어도 하나의 스케일의 제어 마스크를 결정할 수 있고, 식별 특징, 적어도 스테일의 제어 마스 크, 및 적어도 하나의 스테일의 초기 속성 특징에 기초하여 타깃 얼굴 변경 이미지를 획득할 수 있다. 예를 들 어, 제어 마스크는 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는 픽셀을 나타내고, 컴퓨터 기기는 제어 마 스크 및 적어도 하나의 스케일의 초기 속성 특징에 기초하여 적어도 하나의 스케일의 타깃 속성 특징을 결정하 고, 식별 특징 및 적어도 하나의 스케일의 타깃 속성 특징에 기초하여 타깃 얼굴 변경 이미지를 생성할 수 있다. 컴퓨터 기기는 생성기의 각각의 컨볼루션 계층에 대해 계층별 처리를 수행함으로써 타깃 얼굴 변경 이미지를 획 득할 수 있다. 가능한 예에서, 컴퓨터 기기는 생성기의 각각의 컨볼루션 계층을 사용하여 입력된 식별 특징 및 대응하는 스케일의 초기 속성 특징에 대해 다음 단계 S1 내지 S4를 수행한다: 단계 S1: 컴퓨터 기기는 현재 컨볼루션 계층의 이전 컨볼루션 계층에 의해 출력되는 제1 특징 맵을 획득한다. 생성기에서, 각각의 컨볼루션 계층은 이전 컨볼루션 계층에서 출력되는 특징 맵을 처리하여 다음 컨볼루션 계층 에 출력할 수 있다. 첫 번째 컨볼루션 계층에 대해, 컴퓨터 기기는 첫 번째 컨볼루션 계층에 초기 특징 맵을 입 력할 수 있다. 예를 들어, 초기 특징 맵은 4×4×512의 모두 영인 특징 벡터일 수 있다. 마지막 컨볼루션 계층 에 대해, 컴퓨터 기기는 마지막 컨볼루션 계층에 의해 출력되는 특징 맵에 기초하여 최종 타깃 얼굴 변경 이미 지를 생성할 수 있다. 단계 S2: 컴퓨터 기기는 식별 특징 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하고, 제2 특징 맵 및 초기 속성 특징에 기초하여 대응하는 스케일에서 타깃 이미지의 제어 마스크를 결정한다. 제어 마스크는 타깃 얼굴의 식별 특징이 아닌 다른 기능을 가지고 있는 픽셀을 나타낸다. 일부 실시예에서, 컴퓨터 기기는 식별 특징에 기초하여 현재 컨볼루션 계층의 컨볼루션 커널(mapping convolution kernel)의 가중치를 조정하고, 제1 특징 맵 및 조정된 컨볼루션 커널에 기초하여 제2 특징 맵을 획 득한다. 예를 들어, 컴퓨터 기기가 제2 특징 맵을 생성하는 단계는 다음을 포함할 수 있다: 컴퓨터 기기가 식별 특징에 대해 아핀 변환을 수행하여 제1 제어 벡터를 획득하고; 컴퓨터 기기는 현재 컨볼루션 계층의 제1 컨볼루 션 커널을 제1 제어 벡터에 기초하여 제2 컨볼루션 커널에 매핑하고, 제2 컨볼루션 커널에 기초하여 제1 특징 맵에 대해 컨볼루션 연산을 수행하여 제2 특징 맵을 생성한다. 예를 들어, 식별 특징은 식별 특징 벡터로 표현 될 수 있고, 아핀 변환은 제1 제어 벡터를 얻기 위해 식별 특징 벡터에 대해 선형 변환 및 평행 이동 (translation)을 수행하는 연산이다. 아핀 변환 연산은 평행 이동, 스케일링(scaling), 회전 및 역 변환을 포함 하지만 한정되지 않는다. 생성기의 각각의 컨볼루션 계층은 훈련된 아핀 파라미터 행렬을 포함한다. 컴퓨터 기 기는 아핀 파라미터 행렬에 기초하여 식별 특징 벡터에 대해 평행 이동, 스케일링, 회전 및 역변환을 수행할 수 있다. 예를 들어, 컴퓨터 기기는 제1 제어 벡터를 이용하여 현재 컨볼루션 계층의 제1 컨볼루션 계층에 대해 변 조 동작(Mod) 및 복조 동작(Demod)을 수행하여 제2 컨볼루션 커널을 획득할 수 있다. 변조 동작은 현재 컨볼루 션 계층의 컨볼루션 커널 가중치에 대한 스케일링 처리일 수 있고, 복조 동작은 스케일링 처리 후에 획득된 컨 볼루션 커널 가중치에 대한 정규화 처리일 수 있다. 예를 들어, 컴퓨터 기기는 현재 컨볼루션 계층에 입력되는 제1 특징 맵에 대응하는 스케일 비율 및 제1 제어 벡터를 사용하여 컨볼루션 커널 가중치에 대한 스케일링 처리 를 수행할 수 있다. 일부 실시예에서, 컴퓨터 기기는 현재 컨볼루션 계층에 입력된 대응하는 스케일의 초기 속성 특징 및 제2 특징 맵에 기초하여 대응하는 스케일의 제어 마스크를 획득한다. 프로세스는 다음을 포함할 수 있다: 컴퓨터 기기는 제2 특징 맵과 초기 속성 특징에 대해 특징 연결을 수행하여 연결된 특징 맵을 획득하고; 컴퓨터 기기는 미리 구성된 매핑 컨볼루션 커널 및 활성화 함수(activation function)에 기초하여 연결된 특징 맵을 제어 마스크에 매핑한다. 예를 들어, 제어 마스크는 이진 이미지이다. 이진 이미지에서 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는 픽셀의 값, 예를 들어, 머리카락 영역의 픽셀 값 또는 배경 영역의 픽셀 값은 1이고, 식별 특징을 가지고 있는 픽셀의 값은 0이다. 예를 들어, 매핑된 컨볼루션 커널은 1×1의 컨볼루션 커널일 수 있고, 활성화 함수는 시그모이드 함수(Sigmoid function)일 수 있다. 예를 들어, 제2 특징 맵과 초기 속성 특징은 특징 벡터 로 표현될 수 있다. 컴퓨터 기기는 제2 특징 맵에 대응하는 특징 벡터와 초기 속성 특징에 대응하는 특징 벡터 에 대한 조합 연산을 수행하여 연결 벡터를 획득하고, 연결 벡터에 대해 컨볼루션 연산 및 활성화 연산을 수행 하여 제어 마스크를 획득한다. 예를 들어, 생성기는 복수의 블록을 포함할 수 있고, 각각의 블록은 복수의 계층을 포함할 수 있다. 컴퓨터 기 기는 각각의 스케일의 초기 속성 특징 및 식별 특징을 대응하는 스케일의 블룩에 입력한다. 블록에서, 적어도 하나의 계층은 입력된 식별 특징 및 초기 속성 특징에 대한 계층별 처리를 수행하기 위해 사용될 수 있다. 예를 들어, 도 4는 생성기에서 제i 블록(i-th GAN block)의 네트워크 구조이며, 여기서 N은 속성 주입 모듈 (AttrInjection)을 나타내고, 속성 주입 모듈의 내부 구조가 확대되어 우측의 파선 박스에 표시된다. 도 4에 도 시된 바와 같이, 제i번째 블록은 2개의 계층을 포함하며, 첫 번째 계층은 설명을 위한 예로 사용된다. 도 도 4 에서 왼쪽 w는 소스 이미지의 식별 특징 fid를 나타내고, A는 아핀 변환 연산을 나타낸다. 식별 특징 벡터에 대 해 아핀 변환 연산이 수행된 후, 제1 제어 벡터가 획득된다. 도 4에서, Mod 및 Demod는 컨볼루션 커널 Conv 3× 3에서 변조 및 복조 동작이 수행됨을 나타낸다. 컴퓨터 기기는 현재 계층의 제1 특징 맵으로서 현재 블록에 입 력되는 제1 특징 맵에 대해 업샘플링 동작을 수행한 후, Mod 및 Demod 동작 후에 획득되는 컨볼루션 커널 Conv 3x3을 사용하여 업샘플링된 제1 특징 맵에 대해 컨볼루션 연산을 수행하여 제2 특징 맵을 획득한다. 그런 다음, 컴퓨터 기기는 현재 블록에 입력되는 초기 속성 특징 fiatt 및 제2 특징 맵에 대해 연결(Concat) 동작을 수행하고 연결을 통해 획득되는 연결된 특징 벡터를 컨볼루션 커널 Conv 1×1 및 Sigmoid 함수를 사용하여 현재 계층에 대응하는 제어 마스크 Mi,jatt에 매핑한다. 단계 S3: 컴퓨터 기기는 제어 마스크에 기초하여 초기 속성 특징을 스크리닝하여 타깃 속성 특징을 획득한다. 컴퓨터 기기는 제어 마스크에 대응하는 특징 벡터 및 초기 속성 특징에 대응하는 특징 벡터에 대해 점 승산 (point multiplication)을 수행하여 초기 속성 특징에서 타깃 속성 특징을 획득할 수 있다. 도 4에 도시된 같이, 컴퓨터 기기는 제어 마스크 Mi,jatt 및 초기 속성 특징 fiatt에 대해 점 승산을 수행하고, 제2 특징 맵에 대응하는 특징 벡터에 점 곱셈에 의해 획득된 특징 벡터를 가산하여 타깃 속성 특징을 획득할 수 있 다. 단계 S4: 컴퓨터 기기는 타깃 속성 특징 및 제2 특징 맵에 기초하여 제3 특징 맵을 생성하고, 현재 컨볼루션 계 층의 다음 컨볼루션 계층에 제3 특징 맵을 출력하여 다음 컨볼루션 계층의 제1 특징 맵의 역할을 하도록 한다. 컴퓨터 기기는 제2 특징 맵에 대응하는 특징 벡터 및 타깃 속성 특징에 대응하는 특징 벡터를 가산하여 제3 특 징 맵을 획득한다. 생성기에 포함된 각각의 컨볼루션 계층에 대해, 컴퓨터 기기는 생성기의 마지막 컨볼루션 계층에 대해 전술한 단계 S1 내지 단계 S4가 반복 수행되어 마지막 컨볼루션 계층에 의해 출력된 제3 특징 맵을 획득할 때까지 전술 한 단계 S1 내지 단계 S4를 반복하여 수행하여, 마지막 컨볼루션 계층에 의해 출력되는 제3 특징 맵에 기초하여 타깃 얼굴 변경 이미지를 생성한다. 도 4에 도시된 바와 같이, 제i 블록이 2개의 계층을 포함하는 경우, 제i 블록의 두 번째 계층에 제3 특징 맵을 입력하고, 제1 계층의 동작을 반복하고, 두번 째 계층에 의해 획득된 특징 맵을 다음 블록 등 마지막 블록에까 지 출력한다. 도 3에 도시된 바와 같이, N은 속성 주입 모듈(AttrInjection 모듈)을 나타내고, 파선 박스는 StyleGAN2 모델을 사용하는 생성기를 나타낸다. 생성기에 포함된 N개 블록에 대해, 소스 이미지 Xs의 식별 특징 fid가 각각 입력되고, 대응하는 초기 속성 특징 f1att, f2att, ..., fiatt, ..., fN-1att, 및 fNatt이 속성 주입 모듈을사용하여 N개의 블록에 각각 입력된다. 단계 S1 내지 단계 S4의 프로세스는 마지막 블록에 의해 출력된 특징 맵 이 획득될 때까지 각각의 블록에서 수행되고, 마지막 블록에 의해 출력된 특징 맵에 기초하여 최종 타깃 얼굴 변경 이미지 Ys,t가 생성되어, 얼굴 변경을 완료한다. 도 5는 본 출원의 일 실시예에 따른 얼굴 변경 모델 훈련 방법의 개략적인 흐름도이다. 이 얼굴 변경 모델 훈련 방법은 컴퓨터 기기에 의해 수행될 수 있다. 도 5에 도시된 바와 같이, 이 얼굴 변경 모델 훈련 방법은 다음 단 계를 포함한다: 단계 501: 컴퓨터 기기는 샘플 이미지 쌍에서 샘플 소스 이미지의 샘플 식별 특징을 취득하고 샘플 이미지 쌍에 서 샘플 타깃 이미지의 적어도 하나의 스케일의 샘플 초기 속성 특징을 취득한다. 실제 애플리케이션에서, 컴퓨터 기기는 샘플 데이터 세트를 취득하며, 여기서 샘플 데이터 세트는 적어도 하나 의 샘플 이미지 쌍을 포함하고, 컴퓨터 기기는 샘플 데이터 세트를 사용하여 얼굴 변경 모델을 훈련한다. 각각 의 샘플 이미지 쌍은 하나의 샘플 소스 이미지와 하나의 샘플 타깃 이미지를 포함한다. 일부 실시예에서, 샘플 이미지 쌍은 제1 샘플 이미지 쌍 및 제2 샘플 이미지 쌍을 포함할 수 있으며, 여기서 제1 샘플 이미지 쌍은 동 일한 객체에 속하는 샘플 소스 이미지 및 샘플 타깃 이미지를 포함하고, 제2 샘플 이미지 쌍은 서로 다른 객체 에 속하는 샘플 소스 이미지와 샘플 타깃 이미지를 포함한다. 예를 들어, 샘플 이미지 쌍은 타깃 객체 A의 소스 이미지 Xs 및 타깃 이미지 Xt를 포함하는 제1 샘플 이미지 쌍을 포함하고, 또한 객체 B의 소스 이미지 Xs 및 타 깃 이미지 Xt를 포함하는 제2 샘플 이미지 쌍을 포함한다. 제1 샘플 이미지 쌍과 제2 샘플 이미지에는 참(true) 값 레이블이 표시되어 있으며, 참 값 레이블은 대응하는 소스 이미지와 대응하는 타깃 이미지가 동일한 객체인 지를 나타낸다. 여기서, 샘플 소스 이미지의 샘플 식별 특징 및 샘플 타깃 이미지의 샘플 초기 속성 특징은 초기 얼굴 변경 모 델을 사용하여 취득될 수 있다. 일부 실시예에서, 초기 얼굴 변경 모델은 초기 신원 인식 네트워크 및 속성 특 징 맵 추출 네트워크를 포함할 수 있고, 컴퓨터 기기는 초기 신원 인식 네트워크와 속성 특징 맵 추출 네트워크 를 사용하여 샘플 소스 이미지의 샘플 식별 특징과 샘플 타깃 이미지의 적어도 하나의 스케일의 샘플 초기 속성 특징을 개별적으로 추출할 수 있다. 여기에서 샘플 식별 특징 및 샘플 초기 속성 특징을 취득하는 구현은 단계 201에서 식별 특징 및 초기 속성 특징을 추득하는 방식과 유사한 프로세스이며 세부 사항은 여기에서 다시 설명 되지 않는다. 단계 502: 컴퓨터 기기는 초기 얼굴 변경 모델의 생성기를 사용하여 샘플 식별 특징 및 적어도 하나의 스케일의 샘플 초기 속성 특징에 대해 특징 융합을 반복적으로 수행하여 샘플 융합 특징을 획득하고, 초기 얼굴 변경 모 델의 생성기를 사용하여 샘플 융합 특징에 기초한 샘플 생성 이미지를 생성한다. 일부 실시예에서, 초기 얼굴 변경 모델의 생성기는 샘플 소스 이미지의 샘플 식별 특징 및 샘플 타깃 이미지의 적어도 하나의 스케일의 샘플 초기 속성 특징에 기초하여 적어도 하나의 스케일의 샘플 마스크를 결정하고, 샘 플 식별 특징, 적어도 하나의 스케일의 샘플 마스크, 및 적어도 하나의 스케일의 샘플 초기 속성 특징에 기초하 여 샘플 이미지 쌍에 대응하는 샘플 이미지를 생성한다. 생성기는 복수의 컨볼루션 계층을 포함한다. 각각의 샘플 이미지 쌍에 대해, 컴퓨터 기기는 샘플 식별 특징을 각각의 컨볼루션 계층에 입력하고, 적어도 하나의 스케일의 샘플 초기 속성 특징을 샘플 초기 속성 특징의 스케 일과 매칭되는 컨볼루션 계층에 입력하고, 각각의 컨볼루션 계층에 대한 계층별 처리를 수행하여 샘플 생성 이 미지를 획득할 수 있다. 예를 들어, 컴퓨터 기기는 생성기의 각각의 컨볼루션 계층을 사용하여, 입력된 샘플 식별 특징 및 대응하는 스 케일의 샘플 초기 속성 특징에 대해 다음 단계를 수행할 수 있다: 컴퓨터 기기는 이전 초기 컨볼루션 계층의 이 전 초기 컨볼루션 계층에 의해 출력되는 제1 샘플 특징 맵을 취득하고; 샘플 식별 특징 및 제1 샘플 특징 맵에 기초하여 제2 샘플 특징 맵을 생성하고, 제2 샘플 특징 맵 및 샘플 초기 속성 특징에 기초하여 대응하는 스케일 에서 샘플 타깃 이미지의 샘플 마스크를 결정하고; 컴퓨터 기기는 샘플 마스크에 기초하여 샘플 초기 속성 특징 을 스크리닝하여 샘플 타깃 속성 특징을 획득하고; 컴퓨터 기기는 샘플 타깃 속성 특징 및 제2 샘플 특징 맵에 기초하여 제3 샘플 특징 맵을 생성하고, 제3 샘플 특징 맵을 현재 컨볼루션 계층의 다음 컨볼루션 계층에 출력 하여, 다음 컨볼루션 계층의 제1 샘플 특징 맵으로서의 역할을 하도록 한다. 유추하여, 생성기의 마지막 컨볼루 션 계층에 대해 전술한 단계를 반복할 때까지, 마지막 컨볼루션 계층에서 출력되는 제3 특징 맵을 획득하고, 마 지막 컨볼루션 계층에 의해 출력되는 초기 특징 맵에 기초하여 샘플 생성 이미지를 획득한다.모델 훈련 단계에서 각각의 컨볼루션 계층을 사용하여 수행되는 단계는 훈련된 얼굴 변경 모델 생성기에서 각각 의 컨볼루션 계층에 의해 수행되는 단계(즉, 전술한 단계 S1-S4)와 동일한 프로세스이며, 자세한 내용은 여기에 서 다시 설명하지 않는다. 단계 503: 컴퓨터 기기는 초기 얼굴 변경 모델의 판별기(discriminator)를 사용하여 샘플 생성 이미지와 샘플 소스 이미지를 판별하여 판별 결과를 획득한다. 여기서, 샘플 이미지 쌍에서의 샘플 소스 이미지와 샘플 생성 이미지는 초기 얼굴 변경 모델의 판별기에 입력되 어, 판별기에 의해 각각 생성되는 샘플 소스 이미지와 샘플 생성 이미지의 판별 결과를 획득한다. 초기 얼굴 변경 모델은 판별기를 더 포함할 수 있다. 각각의 샘플 이미지 쌍에 대해, 컴퓨터 기기는 샘플 소스 이미지 및 샘플 생성 이미지를 판별기에 입력하고, 샘플 소스 이미지의 제1 판별 결과 및 샘플 생성 이미지의 제2 판별 결과를 출력한다. 제1 판별 결과는 샘플 소스 이미지가 실제 이미지일 확률을 나타낼 수 있다. 제2 판 별 결과는 샘플 생성 이미지가 실제 이미지일 확률을 나타낼 수 있다. 일부 실시예에서, 판별기는 적어도 하나의 컨볼루션 계층을 포함한다. 각각의 컨볼루션 계층은 판별기의 이전 컨볼루션 계층에서 출력된 판별 특징 맵을 처리하여 판별기의 다음 컨볼루션 계층로 출력하도록 구성될 수 있다. 각각의 컨볼루션 계층은 판별기의 마지막 컨볼루션 계층까지 샘플 소스 이미지에 대한 특징 추출을 수행 하기 위한 판별 특징 맵과 샘플 생성 이미지에 대한 특징 추출을 수행하기 위한 판별 특징 맵을 출력할 수 있으 며, 마지막 컨볼루션 계층에 의해 출력된 샘플 소스 이미지의 판별 특징 맵에 기초하여 제1 판별 결과 획득된다. 제2 판별 결과는 마지막 컨볼루션 계층에 의해 출력된 샘플 생성 이미지의 판별 특징 맵에 기초하여 획득된다. 단계 504: 컴퓨터 기기는 판별 결과에 기초하여 초기 얼굴 변경 모델의 손실을 결정하고 손실에 기초하여 초기 얼굴 변경 모델을 훈련시켜 얼굴 변경 모델을 획득한다. 각각의 샘플 이미지 쌍에 대해, 컴퓨터 기기는 샘플 이미지 쌍에서 샘플 타깃 이미지의 적어도 하나의 스케일의 샘플 마스크에 기초하여 제1 손실 값을 결정하고, 샘플 소스 이미지와 샘플 생성 이미지 각각의 판별 결과(즉, 제1 판별 결과 및 제2 판별 결과)에 기초하여 제2 손실 값을 결정하고, 제1 손실 값과 제2 손실 값에 기초한 총 훈련 손실을 획득하고, 타깃 조건이 충족되어 훈련이 중지될 때까지, 총 훈련 손실에 기초하여 초기 얼굴 변경 모델을 훈련시켜, 얼굴 변경 모델을 획득한다. 실제 애플리케이션에서, 컴퓨터 기기는 적어도 하나의 스케일의 샘플 마스크를 누적하고, 적어도 하나의 스케일 의 샘플 마스크에 대응하는 누적 값을 제1 손실 값으로 사용할 수 있다. 예를 들어, 샘플 마스크는 이진 이미지 일 수 있다. 컴퓨터 기기는 이진 이미지의 픽셀 값을 누적하여 각각의 샘플 마스크에 대응하는 제1 합산 값을 획득하고, 샘플 마스크의 적어도 하나의 스케일에 대응하는 제1 합산 값을 누적하여 제1 손실 값을 획득한다. 예를 들어, 생성기는 적어도 하나의 초기 블록을 포함하고, 각각의 초기 블록은 적어도 하나의 계층을 포함한다. 각각의 샘플 이미지 쌍에 대해, 컴퓨터 기기는 다음 공식 1을 사용하여 각각의 샘플 이미지 쌍에서의 샘플 타깃 이미지의 적어도 하나의 스케일의 샘플 마스크에 기초하여 제1 손실 값을 결정할 수 있다: 공식 1: ; 여기서 는 제1 손실 값을 나타내고, i는 생성기의 제i 블록을 나타내고, j는 제i 블록의 j번째 계층을 나 타낸다. 컴퓨터 기기는 공식 1을 사용하여 적어도 하나의 블록 중 적어도 하나의 계층의 샘플 마스크를 누적할 수 있고, 훈련 단계에서 제1 손실 값 을 최소화하여 생성기를 훈련하여, 획득된 제어 마스크가 식별 특징 이 아닌 주요(key) 속성 특징의 픽셀을 효과적으로 나타낼 수 있도록 하며, 제어 마스크는 초기 속성 특징에서 주요 속성 특징을 선택하고, 초기 속성 특징 중의 중복 피처를 필터링하여, 초기 속성 특징에서 주요 및 필요한 특징을 유지하여, 중복 속성을 방지하고 최종적으로 생성된 얼굴 변경 이미지의 정확도를 향상시킬 수 있다. 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있고 다른 스케일의 이진 이미지로 표현되는 픽셀은 정교함의 정 도(degrees of refinement)가 다르다. 도 6은 3개의 타깃 이미지에 각각 대응하는 서로 다른 스케일의 샘플 마 스크를 도시한 것으로, 샘플 마스크의 각 행은 타깃 이미지 중 하나에 대응하는 다양한 스케일의 샘플 마스크이 다. 도 6에 도시된 바와 같이, 모든 타깃 이미지에 대해, 샘플 마스크의 해상도는 왼쪽에서 오른쪽으로 순서대 로 증가한다. 첫 번째 행의 각 스케일의 샘플 마스크 변경이 예로 사용된다. 4×4, 8×8, 16×16, 32×32부터, 타깃 이미지에서 얼굴의 위치가 점차 명확해지며, 여기서 얼굴 영역에 해당하는 픽셀의 값은 0이고, 얼굴 영역이외의 배경 영역에 대응하는 픽셀은 0이다. 64×64, 128×128, 16×16, 256×256, 512×512, 1024×1024로부 터, 타깃 이미지에서 얼굴의 포즈 표현은 점차 선명해지고, 타깃 이미지에서 얼굴의 얼굴 세부사항이 점차적으 로 제시된다. 예를 들어, 컴퓨터 기기는 샘플 소스 이미지와 샘플 생성 이미지에 대한 판별기의 판별 결과에 기초하여 다음 공식 2를 사용하여 제2 손실 값을 결정할 수 있다: 공식 2: ; 여기서, 은 제2 손실 값을 나타내고, 는 판별기에 의한 샘플 소스 이미지의 제1 판별 결과를 나타내 며, 제1 판별 결과는 샘플 소스 이미지 가 실제 이미지일 확률일 수 있다. 는 판별기에 의한 샘플 생성 이미지 의 제2 판별 결과를 나타내며, 제2 판별 결과는 샘플 생성 이미지가 실제 이미지일 확률일 수 있다. 는 의 기대치를 나타내며, 판별기의 손실 값을 나타낼 수 있다. 는 에 대한 기대치를 나타내며, 생성기의 손실 값을 나타낼 수 있다. 는 손실 함수 값을 최소화하려는 생성기의 기대치를 나타내고, 는 판별기에 의해 손실 함수 값 을 최대화하는 것을 나타낸다. 초기 얼굴 변경 모델은 생성기와 판별기를 포함하며, 적대적 네트워크 (adversarial network)일 수 있다. 적대적 네트워크는 생성자와 판별기가 게임을 하는 방식으로 원하는 머신 러 닝 모델을 학습하는 비지도 학습 방법(unsupervised learning method)이다. 생성기 훈련 목표는 입력에 따라 예 상되는 출력을 획득하는 것이다. 판별기의 훈련 목적은 가능한 한, 실제 이미지로부터 생성기에 의해 생성되는 이미지를 구별하는 것이다. 판별기에 대한 입력은 샘플 소스 이미지와 생성기에 의해 생성된 샘플 생성 이미지 를 포함한다. 두 네트워크 모델은 적대적인 방식으로 서로 학습하고, 지속적으로 파라미터를 조정한다. 궁극적 인 목적은 개시자가 판별기를 최대한 속여서, 판별기가 생성기에 의해 생성된 이미지가 실제인지를 판별할 수 없도록 하는 것이다. 일부 실시예에서, 컴퓨터 기기는 제1 손실 값과 제2 손실 값의 합을 총 훈련 손실로 사용할 수 있다. 일부 실시예에서, 컴퓨터 기기는 동일한 객체의 샘플 이미지에 기초하여 훈련을 추가로 수행할 수 있다. 컴퓨터 기기가 총 훈련 손실을 결정하기 전에, 컴퓨터 기기는 제1 샘플 이미지 쌍의 샘플 생성 이미지 및 샘플 타깃 이 미지에 기초하여 제1 샘플 이미지 쌍에 대응하는 제3 손실 값을 획득한다. 컴퓨터 기기에 의한 총 훈련 손실을 결정하는 단계는 다음을 포함할 수 있다: 컴퓨터 기기는 제1 샘플 이미지 쌍에 대응하는 제3 손실 값, 샘플 이 미지 쌍에 때응하는 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득한다. 예를 들어, 컴퓨터 기기는 다음 공식 3을 사용하여 제1 샘플 이미지 쌍의 샘플 생성 이미지 및 샘플 타깃 이미 지에 기초하여 제3 손실 값을 획득할 수 있다: 공식 3: ; 는 제3 손실 값을 나타내고, 는 제1 샘플 이미지 쌍에 대응하는 샘플 생성 이미지를 나타내며, 는 제1 샘플 이미지 쌍에서의 샘플 타깃 이미지를 나타낸다. 샘플 소스 이미지와 샘플 타깃 이미지가 동일한 객체에 속 하는 경우, 얼굴 변경 결과는 샘플 타깃 이미지와 동일하도록 제약될 수 있으므로, 훈련된 얼굴 변경 모델이 동 일한 객체의 이미지에 대해 얼굴 변경을 수행하는 경우, 생성된 얼굴 변경 이미지는 타깃 이미지에 가까워, 모 델 훈련 정확도가 향상된다. 일부 실시예에서, 판별기는 적어도 하나의 컨볼루션 계층을 포함한다. 컴퓨터 기기는 판별기의 각각의 컨볼루션 계층의 출력 결과에 기초하여 손실 계산을 수행할 수 있다. 총 훈련 손실을 결정하기 전에, 컴퓨터 기기는 각각 의 샘플 이미지 쌍에 대해 제1 판별 특징 맵의 비얼굴 영역과 제2 판별 특징 맵의 비얼굴 영역 사이의 제1 유사 도를 결정하며, 여기서 제1 판별 특징 맵은 적어도 하나의 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 타 깃 이미지에 대응하는 특징 맵이고, 제2 판별 특징 맵은 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 생성 이미지의 특징 맵이며; 컴퓨터 기기는 제3 판별 특징 맵과 제4 판별 특징 맵 사이의 제2 유사도를 결정하고, 제 3 판별 특징 맵은 컨볼루션 계층의 제2 부분에 의해 출력되는 샘플 타깃 이미지의 특징 맵이고, 제4 판별 특징 맵 컨볼루션 계층의 제2 부분에 의해 출력되는 샘플 생성 이미지의 특징 맵이며; 컴퓨터 기기는 각각의 샘플 이미지 쌍에 대응하는 제1 유사도 및 제2 유사도에 기초하여 제4 손실 값을 결정한다. 총 훈련 손실을 결정하는 단계는 다음을 포함할 수 있다: 컴퓨터 기기는 제1 손실 값, 제2 손실 값, 및 제4 손실 값에 기초하여 총 훈련 손실을 획득한다. 예를 들어, 컴퓨터 기기는 훈련된 세그멘테이션 모델(trained segmentation model)을 사용하여 제1 유사도를 결 정할 수 있다. 예를 들어, 컴퓨터 기기는 세그멘테이션 모델을 사용하여 제1 판별 특징 맵 또는 제2 판별 특징 맵의 세그멘테이션 마스크(segmentation mask)를 획득하고, 세그멘테이션 마스크에 기초하여 제1 판별 특징 맵 의 비얼굴 영역과 제2 판별 특징 맵의 비얼굴 영역 사이의 제1 유사도를 결정할 수 있다. 세그멘테이션 마스크 는 제1 판별 특징 맵 또는 제2 판별 특징 맵의 이진 이미지일 수 있고, 이진 이미지에서 비얼굴 영역에 대응하 는 픽셀의 값은 1이고, 얼굴 영역 이외의 영역에 대응하는 픽셀의 값은 0이므로, 얼굴 이외의 배경 영역이 효과 적으로 추출된다. 예를 들어, 컴퓨터 기기는 다음 공식 4를 사용하여 샘플 이미지 쌍에 대응하는 제4 손실 값을 결정할 수 있다: 공식 4: ; 여기서 은 제4 손실 값을 나타내고 는 세그멘테이션 마스크를 나타내고, 판별기는 M개의 컨볼루션 계층 을 포함하며, 여기서 제1 내지 제m 컨볼루션 계층이 컨볼루션 계층의 제1 부분이다. 제m 내지 제M 컨볼루션 계 층이 컨볼루션 계층의 제2 부분이다. 는 컨볼루션 계층의 제1 부분에서 제i 컨볼루션 계층으로부터 출력 되는 샘플 타깃 이미지의 특징 맵을 나타내고; 는 컨볼루션 계층의 제1 부분에서 제i 컨볼루션 계층으로 부터 출력되는 샘플 생성 이미지의 특징 맵을 나타내고; 는 컨볼루션 계층의 제2 부분에서 제j 컨볼루션 계층으로부터 출력되는 샘플 타깃 이미지의 특징 맵을 나타내고; 는 컨볼루션 계층의 제2 부분에서 제j 컨볼루션 계층으로부터 출력되는 샘플 생성 이미지의 특징 맵을 나타낸다. m의 값은 0 이상 M 이하의 양의 정수 이며, m의 값은 필요에 따라 설정될 수 있다. 이는 본 출원에서 한정되지 않는다. 일부 실시예에서, 컴퓨터 기기는 또한 손실 계산을 수행하기 위해 이미지의 식별 특징 사이의 유사도를 개별적 으로 획득할 수 있다. 예를 들어, 총 훈련 손실을 결정하기 전에, 각각의 샘플 이미지 쌍에 대해, 컴퓨터 기기 는 샘플 소스 이미지의 제1 식별 특징, 샘플 타깃 이미지의 제2 식별 특징, 및 샘플 생성 이미지의 제3 식별 특 징을 개별적으로 추출할 수 있고; 제1 식별 특징 및 제3 식별 특징에 기초하여 샘플 소스 이미지와 샘플 생성 이미지 사이의 제1 식별 유사도를 결정할 수 있고; 컴퓨터 기기는 제2 식별 특징 및 제3 식별 특징에 기초하여 샘플 생성 이미지와 샘플 타깃 이미지 사이의 제1 식별 거리를 결정하고, 제1 식별 특징 및 제2 식별 특징에 기 초하여 샘플 소스 이미지와 샘플 타깃 이미지 사이의 제2 식별 거리를 결정하고; 컴퓨터 기기는 제1 식별 거리 및 제2 식별 거리에 기초하여 거리 차이를 결정할 수 있고; 컴퓨터 기기는 각각의 샘플 이미지 쌍에 대응하는 제1 식별 유사도 및 거리 차이에 기초하여 각각의 샘플 이미지 쌍에 대응하는 제5 손실 값을 결정한다. 컴퓨터 기기가 총 훈련 손실을 결정하는 단계는 다음을 포함할 수 있다: 컴퓨터 기기는 제1 손실 값, 제2 손실 값 및 제5 손실 값에 기초하여 총 훈련 손실을 획득한다. 예를 들어, 컴퓨터 기기는 다음 공식 5를 사용하여 제5 손실 값을 결정할 수 있다: 공식 5: ; 여기서 은 다섯 번째 손실 값을 나타내고, 는 샘플 소스 이미지의 제1 식별 특징을 나타내고, 는 샘플 타깃 이미지의 제2 식별 특징을 나타내고, 는 샘플 생성 이미지의 제3 식별 특징을 나타 내고; 는 샘플 소스 이미지와 샘플 생성 이미지 사이의 제1 식별 유사도를 나타내고; 는 샘플 생성 이미지와 샘플 타깃 이미지 간의 제1 식별 거리를 나타내고; 는 샘플 소스 이미지와 샘플 타깃 이미지 사이의 제2 식별 거리를 나타내며;는 거리 차이를 나타낸다. 거리 차이는 제1 식별 거리와 제2 식별 거리를 사용하여 결정된다. 제2 식별 거리를 사용하여 샘플 소스 이미지 와 샘플 타깃 이미지 사이의 거리가 측정되므로, 거리 차이가 최소화되어, 제1 식별 거리, 즉 샘플 생성 이미지 와 샘플 타깃 이미지 사이의 거리가 존재하도록 하고, 그 거리는 샘플 소스 이미지와 샘플 타깃 이미지 사이의 거리와 같다. 제1 식별 유사도를 사용함으로써, 생성된 이미지가 타깃 이미지의 식별 특징을 갖도록 보장한다. 따라서 모델 훈련 정확도가 향상되고 얼굴 변경 정확도가 향상된다. 예를 들어, 총 훈련 손실은 전술한 5개의 손실 값이 포함된다. 컴퓨터 기기는 다음 공식 6을 사용하여 총 훈련 손실을 결정할 수 있다: 공식 6: ; 여기서 은 총 훈련 손실을 나타내고, 은 제2 손실 값을 나타내고, 는 제1 손실 값을 나타내고, 은 제3 손실 값을 나타내고, 은 제4 손실 값을 나타내며, 은 제5 손실 값을 나타낸다. 실제 애플리케이션에서, 컴퓨터 기기는 타깃 조건이 충족되고 훈련이 중지될 때까지 총 훈련 손실에 기초하여 초기 얼굴 변경 모델을 훈련하여 얼굴 변경 모델을 획득한다. 전술한 단계 501 내지 단계 504에 기초하여, 컴퓨터 기기는 초기 얼굴 변경 모델에 대해 반복 훈련을 수행하고, 각각의 반복 훈련에 대응하는 총 훈련 손실을 획득하고, 각각의 반복 훈련의 총 훈련 손실에 기초하여 초기 얼 굴 변경 모델의 파라미터를 조정할 수 있다, 예를 들어 초기 얼굴 변경 모델에서 인코더, 디코더, 생성기 및 판 별기에 포함된 파라미터를 총 훈련 손실이 타깃 조건을 충족할 때까지 최적화하여, 컴퓨터 기기는 훈련을 중지 하고 마지막으로 최적화된 초기 얼굴 변경 모델을 얼굴 변경 모델로 사용한다. 예를 들어, 컴퓨터 기기는 Adam 알고리즘 최적화기(Adam algorithm optimizer)를 사용하고 학습율 0.0001을 사용하여 초기 얼굴 변경 모델에 대 해 반복 훈련을 타깃 조건에 도달할 때까지 수행할 수 있으며, 타깃 조건에 도달하면 훈련이 수렴에 도달한 것으로 간주하고 훈련을 중지한다. 예를 들어, 타깃 조건은 총 손실의 값이 타깃 값 범위 내에 있는 것, 예를 들 어 총 손실이 0.5 미만인 것일 수 있다. 대안적으로, 반복 훈련을 여러 번 수행하는 데 소요되는 시간이 최대 지속 기간을 초과하는 경우 등이다. 도 3은 본 출원의 일 실시예에 따른 얼굴 변경 모델의 개략적인 프레임워크도이다. 도 3에 도시된 바와 같이, 컴퓨터 기기는 객체 A의 얼굴 이미지를 소스 이미지 Xs로 사용하고, 객체 B의 얼굴 이미지를 타깃 이미지 Xt로 이용할 수 있다. 컴퓨터 기기는 고정된 얼굴 인식 네트워크(Fixed FR Net)를 사용하여 소스 이미지의 식별 특징 fid를 획득하고, 컴퓨터 기기는 생성기에 포함된 N개 블록에 식별 특징 fid를 개별적으로 입력한다. 컴퓨터 기기 는 U자형 심층 네트워크 구조의 인코더 및 디코더를 사용하여 타깃 이미지의 적어도 하나의 스케일의 초기 속성 특징 f1att, f2att, ..., fiatt, ..., fN-1att, 및 fNatt을 취득하며, 그것들을 각각 대응하는 스케일의 블록에 입력한 다. 컴퓨터 기기는 마지막 블록에 의해 출력되는 특징 맵이 획득될 때까지 각각의 블록에 대해 전술한 단계 S1 내지 단계 S4의 프로세스를 수행한다. 컴퓨터 기기는 마지막 블록에 의해 출력되는 특징 맵에 기초하여 최종 타 깃 얼굴 변경 이미지Ys,t 를 생성함으로써, 얼굴 변경을 완료한다. 본 출원에서의 이미지 처리 방법에 따르면, 고화질의 얼굴 변경이 구현될 수 있으며, 예를 들어 10242와 같은 고해상도의 얼굴 변경 이미지를 생성할 수 있다. 또한, 생성된 고해상도 얼굴 변경 이미지에서 높은 이미지 품 질 및 소스 이미지에서의 소스 얼굴과의 신원 일관성(identity consistency)이 보장되고, 타깃 이미지에서의 타 깃 얼굴의 주요 속성이 높은 정밀도로 효과적으로 유지된다. 관련 기술에의 방법 A에서는, 2562와 같은 저해상도 의 얼굴 변경 이미지만을 생성할 수 있었다. 본 출원의 이미지 처리 방법에서, 적어도 하나의 스케일의 초기 속 성 특징과 식별 특징은 생성기의 계층 컨볼루션에서 처리되고, 초기 속성 특징은 적어도 하나의 스케일의 제어 마스크를 사용하여 스크리닝되므로, 타깃 얼굴의 식별 특징과 같은 중복 정보는 획득된 타깃 속성 특징으로부터 효과적으로 필터링되어, 타깃 얼굴의 주요 속성 특징을 효과적으로 유지한다. 또한, 적어도 하나의 스케일의 초 기 속성 특징은 서로 다른 스케일의 특징에 대응하도록 하이라이트된다. 더 큰 스케일의 초기 속성 특징에 대응 하는 더 큰 스케일의 제어 마스크를 사용함으로써, 주요 속성의 고화질 스크리닝을 구현할 수 있어, 타깃 얼굴 의 헤어라인(hairline), 주름, 얼굴 폐색과 같은 얼굴 세부 특징이 타깃 얼굴이 고정밀도로 유지되어, 생성된얼굴 변경 이미지의 정밀도와 선명도를 크게 향상시키고, 얼굴 변경 이미지의 현실성을 향상시킨다. 또한, 본 출원의 이미지 처리 방법은 얼굴 변경 후 전체 얼굴 변경 이미지를 직접 생성할 수 있으며, 여기서 전 체 얼굴 변경 이미지는 얼굴 변경 후의 얼굴과 배경 영역을 모두 포함하고, 관련 기술에서의 융합 또는 강화같 은 처리는 필요하지 않다. 얼굴 변경 프로세스의 처리 효율이 크게 향상된다. 또한, 본 출원의 얼굴 변경 모델 훈련 방법에서는 모델 훈련 시, 초기 얼굴 변경 모델에 있고 샘플 생성 이미지 생성에 사용되는 전체 생성 프레임워크에 대해 종단 간 훈련을 수행할 수 있어, 다단계 훈련으로 인한 오류 누 적을 방지할 수 있어, 본 출원의 얼굴 변경 모델은 보다 안정적으로 얼굴 변경 이미지를 생성할 수 있고 얼굴 변경 프로세스의 안정성 및 신뢰성이 향상된다. 또한, 본 출원에서의 이미지 처리 방법은 더 높은 해상도의 얼굴 변경 이미지를 생성할 수 있으며, 타깃 이미지 에서의 타깃 얼굴의 질감, 피부 밝기 및 헤어라인과 같은 세부 사항을 정확하게 유지하여, 얼굴 변경의 정밀도, 선명도, 및 현실성을 향상시킬 수 있고, 게임이나 영화와 같이, 얼굴 변경 품질에 대한 요구 사항이 더 높은 시 나리오에 적용될 수 있다. 또한, 가상 이미지 유지관리 시나리오에서 본 출원의 이미지 처리 방법에서 객체의 얼굴이 임의 객체의 얼굴로 대체될 수 있다. 특정 가상 이미지에 대하여, 특정 가상 이미지의 얼굴이 임의의 객 체의 얼굴로 대체될 수 있고, 이는 가상 이미지의 유지관리를 용이하게 하고, 가상 이미지의 유지관리의 편의성 을 향상시킨다. 다음은 본 출원의 이미지 처리 방법의 얼굴 변경 결과와 관련 종래기술의 얼굴 변경 결과를 비교하여 나타낸 것 이다. 비교로부터 본 출원의 이미지 처리 방법에 의해 생성된 고화질의 얼굴 변경 결과는 질적, 양적 비교에서 관련 종래기술에 비해 명백한 우월성을 나타냄을 알 수 있다. 도 7은 관련 술의 일부 방법(이하, 방법 A)과 본 출원에서 제공하는 방안의 고화질 얼굴 변경 결과를 비교한 도 면이다. 비교로부터 A 방법에서는 명백한 피부 밝기의 불일치가 발생하고, 얼굴의 헤어라인 폐색을 유지할 수 없음을 알 수 있다. 본 출원에서 제공되는 방안으로 생성된 결과는 타깃 사람 얼굴의 피부 밝기, 표현, 피부 질 감 및 폐색과 같은 속성 특징을 유지하고, 더 나은 이미지 품질을 가지며 더 현실적이다. 아래의 표 1은 관련 기술의 방법 A와 본 출원에서 제공하는 방안의 고화질 얼굴 변경 결과를 정량적으로 비교한 것이다. 표 1의 실험 데이터는 생성된 얼굴 변경 이미지에서의 얼굴과 소스 이미지에서의 얼굴 간의 신원 유사 도(ID Retrieval, ID 검색), 얼굴 변경 이미지에서의 얼굴과 타깃 이미지에서의 어굴 사이의 포즈 오차(Pose Error) 그리고 얼굴 변경 이미지에서의 얼굴과 실제 얼굴 이미지 사이의 이미지 품질 차이(FID)를 비교한다. 표 1의 실험 데이터로부터, 본 출원에서 제공되는 방안의 고화질 얼굴 변경 결과의 신원 유사도가 관련 방법 A에 비해 현저히 높음을 알 수 있다. 본 출원에서 제안한 솔루션의 고화질 얼굴 변경 결과의 포즈 차 이는 종래 기술의 방법 A보다 낮고, 본 출원의 솔루션의 포즈 차이도 더 낮다. 본 출원에서 제안한 방안의 고화 질 얼굴 변경 결과의 포즈 차이는 관련 종래기술의 방법 A보다 명백히 낮으며, 본 출원의 방안에서 획득되는 얼 굴 변경 이미지와 실제 사진 사이의 사진 품질 차이는 비교적 작다. 따라서 본 출원에서 제공되는 방안은 이미 지 품질, 소스 얼굴과의 신원 일관성, 타깃 얼굴의 속성 유지 등을 고려하여, 관련 기술의 방법 A에 비해 상당 한 이점이 있다."}
{"patent_id": "10-2022-7038636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "본 출원의 본 실시예에서의 이미지 처리 방법에 따르면, 소스 이미지의 식별 특징 및 타깃 이미지의 적어도 하 나의 스케일의 초기 속성 특징이 획득된다. 식별 특징은 훈련된 얼굴 변경 모델에서의 생성기에 입력되고, 적어 도 하나의 스케일의 초기 속성 특징은 생성기에서의 대응하는 스케일의 컨볼루션 계층에 개별적으로 입력되어 타깃 얼굴 변경 이미지를 획득한다. 생성기의 각각의 컨볼루션 계층에서, 식별 특징 및 이전 컨볼루션 계층에의해 출력된 제1 특징 맵에 기초하여 제2 특징 맵이 생성될 수 있다. 제2 특징 맵 및 초기 속성 특징에 기초하 여 대응하는 스케일의 타깃 이미지의 제어 마스크가 결정되므로, 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는 타깃 이미지의 픽셀을 정확하게 찾을 수 있다. 제어 마스크에 기초하여 초기 속성 특징에서 타깃 속성 특 징이 선택되고, 타깃 속성 특징과 제2 특징 맵에 기초하여 제3 피처 맵이 생성되어, 다음 컨볼루션 계층에 출력 된다. 제3 특징 맵은 적어도 하나의 컨볼루션 계층에 의해 처리되어, 최종 타깃 얼굴 변경 이미지에서 타깃 얼 굴의 속성 및 세부 특징이 효과적으로 보존된다. 이는 얼굴 변경 이미지에서 얼굴의 선명도를 크게 향상시키고, 고화질 얼굴 변경를 구현하며, 얼굴 변경의 정밀도를 향상시킨다. 도 8은 본 출원의 일 실시예에 따른 이미지 처리 장치의 개략적인 구성도이다. 도 8에 도시된 바와 같이, 이 이 미지 처리 장치는 특징 취득 모듈 및 얼굴 변경 모듈를 포함하고, 특징 취득 모듈은 수신된 얼굴 변경 요청에 응답하여 소스 이미지의 식별 특징 및 타깃 이미지의 적어도 하나의 스케일의 초기 속성 특징을 취득하도록 구성되고; 얼굴 변경 요청은 타깃 이미지 내의 타깃 얼굴을 소스 이미지 내의 소스 얼굴로 교체하도록 요청하는 데 사용되 고, 식별 특징은 소스 얼굴이 속한 객체를 나타내고, 초기 속성 특징은 타깃 얼굴의 3차원 속성을 나타내며; 얼굴 변경 모듈은 식별 특징 및 적도 하나의 스케일의 초기 속성 특징을 얼굴 변경 모델에 입력하고; 얼굴 변경 모델을 사용하여 식별 특징 및 적어도 하나의 스케일의 초기 속성 특징에 대해 특징 융합을 반복적으 로 수행하여 융합 특징을 획득하고; 얼굴 변경 모델을 사용하여 융합 특징에 기초한 타깃 얼굴 변경 이미지를 생성하고, 타깃 얼굴 변경 이미지를 출력하도록 구성되며; 상기 얼굴 변경 이미지에서의 얼굴은 소스 얼굴의 식별 특징 및 타깃 얼굴의 타깃 속성 특징과 융합된다. 일부 실시예에서, 얼굴 변경 모델은 각각이 하나의 스케일에 대응하는 적어도 하나의 컨볼루션 계층을 포함하고; 얼굴 변경 모듈의 컨볼루션 계층은 취득 유닛, 생성 유닛, 및 속성 스크리닝 유닛을 포함한다. 취득 유닛은 현재 컨볼루션 계층의 이전 컨볼루션 계층에 의해 출력되는 제1 특징 맵(feature map)을 취득하도 록 구성되고; 생성 유닛은 식별 특징 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하도록 구성되고; 속성 스크리닝 유닛은 적어도 하나의 스케일의 초기 속성 특징으로부터 타깃 속성 특징을 선택하도록 구성되고, 타깃 속성 특징은 타깃 얼굴의 식별 특징 이외의 특징이며; 생성 유닛은 추가로, 타깃 속성 특징 및 제2 특징 맵에 기초하여 제3 특징 맵을 생성하고, 제3 특징 맵을 현재 컨볼루션 계층의 다음 컨볼루션 계층에 출력하여, 다음 컨볼루션 계층의 제1 특징 맵의 역할을 하도록 하고 -; 적어도 하나의 컨볼루션 계층 중 마지막 컨볼루션 계층에 의해 출력되는 제3 특징 맵을 융합 특징으로 결정하도 록 구성된다. 일부 실시예에서, 얼굴 번경 모듈의 컨볼루션 계층은 추가로, 제2 특징 맵 및 초기 속성 특징에 기초하여 대응하는 스케일에 대응하는 타깃 이미지의 제어 마스크를 결정하도 록 구성된 제어 마스크 결정 유닛을 더 포함하고; 제어 마스크는 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는 픽셀을 표현하는 데 사용되며; 생성 유닛은 추가로, 제어 마스크에 기초하여 적어도 하나의 스케일의 초기 속성 특징을 스크리닝하여 타깃 속 성 특징을 획득하도록 구성된다. 일부 실시예에서, 제어 마스크 결정 유닛은 추가로, 제2 특징 맵과 초기 속성 특징에 대해 특징 연결(feature concatenation)을 수행하여 연결된 특징 맵을 획득하고; 미리 구성된 매핑 컨볼루션 커널(mapping convolution kernel) 및 활성화 함수에 기초하여 연결된 특징 맵을 제 어 마스크에 매핑하도록 구성된다. 일부 실시예에서, 초기 속성 특징과 컨볼루션 계층의 수량은 모두 타깃 수량이고, 타깃 수량의 컨볼루션 계층은 직렬로 연결되고, 서로 다른 초기 속성 특징은 서로 다른 스케일에 대응하고, 각각의 컨볼루션 계층은 하나의스케일의 초기 속성 특징에 대응하고, 타깃 수량은 2 이상이며; 취득 유닛은 추가로, 현재 컨볼루션 계층이 타깃 수량의 컨볼루션 계층 중 첫 번째 컨볼루션 계층인 경우 초기 특징 맵을 취득하고, 초기 특징 맵을 현재 컨볼루션 계층에 입력되는 제1 특징 맵으로 사용하도록 구성된다. 일부 실시예에서, 생성 유닛은 추가로, 식별 특징에 대해 아핀 변환을 수행하여 제1 제어 벡터를 획득하고; 제1 제어 벡터에 기초하여 현재 컨볼루션 계층의 제1 컨볼루션 커널을 제2 컨볼루션 커널에 매핑하고; 제2 컨볼루션 커널에 기초하여 제1 특징 맵에 대해 컨볼루션 연산을 수행하여 제2 특징 맵을 생성하도록 구성된다. 일부 실시예에서, 이미지 처리 장치가 얼굴 변경 모델을 훈련시킬 때, 이미지 처리 장치는, 샘플 데이터세트를 취득하도록 구성된 샘플 취득 모듈 - 샘플데이터는 적어도 하나의 샘플 이미지 쌍을 포함하 고, 각각의 샘플 이미지 쌍은 하나의 샘플 소스 이미지와 하나의 샘플 타깃 이미지를 포함함 -; 샘플 이미지 쌍에서 샘플 소스 이미지의 샘플 식별 특징을 취득하고 샘플 이미지 쌍에서 샘플 타깃 이미지의 적 어도 하나의 스케일의 샘플 초기 속성 특징을 취득하도록 구성된 샘플 특징 취득 모듈; 초기 얼굴 변경 모델의 생성기를 사용하여 샘플 식별 특징 및 적어도 하나의 스케일의 샘플 초기 속성 특징에 대해 특징 융합을 반복적으로 수행하여 샘플 융합 특징을 획득하도록 구성된 생성 모듈; 초기 얼굴 변경 모델의 판별기(discriminator)를 사용하여 샘플 생성 이미지와 샘플 소스 이미지를 판별하여 판 별 결과를 획득하도록 구성된 판별 모듈; 판별 결과에 기초하여 초기 얼굴 변경 모델의 손실을 결정하도록 구성된 손실 결정 모듈; 및 손실에 기초하여 초기 얼굴 변경 모델을 훈련시켜 얼굴 변경 모델을 획득하도록 구성된 훈련 모듈을 더 포함한 다. 일부 실시예에서, 판별 결과는 샘플 소스 이미지에 대한 제1 판별 결과 및 샘플 생성 이미지에 대한 제2 판별 결과를 포함하고; 손실 결정 모듈은 추가로, 각각의 샘플 이미지 쌍에서의 샘플 타깃 이미지의 적어도 하나의 스케일의 샘플 마스크를 취득하고, 적어도 하나의 스케일의 샘플 마스크에 기초하여 제1 손실 값을 결정하고, 제1 판별 결과 및 제2 판별 결과에 기초하여 제2 손실 값을 결정하도록 구성되고; 훈련 모듈은 추가로, 타깃 조건이 충족되고 훈련이 중지될 때까지 총 훈련 손실에 기초하여 초기 얼굴 변경 모 델을 훈련하여 얼굴 변경 모델을 획득하도록 구성된다. 일부 실시예에서, 샘플 소스 이미지와 샘플 타깃 이미지는 동일한 객체에 대응하고; 상기 손실 결정 모듈은 추가로, 샘플 생성 이미지 및 샘플 타깃 이미지에 기초하여 제3 손실 값을 취득하고; 제 3 손실 값, 제1 손실 값 및 제2 손실 값에 기초하여 총 훈련 손실을 획득하도록 구성된다. 일부 실시예에서, 판별기는 적어도 하나의 컨볼루션 계층을 포함한다. 손실 결정 모듈은 추가로, 각각의 샘플 이미지 쌍에 대해, 제1 판별 특징 맵의 비얼굴 영역과 제2 판별 특징 맵의 비얼굴 영역 사이의 제1 유사도를 결정하고 - 제1 판별 특징 맵은 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 타깃 이미지의 특징 맵이고, 제2 판별 특징 맵은 컨볼루션 계층의 제1 부분에 의해 출력되는 샘플 생성 이미지의 특징 맵임 -; 제3 판별 특징 맵과 제4 판별 특징 맵 사이의 제2 유사도를 결정하고 - 제3 판별 특징 맵은 컨볼루션 계층의 제 2 부분에 의해 출력되는 샘플 타깃 이미지의 특징 맵이고, 제4 판별 특징 맵은 컨볼루션 계층의 제2 부분에 의 해 출력되는 샘플 생성 이미지의 특징 맵임 -; 제1 유사도 및 제2 유사도에 기초하여 제4 손실 값을 결정하고; 제1 손실 값, 제2 손실 값 및 제4 손실 값에 기초하여 총 훈련 손실을 획득하도록 구성된다. 일부 실시예에서, 손실 결정 모듈은 추가로, 샘플 소스 이미지의 제1 식별 특징, 샘플 타깃 이미지의 제2 식별 특징 및 샘플 생성 이미지의 제3 식별 특징을 추출하고; 제1 식별 특징 및 제3 식별 특징에 기초하여 샘플 소스 이미지와 샘플 생성 이미지 사이의 제1 식별 유사도 (identity similarity)를 결정하는 단계; 제2 식별 특징 및 제3 식별 특징에 기초하여 샘플 생성 이미지와 샘플 타깃 이미지 사이의 제1 식별 거리 (identity distance)를 결정하는 단계; 제1 식별 특징 및 제2 식별 특징에 기초하여 샘플 소스 이미지와 샘플 타깃 이미지 사이의 제2 식별 거리를 결 정하는 단계; 제1 식별 거리 및 제2 식별 거리에 기초하여 거리 차이를 결정하는 단계; 각각의 샘플 이미지 쌍에 대응하는 제1 식별 유사도 및 거리 차이에 기초하여 제5 손실 값을 결정하고; 제1 손실 값, 제2 손실 값 및 제5 손실 값에 기초하여 총 훈련 손실을 획득하도록 구성된다. 본 출원의 본 실시예에서의 이미지 처리 장치에 따르면, 소스 이미지의 식별 특징 및 타깃 이미지의 적어도 하 나의 스케일의 초기 속성 특징이 획득된다. 식별 특징은 훈련된 얼굴 변경 모델에서의 생성기에 입력되고, 적어 도 하나의 스케일의 초기 속성 특징은 생성기에서의 대응하는 스케일의 컨볼루션 계층에 개별적으로 입력되어 타깃 얼굴 변경 이미지를 획득한다. 생성기의 각각의 컨볼루션 계층에서, 식별 특징 및 이전 컨볼루션 계층에 의해 출력된 제1 특징 맵에 기초하여 제2 특징 맵이 생성될 수 있다. 제2 특징 맵 및 초기 속성 특징에 기초하 여 대응하는 스케일의 타깃 이미지의 제어 마스크가 결정되므로, 타깃 얼굴의 식별 특징 이외의 특징을 가지고 있는 타깃 이미지의 픽셀을 정확하게 찾을 수 있다. 제어 마스크에 기초하여 초기 속성 특징에서 타깃 속성 특 징이 선택되고, 타깃 속성 특징과 제2 특징 맵에 기초하여 제3 피처 맵이 생성되어, 다음 컨볼루션 계층에 출력 된다. 제3 특징 맵은 적어도 하나의 컨볼루션 계층에 의해 처리되어, 최종 타깃 얼굴 변경 이미지에서 타깃 얼 굴의 속성 및 세부 특징이 효과적으로 보존된다. 이는 얼굴 변경 이미지에서 얼굴의 선명도를 크게 향상시키고, 고화질 얼굴 변경를 구현하며, 얼굴 변경의 정밀도를 향상시킨다. 도 9는 본 출원의 일 실시예에 따른 컴퓨터 기기의 개략적인 구성도이다. 도 9에 도시된 바와 같이, 컴퓨터 기 기는 메모리 및 프로세서를 포함하고; 메모리는 컴퓨터 프로그램을 저장하도록 구성되고; 및 프로세서는 메모리 에 저장된 컴퓨터 프로그램을 구현하여, 본 출원의 실시예에 따른 이미지 처리 방법을 수행하도록 구성된다. 일부 실시예에서, 컴퓨터 기기가 제공된다. 도 9에 도시된 바와 같이, 도 9에 도시된 컴퓨터 기기는 프로 세서와 메모리를 포함한다. 프로세서와 메모리는 예를 들어 버스에 의해 연결된다. 예를 들어, 컴퓨터 기기는 송수신기를 더 포함할 수 있고, 소수신기는 데이터 전송 및/또는 데 이터 수신과 같은 컴퓨터 기기와 다른 컴퓨터 기기 간에 데이터를 교환하도록 구성됩니다. 실제 적용시에는, 하 나 이상의 송수신기가 있을 수 있다. 컴퓨터 기기의 구성은 본 출원의 이 실시예에 대한 한정을 구성 하지 않는다. 프로세서는 중앙 처리 유닛(Central Processing Unit, CPU), 범용 프로세서, 디지털 신호 프로세서 (Digital Signal Processor, DSP), 주문형 반도체(Application-Specific Integrated Circuit, ASIC), 필드 프 로그래머블 게이트 어레이(Field Programmable Gate Array, FPGA) 또는 다른 프로그램 가능한 논리 디바이스, 트랜지스터 논리 디바이스, 하드웨어 구성 요소, 또는 이들의 조합일 수 있다. 프로세서는 본 출원에 개시된 내 용을 참조하여 설명된 논리 블록, 모듈 및 회로의 다양한 예를 구현하거나 수행할 수 있다. 프로세서는 또 한 예를 들어 하나 이상의 마이크로프로세서의 조합 또는 DSP와 마이크로프로세서의 조합을 포함하는 컴퓨팅 기 능을 구현하는 조합일 수 있다. 버스는 전술한 구성요소들 사이에서 정보를 전송하기 위한 채널을 포함할 수 있다. 버스는 주변 구성 요소 상호 연결(Peripheral Component Interconnect, PCI) 버스, 확장 산업 표준 아키텍처(Extended Industry Standard Architecture, EISA) 버스 등일 수 있다. 버스는 어드레스 버스, 데이터 버스, 제어 버스 등으 로 분류될 수 있다. 설명의 편의를 위해 도 9에서의 버스는 하나의 굵은 선만 사용하여 표시되지만 하나의 버스 또는 한 가지 유형의 버스만 있음을 나타내지는 않는다. 메모리는 읽기 전용 메모리(Read-Only Memory, ROM) 또는 정적 정보 및 명령어를 저장할 수 있는 다른 유 형의 정적 저장 기기, 랜덤 액세스 메모리(Random Access Memory, RAM) 또는 정보 및 명령을 저장할 수 있는 다 른 유형의 동적 저장 기기 또는 전기적으로 소거 가능한 프로그램 가능한 읽기 전용 메모리(Electrically Erasable Programmable Read-Only Memory, EEPROM), 컴팩트 디스크 읽기 전용 메모리(Compact Disc Read-Only Memory, CD-ROM), 또는 기타 컴팩트 디스크 스토리지 또는 광 디스크 스토리지(압축된 광 디스크, 레이저 디스 크, 광 디스크, 디지털 범용 광 디스크, 블루레이 광 디스크 등을 포함), 자기 디스크 스토리지 매체 또는 다른 자기 저장 기기, 또는 컴퓨터 프로그램 및 컴퓨터에 의해 판독되는 다른 매체를 운반하거나 저장할 수 있는 기 타 매체를 포함하나, 이에 한정되지 않는다.메모리는 본 출원 실시예를 수행하기 위한 컴퓨터 프로그램을 저장하도록 구성되고, 컴퓨터 프로그램은 프 로세서의 제어 하에 실행된다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 실행하여 전술한 방법 실시예 중 어느 하나의 단계를 구현하도록 구성된다. 전자 기기는 서버, 단말 또는 클라우드 컴퓨팅 센터 기기를 포함하지만 이에 한정되지 않는다. 본 출원의 실시예는 컴퓨터 프로그램을 저장하는 컴퓨터 판독 가능한 저장 매체를 제공하며, 컴퓨터 프로그램은 프로세서에 의해 실행될 때 전술한 방법 실시예에 따른 단계 및 대응하는 내용을 구현한다. 본 출원의 실시예에서는 컴퓨터 프로그램, 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품이 더 제공되며, 컴퓨터 프로그램은 프로세서에 의해 실행될 때 전술한 방법 실시예에 따른 단계 및 대응하는 내용을 구현한다. 본 출원의 명세서, 청구범위 및 첨부 도면에서, 용어 \"제1\", \"제2\", \"제3째\", \"제4\", \"하나\", \"둘\" 등은 (존재 하는 경우) 특정 순서나 우선 순위를 설명하기보다는 유사한 객체를 구별하기 위한 것이다. 그렇게 사용된 데이 터는 적절한 조건에서 교환될 수 있으므로 여기에 설명된 본 출원의 실시예는 여기에 설명되거나 설명된 것과 다른 순서로 구현될 수 있음을 이해해야 한다. 전술한 설명은 단지 본 출원의 일부 구현 시나리오의 선택적인 구현일 뿐이다. 당업자에게 있어, 본 출원의 방 안의 기술적 개념을 벗어나지 않고 사용되는 본 출원의 기술적 사상에 기초한 다른 유사한 구현도 본 출원의 실 시예의 보호 범위에 속한다."}
{"patent_id": "10-2022-7038636", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 출원의 일 실시예에 따른 이미지 처리 방법의 구현 환경의 개략도이다. 도 2는 본 출원의 일 실시예에 따른 이미지 처리 방법의 개략적인 흐름도이다. 도 3은 본 출원의 일 실시예에 따른 얼굴 변경 모델의 개략적인 구성도이다. 도 4는 본 출원의 일 실시예에 따른 생성기의 블록의 개략적인 구성도이다. 도 5는 본 출원의 일 실시예에 따른 얼굴 변경 모델 훈련 방법의 개략적인 흐름도이다. 도 6은 본 출원의 일 실시예에 따른 적어도 하나의 스케일의 제어 마스크의 개략도이다. 도 7은 본 출원의 일 실시예에 따른 얼굴 변경 결과 비교의 개략도이다. 도 8은 본 출원의 일 실시예에 따른 이미지 처리 장치의 개략적인 구성도이다.도 9는 본 출원의 일 실시예에 따른 컴퓨터 기기의 개략적인 구성도이다."}
