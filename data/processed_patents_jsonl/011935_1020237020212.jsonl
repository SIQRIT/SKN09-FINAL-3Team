{"patent_id": "10-2023-7020212", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0109685", "출원번호": "10-2023-7020212", "발명의 명칭": "체화된 에이전트들에서의 자율 애니메이션", "출원인": "소울 머신스 리미티드", "발명자": "허튼, 조"}}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서,i. 상기 가상 캐릭터 또는 디지털 엔티티에 의해 발화될 단어들을 특정하는 입력 텍스트를 수신하는 단계;ii. 입력 텍스트에 적용될 포즈를 결정하는 단계;iii. 입력 텍스트에 적용될 액션을 결정하는 단계; 및iv. 상기 포즈로부터 적용되는 상기 액션을 표현하는 상기 가상 캐릭터 또는 디지털 엔티티의 적어도 하나의 모션을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 포즈는 팔 포즈이고, 상기 포즈를 결정하는 방법은 팔들 사이의 수평 거리를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 포즈는 팔 포즈이고, 상기 포즈를 결정하는 방법은 하나 이상의 팔들의 수직높이를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 적어도 하나의 모션은 비트 제스처인, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하기 위한 시스템으로서,i. 입력 텍스트를 수신하는 입력 모듈;ii. 결정 모듈 - 상기 결정 모듈은,i. 입력 텍스트에 적용될 포즈; 및ii. 적어도 하나의 포즈로부터 적용될 액션을 결정함 -; 및iii. 상기 포즈 및 상기 액션에 기초하여 상기 가상 캐릭터 또는 디지털 엔티티의 적어도 하나의 모션을 생성하는 출력 모듈을 포함하는, 시스템."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서,i. 애니메이션화될 입력 포즈를 결정하는 단계;ii. 제스처를 표현하는 변동 포즈를 결정하는 단계 - 상기 변동 포즈는 상기 입력 포즈와 블렌딩하도록 구성됨-;iii. 상기 입력 포즈와 상기 변동 포즈 사이의 가중된 보간을 포함하는 블렌딩된 포즈를 결정하는 단계; 및iv. 상기 블렌딩된 포즈를 사용하여 상기 가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 단계를포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2023-0109685-3-제1항에 있어서, 상기 포즈를 결정하는 단계는 제6항의 방법의 단계들을 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하기 위한 시스템으로서,i. 결정 모듈 - 상기 결정 모듈은,i. 애니메이션화될 입력 포즈;ii. 상기 입력 포즈와 블렌딩하도록 구성되는, 제스처를 표현하는 변동 포즈;iii. 상기 입력 포즈와 상기 변동 포즈 사이의 가중된 보간을 포함하는 블렌딩된 포즈를 결정함 -; 및ii. 상기 블렌딩된 포즈를 사용하여 상기 가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 애니메이션화 모듈을 포함하는, 시스템."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서, 상기 가상 캐릭터 또는 디지털 엔티티는 적어도 하나의 팔, 손목 및 손가락을 갖고, 상기 방법은,i.팔 포즈들의 범위로부터 선택된 팔 포즈;손목 포즈들의 범위로부터 선택된 손목 포즈; 및 손가락 포즈들의 범위로부터 선택된 손가락 포즈중 적어도 2개를 결정하는 단계; 및ii. 상기 팔 포즈, 상기 손목 포즈 및/또는 상기 손가락 포즈를 포함하는 전체 포즈를 디스플레이하도록 상기가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 적어도 2개를 결정하는 단계는 랜덤으로 결정되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서, 상기 가상 캐릭터 또는 디지털 엔티티는 적어도 하나의 사지(limb)를 갖고, 상기 방법은,i. 적어도,사지 포즈들의 범위로부터 선택된 사지 포즈; 및하위 부분 포즈들의 범위로부터 선택된 상기 사지의 하위 부분의 포즈를 결정하는 단계; 및ii. 상기 사지 포즈 및 상기 사지의 상기 하위 부분의 포즈를 포함하는 전체 포즈를 디스플레이하도록 상기 가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 적어도 결정하는 단계는 랜덤으로 결정되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서,i. 상기 가상 캐릭터 또는 디지털 엔티티에 의해 발화될 단어들을 특정하는 입력 텍스트를 수신하는 단계;ii. 상기 입력 텍스트에서 각각의 단어의 강조 점수를 결정하는 단계;iii. 상기 입력 텍스트 내의 나머지 단어들과 비교하여 비교적 더 높은 강조 점수를 갖는 단어들의 세트를 결정하는 단계; 및공개특허 10-2023-0109685-4-iv. 상기 입력 텍스트를 발화하도록 가상 캐릭터 또는 디지털 엔티티를 애니메이션화하고 비교적 더 높은 강조점수를 갖는 단어들의 세트로부터의 각각의 단어에 제스처를 적용하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 제스처는 비교적 더 높은 강조 점수를 갖는 상기 단어들의 세트로부터의 각각의 단어의강세 음절에 적용되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항 또는 제14항에 있어서, 상기 제스처는 비트 제스처인, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항 내지 제15항 중 어느 한 항에 있어서, 상기 강조 점수는 단어 희귀도에 기초하고, 더 높은 희귀도를 갖는 단어들이 더 높은 강조 점수를 갖는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항 내지 제16항 중 어느 한 항에 있어서, 비교적 더 높은 강조 점수를 갖는 상기 단어들의 세트는 상기 입력 텍스트 내의 모든 단어들의 미리 정의된 상위 백분위수 내의 강조 점수를 갖는 상기 입력 텍스트로부터의 단어들을 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항 내지 제16항 중 어느 한 항에 있어서, 상기 단어들의 세트로부터의 각각의 단어에 적용된 상기 제스처는상기 단어의 상기 강조 점수에 비례하는 또는 실질적으로 비례하는 제스처 진폭을 갖는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항 내지 제16항 중 어느 한 항에 있어서, 상기 강조 점수는 각각의 단어의 상기 강조 점수를 결정하기 위해기준들의 세트를 적용함으로써 계산되고, 상기 강조 점수에 대한 각각의 기준의 기여는 가중을 사용하여 가중되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 기준들의 세트는 단어 감정, 품사, 대문자 표시, 부정 및 희귀도로 구성된 그룹으로부터선택되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 가중은 인간 주석자와 동일한 방식으로 단어들을 강조하도록 최적화되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 가중은 기계 학습을 사용하여 최적화되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하기 위한 시스템으로서,i. 입력 텍스트를 수신하기 위한 입력 수신 수단;ii. 복수의 제스처들 - 각각의 제스처는,i. 애니메이션;ii. 상기 애니메이션을 변경하기 위한 적어도 하나의 구성가능한 파라미터; 및iii. 상기 구성가능한 파라미터의 구성 범위와 연관됨 -;iii. 애니메이션 생성기를 포함하고, 상기 애니메이션 생성기는,공개특허 10-2023-0109685-5-i. 적어도 하나의 제스처를 결정하기 위해 입력 텍스트를 분석하고;ii. 상기 구성 범위로부터 상기 구성가능한 파라미터의 구성을 결정하고;iii. 상기 구성가능한 파라미터에 의해 변경된 바와 같이 상기 애니메이션으로 상기 가상 캐릭터 또는 디지털엔티티를 애니메이션화하도록 구성되는, 시스템."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 각각의 제스처는 상기 구성 파라미터의 구성 범위를 조절하기 위한 적어도 하나의 조절 변수와 연관되고,상기 애니메이션 생성기는 상기 조절 변수에 의해 수정된 바와 같이 상기 구성가능한 파라미터의 구성을 결정하도록 구성되는, 시스템."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제23항 또는 제24항에 있어서, 상기 구성 범위로부터 상기 구성가능한 파라미터의 구성을 결정하는 것은 랜덤으로 결정되는, 시스템."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제23항 내지 제25항 중 어느 한 항에 있어서, 구성가능한 파라미터들은 제스처 속도, 제스처 진폭 및 제스처 포즈로 구성된 그룹으로부터 선택되는, 시스템."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서,i. 제스처들의 세트의 하나 이상의 파라미터들을 구성하는 단계 ― 상기 파라미터들은 상기 제스처들이 상기 가상 캐릭터 또는 디지털 엔티티의 특성들을 반영하도록 구성됨 ―; 및ii. 상기 하나 이상의 파라미터들에 의해 구성된 바와 같이 상기 제스처들로 상기 가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 상기 특성들은 문화, 성별, 스타일, 개성 또는 캐릭터 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제27항 또는 제28항에 있어서, 상기 파라미터들은,i. 제스처들의 속도;ii. 제스처들의 위치;iii. 제스처들의 빈도;iv. 제스처들의 진폭; 및v. 제스처들의 손잡이(handedness)를 포함하는 상기 제스처들의 그룹 중 하나 이상으로부터 선택되는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서,i. 상기 가상 캐릭터 또는 디지털 엔티티에 의해 발화될 단어들을 특정하는 입력 텍스트를 수신하는 단계;ii. 적어도 하나의 제스처 유형을 결정하기 위해 상기 입력 텍스트를 분석하는 단계 - 각각의 제스처 유형은 선택에 이용가능한 복수의 제스처들 및 연관된 빈도 값을 포함함 -;iii. 제스처 빈도 값들을 사용하여 입력 텍스트에 적용될 제스처들을 선택하는 단계; 및iv. 상기 선택된 제스처들을 사용하여 상기 가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 단계를 포함하공개특허 10-2023-0109685-6-는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "가상 캐릭터 또는 디지털 엔티티를 애니메이션화하는 방법으로서,i. 상기 가상 캐릭터 또는 디지털 엔티티에 의해 발화될 단어들을 특정하는 입력 텍스트를 수신하는 단계;ii. 파스 트리(Tree)를 생성하는 단계;iii. 상기 가상 캐릭터 또는 디지털 엔티티의 적어도 하나의 애니메이션을 결정하기 위해 상기 파스 트리를 사용하는 단계; 및iv. 상기 애니매이션에 적어도 기초하여 상기 가상 캐릭터 또는 디지털 엔티티의 적어도 하나의 모션을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제31항에 있어서, 상기 파스 트리는 종속성 트리인, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제31항 또는 제32항에 있어서, 부정의 범위를 결정하기 위해 상기 파스 트리를 사용하는 단계, 및 상기 애니메이션을 결정하기 위해 상기 부정의 범위를 사용하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제31항 내지 제33항 중 어느 한 항에 있어서, 열거를 검출하기 위해 상기 파스 트리를 사용하는 단계, 및 상기적어도 하나의 애니메이션을 결정하기 위해 상기 열거를 사용하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제31항 내지 제34항 중 어느 한 항에 있어서, 상기 적어도 하나의 애니메이션을 표현하는 마크업을 생성하는 단계를 더 포함하고, 상기 마크업을 사용하는 것은 상기 가상 캐릭터 또는 디지털 엔티티의 적어도 하나의 모션을생성하는, 방법."}
{"patent_id": "10-2023-7020212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제31항 내지 제35항 중 어느 한 항에 있어서, 상기 적어도 하나의 애니메이션은 얼굴 및/또는 신체 애니메이션인, 방법."}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서에서 설명되는 실시예들은 입력 텍스트에 대한 애니메이션들의 자동 적용 또는 애니메이션 마크업의 자 동 적용에 의한 제스처들의 자율 애니메이션에 관한 것으로, 여기서 마크업은 비언어적 통신 표현들 또는 제스처 들을 트리거한다. 체화된 에이전트의 움직임들이 가능한 한 자연스럽고 인간과 유사하게 되기 위해, TTG 알고리 즘(Text-To-Gesture Algorithm)은 체화된 에이전트에 의해 발화되기 전에 통신 발화의 입력 텍스트를 분석하고, 입력 텍스트의 의미, 콘텍스트 및 감정 콘텐츠, 및 체화된 에이전트의 제스처 스타일 또는 개성이 주어지면 적절 하고 의미있는 제스처들을 이용하여 이를 마크업한다."}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예들은, 가상 캐릭터들, 디지털 엔티티들, 및/또는 로봇들과 같은 체화된 에이전트들의 자율 애 니메이션에 관한 것이다. 보다 구체적으로 그러나 배타적이지 않게, 본 발명의 실시예들은 체화된 에이전트들 을 동적으로 애니메이션화(animate)하기 위한 대화형 콘텐츠의 자동 및 실시간 분석에 관한 것이다."}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "거동 마크업 언어(Behaviour Mark-up Language) 또는 BML은 \"체화된 대화형 에이전트들\"에 대한 언어적 및 비언 어적 거동을 제어하기 위한 XLM-기반 설명 언어이다. BEAT(SIGGRAPH '01)와 같은 규칙-기반 제스처 생성기들은 키워드들과 같은 텍스트의 특징들과 페어링되는 제스처들을 생성하기 위한 규칙들을 적용한다. 이는 반복적인 및 로봇형 제스처를 초래하며, 이는 세분화된 레벨로 맞춤화하기가 어렵다. 규칙들 및 제스처들의 대형 데이터 베이스들이 요구된다. 스피치-구동 제스처 생성기들은 신경망들을 사용하여, 학습된 제스처 및 스피치 조합들 로부터 자동 움직임들을 생성한다. 그러나, 이들 생성기들은 종종 블랙박스 방식으로 작동하고, 입력 스피치와 출력 모션 사이의 일반적인 관계를 가정하며, 제한된 성공을 거두었다. US9205557B2호는 모바일 로봇의 콘텍스트 거동들을 생성하기 위한 방법을 개시한다. 키워드들의 앞에 커맨드 태그들을 자동으로 삽입하기 위한 모듈이 제공된다. US9721373B2는, 발화의 음향적, 구문적, 의미론적, 화용론적 및 수사학적 분석들을 이용하여 캐릭터의 발화 거동을 분석하는 것을 포함할 수 있는, 립싱크 움직임들 및 비언어적 통신을 위한 거동들의 세트를 생성하기 위한 프로그램들을 개시한다. 체화된 자율 에이전트들에 의한 의사소통 발화(communicative utterance)의 효율적인 자동 온-더-플라이 증강 및/또는 수정은 해결되지 않은 문제로 남아 있다. 또한, 체화된 에이전트들을 현실적이고 비반복적이며 쉽게 맞춤화가능한 방식으로 애니메이션화하는 것은 해결되지 않은 문제로 남아 있다. 본 발명의 목적은, 체화된 에이전트들 내의 자율 애니매이션을 개선하거나, 또는 적어도, 유용한 선택안을 대중 또는 산업계에 제공하는 것이다."}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "체화된 에이전트들, 이를테면 가상 캐릭터들, 디지털 엔티티들 및/또는 로봇들은 텍스트 입력으로부터 스피치를 실시간으로 발화함으로써 사용자와 상호작용할 수 있다. 체화된 에이전트는 디지털 아바타, 만화 캐릭터, 의인 화 아바타 등일 수 있거나, 또는 물리적 아바타, 예컨대 물리적 로봇 등일 수 있다. 물리적 로봇은 상이한 부 분들, 예컨대, 얼굴 부분, 신체 부분 등에 대한 다양한 기계적 유닛들을 포함할 수 있어서, 물리적 아바타가 다 양한 얼굴 모션들 및/또는 신체 모션들을 수행할 수 있게 한다. 체화된 에이전트는 눈, 코, 입 중 적어도 하나를 포함하는 얼굴을 가질 수 있고, 다양한 얼굴 모션들을 제시하 도록 애니메이션화될 수 있다. 아바타는 또한, 머리, 어깨들, 손들, 팔들, 다리들, 발들 등 중 적어도 하나를 포함하는 하나 이상의 신체 부분들을 가질 수 있고, 다양한 신체 모션들을 제시하도록 애니메이션화될 수 있다. 스피치에 동기화된 TTS(text to speech) 및 립 애니메이션들은 이러한 체화된 에이전트들이 인간-유사 스피치와 유사하게 한다. 얼굴 표정들 및 손 제스처들과 같은 비언어적 통신은 인간 통신을 보조하고, 체화된 에이전트 들의 애니메이션에 현실성을 부여한다. 본 명세서에서 설명되는 실시예들은 입력 텍스트에 대한 애니메이션들의 자동 적용 또는 애니메이션 마크업의 자동 적용에 의한 제스처들의 자율 애니메이션에 관한 것으로, 여기서 마크업은 비언어적 통신 표현들 또는 제 스처들을 트리거한다. 텍스트-투-제스처 체화된 에이전트의 움직임들이 가능한 한 자연스럽고 인간과 유사하게 되기 위해, 텍스트-투-제스처 알고리즘 (TTG Algorithm)은 체화된 에이전트에 의해 발화되기 전에 의사소통 발화의 입력 텍스트를 분석하고, 입력 텍스 트의 의미, 콘텍스트 및 감정 콘텐츠 및 체화된 에이전트의 제스처 스타일 또는 개성이 주어지면, 적절하고 의 미있는 제스처들로 이를 마크업한다. 예를 들어: 입력 텍스트: \"Would you like to talk about our technology, or our business model?\"은 TTG 알 고리즘에 의해 프로세싱되어 -> \"#SlightlyHappy Would you #Shrug like to #Smile talk about our #BeatBothArmsLeft technology, or our #BeatBothArmsRight business #PalmsSpread model?\"을 출력할 수 있다.TTG 알고리즘은 자연 언어 프로세싱(NLP)을 사용하여, 곧 발화될 텍스트에 대해 가장 미묘하고 자연스러운 제스 처들을 생성하기 위해, 발화될 텍스트로부터 콘텍스트, 의미 및 의사소통 의도의 가능한 최상의 이해를 얻는다. TTG 알고리즘은 모듈식이고 확장가능하므로, 새롭고 더 정교한 분석이 추가될 수 있고, 기존의 분석이 쉽게 수 정되거나 제거될 수 있다. 방법 도 1은 일 실시예에 따른 TTG 알고리즘을 도시한다. 파싱 단계에서, 입력 텍스트의 각각의 절(clause)에 대한 파스 트리(Parse Tree)를 리턴하는 파서에 의해 입력 텍스트가 수신된다. 각각의 절은 트리이고, 트리 내의 각각의 노드는 단어와 대략적으로 동등한 토큰 이고, 또한 토큰에 관한 정보, 이를테면 그의 보조정리, 품사 태그, 및 그의 부모(parent) 노드와의 종속 관계, 강력한 키워드인지 여부, 명사 구문들의 리스트의 일부 등을 포함한다. 일 실시예에서, 종속성 파싱은 토큰들 사이의 관계들을 제공하는 종속성 트리를 출력한다. 임의의 적합한 종속성 파싱 방법 또는 시스템이 사용될 수 있다. 절 분석기 단계에서, 절 분석기는 입력 텍스트에 관한 추가 정보를 파스 트리에 첨부한다. 절 분석기는 절 분석 정보에 기초하여 마크업을 생성하는 마크업 생성기에 대한 입력으로서 제공하기 위해 절 및 토큰들에 관한 정보를 도출한다. 절들이 의미론적 및 구문론적 패턴들에 대해 분석되고, 키워드들, 감정들 및 대화 동작들이 식별된다. 일 실시 예에서, 절 분석기는 종속성 트리를 수신하고, 종속성 정보를 사용하여 절 내의 비트들, 부정들 및 열거 거동들 을 식별한다. 절 분석은 또한 감정 정보를 종속성 트리에 첨부한다. 감정 절의 감정을 분류하기 위해 임의의 적합한 기계 학습 또는 규칙-기반 방법이 사용될 수 있다. 절들은 원자가 (긍정-중립-부정), 각성(낮음-중립-높음), 및 세밀한 감정 콘텐츠(예를 들어, 즐거움, 슬픔, 분노, 놀람, 두려 움, 혐오)에 기초하여 분류될 수 있다. 일 실시예에서, 텍스트 감정 분석 기능은 지원 벡터 머신(SVM)을 사용하여 구성된다. 임의의 적합한 텍스트 감 정 분석 방법이 사용될 수 있다. SVM은 특정 도메인으로부터의 대화형 콘텐츠를 사용하여 트레이닝될 수 있다. 범용 대화의 경우, SVM은 광범위한 도메인들 및 스타일들, 발화의 길이들 및 다른 파라미터들을 사용하여 트레 이닝될 수 있다. 신경망, 결정 트리, 회귀 기반 분류기, 베이지안 분류기를 포함하지만 이에 제한되지 않는 임 의의 다른 적합한 분류기가 사용될 수 있다. 심층 신경망은 세밀한 감정 콘텐츠를 분류하는 데 적합할 수 있다. 단어 감정은 단어 레벨에서 감정을 식별하고 단어들을 긍정 또는 부정으로 식별할 수 있다. 일 실시예에서, 부 정/ 긍정 단어 사전이 사용된다. 절에서 개별 단어들의 원자가가 기록될 수 있다. 예를 들어, 전체 양의 원자 가를 갖는 절에서, 절 분석기는 양의 원자가 단어들을 갖는 온-부정 단어들 및 부정 원자가를 갖는 비-부정 단 어들을 식별할 수 있다. 일 실시예에서, 감정-기반 애니메이션들은 감정 점수에 기초하여 문장들에 적용된다. 감정 분석을 위한 임의의 적합한 모델이 감정 점수를 결정하기 위해 사용되고 적절하게 트레이닝될 수 있다. 부정 범위 검출 부정되는 토큰들(단어들)은 종속성 링크들에 기초하여 결정될 수 있다(예컨대, 부정의 후손들은 부정에 의해 부 정되는 것으로 간주된다). 종속성 트리 구조는 임의의 부정 단어들(즉, 어느 단어들이 부정되는 것으로 간주될 수 있는지)의 범위를 결정할 수 있다. 특히, 부정의 디센던트(descendant), 시블링(sibling), 니블링 (nibling)(시블링의 자식)인 임의의 단어는 부정의 범위 내에 속한다. 열거 단어들의 그룹들을 결정하기 위해 명사 청크들 및 구동사들이 사용될 수 있다. 명사 청크들(명사구들)의 리스 트가 제공될 수 있다.구동사들이 검출될 수 있다. 일 실시예에서, 구동사들은 다음의 단계들을 포함하는 알고리즘에 의해 검출될 수 있다: 1. 동사들을 발견하는 단계, 2. 부사들을 역방향으로 검색하는 단계, 3. 부사들과 전치사 그리고 명사구 들에 대해 순방향으로 검색하는 단계. 단어들의 그룹들에 관한 정보는 애니메이션을 구동하는 데 사용될 수 있다. 예를 들어, \"Would you like a green avocado, or a brown avocado?\"에서, 체화된 에이전트는, 이들을 개별적인 단어들로서 취급하기보다는, 좌측 \"green avocado\" 및 우측 \"brown avocado\"를 포인팅할 수 있다. 비트들은 그룹 내에서 반복될 수 있다. 예를 들어: 예를 들어: \"I am going on holiday tomorrow\"는 'going' 에 대해 원을 그리고 'tomorrow'에 대해 촙(chop)을 트리거할 수 있지만, \"I can see a big yellow fluffy giraffe\"는 'big', 'fluffy' 및 'giraffe'에 대해 반복되는 촙들을 트리거할 수 있다. 대화 동작 분류 대화 동작 분류는, 옵션들을 나열하는 것, 질문하는 것, 설명하는 것, 대안들을 제공하는 것, 기술하는 것, 주 장하는 것, 철회하는 것, 견해를 제공하는 것, 사과하는 것, 인사하는 것, 주제를 변경하는 것, 예측하는 것, 지시하는 것, 설명하는 것, 모욕하는 것, 또는 놀리는 것과 같이 대화 동작들을 분류할 수 있다. 다시 말해서, 대화 분류 동작은 의사소통 발화가 달성하려고 시도하는 것을 분류한다. 대화 동작 분류는, 규칙 기반 방법들 및 기계 학습 기반 방법들을 포함하지만 이에 제한되지 않는 임의의 적합 한 분류 방법을 사용하여 수행될 수 있다. 일 실시예에서, 심층 학습 분류기는 광범위한 대화 동작들에 대해 트레이닝된다. 질문들에 대해, 의사소통 발화의 문법적 분위기가 결정될 수 있거나(질문들은 의심 분위기인 경향이 있음), 이 를 who, what, when, where, how, do, does로 시작하는 것과 같은 '질문' 어구들의 사전에 대해 체크할 수 있 다. 대화 동작 분류기는 또한, 절의 끝에 물음표가 있는지 여부를 입력으로서 수신할 수 있다. 대화 동작 분 류기는, 이러한 대화 동작을, 사용자 자신들에 대해 또는 사용자의 견해를 묻는 것, 명확화를 요청하는 것, 반 복하도록 요청하는 것, 및 수사학적인 질문들과 같은 상이한 종류들의 질문들로 세분할 수 있다. 권고 및 지시 는 종종 명령형 분위기이거나, 또는 \"you should\" 또는 \"you could\"가 선행된다. 대안들 또는 대조적 아이디어들을 제공하기 위해, 이는 'or' 또는 'but'과 같은 접속사에 의해 분리된 2개의 절 들, 또는 접속사에 의해 분리된 2개의 명사구들 또는 구동사들일 수 있다. 예를 들어, \"We could organise a party for him, or we could wait and see if he organises one himself\". 몇몇 옵션들 또는 항목들을 나열하 기 위해, 쉼표들 또는 접속사들로 분리된 일련의 명사구들 또는 구동사들을 찾는다. 예를 들어, \"Are you going on holiday or travelling for work?\"; \"You will need a pair of 3mm needles, 100g of 4ply yarn in the colourway of your choice, and a cable needle\". 다른 예에서, 텍스트가 \"there are many banks in New Zealand: ASB, ANZ, BNZ and Westpac.\"인 경우, 의도는 \"열거\"로 분류될 수 있다. 가설들, 조건부들, 또는 반사실들은 어구들 \"what if\", \"only if\", \"if...then...\" 등으로 표시될 수 있다. 일 실시예에서, 대화 동작 분류는 감정 분석과 조합되어 비언어적 통신에 추가적인 뉘앙스(nuance)들을 추가할 수 있다. 톤 분류 전달되는 콘텐츠의 톤은 분류되어 행동 성능을 조절하는 데 사용될 수 있다. 분류할 톤의 디멘션들의 예들은, 심각한 대 해학적, 신중한 대 자기 주장, 냉담 대 연민, 일상 대 격식, 또는 사실관계 대 열광적인 것을 포함할 수 있다. 다시 말해서, 톤 분류는 의사소통 발화의 방식을 분류하고, 그에 따라 발화가 전달되는 동안 제스처 및 감정적 수행을 조절할 수 있다. 톤 분류는, 규칙 기반 방법들 및 기계 학습 기반 방법들을 포함하지만 이에 제한되지 않는 임의의 적합한 분류 를 사용하여 수행될 수 있다. 일 실시예에서, 톤의 상이한 디멘션들은 상이한 기계 학습 분류기들을 통해 분류 될 수 있다. 다른 예에서, 심층 학습 분류기는 광범위한 톤 디멘션들에 걸쳐 분류할 수 있다. 패턴 분석 패턴 분석기는 명사구들 및 일련의 명사구들, 구동사들 및 일련의 구동사들을 찾는다. 패턴 분석기는 동사구의 나머지 다음에 오는 전치사 및 이어서 명사구를 체크함으로써 타동사들을 식별할 수 있다. 예를 들어, \"veryquickly running away from the wolf\"는 구동사로서 분석되는데, 왜냐하면, 품사 태그들이 각각 \"ADVERB, ADVERB, VERB, ADVERB, PREPOSITION, DETERMINER, NOUN\"이기 때문이다(그리고 'DETERMINER, NOUN'은 명사구 임). 패턴 분석기는 분위기, 시제, 동사 형태, 형용사 형태(예컨대, 최상급, 비교급), 사람, 숫자 및 다른 형태학적 특징들을 결정할 수 있다. 이러한 정보는, 예를 들어, 최상급 및 비교급 토큰들에 대한 제스처들의 크기를 증가시킴으로써 애니메이션에 영향을 미치는 데 사용될 수 있다. 절의 \"인칭\"은 액션들이 적절한 \"인칭\"으로 지향되도록 액션들을 애니메이션화함으로써 애니메이션에 영향을 미 칠 수 있다. 예를 들어, 1인칭 절은 더 많은 화자-지향적 액션들을 생성할 수 있고, 2인칭 절은 더 많은 청취 자-지향 액션들을 생성할 수 있으며, 3인칭 절은 비지향 액션들을 생성할 수 있다. 절의 시제는, 예를 들어, 가설들을 표현하는, 더 \"견고한\" 애니메이션들로 과거 시제의 절들을 그리고 \"느슨한\" 애니메이션들로 미래 시제의 절들을 애니메이션화함으로써, 제스처들에 영향을 미칠 수 있다. 위치 분석 높은, 낮은, 좁은(또는 중앙) 및 넓은 각각에 대해 하나씩, 위치 및 방향성 문구들의 사전들이 제공될 수 있다. 이들은 정확한 스트링 매치들 또는 패턴 매치들일 수 있는데, 예를 들어, \"under $NOUNPHRASE\"는 \"he was under the sea\", \"it was under a big round table\" 및 \"she was there under some kind of pretence\"이지만 \"they were under 18\"은 아니다. 콘텍스트 이전 절들 및 심지어 이전 대화 턴들(체화된 에이전트 및 사용자 둘 모두)로부터의 콘텍스트 정보는 분석되 는 특정 절에 대한 더 넓은 콘텍스트를 제공한다. 예를 들어, 체화된 에이전트가 사용자에게 자신을 반복 하도록 요청하고 있으면, 체화된 에이전트는 두번째로 약간 상이하게 발화를 수행할 수 있어서: 키 포인트 들을 더 강조하거나 에 더 중점을 두거나 또는 덜 망설인다. 고유명사 또는 다른 용어가 대화 콘텍스트에 이미 도입되었다면, 이는 후속 멘션들에서 키워드일 가능성이 낮을 수 있다. 현재 발성이 대화의 주제를 변경하고 있다면, 새로운 주제에 대한 강조를 나타내기 위한 더 많은(또는 더 큰 또는 더 강력한) 제스처들이 있을 수 있 다. 마크업 생성기 단계에서, 마크업 생성기는 다양한 종류들의 제스처들에 대한 마크업을 생성하기 위해 분석된 트리 내의 정보를 사용한다. 분석된 트리는 절 분석으로부터의 정보로 주석이 달린 파스 트리를 포함할 수 있다. 이러한 마크업 생성기들 각각은 전체 절 이전 또는 이후, 또는 임의의 개별 단어 이전 또는 이후에 후보 마크업들을 추 가할 수 있다. 많은 제스처들은 단어에 '히트 온(hit on)하고'(또는 '트리거됨'), 이는 제스처의 스트로크 포 인트(극단점)가 그 단어의 강세 음절과 동시에 발생한다는 것을 의미한다. 이는, 강세 음절의 순간에 스트로크 포인트에 도달할 시간을 주기 위해, 제스처가 단어 이전에 시작할 수 있다는 것을 의미한다. 제스처들은 얼굴 표정들, 머리 및 목 제스처들, 팔 및 손 제스처들, 및 전신 움직임을 포함한다. 모든 제스처 들은 포즈 및 액션으로 구성되며, 여기서 포즈는 제스처의 시작 포인트이고 액션은 그 시작 포즈로부터 적용된 모션이다. 각각의 액션에 대해, 시작 포즈는 명시적으로 정의될 수 있거나, 또는 시작 포즈는 현재 포즈가 무 엇이든, 예를 들어 이전 제스처의 종료 포즈일 수 있다. 대화 동작 특정 제스처들 적용될 수 있는 대화 동작 특정 제스처들의 예들은: 어깨를 으쓱거리고 질문과 손바닥을 위로 원호를 그리며 절 의 주동사 또는 키워드를 트리거하는 질문들을 포함한다. 부정들은 머리 흔들기 및 팔들이 엇갈리는 것 또는 손목을 빠르게 플리킹하는 것을 트리거한다. 제안하는 대안들은, 한 손이 일 측에 그리고 이어서 다른 손이 다 른 측에 맵핑(map)되어, 가중 스케일들을 나타낸다. 예를 들어, 3개의 옵션들로서 명사들 또는 동사들을 나열 하는 것은, 일 측에 촙, 이어서 중간에서 둘 모두, 이어서 다른 측에 둘 모두로 제스처하는 양 팔들(또는 낮은 레벨, 이어서 약간 더 높은 레벨, 이어서 여전히 약간 더 높은 레벨을 포인팅하는 것과 같이 경로를 따르는 유 사한 제스처들)에 맵핑된다. 리스트 내의 임의의 4개 초과의 항목들은 손가락들을 카운트 오프하는 것에 맵핑 된다.기호성 제스처들 기호성 제스처들은 특정 의미를 갖는 것들이다. 그 의미는 상징적(제스처는 단어 또는 어구를 나타냄), 예를 들어 인사를 전달하는 웨이브; 전통적(제스처는 글자 그대로 단어 또는 어구의 의미를 표현함), 예를 들어 단어 \"box\"에 대해 정사각형 형상을 추적함; 또는 은유적(제스처는 단어 또는 어구의 의미를 표현하지만 문자 그대로 표현하지는 않음), 예를 들어, \"confined\"라는 단어에 대해 정사각형 형상을 추적하는 것일 수 있다. 이들은 각각의 제스처에 대한 사전 검색으로부터 트리거되며, 이는 하나의 사전에서 상징적인, 전통적인, 그리고 은유 적인 트리거 어구들을 포함한다. 사전의 어구들은 선택적으로, 어구 내의 어느 단어가 히트해야 하는지를 나타 낼 수 있다. 디폴트로, 이는 어구의 제1 단어를 히트할 것이다. 이들 어구들은 또한, 정확한 스트링 매치들보 다는 패턴들에 매칭될 수 있는데, 예를 들어, \"I am SAM\"은 \"I am $PROPERNOUN\" 패턴에 매칭하지만, \"I am hungry\"는 그렇지 않다. 이러한 종류의 제스처는 드물게 적용되어야 하며, 그렇지 않으면, 그들이 발성을 연기 하는 것처럼 보일 수 있으며, 이는 익살맞거나 애교로 보일 수 있다. 기호성 제스처들의 레이트는 개성/스타일 구성에서 정의된다. 일 실시예에서, 기호성 제스처들은 각각의 제스처에 대한 범용 사전에 대해 매칭된다. 비트 비트 제스처들은 의미없게 단어들을 강조한다(예를 들어, 기호성 방식으로 또는 임의의 특정 대화 동작에 연결 되지 않음). 비트들은, 구성 설정들에서 정의된 레이트로, 강조 검출 알고리즘에 의해 고른 바와 같은 절의 단 어들에 대해 트리거된다. 액션은 구성에서 정의된 바와 같은 개성 및 제스처 스타일에 기초하여 선택된다. 액 션들의 종류들은 촙(chop)(위, 아래, 대각선), 원들, 및 아킹(arcing) 액션들을 포함하며, 이들 모두는 매우 다 양한 제스처들을 생성하기 위해 경직된 거들먹거리는 제스처로부터 유동적인 개방형 아킹 제스처로 다양한 베이 스 팔 및 손 포즈들에 적용될 수 있다. 따라서, 비트들은 글로벌 구성 설정들에서 정의된 유형들의, 분석된 트리에 특정된 바와 같은 키워드들에 적용 된다. 각각의 비트 제스처는 포즈 및 액션으로 구성되고, 각각의 포즈는 팔, 손목 및 손 요소들로 구성된다. 실시예 제스처들 실시예 제스처들은 구현되는 덕분에 사람들이 행하는 제스처들이다. 예를 들어, 사람들은 긴 기술 또는 설명을 시작하기 전에 깊게 숨을 들이마시거나 또는 탄식한다. 체화된 에이전트들에서, 긴 문장들 전에 깊은 숨들이 트리거될 수 있다. 다른 예는 한 발에서 다른 발로 무게를 이동시키는 것이며, 이는 사람들이 피곤할 때 발생 한다. 체화된 에이전트들에서, 이는 (일부) 절들 사이에서 그리고 다른 갭들에서 트리거될 수 있다. 무언가를 생각하거나 기억하기 위해 잠시 멈추고 한쪽을 바라보는 것은 확률적으로, 절들 사이에서 그리고 긴 또는 매우 희귀한 단어들 또는 고유 명사들이 처음 사용되기 전에, 마치 단어 또는 이름을 생각하려고 시도하는 것처럼 트 리거될 수 있다. 때때로, 이들은 주름진 이마, 또는 채워진 일시정지 또는 주저함 마커, 이를테면 'um'을 동반 한다. 사람들은 개인의 개성에 의해 특정되는 레이트로, 다른 제스처들 없이 갭들에서 트리거되는, 자신의 옷 을 곧게 펴거나, 자신의 코들을 긁거나, 자신의 머리카락을 자신의 귀 뒤로 넘기는 것과 같은 광범위한 그루밍 제스처들을 행한다. 턴-테이킹 제스처들 사람들이 자신들의 스피치를 일시정지하지만 대화 플로어를 양보할 의도가 없을 때, 그들은 시선을 돌리고 때로 는 바닥 유지 제스처들(이를테면, 손 또는 손가락을 드는 것)을 하거나, 'um' 또는 'ah'로 일시정지를 채운다. 턴-테이킹 거동은 일부 절 경계들에서 그리고 고유 명사들을 포함하는 길거나 희귀한 단어들이 처음 언급될 때 그 단어들 전에 트리거될 수 있다. 사람들이 말하기를 마치면, 플로어를 양보하기 위해, 그들은 (예를 들어) 기대하는 듯이 눈을 직접 마주치고 미소를 지으며, 때로는 'your turn' 유형 제스처(예를 들어, 대화 파트너를 향해 손바닥을 위로 하여 한 손 또는 두 손으로 가리킴)를 행한다. 이러한 제스처들은 그들의 전체 발화(하나 또는 몇몇 절들일 수 있음)의 종료 시에 트리거된다. 대화 파트너(사용자)가 캐릭터를 방해하려고 시도할 때, 그들은 그들이 플로어를 포기하지 않고 있음을 나타내기 위해 플로어-유지 제스처를 수행할 수 있거나, 또는 그 들은 약간 놀라는 것처럼 보일 수 있고, 말하는 것 및 제스처를 중단하여, 플로어를 사용자에게 양보할 수 있다 (그들이 이를 수행할 가능성이 얼마나 되는지는 개성 및 역할에 기초하여 구성가능할 수 있음). 사용자가 말하 고 있을 때, 백채널 제스처들은, 중간 STT 결과들의 신속한 감정 분석에 기초하여, 끄덕임들 및 미소들, 찌푸림 들, 'hmm'들 및 'uh huh'들의 형태로 트리거된다. 포즈들 포즈는 제스처에 대한 시작점이며, 여기서 신체는 제스처를 시작하기 전에 이동한다. 예를 들어, 포즈들은 신 체, 머리, 팔, 손목 및 손가락 요소들을 포함할 수 있다. 이들 각각은 베이스 포즈 및 추가된 일부 제어된 랜 덤 변동을 가질 수 있다. 각각의 요소는 선택된 액션과 호환가능한 기본 포즈들의 세트로부터 선택된다(액션이 제스처의 주요 부분이므로, 이것이 먼저 선택됨). 이러한 호환가능한 포즈들로부터, 포즈는 개성, 스타일 및 역할 구성에 의해 정의된 빈도들로 확률적으로 선택된다. 제어된 랜덤 변동은 소량의 \"변동 포즈\"를 블렌딩함 으로써 획득된다. 이러한 변동 포즈들은 감정 점수들뿐만 아니라 위치 분석기로부터의 정보를 사용하여 선택되 며, 이들에 의해 결정되지 않으면, 랜덤으로 선택된다. 블렌딩되는 변동 포즈의 양은 위치 분석기에 의해 특정 된 범위, 감정 변조, 또는 디폴트 범위(이는 단지 다양성을 추가하기 위한 것이지, 포즈를 특정 방향으로 시각 적으로 끌어당기는 것이 아니기 때문에 더 작은 값들일 가능성이 있음)로부터 선택된다. 음성 변조 선택된 제스처들과 더 양호하게 정렬시키기 위해 음성을 변조하기 위해 태그들이 삽입될 수 있고; 그 결과는 발 화의 코히어런트한 전체 성능이다. 예를 들어, 개별 단어들에 대한 음성의 속도, 피치 및 볼륨은 그러한 단어 들을 강조하도록 수정될 수 있다. 그러한 특징부들은 감정 톤을 변경하기 위한 전체 절에 대해 변조될 수 있다. 예를 들어, 피치를 감소시키면서 속도 및 볼륨을 증가시키는 것은 더 화나게 들리고, 3개 모두를 감소시 키는 것은 더 슬프게 들리는 식이다. 마크업 솔버 마크업 솔버는, 개개의 마크업 생성기들에 의해 결정된 바와 같이 모든 후보 마크업들로 주석이 달린 파스 트리 를 취하고, 스피치 및 애니메이션으로 프로세싱되도록 전송될 그 발화의 코히어런트한 성능을 생성하도록 추가 된 적절한 마크업들을 갖는 오리지널 텍스트를 출력한다. 예를 들어, 일부 제스처들은 (하나의 머리 제스처 및 하나의 신체 제스처와 같이) 함께 수행될 수 있는 반면, 다른 제스처들은 수행될 수 없다. 일부 제스처들은 일련의 다른 제스처들과 함께 수행하는 것만이 의미가 있다 (예를 들어, 발화가 \"한편으로는 A, 그러나 다른 한편으로는 B\"인 경우, 이는, 한쪽을 수행하고 다른 쪽을 수행 하지 않기보다는, 2개의 옵션들을 칭량하기 위한 제스처들의 양측을 수행하는 것을 가장 합리적이 되게 한다). 이러한 마크업 솔버는 이러한 충돌들을 해결하지만, 연결된 제스처들을 유지하여, 발화의 코히어런트한 제스처 수행을 구축한다. 일 실시예에서, 적어도 하나의 마크업 태그를 갖는 단어들의 경우, 마크업 솔버는 각각의 단어에 대해 최대 하 나의 신체 제스처 및 하나의 머리 제스처를 선택한다. 이는 우선순위 기반 접근법을 사용하여 구현될 수 있다. 주어진 단어에 대해 다수의 후보 제스처들이 존재하는 경우, 제스처들은 미리 정의된 우선순위 순서로 선택될 수 있다. 일 실시예에서, 다음의 우선순위 순서가 사용된다: 기존의 수동 태그들의 교체 클라이언트 오버라이드 태그들 심볼들, 그러나 너무 많지는 않음 대화 동작들 열거 비트들 턴-테이킹 실시예 다른 실시예에서, 전체로서 취해진 제스처들이 코히어런트한 수행을 형성함을 보장하기 위해, 전체 절 또는 심 지어 전체 단락이 고려된다. 이는 함께 취해진 일련의 제스처들이 합리적인 또는 자연스러운 패턴으로 시퀀스 를 형성하는 것을 보장할 것이다. 예를 들어, 넓은 아킹 제스처 다음에 하나 이상의 작은 촙 비트들이 뒤따르 는 것은 일반적인 시퀀스이지만, 촙, 이어서 아크, 이어서 다른 촙은 덜 자연스럽고, 공간에서 지그재그로 움직이는 일련의 제스처들(넓음, 좁음, 넓음, 좁음)은, 의사소통(상징적) 이유 때문에 지그재그로 움직이지 않는 한 부자연스럽게 보이는 경향이 있다. 이는 또한 더 긴 또는 더 중요한 제스처들에 재생하기에 충분한 시간이 주 어졌지만 더 짧은 제스처들이 더 빠른 연속으로 트리거될 수 있음을 보장할 것이다. 포즈 및 액션 방식 포즈 및 액션 방식은 포즈 및 액션을 입력 텍스트에 독립적으로 적용한다. 비트 제스처들 또는 임의의 다른 적 합한 유형의 제스처에 독립적인 포즈들 및 액션들이 적용될 수 있다. 포즈 포즈는 사지들의 위치와 같은 제스처의 디멘션들 및/또는 위치이다. 예를 들어, 체화된 에이전트의 팔들의 포 즈(예를 들어, 팔 위치들)는 넓거나/좁거나, 또는 높거나/낮을 수 있다. 넓음/중간/좁음 높음/중간/낮음 도 5는, 체화된 에이전트가 의사소통 발화를 하는 동안 다양한 상이한 포즈들의 체화된 에이전트를 도 시한다. 의사소통 발화의 입력 텍스트 및 마크업은 다음과 같다: [middle_pose][strong_beats] Please place your [low_beats] ticket [low_pose] under the [medium_beats] scanner. 예는 포즈들 및 액션들이 입력 텍스트의 상이한 부분들에 어떻게 적용될 수 있는지를 보여준다. 일단 포즈가 정의되면, 모든 후속 액션들은 정의된 포즈에서 시작한다. 도 5a는 넓은 팔/중간 팔 높이 포즈의 체화된 에이전트를 도시한다. 도 5b 및 도 5c는 낮은 팔 높이 포즈 의 체화된 에이전트를 도시한다. 포즈들은 포즈 속도(특정 포즈가 중립 포즈 또는 이전 포즈로부터 얼마나 빨리 도달되는지)와 연관될 수 있다. 포즈들은 속성 태그들, 예를 들어, 스트링 이름 좌측/우측 또는 둘 모두(포즈가 손 포즈인지 여부를 지칭함) 디멘션 태그들과 연관될 수 있다. 예를 들어, 팔 포즈들은 폭 태그(예를 들어, 그것이 좁은 폭 포즈인지, 중간 폭 포즈인지 또는 넓은 폭 포즈인지) 및/또는 높이 태그(그것이 높은 높이 팔 포즈인지, 중간 높이 팔 포 즈인지, 낮은 높이 팔 포즈인지)와 연관될 수 있다. 일 실시예에서, 체화된 에이전트는 각각의 액션 후에 \"중립\" 포즈로 복귀된다. 다른 실시예에서, 특정 액 션의 종료 포즈는 새로운 액션의 새로운 시작 포즈가 될 수 있다. 액션들 액션들은 얼굴 부분 또는 신체 부분에서 다양한 특징점들의 움직임 궤적들을 지칭한다. 액션들은 임의의 적합 한 3D 재구성 기법들에 기초할 수 있다. 예를 들어, 신체 모션을 나타내는 액션은 신체 부분의 미리 결정된 특 징점들의 세트에 의해 재구성될 수 있다. 액션들은, 유형 세기 빈도 속도를 포함하지만, 그에 제한되지 않는 적합한 파라미터들로 구성될 수 있다. 각각의 액션의 하나의 속성은 각각의 액션이 어느 포즈들 위에 적용될 수 있는지이다(예를 들어, 포즈가 이미 넓고 제스처가 팔들을 벌리고 있는 경우, 모든 조합들이 작동하는 것은 아님). 단어-토큰-매칭 정규 표현 정규 표현은 검색 패턴을 특정하는 일련의 문자들이다. 이러한 패턴들은, 패턴과 매칭하는 텍스트의 인스턴스 들을 찾기 위해 텍스트-검색 알고리즘들에 의해 사용될 수 있다. 컴퓨팅에서 사용되는 현대의 정규 표현들은 'regex'로 지칭되며, 통상적으로 다음의 연산자들을 포함한다(그러나 이에 제한되지는 않음): 정상 텍스트 문자들 및 숫자들: a-z, A-Z, 0-9, CJK 문자들, 공백들 등, 예를 들어, 검색 패턴 \"a\"는 제2 위치에서 텍스트 \"cat\"과 매칭할 것이다. 예를 들어, 검색 패턴 \"cat\"은 위치 4에서 텍스트 \"concatenate\"와 매칭할 것이다. '.': 도트는 와일드카드이다. 이는 임의의 문자와 매칭할 것이다. 예를 들어, 검색 패턴 \"c.t\"는 \"cat\", \"cot\" 및 \"cut\"과 매칭할 것이다. '*': 별표는 선행 문자의 0개 이상과 매칭할 것이다. 예를 들어, 검색 패턴 \"cut*\"은 0개 이상의 't' 문자: \"cube\", \"cute\", \"cutting\"과 매칭할 것이다. '+': 플러스 기호는 하나 이상의 선행 문자와 일치할 것이다. '()': 괄호들은 연산자들의 범위 및 우선순위를 정의한다. 일 실시예에서, 텍스트-매칭 방법은 개별 문자들 대신 절 토큰들에 대해 동작한다. \"토큰\"은 일반적으로, 일부 예외들을 갖는 개별 단어에 대응하며: \"don't\"는 \"do\" 및 \"n't\"를 표현하는 2개의 토큰들로 해석된다. 쉼표와 같은 문법 입자들은 전용 토큰들을 갖는다. 이들 토큰들은 다음을 포함하는(그러 나 이에 제한되지 않음) 속성들로서 그들이 표현하는 텍스트의 언어적 특징들을 캡슐화한다: 품사: 명사, 동사, 형용사, 구두점 등. 이들은 표준 약어로서 특정될 수 있으며: \"adjective\"는 \"ADJ\", \"proper noun\"는 \"PROPN\" 등이다. 세부적인 품사: 비교 부사, 한정사, 고유 단수 명사 등. 기본형: 단어의 기본 형태. 예를 들어, \"looking\"의 기본 형태는 look이다. \"is\"의 기본형은 \"be\"이다. 어간: 단어 어간(현재 어떤 형태로도 사용되지 않음. 미래에 사용될 수 있음). 예를 들어, \"fishing\", \"fished\" 및 \"fisher\"의 어간은 \"fish\"이다. \"argue\", \"argued\", \"argues\", 및 \"arguing\"의 어간은 \"argu\"이 다. 종속성: 구문 종속성, 또는 토큰과 그의 부모 토큰의 관계(토큰들은 트리 구조 내에 존재하고, 각각의 토큰 은 부모 또는 자식들을 가질 수 있음). 통상의 텍스트는 SpaCy와 같은 임의의 적합한 도구를 사용하여 토큰들로 변환될 수 있다. 이러한 토큰 기반 텍스트 매칭은 매칭할 속성을 특정함으로써 사용될 수 있다. 예를 들어: \"$lemma:look over there\"는 \"They looked over there\", \"They are looking over there\", 및 \"They will look over there\"와 매칭할 것이다. \"I am $pos:PROPN\"은 고유 명사들, 예를 들어, 자신들을 소개하는 문자: \"I am Sam\", \"I am Rachel\" 등에 매칭할 것이다. \"was $pos:ADV+ excited\" '+' 기호는 선행 연산자(부사)의 하나 이상에 매칭할 것인데, 예를 들어, \"I was really excited\", \"I was really very excited\" - \"really\" 및 \"very\" 둘 모두는 이러한 문장에서 부사들이다. 별표 연산자는 0 이상에 매칭하기 위해 위해 유사하게 사용될 수 있다: \"was $pos:ADV* excited\"는 추가적으 로 \"I was excited\"에 매칭할 것이다.\"a . or .\" the '.' 기호는 여기서 단일 문자/숫자와 매칭될 통상의 정규 표현들과는 달리 임의의 토큰과 매 칭할 것이다. \"a . or .\"는 대안들이 제시되고 있을 때를 검출하는 데 유용할 수 있다. 이러한 검색 패턴들의 리스트들을 저장하는 사전 파일들이 저장될 수 있다. 일부 텍스트가 검색 패턴들 중 하 나와 매칭하면, 텍스트가 발화될 때 관련 액션 또는 감정이 수행되도록 등록될 수 있다. 구성가능성 제스처들, 포즈들 및 액션들은 구성가능할 수 있다. 일 실시예에서, 제스처들, 포즈들 및 액션들의 가능한 구 성들은 제스처 구성 설정들에서 정의된다. 예를 들어, JSON과 같은 제스처 구성 파일은 모든 제스처들, 포즈들 및 액션들의 이용가능한 파라미터들과 함께 그러한 제스처들, 포즈들 및 액션들을 정의할 수 있다. 구성가능한 파라미터들의 예들은 다음을 포함한다: 포즈 세기(특정 포즈에 대한 가중은 무엇인가) 제스처 세기(제스처가 얼마나 현저하거나 강조되는가) 제스처 빈도(제스처가 사용되는 확률은 얼마인가) 일 실시예에서, 제스처 구성들은 제스처 구성 설정들에서 정의된다. 제스처 구성 설정들은 제스처의 각각의 유 형에 대해 이용가능한 제스처들 및 모션들의 범위들을 결정할 수 있다. 제스처들은 \"완전한\" 제스처들일 수 있 으며, 이는 제스처들이 포즈 및 액션으로 분리되는 것과 대조적으로, 제스처들이 완전한 액션 및 포즈 둘 모두 를 포함함을 의미한다. 각각의 제스처에 대해, 구성 설정은 그 제스처에 대한 움직임들의 범위 및 구성가능한 파라미터들을 포함할 수 있다. 예를 들어, 액션의 속도에 대해 허용가능한 값들은 \"speed_min\"과 \"speed_max\" 값 사이에서 제한될 수 있다. 제스처 속도 값은 speed_min과 speed max 사이에서 랜덤으로 생성되고, \"[speed, 0.98]\"에 대한 입력으 로서 제공될 수 있다. 제스처 빈도는 제스처가 랜덤으로 선택될 확률을 정의한다. 각각의 제스처 또는 제스처들의 카테고리는 빈도와 연관될 수 있다. 예를 들어, 다양한 비트 제스처들은 다음의 빈도들 을 가질 수 있다: \"촙\": 0.4, \"원\": 0.1, \"small_arc\": 0.5, \"wide_arc\": 0. 단어가 제스처를 필요로 하는 단어로서 식별되었을 때, 빈도 레이트들에 기 초하여 적절한 제스처가 선택될 수 있다. 비트 액션 구성 설정들은, 예를 들어, 손바닥들이 아래로 향하는 아크의 움직임에 대해, 이용가능한 팔 포즈들 의 세트를 정의할 수 있고, 손목 포즈 및 손 포즈들이 정의된다(일부 액션들이 일부 포즈들과 호환가능하지 않 기 때문임). 구성 설정은 또한, 4개의 미리 설정된 비트 \"강도들\"에 대한 진폭 범위들, 즉, 매우 강함, 강함, 중간 또는 낮음을 정의한다. 본 명세서에서 기술된 강조 검출 알고리즘은 (존재한다면) 각각의 단어에 대한 비 트의 \"강도\"를 결정하고, 정확한 강도는 주어진 범위 내에서 랜덤으로 선택된다. 런타임 시에, 비트 제스처를 생성할 때, 이용가능한 팔, 손목 및 손 포즈들 각각으로부터 랜덤 선택이 이루어질 수 있다. 비트 포즈 구성 설정들은, 손바닥을 위로, 손바닥을 아래로, 및 손바닥 중앙에와 같이 손목 포즈들에 대한 변동 포즈들을 포함 하여, 손목 포즈들에 대해 정의될 수 있다. 개성 구성 - 글로벌 구성 설정 일 실시예에서, 체화된 에이전트들은 하나 이상의 글로벌 구성 설정들을 사용하여 상이한 개성들을 부여받는다. 모든 제스처들의 표현에 영향을 미치는 글로벌 변수들이 설정될 수 있다. 글로벌 구성 설정들은 가능한 범위들 내의 제스처들의 경향 및 사용을 정의한다. 체화된 에이전트의 개성은 글로벌 구성 설정들을 사용하여 구성될 수 있다. 일 실시예에서, 글로벌 구성 설정 json은, 제스처 속도, 제스처 높이 및 폭(평균), 비트 액션의 유형들, 손 포 즈들, 손목 배향, 흥분성(excitability), 주저함 및 임의의 다른 적합한 파라미터들과 같은 제스처 스타일을 생 성하기 위해 캐릭터 생성자가 수정하기를 원할 수 있는 모든 레버들을 캡슐화한다. 추가의 실시예에서, 글로벌 구성 설정의 파라미터들이 변조될 수 있다. 일 실시예에서, 글로벌 구성 설정은 다음의 글로벌 파라미터들을 정의한다: 속도 글로벌 구성 설정은 액션들의 속도를 결정하는 파라미터들을 정의할 수 있다. 예를 들어, 글로벌 구성 설정은 액션들에 대한 최소 속도 및 최대 속도를 결정할 수 있다. 일 실시예에서, 상이한 유형들의 제스처들에 대해 상이한 속도 파라미터들이 설정될 수 있다. 예를 들어, 기호성 제스처들 및 비트 제스처들은 상이한 속도 파라 미터들로 구성될 수 있다. 기호성 제스처 속도는, 체화된 에이전트가 기호성 제스처들로 얼마나 빨리 이동하는지를 정의한다. 기호성 제 스처들로 이동하기 위한 최소 속도 및 최대 속도가 체화된 에이전트에 대해 정의될 수 있다. 비트 제스처 속도는, 체화된 에이전트가 비트 제스처들로 얼마나 빨리 이동하는지를 정의한다. 비트 제스처들 로 이동하기 위한 최소 속도 및 최대 속도가 체화된 에이전트에 대해 정의될 수 있다. 제스처 유형 상이한 유형들의 비트 제스처들의 레이트들이 정의될 수 있다. 예를 들어:"}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "제스처 주파수 글로벌 구성 설정은 체화된 에이전트에 의한 특정 유형들의 제스처들의 빈도를 정의할 수 있다. 예를 들어, 문 장당 최대 수의 기호성 제스처들이 정의되어, 체화된 에이전트가 너무 많은 기호성 제스처들을 디스플레이하지 않는 것을 보장할 수 있다. 글로벌 구성 설정은 강한 제스처들, 중간 제스처들, 및 낮은 제스처들(이들은 비트 제스처들에서 다양성을 생성 하는 데 사용될 수 있음)의 레이트를 독립적으로 설정할 수 있다. 각각의 강조된 단어 상에 '강한', '중간' 또 는 '낮은'의 가중치가 배치된다. rate_strong, rate_medium, rate_low의 글로벌 구성은 상이한 크기들의 제스 처들이 개성에 대해 얼마나 자주 사용되는지를 정의한다. 이러한 3개의 값들의 합이 전체 제스처 레이트이다. 글로벌 구성 설정은 문장에서 체화된 에이전트가 얼마나 많은 강한 비트, 중간 비트 및 낮은 비트를 발화하는지 를 설정한다. \"강조\" 파라미터는 강조 강도에 기초하여 스피치의 속도를 변경한다. 음의 값은 스피치를 느리게 할 것이다. 예를 들어,"}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "\"머리\": 구성은 문장의 강조 및 감정의 강도에 기초하여 강조된 단어들 상에 고레벨(#) 마크업 태그들을 추가한 다. 이러한 고레벨 태그들은 고레벨 구성 파일에서 정의된다. Sentiment_threshold 변수들은 중립 감정의 범위를 정의할 수 있다. 감정 분석은 -1.0(완전 부정) 내지 +1.0 (완전 긍정)의 값을 리턴할 수 있다. 제스처의 유형 내에서, 글로벌 구성 설정은 특정 하위 유형들의 제스처들 (예를 들어, 서클링 액션들, 초핑 액션들 등)의 빈도, 또는 심지어 개별 제스처들의 빈도를 설정할 수 있다. 포즈 구성/제스처 디멘션들 글로벌 구성 설정은 체화된 에이전트에 대한 제스처 디멘션들의 경향들을 결정할 수 있다. 예를 들어, 비트 제 스처들의 경우, 글로벌 구성 설정은 상이한 포즈들, 예를 들어 팔 위치들의 빈도를 정의할 수 있다. 일 실시예 에서, 글로벌 구성 설정은, 체화된 에이전트의 팔 위치들 중 몇 퍼센트가 낮은, 중간 또는 높은 팔 높이/위치에 있는지를 정의하고, 독립적으로, 체화된 에이전트의 팔 위치들 중 몇 퍼센트가 서로로부터 낮은, 중간 또는 높은 폭에 있는지를 정의한다. 다음에 대한 독립적인 구성들이 있을 수 있다: arm_positions: 비트 제스처들에 대한 상이한 팔 높이들 및 폭들의 레이트들. 높이(낮음, 중간, 높음), 폭 (좁음, 중간, 넓음, 매우 넓음) hand_positions: 비트 제스처들에 사용되는 상이한 손 위치들/형상들의 레이트들 hand_orientation: 손바닥들을 위, 중앙 또는 아래로 하는 제스처에 대한 체화된 에이전트의 경향 손잡이(Handedness)및 대칭 체화된 에이전트들은, 구성 설정에서, 한 손에서의 제스처들의 빈도 및/또는 강도를 다른 손에서의 제스처들의 빈도 및/또는 세기보다 크게 정의함으로써, \"손잡이\"를 갖도록 구성될 수 있다. 한 손으로의 기호성 제스처들에 대한 각각의 손의 레이트가 정의될 수 있으며, 예를 들어,"}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "함께 비-기호성(비트) 제스처 손들 대 하나 또는 다른 손의 레이트가 정의될 수 있어서, 예를 들어,"}
{"patent_id": "10-2023-7020212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "감정 감정 파라미터는, 체화된 에이전트의 애니메이션이 감정에 의해 얼마나 많은 영향을 받는지를 정의할 수 있다. emotional_threshold 파라미터는, 제스처의 크기가 증가되기 전에 감정 점수가 얼마나 높아야 하는지를 정의함 으로써, 감정이 얼마나 쉽게 체화된 에이전트에 영향을 미치는지를 정의한다. pose_speed_multiplier 파라미터 는 감정 임계치가 초과될 때 포즈 속도를 곱한다. action_speed_multiplier는 감정 임계치가 초과될 때 액션 속도를 곱한다. 다른 포즈 및 액션에서, 속도는 곱셈이 아니라 가산적으로 수정될 수 있다. rate_multiplier는 감정에 대한 응답으로 체화된 에이전트의 제스처들의 빈도가 얼마나 증가하는지를 정의할 수 있다. size_level_offset은 감정에 대한 응답으로 다수의 레벨들만큼 제스처들의 크기를 증가시킬 수 있다. height_offset은 제스처들의 높이의 증가를 정의할 수 있고, hands_spread_offset은 제스처들의 폭의 증가를 정 의할 수 있다. 제스처 간격들 gesture_interval 변수는 제스처들 사이의 단어들의 최소 및 최대 수를 정의할 수 있다. first_gesture_offset 변수는 문장의 제1 제스처 이전의 최소 수의 단어들을 미리 정의할 수 있다. 이는, 체화 된 에이전트가 발화하기 전에 제1 제스처가 재생되기 시작하지 않음을 보장한다. 즉, 제스처 오프셋은 체화된 에이전트가 발화한 총 시간보다 작다. 주저함 변수는 주저함 마커들 또는 필러 단어들(이를테면, \"ums\" 및 \"ahs\")을 주입할 수 있다. 글로벌 구성 설정은 체화된 에이전트들이 다양한 입력들에 의해 얼마나 영향을 받는지를 결정하는 파라미터들을 정의할 수 있다. 예를 들어, 감정 변조는, 체화된 에이전트가 문장의 감정으로부터 얼마나 영향을 받는지를 결정하는 변수를 설 정함으로써 달성될 수 있다. 그러나, 문장 감정은 체화된 에이전트의 거동에 영향을 미칠 수 있는 입력의 일 예일 뿐이다. 다른 태양들은 (예를 들어, 에이전트의 가상 환경으로부터의 또는 마이크로폰을 통한 사용자로부터의) 오디오 입력, (예를 들 어, 에이전트의 가상 환경으로부터의 또는 카메라를 통한 사용자로부터의) 시각적 입력, 사용자 인터페이스로부 터의 입력, 또는 임의의 다른 적합한 입력을 포함할 수 있다. 글로벌 구성 설정 내의 파라미터들은 변조 규칙들을 사용하여 설정되는 곱셈기들과 연관될 수 있다. 예를 들어, 액션 속도 곱셈기들은 제스처의 속도를 조절하도록 설정될 수 있고, 레이트 곱셈기들은 제스처들의 빈도 를 조절할 수 있다. 크기 레벨 오프셋은 제스처들의 진폭을 증가시킬 수 있다(제스처들이 \"더 크게\" 또는 \"더 작게 됨)\". 랜덤화 제스처 파라미터들의 범위들 및 제스처들의 빈도들을 정의함으로써, 글로벌 구성 설정 파라미터들은 자율 애니 메이션의 변동 및 랜덤화 정도에 영향을 미친다. 변조 단계에서, 변조는 다음을 포함할 수 있다: (한 개인이, 예를 들어, 스피치에서 동일한 장소에서 \"wave01\"을 사용하고 다른 개인이 \"wave02\"를 사용하도 록) 애니메이션 파일들을 스와핑 아웃하는 것; 상이한 제스처들을 사용하는 것(따라서 강조를 위해 한 개인은 \"촙\"을 사용하고 다른 개인은 \"원\"을 사용 함); 제스처들(S)의 속도 또는 진폭을 증가 또는 감소시키는 것; 제스처의 레이트(체화된 에이전트들이 얼마나 많은 제스처들을 수행하는지)를 수정하는 것. 변조는 제스처의 전체 레이트들 및/또는 특정 유형들의 제스처의 레이트들을 수정할 수 있다. 제스처의 레 이트들은 구성 설정들에서 설정될 수 있고, 얼마나 많은 (다양한 종류들의) 제스처들이 문장들에 적용되는지를 결정한다. 변조 모듈은 절 분석 및/또는 마크업 생성에 의해 수정하고/하거나 수정될 수 있다. 인구학적 변조는 나이, 성별, 인종, 및 문화와 같은 인자들에 걸쳐 체화된 에이전트들의 제스처 스타일의 차이 들을 생성한다. 예를 들어, 더 어린 캐릭터들을 묘사하는 체화된 에이전트들은 더 오래된 캐릭터들보다 표현이 더 풍부하고 덜 지배적일 수 있다. 일부 제스처들은 특정 문화 내에서만 의미가 있거나, 또는 (심지어 이들이 동일한 언어를 발화할 때에도) 상이한 문화들에서 상당히 상이한 의미들을 가질 수 있다. 성격 변조는 외향성, 내향성, 확신, 친화성, 개방성과 같은 개성 속성들과 정렬되도록 제스처들을 변조할 수 있 다. 이들은 구성에서 정의되고 더 세밀한 거동 속성들(예를 들어, 높은 에너지)에 맵핑된다. 세밀한 특성들은 제스처 마크업들에서 낮은 레벨의 차이들(예를 들어, 더 빈번하고, 더 크고, 더 빠른 제스처들)로 맵핑된다. 이러한 차이들은 각각 제스처 레이트, 진폭 및 속도에 대해 상이한 평균 값들을 사용함으로써 구현된다. 개성 변조의 추가의 예들은: 긴장하거나 덜 확신하는 개성들에 대한 더 높은 레이트들의 실시예 제스처들(이들은 약 간의 확률로 절들 사이에 삽입됨 - 이들이 평균적으로 얼마나 많이 행할지를 변경하기 위한 확률을 변경함); 더 표현적인 개성들에 대한 더 넓은 다양한 제스처들(각각의 제스처의 레이트들을 더 낮게 그러나 많은 제스처들에 대해 0 초과로 설정하는 것 대 더 적은 수의 상이한 제스처들에 대해 더 높은 레이트들로 설정함); 더 친숙하고 더 개방된 개성들에 대해 손바닥을 위로 하는 열린 손의 더 우세함, 더 유동적인/부드러운 아킹 제스처들; 더 권위적인 개성들에 대해 경직된 거들먹거리는 제스처들의 더 우세함(예를 들어, 손바닥을 위로 하는 제스처들에 대해 더 높은 레이트를 설정함)을 포함한다.스타일 변조는 특유한 제스처 스타일들을 체화된 에이전트들에 적용할 수 있다. 스타일 변조는 개성 변조보다 더 세밀하며, 체화된 에이전트가 편안한 손바닥을 위로 하는 손 포즈로 제스처하는 경향이 있는지 또는 뻣뻣한 손가락들을 펴고 손바닥을 아래로 하는 손 포즈로 제스처하는 경향이 있는지(또는 많은 다른 옵션들), 및 이들 이 촙 액션들, 선회 액션들, 유동적인 아킹 액션들 등을 사용하는 경향이 있는지, 및 이들이 자신들의 좌측 또 는 우측 손을 사용하는 경향이 있는지 또는 대칭적으로 제스처하는 경향이 있는지와 같은 저레벨 제스처 특성들 을 정의할 수 있다. 이들 모두는 그들의 개성에 의해 광범위하게 정의될 수 있지만, 이들은 개별 캐릭터에 고 유한 스타일을 부여하도록 수정될 수 있다. 이들은 모두 고레벨/개성 구성 설정들에서 정의되며, 여기서, 좌측 /우측/양쪽 손들의 레이트, 및 촙 제스처들 및 선회하는 제스처들 등의 레이트가 설정될 수 있다. 역할 변조는 단일 체화된 에이전트가, 심지어 동일한 발화에 대해서도, 그 때 그들이 있는 역할에 따라 상이한 제스처 거동을 디스플레이할 수 있게 한다. 예를 들어, 사람이 회의 토크에서 아이디어를 제시하고 있다면, 그 들은 캐쥬얼한 대화에 관여할 때, 두 경우들 모두에서 동일한 단어들을 말하고 있더라도, 상이한 제스처들을 사 용할 가능성이 있다. 다른 역할들은 일부 사실들을 설명하거나 또는 약술하는 것, 안내하는 것 또는 충고하는 것, 개인지도 또는 교시하는 것을 포함할 수 있다. 캐릭터가 플레이하고 있는 특정 역할은 캐릭터들의 개성 및 특유한 스타일과 상호작용하여 결과적인 전체 제스처 스타일을 형성한다. 감정 변조는, 특정 제스처들을 트리거하기 위해 그리고 또한, 잠재적으로 임의의 또는 모든 다른 제스처들을 변 조하기 위해, 감정 분석의 결과들을 사용하는 것을 지칭한다. 특정 제스처들은 미소들 및 눈썹 올리기, 즐거운 또는 행복한 감정들을 대해, 특히 즐거운 놀람을 표현하기 위해 엄지손가락을 치켜 올리거나 또는 손뼉을 치는 것 또는 분노 또는 불만을 표현하기 위한 찌푸림들 및 꽉 쥔 주먹들일 수 있다. 절에서 표현된 각성은 또한, 선택된 제스처들을 변조한다. 예를 들어, 높은 각성(이를테면, 흥분 또는 불만을 표현하는 절들)은, 포즈들(제 스처들의 시작점들)이 더 넓고 더 높게 되고, 손가락들이 더 벌려지게 되고, 제스처들이 더 빈번하게 되고, 액 션들이 더 크고 더 빨라지는 것을 의미할 것이다. 이는 2개의 방식들로 달성되는데, 첫째로, 오프셋 값들을 제스처들의 빈도 및 각각의 제스처의 진폭 및 속도에 추가함으로써 달성된다. 오프셋은 높은 각성에 대해 긍정이고, 낮은 각성에 대해 음성이고, 각성이 더 높을수 록 오프셋이 더 높게 그리고 그 반대도 마찬가지이도록 스케일링된다. 둘째로, 팔 및 손 포즈들에 대해, 변동 포즈가 블렌딩된다. 팔들의 경우, 변동 포즈는 (높은 각성에 대한) 가 장 넓고 가장 높은 포즈이며, 이는 각각의 제스처에 대한 기본 포즈를 점점 더 넓고 높게 '당기기' 위해 중간 정도까지 기본 포즈와 블렌딩된다. 손들의 경우, 변동 포즈는 작은-중간 정도로 블렌딩된 최대 확산에서의 손 가락들이고, 이는 손가락들이 어떤 기본 포즈에 있든 간에 손가락들을 약간 더 벌려 당긴다. 이러한 오프셋들 및 변동 포즈들의 정도들은 개성 및 제스처 스타일의 변조의 일부로서 구성가능하다. 예를 들어, 하나의 캐릭 터가 다른 캐릭터보다 더 표현력이 있을 수 있어서, 고도로 감정적인 콘텐츠가 그들의 제스처 거동에 더 큰 영 향을 미칠 것이다. 문장-레벨 감정 구성은 문장의 전체 감정을 취하고 감정의 관련 변경을 적용한다. 각각의 감정(이를테면, 분노, 우려, 혐오, 두려움)은 사전(감정을 트리거하는 단어들을 정의함)에 연결될 수 있다. 각각의 감정에 대 해, 감정의 낮은, 중간 및 높은 값들이 정의될 수 있으며, 이들 각각은 세기 및 지속기간을 갖는다. 검출된 감 정의 세기는 감정 분석에 의해 결정될 수 있다. 지속기간은 감정이 얼마나 오래 지속되는지를 정의할 수 있다. 세기 승수(intensity multiplier)는 기본 감정이 무효화되는 정도를 정의한다. 에이전트는, 결합된 계산 및 그래픽 요소들을 갖는 복수의 모듈들을 포함하는 신경 행동 모델(neurobehavioral model)(생물학적으로 모델링된 \"뇌\" 또는 신경 시스템)을 사용하여 시뮬레이션될 수 있다. 각각의 모듈은 생물 학적 프로세스를 표현하고, 생물학적 프로세스와 관련되고 이를 시뮬레이션하는 계산 요소, 및 생물학적 프로세 스를 시각화하는 그래픽 요소를 포함한다. 따라서, 에이전트는 외부 제어 없이 소정의 거동을 수행하도록 \"자 체-애니메이션화\"될 수 있고, 그에 따라, 숨쉬기, 깜박임, 주위 둘러보기, 하품, 자신의 입술들의 움직임과 같 은 자연스럽게 발생하는 자동 거동을 나타낼 수 있다. 생물학적 기반 자율 애니메이션은 감각 및 운동 시스템 들, 반사들, 지각, 감정 및 조절 시스템들, 주의력, 학습 및 메모리, 보상들, 의사 결정 및 목표들을 포함하지 만 이에 제한되지 않는 신경계의 다수의 태양들을 모델링함으로써 달성될 수 있다. 가상 객체 또는 디지털 엔 티티를 애니메이션화하기 위한 신경행동 모델의 사용은 추가로: Sagar, M., Seymour, M. & Henderson, A. Creating connection with autonomous facial animation에 개시된다. Communications of the ACM, 59, 82-91 및 WO2015016723A1이 또한 본 발명의 양수인에게 양도되고 본 명세서에 참조로 통합된다. 자율 애니메이션 시스템은 신경행동 모델과 신호들을 주고받을 수 있다. 신호들을 전송하는 것은, 체화된 에이 전트의 발화들의 감정 및 콘텐츠가 그들의 내부 감정 상태에 영향을 미칠 수 있게 하며, 이는 결국 그들의 근본 적인 감정 또는 유휴 애니메이션들에 영향을 미칠 수 있다. 신호들을 수신하는 것은, 외부 인자들이 그들의 제 스처들, 이를테면 사용자의 감정 상태에 대한 캐릭터의 지각 또는 시야의 객체들의 식별에 영향을 미치게 하여 서, 이들이 사용자 및 상황에 더 반응적이게 허용한다. 다른 예는 사용자가 주의를 기울이고 있음을 검출하고, 그렇지 않은 경우, 일부 스피치 유창성, 예를 들어, 절들을 중단 및 재시작하는 것을 도입하는 것이다. 변동 포즈들 각각의 특정 조인트에 랜덤 변동을 추가하는 것(이는 부자연스러운 포즈들을 초래할 수 있음) 대신에, 변동 포 즈 시스템은 새로운 포즈 변동 포즈를 생성하기 위해 2개 이상의 코히어런트한 입력 포즈들 사이의 블렌딩을 가 능하게 한다. 입력 포즈들은 코히어런트한 방식으로 블렌딩하기 위해 애니메이터에 의해 의도적으로 생성될 수 있다. 도 6은 팔 변동 포즈들 사이의 블렌딩을 도시한다. 도 6a는 넓은 스탠스의 입력 포즈를 도시하고, 도 6b는 도 6a의 포즈와 블렌딩하도록 구성된 변동 포즈를 도시한다. 도 6c는 도 6a와 도 6b 사이의 중간 포즈인 블렌딩된 포즈를 도시한다. 도 7은 손 변동 포즈들 사이의 블렌딩의 제1 예를 도시한다. 도 7a는 펼친 손의 입력 포즈를 도시하고, 도 7b 는 도 7a의 포즈와 블렌딩되도록 구성된 접힌 손의 변동 포즈를 도시한다. 도 7c는 도 7a와 도 7b 사이의 중간 포즈인 블렌딩된 포즈를 도시한다. 도 8은 손 변동 포즈들 사이의 블렌딩의 제2 예를 도시한다. 도 8a는 말린 손가락들을 갖는 손의 입력 포즈를 도시하고, 도 8b는 도 8a의 포즈와 블렌딩하도록 구성된 변동 포즈를 도시한다. 도 8c는 도 8a와 도 8b 사이의 중간 포즈인 블렌딩된 포즈를 도시한다. 일 실시예에서, TTG 시스템은 다음의 단계들을 사용하여 변동 포즈를 생성한다: 입력 포즈를 선택 또는 수신한다. 일 실시예에서, 입력 포즈는 \"베이스 포즈\"이며, 이는, 체화된 에이전트 의 신체 부분이 구성되는 디폴트 포즈임을 의미한다. 입력 포즈와 블렌딩하도록 구성된 대응하는 변형 포즈를 선택 또는 수신한다. 블렌딩된 포즈를 생성하기 위해 각각의 입력 포즈와 하나 이상의 변동 포즈들 사이를 블렌딩한다. 일 실시예에서, 입력 포즈 및 변동 포즈는 각각 세기로 선택되고, 함께 블렌딩된다(예를 들어, 0.8 포즈 1은 0.9 포즈 2와 블렌딩된다). 다른 실시예에서, 서로 블렌딩하도록 구성된 2개 이상의 변동 포즈들이 선택되고, 포즈들 각각 사이의 블렌딩 가중치들이 랜덤으로 생성되어, 변동 포즈가 블렌딩되는 정보를 특정한다(예를 들어, 0.2 포즈1은 0.4 포즈2 및 0.4 포즈3과 블렌딩된다). 포즈 선택들은 다가올 액션과 호환가능하도록 제한될 수 있다. 각각의 액션에 대해 호환가능한 포즈들의 미리 정의된 세트가 존재할 수 있으며, 이로부터 하나가 선택된다. 자율 감정 스피치 일 실시예에서, 체화된 에이전트들은, 본 명세서에서 설명된 바와 같이 TTG 시스템에 의해 외부적으로 (가중되 거나 제어가능한 방식으로) 또한 제어될 수 있는 자체-구동 거동을 갖는 자율 동적 시스템들로서, 자율성의 블 렌딩(여기서 체화된 에이전트 제스처들은 이들의 내부 감정 상태들에 의해 구동됨) 및 지시성(여기서, 체화된 에이전트 제스처들은 TTG 시스템에 따라 텍스트에 의해 구동됨)을 허용한다. \"바텀-업\" 자율 거동은, 발명의 명칭이 \"System for Neurobehavioural Animation\"인 US10181213B2호에 기술된 것과 같은 프로그래밍 환경에 의 해 용이하게 될 수 있다. 복수의 모듈들은 필요한 구조로 배열되고, 각각의 모듈은 적어도 하나의 변수를 갖고, 적어도 하나의 커넥터와 연관된다. 커넥터들은 구조에 걸친 모듈들 사이의 변수들을 연결하고, 모듈들은 함께 신경행동 모델을 제공한다. 변수들 및/또는 모듈들은, 구조의 동작에 영향을 미치기 위해 사용될 수 있는 도파민 또는 옥시토신과 같은 신경전달물질/신경조절기들을 표현할 수 있다. 신경행동 모델은 특허 출원 PCT/IB2020/056280, ARCHITECTURE, SYSTEM, AND METHOD FOR SIMULATING DYNAMICS BETWEEN EMOTIONAL STATES OR BEHAVIOR FOR A MAMMAL MODEL AND ARTIFICIAL NERVOUS SYSTEM에서 기술된 바와같은 감정 시스템을 포함할 수 있고, 이는 본 명세서에 참조로 통합된다. 감정 콘텐츠를 전달하는 각각의 단어에 대해, TTG 시스템은 가능한 제스처와 하나 이상의 감정 자극들 둘 모두 를 출력할 수 있다. 각각의 감정 자극은 내부 감정 시스템의 상태를 교란시킨다. 내부 감정 시스템은 감정들 이 서로 경쟁하고 지속 및 쇠퇴하여 감정 상태들의 이력을 제공하는 유동적인 동적 시스템이다. 따라서, 체화된 에이전트의 내부 감정 반응은 단어의 콘텐츠 및 순서 또는 시퀀스에 의존한다. 일 실시예에서, TTG 시스템은 각각의 단어를 순차적으로 프로세싱하고, 단어가 프로세싱되자마자 하나 이상의 감정 자극들을 출력할 수 있다. 다른 실시예에서, TTG 시스템은 문장의 임의의 적합한 규칙들 또는 분석에 따 라, 전체 절, 문장 및/또는 단락을 프로세싱하고, 감정 자극들을 출력할 수 있다. 따라서, 자율 감정 스피치는, 감정들이 오래 머무르도록, 체화된 에이전트의 내부 상태에 영향을 미치는 입력 텍스트의 콘텐츠(예를 들어, 키워드들 또는 감정들)에 의해 이력과 계층가능하고 블렌딩가능 방식으로 감정 시 스템을 구동시키고, 적절하게 블렌딩된다. 일 실시예에서, 단어들은 2개 이상의 근본적인 감정들로 분해될 수 있다. 예를 들어, \"marvellous\"이라는 단어 는 \"surprising\" 및 \"happy\" 둘 모두로 해석될 수 있고, \"horrified\"는 \"fear\" + \"disgust\"로 분해될 수 있다. 일 실시예에서, 2개 이상의 \"감정 사전들\"은 각각 특정 감정의 요소들을 표현하는 단어들의 리스트들을 포함한 다. 어떤 컴포넌트 감정들이 단어들 또는 토큰들에 적용되는지를 결정하기 위해 단어들 또는 토큰들이 감정 사 전들에 대해 매칭된다. 일 실시예에서, 감정 사전에서 매칭된 각각의 단어는 또한, 단어가 감정 사전에 관련되는 정도를 표현하는 사전 매칭 변수와 페어링될 수 있다. 예를 들어, \"fear\" 사전은 horrifying 0.9, disaster 0.92, scary 0.8, uncomfortable 0.6과 같이 대응하는 사전 매치 변수들을 갖는 단어들을 포함할 수 있다. 매칭된 감정들뿐만 아 니라 사전 매치 변수들 둘 모두가 감정 시스템에 대한 입력으로서 리턴 및 제공될 수 있다. 이는 구성적이고 블렌딩가능하며 전환적인 방식으로 복잡한 복합 감정들에 응답하는 방식을 제공한다. 강조 검출 강조 검출 알고리즘은 의사소통 발화에서 단어들의 중요도를 결정하여, 체화된 에이전트가 제스처들로 가장 중 요한 단어들을 강조할 수 있게 한다. 강조 검출 알고리즘은 소정의 기준들에 따라 키워드들을 식별할 수 있다. 일 실시예에서, 강조 검출 알고리즘은 각각의 절 내의 어느 단어들에 강함, 중간, 낮음, 또는 강조 없음이 주어 질지를 식별한다. 도 2는 일 실시예에 따른 강조 검출 알고리즘을 도시한다. 단계에서, 입력 텍스트가 수신된다. 단계 에서, 입력 텍스트 내의 각각의 \"토큰\" 또는 단어 w에 대해, 각각의 강조 검출 규칙이 적용된다. 단어 점 수의 계산은 몇몇 규칙들의 적용을 포함할 수 있다. 단계에서, 각각의 강조 검출 규칙에 대해, 관련 토큰 또는 단어에 대한 규칙 점수가 계산된다. 강조 검출 규칙들은, 일부 규칙들이 다른 규칙들보다 단어 점수에 더 큰 영향을 미치도록 가중될 수 있다. 단계에서, 토큰 또는 단어에 대한 전체 강조 점수가 계산된다. 단 계에서, 각각의 규칙에 대한 강조 점수들이 리턴된다. 이어서, 단어들에 대한 강조 점수들은 강조 점수들 에 기초하여 제스처들을 적용하기 위해 사용된다. 일 실시예에서, 강조 검출 알고리즘은 각각의 단어의 희귀도를 검색한다. 단어들 및 (특정 언어 또는 콘텍스트 에서 그 단어의 사용의) 연관된 \"빈도들\"의 검색 테이블은 각각의 단어에 대한 단어 희귀도를 리턴하는 데 사용 될 수 있다. 비교적 더 높은 강조 점수들을 갖는 단어들은 \"비트를 트리거\"할 수 있으며, 이는 어떠한 스피치 콘텐츠도 전달 하지 않지만 비-내러티브 콘텐츠를 전달하고 스피치의 리듬과 정렬되는 제스처의 유형이다. 강조 검출은 규칙 들을 활성화시키기 위해 키워드가 정의된 파라미터들을 인식한다. \"가중치\" 또는 세기는 0 내지 1의 범위일 수 있다. 가중치들은 각각의 규칙에 대해 특정된다. 가중치는 2가지 방식들: 규칙당 \"가중치\" 및 워드당 \"가중치\"로 적용될 수 있다. 규칙의 가중치는 일정하게 유지되는데, 예를 들어, 감정 규칙은 항상 0.8의 값으로 가중된다. 한편, 키워드는 예를 들어, I am very excited(감정 사전에서 0.7로서 나열됨)와 같이 대응하는 사전 내에서 키워드의 진술된 값에 따라 가중될 것이다. 주어진 문장에서 다수의 키워드들이 식별되고 그에 따라 비트 제스처들로 강조될 수 있다. 일 실시예에서, 강 조 검출 알고리즘은 주어진 절에서 키워드들을 식별하고, 가중된 키워드 식별 알고리즘에 기초하여 모든 단어들 높음, 중간, 낮음 또는 강조 없음을 할당한다. 문장의 모든 단어들에 대한 점수들이 계산되고, 이어서 내림차 순으로 정렬된다. 상위 10%는 강한 비트들로서 정의되고, 후속 10%는 중간 비트들로서, 다른 후속 10%는 낮은 비트들로서 정의된다. 비트들을 강함, 중간 및/또는 낮음으로서 분류하기 위해 임의의 적합한 임계치들이 제공 될 수 있다. 비트의 스트로크가 단어의 강세 음절과 동기화되도록, 비트 제스처들은 강세 음절에 적용될 수 있다. 규칙들은 합산하거나 MAX를 찾는 것을 포함하는 임의의 적합한 방식으로 조합될 수 있다. 적합한 규칙 가중들 의 일 예가 도 3에 도시된다. 도 4는 입력 텍스트 \"John loves snorkelling in Greece\"에 대한 규칙들의 적용 의 예를 도시한다. 강조 검출 미세 조정 강조 검출 규칙들에 대한 가중치들은, 예를 들어, 인간 주석이 달린 데이터에 대해 그리디 알고리즘(greedy algorithm) 또는 심층 학습 모델(deep learning model)을 사용하여 미세 조정될 수 있다. 다양한 의미론적 도 메인들을 커버하는 문장들의 집합(바람직하게는 1500 초과)이 트레이닝 데이터세트로서 선택된다. 인간 주석자 들은 각각의 문장에 대한 키워드들(강조 단어들)을 수동으로 선택한다. 총 3540개의 문장들이 트레이닝 데이터 세트로서 사용된다. 일 실시예에서, 복수의 주석자들이 사용되며, 이들의 주석 결정들의 일치성이 측정될 수 있다. 하나의 실험에서, 출원인들은 2명의 인간 주석자들이 강조된 단어들의 71.44%에 동의함을 발견하였다. 단일 주석에 대한 오버피팅(overfitting)을 회피하기 위해 모든 주석자들로부터의 주석들이 동시에 사용될 수 있다. 일 실시예에서, 가중치들은 그리디 알고리즘을 사용하여 미세 조정된다. 트레이닝 데이터에 대한 최대 정확도 를 획득하기 위해 가중치들을 수정하도록 그리디 알고리즘이 사용된다. 모든 가중치들은 랜덤으로 초기화된다. 각각의 반복에서, 랜덤으로 선택된 하나를 제외한 모든 가중치들은 고정된다. 이는 트레이닝 데이터의 정확도 를 최대화하기 위해 [0,1] 내에서 0.01 정밀도로 검색함으로써 조정될 것이다. 알고리즘은 10k 반복들 후에 종 료된다. 다른 실시예에서, 가중치들을 트레이닝하기 위해 심층 신경망이 사용된다. 바이어스 또는 활성화가 없는 1-계 층의 완전히 연결된 피드포워드 네트워크가 가중치들을 찾기 위해 케라즈(Keras)로부터 사용된다. 장점들 TTG 시스템은 체화된 에이전트의 제스처 스타일을 변경함으로써 상이한 개성들의 인상들을 생성한다. TTG 시스 템은 고도로 구성가능하다. 개성 및 바디 랭귀지를 이해하는 사람, 예를 들어 영화 감독은 이 시스템을 사용하 여, 체화된 에이전트들에서 상이한 현실적인 거동들을 생성할 수 있다. 사람은 사용되는 제스처들의 세트, 예 를 들어 손바닥을 위로 대 손바닥으로 아래를 선택할 수 있다. 그들은 또한 자신들의 제스처의 속도, 레이트들, 크기 및 위치를 조정할 수 있다. 이들은, 제스처들이 문장의 감정에 의해 어떻게 영향을 받는지를 구성함으로써, 에이전트가 얼마나 감정적으로 표현적인지를 특정할 수 있다. 상기 태양들 모두는 에이전트의 인지된 개성에 영향을 미친다. 액션 및 포즈 방식은 더 적은 계산 저장 공간을 요구하는 방식으로 매우 다양한 제스처들을 효율적으로 생성하 는 데 사용된다. 액션 및 포즈 방식은 또한 애니메이터에 의해 모든 변동들이 수동으로 제작될 필요 없이 액션 및 포즈 방식을 사용하여 많은 세트의 애니메이션들이 자동으로 생성될 수 있기 때문에 애니메이터 시간을 절약 한다. 시스템은, 다음을 포함하여, 대화들에서 가장 일반적으로 사용되는 제스처 유형들을 식별한다: 기호성 제스처들(전통적, 은유적, 상징적) - 스트링-매칭 및 사전들에 기초하여 식별된다. 예를 들어, \"square\"라는 단어에 대한 정사각형을 추적하는 것; \"higher\"에 대해 업 제스처를 사용하는 것. 대화 동작 제스처들 - 언어학에 기초한 규칙들에 의해 식별된다. 예를 들어, 질문에 대해 어깨를 작게 으쓱 하고 열린 손바닥을 아크형으로 위로 향하는 것; 부정에 대해 머리를 흔들고 손목을 빠르게 플리킹하는 것; \"you can have this or that\"에서 \"this or that\" 시에 좌측 그리고 이어서 우측을 가리키는 것. 강조하는 제스처들 - 키워드 검출을 사용하여 식별됨. 예를 들어, \"this is really bad\"에서 \"really\"에 비트 제스처를 적용하는 것. 실시예 제스처들 - 예를 들어, 용어 \"constructivist epistemology\"를 검색하는 것처럼 위의 한쪽을 보고 눈썹을 찌푸리고 이어서 뒤를 보는 것; 절들 사이에서 한 발에서 다른 발로 무게를 이동시키는 것. 턴-테이킹 제스처들 - 예를 들어, 완료되지 않을 때 절들 사이에서 눈길을 돌리고(대화 플로어를 유지함), 사용자를 직접 보고, 완료될 때 미소를 짓는 것(대화 플로어를 양보함). TTG 시스템은, TTG 시스템이 애니메이션을 알리는 것을 돕는 언어 정보를 입력 텍스트로부터 도출하기 때문에, 더 인간-유사 자율 애니메이션을 초래한다. TTG 시스템은 문장을 표현하는 종속성 트리 내의 단어들 사이의 관 계들에 기초하여 부정들을 검출한다. TTG 시스템은 단어들의 품사에서 명사구들, 동사구들, 및 다른 패턴들을 발견함으로써 열거 거동들을 검출한다. 변동 포즈는 제스처들에 자연스럽게 보이는 랜덤성을 도입한다. 해석 기술된 방법들 및 시스템들은 임의의 적합한 전자 컴퓨팅 시스템 상에서 활용될 수 있다. 후술되는 실시예들에 따르면, 전자 컴퓨팅 시스템은 다양한 모듈들 및 엔진들을 사용하여 본 발명의 방법을 활용한다. 전자 컴퓨팅 시스템은, 적어도 하나의 프로세서, 하나 이상의 메모리 디바이스들에의 접속을 위한 하나 이상의 메모리 디바 이스들 또는 인터페이스, 시스템이 하나 이상의 사용자들 또는 외부 시스템들로부터의 명령어들을 수신하고 그 에 따라 동작할 수 있게 하기 위한 외부 디바이스들에의 접속을 위한 입력 및 출력 인터페이스들, 다양한 컴포 넌트들 사이의 내부 및 외부 통신을 위한 데이터 버스, 및 적합한 전력 공급원을 포함할 수 있다. 또한, 전자 컴퓨팅 시스템은 외부 및 내부 디바이스들과 통신하기 위한 하나 이상의 통신 디바이스들(유선 또는 무선), 및 디스플레이, 포인팅 디바이스, 키보드 또는 프린팅 디바이스와 같은 하나 이상의 입력/출력 디바이스들을 포함 할 수 있다. 프로세서는 메모리 디바이스 내의 프로그램 명령어들로서 저장된 프로그램의 단계들을 수행하도록 배열된다. 프로그램 명령어들은 본 명세서에 기술된 바와 같은 본 발명을 수행하는 다양한 방법들이 수행될 수 있게 한다. 프로그램 명령어들은, 예를 들어 C 기반 언어 및 컴파일러와 같은 임의의 적합한 소프트웨어 프로 그래밍 언어 및 툴키트를 사용하여 개발되거나 구현될 수 있다. 또한, 프로그램 명령어들은, 예를 들어 컴퓨터 판독가능 매체 상에 저장되는 것과 같이, 그들이 메모리 디바이스로 전달되거나 프로세서에 의해 판독될 수 있 도록 하는 임의의 적합한 방식으로 저장될 수 있다. 컴퓨터 판독가능 매체는, 예를 들어 솔리드 스테이트 메모 리, 자기 테이프, 콤팩트 디스크(CD-ROM 또는 CD-R/W), 메모리 카드, 플래시 메모리, 광 디스크, 자기 디스크 또는 임의의 다른 적합한 컴퓨터 판독가능 매체와 같은, 프로그램 명령어들을 유형적으로 저장하기 위한 임의의 적합한 매체일 수 있다. 전자 컴퓨팅 시스템은 관련 있는 데이터를 취출하기 위해 데이터 저장 시스템들 또는 디바이스들(예를 들어, 외부 데이터 저장 시스템들 또는 디바이스들)과 통신하도록 배열된다. 본 명세서에 기 술된 시스템은 본 명세서에 기술된 바와 같은 다양한 기능들 및 방법들을 수행하도록 배열되는 하나 이상의 요 소들을 포함한다는 것이 이해될 것이다. 본 명세서에 기술된 실시예들은, 시스템의 요소들을 구성하는 다양한 모듈들 및/또는 엔진들이 기능들이 구현될 수 있게 하기 위해 어떻게 상호접속될 수 있는지의 예들을 독자에게 제공하는 것을 목표로 한다. 또한, 본 설명의 실시예들은, 시스템 관련 상세에서, 본 명세서에 기술된 방법의 단계들이 어떻게 수행될 수 있는지를 설명한다. 개념도들은 다양한 데이터 요소들이 다양한 상이한 모듈들 및/ 또는 엔진들에 의해 상이한 단계들에서 어떻게 프로세싱되는지를 독자에게 나타내기 위해 제공된다. 따라서, 모듈들 또는 엔진들의 배열 및 구성은 시스템 및 사용자 요건들에 따라 적응되어, 다양한 기능들이 본 명세서에 기술된 것들과는 상이한 모듈들 또는 엔진들에 의해 수행될 수 있도록 할 수 있는 것, 및 소정 모듈들 또는 엔 진들이 단일 모듈들 또는 엔진들로 조합될 수 있는 것이 이해될 것이다. 기술된 모듈들 및/또는 엔진들은 임의 의 적합한 형태의 기술을 사용하여 구현되고 명령어들을 제공받을 수 있다는 것이 이해될 것이다. 예를 들어, 모듈들 또는 엔진들은 임의의 적합한 언어로 기록된 임의의 적합한 소프트웨어 코드를 사용하여 구현되거나 생 성될 수 있으며, 여기서 코드는 이어서 임의의 적합한 컴퓨팅 시스템 상에서 구동될 수 있는 실행가능한 프로그 램을 생성하도록 컴파일된다. 대안적으로, 또는 실행가능한 프로그램과 함께, 모듈들 또는 엔진들은 하드웨어, 펌웨어 및 소프트웨어의 임의의 적합한 혼합물을 사용하여 구현될 수 있다. 예를 들어, 모듈들의 부분들은 ASIC(application specific integrated circuit), SoC(system-on-a-chip), FPGA(field programmable gate array) 또는 임의의 다른 적합한 적응가능 또는 프로그래밍가능 프로세싱 디바이스를 사용하여 구현될 수 있다. 본 명세서에 기술된 방법들은 기술된 단계들을 수행하도록 특별히 프로그래밍된 범용 컴퓨팅 시스템을 사용하여 구현될 수 있다. 대안적으로, 본 명세서에 기술된 방법들은 데이터 분류 및 시각화 컴퓨터, 데이터베이스 질의 컴퓨터, 그래픽 분석 컴퓨터, 데이터 분석 컴퓨터, 제조 데이터 분석 컴퓨터, 비즈니스 지능 컴퓨터, 인공지능컴퓨터 시스템 등과 같은 특정 전자 컴퓨터 시스템을 사용하여 구현될 수 있으며, 여기서 컴퓨터는 특정 분야와 연관된 환경으로부터 캡처된 특정 데이터에 대해 기술된 단계들을 수행하도록 특별히 적응되었다."}
{"patent_id": "10-2023-7020212", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 TTG 알고리즘을 도시한다. 도 2는 일 실시예에 따른 강조 검출 알고리즘을 도시한다. 도 3은 강조 검출을 위한 적합한 규칙 가중들의 예를 도시한다. 도 4는 강조 검출을 위한 채점 프로세스의 예를 도시한다. 도 5는 다양한 상이한 포즈들의 체화된 에이전트를 도시한다. 도 6은 팔 변동 포즈들 사이의 블렌딩을 도시한다. 도 7은 손 변동 포즈들 사이의 블렌딩의 제1 예를 도시한다. 도 8은 손 변동 포즈들 사이의 블렌딩의 제2 예를 도시한다."}
