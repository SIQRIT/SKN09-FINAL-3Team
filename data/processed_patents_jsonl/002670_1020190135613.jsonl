{"patent_id": "10-2019-0135613", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0050966", "출원번호": "10-2019-0135613", "발명의 명칭": "적층형 뉴로모픽 장치 및 뉴로모픽 컴퓨팅 장치", "출원인": "삼성전자주식회사", "발명자": "장재훈"}}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "외부의 호스트와 통신하는 로직 다이; 상기 로직 다이 상에 적층되는 복수의 코어 다이들; 및상기 코어 다이들을 관통하는 복수의 관통 실리콘 비아(through silicon via)들을 포함하고,상기 코어 다이들 중 하나 이상은 뉴로모픽 코어 다이들이고,상기 뉴로모픽 코어 다이들 각각은 복수의 로우 라인들 및 복수의 칼럼 라인들에 연결되며, 신경망(neuralnetwork) 시스템을 구성하는 복수의 레이어들에 포함되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에기초하여 연산을 수행하는 복수의 시냅스들을 포함하는 시냅스 어레이를 포함하고,상기 로직 다이는 상기 관통 실리콘 비아들을 통하여 상기 뉴로모픽 코어 다이들에 상기 가중치들을 제공하고,상기 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 제어 회로를 포함하는 적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 복수의 시냅스들은 상기 가중치들과 상기 입력 데이터에 대한 곱셈 연산과 상기 곱셈 연산의 결과를 누적하는 누적 연산을 수행하고,상기 뉴로모픽 코어 다이들 각각은 상기 시냅스 어레이에 연결되어, 상기 누적 연산의 결과를 상기 관통 실리콘비아들을 통하여 상기 제어 회로에 제공하는 데이터 처리기를 포함하고,상기 제어 회로는 상기 외부 호스트와 통신하는 입출력 인터페이스; 및상기 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 레이어 컨트롤러를 포함하는 적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 복수의 시냅스들은 상기 가중치들과 상기 입력 데이터에 대한 곱셈 연산을 수행하고, 상기 뉴로모픽 코어 다이들 각각은 상기 시냅스 어레이에 연결되어, 상기 곱셈 연산의 결과를 상기 관통 실리콘 비아들을 통하여 상기 제어 회로에 제공하는 데이터 처리기를 포함하고,상기 제어 회로는 상기 곱셈 연산의 결과를 누적하는 누적기;상기 외부 호스트와 통신하는 입출력 인터페이스; 및상기 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 레이어 컨트롤러를 포함하는 적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 시냅스들 각각은 저항성 소자를 포함하고, 상기 시냅스들은 입력 데이터 및 상기 가중치들에 기초하여 상기 신경망 시스템에 의해 수행되는 곱셈 및 누적 연산의 결과를 나타내는 복수의 독출 전류들을 발생하고,상기 뉴로모픽 코어 다이들 각각은공개특허 10-2021-0050966-3-상기 복수의 독출 전류들을 복수의 신호 전압들로 변환하는 복수의 전류-전압 컨버터들;상기 복수의 신호 전압들을 복수의 디지털 신호들로 변환하는 복수의 아날로그-디지털 컨버터들;상기 복수의 디지털 신호들을 합산하는 복수의 가산기들; 및상기 복수의 가산기들의 출력에 기초하여 최종 출력 데이터를 발생하는 복수의 쉬프트 레지스터들을 포함하는적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 시냅스 어레이는 상기 로우 라인들을 통하여 상기 시냅스들에 연결되는 제1 뉴런들; 및상기 칼럼 라인들을 통하여 상기 시냅스들에 연결되는 제2 뉴런들을 더 포함하고,상기 시냅스들 각각은저항값이 가변되는 멤리스터; 및상기 멤리스터에 연결되고, 적어도 두 개의 입력 신호들의 인가되는 트랜지스터를 포함하고,상기 멤리스터의 저항값은 상기 트랜지스터에 인가되는 상기 적어도 두 개의 입력 신호들의 시간 차이에 기초하여 가변되고, 상기 멤리스터의 저항값은 상기 적어도 두 개의 입력 신호들의 시간 차이로 인한 전압의 변화에 기초하여 가변되고,상기 멤리스터의 저항값은 상기 트랜지스터의 게이트 단자에 인가되는 제1 입력 신호와 상기 트랜지스터의 소스단자에 인가되는 멤브레인 전압(membrane voltage)에 기초하여 제2 입력 신호 사이의 시간 차이로 인한 전압에변화에 의존하여 가변되고,상기 멤리스터에 흐르는 전류의 방향과 전류의 양은 상기 제1 입력 신호와 상기 2 입력 신호가 입력되는 시간차이로 인한 전압 차이에 의존하고,상기 제2 뉴런들 각각은 휴지 전압을 기준으로 발화(firing)하는 스파이크(spike)를 생성하는 적층형 뉴로모픽장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 시냅스 어레이는 상기 로우 라인들을 통하여 상기 시냅스들에 연결되는 제1 뉴런들; 및상기 칼럼 라인들을 통하여 상기 시냅스들에 연결되는 제2 뉴런들을 더 포함하고,상기 시냅스들 각각은 직렬로 연결된 스위칭 소자 및 멤리스터를 포함하고,상기 제2 뉴런들 각각은 직렬로 연결된 누산기, 가변 저항 소자 및 비교기를 포함하고,상기 제2 뉴런들 각각은상기 비교기의 출력 단자와 상기 가변 저항 소자를 전기적으로 연결하는 제1 피드백 라인; 및상기 비교기의 출력 단자와 상기 스위칭 소자를 전기적으로 연결하는 제2 피드백 라인을 더 포함하고,상기 제2 뉴런들 각각은 상기 비교기의 출력 신호의 제1 일부를 상기 제1 피드백 라인을 통하여 상기 가변 저항소자로 제공하고, 상기 비교기의 출력 신호의 제2 일부를 상기 제2 피드백 라인을 통하여 상기 스위칭 소자로제공하는 적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 시냅스 어레이는 상기 로우 라인들을 통하여 상기 시냅스들에 연결되는 제1 뉴런들; 및공개특허 10-2021-0050966-4-상기 칼럼 라인들을 통하여 상기 시냅스들에 연결되는 제2 뉴런들을 더 포함하고,상기 시냅스들 각각은 직렬로 연결된 트랜지스터 및 상변화 소자를 포함하고,상기 트랜지스터는 접지 전압에 연결되는 소스 단자, 상기 로우 라인들 중 하나에 연결되는 게이트 단자를 포함하고, 상기 상변화 소자는 상기 트랜지스터의 소스 단자에 연결되는 제1 단자 및 상기 칼럼 라인들 중 하나에 연결되는 제2 단자를 포함하는 적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 코어 다이들 중 적어도 일부는 상기 뉴로모픽 다이들의 연산 결과들을 저장하는 메모리 코어 다이이고,상기 메모리 코어 다이는 휘발성 메모리 셀들 및 비휘발성 메모리 셀들 중 하나를 포함하는 적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "중앙처리장치(Central Processing Unit: CPU), 그래픽처리장치(Graphics Processing Unit: GPU), 주문형 집적회로(Application Specific Integrated Circuit: ASIC) 및 필드 프로그래머블 게이트 어레이(FieldProgrammable Gate Array: FPGA) 중 적어도 하나를 포함하는 호스트; 및상기 호스트와 통신하는 적어도 하나의 적층형 뉴로모픽 장치를 포함하고,상기 적어도 하나의 적층형 뉴로모픽 장치는 상기 호스트와 통신하는 로직 다이; 및상기 로직 다이 상에 적층되는 복수의 뉴로모픽 코어 다이들; 및상기 뉴로모픽 코어 다이들을 관통하는 복수의 관통 실리콘 비아(through silicon via)들을 포함하고,상기 뉴로모픽 코어 다이들 각각은 복수의 로우 라인들 및 복수의 칼럼 라인들에 연결되며, 신경망(neuralnetwork) 시스템을 구성하는 복수의 레이어들에 포함되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에기초하여 연산을 수행하는 복수의 시냅스들을 포함하는 시냅스 어레이를 포함하고,상기 로직 다이는 상기 관통 실리콘 비아들을 통하여 상기 뉴로모픽 코어 다이들에 상기 가중치들을 제공하고,상기 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 제어 회로를 포함하는 뉴로모픽 컴퓨팅 시스템."}
{"patent_id": "10-2019-0135613", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "외부의 호스트와 통신하는 로직 다이; 및상기 로직 다이 상에 적층되는 복수의 뉴로모픽 코어 다이들; 및상기 뉴로모픽 코어 다이들을 관통하는 복수의 관통 실리콘 비아(through silicon via)들을 포함하고,상기 뉴로모픽 코어 다이들 각각은 복수의 로우 라인들 및 복수의 칼럼 라인들에 연결되며, 신경망(neuralnetwork) 시스템을 구성하는 복수의 레이어들에 포함되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에기초하여 연산을 수행하는 복수의 시냅스들을 포함하는 시냅스 어레이를 포함하고,상기 로직 다이는 상기 관통 실리콘 비아들을 통하여 상기 뉴로모픽 코어 다이들에 상기 가중치들을 제공하고,상기 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 제어 회로를 포함하고,상기 뉴로모픽 코어 다이들 각각은 상기 시냅스 어레이에 연결되어, 상기 연산의 결과를 상기 관통 실리콘 비아들을 통하여 상기 제어 회로에 제공하는 데이터 처리기를 포함하고,상기 제어 회로는 상기 호스트와 통신하는 입출력 인터페이스; 및공개특허 10-2021-0050966-5-상기 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 레이어 컨트롤러를 포함하는 적층형 뉴로모픽 장치."}
{"patent_id": "10-2019-0135613", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "적층형 뉴로모픽 장치는 로직 다이 및 복수의 뉴로모픽 코어 다이들 및 복수의 관통 실리콘 비아들을 포함한다. 상기 로직 다이는 외부의 호스트와 통신한다. 상기 뉴로모픽 코어 다이들은 상기 로직 다이 상에 적층된다. 상기 관통 실리콘 비아들은 상기 뉴로모픽 코어 다이들을 관통한다. 상기 뉴로모픽 코어 다이들 각각은 복수의 로우 라인들 및 복수의 칼럼 라인들에 연결되며, 신경망(neural network) 시스템을 구성하는 복수의 레이어들에 포함 되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에 기초하여 연산을 수행하는 복수의 시냅스들을 포함하 는 시냅스 어레이를 포함한다. 상기 로직 다이는 제어 회로를 포함한다. 상기 제어 회로는 상기 관통 실리콘 비 아들을 통하여 상기 뉴로모픽 코어 다이들에 상기 가중치들을 제공하고, 상기 뉴로모픽 코어 다이들 사이의 데이 터 전송을 제어한다."}
{"patent_id": "10-2019-0135613", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 지능 분야에 관한 것으로, 보다 상세하게는 성능을 높일 수 있는 전자 장치 및 전자 장치의 동 작 방법에 관한 것이다."}
{"patent_id": "10-2019-0135613", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "뇌에는 수천억 개의 신경 세포(즉, 뉴런(neuron))가 존재하며, 서로 복잡한 신경망으로 구성되어 있다. 뉴런은 수천 개의 다른 뉴런과 신호를 주고 받는 시냅스를 통해 학습, 기억 등 지적 능력을 발휘한다. 뉴런은 신경계의 구조적, 기능적 단위이며 정보 전달의 기본 단위이다. 시냅스는 뉴런 사이의 접합부를 가리키며 어느 하나의 뉴 런의 축색 돌기와 다른 뉴런의 수상 돌기가 연결된 부위를 말한다. 다시 말해 한 개의 뉴런은 수천 개의 다른 뉴런과 시냅스로 이루어져 있다. 뉴로모픽 칩은 생체 신경계의 동작을 모방한 반도체 회로로서 불특정한 환경에 스스로 적응할 수 있는 지능화된 시스템을 구현하는데 활용될 수 있다."}
{"patent_id": "10-2019-0135613", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 적층형 구조를 채용하여 성능을 향상시킬 수 있는 적층형 뉴로모픽 장치를 제공하는 것이다. 본 발명의 일 목적은 적층형 구조를 채용하여 성능을 향상시킬 수 있는 뉴로모픽 컴퓨팅 시스템을 제공하는 것 이다."}
{"patent_id": "10-2019-0135613", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예들에 따른 적층형 뉴로모픽 장치는 로직 다이 및 복수의 뉴로모픽 코어 다이들 및 복수의 관통 실리콘 비아들을 포함한다. 상기 로직 다이는 외부의 호스트와 통신한다. 상기 뉴로모픽 코어 다이들은 상기 로 직 다이 상에 적층된다. 상기 관통 실리콘 비아들은 상기 뉴로모픽 코어 다이들을 관통한다. 상기 뉴로모픽 코 어 다이들 각각은 복수의 로우 라인들 및 복수의 칼럼 라인들에 연결되며, 신경망(neural network) 시스템을 구 성하는 복수의 레이어들에 포함되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에 기초하여 연산을 수행 하는 복수의 시냅스들을 포함하는 시냅스 어레이를 포함한다. 상기 로직 다이는 제어 회로를 포함한다. 상기 제 어 회로는 상기 관통 실리콘 비아들을 통하여 상기 뉴로모픽 코어 다이들에 상기 가중치들을 제공하고, 상기 뉴 로모픽 코어 다이들 사이의 데이터 전송을 제어한다. 본 발명의 실시예들에 따른 적층형 뉴로모픽 컴퓨팅 시스템은 호스트 및 상기 호스트와 통신하는 적층형 뉴로모 픽 장치를 포함한다. 상기 호스트는 중앙처리장치(Central Processing Unit: CPU), 그래픽처리장치(Graphics Processing Unit: GPU), 주문형 집적 회로(Application Specific Integrated Circuit: ASIC) 및 필드 프로그래 머블 게이트 어레이(Field Programmable Gate Array: FPGA) 중 적어도 하나를 포함한다. 상기 적어도 하나의 적층형 뉴로모픽 장치는 로직 다이 및 복수의 뉴로모픽 코어 다이들 및 복수의 관통 실리콘 비아들을 포함한다. 상기 로직 다이는 상기 호스트와 통신한다. 상기 뉴로모픽 코어 다이들은 상기 로직 다이 상에 적층된다. 상기 관통 실리콘 비아들은 상기 뉴로모픽 코어 다이들을 관통한다. 상기 뉴로모픽 코어 다이들 각각은 복수의 로우 라인들 및 복수의 칼럼 라인들에 연결되며, 신경망(neural network) 시스템을 구성하는 복수의 레이어들에 포함 되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에 기초하여 연산을 수행하는 복수의 시냅스들을 포함하 는 시냅스 어레이를 포함한다. 상기 로직 다이는 제어 회로를 포함한다. 상기 제어 회로는 상기 관통 실리콘 비 아들을 통하여 상기 뉴로모픽 코어 다이들에 상기 가중치들을 제공하고, 상기 뉴로모픽 코어 다이들 사이의 데 이터 전송을 제어한다. 본 발명의 실시예들에 따른 적층형 뉴로모픽 장치는 로직 다이 및 복수의 뉴로모픽 코어 다이들 및 복수의 관통 실리콘 비아들을 포함한다. 상기 로직 다이는 외부의 호스트와 통신한다. 상기 뉴로모픽 코어 다이들은 상기 로 직 다이 상에 적층된다. 상기 관통 실리콘 비아들은 상기 뉴로모픽 코어 다이들을 관통한다. 상기 뉴로모픽 코 어 다이들 각각은 복수의 로우 라인들 및 복수의 칼럼 라인들에 연결되며, 신경망(neural network) 시스템을 구 성하는 복수의 레이어들에 포함되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에 기초하여 연산을 수행 하는 복수의 시냅스들을 포함하는 시냅스 어레이를 포함한다. 상기 로직 다이는 제어 회로를 포함한다. 상기 제 어 회로는 상기 관통 실리콘 비아들을 통하여 상기 뉴로모픽 코어 다이들에 상기 가중치들을 제공하고, 상기 뉴 로모픽 코어 다이들 사이의 데이터 전송을 제어한다. 상기 뉴로모픽 코어 다이들 각각은 상기 시냅스 어레이에 연결되어, 상기 연산의 결과를 상기 관통 실리콘 비아들을 통하여 상기 제어 회로에 제공하는 데이터 처리기를 포함한다. 상기 제어 회로는 상기 호스트와 통신하는 입출력 인터페이스 및 상기 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 레이어 컨트롤러를 포함한다."}
{"patent_id": "10-2019-0135613", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 실시예들에 따르면, 적층형 뉴로모픽 장치가 외부의 호스트와 통신하는 로직 다이 및 로직 다이 상에 적층되는 복수의 뉴로모픽 코어 다이들을 포함하고, 뉴로모픽 코어 다이들 각각에서 인공 지능 연산을 수행하여 성능을 높일 수 있다."}
{"patent_id": "10-2019-0135613", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 도면상의 동일 한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 인공 지능 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 룰(rule) 기반 스마트 시스템과 달 리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공 지능 시스템은 사용할수록 인식률이 향상되 고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 룰 기반 스마트 시스템은 점차 딥러닝 기반 인공지 능 시스템으로 대체되고 있다. 인공 지능 기술은 기계학습(예로, 딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 도 1은 본 발명의 실시예들에 따른 적층형 뉴로모픽 장치를 포함하는 전자 장치를 나타내는 블록도이다. 도 1을 참조하면, 본 발명의 실시예들에 따른 전자 장치(뉴로모픽 컴퓨팅 시스템, 10)는 호스트 및 적층형 뉴로모픽 장치를 포함할 수 있다. 적층형 뉴로모픽 장치는 로직 다이 및 로직 다이 상에 적층되며 가중치들을 저장하는 복수의 코어 다 이들(코어 다이들, 300)을 포함할 수 있다. 적층형 뉴로모픽 장치는 코어 다이들을 관통하는 복수의 관통 실리콘 비아(through silicon via)들을 포함할 수 있다. 적층형 뉴로모픽 장치는 호스트로부터 리퀘스트(REQ), 가중치들(WDT) 및 입력 데이터(IDTA)를 수신하고, 가중치들(WDT)을 저장하고, 최종 데이터(DTA)를 호스트에 제공할 수 있다. 뉴로모픽 코어 다이들 (코어 다이들, 300) 각각은 신경망(neural network) 시스템을 구성하는 복수의 레이어들에 포함되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에 기초하여 연산을 수행하는 복수의 시냅스들을 포함하는 시냅스 어레이 를 포함할 수 있다. 로직 다이는 관통 실리콘 비아들을 통하여 상기 뉴로모픽 코어 다이들에 가중치들(WDT)을 제공 하고, 뉴로모픽 코어 다이들 사이의 데이터 전송을 제어하는 제어 회로를 포함할 수 있다. 도 2는 본 발명의 실시예들에 따른 도 1의 전자 장치에서 적층형 뉴로모픽 장치를 나타내는 블록도이다. 도 2를 참조하면, 적층형 뉴로모픽 장치는 로직 다이 및 복수의 코어 다이들(300a~300k, k는 2 이상의 자연수)을 포함할 수 있다. 적층형 뉴로모픽 장치는 로직 다이 및 복수의 코어 다이들(300a~300k)이 각각 적층되어 패키징된 것 일 수 있다. 로직 다이 상에 적층되는 코어 다이들(300a~300k)은 로직 다이 와 전기적으로 연결되며, 이를 위하여 적층형 뉴로모픽 장치는 로직 다이와 코어 다이들 (300a~300k)을 전기적으로 연결하는 도전 수단을 포함할 수 있다. 실시예에 있어서, 상기 도전 수단으로 관통 실리콘 비아(Through silicon via, TSV)가 적용될 수 있다. 실시예에 있어서, 코어 다이들(300a~300k) 중 적어도 일부(200a, 200b)는 메모리 코어 다이(M_DIE)일 수 있다. 코어 다이들(300a~300k) 중 하나 이상(300c~300k)은 뉴로모픽 코어 다이(N_DIE)일 수 잇다. 메모리 코어 다이 (M_DIE)는 뉴로모픽 코어 다이(N_DIE)에서 수행된 연산의 결과를 저장할 수 있다. 메모리 코어 다이(M_DIE)는 휘발성 메모리 셀들 또는 비휘발성 메모리 셀들을 포함할 수 있다. 도 3은 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치의 예를 나타내는 블록도이다. 도 3을 참조하면, 적층형 뉴로모픽 장치(90a)는 다수 개의 레이어들을 포함할 수 있다. 일 예로서, 적층형 뉴로 모픽 장치(90a)는 로직 다이와 로직 다이 상에 적층된 하나 이상의 뉴로모픽 코어 다이들을 포 함할 수 있다. 도 3의 예에서는, 제1 내지 제 4 코어 다이들(300a~300d)이 구비되는 예가 도시되었으나, 상기 코어 다이들의 개수는 다양하게 변경될 수 있다. 실시예에 있어서, 로직 다이는 하나 이상의 뉴로모픽 코어 다이들 상부 또는 사이에 배치될 수도 있다. 로직 다이는 호스트와 통신하고, 호스트로부터 리퀘스트 및 가중치들을 수신할 수 있으며, 수신된 리퀘스트에 기초한 커맨드 및 가중치들을 코어 다이들로 제공할 수 있다. 로직 다이와 코어 다이들 은 서로 다른 공정으로 제작될 수 있다. 로직 다이는 내부 커맨드 생성기 및 제어 회로를 포함할 수 있다. 내부 커맨드 생성기는 호스트로부터 제공되는 리퀘스트(REQ)에 기초하여 커맨드(CMD)를 생성하고, 커맨드(CMD)를 코어 다이별로 서로 독립하게 형성되는 커맨드 TSV(TSV_C)를 통하여 코어 다이들(300a~300d)로 제공될 수 있다. 제어 회로는 코어 다이들(300a~300d)에 가중치들(WDT)를 저장하고, 코어 다이들(300a~300d)에 입력 데이터 (IDTA)를 제공하고, 코어 다이들(300a~300d)로부터 최종 데이터(DTA)를 수신할 수 있다. 코어 다이들(300a~300d) 각각은 커맨드(CMD)를 디코딩하여 시냅스 어레이를 제어하는 내부 제어신호를 출력하는 제어 로직 회로(211a~211d)와 독출된 데이터 및/또는 저장될 데이터(가중치들)에 대한 처리 동작을 수행하는 데 이터 처리기(313a~313d)를 포함할 수 있다. 입력 데이터와 가중치들은 데이터 TSV(TSV_data)를 통하여 코어 다이들(300a~300d) 중 적어도 하나에 제공될 수 있고, 코어 다이들(300a~300d) 중 적어도 하나로부터의 최종 데이터(DTA)는 데이터 TSV(TSV_data)를 통하여 다 른 코어 다이 또는 제어 회로로 제공될 수 있다. 도 4는 본 발명의 실시예들에 따른 도 3의 적층형 뉴로모픽 장치에서 제어 회로를 나타내는 블록도이다. 도 4를 참조하면, 제어 회로(201a)는 중앙처리장치, 액티베이션 함수, 양자화기, 레이어 컨트롤 러, 압축/해제 엔진 및 입출력 인터페이스를 포함할 수 있다. 도 4의 제어 회로(201a)는 도 3의 코어 다이들(300a~300d) 각각에 포함되는 시냅스 어레이가 가중치들 및 입력 데이터에 대한 곱셈 연산 및 곱셈 연산의 결과를 누적하는 누적 연산을 수행하는 경우에 제어 회로의 예에 해당할 수 있다. 중앙처리장치는 제어 회로(201a)의 전반적인 동작을 제어한다. 액티베이션 함수는 시냅스 어레이로부 터 제공되는 누적 연산의 결과에 액티베이션 동작을 적용한다. 양자화기는 가중치들 및 입력 데이터를 양자화하여 양자화된 가중치들 및 양자화된 입력 데이터를 생성하 고, 양자화된 가중치들 및 양자화된 입력 데이터를 코어 다이들(300a~300d)에 제공할 수 있다. 실시예에 있어서, 양자화기는 고정 소수점 타입의 입력 데이터를 더 적은 비트의 고정 소수점 타입의 입력 데이터로 양자화하고, 부동 소수점 타입의 가중치들을 고정 소수점 타입의 가중치들로 양자화할 수 있다. 레이어 컨트롤러는 코어 다이들(300a~300d) 사이에서의 데이터의 전송을 제어할 수 있다. 압축/해제 엔진 은 호스트로부터 제공되는 데이터에 대하여 해제 동작을 수행하고, 호스트로 제공될 데이터에 대 하여 압축 동작을 수행할 수 있다. 입출력 인터페이스는 호스트와 로직 다이 사이의 데이터 입출력과 관련하여 인터페이스 동작을 수행할 수 있다. 실시예에 있어서, 액티베이션 함수와 입출력 인터페이스는 FPGA로 구현될 수 있고, 중앙처리장치 , 양자화기, 레이어 컨트롤러 및 압축/해제 엔진은 ASIC로 구현될 수 있다. 도 5는 본 발명의 실시예들에 따른 도 3의 적층형 뉴로모픽 장치에서 제어 회로를 나타내는 블록도이다. 도 5를 참조하면, 제어 회로(201b)는 중앙처리장치, 액티베이션 함수, 양자화기, 레이어 컨트롤 러, 압축/해제 엔진, 입출력 인터페이스 및 누적기를 포함할 수 있다. 도 5의 제어 회로(201b)는 도 3의 코어 다이들(300a~300d) 각각에 포함되는 시냅스 어레이가 가중치들 및 입력 데이터에 대한 곱셈 연산을 수행하는 경우에 제어 회로의 예에 해당할 수 있다. 도 5의 제어 회로(201b)는 도 4의 제어 회로(201a)와 비교할 때 누적기를 더 포함한다는 점에서 차이가 있 다. 누적기는 코어 다이들(300a~300d)로부터 제공되는 곱셈 연산의 결과들을 누적하는 누적 연산을 수행하고, 누적 연산의 결과를 액티베이션 함수에 제공할 수 있다. 도 6은 본 발명의 실시예들에 따른 도 5의 누적기를 나타내는 회로도이다. 도 6을 참조하면, 누적기는 가산기 및 버퍼를 포함한다. 누적기는 코어 다이들(300a~300 d)로부터 제공되는, 곱셈 결과에 해당하는 곱셈 결과 데이터(MRD)를 누적하여 최종 데이터(DTA)를 제공한다. 가산기는 제1 입력과 제2 입력을 구비하고 제1 입력에서 곱셈 결과 데이터(MRD)를 수신한다. 가산기 는 곱셈 결과 데이터(MRD)와 제2 입력에서 수신되는 버퍼의 출력을 합산하여 가산기의 제2 입력으로 피드백시킨다. 버퍼는 출력 인에이블 신호(OEN)에 응답하여 가산기의 출력을 최종 데이터(DTA)로서 제공하고, 리셋 신호(RST)에 응답하여 리셋된다. 출력 인에이블 신호(OEN) 및 리셋 신호(RST)는 중앙처리장치로부터 제공 될 수 있다. 도 7은 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치에포함되는 뉴로모픽 코어 다이들 중 하나를 나 타내는 블록도이다. 도 7을 참조하면, 뉴로모픽 코어 다이는 시냅스 어레이 및 아날로그-디지털 변환 블록을 포함한 다. 뉴로모픽 코어 다이는 뉴로모픽 컴퓨팅 칩으로 호칭될 수도 이다, 뉴로모픽 코어 다이는 제1 스 위칭 매트릭스, 제2 스위칭 매트릭스, 전류-전압 변환 블록, 가산 블록 및 쉬프트 레지스 터 블록을 더 포함할 수 있다. 시냅스 어레이는 각각 저항성 소자(RE)를 포함하고 매트릭스 형태로 배열되는 복수의 저항성 메모리 셀들 (RMC)을 포함한다. 복수의 저항성 메모리 셀들(RMC)은 시냅스들에 해당할 수 있다. 복수의 저항성 메모리 셀들(RMC) 각각은 복수의 로우(row) 라인들(RW1, RW2, ..., RWN, N은 2 이상의 자연수) 중 하나 및 복수의 컬럼(column) 라인들(CL1, CL2, ..., CLM, M은 2 이상의 자연수) 중 하나와 연결될 수 있다. 시냅스 어레이의 구체적인 구조에 대해서는 도 9a 및 9c 등을 참조하여 후술하도록 한다. 시냅스 어레이는 데이터들(가중치들)을 저장한다. 예를 들어, 복수의 저항성 메모리 셀들(RMC) 각각에 포 함되는 저항성 소자(RE)의 저항 변화를 이용하여, 상기 복수의 데이터들은 복수의 저항성 메모리 셀들(RMC)에 저장될 수 있다. 또한, 시냅스 어레이는 복수의 입력 전압들 및 상기 복수의 데이터들에 기초하여 복수의 신호 전압들(Vsig)에 대응하는 복수의 독출 전류들(Iread)을 발생한다. 예를 들어, 상기 복수의 입력 전압들은 복수의 로우 라인들(RW1, RW2, ..., RWN)을 통해 시냅스 어레이에 입력될 수 있다. 일 실시예에서, 도 8a 및 8b를 참조하여 후술하는 것처럼, 뉴로모픽코어 다이는 인공 신경망(Artificial Neural Network; ANN) 시스템, 컨볼루션 신경망(Convolutional Neural Network; CNN) 시스템, 심층 신경망 (Deep Neural Network; DNN) 시스템, 딥 러닝(deep learning) 시스템 등과 같은 임의의 신경망(neural network) 시스템 및/또는 머신 러닝(machine learning) 시스템을 구동하는데 이용될 수 있다. 예를 들어, 영상 분류(image classify) 서비스, 생체 정보에 기초한 사용자 인증(authentication) 서비스, 운 전 보조 시스템(Advanced Driver Assistance System; ADAS) 서비스, 음성 보조(voice assistant) 서비스, 자동 음성 인식(Automatic Speech Recognition; ASR) 서비스 등과 같은 다양한 서비스 및/또는 어플리케이션이 뉴로 모픽 컴퓨팅 장치에 의해 실행 및 처리될 수 있다. 이 경우, 시냅스 어레이에 저장되는 상기 복수의 데이터들은 신경망 시스템을 구성하는 복수의 레이어들에 포함되는 복수의 가중치들을 나타내며, 복수의 독출 전류들(Iread) 및 복수의 신호 전압들(Vsig)은 상기 신경망 시스템에 의해 수행되는 곱셈 및 누적 연산의 결과 를 나타낼 수 있다. 다시 말하면, 시냅스 어레이는 데이터 저장 및 연산 동작을 한 번에 수행할 수 있으며, 이에 대해서는 도 9b를 참조하여 후술하도록 한다. 제1 스위칭 매트릭스는 시냅스 어레이의 로우 라인들(RW1, RW2, ..., RWN)과 연결될 수 있다. 상세하 게 도시하지는 않았으나, 제1 스위칭 매트릭스는 복수의 로우 라인들(RW1, RW2, ..., RWN) 중 적어도 하나 를 선택하기 위한 로우 선택 신호 및/또는 복수의 로우들(RW1, RW2, ..., RWN) 중 적어도 하나를 구동하기 위한 로우 구동 전압에 기초하여 복수의 로우 라인들(RW1, RW2, ..., RWN)을 구동할 수 있다. 제2 스위칭 매트릭스는 시냅스 어레이의 복수의 컬럼 라인들(CL1, CL2, ..., CLM)과 연결될 수 있다. 상세하게 도시하지는 않았으나, 제2 스위칭 매트릭스는 컬럼 라인들(CL1, CL2, ..., CLM) 중 적어도 하나 를 선택하기 위한 컬럼 선택 신호 및/또는 컬럼 라인들(CL1, CL2, ..., CLM) 중 적어도 하나를 구동하기 위한 컬럼 구동 전압에 기초하여 컬럼 라인들(CL1, CL2, ..., CLM)을 구동할 수 있다.전류-전압 변환 블록은 복수의 전류-전압 컨버터(Current-to-Voltage Converter, IVC)들을 포함할 수 있다. 복수의 전류-전압 컨버터들은 복수의 독출 전류들(Iread)을 복수의 신호 전압들(Vsig)로 변환할 수 있다. 예를 들어, 복수의 전류-전압 컨버터들 각각은 전류 미러(current mirror)를 포함하여 구현될 수 있다. 아날로그-디지털 변환 블록은 복수의 아날로그-디지털 컨버터(Analog-to-Digital Converter, ADC)들(35 2)을 포함한다. 아날로그-디지털 컨버터들은 복수의 신호 전압들(Vsig)을 복수의 디지털 신호들(DS)로 변 환한다. 가산 블록은 복수의 가산기(Adder, ADR)들을 포함할 수 있다. 복수의 가산기들은 복수의 디지털 신호들(DS)을 합산하여 복수의 합산 디지털 신호들(ADS)을 발생할 수 있다. 쉬프트 레지스터 블록은 복수의 쉬프트 레지스터(Shift Register, SR)들을 포함할 수 있다. 복수의 쉬프트 레지스터들은 복수의 가산기들의 출력인 복수의 합산 디지털 신호들(ADS)에 기초하여 최종 출 력 데이터(DAT)를 발생할 수 있다. 최종 출력 데이터(DAT)가 상기 신경망 시스템에 의해 수행되는 곱셈 및 누적 연산의 최종 결과에 대응할 수 있다. 도 7의 실시예에서, 복수의 전류-전압 컨버터들의 개수, 복수의 아날로그-디지털 컨버터들의 개수, 복수의 가산기들의 개수 및 복수의 쉬프트 레지스터들의 개수는 각각 시냅스 어레이의 복수의 컬럼 라인들(CL1, CL2, ..., CLM)의 개수와 실질적으로 동일할 수 있다. 한편, 도시하지는 않았으나, 뉴로모픽 코어 다이는 제1 스위칭 매트릭스, 제2 스위칭 매트릭스, 전류-전압 변환 블록, 아날로그-디지털 변환 블록, 가산 블록 및 쉬프트 레지스터 블록 등 의 동작 타이밍을 제어하기 위한 제어 신호들을 발생하는 타이밍 컨트롤러 또는 제어 로직 회로(도 3의 311a)를 더 포함할 수도 있고, 상기 로우 구동 전압, 상기 컬럼 구동 전압, 기준 전압(Vref) 등을 발생하기 위한 전압 레귤레이터를 더 포함할 수도 있다. 일반적으로, 시냅스 어레이에 포함되는 복수의 저항성 메모리 셀들(RMC)은 온도 및 시간 의존성을 가진다. 예를 들어, 복수의 저항성 메모리 셀들(RMC) 각각에 포함되는 저항성 소자(RE)는 온도가 증가하면 저항이 감소 하고 온도가 감소하면 저항이 증가하는 온도 의존성을 가질 수 있다. 또한, 저항성 소자(RE)는 시간이 지남에 따라 저항이 감소하는 리텐션(retention) 특성을 가지거나, 일부 경우에는 데이터 기입 후 일정 시간이 지나면 저항이 증가하는 드리프트(drift) 특성을 가지는 등의 시간 의존성을 가질 수 있다. 이에 따라, 시냅스 어레이 에서 출력되는 독출 전류(Iread)는 온도 및 시간에 의존하게 되며, 정확한 데이터 저장 및 연산을 위해서 는 이러한 온도 및 시간 의존성에 따른 영향을 감소 또는 제거할 필요가 있다. 본 발명의 실시예들에 따른 뉴로모픽 코어 다이는, 시냅스 어레이에 포함되는 저항성 소자(RE)와 동 일한 저항성 물질을 포함하는 적어도 하나의 저항 메모리 소자를 포함하는 아날로그-디지털 컨버터를 포함 하여 구현된다. 이 경우, 시냅스 어레이에서 출력되는 독출 전류(Iread) 및 이에 대응하는 신호 전압 (Vsig)과 아날로그-디지털 컨버터에서 이용되는 전압이 동일한 온도 및 시간 의존성을 가지게 되며, 이에 따라 아날로그-디지털 변환 시에 온도 및 시간에 의존하지 않고 일정한 디지털 신호(DS)를 발생할 수 있다. 따 라서, 아날로그-디지털 변환 및 데이터 연산을 오차 없이 효과적으로 수행할 수 있다. 도 8a 및 8b는 본 발명의 실시예들에 따른 뉴로모픽 코어 다이에 의해 구동되는 신경망 시스템의 일 예를 설명 하기 위한 도면들이다. 도 8a를 참조하면, 일반적인 신경망의 네트워크 구조는 입력 레이어(IL), 복수의 히든 레이어들(HL1, HL2, ..., HLn) 및 출력 레이어(OL)를 포함할 수 있다. 입력 레이어(IL)는 i(i는 자연수)개의 입력 노드들(x1, x2, ..., xi)을 포함할 수 있고, 길이가 i인 벡터 입력 데이터(IDAT)가 각 입력 노드에 입력될 수 있다. 복수의 히든 레이어들(HL1, HL2, ..., HLn)은 n(n은 자연수)개의 히든 레이어들을 포함하며, 히든 노드들(h1 1, h1 2, h1 3, ..., h1 m, h2 1, h2 2, h2 3, ..., h2 m, hn 1, hn 2, hn 3, ..., hn m)을 포함할 수 있다. 예를 들어, 히든 레이어 (HL1)는 m(m은 자연수)개의 히든 노드들(h1 1, h1 2, h1 3, ..., h1 m)을 포함할 수 있고, 히든 레이어(HL2)는 m개의히든 노드들(h2 1, h2 2, h2 3, ..., h2 m)을 포함할 수 있으며, 히든 레이어(HLn)는 m개의 히든 노드들(hn 1, hn 2, hn 3, ..., hn m)을 포함할 수 있다. 출력 레이어(OL)는 분류할 클래스에 대응하는 j(j는 자연수)개의 출력 노드들(y1, y2, ..., yj)을 포함할 수 있 고, 입력 데이터(IDAT)에 대하여 각 클래스 별로 결과(예를 들어, 점수 또는 class score)를 출력 데이터(ODA T)로서 출력할 수 있다. 출력 레이어(OL)는 fully connected 레이어라고 부를 수 있으며, 예를 들어 입력 데이 터(IDAT)가 자동차에 대응할 확률을 수치로 나타낼 수 있다. 도 8a에 도시된 네트워크 구조는, 두 개의 노드들 사이에 직선으로 도시된 노드들 간의 연결(branch)과, 도시되 지는 않았지만 각 연결에서 사용되는 가중치(weight)를 포함할 수 있다. 이 때, 하나의 레이어 내의 노드들 간 에는 연결이 되지 않을 수 있고, 서로 다른 레이어들에 포함되는 노드들은 완전하게 혹은 부분적으로 연결될 수 있다. 도 8a의 각 노드(예를 들어, h1 1)는 이전 노드(예를 들어, x1)의 출력을 입력 받아 연산할 수 있고, 연산 결과를 이후 노드(예를 들어, h2 1)에 출력할 수 있다. 이 때, 각 노드는 입력된 값을 특정 함수, 예를 들어 비선형 함수 에 적용하여 출력할 값을 연산할 수 있다. 일반적으로 신경망의 네트워크 구조는 미리 결정되어 있으며, 노드들 간의 연결에 따른 가중치들은 이미 어떤 클래스에 속할지 정답이 알려진 데이터를 이용하여 적절한 값을 산정하게 된다. 이와 같이 이미 정답이 알려진 데이터들을 '학습 데이터'라고 하고, 가중치를 결정하는 과정을 '학습'이라고 한다. 또한, 독립적으로 학습이 가능한 구조와 가중치의 묶음을 '모델'이라고 가정하고, 가중치가 결정된 모델이 입력 데이터가 어느 클래스에 속할지를 예측하여 그 예측값을 출력하는 것을 '테스트' 과정이라고 한다. 도 8b를 참조하면, 도 8a의 네트워크 구조에 포함되는 하나의 노드(ND)에서 수행되는 연산의 일 예를 구체적으 로 나타내고 있다. 하나의 노드(ND)에 N개의 입력들(a1, a2, a3, ..., aN)이 제공되는 경우에, 노드(ND)는 N개의 입력들(a1, a2, a3, ..., aN) 및 이에 대응하는 N개의 가중치들(w1, w2, w3, ..., wN)을 각각 곱하여 합산하고, 상기 합산된 입력 값 에 오프셋(b)을 더하며, 상기 오프셋이 반영된 입력 값을 특정 함수(σ)에 적용하여 하나의 출력 값(예를 들어, z)을 발생할 수 있다. 도 8a에 도시된 네트워크 구조에 포함되는 하나의 레이어가 도 8b에 도시된 노드(ND)를 M개 포함되는 경우에, 상기 하나의 레이어의 출력 값들은 하기의 [수학식 1]과 같이 획득될 수 있다. [수학식 1] W*A=Z 상기의 [수학식 1]에서, W는 상기 하나의 레이어에 포함된 모든 연결들에 대한 가중치를 나타내며, M*N 매트릭 스 형태로 구현될 수 있다. A는 상기 하나의 레이어에서 수신되는 N개의 입력들(a1, a2, a3, ..., aN)을 나타내 며, N*1 매트릭스 형태로 구현될 수 있다. Z는 상기 하나의 레이어에서 출력되는 M개의 출력들(z1, z2, z3, ..., zM)을 나타내며, M*1 매트릭스 형태로 구현될 수 있다. 도 9a 및 9b는 본 발명의 실시예들에 따른 도 7의 뉴로모픽 코어 다이에서 시냅스 어레이의 예들을 나타내는 도 면들이다. 도 9a를 참조하면, 시냅스 어레이(310a)는 복수의 워드 라인들(WL1, WL2, ..., WLN), 복수의 비트 라인들(BL1, BL2, ..., BLM) 및 복수의 저항성 메모리 셀들(RMC)을 포함한다. 도 9a의 복수의 워드 라인들(WL1, WL2, ..., WLN)은 도 7의 복수의 로우 라인들(RW1, RW2, ..., RWN)에 대응하 고, 도 9a의 복수의 비트 라인들(BL1, BL2, ..., BLM)은 도 7의 복수의 컬럼 라인들(CL1, CL2, ..., CLM)에 대 응하며, 도 9a의 복수의 저항성 메모리 셀들(RMC)은 도 7의 복수의 저항성 메모리 셀들(RMC)에 대응할 수 있다. 복수의 저항성 메모리 셀들(RMC) 각각은 저항성 소자(RE)를 포함하고, 복수의 워드 라인들(WL1, WL2, ..., WLN) 중 하나 및 복수의 비트 라인들(BL1, BL2, ..., BLM) 중 하나와 연결될 수 있다.저항성 소자(RE)는 복수의 워드 라인들(WL1, WL2, ..., WLN) 또는 복수의 비트 라인들(BL1, BL2, ..., BLM)을 통해 인가되는 기입 전압에 의해 저항 값이 변화하며, 복수의 저항성 메모리 셀들(RMC)은 이러한 저항 변화에 의해 데이터를 저장할 수 있다. 예를 들어, 선택된 워드 라인에 기입 전압이 인가되고 선택된 비트 라인에 접지 전압(예를 들어, 약 0V)이 인가되는 경우에 선택된 저항성 메모리 셀에 데이터 '1'이 기입되며, 선택된 워드 라 인에 상기 접지 전압이 인가되고 선택된 비트 라인에 상기 기입 전압이 인가되는 경우에 선택된 저항성 메모리 셀에 데이터 '0'이 기입될 수 있다. 또한, 선택된 워드 라인에 독출 전압이 인가되고 선택된 비트 라인에 상기 접지 전압이 인가되는 경우에 선택된 저항성 메모리 셀에 기입된 데이터가 독출될 수 있다. 일 실시예에서, 각 저항성 메모리 셀(RMC)은 PRAM(Phase change Random Access Memory) 셀, RRAM(Resistance Random Access Memory) 셀, MRAM(Magnetic Random Access Memory) 셀, FRAM(Ferroelectric Random Access Memory) 셀 등과 같은 임의의 저항성 메모리 셀을 포함하여 구현될 수 있다. 일 실시예에서, 저항성 소자(RE)는 전류량에 따라 결정 상태가 변화하는 상변화 물질(phase-change material)을 포함할 수 있다. 다른 실시예에서, 저항성 소자(RE)는 페로브스카이트(perovskite) 화합물들, 전이 금속 산화물 (transition metal oxide), 자성체 물질(magnetic materials), 강자성(ferromagnetic) 물질들 또는 반강자성 (antiferromagnetic) 물질들을 포함할 수도 있다. 그러나 저항성 소자(RE)에 포함되는 저항성 물질은 상술한 물 질들에 한정되지 않는다. 도 9b를 참조하면, 도 9a의 시냅스 어레이(310a)가 도 8a 및 8b를 참조하여 상술한 연산을 수행하는 일 예를 나 타내고 있다. 각 저항성 메모리 셀(RMC)은 신경망 시스템의 하나의 시냅스(synapse) 또는 연결에 대응하며, 하나의 가중치를 저장할 수 있다. 따라서, 크로스바 어레이(110a)에 저장된 M*N개의 데이터들은, 도 8a 및 8b를 참조하여 상술한 상기 하나의 레이어에 포함되는 M*N 매트릭스 형태로 구현된 가중치 매트릭스, 즉 상기의 [수학식 1]의 W에 대 응할 수 있다. 복수의 워드 라인들(WL1, WL2, ..., WLN)을 통해 인가되는 N개의 입력 전압들(V1, V2, ..., VN)은 상기 하나의 레이어에서 수신되는 N개의 입력들(a1, a2, ..., aN)에 대응하며, N*1 매트릭스 형태로 구현된 입력 매트릭스, 즉 상기의 [수학식 1]의 A에 대응할 수 있다. 복수의 비트 라인들(BL1, BL2, ..., BLM)을 통해 출력되는 M개의 독출 전류들(I1, I2, ..., IM)은 상기 하나의 레이어에서 출력되는 M개의 출력들(z1, z2, ..., zM)에 대응하며, M*1 매트릭스 형태로 구현된 출력 매트릭스, 즉 상기의 [수학식 1]의 Z에 대응할 수 있다. 다시 말하면, 행렬의 형태를 가지는 복수의 가중치들을 복수의 저항성 메모리 셀들(RMC)에 저장하여 시냅스 어 레이(310a)를 구현한 상태에서, 복수의 워드 라인들(WL1, WL2, ..., WLN)을 통해 복수의 입력 값들에 대응하는 입력 전압들(V1, V2, ..., VN)을 입력하면, 복수의 비트 라인들(BL1, BL2, ..., BLM)을 통해 출력되는 독출 전 류들(I1, I2, ..., IM)은 신경망 시스템에서 수행하는 곱셈 및 누적 연산의 결과가 될 수 있다. 이러한 방식으 로 신경망 시스템의 복수의 레이어들을 모두 구현하면, 데이터 저장 및 연산 동작을 한 번에 수행하는 뉴로모픽 컴퓨팅 칩을 구현할 수 있다. 한편, 도 3a 및 도 3b를 참조하여 시냅스 어레이(310a)가 2차원 어레이 구조로 형성되는 경우를 설명하였으나, 본 발명은 이에 한정되지 않으며, 실시예에 따라서 시냅스 어레이는 3차원 수직 어레이 구조로 형성될 수도 있 다. 저항성 메모리 셀의 구조 또한 실시예에 따라서 변경될 수 있다. 도 10은 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치에포함되는 뉴로모픽 코어 다이들 중 하나를 나타내는 블록도이다. 도 10을 참조하면, 뉴로모픽 코어 다이는 시냅스 어레이, 제1 뉴런들(441, 442, ..., 44N) 및 제2 뉴런들(451, 452, ..., 45N)을 포함할 수 있다. 제1 뉴런들(441, 442, ..., 44N) 각각은 프리-시냅틱 뉴런이라 호칭될 수 있고, 제2 뉴런들(451, 452, ..., 45N) 각각은 포스트-시냅틱 뉴런이라 호칭될 수 있다. 시냅스 어레이는 복수의 시냅스들을 포함하고, 시냅스들은 로우 라인들(RW1, RW2, ..., RWN)을 통하여 제1 뉴런들(441, 442, ..., 44N)에 연결되고, 컬럼 라인들(CL1, CL2, ..., CLM)을 통하여 제2 뉴런들 (451, 452, ..., 45N)에 연결될 수 있다. 시냅스 어레이는 신경망 시스템을 구성하는 레이어들에 포함되는 가중치들을 저장하고, 가중치들과 입력 데이터에 기초하여 연산을 수행할 수 있다. 도 11은 본 발명의 실시예들에 따른 도 10의 시냅스 어레이에 포함되는 복수의 시냅스들 중 하나와 대응되는 제 1 뉴런 및 대응되는 제2 뉴런의 연결 관계를 나타낸다. 도 11에서는 시냅스와 로우 라인(RW2)을 통하여 연결되는 제1 뉴런 및 시냅스와 컬럼 라인(CL 2)을 통하여 연결되는 제2 뉴런을 나타낸다. 도 11을 참조하면, 시냅스는 로우 라인(RW2)을 통하여 제1 뉴런과 연결되고 컬럼 라인(CL2)을 통하여 제2 뉴런과 연결된다. 시냅스는 저항값이 가변되는 멤리스터(memristor)와 멤리스터에 연결되고 적어도 두 개의 입력 신호들이 인가되는 트랜지스터 를 포함할 수 있다. 멤리스터는 트랜지스터에 인가되는 적어도 두 개의 입력 신호들이 입력되는 시간 차이에 의존하여 저항값이 가변될 수 있다. 멤리스터는 입력 신호들이 입력되는 시간 차이로 인한 전압의 변화에 따라 저항값이 가변될 수 있다. 예를 들어, 멤리스터의 저항값은 제1 입력 신호와 제2 입력 신호 간의 시간 차이로 인한 전압의 변화에 따라 가 변될 수 있다. 제1 입력 신호는 트랜지스터의 게이트 단자에 인가되는 신호일 수 있다. 그리고, 제2 입력 신호 는 트랜지스터의 소스 단자에 인가되는 멤브레인 전압(membrane voltage)에 기초한 신호일 수 있다. 제1 입력 신호는 제1 뉴런으로부터 전달되고, 제2 입력 신호는 제2 뉴런로부터 전달될 수 있다. 멤리스터에 흐르는 전류의 방향은 제1 입력 신호와 제2 입력 신호가 입력되는 시간 차이에 의존할 수 있다. 예를 들어, 제1 입력 신호가 제2 입력 신호에 비해 먼저 트랜지스터에 입력되는 경우, 전류는 트랜 지스터에서 멤리스터로 흐를 수 있다. 반면에, 제1 입력 신호가 제2 입력 신호보다 나중에 트랜지스 터에 입력되는 경우, 전류는 이전과는 반대로 멤리스터에서 트랜지스터의 방향으로 흐를 수 있 다. 멤리스터에 흐르는 전류의 방향과 전류량은 제1 입력 신호와 제2 입력 신호가 입력되는 시간 차이로 인한 전압 차이에 의존할 수 있다. 예를 들어, 제1 입력 신호와 제2 입력 신호가 서로 시간적으로 발생한 시간차가 커 서로 영향을 미치기 어려운 경우에는, 제 1 입력 신호가 들어오는 동안에 트랜지스터는 온(ON)이 되고 Vref > Vrest 이기 때문에 멤리스터에서 트랜지스터 쪽으로 전류가 흐르게 된다. 이 때, 멤리스터 양단의 전압차(Vref - Vrest)는 멤리스터의 특성을 바꿀 문턱 전압(threshold voltage)보다는 작으 므로 멤리스터는 HRS(High Resistance State)에 있게 되고, 멤리스터에는 '0'에 가까운 적은 량의 전류만이 흐르게 된다. 제1 입력 신호와 제2 입력 신호가 입력되는 시간의 차이가 서로 영향을 미칠 범위에 있을 만큼 작고, 제1 입력 신호가 제2 입력 신호에 비해 약간 먼저 들어오는 경우, 제 1 입력 신호가 들어오는 동안에 트랜지스터는 온(ON)이 되고 트랜지스터 소스쪽의 전압(Vb)는 Vb > Vref 가 되어 트랜지스터 쪽에서 멤리스터 쪽으로 전류가 흐르게 된다. 이 때, 멤리스터 양단의 전압차(Vb - Vref)가 멤리스터의 특성을 바꿀 문턱 전압보다 크게 되면, 멤리스터는 LRS(Low Resistance State)에 있을 수 있게 된다. 멤리스터가 LRS(Low Resistance State)에 있는 경우, 멤리스터에는 많은 량의 전류가 흐르게 되고, 그렇지 않은 경우 멤리스터는 계속해서 HRS(High Resistance State) 상태로 남게 된다. 제1 입력 신호와 제2 입력 신호가 입력되는 시간의 차이가 서로 영향을 미칠 범위에 있을 만큼 작고, 제1 입력 신호가 제2 입력 신호에 비해 비슷하거나 약간 뒤에 들어오는 경우, 제 1 입력 신호가 들어오는 동안에 트랜지 스터는 온(ON)이 되고, 트랜지스터 소스쪽의 전압(Vb)는 Vb < Vref 가 된다. 이때, 전류는 멤리스터 쪽에서 트랜지스터 쪽으로 흐르게 된다. 멤리스터 양단의 전압차(Vref - Vb)가 멤리스터 의 특성을 바꿀 문턱 전압보다 크게 되면 멤리스터는 다시 HRS(High Resistance State)에 있을 수 있다. 멤리스터에는 적은 량의 전류가 흐르게 되고, 그렇지 않은 경우 멤리스터는 계속해서 LRS(Low Resistance State) 상태로 남게 된다. 제1 입력 신호가 제2 입력 신호에 비해 많이 뒤에 들어오는 경우, 시간적으로 발생한 시간차가 커서 서로 영향 을 미치기 어려운 경우가 되고 Vref > Vrest 이기 때문에 전류는 멤리스터에서 트랜지스터 쪽으로 흐 르게 된다. 이 때, 멤리스터 양단의 전압차(Vref - Vrest)는 멤리스터의 특성을 바꿀 문턱 전압보다는 작으므로 멤리스터는 HRS(High Resistance State)에 있게 된다. 멤리스터의 제1 단은 트랜지스터의 드레인(drain) 단자에 연결되고, 제2 단은 기준 전압(Vref)을 인 가하는 전압 소스에 연결될 수 있다. 멤리스터의 채널은 트랜지스터의 채널과 서로 직렬로 연결될 수 있다. 멤리스터와 트랜지스터의 소스 단자에는 서로 다른 전압이 인가될 수 있으며, 멤리스터에 연결되는 트랜지스터는 엔모스 트랜지스터일 수 있다. 시냅스는 트랜지스터의 게이트 단자에 연결되어 제1 입력 신호를 제공하는 제1 단자 및 트랜지스터 의 소스 단자에 연결되어 제2 입력 신호를 제공하는 제2 단자를 더 포함할 수 있다. 시냅스는 제1 단 자를 통해 제1 뉴런와 연결되고, 제2 단자를 통해 제2 뉴런와 연결될 수 있다. 이 때, 제1 전압(Va) 은 제1 단자를 통해 제1 뉴런으로부터 제공되고, 제2 전압(Vb)은 제2 단자를 통해 제2 뉴런으로부터 제공될 수 있다. 제1 뉴런 및 제2 뉴런은 각각 스파이크 혹은 펄스를 발화(firing)시키는 I & F(Integrate & Firing) 스파이킹 뉴런(442a, 452a)을 포함할 수 있다. 제1 뉴런 및 제2 뉴런은 시냅스를 통해 수신하는 전류량이 기 설정된 임계값을 초과하면 스파이크 혹은 펄스를 발화할 수 있다. 제2 뉴런은 휴지 전압(Vrest)을 기준으로 발화(firing)하는 스파이크(spike)를 생성할 수 있다. 제2 뉴런 은 또한 커패시터(452b)를 더 포함할 수 있다. 도 11의 구조는 STDP(Spike-Timing-Dependent Plasticity) 동작을 구현할 수 있다. 도 12는 도 11의 시냅스에 포함된 멤리스터의 동작 특성을 나타낸 그래프이다. 도 12를 참조하면, 멤리스터의 동작 특성을 살펴볼 수 있다. 멤리스터는 얼마나 많은 양의 전류가 통과했는지를 기억할 수 있는 수동 소자로서, 전하의 양을 기억하고 기억된 전하량에 따라 저항이 변화할 수 있다. 다시 말해, 멤리스터는 전류의 흐름과 전류량에 따라 저항값이 가변될 수 있다. 도 12의 그래프에서 멤리스터에 공급되는 전압이 ±0.8V에 다다르지 않은 경우에 전류가 거의 흐르지 않는다는 것을 볼 수 있다. 하지만, 공급되는 전압이 ±0.8V를 넘어서면, 멤리스터에는 급격하게 다량의 전류가 흐르는 것을 볼 수 있다. 이때, 전류량이 급격하게 변화하는 지점의 전압을 멤리스터의 문턱 전압으로 볼수 있으며, 도 12에서는 ±0.8V에 해당할 수 있다. 멤리스터에 공급되는 전압이 문턱값에 다다르지 않아 전류가 거의 흐르지 않는 상태를 고저항 상태(High Resistance State; HRS)라고 할 수 있다. 그리고, 멤리스터에 공급되는 전압이 문턱값을 넘어서 전류가 급격하 게 흐르는 상태를 저저항 상태(Low Resistance State; LRS)라고 할 수 있다. 도 13 및 도 14는 도 12의 제1 뉴런과 제2 뉴런 사이에 흐르는 전류량의 특성 및 일반적인 STDP 동작에서의 스 파이크 발생 시간차와 시냅틱 가중치의 변화량과의 관계를 나타낸다. 포스트-시냅틱 스파이크와 프리-시냅틱 펄스 간의 발생 시간과 그 때 흐르는 전류량에 대한 특성을 살펴보면 도 13과 같으며, STDP 동작에서 펄스(pulse)의 발생 시간차와 시냅틱 가중치 변화량과의 관계는 도 14와 매우 유사 한 특성을 가짐을 알 수 있다. 상술한 시냅스에서 발화한 스파이크를 전자적 파형으로 모델링할 경우, 시냅틱 가중치 변화량은 제1 뉴런 에서 발화한 펄스(이하, '프리-시냅틱 펄스')에 대한 파형과 제2 뉴런에서 발화한 스파이크(이하, '포스트 -시냅틱 스파이크')에 대한 파형의 차(subtraction)로 나타낼 수 있다. 도 15는 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치에 포함되는 뉴로모픽 코어 다이들 중 하나를 나타내는 블록도이다. 도 15를 참조하면, 뉴로모픽 코어 다이는 시냅스 어레이, 제1 뉴런들(541, 542, ..., 54N) 및 제2 뉴런들(551, 552, ..., 55N)을 포함할 수 있다. 제1 뉴런들(541, 542, ..., 54N) 각각은 프리-시냅틱 뉴런이라 호칭될 수 있고, 제2 뉴런들(551, 552, ..., 55N) 각각은 포스트-시냅틱 뉴런이라 호칭될 수 있다. 시냅스 어레이는 복수의 시냅스들을 포함하고, 시냅스들은 로우 라인들(RW1, RW2, ..., RWN)을 통하여 제1 뉴런들(541, 542, ..., 54N)에 연결되고, 컬럼 라인들(CL1, CL2, ..., CLM)과 선택 라인들(SL1, SL2, ..., SLM)을 통하여 제2 뉴런들(551, 552, ..., 55N)에 연결될 수 있다. 시냅스 어레이는 신경망 시스템을 구성하는 레이어들에 포함되는 가중치들을 저장하고, 가중치들과 입력 데이터에 기초하여 연산을 수행할 수 있다.도 16은 본 발명의 실시예들에 따른 도 15의 시냅스 어레이에 포함되는 복수의 시냅스들 중 하나를 나타낸다. 도 16에서는 시냅스와 로우 라인(RW2)을 통하여 연결되는 제1 뉴런 및 시냅스와 컬럼 라인(CL2) 및 선택 라인(SL2)을 통하여 연결되는 제2 뉴런을 나타낸다. 도 16을 참조하면, 시냅스는 직렬로 연결된 스위칭 소자 및 멤리스터를 포함할 수 있다. 스위칭 소자는 모스 트랜지스터 같은 3극 셀렉터 또는 다이오드같은 2극 셀렉터(2-terminals selector)를 포함할 수 있다. 스위칭 소자는 스위칭 트랜지스터라 호칭될 수 있다. 스위칭 트랜지스터의 게이트 전극은 선택 라인(SL2)을 통하여 제2 뉴런과 전기적으로 연결될 수 있고, 스위칭 트랜지스터의 드레인 전극 은 로우 라인(RW2)을 통하여 제1 뉴런과 전기적으로 연결될 수 있고, 스위칭 트랜지스터의 소스 전극 은 멤리스터의 제1 단자와 연결될 수 있다. 멤리스터의 제2 단자는 컬럼 라인(CL2)을 통하여 제2 뉴 런과 전기적으로 연결될 수 있다. 도 15 및 도 16을 참조하면, 로우 신호가 로우 라인(RW2)을 통하여 제1 뉴런으로부터 시냅스로 제공 될 수 있다. 시냅스의 트랜지스터가 턴-온되면 로우 신호는 멤리스터로 제공된다. 로우 신호는 여러 가지 모드에서 멤리스터를 학습시켜 멤리스터의 저항 상태를 조절할 수 있다. 또는, 로우 신호 는 독출 모드에서 멤리스터의 저항 상태에 따른 전류 값으로 변환될 수 있다. 즉, 멤리스터는 로우 신호에 의해 저항 상태가 변하거나, 또는 로우 신호에 의해 멤리스터의 저항 상태에 따른 전류 값을 컬럼 라인(CL2)으로 출력할 수 있다. 즉, 시냅스 가중치가 컬럼 라인(CL2)으로 출력될 수 있다. 도 17은 본 발명의 실시예들에 따른 도 15에서 제2 뉴런을 나타낸다. 도 17을 참조하면, 제2 뉴런은 직렬로 연결된 적산기(summation circuit), 가변 저항 소자 및 비교기를 포함할 수 있다. 시냅스의 출력, 즉 컬럼 라인(CL2)이 적산기의 입력 단자와 연결될 수 있고, 적산기의 출력 단 자가 제1 노드(N1)를 거쳐 가변 저항 소자의 제1 전극과 연결될 수 있고, 가변 저항 소자의 제2 전극 이 제2 노드(N2)를 거쳐 비교기의 입력 단자와 연결될 수 있다. W제2 뉴런은 비교기의 출력 단 자와 가변 저항 소자를 전기적으로 연결하는 제1 피드-백 라인 및 비교기의 출력 단자와 시냅스 를 전기적으로 연결하는 제2 피드-백 라인을 더 포함할 수 있다. 제1 피드-백 라인은 제2 노드 (N2)와 전기적으로 연결될 수 있고, 및 제2 피드-백 라인은 선택 라인(SL2)과 연결될 수 있다. 또는, 제2 피드-백 라인은 선택 라인(SL2)의 일부일 수 있다. 적산기는 동일한 컬럼 라인(CL2) 상의 다수의 시냅스들의 시냅스 가중치들을 합(sum)하여 가변 저항 소자로 제공할 수 있다. 가변 저항 소자의 저항 값 또는 전도도는 적산기의 출력 및/또는 비교기의 출력에 의해 변할 수 있다. 예를 들어, 가변 저항 소자의 저항 값은 적산기의 출력에 의해 감소할 수 있고(set 동작), 비 교기의 출력에 의해 증가할 수 있다(reset 동작). 예를 들어, 적산기에 의해 적산된 시냅스 전류가 낮다면 가변 저항 소자는 높은 저항 레벨을 유지할 수 있다. 따라서, 낮은 레벨의 전류 및 낮은 레벨의 시 냅스 가중치가 비교기로 제공될 수 있다. 반대로, 적산기에 의해 적산된 시냅스 전류가 높다면 가변 저항 소자는 낮은 저항 레벨을 유지할 수 있다. 따라서, 높은 레벨의 전류 및 높은 레벨의 시냅스 가중치 가 비교기로 제공될 수 있다. 비교기는 가변 저항 소자의 출력이 기준 전압보다 높을 경우 전기적 신호를 출력할 수 있다. 즉, 발 화(fire)될 수 있다. 발화된 비교기는 출력 신호(Sout)를 출력할 수 있다. 출력 신호(Sout)의 일부들은 제 1 피드-백 신호(Sb1) 및 제2 피드-백 신호(Sb2)로 분기될 수 있다. 비교기의 출력 신호(Sout)로부터 분기된 제1 피드-백 신호(Sb1)는 가변 저항 소자로 제공되어 가변 저항 소자를 초기화시킬 수 있다. 비교기의 출력 단자는 제2 피드-백 라인 및/또는 선택 라인 (SL2)을 통하여 시냅스의 스위칭 트랜지스터의 게이트 전극과 전기적으로 연결될 수 있다. 즉, 비교 기의 출력 신호(Sout)로부터 분기된 제2 피드-백 신호(Sb2)는 스위칭 트랜지스터의 게이트 전극으로 제공될 수 있다. 따라서, 제2 피드-백 신호(Sb2)는 스위칭 트랜지스터의 게이트 전극으로 제공되어 멤리스 터를 셋/리셋시킬 수 있다. 예를 들어, 제2 피드-백 신호(Sb2)는 시냅스의 가중치를 변화시키는 STDP(spike-timing-dependent-plasticity) 동작을 위한 전기 신호로 이용될 수 있다.도 18은 본 발명의 실시예들에 따른 도 15의 시냅스 어레이에 포함되는 복수의 시냅스들 중 하나를 나타낸다. 도 18을 참조하면, 시냅스(511a)는 트랜지스터 및 상변화 소자을 포함할 수 있다. 트랜지스터의 드레인 단자는 접지 전압(GND)에 연결되고, 게이트 단자는 로우 라인(RW2)에 연결되고 소스 단자는 상변화 소자 에 연결된다. 상변화 소자의 제1 단자는 트랜지스터의 드레인 단자에 연결되고 제2 단자는 컬럼 라인(CL2)에 연결된다. 상변화 소자는 저항값의 변화에 의하여 가중치를 저장할 수 있다. 도 18의 시냅스(511a)가 도 15의 시냅스 어레이에 포함되는 경우, 시냅스 어레이는 가중치들과 입력 데이터에 대한 곱셈 연산을 수행할 수 있다. 도 19는 본 발명의 실시예들에 따른 적층형 뉴로모픽 장치에서 액세스 동작시 데이터 전송 경로를 나타내고, 도 20a 및 20b는 도 19의 데이터 전송 경로를 구현하는 실시예를 나타내는 도면들이다. 도 19의 적층형 뉴로모픽 장치를 참조하면, 제1 내지 제4 뉴로모픽 코어 다이들(300a, 300b, 300c, 300d)에 각 각 상응하는 제1 내지 제4 TSV들(TSV1~TSV4)를 통하여 로직 다이와 제1 내지 제4 뉴로모픽 코어 다이들 (300a, 300b, 300c, 300d) 사이에 데이터 교신이 수행될 수 있다. 즉, 독출 및 기입 동작시에는, 제1 TSV(TSV1)를 통하여 로직 다이와 제1 뉴로모픽 코어 다이(300a) 사이에 데이터가 전송되고, 제2 TSV(TSV2)를 통하여 로직 다이와 제2 뉴로모픽 코어 다이(300b) 사이에 데이터가 전송되고, 제3 TSV(TSV3)를 통하여 로직 다이와 제3 뉴로모픽 코어 다이(300c) 사이에 데이터가 전송되고, 제4 TSV(TSV4)를 통하여 로직 다이와 제4 뉴로모픽 코어 다이(300d) 사이에 데이터가 전송될 수 있다. 제1 내지 제4 TSV들(TSV1~TSV4)의 각각은 복수의 TSV 경로들을 포함하며, 각 TSV 경로는 적층된 뉴로모픽 코어 다이들에 형성된 실리콘 관통 전극들을 연결하여 수직으로 길게 연장될 수 있다. 도 20a 및 20b를 참조하면, 로직 다이와 뉴로모픽 코어 다이들(300a, 300b, 300c, 300d)에는 상응하는 TSV들(TSV1~TSV4)을 통하여 양방향 통신을 수행하는 송신회로들(TX) 및 수신 회로들(RX)을 포함할 수 있다. 제1 내지 제4 뉴로모픽 코어 다이들(300a, 300b, 300c, 300d)의 각각에 제1 내지 제4 TSV들(TSV1~TSV4)의 상응하는 송신회로들(TX) 및 수신 회로들(RX)을 모두 구비하고 이들을 선택적으로 인에이블 할 수 있다. 도 20a는 가중치를 저장하는 동작에 상응하는 데이터 전송 경로를 나타내고 도 20b는 연산 결과를 전송하는 동 작에 데이터 전송 경로를 나타낸다. 도 20a를 참조하면, 가중치를 저장하는 동작시에는 로직 다이의 송신 회로(TX)와 뉴로모픽 코어 다이들 (300a, 300b, 300c, 300d)의 각 수신 회로(RX)가 인에이블되어 TSV들(TSV1~TSV4)의 각각을 통하여 로직 다이 로부터 뉴로모픽 코어 다이들(300a, 300b, 300c, 300d)로 가중치(WDT)가 전송될 수 있다. 로직 다이의 제1 송신 회로(TX1)와 제1 뉴로모픽 코어 다이(300a)의 제1 수신 회로(RX11)가 인에이블되어 상응하는 제1 TSV(TSV1)를 통하여 가중치(WDT1)가 전송된다. 로직 다이의 제2 송신 회로(TX2)와 제2 뉴로 모픽 코어 다이(300b)의 제2 수신 회로(RX22)가 인에이블되어 상응하는 제2 TSV(TSV2)를 통하여 가중치(WDT2)가 전송된다. 로직 다이의 제3 송신 회로(TX3)와 제3 뉴로모픽 코어 다이(300c)의 제3 수신 회로(RX33)가 인 에이블되어 상응하는 제3 TSV(TSV3)를 통하여 가중치(WDT3)가 전송된다. 로직 다이의 제4 송신 회로(TX4) 와 제4 뉴로모픽 코어 다이(300d)의 제4 수신 회로(RX44)가 인에이블되어 상응하는 제4 TSV(TSV4)를 통하여 가 중치(WDT4)가 전송된다. 도 20b를 참조하면, 연산 결과 전송 동작시에는 뉴로모픽 코어 다이들(300a, 300b, 300c, 300d)의 각 송신 회로 (TX)와 로직 다이의 수신 회로(RX)가 인에이블되어 TSV들(TSV1~TSV4)의 각각을 통하여 뉴로모픽 코어 다이 들(300a, 300b, 300c, 300d)로부터 로직 다이로 연산 결과에 해당하는 데이터가 전송될 수 있다. 제1 뉴로모픽 코어 다이(300a)의 제1 송신 회로(TX11)와 로직 다이의 제1 수신 회로(RX1)가 인에이블되어 상응하는 제1 TSV(TSV1)를 통하여 데이터(RD1)가 전송된다. 제2 뉴로모픽 코어 다이(300b)의 제2 송신 회로 (TX22)와 로직 다이의 제2 수신 회로(RX2)가 인에이블되어 상응하는 제2 TSV(TSV2)를 통하여 데이터(RD2) 가 전송된다. 제3 뉴로모픽 코어 다이(300c)의 제3 송신 회로(TX33)와 로직 다이의 제3 수신 회로(RX3)가 인에이블되어 상응하는 제3 TSV(TSV3)를 통하여 데이터(RD3)가 전송된다. 제4 뉴로모픽 코어 다이(300d)의 제4 송신 회로(TX44)와 로직 다이의 제4 수신 회로(RX4)가 인에이블되어 상응하는 제4 TSV(TSV4)를 통하여 데 이터(RD4)가 전송된다. 실시예에 있어서, 도 4의 제어 회로(201a)의 레이어 컨트롤러는 뉴로모픽 코어 다이들(300a, 300b, 300c, 300d) 사이의 데이터 전송을 제어할 수 있다. 예를 들어, 레이어 컨트롤러는 제1 뉴로모픽 코어 다이 (300a)에서 출력되는 데이터가 제2 뉴로모픽 코어 다이(300b)로 제공되도록 제어할 수 있다. 도 21은 본 발명의 실시예들에 따른 적층형 뉴로모픽 장치의 동작 방법을 나타내는 흐름도이다. 도 2 내지 도 21을 참조하면, 로직 다이 및 로직 다이 상에 적층되는 복수의 뉴로모픽 코어 다이들 을 구비하는 적층형 뉴로모픽 장치의 동작 방법에서는 뉴로모픽 코어 다이들을 관통하는 실리콘 관통 비아(TSV)들을 통하여 가중치들을 뉴로모픽 코어 다이들 중 하나 이상의 뉴로 모픽 코어 다이들의 시 냅스 어레이에 저장한다(S610). 하나 이상의 뉴로 모픽 코어 다이들의 시냅스 어레이에서 입력 데이터와 가중치 들을 기초로 연산을 수행한다(S630). 하나 이상의 뉴로 모픽 코어 다이들에서 실리콘 관통 비아(TSV)들을 통하 여 연산의 결과를 로직 다이에 제공한다(S650). 도 22는 본 발명의 실시예들에 따른 뉴로모픽 컴퓨팅 시스템을 나타내는 블록도이다. 도 22를 참조하면, 뉴로모픽 컴퓨팅 시스템은 호스트 및 적어도 하나의 적층형 뉴로모픽 장치를 포함할 수 있다. 호스트는 중앙처리장치(Central Processing Unit: CPU), 그래픽처리장치(Graphics Processing Unit: GPU), 주문형 집적 회로(Application Specific Integrated Circuit: ASIC) 및 필드 프로그래머블 게이트 어레 이(Field Programmable Gate Array: FPGA) 중 적어도 하나를 포함할 수 있다. 적어도 하나의 적층형 뉴로모픽 장치는 로직 다이 및 로직 다이 상에 적층되는 복수의 뉴로모픽 코어 다이들을 포함할 수 있다. 뉴로모픽 컴퓨팅 시스템은 PCI-E 호환 보드일 수 있다. 도 23은 도 22의 V-V’선에 따른 뉴로모픽 컴퓨팅 시스템의 단면도이다. 도 23을 참조하면, 로직 다이 상에 뉴로모픽 코어 다이들이 적층되어 적층형 뉴로모픽 장치를 형성한다. 복수의 적층형 뉴로모픽 장치들이 뉴로모픽 컴퓨팅 시스템에 포함될 수 있다. 호스트는 각각의 로직 다이와 통신할 수 있다. 호스트 및 로직 다이들은 인터포저(Interposer, 805) 상부에 배치 되어 인터포저와 연결될 수 있다. 인터포저는 패키지 기판 상부에 배치되어 패키지 기판과 연결될 수 있다. 적층형 뉴로모픽 장치들 각각은 도 3의 적층형 뉴로모픽 장치(90a)를 채용할 수 있다. 따라서, 적층형 뉴 로모픽 장치들 각각은 호스트로부터 리퀘스트, 가중치들 및 입력 데이터(IDTA)를 수신하고, 가중치들 (WDT)을 저장하고, 최종 데이터를 호스트에 제공할 수 있다. 뉴로모픽 코어 다이들 각각은 신경망 (neural network) 시스템을 구성하는 복수의 레이어들에 포함되는 가중치들을 저장하고 상기 가중치들과 입력 데이터에 기초하여 연산을 수행하는 복수의 시냅스들을 포함하는 시냅스 어레이를 포함할 수 있다. 뉴로모픽 컴퓨팅 시스템에 있어서, 로직 다이는 기본적인 입/출력(I/O) 연산을 수행할 수 있어, 지연 시간을 감소시키고 메모리 트래픽을 개선할 수 있다. 기계 학습 알고리즘은 훈련 및 예측을 위해 매우 큰 대역 폭을 필요로 하기 때문에 이러한 아키텍처의 이점을 누린다. 프로세서 인접 메모리는 로직 다이를 통해 호 스트를 지원한다. 로직 다이는 특화된 논리 함수를 실행하며, 특화된 논리 함수는 특별히 높은 대역 폭을 요구하는 기계 학습 애플리케이션에 특화된 함수일 수 있다. 결론적으로, 시스템 성능은 향상되고 에너지 소비는 감소된다. 산업상 이용가능성 본 발명은 인공 지능을 사용하는 다양한 장치에 적용되어 데이터 처리 효율을 증가시킬 수 있다. 상술한 바와 같이, 본 발명의 바람직한 실시예를 참조하여 설명하였지만 해당 기술 분야에서 통상의 지식을 가 진 자라면 하기의 특허청구범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명 을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9a 도면9b 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20a 도면20b 도면21 도면22 도면23"}
{"patent_id": "10-2019-0135613", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예들에 따른 적층형 뉴로모픽 장치를 포함하는 전자 장치를 나타내는 블록도이다. 도 2는 본 발명의 실시예들에 따른 도 1의 전자 장치에서 적층형 뉴로모픽 장치를 나타내는 블록도이다. 도 3은 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치의 예를 나타내는 블록도이다. 도 4는 본 발명의 실시예들에 따른 도 3의 적층형 뉴로모픽 장치에서 제어 회로를 나타내는 블록도이다. 도 5는 본 발명의 실시예들에 따른 도 3의 적층형 뉴로모픽 장치에서 제어 회로를 나타내는 블록도이다. 도 6은 본 발명의 실시예들에 따른 도 5의 누적기를 나타내는 회로도이다. 도 7은 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치에포함되는 뉴로모픽 코어 다이들 중 하나를 나 타내는 블록도이다. 도 8a 및 8b는 본 발명의 실시예들에 따른 뉴로모픽 코어 다이에 의해 구동되는 신경망 시스템의 일 예를 설명 하기 위한 도면들이다. 도 9a 및 9b는 본 발명의 실시예들에 따른 도 7의 뉴로모픽 코어 다이에서 시냅스 어레이의 예들을 나타내는 도 면들이다. 도 10은 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치에포함되는 뉴로모픽 코어 다이들 중 하나를 나타내는 블록도이다. 도 11은 본 발명의 실시예들에 따른 도 10의 시냅스 어레이에 포함되는 복수의 시냅스들 중 하나와 대응되는 제 1 뉴런 및 대응되는 제2 뉴런의 연결 관계를 나타낸다. 도 12는 도 11의 시냅스에 포함된 멤리스터의 동작 특성을 나타낸 그래프이다. 도 13 및 도 14는 도 12의 제1 뉴런과 제2 뉴런 사이에 흐르는 전류량의 특성 및 일반적인 STDP 동작에서의 스 파이크 발생 시간차와 시냅틱 가중치의 변화량과의 관계를 나타낸다. 도 15는 본 발명의 실시예들에 따른 도 2의 적층형 뉴로모픽 장치에 포함되는 뉴로모픽 코어 다이들 중 하나를 나타내는 블록도이다. 도 16은 본 발명의 실시예들에 따른 도 15의 시냅스 어레이에 포함되는 복수의 시냅스들 중 하나를 나타낸다. 도 17은 본 발명의 실시예들에 따른 도 15에서 제2 뉴런을 나타낸다. 도 18은 본 발명의 실시예들에 따른 도 15의 시냅스 어레이에 포함되는 복수의 시냅스들 중 하나를 나타낸다. 도 19는 본 발명의 실시예들에 따른 적층형 뉴로모픽 장치에서 액세스 동작시 데이터 전송 경로를 나타내고, 도 20a 및 20b는 도 19의 데이터 전송 경로를 구현하는 실시예를 나타내는 도면들이다.도 21은 본 발명의 실시예들에 따른 적층형 뉴로모픽 장치의 동작 방법을 나타내는 흐름도이다. 도 22는 본 발명의 실시예들에 따른 뉴로모픽 컴퓨팅 시스템을 나타내는 블록도이다. 도 23은 도 22의 V-V’선에 따른 뉴로모픽 컴퓨팅 시스템의 단면도이다."}
