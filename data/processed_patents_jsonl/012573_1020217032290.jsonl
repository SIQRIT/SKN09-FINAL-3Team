{"patent_id": "10-2021-7032290", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0130232", "출원번호": "10-2021-7032290", "발명의 명칭": "게임 애플리케이션을 위한 게임 봇 생성", "출원인": "모들.에이아이 에이피에스", "발명자": "야나카키스 조르지오스"}}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법에 있어서,프로세서를 포함하는 시스템을 통해, 게임 봇을 생성하는 단계;상기 시스템을 통해, 실제 플레이어에 대응하는 게임 앱의 게임 원격측정 데이터를 수신하는 단계;상기 시스템을 통해, 상기 게임 봇에 대응하는 상기 게임 앱의 게임 원격측정 데이터를 생성하는 단계; 상기 시스템을 통해, 실제 플레이어에 대응하는 상기 게임 원격측정 데이터 및 상기 게임 봇에 대응하는 상기게임 원격측정 데이터에 기초하여 차이 데이터를 생성하는 단계로서, 상기 차이 데이터는 상기 실제 플레이에의해 생성된 제1 캐릭터와 상기 게임 봇에 의해 생성된 제2 캐릭터 사이의 시간에 따른 차이를 나타내는, 상기생성하는 단계; 및상기 시스템을 통해, 상기 차이 데이터에 기초하여 상기 게임 봇을 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 시간에 따른 차이는 복수의 시간 동안 상기 실제 플레이어에 의해 생성된 상기 제1 캐릭터와 상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 거리를 나타내는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 거리는 유클리드 거리인, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서, 상기 시간에 따른 차이는 상기 복수의 시간들 각각 동안 상기 실제 플레이어에 의해 생성된상기 제1 캐릭터와 상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 상기 거리의 누적을 나타내는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서, 상기 시간에 따른 차이는 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 누적된 게임 스코어의 차이를 나타내는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서, 상기 시간에 따른 차이는 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 게임성과의 차이를 나타내는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서, 상기 시간에 따른 차이는 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 게임목표에 도달하는데 걸리는 시간 차이를 나타내는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서, 상기 시간에 따른 차이는, 시간 기간의 복수의 시간 동안 상기 실제 플레이어에 의해 생성된 상기 제1 캐릭터와 상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 거리, 상기 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 누적된 게임 스코어의 차이, 상기 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 게임 성과의 차이, 또는 상기 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의게임 목표에 도달하는 시간 차이 중 둘 이상의 조합을 나타내는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2021-0130232-3-청구항 1에 있어서, 상기 게임 봇은 게임 원격측정 데이터를 기반으로 상기 실제 플레이어를 모방하도록 훈련된인공 신경망을 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서, 상기 게임 원격측정 데이터는 상기 실제 플레이어 및 상기 게임 봇에 대응하는 픽셀 데이터를 포함하며, 상기 시간에 따른 차이는 복수의 시간 동안 상기 실제 플레이어에 의해 생성된 상기 제1 캐릭터와상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 픽셀 거리를 나타내는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 1에 있어서, 상기 차이 데이터에 기초하여 상기 게임 봇을 업데이트하는 단계는 상기 게임 봇을 조정된게임 봇 구성들로 반복적으로 조정하는 단계, 상기 조정된 게임 봇 구성들에 대응하는 업데이트된 차이 데이터를 반복적으로 생성하는 단계, 및 상기 대응하는 업데이트된 차이 데이터가 차이 임계값과 유리하게 비교될 때상기 조정된 게임 봇 구성들 중 하나를 수락하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "시스템에 있어서,프로세서;상기 프로세서의 의해 실행 시, 상기 프로세서가,게임 봇을 생성하는 단계;실제 플레이어에 대응하는 게임 앱의 게임 원격측정 데이터를 수신하는 단계;상기 게임 봇에 대응하는 상기 게임 앱의 게임 원격측정 데이터를 생성하는 단계; 실제 플레이어에 대응하는 상기 게임 원격측정 데이터 및 상기 게임 봇에 대응하는 상기 게임 원격측정 데이터에 기초하여 차이 데이터를 생성하는 단계로서, 상기 차이 데이터는 상기 실제 플레이어에 의해 생성된 제1 캐릭터 및 상기 게임 봇에 의해 생성된 제2 캐릭터 사이의 시간에 따른 차이를 나타내는, 상기 생성하는 단계; 및상기 차이 데이터에 기초하여 상기 게임 봇을 업데이트하는 단계를 포함하는 동작들을 수행하도록 하는 동작 인스트럭션들을 저장하도록 구성된 메모리를 포함하는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 12에 있어서, 상기 시간에 따른 차이는 복수의 시간 동안 상기 실제 플레이어에 의해 생성된 상기 제1캐릭터와 상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 거리를 나타내는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서, 상기 시간에 따른 차이는 상기 복수의 시간들 각각 동안 상기 실제 플레이어에 의해 생성된 상기 제1 캐릭터와 상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 상기 거리의 누적을 나타내는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 12에 있어서, 상기 시간에 따른 차이는 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 누적된 게임 스코어의 차이를 나타내는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 12에 있어서, 상기 시간에 따른 차이는 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 게임성과의 차이를 나타내는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 12에 있어서, 상기 시간에 따른 차이는 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 게임공개특허 10-2021-0130232-4-목표에 도달하는 데 걸리는 시간 차이를 나타내는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 12에 있어서, 상기 시간에 따른 차이는, 시간 기간의 복수의 시간 동안 상기 실제 플레이어에 의해 생성된 상기 제1 캐릭터와 상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 거리, 상기 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 누적된 게임 스코어의 차이, 상기 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의 게임 성과의 차이, 또는 상기 시간 기간 동안 상기 게임 봇과 상기 실제 플레이어 사이의게임 목표에 도달하는 시간 차이 중 둘 이상의 조합을 나타내는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 12에 있어서, 상기 게임 봇은 게임 원격측정 데이터를 기반으로 상기 실제 플레이어를 모방하도록 훈련된 인공 신경망을 포함하고, 상기 게임 원격측정 데이터는 상기 실제 플레이어 및 상기 게임 봇에 대응하는 픽셀 데이터를 포함하며, 상기 시간에 따른 차이는 복수의 시간 동안 상기 실제 플레이어에 의해 생성된 상기 제1캐릭터와 상기 게임 봇에 의해 생성된 상기 제2 캐릭터 사이의 픽셀 거리를 나타내는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 12에 있어서, 상기 차이 데이터에 기초하여 상기 게임 봇을 업데이트하는 것은 상기 게임 봇을 조정된게임 봇 구성들로 반복적으로 조정하는 것, 상기 조정된 게임 봇 구성들에 대응하는 업데이트된 차이 데이터를반복적으로 생성하는 것, 및 상기 대응하는 업데이트된 차이 데이터가 차이 임계값과 유리하게 비교될 때 상기조정된 게임 봇 구성들 중 하나를 수락하는 것을 포함하는, 시스템."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "방법에 있어서,프로세서를 포함하는 시스템을 통해, 게임에 대응하는 게임 애플리케이션을 수신하는 단계;상기 시스템을 통해, 적어도 하나의 비모방 게임 봇에 의한 상기 게임의 플레이에 기초하여 상기 게임 애플리케이션을 업데이트하여 제1 업데이트된 게임에 대응하는 제1 업데이트된 게임 애플리케이션을 생성하는 단계;상기 시스템을 통해, 제1 복수의 실제 플레이어들에 의한 상기 제1 업데이트된 게임의 플레이에 응답하여 생성된 제1 게임 원격측정 데이터에 기초하여 적어도 하나의 모방 게임 봇을 생성하는 단계;상기 시스템을 통해, 상기 제1 복수의 실제 플레이어들에 의한 상기 제1 업데이트된 게임의 플레이에 기초하여행동 경험 분석(BEA) 데이터를 생성하는 단계;상기 시스템을 통해, 상기 BEA 데이터에 기초하여 적어도 하나의 BEA 툴을 생성하는 단계;상기 시스템을 통해, 상기 적어도 하나의 모방 게임 봇에 의한 상기 제1 업데이트된 게임의 플레이에 기초하여상기 제1 게임 애플리케이션을 업데이트하여 제2 업데이트된 게임에 대응하는 제2 업데이트된 게임 애플리케이션을 생성하는 단계;상기 시스템을 통해, 제2 복수의 실제 플레이어들에 의한 상기 제2 업데이트된 게임의 플레이에 응답하여 생성된 제2 원격측정 데이터에 기초하여 예측된 플레이어 동기부여를 생성하는 단계; 및상기 시스템을 통해, 상기 예측된 플레이어 동기부여에 기초하여 상기 제2 게임 애플리케이션을 업데이트하여제3 업데이트된 게임에 대응하는 제3 업데이트된 게임 애플리케이션을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "방법에 있어서,프로세서를 포함하는 시스템을 통해, 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 단계; 상기 시스템을 통해, 게임 애플리케이션으로부터 픽셀 데이터를 수신하는 단계;상기 시스템을 통해, 상기 BEA 툴을 상기 픽셀 데이터에 적용하여 예측된 사용자 경험을 생성하는 단계; 및상기 시스템을 통해, 상기 예측된 사용자 경험에 기초하여 상기 게임 애플리케이션의 적응을 용이하게 하는 단공개특허 10-2021-0130232-5-계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "청구항 22에 있어서, 상기 시스템은 게임 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현되며,상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 상기 게임 개발 애플리케이션을 통해 상기 게임 애플리케이션의 적응을 용이하게 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "청구항 22에 있어서, 상기 게임 애플리케이션은 복수의 옵션 버전들을 포함하며, 상기 시스템은 상기 게임 애플리케이션을 실행하는 게임 시스템을 통해 구현되고, 상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 상기 예측된 사용자 경험에 기초하여 상기 복수의 옵션 버전들 중 하나를 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "청구항 22에 있어서, 상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 플레이어 불일치를 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "청구항 22에 있어서, 상기 예측된 사용자 경험은 복수의 동기부여 요인들 각각에 대한 스코어를 나타내는 동기부여 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "청구항 22에 있어서, 상기 예측된 사용자 경험은 예측된 플레이어 경험의 변화를 나타내는 시간에 따라 수집된경험 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "청구항 22에 있어서, 상기 픽셀 데이터는 게임 봇에 기초하여 생성되는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "청구항 22에 있어서, 상기 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지들에 기초하고 상기이전 게임 플레이와 연관된 이전 게임 원격측정 데이터에 더 기초하여 훈련된 기계 학습 모델을 포함하는,방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "에 있어서, 상기 시스템은 게임 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현되며,상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 상기 게임 개발 애플리케이션을 통해 상기 게임 애플리케이션의 적응을 용이하게 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "청구항 30에 있어서, 상기 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지들에 기초하고 상기이전 게임 플레이와 연관된 이전 게임 원격측정 데이터에 더 기초하여 훈련된 기계 학습 모델을 포함하는,방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "청구항 30에 있어서, 상기 게임 데이터는 복수의 시청자들로부터의 채팅 데이터를 포함하는, 방법.공개특허 10-2021-0130232-6-청구항 33"}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "청구항 30에 있어서, 상기 게임 애플리케이션은 복수의 옵션 버전들을 포함하며, 상기 시스템은 상기 게임 애플리케이션을 실행하는 게임 시스템을 통해 구현되고, 상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 상기 예측된 사용자 경험에 기초하여 상기 복수의 옵션 버전들 중 하나를 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "청구항 30에 있어서, 상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 플레이어 불일치를 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "청구항 30에 있어서, 상기 예측된 시청자 경험은 예측된 시청자 참여의 변화를 나타내는 시간에 따라 수집된 참여 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "방법에 있어서,프로세서를 포함하는 시스템을 통해, 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 단계; 상기 시스템을 통해, 게임 데이터 및 게임 애플리케이션의 플레이와 연관된 멀티모드 플레이어 데이터를 수신하는 단계;상기 시스템을 통해, 상기 BEA 툴을 상기 게임 데이터 및 상기 멀티모드 플레이어 데이터에 적용하여 예측된 사용자 경험을 생성하는 단계; 및상기 시스템을 통해, 상기 예측된 사용자 경험에 기초하여 상기 게임 애플리케이션의 적응을 용이하게 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "청구항 37에 있어서, 상기 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지들에 기초하고 상기이전 게임 플레이와 연관된 이전 게임 원격측정 데이터에 더 기초하여 훈련된 기계 학습 모델을 포함하는,방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "청구항 37에 있어서, 상기 게임 데이터는, 플레이시간 데이터, 완료 데이터 또는 진행 데이터 중 적어도 하나를포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "청구항 37에 있어서, 상기 게임 데이터는 다른 게임 데이터에 대한 클러스터링 분석을 통해 생성된 복수의 플레이어 유형들 중 하나의 표시를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "청구항 37에 있어서, 상기 시스템은 게임 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현되며,상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 상기 게임 개발 애플리케이션을 통해 상기 게임 애플리케이션의 적응을 용이하게 하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "공개특허 10-2021-0130232-7-청구항 37에 있어서, 상기 게임 애플리케이션은 복수의 옵션 버전들을 포함하며, 상기 시스템은 상기 게임 애플리케이션을 실행하는 게임 시스템을 통해 구현되고, 상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 상기 예측된 사용자 경험에 기초하여 상기 복수의 옵션 버전들 중 하나를 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "청구항 37에 있어서, 상기 게임 애플리케이션의 적응을 용이하게 하는 단계는 플레이어 불일치를 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "청구항 37에 있어서, 상기 예측된 사용자 경험은 복수의 동기부여 요인들 각각에 대한 스코어를 나타내는 동기부여 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "청구항 37에 있어서, 상기 예측된 사용자 경험은 예측된 플레이어 동기부여의 변화를 나타내는 시간에 따라 수집된 동기부여 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "청구항 37에 있어서, 상기 게임 데이터는 게임 봇에 기초하여 생성되는, 방법."}
{"patent_id": "10-2021-7032290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "청구항 37에 있어서, 상기 게임 데이터는 게임 비디오와 연관된 픽셀 데이터를 포함하는, 방법."}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예들에서, 프로세서를 포함하는 시스템을 통해, 게임 봇을 생성하는 단계; 시스템을 통해, 실제 플레 이어에 대응하는 게임 앱의 게임 원격측정 데이터를 수신하는 단계; 시스템을 통해, 게임 봇에 대응하는 게임 앱 의 게임 원격측정 데이터를 생성하는 단계; 시스템을 통해, 실제 플레이어에 대응하는 게임 원격측정 데이터 및 게임 봇에 대응하는 게임 원격측정 데이터에 기초하여 차이 데이터를 생성하는 단계; 및 시스템을 통해, 차이 데 이터에 기초하여 게임 봇을 업데이트하는 단계를 포함하는 방법이 제시된다."}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 게임 시스템 및 다른 게임 장치에 의해 사용되는 게임 애플리케이션의 개발에 사용되는 처리 시스템 및 애플리케이션에 관한 것이다."}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 게임 개발 시스템의 그림/블록도 표현을 나타낸다. 특히, 네트워크를 통한 모바일 장치 및 게임 시스템과 같은 게임 장치들과 네트워크를 통한 게임 데이터 및 플레이어 데이터를 통신하는 게임 개발 플랫폼이 제시된다. 네트워크는 인터넷 또는 다른 광역 또는 근거리 통신망일 수 있다. 게임 개발 시스템은 게임 애플리케이션의 생성, 개발, 테스팅, 밸런싱 및 업데이팅에 사용될 수 있다. 게임 데이터는, 예를 들어, 플레이를 위해 게임 장치들에 제공되는 게임 애플리케이션의 현재 버전을 포함 할 수 있다. 또한, 게임 장치에서 게임 개발 플랫폼으로 전송된 게임 데이터는 게임 원격측정 데이터 를 포함하거나 게임 개발에 사용되는 게임 원격측정 데이터 및/또는 다른 게임 분석을 생성하도록 처리될 수 있 다. 플레이어 데이터는 게임 시스템(112 또는 113)과 관련된 마이크에 의해 생성된 플레이어 또는 시청자 언어 데이터, 플레이어 또는 시청자와 관련된 채팅 데이터 및/또는 예를 들어 플레이어 및/또는 시청자 참여, 반응 또는 감정을 나타내는 게임 시스템(112 또는 113)과 연관된 카메라 또는 다른 이미징 센서를 통해 캡처되 는 얼굴 표정, 머리 포즈 및/또는 기타 비언어적 데이터와 같은 플레이어 또는 시청자의 비언어적 데이터와 같 은 하나 이상의 출력 모드들을 포함할 수 있다. 게임 개발 플랫폼의 동작은 몇 가지 선택적 기능들 및 특징들 및 그 예들을 포함하는, 도 2 내지 도 14를 참조하여 보다 구체적으로 설명될 것이다. 특히, 게임 애플리케이션 개발 기술과 게임 애플리케이션들 자체의 기술 둘 다에 대한 개선 사항들이 본원에 제시된다. 도 2는 본 개시의 일 실시예에 따른 게임 개발 플랫폼의 블록도 표현을 나타낸다. 특히, 게임 개발 플랫폼(12 5)은 3G, 4G, 5G 또는 기타 셀룰러 무선 트랜시버, 블루투스 트랜시버, WiFi 트랜시버, 초광대역 트랜시버, WIMAX 트랜시버, ZigBee 트랜시버 또는 기타 무선 인터페이스, 범용 직렬 버스(USB) 인터페이스, IEEE 1394 펌 웨어 인터페이스, 이더넷 인터페이스 또는 기타 유선 인터페이스 및/또는 네트워크를 통해 하나 이상의 게 임 장치들과 통신하기 위한 기타 네트워크 카드 또는 모뎀을 포함한다. 네트워크는 인터넷 또는 다른 공용 또는 사설 네트워크일 수 있다. 게임 개발 플랫폼은 또한 처리 모듈 및 Apple, Unix, Linux 또는 Microsoft 운영 체제 또는 다른 운 영 체제, 게임 개발 애플리케이션, 하나 이상의 게임 애플리케이션, 하나 이상의 게임 봇, 하나 이상의 절차적 콘텐트 생성(PCG) 툴, 및 하나 이상의 행동 경험 분석(BEA) 툴과 같은 운영 체제 (O/S)를 저장하는 메모리 모듈을 포함한다. 특히, O/S, 게임 개발 애플리케이션, 게임 애 플리케이션, 게임 봇, PCG 툴 및 BEA 툴 각각은, 처리 모듈에 의해 실행될 때, 처리 모듈을 본원에 설명된 특정 기능들을 수행하는 특수 목적 장치로 구성하기 위해 협력하는 동작 인스트럭션들을 포함한다. 게임 개발 플랫폼은 또한 디스플레이 장치, 터치 스크린, 키패드, 터치 패드, 조이 스틱, 썸 휠, 마우스, 하나 이상의 버튼들, 스피커, 마이크로폰, 가속도계, 자이로스코프 또는 기타 모션 또는 위치 센서, 비디오 카 메라 또는 게임 개발 플랫폼의 사용자에게 정보를 제공하고 게임 개발 플랫폼과의 사용자 상호작용에 응답하여 데이터를 생성하는 기타 인터페이스 장치를 포함할 수 있다. 처리 모듈은 단일 처리 장치 또는 복수의 처리 장치들을 통해 구현될 수 있다. 이러한 처리 장치들은 마이 크로프로세서, 마이크로컨트롤러, 디지털 신호 프로세서, 마이크로컴퓨터, 중앙 처리 장치, 필드 프로그램 가능 게이트 어레이, 프로그램 가능 로직 장치, 상태 머신, 로직 회로부, 아날로그 회로부, 디지털 회로부 및/또는 메모리와 같은 메모리에 저장되는 동작 인스트럭션들에 기초한 신호들(아날로그 및/또는 디지털)을 조장하 는 임의의 장치를 포함할 수 있다. 메모리 모듈은 하드 디스크 드라이브 또는 기타 디스크 드라이브, 읽기 전용 메모리, 랜덤 액세스 메모리, 휘발성 메모리, 비휘발성 메모리, 정적 메모리, 동적 메모리, 플래시 메모리, 캐시 메모리, 및/또는 디지털 정보를 저장하는 임의의 장치를 포함할 수 있다. 처리 장치가 상태 머신, 아날로그 회로부, 디지털 회로부 및/또는 로직 회로부를 통해 기능들 중 하나 이상을 구현할 때, 해당 동작 인스트럭션들을 저장하는 메모리는 상태 머신, 아날로그 회로부, 디지털 회로부 및/또는 로직 회로부를 포함하는 회로부 내에 또는 외부에 임베디드될 수 있다. 단일 버스를 포함하는 특정 버스 아키텍처가 제시되어 있지 만, 추가 데이터 버스들 및/또는 하나 이상의 요소들 간의 직접 연결성을 포함하는 다른 아키텍처들이 가능하다. 또한, 게임 개발 플랫폼은 구체적으로 도시되지 않은 하나 이상의 추가 요소들을 포함할 수 있 다. 게임 개발 애플리케이션은 게임 개발자에 의해 게임 애플리케이션의 생성, 개발, 테스팅, 밸런싱, 개 선, 개정, 최적화 적응 및/또는 업데이팅을 지원하고 용이하게 하는 데 사용될 수 있다. 게임 애플리케이션 은 예를 들어, 슈팅 게임 또는 다른 전투 게임, 판타지 게임 또는 다른 액션 또는 어드벤처 게임, 실제 차 량 장치 또는 시스템의 동작을 시뮬레이션하는 시뮬레이션 게임, 실시간 전략 게임, 퍼즐, 스포츠 게임, 롤 플 레잉 게임, 보드 게임 또는 기타 비디오 또는 디지털 애니메이션 게임을 포함하는 멀티플레이어 또는 싱글 플레 이어 게임일 수 있다. 다양한 실시예들에서, 게임 애플리케이션의 하나 이상의 버전들은, 예를 들어, 게임 애플리케이션의 다수의 버전들 또는 업데이트들, 하나 이상의 게임 파라미터 세트들, 게임 프로파일들 또는 게 임 옵션들, 하나 이상의 레벨들 및 기타 콘텐트 및 다른 게임 데이터를 포함하여 저장될 수 있다. 게임 봇은 게임 개발 애플리케이션과 함께 동작하여 게임 애플리케이션의 동작을 테스트하고/하 거나 게임에서 하나 이상의 비-플레이어 캐릭터들(NPC들)로서 동작한다. 게임 봇은 기계 학습 알고리즘을 통해 구성 및 구현되고, 예를 들어, 특정 플레이 스타일 또는 스킬 레벨을 나타내도록 설계된 자동 테스터들로 서 동작하는 게임 플레이 AI(인공 지능) 페르소나를 포함하고/하거나 이로 동작할 수 있다. 이러한 AI 페르소나 는, 예를 들어, 실제 플레이어보다 훨씬 빠르게 게임을 진행하여 게임 콘텐트를 더 빨리 평가하고; 수천 가지의 다양한 플레이스루를 통해 무작위로 레벨의 난이도를 평가하고; 핵심 성능 지표(KPI)를 생성하고, 디자인 반복 속도를 높이고, 디자이너가 게임 플레이와 높은 수준의 개념에 집중할 수 있는 시간을 확보하고; 예를 들어, 게 임 애플리케이션의 다양한 버전들 및/또는 반복들을 통해 동일한 스킬 레벨 및 스타일로 계속해서 테스트 하는 데 사용될 수 있다. 또한, 하나 이상의 AI 페르소나는 기록된 인간 데모에서 기계 학습을 기반으로 게임을 플레이하고 콘텐트 또는 코드 변경 후에도 게임이 여전히 플레이 가능한지 확인하는 회귀 플레이 테스터로 동작할 수 있다. 특히, 회귀 플레이 테스터는 게임에서 오류가 발견될 때 리포트를 생성하고, KPI들을 생성하고, 전체 플레이 시간 및 게임 난이도의 변화를 예측하고 및/또는 BEA 툴과 함께 작동하여 지루함, 흥분, 완성 등을 포함하여 긍정적 및 부정적 둘 다의 플레이어 행동 동기부여의 양의 변화를 예측할 수 있다. 상기에 나타낸 바와 같이, AI 페르소나는 싱글 및 멀티플레이어 게임을 위한 플레이어 스탠드-인, AI 상대 및/ 또는 NPC로 작동할 수 있다. 이는 게임 개발자가 출시 전후에 항상 상대가 있는지 확인하도록 하고 실제 상대를 모방하도록 하고; 스킬 레벨과 스타일이 다양한 상대와 플레이어들에게 도전하도록 하고; 행동 패턴이 다양한 캐릭터들로 생생하고 설득력 있는 세계를 생성하도록 할 수 있다. PCG 툴은 절차적 콘텐츠 생성을 사용하여 새로운 게임 애플리케이션 및/또는 기존 게임 애플리케이션 에 대한 새로운 콘텐트 또는 레벨의 개발 시 게임 개발 애플리케이션을 사용하여 게임 개발자의 창의적 프 로세스를 시작하고 가속화한다. PCG 툴은 구성 알고리즘, 생성 및 테스트 알고리즘, 검색 기반 알고리즘 및/또는 기계 학습 알고리즘을 통해 구성되며, 예를 들어 콘볼루션 신경망, 스택형 신경망, 생성적 대립 네트워 크 또는 게임 원격측정 데이터, 행동 동기부여 데이터 및/또는 하나 이상의 AI 페르소나에 의한 게임 플레이를 기반으로 반복적으로 훈련되고 새로운 게임 변형, 새로운 레벨 및 기타 콘텐트와 같은 새로운 게임 콘텐트를 생 성하도록 동작하는 기타 딥 러닝 알고리즘을 포함한다. 예를 들어, 게임 플레이 AI 페르소나는 게임 콘텐트 전반에 걸쳐 AI 페르소나 플레이 트레이스들 및 통계를 생 성하여 PCG를 통해 생성된 콘텐츠를 평가하고 비판할 수 있으며 예측된 KPI들 및/또는 기타 성능 지표 측면에서 절차적으로 생성된 콘텐트를 평가할 수 있다. 이는 게임 개발 애플리케이션이 PCG 인에이블 게임의 플레이 공간을 이해하고 평가하는 데 있어서 게임 개발자를 자동으로 신속하게 지원하여 플레이할 수 없거나 퇴화하는 예들로부터 PCG 디자인을 보호할 수 있도록 한다. 또한, PCG 툴은 딥 러닝 알고리즘을 시드하고 평가를 위한 새로운 후보 콘텐트를 생성하기 위해 게임 개발 자에 의해 게임 개발 플랫폼에 제공된 예들로부터 학습함으로써 새로운 퍼즐, 레벨 또는 기타 콘텐트를 생 성할 수 있다. 이는 게임 개발 플랫폼을 사용하는 게임 개발자들이 미리 생성된 퍼즐, 레벨 및/또는 기타 콘텐트로 그들의 생산성을 증가시킬 수 있도록 하고; 평범한 레이아웃보다 개념과 중요한 세부 사항들에 집중하 도록 하고; 빈 캔버스 대신 생성된 예들로부터 생성을 시작하고/하거나 게임 개발자에 의해 게임 개발 플랫폼에 제공한 시드 예들을 기반으로 이전 게임 개발자로부터 배운 스타일 및 선호도로 콘텐츠를 생성한다. BEA 툴은 게임 개발 애플리케이션과 함께 동작하여 실시간으로 게임 원격측정 데이터 또는 플레이어 들/시청자들의 다른 플레이 트레이스들로부터 플레이어 동기부여 및 기타 플레이어/시청자 경험들을 자동으로 예측하고, 예를 들어, 플레이어/시청자 동기부여 또는 기타 플레이어/시청자 경험에 대한 예측들을 나타내는 플 레이어/시청자 동기부여의 다른 지표들 또는 복수의 동기부여 요인들 각각에 대한 양을 나타내는 스코어 또는 기타 값을 포함하는 행동 동기부여 데이터(\"동기부여 데이터\", 예측된 \"플레이어/사용자 동기부여\" 또는 예측된 \"사용자 동기부여\"라고도 함)를 생성한다. 또한, 게임 봇 및/또는 PCG 툴과 조합된 BEA 툴의 사 용은 게임 개발자가, 시뮬레이션된 게임 플레이, 미래의 플레이어/시청자 동기부여 및 AI 페르소나의 플레이 트 레이스들로부터의 다른 플레이어 경험들에 기초하여, 예측하도록 할 수 있다. 게임 개발 플랫폼의 이러한 사용은 게임 개발자가 플레이어들 또는 시청자들이 특정 게임 애플리케이션 을 좋아하는 이유를 이해하고, 이탈을 줄이고, 플레이어 경험들 및 장기 참여를 최적화하도록 게임 애플리 케이션을 조정하는 데 도움을 줄 수 있다. 특히, 잠재적인 게임 플레이어들은 서로 다르며, 서로 다른 이유로 플레이한다. 플레이어 동기부여를 예측하면 게임 개발자가 잠재적인 플레이어 기반에서 이러한 차이점과 그룹화 를 이해하는 데 도움이 된다. BEA 툴은 실제 플레이어 동기부여를 학습하고 예측하기 위해, 예를 들어, 플레이어 설문지, 게임 원격측정 데이터 또는 기타 게임 데이터에 기초하여, 훈련되는 선호도 학습 또는 다른 기계 학습 기술들을 통해 구성될 수 있다. 일단 훈련되면, BEA 툴은 다른 플레이어들/시청자들로부터의 게임 원격측정 데이터를 사용하여 게임과 상호작용하는 개별 플레이어들/시청자들의 이유들을 예측한다. 예를 들어, 플레이어들/시청자들이 복수 의 동기부여 요인들에 의해 동기 부여되는 정도 또는 양을 나타내는 동기부여 데이터의 형태로 BEA 데이터를 생 성하는 것은 게임 개발자가 플레이어 경험을 최적화하고 그에 따라 그들의 동기부여에 따라 플레이어들을 매칭 하여, 더 나은 플레이 세션들을 만들도록 하고, 플레이어에 대한 게임들을 최적화 및 개별화하여, 플레이어들/ 시청자들 유지 및 평생 가치를 향상시키도록 하고, 불량한 플레이어 일치(즉, 플레이어 불일치) 및 잠재적인 부 정적인 상호작용을 문제가 되기 전에 식별하도록 하고, 시간이 지남에 따라 게임 플레이어 기반의 발전을 추적 하고 일반적인 플레이어 동기부여 또는 행동 프로필이 변경되기 시작하면 매일 추적하여 게임 애플리케이션을 관리하도록 한다. 다음 사례 예들을 고려한다. 사례#1"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "배경기술 ㆍ게임 개발자는 멀티플레이어 모바일 게임인 게임 애플리케이션을 개발하기 위해 게임 개발 플랫폼 을 사용하고 있다. ㆍ게임은 각각 최대 4명의 캐릭터들로 구성된, 두 개의 상대 팀들이 있으며, 판타지 미식 축구 형태를 플레이하 고 있다. ㆍ플레이어가 사용할 수 있는 캐릭터는 플레이어가 사용할 수 있는 더 큰 풀에서 가져와, 특정 경기들을 위한 \"데크\"로 구축된다. ㆍ캐릭터들 각각은 플레이어 경험을 근본적으로 바꾸는 서로 다른 능력들을 가지고 있다. 서로 다른 데크의 서 로 다른 캐릭터들을 결합하는 것은 플레이어들에게 서로 다른 팀들을 제공할 것이다. ㆍ추가로, 각 캐릭터는 건강 값, 피해, 속도 등의 조합으로 무기한 조정될 수 있다. ㆍ게임이 균형이 잘 잡혀 있고 플레이어들이 게임을 플레이하면서 더 많은 캐릭터들을 획득할 수 있도록 인센티 브를 주기 위해 이러한 다양한 데크들이 서로에 대해 어떻게 플레이하는지 이해하는 것이 중요하다. ㆍ게임 개발자는 초기 출시 이후, 지속적으로 새로운 캐릭터들을 개발하고 주기적으로 새로운 캐릭터들을 출시 할 계획이다. ㆍ추가로, 게임 개발자는 게임플레이의 속성들을 변경하여, 특정 데크의 플레이 가치에 다시 영향을 미치는, 새 로운 플레잉 필드들을 개발 및 출시할 계획이다. 요구 사항들 ㆍ게임 개발자는 단독으로 또는 데크의 다른 캐릭터들과 결합할 때 둘 다, 캐릭터들 각각의 플레이 속성들을 이 해해야 한다. ㆍ이는 게임 개발자가 게임플레이 중에 게임에서 서로에 대해 서로 다른 캐릭터들이 동적으로 수행한다는 것을 이해해야 함을 의미한다. ㆍ이는 서로 다른 캐릭터 데크 구성들로 많은 게임들을 플레이하고 다양한 조합들로 다양한 플레이 스타일들과 전략들의 영향을 관찰하고 분석하는 것을 의미한다. ㆍ게임은 18명의 캐릭터들이 있으며 4명의 캐릭터들를 선택하는 것 외에도, 플레이어들은 그 데크에 추가할 수 있는 4가지 주문들 중에서 선택할 수 있다. ㆍ이는 게임의 현재 버전이 캐릭터들과 주문들의 속성들이 무한정 변할 수 있는 293,760개의 서로 다른 데크 조 합들을 지원한다는 것을 의미한다. ㆍ각 경기가 두 개의 데크들(이는 동일할 수 있음)로 플레이되기 때문에, 게임 값들을 조정하기 전에 설정되고 플레이될 수 있는 86,294,937,600개의 서로 다른 경기들이 있다. ㆍ이 외에도, 서로 다른 게임 맵들은 복잡성을 더욱 증가시킨다. ㆍ이 조합 문제는 더 많은 캐릭터들과 맵들이 게임에 추가됨에 따라 계속 확장된다. ㆍ게임 개발자는 많은 서로 다른 데크 솔루션들의 속성들을 탐색하고 가능한 한 조합들을 일치시켜 게임플레이 를 최적화하고 고객 평생 가치(LTV)를 극대화하기 위해 수익을 창출하는 높은 유지율을 가진 제품을 보장하기를 원한다. 게임 개발 플랫폼의 사용 ㆍ캐릭터와 데크의 속성들을 조사하기 위해 단일 경기를 플레이하는 데에는 현재 동시에 플레이할 수 있도록 조 정해야 하는 두 사람에 대해 각각 약 5분 정도 걸린다. ㆍ캐릭터와 데크의 속성들을 조사하기 위해 단일 경기를 플레이하는 데에는 현재 두 개의 게임 봇들에 대 해 20 내지 25초가 걸린다. ㆍ게임 봇들은 인간 플레이어들을 사용하는 것보다 15배 더 빠를 뿐만 아니라, 많은 경기들이 병렬로 실행 되도록 하고, 데이터가 집계되도록 하며, 통계를 사용하여 비교되도록 하므로, 정성적 해석이 필요하다. ㆍ캐릭터를 정성적으로 검사하고자 하는 게임 개발자들은 게임 봇들에 대해 그렇게 플레이할 수 있으므로, 관련된 인간 노동을 50% 줄이고 직원이 다른 태스크들에 시간을 할애할 수 있으며, 동시에 두 직원들 간의 스케 줄링에 대한 필요를 없앨 수 있다. ㆍ추가로, 게임 봇들은 완성된 게임에 플레이어와 대면하는 NPC로서 포함될 수 있다. 이를 통해 게임 개발 자가 내부적으로 AI에 직면한 플레이어를 별도로 개발할 필요가 없고, 게임 개발자가 플레이어 기반을 구축함에 따라, 신규 플레이어들에게 무제한의 상대들을 제공함으로써 게임의 하드 런칭을 개선한다. 사례#2"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "배경기술 ㆍ게임 개발자는 퍼즐 게임을 구현하는 기존 게임 애플리케이션을 가지고 있다. ㆍ플레이어들에게 게임을 신선하게 유지하려면 새로운 콘텐트를 지속적으로 제작해야 한다. ㆍ새로운 콘텐트는 고품질이어야 한다. ㆍ콘텐트는 교환할 수 없다: 게임 개발자는 분석에서 레벨 품질 - 좋은 레벨은 플레이어들을 유지하는 핵심 구 성 요소이다 - 의 차이가 고객 평생 가치에 큰 영향을 미친다고 보고한다. ㆍ현재 새 레벨을 만드는 팀은 새 레벨을 만드는 2 내지 3명의 레벨 디자이너들로 구성되어 있다. ㆍ이전에는 디자이너들이 2주마다 게임에 출시되는 15개의 새로운 레벨들을 생성할 수 있었다. 외부 플레이테스 트 회사와 함께 이러한 레벨들을 평가하는 데 1주일이 걸렸다. ㆍ반복 시간을 줄이면 디자이너들이 게임 성능의 주요 예측자인 레벨들의 품질을 높이는 새로운 특징들에 집중 할 수 있도록 한다. 요구 사항들 ㆍ게임 개발자는 디자이너들이 레벨 디자인을 구축하는 일상적인 측면보다는 새로운 레벨 아이디어에 집중할 수 있도록, 디자이너들이 선택할 수 있는 새로운 레벨 개념을 자동으로 생성하는 알고리즘을 원한다. ㆍ게임 개발자는 자동 콘텐트 생성을 사용하여 디자이너들과 함께 새로운 아이디어들을 촉발 - \"빈 캔버스 문제\"를 해결 - 즉, 처음부터 아이디어를 시작 - 하고자 한다. ㆍ게임 개발자는 디자이너가 만든 레벨들에 대한 평가를 개선하기 위해, 보다 인간들처럼 플레이하는 봇들을 원 한다. 게임 개발 플랫폼의 사용 ㆍ하나의 단일 게임 봇에 의한 자동화된 플레이 테스팅에 의해, 이 속도는 1주일마다 30개의 완성 레벨들 로 증가될 수 있다. 레벨 평가는 거의 즉각적이므로, 디자이너들은 아이디어들 신선할 때 반복하도록 할 수 있 다. 사례#3"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "배경기술 ㆍ게임 개발자는 PC, Mac 및 PlayStation 4용 다중 플랫폼 내러티브 게임을 구현하는 게임 애플리케이션을 개발하고 있다. ㆍ이 게임은 전체 플레이스루를 위해 약 8시간 분량의 게임플레이로 구성된 매우 복잡한 분기형 내러티브이다. 요구 사항들 ㆍ게임의 요소들은 매우 상호 의존적이다. ㆍ스토리의 초반부를 변경하면 스토리의 후반부에 영향을 미치고 게임을 완료하는 것이 불가능해질 수 있다. ㆍ개발 후반에 식별된 요구 사항들을 해결하거나 버그들을 수정하기 위해 코드를 변경하면 게임의 초반부에서 기능이 중단될 수 있다. ㆍ팀 규모는 제한되어 있으며, 팀에 정규직 품질 보증 담당자가 없다. ㆍ프로그래머가 아닌 팀원들에 의해 버그들이 발견되면, 게임을 테스트하거나 그들이 이를 만드는 동안 콘텐트 를 경험할 수 없기 때문에, 결과적으로 작업이 종종 중단된다. ㆍ이는 창의적인 흐름을 중단시키고 스토리 아이디어를 반복하는 시간을 크게 늘린다. ㆍ프로그래머들에게 긴급한 버그 수정을 요청하는 것은 프로그래머의 작업 흐름을 깨뜨리는 경향이 있으며, 따 라서 연쇄적 비용 효과를 가져온다. ㆍ변경 사항들에 대한 응답으로 전체 게임을 테스트하려면 최소 8시간의 정규 작업과 함께, 로깅, 사례 생성 및 파생 태스크들이 필요하다. ㆍ게임 개발자는 게임의 스토리 콘텐트를 탐색 시 실패 지점들을 자동으로 식별하는 솔루션이 필요하다. 게임 개발 플랫폼의 사용 ㆍ게임 봇들은 게임의 스토리를 자동으로 진행하여, 게임 개발자가 게임이 충돌하거나 플레이어가 멈출 때 를 식별할 수 있도록 한다. ㆍ시스템은 다음의 두 가지 방식들로 동작한다: 1. 플레이어 모방을 통해, 게임 봇들은 이전 플레이어 동작을 시뮬레이션하여 게임 코드 또는 콘텐트의 변 경에 따라 이전 데모가 여전히 가능한지 검증한다. 2. 게임 봇들은 자동으로 게임을 검색하고, 스토리 라인을 따라가며, 충돌 상황 및/또는 막다른 길을 찾는 다. ㆍ게임 개발 플랫폼의 이러한 구현에는 다음의 세 가지 이점이 있다: 1. 게임 개발 플랫폼은 변경 사항들에 따라 게임이 작동하는지 지속적으로 확인할 수 있다. 2. 게임 개발 플랫폼은 게임이 완료 가능한지를 지속적으로 확인할 수 있다. 3. 게임 개발 플랫폼은 게임을 무기한 플레이할 수 있어, 입력 없이 단순히 게임을 실행하는 것보다 인간 상호작용을 시뮬레이션하고 보다 현실적인 사용 사례를 제공하는 스트레스 테스트를 가능하게 한다. ㆍ게임 개발 플랫폼은 대략 한 명의 QA 직원의 노력을 대체한다. ㆍ약 10명의 개인들로 구성된 팀의 경우, 이는 초기 구현 후 예산 측면에서 약 7% 절감에 해당한다. ㆍ추가로, 게임 개발 플랫폼은 최종 게임 성능에 긍정적인 영향을 미칠 수 있는 더 높은 품질의 콘텐트로 이어지는 창의적 효율성의 개선을 제공한다. 사례#4"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "배경기술 ㆍ게임 개발자가 무한 러너 게임을 구현했다. 요구 사항들 ㆍ플레이어 기반이 매우 넓을 경우 플레이어들 알기가 어렵다. ㆍ플레이어의 약 5%만이 게임을 완료한다. ㆍ게임 디자이너의 목표는 대부분의 플레이어들이 게임을 완료하도록 하는 것이다. 게임 개발 플랫폼의 사용 ㆍBEA 툴의 사용은 게임 완료 및 플레이어 유지를 개선하는 것을 돕기 위해 게임을 적응시키는 데 사용되 는 플레이어 동기부여를 포함하는 실시간 플레이어 경험을 결정할 수 있다. 도 3a는 본 개시의 일 실시예에 따른 게임 개발 파이프라인의 흐름/블록도 표현을 나타낸다. 이 게임 개발 파이프라인은 도 1 및 도 2의 게임 개발 플랫폼과 함께 동작하며, 그에 설명된 기능들 및 특징들 중 하나 이상을 사용한다. 특히, 게임 개발 파이프라인은 게임 개발이 단계에서 게임의 초기 생성으로부터 예 를 들어, 알파 테스트, 베타 테스트 및/또는 소프트 런칭을 통해 일시적으로 진행되고, 단계에서 하드 런 칭을 위한 개선된 게임의 생성으로 이어지는 곳에서 제시된다. 단계에서, 게임 애플리케이션의 초기 버전과 같은 게임이 생성된다. 다양한 실시예들에서, 게임의 초 기 버전은 게임 개발 애플리케이션을 사용하여 게임 개발자에 의해, 처음부터 또는 예를 들어 게임 개발자 또는 기타 사용자에 의해 개발된 게임의 이전 버전 또는 이전 게임에 기초하여 PCG 툴에 의해 생성된 초기 게임 콘텐트로부터 개발된다. 단계에서, 게임은 예를 들어, 이전 게임들 또는 게임 개발자에 의해 개발된 게임의 이전 버전들에 대한 테 스트 및 평가로부터 개발되고 훈련된, 비-모방의 게임 봇들을 사용하여 테스트된다. 다양한 실시예들에서, 게임 봇들은 예를 들어, 소스, 이전 사용, 플레이어 스타일, 스킬 레벨, 대응하는 플레이어 동기부여 및/ 또는 각 게임 봇의 기타 특성들을 나타내는 설명 메타데이터와 함께 비모방 게임 봇들의 라이브러리를 포함한다. 게임 개발자는 이 테스트에 사용되는 하나 이상의 기존 게임 봇들을 선택하고 평가할 수 있다. 게임 봇들 중 하나 이상이 선택되면, 예를 들어, 막다른 길을 식별하고, 게임의 균형을 맞추기 시작하고, 플레 이 가능성을 높이는 등을 수행하도록 게임이 테스트 및 개선될 수 있다. 단계에서, 모방 게임 봇들은 하드 런칭 전에 테스트에 사용되는 내부 또는 외부 플레이어들과 같은, 실제 플레이어들로부터의 게임 원격측정 데이터를 기반으로 생성된다. 다양한 실시예들에서, 게임 원격측정 데 이터는 예를 들어, 픽셀 데이터 및 오디오 데이터를 포함하는 게임 오디오 및 비디오 출력, 플레이어 입력, 게 임 상태, 게임 이벤트, 게임 업적, 게임 목표를 향한 진행 상황, 게임 파라미터들, KPI들, 게임 완료 데이터, 게임플레이 데이터, 게임 진행 데이터, 상기 및 기타 게임 원격측정 데이터와 게임 분석 중 임의의 것으로부터 도출된 플레이어 스타일을 포함할 수 있는 플레이 트레이스들로부터 수집된 데이터를 포함할 수 있다. 다양한 실시예들에서, 게임 봇들은 게임 원격측정 데이터 및/또는 실제 플레이어들/시청자들로부터의 다른 데이터를 통해 훈련되는 기계 학습 알고리즘을 통해 동작한다. 이러한 기계 학습 알고리즘의 예들은 인공 신경 망(또는 더 간단히 본원에서 사용되는 \"신경망\"), 지원 벡터 머신(SVM), 베이지안 네트워크, 유전 알고리즘 및/또는 비지도(unsupervised), 반-지도(semi-(supervised), 지도(supervised) 및/또는 강화 학습을 통해 훈련되 는 기타 기계 학습 기술들을 포함하며, 피쳐 학습, 희소 사전 학습, 이상 검출, 결정 트리, 연관 규칙 및/또는 기타 프로세스들을 더 포함할 수 있다. 단계에서, 게임은 예를 들어, 게임 봇들에 의한 게임 플레이에 의해 생성된 KPI들 및 기타 게임 분석 들을 포함하는 게임 원격측정 데이터와 같은, 출력을 모니터링함으로써 더 테스트되고 개선된다. 이 방식으로, 다양한 버전의 게임이 테스트, 평가 및 개선되어, 예를 들어, 막다른 길 식별을 식별하고, 게임의 균형을 더 맞 추고, 플레이 가능성을 더 향상시키고, 예측된 플레이어 유지, 참여, 동기부여 및 기타 경험을 최적화하는 등을 수행할 수 있다. 단계에서, BEA 데이터는, 예를 들어, KPI, 게임 이벤트, 플레이어 행동, 게임 상태, 게임 성과, 게임 목표 를 향한 진행 상황, 게임 파라미터 및 게임 분석과 상관될 수 있는 다양한 플레이어 동기부여 요인들을 포함하 는 플레이어 설문지 또는 기타 경험 메트릭드로부터 수집된다. 플레이어 동기부여 요인들은 역량, 자율성, 관련 성, 존재감과 같은 광범위한 동기부여 요인들일 수 있다. 추가로 또는 대안으로, 플레이어 동기부여 요인들 및/ 또는 행동들은 경쟁, 완료, 환상, 파괴, 발견, 전략, 흥분, 파워를 포함하고, 높은 스코어 달성, 지속적으로 도 전, 일부 다른 빈도로 도전, 게임 목표 및 업적 달성, 레벨 완료, 휴식, 탐색, 지루함 방지, 다른 플레이어를 이기거나 다른 플레이어 게임 스포일링, 부정 행위, 부정 행위를 하는 다른 플레이어들을 방지, 부정 행위를 하 는 다른 플레이어들을 스포일링, 기타 플레이 스타일 등과 같은 보다 구체적인 동기부여를 포함하여, 게임과 관 련될 수 있다. 단계에서, BEA 데이터는 하나 이상의 BEA 툴들을 훈련하는 데 사용된다. 앞서 논의된 바와 같이, BEA 툴 은 실제 플레이어 동기부여를 학습하고 예측하기 위해 BEA 데이터 및/또는 게임 원격측정 데이터에 기초하 여 훈련되는 선호도 학습 또는 다른 서수적 기계 학습 기술들을 통해 구성될 수 있다. 단계에서, 플레이어 동기부여 또는 다른 경험들과 같은 플레이어 경험들은 실제 플레이어들 및/또는 모방 또는 비-모방 게임 봇들으로부터의 게임 원격측정 데이터에 기초하여 BEA 툴들을 통해 자동으로 실시간으 로 예측될 수 있다. 이 플레이어 경험 데이터는, 예를 들어, 게임 성능을 향상, 게임에 대한 플레이어 만족도를 예측, 예상 플레이어 보유를 증가 및/또는 예상 수익 창출을 증가시킴으로써, 단계에서 게임 봇 테스트와 함께 사용되어 하드 런칭을 위해 단계에서 게임을 더 개선할 수 있다. 게임 개발 파이프라인이 하드 런칭을 위한 개선된 게임에 대한 게임의 초기 버전의 적응, 테스트, 분석 및 개선에 대응하는 것으로 설명되었지만, 게임 개발 파이프라인의 하나 이상의 단계들은 또한 마찬가지로 게 임 애플리케이션에 대한 새로운 버전, 업데이트 및/또는 새로운 콘텐트 추가를 처리하는 데 사용될 수 있 다. 더욱이, 게임 개발 파이프라인은 BEA 데이터를 수집하는 단계 및 BEA 데이터에 기초하여 BEA 툴 을 생성하는 단계를 포함하는 것으로 설명되었지만, 게임 개발 플랫폼이 게임 에 대한 유 사한 게임, 새로운 버전, 업데이트 및/또는 새로운 콘텐트 추가를 처리하는 데 사용되는 상황에서, 게임의 이전 버전으로부터 또는 유사한 게임으로부터 생성된 하나 이상의 BEA 툴들이 재사용을 위해 선택될 수 있다. 예를 들어, BEA 툴은 예를 들어, 소스, 이전 사용 및/또는 각 BEA 툴의 다른 특성들을 나타내는 설명 메타 데이터와 함께 BEA 툴의 라이브러리를 포함한다. 게임 개발자는 외부 플레이어들로부터의 게임 원격측정 데이터 에 기초하여 동기부여 및/또는 행동 및 기타 경험들을 포함하는 플레이어 경험들을 예측하기 위해 단계에 서 사용되는 하나 이상의 기존 BEA 툴들을 선택하고 평가할 수 있다. 추가로, 생성적이고 일반적인 플레이어 경험의 계산 모델들(예를 들어, \"일반 경험 페르소나\")을 얻기 위해 다 음 추가 예를 고려한다. 페르소나는 그들이 인간 경험 데모로 제공되는 플레이어들의 경험을 시뮬레이션할 수 있기 때문에 생성적이다. 이 프로세스는 또한 인간 경험의 디지털화 및 시뮬레이션을 포함하는 특정 도메인의 다양한 인스턴스화 전반에 걸쳐 일반적이다. 일반적인 경험 페르소나를 얻기 위해, 게임 개발 플랫폼은 다음과 같은 계산 모델의 3가지 측면에 대한 혁 신을 융합할 수 있다: 모델의 입력, 계산 및 모델의 출력. 이 접근 방식은 인간이 비교(상대적) 방식으로 값들 을 인코딩하는 심리학의 고정 방법을 기반으로 할 수 있다. 혁신적인 서수적 모델링 접근 방식을 기반으로, 페 르소나는 일반화 가능한 특징들을 통해 인간(또는 데모)을 인식하고 이들이 점차적으로 인간이 하는 것처럼 환 경을 경험하도록 기계 학습한다. 게임 개발 플랫폼은 신뢰할 수 있고 유효한 방식으로 경험을 계산적으로 측정하기 위해 심리 측정 및 인간 심리의 근본적인 문제를 전반적으로 해결한다. 또한 인간 컴퓨터 상호 작용 및 플레이어 경험 연구의 핵심질문, 즉 인간이 이를 느끼는 것과 동일한 방식으로 시뮬레이션된 세계에서 경험을 시뮬레이션하는 방법을 다룬 다. 마지막으로, 기계 학습과 감정 컴퓨팅의 교차점에서 전통적인 문제, 즉, 주관적인 성격의 적은 데이터를 최 대한 활용하여 AI 모델 생성 속도를 개선하여, 복잡성을 줄이며 정확도를 향상시키는 방법을 해결한다. 도 3b는 본 개시의 일 실시예에 따른 일반 경험 페르소나의 구성요소의 흐름/블록도 표현을 나타낸다. 특 히, 방법은 도 1, 2 및 3a와 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 이 프로세스 는 입력(설명자 맵), 계산 자체(생성 모델) 및 출력(데모)의 세 가지 핵심 서브 프로세스들에 걸쳐 혁신을 결합 하여 플레이어 경험의 생성적 모델링(예를 들어, 동기부여 및/또는 행동 포함)에 대한 안정적이고 효과적인 솔 루션을 제공한다. 단계 - 경험 데모: 페르소나의 출력을 처리하기 위해 제안된 접근 방식은 전통적인 심리 측정의 모든 주석 유형을 지원할 수 있으므로 일반적이다. 예를 들어, 경험 레이블이 수집되고 처리되는 방식에서, 이전 접근 방 식과 다를 수 있다. 특히, 인간의 경험 데모는 상호 작용으로부터 추출된 참여 메트릭들을 통해 지속적인 방식 으로 수집될 수 있다. 이는 시청자에 의해 비디오(예를 들어, 게임플레이 비디오)의 수동적으로 관찰에서부터 모든 상호작용(예를 들어, 게임)의 능동적 주석에 이르기까지 전부 스펙트럼을 포함한다. 경험 레이블은 서수적 및 무제한 방식으로 처리되므로, 가치에 구애받지 않는 일반 경험 모델을 구성할 수 있다. 1차 및 2차 조합 기 술들을 따름으로써, 유효하고 신뢰할 수 있는 인간의 경험 데모를 얻을 수 있을 뿐만 아니라 제한된 데이터로부 터 대규모 데이터 세트도 생성한다. 모든 유형의 설문지 - 인간 컴퓨터 상호 작용 내에서 지배적인 관행 상태 - 는 더 이상 필요하지 않으며(설문지 데이터가 여전히 처리될 수 있음에도 불구하고), 인간의 참여는 현실적인 소규모 플레이어 그룹 크기로만 제한된다. 단계 - 경험 생성적 모델: 경험 페르소나는 인간의 경험을 예측하는 법을 배우거나 인간이 하는 것처럼 경 험을 표현할 수도 있다. 전자의 경우, 게임 개발 플랫폼은 레이블이 지정된 경험의 전체 또는 부분적 순서를 예 측하는 방법을 배우는 딥(선호도) 러닝 방법들을 포함한다. 후자의 경우, (상기와 같은) 인간 데모의 순서는 강 화 학습 접근법(예를 들어, 신경 진화)이 추론하는 방법을 배울 유틸리티를 정의한다. 그 결과는 인간 플레이어 가 하는 것처럼 시뮬레이션된 환경에서 \"느낄\" 수 있는 경험의 생성적 모델이다. 단계 - 경험 디스크립터 맵: 경험은 상호 작용이 수행되고 경험 레이블링에 의해 제한되는 방식으로 인식 된다. 인식 모델은 모델에 의미가 있는 레이블이 지정된 경험 영역에 초점을 맞추며, 경험과 관련하여 변화가 관찰되거나 보고되지 않는 영역들을 제거한다. 경험의 표현은 상호작용의 일반적인 측면들, 즉 일반적인 경험 디스크립터 맵들을 관찰함으로써 학습된다. 맵들의 디자인은 높은 레벨의 행동 특성화에서 상호 작용의 순차적 패턴에 이르기까지, 경험의 레이블에 매핑되는 상세한 잠재 변수들에 이르기까지 다양할 수 있다. 후자는 가능 한 경우 직접 상호 작용의 시뮬레이션을 통해 구성되거나, 상호 작용을 생성하는 코드에 액세스할 수 없는 경우 상호 작용의 기계 학습된 순방향 모델을 통해 간접적으로 구성된다. 단순한 게임 개발 외에도, 게임 개발 플랫폼의 BEA 툴은 최종 게임 자체에 통합될 수 있다. 이러한 방식으로, 개별 플레이어들은 동기부여 및/또는 행동 측면에서 평가될 수 있다. 다양한 실시예들에서, 특정 게 임 버전 또는 게임 파라미터 설정은 예를 들어, 특정 플레이어에 대한 경험을 향상시키기 위해 개별 플레이어와 상응하도록 예측된 행동들 및/또는 특정 동기부여를 보완하거나 아니면 일치시키기 위해 개별 플레이어에 대한 가능한 게임 버전/설정의 라이브러리로부터 선택될 수 있다. 이 방식으로, 도전을 좋아하는 플레이어에게는 도 전을 받을 수 있고, 완료를 좋아하는 플레이어에게는 완료하기 쉬운 게임이 제공될 수 있다. 또한, 게임 개발 플랫폼의 BEA 툴은 각자의 동기부여 및/또는 행동에 기초하여 멀티플레이어 게임에 서 플레이어들을 페어링하는 데 사용될 수 있다. 예를 들어, BEA 툴에 의한 결정에 기초하여 스포일러를 플레이 하는 것을 좋아하는 우수 플레이어는 정기적으로 그 또는 그녀를 경험이 부족한 플레이어들과 짝을 지어 스포일 링함으로써 유지될 수 있다. 다른 예에서, BEA 툴로 부정행위를 하기로 결정한 플레이어는 이러한 다른 플레이 어들 또는 부정행위 중립을 속이는 플레이어들과 짝을 이룰 수 있으며, 부정 행위를 하는 상대 플레이어들에 의 해 의욕이 저하되는 것으로 판단되는 다른 플레이어들을 방지할 수 있다. 게임용 BEA 데이터 생성과 관련하여 상기에 설명되었지만, 상기에 설명된 기술들은 다른 산업에도 적용될 수 있 다. 사람들의 경험을 모델링 및 생성 둘 다 할 수 있다는 것은 인간 행동과 경험을 포함하는 모든 연구 영역 또 는 산업 분야에서 사용될 수 있다. 프로세스의 잠재적 애플리케이션 목록은 방대하며, 창조 산업, 마케팅, 소매, 웹 서비스, 아키텍쳐 및 건축 환경, 사이버 물리적 시스템, 자동차 산업 및 디지털 예술과 같은 분야들을 포함한다. 생성적 및 일반적 경험 페르소나는 뿐만 아니라 서비스들을 더 빠르고 보다 효율적으로 테스트, 개발 및 제공할 수 있는 능력을 활용한다. 또한 아이디어 구상부터 프로토타이핑, 생산 및 서비스, 프로젝트 또는 인간과 상호 작용할 개체의 출시에 이르기까지 더 나은 (페르소나 중심의) 결정을 내릴 수 있다. 도 4는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1-2, 3a 및 3b와 관련하 여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 단계에서, 이전에 설명된 임의의 게임 봇 들과 같은 게임 봇에 대응하는 게임 봇 모델이 생성된다. 단계는 게임 애플리케이션과 같은 게임 애플리케이션(앱)으로부터 게임 출력을 수신하는 것을 포함한 다. 단계는 게임 봇 모델을 통해 게임 앱에 게임 입력을 생성하는 단계를 포함하며, 여기서 게임 입력은 하나 이상의 시뮬레이션된 플레이어들에 의한 게임 플레이에 대응한다. 단계는 시뮬레이션된 플레이어에 의한 게임 플레이에 응답하여 게임 성능 데이터를 생성하는 단계를 포함한다. 이 게임 성능 데이터는 게임 콘텐 트를 보다 빠르게 평가하고; 다양한 플레이스루를 통해 무작위로 레벨의 난이도를 평가하는 데 사용될 수 있으 며; 핵심 성능 지표(KPI) 또는 기타 게임 분석을 포함할 수 있다. 도 5는 본 개시의 일 실시예에 따른 게임 원격측정 데이터의 그래픽 표현들(500 및 510)을 나타낸다. 다양한 실 시예들에서, 게임 봇은, 게임 원격측정 데이터를 기반으로, 마스터 플레이어 또는 다른 인간 플레이어와 같은 실제 플레이어를 모방하도록 훈련된 인공 신경망을 포함한다. 게임 원격측정 데이터는 실제 플레이어 및 게임 봇에 대응하는 픽셀 데이터를 포함하는 비디오 데이터의 프레임들을 포함할 수 있다. 도시된 특정 예에서, 실제 게임 출력 형태의 게임 원격측정 데이터는 시간(t1)의 다이어그램과 시간(t2)의 다이어그램에 표시된 다. 게임 원격측정 데이터는 게임 봇, 다른 AI 페르소나 또는 기타 AI와 같은 게임 봇 모델에 의해 생성되 는 캐릭터를 포함한다. 게임 원격측정 데이터는 또한 마스터 플레이어, 일반적인 플레이어 또는 게임 봇 모델이 모방하거나 시뮬레이션하려고 하는 다른 플레이어와 같은 실제 플레이어에 의해 생성되는 캐릭터를 포함한다. 게임 개발 애플리케이션은 캐릭터의 위치와 캐릭터의 위치 사이의 시간에 따른 차이를 나타내는 차이 데이터를 생성한다. 예를 들어, 시간에 따른 차이는 복수의 시간 동안 실제 플레이어에 의해 생성된 제1 캐릭터와 게임 봇에 의해 생성된 제2 캐릭터 사이의 픽셀 거리를 나타낸다. 게임 원격측정 데이터에 표시 된 예에서, 시간(t1)에서의 차이인, d(t1)는 캐릭터들(502 및 504)의 중심 사이의 유클리드 거리로 측정된다. 게 임 원격측정 데이터에 도시된 예에서, 시간(t2)에서의 차이인, d(t2)는 캐릭터들(502 및 504)의 중심 사이 의 유클리드 거리로 측정된다. 예를 들어, 마스터 플레이어가 레벨을 완료하는 데 걸린 시간 길이, 마스터 플레 이어들이 트레이스를 플레이하는 샘플의 시간 길이 또는 일부 기타 시간 간격에 대응하는 시간 간격(t0 - tn)을 고려하면, 차이 데이터는 i = 0, n에 대한 d(ti) 값들을 적분하거나 합산하여 생성될 수 있다. 이러한 방식으로 생성된 차이 데이터는 게임 봇을 업데이트하여 마스터 플레이어를 보다 밀접하게 모방하기 위 한 적합성 척도로 사용될 수 있다. 다양한 실시예들에서, 게임 봇은 게임 원격측정 데이터를 기반으로 실제 플 레이어를 모방하도록 훈련된 인공 신경망을 포함한다. 예를 들어, 게임 봇은 인간 마스터 플레이어를 \"섀 도우\"하는 방법을 배우는 강화 학습을 사용할 수 있으며, 동시에 또한 환경으로부터 보이지 않는 새로운 조건들 에 대처하는 방법을 배울 수 있다. 게임 봇을 업데이트하는 것은 조정된 게임 봇 구성들에 대한 강화 학습 을 통해 게임 봇을 반복적으로 재훈련시키는 것, 조정된 게임 봇 구성들에 대응하는 업데이트된 차이 데이터를 반복적으로 생성하는 것, 및 대응하는 업데이트된 차이 데이터가 예를 들어 시뮬레이션된 플레이어와 실제 플레 이어 간의 허용 가능한 일치를 나타내는 차이 임계값과 비교될 때 조정된 게임 봇 구성들 중 하나를 수락하는 것을 포함할 수 있다. 게임 봇을 업데이트하는 것은 또한 게임 봇을 게임 봇의 파라미터들에 대한 검색 알 고리즘을 통해 조정된 게임 봇 구성들로 반복적으로 조정하는 것, 조정된 게임 봇 구성들에 대응하는 업데이트 된 차이 데이터를 반복적으로 생성하는 것, 및 대응하는 업데이트된 차이 데이터가 예를 들어, 수락 가능하거나 원하는 적합성을 나타내는 차이 임계값과 유리하게 비교될 때 조정된 게임 봇 구성들 중 하나를 수락하는 것을 포함할 수 있다. 마스터에서 섀도우까지의 거리 측정은 인간 행동을 복제하는 것과 얼마나 가까운지를 이해하는 데 사용된다. 값 d(ti)는 선형 거리 측정, 대수 거리 측정 또는 일부 다른 비선형 함수에 의해 변환된 거리 측정일 수 있다. 더 욱이, 상기에 유클리드 거리로 설명되어 있지만, 비-유클리드 거리, 비-파라메틱 거리 순위 및 기타 단조 측정 을 포함하는 다른 거리들도 마찬가지로 사용될 수 있다. 상기에 누적 거리 측정의 관점에서 설명되어 있지만, 차이 데이터는 시간 기간(t0 - tn) 동안 게임 봇과 인간 플 레이어 사이의 누적된 게임 스코어의 차이, 시간 기간(t0 - tn) 동안 게임 봇과 인간 플레이어 간 게임 성과의차이, 시간 기간(t0 - tn) 동안 게임 봇과 인간 플레이어 간의 게임 목표에 도달하는 시간 차이, 게임 봇과 인간 플레이어 간 다른 게임 메트릭 또는 기타 게임 분석의 차이 및/또는 이들의 조합과 같은 거리 외에 또는 거리에 대한 대안으로서 하나 이상의 다른 측정들을 포함할 수 있다. 도 6은 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1-2, 3a, 3b, 4 및 5와 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 단계는 게임 봇을 생성하는 단계를 포함한다. 단계는 실제 플레이어에 대응하는 게임 앱으로부터 게임 원격측정 데이터를 수신하는 단계를 포 함한다. 단계는 게임 봇에 대응하는 게임 앱으로부터 게임 원격 측정 데이터를 생성하는 단계를 포함한다."}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "단계는 실제 플레이어에 대응하는 게임 원격측정 데이터 및 실제 플레이어에 의해 생성된 제1 캐릭터와 게 임 봇에 의해 생성된 제2 캐릭터 사이의 시간 경과에 따른 거리를 나타내는 게임 봇에 대응하는 게임 데이터에 기초하여 생성된 차이 데이터에 기초하여 게임 봇을 업데이트하는 단계를 포함한다. 다양한 실시예들에서, 시간에 따른 차이는 복수의 시간 동안 실제 플레이어에 의해 생성된 제1 캐릭터와 복수의 게임 봇에 의해 생성된 제2 캐릭터 사이의 거리를 나타낸다. 거리는 유클리드 거리일 수 있다. 시간에 따른 차 이는 복수의 시간들 각각 동안 실제 플레이어에 의해 생성된 제1 캐릭터와 게임 봇에 의해 생성된 제2 캐릭터 사이의 거리의 누적을 나타낼 수 있다. 다양한 실시예들에서, 시간에 따른 차이는, 시간 기간의 복수의 시간 동안 실제 플레이어에 의해 생성된 제1 캐 릭터와 게임 봇에 의해 생성된 제2 캐릭터 사이의 거리, 시간 기간 동안 게임 봇과 인간 플레이어 사이의 누적 된 게임 스코어의 차이, 시간 기간 동안 게임 봇과 인간 플레이어 사이의 게임 성과의 차이, 또는 시간 기간 동 안 게임 봇과 인간 플레이어 사이의 게임 목표에 도달하는 시간 차이 중 하나 이상을 나타낸다. 다양한 실시예들에서, 게임 봇은 게임 원격측정 데이터를 기반으로 실제 플레이어를 모방하도록 훈련된 인공 신 경망을 포함한다. 게임 원격측정 데이터는 실제 플레이어 및 게임 봇에 대응하는 픽셀 데이터를 포함할 수 있으 며, 시간에 따른 차이는 복수의 시간 동안 실제 플레이어에 의해 생성된 제1 캐릭터와 게임 봇에 의해 생성된 제2 캐릭터 사이의 픽셀 거리를 나타낸다. 단계는 게임 봇을 조정된 게임 봇 구성들로 반복적으로 조정하 는 단계, 조정된 게임 봇 구성들에 대응하는 업데이트된 차이 데이터를 반복적으로 생성하는 단계, 및 대응하는 업데이트된 차이 데이터가 차이 임계값과 유리하게 비교될 때 조정된 게임 봇 구성들 중 하나를 수락하는 단계 를 포함할 수 있다. 도 7은 볼 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1, 2, 3a, 3b 및 4-6과 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 단계는 선호 학습 모델을 기반으로 행동 경험 분석(BEA) 툴을 생성하는 단계를 포함한다. 단계는 사용자와 관련된 게임 앱으로부터 게임 원격 측정 데이터를 수신하는 단계를 포함한다. 단계는 BEA 툴을 게임 원격측정 데이터에 적용함으로써, 예측된 사용자 동기부여를 생성하는 단계를 포함한다. 단계는 예측된 사용자 동기부여에 기초하여 게임을 적응시 키는 단계를 포함한다. 다양한 실시예들에서, 선호 학습 모델은 이전 게임 플레이와 연관된 복수의 플레이어 설문지들에 기초하고 이전 게임 플레이와 연관된 이전 게임 원격측정 데이터에 더 기초하여 훈련된다. 선호 학습 모델은 복수의 플레이어 설문지들로부터 조합적으로 생성된 2차 데이터를 사용하여 훈련될 수 있다. 선호 학습 모델은 서포트 벡터 머신 들을 통해 구현될 수 있다. SVM들은 방사형 기저 함수 커널이 있는 비선형 SVM들을 포함할 수 있다. 다양한 실시예들에서, 게임 원격측정 데이터는, 플레이시간 데이터, 완료 데이터 또는 진행 데이터 중 적어도 하나를 포함한다. 게임 원격측정 데이터는 다른 게임 원격측정 데이터에 대한 클러스터링 분석을 통해 생성된 복수의 플레이어 유형들 중 하나의 표시를 포함할 수 있다. 게임 원격측정 데이터는 게임 봇에 기초하여 생성될 수 있다. 게임 원격측정 데이터는 게임 비디오와 연관된 픽셀 데이터를 포함할 수 있다. 다양한 실시예들에서, 시스템은 게임 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현될 수 있 으며, 게임 애플리케이션의 적응을 용이하게 하는 것은 게임 개발 애플리케이션을 통해 게임 애플리케이션의 적 응을 용이하게 하는 것을 포함한다. 게임 애플리케이션은 복수의 옵션 버전들을 포함할 수 있으며, 시스템은 게 임 애플리케이션을 실행하는 게임 시스템을 통해 구현되고, 게임 애플리케이션의 적응을 용이하게 하는 것은 예 측된 사용자 동기부여에 기초하여 복수의 옵션 버전들 중 하나를 선택하는 것을 포함한다. 다양한 실시예들에서, 게임 애플리케이션의 적응을 용이하게 하는 것은 플레이어 불일치를 식별하는 것을 포함 한다. 예측된 사용자 동기부여는 복수의 동기부여 요인들 각각에 대한 스코어를 나타내는 동기부여 데이터를 포 함할 수 있다. 예측된 사용자 동기부여는 예측된 플레이어 동기부여의 변화들을 나타내는 시간에 따라 수집된 동기부여 데이터를 포함할 수 있다. 본원에 제시된 방법들은 게임 원격측정 데이터를 기반으로, 플레이어 동기부여를 자동으로 정확하게 예측하여 게임 개발 기술을 향상시킨다. 예를 들어, BEA 툴은 게임 애플리케이션의 각 반복/버전에 대한 예측된 사 용자 동기부여를 제시할 수 있으며, 미리 결정된 원하는 사용자 동기부여와 일치하는 예측된 사용자 동기부여를 갖는 게임의 적응 버전을 달성하기 위해 게임 개발 플랫폼의 사용자에 의한 게임의 반복적 적응을 용이하 게 한다. 더욱이, 게임 애플리케이션들은 예를 들어, 개별 플레이어의 예측된 사용자 동기부여에 적응하는 - 게 임에서 개별 플레이어의 경험을 향상시키는 - 여러 버전들로 생성될 수 있다. 예를 들어, 동일한 동기부여들을 일치시키고, 호환 가능한 동기부여들을 일치시키고 및/또는 플레이어들을 위한 매력적인 경험들을 생성하기 위 해 혼환 가능하지 않는 동기부여를 피하기 위해 예측된 사용자 동기부여를 기반으로 플레이어들을 일치시키고/ 시키거나 플레이어 불일치를 방지할 수 있다. 스스로 동기를 부여하여 게임에 복귀하고, 계속 플레이하는 플레 이어들은 게임의 성공을 높일 수 있다. 게임 디자인과 게임이 이끌어내는 경험들에 대한 동기부여의 중심 역할은 게임 내 동기부여에 대한 심리학적 이 론을 채택한 많은 연구들에 의해 강조되었다. 그러나, 이러한 연구들은 정성적 원칙들에 기초하여 고정 관념적 인 플레이어 행동을 식별하고 설명하는 것을 목표로 하는, 동기부여의 현상학적 모델의 하향식 통합을 따른다. 그에 반해, 게임 사용자 연구 및 산업 기반 게임 테스트는 플레이어 행동 및 경험에 대한 이해를 더 많이 밝히 기 위해 플레이어 분석을 기반으로 하는 정량적 접근 방식들로 그 초점을 옮겼다. 이러한 접근 방식들은 복수의 서로 다른 동기부여 요인들을 정량화하는 대신, 플레이어들의 행동 패턴을 기반으로 플레이어들을 클러스터링하 거나 수익화 목적(예를 들어, 이탈 예측)을 위해 플레이어들의 게임플레이 행동의 객관적으로 정의된 측면을 예 측하는 데 중점을 둔다. 이와 관련하여, 플레이어 분석을 기반으로 플레이어 경험(예컨대, 참여 또는 동기부 여)의 측면들을 포착하는 것을 목표로 하는 접근 방식들은 게임에서 사용자 경험의 주관적 개념을 측정하는 복 잡성을 감안할 때 질적으로 유지된다. 동기부여와 플레이 사이의 관계에 대한 정량적 연구들이 부족하다. 다음 예를 고려해보자. BEA 툴은, 예를 들어, 플레이어가 게임에서 행동적으로 수행하는 것 - 그/그녀의 게임플레이 데이터를 통해 나타난 바와 같음 - 과 그/그녀의 동기부여 사이에 알려지지 않은 기본 기능이 있다 고 가정하는 데이터 중심 플레이어 모델링 접근 방식을 사용할 수 있다. 특히, BEA 툴은 플레이어의 게임 플레이로부터의 행동 데이터만이 게임에서 동기부여의 정확한 예측자들을 산출할 것이라고 가정할 수 있다. 동 기부여는 자기 결정 이론(Self Determination Theory) - 동기부여를 위한 긍정적인 심리적 프레임워크 - 을 기 반으로 할 수 있으며, 4가지 핵심 동기부여 요인들인, 역량, 자율성, 관련성 및 존재감을 검사할 수 있으며, 이 는 종종 비디오 게임 영역의 이론과 관련된다. BEA 툴은 플레이어 동기부여를 관찰하는 게임별 툴로 개발된 UPEQ(Ubisoft Perceived Experience Questionnaire)와 같은 동기부여 측정 툴을 사용하여 훈련될 수 있다. 예를 들어, 플레이어 동기부여와 게임플 레이 간의 관계를 추론하기 위해, 데이터는 Tom Clancy's Division의 400명 이상의 플레이어들로부터 수집되었 다. 이 데이터는 가공 및 집계되며 게임과 관련하여 플레이어의 동기부여에 대한 설문 조사들이 독립적으로 수 집되었다. UPEQ 설문지는 게임에서 플레이어의 역량, 자율성, 관련성 및 존재감의 일반적인 레벨들을 측정하는 데 사용되었다. 보고된 개념의 주관적인 특성이 주어지면, BEA 툴은 2차 데이터 처리 접근 방식을 사용할 수 있으며, 플레이어들의 보고된 UPEQ 리커트 척도 값들을 스코어가 아닌 서수적 데이터로 처리할 수 있다. BEA 툴은 게임플레이와 보고된 동기부여 요인들 사이의 기능을 추론하기 위해 서포트 벡터 머신들(SVM들)을 기 반으로 하는 선호 학습 모델에 간단한 통계적 순위 기반 방법들을 적용할 수 있다. 결과들은 보고된 동기부여의 요인들이 몇 가지 높은 레벨의 게임 플레이 특징들에 따라 높은 정확도로 예측될 수 있음을 시사한다. 특히, BEA 툴의 비선형 기계 학습된 선호 학습 모델들은 보이지 않는 플레이어들의 4가지 동기부여 요인들을 적 어도 93% 정확도로 예측하며; 베스트 모델은 존재에 대해 97%의 정확도에 도달한다. 획득된 결과들은 주관적으 로 정의된 개념에 대한 서수적 데이터 처리의 이점들에 대한 기존 증거에 추가하며, 이들은 또한 동기부여가 플 레이에 대한 높은 레벨의 행동 데이터를 기반으로만 검사된 게임에서 정성적으로 최고의 정확도로 포착될 수 있 음을 검증한다. 본원에 설명된 동기부여 모델들은 몇 가지 기술적 개선 사항들을 보여준다. 첫째, 플레이어 동기부여는 게임의 게임플레이 데이터를 통해서만 계산적으로 모델링된다. BEA 툴이 훈련되면, 사용자/플레이어 동기부여는 게임 원격측정 데이터와 같은 게임플레이 데이터만을 기반으로 예측될 수 있다. 둘째, 2차 방법론은 게임 테스 트 및 게임 사용자 연구에서 자주 사용되는 리커트 척도 스코어를 처리하는 데 사용된다. 이 서수적 접근 방식은 모든 플레이어들의 주관적인 스코어들을 서로 비교하며, 따라서 작은 참가자 세트만을 기반으로 매우 큰 데 이터 세트를 조합적으로 생성한다. 접근 방식은 또한 응답자들의 리포팅 편향을 제거하는 데 효과적이어서, 보 고된 동기부여의 실제 사실에 더 잘 근접한다. 셋째, 플레이어 동기부여의 측면들은 소수의 주요 게임플레이 특 징들만을 기반으로 하는 선호 학습을 사용하여 모델링된다. 이러한 방법론들의 예들은 400명 이상의 플레이어들 에 대해 Tom Clancy's The Division(Ubisoft, 2016) 게임을 사용하여 평가되었으며, 이 게임에 대한 동기부여 모델의 예측 능력은 거의 확실(즉, 93% 이상의 정학도)하다. 다른 기술적 개선 사항들도 있을 수 있다. 자기 결정 이론(Self-determination theory; SDT)은 Deci와 Ryan의 연구에 기반한 동기부여 촉진의 긍정적 심 리학 이론이다. 핵심 이론은 동기부여 뒤에 있는 내적 및 외적 인과 소재의 이분법에 초점을 맞춤으로써, 단일 개념으로서의 동기부여의 초기 프레임워크들을 대조하기 위해 개발되었다. 후자는 외부 또는 내부 보상, 압력 및 기대에 의해 촉진되는 반면, 전자는 활동 자체의 본질적인 속성들, 즉 역량, 자율성 및 관련성의 세 가지 기 본 심리적 욕구들을 얼마나 잘 지원할 수 있는지에 기반한다. 비디오 게임은 외적 동기부여를 촉진할 수 있는 상당한 양의 압력과 보상을 포함하지만, 이들은 일반적으로 내적 동기부여의 좋은 촉진자로 간주된다. 게임플레 이 동안 동기부여의 단기적인 변화가 관찰되는 경우에도, 게임은 더 높은 레벨에서 내재적 동기부여를 촉진하기 위해 필요한 심리적 욕구들을 지원한다. 비디오 게임의 맥락에서, R. M. Ryan, C. S. Rigby 및 A. Przybylski 의, \"The motivational pull of video games: A self-determination theory approach\", Motivation and Emotion, vol. 30, no. 4, pp. 344-360, 2006은 내재적 동기부여의 기초가 되는 기본적인 심리적 욕구들을 다 음과 같이 설명한다: ㆍ플레이어들의 근위 및 원위 목표를 통해 나타나는, 역량 또는 성취감 및 행동의 숙달에 대한 열망. 이러한 욕 구는 일반적으로 자기 효능감 및 의미 있는 진행감과 관련이 있다. 이는 플레이어들이 게임을 완료하기 위해 마 스터해야 하는 상호 작용을 통해 지원되지만 그 자체가 완료되는 것은 아니다. ㆍ플레이어들이 취할 수 있는 의미 있는 선택, 전술 및 전략적 결정을 통해 나타나는, 자율성 또는 통제감 및 자기 결정적인 행동에 대한 열망. 이는 플레이 경험을 구성하지만 높은 수준의 자유도와 의미 있는 다른 결과들 을 허용하는 규칙 시스템과 다양한 게임 메커니즘들을 통해 지원된다. ㆍ다른 플레이어들 및 믿을 수 있는 컴퓨터 에이전트들과의 상호 작용들을 통해 나타나는, 관련성 또는 소속감 및 다른 사람들과 연결 및 상호 작용하려는 열망. 다층 상호 작용, 믿을 수 있고 풍부한 비-플레이어 캐릭터, 내러티브한 디자인 및 게임 외부의 다른 플레이어들과의 상호 작용도 지원된다. ㆍ중재 경험의 존재 또는 느낌은 역량과 자율성 둘 다의 주요 촉진자이며, 신체적, 정서적, 서사적 구성요소들 을 갖는 것으로 볼 수 있다. 실제로, 존재감이나 몰입의 추구는 게임플레이 동기부여의 원동력이 될 수 있다. STD와 존재 사이의 강력한 관계를 기반으로, 욕구 만족 설문지의 플레이어 경험과 UPEQ 둘 다 이를 사용하여 다 른 긍정적인 심리적 욕구들을 촉진시킬 수 있는 게임 참여 레벨을 측정한다. 위의 요소들이 내적 동기부여의 형성에 동등하게 기여하지 않지만; 역량 또는 관련성은 핵심 촉매로 간주되며, 자율성은 일반적으로 동기부여 촉진에 지원 역할을 한다는 점에 주목하는 것이 중요하다. 그럼에도 불구하고, 자율성의 부재 시, 동기부여는 내사적이거나 강박적인 것으로 간주될 수 있다. 게임 내에서, 내적 동기부여의 주요 원동력은 일반적으로 활동이 구조화되는 방법 때문에 역량이지만, 관련성은 경험을 향상시키는 데 기여한 다. BEA 툴은 상기에 언급된 동기부여의 4가지 측면들을 정량화하기 위해 SDT에 의존한다. 그 목적을 위해, UPEQ는 게임플레이 경험에 의해 영향을 받는 SDT의 요인들을 측정하도록 설계된 게임 맞춤형 설문지로 사 용된다. UPEQ는 특히 산업 디자이너들 및 이해 관계자들과 관련된 게임플레이 결과들을 예측하기 위해 Massive Entertainment의 연구원들이 개발했다. UPEQ는 SDT의 측정된 요소들을 기반으로 플레이시간, 게임에 사용된 금 액 및 그룹 플레이시간을 예측할 수 있다. UPEQ는 유틸리티 외에도, 게임 참여 설문지, BrainHex 및 플레이어의 욕구 충족 경험과 같은 이전 도메인별 SDT 설문지들의 한계를 해결하는 동시에, 기본 욕구 충족 척도(들)를 비 디오게임 플레이에 특정된 설문조사로의 적응시키는데 초점을 맞추고 있다. SDT에 대한 강력한 이론적 기반을 갖춘 안정적이고 일관된 평가 툴이 그 결과이다. 선호 학습(PL)은 알고리즘이 두 변수 간의 선호 관계를 추론하는 것을 학습하는 지도 기계 학습 기술이다. BEA 툴은 이러한 일반적인 기계 학습 패러다임과 게임에서 플레이어 경험이 작동하는 방식 사이의 강력한 연결 때문에 선호 학습(PL) 모델을 채택한다. 본질적으로, PL은 절대값 대신 발생 간의 차이에 초점을 맞춰 특정 심 리적 프로세스들을 모델링한다. 이 접근 방식은 내부적으로 자신의 경험을 평가하도록 이들을 돕는 플레이어의 인지 프로세스 - 예를 들어, 고정 편향, 적응, 습관화 및 기타 최근 효과 - 에 더 밀접하게 연계된다는 이점이 있다.PL은 절대값이나 클래스 한계 대신 상대적 연관성에 의존하는 강력한 방법이며, 대신 쿼리에서 특징 벡터들 간 의 차이들을 나타내는 원래 데이터 세트의 쌍별 변환을 기반으로 한다. 데이터 세트의 이러한 변환은 이진 분류 기가 이를 해결할 수 있는 방식으로 원래 문제를 다시 공식화한다. 새로운 데이터세트에서, 선호 관계의 방향은 두 클래스 중 하나와 연관될 수 있다. 일 예로서, 선호 관계를 관찰하기로 한다: (xi는 xj보다 선호됨) 관련 출력을 기반으로: yi > yj이다. 쌍별 변환을 통해 두 가지 새로운 특징들이 생성된다: xI = (xi - xj)이고, y'1 = 1 및 x'2 = (xj - xi)와 관련되고, y'2 = -1과 관련된다. 각 특징 벡터 쌍 간의 이러한 비교는, 을 제공한다. 새로운 데이터 포인트. xI는 명확한 선호 관계가 항상 추론 가능한 것은 아니기 때문에 가능한 모든 고유 조합 의 서브셋이다. BEA 툴은 이들이 LIBSVM 라이브러리를 기반으로 하는 선호 학습 툴박스1에서 구현되는 랭킹 서포트 벡터 머신들 (SVM들)을 사용할 수도 있다. SVM들은 제한된 양의 데이터 및 입력 특징들로도 강력한 모델을 생성할 수 있다. SVM들은 원래 더 높은 차원의 피쳐 공간에 투영된 데이터 포인트들을 분리하는 초평면의 마진을 최대화하여 분 류 작업들을 해결하는 데 사용되었지만 나중에 PL 작업들을 해결하는 데도 채택되었다. BEA 툴은 방사형 기저 함수(RBF) 커널들을 갖는 선형 및 비선형 SVM 둘 다를 사용할 수 있다. 데이터 포인트 간의 선형 분리를 목표로 하는 선형 SVM들과 달리, RBF SVM들은 데이터 포인트들의 로컬 근접성을 강조하여, 변환된 피쳐 공간에 최대 마진 초평면을 끼운다. 이러한 알고리즘을 조정하기 위해, BEA 툴은 훈련 세트의 마진 최대화와 분류 오차 최소화 사이의 트레이드 오프를 제어하는 C 정규화 항, 및 - RBF 커널의 경우 - 데이터 포인트 간 유사성 척도의 분산을 제한하여 비선형 토폴로지에서 데이터 포인트 간의 각 비교에 가중치를 부여하는 방법을 제어하 는 γ 하이퍼파라미터에 따라 달라질 수 있다. 이 예에서 분석된 데이터는 게임 내 행동 데이터(플레이어 메트릭) 및 Tom Clancy's The Division(Ubisoft, 2016)(이하, \"The Division\")의 플레이어들로부터의 설문 조사 응답들이다. The Division은 캐릭터 진행 시스템 과 3인칭 커버 기반 전술 슈팅 전투 메커니즘을 결합한 온라인 멀티플레이어 액션 롤 플레잉 게임이다. 이 게임 은 천연두 전염병이 강타한 종말 이후의 뉴욕으로 설정된다. 플레이어들은, 정부 요원으로서, 함께(그리고 서로 에 대해) 협력하여 전염병의 여파와 조직 범죄 활동의 부상으로 혼란에 빠진 도시를 청소하고 조사해야 한다. 이 게임의 핵심은 플레이어들이 새로운 능력을 잠금 해제하고, 무기와 갑옷을 포함한 새로운 장비를 얻기 위해 스토리 중심 및 선택적 미션들을 포함한 다양한 게임 내 활동들에 참여하여 새로운 레벨을 얻는 진행 시스템이 다. 플레이어의 힘은 레벨(최대 30)로 측정될 수 있으며, 장비의 품질은 기어 스코어(Gear Score) 포인트로 표 현된다. 게임의 플레이어 대 환경(PvE) 섹션에서, 플레이어들은 그룹을 만들고 함께 미션들을 완료할 수 있다. 게임은 또한 자체 진행 시스템이 있는 - 다크존이라고 하는 - 경쟁 플레이어 대 플레이어(PvP) 영역을 특징으로 한다. 이 특정 영역에서, 플레이어들은 여전히 더 나은 장비를 위해 미션들을 완료하기 위해 그룹화할 수 있다; 그러나, 이들은 또한 다른 플레이어들을 죽이고 스스로 보상을 받아 서로 등을 돌리고 악당이 될 수 있다. 최대 레벨에 도달한 후, 플레이어들은 특히 그룹들이 수행하기 어려운 미션들인, 습격에 참여할 수 있다. Ubisoft는 또한 새로운 영역, 장비, 및 PvE 및 PvP 콘텐트 둘 다를 게임에 추가한 다운로드 가능한 콘텐트(DLC) 형태로 게 임을 위한 여러 확장판들을 출시했다. 이 게임은 좋은 평가(콘솔2에서 80/100 메타비평 스코어)를 받았을 뿐만 아니라, 그 출시3 당시 Ubisoft의 베스트 셀러 게임이기도 했다. 이 게임은 대규모 멀티플레이어 온라인 롤 플 레잉 게임과 멀티플레이어 슈팅 게임과는 다른 시스템들을 통합하고 서로 다른 플레이 스타일들과 상호작용 모 드들(즉, 플레이어-환경 및 플레이어-플레이어)를 지원하므로, 이는 동기부여에 대한 연구를 위한 풍부하고 복잡한 게임 테스트베드를 제공한다. 수집된 데이터는 장기간에 걸친 플레이어들의 게임 내 활동에 대한 집계 정보와 해당 UPEQ 설문 조사 스코어들 로 구성된다. 이러한 두 가지 유형의 데이터는 독립적으로 수집되었으며, 게임플레이 특징들은 별도로 웹 인터 페이스를 통해 수집된 설문 조사 데이터와 사이에 기록되었다. 이와 같이, 설문조사 데이터는 플레이어들의 일 반적인 성향을 측정한다. 데이터 세트는 플레이어당 하나의 데이터 포인트로 구성되며, 총 443명의 플레이어들이 상기에 언급된 데이터 수집 프로세스에 참여했다. 피험자의 약 51%는 18세에서 34세 사이의 젊은 성인이었던 반면, 9%는 미성년자(15 세에서 17세), 34%는 35세에서 54세 사이, 6%는 55세 이상이었다. 국가별로는 응답자들의 23%가 영국, 15%가 호 주, 14%가 스웨덴, 9%가 덴마크, 5%가 핀란드, 5%가 노르웨이, 1%가 뉴질랜드였으며, 나머지 28%는 답변을 제공 하지 않았다. 임의의 통계 분석 프로세스의 왜곡을 방지하기 위해 데이터 세트에서 누락된 값들, 손상된 엔트리들 및 이상치 들이 있는 데이터 포인트들을 제거했다. 일반적인 게임 메트릭의 분포를 왜곡하는 이상치들과 플레이시간을 부 풀리는 데이터 로깅 서비스에 의해 발생되는 노이즈로 인해 광범위한 전정(pruning)이 필요했다. 클리닝 프로세 스 후 데이터 세트는 298명의 플레이어들을 포함한다. 게임 내에서 플레이어의 행동을 계산적으로 나타내기 위해, 더 넓은 범위의 게임 원격측정 데이터로부터 추출될 수 있는 30가지 고 레벨 게임플레이 특징들이 사용된다. 이들 대부분은 플레이어의 시간 할당 및 진행 상황을 설명하는 단순 집계 게임 메트릭들이지만, 이러한 게임플레이 특징들 중 4개는 클러스터 분석을 통해 수행되는 플레이어의 게임 내 활동에 대한 시퀀스 기반 프로파일링을 기반으로 하는 고유한 플레이 스타일 또는 플레이어 유형의 독점적 카테고리들이다. 추가로, 데이터 세트에는 UPEQ 설문조사로 측정된 각 플레이어의 4가지 동기부 여 요인들을 나타내는 4개의 리커트 스코어를 포함한다. 고려되는 세 가지 유형의 데이터는 다음과 같이 자세히 설명된다: ㆍ게임 메트릭: 이러한 원시 특징들은 일반 플레이시간(플레이한 일수, 그룹에 속한 일수, 다크존에서의 일수, 세션, 플레이시간, 그룹 플레이시간, 다크존 플레이시간, 악당으로 플레이한 시간); 완료(비일상 미션, 일일 미 션, 사이드 미션, 기습이 있는 날, 기습); 진행(기어 스코어, 다크존 순위, 레벨, 초기 레벨 30, 도달 레벨 30); 조기 게임플레이(레벨 < 30, 조기 플레이시간, 조기 그룹 플레이시간, 조기 다크존 플레이타임, 악당으로 서의 조기 플레이시간); 및 DLC 게임플레이(지하 플레이시간, 서바이벌 플레이시간, 시즌 패스)와 관련하여 카 테고리화될 수 있다. ㆍ플레이어 유형: 4가지 다른 플레이어 유형들은 모험가, 엘리트, PvE 올 라운더 및 소셜 다크존 플레이어이다. 이러한 유형들은 집계된 게임 데이터의 기존 k-평균 클러스터링을 통해 도출될 수 있다. ㆍ동기부여 요인: UPEQ는 평균 리커트 척도 값의 형태로 동기부여의 4가지 요인들을 채점한다. 서수적 데이터의 평균을 계산하는 것은 개념적으로 문제가 될 수 있지만, 평균 설문조사 스코어는 여전히 스코어 내에서 특정 경 향을 나타낼 수 있기 때문에 리커트형 데이터를 사용하는 광범위한 방법이다(예를 들어, 스코어가 높을수록 전 반적으로 더 긍정적인 반응에 해당하는 것으로 가정됨). 앞서 언급된 바와 같이, 2차 모델링 접근 방식은 모든 플레이어들에 대한 쌍별 비교들을 통해 이러한 스코어를 서수적 데이터로 처리하는 데 사용된다. 원래 데이터 세트는 플레이어당 하나의 데이터 포인트를 포함하므로, 선호 학습 작업에 사용되는 개별 특징 벡 터들은 독립적이다. 이는 PL 실험을 준비하는 동안, 각 데이터 포인트가 데이터 세트의 쌍별 변환 동안 모든 다 른 포인트와 비교된다는 것을 의미한다. 이 변환은 두 데이터 포인트들이 동일한 것으로 간주되는 의미의 마진 을 제어하는 선호도 임계값(Pt) 파라미터를 적용한다. 임계값(Pt)의 목적은 모델링 결과를 왜곡할 수 있는 실측 데이터의 노이즈에 대응하기 위한 것이다. 추가로, 데이터 포인트의 관계를 선호도 관계로 변환하기 위해, 이 단계는 또한 기계 학습 작업을 위한 새로운 데이터 포인트도 생성한다. 데이터 세트의 크기는 실측 데이터와 최 적의 Pt 파라미터에 따라 평균 64,705개의 훈련 및 775개의 테스트 포인트로 원래의 데이터 세트에 대한 2차 방 정식 비율에 가깝다. 더욱이, 각 쌍별 비교는 - 양방향으로 선호도 관계를 설명하는 - 두 개의 새로운 데이터 포인트들을 생성하기 때문에, 변환은 분류 작업의 기준선을 50% 정확도로 균형을 맞춘다. 모든 PL 모델들은 10겹 교차 검증으로 검증된다. 데이터 누출을 막기 위해, 훈련 및 테스트 폴드는 데이터의 정 규화 및 쌍별 변환 전에 분리된다. z-정규화 기법은 변환 전 훈련 및 테스트 세트 둘 다에 적용될 수 있다. 테 스트 세트의 독립성을 유지하기 위해, 훈련 세트와 동일한 분포에서 추출하고 해당 테스트 세트에도 동일한 변 환을 적용하는 것으로 가정한다.RankSVM들의 최적 파라미터들은 값 범위 내에서 철저한 검색을 통해 찾는다. 특히, 이 방법은 가장 높은 10겹 교차 검증 정확도를 산출하는 C, 감마 및 Pt 값의 삼중항을 철저하게 검색한다. C 정규화 항은"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "의 감마 RBF 파라미터, 및 의 선택적 선호도 임계값 내에서 검색된다. 최고의 감마 파라미터는 모든 실험에서 0.5인 것으로 밝혀졌지만, C와 Pt는 데이터의 토폴로지에 더 민감했다; 도 3 참조. 선택된 C 및 Pt 파라미터들은 선형 SVM들에 대한 역량의 경우 C = 2, Pt = 1; 자율성의 경우 C = 1, Pt = 0; 관련성의 경우 C = 4, Pt = 1; 존재의 경우 C = 3, Pt = 0.5였고; RBF SVM들에 대한 역량의 경우 C = 3, Pt = 0.5; 자율성의 경우 C = 4, Pt = 0; 관련성의 경우 C = 4, Pt = 0; 존재의 경우 C = 2, Pt = 0.5였다. 제1 구현에서는 동기부여의 예측 능력을 테스트하기 위해 SVM 모델의 입력으로서 네 가지 플레이 스타일들만 사 용된다. 입력 특징 세트의 낮은 차원에도 불구하고, 선형 및 비선형 모델 둘 다 모든 모델에 걸쳐 평균 3.7% 및 3.57% 정확도로 각각 50% 기준선을 능가할 수 있다. 제2 구현에서는 PL 모델은 26개의 게임 메트릭만 모델 입력들로서 고려한다. 보고된 동기부여 요인들을 예측하 는 데 게임 메트릭들만으로도 상당히 성공적이다. 특히, 선형 SVM 모델들은 모든 모델들에 걸쳐 65.89%의 평균 정확도로 성공적인 반면, 개별 요인들에 대한 최상의 모델들은 특정 폴드에서 거의 80%의 정확도로 수행된다. 역량, 자율성, 관련성 및 존재감에 대해 각각 79.66%, 75.62%, 71.69% 및 79.68%이다. 관련성은 선형 모델에 대 해 예측하기 가장 쉬운 요인인 것으로 보이며, 이는 관련성이 통계 분석 중에 가장 개별적인 게임 메트릭과 상 관된다는 점을 감안할 때 놀랄 일이 아니다. 반면에, 선형 SVM들은 자율성에 어려움을 겪을 수 있으며, 이는 자 율성과 데이터의 기술적 통계 분석 동안 발견된 다른 특징들 간의 낮은 양의 상관 관계로 설명될 수 있다. 비선형 커널은 모든 모델에 걸쳐 평균 75.62%의 정확도로 모델의 성능을 더욱 향상시킨다. 최상의 개별 모델들 은 거의 90%의 정확도(역량: 86.73%, 자율성: 89.31%, 관련성: 89.95%, 존재: 87.60%)에 도달하는 해당 선형 모델들을 훨씬 능가한다. 선형 모델에 비해, RBF SVM들은 성능이 저조한 선형 모델들(즉, 자율성)도 크게 향상 시킬 수 있으므로 모든 동기부여 요인에 걸쳐 더 강력한 것으로 보인다. 플레이 스타일들에만 기반한 모델들로 획득된 저조한 성능과 달리, 게임 메트릭들에 기반한 모델들은 네 가지 모든 요인들에 걸쳐 매우 정확하고 강력 하다. 플레이어 유형 또는 기타 고 레벨의 플레이 스타일 프로파일들을 포함하면 도메인별 정보를 추가하여 게임 메트 릭들의 예측 능력을 향상시킬 수 있다. PL 작업에 다른 26개 게임 메트릭들과 함께 플레이 스타일을 포함하면 게임 메트릭들만을 기반으로 하는 모델들의 능력 이상으로 비선형 모델들의 정확도를 향상시킨다. 한편, 선형 모델들은 모든 테스트들에 걸쳐 불과 평균 65.92%(역량, 자율성, 관련성 및 존재에 대해 각각 79.66%, 70.94%, 71.79% 및 76.52%)에 도달하며, 이는 게임 메트릭들을 기반으로 하는 모델들에 의해 획득된 성능에 필적한다. 한편, 비선형 RBF 커널을 사용한 모델들은 평균 82.36%의 정확도에 도달하며, 최고 성능 폴드에서 93% 이상의 정확도 값들을 달성한다: 역량, 자율성, 관련성 및 존재에 대해 각각 93.01%, 94.35%, 95.02% 및 96.83%. 개별 특징들과 동기부여 요인들 사이에 명백한 선형 관계가 없는 경우에도, 비선형 PL 기술들은 동기부여를 예측하는 효율적인 방법들을 제공하고 게임 디자인을 위한 통찰력 있는 정성적 툴을 제공할 수 있다. 도 8은 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1-2, 3a, 3b, 및 4-7과 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 단계는 프로세서를 포함하는 시스템 을 통해, 이전 게임 콘텐트에 기초한 절차 콘텐트를 수신하는 단계를 포함한다. 단계는 시스템을 통해, 기 계 학습 및 게임 봇에 의한 시뮬레이션된 게임 플레이로부터의 플레이 트레이스 데이터 및/또는 행동 동기부여 데이터에 기초한 절차 콘텐트를 반복적으로 개선시키는 단계를 포함한다. 단계는 시스템을 통해, 개선된 절차 콘텐트에 기초하여 후보 게임 콘텐트를 생성하는 단계를 포함한다. 도 9는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1-2, 3a, 3b, 및 4-8과 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 단계는 프로세서를 포함하는 시스템 을 통해, 게임에 대응하는 게임 애플리케이션을 수신하는 단계를 포함한다. 단계는 시스템을 통해, 적어도 하나의 비모방 게임 봇에 의한 게임의 플레이에 기초하여 게임 애플리케이션을 업데이트하여 제1 업데이트된 게 임에 대응하는 제1 업데이트된 게임 애플리케이션을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 제1 복수의 실제 플레이어들에 의한 제1 업데이트된 게임의 플레이에 응답하여 생성된 제1 게임 원격측정 데이터 에 기초하여 적어도 하나의 모방 게임 봇을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 제1 복수의 실제 플레이어들에 의한 제1 업데이트된 게임의 플레이에 기초하여 행동 경험 분석(BEA) 데이터를 생성하는 단 계를 포함한다. 단계는 시스템을 통해, BEA 데이터에 기초하여 적어도 하나의 BEA 툴을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 적어도 하나의 모방 게임 봇에 의한 제1 업데이트된 게임의 플레이에 기 초하여 제1 게임 애플리케이션을 업데이트하여 제2 업데이트된 게임에 대응하는 제2 업데이트된 게임 애플리케 이션을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 제2 복수의 실제 플레이어들에 의한 제2 업데이 트된 게임의 플레이에 응답하여 생성된 제2 원격측정 데이터에 기초하여 예측된 플레이어 경험을 생성하는 단계 를 포함한다. 단계는 시스템을 통해, 예측된 플레이어 경험에 기초하여 제2 게임 애플리케이션을 업데이트 하여 제3 업데이트된 게임에 대응하는 제3 업데이트된 게임 애플리케이션을 생성하는 단계를 포함한다. 도 10은 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1-2, 3a, 3b, 및 4-9와 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 전술한 내용은 예를 들어, 게임 출력, 플 레이어 입력, 게임 상태, 게임 이벤트, 게임 성과, 게임 목표를 향한 진행 상황, 게임 파라미터, KPI 및 기타 게임 분석 등을 포함할 수 있는 플레이 트레이스들로부터 수집된 데이터와 같은 게임 원격측정 데이터를 기반으 로 훈련되는 인공 지능 모델들에 크게 초점이 맞춰져 있지만, 게임 애플리케이션의 픽셀 데이터는 예를 들어, 사용자 동기부여 형태로 사용자 경험을 예측하고 및/또는 이에 제한되는 것은 아니나, 본원에 논의된 PCG 또는 BEA 툴들을 포함하는 게임 개발 플랫폼과 관련하여 설명된 기타 기능들 및 특징들 중 어느 하나를 수행하 는 데 사용될 수 있다. 단계는 프로세서를 포함하는 시스템을 통해, 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 게임 애플리케이션으로부터 픽셀 데이터를 수신하는 단계를 포 함한다. 단계은 시스템을 통해, BEA 툴을 픽셀 데이터에 적용하여 예측된 사용자 경험을 생성하는 단계를 포함한다. 단계는 예측된 사용자 경험에 기초하여 게임 애플리케이션의 적응을 용이하게 하는 단계를 포 함한다. 다양한 실시예들에서, 시스템은 게임 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현되며, 게 임 애플리케이션의 적응을 용이하게 하는 것은 게임 개발 애플리케이션을 통해 게임 애플리케이션의 적응을 용 이하게 하는 것을 포함한다. 게임 애플리케이션은 복수의 옵션 버전들을 포함할 수 있으며, 시스템은 게임 애플 리케이션을 실행하는 게임 시스템을 통해 구현되고, 게임 애플리케이션의 적응을 용이하게 하는 것은 예측된 사 용자 경험에 기초하여 복수의 옵션 버전들 중 하나를 선택하는 것을 포함한다. 게임 애플리케이션의 적응을 용 이하게 하는 것은 플레이어 불일치를 식별하는 것을 포함할 수 있다. 예측된 사용자 경험은 복수의 동기부여 요 인들 각각에 대한 스코어를 나타내는 동기부여 데이터 및/또는 예측된 플레이어 경험의 변화를 나타내는 시간이 지남에 따라 수집된 경험 데이터를 포함할 수 있다. 픽셀 데이터는 게임 봇에 기초하여 생성될 수 있다. 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지들에 기초하고 이전 게임 플레이와 연관된 이전 게임 원격측정 데이터에 더 기초하여 훈련된 기계 학습 모델을 포함할 수 있다. 세 가지 유형의 심층 콘볼루션 신경망(CNN) 아키텍처들을 사용하여 비디오 프레임 또는 비디오 시퀀스의 픽셀 데이터를 기반으로 주석이 달린 각성 트레이스의 로우 값과 하이 값 사이를 분류하는 예를 고려하자. 예를 들어, CNN들은 3D 서바이벌 슈팅 게임의 50개 게임플레이 비디오 데이터 세트에서 테스트되었다. 모든 비디오들 은 RankTrace 연속 주석 툴을 사용하여 플레이어들 스스로(1인칭 주석) 각성하도록 주석을 달았다. 경험한 콘텐 트의 픽셀들로부터의 영향을 예측하는 작업은 가능할 뿐만 아니라 매우 정확하다. 특히, 획득한 각성 모델들은 리브 원 아웃 교차 검증(leave-one-video-out cross-validation) 방법을 사용하여 78% 이상의 평균 정확도를 달성할 수 있는 반면; 최고의 모델들은 98%보다 높은 산출 정확도를 얻었다. 결과는 또한 - 적어도 검사된 서수 적 유틸리티의 경우 - 플레이어 경험이 매우 정확하고 일반적인 방식으로 화면 상의 픽셀들을 통해서만 캡처될 수 있음을 보여준다. 본원에서 논의된 방법론들은 게임 애플리케이션 분석 및 디자인의 기술에 대한 몇 가지 개선 사항들을 제공한다. 플레이어 감정/경험은 상호작용의 맥락을 관찰함으로써만 모델링할 수 있으며, 감정의 임의의 다른 직접적인 표명이나 사용자 입력의 양식을 통해서는 모델링할 수 없으며; 이와 관련하여, 제시된 방법들은 일반 적이고 사용자에 구애받지 않는다. 게임플레이 화면은 게임 경험에 매핑되며, 둘 사이의 관계를 모델링하고 예 측하는 데 사용할 수 있다. 감정 컴퓨팅에서 이러한 매핑을 추론하는 능력에 대해 세 가지 CNN 변형들이 비교된 다; 획득된 높은 정확도 값들은 작업에 대한 적합성을 나타낸다. 플레이어 경험 모델링에 대한 이러한 기술적 개선 사항들은 더 빠르고 쉽고 보다 정확한 경험 모델링을 더 빠르고 쉽고 보다 효과적인 게임 분석 및 디자인으로 이어지는 것을 가능하게 한다. 이러한 예들에 사용되는 게임플레이 비디오들은 Unity 3D 게임 엔진에서 개발된 슈팅 게임으로부터 캡처되었다. 특히, Unity 3D의 튜토리얼 패키지로부터 개조된 게임인, Survival Shooter가 사용되었다. 이 게임에서, 플레이 어는 가능한 한 많은 적대적인 토이들을 쏘고 플레이어의 아바타와 충돌하는 토이들로 인한 건강이 고갈되는 것 을 피할 수 있는 60초의 사간을 갖는다. 적대적인 토이들은 미리 결정된 레벨 영역에서 계속 생겨나며 아바타 쪽으로 모인다. 플레이어의 아바타는 몇 번의 발사로 각 토이를 파괴할 수 있는 밝은 레이저 빔들을 발사하는 총이 있다. 파괴된 모든 토이는 플레이어의 스코어에 추가된다. 데이터는 각각이 두 개의 게임플레이 비디오들을 제작하고 주석을 단 25명의 서로 다른 플레이어들로부터 수집 되었다. 각 플레이어는 게임 세션(60초)을 플레이한 다음, 각성 측면에서 녹화된 게임플레이 피트수에 주석을 달았다. 주석은 Griffin PowerMate 휠 인터페이스를 사용하여 정동(affect)에 대한 지속적이고 무제한 주석을 허용하는 RankTrace 주석 툴을 사용하여 수행되었다. 게임플레이 비디오들은 30Hz(즉, 초당 30프레임)로 캡처되 는 반면, RankTrace 툴은 초당 4개의 주석 샘플들을 제공했다. 게임플레이 비디오의 코퍼스는 15초 미만의 게임플레이 피트수를 생략함으로써 정리되어, 45개의 게임플레이 비 디오와 총 8,093개의 각성 주석으로 구성된 깨끗한 코퍼스가 생성되었다. 이 코퍼스의 평균 플레이스루 지속시 간은 44초이지만, 플레이스루의 60%에서 플레이어는 전체 60초 동안 생존하여 게임 레벨을 완료했다. CNN들이 원시 비디오 데이터를 정서적 상태들에 매핑하는 방법을 평가하기 위해, CNN 모델들은 공간 정보만 포 함하는 개별 프레임과, 공간과 시간 정보 둘 다 포함하는 비디오 세그먼트를 입력으로 사용했다. RankTrace는 무제한 주석을 제공하기 때문에, 각 비디오의 주석 값들은 최소-최대 정규화를 통해 값 [0, 1]로 변환되었다. 이 값들은 주석이 없는 임의의 프레임의 각성 값을 마지막 주석이 달린 프레임의 각성 값으로 처리함으로써 주 석(4Hz)이 있는 비디오의 녹화 주파수(30Hz)와 동기화되었다. CNN 학습 및 평가의 계산 복잡성을 줄이기 위해, RGB 비디오 프레임들은 그레이스케일로 변환되었으며 72 × 128 픽셀로 크기가 조절되었다; 이는 색상이 아닌 이미지의 밝기만 고려하는 보다 콤팩트한 표현을 초래했다. Survivor Shooter의 완전한 그림자와 밝게 빛나는 아바타 및 발사체로 인해, 밝기는 게임플레이 행동을 추출하기 위한 핵심 특징일 가능성이 더 높은 것으로 여겨 졌다. RGB 채널들 또는 더 큰 프레임 크기가 사용되어 게임플레이에 대한 더 많은 정보를 제공하고 치수에 영향 을 줄 수 있지만, CNN이 훈련할 데이터를 실질적으로 더 많이 제공할 것이다. CNN의 입력과 관련하여, 적은 수 의 후속 프레임들이 장면의 내용을 캡처하기에 적합한 것으로 간주되었다. 특히, 8개의 후속 프레임들이 플레이 어의 감정 상태를 특성화하는 데 사용되었다. 특히, 게임플레이 비디오들은 일시적으로 인식되는 CNN 아키텍처 들에 대한 입력으로 사용된 8개의 후속 프레임들의 겹치지 않는 세그먼트들로 분할되었다. 입력이 단일 이미지 인 경우, 각 비디오 세그먼트의 마지막 프레임이 사용되었다. CNN의 출력은 8-프레임 비디오 세그먼트들을 기반으로 계산하기에 간단하다. 주석은 4Hz에서 만들어지기 때문에, 대부분의 경우 비디오 프레임 세그먼트는 하나의 주석이 포함할 것이다. 8 프레임 내에서 2개의 주석이 주어지는 경우, 그 평균값이 계산된다. RankTrace는 간격 데이터를 생성하며, 따라서 이는 문제를 회귀 작업으 로 설명하는 것이 자연스러워 보일 수 있다; 그러나, 사용자에 구애받지 않고 일반적인 접근 방식을 제공하려는 목표를 감안할 때, 이는 매우 편향되고 사용자별 모델들을 생성할 수 있기 때문에 출력 값에 대해 가정할 필요 가 없다. 기본 방법론은 각 트레이스의 평균 값을 클래스 분할 기준으로 사용하여 간격 값들을 이진 클래스(낮 은 각성 및 높은 각성)로의 변환 및 분류 작업으로 간주될 수 있다. 클래스 분할은 선택적 임계값 파라미터(E) 를 사용하여 평균 주변의 각성 값들이 분류 동안 '불확실함'으로 표기되고 무시되는 구역을 결정할 수 있다. 클 래스를 분할하는 대안 방법들(예컨대, 곡선 아래 영역 또는 중앙값)이 가능하지만, 뒤따르는 예들은 평균을 기 반으로 트레이스를 분할한다. 앞서 논의된 바와 같이, 세 가지 예시적인 CNN 아키텍처들이 평가되었다. 처음 두 개는 입력들(단일 프레임들 또는 비디오들)에 2D 학습 가능 필터들을 적용하는 반면, 세 번째는 3D 학습 가능 필터들을 적용한다. 모든 CNN 아키텍처들은 동일한 수의 콘볼루션 및 완전 연결 계층, 해당 콘볼루션 계층에서의 동일한 수의 필터들, 완전 연결 계층에서의 동일한 수의 히든 뉴런들을 갖는다. 이를 통해 비디오 데이터를 정서적 상태들에 매핑하는 이 러한 세 가지 아키텍처들의 능력을 공정하게 비교할 수 있으며, 동시에 시간 정보가 분류 작업에 미치는 영향에 대한 통찰력을 얻을 수 있다. 비디오들 및 이미지들을 위한 다른 CNN들은 예를 들어 사용된 것보다 훨씬 더 큰 아키텍처들을 사용할 수 있다는 점에 유의해야 한다. 상술한 논의의 대부분은 픽셀 데이터에 대해 학습되고 이를 활용하는 AI 모델들의 사용에 초점을 맞추고 있지만, 게임의 오디오는 이에 제한되는 것은 아니나, BEA 툴을 포함하는 게임 개발 플랫폼의 AI 모델의입력으로 사용될 수도 있다. 특히, 오디오의 추가는 게임 유형에 따라 AI 모델들의 성능이 5 내지 10% 향상될 수 있다. 특히, 픽셀 오디오 AI 경험 모델은 90% 이상의 정확도에 도달할 수 있다. 도 11은 본 개시의 일 실시예에 따른 CNN 아키텍쳐의 블록도 표현을 나타낸다. 콘볼루션 계층들은 \"C\"로, 최대 풀링 계층들은 \"P\"로, 완전 연결 계층들은 \"F\"로 표시된다. 제1 CNN 예시적인 아키텍처인 2DFrameCNN은 2D 필터들을 적용하는 단일 프레임을 입력으로 사용한다. 2DFrameCNN 아키텍처는 각각 크기가 5×5 픽셀인 8개, 12개 및 16개의 필터들이 있는 3개의 콘볼루션 계층들로 구성된다. 각 콘볼로션 계층에는 크기가 2×2인 2D 최대 풀링 계층이 뒤따른다. 콘볼루션의 출력은 960개 요소 들의 특징 벡터이며, 이는 출력에 연결되는 64개의 히든 뉴런들이 있는 완전 연결 계층에 공급된다. 이 아키텍 처는 약 6.9 × 104 훈련 가능한 파라미터들을 가지고 있으며, 비디오 데이터의 공간 정보만 활용한다. 2DSeqCNN 네트워크는 2DFrameCNN 아키텍처와 정확히 동일한 토폴로지를 갖지만 입력이 비디오 시퀀스이기 때문 에 훈련 가능한 파라미터들의 수는 약간 더 높다(대략 7 × 104). 이 아키텍처는 암시적으로 데이터의 공간 및 시간 정보 둘 다 활용한다. 제3 CNN 아키텍처인 3DSeqCNN은 3D 필터들을 입력 비디오 세그먼트들에 적용한다. 다른 아키텍처와 같이, 3DSeqCNN에는 각각 크기가 5×5×2 픽셀인 8개, 12개 및 16개의 필터들이 있는 3개의 콘볼루션 계층들이 있다. 각각의 콘볼루션 계층들에는 크기가 2×2×1인 3D 최대 풀링 계층이 뒤따른다. 3D 콘볼루션 계층들은 1,920개의 요소들로 구성된 특징 벡터를 생성하며, 이는 64개의 뉴런이 있는 완전 연결 계층에 공급되다. 3D 훈련 가능 필 터들로 인해, 3DSeqCNN에는 대략 14.5×104개의 훈련 가능 파라미터들이 있다. 이 아키텍처는 공간 및 시간 차 원을 따라 훈련 가능 필터의 적용으로 인해 데이터의 공간 및 시간 정보를 명시적으로 활용한다. 2DFrameCNN은 단일 프레임을 입력으로 수신하지만, 2DSeqCNN과 3DSeqCNN 둘 다 8개의 프레임 시퀀스, 즉 267 밀리초 동안 지속되는 비디오의 타임 슬라이스를 입력으로 수신한다. 모든 세 가지 네트워크 아키텍처들에서, 마지막 완전 연결 계층에 이들을 공급하기 전에 콘볼루션 계층들로 구성된 특징들에 배치 정규화가 적용되며, 이는 차례로 이진 분류를 위해 두 개의 출력 뉴런들 공급한다. CNN 아키텍처들의 모든 하이퍼파라미터들은 다음 의 두 가지 서로 다른 기준의 맞추기 위한 시도 시 수동으로 선택된다: (a) 계산 복잡성(훈련 및 평가 시간) 및 (b) 학습 복잡성(언더 피팅/오버 피팅을 방지하는 능력). 세 가지 CNN 모두 게임플레이 피트수를 높거나 낮은 각성으로 분류하는 데 사용되었다. 앞서 언급된 바와 같이, 이 이진 분류 접근 방식은 (각 주석 추적의 평균이 다르기 때문에) 무제한 및 연속 트레이스에 적합하며, 딥 러 닝을 위해 충분히 풍부한 데이터 세트를 생성할 수 있다. 보고된 모든 실험에서, 디맨딩 리브 원 아웃 방식이 사용되었으며; 이는 모델들을 훈련시키기 위해 44개의 비디오로부터 사용된 데이터 및 기타 데이터가 훈련을 위 해 사용되지 않은 성능(즉, 테스트 세트)를 평가하는 데 사용되었다. CNN들의 성능이 모든 비디오들의 데이터에 대해 테스트될 때까지 이 절차가 45번 반복되었다. 모델을 훈련시키는 동안, 오버 피팅을 피하기 위해 조기 중 지 기준이 사용되었다. 조기 중지의 경우, 44개 비디오들의 데이터가 섞였으며, 훈련 세트(데이터의 90%)와 오 버 피팅을 위한 검증 세트(데이터의 10%)로 더 분할되었다. 15개의 훈련 시기 동안 검증 세트에 대한 손실이 개 선되지 않은 경우 조기 중지가 활성화될 수 있다. 보고된 정확도는 45회 실행으로부터 평균 낸 테스트 세트에 대한 분류 정확도이다. 중요성은 이 테스트 정확도의 95% 신뢰 구간으로부터 도출된다. 기준 정확도는 테스트 세트의 평균 분류 정확도이지만, 항상 훈련 세트의 44개의 비디오에서 가장 일반적인 클래스를 선택한다. 당연 히, 기준선은 또한 두 클래스 간의 실측 분포를 나타낸다. 게임플레이 피트수의 세그먼트들을 분류하는 가장 간단한 방법은 주석 트레이스의 평균 각성 값을 기반으로 하 여, 평균 값 위의 모든 주석을 높은 각성으로, 평균 값 아래의 모든 주석을 낮은 각성으로 처리한다. 이 간단한 분류는 모든 45개 비디오로부터 총 8,093개의 데이터 포인트들(즉, 클래스에 할당된 8-프레임 세그먼트들)을 생 성한다.표 1"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "표 1의 맨 위 행은 기본(naive) 분류 방법(E = 0)을 사용한 CNN 모델들의 평균 분류 정확도를 보고한다. 모든 모델들은 기준 분류기보다 20% 이상 높은 정확도를 가지며, 이는 사용된 아키텍처에 관계없이 CNN들이 원시 게 임플레이 비디오를 각성 이진 상태들로 매핑할 수 있는 능력을 가진다는 것을 시사한다. 가장 잘 수행되는 모델 은 2DSeqCNN이며, 이는 데이터의 시간 정보를 암시적으로 활용한다. 정확도는 공간 정보만 활용하는 2DFrameCNN 보다 3% 이상 높지만, 3DSeqCNN보다 약간 더 우수할 뿐이다. 시간 정보를 명시적으로 활용하는 3DSeqCNN의 능력 은 성능에 큰 영향을 미치지 않는 것으로 보인다. 2DFrameCNN의 성능을 다른 두 CNN 모델들의 성능들과 비교하 면 시간 정보가 학습 프로세스에 기여하지만, 입력들에 대한 지배적인 정보는 시간 구조가 아니라 공간에서 비 롯됨을 나타낸다. 이는 입력 비디오 세그먼트들의 매우 짧은 지속시간(267 밀리초)로 인한 것이나 게임의 헤드 업 디스플레이에 존재하는 각성의 강력한 예측자들로 인한 것일 수 있다. 각성 트레이스의 평균 값 이상의 모든 데이터를 높은 것으로 분류하면 대규모 데이터 세트를 생성하지만, 데이 터 세트의 다소 임의적인 분할은 기본 실측을 잘못 표현하고 분할 기준 편향을 도입할 수도 있다. 특히, 평균 주위에 각성 값들이 있는 프레임들은 사소한 차이에 기초하여 하이 또는 로우로 분류된다. 모호한 주석을 필터 링하기 위해(즉, 평균 각성 값 에 가까움), 불확실성 범위 내에서 각성 값 A가 있는 모든 데이터 포인트들은 다음에 의해 결정된다:"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "표 1은 E의 서로 다른 임계값들에 대한 서로 다른 CNN 아키텍처들의 성능을 나타낸다. 데이터 포인트들을 제거 하면 한 클래스의 대표들이 다른 클래스보다 더 자주 사용되기 때문에 기준 값들에 매우 상당한 영향을 미친다 는 점에 유의해야 한다. 그럼에도 불구하고, 특히 높은 E 값의 경우, 모호한 각성 값들이 있는 데이터가 제거되 면 모든 아키텍처들의 정확도가 높아진다. E = 0.20의 경우, 세 가지 CNN 아키텍처 모두의 정확도는 기준선보다 26 내지 28% 높다. 2DFrameCNN은 E = 0.10 및 E = 0.20에 대해 정확도가 2DSeqCNN에 이어 두 번째를 차지하는, 더 클린한 데이터 세트의 이점도 있다. 3DSeqCNN의 추가 훈련 가능 파라미터들은 희소 데이터 세트에서 사용할 수 있는 것보다 더 많은 데이터가 필요한 것으로 보인다. 실제로, 총 데이터 포인트의 수는 (총 4,534개의 데이 터 포인트에 대해) E = 0.05의 경우 12%, E = 0.10의 경우 25%, 및 E = 0.20의 경우 44%로 감소한다. 더 클린 하지만 보다 콤팩트한 데이터 세트를 가지면 덜 복잡한 아키텍처들(2DFrameCNN, 2DSeqCNN)이 더 정확한 모델을 도출하도록 할 수 있지만 복잡한 아키텍처들(3DSeqCNN)에 도전할 수 있다는 것은 분명하다. 트레이드 오프는 게 임플레이 주석의 유사한 작업들에 대해 전진된 흥미로운 문제를 제기한다. 예들은 화면상의 게임플레이 피트수만으로 - 단일 프레임 스냅샷에서도 - 플레이어의 각성에 대한 놀라울 정도 로 정확한 모델들을 생성하는 것이 가능하다는 것을 나타낸다. 특히 모호한 각성 주석들이 있는 데이터를 제거 할 때, 2DFrameCNN 모델은, 평균 테스트 정확도가 77%이지만, 98%(E = 0.20에서)의 테스트 정확도에 도달할 수 있다. 그러나, 화면의 어떤 특징들이 프레임들이나 비디오들을 낮은 각성 또는 높은 각성 클래스들로 구분하는 지 관찰하는 것이 더 흥미롭다. 이는 예를 들어, 기울기 가중 클래스 활성화 매핑(Gradient-weighted Class Activation Mapping)을 통해, 프레임의 어느 부분들이 모델의 예측에 가장 큰 영향을 미치는지 보여줌으로써 달 성될 수 있다. 이 방법은 특정 입력이 주어지면, 콘볼루션 계층의 노드들에 대한 출력 노드들의 기울기를 계산 한다. 입력에 기울기를 곱하고, 계층의 모든 노드들에 걸쳐 평균을 내고, 결과 값들을 정규화함으로써, 입력의 각 영역이 출력 노드의 값을 증가시키는 데 얼마나 많은 양이 기여하는지를 보여주는 히트맵이 획득될 수 있다.도 12a는 본 개시의 일 실시예에 따른 비디오 프레임의 이미지 표현을 나타낸다. 도 12b 및 12c는 2DFrameCNN에 기초하여 계산된, 샘플 게임플레이 프레임에 대한 본 개시의 일 실시예에 따른 낮은 각성의 활성화를 위한 활성화 맵 및 높은 각성의 활성화를 위한 활성화 맵을 나타낸다. 2DSeqCNN은 정확도 가 더 높지만, 정적 수치의 시퀀스를 시각적으로 캡처하는 것이 훨씬 더 어렵기 때문에, 2DFrameCNN의 프레임 전용 정보가 제시된다. 낮고 높은 각성 예측자들은 플레이어가 탐색하고, 쏘고, 적대적인 토이들과 충돌하는 3D 세계에 오버레이되는 헤드업 디스플레이(HUD)의 측면에 초점을 맞춘다는 점에 유의해야 한다. 특히, 화면 상단 중앙의 스코어는 높은 각성에 크게 기여한다. 흥미롭게도, 플레이어가 점점 더 많은 적대적인 토이들을 죽일수 록 게임이 진행되는 동안 스코어가 계속 증가한다. 게임에서 경과된 시간 - 및 스코어 증가 정도가 - 각성에 미 치는 영향은 주석 자체로 확증될 수 있다: 대부분의 경우, 주석자는 시간이 지남에 따라 각성 레벨을 낮추기보 다는 계속 높였다. 효과적으로, 전체 데이터 세트의 모든 각성 값 변화 중 807건이 증가했고 297건이 감소했다. 따라서, 스코어와 남은 시간 둘 다 낮거나 높은 각성을 나타내는 간단한 지표들이 될 것이다. 흥미롭게도, 플레 이어의 건강에 대한 HUD 요소는 어느 클래스에서도 고려되지 않았다. 3D 게임 세계의 다른 특징들 중에서, 적대 적인 토이들은 낮은 각성 출력으로 캡처되는 반면, 플레이어 옆의 장애물은 높은 각성 출력으로 캡처된다. 도 13a는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1-2, 3a, 3b, 및 4- 12와 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 전술한 내용은 사용자 경험, 동기부 여 및 행동을 모델링하고 예측하는 데 주로 중점을 두었지만, 전술한 툴 및 방법론은 마찬가지로 예를 들어, 시 청자 경험을 예측하고 및/또는 이에 제한되는 것은 아니나, 본원에 논의된 PCG 또는 BEA 툴을 포함하는 게임 개 발 플랫폼과 관련하여 설명된 기타 기능들 및 특징들 중 어느 하나를 수행하는 데 사용될 수 있다. 단계는 프로세서를 포함하는 시스템을 통해, 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 게임 애플리케이션과 연관된 게임 데이터를 수신하는 단계를 포 함한다. 단계는 시스템을 통해, BEA 툴을 게임 데이터에 적용하여 예측된 시청자 경험을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 예측된 시청자 경험에 기초하여 게임 애플리케이션의 적응을 용이하게 하는 단계를 포함한다. 다양한 실시예들에서, 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지들에 기초하고 이전 게임 플레이와 연관된 이전 게임 원격측정 데이터에 더 기초하여 훈련된 기계 학습 모델을 포함한다. 게임 데이터는 복수의 시청자들로부터의 채팅 데이터를 포함할 수 있다. 시스템은 게임 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현될 수 있으며, 게임 애플리케이션의 적응을 용이하게 하는 것은 게임 개발 애플리케이 션을 통해 게임 애플리케이션의 적응을 용이하게 하는 것을 포함한다. 게임 애플리케이션은 복수의 옵션 버전들 을 포함할 수 있으며, 시스템은 게임 애플리케이션을 실행하는 게임 시스템을 통해 구현되고, 게임 애플리케이 션의 적응을 용이하게 하는 것은 예측된 시청자 경험에 기초하여 복수의 옵션 버전들 중 하나를 선택하는 것을 포함한다. 게임 애플리케이션의 적응을 용이하게 하는 것은 플레이어 불일치를 식별하는 것을 포함할 수 있다. 예측된 시청자 경험은 예측된 시청자 참여의 변화를 나타내는 시간에 따라 수집된 참여 데이터를 포함할 수 있 다. 순간 순간의 게임플레이 참여에 대한 신뢰할 수 있는 추정치는 게임 개발에 중요하다. 정확한 참여 프록시는 게 임의 수익 창출 전략을 향상시킬 뿐만 아니라, 이들이 참여 기반 에이전트를 통해 게임들을 빠르게 테스트하는 데 사용할 수도 있다. 이러한 에이전트들은 차례로 플레이어 경험을 개선하고 게임 콘텐트 생성을 통해 완전히 새롭고 매력적인 게임플레이 경험의 설계로 이어질 수 있다. 플레이어의 행동을 참여의 예측자로 보는 대신, 다 음 예에서는 모델링 문제를 재구성하고 시청자의 관점에서 게임플레이 참여를 살펴본다. 이를 위해, 참여는 예 를 들어, 게임을 플레이하는 동안 - 시청자들에게 실시간 스트리밍됨 - 플레이어의 행동 상태와 해당 게임의 청 중의 참여 사이에 매핑이 있다고 가정하는 게임플레이의 시청자들의 적극적인 참여로 정의될 수 있다. 다음 예에서는 인기 있는 비디오 라이브 스트리밍 서비스(Twitch1)의 데이터를 사용하고 PlayerUnknown's Battlegrounds―PUBG(PUBG 코포레이션, 2017) 게임으로부터 스트리밍된 데이터를 획득한다. 이 예에서 순간순간 게임 참여 모델을 구성하기 위해, 게임의 중요한 이벤트와 채팅 피드의 해당 메시지 빈도 간의 관계가 조사된다. 특히, 인공 신경망(ANN)은 게임의 각 중요 이벤트(예를 들어, 플레이어 사망, 헤드샷, 킬 등)에서 게 임플레이 참여(시청자의 채팅 빈도에 기인함)를 예측할 수 있는 데 사용된다. 도출된 ANN 모델들은 평균 80%의 정확도에 도달하며, 85%는 게임플레이 이벤트가 시청자 참여의 정확한 예측자가 될 수 있고, 게임플레이가 채팅 빈도를 통한 시청자 행동에 기인될 수 있음을 시사한다. 이러한 ANN 모델들은 접근 방식의 확장성 및 일반화 가 능성을 보여주는 유사하게 높은 정확도로 스트리머 내부 및 전반에 걸친 참여를 예측할 수 있다. 이 작업의 결 과는 스트리밍되는 임의의 특정 라이브 PUBG 비디오에 대한 지속적인 예측 참여(참여 라인)이다(도 13b 참조).도 13b는 본 개시의 일 실시예에 따른 비디오 프레임의 이미지 표현을 나타낸다. 특히, 게임 플레이의 예시적인 화면 디스플레이는 화면 상단에 예측된 시청자 참여의 현재 레벨을 나타내는 참여 스코어 및 현재 게임 시간의 표시를 포함하는 PUBG로 표시된다. 게임 시간에 걸쳐 예측된 시청자 참여의 트랙은 화 면의 하단 근처에 제시된다. PUBG는 멀티플레이어 온라인 슈팅 게임으로, 플레이어 그룹(한 번에 최대 100명)이 공개된 넓은 맵에 떨어져 무 기와 아이템을 찾아 헤매다가, 결국 승자만 남을 때까지 서로 전투를 벌이게 된다. 게임플레이 역학은 빠른 동 작의 폭발로 인한 긴 횡단 및 준비를 특징으로 한다. 게임이 진행됨에 따라, 플레이 가능 영역이 줄어들어, 나 머지 플레이어들이 더 가까이 모여, 전투의 가능성이 높아진다. 플레이어들이 플레이 가능한 반경의 영역 밖에 남아 있으면, 이들은 지속적인 피해를 입으며; 이 영역을 블루 존이라고 한다. 블루존으로 둘러싸인 안전지대의 축소는 단계적으로 수행된다. 각 단계에서, 대피 구역이 지정되며, 이 구역 밖의 플레이어들은 해당 구역에서 대피하라는 경고를 받는다. 그런 다음, 블루 존은 점차적으로 안전 지대를 대피 구역의 크기로 축소한다. 게임 의 페이스는 종종 레드 존으로 표시되는 임의의 국지화된 지역의 폭격으로 인해 중단되며 플레이어들은 건물 내 부로 대피하거나 해당 지역에서 대피하도록 강제된다. PUBG 코포레이션은 개발자들과 연구원들이 게임플레이 원격측정의 고밀도 데이터 세트를 생성할 수 있는 API 및 원격측정 서비스를 제공한다. 각 세션은 게임플레이 이벤트 및 개체(예를 들어, 플레이어, 픽업, 차량 및 무 기)에 의해 조직된 계층 구조로 상세하게 기록된다. API를 통해 사용할 수 있는 40개의 게임플레이 이벤트들과 10개의 개체들이 있으며, 이는 레벨의 모든 플레이어들과 일반 게임 상태들도 포함한다. 이 예는 게임플레이를 방송하는 스트리머의 콘텐트에만 초점을 맞추므로, 다른 플레이어들과 관련된 데이터(예를 들어, 스트리머와 관 련이 없는 위치, 행동 및 전투 기간)는 필터링될 수 있다. 이 예에서, 40개의 PUBG 게임플레이 특징들이 추출되었다. 특징들은 다음과 같은 5가지 주요 카테고리로 나눌 수 있다: 건강, 순회, 전투, 아이템 사용 및 일반 게임 상태. 건강 카테고리는 스트리머의 건강 레벨과 다음과 같은 다수의 부울 이벤트들을 포함한다: 치유, 소생, 소생 받기, 갑옷 파괴, 그로기 제작, 데미지 획득 및 살해. 순회 카테고리는 마지막 이벤트(Delta Location) 이후 이동한 거리, 블루 존 내, 레드 존 내, 수영 시작, 수영 끝, 도약시작, 차량 타기, 차량 이탈 부울 게임 이벤트들을 포함한다. 전투 카테고리는 샷 수, 데미지 수 행 스칼라 값 및 다음의 부울 특징들을 포함한다: 공격 중, 무기 발사, 피해 유발, 물체 파괴, 방어구 파괴, 바 퀴 파괴, 차량 파괴, 적을 그로기 상태로 만들기. 아이템 사용 카테고리는 아이템 드랍, 아이템 장착, 아이템 해제, 아이템 픽업, 케어 패키지에서 아이템 픽업, 전리품 상자에서 아이템 픽업, 아이템 사용, 아이템 부착, 아이템 분리 부울 이벤트를 추적한다. 마지막으로, 일반 게임 상태 카테고리는 경과 시간(초 단위), 살아있는 팀 수 및 살아있는 플레이어 수 및 게임의 단계(예를 들어, 블루 또는 레드 존)를 포함한다. 이 예에서, 라이브 PUBG 게임 플레이 데이터는 Twitch 스트리밍 플랫폼으로부터 획득되었다. Twitch는 범용 라 이브 스트리밍 플랫폼이지만, 사이트 트래픽의 대부분은 파병 및 경쟁 둘 다 비디오 게임 스트리밍에 의해 생성 된다. e스포츠 및 게임 스트리밍이 점점 더 대중화됨에 따라, 더 매력적인 스트림 또는 스트림 일부를 선택해야 할 필요성이 증가한다. 이는 특히 빠르게 상승하는 트렌드가 이전에 성공한 장르를 뒤집을 수 있고 새로운 소비 자 즐겨찾기가 기업을 성장시킬 수 있는 수 비디오게임 스트리밍에 해당된다. Twitch는 스트리머와 시청자를 연 결하는 동시에 시청자들이 서로 연결할 수 있는 플랫폼도 제공한다. 스트리머를 보면서 채팅하는 것은 공유 경 험의 큰 부분이다. 실제로, Twitch 시청률 이면의 동기부여에 대한 현대의 연구는 가장 강력한 동기부여가 사회 적이고, 그 다음으로 정서적 및 긴장 완화 욕구가 뒤따른다는 것을 보여준다. 시청자들은 스트림을 시청하고 다 른 시청자들과 소통함으로써 일정 수준의 만족을 얻지만, 플랫폼 사용자에게는 인지적(즉, 학습) 및 개인 통합 (즉, 동료의 인정) 욕구가 덜 두드러진다. 순간순간의 참여는 게임의 두 연속 이벤트 사이에 채팅 메시지들의 역 빈도로 측정될 수 있다. 이 값은 0에서 1 사이의 범위에서 정규화된 연속 이벤트 간의 채팅 메시지 수로 계산될 수 있다. 참여 예측은 \"하이\" 또는 \"로우\" 참여 레이블을 예측하는 것이 목표인 이진 분류 작업으로 볼 수 있다. 특히, 이 예에서는 선택된 임계값 α보다 각각 높거나 낮은 메시지 빈도로 로우 및 하이 참여 이벤트들을 고려한다. 낮은 빈도를 시청자의 높은 참여도의 순간으로 연관시키는 것이 놀랍게 보일 수 있지만, 비디오를 정성적으로 검사함으로써 화면에서 빠른 속도로 진행되는 동작이 발생할 때(즉, 시청자들이 화면에 더 많은 주의를 기울이고 있을 때) 채팅방이 더 조용 해지고, 더 차분한 느린 속도의 순간이 있을 때(예를 들어, 지루함의 징후) 더 많은 채팅을 하는 경향이 있음을 관찰할 수 있다.원격측정 이벤트를 통해 PUBG 참여를 어느 정도 예측할 수 있는지 테스트하기 위해, 게임 내 이벤트 및 해당 채 팅 메시지들은, 기계 학습을 통해 탐색하기에 충분히 큰 데이터 세트의 가용성과 인기도에 기초하여, 5명의 스 트리머 - chocoTaco, Danucd, sprEEZy, jeemzz, hambinooo - 로부터, 각각 PUBG API 및 Twitch API로부터 수집 되었다. 표 2는 5명의 스트리머 각각에 대해, 스트리머의 순위 3, 수집된 비디오 및 경기 수, 평균 시청자 수 4, 평균 지속 시간, 채팅 메시지 수 및 선택된 타임프레임 내 수집된 이벤트 수를 나타낸다. 표준 편차는 괄호 안에 표시된다. 표 2"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이 통계에 기초하여, 상위에 랭크된 두 스트리머들인, chocoTaco와 Danucd는 그들 사이에 비슷한 수를 가진 다 른 세 스트리머들에 비해 경기당 시청자 수와 채팅 메시지 수가 훨씬 더 많다. 이 인기 순위에서 흥미로운 예외 는 다른 스트리머들보다 약 2배 더 오래 플레이하는 것으로 보이는 sprEEZy의 평균 경기 시간이다. 입력 특징들의 추출 및 전처리 및 메시지 빈도를 상기에 논의된 바와 같이 이진 레이블로 변환한 후, 총 119,345개의 레이블이 지정된 이벤트들이 획득되었다. 선택된 클래스 분할 임계값(α)과 관계없이, 데이터 세트 는 두 클래스 간에 매우 불균형한 비율을 나타내며, 레이블들의 대부분은 높은 참여로 분류된다. 데이터 세트의 균형을 맞추기 위해, 오버샘플링과 언더샘플링이 각각 소수 및 다수 클래스에 적용되어, 기준 정확도가 50%가 되었다. 이 프로세스는 검증 세트에 대한 임의의 데이터 누출을 제거하기 위해 훈련 및 검증 세트에 대해 개별 적으로 따랐다. 이 예제에 포함된 모든 실험에서, 인공 신경망들(ANN들)이 예측 모델들로 적용되었지만, 다른 기계 학습 기술들 도 마찬가지로 사용될 수 있다. 사용된 ANN들은 128개의 노드들로 구성된 단일 완전 연결 히든 계층과 그 뒤에 드롭아웃 계층을 특지으로 하며; 네트워크에는 하이 또는 로우 참여를 예측하는 출력 노드가 있다. 모든 노드들은 ELU 활성화 함수를 사용하고, 학습률은 1e-5이며, ANN은 100 에포크 동안 훈련된다. 제1 실험 세트에 서, 모델은 5개의 스트리머 각각에 대해 개별적으로 훈련 및 테스트되었다. 제2 실험 세트에서, 이러한 참여 모 델의 확장성은 모든 스트리머들에 걸쳐 테트되었다. 대안적인 접근방식에서, 서로 다른 플레이 스타일들이 모든 스트리머들에 걸쳐 식별되고 모델링된다. 이 제1 실험 세트에서, 데이터 포인트들은 하나의 스트리머로부터만 수집되었으며, 모델들은 5겹 교차 검증 체 계를 사용하여 검증되었다; 경기들은 폴드들에 무작위로 분배된다. 어떤 분할 기준이 최상의 성능으로 이어지는 지를 평가하기 위해, 4개의 서로 다른 임계(α) 값들(0.0, 0.1, 0.2, 0.3)을 평가했다. 이 접근 방식은 모델이 이벤트 빈도의 사소한 차이를 기반으로 높은 참여도와 낮은 참여도를 분류하는 방법을 학습할 수 있으므로 분할 기준 편향으로 이어질 수 있다. 이 문제를 해결하기 위해, 선택된 임계값에 가까운 임의의 명확한 데이터 포인 트들을 필터링하기 위해 데이터를 분할할 때 불확실성 한계( )가 사용되었다. 특히, 생략된 모든 이벤트들은 α + 또는 - 범위에 속한다. 4개의 α 값 외에도, 이 예에서는 = 0.02, 0.05, 0.08에 대해 3개의 서로 다 른 값들을 탐색한다 - α와 의 가능한 모든 조합을 철저하게 검사하고 5겹 교차 검증 정확도가 가장 높은 구성을 선택한다. 표 3은 각 스트리머에 대해 선택된 설정을 보여준다. 표 3"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "모든 개별 스트리머 참여 모델은 평균 76% 내지 79%에 이르는 유사한 성능을 달성한다. 특히, 스트리머 Danucd (평균 79.7%; 최고 84.3%), sprEEZy(평균 78.0%; 최고 82.4%), hambinooo(평균 77.8%; 최고 80.43%)에 대해 최 고의 정확도가 관찰된 반면, jeemzz(평균 76.8%; 최고 80.8%) 및 chocoTaco(평균 76.0%; 최고 83.2%)에서 약간 더 낮은 값들이 획득된다. 이러한 결과들은 이미 이 방법론이 4개의 서로 다른 스트리머들에 걸쳐 매우 높은 정 확도로 스트리머 원격측정과 시청자 참여 간의 관계를 포착할 수 있음을 나타낸다. 이전 실험 세트의 결과는 개별 스트리머들의 참여를 매우 높은 정확도로 포착할 수 있음을 보여준다. 모델들을 더 일반화하여 보이지 않는 스트리머들의 참여 값들을 포착할 수 있다. 모델의 일반성을 테스트하기 위해, 모델 이 4명의 스트리머들로부터 수집된 데이터를 기반으로 훈련되고 나머지 스트리머에 대해 테스트되는 리브 원 스 트리머 아웃 교차 검증 방식이 사용된다. 이 프로세스는 각 스트리머마다 한 번씩 5번 반복된 후, 결과들을 평 균낸다. 보고된 모든 실험(표 4)에 대해, 앞서 논의된 바와 같이 α 및 의 모든 조합들에 대한 철저한 검색을 기반으 로 최상의 파라미터 설정이 선택된다. 발견된 최고의 모델(평균 74.7%, 최고 78.7%)은 개별 스트리머들의 데이 터에 대해 테스트된 모델들의 정확도들과 비교하여 더 낮은 정확도를 산출한다. 이는 스트리머 내에서 모델의 일반성이 스트리머 전반에서 스트리머들 전반에 걸친 모델의 일반성을 달성하는 것이 훨씬 더 쉽기 때문에 놀라 운 일이 아니다. 표 4"}
{"patent_id": "10-2021-7032290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "처음 2번의 실험에서 얻은 결과를 감안할 때, 이는 스트리머들 전반에 걸친 일반적인 참여 모델이 어느 정도의 정확도로 수행될 수 있음이 분명해졌다. 스트리머들이 플레이하는 경기 전반에 걸쳐 다양한(일관되지 않은) 행 동들을 묘사할 수 있으며, 이를 고려한다면 참여 모델의 정확도를 향상시킬 수 있다는 것이 가능하다. 특히, 기 계 학습이 포착하고 참여와 연관시킬 수 있는 스트리머들 전반에 걸쳐 일반적인 플레이 패턴들이 있다고 가정한 다 - 이러한 패턴들은 모델의 훈련을 지원하는 데 사용될 수 있다. 5명의 스트리머들이 서로 다른 플레이 스타일들을 보이는지 조사하기 위해, 수집된 데이터를 클러스터링했다. 먼저 원시 데이터를 119,345개의 이벤트에서 324개의 일치 항목으로 집계했으며 - 부울 이벤트들은 합산되고(예 를 들어, 치유를 통해) 스칼라 값들은 평균화됨(예를 들어, 델타 위치를 통해) - 각 일치에 대해 데이터는 최소 -최대 정규화를 통해 정규화되었다. 데이터에 존재하는 클러스터의 수를 결정하기 위해, 두 가지 서로 다른 클 러스터링 알고리즘들 - k-평균 및 계층적 클러스터링 -이 사용되었으며 결과들은 일관성에 대해 테스트되었다. 첫째, k-평균은 1에서 10 사이의 k 순위에 대해 정규화된 데이터에 적용되었으며, 양자화 오차 - 즉, 모든 데이 터 포인트에서 해당 클러스터 중심까지의 거리의 합 - 가 계산되었다. 결과들은 k가 증가할 때 양자화 오차의백분율 감소가 각각 53% 및 20%의 감소로 2개 및 3개 클러스터에서 특히 높다는 것을 보여준다. k(>= 4) 값이 높을수록 차이가 더 많이 포함된다(1% 내지 10% 사이). 적절한 클러스터 수를 찾는 대안적인 접근 방식은 모든 단일 일치에서 시작하여 계층적 방식으로 데이터를 분할 한 다음, 클러스터 수와 해당 클러스터를 분리하는 해당 유클리디안 제곱 거리 간의 관계를 관찰하는 것이다. 계층적 클러스터링의 이 응용 프로그램에서. 전체 클러스터 내 분산을 최소화하기 위해 워드(Ward) 거리 메트릭 이 사용되었다. 이 접근 방식은 k-평균과 유사한 결과들을 산출한다: 6.6보다 높은 유클리디안 제곱 거리 임계 값을 산출하는 것은 3개의 클러스터들을 산출하는 반면, 10.3보다 높은 임계값은 2개의 클러스터들을 산출한다. 이 두 가지 비지도 학습 알고리즘들로 수행된 분석은 가장 적절한 데이터 클러스터 수가 2 내지 3개 사이에 있 음을 집합적으로 나타낸다. 두 개의 클러스터들은 데이터를 제1 클러스터의 경우 86개의 경기(74,947개 이벤 트), 제2 클러스터의 경우 238개의 경기(44,398개 이벤트)가 있는 매우 불균형한 클러스터들로 분할한다. 그러 나, 3개의 클러스터들은 제1, 제2 및 제3 클러스터에 대해 각각 105개(42,878개 이벤트) 및 64개의 경기(61,609 개 이벤트)로 보다 균일하게 분포된 경기 데이터 분할을 생성한다. 정보 엔트로피(E)를 획득된 경기 분포의 균 형의 척도로 사용하면 두 클러스터 솔루션(E = 0.83)에 비해 세 클러스터에서 더 높은 엔트로피(E = 0.94)가 발 생한다. 두 개의 클러스터들로 분할된 경기의 높은 불균형을 감안할 때, 두 클러스터링 알고리즘들에 의해 획득 된 결과의 유사성은 이 데이터 세트에 3개의 클러스터들이 존재함을 나타낸다. 클러스터된 세 가지 플레이어 스타일들에 레이블을 지정하기 위해, 게임플레이의 특징들이 각 클러스터 내에서 그룹화되는 방식에 대한 조사가 수행되었다. 3개의 클러스터들게 걸친 4가지 대표적인 게임 특징들이 고려될 수 있다. 이 네 가지 특징들은 Delta Location(경기에서 커버되는 거리), Kill(경기에서 죽은 적의 수), Take Damage(경기에서 플레이어가 입은 피해), Time(경기 시간(초))이다. 대중적인 게임 문화 용어를 사용하여, 제1 클러스터는 Noob 플레이 스타일로 레이블이 지정되며, 이러한 경기에서 스트리머는 특히 잘 플레이하지 않으며, 적은 수의 킬에 도달하고 자주 죽임을 당한다. 한편, 경기는 훨씬 더 짧으며, 스트리머가 경기 시작 후 몇 분 안에 사망하기 때문일 가능성이 크다. 플레이 스타일의 제2 클러스터는 Explorer로 레이블이 지정된다: 이러한 경기에서, 스트리머는 - 다른 두 클러스터들에 비해 Delta Location 특징이 더 높기 때문에 - 맵을 훨씬 더 탐 색하지만 플레이어의 성능은 Kill 및 Being Killed 특징들에 의해 볼 수 있듯이 여전히 평균이다. 마지막으로, 세 번째 플레이 스타일은 스트리머가 최선을 다해 플레이한 경기를 특징으로 하는 Pro로 표기된다: 그는 다른 두 클러스터들에 비해 더 많은 플레이어를 죽이고 덜 자주 죽는 경향이 있으며 상당한 피해를 받지만 더 오래 생존하여(즉, 더 높은 시간 값) 경기에서 승리할 가능성이 가장 높다. 세 가지 플레이 스타일의 분포는 5명의 스트리머들과 다른 스트리머들이 보여주는 플레이 스타일의 변형에 걸쳐 찾을 수 있다. 이 분포를 적용하면 chocoTaco는 대부분의 Noob 경기와 적은 비율의 Pro 경기를 보여준다. 반면 에, sprEEZy는 Explorer 플레이어 유형에 더 가까운 것으로 보인다. Hambinooo, Danucd 및 Jeemzz는 게임플레 이에서 세 가지 플레이 스타일들의 보다 균일한 분포를 보여준다 세 가지 서로 다른 플레이 스타일들이 주어지면, 스트리머들 대신 별도의 플레이 스타일들을 기반으로 순간순간 참여 모델이 구축될 수 있다. 각 플레이 스타일에 대해 별도의 참여 모델이 훈련된다. 각 플레이 스타일 모델에 대해 미리 결정된 α 및 값들에 대한 철저한 검색이 사용되었다. 획득된 결과들을 비교하기 위해, 리브 원 스트리머 아웃 교차 검증 방식을 사용하여 모델들이 검증된다. 모든 모델들은 높은 정확도(평균 75% 이상)로 참 여를 예측하지만 Noob 플레이 스타일 모델은 Explorer 모델(평균 77%, 81.4%) 및 Pro 플레이 스타일(평균 75.4%, 최고 80.7%)보다 더 나은 성능(평균 78.8%, 최고 84.8%)을 수행한다. 이러한 예들은 여러 주요 게임플레 이 이벤트들에만 의존하고 표준 게임 원격측정을 기반으로 지속적인 방식으로 시청자 참여 레벨을 예측할 수 있 을 뿐만 아니라 -- 이러한 예측은 높은 레벨의 정확도로 수행될 수 있음을 시사한다. 이 예는 인기 있는 라이브 스트리밍 게임에서 특정 애플리케이션을 사용하여 게임 참여에 대한 지속적인 순간순 간 예측을 도입하여 게임 분석 기술을 개선한다. 획득된 참여 모델들은 시청자 참여와 플레이어 행동 사이의 기 능을 정확하게 학습할 수 있음을 나타내는 스트리머들 내 및 스트리머들 전반에 걸쳐 매우 정확하고 일반적이다. 도 14는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 특히, 방법은 도 1-2, 3a, 3b, 및 4-13과 관련하여 설명된 임의의 기능들 및 특징들로 사용하기 위해 제시된다. 전술한 내용은 사용자 경험을 모델링하고 예측하는 데 주로 중점을 두었지만, 개별적인 입력 양식들, 다수의 입력 양식들에 기초한 동기부여 및 행동들은 사용자 경험을 예측하고 및/또는 이에 제한되는 것은 아니나, 본원에 논의된 PCG 또는 BEA 툴을 포함하는 게임개발 플랫폼과 관련하여 설명된 기타 기능들 및 특징들 중 어느 하나를 수행하는 데 사용될 수 있다. 특히, 게임플레이 특징, 게임플레이 화면 픽셀 및/또는 게임 오디오와 같은 게임 원격측정 데이터를 포함하는 게임 데이터의 조합들은 예를 들어, 마이크를 통해 생성된 플레이어의 언어적 정보 수신 및/또는 예를 들 어 비디오 카메라 또는 기타 센서를 통해 생성된 플레이어의 비언어적 정보와 같은 멀티모드 플레이어 데이터를 포함한, 언어적 또는 비언어적 시청자 정보와 같은 플레이 데이터로 사용될 수 있다. 이러한 게임 데이터 및/또는 시청자 정보 및 행동과 멀티모드 플레이어 데이터의 조합은 플레이어의 경험에 대한 신뢰할 수 있고 범 용적인 예측자들을 생성하는 데 사용될 수 있다. 특히, 게임 데이터 및/또는 시청자 경험의 조합에 기반한 예측 모델들은 플레이어의 추가적인 언어적 및 비언어적 정보(예를 들어, 말, 얼굴 표정, 머리 자세 등)로 보완될 수 있다. 플레이어에 대한 이러한 추가 정보는 AI 모델들의 예측 능력을 높일 수 있다. 심층 선호 학습 및 기타 스 트림 기반 기계 학습 알고리즘과 결합된 서수적 감정 컴퓨팅의 방법들은 플레이어 동기부여, 플레이어 참여 및 기타 경험 상태를 더 높은 정확도로 예측하는 방법을 학습할 수 있다. 플레이어들의 멀티모드 데이터(예를 들어, 온라인 플랫폼을 통한 콘텐트 스트리밍)를 사용할 수 있게 되면, 이 정보를 게임플레이 특징들 및/또는 게임플레이의 픽셀 및 오디오와 융합하여 훨씬 더 정확한 플레이어 경험 모델을 도출할 수 있다. 단계는 프로세서를 포함하는 시스템을 통해, 기계 학습에 기초하여 행동 경험 분석(BEA) 툴을 생성하는 단계를 포함한다. 단계는 시스템을 통해, 게임 데이터 및 게임 애플리케이션의 플레이와 연관된 멀티모드 플레이어 데이터를 수신하는 단계를 포함한다. 단계는 시스템을 통해, BEA 툴을 게임 데이터 및 멀티모드 플레이어 데이터에 적용하여 예측된 사용자 경험을 생성하는 단계를 포함한다. 단계는 예측된 사용자 경 험에 기초하여 게임 애플리케이션의 적응을 용이하게 하는 단계를 포함한다. 다양한 실시예들에서, 기계 학습은 이전 게임 플레이와 연관된 복수의 플레이어 설문지들에 기초하고 이전 게임 플레이와 연관된 이전 게임 원격측정 데이터에 더 기초하여 훈련된 기계 학습 모델을 포함한다. 게임 데이터는, 플레이시간 데이터, 완료 데이터 또는 진행 데이터 중 적어도 하나를 포함할 수 있다. 게임 데이터는 다른 게임 데이터에 대한 클러스터링 분석을 통해 생성된 복수의 플레이어 유형들 중 하나의 표시를 포함할 수 있다. 시스 템은 게임 개발 애플리케이션을 더 포함하는 게임 개발 플랫폼을 통해 구현될 수 있으며, 게임 애플리케이션의 적응을 용이하게 하는 것은 게임 개발 애플리케이션을 통해 게임 애플리케이션의 적응을 용이하게 하는 것을 포 함한다. 게임 애플리케이션은 복수의 옵션 버전들을 포함할 수 있으며, 시스템은 게임 애플리케이션을 실행하는 게임 시스템을 통해 구현되고, 게임 애플리케이션의 적응을 용이하게 하는 것은 예측된 사용자 경험에 기초하여 복수의 옵션 버전들 중 하나를 선택하는 것을 포함한다. 게임 애플리케이션의 적응을 용이하게 하는 것은 플레 이어 불일치를 식별하는 것을 포함할 수 있다. 예측된 사용자 경험은 복수의 동기부여 요인들 각각에 대한 스코 어를 나타내는 동기부여 데이터 및/또는 예측된 플레이어 동기부여의 변화를 나타내는 시간이 지남에 따라 수집 된 동기부여 데이터를 포함할 수 있다. 게임 데이터는 게임 봇에 기초하여 생성될 수 있다. 게임 데이터는 게임 비디오와 연관된 픽셀 데이터를 포함할 수 있다. 비트 스트림, 스트림, 신호 시퀀스 등(또는 그 등가물)과 같은 본원에서 사용될 수 있는 용어들은 콘텐트가 원 하는 여러 유형(예를 들어, 데이터, 비디오, 음성, 텍스트, 그래픽, 오디오, 표정, 몸 자세, 시선 패턴, 자연어 등 일반적으로 '데이터'라고 하는 모든 것)에 대응하는 디지털 정보를 설명하기 위해 서로 교환 가능하게 사용 되었음에 유의한다. 본원에서 사용될 수 있는 바와 같이, \"실질적으로\" 및 \"대략적으로\"라는 용어들은 해당 용어 및/또는 항목 간의 상대성에 대해 산업별 허용오차를 제공한다. 일부 산업의 경우, 산업별 허용 오차는 1% 미만이고, 다른 산업의 경우 산업별 허용 오차는 10% 이상이다. 산업별 허용오차의 다른 예들은 1% 미만에서 50%까지이다. 산업별 허용 오차는, 이에 제한되는 것은 아니나, 구성 요소 값, 집적 회로 프로세스 변동, 온도 변동, 상승 및 하강 시간, 열 잡음, 치수, 시그널링 오류, 패킷 드롭, 온도, 압력, 재료 구성 및/또는 성능 메트릭에 대응한다. 산업 내에 서 허용되는 공차의 공차 편차는 백분율 레벨보다 크거나 작을 수 있다(예를 들어, +/- 1% 미만의 치수 공차). 아이템들 간의 일부 상대성은 백분율 레벨 미만의 차이에서 몇 퍼센트까지의 범위일 수 있다. 아이템들 간의 다 른 상대성은 몇 퍼센트의 차이에서 차이의 크기에 이르기까지 다양할 수 있다. 본원에서 사용될 수도 있는 바와 같이, \"~하도록 구성된\", \"~에 동작 가능하게 결합된\", \"~에 결합된\" 및/또는 \"결합\"이라는 용어들은 아이템 간의 직접 결합 및/또는 중간 아이템(예를 들어, 아이템은, 이에 제한되는 것은 아니나, 구성 요소, 요소, 회로 및/또는 모듈을 포함함)을 통한 아이템들 간의 간접 결합을 포함하며, 여기서 간접 결합의 예의 경우, 중간 아이템은 신호의 정보를 수정하지 않지만 신호의 전류 레벨, 전압 레벨 및/또는 전력 레벨을 조정할 수 있다. 본원에서 추가로 사용될 수 있는 바와 같이, 추론된 결합(즉, 하나의 요소가 추론에 의해 다른 요소에 결합되는 경우)은 \"~에 결합된\"과 동일한 방식으로 두 아이템들 간의 직접 및 간접 결합을 포함한다. 본원에서 더 사용될 수 있는 바와 같이, \"~하도록 구성된\", \"~에 동작 가능한\", \"~에 결합된\" 또는 \"~에 동작 가능하게 결합된\"이라는 용어들은 활성화 시, 하나 이상의 그 해당 기능들을 수행하도록 아이템이 전원 연결, 입력(들), 출력(들) 등 중 하나 이상을 포함하며 하나 이상의 다른 아이템들에 대한 추론된 결합을 더 포함할 수 있다는 것을 나타낸다. 본원에서 더 사용될 수 있는 바와 같이, \"~와 연관된\"이라는 용어는 별도의 아이템들 및/또는 하나의 아이템이 다른 아이템 내에 임베디드되는 직접 및/또는 간접 결합을 포함한다. 본원에서 사용될 수 있은 바와 같이, \"유리하게 비교하다\"라는 용어들은 둘 이상의 아이템들, 신호들 등을 비교 하여 원하는 관계를 제공한다는 것을 나타낸다. 예를 들어, 원하는 관계가 신호 1이 신호 2보다 큰 크기를 갖는 관계일 경우, 유리한 비교는 신호 1의 크기가 신호 2의 크기보다 큰 경우 또는 신호 2의 크기가 신호 1의 크기 미만인 경우 달성될 수 있다. 본원에서 사용될 수 있는 바와 같이, \"유리하지 않게 비교하다\"라는 용어는 둘 이 상의 아이템들, 신호들 등 간의 비교가 원하는 관계를 제공하지 못하는 것을 나타낸다. 본원에서 사용될 수 있는 바와 같이, 하나 이상의 청구범위는 이러한 일반 형태의 특정 형태로, \"a, b, 및 c 중 적어도 하나\"라는 문구를 포함하거나, 또는 \"a\", \"b\" 및 \"c\"보다 많거나 적은 요소가 있는 이 일반 형태의 \"a, b 또는 c 중 적어도 하나\"라는 문구를 포함할 수 있다. 어느 문구든, 문구는 동일하게 해석되어야 한다. 특히, \"a, b 및 c 중 적어도 하나\"는 \"a, b 또는 c 중 적어도 하나\"와 동일하며, a, b 및/도는 c를 의미할 것이다. 일 예로서, 이는 \"a\"만, \"b\"만, \"c\" 만, \"a\"와 \"b\", \"a\"와 \"c\", \"b\"와 \"c\" 및/또는 \"a\", \"b\" 및 \"c\"를 의미한다. 본원에서 또한 사용될 수 있는 바와 같이, \"처리 모듈\", \"처리 회로\", \"프로세서\", \"처리 회로부\", 및/또는 \"처 리 유닛\"이라는 용어들은 단일 처리 장치 또는 복수의 처리 장치들일 수 있다. 이러한 처리 장치는 마이크로프 로세서, 마이크로컨트롤러, 디지털 신호 프로세서, 마이크로컴퓨터, 중앙 처리 장치, 필드 프로그램 가능 게이 트 어레이, 프로그램 가능 로직 장치, 상태 머신, 로직 회로부, 아날로그 회로부, 디지털 회로부 및/또는 회로 부 및/또는 동작 인스트럭션들의 하드 코딩에 기초하여 신호들(아날로그 및/또는 디지털)을 조작하는 임의의 장 치일 수 있다. 처리 모듈, 모듈, 처리 회로, 처리 회로부, 및/또는 처리 유닛은 단일 메모리 장치, 복수의 메모 리 장치들, 및/또는 다른 처리 모듈, 모듈, 처리 회로, 처리 회로부, 및/또는 처리 유닛의 임베디드 회로부일 수 있는 메모리 및/또는 통합 메모리 요소일 수 있거나 이을 더 포함할 수 있다. 이러한 메모리 장치는 읽기 전 용 메모리, 랜덤 액세스 메모리, 휘발성 메모리, 비휘발성 메모리, 정적 메모리, 동적 메모리, 플래시 메모리, 캐시 메모리, 및/또는 디지털 정보를 저장하는 임의의 장치일 수 있다. 처리 모듈, 모듈, 처리 회로, 처리 회로 부 및/또는 처리 유닛이 하나 이상의 처리 장치를 포함하는 경우, 처리 장치들이 중앙에 위치(예를 들어, 유선 및/또는 무선 버스 구조를 통해 함께 직접 연결)될 수 있거나 또는 분산 위치(예를 들어, 근거리 통신망 및/또 는 광역 통신망을 통한 간접 결합을 통한 클라우드 컴퓨팅)될 수 있다. 처리 모듈, 모듈, 처리 회로, 처리 회로 부 및/또는 처리 유닛이 상태 머신, 아날로그 회로부, 디지털 회로부 및/또는 로직 회로부를 통해 기능들 중 하 나 이상을 구현하는 경우, 해당 동작 인스트럭션들을 저장하는 메모리 및/또는 메모리 요소는 상태 머신, 아날 로그 회로부, 디지털 회로부 및/또는 로직 회로부를 포함하는 회로부 내에 또는 외부에 임베디드될 수 있다. 또 한, 메모리 요소는 도면들 중 하나 이상에 예시된 단계들 및/또는 기능들의 적어도 일부에 대응하는 하드 코딩 된 및/또는 동작 인스트럭션들을 저장할 수 있고, 처리 모듈, 모듈, 처리 회로, 처리 회로부 및/또는 처리 유닛 은 이를 실행한다는 점에 유의한다. 이러한 메모리 장치 또는 메모리 요소는 제조 물품에 포함될 수 있다. 하나 이상의 실시예들은 특정 기능들의 수행 및 이들의 관계를 예시하는 방법 단계들의 도움으로 상기에 설명되 었다. 이러한 기능적 빌딩 블록 및 방법 단계들의 한계들 및 순서들은 설명의 편의를 위해 본원에서 임의로 정 의되었다. 대안적인 한계들 및 시퀀스들은 지정된 기능들과 관계들이 적절하게 수행되는 한 정의될 수 있다. 따 라서 이러한 대안적인 한계들 또는 시퀀스들은 청구 범위의 범위 및 정신 내에 있다. 또한, 이러한 기능적 빌딩 블록의 한계들은 설명의 편의를 위해 임의로 정의되었다. 대안적인 한계들은 특정 중요한 기능들이 적절하게 수 행되는 한 정의할 수 있다. 마찬가지로, 흐름도 블록들은 특정 중요한 기능을 설명하기 위해 본원에서 임의로 정의될 수도 있다. 사용된 범위 내에서, 흐름도 블록 한계들 및 시퀀스들은 다르게 정의되어도 여전히 특정 중요한 기능을 수행할 수 있다. 따라서, 기능적 빌딩 블록과 흐름도 블록들 및 시퀀스 모두에 대한 이러한 대안적인 정의들은 청구범 위의 범위 및 정신 내에 있다. 당업자는 또한 기능적 빌딩 블록들, 및 본원의 다른 예시적인 블록들, 모듈들 및 구성요소들이 예시된 바와 같이 또는 개별 구성요소들, 애플리케이션별 집적 회로들, 적절한 소프트웨어를 실행하는 프로세서들 등 또는 그 임의의 조합에 의해 구현될 수 있음을 인식할 것이다. 추가로, 흐름도는 \"시작\" 및/또는 \"계속\" 표시를 포함할 수 있다. \"시작\" 및 \"계속\" 표시는 제시된 단계들이 선 택적으로 하나 이상의 다른 루틴들에 통합되거나 아니면 이와 함께 사용될 수 있음을 반영한다. 추가로, 흐름도 는 \"종료\" 및/또는 \"계속\" 표시를 포함할 수 있다. \"종료\" 및/또는 \"계속\" 표시는 제시된 단계가 설명 및 도시 된 대로 종료될 수 있거나 선택적으로 하나 이상의 다른 루틴들에 통합되거나 아니면 하나 이상의 다른 루틴들 과 함께 사용될 수 있음을 반영한다. 이러한 맥락에서, \"시작\"은 제시된 첫 번째 단계의 시작을 나타내며 구체 적으로 표시되지 않은 다른 활동들에 의해 선행될 수 있다. 또한, \"계속\" 표시는 제시된 단계들이 여러 번 수행 될 수 있고/있거나 구체적으로 표시되지 않은 다른 활동들에 의해 계속될 수 있음을 반영한다. 또한, 흐름도는 단계의 특정 순서를 나타내지만, 인과성의 원칙이 유지된다면 다른 순서도 마찬가지로 가능하다. 하나 이상의 실시예들은 하나 이상의 양태들, 하나 이상의 특징들, 하나 이상의 개념들, 및/또는 하나 이상의 예들을 예시하기 위해 본원에서 사용된다. 장치, 제조 물품, 기계, 및/또는 프로세스의 물리적 실시예는 본원에 논의된 실시예들 중 하나 이상을 참조하여 설명된 양태들, 특징들, 개념들, 예들 등 중 하나 이상을 포함할 수 있다. 또한, 도면들에 걸쳐, 실시예들은 동일하거나 상이한 참조 번호를 사용할 수 있는 동일하거나 유사하게 명명된 기능들, 단계들, 모듈들 등을 통합할 수 있으며, 따라서 기능들, 단계들, 모듈들 등은 동일하거나 유사 한 기능들, 단계들, 모듈들 등 또는 다른 것들일 수 있다. 반대 의견으로 구체적으로 언급되지 않는 한, 본원에 제시된 도면들 중 임의의 도면의 요소들에 대한 신호들, 요소들로부터의 신호들 및/또는 요소둘 사이의 신호들은 아날로그 또는 디지털, 연속 시간 또는 이산 시간, 단 일 종단 또는 차동일 수 있다. 예를 들어, 신호 경로가 단일 종단 경로로 표시되면, 이는 차동 신호 경로도 나 타난다. 마찬가지로, 신호 경로가 차동 경로로 표시되면, 이는 단일 종단 신호 경로도 나타난다. 하나 이상의 특정 아키텍처들이 본원에 설명되어 있지만, 명시적으로 나타내지 않은 하나 이상의 데이터 버스, 요소 간의 직 접 연결, 및/또는 당업자에 의해 인식되는 바와 같이 다른 요소 간의 간접 결합을 사용하는 다른 아키텍처들도 마찬가지로 구현될 수 있다. \"모듈\"이라는 용어는 하나 이상의 실시예들의 설명에 사용된다. 모듈은 프로세서 또는 기타 처리 장치 또는 동 작 인스트럭션들을 저장하는 메모리를 포함하거나 이와 관련하여 동작할 수 있는 기타 하드웨어와 같은 장치를 통해 하나 이상의 기능들을 구현한다. 모듈은 독립적으로 및/또는 소프트웨어 및/또는 펌웨어와 함께 동작할 수 있다. 또한 본원에 사용된 바와 같이, 모듈은 하나 이상의 서브 모듈들을 포함할 수 있으며, 그 각각은 하나 이 상의 모듈들일 수 있다. 본원에서 더 사용될 수 있는 바와 같이, 컴퓨터 판독가능 메모리는 하나 이상의 메모리 요소들을 포함한다. 메 모리 요소는 개별 메모리 장치, 다수의 메모리 장치들, 또는 메모리 장치 내의 메모리 위치 세트일 수 있다. 이 러한 메모리 장치는 읽기 전용 메모리, 랜덤 액세스 메모리, 휘발성 메모리, 비휘발성 메모리, 정적 메모리, 동 적 메모리, 플래시 메모리, 캐시 메모리, 및/또는 디지털 정보를 저장하는 임의의 장치일 수 있다. 메모리 장치 는 솔리드 스테이트 메모리, 하드 드라이브 메모리, 클라우드 메모리, 썸 드라이브, 서버 메모리, 컴퓨팅 장치 메모리, 및/또는 디지털 정보를 저장하기 위한 기타 물리적 매체의 형태일 수 있다. 하나 이상의 실시예들의 다양한 기능들 및 특징들의 특정 조합들이 본원에서 명시적으로 설명되었지만, 이러한 특징들 및 기능들의 다른 조합들도 마찬가지로 가능하다. 본 개시는 본원에 개시된 특정 예들에 의해 제한되지 않으며, 이러한 다른 조합들을 명시적으로 통합한다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12a 도면12b 도면12c 도면13a 도면13b 도면14"}
{"patent_id": "10-2021-7032290", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 게임 개발 시스템의 그림/블록도 표현을 나타낸다. 도 2는 본 개시의 일 실시예에 따른 게임 개발 플랫폼의 블록도 표현을 나타낸다. 도 3a는 본 개시의 일 실시예에 따른 게임 개발 파이프라인의 흐름/블록도 표현을 나타낸다. 도 3b는 본 개시의 일 실시예에 따른 일반 경험 페르소나의 구성요소의 흐름/블록도 표현을 나타낸다. 도 4는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 도 5는 본 개시의 일 실시예에 따른 게임 원격측정 데이터의 그래픽 표현을 나타낸다. 도 6은 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 도 7은 볼 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 도 8은 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 도 9는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 도 10은 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 도 11은 본 개시의 일 실시예에 따른 CNN 아키텍쳐의 블록도 표현을 나타낸다. 도 12a는 본 개시의 일 실시예에 따른 비디오 프레임의 이미지 표현을 나타낸다.도 12b 및 12c는 본 개시의 일 실시예에 따른 활성화 맵을 나타낸다. 도 13a는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다. 도 13b는 본 개시의 일 실시예에 따른 비디오 프레임의 이미지 표현을 나타낸다. 도 14는 본 개시의 일 실시예에 따른 방법의 흐름도 표현을 나타낸다."}
