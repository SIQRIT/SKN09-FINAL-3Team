{"patent_id": "10-2021-0152177", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0066797", "출원번호": "10-2021-0152177", "발명의 명칭": "화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법, 그 방법을 이용한 컴퓨터 프로그램", "출원인": "(주)에어사운드", "발명자": "백민호"}}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자단말기 또는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치로부터 실행된 관리 프로그램을 통하여 텍스트 변환을 위한 음성 데이터를 입력받는 단계;상기 관리 프로그램은 사용자 요청된 음성 데이터에 대하여 화자를 분리하여 STT 변환에 의해 텍스트 결과를 추출하는 단계;상기 관리 프로그램은 사용자 요청시 해당 텍스트 결과를 실시간 화면에 자막 형태로 디스플레이하는 단계;상기 관리 프로그램은 사용자에 의해 문서 생성 요청시 STT 변환을 수행하여 화자별 텍스트를 추출하고, 추출된텍스트에 대한 문서를 생성하는 단계;를 포함하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 관리 프로그램은 대기열(Queue)에 저장해둔 음성 데이터를 가져와서 마지막 데이터까지 순차적으로 음성데이터를 분석하고, 분석된 음성 데이터로부터 텍스트를 추출하여 화면상에 실시간 자막 형태로 표시하되,음성파일에는 녹음된 음성에 대한 시간정보를 포함하고 있어, 각 시간 구간마다 발화된 음성을 체크하여 STT 변환하여 발화된 내용을 텍스트로 추출하는 것을 특징으로 하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성방법."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 관리 프로그램은 음성 데이터를 복수개를 음성인식 버퍼에 입력하여 대기열(Queue)에 저장해둔 음성 데이터에 따라 발화점을 검출하여 음성을 텍스트로 변환하되,상기 발화점 검출(체크)시, 음성파일에서 STT 변환시 불필요한 잡음을 제거하도록 음성 주파수 대역의 평균치(RMS)를 구해 가장 큰 대역의 소리만을 취하여 STT 변환을 수행하는 것을 특징으로 하는 화자 음성 분리에 의한실시간 자막 및 문서 생성 방법."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 관리 프로그램은 복수의 마이크에 대한 음성 인식시 동시간대에 음성의 주파수 대역 체크를 통하여 복수의발화한 구간이 있는지를 체크하고, 복수의 발화한 구간에 대해서는 별도의 음성으로 분리하고 추출하여 해당 구간에 대해 STT 변환을 각각 수행하는 것을 특징으로 하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 관리 프로그램은 사용자 요청시 생성된 문서를 열람하여 확인할 수 있도록 제공하며, 문서 편집, 일부 삭제 기능을 통하여 사용자가 직접 문서를 관리할 수 있도록 서비스를 제공하는 단계;상기 관리 프로그램은 사용자 요청시 유무선 통신망에 연결된 관리서버의 데이터베이스에 저장하여 관리하는 단계공개특허 10-2023-0066797-3-를 더 포함하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법을 수행하는 컴퓨터에서 판독 가능한 저장매체에 기록된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제5항 중 어느 한 항의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법을 이용한 실시간 자막 및 문서 생성 장치에 있어서, 입력된 음성 신호에 대하여 화자를 분리하여 STT 변환을 수행한 후 사용자 요청시 실시간 자막을 표시하거나 문서를 생성하며, 문서 내용을 사용자에 의해 수정 및 관리할 수 있는 관리 프로그램을 포함하는 것을 특징으로하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 마이크가 연결되어 음성 신호에 해당하는 음성 신호를 수집하기 위한 마이크 인터페이스를 구비하는 연결부; 사용자 입력에 의해 상기 관리 프로그램을 실행시키고 제어하여 음성 신호를 입력받아 음성 신호에 대한 문서를생성하기 위한 상호작용 인터페이스로 제공하는 입력부; 상기 음성에 대해 텍스트 변환을 수행하고, 변환에 의해 추출된 텍스트를 실시간 자막 형태로 표시하거나 자막을 모아 문서 파일을 생성하는 생성부; 사용자 요청시 상기 생성부로부터 생성된 문서 파일을 열람하여 문서의 수정 또는 삭제 기능을 제공하는 관리부 를 포함하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 관리 프로그램을 디스플레이하고, 사용자가 상기 입력부를 통하여 관리 프로그램을 조작하여 문서 생성 및편집 기능들을 수행할 수 있도록 화면상에 표시하는 표시부; 를 더 포함하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는유무선통신망을 통하여 연결된 관리서버로부터 최초에 관리 프로그램을 다운받거나, 생성된 문서를 웹기반 저장및 관리하기 위해 관리서버와 통신하는 연동부를 더 포함하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 연결부는 상기 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 내부 입력부 또는 표시부를 대신하여 관리 프로그램을 실행시켜, 보조적으로 사용하기 위해 사용자단말기 또는 표시장치와 연결하기 위한 유무선 인터페이스를더 포함하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2023-0066797-4-제8항에 있어서,상기 생성부는 다양한 언어의 음성에 대한 텍스트 변환을 위해 하나 이상의 음성인식모델이 포함되며, 다국어를 지원하기 위한 다국어 음성인식모델, 지방 사투리를 인식하기 위한 음성인식모델이 포함되어, 다국어음성인식모델의 경우 입력된 음성에 대해 사용자가 선택한 원하는 언어로 혹은 설정된 언어도 자동 번역에 의해변환되도록 할 수 있는 것을 특징으로 하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제7항에 있어서,상기 관리 프로그램은 음성 데이터를 복수개를 음성인식 버퍼에 입력하여 대기열(Queue)에 저장해둔 음성 데이터에 따라 발화점을 검출하여 음성을 텍스트로 변환하되,상기 발화점 검출(체크)시, 음성파일에서 STT 변환시 불필요한 잡음을 제거하도록 음성 주파수 대역의 평균치(RMS)를 구해 가장 큰 대역의 소리만을 취하여 STT 변환을 수행하는 것을 특징으로 하는 화자 음성 분리에 의한실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 관리 프로그램은 복수의 마이크에 대한 음성 인식시 동시간대에 음성의 주파수 대역 체크를 통하여 복수의발화한 구간이 있는지를 체크하고, 복수의 발화한 구간에 대해서는 별도의 음성으로 분리하고 추출하여 해당 구간에 대해 STT 변환을 각각 수행하는 것을 특징으로 하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치."}
{"patent_id": "10-2021-0152177", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법은, 사용자단말기 또는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치로부터 실행된 관리 프로그램을 통하여 텍스트 변환을 위한 음 성 데이터를 입력받는 단계; 상기 관리 프로그램은 사용자 요청된 음성 데이터에 대하여 화자를 분리하여 STT 변 환에 의해 텍스트 결과를 추출하는 단계; 상기 관리 프로그램은 사용자 요청시 해당 텍스트 결과를 실시간 화면 에 자막 형태로 디스플레이하는 단계; 상기 관리 프로그램은 사용자에 의해 문서 생성 요청시 STT 변환을 수행하 여 화자별 텍스트를 추출하고, 추출된 텍스트에 대한 문서를 생성하는 단계;를 포함한다."}
{"patent_id": "10-2021-0152177", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 및 방법에 관한 것으로, 더욱 상세하게는 복 수의 마이크로부터 개별적으로 음성 신호를 수집하고, 녹음된 음성에 대한 STT(Speech To Text) 변환을 수행하 여 구간별 실시간 자막 생성 및 문서를 생성하는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 및 이 를 이용한 문서 관리 방법에 관한 것이다."}
{"patent_id": "10-2021-0152177", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 다양한 분야에서 음성 데이터를 텍스트로 변환하여 활용할 수 있는 기술이 개발되고 있다. 특히, 비대면이 필요한 환경을 비롯하여 회의 내용을 기록할 필요가 있는 상황 등 여러 여건으로 인하여, 구성 원들 사이에 활발한 커뮤니케이션에 대한 음성 회의를 자동으로 기록하기 위한 문서 시스템이 있다. 또한 문서 시스템에서는 진행 중인 회의 기록을 데이터베이스에 저장하고, 회의 기간이 종료되면 회의 진행자가 회의 결과의 데이터를 모바일 서버 및 웹서버의 회의 결과창에 표시함과 동시에 데이터베이스에 저장할 수 있도 록 할 필요가 있다. 기존 문서 시스템 서비스의 경우, 사용자가 녹음된 회의 내용(음성 파일)을 서버에 별도로 업로드한 이후 변환 된 텍스트 파일을 제공받는 형태로 구성되어 있으며, 이를 위해선 네트워크 연결이 필수적이다. 또한, 대화 내용을 실시간으로 문자로 변환하여 기록하는 기능을 제공하고 있으며, 기록이 완료된 이후 별도의 후처리 과정을 진행하여 화자가 분리된 대화 기록을 제공하는 형태로 구현되어 있다. 또한 별도의 마이크가 구성되어 있지 않아 사용자가 대화 내용을 녹음하기 위해 사용하는 마이크의 종류, 사용 자와 마이크 간의 거리 등과 같은 여러 환경적 요소에 따라 변환된 텍스트 결과의 품질이 상이하게 되는 문제가 있다. 더욱이 마이크로 입력된 음성들을 병합하여 하나의 음성 데이터를 생성하고, 음성 분리 과정을 통하여 화자를 구분하고 음성에 대한 텍스트를 추출하기 때문에, 음성 분리 과정에서 음성 인식율이 현저히 떨어지고, 화자들 이 동시에 발화하는 경우에는 큰 소리에 대해서만 분리해내고 작은 소리는 잡음으로 오인식되어 화자별 정확한 음성 인식 및 분리에 의한 텍스트 추출이 이루어지지 못해 제대로 된 문서를 생성하기 어려운 문제가 있었다. 또한, 다양한 동영상 서비스 플랫폼에서는 동영상에 대한 자막 기능이 포함되지 않는 경우가 있으며, 다국어를 지원하지 않는 경우도 있어서, 별도로 사용자가 외국 영상 등을 시청하기 위해서는 자막 생성이 필요한 경우가 있어서 불편한 문제가 있었다. 따라서, 전술한 문제를 해결하기 위하여 음성 신호에 대한 화자별로 구분하여 음성에 대한 텍스트를 추출하여 실시간 자막 형태로 표시함과 아울러, 자막들을 병합한 하나의 문서를 생성할 수 있으며, 문서에 대한 편집 등 각종 관리 기능을 제공할 수 있는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법에 대한 연구가 필요하 게 되었다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1995443호(2019.06.26. 등록) (특허문헌 0002) 한국등록특허 제10-1973158호(2019.04.22. 등록)"}
{"patent_id": "10-2021-0152177", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 독립된 마이크로 구분하여 음성 신호에 대한 음성 파일을 생성하고, 화자별로 구분하여 음성 에 대한 텍스트를 추출하여 실시간 자막을 표시함과 아울러, 자막들을 화자별로 분리하여 병합한 하나의 문서를 생성할 수 있으며, 문서에 대한 편집 등 각종 관리 기능을 제공할 수 있는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2021-0152177", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법은, 사용자단말기 또는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치로부터 실행된 관리 프로그램을 통하여 텍스트 변환을 위한 음 성 데이터를 입력받는 단계; 상기 관리 프로그램은 사용자 요청된 음성 데이터에 대하여 화자를 분리하여 STT 변환에 의해 텍스트 결과를 추출하는 단계; 상기 관리 프로그램은 사용자 요청시 해당 텍스트 결과를 실시간 화 면에 자막 형태로 디스플레이하는 단계; 상기 관리 프로그램은 사용자에 의해 문서 생성 요청시 STT 변환을 수 행하여 화자별 텍스트를 추출하고, 추출된 텍스트에 대한 문서를 생성하는 단계;를 포함한다. 상기 관리 프로그램은 대기열(Queue)에 저장해둔 음성 데이터를 가져와서 마지막 데이터까지 순차적으로 음성 데이터를 분석하고, 분석된 음성 데이터로부터 텍스트를 추출하여 화면상에 실시간 자막 형태로 표시하되, 음성 파일에는 녹음된 음성에 대한 시간정보를 포함하고 있어, 각 시간 구간마다 발화된 음성을 체크하여 STT 변환하 여 발화된 내용을 텍스트로 추출하는 것을 특징으로 한다. 상기 관리 프로그램은 음성 데이터를 복수개를 음성인식 버퍼에 입력하여 대기열(Queue)에 저장해둔 음성 데이 터에 따라 발화점을 검출하여 음성을 텍스트로 변환하되, 상기 발화점 검출(체크)시, 음성파일에서 STT 변환시 불필요한 잡음을 제거하도록 음성 주파수 대역의 평균치(RMS)를 구해 가장 큰 대역의 소리만을 취하여 STT 변환 을 수행하는 것을 특징으로 한다. 상기 관리 프로그램은 복수의 마이크에 대한 음성 인식시 동시간대에 음성의 주파수 대역 체크를 통하여 복수의 발화한 구간이 있는지를 체크하고, 복수의 발화한 구간에 대해서는 별도의 음성으로 분리하고 추출하여 해당 구 간에 대해 STT 변환을 각각 수행하는 것을 특징으로 한다. 상기 관리 프로그램은 사용자 요청시 생성된 문서를 열람하여 확인할 수 있도록 제공하며, 문서 편집, 일부 삭 제 기능을 통하여 사용자가 직접 문서를 관리할 수 있도록 서비스를 제공하는 단계; 상기 관리 프로그램은 사용 자 요청시 유무선 통신망에 연결된 관리서버의 데이터베이스에 저장하여 관리하는 단계를 더 포함한다.상기 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법은 컴퓨터에서 판독 가능한 저장매체에 기록된 컴퓨 터 프로그램에 의해 수행될 수 있다. 본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 입력된 음성 신호에 대하 여 화자를 분리하여 STT 변환을 수행한 후 사용자 요청시 실시간 자막을 표시하거나 문서를 생성하며, 문서 내 용을 사용자에 의해 수정 및 관리할 수 있는 관리 프로그램을 포함하는 것을 특징으로 한다. 상기 장치는 마이크가 연결되어 음성 신호에 해당하는 음성 신호를 수집하기 위한 마이크 인터페이스를 구비하 는 연결부; 사용자 입력에 의해 상기 관리 프로그램을 실행시키고 제어하여 음성 신호를 입력받아 음성 신호에 대한 문서를 생성하기 위한 상호작용 인터페이스로 제공하는 입력부; 상기 음성에 대해 텍스트 변환을 수행하고, 변환에 의해 추출된 텍스트를 실시간 자막 형태로 표시하거나 자막을 모아 문서 파일을 생성하는 생 성부; 사용자 요청시 상기 생성부로부터 생성된 문서 파일을 열람하여 문서의 수정 또는 삭제 기능을 제공하는 관리부 를 포함한다. 상기 장치는 상기 관리 프로그램을 디스플레이하고, 사용자가 상기 입력부를 통하여 관리 프로그램을 조작하여 문서 생성 및 편집 기능들을 수행할 수 있도록 화면상에 표시하는 표시부; 를 더 포함한다. 상기 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 유무선통신망을 통하여 연결된 관리서버로부터 최초에 관리 프로그램을 다운받거나, 생성된 문서를 웹기반 저장 및 관리하기 위해 관리서버와 통신하는 연동부 를 더 포함한다. 상기 연결부는 상기 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 내부 입력부 또는 표시부를 대신 하여 관리 프로그램을 실행시켜, 보조적으로 사용하기 위해 사용자단말기 또는 표시장치와 연결하기 위한 유무 선 인터페이스를 더 포함한다. 상기 생성부는 다양한 언어의 음성에 대한 텍스트 변환을 위해 하나 이상의 음성인식모델이 포함되며, 다국어 를 지원하기 위한 다국어 음성인식모델, 지방 사투리를 인식하기 위한 음성인식모델이 포함되어, 다국어 음성인 식모델의 경우 입력된 음성에 대해 사용자가 선택한 원하는 언어로 혹은 설정된 언어도 자동 번역에 의해 변환 되도록 할 수 있는 것을 특징으로 한다. 상기 관리 프로그램은 음성 데이터를 복수개를 음성인식 버퍼에 입력하여 대기열(Queue)에 저장해둔 음성 데이 터에 따라 발화점을 검출하여 음성을 텍스트로 변환하되, 상기 발화점 검출(체크)시, 음성파일에서 STT 변환시 불필요한 잡음을 제거하도록 음성 주파수 대역의 평균치(RMS)를 구해 가장 큰 대역의 소리만을 취하여 STT 변환 을 수행하는 것을 특징으로 한다. 상기 관리 프로그램은 복수의 마이크에 대한 음성 인식시 동시간대에 음성의 주파수 대역 체크를 통하여 복수의 발화한 구간이 있는지를 체크하고, 복수의 발화한 구간에 대해서는 별도의 음성으로 분리하고 추출하여 해당 구 간에 대해 STT 변환을 각각 수행하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0152177", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법은 독립된 채널로 화자별 음성 신호를 수신하 고, 화자 분리에 의해 구분된 음성 신호에 대하여 음성파일을 생성하기 때문에 음성 인식율이 향상되고, 혼합된 음성 신호를 분리하는 과정이 불필요하며, 음성으로부터 텍스트 추출시 음성에 대한 텍스트 변환이 잘 수행되는 장점이 있다. 또한 동시에 복수의 화자가 발언을 하는 경우, 기존의 동시 녹음 후 분리 추출하는 음성 텍스트 변환 시스템은 큰 소리만 구분하여 화자의 발언을 추출하기 때문에, 소리가 작은 화자의 경우 음성에 대한 텍스트 추출이 어려 운 반면, 본 발명에서는 동시에 복수의 화자가 발언하더라도 중첩된 화자의 음성을 분리하여 STT 변환시 구분하 여 텍스트를 추출하도록 함으로써, 각 화자에 대한 대화를 빠짐없이 추출하여 실시간 자막 및 문서를 생성시킬 수 있는 장점이 있다. 또한 본 발명은 생성된 문서에 대한 편집, 삭제를 포함한 관리 기능을 제공하며, 웹 기반으로도 문서 생성 및 관리 서비스를 제공할 수 있어 사용자 편의성을 제공하는 장점이 있다."}
{"patent_id": "10-2021-0152177", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명의 구체적인 실시예를 상세하게 설명한다. 다만, 본 발명의 사상은 제시되 는 실시예에 제한되지 아니하고, 본 발명의 사상을 이해하는 당업자는 동일한 사상의 범위 내에서 다른 구성요 소를 추가, 변경, 삭제 등을 통하여, 퇴보적인 다른 발명이나 본 발명 사상의 범위 내에 포함되는 다른 실시예 를 용이하게 제안할 수 있을 것이나, 이 또한 본원 발명 사상 범위 내에 포함된다고 할 것이다. 또한, 각 실시 예의 도면에 나타나는 동일한 사상의 범위 내의 기능이 동일한 구성요소는 동일한 참조부호를 사용하여 설명한 다. 도 1은 본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법의 전체 과정을 보인 순서도이다. 본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 또는 화자 음성 분리 에 의한 실시간 자막 및 문서 생성 프로그램을 이용한 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법은, 관리 프로그램을 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치에 실행하거나 사용 자단말기에 실행하고, 사용자 인증을 위한 로그인 화면을 제공할 수 있다(S100). 사용자단말기에서 실행되는 관리 프로그램은 사용자단말기에 설치되어 관리서버와 연동하도록 실행되는 프로그램이거나, 관리서버에서 웹기반 또는 모바일 기반 서비스 형태로 제공되는 프로그램이 될 수 있 다. 또한 본 발명의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치에 내장형으로 관리 프로그램 이 탑재될 수도 있으며, 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 세부 구성 및 기능에 대 한 구체적 설명은 후술한다.관리 프로그램은 로그인 후 자막 및 문서화를 원하는 음성 데이터를 입력받을 수 있다(S100, S102). 여기서, 음성 데이터는 여러 가지 상황에 따라 입력될 수 있는데, 예를 들어 온라인/오프라인 화상 회의시 마이 크로부터 입력되는 음성 데이터, 온라인 수업시 선생님의 음성 데이터, 온라인/오프라인 각종 동영상이나 음성 에 대한 실시간 자막 생성을 위한 음성 데이터 등이 될 수 있다. 관리 프로그램은 사용자 요청된 음성 데이터에 대하여 화자를 분리하여 STT 변환을 수행하여 텍스트 결과 를 추출하고, 해당 텍스트 결과를 실시간 화면에 자막 형태로 디스플레이할 수 있다(S103). 이때 화자 분리에 의한 음성 텍스트 추출 알고리즘은 복수의 마이크로 부터 수집된 음성에 대하여 음성 파 일의 싱크 처리를 수행하고, 동시 발화된 화자의 음성에 대해 분리하여 추출하기 위한 알고리즘이다. 또한, 관리 프로그램은 사용자 요청시 화자별로 구분된 자막을 모두 병합하여 하나의 문서로 생성하여 제 공할 수 있으며, 음성 포맷의 화자별 음성파일을 생성시켜 제공할 수도 있다(S104). 이때, 관리 프로그램은 생성된 음성파일의 지연시간으로 인한 시작시간 동기화 및 음성 잡음 제거를 위한 싱크 프로세스 실행시킨 후, STT 변환 및 문서 생성을 위해 각 음성파일을 하나의 병합 파일로 생성시킬 수 있 다. 또한 관리 프로그램은 사용자에 의해 문서 생성 요청시 STT 변환을 수행하여 화자별 텍스트를 추출하고, 추출된 텍스트를 한데 모아 공지의 문서 포맷 형태로 된 하나의 문서를 생성시키게 된다. 즉, 상기 음성파일의 모든 음성에 대하여 STT 변환에 의한 텍스트 추출 후 문서를 생성시키게 된다. 만약 음성 데이터가 화상 회의에 대한 데이터라면 생성되는 문서는 회의록 형태가 될 수 있다. 또한, 관리 프로그램은 생성된 문서를 열람하여 확인할 수 있도록 제공하며, 문서 편집, 일부 삭제 기능을 통하여 사용자가 직접 문서를 관리할 수 있도록 서비스를 제공한다(S105). 이때, 문서 편집 및 삭제 기능은 회원마다 별도의 권한을 부여하여 한정적 권한으로 제한된 서비스를 제공할 수 있도록 하여, 무단으로 도용하거나 악의적인 문서 편집 및 삭제를 방지하는 것이 바람직하다. 이를 위해 문서를 관리서버의 데이터베이스에 저장 및 관리할 수도 있다(S106). 나아가, 생성 또는 편집 완료된 문서는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 내부 메 모리나, 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치에 연결된 사용자단말기에 저장하거나, 요청시 관리서버에 웹상의 블록체인 기반으로 보안 처리되어 데이터베이스에 저장 및 주 기적으로 편집된 문서를 갱신할 수도 있다. 블록체인 기반 관리를 위해 다수의 블록체인서버(미도시)와 연계하여 블록체인망을 구축하고, 기구축된 내부의 블록체인 네트워크를 통해 공개키 및 개인키를 생성하여 해쉬값으로 변환하여 분산 저장하고, 분산 저장된 공개 키와 사용자의 개인정보를 기반으로 사용자 인증을 수행할 수 있다. 도 2는 도 1의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법에서 싱글 채널 마이크에 대한 음성 인식 및 실시간 자막 생성/표시 기능에 대한 세부 과정을 보인 순서도이다. 먼저, 마이크로부터 음성 데이터를 기록하면 마이크 녹음 스레드를 생성하고, STT 엔진 프로세스 및 음성인식 객체를 생성할 수 있다(S200, S202, S204). 또한 녹음이 종료된 경우 해당 음성파일들에 대한 싱크 처리를 수행할 수 있으며, 싱크 처리는 해당 음성파일이 개별적으로 녹음 처리되어 시작시간에 약간의 지연시간이 포함되어 있어 시작시간을 동기화하고, 마이크의 하울링 등 잡음 제거를 위한 것이다. 또한, 음성 데이터를 텍스트로 변환시 사용자가 정의한 언어(예컨대 선호 언어, 자주쓰는 문구 등)에 대한 가중 치가 있다면 연결하여 텍스트 변환시 가중치를 고려하여 이루어질 수 있다(S206). 이후, 관리 프로그램 상에서 텍스트 변환 과정은 대기열(Queue)에 저장해둔 오디오(음성) 데이터를 가져와서 마 지막 데이터까지 순차적으로 음성 데이터를 분석하고, 분석된 음성 데이터로부터 텍스트를 추출하여 화면상에 실시간 자막 형태로 표시할 수 있다(S208, S210, S218). 이때, 음성파일에는 녹음된 음성에 대한 시간정보를 포함하고 있어, 각 시간 구간마다 발화된 음성을 체크하여 STT 변환하여 발화된 내용을 텍스트로 추출할 수 있다.구체적으로 도 8 및 도 10을 참조하면, 회의시 마이크를 통하여 입력된 음성의 실시간 텍스트 변환, 화면 표시 및 문서 생성 화면을 도시하고 있으며, 참가자(화자)별로 구부되어 사용자단말기의 화면에 실시간 표시될 수 있으며, 이후 문서화하여 별도의 리스트를 통하여 문서들을 확인하고 편집도 수행할 수 있다. 또한, 도 9를 참조하면, 시간정보를 고려하여 동영상 데이터에 포함된 음성 데이터에 대해서 실시간 자막 표시 기능을 제공시에는 동영상 내 시간정보와 동기화하여 해당 동영상 구간에 대응하여 실시간 변환된 텍스트 자막 이 표시되도록 한다. 또한, 오디오 데이터는 복수 개를 음성인식 버퍼에 입력하여 발화점을 검출하여 음성에 텍스트를 변환할 수 있 으며, 발화점이 검출되지 않는 경우 시간상 현재 결과와 직전 결과가 같은지 여부에 따라 음성구간 동일 여부를 판단하고, 같은 경우에는 음성인식 결과를 버리게 된다(S214, S216, S220, S222). 특히 발화점 체크시, 음성파일에서 STT 변환시 불필요한 잡음(예 : 옆자리 화자의 목소리 등)을 제거하도록 음 성 주파수 대역의 평균치(RMS)를 구해 가장 큰 대역의 소리(해당 대역의 음원에 추출하기 위한 식별용 인덱스 부여)만을 취하여 STT 변환을 수행하도록 한다. 또한 대기열에서 가져온 데이터가 마지막 데이터인 경우, 해당 오디오 데이터에 대한 음성 텍스트 변환 종료하 고 텍스트와 별개로 복수의 음성 데이터에 대해서 하나의 음성 파일(wave file)로 생성하여 사용자에게 제공해 줄 수 있다(S212). 즉, n개의 음성파일을 하나의 문서 생성을 위해 병합이 필요한 경우, 하나의 음성파일로 병합할 수 있다. 도 3a, 도 3b, 도 3c는 도 1의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법에서 멀티 채널 마이크에 대한 복수의 음성 인식 및 실시간 자막 생성/표시 기능에 대한 세부 과정을 보인 순서도이다. 먼저 멀티 채널인 복수의 마이크로부터 음성 데이터를 기록하면 마이크 녹음 스레드를 생성하고, STT 엔진 프로 세스 및 음성인식 객체를 생성할 수 있다(S302~S304). 그리고, 음성 데이터를 텍스트로 변환시 사용자가 정의한 언어(예컨대 선호 언어, 자주 쓰는 문구 등)에 대한 가중치가 있다면 연결하여 텍스트 변환시 가중치를 고려하여 이루어질 수 있다(S306). 본 발명에서 멀티 채널의 복수의 마이크에 대한 음성 인식시 동시간대에 음성의 주파수 대역 체크를 통하여 복 수의 발화한 구간이 있는지를 체크하고, 복수의 발화한 구간에 대해서는 별도의 음성으로 분리하고 추출하여 해 당 구간에 대해 STT 변환을 각각 수행할 수 있다. 또한 만약 발화한 구간을 모두 체크하여 복수의 발화 구간이 없는 경우, 음성파일에서 STT 변환시 불필요한 잡 음(예 : 옆자리 화자의 목소리 등)을 제거하도록 음성 주파수 대역의 평균치(RMS)를 구해 가장 큰 대역의 소리 (해당 대역의 음원에 추출하기 위한 식별용 인덱스 부여)만을 취하여 STT 변환을 수행하도록 할 수 있다. 이를 구체적으로 살펴보면, 현재 위치 카운트를 초기화하고, 각 마이크에 할당된 대기열(Queue)에 저장해둔 오 디오 데이터를 가져온다(S308, S310). 대기열에서 가져온 데이터의 마지막 데이터 여부를 판단하여 마지막 데이터인 경우, 각 마이크에서 입력된 오디 오 데이터를 하나의 음성파일(Wave file)로 생성할 수 있다(S312, S314). 또한, 대기열에서 가져온 데이터가 3번째 이상 대기열에서 가져온 데이터이면, 현재부터 ??2번째까지 오디오 데 이터의 평균을 구한다(S316, S318). 만약 대기열에서 가져온 데이터가 2번째 이상 대기열에서 가져온 데이터이면 현재부터 ??1번째까지 오디오 데이 터의 평균을 구한다(S320, S322). 대기열에서 가져온 오디오 데이터가 2번째 이상 대기열 가져온 데이터가 아닌 경우에는 현재 오디오 데이터의 평균을 구한다(S324). 즉, 대기열 오디오 데이터들에서 각 오디오 데이터별로 음성을 개별적으로 인식시켜 복수의 화자에 대해서 중첩 된 음성을 분리할 수 있도록 오디오 데이터를 분석할 수 있게 한다. 또한 N개의 마이크 중 음성 신호가 출력되는 설정된 시간 주기 동안 오디 신호의 평균값(RMS)을 산출하여 평균값이 오디오 입력 최대값의 기준값(70%) 이상인 경우 음성에 대한 텍스트 변환을 수행하고, 그렇지 않은 경 우 해당 음성(노이즈에 해당)을 버리게 한다(S326, S328, S330).이제 현재 위치 카운트를 증가시키고, 위 과정을 반복하여 수행할 수 있으며, 만약 현재 위치 카운트가 상술한 과정의 반복된 횟수만큼 카운트되어 그 카운트 수가 5보다 큰 경우에는 다음 과정을 수행할 수 있다(S332, S334). 이후, 도 3c에 도시된 바와 같이 음성 데이터의 특정 구간별로 실시간 자막 디스플레이를 위해 다음 과정이 수 행될 수 있다. 먼저 관리 프로그램은, 대기열에서 가져온 음성 데이터에서 오디오 볼륨 기준에 부합된 데이터를 탐색하고, 여 러 개의 마이크에서 입력된 오디오 중 가장 빨리 입력된 데이터를 탐색할 수 있다(S336, S338). 해당 오디오 데이터를 텍스트(문자)로 변환하고, 현재 마이크의 발화가 끝났는지를 판단한다(S340, S342). 만약 현재 마이크의 발화가 끝난 경우에는 새로운 마이크가 있는지 탐색하고, 음성인식 결과를 화면에 디스플레 이하여 실시간 자막 표시를 할 수 있다(S344, S346). 만약 현재 마이크의 발화가 끝나지 않은 경우에는 직전의 STT 변환 결과와 현재의 STT 변환 결과가 같은지 여부 를 판단하고, 같지 않은 경우에는 음성인식 결과를 화면에서 디스플레이한다(S348, S350). 만약 직전의 STT 변환 결과와 현재의 STT 변환 결과가 같은 경우에는 음성인식의 버퍼가 최대에 도달했는지 판 단하고, 최대에 도달한 경우 음성인식 버퍼를 초기화하고, S340단계로 복귀할 수 있다(S352, S354). 만약 음성인식의 버퍼가 최대에 도달하지 않았다면, 초기화하지 않고 바로 S340 단계로 복귀할 수 있다(S352). 나아가 관리 프로그램은 상술한 실시간 자막 및 문서 생성시 문장에 포함된 구두점(문장 부호)를 문장 형태를 분석하여 자동으로 입력하게 할 수 있으며, 구두점의 종류로는 예컨대 마침표, 물음표, 느낌표 등이 될 수 있다. 구체적으로 상술한 바와 같이 관리 프로그램은 텍스트 문장을 추출하기 위한 음성파일을 입력받고, STT 변환에 의해 입력된 음성파일을 인식하여, 해당 음성에 해당하는 텍스트(문장)를 추출하는데, 이때 실시간 자막 형태로 텍스트를 표시(출력)할 때 또는 문서화할 때 추출된 텍스트의 문자 패턴에 따라 구두점을 결정하기 위해 문자 패턴 데이터베이스를 기반으로 구두점 결정 알고리즘을 수행할 수 있다. 구두점 결정 알고리즘은 종결어미 분석 알고리즘을 통해 구두점을 결정하고, 문자 패턴 데이터베이스를 통하여 문자 패턴을 기반으로 구두점을 결정하도록 문자 패턴 데이터를 제공할 수 있다. 여기서 종결어미 분석 알고리즘은 구두점에 따른 종결 어미들을 구분하여 해당 문장에서 특정 종결 어미가 등장 할 때마다 종결 어미와 연결되는 해당 구두점을 삽입하도록 결정하는 것이 될 수 있다. 또한 종결어미 분석을 통해 삽입할 구두점을 우선적으로 결정하고, 구두점을 결정하지 못하거나, 올바르지 못한 구두점이 결정되는 경우 문자 패턴 데이터베이스를 활용하여 구두점을 결정하도록 한다. 또한 문자 패턴 데이터베이스에는 N-gram 문자 패턴에 대해서 2문자, 3문자 등에 대해서 각각 구분하여, 해당 문자 패턴들을 저장하고, 문자 패턴을 기반으로 하는 구두점 결정 알고리즘 수행시 활용된다. 또한 문자 패턴을 기반으로 하는 구두점 결정시, 전체 구두점을 기준으로 특정 구두점의 비중(확률)을 계산하여, 구두점 결정 기준값인 임계값(THRESHOLD)을 초과하는지 여부에 따라 초과하는 경우에 해당 구두점을 삽입하도록 결정할 수 있다. 나아가 문자 패턴 데이터베이스는 통계적인 수치를 저장하고 있으며, 문장 구두점 결정 횟수가 많을수록 구두점 경우의 수에 대한 통계 데이터가 정확할 수 있으며, 이를 빅데이터화하고, 인공지능 알고리즘을 기반으로 결정 된 구두점의 정확도, 구두점 결정 속도 등을 학습 및 예측하고, 예측 결과에 따라 상술한 임계값을 결정하거나, 미세 조정할 수 있다. 여기서 인공지능 알고리즘은 예컨대, SVM(Support Vector Machine), RNN(Recurrent neural network), CNN(Convolution neural network) 알고리즘 등을 활용할 수 있다. 도 4는 본 발명의 일 실시예에 따른 실시간 변환 및 문서 관리 프로그램이 기능하기 위한 전체 구성을 보인 블 록도이며, 도 5는 본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치가 기능하기 위한 전체 구성을 보인 블록도이고, 도 6은 도 5의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 세부 구성을 보인 블록도이고, 도 7은 도 5의 관리서버의 세부 구성을 보인 블록도이다.본 발명의 일 실시예에 따른 웹기반/모바일 기반 형태로 관리서버에서 제공되는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 프로그램은, 도 4에 도시되어 있으며, 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장 치에 내장되는 형태는 도 7과 같은 형태로 구현되어 주변 장치들과 연계하여 기능을 수행할 수 있다. 사용자단말기에서 실행되는 관리 프로그램은 사용자단말기에 설치되어 관리서버와 연동하도록 실행되는 프로그램이거나, 관리서버에서 웹기반 또는 모바일 기반 서비스 형태로 제공되는 프로그램이 될 수 있 다. 음성변환 수신기에 프로그램이 내장되는 내장형의 경우에는 음성변환 수신기 자체에서 상술한 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법의 일련의 과정들을 수행할 수 있으며, 주변기기로는 실시간 자막 화면 표 시를 위한 사용자단말기 또는 표시장치가 연결될 수 있고, 유무선 통신망을 통하여 연결된 관리서버 에 생성된 음성파일, 문서 파일 등을 클라우드 형태로 저장하여 관리할 수도 있다. 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는, 구체적으로 복수의 마이크로부터 독립적으 로 입력된 화자들의 대화 내용을 수집할 수 있는 음성변환 수신기(Bluetooth Multimedia Receiver : BMR, 30 0)로서 기능하기 위해 마련되며, 관리서버와 유무선 통신망을 통하여 연결되어 화자들의 대화 내용을 수집한 음 성 데이터를 유무선 통신망을 통하여 전송함과 아울러, 음성 데이터에 대한 문서를 생성하여 제공하고, 문 서를 관리서버에서 제공하는 데이터베이스에 저장 및 관리할 수 있도록 통신하는 기능을 포함한다. 특히, 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 음성 데이터에 대한 문서를 생성하고 관리 하기 위한 관리 프로그램이 내장되어 구체적 기능을 수행할 수 있으며, 이와 같은 프로그램이 장치에 기본 내장 되어 제품 출하시 제공되되, 관리서버나 오프라인 장치(USB 플래시 메모리, PC 등)를 통하여, 지속적인 업데이 트가 가능하도록 마련될 수 있다. 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치에 연결되는 복수의 마이크는 화자마다 개별적 으로 설치되어 화자 각각의 음성을 입력받는다. 즉, 마이크는 개별적으로 화자의 음성을 입력받아 음성신 호를 연결된 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치로 전송할 수 있다. 또한 복수의 마이크는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치와 유무선 통신에 의해 음성신호를 전송할 수 있으며, 통신 방식은 USB 연결에 의한 유선 통신, 블루투스, Wi-Fi 등이 될 수 있으나, 이는 예시에 불과하며 본 발명이 특정 통신 방식에 한정되는 것은 아니다. 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 마이크와 연결되어 마이크로부터 입력 되는 음성에 대한 음성 신호를 각 마이크마다 개별적인 채널로 수신하고, 사용자 요청시 음성 신호를 전송 하기 위해 사용자단말기와 연결된다. 즉, 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 복수의 마이크로부터 개별적으로 독립 하여 수신된 음성신호를 마이크별로 구분하여 별도의 음성파일을 생성할 수 있도록 다채널(멀티 채널)로 구성되고, 물론 마이크 연결 수에 따라 싱글 채널 형태로 활용될 수도 있다. 또한 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 자체적으로 내장된 관리 프로그램을 이용하 여 문서를 생성할 수 있다. 나아가 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 복수의 마이크와 유사하게 USB 연결 에 의한 유선 통신, 블루투스, Wi-Fi 등의 유무선 통신 방식으로 사용자단말기에 연결될 수 있다. 사용자단말기는 관리서버에서 제공하는 관리 프로그램을 실행하고, 실행된 관리 프로그램 을 통하여 사용자 입력에 의해 다양한 기능을 수행하도록 제공될 수 있다. 특히 사용자단말기는 관리서버에 제공한 녹음된 화자별 음성파일들을 편집하거나 일부 삭제하여 수정 된 음성파일로 문서를 생성하도록 관리서버에 제공하여 사용자(예컨대 상급 관리자)가 불필요한 내용을 제 외하고 필요한 내용만으로 문서를 생성하도록 요청할 수 있어 효율적인 문서 생성하여 사용자 편의성을 증대시 킬 수 있다. 사용자단말기는 유무선 통신망을 통한 관리서버의 도움 없이 설치된 관리 프로그램을 통하 여 문서 생성, 편집 및 관리 기능을 수행할 수 있으며, 관리서버는 생성된 문서의 클라우드 저장 및 문서 관리, 업데이트 기능만을 제공할 수 있도록 한다. 또한 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 관리 프로그램을 통하여 구체적 기능을 수 행하기 위해 도 6을 참조하면, 연결부, 입력부, 표시부, 생성부, 관리부 및 연동부 를 더 포함한다. 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 내장된 관리 프로그램을 실행시켜, 문서 생 성을 위해 병합된 음성파일에 대한 음성-텍스트 변환(STT)을 수행하고, 텍스트 결과를 이용하여 문서를 생성할 수 있다. 이때 생성되는 문서는 사용자가 열람이 가능한 문서 파일 형태로 생성되고, 시간순으로 화자별로 대화 내용이 일목요연하게 기록되어 문서를 확인하기 용이하도록 생성될 수 있으며, 실행되는 관리 프로그램과 연동하 여 문서 생성, 관리, 편집 기능 등을 제공할 수도 있다. 연결부는 마이크와 연결하기 위한 마이크 인터페이스를 구비하고, 유무선으로 연결된 복수의 마이크로부터 회의 도중 화자 음성에 해당하는 음성 신호를 수집하고, 입력부에 의한 사용자 요청시 해당 음성에 대한 텍스트 출력에 의해 문서를 생성하기 위해 생성부로 음성을 전달한다. 또한 연결부는 별도의 채널로 마이크의 음성이 입력되도록 복수의 채널을 갖는 상기 마이크 인터페이스로 구성될 수 있다. 나아가 연결부는 상기 마이크 인터페이스 외에도 오프라인 장치의 연결 인터페이스를 더 포함할 수 있으며, 예컨대 USB-C 타입 인터페이스를 적어도 하나 이상 구비할 수 있다. 오프라인 장치의 연결 인터페이스 를 통하여 관리 프로그램의 업데이트나 후술할 음성 파일 또는 문서 파일의 내보내기 (별도 저장) 기능 등 사용자 편의 기능을 제공할 수 있다. 나아가 연결부에는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 내부 입력부 및/또 는 표시부를 대신하여 관리 프로그램을 실행시켜, 화면 표시, 문서 편집 등의 기능을 보조적으로 사 용하기 위해 사용자단말기 또는 모니터와 같은 표시장치와 연결하거나, 관리서버와 통신하기 위 한 유무선 인터페이스를 추가로 제공할 수 있다. 즉 사용자단말기는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 입력부 및 표시부 기능을 대신하여 사용할 수 있도록 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 별도의 유무선 인터페이스와 연결되는 PC 형태의 단말기가 될 수 있고, 관리 프로그램이 별도로 설치 및 실행될 수도 있다. 이와 같은 경우 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 음성변환 수신기로서 화자 음성 녹음을 수신하고, 녹음된 음성 파일을 사용자단말기에서 실행되는 관리 프로그램으로 전송하여, 문서 를 생성 및 편집할 수 있도록 제공될 수 있다. 입력부는 기본적으로 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 내에서 사용자가 사용자 입력에 의해 직접 관리 프로그램을 실행시키고 기능들을 제어하여 음성 신호를 입력받아 음성 신호에 대한 문서를 생성하기 위한 상호작용 인터페이스로 제공된다. 이와 같은 입력부는 PC와 유사하게 키보드나 마우스(터치패드 등)와 같은 형태로 제공될 수 있고, 나아가 터치스크린의 형태로 표시부의 기능에 포함되도록 마련될 수도 있다. 표시부는 PC의 모니터와 유사하게 실행되는 관리 프로그램을 디스플레이하고, 사용자가 입력부 를 통하여 관리 프로그램을 조작하여 문서 생성 및 편집 기능들을 수행할 수 있도록 화면상에 표시할 수 있다. 표시부는 단순 표시 기능을 위한 스크린 형태 또는 입력부가 통일된 터치스크린 형태로 마련될 수 있 다. 생성부는 연결부를 통하여 전달받은 음성파일로부터 음성 데이터에 대한 텍스트를 추출한다. 또한 음성 데이터의 포맷은 예컨대 WAV 확장자가 되고, 추출되는 텍스트 포맷은 UTF-8이 될 수 있다. 또한 다양한 언어의 음성에 대한 텍스트 변환을 위해 생성부는 하나 이상의 음성인식모델이 포함되며, 다 국어를 지원하기 위한 다국어 음성인식모델, 지방 사투리를 인식하기 위한 음성인식모델 등이 포함될 수 있다. 다국어 음성인식모델의 경우 입력된 음성에 대해 사용자가 선택한 원하는 언어로 혹은 설정된 언어도 자동 번역 에 의해 변환되도록 할 수 있다.예컨대 도 13을 참조하면, 본 발명에서 실시간 자막 생성시 다국어를 지원하여 사용자가 설정한 언어들로 실시 간 번역된 자막을 생성할 수 있다. 즉, 도 13에서 강의 도중 학생 1의 경우 중국어로, 학생 2의 경우 베트남어로, 학생 3의 경우 우즈베크어로, 학 생 4의 경우 일본어로 실시간 번역하여 자막으로 표시한 예시를 보여주고 있으며, 각각 선생님의 음성 데이터 (한국 음성)를 한국어 텍스트로 먼저 변환하고, 변환된 한국어 텍스트를 다국어 음성인식모델을 토대로 각 사용 자 설정된 언어로 실시간 번역되도록 하는 것이다. 또한 음성인식모델은 음성 인식 성능을 향상시키고, 다양한 음성에 대한 인식을 위해 인공지능 학습 알고리즘에 의해 학습될 수 있다. 이외에도 원어민이 아닌 사용자의 음성에 대해 학습하고 해당 음성 인식을 위한 발성평가모델 등이 추가될 수 있다. 또한 음성 인식 향상을 위한 인공지능 학습 알고리즘은 음성 인식 모델의 음성 인식 결과값에 대해 입력 변수로 학습 모델에 반영함으로서, 트레이닝이 거듭될수록 오차가 미세하게 보정되어 음성 인식율을 향상시킬 수 있게 된다. 구체적으로 음성 인식 모델의 음성 인식 결과값에 대한 허용 임계범위를 정하고, 허용 임계범위를 벗어난 값인 경우 음성 인식율이 낮은 것으로 판단하여 오프셋 차이값을 반영하여 다음 음성 인식시 보정된 음성 인식 결과 를 산출하도록 할 수 있으며, 이와 같은 오프셋 차이값은 학습모델의 학습이 거듭될수록 보정범위가 줄어들어 궁극적으로는 정상적인 음성 인식 범위 내에서 음성 인식이 이루어져 음성 인식율을 향상시킬 수 있게 되는 것 이다. 이를 위한 인공지능 학습 알고리즘은 패턴 학습에 유리한 서포트 벡터 머신(SVM), 컨벌루션 신경망(CNN), 순환 신경망(RNN) 등이 적어도 하나 이상 이용될 수 있다. 또한 생성부는 상기 STT 변환에 의해 추출된 텍스트를 모아 하나의 문서 형태의 문서 파일을 생성한다. 문서 파일의 형태는 열람 후 문서 내용의 일부 삭제, 편집 및 수정이 가능하도록 범용 문서 포맷으로 생성될 수 있으며, 예컨대 워드 포맷(docx), 한글 포맷(hwp) 등이 될 수 있다. 관리부는 관리 프로그램에서 생성된 문서 파일을 열람하여 문서의 수정 및 삭제 기능을 제공한다. 또한 관리부는 사용자의 요청에 따라 사용자단말기의 내부에 저장된 혹은 관리서버의 데이터베 이스에 저장된 문서를 불러와 편집 및 삭제를 수행하도록 지원할 수 있다. 상술한 생성부 및 관리부는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치에 내장되는 관리 프로그램의 형태로 구현될 수 있다. 나아가 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치에 내장되는 관리 프로그램은 문서 관 리에 필요한 다양한 기능을 제공하는데, 구체적으로 다수의 문서가 생성된 경우, 문서 노트별로 목록으로 표시 하여 제공할 수 있으며, 문서 노트에 대한 편집, 시간/장소/사용자(책임자) 등에 대한 지정 정렬 기능, 삭제 기 능, 음성 파일 업로드, 내보내기(파일 별도 저장) 기능을 제공할 수 있으며, 사용자 편의성을 위한 환경설정 등 이 포함될 수 있다. 환경설정 화면은 도 11에 도시하고 있으며, 사용자의 회원 가입된 정보, 프로그램(어플리케이션) 업데이트 정보, 마이크 선택 정보, 자주 쓰는 단어/문구에 대한 정보, 자주 쓰는 단어/문구에 대한 가중치 설정 정보, 실 시간 자막 표시할 때 중간 변환 과정 보기 기능 등을 포함할 수 있다. 또한 관리 프로그램은 보안 및 회원 관리 차원에서 사용자 로그인 기능을 제공하며 이를 위한 회원가입 및 로그인 절차를 포함할 수 있다. 구체적으로 로그인 인증을 위해 회원가입시 라이선스 키를 적용하는 방식으로 회원가입을 수행하고, 회원 가입 된 회원정보를 토대로 로그인이 이루어질 수 있다. 또한 라이선스는 관리서버에서 구매할 수 있는 웹페이지를 제공할 수 있으며, 오프라인 환경의 경우, 오프 라인 구매처나 온라인 구매한 라이선스 키를 USB 메모리 등과 같은 휴대용 저장장치에 저장한 후 사용할 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 또는 사용자단말기에 입력하여 회원가입 완료 후 사용할 수도 있다. 이와 같이 회원 로그인 후에 관리서버로부터 제공되는 관리 프로그램을 다운로드 받아 설치할 수 있 다. 또한 관리 프로그램은 문서 내용, 참석자(화자) 등에 대한 편집, 수정, 삭제 기능을 제공할 수 있으며, 음성 진 행 바(progress bar)에 대한 인터페이스를 제공하여, 음성을 직접 들으면서 편집 및 수정을 수행하도록 제공할 수도 있으며, 특히 불필요한 구간 예를 들어 발화가 발생하지 않은 부분에 대한 삭제 기능 등이 포함될 수도 있 다. 또한 관리 프로그램은 복수의 마이크에 대한 설정 및 편집 기능을 제공하여, 연결된 복수의 마이크 리스트를 확인 후 사용할 마이크를 선택하거나 사용하지 않은 마이크를 선택하는 등의 기능을 제공할 수 있다. 또한 관리 프로그램은 마이크 설정에 따라서는 단일 마이크만을 사용하는 경우도 있을 수 있으 며, 예컨대 다수가 회의를 하는 상황이 아닌 단일 발표자가 프리젠테이션을 수행하는 경우나, 교사, 교수, 강사 등이 강단에서 수업 진행하는 경우에 해당할 수 있으며, 이와 같은 경우에도 상술한 바와 같은 음성 파일 생성 및 음성 파일에 대한 STT 변환 후 해당 음성 내용에 대한 텍스트 기록 결과물을 생성할 수 있음은 물론이다. 또한 관리 프로그램은 사용자 편의를 위한 환경설정 기능이 포함될 수 있으며, 어플리케이션 정보에 따라 프로그램 업데이트를 자동 또는 수동으로 수행하거나, 자주 쓰는 단어를 등록하여 자주 쓰는 단어에 대해서는 문서 생성시 STT 변환을 수행하지 않고 텍스트 추출된 결과를 그대로 사용하는 용도로 활용하여 변환 속도를 향 상시킬 수 있다. 또한 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치는 부가 기능으로서, 관리서버로부터 최 초에 관리 프로그램을 다운받거나, 생성된 문서를 웹기반 저장 및 관리하기 위해 관리서버와 통신하 는 연동부가 더 포함될 수 있다. 또한 관리서버는 생성된 문서의 클라우드 저장 및 문서 관리, 업데이트 기능을 수행하기 위해 세부적으로 통신부, 문서관리부, 학습부, 앱연동부, 데이터베이스를 더 포함한다. 통신부는 관리 프로그램이 설치된 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 또는 사용자단말기와 유무선 통신에 의해 문서를 전송받도록 통신 가능한 적어도 하나의 유무선 통신 프로토콜 을 포함한다. 문서관리부는 통신부를 통하여 수집된 문서에 대해서 해당 문서를 제공한 복수의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 또는 사용자단말기가 존재하는 경우, 화자 음성 분리에 의한 실 시간 자막 및 문서 생성 장치 또는 사용자단말기별로 지정된 정렬 조건(시간, 장소, 사용자 등)에 따 라 정렬하여 목록화하거나, 데이터베이스에 저장하여 관리할 수 있다. 또한 문서관리부는 회원제로 운영하고, 보안을 위해 사용자에 대한 회원정보를 데이터베이스에 저장 하여 관리하고, 회원정보를 토대로 로그인 인증을 수행할 수 있다. 또한 문서관리부는 회원제로 운영하기 위한 라이센스 키를 제공하고, 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 또는 사용자단말기에서 설치되는 관리 프로그램에 대한 인증 및 로그인에 의 해 인증된 프로그램에 한해 실행되도록 한다. 나아가 문서관리부는 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 또는 사용자단말기(20 0)에서 설치되어 실행되는 오프라인 설치형 관리 프로그램을 대신하여, 웹 프로그램 기반으로 통신하여 문 서를 생성 및 편집 등의 기능을 수행하여, 설치형 관리 프로그램과 동일한 기능을 수행하도록 지원할 수 있다. 이를 통하여 관리서버는 관리 프로그램이 내장된 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치를 사용하지 않거나, 별도로 사용자단말기에 설치되어 있지 않더라도 웹 기반으로 문서 생성 및 편집 기능을 유무선 통신을 통하여 실시간으로 제공할 수도 있다. 이와 같은 경우에는 웹기반으로 문서 생성 및 관리 서비스가 제공되기 때문에, 관리서버와 온라인 통신이 가능한 환경이 구축되어 있어야 한다. 학습부는 문서에 대하여 회의별, 장소별, 시간별로 구분하여 문서를 데이터베이스에 저장하여 관리할 수 있도록 하고, 각종 문서에 대한 통계 정보를 생성하여 사용자에게 제공할 수 있다. 앱연동부는 상기 연동부를 통하여 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 또는 사용자단말기에서 설치되어 실행되는 관리 프로그램과 연동(호환) 가능한 통신 인터페이스를 제공하 며, 예컨대 관리 프로그램을 통하여 편집된 문서를 전송받아 데이터베이스에 갱신하여 저장하는 등의 역할을 수행할 수 있다. 또한, 도 12에는 본 발명의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 및 무선 마이크의 실제 사용 가능한 구현 예시를 보여주고 있다. 본 명세서에서 ‘단말기’는 휴대성 및 이동성이 보장된 무선 통신 장치일 수 있으며, 예를 들어 스마트폰, 태 블릿 PC 또는 노트북 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치일 수 있다. 또한, ‘단 말기’는 통신망을 통해 다른 단말 또는 서버 등에 접속할 수 있는 PC 등의 유선 통신 장치인 것도 가능하다. 또한, 통신망은 단말들 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷 (WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 블루투스 통신, 적외선 통신, 초음파 통신, 가시광 통신(VLC: Visible Light Communication), 라이파이(LiFi) 등이 포함되나 이에 한 정되지는 않는다."}
{"patent_id": "10-2021-0152177", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법의 전체 과정을 보인 순서도이다. 도 2는 도 1의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법에서 싱글 채널 마이크에 대한 음성 인식 및 실시간 자막 생성/표시 기능에 대한 세부 과정을 보인 순서도이다. 도 3a, 도 3b, 도 3c는 도 1의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 방법에서 멀티 채널 마이크에 대한 복수의 음성 인식 및 실시간 자막 생성/표시 기능에 대한 세부 과정을 보인 순서도이다. 도 4는 본 발명의 일 실시예에 따른 실시간 변환 및 문서 관리 프로그램이 기능하기 위한 전체 구성을 보인 블 록도이다. 도 5는 본 발명의 일 실시예에 따른 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치가 기능하기 위한 전 체 구성을 보인 블록도이다. 도 6은 도 5의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치의 세부 구성을 보인 블록도이다. 도 7은 도 5의 관리서버의 세부 구성을 보인 블록도이다. 도 8은 스마트 폰 상에서 구현된 화자 음성 분리에 의한 실시간 자막 및 문서 생성 프로그램을 이용한 회의 음 성 실시간 텍스트 변환, 화면 표시 및 문서 생성 화면을 예시적으로 보인 도면이다. 도 9는 스마트 폰 상에서 구현된 화자 음성 분리에 의한 실시간 자막 및 문서 생성 프로그램을 이용한 동영상 내 음성 변환에 의한 실시간 자막 표시 화면을 예시적으로 보인 도면이다. 도 10은 화자 음성 분리에 의한 실시간 자막 및 문서 생성 프로그램을 이용한 복수의 생성된 문서의 관리 화면 을 예시적으로 보인 도면이다. 도 11은 화자 음성 분리에 의한 실시간 자막 및 문서 생성 프로그램의 환경설정 화면을 예시적으로 보인 도면이 다. 도 12는 본 발명의 화자 음성 분리에 의한 실시간 자막 및 문서 생성 장치 및 무선 마이크의 구현 예시를 보인 도면이다. 도 13은 본 발명에서 실시간 자막 생성시 다국어를 지원하여 사용자가 설정한 언어로 실시간 번역된 자막을 생 성하는 예시를 보여주는 도면이다."}
