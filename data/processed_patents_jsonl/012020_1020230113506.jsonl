{"patent_id": "10-2023-0113506", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0008428", "출원번호": "10-2023-0113506", "발명의 명칭": "영상 촬영을 지원하는 방법 및 이를 지원하는 전자 장치", "출원인": "삼성전자주식회사", "발명자": "정미영"}}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치(101)에 있어서, 제1 카메라(651, 810);상기 제1 카메라(651, 810)와 반대 면에 배치된 제2 카메라(652, 820);디스플레이(660, 830, 840); 및상기 제1 카메라(651, 810), 상기 제2 카메라(652, 820) 및 상기 디스플레이(660, 830, 840)와 작동적으로 연결된 적어도 하나의 프로세서(120)를 포함하고, 상기 적어도 하나의 프로세서(120)는,어플리케이션 실행에 기반하여 상기 제1 카메라(651, 810) 및 상기 제2 카메라(652, 820) 중 적어도 하나의 카메라로부터 제1 영상을 획득하고,상기 제1 영상에 기반하여 지정된 촬영 모드를 판단하고,상기 지정된 촬영 모드를 판단하는 것에 기반하여 상기 디스플레이(660, 830, 840)를 통해 그래픽 요소를 표시하고, 및영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동작하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬영하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 제1 영상을 분석하고,상기 제1 영상의 분석에 기반하여 지정된 식별 정보를 검출하고,상기 지정된 식별 정보를 검출하는 것에 기반하여 상기 지정된 촬영 모드를 판단하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 지정된 식별 정보는,상기 지정된 촬영 모드의 실행 여부를 판단하기 위한 미리 지정된 영상 객체를 포함하고,상기 지정된 영상 객체는, 지정된 얼굴 객체 또는 지정된 식별자 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제1 영상은 상기 제1 카메라(651, 810)의 영상 및/또는 상기 제2 카메라(652, 820)의 영상을 포함하고,상기 적어도 하나의 프로세서(120)는,상기 제1 영상과 미리 설정된 영상을 비교하고,상기 제1 영상으로부터 상기 지정된 얼굴 객체를 식별하는 것에 기반하여 상기 지정된 촬영 모드를 판단하도록설정된 전자 장치.공개특허 10-2025-0008428-3-청구항 5 제3항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 그래픽 요소가 표시되는 상기 디스플레이와 동일 면에 위치한 상기 지정된 카메라를 통해 획득되는 영상으로부터 상기 지정된 식별자를 식별하는 것에 기반하여 상기 지정된 촬영 모드를 판단하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 지정된 촬영 모드를 판단하는 것에 기반하여, 상기 제1 카메라(651, 810) 및 상기 제2 카메라(652, 820)중에서 상기 지정된 촬영 모드에서 동작할 상기 지정된 카메라를 결정하고,상기 지정된 카메라를 이용하여 상기 제2 영상을 촬영하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 지정된 촬영 모드에서 동작할 상기 지정된 카메라를 결정하는 것에 기반하여, 상기 지정된 카메라와 반대면에 위치한 카메라를 비활성화하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 전자 장치는, 제1 디스플레이 및 제2 디스플레이를 포함하고,상기 적어도 하나의 프로세서(120)는,상기 제1 디스플레이 및 상기 제2 디스플레이 중 상기 지정된 카메라와 동일 면에 위치한 디스플레이에 기반하여 상기 그래픽 요소를 표시하고,상기 지정된 카메라와 반대 면에 위치한 디스플레이에 기반하여 상기 지정된 카메라로부터 획득하는 영상의 프리뷰를 표시하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 프리뷰는 반사체 및 상기 반사체에 투영된 영상을 포함하며,상기 반사체에 투영된 영상은, 상기 지정된 카메라, 상기 지정된 카메라와 동일 면에 위치한 디스플레이, 및 상기 디스플레이에 표시된 그래픽 요소를 포함하는 상기 전자 장치에 대응하는 객체를 포함하는 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 그래픽 요소가 지정된 조건에 포함되는지 분석하고,상기 그래픽 요소가 지정된 조건에 포함되는 것에 기반하여 상기 결정된 카메라와 동일 면에 위치한 디스플레이공개특허 10-2025-0008428-4-에 표시되는 상기 그래픽 요소에 관련된 지정된 기능을 처리하고,제1 디스플레이 및/또는 제2 디스플레이에 기반하여 상기 기능 처리 결과를 표시하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 프리뷰에서 상기 그래픽 요소에 대응하는 객체에 기반하여 사용자 입력을 감지하고,상기 사용자 입력에 기반하여 상기 결정된 카메라와 동일 면에 위치한 디스플레이에 표시되는 상기 그래픽 요소에 관련된 지정된 기능을 처리하고,제1 디스플레이 및/또는 제2 디스플레이에 기반하여 상기 기능 처리 결과를 표시하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서(120)는, 상기 지정된 촬영 모드를 판단하는 것에 기반하여 상황 인지를 수행하고,상기 상황 인지에 기반하여 상기 디스플레이에 표시할 그래픽 요소를 생성하고,상기 생성된 그래픽 요소를 표시하도록 상기 디스플레이를 제어하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 어플리케이션 실행을 감지하는 것에 기반하여 상기 제1 카메라(651, 810) 및 상기 제2 카메라(652, 820)를활성화하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 어플리케이션 실행을 감지하는 것에 기반하여 상기 전자 장치가 지정된 상태인지 여부를 판단하고,상기 전자 장치가 지정된 상태인 것을 판단하는 것에 기반하여, 상기 제1 카메라(651, 810) 및 상기 제2 카메라(652, 820)를 동시에 활성화하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서(120)는,상기 촬영되는 제2 영상에 상기 그래픽 요소에 관련된 메타데이터를 매핑하여 저장하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서(120)는,지정된 영상을 표시하고,상기 영상 내의 지정된 그래픽 요소에 기반한 사용자 입력을 감지하고,공개특허 10-2025-0008428-5-상기 사용자 입력에 기반하여 상기 지정된 그래픽 요소에 대응하는 메타데이터를 호출하고,상기 메타데이터에 대응하는 기능을 실행하고,상기 기능 실행에 대응하는 컨텐츠를 상기 디스플레이를 통해 표시하도록 설정된 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항에 있어서, 상기 제1 영상은, 상기 제1 카메라(651, 810) 및 상기 제2 카메라(652, 820)로부터 각각 획득되는 복수의 영상들을 포함하고, 상기 디스플레이에 표시되지 않고 상기 적어도 하나의 프로세서(120)에 의해 백그라운드에서 상기 촬영 모드를 판단하는 데 사용되는 영상인 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항에 있어서,상기 제2 영상은, 상기 제1 카메라(651, 810) 및 상기 제2 카메라(652, 820) 중 상기 지정된 카메라로 동작하는카메라로부터 획득되고, 상기 그래픽 요소가 표시되는 디스플레이와 다른 디스플레이를 통해 표시되는 영상인것을 특징으로 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항에 있어서,상기 지정된 카메라는 상기 그래픽 요소를 표시하는 상기 디스플레이와 동일한 면에 위치된 카메라인 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2023-0113506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "전자 장치(101)의 동작 방법에 있어서, 어플리케이션 실행에 기반하여 제1 카메라(651, 810) 및 제2 카메라(652, 820) 중 적어도 하나의 카메라로부터제1 영상을 획득하는 동작;상기 제1 영상에 기반하여 지정된 촬영 모드를 판단하는 동작;상기 지정된 촬영 모드를 판단하는 것에 기반하여 디스플레이(660, 830, 840)를 통해 그래픽 요소를 표시하는동작; 및영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동작하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬영하는 동작을 포함하는 방법."}
{"patent_id": "10-2023-0113506", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 다양한 실시예들은 영상 촬영을 지원하는 방법 및 이를 지원하는 전자 장치를 제공한다. 일 실시예에 따른 전자 장치는, 제1 카메라, 상기 제1 카메라와 반대 면에 배치된 제2 카메라, 디스플레이, 및 적어도 하나의 프로세서를 포함할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 어플리케이션 실행에 기반하 (뒷면에 계속)"}
{"patent_id": "10-2023-0113506", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 실시예는 영상 촬영을 지원하는 방법 및 이를 지원하는 전자 장치를 제공한다."}
{"patent_id": "10-2023-0113506", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털 기술의 발달과 함께 스마트 폰(smart phone), 디지털 카메라(digital camera), 및/또는 웨어러블 장치 (wearable device)와 같은 다양한 유형의 전자 장치가 널리 사용되고 있다. 전자 장치는 기능 지지 및 증대를 위해, 전자 장치의 하드웨어적인 부분 및/또는 소프트웨어적인 부분이 지속적으로 개발되고 있다.사용자들은 전자 장치를 이용하여 영상을 촬영할 수 있다. 예를 들어, 전자 장치는 적어도 하나의 카메라 장치 를 포함할 수 있고, 적어도 하나의 카메라 장치를 통해 사용자의 영상 촬영을 지원할 수 있다. 최근에는 사용자 들에 의해 전자 장치를 이용한 영상 촬영 기능의 사용이 증가되고 있다. 예를 들어, 사용자는 휴대가 간편한 전 자 장치를 이용하여, 시간 및/또는 장소(또는 공간)의 제약 없이 전자 장치의 영상 촬영 기능을 사용하고 있다. 따라서, 최근에는 전자 장치에서 사용자의 영상 촬영에 대한 편의 및 흥미를 제공하기 위한 다양한 기능(또는 서비스)에 대한 연구 및 개발이 진행되고 있습니다. 상술한 정보는 본 개시에 대한 이해를 돕기 위한 목적으로 하는 배경 기술(related art)로 제공될 수 있다. 상 술한 내용 중 어느 것도 본 개시와 관련된 종래 기술(prior art)로서 적용될 수 있는지에 대하여 어떠한 주장이 나 결정이 제기되지 않는다. 본 개시의 일 실시예에서는, 전자 장치의 카메라를 이용하여 반사체에 투영된 피사체를 포함하는 영상 촬영을 지원하는 방법 및 이를 지원하는 전자 장치를 제공한다. 본 개시의 일 실시예에서는, 영상 촬영 시에 반사체를 감지하는 것에 기반하여 지정된 촬영 모드로 자동 전환하 고, 지정된 촬영 모드에서 반사체에 투영되는 전자 장치의 디스플레이 면에 지정된 그래픽 요소를 표시하고, 반 사체에 투영된 디스플레이의 그래픽 요소를 포함하여 영상 촬영을 지원할 수 있는 방법 및 이를 지원하는 전자 장치를 제공한다. 본 문서에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2023-0113506", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 본 개시의 일 실시예에 따른 전자 장치는, 제1 카메라, 상기 제1 카메라와 반대 면에 배치된 제2 카메라, 디스 플레이, 및 상기 제1 카메라, 상기 제2 카메라 및 상기 디스플레이와 작동적으로 연결된 적어도 하나의 프로세 서를 포함할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 어플리케이션 실행에 기반하여 상 기 제1 카메라 및 상기 제2 카메라 중 적어도 하나의 카메라로부터 제1 영상을 획득하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 제1 영상에 기반하여 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 지정된 촬영 모드를 판단하는 것에 기반하여 상기 디스플레이를 통해 그래픽 요소를 표시하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동작 하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬영하도록 동작할 수 있다. 본 개시의 일 실시예에 따른 전자 장치의 동작 방법은, 어플리케이션 실행에 기반하여 제1 카메라 및 제2 카메 라로부터 제1 영상을 획득하는 동작을 포함할 수 있다. 상기 동작 방법은, 상기 제1 영상에 기반하여 지정된 촬 영 모드를 판단하는 동작을 포함할 수 있다. 상기 동작 방법은, 상기 지정된 촬영 모드를 판단하는 것에 기반하 여 디스플레이를 통해 그래픽 요소를 표시하는 동작을 포함할 수 있다. 상기 동작 방법은, 영상 촬영을 위한 사 용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동작하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬영하는 동작을 포함할 수 있다. 상기와 같은 과제를 해결하기 위하여 본 개시의 다양한 실시예들에서는, 상기 방법을 프로세서에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 판독 가능한 기록 매체를 포함할 수 있다. 일 실시예에 따르면, 하나 이상의 프로그램들을 저장하는 비 일시적(non-transitory) 컴퓨터 판독 가능 저장 매 체(또는 컴퓨터 프로그램 프로덕트(product))가 기술된다. 일 실시예에 따르면, 하나 이상의 프로그램들은, 전 자 장치의 프로세서에 의해 실행될 시, 어플리케이션 실행에 기반하여 제1 카메라 및 제2 카메라로부터 제2 영 상을 획득하는 동작, 상기 제1 영상에 기반하여 지정된 촬영 모드를 판단하는 동작, 상기 지정된 촬영 모드를 판단하는 것에 기반하여 디스플레이를 통해 그래픽 요소를 표시하는 동작, 및 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동작하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬 영하는 동작을 수행하는 명령어를 포함할 수 있다. 본 개시의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 개시의 사 상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 개시의 바람직한 실시예와 같은 특정 실시예는 단지 예시로 주어진 것으로 이해되어야 한다.본 개시의 일 실시예에 따른 전자 장치, 그 동작 방법 및 기록 매체에 따르면, 전자 장치에서 사용자의 영상 촬 영에 대한 편의 및 흥미를 제공할 수 있다. 일 실시예에 따르면, 영상 촬영 시에 전자 장치를 통해 사용자 및/ 또는 사용자에 관련된 컨텍스트(context)를 표현하는 시그니처를 제공하고, 해당 시그니처를 포함하는 영상 촬 영을 지원할 수 있다. 일 실시예에 따르면, 영상 촬영에 새로운 기능을 제공하여 사용자의 전자 장치를 이용한 영상 촬영에 대한 니즈(needs)를 충족하고, 사용자에게 새로운 사용자 경험(UX, user experience)을 제공할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부 터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0113506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으 며 여기에서 설명하는 실시예에 한정되지 않는다. 도면의 설명과 관련하여, 동일하거나 유사한 구성요소에 대해 서는 동일하거나 유사한 참조 부호가 사용될 수 있다. 또한, 도면 및 관련된 설명에서는, 잘 알려진 기능 및 구성에 대한 설명이 명확성과 간결성을 위해 생략될 수 있다. 도 1은 다양한 실시예들에 따른 네트워크 환경 내의 전자 장치의 블록도이다. 도 1을 참조하면, 네트워크 환경에서 전자 장치는 제1 네트워크(예: 근거리 무선 통신 네트워크)를 통하여 전자 장치와 통신하거나, 또는 제2 네트워크(예: 원거리 무선 통신 네트워크)를 통하여 전자 장치 또는 서버 중 적어도 하나와 통신할 수 있다. 일 실시예에 따르면, 전자 장치(10 1)는 서버를 통하여 전자 장치와 통신할 수 있다. 일 실시예에 따르면, 전자 장치는 프로세서 , 메모리, 입력 모듈, 음향 출력 모듈, 디스플레이 모듈, 오디오 모듈, 센서 모듈, 인터페이스, 연결 단자, 햅틱 모듈, 카메라 모듈, 전력 관리 모듈, 배터 리, 통신 모듈, 가입자 식별 모듈, 또는 안테나 모듈을 포함할 수 있다. 어떤 실시예에서 는, 전자 장치에는, 이 구성요소들 중 적어도 하나(예: 연결 단자)가 생략되거나, 하나 이상의 다른 구성요소가 추가될 수 있다. 어떤 실시예에서는, 이 구성요소들 중 일부들(예: 센서 모듈, 카메라 모듈 , 또는 안테나 모듈)은 하나의 구성요소(예: 디스플레이 모듈)로 통합될 수 있다. 프로세서는, 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 프로세서에 연결된 전자 장치 의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이 터 처리 또는 연산을 수행할 수 있다. 일 실시예에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 프로세 서는 다른 구성요소(예: 센서 모듈 또는 통신 모듈)로부터 수신된 명령 또는 데이터를 휘발성 메모리에 저장하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비휘발성 메모리에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 메인 프로세서(예: 중앙 처리 장치 (CPU, central processing unit) 또는 어플리케이션 프로세서(AP, application processor)) 또는 이와는 독립 적으로 또는 함께 운영 가능한 보조 프로세서(예: 그래픽 처리 장치(GPU, graphic processing unit), 신 경망 처리 장치(NPU, neural processing unit), 이미지 시그널 프로세서(ISP, image signal processor), 센서 허브 프로세서(sensor hub processor), 또는 커뮤니케이션 프로세서(CP, communication processor))를 포함할 수 있다. 예를 들어, 전자 장치가 메인 프로세서 및 보조 프로세서를 포함하는 경우, 보조 프로 세서는 메인 프로세서보다 저전력을 사용하거나, 지정된 기능에 특화되도록 설정될 수 있다. 보조 프 로세서는 메인 프로세서와 별개로, 또는 그 일부로서 구현될 수 있다. 보조 프로세서는, 예를 들면, 메인 프로세서가 인액티브(inactive)(예: 슬립(sleep)) 상태에 있는 동 안 메인 프로세서를 대신하여, 또는 메인 프로세서가 액티브(예: 어플리케이션 실행) 상태에 있는 동 안 메인 프로세서와 함께, 전자 장치의 구성요소들 중 적어도 하나의 구성요소(예: 디스플레이 모듈 , 센서 모듈, 또는 통신 모듈)와 관련된 기능 또는 상태들의 적어도 일부를 제어할 수 있다. 일 실시예에 따르면, 보조 프로세서(예: 이미지 시그널 프로세서 또는 커뮤니케이션 프로세서)는 기능적으로 관련 있는 다른 구성요소(예: 카메라 모듈 또는 통신 모듈)의 일부로서 구현될 수 있다. 일 실시예에 따르면, 보조 프로세서(예: 신경망 처리 장치)는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 이러한 학습은, 예를 들어, 인공지능 모델이 수행 되는 전자 장치 자체에서 수행될 수 있고, 별도의 서버(예: 서버)를 통해 수행될 수도 있다. 학습 알 고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경 망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network),RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포 함할 수 있다. 메모리는, 전자 장치의 적어도 하나의 구성요소(예: 프로세서 또는 센서 모듈)에 의해 사 용되는 다양한 데이터를 저장할 수 있다. 데이터는, 예를 들어, 소프트웨어(예: 프로그램) 및, 이와 관련 된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 메모리는, 휘발성 메모리 또는 비 휘발성 메모리를 포함할 수 있다. 프로그램은 메모리에 소프트웨어로서 저장될 수 있으며, 예를 들면, 운영 체제(OS, operating system), 미들 웨어(middleware) 또는 어플리케이션을 포함할 수 있다. 입력 모듈은, 전자 장치의 구성요소(예: 프로세서)에 사용될 명령 또는 데이터를 전자 장치 의 외부(예: 사용자)로부터 수신할 수 있다. 입력 모듈은, 예를 들면, 마이크, 마우스, 키보드, 키 (예: 버튼), 또는 디지털 펜(예: 스타일러스 펜)을 포함할 수 있다. 음향 출력 모듈은 음향 신호를 전자 장치의 외부로 출력할 수 있다. 음향 출력 모듈은, 예를 들 면, 스피커 또는 리시버를 포함할 수 있다. 스피커는 멀티미디어 재생 또는 녹음 재생과 같이 일반적인 용도로 사용될 수 있다. 리시버는 착신 전화를 수신하기 위해 사용될 수 있다. 일 실시예에 따르면, 리시버는 스피커와 별개로, 또는 그 일부로서 구현될 수 있다. 디스플레이 모듈은 전자 장치의 외부(예: 사용자)로 정보를 시각적으로 제공할 수 있다. 디스플레이 모듈은, 예를 들면, 디스플레이, 홀로그램 장치, 또는 프로젝터 및 해당 장치를 제어하기 위한 제어 회로 를 포함할 수 있다. 일 실시예에 따르면, 디스플레이 모듈은 터치를 감지하도록 설정된 터치 센서, 또는 상기 터치에 의해 발생되는 힘의 세기를 측정하도록 설정된 압력 센서를 포함할 수 있다. 오디오 모듈은 소리를 전기 신호로 변환시키거나, 반대로 전기 신호를 소리로 변환시킬 수 있다. 일 실시 예에 따르면, 오디오 모듈은, 입력 모듈을 통해 소리를 획득하거나, 음향 출력 모듈, 또는 전자 장치와 직접 또는 무선으로 연결된 외부 전자 장치(예: 전자 장치)(예: 스피커 또는 헤드폰)를 통해 소리를 출력할 수 있다. 센서 모듈은 전자 장치의 작동 상태(예: 전력 또는 온도), 또는 외부의 환경 상태(예: 사용자 상태) 를 감지하고, 감지된 상태에 대응하는 전기 신호 또는 데이터 값을 생성할 수 있다. 일 실시예에 따르면, 센서 모듈은, 예를 들면, 제스처 센서, 자이로 센서, 기압 센서, 마그네틱 센서, 가속도 센서, 그립 센서, 근접 센서, 컬러 센서, IR(infrared) 센서, 생체 센서, 온도 센서, 습도 센서, 또는 조도 센서를 포함할 수 있다. 인터페이스는 전자 장치가 외부 전자 장치(예: 전자 장치)와 직접 또는 무선으로 연결되기 위해 사용될 수 있는 하나 이상의 지정된 프로토콜들을 지원할 수 있다. 일 실시예에 따르면, 인터페이스는, 예 를 들면, HDMI(high definition multimedia interface), USB(universal serial bus) 인터페이스, SD(secure digital) 카드 인터페이스, 또는 오디오 인터페이스를 포함할 수 있다. 연결 단자는, 그를 통해서 전자 장치가 외부 전자 장치(예: 전자 장치)와 물리적으로 연결될 수 있는 커넥터를 포함할 수 있다. 일 실시예에 따르면, 연결 단자는, 예를 들면, HDMI 커넥터, USB 커넥터, SD 카드 커넥터, 또는 오디오 커넥터(예: 헤드폰 커넥터)를 포함할 수 있다. 햅틱 모듈은 전기적 신호를 사용자가 촉각 또는 운동 감각을 통해서 인지할 수 있는 기계적인 자극(예: 진 동 또는 움직임) 또는 전기적인 자극으로 변환할 수 있다. 일 실시예에 따르면, 햅틱 모듈은, 예를 들면, 모터, 압전 소자, 또는 전기 자극 장치를 포함할 수 있다. 카메라 모듈은 정지 영상 및 동영상을 촬영할 수 있다. 일 실시예에 따르면, 카메라 모듈은 하나 이 상의 렌즈들, 이미지 센서들, 이미지 시그널 프로세서들, 또는 플래시들을 포함할 수 있다. 전력 관리 모듈은 전자 장치에 공급되는 전력을 관리할 수 있다. 일 실시예에 따르면, 전력 관리 모 듈은, 예를 들면, PMIC(power management integrated circuit)의 적어도 일부로서 구현될 수 있다. 배터리는 전자 장치의 적어도 하나의 구성요소에 전력을 공급할 수 있다. 일 실시예에 따르면, 배터 리는, 예를 들면, 재충전 불가능한 1차 전지, 재충전 가능한 2차 전지 또는 연료 전지를 포함할 수 있다.통신 모듈은 전자 장치와 외부 전자 장치(예: 전자 장치, 전자 장치, 또는 서버) 간 의 직접(예: 유선) 통신 채널 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 모듈은 프로세서(예: 어플리케이션 프로세서)와 독립적으로 운영되고, 직접(예: 유선) 통 신 또는 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함할 수 있다. 일 실시예에 따르면, 통 신 모듈은 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통신 모듈)을 포함할 수 있다. 이들 통신 모듈 중 해당하는 통신 모듈은 제1 네트워크(예: 블 루투스, WiFi(wireless fidelity) direct 또는 IrDA(infrared data association)와 같은 근거리 통신 네트워크) 또는 제2 네트워크(예: 레거시 셀룰러 네트워크, 5G 네트워크, 차세대 통신 네트워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN(wide area network))와 같은 원거리 통신 네트워크)를 통하여 외부의 전자 장치와 통신할 수 있다. 이런 여러 종류의 통신 모듈들은 하나의 구성요소(예: 단일 칩)로 통합되거 나, 또는 서로 별도의 복수의 구성요소들(예: 복수 칩들)로 구현될 수 있다. 무선 통신 모듈은 가입자 식 별 모듈에 저장된 가입자 정보(예: 국제 모바일 가입자 식별자(IMSI))를 이용하여 제1 네트워크 또는 제2 네트워크와 같은 통신 네트워크 내에서 전자 장치를 확인 또는 인증할 수 있다. 무선 통신 모듈은 4G 네트워크 이후의 5G 네트워크 및 차세대 통신 기술, 예를 들어, NR 접속 기술(new radio access technology)을 지원할 수 있다. NR 접속 기술은 고용량 데이터의 고속 전송(eMBB, enhanced mobile broadband), 단말 전력 최소화와 다수 단말의 접속(mMTC, massive machine type communications), 또는 고신뢰도와 저지연(URLLC, ultra-reliable and low-latency communications)을 지원할 수 있다. 무선 통신 모 듈은, 예를 들어, 높은 데이터 전송률 달성을 위해, 고주파 대역(예: mmWave 대역)을 지원할 수 있다. 무 선 통신 모듈은 고주파 대역에서의 성능 확보를 위한 다양한 기술들, 예를 들어, 빔포밍(beamforming), 거 대 배열 다중 입출력(massive MIMO(multiple-input and multiple-output)), 전차원 다중입출력(FD-MIMO, full dimensional MIMO), 어레이 안테나(array antenna), 아날로그 빔형성(analog beam-forming), 또는 대규모 안테 나(large scale antenna)와 같은 기술들을 지원할 수 있다. 무선 통신 모듈은 전자 장치, 외부 전자 장치(예: 전자 장치) 또는 네트워크 시스템(예: 제2 네트워크)에 규정되는 다양한 요구사항을 지원할 수 있다. 일 실시예에 따르면, 무선 통신 모듈은 eMBB 실현을 위한 Peak data rate(예: 20Gbps 이상), mMTC 실현을 위한 손실 Coverage(예: 164dB 이하), 또는 URLLC 실현을 위한 U-plane latency(예: 다운링크(DL) 및 업링크(UL) 각각 0.5ms 이하, 또는 라운드 트립 1ms 이하)를 지원할 수 있다. 안테나 모듈은 신호 또는 전력을 외부(예: 외부의 전자 장치)로 송신하거나 외부로부터 수신할 수 있다. 일 실시예에 따르면, 안테나 모듈은 서브스트레이트(예: PCB) 위에 형성된 도전체 또는 도전성 패턴으로 이루어진 방사체를 포함하는 안테나를 포함할 수 있다. 일 실시예에 따르면, 안테나 모듈은 복수의 안테나 들(예: 어레이 안테나)을 포함할 수 있다. 이런 경우, 제1 네트워크 또는 제2 네트워크와 같은 통신 네트워크에서 사용되는 통신 방식에 적합한 적어도 하나의 안테나가, 예를 들면, 통신 모듈에 의하여 상기 복수의 안테나들로부터 선택될 수 있다. 신호 또는 전력은 상기 선택된 적어도 하나의 안테나를 통하여 통신 모 듈과 외부의 전자 장치 간에 송신되거나 수신될 수 있다. 어떤 실시예에 따르면, 방사체 이외에 다른 부품 (예: RFIC(radio frequency integrated circuit))이 추가로 안테나 모듈의 일부로 형성될 수 있다. 다양한 실시예들에 따르면, 안테나 모듈은 mmWave 안테나 모듈을 형성할 수 있다. 일 실시예에 따르면, mmWave 안테나 모듈은 인쇄 회로 기판, 상기 인쇄 회로 기판의 제1 면(예: 아래 면)에 또는 그에 인접하여 배치 되고 지정된 고주파 대역(예: mmWave 대역)을 지원할 수 있는 RFIC, 및 상기 인쇄 회로 기판의 제2 면(예: 윗 면 또는 측 면)에 또는 그에 인접하여 배치되고 상기 지정된 고주파 대역의 신호를 송신 또는 수신할 수 있는 복수의 안테나들(예: 어레이 안테나)을 포함할 수 있다. 상기 구성요소들 중 적어도 일부는 주변 기기들간 통신 방식(예: 버스, GPIO(general purpose input and output), SPI(serial peripheral interface), 또는 MIPI(mobile industry processor interface))을 통해 서로 연결되고 신호(예: 명령 또는 데이터)를 상호간에 교환할 수 있다. 일 실시예에 따르면, 명령 또는 데이터는 제2 네트워크에 연결된 서버를 통해서 전자 장치와 외 부의 전자 장치간에 송신 또는 수신될 수 있다. 외부의 전자 장치(102, 또는 104) 각각은 전자 장치 와 동일한 또는 다른 종류의 장치일 수 있다. 일 실시예에 따르면, 전자 장치에서 실행되는 동작들의 전부 또는 일부는 외부의 전자 장치들(102, 104, 또는 108) 중 하나 이상의 외부의 전자 장치들에서 실행될 수 있다. 예를 들면, 전자 장치가 어떤 기능이나 서비스를 자동으로, 또는 사용자 또는 다른 장치로부터의 요청에 반응하여 수행해야 할 경우에, 전자 장치는 기능 또는 서비스를 자체적으로 실행시키는 대신에 또는 추가적으로, 하나 이상의 외부의 전자 장치들에게 그 기능 또는 그 서비스의 적어도 일부를 수행하라고 요청할 수 있다. 상기 요청을 수신한 하나 이상의 외부의 전자 장치들은 요청된 기능 또는 서비스의 적어도 일부, 또는 상 기 요청과 관련된 추가 기능 또는 서비스를 실행하고, 그 실행의 결과를 전자 장치로 전달할 수 있다. 전 자 장치는 상기 결과를, 그대로 또는 추가적으로 처리하여, 상기 요청에 대한 응답의 적어도 일부로서 제 공할 수 있다. 이를 위하여, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨팅, 모바일 에지 컴퓨팅(MEC, mobile edge computing), 또는 클라이언트-서버 컴퓨팅 기술이 이용될 수 있다. 전자 장치는, 예를 들어, 분산 컴퓨팅 또는 모바일 에지 컴퓨팅을 이용하여 초저지연 서비스를 제공할 수 있다. 다른 실시예에 있어서, 외부의 전자 장치는 IoT(internet of things) 기기를 포함할 수 있다. 서버는 기계 학습 및/또는 신경망을 이용 한 지능형 서버일 수 있다. 일 실시예에 따르면, 외부의 전자 장치 또는 서버는 제2 네트워크 내에 포함될 수 있다. 전자 장치는 5G 통신 기술 및 IoT 관련 기술을 기반으로 지능형 서비스(예: 스마트 홈, 스마트 시티, 스마트 카, 또는 헬스 케어)에 적용될 수 있다. 본 개시의 다양한 실시예들을 서술하기에 앞서, 본 개시의 실시예가 적용될 수 있는 전자 장치에 대하여 설명한다. 도 2a는 본 개시의 일 실시예에 따른 펼침 상태(flat state 또는 unfolded state)를 도시한 전자 장치의 사시도 이다. 도 2b는 본 개시의 일 실시예에 따른 펼침 상태에서 전자 장치의 전면을 도시한 평면도이다. 도 2c는 본 개시의 일 실시예에 따른 펼침 상태에서 전자 장치의 후면을 도시한 평면도이다. 도 3a는 본 개시의 일 실시예에 따른 접힘 상태(folded state)를 도시한 전자 장치의 사시도이다. 도 3b는 본 개시의 일 실시예에 따른 중간 상태(intermediate state)를 도시한 전자 장치의 사시도이다. 도 2a 내지 도 3b를 참조하면, 전자 장치(예: 도 1의 전자 장치)는 힌지 구조(예: 도 2b의 힌지 구조 )(예: 힌지 장치 또는 힌지 모듈)를 기준으로 서로에 대하여 마주보며 접히도록 회동 가능하게 결합되는 한 쌍의 하우징(310, 320)(예: 폴더블 하우징)을 포함할 수 있다. 일 실시예에서, 힌지 구조는 x축 방향으 로 배치되거나, y축 방향으로 배치될 수 있다. 일 실시예에서, 힌지 구조는 동일한 방향 또는 서로 다른 방향으로 폴딩되도록 2개 이상 배치될 수도 있다. 일 실시예에서, 전자 장치는 한 쌍의 하우징(310, 320) 에 의해 형성된 영역에 배치되는 제1 디스플레이(예: 메인 디스플레이)(예: 플렉서블 디스플레이)를 포함 할 수 있다. 일 실시예에서, 제1 하우징과 제2 하우징은 폴딩 축(축 F)을 중심으로 양측에 배치되고, 폴딩 축(축 F)에 대하여 실질적으로 대칭인 형상을 가질 수 있다. 일 실시예에서, 제1 하우징 및 제2 하우 징은 전자 장치의 상태가 펼침 상태(flat state 또는 unfolded state)인지, 접힘 상태(folded state)인지, 또는 중간 상태(intermediate state)인지의 여부에 따라 서로 이루는 각도나 거리가 달라질 수 있 다. 일 실시예에 따르면, 한 쌍의 하우징(310, 320)은 힌지 구조와 결합되는 제1 하우징(예: 제1 하우징 구조) 및 힌지 구조와 결합되는 제2 하우징(예: 제2 하우징 구조)을 포함할 수 있다. 일 실시예에서, 제1 하우징은, 펼침 상태에서, 제1 방향(예: 전면 방향)(z축 방향)을 향하는 제1 면 및 제1 면 과 대향되는 제2 방향(예: 후면 방향)(-z축 방향)을 향하는 제2 면을 포함할 수 있다. 일 실시예에서, 제2 하우징은 펼침 상태에서, 제1 방향(z축 방향)을 향하는 제3 면 및 제2 방향(-z축 방향)을 향하는 제4 면을 포함할 수 있다. 일 실시예에서, 전자 장치는, 펼침 상태에서, 제1 하우징의 제1 면 과 제2 하우징의 제3 면이 실질적으로 동일한 제1 방향(z축 방향)을 향하고, 접힘 상태에서 제1 면 과 제3 면이 서로 마주보는 방식으로 동작될 수 있다. 일 실시예에서, 전자 장치는, 펼침 상태 에서, 제1 하우징의 제2 면과 제2 하우징의 제4 면이 실질적으로 동일한 제2 방향(-z 축 방향)을 향하고, 접힘 상태에서 제2 면과 제4 면이 서로 반대 방향을 향하도록 동작될 수 있다. 예를 들면, 접힘 상태에서 제2 면은 제1 방향(z축 방향)을 향할 수 있고, 제4 면은 제2 방향(-z 축 방향) 을 향할 수 있다. 일 실시예에 따르면, 제1 하우징은 적어도 부분적으로 전자 장치의 외관을 형성하는 제1 측면 부재 및 제1 측면 부재와 결합되고, 전자 장치의 제2 면의 적어도 일부를 형성하는 제1 후면 커버를 포함할 수 있다. 일 실시예에서, 제1 측면 부재는 제1 측면(313a), 제1 측면(313a)의 일단으 로부터 연장되는 제2 측면(313b) 및 제1 측면(313a)의 타단으로부터 연장되는 제3 측면(313c)을 포함할 수 있다. 일 실시예에서, 제1 측면 부재는 제1 측면(313a), 제2 측면(313b), 및 제3 측면(313c)을 통해 장방 형(예: 정사각형 또는 직사각형) 형상으로 형성될 수 있다. 일 실시예에 따르면, 제2 하우징은 적어도 부분적으로 전자 장치의 외관을 형성하는 제2 측면 부재 및 제2 측면 부재와 결합되고, 전자 장치의 제4 면의 적어도 일부를 형성하는 제2 후면 커버를 포함할 수 있다. 일 실시예에서, 제2 측면 부재는 제4 측면(323a), 제4 측면(323a)의 일단으 로부터 연장되는 제5 측면(323b) 및 제4 측면(323a)의 타단으로부터 연장되는 제6 측면(323c)을 포함할 수 있다. 일 실시예에서, 제2 측면 부재는 제4 측면(323a), 제5 측면(323b), 및 제6 측면(323c)을 통해 장방 형 형상으로 형성될 수 있다. 일 실시예에 따르면, 한 쌍의 하우징(310, 320)은 도시된 형태 및 결합으로 제한되지 않으며, 다른 형상이나 부 품의 조합 및/또는 결합에 의해 구현될 수 있다. 예를 들어, 제1 측면 부재는 제1 후면 커버와 일체 로 형성될 수 있고, 제2 측면 부재는 제2 후면 커버와 일체로 형성될 수 있다. 일 실시예에 따르면, 전자 장치는, 펼침 상태에서, 제1 측면 부재의 제2 측면(313b)과 제2 측면 부재 의 제5 측면(323b)이 연결될 수 있다. 일 실시예에서, 전자 장치는, 펼침 상태에서, 제1 측면 부재 의 제3 측면(313c)과 제2 측면 부재의 제6 측면(323c)이 연결될 수 있다. 일 실시예에서, 전자 장치 는, 펼침 상태에서, 제2 측면(313b)과 제5 측면(323b)의 합한 길이가 제1 측면(313a) 및/또는 제4 측면 (323a)의 길이보다 길도록 구성될 수 있다. 또한, 제3 측면(313c)과 제6 측면(323c)의 합한 길이가 제1 측면 (313a) 및/또는 제4 측면(323a)의 길이보다 길도록 구성될 수 있다. 일 실시예에 따르면, 제1 측면 부재 및/또는 제2 측면 부재는 금속으로 형성되거나, 금속에 사출되는 폴리머(polymer)를 더 포함할 수 있다. 일 실시예에서, 제1 측면 부재 및/또는 제2 측면 부재는 폴리 머로 형성된 적어도 하나의 분절부(3161, 3162, 및/또는 3261, 3262)를 통해 전기적으로 분절된 적어도 하나의 도전성 부분(316 및/또는 326)을 포함할 수도 있다. 이러한 경우, 적어도 하나의 도전성 부분(316 및/또는 32 6)은 전자 장치에 포함된 무선 통신 회로(예: 도 1의 무선 통신 모듈)와 전기적으로 연결됨으로써 지 정된 적어도 하나의 대역(예: 약 400MHz ~ 약 6000MHz)에서 동작하는 안테나로 사용될 수 있다. 일 실시예에 따르면, 제1 후면 커버 및/또는 제2 후면 커버는, 예를 들어, 코팅 또는 착색된 유리, 세라믹, 폴리머, 또는 금속(예: 알루미늄(aluminum), 스테인레스 스틸(STS, stainless steel), 또는 마그네슘 (magnesium)) 중 적어도 하나 또는 적어도 둘의 조합에 의하여 형성될 수 있다. 일 실시예에 따르면, 제1 디스플레이(예: 메인 디스플레이)는 제1 하우징의 제1 면으로부터 힌 지 구조를 가로질러 제2 하우징의 제3 면의 적어도 일부까지 연장되도록 배치될 수 있다. 예를 들어, 제1 디스플레이는 실질적으로 제1 면과 대응하는 제1 부분(330a), 제3 면과 대응하는 제2 부분(330b), 및 제1 부분(330a)과 제2 부분(330b)을 연결하고, 힌지 구조와 대응하는 제3 부분(330c)(예: 굴곡 가능 영역)을 포함할 수 있다. 일 실시예에서, 전자 장치는 제1 하우징의 가장자리를 따라 결합되는 제1 보호 커버(예: 제1 보 호 프레임 또는 제1 장식 부재)를 포함할 수 있다. 일 실시예에서, 전자 장치는 제2 하우징의 가장자 리를 따라 결합되는 제2 보호 커버(예: 제2 보호 프레임 또는 제2 장식 부재)를 포함할 수 있다. 일 실시 예에서, 제1 보호 커버 및/또는 제2 보호 커버는 금속 또는 폴리머 재질로 형성될 수 있다. 일 실시 예에서, 제1 보호 커버 및/또는 제2 보호 커버는 장식 부재(decoration member)로 사용될 수 있다. 일 실시예에서, 제1 디스플레이는 제1 부분(330a)의 가장자리가 제1 하우징과 제1 보호 커버 사 이에 개재되도록 위치될 수 있다. 일 실시예에서, 제1 디스플레이는 제2 부분(330b)의 가장자리가 제2 하 우징과 제2 보호 커버 사이에 개재되도록 위치될 수 있다. 일 실시예에서, 제1 디스플레이는 힌 지 구조와 대응되는 영역에 배치되는 보호 캡을 통해, 보호 캡에 대응되는 제1 디스플레이(33 0)의 가장자리가 보호되도록 위치될 수 있다. 따라서, 제1 디스플레이는 실질적으로 가장자리가 외부로부 터 보호될 수 있다. 일 실시예에서, 전자 장치는 힌지 구조를 지지하고, 전자 장치가 접힘 상태일 때, 외부로 노출 되고, 펼침 상태일 때, 제1공간(예: 제1 하우징의 내부 공간) 및 제2공간(예: 제2 하우징의 내부 공 간)으로 인입됨으로써 외부로부터 보이지 않게 배치되는 힌지 하우징(예: 힌지 커버)을 포함할 수 있다. 일 실시예에서, 제1 디스플레이는 제2 면의 적어도 일부로부터 제4 면의 적어도 일부까지 연장 배치될 수 있다. 이러한 경우, 전자 장치는 제1 디스플레이가 외부로 노출될 수 있도록 접힐 수 있다 (아웃 폴딩 방식). 일 실시예에 따르면, 전자 장치는 제1 디스플레이와 별도로 배치되는 제2 디스플레이(예: 서브 디스플레이)를 포함할 수 있다. 일 실시예에서, 제2 디스플레이는 제1 하우징의 제2 면에 적어도 부분적으로 노출되도록 배치됨으로써, 접힘 상태일 경우, 제1 디스플레이의 표시 기능을 대체하여, 전 자 장치의 상태 정보를 표시할 수 있다. 일 실시예에서, 제2 디스플레이는 제1 후면 커버의 적 어도 일부 영역을 통해 외부로부터 보일 수 있게 배치될 수 있다. 일 실시예에서, 제2 디스플레이는 제2 하우징의 제4 면에 배치될 수도 있다. 이러한 경우, 제2 디스플레이는 제2 후면 커버의 적 어도 일부 영역을 통해 외부로부터 보일 수 있게 배치될 수 있다. 일 실시예에 따르면, 전자 장치는 입력 장치(예: 마이크)(예: 도 1의 입력 모듈), 음향 출력 장 치(301, 302)(예: 도 1의 음향 출력 모듈), 센서 모듈(예: 도 1의 센서 모듈), 카메라 장치 (305, 308)(예: 도 1의 카메라 모듈), 키 입력 장치(예: 도 1의 입력 모듈), 또는 커넥터 포트 (예: 도 1의 연결 단자) 중 적어도 하나를 포함할 수 있다. 도시된 실시예에서, 입력 장치(예: 마이크), 음향 출력 장치(301, 302), 센서 모듈, 카메라 장치(305, 308), 키 입력 장치, 또는 커넥 터 포트는 제1 하우징 또는 제2 하우징에 형성된 홀(hole) 또는 형상을 지칭하고 있으나, 전자 장치의 내부에 배치되고, 홀 또는 형상을 통해 동작하는 실질적인 전자 부품(예: 입력 장치, 음향 출력 장 치, 센서 모듈, 또는 카메라 장치)를 포함할 수도 있다. 일 실시예에 따르면, 입력 장치는 제2 하우징에 배치되는 적어도 하나의 마이크를 포함할 수 있 다. 일 실시예에서, 입력 장치는 소리의 방향을 감지할 수 있도록 배치되는 복수 개의 마이크들을 포 함할 수 있다. 일 실시예에서, 복수 개의 마이크들은 제1 하우징 및/또는 제2 하우징에서 적절 한 위치에 배치될 수 있다. 일 실시예에서, 음향 출력 장치(301, 302)는 스피커들(301, 302)을 포함할 수 있다. 일 실시예에서, 스피커들(301, 302)은, 제1 하우징에 배치되는 통화용 리시버와 제2 하우징에 배치되는 스피커를 포함할 수 있다. 일 실시예에서, 입력 장치, 음향 출력 장치(301, 302), 및 커넥 터 포트는 전자 장치의 제1 하우징 및/또는 제2 하우징에 마련된 공간에 배치되고, 제1 하 우징 및/또는 제2 하우징에 형성된 적어도 하나의 홀을 통하여 외부 환경에 노출될 수 있다. 일 실시예에서, 적어도 하나의 커넥터 포트는, 외부 전자 장치와 전력 및/또는 데이터를 송수신하기 위하 여 사용될 수 있다. 일 실시예에서, 적어도 하나의 커넥터 포트(예: 이어잭 홀)는 외부 전자 장치와 오디오 신 호를 송수신하기 위한 커넥터(예: 이어잭)를 수용할 수도 있다. 일 실시예에서, 제1 하우징 및/또는 제2 하우징에 형성된 홀은 입력 장치 및 음향 출력 장치(301, 302)를 위하여 공용으로 사용될 수 있다. 일 실시예에서는, 음향 출력 장치(301, 302)는 제1 하우징 및/또는 제2 하우징에 형성된 홀이 배제된 채, 동작되는 스피커(예: 피에조 스피커)를 포함할 수도 있다. 일 실시예에 따르면, 센서 모듈은, 전자 장치의 내부의 작동 상태, 또는 외부의 환경 상태에 대응하 는 전기 신호 또는 데이터 값을 생성할 수 있다. 센서 모듈은, 예를 들어, 제1 하우징의 제1 면(31 1)을 통해 외부 환경을 검출할 수 있다. 일 실시예에서, 전자 장치는 제1 하우징의 제2 면을 통 해 외부 환경을 검출하도록 배치되는 적어도 하나의 센서 모듈을 더 포함할 수도 있다. 일 실시예에서, 센서 모 듈(예: 조도 센서)은 제1 디스플레이 아래에서, 제1 디스플레이를 통해 외부 환경을 검출하도록 배치될 수 있다. 일 실시예에서, 센서 모듈은 제스처 센서(gesture sensor), 자이로 센서(gyro sensor), 기압 센서 (barometer sensor), 마그네틱 센서(magnetic sensor), 가속도 센서(acceleration sensor), 홀 센서(hall sensor), 그립 센서(grip sensor), 컬러 센서(color sensor)(예: RGB(red, green, blue) 센서), IR(infrared) 센서, 생체 센서(biometric sensor), 온도 센서(temperature sensor), 습도 센서(humidity sensor), 조도 센서 (illuminance sensor 또는 ALS(ambient light sensor)), 근접 센서(proximity sensor), 및/또는 초음파 센서 (ultrasonic sensor) 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 카메라 장치들(305, 308)은, 제1 하우징의 제1 면에 배치되는 제1 카메라 장치 (예: 전면 카메라 장치) 및 제1 하우징의 제2 면에 배치되는 제2 카메라 장치(예: 후면 카 메라 장치)를 포함할 수 있다. 전자 장치는 제2 카메라 장치 근처에 배치되는 플래시를 더 포함 할 수 있다. 일 실시예에서, 카메라 장치들(305, 308)은 하나 또는 복수의 렌즈들, 이미지 센서, 및/또는 이미 지 시그널 프로세서(ISP, image signal processor)를 포함할 수 있다. 플래시는, 예를 들어, 발광 다이오 드(LED, light emitting diode), IR LED, 반도체 레이저(LD, laser diode) 및/또는 제논 램프(xenon lamp)와 같은 발광 소자(luminous element)를 포함할 수 있다. 일 실시예에서, 카메라 장치들(305, 308)은 2개 이상의 렌즈들(예: 광각 렌즈, 초광각 렌즈 및/또는 망원 렌즈) 및 이미지 센서들이 전자 장치의 한 면(예: 제1 면, 제2 면, 제3 면, 또는 제4 면)에 위치하도록 배치될 수 있다. 일 실시예에서, 카메라장치들(305, 308)은 TOF(time of flight) 용 렌즈들 및/또는 이미지 센서를 포함할 수도 있다. 일 실시예에 따르면, 키 입력 장치(예: 키 버튼)는, 제1 하우징의 제1 측면 부재의 제3 측면 (313c)에 배치될 수 있다. 일 실시예에서, 키 입력 장치는 제1 하우징의 다른 측면들(313a, 313b) 및 /또는 제2 하우징의 측면들(323a, 323b, 323c) 중 적어도 하나의 측면에 배치될 수도 있다. 일 실시예에서, 전자 장치는 키 입력 장치들 중 일부 또는 전부를 포함하지 않을 수 있고, 포함되지 않 은 키 입력 장치는 제1 디스플레이 상에 소프트 키와 같은 다른 형태로 구현될 수도 있다. 일 실시예 에서, 키 입력 장치는 제1 디스플레이에 포함된 압력 센서를 이용하여 구현될 수도 있다. 일 실시예에 따르면, 카메라 장치들(305, 308) 중 일부 카메라 장치(예: 제1 카메라 장치) 및/또는 센서 모듈은 제1 디스플레이를 통해 노출되도록 배치될 수 있다. 일 예로, 제1 카메라 장치 및/또는 센서 모듈은 전자 장치의 내부 공간에서, 제1 디스플레이에 적어도 부분적으로 형성된 오프닝 (예: 관통 홀)을 통해 외부 환경과 접할 수 있도록 배치될 수 있다. 일 예로, 일부 센서 모듈은 전자 장치 의 내부 공간에서 제1 디스플레이를 통해 시각적으로 노출되지 않고 그 기능을 수행하도록 배치될 수 도 있다. 예를 들어, 이러한 경우, 제1 디스플레이의, 센서 모듈과 대면하는 영역은 오프닝이 생략될 수도 있다. 도 3b를 참고하면, 전자 장치는 힌지 구조를 통해 중간 상태(intermediate state)를 유지하도록 동작 될 수도 있다. 이러한 경우, 전자 장치는 제1 면과 대응하는 디스플레이 영역과, 제3 면과 대응 하는 디스플레이 영역에 서로 다른 컨텐츠가 표시되도록 제1 디스플레이를 제어할 수도 있다. 일 실시예에 서, 전자 장치는 힌지 구조를 통해 일정 변곡 각도(예: 중간 상태일 때, 제1 하우징과 제2 하우 징 사이의 각도)를 기준으로 실질적으로 펼침 상태(예: 도 2a의 펼침 상태) 및/또는 실질적으로 접힘 상태 (예: 도 3a의 접힘 상태)로 동작될 수 있다. 예를 들어, 전자 장치는, 힌지 구조를 통해, 일정 변곡 각도로 펼쳐진 중간 상태에서, 펼쳐지는 방향(R1 방향)으로 가압력이 제공될 경우, 펼침 상태(예: 도 2a의 펼침 상태)로 천이되도록 동작될 수 있다. 예를 들어, 전자 장치는, 힌지 구조를 통해, 일정 변곡 각도로 펼쳐진 중간 상태에서, 접히려는 방향(R2 방향)으로 가압력이 제공될 경우, 접힘 상태(예: 도 3a의 접힘 상태) 로 천이되도록 동작될 수 있다. 일 실시예에서, 전자 장치는, 힌지 구조를 통해 다양한 각도에서 펼 쳐진 상태(미도시)를 유지하도록 동작될 수도 있다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 예를 설명하기 위해 도시하는 도면이다. 일 실시예에 따라, 도 4는 다양한 디스플레이 형태에 따른 전자 장치(예: 도 1의 전자 장치)의 다양한 폼 팩터(form factor)의 예를 나타낼 수 있다. 일 실시예에 따라, 도 4에 예시된 바와 같이, 전자 장치는 다 양한 형태로 구현될 수 있고, 전자 장치의 구현 형태에 따라 디스플레이(예: 도 1의 디스플레이 모듈 )가 다양한 방식으로 제공될 수 있다. 본 문서에 개시된 실시예에 따른 전자 장치는 폴더블 형태의 폼팩터를 가지는 전자 장치(예: 폴더블 장치(410, 420 또는 430))를 예로 설명하지만, 일 실시예에 따른 전자 장치 및 그의 동작은 이에 한정되지 않는다. 예를 들어, 전자 장치는, 폴더블(foldable), 바형(bar type) 또는 평판형(plate type), 슬라이더 블(slidable), 및/또는 폴더블&슬라이더블 하이브리드와 같은 다양한 폼팩터 및 그에 의해서도 동작할 수 있다. 예를 들어, 도시된 전자 장치는 폴더블 장치, 바형 또는 평판형 장치, 또는 슬라이더블 장치의 일부일 수 있다. 일 실시예에서, 전자 장치는 폴딩 및 언폴딩 동작이 가능하고, 접힘 상태, 펼침 상태 또는 중간 상 태를 가지며, 서로 다른 면 각각에 카메라(예: 서로 다른 면에 배치된 적어도 2개의 카메라들(예: 제1 카메라 장치 및 제2 카메라 장치)) 및 디스플레이(예: 서로 다른 면에 배치된 적어도 2개의 디스플레이들(예: 제1 디스플레이 및 제2 디스플레이))가 배치되는 다양한 폼팩터를 포함할 수 있다. 일 실시예에서, 전자 장치는 바형(또는 평판형) 및/또는 슬라이더블과 같이 서로 다른 면 각각에 카메라 (예: 서로 다른 면에 배치된 적어도 2개의 카메라들(예: 제1 카메라 장치 및 제2 카메라 장치))이 배 치되고, 어느 일 면에 디스플레이가 배치되는 다양한 폼팩터를 포함할 수 있다. 일 실시예에서, 펼침 상태(unfolded state)는 열린 상태, 오픈 상태(open state), 또는 플랫(또는 평평한) 상태 (flat state)를 의미할 수 있다. 일 실시예에서, 펼침 상태는 제1 하우징과 제2 하우징이 나란히 배치된 상태로 서, 전자 장치가 완전히 펼쳐진 상태를 의미할 수 있다. 일 실시예에서, 펼침 상태는 제1 하우징과 제2 하 우징 간의 각도가 약 180도를 이루는 것으로, 제1 하우징의 제1 면과 제2 하우징의 제2 면이 동일한 방향(예: 제1 방향)을 향하도록 배치될 수 있다. 일 실시예에서, 접힘 상태(folded state)는 닫힌 상태 또는 클로즈 상태(close state)를 의미할 수 있다. 일 실 시예에서, 접힘 상태는 제1 하우징과 제2 하우징이 서로 마주보게 배치된 상태로서, 전자 장치가 완전히 접혀진 상태를 의미할 수 있다. 일 실시예에서, 접힘 상태는 제1 하우징과 제2 하우징 간의 각도가 좁은 각도 (예: 약 0도 ~ 약 5도)를 이루는 것으로, 제1 하우징의 제1 면과 제2 하우징의 제2 면이 서로 마주볼 수 있다. 일 실시예에서, 중간 상태(intermediate state)는 제1 하우징과 제2 하우징이 일정 각도로 배치된 상태로서, 전 자 장치가 펼침 상태 또는 접힘 상태가 아닐 수 있다. 일 실시예에서, 중간 상태는 제1 하우징의 제1 면과 제2 하우징의 제2 면이 일정 각도(예: 약 6 도 ~ 약 179도)를 이루는 상태를 의미할 수 있다. 일 실시예에 따라, 전자 장치(예: 폴더블 장치(410, 420 또는 430))는 디스플레이(예: 도 1의 디스플레이 모듈)의 서로 다른 두 영역을 실질적으로 마주보게 또는 서로 반대 방향을 향하는(opposite to) 방향으로 접힘이 가능한 전자 장치를 의미할 수 있다. 일반적으로, 사용자는 전자 장치를 휴대하는 경우 전자 장치 (예: 폴더블 장치(410, 420 또는 430))의 디스플레이(예: 도 1의 디스플레이 모듈)를 서로 다른 두 영역이 마주보는 상태로 또는 대향하는 방향으로 접어서 휴대할 수 있고, 전자 장치를 실제 사용하는 상태 에서는 디스플레이를 펼쳐 서로 다른 두 영역이 실질적으로 평판 형태를 이루게 하여 사용할 수 있다. 일 실시예에 따르면, 전자 장치(예: 폴더블 장치(410, 420 또는 430))는 하나의 폴딩 축에 기반하여 2개의 디스플레이 면(예: 제1 디스플레이 면 및 제2 디스플레이 면)을 포함하는 폼팩터(예: 410 또는 420) 및/또는 적 어도 2개의 폴딩 축에 기반하여 적어도 3개의 디스플레이 면(예: 제1 디스플레이 면, 제2 디스플레이 면 및 제3 디스플레이 면)을 포함하는 폼팩터(예: 430)를 포함할 수 있다. 다양한 실시예들이 이에 한정되는 것은 아니며, 이는 예시적인 것으로, 전자 장치가 가질 수 있는 폴딩 축들의 수는 제한하지 않는다. 일 실시예에 따르면, 전자 장치는 구현 형태에 따라 디스플레이(예: 도 1의 디스플레이 모듈)가 다양한 방식(예: 인-폴딩(in-folding), 아웃-폴딩(out-folding), 또는 인/아웃 폴딩)으로 폴딩 또는 언폴딩될 수 있다. 일 실시 예에 따르면, 전자 장치는 세로 폴더블, 가로 폴더블, G 폴더블, Z 폴더블, 또는 폴더블&슬라이더블 하이 브리드와 같이 다양한 폴더블 방식을 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 전자 장치의 전면인 제1 면 및 제2 면에 제1 디스플레이(예: 메인 디스플레이)(예: 도 1의 디스플레이 모듈)를 형성할 수 있다. 제1 디스플레이는 전면(예: 전자 장치 의 제1 방향)에 전체적으로 형성될 수 있다. 제1 디스플레이는 적어도 일부 영역이 평면 또는 곡면으로 변형될 수 있는 플렉서블 디스플레이를 포함할 수 있다. 제1 디스플레이는 폴딩 축을 기준으로 좌, 우 또는 상, 하로 접혀질 수 있다. 제1 디스플레이는 제1 면에 대응하여 제1 표시 영역 또는 제2 면에 대응하여 제2 표시 영역을 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 전자 장치의 후면의 적어도 일부에 제2 디스플레이(예: 커버 디스 플레이 또는 서브 디스플레이)(예: 도 1의 디스플레이 모듈)를 형성할 수 있다. 제2 디스플레이는 전자 장 치의 제3 면의 적어도 일부에 형성될 수 있다. 일 실시예에 따르면, 전자 장치가 펼침 상태에서는 제1 디스플레이는 온(on)(또는 활성화)되고, 제2 디스 플레이는 오프(off)(또는 비활성화)될 수 있다. 제1 디스플레이가 온된 상태에서 일정한 시간(예: 약 5초, 약 10초, 약 1분) 동안 사용자 입력(예: 터치, 버튼 선택)이 검출되지 않는 경우, 전자 장치는 제1 디스플레 이를 오프시킬 수 있다. 일 실시예에 따르면, 제2 디스플레이가 오프된 상태에서 제2 디스플레이에서 사용자 입력(예: 터치, 버튼 선 택)이 검출되는 경우, 전자 장치는 제2 디스플레이를 온시킬 수 있다. 일 실시예에 따르면, 제2 디스플레 이는 전자 장치가 펼침 상태 또는 접힘 상태에서 사용자 입력 또는 전자 장치의 지정된 동작에 기반 하여 턴-온될 수 있다. 일 실시예에 따르면, 전자 장치가 접힘 상태 또는 중간 상태에서는 제1 디스플레이는 오프되고, 제2 디스 플레이는 온될 수 있다. 제2 디스플레이가 온된 상태에서 일정한 시간 동안 사용자 입력이 검출되지 않는 경우, 전자 장치는 제2 디스플레이를 오프시킬 수 있다. 전자 장치가 접힘 상태 또는 중간 상태이고, 제2 디스플레이가 오프된 경우, 전자 장치에 형성된(또는 장착된) 버튼이 선택되는 경우, 전자 장치는 제 2 디스플레이를 온시킬 수 있다. 또는, 전자 장치가 접힘 상태 또는 중간 상태이고, 제2 디스플레이가 오 프된 후, 제2 디스플레이 상에 사용자 입력이 검출되는 경우, 전자 장치는 제2 디스플레이를 온시킬 수 있 다. 본 개시의 일 실시예에서는, 설명의 편의를 위해, 전자 장치가 전면과 후면의 디스플레이(예: 전면의 제1 디스플레이 및 후면(또는 커버면)의 제2 디스플레이)를 갖는 장치인 것을 예로 설명하지만, 본 개시에 따른 다 양한 실시예들은 이에 제한하지 않는다. 도 5는 본 개시의 일 실시예에 따른 전자 장치를 이용하여 영상을 촬영하는 동작 예를 도시하는 도면이다. 일 실시예에 따라, 도 5에서는 사용자가 전자 장치를 이용하여, 반사체에 투영된 투영체 (예: 반사체에 비춰진 사용자의 객체)를 포함하여 영상을 촬영하는 예를 나타낼 수 있다. 예를 들어, 도 5 는 사용자가 반사체를 이용하여 거울 샷(mirror shot 또는 mirror selfie) 촬영을 수행하는 동작 예 를 나타낼 수 있다. 일 실시예에서, 반사체는 빛을 받아서 반사하는 물체를 나타낼 수 있다. 예를 들어, 반사체는 거울, 유리창, 및/또는 오프(off) 상태의 디스플레이 장치(또는 스크린)(예: TV, 모니터)와 같이 사물을 투영하여 나 타낼 수 있는 다양한 물체를 포함할 수 있다. 일 실시예에서, 투영체는 사람 및/또는 사물이 반사체에 반영된(또는 투영된) 객체를 나타낼 수 있다. 예를 들어, 도 5의 예시에서, 투영체는 현실 세계의 사용자와 사용자가 휴대하고 있는 전 자 장치가 반영된 객체를 포함할 수 있다. 일 실시예에서, 투영체는 사용자의 설정 구도에 따라 사용자와 전자 장치가 모두 투영되거나, 또는 전자 장치만 투영될 수 있다. 일 실시예에서, 투 영체는 다른 사물 및 배경이 더 포함될 수 있다. 일 실시예에 따르면, 사용자는 촬영 모드에서 전자 장치의 카메라(예: 도 1의 카메라 모듈)를 반사체를 향하도록 하고, 거울 샷(mirror shot 또는 mirror selfie) 촬영을 수행할 수 있다. 일 실시예에 서, 거울 샷 촬영은, 예를 들어, 사용자가 전자 장치의 카메라를 이용하여 반사체(예: 거울)에 투영 된 피사체(예: 사용자 포함)를 포함하여 촬영하는 촬영 모드를 포함할 수 있다. 일 실시예에 따르면, 전자 장치 는 사용자의 촬영 요청 시에, 카메라를 통해, 반사체 및 반사체에 투영된 사용자 및/또는 전자 장치에 대응하는 투영체를 포함하는 영상을 획득할 수 있다. 일 실시예에 따라, 전자 장치(10 1)는 획득된 영상을 전자 장치의 디스플레이를 통해 표시(예: 프리뷰 표시)할 수 있다. 본 개시의 일 실시예에서는, 전자 장치의 카메라를 이용하여 반사체에 투영된 투영체를 포함하 는 영상 촬영 시에, 전자 장치가 반사체를 감지하고, 반사체를 감지하는 것에 기반하여 지정된 촬영 모드(예: 거울 샷 모드)로 자동 전환하고, 지정된 촬영 모드에서 반사체에 투영되는 전자 장치 의 디스플레이 면에 지정된 그래픽 요소(또는 컨텐츠)를 표시하고, 반사체에 투영된 디스플레이의 그래픽 요소(또는 컨텐츠)를 포함하여 영상 촬영을 지원할 수 있다. 이하에서는, 도 5에 예시된 바와 같은 촬영 환경에 서 반사체 감지에 기반한 영상 촬영을 지원하는 전자 장치 및 그의 동작 방법에 대해서 상세하게 설 명한다. 도 6은 본 개시의 일 실시예에 따른 전자 장치의 구성을 개략적으로 도시하는 도면이다. 도 6을 참조하면, 본 개시의 일 실시예에 따른 전자 장치는 카메라(예: 도 1의 카메라 모듈), 디스플레이(예: 도 1의 디스플레이 모듈), 센서 회로(예: 도 1의 센서 모듈), 메모리 (예: 도 1의 메모리), 및/또는 프로세서(예: 도 1의 프로세서)를 포함할 수 있다. 일 실시 예에 따르면, 전자 장치는 도 1을 참조한 설명 부분에서 설명한 바와 같은 전자 장치의 구성 요소의 전부 또는 적어도 일부를 포함할 수 있다. 일 실시예에 따르면, 카메라는 도 1의 카메라 모듈에 대응할 수 있다. 일 실시예에 따르면, 카메라 는 활성화 시에 피사체 촬영을 통해 관련 결과(예: 촬영 이미지)를 프로세서 및/또는 디스플레이 (예: 도 1의 디스플레이 모듈)에 전달할 수 있다. 일 실시예에 따르면, 카메라는 복수개의 카메 라들(예: 제1 카메라 및 제2 카메라)을 포함할 수 있다. 일 실시예에 따라, 제1 카메라는 전자 장치의 전자 장치의 제1 면에 배치되는 적어도 하나의 카메라 장치(예: 전면 카메라 장치)를 포함할 수 있다. 일 실시예에 따라, 제2 카메라는 전자 장치의 제1 면(예: 제1 디스플레이(또는 메인 디스플 레이)가 제공되는 면)과 반대되는 제2 면(예: 제2 디스플레이(또는 커버 디스플레이)가 제공되는 면)에 매치되 는 적어도 하나의 카메라 장치(예: 후면 카메라 장치)를 포함할 수 있다. 일 실시예에 따르면, 카메라는 TOF(time of flight) 센서(미도시)와 연계하여 동작하거나, TOF 센서가 일 체형으로 포함(또는 결합)된 TOF 카메라를 포함할 수 있다. 예를 들어, TOF는 비행시간(time of flight) 즉, 빛 (예: 적외선)을 쏘아서 반사되어 오는 시간을 측정하여 거리(depth)를 계산하는 방식을 나타낼 수 있다. 일 실 시예에서, TOF 센서는 3차원 센서로 적외선 파장을 통해 물체로 발사한 빛이 반사되어 돌아오는 거리를 시간으로 계산하고, 사물의 입체감과 공간 정보, 및/또는 움직임을 인식하는 센서를 나타낼 수 있다. 일 실시예에서, TOF 센서는 비행시간 즉, 빛을 전방에 쏜 후에 반사되어 돌아오는 빛을 감지하여 거리를 측정(또는 계산)할 수 있다. 예를 들어, TOF 센서는 지정된 신호(예: 적외선, 초음파 또는 레이저)를 쏘아서 반사되어 오는 시간을 측 정하여 거리를 계산할 수 있다. 일 실시예에 따라, TOF 센서는 카메라가 동작 시에 카메라에 의해 촬 영되는 이미지에 거리 정보를 제공할 수 있다. 일 실시예에서, TOF 카메라는 빛을 내는 광원과 빛을 감지하는 감지기(예: TOF 센서)가 한 쌍으로 동작할 수 있고, TOF 방식을 사용하여 거리(depth) 정보를 포함하는 이미지 (예: 3차원 이미지)를 촬영하는 카메라를 나타낼 수 있다. 일 실시예에 따르면, 카메라는 외부의 피사체(또는 객체)를 촬영하고, 이미지 데이터를 생성할 수 있다. 예를 들어, 카메라는 이미지 센서(image sensor)를 포함할 수 있다. 일 실시예에 따르면, 이미지 센서는 멀티 픽셀 센서(MPS, multi pixel sensor)를 포함할 수 있다. 일 실시예에 따르면, 카메라는 이미지 센서 에 의해 피사체의 광학적 신호를 전기적 신호로 변환할 수 있다. 일 실시예에 따르면, 카메라는 이미지 센서를 이용하여 이미지 데이터를 생성할 수 있다. 일 실시예에서, 이미지 데이터는 이미지, 넌-베이어(non-Bayer) 이미지, 이미지 프레임 및 프레임 데이터와 같이 다양하게 지칭 될 수 있다. 일 실시예에 따르면, 이미지 데이터는 프로세서(예: 이미지 시그널 프로세서(ISP, image signal processor) 및/또는 신경망 처리 장치(NPU, neural processing unit))에 입력 데이터로서 제 공되거나, 메모리에 저장될 수 있다. 일 실시예에서, 메모리에 저장된 이미지 데이터는 프로세서 로 제공될 수 있다. 일 실시예에 따르면, 디스플레이는 도 1의 디스플레이 모듈과 동일 또는 유사한 구성을 포함할 수 있 다. 일 실시예에 따라, 디스플레이는 전자 장치의 폼팩터에 따라 하나 또는 그 이상의 디스플레이(예: 제1 디스플레이 및/또는 제2 디스플레이)를 포함할 수 있고, 대응하는 디스플레이를 통해 전자 장치의 외부(예: 사용자)로 다양한 정보를 시각적으로 제공할 수 있다. 일 실시예에 따르면, 디 스플레이는 프로세서의 제어 하에, 실행하는 어플리케이션(예: 도 1의 어플리케이션) 및 그의 사용과 관련된 다양한 정보(예: 컨텐츠(contents), 영상(예: 프리뷰 이미지(preview image), 스틸 이미지 (still image), 비디오(video), 애니메이션 이미지(animation image)(예: GIF(graphics interchange format) 이미지))를 시각적으로 제공할 수 있다. 일 실시예에 따라, 디스플레이는 터치 센서(touch sensor), 터치의 세기를 측정할 수 있는 압력 센서 (pressure sensor) 및/또는 자기장 방식의 스타일러스 펜을 검출하는 터치 패널(touch panel)(예: 디지타이저) 과 결합될 수 있다. 일 실시예에 따르면, 디스플레이는 터치 센서, 압력 센서 및/또는 터치 패널에 기반하 여 디스플레이의 특정 위치에 대한 신호(예: 전압, 광량, 저항, 전자기 신호 및/또는 전하량)의 변화를 측 정함으로써 터치 입력, 에어 제스처(air gesture) 입력, 및/또는 호버링 입력(또는 근접 입력)을 감지할 수 있 다. 일 실시예에 따르면, 디스플레이는 액정 표시 장치(LCD, liquid crystal display), OLED(organic light emitted diode), 및/또는 AMOLED(active matrix organic light emitted diode)를 포함할 수 있다. 일 실 시예에 따르면, 디스플레이는 플렉서블 디스플레이(flexible display)를 포함할 수 있다. 일 실시예에 따라, 디스플레이는 전면의 제1 디스플레이(예: 메인 디스플레이)와 후면의 제2 디스플 레이(예: 커버 디스플레이)를 포함할 수 있다. 일 실시예에 따라, 제1 디스플레이와 제2 디스플레이 는 전자 장치의 폼팩터에 따라 다양한 형태로 구현될 수 있다. 일 실시예에 따라, 전자 장치가 폴더블 장치(foldable device)의 폼팩터인 경우, 제1 디스플레이는 전자 장치가 제1 상태(예: 언폴디드 상태(unfolded state) 또는 오픈 상태(open state))에서 동작 가능한 제1 디스플레이 사이즈를 갖는 메인 디스플레이(main display)를 포함할 수 있다. 일 실시예에 따라, 전자 장치 가 폴더블 장치의 폼팩터인 경우, 제2 디스플레이는 전자 장치가 제2 상태(예: 폴디드 상태 (folded state) 또는 클로즈 상태(close state)) 및/또는 제1 상태에서 동작 가능한 제1 디스플레이 사이즈와 다른 제2 디스플레이 사이즈를 갖는 커버 디스플레이(cover display)를 포함할 수 있다. 일 실시예에 따라, 전자 장치가 롤러블/슬라이더블 장치(rollable/slidable device)의 폼팩터인 경우, 제1 디스플레이는 전자 장치가 제3 상태(예: 클로즈 상태 또는 슬라이드-인 상태(slide-in state))에서 동작 가능한 제3 디스플레이 사이즈를 갖는 메인 디스플레이를 포함할 수 있다. 일 실시예에 따라, 전자 장치 가 롤러블/슬라이더블 장치의 폼팩터인 경우, 제2 디스플레이는 전자 장치가 제4 상태(예: 오픈 상태 또는 슬라이드-아웃 상태(slide-out state))에서 동작 가능한 제3 디스플레이 사이즈와 다른 제4 디스플레 이 사이즈를 갖는 확장 디스플레이를 포함할 수 있다.일 실시예에서, 디스플레이의 종류, 형태 및/또는 사이즈는 전술한 예에 제한하지 않으며, 전자 장치(10 1)의 폼팩터에 따라 다양하게 구현될 수 있다. 일 실시예에 따르면, 센서 회로는 도 1의 센서 모듈에 대응할 수 있다. 일 실시예에 따르면, 센서 모 듈은 상태 감지 센서를 포함할 수 있다. 일 실시예에서, 상태 감지 센서는, 예를 들면, 근접 센서, 조도 센서, 마그네틱 센서, 홀 센서, 제스처 센서, 벤딩 센서, 적외선 센서, 터치 센서, 압력 센서, 또는 적외선 카 메라 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 일 실시예에 따르면, 상태 감지 센서는 전자 장치의 어느 일 측(예: 폴딩 축, 하우징 끝단, 디스플레이 하 단(예: 패널 아래(under panel), 및/또는 디스플레이의 베젤)에 위치하여 전자 장치의 접힘(또는 펼침) 각 도를 측정할 수 있다. 일 실시예에 따르면, 전자 장치는 센서 회로의 상태 감지 센서를 이용한 센서 데이터(예: 접힘(또는 펼침) 각도)에 기반하여 전자 장치의 지정된 상태를 판단할 수 있다. 일 실시예에 따르면, 메모리는 도 1의 메모리에 대응할 수 있다. 일 실시예에 따르면, 메모리는 전자 장치에 의해 사용되는 다양한 데이터를 저장할 수 있다. 일 실시예에서, 데이터는, 예를 들어, 어플 리케이션(예: 도 1의 프로그램), 및 어플리케이션(예: 도 1의 어플리케이션)과 관련된 명령(comman d)에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 일 실시예에서, 데이터는, 카메라를 통해 획득하거나, 외부 장치(예: 다른 전자 장치 및/또는 서버)로부터 획득하는 다양한 종류의 데이터(예: 컨텐츠 및/또는 영상)를 포함할 수 있다. 일 실시예에서, 데이터는, 프리뷰 이미지(preview image), 스틸 이미지(still image), 비디오(video), 및/또는 애니메이션 이미지(animation image)(예: GIF(graphics interchange format) 이미지)를 포함할 수 있다. 일 실시예에서, 데이터는, 카메라 를 통해 획득하는 영상과 관련된 거리 정보(또는 거리 데이터)를 포함할 수 있다. 일 실시예에서, 데이터 는, 전자 장치에서 반사체(예: 도 5의 반사체를 이용한 영상 촬영(예: 거울 샷 촬영)에 따른 동작을 지원하기 위한 다양한 설정에 관한 정보를 포함할 수 있다. 일 실시예에서, 다양한 설정에 관한 정보는, 전자 장치의 디스플레이(예: 제1 디스플레이 및/또 는 제2 디스플레이)의 디스플레이 사이즈에 관련된 정보(예: 디스플레이 별 화면 해상도), 영상 촬영 시에 촬영 모드(예: 일반 촬영 모드 또는 지정된 촬영 모드(예: 거울 샷 모드))를 식별하기 위한 지정된 식별 정보(예: 사용자의 얼굴 특징 정보, 식별 객체(예: 아이콘, 영상, 텍스트))를 포함할 수 있다. 일 실시예에서, 다양한 설정에 관한 정보는, 영상 내 객체를 분석 및/또는 판단하여 지정된 촬영 모드에서 영상 내 객체(예: 그 래픽 요소)에 대한 지정된 기능(예: 리사이즈(resize), 촬영 구도 가이드 제공, 및/또는 증강 객체 제공)을 처 리하기 위한 정보를 포함할 수 있다. 일 실시예에서, 데이터는, 센서 회로로부터 획득하는 다양한 센서 데이터(예: 가속도 센서 데이터, 자이로 센서 데이터, 및/또는 홀 센서 데이터)를 포함할 수 있다. 일 실시예에서, 데이터는, 전자 장치의 지정된 상태(예: 제1 상태(예: 펼침 상태), 제2 상태(예: 부분적으로 접힘 상태), 및 제3 상태(예: 접힘 상태)를 식별 하기 위해 메모리에 설정되는 다양한 기준 데이터를 포함할 수 있다. 일 실시예에서, 데이터는, 사용자와 상호작용으로 사용자의 학습에 기반하여 획득하는 다양한 학습 데이터 및/ 또는 파라미터(parameters)를 포함할 수 있다. 일 실시예에서, 데이터는, 지정된 촬영 모드에서 영상 촬영에 관 련된 동작을 지원하기 위한 다양한 스키마(schema)(또는 알고리즘(algorithm), 모델(model), 네트워크 (network) 또는 함수(function))를 포함할 수 있다. 예를 들어, 영상 촬영에 관련된 동작을 지원하기 위한 스키마는, 뉴럴 네트워크(neural network)를 포함할 수 있다. 일 실시예에서, 뉴럴 네트워크는 ANN(artificial neural network), CNN(convolution neural network), R-CNN(region with convolution neural network), RPN(region proposal network), RNN(recurrent neural network), S-DNN(stacking-based deep neural network), S-SDNN(state-space dynamic neural network), Deconvolution Network, DBN(deep belief network), RBM(restricted boltzman machine), LSTM(long short- term memory) network, classification network, plain residual network, dense network, hierarchical pyramid network, 및/또는 fully convolutional network 중 적어도 하나에 기초한 뉴럴 네트워크 모델을 포함 할 수 있다. 일 실시예에 따라, 뉴럴 네트워크 모델의 종류는 전술한 예에 제한하지 않는다. 일 실시예에 따라, 메모리는, 실행 시에, 프로세서가 동작하도록 하는 인스트럭션들(instructions)을 저장할 수 있다. 예를 들어, 어플리케이션(예: 도 1의 어플리케이션)은 메모리 상에 소프트웨어(예: 도 1의 프로그램)로서 저장될 수 있고, 프로세서에 의해 실행 가능할 수 있다. 일 실시예에 따라, 어플리케이션은 전자 장치에서 다양한 기능(또는 서비스)(예: 영상 촬영 기능, 통화(call) 기능, 무선 통신 기능)를 제공할 수 있는 다양한 어플리케이션일 수 있다. 일 실시예에 따르면, 프로세서는, 전자 장치의 사용자에 의해 요구되는 응용 계층 처리 기능을 할 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 다양한 블록들을 위한 기능의 제어 및 명령을 제 공할 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 각 구성 요소들의 제어 및/또는 통신에 관한 연산이나 데이터 처리를 수행할 수 있다. 예를 들어, 프로세서는 도 1의 프로세서의 구성 및/또 는 기능 중 적어도 일부를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 구성 요소 들과 작동적으로 연결될 수 있다. 일 실시예에 따르면, 프로세서는 전자 장치의 다른 구성 요소로부 터 수신된 명령 또는 데이터를 메모리에 로드(load)하고, 메모리에 저장된 명령 또는 데이터를 처리 하고, 결과 데이터를 저장할 수 있다. 일 실시예에 따르면, 프로세서는 처리 회로(processing circuitry) 및/또는 실행 가능한 프로그램 요소 (executable program elements)를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 처리 회로 및/또는 실행 가능한 프로그램 요소에 기반하여, 전자 장치에서 영상 촬영을 지원하는 것과 관련된 전반적인 동작 을 제어(또는 처리)할 수 있다. 일 실시예에 따르면, 프로세서는 어플리케이션 실행에 기반하여 제1 카메라 및 제2 카메라로부 터 제1 영상을 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 제1 영상에 기반하여 지 정된 촬영 모드를 판단하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드를 판단하는 것에 기반하여 디스플레이를 통해 그래픽 요소를 표시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 지정된 촬영 모드에서 동작 하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬영하는 동작을 수행할 수 있다. 일 실시예에 따르면, 제1 영상은, 제1 카메라 및 제2 카메라로부터 각각 획득되는 복수의 영상들을 포함하고, 디스플레이에 표시되지 않고 프로세서에 의해 백그라운드에서 지정된 촬영 모드를 판단하 는 데 사용되는 영상을 포함할 수 있다. 일 실시예에 따르면, 제2 영상은, 제1 카메라 및 제2 카메라 중 지정된 카메라로 동작하는 카메라로 부터 획득되고, 그래픽 요소가 표시되는 디스플레이(661 또는 662)와 다른 디스플레이(662 또는 661)를 통해 표 시되는 영상을 포함할 수 있다. 일 실시예에 따라, 전자 장치의 프로세서의 상세 동작에 관하여 후술하는 도면들을 참조하여 설명된 다. 일 실시예에 따르면, 프로세서는 어플리케이션 프로세서(AP, application processor)일 수 있다. 일 실시 예에 따르면, 프로세서는 전자 장치의 연산과 멀티미디어 구동 기능을 담당하는 시스템 반도체일 수 있다. 일 실시예에 따르면, 프로세서는 시스템 온 칩(SoC, system-on-chip) 형태로 구성되어, 여러 반도체 기술을 하나로 집적하고, 시스템 블록들을 하나의 칩으로 구현한 기술집약적 반도체 칩을 포함할 수 있다. 일 실시예에 따르면, 프로세서의 시스템 블록들은, 도 6에 예시한 바와 같이, 그래픽 처리 장치(GPU, graphics processing unit), 이미지 시그널 프로세서(ISP, image signal processor), 중앙 처리 장 치(CPU, central processing unit), 신경망 처리 장치(NPU, neural processing unit), 디지털 시그 널 프로세서(digital signal processor), 모뎀(modem), 커넥티비티(connectivity), 및/또는 시 큐리티(security) 블록을 포함할 수 있다. 일 실시예에 따라, GPU는 그래픽 처리를 담당할 수 있다. 일 실시예에 따르면, GPU는 CPU의 명 령을 받아 디스플레이 상에 사물(또는 물체)들의 모양, 위치, 색상, 음영, 움직임, 및/또는 질감을 표현하기 위 한 그래픽 처리를 수행할 수 있다. 일 실시예에 따라, ISP는 이미지 및 비디오의 영상 처리 및 보정을 담당할 수 있다. 일 실시예에 따르면, ISP는 카메라의 이미지 센서에서 전송된 가공되지 않은 데이터(예: 로우 데이터(raw data))를 보정하 여 사용자가 보다 선호하는 형태의 이미지를 생성하는 역할을 할 수 있다. 일 실시예에 따르면, ISP는 이 미지의 부분적인 밝기를 조절하고, 디테일한 부분을 강조하는 것과 같은 후처리를 수행할 수 있다. 예를 들어, ISP는 카메라를 통해 획득하는 영상의 화질 튜닝 및 보정 과정을 자체적으로 거쳐 사용자가 선호하는 결과물을 생성할 수 있다. 일 실시예에 따르면, ISP는 인공지능(AI, artificial intelligence) 기반 영상 처리 기술을 지원할 수 있 다. 일 실시예에 따르면, ISP는 NPU와 연동하여 촬영 중인 장면의 부분들을 인식 및/또는 분류하는 장면 세분화(scene segmentation)(예: 이미지 세그멘테이션(image segmentation)) 기술을 지원할 수 있다. 예 를 들어, ISP는 하늘, 수풀, 및/또는 피부와 같은 객체에 각기 다른 파라미터를 적용하여 처리하는 기능을 포함할 수 있다. 일 실시예에 따르면, ISP는 인공지능 기능을 통해 영상 촬영 시, 사람 얼굴을 감지하여 표시하거나 그 얼굴의 좌표와 정보를 이용하여 이미지의 밝기, 초점, 및/또는 색상을 조절할 수 있다. 일 실시예에 따라, CPU는 프로세서에 대응하는 역할을 담당할 수 있다. 일 실시예에 따르면, CPU는 사용자의 명령을 해독하고, 산술과 논리연산, 및/또는 데이터 처리의 역할을 수행할 수 있다. 예를 들어, CPU는 기억, 해석, 연산, 및 제어라는 기능을 담당할 수 있다. 일 실시예에 따르면, CPU는 전 자 장치의 전반적인 기능을 제어할 수 있다. 예를 들어, CPU는 운영체제(OS, operating system) 위 에서 전자 장치의 모든 소프트웨어(예: 어플리케이션)를 실행하고, 하드웨어 장치를 제어할 수 있다. 일 실시예에 따라, CPU는 하나의 프로세서 코어(single core)를 포함하거나, 복수의 프로세서 코어들 (multi-core)을 포함할 수 있다. 일 실시예에 따르면, CPU는 어플리케이션을 실행하고, 어플리케이션의 실 행에 따라 요구되는 뉴럴 네트워크 기반의 태스크들을 수행하도록 프로세서의 전반적인 동작을 제어할 수 있다. 일 실시예에 따라, NPU는 인공지능의 딥-러닝 알고리즘에 최적화된 처리를 담당할 수 있다. 일 실시예에 따르면, NPU는 딥-러닝 알고리즘 연산(예: 인공지능 연산)에 최적화된 프로세서로, 빅데이터(big data)를 사람의 신경망처럼 빠르고 효율적으로 처리할 수 있다. 예를 들어, NPU는 인공지능 연산에 주로 이용될 수 있다. 일 실시예에 따르면, NPU는 카메라를 통해 영상 촬영 시 배경 안의 사물, 환경, 및/또는 인물 을 인식하여 자동으로 초점을 조정하거나, 반사체를 이용한 영상 촬영(예: 거울 샷 촬영) 시 카메라의 촬 영 모드를 지정된 촬영 모드(예: 지정된 촬영 모드(예: 거울 샷 모드))로 자동 전환하거나, 음식 사진 촬영 시 카메라의 촬영 모드를 음식 모드로 자동 전환하거나, 및/또는 촬영된 결과물에서 불필요한 피사체만 지우 는 처리를 담당할 수 있다. 일 실시예에 따르면, 전자 장치는 GPU, ISP, CPU, 및 NPU와 같은 모든 프로세서를 상호작용하여 통합 머신 러닝(machine learning) 처리를 지원할 수 있다. 일 실시예에 따라, DSP는 디지털 신호를 빠르게 처리하도록 도와주는 집적회로를 나타낼 수 있다. 일 실시 예에 따르면, DSP는 아날로그 신호를 디지털로 변경하여 고속 처리하는 기능을 수행할 수 있다. 일 실시예에 따라, 모뎀은 전자 장치에서 다양한 통신 기능을 사용할 수 있도록 해주는 역할을 수행 할 수 있다. 예를 들어, 모뎀은 기지국과 신호를 주고받으면서 전화 및 데이터 송수신과 같은 통신을 지원 할 수 있다. 일 실시예에 따르면, 모뎀은 LTE 및 2G 내지 5G와 같은 통신 기술을 지원하는 통합 모뎀(예: 셀룰러(cellular) 모뎀, LTE 모뎀, 5G 모뎀, 5G-Advanced 모뎀, 및 6G 모뎀)을 포함할 수 있다. 일 실시예에 따르면, 모뎀은 인공지능 알고리즘을 적용한 인공지능 모뎀을 포함할 수 있다. 일 실시예에 따라, 커넥티비티는 IEEE 802.11에 기반한 무선 데이터 전송을 지원할 수 있다. 일 실시예에 따르면, 커넥티비티는 IEEE 802.11(예: WiFi) 및/또는 802.15(예: bluetooth, ZigBee, UWB)에 기반한 통 신 서비스를 지원할 수 있다. 예를 들어, 커넥티비티는 비면허 대역을 사용하여 실내와 같이 국지적인 지 역에서 불특정 다수를 대상으로 통신 서비스를 지원할 수 있다. 일 실시예에 따라, 시큐리티는 전자 장치에 저장된 데이터나 서비스 간의 독립적인 보안 실행 환경을 제공할 수 있다. 일 실시예에 따르면, 시큐리티는 전자 장치의 생체 인식, 모바일 신분증, 및/또는 페이먼트와 같은 서비스 제공 시, 사용자 인증을 하는 과정에서 소프트웨어 및 하드웨어 상의 보안을 통해 외부 로부터 해킹 발생을 방지하는 역할을 담당할 수 있다. 예를 들어, 시큐리티는 전자 장치의 자체의 보 안 강화를 위한 기기 보안(device security)과 전자 장치에서의 모바일 신분증, 페이먼트, 자동차 키와 같 은 사용자 정보를 기반으로 하는 보안 서비스(security service)에서 독립적인 보안 실행 환경을 제공할 수 있 다. 일 실시예에 따르면, 프로세서에서 수행하는 동작들은, 기록 매체(또는 컴퓨터 프로그램 프로덕트 (computer program product))로 구현될 수 있다. 예를 들어, 기록 매체는 프로세서에서 수행하는 다양한 동작을 실행시키기 위한 프로그램을 기록한 비 일시적(non-transitory) 컴퓨터(computer)로 판독 가능한 기록 매체를 포함할 수 있다.본 개시에서 설명되는 실시예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것을 이용하 여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하 면, 일 실시예에서 설명되는 동작들은 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러 (micro-controllers), 마이크로프로세서(microprocessors), 및/또는 기타 기능 수행을 위한 전기적인 유닛 (unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예에서, 기록 매체(또는 컴퓨터 프로그램 프로덕트)는, 어플리케이션 실행에 기반하여 제1 카메라 및 제 2 카메라로부터 제1 영상을 획득하는 동작, 상기 제1 영상에 기반하여 지정된 촬영 모드를 판단하는 동작, 상기 지정된 촬영 모드를 판단하는 것에 기반하여 디스플레이를 통해 그래픽 요소를 표시하는 동작, 및 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동작하도록 지정된 카메라를 통해 획 득되는 제2 영상을 촬영하는 동작을 실행시키기 위한 프로그램을 기록한 컴퓨터로 판독 가능한 기록 매체를 포 함할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는, 제1 카메라(예: 651), 상기 제1 카메라와 반대 면에 배치된 제2 카메라(예: 652), 디스플레이(예: 660), 및 상기 제1 카메라, 상기 제2 카메라 및 상기 디스플레이와 작동적으 로 연결된 적어도 하나의 프로세서를 포함할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 어플리케이션 실행에 기반하여 상기 제1 카메라 및 상기 제2 카메라 중 적어도 하나의 카메라로부터 제1 영상을 획득하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 제1 영상에 기반하여 지정된 촬영 모드를 판단하도록 동작할 수 있 다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 지정된 촬영 모드를 판단하는 것에 기반하 여 상기 디스플레이를 통해 그래픽 요소를 표시하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나 의 프로세서는, 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동 작하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬영하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 제1 영상을 분석하고, 상기 제1 영상의 분석에 기반하여 지정된 식별 정보를 검출하고, 상기 지정된 식별 정보를 검출하는 것에 기반하여 상기 지정된 촬영 모 드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 상기 지정된 식별 정보는, 상기 지정된 촬영 모드의 실행 여부를 판단하기 위한 미리 지정 된 영상 객체를 포함할 수 있다. 일 실시예에 따르면, 상기 지정된 영상 객체는, 지정된 얼굴 객체 또는 지정된 식별자 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 상기 제1 영상은 상기 제1 카메라의 영상 및/또는 상기 제2 카메라의 영상을 포함할 수 있 다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 제1 카메라의 영상 및/또는 상기 제2 카메 라의 영상을 포함하는 제1 영상과 미리 설정된 기준 영상을 비교할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 제1 영상으로부터 상기 지정된 얼굴 객체를 식별하는 것에 기반하여 상기 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 그래픽 요소가 표시되는 상기 디스플레이와 동 일 면에 위치한 상기 지정된 카메라를 통해 획득되는 영상으로부터 상기 지정된 식별자를 식별하는 것에 기반하 여 상기 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 지정된 촬영 모드를 판단하는 것에 기반하여, 상기 제1 카메라 및 상기 제2 카메라 중에서 상기 지정된 촬영 모드에서 동작할 상기 지정된 카메라를 결정할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 지정된 카메라를 이용하여 상기 제2 영상을 촬영하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 지정된 촬영 모드에서 동작할 상기 지정된 카 메라를 결정하는 것에 기반하여, 상기 지정된 카메라와 반대 면에 위치한 카메라를 비활성화하도록 동작할 수 있다. 일 실시예에 따르면, 상기 전자 장치는, 제1 디스플레이 및 제2 디스플레이를 포함할 수 있다. 일 실시예 에 따르면, 상기 적어도 하나의 프로세서는, 상기 제1 디스플레이 및 상기 제2 디스플레이 중 상기 지정된카메라와 동일 면에 위치한 디스플레이에 기반하여 상기 그래픽 요소를 표시하도록 동작할 수 있다. 일 실시예 에 따르면, 상기 적어도 하나의 프로세서는, 상기 지정된 카메라와 반대 면에 위치한 디스플레이에 기반하 여 상기 지정된 카메라로부터 획득하는 영상의 프리뷰를 표시하도록 동작할 수 있다. 일 실시예에 따르면, 상기 프리뷰는 반사체 및 상기 반사체에 투영된 영상을 포함할 수 있다. 일 실시예에 따르 면, 상기 반사체에 투영된 영상은, 상기 지정된 카메라, 상기 지정된 카메라와 동일 면에 위치한 디스플레이, 및 상기 디스플레이에 표시된 그래픽 요소를 포함하는 상기 전자 장치에 대응하는 객체를 포함할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 그래픽 요소가 지정된 조건에 포함되는지 분석 하고, 상기 그래픽 요소가 지정된 조건에 포함되는 것에 기반하여 상기 결정된 카메라와 동일 면에 위치한 디스 플레이에 표시되는 상기 그래픽 요소에 관련된 지정된 기능을 처리하고, 제1 디스플레이 및/또는 제2 디스플레 이에 기반하여 상기 기능 처리 결과를 표시하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 프리뷰에서 상기 그래픽 요소에 대응하는 객체 에 기반하여 사용자 입력을 감지하고, 상기 사용자 입력에 기반하여 상기 결정된 카메라와 동일 면에 위치한 디 스플레이에 표시되는 상기 그래픽 요소에 관련된 지정된 기능을 처리하고, 제1 디스플레이 및/또는 제2 디스플 레이에 기반하여 상기 기능 처리 결과를 표시하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 지정된 촬영 모드를 판단하는 것에 기반하여 상황 인지를 수행하고, 상기 상황 인지에 기반하여 상기 디스플레이에 표시할 그래픽 요소를 생성하고, 상기 생 성된 그래픽 요소를 표시하도록 상기 디스플레이를 제어하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 어플리케이션 실행을 감지하는 것에 기반하여 상기 제1 카메라 및 상기 제2 카메라를 활성화하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 어플리케이션 실행을 감지하는 것에 기반하여 상기 전자 장치가 지정된 상태인지 여부를 판단할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서 는, 상기 전자 장치가 지정된 상태인 것을 판단하는 것에 기반하여, 상기 제1 카메라 및 상기 제2 카메라 를 동시에 활성화하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 상기 촬영되는 제2 영상에 상기 그래픽 요소에 관련 된 메타데이터를 매핑하여 저장하도록 동작할 수 있다. 일 실시예에 따르면, 상기 적어도 하나의 프로세서는, 지정된 영상을 표시하고, 상기 영상 내의 지정된 그 래픽 요소에 기반한 사용자 입력을 감지하고, 상기 사용자 입력에 기반하여 상기 지정된 그래픽 요소에 대응하 는 메타데이터를 호출하고, 상기 메타데이터에 대응하는 기능을 실행하고, 상기 기능 실행에 대응하는 컨텐츠를 상기 디스플레이를 통해 표시하도록 동작할 수 있다. 일 실시예에 따르면, 상기 제1 영상은, 상기 제1 카메라 및 상기 제2 카메라로부터 각각 획득되는 복수의 영상 들을 포함하고, 상기 디스플레이에 표시되지 않고 상기 적어도 하나의 프로세서에 의해 백그라운드에서 상 기 촬영 모드를 판단하는 데 사용되는 영상을 포함할 수 있다. 일 실시예에 따르면, 상기 제2 영상은, 상기 제1 카메라 및 상기 제2 카메라 중 상기 지정된 카메라로 동작하는 카메라로부터 획득되고, 상기 그래픽 요소가 표시되는 디스플레이와 다른 디스플레이를 통해 표시되는 영상을 포함할 수 있다. 일 실시예에 따르면, 상기 지정된 카메라는 상기 그래픽 요소를 표시하는 상기 디스플레이와 동일한 면에 위치 된 카메라를 포함할 수 있다. 이하에서는 다양한 실시예들의 전자 장치의 동작 방법에 대해서 상세하게 설명한다. 다양한 실시예들에 따 른 전자 장치에서 수행하는 동작들은, 전자 장치의 다양한 프로세싱 회로(various processing circuitry) 및/또는 실행 가능한 프로그램 요소(executable program elements)를 포함하는 프로세서에 의 해 실행될 수 있다. 일 실시예에 따라, 전자 장치에서 수행하는 동작들은, 메모리에 저장되고, 실행 시에, 프로세서가 동작하도록 하는 인스트럭션들(instructions)에 의해 실행될 수 있다. 도 7은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 7은 일 실시예에 따른 전자 장치(예: 도 1의 전자 장치)에서 영상 촬영(예: 도 5의 반사체에 기반한 거울 샷 촬영)을 지원하는 동작의 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 방법은, 예를 들어, 도 7에 도시된 흐름 도에 따라 수행될 수 있다. 도 7에 도시된 흐름도는 전자 장치의 동작의 일 실시예에 따른 흐름도에 불과 하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적 어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 701 내지 동작 709는 전자 장치의 적어도 하나의 프로세서(예: 도 1 또는 도 6의 프로세서)에서 수행 될 수 있다. 도 7에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법은, 영상 촬영을 위한 동작을 감지하는 동작, 지정된 촬영 모드를 판단하는 동작, 지정된 촬영 모드를 판단하는 것에 기반하여 디 스플레이를 통해 그래픽 요소를 표시하는 동작, 촬영 요청 감지에 기반하여 지정된 카메라를 통해 획득되 는 영상을 촬영하는 동작, 및 촬영 영상을 제공하는 동작을 포함할 수 있다. 도 7을 참조하면, 동작 701에서, 전자 장치의 프로세서는 영상 촬영을 위한 동작을 감지하는 동작을 수행할 수 있다. 예를 들어, 프로세서는 사용자로부터 영상 촬영에 관련된 어플리케이션(예: 촬영 어플리 케이션 또는 카메라 어플리케이션)을 실행하기 위한 사용자 입력(예: 어플리케이션의 실행 아이콘 선택)을 수신 할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력을 수신하는 것에 기반하여 영상 촬영 시작을 판 단할 수 있다. 동작 703에서, 프로세서는 영상 촬영을 위한 동작(예: 촬영 어플리케이션 실행)을 감지하는 것에 기반하여 지정된 촬영 모드를 판단하는 동작을 수행할 수 있다. 일 실시예에서, 전자 장치에서 지원 가능한 촬영 모 드는 일반 사진 촬영 모드, 인물 촬영 모드, 음식 촬영 모드, 풍경 촬영 모드, 동영상 촬영 모드, 파노라마 촬 영 모드, 및/또는 거울 샷 촬영 모드와 같이 다양한 촬영 모드를 지원할 수 있으며, 이에 제한하지 않는다. 일 실시예에서, 지정된 촬영 모드를 다양한 촬영 모드 중 거울 샷 촬영 모드를 포함할 수 있다. 일 실시예에서, 거 울 샷 촬영 모드는, 사용자가 전자 장치의 카메라를 이용하여 반사체(예: 거울)에 투영된 피사체(예: 사용 자 포함)를 포함하여 촬영하는 촬영 모드를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 동작 감지에 기반하여 제1 카메라 및/또는 제2 카메라로부터 영상(예: 제 1 영상)을 획득할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라(예: 후면 카메라)로부터 제1 영상 을 획득하도록 동작할 수 있다. 예를 들어, 사용자는 전자 장치를 펼침 상태에서 제1 카메라(예: 후면 카 메라)에 기반하여 영상 촬영을 수행할 수 있고, 프로세서는 제1 카메라를 통해 제1 영상을 획득할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라(예: 후면 카메라)와 제2 카메라(예: 전면 카메라)로부 터 제1 영상을 획득하도록 동작할 수 있다. 예를 들어, 사용자는 전자 장치를 펼침 상태에서 제1 카메라 또는 제2 카메라에 기반하여 영상 촬영을 수행할 수 있고, 프로세서는 사용자에 의해 실행 지정된 카메라 (예: 제1 카메라)로부터 사용자가 촬영하고자 하는 피사체를 포함하는 영상을 획득하고, 백그라운드에서 실행 지정된 카메라와 다른 카메라(예: 제2 카메라)로부터 영상을 획득하고, 제1 카메라 및 제2 카메라의 영상으로부 터 제1 영상을 획득할 수 있다. 일 실시예에 따르면, 제1 영상은, 제1 카메라 또는 제2 카메라로부터 획득되는 영상을 포함하고, 디 스플레이에 표시되지 않고 프로세서에 의해 백그라운드에서 지정된 촬영 모드를 판단하는 데 사용되 는 영상을 포함할 수 있다. 일 실시예에 따르면, 제1 영상은, 제1 카메라 및 제2 카메라로부터 각각 획득되는 복수의 영상들을 포함하고, 디스플레이에 표시되지 않고 프로세서에 의해 백그라운드에서 지정된 촬영 모드를 판단하는 데 사용되는 영상을 포함할 수 있다. 일 실시예에 따라, 제1 카메라와 제2 카메라는 서로 대향하게 배치될 수 있다. 예를 들어, 제2 카메라는 제1 카 메라와 반대 면에 배치될 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라 및/또는 제2 카메라로부터 획득되는 영상에 기반하여 지정된 촬영 모드를 판단할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메 라 또는 제2 카메라로부터 획득되는 제1 영상에 기반하여 영상 분석(예: 객체 인식 및/또는 얼굴 인 식)을 수행하고, 분석된 영상과 전자 장치의 메모리(예: 도 1 또는 도 6의 메모리)에 미리 설정된 기 준 영상(예: 얼굴 인증을 위해 미리 등록된 사용자 얼굴 영상(또는 얼굴 영상 데이터)을 비교하고, 그 결과 확 률적으로 유사한 객체(또는 유사도가 높은 객체)인 것으로 판단하는 것에 기반하여 지정된 촬영 모드를 판단하 도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라로부터 획득되는 영상과 제2 카메라로부터 획득되는 영상에 기 반하여 영상 분석(예: 객체 인식 및/또는 얼굴 인식)을 수행하고, 분석된 영상들을 서로 비교하고, 그 결과 영 상들에 포함된 얼굴 객체가 확률적으로 유사한 객체(또는 유사도가 높은 객체)인 것으로 판단하는 것에 기반하여 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라로부터 획득되는 영상 및/또는 제2 카메라로부터 획득되는 영 상을 포함하는 제1 영상에 기반하여 영상 분석(예: 객체 인식 및/또는 얼굴 인식)을 수행하고, 영상 분석의 결 과에 기반하여 지정된 식별 정보를 검출할 수 있다. 예를 들어, 프로세서는 제1 카메라 및/또는 제2 카메 라로부터 획득되는 제1 영상에서 지정된 식별 정보가 검출되는지 판단할 수 있다. 일 실시예에 따르면, 프로세 서는 지정된 식별 정보가 검출되는 것에 기반하여 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에서, 지정된 식별 정보는 지정된 촬영 모드의 실행 여부를 판단하기 위한 미리 지정된 영상 객체를 포함할 수 있다. 일 실시예에서, 지정된 영상 객체는, 지정된 얼굴 객체 또는 지정된 식별자 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 실행되는 카메라(예: 제1 카메라 또는 제2 카메라)의 영 상과 미리 등록된 기준 영상(예: 지정된 식별자 또는 지정된 얼굴 객체)을 비교하고, 실행되는 카메라의 영상으 로부터 미리 등록된 기준 영상을 식별하는 것에 기반하여 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라의 영상과 제2 카메라의 영상을 비교하고, 제1 카메라의 영상과 제2 카메라의 영상으로부터 지정된 얼굴 객체를 식별하는 것에 기반하여 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라의 영상 및/또는 제2 카메라의 영상으로부터 지정된 식별자를 식별하는 것에 기반하여 지정된 촬영 모드를 판단하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 사용자에 의해 지정된 촬영 모드를 직접적으로 실행(또는 기능 선택)하는 입력(또는 명령)에 기반하여 지정된 촬영 모드를 바로 판단하도록 동작할 수도 있다. 동작 705에서, 프로세서는 지정된 촬영 모드를 판단하는 것에 기반하여 디스플레이를 통해 그래픽 요소를 표시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드를 판단하는 것에 기 반하여 그래픽 요소를 표시하기 위한 디스플레이를 판단(예: 지정된 카메라와 동일 면에 위치된 디스플레이를 판단)하고, 지정된 카메라와 동일 면에 위치된 디스플레이에 기반하여 그래픽 요소를 표시하도록 동작할 수 있 다. 일 실시예에서, 지정된 카메라와 동일 면에 위치된 디스플레이는 지정된 촬영 모드에서 그래픽 요소를 표시 하도록 지정되는 제1 디스플레이 또는 제2 디스플레이일 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드(예: 거울 샷 모드)를 판단하는 것에 기반하여, 지정된 카메라와 동일 면에 위치된 디스플레이(예: 제 1 디스플레이 또는 제2 디스플레이)를 통해 지정된 상황에 맞는 그래픽 요소를 표시하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드를 판단하는 것에 기반하여 상황 인지를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 상황 인지에 기반하여 사용자의 현재 위치, 사용자의 활동, 및/또 는 인식 객체에 대응하는 상황을 판단할 수 있다. 일 실시예에 따르면, 프로세서는 판단하는 상황에 대응 하는 그래픽 요소를 생성할 수 있다. 일 실시예에 따라, 상황 인지에 기반하여 대응하는 그래픽 요소를 생성하 여 제공하는 것과 관련하여 후술하는 도면들을 참조하여 설명된다. 동작 707에서, 프로세서는 촬영 요청 감지에 기반하여 지정된 카메라를 통해 획득되는 영상을 촬영하는 동 작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 위한 사용자 입력을 감지하는 것에 기 반하여, 지정된 촬영 모드에서 동작하도록 지정된 카메라로부터 영상(예: 제2 영상)을 획득할 수 있다. 일 실시 예에 따르면, 프로세서는 지정된 카메라를 통해 획득되는 영상(예: 제2 영상)에 기반하여 영상 촬영을 수 행할 수 있다. 일 실시예에 따르면, 제2 영상은, 제1 카메라 및 제2 카메라 중 지정된 카메라로 동작하는 카메라로 부터 획득되고, 그래픽 요소가 표시되는 디스플레이(661 또는 662)와 다른 디스플레이(662 또는 661)를 통해 표 시되는 영상을 포함할 수 있다. 일 실시예에 따라, 촬영되는 영상(예: 제2 영상)은 반사체(예: 도 5의 반사체 ) 및 반사체에 투영된 영상(예: 도 5의 투영체)을 포함할 수 있다. 일 실시예에 따라, 반사체에 투영 된 영상은, 지정된 카메라, 지정된 카메라와 동일 면에 위치한 디스플레이, 및 디스플레이에 표시된 그래픽 요 소를 포함하는 전자 장치에 대응하는 객체를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드를 판단하는 것에 기반하여, 제1 카메라 및 제2 카메라 중에서 지정된 촬영 모드에서 동작할 지정된 카메라를 결정하고, 지정된 카메라를 이용하여 제2 영상을 촬영하 도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 카메라를 결정하기 위한 지정된 스키마(또 는 알고리즘, 모델, 네트워크 또는 함수)에 기반하여 제1 카메라 또는 제2 카메라 중 어느 하나의 카메라를 지 정된 촬영 모드에서 동작하는 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 영상에 기반하여 분석 가능한 피사체와의 거리, 얼굴 객체의 크기, 얼굴 객체의 인식 여부, 및/또는 지정된 식별자의인식 여부에 적어도 기반하여 지정된 카메라를 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 및 제2 카메라의 영상으로부터 유사한 얼굴 객체(예: 사 용자의 얼굴 객체)가 인식되는 경우, 각 얼굴 객체와의 거리 정보에 기반하여 지정된 카메라를 판단할 수 있다. 예를 들어, 유사한 얼굴 객체는 확률적으로 유사한 객체 또는 유사도가 높은 객체를 나타낼 수 있다. 예를 들어, 프로세서는 제1 카메라의 영상으로부터 추출된 제1 얼굴 객체와의 제1 거리를 판단(예: 추정 (estimate))하고, 제2 카메라의 영상으로부터 추출된 제2 얼굴 객체와의 제2 거리를 판단(예: 추정)할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라와 제2 카메라의 줌 레벨(zoom level)을 식별할 수 있고, 이를 기반으로 추출된 객체들(예: 제1 얼굴 객체 및 제2 얼굴 객체) 각각의 경계를 기반으로 크기를 측정할 수 있다. 일 실시예에 따라, 프로세서는 영상으로부터 얼굴 추출 시에, 눈, 코, 및/또는 입의 배치로부터 크기(예: 픽셀(pixel) 크기)를 측정하거나, 얼굴 라인으로부터 크기를 측정할 수 있다. 일 실시예에 따르면, 프로세서 는 측정된 크기(예: 픽셀 크기)와 매칭되는 거리 추정 값의 모델링에 기반하여 거리를 추정할 수 있다. 일 실시예에 따라, 프로세서는 제1 거리와 제2 거리 중 상대적으로 긴 거리의 얼굴 객체(예: 전자 장치 와 상대적으로 멀리 있는 얼굴 객체)가 포함된 영상을 획득한 카메라를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 및 제2 카메라의 영상으로부터 유사한 얼굴 객체(예: 사 용자의 얼굴 객체)가 인식되는 경우, 각 얼굴 객체의 상대적인 크기 정보에 기반하여 지정된 카메라를 판단할 수 있다. 예를 들어, 프로세서는 제1 카메라의 영상으로부터 추출된 제1 얼굴 객체의 제1 크기(예: 제1 얼 굴 객체가 포함되는 픽셀 크기)와 제2 카메라의 영상으로부터 추출된 제2 얼굴 객체의 제2 크기(예: 제2 얼굴 객체가 포함되는 픽셀 크기)를 비교할 수 있다. 일 실시예에 따라, 프로세서는 제1 크기와 제2 크기 중 상 대적으로 작은 크기의 얼굴 객체(예: 전자 장치와 상대적으로 가까이에 있는 얼굴 객체)가 포함된 영상을 획득한 카메라를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 또는 제2 카메라의 영상 중 어느 하나의 영상으로부터 얼굴 객체(예: 사용자의 얼굴 객체)가 인식되는 경우, 얼굴 객체가 포함되지 않은 영상을 획득한 카메라(예: 사 용자를 향하고 있는 카메라와 반대 면에 위치한 카메라)를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 또는 제2 카메라의 영상 중 어느 하나의 영상으로부터 지정된 식별자가 인식되는 경우, 지정된 식별자를 포함하는 영상을 획득한 카메라(예: 반사체에 투영된 지 정된 식별자를 촬영하는 카메라)를 지정된 카메라로 결정할 수 있다. 동작 709에서, 프로세서는 촬영 영상(예: 제2 영상)을 제공하는 동작을 수행할 수 있다. 일 실시예에 따르 면, 프로세서는 촬영 영상을 디스플레이 상에 표시할 수 있다. 일 실시예에 따르면, 프로세서는 촬영 영상을 전자 장치의 메모리(예: 도 1 또는 도 6의 메모리)에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 촬영 영상을 지정된 외부 장치(예: 클라우드, 및/또는 지정된 다른 전자 장치)에 공유(예: 전 송)할 수 있다. 일 실시예에 따르면, 프로세서는 촬영 영상을 저장할 때, 촬영되는 영상에 그래픽 요소에 관련된 메타데이 터(metadata)를 매핑(mapping)하여 저장하는 동작을 수행할 수 있다. 예를 들어, 프로세서는 지정된 카메 라를 이용하여 촬영된 제2 영상에서 추출된 그래픽 요소와 관련된 메타데이터(예: 태그, 링크, 어플리케이션 정 보, 서비스 정보)를 제2 영상(예: 제2 영상 내의 그래픽 요소)에 매핑하여 저장할 수 있다. 도 8a 및 도 8b는 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 동작 예를 도시하는 도면들 이다. 일 실시예에 따라, 도 8a는 펼침 상태의 전자 장치의 전면의 예를 나타낼 수 있다. 일 실시예에 따라, 도 8b는 펼침 상태의 전자 장치의 후면의 예를 나타낼 수 있다. 일 실시예에 따라, 도 8a 및 도 8b에 예시한 바와 같이, 전자 장치는 펼침 상태에서 전면(예: 제1 면)에 배치되는 제1 카메라(예: 도 6의 제1 카메라)와 제1 디스플레이(예: 도 6의 제1 디스플레이 )를 포함하고, 펼침 상태에서 후면(예: 제2 면 또는 커버 면)에 배치되는 제2 카메라(예: 도 6의 제2 카메라)와 제2 디스플레이(예: 도 6의 제2 디스플레이)를 포함할 수 있다. 일 실시예에 따라, 제1 카메라와 제2 카메라는 전자 장치의 펼침 상태에서 서로 반대되는 면에 배치될 수 있다. 일 실시예에 따라, 제1 디스플레이와 제2 디스플레이는 전자 장치의 펼침 상태 에서 서로 반대되는 면에 배치될 수 있다. 일 실시예에 따라, 제1 카메라는 제1 디스플레이와 동일면(예: 전면) 상에 배치되고, 제2 카메라는 제2 디스플레이와 동일 면(예: 후면)에 배치될 수 있다. 일 실시예에 따르면, 전자 장치는 펼침 상태에서 촬영 모드 진입(예: 어플리케이션 실행) 시에 제1 카메라 또는 제2 카메라를 활성화할 수 있다. 일 실시예에 따라, 활성화되는 카메라는 이전에 실행된 카메 라, 사용자에 의해 실행하도록 설정된 카메라, 또는 촬영 모드 진입 시에 사용자에 의해 실행하도록 지정된 카 메라를 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 촬영 모드 진입 이후 지정된 촬영 모드(예: 거 울 샷 모드)로 동작 시에 활성화된 카메라(예: 제1 카메라 또는 제2 카메라)를 지정된 카메라로 결정 할 수 있다. 일 실시예에 따르면, 전자 장치는 펼침 상태에서 촬영 모드 진입(예: 어플리케이션 실행) 시에 제1 카메라 와 제2 카메라를 동시에 활성화할 수 있다. 일 실시예에 따르면, 전자 장치는 촬영 모드 진입 이후 지정된 촬영 모드(예: 거울 샷 모드)로 동작 시에, 지정된 조건(예: 사용자 얼굴 객체 및/또는 지정된 식 별자)을 식별하는 것에 기반하여 제1 카메라 또는 제2 카메라 중 어느 일 카메라를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 전자 장치의 전면의 제1 카메라와 제1 디스플레이가 사용자를 향하고, 전자 장치의 후면의 제2 카메라와 제2 디스플레이가 반사체(예: 도 5의 반사체)를 향하는 경우 를 가정할 수 있다. 이러한 경우, 전자 장치는 제2 카메라를 지정된 카메라로 결정할 수 있다. 일 실 시예에 따라, 전자 장치는 지정된 카메라를 결정할 시, 지정된 카메라(예: 제2 카메라)와 동일 면에 위치한 디스플레이(예: 제2 디스플레이)를 지정된 그래픽 요소를 표시하기 위한 대상 디스플레이로 결정할 수 있다. 일 실시예에 따라, 전자 장치는 그래픽 요소를 표시하기 위한 대상 디스플레이로 제2 디스플레이 를 결정할 시, 제2 디스플레이를 통해 지정된 그래픽 요소를 표시하고, 제2 디스플레이와 반대 면에 위치한 디스플레이(예: 제1 디스플레이)를 통해 제2 카메라로부터 획득하는 영상의 프리뷰를 표 시하도록 동작할 수 있다. 일 실시예에 따라, 전자 장치의 후면의 제2 카메라와 제2 디스플레이가 사용자를 향하고, 전자 장치의 전면의 제1 카메라와 제1 디스플레이가 반사체(예: 도 5의 반사체)를 향하는 경우 를 가정할 수 있다. 이러한 경우, 전자 장치는 제1 카메라를 지정된 카메라로 결정할 수 있다. 일 실 시예에 따라, 전자 장치는 지정된 카메라를 결정할 시, 지정된 카메라(예: 제1 카메라)와 동일 면에 위치한 디스플레이(예: 제1 디스플레이)를 지정된 그래픽 요소를 표시하기 위한 대상 디스플레이로 결정할 수 있다. 일 실시예에 따라, 전자 장치는 그래픽 요소를 표시하기 위한 대상 디스플레이로 제1 디스플레이 를 결정할 시, 제1 디스플레이를 통해 지정된 그래픽 요소를 표시하고, 제1 디스플레이와 반대 면에 위치한 디스플레이(예: 제2 디스플레이)를 통해 제1 카메라로부터 획득하는 영상의 프리뷰를 표 시하도록 동작할 수 있다. 일 실시예에 따라, 제2 카메라가 지정된 카메라로 동작하는 것을 가정할 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드에서 지정된 카메라로 동작하는 제2 카메라와 동 일 면(예: 후면 또는 제2 면)에 위치한 제2 디스플레이를 통해 지정된 그래픽 요소를 표시할 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드에서 지정된 카메라로 동작하는 제2 카메라와 반대 면(예: 전면 또는 제1 면)의 제1 카메라는 비활성화(예: 턴-오프(turn-off))할 수 있다. 일 실시예에 따르 면, 전자 장치는 지정된 촬영 모드에서 제2 카메라와 반대 면에 위치한 제1 디스플레이를 통해 제2 카메라에서 획득되는 영상의 프리뷰를 표시할 수 있다. 일 실시예에서, 프리뷰는 반사체(예: 도 5의 반사체) 및 반사체에 투영된 영상(예: 도 5의 투영체)을 포함할 수 있다. 일 실시예에서, 반사체에 투영된 영상은, 지정된 카메라로 동작하는 제2 카메라, 제2 카메라와 동일 면에 위치한 제2 디스플레 이, 및 제2 디스플레이에 표시된 그래픽 요소를 포함하는 전자 장치에 각각 대응하는 객체를 포 함할 수 있다. 일 실시예에 따라, 제1 카메라가 지정된 카메라로 동작하는 경우를 가정할 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드에서 지정된 카메라로 동작하는 제1 카메라와 동 일 면(예: 전면 또는 제1 면)에 위치한 제1 디스플레이를 통해 지정된 그래픽 요소를 표시할 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드에서 지정된 카메라로 동작하는 제1 카메라와 반대 면(예: 후면 또는 제2 면)의 제2 카메라는 비활성화(예: 턴-오프)할 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드에서 제1 카메라와 반대 면에 위치한 제2 디스플레이를 통해 제1 카메라에서 획득되는 영상의 프리뷰를 표시할 수 있다. 일 실시예에서, 프리뷰는 반사체(예: 도 5의 반사체 ) 및 반사체에 투영된 영상(예: 도 5의 투영체)을 포함할 수 있다. 일 실시예에서, 반사체에 투영된 영상은, 지정된 카메라로 동작하는 제1 카메라, 제1 카메라와 동일 면에 위치한 디스플레이(예: 제1 디스플레이), 및 제1 디스플레이에 표시된 그래픽 요소를 포함하는 전자 장치에 각각 대응하는 객체를 포함할 수 있다. 도 9a, 도 9b 및 도 9c는 본 개시의 일 실시예에 따른 전자 장치의 폼팩터에 대응하는 다양한 디스플레이의 예 를 도시하는 도면들이다. 일 실시예에 따라, 도 9a, 도 9b 및 도 9c는 다양한 디스플레이 형태에 따른 전자 장치의 다양한 폼팩터 (form factor)의 예를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 바형(bar type) 또는 평판형 (plate type), 폴더블(foldable), 롤러블, 슬라이더블(slidable), 및/또는 폴더블&슬라이더블 하이브리드와 같 은 다양한 폼팩터를 포함할 수 있다. 일 실시예에 따라, 도 9a, 도 9b 및 도 9c에 예시된 바와 같이, 전자 장치 는 다양한 형태로 구현될 수 있고, 전자 장치의 구현 형태에 따라 디스플레이(예: 도 1의 디스플레이 모듈 또는 도 6의 디스플레이)가 다양한 방식으로 제공될 수 있다. 본 문서에 개시된 일 실시예에 따른 전자 장치는 폴더블 형태의 폼팩터를 가지는 전자 장치(예: 폴더 블 장치)를 예로 설명하지만, 다양한 실시예들에 따른 전자 장치 및 그의 동작은 이에 한정되지 않는다. 예를 들면, 전자 장치는, 바형 또는 평판형, 롤러블 및/또는 슬라이더블과 같은 다양한 폼팩터 및 그에 의 해서도 동작할 수 있다. 예를 들어, 도시된 전자 장치는 바형 또는 평판형 장치, 폴더블 장치, 롤러블 장 치 또는 슬라이더블 장치의 일부일 수 있다. 일 실시예에 따라, 도 9a, 도 9b 및 도 9c는 전자 장치의 펼침 상태에서 후면의 디스플레이(또는 제2 디스 플레이)(예: 커버 디스플레이 또는 서브 디스플레이)의 다양한 예를 나타낼 수 있다. 일 실시예에 따라, 도시되 지는 않았으나, 도 9a, 도 9b 및 도 9c에 예시된 전자 장치는 펼침 상태에서 전면의 디스플레이(예: 제1 디스플레이 또는 메인 디스플레이)의 서로 다른 두 영역이 서로 마주보는 방향으로 접힘이 가능한 전자 장치를 나타낼 수 있다. 일 실시예에 따라, 사용자는 전자 장치를 휴대하는 경우 전자 장치의 제1 디스플레 이를 서로 다른 두 영역이 마주보는 상태로 접어서 휴대할 수 있다. 일 실시예에 따라, 사용자는 전자 장치 를 실제 사용하는 상태에서는 제1 디스플레이를 펼쳐 서로 다른 두 영역이 실질적으로 평판 형태를 이루게 하여 사용할 수 있다. 일 실시예에 따라, 전자 장치는 도 9a, 도 9b 및 도 9c의 예시와 같이 제2 디스플레 이(910, 920, 930)를 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 적어도 하나의 폴딩 축에 기반하여 적어도 2개의 디스플레이 면들(예: 제1 디스플레이 면 및 제2 디스플레이 면)을 포함하는 폼팩터를 포함할 수 있다. 다양한 실시예들이 이에 한정 되는 것은 아니며, 이는 예시적인 것으로, 전자 장치가 가질 수 있는 폴딩 축들의 수는 제한하지 않는다. 일 실시예에 따르면, 전자 장치는 구현 형태에 따라 디스플레이가 다양한 방식(예: 인-폴딩(in-folding), 아웃-폴딩(out-folding), 또는 인/아웃 폴딩)으로 폴딩 또는 언폴딩될 수 있다. 일 실시예에 따르면, 도 9a 및 도 9b는 세로 폴더블 형태의 전자 장치의 예를 나타낼 수 있다. 일 실시예 에 따르면, 도 9c는 가로 폴더블 형태의 전자 장치의 예를 나타낼 수 있다. 일 실시예에 따르면, 도 9a, 도 9b 및 도 9c에 예시한 바와 같이, 전자 장치의 디스플레이는 전자 장치의 폼팩터에 따라 디스플레 이(예: 메인 디스플레이 및/또는 커버 디스플레이)의 사양이 다양할 수 있다. 일 실시예에 따르면, 전자 장치의 디스플레이는 디스플레이의 화면 크기(예: 화면 대각선의 길이), 해상도, 화면 비율(예: 해상도에 따른 화면 비율), 디스플레이 형태(예: 가로/세로 비율)가 다양할 수 있으며, 전술한 예에 한정되지 않는다. 일 실시예에서, 이하의 설명에서 “디스플레이 사이즈”는 전술한 예의 적어도 하나의 디스플레이 사양을 포괄하는 의미로 사용될 수 있다. 예를 들어, 이하에서 “디스플레이 사이즈”는 디 스플레이의 하드웨어적인 사양(예: 화면 크기) 및/또는 소프트웨어적인 사양(예: 해상도, 화면 비율, 가로/세로 비율)을 포함할 수 있다. 예를 들어, “디스플레이 사이즈”는 디스플레이의 화면 크기, 해상도, 화면 비율, 디 스플레이 형태와 같은 용어와 상호 호환적으로 사용될 수 있다. 일 실시예에 따라, 전자 장치가 도 9a, 도 9b 및 도 9c의 예시와 같이 폴더블 장치의 폼팩터인 경우, 전자 장치는 제1 상태(예: 언폴디드 상태 또는 오픈 상태)에서 동작 가능한 제1 디스플레이 사이즈(예: 제1 화 면 크기 및 제1 화면 비율)를 갖는 메인 디스플레이(미도시)를 포함할 수 있다. 일 실시예에 따라, 전자 장치 가 폴더블 장치의 폼팩터인 경우, 전자 장치는 제2 상태(예: 폴디드 상태 또는 클로즈 상태) 및/또는제1 상태에서 동작 가능한 제1 디스플레이 사이즈와 다른 제2 디스플레이 사이즈(예: 제2 화면 크기 및 제2 화 면 비율)를 갖는 커버 디스플레이(910, 920, 930)를 포함할 수 있다. 일 실시예에 따라, 도 9a, 도 9b 및 도 9c에서는 전자 장치가 제2 상태에서 커버 디스플레이(910, 920, 930)가 동작하는 예를 나타낼 수 있다. 일 실시예에 따라, 커버 디스플레이(910, 920, 930)는 전자 장치의 폼팩터에 따라 디스플레이 형태 및 디스플레이 사이즈가 다를 수 있다. 예를 들어, 도 9a, 도 9b 및 도 9c에 예 시된 바와 같이, 전자 장치의 커버 디스플레이(910, 920, 930)의 디스플레이 사이즈(또는 화면 해상도)에 따라 서로 다른 형상으로 제공될 수 있다. 일 실시예에 따라, 도 9a, 도 9b 및 도 9c에는 도시하지 않았으나, 전자 장치가 롤러블/슬라이더블 장치의 폼팩터인 경우, 전자 장치는 제3 상태(예: 클로즈 상태 또는 슬라이드-인 상태)에서 동작 가능한 제3 디스 플레이 사이즈를 갖는 메인 디스플레이를 포함할 수 있다. 일 실시예에 따라, 전자 장치가 롤러블/슬라이 더블 장치의 폼팩터인 경우, 전자 장치는 제4 상태(예: 오픈 상태 또는 슬라이드-아웃 상태)에서 동작 가 능한 제3 디스플레이 사이즈와 다른 제4 디스플레이 사이즈를 갖는 확장 디스플레이를 포함할 수 있다. 일 실시예에서, 전자 장치의 폼팩터와 폼팩터에 따른 디스플레이(예: 메인 디스플레이, 커버 디스플레이, 및/또는 확장 디스플레이)의 종류, 형태 및/또는 사이즈는 전술한 예에 제한하지 않으며, 전자 장치의 폼 팩터에 따라 다양하게 구현될 수 있다. 일 실시예에 따르면, 전자 장치는 폴더블&슬라이더블 하이브리드 장치와 같은 폼팩터를 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 전자 장치의 지정된 촬영 모드로 동작 시에 전자 장치의 폼팩 터(예: 도 9a, 도 9b 및 도 9c의 예시와 같은 다양한 폼팩터)에 따른 디스플레이 사이즈에 대응하게 편집(또는 수정)(modify)된 영상(예: 지정된 그래픽 요소)을 표시할 수 있다. 본 개시의 실시예에 따라, 커버 디스플레이 에 맞추어 영상(예: 지정된 그래픽 요소)을 표시하는 것과 관련하여 후술하는 도면을 참조하여 설명된다. 도 10a, 도 10b 및 도 10c는 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 동작 예를 도시 하는 도면들이다. 일 실시예에 따라, 도 10a, 도 10b 및 도 10c는 펼침 상태의 전자 장치의 전면의 예를 나타낼 수 있다. 일 실시예에 따라, 도 10a, 도 10b 및 도 10c에서는 전자 장치가 지정된 촬영 모드로 동작 시에, 전자 장치 의 후면의 카메라(예: 도 8b의 제2 카메라)가 지정된 카메라로 동작하는 예를 나타낼 수 있다. 일 실 시예에 따라, 도 10a 및 도 10b에서는 지정된 카메라로 동작하는 제2 카메라와 반대 면에 위치한 전면의 디스플레이(예: 도 8a의 제1 디스플레이)를 통해 제2 카메라에서 획득하는 영상의 프리뷰를 표 시하는 예를 나타낼 수 있다. 일 실시예에서, 도 10a에 예시한 바와 같이, 프리뷰는 반사체(예: 도 5의 반사체) 및 반사체에 투영 된 영상(예: 도 5의 투영체)에 각각 대응하는 적어도 하나의 객체를 포함할 수 있다. 예를 들어, 적어도 하나의 객체는, 반사체에 대응하는 제1 객체, 사용자에 대응하는 제2 객체, 전자 장치에 대응 하는 제3 객체, 및 전자 장치에서 지정된 카메라로 동작하는 제2 카메라(예: 도 8b의 제2 카메라 )와 동일 면에 위치한 제2 디스플레이(예: 도 8b의 제 2 디스플레이)에 대응하는 제4 객체를 포함할 수 있다. 일 실시예에 따라, 도 10a 및 도 10b에서는 예시하지 않았으나, 적어도 하나의 객체는 지정된 카메라로 동작하는 제2 카메라에 대응하는 제5 객체 및 제2 디스플레이에 표시된 그래픽 요소에 대응 하는 제6 객체를 포함할 수 있다. 일 실시예에서, 그래픽 요소에 대응하는 제6 객체는 제2 디스플레이에 대응하는 제4 객체에 기반하여 표시될 수 있다. 일 실시예에 따라, 전자 장치는 지정된 촬영 모드로 동작(또는 진입) 시에, 전자 장치의 촬영 모드가 지정된 촬영 모드(예: 거울 샷 모드)인 것을 나타내는 가이드 객체를 프리뷰의 지정된 일 영역(예: 화면 하단 중앙)에 제공할 수 있다. 일 실시예에서, 가이드 객체는 지정된 촬영 모드를 나타내는 가이드 아이콘 및/또는 가이드 텍스트(예: Mirror shot)를 포함할 수 있다. 일 실시예에서, 도 10b는 프리뷰에서 지정된 그래픽 요소가 표시될 영역과 지정된 그래픽 요소로 표시 가 능한 적어도 하나의 추천 그래픽 요소(예: 추천 컨텐츠)를 제공하는 예를 나타낼 수 있다. 일 실시예에서, 지정 된 그래픽 요소가 표시될 영역은, 예를 들어, 프리뷰에서 제4 객체에 대응하는 영역(예: 전자 장치 의 제2 디스플레이에 대응하는 영역)을 포함할 수 있다. 일 실시예에 따라, 도 10b에 예시한 바와 같이, 전자 장치는 프리뷰에서 지정된 그래픽 요소가 표시 될 제4 객체에 대응하는 영역에 지정된 효과를 적용하여 다른 객체와 구별되게 강조 표시할 수 있다. 예를 들어, 지정된 효과는 그래픽 요소가 표시될 영역에 대해 사용자에게 시각적으로 제공하기 위한 그래픽 기반 의 어포던스(affordance) 객체에 기반하여 제공될 수 있다. 예를 들어, 지정된 효과는 하이라이팅 효과, 색감 효과, 네온 효과, 및/또는 크로마키(Chroma Key) 효과 중 적어도 하나의 효과를 포함할 수 있다. 일 실시예에 따라, 도 10b에 예시한 바와 같이, 전자 장치는 적어도 하나의 추천 그래픽 요소에 대응하는 적어도 하나의 추천 객체(1060, 1070, 1080)를 프리뷰의 지정된 일 영역(예: 화면 우측)을 통해 제공할 수 있다. 일 실시예에 따르면, 적어도 하나의 추천 객체(1060, 1070, 1080)는 프리뷰 상에서 제4 객체 에 대응하는 영역에 대한 지정된 효과와 함께 제공될 수 있다. 일 실시예에 따라, 적어도 하나의 추천 객체(1060, 1070, 1080)는 지정된 촬영 모드에서 지정된 카메라로 동작 하는 제2 카메라와 동일 면에 위치한 제2 디스플레이에 실질적으로 표시될 적어도 하나의 추천 그래 픽 요소에 관련된 그래픽 객체를 포함할 수 있다. 일 실시예에 따르면, 적어도 하나의 추천 객체(1060, 1070, 1080)는 지정된 형식에 기반한 텍스트 및/또는 이미지 형태를 포함할 수 있다. 일 실시예에 따르면, 적어도 하 나의 추천 객체(1060, 1070, 1080)는 생성형 AI(generative AI) 엔진에 의해 생성된 텍스트 및/또는 이미지를 포함할 수 있다. 예를 들어, 전자 장치는 생성형 AI 기반으로 컨텍스트를 자동 생성할 수 있다. 예를 들어, 전자 장치는 LLM(large language model)에 기반하여 상황에 맞는 가장 적절한 컨텍스트(예: 문구 및"}
{"patent_id": "10-2023-0113506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "/또는 이미지)를 생성할 수 있다. 예를 들어, 전자 장치는 다양하게 학습된 모델에 기반하여 상황을 요약 하고, 자연스러운 문구를 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 생성된 컨텍스트에 기반하여 적어도 하나의 추천 객체(1060, 1070, 1080)를 생성할 수 있다. 일 실시예에서, 생성형 AI가 생성하는 객체는 사전에 예측 가능하고 미리 정의된 문구나 이미지가 아니며, 여러 입력 파라미터(예: 사용자와 관련된 정보(예: 인물, 장소, 시간에 관련된 정보), 사진 관련 정보)를 기반으로 생성되는 컨텐츠를 포함할 수 있다. 일 실시예에서, 생성되는 컨텐츠는 프롬프트 엔지니어링(prompt engineering)으로 지정된 디스플레이(예: 커버 디스플레이)에 맞게 표시될 수 있도록 설정될 수 있다. 일 실시 예에서, 생성형 AI 엔진은 전자 장치 내에 on-device AI로 포함된 엔진이거나, 외부 서버에서 제공하는 AI 엔진을 포함할 수 있다. 일 실시예에서, 지정된 디스플레이(예: 커버 디스플레이)에 예측 불가능한 이미지가 표 시될 수 있기 때문에, 프롬프트 엔지니어링에 기반하여 표시할 수 있는 내용에 대한 가이드라인을 제공할 수 있 다. 예를 들어, 개인 정보(예: 전화번호, 위치)의 표시를 제외하거나, 부적절한 표현이나 사진을 필터링하도록 학습하도록 하거나, 지정된 디스플레이(예: 커버 디스플레이 또는 메인 디스플레이)의 크기에 맞게 이미지를 배 치하거나, 또는 색상에 어울리도록 이미지를 설정하는 것과 같은 가이드를 제공할 수 있다. 일 실시예에 따라, 적어도 하나의 추천 객체(1060, 1070, 1080)는 제1 디스플레이에 표시된 프리뷰 상에 중첩하여 제공될 수 있다. 일 실시예에 따라, 적어도 하나의 추천 객체(1060, 1070, 1080)는 그래픽 요소 가 표시되는 디스플레이(예: 도 8b의 제2 디스플레이)의 형태에 대응하는 형태로 제공할 수 있다. 일 실시예에 따라, 적어도 하나의 추천 객체(1060, 1070, 1080)는 사용자 입력(또는 터치 제스처(touch gesture))(예: 플릭(flick), 스와이프(swipe), 드래그(drag), 또는 핀치(pinch))에 기반하여 속성 및/또는 종 류가 변경(또는 조정)될 수 있다. 예를 들어, 전자 장치는 사용자 입력(예: 추천 객체에 기반한 상하 스크 롤 제스처)에 기반하여 표시된 추천 객체(1060, 1070, 1080)를 다른 추천 객체의 그룹으로 변경하여 제공할 수 있다. 예를 들어, 전자 장치는 사용자 입력(예: 추천 객체에 기반한 좌우 플릭 제스처)에 기반하여 선택된 추천 객체의 스타일을 변경하여 제공할 수 있다. 예를 들어, 전자 장치는 사용자 입력(예: 추천 객체에 기 반한 핀치 제스처(예: 핀치 인(축소) 또는 핀치 아웃(확대)))에 기반하여 선택된 추천 객체가 제2 디스플레이 에 표시되는 크기를 변경하여 제공할 수 있다. 일 실시예에 따라, 적어도 하나의 추천 객체(1060, 1070, 1080)는 사용자 입력(또는 터치 제스처)(예: 탭(ta p))에 기반하여 어느 하나의 추천 객체가 선택될 수 있다. 일 실시예에 따라, 전자 장치는 프리뷰에 서 추천 객체를 선택하는 사용자 입력을 감지할 수 있다. 일 실시예에 따라, 전자 장치는 사용자 입력에 기반하여, 선택된 추천 객체에 대응하는 그래픽 요소를 제2 디스플레이에 표시할 수 있다. 일 실시예에 따라, 전자 장치는 사용자 입력에 기반하여 선택된 추천 객체에 대응하는 그래픽 요소를 제2 디스플레이에 표시할 수 있다. 일 실시예에 따라, 전자 장치의 제2 디스플레이에 그래픽 요소를 제공(예: 표시)하는 것과 관련하여 후술하는 도면들을 참조하여 설명된다. 일 실시예에 따라, 전자 장치는 제2 디스플레이에 그래픽 요소를 표시할 때, 제1 디스플레이의 프리뷰에서 제4 객체에 대응하는 영역에 적용된 지정된 효과를 표시하지 않을 수 있다. 일 실시예에 따라, 프리뷰에서 제4 객체 에 대응하는 영역에 제2 디스플레이에 표시된 그래픽 요소에 대응하는 객체가 표시될 수 있다. 예를들어, 제4 객체에 대응하는 영역은 반사체에 투영된 제2 디스플레이에 표시된 그래픽 요소에 대응하 는 객체가 표시될 수 있다. 일 실시예에 따르면, 전자 장치는 그래픽 요소를 제공할 때, 그래픽 요소를 후보정 처리하여 제공할 수 있 다. 예를 들어, 전자 장치는 그래픽 요소가 보다 선명하게 보이도록 그래픽 요소를 보정한 후 제2 디스플 레이를 통해 표시하도록 동작할 수 있다. 도 11은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 11은 일 실시예에 따른 전자 장치에서, 영상 촬영(예: 반사체에 기반한 거울 샷 촬영)을 지원하는 동작의 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 방법은, 예를 들어, 도 11에 도시된 흐 름도에 따라 수행될 수 있다. 도 11에 도시된 흐름도는 전자 장치의 동작의 일 실시예에 따른 흐름도에 불 과하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 1101 내지 동작 1115는 전자 장치의 적어도 하나의 프로세서(예: 도 1 또는 도 6의 프로세서)에서 수 행될 수 있다. 일 실시예에 따르면, 도 11에서 설명되는 동작은, 예를 들어, 도 7 내지 도 10b에서 설명된 동작들에 결합하여 휴리스틱(heuristic)하게 수행되거나, 설명된 동작의 적어도 일부 동작을 대체하고 적어도 일부 다른 동작에 결 합하여 휴리스틱하게 수행되거나, 설명된 동작들의 적어도 일부 동작의 상세 동작으로 휴리스틱하게 수행될 수 있다. 도 11에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법은, 영상 촬영을 위한 동작 을 감지하는 동작, 제1 카메라 및 제2 카메라로부터 영상을 획득하는 동작, 영상 분석에 기반하여 지정된 식별 정보를 검출하는 동작, 식별 정보 검출에 기반하여 지정된 촬영 모드를 결정하는 동작 , 지정된 촬영 모드에서 동작하는 지정된 카메라를 결정하는 동작, 지정된 카메라와 동일 면에 위 치한 디스플레이에 기반하여 그래픽 요소를 표시하는 동작, 반대 면의 디스플레이를 통해 지정된 카메라 로부터 획득된 영상의 프리뷰를 표시하는 동작, 및 촬영 요청 감지에 기반하여 지정된 카메라를 통해 획 득되는 영상을 촬영하는 동작을 포함할 수 있다. 도 11을 참조하면, 동작 1101에서, 전자 장치의 프로세서는 영상 촬영을 위한 동작을 감지하는 동작 을 수행할 수 있다. 예를 들어, 프로세서는 사용자로부터 영상 촬영에 관련된 어플리케이션(예: 촬영 어플 리케이션 또는 카메라 어플리케이션)을 실행하기 위한 사용자 입력(예: 어플리케이션의 실행 아이콘 선택)을 수 신할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력을 수신하는 것에 기반하여 영상 촬영 시작을 판단할 수 있다. 동작 1103에서, 프로세서는 카메라로부터 영상을 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영에 실행되는 제1 카메라 또는 제2 카메라로부터 영상을 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라 및 제2 카메라로부터 영상을 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 위한 동작(예: 촬영 어플리케이션 실행)을 감지하는 것에 기 반하여 제1 카메라(예: 도 6의 제1 카메라 또는 도 8b의 제1 카메라)(이하, ‘제1 카메라’) 또 는 제2 카메라(예: 도 6의 제2 카메라 또는 도 8a의 제2 카메라)(이하, ‘제2 카메라’)를 활성 화(예: 턴-온(turn-on))할 수 있다. 일 실시예에 따라, 활성화되는 카메라는 이전에 실행된 카메라, 사용자에 의해 실행하도록 설정된 카메라, 또는 촬영 모드 진입 시에 사용자에 의해 실행하도록 지정된 카메라를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 활성화된 카메라(예: 제1 카메라 또는 제2 카메라)로 부터 영상을 획득(또는 수신)할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 위한 동작(예: 촬영 어플리케이션 실행)을 감지하는 것에 기 반하여 제1 카메라와 제2 카메라를 활성화(예: 턴-온)할 수 있다. 일 실시예에 따르면, 프로세서 는 활성화된 제1 카메라와 제2 카메라 각각으로부터 영상을 획득(또는 수신)할 수 있다. 동작 1105에서, 프로세서는 영상으로부터 지정된 식별 정보를 검출하는 동작을 수행할 수 있다. 일 실시예 에 따르면, 프로세서는 QR 코드, 바코드, 및/또는 텍스트를 검출하는 방식과 유사한 방식으로 지정된 식별정보를 검출할 수 있다. 예를 들어, 지정된 식별 정보를 위한 영상을 흑백(예: 0/1)과 같은 형식으로 단순화하 고, 프로세서는 카메라로부터 획득하는 영상의 패턴을 스캔(scan)하면서 비슷한 패턴의 영역을 매칭시키는 방식으로 식별 정보를 검출할 수 있다. 일 실시예에 따르면, 프로세서는 실행되는 카메라(예: 제1 카메라 또는 제2 카메라)의 영상(예: 제1 영상)과 미리 등록된 기준 영상(예: 지정된 식별 정보)을 비교하고, 제1 영상으로부터 미리 등록된 기준 영 상(예: 지정된 식별 정보)을 검출하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라로부터 획득되는 영상과 제2 카메라로부터 획득되는 영상을 포함하는 제1 영상과 미리 등록된 기준 영상(예: 지정된 식별 정보)을 비교하고, 제1 영상으로부터 미리 등록된 기준 영상(예: 지정된 식별 정보)를 검출하도록 동작할 수 있다. 일 실시예에서, 지정된 식별 정보는 지정된 촬영 모드의 실행 여부를 판단하기 위한 미리 지정된 영상 객체를 포함할 수 있다. 일 실시예에서, 지정된 영상 객체는, 지정된 얼굴 객체 또는 지정된 식별자 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라 및/또는 제2 카메라로부터 획득되 는 제1 영상에서 지정된 식별 정보가 검출되는지 판단할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카 메라 및/또는 제2 카메라로부터 획득되는 제1 영상과 전자 장치의 메모리(예: 도 1 또는 도 6의 메모리)에 미리 설정된 기준 영상을 비교하고, 제1 영상으로부터 지정된 얼굴 객체 또는 지정된 식별자를 식별하도록 동작할 수 있다. 동작 1107에서, 프로세서는 식별 정보 검출에 기반하여 지정된 촬영 모드를 결정하는 동작을 수행할 수 있 다. 일 실시예에 따르면, 프로세서는 제1 카메라 및/또는 제2 카메라의 영상으로부터 지정된 식 별 정보(예: 지정된 얼굴 객체 또는 지정된 식별자)를 검출하는 것에 기반하여 지정된 촬영 모드를 판단할 수 있다. 동작 1109에서, 프로세서는 지정된 촬영 모드에서 동작하는 지정된 카메라를 결정하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드를 판단하는 것에 기반하여, 실행된 카메라(예: 제1 영상을 획득하는 제1 카메라 또는 제2 카메라)를 지정된 촬영 모드에서 동작할 지정된 카메라로 결정할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드를 판단하는 것에 기반하여, 제1 카메 라 및 제2 카메라 중에서 지정된 촬영 모드에서 동작할 지정된 카메라를 결정할 수 있다. 일 실시예 에 따르면, 프로세서는 지정된 카메라를 결정하기 위한 지정된 스키마(또는 알고리즘, 모델, 네트워크 또 는 함수)에 기반하여 제1 카메라 또는 제2 카메라 중 어느 하나의 카메라를 지정된 촬영 모드에서 동 작하는 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 영상 분석에 기반하여, 피사체와 의 거리, 얼굴 객체의 크기, 얼굴 객체의 인식 여부, 및/또는 지정된 식별자의 인식 여부에 적어도 기반하여 지 정된 카메라를 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 및 제2 카메라의 영상으로부터 유사한 얼굴 객체(예: 사용자의 얼굴 객체)가 인식되는 경우, 각 얼굴 객체와의 거리 정보에 기반하여 지정된 카메라를 판단 할 수 있다. 예를 들어, 프로세서는 제1 카메라의 영상으로부터 추출된 제1 얼굴 객체와의 제1 거리 를 판단(예: 추정)하고, 제2 카메라의 영상으로부터 추출된 제2 얼굴 객체와의 제2 거리를 판단(예: 추 정)할 수 있다. 일 실시예에 따라, 프로세서는 제1 거리와 제2 거리 중 상대적으로 긴 거리의 얼굴 객체 (예: 전자 장치와 상대적으로 멀리 있는 얼굴 객체)가 포함된 영상을 획득한 카메라를 지정된 카메라로 결 정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 및 제2 카메라의 영상으로부터 유사한 얼굴 객체(예: 사용자의 얼굴 객체)가 인식되는 경우, 각 얼굴 객체의 크기 정보에 기반하여 지정된 카메라를 판단할 수 있다. 예를 들어, 프로세서는 제1 카메라의 영상으로부터 추출된 제1 얼굴 객체의 제1 크기와 제2 카메라의 영상으로부터 추출된 제2 얼굴 객체의 제2 크기를 비교할 수 있다. 일 실시예에 따라, 프로세서 는 제1 크기와 제2 크기 중 상대적으로 작은 크기의 얼굴 객체(예: 전자 장치와 상대적으로 멀리 있 는 얼굴 객체)가 포함된 영상을 획득한 카메라를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 또는 제2 카메라의 영상 중 어느 하나의 영상 으로부터 얼굴 객체(예: 사용자의 얼굴 객체)가 인식되는 경우, 얼굴 객체가 포함되지 않은 영상을 획득한 카메 라(예: 사용자를 향하고 있는 카메라와 반대 면에 위치한 카메라)를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 또는 제2 카메라의 영상 중 어느 하나의 영상 으로부터 지정된 식별자가 인식되는 경우, 지정된 식별자를 포함하는 영상을 획득한 카메라(예: 반사체에 투영된 지정된 식별자를 촬영하는 카메라)를 지정된 카메라로 결정할 수 있다. 동작 1111에서, 프로세서는 지정된 카메라와 동일 면에 위치한 디스플레이에 기반하여 그래픽 요소를 표시 하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드에서 동작할 지정된 카메 라를 판단하는 것에 기반하여, 지정된 카메라와 동일 면에 위치된 디스플레이(예: 도 8a의 제1 디스플레이 또는 도 8b의 제2 디스플레이)를 통해 지정된 상황에 맞는 그래픽 요소를 표시하도록 동작할 수 있다. 일 실시예에 따라, 전자 장치는 지정된 카메라를 결정할 시, 지정된 카메라와 동일 면에 위치한 디스플레이를 지정된 그래픽 요소를 표시하기 위한 대상 디스플레이로 결정할 수 있다. 일 실시예에 따라, 전자 장치는 그래픽 요소를 표시하기 위한 대상 디스플레이를 결정하는 것에 기반하여 대상 디스플레이를 통해 지정된 그래 픽 요소를 표시하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드를 판단하는 것에 기반하여 상황 인지를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 상황 인지에 기반하여 사용자의 현재 위치, 사용자의 활동, 및/또 는 인식 객체에 대응하는 상황을 판단할 수 있다. 일 실시예에 따르면, 프로세서는 판단하는 상황에 대응 하는 그래픽 요소를 생성할 수 있다. 일 실시예에 따라, 상황 인지에 기반하여 대응하는 그래픽 요소를 생성하 여 제공하는 것과 관련하여 후술하는 도면들을 참조하여 설명된다. 동작 1113에서, 프로세서는 반대 면의 디스플레이를 통해 지정된 카메라로부터 획득된 영상의 프리뷰를 표 시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 대상 디스플레이를 결정하는 것에 기반하 여 대상 디스플레이와 반대 면에 위치한 디스플레이를 통해 지정된 카메라로부터 획득하는 영상의 프리뷰를 표 시하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드에서 지정된 카메라와 동일 면에 위치한 디스플레이를 통해 지정된 그래픽 요소를 표시할 수 있다. 일 실시예에 따르면, 프로세서는 동작 시작 시에 제1 카메라 및 제2 카메라를 이용하여 동작하는 경우에서는, 지정된 촬영 모드에서 동작하는 지정된 카메라와 반대 면의 카메라는 비활성화(예: 턴-오프)하는 동작을 더 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 카메라와 반대 면(또는 대상 디스플레이와 반대 면)에 위치한 디 스플레이를 통해 지정된 카메라에서 획득되는 영상의 프리뷰를 표시할 수 있다. 일 실시예에서, 프리뷰는 반사 체(예: 도 5의 반사체) 및 반사체에 투영된 영상(예: 도 5의 투영체)에 각각 대응하는 적어도 하나의 객체를 포함할 수 있다. 예를 들어, 적어도 하나의 객체는, 반사체에 대응하는 객체, 사용자에 대응하는 객체, 전자 장치에 대응하는 객체, 전자 장치에서 지정된 카메라와 동일 면에 위치한 대상 디스플레이에 대 응하는 객체, 지정된 카메라에 대응하는 객체, 및/또는 대상 디스플레이에 표시된 그래픽 요소에 대응하는 객체 를 포함할 수 있다. 동작 1115에서, 프로세서는 촬영 요청 감지에 기반하여 지정된 카메라를 통해 획득되는 영상을 촬영하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 지정된 촬영 모드에서 동작하도록 지정된 카메라로부터 영상을 획득할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 카메라를 통해 획득되는 영상에 기반하여 영상 촬영을 수행할 수 있다. 일 실시예에 따 라, 촬영되는 영상은 반사체(예: 도 5의 반사체) 및 반사체에 투영된 영상(예: 도 5의 투영체)을 포 함할 수 있다. 일 실시예에 따르면, 프로세서는 촬영 영상을 제공하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로 세서는 촬영 영상을 디스플레이 상에 표시할 수 있다. 예를 들어, 프로세서는 프리뷰를 표시하는 디 스플레이에 표시된 프리뷰를 촬영 영상으로 대체하여 표시할 수 있다. 일 실시예에 따르면, 프로세서는 촬 영 영상을 전자 장치의 메모리(예: 도 1 또는 도 6의 메모리)에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 촬영 영상을 지정된 외부 장치(예: 클라우드, 및/또는 지정된 다른 전자 장치)에 공유 (예: 전송)할 수 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치에서 지정된 식별 정보를 제공하는 동작 예를 도시하는 도면이다. 일 실시예에 따라, 도 12는 펼침 상태의 전자 장치의 후면의 예를 나타낼 수 있다. 일 실시예에 따라, 도 12는 지정된 촬영 모드를 판단하기 위한 지정된 식별 정보로 제공 가능한 지정된 식별자의 예를 나타낼 수 있다. 일 실시예에 따르면, 지정된 식별자는 사용자에 의해 다양하게 설정될 수 있다. 예를 들어, 지정된 식별자는 사 용자에 지정 또는 제작되는 시각 디자인 객체를 포함할 수 있다. 예를 들어, 시각 디자인 객체는 아이콘, 텍스 트, 및/또는 영상(예: 스틸 이미지, 비디오, 애니메이션 이미지)을 포함할 수 있다. 일 실시예에서, 시각 디자 인 객체는 전자 장치를 나타내는 브랜드 식별자(또는 로고)에 대응하는 아이콘 및/또는 텍스트를 포함할 수 있다. 일 실시예에서, 시각 디자인 객체는 전자 장치의 메모리(예: 도 1 또는 도 6의 메모리)에 미리 저장되거나, 사용자에 의해 제작되어 메모리에 저장될 수 있다. 일 실시예에 따라, 전자 장치는 촬영 모드 진입 시에 지정된 촬영 모드를 판단하기 위하여, 제1 디스플레 이(예: 도 8a의 제1 디스플레이) 또는 제2 디스플레이를 통하여 지정된 식별자를 표시하도록 동작할 수 있다. 예를 들어, 도 12에 예시한 바와 같이, 전자 장치는 제2 디스플레이를 통해 지정된 식별자(예: “Galaxy”)를 표시할 수 있다. 일 실시예에 따르면, 전자 장치는 반사체에 투영된 지정 된 식별자를 제2 카메라를 통해 획득하여 분석할 수 있다. 일 실시예에 따르면, 전자 장치는 제2 디스플레이를 통해 지정된 식별자(예: “Galaxy”)를 제공할 때, 지정된 식별자를 좌우 반전(또는 좌우 대칭)하여 제공할 수 있다. 예를 들어, 전자 장치는 지정된 식별자가 반사체를 통하 여 촬영될 때, 촬영되는 지정된 식별자가 제1 디스플레이에서 좌우 반전 없이 정상적으로 표시되도 록, 지정된 식별자를 Y축을 기준으로 플립(flip)된 형태로 제공할 수도 있다. 이에 대응하는 예가 후술된 다. 일 실시예에 따르면, 전자 장치는 후면의 후면 커버에 지정된 식별자(예: 브랜드 식별자)가 각인될 수 있 다. 일 실시예에 따르면, 사용자는 전자 장치의 후면 커버에 각인된 브랜드 식별자를 지정된 식별자로 설 정할 수도 있다. 일 실시예에 따르면, 전자 장치는 반사체에 투영된 지정된 식별자(예: 후면 커버에 각인 된 지정된 식별자)를 제2 카메라를 통해 획득하여 분석할 수 있다. 도 13은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 13은 일 실시예에 따른 전자 장치에서, 영상 촬영(예: 도 5의 반사체에 기반한 거울 샷 촬영)을 지원하는 동작의 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 방법은, 예를 들어, 도 13에 도시된 흐 름도에 따라 수행될 수 있다. 도 13에 도시된 흐름도는 전자 장치의 동작의 일 실시예에 따른 흐름도에 불 과하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 1301 내지 동작 1321은 전자 장치의 적어도 하나의 프로세서(예: 도 1 또는 도 6의 프로세서)에서 수 행될 수 있다. 일 실시예에 따르면, 도 13에서 설명되는 동작은, 예를 들어, 도 7 내지 도 12에서 설명된 동작들에 결합하여 휴리스틱하게 수행되거나, 설명된 동작의 적어도 일부 동작을 대체하고 적어도 일부 다른 동작에 결합하여 휴리 스틱하게 수행되거나, 설명된 동작들의 적어도 일부 동작의 상세 동작으로 휴리스틱하게 수행될 수 있다. 일 실시예에 따르면, 전자 장치는 동작 시에 실행되는 어느 하나의 카메라(예: 전면 카메라)에 기반하여 지정된 촬영 모드를 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 동작 시에 제1 카메라(예: 전면 카 메라)와 제2 카메라(예: 후면 카메라)에 기반하여 지정된 촬영 모드를 수행할 수 있다. 일 실시예에 따라, 도 13에서는 제1 카메라와 제2 카메라와 같이 복수의 카메라들에 기반하여 지정된 촬영 모드를 수행하는 동작의 예 를 나타낼 수 있다. 도 13에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법은, 영상 촬영을 위한 동작 을 감지하는 동작, 전자 장치가 지정된 상태인지 판단하는 동작, 전자 장치가 지정된 상 태가 아닌 것을 판단하는 것에 기반하여, 일반 촬영 모드에서 활성화된 카메라에 기반한 영상 촬영 동작을 처리 하는 동작, 전자 장치가 지정된 상태인 것을 판단하는 것에 기반하여, 제1 카메라로부터 제1 영상과 제2 카메라로부터 제2 영상을 획득하는 동작, 제1 영상과 제2 영상에 기반하여 지정된 식별 정보를 판단 하는 동작, 지정된 식별 정보가 검출되는지 판단하는 동작, 지정된 식별 정보가 검출되는 것에 기 반하여, 지정된 촬영 모드에 기반한 동작을 결정하는 동작, 지정된 촬영 모드에 기반한 영상 촬영 동작을 처리하는 동작, 지정된 식별 정보가 검출되지 않는 것에 기반하여, 지정된 촬영 모드를 실행하기 위한 가 이드를 제공하는 동작, 사용자와 상호작용에 기반하여 지정된 촬영 모드 또는 일반 촬영 모드를 실행하는 동작, 및 실행하는 촬영 모드에 기반한 영상 촬영 동작을 처리하는 동작을 포함할 수 있다. 도 13을 참조하면, 동작 1301에서, 전자 장치의 프로세서는 영상 촬영을 위한 동작을 감지하는 동작 을 수행할 수 있다. 예를 들어, 프로세서는 사용자로부터 영상 촬영에 관련된 어플리케이션(예: 촬영 어플 리케이션 또는 카메라 어플리케이션)을 실행하기 위한 사용자 입력(예: 어플리케이션의 실행 아이콘 선택)을 수 신할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력을 수신하는 것에 기반하여 영상 촬영 시작을 판단할 수 있다. 동작 1303에서, 프로세서는 전자 장치가 지정된 상태인지 판단하는 동작을 수행할 수 있다. 일 실시 예에 따르면, 프로세서는 촬영 모드 시작 시에 전자 장치가 제1 상태(예: 펼침 상태)에 있는지 또는 제2 상태(예: 중간 상태 또는 접힘 상태)에 있는지 판단할 수 있다. 일 실시예에서, 지정된 상태는 전자 장치 의 제1 상태(예: 펼침 상태)를 나타낼 수 있다. 일 실시예에서, 펼침 상태는 열린 상태, 오픈 상태, 또는 플랫(또는 평평한) 상태를 의미할 수 있다. 일 실시예에서, 펼침 상태는 전자 장치가 완전히 펼쳐진 상태 를 의미할 수 있다. 예를 들어, 펼침 상태는 제1 하우징과 제2 하우징 간의 각도가 약 180도를 이루는 것으로, 제1 하우징의 제1 면과 제2 하우징의 제2 면이 실질적으로 동일한 방향을 향하도록 배치되는 상태일 수 있다. 일 실시예에 따르면, 프로세서는 센서 회로(예: 도 6의 센서 회로)(예: 상태 감지 센서)를 통해 전자 장치의 접힘(또는 펼침) 각도를 측정할 수 있다. 일 실시예에 따르면, 프로세서는 센서 회로에 의해 측정되는 센서 데이터(예: 접힘(또는 펼침) 각도)에 기반하여 전자 장치가 지정된 상태(예: 펼침 상 태)에 있는지 여부를 판단할 수 있다. 동작 1303에서, 프로세서는 전자 장치가 지정된 상태가 아닌 것을 판단(예: 제2 상태인 것을 판단)하 는 것에 기반하여(예: 동작 1303의 ‘아니오’), 동작 1305에서, 일반 촬영 모드에서 활성화된 카메라(예: 제1 카메라 또는 제2 카메라)에 기반한 영상 촬영 동작을 처리하는 동작을 수행할 수 있다. 일 실시예에 따라, 프로세서는 제2 상태를 판단하는 경우 촬영 모드를 일반 촬영 모드인 것으로 결정하고, 일반 촬영 모드에서의 영상 촬영을 지원하도록 동작할 수 있다. 동작 1303에서, 프로세서는 전자 장치가 지정된 상태인 것을 판단(예: 제1 상태인 것을 판단)하는 것 에 기반하여(예: 동작 1303의 ‘예’), 동작 1307에서, 제1 카메라로부터 제1 영상을 획득하고, 제2 카메 라로부터 제2 영상을 획득하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 촬영 모드 진입 시에 전자 장치의 제1 상태(예: 펼침 상태)를 감지하는 것에 기반하여 제1 카메라와 제2 카메라 를 활성화(예: 턴-온)할 수 있다. 일 실시예에 따르면, 프로세서는 활성화된 제1 카메라와 제2 카메라 각각으로부터 영상(예: 제1 영상 및 제2 영상)을 획득(또는 수신)할 수 있다. 동작 1309에서, 프로세서는 제1 영상과 제2 영상에 기반하여 지정된 식별 정보를 판단하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라로부터 획득되는 제1 영상과 제2 카메라로 부터 획득되는 제2 영상 각각에 기반하여 영상 분석(예: 객체 인식 및/또는 얼굴 인식)을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 분석의 결과에 기반하여 지정된 식별 정보를 검출할 수 있다. 일 실시 예에서, 지정된 식별 정보는 지정된 촬영 모드의 실행 여부를 판단하기 위한 미리 지정된 영상 객체를 포함할 수 있다. 일 실시예에서, 지정된 영상 객체는, 지정된 얼굴 객체 또는 지정된 식별자 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라의 제1 영상과 제2 카메라의 제2 영상을 비교하고, 제1 카메라의 제1 영상과 제2 카메라의 제2 영상으로부터 지정된 얼굴 객체를 식별하도록 동작할 수 있다. 일 실시예에 따르면, 프로세서는 제1 카메라의 제1 영상 또는 제2 카메라의 제 2 영상으로부터 지정된 식별자를 식별하도록 동작할 수 있다. 동작 1311에서, 프로세서는 지정된 식별 정보가 검출되는지 판단하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 제1 영상 및/또는 제2 영상에 적어도 기반하여 지정된 식별 정보(예: 지정된 얼굴 객 체 또는 지정된 식별자)가 검출되는지 여부를 판단할 수 있다. 동작 1311에서, 프로세서는 지정된 식별 정보가 검출되는 것에 기반하여(예: 동작 1311의 ‘예’), 동작 1313에서, 지정된 촬영 모드에 기반한 동작을 결정하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서 는 전자 장치가 펼침 상태이고, 적어도 하나의 영상으로부터 지정된 식별 정보를 검출하는 경우 촬영 모드를 지정된 촬영 모드인 것으로 결정할 수 있다. 동작 1315에서, 프로세서는 지정된 촬영 모드에 기반한 영상 촬영 동작을 처리하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드에서 동작하는 지정된 카메라(예: 제1 카메라 또는 제2 카메라) 및 대상 디스플레이를 결정하고, 지정된 카메라 및 대상 디스플레이에 기반하여 지정된 촬영 모드에서 반사체에 투영된 그래픽 요소를 포함하는 영상 촬영을 지원하도록 동작할 수 있다.동작 1311에서, 프로세서는 지정된 식별 정보가 검출되지 않는 것에 기반하여(예: 동작 1311의 ‘아니오’), 동작 1317에서, 지정된 촬영 모드를 실행하기 위한 가이드를 제공하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 펼침 상태에서 동작하는 것에 기반하여 제1 디스플레이를 통해 지정된 촬영 모드로 동작할 지 또는 일반 촬영 모드로 동작할 지에 대한 선택 가이드를 제공할 수 있다. 일 실시예에 따르면, 사용자는 선택 가이드에 기반하여 지정된 촬영 모드 또는 일반 촬영 모드를 선택할 수 있다. 동작 1319에서, 프로세서는 사용자와 상호작용에 기반하여 지정된 촬영 모드 또는 일반 촬영 모드를 실행 하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 선택 가이드를 통해 수신되는 사용자 입력 에 기반하여 대응하는 촬영 모드(예: 지정된 촬영 모드 또는 일반 촬영 모드)를 실행할 수 있다. 동작 1321에서, 프로세서는 실행하는 촬영 모드에 기반한 영상 촬영 동작을 처리하는 동작을 수행할 수 있 다. 일 실시예에 따르면, 프로세서는 지정된 촬영 모드에서, 지정된 카메라 및 대상 디스플레이에 기반하 여 반사체에 투영된 그래픽 요소를 포함하는 영상 촬영을 지원하도록 동작할 수 있다. 일 실시예에 따르면, 프 로세서는 일반 촬영 모드에서, 활성화된 카메라 및 활성화된 디스플레이에 기반하여 일반적인 영상 촬영을 지원하도록 동작할 수 있다. 일 실시예에 따라, 동작 1317, 동작 1319 및/또는 동작 1321은 옵셔널(optional)적인 동작일 수 있다. 예를 들 어, 동작 1317, 동작 1319 및/또는 동작 1321은 전자 장치의 설정에 기반하여 적어도 하나의 동작을 선택 적으로 수행하거나, 수행하지 않을 수 있다. 예를 들어, 프로세서는 지정된 식별 정보가 검출되지 않는 경 우, 일반 촬영 모드를 결정하고, 일반 촬영 모드에서 영상 촬영을 지원하도록 동작할 수 있다. 도 14는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 14는 일 실시예에 따른 전자 장치에서, 영상 촬영(예: 도 5의 반사체에 기반한 거울 샷 촬영)을 지원하는 동작의 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 방법은, 예를 들어, 도 14에 도시된 흐 름도에 따라 수행될 수 있다. 도 14에 도시된 흐름도는 전자 장치의 동작의 일 실시예에 따른 흐름도에 불 과하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 1401 내지 동작 1409는 전자 장치의 적어도 하나의 프로세서(예: 도 1 또는 도 6의 프로세서)에서 수 행될 수 있다. 일 실시예에 따르면, 도 14에서 설명되는 동작은, 예를 들어, 도 7 내지 도 13에서 설명된 동작들에 결합하여 휴리스틱하게 수행되거나, 설명된 동작의 적어도 일부 동작을 대체하고 적어도 일부 다른 동작에 결합하여 휴리 스틱하게 수행되거나, 설명된 동작들의 적어도 일부 동작의 상세 동작으로 휴리스틱하게 수행될 수 있다. 일 실시예에 따르면, 전자 장치는 동작 시에 실행되는 어느 하나의 카메라(예: 전면 카메라)에 기반하여 지정된 촬영 모드를 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 동작 시에 제1 카메라(예: 전면 카 메라)와 제2 카메라(예: 후면 카메라)에 기반하여 지정된 촬영 모드를 수행할 수 있다. 일 실시예에 따라, 도 14에서는 제1 카메라와 제2 카메라와 같이 복수의 카메라들에 기반하여 지정된 촬영 모드를 수행하는 동작의 예 를 나타낼 수 있다. 도 14에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법은, 제1 카메라와 제2 카메라 중 지정된 촬영 모드에서 동작하는 지정된 카메라를 결정하는 동작, 지정된 카메라 외의 다 른 카메라를 턴-오프하는 동작, 상황 인지에 기반하여 그래픽 요소를 생성하는 동작, 지정된 카메 라와 동일 면에 위치한 디스플레이를 통해 그래픽 요소를 표시하는 동작, 및 반대 면의 디스플레이를 통 해 지정된 카메라로부터 획득된 영상의 프리뷰를 표시하는 동작을 포함할 수 있다. 도 14를 참조하면, 동작 1401에서, 전자 장치의 프로세서는 제1 카메라와 제2 카메라 중 지정된 촬영 모드에서 동작하는 지정된 카메라를 결정하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세 서는 지정된 카메라를 결정하기 위한 지정된 스키마(또는 알고리즘, 모델, 네트워크 또는 함수)에 기반하 여 제1 카메라 또는 제2 카메라 중 어느 하나의 카메라를 지정된 촬영 모드에서 동작하는 지정된 카 메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 영상 분석에 기반하여, 피사체와의 거리, 얼굴 객 체의 크기, 얼굴 객체의 인식 여부, 및/또는 지정된 식별자의 인식 여부에 적어도 기반하여 지정된 카메라를 결 정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 및 제2 카메라의 영상으로부터 유사한 얼굴 객체(예: 사용자의 얼굴 객체)가 인식되는 경우, 각 얼굴 객체와의 거리 정보에 기반하여 지정된 카메라를 판단 할 수 있다. 예를 들어, 프로세서는 제1 카메라의 영상으로부터 추출된 제1 얼굴 객체와의 제1 거리 를 판단(예: 추정)하고, 제2 카메라의 영상으로부터 추출된 제2 얼굴 객체와의 제2 거리를 판단(예: 추 정)할 수 있다. 일 실시예에 따라, 프로세서는 제1 거리와 제2 거리 중 상대적으로 긴 거리의 얼굴 객체 (예: 전자 장치와 상대적으로 멀리 있는 얼굴 객체)가 포함된 영상을 획득한 카메라를 지정된 카메라로 결 정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 및 제2 카메라의 영상으로부터 유사한 얼굴 객체(예: 사용자의 얼굴 객체)가 인식되는 경우, 각 얼굴 객체의 크기 정보에 기반하여 지정된 카메라를 판단할 수 있다. 예를 들어, 프로세서는 제1 카메라의 영상으로부터 추출된 제1 얼굴 객체의 제1 크기와 제2 카메라의 영상으로부터 추출된 제2 얼굴 객체의 제2 크기를 비교할 수 있다. 일 실시예에 따라, 프로세서 는 제1 크기와 제2 크기 중 상대적으로 작은 크기의 얼굴 객체(예: 전자 장치와 상대적으로 멀리 있 는 얼굴 객체)가 포함된 영상을 획득한 카메라를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 또는 제2 카메라의 영상 중 어느 하나의 영상 으로부터 얼굴 객체(예: 사용자의 얼굴 객체)가 인식되는 경우, 얼굴 객체가 포함되지 않은 영상을 획득한 카메 라(예: 사용자를 향하고 있는 카메라와 반대 면에 위치한 카메라)를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 제1 카메라의 영상 또는 제2 카메라의 영상 중 어느 하나의 영상 으로부터 지정된 식별자가 인식되는 경우, 지정된 식별자를 포함하는 영상을 획득한 카메라(예: 도 5의 반사체 에 투영된 지정된 식별자를 촬영하는 카메라)를 지정된 카메라로 결정할 수 있다. 일 실시예에 따라, 프로세서는 지정된 카메라를 결정할 시, 지정된 카메라와 동일 면에 위치한 디스플레이 를 지정된 그래픽 요소를 표시하기 위한 대상 디스플레이로 결정하는 동작을 수행할 수도 있다. 동작 1403에서, 프로세서는 지정된 카메라 외의 다른 카메라를 턴-오프하는 동작을 수행할 수 있다. 일 실 시예에 따르면, 프로세서는 지정된 촬영 모드에서 동작하는 지정된 카메라를 결정하는 것에 기반하여 지정 된 카메라와 반대 면의 카메라는 비활성화(예: 턴-오프)할 수 있다. 예를 들어, 프로세서는 제2 카메라 를 지정된 카메라로 결정하는 것에 기반하여, 제2 카메라는 활성화 상태를 유지하고 제1 카메라(81 0)는 비활성화하도록 제어할 수 있다. 예를 들어, 프로세서는 제1 카메라를 지정된 카메라로 결정하 는 것에 기반하여, 제1 카메라는 활성화 상태를 유지하고 제2 카메라는 비활성화하도록 제어할 수 있 다. 동작 1405에서, 프로세서는 상황 인지에 기반하여 그래픽 요소를 생성하는 동작을 수행할 수 있다. 일 실 시예에 따르면, 프로세서는 촬영 모드가 지정된 촬영 모드로 동작하는 것에 기반하여 표시할 그래픽 요소 를 판단하기 위한 상황 인지를 수행할 수 있다. 일 실시예에 따르면, 프로세서는 상황 인지에 기반하여 사 용자의 현재 위치, 사용자의 활동, 및/또는 인식 객체에 대응하는 상황을 판단할 수 있다. 일 실시예에 따르면, 프로세서는 판단하는 상황에 대응하는 그래픽 요소를 생성할 수 있다. 일 실시예에 따라, 상황 인지에 기 반하여 대응하는 그래픽 요소를 생성하여 제공하는 것과 관련하여 후술하는 도면들을 참조하여 설명된다. 동작 1407에서, 프로세서는 지정된 카메라와 동일 면에 위치한 디스플레이(예: 대상 디스플레이)를 통해 그래픽 요소를 표시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 카메라와 동일 면에 위치한 디스플레이(예: 대상 디스플레이)가 비활성화(또는 턴-오프) 상태인 경우, 대상 디스플레이를 활성 화(또는 턴-온)하는 동작을 더 수행할 수 있다. 일 실시예에 따르면, 프로세서는 생성된 그래픽 요소를 표 시하도록 대상 디스플레이를 제어할 수 있다. 일 실시예에 따라, 프로세서는 제2 디스플레이를 그래 픽 요소를 표시하기 위한 대상 디스플레이로 결정하는 것에 기반하여, 제2 디스플레이를 통해 생성된 그래 픽 요소를 표시하도록 동작할 수 있다. 일 실시예에 따라, 프로세서는 제1 디스플레이를 그래픽 요소 를 표시하기 위한 대상 디스플레이로 결정하는 것에 기반하여, 제1 디스플레이를 통해 생성된 그래픽 요소 를 표시하도록 동작할 수 있다. 동작 1409에서, 프로세서는 반대 면의 디스플레이를 통해 지정된 카메라로부터 획득된 영상의 프리뷰를 표 시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 대상 디스플레이(또는 지정된 카메라)와 반대 면에 위치한 디스플레이를 판단할 수 있다. 일 실시예에 따르면, 프로세서는 반대 면에 위치한 디스 플레이가 비활성화(또는 턴-오프) 상태인 경우, 해당 디스플레이를 활성화(또는 턴-온)하는 동작을 더 수행할수 있다. 일 실시예에 따르면, 프로세서는 지정된 카메라로부터 획득하는 영상의 프리뷰를 표시하도록 해 당 디스플레이를 제어할 수 있다. 일 실시예에 따라, 프로세서는 제2 디스플레이를 대상 디스플레이 로 결정하는 것에 기반하여, 제2 디스플레이와 반대 면에 위치한 제1 디스플레이를 통해 지정된 카메 라로부터 획득하는 영상의 프리뷰를 표시하도록 동작할 수 있다. 일 실시예에 따라, 프로세서는 제1 디스 플레이를 대상 디스플레이로 결정하는 것에 기반하여, 제1 디스플레이와 반대 면에 위치한 제2 디스 플레이를 통해 지정된 카메라로부터 획득하는 영상의 프리뷰를 표시하도록 동작할 수 있다. 도 15a, 도 15b, 도 15c, 도 15d, 및 도 15e는 본 개시의 일 실시예에 따른 전자 장치에서 그래픽 요소와 프리 뷰를 제공하는 동작 예를 도시하는 도면들이다. 일 실시예에 따라, 도 15a, 도 15b, 도 15c, 및 도 15d는 펼침 상태의 전자 장치의 후면의 예를 나타낼 수 있다. 일 실시예에 따라, 도 15e는 펼침 상태의 전자 장치의 전면의 예를 나타낼 수 있다. 일 실시예에 따라, 도 15a, 도 15b, 도 15c, 및 도 15d에 예시한 바와 같이, 전자 장치는 펼침 상태에서 후면(예: 제2 면)에 배치되는 제2 카메라와 제2 디스플레이를 포함할 수 있다. 일 실시예에 따라, 도 15e에 예시한 바와 같이, 전자 장치는 펼침 상태에서 전면(예: 제1 면)에 배치되는 제1 카메라와 제1 디스플레이를 포함할 수 있다. 일 실시예에 따라, 제1 카메라와 제2 카메라는 전자 장치의 펼침 상태에서 서로 반대되는 면에 배치될 수 있다. 일 실시예에 따라, 제1 디스플레이와 제2 디스플레이 는 전자 장치의 펼침 상태에서 서로 반대되는 면에 배치될 수 있다. 일 실시예에 따라, 제1 카메라 는 제1 디스플레이와 동일 면(예: 전면) 상에 배치되고, 제2 카메라는 제2 디스플레이와 동일 면(예: 후면)에 배치될 수 있다. 일 실시예에 따라, 도 15a, 도 15b, 도 15c, 도 15d, 및 도 15e에서는 제2 카메라가 지정된 촬영 모드에서 지정된 카메라로 동작하고, 제2 디스플레이가 그래픽 요소를 표시하는 대상 디스플레이로 동작하고, 제1 디스플레이가 영상의 프리뷰를 표시하는 디스플레이로 동작하는 경우의 예를 나타낼 수 있다. 예를 들어, 전자 장치의 전면의 제1 카메라와 제1 디스플레이가 사용자를 향하고, 전자 장치의 후면의 제2 카메라와 제2 디스플레이가 반사체(예: 도 5의 반사체)를 향하는 경우를 가정할 수 있다. 도 15a, 도 15b, 도 15c, 및 도 15d에 예시한 바와 같이, 도 15a, 도 15b, 도 15c, 및 도 15d는 지정된 촬영 모드에서 제공 가능한 다양한 그래픽 요소가 제2 디스플레이를 통해 표시되는 다양한 예를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 제2 디스플레이를 통해 그래픽 요소를 제공할 때, 그래픽 요 소를 좌우 반전(또는 좌우 대칭)하여 제공할 수 있다. 예를 들어, 전자 장치는 그래픽 요소가 반사체를 통 하여 촬영될 때, 촬영되는 그래픽 요소가 제1 디스플레이에서 좌우 반전 없이 정상적으로 표시되도록, 제2 디스플레이에 표시되는 그래픽 요소를 Y축을 기준으로 플립(flip)된 형태로 제공할 수도 있다. 이의 예가 도 15d에 도시된다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드에 기반하여 상황 인지를 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 상황 인지에 기반하여 사용자의 현재 위치, 사용자의 활동, 및/또는 인식 객체에 대 응하는 상황을 판단할 수 있다. 예를 들어, 전자 장치는 다양한 상황 인지 기술에 기반하여 인지된 상황 정보(예: 사용자의 상황-의도가 반영된 정보)에 기반하여 사용자 중심 컨텐츠(예: 그래픽 요소)를 제공함으로써, 사용자의 상황에 보다 적합한 정보를 제공할 수 있다. 예를 들어, 전자 장치는 상황 인지에 기반하여(예: 사용자의 상황-의도를 반영하여) 사용자에게 보다 맞춤형의 추천 컨텐츠(예: 사용자의 상황-의도 를 반영한 추천 그래픽 요소)를 제공할 수 있다. 일 실시예에 따르면, 전자 장치는 상황 인지를 위한 인지 센서 회로(미도시)를 포함할 수 있다. 일 실시예 에서, 전자 장치는 인지 센서 회로를 이용하여 사용자의 전자 장치 사용과 관련된 다양한 상황 인지 를 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 사용자 중심의 지능화된 서비스를 위해, 인지 센서 회로를 이용하여, 사용자가 전자 장치를 통해 컨텐츠를 이용하는 다양한 상황을 검출할 수 있다. 일 실시 예에 따르면, 인지 센서 회로는 사용자의 상황 검출을 위한 적어도 하나의 센서 회로(예: 도 1의 센서 모듈 또는 도 6의 센서 회로), 적어도 하나의 카메라(예: 도 1의 카메라 모듈 또는 도 6의 카메라 ), 터치 센서, 위치 추적 회로(예: GNSS 모듈), 및/또는 시간 산출 회로(예: 타이머)와 같은 다양한 구성 요소를 포함할 수 있다. 일 실시예에 따르면, 인지 센서 회로는 나열된 구성 요소에 제한하지 않으며, 사용자의 상황 검출을 위한 상황 인지 기술에 이용될 수 있는 다양한 구성 요소가 포함될 수 있다. 일 실시예에서, 전자 장치는, 상황 인지에 기반한 다양한 센싱 데이터에 기반하여 상황 정보(예: 상황 인 지 결과)를 생성할 수 있다. 일 실시예에서, 상황 정보(또는 상황 데이터)는, 인지 센서 회로로부터 획득하는 다양한 센싱 데이터(예: 가속 도 센싱 데이터, 자이로 센싱 데이터, 기압 센싱 데이터, 터치 센싱 데이터, 위치 센싱 데이터, 시간 센싱 데이 터, 어플리케이션 동작 센싱 데이터, 컨텐츠 센싱 데이터, 카메라 영상 데이터)를 포함할 수 있다. 일 실시예에서, 상황 정보(또는 상황 데이터)는 TPOAM 정보를 포함할 수 있다. 예를 들어, 상황 정보는 시간(T, time), 장소(P, place), 상황(또는 빈도)(O, occasion), 어플리케이션(A, application), 및 모멘텀(M, momentum) 중 적어도 하나의 요소(또는 정보)를 포함할 수 있다. 일 실시예에서, TPOAM은, 예를 들어, 전자 장 치에 대한 사용자의 사용성이 발생하는 것에 따라 로그(log)가 생성된 시간(T), 장소(P), 빈도(O), 어플리 케이션(A), 및/또는 모멘텀(M)을 의미할 수 있다. 일 실시예에서, 어플리케이션(A)은 사용자가 사용한 어플리케 이션을 의미할 수 있다. 일 실시예에서, 모멘텀(M)은 사용자가 최근 특정 컨텐츠-TPOA(contents-TPOA)에 대해서 증가하는지 감소하는지를 정규화하여 지수화 한 값을 나타낼 수 있다. 일 실시예에 따라, 상황 정보의 적어도 일부는 전자 장치와 통신 연결된 외부 장치로부터 획득할 수도 있다. 일 실시예에서, 외부 장치는 링 (ring) 장치(예: 스마트 링), 워치 장치, 글래스 장치, 및/또는 이어버드 장치와 같은 웨어러블 장치와 다른 전 자 장치(예: 스마트 폰)를 포함할 수 있다. 일 실시예에서, 상황 정보(또는 상황 데이터)는, 전자 장치와 사용자 사이의 상호작용으로 사용자의 학습 에 기반하여 획득하는 다양한 학습 데이터(또는 컨텐츠(예: 그래픽 요소) 추론 데이터)를 포함할 수 있다. 일 실시예에서, 상황 정보는, 사용자의 사용성에 따른 상황 인지에 대응하는 최종 추천 컨텐츠(예: 그래픽 요소)를 추론하기 위한 다양한 스키마(schema)(또는 알고리즘 또는 함수(function))를 통해 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 상황 정보(예: 상황 인지 결과)에 대응하는 그래픽 요소(또는 컨텐츠)를 생성할 수 있다. 일 실시예에 따르면, 그래픽 요소는 상황 정보에 따른 적어도 하나의 데이터를 이용하여 그래 픽적으로 생성될 수 있다. 일 실시예에 따르면, 전자 장치는 생성된 그래픽 요소를 제2 디스플레이를 통해 표시하여 사용자에게 제공할 수 있다. 이의 예가 도 15a, 도 15b, 도 15c, 및 도 15d에 도시된다. 일 실시 예에 따르면, 전자 장치는 제2 디스플레이를 통해 그래픽 요소를 제공할 때, 그래픽 요소를 좌우 반 전(또는 좌우 대칭)하여 제공할 수 있다. 예를 들어, 전자 장치는 그래픽 요소가 반사체를 통하여 촬영될 때, 촬영되는 그래픽 요소가 제1 디스플레이에서 좌우 반전 없이 정상적으로 표시되도록, 제2 디스플레이 에 표시하는 그래픽 요소를 Y축을 기준으로 플립된 형태로 제공할 수 있다. 이의 예가 도 15d에 도시된다. 일 실시예에 따라, 도 15a에 예시한 바와 같이, 전자 장치는 상황 인지 결과에 따른 현재의 위치 정보에 기반하여 사용자의 현재 위치(예: 영상 촬영 위치)에 관련된 그래픽 요소(예: 지도 어플리케이션을 통해 제공되는 맵 데이터(map data)를 포함하는 컨텐츠)를 생성하고, 그래픽 요소(예: 지도 컨텐츠 화면)를 제 2 디스플레이를 통해 표시할 수 있다. 일 실시예에 따라, 도 15b에 예시한 바와 같이, 전자 장치는 상황 인지 결과에 따른 사용자의 활동 정보 (예: 운동 정보 또는 헬스 정보)에 기반하여 사용자 활동에 관련된 그래픽 요소(예: 헬스 어플리케이션 및/또는 통신 연결된 외부 장치를 통해 제공되는 운동 데이터를 포함하는 컨텐츠)를 생성하고, 그래픽 요소 (예: 운동 컨텐츠 화면)를 제2 디스플레이를 통해 표시할 수 있다. 일 실시예에 따라, 도 15c에 예시한 바와 같이, 전자 장치는 상황 인지 결과에 따라 전자 장치가 지 정된 카메라(예: 제2 카메라)를 이용하여 동영상을 촬영 중인 것을 인지할 수 있다. 일 실시예에 따라, 전 자 장치는 객체 인식(예: 얼굴 인식)에 기반하여 인식 객체에 관련된 그래픽 요소(예: 어카운트 (account) 어플리케이션을 통해 제공되는 사용자 데이터(예: 연락처 정보)를 포함하는 컨텐츠)를 움직이는 컨텐 츠(예: 동영상 컨텐츠 또는 GIF 컨텐츠)로 생성하고, 그래픽 요소를 제2 디스플레이를 통해 표시할 수 있다. 일 실시예에서, 움직이는 컨텐츠에 관련된 그래픽 요소는 사람, 동물, 식물, 및/또는 사물 인식에 대응하 는 객체에 관련된 적어도 하나의 데이터(예: 사용자 데이터, 사진 데이터, 패션 데이터, 장소 데이터, 및/또는 날짜 데이터)를 이용하여 관련 그래픽적인 요소로 다양하게 제공될 수 있다. 일 실시예에서, 움직이는 컨텐츠는 전자 장치의 내부(예: 도1 또는 도 6의 메모리)에 미리 저장된 컨텐츠를 포함할 수 있다. 일 실시예 에서, 움직이는 컨텐츠는 지정된 촬영 모드 동작 시에 상황 인지에 기반하여 제작되는 컨텐츠(예: 흐르는 글 자)를 포함할 수 있다. 일 실시예에 따라, 전자 장치는 움직이는 컨텐츠로 그래픽 요소를 생성할 때, 동영 상 촬영의 형태가 정적인지 또는 동적인지에 기반하여 그래픽 요소를 생성할 수 있다. 예를 들어, 전자 장치는 동영상 촬영 형태를 판단하고, 동영상 촬영 형태가 정적인 촬영인 경우 텍스트 위주의 움직이는 컨텐츠 (예: 흐르는 글자)를 생성하도록 동작할 수 있다. 예를 들어, 전자 장치는 동영상 촬영 형태를 판단하고, 동영상 촬영 형태가 동적인 촬영인 경우 모션 그래픽 위주의 움직이는 컨텐츠(예: GIF 이미지)를 생성하도록 동 작할 수 있다. 일 실시예에 따라, 도 15d에 예시한 바와 같이, 전자 장치는 상황 인지 결과에 따른 인식 객체(예: 얼굴 객체)에 관련된 사용자 데이터, 위치 정보에 관련된 장소 데이터, 및 날짜에 관련된 날짜 데이터에 기반하여 사 용자의 현재 상황에 관련된 그래픽 요소를 생성하고, 그래픽 요소를 제2 디스플레이를 통해 표시할 수 있다. 예를 들어, 전자 장치는 복합적인 상황 인지 결과에 기반하여 복합적인 데이터를 포함하 는 그래픽 요소를 생성할 수 있다. 일 실시예에 따르면, 그래픽 요소는 지정된 형식에 기반한 텍스트 및/또는 이미지 형태를 포함할 수 있다. 일 실시예에 따르면, 그래픽 요소는 생성형 AI(generative AI) 엔진에 의해 생성된 텍스트 및/또는 이미지를 포함할 수 있다. 예를 들어, 전자 장치는 생성형 AI 기반으로 컨텍스트를 자동 생성할 수 있다. 예를 들어, 전자 장치는 LLM(large language model)에 기반하여 상황에 맞는 가장 적절한 컨텍스트(예: 문 구 및/또는 이미지)를 생성할 수 있다. 예를 들어, 전자 장치는 다양하게 학습된 모델에 기반하여 상황을"}
{"patent_id": "10-2023-0113506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "요약하고, 자연스러운 문구를 생성할 수 있다. 일 실시예에 따르면, 전자 장치는 생성된 컨텍스트에 기반 하여 그래픽 요소를 생성할 수 있다. 일 실시예에서, 생성형 AI가 생성하는 그래픽 요소는 사전에 예측 가능하고 미리 정의된 문구나 이미지가 아니며, 여러 입력 파라미터(예: 사용자와 관련된 정보(예: 인물, 장소, 시간에 관련된 정보), 사진 관련 정 보)를 기반으로 생성되는 컨텐츠를 포함할 수 있다. 일 실시예에서, 생성되는 컨텐츠는 프롬프트 엔지니어링 (prompt engineering)으로 지정된 디스플레이(예: 커버 디스플레이)에 맞게 표시될 수 있도록 설정될 수 있다. 일 실시예에서, 생성형 AI 엔진은 전자 장치 내에 on-device AI로 포함된 엔진이거나, 외부 서버에서 제공 하는 AI 엔진을 포함할 수 있다. 일 실시예에서, 지정된 디스플레이(예: 커버 디스플레이)에 예측 불가능한 이 미지가 표시될 수 있기 때문에, 프롬프트 엔지니어링에 기반하여 표시할 수 있는 내용에 대한 가이드라인을 제 공할 수 있다. 예를 들어, 개인 정보(예: 전화번호, 위치)의 표시를 제외하거나, 부적절한 표현이나 사진을 필 터링하도록 학습하도록 하거나, 지정된 디스플레이(예: 커버 디스플레이 또는 메인 디스플레이)의 크기에 맞게 이미지를 배치하거나, 또는 색상에 어울리도록 이미지를 설정하는 것과 같은 가이드를 제공할 수 있다. 일 실시예에 따르면, 전자 장치는 그래픽 요소를 제2 디스플레이를 통해 표시할 때, 그래픽 요 소를 좌우 반전하여, 좌우가 반전된 그래픽 요소를 표시할 수 있다. 예를 들어, 전자 장치는 그래픽 요소가 반사체를 통하여 촬영될 때, 촬영되는 그래픽 요소가 제1 디스플레이에서 좌우 반전 없이 정상적으로 표시되도록, 그래픽 요소를 Y축을 기준으로 플립된 형태의 그래픽 요소로 제공할 수 있다. 일 실시예에 따라, 그래픽 요소는 전술한 예에 제한하지 않으며, 다양할 수 있다. 일 실시예에 따르면, 전자 장 치는 상황 인지 결과에 따른 객체 인식(예: 얼굴 인식 및/또는 복장(또는 패션 인식)에 기반하여 인식 객 체에 관련된 그래픽 요소(예: 어카운트(account) 어플리케이션을 통해 제공되는 사용자 데이터(예: 연락처 정보)를 포함하는 컨텐츠)를 생성하고, 그래픽 요소를 제2 디스플레이를 통해 표시할 수 있다. 일 실시예 에서, 인식 객체에 관련된 그래픽 요소는 사람, 동물, 식물, 및/또는 사물 인식에 대응하는 객체에 관련된 적어 도 하나의 데이터(예: 사용자 데이터, 사진 데이터, 패션 데이터, 장소 데이터, 및/또는 날짜 데이터)를 이용하 여 관련 그래픽적인 요소로 다양하게 제공될 수 있다. 일 실시예에서, 인식 객체에 관련된 데이터는 전자 장치 의 내부(예: 메모리에 저장된 데이터) 또는 외부 장치(예: 어카운트 기반 클라우드 또는 웹 서버)로 부터 획득하여 제공할 수 있다. 도 15e에 예시한 바와 같이, 도 15e는 지정된 촬영 모드에서 지정된 카메라(예: 제2 카메라)를 통해 획득 하는 영상의 프리뷰가 제1 디스플레이를 통해 표시되는 예를 나타낼 수 있다. 일 실시예에 따라, 프 리뷰는 제2 디스플레이에 그래픽 요소가 표시됨에 따라, 프리뷰에서 제1 디스플레이에 대응하는 영역을 통해 그래픽 요소에 대응하는 객체를 포함하여 표시될 수 있다. 예를 들어, 프리뷰 에서 제2 디스플레이의 영역에, 제2 디스플레이에 표시된 그래픽 요소에 대응하는 객체 가 표시될 수 있다. 예를 들어, 그래픽 요소에 대응하는 객체는, 반사체에 투영된 제2 디스플레이에 표시된 그래픽 요소에 대응하는 객체를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 프리뷰를 제공할 때, 프리뷰 상에서 그래픽 요소가 보다 선명하게 보이도록 그래픽 요소에 대응하는 객체에대해 보정 처리하여 제공할 수 있다. 일 실시예에 따르면, 전자 장치는 프리뷰를 제공할 때, 프리뷰 상에서 그래픽 요소가 보다 선명하게 보이도록 제2 디스플레이에 표시하는 그래픽 요소를 보정 처 리하여 제공할 수도 있다. 도 16a, 도 16b 및 도 16c는 본 개시의 일 실시예에 따른 전자 장치에서 그래픽 요소를 제공하는 동작 예를 도 시하는 도면들이다. 일 실시예에 따라, 도 16a, 도 16b 및 도 16c는 전자 장치에서 그래픽 요소를 표시하도록 지정되는 대상 디스플레이의 영역 구분에 기반하여 그래픽 요소를 제공하는 예를 나타낼 수 있다. 일 실시예에 따르면, 도 16a, 도 16b 및 도 16c에 예시한 바와 같이, 전자 장치는 그래픽 요소를 제공할 때, 대상 디스플레이에서, 영역 구분에 기반하여 복수의 그래픽 요소들을 제공할 수 있다. 일 실시예에 따르면, 전자 장치는 대상 디스플레이의 형태나 비율에 기반하여 다양하게 영역을 구분할 수 있고, 구분된 영역 별로 독립적인 그래픽 요소를 각각 제공할 수 있다. 일 실시예에 따라, 도 16a는 펼침 상태의 전자 장치(예: 세로 폴더블 형태의 전자 장치)에서, 전자 장치 의 전면의 제1 디스플레이가 그래픽 요소를 표시하기 위한 대상 디스플레이로 동작하는 예를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드로 동작 시에, 전면의 제1 디스플레이를 제1 영역과 제2 영역으로 구분하고, 제1 영역과 제2 영역 각각을 통해 서로 다른 시각 적 정보를 포함하는 제1 그래픽 요소 및 제2 그래픽 요소를 제공할 수 있다. 일 실시예에 따라, 도 16b는 펼침 상태의 전자 장치(예: 가로 폴더블 형태의 전자 장치)에서, 전자 장치 의 후면의 제2 디스플레이(예: 도 9c의 제2 디스플레이)가 그래픽 요소를 표시하기 위한 대상 디스플레이로 동작하는 예를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드로 동작 시에, 후면의 제2 디스플레이를 제3 영역과 제4 영역으로 구분하고, 제3 영역과 제4 영 역 각각을 통해 서로 다른 시각적 정보를 포함하는 제3 그래픽 요소 및 제4 그래픽 요소를 제공할 수 있 다. 일 실시예에 따라, 도 16c는 펼침 상태의 전자 장치(예: 가로 폴더블 형태의 전자 장치)에서, 전자 장치 의 전면의 제1 디스플레이가 그래픽 요소를 표시하기 위한 대상 디스플레이로 동작하는 예를 나타낼 수 있다. 일 실시예에 따르면, 전자 장치는 지정된 촬영 모드로 동작 시에, 전면의 제1 디스플레이를 제5 영역, 제6 영역 및 제7 영역으로 구분하고, 제5 영역, 제6 영역 및 제7 영 역 각각을 통해 서로 다른 시각적 정보를 포함하는 제5 그래픽 요소, 제6 그래픽 요소 및 제7 그래픽 요 소를 제공할 수 있다. 일 실시예에 따르면, 전자 장치는 구분되는 영역 별로 서로 다른 시각적 정보에 기반하여 그래픽 요소를 생성할 수 있다. 일 실시예에 따르면, 구분되는 영역 별 시각적 정보는 동일 속성 또는 다른 속성에 기반한 다 른 종류의 시각적 정보를 포함할 수 있다. 예를 들어, 전자 장치는 지정된 하나의 어플리케이션(예: 지도 어플리케이션)에 기반하여 구분된 영역 각각에 대응하는 서로 다른 시각적 정보(예: 맵 기반 위치를 나타내는 컨텐츠(예: 맵 컨텐츠) 및 위치에 대응하는 장소에 관련된 정보를 나타내는 컨텐츠(예: 장소 컨텐츠))를 생성하 고, 구분된 영역을 통해 독립적으로 표시하도록 대상 디스플레이를 제어할 수 있다. 일 실시예에 따르면, 전자 장치는 대상 디스플레이의 영역 구분에 기반하여 여러 가지 그래픽 요소를 동시 에 출력할 수 있다. 일 실시예에 따르면, 전자 장치는 영역 구분 시에, 사용자가 전자 장치를 파지하 는 파지 영역을 고려하여 대상 디스플레이의 영역을 구분할 수도 있다. 도 17은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 17은 일 실시예에 따른 전자 장치에서, 영상 촬영(예: 도 5의 반사체에 기반한 거울 샷 촬영)을 지원하는 동작의 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 방법은, 예를 들어, 도 17에 도시된 흐 름도에 따라 수행될 수 있다. 도 17에 도시된 흐름도는 전자 장치의 동작의 일 실시예에 따른 흐름도에 불 과하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 1701 내지 동작 1711은 전자 장치의 적어도 하나의 프로세서(예: 도 1 또는 도 6의 프로세서)에서 수행될 수 있다. 일 실시예에 따르면, 도 17에서 설명되는 동작은, 예를 들어, 도 7 내지 도 16에서 설명된 동작들에 결합하여 휴리스틱하게 수행되거나, 설명된 동작의 적어도 일부 동작을 대체하고 적어도 일부 다른 동작에 결합하여 휴리 스틱하게 수행되거나, 설명된 동작들의 적어도 일부 동작의 상세 동작으로 휴리스틱하게 수행될 수 있다. 도 17에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법은, 제1 디스플레이를 통해 프리뷰를 표시하고 제2 디스플레이를 통해 그래픽 요소를 표시하는 동작, 그래픽 요소를 분석 하는 동작, 그래픽 요소의 식별이 가능한지 판단하는 동작, 그래픽 요소의 식별이 가능한 것에 기 반하여 사용자 요청에 따른 해당 동작 수행을 처리하는 동작, 그래픽 요소의 식별이 가능하지 않는 것에 기반하여 그래픽 요소에 대해 지정된 기능을 처리하는 동작, 및 제1 디스플레이 및/또는 제2 디스플 레이를 통해 기능 처리 결과를 표시하는 동작을 포함할 수 있다. 도 17을 참조하면, 동작 1701에서, 전자 장치의 프로세서는 제1 디스플레이를 통해 프리뷰를 표 시하고 제2 디스플레이를 통해 그래픽 요소를 표시하는 동작을 수행할 수 있다. 예를 들어, 도 17의 예시 에서는 제2 카메라가 지정된 촬영 모드에서 지정된 카메라로 동작하고, 제2 디스플레이가 그래픽 요 소를 표시하는 대상 디스플레이로 동작하고, 제1 디스플레이가 영상의 프리뷰를 표시하는 디스플레이로 동 작하는 경우의 예를 나타낼 수 있다. 예를 들어, 전자 장치의 전면의 제1 카메라와 제1 디스플레이 가 사용자를 향하고, 전자 장치의 후면의 제2 카메라와 제2 디스플레이가 반사체(예: 도 5 의 반사체)를 향하는 경우를 가정할 수 있다. 동작 1703에서, 프로세서는 그래픽 요소를 분석하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세 서는 제1 디스플레이에 표시된 프리뷰에서 그래픽 요소에 대응하는 그래픽 객체(또는 영역)를 식별할 수 있다. 일 실시예에 따라, 프로세서는 식별된 그래픽 객체에 기반하여, 그래픽 객체가 시각적으로 식별 가능한 정도인지 여부를 판단하기 위한 이미지 분석을 수행할 수 있다. 일 실시예에 따라, 프로세서는 지 정된 적어도 하나의 조건(예: 그래픽 객체(또는 프리뷰에서 대상 디스플레이)의 크기, 그래픽 객체의 해상도 및 /또는 피사체와의 거리)을 식별하기 위한 이미지 분석을 수행할 수 있다. 예를 들어, 프로세서는 제1 디스 플레이의 프리뷰에서 그래픽 요소(예: 그래픽 요소에 대응하는 그래픽 객체 또는 대상 디스플레이)가 잘 보이지 않거나, 작거나, 및/또는 흐릿한 조건에 대응하는지 판단하고, 그 결과에 따라 그래픽 요소 및/또는 그 래픽 객체에 대한 후보정을 수행할 수 있다. 동작 1705에서, 프로세서는 그래픽 요소의 식별이 가능한지 판단하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 분석하는 결과에 기반하여 그래픽 요소에 대응하는 그래픽 객체가 시각적으로 식별 가 능한 정도의 상태인지 여부를 판단할 수 있다. 일 실시예에 따라, 프로세서는 프리뷰에서 표시될 제2 디스플레이에 대응하는 객체의 크기(또는 면적)가, 미리 정의된(predetermined) 기준 크기 이하일 경우, 그래픽 객체의 식별이 가능하지 않은 상태(예: 대상 객체가 지정된 크기보다 작아 식별이 어려운 경우)인 것으로 판단할 수 있다. 예를 들어, 프로세서는 이미지 인식(image recognition)으로 프리뷰에서 제2 디스플레이가 표시되는 영역을 추출(또는 정의)하고, 추출된 영역의 픽셀 사이즈(pixel size)가 미리 정의된 기준 픽셀 사이즈(예: 약 400x300) 이하인 경우, 그래픽 객체의 식별이 어려운 상태인 것으로 판단할 수 있다. 일 실시예에 따라, 프로세서는 지정된 촬영 모드에서 전자 장치와 피사체 사이의 추정된 거리와 미리 정의된 임계 값(threshold)에 기반하여 그래픽 요소가 식별 가능한 정도의 상태인지 판단할 수 있다. 예를 들어, 프로세서는 추정된 거리가 미리 정의된 임계 값보다 큰 경우(예: 반사체와 전자 장치 간의 거 리가, 프리뷰를 통해 그래픽 요소를 식별 가능한 거리보다 먼 것으로 지정된 거리보다 큰 경우), 그래픽 객체의 식별이 가능하지 않은 상태(예: 피사체가 멀어 식별이 어려운 경우)인 것으로 판단할 수 있다. 일 실시예에 따라, 프로세서는 프리뷰에서 표시되는 제2 디스플레이에 대응하는 객체(예: 프리뷰에서 제2 디스플레이가 표시되는 영역(또는 객체))의 가로세로비(aspect ratio)(예: 2차원 모형)에서 긴 축과 짧은 축의 길이에 대한 비율)가 제2 디스플레이의 실제 가로세로비가 대체적으로 일치하지 않는 경우, 그 래픽 객체의 식별이 가능하지 않은 상태(예: 시야각이 확보되지 않아 식별이 어려운 경우)인 것으로 판단할 수 있다. 동작 1705에서, 프로세서는 그래픽 요소의 식별이 가능한 것에 기반하여(예: 동작 1705의 ‘예’), 동작 1707에서, 사용자 요청에 따른 해당 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력에 기반하여 영상을 촬영하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력에 기 반하여 촬영 옵션을 조정하는 동작을 수행할 수 있다. 일 실시예에 따라, 프로세서는 사용자 입력에 기반 하여 프리뷰 및/또는 그래픽 요소에 대한 관련 기능을 처리하는 동작을 수행할 수 있다. 동작 1705에서, 프로세서는 그래픽 요소의 식별이 가능하지 않는 것에 기반하여(예: 동작 1705의 ‘아니오 ’), 동작 1709에서, 그래픽 요소에 대해 지정된 기능을 처리하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 그래픽 요소의 식별이 가능하지 않은 경우 그래픽 요소를 지정된 기능에 관련된 보정을 수행하 고, 보정된 그래픽 요소를 제공할 수 있다. 일 실시예에 따라, 지정된 기능에 관련된 보정은, 프로세서에 의해 자동적으로 수행하거나, 및/또는 프로세서가 사용자 입력에 따라 적응적으로 수행할 수 있다. 일 실 시예에 따라, 지정된 기능에 관련된 보정은, 제1 디스플레이에서 프리뷰에서 카메라 기능에 기반하여 수행 하는 보정, 프리뷰에 표시된 그래픽 요소에 대응하는 객체에 기반하여 수행하는 보정, 및/또는 제2 디스플레이 에 표시하는 그래픽 요소의 자체에 대한 보정을 포함할 수 있다. 동작 1711에서, 프로세서는 제1 디스플레이 및/또는 제2 디스플레이를 통해 기능 처리 결과를 표시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 기능 처리 결과에 따라 프리뷰를 조정 한 보정 결과를 제1 디스플레이를 통해 표시하거나, 프리뷰 상에서 그래픽 요소에 기반한 보정 결과를 제1 디스플레이를 통해 표시하거나, 및/또는 그래픽 요소를 변경한 보정 결과를 제2 디스플레이를 통해 표시할 수 있다. 이의 예시에 대하여 도 18a, 도 18b, 도 18c, 및 도 18d를 참조하여 설명된다. 도 18a, 도 18b, 도 18c, 및 도 18d는 본 개시의 일 실시예에 따른 전자 장치에서 프리뷰를 제공하는 동작 예를 도시하는 도면들이다. 일 실시예에 따라, 도 18a, 도 18b, 도 18c, 및 도 18d는 펼침 상태의 전자 장치의 전면의 예를 나타낼 수 있다. 일 실시예에 따라, 도 18a, 도 18b, 도 18c, 및 도 18d에서는 제2 카메라가 지정된 촬영 모드에서 지정된 카메라로 동작하고, 제2 디스플레이가 그래픽 요소를 표시하는 대상 디스플레이로 동작하고, 제1 디스플레 이가 영상의 프리뷰를 표시하는 디스플레이로 동작하는 경우의 예를 나타낼 수 있다. 예를 들어, 전자 장 치의 전면의 제1 카메라와 제1 디스플레이가 사용자를 향하고, 전자 장치의 후면의 제2 카 메라와 제2 디스플레이가 반사체(예: 도 5의 반사체)를 향하는 경우를 가정할 수 있다. 도 18a에 예시한 바와 같이, 도 18a는 지정된 촬영 모드에서 지정된 카메라(예: 제2 카메라)를 통해 획득 하는 영상의 프리뷰를 제1 디스플레이 상에 표시하는 상태의 예를 나타낼 수 있다. 일 실시예에 따 르면, 전자 장치는 지정된 촬영 모드에 기반하여 제1 디스플레이를 통해 프리뷰를 표시하고 제 2 디스플레이를 통해 그래픽 요소를 표시하는 동작을 수행할 수 있다. 예를 들어, 도 18a의 예시에서는 제 2 카메라가 지정된 촬영 모드에서 지정된 카메라로 동작하고, 제2 디스플레이가 그래픽 요소를 표시 하는 대상 디스플레이로 동작하고, 제1 디스플레이가 영상의 프리뷰를 표시하는 디스플레이로 동작 하는 경우의 예를 나타낼 수 있다. 예를 들어, 전자 장치의 전면의 제1 카메라와 제1 디스플레이 가 사용자를 향하고, 전자 장치의 후면의 제2 카메라와 제2 디스플레이가 반사체(예: 도 5 의 반사체)를 향하는 경우를 가정할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 디스플레이에 표시된 프리뷰에서 그래픽 요소에 대응하 는 그래픽 객체(또는 영역)를 식별할 수 있다. 일 실시예에 따라, 전자 장치는 식별된 그래픽 객체 에 대한 이미지 분석에 기반하여, 그래픽 객체가 시각적으로 식별 가능한 정도인지 여부를 판단할 수 있다. 일 실시예에 따라, 전자 장치는 지정된 적어도 하나의 조건(예: 그래픽 객체(또는 프리뷰 에서 대상 디스플레이)의 크기, 그래픽 객체의 해상도 및/또는 피사체와의 거리)을 식별하기 위한 이미지 분석을 수행할 수 있다. 예를 들어, 프로세서는 제1 디스플레이의 프리뷰에서 그래픽 요소(예: 그래픽 요소에 대응하는 그래픽 객체)가 잘 보이지 않거나, 작거나, 및/또는 흐릿한 조건에 대 응하는지 판단하고, 그 결과에 따라 그래픽 요소 및/또는 그래픽 객체에 대한 후보정을 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 그래픽 객체가 시각적으로 식별 가능한 정도의 상태가 아닌 것으 로 판단하는 경우, 그래픽 요소 및/또는 그래픽 객체에 기반하여 후보정을 수행할 수 있다. 일 실시예에 따라, 전자 장치는 프리뷰에서 표시될 제2 디스플레이에 대응하는 객체의 크기(또는 면적)가, 미리 정의된 기준 크기 이하일 경우, 그래픽 객체가 식별이 가능하지 않은 상태(예: 대상 객체가 지정된 크기보다 작아 식별이 어려운 경우)인 것으로 판단할 수 있다. 일 실시예에 따라, 전자 장치는 지정된 촬영 모드에서 전자 장치와 피사체 사이의 추정된 거리와 미리 정의된 임계 값보다 큰 경우(예: 반사체와 전 자 장치 간의 거리가, 프리뷰를 통해 그래픽 요소를 식별 가능한 거리보다 먼 것으로 지정된 거리보 다 큰 경우), 그래픽 객체가 식별이 가능하지 않은 상태(예: 피사체가 멀어 식별이 어려운 경우)인 것으 로 판단할 수 있다. 일 실시예에 따라, 전자 장치는 프리뷰에서 표시되는 제2 디스플레이에 대 응하는 객체(예: 프리뷰에서 제2 디스플레이가 표시되는 영역(또는 객체))의 가로세로비(aspect ratio)(예: 2차원 모형)에서 긴 축과 짧은 축의 길이에 대한 비율)가 제2 디스플레이의 실제 가로세로비가 대체적으로 일치하지 않는 경우, 그래픽 객체의 식별이 가능하지 않은 상태(예: 시야각이 확보되지 않아 식별이 어려운 경우)인 것으로 판단할 수 있다. 일 실시예에 따르면, 전자 장치는 후보정에 따른 처리 결과를 제1 디스플레이 및/또는 제2 디스플레 이을 통해 표시할 수 있다. 이의 예가 도 18b, 도 18c 및 도 18d에 도시된다. 일 실시예에 따라, 도 18b, 도 18c 및 도 18d는 제1 디스플레이에 표시되는 프리뷰에서 그래픽 요소 에 대응하는 그래픽 객체에 기반하여 그래픽 요소를 강조하도록 관련 지정된 효과를 제공하는 예를 나타 낼 수 있다. 일 실시예에 따라, 도 18b에 예시한 바와 같이, 전자 장치는 프리뷰에서 제2 디스플레이에 표 시되는 그래픽 요소에 대응하는 특징 정보(예: 텍스트 및/또는 이미지)를 마커로 제1 디스플레이의 프리뷰 상에 증강하여 표시할 수 있다. 일 실시예에 따라, 도 18c에 예시한 바와 같이, 전자 장치는 자동으로 카메라 기능(예: 주밍 기능)으로 프 리뷰를 주밍(예: 확대)하여 그래픽 객체를 식별 가능한 거리로 주밍(예: 확대}하여 표시할 수 있다. 일 실시예에 따라, 도 18c에 예시한 바와 같이, 전자 장치는 시야각 확보를 통한 그래픽 객체(181 0)의 식별 용이성을 위해, 전자 장치의 방향을 전환하도록 가이드(또는 유도)하는 가이드 객체를 그 래픽 객체를 기준으로 표시할 수 있다. 예를 들어, 시야각(예: 약 -60도 ~ 약 +60도)을 확보하도록 가이 드 객체를 제1 디스플레이의 프리뷰 상에 표시할 수 있다. 일 실시예에 따라, 도 18d에 예시한 바와 같이, 전자 장치는 제2 디스플레이에 표시되는 그래픽 요소 를 제1 디스플레이의 프리뷰에서 식별 가능한 다른 형태로 변경하여 제공할 수 있다. 예를 들어, 전 자 장치는 제2 디스플레이에 출력하는 그래픽 요소를 다른 그래픽 요소로 변경하거나, 그래픽 요소의 적어도 일부(예: 특징 정보)를 강조(예: 확대)하여 제2 디스플레이를 통해 표시할 수 있다. 일 실시예에 따르면, 전자 장치는 제2 디스플레이에 표시하는 그래픽 요소의 변경에 기반하여, 변경된 그래픽 요 소에 대응하는 변경된(또는 가공된) 그래픽 객체를 프리뷰 상에 표시할 수 있다. 도 19는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 일 실시예에 따라, 도 19는 일 실시예에 따른 전자 장치에서, 영상 촬영(예: 도 5의 반사체에 기반한 거울 샷 촬영)을 지원하는 동작의 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 방법은, 예를 들어, 도 19에 도시된 흐 름도에 따라 수행될 수 있다. 도 19에 도시된 흐름도는 전자 장치의 동작의 일 실시예에 따른 흐름도에 불 과하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 1901 내지 동작 1921은 전자 장치의 적어도 하나의 프로세서(예: 도 1 또는 도 6의 프로세서)에서 수 행될 수 있다. 일 실시예에 따르면, 도 19에서 설명되는 동작은, 예를 들어, 도 7 내지 도 18에서 설명된 동작들에 결합하여 휴리스틱하게 수행되거나, 설명된 동작의 적어도 일부 동작을 대체하고 적어도 일부 다른 동작에 결합하여 휴리 스틱하게 수행되거나, 설명된 동작들의 적어도 일부 동작의 상세 동작으로 휴리스틱하게 수행될 수 있다. 도 19에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법은, 제1 디스플레이를 통해 프리뷰를 표시하고 제2 디스플레이를 통해 그래픽 요소를 표시하는 동작, 프리뷰에서 지정된 객체에 기반한 사용자 입력이 감지되는지 판단하는 동작, 지정된 객체에 기반한 사용자 입력이 감지되지 않는 경우 지정된 객체 외의 다른 영역에 기반한 사용자 입력이 감지되는지 판단하는 동작, 다른 영역에 기반한 사용자 입력이 감지되지 않는 경우 동작 1915로 진행하고 그 이하의 동작 수행을 처리하는 동작, 다른 영역에 기반한 사용자 입력이 감지되는 경우 사용자 입력에 기반하여 지정된 기능을 처리하는 동작, 기능 처리에 기반하여 제1 디스플레이의 프리뷰를 변경하여 표시하는 동작, 지정된 객체에 기반한 사용자입력이 감지되는 경우 사용자 입력에 기반하여 지정된 기능을 처리하는 동작, 기능 처리에 기반하여 제2 디스플레이의 그래픽 요소를 변경하여 표시하는 동작, 촬영 요청이 감지되는지 판단하는 동작 , 촬영 요청이 감지되지 않는 경우 사용자 요청에 따른 해당 동작 수행을 처리하는 동작, 촬영 요 청이 감지되는 경우 지정된 카메라를 통해 획득되는 영상을 촬영하는 동작, 및 촬영 영상에 그래픽 요소 에 기반한 메타데이터를 매핑하여 저장하는 동작을 포함할 수 있다. 도 19를 참조하면, 동작 1901에서, 전자 장치의 프로세서는 제1 디스플레이를 통해 프리뷰를 표 시하고 제2 디스플레이를 통해 그래픽 요소를 표시하는 동작을 수행할 수 있다. 예를 들어, 도 19의 예시 에서는 제2 카메라가 지정된 촬영 모드에서 지정된 카메라로 동작하고, 제2 디스플레이가 그래픽 요 소를 표시하는 대상 디스플레이로 동작하고, 제1 디스플레이가 영상의 프리뷰를 표시하는 디스플레이로 동 작하는 경우의 예를 나타낼 수 있다. 예를 들어, 전자 장치의 전면의 제1 카메라와 제1 디스플레이 가 사용자를 향하고, 전자 장치의 후면의 제2 카메라와 제2 디스플레이가 반사체(예: 도 5 의 반사체)를 향하는 경우를 가정할 수 있다. 동작 1903에서, 프로세서는 프리뷰에서 지정된 객체에 기반한 사용자 입력이 감지되는지 판단하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 제1 디스플레이를 통해 표시 중인 프리뷰에서 제2 디스플레이에 표시 중인 그래픽 요소에 대응하는 그래픽 객체(또는 제2 디스플레이에 대응하는 영 역)에 사용자 입력이 감지되는지 판단할 수 있다. 동작 1903에서, 프로세서는 지정된 객체에 기반한 사용자 입력이 감지되지 않는 경우(예: 동작 1903의 ‘ 아니오’), 동작 1905에서, 지정된 객체 외의 다른 영역에 기반한 사용자 입력이 감지되는지 판단하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 제1 디스플레이를 통해 표시 중인 프리뷰에서 제2 디스플레이에 표시 중인 그래픽 요소에 대응하는 그래픽 객체(또는 제2 디스플레이에 대응하는 영 역)가 아닌 다른 영역에 사용자 입력이 감지되는지 판단할 수 있다. 동작 1905에서, 프로세서는 다른 영역에 기반한 사용자 입력이 감지되지 않는 경우(예: 동작 1905의 ‘아 니오’), 동작 1915로 진행하고 동작 1915 이하의 동작을 수행할 수 있다. 동작 1905에서, 프로세서는 다른 영역에 기반한 사용자 입력이 감지되는 경우(예: 동작 1905의 ‘예’), 동작 1907에서, 사용자 입력에 기반하여 지정된 기능을 처리하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 다른 영역에 대한 사용자 입력에 기반하여 프리뷰에서의 카메라 기능(예: 주밍, 촬영 효과 설 정, 촬영 옵션(예: 사진 또는 동영상 촬영 모드 변경)에 관련된 동작을 제어할 수 있다. 동작 1909에서, 프로세서는 기능 처리에 기반하여 제1 디스플레이의 프리뷰를 변경하여 표시하는 동 작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력에 기반하여 처리된 기능에 관련된 결 과 화면을 제1 디스플레이의 프리뷰를 통해 표시할 수 있다. 동작 1903에서, 프로세서는 지정된 객체에 기반한 사용자 입력이 감지되는 경우(예: 동작 1903의 ‘예’), 동작 1911에서, 사용자 입력에 기반하여 지정된 기능을 처리하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 객체(예: 그래픽 객체 또는 제2 디스플레이에 대응하는 영역)에 대한 사용자 입력 에 기반하여 제2 디스플레이에 출력하는 그래픽 요소를 변경(또는 가공)하는 것에 관련된 동작을 제어할 수 있다. 예를 들어, 프로세서는 지정된 객체에 기반한 사용자 입력(예: 핀치 제스처)에 기반하여 제2 디 스플레이에 표시 중인 그래픽 요소에 대한 제1 기능(예: 주밍)을 제어할 수 있다. 예를 들어, 프로세서 는 사용자 입력(예: 플릭 제스처)에 기반하여 제2 디스플레이에 표시 중인 그래픽 요소에 대한 제2 기능(예: 다른 그래픽 요소로 전환)을 제어할 수 있다. 동작 1913에서, 프로세서는 기능 처리에 기반하여 제2 디스플레이의 그래픽 요소를 변경하여 표시하 는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 사용자 입력에 기반하여 처리된 기능에 관련 된 결과 화면을 제2 디스플레이를 통해 표시할 수 있다. 일 실시예에 따라, 제2 디스플레이에 표시되 는 그래픽 요소의 변경에 대응하여, 프리뷰에서 그래픽 요소에 대응하는 그래픽 객체도 변경되어 사용자에게 제 공될 수 있다. 동작 1915에서, 프로세서는 촬영 요청이 감지되는지 판단하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 프리뷰 상의 소프트웨어 버튼(예: 촬영 버튼 또는 플로팅 버튼), 전자 장치에 구 비된 하드웨어 버튼(또는 물리적인 버튼), 촬영 음성 명령, 또는 지정된 객체(예: 사용자 손바닥) 인식에 기반 하여 사용자의 촬영 요청을 감지할 수 있다. 동작 1915에서, 프로세서는 촬영 요청이 감지되지 않는 경우(예: 동작 1915의 ‘아니오’), 동작 1917에서, 사용자 요청에 따른 해당 동작 수행을 처리하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세 서는 사용자 입력에 기반하여 지정된 촬영 모드에서 영상 촬영 동작을 계속하거나, 영상 촬영을 종료할 수 있다. 동작 1915에서, 프로세서는 촬영 요청이 감지되는 경우(예: 동작 1915의 ‘예’), 동작 1919에서, 지정된 카메라를 통해 획득되는 영상을 촬영하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 지정된 촬영 모드에서 동작하도록 지정된 카메라로부터 영 상을 획득할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 카메라를 통해 획득되는 영상에 기반하여 영상 촬영을 수행할 수 있다. 동작 1921에서, 프로세서는 촬영 영상에 그래픽 요소에 기반한 메타데이터를 매핑하여 저장하는 동작을 수 행할 수 있다. 일 실시예에 따르면, 프로세서는 촬영 영상을 저장할 때, 촬영되는 영상에 그래픽 요소에 관련된 메타데이터를 매핑하여 저장하는 동작을 수행할 수 있다. 예를 들어, 프로세서는 지정된 카메라를 이용하여 촬영된 영상에서 추출된 그래픽 요소와 관련된 메타데이터(예: 태그, 링크, 어플리케이션 정보, 서비 스 정보)를 영상(예: 영상 내의 그래픽 요소)에 매핑하여 저장할 수 있다. 예를 들어, 프로세서는 헬스 데 이터(health data)에 기반한 그래픽 요소를 표시하는 경우, 촬영 영상에 그래픽 요소(예: 헬스 데이터)를 실행 할 수 있는 어플리케이션(예: 헬스 어플리케이션) 및/또는 해당 헬스 데이터의 위치로 바로 이동할 수 있는 메 타데이터를 매핑할 수 있다. 도 20은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 21 및 도 22는 본 개시의 일 실시예에 따른 전자 장치에서 그래픽 요소에 기반하여 기능을 실행하는 동작 예 를 도시하는 도면들이다. 일 실시예에 따라, 도 20은 일 실시예에 따른 전자 장치에서, 영상 촬영(예: 도 5의 반사체에 기반한 거울 샷 촬영)을 지원하는 동작의 예를 나타낼 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 방법은, 예를 들어, 도 20에 도시된 흐 름도에 따라 수행될 수 있다. 도 20에 도시된 흐름도는 전자 장치의 동작의 일 실시예에 따른 흐름도에 불 과하며, 적어도 일부 동작의 순서는 변경되거나 병렬적으로 수행되거나, 독립적인 동작으로 수행되거나, 또는 적어도 일부 다른 동작이 적어도 일부 동작에 보완적으로 수행될 수 있다. 본 개시의 일 실시예에 따르면, 동작 2001 내지 동작 2011은 전자 장치의 적어도 하나의 프로세서(예: 도 1 또는 도 6의 프로세서)에서 수 행될 수 있다. 일 실시예에 따르면, 도 20에서 설명되는 동작은, 예를 들어, 도 7 내지 도 19에서 설명된 동작들에 결합하여 휴리스틱하게 수행되거나, 설명된 동작의 적어도 일부 동작을 대체하고 적어도 일부 다른 동작에 결합하여 휴리 스틱하게 수행되거나, 설명된 동작들의 적어도 일부 동작의 상세 동작으로 휴리스틱하게 수행될 수 있다. 도 20에 도시한 바와 같이, 일 실시예에 따른 전자 장치가 수행하는 동작 방법은, 영상을 표시하는 동작 , 영상 내의 지정된 그래픽 요소에 기반한 사용자 입력을 감지하는 동작, 그래픽 요소에 대응하는 메타데이터를 호출하는 동작, 메타데이터에 대응하는 기능을 분석하는 동작, 기능을 실행하는 동작 , 및 기능 실행에 대응하는 컨텐츠를 표시하는 동작을 포함할 수 있다. 도 20을 참조하면, 동작 2001에서, 전자 장치의 프로세서는 영상을 표시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 지정된 어플리케이션(예: 갤러리 어플리케이션)의 실행 화면에서 영상을 선택하는 사용자 입력을 수신할 수 있다. 일 실시예에 따라, 프로세서는 사용자 입력에 기반하여 선택된 영상을 표시하도록 디스플레이를 제어할 수 있다. 이에 예가 도 21에 도시된다. 도 21에 예시한 바와 같이, 프로세서는 어플리케이션의 실행 화면(예: 갤러리 화면)에서 사용자에 의해 선 택된 영상의 영상 화면을, 동작 중인 제1 디스플레이에 표시할 수 있다. 일 실시예에 따라, 선택된 영상은 지정된 촬영 모드에서 촬영된 영상을 나타낼 수 있다. 일 실시예에 따라, 영상 화면은 대상 디스 플레이(예: 제1 디스플레이 또는 제2 디스플레이)를 통해 표시되고 지정된 카메라(예: 제1 카메라 또는 제2 카메라)를 통해 촬영된 그래픽 요소에 대응하는 그래픽 객체를 포함할 수 있다. 일 실시예에서, 그래픽 객체는 그래픽 요소에 대응하여 매핑된 메타데이터를 포함할 수 있다. 동작 2003에서, 프로세서는 영상 내의 지정된 그래픽 요소에 기반한 사용자 입력을 감지하는 동작을 수행 할 수 있다. 일 실시예에 따르면, 프로세서는 영상 화면에서 그래픽 객체(또는 그래픽 객체 에 대응하는 영역)에 기반하여 사용자 입력(예: 탭)을 수신할 수 있다. 동작 2005에서, 프로세서는 그래픽 요소에 대응하는 메타데이터를 호출하는 동작을 수행할 수 있다. 일 실 시예에 따르면, 프로세서는 그래픽 객체를 통해 사용자 입력을 감지하는 것에 기반하여, 영상의 그 래픽 객체에 매핑된 메타데이터를 메모리(예: 도 1 또는 도 6의 메모리)로부터 호출(또는 수집)할 수 있다. 동작 2007에서, 프로세서는 메타데이터에 대응하는 기능을 분석하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 호출된 메타데이터에 기반하여 실행 가능한 어플리케이션 정보, 서비스 정보, 태그, 및/또는 연결 링크(예: 데이터 위치) 중 적어도 하나를 판단할 수 있다. 동작 2009에서, 프로세서는 기능을 실행하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서 는 메타데이터에 기반하여 분석된 어플리케이션을 실행할 수 있다. 일 실시예에 따르면, 프로세서는 어플 리케이션 실행 시에 그래픽 요소에 관련된 데이터(예: 헬스 데이터, 맵 데이터, 사용자 데이터)의 위치를 식별 하고, 관련된 데이터의 위치로 바로 이동하는 기능을 제공할 수도 있다. 동작 2011에서, 프로세서는 기능 실행에 대응하는 컨텐츠를 표시하는 동작을 수행할 수 있다. 일 실시예에 따르면, 프로세서는 실행하는 어플리케이션에 기반하여 그래픽 객체에 대응하는 그래픽 요소를 포함 하는 컨텐츠를 표시하도록 디스플레이를 제어할 수 있다. 이의 예가 도 22에 도시된다. 도 22에 예시한 바와 같이, 프로세서는 그래픽 객체가 맵 데이터(map data)에 기반한 그래픽 요소에 대응하는 경우, 맵 데이터를 실행할 수 있는 어플리케이션(예: 지도 어플리케이션)을 실행할 수 있다. 일 실시 예에 따르면, 프로세서는 어플리케이션 실행 시에, 그래픽 요소에 대응하는 맵 데이터를 포함하는 컨텐츠 (예: 지도 화면)를 표시할 수 있다. 본 개시의 일 실시예에 따른 전자 장치에서 수행하는 동작 방법은, 어플리케이션 실행에 기반하여 제1 카 메라 및 제2 카메라로부터 제2 영상을 획득하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 제1 영상에 기반하여 지정된 촬영 모드를 판단하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 지정된 촬영 모드를 판단하는 것에 기반하여 디스플레이를 통해 그래픽 요소를 표시하 는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 영상 촬영을 위한 사용자 입력을 감지하는 것에 기반하여, 상기 지정된 촬영 모드에서 동작하도록 지정된 카메라를 통해 획득되는 제2 영상을 촬영하는 동 작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 제1 영상을 분석하는 동작, 상기 제1 영상의 분석에 기반하여 지 정된 식별 정보를 검출하는 동작, 및 상기 지정된 식별 정보를 검출하는 것에 기반하여 상기 지정된 촬영 모드 를 판단하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 지정된 식별 정보는, 상기 지정된 촬영 모드의 실행 여부를 판단하기 위한 미리 지정 된 영상 객체를 포함할 수 있다. 일 실시예에 따르면, 상기 지정된 영상 객체는, 지정된 얼굴 객체 또는 지정된 식별자 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 상기 제1 영상은 상기 제1 카메라의 영상과 상기 제2 카메라의 영상을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 제1 카메라의 영상과 상기 제2 카메라의 영상을 비교하는 동작을 포 함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 제1 카메라의 영상과 상기 제2 카메라의 영상으로 부터 상기 지정된 얼굴 객체를 식별하는 것에 기반하여 상기 지정된 촬영 모드를 판단하는 동작을 포함할 수 있 다. 일 실시예에 따르면, 상기 동작 방법은, 상기 그래픽 요소가 표시되는 상기 디스플레이와 동일 면에 위치한 상 기 지정된 카메라를 통해 획득되는 영상으로부터 상기 지정된 식별자를 식별하는 것에 기반하여 상기 지정된 촬 영 모드를 판단하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 지정된 촬영 모드를 판단하는 것에 기반하여, 상기 제1 카메라 및 상기 제2 카메라 중에서 상기 지정된 촬영 모드에서 동작할 상기 지정된 카메라를 결정하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 지정된 카메라를 이용하여 상기 제2 영상을 촬영하는 동작 을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 지정된 촬영 모드에서 동작할 상기 지정된 카메라를 결정하는 것 에 기반하여, 상기 지정된 카메라와 반대 면에 위치한 카메라를 비활성화하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 전자 장치는, 제1 디스플레이 및 제2 디스플레이를 포함할 수 있다. 일 실시예 에 따르면, 상기 동작 방법은, 상기 제1 디스플레이 및 상기 제2 디스플레이 중 상기 지정된 카메라와 동일 면 에 위치한 디스플레이에 기반하여 상기 그래픽 요소를 표시하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 지정된 카메라와 반대 면에 위치한 디스플레이에 기반하여 상기 지정된 카메라로부터 획득하는 영상의 프리뷰를 표시하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 프리뷰는 반사체 및 상기 반사체에 투영된 영상을 포함할 수 있다. 일 실시예에 따르 면, 상기 반사체에 투영된 영상은, 상기 지정된 카메라, 상기 지정된 카메라와 동일 면에 위치한 디스플레이, 및 상기 디스플레이에 표시된 그래픽 요소를 포함하는 상기 전자 장치에 대응하는 객체를 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 그래픽 요소가 지정된 조건에 포함되는지 분석하는 동작, 상기 그 래픽 요소가 지정된 조건에 포함되는 것에 기반하여 상기 결정된 카메라와 동일 면에 위치한 디스플레이에 표시 되는 상기 그래픽 요소에 관련된 지정된 기능을 처리하는 동작, 제1 디스플레이 및/또는 제2 디스플레이에 기반 하여 상기 기능 처리 결과를 표시하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 프리뷰에서 상기 그래픽 요소에 대응하는 객체에 기반하여 사용자 입력을 감지하는 동작, 상기 사용자 입력에 기반하여 상기 결정된 카메라와 동일 면에 위치한 디스플레이에 표 시되는 상기 그래픽 요소에 관련된 지정된 기능을 처리하는 동작, 제1 디스플레이 및/또는 제2 디스플레이에 기 반하여 상기 기능 처리 결과를 표시하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 지정된 촬영 모드를 판단하는 것에 기반하여 상황 인지를 수행하 는 동작, 상기 상황 인지에 기반하여 상기 디스플레이에 표시할 그래픽 요소를 생성하는 동작, 상기 생성된 그 래픽 요소를 표시하도록 상기 디스플레이를 제어하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 어플리케이션 실행을 감지하는 것에 기반하여 상기 제1 카메라 및 상기 제2 카메라를 활성화하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 어플리케이션 실행을 감지하는 것에 기반하여 상기 전자 장치가 지정된 상태인지 여부를 판단하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 전자 장치가 지정된 상태인 것을 판단하는 것에 기반하여, 상기 제1 카메라 및 상기 제2 카메라를 동시에 활성화하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 상기 촬영되는 제2 영상에 상기 그래픽 요소에 관련된 메타데이터를 매 핑하여 저장하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 동작 방법은, 지정된 영상을 표시하는 동작, 상기 영상 내의 지정된 그래픽 요소에 기반한 사용자 입력을 감지하는 동작, 상기 사용자 입력에 기반하여 상기 지정된 그래픽 요소에 대응하는 메타 데이터를 호출하는 동작, 상기 메타데이터에 대응하는 기능을 실행하는 동작, 상기 기능 실행에 대응하는 컨텐 츠를 상기 디스플레이를 통해 표시하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 제1 영상은, 상기 제1 카메라 및 상기 제2 카메라로부터 각각 획득되는 복수의 영상 들을 포함하고, 상기 디스플레이에 표시되지 않고 상기 적어도 하나의 프로세서에 의해 백그라운드에서 상기 촬 영 모드를 판단하는 데 사용되는 영상을 포함할 수 있다. 일 실시예에 따르면, 상기 제2 영상은, 상기 제1 카메라 및 상기 제2 카메라 중 상기 지정된 카메라로 동작하는 카메라로부터 획득되고, 상기 그래픽 요소가 표시되는 디스플레이와 다른 디스플레이를 통해 표시되는 영상을 포함할 수 있다. 일 실시예에 따르면, 상기 지정된 카메라는 상기 그래픽 요소를 표시하는 상기 디스플레이와 동일한 면에 위치 된 카메라를 포함할 수 있다. 본 명세서와 도면에 개시된 본 개시의 다양한 실시예들은 본 개시의 기술 내용을 쉽게 설명하고 본 개시의 이해 를 돕기 위해 특정 예를 제시한 것일 뿐이며, 본 개시의 범위를 한정하고자 하는 것은 아니다. 따라서 본 개시 의 범위는 여기에 개시된 실시예들 이외에도 본 개시의 기술적 사상을 바탕으로 도출되는 모든 변경 또는 변형 된 형태가 본 개시의 범위에 포함되는 것으로 해석되어야 한다. 본 문서에 개시된 다양한 실시예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치는, 예를 들면, 휴대용 통신 장치(예: 스마트폰), 컴퓨터 장치, 휴대용 멀티미디어 장치, 휴대용 의료 기기, 카메라, 웨 어러블 장치, 또는 가전 장치를 포함할 수 있다. 본 문서의 실시예에 따른 전자 장치는 전술한 기기들에 한정되 지 않는다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제1\", \"제2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없 이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으 로(예: 유선으로), 무선으로, 또는 제3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서의 다양한 실시예들에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일 실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형 태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어 (예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 전자 장치)의 프로세서(예: 프로세서 )는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것 을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형 태로 제공될 수 있다. 여기서, ‘비일시적’은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전 자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경 우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스 마트 폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체들을 포함할 수 있으며, 복수의 개체들 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요 소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱(heuristic)하게 실행 되거나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추 가될 수 있다.부호의 설명 101, 300: 전자 장치 120: 프로세서 130: 메모리 160: 디스플레이 모듈 (디스플레이) 661, 830: 제1 디스플레이 662, 840: 제2 디스플레이 180: 카메라 모듈 (카메라) 651, 810: 제1 카메라 652, 820: 제2 카메라 500: 반사체 550: 투영체도면 도면1 도면2a 도면2b 도면2c 도면3a 도면3b 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9a 도면9b 도면9c 도면10a 도면10b 도면10c 도면11 도면12 도면13 도면14 도면15a 도면15b 도면15c 도면15d 도면15e 도면16a 도면16b 도면16c 도면17 도면18a 도면18b 도면18c 도면18d 도면19 도면20 도면21 도면22"}
{"patent_id": "10-2023-0113506", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면 설명과 관련하여, 동일 또는 유사한 구성 요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다. 도 1은 다양한 실시예들에 따른 네트워크 환경 내의 전자 장치의 블록도이다. 도 2a는 본 개시의 일 실시예에 따른 펼침 상태를 도시한 전자 장치의 사시도이다. 도 2b는 본 개시의 일 실시예에 따른 펼침 상태에서 전자 장치의 전면을 도시한 평면도이다. 도 2c는 본 개시의 일 실시예에 따른 펼침 상태에서, 전자 장치의 후면을 도시한 평면도이다. 도 3a는 본 개시의 일 실시예에 따른 접힘 상태를 도시한 전자 장치의 사시도이다. 도 3b는 본 개시의 일 실시예에 따른 중간 상태를 도시한 전자 장치의 사시도이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 예를 설명하기 위해 도시하는 도면이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치를 이용하여 영상을 촬영하는 동작 예를 도시하는 도면이다. 도 6은 본 개시의 일 실시예에 따른 전자 장치의 구성을 개략적으로 도시하는 도면이다. 도 7은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 8a 및 도 8b는 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 동작 예를 도시하는 도면들 이다. 도 9a, 도 9b 및 도 9c는 본 개시의 일 실시예에 따른 전자 장치의 폼팩터에 대응하는 다양한 디스플레이의 예 를 도시하는 도면들이다. 도 10a, 도 10b 및 도 10c는 본 개시의 일 실시예에 따른 전자 장치에서 영상 촬영을 지원하는 동작 예를 도시 하는 도면들이다. 도 11은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치에서 지정된 식별 정보를 제공하는 동작 예를 도시하는 도면이다. 도 13은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 14는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 15a, 도 15b, 도 15c, 도 15d, 및 도 15e는 본 개시의 일 실시예에 따른 전자 장치에서 그래픽 요소와 프리 뷰를 제공하는 동작 예를 도시하는 도면들이다. 도 16a, 도 16b 및 도 16c는 본 개시의 일 실시예에 따른 전자 장치에서 그래픽 요소를 제공하는 동작 예를 도 시하는 도면들이다. 도 17은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 18a, 도 18b, 도 18c, 및 도 18d는 본 개시의 일 실시예에 따른 전자 장치에서 프리뷰를 제공하는 동작 예를 도시하는 도면들이다.도 19는 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 20은 본 개시의 일 실시예에 따른 전자 장치의 동작 방법을 도시하는 흐름도이다. 도 21 및 도 22는 본 개시의 일 실시예에 따른 전자 장치에서 그래픽 요소에 기반하여 기능을 실행하는 동작 예 를 도시하는 도면들이다."}
