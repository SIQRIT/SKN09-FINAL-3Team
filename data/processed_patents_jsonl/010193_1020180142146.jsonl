{"patent_id": "10-2018-0142146", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0063292", "출원번호": "10-2018-0142146", "발명의 명칭": "얼굴 영상 기반의 감정 인식 시스템 및 방법", "출원인": "광운대학교 산학협력단", "발명자": "장주용"}}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "얼굴 인식을 위한 개인별 얼굴 사진과 기계 학습(machine learning)에 의해 개인별 얼굴 사진의 감정 상태에 따른 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 얼굴의 특징점들과 그 얼굴 사진과 관련된 감정 상태에따른 영상 패치 기반 데이터를 저장하는 저장된 얼굴 인식 DB와 얼굴 인식 시스템; 및 상기 얼굴 인식DB와 연동되며, 대상 사람의 얼굴 영상 를 입력받아 N개의 얼굴 특징점들을 추출하고, 특징점 기반 감정 인식 결과 와 그 특징점들 근처의 영상 패치로부터 영상 기반의 감정인식결과 를 제공하여 대상 사람의 얼굴의 최종 감정 인식 결과를 출력하는 감정 인식시스템; 을 포함하는 얼굴 영상 기반의 감정 인식 시스템."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 영상 패치 기반 데이터는 감정 상태에 따른 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라낸 컬러 영상들을 각각 얼굴 인식DB에 저장된 얼굴 인식 데이터이며, 상기 윈도우는 3x3 window, 또는 5x5window를 사용하는, 얼굴 영상 기반의 감정 인식 시스템."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 감정 인식 시스템은 얼굴 영상 를 입력받아 N개의 얼굴 특징점에 대한 좌표 를 출력하는 얼굴 특징점 추출부; 얼굴 인식DB에 통계적으로 감정상태에 따른 얼굴 표정의 특징점 데이터가 저장되며, 상기 N개의 얼굴 특징점들에 대한 좌표 를 입력받아 상기 감정상태에 따른 얼굴 표정의 특징점 데이터와 비교하여 특징점 기반감정 인식 결과를 제공하는 특징점 기반 감정 인식부;입력 얼굴 영상과 상기 N개의 얼굴 특징점 좌표들을 입력받아 얼굴 특징점 좌표를 중심으로 가로, 세로가 W 픽셀의 길이를 가지는 정사각형 패치를 얼굴 영상으로부터 추출하여 결과적으로 총 N개의 영상 패치 를제공하는 영상 패치 추출부; 상기 영상 패치 추출부로부터 상기 총 N개의 영상 패치 를 입력받고, 영상 패치 기반 감정 인식 결과를 제공하는 영상 패치 기반 감정 인식부; 및상기 특징점 기반 감정 인식부 및 상기 영상 패치 기반 감정 인식부로부터 각각 특징점 기반 감정 인식 결과와 영상 패치 기반 감정 인식 결과 를 입력받아 최종 감정 인식 결과 를 출력하는 감정 인식 결과 융합부; 를 포함하는 얼굴 영상 기반의 감정 인식 시스템."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 공개특허 10-2020-0063292-3-상기 얼굴 특징점 추출부, 상기 특징점 기반 감정 인식부, 상기 영상 패치 기반 감정 인식부는 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(CNN)을 사용하며, 상기 얼굴 특징점 추출부는 얼굴의윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들을 추출하는, 얼굴 영상 기반의 감정 인식 시스템."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 감정 인식 결과 융합부는 과 는 모두 M 차원의 벡터로 M개의 감정 카테고리에 대한 확률 분포를 나타내며, 그렇게 추정된 두 개의감정 인식 결과 벡터는 상기 감정 인식 결과 융합부로 입력되고, 최종 감정 인식 결과 가 계산되며, 이는 의 관계식을 통해 특징점 기반 감정 인식 결과 벡터와 영상 패치 기반 감정 인식 결과벡터의 가중 평균으로 계산될 수 있으며, 여기서 α는 특징점 기반 감정 인식 결과에 대한 가중치를 나타내며, 인식된 감정의 카테고리 는 가장 높은 확률을 가지는 감정의 인덱스 로 계산되어 감정 인식 시스템의 최종 감정 인식 결과가 출력되는, 얼굴 영상 기반의 감정 인식 시스템."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 감정 인식 시스템은 얼굴 인식 DC와 출입 관리시의 감정 상태에 따른 얼굴의 특징점 데이터가 저장된 서버에 얼굴 인식을 사용한 상기 감정 인식 시스템이 구축되며, client/server 방식으로 카메라 영상의 얼굴 인식 시에 PC 또는 스마트폰의클라이언트 프로그램으로 얼굴 인식 및 상기 감정 인식 결과를 제공하는, 얼굴 영상 기반의 감정 인식 시스템."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "(a) 감정 인식 시스템에서, 얼굴 영상 를 얼굴 특징점 추출부로 입력 받아, 상기 얼굴 특징점 추출부가 N개의 얼굴 특징점에 대한 좌표 를 출력하는 단계; (b) 상기 얼굴 특징점 추출부로부터 상기 N개의 얼굴 특징점들에 대한 좌표 를 특징점 기반 감정 인식부로 입력받아, 상기 특징점 기반 감정 인식부가 상기 감정상태에 따른 얼굴 표정의 특징점 데이터와 비교하여특징점 기반 감정 인식 결과를 제공하는 단계;(c) 입력 얼굴 영상과 상기 N개의 얼굴 특징점 좌표들을 영상 패치 추출부로 입력받아, 상기 영상 패치 추출부가 얼굴 특징점 좌표를 중심으로 가로, 세로가 W 픽셀의 길이를 가지는 정사각형 패치를 얼굴 영상으로부터 추출하여 결과적으로 총 N개의 영상 패치 를 제공하는 단계; (d) 상기 영상 패치 추출부로부터 상기 총 N개의 영상 패치 를 영상 패치 기반 감정 인식부로 입력받고, 상기 영상 패치 기반 감정 인식부가 영상 패치 기반 감정 인식 결과 를 제공하는 단계; 및(e) 상기 특징점 기반 감정 인식부 및 상기 영상 패치 기반 감정 인식부로부터 얼굴 인식 DB와 연동하여 기계학습 데이터와 비교하여 감정 상태에 따른 개인별 얼굴 사진의 각각 특징점 기반 감정 인식 결과와 영상 패치 기반 감정 인식 결과 를 감정 인식 결과 융합부로 입력받아, 상기 감정 인식 결과 융합부가 최종 감정 인식 결과 를 출력하는 단계; 를 포함하는 얼굴 영상 기반의 감정 인식 방법.공개특허 10-2020-0063292-4-청구항 8 제7항에 있어서, 상기 단계 (a)에서, 상기 얼굴 특징점 추출부, 상기 특징점 기반 감정 인식부, 상기 영상 패치 기반 감정 인식부는 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(CNN)을 사용하며, 상기 얼굴 특징점 추출부는 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들을 추출하는, 얼굴 영상기반의 감정 인식 방법."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 얼굴 인식DB는 기계학습(machine learning)에 따라 개인별 감정상태에 따른 얼굴 사진의 특징점 데이터,및 개인별 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라낸 영상 패치 기반 데이터가 저장되는,얼굴 영상 기반의 감정 인식 방법."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 영상 패치 기반 데이터는 감정 상태에 따른 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라낸 컬러 영상들을 각각 얼굴 인식DB에 저장된 얼굴 인식 데이터이며, 상기 윈도우는 3x3 window, 또는 5x5window를 사용하는, 얼굴 영상 기반의 감정 인식 방법."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 단계 (d)의 상기 감정 인식 결과 융합부는 과 는 모두 M 차원의 벡터로 M개의 감정 카테고리에 대한 확률 분포를 나타내며, 그렇게 추정된 두 개의감정 인식 결과 벡터는 감정 인식 결과 융합부(770)로 입력되고, 최종 감정 인식 결과 가 계산되며, 이는 의 관계식을 통해 특징점 기반 감정 인식 결과 벡터와 영상 패치 기반 감정 인식 결과벡터의 가중 평균으로 계산될 수 있으며, 여기서 α는 특징점 기반 감정 인식 결과에 대한 가중치를 나타내며, 인식된 감정의 카테고리 는 가장 높은 확률을 가지는 감정의 인덱스 로 계산되어 감정 인식 시스템의 최종 감정 인식 결과가 출력되는, 얼굴 영상 기반의 감정 인식 방법."}
{"patent_id": "10-2018-0142146", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 감정 인식 시스템은 얼굴 인식 DC와 출입 관리시의 감정 상태에 따른 얼굴의 특징점 데이터가 저장된 서버에 얼굴 인식을 사용한 상기 감정 인식 시스템이 구축되며, client/server 방식으로 카메라 영상의 얼굴 인식 시에 PC 또는 스마트폰의클라이언트 프로그램으로 얼굴 인식 및 상기 감정 인식 결과를 제공하는, 얼굴 영상 기반의 감정 인식 방법."}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "얼굴 영상 기반의 감정 인식 시스템 및 방법이 개시된다. 얼굴 영상 기반의 감정 인식 시스템은 얼굴 인식을 위 한 개인별 얼굴 사진과 기계 학습(machine learning)에 의해 개인별 얼굴 사진의 감정 상태에 따른 얼굴의 윤곽 선, 눈썹과 눈, 코와 입, 턱을 포함하는 얼굴의 특징점들과 그 얼굴 사진과 관련된 감정 상태에 따른 영상 패치 (뒷면에 계속)"}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 얼굴 영상 기반의 감정 인식 시스템 및 방법에 관한 것으로, 보다 상세하게는 대상 사람의 얼굴 영상 을 입력받아 얼굴 이미지를 캡춰하여 인공 신경망 기술을 사용하여 윤곽선, 눈썹과 눈, 코와 입, 턱 등의 얼굴특징점들(facial landmarks)을 추출하고, 추출된 얼굴 특징점들과 그 특징점들 근처의 영상 패치로부터 특징점 기반의 감정인식 결과와 영상 기반의 감정인식 결과를 통해 얼굴의 미세한 표정 변화를 인식하고 희노애락의 감 정 상태(기쁨, 슬픔, 두려움, 화남)를 추정하여 그 사람의 얼굴의 감정인식 결과를 출력하는, 얼굴 영상 기반의 감정 인식 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴인식(Face Recognition) 기술은 1990년대 초기에 소개된 형상 기반 매칭 방법(appearance based matching method), 및 특징(faeture) 기반의 얼굴 인식이 주로 사용된다. 그러나, 얼굴인식은 카메라의 촬영 각도, 조명 의 방향, 자세, 표정의 변화 및 시간에 따른 얼굴의 변화에 다르게 인식된다. 특징(faeture) 기반의 얼굴 인식은 디지털 카메라, IoT 디바이스의 카메라 또는 스마트폰의 카메라로 촬영된 영 상 데이터를 haar-like feature를 이용한 검출 방법과 MCT(Modified Census Transform) 영상을 이용한 검출 방 법이 사용된다. 스마트폰의 카메라의 입력 영상에서 Haar-like feature로 학습된 얼굴 및 눈 검출기를 사용하여 얼굴의 윤곽선과 이마/눈/코/입을 검출하고, 원형의 눈동자를 검출하기 위해 관심 영역(ROI, Region of Interest)으로 설정된 눈 영역을 grayscale로 변환하며, 눈 영역에서 눈동자와 눈의 외곽선 영역이 추출되는 실 험에 의한 통계적인 임계값(threshold)을 사용하여 눈 이미지의 histogram[x축 각 픽셀의 화소값, y축 해당 화 소 값의 갯수]을 구하고 눈의 이미지를 이진화(binarization)한 후, 히스토그램 평활화(histogram equalization)를 통해 눈 영역의 사진의 전처리를 수행하며, 얼굴 영역에서 눈썹과 눈, 코, 입, 턱의 특징 데이 터를 검출하고, 텍스처 특징(Texture Faetures)과 형상 특징(Shape Features)을 추출하여 얼굴 인식 DB에 저장 된 얼굴 사진의 특징점들과 유사도를 비교하여 얼굴이 인식된다."}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "얼굴 영역의 눈썹과 눈, 코, 입, 턱의 특징 값은 Haar-like feature의 흰 영역에서 포함되는 픽셀들의 합에서 검은 영역에서 포함되는 픽셀의 합의 차로 표현된다. 예를들면, 표준 크기의 얼굴 영역 사진에서 검출된 눈 영역에서 오른쪽과 왼쪽 눈의 양쪽 끝점 까지의 거리, 허 프 원 변환(hough circle transform) 알고리즘을 사용하여 추출된 눈동자(iris)의 크기 값이 특징 값으로 사용 된다. 이와 관련된 선행기술1로써, 특허 공개번호 10-2017-0050465에서는 \"얼굴 인식 장치 및 방법\"을 개시하고 있습 니다. 본 실시예에 의하면, 기계학습을 이용하여 입력영상으로부터 얼굴을 인식함에 있어, 얼굴포즈 및 원근감을 정규 화하여 얼굴인식률을 향상시키고, 얼굴 학습 데이터로서 가상 얼굴 영상을 자동으로 생성하여 얼굴 학습 데이터 를 획득하는데 드는 비용 및 시간을 절약하는 얼굴 인식 장치 및 방법을 제공한다. 도 1은 종래의 얼굴인식장치의 구성도이다. 도 2는 얼굴인식장치의 정규화부를 설명하는 개념도이다. 얼굴인식장치는 영상 표시 장치, 영상 촬영 장치, 얼굴인식서버, 태블릿 PC, 랩톱(Laptop), 개인용 PC, 스 마트폰, 개인휴대용 정보단말기(PDA: Personal Digital Assistant), 이동통신 단말기, 및 지능로봇 (Intelligence Robot) 등 중 어느하나일 수 있다. 얼굴 인식 장치는 카메라로부터 입력되는 입력영상을 획득하는 입력영상 획득부; 상기 입력영상에서 얼굴영역을 검출하여 얼굴포즈(Pose)를 정규화함으로써 정면포즈 영상을 생성하고, 상기 카메라와 피사체 간의 거리에 따른 원근왜곡(Perspective Distortion)을 제거하기 위하여 상기 정면포즈 영상의 원근감(Perspectiv e)을 정규화하여 정규화 영상을 생성하는 정규화부; 상기 정규화 영상으로부터 상기 피사체의 얼굴을 표현 하는 특징벡터(Feature Vector)를 추출하는 특징벡터 추출부; 및 기 학습된 분류모델에 상기 특징벡터를 적용하여 상기 입력영상에 포함된 상기 피사체의 얼굴을 인식하는 얼굴인식부를 포함한다. 입력영상 획득부는 카메라로부터 입력되는 입력영상을 획득한다. 카메라는 깊이인식 카메라, 스테레오 카 메라, 및 컬러 카메라일 수 있다(예를 들면, 키넥트(Kinect) 카메라 등) 또한, 입력영상은 인식대상이 되는 피 사체의 얼굴이 포함된 영상으로서 2차원 정지영상 및 동영상을 포함한다. 입력영상은 컬러영상, 깊이영상, 및 컬러-깊이(RGB-D) 영상을 포함할 수 있다. 정규화부는 입력영상으로부터 얼굴영역을 검출하고 얼굴포즈(Pose) 및 원근감(Perspective)을 정규화하여 정규화 영상을 생성한다. 얼굴포즈에 변화가 있는 경우, 그레이 스케일, 형상, 특징점의 위치 등이 달라지기 때문에 얼굴인식률이 저하된다. 또한, 카메라와 피사체 간의 거리가 달라지면 동일한 피사체라 하더라도 촬영된 위치마다 원근왜곡(Perspective Distortion, 예컨대 뒤틀림)이 다르게 발생하므로, 다른 피사체를 촬영한 것처 럼 보이기도 한다. 따라서 얼굴인식률을 향상시키기 위해서는 입력영상의 얼굴포즈 및 원근감을 정규화할 필요 가 있다. 정규화부는, 다양한 포즈의 학습용 얼굴영상을 제1 인공신경망의 입력층에 입력하고, 정면포즈의 학습용 얼굴영상이 상기 제1 인공신경망의 출력층에서 출력되도록 상기 제1 인공신경망을 학습시키는 얼굴포즈 정규화 학습부; 및 상기 제1 인공신경망의 출력층에서 출력된 데이터를 제 2 인공신경망의 입력층에 입력하고, 원근왜 곡이 없는 학습용 얼굴영상이 상기 제 2 인공신경망의 출력층에서 출력되도록 상기 제2 인공신경망을 학습시키 는 원근감 정규화 학습부를 포함한다. 상기 정규화부는, 학습이 완료된 상기 제1 인공신경망과 상기 제2 인공신경망을 통합한 통합 인공신경망의 입력 층에 다양한 원근 왜곡이 있는 다양한 포즈의 학습용 얼굴영상을 입력하고, 정면포즈의 원근왜곡이 없는 학습용 얼굴영상이 상기통합 인공신경망의 출력층에서 출력되도록 상기 통합 인공신경망을 학습시킨다. 특징벡터 추출부는 기계학습(Machine Learning)을 통해 결정되며, 정규화 영상으로부터 피사체의 얼굴을 표현하는 특징벡터(Feature Vector)를 추출한다. 특징벡터는 얼굴인식에 사용되는 특징값들을 원소로 가지는 벡터이다. 특징벡터를 추출하는데 사용되는 필터로 써 Gabor 필터, Haar 필터, LBP(Local Binary Pattern) - DLBP(Discriminative LBP), ULBP(Uniform LBP), NLBP(Number LBP) 등을 포함 - 등이 있으나, 반드시 이에 한정되는 않으며 그 밖의 다른 필터가 사용될 수 있다. 얼굴 인식부는 기 학습된 분류모델에 특징벡터 추출부에서 추출된 특징벡터를 적용하여 입력영상에 포함된 피사체의 얼굴을 인식한다. 기 학습된 분류모델은 서포트 벡터 머신(Support Vector Machine, SVM), 선 형판별분석(Linear Discriminant Analysis, LDA), 및 Softmax 등을 포함할 수 있으나, 반드시 이에 한정되는 것은 아니다. 가상 얼굴영상 생성부는 정규화부, 특징벡터 추출부, 및 얼굴 인식부가 학습하는데 사용되 는 복수의 가상 얼굴영상을 생성할 수 있다. 복수의 가상 얼굴영상은 가상 얼굴영상 생성부가 카메라로부터 획득된 하나 이상의 2차원 기준영상을 이용 하여 합성한 3차원 얼굴모델을 변형시킴으로써생성되는 얼굴영상을 의미한다. 그러나, 기존의 얼굴 인식 시스템은 입력 영상에 대하여 얼굴 인식 기술을 사용하여 추출된 얼굴 특징점들을 기 반 감정을 인식하여 출력하는 얼굴 영상 기반의 감정 인식 시스템이 제공되지 않았다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허 공개번호 10-2017-0050465 (공개일자 2017년 05월 11일), \"얼굴 인식 장치 및 방법\", 에 스케이텔레콤 주식회사"}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기한 문제점을 해결하기 위한 본 발명의 목적은 대상 사람의 얼굴 영상을 입력받아 얼굴 이미지를 캡춰하여 인공 신경망 기술을 사용하여 윤곽선, 눈썹과 눈, 코와 입, 턱 등의 얼굴 특징점들(facial landmarks)을 추출하 고, 추출된 얼굴 특징점들과 그 특징점들 근처의 영상 패치로부터 특징점 기반의 감정인식 결과와 영상 기반의 감정인식 결과를 통해 사람의 미세한 표정 변화를 인식하고 희노애락의 감정 상태(기쁨, 슬픔, 두려움, 화남)를 추정하여 그 사람의 얼굴의 감정인식 결과를 출력하는, 얼굴 영상 기반의 감정 인식 시스템을 제공한다. 본 발명의 다른 목적은 얼굴 영상 기반의 감정 인식 방법을 제공한다."}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, 얼굴 영상 기반의 감정 인식 시스템은 얼굴 인식을 위한 개인별 얼굴 사진과 기계 학습(machine learning)에 의해 개인별 얼굴 사진의 감정 상태에 따른 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 얼굴의 특징점들과 그 얼굴 사진과 관련된 감정 상태에 따른 영상 패치 기반 데이터를 저장 하는 저장된 얼굴 인식 DB와 얼굴 인식 시스템; 및 상기 얼굴 인식 DB와 연동되며, 대상 사람의 얼굴 영상 를 입력받아 N개의 얼굴 특징점들을 추출하고, 특징점 기반 감정 인식 결과 와 그 특징점들 근처의 영상 패치로부터 영상 기반의 감정인식 결과 를 제공하여 대상 사람의 얼굴의 최종 감정 인식 결과를 출력하는 감정 인식 시스템을 포함한다. 상기 영상 패치 기반 데이터는 감정 상태에 따른 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라 낸 컬러 영상들을 각각 얼굴 인식DB에 저장된 얼굴 인식 데이터이며, 상기 윈도우는 3x3 window, 또는 5x5 window를 사용한다. 상기 감정 인식 시스템은, 얼굴 영상 를 입력받아 N개의 얼굴 특징점에 대한 좌표 를 출력하는 얼굴 특징점 추출부; 얼굴 인식DB에 통계적으로 감정상태에 따른 얼굴 표정의 특징점 데이터가 저장되며, 상기 N개의 얼굴 특징점들에 대한 좌표 를 입력받아 상기 감정상태에 따른 얼굴 표정의 특징점 데이터와 비 교하여 특징점 기반 감정 인식 결과를 제공하는 특징점 기반 감정 인식부;입력 얼굴 영상과 상기 N개의 얼굴 특 징점 좌표들을 입력받아 얼굴 특징점 좌표를 중심으로 가로, 세로가 W 픽셀의 길이를 가지는 정사각형 패치를 얼굴 영상으로부터 추출하여 결과적으로 총 N개의 영상 패치 를 제공하는 영상 패치 추출부; 상기 영 상 패치 추출부로부터 상기 총 N개의 영상 패치 를 입력받고, 영상 패치 기반 감정 인식 결과 를 제공하는 영상 패치 기반 감정 인식부; 및 상기 특징점 기반 감정 인식부 및 상기 영 상 패치 기반 감정 인식부로부터 각각 특징점 기반 감정 인식 결과 와 영상 패치 기반 감 정 인식 결과 를 입력받아 최종 감정 인식 결과 를 출력하는 감정 인식 결과 융합부를 포함한다. 상기 얼굴 특징점 추출부, 상기 특징점 기반 감정 인식부, 상기 영상 패치 기반 감정 인식부는 입력 영상 I로부 터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(CNN)을 사용하며, 상기 얼굴 특징점 추출부는 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들을 추출한다. 상기 감정 인식 결과 융합부는, 과 는 모두 M 차원의 벡터로 M개의 감정 카테고리에 대한 확률 분포를 나 타내며, 그렇게 추정된 두 개의 감정 인식 결과 벡터는 감정 인식 결과 융합부로 입력되고, 최종 감정 인 식 결과 가 계산되며, 이는 의 관계식을 통해 특징점 기반 감정 인식 결과 벡터와 영상 패치 기반 감정 인식 결과 벡터의 가중 평균으로 계산될 수 있으며, 여기서 α는 특징점 기반 감정 인식 결과에 대한 가중치를 나타내며, 인식된 감정의 카테고리 는 가장 높은 확률을 가지는 감정의 인덱스 로 계산되어 감정 인 식 시스템의 최종 감정 인식 결과가 출력된다. 상기 감정 인식 시스템은 얼굴 인식 DC와 출입 관리시의 감정 상태에 따른 얼굴 특징점 데이터가 저장된 서버에 얼굴 인식을 사용한 감정 인식 시스템이 구축되며, client/server 방식으로 카메라 영상의 얼굴 인식 시에 PC 또는 스마트폰의 클라이언트 프로그램으로 얼굴 인식 및 상기 감정 인식 결과를 제공한다. 본 발명의 다른 목적을 달성하기 위해, 얼굴 영상 기반의 감정 인식 방법은 (a) 감정 인식 시스템에서, 얼굴 영 상 를 얼굴 특징점 추출부로 입력 받아, 상기 얼굴 특징점 추출부가 N개의 얼굴 특징점에 대한 좌표 를 출력하는 단계; (b) 상기 얼굴 특징점 추출부로부터 상기 N개의 얼굴 특징점들에 대한 좌표 를 특징점 기반 감정 인식부로 입력받아, 상기 특징점 기반 감정 인식부가 상기 감정상태에 따른 얼굴 표정의 특징점 데이터와 비교하여 특징점 기반 감정 인식 결과를 제공하는 단계; (c) 입력 얼굴 영상과 상기 N개의 얼굴 특징점 좌표들을 영상 패치 추출부로 입력받아, 상기 영상 패치 추출부가 얼굴 특징점 좌표를 중심으 로 가로, 세로가 W 픽셀의 길이를 가지는 정사각형 패치를 얼굴 영상으로부터 추출하여 결과적으로 총 N개의 영 상 패치 를 제공하는 단계; (d) 상기 영상 패치 추출부로부터 상기 총 N개의 영상 패치 를 영상 패치 기반 감정 인식부로 입력받고, 상기 영상 패치 기반 감정 인식부가 영상 패치 기반 감정 인식 결과 를 제공하는 단계; 및 (e) 상기 특징점 기반 감정 인식부 및 상기 영상 패치 기반 감정 인식부로부터 얼굴 인식 DB와 연동하여 기계 학습 데이터와 비교하여 감정 상태에 따른 개인별 얼굴 사진의 각 각 특징점 기반 감정 인식 결과 와 영상 패치 기반 감정 인식 결과 를 감정 인식 결과 융합부로 입력받아, 상기 감정 인식 결과 융합부가 최종 감정 인식 결 과 를 출력하는 단계를 포함한다. 상기 단계 (a)에서, 상기 얼굴 특징점 추출부, 상기 특징점 기반 감정 인식부, 상기 영상 패치 기반 감정 인식 부는 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(CNN)을 사용하며, 상기 얼굴 특 징점 추출부는 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들을 추출한다. 상기 얼굴 인식DB는 기계학습(machine learning)에 따라 개인별 감정상태에 따른 얼굴 사진의 특징점 데이터, 및 개인별 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라낸 영상 패치 기반 데이터가 저장된다. 상기 영상 패치 기반 데이터는 감정 상태에 따른 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라 낸 컬러 영상들을 각각 얼굴 인식DB에 저장된 얼굴 인식 데이터이며, 상기 윈도우는 3x3 window, 또는 5x5 window를 사용한다. 상기 단계 (d)의 상기 감정 인식 결과 융합부는"}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "과 는 모두 M 차원의 벡터로 M개의 감정 카테고리에 대한 확률 분포를 나타내며, 그렇게 추정된 두 개의 감정 인식 결과 벡터는 감정 인식 결과 융합부로 입력되고, 최종 감정 인식 결과 가 계 산되며, 이는 의 관계식을 통해 특징점 기반 감정 인식 결과 벡터와 영상 패치 기반 감정 인식 결과 벡터의 가중 평균으로 계산될 수 있으며, 여기서 α는 특징점 기반 감정 인식 결과에 대한 가중치를 나타내며, 인식된 감정의 카테고리 는 가장 높은 확률을 가지는 감정의 인덱스 로 계산되어 감정 인 식 시스템의 최종 감정 인식 결과가 출력된다. 상기 감정 인식 시스템은, 얼굴 인식 DC와 출입 관리시의 감정 상태에 따른 얼굴의 특징점 데이터가 저장된 서 버에 얼굴 인식을 사용한 감정 인식 시스템이 구축되며, client/server 방식으로 카메라 영상의 얼굴 인식 시에 PC 또는 스마트폰의 클라이언트 프로그램으로 얼굴 인식 및 그 감정 인식 결과를 제공한다."}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 얼굴 영상 기반의 감정 인식 시스템 및 방법은 대상 사람의 얼굴 영상을 입력받아 얼굴 이미지를 캡 춰하여 인공 신경망 기술을 사용하여 윤곽선, 눈썹과 눈, 코와 입, 턱 등의 얼굴 특징점들(facial landmarks)을 추출하고, 추출된 얼굴 특징점들과 그 특징점들 근처의 영상 패치로부터 특징점 기반의 감정인식 결과와 영상 기반의 감정인식 결과를 통해 얼굴의 미세한 표정 변화를 인식하고 희노애락의 감정(기쁨, 슬픔, 두려움, 화남) 상태를 추정하여 그 사람의 감정 상태를 출력하는 효과가 있다. 얼굴 인식 기술은 카메라로 촬영된 영상 데이터를 사용하여 공항 출입국 관리, 얼굴 인식 기반 출입관리, 얼굴 인식 화상 회의, 얼굴 인식 대화형 TV 미디어 서비스, CCTV 카메라의 얼굴 인식 기반 신원 확인 및 범죄 수사에 사용되며, 얼굴 인식을 통해 사람의 감정 상태를 추정하게 되었다."}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다. 본 발명의 얼굴 영상 기반의 감정 인식 시스템은 대상 사람의 얼굴 영상을 입력받아 얼굴 이미지를 캡춰하여 인 공 신경망 기술을 사용하여 윤곽선, 눈썹과 눈, 코와 입, 턱 등의 얼굴 특징점들(facial landmarks)을 추출하고, 추출된 얼굴 특징점들과 그 특징점들 근처의 영상 패치로부터 사람의 미세한 표정 변화를 인식하고 희노애락의 감정 상태(기쁨, 슬픔, 두려움, 화남)를 추정하여 그 사람의 감정 상태를 출력한다. 도 3은 얼굴의 테두리 윤곽, 눈썹과 눈, 코 밑선, 입, 턱을 포함하는 얼굴 특징점들(Facial Landmarks)의 예를 보인 그림이다. 얼굴 특징점은 얼굴에서 구별이 가능한 특징을 가지고 있는 점들을 의미하며, 그 실시예로서 68개의 특징점을 나타냈다. 실제 사람의 얼굴 영상으로부터 추출된 특징점들은 그 사람의 얼굴의 형태, 상태에 대한 정보를 제공한다. 이러 한 얼굴의 특징점들을 활용하여 사람의 표정, 그리고 더 나아가 감정 상태까지 인식을 할 수 있다. 하지만, 얼 굴의 특징점들은 거시적인 정보만을 제공할 수 있을 뿐 사람의 미세한 표정 변화에 따른 얼굴 영상의 미세한 변 화, 예를들면 화난 얼굴에 나타나는 컬러 또는 밝기의 변화를 나타내지는 못한다. 이를 보완하기 위해 얼굴 특"}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "징점들 주위의 영상 정보 또한 함께 사용하여 감정 인식에 활용하고자 한다. 요약하면, 본 발명에서는 얼굴 영 상으로부터 추출된 특징점들과 그러한 특징점들 근처의 영상 패치로부터 사람 얼굴의 미세한 표정 변화를 인식 하고, 감정 상태를 추정하는 시스템을 제안하였다."}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 4는 본 발명에 따른 감정 인식 시스템의 개요를 보인 도면이다. 얼굴 영상 기반의 감정 인식 시스템은 대상 사람의 얼굴 영상을 입력받아 인공 신경망 기술을 사용하여 윤곽선, 눈썹과 눈, 코와 입, 턱 등의 얼굴 특징점 좌표를 추출하고, 추출된 얼굴 특징점들과 그 특징점들 근처 의 영상 패치로부터 특징점 기반의 감정 인식 결과와 영상 기반의 감정인식 결과를 통해 얼굴의 미세한 표정 변 화를 인식하고 희노애락의 감정 상태(기쁨, 슬픔, 두려움, 화남)를 추정하여 최종 감정 인식 결과를 출력한다. 이를 위해, 얼굴 영상 기반의 감정 인식 시스템은 얼굴 영상 기반의 감정 인식 시스템은 얼굴 인식을 위한 개인별 얼굴 사진과 기계 학습(machine learning)에 의 해 개인별 얼굴 사진의 감정 상태에 따른 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 얼굴의 특징점들 과 그 얼굴 사진과 관련된 감정 상태에 따른 영상 패치 기반 데이터를 저장하는 저장된 얼굴 인식 DB와 얼굴 인 식 시스템; 및 상기 얼굴 인식 DB와 연동되며, 대상 사람의 얼굴 영상 를 입력받아 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들을 추출하고, 특징점 기반 감정 인식 결과 와 그 특징 점들 근처의 영상 패치로부터 영상 기반의 감정인식 결과 를 제공하여 대상 사람의 얼굴 의 최종 감정 인식 결과를 출력하는 감정 인식 시스템을 포함한다. 얼굴 인식DB는 기계학습(machine learning, ML)에 따라 감정상태에 따른 얼굴의 특징점 데이터 및 개인별 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라낸 영상 패치 기반 데이터가 저장된다. 상기 영상 패치 기반 데이터는 감정 상태에 따른 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(예, 3x3 window, 또는 5x5 window)로 잘라낸 컬러 영상들을 각각 얼굴 인식DB에 저장된 얼굴 인식 데이터이다. 도 5는 본 발명의 실시예에 따른 감정 인식 시스템의 블록도이다. 감정 인식 시스템은 얼굴 특징점 추출부, 특징점 기반 감정 인식부, 영상 패치 추출부, 영 상 패치 기반 감정 인식부, 및 감정 인식 결과 융합부으로 구성된다. 본 발명의 감정 인식 시스템은 얼굴 영상 를 입력받아, 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들에 대한 좌표 를 출력하는 얼굴 특징점 추출부; 얼굴 인식DB에 통계적으로 감정상태에 따른 얼굴 표정의 특징점 데이터가 저장되며, 상기 N개의 얼굴 특징점들 에 대한 좌표 를 입력받아 상기 감정상태에 따른 얼굴 표정의 특징점 데이터와 비교하여 특징점 기반 감정 인식 결과를 제공하는 특징점 기반 감정 인식부; 입력 얼굴 영상과 상기 N개의 얼굴 특징점 좌표들을 입력받아 얼굴 특징점 좌표를 중심으로 가로, 세로가 W 픽 셀의 길이를 가지는 정사각형 패치를 얼굴 영상으로부터 추출하여 결과적으로 총 N개의 영상 패치 를 출력하는 영상 패치 추출부; 상기 영상 패치 추출부로부터 상기 총 N개의 영상 패치 를 입력받고, 영상 패치 기반 감정 인식 결과 를 제공하는 영상 패치 기반 감정 인식부; 및 상기 특징점 기반 감정 인식부 및 상기 영상 패치 기반 감정 인식부로부터 각각 특징점 기반 감정 인 식 결과 와 영상 패치 기반 감정 인식 결과 를 입력받아 최종 감정 인식 결과 를 출력하는 감정 인식 결과 융합부를 포함한다. 먼저 얼굴 영상 는 얼굴 특징점 추출부로 입력되고, 얼굴 특징점 추출부는 N개의 얼굴 특징점에 대한 좌표 를 출력한다. 상기 얼굴 특징점 추출부은 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 딥러닝의 컨볼루션 신 경망(Convolutional Neural Network, CNN)을 사용하며, 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N 개의 얼굴 특징점들을 추출한다. 상기 얼굴 특징점 추출부, 상기 특징점 기반 감정 인식부, 상기 영상 패치 기반 감정 인식부는 각각 다른 종류의 인공 신경망을 사용한다. 특징점 기반 감정 인식부는 얼굴 특징점 추출부로부터 상기 N개의 얼굴 특징점에 대한 좌표 를 입력받아 얼굴 인식DB에 저장된 상기 감정상태에 따른 얼굴 표정의 특징점 데이터와 비교하여 특징 점 기반 감정 인식 결과를 제공한다. 영상 패치 추출부는 입력 얼굴 영상과 얼굴 특징점 좌표를 입력받아 얼굴 특징점 좌표를 중심으로 가로, 세로가 W 픽셀의 길이를 가지는 정사각형 패치를 얼굴 영상으로부터 추출하여 결과적으로 총 N개의 영상 패치 를 출력한다. 얼굴 인식 DB와 연동되며, 얼굴 특징점 좌표와 영상 패치를 위해, 특징점 기반 감정 인식부와 영상 패치 기반 감정 인식부로부터 각각 감정 인식 결과 융합부로 총 N개의 영상 패치 를 입력받고, 각각 특징점 기반 감정 인식 결과 와 영상 패치 기반 감정 인식 결과 를 입력받고, 감정 인식 결과 융합부는 분류된 감정 중에서 기쁨, 슬픔, 두려움, 화남 중 어느 하나의 최종 감정 인식 결과를 출력한다. 여기서, 과 는 모두 M 차원의 벡터로 M개의 감정 카테고리에 대한 확률 분포를 나타낸다. 그렇게 추정된 두 개의 감정 인식 결과 벡터는 감정 인식 결과 융합부로 입력되며, 최종 감정 인식 결과 가 계산된다. 이는 의 관계식을 통해 특징점 기반 감정 인식 결과 벡터와 영상 패치 기반 감정 인식 결과 벡터의 가중 평균으로 계산될 수 있으며, 여기서 α는 특징점 기반 감정 인식 결과에 대한 가중치를 나타낸다. 마지막으로 인식된 감정의 카테고리 는 가장 높은 확률을 가지는 감정의 인덱스 로 계산되 어 감정 인식 시스템의 최종 감정 인식 결과가 출력된다. 도 6은 인공 신경망 기반의 얼굴 특징점 추출부, 특징점 기반 감정 인식부, 영상 패치 기반의 감정 인식부의 블 록도이다. 입력 얼굴 영상으로부터 얼굴 특징점을 추출하는 얼굴 특징점 추출부는 인공 신경망(Artificial Neural Network) 방법으로 구현된다. 카메라의 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(Convolutional Neural Network, CNN)을 사용한다. 즉, 먼저 입력 영상의 모든 픽셀 정보를 일렬로 나열하여 하나의 커다란 벡터 로 만든 후, 함수를 반복 적용하여 출력 벡터, N개의 얼굴 특징점들에 대한 벡터 를 계산한다:"}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, hi는 i번째 은닉 특징 벡터, hi-1은 i-1번째 은닉 특징 벡터, Wi는 신경망 회로의 가중치 파라미터 (weight parameter, 상수값), bi는 신경망 회로의 바이어스 값이다. 즉, 입력 영상을 나타내는 벡터가 로 설정되어, 총 L 개의 레이어들을 거치며 , , ..., 을 차례대 로 계산하여 최종 출력 벡터는 으 로 결정이 된다. 또한, , , ..., 은 시스템의 입출력이 아닌, 드러나지 않는 양으로 은닉 특징 벡터(Hidden Feature Vector)라고 불린다. 이 때 최종 출력 벡터의 차원 은 으로 N 개의 얼굴 특징점에 대한 2차원 영상 좌표들을 의미한다. 얼굴 특징점 추출부, 특징점 기반의 감정 인식부와 영상 패치 기반의 감정 인식부 또한 인공 신 경망에 의해 구현된다. 인공 신경망은 입력층/은닉층/출력층의 다층 구조의 CNN(Convolutional Neural Networ k)을 사용할 수 있다. 특징점 기반의 감정 인식부의 경우 얼굴 특징점 추출부로부터 출력된 N개의 얼굴 특징점 좌표를 나타 내는 2N 차원의 벡터를 입력으로 받아 M 차원의 감정 확률 벡터 를 출력한다. 비슷하게 영상 패치 기반 감정 인식부의 경우도 영상 패치 추출부로부터 출력된 총 N개의 영상 패치의 픽셀 정보를 일렬로 나열하여 하나의 커다란 벡터로 만든 후 인공 신경망을 통과하여 M차원의 감정 확률 벡터 를 출력한다. 인공 신경망의 구조는 도 5에 도시하였다. 정리하면, 얼굴 특징점 추출부, 특징점 기반 감정 인식부, 영상 패치 기반 감정 인식부는 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(CNN)을 사용하며, 상기 얼굴 특징점 추출부 는 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들을 추출한다. 실시예에서는, 얼굴 인식 DC와 출입 관리시의 감정 상태에 따른 얼굴 특징점 데이터가 저장된 서버에 얼굴 인식 을 사용한 감정 인식 시스템이 구축되며, client/server 방식으로 카메라 영상의 얼굴 인식 시에 PC 또는 스마 트폰의 클라이언트 프로그램으로 얼굴 인식 및 그 감정 인식 결과를 볼 수 있다. 얼굴 인식 기술은 카메라로 촬영된 영상 데이터를 사용하여 공항 출입국 관리, 얼굴 인식 기반 출입관리, 얼굴 인식 화상 회의, 얼굴 인식 대화형 TV 미디어 서비스, CCTV 카메라의 얼굴 인식 기반 신원 확인 및 범죄 수사에사용되며, 얼굴 인식을 통해 사람의 감정 상태를 추정하게 되었다. 또한, 본 발명의 얼굴 영상 기반의 감정 인식 방법은 (a) 감정 인식 시스템에서, 얼굴 영상 를 얼굴 특징 점 추출부로 입력 받아, 상기 얼굴 특징점 추출부가 N개의 얼굴 특징점에 대한 좌표 를 출력하는 단계; (b) 얼굴 인식DB에 기계학습(machine learning)에 따라 개인별 감정상태에 따른 얼굴 사진의 특징점 데이 터, 및 개인별 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(3x3 window, 또는 5x5 window)로 잘라낸 영상 패치 기반 데이터가 저장되며, 상기 얼굴 특징점 추출부로부터 상기 N개의 얼굴 특징점들에 대한 좌표 를 특징점 기반 감정 인식부로 입력받아, 상기 특징점 기반 감정 인식부가 상기 감정상태에 따른 얼굴 표정의 특징 점 데이터와 비교하여 특징점 기반 감정 인식 결과를 제공하는 단계; (c) 입력 얼굴 영상과 상기 N개의 얼굴 특 징점 좌표들을 영상 패치 추출부로 입력받아, 상기 영상 패치 추출부가 얼굴 특징점 좌표를 중심으로 가로, 세 로가 W 픽셀의 길이를 가지는 정사각형 패치를 얼굴 영상으로부터 추출하여 결과적으로 총 N개의 영상 패치 를 제공하는 단계; (d) 상기 영상 패치 추출부로부터 상기 총 N개의 영상 패치 를 영상 패치 기반 감정 인식부로 입력받고, 상기 영상 패치 기반 감정 인식부가 영상 패치 기반 감정 인식 결과 를 제공하는 단계; 및 (e) 상기 특징점 기반 감정 인식부 및 상기 영상 패치 기반 감정 인식부로부터 얼굴 인식 DB와 연동하여 기계 학습 데이터와 비교하여 감정 상태에 따른 개인별 얼굴 사진의 각 각 특징점 기반 감정 인식 결과 와 영상 패치 기반 감정 인식 결과 를 감정 인식 결과 융합부로 입력받아, 상기 감정 인식 결과 융합부가 최종 감정 인식 결 과 를 출력하는 단계를 포함한다. 상기 단계 (a)에서, 상기 얼굴 특징점 추출부, 상기 특징점 기반 감정 인식부, 상기 영상 패치 기반 감정 인식부는 입력 영상 I로부터 입력층/은닉층/출력층의 다층 구조의 컨볼루션 신경망(CNN)을 사용하며, 상기 얼굴 특징점 추출부는 얼굴의 윤곽선, 눈썹과 눈, 코와 입, 턱을 포함하는 N개의 얼굴 특징점들을 추 출한다. 상기 얼굴 인식DB는 기계학습(machine learning)에 따라 개인별 감정상태에 따른 얼굴 사진의 특징점 데이터, 및 개인별 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라낸 영상 패치 기반 데이터가 저장된다. 상기 영상 패치 기반 데이터는 감정 상태에 따른 얼굴 사진의 각 특징점 좌표 중심으로 윈도우(window)로 잘라 낸 컬러 영상들을 각각 얼굴 인식DB에 저장된 얼굴 인식 데이터이며, 상기 윈도우는 3x3 window, 또는 5x5 window를 사용한다. 상기 단계 (d)의 상기 감정 인식 결과 융합부는"}
{"patent_id": "10-2018-0142146", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "과 는 모두 M 차원의 벡터로 M개의 감정 카테고리에 대한 확률 분포를 나타내며, 그렇게 추정된 두 개의 감정 인식 결과 벡터는 감정 인식 결과 융합부로 입력되고, 최종 감정 인식 결과 가 계 산되며, 이는 의 관계식을 통해 특징점 기반 감정 인식 결과 벡터와 영상 패치 기반 감정 인식 결과 벡터의 가중 평균으로 계산될 수 있으며, 여기서 α는 특징점 기반 감정 인식 결과에 대한 가중치를 나타내며, 인식된 감정의 카테고리 는 가장 높은 확률을 가지는 감정의 인덱스 로 계산되어 감정 인 식 시스템의 최종 감정 인식 결과가 출력된다. 상기 감정 인식 시스템은, 얼굴 인식 DC와 출입 관리시의 감정 상태에 따른 얼굴의 특징점 데이터가 저장된 서 버에 얼굴 인식을 사용한 감정 인식 시스템이 구축되며, client/server 방식으로 카메라 영상의 얼굴 인식 시에 PC 또는 스마트폰의 클라이언트 프로그램으로 얼굴 인식 및 상기 감정 인식 결과를 제공한다. 본 발명에 따른 실시예들은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨 터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 기록 매체는 스토리지, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media),플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함될 수 있다. 프로 그램 명령의 예에는 컴파일러에 의해 만들어지는 것과, 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 상기 하드웨어 장치는 본 발명의 동작을 수행하 기 위해 하나 이상의 소프트웨어 모듈로써 작동하도록 구성될 수 있다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에 저장될 수 있다. 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야에서 통상의 지식을 가진자가 하기의 특허 청구범위에 기재된 본 발명의 기술적 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수 정 또는 변형하여 실시할 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2018-0142146", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 얼굴인식장치의 구성도이다. 도 2는 얼굴인식장치의 정규화부를 설명하는 개념도이다. 도 3은 얼굴의 윤곽선, 눈썹과 눈, 코 밑선, 입, 턱을 포함하는 얼굴 특징점들(Facial Landmarks)의 예를 보인 그림이다. 도 4는 본 발명에 따른 감정 인식 시스템의 개요를 보인 도면이다. 도 5는 본 발명의 실시예에 따른 감정 인식 시스템의 블록도이다. 도 6은 인공 신경망 기반의 얼굴 특징점 추출부, 특징점 기반 감정 인식부, 영상 패치 기반의 감정 인식부의 블 록도이다."}
