{"patent_id": "10-2022-7029562", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0125719", "출원번호": "10-2022-7029562", "발명의 명칭": "목표 대상 검측 모델을 트레이닝하는 방법 및 장비, 목표 대상을 검측하는 방법 및 장비, 전", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "왕 샤오디"}}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "목표 대상 검측 모델을 트레이닝하는 방법으로서,복수의 샘플 영상 중 임의의 샘플 영상에 대해,상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 상기 샘플 영상의 복수의 특징맵을 추출하고,상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻고, 상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상의 정보를 얻는 것,상기 목표 대상의 정보 및 상기 샘플 영상의 라벨과 연관된 정보에 기초하여, 상기 목표 대상 검측 모델의 손실을 확정하는 것, 및 상기 손실에 따라, 상기 트레이닝 파라미터를 조정하는 것을 포함하는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 샘플 영상의 복수의 특징맵을 추출하는 것은,상기 샘플 영상에 대해 멀티 해상도 변환을 실행하여, 제1 레벨 특징맵 내지 제N 레벨 특징맵을 각각 얻는 것을포함하고, 여기서, N은 2이상의 정수이고,상기 특징맵을 융합하는 것은,제N 레벨 특징맵부터 시작하여 순차적으로 상기 제N 레벨 특징맵 내지 상기 제1 레벨 특징맵 중의 인접한 두 레벨의 특징맵을 융합하여, 제N 레벨 융합 특징맵 내지 제1 레벨 융합 특징맵을 얻는 것을 포함하는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제N 레벨 특징맵부터 시작하여 순차적으로 상기 제N 레벨 특징맵 내지 상기 제1 레벨 특징맵 중의 인접한두 레벨의 특징맵을 융합하는 것은,제i 레벨 융합 특징맵에 대해 업 샘플링을 실행하여, 업 샘플링된 제i 레벨 융합 특징맵을 얻는 것, 여기서, i는 정수이고, 2 정수 특징이며,제i-1 레벨 특징맵에 대해 1특징 컨볼루션을 실행하여, 컨볼루션된 제i-1 레벨 특징맵을 얻는 것, 및 컨볼루션된 제i-1 레벨 특징맵과 업 샘플링된 제i 레벨 융합 특징맵을 가산하여, 제i-1 레벨 융합 특징맵을 얻는 것을 포함하고,상기 제N 레벨 융합 특징맵은 상기 제N 레벨 특징맵에 대해 1행의 컨볼루션을 실행하여 얻은 것인목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제i 레벨 융합 특징맵에 대해 업 샘플링을 실행하는 것은,상기 제i 레벨 융합 특징맵에 대해 Carafe 연산자 및 변형 가능한 컨볼루션DCN 업 샘플링 동작을 적용하여, 상공개특허 10-2022-0125719-3-기 제i 레벨 융합 특징맵에 대해 업 샘플링을 실행하는 것을 포함하는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,제N 레벨 융합 특징맵 내지 제1 레벨 융합 특징맵을 얻은 후,상기 제1 레벨 융합 특징맵부터 시작하여 순차적으로 상기 제1 레벨 융합 특징맵 내지 제N 레벨 융합 특징맵 중의 인접한 두 레벨의 융합 특징맵에 대해 제2차 융합을 실행하여, 제1 레벨 2차 융합 특징맵 내지 제N 레벨 2차융합 특징맵을 얻는 것을 더 포함하는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제2차 융합을 실행하는 것은,제j 레벨 2차 융합 특징맵에 대해 다운 샘플링을 실행하여, 다운 샘플링된 제j 레벨 2차 융합 특징맵을 얻는것, 여기서, j는 정수이고, 1은 보다 작으며, 제j+1 레벨 융합 특징맵에 대해 3융합 컨볼루션을 실행하여, 컨볼루션된 제j+1 레벨 융합 특징맵을 얻는 것, 및컨볼루션된 제j+1 레벨 융합 특징맵과 다운 샘플링된 제j 레벨 2차 융합 특징맵을 가산하여, 제j+1 레벨 2차 융합 특징맵을 얻는 것을 포함하고,상기 제1 레벨 2차 융합 특징맵은 상기 제1 레벨 융합 특징맵에 대해 3융합 컨볼루션을 실행하여 얻은 것인목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제j 레벨 2차 융합 특징맵에 대해 다운 샘플링을 실행하는 것은,상기 제j 레벨 2차 융합 특징맵에 대해 변형 가능한 컨볼루션DCN 다운 샘플링을 실행하여, 상기 제j 레벨 2차융합 특징맵에 대해 다운 샘플링을 실행하는 것을 포함하는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 샘플 영상의 복수의 특징맵을 추출하기 전에, 상기 샘플 영상을 중첩 전단하여 적어도 2 개의 전단 영상을얻는 것을 더 포함하며,상기 적어도 2 개의 전단 영상 중 임의의 2 개의 전단 영상사이에는 중첩된 영상 구역이 있는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상의 정보를 얻는 것은,상기 적어도 하나의 융합 특징맵을 2 개의 검측 브랜치로 입력하여 목표 대상을 검측함으로써, 목표 대상의 정보를 얻는 것을 포함하고,상기 2 개의 검측 브랜치 중 하나는 상기 목표 대상을 내부에 둘러싼 검측 박스의 좌표 및 검측 박스의 분류 카공개특허 10-2022-0125719-4-테고리를 출력하고, 다른 하나는 목표 대상의 분할 구역 및 분할 결과를 출력하는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 상기 샘플 영상의 복수의 특징맵을 추출하기전에, 샘플 영상의 라벨에 따라 상기 복수의 샘플 영상을 복수의 카테고리로 나누는 것을 더 포함하고,각 카테고리의 샘플 영상에 대해, 상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 상기 샘플영상의 복수의 특징맵을 추출하는 동작을 실행하는목표 대상 검측 모델을 트레이닝하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 방법으로서, 검측하고자 하는 영상의 복수의 특징맵을 추출하는 것,상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻는 것, 및상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상을 검측하는 것을 포함하고,상기 목표 대상 검측 모델은 제1항 내지 제10항 중 어느 한 항의 방법을 사용하여 트레이닝된 것인목표 대상을 검측하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 검측하고자 하는 영상은 드론에 의해 수집된 영상인목표 대상을 검측하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항 또는 제12항에 있어서,상기 검측하고자 하는 영상은 전력망 결함과 연관된 영상인목표 대상을 검측하는 방법."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "목표 대상 검측 모델을 트레이닝하는 장비로서,상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 샘플 영상의 복수의 특징맵을 추출하고, 상기복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻고, 상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상의 정보를 취득하도록 구성된 목표 대상 정보 취득 모듈,상기 목표 대상의 정보 및 상기 샘플 영상의 라벨과 연관된 정보에 기초하여, 상기 목표 대상 검측 모델의 손실을 확정하도록 구성된 손실 확정 모듈, 및 상기 손실에 따라, 상기 트레이닝 파라미터를 조정하도록 구성된 파라미터 조정 모듈을 포함하는목표 대상 검측 모델을 트레이닝하는 장비."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 장비로서,검측하고자 하는 영상의 복수의 특징맵을 추출하도록 구성된 특징맵 추출 모듈,공개특허 10-2022-0125719-5-상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻도록 구성된 특징맵 융합 모듈, 및상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상을 검측하도록 구성된 목표 대상 검측 모듈을 포함하고,상기 목표 대상 검측 모델은 제1항 내지 제10항 중 어느 한 항의 방법을 사용하여 트레이닝된 것인목표 대상을 검측하는 장비."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서와 통신가능하게 연결되는 메모리를 포함하는 전자장비로서,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제11항 중 어느한 항의 방법을 실행하도록 하는전자장비."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 명령이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서,상기 컴퓨터 명령은 상기 컴퓨터로 하여금 제1항 내지 제11항 중 어느한 항의 방법을 실행하도록 하는비 일시적 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2022-7029562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터 프로그램을 포함한 컴퓨터 프로그램 제품으로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제11항 중 어느 한 항의 방법을 구현하는컴퓨터 프로그램 제품."}
{"patent_id": "10-2022-7029562", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 목표 대상 검측 모델의 트레이닝 방법, 목표 대상 검측 방법 및 장비를 개시하고, 인공 지능 분야에 관한 것으로서, 구체적으로는, 컴퓨터 비전 및 딥러닝 기술에 관한 것으로서, 스마트 클라우드 및 전력망 점검 장면에 응용될 수 있다. 트레이닝 방법의 구체적인 구현방안은, 복수의 샘플 영상 중 임의의 하나에 대해, 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 복수의 특징맵을 추출하고, 복수의 특징맵을 융합하여 적 어도 하나의 융합 특징맵을 얻고, 적어도 하나의 융합 특징맵을 사용하여 목표 대상의 정보를 얻는 것, 목표 대 상의 정보 및 샘플 영상의 라벨 정보에 기초하여, 모델의 손실을 확정하는 것, 및 상기 손실에 따라, 트레이닝 파라미터를 조정하는 것을 포함한다."}
{"patent_id": "10-2022-7029562", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2021년 4월 28일에 출원한 출원 번호가 '202110469553.1'인 중국 특허 출원의 우선권을 주장하며, 그 전부 내용을 참조로 인용함으로써 본 출원에 포함시킨다. 본 개시는 인공 지능 분야에 관한 것으로서, 구체적으로는, 컴퓨터 비전 및 딥러닝 기술에 관한 것으로서, 스마 트 클라우드 및 전력망 점검 장면에 응용될 수 있으며, 보다 구체적으로는, 목표 대상 검측 모델의 트레이닝 방 법, 목표 대상 검측 방법 및 장비에 관한 것이다."}
{"patent_id": "10-2022-7029562", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 기술의 발전에 따라, 컴퓨터 비전 기술의 산업 장면에서의 응용은 나날이 풍부해지고 있다. 컴퓨터 비전 기술의 기반으로서, 목표 검측 기술은 인공적으로 진행되는 전통적인 방식에 존재하는 시간 낭비 및 인력 낭비 의 문제점을 해결할 수 있으므로, 광범위한 응용 전망을 갖고 있다. 하지만, 산업 시설의 물리적 결함을 검측할 경우, 결함 종류의 다양화 및 크기의 차이 등 원인으로 인해 검측 결과가 종종 정확하지 못하다. 본 개시는 목표 대상 검측 모델의 트레이닝 방법 및 장비, 목표 대상 검측 방법 및 장비, 및 저장매체를 제공한 다. 본 개시의 한 측면에 의하면, 목표 대상 검측 모델을 트레이닝하는 방법으로서, 복수의 샘플 영상 중 임의의 샘 플 영상에 대해, 상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 상기 샘플 영상의 복수의 특징맵을 추출하고, 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻고, 상기 적어도 하나의 융합 특징맵을 사용하 여 목표 대상의 정보를 얻는 동작, 상기 목표 대상의 정보 및 상기 샘플 영상의 라벨과 연관된 정보에 기초하여, 상기 목표 대상 검측 모델의 손실 을 확정하는 동작, 및 상기 손실에 따라, 상기 트레이닝 파라미터를 조정하는 동작을 실행하는 목표 대상 검측 모델을 트레이닝하는 방법을 제공한다. 본 개시의 다른 측면에 의하면, 목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 방법으로서, 검측하고자 하는 영상의 복수의 특징맵을 추출하는 것, 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻는 것, 및 상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상을 검측하는 것을 포함하고, 상기 목표 대상 검측 모델은 본 개시의 임의의 예시적인 실시예에 따른 방법을 사용하여 트레이닝된 것인 목표 대상을 검측하는 방법을 제공한다. 본 개시의 다른 측면에 의하면, 목표 대상 검측 모델을 트레이닝하는 장비로서, 상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 상기 샘플 영상의 복수의 특징맵을 추출하고, 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻고, 상기 적어도 하나의 융합 특징맵을 사용하 여 목표 대상의 정보를 취득하도록 구성된 목표 대상 정보 취득 모듈, 상기 목표 대상의 정보 및 상기 샘플 영상의 라벨과 연관된 정보에 기초하여, 상기 목표 대상 검측 모델의 손실 을 확정하도록 구성된 손실 확정 모듈, 및 상기 손실에 따라, 상기 트레이닝 파라미터를 조정하도록 구성된 파라미터 조정 모듈을 포함하는 목표 대상 검측 모델을 트레이닝하는 장비를 제공한다. 본 개시의 다른 측면에 의하면, 목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 장비로서, 검측하고자 하는 영상의 복수의 특징맵을 추출하도록 구성된 특징맵 추출 모듈, 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻도록 구성된 특징맵 융합 모듈, 및 상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상을 검측하도록 구성된 목표 대상 검측 모듈을 포함하고, 상기 목표 대상 검측 모델은 본 개시의 임의의 예시적인 실시예에 따른 방법을 사용하여 트레이닝된 것인 목표 대상을 검측하는 장비를 제공한다. 본 개시의 다른 측면에 의하면, 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서와 통신가능하게 연결 되는 메모리를 포함하는 전자장비로서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령 이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세 서로 하여금 본 개시의 실시예에 의해 제공되는 방법을 실행하도록 하는 전자장비를 제공한다. 본 개시의 다른 측면에 의하면, 컴퓨터 명령이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 명령은 상기 컴퓨터로 하여금 본 개시의 실시예에 의해 제공되는 방법을 실행하도록 하는 비 일시적 컴 퓨터 판독가능 저장매체를 제공한다. 본 개시의 다른 측면에 의하면, 컴퓨터 프로그램을 포함한 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램 이 프로세서에 의해 실행될 경우, 본 개시의 실시예에 의해 제공되는 방법을 구현하는 컴퓨터 프로그램 제품을 제공한다. 본 명세서에 기술된 내용은 그 목적이 본 개시의 실시예의 핵심 또는 중요한 특징을 지정하기 위한 것이 아니고, 또한, 본 개시의 범위는 이에 한정되지 아니함을 이해하여야 한다. 본 개시의 다른 특징들은 하기 설명 으로부터 용이하게 이해할 수 있을 것이다."}
{"patent_id": "10-2022-7029562", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 개시의 예시적인 실시예들을 설명한다. 쉽게 이해할 수 있도록, 본 개시의 실시예들 의 세부사항을 포함하게 되는데, 이들은 단지 예시적인 것에 불과하다. 따라서, 당업자라면 본 개시의 범위 및 취지를 벗어나지 않으면서 본 개시의 실시예에 대해 여러가지 변경 및 수정이 이루어질 수 있음을 이해할 것이다. 또한, 명확성과 간결성을 위해 하기의 설명에 있어서, 공지된 기능 및 구성에 대한 설명은 생략한다. 도 1은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델의 트레이닝 방법의 흐름도이다. 통상적으로, 목표 대상 검측 모델을 트레이닝하는 방법은 전반적으로 복수의 샘플 영상을 취득한 후, 상기 목표 대상 검측 모델의 손실이 트레이닝 종료 조건을 만족할 때까지 복수의 샘플 영상을 사용하여 트레이닝을 실행하 는 것을 포함할 수 있다. 도 1에 도시된 바와 같이, 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델을 트레이닝하는 방법은 구체적으로 복수의 샘플 영상 중 임의의 샘플 영상에 대해 단계 S110~단계 S130을 실행하는 것을 포함할 수 있 다. 단계 S110에서는, 상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 상기 샘플 영상의 복수의 특 징맵을 추출하고, 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻고, 상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상의 정보를 얻는다. 특징맵은 영상에 대한 표징으로서, 여러 번의 컨볼루션 계산을 통해 복수의 특징맵을 얻을 수 있다. 특징맵은 컨볼루션 커널의 계산을 거치면서 점점 작아지는데, 상위 층의 특징맵은 비교적 강한 시맨틱 정보를 갖고 있고, 하위 층의 특징맵은 비교적 많은 위치 정보를 갖고 있다. 본 개시는 상기 복수의 특징맵을 융합함으로써, 적어도 하나의 융합 특징맵을 얻을 수 있다. 융합 특징맵은 시맨틱 정보와 위치 정보를 모두 가지고 있다. 따라서, 융합 특징맵을 사용하여 목표 대상을 검측할 경우, 보다 정확한 검측을 실현할 수 있다. 상기 특징맵을 융합하고, 상기 융합 특징맵을 사용하여 목표 대상을 검측함으로써, 목표 대상의 정보를 얻는다. 목표 대상의 정보는 목표 대상을 둘러싸는 검측 박스의 분류 정보, 목표 대상의 중심 위치 좌표 및 스케일 정보 를 포함할 수 있다. 본 개시의 예시적 실시예에서, 목표 대상의 정보는 목표 대상의 분할 구역 및 분할 결과를 더 포함한다. 단계 S120에서는, 상기 목표 대상의 정보 및 상기 샘플 영상의 라벨과 연관된 정보에 기초하여, 상기 목표 대상 검측 모델의 손실을 확정한다. 목표 대상 검측 모델의 손실은 계산 분류 손실, 회귀 박스 손실 및 멀티 브랜치 손실 등을 포함할 수 있다. 예를 들어, 대응하는 손실을 계산하기 위한 손실 함수를 통해 대응하는 손실을 각각 계산하고, 계산된 손실을 합산하여 최종적인 계산 손실을 얻을 수 있다. 단계 S130에서는, 상기 손실에 따라, 상기 트레이닝 파라미터를 조정한다. 예를 들어, 상기 손실이 트레이닝 종 료 조건을 만족하는지 확인한다. 트레이닝 종료 조건은 트레이너가 트레이닝 수요에 따라 설정할 수 있다. 예를 들어, 목표 대상 검측 모델의 손실이 수렴되었는지 및/또는 예정된 손실에 도달했는지에 따라, 목표 대상 검측 모델이 트레이닝을 완료하였는지를 확정할 수 있다. 상기 손실이 트레이닝 종료 조건을 만족하거나 예정된 손실에 도달한 것으로 확정된 것에 응답하여, 상기 목표 대상 검측 모델의 트레이닝이 완료되고, 목표 대상 검측 모델의 트레이닝 방법이 종료된 것으로 간주한다. 그렇 지 않을 경우, 즉, 상기 손실이 트레이닝 종료 조건을 만족하지 않는 것으로 확정될 경우, 해당 트레이닝 방법 은 손실에 따라 트레이닝 파라미터를 조정하고, 다음 트레이닝 영상으로 계속 트레이닝할 수 있다. 본 개시의 예시적 실시예에 따르면, 트레이닝 과정에 목표 검측 모델을 이용하여 샘플 영상의 복수의 특징맵을 추출하고, 상기 복수의 특징맵을 융합하여, 트레이닝된 목표 대상 검측 모델로 하여금 보다 다양한 특징 정보를 얻을 수 있도록 함으로써, 목표 검측의 정확도를 향상시킬 수 있다. 일부 실시예에서는, 트레이닝을 시작하기 전에, 샘플 영상의 라벨에 따라 상기 복수의 샘플 영상을 복수의 카테 고리로 나누고, 각 카테고리의 샘플 영상을 사용하여 목표 대상 검측 모델을 트레이닝할 수 있다. 예를 들어, 상기 단계 S110을 실행하기 전에, 샘플 영상의 라벨에 따라 상기 복수의 샘플 영상을 복수의 카테고리로 나누고, 각 카테고리의 샘플 영상에 대해 단계 S110~단계 S130을 실행할 수 있다. 이러한 방식을 통해, 목표 대 상 검측 모델을 분류하여 트레이닝할 수 있다. 각 카테고리에 대해 목표 대상 검측 모델을 트레이닝할 경우, 각 카테고리의 샘플 영상의 개수를 제어하여, 동일한 카테고리에 속하는 서로 다른 서브 클래스의 라벨에 대해 균 일한 샘플링을 실현하도록 할 수 있다. 전력망 결함 검측 사용될 경우, 결함의 차이성이 매우 크므로, 결함의 크기 유사성에 따라 서로 다른 결함을 분 류하여 서로 다른 카테고리의 라벨을 형성하게 되면, 동일한 라벨 카테고리의 결함은 복수의 서브 클래스를 더 가질 수 있고, 예를 들어, 이러한 서브 클래스는 결함을 야기시키는 원인에 따라 구분될 수 있다. 본 개시의 실 시예는 상기 분류하여 트레이닝하는 방식을 사용함으로써, 트레이닝의 수렴 속도를 가속화하고 트레이닝 효율을 향상시킬 수 있다. 각 라벨 카테고리에 대해 목표 대상 검측 모델을 트레이닝할 경우, 각 서브 클래스에 대해 동적으로 샘플링하는 데이터 샘플링 전략을 통해, 각 서브 클래스의 트레이닝 수량의 차이가 너무 크지 않도록 함으로써, 트레이닝의 수렴 속도를 보다 가속화하고 트레이닝 결과의 정밀도를 향상시킨다. 이하, 도 2a~도 2d를 참조하여 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델이 트레이닝 과정에 실행하 는 동작들을 설명한다. 도 2a는 본 개시의 실시예에 따른 목표 대상 검측 모델이 트레이닝 과정에 실행하는 동작의 흐름도를 도시한다. 도 2a에 도시된 바와 같이, 상기 목표 검측 모델을 이용하여 샘플 영상의 목표 대상에 대한 정보를 취득하는 동 작은 단계 S211~단계 S213을 포함할 수 있다. 단계 S211에서는, 샘플 영상에 대해 멀티 해상도 변환을 실행하여, 제1 레벨 특징맵 내지 제N 레벨 특징맵을 각 각 얻고, 여기서, N은 2이상의 정수이다. 예를 들어, 복수의 컨볼루션 레이어(예를 들어, N개의 컨볼루션 레이 어)를 통해 샘플 영상에 대해 컨볼루션 계산을 실행할 수 있고, 여기서, 각 컨볼루션 레이어는 컨볼루션 커널을 포함한다. 컨볼루션 커널의 컨볼루션 연산을 통해, N개의 특징맵, 즉, 제1 레벨 특징맵 내지 제N 레벨 특징맵을 얻을 수 있다. 단계 S212에서는, 제N 레벨 특징맵부터 시작하여 순차적으로 상기 제N 레벨 특징맵 내지 상기 제1 레벨 특징맵 중의 인접한 두 레벨의 특징맵을 융합하여, 제N 레벨 융합 특징맵 내지 제1 레벨 융합 특징맵을 얻는다. 상위 층의 특징맵은 비교적 강한 시맨틱 정보를 갖고 있고, 하위 층의 특징맵은 비교적 많은 위치 정보를 갖고 있으 므로, 인접한 두 레벨의 특징맵을 융합함으로써, 목표 대상 검측을 위한 융합 특징맵에 보다 다양한 정보가 포 함되도록 함으로써, 검측의 정확도를 향상시킬 수 있다. 단계 S213에서는, 상기 적어도 하나의 융합 특징맵을 사용하여 목표 대상의 정보를 얻는다. 본 개시의 예시적 실시예에서, 목표 대상의 정보는 목표 대상을 둘러싸는 검측 박스의 분류 정보, 목표 대상의 중심 위치 좌표와 스케일 정보, 목표 대상의 분할 구역 및 분할 결과를 포함한다. 본 개시의 실시예에 의하면, 멀티 해상도 변환을 거쳐 얻은 복수의 특징맵을 변환 레벨에 따라 융합함으로써, 계산량을 거의 증가시키지 않으면서 멀티 스케일 물체에 대한 검측 정확도를 향상시킬 수 있어, 복잡한 장면을 포함한 다양한 장면에 응용될 수 있다. 도 2b는 본 개시의 실시예에 따른 목표 대상 검측 모델의 구성 블록도를 도시한다. 도 2b에 도시된 바와 같이, 목표 대상 검측 모델은, 백본(Backbone) 부분, 목(Neck) 부분, 헤드(Head) 부분을 포함할 수 있다. 샘플 영상을 사용하여 목표 대상 검측 모델을 트레이닝할 수 있다. 트레이닝 과정에, 백본 부분을 이용하여 복수의 특징맵을 추출하고, 목 부분을 이용하여 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻고, 헤드 부분을 이용하여 적어도 하나의 융합 특징맵을 사용하여 목표 대상을 검 측하여 목표 대상의 정보를 얻는다. 목표 대상의 정보 및 샘플 영상의 라벨과 연관된 정보에 기초하여, 상기 목표 대상 검측 모델의 손실을 확정할 수 있다. 예를 들어, 목표 대상 검측 모델이 상기 동작을 실행하는 과정에, 백본 부분, 목 부분 및 헤드 부분으로부터 손실 계산과 연관된 정보를 취득할 수 있고, 대응하는 손실 계산 함수를 이용하여 취득한 정보 및 이미 장악한 샘플 영상의 라벨과 연관된 정보에 기초하여, 목표 대상 검측 모델의 손실을 계산 할 수 있다. 손실이 사전에 설정한 수렴 조건을 만족하지 않는다면, 목표 대상 검측 모델에 사용되는 트레이닝 파라미터를 조정하고, 다음 샘플 영상에 대해 다시 트레이닝하는 과정을, 손실이 사전에 설정된 수렴 조건을 만 족할 때까지 반복한다. 이러한 방식을 통해, 목표 대상 검측 모델의 트레이닝을 실현한다. 이하, 목표 검측 모델의 백본(Backbone) 부분, 목(Neck) 부분, 헤드(Head) 부분에 대해 상세하 게 설명한다. 백본 부분은, 샘플 영상에 대한 특징 추출을 실행할 수 있고, 예를 들어, 사전에 설정된 트레이닝 파 라미터를 가진 컨볼루션 신경망을 이용하여 복수의 특징맵을 생성할 수 있다. 구체적으로, 백본 부분은 상 기 샘플 영상에 대해 멀티 해상도 변환을 실행함으로써, 제1 레벨 특징맵 내지 제N 레벨 특징맵 P1, P2…… PN을 각각 얻을 수 있고, 여기서, N은 2이상의 정수이다. 도 2b에서, 3레벨 해상도 변환(N=3)을 예로 들어 목표 대상 검측 모델을 도시한다. 특징맵P1, P2……PN을 추출한 후, 목표 대상 검측 모델이 백본 부분에 의해 추출된 특징맵P1, P2……PN을 그대로 검측 헤드인 헤드 부분으로 보내어 목표 대상을 검측하게 되면, 멀티 스케일 목표 대상에 대한 검 측 능력이 부족할 수 있다. 이에 비해, 본 개시의 실시예에서는, 상기 제1 레벨 특징맵 내지 상기 제N 레벨 특 징맵을 처리함으로써, 서로 다른 단계의 특징맵을 수집할 수 있어, 헤드 부분으로 입력되는 정보를 풍부하 게 할 수 있다. 목 부분은, 상기 제1 레벨 특징맵 내지 상기 제N 레벨 특징맵을 융합할 수 있고, 예를 들어, 제N 레벨 특 징맵부터 시작하여 순차적으로 상기 제N 레벨 특징맵 내지 상기 제1 레벨 특징맵 중의 인접한 두 레벨의 특징맵 을 융합하여, 제N 레벨 융합 특징맵 내지 제1 레벨 융합 특징맵 MN, M(N-1)……M1을 얻을 수 있고, 도 2b에서 N=3이다. 일 실시예에 있어서, 제N 레벨 특징맵부터 시작하여 순차적으로 제N 레벨 특징맵 내지 제1 레벨 특징맵 중의 인 접한 두 레벨의 특징맵을 융합하는 것은, 제i 레벨 융합 특징맵에 대해 업 샘플링을 실행하여, 업 샘플링된 제i 레벨 융합 특징맵을 얻는 것, 여기서, i는 정수이고, 2≤i≤N이며, 제i-1 레벨 특징맵에 대해 1×1 컨볼루션을 실행하여, 컨볼루션된 제i-1 레벨 특징맵을 얻는 것, 및 컨볼루션된 제i-1 레벨 특징맵과 업 샘플링된 제i 레벨 융합 특징맵을 가산하여, 제i-1 레벨 융합 특징맵을 얻는 것을 포함하고, 제N 레벨 융합 특징맵은 제N 레벨 특 징맵에 대해 1×1 컨볼루션을 실행하여 얻은 것이다. 헤드(Head) 부분은, 적어도 하나의 융합 특징맵을 사용하여 목표 대상을 검측함으로써, 목표 대상의 정보 를 얻을 수 있다. 예를 들어, 융합 특징맵 MN, M(N-1)……M1을 사용하여 샘플 영상에 사전에 설정된 카테고리의목표 대상이 존재하는지 확인하고, 목표 대상은 예를 들어 전력망에 존재 가능한 다양한 결함을 포함할 수 있고, 이에 한정되지는 않는다. 도 2c는 본 실시예에 따른 목표 대상 검측 모델을 이용하여 특징맵을 추출하고 특징맵을 융합하는 과정의 개략 도를 도시한다. 도 2c를 참조하면, 백본 부분은 상기 샘플 영상에 대한 멀티 해상도 변환을 통해, 제1 레벨 특징맵P1, 제2 레벨 특징맵P2 및 제3 레벨 특징맵P3을 각각 얻을 수 있다. 이어서, 목 부분에 의해 제1 레벨 특징맵P1 내지 제3 레벨 특징맵P3 중의 인접한 두 레벨의 특징맵을 융합하여, 제3 레벨 융합 특징맵M3 내지 제1 레벨 융합 특징맵M1를 얻는다. 구체적으로, 제N 레벨 융합 특징맵을 제외한 다른 레벨의 융합 특징맵을 얻기 위해, 예를 들어, 제2 레벨 융합 특징맵M2를 얻기 위해, 제3 레벨 융합 특징맵M3에 대해 업 샘플링을 실행하고 제2 레벨 특징맵P2에 대해 1×1 컨볼루션을 실행한 후, 컨볼루션된 제2 레벨 특징맵과 업 샘플링된 제3 레벨 융합 특징맵을 가산하여, 제2 레벨 융합 특징맵을 얻고, 여기서, 제N 레벨 융합 특징맵인 제3 레벨 융합 특징맵M3은 제3 레벨 특징맵에 대해 1×1 컨볼루션을 실행하여 얻은 것이다. 일 실시예에 있어서, 보간 알고리즘을 통해 융합 특징맵에 대한 업 샘플링을 실행할 수 있다. 즉, 기존의 영상 픽셀에 기초하여 적절한 보간 알고리즘을 사용하여 픽셀 포인트 사이에 새로운 요소를 삽입할 수 있다. 또한, 제i 레벨 융합 특징맵에 대해 Carafe 연산자 및 변형 가능한 컨볼루션(Deformable convolution net，DCN) 업 샘플링 동작을 응용하여, 제i 레벨 융합 특징맵에 대해 업 샘플링을 실행할 수도 있다. Carafe는 내용을 감지하 고 특징을 재구성할 수 있는 업 샘플링 방법으로서, 넓은 감지 영역에서 앞뒤 문맥 정보를 융합할 수 있다. 따 라서 전통적인 보간 알고리즘에 비해, Carafe 연산자 및 DCN 업 샘플링 동작을 통해 얻은 특징맵을 사용함으로 써, 앞뒤 문맥 정보를 보다 정확하게 융합할 수 있다. 도 2d는 본 개시의 실시예에 따라 제i 레벨 융합 특징맵 및 제i-1 레벨 특징맵에 기초하여 제i-1 레벨 융합 특 징맵을 얻는 과정의 개략도를 도시한다. 도 2d에 도시된 바와 같이, i=3을 예로 들면, Carafe 연산자 및 DCNv2 연산자를 포함하는 업 샘플링 모듈에 의해 제3 레벨 융합 특징맵M3에 대해 업 샘플링하여, 업 샘플링된 제 3 레벨 융합 특징맵을 얻을 수 있고, 여기서, DCNv2 연산자는 DCN 패밀리 중의 상용 연산자이다. DCNv2 연산자 외에도, 다른 변형 가능한 컨볼루션 연산자를 사용할 수 있다. 또한, 컨볼루션 모듈을 통해 제2 레벨 특징 맵P2에 대해 컨볼루션을 실행하여, 컨볼루션된 제2 레벨 특징맵을 얻는다. 컨볼루션된 제2 레벨 특징맵과 업 샘 플링된 제3 레벨 융합 특징맵을 가산하여, 제2 레벨 융합 특징맵M2을 얻는다. 본 개시의 실시예에 의하면, 컨볼루션된 제i-1 레벨 특징맵과 업 샘플링된 제i 레벨 융합 특징맵을 가산하여, 제i-1 레벨 융합 특징맵을 얻음으로써, 융합 특징맵으로 하여금 서로 다른 해상도, 서로 다른 시맨틱 강도의 특 징을 반영할 수 있도록 하여, 목표 검측의 정확도를 보다 향상시킬 수 있다. 이하, 도 3a~도 3d를 참조하여 본 개시의 다른 실시예에 따른 목표 대상 검측 모델이 트레이닝 과정에 실행하는 동작들을 설명한다. 도 3a는 본 개시의 다른 실시예에 따른 목표 대상 검측 모델이 트레이닝 과정에 실행하는 동작의 흐름도를 도시 한다. 도 3a에 도시된 바와 같이, 목표 검측 모델이 샘플 영상 중의 목표 대상에 대한 정보를 취득하는 동작은 단계 S311~단계 S313을 포함할 수 있다. 단계 S311에서는, 샘플 영상에 대해 멀티 해상도 변환을 실행하여, 제1 레벨 특징맵 내지 제N 레벨 특징맵을 각 각 얻는다. 상기 제1 레벨 특징맵 내지 제N 레벨 특징맵은, N개의 컨볼루션 레이어를 통해 샘플 영상에 대해 컨 볼루션 계산을 실행하여 얻을 수 있다. 단계 S3121에서는, 제N 레벨 특징맵부터 시작하여 순차적으로 상기 제N 레벨 특징맵 내지 상기 제1 레벨 특징맵 중의 인접한 두 레벨의 특징맵을 융합하여, 제N 레벨 융합 특징맵 내지 제1 레벨 융합 특징맵을 얻음으로써, 목 표 대상 검측을 위한 융합 특징맵으로 하여금 보다 다양한 정보를 포함하도록 한다. 지적해두어야 할 것은, 단계 S311 및 단계 S3121은 각각 상기 단계 S211 및 단계 S212와 동일할 수 있으므로, 여기서는 설명을 생략한다. 이하, 단계 S3122에 대해 상세하게 설명한다. 단계 S3122에서는, 제1 레벨 융합 특징맵 내지 제N 레벨 융합 특징맵M1, M2……MN을 얻은 후, 제1 레벨 융합 특 징맵부터 시작하여 순차적으로 제1 레벨 융합 특징맵 내지 제N 레벨 융합 특징맵 중의 인접한 두 레벨의 융합 특징맵에 대해 제2차 융합을 실행하여, 제1 레벨 2차 융합 특징맵 내지 제N 레벨 2차 융합 특징맵Q1, Q2……QN을 얻는다. 이렇게 함으로써, 최상위 층의 융합 특징맵도 하위 층으로부터 제공된 풍부한 위치 정보를 공유할 수 있어, 큰 물체에 대한 검측 효과를 향상시킬 수 있다. 단계 S313에서는, 상기 적어도 하나의 2차 융합 특징맵을 사용하여 목표 대상의 정보를 얻는다. 단계 S313은 앞 에서 설명한 단계 S213 과 동일할 수 있으므로, 여기서는 설명을 생략한다. 본 개시의 실시예에 의하면, 특징맵에 대해 2회의 융합을 실행하여, 최상위 층의 특징맵으로 하여금 하위 층의 위치 정보를 포함도록 함으로써, 목표 대상에 대한 검측 정확도를 향상시킬 수 있다. 도 3b는 본 개시의 다른 실시예에 따른 목표 대상 검측 모델의 구성 블록도를 도시한다. 도 3b에 도시된 목표 대상 검측 모델은 상기의 목표 대상 검측 모델과 유사하며, 적어도 목표 대상 검측 모델은 제1 레벨 특징맵 내지 제N 레벨 특징맵P1, P2……PN에 대해 2회의 융합을 실행하는데 차이점이 있다. 설명을 간략화 하기 위해, 이하, 양자의 차이점에 대해서만 상세하게 설명한다. 도 3b에 도시된 바와 같이, 목표 대상 검측 모델은, 백본 부분, 목 부분 및 헤드 부분을 포함한다. 백본 부분 및 헤드 부분은 각각 앞에서 설명한 백본 부분 및 헤드 부분과 동일 할 수 있으므로, 여기서는 설명을 생략한다. 목 부분은 제1 융합 브랜치(320a) 및 제2 융합 브랜치(320b)를 포함한다. 제1 융합 브랜치(320a)는 제N 레 벨 융합 특징맵 내지 제1 레벨 융합 특징맵을 얻기 위한 것일 수 있다. 제2 융합 브랜치(320b)는 제1 레벨 융합 특징맵부터 시작하여 순차적으로 제1 레벨 융합 특징맵 내지 제N 레벨 융합 특징맵 중의 인접한 두 레벨의 융합 특징맵에 대해 제2차 융합을 실행하여, 제1 레벨 2차 융합 특징맵 내지 제N 레벨 2차 융합 특징맵Q1, Q2……QN 을 얻기 위한 것이다. 도 3c는 본 개시의 다른 실시예에 따라 제i 레벨 융합 특징맵 및 제i-1 레벨 특징맵에 기초하여 제i-1 레벨 융 합 특징맵을 얻는 과정의 개략도를 도시한다. 도 3c에 도시된 바와 같이, 업 샘플링 모듈(321a) 및 컨볼루션 모 듈을 포함하는 제1 융합 브랜치(320a)에 의해 복수의 특징맵P1, P2 및 P3에 대한 융합을 실행하여 융합 특 징맵M1, M2 및 M3을 얻고, 제2 융합 브랜치(320b)에 의해 제2차 융합을 실행하여, 2차 특징맵Q1, Q2 및 Q3을 얻 는다. 제2차 융합을 실행하는 것은, 제1 융합 브랜치(320a)를 통해 제N 레벨 융합 특징맵 내지 제1 레벨 융합 특징맵을 얻은 후, 제j+1 레벨 2차 융합 특징맵Q(j+1)(j는 정수이고, 1≤j＜N)를 얻기 위해, 제j 레벨 2차 융합 특징맵Qj에 대해 다운 샘플링을 실행하고, 제j+1 레벨 융합 특징맵M(j+1)에 대해 3×3 컨볼루션을 실행한 다음, 컨볼루션된 제j+1 레벨 융합 특징맵과 다운 샘플링된 제j 레벨 2차 융합 특징맵을 가산하여, 제j+1 레벨 2차 융 합 특징맵Q(j+1)을 얻고, 여기서, 제1 레벨 2차 융합 특징맵Q1은 제1 레벨 융합 특징맵에 대해 3×3 컨볼루션을 실행하여 얻은 것이다. 구체적으로, 제1 레벨 2차 융합 특징맵을 제외한 다른 레벨의 2차 융합 특징맵을 얻기 위해, 예를 들어, 제2 레 벨 2차 융합 특징맵Q2을 얻기 위해, 제1 레벨 2차 융합 특징맵Q1에 대해 다운 샘플링을 실행하고, 제2 레벨 융 합 특징맵M2에 대해 3×3 컨볼루션을 실행한 다음, 컨볼루션된 제2 레벨 융합 특징맵과 다운 샘플링된 제3 레벨 2차 융합 특징맵을 가산하여, 제2 레벨 2차 융합 특징맵Q2를 얻을 수 있고, 여기서, 제1 레벨 2차 융합 특징맵 Q1은 도 3c에 도시된 바와 같이 제1 레벨 융합 특징맵M1에 대해 3×3 컨볼루션을 실행하여 얻은 것이다. 일 실시예에 있어서, 풀링 동작을 이용함으로써 2차 융합 특징맵에 대한 다운 샘플링을 실행할 수 있다. 또한, 제j 레벨 2차 융합 특징맵에 대해 변형 가능한 컨볼루션DCN 다운 샘플링을 적용함으로써, 제j 레벨 2차 융합 특 징맵에 대해 다운 샘플링을 실행할 수도 있다. 도 3d는 본 개시의 다른 실시예에 따라 제i 레벨 융합 특징맵 및 제i-1 레벨 특징맵에 기초하여 제i-1 레벨 융 합 특징맵을 얻는 과정의 개략도를 도시한다. 도 3d에 도시된 바와 같이, 제2 레벨 2차 융합 특징맵Q2를 얻기 위해, 3×3dCNv2 Stride2로 구현된 다운 샘플링 모듈(321b)을 통해 제1 레벨 2차 융합 특징맵Q1에 대해 다운 샘 플링을 실행하여, 다운 샘플링된 제1 레벨 2차 융합 특징맵을 얻는다. 또한, 컨볼루션 모듈(322b)을 통해 제2 레벨 융합 특징맵M2에 대해 컨볼루션을 실행하여, 컨볼루션된 제2 레벨 융합 특징맵을 얻는다. 마지막으로, 컨 볼루션된 제2 레벨 융합 특징맵과 다운 샘플링된 제1 레벨 2차 융합 특징맵을 가산하여, 제2 레벨 2차 융합 특 징맵Q2을 얻는다. 본 개시의 실시예에 의하면, 특징맵에 대해 2회의 융합을 실행하여, 최상위 층의 특징맵으로 하여금 하위 층의 위치 정보를 포함하도록 함으로써, 목표 대상에 대한 검측 정확도를 향상시킬 수 있다. 일부 실시예에서는, 샘플 영상에 대해 특징을 추출하기 전에, 추가적으로 샘플 영상에 대해 전처리를 실행할 수 도 있다. 예를 들어, 샘플 영상의 특징맵을 추출하기 전에, 샘플 영상을 중첩 전단하여 적어도 2 개의 전단 영 상을 얻을 수 있고, 여기서, 적어도 2 개의 전단 영상 중 임의의 2 개의 전단 영상사이에는 중첩된 영상 구역이 있다. 도 4는 본 개시의 예시적 실시예에 따른 샘플 영상을 중첩 전단하는 개략도를 도시한다. 도 4에 도시된 바와 같이, 드론, 리모트 센싱 등 응용장면에서, 촬영된 샘플 영상의 크기가 너무 크면, 크기가 비교적 작은 목표 대상을 검측 인식하지 못할 수 있다. 예를 들어, 샘플 영상에서 목표 대상(T)이 전체 영 상에서 차지하는 비율이 상대적으로 작으므로, 검측하기 어려울 수 있다. 본 개시의 실시예에 의하면, 샘플 영 상을 4개의 전단 영상 40-1 내지 40-4으로 중첩 전단할 수 있고, 전단 영상 40-1 내지 40-4의 가장자리 사 이에는 중첩된 영상 구역이 있다. 이렇게 함으로써, 목표 대상(T)은 복수의 전단 영상에 나타날 수 있는데, 예 를 들어, 전단 영상40-1, 전단 영상 40-2 및 전단 영상40-4에 나타날 수 있다. 샘플 영상에 비해, 목표 대 상(T)이 전단 영상40-1, 40-2 및 40-4에서 차지하는 비율이 더 크다. 전단 영상40-1 내지 40-4를 이용하여 목표 대상 검측 모델을 트레이닝함으로써, 작은 목표 대상에 대한 목표 대상 트레이닝 모델의 검측 능력을 보다 향상 시킬 수 있다. 또한, 검측 능력을 향상시키기 위해, 상기의 임의의 실시예에 따른 목표 대상 검측 모델의 헤드 부분에 다른 브 랜치를 더 추가하여, 목표 대상의 분할 정보를 검측할 수도 있다. 도 5는 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델의 헤드 부분에 대한 개략도를 도시한다. 도 5에 도시된 바와 같이, 융합된 특징맵(예를 들어, 융합 특징맵Mi 또는 2차 융합 특징맵Qi)은 헤드 부분 에 입력되고, 여기서, 헤드 부분은 2 개의 브랜치 (531, 532)를 포함할 수 있고, 브랜치는 목표 대상을 내 부에 둘러싼 검측 박스의 좌표와 검측 박스의 분류 카테고리의 브랜치 구조를 검측하기 위한 것이고, 브랜치 는 목표 대상의 분할 구역 및 분할 결과를 출력하기 위한 것이다. 브랜치는 5개의 컨볼루션 레이어와 1개의 예측 레이어로 구성된 브랜치 구조로서, 분할 정보를 포함하는 영상을 출력하고, 여기서, 5개의 컨볼루션 레이어는 4개의 14×14×256 컨볼루션 레이어(14×14×256 Convs) 및 1개의 28×28×256 컨볼루션 레이어(28× 28×256 Conv)를 포함한다. 즉, 상기와 같이 처리된 특징맵을 2 개의 검측 브랜치를 포함하는 헤드 부분에 입력 하여 목표 대상을 검측하고, 2 개의 검측 브랜치 중 하나는 목표 대상을 내부에 둘러싼 검측 박스의 좌표 및 검 측 박스의 분류 카테고리를 출력하고, 다른 하나는 목표 대상의 분할 구역 및 분할 결과를 출력한다. 이러한 방식을 통해, 보다 많은 목표 대상의 정보를 출력할 수 있고, 출력된 분할 정보는 네트워크 파라미터의 러닝을 모니터링할 수 있고, 각 브랜치의 목표 검측의 정확도를 향상시킴으로써, 직접 분할 구역을 통해 형상이 고정적이지 않는 결함에 대해 포지셔닝 인식을 실행하는 것을 지원할 수 있다. 본 개시의 다른 측면에 의하면, 목표 대상을 검측하는 방법을 더 제공한다. 도 6은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 방법의 흐름도를 도시한다. 단계 S610에서는, 목표 대상 검측 모델을 사용하여, 검측하고자 하는 영상의 복수의 특징맵을 추출한다. 목표 대상 검측 모델은 상기 실시예에 따른 트레이닝 방법을 통해 트레이닝된 목표 대상 검측 모델일 수 있다. 목표 대상 검측 모델은 상기 임의의 실시예에서 설명한 신경망 구조를 사용할 수 있다. 검측하고자 하는 영상은 드론 에 의해 수집된 영상일 수 있다. 또한, 본 개시의 예시적 실시예에 따른 목표 대상을 검측하는 방법이 전력망 결함을 검측하는데 사용될 경우, 검측하고자 하는 영상은 전력망 결함과 연관된 영상이다. 목표 대상 검측 모델 을 이용하여 검측하고자 하는 영상의 복수의 특징맵을 추출하는 방식은 상기 트레이닝 방법 중의 특징을 추출하 는 방식과 동일할 수 있으며, 여기서는 설명을 생략한다. 단계 S620에서는, 상기 목표 대상 검측 모델에 의해 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵 을 얻음으로써, 목표 대상에 관한 보다 다양한 정보를 포함하는 융합 특징맵을 얻을 수 있다. 목표 대상 검측 모델을 이용하여 상기 복수의 특징맵을 융합하는 방식은 상기 트레이닝 방법 중의 융합 방식과 동일할 수 있으 며, 여기서는 설명을 생략한다. 단계 S630에서는, 목표 대상 검측 모델에 의해 적어도 하나의 융합 특징맵을 사용하여 목표 대상을 검측한다. 목표 대상 검측 모델을 이용하여 목표 대상을 검측하는 방식은 상기 트레이닝 방법 중의 융합 방식과 동일할 수 있으며, 여기서는 설명을 생략한다. 또한, 본 개시의 예시적 실시예에 따라 트레이닝된 목표 대상 검측 모델을 이용하여 목표 대상을 검측할 경우, 상기 검측하고자 하는 영상에 대해 전처리를 실행할 수도 있고, 상기 전처리는 검측하고자 하는 영상을 원 영상 의 2배로 업 샘플링한 다음, 목표 대상 검측 모델로 전송하여 목표 대상을 검측하는 것을 포함할 수 있고, 이에 한정되지는 않는다.본 개시의 실시예에 의하면, 목표 대상 검측 모델을 사용하여 검측하고자 하는 영상의 복수의 특징맵을 추출하 고, 상기 복수의 특징맵을 융합하여, 보다 다양한 특징 정보를 얻을 수 있도록 함으로써, 목표 검측의 정확도를 향상시킬 수 있다. 도 7은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델을 트레이닝하는 장비의 블록도를 도시한다. 도 7에 도시된 바와 같이, 상기 장비는 목표 대상 정보 취득 모듈, 손실 확정 모듈 및 파라미터 조정 모듈을 포함할 수 있다. 목표 대상 정보 취득 모듈은, 상기 목표 대상 검측 모델을 이용하여 트레이닝 파라미터에 따라 상기 샘플 영상의 복수의 특징맵을 추출하고, 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻고, 상기 적 어도 하나의 융합 특징맵을 사용하여 목표 대상의 정보를 취득하도록 구성된다. 본 개시의 예시적 실시예에서, 목표 대상의 정보는 목표 대상을 둘러싸는 검측 박스의 분류 정보, 목표 대상의 중심 위치 좌표와 스케일 정보, 목표 대상의 분할 구역 및 분할 결과를 포함한다. 손실 확정 모듈은, 상기 목표 대상의 정보 및 상기 샘플 영상의 라벨과 연관된 정보에 기초하여, 상기 목 표 대상 검측 모델의 손실을 확정하도록 구성된다. 목표 대상 검측 모델의 손실은 계산 분류 손실, 회귀 박스 손실 및 멀티 브랜치 손실 등을 포함할 수 있다. 예를 들어, 대응하는 손실을 계산하기 위한 공지의 손실 함수 를 통해 대응하는 손실을 각각 계산하고, 계산된 손실을 합산하여 손실을 얻을 수 있다. 파라미터 조정 모듈은, 상기 손실에 따라, 상기 트레이닝 파라미터를 조정하도록 구성된다. 예를 들어, 손 실이 트레이닝 종료 조건을 만족하는지를 확인할 수 있다. 트레이닝 종료 조건은 트레이너가 트레이닝 수요에 따라 설정할 수 있다. 예를 들어, 파라미터 조정 모듈은 목표 대상 검측 모델의 손실이 수렴되었는지 및/ 또는 예정된 값에 도달하였는지에 따라, 목표 대상 검측 모델의 트레이닝 완료 여부를 확정할 수 있다. 본 개시의 예시적 실시예에 의하면, 트레이닝 과정에 목표 검측 모델을 이용하여 샘플 영상의 복수의 특징맵을 추출하고, 상기 복수의 특징맵을 융합하여, 트레이닝된 목표 대상 검측 모델이 보다 다양한 특징 정보를 얻을 수 있도록 함으로써, 목표 대상 검측 모델의 목표 검측의 정확도를 향상시킬 수 있다. 도 8은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 장비의 블 록도를 도시한다. 도 8에 도시된 바와 같이, 목표 대상을 검측하는 장비는 특징맵 추출 모듈, 특징맵 융합 모듈 및 목표 대상 검측 모듈을 포함할 수 있다. 특징맵 추출 모듈은, 목표 대상 검측 모델을 이용하여 검측하고자 하는 영상의 복수의 특징맵을 추출하도 록 구성된다. 상기 목표 대상 검측 모델은 본 개시의 예시적 실시예에 따른 트레이닝 방법 및/또는 장비에 의해 트레이닝된 것일 수 있다. 상기 검측하고자 하는 영상은 드론에 의해 수집된 영상일 수 있다. 또한, 본 개시의 예시적 실시예에 따른 목표 대상을 검측하는 방법이 전력망 결함을 검측하는데 사용될 경우, 검측하고자 하는 영상은 전력망 결함과 연관된 영상이다. 특징맵 융합 모듈은, 상기 목표 대상 검측 모델을 사용하여 상기 복수의 특징맵을 융합하여 적어도 하나의 융합 특징맵을 얻도록 구성된다. 목표 대상 검측 모듈은, 상기 목표 대상 검측 모델을 이용하여 상기 적어도 하나의 융합 특징맵을 사용하 여 목표 대상을 검측하도록 구성된다. 본 개시의 실시예에 의하면, 목표 대상 검측 모델을 이용하여 검측하고자 하는 영상의 복수의 특징맵을 추출하 고, 상기 복수의 특징맵을 융합하여, 보다 다양한 특징 정보를 얻을 수 있도록 함으로써, 목표 검측의 정확도를 향상시킬 수 있다. 본 개시의 기술방안에서 언급된 사용자의 개인정보의 취득, 저장 및 응용 등은 모두 관련 법률, 법규의 규정에 부합되고, 공중도덕에 위배되지 않는다. 본 개시의 실시예에 의하면, 본 개시는 전자장비, 판독가능 저장매체 및 컴퓨터 프로그램 제품을 더 제공하며, 검측하고자 하는 영상의 복수의 특징맵을 추출하고, 상기 복수의 특징맵을 융합하여, 보다 다양한 특징 정보를 얻을 수 있도록 함으로써, 목표 검측의 정확도를 향상시킬 수 있다. 도 9는 본 개시의 실시예들을 실시하기 위한 예시적인 전자장비의 개략적인 블록도이다. 전자장비는 예를 들어, 랩탑 컴퓨터, 데스크 탑 컴퓨터, 워크스테이션, PDA(Personal Digital Assistants), 서버, 블레이드 서 버, 메인프레임 컴퓨터, 및 기타 적절한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 포함할 수 있다. 전자장 비는 예를 들어, PDA(Personal Digital Assistants), 셀룰러 전화기, 스마트 폰, 웨어러블 장비, 및 기타 유사 한 계산 장치와 같은 다양한 형태의 모바일 장치를 포함할 수 있다. 본 명세서에 기재된 부품, 이들의 연결 및 관계, 그리고 이들의 기능은 단지 예시적인 것에 불과하며, 본 명세서에서 설명 및/또는 요구하는 본 개시의 범 위를 한정하기 위한 것이 아니다. 도 9에 도시된 바와 같이, 장비는 ROM(Read Only Memory)에 저장된 컴퓨터 프로그램 또는 저장수단 으로부터 RAM(Random Access Memory)에 로딩된 컴퓨터 프로그램에 따라 각종 적당한 동작 및 처리를 실행할 수 있는 계산수단을 포함한다. 또한, RAM에는 장비의 동작에 필요한 다양한 프로그램 및 데이터가 더 저장될 수 있다. 계산수단, ROM 및 RAM은 버스라인을 통해 서로 연결된다. 입 력/출력(I/O) 인터페이스도 버스라인에 연결된다. 장비중의 복수의 부품은 I/O 인터페이스에 연결되고, 상기 부품에는, 예를 들어 키보드, 마우스 등과 같은 입력수단, 예를 들어 각종 유형의 디스플레이, 스피커 등과 같은 출력수단, 예를 들어 자기 디 스크, 광 디스크 등과 같은 저장수단, 및 예를 들어 네트워크 카드, 모뎀, 무선 통신 송수신기 등과 같은 통신수단이 포함된다. 통신수단에 의해, 장비는 인터넷과 같은 컴퓨터 네트워크 및/또는 각종 전자통신망을 통해 다른 장비와 정보/데이터를 교환할 수 있다. 계산수단은 처리 기능 및 계산 기능을 가진 각종 범용 및/또는 주문형 처리 어셈블리일 수 있다. 계산수단 의 일부 실시예로서는, 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 각종 주문형 인공지능(AI) 컴퓨팅 칩, 각종 머신 러닝 모델 알고리즘을 운행하는 계산수단, 디지털 신호 프로세서(DSP), 및 임의의 적합한 프로세 서, 컨트롤러, 마이크로 컨트롤러 등이 포함될 수 있는데, 이에 한정되지는 않는다. 계산수단은 앞에서 설 명한 각 방법 및 단계를 실행하는데, 예를 들어, 도 1 내지 도 6에 도시된 방법 및 단계를 실행한다. 예를 들어, 일부 실시예에 있어서, 도 1 내지 도 6에 도시된 방법 및 단계는 예를 들어 저장수단과 같은 기계 판독가능 매체에 포함되는 컴퓨터 소프트웨어 프로그램의 형태로 실현될 수 있다. 일부 실시예에 있어서, 컴퓨 터 프로그램의 일부 또는 전부는 ROM 및/또는 통신수단을 거쳐 장비에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 계산수단에 의해 실행될 경우, 앞에서 설명한 목표 대상 검 측 모델을 트레이닝하기 위한 방법 및/또는 목표 대상을 검측하기 위한 방법의 하나 또는 복수의 단계를 실행할 수 있다. 선택적으로, 다른 실시예에 있어서, 계산수단은 다른 임의의 적합한 방식(예를 들어, 펌웨어)을 통해 상기와 같은 목표 대상 검측 모델을 트레이닝하기 위한 방법 및/또는 목표 대상을 검측하기 위한 방법을 실행하도록 구성될 수 있다. 상기에서 설명한 시스템 및 기술의 다양한 실시 형태는 디지털 전자 회로 시스템, 집적 회로 시스템, FPGA(Field Programmable Gate Array), ASIC(Application Specific Integrated circuit), ASSP(Application Specific Standard Product), SOC(System on Chip), CPLD(Complex Programmable Logic Device), 컴퓨터 하드 웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합으로 구현될 수 있다. 이러한 다양한 실시형태는 하나 또는 복 수의 컴퓨터 프로그램을 통해 구현될 수 있고, 상기 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그 램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 주문형 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력장치, 및 적 어도 하나의 출력장치로부터 데이터 및 명령을 수신하고, 데이터 및 명령을 저장 시스템, 적어도 하나의 입력장 치, 및 적어도 하나의 출력장치로 전송할 수 있다. 본 개시의 방법을 실시하기 위한 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합을 통해 프 로그래밍을 실행할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 주문형 컴퓨터 또는 다른 프로그래밍 가능한 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행 됨으로써, 흐름도 및/또는 블록도에서 규정한 기능/동작을 실시하도록 할 수 있다. 프로그램 코드는 전부 머신 에 의해 실행되거나 또는 부분적으로 머신에 의해 실행될 수 있고, 또는 독립적인 소프트웨어 패키지로서 부분 적으로 머신에 의해 실행됨과 동시에 부분적으로 원격 머신에 의해 실행되거나, 또는 전부 원격 머신 또는 서버 에 의해 실행될 수 있다. 본 명세서에 있어서, 기계 판독가능 매체는 실체적인 매체일 수 있고, 상기 매체에는 명령 실행 시스템, 장치 또는 장비에 의해 사용되거나 또는 명령 실행 시스템, 장치 또는 장비와 결합하여 사용되는 프로그램이 포함되 거나 저장될 수 있다. 기계 판독가능 매체는 기계 판독가능 신호 매체 또는 기계 판독가능 저장매체일 수 있다.기계 판독가능 신호 매체는, 전자적, 자기적, 광학적, 전자기적, 적외선적 반도체 시스템, 장치 또는 장비, 또 는 이들의 임의의 적합한 조합을 포함할 수 있는데, 이에 한정되지는 않는다. 기계 판독가능 저장매체의 보다 구체적인 실시예로는, 하나 또는 복수의 라인에 의해 전기적으로 연결되는 휴대용 컴퓨터 디스크, 하드 디스크, RAM, ROM, EPROM(Erasable Programming ROM), 플래시 메모리, 광 파이버, CD-ROM, 광학적 저장 장비, 자기적 저장 장비, 또는 이들의 임의의 적합한 조합일 수 있다. 사용자와의 인터액션을 제공하기 위해서는, 컴퓨터를 통해 본 명세서에서 설명한 시스템 및 기술을 구현할 수 있는데, 상기 컴퓨터는, 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 디스플레이) 모니터), 및 사용자가 상기 컴퓨터에 입력을 제공할 수 있는 키보드 및 포인팅 디바이스(예를 들어, 마우스 또는 트랙 볼)를 포함한다. 기타 유형의 디바이스도 사용자와의 인터액션을 제공하는데 사용될 수 있다. 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피 드백, 또는 촉각 피드백)일 수 있고, 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력을 포함)로 사용자로부 터의 입력을 수신할 수 있다. 본 명세서에서 설명한 시스템 및 기술은, 백 그라운드 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서 버), 또는 미들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 앤드 부품을 포함하는 컴퓨팅 시스템(예를 들어, GUI 또는 웹 브라우저를 갖는 사용자 컴퓨터로서, 사용자는 상기 GUI 또는 상기 웹 브라우저를 통하여 본 명세서에서 설명한 상기 시스템 및 기술의 실시 형태와 인터액션을 할 수 있음), 또는 이러한 백 그라운드 부품, 미들웨어 부품, 또는 프론트 앤드 부품의 임의의 조합을 포함하는 컴퓨팅 시스 템에서 구현될 수 있다. 시스템의 부품은 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워 크)을 통해 서로 연결될 수 있다. 통신 네트워크는 예를 들어 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷 을 포함할 수 있다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통상적으로 통신 네트워크를 통해 인터액션을 진행한다. 클라이언트와 서버의 관계는 대응하는 컴퓨터에서 실행되고 서로 클라이언트-서버의 관계를 갖는 컴퓨터 프로그램에 의해 생성된다. 서버는 클라우드 서브일 수도 있고, 분포식 시스템의 서버 또는 블록체인과 결합된 서버일 수도 있다. 상기에서 설명한 다양한 프로세스를 사용하여 각 단계의 순서를 조정하거나, 일부 단계를 추가 또는 삭제 할 수 있다는 점을 이해하여야 한다. 예를 들어, 본 개시에 개시된 기술방안이 원하는 결과를 구현할 수 있는 한, 본 개시에 기재된 다양한 단계는 병렬적으로 또는 순차적으로, 또는 서로 다른 순서로 실행될 수 있고, 본 개시는 이에 대해 특별히 한정하지 않는다. 본 개시의 보호범위는 상기 다양한 실시 형태에 의해 제한되지 않는다. 당업자라면, 설계 요구 및 기타 요소에 의해, 다양한 수정, 조합, 서브 조합 및 교체가 이루어질 수 있음을 이해할 것이다. 본 개시의 취지 및 원칙내 에서 이루어진 임의의 수정, 등가 교체 및 개선 등은 모두 본 개시의 보호범위에 속한다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면3a 도면3b 도면3c 도면3d 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2022-7029562", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부 도면은 본 기술방안을 보다 쉽게 이해하도록 하기 위한 것이고, 본 개시는 이에 한정되지 않는다. 도 1은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델의 트레이닝 방법의 흐름도이다. 도 2a는 본 개시의 실시예에 따른 목표 대상 검측 모델이 트레이닝 과정에 실행하는 동작의 흐름도를 도시한다. 도 2b는 본 개시의 실시예에 따른 목표 대상 검측 모델의 구성 블록도를 도시한다. 도 2c는 본 실시예에 따른 목표 대상 검측 모델을 이용하여 특징맵을 추출하고 특징맵을 융합하는 과정의 개략 도를 도시한다. 도 2d는 본 개시의 실시예에 따라 제i 레벨 융합 특징맵 및 제i-1 레벨 특징맵에 기초하여 제i-1 레벨 융합 특 징맵을 얻는 과정의 개략도를 도시한다. 도 3a는 본 개시의 다른 실시예에 따른 목표 대상 검측 모델이 트레이닝 과정에 실행하는 동작의 흐름도를 도시 한다. 도 3b는 본 개시의 다른 실시예에 따른 목표 대상 검측 모델의 구성 블록도를 도시한다. 도 3c는 본 개시의 다른 실시예에 따라 제i 레벨 융합 특징맵 및 제i-1 레벨 특징맵에 기초하여 제i-1 레벨 융 합 특징맵을 얻는 과정의 개략도를 도시한다. 도 3d는 본 개시의 다른 실시예에 따라 제i 레벨 융합 특징맵 및 제i-1 레벨 특징맵에 기초하여 제i-1 레벨 융 합 특징맵을 얻는 과정의 개략도를 도시한다. 도 4는 본 개시의 예시적 실시예에 따른 샘플 영상을 중첩 전단하는 개략도를 도시한다. 도 5는 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델의 헤드 부분에 대한 개략도를 도시한다. 도 6은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 방법의 흐름도 를 도시한다. 도 7은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델을 트레이닝하는 장비의 블록도를 도시한다. 도 8은 본 개시의 예시적 실시예에 따른 목표 대상 검측 모델을 사용하여 목표 대상을 검측하는 장비의 블록도 를 도시한다. 도 9는 본 개시의 실시예를 구현하기 위한 전자장비의 다른 실시예의 블록도이다."}
