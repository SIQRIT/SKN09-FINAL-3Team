{"patent_id": "10-2023-0066511", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0043659", "출원번호": "10-2023-0066511", "발명의 명칭": "데이터 처리 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "자첸 위"}}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "타겟 데이터를 획득하는 단계;훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하는 단계;상기 타겟 증강 작업 시퀀스에 따라 상기 타겟 데이터에 대해 데이터 증강을 수행하는 단계; 및증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를 진행하여상기 타겟 데이터에 대응하는 예측 결과를 획득하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 타겟 증강 작업 시퀀스는,캐스케이드된 적어도 2개의 증강 작업을 포함하는데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 훈련된 제1 모델은, 상기 타겟 데이터의 첫 번째 처리의 상태 특징을 결정하는 제1 네트워크;현재 반복의 상태 특징에 기초하여 현재 반복에 대응하는 타겟 증강 작업을 결정하는 제2 네트워크; 및상기 현재 반복의 상태 특징 및 상기 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하는 제3 네트워크를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하는 단계는,현재 반복에 해당하는 타겟 증강 작업이 무작업을 제외한 증강 작업인 경우, 상기 제3 네트워크를 통해 현재 반복의 상태 특징 및 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하는 단계;및상기 제2 네트워크를 통해 기설정된 반복 종료 조건이 만족될 때까지 상기 다음 반복의 상태 특징을 기반으로다음 반복의 타겟 증강 작업을 결정하여 적어도 하나의 타겟 증강 작업 시퀀스를 출력하는 단계공개특허 10-2024-0043659-3-를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 반복 종료 조건은,모든 반복에 대응하는 타겟 증강 작업이 무작업인 경우, 및반복 횟수가 기설정된 최대 반복 횟수에 도달한 경우중 적어도 하나를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 제2 네트워크를 통해 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하는 단계는,상기 제2 네트워크를 통해 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 출력 벡터를 결정하는 단계; 및상기 다음 반복의 출력 벡터에서 기설정된 조건을 만족하는 벡터에 대응하는 증강 작업을 다음 반복의 타겟 증강 작업으로 결정하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하는 단계는,현재 반복에서 결정된 타겟 증강 작업이 N개를 포함하고 N은 1보다 큰 정수인 경우,각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 하나의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족될때까지 반복을 순차적으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하는 단계; 또는각 타겟 증강 작업 및 사익 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 N개의 타겟 증강 작업을 결정하고, 결정된 N*N개의 증강 작업에서 N개의증강 작업을 다음 반복의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족될 때까지 반복을 순차적으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하는 단계; 또는각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 기설정된 반복 종료 조건이 만족될 때까지 다음 반복의 N개의 타겟 증강 작업을 결정하여 복수의 타겟 증강 작업 시퀀스를 출력하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 현재 반복은,공개특허 10-2024-0043659-4-첫 번째 반복을 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 증강된 타겟 데이터를 상기 훈련된 제2 모델에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를진행하여 상기 타겟 데이터에 대응하는 예측 결과를 획득하는 단계는,상기 타겟 증강 작업 시퀀스가 복수개의 증강 작업을 포함하는 경우, 상기 타겟 증강 작업 시퀀스를 기반으로데이터 증강하여 얻은 복수의 증강된 타겟 데이터를 상기 훈련된 제2 모델에 각각 입력하여 복수의 출력 결과를획득하는 단계; 및상기 복수의 출력 결과를 통합하여 상기 타겟 데이터에 대응하는 예측 결과를 획득하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제3항에 있어서, 제1 모델을 상기 훈련된 제1 모델로 훈련하는 과정은,획득된 훈련 데이터에 기초하여, 상기 제1 네트워크 및 상기 제2 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하고, 해당 순위 손실을 바탕으로 상기 제1 모델을 최적화하는 단계; 및현재 반복 훈련의 훈련 데이터를 기반으로, 상기 제2 네트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의각 기설정된 증강 작업의 순위 손실을 결정하고, 반복 횟수가 기설정된 최대 반복 횟수에 도달할 때까지 해당순위 손실을 바탕으로 상기 제1 모델을 최적화하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 현재 반복 훈련의 훈련 데이터를 기반으로, 상기 제2 네트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하고, 반복 횟수가 기설정된 최대 반복 횟수에 도달할 때까지해당 순위 손실을 바탕으로 상기 제1 모델을 최적화하는 단계는,상기 기설정된 증강 작업 중 어느 한 증강 작업을 다음 반복 훈련의 훈련 증강 작업으로 결정하는 단계;상기 현재 반복 훈련의 훈련 데이터에 대해 상기 다음 반복 훈련의 훈련 증강 작업을 수행하여 다음 반복 훈련의 훈련 데이터를 획득하는 단계; 및상기 다음 반복 훈련의 훈련 데이터를 기반으로 상기 제2 네트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 제1 네트워크 및 상기 제2 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하는 것과, 상기 제2 네트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위공개특허 10-2024-0043659-5-손실을 결정하는 것은,상기 다음 반복 훈련의 훈련 데이터에 대해 상기 기설정된 증강 작업을 각각 수행하는 단계;각 증강 작업 후 얻은 훈련 데이터를 제2 모델에 각각 입력하여 대응하는 손실값을 획득하는 단계; 및상기 손실값에 기초하여 다음 훈련 반복의 훈련 레이블을 결정하여 해당 훈련 레이블을 기반으로 다음 훈련 반복에서 얻은 각 증강 작업의 순위 손실을 결정하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 해당 훈련 레이블을 기반으로 다음 훈련 반복에서 얻은 각 증강 작업의 순위 손실을 결정하는 단계는,다음 반복 훈련을 위해 상기 제2 네트워크에서 출력된 출력 벡터를 획득하는 단계; 및상기 해당 훈련 레이블에 다음 반복 훈련의 출력 벡터를 맞춰 상기 다음 반복 훈련의 각 증강 작업의 순위 손실을 결정하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 내지 제13항 중 어느 한 항의 방법을 실행하기 위한 프로그램이 기록되어 있는 것을 특징으로 하는 컴퓨터에서 판독 가능한 기록 매체."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로세서를 포하는 데이터 처리 장치에 있어서,상기 프로세서는,타겟 데이터를 획득하고, 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강작업 시퀀스를 획득하고, 상기 타겟 증강 작업 시퀀스에 따라 상기 타겟 데이터에 대해 데이터 증강을수행하고, 증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를진행하여 상기 타겟 데이터에 대응하는 예측 결과를 획득하는데이터 처리 장치."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 훈련된 제1 모델은, 상기 타겟 데이터의 첫 번째 처리의 상태 특징을 결정하는 제1 네트워크;현재 반복의 상태 특징에 기초하여 현재 반복에 대응하는 타겟 증강 작업을 결정하는 제2 네트워크; 및상기 현재 반복의 상태 특징 및 상기 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하는 제3 네트워크를 포함하는 데이터 처리 장치치.공개특허 10-2024-0043659-6-청구항 17 제16항에 있어서,상기 프로세서는,상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득할때,현재 반복에 해당하는 타겟 증강 작업이 무작업을 제외한 증강 작업인 경우, 상기 제3 네트워크를 통해 현재 반복의 상태 특징 및 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하고,상기 제2 네트워크를 통해 기설정된 반복 종료 조건이 만족될 때까지 상기 다음 반복의 상태 특징을 기반으로다음 반복의 타겟 증강 작업을 결정하여 적어도 하나의 타겟 증강 작업 시퀀스를 출력하는데이터 처리 장치치."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 반복 종료 조건은,모든 반복에 대응하는 타겟 증강 작업이 무작업인 경우, 및반복 횟수가 기설정된 최대 반복 횟수에 도달한 경우중 적어도 하나를 포함하는 데이터 처리 장치."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 상기 제2 네트워크를 통해 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하는 단계는,상기 제2 네트워크를 통해 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 출력 벡터를 결정하는 단계; 및상기 다음 반복의 출력 벡터에서 기설정된 조건을 만족하는 벡터에 대응하는 증강 작업을 다음 반복의 타겟 증강 작업으로 결정하는 단계를 포함하는 데이터 처리 방법."}
{"patent_id": "10-2023-0066511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,상기 프로세서는,상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득할때, 현재 반복에서 결정된 타겟 증강 작업이 N개를 포함하고 N은 1보다 큰 정수인 경우,각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 하나의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족될때까지 반복을 순차적으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하거나, 또는각 타겟 증강 작업 및 사익 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 N개의 타겟 증강 작업을 결정하고, 결정된 N*N개의 증강 작업에서 N개의증강 작업을 다음 반복의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족될 때까지 반복을 순차적공개특허 10-2024-0043659-7-으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하거나, 또는각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 기설정된 반복 종료 조건이 만족될 때까지 다음 반복의 N개의 타겟 증강 작업을 결정하여 복수의 타겟 증강 작업 시퀀스를 출력하는데이터 처리 장치."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 데이터 처리 방법 및 장치에 관한 것으로, 본 개시의 방법은 타겟 데이터를 획득하는 단계, 훈련된 제 1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하는 단계, 상기 타겟 증강 작업 시퀀스에 따라 상기 타겟 데이터에 대해 데이터 증강을 수행하는 단계 및 증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를 진행하여 상기 타겟 데이터에 대 응하는 예측 결과를 획득하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하의 일 실시 예들은 인공지능 기술 분야에 관한 것으로, 특히 데이터 처리 방법, 전자 장치, 저장 매체 및 프로그램 제품에 관한 것이다."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "데이터 증강(Data Augmentation)은 신경망의 견고성을 향상시키기 위해 기계 학습 분야에서 사용되는 일반적인 기술로, 해당 기술의 구현으로 데이터 양을 크게 늘리지 않고도 기존 데이터에서 추가 샘플을 생성할 수 있다. 기존 TTA(Test Time Augmentation)에서는 각 테스트 데이터에 대해 단일 증강이 수행된다. 그러나 단일 증강으 로는 심하게 손상된 테스트 데이터의 증강 요구를 충족할 수 없으며 모델이 증강된 샘플을 예측할 때 좋은 예측 결과를 얻기가 어렵다."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시예는 데이터 처리 방법, 데이터 처리 장치, 전자 장치, 저장 매체 및 프로그램 제품을 제공하며, 테스트 단계 동안 증강 요구에 적응하고, 증강 작업의 검색 공간 및 상한을 확장하고, 보다 적합한 증강 작업을 찾아 예측 효과를 높이는 것을 목적으로 한다. 본 발명의 일 실시 예에 따른 데이터 처리 방법은, 타겟 데이터를 획득하는 단계; 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하는 단계; 상기 타겟 증강 작업 시 퀀스에 따라 상기 타겟 데이터에 대해 데이터 증강을 수행하는 단계; 및 증강된 타겟 데이터를 훈련된 제2 모델 에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를 진행하여 상기 타겟 데이터에 대응하는 예측 결 과를 획득하는 단계를 포함할 수 있다. 이때, 상기 타겟 증강 작업 시퀀스는, 캐스케이드된 적어도 2개의 증강 작업을 포함할 수 있다. 이때, 상기 훈련된 제1 모델은, 상기 타겟 데이터의 첫 번째 처리의 상태 특징을 결정하는 제1 네트워크; 현재 반복의 상태 특징에 기초하여 현재 반복에 대응하는 타겟 증강 작업을 결정하는 제2 네트워크; 및 상기 현재 반 복의 상태 특징 및 상기 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하는 제3 네트워크를 포함할 수 있다. 이때, 상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하는 단계는, 현재 반복에 해당하는 타겟 증강 작업이 무작업을 제외한 증강 작업인 경우, 상기 제3 네트워 크를 통해 현재 반복의 상태 특징 및 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징 을 결정하는 단계; 및 상기 제2 네트워크를 통해 기설정된 반복 종료 조건이 만족될 때까지 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하여 적어도 하나의 타겟 증강 작업 시퀀스를 출력하 는 단계를 포함할 수 있다. 이때, 상기 반복 종료 조건은, 모든 반복에 대응하는 타겟 증강 작업이 무작업인 경우, 및 반복 횟수가 기설정 된 최대 반복 횟수에 도달한 경우 중 적어도 하나를 포함할 수 있다. 이때, 상기 제2 네트워크를 통해 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하는 단 계는, 상기 제2 네트워크를 통해 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 출력 벡터를 결정하는 단 계; 및 상기 다음 반복의 출력 벡터에서 기설정된 조건을 만족하는 벡터에 대응하는 증강 작업을 다음 반복의 타겟 증강 작업으로 결정하는 단계를 포함할 수 있다. 이때, 상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하는 단계는, 현재 반복에서 결정된 타겟 증강 작업이 N개를 포함하고 N은 1보다 큰 정수인 경우, 각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 하나의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족될 때까지 반 복을 순차적으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하는 단계; 또는 각 타겟 증강 작업 및 사익 현 재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 N개의 타겟 증강 작업을 결정하고, 결정된 N*N개의 증강 작업에서 N개의 증강 작업을 다음 반복의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족될 때까지 반복을 순차적으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하는 단계; 또는 각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반복의 상 태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 기설정된 반복 종료 조건이 만족될 때까지 다음 반복의 N개의 타겟 증강 작업을 결정하여 복수의 타겟 증강 작업 시퀀스를 출력하는 단계를 포함할 수 있다. 이때, 상기 현재 반복은, 첫 번째 반복을 포함할 수 있다. 이때, 상기 증강된 타겟 데이터를 상기 훈련된 제2 모델에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를 진행하여 상기 타겟 데이터에 대응하는 예측 결과를 획득하는 단계는, 상기 타겟 증강 작업 시퀀스가 복 수개의 증강 작업을 포함하는 경우, 상기 타겟 증강 작업 시퀀스를 기반으로 데이터 증강하여 얻은 복수의 증강 된 타겟 데이터를 상기 훈련된 제2 모델에 각각 입력하여 복수의 출력 결과를 획득하는 단계; 및 상기 복수의 출력 결과를 통합하여 상기 타겟 데이터에 대응하는 예측 결과를 획득하는 단계를 포함할 수 있다. 이때, 제1 모델을 상기 훈련된 제1 모델로 훈련하는 과정은, 획득된 훈련 데이터에 기초하여, 상기 제1 네트워 크 및 상기 제2 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하고, 해당 순위 손실을 바탕으로 상기 제1 모델을 최적화하는 단계; 및 현재 반복 훈련의 훈련 데이터를 기반으로, 상기 제2 네 트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하고, 반복 횟수가 기설정된 최대 반복 횟수에 도달할 때까지 해당 순위 손실을 바탕으로 상기 제1 모델을 최적화하는 단계 를 포함할 수 있다. 이때, 상기 현재 반복 훈련의 훈련 데이터를 기반으로, 상기 제2 네트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하고, 반복 횟수가 기설정된 최대 반복 횟수에 도달할 때까지 해당 순위 손실을 바탕으로 상기 제1 모델을 최적화하는 단계는, 상기 기설정된 증강 작업 중 어느 한 증강 작업을 다음 반복 훈련의 훈련 증강 작업으로 결정하는 단계; 상기 현재 반복 훈련의 훈련 데이터에 대해 상기 다음 반복 훈련의 훈련 증강 작업을 수행하여 다음 반복 훈련의 훈련 데이터를 획득하는 단계; 및 상기 다 음 반복 훈련의 훈련 데이터를 기반으로 상기 제2 네트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하는 단계를 포함할 수 있다. 이때, 상기 제1 네트워크 및 상기 제2 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하는 것과, 상기 제2 네트워크 및 상기 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순 위 손실을 결정하는 것은, 상기 다음 반복 훈련의 훈련 데이터에 대해 상기 기설정된 증강 작업을 각각 수행하 는 단계; 각 증강 작업 후 얻은 훈련 데이터를 제2 모델에 각각 입력하여 대응하는 손실값을 획득하는 단계; 및 상기 손실값에 기초하여 다음 훈련 반복의 훈련 레이블을 결정하여 해당 훈련 레이블을 기반으로 다음 훈련 반 복에서 얻은 각 증강 작업의 순위 손실을 결정하는 단계를 포함할 수 있다. 이때, 상기 해당 훈련 레이블을 기반으로 다음 훈련 반복에서 얻은 각 증강 작업의 순위 손실을 결정하는 단계 는, 다음 반복 훈련을 위해 상기 제2 네트워크에서 출력된 출력 벡터를 획득하는 단계; 및 상기 해당 훈련 레이 블에 다음 반복 훈련의 출력 벡터를 맞춰 상기 다음 반복 훈련의 각 증강 작업의 순위 손실을 결정하는 단계를 포함할 수 있다. 본 발명의 일 실시 예에 따른 프로세서를 포하는 데이터 처리 장치에 있어서, 상기 프로세서는, 타겟 데이터를 획득하고, 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하고, 상기 타겟 증강 작업 시퀀스에 따라 상기 타겟 데이터에 대해 데이터 증강을 수행하고, 증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를 진행하여 상기 타겟 데이터에 대응하는 예측 결과를 획득할 수 있다. 이때, 상기 훈련된 제1 모델은, 상기 타겟 데이터의 첫 번째 처리의 상태 특징을 결정하는 제1 네트워크; 현재 반복의 상태 특징에 기초하여 현재 반복에 대응하는 타겟 증강 작업을 결정하는 제2 네트워크; 및 상기 현재 반 복의 상태 특징 및 상기 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하는 제3 네트워크를 포함할 수 있다. 이때, 상기 프로세서는, 상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증 강 작업 시퀀스를 획득할 때, 현재 반복에 해당하는 타겟 증강 작업이 무작업을 제외한 증강 작업인 경우, 상기 제3 네트워크를 통해 현재 반복의 상태 특징 및 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하고, 상기 제2 네트워크를 통해 기설정된 반복 종료 조건이 만족될 때까지 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하여 적어도 하나의 타겟 증강 작업 시퀀스를 출력할 수 있다. 이때, 상기 반복 종료 조건은, 모든 반복에 대응하는 타겟 증강 작업이 무작업인 경우, 및 반복 횟수가 기설정 된 최대 반복 횟수에 도달한 경우 중 적어도 하나를 포함할 수 있다. 이때, 상기 제2 네트워크를 통해 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하는 단 계는, 상기 제2 네트워크를 통해 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 출력 벡터를 결정하는 단 계; 및 상기 다음 반복의 출력 벡터에서 기설정된 조건을 만족하는 벡터에 대응하는 증강 작업을 다음 반복의 타겟 증강 작업으로 결정하는 단계를 포함할 수 있다. 이때, 상기 프로세서는, 상기 훈련된 제1 모델에 기초하여 상기 타겟 데이터를 처리하여 적어도 하나의 타겟 증 강 작업 시퀀스를 획득할 때, 현재 반복에서 결정된 타겟 증강 작업이 N개를 포함하고 N은 1보다 큰 정수인 경 우, 각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 다음 반복의 하나의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족 될 때까지 반복을 순차적으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하거나, 또는 각 타겟 증강 작업 및 사익 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으 로 다음 반복의 N개의 타겟 증강 작업을 결정하고, 결정된 N*N개의 증강 작업에서 N개의 증강 작업을 다음 반복 의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건이 만족될 때까지 반복을 순차적으로 수행하여 N개의 타겟 증강 작업 시퀀스를 출력하거나, 또는 각 타겟 증강 작업 및 상기 현재 반복의 상태 특징에 대해 다음 반 복의 상태 특징을 결정하고, 상기 다음 반복의 상태 특징을 기반으로 기설정된 반복 종료 조건이 만족될 때까지 다음 반복의 N개의 타겟 증강 작업을 결정하여 복수의 타겟 증강 작업 시퀀스를 출력할 수 있다."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시는 데이터 처리 방법 및 장치를 제공한다. 구체적으로, 테스트 단계에서 테스트를 위한 타겟 데이터를 획득할 때, 먼저 이미 훈련된 제1 모델에 대해 타겟 데이터 처리하여 캐스케이드된 적어도 두 개의 증강 작업을 포함하는 적어도 하나의 타겟 증강 작업 시퀀스를 획득한다. 그런 다음, 해당 타겟 증강 작업 시퀀스를 기반으 로 타겟 데이터에 대해 데이터를 증강하고, 증강된 타겟 데이터를 이미 훈련된 제2 모델에 입력하여 그에 따라 증강된 타겟 데이터를 처리하여 타겟 데이터의 대응하는 예측 결과를 얻을 수 있다. 본 개시 기술방안의 구현은 제2 모델을 변경하지 않는 전제 하에 타겟 데이터의 캐스케이드 반복 처리 방법을 통해, 타겟 데이터에 상응하 는 일련의 타겟 증강 작업을 적응적으로 계단식으로 예측할 수 있고, 보다 낮은 계산 비용으로 증강 작업의 검 색 공간과 상한을 확장하여 더 적합한 증강 작업을 찾을 수 있다. 또한, 증강된 타겟 데이터를 기반으로 훈련된 제2 모델을 테스트하여 기존 방안보다 더 나은 예측 효과를 얻을 수 있다."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면을 참조하여 실시예들을 상세하게 설명한다. 그러나, 실시예들에는 다양한 변경이 가해 질 수 있어서 특허출원의 권리 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 실시예들에 대한 모든 변경, 균등물 내지 대체물이 권리 범위에 포함되는 것으로 이해되어야 한다. 실시예에서 사용한 용어는 단지 설명을 목적으로 사용된 것으로, 한정하려는 의도로 해석되어서는 안된다. 단 수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조부호를 부여 하고 이에 대한 중복되는 설명은 생략하기로 한다. 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적 인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 실시 예의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 어느 하나의 실시 예에 포함된 구성요소와, 공통적인 기능을 포함하는 구성요소는, 다른 실시 예에서 동일한 명 칭을 사용하여 설명하기로 한다. 반대되는 기재가 없는 이상, 어느 하나의 실시 예에 기재한 설명은 다른 실시 예에도 적용될 수 있으며, 중복되는 범위에서 구체적인 설명은 생략하기로 한다."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 개시는 인공지능 기술분야에 관한 것으로, 인공지능(AI)은 디지털 컴퓨터 또는 디지털 컴퓨터로 제어되는 기 계를 사용하여 인간 지능을 시뮬레이션, 연장 및 확장하고, 환경을 인식하고, 지식을 획득하고, 지식을 사용하 여 최상의 결과를 얻는 이론, 방법, 기술 및 응용 시스템이다. 즉, 인공지능은 지능의 본질을 이해하고 인간의 지능과 유사하게 반응할 수 있는 새로운 지능 기계를 생산하려는 컴퓨터 과학의 종합 기술이다. 인공지능은 다 양한 지능형 기계의 설계 원리와 구현 방법을 연구하여 기계가 인식, 추론 및 의사 결정 기능을 갖도록 하는 것 이다. 인공지능 기술은 하드웨어 측면의 기술과 소프트웨어 측면의 기술을 모두 포함하는 광범위한 분야를 포함하는 포괄적인 학문이다. 인공지능의 기본 기술에는 일반적으로 센서, 특수 인공지능 칩, 클라우드 컴퓨팅, 분산 스 토리지, 빅 데이터 처리 기술, 운영/상호 작용 시스템, 전자 기계 통합 등과 같은 기술이 포함된다. 인공지능 소프트웨어 기술은 주로 컴퓨터 비전 기술, 음성 처리 기술, 자연어 처리 기술 및 기계 학습/딥 러닝, 자율 주 행, 스마트 교통 등 주요 방향을 포함한다. 구체적으로, 본 개시는 확률 이론, 통계학, 근사 이론, 볼록 분석, 알고리즘 복잡성 이론 등 다양한 학과와 관 련된 여러 분야의 교차 학과인 머신 러닝(Machine Learning, ML)과 관련이 있다. 컴퓨터가 인간의 학습 행동을 시뮬레이션하거나 구현하여 새로운 지식 또는 기술을 습득하고 기존 지식 구조를 재구성하여 자신의 성능을 지 속적으로 향상시키는 방법을 전문적으로 연구한다. 머신 러닝은 인공지능의 핵심이자 컴퓨터를 지능화하는 근본 적인 방법으로 인공지능의 다양한 분야에 적용된다. 머신 러닝 및 딥 러닝은 일반적으로 인공 신경망, 신뢰 네 트워크, 강화 학습, 전이 학습, 귀납 학습, 형식 학습 등 기술을 포함한다. 본 개시에서 제공하는 기술방안은 머신 러닝 분야의 데이터 증강 기술과 관련된다고 볼 수 있다. 데이터 증강은 모델의 훈련 단계 또는 모델의 테스트 단계 중에 구현될 수 있다. 본 개시는 테스트 단계에서 관련 기술의 증강 에 존재하는 문제를 개선할 수 있다. TTA(Test Time Augmentation)는 알고리즘의 테스트 단계에서 테스트 데이 터의 데이터 증강을 의미하는 것으로 이해할 수 있다. 해당 방법의 구현은 증강을 통해 손상된 테스트 데이터의 고유한 훈련 데이터 분포를 복원하여 좋은 예측 결과를 얻는 것을 목표로 한다. 그러나 테스트 데이터의 단일 증강만으로는 심하게 손상된 일부 테스트 데이터의 증강 요구를 충족할 수 없으므로, 모델이 증강된 샘플(테스 트 데이터를 증강하여 얻은)을 예측할 때 좋은 예측 결과를 얻을 수 없다. 상기 기술적 문제 또는 개선이 필요한 부분에 있어, 본 개시는 데이터 처리 방법, 데이터 처리 장치, 전자 장치, 저장 매체 및 프로그램 제품을 제안하며, 이는 즉 한 번에 타겟 데이터에 적용된 일련의 타겟 증강 작업 을 캐스케이드하여 출력할 수 있는 캐스케이드 반복의 데이터 증강 방식이다. 제2 모델이 변경되지 않은 상태에 서 관련 기술보다 더 나은 예측 효과를 달성하는 동시에 더 낮은 컴퓨팅 비용으로 전략 검색 공간을 크게 확장 및 증강시키고 보다 더 유연하게 반복 횟수를 제어한다. 본 개시의 방안은 모델의 테스트 단계 또는 모델의 훈 련 단계에서 사용할 수 있다. 이하, 본 개시 실시예의 기술방안 및 본 개시의 기술방안에 의해 생성된 기술적 효과를 설명하기 위해 몇 가지 예시적 실시예에 대해 설명한다. 이하 구현 방법은 상호 참고, 참조 또는 결합될 수 있으며, 상이한 구현 방법 중 동일한 용어, 유사한 기능 및 유사한 구현 단계 등에 대해서는 반복 설명하지 않는다.도 1은 본 개시의 실시예에 따른 데이터 처리 장치에서 데이터를 처리하는 과정을 도시한 흐름도이다. 도 1을 참조하면, 데이터 처리 장치는 단말기 또는 서버와 같은 임의의 전자 장치에 의해 실행될 수 있다. 단말 기는 스마트폰, 태블릿, 노트북, 데스크톱 컴퓨터, 스마트 스피커, 스마트 워치, 자동차 탑재 장치 등일 수 있 다. 서버는 독립적인 물리적 서버이거나 여러 물리적 서버로 구성된 서버 클러스터 또는 분산 시스템일 수 있으 며, 클라우드 서비스, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 스토리지, 네트워크 서비스, 클라우드 커뮤니케이션, 미들웨어 서비스, 도메인 네임 서비스, 보안 서비스, CDN, 빅데이터 및 인공지 능 플랫폼 등 기본적인 클라우드 컴퓨팅 서비스를 제공하는 클라우드 서버가 될 수도 있으며, 이에 국한되지 않 는다. 구체적으로, 도 1에 도시된 바와 같이, 본 개시 실시예에서 제공하는 데이터 처리 방법은 다음 101단계 내지 104 단계를 포함한다. 먼저, 데이터 처리 장치는 타겟 데이터를 획득할 수 있다. 구체적으로, 본 개시 실시예에서 제공하는 데이터 처리 장치는 모델을 테스트하는 과정에서 구현될 수 있다. 따 라서, 타겟 데이터는 제2 모델의 테스트 세트의 테스트 데이터에 속한다. 테스트 세트는 복수의 테스트 데이터 를 포함할 수 있으며, 이들 각각은 101단계에서 언급된 타겟 데이터로 간주될 수 있음을 이해할 수 있다. 즉, 각 테스트 데이터에 대해 다음 102단계 내지 104단계가 구현될 수 있다. 선택적으로, 다양한 응용 시나리오에 적합하며, 타겟 데이터는 다양한 유형의 데이터일 수 있다. 예를 들어 이 미지 처리 시나리오에서 타겟 데이터는 이미지 데이터일 수 있고, 오디오 처리 시나리오에서 타겟 데이터는 오 디오 데이터(예, 음성 데이터)일 수 있다. 본 개시에서 제공하는 다양한 예시를 더 잘 설명하기 위해, 이하, 타 겟 데이터를 이미지 데이터(예, 테스트 이미지)로 예를 들어 설명한다. 그리고, 데이터 처리 장치는 훈련된 제1 모델에 기초하여, 타겟 데이터를 처리하여 캐스케이드된 적어도 2개의 증강 작업을 포함하는 적어도 하나의 타겟 증강 작업 시퀀스를 획득할 수 있다. 이때, 훈련된 제1 모델은 훈련된 제2 모델과 서로 독립적인 신경망 모델일 수 있다. 훈련된 제1 모델은 타겟 데 이터에 적합한 적어도 하나의 타겟 증강 작업 시퀀스를 검색하는데 사용될 수 있다. 제1 모델의 네트워크 구조 및 그 구현 내용은 후속 실시예에서 설명될 것이다. 제1 모델은 복수의 기설정된 증강 작업에 적용되어 있음을 알 수 있다. 즉, 제1 모델은 복수의 기설정된 증강 작업에서 타겟 데이터에 적용 가능한 일련의 타겟 증강 작업 을 찾아낼 수 있다. 도 2는 본 개시의 실시예에 따른 증강 작업의 예를 도시한 도면이다. 도 2에 도시된 바와 같이, 테스트 이미지의 경우 증강 작업은 작업 없음(원본 이미지), 회전, 스케일 , 대비, 채도 및 흐림 등 중 적어도 하나의 작업을 포함할 수 있다. 선택적으로, 작업이 없다는 것은 테스트 이미지에 그 어떤 증강 작업도 수행되지 않고 원본 이미지가 유지됨을 의미한다. 본 개시의 실시예에서 언급된 기설정된 증강 작업에서, 타겟 데이터가 이미지인 경우, 기설정된 증강 동작은 이미지 데이 터에 대해 구현될 수 있는 임의의 복수의 증강 작업일 수 있으며, 본 개시는 이에 대해 제한하지 않는다. 또한, 타겟 데이터가 테스트 오디오인 경우, 기설정된 증강 작업은 노이즈 감소, 압축, 속도 증가, 감속 등의 작업일 수 있다. 이때, 타겟 데이터의 처리는 캐스케이드 반복(Cascade Iterations)을 이용하여 수행할 수 있으며, 캐스케이드 반복의 구현은 타겟 데이터에 적합한 일련의 타겟 증강 작업을 한 번에 캐스케이드하여 출력할 수 있다. 선택적 으로, 제3 네트워크(Recurrent Neural Network, RNN)를 포함하는 모델을 통해 캐스케이드 반복 프로세스를 구현 할 수 있고, 이를 통해 보다 가볍고 효율적인 네트워크 구조로 증강 전략 검색(Augmentation Policy Search)의 효과를 높일 수 있다. 본 개시의 실시예에서, 제1 모델은 캐스케이드 손실 예측 모델 또는 캐스케이드 손실 예측기(cascade loss predictor)라고 부를 수 있다. 그리고, 데이터 처리 장치는 타겟 증강 작업 시퀀스에 기초하여 타겟 데이터에 대해 데이터를 증강할 수 있다 . 구체적으로, 102 단계에서 결정된 타겟 데이터에 적합한 적어도 하나의 타겟 증강 작업 시퀀스는 타겟 데이터에 대해 각각 데이터를 증강하여 적어도 하나의 증강된 타겟 데이터를 획득할 수 있다. 해당 단계의 구현은 추가테스트 데이터 없이 여러 타겟 데이터에 대한 증강 복사본을 만들 수 있다. 그리고, 데이터 처리 장치는 증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 증강된 타겟 데이터에 대해 상 응 처리하여 타겟 데이터에 대응하는 예측 결과를 획득할 수 있다. 구체적으로, 데이터 처리 장치는 증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 타겟 데이터의 최종 예측 결과를 획득할 수 있다. 선택적으로, 제2 모델이 다른 처리 작업에 적합할 경우, 데이터 처리 장치는 처리 작업 에 해당하는 신경망을 훈련하여 얻을 수 있다. 예를 들어 이미지 분류 작업의 경우 제2 모델은 분류기가 될 수 있다. 훈련된 분류기에 증강된 타겟 데이터를 입력하면 해당 타겟 데이터에 대응하는 분류 결과를 얻을 수 있다. 본 개시의 실시예에서, 제2 모델은 타겟 모델로 칭할 수 있다. 본 개시의 실시예에서, 데이터 처리 방법은 테스트 단계에서 증강 요구에 적응하고 증강 작업의 검색 공간과 상 한을 확장하고 더 적절한 증강 작업을 검색한 다음, 제2 모델에서 증강된 타겟 테이터를 기반으로 예측을 진행 할 때 제2 모델의 예측 성능을 향상시킬 수 있다. 본 개시의 실시예에서, 이미지에 대한 데이터 증강 처리에서, 훈련된 제2 모델 및 입력 이미지(예를 들어, 테스 트 이미지)를 제공함으로써, 상이한 증강 샘플로부터의 손실값이 사용된 증강 작업의 품질을 정확하게 나타낼 수 있다. 따라서 정확한 손실값을 사용하여 테스트 단계 증강을 선택하는 것이 보다 직접적인 접근 방식이다. 데이터 처리 장치는 효율성을 높이기 위해 손실 예측기를 기반으로 적절한 증강 작업을 검색할 수 있다. 제1 모 델은 미리 정의된 각각의 증강 작업에 대응하는 손실값을 독립적으로 추정할 수 있다. 입력 이미지는 제2 모델 에 직접 입력되는 것이 아니며, 사전에 가장 낮은 예측 손실값을 갖는 증강 작업을 통해 데이터를 증강한다. 손실 예측기는 제2 모델에 대해 최상의 성능을 달성할 수 있는 증강 작업을 결정하는데 사용된다. 손실 예측기 의 출력은 증강 작업의 품질 순위를 나타내므로 통합 효과의 이점도 누릴 수 있다. 데이터 처리 장치는 k를 기 설정된 증강 작업 수로 설정하고, 통합을 위해 이전 k개의 최저값에 해당하는 증강 작업을 선택할 수 있다. 또 한, 데이터 처리 장치는 제2 모델과 손실 예측기 사이의 완전한 분리로 인해 입력 샘플의 전처리가 상당히 가벼 운 레벨의 모듈임을 예상할 수 있다. 이를 기반으로, 데이터 처리 방법은 다중 레벨 특징 수정이 있는 EfficientNet-B0를 손실 예측기의 백본으로 선택할 수 있다. 이때, EfficientNet-b0는 컨벌루션 신경망이며, ImageNet 데이터베이스의 1백만 개가 넘는 영상에 대해 훈련되 었다. EfficientNet-b0는 영상을 키보드, 마우스, 연필, 각종 동물 등 1,000가지 사물 범주로 분류할 수 있다. 데이터 처리 장치는 심하게 손상된 테스트 샘플을 처리하기 위해, 순환 반복의 손실 예측기를 사용하여 처리할 수 있다. 데이터 처리 장치는 순환 방식으로 손실 예측기에 순환 TTA(Cyclic TTA)를 도입할 수 있다. 단일 손실 예측기는 하나의 증강 작업만 예측하므로, 증강된 이미지는 제2 모델에 의해 처리되는 반면, 순환 TTA는 손실 예측기의 다중 재사용을 수행할 수 있다. 손실 예측기는 개별 버전과 동일하지만 증강된 이미지는 다시 한번 순 환을 형성하는 입력으로 간주된다. 따라서 데이터 처리 장치는 각 테스트 샘플에 대해 종료 신호가 활성화될 때 까지 3단계 반복(손실 예측, 증강 선택, 이미지 증강)을 계속 반복할 수 있다. 순환을 깨는 데는 두 가지 조건 이 있다. 하나는 항등식으로서 예측된 최적 증강 작업이고, 다른 하나는 미리 정해진 상한 반복 횟수이다. 전자 는 현재 이미지의 최적 상태를 나타내고 후자는 끝없는 예측을 방지한다. 최대 반복 횟수는 하이퍼 매개변수이 지만 다중 손실 예측에서 높은 손상을 더 많이 억제할 수 있다. 데이터 처리 장치는 개선된 EfficientNet-B0의 경량 레벨 백본을 채택하였기 때문에, 손실 예측기를 여러 번 구현하더라도 제2 모델의 경우 순환 TTA 비용이 미미하다. 그러나 순환 TTA는 여전히 손실 예측기를 반복적으로 호출해야 하며 경량 레벨 백본 네트워크는 그 능력이 어느 정도 제한될 수 있다. 손실 예측기의 훈련 방법은 단일 증강 방법과 순환 증강 방법 모두 동일하다. 손실 예측기를 훈련하는 경우에도 제2 모델은 고정된 상태로 유지된다. 먼저, 데이터 처리 장치는 작업 없음을 포함하여 N개의 증강 작업을 미리 정의한다. 데이터 처리 장치는 입력 이미지가 주어지면, 증강된 N개의 샘플을 각각 제2 모델에 입력하여 N개의 교차 엔트로피 손실값을 얻는다. 데이터 처리 장치는 손실값을 수집한 후, 정규화를 위해 softmax 함수를 적용 하여 최종적으로 손실 예측기의 실제값을 생성한다. 여기서, 데이터 처리 장치는 Spearman 관련 순위 손실을 최 적화를 위한 타겟 함수로 계산한다. 따라서 손실 예측기는 테스트 중 적절한 증강 작업을 선택할 수 있도록 사 전 정의된 증강 작업의 품질을 정렬하는 방법을 학습한다. 또한 손실 예측기의 훈련 및 검증 데이터는 제2 모델 의 훈련 데이터에서 가져와서 방법의 가용성을 높일 수 있다. 공간이 확장됨에 따라 손실 예측기의 성능도 향상된다. 이러한 가상의 손실 예측의 상대 손실값은 정확하며 손 실이 가장 적은 증강 작업을 통해 테스트 샘플을 늘릴 수 있다. 그 성능은 손실 예측기의 상한을 시뮬레이션한 다. 순환 TTA는 더 긴 반복이 더 높은 성능으로 이어질 수 있고 더 많은 개선 가능성을 제공할 수 있음을 나타 낸다. 순환 TTA의 장점은 단일 테스트 샘플에 대해 여러 번의 증강 반복을 수행할 때 분명해진다. 본 개시 실시예에서 제공하는 방법 중, 단일 네트워크를 사용하여 일련의 타겟 증강 작업을 한 번에 생성하는 방법에 중점을 둔다. 제안된 캐스케이드 TTA(Cascade TTA)는 반복 신경망(RNN)을 사용하여 각 반복에서 증강된 이미지의 의미 정보를 캡처하고 중간의 증강된 이미지를 사용하지 않고 예측 반복의 증강 작업을 실현한다. 도 8a는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 일 예를 도시한 예시도이다. 도 8b는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 다른 예를 도시한 예시도이다. 도 8c는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 또 다른 예를 도시한 예시도이다. 도 8d는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 또 다른 예를 도시한 예시도이다. 도 8b는 테스트 중 캐스케이드-TTA 프로세스를 설명한다. 이때, 여러 개의 필요한 타겟 증강 작업을 반복적으 로 얻기 위해 제1 모델인 캐스케이드 손실 예측기의 순방향 전파 하나만 필요로 한다. 증강된 이미지를 손 실 예측기에 다시 입력하는 번거로운 과정 필요 없이, 새로운 캐스케이드 네트워크는 원본 입력만 수 락하지만, 일련의 적절한 타겟 증강 작업은 제공한다. 이런 경우, 본 개시 실시예는 직접 한 번 실행하여 타겟 증강 작업 시퀀스를 얻을 수 있고, 제2 모델에 입력되는 최종 증강 샘플을 직접 얻을 수 있다. 도 8c에 도시된 바와 같이, RNN 유닛(제3 네트워크)은 캐스케이드 손실 예측을 통해 종속 관계를 처리한다. 본 개시의 실시예는 타겟 증강 작업 시퀀스를 생성하기 위한 RNN 기반의 합리적인 캐스케이드 손실 예측기를 제안한다. 제안하는 캐스케이드 손실 예측기는 백본 네트워크(제1 네트워크), RNN 유닛(제3 네트 워크) 및 출력 유닛(제2 네트워크) 등 세 가지 부분으로 구성된다. 본 개시의 실시예에서, 손실 예측 방법을 통해 타겟 데이터에 적합한 타겟 증강 작업을 찾는 것은 테스트 단계 증강에서 효과적인 검색 전략이다. 이하, 본 개시의 실시예에서 적어도 하나의 타겟 증강 작업 시퀀스를 결정하 는 구체적인 내용에 대해 설명한다. 도 3은 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 과정을 도시한 흐름도이다. 실행 가능한 실시예에서, 도 3에 도시된 바와 같이, 데이터 처리 장치는 훈련된 제1 모델을 통해 타겟 데이터에 대해 캐스케이드 반복 처리를 진행할 수 있다. 타겟 데이터(도 3에 도시된 입력 이미지)를 제1 모델 에 입력하고, {a0，a1，…，at}와 같이, 제1 모델에 의해 타겟 데이터에 대해 캐스케이드 반복 처리 후 타겟 데이터에 적합한 타겟 증강 작업 순서를 찾아낸다. 그리고, 데이터 처리 장치는 입력 이미지와 {a0，a1，…，at}를 제2 모델에 제공하여 최종 결과 를 획득할 수 있다. 도 4는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델의 처리 과정을 도시한 흐름도이다. 구체적으로, 도 4에 도시된 바와 같이, 제1 모델은 타겟 데이터가 처음으로 처리한 상태 특징을 결정하는 제1 네트워크, 다음 반복의 상태 특징에 기초하여 다음 반복에 대응하는 타겟 증강 작업을 결정하는 제2 네트워크 및 현재 반복의 상태 특징 및 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정 하는 제3 네트워크를 포함한다. 이때, 제1 네트워크는 백본 네트워크(Backbone)일 수 있고, 네트워크 구조는 관련 딥 러닝 기술의 내용을 참조할 수 있으므로 본 개시에서는 자세히 설명하지 않는다. 도 4를 통해 알 수 있듯이, 제1 네트워크는 제1 모 델에서 반복의 초기 단계(즉 0번째 반복)에서 타겟 데이터(도 4에 도시된 입력 이미지))의 상태 특징 state0을 추출하는데 사용될 수 있다. 이때, 제2 네트워크는 복수의 출력 유닛(431, 432, 433)을 포함할 수 있다. 출력 유닛은 제1 모델의 일부 로서 상태 특징 state0의 변형(reshape), 풀링(pooling), 선형 변환(linear), 소프트맥스(softmax) 등 작업을 포함할 수 있고, 구체적으로 상이한 제1 네트워크에 따라 유연하게 조절할 수 있으며 본 개시는 이에 대해 제한 하지 않는다.이때, 제3 네트워크는 순환 신경망(도 4와 같은 RNN 유닛(441, 442)을 포함할 수 있음)일 수 있으며, 제1 모델 의 제1 네트워크와 동일한 역할을 하며, 각 반복과 관련된 상태 특징을 결정하는데 사용된다. 그러나 제3 네트 워크의 입력은 제1 네트워크와 다르며, 제3 네트워크의 입력에는 현재 반복의 상태 특징과 현재 반복의 타겟 증 강 작업(인코딩된 정보)이 포함된다. 이때, 현재 반복의 상태 특징은 히든 상태(hidden state)로 사용될 수 있 고, 인코딩을 통해서 인코딩된 현재 반복의 타겟 증강 작업은 입력으로 사용되어 제3 네트워크로 전송될 수 있다. 도 4를 참조하면, 데이터 처리 장치는 각 반복에서 증강된 이미지가 무작업인지 여부(451, 452)를 확인할 수 있 다. 제1 모델의 네트워크 구조와 결합하여, 이하, 제1 모델의 훈련 부분에 대해 설명한다. 도 9는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 흐름도이다. 도 9를 참조하면, 데이터 처리 장치는 획득한 훈련 데이터를 기반으로 제1 네트워크 및 제2 네트워크를 통해 다 음 반복 훈련의 각 사전 설정된 증강 작업의 순위 손실을 결정하고, 해당 순위 손실을 기반으로 제1 모델을 최 적화할 수 있다. 그리고, 데이터 처리 장치는 현재 반복 훈련의 훈련 데이터를 기반으로 제2 네트워크 및 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정하고, 해당 순위 손실을 기반으로 제1 모델을 반복 횟수가 기설정된 최대 반복 횟수에 도달할 때까지 최적화할 수 있다. 구체적으로, 도 8a 내지 도 8d에 도시된 바와 같이, 제1 모델의 훈련 부분은 제1 네트워크 및 제2 네트워 크에 의해 구현되는 부분과 제2 네트워크 및 제3 네트워크에 의해 구현되는 부분으로 나눌 수 있다(해당 구분은 단지 캐스케이드 반복의 전반적인 과정을 더 잘 설명하기 위함임). 도 8a에 도시된 바와 같이, 각 반복 훈련에서 제2 네트워크의 출력은 레이블 생성기)에서 출력된 해 당 레이블(ground-truth)과 결합되고, Spearman 순위 손실을 통해 각 증강 작업의 순위 손실을 계산하여 한 번 의 반복 훈련을 완성한다. 즉, 데이터 처리 장치는 0번째 반복으로 한 번의 제1 모델을 최적화할 수 있다. 이때, 제1 네트워크 및 제2 네트워크에 의해 구현된 훈련 부분은 획득된 훈련 데이터를 처리하고, 즉, 제1 네트워크는 훈련 중에 원본 훈련 데이터를 처리한다. 제2 네트워크 및 제3 네트워크에 의해 구현된 훈련 부분은 현재 반복의 훈련 데이터를 처리하고, 즉, 제3 네트워크의 훈련 중 입력된 특징 은 현재 반복 훈련에서 얻은 특징을 포함한다. 선택적으로, 도 9의 920단계는 다음 도 10의 단계를 포함할 수 있다. 도 10은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제2 및 제3 네트워크를 통해 다음 반복의 각각의 기 설정된 증강 작업의 순위 손실을 결정하는 흐름도이다. 도 10을 참조하면, 데이터 처리 장치는 기설정된 증강 작업 중 임의의 증강 작업을 다음 반복 훈련의 훈련 증강 작업으로 결정할 수 있다. 그리고, 데이터 처리 장치는 현재 반복 훈련의 훈련 데이터에 대해 다음 반복 훈련의 훈련 증강 작업을 진행하 여 다음 반복 훈련의 훈련 데이터를 획득할 수 있다. 그리고, 데이터 처리 장치는 다음 반복 훈련의 훈련 데이터에 기초하여, 제2 및 제3 네트워크를 통해 다음 반복 훈련의 각 기설정된 증강 작업의 순위 손실을 결정할 수 있다. 실시예에서, 도 8a 내지 도 8d에 도시된 바와 같이, 제1 네트워크 및 제2 네트워크에 의해 구현되는 훈련은 0번째 반복에 대응하고, 제2 네트워크 및 제3 네트워크에 의해 구현되는 훈련은 첫 번째 반복 부터 i번째 반복에 대응하며, 즉, 훈련 단계의 반복 횟수는 기설정된 길이 L로 설정될 수 있다. 이를 바탕으로 첫 번째 반복부터 시작하여 제1 모델의 제3 네트워크제3 네트워크가 역할을 발휘하고, 훈련 단계에서 데이 터의 다양성을 달성하기 위해 제2 네트워크 및 제3 네트워크에 의해 구현되는 각 반복 훈련은 증강 작업을 무작위로 할당할 수 있다. 도 8a 내지 8d에 도시된 바와 같이, 1차 반복 훈련 동안 먼저 I0에 대해 무작 위 할당된 a0증강을 진행하여 I1를 얻고, 레이블 생성기를 사용하여 I1의 레이블을 얻는다. 그런 다음 state0와 인코딩된 a0를 RNN 유닛(제3 네트워크)으로 전송하여 본 회차의 히든 상태 state1를 얻고, 제2 네트워크를 통해 Spearman 순위 손실을 다시 사용하여 최적화한다.이하, 레이블 생성기의 구체적인 내용에 대해 설명한다. 선택적으로, 도 9의 910단계 및 920단계는 다음 도 11의 단계를 포함할 수 있다. 도 11은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 다음 반복의 각각의 기설정된 증강 작업의 순위 손 실을 결정하는 흐름도이다. 데이터 처리 장치는 다음 반복 훈련의 훈련 데이터에 대해 각각 기설정된 증강 작업을 진행할 수 있다. 그리고, 데이터 처리 장치는 다양한 증강 작업 후에 얻은 훈련 데이터를 각각 제2 모델에 입력하여 대응하는 손 실값을 획득할 수 있다. 그리고, 데이터 처리 장치는 손실값을 기반으로 다음 반복 훈련의 훈련 레이블을 결정하여, 해당 훈련 레이블을 기반으로 다음 반본 훈련에서 얻은 각 증강 작업의 순위 손실을 결정할 수 있다. 도 7은 본 개시의 실시예에 따른 데이터 처리 장치의 레이블 생성기(label builder)의 구성의 예를 도시한 예시 도이다. 구체적으로, 도 7에 도시된 바와 같이, 레이블 생성기는 다음 반복 훈련의 훈련 데이터(입력된 이미지 )에 대해, 먼저 기설정된 N개의 증강 작업을 바탕으로 데이터를 증강하여 증강 이미지1, 증강 이미지2, 쪋, 증강 이미지 N을 획득한다. 그런 다음, 레이블 생성기는 해당 N개의 증강 이미지를 각각 제2 모델)에 입력하여 제2 모델)에 서 출력하는 N개의 손실값{loss0,1，loss0,2，…，loss0,N}(751, 752, 753)을 획득하고, N개의 손실값(751, 752, 753)을 정규화(예, softmax) 처리하여 이미지에 해당하는 훈련 레이블을 획득할 수 있다. 선택적으로, 도 11의 1130단계는 다음 도 12의 단계를 포함할 수 있다. 도 12는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 해당 훈련 레이블을 기반으로 다음 반본 훈련에서 얻은 각 증강 작업의 순위 손실을 결정하는 흐름도이다. 도 12를 참조하면, 데이터 처리 장치는 다음 반복 훈련의 제2 네트워크에서 출력한 출력 벡터를 획득할 수 있다 . 그리고, 데이터 처리 장치는 해당 훈련 레이블에 다음 반복 훈련의 출력 벡터를 맞추고, 다음 반복 훈련의 각 증강 작업의 순위 손실을 결정할 수 있다. 구체적으로, 도 8a, 도 8b, 도 8c, 도 8d와 같이, 데이터 처리 장치는 훈련 과정에서 출력 벡터를 훈련 레이블 에 맞춰서 각 반복 훈련의 손실을 계산할 수 있다. 즉, 데이터 처리 장치는 타겟 데이터에 기설정된 N개의 증강 작업을 거친 후 제2 네트워크에서 출력하는 출력 벡터를 타겟 모델에서의 손실값에 맞출 수 있다. 선택적으로, 훈련 부분의 예시에서, 데이터 처리 장치는 최대 반복 횟수를 L로 미리 설정할 수 있다. 데이터 처 리 장치는 0번째 반복 훈련에서 제1 모델의 제1 네트워크와 제1 네트워크와 협력하는 제2 네트워크 를 최적화할 수 있다. 데이터 처리 장치는 첫 번째 내지 L-1번째 반복 훈련에서 제1 모델의 제3 네트워크 , 제3 네트워크와 협력하는 제2 네트워크 부분을 최적화할 수 있다. 데이터 처리 장치는 최대 반복 횟수를 L로 설정하는 경우, 제1 모델은 1개의 제1 네트워크, L-1개의 제3 네트워크 및 L개의 제 2 네트워크를 포함하는 것을 알 수 있다. 이하, 구체적인 예시와 함께 제1 모델의 훈련 부분과 관련된 각 작업 단계에 대해 설명한다. 일례로, 제1 모델의 훈련 데이터를 훈련 이미지로 설명한다. 구체적으로, 제1 모델의 훈련 부분의 단계는 다음 과 같다. 도 13은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 과정을 도시한 흐름도이다. 도 13을 참조하면, 데이터 처리 장치는 N개의 다른 증강 작업을 미리 설정한다. 그리고, 데이터 처리 장치는 훈련 이미지에 대해 N개의 증강을 진행하여 {I0,1，I0,2，…，I0,N}를 획득하고, 획득 한 N개의 이미지를 각각 제2 모델로 전송하여 N개의 손실값{loss0,1，loss0,2，…，loss0,N}을 획득한다. 그런 다 음, 데이터 처리 장치는 N개의 손실값을 길이가 N인 벡터로 결합하고 softmax 함수를 사용하여 정규화하여 0번째 반복 훈련의 v0을 획득한다. 1320단계는 0번째 반복의 실행으로 볼 수 있다. 그리고, 데이터 처리 장치는 훈련 이미지 I0,0를 제1 모델의 제1 네트워크로 전송하여 0번째 반복의 상태 특징 state0을 획득한다. 그리고, 데이터 처리 장치는 상태 특징 state0을 제2 네트워크로 전송하여 출력 벡터 p0를 획득하고, Spearman 순위 손실을 사용하고, 출력 벡터 p0를 훈련 레이로 v0에 맞춰 제1 모델을 최적화한다. 그리고, 데이터 처리 장치는 N개의 증강 중 하나의 증강 작업 a0을 무작위로 지정하고, 훈련 이미지 I0,0에 대해 해당 a0 방법으로 증강하여 첫 번째 반복 훈련 이미지 I1,0를 획득한다. 1350단계는 첫 번째 반복의 실행 으로 볼 수 있다. 그리고, 데이터 처리 장치는 첫 번째 반복의 훈련 이미지 I1,0에 대해 N개의 증강을 진행하여 {I1,1，I1,2，…， I1,N}를 획득하고, 데이터 처리 장치는 N개의 증강된 이미지를 각각 제2 모델로 전송하여 N개의 손실값{loss1,1， loss1,2，…，loss1,N}을 획득한다. 데이터 처리 장치는 N개의 손실값을 길이가 N인 벡터로 결합하고 softmax 함 수를 사용하여 정규화하여 v1을 획득한다. 그리고, 데이터 처리 장치는 상태 특징 state0과 인코딩된 a0을 각각 히든 상태(hidden state) 및 입력(input) 으로 RNN 유닛에 입력하여 첫 번째 반복의 상태 특징 state1을 획득한다. 그리고, 데이터 처리 장치는 state1을 제2 네트워크로 전송하여 출력 벡터 p1를 획득하고, Spearman 순위 손실을 사용하고, 출력 벡터 p1를 훈련 레이블로v1에 맞춰 제1 모델을 최적화한다. 그리고, 데이터 처리 장치는 후속 반복에 대해 상술한 바와 같이 반복하고, 훈련 단계가 L-1번째 반복에서 멈출 때까지 최대 반복 횟수 L을 설정한다. 도 8b 및 도 8c에서, τ1 분기는 0번째 반복에서 예측한 손실값에 대응하고, τN 분기는 N번째 반복에서 예측한 손실값에 대응한다. τ1 분기에서, 0.3τ0, 0.1τ1, …, 0.5τN는 0번째 반복에 대응하는 N개의 손실값이다. τN 분기에서, 0.4τ0, 0.6τ1, …, 0.2τN는 N번째 반복에 대응하는 N개의 손실값이다. 이하, 제1 모델의 테스트 부분에 대해 설명한다. 먼저, 본 개시 실시예에서의 제1 네트워크 및 제2 네트워크를 통한 타겟 데이터의 1차 처리의 구체적인 내용에 대해 설명한다. 구체적으로, 데이터 처리 장치는 제1 네트워크 및 제2 네트워크를 통해 기설정된 복수의 증강 작업 중 타겟 데 이터의 1차 처리에 해당되는 타겟 증강 작업을 결정할 수 있다. 이때, 도 4에 도시된 바와 같이, 1차 처리(0번째 반복)에서, 제1 모델은 제1 네트워크 및 제2 네트워크를 통해 타겟 데이터에 적합한 타겟 증강 작업을 결정할 수 있다. 선택적으로, 제1 네트워크 및 제2 네트워크를 통해, 기설정된 복수의 증강 작업에서 타겟 데이터의 1차 처리에 대응하는 타겟 증강 작업을 결정하는 것은 구체적으로 다음의 과정을 수행할 수 있다. 데이터 처리 장치는 제1 네트워크를 통해 타겟 데이터의 1차 처리의 상태 특징을 결정한다. 그리고, 데이터 처리 장치는 제2 네트워크를 통해 1차 처리된 상태 특징을 기반으로 다음 반복의 출력 벡터를 결정할 수 있다. 그리고, 데이터 처리 장치는 다음 반복의 출력 벡터를 기설정된 조건에 대응하는 증강 작업에 만족시켜, 타겟 데이터의 다음 반복에 대응하 는 타겟 증강 작업을 결정할 수 있다. 구체적으로, 1차 처리(즉, 0번째 반복) 동안, 도 4와 같이, 입력 이미지(I0)를 백본 네트워크에 해당 하는 제1 네트워크에 전송하여 I0의 상태 특징을 얻을 수 있으며, 이는 RNN 유닛에 해당하는 제3 네트워크 의 히든 상태 state0로 간주될 수 있다. 출력 유닛에 해당하는 제2 네트워크는 제1 모델의 일부로서 상태 특징 state0의 변형(reshape), 풀링(pooling), 선형 변환(linear), 정규화(softmax) 등 작업을 포함할 수 있고, 구체적으로 상이한 제1 네트워크에 따라 유연하게 조절할 수 있다. 데이터 처리 장치는 기설정된 조건이 한 번의 반복으로 타겟 증강 작업을 결정하는 것이라면, 제2 네트워크에 의해 출력된 출력 벡터가 입력 이미지(I0)의 N개의 증강을 진행한 후 제2 모델에서의 손실값에 맞추는 것 을 기반으로, 해당 출력 벡터의 최소값(argmin 함수에 의해 결정될 수 있는, 즉 출력 벡터가 최소가 될 때의 변 수 값)의 위치에 해당하는 증강 작업 a0이 I0에 적용 가능한 증강 작업인 것을 결정할 수 있다. 실현 가능한 실시예에서, 102 단계는 다음의 도 14를 포함할 수 있다. 도 14는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 타겟 증강 동작 시퀀스를 획득하는 흐름도이다. 도 14를 참조하면, 데이터 처리 장치는 현재 반복에 해당하는 타겟 증강 작업이 무작업 이외의 증강 작업인 경 우, 제3 네트워크는 현재 반복의 상태 특징 및 현재 반복에 대응하는 타겟 증강 작업을 기반으로 다음 반복의 상태 특징을 결정하고, 제2 네트워크를 통해 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하고, 기설정된 반복 종료 조건을 충족시킬 때까지 적어도 하나의 타겟 증강 작업 시퀀스를 출력할 수 있다 . 구체적으로, 도 4에 도시된 바와 같이, 제1 모델의 RNN 유닛은 첫 번째 반복부터 시작된다. 단순한 순환 (cyclic) 반복과 달리, 본 개시의 실시예에서 제공하는 알고리즘은 진정한 의미에서 테스트 이미지(입력 이미지 ) I0의 a0 증강(즉 테스트 이미지 I1의 생성)을 실현할 필요가 없으며, 대신에 상태 특징 state0 및 인코딩 된 a0을 사용하여 RNN 유닛에 전송할 수 있다. 출력된 상태 특징 state1은 테스트 이미지 I1의 특징을 나타 내기에 충분하다. 따라서, 데이터 처리 장치는 상태 특징 state1을 제2 네트워크(출력 유닛)로 직접 전송 하면 테스트 이미지 I1에 적합한 타겟 증강 작업 a1을 획득할 수 있고, 그런 다음 테스트 이미지 I0에 적합한 이 차 증강{a0，a1}을 얻을 수 있다. 데이터 처리 장치는 후속 단계 또한 이와 같이 진행할 수 있고, 반복 종료에는 두 가지 조건이 있을 수 있으며, 그중 하나를 만족하면 반복을 종료할 수 있다. 테스트 이미지 I1는 테스트 이미지 I0의 증강된 사본으로 간주될 수 있다. 선택적으로, 반복 종료 조건에는 다음 두 가지 항목이 포함된다. 반복 종료 조건 1: 임의의 반복에 대응하는 타겟 증강 작업이 무작업(별도의 증강 작업이 없는 경우)인 경우이 다. 이때, 타겟 데이터에 적용할 수 있는 예측된 증강 작업이 작업 없음인 경우, 해당 타겟 데이터는 이미 최적 상 태에 도달하여 더 이상의 증강이 필요하지 않음을 의미할 수 있다. 반복 종료 조건 2: 반복 횟수가 기설정된 최대 반복 횟수에 도달한 경우이다. 이때, 데이터 처리 장치는 요구 사항에 따라 최대 반복 횟수를 설정할 수 있으며, 해당 값을 설정하면 계산량을 효과적으로 제한할 수 있으므로 궁극적으로 타겟 데이터에 더 적합한 복수의 증강을 얻을 수 있다. 본 개시의 실시예에서, 데이터 처리 장치는 캐스케이드 반복 방법을 통해 타겟 데이터를 처리하면, 증강 전략의 검색 공간을 효과적으로 확장할 수 있다. 도 5는 본 개시의 실시예에 따른 데이터 처리 장치에서 검색 공간 확장이 확장된 예를 도시한 예시도이다. 도 5에 도시된 바와 같이, 타겟 데이터를 테스트 이미지로 예를 들면, N(기설정된 증강 작업의 수)이 2, 즉 기 설정된 증강 작업이 두 가지(선명화 및 채도)라고 가정하면, 관련 기술 L2T(Learning Loss for Test-Time Augmentation) 알고리즘의 단일 반복에는 선명화 및 채도의 두 가지 유형의 증강 전략 검색 공간만 있다. 그러 나 본 개시의 캐스케이드 반복에서는 반복 횟수가 증가함에 따라 공간 용량이 기하급수적으로 증가하였다. 예를 들어, 반복 횟수가 2일 때 증강 전략의 검색 공간은 선명화-선명화, 선명화-채도, 채도-선명화, 채도-채도의 4 가지 유형으로 커진다. 이와 같이 반복 횟수가 t일 때 공간 용량은 2t로 증가한다. 공간 용량의 증가는 TTA 방 법 유효성의 상한(upper bound) 증가로 이어질 수 있다. 여기서 상한은 TTA 방법이 예측 효과를 개선하기 위해 테스트 세트의 각 이미지에 대해 적절한 증강을 올바르게 선택할 수 있음을 의미한다. 선택적으로, 도 14의 1410단계는 다음 도 15의 단계를 포함할 수 있다. 도 15는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제2 네트워크를 통해 다음 반복의 상태 특징을 기반 으로 다음 반복의 타겟 증강 작업을 결정하는 흐름도이다. 도 15를 참조하면, 데이터 처리 장치는 제2 네트워크를 통해 다음 반복의 상태 특징을 기반으로 다음 반복의 출 력 벡터를 결정할 수 있다. 그리고, 데이터 처리 장치는 다음 반복의 출력 벡터에서 기설정된 조건을 충족하는 벡터에 대응하는 증강 작업 을 다음 반복의 타겟 증강 작업으로 결정할 수 있다. 구체적으로, 데이터 처리 장치는 캐스케이드 반복의 프로세스 중, 제2 네트워크는 다음 반복의 상태 특징을 기 반으로 다음 반복의 출력 벡터를 출력할 수 있다. 훈련 부분에서 언급한 바와 같이, 제2 네트워크의 출력 벡터 는 기설정된 N개의 증강 작업을 수행한 후 타겟 모델에서의 타겟 데이터의 손실값을 맞추는(fitting) 것으로 이 해할 수 있다. 따라서 기설정된 조건을 만족하는 출력 벡터의 위치에 대응하는 증강 작업이 타겟 데이터에 적합 하다고 판단할 수 있다. 기설정된 조건이 한 반복에서 하나의 타겟 증강 작업만 결정된다면, 데이터 처리 장치 는 출력 벡터에서 최소값의 위치에 대응하는 증강 작업을 대응하는 타겟 증강 작업으로 결정할 수 있다. 기설정 된 조건이 M(M은 1보다 큰 양의 정수)개의 타겟 증강 작업을 1회 반복으로 결정하는 것이라면, 데이터 처리 장 치는 M개의 타겟 증강 작업이 1회 반복으로 결정될 때 벡터 중 가장 작은 M값에 대응하는 증강 작업을 대응하는 타겟 증강 작업으로 결정할 수 있다. 실행 가능한 실시예에서, 데이터 처리 장치는 각 반복에서 복수의 타겟 증강 작업을 결정할 수 있으며, 이하 다 양한 상황에 대해 설명한다. 상황 1: 각 반복은 타겟 증강 작업을 결정한다. 도 6a는 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 일 예를 도시한 흐름도이다. 도 6a에 도시된 바와 같이, 데이터 처리 장치는 전체 테스트 단계에서 각 반복에 대해 타겟 데이터인 입력 이미 지에 적용할 수 있는 하나의 타겟 증강 작업만 결정된다. 해당 방법의 구현에서는 반복 분기가 하나 만 있으며, 궁극적으로 하나의 타겟 증강 작업 시퀀스가 출력된다. 데이터 처리 장치는 타겟 증강 작업 시퀀스 에 의한 증강된 이미지 IT를 타겟 모델인 타겟 모델에 제공할 수 있다. 상황 2: 데이터 처리 장치는 현재 반복에서 결정된 타겟 증강 작업이 N개를 포함하고, N은 1보다 큰 정수인 경 우, 각각의 타겟 증강 작업과 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정한다. 그리고, 데이 터 처리 장치는 다음 반복의 상태 특징을 기반으로 다음 반복의 타겟 증강 작업을 결정하여, 기설정된 반복 종 료 조건이 만족될 때까지 순차적으로 반복을 실행하여 N개의 타겟 증강 작업 시퀀스를 출력한다. 구체적으로, 데이터 처리 장치는 현재 반복의 타겟 증강 작업에 N 항목이 포함된 경우, 각 타겟 증강 작업을 바 탕으로 각각 다음 반복을 진행하며, 다음 반복은 하나의 타겟 증강 작업만을 결정한다. 해당 상황의 처리는 최 종적으로 N개의 타겟 증강 작업 시퀀스를 출력하게 한다. 도 6b는 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 다른 예를 도시한 흐름도이다. 도 6b에 도시된 바와 같이, 데이터 처리 장치는 예를 들어 첫 번째 반복의 타겟 증강 작업에 K개가 포함된 경우, K개의 병렬 분기(631, 632)가 존재할 수 있다. 각 분기(631, 632)는 연속적인 캐스케이드 타겟 증강 작업 세트를 나타낸다. 예를 들어, 데이터 처리 장치는 K가 2일 때, 2개의 병렬 분기(631, 632)가 존재하고, T차 반 복 후에 두 개의 서로 다른 연속적으로 증강된 이미지 I0,T 및 I1,T를 획득할 수 있다. 상황 3: 데이터 처리 장치는 현재 반복에서 결정된 타겟 증강 작업이 N 개를 포함하고, N은 1보다 큰 정수인 경 우, 각각의 타겟 증강 작업과 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정한다. 그리고, 데이 터 처리 장치는 다음 반복의 상태 특징을 기반으로 다음 반복에 대한 N개의 증강 작업을 결정한다. 그리고, 데 이터 처리 장치는 결정된 N*N개 증강 동작 중에서 N개의 증강 작업을 선택하여 다음 반복을 위한 타겟 증강 작 업을 결정하고, 기설정된 반복 종료 조건이 만족될 때까지 순차적으로 반복을 실행하여 N 개의 타겟 증강 작업 시퀀스를 출력한다. 구체적으로, 데이터 처리 장치는 현재 반복에 대응하는 타겟 증강 작업을 N개 포함하는 경우, 각각의 타겟 증강 작업에 기초하여 다음 반복을 진행할 수 있다. 그리고, 데이터 처리 장치는 다음 반복에 대한 N개의 증강 작업 을 각각 결정할 수 있다. 이때, 다음 반복에는 총 N*N 증강 작업을 포함할 수 있다. 그리고, 데이터 처리 장치 는 반복 횟수가 증가함에 따라 계산 작업 부하가 증가하는 것을 방지하기 위해 해당 N*N 증강 작업에서 N 항목 (현재 반복의 타겟 증강 작업의 항목 수와 일치함)을 다음 반복의 타겟 증강 작업으로 유지할 수 있다. 해당 상황의 처리는 최종적으로 N개의 타겟 증강 작업 시퀀스를 출력하게 한다. 도 6c는 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 또 다른 예를 도시한 흐름도이다. 도 6c에 도시된 바와 같이, 데이터 처리 장치는 현재 반복을 0번째 반복으로 예로 들면, 첫 번째 반복에서의 타 겟 증강 작업이 K개를 포함한다면, 각 반복마다 K개의 최적 증강 작업이 선택된다(641, 642)(도 6c에서 K=2를 예로 듬). 도 6c에 도시된 예시에서, 데이터 처리 장치는 첫 번째 반복부터 시작하여 빔 검색(beam search)을 사용하여 반복 횟수가 증가함에 따라 병렬 분기가 증가하고 계산량이 지나치게 커지는 것을 효과적으로 방지할 수 있다. 구체적으로, 데이터 처리 장치는 0번째 반복에서 2개의 타겟 증강 작업을 선택하면 2개의 분기를 얻을 수 있다. 데이터 처리 장치는 첫 번째 반복에서, 각 분기에 대해 2개의 타겟 증강 작업을 선택하면 첫 번째 반 복에는 총 4개의 타겟 증강 작업이 포함되고, 후속적으로 4개의 분기를 가져오므로, 계산량이 증가하는 것을 방 지하기 위해 4개의 타겟 증강 작업에서 최적의 2개를 첫 번째 반복에 대응하는 타겟 증강 작업으로 선택할 수 있다. 즉, 데이터 처리 장치는 4개 분기 중 2개 분기를 선택(641, 642)하여 후속 캐스케이드 반복을 수행하여, 궁극적으로 두 개의 서로 다른 연속적으로 증강된 이미지 I0,T 및 I1,T를 획득할 수 있다. 도 6b 및 도 6c에 도시된 예시는 도 6a에 도시된 예시와 비교하여 제1 모델 출력의 일련의 타겟 증강 작업이 테 스트 단계에서 제2 모델을 보다 안정적이고 우수한 효과를 얻을 수 있게 함을 이해할 수 있다. 상황 4: 데이터 처리 장치는 현재 반복에서 결정된 타겟 증강 작업을 N(N은 1보다 큰 정수)개 포함하는 경우, 각 타겟 증강 작업 및 현재 반복의 상태 특징에 대해 다음 반복의 상태 특징을 결정한다. 그리고, 데이터 처리 장치는 다음 반복의 상태 특징에 따라 기설정된 반복 종료 조건이 만족될 때까지 다음 반복의 N개의 타겟 증강 작업을 결정하고, 복수의 타겟 증강 작업 시퀀스를 출력한다. 구체적으로, 데이터 처리 장치는 계산량을 고려하지 않고 타겟 데이터에 대해 보다 적합한 타겟 증강 작업을 찾 기 위해, 이전 반복에서 얻은 각각의 타겟 증강 작업에 대해 다음 반복에서 반복 처리를 수행할 수 있다. 구체 적으로, 데이터 처리 장치는 1차 반복이 N개의 타겟 증강 작업을 결정하고 첫 번째 반복이 N개의 반복 분기를 포함하는 경우, 각 분기에 대해 각각 반복을 진행할 수 있다. 그리고, 데이터 처리 장치는 첫 번째 반복에서 각 분기에 대해 N개의 타겟 증강 작업을 결정할 수 있다. 즉, 데이터 처리 장치는 첫 번째 반복에서 총 N*N개 의 타겟 증강 작업을 획득할 수 있다. 그리고, 데이터 처리 장치는 두 번째 반복에서 N*N개의 반복 분기를 포함 하고, 기설정된 반복 종료 조건이 만족될 때까지 각 분기에 대해 반복을 계속하여 복수의 타겟 증강 작업 시퀀 스를 출력한다. 상황 3은 계산량을 줄이면서 결정된 타겟 증강 작업의 정확성을 보장하기 위해 상황 4에 기초하여 번들 검색 처 리를 사용하는 것과 동일하다는 것을 이해할 수 있다. 선택적으로, 104단계에서 증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 그에 따라 증강된 타겟 데이터를 처리하고, 타겟 데이터에 대응하는 예측 결과를 획득하는 단계는 다음의 단계를 포함할 수 있다. 104단계는 타겟 증강 작업 시퀀스를 복수개 포함하는 경우, 타겟 증강 작업 시퀀스에 기초하여 데이터를 증강한 후 얻은 복수의 증강된 타겟 데이터를 훈련된 제2 모델에 각각 입력하여 복수의 출력 결과를 얻고, 복수의 출력 결과를 통합하여 타겟 데이터에 대응하는 예측 결과를 획득하는 단계를 포함할 수 있다. 구체적으로, 도 6b 및 도 6c에 도시된 바와 같이, 데이터 처리 장치는 복수의 분기가 포함될 때, 각각의 분기는 최종적으로 입력 이미지 I0에 적용 가능한 복수의 세트의 일련의 타겟 증강 작업을 포함하는 타겟 증강 작업 시 퀀스를 출력한다. 데이터 처리 장치는 2개의 분기가 포함되어 있다고 가정하면, 입력 이미지 I0에 적용 가능한 두 세트의 타겟 증강 작업을 포함한다. 이때, 증강된 입력 이미지는 2개(지속적인 강화를 통해 획득)를 포함한 다. 그리고, 데이터 처리 장치는 2개의 증강된 입력 이미지 I0,T 및 I1,T를 제2 모델에 입력하여 2개의 출력 결과 를 획득한 다음, 두 출력 결과를 통합하여 최종 출력된 타겟 데이터에 대한 예측 결과를 획득할 수 있다. 이때, 통합은 출력 결과의 평균값일 수 있다. 선택적으로, 도 6a에 도시된 바와 같이, 데이터 처리 장치는 오직 하나의 분기만 있을 때, 하나의 타겟 증강 작 업 시퀀스를 최종적으로 출력한다. 즉, 데이터 처리 장치는 일련의 적용 가능한 타겟 증강 작업에 의해 한 세트 의 입력 이미지 I0를 증강하여 증강된 입력 이미지IT를 획득하고, 그런 다음 해당 증강된 입력 이미지IT를 제2 모델로 전송하여 예측 결과를 획득한다. 이하, 구체적 예시를 결합하여 제1 모델의 테스트 부분과 관련된 각 작업 단계에 대해 아래에서 설명한다. 일 예시에서, 타겟 데이터를 테스트 이미지인 경우를 예로 들어 제1 모델의 테스트 부분에 대해 아래에서 도 16 을 참조하여 설명한다. 도 16은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제1 모델을 테스트하는 과정을 도시한 흐름도이다. 도 16을 참조하면, 데이터 처리 장치는 테스트 부분의 최대 반복 횟수를 T로 미리 설정한다. 여기서의 반 복 횟수 T와 훈련 부분의 반복 횟수 L은 서로 영향을 미치지 않는다는 것을 알 수 있다. 본 개시의 실시예는 반 복 횟수를 유연하게 조절할 수 있다. 그리고, 데이터 처리 장치는 테스트 이미지 I0를 제1 모델의 제1 네트워크로 전송하여 0번째 반복의 상태 특징 state0을 획득한다. 이때, 1620단계는 0번째 반복의 실행에 해당한다. 그리고, 데이터 처리 장치는 0번째 반복의 상태 특징 state0을 제2 네트워크로 전송하여 출력 벡터 p0를 획득한 다. 이때, 출력 벡터 p0는 N개의 증강 후 제2 모델에서 테스트 이미지 I0의 손실값에 적합하므로, 출력 벡 터 p0에서 최소값의 위치에 대응하는 증강 작업은 0번째 반복에서 출력되는 타겟 증강 작업 a0이다. 그리고, 데이터 처리 장치는 타겟 증강 작업 a0이 무작업인지 여부를 판단한다. 1640단계의 확인결과 타겟 증강 작업이 무작업이 아니면, 데이터 처리 장치는 j-1번째 반복의 상태 특징 statej- 1 및 인코딩된 aj-1를 각각 히든 상태(hidden state) 및 입력(input)으로 RNN 유닛에 전송하여 j 번째 반복의 상 태 특징 statej을 획득할 수 있다. 이때, 1650단계는 j번째 반복의 실행에 해당한다. 1650단계에서 j번째 가 첫번째인 경우, 데이터 처리 장치는 0번째 반복의 상태 특징 state0 및 인코딩된 a0를 각각 히든 상태(hidden state) 및 입력(input)으로 RNN 유닛에 전송하여 첫 번째 반복의 상태 특징 state1을 획득할 수 있다. 그리고, 데이터 처리 장치는 j 번째 반복의 상태 특징 statej을 제2 네트워크에 전송하여 출력 벡터 pj를 획득하 고, 출력 벡터 pj에서 최소값의 위치에 대응하는 증강 작업인 타겟 증강 작업 aj을 확인할 수 있다. 그리고, 데이터 처리 장치는 타겟 증강 작업 aj이 무작업인지 여부를 판단한다. 1670단계의 확인결과 타겟 증강 작업이 무작업이 아니면, 데이터 처리 장치는 최대 반복 횟수에 도달했는지 확 인한다. 1680단계의 확인결과 최대 반복 횟수에 도달하지 않았으면, 1650단계로 돌아가 일련과 과정을 반복 수행한다. 모든 반복에 의해 출력되는 타겟 증강 작업은 순서대로 {a0，a1，…, at}이다. 1640단계 또는 1670의 확인결과 타겟 증강 작업이 무작업이거나, 또는 최대 반복 횟수에 도달한 경우, 데이터 처리 장치는 원본 테스트 이미지 I0에 대해 일련의 타겟 증강 작업을 계속 수행하여 It를 획득하고, 획득한 It를 제2 모델로 보내 최종 결과를 획득한다. 본 개시의 실시예에서 제공하는 데이터 처리 방법이 달성할 수 있는 기술적 효과를 더 잘 설명하기 위해, 설정 데이터 세트에 대한 처리 상황과 관련하여 다음을 설명한다. 도 17은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 설정 데이터 세트에 대한 분류 작업의 시각화 효과 의 예시도이다. 도 17은 본 개시의 설정 데이터 세트(Cifar10 및 Cifar10-c)에 대한 분류 작업의 시각화 효과를 표시한다. 도 17을 참조하면, 두개의 행은 두 개의 예시 이미지를 나타낸다. 첫 번째 열은 원래 Cifar10 데이터 세트(범용 객 체를 식별하는데 사용되는 데이터 세트)의 이미지이다. 두 번째 열은 손상된(corruption) 이미지로, 손상 방식 은 이미지 아래에 있는 콘텐츠와 같다. 예를 들어 두 번째 열의 두 번째 이미지는 채도로 인해 손상되었다. 마 지막 세 번째 열은 각기 다른 반복 후 캐스케이드 증강 효과를 보여준다. 첫 번째 행의 자동차(automobile) 카 테고리를 예로 들면, 가우시안 노이즈를 경험한 후 이미지가 손상되고 제2 모델이 올바르게 분류될 수 없다. 단 일 반복의 TTA, 즉 선명화 증강 작업을 거친 후 개선은 되었지만 여전히 카테고리를 식별하기 어렵다. 그러나 본 개시에서 선명화, 채도 및 대비 증강을 지속적으로 사용하면 이미지 분류 효과가 시각적으로 더 정확한 경향 을 보인다.본 개시는 이미지 분류 작업뿐만 아니라 대부분의 컴퓨터 비전 작업에도 사용할 수 있다. 타겟 검출 작업의 예 시도는 도 18에 도시되어 있다. 도 18은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 타겟 검출 작업에 대한 효과를 도시한 예시도이다. 도 18을 참조하면, 원본 입력 이미지에서 타겟 모델인 제2 모델을 사용하여 이미지의 황소를 검출 하는 경우, 데이터 분포 드리프트의 문제로 인해 검출이 부정확할 수 있다(흰색 점선 박스에 표시된 결과). 그러나 데이터 처리 장치는 원본 입력 이미지를 캐스케이드 손실 예측 모델인 제1 모델에 입력하고 대비, 채도 및 스케일의 3가지 증강 작업을 연속 사용하여 데이터를 증강한 후 증 강된 이미지를 타겟 모델인 제2 모델에 입력하여 보다 더 정확한 결과를 얻을 수 있다(흰색 실선 박스 에 표시된 결과). 도 19는 본 개시의 실시예에 따른 데이터 처리 장치의 구성을 개략적으로 도시한 예시도이다. 도 19를 참조하면, 데이터 처리 장치는 프로세서 및 메모리를 포함할 수 있다. 메모리는 읽기 전용 메모리(ROM) 또는 정적 정보 및 명령을 저장할 수 있는 다른 유형의 정적 저장 장치, 랜덤 액세스 메모리(RAM) 또는 정보 및 명령을 저장할 수 있는 다른 유형의 동적 저장 장치일 수 있고, EEPROM, CD-ROM 또는 기타 광 디스크 스토리지, 광 디스크 스토리지(압축 광 디스크, 레이저 디스크, 광 디스크, 디지털 다목적 디스크, 블루 레이 디스크 등 포함), 디스크 저장 매체, 기타 자기 저장 장치 또는 컴퓨터 프로그램을 운반하거나 저장하는데 사용할 수 있고 컴퓨터에서 읽을 수 있는 기타 모든 매체일 수도 있으며, 여기서 이에 대해 제한하지는 않는다. 메모리는 본 개시의 실시예를 실행하기 위한 컴퓨터 프로그램을 저장하는데 사용되며 프로세서에 의해 제어된다. 프로세서는 타겟 데이터를 획득하고, 훈련된 제1 모델에 기초하여 타겟 데이터를 처리하여 적어도 하나의 타겟 증강 작업 시퀀스를 획득하고, 타겟 증강 작업 시퀀스에 따라 타겟 데이터에 대해 데이터 증강을 수행하고, 증강된 타겟 데이터를 훈련된 제2 모델에 입력하여 상기 증강된 타겟 데이터에 대해 상응하는 처리를 진행하여 상기 타겟 데이터에 대응하는 예측 결과를 획득할 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 실행하여 전술한 방법 실시예에 도시된 단계들을 실현하도록 구성된다. 본 개시 실시예는 메모리, 프로세서 및 메모리에 저장된 컴퓨터 프로그램을 포함하는 전자 장치를 제공한다. 해 당 프로세서는 컴퓨터 프로그램을 실행하여 데이터 처리 방법의 단계를 구현하고, 종래 기술과 비교하여 다음을 구현할 수 있다. 테스트 단계에서 테스트를 위한 타겟 데이터를 획득할 때, 먼저 이미 훈련된 제1 모델에 대해 타겟 데이터 처리하여 캐스케이드된 적어도 두 개의 증강 작업을 포함하는 적어도 하나의 타겟 증강 작업 시퀀 스를 획득한다. 그런 다음, 해당 타겟 증강 작업 시퀀스를 기반으로 타겟 데이터에 대해 데이터를 증강하고, 증강된 타겟 데이터를 이미 훈련된 제2 모델에 입력하여 그에 따라 증강된 타겟 데이터를 처리하여 타겟 데이터 의 대응하는 예측 결과를 얻을 수 있다. 본 개시 기술방안의 구현은 제2 모델을 변경하지 않는 전제 하에 타겟 데이터의 캐스케이드 반복 처리 방법을 통해, 타겟 데이터에 상응하는 일련의 타겟 증강 작업을 적응적으로 계 단식으로 예측할 수 있고, 보다 낮은 계산 비용으로 증강 작업의 검색 공간과 상한을 확장하여 더 적합한 증강 작업을 찾을 수 있다. 또한, 증강된 타겟 데이터를 기반으로 훈련된 제2 모델을 테스트하여 기존 방안보다 더 나은 예측 효과를 얻을 수 있다. 선택 가능한 실시예에서, 전자 장치를 제공할 수 있다. 도 20은 본 개시의 실시예에 따른 전자 장치의 개략적인 구성을 도시한 예시도이다. 도 20에 도시된 바와 같이, 도 20에 도시된 전자 장치는 프로세서 및 메모리를 포함할 수 있 다. 이때, 프로세서는, 예를 들어 버스를 통해 메모리에 연결된다. 선택적으로, 전자 장치(200 0)는 통신부를 더 포함할 수 있으며, 통신부는 데이터 송신 및/또는 데이터 수신과 같은 전자 장치와 다른 전자 장치 간의 데이터 상호작용을 위해 사용될 수 있다. 실제 응용에서 통신부는 하나로 제한되 지 않으며, 해당 전자 장치의 구조는 본 개시 실시예에 대한 제한을 구성하지 않는다는 점에 유의해야 한 다. 프로세서는 CPU, 범용 프로세서, DSP, 주문형 집적 회로(ASIC), 필드 프로그램 가능 게이트 어레이(FPGA) 또는 기타 프로그램 가능 논리 장치, 트랜지스터 논리 장치, 하드웨어 구성 요소, 또는 이들의 임의의 조합일 수 있다. 이는 본 개시에서 설명된 다양한 예시적 논리 블록, 모듈 및 회로를 구현하거나 실행할 수 있다. 프로 세서는 또한, 예를 들어, 하나 이상의 마이크로프로세서 조합, DSP와 마이크로프로세서의 조합 등을 포함 하는 컴퓨팅 기능을 실현하는 조합일 수 있다. 버스는 구성요소들 사이에서 정보를 전달하기 위한 경로를 포함할 수 있다. 버스는 PCI(Peripheral Component Interconnect) 버스 또는 EISA(Extended Industry Standard Architecture) 버스일 수 있다. 버스 는 어드레스 버스, 데이터 버스, 제어 버스 등으로 구분될 수 있다. 예시의 편의를 위해, 도 20에는 굵은 선 하나만 도시하였으나, 버스가 하나 또는 한 종류만 있는 것은 아니다. 메모리는 읽기 전용 메모리(ROM) 또는 정적 정보 및 명령을 저장할 수 있는 다른 유형의 정적 저장 장치, 랜덤 액세스 메모리(RAM) 또는 정보 및 명령을 저장할 수 있는 다른 유형의 동적 저장 장치일 수 있고, EEPROM, CD-ROM 또는 기타 광 디스크 스토리지, 광 디스크 스토리지(압축 광 디스크, 레이저 디스크, 광 디스크, 디지털 다목적 디스크, 블루 레이 디스크 등 포함), 디스크 저장 매체, 기타 자기 저장 장치 또는 컴퓨터 프로그램을 운반하거나 저장하는데 사용할 수 있고 컴퓨터에서 읽을 수 있는 기타 모든 매체일 수도 있으며, 여기서 이에 대해 제한하지는 않는다. 메모리는 본 개시의 실시예를 실행하기 위한 컴퓨터 프로그램을 저장하는데 사용되며 프로세서에 의해 제어된다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 실행하여 전술한 방법 실시예에 도 시된 단계들을 실현하도록 구성된다. 본 출원 실시예에서 제공하는 방법은 AI 모델을 통해 구현될 수 있다. AI와 관련된 기능은 비휘발성 메모리, 휘 발성 메모리 및 프로세서에 의해 수행될 수 있다. 해당 프로세서는 하나 이상의 프로세서를 포함할 수 있다. 이때, 해당 하나 이상의 프로세서는 범용 프로세서 (예, 중앙 처리 장치(CPU), 응용 프로세서(AP) 등) 또는 순수 그래픽 처리 장치(예, 그래픽 처리 장치(GPU), 시 각 처리 장치(VPU)), 및/또는 AI 전용 프로세서(예, 신경 처리 장치(NPU))일 수 있다. 해당 하나 이상의 프로세서는 비휘발성 메모리 및 휘발성 메모리에 저장된 사전 정의된 동작 규칙 또는 인공 지 능(AI) 모델에 따라 입력 데이터의 처리를 제어한다. 훈련 또는 학습을 통해 사전 정의된 동작 규칙 또는 인공 지능 모델을 제공한다. 여기서, 학습에 의한 제공은 복수의 학습 데이터에 학습 알고리즘을 적용하여 사전 정의된 동작 규칙 또는 원하 는 특성을 갖는 AI 모델을 얻는 것을 의미한다. 이러한 학습은 실시예에 따른 AI가 수행되는 장치 자체에서 수 행될 수 있고, 및/또는 별도의 서버/시스템에 의해 구현될 수 있다. 해당 AI 모델은 복수의 신경망 레이어로 구성될 수 있다. 각 레이어는 복수의 가중치 값을 가지며, 하나의 레이 어의 계산은 이전 레이어의 계산 결과와 현재 레이어의 복수의 가중치에 의해 수행된다. 신경망의 예시로, 컨볼 루션 신경망(CNN), 심층 신경망(DNN), 순환 신경망(RNN), 제한된 볼츠만 머신(RBM), 심층 신뢰망(DBN), 양방향 순환 심층 신경망(BRDNN), 생성 대응 네트워크(GAN) 및 심층 Q 네트워크를 포함하나 이에 제한되지 않는다. 학습 알고리즘은 복수의 학습 데이터를 이용하여 소정의 타겟 장치(예, 로봇)를 훈련시켜 타겟 장치를 결정 또 는 예측하도록 유도, 허용 또는 제어하는 *?*방법이다. 해당 학습 알고리즘의 예시는 지도 학습(supervised learning), 비지도 학습, 반 지도 학습 또는 강화 학습을 포함하나 이에 국한되지는 않는다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 저장할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 저장될 수 있다. 소프트웨어는 네트워크로 연결된 컴 퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이 상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다."}
{"patent_id": "10-2023-0066511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2023-0066511", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시예에 따른 데이터 처리 장치에서 데이터를 처리하는 과정을 도시한 흐름도이다. 도 2는 본 개시의 실시예에 따른 증강 작업의 예를 도시한 도면이다. 도 3은 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 과정을 도시한 흐름도이다.도 4는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델의 처리 과정을 도시한 흐름도이다. 도 5는 본 개시의 실시예에 따른 데이터 처리 장치에서 검색 공간 확장이 확장된 예를 도시한 예시도이다. 도 6b는 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 다른 예를 도시한 흐름도이다. 도 6b는 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 다른 예를 도시한 흐름도이다. 도 6c는 본 개시의 실시예에 따른 데이터 처리 장치에서 테스트하는 또 다른 예를 도시한 흐름도이다. 도 7은 본 개시의 실시예에 따른 데이터 처리 장치의 레이블 생성기(label builder)의 구성의 예를 도시한 예시 도이다. 도 8a는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 일 예를 도시한 예시도이다. 도 8b는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 다른 예를 도시한 예시도이다. 도 8c는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 또 다른 예를 도시한 예시도이다. 도 8d는 본 개시의 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 또 다른 예를 도시한 예시도이다. 도 9는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 흐름도이다. 도 10은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제2 및 제3 네트워크를 통해 다음 반복의 각각의 기 설정된 증강 작업의 순위 손실을 결정하는 흐름도이다. 도 11은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 다음 반복의 각각의 기설정된 증강 작업의 순위 손 실을 결정하는 흐름도이다. 도 12는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 해당 훈련 레이블을 기반으로 다음 반본 훈련에서 얻은 각 증강 작업의 순위 손실을 결정하는 흐름도이다. 도 13은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제1 모델을 훈련하는 과정을 도시한 흐름도이다. 도 14는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 타겟 증강 동작 시퀀스를 획득하는 흐름도이다. 도 15는 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제2 네트워크를 통해 다음 반복의 상태 특징을 기반 으로 다음 반복의 타겟 증강 작업을 결정하는 흐름도이다. 도 16은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 제1 모델을 테스트하는 과정을 도시한 흐름도이다. 도 17은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 설정 데이터 세트에 대한 분류 작업의 시각화 효과 의 예시도이다. 도 18은 본 개시의 일 실시예에 따른 데이터 처리 장치에서 타겟 검출 작업에 대한 효과를 도시한 예시도이다. 도 19는 본 개시의 실시예에 따른 데이터 처리 장치의 구성을 개략적으로 도시한 예시도이다. 도 20은 본 개시의 실시예에 따른 전자 장치의 개략적인 구성을 도시한 예시도이다."}
