{"patent_id": "10-2023-0090226", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0010251", "출원번호": "10-2023-0090226", "발명의 명칭": "아이템 영역 풀링을 이용한 패션 스타일 분류 방법 및 장치", "출원인": "주식회사 딥패션", "발명자": "남정우"}}
{"patent_id": "10-2023-0090226", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "아이템 영역 풀링을 이용한 패션 스타일 분류 방법에 있어서,(a) 전역특징추출부가 백본 네트워크와 사전학습된 영상-텍스트처리모델, 영상처리 모델 중 적어도 하나를 이용하여 입력된 이미지로부터 전역적특징을 추출하는 단계;(b) 아이템특징추출부가 입력된 이미지로부터 다수개의 패션 아이템 영역에서 각각의 패션아이템별로 아이템별특징을 추출하는 단계;(c) 스타일분류부가 추출된 상기 전역적특징과 아이템별 특징을 결합하고, 결합된 전체특징벡터를 전역연결계층에 입력하여 패션스타일을 분류하는 단계를 포함하는 아이템 영역 풀링을 이용한 패션 스타일 분류 방법."}
{"patent_id": "10-2023-0090226", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 (b) 단계는,아이템특징추출부의 아이템영역세그멘테이션모듈이 입력된 이미지의 픽셀별로 물체를 식별하여 분류하여 물체의마스크 정보를 추출하는 단계;아이템특징추출부의 크기조정모듈이 추출한 아이템별 마스크들을 전역적특징맵의 크기와 일치하도록 크기를 조정하는 단계를 포함하는 아이템 영역 풀링을 이용한 패션 스타일 분류 방법."}
{"patent_id": "10-2023-0090226", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,아이템특징추출부의 산술연산모듈이 크기 조정된 아이템별 마스크들과 전역적특징맵을 산술연산곱셈을 통해 아이템영역만의 특징을 추출하는 단계;아이템특징추출부의 변환인코더모듈이 추출된 각각의 아이템영역만의 특징에 대해 변환하는 단계를 더 포함하는아이템 영역 풀링을 이용한 패션 스타일 분류 방법."}
{"patent_id": "10-2023-0090226", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,아이템특징추출부의 다운샘플링모듈이 변환된 각각의 아이템영역만의 특징에 대해 다운샘플링하는 단계;아이템특징추출부의 GLU모듈이 다운샘플링된 아이템영역만의 특징의 입력의 절반에 시그모이드 함수를 취한 것과 나머지 입력의 절반을 산술연산곱셈 계산하여 반영할 아이템특징을 추출하는 단계를 더 포함하는 아이템 영역 풀링을 이용한 패션 스타일 분류 방법."}
{"patent_id": "10-2023-0090226", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "백본 네트워크와 영상-텍스트처리모델을 이용하여 입력된 이미지로부터 전역적특징 추출하는 전역특징추출부;입력된 이미지의 픽셀별로 물체를 식별하여 분류하여 물체의 마스크 정보를 추출하고, 추출한 아이템별 마스크공개특허 10-2025-0010251-3-들을 전역적특징맵의 크기와 일치하도록 크기를 조정하고, 크기조정된 아이템별 마스크들과 전역적특징맵을 산술연산곱셈을 통해 아이템영역만의 특징을 추출하고, 추출된 각각의 아이템영역만의 특징에 대해 변환하고, 변환된 각각의 아이템영역만의 특징에 대해 다운샘플링하고, 다운샘플링된 아이템영역만의 특징의 입력의 절반에시그모이드 함수를 취한 것과 나머지 입력의 절반을 산술연산곱셈 계산하여 반영할 아이템특징을 추출하여 입력된 이미지로부터 다수개의 패션 아이템 영역에서 각각의 패션아이템별로 아이템별 특징 추출하는 아이템특징추출부; 및추출된 전역적특징과 아이템별 특징을 결합하고, 결합된 전체특징벡터를 전역연결계층에 입력하여 패션스타일분류하는 스타일분류부를 포함하는 아이템 영역 풀링을 이용한 패션 스타일 분류 장치."}
{"patent_id": "10-2023-0090226", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 아이템 영역 풀링을 이용한 패션 스타일 분류 방법에 관한 것으로, 전역특징추출부가 백본 네트워크와 영상-텍스트처리모델을 이용하여 입력된 이미지로부터 전역적특징을 추출하는 단계와, 아이템특징추출부가 입력 된 이미지로부터 다수개의 패션 아이템 영역에서 각각의 패션아이템별로 아이템별 특징을 추출하는 단계와, 스타 일분류부가 추출된 상기 전역적특징과 아이템별 특징을 결합하고, 결합된 전체특징벡터를 전역연결계층에 입력하 여 패션스타일을 분류하는 단계를 포함한다."}
{"patent_id": "10-2023-0090226", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 아이템 영역 풀링을 이용한 패션 스타일 분류 방법 및 장치로, 이미지로부터 전역적 특징과 패션 아 이템 영역별 특징을 추출하여 패션 영상 전체에서 추출한 전역적 특징과 아이템별 특징을 결합하고, 결합된 전 체 특징벡터를 스타일 분류 계층에 입력함으로써 영상 전체, 또는 인물 영역 단위의 특성 뿐 아니라 각 아이템 단위의 특성을 섬세하게 반영해 패션 스타일을 분류할 수 있는 아이템 영역 풀링을 이용한 패션 스타일 분류 방 법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0090226", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 모바일 의류쇼핑 앱이 인기를 끌면서, 패션 이커머스(eCommerce) 시장이 빠르게 성장하고 있다. 온라인 패 션 스토어는 오프라인 매장에 비해 시공간의 제약을 받지 않으며, 많은 상품들을 빠르게 비교할 수 있다는 장점 이 있다. 패션 산업에서는 기존의 패션 디자인과 트렌드에 더해, 소비자의 취향과 스타일에 대한 이해가 필요하 며 소비자의 스타일을 파악하고 이에 맞는 제품을 제공하는 것이 패션 산업에서의 경쟁력을 높일 수 이는 핵심 적인 요소이다. 세부적인 스타일 차이를 파악하고 분류할 수 있는 패션 스타일 인식기를 이용하면 패션 시장에 서 더 정확하고 다양한 패션 아이템 추천 서비스를 제공할 수 있을 것이다. 딥러닝이 이미지 분류나 객체 검출 분야에서 많은 발전을 이룬 후 여러 산업 분야에서 딥러닝을 적용하려는 시 도가 있었다. 패션 산업에도 패션 스타일 분류, 패션 이미지 생성 등에 딥러닝이 적용되었다. 그러나 각 패션 스타일의 명확한 기준을 정의하기 어렵고, 일부 스타일 간에는 시각적 유사도가 매우 높으며, 동일 스타일의 옷 이라도 시각적 차이가 크기 때문에 일반적인 딥러닝 영상 인식 방법을 그대로 적용해서는 좋은 성능을 얻기 어 렵다. 특히, 스타일은 패션 영상 전체의 전역적 특성 외에도 각 아이템들의 특성 및 조합에 의해 발현되기 때문 에 전역적 특성 만을 반영하는 일반적인 영상 인식 딥러닝 모델만으로는 우수한 스타일 분류 성능을 얻기 어려 우며 반드시 각 패션 아이템 별 특성 및 이들의 조합을 반영해 패션 스타일을 분류해야 한다. 선행기술로는 국내공개특허 제10-2021-0030240호(다중 레이블링 학습된 인공지능 모델을 이용한 패션 아이템의 스타일 분류 방법, 장치 및 컴퓨터프로그램)가 있으나, 컴퓨팅 장치에 의해 수행되는 방법에 있어서, 제1 패션 아이템에 관한 제1 이미지를 수집하는 단계, 인공지능 모델을 이용하여 제1 패션 아이템에 대응하는 제2 패션 아이템에 관한 복수의 제2 이미지를 선택하는 단계 및 상기 선택된 복수의 제2 이미지 각각에 레이블링된 상기 제2 패션 아이템의 스타일 정보에 기초하여 상기 제1 패션 아이템의 스타일을 분류하는 단계를 포함하고 있을 뿐이다."}
{"patent_id": "10-2023-0090226", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 패션 스타일을 효과적으로 인식하기 위해 각 아이템의 특성을 개별적으로 분 석하는 동시에 복수의 아이템 조합이 이루는 조화를 종합적으로 고려할 수 있으며, 영상의 전역적 특징 뿐만 아 니라 각 패션 아이템 별 특징을 별도의 네트워크 브랜치(branch)에서 분석한 후 그 결과를 통합하여 스타일을판별할 수 있는 아이템 영역 풀링을 이용한 패션 스타일 분류 방법 및 장치를 제공하는 데 있다."}
{"patent_id": "10-2023-0090226", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 아이템 영역 풀링을 이용한 패션 스타일 분류 방법에 관한 것으로, 전역특징추출부가 백본 네트워크 와 영상-텍스트처리모델을 이용하여 입력된 이미지로부터 전역적특징을 추출하는 단계와, 아이템특징추출부가 입력된 이미지로부터 다수개의 패션 아이템 영역에서 각각의 패션아이템별로 아이템별 특징을 추출하는 단계와, 스타일분류부가 추출된 상기 전역적특징과 아이템별 특징을 결합하고, 결합된 전체특징벡터를 스타일 분류 계층 에 입력하여 패션스타일을 분류하는 단계를 포함한다. 본 발명은 아이템 영역 풀링을 이용한 패션 스타일 분류 장치는 백본 네트워크와 영상-텍스트처리모델을 이용하 여 입력된 이미지로부터 전역적특징 추출하는 전역특징추출부, 입력된 이미지의 픽셀별로 물체를 식별하여 분류 하여 물체의 마스크 정보를 추출하고, 추출한 아이템별 마스크들을 전역적특징맵의 크기와 일치하도록 크기를 조정하고, 크기조정된 아이템별 마스크들과 전역적특징맵을 산술연산곱셈을 통해 아이템영역만의 특징을 추출하 고, 추출된 각각의 아이템영역만의 특징에 대해 변환하고, 변환된 각각의 아이템영역만의 특징에 대해 다운샘플 링하고, 다운샘플링된 아이템영역만의 특징의 입력의 절반에 시그모이드 함수를 취한 것과 나머지 입력의 절반 을 산술연산곱셈 계산하여 반영할 아이템특징을 추출하여 입력된 이미지로부터 다수개의 패션 아이템 영역에서 각각의 패션아이템별로 아이템별 특징 추출하는 아이템특징추출부 및 추출된 전역적특징과 아이템별 특징을 결 합하고, 결합된 전체특징벡터를 전역연결계층에 입력하여 패션스타일 분류하는 스타일분류부를 포함한다."}
{"patent_id": "10-2023-0090226", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면 백본 네트워크를 이용하여 입력 영상으로부터 전역적 특징맵을 추출할 수 있다. 또한, 각 패션 아이템 영역으로부터 특징 벡터를 추출하여 영상 전체에서 추출한 전역적 특징벡터와 각 아이템 별 특징벡터를 병합한 전체 특징벡터를 이용함으로써 영상 전체의 전역적 특성과 아이템 별 특성을 함께 반영해 입력 영상의 패션 스타일을 전역적 특징만을 이용하는 기존의 영상 분류 모델보다 훨씬 우수한 정확도로 판별할 수 있다."}
{"patent_id": "10-2023-0090226", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명은 단지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예 들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에서 상세하게 설명하고자 한다. 그러나 이는 본 발명의 개념에 따른 실시 예 들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물, 또는 대체물을 포함한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서,\"포함하다\" 또는 \"가지다\" 등의 용어는 본 명세서에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구 성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하, 본 명세서에 첨부된 도면들을 참조하여 본 발명의 실시 예들을 상세히 설명한다. 도 1은 본 발명의 실시예에 따른 아이템 영역 풀링을 이용한 패션 스타일 분류 방법을 설명하는 흐름도이다. 도 1을 참조하면, 전역특징추출부가 백본(backbone) 네트워크와 영상-텍스트처리모델을 이용하여 입력된 이미지로부터 전역적 특징을 추출한다(S101). 상기 이미지 또는 영상은 패션 아이템들을 장착한 인물 이미지 또 는 영상일 수 있으나, 반드시 이에 한정되는 것은 아니다. 상기 전역적특징이란, 입력된 이미지 또는 영상 전체 로부터 백본 네트워크와 영상-텍스트처리모델에서 생성한 특징맵으로부터 추출하는 전체적인 패션 스타일 특징 일 수 있다. 또한 전역특징추출부는 사전학습 된 영상처리 모델 또는 영상-텍스트 처리모델(예: CLIP(Contrastive Language-Image Pre-Training))의 영상 인코더(image encoder)를 특징 추출에 사용할 수 있 다. 아이템특징추출부가 입력된 이미지로부터 다수개의 패션 아이템 영역에서 각각의 패션 아이템별로 아이템 별 특징을 추출한다(S103). 아이템특징추출부는 각 패션 아이템들의 영역을 마스크 형태로 예측하고, IRP(Item-Region Pooling)를 이용해 각 패션 아이템 별 특징을 추출할 수 있다. 스타일분류부가 추출된 전 역적특징과 아이템별 특징을 결합하고, 결합된 전체특징벡터를 전역연결계층에 입력하여 패션스타일을 분류한다 (S105). 스타일분류부는 패션 스타일을 효과적으로 인식하기 위하여 각 패션 아이템의 복수의 조합이 이루 는 조화를 고려하기 위하여 전역적특징의 특징벡터와 아이템별 특징의 특징벡터를 병합(concatenate)한 전체특 징벡터를 생성할 수 있다. 스타일분류부는 결합된 전체특징벡터를 전역연결계층(fully-connected layer, FC layer)에 입력하여 패션스타일을 분류하고 예측할 수 있다. 도 2는 본 발명의 실시예에 따른 아이템별 특징을 추출하는 방법을 설명하는 흐름도이다. 도 2를 참조하면, 아이템특징추출부의 아이템영역세그멘테이션모듈이 입력된 이미지의 픽셀별로 물체 를 식별하여 분류하여 물체의 마스크 정보를 추출한다(S201). 상기 마스크 정보는 물체의 위치, 크기, 실루엣의 정보를 포함할 수 있으며, 마스크 정보는 아이템 영역을 의미할 수 있다. 아이템특징추출부의 크기조정모 듈이 추출한 아이템별 마스크들을 전역적특징맵의 크기와 일치하도록 크기를 조정한다(S203). 아이템특징 추출부의 산술연산모듈이 크기조정된 아이템별 마스크들과 전역적특징맵을 산술연산곱셈을 통해 아이 템영역만의 특징을 추출한다(S205). 산술연산모듈은 IRP(Item-Region Pooling)을 이용하여 각 아이템별 특 징벡터를 추출할 수 있다. IRP는 크기 조정이 완료된 패션 아이템별 마스크들을 이용하여 전역적특징맵으로부터 산술연산곱셈(element-wise multiplication)을 통해 아이템영역만의 특징을 추출할 수 있다. 상기 아이템영역만 의 특징은 각 아이템의 색깔, 핏, 착용방식, 사이즈, 패턴, 소재, 디테일, 실루엣, 분위기, 노출 여부, 기장 중 적어도 하나를 포함할 수 있으며, 반드시 이에 한정되는 것은 아니다. 아이템특징추출부의 변환인코더모듈이 추출된 각각의 아이템영역만의 특징에 대해 변환한다(S207). 변환인코더모듈은 Transformer Block을 사용하여 분석할 수 있으나, 반드시 이에 한정되는 것은 아니다. 아이템특징추출부의 다운샘플링모듈이 변환된 각각의 아이템영역만의 특징에 대해 다운샘플링 (Downsampling) 한다(S209). 다운샘플링(Downsampling)은 샘플(sample)의 개수를 줄이는 처리과정으로, 인코딩 할 때 data의 개수를 줄이는 처리과정을 의미한다. 아이템특징추출부의 GLU모듈이 다운샘플링된 아이 템영역만의 특징의 입력의 절반에 시그모이드 함수를 취한 것과 나머지 입력의 절반을 산술연산곱셈(element- wise multiplication) 계산하여 반영할 아이템 특징을 추출한다(S211). GLU모듈은 GLU(Gated Linear Unit)을 통해 패션 스타일 특징으로 반영할 정보의 양을 결정할 수 있다. 도 3은 본 발명의 실시예에 따른 아이템 영역 풀링을 이용한 패션 스타일 분류 장치를 설명하는 구성도이다. 도 3을 참조하면, 아이템 영역 풀링을 이용한 패션 스타일 분류 장치는 전역특징추출부, 아이템특징추 출부, 스타일분류부로 구성된다. 전역특징추출부는 이미지 또는 영상을 입력으로 하여 백본 네트워크를 이용하여 이미지 또는 영상으로부터 전역적특징을 추출할 수 있다. 상기 이미지 또는 영상은 패션 아이템들을 장착한 인물 이미지 또는 영상일 수 있으나, 반드시 이에 한정되는 것은 아니다. 상기 전역적특징이란, 입력된 이미지 또는 영상을 바탕으로 백본 네트워크에서 생성한 특징맵으로부터 추출하는 전체적인 패션 스타일 특징일 수 있다. 상기 백본(backbone) 네 트워크는 심층신경망으로 구성된 것으로, 영상의 고수준 특징(high-level feature)를 효과적으로 학습하고 추출 할 수 있다. 백본 네트워크는 원본 이미지를 입력받아 CNN(Convolutional Neural Network)이나 Transformer을 수행하여 원본 이미지에 대한 특징맵을 생성할 수 있으나, 반드시 이에 한정되는 것은 아니며, 이 외에도 멀티 스케일 특징맵을 생성할 수 있는 것은 백본 네트워크로 활용될 수 있다. 백본 네트워크는 입력 이미지 또는 영 상으로부터 저수준 특징(low-level feature)을 추출한 후 계층적 구조를 통해 여러 단계의 추상화 과정을 거쳐 고수준 특징(high-level feature)을 추출한다. 고수준 특징(high-level feature)은 영상의 전체적인 구조나 컨 텍스트를 반영하며 객체나 장면의 분류나 검출과 같은 고차원적인 작업에 필요한 정보를 포함하고 있어서 영상 의 의미 및 내용 분석에 널리 사용된다. 전역특징추출부는 추출된 전역적특징을 다운샘플링(downsamplin g)할 수 있다. 전역특징추출부는 이미지 또는 영상을 입력으로 하여 백본 네트워크 이외에 추가적으로 영상-텍스트 처리 모델을 이용하여 이미지 또는 영상으로부터 전역적특징을 추출할 수 있다. 상기 전역적특징이란, 입력된 이미지 또는 영상을 바탕으로 영상-텍스트 처리모델을 통해 생성한 특징맵으로부터 추출하는 전체적인 패션 스타일 특 징일 수 있다. 이 때 전역특징추출부는 영상-텍스트 처리모델로 CLIP(Contrastive Language-Image Pre- Training)을 사용하여 CLIP의 영상 인코더(image encoder)를 특징 추출에 사용할 수 있다. CLIP은 OpenAI에서 발표한 이미지와 텍스트를 함께 학습하여 다양한 시각적 개념을 인식하고 표현할 수 있는 거대 인공지능 모델이 다. CLIP은 이미지와 텍스트 간의 관련성을 측정하고 최적화하는 방식으로 학습되므로, 다른 모델들과 비교하여 더 다양하고 일반화된 시각적 지식을 학습하기 때문에 영상만으로 학습된 일반적인 백본 네트워크를 보완하기에 적합한 상보적인 특징벡터를 추출할 수 있다. 아이템특징추출부는 아이템영역세그멘테이션모듈, 크기조정모듈, 산술연산모듈, 변환인코 더모듈, 다운샘플링모듈, GLU모듈로 구성된다. 상기 아이템영역세그멘테이션모듈은 입력된 이미지의 픽셀(pixel)별로 물체를 식별하여 분류하여 물체의 마스크 정보를 추출할 수 있다. 상기 마스크 정보는 물체의 위치, 크기, 실루엣의 정보를 포함할 수 있으며, 마 스크 정보는 아이템 영역을 의미할 수 있다. 이 때 물체는 입력된 이미지에 포함되어 있는 패션 아이템을 의미 하는 것일 수 있으며, 모자, 상의, 하의, 아우터, 신발, 가방, 기타 액세서리 중 적어도 하나를 포함할 수 있으 나, 반드시 이에 한정되는 것은 아니다. 상기 크기조정모듈은 상기 아이템영역세그멘테이션모듈이 추출한 패션 아이템별 마스크들을 전역특징 추출부가 추출한 전역적특징맵의 크기와 일치하도록 크기를 조정할 수 있다. 상기 산술연산모듈은 IRP(Item-Region Pooling)을 이용하여 각 아이템별 특징벡터를 추출할 수 있다. IRP 는 크기 조정이 완료된 패션 아이템별 마스크들을 이용하여 전역적특징맵으로부터 산술연산곱셈(element-wise multiplication)을 통해 아이템영역만의 특징을 추출할 수 있다. 상기 아이템영역만의 특징은 각 아이템의 색깔, 핏, 착용방식, 사이즈, 패턴, 소재, 디테일, 실루엣, 분위기, 노출 여부, 기장 중 적어도 하나를 포함할 수 있으며, 반드시 이에 한정되는 것은 아니다. 상기 변환인코더모듈은 추출된 각각의 아이템영역만의 특징들을 변환하여 분석할 수 있다. 변환인코더모듈 은 Transformer Block을 사용하여 분석할 수 있으나, 반드시 이에 한정되는 것은 아니다. 상기 다운샘플링모듈은 변환된 각각의 아이템영역만의 특징들에 대해 다운샘플링 할 수 있다. 다운샘플링 (Downsampling)은 샘플(sample)의 개수를 줄이는 처리과정으로, 인코딩할 때 data의 개수를 줄이는 처리과정을 의미한다. 상기 GLU모듈은 다운샘플링된 아이템영역만의 특징의 입력의 절반에 시그모이드 함수를 취한 것과 나머지 입력의 절반을 산술연산곱셈 계산하여 반영할 아이템특징을 추출하고, 각 아이템별 특징벡터를 생성할 수 있다. GLU모듈은 GLU(Gated Linear Unit)을 통해 패션 스타일 특징으로 반영할 정보의 양을 결정할 수 있다. 스타일분류부는 전역특징추출부가 추출한 전역적특징과 아이템특징추출부가 추출한 아이템별 특 징을 결합하여 전체특징벡터를 생성할 수 있다. 스타일분류부는 패션 스타일을 효과적으로 인식하기 위하여 각 패션 아이템의 복수의 조합이 이루는 조화를 고려하기 위하여 전역적특징의 특징벡터와 아이템별 특징의 특징벡터를 병합(concatenate)한 전체특징벡터를 생성할 수 있다. 스타일분류부는 결합된 전체특징벡터를 전역연결계층(fully-connected layer, FC layer)에 입력하여 패션스타일을 분류하고 예측할 수 있다. 스타일분 류부는 전체특징벡터를 통해 오피스, 엘레강스, 보헤미안, 미니멀 모던, 바캉스, 로맨틱, 섹시, 스포티, 테크웨어, 레트로, 스트릿, 펑크, 베이직 중 적어도 하나의 패션스타일로 분류할 수 있으나, 반드시 이에 한정 되는 것은 아니다. 스타일분류부는 전역적특징과 아이템별 특징을 조합하여 패션스타일을 분류할 수 있으며, 다양한 아이템별 특징들의 조합을 통해 예측 가능하다. 일 실시예로, 스타일분류부는 자켓, 셔츠, 슬랙스, 정장 스커트, 베 스트, 타이(넥타이, 보타이), 구두, 로퍼, 시계 중 적어도 하나의 조합을 고려하여 고전적이면서 세련되고 포멀 한 옷차림으로 판단하여 오피스 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템들의 특징 중 소재가 벨벳, 새틴, 트위드 중 적어도 하나이거나, 투피스, 블라우스, 스커트, 드레스, 모노그램 패턴 중 적어도 하나의 조합을 고려하여 가는 허리와 부드러운 어깨를 표현하며 여성의 우아함을 강조한 스타일로 판 단하여 엘레강스 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템의 특징 중 내추럴한 컬러나 소재, 에스닉한 문양과 소재, 샌들, 페도라 중 적어도 하나의 조합을 고려하여 보헤미안의 의상에 현대 적인 감각을 더한 스타일인 보헤미안 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템 들의 특징 중 색상이 모노톤, 뉴트럴 컬러 중 적어도 하나이거나 핏과 디테일의 심플함 중 적어도 하나의 조합 을 고려하여 극도의 단순함을 추구하는 미니멀리스트 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류 부는 아이템의 특징 중 수영복, 비치웨어, 라탄 소재, 메쉬 소재, 선글라스, 샌들, 트로피컬 패턴, 블라우 스 중 적어도 하나의 조합을 고려하여 피서지 또는 리조트 등에서 입는 의상인 바캉스 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템의 특징 중 주름, 리본, 러플, 프릴, 플리츠, 레이스, 쉬 폰, 꽃 문양 중 적어도 하나의 조합을 고려하여 소녀적인 무드가 강한 로맨틱 룩이라고 분류할 수 있다. 또 다 른 실시예로, 스타일분류부는 아이템의 특징 중 여성성을 드러내는 핏과 재단. 짧은 기장, 노출정도, 실루 엣, 시스루나 글로시한 소재 중 적어도 하나의 조합을 고려하여 성적인 매력을 강조한 옷차림인 섹시 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템의 특징 중 트랙탑, 조거팬츠, 후드집업, 레깅 스, 스포츠브라, 스포츠 브랜드 로고, 스포티한 하의 중 적어도 하나의 조합을 고려하여 기능성을 중요시하여 활동적인 스포츠웨어를 의미하는 스포티 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 테 크 베스트, 카고팬츠, 포켓, 버튼, 지퍼, 벨크로, 웨빙테이프, 작업복, 밀리터리 스타일 중 적어도 하나의 조합 을 고려하여 면 소재의 한계를 극복한 미래지향적 스타일인 테크웨어라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템 특징 중 컬러 도트무늬, 스트라이프, 기하학적 그래픽 패턴, 하이웨이스트 하의, 로우 웨이스트 하의, 부츠컷, 올드스쿨 스타일 바람막이, 체크무늬 셔츠, 붉은 립스틱, 뱅헤어 스타일, 스카프 연출, 넥 헤어벤드 중 적어도 하나의 조합을 고려하여 복고 패션을 현대적으로 세련되게 해석한 스타일인 레트 로 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템 특징 중 자수, 나염, 아트웍의 밀 도, 루즈 핏, 와이드 핏, 바시티자켓, 와이드 조거팬츠, 웨이스트, 중 적어도 하나의 조합을 고려하여 힙합 스 타일인 스트릿 룩이라고 분류할 수 있다. 또 다른 실시예로, 스타일분류부는 아이템 특징 중 체커 원피스, 부츠, 락밴드 티셔츠, 금속 체인 장식, 바이커 스타일, 레드 타탄체크, 레더 소재, 매쉬 소재, 하이탑 스니커즈 중 적어도 하나의 조합을 고려하여 음악 장르에서 생겨난 펑크 룩이라고 분류할 수 있다. 또 다른 실시예로, 스 타일분류부는 아이템 특징 중 스탠다드 핏, 청바지, 면바지, 반바지, 스니커즈, 운동화, 스트레이트 하의, 스키니 하의, 기본 핏 중 적어도 하나의 조합을 고려하여 기본적인 스타일인 베이직 룩이라고 분류할 수 있다. 상기 전역연결계층(FC layer)은 한 층(layer)의 모든 뉴런이 그 다음 층(layer)의 모든 뉴런과 연결된 상태를 의미하는 것으로, 1차원 배열의 형태로 평탄화된 행렬을 통해 이미지를 분류하는데 사용되는 계층이다. 본 명세서에서 신경망, 네트워크 함수, 뉴럴 네트워크(neural network)는 상호 교환 가능한 의미로 사용될 수 있다. 신경망은 일반적으로 노드라 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이러 한 노드들은 뉴런(neuron)들로 지칭될 수도 있다. 신경망은 적어도 하나 이상의 노드들을 포함하여 구성된다. 신경망들을 구성하는 노드(또는 뉴런)들은 하나 이상의 링크에 의해 상호 연결될 수 있다. 신경망 내에서, 링크 를 통해 연결된 하나 이상의 노드들은 상대적으로 입력 노드 및 출력 노드의 관계를 형성할수 있다. 입력 노드 및 출력 노드의 개념은 상대적인 것으로서, 하나의 노드에 대하여 출력 노드 관계에 있는 임의의 노드는 다른 노드와의 관계에서 입력 노드 관계에 있을 수 있으며, 그 역도 성립할 수 있다. 상술한 바와 같이, 입력 노드 대 출력 노드 관계는 링크를 중심으로 생성될 수 있다. 하나의 입력 노드에 하나 이상의 출력 노드가 링크를 통 해 연결될 수 있으며, 그 역도 성립할 수 있다.하나의 링크를 통해 연결된 입력 노드 및 출력 노드 관계에서, 출력 노드의 데이터는 입력 노드에 입력된 데이 터에 기초하여 그 값이 결정될 수 있다. 여기서 입력 노드와 출력 노드를 상호 연결하는 링크는 가중치(weigh t)를 가질 수 있다. 가중치는 가변적일 수 있으며, 신경망이 원하는 기능을 수행하기 위해, 사용자 또는 알고리 즘에 의해 가변 될 수 있다. 예를 들어, 하나의 출력 노드에 하나 이상의 입력 노드가 각각의 링크에 의해 상호 연결된 경우, 출력 노드는 상기 출력 노드와 연결된 입력 노드들에 입력된 값들 및 각각의 입력 노드들에 대응 하는 링크에 설정된 가중치에 기초하여 출력 노드 값을 결정할 수 있다. 상술한 바와 같이, 신경망은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호 연결되어 신경망 내에서 입력 노드 및 출력 노드 관계를 형성한다. 신경망 내에서 노드들과 링크들의 개수 및 노드들과 링크들 사이의 연관관 계, 링크들 각각에 부여된 가중치의 값에 따라, 신경망의 특성이 결정될 수 있다. 예를 들어, 동일한 개수의 노 드 및 링크들이 존재하고, 링크들의 가중치 값이 상이한 두 신경망이 존재하는 경우, 두 개의 신경망들은 서로 상이한 것으로 인식될 수 있다. 신경망은 하나 이상의 노드들의 집합으로 구성될 수 있다. 신경망을 구성하는 노드들의 부분 집합은 레이어 (layer)를 구성할 수 있다. 신경망을 구성하는 노드들 중 일부는, 최초 입력 노드로부터의 거리들에 기초하여, 하나의 레이어(layer)를 구성할 수 있다. 예를 들어, 최초 입력 노드로부터 거리가 n인 노드들의 집합은, n 레 이어를 구성할 수 있다. 최초 입력 노드로부터 거리는, 최초 입력 노드로부터 해당 노드까지 도달하기 위해 거 쳐야 하는 링크들의 최소 개수에 의해 정의될 수 있다. 그러나, 이러한 레이어의 정의는 설명을 위한 임의적인 것으로서, 신경망 내에서 레이어의 차수는 상술한 것과 상이한 방법으로 정의될 수 있다. 예를 들어, 노드들의 레이어는 최종 출력 노드로부터 거리에 의해 정의될 수도 있다. 최초 입력 노드는 신경망 내의 노드들 중 다른 노드들과의 관계에서 링크를 거치지 않고 데이터가 직접 입력되 는 하나 이상의 노드들을 의미할 수 있다. 또는, 신경망 네트워크 내에서, 링크를 기준으로 한 노드 간의 관계 에 있어서, 링크로 연결된 다른 입력 노드들을 가지지 않는 노드들을 의미할 수 있다. 이와 유사하게, 최종 출 력 노드는 신경망 내의 노드들 중 다른 노드들과의 관계에서, 출력 노드를 가지지 않는 하나 이상의 노드들을 의미할 수 있다. 또한, 히든 노드는 최초 입력 노드 및 최후 출력 노드가 아닌 신경망을 구성하는 노드들을 의 미할 수 있다. 본 발명의 일 실시예에 따른 신경망은 입력 레이어의 노드의 개수가 출력 레이어의 노드의 개수와 동일할 수 있 으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 감소하다가 다시 증가하는 형태의 신경망일수 있다. 또한, 본 개시의 다른 일 실시예에 따른 신경망은 입력 레이어의 노드의 개수가 출력 레이어의 노드의 개 수 보다 적을 수 있으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 감소하는 형태의 신경망일 수 있다. 또한, 본 개시의 또 다른 일 실시예에 따른 신경망은 입력 레이어의 노드의 개수가 출력 레이어의 노 드의 개수보다 많을 수 있으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 증가하는 형태의 신 경망일 수 있다. 본 개시의 또 다른 일 실시예에 따른 신경망은 상술한 신경망들의 조합된 형태의 신경망일수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이 어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(예를 들어, 어떤 물체가 사 진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감정이 무엇인지 등)를 파악할 수 있다. 딥 뉴럴 네 트워크는 컨볼루션 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), 오토 인코더(auto encoder), GAN(Generative Adversarial Networks), 제한 볼츠 만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크, 적대적 생성 네트워크(GAN: Generative Adversarial Network) 등을 포함할 수 있다. 전술한 딥 뉴럴 네트워크의 기재는 예시일 뿐이며 본 개시는 이에 제한되지 않는다. 본 발명의 일 실시예에서 네트워크 함수는 오토 인코더(autoencoder)를 포함할 수도 있다. 오토 인코더는 입력 데이터와 유사한 출력 데이터를 출력하기 위한 인공 신경망의 일종일 수 있다. 오토 인코더는 적어도 하나의 히 든 레이어를 포함할 수 있으며, 홀수 개의 히든 레이어가 입출력 레이어 사이에 배치될 수 있다. 각각의 레이어 의 노드의 수는 입력 레이어의 노드의 수에서 병목 레이어(인코딩)라는 중간 레이어로 축소되었다가, 병목 레이 어에서 출력 레이어(입력 레이어와 대칭)로 축소와 대칭되어 확장될 수도 있다. 오토 인코더는 비선형 차원 감 소를 수행할 수 있다. 입력 레이어 및 출력 레이어의 수는 입력 데이터의 전처리 이후에 차원과 대응될 수 있다. 오토 인코더 구조에서 인코더에 포함된 히든 레이어의 노드의 수는 입력 레이어에서 멀어질수록 감소하는구조를 가질 수 있다. 병목 레이어(인코더와 디코더 사이에 위치하는 가장 적은 노드를 가진 레이어)의 노드의 수는 너무 작은 경우 충분한 양의 정보가 전달되지 않을 수 있으므로, 특정 수 이상(예를 들어, 입력 레이어의 절반 이상 등)으로 유지될 수도 있다. 뉴럴 네트워크는 교사 학습, 비교사 학습(unsupervised learning), 반교사 학습(semi supervised learning), 또는 강화 학습 중 적어도 하나의 방식으로 학습될 수 있다. 뉴럴 네트워크의 학습은 뉴럴 네트워크가 특정한 동작을 수행하기 위한 지식을 뉴럴 네트워크에 적용하는 과정일 수 있다. 뉴럴 네트워크는 출력의 오류를 최소화하는 방향으로 학습될 수 있다. 뉴럴 네트워크의 학습에서 반복적으로 학 습 데이터를 뉴럴 네트워크에 입력시키고 학습 데이터에 대한 뉴럴 네트워크의 출력과 타겟의 에러를 계산하고, 에러를 줄이기 위한 방향으로 뉴럴 네트워크의 에러를 뉴럴 네트워크의 출력 레이어에서부터 입력 레이어 방향 으로 역전파(backpropagation)하여 뉴럴 네트워크의 각 노드의 가중치를 업데이트 하는 과정이다. 교사 학습의 경우 각각의 학습 데이터에 정답이 라벨링 되어있는 학습 데이터를 사용하며(즉, 라벨링된 학습 데이터), 비교 사 학습의 경우는 각각의 학습 데이터에 정답이 라벨링되어 있지 않을 수 있다. 즉, 예를 들어 데이터 분류에 관한 교사 학습의 경우의 학습 데이터는 학습 데이터 각각에 카테고리가 라벨링 된 데이터 일 수 있다. 라벨링 된 학습 데이터가 뉴럴 네트워크에 입력되고, 뉴럴 네트워크의 출력(카테고리)과 학습 데이터의 라벨을 비교함 으로써 오류(error)가 계산될 수 있다. 다른 예로, 데이터 분류에 관한 비교사 학습의 경우 입력인 학습 데이터 가 뉴럴 네트워크 출력과 비교됨으로써 오류가 계산될 수 있다. 계산된 오류는 뉴럴 네트워크에서 역방향(즉, 출력 레이어에서 입력 레이어 방향)으로 역전파 되며, 역전파에 따라 뉴럴 네트워크의 각 레이어의 각 노드들의 연결 가중치가 업데이트 될 수 있다. 업데이트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따라 변 화량이 결정될 수 있다. 입력 데이터에 대한 뉴럴 네트워크의 계산과 에러의 역전파는 학습 사이클(epoch)을 구 성할 수 있다. 학습률은 뉴럴 네트워크의 학습 사이클의 반복 횟수에 따라 상이하게 적용될 수 있다. 예를 들어, 뉴럴 네트워크의 학습 초기에는 높은 학습률을 사용하여 뉴럴 네트워크가 빠르게 일정 수준의 성능을 확 보하도록 하여 효율성을 높이고, 학습 후기에는 낮은 학습률을 사용하여 정확도를 높일 수 있다. 뉴럴 네트워크의 학습에서 일반적으로 학습 데이터는 실제 데이터(즉, 학습된 뉴럴 네트워크를 이용하여 처리하 고자 하는 데이터)의 부분집합일 수 있으며, 따라서, 학습 데이터에 대한 오류는 감소하나 실제 데이터에 대해 서는 오류가 증가하는 학습 사이클이 존재할 수 있다. 과적합(overfitting)은 이와 같이 학습 데이터에 과하게 학습하여 실제 데이터에 대한 오류가 증가하는 현상이다. 예를 들어, 노란색 고양이를 보여 고양이를 학습한 뉴 럴 네트워크가 노란색 이외의 고양이를 보고는 고양이임을 인식하지 못하는 현상이 과적합의 일종일 수 있다. 과적합은 머신러닝 알고리즘의 오류를 증가시키는 원인으로 작용할 수 있다. 이러한 과적합을 막기 위하여 다양 한 최적화 방법이 사용될 수 있다. 과적합을 막기 위해서는 학습 데이터를 증가시키거나, 레귤라이제이션 (regularization), 학습의 과정에서 네트워크의 노드 일부를 비활성화하는 드롭아웃(dropout), 배치 정규화 레 이어(batch normalization layer)의 활용 등의 방법이 적용될 수 있다. 도 4 내지 도 5는 본 발명의 실시예에 따른 물체의 마스크 정보가 추출된 것을 나타내는 도면이다. 도 4를 참조하면, 아이템 마스크의 예를 확인할 수 있다. 도 4(a)는 입력 이미지를 나타내고, 도 4(b)는 머리의 이진 마스크(binary mask)와 입력 이미지의 곱을 나타내고, 도 4(c)는 상의의 이진 마스크(binary mask)와 입력 이미지의 곱을 나타내고, 도 4(d)는 하의의 이진 마스크(binary mask)와 입력 이미지의 곱을 나타내고, 도 4 (e)는 신발의 이진 마스크(binary mask)와 입력 이미지의 곱을 나타낸다. 아이템특징추출부의 아이템영역 세그멘테이션모듈은 도 4와 같이 입력된 이미지(a)를 픽셀별로 식별하여 머리, 상의, 하의, 신발의 마스크 정보를 추출할 수 있는 것을 보여준다. 도 5를 참조하면, 또 다른 아이템 마스크의 예를 확인할 수 있다. 도 5(a)는 입력 이미지를 나타내고, 도 5(b) 는 옷(clothes)의 이진 마스크(binary mask)를 나타내고, 도 5(c)는 입력 이미지와 옷의 이진 마스크(binary mask)의 곱을 나타낸다. 도 6은 본 발명의 실시예에 따른 패션 스타일 분류 실험에 대한 실험값을 설명하는 도면이다. 도 6을 참조하면, 본 발명의 아이템 영역 풀링을 이용한 패션 스타일 분류 장치의 성능 개선 여부를 확인하 기 위하여 fashionstyle14라는 이미지 패션 스타일 예측 데이터셋을 활용하여 시행한 실험에 대한 결과값을 확인할 수 있다. 먼저 resNet50 이라는 50개 계층으로 구성된 컨벌루션 신경망만 사용한 경우와 IRP를 추가적으로 이용하여 아이 템별 특징을 결합한 후에 패션 스타일을 분류한 경우를 비교해 보았을 때 0.7153에서 0.7876으로 성능이 개선되 었음이 확인되었다. 또한 convnext tiny 모델만을 사용한 경우와 IRP를 추가적으로 이용하여 아이템별 특징을 결합한 후에 패션 스 타일을 분류한 경우를 비교해 보았을 때 0.7484에서 0.7718로 성능이 개선되었음이 확인되었다. 또한 efficientnet b3 모델만을 사용한 경우와 IRP를 추가적으로 이용하여 아이템별 특징을 결합한 후에 패션 스타일을 분류한 경우를 비교해 보았을 때 0.643에서 0.817로 성능이 개선되었음이 확인되었다. 또한 mobilenetV2 모델만을 사용한 경우와 IRP를 추가적으로 이용하여 아이템별 특징을 결합한 후에 패션 스타 일을 분류한 경우를 비교해 보았을 때 0.7259에서 0.8087로 성능이 개선되었음이 확인되었다. 이처럼 전역적 특징만을 사용하여 패션 스타일을 분류하는 것보다, IRP를 사용하여 아이템 영역에서 각각의 아 이템영역만의 특징을 분리하여 전역적 특징과 결합하여 패션 스타일을 분류하고 예측하는 것이 아이템 별 특성 을 적극적으로 반영할 수 있어 기존과 차별적인 딥러닝 기반 패션 스타일 인식 방법이 될 것이다. 발명은 도면에 도시된 실시 예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지 식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0090226", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 아이템 영역 풀링을 이용한 패션 스타일 분류 방법을 설명하는 흐름도이다. 도 2는 본 발명의 실시예에 따른 아이템별 특징을 추출하는 방법을 설명하는 흐름도이다. 도 3은 본 발명의 실시예에 따른 아이템 영역 풀링을 이용한 패션 스타일 분류 장치를 설명하는 구성도이다. 도 4 내지 도 5는 본 발명의 실시예에 따른 물체의 마스크 정보가 추출된 것을 나타내는 도면이다. 도 6은 본 발명의 실시예에 따른 패션 스타일 분류 실험에 대한 실험값을 설명하는 도면이다."}
