{"patent_id": "10-2019-0161714", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0072202", "출원번호": "10-2019-0161714", "발명의 명칭": "영유아 감정 상태 출력 방법", "출원인": "주식회사 비즈모델라인", "발명자": "김재형"}}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사운드 입력부 및 카메라모듈을 구비하여 지정된 거점에 구비된 카메라장치와 통신하는 운영서버를 통해 실행되는 방법에 있어서,지정된 인공지능 기반의 학습(Learning) 과정을 통해 아기 표정에 대응하는 지정된 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 제1 단계;상기 카메라장치의 카메라모듈을 통해 상기 거점 내의 특정 아기를 촬영하여 지정 방식으로 엔코딩된 비디오 데이터와 상기 카메라장치의 사운드 입력부를 통해 입력되어 지정 방식으로 엔코딩된 오디오 데이터를 수신하여지정된 저장매체의 특정 저장영역에 연계 저장 관리하는 제2 단계;상기 인공지능 기반의 표정 기반 감정상태 판별 정보를 통해 지정된 비디오 데이터를 판독하는 절차를 수행하여지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N)개의 아기 감정 항목을 근거로 상기 비디오 데이터의 아기 표정에 대응하는 n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값을 판별하는제3 단계; 상기 산출된 n1개의 감정 항목 별 아기 감정 상태 값을 이용하여 비디오 데이터 상에 표시 가능한 지정된 n(1≤n≤N)개의 감정 항목 별 아기 감정 상태 정보를 생성하는 제4 단계; 및비디오 데이터 상의 지정된 일정 영역에 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디오데이터를 포함하는 송신 데이터를 사용자 무선단말의 앱이나 IPTV로 제공하는 제5 단계;를 포함하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 제1 단계는, 지정된 인공지능 기반의 학습(Learning) 과정을 수행하여 지정된 E(E≥2)개의 아기 표정 중 지정된 아기 안면영역에 대응하는 e(1≤e≤E)개의 아기 표정을 판별하고, 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N)개의 아기 감정 항목을 기반으로 상기 판별된 e개의 아기 표정과 매칭 관계를 지닌n1(1≤n1≤N1)개의 아기 감정 항목을 판별하고, 상기 확인된 e개의 아기 표정과 n1개의 아기 감정 항목 간 상관도에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 상기 제1 단계는, 지정된 E(E≥2)개의 아기 표정 중 지정된 e(1≤e≤E)개의 아기 표정에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 안면영역을 포함하는 장면에 대응하는 복수의 비디오 정보들을 입력받고, 상기 입력된 복수의 비디오 정보에 대한n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값을 출력변수로 설정하는 단계;상기 입력된 복수의 비디오 정보들에 포함된 아기 안면 영역의 지정된 특징점 간 기하학 관계를 판독하고 패턴인식하여 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값에 대응하는 P(P≥2)개의 장면 패턴 특성 정보를 추출하여 입력변수(Feature Vectors)로 설정하는 단계;지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 아기 안면 영역을 포공개특허 10-2021-0072202-3-함하는 복수의 장면들 중 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계;를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 제1 단계는, 지정된 E(E≥2)개의 아기 표정 중 지정된 e(1≤e≤E)개의 아기 표정에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 안면영역을 포함하는 장면에 대응하는 복수의 비디오 정보들의 아기 안면 영역의 지정된 특징점 간 기하학 관계를판독하고 패턴 인식하여 상기 아기 안면 영역의 아기 표정에 대응하는 n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값의 패턴 특성으로 추출된 P(P≥2)개의 장면 패턴 특성 정보를 입력변수(Feature Vectors)로입력받고, 상기 P개의 장면 패턴 특성 정보가 추출된 비디오 정보에 대한 n1개의 감정 항목 별 아기 감정 상태값을 출력변수로 설정하는 단계;지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 아기 안면 영역을 포함하는 복수의 장면들 중 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계;를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항 또는 제 4항에 있어서, 상기 출력변수는, 상기 비디오 정보에 포함된 상기 아기 안면 영역에 대응하는 e개의 아기 표정 정보와, 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서, 상기 제2 단계는, 상기 카메라장치로부터 상기 비디오 데이터와 오디오 데이터를 포함하는 동영상 데이터를 수신하여 지정된 저장매체의 특정 저장영역에 저장 관리하는 단계를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서, 상기 제2 단계는, 상기 카메라장치로부터 상기 비디오 데이터와 오디오 데이터를 각기 수신하여 지정된 저장매체의 특정 저장영역에 저장 관리하는 단계를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 제2 단계는, 상기 카메라장치로부터 수신된 상기 비디오 데이터와 오디오 데이터의 시간을 동기화시켜 지정된 저장매체의 특정 저장영역에 저장하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법.공개특허 10-2021-0072202-4-청구항 9 제 1항에 있어서, 상기 송신 데이터는, 상기 저장매체의 특정 저장영역에 저장된 오디오 데이터를 더 포함하여 이루어지는 것을 특징으로 하는 영유아감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1항에 있어서, 상기 지정된 비디오 데이터는, 지정된 재생 시간 단위 별로 주기적으로 선별되는 비디오 데이터, 지정된 재생 프레임 수 별로 주기적으로 선별되는 비디오 데이터 중 적어도 하나의 비디오 데이터를 포함하여이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1항에 있어서, 지정된 사용자 무선단말의 앱이나 IPTV로 상기 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는송신 데이터를 제공하는지 확인하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1항에 있어서, 상기 제3 단계는, 상기 인공지능 기반의 표정 기반 감정상태 판별 정보를 통해 지정된 비디오 데이터를 판독하는 절차를 수행하여지정된 E개의 아기 표정 중 상기 비디오 데이터 상의 아기 안면 영역에 대응하는 e개의 아기 표정을 판별하고,아기 표정을 통해 구별 가능한 N1개의 아기 감정 항목 중 상기 판별된 e개의 아기 표정과 매칭 관계를 지닌 n1개의 아기 감정 항목을 판별하고, 상기 확인된 e개의 아기 표정과 n1개의 아기 감정 항목 간 상관도에 대응하는n1개의 감정 항목 별 아기 감정 상태 값을 판별하는 단계를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1항에 있어서, 상기 제4 단계는, 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 상기 비디오 데이터와 연계 저장하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서, 상기 제4 단계는, 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 상기 비디오 데이터의 지정된 재생 시점과 동기화하는시간 값(또는 타임스탬프)과 연계하여 저장하는 단계를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정상태 출력 방법.공개특허 10-2021-0072202-5-청구항 15 제 1항에 있어서, 상기 제1 단계는, 지정된 인공지능 기반의 학습(Learning) 과정을 통해 아기 울음소리에 대응하는 지정된 감정 항목 별 아기 감정상태 값을 판별하기 위한 울음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계를 더포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15항에 있어서, 상기 제1 단계는, 지정된 인공지능 기반의 학습(Learning) 과정을 수행하여 지정된 C(C≥2)개의 아기 울음소리 중 지정된 아기 울음에 대응하는 c(1≤c≤C)개의 아기 울음소리를 판별하고, 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목을 기반으로 상기 판별된 c개의 아기 울음소리와 매칭관계를 지닌 n2(1≤n2≤N2)개의 아기 감정 항목을 판별하고, 상기 확인된 c개의 아기 울음소리와 n2개의 아기감정 항목 간 상관도에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 울음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 15항에 있어서, 상기 제1 단계는, 지정된 C(C≥2)개의 아기 울음소리 중 지정된 c(1≤c≤C)개의 아기 울음소리에 대응하면서 지정된 N(N≥2)개의아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 울음에 대응하는 복수의 오디오 정보들을 입력받고, 상기 입력된 복수의 오디오 정보에 대한 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값을 출력변수로 설정하는 단계;상기 입력된 복수의 오디오 정보들을 판독하고 패턴 인식하여 상기 아기 울음소리에 대응하는 n2개의 감정 항목별 아기 감정 상태 값에 대응하는 Q(Q≥2)개의 소리 패턴 특성 정보를 추출하여 입력변수(Feature Vectors)로설정하는 단계;지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 지정된 오디오 데이터에 포함된 아기 울음소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 울음소리 기반감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계;를 포함하여 이루어지는 것을 특징으로 하는영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 15항에 있어서, 상기 제1 단계는, 지정된 C(C≥2)개의 아기 울음소리 중 지정된 c(1≤c≤C)개의 아기 울음소리에 대응하면서 지정된 N(N≥2)개의아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 울음에 대응하는 복수의 오디오 정보들을 판독하고 패턴 인식하여 상기 아기 울음소리에 대응하는 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값의 패턴 특성으로 추출된 Q(Q≥2)개의 소리 패턴 특성 정보를 입력변수(Feature Vectors)로 입력받고, 상기 Q개의 소리 패턴 특성 정보가 추출된 오디오 정보에 대한 n2개의 감정 항목 별 아기 감정 상태 값을 출력변수로 설정하는 단계;지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 지정된 오디오 데이터에 포함된 아기 울음소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 울음소리 기반감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계;를 포함하여 이루어지는 것을 특징으로 하는영유아 감정 상태 출력 방법.공개특허 10-2021-0072202-6-청구항 19 제 17항 또는 제 18항에 있어서, 상기 출력변수는, 상기 오디오 정보에 포함된 상기 아기 울음에 대응하는 c개의 아기 울음소리 정보와, 상기 아기 울음소리에 대응하는 n2개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함하여 이루어지는것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 15항에 있어서, 상기 제3 단계는, 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 통해 지정된 오디오 데이터를 판독하는 절차를 수행하여 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목을 근거로 상기 오디오 데이터의 아기 울음소리에 대응하는 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태값을 판별하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 20항에 있어서, 상기 제3 단계는, 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 통해 지정된 오디오 데이터를 판독하는 절차를 수행하여 지정된 C개의 아기 울음소리 중 상기 오디오 데이터 상의 아기 울음에 대응하는 c개의 아기 울음소리를 판별하고, 아기 울음소리를 통해 구별 가능한 N2개의 아기 감정 항목 중 상기 판별된 c개의 아기 울음소리와 매칭관계를 지닌 n2개의 아기 감정 항목을 판별하고, 상기 확인된 c개의 아기 울음소리와 n2개의 아기 감정 항목 간상관도에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하는 단계를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 20항 또는 제 21항에 있어서, 상기 제4 단계는, 상기 산출된 n2개의 감정 항목 별 아기 감정 상태 값을 추가 이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 1항에 있어서,상기 제1 단계는, 상기 카메라장치에 구비되거나 연계된 센서모듈을 통해 센싱된 센싱 데이터 중 아기의 감정 표현과 연관된 지정된 센싱 대상의 센싱 데이터에 대한 S(S≥2)개의 센싱 값 패턴 정보와 지정된 N개의 아기 감정 항목 중 지정된센싱 대상의 센싱 값 패턴을 근거로 구별 가능한 N3(1≤N3≤N)개의 아기 감정 항목 사이의 매칭 관계정보 및 상기 S개의 센싱 값 패턴 정보와 N3개의 아기 감정 항목 간 상관도를 수치화한 센싱 기반 상관도 수치 관계정보를포함하는 센싱 기반 감정상태 판별 정보를 운영D/B에 등록 저장하는 단계를 더 포함하고, 상기 제2 단계는, 상기 카메라장치에 구비되거나 연계된 센서모듈을 통해 센싱된 센싱 데이터를 수신하고 상기 비디오 데이터와연계하여 지정된 저장매체의 특정 저장영역에 저장 관리하는 단계를 더 포함하며, 공개특허 10-2021-0072202-7-상기 제3 단계는, 상기 비디오 데이터와 연계된 센싱 데이터를 판독하여 상기 특정 아기의 감정 표현과 연관된 지정된 센싱 대상의 센싱 데이터에 대한 k(k≥1)개의 센싱 값 인식 정보를 인식하고,상기 센싱 기반 감정상태 판별 정보를 근거로 상기 인식된 k개의 센싱 값 인식 정보와 기 설정된 기준 유사도이상 매칭된 s(1≤s≤S)개의 센싱 값 패턴 정보를 확인하고 상기 확인된 s개의 센싱 값 패턴 정보와 매칭 관계를 지닌 n3(1≤n3≤N3)개의 아기 감정 항목을 판별하며,상기 인식된 k개의 센싱 값 인식 정보와 상기 s개의 센싱 값 패턴 정보 간 매칭 비율을 근거로 상기 s개의 센싱값 패턴 정보와 n3개의 아기 감정 항목 간 상관도 수치 관계를 판독하여 상기 인식된 k개의 센싱 값 인식 정보에 대응하는 n3개의 감정 항목 별 아기 감정 상태를 수치화한 n3개의 감정 항목 별 아기 감정 상태 값을 산출하는 단계를 더 포함하고, 상기 제4 단계는, 상기 산출된 n3개의 감정 항목 별 아기 감정 상태 값을 추가 이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성하는 단계를 더 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 23항에 있어서, 상기 센서모듈은, 아기의 신체에 착용하여 지정된 센싱 대상을 센싱하는 웨어러블(Wearable) 센서모듈, 지정된 전자파를 이용하여 아기의 지정된 센싱 대상을 센싱하는 레이더(Radar) 센서모듈 중 적어도 하나의 센서모듈을 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 23항 또는 제 20항에 있어서, 상기 센싱 대상은,아기의 심장박동, 아기의 체온, 아기 주변 습도, 아기의 무호흡 여부 중 적어도 하나를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 23항에 있어서, 상기 S개의 센싱 값 패턴 정보는, 아기의 감정표현과 연관된 지정된 센싱 대상의 센싱 데이터에 대한 각각의 센싱 값 패턴을 구성하는 센싱 값 특징의 범위 정보를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 26항에 있어서, 상기 센싱 값 특징은, 센싱 값의 변화 규칙 특징, 센싱 값의 변화량 특징, 센싱 값 변화율 특징, 센싱 값 변화의 주기성 특징 중 적어도 하나 또는 둘 이상의 조합을 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제 23항에 있어서, 상기 센싱 기반 상관도 수치 관계정보는, 지정된 센싱 대상의 센싱 데이터를 통해 인식된 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 간 매칭 비공개특허 10-2021-0072202-8-율에 비례하는 관계식을 통해 산출되는 상관도 수치정보를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제 23항에 있어서, 상기 센싱 기반 상관도 수치 관계정보는, 지정된 센싱 대상의 센싱 데이터를 통해 인식된 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 사이의 각매칭 비율 구간 별 상관도 수치정보를 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 1항에 있어서, 상기 n개의 감정 항목 별 아기 감정 상태 정보는, n개의 감정 항목 정보와 각 감정 항목 별 아기 감정 상태의 수치정보를 문자 형태로 포함하여 이루어지는 것을특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제 1항에 있어서, 상기 n개의 감정 항목 별 아기 감정 상태 정보는, n개의 감정 항목 정보와 각 감정 항목 별 아기 감정 상태의 수치정보를 그래프 형태로 포함하여 이루어지는 것을 특징으로 하는 영유아 감정 상태 출력 방법."}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 영유아 감정 상태 출력 방법에 따르면, 사운드 입력부 및 카메라모듈을 구비하여 지정된 거점에 구비 된 카메라장치와 통신하는 운영서버를 통해 실행되는 방법에 있어서, 지정된 인공지능 기반의 학습(Learning) 과 정을 통해 아기 표정에 대응하는 지정된 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 (뒷면에 계속)"}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 지정된 거점에 구비된 카메라장치를 통해 상기 거점 내의 특정 아기를 촬영한 비디오 데이터를 포함 하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공 시 상기 카메라장치를 통해 획득된 하나 이 상의 데이터를 근거로 상기 특정 아기에 대한 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하고 상기 송 신 데이터의 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 각 감정 항목 별 아기 감정 상태 정보를 표시 하여 제공하는 것이다."}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래에 다수개의 웹 PC 카메라가 설치된 병원 또는 조산원 또는 산후 조리원에서 회원으로 가입된 아기의 동영 상이나 정지 화상 및 신생아 정보(예컨대, 태몽, 초음파 진단 사진 등)를 인터넷을 통해 회원에게 제공하는 서 비스가 제안된 바 있다(특허공개번호 특2001-0091236(2001년10월23일)). 그러나 종래의 서비스는 단순히 아기의 동영상이나 정지 화상 및 신생아 정보를 인터넷을 통해 제공하는 것으로, 기본 제공되는 아기의 동영상이나 정지 화상 및 신생아 정보 외에 아기의 현재 상태와 관련된 실시간 정보를 자동 파악하여 제공하기에는 기술적으로 난해한 문제점을 지니고 있다."}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해소하기 위한 본 발명의 목적은, 아기의 지정된 감정 항목 별 아기 감정 상태 값을 판별 하기 위한 감정상태 판별 정보를 저장한 후, 상기 카메라장치의 카메라모듈을 통해 상기 거점 내의 특정 아기를촬영하여 획득된 비디오 데이터를 포함하는 획득 데이터를 수신하여 지정된 저장매체의 특정 저장영역에 저장하 고, 상기 감정상태 판별 정보를 통해 지정된 비디오 데이터를 포함하는 하나 이상의 데이터를 판독하는 절차를 수행하여 상기 아기에 대한 지정된 감정 항목 별 아기 감정 상태 값을 판별하고, 상기 산출된 하나 이상의 아기 감정 상태 정보를 이용하여 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하고, 비디오 데이터 상의 지정 된 일정 영역에 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포함하는 송신 데이터를 사용자 무선단말의 앱이나 IPTV로 제공하는 영유아 감정 상태 출력 방법을 제공함에 있다."}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 영유아 감정 상태 출력 방법은, 사운드 입력부 및 카메라모듈을 구비하여 지정된 거점에 구비된 카메라장치와 통신하는 운영서버를 통해 실행되는 방법에 있어서, 지정된 인공지능 기반의 학습(Learning) 과정 을 통해 아기 표정에 대응하는 지정된 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판 별 정보를 생성하여 지정된 저장영역에 저장하는 제1 단계와 상기 카메라장치의 카메라모듈을 통해 상기 거점 내의 특정 아기를 촬영하여 지정 방식으로 엔코딩된 비디오 데이터와 상기 카메라장치의 사운드 입력부를 통해 입력되어 지정 방식으로 엔코딩된 오디오 데이터를 수신하여 지정된 저장매체의 특정 저장영역에 연계 저장 관 리하는 제2 단계와 상기 인공지능 기반의 표정 기반 감정상태 판별 정보를 통해 지정된 비디오 데이터를 판독하 는 절차를 수행하여 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N)개의 아 기 감정 항목을 근거로 상기 비디오 데이터의 아기 표정에 대응하는 n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값을 판별하는 제3 단계와 상기 산출된 n1개의 감정 항목 별 아기 감정 상태 값을 이용하여 비디오 데이터 상에 표시 가능한 지정된 n(1≤n≤N)개의 감정 항목 별 아기 감정 상태 정보를 생성하는 제4 단계 및 비디오 데 이터 상의 지정된 일정 영역에 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포함하는 송신 데이터를 사용자 무선단말의 앱이나 IPTV로 제공하는 제5 단계를 포함하는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제1 단계는, 지정된 인공지능 기반의 학습 (Learning) 과정을 수행하여 지정된 E(E≥2)개의 아기 표정 중 지정된 아기 안면 영역에 대응하는 e(1≤e≤E)개 의 아기 표정을 판별하고, 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N) 개의 아기 감정 항목을 기반으로 상기 판별된 e개의 아기 표정과 매칭 관계를 지닌 n1(1≤n1≤N1)개의 아기 감 정 항목을 판별하고, 상기 확인된 e개의 아기 표정과 n1개의 아기 감정 항목 간 상관도에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장 하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제1 단계는, 지정된 E(E≥2)개의 아기 표정 중 지 정된 e(1≤e≤E)개의 아기 표정에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가 능한 N1(1≤N1≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 안면 영역을 포함하는 장면에 대응하는 복 수의 비디오 정보들을 입력받고, 상기 입력된 복수의 비디오 정보에 대한 n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값을 출력변수로 설정하는 단계와 상기 입력된 복수의 비디오 정보들에 포함된 아기 안면 영역의 지 정된 특징점 간 기하학 관계를 판독하고 패턴 인식하여 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감 정 항목 별 아기 감정 상태 값에 대응하는 P(P≥2)개의 장면 패턴 특성 정보를 추출하여 입력변수(Feature Vectors)로 설정하는 단계와 지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 아기 안면 영역을 포함하는 복수의 장면들 중 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감 정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제1 단계는, 지정된 E(E≥2)개의 아기 표정 중 지 정된 e(1≤e≤E)개의 아기 표정에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가 능한 N1(1≤N1≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 안면 영역을 포함하는 장면에 대응하는 복 수의 비디오 정보들의 아기 안면 영역의 지정된 특징점 간 기하학 관계를 판독하고 패턴 인식하여 상기 아기 안 면 영역의 아기 표정에 대응하는 n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값의 패턴 특성으로 추출된 P(P≥2)개의 장면 패턴 특성 정보를 입력변수(Feature Vectors)로 입력받고, 상기 P개의 장면 패턴 특성 정보가추출된 비디오 정보에 대한 n1개의 감정 항목 별 아기 감정 상태 값을 출력변수로 설정하는 단계와 지정된 인공 지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 아기 안면 영역을 포함하는 복수 의 장면들 중 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 출력변수는, 상기 비디오 정보에 포함된 상기 아기 안면 영역에 대응하는 e개의 아기 표정 정보와, 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제2 단계는, 상기 카메라장치로부터 상기 비디오 데이터와 오디오 데이터를 포함하는 동영상 데이터를 수신하여 지정된 저장매체의 특정 저장영역에 저장 관리하 는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제2 단계는, 상기 카메라장치로부터 상기 비디오 데이터와 오디오 데이터를 각기 수신하여 지정된 저장매체의 특정 저장영역에 저장 관리하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제2 단계는, 상기 카메라장치로부터 수신된 상기 비디오 데이터와 오디오 데이터의 시간을 동기화시켜 지정된 저장매체의 특정 저장영역에 저장하는 단계를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 송신 데이터는, 상기 저장매체의 특정 저장영역에 저장된 오디오 데이터를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 지정된 비디오 데이터는, 지정된 재생 시간 단위 별로 주기적으로 선별되는 비디오 데이터, 지정된 재생 프레임 수 별로 주기적으로 선별되는 비디오 데이터 중 적어도 하나의 비디오 데이터를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 지정된 사용자 무선단말의 앱이나 IPTV로 상기 저장매체 의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 제공하는지 확인하는 단계를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제3 단계는, 상기 인공지능 기반의 표정 기반 감정 상태 판별 정보를 통해 지정된 비디오 데이터를 판독하는 절차를 수행하여 지정된 E개의 아기 표정 중 상기 비 디오 데이터 상의 아기 안면 영역에 대응하는 e개의 아기 표정을 판별하고, 아기 표정을 통해 구별 가능한 N1개 의 아기 감정 항목 중 상기 판별된 e개의 아기 표정과 매칭 관계를 지닌 n1개의 아기 감정 항목을 판별하고, 상 기 확인된 e개의 아기 표정과 n1개의 아기 감정 항목 간 상관도에 대응하는 n1개의 감정 항목 별 아기 감정 상 태 값을 판별하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제4 단계는, 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 상기 비디오 데이터와 연계 저장하는 단계를 더 포함하여 이루어지는 것을 특징으로 한다.본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제4 단계는, 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 상기 비디오 데이터의 지정된 재생 시점과 동기화하는 시간 값(또는 타임스탬프)과 연계하여 저장하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제1 단계는, 지정된 인공지능 기반의 학습 (Learning) 과정을 통해 아기 울음소리에 대응하는 지정된 감정 항목 별 아기 감정 상태 값을 판별하기 위한 울 음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제1 단계는, 지정된 인공지능 기반의 학습 (Learning) 과정을 수행하여 지정된 C(C≥2)개의 아기 울음소리 중 지정된 아기 울음에 대응하는 c(1≤c≤C)개 의 아기 울음소리를 판별하고, 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1 ≤N2≤N)개의 아기 감정 항목을 기반으로 상기 판별된 c개의 아기 울음소리와 매칭 관계를 지닌 n2(1≤n2≤N2) 개의 아기 감정 항목을 판별하고, 상기 확인된 c개의 아기 울음소리와 n2개의 아기 감정 항목 간 상관도에 대응 하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 울음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제1 단계는, 지정된 C(C≥2)개의 아기 울음소리 중 지정된 c(1≤c≤C)개의 아기 울음소리에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통 해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 울음에 대응하는 복수의 오디오 정보들을 입력받고, 상기 입력된 복수의 오디오 정보에 대한 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값을 출력변수로 설정하는 단계와 상기 입력된 복수의 오디오 정보들을 판독하고 패턴 인식하여 상기 아기 울음 소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값에 대응하는 Q(Q≥2)개의 소리 패턴 특성 정보를 추출 하여 입력변수(Feature Vectors)로 설정하는 단계와 지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 지정된 오디오 데이터에 포함된 아기 울음소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 울음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장 하는 단계;를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제1 단계는, 지정된 C(C≥2)개의 아기 울음소리 중 지정된 c(1≤c≤C)개의 아기 울음소리에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통 해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 울음에 대응하는 복수의 오디오 정보들을 판독하고 패턴 인식하여 상기 아기 울음소리에 대응하는 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값의 패턴 특성으로 추출된 Q(Q≥2)개의 소리 패턴 특성 정보를 입력변수(Feature Vectors)로 입력받고, 상기 Q개의 소리 패턴 특성 정보가 추출된 오디오 정보에 대한 n2개의 감정 항목 별 아기 감정 상태 값을 출력 변수로 설정하는 단계와 지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습 시켜 지정된 오디오 데이터에 포함된 아기 울음소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별 하기 위한 울음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하는 단계;를 포함하여 이루어 지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 출력변수는, 상기 오디오 정보에 포함된 상기 아기 울음에 대응하는 c개의 아기 울음소리 정보와, 상기 아기 울음소리에 대응하는 n2개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제3 단계는, 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 통해 지정된 오디오 데이터를 판독하는 절차를 수행하여 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목을 근거로 상기 오디오 데이터의아기 울음소리에 대응하는 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값을 판별하는 단계를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제3 단계는, 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 통해 지정된 오디오 데이터를 판독하는 절차를 수행하여 지정된 C개의 아기 울음소리 중 상기 오디오 데이터 상의 아기 울음에 대응하는 c개의 아기 울음소리를 판별하고, 아기 울음소리를 통해 구별 가능한 N2개의 아기 감정 항목 중 상기 판별된 c개의 아기 울음소리와 매칭 관계를 지닌 n2개의 아기 감정 항목 을 판별하고, 상기 확인된 c개의 아기 울음소리와 n2개의 아기 감정 항목 간 상관도에 대응하는 n2개의 감정 항 목 별 아기 감정 상태 값을 판별하는 단계를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 제4 단계는, 상기 산출된 n2개의 감정 항목 별 아 기 감정 상태 값을 추가 이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성하는 단계를 더 포함 하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 카메라장치에 구비되거나 연계된 센서모듈을 통해 센싱된 센싱 데이터 중 아기의 감정 표현과 연관된 지정된 센싱 대상의 센싱 데이터에 대한 S(S≥2)개의 센싱 값 패턴 정보와 지정된 N개의 아기 감정 항목 중 지정된 센싱 대상의 센싱 값 패턴을 근거로 구별 가능한 N3(1 ≤N3≤N)개의 아기 감정 항목 사이의 매칭 관계정보 및 상기 S개의 센싱 값 패턴 정보와 N3개의 아기 감정 항목 간 상관도를 수치화한 센싱 기반 상관도 수치 관계정보를 포함하는 센싱 기반 감정상태 판별 정보를 운영D/B에 등록 저장하는 단계를 더 포함하고, 상기 제2 단계는, 상기 카메라장치에 구비되거나 연계된 센서모듈을 통해 센싱된 센싱 데이터를 수신하고 상기 비디오 데이터와 연계하여 지정된 저장매체의 특정 저장영역에 저장 관리 하는 단계를 더 포함하며, 상기 제3 단계는, 상기 비디오 데이터와 연계된 센싱 데이터를 판독하여 상기 특정 아기의 감정 표현과 연관된 지정된 센싱 대상의 센싱 데이터에 대한 k(k≥1)개의 센싱 값 인식 정보를 인식하고, 상기 센싱 기반 감정상태 판별 정보를 근거로 상기 인식된 k개의 센싱 값 인식 정보와 기 설정된 기 준 유사도 이상 매칭된 s(1≤s≤S)개의 센싱 값 패턴 정보를 확인하고 상기 확인된 s개의 센싱 값 패턴 정보와 매칭 관계를 지닌 n3(1≤n3≤N3)개의 아기 감정 항목을 판별하며, 상기 인식된 k개의 센싱 값 인식 정보와 상기 s개의 센싱 값 패턴 정보 간 매칭 비율을 근거로 상기 s개의 센싱 값 패턴 정보와 n3개의 아기 감정 항목 간 상 관도 수치 관계를 판독하여 상기 인식된 k개의 센싱 값 인식 정보에 대응하는 n3개의 감정 항목 별 아기 감정 상태를 수치화한 n3개의 감정 항목 별 아기 감정 상태 값을 산출하는 단계를 더 포함하고, 상기 제4 단계는, 상 기 산출된 n3개의 감정 항목 별 아기 감정 상태 값을 추가 이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성하는 단계를 더 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 센서모듈은, 아기의 신체에 착용하여 지정된 센싱 대상을 센싱하는 웨어러블(Wearable) 센서모듈, 지정된 전자파를 이용하여 아기의 지정된 센싱 대상을 센싱하는 레이더(Radar) 센서모듈 중 적어도 하나의 센서모듈을 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 센싱 대상은, 아기의 심장박동, 아기의 체온, 아기 주변 습도, 아기의 무호흡 여부 중 적어도 하나를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 S개의 센싱 값 패턴 정보는, 아기의 감정표현과 연 관된 지정된 센싱 대상의 센싱 데이터에 대한 각각의 센싱 값 패턴을 구성하는 센싱 값 특징의 범위 정보를 포 함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 센싱 값 특징은, 센싱 값의 변화 규칙 특징, 센싱 값의 변화량 특징, 센싱 값 변화율 특징, 센싱 값 변화의 주기성 특징 중 적어도 하나 또는 둘 이상의 조합을포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 센싱 기반 상관도 수치 관계정보는, 지정된 센싱 대상의 센싱 데이터를 통해 인식된 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 간 매칭 비율에 비례하는 관계식을 통해 산출되는 상관도 수치정보를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 센싱 기반 상관도 수치 관계정보는, 지정된 센싱 대상의 센싱 데이터를 통해 인식된 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 사이의 각 매칭 비율 구 간 별 상관도 수치정보를 포함하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 n개의 감정 항목 별 아기 감정 상태 정보는, n개의 감정 항목 정보와 각 감정 항목 별 아기 감정 상태의 수치정보를 문자 형태로 포함하여 이루어지는 것을 특징으 로 한다. 본 발명에 따른 영유아 감정 상태 출력 방법에 있어서, 상기 n개의 감정 항목 별 아기 감정 상태 정보는, n개의 감정 항목 정보와 각 감정 항목 별 아기 감정 상태의 수치정보를 그래프 형태로 포함하여 이루어지는 것을 특징 으로 한다."}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 지정된 거점에 구비된 카메라장치를 통해 상기 거점 내의 특정 아기를 촬영한 비디오 데이터 를 포함하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공 시 상기 카메라장치를 통해 획득된 하나 이상의 데이터를 근거로 상기 특정 아기에 대한 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하고 상기 송신 데이터의 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 각 감정 항목 별 아기 감정 상태 정보 를 표시하여 제공함으로써, 무선단말의 앱이나 IPTV를 통해 상기 송신 데이터를 시청하는 사용자는 상기 송신 데이터의 비디오 데이터에 대응하는 아기의 영상 화면이나 상기 송신 데이터의 오디오 데이터에 대응하는 아기 의 소리 이외에 상기 아기의 각 감정 항목 별 감정 상태까지 실시간 파악할 수 있는 이점이 있다."}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면과 설명을 참조하여 본 발명의 바람직한 실시예에 대한 동작 원리를 상세히 설명한다. 다만, 하기에 도시되는 도면과 후술되는 설명은 본 발명의 특징을 효과적으로 설명하기 위한 여러 가지 방법 중에서바람직한 실시 방법에 대한 것이며, 본 발명이 하기의 도면과 설명만으로 한정되는 것은 아니다. 즉, 하기의 실시예는 본 발명의 수 많은 실시예 중에 바람직한 합집합 형태의 실시예에 해당하며, 하기의 실시 예에서 특정 구성(또는 단계)을 생략하는 실시예, 또는 특정 구성(또는 단계)에 구현된 기능을 특정 구성(또는 단계)으로 분할하는 실시예, 또는 둘 이상의 구성(또는 단계)에 구현된 기능을 어느 하나의 구성(또는 단계)에 통합하는 실시예, 특정 구성(또는 단계)의 동작 순서를 교체하는 실시예 등은, 하기의 실시예에서 별도로 언급 하지 않더라도 모두 본 발명의 권리범위에 속함을 명백하게 밝혀두는 바이다. 따라서 하기의 실시예를 기준으로 부분집합 또는 여집합에 해당하는 다양한 실시예들이 본 발명의 출원일을 소급받아 분할될 수 있음을 분명하게 명기하는 바이다. 또한, 하기에서 본 발명을 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지 를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서, 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 발명에서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 결과적으로, 본 발명의 기술적 사상은 청구범위에 의해 결정되며, 이하 실시예는 진보적인 본 발명의 기술적 사"}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상을 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 효율적으로 설명하기 위한 일 수단일 뿐이다. 도면1은 본 발명의 실시 방법에 따라 아기의 감정 상태를 표시하는 시스템의 구성을 도시한 도면이다. 보다 상세하게 본 도면1은 지정된 거점에 구비된 카메라장치를 통해 상기 거점 내의 특정 아기를 포함하는 영유아를 촬영한 비디오 데이터를 포함하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공 시 상기 카메라장치를 통해 획득된 하나 이상의 데이터를 근거로 상기 특정 아기에 대한 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하고 상기 송신 데이터의 비디오 데이터 상의 지정된 일정 영역에 상 기 생성된 각 감정 항목 별 아기 감정 상태 정보를 표시하여 제공하는 시스템의 구성을 도시한 것으로서, 본 발"}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면1을 참조 및/또는 변형하여 상기 시스템의 구성에 대한 다양한 실시 방법(예컨대, 일부 구성부가 생략되거나, 또는 세분화되거나, 또는 합쳐진 실시 방법)을 유추 할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면1에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 본 발명의 시스템은, 지정된 거점에 구비되어 피사체를 찰영하고 통신망에 접속 가능한 카메라장치와, 상 기 카메라장치의 카메라모듈을 통해 상기 거점 내의 특정 아기를 촬영하여 획득된 영상 신호를 지정된 방 식으로 엔코딩한 비디오 데이터를 포함하는 획득 데이터를 수신하여 지정된 저장매체의 특정 저장영역에 저장하 는 기능, 상기 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 지정된 사용자 무 선단말의 앱이나 IPTV로 제공하는 기능, 상기 카메라장치를 통해 획득된 하나 이상의 데이터를 근거로 상기 특정 아기에 대한 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하는 기능, 상기 비디오 데 이터 상의 지정된 일정 영역에 상기 생성된 각 감정 항목 별 아기 감정 상태 정보를 표시하는 기능 중 하나 이 상 수행하는 운영서버를 포함하여 이루어진다. 상기 운영서버는 독립된 서버 형태, 둘 이상의 서버 조합 형태, 기 구비된 서버를 통해 실행되는 소프트웨어 형태 중 적어도 하나 또는 둘 이상의 조합 형태로 구현 될 수 있으며, 상기 운영서버를 구현하는 실시예나 상기 운영서버의 명칭에 의해 본 발명이 한정되지 아니한다. 상기 카메라장치는 지정된 거점에 구비되어 피사체를 촬영하는 카메라를 구비한 단말이나 장치의 총칭으로 서, 바람직하게 산후조리원이나 가정집의 아기가 기거하는 공간에 구비되어 상기 공간에 존재하는 특정 아기를 촬영하는 카메라를 구비한 단말이나 장치를 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 카메라장치는 거점 내의 지정된 피사체를 촬영하는 카메라모듈과, 지 정된 통신망에 연결하는 통신모듈 및 상기 카메라모듈을 통해 획득된 영상 신호를 지정된 방식으로 엔코딩한 비 디오 데이터를 포함하는 획득 데이터를 생성하여 상기 통신모듈을 통해 지정된 운영서버로 전송하는 절차 를 수행하는 제어모듈을 구비한다. 상기 카메라모듈은 피사체로부터 반사된 광신호를 입력받는 하나 이상의 렌즈부와, 상기 렌즈부를 통해 입력되 는 광신호를 검지하여 전기적 영상 신호로 변환하는 이미지 센서부 및 상기 렌즈부와 이미지 센서부 사이에서 자동초점 기능이나 줌 기능 등을 포함하는 지정된 기능 동작을 구현하는 액츄에이터부(Actuator)를 포함하여 이 루어진다. 한편 실시 방법에 따라 상기 카메라모듈은상기 렌즈부와 이미지 센서부 사이에는 야간에도 피사체를 촬영하기 위한 적외선 필터를 포함하는 이상의 필터부를 더 구비할 수 있다. 한편 상기 카메라모듈은 상기 이미 지 센서부를 통해 생성된 영상 신호를 제어모듈로 제공하기 위한 PCB를 구비한다. 한편 실시 방법에 따라 상기 카메라모듈은 상기 이미지 센서부를 통해 생성된 영상 신호의 품질 향상을 위해 지정된 절차에 따라 상기 영상 신호를 가공하는 이미지 신호처리 프로세서(Image Signal Processor; ISP)를 더 구비할 수 있다. 상기 통신모듈은 패킷 기반의 통신망에 연결하는 모듈의 총칭으로서, 바람직하게 UTP 케이블 등의 유선을 이용 하여 통신망에 연결하는 통신모듈과 무선랜을 통해 통신망에 연결하는 통신모듈 중 적어도 하나 또는 둘을 모두 포함할 수 있다. 한편 실시 방법에 따라 상기 통신모듈은 무선랜 이외에 이동통신망이나 별도의 지정된 무선 통 신을 통해 통신망에 연결하는 통신모듈을 더(또는 대체) 포함할 수 있으며, 이에 의해 본 발명이 한정되지 아니 한다. 상기 제어모듈은 상기 카메라모듈을 통해 생성된 영상 신호를 지정된 방식으로 엔코딩하여 비디오 데이터를 생 성할 수 있다. 한편 실시 방법에 따라 상기 비디오 데이터는 상기 카메라모듈을 통해 생성되어 상기 제어모듈로 전달될 수 있다. 한편 상기 비디오 데이터는 상기 영상 신호를 촬영한 시점의 시간 값(또는 타임스탬프)를 더 포함할 수 있다. 상기 제어모듈은 상기 비디오 데이터를 포함하는 획득 데이터를 생성하여 상기 통신모듈을 통해 지정된 운영서 버로 전송하는 절차를 수행할 수 있다. 한편 실시 방법에 따라 상기 획득 데이터는 상기 비디오 데이터 이 외에 오디오 데이터를 더 포함하거나 및/또는 지정된 센서모듈을 통해 센싱된 센싱 데이터를 더 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 카메라장치는 거점 내의 사운드 신호를 입력받는 사운드 입력부를 더 구비하며, 이 경우 상기 제어모듈은 상기 사운드 입력부를 통해 획득된 사운드 신호를 지정된 방식으로 엔코딩 한 오디오 데이터를 더 포함하는 획득 데이터를 생성하여 상기 통신모듈을 통해 지정된 운영서버로 전송하 는 절차를 수행할 수 있다. 상기 사운드 입력부는 공기의 진동을 전기적 신호 형태의 사운드 신호로 변환하는 마이크로폰 및 이를 제어모듈 과 인터페이스하는 인터페이스부를 포함하여 구성되며, 상기 제어모듈은 상기 사운드 입력부를 통해 획득된 사 운드 신호를 지정된 지정된 방식으로 엔코딩하여 오디오 데이터를 생성할 수 있다. 한편 실시 방법에 따라 상기 사운드 입력부가 별도의 모듈 형태로 구현되는 겨우, 상기 오디오 데이터는 상기 사운드 입력부를 통해 카메라 모듈을 통해 생성되어 상기 제어모듈로 전달될 수 있다. 한편 상기 오디오 데이터는 상기 사운드 신호를 입력받 은 시점의 시간 값(또는 타임스탬프)를 더 포함할 수 있다. 상기 카메라장치에 상기 사운드 입력부를 구비하여 상기 사운드 입력부를 통해 획득된 사운드 신호를 엔코 딩한 오디오 데이터가 생성되는 경우, 상기 제어모듈은 상기 비디오 데이터와 오디오 데이터를 포함하는 획득 데이터를 생성하여 상기 통신모듈을 통해 지정된 운영서버로 전송하는 절차를 수행할 수 있다. 본 발명의 일 실시 방법에 따르면, 상기 획득 데이터는 상기 비디오 데이터와 오디오 데이터를 지정된 데이터 포맷에 포함하는 동영상 데이터(또는 멀티미디어 데이터) 형태로 생성될 수 있다. 본 발명의 다른 일 실시 방법에 따르면, 상기 획득 데이터는 상기 비디오 데이터와 오디오 데이터를 지정된 각 각의 데이터 포맷에 포함하되, 상기 비디오 데이터와 오디오 데이터에 포함된 시간 값(또는 타임스탬프)를 통해 시점을 동기화 가능한 각각의 데이터 형태로 생성될 수 있다. 본 발명의 실시 방법에 따르면, 상기 카메라장치는 지정된 사운드 신호를 지정된 신호 강도로 출력하는 사 운드 출력부를 더 구비할 수 있으며, 이 경우 상기 제어모듈은 지정된 절차에 따라 상기 사운드 출력부를 통해 출력할 사운드 신호에 대응하는 오디오 데이터를 생성하거나 및/또는 지정된 저장영역으로부터 추출하거나 및/ 또는 상기 통신모듈을 통해 지정된 운영서버로부터 상기 사운드 출력부를 통해 출력할 사운드 신호에 대응 하는 오디오 데이터를 수신하고, 상기 생성/추출/수신된 오디오 데이터에 대응하는 사운드 신호를 상기 사운드 출력부를 통해 출력하도록 처리하는 절차를 수행할 수 있다. 상기 사운드 출력부는 오디오 데이터를 디코딩한 전기적 신호 형태의 사운드 신호를 출력하는 스피커 및 이를 제어모듈과 인터페이스하는 인터페이스부를 포함하여 구성되며, 상기 제어모듈은 상기 사운드 출력부를 통해 출 력할 오디오 데이터를 생성하거나 및/또는 지정된 저장영역으로부터 추출하거나 및/또는 상기 통신모듈을 통해 지정된 운영서버로부터 수신하고, 상기 사운드 출력부를 통해 상기 오디오 데이터에 대응하는 사운드 신호 를 지정된 신호 강도(예컨대, 카메라장치의 스피커를 통해 출력된 사운드 신호가 지정된 거리 내외로 이격 된 아기에게 지정된 소리 크기로 전달되도록 설정된 신호 강도)로 출력할 수 있다. 본 발명의 실시 방법에 따르면, 상기 카메라장치는 지정된 센서를 통해 아기의 지정된 센싱 대상을 센싱하 는 센서모듈을 구비하거나 연계될 수 있으며, 상기 제어모듈은 상기 센서모듈을 통해 센싱하여 획득된 센싱 신 호를 지정된 방식으로 엔코딩한 센싱 데이터를 더 포함하는 획득 데이터를 생성하여 상기 통신모듈을 통해 지정 된 운영서버로 전송하는 절차를 수행할 수 있다. 바람직하게, 상기 센서모듈을 통해 센싱하는 아기의 지정 된 센신 대상은 아기의 심장박동, 아기의 체온, 아기 주변 습도, 아기의 무호흡 여부 중 적어도 하나를 포함할 수 있다. 상기 센서모듈은 아기의 신체 중 지정된 부위에 착용하여 아기의 지정된 센싱 대상을 센싱하는 웨어러블 (Wearable) 센서모듈을 포함할 수 있으며, 이 경우 상기 제어모듈은 지저된 근거리 통신(예컨대, 블루투스 등) 을 통해 상기 웨어러블 센서모듈과 연계하여 상기 센서모듈을 통해 센싱된 센싱 값에 대응하는 센싱 신호를 수 신하거나 또는 상기 센서모듈을 통해 상기 센싱 신호를 지정된 방식으로 엔코딩한 센싱 데이터를 수신할 수 있 다. 한편 상기 센서모듈은 지정된 전자파를 이용하여 아기의 지정된 센싱 대상을 센싱하는 레이더(Radar) 센서모듈 을 포함할 수 있으며, 이 경우 상기 제어모듈은 상기 레이더 센서모듈을 통해 싱된 센싱 값에 대응하는 센싱 신 호를 확인하고 지정된 방식으로 엔코딩하여 센싱 데이터를 생성할 수 있다. 한편 상기 레이더 센서모듈은 상기 센싱 신호를 지정된 방식으로 엔코딩한 센싱 데이터를 생성하여 상기 제어모듈로 제공할 수 있으며, 이 경우 상 기 제어모듈은 상기 레이더 센서모듈로부터 상기 센싱 데이터를 제공받을 수 있다. 본 발명의 실시 방법에 따르면, 상기 센싱 데이터는 상기 센서모듈을 통해 지정된 센싱 대상을 센싱한 센싱 값 을 포함하며, 바람직하게 상기 센서모듈을 통해 상기 센싱 값을 센싱한 시점의 시간 값(또는 타임스탬프)를 더 포함할 수 있다. 상기 카메라장치에 상기 센서모듈을 구비하거나 연계시켜 아기의 지정된 센싱 대상을 센싱한 센싱 데이터 가 생성되는 경우, 상기 제어모듈은 상기 획득 데이터에 상기 센싱 데이터를 추가하여 상기 통신모듈을 통해 지 정된 운영서버로 전송하는 절차를 수행할 수 있다. 바람직하게, 상기 센싱 데이터는 지정된 데이터 포맷에 포함된 형태로 상기 획득 데이터에 포함될 수 있으며, 상기 비디오 데이터와 센싱 데이터에 포함된 시간 값(또 는 타임스탬프)를 통해 시점을 동기화 가능한 데이터 형태로 생성될 수 있다. 본 발명의 실시 방법에 따르면, 상기 카메라장치는 상기 카메라모듈의 촬영 방향을 상/하/좌/우 방향으로 지정된 각도 범위 내로 구동하는 구동모듈을 더 구비하며, 상기 제어모듈은 상기 카메라모듈을 통해 촬영되는 비디오 데이터를 판독하여 아기(또는 아기의 안면)에 대응하거나 아기가 누워 있는 요람이나 이불에 대응하는 객체를 인식하는 과정을 시도할 수 있다. 만약 상기 객체가 인식되지 않는 경우, 상기 제어모듈은 상기 구동모 듈을 통해 상기 카메라모듈의 촬영 방향을 지정된 방향으로 지정된 각도 범위만큼 이격하면서 상기 객체가 인식 하는 과정을 전 각도 범위에 도달할 때까지 반복할 수 있다. 만약 상기의 인식 과정을 통해 상기 객체가 인식되 면, 상기 카메라장치는 상기 인식된 아기의 안면 영역을 상기 비디오 데이터 상의 지정된 영역 내에 존재 하도록 촬영방향을 제어하고, 상기 아기의 안면 영역의 움직임이나 이동에 반응하여 상기 아기의 안면 영역을 추적하여 상기 비디오 데이터 상의 지정된 영역 내에 존재하도록 상기 카메라모듈의 촬영방향을 제어할 수 있다. 한편 상기 구동모듈을 통해 상기 카메라모듈의 촬영 방향을 제어하거나 상기 객체를 인식하는 과정은 상 기 서버를 통해 실행될 수 있으며, 이에 의해 본 발명이 한정되지 아니한다. 본 발명의 실시 방법에 따르면, 상기 카메라장치는 램프를 통해 지정된 형상이나 영상을 천정이나 벽면에 투영하는 프로젝터부를 더 구비할 수 있으며, 이 경우 상기 제어모듈은 지정된 절차에 따라 상기 프로젝터부의 램프를 온/오프 처리할 수 있으며, 또는 상기 제어모듈은 상기 통신모듈을 통해 지정된 운영서버로부터 상 기 프로젝터부의 램프를 온/오프 처리하기 위한 제어정보를 수신할 수 있으며, 상기 제어정보를 근거로 상기 프 로젝터부의 램프를 온/오프 처리할 수 있다. 한편 상기 프로젝터부를 통해 복수의 필름 중 어느 한 필름으로 선 택하여 투영할 형상이나 영상을 선택 가능한 경우, 상기 제어모듈은 지정된 절차에 따라 상기 프로젝터부의 필 름을 선택하거나 및/또는 램프를 온/오프 처리할 수 있으며, 또는 상기 제어모듈은 상기 통신모듈을 통해 지정 된 운영서버로부터 상기 프로젝터부의 필름을 선택하거나 및/또는 램프를 온/오프 처리하기 위한 제어정보 를 수신할 수 있으며, 상기 제어정보를 근거로 상기 프로젝터부의 필름을 선택하거나 및/또는 램프를 온/오프 처리할 수 있다. 한편 상기 프로젝터부를 통해 전자적 형상이나 전자적 영상을 투영 가능한 경우, 상기 제어모 듈은 지정된 절차에 따라 지정된 저장영역에 저장된 전자적 형상이나 전자적 영상을 추출하여 상기 프로젝터부 를 통해 투영할 형상이나 영상으로 처리하거나 및/또는 램프를 온/오프 처리할 수 있으며, 또는 상기 제어모듈 은 상기 통신모듈을 통해 지정된 운영서버로부터 저장된 전자적 형상이나 전자적 영상을 및/또는 램프를 온/오프 처리하기 위한 제어정보를 수신할 수 있으며, 상기 제어정보를 근거로 상기 수신된 전자적 형상이나 전 자적 영상을 상기 프로젝터부를 통해 투영할 형상이나 영상으로 처리하거나 및/또는 램프를 온/오프 처리할 수 있다. 상기 사용자 무선단말은 상기 카메라장치를 통해 촬영된 비디오 데이터를 포함하는 송신 데이터를 제 공받을 사용자가 사용하는 무선통신기기의 총칭으로서, 사용자가 사용하는 휴대폰, 스마트폰, 태블릿PC 등의 각 종 무선통신기기를 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 사용자 무선단말은 운영서버에 지정된 정보를 등록하고, 상기 운영서버로부터 상기 카메라장치를 통해 촬영된 비디오 데이터를 포함하는 송신 데이터를 제공받기 위해 앱(Application)이 설치 실행된다. 이하, 별도의 언급이 없더라도 상기 사용자 무선단말을 주체 또는 객체로 하여 구현되는 기능의 설명은 상기 앱을 통해 구현되는 기능임을 밝혀두는 바이다.상기 운영서버는 지정된 거점에 구비된 카메라장치와 통신하고 지정된 앱을 설치 실행한 사용자 무선 단말의 앱과 통신 가능한 서버의 총칭으로서, 상기 카메라장치의 카메라모듈을 통해 상기 거점 내의 특정 아기를 촬영하여 지정된 방식으로 엔코딩된 비디오 데이터를 포함하는 획득 데이터를 수신하여 지정된 저 장매체의 특정 저장영역에 저장하는 기능, 상기 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공하는 기능 중 적어도 하나의 기능을 수 행하며, 본 발명에 따라 상기 카메라장치를 통해 획득된 하나 이상의 데이터를 근거로 상기 특정 아기에 대한 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하는 기능과, 상기 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 각 감정 항목 별 아기 감정 상태 정보를 표시하는 기능 중 적어도 하나의 기능을 수행한다. 본 발명의 실시 방법에 따르면, 상기 송신 데이터는 상기 저장매체의 특정 저장영역에 저장된 비디오 데이터 외 에, 상기 비디오 데이터와 연계되어 상기 저장매체의 특정 저장영역에 저장된 오디오 데이터, 또는 상기 비디오 데이터를 포함하는 동영상 데이터의 오디오 데이터를 더 포함할 수 있다. 도면1을 참조하면, 상기 운영서버는, 상기 카메라장치를 통해 촬영되는 아기에 대한 지정된 감정 항 목 별 아기 감정 상태 값을 판별하기 위한 감정상태 판별 정보를 지정된 저장영역에 저장 관리하는 정보 관리부 를 포함한다. 상기 정보 관리부는 지정된 인공지능 기반의 학습(Learning) 과정을 통해 아기 표정에 대응하는 지정된 감 정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반의 표정 기반 감정상태 판별 정보를 생성하여 지 정된 저장영역에 저장하거나, 및/또는 지정된 운영단말로부터 패턴 인식 기반의 표정 기반 감정상태 판별 정보 를 등록받아 지정된 저장영역에 저장할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 인공지능 기반의 표정 기반 감정상태 판별 정보를 생 성하는 경우, 지정된 인공지능 기반의 지도 학습(Supervised Learning) 과정을 통해 아기 표정에 대응하는 지정 된 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반의 표정 기반 감정상태 판별 정보를 생성하 여 지정된 저장영역에 저장할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 지정된 인공지능 기반의 학습 과정을 수행하여, 지정 된 E(E≥2)개의 아기 표정 중 지정된 아기 안면 영역에 대응하는 e(1≤e≤E)개의 아기 표정을 판별하고, 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N)개의 아기 감정 항목을 기반으로 상 기 판별된 e개의 아기 표정과 매칭 관계를 지닌 n1(1≤n1≤N1)개의 아기 감정 항목을 판별하고, 상기 확인된 e 개의 아기 표정과 n1개의 아기 감정 항목 간 상관도에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별 하기 위한 인공지능 기반의 표정 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장할 수 있다. 본 발명의 실시 방법에 따르면, 상기 N개의 아기 감정 항목은 '기쁨(喜)', '노여움(怒)', '슬픔(哀)', '즐거움 (樂)', '사랑(愛)', '미움(惡)', '욕심(欲)' 등의 기본 감정 중에서 사회화가 진행되지 않거나 성인보다 덜 진 행된 아기라도 느낄 수 있는 하나 이상의 감정(예컨대, '기쁨', '노여움', '슬픔', '즐거움' 등)에 대응하는 감 정 항목을 포함할 수 있으며, 상기 기본 감정 외에 아기가 느낄 수 있는 다양한 감정(예컨대, '짜증', '외로 움', '답답함', '불쾌', '두려움' 등)에 대한 감정 항목을 더 포함하거나 및/또는 상기 기본 감정 중 적어도 하 나를 아기의 상황에 맞게 구체화한 감정(예컨대, '욕심' 중 수면욕에 해당하는 '졸림'이나 식욕에 해당하는 '배 고픔' 등)에 대응하는 감정 항목을 더 포함할 수 있다. 한편 상기 인공지능 기반의 표정 기반 감정상태 판별 정보를 생성하는 일 실시예에 따르면, 상기 정보 관리부 는 지정된 데이터베이스나 운영단말로부터 지정된 E(E≥2)개의 아기 표정 중 지정된 e(1≤e≤E)개의 아기 표정에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1≤N)개의 아 기 감정 항목과 지정된 상관도를 지닌 아기 안면 영역을 포함하는 장면에 대응하는 복수의 비디오 정보를 포함 하는 빅 데이터를 입력받고, 상기 입력된 복수의 비디오 정보에 대한 n1(1≤n1≤N1)개의 감정 항목 별 아기 감 정 상태 값을 출력변수(Labels)로 설정한 후, 지정된 절차에 따라 상기 입력된 복수의 비디오 정보들에 포함된 아기 안면 영역의 지정된 특징점 간 기하학 관계를 판독하고 패턴 인식하여 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값에 대응하는 P(P≥2)개의 장면 패턴 특성 정보를 추출하고, 상 기 추출된 P개의 장면 패턴 특성 정보를 입력변수(Feature Vectors)로 설정하고 지정된 인공지능 알고리즘을 통 해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 아기 안면 영역을 포함하는 복수의 장면들 중 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기 반의 표정 기반 감정상태 판별 정보를 생성할 수 있다. 한편 상기 출력변수는 상기 비디오 정보에 포함된 상기 아기 안면 영역에 대응하는 e개의 아기 표정 정보와, 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함할 수 있다. 또는, 상기 정보 관리부는 지정된 데이터베이스나 운영단말로부터 지정된 E(E≥2)개의 아기 표정 중 지정 된 e(1≤e≤E)개의 아기 표정에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능 한 N1(1≤N1≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 안면 영역을 포함하는 장면에 대응하는 복수 의 비디오 정보들을 지정된 절차에 따라 판독하고 패턴 인식하여 상기 아기 안면 영역의 아기 표정에 대응하는 n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값의 패턴 특성으로 추출된 P(P≥2)개의 장면 패턴 특성 정보 를 포함하는 빅 데이터를 입력변수(Feature Vectors)로 입력받고, 상기 P개의 장면 패턴 특성 정보가 추출된 비 디오 정보에 대한 n1개의 감정 항목 별 아기 감정 상태 값을 출력변수(Labels)로 설정한 후, 지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 아기 안면 영역을 포함하는 복수의 장 면들 중 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반의 표정 기반 감정상태 판별 정보를 생성할 수 있다. 한편 상기 출력변수는 상기 비디오 정보에 포함된 상기 아기 안면 영역에 대응하는 e개의 아기 표정 정보와, 상기 아기 안면 영역의 아기 표정에 대응하는 n1개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 패턴 인식 기반의 표정 기반 감정상태 판별 정보를 생 성하는 경우, 상기 정보 관리부는 아기의 안면 영역에 존재하는 F(F≥2)개의 특징점 중 아기의 감정 표현 과 연관된 특징점 간 기하학 관계에 대응하는 E(E≥2)개의 아기 표정 패턴 정보와 지정된 N(N≥2)개의 아기 감 정 항목 중 아기 표정 패턴을 근거로 구별 가능한 N1(1≤N1≤N)개의 아기 감정 항목 사이의 매칭 관계정보를 포 함하고 상기 E개의 아기 표정 패턴 정보와 N1개의 아기 감정 항목 간 상관도를 수치화한 표정 기반 상관도 수치 관계정보를 포함하는 표정 기반 감정상태 판별 정보를 지정된 운영D/B에 등록 저장한다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 지정된 운영단말로부터 아기의 안면 영역에 존재하는 F개의 특징점 중 아기의 감정 표현과 연관된 특징점 간 기하학 관계에 대응하는 E개의 아기 표정 패턴 정보를 등록받고, 상기 E개의 아기 표정 패턴 정보를 지정된 N개의 아기 감정 항목 중 아기 표정 패턴을 근거로 구별 가능한 N1개의 아기 감정 항목과 매칭하는 매칭 관계정보를 등록받고, 상기 E개의 아기 표정 패턴 정보와 N1개 의 아기 감정 항목 간 상관도를 수치화한 표정 기반 상관도 수치 관계정보를 등록받아 지정된 운영D/B에 등록 저장할 수 있다. 예를들어, 상기 정보 관리부는 상기 E개의 아기 표정 패턴 정보와 N1개의 아기 감정 항목 을 행 또는 열의 타이틀로 포함하며 상기 표정 기반 상관도 수치 관계정보를 각 행열에 대응하는 셀(Cell)의 정 보로 포함하는 테이블 형태의 표정 기반 감정상태 판별 정보를 지정된 운영D/B에 등록 저장할 수 있다. 본 발명의 일 실시 방법에 따르면, 상기 E개의 아기 표정 패턴 정보는 아기의 감정표현과 연관된 각각의 아기 표정 패턴에 대응하는 각 특징점 간 기하학 관계 정보를 포함할 수 있다. 바람직하게, 상기 특징점 간 기하학 관계는 각 특징점 간 거리 관계, 각 특징점 간 각도 관계, 각 특징점 간 거리 관계와 각도 관계의 조합 관계 중 하나 이상의 관계를 포함할 수 있다. 예를들어, 상기 특징점 간 기하학 관계 정보는 지정된 기준 특징점 간 거리 수치를 기준으로 하는 각 특징점 간 거리 수치, 각 특징점 간 각도 수치, 각 특징점 간 거리 수치와 각도 수 치의 조합 중 하나 이상의 수치를 포함할 수 있다. 한편 본 발명의 다른 일 실시 방법에 따르면, 상기 E개의 아기 표정 패턴 정보는 아기의 감정표현과 연관된 각 각의 아기 표정 패턴에 대응하는 각 특징점 간 기하학 관계의 범위 정보를 포함할 수 있다. 바람직하게, 상기 특징점 간 기하학 관계는 각 특징점 간 거리 관계, 각 특징점 간 각도 관계, 각 특징점 간 거리 관계와 각도 관 계의 조합 관계 중 하나 이상의 관계를 포함할 수 있다. 예를들어, 상기 특징점 간 기하학 관계의 범위 정보는 지정된 기준 특징점 간 거리 수치를 기준으로 하는 각 특징점 간 거리 수치 범위, 각 특징점 간 각도 수치 범위, 각 특징점 간 거리 수치 범위와 각도 수치 범위의 조합 중 하나 이상의 수치 범위를 포함할 수 있다. 본 발명의 일 실시 방법에 따르면, 상기 표정 기반 상관도 수치 관계정보는 아기의 표정을 인식한 아기 표정 인 식 정보와 기 등록된 아기 표정 패턴 정보 간 매칭 비율에 비례하는 관계식을 통해 산출되는 상관도 수치정보를 포함할 수 있다. 예를들어, 상기 표정 기반 상관도 수치 관계정보는 아기 표정 인식 정보와 기 등록된 아기 표 정 패턴 정보 간 매칭 비율이 작을수록 작은 수치정보로 산출될 수 있으며, 상기 매칭 비율을 클수록 큰 수치정 보로 산출될 수 있다. 한편 본 발명의 다른 일 실시 방법에 따르면, 상기 표정 기반 상관도 수치 관계정보는 아기의 표정을 인식한 아 기 표정 인식 정보와 기 등록된 아기 표정 패턴 정보 사이의 각 매칭 비율 구간 별 상관도 수치정보를 포함할 수 있다. 예를들어, 상기 표정 기반 상관도 수치 관계정보는 아기 표정 인식 정보와 기 등록된 아기 표정 패턴 정보 간 매칭 비율이 기 설정된 최소 비율 구간인 경우 '0'이나 지정된 최소값의 수치정보로 산출될 수 있으며, 상기 매칭 비율이 기 설정된 최대 비율 구간인 경우 지정된 최대값의 수치정보로 산출될 수 있다. 한편 본 발명의 실시 방법에 따르면, 지정된 운영단말을 통해 상기 운영D/B에 상기 표정 기반 감정상태 판별 정 보가 등록 저장된 후, 하기 정보 인식부를 통해 지정된 아기 표정 인식 정보가 인식된 경우, 상기 정보 관 리부는 상기 아기 표정 인식 정보가 인식된 후에 상기 카메라장치로부터 수신되어 지정된 저장매체의 특정 저장영역에 저장되는 비디오 데이터를 판독하여 아기의 보호자에 대응하는 객체를 인식함과 동시에 상기 비디오 데이터와 연계된 오디오 데이터를 판독하여 아기의 보호자가 아기에게 발화하는 음성 중 아기 감정 인지 와 관련된 음성(예컨대, '우리 애기 배고프구나', '우리 애기 똥 쌋구나', '우리 애기 졸리구나' 등)을 인식하 는 절차를 수행할 수 있다. 만약 아기 표정 인식 정보가 인식된 후에 보호자의 아기 감정 인지와 관련된 음성이 인식된 경우, 상기 정보 관리부는 상기 인식된 아기 표정 인식 정보를 패턴화함과 동시에 상기 아기 감정 인지와 관련된 음성에 대응하는 음성 인식 기반의 아기 감정 항목을 식별하고, 상기 인식된 아기 표정 인식 정 보를 패턴화한 아기 표정 패턴 정보와 상기 식별된 음성 인식 기반의 아기 감정 항목의 조합을 학습하는 과정을 반복함으로써 상기 표정 기반 감정상태 판별 정보의 빅데이터 기반 정확도와 신뢰도를 지속적으로 향상시킬 수 있다. 한편 본 발명의 확장 실시예에 따르면, 상기 정보 관리부는 상기 표정 기반 감정상태 판별 정보 외에 상기 카메라장치의 사운드 입력부를 통해 획득된 오디오 데이터를 근거로 아기 울음소리를 인식하여 아기의 감 정 상태를 판별하기 위한 울음소리 기반 감정상태 판별 정보를 운영D/B에 등록 저장하거나, 및/또는 상기 카메 라장치에 아기의 감정 표현과 연관된 지정된 센싱 대상을 센싱하는 센서모듈이 구비되거나 연계되고 상기 카메라장치로부터 상기 센서모듈을 통해 아기의 지정된 센싱 대상을 센싱하여 획득된 센싱 데이터가 수신 되는 경우 상기 센싱 데이터를 이용하여 아기의 감정 상태를 판별하기 위한 센싱 기반 감정상태 판별 정보를 운 영D/B에 등록 저장할 수 있다. 한편 본 발명의 다른 실시예에 따르면, 상기 정보 관리부는 상기 표정 기반 감정상태 판별 정보를 대신(또 는 대체)하여 상기 울음소리 기반 감정상태 판별 정보 및/또는 센싱 기반 감정상태 판별 정보를 운영D/B에 등록 저장할 수 있으며, 이에 의해 본 발명이 한정되지 아니한다. 이하, 편의 상 표정 기반 감정상태 판별 정보를 기본 감정상태 판별 정보로 이용하고 상기 울음소리 기반 감정상태 판별 정보 및/또는 센싱 기반 감정상태 판별 정보를 부 감정상태 판별 정보로 이용하는 실시예를 통해 본 발명의 특징을 설명할 것이나, 본 발명의 기술적 특징이 이에 한정되는 것은 아니며, 본 발명의 실시예와 청구범위의 기재에 따라 상기 울음소리 기반 감정상태 판별 정보 및/또는 센싱 기반 감정상태 판별 정보도 기본 감정상태 판별 정보로 이용될 수 있음을 명백하게 밝 혀두는 바이다. 본 발명의 확장/다른 실시예에 따르면, 상기 정보 관리부는 지정된 인공지능 기반의 학습(Learning) 과정 을 통해 아기 울음소리에 대응하는 지정된 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장하거나, 및/또는 지정된 운영단말로부터 패턴 인식 기반의 울음소리 기반 감정상태 판별 정보를 등록받아 지정된 저장영역에 저장할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 생성하는 경우, 지정된 인공지능 기반의 지도 학습(Supervised Learning) 과정을 통해 아기 울음소리에 대응하 는 지정된 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반의 울음소리 기반 감정상태 판별 정 보를 생성하여 지정된 저장영역에 저장할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 지정된 인공지능 기반의 학습 과정을 수행하여, 지정 된 C(C≥2)개의 아기 울음소리 중 지정된 c(1≤c≤C)개의 아기 울음소리를 판별하고, 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목을 기반으로 상기 판별된 c개 의 아기 울음소리와 매칭 관계를 지닌 n2(1≤n2≤N2)개의 아기 감정 항목을 판별하고, 상기 확인된 c개의 아기 울음소리와 n2개의 아기 감정 항목 간 상관도에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 생성하여 지정된 저장영역에 저장할 수 있다. 한편 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 생성하는 일 실시예에 따르면, 상기 정보 관리 부는 지정된 데이터베이스나 운영단말로부터 지정된 C(C≥2)개의 아기 울음소리 중 지정된 c(1≤c≤C)개의 아기 울음소리에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤ N2≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 울음에 대응하는 복수의 오디오 정보를 포함하는 빅 데이터를 입력받고, 상기 입력된 복수의 오디오 정보에 대한 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값을 출력변수(Labels)로 설정한 후, 지정된 절차에 따라 상기 입력된 복수의 오디오 정보들을 판독하고 패턴 인식하여 상기 아기 울음소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값에 대응하는 P(P≥2)개의 장면 패턴 특성 정보를 추출하고, 상기 추출된 P개의 장면 패턴 특성 정보를 입력변수(Feature Vectors)로 설정하고 지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 지정된 오디오 데이 터에 포함된 아기 울음소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반 의 울음소리 기반 감정상태 판별 정보를 생성할 수 있다. 한편 상기 출력변수는 상기 오디오 정보에 포함된 상 기 아기 울음에 대응하는 c개의 아기 울음소리 정보와, 상기 아기 울음소리에 대응하는 n2개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함할 수 있다. 또는, 상기 정보 관리부는 지정된 데이터베이스나 운영단말로부터 지정된 C(C≥2)개의 아기 울음소리 중 지정된 c(1≤c≤C)개의 아기 울음소리에 대응하면서 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통 해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목과 지정된 상관도를 지닌 아기 울음에 대응하는 복수의 오디오 정보들을 지정된 절차에 따라 판독하고 패턴 인식하여 상기 아기 울음소리에 대응하는 n2(1≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값의 패턴 특성으로 추출된 P(P≥2)개의 장면 패턴 특성 정보를 포함하는 빅 데이터를 입력변수(Feature Vectors)로 입력받고, 상기 P개의 장면 패턴 특성 정보가 추출된 오디오 정보에 대한 n2개의 감정 항목 별 아기 감정 상태 값을 출력변수(Labels)로 설정한 후, 지정된 인공지능 알고리즘을 통해 지정 개수 이상의 상기 입력변수와 출력변수를 학습시켜 지정된 오디오 데이터에 포함된 아기 울음소리에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별하기 위한 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 생성할 수 있다. 한편 상기 출력변수는 상기 오디오 정보에 포함된 상기 아기 울음에 대응하는 c개의 아기 울음소리 정보와, 상기 아기 울음소리에 대응하는 n2개의 아기 감정 항목 정보 중 적어도 하나의 정보를 더 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 패턴 인식 기반의 울음소리 기반 감정상태 판별 정보 를 생성하는 경우, 아기의 울음소리 패턴 중 아기의 감정 표현과 연관된 C(C≥2)개의 아기 울음소리 패턴 정보 와 지정된 N개의 아기 감정 항목 중 아기 울음소리 패턴을 근거로 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항 목 사이의 매칭 관계정보를 포함하고 상기 C개의 아기 울음소리 패턴 정보와 N2개의 아기 감정 항목 간 상관도 를 수치화한 울음소리 기반 상관도 수치 관계정보를 포함하는 울음소리 기반 감정상태 판별 정보를 운영D/B에 등록 저장할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 지정된 운영단말로부터 아기의 울음소리 패턴 중 아기 의 감정 표현과 연관된 C개의 아기 울음소리 패턴 정보를 등록받고, 상기 C개의 아기 울음소리 패턴 정보를 지 정된 N개의 아기 감정 항목 중 아기 울음소리 패턴을 근거로 구별 가능한 N2개의 아기 감정 항목과 매칭하는 매 칭 관계정보를 등록받고, 상기 C개의 아기 울음소리 패턴 정보와 N2개의 아기 감정 항목 간 상관도를 수치화한 울음소리 기반 상관도 수치 관계정보를 등록받아 지정된 운영D/B에 등록 저장할 수 있다. 예를들어, 상기 정보 관리부는 C개의 아기 울음소리 패턴 정보와 N2개의 아기 감정 항목를 행 또는 열의 타이틀로 포함하며 상 기 울음소리 기반 상관도 수치 관계정보를 각 행열에 대응하는 셀의 정보로 포함하는 테이블 형태의 울음소리 기반 감정상태 판별 정보를 운영D/B에 등록 저장할 수 있다 본 발명의 일 실시 방법에 따르면, 상기 C개의 아기 울음소리 패턴 정보는 아기의 감정표현과 연관된 각각의 아 기 울음소리 패턴을 구성하는 울음소리 특징 정보를 포함할 수 있다. 바람직하게, 상기 울음소리 특징은 주파수 대역 특징, 주파수 대역 특징의 배치 관계 특징, 주파수 대역 특징의 주기성 특징, 소리 강도 특징, 소리 강도 특징의 배치 관계 특징, 소리 강도 특징의 주기성 특징, 주파수 대역 특징과 소리 강도 특징의 조합 특징, 주파 수 대역 특징과 소리 강도 특징의 배치 관계 특징, 주파수 대역 특징과 소리 강도 특징의 주기성 특징 중 하나 이상의 특징을 포함할 수 있다. 한편 본 발명의 다른 일 실시 방법에 따르면, 상기 C개의 아기 울음소리 패턴 정보는 아기의 감정표현과 연관된 각각의 아기 울음소리 패턴을 구성하는 울음소리 특징의 범위 정보를 포함할 수 있다. 바람직하게, 상기 울음소 리 특징은 주파수 대역 특징, 주파수 대역 특징의 배치 관계 특징, 주파수 대역 특징의 주기성 특징, 소리 강도 특징, 소리 강도 특징의 배치 관계 특징, 소리 강도 특징의 주기성 특징, 주파수 대역 특징과 소리 강도 특징의 조합 특징, 주파수 대역 특징과 소리 강도 특징의 배치 관계 특징, 주파수 대역 특징과 소리 강도 특징의 주기 성 특징 중 하나 이상의 특징을 포함할 수 있다. 예를들어, 상기 울음소리 특징의 범위 정보는 각 특징 별 주파 수 대역의 허용 범위 및/또는 각 특징 별 소리 강도의 허용 범위를 포함할 수 있다. 본 발명의 일 실시 방법에 따르면, 상기 울음소리 기반 상관도 수치 관계정보는 아기의 울음소리를 인식한 아기 울음소리 인식 정보와 기 등록된 아기 울음소리 패턴 정보 간 매칭 비율에 비례하는 관계식을 통해 산출되는 상 관도 수치정보를 포함할 수 있다. 예를들어, 상기 울음소리 기반 상관도 수치 관계정보는 아기 울음소리 인식 정보와 기 등록된 아기 울음소리 패턴 정보 간 매칭 비율이 작을수록 작은 수치정보로 산출될 수 있으며, 상기 매칭 비율을 클수록 큰 수치정보로 산출될 수 있다. 한편 본 발명의 다른 일 실시 방법에 따르면, 상기 울음소리 기반 상관도 수치 관계정보는 아기의 울음소리를 인식한 아기 울음소리 인식 정보와 기 등록된 아기 울음소리 패턴 정보 사이의 각 매칭 비율 구간 별 상관도 수 치정보를 포함할 수 있다. 예를들어, 상기 울음소리 기반 상관도 수치 관계정보는 아기 울음소리 인식 정보와 기 등록된 아기 울음소리 패턴 정보 간 매칭 비율이 기 설정된 최소 비율 구간인 경우 '0'이나 지정된 최소값의 수치정보로 산출될 수 있으며, 상기 매칭 비율이 기 설정된 최대 비율 구간인 경우 지정된 최대값의 수치정보로산출될 수 있다. 한편 본 발명의 실시 방법에 따르면, 지정된 운영단말을 통해 상기 운영D/B에 상기 울음소리 기반 감정상태 판 별 정보가 등록 저장된 후, 하기 정보 인식부를 통해 지정된 아기 울음소리 인식 정보가 인식된 경우, 상 기 정보 관리부는 상기 아기 울음소리 인식 정보가 인식된 후에 상기 카메라장치로부터 수신되어 지 정된 저장매체의 특정 저장영역에 저장되는 비디오 데이터를 판독하여 아기의 보호자에 대응하는 객체를 인식함 과 동시에 상기 비디오 데이터와 연계된 오디오 데이터를 판독하여 아기의 보호자가 아기에게 발화하는 음성 중 아기 감정 인지와 관련된 음성(예컨대, '우리 애기 배고프구나', '우리 애기 똥 쌋구나', '우리 애기 졸리구나' 등)을 인식하는 절차를 수행할 수 있다. 만약 아기 울음소리 인식 정보가 인식된 후에 보호자의 아기 감정 인지 와 관련된 음성이 인식된 경우, 상기 정보 관리부는 상기 인식된 아기 울음소리 인식 정보를 패턴화함과 동시에 상기 아기 감정 인지와 관련된 음성에 대응하는 음성 인식 기반의 아기 감정 항목을 식별하고, 상기 인 식된 아기 울음소리 인식 정보를 패턴화한 아기 울음소리 패턴 정보와 상기 식별된 음성 인식 기반의 아기 감정 항목의 조합을 학습하는 과정을 반복함으로써 상기 울음소리 기반 감정상태 판별 정보의 빅데이터 기반 정확도 와 신뢰도를 지속적으로 향상시킬 수 있다. 한편 본 발명의 확장/다른 실시예에 따르면, 상기 정보 관리부는 상기 카메라장치에 구비되거나 연계 된 센서모듈을 통해 센싱된 센싱 데이터 중 아기의 감정 표현과 연관된 지정된 센싱 대상의 센싱 데이터에 대한 S(S≥2)개의 센싱 값 패턴 정보와 지정된 N개의 아기 감정 항목 중 지정된 센싱 대상의 센싱 값 패턴을 근거로 구별 가능한 N3(1≤N3≤N)개의 아기 감정 항목 사이의 매칭 관계정보를 포함하고 상기 S개의 센싱 값 패턴 정보 와 N3개의 아기 감정 항목 간 상관도를 수치화한 센싱 기반 상관도 수치 관계정보를 포함하는 센싱 기반 감정상 태 판별 정보를 운영D/B에 등록 저장할 수 있다. 본 발명의 실시 방법에 따르면, 상기 센서모듈은 아기의 신체에 착용하여 지정된 센싱 대상을 센싱하는 웨어러 블(Wearable) 센서모듈, 지정된 전자파를 이용하여 아기의 지정된 센싱 대상을 센싱하는 레이더(Radar) 센서모 듈 중 적어도 하나의 센서모듈을 포함할 수 있으며, 상기 지정된 센싱 대상은 아기의 심장박동, 아기의 체온, 아기 주변 습도, 아기의 무호흡 여부 중 적어도 하나를 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 정보 관리부는 지정된 운영단말로부터 상기 카메라장치에 구비 되거나 연계된 센서모듈을 통해 센싱된 센싱 데이터 중 아기의 감정 표현과 연관된 지정된 센싱 대상의 센싱 데 이터에 대한 S개의 센싱 값 패턴 정보를 등록받고, 상기 S개의 센싱 값 패턴 정보를 지정된 N개의 아기 감정 항 목 중 지정된 센싱 대상의 센싱 값 패턴을 근거로 구별 가능한 N3개의 아기 감정 항목 사이의 매칭 관계정보를 등록받고, 상기 S개의 센싱 값 패턴 정보와 N3개의 아기 감정 항목 간 상관도를 수치화한 센싱 기반 상관도 수 치 관계정보를 등록받아 지정된 운영D/B에 등록 저장할 수 있다. 예를들어, 상기 정보 관리부는 상기 S개 의 센싱 값 패턴 정보와 N3개의 아기 감정 항목을 행 또는 열의 타이틀로 포함하며 센싱 기반 상관도 수치 관계 정보를 각 행열에 대응하는 셀의 정보로 포함하는 테이블 형태의 센싱 기반 감정상태 판별 정보를 운영D/B에 등 록 저장할 수 있다. 본 발명의 일 실시 방법에 따르면, 상기 S개의 센싱 값 패턴 정보는 아기의 감정표현과 연관된 지정된 센싱 대 상의 센싱 데이터에 대한 각각의 센싱 값 패턴을 구성하는 센싱 값 특징 정보를 포함할 수 있다. 바람직하게, 상기 센싱 값 특징은 센싱 값의 변화 규칙 특징, 센싱 값의 변화량 특징, 센싱 값 변화율 특징, 센싱 값 변화의 주기성 특징 중 적어도 하나 또는 둘 이상의 조합을 포함할 수 있다. 한편 본 발명의 다른 일 실시 방법에 따르면, 상기 S개의 센싱 값 패턴 정보는 아기의 감정표현과 연관된 지정 된 센싱 대상의 센싱 데이터에 대한 각각의 센싱 값 패턴을 구성하는 센싱 값 특징의 범위 정보를 포함할 수 있 다. 바람직하게, 상기 센싱 값 특징은 센싱 값의 변화 규칙 특징, 센싱 값의 변화량 특징, 센싱 값 변화율 특징, 센싱 값 변화의 주기성 특징 중 적어도 하나 또는 둘 이상의 조합을 포함할 수 있다. 예를들어, 상기 센싱 값 특징의 범위 정보는 각 특징 별 변화 규칙의 허용 범위, 각 특징 별 센싱 값 변화량의 허용 범위, 각 특 징 별 센싱 값 변화율의 허용 범위를 포함할 수 있다. 본 발명의 일 실시 방법에 따르면, 상기 센싱 기반 상관도 수치 관계정보는 지정된 센싱 대상의 센싱 데이터를 통해 인식된 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 간 매칭 비율에 비례하는 관계식을 통해 산출되 는 상관도 수치정보를 포함할 수 있다. 예를들어, 상기 센싱 기반 상관도 수치 관계정보는 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 간 매칭 비율이 작을수록 작은 수치정보로 산출될 수 있으며, 상기 매칭 비율을 클수록 큰 수치정보로 산출될 수 있다. 한편 본 발명의 다른 일 실시 방법에 따르면, 상기 센싱 기반 상관도 수치 관계정보는 지정된 센싱 대상의 센싱 데이터를 통해 인식된 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 사이의 각 매칭 비율 구간 별 상관도 수치정보를 포함할 수 있다. 예를들어, 상기 센싱 기반 상관도 수치 관계정보는 센싱 값 인식 정보와 기 등록된 센싱 값 패턴 정보 간 매칭 비율이 기 설정된 최소 비율 구간인 경우 '0'이나 지정된 최소값의 수치정보로 산출 될 수 있으며, 상기 매칭 비율이 기 설정된 최대 비율 구간인 경우 지정된 최대값의 수치정보로 산출될 수 있다. 한편 본 발명의 실시 방법에 따르면, 지정된 운영단말을 통해 상기 운영D/B에 상기 센싱 기반 감정상태 판별 정 보가 등록 저장된 후, 하기 정보 인식부를 통해 지정된 센싱 값 인식 정보가 인식된 경우, 상기 정보 관리 부는 상기 센싱 값 인식 정보가 인식된 후에 상기 카메라장치로부터 수신되어 지정된 저장매체의 특 정 저장영역에 저장되는 비디오 데이터를 판독하여 아기의 보호자에 대응하는 객체를 인식함과 동시에 상기 비 디오 데이터와 연계된 오디오 데이터를 판독하여 아기의 보호자가 아기에게 발화하는 음성 중 아기 감정 인지와 관련된 음성(예컨대, '우리 애기 배고프구나', '우리 애기 똥 쌋구나', '우리 애기 졸리구나' 등)을 인식하는 절차를 수행할 수 있다. 만약 센싱 값 인식 정보가 인식된 후에 보호자의 아기 감정 인지와 관련된 음성이 인식 된 경우, 상기 정보 관리부는 상기 인식된 센싱 값 인식 정보를 패턴화함과 동시에 상기 아기 감정 인지와 관련된 음성에 대응하는 음성 인식 기반의 아기 감정 항목을 식별하고, 상기 인식된 센싱 값 인식 정보를 패턴 화한 아기 울음소리 패턴 정보와 상기 식별된 음성 인식 기반의 아기 감정 항목의 조합을 학습하는 과정을 반복 함으로써 상기 센싱 기반 감정상태 판별 정보의 빅데이터 기반 정확도와 신뢰도를 지속적으로 향상시킬 수 있다. 도면1을 참조하면, 상기 운영서버는, 지정된 거점에 구비된 카메라장치를 통해 상기 거점 내의 특정 아기를 촬영한 비디오 데이터를 포함하는 송신 데이터를 제공받을 대상과 상기 카메라장치를 매핑하는 정 보를 등록받아 지정된 관리D/B에 저장하는 정보 등록부를 포함한다. 상기 카메라장치를 구매하거나 공급받는 사용자가 이용하는 사용자단말을 통해 가입신청정보를 입력하거나 종이 형태의 가입신청서(예컨대, 카메라장치를 이용한 서비스와 IPTV를 결합하는 신청서, 카메라장치 를 이용한 서비스와 사용자 무선단말을 결합하는 신청서 등)를 작성한 경우, 상기 정보 등록부 는 사용자 단말이나 지정된 등록단말을 통해 상기 가입신청정보나 가입신청서에 대응하는 사용자정보와 상기 사 용자에게 제공/공급된 카메라장치를 고유 식별하는 카메라장치정보를 등록받아 관리D/B에 저장할 수 있다. 한편 상기 정보 등록부는 상기 사용자 단말이나 지정된 등록단말을 통해 상기 카메라장치를 통 해 촬영된 비디오 데이터를 포함하는 송신 데이터를 사용자가 이용하는 IPTV로 제공하기 위한 ID/PW정보를 등록받고 상기 사용자정보 및/또는 카메라장치정보와 연계하여 관리D/B에 저장할 수 있다. 한편 본 발명의 실시 방법에 따라 상기 ID/PW정보는 상기 카메라장치를 통해 촬영된 비디오 데이터를 포함하는 송신 데이 터를 웹을 통해 사용자가 이용하는 유선단말이나 무선단말로 제공하기 위해 사용될 수 있으며, 본 발명은 이러한 실시예도 권리범위로 포함할 수 있다. 한편 상기 사용자가 본인이 사용하는 사용자 무선단말에 지정된 앱을 설치하고 최초(또는 가입 전) 구동 시, 상기 정보 등록부는 상기 사용자 무선단말의 앱으로부터 상기 사용자에 대한 사용자정보와 상기 사용자에게 제공/공급된 카메라장치를 고유 식별하는 카메라장치정보를 등록받아 관리D/B에 저장할 수 있다. 한편 상기 정보 등록부는 상기 카메라장치를 통해 촬영된 비디오 데이터를 포함하는 송신 데이터를 상기 사용자 무선단말의 앱으로 제공하기 위해 상기 사용자 무선단말의 앱을 고유 식별하는 고유식별정보를 생성하거나 상기 사용자 무선단말의 앱으로부터 제공받고 상기 사용자정보 및/또는 카메라 장치정보와 연계하여 관리D/B에 저장할 수 있으며, 상기 고유식별정보를 생성한 경우 상기 사용자 무선단 말의 앱으로 제공하여 지정된 저장영역에 저장하도록 처리할 수 있다. 한편 상기 정보 등록부는 상기 사용자 무선단말의 앱으로부터 상기 카메라장치를 통해 촬영된 비디오 데이터를 포함하는 송신 데이 터를 사용자가 이용하는 IPTV로 제공하기 위한 ID/PW정보를 등록받고 상기 사용자정보 및/또는 카메라장치 정보와 연계하여 관리D/B에 저장할 수 있다. 한편 본 발명의 실시 방법에 따라 상기 ID/PW정보는 상기 카 메라장치를 통해 촬영된 비디오 데이터를 포함하는 송신 데이터를 웹을 통해 사용자가 이용하는 유선단말 이나 무선단말로 제공하기 위해 사용될 수 있으며, 본 발명은 이러한 실시예도 권리범위로 포함할 수 있다. 한편 본 발명의 실시 방법에 따르면, 상기 사용자 무선단말의 앱은 상기 카메라장치를 통해 촬영된 비디오 데이터를 포함하는 송신 데이터를 제공받을 다른 무선단말의 고유정보(예컨대, 휴대폰번호 등)를 입력/등록할 수 있으며, 이 경우 상기 정보 등록부는 상기 다른 무선단말의 고유정보를 관리D/B에 저 장하고, 상기 다른 무선단말의 고유정보를 통해 상기 다른 무선단말에 지정된 앱이 설치되도록 유도 하거나 및/또는 상기 다른 무선단말에 설치 실행된 앱을 확인하고, 상기 다른 무선단말의 앱을 고유 식별하는 고유식별정보를 생성하거나 상기 다른 무선단말의 앱으로부터 제공받고 상기 등록되어 있는 카메 라장치정보와 연계하여 관리D/B에 저장함으로써, 상기 사용자 무선단말의 앱 이외에 상기 사용자 무 선단말의 앱을 통해 지저된 다른 무선단말의 앱을 통해서도 상기 카메라장치를 통해 촬영된 비 디오 데이터를 포함하는 송신 데이터를 제공받을 수 있도록 처리할 수 있다. 도면1을 참조하면, 상기 운영서버는, 지정된 거점에 구비된 카메라장치와의 통신 연결을 관리하는 통 신 관리부와, 상기 카메라장치의 카메라모듈을 통해 획득되어 지정된 방식으로 엔코딩된 비디오 데이 터를 포함하는 획득 데이터를 수신하는 데이터 수신부와, 상기 수신된 획득 데이터를 지정된 저장매체의 특정 저장영역에 저장하여 관리하는 데이터 저장부를 포함한다. 지정된 거점에 구비된 카메라장치에 전원이 입력되면, 상기 카메라장치의 제어모듈은 지정된 절차에 따라 통신모듈을 통해 지정된 운영서버와 지정된 하나 이상의 정보를 교환하여 통신 연결을 요청하며, 상 기 통신 관리부는 상기 지정된 정보의 교환을 근거로 상기 카메라장치의 유효성을 인증하여 상기 카 메라장치와 통신을 연결한다. 상기 카메라장치와 통신이 연결되면, 상기 통신 관리부는 상기 카메라장치를 통해 획득된 획득 데이터를 수신하기 위한 일회용주소정보를 동적 생성하여 상기 카메라장치로 제공하며, 이 경우 상기 카메 라장치의 제어모듈은 상기 일회용주소정보를 수신하고, 상기 일회용주소정보를 상기 획득 데이터를 전송할 목적지 주소로 설정한 후, 상기 획득된 획득 데이터를 상기 일회용주소에 대응하는 목적지 주소로 전송할 수 있 다. 여기서, 상기 일회용주소정보는 주소도메인정보는 동일하되 도메인 이후의 파라미터값이 중복되지 않게 동 적 생성된 파라미터값으로 이루어진 주소정보를 포함할 수 있다. 본 발명의 실시 방법에 따르면, 상기 통신 관리부는 주기적으로 상기 카메라장치에 대한 신규 일회용 주소정보를 동적 생성하여 상기 카메라장치로 제공할 수 있으며, 이 경우 상기 카메라장치의 제어모 듈은 상기 신규 일회용주소정보를 수신하고, 이전 일회용주소에 대응하는 목적지 주소로 상기 획득 데이터를 전 송하는 과정을 인터럽트함과 동시에 이전 일회용주소로 획득 데이터를 전송한 이전 전송 정보를 확인하고, 상기 신규 일회용주소정보를 상기 획득 데이터를 이어서 전송할 신규 목적지 주소로 설정한 후, 상기 이전 전송 정보 를 근거로 이전 일회용주소로 전송하던 획득 데이터를 상기 신규 일회용주소에 대응하는 신규 목적지 주소로 이어서 전송할 수 있으며, 상기의 과정은 주기적으로 반복될 수 있다. 이하, 별도의 언급이 없더라도 상기 카메라 장치는 상기 일회용주소로 획득 데이터를 전송할 수 있음을 명기하는 바이다. 한편 본 발명의 다른 실시 방법에 따르면, 상기 통신 관리부의 일회용주소정보 생성 내지 적용 과정은 생략 가능하며, 이에 의해 본 발명이 한정되지 아니한다. 본 발명의 실시 방법에 따라 상기 카메라장치의 제어모듈이 상기 카메라모듈을 통해 획득되어 지정된 방식 으로 엔코딩된 비디오 데이터를 포함하는 획득 데이터를 전송하면, 상기 데이터 수신부는 상기 카메라모듈 을 통해 획득되어 지정된 방식으로 엔코딩된 비디오 데이터를 포함하는 획득 데이터를 수신하고, 상기 데이터 저장부는 지정된 저장매체의 특정 저장영역에 상기 수신된 획득 데이터의 비디오 데이터를 저장하여 일정 기간 동안 관리할 수 있다. 한편 본 발명의 실시 방법에 따라 상기 카메라장치의 제어모듈이 상기 카메라모듈을 통해 획득되어 지정된 방식으로 엔코딩된 비디오 데이터와 상기 사운드 입력부를 통해 획득되어 지정된 방식으로 엔코딩된 오디오 데 이터를 포함하는 획득 데이터를 전송하면, 상기 데이터 수신부는 상기 카메라모듈을 통해 획득되어 지정된 방식으로 엔코딩된 비디오 데이터와 상기 사운드 입력부를 통해 획득되어 지정된 방식으로 엔코딩된 오디오 데 이터를 포함하는 획득 데이터를 수신하고, 상기 데이터 저장부는 지정된 저장매체의 특정 저장영역에 상기 수신된 획득 데이터의 비디오 데이터와 오디오 데이터를 연계 저장하여 일정 기간 동안 관리한다. 본 발명의 실시 방법에 따르면, 상기 카메라장치의 제어모듈은 상기 비디오 데이터와 오디오 데이터를 포 함하는 동영상 데이터 형태의 획득 데이터를 전송할 수 있으며, 이 경우 상기 데이터 수신부는 상기 카메 라장치로부터 상기 동영상 데이터 형태의 획득 데이터를 수신하고, 상기 데이터 저장부는 지정된 저 장매체의 특정 저장영역에 상기 수신된 동영상 데이터를 저장하여 관리할 수 있다. 한편 본 발명의 실시 방법에 따르면, 상기 카메라장치의 제어모듈은 상기 비디오 데이터와 상기 오디오 데 이터를 각각의 데이터 형태로 포함하는 획득 데이터를 전송할 수 있으며, 이 경우 상기 데이터 수신부는 상기 카메라장치로부터 상기 비디오 데이터와 오디오 데이터를 제각기 포함하는 획득 데이터를 수신하고, 상기 데이터 저장부는 상기 카메라장치로부터 각기 수신된 상기 비디오 데이터와 오디오 데이터를 연 계하여 지정된 저장매체의 특정 저장영역에 저장하여 관리할 수 있다. 바람직하게, 상기 데이터 저장부는 상기 비디오 데이터와 오디오 데이터의 시간 값(또는 타임스탬프)를 기준으로 상기 비디오 데이터와 오디오 데 이터의 시간을 동기화시켜 지정된 저장매체의 특정 저장영역에 저장할 수 있다. 한편 본 발명의 실시 방법에 따라 상기 카메라장치의 제어모듈이 상기 카메라모듈을 통해 획득되어 지정된 방식으로 엔코딩된 비디오 데이터 및/또는 상기 사운드 입력부를 통해 획득되어 지정된 방식으로 엔코딩된 오디 오 데이터 외에, 지정된 센서모듈을 통해 센싱되어 지정된 방식으로 엔코딩된 센싱 데이터를 더 포함하는 획득 데이터를 전송하면, 상기 데이터 수신부는 상기 센싱 데이터를 포함하는 획득 데이터를 수신하고, 상기 데 이터 저장부는 지정된 저장매체의 특정 저장영역에 상기 수신된 획득 데이터의 비디오 데이터 및/또는 오 디오 데이터와 상기 센싱 데이터를 연계 저장하여 일정 기간 동안 관리할 수 있다. 바람직하게, 상기 데이터 저 장부는 상기 비디오 데이터 및/또는 오디오 데이터의 시간 값(또는 타임스탬프)과 상기 센싱 데이터의 시 간 값(또는 타임스탬프)을 기준으로 상기 비디오 데이터 및/또는 오디오 데이터의 시간과 상기 센싱 데이터의 시간을 동기화시켜 지정된 저장매체의 특정 저장영역에 저장할 수 있다. 본 발명의 제1 아기 감정 상태 생성 실시예에 따르면, 상기 운영서버는 지정된 사용자 무선단말의 앱 이나 IPTV로 상기 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 제공하는 시점에 상기 송신 데이터에 포함되는 비디오 데이터 및/또는 상기 비디오 데이터와 연계된 데이터(예컨대, 오디 오 데이터 및/또는 센싱 데이터 등)를 근거로 지정된 절차에 따라 각 감정 항목 별 아기 감정 상태 정보를 생성 하여 상기 사용자 무선단말의 앱이나 IPTV로 제공되는 송신 데이터의 비디오 데이터 상의 지정된 일정 영역에 실시간 표시되도록 처리할 수 있다. 한편 본 발명의 제2 아기 감정 상태 생성 실시예에 따르면, 상기 운영서버는 지정된 저장매체의 특정 저장 영역에 상기 카메라장치로부터 수신된 획득 데이터가 저장된 후, 상기 저장매체의 특정 저장영역에 저장된 획득 데이터를 근거로 지정된 절차에 따라 각 감정 항목 별 아기 감정 상태 정보를 생성하여 상기 획득 데이터 와 연계 저장하도록 처리할 수 있으며, 이 경우 상기 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함 하는 지정된 사용자 무선단말의 앱이나 IPTV로 제공 시 상기 송신 데이터의 비디오 데이터와 연계된 각 감정 항목 별 아기 감정 상태 정보가 상기 송신 데이터의 비디오 데이터 상의 지정된 일정 영역에 표시되도 록 처리할 수 있다. 도면1을 참조하면, 상기 운영서버는, 인공지능 기반의 감정상태 판별 정보를 통해 아기의 지정된 감정 항 목 별 아기 감정 상태 값을 판별하는 경우, 상기 인공지능 기반의 감정상태 판별 정보를 통해 상기 카메라장치 를 통해 획득되는 비디오 데이터 및/또는 오디오 데이터를 판독하는 절차를 수행하여 지정된 감정 항목 별 아기 감정 상태 값을 판별하는 감정 상태 판별부와, 상기 산출된 하나 이상의 아기 감정 상태 값을 이용하 여 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하는 정보 생성부를 포함한다. 상기 정보 관리부를 통해 인공지능 기반의 표정 기반 감정상태 판별 정보를 생성하여 저장 관리하는 경우, 상기 감정 상태 판별부는 상기 인공지능 기반의 표정 기반 감정상태 판별 정보를 통해 지정된 비디오 데이 터를 판독하는 절차를 수행하여 지정된 N(N≥2)개의 아기 감정 항목 중 아기 표정을 통해 구별 가능한 N1(1≤N1 ≤N)개의 아기 감정 항목을 근거로 상기 비디오 데이터의 아기 표정에 대응하는 n1(1≤n1≤N1)개의 감정 항목 별 아기 감정 상태 값을 판별한다. 본 발명의 실시 방법에 따르면, 상기 감정 상태 판별부는 상기 인공지능 기반의 표정 기반 감정상태 판별 정보에 대응하는 인공지능 알고리즘을 통해 지정된 비디오 데이터를 판독하는 절차를 수행하여 지정된 E개의 아 기 표정 중 상기 비디오 데이터 상의 아기 안면 영역에 대응하는 e개의 아기 표정을 판별하고, 아기 표정을 통 해 구별 가능한 N1개의 아기 감정 항목 중 상기 판별된 e개의 아기 표정과 매칭 관계를 지닌 n1개의 아기 감정 항목을 판별하고, 상기 확인된 e개의 아기 표정과 n1개의 아기 감정 항목 간 상관도에 대응하는 n1개의 감정 항 목 별 아기 감정 상태 값을 판별할 수 있다. 상기 정보 생성부는 상기 판별된 n1개의 감정 항목 별 아기 감정 상태 값을 이용하여 비디오 데이터 상에 표시 가능한 지정된 n(1≤n≤N)개의 감정 항목 별 아기 감정 상태 정보를 생성한다. 한편 본 발명의 제2 아기 감정 상태 생성 실시예에 따라 상기 저장매체의 특정 저장영역에 상기 획득 데이터가 저장된 후 상기 n개의 감 정 항목 별 아기 감정 상태 정보가 생성된 경우, 상기 정보 생성부는 상기 생성된 n개의 감정 항목 별 아 기 감정 상태 정보를 상기 비디오 데이터와 연계하여 상기 저장매체의 특정 저장영역에 저장할 수 있다. 도면1을 참조하면, 상기 운영서버는, 패턴 인식 기반의 감정상태 판별 정보를 통해 아기의 지정된 감정 항 목 별 아기 감정 상태 값을 판별하는 경우, 지정된 거점의 카메라장치를 통해 획득된 획득 데이터 중 적어 도 하나의 데이터를 판독하여 아기의 감정을 판별하기 위한 지정된 인식 대상의 인식 정보를 인식하는 정보 인 식부와, 지정된 감정상태 판별 정보를 근거로 상기 인식된 인식 정보와 기 설정된 기준 유사도 이상 매칭 된 지정된 인식 대상의 패턴 정보를 확인하고 상기 확인된 패턴 정보와 매칭 관계를 지닌 하나 이상의 아기 감 정 항목을 판별하는 정보 판별부와, 상기 인식 정보와 패턴 정보 간 매칭 비율을 근거로 상기 패턴 정보와 아기 감정 항목 간 상관도 수치 관계를 판독하여 상기 인식 정보에 대응하는 하나 이상의 감정 항목 별 아기 감 정 상태를 수치화한 감정 항목 별 아기 감정 상태 값을 판별하는 감정 상태 판별부와, 상기 산출된 하나 이상의 아기 감정 상태 값을 이용하여 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하는 정보 생성부 를 포함한다. 상기 정보 인식부는 지정된 비디오 데이터를 판독하여 상기 거점 내의 특정 아기의 안면 영역에 대한 f(1 ≤f≤F)개의 특징점을 인식하면서 상기 인식된 f개의 특징점 중 아기의 감정 표현과 연관된 특징점 간 기하학 관계에 대응하는 i(i≥1)개의 아기 표정 인식 정보를 인식한다. 본 발명의 실시 방법에 따르면, 상기 지정된 비디오 데이터는 지정된 재생 시간 단위 별로 주기적으로 선별되는 비디오 데이터, 지정된 재생 프레임 수 별로 주기적으로 선별되는 비디오 데이터 중 적어도 하나의 비디오 데이 터를 포함할 수 있다. 본 발명의 제1 아기 감정 상태 생성 실시예의 경우, 상기 정보 인식부는 상기 관리D/B에 저장된 고유식별 정보에 대응하는 사용자 무선단말의 앱이나 상기 관리D/B에 저장된 ID/PW정보를 통해 식별/인증된 IPTV로 상기 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 제공하는지 확 인한다. 만약 상기 사용자 무선단말의 앱이나 IPTV로 상기 송신 데이터를 제공하는 경우, 상기 정보 인식부는 상기 송신 데이터의 비디오 데이터 중 지정된 비디오 데이터를 판독하여 상기 거점 내의 특정 아 기의 안면 영역에 대한 f개의 특징점을 인식하면서 상기 인식된 f개의 특징점 중 아기의 감정 표현과 연관된 특 징점 간 기하학 관계에 대응하는 i개의 아기 표정 인식 정보를 인식할 수 있다. 한편 본 발명의 제2 아기 감정 상태 생성 실시예의 경우, 상기 정보 인식부는 상기 카메라장치로부터 수신된 획득 데이터가 상기 저장매체의 특정 저장영역에 저장된 후 상기 저장매체의 특정 저장영역에 저장된 비 디오 데이터 중 지정된 비디오 데이터를 판독하여 상기 거점 내의 특정 아기의 안면 영역에 대한 f개의 특징점 을 인식하면서 상기 인식된 f개의 특징점 중 아기의 감정 표현과 연관된 특징점 간 기하학 관계에 대응하는 i개 의 아기 표정 인식 정보를 인식할 수 있다. 상기 정보 인식부를 통해 i개의 아기 표정 인식 정보가 인식되면, 상기 정보 판별부는 상기 운영D/B 에 저장된 표정 기반 감정상태 판별 정보를 근거로 상기 인식된 i개의 아기 표정 인식 정보와 기 설정된 기준 유사도 이상 매칭된 e(1≤e≤E)개의 아기 표정 패턴 정보를 확인한다. 만약 상기 인식된 i개의 아기 표정 인식 정보와 기 설정된 기준 유사도 이상 매칭된 e개의 아기 표정 패턴 정보가 확인되면, 상기 정보 판별부는 상기 확인된 e개의 아기 표정 패턴 정보와 매칭 관계를 지닌 n1(1≤n1≤N1)개의 아기 감정 항목을 판별한다. 상기 정보 판별부를 통해 i개의 아기 표정 인식 정보에 대응하는 n1개의 아기 감정 항목이 판별되면, 상기 감정 상태 판별부는 상기 인식된 i개의 아기 표정 인식 정보와 상기 e개의 아기 표정 패턴 정보 간 매칭 비율을 근거로 상기 e개의 아기 표정 패턴 정보와 n1개의 아기 감정 항목 간 상관도 수치 관계를 판독하여 상기 인식된 i개의 아기 표정 인식 정보에 대응하는 n1개의 감정 항목 별 아기 감정 상태를 수치화한 n1개의 감정 항 목 별 아기 감정 상태 값을 판별하고, 상기 정보 생성부는 상기 판별된 n1개의 감정 항목 별 아기 감정 상 태 값을 이용하여 비디오 데이터 상에 표시 가능한 지정된 n(1≤n≤N)개의 감정 항목 별 아기 감정 상태 정보를 생성한다. 한편 본 발명의 제2 아기 감정 상태 생성 실시예에 따라 상기 저장매체의 특정 저장영역에 상기 획득 데이터가 저장된 후 상기 n개의 감정 항목 별 아기 감정 상태 정보가 생성된 경우, 상기 정보 생성부는 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 상기 비디오 데이터와 연계하여 상기 저장매체의 특정 저장영역에 저장할 수 있다. 한편 상기 정보 관리부를 통해 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 생성하여 저장 관리 하는 경우, 상기 감정 상태 판별부는 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 통해 지정된 오디오 데이터를 판독하는 절차를 수행하여 지정된 N(N≥2)개의 아기 감정 항목 중 아기 울음소리를 통해 구별 가능한 N2(1≤N2≤N)개의 아기 감정 항목을 근거로 상기 오디오 데이터의 아기 울음소리에 대응하는 n2(1 ≤n2≤N2)개의 감정 항목 별 아기 감정 상태 값을 판별할 수 있다. 본 발명의 실시 방법에 따르면, 상기 감정 상태 판별부는 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보에 대응하는 인공지능 알고리즘을 통해 지정된 오디오 데이터를 판독하는 절차를 수행하여 지정된 C개 의 아기 울음소리 중 상기 오디오 데이터 상의 아기 울음에 대응하는 c개의 아기 울음소리를 판별하고, 아기 울 음소리를 통해 구별 가능한 N2개의 아기 감정 항목 중 상기 판별된 c개의 아기 울음소리와 매칭 관계를 지닌 n2 개의 아기 감정 항목을 판별하고, 상기 확인된 c개의 아기 울음소리와 n2개의 아기 감정 항목 간 상관도에 대응 하는 n2개의 감정 항목 별 아기 감정 상태 값을 판별할 수 있다. 한편 상기 정보 관리부를 통해 상기 운영D/B에 패턴 인식 기반의 울음소리 기반 감정상태 판별 정보가 저 장된 경우, 상기 정보 인식부는 상기 비디오 데이터와 연계된 일정 일정 구간의 오디오 데이터를 판독하여 상기 특정 아기에 대한 j(j≥1)개의 아기 울음소리 인식 정보를 인식할 수 있다. 상기 정보 인식부를 통해 j개의 아기 울음소리 인식 정보가 인식되면, 상기 정보 판별부는 상기 운영 D/B에 저장된 울음소리 기반 감정상태 판별 정보를 근거로 상기 인식된 j개의 아기 울음소리 인식 정보와 기 설 정된 기준 유사도 이상 매칭된 c(1≤c≤C)개의 아기 울음소리 패턴 정보를 확인한다. 만약 상기 인식된 j개의 아기 울음소리 인식 정보와 기 설정된 기준 유사도 이상 매칭된 c개의 아기 울음소리 패턴 정보가 확인되면, 상 기 정보 판별부는 상기 확인된 c개의 아기 울음소리 패턴 정보와 매칭 관계를 지닌 n2(1≤n2≤N2)개의 아 기 감정 항목을 판별한다. 상기 정보 판별부를 통해 j개의 아기 울음소리 인식 정보에 대응하는 n2개의 아기 감정 항목이 판별되면, 상기 감정 상태 판별부는 상기 인식된 j개의 아기 울음소리 인식 정보와 상기 c개의 아기 울음소리 패턴 정보 간 매칭 비율을 근거로 상기 c개의 아기 울음소리 패턴 정보와 n2개의 아기 감정 항목 간 상관도 수치 관 계를 판독하여 상기 인식된 j개의 아기 울음소리 인식 정보에 대응하는 n2개의 감정 항목 별 아기 감정 상태를 수치화한 n2개의 감정 항목 별 아기 감정 상태 값을 판별하고, 상기 정보 생성부는 상기 판별된 n2개의 감 정 항목 별 아기 감정 상태 값을 (추가)이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 본 발명의 실시 방법에 따르면, 상기 n1개의 감정 항목 별 아기 감정 상태 값이 기 산출된 경우, 상기 정보 생 성부는 상기 산출된 n1개의 감정 항목 별 아기 감정 상태 값과 상기 산출된 n2개의 감정 항목 별 아기 감 정 상태 값을 조합하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 바람직하게, 상기 n 개의 감정 항목 별 아기 감정 상태 정보는 'n1개의 감정 항목 별 아기 감정 상태 값 ∩ n2개의 감정 항목 별 아 기 감정 상태 값'의 합집합 관계이거나, 또는 상기 합집합의 부분집합 관계일 수 있다. 한편 상기 n1개의 감정 항목 별 아기 감정 상태 값과 n2개의 감정 항목 별 아기 감정 상태 값을 조합하여 n개의 감정 항목 별 아기 감정 상태 정보를 생성 시, 상기 정보 생성부는 상기 n1개의 감정 항목과 n2개의 감정 항목 중 중복되는 감정 항목에 대하여 각 아기 감정 상태 값에 대한 지정된 통계 연산(예컨대, 평균 값 산출 연 산)이나 해당 감정 항목과 표정 또는 울음소리 사이의 상관 관계에 따라 지정된 인식 대상에 지정된 가중치를 부여한 통계 연산을 통해 상기 중복되는 감정 항목의 아기 감정 상태 정보를 생성할 수 있다. 한편 상기 정보 관리부를 통해 상기 운영D/B에 상기 센싱 기반 감정상태 판별 정보가 저장되고, 상기 저장 매체의 특정 저장영역에 비디오 데이터 및/또는 오디오 데이터와 상기 카메라장치에 구비되거나 연계된 센 서모듈을 통해 센싱된 센싱 데이터가 연계 저장된 경우, 상기 정보 인식부는 상기 비디오 데이터 맟/또는오디오 데이터와 연계된 센싱 데이터를 판독하여 상기 특정 아기의 감정 표현과 연관된 지정된 센싱 대상의 센 싱 데이터에 대한 k(k≥1)개의 센싱 값 인식 정보를 인식할 수 있다. 한편 상기 정보 인식부를 통해 k개의 센싱 값 인식 정보가 인식되면, 상기 정보 판별부는 상기 운영 D/B에 저장된 센싱 기반 감정상태 판별 정보를 근거로 상기 인식된 k개의 센싱 값 인식 정보와 기 설정된 기준 유사도 이상 매칭된 s(1≤s≤S)개의 센싱 값 패턴 정보를 확인한다. 만약 상기 인식된 k개의 센싱 값 인식 정보 와 기 설정된 기준 유사도 이상 매칭된 s개의 센싱 값 패턴 정보가 화긴되면, 상기 정보 판별부는 상기 확 인된 s개의 센싱 값 패턴 정보와 매칭 관계를 지닌 n3(1≤n3≤N3)개의 아기 감정 항목을 판별한다. 상기 정보 판별부를 통해 k개의 센싱 값 인식 정보에 대응하는 n3개의 아기 감정 항목이 판별되면, 상기 감정 상태 판별부는 상기 인식된 k개의 센싱 값 인식 정보와 상기 s개의 센싱 값 패턴 정보 간 매칭 비율 을 근거로 상기 s개의 센싱 값 패턴 정보와 n3개의 아기 감정 항목 간 상관도 수치 관계를 판독하여 상기 인식 된 k개의 센싱 값 인식 정보에 대응하는 n3개의 감정 항목 별 아기 감정 상태를 수치화한 n3개의 감정 항목 별 아기 감정 상태 값을 판별하고, 상기 정보 생성부는 상기 판별된 n3개의 감정 항목 별 아기 감정 상태 값 을 (추가)이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 본 발명의 실시 방법에 따르면, 상기 n1개의 감정 항목 별 아기 감정 상태 값이 기 산출된 경우, 상기 정보 생 성부는 상기 산출된 n1개의 감정 항목 별 아기 감정 상태 값과 상기 k개의 센싱 값 인식 정보를 근거로 산 출된 n3개의 감정 항목 별 아기 감정 상태 값을 조합하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생 성할 수 있다. 바람직하게, 상기 n개의 감정 항목 별 아기 감정 상태 정보는 'n1개의 감정 항목 별 아기 감정 상태 값 ∩ n3개의 감정 항목 별 아기 감정 상태 값'의 합집합 관계이거나, 또는 상기 합집합의 부분집합 관계 일 수 있다. 한편 상기 n1개의 감정 항목 별 아기 감정 상태 값과 n3개의 감정 항목 별 아기 감정 상태 값을 조합하여 n개의 감정 항목 별 아기 감정 상태 정보를 생성 시, 상기 정보 생성부는 상기 n1개의 감정 항목과 n3개의 감정 항목 중 중복되는 감정 항목에 대하여 각 아기 감정 상태 값에 대한 지정된 통계 연산(예컨대, 평균 값 산출 연 산)이나 해당 감정 항목과 표정 또는 지정된 센싱 대상의 센싱 값 사이의 상관 관계에 따라 지정된 인식 대상에 지정된 가중치를 부여한 통계 연산을 통해 상기 중복되는 감정 항목의 아기 감정 상태 정보를 생성할 수 있다. 한편 본 발명의 실시 방법에 따르면, 상기 n1개의 감정 항목 별 아기 감정 상태 값과 상기 j개의 아기 울음소리 인식 정보를 n2개의 감정 항목 별 아기 감정 상태 값이 기 산출된 경우, 상기 정보 생성부는 상기 산출된 n1개의 감정 항목 별 아기 감정 상태 값과 상기 산출된 n2개의 감정 항목 별 아기 감정 상태 값 및 상기 k개의 센싱 값 인식 정보를 근거로 산출된 n3개의 감정 항목 별 아기 감정 상태 값을 조합하여 지정된 n개의 감정 항 목 별 아기 감정 상태 정보를 생성할 수 있다. 바람직하게, 상기 n개의 감정 항목 별 아기 감정 상태 정보는 'n1개의 감정 항목 별 아기 감정 상태 값 ∩ n2개의 감정 항목 별 아기 감정 상태 값 ∩ n3개의 감정 항목 별 아기 감정 상태 값'의 합집합 관계이거나, 또는 상기 합집합의 부분집합 관계일 수 있다. 한편 상기 n1개의 감정 항목 별 아기 감정 상태 값과 n2개의 감정 항목 별 아기 감정 상태 값 및 n3개의 감정 항목 별 아기 감정 상태 값 등을 조합하여 n개의 감정 항목 별 아기 감정 상태 정보를 생성 시, 상기 정보 생성 부는 상기 n1개의 감정 항목과 n2개의 감정 항목 및 n3개의 감정 항목 중 중복되는 감정 항목에 대하여 각 아기 감정 상태 값에 대한 지정된 통계 연산(예컨대, 평균 값 산출 연산)이나 해당 감정 항목과 표정 또는 울음 소리 또는 지정된 센싱 대상의 센싱 값 사이의 상관 관계에 따라 지정된 인식 대상에 지정된 가중치를 부여한 통계 연산을 통해 상기 중복되는 감정 항목의 아기 감정 상태 정보를 생성할 수 있다. 도면1을 참조하면, 상기 운영서버는, 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 n개의 감정 항 목 별 아기 감정 상태 정보를 표시하는 정보 적용부와, 상기 비디오 데이터를 포함하는 송신 데이터를 사 용자 무선단말의 앱이나 IPTV로 제공하는 데이터 제공부를 포함한다. 상기 정보 생성부를 통해 생성되는 n개의 감정 항목 별 아기 감정 상태 정보는 n개의 감정 항목 정보와 각 감정 항목 별 아기 감정 상태의 수치정보를 문자 형태로 포함하는 문자 형태의 감정 항목 별 아기 감정 상태 정 보를 포함할 수 있다. 또는 상기 정보 생성부를 통해 생성되는 n개의 감정 항목 별 아기 감정 상태 정보는 n개의 감정 항목 정보와 각 감정 항목 별 아기 감정 상태의 수치정보를 그래프 형태로 포함하는 그래프 형태의 감정 항목 별 아기 감정 상태 정보를 포함할 수 있다. 상기 정보 적용부는 지정된 사용자 무선단말의 앱이나 IPTV로 제공될 송신 데이터의 비디오 데 이터 상의 지정된 일정 영역에 상기 정보 생성부를 통해 생성된 n개의 감정 항목 별 아기 감정 상태 정보 (예컨대, 문자 형태의 감정 항목 별 아기 감정 상태 정보, 또는 그래프 형태의 감정 항목 별 아기 감정 상태 정 보 등)를 표시할 수 있다. 상기 데이터 제공부는 상기 n개의 감정 항목 별 아기 감정 상태 정보를 지정된 영역에 표시한 비디오 데이 터를 포함하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공하며, 상기 사용자 무선 단말의 앱이나 IPTV는 상기 송신 데이터를 수신하여 출력할 수 있다. 바람직하게, 상기 송신 데이터 는 상기 n개의 감정 항목 별 아기 감정 상태 정보를 지정된 영역에 표시한 비디오 데이터 외에 오디오 데이터를 더 포함할 수 있으며, 이에 의해 본 발명이 한정되지 아니한다. 도면2는 본 발명의 실시 방법에 따른 정보 저장/등록 과정을 도시한 도면이다. 보다 상세하게 본 도면2는 지정된 각 감정 항목 별 아기 감정 상태 정보를 생성하기 위한 지정된 인식 대상(예 컨대, 아기 표정, 아기 울음소리, 지저된 센서모듈을 통해 아깅의 지정된 센싱 대사을 센싱한 센싱 값 등) 별 감정상태 판별 정보를 저장하거나, 지정된 거점에 구비된 카메라장치를 통해 상기 거점 내의 특정 아기를 촬영한 비디오 데이터를 포함하는 송신 데이터를 제공받을 대상과 상기 카메라장치를 매핑하는 정보를 등"}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "록받아 지정된 관리D/B에 저장하는 과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면2를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거 나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함 하여 이루어지며, 본 도면2에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면2를 참조하면, 상기 운영서버는 아기의 감정 상태를 판별하기 위해 인식하도록 적어도 하나의 지정된 인식 대상(예컨대, 아기 표정, 아기 울음소리, 지저된 센서모듈을 통해 아깅의 지정된 센싱 대사을 센싱한 센싱 값 등) 별 감정상태 판별 정보를 지정된 저장영역이나 운영D/B에 저장하여 관리한다. 본 발명의 실시 방법 에 따르면, 상기 인식 대상 별 감정상태 판별 정보는 인공지능 기반의 감정상태 판별 정보를 포함하거나 및/또 는 패턴 인식 기반의 감정상태 판별 정보를 포함할 수 있다. 도면2를 참조하면, 상기 운영서버는 지정된 거점에 구비된 카메라장치를 통해 상기 거점 내의 특정 아기를 촬영한 비디오 데이터를 포함하는 송신 데이터를 제공받을 대상과 상기 카메라장치를 매핑하기 위 해 사용자 무선단말의 앱으로부터 사용자에 대한 사용자정보, 상기 사용자에게 제공/공급된 카메라장치 를 고유 식별하는 카메라장치정보, 상기 사용자 무선단말의 앱을 고유 식별하는 고유식별정보 및 상기 사용자가 설정한 ID/PW정보 등을 지정된 절차에 따라 매핑 등록 요청할 수 있으며, 상기 운영서버 는 상기 사용자 무선단말의 앱으로부터 상기 사용자정보, 카메라장치정보, 고유식별정보 및 ID/PW정보 등을 지정된 절차에 따라 수신하고, 상기 사용자정보, 카메라장치정보, 고유식별정보 및 ID/PW정보 등을 지정된 관리Dd/B에 연계 저장한다. 한편 실시 방법에 따라 상기 사용자정보와 카메라장치정보 및 ID/PW정보 등은 상기 카메라장치를 구매하거나 공급받는 사용자가 이용하는 사용자단말이나 상기 사용자의 가입신청서를 접수한 지정된 등록단말을 통해 등록될 수 있다. 도면3은 본 발명의 실시 방법에 따라 지정된 거점의 카메라장치를 통해 획득한 획득 데이터를 전송하여 지 정된 저장매체에 저장 관리하는 도시한 도면이다. 보다 상세하게 본 도면3은 지정된 거점에 구비된 카메라장치의 카메라모듈을 통해 획득한 비디오 데이터를 포함하는 획득 데이터를 운영서버로 전송하여 지정된 저자매체의 특정 저장영역에 저장하여 관리하는 과정"}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면3을 참조 및/또는 변형 하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면3에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면3을 참조하면, 상기 카메라장치는 동작을 위한 전원 공급이 확인되면, 지정된 절차에 따라 통신 모듈을 통해 지정된 운영서버와 지정된 하나 이상의 정보를 교환하여 통신 연결을 요청하며, 상기 운 영서버는 상기 카메라장치와 지정된 정보를 교환하여 상기 카메라장치의 유효성을 인증한 경우 , 상기 카메라장치와 통신 연결하고, 이에 대응하여 상기 카메라장치로 상기 운영서버 와 통신이 연결된다. 한편 상기 운영서버는 상기 카메라장치를 통해 획득된 획득 데이터를 수신하기 위한 일회용주소정보 를 동적 생성하고, 상기 카메라장치로 상기 생성된 일회용주소정보를 제공하며, 상기 카메라장 치는 상기 운영서버로부터 상기 일회용주소정보를 수신하고, 상기 수신된 일회용주소정보를 상 기 획득 데이터를 전송할 목적지 주소로 설정할 수 있으며, 상기의 일회용주소정보 생성 내지 목적지 주소 로 설정하는 과정은 주기적으로(예컨대, 30초 단위) 반복될 수 있다. 한편 상기 카메라장치는 상기 카메라모듈을 통해 지정된 거점 내의 아기를 촬영한 비디오 데이터를 획득하 고(340a), 상기 비디오 데이터를 포함하는 획득 데이터를 지정된 목적지 주소로 전송할 수 있다. 또는 상기 카메라장치는 상기 카메라모듈을 통해 지정된 거점 내의 아기를 촬영한 비디오 데이터를 획득하 고(340a), 상기 사운드 입력부를 통해 상기 거점 내의 오디오 데이터를 획득한 후(340b), 상기 비디오 데이터와 오디오 데이터를 포함하는 획득 데이터를 지정된 목적지 주소로 전송할 수 있다. 또는 상기 카메라장치는 상기 카메라모듈을 통해 지정된 거점 내의 아기를 촬영한 비디오 데이터를 획득하 고(340a), 상기 센서모듈을 통해 아기의 지정된 센싱 대상을 센싱한 센싱 데이터를 획득한 후(340c), 상기 비디 오 데이터와 센싱 데이터를 포함하는 획득 데이터를 지정된 목적지 주소로 전송할 수 있다. 또는 상기 카메라장치는 상기 카메라모듈을 통해 지정된 거점 내의 아기를 촬영한 비디오 데이터를 획득하 고(340a), 상기 사운드 입력부를 통해 상기 거점 내의 오디오 데이터를 획득하고(340b), 상기 센서모듈을 통해 아기의 지정된 센싱 대상을 센싱한 센싱 데이터를 획득한 후(340c), 상기 비디오 데이터와 오디오 데이터 및 센 싱 데이터를 포함하는 획득 데이터를 지정된 목적지 주소로 전송할 수 있다. 상기 운영서버는 상기 카메라장치로부터 적어도 비디오 데이터를 포함하는 획득 데이터를 수신하고 , 상기 수신된 획득 데이터(또는 획득 데이터에 포함된 각각의 데이터)를 지정된 저장매체의 특정 저장영역에 저장하여 관리한다. 도면4는 본 발명의 제1 실시 방법에 따라 지정 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포 함하는 송신 데이터를 제공하는 도시한 도면이다. 보다 상세하게 본 도면4는 지정된 비디오 데이터를 판독하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성한 후 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 표 시한 비디오 데이터를 포함하는 송신 데이터를 사용자 무선단말의 앱이나 IPTV로 제공하는 과정을 도"}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면4를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면4에 도시된 실시 방 법만으로 그 기술적 특징이 한정되지 아니한다. 도면4를 참조하면, 상기 도면2의 과정을 통해 인공지능 기반의 표정 기반 감정상태 판별 정보를 생성하여 저장 한 경우, 상기 도면3의 과정을 통해 지정된 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공하는 시점, 또는 상기 도면3의 과정을 통해 지정된 저장매체의 특정 저장영역에 카메라장치를 통해 획득된 비디오 데이터를 포함하는 획득 데이터가 저장된 후, 상기 운영서버는 상기 인공지능 기반의 표정 기반 감정상태 판별 정보를 통해 지정된 비디오 데이터를 판독하는 절차를 수행하여 상기 비디오 데이터의 아기 표정에 대응하는 n1개의 감정 항목 별 아기 감 정 상태 값을 판별한다(a00). 한편 상기 도면2의 과정을 통해 패턴 인식 기반의 표정 기반 감정상태 판별 정보를 생성하여 저장한 경우, 상기 도면3의 과정을 통해 지정된 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 지정 된 사용자 무선단말의 앱이나 IPTV로 제공하는 시점, 또는 상기 도면3의 과정을 통해 지정된 저장매 체의 특정 저장영역에 카메라장치를 통해 획득된 비디오 데이터를 포함하는 획득 데이터가 저장된 후, 상 기 운영서버는 지정된 비디오 데이터를 판독하여 상기 거점 내의 특정 아기의 안면 영역에 대한 f개의 특 징점을 인식하면서 상기 인식된 f개의 특징점 중 아기의 감정 표현과 연관된 특징점 간 기하학 관계에 대응하는 i개의 아기 표정 인식 정보를 인식한다. 만약 상기 비디오 데이터를 근거로 i개의 아기 표정 인식 정보가 인식되면, 상기 운영서버는 상기 도면2의 과정을 통해 운영D/B에 저장된 표정 기반 감정상태 판별 정보를 근거로 상기 인식된 i개의 아기 표정 인식 정보 와 기 설정된 기준 유사도 이상 매칭된 e개의 아기 표정 패턴 정보를 확인하고, 상기 e개의 아기 표정 패 턴 정보와 매칭 관계를 지닌 n1개의 아기 감정 항목을 판별한다. 만약 상기 인식된 i개의 아기 표정 인식 정보에 대응하는 n1개의 아기 감정 항목이 판별되면, 상기 운영서버 는 상기 인식된 i개의 아기 표정 인식 정보와 상기 e개의 아기 표정 패턴 정보 간 매칭 비율을 근거로 상 기 e개의 아기 표정 패턴 정보와 n1개의 아기 감정 항목 간 상관도 수치 관계를 판독하여 상기 인식된 i개의 아 기 표정 인식 정보에 대응하는 n1개의 감정 항목 별 아기 감정 상태를 수치화한 n1개의 감정 항목 별 아기 감정 상태 값을 판별한다. 만약 상기 n1개의 감정 항목 별 아기 감정 상태 값이 산출되면, 상기 운영서버는 상기 판별된 n1개의 감정 항목 별 아기 감정 상태 값을 이용하여 비디오 데이터 상에 표시 가능한 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성한다.만약 상기 n개의 감정 항목 별 아기 감정 상태 정보가 생성되면, 상기 운영서버는 도면2의 과정을 통해 관 리D/B에 저장된 고유식별정보에 대응하는 사용자 무선단말의 앱이나 상기 관리D/B에 저장된 ID/PW정보를 통해 식별/인증된 IPTV로 제공할 송신 데이터의 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 n개 의 감정 항목 별 아기 감정 상태 정보를 표시하고, 상기 n개의 감정 항목 별 아기 감정 상태 정보를 표시 한 비디오 데이터를 포함하는 송신 데이터를 상기 사용자 무선단말의 앱이나 IPTV로 제공하며, 상기 사용자 무선단말의 앱이나 IPTV는 상기 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디 오 데이터를 포함하는 송신 데이터를 수신하여 출력한다. 바람직하게, 상기 송신 데이터는 상기 비디오 데 이터와 연계된 오디오 데이터를 더 포함할 수 있다. 도면5는 본 발명의 제2 실시 방법에 따라 지정 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포 함하는 송신 데이터를 제공하는 도시한 도면이다. 보다 상세하게 본 도면5는 지정된 비디오 데이터와 연계된 오디오 데이터를 판독하여 인식된 아기 울음소리 인 식 정보를 (추가)이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성한 후 비디오 데이터 상의 지 정된 일정 영역에 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포함하는 송 신 데이터를 사용자 무선단말의 앱이나 IPTV로 제공하는 과정을 도시한 것으로서, 본 발명이 속한 기 술분야에서 통상의 지식을 가진 자라면, 본 도면5를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법 (예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면5에 도시된 실시 방법만으로 그 기술적 특징이 한정되 지 아니한다. 도면5를 참조하면, 상기 도면2의 과정을 통해 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 생성하여 저장한 경우, 상기 도면3의 과정을 통해 지정된 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공하는 시점, 또는 상기 도면3의 과정을 통해 지정된 저장매체의 특정 저장영역에 카메라장치를 통해 획득된 비디오 데이터를 포함하는 획득 데이 터가 저장된 후, 또는 상기 도면4에 도시된 아기 표정 인식 기반의 n1개의 감정 항목 별 아기 감정 상태 값 산 출 과정과 연동하여, 상기 운영서버는 상기 인공지능 기반의 울음소리 기반 감정상태 판별 정보를 통해 지 정된 비디오 데이터와 연계된 오디오 데이터를 판독하는 절차를 수행하여 상기 오디오 데이터의 아기 울음소리 에 대응하는 n2개의 감정 항목 별 아기 감정 상태 값을 값을 판별한다(b00). 한편 상기 도면2의 과정을 통해 패턴 인식 기반의 표정 기반 감정상태 판별 정보를 생성하여 저장한 경우, 상기 도면3의 과정을 통해 지정된 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함하는 송신 데이터를 지정 된 사용자 무선단말의 앱이나 IPTV로 제공하는 시점, 또는 상기 도면3의 과정을 통해 지정된 저장매 체의 특정 저장영역에 카메라장치를 통해 획득된 비디오 데이터를 포함하는 획득 데이터가 저장된 후, 또 는 상기 도면4에 도시된 아기 표정 인식 기반의 n1개의 감정 항목 별 아기 감정 상태 값 산출 과정과 연동하여, 상기 운영서버는 지정된 비디오 데이터와 연계된 일정 일정 구간의 오디오 데이터를 판독하여 상기 특정 아기에 대한 j개의 아기 울음소리 인식 정보를 인식한다. 만약 상기 오디오 데이터를 근거로 j개의 아기 울음소리 인식 정보가 인식되면, 상기 운영서버는 상기 도 면2의 과정을 통해 운영D/B에 저장된 울음소리 기반 감정상태 판별 정보를 근거로 상기 인식된 j개의 아기 울음 소리 인식 정보와 기 설정된 기준 유사도 이상 매칭된 c개의 아기 울음소리 패턴 정보를 확인하고, 상기 확인된 c개의 아기 울음소리 패턴 정보와 매칭 관계를 지닌 n2개의 아기 감정 항목을 판별한다. 만약 상기 인식된 j개의 아기 울음소리 인식 정보에 대응하는 n2개의 아기 감정 항목이 판별되면, 상기 운영서 버는 상기 인식된 j개의 아기 울음소리 인식 정보와 상기 c개의 아기 울음소리 패턴 정보 간 매칭 비율을 근거로 상기 c개의 아기 울음소리 패턴 정보와 n2개의 아기 감정 항목 간 상관도 수치 관계를 판독하여 상기 인식된 j개의 아기 울음소리 인식 정보에 대응하는 n2개의 감정 항목 별 아기 감정 상태를 수치화한 n2개의 감정 항목 별 아기 감정 상태 값을 판별한다. 만약 상기 n2개의 감정 항목 별 아기 감정 상태 값이 산출되면, 상기 운영서버는 상기 판별된 n2개의 감정 항목 별 아기 감정 상태 값을 이용하여 비디오 데이터 상에 표시 가능한 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 한편 상기 n2개의 감정 항목 별 아기 감정 상태 값이 산출되기 전 또는 중 또는 후의 일 시점에 상기 도면4의 과정을 통해 n1개의 감정 항목 별 아기 감정 상태 값이 산출된 경우, 상기 운영서버는 상기 판별된 n1개의 감정 항목 별 아기 감정 상태 값과 상기 n2개의 감정 항목 별 아기 감정 상태 값을 조합하여 비디오 데이터 상 에 표시 가능한 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 만약 상기 n개의 감정 항목 별 아기 감정 상태 정보가 생성되면, 상기 운영서버는 도면2의 과정을 통해 관 리D/B에 저장된 고유식별정보에 대응하는 사용자 무선단말의 앱이나 상기 관리D/B에 저장된 ID/PW정보를 통해 식별/인증된 IPTV로 제공할 송신 데이터의 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 n개 의 감정 항목 별 아기 감정 상태 정보를 표시하고, 상기 n개의 감정 항목 별 아기 감정 상태 정보를 표시 한 비디오 데이터를 포함하는 송신 데이터를 상기 사용자 무선단말의 앱이나 IPTV로 제공하며, 상기 사용자 무선단말의 앱이나 IPTV는 상기 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디 오 데이터를 포함하는 송신 데이터를 수신하여 출력한다. 바람직하게, 상기 송신 데이터는 상기 비디오 데 이터와 연계된 오디오 데이터를 더 포함할 수 있다. 도면6은 본 발명의 제3 실시 방법에 따라 지정 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포 함하는 송신 데이터를 제공하는 도시한 도면이다. 보다 상세하게 본 도면6은 지정된 비디오 데이터 및/또는 오디오 데이터와 연계된 센싱 데이터를 판독하여 인식 된 센싱 값 인식 정보를 (추가)이용하여 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성한 후 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터 를 포함하는 송신 데이터를 사용자 무선단말의 앱이나 IPTV로 제공하는 과정을 도시한 것으로서, 본"}
{"patent_id": "10-2019-0161714", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면6을 참조 및/또는 변형하여 상기 과정에 대한 다 양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면6에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면6을 참조하면, 상기 도면3의 과정을 통해 지정된 저장매체의 특정 저장영역에 저장된 비디오 데이터를 포함 하는 송신 데이터를 지정된 사용자 무선단말의 앱이나 IPTV로 제공하는 시점, 또는 상기 도면3의 과 정을 통해 지정된 저장매체의 특정 저장영역에 카메라장치를 통해 획득된 비디오 데이터를 포함하는 획득 데이터가 저장된 후, 또는 상기 도면4에 도시된 아기 표정 인식 기반의 n1개의 감정 항목 별 아기 감정 상태 값 산출 과정과 연동하거나, 또는 상기 도면5에 도시된 아기 울음소리 인식 기반의 n2개의 감정 항목 별 아기 감정 상태 값 산출 과정과 연동하여, 상기 운영서버는 지정된 비디오 데이터 및/또는 오디오 데이터와 연계된 센싱 데이터를 판독하여 상기 특정 아기의 감정 표현과 연관된 지정된 센싱 대상의 센싱 데이터에 대한 k개의 센싱 값 인식 정보를 인식한다. 만약 상기 센싱 데이터를 근거로 k개의 센싱 값 인식 정보가 인식되면, 상기 운영서버는 상기 도면2의 과 정을 통해 운영D/B에 저장된 센싱 기반 감정상태 판별 정보를 근거로 상기 인식된 k개의 센싱 값 인식 정보와 기 설정된 기준 유사도 이상 매칭된 s개의 센싱 값 패턴 정보를 확인하고, 상기 확인된 s개의 센싱 값 패턴 정보와 매칭 관계를 지닌 n3개의 아기 감정 항목을 판별한다. 만약 상기 인식된 k개의 센싱 값 인식 정보에 대응하는 n3개의 아기 감정 항목이 판별되면, 상기 운영서버(10 0)는 상기 인식된 k개의 센싱 값 인식 정보와 상기 s개의 센싱 값 패턴 정보 간 매칭 비율을 근거로 상기 s개의 센싱 값 패턴 정보와 n3개의 아기 감정 항목 간 상관도 수치 관계를 판독하여 상기 인식된 k개의 센싱 값 인식 정보에 대응하는 n3개의 감정 항목 별 아기 감정 상태를 수치화한 n3개의 감정 항목 별 아기 감정 상태 값을 판 별한다. 만약 상기 n3개의 감정 항목 별 아기 감정 상태 값이 산출되면, 상기 운영서버는 상기 판별된 n3개의 감정 항목 별 아기 감정 상태 값을 이용하여 비디오 데이터 상에 표시 가능한 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 한편 상기 n3개의 감정 항목 별 아기 감정 상태 값이 산출되기 전 또는 중 또는 후의 일 시점에 상기 도면4의 과정을 통해 n1개의 감정 항목 별 아기 감정 상태 값이 산출된 경우, 상기 운영서버는 상기 판별된 n1개의 감정 항목 별 아기 감정 상태 값과 상기 n3개의 감정 항목 별 아기 감정 상태 값을 조합하여 비디오 데이터 상 에 표시 가능한 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 또는 상기 n3개의 감정 항목 별 아기 감정 상태 값이 산출되기 전 또는 중 또는 후의 일 시점에 상기 도면4의 과정을 통해 n1개의 감정 항목 별 아기 감정 상태 값이 산출되고 상기 도면5의 과정을 통해 n2개의 감정 항목 별 아기 감정 상태 값이 산출된 경우, 상기 운영서버는 상기 판별된 n1개의 감정 항목 별 아기 감정 상태 값과 n2개의 감정 항목 별 아기 감정 상태 값 및 상기 n3개의 감정 항목 별 아기 감정 상태 값을 조합하여 비디 오 데이터 상에 표시 가능한 지정된 n개의 감정 항목 별 아기 감정 상태 정보를 생성할 수 있다. 만약 상기 n개의 감정 항목 별 아기 감정 상태 정보가 생성되면, 상기 운영서버는 도면2의 과정을 통해 관 리D/B에 저장된 고유식별정보에 대응하는 사용자 무선단말의 앱이나 상기 관리D/B에 저장된 ID/PW정보를 통해 식별/인증된 IPTV로 제공할 송신 데이터의 비디오 데이터 상의 지정된 일정 영역에 상기 생성된 n개 의 감정 항목 별 아기 감정 상태 정보를 표시하고, 상기 n개의 감정 항목 별 아기 감정 상태 정보를 표시 한 비디오 데이터를 포함하는 송신 데이터를 상기 사용자 무선단말의 앱이나 IPTV로 제공하며, 상기 사용자 무선단말의 앱이나 IPTV는 상기 n개의 감정 항목 별 아기 감정 상태 정보를 표시한 비디 오 데이터를 포함하는 송신 데이터를 수신하여 출력한다. 바람직하게, 상기 송신 데이터는 상기 비디오 데 이터와 연계된 오디오 데이터를 더 포함할 수 있다."}
{"patent_id": "10-2019-0161714", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 방법에 따라 아기의 감정 상태를 표시하는 시스템의 구성을 도시한 도면이다. 도 2는 본 발명의 실시 방법에 따른 정보 저장/등록 과정을 도시한 도면이다. 도 3은 본 발명의 실시 방법에 따라 지정된 거점의 카메라장치를 통해 획득한 획득 데이터를 전송하여 지 정된 저장매체에 저장 관리하는 도시한 도면이다. 도 4는 본 발명의 제1 실시 방법에 따라 지정 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포 함하는 송신 데이터를 제공하는 도시한 도면이다. 도 5는 본 발명의 제2 실시 방법에 따라 지정 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포 함하는 송신 데이터를 제공하는 도시한 도면이다. 도 6은 본 발명의 제3 실시 방법에 따라 지정 감정 항목 별 아기 감정 상태 정보를 표시한 비디오 데이터를 포 함하는 송신 데이터를 제공하는 도시한 도면이다."}
