{"patent_id": "10-2023-0043622", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0056004", "출원번호": "10-2023-0043622", "발명의 명칭": "가상 현실 기반의 수술 환경을 제공하는 장치 및 방법", "출원인": "(주)휴톰", "발명자": "박석래"}}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장치에 의해 가상 현실 기반의 수술 환경을 제공하는 방법에 있어서, 제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정된 프레임 마다 상기 실제 수술 영상 내에 포함된적어도 하나의 실제 수술 도구를 인식하는 단계;상기 실제 수술 도구 및 가상 현실 기반의 상기 실제 수술 도구에 대응되는 적어도 하나의 가상 수술 도구의 적어도 하나의 동일 부위에 대해 동일점 매칭(Correspondence matching)을 수행하는 단계;상기 수행된 동일점 매칭 결과에 따라, 상기 가상 수술 도구가 상기 실제 수술 도구의 위치에 대응되도록 보정하는 단계;상기 보정된 상기 가상 수술 도구의 좌표값을 산출하는 단계;상기 기 설정된 프레임 마다 상기 가상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출하는 단계; 및상기 산출된 복수의 좌표값 간의 차이를 기반으로 복수의 로그 정보를 생성하는 단계; 를 포함하는, 가상 현실기반의 수술 환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 동일점 매칭 단계는,상기 실제 수술 도구의 적어도 하나의 부위를 제1 기준점으로 설정하는 단계;시멘틱(semantic) 동일점 매칭 기법을 이용하여, 상기 가상 수술 도구에서 상기 실제 수술 도구의 적어도 하나의 부위와 동일한 부위를 제2 기준점으로 설정하는 단계; 및상기 제1 및 제2 기준점을 이용하여 상기 동일점 매칭을 수행하는 단계; 를 포함하는, 가상 현실 기반의 수술환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 로그 정보 생성 단계는,상기 복수의 좌표값이 산출될 때마다 이전에 산출된 좌표값과 이후에 산출된 좌표값 간의 차이에 대한 로그 정보를 순차적으로 생성하는, 가상 현실 기반의 수술 환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 순차적으로 생성된 로그 정보를 누적하여 저장하는 단계; 를 더 포함하는, 가상 현실 기반의 수술 환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 누적 저장 단계는,상기 순차적으로 생성된 로그 정보 간의 차이가 기 설정된 차이 이상인 경우에만, 현재 생성된 로그 정보를 누적 저장하는, 가상 현실 기반의 수술 환경 제공 방법.공개특허 10-2023-0056004-3-청구항 6 제4항에 있어서,상기 누적 저장된 로그 정보를 기반으로 상기 실제 수술 영상 내의 현재 프레임에서 다음 프레임에 변경되는 실제 수술 도구의 움직임을 예측하는 단계; 및상기 예측된 움직임을 나타내는 시각 효과를 상기 실제 수술 영상 내의 현재 프레임 상의 상기 움직임에 해당하는 위치에 표시하는 단계; 를 더 포함하는, 가상 현실 기반의 수술 환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 실제 수술 영상은,입체경 카메라를 통해 촬영되어 상기 프레임 마다 상기 실제 수술 객체에 대한 3차원 깊이값을 포함하고,상기 보정 단계는,상기 보정된 가상 수술 도구의 위치에 해당 3차원 깊이값을 부여하여 상기 가상 수술 도구를 3차원 객체로 렌더링하는, 가상 현실 기반의 수술 환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 좌표값 산출 단계는,상기 3차원 깊이값이 부여된 후 상기 보정된 가상 수술 도구의 위치에 해당하는 좌표값 내에 상기 3차원 깊이값을 포함시키는, 가상 현실 기반의 수술 환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 로그 정보 생성 단계는,상기 3차원 깊이값이 포함되어 산출된 복수의 좌표값 간의 차이를 기반으로 상기 3차원 깊이값이 부여된 복수의로그 정보를 생성하는, 가상 현실 기반의 수술 환경 제공 방법."}
{"patent_id": "10-2023-0043622", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "가상 현실 기반의 수술 환경을 제공하는 장치에 있어서, 실제 수술 영상을 획득하는 영상 획득부; 메모리; 및제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정된 프레임 마다 상기 실제 수술 영상 내에 포함된적어도 하나의 실제 수술 도구를 인식하는 제1 프로세스를 수행하고,상기 실제 수술 도구 및 가상 현실 기반의 상기 실제 수술 도구에 대응되는 적어도 하나의 가상 수술 도구의 적어도 하나의 동일 부위에 대해 동일점 매칭(Correspondence matching)을 수행하는 제2 프로세스를 수행하고,상기 수행된 동일점 매칭 결과에 따라, 상기 가상 수술 도구가 상기 실제 수술 도구의 위치에 대응되도록 보정하는 제3 프로세스를 수행하고,상기 보정된 상기 가상 수술 도구의 좌표값을 산출하는 제4 프로세스를 수행하고,상기 제1 내지 제4 프로세스를 반복 수행하여, 상기 기 설정된 프레임 마다 상기 가상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출하는 제5 프로세스를 수행하고,상기 산출된 복수의 좌표값 간의 차이를 기반으로 복수의 로그 정보를 생성하는 제6 프로세스를 수행하는 프로세서; 를 포함하는, 장치. 공개특허 10-2023-0056004-4-"}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 장치에 의해 가상 현실 기반의 수술 환경을 제공하는 방법에 있어서, 제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정된 프레임 마다 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식하는 단계, 상기 실제 수술 도구 및 가상 현실 기반의 상기 실제 수술 도구에 대응되는 적어도 하나의 가상 수술 도구의 적어도 하나의 동일 부위에 대해 동일점 매칭(Correspondence matching)을 수행하는 단계, 상기 수 행된 동일점 매칭 결과에 따라, 상기 가상 수술 도구가 상기 실제 수술 도구의 위치에 대응되도록 보정하는 단계, 상기 보정된 상기 가상 수술 도구의 좌표값을 산출하는 단계, 상기 기 설정된 프레임 마다 상기 가상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출하는 단계 및 상기 산출된 복수의 좌표값 간의 차이를 기반으 로 복수의 로그 정보를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상 현실 기반의 수술 환경을 제공하는 방법에 관한 것으로, 보다 상세하게는 수술 영상에서 수술 도구의 움직임을 파악하여 가상 현실 기반의 수술 환경을 제공하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어 병원에서 수술하는 경우, 바로 수술을 진행하지 않고, 수술 전 환자의 조건을 3D 시뮬레이션(입체영 상)으로 만든 뒤 실제 수술과 동일한 조건 하에 가상으로 수술을 시행할 수 있다. 보다 상세하게는, 가상 모의 수술의 경우, 정밀한 진단을 사전에 세울 수 있다. 그러므로, 전문의의 감에 의존 하는 것이 아니라 가상 모의 수술을 통해 계획을 세우고, 아주 작은 오차까지도 줄여 나갈 수 있다. 위와 같은 가상 모의 수술이 가져오는 놀라운 효과는 수술의 정확성이 향상되고, 실제 수술 상황을 예측 가능며, 환자 개인에게 적합한 수술방법이 제공되어 시간을 단축할 수 있다는 것이다. 그러나, 이런 가상 모의 수술의 정확도를 높이기 위해서는 가상 모의 수술을 시행하는 환경에 대한 기본적인 설 정이 매우 중요하다. 구체적으로, 가상 모의 수술을 시행할 때 필수적으로 필요한 가상 수술도구에 대한 데이터 가 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허공보 제10-2020-0048830호"}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 바와 같은 문제점을 해결하기 위한 본 발명은 실제 수술 영상에서의 실제 수술 도구와 동일한 가상 수술 도구를 가상 현실 기반에 생성하여 가상 수술 도구의 로그 정보에 따라 실제 수술 도구의 움직임을 판단하는 것 을 그 목적으로 한다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명에 따른 장치에 의해 가상 현실 기반의 수술 환경을 제공하는 방법에 있어 서, a) 제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정된 프레임 마다 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식하는 단계, b) 상기 실제 수술 도구 및 가상 현실 기반의 상기 실 제 수술 도구에 대응되는 적어도 하나의 가상 수술 도구의 적어도 하나의 동일 부위에 대해 동일점 매칭 (Correspondence matching)을 수행하는 단계, c) 상기 수행된 동일점 매칭 결과에 따라, 상기 가상 수술 도구가 상기 실제 수술 도구의 위치에 대응되도록 보정하는 단계, d) 상기 보정된 상기 가상 수술 도구의 좌표값을 산 출하는 단계, e) 상기 a) 내지 d) 단계를 반복 수행하여, 상기 기 설정된 프레임 마다 상기 가상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출하는 단계 및 f) 상기 산출된 복수의 좌표값 간의 차이를 기반으로 복수의 로그 정보를 생성하는 단계를 포함할 수 있다. 여기서, 상기 동일점 매칭 단계는, 상기 실제 수술 도구의 적어도 하나의 부위를 제1 기준점으로 설정하는 단계 및 시멘틱(semantic) 동일점 매칭 기법을 이용하여, 상기 가상 수술 도구에서 상기 실제 수술 도구의 적어도 하 나의 부위와 동일한 부위를 제2 기준점으로 설정하는 단계 및 상기 제1 및 제2 기준점을 이용하여 상기 동일점 매칭을 수행하는 단계를 포함할 수 있다. 여기서, 상기 로그 정보 생성 단계는, 상기 복수의 좌표값이 산출될 때마다 이전에 산출된 좌표값과 이후에 산 출된 좌표값 간의 차이에 대한 로그 정보를 순차적으로 생성할 수 있다. 또한, 본 발명에 따른 장치에 의해 가상 현실 기반의 수술 환경을 제공하는 방법은 상기 순차적으로 생성된 로 그 정보를 누적하여 저장하는 단계를 더 포함할 수 있다. 여기서, 상기 누적 저장 단계는, 상기 순차적으로 생성된 로그 정보 간의 차이가 기 설정된 차이 이상인 경우에 만, 현재 생성된 로그 정보를 누적 저장할 수 있다. 또한, 본 발명에 따른 장치에 의해 가상 현실 기반의 수술 환경을 제공하는 방법은 상기 누적 저장된 로그 정보 를 기반으로 상기 실제 수술 영상 내의 현재 프레임에서 다음 프레임에 변경되는 실제 수술 도구의 움직임을 예 측하는 단계 및 상기 예측된 움직임을 나타내는 시각 효과를 상기 실제 수술 영상 내의 현재 프레임 상의 상기 움직임에 해당하는 위치에 표시하는 단계를 더 포함할 수 있다. 반면에, 상기 실제 수술 영상은, 입체경 카메라를 통해 촬영되어 상기 프레임 마다 상기 실제 수술 객체에 대한 3차원 깊이값을 포함할 수 있다. 이에 따라, 상기 보정 단계는, 상기 보정된 가상 수술 도구의 위치에 해당 3차원 깊이값을 부여하여 상기 가상 수술 도구를 3차원 객체로 렌더링할 수 있다. 또한, 상기 좌표값 산출 단계는, 상기 3차원 깊이값이 부여된 후 상기 보정된 가상 수술 도구의 위치에 해당하 는 좌표값 내에 상기 3차원 깊이값을 포함시킬 수 있다. 또한, 상기 로그 정보 생성 단계는, 상기 3차원 깊이값이 포함되어 산출된 복수의 좌표값 간의 차이를 기반으로 상기 3차원 깊이값이 부여된 복수의 로그 정보를 생성할 수 있다. 또한, 상술한 과제를 해결하기 위한 본 발명에 따른 가상 현실 기반의 수술 환경을 제공하는 장치에 있어서, 실 제 수술 영상을 획득하는 영상 획득부, 메모리 및 제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정 된 프레임 마다 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식하는 제1 프로세스를 수 행하고, 상기 실제 수술 도구 및 가상 현실 기반의 상기 실제 수술 도구에 대응되는 적어도 하나의 가상 수술 도구의 적어도 하나의 동일 부위에 대해 동일점 매칭(Correspondence matching)을 수행하는 제2 프로세스를 수 행하고, 상기 수행된 동일점 매칭 결과에 따라, 상기 가상 수술 도구가 상기 실제 수술 도구의 위치에 대응되도 록 보정하는 제3 프로세스를 수행하고, 상기 보정된 상기 가상 수술 도구의 좌표값을 산출하는 제4 프로세스를 수행하고, 상기 제1 내지 제4 프로세스를 반복 수행하여, 상기 기 설정된 프레임 마다 상기 가상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출하는 제5 프로세스를 수행하고, 상기 산출된 복수의 좌표값 간의 차 이를 기반으로 복수의 로그 정보를 생성하는 제6 프로세스를 수행하는 프로세서를 포함할 수 있다. 이 외에도, 본 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같은 본 발명에 따르면, 실제 수술 영상에서의 실제 수술 도구와 동일한 가상 수술 도구를 가상 현실 기 반에 생성하여 가상 수술 도구의 로그 정보에 따라 실제 수술 도구의 움직임을 판단함으로써 실제 수술 도구의 움직임을 정확하게 파악할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명을 상세하게 설명한다. 도 1은 본 발명에 따른 가상 현실 기반의 수술 환경을 제공하는 장치를 설명하기 위한 도면이다. 도 2는 본 발명에 따른 장치의 프로세서가 실제 수술 영상을 통해 가상 현실 기반의 가상 수술 도구의 좌표값을 산출하는 것을 설명하기 위한 도면이다. 도 3은 본 발명에 따른 장치의 프로세서가 실제 수술 영상을 통해 가상 현실 기반의 가상 수술 도구의 로그 정보를 생성하는 것을 설명하기 위한 도면이다. 도 4는 본 발명에 따른 장치의 프로세서가 깊이값이 적용되는 실제 수술 영상을 통해 가상 현실 기반 의 가상 수술 도구의 좌표값을 산출하는 것을 설명하기 위한 도면이다. 도 5는 본 발명에 따른 장치의 프로세서가 깊이값이 적용되는 실제 수술 영상을 통해 가상 현실 기반 의 가상 수술 도구의 로그 정보를 생성하는 것을 설명하기 위한 도면이다. 도 6a 내지 6c는 본 발명에 따른 장치의 프로세서가 실제 수술 영상에 예측된 움직임을 나타내는 시각 효과를 표시하는 것을 설명하기 위한 도면이다. 이하, 도 1 내지 도 6c를 참조하여 본 발명에 따른 가상 현실 기반의 수술 환경을 제공하는 장치에 대해서 설명하도록 한다. 여기서, 장치는 로컬의 컴퓨팅 장치뿐만 아니라 서버장치로도 구현될 수 있다. 장치는 실제 수술 영상에서의 실제 수술 도구와 동일한 가상 수술 도구를 가상 현실 기반에 생성하여 가상 수술 도구의 로그 정보에 따라 실제 수술 도구의 움직임을 판단함으로써 실제 수술 도구의 움직임을 정확하게 파악할 수 있는 효과를 가질 수 있다. 먼저, 도 1을 참조하면, 장치는 영상 획득부, 메모리 및 프로세서를 포함한다. 여기서, 장 치는 도 1에 도시된 구성요소보다 더 적은 수의 구성요소나 더 많은 구성요소를 포함할 수도 있다.영상 획득부는 실제 수술 영상을 기 설정된 주기, 실시간 또는 사용자의 입력이 있는 시점에서 외부 장치 (미도시)로부터 획득할 수 있다. 또는 영상 획득부는 실제 수술 영상을 메모리를 통해 획득할 수 있 다. 여기서, 영상 획득부는 통신모듈을 포함할 수 있다. 통신모듈은 상기 장치와 무선 통신 시스템 사이 또는 상기 장치와 외부 장치(미도시) 사이의 무선 통신을 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 또한, 상기 통신모듈은 장치를 하나 이상 의 네트워크에 연결하는 하나 이상의 모듈을 포함할 수 있다. 메모리는 상기 장치의 다양한 기능을 지원하는 정보를 저장할 수 있다. 메모리는 상기 장치 에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 상기 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버(미도시)로부터 다운로드 될 수 있다. 또한 이러한 응용 프로그램 중 적어도 일부는, 상기 장치의 기본적인 기능을 위하여 존재할 수 있다. 한편, 응용 프로그램은, 메모리에 저장되고, 상기 장치 상에 설치되어, 프로세서에 의하여 상기 장치의 동작(또는 기능)을 수행하도록 구동될 수 있다. 또한, 메모리는 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식하기 위한 제1 인 공지능 모델을 저장할 수 있다. 여기서, 제1 인공지능 모델은 콘볼루션 뉴럴 네트워크(CNN, convolutional neural network) 및 순환 뉴럴 네트워크(recurrent neural network)를 포함할 수 있으나 반드시 이에 한정되지 않고, 다양한 구조의 신경망으로 형성될 수 있다. 이하, 콘볼루션 뉴럴 네트워크는 ‘CCN’이라 명칭하고, 순환 뉴럴 네트워크는 ‘RNN’이라 명칭하겠다. CNN은 영상의 각 영역에 대해 복수의 필터를 적용하여 특징 지도(Feature Map)를 만들어 내는 콘볼루션 층 (Convolution Layer)과 특징 지도를 공간적으로 통합함으로써 위치나 회전의 변화에 불변하는 특징을 추출할 수 있도록 하는 통합층(Pooling Layer)을 번갈아 수차례 반복하는 구조로 형성될 수 있다. 이를 통해, 점, 선, 면 등의 낮은 수준의 특징에서부터 복잡하고 의미 있는 높은 수준의 특징까지 다양한 수준의 특징을 추출해낼 수 있다. 콘볼루션 층은 입력 영상의 각 패치에 대하여 필터와 국지 수용장(Local Receptive Field)의 내적에 비선형 활 성 함수(Activation Function)를 취함으로 서 특징지도(Feature Map)를 구할 수 있다. 다른 네트워크 구조와 비교하여, CNN은 희소한 연결성 (Sparse Connectivity)과 공유된 가중치(Shared Weights)를 가진 필터를 사용 하는 특징을 가질 수 있다. 이러한 연결구조는 학습할 모수의 개수를 줄여주고, 역전파 알고리즘을 통한 학습을 효율적으로 만들어 결과적으로 예측 성능을 향상시킬 수 있다. 통합 층(Pooling Layer 또는 Sub-sampling Layer)은 이전 콘볼루션 층에서 구해진 특징 지도의 지역 정보를 활 용하여 새로운 특징 지도를 생성할 수 있다. 일반적으로 통합 층에 의해 새로 생성된 특징지도는 원래의 특징 지도보다 작은 크기로 줄어드는데, 대표적인 통합 방법으로는 특징 지도 내 해당 영역의 최대값을 선택하는 최 대 통합(Max Pooling)과 특징 지도 내 해당 영역의 평균값을 구하는 평균 통합(Average Pooling) 등이 있을 수 있다. 통합 층의 특징지도는 일반적으로 이전 층의 특징 지도보다 입력 영상에 존재하는 임의의 구조나 패턴의 위치에 영향을 적게 받을 수 있다. 즉, 통합층은 입력 영상 혹은 이전 특징 지도에서의 노이즈나 왜곡과 같은 지역적 변화에 보다 강인한 특징을 추출할 수 있게 되고, 이러한 특징은 분류 성능에 중요한 역할을 할 수 있다. 또 다른 통합 층의 역할은, 깊은 구조상에서 상위의 학습 층으로 올라갈수록 더 넓은 영역의 특징을 반영 할 수 있게 하는 것으로서, 특징 추출 층이 쌓이면서, 하위 층에서는 지역적인 특징을 반영하고 상위 층으로 올 라 갈수록 보다 추상적인 전체 영상의 특징을 반영하는 특징 생성할 수 있다. 이와 같이, 콘볼루션 층과 통합 층의 반복을 통해 최종적으로 추출된 특징은 다중 신경망(MLP: Multi-Layer Perceptron)이나 서포트 벡터 머신(SVM: Support Vector Machine)과 같은 분류 모델이 완전 연결 층(Fully- connected Layer)의 형태로 결합되어 분류 모델 학습 및 예측에 사용될 수 있다. RNN은 어떤 특정 부분이 반복되는 구조를 통해 순서를 학습하기에 효과적인 딥러닝 기법으로 이전 상태의 상태 값이 다음 계산의 입력으로 들어가서 결과에 영향을 미칠 수 있다. 또한, 메모리는 영상 획득부를 통해 획득한 상기 적어도 하나의 실제 수술 영상을 저장할 수 있다. 또는, 메모리는 미리 상기 적어도 하나의 실제 수술 영상을 저장하고 있을 수 있다. 여기서, 상기 실제 수 술 영상은 병원의 수술실이나 실험실 환경에서 수술 과정을 촬영한 수술 동영상 내에 포함된 적어도 하나의 실제 수술 도구가 촬영된 동영상일 수 있다. 보다 상세하게는, 메모리는 상기 적어도 하나의 실제 수술 영상 각각을 수술 종류, 수술자 이름, 병원 이 름, 환자 상태, 수술 시간 및 수술 환경 등에 매칭하여 저장할 수 있다. 또한, 메모리는 적어도 하나의 실제 수술 영상에 대한 3차원 깊이값을 포함하여 저장하거나 별도로 저장할 수 있다. 보다 상세하게는, 메모리는 입체경 카메라를 통해 촬영된 상기 실제 수술 영상에 대해 상기 프레임 마다 상기 실제 수술 객체에 대한 3차원 깊이값을 포함하여 저장하거나 별도로 저장할 수 있다. 여기서, 프로세서는 상기 입체경 카메라를 통해 촬영된 실제 수술 영상에 대해 멀티뷰 지오메트리(Multiview geometry)를 활용하여 상기 3차원 깊이값(3차원 깊이맵(depth map))을 얻을 수 있다. 또한, 메모리는 프로세서를 통해 기 설정된 프레임 마다 가상 수술 도구가 보정되는 위치에 대한 복 수의 좌표값 간의 차이에 따라 생성된 복수의 로그 정보를 누적하여 저장할 수 있다. 프로세서는 상기 응용 프로그램과 관련된 동작 외에도, 통상적으로 상기 장치의 전반적인 동작을 제어 할 수 있다. 프로세서는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 메모리에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또 는 처리할 수 있다. 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 도 1과 함께 살펴본 구성요소들 중 적어도 일부를 제어할 수 있다. 나아가, 프로세서는 상기 응용 프로그램의 구동을 위하여, 상기 장치 에 포함된 구성요소들 중 적어도 둘 이상을 서로 조합하여 동작 시킬 수 있다. 이하, 도 2 내지 6c를 통해 프로세서의 동작에 대해 상세히 후술하도록 한다. 프로세서는 제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정된 프레임 마다 상기 실제 수술 영 상 내에 포함된 적어도 하나의 실제 수술 도구를 인식할 수 있다(A 단계). 또는, 프로세서는 제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정된 프레임 마다 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식할 수 있다(A 단계). 여기서, 상기 실제 수술 영상 은, 입체경(Stereoscope) 카메라를 통해 촬영되어 상기 프레임 마다 상기 실제 수술 객체에 대한 3차원 깊 이값을 포함할 수 있다. 즉, 상기 실제 수술 영상에 실제 수술 도구, 실제 수술 장기, 실제 수술시 전문의 손 등의 상기 실제 수술 객체에 대한 3차원 깊이값이 포함되거나, 별도로 메모리에 상기 실제 수술 영상과 매 칭되어 저장될 수 있다. 여기서, 프로세서는 상기 실제 수술 영상의 전체 프레임인 제1 프레임 내지 제N 프레임에 대해 각각의 하 나의 프레임 마다 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식할 수 있다. 또는, 프 로세서는 상기 실제 수술 영상의 전체 프레임인 제1 프레임 내지 제N 프레임에 대해 기 설정된 개수의 프 레임 마다 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식할 수 있다. 일 예로, 프로세서는 제1 인공지능 모델을 기반으로 상기 실제 수술 영상 내의 제1 내지 제N 프레임 마다 상기 실제 수술 영상 내에 포함된 두개의 실제 수술 도구를 인식할 수 있다. 프로세서는 상기 실제 수술 도구 및 가상 현실 기반의 상기 실제 수술 도구에 대응되는 적어도 하나의 가 상 수술 도구의 적어도 하나의 동일 부위에 대해 동일점 매칭(Correspondence Matching)을 수행할 수 있다(B 단 계). 여기서, 실제 수술 영상의 각각의 프레임과 가상 현실 기반에서 생성되는 각각의 프레임은 일대일로 대응 될 수 있다. 보다 상세하게는, 프로세서는 상기 실제 수술 도구의 적어도 하나의 부위를 제1 기준점으로 설정할 수 있 다. 여기서, 프로세서는 시멘틱 동일점 매칭(Semantic Correspondence Matching) 기법을 이용하여, 상기 가상 수술 도구에서 상기 실제 수술 도구의 적어도 하나의 부위와 동일한 부위를 제2 기준점으로 설정할 수 있 다. 이후, 프로세서는 상기 제1 및 제2 기준점을 이용하여 상기 동일점 매칭을 수행할 수 있다. 여기서, 상기 제1 및 제2 기준점은 적어도 하나의 지점(Point)을 의미할 수 있다. 일 예로, 프로세서는 제1 내지 제N 프레임 마다 상기 실제 수술 도구 및 가상 현실 기반의 두개의 가 상 수술 도구의 적어도 하나의 동일 부위(202, 212)에 대해 동일점 매칭(Correspondence Matching)을 수 행할 수 있다. 보다 상세하게는, 프로세서는 상기 실제 수술 도구의 특정 부위를 제1 기준점으로 설정할 수 있 다. 프로세서는 상기 시멘틱 동일점 매칭 기법을 통해 상기 가상 수술 도구에서 상기 실제 수술 도구 의 특정 부위와 동일한 부위를 제2 기준점으로 설정할 수 있다. 프로세서는 상기 제1 기준점과 제2 기준점을 이용하여 상기 동일점 매칭을 수행할 수 있다. 프로세서는 상기 수행된 동일점 매칭 결과에 따라, 상기 가상 수술 도구가 상기 실제 수술 도구의 위치에 대응되도록 보정할 수 있다(C 단계). 일 예로, 도 2를 참조하면, 프로세서는 상기 실제 수술 영상의 제1 프레임에 매칭되는 가상 현실 기반의 제1_1 프레임에서 상기 수행된 동일점 매칭 결과에 따라 상기 가상 수술 도구가 가상 현실 기반에서 디폴 트 프레임에 도시된 바와 같이 위치하여 있다가 제1_1 프레임에 도시된 바와 같이 위치하도록 보정할 수 있다. 또한, 프로세서는 상기 실제 수술 영상의 제2 프레임에 매칭되는 가상 현실 기반의 제2_1 프레임에서 상기 수행된 동일점 매칭 결과에 따라 상기 가상 수술 도구가 가상 현실 기반에서 제1_1 프레임에 도시된 바와 같이 위치하여 있다가 제2_1 프레임에 도시된 바와 같이 위치하도록 보정할 수 있다. 다른 예로, 도 4를 참조하면, 프로세서는 상기 보정된 가상 수술 도구의 위치에 해당 3차원 깊이값을 부여 하여 상기 가상 수술 도구를 3차원 객체로 렌더링할 수 있다. 그리고, 프로세서는 상기 기 설정된 프레임 마다 상기 3차원 객체로 렌더링된 상기 가상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출할 수 있 다. 여기서, 프로세서는 입체경 카메라를 통해 촬영된 깊이맵을 가지는 실제 수술 영상(예컨대, Stereoscope 영상)을 활용한 경우 더욱 정확한 렌더링 결과 획득이 가능한 효과를 가질 수 있다. 프로세서는 상기 보정된 상기 가상 수술 도구의 좌표값을 산출할 수 있다(D 단계). 일 예로, 도 2을 참조하면, 프로세서는 가상 현실 기반의 제1_1 프레임에서 상기 가상 수술 도구의 제1 좌 표값(X_v1, Y_v1, Z_v1)을 산출할 수 있다. 또한, 프로세서는 가상 현실 기반의 제2_1 프레임에서 상기 가 상 수술 도구의 제2 좌표값(X_v2, Y_v2, Z_v2)을 산출할 수 있다. 또한, 프로세서는 가상 현실 기반의 제 N-1_1 프레임에서 상기 가상 수술 도구의 제N-1 좌표값(X_vn-1, Y_vn-1, Z_vn-1)을 산출할 수 있다. 또한, 프 로세서는 가상 현실 기반의 제N_1 프레임에서 상기 가상 수술 도구의 제N 좌표값(X_vn, Y_vn, Z_vn)을 산 출할 수 있다. 다른 예로, 도 4을 참조하면, 프로세서는 가상 현실 기반의 제1_1 프레임에서 상기 가상 수술 도구의 제1 좌표값(X_v1, Y_v1, Z_v1, D_v1)을 산출할 수 있다. 또한, 프로세서는 가상 현실 기반의 제2_1 프레임에서 상기 가상 수술 도구의 제2 좌표값(X_v2, Y_v2, Z_v2, D_v2)을 산출할 수 있다. 또한, 프로세서는 가상 현 실 기반의 제N-1_1 프레임에서 상기 가상 수술 도구의 제N-1 좌표값(X_vn-1, Y_vn-1, Z_vn-1, D_vn-1)을 산출 할 수 있다. 또한, 프로세서는 가상 현실 기반의 제N_1 프레임에서 상기 가상 수술 도구의 제N 좌표값 (X_vn, Y_vn, Z_vn, D_vn-1)을 산출할 수 있다. 여기서, 프로세서는 가상 현실 기반의 제1_1 내지 제 N_1 프레임에서 상기 가상 수술 도구의 제1 내지 제N 좌표값을 산출할 때 깊이값을 부여함으로써 3차원의 깊이감을 가지는 가상 수술 도구를 표시할 수 있다. 또한, 프로세서는 상기 3차원 깊이값이 부여된 후 상기 보정된 가상 수술 도구의 위치에 해당하는 좌표값 내에 상기 3차원 깊이값을 포함시켜 저장할 수 있다. 즉, 프로세서는 상기 A 내지 D 단계를 반복 수행하여, 상기 기 설정된 프레임 마다 상기 가상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출할 수 있다. 프로세서는 상기 산출된 복수의 좌표값 간의 차이를 기반으로 복수의 로그 정보를 생성할 수 있다. 보다 상세하게는, 프로세서는 상기 복수의 좌표값이 산출될 때마다 이전에 산출된 좌표값과 이후에 산출된 좌표값 간의 차이에 대한 로그 정보를 순차적으로 생성할 수 있다. 일 예로, 도 3을 참조하면, 프로세서는 제1 좌표값(X_v1, Y_v1, Z_v1)과 제2 좌표값(X_v2, Y_v2, Z_v2) 간의 차이에 대한 로그 정보인 제1 로그 정보(X_v2-X_v1, Y_v2-Y_v1, Z_v2-Z_v1)를 생성할 수 있다. 이처럼, 프로세서는 하나의 프레임과 상기 하나의 프레임 바로 뒤 프레임 좌표값 간의 차이에 대한 로그 정보를 순 차적으로 계속 생성할 수 있다. 즉, 프로세서는 제N 좌표값(X_vn, Y_vn, Z_vn)과 제N-1 좌표값(X_vn-1, Y_vn-1, Z_vn-1) 간의 차이에 대한 로그 정보인 제N-1 로그 정보(X_vn-X_vn-1, Y_vn-Y_vn-1, Z_vn-Z_vn-1)까지 생성할 수 있다. 다른 예로, 도 5를 참조하면, 프로세서는 제1 좌표값(X_v1, Y_v1, Z_v1, D_v1)과 제2 좌표값(X_v2, Y_v2, Z_v2, D_v2) 간의 차이에 대한 깊이값이 포함되는 로그 정보인 제1 로그 정보(X_v2-X_v1, Y_v2-Y_v1, Z_v2- Z_v1, D_v2-D_v1)를 생성할 수 있다. 이처럼, 프로세서는 하나의 프레임과 상기 하나의 프레임 바로 뒤 프레임 좌표값 간의 차이에 대한 로그 정보를 순차적으로 계속 생성할 수 있다. 즉, 프로세서는 제N 좌표값 (X_vn, Y_vn, Z_vn, D_vn)과 제N-1 좌표값(X_vn-1, Y_vn-1, Z_vn-1, D_vn-1) 간의 차이에 대한 깊이값이 포함 되는 로그 정보인 제N-1 로그 정보(X_vn-X_vn-1, Y_vn-Y_vn-1, Z_vn-Z_vn-1, D_푸-D_푸-1)까지 생성할 수 있다. 프로세서는 상기 순차적으로 생성된 로그 정보를 상기 메모리에 누적하여 저장할 수 있다. 보다 상세하게는, 프로세서는 상기 순차적으로 생성된 로그 정보 간의 차이가 기 설정된 차이 이상인 경우 에만, 현재 생성된 로그 정보를 누적 저장할 수 있다. 즉, 프로세서는 제1 프레임에서 제2 프레임으로 넘어가면서 생성되는 제1 로그정보가 제2 프레임에서 제3 프레임으로 넘어가면서 생성되는 제2 로그정보와 기 설정된 차이 미만인 경우, 그대로 제1 로그정보 한번 더 저 장할 수 있다. 반대로, 프로세서는 제7 프레임에서 제8 프레임으로 넘어가면서 생성되는 제7 로그 정보가 기 설정된 차이 이상인 경우, 앞에서 생성되었던 제6 로그 정보를 누적하여 저장하지 않고, 제7 로그 정보를 누 적 저장할 수 있다. 프로세서는 상기 누적 저장된 로그 정보를 기반으로 상기 실제 수술 영상 내의 현재 프레임에서 다음 프레 임에 변경되는 실제 수술 도구의 움직임을 예측할 수 있다. 프로세서는 상기 예측된 움직임을 나타내는 시각 효과를 상기 실제 수술 영상 내의 현재 프레임 상의 상기 움직임에 해당하는 위치에 표시할 수 있다. 보다 상세하게는, 프로세서는 상기 저장된 실제 수술 영상의 각각의 프레임 상에 상기 예측된 움직임을 나 타내는 시각 효과를 상기 실제 수술 도구의 다음 프레임에서의 움직임에 해당하는 위치에 표시할 수 있다. 일 예로, 도 6a를 보면, 프로세서는 상기 실제 수술 영상 내의 제1 프레임에서 제2 프레임에 변경되는 실 제 수술 도구의 움직임을 예측하고, 상기 예측된 움직임을 나타내는 화살표 모양의 마커로 제1 시각 효과 를 제1 프레임에 상기 움직임에 해당하는 위치에 표시할 수 있다. 다른 예로, 도 6b를 보면, 프로세서는 상기 실제 수술 영상 내의 제1 프레임에서 제2 프레임에 변경되는 실제 수술 도구의 움직임을 예측하고, 상기 예측된 움직임을 나타내는 블링킹(Blinking) 형태로 제1 시각 효과를 제1 프레임에 상기 움직임에 해당하는 위치에 표시할 수 있다. 또 다른 예로, 도 6c를 보면, 프로세서는 상기 실제 수술 영상 내의 제1 프레임에서 제2 프레임에 변경되 는 실제 수술 도구의 움직임을 예측하고, 상기 예측된 움직임을 나타내는 반 투명의 실제 수술 도구형태로 제1 시각 효과를 제1 프레임에 상기 움직임에 해당하는 위치에 표시할 수 있다. 따라서, 프로세서는 예측된 실제 수술 도구의 움직임을 상기 실제 수술 영상에 표시함으로 사용자들 이 상기 실제 수술 영상을 보면서 수술을 연습할 때 유도 수술을 제공할 수 있어서 확실하고 실질적인 도움을 줄 수 있는 효과가 있다. 프로세서는 상기 로그 정보를 통해 상기 로그 정보가 생성된 상기 실제 수술 영상에 대해 수술 종류를 판 단하고, 상기 판단된 수술 종류에 따라 동일한 종류의 로봇을 통한 수술이 시행되는 경우, 상기 로그 정보를 이 용하여 상기 로봇을 원격 조정할 수 있다. 프로세서는 상기 로그 정보를 통해 상기 실제 수술 영상에 대한 수술 분석을 수행할 수 있다. 보다 상세하 게는, 프로세서는 상기 로그 정보 중 이전에 생성된 로그 정보와 바로 이후에 생성된 로그 정보와의 차이 가 기 설정되 차이 이상인 경우, 이벤트 발생인 것으로 판단할 수 있다. 이에 따라, 프로세서는 상기 실제 수술 영상에 대해 구체적인 수술 과정을 판단할 수 있다. 도 7은 본 발명에 따른 장치의 프로세서가 가상 현실 기반의 수술 환경을 제공하는 과정을 나타낸 흐 름도이다. 도 8은 본 발명에 따른 장치의 프로세서가 동일점 매칭을 수행하는 과정을 나타낸 흐름도이다. 도 7 내지 도 8에서 프로세서의 동작은 장치에서 수행 가능하다. 프로세서는 실제 수술 영상 내의 프레임 마다 적어도 하나의 실제 수술 도구를 인식할 수 있다(S701). 구체적으로, 프로세서는 제1 인공지능 모델을 기반으로 실제 수술 영상 내의 기 설정된 프레임 마다 상기 실제 수술 영상 내에 포함된 적어도 하나의 실제 수술 도구를 인식할 수 있다. 프로세서는 상기 실제 수술 도구 및 가상 현실 기반의 가상 수술 도구에 대해 동일점 매칭(Correspondence matching)을 수행할 수 있다(S702). 구체적으로, 프로세서는 상기 실제 수술 도구 및 가상 현실 기반의 상기 실제 수술 도구에 대응되는 적어 도 하나의 가상 수술 도구의 적어도 하나의 동일 부위에 대해 동일점 매칭(Correspondence matching)을 수행할 수 있다. 단계 S702에 대해, 보다 상세하게는, 도 8을 보면, 프로세서는 상기 실제 수술 도구의 적어도 하나의 부위 를 제1 기준점으로 설정할 수 있다(S801). 프로세서는 시멘틱(semantic) 동일점 매칭 기법을 이용하여, 상기 가상 수술 도구에서 상기 실제 수술 도 구의 적어도 하나의 부위와 동일한 부위를 제2 기준점으로 설정할 수 있다(S802). 프로세서는 상기 제1 및 제2 기준점을 이용하여 상기 동일점 매칭을 수행할 수 있다(S803). 프로세서는 상기 수행된 동일점 매칭 결과에 따라, 상기 가상 수술 도구가 상기 실제 수술 도구의 위치에 대응되도록 보정할 수 있다(S703). 프로세서는 상기 보정된 상기 가상 수술 도구의 좌표값을 산출할 수 있다(S704). 프로세서는 단계 S701 내지 단계 S704를 반복 수행하여, 상기 기 설정된 프레임 마다 상기 가상 수술 도구 가 보정되는 위치에 대한 복수의 좌표값을 산출할 수 있다(S705). 여기서, 프로세서는 상기 실제 수술 영상이 입체경 카메라를 통해 촬영되어 3차원 깊이값을 가지는 경 우, 상기 보정된 가상 수술 도구의 위치에 해당 3차원 깊이값을 부여하여 상기 가상 수술 도구를 3차원 객체로 렌더링할 수 있다. 그리고, 프로세서는 상기 기 설정된 프레임 마다 상기 3차원 객체로 렌더링된 상기 가 상 수술 도구가 보정되는 위치에 대한 복수의 좌표값을 산출할 수 있다. 프로세서는 상기 산출된 복수의 좌표값 간의 차이를 기반으로 복수의 로그 정보를 생성할 수 있다(S706). 보다 상세하게는, 프로세서는 상기 복수의 좌표값이 산출될 때마다 이전에 산출된 좌표값과 이후에 산출된 좌표값 간의 차이에 대한 로그 정보를 순차적으로 생성할 수 있다. 또는, 프로세서는 상기 3차원 깊이값이 포함되어 산출된 복수의 좌표값 간의 차이를 기반으로 상기 3차원 깊이값이 부여된 복수의 로그 정보를 생성할 수 있다. 프로세서는 상기 순차적으로 생성된 로그 정보를 메모리에 누적하여 저장할 수 있다(S707). 보다 상세하게는, 프로세서는 상기 순차적으로 생성된 로그 정보 간의 차이가 기 설정된 차이 이상인 경우 에만, 현재 생성된 로그 정보를 누적 저장할 수 있다. 프로세서는 상기 누적 저장된 로그 정보를 기반으로 상기 실제 수술 영상 내의 현재 프레임에서 다음 프레 임에 변경되는 실제 수술 도구의 움직임을 예측할 수 있다(S708). 프로세서는 상기 예측된 움직임을 나타내는 시각 효과를 상기 실제 수술 영상 내의 현재 프레임 상의 상기 움직임에 해당하는 위치에 표시할 수 있다(S709). 도 7 내지 8은 복수의 단계를 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 실시예의 기술 사상을 예"}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술분야에서 통상의 지식을 가진 자라면 본 실시 예의 본질적인 특성에서 벗어나지 않는 범위에서 도 7 내지 8에 기재된 순서를 변경하여 실행하거나 복수의 단 계 중 하나 이상의 단계를 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이므로, 도 7 내지 8은 시계열적인 순서로 한정되는 것은 아니다. 이상에서 전술한 본 발명에 따른 방법은, 하드웨어인 서버와 결합되어 실행되기 위해 프로그램(또는 애플리케이 션)으로 구현되어 매체에 저장될 수 있다. 상기 전술한 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, 기 계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필요 한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들을 상기컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있다. 또한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨 터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠 한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어 떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는지 등 에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다."}
{"patent_id": "10-2023-0043622", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0043622", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 가상 현실 기반의 수술 환경을 제공하는 장치를 설명하기 위한 도면이다. 도 2는 본 발명에 따른 장치의 프로세서가 실제 수술 영상을 통해 가상 현실 기반의 가상 수술 도구의 좌표값을 산출하는 것을 설명하기 위한 도면이다. 도 3은 본 발명에 따른 장치의 프로세서가 실제 수술 영상을 통해 가상 현실 기반의 가상 수술 도구의 로그 정 보를 생성하는 것을 설명하기 위한 도면이다. 도 4는 본 발명에 따른 장치의 프로세서가 깊이값이 적용되는 실제 수술 영상을 통해 가상 현실 기반의 가상 수 술 도구의 좌표값을 산출하는 것을 설명하기 위한 도면이다.도 5는 본 발명에 따른 장치의 프로세서가 깊이값이 적용되는 실제 수술 영상을 통해 가상 현실 기반의 가상 수 술 도구의 로그 정보를 생성하는 것을 설명하기 위한 도면이다. 도 6은 본 발명에 따른 장치의 프로세서가 실제 수술 영상에 예측된 움직임을 나타내는 시각 효과를 표시하는 것을 설명하기 위한 도면이다. 도 7은 본 발명에 따른 장치의 프로세서가 가상 현실 기반의 수술 환경을 제공하는 과정을 나타낸 흐름도이다. 도 8은 본 발명에 따른 장치의 프로세서가 동일점 매칭을 수행하는 과정을 나타낸 흐름도이다."}
