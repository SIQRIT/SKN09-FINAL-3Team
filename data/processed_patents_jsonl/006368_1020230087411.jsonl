{"patent_id": "10-2023-0087411", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0007365", "출원번호": "10-2023-0087411", "발명의 명칭": "단일 모델을 이용한 여러 유형의 데이터 생성방법 및 이를 이용한 시스템", "출원인": "한양대학교 산학협력단", "발명자": "박종규"}}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "외부에서 수집되는 다양한 유형의 입력 데이터를 가공하는 단계;상기 가공된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰을 입력하여 시계열화된출력 데이터를 생성하도록 인공지능 모델을 학습하는 단계; 및사용자가 생성하고자 하는 유형 정보를 입력하면, 상기 학습된 인공지능 모델로부터 상기 유형 정보에 기초한출력 데이터를 생성하는 단계;를 포함하고,상기 입력 데이터를 가공하는 단계는,미리 설정된 기준값에 기초하여 상기 입력 데이터를 코드화하고, 상기 코드화된 입력 데이터를 시계열화하고,상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마스킹 처리를 수행하는 것;을포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 입력 데이터를 가공하는 단계는,상기 입력 데이터를 헥스 코드로 변환하는 것;을 포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 입력 데이터를 가공하는 단계는,상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추가하고, 상기 클래스 토큰이 추가된 입력 데이터에 마스킹 처리를 수행하는 것;을 포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 입력 데이터를 가공하는 단계는,상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상기 시계열화된 입력 데이터에 상기 스톱 토큰을 추가하는 것;을 포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 인공지능 모델은, 트랜스포머 디코더 및 분배기를 포함하고,상기 인공지능 모델을 학습하는 단계는,상기 클래스 토큰 및 상기 가공된 입력 데이터에 기초하여 상기 트랜스포머 디코더가 확률값을 출력하고, 상기분배기가 확률값에 기초하여 새로운 출력 데이터를 예측하고, 측정된 손실함수가 낮아지는 방향으로 학습을 진행하는 것;을 포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,공개특허 10-2025-0007365-3-상기 출력 데이터를 생성하는 단계는,상기 학습된 인공지능 모델이 추론하는 데이터를 샘플링하고, 상기 샘플링된 데이터를 시계열로 정렬하는 것;을포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "프로세서;와 인공지능 모델 및 외부에서 수집되는 다양한 유형의 입력 데이터를 저장하는 메모리;를 포함하고,상기 프로세서는,상기 입력 데이터를 가공하고, 상기 가공된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰을 입력하여 시계열화된 출력 데이터를 생성하도록 상기 인공지능 모델을 학습시키고, 사용자가 생성하고자 하는 유형 정보를 입력하면, 상기 학습된 인공지능 모델로부터 상기 유형 정보에 기초한 출력 데이터를 생성하고,상기 프로세서는,헥스 코드에 기초하여 상기 입력 데이터를 코드화하고, 상기 코드화된 입력 데이터를 시계열화하고, 상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마스킹 처리를 수행함으로써, 입력 데이터를 가공하는 데이터 생성 시스템."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 프로세서는, 상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추가하고, 상기 클래스 토큰이 추가된 입력 데이터에 마스킹 처리를 수행하는 데이터 생성 시스템."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 프로세서는,상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상기 시계열화된 입력 데이터에 상기 스톱 토큰을 추가하는 데이터 생성 시스템."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7항에 있어서,상기 인공지능 모델은, 트랜스포머 디코더 및 분배기를 포함하고,상기 프로세서는,상기 클래스 토큰 및 상기 가공된 입력 데이터에 기초하여 상기 트랜스포머 디코더가 확률값을 출력하고, 상기분배기가 확률값에 기초하여 새로운 출력 데이터를 예측하고, 측정된 손실함수가 낮아지는 방향으로 학습을 진행하는 데이터 생성 시스템."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7항에 있어서,상기 프로세서는,학습된 인공지능 모델이 추론하는 데이터를 샘플링하고, 상기 샘플링된 데이터를 시계열로 정렬하는 데이터 생성 시스템."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "사용자로부터 유형 정보를 수신하는 입력부;공개특허 10-2025-0007365-4-프로세서와 인공지능 모델 및 외부에서 수집되는 다양한 유형의 입력 데이터를 저장하는 메모리를 포함하는 제어부;상기 인공지능 모델이 생성하는 출력 데이터 중 이미지 데이터를 출력하는 디스플레이; 및상기 인공지능 모델이 생성하는 출력 데이터 중 음성 데이터를 출력하는 스피커;를 포함하고,상기 제어부는,헥스 코드에 기초하여 상기 입력 데이터를 코드화하고, 상기 코드화된 입력 데이터를 시계열화하고, 상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마스킹 처리를 수행함으로써, 입력 데이터를 가공하고, 상기 가공된 입력 데이터 및 상기 유형 정보를 포함한 클래스 토큰을 입력하고, 시계열화된 출력 데이터를 생성하도록 상기 인공지능 모델을 학습시키고, 상기 유형 정보에 기초하여 상기 출력 데이터를 생성하도록 상기 학습된 인공지능 모델을 제어하는 데이터 생성장치."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 제어부는,상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추가하고, 상기 클래스 토큰이 추가된 입력 데이터에 마스킹 처리를 수행하고,상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상기 시계열화된 입력 데이터에 상기 스톱 토큰을 추가하는 데이터 생성 장치."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12항에 있어서,상기 인공지능 모델은, 트랜스포머 디코더 및 분배기를 포함하고,상기 제어부는,상기 클래스 토큰 및 상기 가공된 입력 데이터에 기초하여 상기 트랜스포머 디코더가 확률값을 출력하고, 상기분배기가 확률값에 기초하여 새로운 출력 데이터를 예측하고, 측정된 손실함수가 낮아지는 방향으로 학습을 진행하는 데이터 생성 장치."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 12항에 있어서,상기 제어부는,학습된 인공지능 모델이 추론하는 데이터를 샘플링하고, 상기 샘플링된 데이터를 시계열로 정렬하는 데이터 생성 장치."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "외부로부터 수신되는 다양한 유형의 입력 데이터를 가공하고, 상기 가공된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰을 입력하여 시계열화된 출력 데이터를 생성하도록 인공지능 모델을 학습시키는 제1 단계; 및사용자가 생성하고자 하는 유형 정보를 입력하면, 상기 학습된 인공지능 모델로부터 상기 유형 정보에 기초한출력 데이터를 생성하는 제2 단계;를 포함하고,상기 제1 단계는,공개특허 10-2025-0007365-5-미리 설정된 기준값에 기초하여 상기 입력 데이터를 코드화하고, 상기 코드화된 입력 데이터를 시계열화하고,상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마스킹 처리를 수행하는 데이터생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서,제 1단계는,상기 입력 데이터를 헥스 코드로 변환하고,상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추가하고, 상기 클래스 토큰이 추가된 입력 데이터에 마스킹 처리를 수행하는 것;을 포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17항에 있어서,제 1단계는,상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상기 시계열화된 입력 데이터에 상기 스톱 토큰을 추가하는 것;을 포함하는 데이터 생성 방법."}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개시된 일 실시예에 따른 데이터 생성 방법은, 외부에서 수집되는 다양한 유형의 입력 데이터를 가공하는 단계; 상기 가공된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰을 입력하여 시계열화된 출력 데이터를 생성하도록 인공지능 모델을 학습하는 단계; 및 사용자가 생성하고자 하는 유형 정보를 입력하면, 상기 학습된 인공지능 모델로부터 상기 유형 정보에 기초한 출력 데이터를 생성하는 단계;를 포함하고, 상기 입 력 데이터를 가공하는 단계는, 미리 설정된 기준값에 기초하여 상기 입력 데이터를 코드화하고, 상기 코드화된 입력 데이터를 시계열화하고, 상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마 스킹 처리를 수행하는 것;을 포함한다."}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 일 실시예는 인공지능 모델이 다양한 유형의 학습 데이터를 학습하고, 하나의 인공지능 모델에서 다양한 유형의 데이터를 생성할 수 있는 데이터 생성 기법에 관한 것이다."}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 모델에 대한 개발과 연구가 활발히 진행되고 있다. 특히, 여러 학습 데이터 또는 샘플을 이용하 여 학습한 인공지능 모델이 새로운 데이터를 생성하는 생성 AI(Artificial Intelligence)에 대한 연구 및 개발 이 활발히 진행되고 있다. 예를 들어, GAN(Generative Adversarial Network)는 생성자(Generator) 및 판별자(Discriminator)를 이용한 적 대적 생성 모델로, 이미지 또는 가상현실의 환경을 생성하는데 사용된다. 다른 예로, VAE(Variational Autoencoder)는 저차원의 잠재공간을 인코딩하여 원본 데이터를 재구성하는 모델로, 음성 및 텍스트 등의 데이 터를 생성하는데 사용된다. Diffusion은 확률적 모델링에 의해서 이미지 생성, 이미지의 노이즈 제거 등에 주로 활용된다. 이렇게 다양한 데이터 생성 모델은 특정 유형의 데이터를 생성하는데 특화되어 있으며, 데이터를 생성하기 위해 서 각 모델은 생성하고자 하는 데이터의 유형에 상응하는 모델링 및 일정 수준 이상의 메모리 공간이 필요하다 는 한계가 있다. 구체적으로 GAN은 이미지 및 음성 데이터 생성이 가능하나, 실질적으로 GAN을 이용하여 이미지 데이터를 생성하기 위해 모델링이 수행되면, 모델링된 GAN은 이미지 데이터만을 생성할 뿐, 음성 데이터를 생성 하기 어렵다. 또한, 종래 생성 모델을 활용하여 다양한 크기의 데이터를 생성하기 위해서는 전처리 과정에서 데이터의 크기를 강제로 일치시키거나, 후처리를 통해 데이터의 크기를 다시 조절해야 하기 때문에 생성되는 데이터의 품질에 악 영향을 끼치는 경우가 있었다."}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 일 실시예에 따르면, 다양한 유형의 데이터를 헥스 코드(Hex Code)로 변환 및 시계열화하여 배치 내에 필요한 마스킹 전처리를 수행한 후, 데이터 생성 모델을 학습시킴으로써, 단일 모델에서도 다양한 유형의 데이터를 생성할 수 있는 데이터 생성방법 및 이를 이용한 시스템에 관한 것이다."}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시된 일 실시예에 따른 데이터 생성 방법은, 외부에서 수집되는 다양한 유형의 입력 데이터를 가공하는 단계; 상기 가공된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰을 입력하여 시계열화된 출력 데이터를 생성하도록 인공지능 모델을 학습하는 단계; 및 사용자가 생성하고자 하는 유형 정보를 입력하면, 상기 학습된 인공지능 모델로부터 상기 유형 정보에 기초한 출력 데이터를 생성하는 단계;를 포함하 고, 상기 입력 데이터를 가공하는 단계는, 미리 설정된 기준값에 기초하여 상기 입력 데이터를 코드화하고, 상 기 코드화된 입력 데이터를 시계열화하고, 상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마스킹 처리를 수행하는 것;을 포함한다. 상기 입력 데이터를 가공하는 단계는, 상기 입력 데이터를 헥스 코드로 변환하는 것;을 포함할 수 있다. 상기 입력 데이터를 가공하는 단계는, 상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추가하고, 상기 클래 스 토큰이 추가된 입력 데이터에 마스킹 처리를 수행하는 것;을 포함할 수 있다. 상기 입력 데이터를 가공하는 단계는, 상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상 기 시계열화된 입력 데이터에 상기 스톱 토큰을 추가하는 것;을 포함할 수 있다. 상기 인공지능 모델은, 트랜스포머 디코더 및 분배기를 포함하고, 상기 인공지능 모델을 학습하는 단계는, 상기 클래스 토큰 및 상기 가공된 입력 데이터에 기초하여 상기 트랜스 포머 디코더가 확률값을 출력하고, 상기 분배기가 확률값에 기초하여 새로운 출력 데이터를 예측하고, 측정된 손실함수가 낮아지는 방향으로 학습을 진행하는 것;을 포함할 수 있다. 상기 출력 데이터를 생성하는 단계는, 상기 학습된 인공지능 모델이 추론하는 데이터를 샘플링하고, 상기 샘플 링된 데이터를 시계열로 정렬하는 것;을 포함할 수 있다. 개시된 다른 실시예에 따른 데이터 생성 시스템은, 프로세서;와 인공지능 모델 및 외부에서 수집되는 다양한 유 형의 입력 데이터를 저장하는 메모리;를 포함하고, 상기 프로세서는, 상기 입력 데이터를 가공하고, 상기 가공 된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰을 입력하여 시계열화된 출력 데 이터를 생성하도록 상기 인공지능 모델을 학습시키고, 사용자가 생성하고자 하는 유형 정보를 입력하면, 상기 학습된 인공지능 모델로부터 상기 유형 정보에 기초한 출력 데이터를 생성하고, 헥스 코드에 기초하여 상기 입 력 데이터를 코드화하고, 상기 코드화된 입력 데이터를 시계열화하고, 상기 인공지능 모델의 배치 사이즈에 기 초하여 상기 시계열화된 입력 데이터의 마스킹 처리를 수행함으로써, 입력 데이터를 가공한다. 상기 프로세서는, 상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추가하고, 상기 클래스 토큰이 추가된 입 력 데이터에 마스킹 처리를 수행할 수 있다. 상기 프로세서는, 상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상기 시계열화된 입력 데이터에 상기 스톱 토큰을 추가할 수 있다. 상기 인공지능 모델은, 트랜스포머 디코더 및 분배기를 포함하고, 상기 프로세서는, 상기 클래스 토큰 및 상기 가공된 입력 데이터에 기초하여 상기 트랜스포머 디코더가 확률값을 출력하고, 상기 분배기가 확률값에 기초하 여 새로운 출력 데이터를 예측하고, 측정된 손실함수가 낮아지는 방향으로 학습을 진행할 수 있다. 상기 프로세서는, 학습된 인공지능 모델이 추론하는 데이터를 샘플링하고, 상기 샘플링된 데이터를 시계열로 정 렬할 수 있다. 개시된 또 다른 실시예에 따른 데이터 생성 장치는, 사용자로부터 유형 정보를 수신하는 입력부; 프로세서와 인 공지능 모델 및 외부에서 수집되는 다양한 유형의 입력 데이터를 저장하는 메모리를 포함하는 제어부; 인공지능 모델이 생성하는 출력 데이터 중 이미지 데이터를 출력하는 디스플레이; 및 상기 인공지능 모델이 생성하는 출 력 데이터 중 음성 데이터를 출력하는 스피커;를 포함하고, 상기 제어부는, 헥스 코드에 기초하여 상기 입력 데 이터를 코드화하고, 상기 코드화된 입력 데이터를 시계열화하고, 상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마스킹 처리를 수행함으로써, 입력 데이터를 가공하고, 상기 가공된 입력 데이 터 및 상기 유형 정보를 포함한 클래스 토큰을 입력하고, 시계열화된 출력 데이터를 생성하도록 상기 인공지능 모델을 학습시키고, 상기 유형 정보에 기초하여 상기 출력 데이터를 생성하도록 상기 학습된 인공지능 모델을제어한다. 상기 제어부는, 상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추가하고, 상기 클래스 토큰이 추가된 입력 데이터에 마스 킹 처리를 수행하고, 상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상기 시계열화된 입 력 데이터에 상기 스톱 토큰을 추가할 수 있다. 상기 인공지능 모델은, 트랜스포머 디코더 및 분배기를 포함하고, 상기 제어부는, 상기 클래스 토큰 및 상기 가 공된 입력 데이터에 기초하여 상기 트랜스포머 디코더가 확률값을 출력하고, 상기 분배기가 확률값에 기초하여 새로운 출력 데이터를 예측하고, 측정된 손실함수가 낮아지는 방향으로 학습을 진행할 수 있다. 상기 제어부는, 학습된 인공지능 모델이 추론하는 데이터를 샘플링하고, 상기 샘플링된 데이터를 시계열로 정렬 할 수 있다. 개시된 다른 실시예에 따른 데이터 생성 방법은, 외부로부터 수신되는 다양한 유형의 입력 데이터를 가공하고, 상기 가공된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰을 입력하여 시계열화된 출력 데이터를 생성하도록 상기 인공지능 모델을 학습시키는 제1 단계; 및 사용자가 생성하고자 하는 유형 정보 를 입력하면, 상기 학습된 인공지능 모델로부터 상기 유형 정보에 기초한 출력 데이터를 생성하는 제2 단계;를 포함하고, 상기 제1 단계는, 미리 설정된 기준값에 기초하여 상기 입력 데이터를 코드화하고, 상기 코드화된 입 력 데이터를 시계열화하고, 상기 인공지능 모델의 배치 사이즈에 기초하여 상기 시계열화된 입력 데이터의 마스 킹 처리를 수행한다. 제 1단계는, 상기 입력 데이터를 헥스 코드로 변환하고, 상기 시계열화된 입력 데이터에 상기 클래스 토큰을 추 가하고, 2상기 클래스 토큰이 추가된 입력 데이터에 마스킹 처리를 수행하는 것;을 포함할 수 있다. 제 1단계는, 상기 인공지능 모델의 배치 사이즈에 기초하여 스톱 토큰을 생성하고, 상기 시계열화된 입력 데이 터에 상기 스톱 토큰을 추가하는 것;을 포함할 수 있다."}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 일 실시예에 따른 단일 모델을 이용한 여러 유형의 데이터 생성방법 및 이를 이용한 시스템은 다양한 유 형의 데이터를 헥스 코드로 변환 및 시계열화하여 배치 내에 필요한 마스킹 전처리를 수행한 후, 데이터 생성 모델을 학습시킴으로써, 단일 모델에서도 다양한 유형의 데이터를 생성할 수 있다."}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2023-0087411", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 발명의 작용 원리 및 실시예들에 대해 설명한다. 도 1은 개시된 일 실시예에 따른 데이터 생성 시스템을 개략적으로 설명하기 위한 도면이다. 개시된 데이터 생성 시스템은 여러 유형 정보를 포함하는 입력 데이터를 학습한다. 종래 일반적인 생성 AI는 인공지능 모델이 학습한 하나의 유형의 데이터를 계속적으로 생성하는데 반해, 개시된 데이터 생성 시스템은 여러 유형 정보를 포함하는 데이터를 생산할 수 있다. 구체적으로 데이터 생성 시스템이 학습하는 여러 유형 정보는, 이미지, 동영상 또는 음성 파일 등 다양한 입 력 데이터를 포함할 수 있다. 도 1에서 도신된 바와 같이, 데이터 생성 시스템은 28 x 28 크기를 가진 신발 이미지 파일 뿐만 아니라, 1000kbyte의 크기와 발표문을 내용으로 하는 음성 파일을 학습 데이터로 사용할 수 있다. 도 1에서 도시되지 않았지만, 데이터 생성 시스템은 서로 다른 유형의 데이터뿐만 아니라, 같은 유형 의 데이터라도, 파일의 크기가 다른 데이터(예를 들어, 14 x 14 크기를 가진 이미지 데이터를 학습 데이터로 사 용할 수 있다. 데이터 생성 시스템은 서로 다른 유형의 입력 데이터를 학습한 후, 사용자의 입력에 따라 서로 다른 유형의 출력 데이터를 생성한다. 예를 들어, 사용자가 신발을 포함하는 이미지 데이터의 생성을 요청하는 경우, 학습이 완료된 데이터 생성 시스템은 추론 때마다 서로 다른 신발 모양을 포함한 이미지(제1 이미지, 제2 이미지)를 생성할 수 있다. 만약 사용자가 음성 데이터의 생성을 요청하는 경우라도, 학습이 완료된 데이터 생성 시스템 은 이미지가 아닌 음성 데이터를 생성할 수도 있다. 도 2는 개시된 데이터 생성 시스템의 하드웨어적 구성을 설명하기 위한 제어 블록도이다. 도 2를 참조하면, 데이터 생성 시스템은 사용자로부터 유형 정보를 포함한 사용자 명령을 수신받는 입력부 , 데이터 생성 시스템의 전반을 제어하는 제어부, 제어부가 생성하는 출력 데이터를 표시하는 디 스플레이, 제어부가 생성하는 출력 데이터가 음성 파일인 경우 소리를 출력하는 스피커를 포함한다. 구체적으로 입력부는 사용자로부터 인공지능 모델의 학습 개시 명령, 생성하고자 하는 출력 데이터의 유형 정보를 포함한 다양한 사용자 명령을 수신할 수 있다. 일 예에 따라, 사용자는 학습이 완료된 데이터 생성 시스 템에게 유형 정보를 입력하고, 데이터 생성 시스템은 유형 정보에 맞는 출력 데이터를 생성한다. 여기서 유형 정보는 생성할 데이터의 종류(예를 들어, 이미지 파일) 및 데이터의 크기(예를 들어 28 x 28)를 포함하는 정보이다. 다른 예로, 입력부는 유형 정보 뿐만 아니라, 생성될 출력 데이터의 구체적인 내용 정보(예를 들 어, 신발 이미지)를 수신할 수도 있다. 전술한 동작을 위해서 입력부는 사용자의 입력 명령을 수신하기 위한 각종 버튼(buton), 입력 포트(port), 키보드, 마우스, 트랙볼(track-ball), 각종 레버(lever), 핸들(handle)이나 스틱(stick) 등과 같은 하드웨어적 인 장치를 포함할 수 있다. 제어부는 데이터 생성 시스템이 입력 데이터를 학습하고, 학습이 완료된 후 출력 데이터를 생성(또는 추 론)하는 일련의 모든 동작을 제어한다. 구체적으로 제어부는 외부에서 수집되는 다양한 유형의 입력 데이터를 가공하고, 가공된 입력 데이터 및 생 성하고자 하는 데이터의 유형 정보를 포함한 클래스 토큰(Class Token)을 입력하여 시계열화된 출력 데이터를 생성하도록 인공지능 모델을 학습시킨다. 사용자가 생성하고자 하는 유형 정보를 입력하면, 제어부는 학습 된 인공지능 모델로부터 유형 정보에 기초한 출력 데이터를 생성한다. 제어부의 동작에 대한 구체적인 내용 은 이하의 다른 도면을 통해 후술한다. 제어부는 전술한 데이터 생성 방법을 실행하는 것 뿐만 아니라 입력부, 디스플레이 및 스피커 등 데이터 생성 시스템의 구성을 제어하는 프로세서 및 인공지능 모델의 학습에 필요한 입력 데이터, 학 습 전후의 인공지능 모델, 생성된 다양한 유형의 출력 데이터를 저장하는 메모리로 구성될 수 있다. 프로세서는 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회 로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미한다. 프로세서의 일 예로서, 마이크로프로세서 (microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세 서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array), GPU(Graphics Processing Unit) 등의 처리 장치를 망라할 수 있으나, 이에 한정되는 것은 아니다. 프 로세서는 반드시 단일 개로 마련될 필요는 없으며, 복수 개의 프로세서를 포함할 수 있다. 메모리는 캐쉬, ROM(Read Only Memory), PROM(Programmable ROM), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM) 및 플래쉬 메모리(Flash memory)와 같은 비휘발성 메모리 소 자 또는 RAM(Random Access Memory)과 같은 휘발성 메모리 소자 또는 하드디스크 드라이브(HDD, Hard Disk Drive), CD-ROM과 같은 저장 매체 중 적어도 하나로 구현될 수 있다. 메모리는 프로세서와 별개의 칩으로 구현될 수 있으나, 반드시 이에 한정되는 것은 아니다. 디스플레이는 사용자가 입력하는 이미지 파일을 재생하거나, 제어부가 생성하는 출력 데이터이 이미지 또는 동영상일 때, 자료를 표시하는 구성이다. 디스플레이는 음극선관(Cathode Ray Tube: CRT), 디지털 광 원 처리(Digital Light Processing: DLP) 패널, 플라즈마 디스플레이 패널(Plasma Display Penal), 액정 디스 플레이(Liquid Crystal Display: LCD) 패널, 전기 발광(Electro Luminescence: EL) 패널, 전기영동 디스플레이 (Electrophoretic Display: EPD) 패널, 전기변색 디스플레이(Electrochromic Display: ECD) 패널, 발광 다이오 드(Light Emitting Diode: LED) 패널 또는 유기 발광 다이오드(Organic Light Emitting Diode: OLED) 패널 등 으로 마련될 수 있으나, 이에 한정되지는 않는다. 스피커는 사용자가 입력하는 음성 파일을 재생하거나, 제어부가 생성하는 출력 데이터를 소리로 출력하 는 구성으로, 디스플레이와 일체의 구성으로 마련되거나, 별개의 구성으로 마련될 수 있다. 한편, 개시된 데이터 생성 시스템은 단일 모델에서 여러 유형의 출력 데이터를 생성할 수 있으므로, 데이터 를 저장하는 메모리 측면에서 뛰어난 효과가 있다. 예를 들어, 종래 일반적인 생성 AI가 음성 파일을 생성하기 위한 학습이 완료되면, 모델 크기는 약 12,000KB가 된다. 또한 종래 일반적인 생성 AI가 28 x 28 이미지 파일을 생성하도록 학습이 완료되면, 모델 크기가 약 13,000KB가 된다. 이에 비해, 개시된 데이터 생성 시스템은 이 미지 파일 및 음성 파일 모두를 생성할 수 있도록 학습되더라도, 모델 크기가 약 13,000KB가 된다. 따라서 개시 된 데이터 생성 시스템은 다수의 프로세서 및 메모리를 포함한 서버와 같은 대규모 데이터 처리시설 뿐만 아 니라, 노트북, 데스크톱(desktop), 랩톱(laptop), 태블릿 PC와 같은 웨어러블 장치에서도 동작할 수 있는 효과 가 있다. 도 3은 개시된 일 실시예에 따른 데이터 생성 방법의 순서도이다. 개시된 데이터 생성 방법은, 입력 데이터를 가공하는 단계, 인공지능 모델이 가공된 입력 데이터를 학습하 는 단계 및 학습된 인공지능 모델을 이용하여 출력 데이터를 생성하는 단계로 구분된다. 먼저, 입력 데이터를 가공하는 단계 는, 가공된 입력 데이터 및 생성하고자 하는 데이터의 유형 정보를 포 함한 클래스 토큰을 입력하여 시계열화된 출력 데이터를 생성한다. 입력 데이터를 가공하는 단계에서 데이터 생성 시스템은 사용자의 입력 또는 외부 네트워크 등 다양한 경로를 통해서 다양한 유형의 입력 데이터를 수집한다. 이미지 파일, 동영상 파일, 음성 파일 등 다양한 유형의 입력 데이터가 수집되면, 데이터 생성 시스템은 데이터 전처리 과정을 수행한다. 구체적으로 데이터 생성 시 스템은 미리 설정된 세그먼트에 기초하여 입력 데이터를 헥스 코드(Hex Code)로 변환하고, 변환된 헥스 코드 에 유형 정보를 포함한 클래스 토큰을 추가한 후, 입력 데이터를 시계열화한다. 데이터 생성 시스템은 인공 지능 모델이 요구하는 배치 사이즈에 맞춰 시계열화된 입력 데이터에 마스킹 처리를 수행함으로써, 입력 데이터를 가공한다. 인공지능 모델이 가공된 입력 데이터를 학습하는 단계는, 인공지능 모델을 가공된 입력 데이터를 학습 데이 터로 사용하면서, 유형 정보가 포함된 클래스 토큰도 함께 학습시킨다. 일 예에 따른 인공지능 모델은 트랜스포머 디코더 및 분배기를 포함할 수 있다. 여기서 트랜스포머 디코더는 자 연어 처리와 기계 번역 분야에서 사용되는 인공 신경망 아키텍처인 트랜스포머 네트워크(Transformer Network) 의 일 구성을 의미한다. 트랜스포머 네트워크는 2017년에 발표된 논문 \"Attention is All You Need\"에서 처음 소개된 아키텍처로 시퀀스 투 시퀀스(sequence-to-sequence) 모델의 일종이다. 기존의 시퀀스 투 시퀀스 모델인 순환 신경망(RNN) 기반의 모델, 특히 LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit)와 같은 RNN 변형들은 많은 자연어 처리 작업에서 좋은 성능을 보여주었지만, 장기 의존성(long-term dependency) 문제와 계 산 효율성 측면에서 제한이 있었다. 트랜스포머 네트워크는 이러한 문제를 해결하기 위해 제안된 아키텍처로, RNN 대신에 셀프 어텐션(self-attention) 메커니즘을 사용한다. 셀프 어텐션은 입력 시퀀스 내의 데이터 사이의 상호 관계를 모델링하는데 사용된다. 트렌스포머의 디코더는 여러 개의 층(layer)으로 구성되어 있으며, 각 층은 셀프 어텐션, 피드 포워드 신경망 (feed-forward neural network) 레이어, 선형 레이어(Linear Layer) 및 소프트맥스(softmax) 함수를 포함하며, 선형 레이어 및 소프트맥스로 구성된 디코더의 마지막 층은 셀프 어텐션과 피드 포워드 신경망으로부터 출력되 는 데이터 정보를 받아 점수를 계산한다. 분배기는 소프트맥스 함수를 통해 이 점수들을 확률 분포로 변환할 수 있다. 인공지능 모델이 가공된 입력 데이터를 학습하는 단계에서 데이터 생성 시스템은 트랜스포머 디코더에서 출력되는 확률값과 분배기를 통해 데이터를 생성하는 방법을 학습한다. 트랜스포머 디코더 및 분배기를 포함한 인공지능 모델은 Negative log-likelihood가 최소가 되도록 학습을 진행함으로써, 클래스 토큰에서 요구한 유형 정보에 맞는 출력 데이터를 생성하도록 학습된다. 한편, 개시된 일 실시예에 따른 인공지능 모델이 반드시 트랜스포머 디코더로 구성되는 것에 한정되는 것은 아 니다. 데이터 생성 시스템은 생성 AI의 배치 사이즈에 맞도록 다양한 유형의 입력 데이터를 헥스 코드로 변 환 및 시계열화한 뒤, 마스킹 처리를 수행하는 전처리 과정을 수행하면 충분하고, 학습할 인공지능 모델이 반드 시 트랜스포머 디코더에만 제한되지 않는다. 학습된 인공지능 모델을 이용하여 출력 데이터를 생성하는 단계는 학습된 인공지능 모델이 데이터를 생성 (추론)하고, 생성된 데이터를 샘플링한 후, 시계열로 샘플링된 데이터를 정렬하는 과정을 포함한다. 학습된 인공지능 모델이 추론하는 데이터는 헥스 코드로 출력되며, 샘플링 과정을 거친다. 개시된 일 예에서 샘 플링은 Top-K, Top-P 및 온도(Temperature) 샘플링을 포함하며, 그 이외에도 다양한 샘플링 방법이 사용될 수 있다. 구체적으로 Top-K 샘플링은 학습된 인공지능 모델에서 출력되는 데이터 집합에서 가장 확률이 높은 K 개 의 데이터를 선택하는 방법이며, Top-P 샘플링은 인공지능 모델에서 출력되는 확률 분포에서 누적 확률이 상위 P (P는 0에서 1 사이)에 해당하는 데이터를 선택하는 방법이다. 온도 샘플링은 0보다 큰 실수값으로 설정된 온 도 매개변수에 따라 데이터를 선택하는 방법이다. 개시된 샘플링 과정은 인공지능 모델이 출력하는 데이터에 따 라 사용자에 의해서 선택되어 적용될 수 있다. 학습된 인공지능 모델을 이용하여 출력 데이터를 생성하는 단계에서 데이터 생성 시스템은 샘플링되어 출력된 데이터를 시계열로 정렬하여, 최종적인 출력 데이터를 생성한다. 한편, 도 3에서 전술한 각 단계에 대해서 이하의 다른 도면을 통해 더욱 구체적으로 설명한다. 도 4 및 도 5는 도 3에서 설명한 입력 데이터를 가공하는 방법을 구체적으로 설명하기 위한 도면이다. 도 4를 먼저 참조하면, 데이터 생성 시스템은 다양한 유형의 입력 데이터를 수신한다. 수신된 제1 입력 데이터가 이미지 데이터인 경우, 데이터 생성 시스템은 이미지 데이터의 각 픽셀을 헥스 코드로 변환한다. 여기서 헥스 코드는 16진법으로 표현된 시퀀스로써, 개시된 실시예에서는 00에서 FF까지 256개의 코드로 입력 데이터를 변환한다. 데이터 생성 시스템은 헥스 코드로 변환한 입력 데이터를 미리 설정된 기준에 따라 시계열화된 데이터로 변경한다. 여기서 미리 설정된 기준은 다양할 수 있으며, 반드시 도 4의 예처럼 왼쪽 측면의 헥스 코드부터 시 계열화될 필요는 없다. 데이터 생성 시스템은 입력 데이터 1, 2, 3 등을 시계열화 한 후, 시계열화된 데이터의 마지막에 스톱 토큰 (24a, 24b, 24c)을 추가한다. 여기서 스톱 토큰은 복수 개의 입력 데이터가 인공지능 모델에 입력될 때, 각 각의 입력 데이터를 구분하기 위한 것으로, 헥스 코드 중 어느 하나면 충분하다. 도 5를 참조하면, 데이터 생성 시스템은 스톱 토큰을 추가한 각각의 입력 데이터에 대해서 마스킹 처리 를 수행한다. 여기서 마스킹 처리란, 인공지능 모델의 배치(batch)를 기준으로 가장 데이터의 크기가 큰 입력 데이터에 맞춰 다른 입력 데이터에 스톱 토큰을 더 추가하는 처리를 의미한다. 도 5의 예시에서 입력 데이터 2 가 가장 큰 데이터 크기를 가지므로, 데이터 생성 시스템은 입력 데이터 1 및 3을 입력 데이터 2의 크기에 맞춰 스톱 토큰(24e)을 더 추가한다. 이를 통해서 개시된 데이터 생성 시스템은 다양한 유형 및 다양한 크기를 가진 입력 데이터를 학습할 인공지 능의 배치 사이즈에 맞도록 일정한 데이터로 전처리를 수행함으로써, 단일 인공지능 모델이 여러 유형의 데이터 를 생성할 수 있도록 한다. 또한, 이러한 전처리를 수행함으로써, 데이터 생성 시스템은 학습된 인공지능 모 델이 다양한 크기의 데이터를 생성할 때, 원본 데이터의 품질을 손상시키지 않을 수 있다. 도 6및 도 7은 도 3에서 설명한 가공한 입력 데이터를 통해 인공지능 모델을 학습하는 방법을 설명하기 위한 도 면이다. 도 6 및 도 7에서는 인공지능 모델을 트랜스포머 디코더와 범주형 분배기(Categorical Distributor, 33)를 포함하는 것으로 설명한다. 도 6을 먼저 참조하면, 데이터 생성 시스템은 도 5에서 설명한 마스킹 처리된 입력 데이터, 즉 가공된 입력 데이터를 트랜스포머 디코더에 입력시킨다. 트랜스포머 디코더 및 범주형 분배기를 거처 예측 되는 학습용 출력 데이터에 대해서 데이터 생성 시스템은 손실 함수의 값이 최소화되는 방향으로 트 랜스포머 디코더를 조정함으로써, 학습을 진행한다. 일 예에서 손실 함수는 평균 제곱 오차(Mean Squared Error, MSE) 또는 교차 엔트로피 손실(Cross-Entropy Loss) 등이 사용될 수 있다. 도 7을 참조하면, 데이터 생성 시스템은 클래스 토큰과 마스킹 처리된 입력 데이터를 시계열적으로 트랜스포머 디코더에 입력한다. 구체적으로 클래스 토큰은 입력 데이터(31a)에 대한 시퀀스(Lseq)의 시작을 나타내는 역할로, 데이터 생성 시스템은 입력 데이터의 유형 정보를 포함한 헥스 코드를 클래스 토큰으로 사용할 수 있다. 클래스 토큰을 트랜스포머 디코더에 입력한 후, 데이터 생성 시스템은 입력 데이터의 각각의 헥 스 코드를 트랜스포머 디코더에 입력한다. 트랜스포머 디코더는 입력되는 헥스 코드들을 벡터 임베딩으 로 변환하는 레이어, 각 헥스 코드 간의 상호 작용을 모델링하는 어텐션 레이어 등을 포함하며, 최종적인 레이 어에서 입력된 시퀀스(예를 들어 4까지 입력)의 다음 시퀀스(L5)에 해당하는 확률값( )을 예측한다. 분배기는 확률 분포를 통해 입력 데이터과 동일하게 헥스 코드로 시계열화된 학습용 출력 데이터를 출력하고, 데이터 생성 시스템은 손실함수를 조정함으로써 학습을 진행한다. 데이터 생성 시스템은 여러 유형의 입력 데이터를 학습 데이터로 사용하면서, 입력되는 데이터의 유형 정보 를 함께 학습시킨다. 따라서 학습이 완료된 인공지능 모델은, 유형 정보에 해당하는 헥스 코드화된 시계열 데이 터를 출력하도록 학습되며, 이를 통해서 종래 일반적인 생성 AI와 다르게, 단일 모델이 다양한 유형의 데이터를 출력할 수 있게 된다. 도 8 및 도 9는 도 3에서 설명한 학습이 완료된 인공지능 모델을 통해 출력 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 8을 먼저 참조하면, 데이터 생성 시스템은 사용자로부터 유형 정보를 수신한다. 여기서 유형 정보는, 생성할 출력 데이터의 유형, 예를 들어 음성 파일인지, 이미지 데이터인지 여부를 결정하 는 정보를 포함한다. 또한, 유형 정보는 출력 데이터의 크기에 대한 정보 및 출력 데이터가 포함할 내용, 예를 들어 신발 이미지와 같은 정보도 함께 포함될 수 있다. 데이터 생성 시스템은 사용자가 입력한 유형 정보를 클래스 토큰으로 변환한다. 변환된 클래스 토큰이 입력되면, 학습된 인공지능 모델은 데이터를 추론한다. 도 9를 참조하면, 학습된 인공지능 모델은 클래스 토큰이 입력된 후, 첫 번째 데이터(47a)를 추론한다. 이후 학습된 인공지능 모델은 계속적으로 헥스 코드화된 다음 데이터(47b)를 추론한다. 여기서 각각의 데이 터(47a, 47b, 47c)은 헥스 코드로 생성된다. 데이터 추론이 완료되면, 데이터 생성 시스템은 추론된 데이터를 샘플링한다. 도 3 등에서 전술한 바와 같이, 데이터 생성 시스템은 Top-K, Top-P 및 온도(Temperature) 샘플링 등 다양한 방법을 통해서 데이터 샘플링을 수행할 수 있다. 데이터 샘플링이 완료되면, 데이터 생성 시스템은 샘플링된 데이터를 시계열로 정렬한다. 도 9를 다시 참조하면, 데이터 생성 시스템은 샘플링된 각각의 데이터(47a, 47b, 47c)를 시계열적으로 정렬 한 최종적인 출력 데이터를 출력한다. 출력 데이터는 사용자가 입력한 유형 정보에 기초한 생성 데이터 이다. 이를 통해서 개시된 데이터 생성 시스템은 하나의 단일 인공지능 모델로부터 다양한 유형의 데이터를 출력할 수 있으며, 효율적인 메모리 공간을 통해 생성 AI를 실현할 수 있으며, 적은 메모리를 할당받는 웨어러블 장치 에서도 생성 AI를 활용할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0087411", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 개시된 일 실시예에 따른 데이터 생성 시스템을 개략적으로 설명하기 위한 도면이다. 도 2는 개시된 데이터 생성 시스템의 하드웨어적 구성을 설명하기 위한 제어 블록도이다. 도 3은 개시된 일 실시예에 따른 데이터 생성 방법의 순서도이다. 도 4 및 도 5는 도 3에서 설명한 입력 데이터를 가공하는 방법을 구체적으로 설명하기 위한 도면이다. 도 6및 도 7은 도 3에서 설명한 가공한 입력 데이터를 통해 인공지능 모델을 학습하는 방법을 설명하기 위한 도 면이다. 도 8 및 도 9는 도 3에서 설명한 학습이 완료된 인공지능 모델을 통해 출력 데이터를 생성하는 방법을 설명하기 위한 도면이다."}
