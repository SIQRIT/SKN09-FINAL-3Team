{"patent_id": "10-2024-7039320", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0048178", "출원번호": "10-2024-7039320", "발명의 명칭": "출력 데이터의 일관성을 보장하기 위하여 생성형 인공지능 모델을 학습시키는 방법,", "출원인": "주식회사 슈퍼엔진", "발명자": "임철수"}}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법으로서,선화(outline) 데이터를 획득하는 단계;채색 데이터를 획득하는 단계; 및상기 선화 데이터 및 상기 채색 데이터를 기초로 화풍 행렬을 생성하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,초기 데이터를 획득하는 단계; 및상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계는,상기 초기 데이터를 기 설정된 복수의 카테고리로 분류하는 단계; 및상기 카테고리를 기초로 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계는,상기 초기 데이터로부터 오류 데이터를 제거하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계는,상기 선화 데이터 또는 상기 채색 데이터가 기 설정된 수보다 적을 경우, 초기 데이터를 기초로 상기 선화 데이터 또는 상기 채색 데이터를 추가로 생성하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 선화 데이터 및 상기 채색 데이터를 기초로 화풍 행렬을 생성하는 단계는,가중치 행렬을 포함하는 제1 인공신경망 모델을 획득하는 단계;상기 인공신경망 모델에 상기 선화 데이터 및 상기 채색 데이터를 학습시키는 단계; 및학습 후 상기 제1 인공신경망 모델에 포함된 가중치 행렬의 변화를 기초로 상기 화풍 행렬을 생성하는 단계;를포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2025-0048178-3-제1항에 있어서,인물 데이터를 획득하는 단계; 및상기 인물 데이터를 기초로 인물 행렬을 생성하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 인물 데이터를 기초로 인물 행렬을 생성하는 단계는,제2 가중치 행렬을 포함하는 제2 인공신경망 모델을 획득하는 단계;상기 제2 인공신경망 모델에 상기 인물 데이터를 학습시키는 단계; 및학습 후 상기 제2 인공신경망 모델에 포함된 가중치 행렬의 변화를 기초로 상기 인물 행렬을 생성하는 단계;를포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 화풍 행렬과 상기 인물 행렬을 기초로 병합 행렬을 생성하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 화풍 행렬과 상기 인물 행렬을 기초로 병합 행렬을 생성하는 단계는,병합 비율을 획득하는 단계; 및상기 병합 비율을 기초로 상기 화풍 행렬과 상기 인물 행렬을 병합시키는 단계;를 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,기 저장된 생성형 인공지능 모델에 상기 화풍 행렬 또는 상기 병합 행렬을 병합하는 단계;를 더 포함하는,방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 생성형 인공지능 모델로부터 출력 데이터를 획득하는 단계;상기 병합 비율을 수정하는 단계;상기 수정된 병합 비율을 기초로 병합 행렬을 다시 생성하는 단계; 및기 저장된 생성형 인공지능 모델에 다시 생성된 병합 행렬을 병합하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 생성형 인공지능 모델로부터 출력 데이터를 획득하는 단계;추가 데이터를 획득하는 단계;상기 추가 데이터를 기초로 화풍 행렬 또는 병합 행렬을 다시 생성하는 단계; 및기 저장된 생성형 인공지능 모델에 다시 생성된 화풍 행렬 또는 병합 행렬을 병합하는 단계;를 더 포함하는, 방법.공개특허 10-2025-0048178-4-청구항 14 제11항에 있어서,상기 생성형 인공지능 모델로부터 출력 데이터를 획득하는 단계; 및상기 출력 데이터가 시각적으로 표시되도록 하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,배경 데이터를 획득하는 단계; 및상기 배경 데이터를 기초로 배경 행렬을 생성하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 화풍 행렬과 상기 인물 행렬을 기초로 병합 행렬을 생성하는 단계는, 상기 화풍 행렬, 상기 인물 행렬 및상기 배경 행렬을 기초로 병합 행렬을 생성하는 단계인, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,초기 데이터를 획득하는 단계; 및상기 초기 데이터로부터 상기 배경 데이터를 추출하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제7항에 있어서,초기 데이터를 획득하는 단계; 및상기 초기 데이터로부터 상기 인물 데이터를 추출하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "생성형 인공지능 모델을 학습시키기 위해 사용되는 장치로서,메모리; 및프로세서;를 포함하고,상기 프로세서는,선화(outline) 데이터 및 채색 데이터를 획득하여 상기 메모리에 저장하고, 상기 선화 데이터 및 상기 채색 데이터를 기초로 화풍 행렬을 생성하는, 장치."}
{"patent_id": "10-2024-7039320", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은 장치의 프로세서에서 실행되는 경우, 생성형 인공지능 모델을 학습시키기 위한 단계들을 수행하며, 상기 단계들은,선화(outline) 데이터를 획득하는 단계;채색 데이터를 획득하는 단계; 및상기 선화 데이터 및 상기 채색 데이터를 기초로 화풍 행렬을 생성하는 단계;를 포함하는, 프로그램."}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면 선화(outline) 데이터를 획득하는 단계; 채색 데이터를 획득하는 단계; 및 상기 선화 데이터 및 상기 채색 데이터를 기초로 화풍 행렬을 생성하는 단계;를 포함하는 생성형 인공지능 모델을 학 습시키는 방법이 개시된다. 이를 통하여 생성형 인공지능 모델이 출력하는 데이터의 일관성을 보장하고 사용자의 의도에 부합하는 출력을 얻을 수 있으며, 생성형 인공지능 모델을 학습시키는 목적에 따라 입력 데이터를 달리하 여 생성형 인공지능 모델을 프롬프팅(prompting)하기 위해서 소요되는 시간과 비용이 획기적으로 감소할 뿐 아니 라 출력 데이터의 질을 향상시키는 효과를 얻을 수 있다."}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 생성형 인공지능 모델을 학습시키는 방법, 프로그램, 및 장치에 관한 것으로, 더 상세하게는 생성형 인공지능 모델이 출력하는 데이터의 일관성을 보장하고 사용자의 의도에 부합하는 출력을 얻기 위하여 생성형 인공지능 모델을 학습시키는 방법, 프로그램, 및 장치에 관한 것이다."}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 많은 사람들이 그림을 직접 그리지 않고도 생성형 인공지능 모델인 디퓨전 모델(diffusion model)을 통해 그림을 생성하고 있다. 이러한 디퓨전 모델의 경우 방대한 학습량을 가지고 있으며, 오픈소스 정책을 통해 다양 한 사람들의 추가적인 학습 데이터가 적용된다. 이에 따라 디퓨전 모델을 통해 생성되는 이미지의 품질이 점점 더 고도화되어가는 추세이다. 그러나, 이러한 생성형 인공지능 모델은 무작위로 다양한 이미지들을 생성하기만 할 뿐, 사용자가 의도한 대로 일관된 이미지들을 생성해주지 않는다. 따라서, 사용자는 원하는 이미지를 얻기 위해 수많은 시도를 해야만 한 다. 한편, 최근 기업체들은 업무 또는 인력의 일부를 생성형 인공지능 모델로 대체하고자 하며, 특히 번역이나 매일 반복되는 루틴에 대한 자동화 등에 생성형 인공지능 모델을 적극적으로 사용하는 경향이 있다. 이와 같은 업무 는 생성형 인공지능 모델이 무작위적 결과를 출력하더라도 인간에 의한 추가 수정 작업이 쉬운 편이기 때문이다. 반면, 출력 데이터의 일관성이 유지되어야 하는 업무, 또는 결과물의 특성이 1인 의존적이어야 하는 업무에 대해서는 생성형 인공지능 모델 사용에 대한 한계가 존재한다. 1인 의존적이어야 하는 업무란, 작곡가, 작사가, 화가, 소설가, 만화 작가 등의 예술가의 창작 업무를 포함한다. 특히, 최근 오프라인 상에서 연재되는 만화뿐만 아니라 온라인 상에서 연재되는 디지털 만화인 웹툰(webtoon)에 대한 사람들의 수요가 커지면서 만화 시장이 커지고 있다. 일반적으로 웹툰을 연재하는 작가들은 일정 주기(예 를 들어, 주 1회, 주 2회 등)에 따라 웹툰을 제작하여 온라인 상에 업로드한다. 최근 웹툰 시장이 커지면서 웹 툰의 퀄리티에 대한 일반 수요자들의 기대 또한 커져 일정 주기에 따라 기대에 맞는 퀄리티의 웹툰을 제작하는 것이 어려운 실정이다. 이에 생성형 인공지능 모델을 이용하여 만화를 제작하려는 노력이 시도되고 있으나, 생 성형 인공지능 모델은 무작위로 생성된 이미지만을 출력할 뿐 일관된 이미지를 생성하지는 못하므로, 작가의 화 풍에 맞는 일관된 복수의 이미지를 생성해야 하는 만화의 필수 조건이 지켜지기 어려운 실정이다. 이에 따라, 생성형 인공지능 모델을 이용하여 이미지들을 생성할 때, 사용자의 의도를 반영하여 일관된 이미지 들을 생성하도록 생성형 인공지능 모델을 학습하는 방법의 필요성이 대두되고 있다."}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 위와 같은 문제를 해결하기 위하여 제안된 것으로, 생성형 인공지능 모델이 출력하는 데이터의 일관 성을 보장하고 사용자의 의도에 부합하는 출력을 얻기 위하여 생성형 인공지능 모델을 학습시키는 방법, 프로그 램, 및 장치를 제공하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 이하에서 설명할 내 용으로부터 통상의 기술자에게 자명한 범위 내에서 다양한 기술적 과제가 포함될 수 있다."}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따라 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 선화 (outline) 데이터를 획득하는 단계; 채색 데이터를 획득하는 단계; 및 상기 선화 데이터 및 상기 채색 데이터를 기초로 화풍 행렬을 생성하는 단계;를 포함한다. 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 초기 데이터를 획득하는 단계; 및 상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계;를 더 포함할 수 있 다. 상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계는, 상기 초기 데이터를 기 설 정된 복수의 카테고리로 분류하는 단계; 및 상기 카테고리를 기초로 상기 선화 데이터 및 상기 채색 데이터를추출하는 단계;를 포함할 수 있다. 상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계는, 상기 초기 데이터로부터 오 류 데이터를 제거하는 단계;를 더 포함할 수 있다. 또한 상기 초기 데이터로부터 상기 선화 데이터 및 상기 채색 데이터를 추출하는 단계는, 상기 선화 데이터 또 는 상기 채색 데이터가 기 설정된 수보다 적을 경우, 초기 데이터를 기초로 상기 선화 데이터 또는 상기 채색 데이터를 추가로 생성하는 단계;를 더 포함할 수 있다. 상기 선화 데이터 및 상기 채색 데이터를 기초로 화풍 행렬을 생성하는 단계는, 가중치 행렬을 포함하는 제1 인 공신경망 모델을 획득하는 단계; 상기 제1 인공신경망 모델에 상기 선화 데이터 및 상기 채색 데이터를 학습시 키는 단계; 및 학습 후 상기 가중치 행렬의 변화를 기초로 상기 화풍 행렬을 생성하는 단계;를 포함할 수 있다. 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 인물 데이터를 획득하는 단계; 및 상기 인물 데이터를 기초로 인물 행렬을 생성하는 단계;를 더 포함할 수 있다. 상기 인물 데이터를 기초로 인물 행렬을 생성하는 단계는, 가중치 행렬을 포함하는 제2 인공신경망 모델을 획득 하는 단계; 상기 제2 인공신경망 모델에 상기 인물 데이터를 학습시키는 단계; 및 학습 후 상기 가중치 행렬의 변화를 기초로 상기 인물 행렬을 생성하는 단계;를 포함할 수 있다. 또한 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 상기 화풍 행렬과 상 기 인물 행렬을 기초로 병합 행렬을 생성하는 단계;를 더 포함할 수 있다. 상기 화풍 행렬과 상기 인물 행렬을 기초로 병합 행렬을 생성하는 단계는, 병합 비율을 획득하는 단계; 및 상기 병합 비율을 기초로 상기 화풍 행렬과 상기 인물 행렬을 병합시키는 단계;를 포함할 수 있다. 상기 병합 비율은 화풍 행렬 0.8 : 인물 행렬 0.2, 화풍 행렬 0.5 : 인물 행렬 0.5, 또는 인물 행렬의 비율이 화풍 행렬을 넘지 않는 비율일 수 있다. 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 기 저장된 생성형 인공지 능 모델에 상기 화풍 행렬 또는 상기 병합 행렬을 병합하는 단계;를 더 포함할 수 있다. 또한 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 상기 생성형 인공지 능 모델로부터 출력 데이터를 획득하는 단계; 상기 병합 비율을 수정하는 단계; 상기 수정된 병합 비율을 기초 로 병합 행렬을 다시 생성하는 단계; 및 기 저장된 생성형 인공지능 모델에 다시 생성된 병합 행렬을 병합하는 단계;를 더 포함할 수 있다. 또한 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 상기 생성형 인공지 능 모델로부터 출력 데이터를 획득하는 단계; 추가 데이터를 획득하는 단계; 상기 추가 데이터를 기초로 화풍 행렬 또는 병합 행렬을 다시 생성하는 단계; 및 기 저장된 생성형 인공지능 모델에 다시 생성된 화풍 행렬 또는 병합 행렬을 병합하는 단계;를 더 포함할 수 있다. 또는, 상기 출력 데이터가 시각적으로 표시되도록 하는 단계;를 더 포함할 수 있다. 또한 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 배경 데이터를 획득 하는 단계; 및 상기 배경 데이터를 기초로 배경 행렬을 생성하는 단계;를 더 포함할 수 있다. 상기 배경 데이터를 기초로 배경 행렬을 생성하는 단계는, 가중치 행렬을 포함하는 제3 인공신경망 모델을 획득 하는 단계; 상기 제3 인공신경망 모델에 상기 배경 데이터를 학습시키는 단계; 및 학습 후 상기 제3 인공신경망 모델에 포함된 가중치 행렬의 변화를 기초로 상기 배경 행렬을 생성하는 단계;를 포함할 수 있다. 상기 화풍 행렬과 상기 인물 행렬을 기초로 병합 행렬을 생성하는 단계는, 상기 화풍 행렬, 상기 인물 행렬 및 상기 배경 행렬을 병합하여 수행될 수 있다. 또한 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 초기 데이터를 획득 하는 단계; 및 상기 초기 데이터로부터 상기 배경 데이터를 추출하는 단계;를 더 포함할 수 있다. 상기 초기 데이터로부터 상기 배경 데이터를 추출하는 단계는, 상기 초기 데이터를 기 설정된 복수의 카테고리 로 분류하는 단계; 및 상기 카테고리를 기초로 상기 배경 데이터를 추출하는 단계;를 포함할 수 있다. 상기 초기 데이터로부터 상기 배경 데이터를 추출하는 단계는, 상기 초기 데이터로부터 오류 데이터를 제거하는 단계;를 더 포함할 수 있다. 또한 상기 초기 데이터로부터 상기 배경 데이터를 추출하는 단계는, 상기 선화 데이터 또는 상기 채색 데이터가 기 설정된 수보다 적을 경우, 초기 데이터를 기초로 상기 선화 데이터 또는 상기 채색 데이터를 추가로 생성하 는 단계;를 더 포함할 수 있다. 또한 일 실시예에서, 장치의 프로세서에 의해 생성형 인공지능 모델을 학습시키는 방법은, 초기 데이터를 획득 하는 단계; 및 상기 초기 데이터로부터 상기 인물 데이터를 추출하는 단계;를 더 포함할 수 있다. 상기 초기 데이터로부터 상기 인물 데이터를 추출하는 단계는, 상기 초기 데이터를 기 설정된 복수의 카테고리 로 분류하는 단계; 및 상기 카테고리를 기초로 상기 인물 데이터를 추출하는 단계;를 포함할 수 있다. 상기 초기 데이터로부터 상기 인물 데이터를 추출하는 단계는, 상기 초기 데이터로부터 오류 데이터를 제거하는 단계;를 더 포함할 수 있다. 또한 상기 초기 데이터로부터 상기 인물 데이터를 추출하는 단계는, 상기 인물 데이터가 기 설정된 수보다 적을 경우, 초기 데이터를 기초로 상기 인물 데이터를 추가로 생성하는 단계;를 더 포함할 수 있다. 상기 기 설정된 수는 100개 또는 90개 내지 110개인 것이 바람직하다. 상기 가중치 행렬은, 제1 가중치 행렬과 제2 가중치 행렬을 포함할 수 있으며, 상기 인공신경망 모델에 상기 화 풍 데이터, 상기 인물 데이터, 또는 상기 배경 데이터를 학습시키는 단계는, 상기 제1 가중치 행렬을 변화시키 지 않으면서 상기 제2 가중치 행렬을 변화시키는 것일 수 있다. 상기 화풍 행렬, 상기 인물 행렬, 또는 상기 배경 행렬은, 상기 제2 가중치 행렬의 변화를 기초로 생성된 것일 수 있다."}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 생성형 인공지능 모델을 학습시키는 목적에 따라 입력 데이터를 달리하여 사용 자의 의도에 더욱 부합하는 출력을 얻을 수 있다. 예를 들어, 무분별하게 많은 데이터를 학습한 생성형 인공지 능 모델을 통하여 웹툰과 같은 그래픽 데이터를 얻고자 할 때는 캐릭터의 외형, 그림체, 배경, 상황 등을 모두 입력하여야 하나, 본 발명의 일 실시예에 따른 방법을 통하여 학습한 생성형 인공지능 모델을 사용한다면 기본 적으로 화풍, 인물, 및 배경 정보 등을 반영한 출력을 생성하므로, 단순히 캐릭터명 및 상황 설명만으로도 사용 자의 의도에 부합하는 출력 결과를 얻을 수 있다. 따라서, 생성형 인공지능 모델을 프롬프팅(prompting)하기 위 해서 소요되는 시간과 비용이 획기적으로 감소할 뿐 아니라 출력 데이터의 질을 향상시킬 수 있다."}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 실시예들은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는바, 특정 실시예들을 도면에 예시 하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하려는 것이 아니며, 본 발명의 실시예의 다양한 변경(modifications), 균등물(equivalents), 및/또는 대체물 (alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시예는 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 기술적 사상의 범위가 하기 실시예 에 한정되는 것은 아니다. 오히려, 이들 실시예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 발명 의 기술적 사상을 완전하게 전달하기 위하여 제공되는 것이다. 본 개시에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 권리범위를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직 접 접속되어\" 있다고 언급된 때에는, 어떤 구성요소와 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소) 가 존재하지 않는 것으로 이해될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 즉, 달리 특정되지 않거나 단 수 형태를 지시하는 것으로 문맥상 명확하지 않은 경우, 본 개시와 청구범위에서 단수는 일반적으로 \"하나 또는 그 이상\"을 의미하는 것으로 해석되어야 한다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트 웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 실시예에 있어서 '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구 현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 혹은 복수의 '부'는 특정한 하드웨어로 구현될 필요가 있는 '모듈' 혹은 '부'를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 사용되는 용어 \"정보\" 및 \"데이터\"는 서로 상호 교환 가능하도록 사용될 수 있다. 마찬가지로, 본 개시에서 사용되는 용어 \"그림\" 및 \"이미지\"는 서로 상호 교환 가능하도록 사용될 수 있다. 본 개시에서 사용되 는 \"컨텐츠\"는 인터넷이나 컴퓨터 통신 등을 통하여 제공되는 각종 정보나 내용물을 의미하는 것으로써, 그림, 이미지, 영상, 글 등을 포함할 수 있다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 한편, 도면에서의 다양한 요소와 영역은 개략적으로 그려진 것이다. 따라서, 본 발명의 기술적 사상은 첨부한 도면에 그려진 상대적인 크기나 간격에 의해 제한되지 않는다. 이하에서는 첨부한 도면을 참고하여 본 개시에 따른 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 모델의 구조를 설명하기 위한 도면이다. 도 1을 참고하면, 인공지능 모델 또는 생성형 인공지능 모델은 입력 레이어(Input layer)와 출력 레이어(Output layer 또는 Decision layer), 그리고 적어도 하나의 히든 레이어(Hidden layer)를 포함할 수 있다. 각 레이어는 복수의 가중치(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중 치의 연산을 통해 레이어의 연산을 수행한다. 신경망의 예로는, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크(Deep Q-Networks)이 있 으며, 본 개시에서의 신경망은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 모델이란, 입력 데이터를 기반으로 연산을 수행하여 적어도 하나의 결과값을 출력할 때, 입력부터 출력까지의 과정을 정의하는 알고리즘과, 해당 알고리즘의 수정 또는 실행을 위한 규칙을 포함하는 집합을 의미하며, 인공 신경망(Artificial neural network, ANN) 모델 또는 인공지능 모델이란, 생물학적 뉴런의 작동 원리를 모방하여 설계된 그래프 형태의 수학적 모델을 의미한다. 히든 레이어 또는 은닉층 내 뉴런은 모델 내 다른 뉴런으로부터 적어도 하나의 입력을 받아 적어도 하나의 출력 값을 생성하는데, 이 때 뉴런 내에서 입력값으로부터 출력값을 생성하는 함수를 활성화 함수(Activation function)이라 한다. 활성화 함수는 시그모이드 함수(Sigmoid function), 렐루 함수(Rectified Linear Unit function, ReLU), 소프트맥스 함수(Softmax function)를 포함할 수 있으나, 이에 한정되지 않으며, 하나의 모 델 또는 하나의 층을 구성하는 뉴런 간에 사용되는 활성화 함수가 다를 수 있다. 학습이란, 모델의 성능을 향상시키기 위해 수행하는 것으로, 좁게는 모델 내 뉴런의 활성화 함수에 입력되는 각 입력값에 곱해지는 가중치(Weight)와 각 뉴런마다 하나가 설정되어 뉴런의 활성화 정도를 결정하는 편향(Bias) 의 값을 정하는 것을 의미하며, 넓게는 가중치와 편향의 값을 정하는 것 외에 모델의 입력값이 될 데이터셋의 생성 또는 수집, 생성 또는 수집한 데이터의 전처리, 사용할 모델에 대한 선택 또는 설계, 정해진 가중치 및 편 향에 기반한 모델의 평가, 개선, 및 최적화 등 모델에 영향을 끼칠 수 있는 모든 행위를 의미한다. 학습 과정 중 일부는 모델의 성능을 향상시키기 위해 반복적으로 수행될 수 있다. 인공지능 모델이 학습을 수행하는 알고 리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습 (semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘 은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 모델은 가중치를 행렬 또는 벡터의 리스트와 같이 행렬로 변환이 가능한 형태로 저장할 수 있으며, 학습 전 가 중치 행렬과 학습 후 가중치 변화량 행렬을 함께 저장할 수 있다. 가중치 또는 가중치 변화량을 나타내는 행렬 은 두 개 이상의 행렬로 저장될 수 있다. 예를 들어, 도 1에 도시된 가중치를 나타내는 행렬 W의 변화량은 보다 낮은 차원의 행렬 A와 B의 내적곱일 수 있다. 이 때, 모델은 학습을 수행할 때, 기존 모델의 가중치가 저장된 W 를 고정한 채로, A와 B만을 변화시킬 수 있다. 이와 같이 하나의 행렬을 표현하기 위해 두 개 또는 두 개 이상의 행렬을 사용하는 경우, 학습 과정에서는 학습 속도가 빨라지고, 메모리 등 하드웨어 요구사항이 낮아지며, 다른 모델 또는 작업에 저랭크 행렬을 적용시킬 수 있어 확장성이 높다는 장점이 있다. 본 개시에서 화풍 행렬, 인물 행렬, 및 배경 행렬은 인공신경망 모델의 가 중치 행렬을 표현하는 두 개 이상의 행렬 중 적어도 하나일 수 있다. 모든 행렬은 벡터를 포함한다. 도 2는 본 발명의 일 실시예와 관련된 생성형 인공지능 모델 학습 시스템의 네트워크 환경을 나타낸 도면이다. 도 2를 참고하면, 생성형 인공지능 모델을 학습시키기 위해 사용되는 장치(이하 학습 장치)는 사용자 단말 또는 생성형 인공지능 모델을 포함하는 생성형 인공지능 장치와 직접 또는 네트워크를 통하여 정보 또는 전기적 신호를 주고받을 수 있다. 이 때, 네트워크는 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 3G, 4G, LTE(long term evolution), VoLTE(voice over LTE), 5G NR(new radio) Wi-Fi(wireless-fidelity), 블루투스 (Bluetooth), NFC, RFID (radio frequency identification), 홈 네트워크(home network), IoT(internet of things) 등을 포함할 수 있다. 사용자 단말은 적어도 하나의 입력 장치, 출력 장치, 메모리, 통신 장치, 그리고 프로세서를 포함할 수 있 으며, 컴퓨터, 태블릿, 또는 스마트폰과 같은 형태의 전자 기기일 수 있다. 입력 장치는 사용자 단말의 구성요소(예: 프로세서)에 사용될 명령 또는 데이터를 사용자 단말의 외부(예: 사용자)로부터 수신할 수 있다. 입력 장치는, 예를 들면, 마이크, 마우스, 키보드, 또는 디지털 펜(예: 스타일러스 펜), 터치 패널 등을 포함할 수 있다. 터치 패널은 전기 신호의 변화를 감지하는 정전식 터치 패널, 물리적 압력을 감지하는 감압식 터치 패 널, 적외선 격자를 형성하여 적외선 격자의 변화를 감지하는 적외선식 터치 패널, 초음파 격자를 형성하여 초음 파 격자의 변화를 감지하는 표면 초음파 방식 터치 패널 등으로 이루어질 수 있다. 출력 장치는 조명, 스피커, 텍스트 표시 장치 및 디스플레이 패널 등을 포함할 수 있다. 특히, 디스플레이 패널 은 LCD(Liquid Crystal Display) 패널, OLED(Organic Light Emitting Diodes) 패널, AM-OLED(Active-Matrix Organic Light-Emitting Diode), LcoS(Liquid Crystal on Silicon), QLED(Quantum dot Light-Emitting Diode) 및 DLP(Digital Light Processing), PDP(Plasma Display Panel) 패널, 무기 LED 패널, 마이크로 LED 패널 등 다양한 종류의 디스플레이 패널을 포함할 수 있으나, 이에 한정되는 것은 아니다. 한편, 디스플레이 패널은 상 술한 터치 패널과 함께 터치 스크린을 구성할 수도 있으며, 플렉서블 패널로 이루어질 수도 있다. 메모리는 각종 프로그램이나 데이터를 일시적 또는 비일시적으로 저장하고, 프로세서의 호출에 따라서 저장된 정보를 프로세서에 전달한다. 또한, 메모리는, 프로세서의 연산, 처리 또는 제어 동작 등에 필요한 각종 정보를 전자적 포맷으로 저장할 수 있다. 메모리는, 예를 들어, 주기억장치 및 보조기억장치 중 적어도 하나를 포함할 수 있다. 주기억장치는 롬(ROM) 및 /또는 램(RAM)과 같은 반도체 저장 매체를 이용하여 구현된 것일 수 있다. 롬은, 예를 들어, 통상적인 롬, 이피 롬(EPROM), 이이피롬(EEPROM) 및/또는 마스크롬(MASK-ROM) 등을 포함할 수 있다. 램은 예를 들어, 디램(DRAM) 및/또는 에스램(SRAM) 등을 포함할 수 있다. 보조기억장치는, 플래시 메모리 장치, SD(Secure Digital) 카드, 솔리드 스테이트 드라이브(SSD, Solid State Drive), 하드 디스크 드라이브(HDD, Hard Disc Drive), 자기 드럼, 컴팩트 디스크(CD), 디브이디(DVD) 또는 레이저 디스크 등과 같은 광 기록 매체(optical media), 자기테 이프, 광자기 디스크 및/또는 플로피 디스크 등과 같이 데이터를 영구적 또는 반영구적으로 저장 가능한 적어도 하나의 저장 매체를 이용하여 구현될 수 있다. 통신 장치는, 유선 통신 장치 또는 무선 통신 장치일 수 있고, 둘을 모두 포함할 수도 있으나, 무선 통신 장치 를 포함하는 것이 바람직하다. 이러한 무선 통신 기술로는, 예를 들어, 블루투스(Bluetooth), 저전력 블루투스 (Bluetooth Low Energy), 캔(CAN) 통신, 와이 파이(Wi-Fi), 와이파이 다이렉트(Wi-Fi Direct), 초광대역 통신 (UWB, ultrawide band), 지그비(zigbee), 적외선 통신(IrDA, infrared Data Association) 또는 엔에프씨(NFC, Near Field Communication) 등이 포함될 수 있으며, 이동 통신 기술 로는, 와이맥스(Wi-Max), LTE(Long Term Evolution), 5G, 6G 및 후속 통신 표준 기술 등이 포함될 수 있다. 무선 통신 인터페이스는 전자기파를 외부로 송신하거나 또는 외부에서 전달된 전자기파를 수신할 수 있는 안테나, 통신 칩 및 기판 등을 이용하여 구현될 수 있다. 프로세서는 메모리를 포함하는 사용자자 단말의 구성과 연결되며, 상술한 바와 같은 메모리에 저장된 적어 도 하나의 인스트럭션을 실행함으로써, 학습 장치 또는 생성형 인공지능 장치에서 수행하는 동작을 제어할 수 있다. 특히, 프로세서는 하나의 프로세서로 구현될 수 있을 뿐만 아니라 복수의 프로세서로 구현될수 있다. 이 때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등 과 같은 범용 프로세서, GPU(Graphic Processing Unit). VPU(Vision processing unit) 등과 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit), TPU(Tensor Processing Unit)와 같은 인공지능 전용 프로세서일 수 있다. 사용자 단말은 하나의 작가가 그린 다양한 그림을 포함하는 데이터를 직접 또는 네트워크를 통하여 학습 장치에 전송할 수 있다. 이후 학습 장치는 사용자 단말로부터 전송받은 데이터를 기반으로 생성 형 인공지능 장치를 학습시킬 수 있다. 생성형 인공지능 장치는 학습 장치 또는 사용자 단말 에 직접 또는 네트워크를 통하여 출력 데이터를 전달할 수 있다. 사용자 단말, 학습 장치, 및 생성형 인공지능 장치 중 적어도 두 개는 물리적으로 서로 결합되어 구현될 수 있다. 도 3은 본 발명의 일 실시예에 따라 생성형 인공지능 모델을 학습시키기 위해 사용되는 장치의 구성을 도시한 블록도이다. 도 3을 참고하면, 학습 장치는, 적어도 하나의 프로그램 명령이 저장된 메모리 및 적어도 하나의 프 로그램 명령을 수행하는 적어도 하나의 프로세서를 포함할 수 있다. 메모리 및 보조 기억 장치는 각종 프로그램이나 데이터를 일시적 또는 비일시적으로 저장하고, 프로 세서의 호출에 따라서 저장된 정보를 프로세서에 전달할 수 있다. 메모리 및 보조 기억 장치에 저장되는 각종 프로그램이나 데이터는 생성형 인공지능 모델 또는 가중치 행렬 생성을 위한 인공신경망 모델을 포함할 수 있다. 생성형 인공지능 모델과 가중치 행렬 생성을 위한 인공신경망 모델은 동일한 것일 수 있다. 상 기 인공신경망 모델은 이미지와 같은 그래픽 데이터 내에서 각 객체를 구분하기 위한 정보를 사전 학습한 것임 이 바람직하다. 인공신경망 모델에 입력 데이터(예: 선화 데이터, 채색 데이터, 배경 데이터, 인물 데이터)를 학습시키는 경우, 인공신경망 모델 내에 저장된 데이터 일부가 삭제된 후 새로운 데이터가 생성될 수 있다. 즉, 덮어쓰기(overwrite) 방식으로 학습될 수 있다. 또한, 메모리는, 프로세서의 연산, 처리 또는 제어 동작 등에 필요한 각종 정보를 전자적 포맷으로 저장할 수 있다. 사용자는 사용자 단말을 통하여 메모리에 사용자가 생성 또는 수집한 데이터를 저장 할 수 있다. 메모리 또는 보조 기억 장치는, 예를 들어, 주기억장치 및 보조기억장치 중 적어도 하나를 포함할 수 있다. 주기억장치는 롬(ROM) 및/또는 램(RAM)과 같은 반도체 저장 매체를 이용하여 구현된 것일 수 있다. 롬은, 예를 들어, 통상적인 롬, 이피롬(EPROM), 이이피롬(EEPROM) 및/또는 마스크롬(MASK-ROM) 등을 포함할 수 있다. 램은 예를 들어, 디램(DRAM) 및/또는 에스램(SRAM) 등을 포함할 수 있다. 보조기억장치는, 플래시 메모리 장치, SD(Secure Digital) 카드, 솔리드 스테이트 드라이브(SSD, Solid State Drive), 하드 디스크 드라이브(HDD, Hard Disc Drive), 자기 드럼, 컴팩트 디스크(CD), 디브이디(DVD) 또는 레이저 디스크 등과 같은 광 기록 매체 (optical media), 자기테이프, 광자기 디스크 및/또는 플로피 디스크 등과 같이 데이터를 영구적 또는 반영구적 으로 저장 가능한 적어도 하나의 저장 매체를 이용하여 구현될 수 있다. 또한 메모리 또는 보조 기억 장치 는, 물리적으로 학습 장치 외부에 위치하는 저장소와의 연동을 지원하는 형태로 구현되거나, 학습 장 치 외부에 위치하는 저장소와 학습 장치 내부에 위치하는 저장소의 논리적 결합으로 구성될 수 있다. 메모리 또는 보조 기억 장치에 저장되는 초기 데이터는 그래픽 데이터 뿐 아니라 텍스트 또는 구분자 를 추가로 포함하는, 즉 태깅(tagging) 또는 라벨링(labeling)된 형태의 데이터일 수 있다. 일 실시예에서, 상 기 초기 데이터는 모두 하나의 작가로부터 생성된 것일 수 있다. 이 때, 초기 데이터는 작가의 습관과 특징이 그대로 반영된 것이므로 보다 일관성을 갖는 출력 데이터를 얻을 수 있도록 한다는 장점이 있다. 프로세서는 메모리를 포함하는 학습 장치의 구성과 연결되며, 상술한 바와 같이 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써, 학습 장치에서 수행하는 동작을 전반적으로 제어할 수 있다. 특히, 프로세서는 하나의 프로세서로 구현될 수 있을 뿐만 아니라 복수의 프로세서로 구현될 수 있 다. 이 때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같 은 범용 프로세서, GPU(Graphic Processing Unit). VPU(Vision processing unit) 등과 같은 그래픽 전용 프로 세서 또는 NPU(Neural Processing Unit), TPU(Tensor Processing Unit)와 같은 인공지능 전용 프로세서일 수 있다. 메모리 또는 보조 기억 장치가 인공신경망 모델을 포함하는 경우, 프로세서는 인공신경망 모델의 학습을 수행할 수 있다. 송수신 장치는 유선 통신 장치 또는 무선 통신 장치일 수 있고, 둘을 모두 포함할 수도 있으나, 무선 통신 장치를 포함하여 상술한 네트워크, 사용자 단말 또는 생성형 인공지능 장치와 정보를 주고받을 수 있 도록 하는 것이 바람직하다. 학습 장치가 송수신 장치를 포함하는 경우, 학습 장치는 서버일 수 있다. 송수신 장치는 사용자로부터 초기 데이터를 획득할 수 있고, 외부(예: 웹)로부터 초기 데이터를 수 집할 수 있다. 입력 장치는, 예를 들면, 마이크, 마우스, 키보드, 또는 디지털 펜(예: 스타일러스 펜), 터치 패널 등을 포함할 수 있다. 터치 패널은 전기 신호의 변화를 감지하는 정전식 터치 패널, 물리적 압력을 감지하는 감압식 터치 패널, 적외선 격자를 형성하여 적외선 격자의 변화를 감지하는 적외선식 터치 패널, 초음파 격자를 형성하 여 초음파 격자의 변화를 감지하는 표면 초음파 방식 터치 패널 등으로 이루어질 수 있다. 장치는 입력 장 치를 통한 입력을 바탕으로 행렬의 재생성 등 모델 학습에 관한 프로세스의 진행 여부 또는 순서를 결정할 수 있다. 출력 장치는 조명, 스피커, 텍스트 표시 장치 및 디스플레이 패널 등을 포함할 수 있다. 특히, 디스플레이 패널은 LCD(Liquid Crystal Display) 패널, OLED(Organic Light Emitting Diodes) 패널, AM-OLED(Active- Matrix Organic Light-Emitting Diode), LcoS(Liquid Crystal on Silicon), QLED(Quantum dot Light-Emitting Diode) 및 DLP(Digital Light Processing), PDP(Plasma Display Panel) 패널, 무기 LED 패널, 마이크로 LED 패 널 등 다양한 종류의 디스플레이 패널을 포함할 수 있으나, 이에 한정되는 것은 아니다. 한편, 디스플레이 패널 은 상술한 터치 패널과 함께 터치 스크린을 구성할 수도 있으며, 플렉서블 패널로 이루어질 수도 있다. 생성형 인공지능 모델이 생성한 출력 데이터는 출력 장치를 통하여 시각적으로 표현될 수 있다. 도 4는 본 발명의 일 실시예에 따라 생성형 인공지능 모델을 학습시키고 출력값을 획득하는 방법을 도시한 순서 도이다. 도 4를 참고하면, 생성형 인공지능 모델을 학습시키거나 출력값을 획득하기 위해서는 초기 데이터를 획득해야 한다. 초기 데이터는 작가 또는 사람이 직접 생성한 창작 데이터일 수 있다. 장치는 작가 또는 작가와 관 련된 외부로부터 초기 데이터를 수신하거나, 웹에서 작가의 초기 데이터를 수집하는 방식으로 초기 데이터를 획 득할 수 있다. 이 때, 장치는 초기 데이터를 기 설정된 수량(예: 약 100개 이상)만큼 수집할 수 있다. 초 기 데이터는 분류 또는 가공을 거쳐 행렬 생성을 위하여 모델에 입력되는 데이터(예: 선화 데이터, 채색 데이터, 배경 데이터, 인물 데이터)로 변환될 수 있다. 이러한 변환 과정은 추출 과정이라 칭할 수 있다. 생성형 인공지능 모델을 학습시키는 장치는, 선화 데이터 및 채색 데이터를 획득하고, 선화 데이터 및 채 색 데이터를 기반으로 화풍 행렬을 생성할 수 있다. 이 때, 장치는 인공신경망 모델을 획득하고, 인공신경 망 모델에 선화 데이터를 학습시켜 선화 행렬을 생성하고, 채색 데이터를 학습시켜 채색 행렬을 생성한 후, 상 기 선화 행렬과 상기 채색 행렬을 병합하여 화풍 행렬을 생성할 수 있다. 행렬 간 병합은 두 개의 행렬 간 덧셈 과 두 개의 행렬 또는 하나의 행렬과 하나의 수 간의 곱셈을 기초로 이루어지는 것이 바람직하다. 인공신경망 모델의 학습을 통하여 행렬을 획득하는 방법은 상술한 바와 같이 모델의 학습 전후 가중치 행렬의 변화량에 기 반할 수 있다. 배경 데이터로부터 배경 행렬을 생성하는 과정 역시 이와 유사하게 수행되는 것이 바람직하다. 배경 데이터는 소재 데이터라 칭할 수 있다. 인물 데이터로부터 인물 행렬을 생성하는 과정은 상술한 과정 외 성별 데이터와 의상 데이터를 수집 또는 학습하는 과정을 포함할 수 있다. 또는, 인물 데이터와 의상 데이터를 구분하여 인물 행렬과 의상 행렬을 각각 생성할 수 있다. 일 실시예에서, 선화(outline) 데이터는 흑백, 단일 색상 또는 제한된 색상만을 포함하는 그래픽 데이터일 수 있으며, 그래픽 데이터 내 객체의 윤곽선의 정보를 지시하는 데이터임이 바람직하다. 채색 데이터는 그래픽 데 이터 내 사용된 색상의 정보를 지시하는 데이터일 수 있으며, 그래픽 데이터의 채도, 명도 등을 포함하는 것이 바람직하다. 인물 데이터는 웹툰 내 등장인물의 외형을 지시하는 데이터일 수 있으며, 이 때, 생성형 인공지능 모델의 사용자는 인물의 외형을 매번 길게 프롬프팅하지 않더라도 인물의 이름과 같은 구분자만을 사용하여 의 도한 출력 데이터를 생성할 수 있다. 배경 데이터는 인물 외 객체의 외형을 지시하는 데이터임이 바람직하다. 배경 데이터는 사용 환경에 따라 소재 데이터, 후처리 데이터 또는 기타 데이터라 칭할 수 있다. 선화 행렬, 채색 행렬, 화풍 행렬, 배경 행렬, 및 인물 행렬을 생성하기 위하여 사용되는 인공신경망 모델은 동 일할 수 있으며, 각 데이터의 특징에 따라 상이할 수 있다. 또한, 행렬을 생성하기 위하여 사용되는 인공신경망 모델은 장치의 메모리에 저장되어 있을 수 있으나, 메모리에 저장되어 있지 않고 외부에 위치하여 장 치로부터 학습 데이터를 수신한 후 가중치 행렬 등 선화 행렬, 채색 행렬, 화풍 행렬, 배경 행렬, 및 인물 행렬을 생성하기 위한 데이터를 반환할 수 있다.장치는 화풍 행렬, 배경 행렬, 및 인물 행렬 중 적어도 두 개를 생성한 후, 생성된 복수의 행렬을 병합하 여 병합 행렬을 생성할 수 있다. 병합 행렬을 획득한 장치는 엔진, 즉 생성형 인공지능 모델을 선정한 후 상기 병합 행렬을 포함하는 입력을 통해 출력 데이터를 획득할 수 있다. 생성형 인공지능 모델에 입력되는 데이 터는 병합 행렬과 텍스트에 기반한 프롬프트(prompt)일 수 있으며, 또는 병합 행렬을 포함하는 사용자 인터페이 스(Graphic User Interface; GUI)를 통한 입력일 수 있다. 도 5는 본 발명의 일 실시예에 따라 초기 데이터로부터 인물 데이터, 선화 데이터 및 채색 데이터, 또는 배경 데이터를 획득하는 과정을 도시한 순서도이다. 장치는 초기 데이터를 수집 또는 획득할 수 있다. 이 때 초기 데이터는, 작가로부터 생성된 그래픽 데이터 일 수 있다. 장치는 작가로부터 직접 원본 데이터를 수신하거나, 웹에서 작가의 원본 데이터를 수집하는 방식으로 작가의 원본 데이터를 확보할 수 있다. 이 때 작가는 작곡가, 작사가, 화가, 소설가, 만화 작가 등을 포함하며, 작가는 기본적으로 개인(1인)을 의미하나 단체를 포함할 수 있다. S510 단계에서, 초기 데이터를 획득한 장치는 상기 초기 데이터를 인공지능 모델 또는 인공신경망 모델이 처리하기 좋은 형태로 가공할 수 있다. 장치가 데이터를 가공하는 방법에는 오류 또는 결측값 처리, 스케 일링 및 정규화, 차원 축소, 데이터 증강, 데이터 정제, 토큰화, 임베딩, 검증 등이 포함될 수 있다. 정규화 과 정은 초기 데이터 각각의 품질 지수를 계산하는 단계를 포함할 수 있으며, 상기 품질 지수가 데이터의 크기를 포함하는 경우, 그래픽 데이터의 최소사이즈를 구분하여 특정 크기 이하의 데이터를 제거하는 과정을 포함할 수 있다. 예를 들어, 데이터 원본 또는 특정 형식(예: 확장자)로 변환한 데이터가 약 200KB 또는 262,144 바이트 이하인 데이터는 S510 단계에서 제거될 수 있다. 또는, 일정한 데이터를 모두 동일한 크기(예: 512,512 바이 트)로 변환할 수 있다. 또한, 특수한 형태의 이미지를 정제 또는 수정하는 과정이 포함될 수 있다. 예를 들어, 작가가 의도적으로 다른 그림체로 생성한 그래픽 데이터를 제거하거나, 특수효과를 포함하는 그래픽 데이터 내 특수효과가 모델의 성능 에 영향을 끼치지 않도록 수정할 수 있다. 또한, 장치가 데이터를 가공하는 과정에는 그래픽 데이터에 데 이터의 특징을 설명하는 텍스트를 더하는 태깅(tagging) 과정이 포함될 수 있다. 상기 태깅 과정을 통하여 그래 픽 데이터의 화풍, 소재, 특징 등을 강조할 수 있다. S520 단계에서, 장치는 가공된 초기 데이터를 복수의 범주(또는 카테고리)로 분류할 수 있다. 장치가 수행하는 분류는 이진 분류(Binary Classification), 다중 클래스 분류(Multi-Class Classification), 및 다중 레이블 분류(Multi-Label Classification) 중 적어도 하나일 수 있다. 이진 분류는 두 개의 상호 배타적인 범주 중 하나에 입력을 할당하는 분류 방식이고, 다중 클래스 분류는 세 개 이상의 범주 중 하나에 입력을 할당하는 문제로, 이진 분류 및 다중 클래스 분류는 각 입력이 단 하나의 범주에만 속한다는 특징을 갖는다. 다중 레이블 분류는 각 입력이 하나 이상의 범주에 속할 수 있는 분류 방식이다. 초기 데이터 또는 가공된 초기 데이터는 분 류하고자 하는 범주로 라벨링된 데이터 또는 라벨링이 되지 않은 데이터일 수 있으며, 둘 모두를 포함할 수도 있다. 장치가 라벨링된 데이터를 획득하는 경우, 데이터의 각 레이블(label)에 기반하여 분류를 수행하는 것이 바람직하다. 또는, 태깅 과정에서 그래픽 데이터에 포함된(tag)에 기반하여 수행될 수 있다. 일 실시예에 서, S520 단계는 S510 단계보다 선행할 수 있다. 즉, 복수의 범주로 분류된 초기 데이터를 각 범주 내에서 가공 할 수 있다. 상기 복수의 범주 중 적어도 두 개는 각각 선화 데이터 및 채색 데이터와 관련된 것이 바람직하며, 그 외의 범 주는 배경 데이터, 인물 데이터 등과 관련될 수 있다. 또는 복수의 범주는 화풍 범주, 배경 범주, 및 인물 범주 중 적어도 하나를 포함할 수 있다. 복수의 범주가 화풍 범주를 포함하는 경우, 선화 데이터 및 채색 데이터는 초기 데이터 중에서도 화풍 범주로 분류된 초기 데이터만을 기반으로 획득한 것일 수 있다. 이와 유사하게, 배 경 데이터는 배경 범주로 분류된 초기 데이터를 기반으로 획득한 것이며, 인물 데이터는 인물 범주로 분류된 초 기 데이터를 기반으로 획득한 것일 수 있다. 배경 데이터는 배경 및 소재와 관련된 정보를 포함하는 배경 및 소 재 데이터일 수 있으며, 범주가 배경 데이터와 소재 데이터를 각각 포함할 수 있고, 그 외에도 특수효과 데이터 를 포함할 수 있는 등, 범주는 상술한 예에 한정되지 않으며 그래픽 데이터와 관련된 다양한 속성에 따라 상이 하게 정의될 수 있다. S530 단계에서, 장치는 각 범주별 데이터가 기 설정된 수 이상인지 확인할 수 있다. 이 때, 기 설정된 수 는 100개 이내인 것이 바람직하며, 범주별로 다를 수 있다. 예를 들어, 장치는 선화 데이터는 100개 이상 이고, 채색 데이터는 150개 이상인 지를 확인할 수 있다.각 범주별 데이터가 기 설정된 수 이상인 경우, 장치는 오류 데이터 제거를 수행할 수 있다. 장치가 수행하는 오류 데이터 제거에는 노이즈 제거가 포함될 수 있다. 구체적으로, 장치는 복수의 초기 데이터 중 노이즈를 포함하는 초기 데이터 자체를 제거하거나, 노이즈를 포함하는 초기 데이터에서 노이즈에 해당하는 부분만을 제거할 수 있다. 이때, 노이즈란, 학습에 방해되는 요소를 의미할 수 있다. 예를 들어, 작가가 그림 에 포함시킨 빛 특수 효과 및 블러(blur) 처리 효과 등을 의미할 수 있다. S530 단계에서 기 설정된 수 미만의 데이터를 갖는 범주가 존재하는 경우, 장치는 추가 데이터를 획득할 수 있다. 이 때, 추가 데이터는, 별도의 모델에 초기 데이터 중 적어도 일부를 학습시킨 후, 상기 별도의 모델 로부터 생성된 유사 데이터를 포함할 수 있다. 예를 들어, 선화 데이터의 수가 부족한 경우, 선화 데이터로 분 류되지 않는 초기 데이터로부터 선화(outline)만을 추출한 데이터를 생성하여 이를 선화 데이터로 활용할 수 있 다. 이 때, 장치는 초기 데이터로부터 선화만을 추출하기 위하여 외부에 초기 데이터와 요청을 전송하고, 그 결과로 선화 데이터를 전송받을 수 있다. 또한, S510 단계에서 크기 부적합 등을 이유로 제거된 초기 데이터 가 추가 데이터로 활용될 수 있다. 추가 데이터를 획득한 장치는 S520 단계를 반복할 수 있으며, 각 범주별 데이터가 기 설정된 수 이상일 경 우까지 추가 데이터 획득 과정을 2회 이상 반복할 수 있다. 최종적으로, 장치는 초기 데이터로부터 인물 데이터, 선화 및 채색 데이터, 배경 데이터 중 적어도 하나를 획득할 수 있다. 도 6은 본 발명의 일 실시예에 따라 출력 데이터를 생성하는 과정을 설명하기 위한 순서도이다. 도 6을 참고하면, 장치는 병합 비율, 인물 행렬, 화풍 행렬, 배경 행렬 중 적어도 두 개로부터 병합 행렬 을 생성할 수 있다. 상기 병합 비율은 인공 신경망의 블록(block) 또는 노드(node) 각각에 따라 다르게 설정될 수 있으며, 따라서 자명하게 인공 신경망의 각 레이어에 따라 다르게 설정될 수 있다. 일반적으로, 병합 비율은 입력 레이어(IL), 히든 레이어(HL), 및 출력 레이어(OL) 각각에 대하여 설정된다. 병합 비율은 또한, 장치(20 0)를 통하여 인물 데이터, 선화 데이터, 채색 데이터, 또는 배경 데이터를 학습하지 않은 인공신경망 모델의 기 존 가중치 행렬의 반영 비율을 더 지정할 수 있다. 또한, 장치는 내부적으로 또는 외부의 입력을 기반으로 병합 행렬을 생성하기 위한 학습률(learning rate)을 더 설정할 수 있다. 학습률은 모델별로, 또는 데이터별로 상이할 수 있으며, 반복 학습 시 동일한 학습률이 적용되는 것을 방지하기 위하여 학습률 스케쥴러 (learning rate scheduler)의 형태로 설정 및 인공 신경망 모델에 입력될 수 있다. 학습률 스케쥴러는 학습 도중 수정이 가능할 수 있다. 또한, 병합 행렬은 행렬 간 2회 이상의 병합을 통하여 생성될 수 있다. 예를 들어, 화풍 행렬과 배경 행렬을 병 합한 후, 인물 행렬을 추가로 병합할 수 있다. 이 때, 병합 비율은 제1 병합 비율과 제2 병합 비율을 포함하며, 제1 병합 비율과 제2 병합 비율은 서로 독립적인 것이 바람직하다. S620 단계에서, 장치는 출력 데이터를 생성하기 위한 엔진을 선정할 수 있다. 상기 엔진은 생성형 인공지 능 모델이라 칭할 수 있으며, 특히 디퓨전 모델에서 사용되는 경우 체크포인트(checkpoint)라 칭할 수 있다. S620 단계에서, 장치는 초기 데이터와의 유사도를 기초로 엔진을 선정할 수 있다. 이때, 엔진은 장치의 메 모리 내 존재하는 생성형 인공지능 모델 또는 생성형 인공지능 모델의 일부일 수 있다. 장치는 엔진 을 선정한 후 행렬(예: 화풍 행렬, 병합 행렬) 및 프롬프트를 통하여 적어도 하나의 출력 데이터를 생성할 수 있다. S630 단계에서, 장치는 출력 데이터 확정 여부를 결정할 수 있다. S630 단계는 외부(예: 작가, 사용자)에 출력 데이터를 출력하고 외부로부터 입력받은 정보에 기반하여 결정될 수 있으며, 장치가 직접 출력 데이 터와 초기 데이터 간 유사도를 측정하여 수행할 수 있다. 상기 유사도가 기 설정된 기준치 이상인 경우, 장치 는 출력 데이터를 확정하고 모델 학습 과정을 종료할 수 있다. 상기 기 설정된 기준치는 약 0.7일 수 있다. S630 단계에서 장치가 출력 데이터를 수정하는 것으로 결정한 경우, 장치는 병합 행렬 또는 엔진을 수정할 수 있다. 병합 행렬을 수정하기 위해서는 병합 비율을 조정하거나 인물 데이터, 선화 데이터, 채색 데이 터, 및 배경 데이터 중 적어도 하나에 대하여 추가 또는 삭제 과정을 거쳐 행렬을 재생성할 수 있다. 이러한 과 정은 출력 데이터가 확정될 때 까지 2회 이상 반복될 수 있다. 상술한 프로세스는 작가의 그림을 효과적으로 재현하며, 작가의 화풍으로 새로운 이미지를 생성할 뿐만 아니라 작가의 습관과 특징을 학습함으로써 학습 데이터, 즉 초기 데이터에 존재하지 않았던 새로운 형태의 그림을 생 성할 수 있다. 또한, 러프 스케치와 스토리보드 만으로도 작가의 그림과 유사한 완성 원고를 생성할 수 있으며,자동화된 채색이 가능한 시스템을 제공할 수 있다. 특히, 웹툰 제작 분야에서 사용되는 경우, 제작 속도 향상은 물론 작가의 노동력 의존성 해소, 자동 채색처리 등 제작 속도 향상 및 효율 증대라는 장점을 제공할 수 있다. 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시예에 한"}
{"patent_id": "10-2024-7039320", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통 상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안 될 것이다."}
{"patent_id": "10-2024-7039320", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 모델의 구조를 설명하기 위한 도면이다. 도 2는 본 발명의 일 실시예와 관련된 생성형 인공지능 모델 학습 시스템의 네트워크 환경을 나타낸 도면이다. 도 3은 본 발명의 일 실시예에 따라 생성형 인공지능 모델을 학습시키기 위해 사용되는 장치의 구성을 도시한 블록도이다. 도 4는 본 발명의 일 실시예에 따라 생성형 인공지능 모델을 학습시키고 출력값을 획득하는 방법을 도시한 순서 도이다. 도 5는 본 발명의 일 실시예에 따라 초기 데이터로부터 인물 데이터, 선화 데이터 및 채색 데이터, 또는 배경 데이터를 획득하는 과정을 도시한 순서도이다. 도 6은 본 발명의 일 실시예에 따라 출력 데이터를 생성하는 과정을 설명하기 위한 순서도이다."}
