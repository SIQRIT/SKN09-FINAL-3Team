{"patent_id": "10-2023-0055550", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0155965", "출원번호": "10-2023-0055550", "발명의 명칭": "집단 지성을 이용한 정보 처리 시스템 및 그 방법", "출원인": "유한회사 닥터다비드", "발명자": "김행철"}}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 상기 비교대상 영상과 관련한 메타 정보 및 사용자 정보를 수집하고, 상기 로우 데이터와 상기 비교 대상 영상을 근거로생성될 아바타 및 아이템 중 적어도 하나의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단말; 및상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 상기 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보, 상기 레벨 선택 라벨링에 대한 정보, 상기 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보 및, 단말의 식별 정보를 수신하고, 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 상기 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보 및, 상기 레벨 선택 라벨링에 대한 정보를 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 딥페이크 영상인 라스트 레벨(last level) 영상을 생성하는 서버를 포함하는 집단 지성을 이용한 정보 처리 시스템."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 사용자 정보는,상기 사용자와 관련한 MBTI 유형을 포함하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 시스템."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 서버는,개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말을 대상으로 게임 시작 시,MBTI 점수 체계를 제정하고, 상기 단말과 연동하여 상기 단말의 사용자와 관련한 아바타 및 아이템과, 상기 게임에 참여한 다른 게임 참가자와 관련한 아바타 및 아이템을 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을수행하고, 상기 게임에 참여한 복수의 단말의 사용자와 관련한 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및 아이템에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로 하여 다른기계 학습을 수행하고, 다른 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 시스템."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "단말에 의해, 상기 단말의 사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보,비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보 및 사용자 정보를 수집하는 단계;상기 단말에 의해, 상기 로우 데이터와 상기 비교 대상 영상을 근거로 생성될 아바타 및 아이템 중 적어도 하나의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단계;서버에 의해, 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보,상기 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보, 상기 레벨 선택 라벨링에대한 정보, 상기 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보 및, 단말의 식별 정보를수신하는 단계;상기 서버에 의해, 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 상기 비교 대상영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보 및, 상기 레벨 선택 라벨링에 대한 정보를입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 딥페이크 영상인 라스트 레벨(last level) 영상을 생성하는 단계;공개특허 10-2023-0155965-3-상기 서버에 의해, 상기 생성된 라스트 레벨 영상을 상기 단말에 전송하는 단계; 및상기 단말에 의해, 상기 서버로부터 전송되는 라스트 레벨 영상을 출력하는 단계를 포함하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 라스트 레벨 영상은,상기 로우 데이터와 상기 비교 대상 영상을 딥페이크하여 생성되며, 아바타 및 아이템 중 적어도 하나를 포함하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 라스트 레벨 영상을 생성하는 단계는,상기 레벨 선택 라벨링에 대한 정보에 따라 트레이닝율이 다르게 설정되어 실제 상기 로우 데이터와 상기 비교대상 영상과의 일치율이 다르게 설정된 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 4 항에 있어서,상기 라스트 레벨 영상을 생성하는 단계는,상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 상기 비교 대상 영상, 상기 비교 대상영상과 관련한 메타 정보, 상기 사용자 정보 및, 상기 레벨 선택 라벨링에 대한 정보를 미리 설정된 생성 모델의 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 상기 로우 데이터와 상기 비교 대상 영상을 딥페이크한 상기 라스트 레벨 영상을 생성하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 4 항에 있어서,상기 서버에 의해, 상기 라스트 레벨 영상을 생성하기 전에, 상기 로우 데이터와 비교 대상 영상 관련 라스트레벨 영상 생성 요청 정보를 근거로 상기 레벨 선택 라벨링에 대한 정보에 대응하는 MBTI 점수에 대해서 상기단말의 사용자 계정에 적립된 MBTI 점수를 이용해서 결제 기능을 수행하는 단계를 더 포함하는 것을 특징으로하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 4 항에 있어서,상기 단말에 의해, 상기 서버 및 결제 서버와 연동하여, 상기 라스트 레벨 영상에 포함된 아바타 및 아이템 중적어도 하나에 대한 레벨 강화 기능을 수행하는 단계를 더 포함하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 4 항에 있어서,상기 서버에 의해, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말을 대상으로게임 시작 시, MBTI 점수 체계를 제정하는 단계;상기 단말에 의해, 상기 서버와 연동하여, 상기 단말의 사용자와 관련한 아바타 및 아이템과, 상기 게임에 참여한 다른 게임 참가자와 관련한 아바타 및 아이템을 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을 수행하는단계; 및상기 서버에 의해, 상기 게임에 참여한 복수의 단말의 사용자와 관련한 게임 참가자별 MBTI 선택라벨링에 대한공개특허 10-2023-0155965-4-정보, 사용자별 아바타 및 아이템에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로하여 다른 기계 학습을 수행하고, 다른 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정하는 단계를 더포함하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 MBTI 점수 체계를 제정하는 단계는,게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 상기 게임을 관전 중이거나 미리 설정된 게임상의국가기관, 회사 및 상점 중 어느 하나에 소속된 사용자가 소지한 다른 복수의 단말 및, 상기 게임과 유사한 게임에 참여했던 다른 사용자가 소지한 또 다른 복수의 단말과 연동하여, 상기 게임과 관련한 MBTI 점수 체계를제정하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서,상기 MBTI 점수 체계는,상기 게임과 관련해서 경쟁 게임을 진행하고 승패를 결정짓는 구성 요소로, 상기 게임과 관련한 헌법, 법률 및규칙을 포함하며, 아바타의 MBTI 유형과 아이템의 MBTI 유형에 따른 상극과 상생의 법칙으로 승부를 결정짓는방식인 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 게임 참가자별 MBTI 선택라벨링 기능을 수행하는 단계는,상기 게임에 참여한 모든 사용자와 관련한 아바타 및 아이템에 대해서 상기 단말의 사용자가 생각하는 MBTI 유형 및 상기 MBTI 유형에 따른 항목별 점수를 설정하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 게임에서의 승패를 결정하는 단계는,상기 다른 기계 학습 결과인 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수를 예측하고, 상기 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, 상기 MBTI 점수체계 및, 상생과 상극의 라벨별점수를 근거로 게임의 승패를 결정하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 사용자 정보 및, 레벨 선택 라벨링에 대한 정보를 입력값으로 하여 기계 학습을 수행하고, 기계학습 결과를 근거로 딥페이크 영상인 라스트 레벨 영상을 생성하고, 상기 생성된 라스트 레벨 영상을 제공하는서버; 및상기 서버 및 외부 서버와 연동하여, 상기 서버로부터 제공되는 상기 라스트 레벨 영상을 이용한 특정 기능을수행하는 단말을 포함하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 시스템."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "서버에 의해, 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 사용자 정보 및, 레벨 선택 라벨링에 대한 정보를 입력값으로 하여 기계 학습을수행하고, 기계 학습 결과를 근거로 딥페이크 영상인 라스트 레벨 영상을 생성하는 단계;단말에 의해, 상기 서버로부터 제공되는 상기 라스트 레벨 영상을 수신하는 단계; 및공개특허 10-2023-0155965-5-상기 단말에 의해, 상기 서버 및 외부 서버와 연동하여, 상기 라스트 레벨 영상을 이용한 특정 기능을 수행하는단계를 포함하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 특정 기능을 수행하는 단계는,상기 라스트 레벨 영상에 포함된 아바타 및 아이템 중 적어도 하나를 이용한, 문자메시지 송/수신 기능, 게시물작성 기능, 이모티콘/아이콘 제작 및 사용 기능, 채팅 기능 및, 상기 외부 서버에서 제공하는 게임 내 아바타또는 아이템에 적용하는 기능 중 적어도 하나의 기능을 수행하는 것을 특징으로 하는 집단 지성을 이용한 정보처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및 사용자 정보를 수집하는단말; 및상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 사용자 정보및 상기 단말의 식별 정보를 수신하고, 상기 수신된 사용자 정보를 상기 수신된 로우 데이터에 매핑하고, 상기단말과 연동하여 상기 사용자 정보가 매핑된 로우 데이터를 이용해서 게임 기능을 수행하는 서버를 포함하는 집단 지성을 이용한 정보 처리 시스템."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "단말에 의해, 상기 단말의 사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및사용자 정보를 수집하는 단계;서버에 의해, 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보,사용자 정보 및 상기 단말의 식별 정보를 수신하는 단계;상기 서버에 의해, 상기 수신된 사용자 정보를 상기 수신된 로우 데이터에 매핑하는 단계; 및상기 단말에 의해, 상기 서버와 연동하여, 상기 사용자 정보가 매핑된 로우 데이터를 이용해서 게임 기능을 수행하는 단계를 포함하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 사용자 정보가 매핑된 로우 데이터를 이용해서 게임 기능을 수행하는 단계는,상기 게임 기능이 미팅 게임일 때, 상기 서버에 미리 등록된 복수의 사용자 정보가 적용된 복수의 로우 데이터중에서, 상기 사용자 정보가 적용된 로우 데이터를 이용해서 상기 사용자 정보에 포함된 MBTI 유형 및 해당MBTI 유형에 따른 항목별 점수를 근거로 미리 설정된 상생 관계 및 상극 관계에 따른 서로 다른 사용자 정보가적용된 하나 이상의 다른 로우 데이터를 확인하는 과정;상기 서버에 의해, 상기 확인된 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터를 상기 단말에제공하는 과정;상기 단말에 의해, 상기 서버로부터 제공되는 상기 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터를 표시하는 과정; 및상기 단말에 표시되는 상기 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터 중에서 특정 다른로우 데이터가 선택되는 경우, 상기 단말에 의해, 상기 서버 및 상기 선택된 특정 다른 로우 데이터에 대응하는다른 단말과 연동하여, 미팅 기능 또는 채팅 기능을 수행하는 과정을 포함하는 것을 특징으로 하는 집단 지성을이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "공개특허 10-2023-0155965-6-사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및 사용자 정보를 수집하고,상기 사용자 정보가 매핑된 로우 데이터의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단말; 및상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 사용자 정보및 상기 단말의 식별 정보를 수신하고, 상기 수신된 사용자 정보를 상기 수신된 로우 데이터에 매핑하고, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말을 대상으로 게임 시작 시, MBTI 점수 체계를 제정하고, 상기 단말과 연동하여 게임에 참여한 상기 단말의 사용자와 관련한 게임 캐릭터와, 상기게임에 참여한 다른 게임 참가자와 관련한 게임 캐릭터를 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을 수행하고, 상기 게임에 참여한 복수의 단말의 사용자와 관련한 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로 하여 기계 학습을수행하고, 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정하는 것을 특징으로 하는 집단 지성을 이용한정보 처리 시스템."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "단말에 의해, 상기 단말의 사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및사용자 정보를 수집하는 단계;서버에 의해, 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보,사용자 정보 및 상기 단말의 식별 정보를 수신하는 단계;상기 서버에 의해, 상기 수신된 사용자 정보를 상기 수신된 로우 데이터에 매핑하는 단계;상기 단말에 의해, 상기 사용자 정보가 매핑된 로우 데이터의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단계;상기 서버에 의해, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말을 대상으로게임 시작 시, MBTI 점수 체계를 제정하는 단계;상기 단말에 의해, 상기 서버와 연동하여, 게임에 참여한 상기 단말의 사용자와 관련한 게임 캐릭터와, 상기 게임에 참여한 다른 게임 참가자와 관련한 게임 캐릭터를 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을 수행하는 단계; 및상기 서버에 의해, 상기 게임에 참여한 복수의 단말의 사용자와 관련한 게임 참가자별 MBTI 선택라벨링에 대한정보, 사용자별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로 하여기계 학습을 수행하고, 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정하는 단계를 더 포함하는 것을 특징으로 하는 집단 지성을 이용한 정보 처리 방법."}
{"patent_id": "10-2023-0055550", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 22 항에 있어서,상기 게임에서의 승패를 결정하는 단계는,아이템, 상품 정보 및 게임 상대자를 추천하는 정보를 포함하는 것을 특징으로 하는 집단 지성을 이용한 정보처리 방법."}
{"patent_id": "10-2023-0055550", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 집단 지성을 이용한 정보 처리 시스템 및 그 방법을 개시한다. 즉, 본 발명은 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이터 등에 대해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대해서 레벨 강화 기능 등을 수행하고, 최종 (뒷면에 계속)"}
{"patent_id": "10-2023-0055550", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 집단 지성을 이용한 정보 처리 시스템 및 그 방법에 관한 것으로서, 특히 사용자로부터 제공되는 로 우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이터 등에 대해서 미리 설정된 생성 모델을 통해 학 습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대해서 레벨 강화 기능 등을 수행하고, 최종 레 벨이 적용된 라스트 레벨 영상을 이용해서 게임에 참여하고, 해당 게임에 참여한 게임 참가자 및 관전자 참여에 의해 MBTI 점수 체계를 제정하고, 게임 참가자 자신의 아바타 및 아이템과 다른 게임 참가자의 아바타 및 아이 템을 참조하여 전체 게임 참가자에 대한 MBTI 선택라벨링 기능을 수행하고, 게임 참가자별 MBTI 선택라벨링에 대한 정보, MBTI 점수체계 등에 대해서 승패 결정 모델을 통해 다른 학습 기능을 수행하고, 승패 결정 모델의 출력값인 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수를 예측하고, 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정 하고, 결정된 게임 결과를 근거로 게임 참가자별 아바타 및 아이템의 레벨을 유지/업/다운하는 집단 지성을 이 용한 정보 처리 시스템 및 그 방법을 제공하는 데 있다."}
{"patent_id": "10-2023-0055550", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "집단 지성은 집단 구성원들이 서로 협력하거나 경쟁하여 쌓은 지적 능력의 결과로 얻어진 지성. 또는 그러한 집 단적 능력을 나타낸다. 이러한 집단 지성은 아바타, 아이템, 로보틱스 등의 정보 데이터베이스 기술의 발전에 따라, 새로운 빅데이터 기반의 지식 서비스와의 연결에 대한 필요성이 존재한다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1859198호 [제목: 집단지성 서비스 시스템 및 그 방법]"}
{"patent_id": "10-2023-0055550", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이터 등 에 대해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대 해서 레벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해서 게임에 참여하고, 해당 게임에 참여한 게임 참가자 및 관전자 참여에 의해 MBTI 점수 체계를 제정하고, 게임 참가자 자신의 아바타 및 아이템과 다른 게임 참가자의 아바타 및 아이템을 참조하여 전체 게임 참가자에 대한 MBTI 선택라벨링 기능을 수행하고, 게임 참가자별 MBTI 선택라벨링에 대한 정보, MBTI 점수체계 등에 대해서 승패 결정 모델을 통해 다 른 학습 기능을 수행하고, 승패 결정 모델의 출력값인 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점 수를 예측하고, 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상극 의 라벨별 점수를 근거로 게임의 승패를 결정하고, 결정된 게임 결과를 근거로 게임 참가자별 아바타 및 아이템 의 레벨을 유지/업/다운하는 집단 지성을 이용한 정보 처리 시스템 및 그 방법을 제공하는 데 있다. 본 발명의 다른 목적은 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이 터 등에 대해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상 에 대해서 레벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해서 문자메시지 송/수 신 기능, 게시물 작성 기능, 이모티콘/아이콘 생성 및 적용 기능, 채팅 기능, 외부 서버에서 제공하는 게임 내 아바타 또는 아이템에 적용하는 기능 등을 수행하는 집단 지성을 이용한 정보 처리 시스템 및 그 방법을 제공하 는 데 있다. 본 발명의 또 다른 목적은 사용자로부터 제공되는 로우 데이터에 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 포함하는 사용자 정보를 적용하고, 사용자 정보가 적용된 로우 데이터를 이용해서 게임 기능을 수행하는 집단 지성을 이용한 정보 처리 시스템 및 그 방법을 제공하는 데 있다."}
{"patent_id": "10-2023-0055550", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 시스템은 사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보 및 사용자 정 보를 수집하고, 상기 로우 데이터와 상기 비교 대상 영상을 근거로 생성될 아바타 및 아이템 중 적어도 하나의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단말; 및 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이 터, 상기 로우 데이터와 관련한 메타 정보, 상기 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상 기 사용자 정보, 상기 레벨 선택 라벨링에 대한 정보, 상기 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영 상 생성 요청 정보 및, 단말의 식별 정보를 수신하고, 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련 한 메타 정보, 상기 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보 및, 상기 레 벨 선택 라벨링에 대한 정보를 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 딥페이크 영상인 라스트 레벨(last level) 영상을 생성하는 서버를 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 사용자 정보는, 상기 사용자와 관련한 MBTI 유형을 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 서버는, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말을 대상으로 게임 시작 시, MBTI 점수 체계를 제정하고, 상기 단말과 연동하여 상기 단말의 사용자 와 관련한 아바타 및 아이템과, 상기 게임에 참여한 다른 게임 참가자와 관련한 아바타 및 아이템을 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을 수행하고, 상기 게임에 참여한 복수의 단말의 사용자와 관련한 게임 참 가자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및 아이템에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로 하여 다른 기계 학습을 수행하고, 다른 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정할 수 있다. 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 방법은 단말에 의해, 상기 단말의 사용자와 관련한 하 나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보 및 사용자 정보를 수집하는 단계; 상기 단말에 의해, 상기 로우 데이터와 상기 비교 대상 영상을 근 거로 생성될 아바타 및 아이템 중 적어도 하나의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단계; 서버에 의해, 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 상기 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보, 상기 레벨 선택 라벨링에 대한 정보, 상기 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보 및, 단말의 식별 정보를 수신 하는 단계; 상기 서버에 의해, 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 상기 비 교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보 및, 상기 레벨 선택 라벨링에 대한 정보를 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 딥페이크 영상인 라스트 레벨(last level) 영상을 생성하는 단계; 상기 서버에 의해, 상기 생성된 라스트 레벨 영상을 상기 단말에 전송하는 단계; 및 상기 단말에 의해, 상기 서버로부터 전송되는 라스트 레벨 영상을 출력하는 단계를 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 라스트 레벨 영상은, 상기 로우 데이터와 상기 비교 대상 영상을 딥페이크하 여 생성되며, 아바타 및 아이템 중 적어도 하나를 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 라스트 레벨 영상을 생성하는 단계는, 상기 레벨 선택 라벨링에 대한 정보에 따라 트레이닝율이 다르게 설정되어 실제 상기 로우 데이터와 상기 비교 대상 영상과의 일치율이 다르게 설정될 수 있다. 본 발명과 관련된 일 예로서 상기 라스트 레벨 영상을 생성하는 단계는, 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 상기 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 상기 사용자 정보 및, 상기 레벨 선택 라벨링에 대한 정보를 미리 설정된 생성 모델의 입력값으로 하여 기계 학습을 수행하 고, 기계 학습 결과를 근거로 상기 로우 데이터와 상기 비교 대상 영상을 딥페이크한 상기 라스트 레벨 영상을 생성할 수 있다. 본 발명과 관련된 일 예로서 상기 서버에 의해, 상기 라스트 레벨 영상을 생성하기 전에, 상기 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보를 근거로 상기 레벨 선택 라벨링에 대한 정보에 대응하 는 MBTI 점수에 대해서 상기 단말의 사용자 계정에 적립된 MBTI 점수를 이용해서 결제 기능을 수행하는 단계를 더 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 단말에 의해, 상기 서버 및 결제 서버와 연동하여, 상기 라스트 레벨 영상에 포함된 아바타 및 아이템 중 적어도 하나에 대한 레벨 강화 기능을 수행하는 단계를 더 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 서버에 의해, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장 하는 복수의 단말을 대상으로 게임 시작 시, MBTI 점수 체계를 제정하는 단계; 상기 단말에 의해, 상기 서버와 연동하여, 상기 단말의 사용자와 관련한 아바타 및 아이템과, 상기 게임에 참여한 다른 게임 참가자와 관련한 아바타 및 아이템을 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을 수행하는 단계; 및 상기 서버에 의해, 상 기 게임에 참여한 복수의 단말의 사용자와 관련한 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바 타 및 아이템에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로 하여 다른 기계 학습 을 수행하고, 다른 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정하는 단계를 더 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 MBTI 점수 체계를 제정하는 단계는, 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 상기 게임을 관전 중이거나 미리 설정된 게임상의 국가기관, 회사 및 상점 중 어느 하나에 소속된 사용자가 소지한 다른 복수의 단말 및, 상기 게임과 유사한 게임에 참여했던 다른 사용자가 소지한 또다른 복수의 단말과 연동하여, 상기 게임과 관련한 MBTI 점수 체계를 제정할 수 있다. 본 발명과 관련된 일 예로서 상기 MBTI 점수 체계는, 상기 게임과 관련해서 경쟁 게임을 진행하고 승패를 결정 짓는 구성 요소로, 상기 게임과 관련한 헌법, 법률 및 규칙을 포함하며, 아바타의 MBTI 유형과 아이템의 MBTI 유형에 따른 상극과 상생의 법칙으로 승부를 결정짓는 방식일 수 있다. 본 발명과 관련된 일 예로서 상기 게임 참가자별 MBTI 선택라벨링 기능을 수행하는 단계는, 상기 게임에 참여한 모든 사용자와 관련한 아바타 및 아이템에 대해서 상기 단말의 사용자가 생각하는 MBTI 유형 및 상기 MBTI 유형 에 따른 항목별 점수를 설정할 수 있다. 본 발명과 관련된 일 예로서 상기 게임에서의 승패를 결정하는 단계는, 상기 다른 기계 학습 결과인 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수를 예측하고, 상기 예측된 전체 게임 참가자의 아바타 및 아이템 별 MBTI 라벨별 점수, 상기 MBTI 점수체계 및, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정할 수 있다. 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 시스템은 하나 이상의 로우 데이터, 상기 로우 데이터 와 관련한 메타 정보, 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 사용자 정보 및, 레벨 선택 라벨링에 대한 정보를 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 딥페이크 영상인 라스 트 레벨 영상을 생성하고, 상기 생성된 라스트 레벨 영상을 제공하는 서버; 및 상기 서버 및 외부 서버와 연동 하여, 상기 서버로부터 제공되는 상기 라스트 레벨 영상을 이용한 특정 기능을 수행하는 단말을 포함할 수 있다. 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 방법은 서버에 의해, 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 상기 비교 대상 영상과 관련한 메타 정보, 사용자 정보 및, 레벨 선택 라벨링에 대한 정보를 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 딥페이크 영 상인 라스트 레벨 영상을 생성하는 단계; 단말에 의해, 상기 서버로부터 제공되는 상기 라스트 레벨 영상을 수 신하는 단계; 및 상기 단말에 의해, 상기 서버 및 외부 서버와 연동하여, 상기 라스트 레벨 영상을 이용한 특정 기능을 수행하는 단계를 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 특정 기능을 수행하는 단계는, 상기 라스트 레벨 영상에 포함된 아바타 및 아 이템 중 적어도 하나를 이용한, 문자메시지 송/수신 기능, 게시물 작성 기능, 이모티콘/아이콘 제작 및 사용 기 능, 채팅 기능 및, 상기 외부 서버에서 제공하는 게임 내 아바타 또는 아이템에 적용하는 기능 중 적어도 하나 의 기능을 수행할 수 있다. 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 시스템은 사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및 사용자 정보를 수집하는 단말; 및 상기 단말로부터 전송되는 상기 하 나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 사용자 정보 및 상기 단말의 식별 정보를 수신 하고, 상기 수신된 사용자 정보를 상기 수신된 로우 데이터에 매핑하고, 상기 단말과 연동하여 상기 사용자 정 보가 매핑된 로우 데이터를 이용해서 게임 기능을 수행하는 서버를 포함할 수 있다. 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 방법은 단말에 의해, 상기 단말의 사용자와 관련한 하 나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및 사용자 정보를 수집하는 단계; 서버에 의해, 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 사용자 정보 및 상기 단말의 식별 정보를 수신하는 단계; 상기 서버에 의해, 상기 수신된 사용자 정보를 상기 수신된 로우 데이터에 매핑하는 단계; 및 상기 단말에 의해, 상기 서버와 연동하여, 상기 사용자 정보가 매핑된 로우 데이터 를 이용해서 게임 기능을 수행하는 단계를 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 사용자 정보가 매핑된 로우 데이터를 이용해서 게임 기능을 수행하는 단계는, 상기 게임 기능이 미팅 게임일 때, 상기 서버에 미리 등록된 복수의 사용자 정보가 적용된 복수의 로우 데이터 중에서, 상기 사용자 정보가 적용된 로우 데이터를 이용해서 상기 사용자 정보에 포함된 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 근거로 미리 설정된 상생 관계 및 상극 관계에 따른 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터를 확인하는 과정; 상기 서버에 의해, 상기 확인된 서로 다른 사용자 정보 가 적용된 하나 이상의 다른 로우 데이터를 상기 단말에 제공하는 과정; 상기 단말에 의해, 상기 서버로부터 제 공되는 상기 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터를 표시하는 과정; 및 상기 단말에 표시되는 상기 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터 중에서 특정 다른 로우 데이터가 선택되는 경우, 상기 단말에 의해, 상기 서버 및 상기 선택된 특정 다른 로우 데이터에 대응하는 다른 단말과연동하여, 미팅 기능 또는 채팅 기능을 수행하는 과정을 포함할 수 있다. 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 시스템은 사용자와 관련한 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및 사용자 정보를 수집하고, 상기 사용자 정보가 매핑된 로우 데이터의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단말; 및 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이 터, 상기 로우 데이터와 관련한 메타 정보, 사용자 정보 및 상기 단말의 식별 정보를 수신하고, 상기 수신된 사 용자 정보를 상기 수신된 로우 데이터에 매핑하고, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말을 대상으로 게임 시작 시, MBTI 점수 체계를 제정하고, 상기 단말과 연동하여 게임에 참 여한 상기 단말의 사용자와 관련한 게임 캐릭터와, 상기 게임에 참여한 다른 게임 참가자와 관련한 게임 캐릭터 를 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을 수행하고, 상기 게임에 참여한 복수의 단말의 사용자와 관 련한 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정할 수 있다. 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 방법은 단말에 의해, 상기 단말의 사용자와 관련한 하 나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보 및 사용자 정보를 수집하는 단계; 서버에 의해, 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터, 상기 로우 데이터와 관련한 메타 정보, 사용자 정보 및 상기 단말의 식별 정보를 수신하는 단계; 상기 서버에 의해, 상기 수신된 사용자 정보를 상기 수신된 로우 데이터에 매핑하는 단계; 상기 단말에 의해, 상기 사용자 정보가 매핑된 로우 데이터의 레벨을 선택하는 레벨 선택 라벨링을 수행하는 단계; 상기 서버에 의해, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입 장하는 복수의 단말을 대상으로 게임 시작 시, MBTI 점수 체계를 제정하는 단계; 상기 단말에 의해, 상기 서버 와 연동하여, 게임에 참여한 상기 단말의 사용자와 관련한 게임 캐릭터와, 상기 게임에 참여한 다른 게임 참가 자와 관련한 게임 캐릭터를 참조하여, 게임 참가자별 MBTI 선택라벨링 기능을 수행하는 단계; 및 상기 서버에 의해, 상기 게임에 참여한 복수의 단말의 사용자와 관련한 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자 별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보 및, 상기 MBTI 점수 체계를 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 상기 게임에서의 승패를 결정하는 단계를 더 포함할 수 있다. 본 발명과 관련된 일 예로서 상기 게임에서의 승패를 결정하는 단계는, 아이템, 상품 정보 및 게임 상대자를 추 천하는 정보를 포함할 수 있다."}
{"patent_id": "10-2023-0055550", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이터 등에 대해 서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대해서 레 벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해서 게임에 참여하고, 해당 게임에 참여한 게임 참가자 및 관전자 참여에 의해 MBTI 점수 체계를 제정하고, 게임 참가자 자신의 아바타 및 아이템 과 다른 게임 참가자의 아바타 및 아이템을 참조하여 전체 게임 참가자에 대한 MBTI 선택라벨링 기능을 수행하 고, 게임 참가자별 MBTI 선택라벨링에 대한 정보, MBTI 점수체계 등에 대해서 승패 결정 모델을 통해 다른 학습 기능을 수행하고, 승패 결정 모델의 출력값인 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수를 예측 하고, 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정하고, 결정된 게임 결과를 근거로 게임 참가자별 아바타 및 아이템의 레벨을 유지/업/다운함으로써, 로우 데이터와 관련한 아바타 및/또는 아이템을 사용자에게 제공하고, 로우 데이터에 대 한 라벨링을 통해 인공지능의 추론 능력을 향상시키고, 로우 데이터 등을 근거로 생성된 라스트 레벨 영상에 대 응하는 아바타 및 아이템을 이용해서 다양한 게임을 수행함에 따라 사용자의 흥미를 높일 수 있는 효과가 있다. 또한, 본 발명은 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이터 등 에 대해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대 해서 레벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해서 문자메시지 송/수신 기 능, 게시물 작성 기능, 이모티콘/아이콘 생성 및 적용 기능, 채팅 기능, 외부 서버에서 제공하는 게임 내 아바 타 또는 아이템에 적용하는 기능 등을 수행함으로써, 인공지능에 따른 결과물인 라스트 레벨 영상에 대응하는 아바타 및 아이템을 다양하게 활용할 수 있는 효과가 있다. 또한, 본 발명은 사용자로부터 제공되는 로우 데이터에 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 포 함하는 사용자 정보를 적용하고, 사용자 정보가 적용된 로우 데이터를 이용해서 게임 기능을 수행함으로써, 사용자의 MBTI 유형에 따른 다양한 게임을 수행함에 따라 사용자의 관심 및 흥미를 유발할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0055550", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에서 사용되는 기술적 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려 는 의도가 아님을 유의해야 한다. 또한, 본 발명에서 사용되는 기술적 용어는 본 발명에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술적 용어일 때에 는 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에서 사용 되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하며, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 본 발명에서 \"구성된다\" 또는 \"포함한다\" 등의 용어는 발명에 기재된 여러 구성 요소들 또는 여러 단계를 반드 시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수 도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 또한, 본 발명에서 사용되는 제 1, 제 2 등과 같이 서수를 포함하는 용어는 구성 요소들을 설명하는데 사용될 수 있지만, 구성 요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성 요소를 다른 구성 요소 로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성 요소는 제 2 구성 요소로 명명될 수 있고, 유사하게 제 2 구성 요소도 제 1 구성 요소로 명명될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일 하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 발명의 사상을 쉽게 이해할 수 있도록 하기위한 것일 뿐, 첨부된 도면에 의해 본 발명의 사상이 제한되는 것으로 해석되어서는 아니 됨을 유의해야 한다. 도 1은 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 시스템의 구성을 나타낸 블록도이다. 도 1에 도시한 바와 같이, 집단 지성을 이용한 정보 처리 시스템은 단말 및 서버로 구성된다. 도 1에 도시된 집단 지성을 이용한 정보 처리 시스템의 구성 요소 모두가 필수 구성 요소인 것은 아니며, 도 1 에 도시된 구성 요소보다 많은 구성 요소에 의해 집단 지성을 이용한 정보 처리 시스템이 구현될 수도 있고, 그보다 적은 구성 요소에 의해서도 집단 지성을 이용한 정보 처리 시스템이 구현될 수도 있다. 상기 단말은 스마트폰(Smart Phone), 휴대 단말기(Portable Terminal), 이동 단말기(Mobile Terminal), 폴더블 단말기(Foldable Terminal), 개인 정보 단말기(Personal Digital Assistant: PDA), PMP(Portable Multimedia Player) 단말기, 텔레매틱스(Telematics) 단말기, 내비게이션(Navigation) 단말기, 개인용 컴퓨터 (Personal Computer), 노트북 컴퓨터, 슬레이트 PC(Slate PC), 태블릿 PC(Tablet PC), 울트라북(ultrabook), 웨어러블 디바이스(Wearable Device, 예를 들어, 워치형 단말기(Smartwatch), 글래스형 단말기(Smart Glass), HMD(Head Mounted Display) 등 포함), 와이브로(Wibro) 단말기, IPTV(Internet Protocol Television) 단말기, 스마트 TV, 디지털방송용 단말기, AVN(Audio Video Navigation) 단말기, A/V(Audio/Video) 시스템, 플렉시블 단말기(Flexible Terminal), 디지털 사이니지 장치, VR 시뮬레이터, 로봇(robot) 등과 같은 다양한 단말기에 적 용될 수 있다. 상기 서버는 클라우드 컴퓨팅(cloud computing), 그리드 컴퓨팅(grid computing), 서버 기반 컴퓨팅 (server-based computing), 유틸리티 컴퓨팅(utility computing), 네트워크 컴퓨팅(network computing), 퀀텀 클라우드 컴퓨팅(quantum cloud computing), 웹 서버, 데이터베이스 서버, 프록시 서버 등의 형태로 구현될 수 있다. 또한, 상기 서버에는 네트워크 부하 분산 메커니즘, 내지 해당 서버가 인터넷 또는 다른 네트 워크상에서 동작할 수 있도록 하는 다양한 소프트웨어 중 하나 이상이 설치될 수 있으며, 이를 통해 컴퓨터화된 시스템으로 구현될 수 있다. 또한, 네트워크는 http 네트워크일 수 있으며, 전용 회선(private line), 인트라넷 또는 임의의 다른 네트워크일 수 있다. 나아가, 상기 단말 및 상기 서버 간의 연결은 데이터가 임의 의 해커 또는 다른 제3자에 의한 공격을 받지 않도록 보안 네트워크로 연결될 수 있다. 또한, 상기 서버는 복수의 데이터베이스 서버를 포함할 수 있으며, 이러한 데이터베이스 서버가 분산 데이터베이스 서버 아키텍처 를 비롯한 임의의 유형의 네트워크 연결을 통해 상기 서버와 별도로 연결되는 방식으로 구현될 수 있다. 상기 단말 및 상기 서버 각각은 다른 단말들과의 통신 기능을 수행하기 위한 통신부(미도시), 다양한 정보 및 프로그램(또는 애플리케이션)을 저장하기 위한 저장부(미도시), 다양한 정보 및 프로그램 실행 결과를 표시하기 위한 표시부(미도시), 상기 다양한 정보 및 프로그램 실행 결과에 대응하는 음성 정보를 출력하기 위 한 음성 출력부(미도시), 각 단말의 다양한 구성 요소 및 기능을 제어하기 위한 제어부(미도시) 등을 포함할 수 있다. 상기 단말은 상기 서버 등과 통신한다. 이때, 상기 단말은 해당 서버에서 제공하는 전용 앱을 통해 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영상 활용 기능 등을 수행하기 위한 사용자(또는 특정 분야의 전문가)가 소지한 단말일 수 있다. 또한, 상기 단말은 상기 서버와의 연동에 의해, 상기 서버에서 제공하는 전용 앱 및/또는 웹 사 이트를 통해 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등을 제공받기 위한 사용자로 회원 가입하며, 개인 정보 등을 상기 서버에 등록한다. 이때, 상기 개인 정보는 아이디, 이메일 주소, 패스워드(또는 비밀번호), 이름, 성별, 생년월일, 연락처, 주소지(또는 주소정보) 등을 포함한다. 또한, 상기 단말은 해당 단말의 사용자가 가입한 SNS 계정 정보 또는 타사이트 계정 정보 또는 모바 일 메신저 계정 정보를 이용하여 상기 서버에 사용자로 회원 가입할 수도 있다. 여기서, 상기 SNS 계정은 페이스북, 트위터, 인스타그램, 카카오 스토리, 네이버 블로그 등과 관련한 정보일 수 있다. 또한, 상기 타사이 트 계정은 유튜브, 카카오, 네이버 등과 관련한 정보일 수 있다. 또한, 상기 모바일 메신저 계정은 카카오톡 (KakaoTalk), 라인(line), 바이버(viber), 위챗(wechat), 와츠앱(whatsapp), 텔레그램(Telegram), 스냅챗 (snapchat) 등과 관련한 정보일 수 있다. 또한, 회원 가입 절차 수행 시, 상기 단말은 본인 인증 수단(예를 들어 이동 전화, 신용카드, 아이핀 등 포함)을 통한 인증 기능을 완료해야 상기 서버에 대한 회원 가입 절차를 정상적으로 완료할 수 있다. 또한, 회원 가입이 완료된 후, 상기 단말은 상기 서버에서 제공하는 서비스를 이용하기 위해서, 상기 서버로부터 제공되는 전용 앱(또는 애플리케이션/응용 프로그램/특정 앱)을 해당 단말에 설치한다. 이때, 상기 전용 앱은 네이티브 앱(Native App), 모바일 웹앱(Mobile WebApp), 반응형 웹앱(Mobile WebApp Design: RWD), 적응형 웹앱(Adaptive Web Design: AWD), 하이브리드 앱(Hybrid App) 등을 포함하며, 로우 데이 터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영상 활용 기능 등을 수 행하기 위한 앱일 수 있다. 또한, 회원 가입이 완료된 후, 상기 단말은 상기 서버에서 제공되는 할인 쿠폰을 해당 전용 앱을 통 해 표시할 수 있다. 이때, 상기 할인 쿠폰은 해당 서버에서 제공하는 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영상 활용 기능 등을 이용시 일정 비율의 할인 정 보를 포함하는 할인 쿠폰일 수 있다. 또한, 상기 단말은 상기 서버에서 제공하는 기능들을 수행하기 위해서, 상기 서버 및 결제 서버 (미도시)와 연동하여, 구독 기능에 따라 결제 기능을 수행한다. 이때, 상기 서버는 카드 결제, 은행의 결 제 계좌 연동을 통한 자동 이체, 상기 서버에 회원 가입한 상기 단말의 계정에 남아 있는 현금성 포 인트나 현금을 이용한 결제, 카카오페이, 네이버페이 등을 포함하는 간편결제 등을 통해 결제 기능을 수행할 수 있다. 결제가 실패한 경우, 상기 단말은 상기 서버(또는 상기 결제 서버)로부터 전송되는 결제가 실패한 상 태임을 나타내는 정보(예를 들어 잔액 부족, 한도 초과 등 포함)를 수신하고, 상기 수신된 결제가 실패한 상태 임을 나타내는 정보를 출력(또는 표시)한다. 또한, 상기 단말은 결제 기능이 정상적으로 수행된 후, 상기 서버로부터 전송되는 결제 기능 수행 결 과를 수신한다. 여기서, 상기 결제 기능 수행 결과는 구독 기간, 결제 금액, 결제 일자 및 시각 정보 등을 포함 한다. 또한, 상기 단말은 네트워크를 통해 웹사이트에 접속하며, 상기 서버로부터 생성 알고리즘을 이 용한 가상 아바타 및 아이템의 생성 및/또는 출력 플랫폼을 제공받을 수 있다. 상기 단말은 브라우저를 실 행하는 과정에서 상기 서버로부터 제공되는 생성 알고리즘을 이용한 가상 아바타의 생성 플랫폼을 제 공받을 수 있다. 상기 단말은 상기 서버가 제공하는 각종 서비스 및 플랫폼에 관한 애플리케이션을 다운로드, 설치 및 실행함으로써, 애플리케이션을 통해 상기 서버가 제공하는 각종 서비스를 제공받을 수 있다. 이를 위해 단 말은 스마트폰과 같이 애플리케이션의 구동이 가능한 운영체제를 탑재한다. 그러나 이에 한정되지 않고, 단말은 애플리케이션의 구동이 가능한 다른 범용적인 장치들이 적용된다. 본 발명의 일 실시예에서, 단말은 애플리케이션 외에 웹 기반으로도 서비스를 제공하며, 단말이 서비 스를 제공하는 방법은 특정한 형식으로 제한되지 않는다. 또한, 상기 단말은 하나 이상의 시각 세트 장치(미도시)와 연동하여, 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련 한 메타 정보, 사용자 정보 등을 수집한다. 여기서, 상기 시각 세트 장치는 카메라부, 라이다, 아이트래커, 모 션 캡처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의료용 초음파 등) 등을 포함한다. 또한, 상기 로우 데이터(raw data)(또는 기초영상/원본 데이터/소스 데이터/시각 데이터/실제 현실의 영상)는 실제 현실에 서 획득되는(또는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정 값 등을 포함한다. 여기서, 상기 측정값은 상기 라이다, 상기 아이트래커, 상기 모션 캡처 및 모션트래커, 상기 의료장비 등을 통해 측정되는 영상 정보(또는 3차원 데이터) 등을 포함한다. 또한, 상기 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유형에 따른 항목별 점수/MBTI 선호도 점수 등 포함) 등을 포함한다. 이때, 상기 단말은 해당 단말에 미리 설치된 전용 앱을 실행하고, 전용 앱 실행에 따른 앱 실행 결과 화면을 표시한다. 여기서, 상기 앱 실행 결과 화면은 해당 단말의 사용자와 관련한 하나 이상의 로우 데이 터, 해당 로우 데이터와 관련한 메타 정보 등을 수집하기 위한 수집 메뉴(또는 버튼/항목), 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하기 위한 레벨 선택 메뉴, 수집된 정보 나 서버로부터 제공되는 정보를 표시하기 위한 보기 메뉴, 해당 로우 데이터와 관련해서 생성된 라스트 레 벨 영상에 대한 레벨업 기능 수행을 위한 상점 메뉴, 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게 임 대기실 메뉴, 환경 설정을 위한 설정 메뉴 등을 포함한다. 이때, 상기 단말은 해당 전용 앱을 제공하는상기 서버에 회원 가입한 상태로, 회원 가입에 따른 아이디 및 비밀번호, 상기 아이디를 포함하는 바코드 또는 QR 코드 등을 이용해서 상기 전용 앱 실행 시 로그인 절차를 수행하여, 해당 전용 앱의 하나 이상의 기능 (예를 들어 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등 포함)을 수행할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 수집 메뉴가 선택되는 경우, 상기 단말 은 사용자 설정에 따른 하나 이상의 시각 세트 장치로부터 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보 등을 수집하기 위해서, 상기 선택된 수집 메뉴에 대응하는 수집 화면을 표시한다. 여기서, 상기 수집 화면은 사용자 선택(또는 사용자 입력/터치/제어)에 따라 해당 단말과 연동하는 하나 이상의 시 각 세트 장치를 선택하기 위한 정보 수집 대상 선택 항목, 선택된 정보 수집 대상으로부터 수집할 정보의 종류 를 선택하기 위한 수집 정보 종류 선택 항목, 선택된 항목에 따라 해당 정보 수집 대상으로부터 정보를 수집하 기 위한 수집 시작 항목 등을 포함한다. 또한, 상기 단말은 해당 단말에 표시되는 수집 화면에서 해당 단말의 사용자 입력(또는 사용자/ 전문가 선택/터치/제어)에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 여기서, 상기 복수의 입력값은 정보 수집 대상(또는 시각 세트 장치 정보/시각 세트 장치의 식별 정보), 수집할 정보의 종류(예를 들 어 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값/센서값 등 포함) 등을 포함한다. 또한, 상기 단말은 상기 수신된 복수의 입력값을 근거로 상기 하나 이상의 시각 세트 장치와 연동하여, 해 당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보 등을 수집한다. 이때, 상기 단말은 해당 단 말의 사용자와 관련해서 1명의 사용자로부터 1개의 로우 데이터를 수집할 수도 있고, 1명의 사용자로부터 서로 다른 복수의 로우 데이터(또는 어노테이션 단계(annotation 단계) 또는 어트리뷰트(attribute) 항목의 로 우 데이터/기초 영상정보)를 수집할 수도 있다. 여기서, 상기 비교 대상 영상은 저작권, 초상권 등의 지식 재산 권에 저촉되지 않는 콘텐츠일 수 있다. 상기 시각 세트 장치는 상기 단말, 상기 서버 등과 통신한다. 또한, 상기 시각 세트 장치는 카메라부, 라이다, 아이트래커, 모션 캡처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의료용 초음파 등) 등을 포함한다. 또한, 상기 시각 세트 장치는 해당 시각 세트 장치가 구성된(또는 배치된/설치된) 장소(또는 영역)와 관련한 실 제 현실의 영상(또는 실제 현실의 영상정보)을 획득(또는 수집/촬영/측정)한다. 여기서, 상기 실제 현실의 영상 은 로우 데이터(raw data)(또는 원본 데이터/소스 데이터/시각 데이터)를 나타내며, 실제 현실에서 획득되는(또 는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상/속성), 동영상(또는 타깃 속 성), 측정값 등을 포함한다. 또한, 상기 측정값은 상기 라이다, 상기 아이트래커, 상기 모션 캡처 및 모션트래 커, 상기 의료장비 등을 통해 측정되는 영상 정보(또는 3차원 데이터) 등을 포함한다. 또한, 상기 획득된 하나 이상의 실제 현실의 영상은 합병(merge)하여 사용할 수 있다. 본 발명의 일 실시예에서, 도 2 내지 도 4에 도시된 바와 같이, 사용자의 기초 영상정보(또는 로우 데이 터)는 인플루언서의 기초 영상정보(또는 비교 대상 영상)와 딥페이크된다. 시각세트장치가 연결된 단말을 통하여 상기 서버는 실제 현실의 데이터인 제1 기초 영상정보 를 획득한다. 제1 영상정보인 메타버스의 가상의 아바타 및 아이템을 생성하거나 출력하기 위해 실제 현실의 영상정보를 수집하는 영상 정보 수집장치를 '시각세트장치'로 정의한다. 시각세트장치는 기초 영상정보를 실시예와 같은 방식으로 획득한다. 실제 사용자의 MBTI 선호도 정보가 시각세트장치를 통 해 기초 영상정보에 매핑된 상태로 전송된다. 본 발명의 일 실시예에서, 사용자는 단말에 설치된 MBTI 선호도 검사 애플리케이션을 통해 자신의 MBTI 선 호도 정보를 획득하고, 획득된 MBTI 선호도 정보를 영상정보의 메타정보로 매핑하여 영상정보와 함께 서버(20 0)에 전송한다. '제1 기초 영상정보, 제2 기초 영상정보, 제 3 기초 영상정보…'는 기초 영상정보고, 1명의 사 용자로부터 획득한 어트리뷰트(attribute) 항목(또는 어노테이션 단계)의 복수의 입력 데이터이다. 한 명의 사 용자가 단일 아바타에 대해 동일한 동작을 반복적으로 시행하여 복수의 입력데이터를 획득한다.또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대 상 영상, 해당 비교 대상 영상과 관련한 메타 정보 등을 표시(또는 출력)한다. 이때, 상기 단말은 해당 로 우 데이터 등에 가상현실, 증강현실, 확장현실, 혼합현실 등을 적용하여 표시(또는 출력)할 수도 있다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 보기 메뉴가 선택되는 경우, 상기 단말 은 수집된 정보나 상기 서버로부터 제공되는 정보를 표시하기 위해서, 상기 선택된 보기 메뉴에 대응 하는 보기 화면을 표시한다. 여기서, 상기 보기 화면은 상기 로우 데이터나 생성된 영상을 표시하기 위한 영상 표시 영역, 상기 비교 대상 영상을 표시하기 위한 비교 대상 영상 표시 영역, 동영상에 대한 재생/일시정지/멈 춤 기능 등을 제공하기 위한 재생바 등을 포함한다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면 내의 보기 화면에 포함된 재생바가 선택되는 경우 또는 해 당 보기 화면 내의 재생 버튼이 선택되는 경우, 상기 단말은 상기 수집된 로우 데이터를 상기 영상 표시 영역에 표시(또는 출력)하고, 상기 수집된 로우 데이터에 대응하는 비교 대상 영상(또는 상기 서버로부터 제공받은 해당 로우 데이터에 대응하는 비교 대상 영상)을 상기 비교 대상 영상 표시 영역에 표시(또는 출력)한 다. 이때, 상기 단말은 상기 로우 데이터 및 상기 비교 대상 영상에 각각 대응하는 메타 정보를 근거로 해 당 로우 데이터 및 상기 비교 대상 영상에 대해 동기화를 수행하여, 동기화된 로우 데이터 및 비교 대상 영상을 상기 영상 표시 영역 및 상기 비교 대상 영상 표시 영역에 각각 표시할 수 있다. 여기서, 상기 단말 내의 상기 영상 표시 영역에 표시되는 로우 데이터 및 상기 비교 대상 영상 표시 영역에 표시되는 비교 대상 영상 중 에서 어느 하나가 일시정지 기능 또는 멈춤 기능에 의해 멈추는 경우, 상기 단말은 다른 하나도 함께 일시 정지 기능 또는 멈춤 기능에 의해 멈추도록 제어한다. 또한, 상기 단말은 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하는 레벨 선택 라벨링(또는 레벨 선택 라벨링 기능)을 수행한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 레벨 선택 메뉴가 선택되는 경우, 상기 단 말은 앞서 수집된 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택 (또는 설정)하기 위해서, 상기 선택된 레벨 선택 메뉴에 대응하는 레벨 선택 화면을 표시한다. 여기서, 상기 레 벨 선택 화면은 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 각각 선 택하기 위한 아바타 레벨 입력 항목, 아이템 레벨 입력 항목, 완료 항목 등을 포함한다. 이때, 상기 레벨 선택 메뉴는 상기 수집 화면을 통해서 하나 이상의 로우 데이터, 비교 대상 영상 등이 수집된 경우에 한해서 활성화 되어 표시되며, 디폴트로는 비활성화된 상태를 유지하도록 구성하며, 각 아바타별/아이템별로 서로 다른 최소 레벨 ~ 최대 레벨이 각각 분류된 상태일 수 있다. 또한, 상기 단말은 해당 단말에 표시되는 레벨 선택 화면에서 해당 단말의 사용자 입력(또는 사 용자/전문가 선택/터치/제어)에 따라 복수의 다른 입력 항목에 대응하는 복수의 다른 입력값을 수신한다. 여기 서, 상기 복수의 다른 입력값(또는 레벨 선택 라벨링에 대한 정보)은 해당 로우 데이터와 비교 대상 영상을 근 거로 생성될 아바타의 레벨 정보, 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아이템의 레벨 정보 등 을 포함한다. 이와 같이, 상기 단말은 상기 수집된 로우 데이터, 비교 대상 영상 등에 대해서, 해당 단말의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또 는 아이템의 레벨을 각각 설정(또는 수신/입력)한다. 이때, 상기 레벨 선택 라벨링 과정이 생략되는 경우 또는 상기 단말에서 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템에 대해 레벨을 설정하지 않는 경우 또는 미리 설정된 레벨 선택 라벨링 과정 시간이 지난 경우, 상기 단말은 미리 설정된 디폴트값(예를 들어 아바타별/아이템별 최소 레벨)으로 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아 바타 및/또는 아이템의 레벨을 각각 설정한다. 또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메 타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상기 수신된 레벨 선택 라벨 링에 대한 정보, 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보, 단말의 식별 정보 등을 상기 서버에 전송한다. 여기서, 상기 단말의 식별 정보는 MDN(Mobile Directory Number), 모바일 IP, 모바일 MAC, Sim(subscriber identity module: 가입자 식별 모듈) 카드 고유정보, 시리얼번호 등을 포함한다. 개시된 실시 예에 따른 메타버스 플랫폼은 메타버스 환경으로 구현된 메타버스 국가 플랫폼을 제공한다. 모든 아바타는 국가기관에서 일하거나 국가기관(예를 들어 입법부, 사법부, 행정부 등 포함)과 계층적으로 연결된 회 사에서 일을 한다. 메타버스 국가는 실제 현실의 국가 체계와 유사한 디지털 트윈 형태이고, 국가기관 및 산하기관, 회사, 상점 등 은 현실과 유사한 계층적 군집이다. 정부 조직도, 국회 조직도, 법원 조직도와 같은 방식으로 메타버스의 국가 를 계층적 군집화하고, 조직의 각 파트와 계층적으로 연결된 상점과 회사는 계층적 군집화 라벨값을 ID(신분증 및 코드)로 부여받는다. 위 계층적 군집화 라벨을 아바타와 아이템에 ID(신분증 및 코드)를 부여할 때 사용하는 '메타버스 국가 라벨분류'로 정의한다. 메타버스 국가 라벨분류를 참조하여, 사용자는 아바타 및 아이템을 선택하고 ID 입력창에 ID(신분증 및 코드)형 태의 라벨값을 입력한다. 본 발명의 일 실시예에서, 회사와 상점은 국가기관과 산하기관의 ID와 연결된 NFT 형태의 주소 ID를 발급받는다. 본 발명의 일 실시예에서, 손흥민 아바타를 예로 들자면, 국가기관은 문화체육관광부이고, 회사는 전남 드래곤 즈와 같은 축구구단이고, 축구용품 판매점 알파(가칭) 상점이다. 문화체육관광부의 라벨은 12, 전남드래곤즈의 라벨은 12-12345, 손흥민 아바타의 라벨은 12-12345-S999111이다. 전남드래곤즈 전용 축구장의 입구에 위치한 축구용품 판매점 알파(가칭)의 라벨은 12-12345- 67890이다. 이는 메타버스 국가 라벨분류의 라벨값들이다. 사 용자는 손흥민 아바타를 선택하고 ID 입력창에 손흥민 아바타의 라벨인 '12-12345-S999111'를 라벨값으로 입력 하고 '12-12345-S99111-USER13579'를 사용자 ID로 서버로부터 부여받는다. 아바타 및 아이템의 레벨을 선택하는 방식의 하이브리드된 지도학습과 비지도학습의 집단지성화를 이용하여 다 양한 영상을 생성하거나 고도화하는 생성적 신경망 알고리즘을 '생성 알고리즘'으로 정의한다. 본 발명의 일 실시예로, 생성적 신경망 알고리즘으로 GAN(Generative Adversarial Networks)을 사용한다. 사용자에 의해 메타버스 상에서 사용되고 있는 특정시점에서의 아바타 및 아이템의 영상정보와 그 시점에서 수 집된 제1 기초 영상정보가 단일모델로 학습되어 생성된 가상의 아바타 및 아이템을 라스트 레벨(Last Level) 영상정보로 정의한다. Last Level 영상정보에 MBTI 메타정보가 매핑된다. Last Level 영상정 보는 정지영상 및 시계열적 이동영상, 그리고 다양한 메타정보값(예를 들어 계층적군집, 성별, 나이, MBTI 정보 등 포함)을 입력으로 사용하였을 때 추론되어 나오는 모델의 최종 출력 결과값이다. 본 발명의 일 실시예로, 사용자가 메타버스 게임을 처음 시작한다면 사용자와 인플루언서의 제1 기초 영상 정보에 의해서 가상의 아바타와 아이템이 생성된다. 본 발명의 일 실시예에서, 시각세트장치는 셀프 포토 스튜디오의 사진기, 휴대전화기, 라이다, 아이트래커, 모션 캡처 및 모션트래커 등을 포함한다. 수집된 영상정보는 합병하여 사용될 수 있다. 메타버스 국가의 모든 게임에서 아바타의 얼굴 표정 및 동작의 트레이닝에는 아바타의 레벨별로 필요한 MBTI 점 수(또는 MBTI 선호도 점수)가 있다. 아이템의 획득에도 동일하게 필요한 MBTI 점수가 있다. 레벨별로 필요한 MBTI 점수를 사용자가 지급하면, 사용자는 상점에서 자신의 아바타와 아이템의 레벨을 상승시킬 수 있다. 생성 알고리즘(또는 하이브리드 생성 알고리즘/생성 모델)의 중간 과정에서의 미흡함을 집단지성과 계급화된 게 임성을 동원하여, 비지도 학습과 집단지성 지도학습이 결합된 하이브리드 생성 알고리즘 학습 메커니즘 방 식으로 학습이 덜 된 중간 단계의 결과물을 훈련 에포크(Training Epoch)의 수에 따라 회원 등급(레벨)에 따라 차등 제공한다. 본 발명의 일 실시예에서, 사용자는 자신의 메타데이터(예를 들어 영상정보, MBTI 선호도 정보 등 포함)를 서버 에 전송하는 방법 혹은 MBTI 점수를 구입하는 방법 혹은 게임 도중에 획득하는 방법으로 MBTI 점수를 지급 한다. 본 발명의 일 실시예에서, MBTI의 각 라벨은 음양오행 이론의 목, 화, 토, 금, 수, 음, 양의 라벨로 대체 가능 하다. MBTI 점수체계와 동일한 방식의 상생, 상극의 원리를 적용한다. 본 발명의 일 실시예에서, 트레이닝율을 높이는 방법(레벨을 높이는 방법)은 높은 결제금을 지급하는 방법 혹은 지신의 실제 MBTI와 잘 매칭된 아바타를 선정하는 방법 혹은 라벨링(일)을 많이 하여 MBTI 점수를 충분히 획득 하는 방법 혹은 경쟁게임에서 승리하여 획득하는 방법 등이 있다. 본 발명의 일 실시예에서, 사용자가 요금부과 한 결제금에 따라 아바타의 MBTI 점수가 충전되고, 충전된 MBTI 점수와 사용자의 메타데이터(MBTI의 분석내용 및 점수)가 일정한 계산방식으로 합산되어 생성 및/또는 출력된 아바타의 MBTI 점수가 최종 결정된다. 사용자는 직업과 취미에 따라서 자신에게 맞는 MBTI 선호도를 검사하여 잘 매칭되는 아바타와 아이템을 선택하고, 아바타와 아이템의 트레이닝율을 높일 수 있다. 메타버스 상의 직업 (MBTI 선호도)이 사용자 자신의 메타데이터에 입각한 정보(MBTI 선호도)와 유사할 때 아바타의 트레이닝율이 높 아지고 MBTI 선호도 점수도 높아진다. 메타데이터(사용자의 얼굴과 동작에 대한 사진 및 동영상정보)를 기준으 로 아바타 및 아이템과 사용자의 매칭 수준을 정한다. 매칭 수준이 높을수록 아바타의 트레이닝 레벨을 쉽게 높 일 수 있다. 본 발명의 일 실시예에서, MBTI의 분석에 의해 사용자 갑순이는 모험을 즐기는 사업가이기에 여행이나 캠핑 관 련 아바타와 아이템에 매칭 수준이 높다. 갑순이에게는 화장품은 30% 수준만 매칭이 되며 오히려 여행이나 캠핑 관련 메타버스 콘텐츠는 100% 매칭이 된다. 즉 갑순이는 화장을 즐겨 하는 사용자가 아니므로 매칭률이 낮다. 화장품이라는 아이템의 각 사용자와의 매칭률(30% 혹은 100%)을 정하는 것은 메타버스 상의 국가 기관과 산하기 관 회사 상점에서 일하고 있는 사용자들의 단말의 앱 실행 결과 화면을 통한 집단지성 및 행동 및 반응 기 반으로 자동 산출될 수 있다. 본 발명의 일 실시예에서, 손흥민 아바타의 드리블 동작을 레벨 1로 트레이닝하려면 감각 선호도 점수가 90점 사고 선호도 점수가 80점을 확보하여야 하고, 레벨 2로 트레이닝 하려면 감각선호도 점수 180점, 사고 선호도 점수 160점을 확보하여야 한다. 레벨 5로 트레이닝 하려면 감각선호도 점수 450점, 사고 선호도 점수 400점을 확보하여야 한다. 이에 필요한 MBTI 선호도 점수는 요금부과를 통해서 확보할 수 있고, 아이템을 거래하는 회사 나 상점 등에서도 라벨링의 보상으로 획득한 점수로도 가능하다. 고급 아이템과 아바타의 높은 레벨의 트레이닝 에는 많은 MBTI 점수가 필요하다. 다양한 아바타의 고도화에는 다양한 MBTI 점수가 필요하다. 본 발명의 일 실시예에서, 메타버스 상의 국가기관과 산하기관, 회사와 상점은 현실의 국가기관과 산하기관, 회 사와 상점의 영상정보로 트레이닝시켜 얻은 현실과 유사하나 새로운 생성물이다. GAN으로 충분히 트레이닝 되어 고도화된 아바타와 건물 영상은 실제 사람 및 건물과 유사하나 고도화가 덜 된 것(트레이닝 레벨이 낮은 것)은 다소 익숙하지 않은 기괴한 형태를 가질 수도 있다. 또한, 상기 단말은 상기 서버로부터 전송되는 라스트 레벨 영상을 수신한다. 여기서, 라스트 레벨 (last level) 영상은 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 비 교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상기 레벨 선택 라벨링에 대한 정보 등 에 대한 인공지능을 통한 학습을 통해 생성된 정보일 수 있다. 또한, 상기 단말은 상기 수신된 라스트 레벨 영상을 출력(또는 표시)한다. 이때, 상기 단말은 상기 로우 데이터, 상기 비교 대상 영상 및 상기 라스트 레벨 영상을 화면 분할하여 출력(또는 표시)할 수도 있다. 또한, 상기 단말은 상기 서버 및 상기 결제 서버와 연동하여, 해당 서버에서 제공하는 메타버스 내의 상점에서 포인트(또는 MBTI 점수) 구매를 통해 해당 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강화 기능을 수행한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 상점 메뉴가 선택되는 경우, 상기 단말 은 상기 생성된 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강화를 위해서, 상기 선택 된 상점 메뉴에 대응하는 상점 화면을 표시한다. 여기서, 상기 상점 화면은 해당 단말의 사용자와 관련해 서 생성된 하나 이상의 아바타에 대한 정보(또는 목록)를 제공하기 위한 보유 아바타 리스트 항목, 해당 아바타 와 관련한 하나 이상의 아이템에 대한 정보(또는 목록)를 제공하기 위한 보유 아이템 리스트 항목, 아바타나 아 이템에 대한 레벨을 강화하기 위한 레벨 강화 항목 등을 포함한다. 또한, 상기 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에 포함된 하나 이상의 아바타 중에 서 특정 아바타가 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 단 말은 상기 서버 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련해서 상기 선택된 레 벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아바타의 레벨을 기준으 로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계 별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된 9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 해당 특정 아바타에 대해서 레벨 업 전/후의 레 벨 상태를 화면의 일측에 표시한다. 또한, 상기 단말은 상기 서버에 의해 강화된 해당 특정 아바타에 대해서 레벨 업 전/후의 레벨 상태 를 화면의 일측에 표시한다. 또한, 상기 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에 포함된 하나 이상의 아바타 중에 서 특정 아바타가 선택되는 경우, 상기 단말은 상기 선택된 특정 아바타와 관련한 하나 이상의 아이템을 상기 보유 아이템 리스트 항목에 표시한다. 또한, 상기 단말에 표시되는 보유 아이템 리스트 항목에 포함된 하나 이상의 아이템 중에서 특정 아이템이 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 단말은 상기 서 버 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련한 특정 아이템과 관련해서 상기 선택 된 레벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말 의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아이템의 레벨 을 기준으로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된 9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 해당 특정 아바타와 관련한 특정 아이템에 대해 서 레벨 업 전/후의 레벨 상태를 화면의 일측에 표시한다. 또한, 상기 단말은 상기 서버에 의해 강화된 해당 특정 아바타와 관련한 특정 아이템에 대해서 레벨 업 전/후의 레벨 상태를 화면의 일측에 표시한다. 이와 같이, 상기 단말은 앞서 단말에서 설정한 레벨 선택 라벨링에 대한 정보 등을 적용하여 생성되 는 라스트 레벨 영상에 대해서, 추가 MBTI 점수 결제에 따라, 해당 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨을 강화(또는 업그레이드/업데이트)할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 게임 대기실 메뉴가 선택되는 경우, 상기 단말은 게임 참여를 위해 개설된 게임방 목록을 제공하거나 새로운 게임방을 개설하기 위해서, 상기 선택 된 게임 대기실 메뉴에 대응하는 게임 대기실 화면을 표시한다. 여기서, 상기 게임 대기실화면은 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게임방 리스트 항목, 새로운 게임방을 개설하기 위한 게임방 생성 항 목 등을 포함한다. 이때, 새로운 게임방을 생성하고자 하는 경우, 상기 단말은 상기 서버 및 상기 결 제 서버와 연동하여, 미리 설정된 MBTI 점수에 해당하는 결제 금액에 대해서 결제 기능을 수행할 수도 있다. 또한, 상기 단말에 표시되는 게임 대기실화면 내의 게임방 리스트 항목에 포함된 하나 이상의 게임 대기방 중에서 어느 하나의 게임 대기방이 선택되는 경우, 상기 단말은 상기 서버와 연동하여, 상기 선택된 게임 대기방에 대응하는 게임룸에 입장(또는 참여)한다. 또한, 상기 단말에서 참여한 게임룸을 개설한 방장에 의해 미리 설정된 게임 시작 메뉴가 선택되는 경우 (또는 해당 게임룸과 관련해서 미리 설정된 게임 시작 조건을 만족하는 경우), 상기 단말은 상기 서버 , 해당 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 해당 게임을 관전 중이거나 미리 설정된 게임상의 국가기관/회사/상점에 소속된 사용자가 소지한 다른 복수의 단말, 해당 게임과 유사한 게 임에 참여했던 다른 사용자가 소지한 또 다른 복수의 단말 등과 연동하여, 해당 게임(또는 해당 게임룸)과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 게임 시작 조건은 미리 설정된 게임 참가자 수를 만족하는 경우, 미리 설정된 게임 시작 시각을 만족하는 경우 등을 포함한다. 이때, 상기 서버는 미리 설 정된 조건(예를 들어 게임 시작 후 미리 설정된 시간(일 예로 5분, 10분 등 포함)이 지난 경우, 미리 설정된 참 여자(일 예로 10명) 이상이 MBTI 점수 체계 제정에 참여한 경우 등 포함)을 만족할 때까지 해당 게임과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 조건을 충족할 때까지 상기 게임과 관련한 MBTI 점수 체 계가 제정되지 않은 경우, 상기 서버는 해당 게임과 관련해서 미리 설정된 디폴트값으로 해당 MBTI 점수 체계를 제정(또는 설정)할 수도 있다. 메타버스 헌법 또는 법률 또는 규칙 등은 메타버스 국가의 경쟁게임을 진행하고 승패를 결정짓게 하기 위한 MBTI 점수 체계이다. 메타버스 헌법 또는 법률 또는 규칙 등은 메타버스 국가기관에서 정한다. 메타버스 국가기 관의 군집은 상부계층에서 하부계층으로 가면서 계층적으로 세분화되고, 상부계층은 헌법 및 법률을 정하고, 하 부계층은 규칙을 정한다. 메타버스 국가의 헌법 또는 법률 또는 규칙 등을 정하는 방식은 실제 현실과 유사한디지털 트윈 형태이고 메타버스 의제선정과 메타버스 선거로 정한다. MBTI 점수 체계는 아바타의 성격 유형에 따른 상극과 상생의 법칙으로 승부를 결정짓는 임의의 방식이다. 메타버스 헌법 또는 법률 또는 규칙 등에 대해 각 국가기관과 회사와 상점에 소속된 사용자 아바타들이 선택하 고 결정할 의제는 사용자들의 가상 메타버스 휴대전화기 SNS 내에 대한 서버의 분석에 의해 얻어진다. 서 버는 국가기관 혹은 회사 혹은 상점의 사용자(아바타)의 메타버스 휴대전화기 SNS에 대한 로그 시스템 및 실시간 분석(람다아키텍처) 등을 통해 의제를 선정하여 해당 국가기관 혹은 회사 및 상점에 소속된 사용자(아바 타)에게 해당 단말에서의 앱 실행 결과 화면을 통해 추천한다. 이를 '메타버스 의제선정'이라고 정의한다. 사용자는 메타버스 의제선정에 대해 해당 단말에서의 앱 실행 결과 화면에서의 플러스 버튼 혹은 마이너스 버튼을 눌러 선택한다. 플러스 버튼은 찬성이고, 마이너스 버튼은 거부이다. 회사가 일을 하는 방식에 대한 규 칙과 상점에서의 아이템 교환과 판매에서의 규칙 등도 동일한 방식으로 버튼을 눌러 선택하여 집단지성화한다. 이를 '메타버스 선거'라고 정의한다. 메타버스 국가기관, 회사, 상점 등에는 해당 단말에서의 앱 실행 결과 화면(또는 전용 앱)이 설치돼 있다. 회사는 사용자가 일을 하고 MBTI 점수를 획득하는 곳이고, 국가기관에서 일하는 공무원 아바타에게 헌법 또는 법률 또는 규칙 등을 정하는 것은 일종의 일이다. '일'은 해당 단말에서의 앱 실행 결과 화면을 통해 자신 및 타인의 아바타 및 아이템에 대해 라벨링을 하는 것이다. 본 발명의 일 실시예에서, MBTI 선호도 점수 체계는 다음과 같다. 레벨 2로 트레이닝된 공격수 손흥민 아바타(E 점수 180, S 점수 30, T 점수 160, P 점수 70)를 레벨 2의 수비수 이동호 아바타(I 점수 170 점, S 점수 30, T 점수 160, J 점수 80)가 방어하면, 상극인 E 점수와 I 점수, 그리고 P 점수와 J 점수를 비교하여 상극의 점수가 높은 쪽이 경쟁에서 유리하다. 또한, 공격수 손흥민 (E 점수 180, S 점수 30, T 점수 160, P 점수 70)와 공격수 이강인 아바타(E 점수 140, S 점수 50, T 점수 130, J 점수 50)가 콤비플레이를 진행할 경우, 상생의 점수인 E 점수, S 점수, T 점수를 비교하여 상생의 점수의 유사도가 높을수록 콤비 플레이의 성공률이 높아진다. 상극과 상생의 점수비교는 메타버스 헌법 및 법률에 해당되는 것이고 '상극의 점수가 높은 쪽이 경쟁에서 유리한 것' 또는 '상생의 점수의 유사도가 높을수록 콤비 플레이의 성공률이 높아지는 것' 등에 대한 구체적인 수치화 및 전산화는 규칙에 해당된다. 본 발명의 일 실시예에서, 슈팅 게임이나 서바이벌 게임에서 타격을 가하고 타격을 당할 때의 승부를 결정하는 방식은 디지털트윈 방식이다. 메타버스 국가의 국방부 혹은 이하 산하기관 등에서 위 승부 결정방식에 관련된 MBTI 점수체계에 대해 입안하고 메타버스 국회에서 제정한다. 그리고 하위 규칙 등은 지방자치단체의 의회에서 결정한다. 메타버스 국회, 메타버스 국가의 국방부, 지방자치단체 등의 사용자(아바타)는 메타버스 의제선정 및 메타버스 선거를 통해 자신의 일을 한다. 입안의 단계, 제정의 단계, 공포의 단계 모두 디지털트윈 방식으로 메 타버스 의제선정과 메타버스 선거를 통해 이루어진다. 또한, 상기 단말은 상기 서버와 연동하여, 해당 단말의 사용자와 관련한 아바타 및/또는 아이템 과, 해당 게임에 참여한 다른 게임 참가자와 관련한 아바타 및/또는 아이템을 참조하여, 게임 참가자별 MBTI 선 택라벨링(또는 복수의 단말의 게임 참가자/사용자와 관련한 아바타 및/또는 아이템별 MBTI 선택라벨링) 기 능을 수행한다. 여기서, 상기 MBTI 선택라벨링(또는 MBTI 선택레이블링)은 해당 게임에 참여한 모든 사용자와 관련한 아바타 또는 아이템에 대해서 해당 단말의 사용자가 생각하는 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 설정하는(또는 붙이는) 라벨링 방법을 나타낸다. 이때, 상기 MBTI 유형에 따른 항목별 점수(또는 MBTI 선호도 점수)는 미리 설정된 범위(예를 들어 0점 ~ 100점) 중에서 선택될 수 있다. 이와 같이, 상기 단말은 해당 게임에 참여한 복수의 게임 참가자가 각각 소지한 아바타 및 아이템과 관련 해서, 각각의 게임 참가자별 MBTI 선택라벨링(또는 사용자별 MBTI 선택라벨링) 기능을 수행하여, 게임 참가자별 아바타 및 아이템에 대한 MBTI 유형과 항목별 점수를 각각 설정(또는 수신/입력)할 수 있다. 단말에서의 앱 실행 결과 화면을 참조하면, 사용자는 선택라벨링과 동일한 방법으로 아바타와 아이템 을 선택하여 MBTI 선택라벨링을 수행한다. 영상정보에서 마우스의 화살표 및 기타입력장치 및 시간축 및 시각을 나타내는 표를 이용한 드래그와 태그를 통해 아바타와 아이템에 대해 객체인식을 한다. 제1 버튼 내지 제8 버튼과 플러스버튼과 마이너스버튼을 이용하여 인식된 아바타와 아이템에 대해 총 8가지의 MBTI 라벨값을 붙인다. 총 8가지의 MBTI 라벨정보와 각 라벨의 입력점수는 메타정보로 영상정보에 매핑된다. MBTI 라벨값을 붙이는 경우에 실제 현실의 체계화된 MBTI 분류를 적용하고 이를 메타버스 국가 플랫폼의 'MBTI 라벨분류'로 사용한다. 또한, MBTI 라벨값에 대한 점수입력은 'MBTI 라벨분류'를 참조하여 사용자가 임으로 입 력한다. 제1생성 알고리즘의 예측값인 제1 계층적 군집의 아바타 및/또는 아이템은 제1 MBTI 선택라벨링에 의해 1 차 라벨링되고 제2 생성 알고리즘의 예측값인 제1 계층적 군집의 아바타 및/또는 아이템은 제2 MBTI 선택 라벨링에 의해 2차 라벨링되고, 이 과정은 계속하여 반복된다. 동영상정보의 출력 및/또는 정지영상정보의 출력을 확인하고 외향형(E) 아바타 혹은 아이템이라고 사용자가 판 단하는 경우에는 플러스버튼을 누르고 제1 버튼 또는 제5 버튼을 누르고, 내향형(I)이라고 판단하는 경우에는 마이너스버튼을 누르고 제1 버튼 또는 제5 버튼을 누른다. 감각형(S) 아바타 혹은 아이템이라고 사용자가 판단하는 경우에는 플러스버튼을 누르고 제2 버튼 또는 제6 버튼 을 누르고, 직관형(N)이라고 판단하는 경우에는 마이너스버튼을 누르고 제2 버튼 또는 제6 버튼을 누른다. 사고형(T) 아바타 혹은 아이템 경우에는 플러스버튼을 누르고 제3 버튼 또는 제7 버튼을 누르고, 감정형(F) 경 우에는 마이너스버튼을 누르고 제3 버튼 또는 제7 버튼을 누른다. 판단형(J) 아바타 혹은 아이템 경우에는 플러스버튼을 누르고 제4 버튼 또는 제8 버튼을 누르고, 인식형(P) 경 우에는 마이너스버튼을 누르고 제4 버튼 또는 제8 버튼을 누른다. 버튼에 의해서 선택된 라벨값이 해당 아바타와 아이템의 정지영상정보 및 동영상정보에 입력된다. 본 발명의 일 실시예에서, 실제 손흥민은 ESFJ이고 외향적, 감각적, 감정적, 판단적인 성격유형이고 사용자는 MBTI 라벨분류를 참조하여, 임으로 E, S, F, J 라벨링을 하면서 점수를 입력한다. 본 발명의 일 실시예에서, '세상과 상호작용하는 방식과 에너지를 발휘하는 방향' 혹은 '선천적으로 주목하는 정보의 종류' 혹은 '조직화된 방식을 선호하는가 아니면 자발적인 방식을 선호하는가에 대한 차이' 혹은 '의사 결정 방식 사고형에 따른 차이'에 대해 MBTI 라벨분류를 만든다. 본 발명의 일 실시예에서, 사용자는 실제 MBTI 선호도 검사 후, 서버로 전송한다. 사용자의 아바타는 사용 자의 실제 MBTI 선호도 점수를 메타데이터로 소유하게 되고, 메타버스 상에서의 각자의 행동(반응, 댓글, 각종 참여 행위 등)에 기반하여 변화될 수 있으며, 이에 따라 사용자 아바타의 행동 빅데이터 정보에 기반한 패턴 분 석을 통해 점수가 구체적으로 세분화될 수 있다. 사용자는 다른 사용자의 아바타의 반응, 댓글, 각종 참여 행위 에 대해 단말에서의 앱 실행 결과 화면을 이용하여 아바타와 아이템에 MBTI 라벨값을 붙이고 점수를 입력 한다. 또한, 상기 단말은 영상정보에 드래그를 하거나 태그를 붙여서 경계선과 경계면을 자동인식하는 객체인식 기법을 이용하여 2분법, 3분법, 다분법 등의 방식으로 단말에서의 앱 실행 결과 화면에 표시되는 영상정보 에 MBTI 라벨을 붙이는 라벨링 방법을 'MBTI 선택라벨링'라고 정의한다. 해당 객체 인식(object recognition/object detection)을 위한 인공신경망은 해당 단말의 사용자가 해당 단말에서의 앱 실행 결과 화면의 영상정보에 드래그를 하거나 태그를 붙이면, 하나 이상의 잘못된 동작 부 위 및 동작들을 탐지하여 이미지를 분리하고 분석한다. 또한, 상기 단말은 인공지능 추론 과정을 통해 사 용자에게 추론 결과를 제공한다. 다양한 실시예로, 로우 데이터(또는 영상 정보)는 2D 영상 정보, 3D 영상 정보, 정지 영상의 포인트 클라우드 정보 등을 포함한다. 본 발명의 일 실시예에서, 시간축에서 시각을 나타내는 표를 이동하여(또는 상기 단말은 해당 단말에 표시되는 로우 데이터(예를 들어 동영상)에서 해당 재생바 내의 타임 라인 상에서 사용자 입력에 따라 마우스의 화살표(또는 마우스의 포인트)를 이동하여) 특정 시점에서 정지하여 정지영상을 캡처한 다음, 해당 시각의 정지 영상에 경계선과 경계면이 자동 인식되게 마우스의 버튼과 화살표로 태그를 붙인다. 또한, 상기 단말은 동 영상 중에서 캡처한 복수의 3D 정지 영상에 태그를 붙이면, 동영상 전체의 경계면과 경계선이 자동 인식되도록 제어한다. 본 발명의 일 실시예에서, 영상정보 전체에 대해 MBTI 라벨을 붙일 때는 인터페이스 화면의 버튼을 직접 누르는 방식으로 가능하고 세밀한 부분을 지정하여 라벨값을 입력하여 라벨을 붙이고자 할 때는 마우스 드래그를 이용 하여 경계선(직선이나 곡선)이나 경계면(폐곡선)을 지정하거나 다수개의 포인트를 마우스 버튼으로 지정한 다음MBTI 버튼을 누른다. 본 발명의 일 실시예에서, 2D 영상정보 및 3D 영상정보의 복수의 포인트 클라우드에 마우스의 왼쪽 버튼을 눌러 태그를 붙이거나 및/또는 드래그를 하여 태그를 붙이면 경계선 및 경계면의 자동 인식이 가능하도록 프로그램을 코딩한다. 본 발명의 일 실시예에서, 객체 인식의 방법에서 객체 탐지, 위치 측정, 객체 및 인스턴스 분할, 자세 추정 등 이 적용되고, 동영상 분석을 위한 인스턴스 추적, 행동 인식, 움직임 추정 등에도 동일하게 적용된다. 또한, 동 영상 클립에 포함된 동작을 감지하기 위해 합성곱 신경망과 결합하여 사용한다. 동작 감지, 장면 추출, 다음 프 레임 예측, 객체 추적 등이 사용된다. 자동 인식된 경계선과 경계면을 기준으로 인터페이스에서 출력되는 객체 및 동작의 잘된 부분과 잘못된 부분에 각각 승인 버튼 또는 거절 버튼을 누르는 방식으로 해당 라벨을 붙인다. 본 발명의 일 실시예에서, 2D 영상 정보 및 3D 영상 정보의 복수의 포인트 클라우드에 마우스의 왼쪽 버튼을 눌 러 태그를 붙이거나 및/또는 드래그를 하여 태그를 붙이면, 경계선 및 경계면의 자동 인식이 가능할 수 있다. 또한, 3D 정지 영상 중에서 x, y, z 좌표상에 존재하는 복수의 포인트 클라우드에 마우스 왼쪽 버튼을 눌러 태 그를 붙이거나 드래그를 하여 태그를 붙이면, 잘된 정보와 잘못된 정보의 경계선이 자동 인식되고, 폐곡선에 의 해 경계면이 자동 인식될 수 있다. 또한, 상기 단말은 상기 서버로부터 전송되는 해당 게임 결과를 각각 수신한다. 여기서, 상기 게임 결과는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자별 MBTI 선택라 벨링에 대한 정보(또는 복수의 단말의 게임 참가자/사용자와 관련한 아바타 및/또는 아이템별 MBTI 선택라 벨링에 대한 정보), 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 입력값으로 하여 수행된 인공지능에 의한 학습 결과일 수 있다. 또한, 상기 단말은 상기 수신된 게임 결과를 출력(또는 표시)한다. 또한, 상기 정보 처리 시스템은 기타 입력 장치(미도시)를 더 포함할 수 있다. 상기 기타 입력 장치는 상기 단말, 상기 서버 등과 통신한다. 또한, 상기 기타 입력 장치는 로우 데이터(또는 영상 정보)에 마우스로 태그를 붙이거나 드래그를 하여 라벨을 붙일 때 사용한다. 또한, 상기 기타 입력 장치는 컨트롤러, 아이 트래커(eye tracker), 데이터 글러브(data glove), 음성인식 인터 페이스(speech recognition interface), 브레인 컴퓨터 인터페이스(Brain-Computer Interface: BCI), 손 추적 기술(hand tracking technology), 햅틱 장치(haptic device) 등을 포함한다. 다음은 상기 기타 입력 장치의 사용 방법의 예를 나타낸다. 즉, 상기 기타 입력 장치의 사용 방법은 마우스의 화살표나 버튼을 음성 인식 인터페이스와 브레인 컴퓨터 인터 페이스로 작동시켜, 태그를 붙이거나 드래그를 하고 라벨을 붙이는 방법, 광선이 나오는 컨트롤러를 음성 인식 인터페이스와 브레인 컴퓨터 인터페이스로 작동시켜 태그를 붙이거나 드래그를 하고 라벨을 붙이는 방법, 아이 트래커를 음성 인식 인터페이스와 브레인 컴퓨터 인터페이스로 작동시켜 태그를 붙이거나 드래그를 하고 라벨을 붙이는 방법, 데이터 글러브를 손 추적 기술, 음성 인식 인터페이스, 브레인 컴퓨터 인터페이스로 작동시켜 태 그를 붙이거나 드래그를 하고 라벨을 붙이는 방법 등을 포함한다. 본 발명의 일 실시예에서, 음성 인식 인터페이스로 컴퓨터의 마우스의 버튼을 직접 움직인다. 컨트롤러의 광선 을 움직여서 태그를 붙이거나 드래그를 할 수도 있다. 또한, 아이 트래커를 사용하여 사용자의 응시를 감지해 시야각의 중심부에 태그를 붙이는 방법으로 분류하고자 하는 개체를 식별하여 객체에 라벨링을 수행한다. 또한, 데이터 글러브 및 손동작의 상호작용(또는 손동작 추적 기술)을 이용하여 사용자 인터페이스상의 영상에 태그를 붙이거나 객체에 경계선과 경계면을 만든다. 플랫폼 사용자(또는 각 분야 전문가 집단)가 사람의 뇌와 컴퓨터를 연결하는 브레인 컴퓨터 인터페이스 기술을 이용한다면, 플랫폼 사용자는 영상(예를 들어 정지 영상, 동영상 등 포함)을 보고, 경계선과 경계면에 마우스로 태그를 붙이거나 드래그를 한 다음 자신의 의지(또는 생각)만으로 정지 영상이나 동영상에 승인 버튼 또는 거절 버튼을 눌러 라벨을 붙일 수 있다. 더 나아가, 자신의 의지(또는 생각)만으로 정지 영상이나 동영상에서 경계선과 경계면을 만들기 위한 태그를 붙이거나 드래그를 한 다음, 구 분된 정지 영상과 동영상에서 선택라벨링을 수행한다. 본 발명의 일 실시예에서, 브레인 컴퓨터 인터페이스와 순환 신경망, 합성곱 신경망, 다층 신경망 알고리즘 등 과 로봇팔 기술을 융합하여 사용하면, 생각만으로도 해당 단말의 화면에 표시되는 승인 버튼 또는 거절 버 튼을 눌러 라벨을 붙이거나 선택라벨링을 할 수 있다. 또한, 상기 단말은 뇌 기계 인터페이스, 뉴로모핍 칩 등을 이용하여 정지 영상 정보와 동영상 정보에 라벨링을 하고, 라벨링된 정보들로 계층적 군집화를 할 수도 있다. 본 발명의 일 실시예에서, 고도화된 브레인 컴퓨터 인터페이스가 개발되면, 해당 단말에 표시되는 사용자 인터페이스(또는 화면)가 생각만으로 사용자의 머릿속에 나타나고, 사용자의 생각만으로 라벨링을 할 수도 있다. 또한, 상기 단말 또는 상기 서버는 라벨링된 정보들로 계층적 군집화를 하고, 생성 모델에 활 용할 수 있다. 또한, 상기 단말은 상기 서버 및 외부 서버(미도시)와 연동하여, 해당 라스트 레벨 영상(예를 들어 아바타, 아이템 등 포함)을 이용한, 문자메시지 송/수신 기능, 게시물 작성 기능, 이모티콘/아이콘 제작 및 사 용 기능, 채팅 기능, 해당 외부 서버에서 제공하는 게임 내 아바타(또는 아이템)에 적용(또는 반영/연동)하는 기능 등을 수행(또는 적용)한다. 여기서, 상기 외부 서버는 문자메시지 송/수신 기능을 제공하는 통신사 서버, 게시물 작성 기능 등을 제공하는 SNS 서버, 이모티콘/아이콘 제작 및 사용 기능을 제공하는 포털 서버, 채팅 기 능을 제공하는 채팅 서버, 게임을 제공하는 게임사 서버 등을 포함한다. 또한, 상기 단말은 하나 이상의 시각 세트 장치(미도시)와 연동하여, 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 여기서, 상기 시 각 세트 장치는 카메라부, 라이다, 아이트래커, 모션 캡처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의료용 초음파 등) 등을 포함한다. 또한, 상기 로우 데이터(또는 기초영상/원본 데이터/소스 데이터/시각 데이터/실제 현실의 영상)는 실제 현실에서 획득되는(또는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값 등을 포함한다. 여기서, 상기 측정값은 상기 라이다, 상기 아이트래 커, 상기 모션 캡처 및 모션트래커, 상기 의료장비 등을 통해 측정되는 영상 정보(또는 3차원 데이터) 등을 포 함한다. 또한, 상기 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유형에 따른 항목별 점수 등 포함) 등을 포함한다. 이때, 상기 단말은 해당 단말에 미리 설치된 전용 앱을 실행하고, 전용 앱 실행에 따른 앱 실행 결과 화면을 표시한다. 여기서, 상기 앱 실행 결과 화면은 해당 단말의 사용자와 관련한 하나 이상의 로우 데이 터, 해당 로우 데이터와 관련한 메타 정보 등을 수집하기 위한 수집 메뉴(또는 버튼/항목), 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하기 위한 레벨 선택 메뉴, 수집된 정보 나 서버로부터 제공되는 정보를 표시하기 위한 보기 메뉴, 해당 로우 데이터와 관련해서 생성된 라스트 레 벨 영상에 대한 레벨업 기능 수행을 위한 상점 메뉴, 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게 임 대기실 메뉴, 환경 설정을 위한 설정 메뉴 등을 포함한다. 이때, 상기 단말은 해당 전용 앱을 제공하는 상기 서버에 회원 가입한 상태로, 회원 가입에 따른 아이디 및 비밀번호, 상기 아이디를 포함하는 바코드 또는 QR 코드 등을 이용해서 상기 전용 앱 실행 시 로그인 절차를 수행하여, 해당 전용 앱의 하나 이상의 기능 (예를 들어 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등 포함)을 수행할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 수집 메뉴가 선택되는 경우, 상기 단말 은 사용자 설정에 따른 하나 이상의 시각 세트 장치로부터 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집하기 위해서, 상기 선택된 수집 메 뉴에 대응하는 수집 화면을 표시한다. 여기서, 상기 수집 화면은 사용자 선택(또는 사용자 입력/터치/제어)에 따라 해당 단말과 연동하는 하나 이상의 시각 세트 장치를 선택하기 위한 정보 수집 대상 선택 항목, 선택 된 정보 수집 대상으로부터 수집할 정보의 종류를 선택하기 위한 수집 정보 종류 선택 항목, 선택된 항목에 따 라 해당 정보 수집 대상으로부터 정보를 수집하기 위한 수집 시작 항목 등을 포함한다. 또한, 상기 단말은 해당 단말에 표시되는 수집 화면에서 해당 단말의 사용자 입력(또는 사용자/ 전문가 선택/터치/제어)에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 여기서, 상기 복수의 입력값은 정보 수집 대상(또는 시각 세트 장치 정보/시각 세트 장치의 식별 정보), 수집할 정보의 종류(예를 들 어 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값/센서값 등 포함) 등을 포함한다. 또한, 상기 단말은 상기 수신된 복수의 입력값을 근거로 상기 하나 이상의 시각 세트 장치와 연동하여, 해 당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 이때, 상기 단말은 해당 단말의 사용자와 관련해서 1명의 사용자로부터 1개의 로우데이터를 수집할 수도 있고, 1명의 사용자로부터 서로 다른 복수의 로우 데이터(또는 어트리뷰트 항목/어노테이 션 단계)에 따른 복수의 로우 데이터)를 수집할 수도 있다. 또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메 타 정보, 사용자 정보, 단말의 식별 정보 등을 상기 서버에 전송한다. 여기서, 상기 단말의 식 별 정보는 MDN, 모바일 IP, 모바일 MAC, Sim 카드 고유정보, 시리얼번호 등을 포함한다. 또한, 상기 단말은 상기 서버와 연동하여, 해당 사용자 정보(또는 해당 사용자와 관련한 MBTI 정보/ 해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수)가 적용된 로우 데이터를 이용해서, 미리 설정 된 기능을 수행한다. 여기서, 상기 미리 설정된 기능(또는 미리 설정된 이벤트)은, 해당 사용자의 MBTI 유형 맞 춤형 미팅 기능, 해당 사용자의 MBTI 유형 맞춤형 채팅 기능, 해당 사용자의 MBTI 유형 맞춤형 상품 추천 기능, 해당 사용자의 MBTI 유형 맞춤형 게임 상대 추천 기능 등을 포함한다. 즉, 해당 단말에서 게임 기능을 시작하는 경우, 상기 단말은 상기 서버로부터 제공되는 한 명 이상의 사용자에 대한 정보, 하나 이상의 상품 정보 등을 수신한다. 여기서, 상기 한 명 이상의 사용자에 대한 정보는 해당 서버에 미리 등록된 복수의 사용자 정보가 적용된 복수의 로우 데이터 중에서, 해당 사용자 정보가 적용된 로우 데이터를 이용해서 해당 사용자 정보에 포함된 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 근거로 미리 설정된 상생 관계 및/또는 상극 관계에 따라 확인된 한 명 이상의 사용자(또는 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터)에 대한 정보일 수 있다. 또한, 상기 상품 정보는 카테고리, 상품 명(또는 제품명), 상품 사진/동영상, 상품 상세 정보, 판매 가격(또는 판매 금액), 제조사명(또는 브랜드명), 판매자명, 판매자 연락처, 판매자 사업자등록번호, 판매자 통신판매업 신고번호 등을 포함한다. 또한, 상기 단말은 상기 수신된 한 명 이상의 사용자에 대한 정보(또는 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터), 하나 이상의 상품 정보 등을 표시한다. 또한, 상기 단말에 표시되는 한 명 이상의 사용자에 대한 정보(또는 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터에 대한 정보) 중에서 특정 사용자에 대한 정보(또는 특정 다른 로우 데이터에 대한 정 보/특정 다른 사용자 정보가 적용돼 특정 다른 로우 데이터에 대한 정보)가 선택되는 경우, 상기 단말은 상기 서버 및 상기 선택된 특정 사용자에 대한 정보에 대응하는 다른 단말(미도시)과 연동하여, 미팅 기능, 채팅 기능, 게임 기능(예를 들어 슈팅 게임, 농구 게임, 축구 게임 등 포함) 등을 수행한다. 여기서, 상 기 미팅 기능, 채팅 기능, 게임 기능 등은 상기 사용자 정보가 적용된 로우 데이터를 이용해서 가상현실, 증강 현실, 혼합현실, 확장현실, 메타버스, 디지털트윈 등의 형태로 수행(또는 구현/구성)될 수 있다. 또한, 상기 단말에 표시되는 하나 이상의 상품 정보(또는 해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수에 따라 추천된 하나 이상의 상품 정보) 중에서 특정 상품 정보가 선택되는 경우, 상기 단말 은 상기 서버 및 결제 서버(미도시)와 연동하여, 상기 선택된 특정 상품 정보에 대응하는 결제 금액 에 대해 결제 기능을 수행한다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 상기 서버(또는 상기 결제 서버)로부터 제 공되는 결제 기능 수행 결과를 수신하고, 상기 수신된 결제 기능 수행 결과를 표시한다. 여기서, 상기 결제 기 능 수행 결과는 상품 정보, 결제 금액, 결제 일자 및 시각 정보 등을 포함한다. 또한, 상기 단말은 하나 이상의 시각 세트 장치(미도시)와 연동하여, 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 여기서, 상기 시 각 세트 장치는 카메라부, 라이다, 아이트래커, 모션 캡처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의료용 초음파 등) 등을 포함한다. 또한, 상기 로우 데이터(또는 기초영상/원본 데이터/소스 데이터/시각 데이터/실제 현실의 영상)는 실제 현실에서 획득되는(또는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값 등을 포함한다. 여기서, 상기 측정값은 상기 라이다, 상기 아이트래 커, 상기 모션 캡처 및 모션트래커, 상기 의료장비 등을 통해 측정되는 영상 정보(또는 3차원 데이터) 등을 포 함한다. 또한, 상기 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유형에 따른 항목별 점수/실제 사용자의 MBTI 선호도 점수 등 포 함) 등을 포함한다. 이때, 상기 단말은 해당 단말에 미리 설치된 전용 앱을 실행하고, 전용 앱 실행에 따른 앱 실행 결과 화면을 표시한다. 여기서, 상기 앱 실행 결과 화면은 해당 단말의 사용자와 관련한 하나 이상의 로우 데이 터, 해당 로우 데이터와 관련한 메타 정보 등을 수집하기 위한 수집 메뉴(또는 버튼/항목), 해당 로우 데이터와비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하기 위한 레벨 선택 메뉴, 수집된 정보 나 서버로부터 제공되는 정보를 표시하기 위한 보기 메뉴, 해당 로우 데이터와 관련해서 생성된 라스트 레 벨 영상에 대한 레벨업 기능 수행을 위한 상점 메뉴, 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게 임 대기실 메뉴, 환경 설정을 위한 설정 메뉴 등을 포함한다. 이때, 상기 단말은 해당 전용 앱을 제공하는 상기 서버에 회원 가입한 상태로, 회원 가입에 따른 아이디 및 비밀번호, 상기 아이디를 포함하는 바코드 또는 QR 코드 등을 이용해서 상기 전용 앱 실행 시 로그인 절차를 수행하여, 해당 전용 앱의 하나 이상의 기능 (예를 들어 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등 포함)을 수행할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 수집 메뉴가 선택되는 경우, 상기 단말 은 사용자 설정에 따른 하나 이상의 시각 세트 장치로부터 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집하기 위해서, 상기 선택된 수집 메 뉴에 대응하는 수집 화면을 표시한다. 여기서, 상기 수집 화면은 사용자 선택(또는 사용자 입력/터치/제어)에 따라 해당 단말과 연동하는 하나 이상의 시각 세트 장치를 선택하기 위한 정보 수집 대상 선택 항목, 선택 된 정보 수집 대상으로부터 수집할 정보의 종류를 선택하기 위한 수집 정보 종류 선택 항목, 선택된 항목에 따 라 해당 정보 수집 대상으로부터 정보를 수집하기 위한 수집 시작 항목 등을 포함한다. 또한, 상기 단말은 해당 단말에 표시되는 수집 화면에서 해당 단말의 사용자 입력(또는 사용자/ 전문가 선택/터치/제어)에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 여기서, 상기 복수의 입력값은 정보 수집 대상(또는 시각 세트 장치 정보/시각 세트 장치의 식별 정보), 수집할 정보의 종류(예를 들 어 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값/센서값 등 포함) 등을 포함한다. 또한, 상기 단말은 상기 수신된 복수의 입력값을 근거로 상기 하나 이상의 시각 세트 장치와 연동하여, 해 당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 이때, 상기 단말은 해당 단말의 사용자와 관련해서 1명의 사용자로부터 1개의 로우 데이터를 수집할 수도 있고, 1명의 사용자로부터 서로 다른 복수의 로우 데이터(또는 어트리뷰트 항목/어노테이 션 단계에 따른 복수의 로우 데이터)를 수집할 수도 있다. 또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메 타 정보, 사용자 정보, 단말의 식별 정보 등을 상기 서버에 전송한다. 여기서, 상기 단말의 식 별 정보는 MDN, 모바일 IP, 모바일 MAC, Sim 카드 고유정보, 시리얼번호 등을 포함한다. 또한, 상기 단말에서 참여한 게임룸을 개설한 방장에 의해 미리 설정된 게임 시작 메뉴가 선택되는 경우 (또는 해당 게임룸과 관련해서 미리 설정된 게임 시작 조건을 만족하는 경우), 상기 단말은 상기 서버 , 해당 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 해당 게임을 관전 중이거나 미리 설정된 게임상의 국가기관/회사/상점에 소속된 사용자가 소지한 다른 복수의 단말, 해당 게임과 유사한 게 임에 참여했던 다른 사용자가 소지한 또 다른 복수의 단말 등과 연동하여, 해당 게임(또는 해당 게임룸)과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 게임 시작 조건은 미리 설정된 게임 참가자 수를 만족하는 경우, 미리 설정된 게임 시작 시각을 만족하는 경우 등을 포함한다. 이때, 상기 서버는 미리 설 정된 조건(예를 들어 게임 시작 후 미리 설정된 시간(일 예로 5분, 10분 등 포함)이 지난 경우, 미리 설정된 참 여자(일 예로 10명) 이상이 MBTI 점수 체계 제정에 참여한 경우 등 포함)을 만족할 때까지 해당 게임과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 조건을 충족할 때까지 상기 게임과 관련한 MBTI 점수 체 계가 제정되지 않은 경우, 상기 서버는 해당 게임과 관련해서 미리 설정된 디폴트값으로 해당 MBTI 점수 체계를 제정(또는 설정)할 수도 있다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 게임 대기실 메뉴가 선택되는 경우, 상기 단말은 게임 참여를 위해 개설된 게임방 목록을 제공하거나 새로운 게임방을 개설하기 위해서, 상기 선택 된 게임 대기실 메뉴에 대응하는 게임 대기실 화면을 표시한다. 여기서, 상기 게임 대기실화면은 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게임방 리스트 항목, 새로운 게임방을 개설하기 위한 게임방 생성 항 목 등을 포함한다. 또한, 상기 단말에 표시되는 게임 대기실화면 내의 게임방 리스트 항목에 포함된 하나 이상의 게임 대기방 중에서 어느 하나의 게임 대기방이 선택되는 경우, 상기 단말은 상기 서버와 연동하여, 상기 선택된 게임 대기방에 대응하는 게임룸에 입장(또는 참여)한다.또한, 상기 단말에서 참여한 게임룸을 개설한 방장에 의해 미리 설정된 게임 시작 메뉴가 선택되는 경우 (또는 해당 게임룸과 관련해서 미리 설정된 게임 시작 조건을 만족하는 경우), 상기 서버는 해당 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 해당 게임을 관전 중이거나 미리 설정된 게임상의 국 가기관/회사/상점에 소속된 사용자가 소지한 다른 복수의 단말, 해당 게임과 유사한 게임에 참여했던 다른 사용자가 소지한 또 다른 복수의 단말 등과 연동하여, 해당 게임(또는 해당 게임룸)과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 게임 시작 조건은 미리 설정된 게임 참가자 수를 만족하는 경우, 미리 설정된 게임 시작 시각을 만족하는 경우 등을 포함한다. 이때, 상기 서버는 미리 설정된 조건(예를 들어 게임 시작 후 미리 설정된 시간(일 예로 5분, 10분 등 포함)이 지난 경우, 미리 설정된 참여자(일 예로 10 명) 이상이 MBTI 점수 체계 제정에 참여한 경우 등 포함)을 만족할 때까지 해당 게임과 관련한 MBTI 점수 체계 를 제정한다. 여기서, 상기 미리 설정된 조건을 충족할 때까지 상기 게임과 관련한 MBTI 점수 체계가 제정되지 않은 경우, 상기 서버는 해당 게임과 관련해서 미리 설정된 디폴트값으로 해당 MBTI 점수 체계를 제정(또 는 설정)할 수도 있다. 또한, 상기 단말은 상기 서버와 연동하여, 해당 게임에 참여하는 해당 단말의 사용자(또는 게임 참가자)와 관련한 게임 캐릭터(또는 게임 캐릭터의 MBTI 유형/상기 사용자 정보가 적용된 로우 데이터)와, 해당 게임에 참여한 다른 게임 참가자와 관련한 게임 캐릭터(또는 게임 캐릭터의 MBTI 유형/상기 사용자 정보가 적용 된 로우 데이터)를 참조하여, 게임 참가자별 MBTI 선택라벨링(또는 복수의 단말의 게임 참가자/사용자와 관련한 게임 캐릭터별 MBTI 선택라벨링) 기능을 수행한다. 여기서, 상기 MBTI 선택라벨링(또는 MBTI 선택레이블 링)은 해당 게임에 참여한 모든 사용자와 관련한 게임 캐릭터에 대해서 해당 단말의 사용자가 생각하는 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 설정하는(또는 붙이는) 라벨링 방법을 나타낸다. 이때, 상 기 MBTI 유형에 따른 항목별 점수는 미리 설정된 범위(예를 들어 0점 ~ 100점) 중에서 선택될 수 있다. 이와 같이, 상기 단말은 해당 게임에 참여한 복수의 게임 참가자가 각각 소지한 게임 캐릭터(예를 들어 아 바타, 아이템 등 포함)와 관련해서, 각각의 게임 참가자별 MBTI 선택라벨링(또는 사용자별 MBTI 선택라벨링) 기 능을 수행하여, 게임 참가자별 게임 캐릭터에 대한 MBTI 유형과 항목별 점수를 각각 설정(또는 수신/입력)할 수 있다. 본 발명의 실시예에서는 상기 단말에서 전용 앱 형태로 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영상 활용 기능 등을 수행하는 것을 설명하고 있으나, 이에 한정 되는 것은 아니며, 상기 전용 앱 이외에도 상기 서버에 제공하는 웹 사이트 등을 통해 상기 로우 데이터 수집 기능, 상기 레벨 선택 라벨링 기능, 상기 레벨 강화 기능, 상기 게임 참여 기능, 상기 라스트 레벨 영상 활용 기능 등을 수행할 수도 있다. 상기 서버는 상기 단말 등과 통신한다. 또한, 상기 서버는 상기 단말 등의 사용자에 대한 회원 가입 절차 등을 수행한다. 또한, 상기 서버는 상기 단말 등의 사용자와 관련한 개인 정보를 등록한다. 이때, 상기 서버는 해당 개인 정보 등을 DB 서버(미도시)에 등록(또는 관리)할 수 있다. 또한, 상기 서버는 상기 단말 등의 사용자에 대한 회원 관리 기능을 수행한다. 또한, 상기 서버는 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라 스트 레벨 영상 활용 기능 등을 제공하는 전용 앱 및/또는 웹 사이트를 상기 단말 등에 제공한다. 또한, 상기 서버는 공지사항, 이벤트 등을 위한 게시판 기능을 제공한다. 또한, 상기 서버는 상기 단말 및 상기 결제 서버와 연동하여, 해당 서버에서 제공하는 로우 데 이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영상 활용 기능 등에 대해서 해당 단말에서의 구독 기능 수행에 따른 결제 기능을 수행한다. 결제 기능이 실패한 경우, 상기 서버는 결제 실패 정보(예를 들어 결제일자, 결제금액, 실패 정보(예를 들 어 잔액 부족, 한도 초과 등 포함) 등 포함)(또는 결제가 실패한 상태임을 나타내는 정보)를 상기 단말로 제공한다. 또한, 상기 서버는 상기 단말과의 결제 기능이 정상적으로 수행된 후, 상기 결제 서버로부터 제공되 는 결제 기능 수행 결과를 상기 단말에 각각 전송한다. 여기서, 상기 결제 기능 수행 결과는 구독 기간,결제 금액, 결제 일자 및 시각 정보 등을 포함한다. 또한, 상기 서버는 결제 기능 수행 결과를 해당 단말(또는 해당 단말과 관련한 계정 정보)과 매 핑하여(또는 매칭하여/연동하여) 관리(또는 저장/등록)한다. 또한, 상기 서버는 상기 구독 기능 수행에 따라, 상기 단말에서 해당 전용 앱을 통해 해당 서버(20 0)에서 제공하는 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레 벨 영상 활용 기능 등을 수행하기 위한 다양한 정보 등을 제공한다. 또한, 상기 서버는 해당 서버의 구성 요소 간 통신 기능을 제공하기 위해서 버스(미도시), 통신 인터 페이스(미도시) 등을 더 포함할 수 있다. 상기 버스는 주소 버스(address bus), 데이터 버스(data bus), 제어 버스(control bus) 등 다양한 형태의 버스 로 구현한다. 상기 통신 인터페이스는 상기 서버의 유/무선 인터넷 통신을 지원한다. 또한, 상기 서버는 컴퓨터 프로그램이 메모리에 로드될 때, 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방법/기능을 수행하도록 하는 하나 이상의 인스트럭션을 포함한다. 즉, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 본 발명의 다양한 실시예에 따른 상기 방법/기능을 수행한다. 또한, 상기 서버는 사전에 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 레벨 선택 라벨링에 대한 정보, 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사 용자 정보, MBTI 점수 체계 등을 지속적인 기계학습(또는 딥러닝)의 데이터로 활용한다. 여기서, 상기 기계학습 을 위한 입력 데이터세트는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정 보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 레벨 선택 라벨링에 대한 정보, 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 미리 설정된 비율(예를 들어 7:3, 8:2 등 포함)로 훈련 세트(train set)와 테스트 세트(test set)로 분할하여, 훈련 및 테스트 기능을 수행할 수 있다. 또한, 상기 기계학습을 위한 입력 데이터 세트는 추후 수집되는 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 레벨 선택 라벨링에 대한 정보, 게임 참가 자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 포함한다. 또한, 상기 기계학습을 위한 출력 데이터세트는 예측하고 싶은 부분으로, 수집된 정 보 등에 따라 학습하고, 추후에 이를 생성하거나 승패를 결정하여, 하나 이상의 로우 데이터와 비교 대상 영상 을 이용해서 딥페이크(deepfake) 형태의 아바타 및/또는 아이템을 생성하고, 게임에 참여한 사용자별 승패에 대 한 정보를 결정(또는 예측)하는 정보 등을 포함한다. 즉, 상기 서버는 미리 설정된 학습용 데이터를 통해 생성 모델에서 하나 이상의 로우 데이터(또는 기초영 상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 레벨 선택 라벨링에 대한 정보 등에 대해서 딥페이크된 아바타 및/또는 아이템을 생성하기 위한 학습 기 능을 수행한다. 이때, 상기 서버는 해당 정보들을 병렬 및 분산하여 저장하고, 저장된 정보들 내에 포함된 사전에 수집된 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정 보, 사용자 정보, 레벨 선택 라벨링에 대한 정보 등을 비정형(Unstructed) 데이터, 정형(Structured) 데이터, 반정형 데이터(Semi-structured)를 정제하고, 메타 데이터로 분류를 포함한 전처리를 실시하고, 전처리된 데이 터를 데이터 마이닝(Data Mining)을 포함하는 분석을 실시하고 적어도 하나의 종류의 기계학습에 기반하여 학습, 훈련 및 테스트를 진행하여 빅데이터를 구축할 수 있다. 이때, 적어도 하나의 종류의 기계학습은 지도 학 습(Supervised Learning), 반지도 학습(Semi-Supervised Learning), 비지도 학습(Unsupervised Learning), 강 화 학습(Reinforcement Learning) 및 심층 강화 학습(Deep Reinforcement Learning) 중 어느 하나 또는 적어도 하나의 조합으로 이루어질 수 있다. 또한, 상기 서버는 미리 설정된 학습용 데이터를 통해 승패 결정 모델(또는 게임 목적 달성 모델)에 대해 사전에 수집된 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사 용자별 사용자 정보, MBTI 점수 체계 등에 대해서 해당 정보들에 따른 게임의 승패를 결정(또는 예측)하기 위한 학습 기능을 수행한다. 이때, 상기 서버는 해당 정보들을 병렬 및 분산하여 저장하고, 저장된 정보들 내에 포함된 사전에 수집된 게임 참가자별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 비정형 데이터, 정형 데이터, 반정형 데이터를 정제하고, 메타 데이터로 분류를 포함한 전처리를 실시하고, 전처리된 데이터를 데이터 마이닝을 포함하는 분석을 실시하고 적 어도 하나의 종류의 기계학습에 기반하여 학습, 훈련 및 테스트를 진행하여 빅데이터를 구축할 수 있다. 이때, 적어도 하나의 종류의 기계학습은 지도 학습, 반지도 학습, 비지도 학습, 강화 학습 및 심층 강화 학습 중 어느 하나 또는 적어도 하나의 조합으로 이루어질 수 있다. 이와 같이, 상기 서버는 상기 학습용 데이터 등을 통해서 뉴럴 네트워크(Neural Networks) 형태의 상기 생 성 모델, 상기 승패 결정 모델 등에 대해서 학습 기능을 수행한다. 또한, 상기 서버는 생성형 딥러닝(deep learning) 인공지능 알고리즘을 이용한. 본 발명의 일 실시예에서, 상기 서버는 객체의 다음 동작을 예측하는 신경망 알고리즘을 사용한다. 또한, 상기 서버는 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상 기 레벨 선택 라벨링에 대한 정보, 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보, 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정 보를 근거로 상기 레벨 선택 라벨링에 대한 정보에 대응하는 결제 금액에 대해서 해당 단말의 사용자 계정 에 적립된 포인트(또는 현금성 포인트/현금에 대응하는 MBTI 점수)를 이용해서 결제 기능(또는 요금부과 기능) 을 수행한다. 이때, 해당 단말의 사용자 계정에 적립된 포인트가 해당 상기 레벨 선택 라벨링에 대한 정보 에 대응하는 포인트보다 적은 경우, 상기 서버는 해당 단말 및 결제 서버(미도시)와 연동하여, 해당 레벨 선택 라벨링에 대한 정보에 대응하는 포인트와 관련한 결제 금액(또는 부족한 포인트와 관련한 금액)에 대 해서 결제 기능을 수행할 수도 있다. 여기서, 상기 단말에서 상기 레벨 선택 라벨링을 미리 설정된 디폴트 값으로 설정한 경우, 상기 서버는 결제 기능을 생략하거나 또는, 해당 디폴트값에 대응하는 포인트에 대해 결제 기능을 수행할 수 있다. 이때, 상기 라스트 레벨 영상 생성이 무료로 진행되는 경우, 상기 결제 과정은 생 략될 수도 있다. 본 발명의 실시예에서는, 상기 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보를 근거로 결제 기능을 수행하는 것을 주로 설명하고 있으나 이에 한정되는 것은 아니며, 상기 서버는 상기 로우 데 이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보를 근거로 상기 로우 데이터와 상기 비교 대상 영 상을 딥페이크한 라스트 레벨 영상을 생성한 후, 상기 생성된 라스트 레벨 영상을 상기 단말에 제공하기 직전에 해당 결제 기능을 수행할 수도 있다. 또한, 상기 서버는 상기 수신된 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련 한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상기 레벨 선택 라벨링 에 대한 정보 등을 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공 지능 결과/딥 러닝 결과)를 근거로 해당 로우 데이터와 해당 비교 대상 영상을 딥페이크한 라스트 레벨(last level) 영상을 생성한다. 이때, 상기 라스트 레벨 영상은 상기 로우 데이터와 상기 비교 대상 영상을 근거로 생 성되는 아바타(또는 해당 아바타의 동작 관련 영상), 하나 이상의 아이템(또는 해당 아이템의 동작 관련 영상) 등을 포함하며, 상기 레벨 선택 라벨링에 대한 정보에 따라 트레이닝율이 다르게 설정되어 실제 상기 로우 데이 터와 상기 비교 대상 영상과의 일치율(또는 유사율)이 다를 수 있다. 여기서, 상기 단말에서 상기 레벨 선 택 라벨링을 미리 설정된 디폴트값으로 설정한 경우, 상기 서버는 해당 디폴트값에 대응하는 기본 트레이 닝율(예를 들어 10%)을 적용하여 상기 라스트 레벨 영상을 생성할 수 있다. 즉, 상기 서버는 결제 기능이 정상적으로 완료된 후, 상기 수신된 상기 하나 이상의 로우 데이터(또는 기 초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사 용자 정보, 상기 레벨 선택 라벨링에 대한 정보 등을 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 로우 데이터 와 해당 비교 대상 영상을 딥페이크한 라스트 레벨 영상을 생성한다. 이때, 상기 서버는 상기 수신된 사용자 정보, 레벨 선택 라벨링에 대한 정보 등을 근거로 인공지능 기반의 기계 학습을 수행하여, 기계 학습 결과를 근거로 해당 레벨 선택 라벨링에 대한 정보의 분류값을 생성한다. 여 기서, 상기 레벨 선택 라벨링에 대한 정보의 분류값(또는 해당 레벨 선택 라벨링의 분류값)은 해당 로우 데이터 와 비교 대상 영상을 근거로 생성될 아바타의 레벨 정보, 해당 로우 데이터와 비교 대상 영상을 근거로 생성될아이템의 레벨 정보 등을 동일 항목별로 분류한 값일 수 있다. 즉, 상기 서버는 상기 사용자 정보, 상기 레벨 선택 라벨링에 대한 정보 등을 미리 설정된 분류 모델의 입 력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결 과)를 근거로 해당 레벨 선택 라벨링에 대한 정보에 대한 분류값을 생성(또는 확인)한다. 또한, 상기 서버는 상기 생성된 해당 레벨 선택 라벨링에 대한 정보에 대한 분류값(또는 해당 레벨 선택 라벨링의 분류값), 해당 레벨 선택 라벨링에 대한 정보, 해당 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 해당 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 해당 사용자 정보 등을 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과 /딥 러닝 결과)를 근거로 해당 로우 데이터와 해당 비교 대상 영상을 딥페이크한 라스트 레벨 영상을 생성한다. 즉, 상기 서버는 상기 생성된 해당 레벨 선택 라벨링에 대한 정보에 대한 분류값(또는 해당 레벨 선택 라 벨링의 분류값), 해당 레벨 선택 라벨링에 대한 정보, 해당 하나 이상의 로우 데이터(또는 기초영상), 해당 로 우 데이터와 관련한 메타 정보, 해당 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 해당 사용자 정보 등을 상기 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 로우 데이터와 해당 비교 대상 영상을 딥페이크한 라스트 레벨 영상을 생성한다. 또한, 상기 서버는 상기 생성된 라스트 레벨 영상을 상기 단말에 전송한다. 본 발명의 일 실시예에서, 트레이닝율에 따른 아바타의 레벨(또는 등급)은 다음과 같이 정할 수 있다. [표 1]을 참조하면, 특정 사람(예를 들어 연예인, 운동선수 등 포함)의 얼굴을 다른 사용자의 얼굴과 합성한다 고 할 때, 트레이닝 수준이 5% ~ 60%일 경우 일반적인 사람의 얼굴이 아닌 이상한 형상(예를 들어 작은 원숭이 와 같은 얼굴이 이중으로 뜨는 경우, 가면을 쓴 것 같은 얼굴 등 포함)을 갖는 이미지가 생성될 수 있다. 트레 이닝율 수준이 90% 이상일 경우, 상대적으로 자연스러운 결과물이 생성될 수 있다. 여기서, 얼굴과 표정 결과물 및, 결과물의 특징은 예시로 들은 기괴한 형태의 모습이다. 표 1 라벨값 (아바타 얼굴 레벨)얼굴과 표정 결과물트레이닝율 결과물의 특징 정보형태 1 가면 얼굴 형태 1 45%가면 얼굴이 조잡스러운 상태, 표 정이 매우 부자연스러움영상 등 2 가면 얼굴 형태 2 50%가면 얼굴의 조잡스러움이 다소 호 전된 상태영상 등 3 가면 얼굴 형태 3 55%가면 얼굴의 조잡스러움이 다소 호 전돼도 얼굴의 부자연스러움도 다 소 해결된 상태영상 등 ... .. ...... ... r 원숭이 얼굴 형태 1 75%딥페이크 대상의 얼굴이 원숭이 얼 굴 모양으로 대체되었으나 조잡스 러운 상태, 얼굴 표정도 부자연스 러움영상 등 ... 원숭이 얼굴 형태 2 80%딥페이크 대상의 얼굴이 원숭이 얼 굴 모양으로 대체되었고 조잡스러 움이 다소 해결된 상태영상 등 ... ... ...... ... m8 자연스런 얼굴 형태 1 90%육안으로 보기에 딥페이크가 어느 정도 성공한 수준영상 등 ... 자연스런 얼굴 형태 93% 자연스런 얼굴 표정 영상 등 ... 자연스런 얼굴 형태 96% 좀 더 완성된 얼굴 표정 영상 등 [표 2]는 드리블 동작 결과물과 결과물의 특징 등을 예시로 한 기괴한 형태의 동작이다. 표 2 라벨값 (드리블 레벨)드리블 동작 결과물트레이닝율 결과물의 특징 정보형태 1이중으로 몸이 움직이는 동 작 145%동작이 이중으로 나타나는 조잡스 러운 상태, 동작이 매우 부자연스 러움영상 등 2이중으로 몸이 움직이는 동 작 250%동작이 이중으로 나타나는 조잡스 러운 상태 동작의 부자연스러움이 다소 해소 됨영상 등 3이중으로 몸이 움직이는 동 작 355%동작이 이중으로 나타나는 상태이 나 동작의 부자연스러움이 다소 해 소됨영상 등 ... ... ...... ... o사용자의 몸에 대상자의 몸 이 마스킹되서 움직이는 동 작 175%사용자의 몸에 딥페이크 대상의 몸 이 대체되었으나 조잡스러운 상태, 동작이 부자연스러움영상 등 ...사용자의 몸에 대상자의 몸 이 마스킹되서 움직이는 동 작 280%사용자의 몸에 딥페이크 대상의 몸 이 대체되었으나 조잡스러움이 다 소 해결된 상태영상 등 ... ... m9 자연스런 동작 1 90%육안으로 보기에 딥페이크가 어느 정도 성공한 수준의 동작영상 등 ... 자연스런 동작 2 93% 자연스런 동작 영상 등 ... 자연스런 동작 3 96% 좀 더 완성된 동작 영상 등 도 5는 본 발명의 실시예에 따른 사용자의 메타데이터인 영상정보(또는 로우 데이터)이고, 도 6은 본 발명의 실 시예에 따른 도 6에 대한 복수의 결과물의 예를 나타낸 도이고, 도 7 및 도 8은 본 발명의 실시예에 따른 가면 얼굴 형태의 예를 나타낸 도이고, 도 9 및 도 10은 본 발명의 실시예에 따른 원숭이 얼굴 형태의 예를 나타낸 도이다. 생성 알고리즘(또는 생성 모델)으로 지도학습의 라벨 없이 학습 가능한 비지도 학습을 하여, 데이터를 생 성한다. 직접 생성된 이미지의 Real or Fake 정보를 추론하고, 정확도를 올리기 위해 제너레이터(Generator)(또 는 생성 모델)가 진화하며, 많은 량의 반복 시도를 한다. 정확하게 제너레이터가 학습되지 않은 상태에서, 중간 결과를 실제 현실(Real World)의 데이터를 적용하는 경우 (특히 Face 부분의 실사에 적용하는 경우)에 해당 결과물은 특히 리플레이스(replace)된 영역이 마스크(Mask)가 있는 것처럼 돋아져 보이게 되며, 이는 조잡한 인상을 줄 수 있다. 얼굴과 표정의 중간 결과를 이용하는 방식은 동작의 딥페이크에도 동일하게 적용된다. 딥페이크의 결과물의 트레이닝율에 영향을 미치는 요인으로 사용자가 제공한 사용자 자신의 동영상과 딥페이크 대상의 동영상의 매칭률이 있다. 따라서, 사용자가 실험적인 방법으로 낮은 매칭률과 높은 매칭률을 가진 사용 자 자신의 동영상과 딥페이크 대상의 동영상을 제공한다면, 얼굴 표정과 동작에 있어서 다양한 라벨값과 속성값 들이 집단지성화로 생성된다. 또한, 구현하고자 하는 얼굴 표정 및 동작의 난이도는 트레이닝율에 영향을 미친다. 복잡한 동작을 구현하고자 할 때, 사용자의 실험적인 의도에 따라 다양한 라벨값과 속성값들이 생성된다. 딥페이크 대상을 한 명이 아닌 복수로 선정할 때, 다양한 라벨분류의 집단지성화가 된다. 각 등급(레벨)의 회원은 중간 중간 결과물에 대해 프 레임(Frame)별로 복수를 선별(혹은 제공된 동영상의 결과물 선택하는 것을 라벨분류표 [표 1] 및/또는 [표 2]를 참조하여 선택)할 수 있다. 동영상의 복수의 결과물을 선택하는 라벨링은 특정 에포크(epoch)의 결과물에 대한 집단지성 라벨링(지도학습)의 과정이다. 라벨값을 기준으로 사용자에 의한 라벨링에 의해 집단지성화하여 아바 타와 동작 아이템의 레벨을 정할 때, 에포크 수와 상관없이 라벨링이 되고 레벨값이 정해진다. 사용자들에 의하 여 선택되고 사용되는 과정이 반복되면, 비지도 학습 생성 알고리즘은 기존의 방식에 비하여 비지도학습과 지도학습의 하이브리드 방식으로 품질이 좋아진다. 이렇게 진화된 결과물은 라스트 라벨(Last Level) 영상정보 를 한 단계 더 진화시켜, 라스트 라벨+1 영상정보를 만들어 낼 수 있으며, 결과물이 계속 사용자들의 선택과정(마치 지도학습과 같은 효과)을 거치기 때문에 더 우수하다. 레벨 2 회원은 1만 에포크 이상의 트레이닝 결과물 을 제공하며, 레벨 1 회원은 5천 에포크 이상 1만 에포크 미만의 트레이닝 결과물을 제공한다. 본 발명의 일 실시예에서, 개시된 플랫폼(또는 정보 처리 시스템) 내에서의 화장품 상점이라는 것은 화장품 회사들의 수많은 인터넷 쇼핑몰과 건물 이미지, 회사 내부들을 생성 및 출력한 것이다. MBTI 점수가 높고 고도 화된 아이템을 장착한 잘 트레이닝된 아바타 사용자에게는 GAN으로 많이 충분히 트레이닝되어 고도화된 화장품 상점에 입장하도록 한다. 반면, 아이템이 허술하고 MBTI 점수가 일정 수준 이하인 사용자에게는 약간 부족한 수 준, 즉 약간 기괴한 형태의 화장품 상점만 입장이 가능하도록 한다. 점수가 일정 이하인 사용자는 약간 부족한 수준의 화장품만 구입할 수 있다. 고도화된 화장품 상점이라는 것은 그 모습이 안정적이고 정상적인 수준에 가 까운 것을 의미하고 고도화가 덜된 화장품 상점이라는 것은 트레이닝 수준이 아직 높지 않아서 정상적이지 않고 기괴한 화장품을 의미한다. 고도화가 많이 진행된 화장품 상점일수록 고급화된 아이템들을 판매하고 비싼 금액 을 요금부과 한다. 또한, 각 사용자가 구매하거나 생성한 건물에는 광고 게시판(예: 옥탑 광고판, 디지털 사이 니지 등)이 마련될 수 있으며, 건물에 게시된 광고비 수익의 일정 부분은 건물의 주인인 사용자에게 지급될 수 있다. 다만, 각 건물의 완성도는 서로 상이하게 설정될 수 있으며, 완성도가 높게 생성된 건물의 경우 광고 또 한 선명하게, 현실과 같은 형태로 표시될 수 있으나, 완성도가 낮은 건물의 경우 광고 또한 흐리거나 이상한 형 태로 표시될 수 있다. 즉, 건물의 소유자들은 광고 수입을 높이기 위해서도 건물의 완성도를 높이고자 하는 유 인을 가질 수 있다. 본 발명의 실시예는 건물 외에도 상점이나 기차 등 교통수단에도 적용될 수 있으며, 이에 제한되지 않는다. 본 발명의 일 실시예에서, MBTI 선호도 점수가 높을수록 더 높은 레벨로 트레이닝된 페라리 아이템을 소유할 수 있다. 페라리 매장에 자동차를 구매하는 사용자 아바타도 MBTI 점수에서 일정 조건이 필요하고 그 조건이 만족하여야 만 페라리를 구매할 수 있다. 즉, MBTI 선호도 점수가 높을수록 점수를 지급하고 더 높은 수준(예: 70% -> 80% -> 90%)으로 트레이닝된 페라리 아이템을 소유할 수 있다. 예를 들어, 댄스 오디션 게임의 아바타는 MBTI 점수 및 선호도가 댄스에 적합하여야 하고, 아이템 또한 댄스, 성형, 무용, 연기, 스피치, 화장, 패션 등에 적합한 MBTI 선호도를 갖추어야 한다. 그리고 이런 분야에 해당하 는 MBTI 선호도가 아바타와 매칭이 잘되고 점수가 높아야 높은 트레이닝 레벨의 아바타와 아이템을 사용자가 용 이하게 획득한다. 마찬가지로, 아바타의 동작(예 : 의료기술, 춤, 연기, 운동) 또한 생성 알고리즘에 기반하여 생성된다. 즉, 개시된 실시 예에 따른 생성 알고리즘 모델은 다양한 동작 레벨(예 : 잘하는 의료 기술, 잘 추는 춤과 못 추는 춤, 높은 축구실력과 낮은 축구 실력)을 차등적으로 학습한 모델일 수 있고, 서버는 비싸게 요금 이 부과된 아바타의 경우 GAN을 이용하여 높은 레벨의 동작을 생성하고, 상대적으로 저렴하게 요금이 부과된 아 바타의 경우 생성 알고리즘을 이용하여 상대적으로 낮은 레벨의 동작을 생성한다. 본 발명의 일 실시예에서, 서버는 아이템 구매를 위한 결제페이지를 제공하며, 구매 완료된 아이템을 아바 타에 합성하거나, 구매된 서비스에 따라 아바타를 변형한다. 또한, 서버는 메타버스 내에 미용실 콘텐츠를 제공하고, 원하는 서비스에 대한 비용을 지급하면 메이크업 이나 머리 세팅을 하듯이 생성 알고리즘을 이용하여 아바타의 일정 부분이나 전체를 변경한다. 또한, 서버는 메타버스 내에 옷가게, 액세서리샵 등 콘텐츠를 제공하고, 원하는 아이템에 대한 비용 지급 시 아이템을 구매하고, 생성 알고리즘을 이용하여 아바타의 일정 부분이나 전체를 변경한다. 또한, 서버는 메타버스 내에 요가원, 춤 학원, 스포츠 학원 등의 콘텐츠를 제공하고, 원하는 서비스에 대 한 비용 지급시 해당 서비스에 관련된 능력치를 고도화시킬 수 있다. 또한, 서버는 메타버스 내에 외국어 학원 콘텐츠를 제공하고, 원하는 서비스에 대한 비용 지급시 번역기능 을 강화하여 해당 언어로 의사소통을 더 잘하도록 능력치를 고도화시킬 수 있다. 또한, 서버는 메타버스 내에 스피치 학원 콘텐츠를 제공하고, 원하는 서비스에 대한 비용 지급 시 더 좋은 발음, 목소리가 생성되도록 하여 능력치를 고도화시킬 수 있다. 서버는 아바타를 이용하여 오디션 게임을 진행한다. 오디션 게임은 생성된 아바타의 외모, 동작(예: 춤, 연기, 운동 등)을 겨루는 것일 수 있다.서버는 아바타를 이용하여 스포츠 게임을 진행한다. 스포츠 게임은 각각의 사용자에 대응하여 생성된 아바 타들을 이용하여 진행될 수 있으며, 각각의 아바타는 생성 알고리즘을 이용하여 생성된 동작에 기반하여 스포츠 게임을 수행한다. 상술한 바와 같이 각 아바타는 차등화된 레벨의 운동능력이나 스킬을 가질 수 있고, 이에 따라 높은 레벨의 운동능력이나 스킬을 가지고 있을수록 게임에서 유리하다. 본 발명의 일 실시예에서, 서버는 메타버스 국가에서 할 수 있는 게임의 아바타를 제작한다. 재판 게임, 경찰게임, 소방관게임, 예술품 창작 게임, 농업게임, 무역 게임, 토지개발 게임, 건축게임, 금융투자 게임, 에 너지 발전 게임, 병원 게임, 치과 병원 게임, 남녀 미팅 게임, 회사 운영 게임, 국가기관 운영 게임, 전쟁 및 전투 게임, 슈팅 게임, 전략 게임, 아케이드 게임, 스포츠 게임, 오디션 게임 등이 메타버스 국가 내에서 일어 날 수 있는 경쟁 게임의 일부분이다. 메타버스 병원 게임은 메타버스 국가 게임의 일부이고, 디지털 카데바는 아바타의 일종이다. 도 11은 본 발명의 실시 예에 따른 생성 알고리즘을 이용한 가상 아바타 및 아이템의 생성 및/또는 출력 플랫폼 제공 방법을 나타내는 도면이다. 도 11을 참조하면, 상기 서버는 사용자로부터 사용자 정보를 획득하는 단계와(S1110), 획득된 사용자 정보 를 기초로, 가상의 아바타 및 아이템을 생성하는 단계와(S1120), 상기 아바타를 메타버스 상에 제공하는 단계와 (S1130), 상기 아바타를 이용한 가상 게임 등을 진행하는 단계(S1140)를 포함하는 가상 아바타의 생성에 관한 플랫폼 제공 방법을 수행하도록 하는 하나 이상의 인스트럭션을 포함한다. 즉, 상기 서버는 사용자로부터 사용자 정보를 획득하고(S1110), 획득된 사용자 정보를 기초로, 가상의 아 바타를 생성 알고리즘에 의해 생성하고(S1120), 상기 아바타를 메타버스 상에 제공하고(S1130), 상기 아바타를 이용한 메타버스 게임 등을 진행한다(S1140). 이와 같이, 상기 서버는 사용자로부터 사용자 정보를 획득한다(S1110). 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유형에 따른 항목별 점수 등 포함) 등을 포함하나, 이에 한정되는 것은 아니다. 상기 서버는 획득된 사용자 정보 를 기초로 가상의 아바타 및 아이템을 생성 혹은 출력한다(S1120). 상기 서버는 아바타를 메타버스 상에 제공하고(S1130), 아바타를 이용해 각종 게임을 진행한다(S1140). 본 발명의 실시 예에 따른 GAN은 동영상, 포즈, 움직임의 특성에 대한 정보를 특징 내에 표현하기 위해, 포인트 와 포인트의 연결에 있어서, 관절의 특성(예를 들어 안으로만 접힐 수 있음), 각도, 거리, 랜드마크 포인트 (land mark point) 등을 추가로 표현한다. 메타 정보는 비지도(unsupervised) GAN의 트레이닝에 있어, 지도(supervised) 라벨의 보완 정보로 사용되며, 조 건(Conditional) 정보로 사용된다. 해당 메타 정보는 각종 시각적 트레이닝 시, 유사 정도를 GAN이 기억하게 되고, 향후 특정 속성 정보가 바뀔 때, 시각정보가 그에 맞추어 가변적으로 인위적 개입을 함에 있어 도움을 주는 입력값 정보로 활용된다. 본 발 명의 일 실시예에서, 근육량 수치를 늘리거나, 연령을 낮추는 경우 생성된 가상의 아바타의 모양은 해당 값에 따라 달라지게 될 수 있는 것이다. 본 발명의 실시예에 따라, 서버는 조건부(Conditional) GAN의 조건(Condition) 메타 정보를 수정하여, 아 바타의 날씬해지기, 근육맨 등 체형특성정보를 수정한다. 서버는 다양한 게임에서 메타정보의 수정이 가능 하다. 이를 통해, 미리 학습된 객체에 대한 특성을 트레이닝 특징으로 활용한다. 자동차의 바퀴는 돌아갈 수 있고, 집 의 현관문은 열리고, 손과 발은 몸에서 떨어질 수 없고 안쪽으로 굽어질 수 있으며, 모자는 머리에서 떨어질 수 있고, 씌워질 수 있다. 본 발명의 일 실시예에서, 비히클(VEHICLE) VR 시뮬레이터는 다음과 같다. 다양한 형태의 비히클로 변경 설정이 가능한 VR 시뮬레이터가 제작되거나 다양한 형태의 VR 시뮬레이터가 제작되어야 한다.(VEHICLE 예시 : 잠수함, 탱크, 드론, 전투기 등) 아바타(또는 인간)가 비히클형 VR 시뮬레이터의 조종장치를 이용하여 운전하는 방식을 데이터화하여 아바타를 생성할 수 있다. 본 발명의 일 실시예에서, VR 트레드밀은 다음과 같다. VR 트레드밀을 이용한 아바타 컨트롤 시스템(HEAD MOUNTED DISPLAY 착용)은 다음과 같은 기술이 필요하다. VR 트레드밀에 탑승한 상황에서의 사용자의 행동 정보 가 가상환경에 정합되도록 하는 동기화 시스템(사용자와 아바타의 이동, 행동, 무한 보행, 회전 등의 정합 알고리즘)이 필요하다, 시각세트장치가 연결된 단말의 사용자 인터페이스에서 사용자는 MBTI 선택라벨링 및 레벨 선택 라벨링(레벨선택, 210)을 하고, 라벨링된 시각데이터는 생성 알고리즘에서 아바타와 아이템의 생성에 사용된다. 생성 알고리즘은 아바타의 동작을 생성하기 위해 시각데이터를 시뮬레이션 엔진에 전달한 다. 시각데이터는 시뮬레이션 엔진 및 그래픽스 엔진 및 디스플레이 장치 및 제어알고리즘(20 9)의 순서대로 전달되어 사용자 인터페이스를 통해 생성된다. 애플리케이션 화면(또는 앱 실행 결과 화 면)은 사용자 인터페이스가 단말에서 화면으로 구현된 것이다. 본 발명의 일 실시예에서, 서버에 시각세트장치가 직접 연결되고, 단말에 시각세트장치가 간접적으로 연결될 수 있다. 본 발명의 일 실시예에서, 동영상정보의 출력 및 정지영상정보의 출력을 확인하고, 아바타와 아이템의 레벨을 선택하는 방식을 레벨 선택 라벨링 즉, 레벨선택이라고 정의한다. 레벨 선택은 MBTI 선택라벨링과 유 사한 객체인식 방법과 라벨링 방식을 사용한다. 레벨선택은 하이브리드된 지도학습과 비지도학습의 집단지성화 를 이용하는 방식이다. 또한, 상기 서버는 상기 단말 및 상기 결제 서버와 연동하여, 해당 서버에서 제공하는 메타버스 내의 상점에서 MBTI 점수 구매를 통해 해당 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강 화 기능을 수행한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 상점 메뉴가 선택되는 경우, 상기 서버 는 상기 생성된 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강화를 위해서, 상기 선택 된 상점 메뉴에 대응하는 상점 화면을 상기 단말에 제공한다. 여기서, 상기 상점 화면은 해당 단말의 사용자와 관련해서 생성된 하나 이상의 아바타에 대한 정보(또는 목록)를 제공하기 위한 보유 아바타 리스트 항 목, 해당 아바타와 관련한 하나 이상의 아이템에 대한 정보(또는 목록)를 제공하기 위한 보유 아이템 리스트 항 목, 아바타나 아이템에 대한 레벨을 강화하기 위한 레벨 강화 항목 등을 포함한다. 또한, 상기 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에 포함된 하나 이상의 아바타 중에 서 특정 아바타가 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 서 버는 상기 단말 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련해서 상기 선택된 레 벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아바타의 레벨을 기준으 로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계 별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된 9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 해당 특정 아바타의 레벨 업 전/후의 레벨 상태 를 확인할 수 있도록, 해당 특정 아바타에 대해서 레벨 업 전/후의 레벨 상태를 상기 단말에 제공한다. 즉, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 하나 이상의 로우 데이터(또는 기초영상), 해 당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 결제 기능에 대응하는 아바타 레벨 강화에 대한 정보(또는 아바타 레벨 강화 라벨링에 대한 정보) 등을 상기 미 리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아바타)을 강 화(또는 업그레이드/업데이트)한다. 이때, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 라스트 레벨 영상, 결제 기능에 대 응하는 아바타 레벨 강화에 대한 정보(또는 아바타 레벨 강화 라벨링에 대한 정보) 등을 상기 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아바타)을 강화할 수도 있다. 또한, 상기 단말에 표시되는 보유 아이템 리스트 항목에 포함된 하나 이상의 아이템 중에서 특정 아이템이 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 서버는 상기 단 말 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련한 특정 아이템과 관련해서 상기 선택 된 레벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말 의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아이템의 레벨을 기준으로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된 9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 특정 아이템의 레벨 업 전/후의 레벨 상태를 확 인할 수 있도록, 해당 특정 아이템에 대해서 레벨 업 전/후의 레벨 상태를 상기 단말에 제공한다. 즉, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 하나 이상의 로우 데이터(또는 기초영상), 해 당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 결제 기능에 대응하는 아이템 레벨 강화에 대한 정보(또는 아이템 레벨 강화 라벨링에 대한 정보) 등을 상기 미 리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아이템)을 강 화(또는 업그레이드/업데이트)한다. 이때, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 라스트 레벨 영상, 결제 기능에 대 응하는 아이템 레벨 강화에 대한 정보(또는 아이템 레벨 강화 라벨링에 대한 정보) 등을 상기 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아이템)을 강화할 수도 있다. 또한, 상기 서버는 해당 단말의 사용자와 관련한 MBTI 점수(또는 해당 사용자의 계정에 보유 중인 MBTI 점수)에 따라, 게임 상대 추천 기능, NFT 상품(또는 NFT 아이템) 추천 기능 등을 상기 단말에 제공한 다. 이에 따라, 상기 단말은 상기 서버로부터 추천되는 게임 상태와 게임 기능을 수행하거나 또는, 해당 서버로부터 추천되는 NFT 상품에 대한 구매 기능을 수행한다. 또한, 상기 서버는 복수의 단말과 연동하여, 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방 에 입장하는 복수의 단말을 대상으로 게임 시작 시, MBTI 점수 체계를 제정(또는 결정/설정)한다. 이때, 상기 MBTI 점수 체계는 해당 게임룸(또는 개설된 게임방)에 대응하는 게임과 관련해서 경쟁 게임을 진행하고 승 패를 결정짓는 구성 요소로, 해당 게임과 관련한 헌법, 법률, 규칙 등을 포함하며, 아바타의 MBTI 유형 및/또는 아이템의 MBTI 유형에 따른 상극과 상생의 법칙으로 승부를 결정짓는 방식일 수 있다. 여기서, 상기 게임과 관 련한 헌법은 상극과 상생의 점수 비교 방식을 결정하는 것이고, 상기 게임과 관련한 법률은 해당 헌법의 내용을 구체화한 것이고, 상기 게임과 관련한 규칙은 상극의 점수가 높은 쪽이 경쟁에서 유리한 것, 상생의 점수의 유 사도가 높을수록 콤비 플레이의 성공률이 높아지는 것 등과 같이 구체적으로 수치화된 내용(또는 조건)을 포함 한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 게임 대기실 메뉴가 선택되는 경우, 상기 서버는 게임 참여를 위해 개설된 게임방 목록을 제공하거나 새로운 게임방을 개설하기 위해서, 상기 선택 된 게임 대기실 메뉴에 대응하는 게임 대기실 화면을 상기 단말에 제공한다. 여기서, 상기 게임 대기실화 면은 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게임방 리스트 항목, 새로운 게임방을 개설하기 위 한 게임방 생성 항목 등을 포함한다. 또한, 상기 단말에 표시되는 게임 대기실화면 내의 게임방 리스트 항목에 포함된 하나 이상의 게임 대기방 중에서 어느 하나의 게임 대기방이 선택되는 경우, 상기 서버는 상기 선택된 게임 대기방에 대응하는 게임 룸에 상기 단말(또는 해당 단말과 관련한 계정/아바타)을 입장(또는 참여)시킨다. 또한, 상기 단말에서 참여한 게임룸을 개설한 방장에 의해 미리 설정된 게임 시작 메뉴가 선택되는 경우 (또는 해당 게임룸과 관련해서 미리 설정된 게임 시작 조건을 만족하는 경우), 상기 서버는 해당 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 해당 게임을 관전 중이거나 미리 설정된 게임상의 국 가기관/회사/상점에 소속된 사용자가 소지한 다른 복수의 단말, 해당 게임과 유사한 게임에 참여했던 다른 사용자가 소지한 또 다른 복수의 단말 등과 연동하여, 해당 게임(또는 해당 게임룸)과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 게임 시작 조건은 미리 설정된 게임 참가자 수를 만족하는 경우, 미리 설정된 게임 시작 시각을 만족하는 경우 등을 포함한다. 이때, 상기 서버는 미리 설정된 조건(예를 들어 게임 시작 후 미리 설정된 시간(일 예로 5분, 10분 등 포함)이 지난 경우, 미리 설정된 참여자(일 예로 10 명) 이상이 MBTI 점수 체계 제정에 참여한 경우 등 포함)을 만족할 때까지 해당 게임과 관련한 MBTI 점수 체계 를 제정한다. 여기서, 상기 미리 설정된 조건을 충족할 때까지 상기 게임과 관련한 MBTI 점수 체계가 제정되지않은 경우, 상기 서버는 해당 게임과 관련해서 미리 설정된 디폴트값으로 해당 MBTI 점수 체계를 제정(또 는 설정)할 수도 있다. 이와 같이, 상기 서버는 상기 복수의 단말과 연동하여, 개설된 게임룸과 관련한 게임의 승패를 결정 하기 위한 MBTI 점수 체계를 제정할 수 있다. 또한, 상기 서버는 상기 단말과 연동하여, 해당 단말의 사용자와 관련한 아바타 및/또는 아이템 과, 해당 게임에 참여한 다른 게임 참가자와 관련한 아바타 및/또는 아이템을 참조하여, 게임 참가자별 MBTI 선 택라벨링(또는 복수의 단말의 게임 참가자/사용자와 관련한 아바타 및/또는 아이템별 MBTI 선택라벨링) 기 능을 수행한다. 여기서, 상기 MBTI 선택라벨링(또는 MBTI 선택레이블링)은 해당 게임에 참여한 모든 사용자와 관련한 아바타 또는 아이템에 대해서 해당 단말의 사용자가 생각하는 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 설정하는(또는 붙이는) 라벨링 방법을 나타낸다. 이때, 상기 MBTI 유형에 따른 항목별 점수는 미 리 설정된 범위(예를 들어 0점 ~ 100점) 중에서 선택될 수 있다. 또한, 상기 서버는 해당 게임룸에 참여한 복수의 단말을 대상으로 상기 MBTI 선택라벨링 기능 수행에 따른 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 수집한다. 또한, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가 자별 MBTI 선택라벨링에 대한 정보(또는 복수의 단말의 게임 참가자/사용자와 관련한 아바타 및/또는 아이 템별 MBTI 선택라벨링에 대한 정보), 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 입력값으로 하여 다른 기계 학습(또는 다른 인공지능/다른 딥 러닝)을 수행하고, 다른 기 계 학습 결과(또는 다른 인공지능 결과/다른 딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 즉, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자 별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 미리 설정된 승패 결정 모델의 입력값으로 하여 다른 기계 학습(또는 다른 인공지능/다른 딥 러 닝)을 수행하고, 다른 기계 학습 결과(또는 다른 인공지능 결과/다른 딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 여기서, 상기 승패 결정 모델(또는 MBTI 점수체계 예측 모델/게임 목적 달성 모델)은 통계적 모델, 회귀 모델, 딥러닝 모델 등을 포함한다. 이때, 상기 서버는 상기 승패 결정 모델에 따라 게임의 승 패를 결정하는 과정과 관련한 화면(또는 사용자 인터페이스)을 해당 게임에 참여한 복수의 단말에 각각 제 공할 수도 있다. 또한, 상기 승패 결정 모델은 아이템 및/또는 실제 현실의 상품(디지털트윈) 및/또는 게임 상대자를 추천하는 모델을 포함하며, 해당 승패 결정 모델에 의한 게임 결과는 아이템, 상품 정보, 게임 상대자를 추천하는 정보 등을 포함한다. 또한, 게임의 종류가 경쟁게임이 아닌 경우에는, 승패 결정 모델은 게임의 목적의 성공, 실패를 예측하는 모델 일 수 있다. 추천과 게임의 목적 달성, 승패 결정 모델에 있어서, 상기 서버는 실제 MBTI 선호도 점수를 기초로 하여, 사용자 입력에 따라 MBTI 선택라벨링을 수행할 수 있다. 이와 같이, 상기 서버는 상기 승패 결정 모델의 출력값인 전체 게임 참가자의 아바타 및 아이템별 MBTI 라 벨별 점수를 예측하고, 상기 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정한다. 이때, 게임의 승패가 없는 경우에는, 상기 서버 는 해당 게임의 목적을 달성한 상태로 해당 게임을 종료한다. 즉, 상기 서버는 집단 지성화를 통해 상기 수집된 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 근거로 게임 참가자별 아바타 및 아이템에 대한 MBTI 유형 및 MBTI 유형에 따른 항목별 점수를 설정(또 는 산출)한다. 이때, 상기 서버는 집단 지성을 통해 특정 아바타/특정 아이템에 대해서 서로 대응하는 MBTI 항목이 존재 하는 경우, 해당 MBTI 항목 중에서 항목별 점수가 더 높은 항목을 해당 특정 아바타/특정 아이템의 주요 MBTI 유형 항목으로 설정한다. 예를 들어, 상기 단말의 제 1 아바타와 관련해서 해당 단말의 사용자의 MBTI 선택라벨링에 따른 MBTI 유형이 ESFJ이고, 해당 MBTI 유형에 따른 항목별 점수가 E: 90점, S: 75점, F: 80점, J: 85점이고, 다른 단말 의 사용자가 해당 단말의 제 1 아바타와 관련해서 MBTI 선택라벨링을 수행한 MBTI 유형이 ESFP이고해당 MBTI 유형에 따른 항목별 점수가 E: 85점, S: 80점, F: 85점, P: 80점인 상태에서, 해당 단말의 사 용자 및 해당 다른 단말의 사용자의 MBTI 선택라빌렝에 따라, 제 1 아바타의 J 항목과 P 항목이 서로 대응 하고, 해당 제 1 아바타의 J 항목의 점수가 85점이고 해당 제 1 아바타의 P 항목의 점수가 80점인 경우, 상기 서버는 동일한 항목(예를 들어 E 항목, S 항목 및 F 항목)은 그대로 유지하고, 대응하는 항목 중에서는 상 기 J 항목을 선택하여, 해당 제 1 아바타에 대한 MBTI 유형을 ESFJ로 관리한다. 또한, 상기 서버는 집단 지성을 통해 특정 아바타/특정 아이템에 대해서 서로 동일한 MBTI 항목이 존재하 는 경우, 해당 MBTI 항목에 대응하는 항목별 점수의 평균을 해당 특정 아바타/특정 아이템의 MBTI 항목의 점수 로 설정한다. 예를 들어, 상기 제 1 사용자가 선택한 제 1 아바타의 E 항목의 점수가 90점이고, 상기 제 2 사용자가 선택한 제 1 아바타의 E 항목의 점수가 85점인 경우, 상기 서버는 해당 제 1 아바타의 E 항목에 대해서 90점과 85 점의 평균인 87.5점을 해당 제 1 아바타의 E 항목의 점수로 설정한다. 이때, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가 자별 MBTI 선택라벨링에 대한 정보 등을 근거로 인공지능 기반의 기계 학습을 수행하여, 기계 학습 결과를 근거 로 해당 게임 참가자별 MBTI 선택라벨링에 대한 정보의 분류값을 생성한다. 여기서, 상기 게임 참가자별 MBTI 선택라벨링에 대한 정보의 분류값(또는 해당 게임 참가자별 MBTI 선택라벨링의 분류값)은 해당 게임에서의 승패 를 결정하기 위한 MBTI 유형 및 MBTI 유형의 항목별 점수 등을 동일 항목별로 분류한 값일 수 있다. 즉, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자 별 MBTI 선택라벨링에 대한 정보 등을 상기 미리 설정된 분류 모델의 입력값으로 하여 기계 학습(또는 인공지능 /딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자별 MBTI 선택라벨링에 대한 정보에 대한 분류값을 생성(또는 확인)한다. 또한, 상기 서버는 상기 생성된 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련 한 게임 참가자별 MBTI 선택라벨링에 대한 정보에 대한 분류값(또는 해당 게임 참가자별 MBTI 선택라벨링의 분 류값), 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자별 MBTI 선택라 벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 즉, 상기 서버는 상기 생성된 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자별 MBTI 선택라벨링에 대한 정보에 대한 분류값(또는 해당 게임 참가자별 MBTI 선택라벨링의 분류값), 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자별 MBTI 선택 라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등 을 상기 미리 설정된 승패 결정 모델의 입력값으로 하여 다른 기계 학습(또는 다른 인공지능/다른 딥 러닝)을 수행하고, 다른 기계 학습 결과(또는 다른 인공지능 결과/다른 딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 또한, 상기 서버는 상기 게임 결과(또는 해당 게임 결과에 대한 정보)를 해당 게임에 참여한 복수의 단말 에 각각 전송한다. 여기서, 상기 게임 결과는 해당 게임 참가자에 대한 승/패 결과뿐만 아니라, 아이템 및 /또는 실제 현실의 상품(디지털트윈), 게임 상대자 등을 추천하는 결과, 게임의 종류가 경쟁게임이 아닌 경우에 는 게임의 목적의 성공/실패를 예측한 결과 등을 포함할 수 있다. 또한, 상기 서버는 해당 게임에서의 승패 결과에 따라, 게임 참가자별 아바타 및/또는 아이템의 레벨 유지 /업/다운 기능을 수행한다. 즉, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 라스트 레벨 영상 에 포함된 아바타 및/또는 아이템의 레벨을 유지/업/다운한다. 또한, 상기 서버는 상기 게임 결과를 근거로 MBTI 점수를 해당 게임 참가자의 해당 아바타(또는 해당 게임 참가자의 계정)에 적립(또는 제공)한다. 상기 서버는 수신된 상기 MBTI 라벨링 정보(또는 게임 참가자별 MBTI 선택라벨링에 대한 정보)를 이용하여 회귀모델 혹은 통계적 모델 혹은 딥러닝 인공지능 방식으로 경쟁게임의 승패를 결정하는 아바타와 아이템의MBTI 점수 체계(헌법, 법률 규칙)를 사용자에게 추천하고 아바타 및 아이템의 트레이닝 레벨별 필요한 MBTI 점 수 체계를 정한다. 본 발명의 일 실시예에서, 분류모델 및/또는 MBTI 점수체계 예측모델(또는 승패 결정 모델/MBTI 점수체계 예측 모델)은 메타버스 국가의 MBTI 점수체계이고 헌법, 법률, 규칙 등이다. 메타버스 의제선정과 메타버스 선거로 분류모델 및 예측모델의 형태가 결정된다. MBTI 점수체계 예측모델은 MBTI 점수체계에 근거하여 아바타 및 아이 템에 입력될 각 라벨별 점수를 예측하는 모델이다. 본 발명의 일 실시예에서, Last Level 영상정보 및 제1 기초 영상정보(또는 로우 데이터)의 각 라벨 별 MBTI 점수는 제1 MBTI 선택라벨링에 의해 라벨링 및 점수가 입력되고 제1 분류모델에 의해 분류 된다. 제1 MBTI 점수체계 예측모델에 의해 각 라벨별 MBTI 점수를 Last Level 영상정보에 매핑한다. 또한, Last Level 영상정보 및 제2 기초 영상정보의 각 라벨별 MBTI 점수는 제2 MBTI 선택라벨링 에 의해 라벨링 및 점수가 입력되고 제2 분류모델에 의해 분류된다. 제2 MBTI 점수체계 예측모델 에 의해 각 라벨별 MBTI 점수를 Last Level + 1 영상정보에 매핑한다. 본 발명의 일 실시예에서, 제1 생성 알고리즘은 다음 과정을 포함한다. 제1 계층적 군집에 속한 아 바타와 아이템에 대해 제1 MBTI 선택라벨링을 하여 분류된 MBTI 각 라벨 및 점수정보를 제1 분류모델 을 통해 분류하고 제1 MBTI 점수체계 예측모델을 통해 예측한 다음, Last Level 영상정보에 메 타정보로 매핑한다. 또한, 제2 생성알고리즘은 다음 과정을 포함한다. 제2 계층적 군집에 속한 아바타와 아이템에 대해 제2 MBTI 선택라벨링을 하여 분류된 MBTI 각 라벨 및 점수 정보를 제2 분류모델을 통해 분류하고 제2 MBTI 점수체계 예측모델을 통해 예측한 다음, Last Level + 1 영상정보에 메타정보로 매핑한다. 본 발명의 일 실시예로, MBTI 점수체계 예측모델에 의한 각 MBTI 라벨별 점수와 상생과 상극의 라벨별 점수로 메타버스 국가의 게임의 승패를 결정한다. 본 발명의 일 실시예에서, 다음은 MBTI 점수체계의 예시이다. 통계적 모델에서는 실제 MBTI별 사용자들 간의 통 계적 승률 데이터를 활용, 각 조합과 상대 조합의 승률에 따라, 조합의 플레이(PLAY)에 가중치를 주는 방식이다. 이 경우는 미세하게 드러나는 통계적 승률 차이가 의도적 가중치에 의해 강화되는 경향성을 갖게 되 며, 이는 게임 내에서 팀원 선택 및 복수의 선수 기용패턴에 게임성을 갖게 하는 특징으로 발현될 수 있다. 회 귀모델에서는 유의미한 통계적 수치가 존재하지 않은 경우 다른 요소 입력값 혹은 MBTI 요소 개별조합을 통해 위 가중치 값을 예측해내는 의미부여가 가능하다. 메타버스 월드 내에서는 구단, 도시, 국가, 감독뿐 아니라, 선수, 실 게임 플레이어 등 다양한 조합이 존재하고, 게임 외에도 다양한 사회활동이 존재하고 그 모든 것이 유 의미한 통계값을 확보하는 것은 불가능에 가까울 수 있다. 이러한 부분은 회귀커버되어야 하는 부분이라 할 수 있다. 딥러닝 인공지능 방식은 사용자의 딥러닝 인공지능 방식은 사용자의 집단지성을 게임의 퀄리티에 연결하 는 역할을 한다. 통계적 모델 및 회귀모델은 상황에 따라 별도의 서로 다른 가중치가 적용되거나 특정 모델로 취사 선택될 필요가 있다. 기타, 상황에 따라 사용자가 더 재미있는 몰입감을 갖도록 진화하려면 사용자가 플레 이하면서 머문시간, 좋아요 선호도를 표시한 개수 및 기타 피드백을 통해 강화학습 등을 이용하여 최적화가 진 행되고, 고도화되도록 설계할 필요가 있다. 이 부분이 딥러닝 인공지능 방식의 실시예라 할 수 있으며, 강화학 습 외에도 다양한 딥러닝 방식이 이 부분에 활용되어 질 수 있다. 또한, 상기 승패 결정 모델은 도 4의 생성알고리즘을 통한 아이템 및/또는 실제 현실의 상품(디지털트윈) 을 추천하는 모델, MBTI 선호도 점수를 기초로 실제 현실의 상품을 추천하는 모델, 게임 상대자를 추천하는 모 델 등을 포함한다. 또한, 게임의 종류가 경쟁게임이 아닌 경우에는, 승패 결정 모델은 게임의 목적에 대해서 성공 또는 실패 여부 를 예측하는 모델일 수 있다. 추천과 게임의 목적 달성, 승패 결정 모델에 있어서, 상기 서버는 실제 현실의 MBTI 선호도 점수를 기초로 하여, 사용자 입력에 따라 MBTI 선택라벨링을 수행할 수 있다. 제1 계층적 군집의 Last Level 영상정보 및 제2 기초 영상정보가 단일모델로 학습되고, 각 군 집별로 Last Level + 1 영상정보가 생성된다. 로우 데이터인 제2 기초 영상정보와 제1기초 영상정보의 라벨링 데이터인 Last Level 영상정보 가 동일 모델(단일모델)로 학습된다.모델 관점에서 제2 기초 영상정보와 제1 생성알고리즘의 예측값인 Last Level 영상정보는 정확도나 정교함의 장단점이 서로 상이할 수 있는데, 제2 생성 알고리즘의 학습 데이터로 사용된다. 1차 레벨 선택에 의해 제1 생성알고리즘이 Last Level 영상정보를 생성하고, 2차 레벨 선택(레벨선택 라벨링, 210)에 의해 제2 생성알고리즘이 Last Level + 1 영상정보를 생성한다. 이 과정을 과거 라벨 된 데이터(Last Level 영상정보, 303)와 다른 데이터(제2 기초 영상정보, 305)가 함께 반복 수행하게 되며, 한 번 학습했던 데이터 및/또는 유사한 레이블 값 또한 매 반복 학습(epoch)에 계속 등장하여, 여러 번의 실험을 거치는 과정이 필요하다. 매 에포크(epoch)는 누적된 단위 레이블의 총 개수(batch size)만큼을 학습 연산 단위 (mini batch size)로 분할하여 다양한 실험을 하게 되며 해당 과정에서 집단지성의 라벨값은, 취사 선택 및 평 균화 되어 모델에 반영된다. 또한, 상기 서버는 블록체인 서버(미도시)와 연동하여, 상기 단말에서 제공한 로우 데이터, 비교 대 상 영상 등을 근거로 생성되는 라스트 레벨 영상 등을 대상으로 NFT(non-fungible token: 대체 불가 토큰)를 발 행(또는 발급)한다. 상기 서버에 의해 발행되는 NFT(또는 NFT 콘텐츠)는 상기 로우 데이터, 상기 비교 대상 영상을 제공한 소 유권이 있는 소유자가 소지한 임의의 디지털 아트와 관련되며, 해당 디지털 아트(예를 들어 상기 라스트 레벨 영상 등 포함)에 대응하여 생성된 콘텐츠(또는 MR 콘텐츠/실감 콘텐츠)이며, 원본 디지털 자산에 디지털 파일을 가리키는 주소, 고유 식별 코드(예를 들어 자산 정보, 작성자, 소유자 등에 대한 정보 포함) 등이 토큰에 삽입 된 상태일 수 있다. 또한, 상기 서버는 상기 발행된 NFT와 관련해서, 상기 라스트 레벨 영상 등이 표시되는 상기 단말의 화면의 일측에 마커가 함께 표시되도록 구성한다. 또한, 상기 라스트 레벨 영상 등의 일측에 표시되는 마커가 상기 단말의 사용자 터치에 따라 선택되는 경 우, 상기 서버는 상기 선택된 마커에 대응하는 NFT를 확인하고, 상기 확인된 NFT에 대한 정보(예를 들어 자산 정보, 작성자, 소유자 등에 대한 정보 등 포함)를 상기 단말의 화면 일측에(또는 상기 라스트 레벨 영상 등이 표시되는 화면에 팝업 형태로) 표시되도록 구성할 수 있다. 이때, 상기 단말은 상기 확인된 NFT 에 대한 정보를 가상현실, 증강현실, 혼합현실, 확장현실 등의 형태로 표시할 수도 있다. 또한, 상기 서버는 상기 발행된 상기 라스트 레벨 영상 등과 관련한 NFT에 대해서 거래 기능(또는 판매 기 능/소유권 이전 기능) 등을 제공한다. 즉, 상기 영상정보(예를 들어 상기 라스트 레벨 영상 등 포함)는 NFT가 부여된 영상정보이고 상기 NFT가 부여된 영상정보 플랫폼 제공 시스템은 사용자 및 참여자 및 기업들이 이익을 창출하고 돈을 벌면서 재미요소를 배가하 는 원순환 구조(flywheel)이다. 상기 도 2를 참조하면, 생성 알고리즘을 이용한 가상 아바타 생성 및/또는 출력 플랫폼 제공 시스템은 사 용자(user), 참여자(인플루언서 또는 SNS에 자신의 캐릭터를 홍보하는 개개인), 기업(광고주 및/또는 제조 사)들이 서로서로 이익을 창출하고 돈을 벌면서 재미요소를 배가하는 플랫폼으로서의 원순환 구조(flywheel)이 다. 생성 알고리즘은 도 1의 서버에서 작동한다. 생성 알고리즘은 인플루언서로부터 제공받은 기초 영상정보(또는 로우 데이터)를 활용하여, 마케팅 플랫폼에 NFT 아바타 및 아이템을 생성하거나 출력한다. 기업 및 투자자는 인플루언서의 프로필(예를 들어 동영상, 사진 등 포함) NFT 및 상품 NFT를 소 유할 수 있고, 마케팅 및/또는 기업 홍보에 활용한다. 프로필(예를 들어 동영상, 사진 등 포함)은 생성된 아바 타이고, 상품은 아이템이다. 메타버스 상에서 NFT는 아바타와 아이템을 현실세계의 소유자, 생성자, 광고주, 실물상품 등과의 디지털 트윈 (digital twin)을 위한 매개로 연결된다. 또한, 참여자에게는 홍보비를 제공하고, 사용자에게는 아바타 및 아이템에 대한 NFT를 발급함으로써 유일성이 부여되어 가치가 측정되고, 가치에 따른 비용이 환급됨으로써 이익을 창출한다. 상기 서버는 사람 몸을 별도 객체화하고, 성별, 나이, 체형, 동양인 등 정보를 메타 정보와 연결한다. 이 때, 각 아바타 ID는 유저ID 및 NFT ID와 연결된다. 위와 같이, 다양한 현실의 가치 및 재화 정보는 메타 데이터 형태로 포함되어 NFT화될 수 있으며, 이는 아이템 NFT 형태로 유일성이 보장되면서 매매 및 거래가 될 수 있다. 플랫폼은 해당 NFT 소유가 현실의 가치 이용의 사 용권이 될 수 있도록 보장하며, 서비스의 사용 내역 및 단계는 플랫폼 데이터베이스와 연동되어, NFT 메타정보 가 갱신되고 참조된다. 도 4를 참조하면, 도 1의 서버는 실제 판매되는 제품을 메타버스 내 아이템으로 생성할 수 있고, 현실에서 실제 제품을 구매할 수 있도록 인스트럭션을 제공할 수 있다. 본 발명의 서비스를 이용하는 인플루언서는 본인의 아바타나 본 발명의 서비스를 본인의 네트워크상의 SNS 에 홍보할 수 있고, 서버는 네트워크상의 SNS 채널에 업로드된 홍보 관련 콘텐츠를 획득할 수 있다. 서버 는 네트워크상의 SNS 채널을 통해 유입된 사용자를 분석할 수 있고, 분석된 결과를 기초로 네트워크상의 SNS에게 제공할 홍보비용을 정산할 수 있다. 서버는 각 인플루언서별로 상이한 링크를 생성하여 제공 할 수 있고, 해당 링크를 통해 유입되는 사용자에 대한 보상을 인플루언서에게 제공할 수 있다. 또한, 사 용자의 가입 여부, 아이템 구매 금액 등을 분석하여 인플루언서에게 추가 보상을 제공할 수도 있다. 본 발명의 일 실시예에서, 인플루언서는 연예인, 배우, 운동선수 등을 포함한다. 본 발명의 일 실시예에서, 메타버스 내의 땅이나 바다를 포함하는 각각의 영역에도 NFT가 부여되어, 부동산 등 기부와 같은 역할을 수행하도록 한다. 사용자들은 NFT를 이용하여 각각의 영역을 거래한다. 본 발명의 일 실시예에서, 메타버스 병원게임에서 각 객체는 무늬, 색, 재질, 디자인 등의 복합 요소로 구성될 수 있고, 서버는 재료ID, 장비ID, 의사ID, 환자ID, 병원ID 등과 메타 정보를 연동하고 NFT화한다. 또한, 서버는 모자, 액세서리, 의상을 별도 객체화하고, 각 객체는 사용자, 생성자, 유일성ID 또는 대표객 체ID의 메타 정보와 연결한다. 이때, 각 아이템 ID는 NFT ID와 연결될 수 있다. 또한, 서버는 액세서리 등 사용자가 구매한 아이템에 NFT를 부여하고, 이에 기반한 거래가 메타버스 내에 서 가능하도록 구성한다. 본 발명의 일 실시예에서, 서버는 구매 완료된 아이템이 합성된 아바타에 NFT를 발급한다. 사용자는 해당 아바타에 대한 NFT를 발급받을 수 있으며, 이를 판매하여 수익을 얻는 것이 가능하다. 즉, 본 발명의 실시 예에 따르면, 생성 알고리즘을 통해 아바타에게 다양한 조합의 아이템을 코디네이션 하면서, 재미요소를 제공하고, 합성이 완료된 아바타에 대해 NFT를 발급함으로써, 유일성을 제공하며, 이를 통 한 수익을 얻을 수도 있다. 또한, 서버는 액세서리 등 사용자가 구매한 아이템에 NFT를 부여하고, 이에 기 반한 거래가 메타버스 내에서 가능하도록 구성한다. 또한, 상기 서버는 상기 단말 및 외부 서버(미도시)와 연동하여, 해당 라스트 레벨 영상(예를 들어 아바타, 아이템 등 포함)을 이용한, 문자메시지 송/수신 기능, 게시물 작성 기능, 이모티콘/아이콘 제작 및 사 용 기능, 채팅 기능, 해당 외부 서버에서 제공하는 게임 내 아바타(또는 아이템)에 적용(또는 반영/연동)하는 기능 등을 수행(또는 적용)한다. 여기서, 상기 외부 서버는 문자메시지 송/수신 기능을 제공하는 통신사 서버, 게시물 작성 기능 등을 제공하는 SNS 서버, 이모티콘/아이콘 제작 및 사용 기능을 제공하는 포털 서버, 채팅 기 능을 제공하는 채팅 서버, 게임을 제공하는 게임사 서버 등을 포함한다. 또한, 상기 서버는 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 사용자 정보, 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 해당 사용자 정보(또는 상기 사용자 정보에 포함된 해당 사용자와 관련한 MBTI 정보/해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수)를 상기 수신된 해당 로우 데이터에 적용(또는 반영/매핑/매칭)한다. 또한, 상기 서버는 상기 단말과 연동하여, 해당 사용자 정보(또는 해당 사용자와 관련한 MBTI 정보/ 해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수)가 적용된 로우 데이터를 이용해서, 미리 설정 된 기능을 수행한다. 여기서, 상기 미리 설정된 기능(또는 미리 설정된 이벤트)은, 해당 사용자의 MBTI 유형 맞 춤형 미팅 기능, 해당 사용자의 MBTI 유형 맞춤형 채팅 기능, 해당 사용자의 MBTI 유형 맞춤형 상품 추천 기능, 해당 사용자의 MBTI 유형 맞춤형 게임 상대 추천 기능 등을 포함한다. 즉, 상기 서버는 해당 단말에서 상기 미리 설정된 기능을 시작하는 경우, 해당 서버에 미리 등 록된 복수의 사용자 정보가 적용된 복수의 로우 데이터 중에서, 해당 사용자 정보가 적용된 로우 데이터를 이용 해서 해당 사용자 정보에 포함된 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 근거로 미리 설정된 상생관계 및/또는 상극 관계에 따른 한 명 이상의 사용자(또는 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터), 하나 이상의 상품 정보 등을 확인(또는 선정)한다. 또한, 상기 서버는 상기 확인된(또는 선정된) 한 명 이상의 사용자에 대한 정보(또는 서로 다른 사용자 정 보가 적용된 하나 이상의 다른 로우 데이터에 대한 정보), 하나 이상의 상품 정보 등을 상기 단말에 제공 (또는 전송)한다. 또한, 상기 단말에 표시되는 한 명 이상의 사용자에 대한 정보 중에서 특정 사용자에 대한 정보가 선택되 는 경우, 상기 서버는 상기 단말 및 상기 선택된 특정 사용자에 대한 정보에 대응하는 다른 단말(미 도시)과 연동하여, 미팅 기능, 채팅 기능, 게임 기능(예를 들어 슈팅 게임, 농구 게임, 축구 게임 등 포함) 등 을 수행한다. 여기서, 상기 미팅 기능, 채팅 기능, 게임 기능 등은 상기 사용자 정보가 적용된 로우 데이터를 이용해서 가상현실, 증강현실, 혼합현실, 확장현실, 메타버스, 디지털트윈 등의 형태로 수행(또는 구현/구성)될 수 있다. 이때, 상기 서버는 집단 지성화에 따른 사용자 정보 내의 MBTI 정보를 업데이트하기 위해서, 해 당 단말의 사용자와 관련한 사용자 정보 내의 MBTI 정보에 대해서 상기 게임 결과(또는 미팅/채팅/게임 기 능 수행 결과), 다른 사용자에 의한 라벨선택링 등을 반영하여 해당 사용자 정보 내의 MBTI 레벨, MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 업데이트하고, 업데이트된 사용자 정보를 상기 로우 데이터에 적용(또는 매핑/반영)할 수 있다. 여기서, 상기 MBTI 정보는 해당 사용자의 MBTI 유형, 해당 MBTI 유형에 따른 항목별 점 수 등을 포함한다. 또한, 상기 단말에 표시되는 하나 이상의 상품 정보(또는 해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수에 따라 추천된 하나 이상의 상품 정보) 중에서 특정 상품 정보가 선택되는 경우, 상기 서버 는 상기 단말 및 상기 결제 서버(미도시)와 연동하여, 상기 선택된 특정 상품 정보에 대응하는 결제 금액에 대해 결제 기능을 수행한다. 결제 기능이 정상적으로 수행된 경우, 상기 서버는 결제 기능 수행 결과를 상기 단말에 제공한다. 여 기서, 상기 결제 기능 수행 결과는 상품 정보, 결제 금액, 결제 일자 및 시각 정보 등을 포함한다. 또한, 결제 기능이 실패한 경우, 상기 서버는 결제 실패 정보(예를 들어 결제일자, 결제금액, 실패 정보 (예를 들어 잔액 부족, 한도 초과 등 포함) 등 포함)(또는 결제가 실패한 상태임을 나타내는 정보)를 상기 단말 로 제공한다. 또한, 상기 서버는 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 사용자 정보, 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 해당 사용자 정보(또는 상기 사용자 정보에 포함된 해당 사용자와 관련한 MBTI 정보/해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수)를 상기 수신된 해당 로우 데이터에 적용(또는 반영/매핑/매칭)한다. 또한, 상기 서버는 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말 을 대상으로 게임 시작 시, MBTI 점수 체계를 제정(또는 결정/설정)한다. 이때, 상기 MBTI 점수 체계는 해당 게 임룸(또는 개설된 게임방)에 대응하는 게임과 관련해서 경쟁 게임을 진행하고 승패를 결정짓는 구성 요소로, 해 당 게임과 관련한 헌법, 법률, 규칙 등을 포함하며, 해당 게임에 참여하는 사용자(또는 게임 참가자)와 관련한 게임 캐릭터(또는 아바타/상기 사용자 정보가 적용된 로우 데이터)의 MBTI 유형 및/또는 게임 캐릭터(또는 아바 타/상기 사용자 정보가 적용된 로우 데이터)의 MBTI 유형에 따른 상극과 상생의 법칙으로 승부를 결정짓는 방식 일 수 있다. 여기서, 상기 게임과 관련한 헌법은 상극과 상생의 점수 비교 방식을 결정하는 것이고, 상기 게임 과 관련한 법률은 해당 헌법의 내용을 구체화한 것이고, 상기 게임과 관련한 규칙은 상극의 점수가 높은 쪽이 경쟁에서 유리한 것, 상생의 점수의 유사도가 높을수록 콤비 플레이의 성공률이 높아지는 것 등과 같이 구체적 으로 수치화된 내용(또는 조건)을 포함한다. 또한, 상기 단말에 표시되는 게임 대기실화면 내의 게임방 리스트 항목에 포함된 하나 이상의 게임 대기방 중에서 어느 하나의 게임 대기방이 선택되는 경우, 상기 서버는 상기 선택된 게임 대기방에 대응하는 게임 룸에 상기 단말(또는 해당 단말과 관련한 계정/아바타)을 입장(또는 참여)시킨다. 또한, 상기 단말에서 참여한 게임룸을 개설한 방장에 의해 미리 설정된 게임 시작 메뉴가 선택되는 경우 (또는 해당 게임룸과 관련해서 미리 설정된 게임 시작 조건을 만족하는 경우), 상기 서버는 해당 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 해당 게임을 관전 중이거나 미리 설정된 게임상의 국 가기관/회사/상점에 소속된 사용자가 소지한 다른 복수의 단말, 해당 게임과 유사한 게임에 참여했던 다른사용자가 소지한 또 다른 복수의 단말 등과 연동하여, 해당 게임(또는 해당 게임룸)과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 게임 시작 조건은 미리 설정된 게임 참가자 수를 만족하는 경우, 미리 설정된 게임 시작 시각을 만족하는 경우 등을 포함한다. 이때, 상기 서버는 미리 설정된 조건(예를 들어 게임 시작 후 미리 설정된 시간(일 예로 5분, 10분 등 포함)이 지난 경우, 미리 설정된 참여자(일 예로 10 명) 이상이 MBTI 점수 체계 제정에 참여한 경우 등 포함)을 만족할 때까지 해당 게임과 관련한 MBTI 점수 체계 를 제정한다. 여기서, 상기 미리 설정된 조건을 충족할 때까지 상기 게임과 관련한 MBTI 점수 체계가 제정되지 않은 경우, 상기 서버는 해당 게임과 관련해서 미리 설정된 디폴트값으로 해당 MBTI 점수 체계를 제정(또 는 설정)할 수도 있다. 또한, 상기 서버는 상기 단말과 연동하여, 해당 게임에 참여하는 해당 단말의 사용자(또는 게임 참가자)와 관련한 게임 캐릭터(또는 게임 캐릭터의 MBTI 유형/상기 사용자 정보가 적용된 로우 데이터)와, 해당 게임에 참여한 다른 게임 참가자와 관련한 게임 캐릭터(또는 게임 캐릭터의 MBTI 유형/상기 사용자 정보가 적용 된 로우 데이터)를 참조하여, 게임 참가자별 MBTI 선택라벨링(또는 복수의 단말의 게임 참가자/사용자와 관련한 게임 캐릭터별 MBTI 선택라벨링) 기능을 수행한다. 여기서, 상기 MBTI 선택라벨링(또는 MBTI 선택레이블 링)은 해당 게임에 참여한 모든 사용자와 관련한 게임 캐릭터에 대해서 해당 단말의 사용자가 생각하는 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 설정하는(또는 붙이는) 라벨링 방법을 나타낸다. 이때, 상 기 MBTI 유형에 따른 항목별 점수는 미리 설정된 범위(예를 들어 0점 ~ 100점) 중에서 선택될 수 있다. 또한, 상기 서버는 해당 게임룸에 참여한 복수의 단말을 대상으로 상기 MBTI 선택라벨링 기능 수행에 따른 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 수집한다. 또한, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가 자별 MBTI 선택라벨링에 대한 정보(또는 복수의 단말의 게임 참가자/사용자와 관련한 게임 캐릭터별 MBTI 선택라벨링에 대한 정보), 사용자별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 입 력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결 과)를 근거로 해당 게임에서의 승패를 결정한다. 즉, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자 별 MBTI 선택라벨링에 대한 정보(또는 복수의 단말의 게임 참가자/사용자와 관련한 게임 캐릭터별 MBTI 선 택라벨링에 대한 정보), 사용자별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 미리 설정된 승패 결정 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 여기서, 상기 승패 결정 모델(또는 MBTI 점수체계 예측 모델)은 통계적 모델, 회귀 모델, 딥러닝 모델 등을 포함한다. 이때, 상기 서버는 상 기 승패 결정 모델에 따라 게임의 승패를 결정하는 과정과 관련한 화면(또는 사용자 인터페이스)을 해당 게임에 참여한 복수의 단말에 각각 제공할 수도 있다. 이와 같이, 상기 서버는 상기 승패 결정 모델의 출력값인 전체 게임 참가자의 게임 캐릭터별 MBTI 라벨별 점수를 예측하고, 상기 예측된 전체 게임 참가자의 게임 캐릭터별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상 극의 라벨별 점수를 근거로 게임의 승패를 결정한다. 즉, 상기 서버는 집단 지성화를 통해 상기 수집된 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 근거로 게임 참가자별 게임 캐릭터에 대한 MBTI 유형 및 MBTI 유형에 따른 항목별 점수를 설정(또는 산 출)한다. 또한, 상기 서버는 상기 게임 결과(또는 해당 게임 결과에 대한 정보)를 해당 게임에 참여한 복수의 단말 에 각각 전송한다. 또한, 상기 복수의 단말은 상기 서버로부터 전송되는 해당 게임 결과를 각각 수신하고, 상기 수신된 게임 결과를 출력(또는 표시)한다. 또한, 상기 서버는 해당 게임에서의 승패 결과에 따라, 게임 참가자별 게임 캐릭터의 레벨 유지/업/다운 기능을 수행한다. 즉, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 게임 캐릭터(예를 들어 아바타, 아이템 등 포함)의 레벨을 유지/업/다운한다. 또한, 상기 서버는 상기 게임 결과를 근거로 MBTI 점수를 해당 게임 참가자의 해당 게임 캐릭터(또는 해당 게임 참가자의 계정)에 적립(또는 제공)한다. 또한, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 사용자 정보 내 의 MBTI 유형, MBTI 유형에 따른 항목별 점수 등을 업데이트(또는 업그레이드)한다. 상기 집단 지성을 이용한 정보 처리 시스템은 다른 외부 서버(미도시)를 더 포함할 수 있다. 상기 다른 외부 서버는 네트워크를 통해 서비스 제공 장치인 상기 서버와 연결될 수 있으며, 상기 서버 가 생성 알고리즘을 이용한 가상 아바타의 생성 및/또는 출력 플랫폼 제공 방법을 수행하기 위한 각 종 정보를 저장 및 관리한다. 또한, 상기 다른 외부 서버는 상기 서버가 생성 알고리즘을 이용한 가상 아바타의 생성 및/또는 출력 플랫폼 제공 방법을 수행함에 따라, 생성 및/또는 출력되는 각종 정보 및 데이터를 제공받아 저장한다. 본 발명의 일 실시예에서, 상기 다른 외부 서버는 상기 서버 외부에 별도로 구비되는 저장 서버이다. 이와 같이, 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이터 등에 대 해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대해서 레벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해서 게임에 참여하고, 해당 게임 에 참여한 게임 참가자 및 관전자 참여에 의해 MBTI 점수 체계를 제정하고, 게임 참가자 자신의 아바타 및 아이 템과 다른 게임 참가자의 아바타 및 아이템을 참조하여 전체 게임 참가자에 대한 MBTI 선택라벨링 기능을 수행 하고, 게임 참가자별 MBTI 선택라벨링에 대한 정보, MBTI 점수체계 등에 대해서 승패 결정 모델(또는 게임 목적 달성 모델)을 통해 다른 학습 기능을 수행하고, 승패 결정 모델의 출력값인 전체 게임 참가자의 아바타 및 아이 템별 MBTI 라벨별 점수를 예측하고, 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, MBTI 점 수체계, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정하고, 결정된 게임 결과를 근거로 게임 참가자 별 아바타 및 아이템의 레벨을 유지/업/다운할 수 있다. 또한, 이와 같이, 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설정된 레벨, 로우 데이터 등 에 대해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대 해서 레벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해서 문자메시지 송/수신 기 능, 게시물 작성 기능, 이모티콘/아이콘 생성 및 적용 기능, 채팅 기능, 외부 서버에서 제공하는 게임 내 아바 타 또는 아이템에 적용하는 기능 등을 수행할 수 있다. 또한, 이와 같이, 사용자로부터 제공되는 로우 데이터에 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 포 함하는 사용자 정보를 적용하고, 사용자 정보가 적용된 로우 데이터를 이용해서 게임 기능을 수행할 수 있다. 이하에서는, 본 발명에 따른 집단 지성을 이용한 정보 처리 방법을 도 1 내지 도 20을 참조하여 상세히 설명한 다. 도 12는 본 발명의 제 1 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다. 먼저, 단말은 하나 이상의 시각 세트 장치(미도시)와 연동하여, 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메 타 정보, 사용자 정보 등을 수집한다. 여기서, 상기 시각 세트 장치는 카메라부, 라이다, 아이트래커, 모션 캡 처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의료용 초음파 등) 등을 포함한다. 또한, 상기 로우 데이터(raw data)(또는 기초영상/원본 데이터/소스 데이터/시각 데이터/실제 현실의 영상)는 실제 현실에서 획 득되는(또는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값 등 을 포함한다. 여기서, 상기 측정값은 상기 라이다, 상기 아이트래커, 상기 모션 캡처 및 모션트래커, 상기 의료 장비 등을 통해 측정되는 영상 정보(또는 3차원 데이터) 등을 포함한다. 또한, 상기 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유 형에 따른 항목별 점수 등 포함) 등을 포함한다. 이때, 상기 단말은 해당 단말에 미리 설치된 전용 앱을 실행하고, 전용 앱 실행에 따른 앱 실행 결과 화면을 표시한다. 여기서, 상기 앱 실행 결과 화면은 해당 단말의 사용자와 관련한 하나 이상의 로우 데이 터, 해당 로우 데이터와 관련한 메타 정보 등을 수집하기 위한 수집 메뉴(또는 버튼/항목), 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하기 위한 레벨 선택 메뉴, 수집된 정보 나 서버로부터 제공되는 정보를 표시하기 위한 보기 메뉴, 해당 로우 데이터와 관련해서 생성된 라스트 레 벨 영상에 대한 레벨업 기능 수행을 위한 상점 메뉴, 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게임 대기실 메뉴, 환경 설정을 위한 설정 메뉴 등을 포함한다. 이때, 상기 단말은 해당 전용 앱을 제공하는 상기 서버에 회원 가입한 상태로, 회원 가입에 따른 아이디 및 비밀번호, 상기 아이디를 포함하는 바코드 또는 QR 코드 등을 이용해서 상기 전용 앱 실행 시 로그인 절차를 수행하여, 해당 전용 앱의 하나 이상의 기능 (예를 들어 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등 포함)을 수행할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 수집 메뉴가 선택되는 경우, 상기 단말 은 사용자 설정에 따른 하나 이상의 시각 세트 장치로부터 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보 등을 수집하기 위해서, 상기 선택된 수집 메뉴에 대응하는 수집 화면을 표시한다. 여기서, 상기 수집 화면은 사용자 선택(또는 사용자 입력/터치/제어)에 따라 해당 단말과 연동하는 하나 이상의 시 각 세트 장치를 선택하기 위한 정보 수집 대상 선택 항목, 선택된 정보 수집 대상으로부터 수집할 정보의 종류 를 선택하기 위한 수집 정보 종류 선택 항목, 선택된 항목에 따라 해당 정보 수집 대상으로부터 정보를 수집하 기 위한 수집 시작 항목 등을 포함한다. 또한, 상기 단말은 해당 단말에 표시되는 수집 화면에서 해당 단말의 사용자 입력(또는 사용자/ 전문가 선택/터치/제어)에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 여기서, 상기 복수의 입력값은 정보 수집 대상(또는 시각 세트 장치 정보/시각 세트 장치의 식별 정보), 수집할 정보의 종류(예를 들 어 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값/센서값 등 포함) 등을 포함한다. 또한, 상기 단말은 상기 수신된 복수의 입력값을 근거로 상기 하나 이상의 시각 세트 장치와 연동하여, 해 당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보 등을 수집한다. 이때, 상기 단말은 해당 단 말의 사용자와 관련해서 1명의 사용자로부터 1개의 로우 데이터를 수집할 수도 있고, 1명의 사용자로부터 서로 다른 복수의 로우 데이터(또는 어트리뷰트 항목/어노테이션 단계)에 따른 복수의 로우 데이터)를 수집할 수도 있다. 여기서, 상기 비교 대상 영상은 저작권, 초상권 등의 지식 재산권에 저촉되지 않는 콘텐츠일 수 있 다. 일 예로, 제 1 단말은 해당 제 1 단말에 미리 설치된 닥터다비드 앱을 실행하고, 닥터다비드 앱 실행 결과 화면을 표시한다. 이때, 상기 제 1 단말의 제 1 사용자는 제 1 아이디와 제 1 비밀번호를 이용해서 해당 닥터다 비드 앱에 로그인한 상태일 수 있다. 또한, 상기 닥터다비드 앱 실행 결과 화면 중에서 수집 메뉴가 선택될 때, 도 13에 도시된 바와 같이, 상기 제 1 단말은 상기 선택된 수집 메뉴에 대응하는 수집 화면을 표시한다. 또한, 상기 제 1 단말은 상기 수집 화면에서 해당 제 1 사용자 입력에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 또한, 상기 제 1 단말은 상기 수신된 복수의 입력값을 근거로 해당 제 1 단말의 제 1 사용자가 위치한 사무실에 설치된 시각 세트 장치에 포함된 제 1 카메라부와 연동하여, 해당 제 1 사용자를 포함하는 제 1 로우 데이터, 상기 제 1 로우 데이터와 관련한 메타 정보, 해당 제 1 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축구 선수 손흥민과 관련한 제 1 비교 대상 영상, 상기 제 1 비교 대상 영상과 관련한 메타 정보, 해당 제 1 사용자 와 관련한 제 1 사용자 정보 등을 수집한다(S1210). 이후, 상기 단말은 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하는 레벨 선택 라벨링을 수행한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 레벨 선택 메뉴가 선택되는 경우, 상기 단 말은 앞서 수집된 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택 (또는 설정)하기 위해서, 상기 선택된 레벨 선택 메뉴에 대응하는 레벨 선택 화면을 표시한다. 여기서, 상기 레 벨 선택 화면은 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 각각 선 택하기 위한 아바타 레벨 입력 항목, 아이템 레벨 입력 항목, 완료 항목 등을 포함한다. 이때, 상기 레벨 선택 메뉴는 상기 수집 화면을 통해서 하나 이상의 로우 데이터, 비교 대상 영상 등이 수집된 경우에 한해서 활성화 되어 표시되며, 디폴트로는 비활성화된 상태를 유지하도록 구성하며, 각 아바타별/아이템별로 서로 다른 최소 레벨 ~ 최대 레벨이 각각 분류된 상태일 수 있다. 또한, 상기 단말은 해당 단말에 표시되는 레벨 선택 화면에서 해당 단말의 사용자 입력(또는 사 용자/전문가 선택/터치/제어)에 따라 복수의 다른 입력 항목에 대응하는 복수의 다른 입력값을 수신한다. 여기 서, 상기 복수의 다른 입력값(또는 레벨 선택 라벨링에 대한 정보)은 해당 로우 데이터와 비교 대상 영상을 근 거로 생성될 아바타의 레벨 정보, 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아이템의 레벨 정보 등 을 포함한다. 이와 같이, 상기 단말은 상기 수집된 로우 데이터, 비교 대상 영상 등에 대해서, 해당 단말의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또 는 아이템의 레벨을 각각 설정(또는 수신/입력)한다. 이때, 상기 레벨 선택 라벨링 과정이 생략되는 경우 또는 상기 단말에서 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템에 대해 레벨을 설정하지 않는 경우 또는 미리 설정된 레벨 선택 라벨링 과정 시간이 지난 경우, 상기 단말은 미리 설정된 디폴트값(예를 들어 아바타별/아이템별 최소 레벨)으로 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아 바타 및/또는 아이템의 레벨을 각각 설정한다. 또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메 타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상기 수신된 레벨 선택 라벨 링에 대한 정보, 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보, 단말의 식별 정보 등을 상기 서버에 전송한다. 여기서, 상기 단말의 식별 정보는 MDN, 모바일 IP, 모바일 MAC, Sim 카드 고유정보, 시리얼번호 등을 포함한다. 일 예로, 상기 닥터다비드 앱 실행 결과 화면 중에서 레벨 선택 메뉴가 선택될 때, 도 14에 도시된 바와 같이, 상기 제 1 단말은 상기 선택된 레벨 선택 메뉴에 대응하는 레벨 선택 화면을 표시한다. 또한, 상기 제 1 단말은 상기 레벨 선택 화면에서 해당 제 1 사용자 입력에 따라 복수의 다른 입력 항목 에 대응하는 복수의 다른 입력값을 포함하는 제 1 레벨 선택 라벨링에 대한 정보(예를 들어 아바타 3 레벨, 아 이템 3 레벨 등 포함)를 수신한다. 또한, 상기 제 1 단말은 상기 수집된 해당 제 1 사용자를 포함하는 제 1 로우 데이터, 상기 제 1 로우 데이터와 관련한 메타 정보, 해당 제 1 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축구선수 손흥민과 관련한 제 1 비교 대상 영상, 상기 제 1 비교 대상 영상과 관련한 메타 정보, 해당 제 1 사용자와 관련한 제 1 사용자 정 보, 상기 수신된 제 1 레벨 선택 라벨링에 대한 정보, 제 1 라스트 레벨 영상 생성 요청 정보, 상기 제 1 단말 의 식별 정보 등을 상기 서버에 전송한다(S1220). 이후, 상기 서버는 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상 기 레벨 선택 라벨링에 대한 정보, 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보, 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정 보를 근거로 상기 레벨 선택 라벨링에 대한 정보에 대응하는 MBTI 점수에 대해서 해당 단말의 사용자 계정 에 적립된 MBTI 점수를 이용해서 결제 기능(또는 요금부과 기능)을 수행한다. 이때, 해당 단말의 사용자 계정에 적립된 MBTI 점수가 해당 상기 레벨 선택 라벨링에 대한 정보에 대응하는 MBTI 점수보다 적은 경우, 상 기 서버는 해당 단말 및 결제 서버(미도시)와 연동하여, 해당 레벨 선택 라벨링에 대한 정보에 대응 하는 MBTI 점수와 관련한 결제 금액(또는 부족한 MBTI 점수와 관련한 금액)에 대해서 결제 기능을 수행할 수도 있다. 여기서, 상기 단말에서 상기 레벨 선택 라벨링을 미리 설정된 디폴트값으로 설정한 경우, 상기 서버 는 결제 기능을 생략하거나 또는, 해당 디폴트값에 대응하는 MBTI 점수에 대해 결제 기능을 수행할 수 있 다. 일 예로, 상기 서버는 상기 제 1 단말로부터 전송되는 해당 제 1 사용자를 포함하는 제 1 로우 데이터, 상 기 제 1 로우 데이터와 관련한 메타 정보, 해당 제 1 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축구선 수 손흥민과 관련한 제 1 비교 대상 영상, 상기 제 1 비교 대상 영상과 관련한 메타 정보, 해당 제 1 사용자와 관련한 제 1 사용자 정보, 상기 제 1 레벨 선택 라벨링에 대한 정보, 제 1 라스트 레벨 영상 생성 요청 정보, 상기 제 1 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 제 1 라스트 레벨 영상 생성 요청 정보를 근거로, 상기 수신된 제 1 레벨 선택 라벨링에 대한 정보(예를 들어 전체 제 1 레벨 내지 제 10 레벨 중, 제 3 레벨)에 따라, 해당 제 1 단말의 제 1 사용자가 보유 중인 MBTI 점수에서 상기 제 3 레벨에 대응하는 MBTI 점수를 차감하여 결제 기능을 수행한다(S1230). 이후, 상기 서버는 상기 수신된 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련 한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상기 레벨 선택 라벨링 에 대한 정보 등을 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공 지능 결과/딥 러닝 결과)를 근거로 해당 로우 데이터와 해당 비교 대상 영상을 딥페이크한 라스트 레벨(last level) 영상을 생성한다. 이때, 상기 라스트 레벨 영상은 상기 로우 데이터와 상기 비교 대상 영상을 근거로 생 성되는 아바타(또는 해당 아바타의 동작 관련 영상), 하나 이상의 아이템(또는 해당 아이템의 동작 관련 영상) 등을 포함하며, 상기 레벨 선택 라벨링에 대한 정보에 따라 트레이닝율이 다르게 설정되어 실제 상기 로우 데이 터와 상기 비교 대상 영상과의 일치율(또는 유사율)이 다를 수 있다. 여기서, 상기 단말에서 상기 레벨 선 택 라벨링을 미리 설정된 디폴트값으로 설정한 경우, 상기 서버는 해당 디폴트값에 대응하는 기본 트레이 닝율(예를 들어 10%)을 적용하여 상기 라스트 레벨 영상을 생성할 수 있다. 즉, 상기 서버는 결제 기능이 정상적으로 완료된 후, 상기 수신된 상기 하나 이상의 로우 데이터(또는 기 초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사 용자 정보, 상기 레벨 선택 라벨링에 대한 정보 등을 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 로우 데이터 와 해당 비교 대상 영상을 딥페이크한 라스트 레벨 영상을 생성한다. 또한, 상기 서버는 상기 생성된 라스트 레벨 영상을 상기 단말에 전송한다. 또한, 상기 단말은 상기 서버로부터 전송되는 상기 라스트 레벨 영상을 수신하고, 상기 수신된 라스 트 레벨 영상을 출력(또는 표시)한다. 이때, 상기 단말은 상기 로우 데이터, 상기 비교 대상 영상 및 상기 라스트 레벨 영상을 화면 분할하여 출력(또는 표시)할 수도 있다. 일 예로, 상기 서버는 해당 제 1 사용자를 포함하는 제 1 로우 데이터, 상기 제 1 로우 데이터와 관련한 메타 정보, 해당 제 1 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축구선수 손흥민과 관련한 제 1 비교 대상 영상, 상기 제 1 비교 대상 영상과 관련한 메타 정보, 해당 제 1 사용자와 관련한 제 1 사용자 정보, 상기 제 1 레벨 선택 라벨링에 대한 정보 등을 상기 생성 모델의 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 해당 제 1 로우 데이터와 상기 제 1 비교 대상 영상을 딥페이크한 제 1 라스트 레벨 영상을 생성 한다. 이때, 상기 제 1 라스트 레벨 영상은 상기 제 1 레벨 선택 라벨링에 대한 정보(예를 들어 전체 1 레벨 ~ 10 레벨 중에서 3 레벨)에 따른 트레이닝율(예를 들어 30%)이 적용되어 생성된 제 1 아바타 및 제 1-1 아이템 내지 제 1-2 아이템을 포함한다. 또한, 상기 서버는 상기 생성된 제 1 라스트 레벨 영상을 상기 제 1 단말에 전송한다. 또한, 상기 제 1 단말은 상기 서버로부터 전송되는 제 1 라스트 레벨 영상을 수신하고, 상기 수신된 제 1 라스트 레벨 영상을 출력한다(S1240). 이후, 상기 단말은 상기 서버 및 상기 결제 서버와 연동하여, 해당 서버에서 제공하는 메타버스 내의 상점에서 MBTI 점수 구매를 통해 해당 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강 화 기능을 수행한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 상점 메뉴가 선택되는 경우, 상기 단말 은 상기 생성된 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강화를 위해서, 상기 선택 된 상점 메뉴에 대응하는 상점 화면을 표시한다. 여기서, 상기 상점 화면은 해당 단말의 사용자와 관련해 서 생성된 하나 이상의 아바타에 대한 정보(또는 목록)를 제공하기 위한 보유 아바타 리스트 항목, 해당 아바타 와 관련한 하나 이상의 아이템에 대한 정보(또는 목록)를 제공하기 위한 보유 아이템 리스트 항목, 아바타나 아 이템에 대한 레벨을 강화하기 위한 레벨 강화 항목 등을 포함한다. 또한, 상기 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에 포함된 하나 이상의 아바타 중에 서 특정 아바타가 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 단 말은 상기 서버 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련해서 상기 선택된 레 벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아바타의 레벨을 기준으 로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계 별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 해당 특정 아바타에 대해서 레벨 업 전/후의 레 벨 상태를 화면의 일측에 표시한다. 즉, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 하나 이상의 로우 데이터(또는 기초영상), 해 당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 결제 기능에 대응하는 아바타 레벨 강화에 대한 정보(또는 아바타 레벨 강화 라벨링에 대한 정보) 등을 상기 미 리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아바타)을 강 화(또는 업그레이드/업데이트)한다. 이때, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 라스트 레벨 영상, 결제 기능에 대 응하는 아바타 레벨 강화에 대한 정보(또는 아바타 레벨 강화 라벨링에 대한 정보) 등을 상기 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아바타)을 강화할 수도 있다. 또한, 상기 단말은 상기 서버에 의해 강화된 해당 특정 아바타에 대해서 레벨 업 전/후의 레벨 상태 를 화면의 일측에 표시한다. 또한, 상기 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에 포함된 하나 이상의 아바타 중에 서 특정 아바타가 선택되는 경우, 상기 단말은 상기 선택된 특정 아바타와 관련한 하나 이상의 아이템을 상기 보유 아이템 리스트 항목에 표시한다. 또한, 상기 단말에 표시되는 보유 아이템 리스트 항목에 포함된 하나 이상의 아이템 중에서 특정 아이템이 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 단말은 상기 서 버 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련한 특정 아이템과 관련해서 상기 선택 된 레벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말 의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아이템의 레벨 을 기준으로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된 9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 해당 특정 아바타와 관련한 특정 아이템에 대해 서 레벨 업 전/후의 레벨 상태를 화면의 일측에 표시한다. 즉, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 하나 이상의 로우 데이터(또는 기초영상), 해 당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 결제 기능에 대응하는 아이템 레벨 강화에 대한 정보(또는 아이템 레벨 강화 라벨링에 대한 정보) 등을 상기 미 리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아이템)을 강 화(또는 업그레이드/업데이트)한다. 이때, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 라스트 레벨 영상, 결제 기능에 대 응하는 아이템 레벨 강화에 대한 정보(또는 아이템 레벨 강화 라벨링에 대한 정보) 등을 상기 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아이템)을 강화할 수도 있다. 또한, 상기 단말은 상기 서버에 의해 강화된 해당 특정 아바타와 관련한 특정 아이템에 대해서 레벨 업 전/후의 레벨 상태를 화면의 일측에 표시한다. 이와 같이, 상기 단말은 앞서 단말에서 설정한 레벨 선택 라벨링에 대한 정보 등을 적용하여 생성되 는 라스트 레벨 영상에 대해서, 추가 MBTI 점수 결제에 따라, 해당 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨을 강화(또는 업그레이드/업데이트)할 수 있다. 일 예로, 상기 닥터다비드 앱 실행 결과 화면 중에서 상점 메뉴가 선택될 때, 도 15에 도시된 바와 같이, 상기 제 1 단말은 상기 선택된 상점 메뉴에 대응하는 상점 화면을 표시한다.또한, 상기 제 1 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에서 상기 제 1 아바타 가 선택된 후, 해당 상점 화면의 일측에 표시되는 9 레벨로 강화 항목이 선택될 때, 상기 제 1 단 말은 상기 서버와 연동하여, 해당 제 1 단말의 제 1 사용자가 보유 중인 MBTI 점수에서 상기 9 레벨로 강 화 항목에 대응하는 MBTI 점수를 차감하여 결제 기능을 수행한다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 제 1 라스트 레벨 영상, 상기 9 레 벨로 강화 항목에 대응하는 아바타 레벨 강화 라벨링에 대한 정보(예를 들어 9 레벨) 등을 상기 생성 모델의 입 력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 해당 제 1 로우 데이터와 상기 제 1 비교 대상 영상을 딥페이크한 제 1 라스트 레벨 영상 내의 제 1 아바타를 강화한다. 또한, 상기 서버는 상기 강화된 제 1 아바타를 포함하는 제 1 라스트 레벨 영상을 상기 제 1 단말에 전송 한다. 또한, 상기 제 1 단말은 상기 서버로부터 전송되는 상기 업그레이드된 제 1 아바타를 포함하는 제 1 라스 트 레벨 영상을 수신하고, 상기 제 1 아바타에 대해서 레벨 업 전/후의 레벨 상태(예를 들어 레벨 업 전인 3 레 벨의 제 1 아바타와 레벨 업 후인 9 레벨의 제 1 아바타)를 화면에 각각 표시한다(S1250). 이후, 상기 서버는 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말 을 대상으로 게임 시작 시, MBTI 점수 체계를 제정(또는 결정/설정)한다. 이때, 상기 MBTI 점수 체계는 해당 게 임룸(또는 개설된 게임방)에 대응하는 게임과 관련해서 경쟁 게임을 진행하고 승패를 결정짓는 구성 요소로, 해 당 게임과 관련한 헌법, 법률, 규칙 등을 포함하며, 아바타의 MBTI 유형 및/또는 아이템의 MBTI 유형에 따른 상 극과 상생의 법칙으로 승부를 결정짓는 방식일 수 있다. 여기서, 상기 게임과 관련한 헌법은 상극과 상생의 점 수 비교 방식을 결정하는 것이고, 상기 게임과 관련한 법률은 해당 헌법의 내용을 구체화한 것이고, 상기 게임 과 관련한 규칙은 상극의 점수가 높은 쪽이 경쟁에서 유리한 것, 상생의 점수의 유사도가 높을수록 콤비 플레이 의 성공률이 높아지는 것 등과 같이 구체적으로 수치화된 내용(또는 조건)을 포함한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 게임 대기실 메뉴가 선택되는 경우, 상기 단말은 게임 참여를 위해 개설된 게임방 목록을 제공하거나 새로운 게임방을 개설하기 위해서, 상기 선택 된 게임 대기실 메뉴에 대응하는 게임 대기실 화면을 표시한다. 여기서, 상기 게임 대기실화면은 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게임방 리스트 항목, 새로운 게임방을 개설하기 위한 게임방 생성 항 목 등을 포함한다. 또한, 상기 단말에 표시되는 게임 대기실화면 내의 게임방 리스트 항목에 포함된 하나 이상의 게임 대기방 중에서 어느 하나의 게임 대기방이 선택되는 경우, 상기 단말은 상기 서버와 연동하여, 상기 선택된 게임 대기방에 대응하는 게임룸에 입장(또는 참여)한다. 또한, 상기 단말에서 참여한 게임룸을 개설한 방장에 의해 미리 설정된 게임 시작 메뉴가 선택되는 경우 (또는 해당 게임룸과 관련해서 미리 설정된 게임 시작 조건을 만족하는 경우), 상기 서버는 해당 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 해당 게임을 관전 중이거나 미리 설정된 게임상의 국 가기관/회사/상점에 소속된 사용자가 소지한 다른 복수의 단말, 해당 게임과 유사한 게임에 참여했던 다른 사용자가 소지한 또 다른 복수의 단말 등과 연동하여, 해당 게임(또는 해당 게임룸)과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 게임 시작 조건은 미리 설정된 게임 참가자 수를 만족하는 경우, 미리 설정된 게임 시작 시각을 만족하는 경우 등을 포함한다. 이때, 상기 서버는 미리 설정된 조건(예를 들어 게임 시작 후 미리 설정된 시간(일 예로 5분, 10분 등 포함)이 지난 경우, 미리 설정된 참여자(일 예로 10 명) 이상이 MBTI 점수 체계 제정에 참여한 경우 등 포함)을 만족할 때까지 해당 게임과 관련한 MBTI 점수 체계 를 제정한다. 여기서, 상기 미리 설정된 조건을 충족할 때까지 상기 게임과 관련한 MBTI 점수 체계가 제정되지 않은 경우, 상기 서버는 해당 게임과 관련해서 미리 설정된 디폴트값으로 해당 MBTI 점수 체계를 제정(또 는 설정)할 수도 있다. 일 예로, 상기 닥터다비드 앱 실행 결과 화면 중에서 게임 대기실 메뉴가 선택될 때, 도 16에 도시된 바와 같이, 상기 제 1 단말은 상기 선택된 게임 대기실 메뉴에 대응하는 게임 대기실 화면을 표시한다. 또한, 상기 게임 대기실 화면에 포함된 하나 이상의 게임 대기방 중에서 제 3 슈팅 게임 대기방이 선택될 때, 상기 제 1 단말은 상기 서버와 연동하여, 상기 선택된 제 3 슈팅 게임 대기방에 대응하는 제 3 슈팅 게임룸에 입장한다.또한, 상기 제 3 슈팅 게임룸을 개설한 제 2 단말의 사용자에 의해 미리 설정된 게임 시작 조건인 2명의 게임 참가자 수를 만족할 때, 상기 서버는 상기 슈팅 게임에 참여하는 제 1 단말 및 제 2 단말과, 해당 슈 팅 게임을 관전 중인 제 11 단말 내지 제 15 단말과, 해당 슈팅 게임에 참여했던 제 21 단말 내 지 제 30 단말과 연동하여, 해당 제 3 슈팅 게임룸과 관련한 제 3 MBTI 점수 체계를 제정한다. 여기서, 상 기 제 3 MBTI 점수 체계는 상극의 점수가 높은 쪽이 경쟁에서 유리한 것, 상생의 점수의 유사도가 높을수록 콤 비 플레이의 성공률이 높아지는 것 등을 포함한다(S1260). 이후, 상기 단말은 상기 서버와 연동하여, 해당 단말의 사용자와 관련한 아바타 및/또는 아이템 과, 해당 게임에 참여한 다른 게임 참가자와 관련한 아바타 및/또는 아이템을 참조하여, 게임 참가자별 MBTI 선 택라벨링(또는 복수의 단말의 게임 참가자/사용자와 관련한 아바타 및/또는 아이템별 MBTI 선택라벨링) 기 능을 수행한다. 여기서, 상기 MBTI 선택라벨링(또는 MBTI 선택레이블링)은 해당 게임에 참여한 모든 사용자와 관련한 아바타 또는 아이템에 대해서 해당 단말의 사용자가 생각하는 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 설정하는(또는 붙이는) 라벨링 방법을 나타낸다. 이때, 상기 MBTI 유형에 따른 항목별 점수는 미 리 설정된 범위(예를 들어 0점 ~ 100점) 중에서 선택될 수 있다. 이와 같이, 상기 단말은 해당 게임에 참여한 복수의 게임 참가자가 각각 소지한 아바타 및 아이템과 관련 해서, 각각의 게임 참가자별 MBTI 선택라벨링(또는 사용자별 MBTI 선택라벨링) 기능을 수행하여, 게임 참가자별 아바타 및 아이템에 대한 MBTI 유형과 항목별 점수를 각각 설정(또는 수신/입력)할 수 있다. 또한, 상기 서버는 해당 게임룸에 참여한 복수의 단말을 대상으로 상기 MBTI 선택라벨링 기능 수행에 따른 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 수집한다. 일 예로, 도 17에 도시된 바와 같이, 상기 제 1 단말은 게임 참가자별 MBTI 선택라벨링을 수행하기 위해서 MBTI 선택라벨링 화면을 표시한다. 또한, 상기 제 1 단말은 해당 제 1 단말의 제 1 사용자 입력에 따라, 해당 제 1 사용자와 관련한 제 1 아바타에 대한 제 1-1 MBTI 유형(예를 들어 ESFJ) 및 해당 제 1-1 MBTI 유형에 따른 제 1-1 항목별 점수(예를 들어 E: 90점, S: 75점, F: 80점, J: 85점), 제 1-1 아이템에 대한 제 1-2 MBTI 유형(예를 들어 ESTJ) 및 해당 제 1-2 MBTI 유형에 따른 제 1-2 항목별 점수(예를 들어 E: 95점, S: 70점, T: 75점, J: 85점), 제 1-2 아이템에 대한 제 1-3 MBTI 유형(예를 들어 ENTJ) 및 해당 제 1-3 MBTI 유형에 따른 제 1-3 항목별 점수(예를 들어 E: 90점, N: 75점, T: 75점, J: 80점)와, 해당 제 2 사용자와 관련한 제 2 아바타에 대한 제 1-4 MBTI 유형(예를 들어 INFP) 및 해당 제 1-4 MBTI 유형에 따른 제 1-4 항목별 점수(예를 들어 I: 90점, N: 80점, F: 75점, P: 75점), 제 2-1 아이템에 대한 제 1-5 MBTI 유형(예를 들어 ENFP) 및 해당 제 1-5 MBTI 유형에 따른 제 1-5 항목별 점 수(예를 들어 E: 80점, N: 90점, F: 85점, P: 90점) 등을 포함하는 제 1 사용자 MBTI 선택라벨링에 대한 정보를 수신한다. 또한, 상기 제 1 단말은 상기 수신된 제 1 사용자 MBTI 선택라벨링에 대한 정보, 상기 제 1 단말의 식별 정보 등을 상기 서버에 전송한다. 또한, 상기 서버는 상기 제 1 단말로부터 전송되는 제 1 사용자 MBTI 선택라벨링에 대한 정보, 상기 제 1 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 제 2 단말로부터 전송되는 제 2 사용자 MBTI 선택라벨링에 대한 정보, 상기 제 2 단말의 식별 정보 등을 수신한다. 여기서, 상기 제 2 사용자 MBTI 선택라벨링에 대한 정보는 해당 제 2 단말의 제 2 사용자 입력에 따른, 해당 제 1 사용자와 관련한 제 1 아바타에 대한 제 2-1 MBTI 유형(예를 들어 ESFP) 및 해당 제 2-1 MBTI 유형에 따른 제 2-1 항목별 점수(예를 들어 E: 85점, S: 80점, F: 85점, P: 80점), 제 1- 1 아이템에 대한 제 2-2 MBTI 유형(예를 들어 ESTJ) 및 해당 제 2-2 MBTI 유형에 따른 제 2-2 항목별 점수(예를 들어 E: 90점, S: 80점, T: 75점, J: 80점), 제 2-2 아이템에 대한 제 2-3 MBTI 유형(예를 들어 ENFJ) 및 해당 제 2-3 MBTI 유형에 따른 제 2-3 항목별 점수(예를 들어 E: 90점, N: 75점, F: 80점, J: 70점)와, 해당 제 2 사용자와 관련한 제 2 아바타에 대한 제 2-4 MBTI 유형(예를 들어 INFP) 및 해당 제 2-4 MBTI 유형에 따른 제 2-4 항목별 점수(예를 들어 I: 90점, N: 85점, F: 80점, P: 85점), 제 2-1 아이템에 대한 제 2-5 MBTI 유형(예 를 들어 ESTJ) 및 해당 제 2-5 MBTI 유형에 따른 제 2-5 항목별 점수(예를 들어 E: 90점, S: 80점, T: 80점, J: 95점) 등을 포함한다(S1270). 이후, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가 자별 MBTI 선택라벨링에 대한 정보(또는 복수의 단말의 게임 참가자/사용자와 관련한 아바타 및/또는 아이템별 MBTI 선택라벨링에 대한 정보), 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 입력값으로 하여 다른 기계 학습(또는 다른 인공지능/다른 딥 러닝)을 수행하고, 다른 기 계 학습 결과(또는 다른 인공지능 결과/다른 딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 즉, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자 별 MBTI 선택라벨링에 대한 정보, 사용자별 아바타 및/또는 아이템에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 미리 설정된 승패 결정 모델의 입력값으로 하여 다른 기계 학습(또는 다른 인공지능/다른 딥 러 닝)을 수행하고, 다른 기계 학습 결과(또는 다른 인공지능 결과/다른 딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 여기서, 상기 승패 결정 모델(또는 MBTI 점수체계 예측 모델)은 통계적 모델, 회귀 모델, 딥 러닝 모델 등을 포함한다. 이때, 상기 서버는 상기 승패 결정 모델에 따라 게임의 승패를 결정하는 과정과 관련한 화면(또는 사용자 인터페이스)을 해당 게임에 참여한 복수의 단말에 각각 제공할 수도 있다. 이와 같이, 상기 서버는 상기 승패 결정 모델의 출력값인 전체 게임 참가자의 아바타 및 아이템별 MBTI 라 벨별 점수를 예측하고, 상기 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정한다. 즉, 상기 서버는 집단 지성화를 통해 상기 수집된 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 근거로 게임 참가자별 아바타 및 아이템에 대한 MBTI 유형 및 MBTI 유형에 따른 항목별 점수를 설정(또 는 산출)한다. 또한, 상기 서버는 상기 게임 결과(또는 해당 게임 결과에 대한 정보)를 해당 게임에 참여한 복수의 단말 에 각각 전송한다. 여기서, 상기 게임 결과는 해당 게임 참가자에 대한 승/패 결과뿐만 아니라, 아이템 및 /또는 실제 현실의 상품(디지털트윈), 게임 상대자 등을 추천하는 결과, 게임의 종류가 경쟁게임이 아닌 경우에 는 게임의 목적의 성공/실패를 예측한 결과 등을 포함할 수 있다. 또한, 상기 복수의 단말은 상기 서버로부터 전송되는 해당 게임 결과를 각각 수신하고, 상기 수신된 게임 결과를 출력(또는 표시)한다. 일 예로, 상기 수신된 제 1 사용자 MBTI 선택라벨링에 대한 정보, 상기 수신된 제 2 사용자 MBTI 선택라벨링에 대한 정보, 제 1 사용자의 제 1 아바타와 제 1-1 아이템과 제 1-2 아이템에 대한 정보, 제 2 사용자의 제 2 아 바타와 제 2-1 아이템에 대한 정보, 상기 제 1 사용자 정보, 제 2 사용자 정보, 상기 제정된 제 3 MBTI 점수 체 계 등을 상기 승패 결정 모델의 입력값으로 하여 다른 기계 학습을 수행하고, 다른 기계 학습 결과를 근거로 해 당 제 3 슈팅 게임의 승자와 패자를 결정한다. 이때, 상기 서버는 해당 제 3 MBTI 점수 체계에 따라, 슈터인 제 1 사용자와 관련한 레벨 9로 트레이닝된 제 1 아바타에 대한 선택라벨링에 따른 MBTI 유형(예를 들어 ESFJ) 및 골키퍼인 제 2 사용자와 관련한 레벨 7로 트레이닝된 제 2 아바타에 대한 선택라벨링에 따른 MBTI 유형(예를 들어 INFP)을 근거로 상극 관계인 E 점수(예 를 들어 평균인 87.5점)와 I 점수(예를 들어 평균인 90점), S 점수(예를 들어 평균인 77.5점)와 N 점수(예를 들 어 평균인 82.5점) 및, J 점수(예를 들어 평균인 85점)와 P 점수(예를 들어 평균인 80점)를 비교하여, 해당 제 1 아바타의 점수(예를 들어 상극 관계인 항목의 점수 합이 250점)가 상기 제 2 아바타의 점수(예를 들어 상극 관계인 항목의 점수 합이 252.5점)보다 낮으므로, 상기 제 2 아바타의 승리로 결정한다. 여기서, 상기 제 1 아 바타에 대한 선택라벨링에 따른 MBTI 유형(예를 들어 ESFJ)은 상기 제 1 사용자의 선택라벨링에 따른 제 1-1 MBTI 유형(예를 들어 ESFJ) 및 해당 제 1-1 MBTI 유형에 따른 제 1-1 항목별 점수(예를 들어 E: 90점, S: 75점, F: 80점, J: 85점)와 상기 제 2 사용자의 선택라벨링에 따른 제 2-1 MBTI 유형(예를 들어 ESFP) 및 해당 제 2-1 MBTI 유형에 따른 제 2-1 항목별 점수(예를 들어 E: 85점, S: 80점, F: 85점, P: 80점)를 근거로 동일 한 항목에 대해서는 해당 항목의 평균값을 계산하여 정리하고, 서로 다른 항목에 대해서는 해당 항목의 점수가 더 높은 항목을 선택하여, 결정한 상태(예를 들어 제 1-1 MBTI 유형 내의 E 항목과 제 2-1 MBTI 유형 내의 E 항 목이 동일하여 해당 항목의 경우 E 항목으로 결정하고, 90점 및 85점의 평균값인 87.5점을 사용하고, 제 1-1 MBTI 유형 내의 S 항목과 제 2-1 MBTI 유형 내의 S 항목이 동일하여 해당 항목의 경우 S 항목으로 결정하고, 75 점 및 80점의 평균값인 77.5점을 사용하고, 제 1-1 MBTI 유형 내의 F 항목과 제 2-1 MBTI 유형 F 항목이 동일하 여 해당 항목의 경우 F 항목으로 결정하고, 80점 및 85점의 평균값인 82.5점을 사용하고, 제 1-1 MBTI 유형 내 의 J 항목과 제 2-1 MBTI 유형 P 항목이 서로 다른 상태에서 J 항목의 점수가 85점으로 P 항목의 점수 80점보다 크므로 해당 항목의 경우 J 항목으로 결정하고 해당 J 항목의 점수인 85점을 사용)일 수 있다. 또한, 상기 서버는 해당 제 3 슈팅 게임의 게임 결과(예를 들어 제 1 사용자가 패배, 제 2 사용자가 승리, 게임 승패에 따라 해당 제 1 사용자와 관련한 제 1 아바타, 제 1-1 아이템 및 제 1-2 아이템의 레벨을 유지하고 MBTI 점수 3점을 제공, 해당 제 2 사용자와 관련한 제 2 아바타 및 제 2-1 아이템의 레벨을 0.001% 업시키고 MBTI 점수 10점을 제공 등 포함)를 상기 제 1 단말 및 상기 제 2 단말에 각각 전송한다. 또한, 상기 제 1 단말 및 상기 제 2 단말은 상기 서버로부터 전송되는 해당 제 3 슈팅 게임의 게임 결과를 각각 수신하고, 상기 수신된 해당 제 3 슈팅 게임의 게임 결과를 각각 표시한다(S1280). 이후, 상기 서버는 해당 게임에서의 승패 결과에 따라, 게임 참가자별 아바타 및/또는 아이템의 레벨 유지 /업/다운 기능을 수행한다. 즉, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 라스트 레벨 영상 에 포함된 아바타 및/또는 아이템의 레벨을 유지/업/다운한다. 또한, 상기 서버는 상기 게임 결과를 근거로 MBTI 점수를 해당 게임 참가자의 해당 아바타(또는 해당 게임 참가자의 계정)에 적립(또는 제공)한다. 일 예로, 상기 서버는 해당 제 3 슈팅 게임의 게임 결과를 근거로 해당 제 1 사용자와 관련한 제 1 라스트 레벨 영상 내에 포함된 제 1 아바타, 제 1-1 아이템 및 제 1-2 아이템의 레벨을 그대로 유지하고, 해당 제 1 사 용자와 관련한 MBTI 점수를 3점 증가시킨다. 또한, 상기 서버는 해당 제 3 슈팅 게임의 게임 결과를 근거로 해당 제 2 사용자와 관련한 제 2 라스트 레 벨 영상 내에 포함된 제 2 아바타 및 제 2-1 아이템의 레벨을 0.001% 업시키고, 해당 제 2 사용자와 관련한 MBTI 점수를 10점 증가시킨다(S1290). 도 18은 본 발명의 제 2 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다. 먼저, 단말은 하나 이상의 시각 세트 장치(미도시)와 연동하여, 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메 타 정보, 사용자 정보 등을 수집한다. 여기서, 상기 시각 세트 장치는 카메라부, 라이다, 아이트래커, 모션 캡 처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의료용 초음파 등) 등을 포함한다. 또한, 상기 로우 데이터(또는 기초영상/원본 데이터/소스 데이터/시각 데이터/실제 현실의 영상)는 실제 현실에서 획득되는(또는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값 등을 포함한다. 여기서, 상기 측정값은 상기 라이다, 상기 아이트래커, 상기 모션 캡처 및 모션트래커, 상기 의료장비 등을 통 해 측정되는 영상 정보(또는 3차원 데이터) 등을 포함한다. 또한, 상기 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유형에 따른 항 목별 점수 등 포함) 등을 포함한다. 이때, 상기 단말은 해당 단말에 미리 설치된 전용 앱을 실행하고, 전용 앱 실행에 따른 앱 실행 결과 화면을 표시한다. 여기서, 상기 앱 실행 결과 화면은 해당 단말의 사용자와 관련한 하나 이상의 로우 데이 터, 해당 로우 데이터와 관련한 메타 정보 등을 수집하기 위한 수집 메뉴(또는 버튼/항목), 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하기 위한 레벨 선택 메뉴, 수집된 정보 나 서버로부터 제공되는 정보를 표시하기 위한 보기 메뉴, 해당 로우 데이터와 관련해서 생성된 라스트 레 벨 영상에 대한 레벨업 기능 수행을 위한 상점 메뉴, 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게 임 대기실 메뉴, 환경 설정을 위한 설정 메뉴 등을 포함한다. 이때, 상기 단말은 해당 전용 앱을 제공하는 상기 서버에 회원 가입한 상태로, 회원 가입에 따른 아이디 및 비밀번호, 상기 아이디를 포함하는 바코드 또는 QR 코드 등을 이용해서 상기 전용 앱 실행 시 로그인 절차를 수행하여, 해당 전용 앱의 하나 이상의 기능 (예를 들어 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등 포함)을 수행할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 수집 메뉴가 선택되는 경우, 상기 단말 은 사용자 설정에 따른 하나 이상의 시각 세트 장치로부터 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보 등을 수집하기 위해서, 상기 선택된 수집 메뉴에 대응하는 수집 화면을 표시한다. 여기서, 상기 수집 화면은 사용자 선택(또는 사용자 입력/터치/제어)에 따라 해당 단말과 연동하는 하나 이상의 시 각 세트 장치를 선택하기 위한 정보 수집 대상 선택 항목, 선택된 정보 수집 대상으로부터 수집할 정보의 종류 를 선택하기 위한 수집 정보 종류 선택 항목, 선택된 항목에 따라 해당 정보 수집 대상으로부터 정보를 수집하기 위한 수집 시작 항목 등을 포함한다. 또한, 상기 단말은 해당 단말에 표시되는 수집 화면에서 해당 단말의 사용자 입력(또는 사용자/ 전문가 선택/터치/제어)에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 여기서, 상기 복수의 입력값은 정보 수집 대상(또는 시각 세트 장치 정보/시각 세트 장치의 식별 정보), 수집할 정보의 종류(예를 들 어 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값/센서값 등 포함) 등을 포함한다. 또한, 상기 단말은 상기 수신된 복수의 입력값을 근거로 상기 하나 이상의 시각 세트 장치와 연동하여, 해 당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보 등을 수집한다. 이때, 상기 단말은 해당 단 말의 사용자와 관련해서 1명의 사용자로부터 1개의 로우 데이터를 수집할 수도 있고, 1명의 사용자로부터 서로 다른 복수의 로우 데이터(또는 어트리뷰트 항목/어노테이션 단계)에 따른 복수의 로우 데이터)를 수집할 수도 있다. 여기서, 상기 비교 대상 영상은 저작권, 초상권 등의 지식 재산권에 저촉되지 않는 콘텐츠일 수 있 다. 일 예로, 제 11 단말은 해당 제 11 단말에 미리 설치된 닥터다비드 앱을 실행하고, 닥터다비드 앱 실행 결 과 화면을 표시한다. 이때, 상기 제 11 단말의 제 11 사용자는 제 11 아이디와 제 11 비밀번호를 이용해서 해당 닥터다비드 앱에 로그인한 상태일 수 있다. 또한, 상기 닥터다비드 앱 실행 결과 화면 중에서 수집 메뉴가 선택될 때, 상기 제 11 단말은 상기 선택된 수집 메뉴에 대응하는 수집 화면을 표시한다. 또한, 상기 제 11 단말은 상기 수집 화면에서 해당 제 11 단말의 제 11 사용자 입력에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 또한, 상기 제 11 단말은 상기 수신된 복수의 입력값을 근거로 해당 제 11 단말의 제 11 사용자가 위치한 사무 실에 설치된 시각 세트 장치에 포함된 제 11 카메라부와 연동하여, 해당 제 11 사용자를 포함하는 제 11 로우 데이터, 상기 제 11 로우 데이터와 관련한 메타 정보, 해당 제 11 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축구선수 손흥민과 관련한 제 11 비교 대상 영상, 상기 제 11 비교 대상 영상과 관련한 메타 정보, 해당 제 11 사용자와 관련한 제 11 사용자 정보 등을 수집한다(S1810). 이후, 상기 단말은 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하는 레벨 선택 라벨링을 수행한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 레벨 선택 메뉴가 선택되는 경우, 상기 단 말은 앞서 수집된 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택 (또는 설정)하기 위해서, 상기 선택된 레벨 선택 메뉴에 대응하는 레벨 선택 화면을 표시한다. 여기서, 상기 레 벨 선택 화면은 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 각각 선 택하기 위한 아바타 레벨 입력 항목, 아이템 레벨 입력 항목, 완료 항목 등을 포함한다. 이때, 상기 레벨 선택 메뉴는 상기 수집 화면을 통해서 하나 이상의 로우 데이터, 비교 대상 영상 등이 수집된 경우에 한해서 활성화 되어 표시되며, 디폴트로는 비활성화된 상태를 유지하도록 구성하며, 각 아바타별/아이템별로 서로 다른 최소 레벨 ~ 최대 레벨이 각각 분류된 상태일 수 있다. 또한, 상기 단말은 해당 단말에 표시되는 레벨 선택 화면에서 해당 단말의 사용자 입력(또는 사 용자/전문가 선택/터치/제어)에 따라 복수의 다른 입력 항목에 대응하는 복수의 다른 입력값을 수신한다. 여기 서, 상기 복수의 다른 입력값(또는 레벨 선택 라벨링에 대한 정보)은 해당 로우 데이터와 비교 대상 영상을 근 거로 생성될 아바타의 레벨 정보, 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아이템의 레벨 정보 등 을 포함한다. 이와 같이, 상기 단말은 상기 수집된 로우 데이터, 비교 대상 영상 등에 대해서, 해당 단말의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또 는 아이템의 레벨을 각각 설정(또는 수신/입력)한다. 이때, 상기 레벨 선택 라벨링 과정이 생략되는 경우 또는 상기 단말에서 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템에 대해 레벨을 설정하지 않는 경우 또는 미리 설정된 레벨 선택 라벨링 과정 시간이 지난 경우, 상기 단말은 미리 설정된 디폴트값(예를 들어 아바타별/아이템별 최소 레벨)으로 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아 바타 및/또는 아이템의 레벨을 각각 설정한다.또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메 타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상기 수신된 레벨 선택 라벨 링에 대한 정보, 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보, 단말의 식별 정보 등을 상기 서버에 전송한다. 여기서, 상기 단말의 식별 정보는 MDN, 모바일 IP, 모바일 MAC, Sim 카드 고유정보, 시리얼번호 등을 포함한다. 일 예로, 상기 닥터다비드 앱 실행 결과 화면 중에서 레벨 선택 메뉴가 선택될 때, 상기 제 11 단말은 상기 선 택된 레벨 선택 메뉴에 대응하는 레벨 선택 화면을 표시한다. 또한, 상기 제 11 단말은 상기 레벨 선택 화면에서 해당 제 11 사용자 입력에 따라 복수의 다른 입력 항목에 대 응하는 복수의 다른 입력값을 포함하는 제 11 레벨 선택 라벨링에 대한 정보(예를 들어 아바타 3 레벨, 아이템 3 레벨 등 포함)를 수신한다. 또한, 상기 제 11 단말은 상기 수집된 해당 제 11 사용자를 포함하는 제 11 로우 데이터, 상기 제 11 로우 데이 터와 관련한 메타 정보, 해당 제 11 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축구선수 손흥민과 관련 한 제 11 비교 대상 영상, 상기 제 11 비교 대상 영상과 관련한 메타 정보, 해당 제 11 사용자와 관련한 제 11 사용자 정보, 상기 수신된 제 11 레벨 선택 라벨링에 대한 정보, 제 11 라스트 레벨 영상 생성 요청 정보, 상기 제 11 단말의 식별 정보 등을 상기 서버에 전송한다(S1820). 이후, 상기 서버는 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상 기 레벨 선택 라벨링에 대한 정보, 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정보, 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 해당 로우 데이터와 비교 대상 영상 관련 라스트 레벨 영상 생성 요청 정 보를 근거로 상기 레벨 선택 라벨링에 대한 정보에 대응하는 결제 금액에 대해서 해당 단말의 사용자 계정 에 적립된 포인트를 이용해서 결제 기능(또는 요금부과 기능)을 수행한다. 이때, 해당 단말의 사용자 계정 에 적립된 포인트가 해당 상기 레벨 선택 라벨링에 대한 정보에 대응하는 포인트보다 적은 경우, 상기 서버 는 해당 단말 및 결제 서버(미도시)와 연동하여, 해당 레벨 선택 라벨링에 대한 정보에 대응하는 포 인트와 관련한 결제 금액(또는 부족한 포인트와 관련한 금액)에 대해서 결제 기능을 수행할 수도 있다. 여기서, 상기 단말에서 상기 레벨 선택 라벨링을 미리 설정된 디폴트값으로 설정한 경우, 상기 서버는 결제 기능을 생략하거나 또는, 해당 디폴트값에 대응하는 포인트에 대해 결제 기능을 수행할 수 있다. 이때, 상기 라 스트 레벨 영상 생성이 무료로 진행되는 경우, 상기 결제 과정은 생략될 수도 있다. 일 예로, 상기 서버는 상기 제 11 단말로부터 전송되는 해당 제 11 사용자를 포함하는 제 11 로우 데이터, 상기 제 11 로우 데이터와 관련한 메타 정보, 해당 제 11 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축 구선수 손흥민과 관련한 제 11 비교 대상 영상, 상기 제 11 비교 대상 영상과 관련한 메타 정보, 해당 제 11 사 용자와 관련한 제 11 사용자 정보, 상기 제 11 레벨 선택 라벨링에 대한 정보, 제 11 라스트 레벨 영상 생성 요 청 정보, 상기 제 11 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 제 11 라스트 레벨 영상 생성 요청 정보를 근거로, 상기 수신된 제 11 레 벨 선택 라벨링에 대한 정보(예를 들어 전체 제 1 레벨 내지 제 10 레벨 중, 제 3 레벨)에 따라, 해당 제 11 단 말의 제 11 사용자가 보유 중인 포인트에서 상기 제 3 레벨에 대응하는 포인트를 차감하여 결제 기능을 수행한 다(S1830). 이후, 상기 서버는 상기 수신된 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련 한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 상기 레벨 선택 라벨링 에 대한 정보 등을 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공 지능 결과/딥 러닝 결과)를 근거로 해당 로우 데이터와 해당 비교 대상 영상을 딥페이크한 라스트 레벨(last level) 영상을 생성한다. 이때, 상기 라스트 레벨 영상은 상기 로우 데이터와 상기 비교 대상 영상을 근거로 생 성되는 아바타(또는 해당 아바타의 동작 관련 영상), 하나 이상의 아이템(또는 해당 아이템의 동작 관련 영상) 등을 포함하며, 상기 레벨 선택 라벨링에 대한 정보에 따라 트레이닝율이 다르게 설정되어 실제 상기 로우 데이 터와 상기 비교 대상 영상과의 일치율(또는 유사율)이 다를 수 있다. 여기서, 상기 단말에서 상기 레벨 선 택 라벨링을 미리 설정된 디폴트값으로 설정한 경우, 상기 서버는 해당 디폴트값에 대응하는 기본 트레이 닝율(예를 들어 10%)을 적용하여 상기 라스트 레벨 영상을 생성할 수 있다.즉, 상기 서버는 결제 기능이 정상적으로 완료된 후, 상기 수신된 상기 하나 이상의 로우 데이터(또는 기 초영상), 해당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사 용자 정보, 상기 레벨 선택 라벨링에 대한 정보 등을 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 로우 데이터 와 해당 비교 대상 영상을 딥페이크한 라스트 레벨 영상을 생성한다. 또한, 상기 서버는 상기 생성된 라스트 레벨 영상을 상기 단말에 전송한다. 또한, 상기 단말은 상기 서버로부터 전송되는 상기 라스트 레벨 영상을 수신하고, 상기 수신된 라스 트 레벨 영상을 출력(또는 표시)한다. 이때, 상기 단말은 상기 로우 데이터, 상기 비교 대상 영상 및 상기 라스트 레벨 영상을 화면 분할하여 출력(또는 표시)할 수도 있다. 일 예로, 상기 서버는 해당 제 11 사용자를 포함하는 제 11 로우 데이터, 상기 제 11 로우 데이터와 관련 한 메타 정보, 해당 제 11 사용자가 딥페이크를 수행하고자 하는 관심 대상인 축구선수 손흥민과 관련한 제 11 비교 대상 영상, 상기 제 11 비교 대상 영상과 관련한 메타 정보, 해당 제 11 사용자와 관련한 제 11 사용자 정 보, 상기 제 11 레벨 선택 라벨링에 대한 정보 등을 상기 생성 모델의 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 해당 제 11 로우 데이터와 상기 제 11 비교 대상 영상을 딥페이크한 제 11 라스트 레 벨 영상을 생성한다. 이때, 상기 제 11 라스트 레벨 영상은 상기 제 11 레벨 선택 라벨링에 대한 정보(예를 들 어 전체 1 레벨 ~ 10 레벨 중에서 3 레벨)에 따른 트레이닝율(예를 들어 30%)이 적용되어 생성된 제 11 아바타 및 제 11-1 아이템을 포함한다. 또한, 상기 서버는 상기 생성된 제 11 라스트 레벨 영상을 상기 제 11 단말에 전송한다. 또한, 상기 제 11 단말은 상기 서버로부터 전송되는 제 11 라스트 레벨 영상을 수신하고, 상기 수신된 제 11 라스트 레벨 영상을 출력한다(S1840). 이후, 상기 단말은 상기 서버 및 상기 결제 서버와 연동하여, 해당 서버에서 제공하는 메타버스 내의 상점에서 포인트 구매를 통해 해당 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강화 기능을 수행한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 상점 메뉴가 선택되는 경우, 상기 단말 은 상기 생성된 라스트 레벨 영상에 포함된 아바타 및/또는 아이템에 대한 레벨 강화를 위해서, 상기 선택 된 상점 메뉴에 대응하는 상점 화면을 표시한다. 여기서, 상기 상점 화면은 해당 단말의 사용자와 관련해 서 생성된 하나 이상의 아바타에 대한 정보(또는 목록)를 제공하기 위한 보유 아바타 리스트 항목, 해당 아바타 와 관련한 하나 이상의 아이템에 대한 정보(또는 목록)를 제공하기 위한 보유 아이템 리스트 항목, 아바타나 아 이템에 대한 레벨을 강화하기 위한 레벨 강화 항목 등을 포함한다. 또한, 상기 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에 포함된 하나 이상의 아바타 중에 서 특정 아바타가 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 단 말은 상기 서버 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련해서 상기 선택된 레 벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아바타의 레벨을 기준으 로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계 별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된 9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 해당 특정 아바타에 대해서 레벨 업 전/후의 레 벨 상태를 화면의 일측에 표시한다. 즉, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 하나 이상의 로우 데이터(또는 기초영상), 해 당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 결제 기능에 대응하는 아바타 레벨 강화에 대한 정보(또는 아바타 레벨 강화 라벨링에 대한 정보) 등을 상기 미 리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아바타)을 강 화(또는 업그레이드/업데이트)한다. 이때, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 라스트 레벨 영상, 결제 기능에 대 응하는 아바타 레벨 강화에 대한 정보(또는 아바타 레벨 강화 라벨링에 대한 정보) 등을 상기 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아바타)을 강화할 수도 있다. 또한, 상기 단말은 상기 서버에 의해 강화된 해당 특정 아바타에 대해서 레벨 업 전/후의 레벨 상태 를 화면의 일측에 표시한다. 또한, 상기 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에 포함된 하나 이상의 아바타 중에 서 특정 아바타가 선택되는 경우, 상기 단말은 상기 선택된 특정 아바타와 관련한 하나 이상의 아이템을 상기 보유 아이템 리스트 항목에 표시한다. 또한, 상기 단말에 표시되는 보유 아이템 리스트 항목에 포함된 하나 이상의 아이템 중에서 특정 아이템이 선택된 후, 상기 상점 화면 내의 일측에 표시되는 레벨 강화 항목이 선택되는 경우, 상기 단말은 상기 서 버 및 상기 결제 서버와 연동하여, 상기 선택된 특정 아바타와 관련한 특정 아이템과 관련해서 상기 선택 된 레벨 강화 항목에 대응하는 결제 금액에 대해서 결제 기능을 수행한다. 이때, 상기 단말은 해당 단말 의 사용자 입력(또는 사용자 선택/터치/제어)에 따라, 복수의 레벨 중에서 현재 해당 특정 아이템의 레벨 을 기준으로 한 단계 이상 레벨 강화를 수행할 수 있으며, 레벨 강화(또는 레벨 업그레이드/레벨 업데이트)에 따른 단계별로 서로 다른 결제 금액(예를 들어 1 단계 추가 레벨 강화시 5,000원, 2 단계 추가 레벨 강화시 5% 할인된 9,500원, 3 단계 추가 레벨 강화시 10% 할인된 13,500원 등 포함)이 설정될 수 있다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 해당 특정 아바타와 관련한 특정 아이템에 대해 서 레벨 업 전/후의 레벨 상태를 화면의 일측에 표시한다. 즉, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 하나 이상의 로우 데이터(또는 기초영상), 해 당 로우 데이터와 관련한 메타 정보, 비교 대상 영상, 해당 비교 대상 영상과 관련한 메타 정보, 사용자 정보, 결제 기능에 대응하는 아이템 레벨 강화에 대한 정보(또는 아이템 레벨 강화 라벨링에 대한 정보) 등을 상기 미 리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아이템)을 강 화(또는 업그레이드/업데이트)한다. 이때, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 라스트 레벨 영상, 결제 기능에 대 응하는 아이템 레벨 강화에 대한 정보(또는 아이템 레벨 강화 라벨링에 대한 정보) 등을 상기 미리 설정된 생성 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 라스트 레벨 영상(또는 해당 라스트 레벨 영상 내의 아이템)을 강화할 수도 있다. 또한, 상기 단말은 상기 서버에 의해 강화된 해당 특정 아바타와 관련한 특정 아이템에 대해서 레벨 업 전/후의 레벨 상태를 화면의 일측에 표시한다. 이와 같이, 상기 단말은 앞서 단말에서 설정한 레벨 선택 라벨링에 대한 정보 등을 적용하여 생성되 는 라스트 레벨 영상에 대해서, 추가 포인트 결제에 따라, 해당 라스트 레벨 영상에 포함된 아바타 및/또는 아 이템에 대한 레벨을 강화(또는 업그레이드/업데이트)할 수 있다. 일 예로, 상기 닥터다비드 앱 실행 결과 화면 중에서 상점 메뉴가 선택될 때, 상기 제 11 단말은 상기 선택된 상점 메뉴에 대응하는 상점 화면을 표시한다. 또한, 상기 제 11 단말에 표시되는 상점 화면 내의 보유 아바타 리스트 항목에서 상기 제 11 아바타가 선택된 후, 해당 상점 화면의 일측에 표시되는 7 레벨로 강화 항목이 선택될 때, 상기 제 11 단말은 상기 서버와 연동하여, 해당 제 11 단말의 제 11 사용자가 보유 중인 포인트에서 상기 7 레벨로 강화 항목에 대응하는 포인 트를 차감하여 결제 기능을 수행한다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 서버는 상기 생성된 제 11 라스트 레벨 영상, 상기 7 레 벨로 강화 항목에 대응하는 아바타 레벨 강화 라벨링에 대한 정보(예를 들어 7 레벨) 등을 상기 생성 모델의 입 력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 해당 제 11 로우 데이터와 상기 제 11 비교 대 상 영상을 딥페이크한 제 11 라스트 레벨 영상 내의 제 11 아바타를 강화한다. 또한, 상기 서버는 상기 강화된 제 11 아바타를 포함하는 제 11 라스트 레벨 영상을 상기 제 11 단말에 전 송한다.또한, 상기 제 11 단말은 상기 서버로부터 전송되는 상기 업그레이드된 제 11 아바타를 포함하는 제 11 라 스트 레벨 영상을 수신하고, 상기 제 11 아바타에 대해서 레벨 업 전/후의 레벨 상태(예를 들어 레벨 업 전인 3 레벨의 제 11 아바타와 레벨 업 후인 7 레벨의 제 11 아바타)를 화면에 각각 표시한다(S1850). 이후, 상기 단말은 상기 서버 및 외부 서버(미도시)와 연동하여, 해당 라스트 레벨 영상(예를 들어 아바타, 아이템 등 포함)을 이용한, 문자메시지 송/수신 기능, 게시물 작성 기능, 이모티콘/아이콘 제작 및 사 용 기능, 채팅 기능, 해당 외부 서버에서 제공하는 게임 내 아바타(또는 아이템)에 적용(또는 반영/연동)하는 기능 등을 수행(또는 적용)한다. 여기서, 상기 외부 서버는 문자메시지 송/수신 기능을 제공하는 통신사 서버, 게시물 작성 기능 등을 제공하는 SNS 서버, 이모티콘/아이콘 제작 및 사용 기능을 제공하는 포털 서버, 채팅 기 능을 제공하는 채팅 서버, 게임을 제공하는 게임사 서버 등을 포함한다. 일 예로, 상기 제 11 단말은 상기 서버 및 상기 외부 서버와 연동하여, 해당 7 레벨로 강화된 제 11 아바 타를 포함하는 멀티미디어 메시지를 해당 제 11 사용자의 친구인 제 12 사용자가 소지한 제 12 단말로 전 송한다. 다른 일 예로, 상기 제 11 단말은 상기 서버 및 상기 외부 서버와 연동하여, 해당 7 레벨로 강화된 제 11 아바타를 포함하는 게시물을 작성하고, 상기 작성된 제 11 아바타를 포함하는 게시물을 해당 외부 서버에서 제 공하는 SNS 서비스에 등록한다. 또 다른 일 예로, 상기 제 11 단말은 상기 서버 및 상기 외부 서버와 연동하여, 해당 외부 서버에서 제공 하는 축구 게임의 게임 플레이어로 해당 7 레벨로 강화된 제 11 아바타를 게임 내 아바타로 적용하여 해당 축구 게임을 플레이한다(S1860). 도 19는 본 발명의 제 3 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다. 먼저, 단말은 하나 이상의 시각 세트 장치(미도시)와 연동하여, 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 여기서, 상기 시각 세 트 장치는 카메라부, 라이다, 아이트래커, 모션 캡처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의 료용 초음파 등) 등을 포함한다. 또한, 상기 로우 데이터(또는 기초영상/원본 데이터/소스 데이터/시각 데이터/ 실제 현실의 영상)는 실제 현실에서 획득되는(또는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값 등을 포함한다. 여기서, 상기 측정값은 상기 라이다, 상기 아이트래커, 상기 모션 캡처 및 모션트래커, 상기 의료장비 등을 통해 측정되는 영상 정보(또는 3차원 데이터) 등을 포함한다. 또 한, 상기 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유형에 따른 항목별 점수 등 포함) 등을 포함한다. 이때, 상기 단말은 해당 단말에 미리 설치된 전용 앱을 실행하고, 전용 앱 실행에 따른 앱 실행 결과 화면을 표시한다. 여기서, 상기 앱 실행 결과 화면은 해당 단말의 사용자와 관련한 하나 이상의 로우 데이 터, 해당 로우 데이터와 관련한 메타 정보 등을 수집하기 위한 수집 메뉴(또는 버튼/항목), 해당 로우 데이터와 비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하기 위한 레벨 선택 메뉴, 수집된 정보 나 서버로부터 제공되는 정보를 표시하기 위한 보기 메뉴, 해당 로우 데이터와 관련해서 생성된 라스트 레 벨 영상에 대한 레벨업 기능 수행을 위한 상점 메뉴, 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게 임 대기실 메뉴, 환경 설정을 위한 설정 메뉴 등을 포함한다. 이때, 상기 단말은 해당 전용 앱을 제공하는 상기 서버에 회원 가입한 상태로, 회원 가입에 따른 아이디 및 비밀번호, 상기 아이디를 포함하는 바코드 또는 QR 코드 등을 이용해서 상기 전용 앱 실행 시 로그인 절차를 수행하여, 해당 전용 앱의 하나 이상의 기능 (예를 들어 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등 포함)을 수행할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 수집 메뉴가 선택되는 경우, 상기 단말 은 사용자 설정에 따른 하나 이상의 시각 세트 장치로부터 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집하기 위해서, 상기 선택된 수집 메 뉴에 대응하는 수집 화면을 표시한다. 여기서, 상기 수집 화면은 사용자 선택(또는 사용자 입력/터치/제어)에 따라 해당 단말과 연동하는 하나 이상의 시각 세트 장치를 선택하기 위한 정보 수집 대상 선택 항목, 선택 된 정보 수집 대상으로부터 수집할 정보의 종류를 선택하기 위한 수집 정보 종류 선택 항목, 선택된 항목에 따 라 해당 정보 수집 대상으로부터 정보를 수집하기 위한 수집 시작 항목 등을 포함한다. 또한, 상기 단말은 해당 단말에 표시되는 수집 화면에서 해당 단말의 사용자 입력(또는 사용자/ 전문가 선택/터치/제어)에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 여기서, 상기 복수의 입력값은 정보 수집 대상(또는 시각 세트 장치 정보/시각 세트 장치의 식별 정보), 수집할 정보의 종류(예를 들 어 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값/센서값 등 포함) 등을 포함한다. 또한, 상기 단말은 상기 수신된 복수의 입력값을 근거로 상기 하나 이상의 시각 세트 장치와 연동하여, 해 당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 이때, 상기 단말은 해당 단말의 사용자와 관련해서 1명의 사용자로부터 1개의 로우 데이터를 수집할 수도 있고, 1명의 사용자로부터 서로 다른 복수의 로우 데이터(또는 어트리뷰트 항목/어노테이 션 단계)에 따른 복수의 로우 데이터)를 수집할 수도 있다. 또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메 타 정보, 사용자 정보, 단말의 식별 정보 등을 상기 서버에 전송한다. 여기서, 상기 단말의 식 별 정보는 MDN, 모바일 IP, 모바일 MAC, Sim 카드 고유정보, 시리얼번호 등을 포함한다. 일 예로, 제 21 단말은 해당 제 21 단말에 미리 설치된 닥터다비드 앱을 실행하고, 닥터다비드 앱 실행 결 과 화면을 표시한다. 이때, 상기 제 21 단말의 제 21 사용자는 제 21 아이디와 제 21 비밀번호를 이용해서 해당 닥터다비드 앱에 로그인한 상태일 수 있다. 또한, 상기 닥터다비드 앱 실행 결과 화면 중에서 수집 메뉴가 선택될 때, 상기 제 21 단말은 상기 선택된 수집 메뉴에 대응하는 수집 화면을 표시한다. 또한, 상기 제 21 단말은 상기 수집 화면에서 해당 제 21 단말의 제 21 사용자 입력에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 또한, 상기 제 21 단말은 상기 수신된 복수의 입력값을 근거로 해당 제 21 단말의 제 21 사용자가 위치한 집에 설치된 시각 세트 장치에 포함된 제 21 카메라부와 연동하여, 해당 제 21 사용자를 포함하는 제 21 로우 데이터, 상기 제 21 로우 데이터와 관련한 메타 정보, 해당 제 21 사용자와 관련한 제 21 사용자 정보 등을 수 집한다. 또한, 상기 제 21 단말은 상기 수집된 해당 제 21 사용자를 포함하는 제 21 로우 데이터, 상기 제 21 로우 데이 터와 관련한 메타 정보, 해당 제 21 사용자와 관련한 제 21 사용자 정보 등을 상기 서버에 전송한다 (S1910). 이후, 상기 서버는 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 사용자 정보, 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 해당 사용자 정보(또는 상기 사용자 정보에 포함된 해당 사용자와 관련한 MBTI 정보/해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수)를 상기 수신된 해당 로우 데이터에 적용(또는 반영/매핑/매칭)한다. 일 예로, 상기 서버는 상기 제 21 단말로부터 전송되는 해당 제 21 사용자를 포함하는 제 21 로우 데이터, 상기 제 21 로우 데이터와 관련한 메타 정보, 해당 제 21 사용자와 관련한 제 21 사용자 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 제 21 사용자 정보를 상기 제 21 로우 데이터에 적용한다(S1920). 이후, 상기 단말은 상기 서버와 연동하여, 해당 사용자 정보(또는 해당 사용자와 관련한 MBTI 정보/ 해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수)가 적용된 로우 데이터를 이용해서, 미리 설정 된 기능을 수행한다. 여기서, 상기 미리 설정된 기능(또는 미리 설정된 이벤트)은, 해당 사용자의 MBTI 유형 맞 춤형 미팅 기능, 해당 사용자의 MBTI 유형 맞춤형 채팅 기능, 해당 사용자의 MBTI 유형 맞춤형 상품 추천 기능, 해당 사용자의 MBTI 유형 맞춤형 게임 상대 추천 기능 등을 포함한다. 즉, 상기 서버는 해당 단말에서 상기 미리 설정된 기능을 시작하는 경우, 해당 서버에 미리 등 록된 복수의 사용자 정보가 적용된 복수의 로우 데이터 중에서, 해당 사용자 정보가 적용된 로우 데이터를 이용 해서 해당 사용자 정보에 포함된 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 근거로 미리 설정된 상생 관계 및/또는 상극 관계에 따른 한 명 이상의 사용자(또는 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터), 하나 이상의 상품 정보 등을 확인(또는 선정)한다. 또한, 상기 서버는 상기 확인된(또는 선정된) 한 명 이상의 사용자에 대한 정보(또는 서로 다른 사용자 정 보가 적용된 하나 이상의 다른 로우 데이터에 대한 정보), 하나 이상의 상품 정보 등을 상기 단말에 제공(또는 전송)한다. 또한, 상기 단말은 상기 서버로부터 제공되는 한 명 이상의 사용자에 대한 정보, 하나 이상의 상품 정보 등을 수신하고, 상기 수신된 한 명 이상의 사용자에 대한 정보, 하나 이상의 상품 정보 등을 표시한다. 또한, 상기 단말에 표시되는 한 명 이상의 사용자에 대한 정보(또는 서로 다른 사용자 정보가 적용된 하나 이상의 다른 로우 데이터에 대한 정보) 중에서 특정 사용자에 대한 정보(또는 특정 다른 로우 데이터에 대한 정 보/특정 다른 사용자 정보가 적용돼 특정 다른 로우 데이터에 대한 정보)가 선택되는 경우, 상기 단말은 상기 서버 및 상기 선택된 특정 사용자에 대한 정보에 대응하는 다른 단말(미도시)과 연동하여, 미팅 기능, 채팅 기능, 게임 기능(예를 들어 슈팅 게임, 농구 게임, 축구 게임 등 포함) 등을 수행한다. 여기서, 상 기 미팅 기능, 채팅 기능, 게임 기능 등은 상기 사용자 정보가 적용된 로우 데이터를 이용해서 가상현실, 증강 현실, 혼합현실, 확장현실, 메타버스, 디지털트윈 등의 형태로 수행(또는 구현/구성)될 수 있다. 또한, 상기 단말에 표시되는 하나 이상의 상품 정보(또는 해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수에 따라 추천된 하나 이상의 상품 정보) 중에서 특정 상품 정보가 선택되는 경우, 상기 단말 은 상기 서버 및 결제 서버(미도시)와 연동하여, 상기 선택된 특정 상품 정보에 대응하는 결제 금액 에 대해 결제 기능을 수행한다. 또한, 결제 기능이 정상적으로 수행된 경우, 상기 단말은 상기 서버(또는 상기 결제 서버)로부터 제 공되는 결제 기능 수행 결과를 수신하고, 상기 수신된 결제 기능 수행 결과를 표시한다. 여기서, 상기 결제 기 능 수행 결과는 상품 정보, 결제 금액, 결제 일자 및 시각 정보 등을 포함한다. 일 예로, 상기 제 21 단말에서 상기 미리 설정된 기능에 포함된 미팅 게임을 시작할 때, 상기 서버는 해당 서버에 미리 등록된 복수의 사용자 정보가 적용된 복수의 로우 데이터 중에서, 상기 제 21 사용자 정보가 적용된 제 21 로우 데이터의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수에서의 상생 관계 및 상극 관계를 고려하여 제 31 사용자 정보가 적용된 제 31 로우 데이터 내지 제 33 사용자 정보가 적용된 제 33 로우 데이터 를 확인한다. 또한, 상기 서버는 상기 확인된 제 31 사용자 정보가 적용된 제 31 로우 데이터에 대한 정보 내지 제 33 사용자 정보가 적용된 제 33 로우 데이터에 대한 정보를 상기 제 21 단말에 전송한다. 또한, 상기 제 21 단말은 상기 서버로부터 전송되는 상기 제 31 사용자 정보가 적용된 제 31 로우 데이터 에 대한 정보 내지 제 33 사용자 정보가 적용된 제 33 로우 데이터에 대한 정보를 수신하고, 상기 수신된 제 31 사용자 정보가 적용된 제 31 로우 데이터에 대한 정보 내지 제 33 사용자 정보가 적용된 제 33 로우 데이터에 대한 정보를 표시한다. 또한, 상기 제 21 단말에 표시되는 제 31 사용자 정보가 적용된 제 31 로우 데이터에 대한 정보 내지 제 33 사 용자 정보가 적용된 제 33 로우 데이터에 대한 정보 중에서 제 32 사용자 정보가 적용된 제 32 로우 데이터에 대한 정보가 선택될 때, 상기 제 21 단말은 상기 서버의 중개에 의해 해당 제 32 사용자 정보가 적용된 제 32 로우 데이터에 대응하는 제 32 사용자가 소지한 제 32 단말과 연동하여, 미팅 기능을 수행한다(S1930). 도 20은 본 발명의 제 4 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다. 먼저, 단말은 하나 이상의 시각 세트 장치(미도시)와 연동하여, 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 여기서, 상기 시각 세 트 장치는 카메라부, 라이다, 아이트래커, 모션 캡처 및 모션트래커, 의료장비(예를 들어 CT, 스캐너, MRI, 의 료용 초음파 등) 등을 포함한다. 또한, 상기 로우 데이터(또는 기초영상/원본 데이터/소스 데이터/시각 데이터/ 실제 현실의 영상)는 실제 현실에서 획득되는(또는 수집되는/촬영되는/측정되는) 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값 등을 포함한다. 여기서, 상기 측정값은 상기 라이다, 상기 아이트래커, 상기 모션 캡처 및 모션트래커, 상기 의료장비 등을 통해 측정되는 영상 정보(또는 3차원 데이터) 등을 포함한다. 또 한, 상기 사용자 정보는 성별, 나이, 체형, 인종, 사용자의 얼굴 이미지, 직업 정보, 해당 사용자와 관련한 MBTI 정보(예를 들어 MBTI 유형, MBTI 유형에 따른 항목별 점수/실제 사용자의 MBTI 선호도 점수 등 포함) 등을 포함한다. 이때, 상기 단말은 해당 단말에 미리 설치된 전용 앱을 실행하고, 전용 앱 실행에 따른 앱 실행 결과 화면을 표시한다. 여기서, 상기 앱 실행 결과 화면은 해당 단말의 사용자와 관련한 하나 이상의 로우 데이 터, 해당 로우 데이터와 관련한 메타 정보 등을 수집하기 위한 수집 메뉴(또는 버튼/항목), 해당 로우 데이터와비교 대상 영상을 근거로 생성될 아바타 및/또는 아이템의 레벨을 선택하기 위한 레벨 선택 메뉴, 수집된 정보 나 서버로부터 제공되는 정보를 표시하기 위한 보기 메뉴, 해당 로우 데이터와 관련해서 생성된 라스트 레 벨 영상에 대한 레벨업 기능 수행을 위한 상점 메뉴, 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게 임 대기실 메뉴, 환경 설정을 위한 설정 메뉴 등을 포함한다. 이때, 상기 단말은 해당 전용 앱을 제공하는 상기 서버에 회원 가입한 상태로, 회원 가입에 따른 아이디 및 비밀번호, 상기 아이디를 포함하는 바코드 또는 QR 코드 등을 이용해서 상기 전용 앱 실행 시 로그인 절차를 수행하여, 해당 전용 앱의 하나 이상의 기능 (예를 들어 로우 데이터 수집 기능, 레벨 선택 라벨링 기능, 레벨 강화 기능, 게임 참여 기능, 라스트 레벨 영 상 활용 기능 등 포함)을 수행할 수 있다. 또한, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 수집 메뉴가 선택되는 경우, 상기 단말 은 사용자 설정에 따른 하나 이상의 시각 세트 장치로부터 해당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집하기 위해서, 상기 선택된 수집 메 뉴에 대응하는 수집 화면을 표시한다. 여기서, 상기 수집 화면은 사용자 선택(또는 사용자 입력/터치/제어)에 따라 해당 단말과 연동하는 하나 이상의 시각 세트 장치를 선택하기 위한 정보 수집 대상 선택 항목, 선택 된 정보 수집 대상으로부터 수집할 정보의 종류를 선택하기 위한 수집 정보 종류 선택 항목, 선택된 항목에 따 라 해당 정보 수집 대상으로부터 정보를 수집하기 위한 수집 시작 항목 등을 포함한다. 또한, 상기 단말은 해당 단말에 표시되는 수집 화면에서 해당 단말의 사용자 입력(또는 사용자/ 전문가 선택/터치/제어)에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 여기서, 상기 복수의 입력값은 정보 수집 대상(또는 시각 세트 장치 정보/시각 세트 장치의 식별 정보), 수집할 정보의 종류(예를 들 어 시퀀셜 정지영상(또는 복수의 시퀀셜 정지영상), 동영상, 측정값/센서값 등 포함) 등을 포함한다. 또한, 상기 단말은 상기 수신된 복수의 입력값을 근거로 상기 하나 이상의 시각 세트 장치와 연동하여, 해 당 단말의 사용자와 관련한 하나 이상의 로우 데이터, 해당 로우 데이터와 관련한 메타 정보, 사용자 정보 등을 수집한다. 이때, 상기 단말은 해당 단말의 사용자와 관련해서 1명의 사용자로부터 1개의 로우 데이터를 수집할 수도 있고, 1명의 사용자로부터 서로 다른 복수의 로우 데이터(또는 어트리뷰트 항목/어노테이 션 단계에 따른 복수의 로우 데이터)를 수집할 수도 있다. 또한, 상기 단말은 상기 수집된 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메 타 정보, 사용자 정보, 단말의 식별 정보 등을 상기 서버에 전송한다. 여기서, 상기 단말의 식 별 정보는 MDN, 모바일 IP, 모바일 MAC, Sim 카드 고유정보, 시리얼번호 등을 포함한다. 또한, 상기 서버는 상기 단말로부터 전송되는 상기 하나 이상의 로우 데이터(또는 기초영상), 해당 로우 데이터와 관련한 메타 정보, 사용자 정보, 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 해당 사용자 정보(또는 상기 사용자 정보에 포함된 해당 사용자와 관련한 MBTI 정보/해당 사용자의 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수)를 상기 수신된 해당 로우 데이터에 적용(또는 반영/매핑/매칭)한다. 일 예로, 제 31 단말은 해당 제 31 단말에 미리 설치된 닥터다비드 앱을 실행하고, 닥터다비드 앱 실행 결 과 화면을 표시한다. 이때, 상기 제 31 단말의 제 31 사용자는 제 31 아이디와 제 31 비밀번호를 이용해서 해당 닥터다비드 앱에 로그인한 상태일 수 있다. 또한, 상기 닥터다비드 앱 실행 결과 화면 중에서 수집 메뉴가 선택될 때, 상기 제 31 단말은 상기 선택된 수집 메뉴에 대응하는 수집 화면을 표시한다. 또한, 상기 제 31 단말은 상기 수집 화면에서 해당 제 31 단말의 제 31 사용자 입력에 따라 복수의 입력 항목에 대응하는 복수의 입력값을 수신한다. 또한, 상기 제 31 단말은 상기 수신된 복수의 입력값을 근거로 해당 제 31 단말의 제 31 사용자가 위치한 집에 설치된 시각 세트 장치에 포함된 제 31 카메라부와 연동하여, 해당 제 31 사용자를 포함하는 제 31 로우 데이터, 상기 제 31 로우 데이터와 관련한 메타 정보, 해당 제 31 사용자와 관련한 제 31 사용자 정보 등을 수 집한다. 또한, 상기 제 31 단말은 상기 수집된 해당 제 31 사용자를 포함하는 제 31 로우 데이터, 상기 제 31 로우 데이 터와 관련한 메타 정보, 해당 제 31 사용자와 관련한 제 31 사용자 정보 등을 상기 서버에 전송한다. 또한, 상기 서버는 상기 제 31 단말로부터 전송되는 해당 제 31 사용자를 포함하는 제 31 로우 데이터, 상 기 제 31 로우 데이터와 관련한 메타 정보, 해당 제 31 사용자와 관련한 제 31 사용자 정보 등을 수신한다. 또한, 상기 서버는 상기 수신된 제 31 사용자 정보를 상기 제 31 로우 데이터에 적용한다(S2010). 이후, 상기 서버는 개설된 복수의 게임 대기방 중 어느 하나의 게임 대기방에 입장하는 복수의 단말 을 대상으로 게임 시작 시, MBTI 점수 체계를 제정(또는 결정/설정)한다. 이때, 상기 MBTI 점수 체계는 해당 게 임룸(또는 개설된 게임방)에 대응하는 게임과 관련해서 경쟁 게임을 진행하고 승패를 결정짓는 구성 요소로, 해 당 게임과 관련한 헌법, 법률, 규칙 등을 포함하며, 해당 게임에 참여하는 사용자(또는 게임 참가자)와 관련한 게임 캐릭터(또는 아바타/상기 사용자 정보가 적용된 로우 데이터)의 MBTI 유형 및/또는 게임 캐릭터(또는 아바 타/상기 사용자 정보가 적용된 로우 데이터)의 MBTI 유형에 따른 상극과 상생의 법칙으로 승부를 결정짓는 방식 일 수 있다. 여기서, 상기 게임과 관련한 헌법은 상극과 상생의 점수 비교 방식을 결정하는 것이고, 상기 게임 과 관련한 법률은 해당 헌법의 내용을 구체화한 것이고, 상기 게임과 관련한 규칙은 상극의 점수가 높은 쪽이 경쟁에서 유리한 것, 상생의 점수의 유사도가 높을수록 콤비 플레이의 성공률이 높아지는 것 등과 같이 구체적 으로 수치화된 내용(또는 조건)을 포함한다. 즉, 상기 단말에 표시되는 앱 실행 결과 화면에서 미리 설정된 게임 대기실 메뉴가 선택되는 경우, 상기 단말은 게임 참여를 위해 개설된 게임방 목록을 제공하거나 새로운 게임방을 개설하기 위해서, 상기 선택 된 게임 대기실 메뉴에 대응하는 게임 대기실 화면을 표시한다. 여기서, 상기 게임 대기실화면은 게임 참여를 위해 개설된 게임방 목록을 제공하기 위한 게임방 리스트 항목, 새로운 게임방을 개설하기 위한 게임방 생성 항 목 등을 포함한다. 또한, 상기 단말에 표시되는 게임 대기실화면 내의 게임방 리스트 항목에 포함된 하나 이상의 게임 대기방 중에서 어느 하나의 게임 대기방이 선택되는 경우, 상기 단말은 상기 서버와 연동하여, 상기 선택된 게임 대기방에 대응하는 게임룸에 입장(또는 참여)한다. 또한, 상기 단말에서 참여한 게임룸을 개설한 방장에 의해 미리 설정된 게임 시작 메뉴가 선택되는 경우 (또는 해당 게임룸과 관련해서 미리 설정된 게임 시작 조건을 만족하는 경우), 상기 서버는 해당 게임에 참여하는 복수의 게임 참가자가 소지한 복수의 단말, 해당 게임을 관전 중이거나 미리 설정된 게임상의 국 가기관/회사/상점에 소속된 사용자가 소지한 다른 복수의 단말, 해당 게임과 유사한 게임에 참여했던 다른 사용자가 소지한 또 다른 복수의 단말 등과 연동하여, 해당 게임(또는 해당 게임룸)과 관련한 MBTI 점수 체계를 제정한다. 여기서, 상기 미리 설정된 게임 시작 조건은 미리 설정된 게임 참가자 수를 만족하는 경우, 미리 설정된 게임 시작 시각을 만족하는 경우 등을 포함한다. 이때, 상기 서버는 미리 설정된 조건(예를 들어 게임 시작 후 미리 설정된 시간(일 예로 5분, 10분 등 포함)이 지난 경우, 미리 설정된 참여자(일 예로 10 명) 이상이 MBTI 점수 체계 제정에 참여한 경우 등 포함)을 만족할 때까지 해당 게임과 관련한 MBTI 점수 체계 를 제정한다. 여기서, 상기 미리 설정된 조건을 충족할 때까지 상기 게임과 관련한 MBTI 점수 체계가 제정되지 않은 경우, 상기 서버는 해당 게임과 관련해서 미리 설정된 디폴트값으로 해당 MBTI 점수 체계를 제정(또 는 설정)할 수도 있다. 일 예로, 상기 닥터다비드 앱 실행 결과 화면 중에서 게임 대기실 메뉴가 선택될 때, 상기 제 31 단말은 상기 선택된 게임 대기실 메뉴에 대응하는 게임 대기실 화면을 표시한다. 또한, 상기 게임 대기실 화면에 포함된 하나 이상의 게임 대기방 중에서 제 5 농구 자유투 게임 대기방이 선택 될 때, 상기 제 31 단말은 상기 서버와 연동하여, 상기 선택된 제 5 농구 자유투 게임 대기방에 대응하는 제 5 농구 자유투 게임룸에 입장한다. 또한, 상기 제 5 농구 자유투 게임룸을 개설한 제 32 단말의 사용자에 의해 미리 설정된 게임 시작 조건인 2명의 게임 참가자 수를 만족할 때, 상기 서버는 상기 농구 자유투 게임에 참여하는 제 31 단말 및 제 32 단말과, 해당 농구 자유투 게임을 관전 중인 제 41 단말 내지 제 45 단말과, 해당 농구 자유투 게임 에 참여했던 제 51 단말 내지 제 60 단말과 연동하여, 해당 제 5 농구 자유투 게임룸과 관련한 제 5 MBTI 점수 체계를 제정한다. 여기서, 상기 제 5 MBTI 점수 체계는 상극의 점수가 높은 쪽이 경쟁(일 예로 공격, 수비 등 포함)에서 유리한 것, 상생의 점수의 유사도가 높을수록 콤비 플레이(일 예로 패스, 수비, 공격 등 포 함)의 성공률이 높아지는 것 등을 포함한다(S3220). 이후, 상기 단말은 상기 서버와 연동하여, 해당 게임에 참여하는 해당 단말의 사용자(또는 게임 참가자)와 관련한 게임 캐릭터(또는 게임 캐릭터의 MBTI 유형/상기 사용자 정보가 적용된 로우 데이터)와, 해당 게임에 참여한 다른 게임 참가자와 관련한 게임 캐릭터(또는 게임 캐릭터의 MBTI 유형/상기 사용자 정보가 적용된 로우 데이터)를 참조하여, 게임 참가자별 MBTI 선택라벨링(또는 복수의 단말의 게임 참가자/사용자와 관련한 게임 캐릭터별 MBTI 선택라벨링) 기능을 수행한다. 여기서, 상기 MBTI 선택라벨링(또는 MBTI 선택레이블 링)은 해당 게임에 참여한 모든 사용자와 관련한 게임 캐릭터에 대해서 해당 단말의 사용자가 생각하는 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 설정하는(또는 붙이는) 라벨링 방법을 나타낸다. 이때, 상 기 MBTI 유형에 따른 항목별 점수는 미리 설정된 범위(예를 들어 0점 ~ 100점) 중에서 선택될 수 있다. 이와 같이, 상기 단말은 해당 게임에 참여한 복수의 게임 참가자가 각각 소지한 게임 캐릭터(예를 들어 아 바타, 아이템 등 포함)와 관련해서, 각각의 게임 참가자별 MBTI 선택라벨링(또는 사용자별 MBTI 선택라벨링) 기 능을 수행하여, 게임 참가자별 게임 캐릭터에 대한 MBTI 유형과 항목별 점수를 각각 설정(또는 수신/입력)할 수 있다. 또한, 상기 서버는 해당 게임룸에 참여한 복수의 단말을 대상으로 상기 MBTI 선택라벨링 기능 수행에 따른 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 수집한다. 일 예로, 상기 제 31 단말은 게임 참가자별 MBTI 선택라벨링을 수행하기 위해서 MBTI 선택라벨링 화면을 표시한 다. 또한, 상기 제 31 단말은 해당 제 31 단말의 제 31 사용자 입력에 따라, 해당 제 31 사용자와 관련한 상기 제 31 사용자 정보가 적용된 상기 제 31 로우 데이터에 대응하는 제 31 게임 캐릭터에 대한 제 31-1 MBTI 유형(예 를 들어 ENTP) 및 해당 제 31-1 MBTI 유형에 따른 제 31-1 항목별 점수(예를 들어 E: 90점, N: 85점, T: 80점, P: 85점)와, 해당 제 32 사용자와 관련한 해당 제 32 사용자 정보가 적용된 제 32 로우 데이터에 대응하는 제 32 게임 캐릭터에 대한 제 32-1 MBTI 유형(예를 들어 ESFP) 및 해당 제 31-2 MBTI 유형에 따른 제 31-2 항목별 점수(예를 들어 E: 85점, S: 80점, F: 75점, P: 90점) 등을 포함하는 제 31 사용자 MBTI 선택라벨링에 대한 정 보를 수신한다. 또한, 상기 제 31 단말은 상기 수신된 제 31 사용자 MBTI 선택라벨링에 대한 정보, 상기 제 31 단말의 식별 정 보 등을 상기 서버에 전송한다. 또한, 상기 서버는 상기 제 31 단말로부터 전송되는 제 31 사용자 MBTI 선택라벨링에 대한 정보, 상기 제 31 단말의 식별 정보 등을 수신한다. 또한, 상기 서버는 상기 제 32 단말로부터 전송되는 제 32 사용자 MBTI 선택라벨링에 대한 정보, 상기 제 32 단말의 식별 정보 등을 수신한다. 여기서, 상기 제 32 사용자 MBTI 선택라벨링에 대한 정보는 해당 제 32 단 말의 제 32 사용자 입력에 따른, 해당 제 31 사용자와 관련한 제 31 게임 캐릭터에 대한 제 32-1 MBTI 유형(예 를 들어 ENFP) 및 해당 제 32-1 MBTI 유형에 따른 제 32-1 항목별 점수(예를 들어 E: 80점, N: 85점, F: 75점, P: 80점)와, 해당 제 32 사용자와 관련한 제 32 게임 캐릭터에 대한 제 32-2 MBTI 유형(예를 들어 ESFP) 및 해 당 제 32-2 MBTI 유형에 따른 제 32-1 항목별 점수(예를 들어 E: 80점, S: 85점, F: 80점, P: 85점) 등을 포함 한다(S2030). 이후, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가 자별 MBTI 선택라벨링에 대한 정보(또는 복수의 단말의 게임 참가자/사용자와 관련한 게임 캐릭터별 MBTI 선택라벨링에 대한 정보), 사용자별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 입 력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결 과)를 근거로 해당 게임에서의 승패를 결정한다. 즉, 상기 서버는 해당 게임에 참여한 복수의 단말의 사용자(또는 게임 참가자)와 관련한 게임 참가자 별 MBTI 선택라벨링에 대한 정보(또는 복수의 단말의 게임 참가자/사용자와 관련한 게임 캐릭터별 MBTI 선 택라벨링에 대한 정보), 사용자별 게임 캐릭터에 대한 정보, 사용자별 사용자 정보, MBTI 점수 체계 등을 미리 설정된 승패 결정 모델의 입력값으로 하여 기계 학습(또는 인공지능/딥 러닝)을 수행하고, 기계 학습 결과(또는 인공지능 결과/딥 러닝 결과)를 근거로 해당 게임에서의 승패를 결정한다. 여기서, 상기 승패 결정 모델(또는 MBTI 점수체계 예측 모델)은 통계적 모델, 회귀 모델, 딥러닝 모델 등을 포함한다. 이때, 상기 서버는 상 기 승패 결정 모델에 따라 게임의 승패를 결정하는 과정과 관련한 화면(또는 사용자 인터페이스)을 해당 게임에 참여한 복수의 단말에 각각 제공할 수도 있다. 이와 같이, 상기 서버는 상기 승패 결정 모델의 출력값인 전체 게임 참가자의 게임 캐릭터별 MBTI 라벨별 점수를 예측하고, 상기 예측된 전체 게임 참가자의 게임 캐릭터별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정한다. 즉, 상기 서버는 집단 지성화를 통해 상기 수집된 복수의 단말별로 게임 참가자별 MBTI 선택라벨링에 대한 정보를 근거로 게임 참가자별 게임 캐릭터에 대한 MBTI 유형 및 MBTI 유형에 따른 항목별 점수를 설정(또는 산 출)한다. 또한, 상기 서버는 상기 게임 결과(또는 해당 게임 결과에 대한 정보)를 해당 게임에 참여한 복수의 단말 에 각각 전송한다. 또한, 상기 복수의 단말은 상기 서버로부터 전송되는 해당 게임 결과를 각각 수신하고, 상기 수신된 게임 결과를 출력(또는 표시)한다. 또한, 상기 서버는 해당 게임에서의 승패 결과에 따라, 게임 참가자별 게임 캐릭터의 레벨 유지/업/다운 기능을 수행한다. 즉, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 게임 캐릭터(예를 들어 아바타, 아이템 등 포함)의 레벨을 유지/업/다운한다. 또한, 상기 서버는 상기 게임 결과를 근거로 MBTI 점수를 해당 게임 참가자의 해당 게임 캐릭터(또는 해당 게임 참가자의 계정)에 적립(또는 제공)한다. 또한, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 사용자 정보 내 의 MBTI 유형, MBTI 유형에 따른 항목별 점수 등을 업데이트(또는 업그레이드)한다. 일 예로, 상기 수신된 제 31 사용자 MBTI 선택라벨링에 대한 정보, 상기 수신된 제 32 사용자 MBTI 선택라벨링 에 대한 정보, 제 31 사용자의 제 31 게임 캐릭터에 대한 정보(또는 상기 제 31 사용자 정보가 적용된 상기 제 31 로우 데이터에 대한 정보), 제 32 사용자의 제 32 게임 캐릭터에 대한 정보(또는 상기 제 32 사용자 정보가 적용된 상기 제 32 로우 데이터에 대한 정보), 상기 제 31 사용자 정보, 제 32 사용자 정보, 상기 제정된 제 5 MBTI 점수 체계 등을 상기 승패 결정 모델의 입력값으로 하여 기계 학습을 수행하고, 기계 학습 결과를 근거로 해당 제 5 농구 자유투 게임의 승자와 패자를 결정한다. 또한, 상기 서버는 해당 게임에서의 승패 결과에 따라, 게임 참가자별 게임 캐릭터의 레벨 유지/업/다운 기능을 수행한다. 즉, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 게임 캐릭터(예를 들어 아바타, 아이템 등 포함)의 레벨을 유지/업/다운한다. 또한, 상기 서버는 상기 게임 결과를 근거로 MBTI 점수를 해당 게임 참가자의 해당 게임 캐릭터(또는 해당 게임 참가자의 계정)에 적립(또는 제공)한다. 또한, 상기 서버는 상기 게임 결과를 근거로 게임 참가자별로 해당 게임 참가자와 관련한 사용자 정보 내 의 MBTI 유형, MBTI 유형에 따른 항목별 점수 등을 업데이트(또는 업그레이드)한다. 이때, 상기 서버는 해당 제 5 MBTI 점수 체계에 따라, 자유투 슈터인 제 31 사용자와 관련한 레벨 5로 트 레이닝된 제 31 게임 캐릭터에 대한 선택라벨링에 따른 MBTI 유형(예를 들어 ENTP) 및 수비수인 제 32 사용자와 관련한 레벨 4로 트레이닝된 제 32 게임 캐릭터에 대한 선택라벨링에 따른 MBTI 유형(예를 들어 ESFP)을 근거로 상극 관계인 N 점수(예를 들어 85점)와 S 점수(예를 들어 82.5점) 및 T 점수(예를 들어 77.5점)와 F 점수(예를 들어 77.5점)를 비교하여, 해당 제 31 게임 캐릭터의 점수(예를 들어 상극 관계인 항목의 점수 합이 162.5점)가 해당 제 32 게임 캐릭터의 점수(예를 들어 상극 관계인 항목의 점수 합이 160점)보다 높으므로, 상기 제 31 게 임 캐릭터의 승리로 결정한다. 또한, 상기 서버는 해당 제 5 농구 자유투 게임의 게임 결과(예를 들어 제 31 사용자가 승리, 제 32 사용 자가 패배, 게임 승패에 따라 해당 제 31 사용자와 관련한 제 31 게임 캐릭터의 레벨//MBTI 항목별 점수를 0.001% 업시키고 MBTI 점수 10점을 제공, 해당 제 32 사용자와 관련한 제 32 게임 캐릭터의 레벨을 유지하고 MBTI 점수 3점을 제공 등 포함)를 상기 제 31 단말 및 상기 제 32 단말에 각각 전송한다. 또한, 상기 제 31 단말 및 상기 제 32 단말은 상기 서버로부터 전송되는 해당 제 5 농구 자유투 게임의 게 임 결과를 각각 수신하고, 상기 수신된 해당 제 5 농구 자유투 게임의 게임 결과를 각각 표시한다. 또한, 상기 서버는 해당 제 5 농구 자유투 게임의 게임 결과를 근거로 해당 제 31 사용자와 관련한 제 31 사용자 정보 내의 MBTI 유형에 따른 항목별 점수(또는 상기 선택라벨링에 의한 MBTI 유형에 따른 항목별 점수) 를 0.001% 업시키고, 해당 제 31 사용자와 관련한 MBTI 점수를 10점 증가시킨다. 또한, 상기 서버는 해당 제 5 농구 자유투 게임의 게임 결과를 근거로 해당 제 32 사용자와 관련한 제 32 사용자 정보 내의 MBTI 유형에 따른 항목별 점수(또는 상기 선택라벨링에 의한 MBTI 유형에 따른 항목별 점수) 를 그대로 유지하고, 해당 제 32 사용자와 관련한 MBTI 점수를 3점 증가시킨다(S2040). 본 발명의 실시예는 앞서 설명된 바와 같이, 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하고, 설 정된 레벨, 로우 데이터 등에 대해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값 인 라스트 레벨 영상에 대해서 레벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해 서 게임에 참여하고, 해당 게임에 참여한 게임 참가자 및 관전자 참여에 의해 MBTI 점수 체계를 제정하고, 게임 참가자 자신의 아바타 및 아이템과 다른 게임 참가자의 아바타 및 아이템을 참조하여 전체 게임 참가자에 대한 MBTI 선택라벨링 기능을 수행하고, 게임 참가자별 MBTI 선택라벨링에 대한 정보, MBTI 점수체계 등에 대해서 승 패 결정 모델을 통해 다른 학습 기능을 수행하고, 승패 결정 모델의 출력값인 전체 게임 참가자의 아바타 및 아 이템별 MBTI 라벨별 점수를 예측하고, 예측된 전체 게임 참가자의 아바타 및 아이템별 MBTI 라벨별 점수, MBTI 점수체계, 상생과 상극의 라벨별 점수를 근거로 게임의 승패를 결정하고, 결정된 게임 결과를 근거로 게임 참가 자별 아바타 및 아이템의 레벨을 유지/업/다운하여, 로우 데이터와 관련한 아바타 및/또는 아이템을 사용자에게 제공하고, 로우 데이터에 대한 라벨링을 통해 인공지능의 추론 능력을 향상시키고, 로우 데이터 등을 근거로 생 성된 라스트 레벨 영상에 대응하는 아바타 및 아이템을 이용해서 다양한 게임을 수행함에 따라 사용자의 흥미를 높일 수 있다. 또한, 본 발명의 실시예는 앞서 설명된 바와 같이, 사용자로부터 제공되는 로우 데이터에 대해서 레벨을 설정하 고, 설정된 레벨, 로우 데이터 등에 대해서 미리 설정된 생성 모델을 통해 학습 기능을 수행하고, 생성 모델의 출력값인 라스트 레벨 영상에 대해서 레벨 강화 기능 등을 수행하고, 최종 레벨이 적용된 라스트 레벨 영상을 이용해서 문자메시지 송/수신 기능, 게시물 작성 기능, 이모티콘/아이콘 생성 및 적용 기능, 채팅 기능, 외부 서버에서 제공하는 게임 내 아바타 또는 아이템에 적용하는 기능 등을 수행하여, 인공지능에 따른 결과물인 라 스트 레벨 영상에 대응하는 아바타 및 아이템을 다양하게 활용할 수 있다. 또한, 본 발명의 실시예는 앞서 설명된 바와 같이, 사용자로부터 제공되는 로우 데이터에 MBTI 유형 및 해당 MBTI 유형에 따른 항목별 점수를 포함하는 사용자 정보를 적용하고, 사용자 정보가 적용된 로우 데이터를 이용 해서 게임 기능을 수행하여, 사용자의 MBTI 유형에 따른 다양한 게임을 수행함에 따라 사용자의 관심 및 흥미를 유발할 수 있다. 전술된 내용은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어 나지 않는 범위에서 수정 및 변형이 가능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상 을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0055550", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 집단 지성을 이용한 정보 처리 시스템의 구성을 나타낸 블록도이다. 도 2는 본 발명의 실시예에 따른 서버에서 작동하여 단말에서 출력 및 생성되는 시각렌더링의 원리를 나타내는 도이다. 도 3은 본 발명의 실시예에 따른 기초 영상정보가 계속 수집될 경우, 기존 데이터와 같이 하나의 모델로 적용되 는 원리를 나타내는 도이다. 도 4는 본 발명의 실시예에 따른 사용자 및 참여자 및 기업들이 이익을 창출하고 돈을 벌면서 재미요소를 배가 하는 플랫폼으로서의 원순환 구조를 나타내는 도이다. 도 5는 본 발명의 실시예에 따른 사용자의 메타데이터인 영상정보의 예를 나타낸 도이다. 도 6은 본 발명의 실시예에 따른 도 6에 대한 복수의 결과물의 예를 나타낸 도이다. 도 7 및 도 8은 본 발명의 실시예에 따른 가면 얼굴 형태의 예를 나타낸 도이다. 도 9 및 도 10은 본 발명의 실시예에 따른 원숭이 얼굴 형태의 예를 나타낸 도이다. 도 11은 본 발명의 실시 예에 따른 생성 알고리즘을 이용한 가상 아바타 및 아이템의 생성 및/또는 출력 플랫폼 제공 방법을 나타내는 도다. 도 12는 본 발명의 제 1 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다. 도 13 내지 도 17은 본 발명의 실시예에 따른 단말의 화면의 예를 나타낸 도이다. 도 18은 본 발명의 제 2 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다. 도 19는 본 발명의 제 3 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다. 도 20은 본 발명의 제 4 실시예에 따른 집단 지성을 이용한 정보 처리 방법을 나타낸 흐름도이다."}
