{"patent_id": "10-2017-0094968", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0012065", "출원번호": "10-2017-0094968", "발명의 명칭": "화자 검증 방법 및 음성인식 시스템", "출원인": "네이버 주식회사", "발명자": "이봉진"}}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성인식 장치와 음성인식 서버를 포함하는 음성인식 시스템에 있어서, 상기 음성인식 서버에 의하여,상기 음성인식 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하는 단계;상기 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하는 단계;상기 음성 신호에서 화자 특징 벡터를 추출하여 상기 화자 특징 벡터를 등록된 화자 특징 벡터(registeredspeaker feature vector)와 비교하고, 상기 비교 결과에 따라 상기 음성 신호의 화자가 등록된 제2 화자(registered second speaker)라고 결정하는 단계;상기 제2 화자의 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신하는 단계;상기 휴대 장치로부터 승인 입력을 수신하는 단계; 및상기 음성인식 결과에 대응하는 동작을 실행하는 단계를 포함하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 등록된 제2 화자(registered second speaker)는 상기 음성인식 시스템에 등록된 복수의 사용자들 중 하나인 것을 특징으로 하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 음성인식 장치에 의하여, 카메라를 이용하여 상기 음성 신호가 생성된 시점의 영상을 포함하는 영상 신호를 생성하고, 상기 영상 신호를 상기 음성인식 서버로 송신하는 단계; 및상기 음성인식 서버에 의하여, 상기 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호와 함께 상기 영상 신호를 송신하는 단계를 더 포함하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 영상 신호는 상기 제1 화자의 음성이 발생한 방향의 영상을 포함하는 것을 특징으로 하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서, 상기 음성인식 서버에 의하여, 상기 비교 결과에 따라 상기 음성 신호의 화자가 등록되지 않은 사용자(unregistered user)라고 결정하는 경우, 상기 음성인식 결과에 대응하는 동작을 실행하지 않는 단계를 더 포함하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서, 상기 음성인식 서버에 의하여, 공개특허 10-2019-0012065-3-상기 음성인식 결과에 대응하는 동작 및 상기 제2 화자의 설정 중 적어도 하나를 기초로 상기 휴대 장치를 이용한 검증 절차의 실행 여부를 결정하는 단계를 더 포함하고,상기 검증 절차는,상기 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신하는 단계; 및상기 휴대 장치로부터 승인 입력을 수신하는 단계를 포함하는 것을 특징으로 하는 음성인식 시스템의 화자 검증방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서, 상기 휴대 장치를 이용한 검증 절차의 실행 여부를 결정하는 단계는, 상기 음성인식 결과에 따른 동작이 상기제2 화자가 미리 설정한 사전 승인 동작 리스트에 포함되는 경우, 상기 검증 절차의 실행을 결정하는 단계를 포함하는 것을 특징으로 하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서, 상기 음성인식 서버에 의하여, 상기 음성인식 결과에 따른 동작이 상기 제2 화자가 미리 설정한 사후 통지 동작리스트에 포함되는 경우, 상기 음성인식 결과에 대응하는 상기 동작이 실행된 후에, 상기 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신하는 단계를 더 포함하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6 항에 있어서, 상기 휴대 장치를 이용한 검증 절차의 실행 여부를 결정하는 단계는, 상기 휴대 장치의 위치 및 현재 시간 중적어도 하나가 사전 승인 조건에 부합하는 경우, 상기 검증 절차의 실행을 결정하는 단계를 포함하는 것을 특징으로 하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 사전 승인 조건은 상기 제2 화자에 의해 미리 설정되거나, 상기 제2 화자의 행동 패턴에 기초하여 결정되는 것을 특징으로 하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항에 있어서, 상기 휴대 장치에 의하여,상기 음성인식 서버로부터 상기 음성인식 결과 및 상기 음성 신호를 수신하는 단계;상기 음성인식 결과가 상기 휴대 장치 상에 표시되는 단계;상기 음성 신호를 재생하는 단계;상기 음성인식 결과에 대응하는 동작의 실행을 승인 또는 거절하기 위한 상기 제2 화자의 승인 입력 또는 거절입력을 수신하는 단계; 및상기 승인 입력 또는 거절 입력을 상기 음성인식 서버로 송신하는 단계를 더 포함하는 음성인식 시스템의 화자검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1 항에 있어서, 상기 음성인식 서버에 의하여,공개특허 10-2019-0012065-4-상기 휴대 장치로부터 거절 입력을 수신하는 단계; 및상기 음성인식 결과에 대응하는 동작을 실행하지 않는 단계를 더 포함하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서, 상기 음성인식 서버에 의하여,상기 휴대 장치로부터 상기 제2 화자의 응답 음성을 포함하는 응답 음성 신호를 수신하는 단계; 및상기 음성인식 장치에 의해 상기 제2 화자의 응답 음성이 재생되도록, 상기 응답 음성 신호를 상기 음성인식 장치로 송신하는 단계를 더 포함하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1 항에 있어서, 상기 음성인식 서버에 의하여, 상기 휴대 장치로부터 승인 입력이 수신되면, 상기 음성 신호에서 추출된 상기화자 특징 벡터를 이용하여 상기 제2 화자의 상기 등록된 화자 특징 벡터를 개선하는 단계를 더 포함하는 음성인식 시스템의 화자 검증 방법."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "음성인식 시스템의 음성인식 서버의 프로세서가 제1항, 제5항 내지 제10항, 제12항, 제13항 및 제14항 중 어느한 항의 화자 검증 방법을 실행하도록 하는 명령어들을 포함하는 하나 이상의 프로그램이 기록된 컴퓨터로 읽을수 있는 기록 매체."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "음성인식 장치 및 휴대 장치와 통신하는 통신 모듈; 및상기 통신 모듈을 이용하여 상기 음성인식 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하고,상기 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하고,상기 음성 신호에서 화자 특징 벡터를 추출하고, 상기 화자 특징 벡터를 등록된 화자 특징 벡터(registeredspeaker feature vector)와 비교하고, 상기 비교 결과에 따라 상기 음성 신호의 화자가 등록된 제2 화자(registered second speaker)라고 결정하고,상기 통신 모듈을 이용하여 상기 제2 화자의 상기 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신하고,상기 통신 모듈을 이용하여 상기 휴대 장치로부터 승인 입력을 수신하고,상기 음성인식 결과에 대응하는 동작을 실행하도록 구성되는 프로세서를 포함하는 음성인식 서버."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 프로세서는,상기 휴대 장치로부터 상기 거절 입력과 함께 상기 제2 화자의 응답 음성을 포함하는 응답 음성 신호를 수신하고,상기 음성인식 장치에 의해 상기 제2 화자의 응답 음성이 재생되도록, 상기 통신 모듈을 이용하여 상기 응답 음성 신호를 상기 음성인식 장치로 송신하도록 구성되는 것을 특징으로 하는 음성인식 서버."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16 항 또는 제17 항의 음성인식 서버와 통신하는 통신 모듈;공개특허 10-2019-0012065-5-오디오 신호를 생성하는 마이크로폰; 상기 오디오 신호로부터 제1 화자의 음성을 포함하는 음성 신호를 검출하고, 상기 음성 신호를 상기 음성인식서버로 송신하고, 상기 음성인식 서버로부터 합성음 신호를 수신하도록 구성되는 프로세서; 및상기 합성음 신호에 대응하는 상기 합성음을 재생하는 스피커를 포함하는 음성인식 장치."}
{"patent_id": "10-2017-0094968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "음성인식 서버와 음성인식 장치를 포함하는 음성인식 시스템으로서,상기 음성인식 장치는 상기 음성인식 서버와 통신하는 제1 통신 모듈, 오디오 신호를 생성하는 마이크로폰, 상기 오디오 신호로부터 상기 음성 신호를 검출하고 상기 음성 신호를 상기 음성인식 서버로 송신하고 상기 음성인식 서버로부터 합성음 신호를 수신하는 제1 프로세서, 및 상기 합성음 신호에 대응하는 합성음을 재생하는 스피커를 포함하고,상기 음성인식 서버는 제2 프로세서, 및 상기 음성인식 장치 및 휴대 장치와 통신하는 제2 통신 모듈을 포함하고,상기 제2 프로세서는,상기 음성인식 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하고,상기 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하고,상기 음성 신호에서 화자 특징 벡터를 추출하고, 상기 화자 특징 벡터를 등록된 화자 특징 벡터(registeredspeaker feature vector)와 비교하고, 상기 비교 결과에 따라 상기 음성 신호의 화자가 등록된 제2 화자(registered second speaker)라고 인식하고,상기 제2 화자의 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신하고,상기 휴대 장치로부터 승인 입력을 수신하면, 상기 음성인식 결과에 대응하는 동작을 실행하도록 구성되는 것을특징으로 하는 음성인식 시스템."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "화자를 정확하게 인식할 수 있는 음성 인식 시스템 및 이의 화자 검증 방법이 제공된다. 화자 검증 방법은 상기 음성인식 서버에 의하여, 상기 음성인식 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하는 단계, 상 기 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하는 단계, 상기 음성 신호에서 화자 특징 벡 터를 추출하여 상기 화자 특징 벡터를 등록된 화자 특징 벡터와 비교하고, 상기 비교 결과에 따라 상기 음성 신 호의 화자가 등록된 제2 화자라고 결정하는 단계, 상기 제2 화자의 휴대 장치로 상기 음성인식 결과 및 상기 음 성 신호를 송신하는 단계, 상기 휴대 장치로부터 승인 입력을 수신하는 단계, 및 상기 음성인식 결과에 대응하는 동작을 실행하는 단계를 포함한다."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 화자 검증 방법 및 음성인식 시스템에 관한 것으로서, 보다 상세하게는 음성인식 장치와 음성인식 서 버를 포함하는 음성인식 시스템에서 화자를 검증하는 방법에 관한 것이다."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성인식 기능이 탑재된 인공지능 스피커 장치가 출시되고 있다. 인공지능 스피커 장치는 사용자의 음성을 인 식하고 음성에 포함된 명령을 추출하여 명령에 따른 동작을 실행하고 그 결과를 음성으로 출력함으로써 인공지 능 비서와 같은 역할을 수행할 수 있다. 인공지능 스피커 장치가 단순히 음성 질의에 응답하여 질의 결과를 음 성으로 출력하는 수준을 넘어서 금융 거래나 쇼핑과 같이 보안이 필요한 분야에서 사용되기 위해서는 정확하게 화자를 인식 및 식별할 수 있어야 한다. 그러나, 인공지능 스피커 장치는 목소리를 기초로 사용자를 식별할 수 밖에 없기 때문에 지문이나 홍채 인식과 같은 생체 정보를 이용한 사용자 식별 또는 인증 방법에 비해 정확도가 떨어진다."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시가 해결하고자 하는 과제는 전술한 문제를 해결하기 위한 것으로서, 화자를 정확하게 인식 및 식별할 수 있는 방법을 제공하는 것이다."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은 음성인식 장치와 음성인식 서버 를 포함하는 음성인식 시스템에서 화자를 검증하는 방법을 제공한다. 화자 검증 방법은 상기 음성인식 서버에 의하여, 상기 음성인식 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하는 단계, 상기 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하는 단계, 상기 음성 신호에서 화자 특징 벡터를 추출하여 상기 화자 특징 벡터를 등록된 화자 특징 벡터와 비교하고, 상기 비교 결과에 따라 상기 음성 신호의 화자가 등 록된 제2 화자라고 결정하는 단계, 상기 제2 화자의 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신 하는 단계, 상기 휴대 장치로부터 승인 입력을 수신하는 단계, 및 상기 음성인식 결과에 대응하는 동작을 실행 하는 단계를 포함한다. 일 예에 따르면, 상기 등록된 제2 화자는 상기 음성인식 시스템에 등록된 복수의 사용자들 중 하나일 수 있다. 본 개시의 제2 측면은 음성인식 장치 및 휴대 장치와 통신한는 통신 모듈 및 프로세서를 포함하는 음성인식 서 버를 제공한다. 프로세서는 상기 통신 모듈을 이용하여 상기 음성인식 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하고, 상기 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하고, 상기 음성 신 호에서 화자 특징 벡터를 추출하고, 상기 화자 특징 벡터를 등록된 화자 특징 벡터와 비교하고, 상기 비교 결과 에 따라 상기 음성 신호의 화자가 등록된 제2 화자라고 결정하고, 상기 통신 모듈을 이용하여 상기 제2 화자의 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신하고, 상기 통신 모듈을 이용하여 상기 제 휴대 장치 로부터 승인 입력을 수신하고, 상기 음성인식 결과에 대응하는 동작을 실행하도록 구성된다. 본 개시의 제3 측면은 음성인식 서버와 음성인식 장치를 포함하는 음성인식 시스템을 제공한다. 음성인식 장치 는 상기 음성인식 서버와 통신하는 제1 통신 모듈, 오디오 신호를 생성하는 마이크로폰, 상기 오디오 신호로부 터 상기 음성 신호를 검출하고 상기 음성 신호를 상기 음성인식 서버로 송신하고 상기 음성인식 서버로부터 합 성음 신호를 수신하는 제1 프로세서, 및 상기 합성음 신호에 대응하는 합성음을 재생하는 스피커를 포함한다. 음성인식 서버는 제2 프로세서, 및 상기 음성인식 장치 및 휴대 장치와 통신할 수 있는 제2 통신 모듈을 포함한 다. 상기 제2 프로세서는 상기 음성인식 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하고, 상기 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하고, 상기 음성 신호에서 화자 특징 벡터를 추 출하고, 상기 화자 특징 벡터를 등록된 화자 특징 벡터와 비교하고, 상기 비교 결과에 따라 상기 음성 신호의 화자가 등록된 제2 화자라고 인식하고, 상기 제2 화자의 휴대 장치로 상기 음성인식 결과 및 상기 음성 신호를 송신하고, 상기 휴대 장치로부터 승인 입력을 수신하고, 상기 음성인식 결과에 대응하는 동작을 실행하도록 구 성된다. 본 개시의 제4 측면은 음성인식 시스템의 음성인식 서버의 프로세서가 제1 측면에 따른 화자 검증 방법을 실행 하도록 하는 명령어들을 포함하는 하나 이상의 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예들에 따르면, 화자 검증 절차를 통해 화자를 정확하게 식별 및 인식할 수 있기 때문에 도용의 우려 없이 화자의 명령을 실행할 수 있다. 뿐만 아니라, 화자 검증 오류 또는 목소리 도용이 발생하더 라도 이러한 사실을 화자 당사자가 파악할 수 있다."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시예에서\" 또는 \"일 실시예에서\" 등의 어구는 반드시 모두 동일한 실시예를 가리키는 것은 아니다. 일부 실시예는 기능적인 블럭 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블럭들의 일 부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 본 개시의 기능 블럭들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능 을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블럭들은 다양한 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블럭들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구 현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “모듈” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성 들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 본 개시에서 음성인식 기능은 사용자의 음성을 포함하는 음성 신호를 문자열(또는 텍스트)로 변환하는 것을 말 한다. 음성 인식 기능에 의해 음성 신호가 변환된 문자열(또는 텍스트)은 음성인식 결과로 지칭될 수 있다. 사용자의 음성 신호는 음성 명령을 포함할 수 있으며, 음성인식 결과 역시 음성 명령에 대응하는 명령을 포함할 수 있다. 음성 명령은 음성인식 스피커 장치 또는 음성인식 서버의 특정 기능을 실행할 수 있다. 한편, 본 개 시에서 음성합성 기능은 음성인식 기능과 반대로 문자열(또는 텍스트)을 음성 신호로 변환하는 것을 말한다. 음성 인식 기능에 의해 문자열(또는 텍스트)이 변환된 음성 신호는 합성음 신호로 지칭될 수 있다. 본 개시에서 \"등록된(registered)\"이라는 표현은 음성인식 시스템에 사용자 또는 이의 관련 정보로서 등록되어 있음을 의미한다. \"등록된 사용자\"는 음성인식 시스템에 사용자 등록을 마친 사용자를 의미한다. 어느 한 사 람은 본 개시에 따른 음성인식 시스템에 사용자로 등록할 수 있으며, 사용자로 등록할 때 본인의 음성을 입력할 수 있다. 음성인식 시스템은 사용자 등록 시에 입력된 음성의 음성 신호에서 화자 특징 벡터를 추출하여 등록 된 사용자의 관련 정보로 저장할 수 있다. 이와 같이 음성인식 시스템에 저장된 화자 특징 벡터는 등록된 화자 특징 벡터라고 지칭할 수 있다. 또한, 사용자 등록 시에, 자기 소유의 휴대 장치의 식별 번호를 함께 저장할 수 있다. 음성인식 시스템에는 복수의 사용자들이 등록될 수 있다. 본 개시에서, 제1 화자는 음성 신호의 음성을 실제로 발성한 사람을 의미하고, 등록된 제2 화자(registered second speaker)는 음성인식 시스템에 등록된 복수의 사 용자들 중에서 음성인식 시스템이 음성 신호의 음성을 발성한 것으로 인식 또는 결정한 사용자를 의미한다. 등 록된 제2 화자는 일반적으로 제1 화자와 동일하지만, 음성인식 시스템의 화자 오인식 및 목소리 도용이 발생하 는 경우, 등록된 제2 화자는 제1 화자와 상이할 수 있다. 본 개시에서 키워드는 워드 형태를 갖거나, 구 형태를 가질 수 있다. 본 개시에서, 웨이크업 키워드 이후에 발 화되는 음성 명령은 자연어 형태의 문장 형태, 워드 형태, 또는 구 형태를 가질 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 음성인식 시스템의 예시적인 네트워크 구성도이다. 도 1을 참조하면, 음성인식 시스템의 네트워크 환경은 음성인식 스피커 장치, 음성인식 서버, 휴대 장치 및 네트워크를 포함하는 것으로 예시적으로 도시된다. 음성인식 시스템은 음성인식 스피커 장 치 및 음성인식 서버를 포함한다. 음성인식 스피커 장치는 음성인식 장치의 일 예로서, 음성 제어 기능이 탑재되어 특정 기능을 수행하는 스 피커 장치이다. 음성인식 스피커 장치는 스마트 스피커 장치 또는 인공지능 스피커 장치로 지칭될 수도 있다. 음성인식 스피커 장치는 화자의 음성을 수신하면 음성과 화자를 인식하고 음성에 포함된 명령을 추 출하여 명령에 따른 동작을 실행하고 그 결과를 음성으로 출력할 수 있다. 음성인식 스피커 장치가 수행 할 수 있는 특정 기능은 예컨대 음성 정보 제공, 음악 재생, 인터넷 쇼핑, 금융 거래, 전화 연결, 메시지 전송, 알람 설정, 및 음성인식 스피커 장치에 네트워크를 통해 접속된 전자 또는 기계 장치의 제어 등을 포함할 수 있 다. 예를 들면, 음성인식 스피커 장치가 네트워크를 통해 스마트 텔레비전에 접속된 경우, 특정 기능은 채널 시청, 채널 검색, 동영상 재생, 및 프로그램 검색 등을 포함할 수 있다. 예를 들어, 음성인식 스피커 장치 가 스마트 냉장고와 같은 가전 기기에 접속된 경우, 특정 기능은 냉장 및 냉동 상태 점검 및 온도 설정 등 을 포함할 수 있다. 그러나, 본 개시에서 특정 기능은 상술한 바로 제한되지 않는다. 음성인식 스피커 장치는 무선 또는 유선 통신을 통해 네트워크를 통해 음성인식 서버와 통신할 수 있다. 네트워크의 통신 방식은 제한되지 않으며, 네트워크에 포함될 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용한 통신 방식뿐만 아니라, 음성인식 스피커 장치와의 근거리 무 선 통신이 포함될 수 있다. 예를 들어, 네트워크는 PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 네트워크 는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적 (hierarchical) 네트워크 등을 포함하는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제 한되지 않는다. 음성인식 서버는 네트워크를 통해 음성인식 스피커 장치와 통신하며, 적어도 하나의 컴퓨터 장 치로 구현될 수 있다. 음성인식 서버는 클라우드 형태로 분산될 수 있으며, 명령, 코드, 파일, 컨텐츠 등 을 제공할 수 있다. 음성인식 서버는 음성인식 스피커 장치로부터 수신되는 음성 신호를 문자열(또는 텍스트)로 변환하여 음성인식 결과를 생성할 수 있다. 음성인식 서버는 음성인식 스피커 장치에서 재생될 음성을 합성하 여 합성음 신호를 생성하고 합성음 신호를 음성인식 스피커 장치에 송신할 수 있다. 음성인식 서버는 음성인식 스피커 장치가 수행할 수 있는 특정 기능들을 실제로 수행할 수 있다. 예 컨대, 음성 정보 제공 기능의 경우, 음성인식 서버는 음성인식 스피커 장치로부터 수신된 음성 신호 에 포함된 정보 요청을 인식하고, 이에 대한 결과를 생성하여, 합성음 신호의 형태로 음성인식 스피커 장치 로 송신할 수 있다. 전화 연결 기능의 경우, 음성인식 서버는 음성인식 스피커 장치로부터 수 신된 음성 신호에 포함된 전화 연결 요청을 인식하고, 요청에 따라 전화 연결을 수행하며, 전화 연결 시 송신 신호와 수신 신호를 중계할 수 있다. 음성인식 서버는 네트워크를 통해 가전 기기에도 접속될 수 있 으며, 음성인식 서버는 음성인식 스피커 장치로부터 수신된 음성 신호에 포함된 제어 명령에 따라 가 전 기기를 제어할 수 있다. 음성인식 서버는 네트워크를 통해 휴대 장치에 접속될 수 있다. 음성인식 서버와 음성인 식 스피커 장치를 연결하는 네트워크와 음성인식 서버와 휴대 장치를 연결하는 네트워크는 서로 다른 종류일 수도 있다. 예컨대, 음성인식 서버와 음성인식 스피커 장치를 연결하는 네트워크는 LAN 또는 인터넷일 수 있으며, 음성인식 서버와 휴대 장치를 연결하는 네트워크는 이동통신망일 수 있다. 휴대 장치는 사용자가 휴대하고 다닐 수 있는 무선 통신을 지원하는 전자 기기이다. 예컨대, 휴대 장치 는 휴대 전화, 스마트폰, 태블릿, 또는 노트북 등일 수 있다. 휴대 장치는 전화 기능, 메시지 기능, 또는 메신저 기능을 가질 수 있으며, 음성인식 서버로부터 수신되는 음성 신호 또는 영상 신호를 재생할 수 있다. 또한, 휴대 장치는 음성 신호를 음성인식 서버로 제공할 수도 있다. 휴대 장치는 일 반적으로 한 개인이 사용하는 전자 기기일 수 있다. 도 1에는 음성인식 스피커 장치가 네트워크를 통해 음성인식 기능을 수행하는 음성인식 서버에 접속되는 것으로 도시되어 있지만, 이는 예시적이며, 음성인식 스피커 장치는 독립적으로 음성인식 또는 음성합성 기능을 수행할 수도 있다. 도 2a는 일 실시예에 따른 음성인식 스피커 장치의 내부 구성을 설명하기 위한 블록도이다. 도 2a를 참조하면, 음성인식 스피커 장치는 프로세서, 마이크로폰, 스피커 및 통신 모듈 을 포함할 수 있다. 음성인식 스피커 장치는 도 2a에 도시된 구성요소보다 많은 구성 요소들을 포함 할 수 있다. 예를 들면, 음성인식 스피커 장치는 메모리를 더 포함할 수 있다. 음성인식 스피커 장치 는 통신 모듈을 통해 도 1의 네트워크에 접속되어, 음성인식 서버와 통신할 수 있다. 마이크로폰은 주변의 오디오를 전기적인 음향 데이터로 변환함으로써 오디오 신호를 직접 생성할 수 있다. 음성인식 스피커 장치는 복수의 마이크로폰을 포함할 수 있으며, 복수의 마이크로폰을 이용하여 오디오 신호의 입력 방향을 찾아낼 수 있다. 다른 예에 따르면, 음성인식 스피커 장치는 통신 모듈을 통해 외부 장치로부터 송신된 오디오 신호를 수신할 수도 있다. 스피커는 오디오 신호를 음성으로 변환하여 출력할 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리로부터 프로세서에 제공되거나, 통신 모듈을 통해 수신되어 프로세서 로 제공될 수 있다. 예를 들면 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 명령을 실행하도록 구성될 수 있다. 프로세서는 마이크로폰에서 생성된 오디오 신호로부터 화자의 음성에 대응하는 음성 신호를 검출하고, 통신 모듈을 통해 검출된 음성 신호를 음성인식 서버로 송신할 수 있다. 프로세서는 키워드를 이용하여 오디오 신호로부터 음성 신호를 검출할 수 있다. 프로세서는 오디오 신호 중에서 키워 드에 대응하는 키워드 음성 신호를 추출함으로써 키워드 음성 신호에 후속하여 수신되는 음성 신호를 식별할 수 있다. 프로세서는 음성인식 서버로부터 합성음 신호를 수신하고 스피커를 통해 합성음 신호에 대응하 는 합성음을 재생할 수 있다. 도 2b는 다른 실시예에 따른 음성인식 스피커 장치(100a)의 내부 구성을 설명하기 위한 블록도이다. 도 2b를 참조하면, 음성인식 스피커 장치(100a)는 도 2a의 음성인식 스피커 장치에 비해 카메라를 더 포함할 수 있다. 카메라는 프로세서에 의해 제어되며, 마이크로폰으로부터 수신되는 오디오 신호에서 음성 신호 가 검출된 시점의 영상에 대응하는 영상 신호를 생성할 수 있다. 프로세서는 통신 모듈을 통해 영상 신호를 음성인식 서버로 송신할 수 있다. 카메라는 예컨대 360도를 모두 촬영할 수 있는 360도 카메 라일 수 있다. 다른 예에 따르면, 음성인식 스피커 장치(100a)는 카메라의 촬영 방향을 조절할 수 있다. 음성인식 스피 커 장치(100a)는 음성이 발생한 방향을 감지할 수 있는 센서를 포함할 수 있다. 프로세서는 음성 신호가 검출된 방향을 감지하고, 카메라의 촬영 방향을 음성 신호가 검출된 방향으로 조절할 수 있다. 이때, 프 로세서에서 음성인식 서버로 전송되는 영상 신호는 화자의 음성이 발생한 방향의 영상을 포함할 수 있다. 또 다른 예에 따르면, 음성인식 스피커 장치(100a)는 주변 360도를 촬영할 수 있도록 일정한 간격으로 배열되는 복수의 카메라를 포함할 수 있다. 음성인식 스피커 장치(100a)는 음성이 발생한 방향을 감지할 수 있는 센서를 포함할 수 있다. 프로세서는 음성 신호가 검출된 방향을 감지하고, 복수의 카메라 중에서 음 성 신호가 검출된 방향을 촬영할 수 있는 카메라를 이용하여 화자의 음성이 발생한 방향의 영상에 대응하 는 영상 신호를 획득할 수 있다. 도 3은 일 실시예에 따른 음성인식 서버의 내부 구성을 설명하기 위한 블록도이다. 도 3을 참조하면, 음성인식 서버는 프로세서, 메모리 및 통신 모듈을 포함한다. 음성인식 서버는 도 3에 도시된 구성요소보다 많은 구성 요소들을 포함할 수 있다. 예를 들면, 음성인식 서버(20 0)는 입출력 장치를 더 포함할 수 있다.통신 모듈은 네트워크를 통해 음성인식 서버가 음성인식 스피커 장치 및 휴대 장치와 통신하기 위한 기능을 제공할 수 있다. 음성인식 서버는 통신 모듈을 통해 도 1의 네트워크에 접속되어, 음성인식 스피커 장치 및 휴대 장치와 통신할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록 매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 메모리 에는 운영체제와 적어도 하나의 프로그램 코드(예컨대, 음성인식 서버에 설치되어 구동되는 음성인식 어플리케이션, 음성합성 어플리케이션 등을 위한 코드)가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 통 신 모듈을 이용하여 통신을 통해 메모리에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 어플리케이션의 설치 파일을 배포하는 파일 배포 시스템이 네트워크를 통해 제공하는 파일 들에 의해 설치되는 프로그램에 기반하여 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 프로세서는 메모리에 저장된 프로그램 코드에 따라 명령을 실행하도록 구성될 수 있다. 프로세서는 음성인식 스피커 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신하고, 음성 신 호에 대하여 음성인식을 수행하여 음성인식 결과를 생성하도록 구성될 수 있다. 예를 들어, 프로세서는 음성 신호에 대한 음성 인식을 수행하기 위하여, 음성 신호의 주파수 특성을 추출하고, 음향 모델과 언어 모델 을 이용하여 음성 인식을 수행할 수 있다. 주파수 특성은 음향 입력의 주파수 스펙트럼을 분석하여 추출되는 음향 입력의 주파수 성분들의 분포를 의미할 수 있다. 음향 모델과 언어 모델은 메모리에 저장될 수 있다. 다만 음성인식 방법은 이에 한정되는 것은 아니며, 음성 신호를 문자열(또는 텍스트)로 변환하는 다양한 기술들이 사용될 수 있다. 프로세서는 음성 신호를 분석하여 음성 신호에 포함된 음성을 발화한 화자가 누구인지를 판단할 수 있다. 예를 들어, 음성 신호에서 화자 특징 벡터를 추출하여 화자 특징 벡터를 등록된 화자 특징 벡터와 비교하고, 비 교 결과에 따라 음성 신호의 화자가 등록된 제2 화자(registered second speaker)라고 결정하도록 구성될 수 있 다. 등록된 화자 특징 벡터(registered speaker feature vector)는 메모리에 미리 저장될 수 있다. 음 성인식 서버에 복수의 화자들이 음성인식 스피커 장치의 사용자로 등록할 수 있으며, 이 경우, 메모 리에는 복수의 등록된 화자 특징 벡터들이 저장될 수 있다. 등록된 화자 특징 벡터들은 등록된 화자들에 각각 대응할 수 있다. 프로세서는 음성 신호의 화자가 제2 화자라고 결정하기 위하여, 음향 모델로부터 추출된 사후 정보(states posteriors), 일반적 배경 모델, 및 전체 변이성 변환 정보 중 적어도 하나를 이용하여 음성 신호의 주파수 특 성으로부터 화자 특징 벡터를 생성할 수 있다. 프로세서는 생성된 화자 특징 정보와 메모리에 저장 된 등록된 화자 특징 벡터들에 기초하여 음성 신호의 화자가 등록된 화자인지 여부를 판단할 수 있다. 메모리 에는 사후 정보, 일반적 배경 모델, 전체 변이성 변환 정보, 및 등록된 화자 정보 중 적어도 하나가 저장 될 수 있다. 프로세서는 제2 화자의 휴대 장치로 음성인식 결과 및 음성 신호를 송신하고, 제2 화자의 휴대 장치 로부터 승인 입력을 수신하도록 구성될 수 있다. 제2 화자의 등록된 휴대 장치에 관한 정보는 메모 리에 미리 저장될 수 있다. 제2 화자가 음성인식 스피커 장치를 통해 음성인식 서버에 음성인 식 스피커 장치의 사용자로 등록할 때, 자신의 휴대 장치에 관한 정보(예컨대, 휴대 장치의 식 별번호)를 함께 등록할 수 있다. 프로세서는 음성인식 결과에 대응하는 동작을 실행하도록 구성될 수 있다. 프로세서는 음성인식 결 과에 대응하는 기능을 결정하고, 해당 기능을 수행할 수 있다. 프로세서는 동작의 실행 결과를 보고하기 위한 합성음 신호를 생성하도록 구성될 수 있다. 프로세서는 함성음 신호를 음성인식 스피커 장치에 송신하도록 구성될 수 있다. 음성인식 서버는 입출력 장치로서, 마이크로폰 또는 스피커를 더 포함할 수 있다. 음성인식 서버는 음성 신호를 직접 생성하고 합성음을 직접 재생할 수도 있다. 도 4a는 일 실시예에 따른 음성인식 서버의 프로세서의 내부 구성을 설명하기 위한 블록도이다. 도 4a를 참조하면, 음성인식 서버의 프로세서는 음성 신호 수신부, 음성 인식부, 화자 인 식부, 화자 검증부, 및 기능부를 포함한다. 음성인식 서버는 합성음 신호 생성부를 더 포함할 수 있다. 화자 인식부는 화자 특징 벡터 추출부(213a), 화자 특징 벡터 비교부(213b), 및 등록 화자 결정부(213c)를 포함한다. 음성 신호 수신부는 음성인식 스피커 장치로부터 제1 화자의 음성을 포함하는 음성 신호를 수신한다. 음성 인식부는 음성 신호 수신부에 의해 수신된 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성한다. 음성 인식부는 음성 신호에 대하여 음성인식을 수행하여 화자의 음성을 문자열(또는 텍 스트)로 변환할 수 있다. 음성 인식부는 변환된 문자열(또는 텍스트)을 자연어 처리하여 음성 신호에 포 함된 화자의 명령을 추출할 수 있다. 음성인식 결과는 화자의 명령을 포함하며, 음성인식 결과에 대응하는 동 작은 화자의 명령에 따른 동작을 의미한다. 화자 인식부는 음성 신호 수신부에 의해 수신된 음성 신호의 화자가 제2 화자라고 결정한다. 제2 화 자는 음성인식 시스템에 음성인식 스피커 장치의 사용자로 등록된 화자이다. 예를 들면, 화자 특징 벡터 추출부(213a)는 음성 신호 수신부에 의해 수신된 음성 신호에서 화자 특징 벡터를 추출한다. 화자 특징 벡터 추출부(213a)는 시간 도메인(time domain) 기반의 음성 신호를 주파수 도메인(frequency domain) 상의 신 호로 변환하고, 변환된 신호의 주파수 에너지를 서로 다르게 변형함으로써 화자 특징 벡터를 추출할 수 있다. 예컨대, 화자 특징 벡터는 멜 주파수 켑스트럼 계수(Mel-Frequency Cepstral Coefficients) 또는 필터뱅크 에 너지(Filter Bank Energy)를 기초로 추출될 수 있으나, 이에 한정되는 것은 아니며 다양한 방식으로 오디오 데 이터로부터 화자 특징 벡터를 추출할 수 있다. 화자 특징 벡터 비교부(213b)는 화자 특징 벡터 추출부(213a)에 의해 추출된 화자 특징 벡터를 메모리에 저장된 등록된 화자 특징 벡터와 비교한다. 메모리에는 복수의 등록된 화자 특징 벡터들이 존재하며, 화 자 특징 벡터 비교부(213b)는 추출된 화자 특징 벡터를 복수의 등록된 화자 특징 벡터들과 비교하여, 가장 유사 도가 높은 등록된 화자 특징 벡터를 결정한다. 등록 화자 결정부(213c)는 화자 특징 벡터 비교부(213b)의 비교 결과에 따라 음성 신호의 화자가 등록된 제2 화자라고 결정한다. 등록 화자 결정부(213c)는 가장 유사도가 높 은 등록된 화자 특징 벡터의 화자를 음성 신호의 화자로 결정한다. 등록된 화자 특징 벡터들이 모두 미리 설정 한 기준치를 넘는 유사도를 갖지 못한 경우, 등록 화자 결정부(213c)는 음성 신호의 화자가 등록된 화자가 아니 라고 결정할 수 있다. 이때, 프로세서는 음성인식 결과에 대응하는 동작을 수행하지 않거나, 음성인식 결 과에 대응하는 동작이 누구나 수행할 수 있는 동작으로 설정된 경우에 한하여 해당 동작을 수행할 수 있다. 화자 검증부는 화자 인식부에서 결정되는 제2 화자의 휴대 장치로 음성 인식부에서 생성된 음성 인식 결과와 음성 신호 수신부에서 수신된 음성 신호를 송신한다. 제2 화자의 휴대 장치의 식별 번호는 메모리에 미리 저장될 수 있다. 화자 검증부는 제2 화자의 휴대 장치로부터 승인 입력을 수신할 수 있다. 기능부는 화자 검증부에서 승인 입력을 수신하면, 음성 인식부에서 생성된 음성인식 결과에 대 응하는 동작을 실행한다. 기능부는 음성 신호의 화자가 등록된 화자가 아니라고 판단되는 경우 음성인식 결과에 대응하는 동작을 실행하지 않을 수 있다. 기능부는 화자 검증부에서 거절 입력을 수신하면 음성인식 결과에 대응하는 동작을 실행하지 않는다. 합성음 신호 생성부는 기능부에서 동작을 실행한 경우, 동작의 실행 결과를 보고하기 위한 합성음 신 호를 생성한다. 합성음 신호 생성부는 음성 신호의 화자가 등록된 화자가 아니라고 판단되어 음성인식 결 과에 대응하는 동작이 실행되지 않은 경우나, 화자 검증부에서 승인 입력을 수신하지 못하여 음성인식 결 과에 대응하는 동작이 실행되지 않은 경우에는 동작이 실행되지 않았음을 보고하기 위한 합성음 신호를 생성할 수 있다. 다른 실시예에 따르면, 프로세서는 음성인식 스피커 장치로부터 영상 신호를 수신하는 영상 신호 수 신부를 더 포함할 수 있다. 이때, 화자 검증부는 영상 신호 수신부에 의해 수신된 영상 신호를 제2 화자 의 휴대 장치로 송신할 수 있다. 다른 실시예에 따르면, 프로세서는 화자 벡터 개선부를 더 포함하여 구성될 수 있다. 화자 검증부가 제2 화자의 휴대 장치로부터 승인 입력을 수신하면, 수신된 음성 신호의 화자가 제2 화자임이 확인된 것이므로, 화자 벡터 개선부는 수신된 음성 신호에서 추출된 화자 특징 벡터를 이용하여 메모리에 저장된 제2 화자의 등록된 화자 특징 벡터를 개선할 수 있다. 화자 특징 벡터 개선부는 음성 신호에서 추출된 화자 특징 벡터를 이용한 적응 훈련 방식을 통해 제2 화자의 등록된 화자 특징 벡터를 생성하고, 새로 생성된 등록된 화자 특징벡터가 적응 훈련 이전의 등록된 화자 특징 벡터에 비해 적응 훈련 성능이 상승한 경우, 새로 생성된 등록된 화 자 특징 벡터를 메모리에 저장함으로써 등록된 화자 특징 벡터를 개선할 수 있다. 도 4b는 일 실시예에 따른 음성인식 서버의 프로세서의 내부 구성을 설명하기 위한 블록도이다. 도 4b를 참조하면, 음성인식 서버의 프로세서(210a)는 음성 신호 수신부, 음성 인식부, 화자 인 식부, 검증 여부 결정부, 화자 검증부, 기능부, 및 합성음 신호 생성부를 포함한다. 검증 여부 결정부는 음성인식 결과에 대응하는 동작 및 제2 화자의 설정 중 적어도 하나를 기초로 화자 검 증부의 동작을 실행할 것인지의 여부를 결정한다. 일 예에 따르면, 검증 여부 결정부는 음성인식 결과에 따른 동작이 제2 화자가 미리 설정한 사전 승인 동 작 리스트에 포함되는 경우, 화자 검증부의 동작을 실행하도록 결정할 수 있다. 사전 승인 동작 리스트는 메모리에 저장될 수 있으며, 음성인식 스피커 장치를 통해 수행할 수 있는 동작들 또는 기능들 중 일 부가 미리 설정한 사전 승인 동작 리스트에 포함될 수 있다. 예컨대, 금융 거래나 인터넷 쇼핑, 메시지 보내기 등과 같은 동작들이 미리 설정한 사전 승인 동작 리스트에 포함될 수 있다. 사전 승인 동작 리스트에 포함되는 동작들은 등록된 화자들마다 다르게 설정될 수 있다. 다른 예에 따르면, 음성인식 결과에 따른 동작이 제2 화자가 미리 설정한 사후 통지 동작 리스트에 포함되는 경 우, 검증 여부 결정부는 기능부에 의해 음성인식 결과에 대응하는 동작이 먼저 실행되고, 제2 화자의 휴대 장치로 음성인식 결과 및 음성 신호를 송신하도록 결정할 수 있다. 사후 통지 동작 리스트는 메모리(22 0)에 저장될 수 있으며, 음성인식 스피커 장치가 수행할 수 있는 동작들 중 일부의 동작이 미리 설정한 사 후 통지 동작 리스트에 포함될 수 있다. 예컨대, 전화 걸기, 설정 변경 등과 같은 동작들이 미리 설정한 사후 통지 동작 리스트에 포함될 수 있다. 사후 통지 동작 리스트에 포함되는 동작들은 등록된 화자들마다 다르게 설정될 수 있다. 또 다른 예에 따르면, 검증 여부 결정부는 제2 화자의 휴대 장치의 위치 및 현재 시간 중 적어도 하나가 사전 승인 조건에 부합하는 경우, 화자 검증부의 동작을 실행하도록 결정할 수 있다. 예를 들면, 제2 화 자의 휴대 장치의 위치가 음성인식 스피커 장치의 위치와 가깝게 위치하는 경우, 예컨대, 제2 화자의 휴대 장치와 음성인식 스피커 장치가 동일한 무선 와이파이 액세스 포인트에 접속되는 경우나, 제2 화자의 휴대 장치의 GPS 위치 또는 무선망 접속 위치가 음성인식 스피커 장치의 위치와 실질적으로 일치하는 경우, 제2 화자가 음성 신호 수신부에서 수신한 음성 신호에 대응하는 음성을 실제로 말했을 가능성이 높으므로, 검 증 여부 결정부는 화자 검증부의 동작을 생략할 수 있다. 등록된 화자들은 이러한 화자 검증부(21 4)의 동작의 생략 여부를 각각 설정할 수 있다. 검증 여부 결정부는 제2 화자가 설정한 시간, 예컨대, 주중 낮 시간에는 화자 검증부의 동작을 실행 하도록 결정할 수 있다. 예컨대, 직장인인 제2 화자는 주중 낮 시간에는 집에 없을 가능성이 높으므로, 집에 위치한 음성인식 스피커 장치가 제2 화자의 음성을 수신할 가능성이 낮다. 검증 여부 결정부는 이러 한 경우에 화자 검증부의 동작을 실행하도록 결정할 수 있다. 등록된 화자들은 시간을 기초로 화자 검증 부의 동작을 실행할 것인지의 여부를 각각 설정할 수 있다. 사전 승인 조건은 등록된 화자에 의해 미리 설정되어 메모리에 저장될 수 있다. 또한, 사전 승인 조건은 등록된 화자의 행동 패턴에 기초하여 결정될 수 있다. 등록된 화자의 행동 패턴은 등록된 화자의 휴대 장치의 위치를 기초로 생성될 수 있다. 예를 들면, 검증 여부 결정부는 등록된 화자의 휴대 장치의 위치를 오랜 시간 동안 수집할 수 있다. 검증 여부 결정부는 수집된 휴대 장치의 위치를 분석하여 등록된 화자가 음성 인식 스피커 장치와 가깝게 위치하지 않는 시간대를 결정할 수 있다. 검증 여부 결정부는 현재 시간 이 이 시간대에 해당하는 경우에 화자 검증부의 동작을 실행하도록 자동적으로 결정할 수 있다. 도 5a 및 도 5b는 일 실시예에 따른 음성인식 시스템의 화자 검증 방법을 설명하기 위한 예시적인 흐름도이다. 도 5a 및 도 5b를 참조하면, 음성인식 시스템은 음성인식 스피커 장치와 음성인식 서버를 포함한다. 제2 화자의 휴대 장치는 음성인식 서버에 네트워크를 통해 접속된다. 음성인식 스피커 장치는 마이크로폰(도 2a의 120)을 이용하여 주변의 소리를 전기적으로 변환하여 오디오 신호를 생성할 수 있다(S101). 음성인식 스피커 장치는 오디오 신호로부터 음성 신호를 검출할 수 있다(S102). 음성 신호는 사용자의 음 성을 포함할 수 있다. 여기서 사용자는 제1 화자로 지칭한다. 음성은 사용자의 음성 명령을 포함할 수 있다.음성 명령에는 음성 정보 검색, 전화 연결, 메시지 전송, 금융 거래, 인터넷 쇼핑, 음식 배달, 주변 가전 기기 제어, 스마트 홈 제어 등이 포함될 수 있다. 본 예에서는 음성 명령이 금융 거래에 관한 것으로서, 제1 화자의 음성이 \"B에게 100만원을 송금해줘\"라고 가정한다. 제1 화자의 음성에는 음성인식 스피커 장치를 웨이크 업하기 위한 트리거 키워드가 포함될 수 있다. 음성인식 스피커 장치는 트리거 키워드를 인식함으로써 오 디오 신호로부터 음성 신호를 검출할 수 있다. 음성인식 스피커 장치는 음성 신호를 음성인식 서버로 송신하고(S103), 음성인식 서버는 음성인 식 스피커 장치로부터 음성 신호를 수신한다(S201). 음성인식 서버는 음성 신호에 대하여 음성인식을 수행하여 음성인식 결과를 생성한다(S202). 음성인식 서 버는 음성 신호의 주파수 특성을 추출하고, 음향 모델과 언어 모델을 이용하여 음성 인식을 수행할 수 있 다. 음성인식 서버는 음성 신호를 문자열로 변환하고, 문자열을 자연어 처리함으로써 음성인식 결과를 생 성할 수 있다. 음성인식 결과는 음성 명령을 포함할 수 있다. 음성인식 서버는 음성 신호에서 화자 특징 벡터를 추출한다(S203). 음성인식 서버는 음향 모델로부 터 추출된 사후 정보(states posteriors), 일반적 배경 모델, 및 전체 변이성 변환 정보 중 적어도 하나를 이용 하여 음성 신호의 주파수 특성으로부터 화자 특징 벡터를 생성할 수 있다. 음성인식 서버는 추출된 화자 특징 벡터와 등록된 화자 특징 벡터를 비교한다(S204). 등록된 화자 특징 벡터는 메모리(도 3의 220)에 저장될 수 있으며, 사용자가 음성인식 시스템에 등록할 때 입력되는 사용자의 음 성을 기초로 미리 생성될 수 있다. 음성인식 서버는 단계(S204)의 비교 결과에 따라 음성 신호의 화자가 등록된 제2 화자라고 결정한다 (S205). 단계(S204)에서 음성인식 서버는 추출된 화자 특징 벡터를 등록된 화자 특징 벡터들 각각과 비교 할 수 있다. 비교 결과, 등록된 화자 특징 벡터들 중에서 추출된 화자 특징 벡터와 가장 유사도가 높은 등록된 화자 특징 벡터가 결정될 수 있다. 음성인식 서버는 가장 유사도가 높은 등록된 화자 특징 벡터의 사용자 가 음성 신호의 화자라고 결정하며, 여기서 가장 유사도가 높은 등록된 화자 특징 벡터에 대응하는 사용자는 제 2 화자로 지칭한다. 제2 화자는 일반적으로 제1 화자와 동일하다. 그러나, 음성인식 서버의 화자 인식 기능의 오류로 인하여, 제2 화자는 제1 화자와 상이할 수 있다. 예를 들면, 제1 화자가 음성 명령을 발화하였으나, 음성인식 서버는 화자 인식 기능의 오류로 인하여 음성 명령을 제1 화자와 다른 제2 화자가 발화한 것으로 인식할 수 있다. 이 경우, 음성인식 서버는 제2 화자 가 \"B에게 100만원 송금해줘\"라고 발화한 것으로 인식할 것이므로, 음성인식 서버는 제2 화자의 계좌에서 B에게 100만원을 송금하는 문제가 발생한다. 다른 예로서, 제1 화자가 제2 화자의 목소리를 흉내내어 음성 명령을 발화하였고, 음성인식 서버는 이 음 성 명령을 제2 화자가 발화한 것으로 인식할 수 있다. 이 경우는 목소리 도용으로 인한 경우이다. 이 경우에 도, 음성인식 서버는 제2 화자가 \"B에게 100만원 송금해줘\"라고 발화한 것으로 인식할 것이므로, 음성인식 서버는 제2 화자의 계좌에서 B에게 100만원을 송금하는 문제가 발생한다. 음성인식 서버는 이러한 문제를 해소하기 위하여 추가적인 화자 검증 절차를 실행할 수 있다. 음성인식 서버는 음성인식 결과 및 음성 신호를 제2 화자의 휴대 장치로 송신할 수 있다. 제2 화자가 음성인 식 시스템에 음성인식 스피커 장치의 사용자로 등록할 때 자신의 휴대 장치의 식별번호를 입력할 수 있으며, 제2 화자의 휴대 장치의 식별번호는 메모리에 저장될 수 있다. 한편, 음성인식 서버는 단계(S204)의 비교 결과에 따라 음성 신호의 화자가 미리 등록된 사용자가 아니라 고 결정할 수 있다. 추출된 화자 특징 벡터와 등록된 화자 특징 벡터들 간의 유사도가 미리 설정한 기준 유사 도를 넘지 못하는 경우, 음성인식 서버는 음성 신호의 화자가 미리 등록되지 않았다고 결정하고, 음성 명 령에 따른 동작을 실행하지 않을 수 있다. 이 경우, 음성인식 서버는 바로 단계(S209)로 진행하여, 동작 이 실행되지 않았음을 보고하기 위한 합성음을 생성할 수 있다. 이 경우에도, 음성 명령의 내용이 누구나 할 수 있도록 설정된 것이라면, 음성인식 서버는 음성 신호의 화자가 미리 등록되지 않았다고 하더라도 음성 명령에 따른 동작을 수행할 수 있다. 이 경우, 음성인식 서버는 화자 검증 절차(단계들(S206, S301-S305, S207))를 생략하고, 바로 단계(S208)로 진행하여 음성 명령에 따른 동작을 수행할 수 있다. 일 실시예에 따르 면, 음성 명령에 따른 동작이 누구나 할 수 있는 동작인 경우라면, 음성인식 서버는 단계(S203-S205)를 실 행하지 않을 수도 있다. 제2 화자의 휴대 장치는 음성인식 서버로부터 음성인식 결과 및 음성 신호를 수신한다(S301). 전술 한 바와 같이, 제2 화자는 실제로 음성 신호에 포함되는 음성을 발화한 제1 화자와 동일할 수도 있고 동일하지 않을 수도 있다. 휴대 장치는 음성인식 결과를 표시할 수 있다(S302). 도 6은 일 실시예에 따라서 음성인식 시스템에 접속 되는 제2 화자의 휴대 장치의 예시적인 화면을 도시한다. 도 6에 도시된 바와 같이, 휴대 장치의 디스플레이 창 상에는 \"음성인식 스피커 장치에서 다음 명령 이 실행되었습니다.\"라는 문구가 표시될 수 있다. 수신된 음성인식 결과 또는 음성인식 결과에 포함되는 음성 명령이 문구 아래의 영역에 표시될 수 있다. 본 예에서, 영역에는 \"B에게 100만원을 송금 해줘\"라는 문구가 표시될 수 있다. 디스플레이 창에는 음성인식 스피커 장치에서 검출한 음성 신호를 재생할 수 있는 재생 버튼이 표시될 수 있다. 제2 화자가 재생 버튼을 터치하는 경우, 음성인식 서버로부터 수신된 음성 신호가 재생될 수 있다. 디스플레이 창에는 \"승인하시겠습니까\"라는 문구가 표시될 수 있다. 문구 아래에 승인 버튼 과 거절 버튼이 표시될 수 있다. 제2 화자는 수신된 음성인식 결과 또는 재생되는 음성을 확인한 후 승인 버튼을 터치함으로써 음성인식 서버가 음성인식 결과의 음성 명령에 따른 동작을 실행하도록 승 인할 수 있다. 제2 화자는 자신이 발화한 적이 없거나 수신된 음성인식 결과가 자신이 발화한 음성 명령과 상 이하다면, 거절 버튼을 터치함으로써 음성인식 서버가 음성인식 결과에 대응하는 동작을 실행하지 않 도록 할 수 있다. 음성인식 서버의 화자 인식 기능에 오류가 있거나, 제2 화자가 자신이 목소리를 도용당 한 경우, 제2 화자가 휴대 장치를 이용하여 음성인식 결과에 대응하는 동작을 실행하지 않도록 함으로써 피해를 방지할 수 있다. 디스플레이 창에는 신고하기 버튼이 표시될 수 있다. 제2 화자는 재생 버튼을 터치하여 재생되 는 음성을 들은 후, 자신의 목소리를 도용당했다고 판단되는 경우, 신고하기 버튼을 터치하여 목소리 도용 사실을 관련 금융회사, 관청, 또는 음성인식 시스템의 제조사와 같은 외부 기관에 신고할 수 있다. 이 경우, 휴대 장치는 목소리 도용과 관련된 정보와 함께 음성인식 서버로부터 수신된 음성 신호를 외부 기관 에 송신할 수 있다. 디스플레이 창에는 음성 피드백 보내기 버튼이 표시될 수 있다. 제2 화자가 음성 피드백 보내기 버 튼을 터치하면 음성인식 스피커 장치에서 출력될 음성을 입력할 수 있다. 제2 화자는 음성 피드백 보내기 버튼을 터치한 후 목소리 도용자 등에게 전할 응답 음성을 발화할 수 있다. 휴대 장치는 응 답 음성에 대응하는 응답 음성 신호를 생성하고, 응답 음성 신호를 음성인식 서버로 송신할 수 있다. 음 성인식 서버는 응답 음성 신호를 수신하고 음성인식 스피커 장치로 전달할 수 있다. 음성인식 스피 커 장치는 음성인식 서버로부터 전송된 응답 음성 신호를 수신하고, 응답 음성 신호에 대응하는 제2 화자의 응답 음성을 출력할 수 있다. 다른 실시예에 따르면, 디스플레이 창에는 음성 통신 버튼이 표시될 수 있으며, 제2 화자가 음성 통신 버 튼을 터치하면, 음성인식 스피커 장치와 휴대 장치 사이에 음성을 송수신할 수 있는 세션이 연결된다. 제2 화자는 연결된 세션을 통해 음성인식 스피커 장치의 주변에 위치한 사람과 음성을 주고 받 을 수 있다. 예컨대, 제1 화자가 제2 화자의 가족인 경우, 제1 화자는 제2 화자에게 음성인식 결과에 따른 동 작이 필요한 이유를 설명하고, 제2 화자는 제1 화자의 설명을 들은 후 해당 동작을 승인할 수도 있다. 휴대 장 치는 음성인식 스피커 장치와 직접 연결되거나, 음성인식 서버의 중계 하에 음성인식 스피커 장 치와 연결될 수 있다. 다시 도 5a 및 도 5b를 참조하면, 휴대 장치는 디스플레이 창의 영역 상에 음성인식 결과를 표 시할 수 있다(S302). 또한, 휴대 장치는 제2 화자가 재생 버튼을 터치함으로써 음성 신호를 재생할 수 있다(S303). 휴대 장치는 제2 화자가 승인 버튼을 터치함으로써 승인 입력을 수신하거나, 제2 화자가 거절 버튼 을 터치함으로써 거절 입력을 수신할 수 있다(S304). 휴대 장치는 승인 입력 또는 거절 입력을 음성 인식 서버로 송신할 수 있다(S305). 휴대 장치는 미리 설정된 시간 동안 승인 입력이 수신되지 않으 면 거절 입력이 수신된 것으로 간주하여 거절 입력을 음성인식 서버로 송신할 수 있다. 음성인식 서버는 휴대 장치로부터 승인 입력 또는 거절 입력을 수신할 수 있다(S207). 음성인식 서 버는 승인 입력을 수신한 경우 음성인식 결과에 대응하는 동작을 실행하고, 거절 입력을 수신한 경우 음성인식 결과에 대응하는 동작을 실행하지 않는다(S208). 본 예에서, 음성인식 서버는 승인 입력을 수신한 경우 제2 화자의 계좌에서 B에게 100만원을 송금할 수 있다. 음성인식 서버는 거절 입력을 수신한 경우 B 에게 100만원을 송금하지 않는다. 음성인식 서버는 음성인식 결과에 대응하는 동작을 실행한 후 동작의 실행 결과를 보고하기 위한 합성음 신호를 생성한다(S209). 이때, 합성음 신호는 예컨대 \"제2 화자의 계좌에서 B에게 100만원을 송금하였습니다\" 라는 합성음에 대응될 수 있다. 음성인식 서버는 음성인식 결과에 대응하는 동작을 실행하지 않은 경우, 동작의 미실행을 보고하기 위한 합성음 신호를 생성한다(S209). 이때, 합성음 신호는 예컨대 \"제2 화자의 불승 인으로 인하여 B에게 100만원을 송금하지 않았습니다\"라는 합성음에 대응될 수 있다. 음성인식 서버는 생 성된 합성음 신호를 음성인식 스피커 장치로 송신할 수 있다(S210). 음성인식 스피커 장치는 합성음 신호를 수신하고(S104), 합성음 신호에 대응하는 합성음을 재생할 수 있다 (S105). 따라서, 음성 신호의 음성을 발화했던 제1 화자는 자신의 음성 명령의 실행 결과를 직접 확인할 수 있 다. 다른 실시예에 따라, 음성인식 스피커 장치가 카메라(도 2b의 150)를 포함하는 경우, 단계(S102)에서 음성 인식 스피커 장치는 카메라를 이용하여 음성 신호가 검출된 시점의 영상을 포함하는 영상 신호를 생 성할 수 있다. 또한, 단계(S103)에서 음성인식 스피커 장치는 음성 신호와 함께 영상 신호를 음성인식 서 버로 송신할 수 있다. 단계(S201)에서 음성인식 서버는 음성인식 스피커 장치로부터 영상 신호를 수신하고, 단계(S206)에서 음성인식 결과 및 음성 신호와 함께 영상 신호를 제2 화자의 휴대 장치로 전송할 수 있다. 이 경우, 휴대 장치는 영상 신호를 표시할 수 있는 인터페이스, 예컨대, 영상 표시 버튼을 가질 수 있다. 제2 화자가 영상 신호를 표시하기 위해 영상 표시 버튼을 터치하면, 휴대 장치가 영상 신호의 영상을 표시 함으로써, 제2 화자는 자신이 발화하지 않은 음성인식 결과를 수신한 경우에 음성을 발화한 사람이 포함된 영상 을 확인할 수 있다. 영상 신호는 제1 화자의 음성이 발생한 방향의 영상을 포함할 수 있다. 영상 신호는 동영 상 신호일 수도 있다. 휴대 장치는 동영상 신호를 재생할 수 있는 인터페이스, 예컨대, 영상 재생 버튼을 가질 수 있다. 제2 화자가 영상 재생 버튼을 터치하면, 휴대 장치는 동영상 신호에 포함된 동영상을 재생 할 수 있다. 다른 실시예에 따라, 단계(S207)에서 음성인식 서버가 휴대 장치로부터 승인 입력을 수신한 경우, 제 1 화자와 제2 화자의 동일성이 확인된 것이므로, 음성인식 서버는 추출된 화자 특징 벡터를 이용하여 제2 화자의 등록된 화자 특징 벡터를 개선할 수 있다. 도 7은 다른 실시예에 따른 음성인식 시스템의 화자 검증 방법을 설명하기 위한 예시적인 흐름도이다. 도 7을 참조하면, 다른 실시예에 따른 화자 검증 방법에 따르면, 도 5의 단계(S205)가 수행된 후에, 음성인식 서버는 음성인식 결과에 대응하는 동작 및 제2 화자의 설정 중 적어도 하나를 기초로, 제2 화자의 휴대 장 치를 이용한 검증 절차(S206, S301-S305, S207)의 실행 여부를 결정할 수 있다(S211). 단계(S211)에서 검증 절차를 실행하기로 결정한 경우, 음성인식 서버는 단계(S206)로 진행하여 음성인식 결과 및 음성 신호를 송신할 수 있다. 그러나, 단계(S211)에서 검증 절차를 실행하지 않기로 결정한 경우, 음 성인식 서버는 검증 절차를 생략하고 단계(S208)로 진행하여 음성인식 결과에 대응하는 동작을 실행할 수 있다. 일 예에 따르면, 음성인식 결과에 따른 동작이 제2 화자가 미리 설정한 사전 승인 동작 리스트에 포함되는 경우, 단계(S211)에서 음성인식 서버는 검증 절차(S206, S301-S305, S207)를 실행하도록 결정할 수 있다. 사전 승인 동작 리스트는 메모리(도 3의 220)에 저장될 수 있다. 사전 승인 동작 리스트에는 음성인식 스피커 장치를 통해 수행할 수 있는 동작들 중에서 제2 화자가 미리 선택한 일부의 동작이 포함될 수 있다. 예컨 대, 제2 화자는 금융 거래나 인터넷 쇼핑, 메시지 보내기 등과 같은 동작들을 선택하여 사전 승인 동작 리스트 에 포함시킬 수 있다. 다른 예에 따르면, 단계(S211)에서 음성인식 서버는 제2 화자의 휴대 장치의 위치 및 현재 시간 중 적어도 하나가 사전 승인 조건에 부합하는 경우, 검증 절차(S206, S301-S305, S207)를 실행하도록 결정할 수 있 다. 예를 들면, 제2 화자의 휴대 장치가 음성인식 스피커 장치로부터 떨어져 위치하는 경우, 제2 화 자가 음성 신호에 대응하는 음성을 실제로 발화했을 가능성이 낮으므로, 단계(S211)에서 음성인식 서버는검증 절차(S206, S301-S305, S207)를 실행하도록 결정할 수 있다. 그러나, 제2 화자의 휴대 장치가 음성 인식 스피커 장치와 가깝게 위하는 경우, 단계(S211)에서 음성인식 서버는 검증 절차(S206, S301- S305, S207)를 생략할 수 있다. 이러한 사전 승인 조건은 휴대 장치의 위치 외에도 제2 화자가 설정한 시 간대를 기초로 정해질 수 있다. 예를 들면, 단계(S211)에서 음성인식 서버는 현재 시간이 제2 화자가 설정한 시간, 예컨대, 주중 낮 시간 에 해당하는 경우에 검증 절차(S206, S301-S305, S207)를 실행하도록 결정할 수 있다. 예컨대, 제2 화자는 자 신이 집에 없을만한 시간대를 미리 설정할 수 있다. 이러한 사전 승인 조건은 등록된 화자들마다 상이하게 설 정될 수 있다. 사전 승인 조건은 등록된 화자에 의해 미리 설정되어 메모리에 저장될 수 있다. 예를 들어, 사전 승인 조 건은 등록된 화자의 휴대 장치의 위치를 기초로 생성되는 등록된 화자의 행동 패턴에 기초하여 결정될 수 있다. 음성인식 서버는 등록된 화자의 휴대 장치의 위치를 수집할 수 있다. 음성인식 서버는 수집된 휴대 장치의 위치를 분석하여 등록된 화자가 음성인식 스피커 장치와 멀리 떨어져 위치하는 시간대를 결정할 수 있다. 음성인식 서버는 현재 시간이 이 시간대에 해당하는 경우에 검증 절차(S206, S301-S305, S207)를 실행하도록 자동적으로 결정할 수 있다. 또 다른 예에 따르면, 음성인식 결과에 따른 동작이 제2 화자가 미리 설정한 사후 통지 동작 리스트에 포함되는 경우, 음성인식 서버는 단계(S209)를 먼저 실행하고, 사후 통지 절차(S206, S301-S303)를 나중에 수행하도 록 결정할 수 있다. 사후 통지 동작 리스트는 메모리에 저장될 수 있으며, 사후 통지 동작 리스트에는 음 성인식 스피커 장치가 수행할 수 있는 동작들 중에서 제2 화자가 선택한 일부의 동작이 포함될 수 있다. 예컨대, 전화 걸기, 설정 변경 등과 같은 동작들이 미리 설정한 사후 통지 동작 리스트에 포함될 수 있다. 사 후 통지 동작 리스트에 포함되는 동작들은 등록된 화자들마다 다르게 설정될 수 있다. 이상 설명된 본 발명에 따른 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것 일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예 시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에 서 관리하는 기록매체 내지 저장매체도 들 수 있다. 본 명세서에서, \"부\", \"모듈\" 등은 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프 로세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 예를 들면, \"부\", \"모듈\" 등은 소프트웨어 구성 요소들, 객체 지향 소프트웨어 구성 요소들, 클래스 구성 요소들 및 태스 크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들에 의해 구현될 수 있다."}
{"patent_id": "10-2017-0094968", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2017-0094968", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 음성인식 시스템의 예시적인 네트워크 구성도이다. 도 2a는 일 실시예에 따른 음성인식 스피커 장치의 내부 구성을 설명하기 위한 블록도이다. 도 2b는 다른 실시예에 따른 음성인식 스피커 장치의 내부 구성을 설명하기 위한 블록도이다. 도 3은 일 실시예에 따른 음성인식 서버의 내부 구성을 설명하기 위한 블록도이다. 도 4a는 일 실시예에 따른 음성인식 서버의 프로세서의 내부 구성을 설명하기 위한 블록도이다. 도 4b는 일 실시예에 따른 음성인식 서버의 프로세서의 내부 구성을 설명하기 위한 블록도이다. 도 5a 및 도 5b는 일 실시예에 따른 음성인식 시스템의 화자 검증 방법을 설명하기 위한 예시적인 흐름도이다. 도 6은 일 실시예에 따라서 음성인식 시스템에 접속되는 제2 화자의 휴대 장치의 예시적인 화면을 도시한다. 도 7은 다른 실시예에 따른 음성인식 시스템의 화자 검증 방법을 설명하기 위한 예시적인 흐름도이다."}
