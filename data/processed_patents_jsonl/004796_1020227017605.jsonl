{"patent_id": "10-2022-7017605", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0083830", "출원번호": "10-2022-7017605", "발명의 명칭": "이미지 처리 방법 및 이미지 합성 방법, 이미지 처리 장치 및 이미지 합성 장치, 그리고 저장", "출원인": "텐센트 테크놀로지", "발명자": "라이 샤오이"}}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 의해 수행되는 이미지 처리 방법으로서,복수의 처리될 얼굴 특징점(feature point)을 획득하기 위해 처리될 얼굴 이미지에 대해 특징점 인식을 수행하는 단계 ― 상기 복수의 처리될 얼굴 특징점은 상기 처리될 얼굴 이미지의 얼굴 특징점임 ―;상기 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보를 결정하는 단계― 상기 복수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점임 ―;상기 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 상기 특징점 위치 오프셋 정보에기초하여, 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정을 수행하는 단계 ― 상기 기준 얼굴 깊이 이미지는 상기 기준 얼굴 이미지에 대응하는 얼굴 깊이 이미지임 ―; 및타깃 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 깊이 이미지에 따라 상기 처리될 얼굴 이미지에 대해 방향편향을 수행하는 단계를 포함하는 이미지 처리 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 타깃 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 깊이 이미지에 따라 상기 처리될 얼굴 이미지에 대해방향 편향을 수행하는 단계는,상기 타깃 얼굴 깊이 이미지 및 기준 깊이 관계에 따라 상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이정보를 획득하는 단계;상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보에 따라 상기 처리될 얼굴 이미지에 대응하는 입체얼굴 이미지를 생성하는 단계;편향된 입체 얼굴 이미지를 획득하기 위해 상기 입체 얼굴 이미지를 타깃 방향으로 편향시키는 단계; 및상기 타깃 얼굴 이미지를 획득하기 위해 상기 편향된 입체 얼굴 이미지를 상기 처리될 얼굴 이미지의 방향으로투영하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 타깃 얼굴 깊이 이미지 및 기준 깊이 관계에 따라 상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이정보를 획득하는 단계는,상기 타깃 얼굴 깊이 이미지로부터 각각의 픽셀의 깊이 레벨을 결정하는 단계;상기 복수의 처리될 얼굴 특징점의 깊이 기준 특징점과 상기 기준 깊이 관계에 따라 상기 처리될 얼굴 이미지의얼굴 깊이 파라미터를 결정하는 단계; 및상기 얼굴 깊이 파라미터 및 상기 각각의 픽셀의 깊이 레벨에 기초하여, 상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 결정하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2022-0083830-3-제1항에 있어서, 상기 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보를 결정하는 단계는,상기 기준 얼굴 이미지에 대한 상기 처리될 얼굴 이미지의 특징점 위치 오프셋 정보를 결정하기 위해 상기 기준얼굴 이미지의 포지셔닝(positioning) 특징점을 위치 기준으로 사용하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 타깃 얼굴 깊이 이미지를 획득하기 위해, 상기 특징점 위치 오프셋 정보에 기초하여 기준 얼굴 깊이 이미지의얼굴 특징점에 대해 위치 조정을 수행하는 단계는, 상기 특징점 위치 오프셋 정보로부터 상기 복수의 처리될 얼굴 특징점의 오프셋 방향 및 오프셋 가중치를 결정하는 단계; 및상기 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 상기 오프셋 방향 및 상기 오프셋 가중치에 따라, 상기 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 상기 위치 조정을 수행하는 단계를 포함하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "전자 장치에 의해 수행되는 이미지 합성 방법으로서,처리될 얼굴 이미지를 획득하는 단계;상기 처리될 얼굴 이미지에 따라 타깃 얼굴 이미지를 획득하는 단계 ― 상기 타깃 얼굴 이미지는 제1항 내지 제5항 중 어느 한 항에 따른 이미지 처리 방법의 처리에 의해 획득됨 ―; 및타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 상기 타깃 얼굴 이미지를 융합하는 단계를 포함하는 이미지 합성 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 처리될 얼굴 이미지에 따라 타깃 얼굴 이미지를 획득하는 단계는,상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 획득하는 단계;상기 각각의 픽셀 포인트의 깊이 정보에 따라 상기 처리될 얼굴 이미지에 대응하는 입체 얼굴 이미지를 생성하는 단계;편향된 입체 얼굴 이미지를 획득하기 위해 상기 입체 얼굴 이미지를 타깃 방향으로 편향시키는 단계; 및상기 타깃 얼굴 이미지를 획득하기 위해 상기 편향된 입체 얼굴 이미지를 상기 처리될 얼굴 이미지의 방향으로투영하는 단계를 포함하는, 이미지 합성 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 처리될 얼굴 이미지를 획득하는 단계는,미리 설정된 방향 범위 내에서 상기 얼굴 영역의 복수의 처리될 이미지를 획득하는 단계;상기 복수의 처리될 이미지에 따라 입체 얼굴 이미지를 생성하는 단계;공개특허 10-2022-0083830-4-편향된 입체 얼굴 이미지를 획득하기 위해 상기 입체 얼굴 이미지를 타깃 방향으로 편향시키는 단계; 및상기 타깃 얼굴 이미지를 획득하기 위해 상기 편향된 입체 얼굴 이미지를 상기 처리될 얼굴 이미지의 방향으로투영하는 단계를 포함하는, 이미지 합성 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 처리될 얼굴 이미지를 획득하는 단계는,처리될 이미지를 획득하는 단계; 및상기 처리될 이미지의 얼굴 영역의 방향이 미리 설정된 방향인 경우에, 상기 처리될 이미지로부터의 얼굴 영역을 상기 처리될 얼굴 이미지로서 분할하는 단계 ― 상기 미리 설정된 방향은 상기 얼굴 영역이 기준 얼굴 이미지 내에 위치되는 방향임 ―를 포함하는, 이미지 합성 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서, 상기 처리될 얼굴 이미지를 획득하는 단계 이전에,상기 이미지 합성 방법은,상기 사용자에 의해 수행되는 얼굴 처리 페이지 상의 이미지 템플릿 선택 조작이 검출되는 경우에, 상기 사용자에 의해 선택되는 템플릿 이미지를 획득하는 단계; 및상기 템플릿 이미지의 얼굴 영역의 방향 및 상기 처리될 얼굴 이미지의 방향에 기초하여, 타깃 편향 각도를 결정하는 단계를 더 포함하고,상기 편향된 입체 얼굴 이미지를 획득하기 위해 상기 입체 얼굴 이미지를 타깃 방향으로 편향시키는 단계는,상기 편향된 입체 얼굴 이미지를 획득하기 위해, 상기 타깃 편향 각도에 기초하여 상기 입체 얼굴 이미지를 상기 타깃 방향으로 편향시키는 단계를 포함하는, 이미지 합성 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항에 있어서, 상기 타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 상기 타깃 얼굴 이미지를 융합하는 단계는,타깃 얼굴 특징점을 획득하기 위해 상기 타깃 얼굴 이미지에 대해 특징점 인식을 수행하는 단계;합성 얼굴 영역을 획득하기 위해, 상기 타깃 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 상기 타깃 얼굴 이미지와 상기 템플릿 이미지의 얼굴 영역을 융합하는 단계 ― 상기 템플릿 얼굴 특징점은 상기 템플릿이미지의 얼굴 특징점임 ―; 및상기 타깃 이미지를 획득하기 위해 상기 템플릿 이미지의 다른 영역과 상기 합성 얼굴 영역을 합성하는 단계를 포함하는, 이미지 합성 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 합성 얼굴 영역을 획득하기 위해, 상기 타깃 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 상공개특허 10-2022-0083830-5-기 타깃 얼굴 이미지와 상기 템플릿 이미지의 얼굴 영역을 융합하는 단계는,상기 타깃 얼굴 이미지로부터 중심 영역 및 원주 영역을 결정하는 단계;처리될 얼굴 특징점 및 상기 대응하는 템플릿 얼굴 특징점에 기초하여, 상기 중심 영역과 상기 템플릿 이미지의대응하는 중심 영역을 제1 가중치로 융합하는 단계;상기 처리될 얼굴 특징점 및 상기 대응하는 템플릿 얼굴 특징점에 기초하여, 상기 원주 영역과 상기 템플릿 이미지의 대응하는 원주 영역을 제2 가중치로 융합하는 단계 ― 상기 제1 가중치는 상기 제2 가중치보다 더 큼―; 및상기 합성 얼굴 영역으로서 상기 융합된 이미지를 획득하는 단계를 포함하는, 이미지 합성 방법."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "이미지 처리 장치로서,복수의 처리될 얼굴 특징점을 획득하기 위해 처리될 얼굴 이미지에 대해 특징점 인식을 수행하도록 구성된 인식유닛;상기 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보를 결정하도록 구성된 계산 유닛 ― 상기 복수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점임 ―;상기 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 상기 특징점 위치 오프셋 정보에기초하여 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정을 수행하도록 구성된 조정 유닛 ― 상기 기준얼굴 깊이 이미지는 상기 기준 얼굴 이미지에 대응하는 얼굴 깊이 이미지임 ―; 및타깃 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 깊이 이미지에 따라 상기 처리될 얼굴 이미지에 대해 방향편향을 수행하도록 구성된 편향 유닛을 포함하는 이미지 처리 장치."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 편향 유닛은 획득 서브유닛, 생성 서브유닛, 편향 서브유닛 및 투영 서브유닛을 포함하며,상기 획득 서브유닛은 상기 타깃 얼굴 깊이 이미지 및 기준 깊이 관계에 따라 상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 획득하도록 구성되고,상기 생성 서브유닛은 상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보에 따라 상기 처리될 얼굴 이미지에 대응하는 입체 얼굴 이미지를 생성하도록 구성되며,상기 편향 서브유닛은 편향된 입체 얼굴 이미지를 획득하기 위해 상기 입체 얼굴 이미지를 타깃 방향으로 편향시키도록 구성되고,상기 투영 서브유닛은 상기 타깃 얼굴 이미지를 획득하기 위해 상기 편향된 입체 얼굴 이미지를 상기 처리될 얼굴 이미지의 방향으로 투영하도록 구성되는,이미지 처리 장치."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 획득 서브유닛은,상기 타깃 얼굴 깊이 이미지로부터 각각의 픽셀의 깊이 레벨을 결정하고,상기 처리될 얼굴 특징점의 깊이 기준 특징점과 상기 기준 깊이 관계에 따라 상기 처리될 얼굴 이미지의 얼굴깊이 파라미터를 결정하며,공개특허 10-2022-0083830-6-상기 얼굴 깊이 파라미터 및 상기 각각의 픽셀의 깊이 레벨에 기초하여, 상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 결정하도록추가로 구성되는, 이미지 처리 장치."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "이미지 합성 장치로서,처리될 얼굴 이미지를 획득하도록 구성된 획득 유닛;상기 처리될 얼굴 이미지에 따라 타깃 얼굴 이미지를 획득하도록 구성된 처리 유닛 ― 상기 타깃 얼굴 이미지는제1항 내지 제5항 중 어느 한 항에 따른 이미지 처리 방법의 처리에 의해 획득됨 ―; 및타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 상기 타깃 얼굴 이미지를 융합하도록 구성된 융합유닛을 포함하는 이미지 합성 장치."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 이미지 합성 장치는,제1 합성 유닛 ― 상기 제1 합성 유닛은,상기 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 획득하고,상기 각각의 픽셀 포인트의 깊이 정보에 따라 상기 처리될 얼굴 이미지에 대응하는 입체 얼굴 이미지를 생성하며,편향된 입체 얼굴 이미지를 획득하기 위해 상기 입체 얼굴 이미지를 타깃 방향으로 편향시키고,상기 타깃 얼굴 이미지를 획득하기 위해 상기 편향된 입체 얼굴 이미지를 상기 처리될 얼굴 이미지의 방향으로투영하도록구성됨 ―을 더 포함하는 이미지 합성 장치."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서, 상기 이미지 합성 장치는,제2 합성 유닛 ― 상기 제2 합성 유닛은,미리 설정된 방향 범위 내에서 상기 얼굴 영역의 복수의 처리될 이미지를 획득하고,상기 복수의 처리될 이미지에 따라 입체 얼굴 이미지를 생성하며,편향된 입체 얼굴 이미지를 획득하기 위해 상기 입체 얼굴 이미지를 타깃 방향으로 편향시키고,상기 타깃 얼굴 이미지를 획득하기 위해 상기 편향된 입체 얼굴 이미지를 상기 처리될 얼굴 이미지의 방향으로투영하도록구성됨 ―을 더 포함하는 이미지 합성 장치."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서, 상기 획득 유닛은,공개특허 10-2022-0083830-7-처리될 이미지를 획득하고,상기 처리될 이미지의 얼굴 영역의 방향이 미리 설정된 방향인 경우에, 상기 처리될 이미지로부터의 얼굴 영역을 상기 처리될 얼굴 이미지로서 분할하도록 ― 상기 미리 설정된 방향은 상기 얼굴 영역이 기준 얼굴 이미지내에 위치되는 방향임 ―추가로 구성되는, 이미지 합성 장치."}
{"patent_id": "10-2022-7017605", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 판독 가능 저장 매체로서,복수의 명령을 저장하고,상기 명령은 제1항 내지 제5항 중 어느 한 항에 따른 이미지 처리 방법에서의 작동, 또는 제6항 내지 제12항 중어느 한 항에 따른 이미지 합성 방법에서의 작동을 수행하기 위해 프로세서에 의해 로딩되도록 구성되는,컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-7017605", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 처리 방법 및 이미지 합성 방법, 이미지 처리 장치 및 이미지 합성 장치, 그리고 저장 매체가 개시된다. 이 방법은, 처리될 얼굴 부분 특징점을 획득하기 위해 처리될 얼굴 이미지에 대해 특징점 인식을 수행하는 단계 ― 상기 얼굴 부분 특징점은 상기 얼굴 이미지의 얼굴 부분 특징점임 ―; 기준 얼굴 부분 특징점에 대한 (뒷면에 계속)"}
{"patent_id": "10-2022-7017605", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2020년 6월 1일에 중국 특허청에 출원된 중국 특허 출원 제202010486646.0호('이미지 처리 방법 및 이미지 합성 방법, 이미지 처리 장치 및 이미지 합성 장치, 그리고 저장 매체')의 우선권을 주장하며 이것은 그 전체가 참조로서 본 명세서에 포함된다. 본 출원은 이미지 처리 분야에 관한 것으로, 구체적으로는, 이미지 처리 및 이미지 합성을 위한 방법 및 장치, 그리고 컴퓨터 판독 가능 저장 매체에 관한 것이다."}
{"patent_id": "10-2022-7017605", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일부 이미지 처리 애플리케이션은 사용자에게 일부 이미지 처리 기능을 제공할 수 있다. 예를 들어, 사용자에 의해 업로드된 전면 이미지에 따라 다양한 각도의 얼굴 이미지가 생성될 수 있다. 현재, 3D 얼굴 재구성 기술 은 이미지 처리 애플리케이션에 적용되어 사용자에 의해 업로드된 전면 이미지에 따라 3D 모델을 생성하고, 그 다음 모델에 따라 다양한 각도의 얼굴 이미지를 획득한다. 그러나, 이러한 방식은 고정밀 3D 모델의 생성 및 개입이 필요하며, 사용자의 얼굴 각도 및 얼굴과 얼굴 특징 사이의 비율을 동적으로 매칭시키기 위해 변형 가능 한 3D 모델이 필요하다. 또한, 대량의 3D 구현 개발이 필요하다. 따라서, 적용된 제품의 기술적 아키텍처가 복잡하여, 이미지 처리 속도에 영향을 미친다. 본 출원의 실시예는 처리될 얼굴 이미지를 타깃 방향으로 간단하고 편리하게 편향시킬 수 있는 이미지 처리 및 이미지 합성을 위한 방법 및 장치, 그리고 컴퓨터 판독 가능 저장 매체를 제공한다. 본 출원의 실시예는 전자 장치에 의해 수행되는 이미지 처리 방법을 제공하며, 이 방법은, 처리될 얼굴 이미지를 획득하는 단계; 복수의 처리될 얼굴 특징점(feature point)을 획득하기 위해 처리될 얼굴 이미지에 대해 특징점 인식을 수행하 는 단계; 상기 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보를 결정하는 단계 ― 상기 복수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점임 ―; 상기 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 상기 특징점 위치 오프셋 정보에 기초하여 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정을 수행하는 단계 ― 상기 기준 얼굴 깊이 이 미지는 상기 기준 얼굴 이미지에 대응하는 얼굴 깊이 이미지임 ―; 및 타깃 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 깊이 이미지에 따라 상기 처리될 얼굴 이미지에 대해 방향 편향을 수행하는 단계를 포함한다.이에 상응하여, 본 출원의 실시예는 전자 장치에 의해 수행되는 이미지 합성 방법을 추가로 제공하며, 이 방법 은, 처리될 얼굴 이미지를 획득하는 단계; 상기 처리될 얼굴 이미지에 따라 타깃 얼굴 이미지를 획득하는 단계 ― 상기 타깃 얼굴 이미지는 상기 이미지 처리 방법의 처리에 의해 획득됨 ―; 및 타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 상기 타깃 얼굴 이미지를 융합하는 단계를 포함한다. 본 출원의 실시예는 이미지 처리 장치를 추가로 제공하며, 이 이미지 처리 장치는, 복수의 처리될 얼굴 특징점을 획득하기 위해 처리될 얼굴 이미지에 대해 특징점 인식을 수행하도록 구성된 인식 유닛; 상기 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보를 결정하도록 구 성된 계산 유닛 ― 상기 복수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점임 ―; 상기 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 상기 특징점 위치 오프셋 정보에 기초하여, 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정을 수행하도록 구성된 조정 유닛 ― 상기 기 준 얼굴 깊이 이미지는 상기 기준 얼굴 이미지에 대응하는 얼굴 깊이 이미지임 ―; 및 타깃 얼굴 이미지를 획득하기 위해 상기 타깃 얼굴 깊이 이미지에 따라 상기 처리될 얼굴 이미지에 대해 방향 편향을 수행하도록 구성된 편향 유닛을 포함한다. 이에 상응하여, 본 출원의 실시예는 이미지 합성 장치를 추가로 제공하며, 이 이미지 합성 장치는, 처리될 얼굴 이미지를 획득하도록 구성된 획득 유닛; 상기 처리될 얼굴 이미지에 따라 타깃 얼굴 이미지를 획득하도록 구성된 처리 유닛 ― 상기 타깃 얼굴 이미지는 상기 이미지 처리 방법의 처리에 의해 획득됨 ―; 및 타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 상기 타깃 얼굴 이미지를 융합하도록 구성된 융합 유닛을 포함한다. 본 출원의 실시예는 컴퓨터 판독 가능 저장 매체를 추가로 제공하며, 이 컴퓨터 판독 가능 저장 매체는 복수의 명령을 저장하고, 상기 명령은 본 출원의 실시예에 따른 임의의 이미지 처리 방법 또는 이미지 합성 장치에서의 작동을 수행하기 위해 프로세서에 의해 로딩되도록 구성된다. 본 출원의 본 실시예에서, 처리될 얼굴 이미지가 획득될 수 있고, 특징점 인식이 복수의 처리될 얼굴 특징점을 획득하기 위해 처리될 얼굴 이미지에 대해 수행되며 ―복수의 처리될 얼굴 특징점은 처리될 얼굴 이미지의 얼굴 특징점임 ―, 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보가 결정되 고 ― 복수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점임 ―, 처리될 얼굴 이미지에 대응 하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 특징점 위치 오프셋 정보에 기초하여 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정이 수행되며 ― 기준 얼굴 깊이 이미지는 기준 얼굴 이미지에 대응하는 얼굴 깊이 이미지임 ―, 타깃 얼굴 이미지를 획득하기 위해 타깃 얼굴 깊이 이미지에 따라 처리될 얼굴 이미지에 대해 방 향 편향이 수행된다. 따라서, 해결수단은 처리될 얼굴 이미지를 타깃 방향으로 간단하고 편리하게 편향시킬 수 있다."}
{"patent_id": "10-2022-7017605", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 실시예의 기술적 해결수단은 본 출원의 실시예의 첨부 도면을 참조하여 이하에서 명확하고 완전하게 설명된다. 물론, 설명된 실시예는 본 출원의 모든 실시예가 아니라 단지 일부에 불과하다. 창의적인 노력 없 이 본 출원의 실시예에 기초하여 당업자에 의해 획득된 다른 모든 실시예는 본 출원의 보호 범위에 속할 것이다. 본 출원의 실시예는 이미지 처리 및 이미지 합성을 위한 방법 및 장치, 그리고 컴퓨터 판독 가능 저장 매체를 제공한다. 이미지 처리 장치는 구체적으로 전자 장치에 통합될 수 있다. 전자 장치는 단말, 서버 등일 수 있다. 단말은 모바일 전화, 태블릿 컴퓨터, 지능형 블루투스 장치, 노트북 컴퓨터 또는 개인용 컴퓨터(personal computer, PC)와 같은 장치일 수 있으며, 서버는 단일 서버이거나 또는 복수의 서버를 포함하는 서버 클러스터일 수 있다. 일부 실시예에서, 이미지 처리 장치는 복수의 전자 장치에 추가로 통합될 수 있다. 예를 들어, 이미지 처리 장 치는 복수의 서버에 통합될 수 있고, 본 출원의 이미지 처리 방법은 복수의 서버에 의해 구현될 수 있다. 일부 실시예에서, 이미지 처리는 또한 단말의 형태로 구현될 수 있다. 예를 들어, 도 1a를 참조하면, 전자 장치는 처리될 얼굴 이미지를 획득할 수 있고, 특징점 인식은 복수의 처리 될 얼굴 특징점을 획득하기 위해 처리될 얼굴 이미지에 대해 수행되며, 복수의 처리될 얼굴 특징점은 처리될 얼 굴 이미지의 어굴 특징점이고, 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프 셋 정보가 결정되며, 복수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점이고, 특징점 위치 오프셋 정보에 기초하여, 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해 기준 얼굴 깊 이 이미지의 얼굴 특징점에 대해 위치 조정이 수행되며, 기준 얼굴 깊이 이미지는 기준 얼굴 이미지에 대응하는 얼굴 깊이 이미지이고, 타깃 얼굴 이미지를 획득하기 위해 타깃 얼굴 깊이 이미지에 따라 처리될 얼굴 이미지에 대해 방향 편향이 수행된다. 따라서, 해결수단은 처리될 얼굴 이미지를 타깃 방향으로 간단하고 편리하게 편향 시킬 수 있다. 이에 상응하여, 이미지 합성 장치는 구체적으로 전자 장치에 통합될 수 있다. 전자 장치는 단말, 서버 등일 수 있다. 단말은 모바일 전화, 태블릿 컴퓨터, 지능형 블루투스 장치, 노트북 컴퓨터 또는 개인용 컴퓨터(PC)와 같은 장치일 수 있고, 서버는 단일 서버이거나 또는 복수의 서버를 포함하는 서버 클러스터일 수 있다. 일부 실시예에서, 이미지 합성 장치는 복수의 전자 장치에 추가로 통합될 수 있다. 예를 들어, 이미지 합성 장 치는 복수의 서버에 통합될 수 있고, 본 출원의 이미지 합성 방법은 복수의 서버에 의해 구현될 수 있다. 일부실시예에서, 이미지 합성은 또한 단말의 형태로 구현될 수 있다. 도 b를 참조하면, 전자 장치는 처리될 얼굴 이미지를 획득할 수 있고, 타깃 얼굴 이미지는 처리될 얼굴 이미지 에 따라 획득되며, 타깃 얼굴 이미지는 타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 융합된다. 해결수단에서, 사용자에 의해 업로드된 얼굴 이미지는 템플릿 이미지와 서로 다른 방향으로 융합될 수 있다. 즉, 사용자는 하나의 처리될 얼굴 이미지만 업로드한 다음, 다른 각도에서 복수의 타깃 이미지가 합성될 수 있 으므로, 이미지 합성의 재생성과 실용성이 향상될 수 있다. 상세한 설명은 아래에서 별도로 수행된다. 다음 실시예의 시퀀스 번호는 실시예의 우선 순위를 제한하고자 하 는 것이 아니다. 본 실시예에서, 이미지 처리 방법이 제공된다. 도 2a에 도시된 바와 같이, 이미지 처리 방법은 다음의 구체적 인 단계를 포함할 수 있다. 특징점 인식은 처리될 얼굴 특징점을 획득하기 위해 처리될 얼굴 이미지에 대해 수행된다. 처리될 얼굴 이미지는 사용자에 의해 업로드된 처리될 이미지의 얼굴 영역을 지칭한다. 실시예에서, 단말은 처리될 이미지를 획득하기 위해 다음의 단계를 취할 수 있다. 처리될 이미지가 획득되고, 처리될 이미지의 얼굴 영역의 방향이 미리 설정된 방향인 경우, 얼굴 영역은 처리될 얼굴 이미지로서 처리될 이 미지로부터 분할된다. 미리 설정된 방향은 기준 얼굴 이미지의 얼굴 영역이 위치되는 방향이다. 적용의 편의를 위해, 미리 설정된 방 향은 일반적으로 정면으로 설정된다. 즉, 이미지의 머리의 코로나선(coronal line)이 위치된 면이 이미지가 위 치된 면과 평행하다. 기준 얼굴 이미지는 미리 설정된 표준 얼굴 이미지이다. 표준 얼굴은 대량의 얼굴 이미지를 융합함으로써 획득 될 수 있다. 실시예에서, 이미지 처리 페이지는 단말에 디스플레이될 수 있고, 사용자는 처리될 이미지를 획득하기 위해 이 미지 처리 페이지에 대한 조작을 수행할 수 있다. 예를 들어, 이미지 처리 페이지에는 픽처를 획득하기 위한 제어가 제공되고, 제어는 처리될 이미지를 획득하기 위한 명령 인터페이스이며, 버튼 및 아이콘과 같은 다양한 형태로 표현될 수 있다. 사용자가 제어를 클릭하는 경우, 단말은 픽처를 획득하기 위한 명령을 수신하고, 명령 에 따라 처리될 이미지를 획득한다. 실시예에서, 단말은 명령에 기초하여 카메라를 켜고, 촬영 페이지에서 사용자에 의해 수행된 조작에 기초하여 처리될 이미지를 획득하기 위해 촬영 페이지를 디스플레이할 수 있다. 다른 실시예에서, 단말은 명령에 기초하 여 단말 메모리에 저장된 픽처를 추가로 획득하고, 사용자에 의해 수행된 선택 조작에 기초하여 단말 메모리로 부터 처리될 이미지를 결정할 수 있다. 실시예에서, 도 5d를 참조하면, 처리될 이미지의 얼굴 영역의 방향이 미리 설정된 방향이 아닌 경우, 얼굴 영역 이미지는 처리될 이미지로부터 분할될 수 있고, 얼굴 영역 이미지는 기준 얼굴 이미지에 따라 처리될 얼굴 이미 지를 획득하기 위해 미리 설정된 방향으로 편향되며, 여기서 얼굴 영역 이미지를 미리 설정된 방향으로 편향시 키는 데 사용되는 방법에 대해서는 실시예 102 내지 105가 참조될 수 있으며, 세부 사항은 여기에서 반복되지 않는다. 얼굴 특징점은 얼굴 부분의 필수 특징(얼굴 특징과 같음)을 반영하는 포인트일 수 있으며, 예를 들어, 얼굴 윤 곽 특징점, 눈 특징점(왼쪽 눈 특징점, 오른쪽 눈 특징점, 눈동자 특징점과 같음), 눈썹 특징점(왼쪽 눈썹 특징 점, 오른쪽 눈썹 특징점과 같음), 입 특징점, 코 특징점 등과 같은 얼굴 특징점을 포함할 수 있다. 얼굴 특징점을 인식하는 방법에는 여러 가지가 있다. 예를 들어, 딥 러닝 네트워크 모델에 기초하여 얼굴 특징 점이 인식될 수 있다. 다른 예로, 훈련된 얼굴 특징 네트워크 인식 모델에 기초하여 얼굴 이미지에 대해 특징 점 인식이 수행될 수 있고, 얼굴 특징 네트워크 인식 모델은 컨볼루션 신경망에 기초한 모델로서 제공될 수 있 다. 얼굴 특징 네트워크 인식 모델이 사용되기 전에, 얼굴 특징 네트워크 인식 모델은 대량의 샘플 얼굴 이미지를 사용하여 훈련될 필요가 있다.얼굴 특징 네트워크 인식 모델은 인공지능(artificial intelligence, AI)을 포함하는데, 이는 디지털 컴퓨터를 사용하여 인간의 환경 지각, 지식 습득 및 지식 사용을 시뮬레이션하는 기술이다. 이 기술은 기계가 지각, 추 론 및 의사 결정과 같은 인간과 유사한 기능을 가질 수 있도록 한다. AI 기술은 주로 컴퓨터 비전(computer vision, CV) 기술, 음성 처리 기술, 자연어 처리 기술, 머신 러닝/딥 러닝(deep learning, DL)과 같은 분야를 포함한다. CV는 처리될 이미지를 인식하고, 측정하며, 추가 처리하기 위해 컴퓨터를 사용하여 인간 눈을 대체하는 기술이 다. CV 기술은 일반적으로 이미지 처리, 이미지 인식, 이미지 시맨틱 이해, 이미지 검색, 가상 현실, 증강 현 실, 동기 위치 지정 및 지도 구성과 같은 기술을 포함하며, 예를 들어 이미지 채색 및 이미지 스트로크 추출과 같은 이미지 처리 기술을 포함한다. 인식된 얼굴 특징점의 개수는 필요에 따라 설정될 수 있으며, 예를 들어 인식된 얼굴 윤곽 특징점의 개수, 눈 특징점의 개수 등이 설정될 수 있다. 예를 들어, 도 5a를 참조하면, 얼굴 특징 네트워크 인식 모델은 얼굴 이미지에 대한 인식을 수행하는 데 사용되 고, 얼굴 특징점이 획득될 수 있다. 얼굴 특징의 특징점은 얼굴 윤곽에 대해 21개 포인트, 왼쪽 눈에 대해 8개 의 포인트, 오른쪽 눈에 대해 8개의 포인트, 동공에 대해 2개의 포인트, 왼쪽 눈썹에 대해 8개의 포인트, 오른 쪽 눈썹에 대해 8개의 포인트, 입에 대해 20개의 포인트 및 코에 대해 13개의 포인트를 포함하여 88개의 좌표 포인트에 의해 설명될 수 있다. 처리될 얼굴 특징점과 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보가 결정되고, 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점이다. 도 5a를 참조하면, 대응하는 기준 얼굴 특징점에 대한 처리될 얼굴 특징점 사이의 위치 오프셋 정보가 계산되고, 위치 오프셋 정보는 오프셋 방향 및 오프셋 가중치를 포함한다. 실시예에서, 기준 얼굴 이미지의 위치 특징점은 기준 얼굴 이미지에 대한 처리될 얼굴 이미지의 특징점 위치 오 프셋 정보를 결정하기 위한 위치 기준으로서 사용될 수 있다. 특징점을 찾기 위해 코끝의 특징점이 선택될 수 있다. 특징점 위치 오프셋 정보에 기초하여, 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정이 수행된다. 도 5c를 참조하면, 조정은 구체적으로 다음의 단계를 포함할 수 있다. 처리될 얼굴 특징점의 오프셋 방향 및 오프셋 가중치는 특징점 위치 오프셋 정보로부터 결정되고, 오프셋 방향 및 오프셋 가중치에 따라, 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정이 수행된다. 깊이 이미지는 표준 안면 해부학에 따라 그려진다. 깊이가 가장 얕은 위치에서 깊이가 가장 깊은 위치까지 흰 색에서 검은색으로 표현되며, 기본적으로 코로나선(머리 앞의 가시 범위)까지 코끝을 덮으며 색상이 너무 유연 하고 부드럽다. 도 5a를 참조하면, 사용자의 얼굴을 인식함으로써, 얼굴의 주요 포인트 및 얼굴 특징이 파악되고, 기준 얼굴 이 미지 및 처리될 얼굴 이미지의 특징점 위치 오프셋 정보는 \"깊이 마스크\"와 유사한 처리될 얼굴 이미지에 대응 하는 깊이 이미지를 형성하기 위해 기준 깊이 이미지로 전달된다. 이와 같이, \"3D\" 얼굴 재구성은 3D 모델과 3D 기술을 도입하지 않고 시뮬레이션된다. 따라서, 해결수단은 처리될 얼굴 이미지를 타깃 방향으로 간단하고 편리하게 편향시킬 수 있다. 타깃 얼굴 이미지를 획득하기 위해 타깃 얼굴 깊이 이미지에 따라 처리될 얼굴 이미지에 대해 방향 편향이 수행 된다. 실시예에서, 도 5b 및 도 5c를 참조하면, 단계는 구체적으로, 타깃 얼굴 깊이 이미지와 기준 깊이 관계에 따라 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 획득 하는 단계; 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보에 따라 처리될 얼굴 이미지에 대응하는 입체 얼굴 이미 지를 생성하는 단계; 편향된 입체 얼굴 이미지를 획득하기 위해 입체 얼굴 이미지을 타깃 방향으로 편향시키는 단계; 및 타깃 얼굴 이미지를 획득하기 위해 편향된 입체 얼굴 이미지를 처리될 얼굴 이미지의 방향으로 투영하는 단계를 포함한다. 도 5b를 참조하면, 기준 깊이 관계는 눈썹에서 턱까지의 길이와 생성된 최대 깊이 사이의 관계를 지칭한다. 본 실시예에서, 얼굴의 적절한 깊이는 사람의 머리 구조에 따라 계산될 수 있으며, 생성된 최대 깊이 사이의 관계 는 생성된 최대 깊이=0.75a로서 취해지며, 여기서 a는 눈썹에서 턱까지의 길이이다. 편향된 입체 얼굴 이미지 는 도 5의 세 번째 픽처에 도시되어 있다. 투영은 편향된 입체 얼굴 이미지의 그림자를 처리될 얼굴 이미지의 방향과 일치하는 평면에 투사하는 것을 지칭 한다. \"타깃 얼굴 깊이 이미지 및 기준 깊이 관계에 따라 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 획 득하는 단계\"는, 타깃 얼굴 깊이 이미지으로부터 각각의 픽셀의 깊이 레벨을 결정하는 단계; 처리될 얼굴 특징점의 깊이 기준 특징점과 기준 깊이 관계에 따라 처리될 얼굴 이미지의 얼굴 깊이 파라미터를 결정하는 단계; 및 얼굴 깊이 파라미터 및 각각의 픽셀의 깊이 레벨에 기초하여, 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 결정하는 단계를 포함할 수 있다. 도 6d에 도시된 바와 같이, 본 실시예에서, 타깃 각도를 갖는 얼굴 이미지를 획득하기 위해 사용자에 의해 입력 된 정면 얼굴 이미지에 대해 처리가 수행될 수 있다. 즉, 해결수단은 처리될 얼굴 이미지를 타깃 방향으로 간 단하고 편리하게 편향시킬 수 있다. 본 출원의 실시예에서, 이미지 처리 방법은 다음의 단계에 따라 수행될 수 있다. 1) 처리될 얼굴 특징점의 위치, 기준 얼굴 깊이 이미지 및 특징점의 위치에 따라, 변형 및 신축을 통해, 처리될 얼굴 특징점의 위치와 일치하는 얼굴 깊이 이미지가 획득되고, 중심 정렬이 유지된다. 2) 템플릿 이미지의 특징점과 처리될 얼굴 이미지의 특징점에 따라 회전 행렬이 계산된다. 3) 회전 행렬에 따라, 원래의 처리될 얼굴 이미지의 각각의 픽셀 포인트의 위치가 회전된 이미지에서 계산된다. 4) 채워진 후 픽셀이 없는 위치에 대해, 가장 가까운 이웃 픽셀 값이 채워진다. 이러한 단계의 구현은 아래에서 상세하게 설명된다. 1) 처리될 얼굴 특징점의 얼굴 특징점의 위치, 기본 얼굴 깊이 이미지 및 특징점의 위치에 따라, 변형 및 신축 에 의해, 처리될 얼굴 특징점의 얼굴 특징점의 위치와 일치하는 얼굴 깊이 이미지가 획득되고, 중심 정렬이 유 지된다. 기본 얼굴 깊이 이미지는 도 5a에 도시되어 있으며, 얼굴 특징점이 표시된 2차원 흑백 이미지로, 얼굴의 서로 다른 영역의 깊이 정보를 표현한 것이다. 사용자마다 얼굴 형상과 크기가 다르기 때문에, 기본 얼굴 깊이 이미 지는 변형을 통해 변형되고 신축될 수 있다. 이에 의해, 사용자의 얼굴 특징점의 위치와 일치하는 효과가 달성 될 수 있고, 그 다음 처리될 얼굴 이미지의 각각의 픽셀의 얼굴 깊이 정보가 획득될 수 있다. 이러한 단계의 알고리즘은 원래의 얼굴 융합 과정에서의 변형의 알고리즘과 일치한다. 아래 이미지는 변형 후 특정 처리될 얼 굴 이미지에 대한 깊이 이미지이다. 2) 템플릿 이미지의 특징점과 처리될 얼굴 이미지의 특징점에 따라 회전 행렬이 계산된다. 회전 각도가 각각 좌표축을 중심으로하는 회전(x축, y축 및 z축을 중심으로 하는 회전) 각도를 나타내는 (α, β, γ)인 것으로 가정하면, 회전 행렬은 아래의 3차원 좌표계의 표준 좌표점 회전 공식, 즉 이다. 3) 회전 행렬에 따라, 원래의 처리될 얼굴 이미지의 각각의 픽셀 포인트의 위치는 회전된 이미지에서 계산되고, 픽셀이 채워진다. 회전 행렬 R이 획득된 후, 회전 후 처리될 얼굴 이미지의 각각의 픽셀 포인트의 좌표는 처리될 얼굴 이미지, 얼 굴 특징점의 위치 및 얼굴의 깊이 이미지에 따라 새로운 이미지에서 계산될 수 있다. R = {R[0], R[1], R[2], R[3], R[4], R[5], R[6], R[7], R[8]}인 것으로 가정하면, 처리될 얼굴 이미지의 좌표점은 (i, j)이고, 좌표점에 대응하는 깊이 정보는 픽셀 깊이인 경우, 다음의 수학식 이 회전된 이미지에서 좌표점 (x, y) 및 깊이 z를 계산하는 데 사용될 수 있다: int x = ceil(R[0] * (j - center.x) + R[1] * (i - center.y) + R[2] * pixeldepth + center.x); int y = ceil(R[3] * (j - center.x) + R[4] * (i - center.y) + R[5] * pixeldepth + center.y); float z = R[6] * (j - center.x) + R[7] * (i - center.y) + R[8] * pixeldepth; 편향 후 동일한 좌표 (x, y)에 매핑된 복수의 픽셀이 있는 것으로 가정하면, 더 작은 z를 갖는 (사용자에게 더 가까운) 픽셀 포인트의 값은 편향 후 좌표 (x, y)로서 취해진다. 4) 채워진 후 픽셀이 없는 위치에 대해, 가장 가까운 이웃 픽셀 값이 채워진다. 이 단계는 타깃 얼굴 이미지에서 일부 픽셀이 누락되는 것을 방지하기 위해 타깃 얼굴 이미지에서 누락된 픽셀 을 채우는 것이다. 가장 단순하고 가장 가까운 이웃 픽셀로 채우기가 완료될 수 있다. 본 출원의 실시예에서 제공되는 얼굴 이미지 처리 해결수단은 다양한 얼굴 이미지 처리 시나리오, 예를 들어 이 미지 합성 시나리오에 적용될 수 있다. 도 6e를 참조하면, 전술한 실시예에서 설명된 이미지 처리 방법에 따라, 이미지 합성 방법이 아래에서 추가로 자세하게 설명된다. 본 실시예에서, 본 출원의 본 실시예에서 제공되는 이미지 합성 방법은 얼굴 이미지 처리를 예로 사용하여 상세 하게 설명된다. 도 2b에 도시된 바와 같이, 이미지 합성 방법은 도 4에 도시된 전자 장치에 의해 수행될 수 있고, 그 과정은 다 음과 같다. 처리될 얼굴 이미지가 획득된다. 실시예에서, 도 6a를 참조하면, 처리될 얼굴 이미지가 획득되기 전에, 다음의 단계는, 사용자에 의해 수행된 얼굴 처리 페이지에서 이미지 템플릿 선택 조작이 검출되는 경우, 사용자에 의해 선택된 템플릿 이미지를 획득하는 단계; 및 템플릿 이미지의 얼굴 영역의 방향 및 처리될 얼굴 이미지의 방향에 기초하여, 타깃 편향 각도를 결정하는 단계 를 더 포함한다.이에 상응하여, 편향된 입체 얼굴 이미지를 획득하기 위해 입체 얼굴 이미지를 타깃 방향으로 편향시키는 단계 는, 편향된 입체 얼굴 이미지를 획득하기 위해, 타깃 편향 각도에 기초하여, 입체 얼굴 이미지를 타깃 방향으로 편 향시키는 단계를 포함한다. 도 6a를 참조하면, 제1 그룹의 이미지는 템플릿 이미지이고, 제2 그룹의 이미지는 타깃 이미지이다. 타깃 얼굴 이미지는 처리될 얼굴 이미지에 따라 획득된다. 실시예에서, 타깃 얼굴 이미지는 제1 실시예의 방법을 사용하여 획득될 수 있다. 다른 실시예에서, 단말에 배치된 깊이 카메라는 사용자의 얼굴의 입체 이미지를 캡처하는 데 추가로 사용될 수 있으며, 처리될 얼굴 이미지에서 각각의 픽셀 포인트의 깊이 정보를 획득하는 단계; 각각의 픽셀 포인트의 깊이 정보에 따라 처리될 얼굴 이미지에 대응하는 입체 얼굴 이미지을 생성하는 단계; 편향된 입체 얼굴 이미지를 획득하기 위해 입체 얼굴 이미지을 타깃 방향으로 편향시키는 단계; 및 타깃 얼굴 이미지를 획득하기 위해 편향된 입체 얼굴 이미지를 처리될 얼굴 이미지의 방향으로 투영하는 단계 를 포함할 수 있다. 실시예에서, 타깃 얼굴 이미지는 참조 이미지에 대응하는 정규화된 좌표 코드(Normalized Coordinate Code, NCC)에 따라 획득되며, 여기서 NCC는 3차원 표현에서 얼굴을 보다 풍부하게 복원할 수 있다(예를 들어, 콧구멍 안쪽과 같은 정보지만, 합성 사진의 정확도에 관한 한 그러한 세부 사항은 저장될 수 있음). NCC는 3DMM 얼굴 재구성의 초기화 모델과 동일하며, 얼굴 포인트의 인식 및 전송을 통해 사용자를 위해 전체 각도 법선 정보를 갖는 마스크 PNCC가 생성될 수 있다. 실시예에서, 성숙한 3DMM 얼굴 재구성 기술 또는 인터페이스는 얼굴 재구성, 성형 및 표정 복원 후에 사용자의 얼굴의 3D 모델 및 텍스처를 신속하게 획득하도록 추가로 선택될 수 있고, 3D 모델은 회전되며 3D 좌표에 사용 된다. 실시예에서, 사용자는 다중 각도 이미지를 효율적으로 제공하기 위해 360° 연속 촬영으로 더 안내될 수 있다. 예를 들어, 카메라 자이로스코프의 전면의 초기 위치 지정 및 연동 포지셔닝을 통해, 사용자는 모바일 전화를 호를 그리도록 안내되고, 사용자 얼굴의 주요 각도에서 인물 사진이 촬영된다(처음으로 사용자의 얼굴 정보를 기록하기 위해 iOS와 FaceID의 상호 작용과 유사함). 사진이 5°마다 촬영되는 경우, 16개 내지 48개의 연속 셀카가 대부분의 정면 얼굴 각도를 커버할 수 있다. 다음의 단계가 포함될 수 있다: 미리 설정된 방향 범위 내에서 얼굴 영역의 복수의 처리될 이미지를 획득하는 단계; 복수의 처리될 이미지에 따라 입체 얼굴 이미지를 생성하는 단계; 편향된 입체 얼굴 이미지를 획득하기 위해 입체 얼굴 이미지를 타깃 방향으로 편향시키는 단계; 및 타깃 얼굴 이미지를 획득하기 위해 편향된 입체 얼굴 이미지를 처리될 얼굴 이미지의 방향으로 투영하는 단계 203. 타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 타깃 얼굴 이미지를 융합한다. 실시예에서, \"타깃 이미지를 획득하기 위해 템플릿 이미지의 얼굴 영역에 타깃 얼굴 이미지를 융합하는\" 단계는, 목표 얼굴 특징점을 획득하기 위해 타깃 얼굴 이미지에 대한 특징점 인식을 수행하는 단계; 타깃 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 합성 열굴 영역을 획득하기 위해 타깃 얼굴 이 미지 및 템플릿 이미지의 얼굴 영역과 타깃 얼굴 특징점을 융합하는 단계 ― 타깃 얼굴 특징점은 템플릿 이미지 의 얼굴 특징점임 ―; 및 타깃 이미지를 획득하기 위해 합성 얼굴 영역을 템플릿 이미지의 다른 영역과 합성하는 단계를 포함할 수 있다. 실시예에서, \"합성 얼굴 영역을 획득하기 위해 타깃 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 타깃 얼굴 이미지 및 템플릿 이미지의 얼굴 영역을 융합하는\" 단계는,타깃 얼굴 이미지로부터 중심 영역 및 원주 영역을 결정하는 단계; 처리될 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 상기 중심 영역 및 템플릿 이미지의 대응하는 중심 영역을 제1 가중치로 융합하는 단계; 처리될 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 원주 영역과 템플릿 이미지의 대응하는 원주 영역을 제2 가중치로 융합하는 단계 ― 제1 가중치는 제2 가중치보다 더 큼 ―; 및 도 6c를 참조하면, 융합된 이미지를 합성 얼굴 영역으로 획득하는 단계 를 포함할 수 있다. 중심 영역은 얼굴 특징이 위치하는 영역을 지칭하고, 기준 이미지의 중심 영역은 검은 하트 형상의 영역을 지칭 하며, 원주 영역은 중심 영역을 제외한 얼굴의 영역을 지칭한다. 실시예에서, 도 6c를 참조하면, 다음의 단계가 융합을 위해 사용될 수 있다. 1. 얼굴 특징 포지셔닝: 기존의 얼굴 인식 및 얼굴 특징 포지셔닝 알고리즘이 사용된다. 2. 자르기 및 보정. 타깃 얼굴 이미지의 얼굴 영역과 템플릿 이미지의 얼굴 영역이 각각 잘라지고, 잘린 이미 지는 정사각형이고, 코끝은 중심에 위치되며, 얼굴은 y 방향으로 수직이 되도록 한다. 3. 타깃 얼굴 이미지의 피부색 영역의 색상이 융합된 색상이 보다 자연스럽도록 조정된다. 4. 타깃 얼굴 이미지, 템플릿 이미지 및 마스크 맵이 타깃 얼굴 포인트에 따라 변형되고 조정된다. 이 단계에 서, 삼각형 맞춤을 통해 변형이 수행된다. 5. 변형된 타깃 얼굴 이미지 및 템플릿 이미지가 중첩되고, 마스크 맵을 사용하여 중첩 정도가 제어된다(예를 들어, 도 6c에서, 블랙 영역(중심 영역)이 타깃 얼굴 이미지 가중치를 더 많이 사용하고, 흰색 영역(원주 영 역)은 템플릿 이미지 가중치를 더 많이 사용함). 6. 최종 결과, 즉 타깃 이미지를 획득하기 위해 획득된 합성 얼굴 영역이 템플릿 이미지 내에 다시 붙여진다 (paste back). 이상에서 알 수 있듯이, 본 출원에서, 사용자에 의해 업로드된 얼굴 이미지가 템플릿 이미지와 서로 다른 방향 으로 융합될 수 있음을 알 수 있다. 도 6b를 참조하면, 사용자에 의해 입력된 이미지를 템플릿 이미지와 직접 융합하는 방식에 비해, 본 출원의 본 실시예에서의 이미지 합성 효과가 보다 자연스럽다. 즉, 사용자는 하나의 얼굴 이미지만 업로드하면, 여러 각도에서 복수의 얼굴 이미지가 생성될 수 있으므로, 이미지 합성의 재생성과 실용성이 향상될 수 있다. 도 5e에 도시된 바와 같이, 이미지 합성 방법은 포토 리터칭(photo-retouching) 애플리케이션의 미친 얼굴 변화 기능에 적용될 수 있다. 도 6e를 참조하면, (인물 사진과 같은) 복수의 각도의 이미지를 합성하는 것 외에도, 각도 변경 프로세스를 통 해 동적 또는 비디오 이미지 합성 기능에 기술적 해결수단이 적용될 수도 있다. 정면 이미지만으로도, 사용자 는 간단한 이미지 합성을 사용하여 연속 조향의 동적 결과를 획득할 수 있어, 제품의 게임 플레이 확장성을 높 일 수 있다(구현 로직은 GAN 생성 적대 네트워크 모델보다 더 간단하며, 서버 자원을 필요로 하지 않는다). 전술한 방법을 더 잘 구현하기 위해, 본 출원의 본 실시예는 이미지 처리 장치를 추가로 제공하고, 이미지 처리 장치는 전자 장치에 통합될 수 있으며, 전자 장치는 단말, 서버 등일 수 있다. 단말은 모바일 전화, 태블릿 컴 퓨터, 지능형 블루투스 장치, 노트북 컴퓨터 또는 개인용 컴퓨터(PC)와 같은 장치일 수 있고, 서버는 단일 서버 이거나 복수의 서버를 포함하는 서버 클러스터일 수 있다. 예를 들어, 본 실시예에서, 본 출원의 본 실시예의 방법은 예로서 전자 장치에 통합된 이미지 처리 장치를 사용 하여 상세하게 설명된다. 예를 들어, 도 3a에 도시된 바와 같이, 이미지 처리 장치는 인식 유닛, 계산 유닛, 조정 유닛 및 편향 유닛을 포함할 수 있으며, 1. 인식 유닛은 복수의 처리될 얼굴 특징점을 획득하기 위해 처리될 얼굴 이미지에 대한 특징점 인식을 수 행하도록 구성되고,2. 계산 유닛은 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보를 결정하도록 구성되며, 복수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점이며, 3. 조정 유닛은 특징점 위치 오프셋 정보에 기초하여, 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이 미지를 획득하기 위해 기준 얼굴 깊이 이미지의 얼굴 특징점에 대한 위치 조정을 수행하도록 구성되고, 기준 얼 굴 깊이 이미지는 기준 얼굴 이미지에 대응하는 얼굴 깊이 이미지이며, 4. 편향 유닛은 타깃 얼굴 이미지를 획득하기 위해 타깃 얼굴 깊이 이미지에 따라 처리될 얼굴 이미지에 대해 방향 편향을 수행하도록 구성된다. 편향 유닛은 획득 서브유닛, 생성 서브유닛, 편향 서브유닛 및 투영 서브유닛을 포함할 수 있으며, 획득 서브유닛은 타깃 얼굴 깊이 이미지 및 기준 깊이 관계에 따라 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 획득하도록 구성되고, 생성 서브유닛은 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보에 따라 처리될 얼굴 이미지에 대응하는 입체 얼굴 이미지를 생성하도록 구성되며, 편향 서브유닛은 편향된 입체 얼굴 이미지를 획득하기 위해 입체 얼굴 이미지를 타깃 방향으로 편향시키도록 구 성되고, 투영 서브유닛은 타깃 얼굴 이미지를 획득하기 위해 편향된 입체 얼굴 이미지를 처리될 얼굴 이미지의 방향으로 투영하도록 구성된다. 획득 서브유닛은, 타깃 얼굴 깊이 이미지로부터 각각의 픽셀의 깊이 레벨을 결정하고, 처리될 얼굴 특징점의 깊이 기준 특징점과 기준 깊이 관계에 따라 처리될 얼굴 이미지의 얼굴 깊이 파라미터를 결정하며, 얼굴 깊이 파라미터 및 각각의 픽셀의 깊이 레벨에 기초하여, 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 결정하도록 추가로 구성된다. 계산 유닛은, 기준 얼굴 이미지에 대한 처리될 얼굴 이미지의 특징점 위치 오프셋 정보를 결정하기 위해 기준 얼굴 이미지의 포지셔닝 특징점을 위치 기준으로 사용하도록 추가로 구성된다. 조정 유닛은, 특징점 위치 오프셋 정보로부터 처리될 얼굴 특징점의 오프셋 방향 및 오프셋 가중치를 결정하고, 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 오프셋 방향 및 오프셋 가중치에 따라, 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정을 수행하도록 구성된다. 전술한 방법을 더 잘 구현하기 위해, 본 출원의 본 실시예는 이미지 합성 장치를 추가로 제공하고, 이미지 합성 장치는 전자 장치에 통합될 수 있고, 전자 장치는 단말, 서버 등일 수 있다. 단말은 모바일 전화, 태블릿 컴퓨 터, 지능형 블루투스 장치, 노트북 컴퓨터, 개인용 컴퓨터(PC) 등과 같은 장치일 수 있고, 서버는 단일 서버이 거나 복수의 서버를 포함하는 서버 클러스터일 수 있다. 예를 들어, 본 실시예에서, 본 출원의 본 실시예의 방법은 예로서 전자 장치에 통합된 이미지 합성 장치를 사용 하여 상세하게 설명된다. 예를 들어, 도 3b에 도시된 바와 같이, 이미지 합성 장치는 획득 유닛, 처리 유닛 및 융합 유닛(40 3)을 포함할 수 있으며, 1. 획득 유닛은 처리될 얼굴 이미지를 획득하도록 구성되고, 2. 처리 유닛은 처리될 얼굴 이미지에 따라 타깃 얼굴 이미지를 획득하도록 구성되며, 타깃 얼굴 이미지는 본 출원의 전술한 실시예에 따른 이미지 처리 방법의 처리에 의해 획득고, 3. 융합 유닛은 타깃 이미지를 획득하기 위해 타깃 얼굴 이미지를 템플릿 이미지의 얼굴 영역에 융합하도록 구 성된다. 실시예에서, 이미지 합성 장치는, 처리될 얼굴 이미지의 각각의 픽셀 포인트의 깊이 정보를 획득하고, 각각의 픽셀 포인트의 깊이 정보에 따라 처리될 얼굴 이미지에 대응하는 입체 얼굴 이미지를 생성하며, 편향된 입체 얼굴 이미지를 획득하기 위해 입체 얼굴 이미지를 타깃 방향으로 편향시키고, 타깃 얼굴 이미지를 획득하기 위해 편향된 입체 얼굴 이미지를 처리될 얼굴 이미지의 방향으로 투영하도록 구성 된 제1 합성 유닛을 더 포함한다. 실시예에서, 이미지 합성 장치는, 미리 설정된 방향 범위 내에서 얼굴 영역의 복수의 처리될 이미지를 획득하고, 복수의 처리될 이미지에 따라 입체 얼굴 이미지를 생성하며, 편향된 입체 얼굴 이미지를 획득하기 위해 입체 얼굴 이미지를 타깃 방향으로 편향시키고, 타깃 얼굴 이미지를 획득하기 위해 편향된 입체 얼굴 이미지를 처리될 얼굴 이미지의 방향으로 투영하도록 구성 된 제2 합성 유닛을 더 포함하다. 획득 유닛은, 처리될 이미지를 획득하고, 처리될 이미지의 얼굴 영역의 방향이 미리 설정된 방향인 경우, 처리될 이미지로부터의 얼굴 영역을 처리될 얼 굴 이미지로 분할하도록 ― 미리 설정된 방향은 얼굴 영역이 기준 얼굴 이미지에 위치되는 방향임 ― 구성된다. 융합 유닛은 인식 서브유닛, 융합 서브유닛 및 합성 서브유닛을 포함할 수 있으며, 인식 서브유닛은 타깃 얼굴 특징점을 획득하기 위해 타깃 얼굴 이미지에 대해 특징점 인식을 수행하도록 구성되 고, 융합 서브유닛 퓨즈는 합성 얼굴 영역을 획득하기 위해, 타깃 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 타깃 얼굴 이미지와 템플릿 이미지의 얼굴 영역을 타깃 얼굴 특징점과 융합하도록 구성되며, 템플릿 얼굴 특징점은 템플릿 이미지의 얼굴 특징점이고, 합성 서브유닛은 타깃 이미지를 획득하기 위해 합성 얼굴 영역을 템플릿 이미지의 다른 영역과 합성하도록 구성 된다. 융합 서브유닛은, 타깃 얼굴 이미지로부터 중심 영역 및 원주 영역을 결정하고, 처리될 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 얼굴 영역 및 템플릿 이미지의 대응하는 중심 영역을 제1 가중치로 융합하며, 처리될 얼굴 특징점 및 대응하는 템플릿 얼굴 특징점에 기초하여, 원주 영역 및 템플릿 이미지의 대응하는 원주 영역을 제2 가중치로 융합하고, 제1 가중치는 제2 가중치보다 더 크며, 합성 얼굴 영역으로서 융합된 이미지를 획득하도록 구성된다. 전술한 유닛은 독립적인 개체로서 구현될 수 있거나, 또는 임의로 결합되어 동일한 개체 또는 복수의 개체로서 구현될 수 있다. 전술한 유닛의 특정 구현을 위해, 전술한 방법 실시예가 참조될 수 있으므로, 세부사항은 여 기에서 다시 설명되지 않는다. 본 출원의 실시예는 전자 장치를 추가로 제공하며, 전자 장치는 단말, 서버 등일 수 있다. 단말은 모바일 전화, 태블릿 컴퓨터, 지능형 블루투스 장치, 노트북 컴퓨터, 개인용 컴퓨터(PC) 등일 수 있으며, 서버는 단일 서버이거나 복수의 서버를 포함하는 서버 클러스터일 수 있다. 일부 실시예에서, 이미지 처리 장치 또는 이미지 합성 장치는 복수의 전자 장치에 추가로 통합될 수 있다. 예 를 들어, 이미지 처리 장치는 복수의 서버에 통합될 수 있고, 본 출원의 이미지 처리 방법은 복수의 서버에 의 해 구현될 수 있다. 일부 실시예에서, 얼굴 이미지 처리 서버 및 얼굴 이미지 합성 서버는 또한 하나의 서버로 구현될 수 있다. 본 실시예에서, 본 실시예의 전자 장치가 상세하게 설명된다. 예를 들어, 도 4는 본 출원의 실시예에 따른 전 자 장치의 개략적인 구조도이다. 전자 장치는 처리 코어 역할을 하는 하나 이상의 프로세서, 하나 이상의 메모리, 전원 공급 장치 , 입력 모듈 및 통신 모듈과 같은 컴포넌트를 포함할 수 있다. 메모리는 컴퓨터 판독 가 능 저장 매체일 수 있다. 당업자는 도 4에 도시된 전자 장치 구조가 전자 장치에 대한 제한을 구성하지 않음을 이해할 수 있다. 전자 장치는 도면에 도시된 것보다 더 많거나 더 적은 컴포넌트를 포함할 수 있거나, 또는 일 부 컴포넌트가 결합될 수 있거나, 또는 상이한 컴포넌트 배치가 사용될 수 있다. 프로세서는 전자 장치의 제어 위치이고, 다양한 인터페이스 및 라인을 사용하여 전체 전자 장치의 다양한 부분을 연결한다. 메모리에 저장된 소프트웨어 프로그램 및/또는 모듈을 실행하거나 수행하고, 메모리 에 저장된 데이터를 호출하여, 프로세서는 전자 장치의 다양한 기능을 수행하고 데이터를 처리함으로써, 전자 장치에 대한 전반적인 모니터링을 수행할 수 있다. 일부 실시예에서, 프로세서는 하나 이상의 처리 코어를 포함할 수 있다. 일부 실시예에서, 프로세서는 애플리케이션 프로세서 및 모뎀을 통합할 수 있다. 애플리케이션 프로세서는 주로 운영체제, 사용자 인터페이스, 애플리케이션 프로그램 등을 처리한다. 모뎀은 주로 무선 통신을 처리한다. 전술한 모뎀은 프로세서에 통합되지 않을 수 있음을 이해할 수 있다. 메모리는 소프트웨어 프로그램 및 모듈을 저장하도록 구성될 수 있고, 프로세서는 다양한 기능적 애 플리케이션 및 데이터 처리를 구현하기 위해 메모리에 저장된 소프트웨어 프로그램 및 모듈을 실행한다. 메모리는 주로 프로그램 저장 영역과 데이터 저장 영역을 포함할 수 있다. 프로그램 저장 영역은 운영체 제, 적어도 하나의 기능(예를 들어, 사운드 재생 기능 및 이미지 재생 기능)에 필요한 애플리케이션 프로그램 등을 저장할 수 있다. 데이터 저장 영역은 전자 장치의 사용에 따라 생성된 데이터를 저장할 수 있다. 또한, 메모리는 고속 랜덤 액세스 메모리를 포함할 수 있고, 또한 적어도 하나의 자기 디스크 저장 장치, 플래시 메모리, 또는 다른 휘발성 고체 상태 저장 장치와 같은 비휘발성 메모리를 포함할 수 있다. 이에 상응하여, 메 모리는 메모리에 대한 프로세서의 액세스를 제공하기 위해 메모리 제어기를 더 포함할 수 있다. 전자 장치는 컴포넌트에 전원을 공급하기 위한 전원 공급 장치를 더 포함한다. 일부 실시예에서, 전원 공 급 장치는 전원 관리 시스템을 사용하여 프로세서에 논리적으로 연결될 수 있으므로, 전원 관리 시스 템을 사용하여 충전, 방전 및 전력 소비 관리와 같은 기능을 구현할 수 있다. 전원 공급 장치는 직류 또 는 교류 전원 공급 장치, 재충전 시스템, 정전 검출 회로, 전원 공급 장치 변환기 또는 인버터, 전원 공급 장치 상태 지시기, 및 임의의 다른 컴포넌트 중 하나 이상을 더 포함할 수 있다. 전자 장치는 입력 모듈을 더 포함할 수 있다. 입력 모듈은 입력된 숫자 또는 문자 정보를 수신하고, 사용자 설정 및 기능 제어에 관련된 키보드, 마우스, 조이스틱, 광학 또는 트랙볼 신호 입력을 생성하도록 구성 될 수 있다. 전자 장치는 통신 모듈을 더 포함할 수 있다. 일부 실시예에서, 통신 모듈은 무선 모듈을 포함할 수 있다. 전자 장치는 사용자에게 무선 광대역 인터넷 액세스를 제공하기 위해 통신 모듈의 무선 모듈을 통 해 근거리 무선 전송을 수행할 수 있다. 예를 들어, 통신 모듈은 사용자가 이메일을 수신하고 전송하며, 웹 페이지를 브라우징하고, 스트리밍 매체에 액세스하는 등을 돕도록 구성될 수 있다. 도면에는 도시되지 않았으나, 전자 장치는 디스플레이 유닛 등을 더 포함할 수 있다. 세부 사항은 여기에서 다 시 설명되지 않는다. 본 실시예에서, 전자 장치의 프로세서는 다음의 명령에 따라 하나 이상의 애플리케 이션 프로그램의 프로세스에 대응하는 실행 가능한 파일을 메모리에 로드할 수 있고, 프로세서는, 복수의 처리될 얼굴 특징점을 획득하기 위해 특징점 인식이 처리될 얼굴 이미지에 대해 수행되는 기능; 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보가 결정되고, 복수의 기 준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점인 기능;특징점 위치 오프셋 정보에 기초하여, 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정이 수행되고, 기준 얼굴 깊이 이미지는 기준 얼굴 이미 지에 대응하는 얼굴 깊이 이미지인 기능; 및 타깃 얼굴 이미지를 획득하기 위해 타깃 얼굴 깊이 이미지에 따라 처리될 얼굴 이미지에 대해 방향 편향이 수행 되는 기능 과 같이 다양한 기능을 구현하기 위해 메모리에 저장된 애플리케이션 프로그램을 실행한다. 또는, 처리될 얼굴 이미지가 획득되고, 타깃 얼굴 이미지가 처리될 얼굴 이미지에 따라 획득되며, 타깃 얼굴 이미지는 이미지 처리 방법의 처리에 의해 획득되고, 타깃 이미지를 획득하기 위해 타깃 얼굴 이미지가 템플릿 이미지의 얼굴 영역에 융합된다. 전술한 작동의 특정 구현을 위해, 전술한 실시예가 참조될 수 있다. 세부 사항은 여기에서 다시 설명되지 않는 다. 당업자는 전술한 실시예의 방법의 전부 또는 일부 단계가 명령을 통해 구현될 수 있거나, 또는 관련 하드웨어를 제어하는 명령을 통해 구현될 수 있고, 명령이 컴퓨터 판독 가능 저장 매체에 저장되어, 프로세서에 의해 실행 될 수 있음을 이해할 수 있다. 본 출원의 측면에 따르면, 컴퓨터 프로그램 제품 또는 컴퓨터 프로그램이 제공되고, 컴퓨터 프로그램 제품 또는 컴퓨터 프로그램은 컴퓨터 명령을 포함하며, 컴퓨터 명령은 컴퓨터 판독 가능 저장 매체에 저장된다. 전자 장 치의 프로세서는 컴퓨터 판독 가능 저장 매체로부터 컴퓨터 명령을 읽고, 컴퓨터 명령을 실행하여 전자 장치가 전술한 실시예에서 설명된 이미지 처리 방법 또는 이미지 합성 방법을 수행하도록 한다. 따라서, 본 출원의 실시예는 복수의 명령을 저장하는 컴퓨터 판독 가능 저장 매체를 제공한다. 명령은 본 출원 의 실시예에 따른 임의의 이미지 처리 방법의 단계를 수행하기 위해 프로세서에 의해 로드될 수 있다. 예를 들 어 명령은, 복수의 처리될 얼굴 특징점을 획득하기 위해 특징점 인식이 처리될 얼굴 이미지에 대해 수행되는 단계; 복수의 처리될 얼굴 특징점과 복수의 기준 얼굴 특징점 사이의 특징점 위치 오프셋 정보가 결정되는 단계 ― 복 수의 기준 얼굴 특징점은 기준 얼굴 이미지에 대응하는 얼굴 특징점임 ―; 처리될 얼굴 이미지에 대응하는 타깃 얼굴 깊이 이미지를 획득하기 위해, 특징점 위치 오프셋 정보에 기초하여, 기준 얼굴 깊이 이미지의 얼굴 특징점에 대해 위치 조정이 수행되는 단계 ― 기준 얼굴 깊이 이미지는 기준 얼 굴 이미지에 대응하는 얼굴 깊이 이미지임 ―; 및 타깃 얼굴 이미지를 획득하기 위해 타깃 얼굴 깊이 이미지에 따라 처리될 얼굴 이미지에 대해 방향 편향이 수행 되는 단계 를 수행할 수 있다. 또는, 처리될 얼굴 이미지가 획득되고, 타깃 얼굴 이미지가 처리될 얼굴 이미지에 따라 획득되고, 타깃 얼굴 이미지는 이미지 처리 방법의 처리에 의해 획득되며, 타깃 이미지를 획득하기 위해, 타겟 얼굴 이미지가 템플릿 이미지의 얼굴 영역에 융합된다. 컴퓨터 판독 가능 저장 매체는 읽기 전용 메모리(read-only memory, ROM), 랜덤 액세스 메모리(random access memory, RAM), 자기 디스크, 광 디스크 등을 포함할 수 있다. 컴퓨터 판독 가능 저장 매체에 저장된 명령이 본 출원의 실시예에서 제공되는 임의의 이미지 처리 방법 또는 이 미지 합성 방법의 단계를 수행할 수 있기 때문에, 명령은 본 출원의 실시예에서 제공되는 임의의 이미지 처리 방법 또는 이미지 합성 방법에 의해 구현될 수 있는 유익한 효과를 구현할 수 있다. 자세한 내용에 대해서는,전술한 실시예가 참조될 수 있다. 세부 사항은 여기에서 다시 설명되지 않는다. 본 출원의 실시예에서 제공되는 이미지 처리 및 얼굴 합성을 위한 방법 및 장치, 그리고 컴퓨터 판독 가능 저장 매체는 위에서 상세히 설명되었다. 본 명세서의 특정 예를 사용하여 본 출원의 원리 및 구현이 설명된다. 전 술한 실시예의 설명은 단지 본 출원의 방법 및 핵심 아이디어를 이해하는 것을 돕기 위한 것이다. 또한, 당업 자는 본 출원의 아이디어에 따라 특정 구현 및 적용 범위에 대해 수정을 가할 수 있다. 결론적으로, 본 명세서 의 내용은 본 출원에 대한 제한으로 해석되어서는 안 된다."}
{"patent_id": "10-2022-7017605", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 출원의 실시예에서의 기술적 해결수단을 보다 명확하게 설명하기 위해, 이하에서는 실시예를 설명하는 데 필 요한 첨부 도면을 간략하게 소개한다. 명백하게, 다음 설명에서의 첨부 도면은 본 출원의 일부 실시예만을 도 시하며, 당업자는 창조적 노력 없이도 첨부 도면으로부터 다른 첨부 도면을 여전히 도출할 수 있다. 도 1a는 본 출원의 실시예에 따른 이미지 처리 방법의 시나리오의 개략도이다. 도 1b는 본 출원의 실시예에 따른 이미지 합성 방법의 시나리오의 개략도이다. 도 2a는 본 출원의 실시예에 따른 이미지 처리 방법의 개략적인 흐름도이다.도 2b는 본 출원의 실시예에 따른 이미지 합성 방법의 개략적인 흐름도이다. 도 3a는 본 출원의 실시예에 따른 이미지 처리 장치의 개략적인 구조도이다. 도 3b는 본 출원의 실시예에 따른 이미지 합성 장치의 개략적인 구조도이다. 도 4는 본 출원의 실시예에 따른 전자 장치의 개략적인 구조도이다. 도 5a는 본 출원의 실시예에 따른 이미지 처리 방법의 타깃 깊이 이미지 생성의 개략적인 흐름도이다. 도 5b는 본 출원의 실시예에 따른 이미지 처리 방법의 기준 깊이 관계의 개략도이다. 도 5c는 본 출원의 실시예에 따른 이미지 처리 방법의 이미지 편향의 개략도이다. 도 5d는 본 출원의 실시예에 따른 이미지 처리 방법의 얼굴 방향 보정의 개략도이다. 도 5e는 본 출원의 실시예에 따른 이미지 합성 방법의 전체 개략 흐름도이다. 도 6a는 본 출원의 실시예에 따른 이미지 합성 방법의 시나리오의 개략적인 흐름도이다. 도 6b는 본 출원의 실시예에 따른 이미지 합성 방법과 관련 기술 사이를 비교한 개략도이다. 도 6c는 본 출원의 실시예에 따른 이미지 합성 방법의 융합 프로세스의 개략도이다. 도 6d는 본 출원의 실시예에 따른 이미지 합성 방법의 합성 결과의 개략도이다. 도 6e는 본 출원의 실시예에 따른 이미지 합성 방법의 비디오 합성의 개략도이다."}
