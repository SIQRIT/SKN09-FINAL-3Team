{"patent_id": "10-2024-0091712", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0115780", "출원번호": "10-2024-0091712", "발명의 명칭": "미소 및 치아 상태 인식을 위한 이미지 분석 방법 및 전자 장치", "출원인": "연세대학교 산학협력단", "발명자": "김종은"}}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 사용자의 미소 및 치아 상태를 분석하는 방법에 있어서,하나 이상의 카메라를 이용하여 사용자에 대한 인터뷰를 촬영한, 인터뷰 동영상을 획득하는 단계;상기 인터뷰 동영상에 포함되는 복수의 프레임들을 미소 분석 모델에 적용하여, 상기 프레임들에 대한 미소 분석 정보를 획득하는 단계;상기 미소 분석 정보에 기초하여, 상기 프레임들 중에서 미소가 검출된 하나 이상의 프레임들을 식별하는 단계;상기 미소가 검출된 하나 이상의 프레임들의 각각에 대하여, 미소 레벨을 결정하는 단계;상기 미소 분석 정보 및 상기 미소 레벨에 기초하여, 상기 사용자의 미소 특성 정보를 생성하되, 상기 사용자의미소 특성 정보는, 상기 사용자의 상기 미소 레벨에 대응하는 상기 사용자의 치아 및 치은 노출 특성을 나타내는 것인, 단계;상기 사용자의 미소 특성 정보에 기초하여, 상기 사용자의 치아 상태 정보를 생성하는 단계; 및상기 사용자의 치아 상태 정보를 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인터뷰 동영상을 획득하는 단계는,상기 사용자의 자연스러운 미소를 유도하기 위한, 기설정된 자연어 문장을 출력하는 단계; 및상기 자연어 문장이 출력됨에 따라, 상기 자연어 문장에 응답하는 상기 사용자를 촬영하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 기설정된 자연어 문장은, 서로 다른 미소 레벨의 미소를 유도하기 위한 복수의 자연어 문장들로 구성되는것인, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 인터뷰 동영상을 획득하는 단계는,복수의 카메라를 이용하여 복수의 인터뷰 동영상들을 획득하는 단계를 포함하되, 상기 복수의 인터뷰 동영상들은, 상기 사용자를 정면, 반측면, 측면 중 적어도 둘 이상을 촬영한 동영상들인 것인, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 미소 분석 정보를 획득하는 단계는,상기 사용자의 얼굴로부터 눈, 눈썹, 코, 귀, 치아, 치식 번호, 윗입술, 아랫입술 및 협측 회랑 중 적어도 하나에 대응하는, 미소 파라미터를 검출하는 단계; 및상기 미소 파라미터에 기초하여, 상기 사용자가 미소짓는지 여부를 수치화한, 상기 미소 분석 정보를 획득하는공개특허 10-2024-0115780-3-단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 미소가 검출된 하나 이상의 프레임들을 식별하는 단계는,상기 프레임들의 각각에 대하여, 상기 미소 분석 정보를 기 설정된 임계값과 비교함으로써 상기 사용자의 미소유무를 검출하는 단계; 및상기 프레임들 중에서, 상기 사용자의 미소가 검출된 하나 이상의 프레임들을 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 미소 레벨을 결정하는 단계는,상기 미소가 검출된 상기 하나 이상의 프레임들을 비교하는 단계; 및상기 비교의 결과 및 상기 미소 파라미터 중 적어도 하나에 기초하여, 상기 미소가 검출된 하나 이상의 프레임들의 각각에 대응하는 상기 미소 레벨을 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 미소 특성 정보를 생성하는 단계는,상기 사용자의 상기 윗입술, 상기 아랫입술, 상기 치아, 상기 치은 및 상기 협측 회랑의 면적 대비 상기 사용자의 상기 치아 및 상기 치은의 면적을 계산하는 단계; 및상기 계산의 결과에 기초하여, 상기 결정된 미소 레벨에 대응하는 상기 사용자의 미소 특성을 수치화한, 상기미소 특성 정보를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 치아 상태 정보를 생성하는 단계는,상기 사용자의 미소 시 노출되는 치아 및 치은에 기초하여, 상기 사용자의 치아별 크기, 치아별 모양 및 치열중 적어도 하나를 포함하는, 치아 상태 정보를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 치아 상태 정보를 생성하는 단계는,상기 사용자의 치아를 촬영한 치아 이미지를 획득하는 단계; 및상기 치아 이미지에 더 기초하여 상기 치아 상태 정보를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 방법은,상기 미소가 검출된 하나 이상의 프레임들 중에서, 얼굴 정면이 포함되는 프레임을 식별하는 단계;상기 얼굴 정면이 포함되는 프레임을 이용하여, 상기 사용자의 얼굴 중심선 및 치아 중심선을 식별하는 단계;상기 얼굴 중심선 및 상기 치아 중심선에 기초하여, 상기 사용자가 미소 지은 상태에서의 치열을 교정한, 치아공개특허 10-2024-0115780-4-교정 정보를 생성하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 방법은,상기 치아 교정 정보를 출력하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "사용자의 미소 및 치아 상태를 분석하는 전자 장치에 있어서,통신 인터페이스;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,하나 이상의 카메라를 이용하여 사용자에 대한 인터뷰를 촬영한, 인터뷰 동영상을 획득하고,상기 인터뷰 동영상에 포함되는 복수의 프레임들을 미소 분석 모델에 적용하여, 상기 프레임들에 대한 미소 분석 정보를 획득하고,상기 미소 분석 정보에 기초하여, 상기 프레임들 중에서 미소가 검출된 하나 이상의 프레임들을 식별하고,상기 미소가 검출된 하나 이상의 프레임들의 각각에 대하여, 미소 레벨을 결정하고,상기 미소 분석 정보 및 상기 미소 레벨에 기초하여, 상기 사용자의 미소 특성 정보를 생성하되, 상기 사용자의미소 특성 정보는, 상기 사용자의 상기 미소 레벨에 대응하는 상기 사용자의 치아 및 치은 노출 특성을 나타내는 것이고,상기 사용자의 미소 특성 정보에 기초하여, 상기 사용자의 치아 상태 정보를 생성하고,상기 사용자의 치아 상태 정보를 출력하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 전자 장치는,하나 이상의 카메라를 더 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자의 자연스러운 미소를 유도하기 위한, 기설정된 자연어 문장을 출력하고,상기 자연어 문장이 출력됨에 따라, 상기 하나 이상의 카메라를 이용하여 상기 자연어 문장에 응답하는 상기 사용자를 촬영하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 기설정된 자연어 문장은, 서로 다른 미소 레벨의 미소를 유도하기 위한 복수의 자연어 문장들로 구성되는것인, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,공개특허 10-2024-0115780-5-복수의 카메라들 이용하여 복수의 인터뷰 동영상들을 획득하되, 상기 복수의 카메라들은, 상기 전자 장치의 상기 하나 이상의 카메라 및 상기 전자 장치에 연결된 다른 카메라들로 구성되는 것이고, 상기 복수의 인터뷰 동영상들은, 상기 사용자를 정면, 반측면, 측면 중 적어도 둘 이상을 촬영한 동영상들인 것인, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자의 얼굴로부터 눈, 눈썹, 코, 귀, 치아, 치식 번호, 윗입술, 아랫입술 및 협측 회랑 중 적어도 하나에 대응하는, 미소 파라미터를 검출하고,상기 미소 파라미터에 기초하여, 상기 사용자가 미소짓는지 여부를 수치화한, 상기 미소 분석 정보를 획득하는,전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 프레임들의 각각에 대하여, 상기 미소 분석 정보를 기 설정된 임계값과 비교함으로써 상기 사용자의 미소유무를 검출하고,상기 프레임들 중에서, 상기 사용자의 미소가 검출된 하나 이상의 프레임들을 선택하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 미소가 검출된 상기 하나 이상의 프레임들을 비교하고,상기 비교의 결과 및 상기 미소 파라미터 중 적어도 하나에 기초하여, 상기 미소가 검출된 하나 이상의 프레임들의 각각에 대응하는 상기 미소 레벨을 결정하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자의 상기 윗입술, 상기 아랫입술, 상기 치아, 상기 치은 및 상기 협측 회랑의 면적 대비 상기 사용자의 상기 치아 및 상기 치은의 면적을 계산하고,상기 계산의 결과에 기초하여, 상기 결정된 미소 레벨에 대응하는 상기 사용자의 미소 특성을 수치화한, 상기미소 특성 정보를 생성하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자의 미소 시 노출되는 치아 및 치은에 기초하여, 상기 사용자의 치아별 크기, 치아별 모양 및 치열중 적어도 하나를 포함하는, 치아 상태 정보를 생성하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,공개특허 10-2024-0115780-6-상기 사용자의 치아를 촬영한 치아 이미지를 획득하고,상기 치아 이미지에 더 기초하여 상기 치아 상태 정보를 생성하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 미소가 검출된 하나 이상의 프레임들 중에서, 얼굴 정면이 포함되는 프레임을 식별하고,상기 얼굴 정면이 포함되는 프레임을 이용하여, 상기 사용자의 얼굴 중심선 및 치아 중심선을 식별하고,상기 얼굴 중심선 및 상기 치아 중심선에 기초하여, 상기 사용자가 미소 지은 상태에서의 치열을 교정한, 치아교정 정보를 생성하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 치아 교정 정보를 출력하는, 전자 장치."}
{"patent_id": "10-2024-0091712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제1항 내지 제12항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 사용자의 미소 및 치아를 분석하는 방법이 제공된다. 상기 방법은, 하나 이상의 카메라를 이용하여 사용자에 대한 인터뷰를 촬영한, 인터뷰 동영상을 획득하는 단계, 상기 인터뷰 동영상에 포함되는 복수의 프레임 들을 미소 분석 모델에 적용하여, 상기 프레임들에 대한 미소 분석 정보를 획득하는 단계, 상기 미소 분석 정보 (뒷면에 계속)"}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상 분석 장치 및 그 분석 방법에 관한 것이다. 보다 상세하게는, 인공 지능 기반의 미소 인식을 이 용하여 치아 상태를 분석하는 영상 분석 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "치아의 교정 치료 및 보철 치료를 설계함에 있어서, 환자의 얼굴과 조화된 교정 결과를 제공하기 위한 다양한 방법들이 연구되고 있다. 치아 교정 치료에 있어서, 치아의 올바른 교합 등의 기능적 개선 뿐 아니라, 가지런한 배열 등의 심미적인 개선 또한 중요한 요소이다. 또한, 치아 보철 치료에 있어서, 치아가 상실되거나 방치된 경 우, 치아가 부분적으로 손실된 경우 등에 치아를 인공적으로 생성할 때에도, 심미적인 요소는 중요시된다. 이에 따라, 교정 치료 및 보철 치료의 심미적 효과를 개선하기 위해, 치아 교정 치료 및/또는 보철 치료를 설계하기 위한 초기 정보로 환자의 미소 사진을 사용하는 다양한 방법들이 존재한다. 환자의 인터뷰 동영상을 이용하여, 환자의 자연스러운 미소 이미지를 획득하며, 치아 교정 치료 및/또는 보철 치료에 활용될 수 있는 다양한 데이터를 생성하여 제공할 수 있는, 미소 및 치아 상태 분석 방법을 제시하고자 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-2161438호, (공개일: 2020.10.05)"}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은, 사용자의 인터뷰 동영상을 이용하여, 사용자의 자연스러운 미소를 검출하고, 미소를 분석 및 치아 상태를 분석하는 전자 장치 및 그 동작 방법을 제공하기 위한 것이다. 다만, 본 발명이 해결하고자 하 는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재로부터 통 상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 전자 장치가 사용자의 미소 및 치아 상태를 분석하는 방법을 제공할 수 있다. 상 기 방법은, 하나 이상의 카메라를 이용하여 사용자에 대한 인터뷰를 촬영한, 인터뷰 동영상을 획득하는 단계; 상기 인터뷰 동영상에 포함되는 복수의 프레임들을 미소 분석 모델에 적용하여, 상기 프레임들에 대한 미소 분 석 정보를 획득하는 단계; 상기 미소 분석 정보에 기초하여, 상기 프레임들 중에서 미소가 검출된 하나 이상의 프레임들을 식별하는 단계; 상기 미소가 검출된 하나 이상의 프레임들의 각각에 대하여, 미소 레벨을 결정하는 단계; 상기 미소 분석 정보 및 상기 미소 레벨에 기초하여, 상기 사용자의 미소 특성 정보를 생성하되, 상기 사 용자의 미소 특성 정보는, 상기 사용자의 상기 미소 레벨에 대응하는 상기 사용자의 치아 및 치은 노출 특성을 나타내는 것인, 단계; 상기 사용자의 미소 특성 정보에 기초하여, 상기 사용자의 치아 상태 정보를 생성하는 단 계; 및 상기 사용자의 치아 상태 정보를 출력하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 사용자의 미소 및 치아 상태를 분석하는 전자 장치를 제공할 수 있다. 상기 전자 장치는, 통신 인터페이스; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이 상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로 써, 하나 이상의 카메라를 이용하여 사용자에 대한 인터뷰를 촬영한, 인터뷰 동영상을 획득하고, 상기 인터뷰 동영상에 포함되는 복수의 프레임들을 미소 분석 모델에 적용하여, 상기 프레임들에 대한 미소 분석 정보를 획 득하고, 상기 미소 분석 정보에 기초하여, 상기 프레임들 중에서 미소가 검출된 하나 이상의 프레임들을 식별하 고, 상기 미소가 검출된 하나 이상의 프레임들의 각각에 대하여, 미소 레벨을 결정하고, 상기 미소 분석 정보 및 상기 미소 레벨에 기초하여, 상기 사용자의 미소 특성 정보를 생성하되, 상기 사용자의 미소 특성 정보는, 상기 사용자의 상기 미소 레벨에 대응하는 상기 사용자의 치아 및 치은 노출 특성을 나타내는 것이고, 상기 사 용자의 미소 특성 정보에 기초하여, 상기 사용자의 치아 상태 정보를 생성하고, 상기 사용자의 치아 상태 정보 를 출력할 수 있다. 본 개시의 일 측면에 따르면, 서버가 사용자의 미소 및 치아 상태를 분석을 제공하는, 전술한 방법을 실행시키 기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다. 이 외에도, 본 개시의 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프 로그램을 기록하는 컴퓨터 판독 가능한 기록 매체가 더 제공될 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은, 사용자가 편안한 상태에서 자연스럽게 얻어진 인터뷰 동영상에 기초하여, 치아 교정 치료 및/또는 보철 치료에 사용될 수 있는, 정확하고 다양한 데이터를 생성함으로써, 치아 교정 치료 및/또는 보철 치료 설계 의 효율성을 높일 수 있다. 또한, 사용자에게 치아 교정 치료 및/또는 보철 치료 결과를 미리 예측하여 보여주 는, 사용자 편의를 제공할 수 있다."}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0091712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한, 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭할 수 있으나, 동일한 구성요소가 다 른 도면에서 다른 참조 부호를 사용하여 설명될 수 있다. 도 1은 본 개시의 일 실시예에 따른 전자 장치의 동작을 개략적으로 설명하기 위한 도면이다. 개시된 실시예에서, 전자 장치는 인터뷰 동영상을 미소 분석 모델에 입력할 수 있다. 미소 분 석 모델은 인터뷰 동영상을 입력 받아, 인터뷰 동영상에 포함되는 복수의 프레임들 각각에 대하 여, 사용자의 얼굴 내 포함되는 객체들을 세그멘테이션 할 수 있다. 전자 장치는 미소 분석 모델의 출력을 이용하여, 인터뷰 동영상 내 프레임들 각각에 대응하는 미소 분석 정보를 획득할 수 있다. 개시된 실시예에서, 미소 분석 정보는 미소 분석 모델으로부터 출력된데이터들을 후처리하여 사용자의 미 소를 분석한 정보일 수 있다. 미소 분석 정보는 미소 분석 모델의 출력 데이터에 기초하여, 사용자가 미소 짓는지 여부를 수치화한 정보일 수 있다. 한편, 전자 장치는 사용자의 미소를 수치화한 미소 분석 정보 외에, 사용자의 미소의 정도를 나타내 는 미소 레벨, 사용자의 미소 레벨에 대응하는 치아 및 치은 노출 특성을 나타내는 미소 특성 정보, 사용자의 치아별 크기, 치아별 모양 및 치열 등의 정보를 포함하는 치아 상태 정보, 사용자의 치아 상태에 기초하여 사용 자의 치아를 교정한 치아 교정 정보들 및, 전술한 정보들을 생성하기 위해 가공 및 처리되는 중간 데이터들을 생성할 수 있다.한편, 전술한 도 1에 대한 설명 및 후술하는 도면들에 대한 설명들에서, 사용자의 미소를 검출하고, 미소를 분 석하는 실시예들을 설명하지만, 이는 설명의 편의 및 이해를 돕기 위한 예시일 뿐이다. 본 개시는 사용자의 치 아 상태를 분석하여 교정 치료 및/또는 보철 치료에 활용 가능한 데이터를 생성하는 것에 관한 것으로, 사용자 의 미소가 반드시 검출되지 않더라도 균등한 실시예가 실시되어 동일/유사한 효과가 달성될 수 있다. 예를 들어, 전자 장치는 사용자의 발음, 감정, 표정 등에 따른 치아 노출 변화를 데이터화한 정보들을, 후술하 는 설명에서 예시로 기재된 미소에 관련된 정보들과 동일/유사하게 사용함으로써 사용자의 치아 상태를 분석할 수 있다. 즉, 전자 장치는 치아가 노출되는 모든 경우에 대하여 사용자의 얼굴 특성을 검출할 수 있으나, 이하에서는, 설명의 편의를 위하여 사용자의 미소를 검출하는 것만을 예시로 설명한다. 이하의 본 개시에서, 전자 장치가 사용자의 미소 및 치아 상태를 분석하는 구체적인 동작들을, 후술하는 도면들 및 그에대한 설명을 참조하여 보다 상세하게 설명한다. 도 2a 내지 도 2b는 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 2a 내지 도 2b를 설명함에 있어서, 동일한 구성은 동일한 도면 부호를 사용하여 설명한다. 도 2a는 본 개시의 일 실시예에 따른 전자 장치의 개략적으로 구성을 도시한 블록도이다. 일 실시예에 따른 전자 장치는 적어도 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 외부 전자 장치(예를 들어, 서버)들과 데이터 통신을 수행할 수 있다. 통신 인터페이스는, 예를 들어, 유선 랜, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), 블루투스 (Bluetooth), 지그비(zigbee), WFD(Wi-Fi Direct), 적외선 통신(IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하는 데이터 통신 방식 중 적어도 하나를 이 용하여 전자 장치와 외부 전자 장치들 간의 데이터 통신을 수행할 수 있다. 일 실시예에 따른 통신 인터페이스는 전자 장치가 사용자의 미소 및 치아 상태를 분석하기 위한 데 이터를 외부 전자 장치와 송수신할 수 있다. 예를 들어, 통신 인터페이스는 인터뷰 동영상을 외부 전자 장치로부터 미소 분석 모델을 훈련시키기 위한 훈련 데이터셋을 외부 전자 장치로부터 수신하거나, 학습된 미소 분석 모델을 외부 전자 장치로부터 수신할 수 있다. 통신 인터페이스는 미소 분석 결과 또는 치아 상태 분석 결과를 외부 전자 장치로 전송할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘 발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모 리를 포함할 수 있다. 일 실시예에 따른 메모리는 전자 장치가 사용자의 미소 및 치아 상태를 분석하기 위해 동작하도록 하는 하나 이상의 인스트럭션 또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 사용자의 미소 및 치아 상태를 분석하기 위한 다양한 소프트웨어 모듈이 저장될 수 있다. 메모리에 저장된 복수의 소프트웨 어 모듈들에 대하여는, 도 2b에 대한 설명에서 더 서술한다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 전자 장치가 사용자의 미소 및 치아 상태를 분석하기 위한 전반적인 동작들을 제어할 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits),DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서(Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전 용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에 따른 프로세서가 사용자의 미소 및 치아 상태를 분석하기 위해 수행하는 다양한 동작들은, 메모리에 저장된 소프트웨어 모듈들을 도시한 도 2b에 대한 설명을 참조하여 더 서술한다. 도 2b는 본 개시의 일 실시예에 따른 전자 장치의 메모리에 저장된 모듈들을 도시한 블록도이다. 일 실시예에서, 메모리에는 데이터 수집 모듈, 대화 생성 모듈, 미소 분석 모듈, 치아 분석 모듈이 저장될 수 있다. 프로세서는 메모리에 저장된 하나 이상의 모듈을 실행할 수 있다. 일 실시예에서, 프로세서는 데이터 관리 모듈을 실행하여 사용자의 미소 및 치아 상태 분석을 위해 이용되는 데이터들을 관리할 수 있다. 프로세서는 하나 이상의 카메라를 이용하여 사용자에 대한 인터뷰를 촬영한, 인터뷰 동영상을 획득할 수 있다. 프로세서는 외부 전자 장치(예를 들어, 서버)로부터 인터뷰 동영상을 수신하거나, 전자 장치(100 0)가 촬영한 인터뷰 동영상을 저장할 수 있다. 일 실시예에서, 인터뷰 동영상은 하나의 인터뷰 장면을 하나의 카메라를 이용하여 촬영한 것일 수 있다. 이 경 우, 인터뷰 동영상은 사용자의 얼굴이 촬영되도록 사용자를 정면, 반측면 중 적어도 하나를 촬영한 것일 수 있 다. 일 실시예에서, 인터뷰 동영상은 하나의 인터뷰 장면을 복수의 카메라를 이용하여 촬영한 것일 수 있다. 이 경 우, 복수의 카메라 각각으로부터 복수의 인터뷰 동영상들이 획득될 수 있다. 복수의 인터뷰 동영상들은, 사용자 를 정면, 반측면, 측면 중 적어도 둘 이상을 촬영한 것일 수 있다. 프로세서는 미소 분석 모델을 훈련시키기 위한 훈련 데이터셋을 생성할 수 있다. 일 실시예에서, 프로세서는 복수의 훈련용 인터뷰 동영상들을 획득할 수 있다. 훈련용 인터뷰 동영상이란, 사용자의 과거 인터뷰 동영상 및/또는 사용자 외 다른 사람들을 인터뷰한 동영상일 수 있다. 프로 세서는 복수의 훈련용 인터뷰 동영상들 각각에 대하여, 인터뷰 동영상에 포함되는 복수의 프레임들을 중 사람의 얼굴이 포함되는 프레임들을 식별할 수 있다. 프로세서는 사람의 얼굴이 포함되는 프레임들에 대 하여, 사람의 미소를 식별하기 위한 미소 파라미터들(예를 들어, 눈, 눈썹, 입술, 치아 등)을 레이블링함으로써 훈련 데이터를 생성할 수 있다. 일 실시예에서, 프로세서는 복수의 훈련용 이미지들을 획득할 수 있다. 프로세서는 미소 파라미터 들이 레이블링 되어있는 훈련용 이미지들을 외부 전자 장치로부터 획득하거나, 사람의 얼굴이 포함된 이미지들 을 획득하고, 획득된 이미지들에 미소 파라미터들을 레이블링함으로써 훈련 데이터를 생성할 수 있다. 프로세서는 후술하는 실시예들을 통해 획득되는 미소 분석 정보, 미소 특성 정보, 치아 상태 정보들 및 각각의 정보들을 생성하기 위해 획득되는 중간 데이터들을 관리할 수 있다. 일 실시예에서, 프로세서는 대화 생성 모듈을 실행하여 기설정된 자연어 문장을 출력할 수 있다. 이 경우, 기설정된 자연어 문장은 전자 장치를 이용하여 사용자를 인터뷰할 때, 사용자의 자연스러운 미 소를 유도하기 위한 자연어 문장들일 수 있다. 프로세서는 자연어 처리(Natural Language Processing; NLP) 모델을 이용할 수 있으며, 자연어 처리 모델은 자연어 이해(Natural Language Understanding; NLU) 모델 및 자연어 생성(Natural Language Generation; NLG) 모델로 구성될 수 있다. 프로세서는 서로 다른 미소 레벨의 미소를 유도하기 위한 자연어 문장들을 출력할 수 있다. 예를 들어, 프로세서는 낮은 레벨의 미소(잔잔한 미소)를 유도하기 위한 자연어 문장, 높은 레벨의 미소(환한 미소) 를 유도하기 위한 자연어 문장 등을 출력할 수 있다. 프로세서는 자연어 문장이 출력됨에 따라, 자연어 문장에 응답하는 사용자의 발화를 이해하고, 대응되는 다른 문장을 더 출력할 수 있다. 프로세서가 하나 이상의 자연어 문장을 출력함에 따라 사용자 인터뷰가 진행되면, 사용자의 미소를 인식하기 위한 사용자 인터뷰 동영상이 획득될 수 있다.일 실시예에서, 프로세서는 미소 분석 모듈을 실행하여 사용자의 미소를 분석할 수 있다. 미소 분 석 모듈은 사용자의 미소를 인식하기 위한 인공지능 모델인, 미소 분석 모델을 포함할 수 있다. 프로세서는 사용자의 인터뷰 동영상에 포함되는 복수의 프레임들을 미소 분석 모델에 적용하여, 미소 분 석 정보를 획득할 수 있다. 예를 들어, 프로세서는 사용자의 얼굴로부터 눈, 눈썹, 코, 귀, 치아, 치식 번호, 윗입술, 아랫입술 및 협측 회랑(Buccal corridor) 중 적어도 하나에 대응하는, 미소 파라미터를 검출할 수 있다. 프로세서는 미소 파라미터에 기초하여 사용자가 미소짓는지 여부를 수치화한, 미소 분석 정보를 획득할 수 있다. 일 실시예에서, 프로세서는 미소 분석 정보에 기초하여, 사용자의 인터뷰 동영상에 포함되는 복수의 프레 임들 중에서 미소가 존재하는 프레임들을 검출할 수 있다. 예를 들어, 인터뷰 동영상에 포함되는 복수의 프레임 들 중에는, 사용자가 카메라가 아닌 다른 곳을 보고 있어 사용자의 얼굴이 검출되지 않거나, 사용자의 얼굴이 검출되었더라도 사용자가 미소짓고 있지 않은 프레임들이 포함될 수 있다. 프로세서는 미소 분석 정보를 기 설정된 임계값과 비교함으로써, 사용자의 미소 유무를 검출하고, 인터뷰 동영상에 포함되는 복수의 프레임들 중에서 사용자의 미소가 검출된 하나 이상의 프레임들을 선택할 수 있다. 일 실시예에서, 프로세서는 사용자의 미소가 검출된 하나 이상의 프레임들에 대하여, 미소 레벨을 결정할 수 있다. 미소 레벨은, 사용자가 미소를 짓고 있는 정도(예를 들어, 잔잔한 미소, 환한 미소 등)로, 눈 모양, 입술 모양, 치아가 노출되는 정도 등 다양한 미소 파라미터들에 의해 결정될 수 있다. 프로세서가 미소 레벨을 결정한 결과, 미소가 검출된 프레임들 중 프레임 #1은 '미소 레벨 1', 프레임 #4는 '미소 레벨 3', 프레 임 #5는 '미소 레벨 2', 프레임 #N은 '미소 레벨 5'로 결정될 수 있다. 여기서, 미소 레벨이 높을수록 환한 미 소를 의미할 수 있으나, 이에 한정되는 것은 아니다. 프로세서는 미소 분석 정보 및 미소 레벨에 기초하여, 사용자의 미소 특성 정보를 생성할 수 있다. 사용 자의 미소 특성 정보는, 사용자의 미소 레벨에 대응하는, 사용자의 치아 및 치은 노출 특성을 나타낼 수 있다. 사용자의 미소 특성은, 사용자마다 미소를 지을 때 특성이 상이함에 따라 이를 데이터화 한 것이다. 예를 들어, 제1 사용자는 환한 미소를 짓더라도 치아 및 치은 노출이 다른 사용자들의 평균보다 적고, 제2 사용자는 환한 미소를 지을 때 치아 및 치은 노출이 다른 사용자들의 평균보다 클 수 있다. 일 실시예에서, 프로세서는 사용자의 윗입술, 아랫입술, 치아, 치은 및 협측 회랑의 면적 대비, 사용자의 치아 및 치은의 면적을 계산할 수 있다. 프로세서는 결정된 미소 레벨에 대응하는 사용자의 미소 특성을 수치화한, 미소 특성 정보를 생성할 수 있다. 예를 들어, 제1 사용자에 대하여 미소 특성 정보가 생성된 결과, 제1 사용자의 미소 레벨 1은, 수치화된 미소 특성이 'X'이고, 제1 사용자의 미소 레벨 2는, 수치화된 미소 특성 이 'Y'일 수 있다. 다른 예에서, 제2 사용자에 대하여 미소 특성 정보가 생성된 결과, 제2 사용자의 미소 레벨 1은, 수치화된 미소 특성이 'W'이고, 제1 사용자의 미소 레벨 2는, 수치화된 미소 특성이 'Z'일 수 있다. 또한, 미소 특성 정보는 사용자의 미소 레벨 별로, 사용자가 해당 미소 레벨에서의 미소가 유지되는 시간을 포함할 수 있다. 미소가 유지되는 시간은, 사용자가 해당 레벨의 미소를 지을 때 더 오랜 시간 동안 미소짓고 있음을 의미 하므로, 치아 상태 정보 및/또는 치아 교정 정보를 생성할 때 가중치 정보로써 활용될 수 있다. 일 실시예에서, 프로세서는 치아 분석 모듈을 실행하여 사용자의 치아를 분석할 수 있다. 프로세서 는 사용자의 미소 특성 정보에 기초하여, 사용자의 치아 상태 정보를 생성할 수 있다. 예를 들어, 프로세 서는 사용자의 미소 시 노출되는 치아 및 치은의 정도에 기초하여 사용자의 치아별 크기, 치아별 모양 및 치열 중 적어도 하나를 포함하는, 치아 상태 정보를 생성할 수 있다. 일 실시예에서, 프로세서는 사용자의 치아를 촬영한 치아 이미지를 획득할 수 있다. 치아 이미지는, 보다 정확한 치아 상태 정보를 획득하기 위한 이미지로, 사용자가 치아가 최대한 많이 보이게 입을 벌리고 촬영한 이 미지이거나, 사용자가 개구기를 착용한 상태에서 치아를 촬영한 이미지 등, 다양한 방식으로 사용자의 치아를 촬영한 이미지일 수 있다. 프로세서는 사용자의 치아 이미지가 획득되는 경우, 사용자의 치아 이미지에 더 기초하여 치아 상태 정보를 생성할 수 있다. 일부 실시예에서, 치아 이미지는, 일반적인 카메라(예를 들어, RGB 카메라)를 통해 획득된 이미지일 수 있다. 일부 실시예에서, 치아 이미지는, 치아 특성을 촬영하기 위해 보 다 적합한, 외부 촬영 장치를 통해 획득된 이미지일 수 있다. 예를 들어, 치아 이미지는 3D 스캐너를 이용하여 치아를 촬영한 이미지일 수 있다. 다만, 3D 스캐너는 예시일 뿐이며, 외부 촬영 장치가 이에 한정되는 것은 아 니다. 전자 장치에 외부 촬영 장치(예를 들어, 3D 스캐너)가 연결될 수 있다. 프로세서는 통신 인 터페이스를 제어하여, 외부 촬영 장치로부터 치아 이미지를 획득할 수 있다.일 실시예에서, 프로세서는 사용자가 미소 지은 상태에서의 치열을 교정한, 치아 교정 정보를 생성할 수 있다. 프로세서는 미소 분석 정보, 미소 특성 정보, 치아 상태 정보 중 적어도 하나를 이용하여, 사용자 가 미소 지은 상태에서 사용자의 치열을 교정한, 치아 교정 정보를 생성할 수 있다. 예를 들어, 프로세서는 미소가 검출된 프레임들 중에서, 얼굴 정면이 포함되는 프레임을 식별할 수 있다. 프로세서는 얼굴 정면이 포함되는 프레임으로부터 사용자의 얼굴 중심선 및 치아 중심선을 식별할 수 있 다. 프로세서는 얼굴 중심선 및 치아 중심선에 기초하여, 사용자가 미소지은 상태에서의 치열을 교정한, 치아 교정 정보를 생성할 수 있다. 치아 교정 정보는, 사용자가 미소지은 상태에서의 치열이 교정된 이미지, 교 정한 사용자의 치아를 3D 모델링한 데이터일 수 있으나, 이에 한정되는 것은 아니다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 이용하는 미소 분석 모델을 설명하기 위한 도면이다. 도 3을 참조하면, 일 실시예에 따른 전자 장치는 미소 분석 모델을 이용하여, 미소 분석 정보 를 획득할 수 있다. 일 실시예에서, 미소 분석 모델은 이미지 내에서 타겟 객체를 검출, 인식, 세그멘테이션이 가능한 알고리 즘을 이용하는, 다양한 방식의 인공지능 모델로 구현될 수 있다. 이하 도 3을 설명함에 있어서, 이미지 내에서 서로 다른 객체를 구별하여 인식 가능한 인스턴스 세그멘테이션을 수행하는, YOLACT++(You Only Look At CoefficienTs) 모델의 아키텍처를 도시하였다. 다만, 이는 설명의 편의 를 위한 일 예시일 뿐, 본 개시의 미소 분석 모델의 아키텍처는 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치가 YOLACT++ 아키텍처를 사용하여 미소 분석 정보를 획득하는 경우, 전자 장치 는 인터뷰 동영상의 프레임들로부터 실시간으로 객체들을 세그멘테이션함으로써 미소 분석 정보를 획득할 수 있다. 예를 들어, 전자 장치는 인터뷰 동영상의 프레임들 각각마다, 사용자의 얼굴 내 윗입술, 아랫입술, 눈, 눈썹, 코, 귀, 치아, 협측 회랑 중 하나 이상을 인스턴스 세그멘테이션한, 미소 분석 정보를 획득할 수 있 다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 미소 분석 모델을 훈련시키기 위하여 이용하는 훈련 데이터를 설명하기 위한 도면이다. 도 4를 참조하면, 일 실시예에 따른 전자 장치는 미소 분석 모델을 훈련시키기 위한 훈련 데이터셋 을 획득할 수 있다. 전자 장치는 외부 전자 장치(예를 들어, 서버)로부터 훈련 데이터셋을 수신하거 나, 전자 장치가 이미지에 미소 검출을 위한 미소 파라미터들에 레이블링을 수행함으로써 훈련 데이터셋 을 생성할 수 있다. 일 실시예에서, 전자 장치가 레이블링하는 미소 파라미터는, 예를 들어, 치아의 치식 번호 및 얼굴 의 랜드마크일 수 있다. 치식 번호는, 사람의 위턱(상악)의 치아들인 앞니, 송곳니 및 어금니들 각각, 사람의 아래턱(하악)의 치아 들인 전치, 견치, 소구치 및 대구치들 각각을 인덱싱한 것일 수 있다. 얼굴의 랜드마크는 윗입술, 아랫입 술, 눈, 눈썹, 코, 귀, 협측 회랑을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치가 이미지에 대하여 미소 파라미터들을 레이블링하는 방법은, 다양한 레이블링 기술들이 이용될 수 있다. 예를 들어, 전자 장치는 다각형 모양으로 객체들의 영역 외곽선을 연결하여 구 별하는 폴리곤 레이블링, 점을 찍어 구별하는 키포인트 레이블링 등을 활용할 수 있으나, 이에 한정되는 것은 아니다. 레이블링이 완료된 훈련 데이터셋에 포함되는 이미지들은, 각각의 미소 파라미터들에 대한 주석들 (annotations)이 포함될 수 있다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 미소 분석 모델을 이용하여 미소 분석 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 5를 참조하면, 일 실시예에 따른 전자 장치는 인터뷰 동영상을 미소 분석 모델에 입력하고, 미소 분석 모델으로부터 출력되는 미소 분석 정보를 획득할 수 있다. 이 경우, 미소 분석 모델은 도 4에서 설명하였던 훈련 데이터셋을 이용하여 미리 학습이 완료된, 인 공지능 모델일 수 있다. 미소 분석 정보는, 인터뷰 동영상에 포함되는 복수의 프레임들 각각에 대하여 획득된다. 복수의 프레 임들 중 하나의 프레임을 예로 들면, 미소 분석 정보는 사용자 얼굴로부터 검출된 치식 번호 및 얼굴의 랜 드마크 등을 수치화한 형태로 출력될 수 있다. 일 실시예에서, 전자 장치가 전자 장치에 포함된 하나 이상의 카메라를 이용하여 실시간으로 인터 뷰 동영상을 획득하는 경우, 전자 장치는 인터뷰 동영상을 실시간으로 미소 분석 모델에 적용할 수 있다. 이에 따라, 전자 장치는 인터뷰 동영상으로부터 미소 분석 정보를 실시간으로 추출할 수 있다. 일 실시예에서, 전자 장치가 인터뷰 동영상으로부터 미소 분석 정보를 추출하는 경우, 인터뷰 동영상 내 프레임들 중에서 일부의 프레임은, 사용자의 얼굴이 포함되지 않거나 사용자가 미소짓고 있지 않을 수 있다. 이 경우, 상기 일부의 프레임들에 대하여는, 미소 분석 정보가 획득되지 않거나, 미소 분석 정보 의 검출된 치식 번호 및 얼굴의 랜드마크 등의 수치가 낮게 획득될 수 있다. 전자 장치는 미소 분석 정보에 기초하여, 인터뷰 동영상 내의 프레임들 중에서, 미소가 존재하는 프레임들을 검출할 수 있다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 미소 레벨을 결정하는 동작을 설명하기 위한 도면이 다. 일 실시예에서, 전자 장치는 미소가 검출된 하나 이상의 프레임들을 식별할 수 있다. 전자 장치 는 미소가 검출된 하나 이상의 프레임들 각각에 대하여, 미소 레벨을 결정할 수 있다. 이하에서는, 설명의 편의를 위하여, 미소가 검출된 하나 이상의 프레임들 중에서, 제1 프레임을 예시 로 설명하기로 한다. 일 실시예에서, 전자 장치는 제1 프레임의 미소 분석 정보에 기초하여, 제1 프레임의 미소 레 벨을 결정할 수 있다. 예를 들어, 전자 장치는 눈 모양, 입술 모양, 얼굴 면적 대비 치아가 노출되 는 면적, 노출된 치아의 개수, 치은의 노출 면적, 얼굴 중심선으로부터 입꼬리까지의 거리, 치아 중심선의 가로 길이 등 다양한 정보의 조합을 이용하여 미소 레벨을 결정할 수 있다. 예를 들어, 제1 프레임의 미소 레벨은, '미소 레벨 3'으로 결정될 수 있다. 이 경우, 미소가 검출된 하나 이상의 프레임들 중에서, 제1 프레임보다 덜 미소짓는 얼굴을 포함하는 프레임들은 '미소 레벨 3'보다 낮은 레벨로 결정되고, 제1 프레임보다 더크게 미소 짓는 얼굴을 포함하는 프레임들은 '미소 레벨 3'보다 높은 레벨로 결정될 수 있다. 즉, 전자 장치는 사용자의 미소에 대하여 미소 레벨을 결정할 수 있으며, 사용자마다 미소 특성이 상이할 수 있으므로, 사용자의 미소 정도에 기초하여 상대적으로 미소 레벨을 대응시킬 수 있다. 일 실시예에서, 전자 장치는 미소 레벨을 결정하면, 미소 분석 정보 및 미소 레벨에 기초하여, 사용자의 미소 특성 정보를 생성할 수 있다. 미소 특성 정보는, 사용자의 미소 레벨에 대응하는 사용자의 미소 특성일 수 있으며, 사용자의 치아 및 치은 노출 특성(미소 레벨에 따른 치아 노출 시간, 미소 레벨에 따른 치아 노출 비율 등)을 포함할 수 있다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 치아 상태 정보를 생성하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 사용자의 미소 특성 정보에 기초하여, 사용자의 치아 상태 정보를 생성 할 수 있다. 전술한 실시예들에 따라, 전자 장치는 사용자의 미소가 검출된 하나 이상의 프레임들을 식별할 수 있다. 또한, 미소가 검출된 하나 이상의 프레임들 각각에 대하여, 미소 레벨이 각각 결정되어 있을 수 있다. 이하에서, 미소가 검출된 프레임들은, 프레임 #1, 프레임 #4, 프레임 #5 및 프레임 #N 4 개의 프레임을 예시로 설명한다. 일 실시예에서, 전자 장치가 각각의 프레임들에 대하여 미소 레벨을 결정한 결과, 프레임 #1은 '미 소 레벨 1', 프레임 #4는 '미소 레벨 3', 프레임 #5는 '미소 레벨 2', 프레임 #N은 '미소 레벨 5'일 수 있다. 전자 장치는 프레임 #1, #4, #5 및 #N(710 내지 740)으로부터 획득된 미소 특성 정보에 기초하여, 사용자 의 치아별 크기(예를 들어, 좌측 앞니, 우측 앞니의 크기), 치아별 모양(예를 들어, 좌측 앞니, 우측 앞니의 모 양) 및 치열 중 적어도 하나를 포함하는, 치아 상태 정보를 생성할 수 있다.일 실시예에서, 전자 장치는 복수의 프레임들로부터 획득된 미소 특성 정보를 조합하여, 사용자의 치아 상태 정보를 생성하므로, 하나의 이미지로부터 사용자의 치아 상태 정보를 생성하는 것보다 더 정확 한 치아 상태 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 치아 상태 정보를 생성할 때, 각각의 프레임들이 조합되는 정도를 다르 게하기 위한, 서로 다른 가중치를 적용할 수 있다. 예를 들어, 전자 장치는 미소 레벨이 가장 높은 프레임에 가장 높은 가중치를 적용할 수 있다. 구체적으 로, 전자 장치는 가장 환한 미소를 나타내는 '미소 레벨 5'로 결정된 프레임 #N에 가장 높은 가중치 를 둠으로써, 치아별 크기, 모양, 치열 등을 포함하는 치아 상태 정보를 생성할 수 있다. 다른 예에서, 전 자 장치는 미소 지속 시간이 가장 긴 프레임에 가장 높은 가중치를 적용할 수 있다. 구체적으로, 전자 장 치는 가장 미소 지속시간이 길었던 사용자의 미소인 '미소 레벨 3'으로 결정된 프레임 #4에 가장 높 은 가중치를 둠으로써, 치아별 크기, 모양, 치열 등을 포함하는 치아 상태 정보를 생성할 수 있다. 일 실 시예에 따른 전자 장치는 복수의 프레임들을 조합하여 치아 상태 정보를 생성하되, 기설정된 기준들 에 기초하여 서로 다른 가중치를 적용함으로써, 보다 정확한 치아 상태 정보를 획득할 수 있다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 치아 상태 정보를 생성하는, 다른 동작을 설명하기 위한 도면 이다. 일 실시예에서, 전자 장치는 사용자의 치아를 촬영한 치아 이미지를 획득할 수 있다. 치아 이미지는, 보다 정확한 치아 상태 정보를 획득하기 위한 이미지로, 사용자가 치아가 최대한 많이 보이게 입을 벌리고 촬영한 이미지이거나, 사용자가 개구기를 착용한 상태에서 치아를 촬영한 이미지 등, 다양한 방식 으로 사용자의 치아를 촬영한 이미지일 수 있다. 치아 이미지는 외부 전자 장치로부터 획득될 수 있다. 또는, 전자 장치는 치아 이미지를 직접 획득할 수 있다. 전자 장치는 사용자의 치아를 촬영하기 위하여, 사용자에게 치아를 노출할 것을 가이드 하는 알림을 시각적 및/또는 청각적으로 출력할 수 있다. 전자 장치는 알림을 출력하고 사용자를 촬영함 으로써, 치아 이미지를 획득할 수 있다. 전자 장치는 치아 상태 정보를 생성함에 있어서, 사용자의 미소 특성 정보 외에 치아 이미지를 더 이용함으로써, 도 7에서 설명하였던 실시예보다 더 정확한, 치아 상태 정보를 생성할 수 있다. 일 실시예에서, 전자 장치는 미소가 검출된 프레임들 중에서, 얼굴 정면이 포함되는 프레임을 식별 할 수 있다. 전자 장치는 얼굴 정면이 포함되는 프레임으로부터 사용자의 얼굴 중심선 및 치아 중심 선을 식별할 수 있다. 또한, 전자 장치는 치아 이미지으로부터, 치아들의 크기, 모양, 치식 번호 등 을 식별할 수 있다. 이 경우, 얼굴 중심선, 치아 중심선, 치아들의 크기, 모양, 치식 번호 등을 식별할 수 있는 다양한 알고리즘 및/또는 인공지능 모델이 사용될 수 있다. 일 실시예에 따른 전자 장치는, 미소 특성 정보, 얼굴 정면이 포함되는 프레임 및 치아 이미지(82 0)에 기초하여, 사용자의 치아별 크기, 치아별 모양 및 치열 중 적어도 하나를 포함하는, 치아 상태 정보 를 생성할 수 있다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 치아 교정 정보를 생성하는 동작을 설명하기 위한 도면이다. 도 9를 설명함에 있어서, 설명의 편의를 위하여, 사용자의 윗턱(상악)의 치아들을 예시로 설명한다. 일 실시예에서, 전자 장치는 치아 상태 정보에 기초하여, 교정 전 치아를 교정한, 교정 후 치아 를 나타내는 데이터를 생성할 수 있다. 치아 교정 정보인 교정 후 치아는, 교정 전 치아의 치열 을 교정함으로써 교정이 완료된 경우를 시뮬레이션한 결과를 나타내는 모든 데이터일 수 있다. 예를 들어, 도 9 에 도시된 것과 같이, 치아 교정 정보는 교정한 사용자의 치아를 3D 모델링한 데이터일 수 있으나, 이에 한정되 는 것은 아니다. 치아 교정 정보는, 사용자의 치아를 교정치료하기 위한 아치형의 교정 라인을 나타내는 데이터 를 포함할 수 있다. 한편, 도 9에는 도시되지 않았으나, 치아 교정 정보는, 사용자가 미소지은 상태에서의 치열이 교정된 이미지일 수 있다. 이 경우, 전자 장치는 사용자의 인터뷰 동영상으로부터 얼굴 정면이 포함되고, 사용자가 미소짓 고 있는 프레임을 식별할 수 있다. 전자 장치는 사용자의 얼굴 정면이 포함되고, 사용자가 미소짓고 있는 프레임으로부터, 얼굴 중심선 및 치아 중심선을 식별할 수 있다. 전자 장치는 얼굴 중심선 및 치아 중심 선에 기초하여, 사용자가 미소지은 상태에서의 치열을 교정한, 치아 교정 정보를 생성할 수 있다. 예를 들어,사용자가 덧니, 부정교합 등으로 인해 치열이 고르지 못한 경우, 전자 장치는 사용자가 미소지은 상태에 서 치열이 교정된, 치아 교정 이미지를 생성할 수 있다. 일 실시예에서, 전자 장치는 치아 교정 정보를 출력할 수 있다. 예를 들어, 전자 장치는 치아 교정 이미지를 전자 장치의 디스플레이에 출력할 수 있다. 전자 장치는 사용자의 치아가 교정된 상태를 나타내는 치아 교정 이미지를 사용자에게 제공함으로써, 사용자가 교정 치료를 완료하였을 때의 교정 결과를 확 인할 수 있도록 할 수 있다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 미소를 분석하고, 치아 상태 정보를 출력하는 방법 을 설명하기 위한 흐름도이다. 도 10은, 전술한 실시예들을 포함하여 본 발명의 동작의 이해를 돕기 위한 것으로, 전술한 도면들에서 상세하게 설명하였던 구체적인 실시예들에 대해서는 설명을 생략한다. 단계 S1010에서, 일 실시예에 따른 전자 장치는 하나 이상의 카메라를 이용하여 사용자에 대한 인터뷰를 촬영한, 인터뷰 동영상을 획득한다. 전자 장치는 외부 전자 장치(예를 들어, 서버)로부터 인터뷰 동영상을 수신하거나, 전자 장치가 촬 영한 인터뷰 동영상을 저장할 수 있다. 일 실시예에서, 인터뷰 동영상은 인터뷰 장면을 하나의 카메라를 이용하 여 촬영한 것일 수 있다. 인터뷰 동영상은 사용자의 얼굴이 촬영되도록 사용자를 정면, 반측면 중 적어도 하나 를 촬영한 것일 수 있다. 다른 실시예에서, 인터뷰 동영상은 하나의 인터뷰 장면을 복수의 카메라를 이용하여 촬영한 것일 수 있다. 이 경우, 복수의 카메라 각각으로부터 복수의 인터뷰 동영상들이 획득될 수 있다. 복수의 인터뷰 동영상들은, 사용자를 정면, 반측면, 측면 중 적어도 둘 이상을 촬영한 것일 수 있다. 단계 S1020에서, 일 실시예에 따른 전자 장치는 인터뷰 동영상에 포함되는 복수의 프레임들을 미소 분석 모델에 적용하여, 프레임들에 대한 미소 분석 정보를 획득한다. 전자 장치는 사용자의 인터뷰 동영상에 포함되는 복수의 프레임들을 미소 분석 모델에 적용하여, 미소 분 석 정보를 획득할 수 있다. 예를 들어, 전자 장치는 사용자의 얼굴로부터 눈, 눈썹, 코, 귀, 치아, 치식 번호, 윗입술, 아랫입술 및 협측 회랑 중 적어도 하나에 대응하는, 미소 파라미터를 검출할 수 있다. 전자 장치 는 미소 파라미터에 기초하여 사용자가 미소짓는지 여부를 수치화한, 미소 분석 정보를 획득할 수 있다. 단계 S1030에서, 일 실시예에 따른 전자 장치는 미소 분석 정보에 기초하여, 프레임들 중에서 미소가 검 출된 하나 이상의 프레임들을 식별한다. 일 실시예에서, 인터뷰 동영상에 포함되는 복수의 프레임들 중에는, 사용자가 카메라가 아닌 다른 곳을 보고 있 어 사용자의 얼굴이 검출되지 않거나, 사용자의 얼굴이 검출되었더라도 사용자가 미소짓고 있지 않은 프레임들 이 포함될 수 있다. 전자 장치는 미소 분석 정보를 기 설정된 임계값과 비교함으로써, 사용자의 미소 유 무를 검출하고, 인터뷰 동영상에 포함되는 복수의 프레임들 중에서 사용자의 미소가 검출된 하나 이상의 프레임 들을 선택할 수 있다. 단계 S1040에서, 일 실시예에 따른 전자 장치는 미소가 검출된 하나 이상의 프레임들의 각각에 대하여, 미소 레벨을 결정한다. 전자 장치는 사용자의 미소가 검출된 하나 이상의 프레임들에 대하여, 미소 레벨을 결정할 수 있다. 미소 레벨은, 사용자가 미소를 짓고 있는 정도(예를 들어, 잔잔한 미소, 환한 미소 등)로, 눈 모양, 입술 모양, 치아 가 노출되는 정도 등 다양한 미소 파라미터들에 의해 결정될 수 있다. 단계 S1050에서, 일 실시예에 따른 전자 장치는 미소 분석 정보 및 미소 레벨에 기초하여, 사용자의 미소 특성 정보를 생성한다. 일 실시예에서, 사용자의 미소 특성 정보는, 사용자의 미소 레벨에 대응하는, 사용자의 치아 및 치은 노출 특성 을 나타낼 수 있다. 전자 장치는 사용자의 윗입술, 아랫입술, 치아, 치은 및 협측 회랑의 면적 대비, 사용자의 치아 및 치은 의 면적을 계산할 수 있다. 프로세서는 결정된 미소 레벨에 대응하는 사용자의 미소 특성을 수치화한, 미 소 특성 정보를 생성할 수 있다. 단계 S1060에서, 일 실시예에 따른 전자 장치는 상기 사용자의 미소 특성 정보에 기초하여, 상기 사용자 의 치아 상태 정보를 생성한다. 전자 장치는 사용자의 미소 시 노출되는 치아 및 치은의 정도에 기초하여 사용자의 치아별 크기, 치아별 모양 및 치열 중 적어도 하나를 포함하는, 치아 상태 정보를 생성할 수 있다. 전자 장치는 치아 상태 정 보를 생성할 때, 사용자의 치아 이미지를 획득하고, 획득된 사용자의 치아 이미지에 더 기초하여 치아 상태 정 보를 생성할 수 있다. 단계 S1070에서, 일 실시예에 따른 전자 장치는 상기 사용자의 치아 상태 정보를 출력한다. 전자 장치는 전술한 실시예들에 따라 전자 장치에서 생성된 사용자의 치아 상태 정보를 사용자가 확인할 수 있도록, 전자 장치의 디스플레이에 사용자의 치아 상태 정보를 표시할 수 있다. 도 11은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다. 일 실시예에서, 전자 장치는 도 2a 내지 도 2b에서 전술한 구성들 외에, 카메라, 디스플레이 및 입출력 인터페이스를 더 포함할 수 있다. 전자 장치의 통신 인터페이스, 메모리 및 프로세서는 도 2a 내지 도 2b에서 이미 전술하였으므로, 동일한 설명은 생략한다. 카메라는 촬영 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화상 프레임을 처리한 다. 처리된 화상 프레임은 디스플레이에 표시되거나 메모리에 저장될 수 있다. 한편, 전자 장치의 카메라 외에, 다른 복수의 카메라들이 전자장치에 연결될 수 있다. 전자 장치에 다른 복수의 카메라들이 연결되는 경우, 전자 장치는 카메라 및 전자 장치에 연결된 다른 복수의 카메라들을 이용하여, 복수의 인터뷰 동영상들을 획득할 수 있다. 이 경우, 복수의 인터뷰 동영상 들은 사용자를 정면, 반측면, 측면 중 적어도 둘 이상을 촬영한 동영상들일 수 있다. 한편, 전자 장치는 카메라를 이용하여, 전술한 실시예들의 치아 이미지를 획득할 수 있다. 일부 실 시예에서, 치아 이미지는, 치아 특성을 촬영하기 위해 보다 적합한, 외부 촬영 장치를 통해 획득된 이미지일 수 있다. 예를 들어, 치아 이미지는 3D 스캐너를 이용하여 치아를 촬영한 이미지일 수 있다. 다만, 3D 스캐너는 예 시일 뿐이며, 외부 촬영 장치가 이에 한정되는 것은 아니다. 전자 장치에 외부 촬영 장치(예를 들어, 3D 스캐너)가 연결될 수 있다. 프로세서는 통신 인터페이스를 제어하여, 외부 촬영 장치로부터 치아 이미지를 획득할 수 있다. 디스플레이는 프로세서의 제어에 의해 전자 장치에서 처리되는 정보를 표시(출력)한다. 예를 들어, 디스플레이는 사용자의 미소 분석 정보, 사용자의 치아 상태 정보, 사용자의 치아 교정 정보를 표 시할 수 있다. 전자 장치에 디스플레이가 포함되는 경우, 전술한 실시예들에 따라 전자 장치(100 0)가 정보를 출력한다고 함은, 디스플레이에 정보가 표시되는 것일 수 있다. 입출력 인터페이스는 전자 장치에 입력/출력되는 다양한 데이터를 처리하기 위한 하드웨어 및 소프트웨어 로 구성될 수 있다. 입출력 인터페이스의 입력 인터페이스는, 하나 이상의 마이크로폰 및 사용자 입력부 중 적어도 하나를 포 함할 수 있다. 마이크로폰은 외부의 음향 신호를 전기적인 음성 데이터로 처리한다. 처리된 음성 데이터는 전자 장치에 서 수행 중인 기능(또는 실행 중인 응용 프로그램)에 따라 다양하게 활용될 수 있다. 한편, 마이크로폰에는 외 부의 음향 신호를 입력 받는 과정에서 발생되는 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알고리즘이 구 현될 수 있다. 사용자 입력부는 사용자로부터 정보를 입력받기 위한 것으로서, 사용자 입력부를 통해 정보가 입력되면, 제어부 는 입력된 정보에 대응되도록 본 장치의 동작을 제어할 수 있다. 이러한, 사용자 입력부는 하드웨어식 물리 키 (예를 들어, 본 장치의 전면, 후면 및 측면 중 적어도 하나에 위치하는 버튼, 돔 스위치 (dome switch), 조그 휠, 조그 스위치 등) 및 소프트웨어식 터치 키를 포함할 수 있다. 입출력 인터페이스의 출력 인터페이스는, 음향 출력부를 포함할 수 있다. 음향 출력부는 통신부를 통해 수신되거나 또는 메모리에 저장된 오디오 데이터를 출력하거나, 본 장치에서 수행되는 기능과 관련된 음향 신호 를 출력할 수 있다. 이러한 음향 출력부에는 리시버(receiver), 스피커(speaker), 버저(buzzer) 등이 포함될 수 있다. 개시된 실시예에서, 전자 장치가 사용자 인터뷰 동영상을 촬영하는 경우, 전자 장치는 음향 출력부를 이용하여 사용자의 미소를 유도하기 위한 자연어 문장을 출력할 수 있다. 또한, 전자 장치가 치아 이미지를 획득하는 경우, 전자 장치는 음향 출력부를 이용하여 사용자에게 치아를 노출할 것을 가이드 하는 자연어 문장 및/또는 음향을 출력할 수 있다. 한편, 개시된 실시예들은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto- optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드 뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 컴퓨터 판 독 가능 매체는, 비일시적(non-transitory) 기록매체의 형태로 제공될 수 있다. 여기서, 비일시적 기록매체는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어 는 데이터가 기록매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, ' 비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다."}
{"patent_id": "10-2024-0091712", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치의 동작을 개략적으로 설명하기 위한 도면이다. 도 2a는 본 개시의 일 실시예에 따른 전자 장치의 개략적으로 구성을 도시한 블록도이다. 도 2b는 본 개시의 일 실시예에 따른 전자 장치의 메모리에 저장된 모듈들을 도시한 블록도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 이용하는 미소 분석 모델을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 미소 분석 모델을 훈련시키기 위하여 이용하는 훈련 데이터를설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 미소 분석 모델을 이용하여 미소 분석 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 미소 레벨을 결정하는 동작을 설명하기 위한 도면이 다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 치아 상태 정보를 생성하는 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 치아 상태 정보를 생성하는, 다른 동작을 설명하기 위한 도면 이다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 치아 교정 정보를 생성하는 동작을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 사용자의 미소를 분석하고, 치아 상태 정보를 출력하는 방법 을 설명하기 위한 흐름도이다. 도 11은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다."}
