{"patent_id": "10-2019-0130120", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0046432", "출원번호": "10-2019-0130120", "발명의 명칭": "AR 모드 및 VR 모드를 제공하는 XR 디바이스 및 그 제어 방법", "출원인": "엘지전자 주식회사", "발명자": "이현옥"}}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "XR 디바이스에서, 외부 디바이스와 데이터를 송수신하는 무선 통신부;상기 XR 디바이스의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를제외한 제 1 이미지를 캡쳐하는 카메라;투명한 부분을 포함하고, 캡쳐된 상기 제 1 가상 이미지를 디스플레이하는 디스플레이;상기 XR 디바이스를 착용한 사용자의 움직임을 센싱하는 센서부; 및캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 1 이미지 및 상기 센싱된 사용자의 움직임을 기초로 사용자 행동을 예측하고, 예측된 상기 사용자 행동에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는 제어부를 포함하는 XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 제어부는 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하는, XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 제어부는 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 주변 이미지와 구분 가능하게 디스플레이하도록 제어하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 제어부는 상기 센싱된 사용자의 움직임을 3축 가속도 센서를 이용하여 개별 행동 별로 DC 데이터를 추출하고, 추출된 상기 DC 데이터를 기초로 사용자 행동을 예측하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 제어부는 상기 사용자와 제 1 가상 오브젝트 사이의 거리를 기초로 상기 디스플레이가 변경된 상기 제 1 가상 이미지를디스플레이하도록 제어하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 제어부는 공개특허 10-2021-0046432-3-상기 사용자가 상기 제 1 가상 오브젝트를 보고 놀라는 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상이미지를 디스플레이하도록 제어하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 제어부는 상기 사용자가 제 1 가상 오브젝트와 관련된 특정 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 상기 제어부는 상기 사용자가 현실 오브젝트를 가상 오브젝트로 잘못 인지하고 현실 오브젝트에 다가가는 경우, 상기 디스플레이가 변경된 가상 이미지를 현실 오브젝트 주위에 디스플레이하도록 제어하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 2 항에 있어서, 상기 제어부는 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하고, 상기 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하고, 이후 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 결정된 상기 특정 레벨부터 디스플레이하도록 제어하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 상기 제어부는 예측된 상기 사용자 행동을 기초로 사용자가 위험하다고 결정되면, 상기 디스플레이가 상기 제 1 가상 이미지를사라지도록 제어하는,XR 디바이스."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "XR 디바이스 제어 방법에 있어서, XR 디바이스의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를 제외한 제 1 이미지를 캡쳐하는 단계;상기 XR 디바이스를 착용한 사용자의 움직임을 센싱하는 단계;캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 1 이미지 및 상기 센싱된 사용자의 움직임을 기초로 사용자 행동을 예측하는 단계; 예측된 상기 사용자 행동이 문제를 발생시키는지를 결정하는 단계; 및 예측된 사용자 행동에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는단계;를 포함하는 XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2021-0046432-4-제 11 항에 있어서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 주변 이미지와 구분 가능하게 디스플레이하도록 제어하는단계를 더 포함하는,XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서, 상기 센싱된 사용자의 움직임을 3축 가속도 센서를 이용하여 개별 행동 별로 DC 데이터를 추출하는 단계; 및 추출된 상기 DC 데이터를 기초로 사용자 행동을 예측하는 단계를 더 포함하는, XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서, 상기 사용자와 제 1 가상 오브젝트 사이의 거리를 기초로 상기 디스플레이가 변경된 상기 제 1 가상 이미지를디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서, 상기 사용자가 상기 제 1 가상 오브젝트를 보고 놀라는 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상이미지를 디스플레이하도록 제어하는 단계를 더 포함하는,XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11 항에 있어서, 상기 사용자가 제 1 가상 오브젝트와 관련된 특정 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는 단계를 더 포함하는,XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서, 상기 사용자가 현실 오브젝트를 가상 오브젝트로 잘못 인지하고 현실 오브젝트에 다가가는 경우, 상기 디스플레이가 변경된 가상 이미지를 현실 오브젝트 주위에 디스플레이하도록 제어하는 단계를 더 포함하는,XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 12 항에 있어서, 공개특허 10-2021-0046432-5-상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하는 단계; 상기 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하는 단계; 및이후 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 결정된 상기 특정 레벨부터 디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 11 항에 있어서, 예측된 상기 사용자 행동을 기초로 사용자가 위험하다고 결정되면, 상기 디스플레이가 상기 제 1 가상 이미지를사라지도록 제어하는 단계를 더 포함하는,XR 디바이스의 제어 방법."}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서에서는 본 발명은 AR (Augmented Reality) 모드 및 VR (Virtual Reality) 모드를 제공하는 XR 디바이 스 및 그 제어 방법에 관한 것으로서, 보다 구체적으로는 5G 통신"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": ", 로봇 기술 분야, 자율 주행 기술 분야 및 AI (Artificial Intelligence) 기술 분야에도 모두 적용 가능하다. 본 발명은 캡쳐된 제 1 가상 이미지, 캡쳐된 제 1 이미지 및 센싱된 사용자의 움직임을 기초로 사용자 행동을 예측하고, 예측된 상기 사용자 행동에 따라서, 디스플레이가 변경된 제 1 가상 이미지를 디스플레이하도록 제어하는 것을 그 요지로 한다. 대 표 도 - 도24"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2021-0046432 CPC특허분류 G06F 3/0346 (2013.01) G06N 3/08 (2013.01) G06T 19/006 (2013.01) 발명자 조창석 서울특별시 서초구 양재대로11길 19 LG전자 특허센 터 강철 서울특별시 서초구 양재대로11길 19 LG전자 특허센 터 송상훈 서울특별시 서초구 양재대로11길 19 LG전자 특허센 터신만수 서울특별시 서초구 양재대로11길 19 LG전자 특허센 터 전상국 서울특별시 서초구 양재대로11길 19 LG전자 특허센 터명 세 서 청구범위 청구항 1 XR 디바이스에서, 외부 디바이스와 데이터를 송수신하는 무선 통신부; 상기 XR 디바이스의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를 제외한 제 1 이미지를 캡쳐하는 카메라; 투명한 부분을 포함하고, 캡쳐된 상기 제 1 가상 이미지를 디스플레이하는 디스플레이; 상기 XR 디바이스를 착용한 사용자의 움직임을 센싱하는 센서부; 및 캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 1 이미지 및 상기 센싱된 사용자의 움직임을 기초로 사용자 행 동을 예측하고, 예측된 상기 사용자 행동에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어 하는 제어부 를 포함하는 XR 디바이스. 청구항 2 제 1 항에 있어서, 상기 제어부는 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하는, XR 디바이스. 청구항 3 제 1 항에 있어서, 상기 제어부는 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 주변 이미지와 구분 가능하게 디스플레이하도록 제어하는, XR 디바이스. 청구항 4 제 1 항에 있어서, 상기 제어부는 상기 센싱된 사용자의 움직임을 3축 가속도 센서를 이용하여 개별 행동 별로 DC 데이터를 추출하고, 추출된 상기 DC 데이터를 기초로 사용자 행동을 예측하는, XR 디바이스. 청구항 5 제 1 항에 있어서, 상기 제어부는 상기 사용자와 제 1 가상 오브젝트 사이의 거리를 기초로 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는, XR 디바이스. 청구항 6 제 1 항에 있어서, 상기 제어부는 상기 사용자가 상기 제 1 가상 오브젝트를 보고 놀라는 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는, XR 디바이스. 청구항 7 제 1 항에 있어서, 상기 제어부는 상기 사용자가 제 1 가상 오브젝트와 관련된 특정 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상 이미 지를 디스플레이하도록 제어하는, XR 디바이스. 청구항 8 제 1 항에 있어서, 상기 제어부는 상기 사용자가 현실 오브젝트를 가상 오브젝트로 잘못 인지하고 현실 오브젝트에 다가가는 경우, 상기 디스플레 이가 변경된 가상 이미지를 현실 오브젝트 주위에 디스플레이하도록 제어하는, XR 디바이스. 청구항 9 제 2 항에 있어서, 상기 제어부는 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하고, 상기 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하고, 이후 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 결정된 상기 특정 레벨부터 디스플레이하도록 제어하 는, XR 디바이스. 청구항 10 제 1 항에 있어서, 상기 제어부는 예측된 상기 사용자 행동을 기초로 사용자가 위험하다고 결정되면, 상기 디스플레이가 상기 제 1 가상 이미지를 사라지도록 제어하는, XR 디바이스. 청구항 11 XR 디바이스 제어 방법에 있어서, XR 디바이스의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를 제외 한 제 1 이미지를 캡쳐하는 단계; 상기 XR 디바이스를 착용한 사용자의 움직임을 센싱하는 단계; 캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 1 이미지 및 상기 센싱된 사용자의 움직임을 기초로 사용자 행 동을 예측하는 단계; 예측된 상기 사용자 행동이 문제를 발생시키는지를 결정하는 단계; 및 예측된 사용자 행동에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는 단계; 를 포함하는 XR 디바이스의 제어 방법. 청구항 12 제 11 항에 있어서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하는 단 계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 13 제 11 항에 있어서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 주변 이미지와 구분 가능하게 디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 14 제 11 항에 있어서, 상기 센싱된 사용자의 움직임을 3축 가속도 센서를 이용하여 개별 행동 별로 DC 데이터를 추출하는 단계; 및 추출된 상기 DC 데이터를 기초로 사용자 행동을 예측하는 단계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 15 제 11 항에 있어서, 상기 사용자와 제 1 가상 오브젝트 사이의 거리를 기초로 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 16 제 11 항에 있어서, 상기 사용자가 상기 제 1 가상 오브젝트를 보고 놀라는 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 17 제 11 항에 있어서, 상기 사용자가 제 1 가상 오브젝트와 관련된 특정 행동을 하면, 상기 디스플레이가 변경된 상기 제 1 가상 이미 지를 디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 18 제 17 항에 있어서, 상기 사용자가 현실 오브젝트를 가상 오브젝트로 잘못 인지하고 현실 오브젝트에 다가가는 경우, 상기 디스플레 이가 변경된 가상 이미지를 현실 오브젝트 주위에 디스플레이하도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 19 제 12 항에 있어서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어하는 단 계; 상기 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하는 단계; 및 이후 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 결정된 상기 특정 레벨부터 디스플레이하도록 제어하 는 단계를 더 포함하는, XR 디바이스의 제어 방법. 청구항 20 제 11 항에 있어서, 예측된 상기 사용자 행동을 기초로 사용자가 위험하다고 결정되면, 상기 디스플레이가 상기 제 1 가상 이미지를 사라지도록 제어하는 단계를 더 포함하는, XR 디바이스의 제어 방법. 발명의 설명 기 술 분 야 본 발명은 AR (Augmented Reality) 모드 및 VR (Virtual Reality) 모드를 제공하는 XR 디바이스 및 그 제어 방 법에 관한 것으로서, 보다 구체적으로는 5G 통신 기술 분야, 로봇 기술 분야, 자율 주행 기술 분야 및 AI (Artificial Intelligence) 기술 분야에도 모두 적용 가능하다. 본 발명은 사용자가 XR 디바이스를 착용하고, 가상 이미지를 현실로 오인하여 가상 이미지와 관련된 특정 동작을 하면, 사용자의 움직임을 기초로 사용자 행 동을 예측하고, 사용자가 현실과 가상 오브젝트를 구별할 수 있도록 가상 이미지를 디스플레이하는 XR 디바이스 에 관한 것이다."}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "VR (Virtual Reality) 기술은 현실 세계의 객체나 배경 등을 CG (Computer Graphic) 영상으로만 제공하고, AR (Augmented Reality) 기술은 실제 사물 영상 위에 가상으로 만들어진 CG 영상을 함께 제공하며, MR (Mixed) 기 술은 현실 세계에 가상 객체들을 섞고 결합시켜서 제공하는 컴퓨터 그래픽 기술이다. 전술한 VR, AR, MR 등을 모두 간단히 XR (extended reality) 기술로 지칭하기도 한다. AR 기술은 현실세계에 가상의 디지털 이미지를 입히는 방식이다. 눈으로 실제 세계를 볼 수 있다는 점에서 눈을 가린 채 그래픽 영상만 보여주는 가상현실(VR)과는 다르다. 실내에서만 쓸 수 있는 VR 기기와 달리 AR 글래스는 안경처럼 걸어다니면서 쓸 수 있어 쓰임새가 훨씬 다양하다. 가상 이미지의 기술은 점점 발달하여 더욱 사실감이 드는 가상 이미지를 구현하는 것이 가능하다. 그런데, 종래 기술의 경우, 사용자가 AR 글래스를 착용한 상태에서 가상 오브젝트를 실제 오브젝트로 오인하고 특정 행동을 하면, 문제가 생기는 불편함이 있었다. 예를 들어, 가상 나무를 현실 나무로 오인지하고, 사용자가 가상 나무에 기대는 동작을 하면, 실제로는 사용자가 허공에 기대기 때문에 무게 중심을 잃고 넘어지게 되어 사용자가 불편 함을 느끼는 문제점이 있었다."}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시 예의 목적은, 전술한 문제점 등을 해결하기 위하여 제시된다. 본 발명의 일 실시 예는, 사용 자가 가상 이미지를 현실 이미지로 오인하여 가상 이미지와 관련된 특정 동작을 하면, 사용자의 움직임을 기초 로 사용자 행동을 예측하고, 예측된 사용자 행동에 따라서 사용자가 현실과 가상 오브젝트를 구별할 수 있도록 변경된 가상 이미지를 디스플레이하는 XR 디바이스 및 그 제어 방법을 제공하는 것을 목적으로 한다. 본 발명의 다른 실시 예는, 예측된 사용자 행동에 따라서 사용자가 현실과 가상 오브젝트를 구별할 수 있도록 가상 이미지를 복수의 단계 별로 다르게 디스플레이하는 XR 디바이스 및 그 제어 방법을 제공하는 것을 목적으로 한다. 본 발명의 또 다른 실시 예는, 디스플레이가 변경된 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이 하도록 제어하고, 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하고, 이후 디스플레이가 변경된 제 1 가상 이미지를 결정된 특정 레벨부터 디스플레이하도록 XR 디바이스 및 그 제어 방법을 제공하는 것을 목 적으로 한다. 다만, 전술한 목적만으로 제한되는 것은 아니며, 본 명세서 전체 내용에 기초하여 당업자가 유추할 수 있는 다 른 목적으로 본 발명의 권리범위가 확장될 수 있다."}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일면에 따른, XR 디바이스는, 외부 디바이스와 데이터를 송수신하는 무선 통신부; 상기 XR 디바이스 의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를 제외한 제 1 이 미지를 캡쳐하는 카메라; 투명한 부분을 포함하고, 캡쳐된 상기 제 1 가상 이미지를 디스플레이하는 디스플레이; 상기 XR 디바이스를 착용한 사용자의 움직임을 센싱하는 센서부; 및 캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 1 이미지 및 상기 센싱된 사용자의 움직임을 기초로 사용자 행동을 예측하고, 예측된 상기 사용자 행동에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하는 제 어부를 포함한다. 본 발명의 다른 면에 따른, XR 디바이스 제어 방법은, XR 디바이스의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를 제외한 제 2 이미지를 캡쳐하는 단계; 상기 XR 디바이스를 착용한 사용자의 움직임을 센싱하는 단계; 캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 1 이미지 및 상기 센 싱된 사용자의 움직임을 기초로 사용자 행동을 예측하는 단계; 예측된 상기 사용자 행동이 문제를 발생시키는지 를 결정하는 단계; 및 결정 결과에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도 록 제어하는 단계를 포함한다."}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시 예에 따르면, 사용자가 가상 이미지를 현실 이미지로 오인하여 가상 이미지와 관련된 특정 동작을 하면, 사용자의 움직임을 기초로 사용자 행동을 예측하고, 예측된 사용자 행동에 따라서 사용자가 현실 과 가상 오브젝트를 구별할 수 있도록 변경된 가상 이미지를 디스플레이할 수 있어서, 사용자가 현실과 가상 오 브젝트를 오인해서 생기는 사고를 방지할 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 본 발명의 다른 실시 예에 따르면, 예측된 사용자 행동에 따라서 사용자가 현실과 가상 오브젝트를 구별할 수 있도록 가상 이미지를 복수의 단계 별로 다르게 디스플레이할 수 있어서, 사용자가 가상 오브젝트를 인식하는데 도움을 줄 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 본 발명의 또 다른 실시 예에 따르면, 디스플레이가 변경된 제 1 가상 이미지를 복수의 단계 별로 상이하게 디 스플레이하도록 제어하고, 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하고, 이후 디스플레이 가 변경된 제 1 가상 이미지를 결정된 특정 레벨부터 디스플레이하도록 제어할 수 있어서, 사용자가 현실과 가 상 오브젝트를 보다 빠르게 구별할 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 하기의 실시예들은 본 발명을 구체화하기 위한 것일 뿐 본 발명의 권리 범위를 제한하거나 한정하는 것이 아님은 물론이다. 본 발명의 상세한 설명 및 실시예들로부터 본 발명이 속하는 기술 분야의 전문가가 용이 하게 유추할 수 있는 것은 본 발명의 권리 범위에 속하는 것으로 해석된다. 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 안되며, 예시적인 것으로 고려되어야 한다. 본 발 명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경 은 본 발명의 범위에 포함된다.Introduction 이하에서, 하향링크(downlink, DL)는 기지국(base station, BS)에서 사용자 기기(user equipment, UE)로의 통 신을 의미하며, 상향링크(uplink, UL)는 UE에서 BS로의 통신을 의미한다. 하향링크에서 전송기(transmitter)는 BS의 일부이고, 수신기(receiver)는 UE의 일부일 수 있다. 상향링크에서 전송기는 UE의 일부이고, 수신기는 BS 의 일부일 수 있다. 본 명세에서 UE는 제 1 통신 장치, BS는 제 2 통신 장치로 표현될 수도 있다. BS는 고정국 (fixed station), Node B, eNB(evolved-NodeB), gNB(Next Generation NodeB), BTS(base transceiver system), 접속 포인트(access point, AP), 네트워크 혹은 5G (5th generation) 네트워크 노드, AI (Artificial Intelligence) 시스템, RSU(road side unit), 로봇, AR/VR(Augmented Reality/Virtual Reality) 시스템 등의 용어에 의해 대체될 수 있다. 또한, UE는 단말(terminal), MS(Mobile Station), UT(User Terminal), MSS(Mobile Subscriber Station), SS(Subscriber Station), AMS(Advanced Mobile Station), WT(Wireless terminal), MTC(Machine-Type Communication) 장치, M2M(Machine-to-Machine) 장치, D2D(Device-to-Device) 장치, 차량(vehicle), 로봇(robot), AI 장치 (또는 모듈), AR/VR 장치 (또는 모듈) 등의 용어로 대체될 수 있 다. 이하의 기술은 CDMA(Code Division Multiple Access), FDMA(Frequency Division Multiple Access), TDMA(Time Division Multiple Access), OFDMA(Orthogonal Frequency Division Multiple Access), SC-FDMA(Single Carrier FDMA) 등과 같은 다양한 무선 접속 시스템에 사용될 수 있다. 설명의 편의를 위해, 본 명세는 3GPP 통신 시스템(예, LTE-A, NR)을 기반으로 설명하지만 본 발명이 이에 제한 되는 것은 아니다. 참고로, 3GPP(3rd Generation Partnership Project) LTE(Long Term Evolution)은 E-UTRA를 사용하는 E-UMTS(Evolved UMTS)의 일부이고 LTE-A(Advanced)/LTE-A pro는 3GPP LTE의 진화된 버전이다. 3GPP NR(New Radio or New Radio Access Technology)는 3GPP LTE/LTE-A/LTE-A pro의 진화된 버전이다. 본 명세(disclosure)에서, 노드(node)라 함은 UE와 통신하여 무선 신호를 전송/수신할 수 있는 고정된 포인트 (point)을 말한다. 다양한 형태의 BS들이 그 명칭에 관계없이 노드로서 이용될 수 있다. 예를 들어, BS, NB, eNB, 피코-셀 eNB(PeNB), 홈 eNB(HeNB), 릴레이(relay), 리피터(repeater) 등이 노드가 될 수 있다. 일 노드에 는 최소 하나의 안테나가 설치된다. 상기 안테나는 물리 안테나를 의미할 수도 있으며, 안테나 포트, 가상 안테 나, 또는 안테나 그룹을 의미할 수도 있다. 노드는 포인트(point)라고 불리기도 한다. 본 명세에서 셀(cell)이라 함은 하나 이상의 노드가 통신 서비스를 제공하는 일정 지리적 영역 혹은 무선 자원 을 의미할 수 있다. 지리적 영역의 \"셀\"은 노드가 반송파를 이용하여 서비스를 제공할 수 있는 커버리지 (coverage)라고 이해될 수 있으며, 무선 자원의 \"셀\"은 상기 반송파에 의해 설정(configure)되는 주파수 크기인 대역폭(bandwidth, BW)와 연관된다. 노드가 유효한 신호를 전송할 수 있는 범위인 하향링크 커버리지와 UE로부 터 유효한 신호를 수신할 수 있는 범위인 상향링크 커버리지는 해당 신호를 나르는 반송파에 의해 의존하므로 노드의 커버리지는 상기 노드가 사용하는 무선 자원의 \"셀\"의 커버리지와 연관되기도 한다. 따라서 \"셀\"이라는 용어는 때로는 노드에 의한 서비스의 커버리지를, 때로는 무선 자원을, 때로는 상기 무선 자원을 이용한 신호가 유효한 세기로 도달할 수 있는 범위를 의미하는 데 사용될 수 있다. 본 명세에서 특정 셀과 통신한다고 함은 상기 특정 셀에 통신 서비스를 제공하는 BS 혹은 노드와 통신하는 것을 의미할 수 있다. 또한, 특정 셀의 하향링크/상향링크 신호는 상기 특정 셀에 통신 서비스를 제공하는 BS 혹은 노드로부터의/로의 하향링크/상향링크 신호를 의미한다. UE에게 상향링크/하향링크 통신 서비스를 제공하는 셀 을 특히 서빙 셀(serving cell)이라고 한다. 또한, 특정 셀의 채널 상태/품질은 상기 특정 셀에 통신 서비스를 제공하는 BS 혹은 노드와 UE 사이에 형성된 채널 혹은 통신 링크의 채널 상태/품질을 의미한다. 한편, 무선 자원과 연관된 \"셀\"은 하향링크 자원(DL resources)와 상향링크 자원(UL resources)의 조합, 즉, DL 컴포넌트 반송파(component carrier, CC) 와 UL CC의 조합으로 정의될 수 있다. 셀은 DL 자원 단독, 또는 DL 자원과 UL 자원의 조합으로 설정될(configured) 수도 있다. 반송파 집성(carrier aggregation)이 지원되는 경우, DL 자원(또는, DL CC)의 반송파 주파수(carrier frequency)와 UL 자원(또는, UL CC)의 반송파 주파수 (carrier frequency) 사이의 링키지(linkage)는 해당 셀을 통해 전송되는 시스템 정보(system information)에 의해 지시될 수 있다. 여기서, 반송파 주파수는 각 셀 혹은 CC의 중심 주파수(center frequency)와 같을 수도 혹은 다를 수도 있다. 이하에서는 1차 주파수(primary frequency) 상에서 동작하는 셀을 1차 셀(primary cell, Pcell) 혹은 PCC로 지칭하고, 2차 주파수(Secondary frequency) 상에서 동작하는 셀을 2차 셀(secondary cell, Scell) 혹은 SCC로 칭한다. Scell이라 함은 UE가 BS와 RRC(Radio Resource Control) 연결 수립(connection establishment) 과정을 수행하여 상기 UE와 상기 BS 간에 RRC 연결이 수립된 상태, 즉, 상기 UE가RRC_CONNECTED 상태가 된 후에 설정될 수 있다. 여기서 RRC 연결은 UE의 RRC와 BS의 RRC가 서로 RRC 메시지를 주고 받을 수 있는 통로를 의미할 수 있다. Scell은 UE에게 추가적인 무선 자원을 제공하기 위해 설정될 수 있 다. UE의 성능(capabilities)에 따라, Scell이 Pcell과 함께, 상기 UE를 위한 서빙 셀의 모음(set)을 형성할 수 있다. RRC_CONNECTED 상태에 있지만 반송파 집성이 설정되지 않았거나 반송파 집성을 지원하지 않는 UE의 경 우, Pcell로만 설정된 서빙 셀이 단 하나 존재한다. 셀은 고유의 무선 접속 기술을 지원한다. 예를 들어, LTE 셀 상에서는 LTE 무선 접속 기술(radio access technology, RAT)에 따른 전송/수신이 수행되며, 5G 셀 상에서는 5G RAT에 따른 전송/수신이 수행된다. 반송파 집성 기술은 광대역 지원을 위해 목표 대역폭(bandwidth)보다 작은 시스템 대역폭을 가지는 복수의 반송 파들을 집성하여 사용하는 기술을 말한다. 반송파 집성은 각각이 시스템 대역폭(채널 대역폭이라고도 함)을 형 성하는 복수의 반송파 주파수들을 사용하여 하향링크 혹은 상향링크 통신을 수행한다는 점에서, 복수의 직교하 는 부반송파들로 분할된 기본 주파수 대역을 하나의 반송파 주파수에 실어 하향링크 혹은 상향링크 통신을 수행 하는 OFDMA 기술과 구분된다. 예를 들어, OFDMA 혹은 직교 주파수 분할 다중화(orthogonal frequency division multiplexing, OFDM)의 경우에는 일정 시스템 대역폭을 갖는 하나의 주파수 대역이 일정 부반송파 간격을 갖는 복수의 부반송파들로 분할되고, 정보/데이터가 상기 복수의 부반송파들 내에서 매핑되며, 상기 정보/데이터가 맵핑된 상기 주파수 대역은 주파수 상향 변환(upconversion)을 거쳐 상기 주파수 대역의 반송파 주파수로 전송 된다. 무선 반송파 집성의 경우에는 각각이 자신의 시스템 대역폭 및 반송파 주파수를 갖는 주파수 대역들이 동 시에 통신에 사용될 수 있으며, 반송파 집성에 사용되는 각 주파수 대역은 일정 부반송파 간격을 갖는 복수의 부반송파들로 분할될 수 있다. 3GPP 기반 통신 표준은 물리 계층(physical layer)의 상위 계층(upper layer)(예, 매제 접속 제어(medium access control, MAC) 계층, 무선 링크 제어(radio link control, RLC) 계층, 패킷 데이터 수렴 프로토콜 (protocol data convergence protocol, PDCP) 계층, 무선 자원 제어(radio resource control, RRC) 계층, 서비 스 데이터 적응 프로토콜(service data adaptation protocol, SDAP), 비-접속 층(non-access stratum, NAS) 계 층)로부터 기원한 정보를 나르는 자원 요소(resource element)들에 대응하는 하향링크 물리 채널들과, 물리 계 층에 의해 사용되나 상위 계층으로부터 기원하는 정보를 나르지 않는 자원 요소들에 대응하는 하향링크 물리 신 호들을 정의한다. 예를 들어, 물리 하향링크 공유 채널(physical downlink shared channel, PDSCH), 물리 브로 드캐스트 채널(physical broadcast channel, PBCH), 물리 멀티캐스트 채널(physical multicast channel, PMCH), 물리 제어 포맷 지시자 채널(physical control format indicator channel, PCFICH), 물리 하향링크 제 어 채널(physical downlink control channel, PDCCH)이 하향링크 물리 채널들로서 정의되어 있으며, 참조 신호 와 동기 신호가 하향링크 물리 신호들로서 정의되어 있다. 파일럿(pilot)이라고도 지칭되는 참조 신호 (reference signal, RS)는 BS와 UE가 서로 알고 있는 기정의된 특별한 파형의 신호를 의미하는데, 예를 들어, 셀 특정적 RS(cell specific RS), UE-특정적 RS(UE-specific RS, UE-RS), 포지셔닝 RS(positioning RS, PRS), 채널 상태 정보 RS(channel state information RS, CSI-RS), 복조 참조 신호(demodulation reference signal, DMRS)가 하향링크 참조 신호들로서 정의된다. 한편, 3GPP 기반 통신 표준은 상위 계층으로부터 기원한 정보를 나르는 자원 요소들에 대응하는 상향링크 물리 채널들과, 물리 계층에 의해 사용되나 상위 계층으로부터 기원하 는 정보를 나르지 않는 자원 요소들에 대응하는 상향링크 물리 신호들을 정의하고 있다. 예를 들어, 물리 상향 링크 공유 채널(physical uplink shared channel, PUSCH), 물리 상향링크 제어 채널(physical uplink control channel, PUCCH), 물리 임의 접속 채널(physical random access channel, PRACH)가 상향링크 물리 채널로서 정 의되며, 상향링크 제어/데이터 신호를 위한 복조 참조 신호(demodulation reference signal, DMRS)와 상향링크 채널 측정에 사용되는 사운딩 참조 신호(sounding reference signal, SRS)가 정의된다. 본 명세에서 물리 공유 채널(예, PUSCH, PDSCH)은 물리 계층(physical layer)의 상위 계층(upper layer)(예, 매제 접속 제어(medium access control, MAC) 계층, 무선 링크 제어(radio link control, RLC) 계층, 패킷 데 이터 수렴 프로토콜(protocol data convergence protocol, PDCP) 계층, 무선 자원 제어(radio resource control, RRC) 계층, 서비스 데이터 적응 프로토콜(service data adaptation protocol, SDAP), 비-접속 층 (non-access stratum, NAS) 계층)로부터 기원한 정보를 나르는 데 사용된다. 본 명세에서 참조 신호(reference signal, RS)는 BS와 UE가 서로 알고 있는 기정의된 특별한 파형의 신호를 의 미한다. 3GPP 기반 통신 시스템에서는, 예를 들어, 셀 공통 RS인 셀 특정적 RS(cell specific RS), 특정 UE를 위한 물리 채널의 복조를 위한 UE-특정적 RS(UE-specific RS, UE-RS), 하향링크 채널 상태를 측정/추정하기 위 한 채널 상태 정보 RS(channel state information RS, CSI-RS), 물리 채널의 복조를 위한 복조 참조 신호 (demodulation reference signal, DMRS)가 하향링크 RS들로서 정의되며, 상향링크 제어/데이터 신호의 복조를위한 DMRS와 상향링크 채널 상태 측정/추정에 사용되는 사운딩 참조 신호(sounding reference signal, SRS)가 상향링크 RS들로서 정의된다. 본 명세에서 수송 블록(transport block)은 물리 계층을 위한 페이로드(payload)이다. 예를 들어, 상위 계층 혹 은 매체 접속 제어(medium access control, MAC) 계층으로부터 물리 계층에 주어진 데이터가 기본적으로 수송 블록으로 지칭된다. AR/VR 모듈을 포함하는 장치(AR/VR 장치)인 UE UE는 AR/VR 데이터를 포함하는 수송 블록을 PUSCH를 통해 무선 통신 네트워크(예, 5G 네트워크)로 전송할 수 있다. 혹은 UE는 5G 네트워크로부터의 AR/VR 데이터를 포함하는 수송 블록 혹은 상기 UE가 전송한 AR/VR 데이터와 관련된 응답을 포함하는 수송 블록을 상기 무선 통신 네트워크로부터 수신할 수 있다. 본 명세에서 HARQ(Hybrid Automatic Repeat and reQuest)는 오류 제어 방법의 일종이다. 하향링크를 통해 전송 되는 HARQ-ACK(HARQ acknowledgement)은 상향링크 데이터에 대한 오류 제어를 위해 사용되며, 상향링크를 통해 전송되는 HARQ-ACK은 하향링크 데이터에 대한 오류 제어를 위해 사용된다. HARQ 동작을 수행하는 전송단은 데이 터(예, 수송 블록, 코드워드)를 전송한 후 긍정 확인(ACK; acknowledgement)를 기다린다. HARQ 동작을 수행하는 수신단은 데이터를 제대로 받은 경우만 긍정 확인(ACK)을 보내며, 수신 데이터에 오류가 생긴 경우 부정 확인 (negative ACK, NACK)을 보낸다. 전송단이 ACK을 수신한 경우에는 (새로운) 데이터를 전송할 수 있고, NACK을 수신한 경우에는 데이터를 재전송할 수 있다. 본 명세에서 채널 상태 정보(channel state information, CSI)는 UE와 안테나 포트 사이에 형성되는 무선 채널 (혹은 링크라고도 함)의 품질을 나타낼 수 있는 정보를 통칭한다. CSI는 채널 품질 지시자(channel quality indicator, CQI), 프리코딩 행렬 지시자 (precoding matrix indicator, PMI), CSI-RS 자원 지시자(CSI-RS resource indicator, CRI), SSB 자원 지시자(SSB resource indicator, SSBRI), 레이어 지시자(layer indicator, LI), 랭크 지시자(rank indicator, RI) 또는 참조 신호 수신 품질(reference signal received power, RSRP) 중 적어도 하나를 포함할 수 있다. 본 명세에서 주파수 분할 다중화(frequency division multiplexing, FDM)라 함은 신호/채널/사용자들을 서로 다른 주파수 자원에서 전송/수신하는 것을 의미할 수 있으며, 시간 분할 다중화(time division multiplexing, TDM)이라 함은 신호/채널/사용자들을 서로 다른 시간 자원에서 전송/수신하는 것을 의미할 수 있다. 본 명세에서 주파수 분할 듀플렉스(frequency division duplex, FDD)는 상향링크 반송파에서 상향링크 통신이 수행되고 상기 상향링크용 반송파에 링크된 하향링크용 반송파에서 하향링크 통신이 수행되는 통신 방식을 말하 며, 시간 분할 듀플렉스(time division duplex, TDD)라 함은 상향링크 통신과 하향링크 통신이 동일 반송파에서 시간을 나누어 수행되는 통신 방식을 말한다. 한편, 본 명세에서 반-듀플렉스란 통신 장치가 한 시점에 일 주파 수 상에서 상향링크 아니면 상향링크로만 동작하고, 다른 시점에는 다른 주파수 상에서 하향링크 아니면 상향링 크로 동작하는 것을 말한다. 예를 들어, 통신 장치가 반-듀플렉스로 동작하는 경우, 상향링크 주파수와 하향링 크 주파수를 사용하여 통신하되 상기 통신 장치는 상향링크 주파수와 하향링크 주파수를 동시에 사용하지 못하 며, 시간을 나눠서 일정 시간 동안에는 상향링크 주파수를 통해 상향링크 전송을 수행하고 다른 일정 시간 동안 에는 하향링크 주파수로 리튜닝하여 하향링크 수신을 수행한다. 도 1은 3GPP 기반 시스템에서 물리 신호/채널들의 매핑되는 자원 격자를 예시한 것이다. 도 1을 참고하면, 각 부반송파 간격 설정 및 반송파에 대해, 개 부반송파들 및 OFDM 심볼들의 자원 격자가 정의되며, 여기서 는 BS로부터의 RRC 시그널링에 의해 지시된다. μ는 부반송파 간격 △f = 2μ*15 [kHz]를 나타내며, 5G 시스템에서 μ∈{0, 1, 2, 3, 4}이다. 는 부반송파 간격 설정 μ뿐만 아니라 상향링크와 하향링크 간에도 달라질 수 있다. 부반송파 간격 설 정 μ, 안테나 포트 p 및 전송 방향(상향링크 또는 하향링크)에 대해 하나의 자원 격자가 있다. 부반송파 간격 설정 μ 및 안테나 포트 p에 대한 자원 격자의 각 요소는 자원 요소(resource element)로 지칭되고, 인덱스 쌍 (k,l)에 의해 고유하게(uniquely) 식별되며, 여기서 k는 주파수 도메인에서의 인덱스이고, l은 참조 포인트에 대해 상대적인 시간 도메인 내 심볼 위치를 지칭한다. 물리 채널들의 자원 요소들로의 매핑을 위해 사용되는 주 파수 단위인 자원 블록(resource block, RB)는 주파수 도메인에서 개의 연속적인(consecutive) 부반 송파들로 정의된다. 5G 시스템에서는, 상기 5G 시스템이 지원하는 넓은 대역폭을 UE가 한 번에 지원할 수 없을 수 있다는 점을 고려하여, UE가 셀의 주파수 대역폭 중 일부(이하, 대역폭 파트(bandwidth part, BWP))에서 동작하도록 설정될 수 있다."}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 명세에서 사용된 배경기술, 용어, 약어 등에 관해서는 본 발명 이전에 공개된 표준 문서에 기재된 사항을 참 조할 수 있다. 예를 들어, 다음 문서를 참조할 수 있다. 3GPP LTE - 3GPP TS 36.211: Physical channels and modulation - 3GPP TS 36.212: Multiplexing and channel coding - 3GPP TS 36.213: Physical layer procedures - 3GPP TS 36.214: Physical layer; Measurements - 3GPP TS 36.300: Overall description - 3GPP TS 36.304: User Equipment (UE) procedures in idle mode - 3GPP TS 36.314: Layer 2 - Measurements - 3GPP TS 36.321: Medium Access Control (MAC) protocol - 3GPP TS 36.322: Radio Link Control (RLC) protocol - 3GPP TS 36.323: Packet Data Convergence Protocol (PDCP) - 3GPP TS 36.331: Radio Resource Control (RRC) protocol - 3GPP TS 23.303: Proximity-based services (Prose); Stage 2 - 3GPP TS 23.285: Architecture enhancements for V2X services - 3GPP TS 23.401: General Packet Radio Service (GPRS) enhancements for Evolved Universal Terrestrial Radio Access Network (E-UTRAN) access - 3GPP TS 23.402: Architecture enhancements for non-3GPP accesses - 3GPP TS 23.286: Application layer support for V2X services; Functional architecture and information flows - 3GPP TS 24.301: Non-Access-Stratum (NAS) protocol for Evolved Packet System (EPS); Stage 3 - 3GPP TS 24.302: Access to the 3GPP Evolved Packet Core (EPC) via non-3GPP access networks; Stage 3 - 3GPP TS 24.334: Proximity-services (ProSe) User Equipment (UE) to ProSe function protocol aspects; Stage 3 - 3GPP TS 24.386: User Equipment (UE) to V2X control function; protocol aspects; Stage 3 3GPP NR (e.g. 5G) - 3GPP TS 38.211: Physical channels and modulation - 3GPP TS 38.212: Multiplexing and channel coding - 3GPP TS 38.213: Physical layer procedures for control - 3GPP TS 38.214: Physical layer procedures for data - 3GPP TS 38.215: Physical layer measurements - 3GPP TS 38.300: NR and NG-RAN Overall Description - 3GPP TS 38.304: User Equipment (UE) procedures in idle mode and in RRC inactive state - 3GPP TS 38.321: Medium Access Control (MAC) protocol - 3GPP TS 38.322: Radio Link Control (RLC) protocol - 3GPP TS 38.323: Packet Data Convergence Protocol (PDCP) - 3GPP TS 38.331: Radio Resource Control (RRC) protocol - 3GPP TS 37.324: Service Data Adaptation Protocol (SDAP) - 3GPP TS 37.340: Multi-connectivity; Overall description - 3GPP TS 23.287: Application layer support for V2X services; Functional architecture and information flows - 3GPP TS 23.501: System Architecture for the 5G System - 3GPP TS 23.502: Procedures for the 5G System - 3GPP TS 23.503: Policy and Charging Control Framework for the 5G System; Stage 2 - 3GPP TS 24.501: Non-Access-Stratum (NAS) protocol for 5G System (5GS); Stage 3 - 3GPP TS 24.502: Access to the 3GPP 5G Core Network (5GCN) via non-3GPP access networks - 3GPP TS 24.526: User Equipment (UE) policies for 5G System (5GS); Stage 3 도 2는 3GPP 신호 전송/수신 방법의 일례를 나타낸 도이다. 도 2를 참고하면, UE는 전원이 켜지거나 새로이 셀에 진입한 경우 BS와 동기를 맞추는 등의 초기 셀 탐색 (initial cell search) 작업을 수행한다(S201). 이를 위해, UE는 BS로부터 1차 동기 채널(primary synchronization channel, P-SCH) 및 2차 동기 채널(secondary synchronization channel, S-SCH)을 수신하여 BS와 동기를 맞추고, 셀 ID 등의 정보를 획득할 수 있다. LTE 시스템과 NR 시스템에서 P-SCH와 S-SCH는 각각 1 차 동기 신호(primary synchronization signal, PSS)와 2차 동기 신호(secondary synchronization signal, SSS)로 불린다. 상기 초기 셀 탐색 절차는 이하에서 더 상세히 설명된다. 초기 셀 탐색 후, UE는 BS로부터 물리 브로드캐스트 채널(physical broadcast channel, PBCH)를 수신하여 셀 내 브로드캐스트 정보를 획득할 수 있다. 한편, UE는 초기 셀 탐색 단계에서 하향링크 참조 신호(downlink reference Signal, DL RS)를 수신하여 하향링크 채널 상태를 확인할 수 있다. 초기 셀 탐색을 마친 UE는 PDCCH 및 상기 PDCCH에 실린 정보에 따라 PDSCH를 수신함으로써 좀더 구체적인 시스 템 정보를 획득할 수 있다(S202). 한편, BS에 최초로 접속하거나 신호 전송을 위한 무선 자원이 없는 경우 UE는 BS에 대해 임의 접속 과정(random access procedure)을 수행할 수 있다(단계 S203 내지 단계 S206). 이를 위해, UE는 PRACH를 통해 특정 시퀀스 를 프리앰블로서 전송하고(S203 및 S205), PDCCH 및 대응하는 PDSCH를 통해 프리앰블에 대한 임의 접속 응답 (random access response, RAR) 메시지를 수신할 수 있다(S204 및 S206). 경쟁 기반 임의 접속 과정의 경우, 추가적으로 충돌 해결 과정(contention resolution procedure)를 수행할 수 있다. 상기 임의 접속 과정은 이하 에서 더 상세히 설명된다. 상술한 바와 같은 과정을 수행한 UE는 이후 일반적인 상향링크/하향링크 신호 전송 과정으로서 PDCCH/PDSCH 수 신(S207) 및 PUSCH/PUCCH 전송(S208)을 수행할 수 있다. 특히 UE는 PDCCH를 통하여 DCI를 수신한다. UE는 해당 탐색 공간 설정(configuration)들에 따라 서빙 셀 상의 하나 이상의 제어 요소 세트(control element set, CORESET)들에 설정된 모니터링 기회(occasion)들에서 PDCCH 후보(candidate)들의 세트를 모니터 링한다. UE가 모니터할 PDCCH 후보들의 세트는 탐색 공간 세트들의 관점에서 정의되며, 탐색 공간 세트는 공통 탐색 공간 세트 또는 UE-특정 탐색 공간 세트일 수 있다. CORESET은 1~3개 OFDM 심볼들의 시간 지속기간을 갖는 (물리) 자원 블록들의 세트로 구성된다. 네트워크는 UE가 복수의 CORESET들을 갖도록 설정할 수 있다. UE는 하 나 이상의 탐색 공간 세트들 내 PDCCH 후보들을 모니터링한다. 여기서 모니터링이라 함은 탐색 공간 내 PDCCH 후보(들)에 대한 디코딩을 시도하는 것을 의미한다. UE가 탐색 공간 내 PDCCH 후보들 중 하나에 대한 디코딩에 성공하면, 상기 UE는 해당 PDCCH 후보에서 PDCCH를 검출했다고 판단하고, 상기 검출된 PDCCH 내 DCI를 기반으로 PDSCH 수신 혹은 PUSCH 전송을 수행한다. PDCCH는 PDSCH 상의 DL 전송들 및 PUSCH 상의 UL 전송들을 스케줄링하는 데 사용될 수 있다. 여기서 PDCCH 상의 DCI는 하향링크 공유 채널과 관련된, 변조(modulation) 및 코딩 포맷과 자원 할당(resource allocation) 정보 를 적어도 포함하는 하향링크 배정(assignment)(즉, DL 그랜트), 또는 상향링크 공유 채널과 관련된, 변조 및 코딩 포맷과 자원 할당 정보를 포함하는 상향링크 그랜트(UL grant)를 포함한다. 초기 접속 (Initial Access, IA) 과정 SSB(Synchronization Signal Block) 전송 및 관련 동작 도 3은 SSB 구조를 예시한다. UE는 SSB에 기반하여 셀 탐색(search), 시스템 정보 획득, 초기 접속을 위한 빔 정렬, DL 측정 등을 수행할 수 있다. SSB라는 용어는 SS/PBCH(Synchronization Signal/Physical Broadcast channel) 블록이라는 용어와 혼용된다. 도 3을 참조하면, SSB는 PSS, SSS와 PBCH로 구성된다. SSB는 4개의 연속된 OFDM 심볼들에 구성되며, OFDM 심볼 별로 PSS, PBCH, SSS/PBCH 또는 PBCH가 전송된다. PBCH는 폴라(Polar) 코드를 기반으로 인코딩/디코딩되고, QPSK(Quadrature Phase Shift Keying)에 따라 변조(modulation)/복조(demodulation)된다. OFDM 심볼 내 PBCH는 PBCH의 복소 변조 값이 매핑되는 데이터 자원 요소(resource element, RE)들과 상기 PBCH를 위한 복조 참조 신 호(demodulation reference signal, DMRS)가 매핑되는 DMRS RE들로 구성된다. OFDM 심볼의 자원 블록별로 3개 의 DMRS RE가 존재하며, DMRS RE 사이에는 3개의 데이터 RE가 존재한다. 셀 탐색(search) 셀 탐색은 UE가 셀의 시간/주파수 동기를 획득하고, 상기 셀의 셀 ID(Identifier)(예, Physical layer Cell ID, PCI)를 검출하는 과정을 의미한다. PSS는 셀 ID 그룹 내에서 셀 ID를 검출하는데 사용되고, SSS는 셀 ID 그 룹을 검출하는데 사용된다. PBCH는 SSB (시간) 인덱스 검출 및 하프-프레임 검출에 사용된다. 5G 시스템에서는 336개의 셀 ID 그룹이 존재하고, 셀 ID 그룹 별로 3개의 셀 ID가 존재한다. 총 1008개의 셀 ID 가 존재한다. 셀의 셀 ID가 속한 셀 ID 그룹에 관한 정보는 상기 셀의 SSS를 통해 제공/획득되며, 상기 셀 ID 내 336개 셀들 중 상기 셀 ID에 관한 정보는 PSS를 통해 제공/획득된다 SSB는 SSB 주기(periodicity)에 맞춰 주기적으로 전송된다. 초기 셀 탐색 시에 UE가 가정하는 SSB 기본 주기는 20ms로 정의된다. 셀 접속 후, SSB 주기는 네트워크(예, BS)에 의해 {5ms, 10ms, 20ms, 40ms, 80ms, 160ms} 중 하나로 설정될 수 있다. SSB 주기의 시작 부분에 SSB 버스트(burst) 세트가 구성된다. SSB 버스트 세트는 5ms 시간 윈도우(즉, 하프-프레임)로 구성되며, SSB는 SS 버스트 세트 내에서 최대 L번 전송될 수 있다. SSB의 최대 전송 횟수 L은 반송파의 주파수 대역에 따라 다음과 같이 주어질 수 있다. - For frequency range up to 3 GHz, L = 4 - For frequency range from 3GHz to 6 GHz, L = 8 - For frequency range from 6 GHz to 52.6 GHz, L = 64 하프-프레임 내 SSB들의 가능한(possible) 시간 위치들은 부반송파 간격에 의해 결정되고, SSB들이 전송되는 하 프-프레임들의 주기(periodicity)는 네트워크에 의해 설정된다. SSB 후보의 시간 위치는 SSB 버스트 세트(즉, 하프-프레임) 내에서 시간 순서에 따라 0 ~ L-1로 인덱싱된다(SSB 인덱스). 하프-프레임 동안, 다른 SSB들이 (셀의 커버리지 영역을 스팬하는, 다른 빔들을 사용하여) 다른 공간(spatial) 방향들로 전송될 수 있다. 따라서, 5G 시스템에서 SSBI는 BS Tx 빔 방향과 연관될 수 있다. UE는 SSB를 검출함으로써 DL 동기를 획득할 수 있다. UE는 검출된 SSB (시간) 인덱스(SSB index, SSBI)에 기반 하여 SSB 버스트 세트의 구조를 식별할 수 있고, 이에 따라 심볼/슬롯/하프-프레임 경계를 검출할 수 있다. 검 출된 SSB가 속하는 프레임/하프-프레임의 번호는 시스템 프레임 번호(system frame number, SFN) 정보와 하프- 프레임 지시 정보를 이용하여 식별될 수 있다. 구체적으로, UE는 PBCH로부터 상기 PBCH가 속한 프레임에 대한 10 비트의 SFN을 획득할 수 있다. 다음으로, UE 는 1 비트의 하프-프레임 지시 정보를 획득할 수 있다. 예를 들어, UE가 하프-프레임 지시 비트가 0으로 세팅된 PBCH를 검출한 경우에는 상기 PBCH가 속한 SSB가 프레임 내 첫 번째 하프-프레임에 속한다고 판단할 수 있고, 하프-프레임 지시 비트가 1로 세팅된 PBCH를 검출한 경우에는 상기 PBCH가 속한 SSB가 프레임 내 두 번째 하프- 프레임에 속한다고 판단할 수 있다. 마지막으로, UE는 DMRS 시퀀스와 PBCH가 나르는 PBCH 페이로드에 기반하여 상기 PBCH가 속한 SSB의 SSBI를 획득할 수 있다.시스템 정보 (system information; SI) 획득 SI는 마스터 정보 블록(master information block, MIB)와 복수의 시스템 정보 블록(system information block, SIB)들로 나눠진다. MIB 외의 SI는 RMSI(Remaining Minimum System Information)으로 지칭될 수 있다. 자세한 사항은 다음을 참조할 수 있다. - MIB는 SIB1(SystemInformationBlock1)을 나르는 PDSCH를 스케줄링하는 PDCCH의 모니터링을 위한 정보/파라미 터를 포함하며 SSB의 PBCH를 통해 BS에 의해 전송된다. 예를 들어, UE는 MIB에 기반하여 Type0-PDCCH 공통 탐색 공간(common search space)을 위한 CORESET(Control Resource Set)이 존재하는지 확인할 수 있다. Type0-PDCCH 공통 탐색 공간은 PDCCH 탐색 공간의 일종이며, SI 메시지를 스케줄링하는 PDCCH를 전송하는 데 사용된다. Type0-PDCCH 공통 탐색 공간이 존재하는 경우, UE는 MIB 내의 정보(예, pdcch-ConfigSIB1)에 기반하여 (i) CORESET을 구성하는 복수의 인접(contiguous) 자원 블록들 및 하나 이상의 연속된(consecutive) 심볼들과 (ii) PDCCH 기회(occasion)(예, PDCCH 수신을 위한 시간 도메인 위치)를 결정할 수 있다. - SIB1은 나머지 SIB들(이하, SIBx, x는 2 이상의 정수)의 가용성(availability) 및 스케줄링(예, 전송 주기, SI-윈도우 크기)과 관련된 정보를 포함한다. 예를 들어, SIB1은 SIBx가 주기적으로 브로드캐스트되는지 on- demand 방식에 의해 UE의 요청에 의해 제공되는지 여부를 알려줄 수 있다. SIBx가 on-demand 방식에 의해 제공 되는 경우, SIB1은 UE가 SI 요청을 수행하는 데 필요한 정보를 포함할 수 있다. SIB1을 스케줄링 하는 PDCCH는 Type0-PDCCH 공통 탐색 공간을 통해 전송되며, SIB1은 상기 PDCCH에 의해 지시되는 PDSCH를 통해 전송된다. - SIBx는 SI 메시지에 포함되며 PDSCH를 통해 전송된다. 각각의 SI 메시지는 주기적으로 발생하는 시간 윈도우 (즉, SI-윈도우) 내에서 전송된다. 임의 접속(Random Access) 과정 임의 접속 과정은 다양한 용도로 사용된다. 예를 들어, 임의 접속 과정은 네트워크 초기 접속, 핸드오버, UE-트 리거드(triggered) UL 데이터 전송에 사용될 수 있다. UE는 임의 접속 과정을 통해 UL 동기와 UL 전송 자원을 획득할 수 있다. 임의 접속 과정은 경쟁 기반(contention-based) 임의 접속 과정과 경쟁 프리(contention free) 임의 접속 과정으로 구분된다. 도 4는 임의 접속 과정의 일례를 예시한다. 특히 도 4는 경쟁 기반 임의 접속 과정을 예시한다. 먼저, UE가 UL에서 임의 접속 과정의 Msg1로서 임의 접속 프리앰블을 PRACH를 통해 전송할 수 있다. 본 명세에 서 임의 접속 과정과 임의 접속 프리앰블은 각각(respectively) RACH 과정과 RACH 프리앰블로도 칭해진다. 다수의 프리앰블 포맷들이 하나 또는 그 이상의 RACH OFDM 심볼들 및 서로 다른 순환 프리픽스(cyclic prefix, CP) (및/또는 가드 시간(guard time))에 의해 정의된다. 셀을 위한 RACH 설정(configuration)이 상기 셀의 시 스템 정보에 포함되어 UE에게 제공된다. 상기 RACH 설정은 PRACH의 부반송파 간격, 이용 가능한 프리앰블들, 프 리앰블 포맷 등에 관한 정보를 포함한다. 상기 RACH 설정은 SSB들과 RACH (시간-주파수) 자원들 간의 연관 정보, 즉, SSB 인덱스(SSB index, SSBI)들과 RACH (시간-주파수) 자원들 간의 연관 정보를 포함한다. SSBI들은 BS의 Tx 빔들과 각각(respectively) 연관된다. UE는 검출한 혹은 선택한 SSB와 연관된 RACH 시간-주파수 자원에 서 RACH 프리앰블을 전송한다. BS는 RACH 프리앰블이 검출된 시간-주파수 자원을 기반으로 해당 UE가 선호하는 BS Tx 빔을 알 수 있다. RACH 자원 연관을 위한 SSB의 임계값이 네트워크에 의해 설정될 수 있으며, SSB 기반으로 측정된 RSRP가 상기 임계값을 충족하는 SSB를 기반으로 RACH 프리앰블의 전송(즉, PRACH 전송) 또는 재전송이 수행된다. 예를 들어, UE는 임계값을 충족하는 SSB(들) 중 하나를 선택하고, 선택된 SSB에 연관된 RACH 자원을 기반으로 RACH 프리앰 블을 전송 또는 재전송할 수 있다. BS가 UE로부터 RACH 프리앰블을 수신하면, BS는 RAR 메시지(Msg2)를 상기 UE에게 전송한다. RAR을 나르는 PDSCH 를 스케줄링하는 PDCCH는 임의 접속(random access, RA) 무선 네트워크 임시 식별자(radio network temporary identifier, RNTI)(RA-RNTI)로 CRC 마스킹되어 전송된다. RA-RNTI로 마스킹된 PDCCH를 검출한 UE는 상기 PDCCH 가 나르는 DCI가 스케줄링하는 PDSCH로부터 RAR을 수신할 수 있다. UE는 자신이 전송한 프리앰블, 즉, Msg1에 대한 RAR 정보가 상기 RAR 내에 있는지 확인한다. 자신이 전송한 Msg1에 대한 임의 접속 정보가 존재하는지 여 부는 상기 UE가 전송한 프리앰블에 대한 RACH 프리앰블 ID가 존재하는지 여부에 의해 판단될 수 있다. Msg1에 대한 응답이 없으면, UE는 전력 램핑(power ramping)을 수행하면서 RACH 프리앰블을 소정의 횟수 이내에서 재전 송할 수 있다. UE는 가장 최근의 경로 손실 및 전력 램핑 카운터를 기반으로 프리앰블의 재전송에 대한 PRACH전송 전력을 계산한다. UE가 PDSCH 상에서 자신에 대한 RAR 정보를 수신하면, 상기 UE는 UL 동기화를 위한 타이밍 어드밴스(timing advance) 정보, 초기 UL 그랜트, UE 임시(temporary) 셀 RNTI(cell RNTI, C-RNTI)를 알 수 있다. 상기 타이밍 어드밴스 정보는 상향링크 신호 전송 타이밍을 제어하는 데 사용된다. UE에 의한 PUSCH/PUCCH 전송이 네트워크 단에서 서브프레임 타이밍과 더 잘 정렬(align)되도록 하기 위해, 네트워크(예, BS)는 PUSCH/PUCCH/SRS 수신 및 서브프레임 간 시간 차이를 측정하고 이를 기반으로 타이밍 어드밴스 정보를 보낼 수 있다. 상기 UE는 RAR 정보 를 기반으로 PUSCH 상에서 UL 전송을 RACH 과정의 Msg3로서 전송할 수 있다. Msg3은 RRC 연결 요청 및 UE 식별 자를 포함할 수 있다. Msg3에 대한 응답으로서, 네트워크는 Msg4를 전송할 수 있으며, 이는 DL 상에서의 경쟁 해결 메시지로 취급될 수 있다. Msg4를 수신함으로써, UE는 RRC 연결된 상태에 진입할 수 있다. 한편, 경쟁-프리 RACH 과정은 UE가 다른 셀 혹은 BS로 핸드오버 하는 과정에서 사용되거나, BS의 명령에 의해 요청되는 경우에 수행될 수 있다. 경쟁-프리 RACH 과정의 기본적인 과정은 경쟁 기반 RACH 과정과 유사하다. 다 만, UE가 복수의 RACH 프리앰블들 중 사용할 프리앰블을 임의로 선택하는 경쟁 기반 RACH 과정과 달리, 경쟁-프 리 RACH 과정의 경우에는 UE가 사용할 프리앰블(이하 전용 RACH 프리앰블)이 BS에 의해 상기 UE에게 할당된다. 전용 RACH 프리앰블에 대한 정보는 RRC 메시지(예, 핸드오버 명령)에 포함되거나 PDCCH 오더(order)를 통해 UE 에게 제공될 수 있다. RACH 과정이 개시되면 UE는 전용 RACH 프리앰블을 BS에게 전송한다. 상기 UE가 상기 BS로 부터 RACH 과정을 수신하면 상기 RACH 과정은 완료(complete)된다. DL 및 UL 전송/수신 동작 DL 전송/수신 동작 하향링크 그랜트(downlink grant)( (assignment)이라고도 함)는 동적 그랜트(dynamic)와 설정된 그랜 트(configured grant)로 구분될 수 있다. 동적 그랜트(dynamic grant)는 자원의 활용을 최대화하기 위한 것으로 BS에 의한 동적 스케줄링 기반의 데이터 전송/수신 방법을 의미한다. BS는 DCI를 통해 하향링크 전송을 스케줄링한다. UE는 BS로부터 하향링크 스케줄링을 위한(즉, PDSCH의 스케줄 링 정보를 포함하는) DCI(이하, DL 그랜트 DCI)를 PDCCH 상에서 수신한다. 하향링크 스케줄링을 위한 DCI에는, 예를 들어, 다음과 같은 정보가 포함될 수 있다: 대역폭 파트 지시자(bandwidth part indicator), 주파수 도메 인 자원 배정(frequency domain resource assignment), 시간 도메인 자원 배정(time domain resource assignment), 변조 및 코딩 방식(modulation and coding scheme, MCS). UE는 DCI 내 MCS 필드를 기반으로 PDSCH에 대한 변조 차수(modulation order), 목표 코드 레이트(target code rate), 수송 블록 크기(transport block size, TBS)를 결정할 수 있다. UE는 주파수 도메인 자원 할당 정보 및 시간 도메인 자원 할당 정보에 따른 시간-주파수 자원에서 PDSCH를 수신할 수 있다. DL 설정된 그랜트는 준-지속적 스케줄링(semi-persistent scheduling, SPS)라고도 한다. UE는 BS로부터 DL 데 이터의 전송을 위한 자원 설정(resource configuration)을 포함하는 RRC 메시지를 수신할 수 있다. DL SPS의 경우에는 실제 DL 설정된 그랜트가 PDCCH에 의해 제공되며 상기 PDCCH에 의해 활성화 혹은 활성해제 (deactivate)된다. DL SPS가 설정되는 경우, BS로부터의 RRC 시그널링을 통해 적어도 다음 파라미터들이 UE에게 제공된다: 활성화, 활성해제 및 재전송을 위한 설정된 스케줄링 RNTI(configured scheduling RNTI, CS-RNTI); 및 주기. DL SPS의 실제 DL 그랜트(예, 주파수 자원 할당)는 CS-RNTI에 어드레스된 PDCCH 내 DCI에 의해 UE에게 제공된다. UE는 CS-RNTI에 어드레스된 PDCCH 내 DCI의 특정 필드들이 스케줄링 활성화를 위한 특정 값으로 세팅 되어 있으면, 상기 CS-RNTI와 연관된 SPS를 활성화한다. 상기 CS-RNTI에 어드레스된 PDCCH 내 DCI는 실제 주파 수 자원 할당 정보, MCS 인덱스 값 등을 포함한다. UE는 SPS를 기반으로 PDSCH를 통한 하향링크 데이터를 수신 할 수 있다. UL 전송/수신 동작 상향링크 그랜트(uplink grant)는 PUSCH는 UL 그랜트 DCI에 의해 동적으로 PUSCH를 스케줄링하는 동적 그랜 트(dynamic grant)와 RRC 시그널링에 의해 준-정적으로(semi-statically) PUSCH를 스케줄링하는 설정된 그 랜트(configured grant)로 구분될 수 있다. 도 5는 상향링크 그랜트에 따른 UL 전송의 일례를 나타낸다. 특히, 도 5 (a)는 동적 그랜트를 기반으로 한 UL 전송 과정을 예시하고, 도 5 (b)는 설정된 그랜트를 기반으로 한 UL 전송 과정을 예시한다. UL 동적 그랜트(dynamic grant)의 경우, BS는 상향링크 스케줄링 정보를 포함하는 DCI를 UE에게 전송한다. 상기 UE는 BS로부터 상향링크 스케줄링을 위한(즉, PUSCH의 스케줄링 정보를 포함하는) DCI(이하, UL 그랜트 DCI)를 PDCCH 상에서 수신한다. 상향링크 스케줄링을 위한 DCI에는, 예를 들어, 다음과 같은 정보가 포함될 수 있다: 대역폭 파트 지시자(Bandwidth part indicator), 주파수 도메인 자원 배정(frequency domain resource assignment), 시간 도메인 자원 배정(time domain resource assignment), MCS. BS에 의한 상향링크 무선 자원 의 효율적인 할당을 위해서, UE는 자신이 전송하고자 하는 상향링크 데이터에 관한 정보를 BS으로 전달하고, 상 기 BS는 이에 기반하여 상기 UE에게 상향링크 자원을 할당할 수 있다. 이 경우, UE가 BS로 전달하는 상향링크 데이터에 정보를 버퍼 상태 보고(buffer status report, BSR)라고 하며, BSR은 UE 자신의 버퍼에 저장되어 있는 상향링크 데이터의 양과 관련이 있다. 도 5 (a)를 참고하면, UE가 BSR의 전송에 이용 가능한 상향링크 무선 자원을 가지고 있지 않을 때, UL 전송 과 정을 예시한다. UL 데이터 전송에 이용 가능한 UL 그랜트가 없는 UE는 PUSCH를 통해 BSR을 전송할 수도 없으므 로, PUCCH를 통한 스케줄링 요청 전송을 시작으로 상향링크 데이터를 위한 자원을 요청해야 하며, 이 경우 5단 계의 상향링크 자원 할당 과정이 사용된다. 도 5 (a)를 참고하면, BSR를 전송하기 위한 PUSCH 자원이 없는 경우, UE는 PUSCH 자원을 할당받기 위해 먼저 스 케줄링 요청(scheduling request, SR)을 BS에 전송한다. SR은 버퍼 상태 보고 이벤트(reporting event)가 발생 되었으나 UE에게 이용 가능한 PUSCH 자원이 없는 경우, UE가 상향링크 전송을 위한 PUSCH 자원을 BS에게 요청하 기 위해 이용된다. SR을 위한 유효한(valid) PUCCH 자원이 있으면 UE는 PUCCH를 통해 SR을 전송하고, 유효한 PUCCH 자원이 없으면 전술한 (경쟁 기반) RACH 과정을 개시한다. UE가 BS로부터 UL 그랜트 DCI를 통해 UL 그랜 트를 수신하면, 상기 UL 그랜트에 의해 할당된 PUSCH 자원을 통해 BSR을 BS로 전송한다. BS는 BSR을 기반으로 UE가 상향링크로 전송할 데이터의 양을 확인하고 UL 그랜트 DCI를 통해 UL 그랜트를 UE에 전송한다. 상기 UL 그 랜트 DCI를 포함하는 PDCCH를 검출한 UE는 상기 UL 그랜트 DCI 내 UL 그랜트를 기반으로 PUSCH를 통해 실제 상 향링크 데이터를 BS로 전송한다. 설정된 그랜트의 경우, 도 5 (b)를 참고하면, UE는 BS로부터 UL 데이터의 전송을 위한 자원 설정(resource configuration)을 포함하는 RRC 메시지를 수신한다. NR 시스템에서는 2가지 타입의 UL 설정된 그랜트가 있다: 타입 1 및 타입 2. UL 설정된 그랜트 타입 1의 경우에는 실제 UL 그랜트(예, 시간 자원, 주파수 자원)가 RRC 시 그널링에 의해 제공되며, UL 설정된 그랜트 타입 2의 경우에는 실제 UL 그랜트가 PDCCH에 의해 제공되며 상기 PDCCH에 의해 활성화 혹은 활성해제(deactivate)된다. 설정된 그랜트 타입 1이 설정되는 경우, BS로부터의 RRC 시그널링을 통해 적어도 다음 파라미터들이 UE에게 제공된다: 재전송을 위한 CS-RNTI; 설정된 그랜트 타입 1의 주기(periodicity); 슬롯 내 PUSCH를 위한 시작 심볼 인덱스 S 및 심볼 개수 L에 관한 정보; 시간 도메인에서 SFN=0에 대한 자원의 오프셋을 나타내는 시간 도메인 오프셋; 변조 차수, 타겟 코드 레이트 및 수송 블록 크기 를 나타내는 MCS 인덱스. 설정된 그랜트 타입 2가 설정되는 경우, BS로부터의 RRC 시그널링을 통해 적어도 다음 파라미터들이 UE에게 제공된다: 활성화, 활성해제 및 재전송을 위한 CS-RNTI; 설정된 그랜트 타입 2의 주기. 설 정된 그랜트 타입 2의 실제 UL 그랜트는 CS-RNTI에 어드레스된 PDCCH 내 DCI에 의해 UE에게 제공된다. UE는 CS- RNTI에 어드레스된 PDCCH 내 DCI의 특정 필드들이 스케줄링 활성화를 위한 특정 값으로 세팅되어 있으면, 상기 CS-RNTI와 연관된 설정된 그랜트 타입 2를 활성화한다. 스케줄링 활성화를 위한 특정 값으로 세팅된 PDCCH 내 DCI는 실제 자원 할당 정보, MCS 인덱스 값 등을 포함한다. UE는 타입 1 혹은 타입 2에 따른 설정된 그랜트을 기반으로 PUSCH를 통한 상향링크 전송을 수행할 수 있다. 도 6은 물리 채널 프로세싱(physical channel processing)의 개념도의 일례를 나타낸다. 도 6에 도시된 블록들 각각은 전송 장치의 물리 계층 블록 내 각 모듈에서 수행될 수 있다. 보다 구체적으로, 도 6에서의 신호 처리는 본 명세에서 기재하는 UE의 프로세서에서 UL 전송을 위해 수행될 수 있다. 도 6에서 트 랜스폼 프리코딩을 제외하는 한편 SC-FDMA 신호 생성 대신 CP-OFDM 신호 생성을 포함하는 신호 처리는 본 명세 서에서 기재하는 BS의 프로세서에서 DL 전송을 위해 수행될 수 있다. 도 H5를 참조하면, 상향링크 물리 채널 프 로세싱은 스크램블링(scrambling), 변조 매핑(modulation mapping), 레이어 매핑(layer mapping), 트랜스폼 프 리코딩(transform precoding), 프리코딩(precoding), 자원 요소 매핑(resource element mapping), SC-FDMA 신 호 생성 (SC-FDMA signal generation)의 과정을 거쳐 수행될 수 있다. 위의 각 과정은 전송 장치의 각 모듈에서 별도로 또는 함께 수행될 수 있다. 상기 트랜스폼 프리코딩은 파형(waveform)의 피크-to-평균 전력 비율(peak- to-average power ratio, PAPR)을 감소시키는 특별한 방식으로 UL 데이터를 스프레드하는 것이며, 이산 푸리에변환(discrete Fourier transform, DFT)의 일종이다. DFT 스프레딩을 수행하는 트랜스폼 프리코딩과 함께 CP를 사용하는 OFDM을 DFT-s-OFDM이라 하고, DFT 스프레딩없이 CP를 사용하는 OFDM을 CP-OFDM이라 한다. DFT-s-OFDM 에 의해 SC-FDMA 신호가 생성된다. NR 시스템에서 UL에 대해 가능화(enable)되면 트랜스폼 프리코딩이 선택적으 로(optionally) 적용될 수 있다. 즉, NR 시스템은 UL 파형을 위해 2가지 옵션을 지원하며, 그 중 하나는 CP- OFDM이고, 다른 하나는 DFT-s-OFDM이다. UE가 CP-OFDM을 UL 전송 파형으로 사용해야 하는지 아니면 DFT-s-OFDM 을 UL 전송 파형으로 사용해야 하는지는 RRC 파라미터들을 통해 BS로부터 UE에게 제공된다. 도 H5는 DFT-s-OFDM 을 위한 상향링크 물리 채널 프로세싱 개념도이며, CP-OFDM의 경우에는 도 H5의 프로세스들 중 트랜스폼 프리코 딩이 생략된다. DL 전송, CP-OFDM이 DL 파형 전송을 위해 사용된다. 위의 각 과정에 대해 보다 구체적으로 살펴보면, 전송 장치는 하나의 코드워드에 대해, 코드워드 내 부호화된 비트(coded bits)를 스크램블링 모듈에 의해 스크램블링한 후 물리 채널을 통해 전송할 수 있다. 여기서 코드워 드는 수송 블록을 인코딩하여 얻어진다. 스크램블된 비트는 변조 매핑 모듈에 의해 복소 값 변조 심볼로 변조된 다. 상기 변조 매핑 모듈은 상기 스크램블된 비트들을 기결정된 변조 방식에 따라 변조하여 신호 성상(signal constellation) 상의 위치를 표현하는 복소 값 변조 심볼로 배치할 수 있다. pi/2-BPSK(pi/2-Binary Phase Shift Keying), m-PSK(m-Phase Shift Keying) 또는 m-QAM(m-Quadrature Amplitude Modulation) 등이 상기 부 호화된 데이터의 변조에 이용될 수 있다. 상기 복소 값 변조 심볼은 레이어 매핑 모듈에 의해 하나 이상의 전송 레이어로 맵핑될 수 있다. 각 레이어 상의 복소 값 변조 심볼은 안테나 포트 상에서의 전송을 위해 프리코딩 모 듈에 의해 프리코딩될 수 있다. UL 전송을 위해 트랜스폼 프리코딩이 가능화된 경우, 프리코딩 모듈은 도 H5에 도시된 바와 같이 복소 값 변조 심볼들에 대한 트랜스폼 프리코딩(transform precoding)을 수행한 이후에 프리 코딩을 수행할 수 있다. 상기 프리코딩 모듈은 상기 복소 값 변조 심볼들을 다중 전송 안테나에 따른 MIMO 방식 으로 처리하여 안테나 특정 심볼들을 출력하고, 상기 안테나 특정 심볼들을 해당 자원 요소 매핑 모듈로 분배할 수 있다. 프리코딩 모듈의 출력 z는 레이어 매핑 모듈의 출력 y를 N×M의 프리코딩 행렬 W와 곱해 얻을 수 있다. 여기서, N은 안테나 포트의 개수, M은 레이어의 개수이다. 자원 요소 매핑 모듈은 각 안테나 포트에 대한 복조 값 변조 심볼들을 전송을 위해 할당된 자원 블록 내에 있는 적절한 자원 요소에 맵핑한다. 자원 요소 매핑 모듈은 복소 값 변조 심볼들을 적절한 부반송파들에 매핑하고, 사용자에 따라 다중화할 수 있다. SC-FDMA 신호 생성 모듈(DL 전송의 경우 혹은 UL 전송을 위해 트랜스폼 프리코딩이 불능화(disable)된 경우에는 CP-OFDM 신호 생성 모듈)은 복소 값 변조 심볼을 특정 변조 방식 예컨대, OFDM 방식으로 변조하여 복소 값 시간 도메인 (complex-valued time domain) OFDM 심볼 신호를 생성할 수 있다. 상기 신호 생성 모듈은 안테나 특정 심볼에 대해 IFFT(Inverse Fast Fourier Transform)를 수행할 수 있으며, IFFT가 수행된 시간 도메인 심볼에는 CP가 삽입될 수 있다. OFDM 심볼은 디지털-아날로그(digital-to-analog) 변환, 주파수 상향변환(upconversion) 등을 거쳐, 각 전송 안테나를 통해 수신 장치로 전송된다. 상기 신호 생성 모듈은 IFFT 모듈 및 CP 삽입기, DAC(Digital-to-Analog Converter), 주파수 상향 변환기(frequency uplink converter) 등을 포함할 수 있다. 수신 장치의 신호 처리 과정은 전송 장치의 신호 처리 과정의 역으로 구성될 수 있다. 구체적인 사항은 위의 내 용과 도 6을 참고하기로 한다. 다음으로, PUCCH에 대해 살펴본다. PUCCH는 UCI의 전송에 사용된다. UCI에는 상향링크 전송 자원을 요청하는 스케줄링 요청(scheduling request, SR), DL RS를 기반으로 UE 측정된 하향링크 채널 상태를 나타내는 채널 상태 정보(channel state information, CSI), 및/또는 하향링크 데이터가 UE에 의해 성공적으로 수신되었는지 여부를 나타내는 HARQ-ACK가 있다. PUCCH는 다수의 포맷(format)들을 지원하며, PUCCH 포맷들은 심볼 지속기간(symbol duration), 페이로드 크기 (payload size), 그리고 다중화(multiplexing) 여부 등에 의해 분류될 수 있다. 아래 표 1은 PUCCH 포맷들을 예시한 것이다.표 1"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "PUCCH 자원들은 BS에 의해 RRC 시그널링을 통해 UE에게 설정된다. PUCCH 자원을 할당하는 일 예로, BS는 UE에게 복수의 PUCCH 자원 세트를 설정하고, UE는 UCI (페이로드) 크기(예, UCI 비트 수)의 범위에 따라 특정 범위에 대응되는 특정 PUCCH 자원 세트를 선택할 수 있다. 예를 들어, UE는 UCI 비트 수 에 따라 다음 중 하나의 PUCCH 자원 세트를 선택할 수 있다. - PUCCH 자원 세트 #0, if UCI 비트 수 ≤ 2 - PUCCH 자원 세트 #1, if 2< UCI 비트 수 ≤ ... - PUCCH 자원 세트 #(K-1), if NK-2 < UCI 비트 수 ≤"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, K는 PUCCH 자원 세트를 개수를 나타내고(K>1), Ni는 PUCCH 자원 세트 #i가 지원하는 최대 UCI 비트 수 이다. 예를 들어, PUCCH 자원 세트 #1은 PUCCH 포맷 0~1의 자원으로 구성될 수 있고, 그 외의 PUCCH 자원 세트 는 PUCCH 포맷 2~4의 자원으로 구성될 수 있다. 이후, BS는 UE에게 PDCCH를 통해 DCI를 전송하며, DCI 내의 ARI(ACK/NACK Resource Indicator)를 통해 특정 PUCCH 자원 세트 내 PUCCH 자원들 중에서 UCI 전송에 사용할 PUCCH 자원을 지시할 수 있다. ARI는 HARQ-ACK 전 송을 위한 PUCCH 자원을 지시하는 데 사용되며, PRI(PUCCH Resource Indicator)로 지칭될 수도 있다. eMBB (enhanced Mobile Broadband communication) NR 시스템의 경우, 전송/수신 안테나가 크게 증가하는 거대(massive) 다중 입력 다중 출력(multiple input multiple output, MIMO) 환경이 고려되고 있다. 한편, 6GHz 이상의 대역을 사용하는 NR 시스템은 급격한 전파 감쇄 특성을 보상하기 위해 신호 전송을 전방향이 아닌 특정 방향으로 에너지를 모아서 전송하는 빔포밍 기법이 고려된다. 이에 따라, 하드웨어 구현의 복잡도를 줄이고, 다수의 안테나들을 이용한 성능 증가, 자원 할당의 유 연성, 주파수별 빔 제어의 용이를 위해, 빔 형성 가중치 벡터(weight vector)/프리코딩 벡터(precoding vector)를 적용하는 위치에 따라 아날로그 빔포밍(analog beamforming) 기법과 디지털 빔포밍(digital beamforming) 기법이 결합된 하이브리드(hybrid) 형태의 빔포밍 기법이 요구된다.하이브리드 빔포밍(Hybrid Beamforming) 도 7은 하이브리드 빔포밍(hybrid beamforming)을 위한 전송단 및 수신단의 블록도의 일례를 나타낸 도이다. 하이브리드 빔포밍에 의하면, BS나 UE에서 많은 수의 안테나에 적절한 위상차를 이용하여 동일한 신호를 전송함 으로써 특정한 방향에서만 에너지가 높아지게 함으로써 좁은 빔이 형성될 수 있다. 빔 관리(Beam Management, BM) BM 과정은 하향링크(downlink, DL) 및 상향링크(uplink, UL) 전송/수신에 사용될 수 있는 BS(혹은 전송 및 수신 포인트(transmission and reception point, TRP)) 및/또는 UE 빔들의 세트(set)를 획득하고 유지하기 위한 과 정들로서, 아래와 같은 과정 및 용어를 포함할 수 있다. - 빔 측정(beam measurement): BS 또는 UE가 수신된 빔포밍 신호의 특성을 측정하는 동작. - 빔 결정(beam determination): BS 또는 UE가 자신의 전송 빔(Tx beam) / 수신 빔(Rx beam)을 선택하는 동작. - 빔 스위핑(beam sweeping): 미리 결정된 방식으로 일정 시간 인터벌 동안 전송 및/또는 수신 빔을 이용하여 공간 도메인을 커버하는 동작. - 빔 보고(beam report): UE가 빔 측정에 기반하여 빔포밍된 신호의 정보를 보고하는 동작. BM 과정은 SSB 또는 CSI-RS를 이용하는 DL BM 과정과, SRS(sounding reference signal)을 이용하는 UL BM 과정으로 구분될 수 있다. 또한, 각 BM 과정은 Tx 빔을 결정하기 위한 Tx 빔 스위핑과 Rx 빔을 결정하기 위 한 Rx 빔 스위핑을 포함할 수 있다. 이하에서는 SSB를 이용한 DL BM 과정에 대해 주로 설명된다. SSB를 이용한 DL BM 과정은 BS에 의한 빔포밍된 SSB 전송과, UE에 의한 빔 보고(beam reporting)를 포 함할 수 있다. SSB는 Tx 빔 스위핑과 Rx 빔 스위핑 모두에 사용될 수 있다. SSB를 이용한 Rx 빔 스위핑은 UE가 Rx 빔을 변경하면서 SSB의 수신을 시도함으로써 수행될 수 있다. SSB를 이용한 빔 보고(beam report)에 대한 설정은 RRC_CONNECTED에서 채널 상태 정보(channel state information, CSI)/빔 설정 시에 수행된다. - UE는 BM을 위해 사용되는 SSB 자원 세트에 대한 정보를 BS로부터 수신한다. SSB 자원 세트는 하나 이상의 SSB 인덱스(SSBI)들로 설정될 수 있다. 각 SSB 자원 세트에 대한 SSBI는 0부터 최대 63까지 정의될 수 있다. - UE는 SSB 자원 세트에 대한 정보에 기초하여 SSB 자원들 상의 신호들을 상기 BS로부터 수신한다. - SSB 자원 지시자(SSB resource indicator, SSBRI) 및 RSRP에 대한 보고를 수행할 것이 BS에 의해 UE에게 설 정된 경우, 상기 UE는 최선(best) SSBRI 및 이에 대응하는 RSRP를 BS에게 보고한다. BS는 UE로부터의 빔 보고를 바탕으로 상기 UE로의 DL 전송에 사용할 BS Tx 빔을 결정할 수 있다. 빔 실패 복구(beam failure recovery, BFR) 과정 빔포밍된 시스템에서, RLF(Radio Link Failure)는 UE의 회전(rotation), 이동(movement) 또는 빔포밍 블로키지 (blockage)로 인해 자주 발생할 수 있다. 따라서, 잦은 RLF가 발생하는 것을 방지하기 위해 BFR이 NR에서 지원 된다. 빔 실패 검출을 위해, BS는 UE에게 빔 실패 검출 참조 신호들을 설정하고, 상기 UE는 상기 UE의 물리 계층으로 부터의 빔 실패 지시(indication)들의 횟수가 BS의 RRC 시그널링에 의해 설정된 기간(period) 내에 RRC 시그널 링에 의해 설정된 임계치(threshold)에 이르면(reach), 빔 실패를 선언(declare)한다. 빔 실패가 검출된 후, 상기 UE는 PCell 상의 RACH 과정을 개시(initiate)함으로써 빔 실패 복구를 트리거하고; 적절한(suitable) 빔을 선택하여 빔 실패 복구를 수행한다(BS가 어떤(certain) 빔들에 대해 전용 RACH 자원들을 제공한 경우, 상기 UE는 이들을 우선적으로 사용하여 BFR을 위한 RACH 과정을 수행한다). 상기 RACH 과정의 완 료(completion) 시, 빔 실패 복구가 완료된 것으로 간주된다.URLLC (Ultra-Reliable and Low Latency Communication) NR에서 정의하는 URLLC 전송은 상대적으로 낮은 트래픽 크기, 상대적으로 낮은 도착 레이트(low arrival rate), 극도의 낮은 레이턴시 요구사항(requirement)(예, 0.5, 1ms), 상대적으로 짧은 전송 지속기간(duration)(예, 2 OFDM symbols), 긴급한 서비스/메시지 등에 대한 전송을 의미할 수 있다. 프리엠션 지시(Pre-emption indication) eMBB와 URLLC 서비스들은 비-중첩(non-overlapping) 시간/주파수 자원들 상에서 스케줄링될 수 있지만, 진행 중 인(ongoing) eMBB 트래픽이 스케줄링된 자원들에서 URLLC 전송이 발생할 수도 있다. PDSCH를 수신하는 UE로 하 여금 다른 UE에 의한 URLLC 전송에 의해 상기 PDSCH가 부분적으로 펑처링(puncturing)되었음을 알 수 있도록 하 기 위해, 프리엠션 지시(preemption indication)가 사용될 수 있다. 상기 프리엠션 지시(preemption indication)는 중단된 전송 지시(interrupted transmission indication)으로 지칭될 수도 있다. 프리엠션 지시와 관련하여, UE는 BS로부터의 RRC 시그널링을 통해 하향링크 프리엠션 RRC 정보(예, DownlinkPreemption IE)를 수신한다. 상기 UE는 하향링크 프리엠션 RRC 정보에 기초하여 DCI 포맷 2_1을 상기 BS로부터 수신한다. 예를 들어, 상기 UE는 상기 하향링크 프리엠션 RRC 정보에 의해 설정된 int-RNTI를 이용하여, 프리엠션 지시 관련 DCI인 DCI 포 맷 2_1을 운반(convey)하는 PDCCH의 검출을 시도한다. UE가 하향링크 프리엠션 RRC 정보에 의해 설정된 서빙 셀(들)에 대한 DCI 포맷 2_1을 검출하면, 상기 UE는 상기 DCI 포맷 2_1이 속한 모니터링 기간의 바로 앞(last) 모니터링 기간의 자원 블록(resource block, RB)들의 세트 및 심볼들의 세트 중 상기 DCI 포맷 2_1에 의해 지시되는 RB들 및 심볼들 내에는 상기 UE로의 아무런 전송도 없 다고 가정할 수 있다. 예를 들어, 도 J2를 참조하면, UE는 프리엠션에 의해 지시된 시간-주파수 자원 내 신호는 자신에게 스케줄링된 DL 전송이 아니라고 보고 나머지 자원 영역에서 수신된 신호들을 기반으로 데이터를 디코 딩한다. mMTC (massive MTC) mMTC(massive Machine Type Communication)은 많은 수의 UE와 동시에 통신하는 초연결 서비스를 지원하기 위한 5G의 시나리오 중 하나이다. 이 환경에서, UE는 굉장히 낮은 전송 속도와 이동성을 가지고 간헐적으로 통신하게 된다. 따라서, mMTC는 UE를 얼마나 낮은 비용으로 오랫동안 구동할 수 있는지를 주요 목표로 하고 있다. 이와 관련하여, 3GPP에서 다루고 있는 MTC와 NB-IoT에 대해 살펴본다. 이하에서는 물리 채널의 전송 시간 인터벌(transmission time interval)이 서브프레임인 경우를 예로 하여 설명 된다. 예를 들어, 일 물리 채널의 전송 시작에서 다음 물리 채널의 전송 시작까지의 최소 시간 인터벌이 1개 서 브프레임인 경우를 예로 하여 설명된다. 그러나, 이하의 설명에서 서브프레임은 슬롯, 미니-슬롯, 혹은 다수 (multiple) 슬롯들로 대체될 수 있다. MTC (Machine Type Communication) MTC(Machine Type Communication)은 M2M (Machine-to-Machine) 또는 IoT (Internet-of-Things) 등에 적용될 수 있는 많은 처리량(throughput)을 요구하지 않는 어플리케이션으로서, 3GPP(3rd Generation Partnership Project)에서 IoT 서비스의 요구 사항을 충족시키기 위해 채택된 통신 기술을 말한다. 이하에서 기술되는 내용은 주로 eMTC와 관련된 특징들이나, 특별한 언급이 없는 한 MTC, eMTC, 5G(또는 NR)에 적용될 MTC에도 동일하게 적용될 수 있다. 후술하는 MTC라는 용어는 eMTC (enhanced MTC), LTE-M1/M2, BL (Bandwidth reduced low complexity) / CE(coverage enhanced), non-BL UE(in enhanced coverage), NR MTC, enhanced BL / CE 등과 같이 다른 용어로 지칭될 수 있다. MTC 일반적 특징 MTC는 특정 시스템 대역폭(또는 채널 대역폭) 내에서만 동작한다. MTC는 기존(legacy) LTE 시스템 혹은 NR 시스템의 시스템 대역 내 자원 블록(resource block, RB)들 중 특정 개수의 RB들을 사용할 수도 있다. MTC가 동작하는 주파수 대역폭은 NR의 주파수 범위(frequency range) 및 부반 송파 간격(subcarrier spacing)을 고려하여 정의될 수 있다. 이하, MTC가 동작하는 특정 시스템 혹은 주파수 대 역폭을 MTC 협대역(narrowband, NB) 혹은 MTC 서브밴드라고 칭한다. NR에서 MTC는 적어도 하나의 대역폭 파트 (bandwidth part, BWP)에서 동작하거나 또는 BWP의 특정 대역에서 동작할 수도 있다. MTC는 1.08MHz보다 훨씬 더 큰 대역폭(예: 10MHz)을 가진 셀에 의해 지원될 수 있으나, MTC에 의해 송/수신되는 물리 채널 및 신호는 항상 1.08MHz 또는 6개 (LTE) RB들로 제한된다. 예를 들어, LTE 시스템에서 협대역은 주파 수 도메인에서 6개의 비-중첩하는(non-overlapping) 연속적인(consecutive) 물리 자원 블록으로 정의된다. MTC에서 하향링크와 상향링크의 일부 채널은 협대역 내로 제한되어 할당될 수 있으며, 한 시간 유닛에서 하나의 채널이 복수의 협대역을 점유하지는 않는다. 도 8 (a)는 협대역 동작의 일례를 나타낸 도이며, 도 8 (b)는 RF 리튜닝(retuning)을 가지는 MTC 채널 반복의 일례를 나타낸 도이다. MTC의 협대역은 BS에 의해 전송되는 시스템 정보 또는 DCI(downlink control information)를 통해 UE에게 설정 될 수 있다. MTC는 기존 LTE 또는 NR의 전체 시스템 대역폭에 걸쳐서 분산되어야 하는 (기존 LTE 또는 NR에서 정의되는) 채널을 사용하지 않는다. 일례로, 기존 LTE의 PDCCH는 시스템 대역폭 전체에 분산되어 전송되므로, MTC 에서는 기존 PDCCH가 사용되지 않는다. 대신 MTC에서는 새로운 제어 채널인 MPDCCH(MTC PDCCH)가 사용된다. MPDCCH는 주파수 도메인에서 최대 6개 RB들 내에서 전송/수신된다. MPDCCH는 시간 도메인에서는 서브프레임 내 OFDM 심볼 들 중 BS로부터의 RRC 파라미터에 의해 지시된 시작 OFDM 심볼 인덱스를 갖는 OFDM 심볼부터 시작하여 하나 이 상의 OFDM 심볼들을 이용하여 전송될 수 있다. MTC의 경우, PBCH, PRACH, MPDCCH, PDSCH, PUCCH, PUSCH가 반복적으로 전송될 수 있다. 이와 같은 MTC 반 복 전송은 지하실과 같은 열악한 환경에서와 같이 신호 품질 또는 전력이 매우 열악한 경우에도 MTC 채널이 디 코딩될 수 있어 셀 반경 증가 및 신호 침투 효과를 가져올 수 있다. MTC 동작 모드 및 레벨 MTC는 커버리지 향상(coverage enhancement, CE)을 위해 2개의 동작 모드(operation mode)(CE Mode A, CE Mode B)와 4개의 서로 다른 CE 레벨들이 사용되며, 아래 표 2와 같을 수 있다. 표 2"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "MTC 동작 모드는 BS에 의해 결정되며, CE 레벨은 MTC UE에 의해 결정된다. MTC 보호 기간 (guard period) MTC에 사용되는 협대역의 위치는 특정 시간 유닛(예, 서브프레임 또는 슬롯)마다 다를 수 있다. MTC UE는 시간 유닛들에 따라 다른 주파수로 튜닝할 수 있다. 주파수 리튜닝에는 일정 시간이 필요하며, 이 일정 시간이 MTC의 가드 기간(guard period)으로 사용될 수 있다. 상기 가드 기간 동안에는 전송 및 수신이 발생하지 않는다. MTC 신호 전송/수신 방법 MTC에서의 신호 전송/수신 과정은 MTC에 특유한 사항을 제외하면 도 2의 과정과 유사하다. 도 2의 S201에서 설 명된 과정이 MTC에서도 수행될 수 있다. 상기 MTC의 초기 셀 탐색 동작에 이용되는 PSS / SSS는 기존 LTE의 PSS / SSS일 수 있다. PSS/SSS를 이용하여 BS와 동기화한 후, MTC UE는 BS로부터 PBCH 신호를 수신하여 셀 내 브로드캐스트 정보를 획 득할 수 있다. PBCH를 통해 전송되는 브로드캐스트 정보는 MIB이다. MTC의 경우, 기존 LTE의 MIB 내 비트들 중 유보 비트(reserved bit)들이 새로운 SIB1-BR(system information block for bandwidth reduced device)에 대 한 스케줄링 정보를 전송하기 위해 사용된다. SIB1-BR에 대한 상기 스케줄링 정보는 상기 SIB1-BR을 나르는 PDSCH를 위한 반복 횟수에 관한 정보 및 수송 블록 크기(transport block size, TBS)에 관한 정보를 포함할 수 있다. SIB-BR을 나르는 PDSCH에 대한 주파수 자원 할당은 협대역 내 6개 연속 RB들의 세트일 수 있다. SIB-BR은 상기 SIB-BR과 연관된 제어 채널(예, PDCCH, MPDDCH) 없이 직접 PDSCH 상에서 전송된다. 초기 셀 탐색을 마친 MTC UE는 MPDCCH와 상기 MPDCCH 정보에 따른 PDSCH를 수신하여 조금 더 구체적인 시스템 정보를 획득할 수 있다(S202). 이후, MTC UE는 BS에 접속을 완료하기 위해 RACH 과정을 수행할 수 있다(S203 ~ S206). MTC UE의 RACH 과정과 관련된 기본적인 설정(configuration)은 SIB2에 의해 전송될 수 있다. 또한, SIB2는 페이징과 관련된 파라미터 들을 포함한다. 3GPP 시스템에서 페이징 기회(Paging Occasion, PO)는 UE가 페이징의 수신을 시도할 수 있는 시 간 유닛을 의미한다. 페이징이라 함은 네트워크가 상기 UE에게 전송할 데이터가 있음을 알리는 것을 의미한다. MTC UE는 페이징용으로 설정된 협대역(PNB) 상에서 자신의 PO에 해당하는 시간 유닛 내 P-RNTI를 기반으로 MPDCCH의 수신을 시도한다. P-RNTI를 기반으로 MPDCCH의 디코딩에 성공한 UE는 상기 MPDCCH에 의해 스케줄링된 PDSCH를 수신하여, 자신에 대한 페이징 메시지를 확인할 수 있다. 자신에 대한 페이징 메시지가 있으면 RACH 과 정을 수행하여 네트워크로의 접속을 수행한다. MTC에서 RACH 과정에서 전송되는 신호 및/또는 메시지들(Msg1, Msg2, Msg3, Msg4)는 반복적으로 전송될 수 있으 며, 이러한 반복 패턴은 CE 레벨에 따라 다르게 설정된다. 임의 접속을 위해 서로 다른 CE 레벨들에 대한 PRACH 자원들이 BS에 의해 시그널링된다. 최대 4개까지의 CE 레 벨들에 대해 각각(respectively) 서로 다른 PRACH 자원들이 MTC UE로 시그널링될 수 있다. MTC UE는 하향링크 RS(예, CRS, CSI-RS, TRS 등)을 이용하여 RSRP를 추정하고, 측정 결과에 기초하여 BS에 의해 시그널링된 CE 레 벨들 중 하나를 결정한다. 상기 UE는 상기 결정된 CE 레벨을 기반으로, 임의 접속에 대한 서로 다른 PRACH 자원 예, PRACH를 위한 주파수, 시간, 프리앰블 자원)들 중 하나를 선택하여, PRACH 전송을 수행한다. BS는 UE가 PRACH 전송에 사용한 PRACH 자원을 기반으로 상기 UE의 CE 레벨을 알 수 있다. 상기 BS는 UE가 PRACH 전송을 통 해 알린 CE 레벨을 기반으로 상기 UE를 위한 CE 모드를 결정할 수 있다. 상기 BS는 상기 UE를 위한 CE 모드에 따라 DCI를 상기 UE에게 전송할 수 있다. PRACH에 대한 RAR 및 경쟁 해결 메시지(contention resolution message)들에 대한 탐색 공간들은 또한 시스템 정보를 통해 BS에 의해 시그널링된다. 상술한 바와 같은 과정을 수행한 MTC UE는 이후 일반적인 상향링크/하향링크 신호 전송 과정으로서 MPDCCH 신호 및/또는 PDSCH 신호의 수신(S207) 및 물리 상향링크 공유 채널(PUSCH) 신호 및/또는 물리 상향링크 제어 채널 (PUCCH) 신호의 전송(S208)을 수행할 수 있다. MTC UE는 PUCCH 혹은 PUSCH를 통해 BS에게 UCI를 전송할 수 있 다. MTC UE에 대한 RRC 연결이 수립(establish)되면, MTC UE는 상향링크 및 하향링크 데이터 할당을 획득하기 위해 설정된 탐색 공간(search space)에서 MPDCCH를 모니터링하여 MDCCH의 수신을 시도한다. 기존(legacy) LTE에서 PDSCH는 PDCCH를 사용하여 스케줄링된다. 구체적으로, PDCCH는 서브프레임(subframe, SF)에서 처음 N개의 OFDM 심볼들에서 전송될 수 있고(N=1~3), 상기 PDCCH에 의해 스케줄링되는 PDSCH는 동일한 서브프레임에서 전송된다. 기존 LTE에서와 달리 MTC의 경우, MPDCCH와 상기 MDCCH에 의해 스케줄링되는 PDSCH가 서로 다른 서브프레임에서 전송/수신된다. 예를 들어, 서브프레임 #n에서 마지막 반복을 가지는 MPDCCH는 서브프레임 #n+2에서 시작하는 PDSCH를 스케줄링한다. MPDCCH는 한 번만 전송되거나 반복하여 전송될 수 있다. MPDCCH의 최대 반복 횟수는 BS로부터의 RRC 시그널링에 의해 UE에게 설정된다. MPDCCH에 의해 전송되는 DCI는 언제 PDSCH 전송이 시작되는지 를 MTC UE가 알 수 있도록 하기 위해 상기 MPDCCH가 얼마나 반복되는지에 대한 정보를 제공한다. 예를 들어, 서 브프레임 #n부터 전송이 시작된 MPDCCH 내 DCI가 상기 MPDCCH가 10번 반복된다는 정보를 포함하는 경우, 상기 MPDCCH가 전송되는 마지막 서브프레임은 서브프레임 #n+9이고, PDSCH의 전송은 서브프레임 #n+11에서 시작할 수 있다. MPDCCH에 의해 전송되는 DCI는 상기 DCI가 스케줄링하는 물리 데이터 채널(예, PUSCH, PDSCH)의 반복 횟 수에 관한 정보를 포함할 수 있다. UE는 DCI가 스케줄링하는 물리 데이터 채널에 대한 반복 횟수 정보에 따라, 시간 도메인에서 상기 물리 데이터 채널을 반복하여 전송/수신할 수 있다. PDSCH는 상기 PDSCH를 스케줄링하는 MPDCCH가 있는 협대역과는 같은 혹은 다른 협대역에 스케줄링될 수 있다. MPDCCH와 해당 PDSCH가 다른 협대역에 위치하는 경우, MTC UE는 PDSCH를 디코딩하기 전에 상기 PDSCH가 있는 협대역으로 주파수를 리튜닝할 필요가 있 다. 상향링크 스케줄링의 경우, 레거시 LTE와 동일한 타이밍을 따를 수 있다. 예를 들어, 서브프레임 #n에서 마 지막 전송이 있는 MPDCCH는 서브프레임 #n+4에서 시작하는 PUSCH 전송을 스케줄링할 수 있다. 물리 채널에 반복 전송이 적용되는 경우, RF 리튜닝에 의해 서로 다른 MTC 서브밴드들 사이에서 주파수 호핑이 지원된다. 예를 들 어, 32개의 서브프레임들에서 PDSCH가 반복 전송되는 경우, 처음 16개의 서브프레임들에서 PDSCH는 제1 MTC 서 브밴드에서 전송되고, 나머지 16개의 서브프레임들에서 PDSCH는 제2 MTC 서브밴드에서 전송될 수 있다. MTC는 반-듀플렉스 모드로 동작할 수 있다. NB-IoT (Narrowband-Internet of Things) NB-IoT는 무선 통신 시스템(예, LTE 시스템, NR 시스템 등)의 1개 자원 블록(resource block, RB)에 해당하는 시스템 대역폭(system BW)을 통해 낮은 복잡도(complexity), 낮은 전력 소비(power consumption), 주파수 자원 의 효율적 사용을 지원하기 위한 시스템을 의미할 수 있다. NB-IoT는 반-듀플렉스 모드로 동작할 수 있다. NB- IoT는 주로 기계 타입 통신(machine-type communication, MTC) 등과 같은 장치(device)(또는 UE)를 셀룰러 시 스템(cellular system)에서 지원하여 IoT(즉, 사물 인터넷)를 구현하기 위한 통신 방식으로 이용될 수도 있다. NB-IoT의 경우, 각 UE는 1개 자원 블록(resource block, RB)를 1개 반송파(carrier)로 인식하므로, 본 명세에 서 NB-IoT와 관련되어 언급되는 RB 및 반송파는 서로 동일한 의미로 해석될 수도 있다. 이하, 본 명세서에서의 NB-IoT와 관련된 프레임 구조, 물리 채널, 다중 반송파 동작(multi carrier operation), 일반적인 신호 전송/수신 등은 기존의 LTE 시스템의 경우를 고려하여 설명되지만, 차세대 시스템 (예, NR 시스템 등)의 경우에도 적용될 수 있음은 물론이다. 또한, 본 명세서에서의 NB-IoT와 관련된 내용은 유 사한 기술적 목적(예: 저-전력, 저-비용, 커버리지 향상 등)을 지향하는 MTC에 적용될 수도 있다. NB-IoT의 프레임 구조 및 물리 자원 NB-IoT 프레임 구조는 부반송파 간격(subcarrier spacing)에 따라 다르게 설정될 수 있다. 예를 들어, 15kHz 부반송파 간격에 대한 NB-IoT 프레임 구조는 기존(legacy) 시스템(예, LTE 시스템)의 프레임 구조와 동일하게 설정될 수 있다. 예를 들어, 10ms NB-IoT 프레임은 1ms NB-IoT 서브프레임 10개를 포함하며, 1ms NB-IoT 서브 프레임은 0.5ms NB-IoT 슬롯 2개를 포함할 수 있다. 또한, 각각의 0.5ms NB-IoT은 7개의 OFDM 심볼들을 포함할 수 있다. 다른 예로, 3.75kHz 부반송파 간격을 갖는 BWP 혹은 셀/반송파의 경우, 10ms NB-IoT 프레임은 2ms NB-IoT 서브프레임 5개를 포함하며, 2ms NB-IoT 서브프레임은 7개의 OFDM 심볼들과 하나의 보호 기간(guard period, GP)을 포함할 수 있다. 또한, 상기 2ms NB-IoT 서브프레임은 NB-IoT 슬롯 또는 NB-IoT 자원 유닛 (resource unit, RU) 등에 의해 표현될 수도 있다. NB-IoT 프레임 구조는 15kHz 및 3.75kHz에 한정되는 것은 아니며, 다른 부반송파 간격(예, 30kHz 등)에 대한 NB-IoT도 시간/주파수 단위를 달리하여 고려될 수 있음은 물 론이다. NB-IoT 하향링크의 물리 자원은 시스템 대역폭이 특정 개수의 RB(예, 1개의 RB 즉, 180kHz)로 한정되는 것을 제 외하고는, 다른 무선 통신 시스템(예, LTE 시스템, NR 시스템 등)의 물리 자원을 참고하여 설정될 수 있다. 일 례로, 상술한 바와 같이 NB-IoT 하향링크가 15kHz 부반송파 간격만을 지원하는 경우, NB-IoT 하향링크의 물리 자원은 상술한 도 1에 예시된 자원 격자를 주파수 도메인 상의 1개 RB로 제한한 자원 영역으로 설정될 수 있다. NB-IoT 상향링크의 물리 자원의 경우에도 하향링크의 경우와 같이 시스템 대역폭은 1개의 RB로 제한되어 구성될 수 있다. NB-IoT에서, 상향링크 대역의 부반송파 수 및 슬롯 기간 은 아래의 표 3과 같이 주어질수 있다. LTE 시스템의 NB-IoT의 경우, 한 개 슬롯의 슬롯 기간 은 시간 도메인에서 7개 SC-FDMA 심볼들로 정의된다. 표 3"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "NB-IoT에서는 NB-IoT용 PUSCH(이하, NPUSCH)의 자원 요소들로의 매핑을 위해 자원 유닛(resource unit, RU)들 이 사용된다. RU는 시간 도메인 상에서 개의 SC-FDMA 심볼들로 구성되고, 주파수 도메인 상에서 개의 연속적인(consecutive) 부반송파들로 구성될 수 있다. 일례로, 및 는 FDD용 프레임 구조를 가진 셀/반송파에 대해서는 아래의 표 4에 의해 주어지며, TDD용 프레임 구조인 프레임 구조를 가진 셀/ 반송파에 대해서는 표 5에 의해 주어질 수 있다. 표 4 표 5"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "NB-IoT의 물리 채널 NB-IoT 하향링크에는 15kHz의 부반송파 간격에 기반하여 OFDMA 방식이 적용될 수 있다. 이를 통해, 부반송파 간 직교성(orthogonality)을 제공하여 다른 시스템(예, LTE 시스템, NR 시스템)과의 공존(co-existence)이 효율적 으로 지원될 수 있다. NB-IoT 시스템의 하향링크 물리 채널/신호는 기존의 시스템과의 구분을 위하여 ‘ N(Narrowband)’이 추가된 형태로 표현될 수 있다. 예를 들어, 하향링크 물리 채널은 NPBCH, NPDCCH, NPDSCH) 등으로 지칭되며, 하향링크 물리 신호는 NPSS, NSSS, NRS(Narrowband Reference Signal), NPRS(Narrowband Positioning Reference Signal), NWUS(Narrowband Wake Up Signal) 등으로 지칭될 수 있다. NB-IoT 시스템의 하향링크 채널인 NPBCH, NPDCCH, NPDSCH 등의 경우, 커버리지 향상을 위하여 반복 전송(repetition transmission)이 수행될 수 있다. 또한, NB-IoT는 새롭게 정의된 DCI 포맷을 사용하며, 일례로 NB-IoT를 위한 DCI 포맷은 DCI 포맷 N0, DCI 포맷 N1, DCI 포맷 N2 등으로 정의될 수 있다. NB-IoT 상향링크에는 15kHz 또는 3.75kHz의 부반송파 간격에 기반하여 SC-FDMA 방식이 적용될 수 있다. 하향링 크 부분에서 언급한 것과 같이, NB-IoT 시스템의 물리 채널은 기존의 시스템과의 구분을 위하여 ‘ N(Narrowband)’이 추가된 형태로 표현될 수 있다. 예를 들어, 상향링크 물리 채널은 NPRACH 및 NPUSCH 등으로 표현되고, 상향링크 물리 신호는 NDMRS 등으로 표현될 수 있다. NPUSCH는 NPUSCH 포맷 1과 NPUSCH 포맷 2 등으 로 구분될 수 있다. 일례로, NPUSCH 포맷 1은 상향링크 공유 채널(uplink shared channel, UL-SCH) 전송(또는 운반)을 위해 이용되며, NPUSCH 포맷 2는 HARQ ACK 시그널링 등과 같은 UCI 전송을 위해 이용될 수 있다. NB- IoT 시스템의 상향링크 채널인 NPRACH 등의 경우, 커버리지 향상을 위하여 반복 전송이 수행될 수 있다. 이 경 우, 반복 전송은 주파수 호핑이 적용되어 수행될 수도 있다. NB-IoT의 다중 반송파 동작 NB-IoT는 다중 반송파 모드로 동작할 수 있다. 다중 반송파 동작은 NB-IoT에서 BS 및/또는 UE가 상호 간에 채널 및/또는 신호를 전송/수신함에 있어서 용도가 서로 다르게 설정된(즉, 타입이 다른) 다수의 반송파들이 이용되 는 것을 의미할 수 있다. NB-IoT의 다중 반송파 모드에서, 반송파는 앵커 타입의 반송파(anchor type carrier)(즉, 앵커 반송파(anchor carrier), 앵커 PRB) 및 비-앵커 타입의 반송파(non-anchor type carrier)(즉, 비-앵커 반송파(non-anchor carrier), 비-앵커 PRB)로 구분될 수 있다. 앵커 반송파는 BS 관점에서 초기 접속(initial access)을 위해 NPSS, NSSS, NPBCH, 및 시스템 정보 블록(N- SIB)를 위한 NPDSCH 등을 전송하는 반송파를 의미할 수 있다. 즉, NB-IoT에서 초기 접속을 위한 반송파는 앵커반송파로 지칭되고, 그 외의 것(들)은 비-앵커 반송파로 지칭될 수 있다. NB-IoT 신호 전송/수신 과정 NB-IoT에서의 신호 전송/수신 과정은 NB-IoT에 특유한 사항을 제외하면 도 2의 과정과 유사하다. 도 2를 참조하 면, 전원이 꺼진 상태에서 다시 전원이 켜지거나, 새로이 셀에 진입한 NB-IoT UE는 초기 셀 탐색(Initial cell search) 작업을 수행할 수 있다(S201). 이를 위해 NB-IoT UE는 BS로부터 NPSS 및 NSSS를 수신하여 BS와의 동기 화를 수행하고, 셀 ID(cell identity) 등의 정보를 획득할 수 있다. 또한, NB-IoT UE는 BS로부터 NPBCH를 수신 하여 셀 내 브로드캐스트 정보를 획득할 수 있다. 초기 셀 탐색을 마친 NB-IoT UE는 NPDCCH 및 이에 대응되는 NPDSCH를 수신하여 좀더 구체적인 시스템 정보를 획 득할 수 있다(S202). 다시 말해, BS는 초기 셀 탐색을 마친 NB-IoT UE에게 NPDCCH 및 이에 대응되는 NPDSCH를 전송하여 좀더 구체적인 시스템 정보를 전달할 수 있다. 이후, NB-IoT UE는 BS에 접속을 완료하기 위해 RACH 과정을 수행할 수 있다(S203 ~ S206). 구체적으로, NB-IoT UE는 NPRACH를 통해 프리앰블을 BS으로 전송할 수 있으며(S203), 상술한 바와 같이 NPRACH는 커버리지 향상 등 을 위하여 주파수 호핑 등에 기반하여 반복 전송되도록 설정될 수 있다. 다시 말해, BS는 NB-IoT UE로부터 NPRACH를 통해 프리앰블을 (반복적으로) 수신할 수 있다. 이후, NB-IoT UE는 NPDCCH 및 이에 대응하는 NPDSCH를 통해 프리앰블에 대한 RAR을 BS로부터 수신할 수 있다(S204). 다시 말해, BS는 NPDCCH 및 이에 대응하는 NPDSCH 를 통해 프리앰블에 대한 RAR를 NB-IoT UE로 전송할 수 있다. 이후, NB-IoT UE는 RAR 내의 스케줄링 정보를 이 용하여 NPUSCH를 BS으로 전송하고(S205), NPDCCH 및 이에 대응하는 NPDSCH를 수신하여 충돌 해결 과정 (Contention Resolution Procedure)를 수행할 수 있다(S206). 상술한 바와 같은 과정을 수행한 NB-IoT UE는 이후 일반적인 상향/하향링크 신호 전송 과정으로서 NPDCCH/NPDSCH 수신(S207) 및 NPUSCH 전송(S208)을 수행할 수 있다. 다시 말해, 상술한 과정들을 수행한 후, BS는 NB-IoT UE로 일반적인 신호 전송/수신 과정으로서 NPDCCH/NPDSCH 전송 및 NPUSCH 수신을 수행할 수 있다. NB-IoT의 경우, 앞서 언급한 바와 같이 NPBCH, NPDCCH, NPDSCH 등은 커버리지 향상 등을 위하여 반복 전송될 수 있다. 또한, NB-IoT의 경우 NPUSCH를 통해 UL-SCH(즉, 일반적인 상향링크 데이터) 및 UCI전달될 수 있다. 이 때, UL-SCH 및 UCI는 각각 다른 NPUSCH 포맷(예, NPUSCH 포맷 1, NPUSCH 포맷 2 등)을 통해 전송되도록 설정될 수도 있다. NB-IoT에서 UCI는 일반적으로 NPUSCH를 통해 전송될 수 있다. 또한, 네트워크(예: BS)의 요청/지시에 따라 UE는 NPUSCH를 통해 UCI를 주기적(periodic), 비주기적(aperiodic), 또는 반-지속적(semi-persistent)으로 전송할 수 있다. 무선 통신 장치 도 9는 본 명세서에서 제안하는 방법들이 적용될 수 있는 무선 통신 시스템의 블록 구성도를 예시한다. 도 9를 참조하면, 무선 통신 시스템은 제 1 통신 장치 및/또는 제 2 통신 장치을 포함한다. ‘A 및/ 또는 B’는 ‘A 또는 B 중 적어도 하나를 포함한다’와 동일한 의미로 해석될 수 있다. 제 1 통신 장치가 BS를 나타내고, 제 2 통신 장치가 UE를 나타낼 수 있다(또는 제 1 통신 장치가 UE를 나타내고, 제 2 통신 장치가 BS 를 나타낼 수 있다). 제 1 통신 장치와 제 2 통신 장치는 프로세서(processor, 911,921), 메모리(memory, 914,924), 하나 이상의 Tx/Rx RF 모듈(radio frequency module, 915,925), Tx 프로세서(912,922), Rx 프로세서(913,923), 안테나 (916,926)를 포함한다. Tx/Rx 모듈은 트랜시버라고도 한다. 프로세서는 앞서 살핀 기능, 과정 및/또는 방법을 구현한다. 보다 구체적으로, DL(제 1 통신 장치에서 제 2 통신 장치로의 통신)에서, 코어 네트워크로부터의 상 위 계층 패킷은 프로세서에 제공된다. 프로세서는 레이어 2(즉, L2) 계층의 기능을 구현한다. DL에서, 프 로세서는 논리 채널과 전송 채널 간의 다중화(multiplexing), 무선 자원 할당을 제 2 통신 장치에 제공하 며, 제 2 통신 장치로의 시그널링을 담당한다. 전송(TX) 프로세서는 L1 계층(즉, 물리 계층)에 대한 다양 한 신호 처리 기능을 구현한다. 상기 신호 처리 기능은 제 2 통신 장치에서 FEC(forward error correction)을 용이하게 하고, 코딩 및 인터리빙(coding and interleaving)을 포함한다. 인코딩 및 인터리밍을 거친 신호는 스크램블링(scrambling) 및 변조(modulation)을 거쳐 복소 값(complex valued) 변조 심볼들로 변조된다. 변조에 는 채널에 따라 BPSK, QPSK, 16QAM, 64QAM, 246QAM 등이 사용될 수 있다. 복소 값 변조 심볼들(이하, 변조 심 볼들)은 병렬 스트림으로 분할되고, 각각의 스트림은 OFDM 부반송파에 매핑되고, 시간 및/또는 주파수 도메인에 서 참조 신호와 다중화(multiplexing)되며, IFFT를 사용하여 함께 결합되어 시간 도메인 OFDM 심볼 스트림을 운 반하는 물리적 채널을 생성한다. OFDM 심볼 스트림은 다중 공간 스트림을 생성하기 위해 공간적으로 프리코딩된 다. 각각의 공간 스트림은 개별 Tx/Rx 모듈(또는 트랜시버, 915)를 통해 상이한 안테나에 제공될 수 있다. 각각의 Tx/Rx 모듈은 전송을 위해 각각의 공간 스트림을 RF 반송파로 주파수 상향변환(upconvert)할 수 있다. 제 2 통신 장치에서, 각각의 Tx/Rx 모듈(또는 트랜시버, 925)는 각 Tx/Rx 모듈의 각 안테나을 통해 RF 반 송파의 신호를 수신한다. 각각의 Tx/Rx 모듈은 상기 RF 반송파의 신호를 기저대역(baseband) 신호로 복원하여, 수신(RX) 프로세서에 제공한다. RX 프로세서는 L1(즉, 물리 계층)의 다양한 신호 프로세싱 기능을 구현한 다. RX 프로세서는 제 2 통신 장치로 향하는 임의의 공간 스트림을 복구하기 위해 정보에 공간 프로세싱을 수행 할 수 있다. 만약 다수의 공간 스트림들이 제 2 통신 장치로 향하는 경우, 다수의 RX 프로세서들에 의해 단일 OFDMA 심볼 스트림으로 결합될 수 있다. RX 프로세서는 고속 푸리에 변환 (FFT)을 사용하여 시간 도메인 신호인 OFDM 심볼 스트림을 주파수 도메인 신호로 변환한다. 주파수 도메인 신호는 OFDM 신호의 각각의 부반송파에 대 한 개별적인 OFDM 심볼 스트림을 포함한다. 각각의 부반송파 상의 변조 심볼들 및 참조 신호는 제 1 통신 장치 에 의해 전송된 가장 가능성 있는 신호 성상(constellation) 포인트들을 결정함으로써 복원되고 복조된다. 이러 한 연 판정(soft decision)들은 채널 추정 값들에 기초할 수 있다. 연판정들은 물리 채널 상에서 제 1 통신 장 치에 의해 원래 전송된 데이터 및 제어 신호를 복원하기 위해 디코딩 및 디인터리빙되다. 해당 데이터 및 제어 신호는 프로세서에 제공된다. UL(제 2 통신 장치에서 제 1 통신 장치로의 통신)은 제 2 통신 장치에서 수신기 기능과 관련하여 기술된 것과 유사한 방식으로 제 1 통신 장치에서 처리된다. 각각의 Tx/Rx 모듈는 각각의 안테나을 통 해 신호를 수신한다. 각각의 Tx/Rx 모듈은 RF 반송파 및 정보를 RX 프로세서에 제공한다. 프로세서 는 프로그램 코드 및 데이터를 저장하는 메모리 와 관련될 수 있다. 메모리는 컴퓨터 판독 가능 매체로서 지칭될 수 있다. <인공 지능(AI: Artificial Intelligence)> 인공 지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미하며, 머신 러닝(기계 학습, Machine Learning)은 인공 지능 분야에서 다루는 다양한 문제를 정의하고 그것을 해결하는 방법론을 연구하는 분야를 의미한다. 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작업에 대한 성능을 높이는 알고리 즘으로 정의하기도 한다. 인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로써, 시냅스의 결합으로 네트워 크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층(Hidden Layer)를 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하는 시냅 스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함숫값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망의 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수 는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키 는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화 하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 인공 신경망 중에서 복수의 은닉층을 포함하는 심층 신경망(DNN: Deep Neural Network)으로 구현되는 머신 러닝 을 딥 러닝(심층 학습, Deep Learning)이라 부르기도 하며, 딥 러닝은 머신 러닝의 일부이다. 이하에서, 머신 러닝은 딥 러닝을 포함하는 의미로 사용된다. <로봇(Robot)> 로봇은 스스로 보유한 능력에 의해 주어진 일을 자동으로 처리하거나 작동하는 기계를 의미할 수 있다. 특히, 환경을 인식하고 스스로 판단하여 동작을 수행하는 기능을 갖는 로봇을 지능형 로봇이라 칭할 수 있다. 로봇은 사용 목적이나 분야에 따라 산업용, 의료용, 가정용, 군사용 등으로 분류할 수 있다. 로봇은 액츄에이터 또는 모터를 포함하는 구동부를 구비하여 로봇 관절을 움직이는 등의 다양한 물리적 동작을 수행할 수 있다. 또한, 이동 가능한 로봇은 구동부에 휠, 브레이크, 프로펠러 등이 포함되어, 구동부를 통해 지 상에서 주행하거나 공중에서 비행할 수 있다. <자율 주행(Self-Driving)> 자율 주행은 스스로 주행하는 기술을 의미하며, 자율 주행 차량은 사용자의 조작 없이 또는 사용자의 최소한의 조작으로 주행하는 차량(Vehicle)을 의미한다. 예컨대, 자율 주행에는 주행중인 차선을 유지하는 기술, 어댑티브 크루즈 컨트롤과 같이 속도를 자동으로 조절 하는 기술, 정해진 경로를 따라 자동으로 주행하는 기술, 목적지가 설정되면 자동으로 경로를 설정하여 주행하 는 기술 등이 모두 포함될 수 있다. 차량은 내연 기관만을 구비하는 차량, 내연 기관과 전기 모터를 함께 구비하는 하이브리드 차량, 그리고 전기 모터만을 구비하는 전기 차량을 모두 포괄하며, 자동차뿐만 아니라 기차, 오토바이 등을 포함할 수 있다. 이때, 자율 주행 차량은 자율 주행 기능을 가진 로봇으로 볼 수 있다. <확장 현실(XR: eXtended Reality)> 확장 현실은 가상 현실(VR: Virtual Reality), 증강 현실(AR: Augmented Reality), 혼합 현실(MR: Mixed Reality)을 총칭한다. VR 기술은 현실 세계의 객체나 배경 등을 CG 영상으로만 제공하고, AR 기술은 실제 사물 영상 위에 가상으로 만들어진 CG 영상을 함께 제공하며, MR 기술은 현실 세계에 가상 객체들을 섞고 결합시켜서 제공하는 컴퓨터 그래픽 기술이다. MR 기술은 현실 객체와 가상 객체를 함께 보여준다는 점에서 AR 기술과 유사하다. 그러나, AR 기술에서는 가상 객체가 현실 객체를 보완하는 형태로 사용되는 반면, MR 기술에서는 가상 객체와 현실 객체가 동등한 성격으로 사용된다는 점에서 차이점이 있다. XR 기술은 HMD(Head-Mount Display), HUD(Head-Up Display), 휴대폰, 태블릿 PC, 랩탑, 데스크탑, TV, 디지털 사이니지 등에 적용될 수 있고, XR 기술이 적용된 장치를 XR 장치(XR Device)라 칭할 수 있다. 도 10은 본 발명의 일 실시 예에 따른 AI 장치를 나타낸다. 도 10에 도시된 AI 장치는 TV, 프로젝터, 휴대폰, 스마트폰, 데스크탑 컴퓨터, 노트북, 디지털방송용 단 말기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 태블릿 PC, 웨어러 블 장치, 셋톱박스(STB), DMB 수신기, 라디오, 세탁기, 냉장고, 데스크탑 컴퓨터, 디지털 사이니지, 로봇, 차량 등과 같은, 고정형 기기 또는 이동 가능한 기기 등으로 구현될 수 있다. 도 10을 참조하면, AI 장치는 통신부, 입력부, 러닝 프로세서, 센싱부, 출력부 , 메모리 및 프로세서 등을 포함할 수 있다. 통신부는 유무선 통신 기술을 이용하여 다른 AI 장치나 AI 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 예컨대, 통신부는 외부 장치들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 이때, 통신부가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블루투 스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 특히, 이전 도 1 내지 도 9에서 전술한 5G 기술이 적용될 수도 있다. 입력부는 다양한 종류의 데이터를 획득할 수 있다. 이때, 입력부는 영상 신호 입력을 위한 카메라, 오디오 신호를 수신하기 위한 마이크로폰, 사용자로부터 정보를 입력 받기 위한 사용자 입력부 등을 포 함할 수 있다. 여기서, 카메라나 마이크로폰을 센서로 취급하여, 카메라나 마이크로폰으로부터 획득한 신호를 센싱 데이터 또는 센서 정보라고 할 수도 있다. 입력부는 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때 사용될 입력 데이터 등을 획득할 수 있다. 입력부는 가공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 프로세서 또는 러닝 프로세서는 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학 습된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데이터에 대하 여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기초로 이용될 수 있다. 이때, 러닝 프로세서는 AI 서버의 러닝 프로세서와 함께 AI 프로세싱을 수행할 수 있다. 이때, 러닝 프로세서는 AI 장치에 통합되거나 구현된 메모리를 포함할 수 있다. 또는, 러닝 프로세 서는 메모리, AI 장치에 직접 결합된 외부 메모리 또는 외부 장치에서 유지되는 메모리를 사 용하여 구현될 수도 있다. 센싱부는 다양한 센서들을 이용하여 AI 장치 내부 정보, AI 장치의 주변 환경 정보 및 사용 자 정보 중 적어도 하나를 획득할 수 있다. 이때, 센싱부에 포함되는 센서에는 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다, 레이더 등이 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시킬 수 있다. 이때, 출력부에는 시각 정보를 출력하는 디스플레이부, 청각 정보를 출력하는 스피커, 촉각 정보를 출력 하는 햅틱 모듈 등이 포함될 수 있다. 메모리는 AI 장치의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 예컨대, 메모리는 입력부에서 획득한 입력 데이터, 학습 데이터, 학습 모델, 학습 히스토리 등을 저장할 수 있다. 프로세서는 데이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하 여, AI 장치의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서는 AI 장치 의 구성 요소들을 제어하여 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 러닝 프로세서 또는 메모리의 데이터를 요청, 검색, 수신 또는 활용 할 수 있고, 상기 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동작을 실 행하도록 AI 장치의 구성 요소들을 제어할 수 있다. 이때, 프로세서는 결정된 동작을 수행하기 위하여 외부 장치의 연계가 필요한 경우, 해당 외부 장치를 제 어하기 위한 제어 신호를 생성하고, 생성한 제어 신호를 해당 외부 장치에 전송할 수 있다. 프로세서는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요구 사 항을 결정할 수 있다.이때, 프로세서는 음성 입력을 문자열로 변환하기 위한 STT(Speech To Text) 엔진 또는 자연어의 의도 정 보를 획득하기 위한 자연어 처리(NLP: Natural Language Processing) 엔진 중에서 적어도 하나 이상을 이용하여, 사용자 입력에 상응하는 의도 정보를 획득할 수 있다. 이때, STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 적어도 일부가 머신 러닝 알고리즘에 따라 학습된 인 공 신경망으로 구성될 수 있다. 그리고, STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 러닝 프로세서 에 의해 학습된 것이나, AI 서버의 러닝 프로세서에 의해 학습된 것이거나, 또는 이들의 분산 처리에 의 해 학습된 것일 수 있다. 참고로, AI 서버의 구체적인 구성요소들은 이하 도 11에 상세히 도시되어 있다. 프로세서는 AI 장치의 동작 내용이나 동작에 대한 사용자의 피드백 등을 포함하는 이력 정보를 수 집하여 메모리 또는 러닝 프로세서에 저장하거나, AI 서버 등의 외부 장치에 전송할 수 있다. 수집 된 이력 정보는 학습 모델을 갱신하는데 이용될 수 있다. 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, AI 장치의 구성 요소들 중 적어도 일부를 제어할 수 있다. 나아가, 프로세서는 상기 응용 프로그램의 구동을 위하여, AI 장치(100 0)에 포함된 구성 요소들 중 둘 이상을 서로 조합하여 동작시킬 수 있다. 도 11은 본 발명의 일 실시 예에 따른 AI 서버를 나타낸다. 도 11을 참조하면, AI 서버는 머신 러닝 알고리즘을 이용하여 인공 신경망을 학습시키거나 학습된 인공 신경망을 이용하는 장치를 의미할 수 있다. 여기서, AI 서버는 복수의 서버들로 구성되어 분산 처리를 수 행할 수도 있고, 5G 네트워크로 정의될 수 있다. 이때, AI 서버는 AI 장치의 일부의 구성으로 포함 되어, AI 프로세싱 중 적어도 일부를 함께 수행할 수도 있다. AI 서버는 통신부, 메모리, 러닝 프로세서 및 프로세서 등을 포함할 수 있다. 통신부는 AI 장치 등의 외부 장치와 데이터를 송수신할 수 있다. 메모리는 모델 저장부를 포함할 수 있다. 모델 저장부는 러닝 프로세서을 통하여 학습 중인 또는 학습된 모델(또는 인공 신경망, 1125)을 저장할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망을 학습시킬 수 있다. 학습 모델은 인공 신경 망의 AI 서버에 탑재된 상태에서 이용되거나, AI 장치 등의 외부 장치에 탑재되어 이용될 수도 있 다. 학습 모델은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 학습 모델의 일부 또는 전부가 소프트웨어로 구현되는 경우 학습 모델을 구성하는 하나 이상의 명령어(instruction)는 메모리 에 저장될 수 있다. 프로세서는 학습 모델을 이용하여 새로운 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기초한 응답이나 제어 명령을 생성할 수 있다. 도 12는 본 발명의 일 실시 예에 따른 AI 시스템을 나타낸다. 도 12를 참조하면, AI 시스템은 AI 서버, 로봇, 자율 주행 차량, XR 장치, 스마트폰 또는 가전 중에서 적어도 하나 이상이 클라우드 네트워크와 연결된다. 여기서, AI 기술이 적용된 로봇, 자율 주행 차량, XR 장치, 스마트폰 또는 가전 등을 AI 장치라 칭할 수 있다. 클라우드 네트워크는 클라우드 컴퓨팅 인프라의 일부를 구성하거나 클라우드 컴퓨팅 인프라 안에 존재하 는 네트워크를 의미할 수 있다. 여기서, 클라우드 네트워크는 3G 네트워크, 4G 또는 LTE(Long Term Evolution) 네트워크 또는 5G 네트워크 등을 이용하여 구성될 수 있다. 즉, AI 시스템을 구성하는 각 장치들(1210 내지 1260)은 클라우드 네트워크를 통해 서로 연결될 수 있다. 특히, 각 장치들(1210 내지 1260)은 기지국을 통해서 서로 통신할 수도 있지만, 기지국을 통하지 않고 직접 서 로 통신할 수도 있다.AI 서버는 AI 프로세싱을 수행하는 서버와 빅 데이터에 대한 연산을 수행하는 서버를 포함할 수 있다. AI 서버는 AI 시스템을 구성하는 AI 장치들인 로봇, 자율 주행 차량, XR 장치, 스마 트폰 또는 가전 중에서 적어도 하나 이상과 클라우드 네트워크을 통하여 연결되고, 연결된 AI 장치들(1210 내지 1250)의 AI 프로세싱을 적어도 일부를 도울 수 있다. 이때, AI 서버는 AI 장치(1210 내지 1250)를 대신하여 머신 러닝 알고리즘에 따라 인공 신경망을 학습시 킬 수 있고, 학습 모델을 직접 저장하거나 AI 장치(1210 내지 1250)에 전송할 수 있다. 이때, AI 서버는 AI 장치(1210 내지 1250)로부터 입력 데이터를 수신하고, 학습 모델을 이용하여 수신한 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기초한 응답이나 제어 명령을 생성하여 AI 장치 (1210 내지 1250)로 전송할 수 있다. 또는, AI 장치(1210 내지 1250)는 직접 학습 모델을 이용하여 입력 데이터에 대하여 결과 값을 추론하고, 추론 한 결과 값에 기초한 응답이나 제어 명령을 생성할 수도 있다. 이하에서는, 상술한 기술이 적용되는 AI 장치(1210 내지 1250)의 다양한 실시 예들을 설명한다. 여기서, 도 12 에 도시된 AI 장치(1210 내지 1250)는 도 10에 도시된 AI 장치의 구체적인 실시 예로 볼 수 있다. <AI+XR> XR 장치는 AI 기술이 적용되어, HMD(Head-Mount Display), 차량에 구비된 HUD(Head-Up Display), 텔레비 전, 휴대폰, 스마트 폰, 컴퓨터, 웨어러블 디바이스, 가전 기기, 디지털 사이니지, 차량, 고정형 로봇이나 이동 형 로봇 등으로 구현될 수도 있다. XR 장치는 다양한 센서들을 통해 또는 외부 장치로부터 획득한 3차원 포인트 클라우드 데이터 또는 이미 지 데이터를 분석하여 3차원 포인트들에 대한 위치 데이터 및 속성 데이터를 생성함으로써 주변 공간 또는 현실 객체에 대한 정보를 획득하고, 출력할 XR 객체를 렌더링하여 출력할 수 있다. 예컨대, XR 장치는 인식된 물체에 대한 추가 정보를 포함하는 XR 객체를 해당 인식된 물체에 대응시켜 출력할 수 있다. XR 장치는 적어도 하나 이상의 인공 신경망으로 구성된 학습 모델을 이용하여 상기한 동작들을 수행할 수 있다. 예컨대, XR 장치는 학습 모델을 이용하여 3차원 포인트 클라우드 데이터 또는 이미지 데이터에서 현실 객체를 인식할 수 있고, 인식한 현실 객체에 상응하는 정보를 제공할 수 있다. 여기서, 학습 모델은 XR 장 치에서 직접 학습되거나, AI 서버 등의 외부 장치에서 학습된 것일 수 있다. 이때, XR 장치는 직접 학습 모델을 이용하여 결과를 생성하여 동작을 수행할 수도 있지만, AI 서버 등의 외부 장치에 센서 정보를 전송하고 그에 따라 생성된 결과를 수신하여 동작을 수행할 수도 있다. <AI+로봇+XR> 로봇은 AI 기술 및 XR 기술이 적용되어, 안내 로봇, 운반 로봇, 청소 로봇, 웨어러블 로봇, 엔터테인먼트 로봇, 펫 로봇, 무인 비행 로봇, 드론 등으로 구현될 수 있다. XR 기술이 적용된 로봇은 XR 영상 내에서의 제어/상호작용의 대상이 되는 로봇을 의미할 수 있다. 이 경 우, 로봇은 XR 장치와 구분되며 서로 연동될 수 있다. XR 영상 내에서의 제어/상호작용의 대상이 되는 로봇은 카메라를 포함하는 센서들로부터 센서 정보를 획 득하면, 로봇 또는 XR 장치는 센서 정보에 기초한 XR 영상을 생성하고, XR 장치는 생성된 XR 영상을 출력할 수 있다. 그리고, 이러한 로봇은 XR 장치를 통해 입력되는 제어 신호 또는 사용자의 상호작용에 기초하여 동작할 수 있다. 예컨대, 사용자는 XR 장치 등의 외부 장치를 통해 원격으로 연동된 로봇의 시점에 상응하는 XR 영 상을 확인할 수 있고, 상호작용을 통하여 로봇의 자율 주행 경로를 조정하거나, 동작 또는 주행을 제어하 거나, 주변 객체의 정보를 확인할 수 있다.<AI+자율주행+XR> 자율 주행 차량은 AI 기술 및 XR 기술이 적용되어, 이동형 로봇, 차량, 무인 비행체 등으로 구현될 수 있 다. XR 기술이 적용된 자율 주행 차량은 XR 영상을 제공하는 수단을 구비한 자율 주행 차량이나, XR 영상 내 에서의 제어/상호작용의 대상이 되는 자율 주행 차량 등을 의미할 수 있다. 특히, XR 영상 내에서의 제어/상호 작용의 대상이 되는 자율 주행 차량은 XR 장치와 구분되며 서로 연동될 수 있다. XR 영상을 제공하는 수단을 구비한 자율 주행 차량은 카메라를 포함하는 센서들로부터 센서 정보를 획득 하고, 획득한 센서 정보에 기초하여 생성된 XR 영상을 출력할 수 있다. 예컨대, 자율 주행 차량은 HUD를 구비하여 XR 영상을 출력함으로써, 탑승자에게 현실 객체 또는 화면 속의 객체에 대응되는 XR 객체를 제공할 수 있다. 이때, XR 객체가 HUD에 출력되는 경우에는 XR 객체의 적어도 일부가 탑승자의 시선이 향하는 실제 객체에 오버 랩되도록 출력될 수 있다. 반면, XR 객체가 자율 주행 차량(100b)의 내부에 구비되는 디스플레이에 출력되는 경 우에는 XR 객체의 적어도 일부가 화면 속의 객체에 오버랩되도록 출력될 수 있다. 예컨대, 자율 주행 차량 은 차로, 타 차량, 신호등, 교통 표지판, 이륜차, 보행자, 건물 등과 같은 객체와 대응되는 XR 객체들을 출력할 수 있다. XR 영상 내에서의 제어/상호작용의 대상이 되는 자율 주행 차량은 카메라를 포함하는 센서들로부터 센서 정보를 획득하면, 자율 주행 차량 또는 XR 장치는 센서 정보에 기초한 XR 영상을 생성하고, XR 장 치는 생성된 XR 영상을 출력할 수 있다. 그리고, 이러한 자율 주행 차량은 XR 장치 등의 외 부 장치를 통해 입력되는 제어 신호 또는 사용자의 상호작용에 기초하여 동작할 수 있다. 본 발명에 의한 VR (Virtual Reality) 기술, AR (Augmented Reality) 기술, MR (Mixed Reality) 기술은, 다양 한 디바이스에 적용 가능하며, 보다 구체적으로 예를 들면 HMD (Head-Mount Display), 차량(vehicle)에 부착된 HUD (Head-Up Display), 휴대폰, 태블릿 PC, 랩탑, 데스크탑, TV, 사이니지 등에 적용된다. 또한, 플렉서블, 롤러블 디스플레이를 장착한 디바이스에도 적용 가능하다. 나아가 전술한 VR 기술, AR 기술, MR 기술은 컴퓨터 그래픽을 기반으로 구현되며 사용자의 시야에 펼쳐지는 영 상에서 CG(Computer Graphic) 영상이 차지하는 비율에 따라 구분될 수도 있다. 즉, VR 기술은, 현실 세계의 객체나 배경 등을 CG 영상으로만 제공하는 디스플레이 기술이다. 반면, AR 기술은, 실제 사물 영상 위에 가상으로 만들어진 CG 영상을 함께 보여 주는 기술을 의미한다. 나아가, MR 기술은, 현실세계에 가상 객체들을 섞고 결합시켜서 보여준다는 점에서 전술한 AR 기술과 유사하다. 그러나, AR 기술에서는 현실 객체와 CG 영상으로 만들어진 가상 객체의 구별이 뚜렷하고, 현실 객체를 보완하는 형태로 가상 객체를 사용하는 반면, MR 기술에서는 가상 객체가 현실 객체와 동등한 성격으로 간주된다는 점에 서 AR 기술과는 구별이 된다. 보다 구체적으로 예를 들면, 전술한 MR 기술이 적용된 것이 홀로그램 서비스 이 다. 다만, 최근에는 VR, AR, MR 기술을 명확히 구별하기 보다는 XR (extended Reality) 기술로 부르기도 한다. 따 라서, 본 발명의 실시예들은 VR, AR, MR, XR 기술 모두에 적용 가능하다. 한편, VR, AR, MR, XR 기술에 적용되는 하드웨어(HW) 관련 요소 기술로서, 예를 들어 유/무선 통신 기술, 입력 인터페이스 기술, 출력 인터페이스 기술 및 컴퓨팅 장치 기술 등이 존재한다. 또한, 소프트웨어(SW) 관련 요소 기술로서, 예를 들어 추적 및 정합 기술, 음성 인식 기술, 상호 작용 및 사용자 인터페이스 기술, 위치기반 서 비스 기술, 검색 기술, AI (Artificial Intelligence) 기술 등이 존재한다. 특히, 본 발명의 실시예들은, 전술한 HW/SW 관련 요소 기술 등을 이용하여, 다른 디바이스와의 통신 문제, 효율 적인 메모리 사용 문제, 불편한 UX/UI로 인한 데이터 처리 속도가 낮아지는 문제, 영상 문제, 음향 문제, 멀미 현상 또는 기타 문제 중 적어도 하나를 해결하고자 한다. 도 13은 본 발명의 실시예들에 의한 XR 디바이스의 블록도를 도시한 도면이다. XR 디바이스는 카 메라, 디스플레이, 센서, 프로세서, 메모리 및 통신 모듈 등을 포함한다. 물론, 당업자의 필요에 따라 일부 모듈을 삭제, 변경, 추가하는 것도 본 발명의 권리범위에 속한다. 통신 모듈은 외부 장치 또는 서버와 유선/무선으로 통신을 수행하며, 근거리 무선 통신으로 예를 들어 Wi-Fi, 블루투스 등이 사용될 수 있고, 원거리 무선 통신으로 예를 들어 3GPP 통신 규격이 사용될 수 있다. LTE는 3GPP TS 36.xxx Release 8 이후의 기술을 의미한다. 세부적으로, 3GPP TS 36.xxx Release 10 이후의 LTE 기술은 LTE-A로 지칭되고, 3GPP TS 36.xxx Release 13 이후의 LTE 기술은 LTE-A pro로 지칭된다. 3GPP 5G (5th generation) 기술은 TS 36.xxx Release 15 이후의 기술 및 TS 38.XXX Release 15 이후의 기술을 의미하며, 이 중 TS 38.xxx Release 15 이후의 기술은 3GPP NR로 지칭되고, TS 36.xxx Release 15 이후의 기술은 enhanced LTE로 지칭될 수 있다. \"xxx\"는 표준 문서 세부 번호를 의미한다. LTE/NR은 3GPP 시스템으로 통칭될 수 있다. 카메라는 XR 디바이스 주변 환경을 촬영하여 전기적 신호로 변환할 수 있다. 카메라에서 촬 영되어 전기적 신호로 변환된 이미지는 메모리에 저장된 후 프로세서를 통해 디스플레이에서 디스플레이 될 수 있다. 또한, 상기 이미지는 상기 메모리에 저장 없이, 바로 프로세서를 이용하 여 디스플레이를 통해 디스플레이 될 수 있다. 또한, 카메라는 화각을 가질 수 있다. 이 때, 화각 은 예를 들어 카메라 주변에 위치하는 리얼 오브젝트를 디텍트할 수 있는 영역을 의미한다. 카메라 는 화각내에 위치하는 리얼 오브젝트만을 디텍트할 수 있다. 리얼 오브젝트가 카메라의 화각 내에 위치하는 경우, XR 디바이스는 리얼 오브젝트에 대응하는 증강 현실 오브젝트를 디스플레이 할 수 있다. 또한, 카메라는 카메라와 리얼 오브젝트의 각도를 디텍트할 수 있다. 센서는 적어도 하나의 센서를 포함할 수 있으며, 예를 들어, 중력(gravity) 센서, 지자기 센서, 모션 센 서, 자이로 센서, 가속도 센서, 기울임(inclination) 센서, 밝기 센서, 고도 센서, 후각 센서, 온도 센서, 뎁스 센서, 압력 센서, 벤딩 센서, 오디오 센서, 비디오 센서, GPS(Global Positioning System) 센서, 터치 센서 등 의 센싱 수단을 포함한다. 나아가, 디스플레이는 고정형일 수도 있으나, 높은 플렉시빌러티 (flexibility)를 갖도록 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diode), ELD(Electro Luminescent Display), M-LED(Micro LED)로 구현 가능하다. 이 때, 상기 센서는 전술한 LCD, OLED, ELD, M-LED (마이크로 LED) 등으로 구현된 디스플레이의 휘어짐, 벤딩(Bending) 정도를 디텍트 하도록 설 계한다. 그리고, 메모리는 카메라에 의해 촬영된 이미지를 저장하는 기능을 가지고 있을 뿐만 아니라, 외부 장치 또는 서버와 유선/무선으로 통신을 수행한 결과값의 전부 또는 일부를 저장하는 기능을 가지고 있다. 특 히, 통신 데이터 트래픽이 증가하는 추세(예를 들어, 5G 통신 환경에서)를 고려할 때, 효율적인 메모리 관리가 요구된다. 이와 관련하여, 이하 도 14에서 상세히 후술하도록 하겠다. 도 14는 도 13에 도시된 메모리를 보다 구체적으로 도시한 블록도이다. 이하, 도 14를 참조하여, 본 발 명의 일실시예에 따라 램 및 플래쉬 메모리 간의 스왑 아웃(swap out) 과정을 설명하도록 하겠다. 제어부는 램 내의 AR/VR 관련 페이지 데이터들을 플래시 메모리로 스왑 아웃할 때에, 스왑 아웃할 AR/VR 관련 페이지 데이터들 중에서 서로 내용이 동일한 둘 이상의 AR/VR 관련 페이지 데이터들에 대해 서는 오직 하나만을 플래시 메모리로 스왑 아웃할 수 있다. 즉, 제어부는 상기 스왑 아웃할 AR/VR 관련 페이지 데이터들의 내용을 각각 구별하는 구별값(예를 들어, 해쉬 함수)들을 계산하고, 상기 계산된 구별값들 중 서로 동일한 구별값을 가지는 둘 이상의 AR/VR 페이지 데이 터들의 내용이 서로 동일한 것으로 판단할 수 있다. 따라서, 불필요한 AR/VR 관련 페이지 데이터들이 플래쉬 메모리에 저장되어, 상기 플래쉬 메모리 뿐만 아니라 이를 포함하는 AR/VR 디바이스의 수명이 단축 되는 문제점을 해결할 수가 있다. 상기 제어부의 동작은 소프트웨어 형태로 구현할 수도 있고, 또는 하드웨어 형태로 구현하는 것도 본 발 명의 권리범위에 속한다. 나아가, 보다 구체적으로 도 14에 도시된 메모리 등은, HMD (Head-Mount Display), 차 량(vehicle), 휴대폰, 태블릿 PC, 랩탑, 데스크탑, TV, 사이니지 등에 포함되어, 스왑 기능을 수행한다. 한편, 본 발명의 실시예들에 따른 디바이스는3차원 포인트 클라우드 데이터를 처리하여VR, AR, MR, XR 및 자율 주행 서비스 등 다양한 서비스를 사용자에게 제공할 수 있다. 3차원 포인트 클라우드 데이터를 수집하는 센서는 예를 들어, LiDAR (light detection and ranging), RGB- D(Red Green Blue Depth), 3D 레이저 스캐너(Laser Scanner) 등이 될 수 있으며, 상기 센서는 HMD (Head-Mount Display), 차량(vehicle), 휴대폰, 태블릿 PC, 랩탑, 데스크탑, TV, 사이니지 등의 내부 또는 외부에 장착 가능 하다. 도 15는 포인트 클라우트 데이터 처리 시스템을 나타낸다. 도 15에 도시된 포인트 클라우드 처리 시스템은 포인트 클라우드 데이터를 획득하여 인코딩 처리하여 전 송하는 전송 디바이스 및 비디오 데이터를 수신하여 디코딩 처리하여 포인트 클라우드 데이터를 획득하는 수신 디바이스를 포함한다. 도 15에 도시된 바와 같이 본 발명의 실시예들에 따른 포인트 클라우드 데이터는 포인트 클라우드 데이터의 캡처, 합성 또는 생성 과정 등을 통하여 획득될 수 있다(S1510). 획득 과정에서 포인트들에 대한 3D 위치(x, y, z)/속성 (color, reflectance, transparency 등) 데이터 (예를 들어, PLY(Polygon File format or the Stanford Triangle format) 파일 등)이 생성될 수 있다. 여러 개의 프레임을 갖는 비디오의 경 우 하나 이상의 파일들이 획득될 수 있다. 캡처 과정에서 포인트 클라우드 데이터 관련 메타데이터 (예를 들어 캡처와 관련된 메타데이터 등)가 생성될 수 있다. 본 발명의 실시예들에 따른 전송 디바이스 또는 인코더는 Video-based Point Cloud Compression (V-PCC) 또는 Geometry-based Point Cloud Compression (G-PCC) 방식을 이용하여 포인트 클라우드 데이터를 인코딩하여 하나 또는 그 이상의 비디오 스트림들을 출력할 수 있다 (S1520). V-PCC는 HEVC, VVC 등의 2D 비디오 코덱 (video codec)을 기반으로 포인트 클라우드 데이터를 압축 하는 방법이고, G-PCC는 포인트 클라우드 데이터를 지오메트리 (geometry) 및 어트리뷰트(attribute) 두 가지 스트림으로 나누어 인코딩하는 방법이다. 지오메트리 스트림은 포인트들의 위치 정보를 재구성하고 인코딩하여 생성될 수 있으머, 어트리뷰트 스트림은 각 포인트와 연관된 속성 정보 (예를 들면 색상 등)를 재구성하고 인코 딩하여 생성될 수 있다. V-PCC의 경우, 2D 비디오와 호환 가능하나, V-PCC 처리된 데이터를 복구하는데 G-PCC 대비 더 많은 데이터(예를 들면, 지오메트리 비디오, 어트리뷰트(attribute) 비디오, 어큐판시(occupancy) 맵 비디오 및 부가 정보(auxiliary information))가 필요하여 서비스 제공 시 더 긴 지연시간이 발생할 수 있다. 출력된 하나 또는 그 이상의 비트 스트림들은 관련 메타데이터와 함께 파일 등의 형태 (예를 들면 ISOBMFF 등의 파일 포맷 등)로 인캡슐레이션되어 네트워크 또는 디지털 저장매체를 통해 전송될 수 있다(S1530). 본 발명의 실시예들에 따른 디바이스 또는 프로세서는 수신한 비디오 데이터를 디캡슐레이션 처리하여 하나 또 는 그 이상의 비트 스트림들을 및 관련 메타 데이터를 획득하고, 획득한 비트 스트림들을 V-PCC 또는 G-PCC 방 식으로 디코딩하여 3차원의 포인트 클라우드 데이터를 복원할 수 있다(S1540). 렌더러는 디코딩된 포인트 클라 우드 데이터를 렌더링하고 디스플레이부를 통해 사용자에게 VR/AR/MR/ 서비스에 맞는 콘텐트를 제공할 수 있다 (S1550). 도 15에 도시된 바와 같이, 본 발명의 실시예들에 따른 디바이스 또는 프로세서는 렌더링/디스플레이 과정에서 획득한 다양한 피드백 정보들을 송신 디바이스로 전달하거나, 디코딩 과정에 전달하는 피드백 프로세스를 수행 할 수 있다(S1560). 본 발명의 실시예들에 따른 피드백 정보는 헤드 오리엔테이션(Head Orientation) 정보, 사 용자가 현재 보고 있는 영역을 나타내는 뷰포트(Viewport) 정보 등을 포함할 수 있다. 피드백 프로세스를 통해 사용자와 서비스 (또는 콘텐트) 프로바이더 간의 상호작용이 이루어지므로, 본 발명의 실시예들에 따른 디바이 스는 보다 높은 사용자 편의가 고려된 다양한 서비스들을 제공할 수 있을 뿐만 아니라, 전술한 V-PCC 또는 G- PCC 방식을 이용하여 보다 빠른 데이터 처리 속도를 제공하거나 선명한 비디오 구성이 가능한 기술적 효과가 있 다. 도 16은 러닝 프로세서를 포함하는 XR 디바이스를 나타낸다. 이전 도 13과 대비하여, 러닝 프로세서 만 추가되었으므로, 다른 구성요소들은 도 13을 참조하여 해석 가능하므로 중복되는 설명은 생략한다. 도 16에 도시된 XR 디바이스는 학습모델을 탑재할 수 있다. 학습 모델은 하드웨어, 소프트웨어 또는 하드 웨어와 소프트웨어의 조합으로 구현될 수 있다. 학습 모델의 일부 또는 전부가 소프트웨어로 구현되는 경우 학 습 모델을 구성하는 하나 이상의 명령어(instruction)는 메모리에 저장될 수 있다. 본 발명의 실시예들에 따른 러닝 프로세서는 프로세서와 통신 가능하도록 연결될 수 있으며, 훈련 데이터를 이용하여 인공 신경망으로 구성된 모델을 반복적으로 학습시킬 수 있다. 인공신경망은 생물학적 뉴런 의 동작원리와 뉴런간의 연결 관계를 모델링한 것으로 노드(node) 또는 처리 요소(processing element)라고 하 는 다수의 뉴런들이 레이어(layer) 구조의 형태로 연결된 정보처리 시스템이다. 인공 신경망은 기계 학습에서사용되는 모델로써, 기계학습과 인지과학에서 생물학의 신경망(동물의 중추신경계 중 특히 뇌)에서 영감을 얻은 통계학적 학습 알고리즘이다. 기계 학습은 머신 러닝(Machine Learning)과 혼용되어 사용될 수 있다. 머신 러닝 은 인공지능(Artificial Intelligence, AI)의 한 분야로, 컴퓨터에 명시적인 프로그램 없이 배울 수 있는 능력 을 부여하는 기술이다. 머신 러닝은 경험적 데이터를 기반으로 학습을 하고 예측을 수행하고 스스로의 성능을 향상시키는 시스템과 이를 위한 알고리즘을 연구하고 구축하는 기술이다. 따라서 본 발명의 실시예들에 따른 러 닝 프로세서는 인공 신경망을 반복 학습시킴으로서, 인공 신경망의 최적화된 모델 파라미터들을 결정하여 새로운 입력 데이터에 대하여 결과 값을 추론할 수 있다. 따라서 러닝 프로세서는 사용자의 디바이스 사 용 히스토리 정보를 기반으로 사용자의 디바이스 사용 패턴을 분석할 수 있다. 또한, 러닝 프로세서는 데이터 마이닝, 데이터 분석, 지능형 의사 결정, 및 기계 학습 알고리즘 및 기술을 위해 이용될 정보를 수신, 분류, 저장 및 출력하도록 구성될 수 있다. 본 발명의 실시예들에 따른 프로세서는 러닝 프로세서에서 분석되거나 생성된 데이터를 기반으로 디바이스의 적어도 하나의 실행 가능한 동작을 결정 또는 예측할 수 있다. 또한 프로세서는 러닝 프로세 서의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 적어도 하나의 실행 가능한 동작 중 예측되는 동 작이나, 바람직한 것으로 판단되는 동작을 실행하도록 XR 디바이스를 제어할 수 있다. 본 발명의 실시예 들에 따른 프로세서는 지능적 에뮬레이션(즉, 지식 기반 시스템, 추론 시스템 및 지식 획득 시스템)을 구 현하는 다양한 기능을 수행 할 수 있다. 이는 적응 시스템, 기계 학습 시스템, 인공 신경망 등을 포함하는, 다 양한 유형의 시스템(예컨대, 퍼지 논리 시스템)에 적용될 수 있다. 즉, 프로세서는 러닝 프로세서 에서 사용자의 디바이스 사용 패턴을 분석한 데이터를 기반으로 추후 사용자 디바이스 사용 패턴을 예측하여 XR 디바이스는 사용자에게 보다 적합한 XR 서비스를 제공할 수 있도록 제어할 수 있다. 여기서의, XR 서비 스는 AR 서비스, VR 서비스, MR 서비스 중 적어도 하나 이상을 포함한다. 도 17은 도 16에 도시된 본 발명의 XR 디바이스가 XR 서비스를 제공하는 과정을 나타낸다. 본 발명의 실시예들에 따른 프로세서는 사용자의 디바이스 사용 히스토리 정보를 메모리에 저장할 수 있다(S1710). 디바이스 사용 히스토리 정보는 사용자에게 제공된 콘텐트 이름, 카테고리, 내용 등의 정보, 디바이스가 사용된 시간 정보, 사용자가 디바이스를 사용한 장소 정보, 시간 정보, 디바이스에 설치된 어플리케 이션 사용 정보 등을 포함할 수 있다. 본 발명의 실시예들에 따른 러닝 프로세서는 디바이스 사용 히스토리 정보를 분석하여 사용자의 디바이스 사용 패턴 정보를 획득할 수 있다(S1720). 예를 들어 XR 디바이스가 사용자에게 특정 콘텐트 A를 제공한 경우, 러닝 프로세서는 콘텐트 A에 대한 구체적인 정보 (예를 들면, 콘텐트 A를 주로 사용하는 사용자들 의 관한 나이 정보, 콘텐트 A의 내용 정보, 콘텐트 A와 유사한 콘텐트 정보 등), 해당 단말기를 사용하는 사용 자가 특정 콘텐트 A를 소비한 시간, 장소, 횟수 등의 정보를 총 종합하여, 사용자가 콘텐트 A를 해당 디바이스 에서 사용하는 패턴 정보를 학습할 수 있다. 본 발명의 실시예들에 따른 프로세서는 러닝 프로세서에서 학습한 정보를 기반으로 생성된 사용자 디바이스 패턴 정보를 획득하고, 디바이스 사용 패턴 예측 정보를 생성할 수 있다(S1730). 또한 프로세서(164 0)는 예를 들어, 사용자가 디바이스를 사용하지 않는 경우 사용자가 디바이스를 자주 사용했던 장 소에 있다고 판단되거나, 사용자가 디바이스를 주로 사용하는 시간에 가까운 경우, 프로세서는 디 바이스가 동작하도록 지시할 수 있다. 이 경우, 본 발명의 실시예들에 따른 디바이스는 사용자 패턴 예측 정보에 기반하여 AR 콘텐트를 제공할 수 있다(S1740). 또한 사용자가 디바이스를 사용하는 경우, 프로세서는 현재 사용자에게 제공되고 있는 콘텐트의 정 보를 파악하고, 해당 콘텐트와 관련된 사용자의 디바이스 사용 패턴 예측 정보(예를 들면 사용자가 다른 관련 콘텐트를 요청하거나 현재 콘텐트와 관련된 추가 데이터를 요청하는 경우 등)를 생성할 수 있다. 또한 프로세서 는 디바이스의 동작을 지시하여 사용자 패턴 예측 정보에 기반하여 AR 콘텐트를 제공할 수 있다 (S1740). 본 발명의 실시예들에 따른 AR 콘텐트는 광고, 네비게이션 정보, 위험 정보 등을 포함할 수 있다. 도 18은 XR 디바이스와 로봇의 외관을 도시하고 있다. 본 발명의 일실시예에 의한 XR 기술이 탑재된 디바이스의 구성 모듈에 대해서는 이전 도면들에서 상세히 설명한 바 중복되는 설명은 생략한다. 도 18에 도시된 로봇의 외관은 예시에 불과하며, 다양한 외관으로 본 발명의 로봇을 구현할 수 있다. 예 를 들어, 도 18에 도시된 로봇은, 드론, 청소기, 요리 로봇, 웨어러블 로봇 등이 될 수 있으며, 특히, 각 각의 구성요소는 로봇의 형상에 따라 상하좌우 전후 등에서 다른 위치에 배치될 수 있다. 로봇은 외부의 물체를 식별하기 위한 다양한 센서들을 로봇의 외부에 다수 배치할 수 있다. 또한 로봇은 사용자에게 소정의 정보를 제공하기 위해 인터페이스부를 로봇의 상부 또는 후면에 배치하였 다. 로봇의 이동과 주변의 사물을 감지하여 로봇을 제어하기 위해 로봇제어모듈이 로봇 내부에 탑재된 다. 로봇제어모듈은 소프트웨어 모듈 또는 이를 하드웨어로 구현한 칩 등으로 구현 가능하다. 로봇제어 모듈은 세부적으로 딥러닝부, 센싱정보처리부, 이동경로생성부, 통신 모듈 등을 더 포함할 수 있다. 센싱정보처리부는 로봇에 배치된 다양한 종류의 센서들(라이다 센서, 적외선 센서, 초음파 센서, 뎁스 센서, 이미지 센서, 마이크 등)이 센싱한 정보를 취합 및 처리한다. 딥러닝부는 센싱정보처리부가 처리한 정보 또는 로봇이 이동 과정에서 누적 저장한 정보 등 을 입력하여 로봇이 외부 상황을 판단하거나, 정보를 처리하거나, 이동 경로를 생성하는데 필요한 결과물 을 출력할 수 있다. 이동경로생성부는 딥러닝부가 산출한 데이터 또는 센싱정보처리부에서 처리한 데이터를 이용 하여 로봇의 이동 경로를 산출할 수 있다. 다만, XR 기술이 탑재된 디바이스 및 로봇은 모두 통신 모듈을 가지고 있으므로, Wi-Fi, 블루투스 등의 근거리 무선 통신이나 5G 원거리 무선 통신 등을 통하여, 데이터를 송수신 하는 것이 가능하다. XR 기술 이 탑재된 디바이스를 이용하여, 로봇을 제어하는 기술에 대해서는, 이하 도 19에서 후술하도록 한 다. 도 19는 XR 기술이 탑재된 디바이스를 이용하여, 로봇을 제어하는 과정을 도시한 플로우 차트이다. 우선, XR 기술이 탑재된 디바이스 및 로봇은 5G 네트워크로 통신 연결된다(S1901). 물론, 다른 근거리, 원거리 통신 기술을 통해 서로 데이터를 송수신하는 것도 본 발명의 권리범위에 속한다. 로봇은 내외부에 설치된 적어도 하나의 카메라를 이용하여 로봇 주변의 이미지 또는 영상을 캡쳐하고(S1902), 캡쳐된 이미지/영상을 XR 디바이스로 전송한다(S1903). XR 디바이스는 캡쳐된 이미지/영상을 디스플레이 하고 (S1904), 로봇을 제어하기 위한 커맨드를 로봇에 전송한다(S1905). 상기 커맨드는 XR 디바이스의 유저에 의해 수동으로 입력될 수도 있고, 또는 AI (Artificial Intelligent) 기술을 통해 자동으로 생성되는 것도 본 발명의 권리범위에 속한다. 로봇은 상기 S405 단계에서 수신한 커맨드에 따라 해당 기능을 실행하고(S1906), 결과값을 XR 디바이스에 전송 한다(S1907). 상기 결과값은, 통상의 데이터 처리 성공/실패 여부에 대한 인디케이터, 현재 촬영된 이미지/영 상 또는 XR 디바이스를 고려한 특정 데이터가 될 수도 있다. 상기 특정 데이터라 함은, 예를 들어 XR 디바이스 의 상태에 따라 변경되도록 설계한다. 만약, XR 디바이스의 디스플레이가 off 상태인 경우, XR 디바이스의 디 스플레이를 ON 시키는 커맨드를 S1907 단계에 포함시킨다. 따라서, 로봇 주변에 위급한 상황 발생시, 원격에 있는 XR 디바이스의 디스플레이가 꺼져 있어도, 알림 메시지가 전달될 수 있는 기술적 효과가 있다. 그리고, 상기 S1907 단계에서 수신한 결과값에 따라, AR/VR 관련 컨텐츠가 디스플레이 된다(S1908). 추가적으로 본 발명의 다른 일실시예에 의하면, 로봇에 부착된 GPS 모듈을 이용하여, XR 디바이스에서 로봇의 위치 정보를 디스플레이 하는 것도 가능하다. 도 13에서 설명한 XR 디바이스는 자율 주행 서비스를 제공하는 차량과 유/무선 통신이 가능하도록 연결되 거나, 자율 주행 서비스를 제공하는 차량에 탑재될 수 있다. 따라서 자율 주행 서비스를 제공하는 차량에서도 AR/VR를 포함한 다양한 서비스를 제공할 수 있다.도 20은 자율 주행 서비스를 제공하는 차량을 나타낸다. 본 발명의 실시예들에 따른 차량은 도로나 선로 위를 주행하는 수송 수단으로 자동차, 기차, 오토바이를 포함할 수 있다. 본 발명의 실시예들에 따른 차량은 동력원으로서 엔진을 구비하는 내연기관 차량, 동력 원으로서 엔진과 전기 모터를 구비하는 하이브리드 차량, 동력원으로서 전기 모터를 구비하는 전기 차량등을 모 두 포함할 수 있다. 본 발명의 실시예들에 따른 차량은 차량의 동작을 제어하기 위해 다음의 구성요소들을 포함할 수 있다: 사용자 인터페이스 장치, 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 구동 제어 장치, 자율 주 행 장치, 센싱부 및 위치 데이터 생성 장치; 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 구동 제어 장치, 자율 주행 장치, 센싱부 및 위치 데이터 생성 장치는 각각 전기적 신호를 생성하고, 상호간에 전기적 신호를 교환하는 전자 장치로 구현될 수 있 다. 사용자 인터페이스 장치는 사용자 입력을 수신하고, 사용자에게 차량에서 생성된 정보를 UI(User Interface) 또는 UX(User Experience)의 형식으로 제공할 수 있다. 사용자 인터페이스 장치는 입/출력 장치 및 사용자 모니터링 장치를 포함할 수 있다. 오브젝트 검출 장치는 차량 외부의 오브젝트의 존재유무를 검출 하고, 오브젝트에 대한 정보를 생성할 수 있다. 상기 오브젝트 검출 장치는, 예를 들어 카메라, 라이다, 적외 선 센서 및 초음파 센서 중 적어도 하나를 포함할 수 있다. 카메라는 영상을 기반으로 차량 외부의 오브 젝트 정보를 생성할 수 있다. 카메라는 하나 또는 그 이상의 렌즈들, 하나 또는 그 이상의 이미지 센서들 및 오 브젝트 정보를 생성하기 위한 하나 또는 그 이상의 프로세서들을 포함할 수 있다. 카메라는 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오브젝트와의 거리 정보 또는 오브젝트와의 상대 속도 정보를 획 득할 수 있다. 또한 카메라는 차량 외부를 촬영하기 위해 차량에서 FOV(field of view) 확보가 가능한 위치에 장착될 수 있으며, AR/VR을 기반으로 한 서비스를 제공하기 위해 사용될 수 있다. 라이다는 레이저 광을 이용 하여, 차량(K600) 외부의 오브젝트에 대한 정보를 생성할 수 있다. 라이다는 광 송신부, 광 수신부 및 광 송신 부 및 광 수신부와 전기적으로 연결되어 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 통신 장치는 차량 외부에 위치하는 디바이스(예를 들면, 인프라(예를 들면, 서버, 방송국), 타 차량, 단 말기등) 와 신호를 교환할 수 있다. 운전 조작 장치는 운전을 위한 사용자 입력을 수신하는 장치이다. 메뉴얼 모드인 경우, 차량은 운전 조작 장치에 의해 제공되는 신호에 기초하여 운행될 수 있다. 운전 조작 장치 는, 조향 입력 장치(예를 들면, 스티어링 휠), 가속 입력 장치(예를 들면, 가속 페달) 및 브레이크 입력 장치 (예를 들면, 브레이크 페달)를 포함할 수 있다. 센싱부는 차량의 상태를 센싱할 수 있으며 상태 정보를 생성할 수 있다. 위치 데이터 생성 장치는 차량 의 위치 데이터를 생성할 수 있다. 위치 데이터 생성 장치는, GPS(Global Positioning System) 및 DGPS(Differential Global Positioning System) 중 적어도 어느 하나를 포함할 수 있다. 위치 데이터 생성 장 치는, GPS 및 DGPS 중 적어도 어느 하나에서 생성되는 신호에 기초하여차량(K600)의 위치 데이터를 생성할 수 있다. 메인 ECU는 차량내에 구비되는 적어도 하나의 전자 장치의 전반적인 동작을 제어할 수 있으며, 구 동 제어 장치는 차량내 차량 구동 장치를 전기적으로 제어할 수 있다. 자율 주행 장치는 오브젝트 검출 장치, 센싱부, 위치 데이터 생성장치 등으로부터 획득된 데이터에 기초하여, 자율 주행 서비스를 위한 경로를 생성할 수 있다. 자율 주행 장치는, 생성된 경로를 따라 주행하기 위한 드라이 빙 플랜을 생성하고 드라이빙 플랜에 따른 차량의 움직임을 제어하기 위한 신호를 생성할 수 있다. 자율 주행 장치에서 생성된 신호는 구동 제어 장치에 전송되므로 구동 제어 장치는 차량의 내 차량 구동 장치를 제 어할 수 있다. 도 20에 도시된 바와 같이 자율 주행 서비스를 제공하는 차량은 XR 디바이스와 유/무선 통신이 가 능하도록 연결된다. 도 20에 도시된 XR 디바이스는 프로세서 및 메모리를 포함할 수 있다. 또한 도면에 도시되지 않았으나, 도 20의 XR 디바이스는 도 13에서 설명한 XR 디바이스의 구성요소 를 더 포함할 수 있다. 도 20의 XR 디바이스가 차량과 유/무선 통신이 가능하도록 연결된 경우, 도 20의 XR 디바이스 는 자율 주행 서비스와 함께 제공할 수 있는 AR/VR 서비스 관련 콘텐트 데이터를 수신/처리하여 차량 에 전송할 수 있다. 또한 도 20의 XR 디바이스가 차량에 탑재된 경우, 도 20의 XR 디바이스는 사용자 인터페이스 장치를 통해 입력된 사용자 입력 신호에 따라 AR/VR 서비스 관련 콘텐트 데이터를 수신/처리하여 사용자에게 제공할 수 있다. 이 경우, 프로세서는 오브젝트 검출 장치, 센싱부, 위치 데이 터 생성장치, 자율 주행 장치 등으로부터 획득된 데이터에 기초하여, AR/VR 서비스 관련 콘텐트 데이터를 수신/ 처리할 수 있다. 본 발명의 실시예들에 따른 AR/VR 서비스 관련 콘텐트 데이터는 운전 정보, 자율 주행 서비스 를 위한 경로 정보, 운전 조작 정보, 차량 상태 정보, 오브젝트 정보 등 자율 주행 서비스와 관련된 정보뿐 만 아니라 자율 주행 서비스와 관련 없는 엔터테인먼트 콘텐트, 날씨 정보 등을 포함할 수 있다. 도 21은 자율 주행 서비스 중 AR/VR 서비스를 제공하는 과정을 나타낸다. 본 발명의 실시예들에 따른 차량 또는 사용자 인터페이스 장치는 사용자 입력 신호를 수신할 수 있다(S2110). 본 발명의 실시예들에 따른 사용자 입력 신호는 자율 주행 서비스를 지시하는 신호를 포함할 수 있다. 본 발명 의 실시에들에 따른 자율 주행 서비스는 완전 자율 주행 서비스 및 일반 자율 주행 서비스를 포함할 수 있다. 완전 자율 주행 서비스는 도착지까지 사용자의 수동 주행 없이 완전히 자율 주행으로만 차량이 구동되는 서비스 를 의미하며, 일반 자율 주행 서비스는 도착지까지 사용자의 수동 주행과 자율 주행이 복합되어 차량이 구동되 는 서비스를 의미한다. 본 발명의 실시예들에 따른 사용자 입력 신호가 완전 자율 주행 서비스에 대응하는지 여부를 판단할 수 있다 (S2120). 판단 결과 사용자 입력 신호가 완전 자율 주행 서비스에 대응하는 경우, 본 발명의 실시예들에 따른 차량은 완전 자율 주행 서비스를 제공할 수 있다(S2130). 완전 자율 주행 서비스의 경우 사용자 조작이 필요없 으므로, 본 발명의 실시예들에 따른 차량은 차량의 창문, 사이드 미러, HMD, 스마트 폰 등을 통해 사용자에게 VR 서비스와 관련된 콘텐트를 제공할 수 있다(S2130). 본 발명의 실시예들에 따른 VR 서비스와 관련된 콘텐트는 완전 자율 주행과 연관된 콘텐트(예를 들면 네비게이션 정보, 운행 정보, 외부 오브젝트 정보 등)이 될 수도 있 고, 사용자의 선택에 따라 완전 자율 주행과 관련이 없는 콘텐트 (예를 들면 날씨 정보, 거리 이미지, 자연 이 미지, 화상 전화 이미지 등)이 될 수 있다. 판단 결과 사용자 입력 신호가 완전 자율 주행 서비스에 대응하지 않는 경우, 본 발명의 실시예들에 따른 차량 은 일반 자율 주행 서비스를 제공할 수 있다(S2140). 일반 자율 주행 서비스의 경우, 사용자의 수동 주행을 위 하여 사용자의 시야가 확보되어야 하므로, 본 발명의 실시예들에 따른 차량은 차량의 창문, 사이드 미러, HMD, 스마트 폰 등을 통해 사용자에게 AR 서비스와 관련된 콘텐트를 제공할 수 있다(S2140). 본 발명의 실시예들에 따른 AR 서비스와 관련된 콘텐트는 완전 자율 주행과 연관된 콘텐트(예를 들면 네비게이 션 정보, 운행 정보, 외부 오브젝트 정보 등)이 될 수도 있고, 사용자의 선택에 따라 완전 자율 주행과 관련이 없는 콘텐트 (예를 들면 날씨 정보, 거리 이미지, 자연 이미지, 화상 전화 이미지 등)이 될 수 있다. 도 22는 본 발명의 일실시예에 의한 XR 디바이스를 HMD 타입으로 구현한 경우를 도시하고 있다. 전술한 다양한 실시예들은 도 22에 도시된 HMD 타입으로 구현할 수도 있다. 도 22에 도시된 HMD 타입의 XR 디바이스(100a)는, 커뮤니케이션 유닛, 컨트롤 유닛, 메모리 유닛 , I/O 유닛(140a), 센서 유닛(140b), 그리고 파워 공급 유닛(140c) 등을 포함한다. 특히, XR 디바이스 (10a)내 커뮤니케이션 유닛은 모바일 터미날(100b)과 유무선 통신이 이루어 진다. 그리고, 도 23은 본 발명의 일실시예에 의한 XR 디바이스를 AR 글래스 타입으로 구현한 경우를 도시하고 있다. 전술한 다양한 실시예들은 도 44에 도시된 AR 글래스 타입으로 구현할 수도 있다. 도 23에 도시된 바와 같이, AR 글래스는 프레임, 제어부 및 광학 디스플레이부를 포함할 수 있다. 프레임은 도 23에 도시된 바와 같이, 사용자의 신체 중 안면에 착용되는 안경 형태를 가질 수 있으나, 이에 반드시 한정되는 것은 아니고, 사용자의 안면에 밀착되어 착용되는 고글 등의 형태를 가질 수도 있다. 이와 같은 프레임은 전면 프레임과 제1, 2 측면 프레임을 포함할 수 있다. 전면 프레임은 적어도 하나의 개구부를 구비하고, 제1 수평 방향(x)으로 연장될 수 있으며, 제1, 2 측면 프레임은 전면 프레임과 교차하는 제2 수평 방향(y)으로 연장되어 서로 나란하게 연장될 수 있다. 제어부는 사용자에게 보여질 이미지 또는 이미지가 연속되는 영상을 생성할 수 있다. 이와 같은 제어 부에는 이미지를 발생시키는 이미지 소스와 이미지 소스에서 발생된 빛을 확산 및 수렴하는 복수의 렌즈 등을 포함할 수 있다. 이와 같이 제어부에서 생성되는 이미지는 제어부와 광학 디스플레이부 사이에 위치하는 가이드 렌즈(P200)을 통해 광학 디스플레이부로 출사될 수 있다. 이와 같은 제어부는 제1, 2 측면 프레임 중 어느 하나의 측면 프레임에 고정될 수 있다. 일례로, 제어부 는 어느 하나의 측면 프레임 내측 또는 외측에 고정되거나, 어느 하나의 측면 프레임의 내부에 내장되어 일체로 형성될 수 있다. 광학 디스플레이부는 제어부에서 생성된 이미지가 사용자에게 보여지도록 하는 역할을 수행할 수 있으며, 이미지가 사용자에게 보여지도록 하면서, 개구부를 통하여 외부 환경을 볼 수 있도록 하기 위하여, 반투명 재질로 형성될 수 있다. 이와 같은 광학 디스플레이부는 전면 프레임에 포함된 개구부에 삽입되어 고정되거나, 개부구의 배면 [즉 개구부와 사용자 사이]에 위치하여, 전면 프레임에 고정되어 구비될 수 있다. 본 발명에서는 일례 로, 광학 디스플레이부가 개구부의 배면에 위치하여, 전면 프레임에 고정된 경우를 일예로 도시하였 다. 이와 같은 XR 디바이스는 도 23에 도시된 바와 같이, 제어부에서 이미지에 대한 이미지를 광학 디스플레이 부의 입사 영역(S1)으로 입사시키면, 이미지광이 광학 디스플레이부를 통하여, 광학 디스플레이부 의 출사 영역(S2)으로 출사되어, 제어부에서 생성된 이미지를 사용자에게 보여지도록 할 수 있다. 이에 따라, 사용자는 프레임의 개구부를 통하여 외부 환경을 보면서 동시에 제어부에서 생성된 이미지를 함께 볼 수 있다. 전술한 바와 같이, 본원 발명은 5G 통신 기술 분야, 로봇 기술 분야, 자율 주행 기술 분야 및 AI 기술 분야 모 두에 적용 가능하지만, 이하 도면들에서는 XR 디바이스, 디지털 사이니지 및 TV 등의 멀티미디어 디바이스에 적 용 가능한 본원 발명을 중점적으로 설명하도록 하겠다. 다만, 이전 도 1 내지 도 23을 참조하여, 후술할 도면 들을 당업자가 결합하여 다른 실시예를 구현하는 것도 본 발명의 권리범위에 속한다. 특히, 후술할 도면들에서 설명할 멀티미디어 디바이스는 디스플레이 기능이 있는 디바이스면 충분하므로, XR 디 바이스에 한정되지 않고, 이전 도 1 내지 도 9에서 설명한 UE (User Equipment)에 해당하여 5G 에 따른 통신을 추가적으로 수행하는 것도 가능하다. 또한， 이하에서는，디스플레이 디바이스로서 도 24에 도시된 XR 디바이스를 예로 들어 본 발명의 실시 예들을 설명하기로 한다. 그러나, 본 발명의 일 실시 예에 의한 XR 디바이스가 도 1 내지 도 23에 도시된 XR 디바이스 로 구현될 수도 있음은 물론이다. 도 24는 본 발명의 일 실시 예에 따른, XR 디바이스의 구성도를 도시한 도면이다. 도 24를 참조하면, XR 디바이스는 무선 통신부, 카메라, 마이크, 사용자 입력부, 센 서부, 디스플레이, 제어부를 포함한다. 무선 통신부는 외부 디바이스와 데이터를 송수신한다. 외부 디바이스는 외부 서버를 포함한다. 외부 서버는 필요한 경우, 제어부의 기능을 수행할 수 있다. 예를 들면, 제어부의 기능을 수행 할 때 배터리량이 부적한 경우, 더 빠른 연산 속도가 필요한 경우가 될 수 있다. 카메라는 XR 디바이스의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를 제외한 제 2 이미지를 캡쳐한다. 카메라는 TOF 카메라를 포함한다. TOF 카메라는 일반 카메라에 TOF 센서를 부착한 카메라를 의미한다. 구체적으로, 장면을 캡쳐해 보여주는 이미지센서는 2D 기반의 결과물을 도출한다. 여기에 TOF 센서가 개입하면 심도 측정이 가능해지면서 3D 결과물 을 구현할 수 있다. TOF (Time of Flight)는 음파나 광원을 피사체에 전송하고, 피사체를 거쳐 다시 돌아오는 시간을 의미한다. TOF 센서는 이러한 역할을 감지할 수 있는 부품의 일종이다. 뎁쓰 맵은 (depth map)은 3차원 컴퓨터 그래픽에서 관찰 시점(viewpoint)으로부터 물체 표면과의 거리와 관련된 정보가 담긴 하나의 이미지를 의미한다. TOF 카메라는 뎁쓰 맵을 포함하는 제 1 이미지를 캡쳐한다. TOF 카메라로 촬영을 하면, 원본 이미지, 뎁스 맵, 원본 이미지에 뎁스 맵을 적용한 결과 이미지를 획득한다. 마이크는 사용자의 음성을 수신한다. 구체적으로, 마이크는 외부의 음향 신호를 전기적인 음성 데이 터로 처리한다. 마이크는 마이크로폰의 약자이다. 처리된 음성 데이터는 XR 디바이스에서 수행중인 기능 또는 실행 중인 응용 프로그램에 따라 다양하게 활용될 수 있다. 한편, 마이크에는 외부의 음향 신호를 입력 받는 과정에서 발생되는 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알고리즘이 구현될 수 있 다 마이크은 사용자의 음성, 기타 소리 등을 입력 받도록 이루어진다. 마이크는 복수의 개소에 구비되어 스테레오 음향을 입력 받도록 구성될 수 있다. 사용자 입력부는 사용자로부터 정보를 입력받기 위한 것으로서, 사용자 입력부를 통해 정보가 입력되 면, 제어부는 입력된 정보에 대응되도록 XR 디바이스의 동작을 제어할 수 있다. 이러한, 사용자 입력 부는 기계식 (mechanical) 입력수단(또는, 메커니컬 키, 예를 들어, XR 디바이스의 전·후면 또는 측 면에 위치하는 버튼, 돔 스위치 (dome switch), 조그 휠, 조그 스위치 등) 및 터치식 입력수단을 포함할 수 있 다. 일 예로서, 터치식 입력수단은, 소프트웨어적인 처리를 통해 터치스크린에 표시되는 가상 키(virtual key), 소프트 키(soft key) 또는 비주얼 키(visual key)로 이루어지거나, 상기 터치스크린 이외의 부분에 배치되는 터 치 키(touch key)로 이루어질 수 있는 한편, 상기 가상키 또는 비주얼 키는, 다양한 형태를 가지면서 터치스크 린 상에 표시되는 것이 가능하며, 예를 들어, 그래픽(graphic), 텍스트(text), 아이콘(icon), 비디오(video) 또 는 이들의 조합으로 이루어질 수 있다. 센서부는 XR 디바이스를 착용한 사용자의 움직임을 센싱한다. 또한, 센서부는 XR 디바이스를 둘러싼 주변 환경 정보를 센싱한다. 여기서, 주변 환경 정보는 XR 디바이스의 변위(displacement)를 포함한다. 센서부 는 XR 디바이스 내 정보, XR 디바이스를 둘러싼 주변 환경 정보 및 사용자 정보 중 적어도 하나를 센싱하고, 이에 대응하는 센싱 신호를 발생시킨다. 제어부는 이러한 센싱 신호에 기초하여, XR 디바이스 의 구동 또는 동작을 제어하거나, XR 디바이스에 설치된 응용 프로그램과 관련된 데이터 처리, 기능 또는 동작을 수행 할 수 있다. 센서부에 포함될 수 있는 다양한 센서 중 대표적인 센서들의 대하여, 보다 구체적으로 살펴본다. 먼저, 근접 센서는 소정의 검출면에 접근하는 물체, 혹은 근방에 존재하는 물체의 유무를 전자계의 힘 또 는 적외선 등을 이용하여 기계적 접촉이 없이 검출하는 센서를 말한다. 이러한 근접 센서는 위에서 살펴본 터치 스크린에 의해 감싸지는 이동 단말기의 내부 영역 또는 상기 터치 스크린의 근처에 근접 센서가 배치 될 수 있다. 근접 센서의 예로는 투과형 광전 센서, 직접 반사형 광전 센서, 미러 반사형 광전 센서, 고주파 발진형 근 접 센서, 정전 용량형 근접 센서, 자기형 근접 센서, 적외선 근접 센서 등이 있다. 터치 스크린이 정전식인 경 우에, 근접 센서는 전도성을 갖는 물체의 근접에 따른 전계의 변화로 상기 물체의 근접을 검출하도록 구성 될 수 있다. 이 경우 터치 스크린(또는 터치 센서) 자체가 근접 센서로 분류될 수 있다. 한편, 설명의 편의를 위해, 터치 스크린 상에 물체가 접촉되지 않으면서 근접되어 상기 물체가 상기 터치 스크 린 상에 위치함이 인식되도록 하는 행위를 \"근접 터치(proximity touch)\"라고 명명하고, 상기 터치 스크린 상에 물체가 실제로 접촉되는 행위를 \"접촉 터치(contact touch)\"라고 명명한다. 상기 터치 스크린 상에서 물체가 근 접 터치 되는 위치라 함은, 상기 물체가 근접 터치될 때 상기 물체가 상기 터치 스크린에 대해 수직으로 대응되 는 위치를 의미한다. 상기 근접 센서는, 근접 터치와, 근접 터치 패턴(예를 들어, 근접 터치 거리, 근접 터치 방향, 근접 터치 속도, 근접 터치 시간, 근접 터치 위치, 근접 터치 이동 상태 등)을 감지할 수 있다. 한 편, 제어부는 위와 같이, 근접 센서를 통해 감지된 근접 터치 동작 및 근접 터치 패턴에 상응하는 데 이터(또는 정보)를 처리하며, 나아가, 처리된 데이터에 대응하는 시각적인 정보를 터치 스크린상에 출력시킬 수 있다. 나아가, 제어부는, 터치 스크린 상의 동일한 지점에 대한 터치가, 근접 터치인지 또는 접촉 터치인 지에 따라, 서로 다른 동작 또는 데이터(또는 정보)가 처리되도록 XR 디바이스를 제어할 수 있다. 터치 센서는 저항막 방식, 정전용량 방식, 적외선 방식, 초음파 방식, 자기장 방식 등 여러 가지 터치방식 중 적어도 하나를 이용하여 터치 스크린(또는 디스플레이부)에 가해지는 터치(또는 터치입력)을 감지한다. 일 예로서, 터치 센서는, 터치 스크린의 특정 부위에 가해진 압력 또는 특정 부위에 발생하는 정전 용량 등의 변화를 전기적인 입력신호로 변환하도록 구성될 수 있다. 터치 센서는, 터치 스크린 상에 터치를 가하는 터치 대상체가 터치 센서 상에 터치 되는 위치, 면적, 터치 시의 압력, 터치 시의 정전 용량 등을 검출할 수 있도록 구성될 수 있다. 여기에서, 터치 대상체는 상기 터치 센서에 터치를 인가하는 물체로서, 예를 들어, 손가락, 터 치펜 또는 스타일러스 펜(Stylus pen), 포인터 등이 될 수 있다. 이와 같이, 터치 센서에 대한 터치 입력이 있는 경우, 그에 대응하는 신호(들)는 터치 제어기로 보내진다. 터치 제어기는 그 신호(들)를 처리한 다음 대응하는 데이터를 제어부로 전송한다. 이로써, 제어부는 디스 플레이부의 어느 영역이 터치 되었는지 여부 등을 알 수 있게 된다. 여기에서, 터치 제어기는, 제어부 와 별도의 구성요소일 수 있고, 제어부 자체일 수 있다. 디스플레이는 투명한 부분을 포함하고, 캡쳐된 상기 이미지를 제어부로부터의 제어 명령에 따라 디스 플레이한다. 디스플레이는 프리즘을 이용하여 사용자의 눈으로 이미지를 투사할 수 있다. 또한, 사용자가 투사된 이미지와 전방의 일반 시야(사용자가 눈을 통하여 바라보는 범위)를 함께 볼 수 있도록, 프리즘은 투광 성으로 형성될 수 있다. 이처럼, 디스플레이를 통하여 출력되는 영상은, 일반 시야와 오버랩(overlap)되어 보여질 수 있다. XR 디 바이스는 이러한 디스플레이의 특성을 이용하여 현실의 이미지나 배경에 가상 이미지를 겹쳐서 하나의 영 상으로 보여주는 증강현실(Augmented Reality, AR)을 제공할 수 있다. 제어부는 캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 2 이미지 및 상기 센싱된 사용자의 움직임을 기 초로 사용자 행동을 예측하고, 예측된 상기 사용자 행동에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어한다. 구체적으로, 제어부는 캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 2 이미지 및 상기 센싱된 사용자의 움직임을 기초로 사용자 행동을 예측하고, 예측된 사용자 행동이 문제를 발생시키는지를 결정하고, 결정 결과에 따라서 제 1 가상 이미지를 렌더링하고, 렌더링된 상기 사용자 행동에 따라서, 상기 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어한다. 제어부는 예측된 사용자 행동이 문제를 발생시키는지를 단계 별로 결정한다. 예를 들어, 문제를 발생시키 는 단계를 5 단계로 나눌 수 있고, 제 1 단계에서 제 5 단계로 갈수록 위험 발생 가능성이 점점 높아진다. 제 1 단계는 사용자 행동이 사용자에게 문제가 발생할 수 있다는 것을 감지하는 단계를 의미하고, 제 5 단계는 사용 자 행동이 사용자를 위험 상태에 있는 것을 의미한다. 도 25는 본 발명의 일 실시 예에 따른, XR 디바이스 제어 방법의 순서도를 도시한 도면이다. 본 발명은 제어부 에 의하여 수행된다. 도 25를 참조하면, XR 디바이스의 정면에 있는 제 1 가상 오브젝트의 제 1 가상 이미지와 전체 이미지 중 제 1 가상 이미지를 제외한 제 2 이미지를 캡쳐한다. (S2510). XR 디바이스를 착용한 사용자의 움직임을 센싱한다(S2520). 캡쳐된 상기 제 1 가상 이미지, 캡쳐된 상기 제 2 이미지 및 상기 센싱된 사용자의 움직임을 기초로 사용자 행 동을 예측한다(S2530). 예측된 사용자 행동이 문제를 발생시키는지를 결정한다(S2540). 예측된 사용자 행동이 문제를 발생하면(S2550), 제 1 가상 이미지를 변경한다(S2560). 예측된 사용자 행동이 문제를 발생하지 않으면(S2550), S2510 단계로 재진입한다. 예측된 사용자 행동에 따라서, 디스플레이가 변경된 제 1 가상 이미지를 디스플레이하도록 제어한다(S2570). 도 26은 본 발명의 일 실시 예에 따른, XR 디바이스 제어 방법의 순서도를 도시한 도면이다. 도 26은 제어부 에 위하여 수행된다. XR 디바이스가 정상 동작한다(S2610). 센서에 기반하여 사용자 행동을 예측한다(S2615). 예를 들어, 제어부는 사용자와 오브젝트와의 거리 변화 를 기초로 사용자의 행동을 예측한다. 2차원 영상을 기초로 사용자의 행동을 예측한다. 사용자의 움직임을 센싱 한 센싱 결과를 기초로 사용자의 행동을 예측할 수 있다. 사용자가 제 1 가상 이미지에 반응하는지 확인한다(S2620). 사용자가 제 1 가상 이미지에 반응하면(S2620), 해당 사용자 반응이 문제를 발생하는지 확인한다(S2625). 해당 사용자 반응이 문제를 발생하지 않으면(S2625), S2610 단계로 재진입한다. 해당 사용자 반응이 문제를 발생하면(S2625), 제 1 가상 이미지가 가상임을 사용자에게 강조하는 영상 처리를 진행한다(S2630). 예를 들어, 제어부는 제 1 가상 이미지를 렌더링할 수 있다. 제 1 가상 이미지의 해상도를 저하한다(S2635). 사용자가 가상 이미지임을 감지하는지 확인한다(S2640). 사용자가 가상 이미지임을 감지한 것으로 확인되면(S2640), 종료한다. 사용자가 가상 이미지임을 감지한 것으로 확인되지 않으면(S2640), 제 1 가상 이미지의 칼라 해상도를 저하한다 (S2645). 사용자가 가상 이미지임을 감지하는지 확인한다(S2650). 사용자가 가상 이미지임을 감지한 것으로 확인되면(S2650), 종료한다. 사용자가 가상 이미지임을 감지한 것으로 확인되지 않으면(S2650), 제 1 가상 이미지의 투명도를 조절한다 (S2655). 사용자가 가상 이미지임을 감지하는지 확인한다(S2660). 사용자가 가상 이미지임을 감지한 것으로 확인되면(S2660), 종료한다. 사용자가 가상 이미지임을 감지한 것으로 확인되지 않으면(S2660), 제 1 가상 이미지를 화면에서 사라지도록 제 어한다(S2665). 사용자가 가상 이미지임을 감지하는지 확인한다(S2670). 사용자가 가상 이미지임을 감지한 것으로 확인되면(S2670), 종료한다. 사용자가 가상 이미지임을 감지한 것으로 확인되지 않으면(S2670), 경고 메시지를 발생한(S2675). 도 27은 본 발명의 일 실시 예에 따른, XR 디바이스를 AR 글래스 타입으로 구현한 구성도를 도시한 도면이다. 도 27을 참조하면, AR 글래스 타입의 XR 디바이스는 인체의 두부에 착용 가능하도록 구성되며, 이를 위한 프레임부(케이스, 하우징 등)을 구비할 수 있다. 프레임부는 착용이 용이하도록 플렉서블 재질로 형성될 수 있 다. 본 도면에서는, 프레임부가 서로 다른 재질의 제 1 프레임과 제 2 프레임을 포함하는 것을 예시 하고 있다. 프레임부는 두부에 지지되며, 각종 부품들이 장착되는 공간을 마련한다. 도시된 바와 같이, 프레임부에는 제어 부, 음향 출력 모듈 등과 같은 전자부품이 장착될 수 있다. 또한, 프레임부에는 좌안 및 우안 중 적 어도 하나를 덮는 렌즈가 착탈 가능하게 장착될 수 있다. 음악 출력 모듈는 스피커를 포함한다. 제어부는 이동 단말기에 구비되는 각종 전자부품을 제어하도록 이루어진다. 제어 모듈은 앞서 설명한 제어부에 대응되는 구성으로 이해될 수 있다. 본 도면에서는, 제어부가 일측 두부 상의 프레 임부에 설치된 것을 예시하고 있다. 하지만, 제어부의 위치는 이에 한정되지 않는다. 디스플레이부는 헤드 마운티드 디스플레이(Head Mounted Display, HMD) 형태로 구현될 수 있다. HMD 형태 란, 두부에 장착되어, 사용자의 눈 앞에 직접 영상을 보여주는 디스플레이 방식을 말한다. 사용자가 AR 글래스 타입의 이동 단말기를 착용하였을 때, 사용자의 눈 앞에 직접 영상을 제공할 수 있도록, 디스플레이부 는 좌안 및 우안 중 적어도 하나에 대응되게 배치될 수 있다. 본 도면에서는, 사용자의 우안을 향하여 영 상을 출력할 수 있도록, 디스플레이부가 우안에 대응되는 부분에 위치한 것을 예시하고 있다. 디스플레이부는 프리즘을 이용하여 사용자의 눈으로 이미지를 투사할 수 있다. 또한, 사용자가 투사된 이 미지와 전방의 일반 시야(사용자가 눈을 통하여 바라보는 범위)를 함께 볼 수 있도록, 프리즘은 투광성으로 형 성될 수 있다. 이처럼, 디스플레이부를 통하여 출력되는 영상은, 일반 시야와 오버랩(overlap)되어 보여질 수 있다. 이동 단말기는 이러한 디스플레이의 특성을 이용하여 현실의 이미지나 배경에 가상 이미지를 겹쳐서 하나의 영 상으로 보여주는 증강현실(Augmented Reality, AR)을 제공할 수 있다. 카메라는 좌안 및 우안 중 적어도 하나에 인접하게 배치되어, 전방의 영상을 촬영하도록 형성된다. 카메라 가 눈에 인접하여 위치하므로, 카메라는 사용자가 바라보는 장면을 영상으로 획득할 수 있다. 본 도면에서는, 카메라가 제어부에 구비된 것을 예시하고 있으나, 반드시 이에 한정되는 것은 아니다. 카메라는 프레임부에 설치될 수도 있으며, 복수 개로 구비되어 입체 영상을 획득하도록 이루어질 수도 있다. 글래스 타입의 이동 단말기는 제어명령을 입력 받기 위하여 조작되는 사용자 입력부(423a, 423b)를 구비할 수 있다. 사용자 입력부(423a, 423b)는 터치, 푸시 등 사용자가 촉각적인 느낌을 가면서 조작하게 되는 방식 (tactile manner)이라면 어떤 방식이든 채용될 수 있다. 본 도면에서는, 프레임부와 제어부에 각각 푸시 및 터치 입력 방식의 사용자 입력부(423a, 423b)가 구비된 것을 예시하고 있다. 또한, 글래스 타입의 이동 단말기에는 사운드를 입력 받아 전기적인 음성 데이터로 처리하는 마이크로폰 (미도시) 및 음향을 출력하는 음향 출력 모듈이 구비될 수 있다. 음향 출력 모듈은 일반적인 음향 출 력 방식 또는 골전도 방식으로 음향을 전달하도록 이루어질 수 있다. 음향 출력 모듈이 골전도 방식으로 구현되는 경우, 사용자가 이동 단말기를 착용시, 음향 출력 모듈은 두부에 밀착되며, 두개골을 진동 시켜 음향을 전달하게 된다. 도 28은 본 발명의 일 실시 예에 따른, 사용자가 가상 오브젝트를 실제 오브젝트로 오인지하는 것을 도시한 도 면이다. 도 28은 도 28(a), 도 28(b)를 포함한다. 도 28(a)는 사용자가 현실 컵을 가상 컵으로 오인지하는 것을 도시한 도면이다. 도 28(b)는 사용자가 가상 나무 를 오인지하고 기대는 것을 도시한 도면이다. 도 28(a)를 참조하면, 현실의 컵이 공중에서 떨어지는데, XR 디바이스를 착용한 사용자가 현실 의 컵을 가상 컵으로 오인하는 경우, 현실의 컵은 깨지게 된다. 도 28(b)를 참조하면, XR 디바이스를 착용한 사용자가 가상 나무를 현실 나무로 오인지하고 기 대는 동작을 하는 경우, 사용자가 기대는 위치에 가상 나무가 없기 때문에 사용자가 부상을 입을 수 있다. 도 29는 본 발명의 일 실시 예에 따른, 사용자가 가상의 오브젝트를 주변과 구분되는 모드로 설정하는 것을 도 시한 도면이다. 도 29는 도 29(a), 도 29(b)를 포함한다. 도 29(a)는 사용자가 XR 디바이스의 특정 버튼을 누르면, 컵 모양의 가상 이미지를 주변과 구분되는 모드 로 변경된 것을 도시한 도면이다. 가상 오브젝트를 주변과 구분되는 모드로 설정하는 XR 디바이스의 특정 버튼을 누르는 선택 입력을 사용자 로부터 수신하면, 제어부는 디스플레이가 제 1 가상 이미지 대신에 변경된 제 1 가상 이미지 를 주변 이미지와 구분 가능하게 디스플레이하도록 제어한다. 구체적으로, 제어부는 제 1 가상 이미지을 i) 해상도 저하, ii) 테두리 선 처리, iii) 오브젝트에 적용되는 빛의 방향을 다른 방식으로 디스플레이해서, 제 1 가상 이미지 데신 변경된 제 1 가상 이미지 를 주변 이미지와 구분 가능하게 디스플레이할 수 있다. 도 29(a)를 참조하면, 예를 들어, 제어부는 디스플레이가 컵 모양의 가상 이미지대신 윤곽을 강조한 가상 이미지를 도시하여, 주변 이미지와 구분 가능하게 디스플레이할 수 있다. 도 29(b)는 사용자가 가상 나무에 다가가면, 나무 이미지가 주변과 구분되는 가상 이미지로 변하는 것을 도시한 도면이다. 도 29(b)를 참조하면, 사용자가 가상 나무에 다가가서 기대는 동작을 하면, 제어부는 디스플레이가 가상 이미지를 반투명 상태로 디스플레이하도록 제어한다. 도 30은 본 발명의 일 실시 예에 따른, 클라우드 종류에 따른 실행할 수 있는 세부 기능을 설명한 도면이다. 도 30을 참조하면, 엣지 클라우드에서만 가능한 기능, 광역 도시망 클라우드에서 가능한 기능, 중 앙집중식 클라우드에서 가능한 기능이 있다. 엣지 클라우드에서만 가능한 기능은 4K 비디오 클릭에서 시작까지 기능, 게임 외 증강 현실 기능을 포함 한다. 광역 도시망 클라우드에서 가능한 기능 눈 깜박임 기능, 육상 출발 기능을 포함한다. 중앙 집중식 클라우드에서 가능한 기능은 메신저, 웹페이지 로딩을 포함한다. 도 31은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고, MR 현실을 보는 것을 도시한 도면이 다. 도 31을 참조하면, 사용자는 XR 디바이스를 착용하고 MR 현실을 시청한다. MR 현실은 Mixed Reality의 약자로, 실제 현실과 증강 현실이 혼합된 현실을 의미한다. 도 32는 본 발명의 일 실시 예에 따른, 사용자가 가상 오브젝트에 어떠한 동작을 취하는지 예상할 수 있는 기술 적 배경을 설명하는 것을 도시한 도면이다. 도 32는 도 32(a), 도 32(b) 및 도 32(c)를 포함한다. 도 32(a)는 XR 디바이스를 도시한 도면이다. 도 32(b)는 오브젝트를 감지하고, 3차원 SLAM을 구성하는 것을 도 시한 도면이다. 도 32(c)는 3차원 이미지를 디스플레이하는 것을 도시한 도면이다. 도 32(a)를 참조하면, XR 디바이스는 2차원 카메라, 3차원 카메라, 움직임 센서를 포함한다. XR 디바이스 는 2차원 카메라로 칼라 이미지를 획득하고, 3차원 카메라로 뎁스 이미지를 획득하고, 움직임 센서로 오브 젝트의 움직임 거리를 획득한다. 도 32(b)를 참조하면, XR 디바이스의 제어부는 칼라 이미지, 뎁스 이미지, 오브젝트의 움직임 거리를 기초로 이미지를 감지하고, 좌표를 생성한 후, 3차원 맵을 생성한다. 제어부는 생성된 3차원 맵을 렌더링한다. 제어부는 렌더링된 3차원 맵을 기초로 3차원 SLAM을 생성한다. 여기서, SLAM(Simultaneous localization and mapping), 동시적 위치 추정 및 지도 작성을 의미하고, SLAM은 로봇공학 등에서 사용하는 개념으로, 임의 공간에서 이동하면서 주변을 탐색할 수 있는 로봇에 대해, 그 공간의 지도 및 현재 위치를 추정하는 것을 의미 한다. 도 32(c)를 참조하면, 제어부는 렌더링된 3차원 이미지를 SLAM 위치에 맞게 배치한다. 도 33은 본 발명의 일 실시 예에 따른, 사용자 행동을 2D 이미지를 기초로 예측하는 것을 도시한 도면이다. 도 33은 도 33(a), 도 33(b) 및 도 33(c)를 포함한다. 도 33(a)는 사용자의 제 1 행동을 1초 전에 예상한 것과 실제 사용자의 제 1 행동을 도시한 도면이다. 도 33 (b)는 사용자의 제 2 행동을 1초 전에 예상한 것과 실제 사용자의 제 2 행동을 도시한 도면이다. 도 33(c)는 사 용자의 제 3 행동을 1초 전에 예상한 것과 실제 사용자의 제 3 행동을 도시한 도면이다. 도 33(a)를 참조하면, TV 드라마 화면 이미지를 기초로 화면 이미지를 분석하고, 제어부가 1초 전 예상한 행동은 kiss 이고, 실제로 다음 화면은 kiss 가 된다. 도 33(b)를 참조하면, TV 드라마 화면 이미지를 기초로 화면 이미지를 분석하고, 제어부가 1초 전 예상한 행동은 high five 이고, 실제로 다음 화면은 High five 가 된다. 도 33(c)를 참조하면, TV 드라마 화면 이미지를 기초로 화면 이미지를 분석하고, 제어부가 1초 전 예상한 행동은 Hug 이고, 실제로 다음 화면은 Hug 가 된다. 본 발명에 따르면, TV 드라마 화면을 이용하여 인공 지능을 훈련시키고, 다음 화면에 어떤 동작이나 물체가 나 올 지 예측할 수 있다. 도 34는 본 발명의 일 실시 예에 따른, 이미지를 분석하여 이미지 내부의 사람의 행동을 예측하는 것을 도시한 도면이다. 도 34를 참조하면, 제어부는 건널목이 서있는 사람이 신호등에 맞추어 횡단 보도를 건널지 아니면 무단 횡 단을 할 지를 화면 이미지를 기초로 미리 예측할 수 있다. 제 1 사용자의 경우, 화면 이미지를 기초로 제어부는 제 1 사용자가 무단 횡단을 할 확률이 80 % 라고 결정한다. 제 2 사용자의 경우, 화면 이미지를 기초로 제어부는 제 2 사용자가 무단 횡단을 할 확률이 50 %라고 결정한다. 제 3 사용자의 경우, 화면 이미지를 기초로 제어부는 제 3 사용자 가 무단 횡단을 할 확률이 10 %라고 결정한다. 제 4 사용자의 경우, 화면 이미지를 기초로 제어부는 제 4 사용자가 무단 횡단을 할 확률이 10 %라고 결정한다. 본 발명에 따르면, 캡쳐된 이미지를 이용하여 인공 지능을 훈련시키고, 소정 시간 후에 사용자가 어떤 행동을 할 지 예측할 수 있다. 도 35는 본 발명의 일 실시 예에 따른, 가속도 센서로 측정한 센서값을 FFT를 이용하여, 사용자 행동을 예측하 는 것을 도시한 도면이다. 도 35를 참조하면, 가속도 센서로 센싱한 센서값을 획득한다(S3510). 획득한 센서값을 프리 프로세싱한다(S3520). 프리 프로세싱된 센서값으로부터 주요 특징을 추출한다(S3530). 추출된 주요 특징을 분류화한다(S3540). 분류화된 주요 특징을 출력한다(S3550). 가속도 센서를 이용하여 사용자의 행동을 인식한다(S3560). 다음으로, 3축 움직임 센서에 기반하여 사용자 행동을 예측하는 것에 대하여 설명한다. 제어부는 센싱된 사용자의 움직임을 3축 가속도 센서를 이용하여 개별 행동 별로 DC 데이터를 추출하고, 추출된 상기 DC 데이터를 기초로 사용자 행동을 예측한다. 구체적으로, 제어부는 센싱된 사용자의 움직임을 3 축 가속도 센서를 이용하여 사용자의 행동 별로 DC 데 이터값을 추출하고, 추출된 상기 DC 데이터 값을 주파수 대역으로 변환하여 신호 해석을 실행하고, 상기 3 축의 개별 축마다 주파수 단위 별로 에너지 값과 축과 축 사이의 상관 관계를 계산하고, 계산된 상관 관계를 기초로 사용자 행동을 예측한다. 본 발명에 따르면, 3 축 가속도 센서를 이용하여 사용자 행동 인식을 하기 위해, 행동 별로 추출한 DC 데이터 값을 FFT 를 이용하여 주파수 대역으로 변환하고, 신호 해석을 통해 필요한 특징을 추출한다. 추출된 특징은 각 각의 사용자의 행동 별로 주파수 대역마다 크기 값이 다르게 분포된다. 이러한 크기 값에 대해 FFT를 통해 각 축을 주파수 단위 별로 에너지 값과 축과 축사이의 상관 관계를 계산하고, 계산된 상관 관계를 기초로 사용자의 행동을 예측할 수 있다. 도 36은 본 발명의 일 실시 예에 따른, FFT를 이용하여 사용자 행동을 예측하는 것을 도시한 도면이다. 그래프 에서, 가로축은 시간 축을 의미하고, 세로축은 에너지 축을 의미한다. 도 36을 참조하면, 각 축을 주파수 단위 별로, 에너지 값과 x 축, y 축, z 축 중 두 개의 축 사이의 상관 관계 를 계산하고, 계산된 상관 관계를 기초로 사용자의 행동을 예측할 수 있다. 도 37은 본 발명의 일 실시 예에 따른, 주파수를 기초로 사용자 행동을 예측하는 것을 도시한 도면이다. 도 37 은 도 37(a), 도 37(b), 도 37(c) 및 도 39(d)를 포함한다. 그래프에서, x 축은 시간 축을 의미하고, y 축은 에너지 축을 의미한다. 도 37(a)를 참조하면, 주파수를 기초로 예측한 사용자 행동은 앞으로 걷기를 의미한다. 도 37(b)를 참조하면, 주파수를 기초로 예측한 사용자 행동은 돌기를 의미한다. 도 37(c)를 참조하면, 주파수를 기초로 예측한 사용자 행동은 달리기를 의미한다. 도 37(d)를 참조하면, 주파수를 기초로 예측한 사용자 행동은 계단 내려가기를 의미 한다. 도 38은 본 발명의 일 실시 예에 따른, 주파수를 기초로 사용자 행동을 예측하는 것을 도시한 도면이다. 도 38 은 도 38(a), 도 38(b), 도 38(c) 및 도 38(d)를 포함한다. 그래프에서, x 축은 시간 축을 의미하고, y 축은 에너지 축을 의미한다. 도 38(a)를 참조하면, 주파수를 기초로 예측한 사용자 행동은 앉기를 의미한다. 도 38(b)를 참조하면, 주파수를 기초로 예측한 사용자 행동은 일어서기를 의미한다. 도 38(c)를 참조하면, 주파수를 기초로 예측한 사용자 행동 은 계단 오르기를 의미한다. 도 38(d)를 참조하면, 주파수를 기초로 예측한 사용자 행동은 엘리베이터 타기를 의미한다. 도 39는 본 발명의 일 실시 예에 따른, 제 1 오브젝트가 가상 오브젝트임을 사용자에게 알려주어야 하는 경우를 도시한 도면이다. 도 39는 도 39(a), 도 39(b)를 포함한다. 도 39(a)는 위협 상황으로 제 1 오브젝트가 가상 오브젝트 임을 사용자에게 알려주어야 하는 경우를 도시한 도 면이다. 도 39(a)를 참조하면, 사용자가 제 1 오브젝트를 보고 위협을 느끼는 상황이 될 수 있다. 예를 들어, 가상의 개 가 갑자기 등장하는 경우, 사용자는 가상의 개를 보고 놀랄 수 있다. 또한, 가상의 컵이 떨어져 깨지려고 하는 경우, 가상의 노트북이나 폰이 떨어져 망가지려 하는 경우, 주변 사람 이 가상의 표족한 물체에 닿으려고 하는 경우, 사자, 멧돼지 등과 같은 동물이 등장하는 경우, 칼이나 흉기를 소지한 가상의 사람이 등장하는 경우가 될 수 있다. 이러한 경우, 현실 세계에서 아무런 문제가 없는데 사용자 가 비명을 지르거나 주변 사람에게 가상의 물체를 조심하라고 경고할 문제가 있다. 또한, 그리고 사용자가 가상 의 위험 물체를 급히 피하려다 다칠 수 있다. 도 39(b)는 사용자가 제 1 가상 오브젝트와 관련된 특정 행동을 하면, 그 행동이 사용자에게 문제를 발생시킨다 고 결정하는 실시 예를 도시한 도면이다. 도 39(b)를 참조하면, 제어부는 사용자가 제 1 가상 오브젝트와 관련된 특정 행동을 하면, 디스플레이가 변경된 제 1 가상 이미지를 디스플레이하도록 제어한다. 예를 들어, 사용자가 가상의 나무에 기대려고 하는 경우, 제어부는 기대는 행동이 사용자에 게 문제를 발생시킨다고 결정하고, 디스플레이가 변경된 가상 나무 이미지를 디스플레이하도록 제어한다. 구체적으로, 사용자가 가상의 의자에 앉으려고 하는 경우, 사용자가 가상의 컵을 집으려고 경우, 사용자가 가상 의 오토바이를 타려고 하는 경우, 사용자가 말을 타려고 하는 경우, 사용자가 가상의 계단, 가상의 바위를 올라 가려고 하는 경우가 될 수 있다. 본 발명에 따르면, 사용자가 형체가 없는 가상의 물체에 특정 행동을 가하다 중심을 잃고 다칠 위험이 있는데, 이러한 경우, 변경된 가상 이미지를 디스플레이하여 안전 사고를 예방할 수 있다. 도 40은 본 발명의 일 실시 예에 따른, 변경된 제 1 가상 이미지를 단계별로 디스플레이하는 것을 도시한 도면 이다. 도 40은 도 40(a), 도 40(b), 도 40(c), 도 40(d) 및 도 40(e)를 포함한다. 도 40(a)는 원본 가상 이미지를 도시한 도면이다. 도 40(b)는 원본 가상 이미지의 해상도를 저하한 가상 이미지 를 도시한 도면이다. 도 40(c)는 원본 가상 이미지의 칼라 해상도를 적용한 가상 이미지를 도시한 도면이다. 도 40(d)는 원본 가상 이미지에 투명화를 적용한 가상 이미지를 도시한 도면이다. 도 40(e)는 원본 가상 이미지를 제거한 도면이다. 도 40을 참조하면, 제 1 가상 이미지를 단계별로 디스플레이하는 것에 대하여 설명한다. 제어부는 디스플 레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어한다. 즉, 도 40(a)를 참조하면, 처음에는 원본 가상 이미지를 디스플레이한다. 도 40(b)를 참조하면, 사용자가 인지를 못하면, 원본 가상 이미지 대신 원본 가상 이미지의 해상도를 저하한 가상 이미지를 디스플 레이한다. 도 40(c)를 참조하면, 사용자가 인지를 하지 못하면 원본 가상 이미지의 칼라 해상도를 적용한 가상 이미지를 디스플레이한다. 원본 가상 이미지의 칼라 해상도를 적용한 것은 원본 가상 이미지의 칼라를 변 경하고, 해상도를 저하한 것을 의미한다. 도 40(d)를 참조하면, 사용자가 인지를 못하면, 원본 가상 이미지에 투명화를 적용한 가상 이미지를 디스 플레이하고, 도 40(e)를 참조하면, 원본 가상 이미지를 제거한 도면을 디스플레이한다. 즉, 원본 가상 이미지 -> 해상도가 저하된 가상 이미지 -> 칼라 해상도가 저하된 가상 이미지 -> 투명화를 적용 한 가상 이미지 -> 가상 이미지 제거 순으로 진행된다. 본 발명에 따르면, 사용자의 몰입감을 저하시키지 않기 위해서, 처음에는 사용자에게 최소한의 변경된 가상 이 미지를 보여주다가, 사용자가 가상 이미지로 가상 오브젝트임을 인지할 때까지, 점차적으로 가상 이미지임을 강 조하는 가상 이미지를 보여준다. 다음으로, 해당 사용자가 가장 잘 인식하는 가상 이미지의 레벨을 학습하고, 가상 이미지를 다시 디스플레이하 는 경우, 해당하는 레벨부터 적용하는 실시 예에 대하여 설명한다. 제어부는 디스플레이가 변경된 상기 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도 록 제어하고, 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하고, 디스플레이가 변경된 상 기 제 1 가상 이미지를 결정된 상기 특정 레벨부터 디스플레이하도록 제어한다. 예를 들어, 가상 이미지가 변경됨에 따라서 제 1 레벨, 제 2 레벨, 제 3 레벨, 제 4 레벨, 제 5 레벨이 있을 수 있다. 제 1 레벨은 원본 가상 이미지를 의미하고, 제 2 레벨은 해상도가 저하된 가상 이미지를 의미하고, 제 3 레벨은 칼라 해상도가 저하된 가상 이미지를 의미하고, 제 4 레벨은 투명화를 적용한 가상 이미지 를 의미하고, 제 5 레벨은 가상 이미지 제거가 된 것을 의미한다. 제어부는 제 1 가상 이미지를 제 1 단계 내지 제 5 단계 별로 상이하게 디스플레이하도록 제어하고, 5 단 계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정한다. 예를 들어, 사용자가 가장 잘 인식하는 단계가 3 단계 로 결정된 경우, 제어부는 변경된 제 1 가상 이미지를 제 3 단계부터 디스플레이하도록 제어한다. 즉, 원 본 가상 이미지에서 바로 칼라 해상도가 저하된 가상 이미지를 디스플레이한다. 본 발명의 경우, 복수의 사용자가 XR 디바이스를 사용할 때, 복수의 사용자 중 특정 사용자가 가장 잘 인식하는 가상 이미지 레벨을 학습한 후, 나중에 특정 사용자가 XR 디바이스를 착용하면, 그 레벨부터 가상 이미지를 디 스플레이할 수 있다. 따라서, 특정 사용자가 가상 이미지를 보다 신속하고 정확하게 인식할 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 다음으로, 사용자가 위험하다고 결정되면, 제 1 가상 이미지를 사라지게 하는 실시 예에 대하여 설명한다. 도 40(e)를 참조하면, 제어부는 예측된 사용자 행동을 기초로 사용자가 위험하다고 결정되면, 디스플레이 가 제 1 가상 이미지를 사라지도록 제어한다. 사용자가 가상 이미지 임을 인지하지 못하고, 가상 이미지에 대한 특정 행동을 계속하면, 사용자가 위험할 수 있다. 제어부는 예측된 사용자 행동을 기초로 사용자가 계속하여 특정 행동을 계속하면, 계속 사용자가 위 험하다고 결정하고, 가상 이미지를 사라지도록 제어한다. 본 발명에 따르면, 사용자는 가상 이미지가 더 이상 보이지 않게 되어 위험 상황에서 특정 행동을 중지할 수 있 으므로 사고 예방을 할 수 있다. 도 41은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 현실 방을 바라볼 때, 현실 방에 가상 이미지가 적용된 것을 도시한 도면이다. 도 41은 도 41(a), 도 41(b)를 포함한다. 도 41(a)는 현실 방을 도시한 도면이다. 도 41(b)는 사용자가 XR 디바이스를 착용하고, 현실 방을 바라볼 때, 현실 방에 가상 이미지가 적용된 것을 도시한 도면이다. 도 41(a)를 참조하면, 현실의 방에는 가상 이미지가 적용되지 않은 실제 의자가 있다. 도 41(b)를 참조하면, 사용자가 XR 디바이스를 착용하고, 현실 방을 바라볼 때, 현실 방에 가상 이미 지가 적용된다. 사용자는 평범한 자신의 방을 XR 디바이스를 이용하여 가상 이미지가 적용된 예쁜 방으로 꾸밀 수 있다. 예를 들어, 의자 이미지는 혼합 이미지로 실제 의자 아랫 부분 이미지와 가상 의자 등받이 이미지 가 결합되어 구성된다. 호박 마차 이미지는 100 % 가상 이미지로 구성된다. 실제 이미지는 현실 오브젝트가 존재하는 이미지이고, 가상 이미지는 현실 오브젝트가 존재하지 않는 이미지이 고, 혼합 이미지는 실제 이미지와 가상 이미지가 혼합된 이미지이다. 예를 들어, 의자 이미지(30, 32)는 실제 의자와 가상 등받이 이미지가 혼합된 이미지이고, 호박 마차 이미지 는 실제 호박 마차가 존재하지 않으며, 100 % 가상 이미지이다. 도 42는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 현실 의자를 바라볼 때, 현실 의자 방 에 가상 이미지가 적용된 것을 도시한 도면이다. 도 42는 도 42(a), 도 42(b)를 포함한다. 도 42(a)는 현실 의자를 도시한 도면이다. 도 42(b)는 사용자가 XR 디바이스를 착용하고, 현실 의자를 바라볼 때, 현실 의자에 가상 이미지가 적용된 것을 도시한 도면이다. 도 42(a)를 참조하면, 현실의 방에는 가상 이미지가 적용되지 않은 실제 의자가 있다. 도 42(b)를 참조하면, 사용자가 XR 디바이스를 착용하고, 현실 의자를 바라볼 때, 현실 의자 에 가상 이미지가 적용된다. 사용자는 평범한 자신의 의자를 XR 디바이스를 이용하여 가상 이미지(3 2)가 적용된 멋진 의자로 꾸밀 수 있다. 예를 들어, 의자 이미지(30, 32)는 실제 의자와 가상 등받이 이미지가 혼합된 이미지이다. 즉, 의자 이 미지(30, 32)는 사용자가 앉을 수 있는 부분에 대응하는 실제 이미지와 사용자가 기댈 수 있는 등받이 부분 에 대응하는 가상 이미지가 혼합된 혼합 이미지이다. 따라서, 사용자가 가상 이미지 부분을 실제 오브젝트로 오인하고, 실제고 기대는 행동을 하는 경우, 사고 발생 위험이 있다. 도 43은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 가상 이미지로 다가갈 때, 가상 이미 지가 변하는 것을 도시한 도면이다. 도 43은 도 43(a), 도 43(b)를 포함한다. 도 43(a)는 사용자가 가상 호박 마차 이미지로 다가가는 것을 도시한 도면이다. 도 43(b)는 사용자가 가상 호박 마차 이미지로 가까이 다가갈 때 가상 호박 마차 이미지의 해상도를 저하시킨 것을 도시한 도면이다. 도 43(a)를 참조하면, 사용자가 가상 호박 마차 이미지로 접근한다. 이러한 경우, 실물 형체가 전혀 없 는 가상 호박 마차 이미지를 현실의 마차로 오해하고 사용자가 올라가거나 기댈 수 있어서 사용자가 부상을 당할 수 있는 위험이 있다. 도 43(b)를 참조하면, 사용자가 가상 호박 마차 이미지로 더욱 가까이 접근한다. 이러한 경우, 제어부 는 접근 거리를 기초로 가상 호박 마차 이미지의 해상도를 저하시켜서 사용자가 가상 이미지임을 인지 할 수 있도록 한다. 도 44는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 가상 이미지로 계속하여 다가갈 때, 가상 이미지가 변하는 것을 도시한 도면이다. 도 44는 도 44(a), 도 44(b), 도 44(c)를 포함한다. 도 44(a)는 사용자가 가상 호박 마차 이미지로 다가가는 것을 도시한 도면이다. 도 44(b)는 사용자가 가상 호박 마차 이미지로 가까이 다가갈 때 가상 호박 마차 이미지의 칼라 해상도를 저하시킨 것을 도시한 도면이다. 도 44(c)는 사용자가 가상 호박 마차 이미지로 더욱 가까이 다가갈 때 가상 호박 마차 이미지를 투명화하고, 사 용자가 더 접근하면 가상 호박 마차 이미지를 제거하는 것을 도시한 도면이다. 도 44(a)를 참조하면, 사용자가 가상 호박 마차 이미지로 접근한다. 이러한 경우, 실물 형체가 전혀 없 는 가상 호박 마차 이미지를 현실의 마차로 오해하고 사용자가 올라가거나 기댈 수 있어서 사용자가 부상을 당할 수 있는 위험이 있다. 이러한 경우, 제어부는 가상 호박 마차 이미지의 해상도를 저하시켜서 사 용자가 가상 이미지임을 인지할 수 있도록 한다. 사용자는 해상도가 저하된 가상 호박 마차 이미지를 보고 가상 이미지임을 인지할 수 있다. 도 44(b)를 참조하면, 사용자가 가상 호박 마차 이미지로 가까이 접근한다. 이러한 경우, 제어부 는 가상 호박 마차 이미지의 칼라 해상도를 저하시켜서 사용자가 가상 이미지임을 인지할 수 있도록 한다. 사용자는 칼라 해상도가 저하된 가상 호박 마차 이미지를 보고 가상 이미지임을 인지할 수 있다. 도 44(c)를 참조하면, 사용자가 가상 호박 마차 이미지로 더욱 가까이 접근한다. 이러한 경우, 제어부 는 가상 호박 마차 이미지를 반투명화시켜서 사용자가 가상 이미지임을 인지할 수 있도록 한다. 사용 자는 반투명화가 적용된 가상 호박 마차 이미지를 보고 가상 이미지임을 인지할 수 있다. 반투명화를 적용한다는 것은 가상 이미지의 투명도를 50 % 로 설정한다는 것을 의미한다. 사용자가 반투명 화가 적용된 가상 호박 마차 이미지를 보고도 계속 접근하면, 제어부는 가상 호박 마차 이미지를 화면에서 사라지도록 제어한다. 다음으로, 사용자와 제 1 가상 오브젝트 사이의 거리를 기초로 제 1 가상 이미지를 디스플레이하는 실시 예에 대하여 설명한다. 제어부는 사용자와 제 1 가상 오브젝트 사이의 거리를 기초로 디스플레이가 변경된 제 1 가상 이미지 를 디스플레이하도록 제어한다. 예를 들어, 제어부는 사용자와 가상 호박 마차 사이의 거리를 기초로 디스플레이가 변경된 가상 호박 마차 이미지를 단계 별로 다르게 디스플레이하도록 제어한다. 그리고, 제어부는 사용자와 가상 호박 마차 사이의 거리를 기초로 사용자가 위험하다고 결정 되면, 디스플레이가 가상 호박 마차 이미지를 화면에서 사라지도록 제어한다. 본 발명에 따르면, 사용자가 가상 호박 마차 이미지를 인지하지 못하고 여전히 접근할 수 있다. 이는 사용자의 부주의, 나쁜 시력, 색맹 등을 원인으로 이를 인지하지 못하고 물체를 만지거나 기대려는 행동을 계속할 수 있 다. 따라서, 제어부는 가상 이미지임을 암시하는 단계를 변경시켜서 사용자에게 가상 이미지임을 알려주고 인지를 못하는 사용자 피드백이 계속되면 가상 이미지를 화면에서 사라지게 한다. 도 45는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 가상 이미지로 다가갈 때, 가상 이미 지가 변하는 것을 도시한 도면이다. 도 45는 도 45(a), 도 45(b)를 포함한다. 도 45(a)는 사용자가 가상 의자 이미지(30, 32)로 다가가는 것을 도시한 도면이다. 도 45(b)는 사용자가 가상 의자 이미지로 가까이 다가갈 때 가상 의자 이미지 중 등받이 부분 이미지를 제거한 것을 도시한 도면이다. 도 45(a)를 참조하면, 사용자가 가상 의자 이미지(30, 32)로 접근한다. 이러한 경우, 가상 의자 이미지(30, 32)에서, 의자의 다리 부분은 실체가 있으나 의자의 등받이 부분는 실체가 없다. 따라서, 사용자가 가 상 의자 이미지(30, 32)에 앉아서 뒤로 기대는 경우, 사용자가 부상을 당할 수 있는 위험이 있다. 도 45(b)를 참조하면, 사용자가 가상 의자 이미지(30, 32)로 가까이 접근한다. 이러한 경우, 제어부는 가상 의자 이미지(30, 32) 중 등받이 부분의 이미지를 사라지도록 해서 사용자가 가상 이미지임을 인지할 수 있 도록 한다. 사용자는 등받이 부분의 이미지가 제거된 의자 이미지를 보고 등받이 부분이 가상 이미 지임을 인지할 수 있다. 따라서, 사용자가 가상 의자 이미지(30, 32)에 앉아서 뒤로 기대지 않으므로 사용자가 부상을 당할 수 있는 위 험을 방지할 수 있다. 도 46은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 운동을 할 때, 배경에 가상 이미지가 적용된 것을 도시한 도면이다. 도 46는 도 46(a), 도 46(b)를 포함한다. 도 46(a)는 사용자가 공원에서 산책하며 실제 공간에서 실제 오브젝트를 보는 것을 도시한 도면이다. 도 46(b) 는 사용자가 공원에서 산책하며 가상 이미지가 적용된 공간에서 실제 오브젝트를 보는 것을 도시한 도면이다. 도 46(a)를 참조하면, 사용자는 공원 공간에서 산책하면서 실제 사람 오브젝트(11, 12, 13)를 본다. 이 러한 경우, 사람은 평소 산책하는 공간이 지겨워서 XR 디바이스의 특정 버튼을 눌러서 눈에 보이는 공간을 다른 공간을 변경할 수 있다. 도 46(b)를 참조하면, 사용자는 XR 디바이스의 특정 버튼을 눌러서 가상 이미지가 적용된 공간에 서 산책할 수 있다. 이 경우, 배경만 가상 이미지가 적용된 공간이고, 실제 사람 오브젝트(11, 12, 13)는 그대로 유지된다. 본 발명에 따르면, 사용자는 현실의 사람 오브젝트(11, 12, 13)와 가상 이미지가 적용된 배경이 혼합 된 혼합 현실(MR, Mixed Reality)을 체험할 수 있다. 도 47은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용한 상태에서 가상 이미지를 보고 놀라는 행 동을 하면, 가상 이미지가 다르게 디스플레이되는 것을 도시한 도면이다. 도 47은 도 47(a), 도 47(b)를 포함한 다. 도 47(a)는 사용자가 공원에서 산책하다가 가상 이미지를 보고 놀라는 것을 도시한 도면이다. 도 47(b)는 사용 자가 공원에서 산책하다가 가상 이미지를 보고 놀라서 가상 이미지로부터 더욱 멀어지는 것을 도시한 도면이다. 도 47(a)을 참조하면, 사용자가 공원에서 산책하는 중에, 가상의 사자가 갑자기 나타난 경우, 사용자 는 가상 사자 이미지를 보고 놀랄 수 있다. 도 47(b)를 참조하면, 사용자가 제 1 가상 오브젝트를 보고 놀라는 행동을 하면, 제어부는 디스플 레이가 변경된 제 1 가상 이미지를 디스플레이하도록 제어한다. 예를 들어, 사용자가 가상 사자 이미지를 보고 놀라는 행동을 하면, 제어부는 변경된 가상 사자 이미지를 디스플레이한다. 여기서, 변경된 가상 사자 이미지는 해상도가 저하된 가상 사자 이미지, 칼라 해상도가 저하된 가상 사자 이미지를 포함한다. 놀라는 행동은 사용자가 갑자기 진행 방향을 바꾸는 경우, 사용자가 소리를 지르며 소정 시간 동안 진행을 멈추 는 행동을 경우, 사용자가 소정 시간 동안 움직이지 않은 경우, 사용자가 소정 시간 동안 두려움에 떠는 경우 등이 될 수 있다. XR 디바이스의 센서부는 사용자의 놀라는 행동을 센싱할 수 있다. 본 발명에 따르면, 제어부는 사용자가 가상 사자 이미지로부터 멀어지는 행동을 하고, 사용자가 사자 에게 두려움을 느끼고 있다는 것이 센서부를 통하여 감지가 되면, 가상 사자 이미지의 해상도를 저하 시켜서 가상 사자라는 것을 사용자에게 알려준다. 본 발명의 일 실시 예 따르면, 사용자가 위험 상황을 인지했다고 결정되면, 원본 가상 이미지를 다시 디스플레 이할 수 있다. 예를 들어, 제어부는 디스플레이가 변경된 상기 제 1 가상 이미지를 디스플레이하도록 제어하고 소정 시간 이내에 상기 사용자와 상기 제 1 오브젝트와의 거리가 이전 거리보다 가까워지면, 변경 전의 상기 제 1 가 상 이미지를 디스플레이하도록 제어한다. 여기서, 사용자가 인지한다는 것은 사용자가 가상 이미지임을 깨닫고 놀란 행동을 하는 것을 중지하는 것을 의 미한다. 즉, 사용자와 가상 이미지 사이의 제 1 거리가 계속하여 증가하였다가 사용자가 가상 이미지임을 인지 하게 되면, 제 1 거리가 증가하지 않는다. 본 발명에 따르면, 사용자가 위험 상황을 인지했다고 결정되면, 원본 가상 이미지를 디스플레이하여 사용자의 몰입감을 증가시킬 수 있다. 도 48은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용한 상태에서 가상 이미지를 보고 놀라는 행 동을 계속적으로 하면, 가상 이미지가 다르게 디스플레이되는 것을 도시한 도면이다. 도 48은 도 48(a), 도 48(b), 도 48(c), 도 48(d) 및 도 48(e)를 포함한다. 도 48(a)는 원본 가상 이미지를 도시한 도면이다. 도 48(b)는 원본 가상 이미지의 해상도를 저하한 가상 이미지 를 도시한 도면이다. 도 48(c)는 원본 가상 이미지의 칼라 해상도를 적용한 가상 이미지를 도시한 도면이다. 도 48(d)는 원본 가상 이미지에 투명화를 적용한 가상 이미지를 도시한 도면이다. 도 48(e)는 원본 가상 이미지를 제거한 도면이다. 도 48을 참조하면, 제 1 가상 이미지를 단계별로 디스플레이하는 것에 대하여 설명한다. 제어부는 디스플 레이가 변경된 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제어한다. 즉, 도 48(a)를 참조하면, 처음에는 원본 가상 이미지를 디스플레이하한다. 도 48(b)를 참조하면, 사용자 가 가상 이미지임을 인지하지 못하면, 원본 가상 이미지의 해상도를 저하한 가상 이미지를 디스플레이한 다. 도 48(c)를 참조하면, 사용자가 가상 이미지 임을 인지하지 못하면, 원본 가상 이미지의 칼라 해상도를 적 용한 가상 이미지를 디스플레이한다. 원본 가상 이미지의 칼라 해상도를 적용한 것은 원본 가상 이미지의 칼라를 변경하고, 해상도를 저하한 것을 의미한다. 도 48(d)를 참조하면, 사용자가 가상 이미지임을 인지하지 못하면, 원본 가상 이미지에 투명화를 적용한 가상 이미지를 디스플레이하고, 도 48(e)를 참조하면, 원본 가상 이미지를 제거한 도면을 디스플레이한 다. 즉, 사용자가 인지할 때까지, 원본 가상 이미지 -> 해상도가 저하된 가상 이미지 -> 칼라 해상도가 저하된 가상 이미지 -> 투명화를 적용한 가상 이미지 -> 가상 이미지 제거 순으로 진행된다. 여기서, 사용자가 인지한다는 것은 사용자가 가상 이미지임을 깨닫고 놀란 행동을 하는 것을 중지하는 것을 의 미한다. 즉, 사용자와 가상 이미지 사이의 제 1 거리가 계속하여 증가하였다가 사용자가 가상 이미지임을 인지 하게 되면, 제 1 거리가 증가하지 않는다. 본 발명에 따르면, 사용자의 몰입감을 저하시키지 않기 위해서, 처음에는 사용자에게 최소한의 변경된 가상 이 미지를 보여주다가, 사용자가 가상 이미지로부터 계속 도망가면 사용자가 가상 오브젝트임을 인지할 때까지, 점 차적으로 가상 이미지임을 강조하는 가상 이미지를 보여준다. 다음으로, 해당 사용자가 가장 잘 인식하는 레벨을 학습하고, 해당하는 레벨부터 적용하는 실시 예에 대하여 설 명한다. 제어부는 디스플레이가 변경된 제 1 가상 이미지를 복수의 단계 별로 상이하게 디스플레이하도록 제 어하고, 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하고, 디스플레이가 변경된 제 1 가 상 이미지를 결정된 특정 레벨부터 디스플레이하도록 제어한다. 예를 들어, 가상 이미지가 변경됨에 따라서 제 1 레벨, 제 2 레벨, 제 3 레벨, 제 4 레벨, 제 5 레벨이 있을 수 있다. 제 1 레벨은 원본 가상 이미지를 의미하고, 제 2 레벨은 해상도가 저하된 가상 이미지를 의미하고, 제 3 레벨은 칼라 해상도가 저하된 가상 이미지를 의미하고, 제 4 레벨은 투명화를 적용한 가상 이미지를 의미하고, 제 5 레벨은 가상 이미지 제거가 된 것을 의미한다. 제어부는 제 1 가상 이미지를 제 1 단계 내지 제 5 단계 별로 상이하게 디스플레이하도록 제어하고, 5 단 계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정한다. 예를 들어, 사용자가 가장 잘 인식하는 단계가 3 단계 로 결정된 경우, 제어부는 변경된 제 1 가상 이미지를 제 3 단계부터 디스플레이하도록 제어한다. 즉, 원 본 가상 이미지에서 바로 칼라 해상도가 저하된 가상 이미지를 디스플레이한다. 본 발명의 경우, 복수의 사용자가 XR 디바이스를 사용할 때, 복수의 사용자 중 특정 사용자가 가장 잘 인식하는 가상 이미지 레벨을 학습한 후, 나중에 특정 사용자가 XR 디바이스를 착용하고, 사용자가 놀라는 행위를 하면, 그 레벨부터 가상 이미지를 디스플레이할 수 있다. 따라서, 특정 사용자가 가상 이미지를 보다 신속하고 정확하 게 인식할 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 도 49는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용한 상태에서 실제 오브젝트를 가상 오브젝 트로 오인하고 다가가는 실시 예를 도시한 도면이다. 도 49는 도 49(a), 도 49(b) 및 도 49(c)를 포함한다. 도 49(a)는 실제 오브젝트 주변에 경고 메시지를 도시한 도면이다. 도 49(b)는 실제 오브젝트 주변에 가상 이미 지를 디스플레이하는 것을 도시한 도면이다. 도 49(c)는 실제 오브젝트 주변에 보다 강화된 가상 이미지를 디스 플레이하는 것을 도시한 도면이다. 도 49(a)를 참조하면, 사용자가 현실 오브젝트를 가상 오브젝트로 잘못 인지하고 현실 오브젝트에 다가가는 경우, 제어부는 디스플레이가 경고 메시지를 현실 오브젝트 주위에 디스플레이하도록 제어한다. 예를 들어, 사용자가 현실 투견을 가상 이미지로 잘못 인지하고 현실 투견에 다가가는 경우, 제어 부는 디스플레이가 경고 메시지를 현실 오브젝트 주위에 디스플레이하도록 제어한다. 경고 메시지는 목줄이 묶이지 않음. 진짜 투견. 접근 금지! 내용을 포함할 수 있다. 도 49(b)를 참조하면, 경고 메시지가 디스플레이되었음에도 불구하고, 사용자가 현실 투견을 가상 이미지로 잘못 인지하고 현실 투견에 계속하여 다가가는 경우, 제어부는 디스플레이가 위험 지역 임을 암시하는 가상 이미지를 현실 오브젝트 주위에 디스플레이하도록 제어한다. 가상 이미지는 현 실 오브젝트 주위에서 배경과 다른 색상으로 표시될 수 있다. 도 49(c)를 참조하면, 위험 지역임을 암시하는 가상 이미지가 디스플레이되었음에도 불구하고, 사용자 가 현실 투견을 가상 이미지로 잘못 인지하고 현실 투견에 계속하여 더욱 다가가는 경우, 제어부 는 디스플레이가 위험 지역임을 암시하는 가상 이미지와 위험 지역을 보다 강조하는 강화된 가상 이미 지를 현실 오브젝트 주위에 디스플레이하도록 제어한다. 강화된 가상 이미지는 현실 오브젝트 주위에서 가상 이미지와 다른 모양, 색상으로 표시될 수 있다. 예를 들어, 강화된 이미지는 불 이미지 가 될 수 있다. 본 발명에 따르면, 사용자가 실제 투견을 보았음에도 가상 이미지로 오인하고 계속하여 다가갈 수 있다. 먼저 투견을 피하라고 경고 메시지를 디스플레이하고, 사용자가 계속하여 접근하면 투견 주변에 가상 이미지를 디스 플레이한다. 그래도 사용자가 인지를 못하고 계속 접근하면, 가상의 불을 디스플레이함으로써 사용자에게 위험 을 알릴 수 있다. 또한, 추가적으로 제어부는 스피커가 경고 메시지를 단계 별로 다르게 발생하도록 제어할 수 있다. 예를 들어, 위험의 단계를 1 단계에서 5 단계로 나눌 수 있고, 1 단계의 경우, 작은 소리로 위험 가능성이 있음을 전 달하고, 3 단계의 경우, 중간 크기의 소리로 사용자가 위험해 질 수 있음을 경고하고, 5 단계의 경우, 최대 볼 륨의 크기로 사용자가 위험해 질 수 있음을 경고할 수 있다. 도 50은 본 발명의 일 실시 예에 따른, 현실 오브젝트에 가상 오브젝트가 추가된 것을 도시한 도면이다. 도 50 은 도 50(a) 및 도 50(b)를 포함한다. 도 50(a)는 현실 케이크를 담은 접시와 현실의 식탁을 도시한 도면이다. 도 50(b)는 현실 케이크를 담은 접시, 현실의 식탁, 현실의 식탁 위에 가상 그릇 이미지를 디스플레이하는 것을 도시한 도면이다. 도 50(a)를 참조하면, 사용자가 현실 케이크를 담은 접시와 현실의 식탁을 보면, 매우 단출하다고 느낄 수 있다. 도 50(b)를 참조하면, 사용자는 현실 케이크를 담은 접시를 볼 수 있다. 사용자가 XR 디바이스를 착용하면, 추가적으로 현실의 식탁에 가상 접시 이미지, 가상 음식 이미지를 디스플레이하여, 현실 의 식탁을 풍성하게 꾸밀 수 있다. 도 51은 본 발명의 일 실시 예에 따른, 현실 오브젝트와 가상 오브젝트를 구별하는 상황에서, 가상 이미지를 다 르게 디스플레이하는 것을 도시한 도면이다. 도 51은 도 51(a) 및 도 51(b)를 포함한다. 도 51(a)는 현실 오브젝트와 가상 오브젝트를 구별해야 하는 상황을 도면이다. 도 51(b)는 현실 오브젝트와 가 상 오브젝트를 구별하는 상황에서 가상 이미지를 다르게 디스플레이하는 것을 도시한 도면이다. 도 51(a)를 참조하면, 아이가 산만하게 굴어서 그릇을 깨뜨릴 수 있을 것 같은 상황이 생기는데, 복수의 그 릇(20, 30, 32) 중 어느 그릇이 진짜인지 또는 가상 이미지인지 구분이 구별할 수 없어서, 사용자가 아이 에게 주의를 줄 수 없다. 도 51(b)를 참조하면, 아이가 그릇을 깨뜨릴 것처럼 팔을 뻗는 경우, 제어부는 아이가 손을 대는 오브젝트가 가상 오브젝트인지 진짜 오브젝트인지 구분할 수 있게 가상 이미지(30, 32)를 디스플레이한다. 예를 들어, 아이가 팔을 뻗는 경우, 아이의 팔이 가상 그릇 이미지 위에 있으면, 제어부는 가상 그릇 이미지(30, 32)의 해상도를 낮추어서 디스플레이한다. 또는 가상 그릇 이미지(30, 32)를 반투명하게 하거 나 블러링 처리를 할 수 있다. 다라서, 사용자는 XR 디바이스를 착용한 상태에서, 가상 그릇 이미지 (30, 32)를 현실 케이크를 담은 접시와 구분할 수 있다. 그리고, 아이가 손을 현실 케이크를 담은 접시가 아닌 가상 그릇 이미지(30, 32)에 손을 뻗고 있으므로, 사용자는 위험하지 않은 상황임을 인지할 수 있다. 본 발명의 일 실시 예에 따르면, 사용자가 가상 이미지를 현실 이미지로 오인하여 가상 이미지와 관련된 특정 동작을 하면, 사용자의 움직임을 기초로 사용자 행동을 예측하고, 예측된 사용자 행동에 따라서 사용자가 현실 과 가상 오브젝트를 구별할 수 있도록 변경된 가상 이미지를 디스플레이할 수 있어서, 사용자가 현실과 가상 오 브젝트를 오인해서 생기는 사고를 방지할 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 본 발명의 다른 실시 예에 따르면, 예측된 사용자 행동에 따라서 사용자가 현실과 가상 오브젝트를 구별할 수 있도록 가상 이미지를 복수의 단계 별로 다르게 디스플레이할 수 있어서, 사용자가 가상 오브젝트를 인식하는데 도움을 줄 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 본 발명의 또 다른 실시 예에 따르면, 디스플레이가 변경된 제 1 가상 이미지를 복수의 단계 별로 상이하게 디 스플레이하도록 제어하고, 복수의 단계 중 사용자가 가장 잘 인식하는 특정 레벨을 결정하고, 이후 디스플레이 가 변경된 제 1 가상 이미지를 결정된 특정 레벨부터 디스플레이하도록 제어할 수 있어서, 사용자가 현실과 가 상 오브젝트를 보다 빠르게 구별할 수 있으므로 사용자 편의성을 향상 시킬 수 있다. 본 발명에 따른 XR 디바이스 및 그 제어 방법은 상기한 바와 같이 설명된 실시 예들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시 예들은 다양한 변형이 이루어질 수 있도록 각 실시 예들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다. 또한, 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2019-0130120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0130120", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 3GPP 기반 시스템에서 물리 신호/채널들의 매핑되는 자원 격자를 예시한 것이다. 도 2는 3GPP 신호 전송/수신 방법의 일예를 나타낸 도면이다. 도 3은 SSB 구조를 예시한다. 도 4는 임의 접속 과정의 일례를 예시한다. 도 5는 상향링크 그랜트에 따른 UL 전송의 일례를 나타낸다.도 6은 물리 채널 프로세싱(physical channel processing)의 개념도의 일례를 나타낸다. 도 7은 하이브리드 빔포밍(hybrid beamforming)을 위한 전송단 및 수신단의 블록도의 일례를 나타낸 도이다. 도 8 (a)는 협대역 동작의 일례를 나타낸 도이며, 도 8 (b)는 RF 리튜닝(retuning)을 가지는 MTC 채널 반복의 일례를 나타낸 도이다. 도 9는 본 명세서에서 제안하는 방법들이 적용될 수 있는 무선 통신 시스템의 블록 구성도를 예시한다. 도 10은 본 발명의 일 실시 예에 따른 AI 장치를 나타낸다. 도 11은 본 발명의 일 실시 예에 따른 AI 서버를 나타낸다. 도 12는 본 발명의 일 실시 예에 따른 AI 시스템을 나타낸다. 도 13은 본 발명의 실시예들에 의한 XR 디바이스의 블록도를 도시한 도면이다. 도 14는 도 13에 도시된 메모리를 보다 구체적으로 도시한 블록도이다. 도 15는 포인트 클라우트 데이터 처리 시스템을 나타낸다. 도 16은 러닝 프로세서를 포함하는 디바이스를 나타낸다. 도 17은 도 16에 도시된 본 발명의 XR 디바이스가 XR 서비스를 제공하는 과정을 나타낸다. 도 18은 XR 디바이스와 로봇의 외관을 도시하고 있다. 도 19는 XR 기술이 탑재된 디바이스를 이용하여, 로봇을 제어하는 과정을 도시한 플로우 차트이다. 도 20은 자율 주행 서비스를 제공하는 차량을 나타낸다. 도 21은 자율 주행 서비스 중 AR/VR 서비스를 제공하는 과정을 나타낸다. 도 22는 본 발명의 일실시예에 의한 XR 디바이스를 HMD 타입으로 구현한 경우를 도시하고 있다. 도 23은 본 발명의 일실시예에 의한 XR 디바이스를 AR 글래스 타입으로 구현한 경우를 도시하고 있다. 도 24는 본 발명의 일 실시 예에 따른, XR 디바이스의 구성도를 도시한 도면이다. 도 25는 본 발명의 일 실시 예에 따른, XR 디바이스 제어 방법의 순서도를 도시한 도면이다. 도 26은 본 발명의 일 실시 예에 따른, XR 디바이스 제어 방법의 순서도를 도시한 도면이다. 도 27은 본 발명의 일 실시 예에 따른, XR 디바이스를 AR 글래스 타입으로 구현한 구성도를 도시한 도면이다. 도 28은 본 발명의 일 실시 예에 따른, 사용자가 가상 오브젝트를 실제 오브젝트로 오인지하는 것을 도시한 도 면이다. 도 29는 본 발명의 일 실시 예에 따른, 사용자가 가상의 오브젝트를 주변과 구분되는 모드로 설정하는 것을 도 시한 도면이다. 도 30은 본 발명의 일 실시 예에 따른, 클라우드 종류에 따른 실행할 수 있는 세부 기능을 설명한 도면이다. 도 31은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고, MR 현실을 보는 것을 도시한 도면이 다. 도 32는 본 발명의 일 실시 예에 따른, 사용자가 가상 오브젝트에 어떠한 동작을 취하는지 예상할 수 있는 기술 적 배경을 설명하는 것을 도시한 도면이다. 도 33은 본 발명의 일 실시 예에 따른, 사용자 행동을 2D 이미지를 기초로 예측하는 것을 도시한 도면이다. 도 34는 본 발명의 일 실시 예에 따른, 이미지를 분석하여 이미지 내부의 사람의 행동을 예측하는 것을 도시한 도면이다. 도 35는 본 발명의 일 실시 예에 따른, 가속도 센서로 측정한 센서값을 FFT를 이용하여, 사용자 행동을 예측하 는 것을 도시한 도면이다. 도 36은 본 발명의 일 실시 예에 따른, FFT를 이용하여 사용자 행동을 예측하는 것을 도시한 도면이다. 도 37은 본 발명의 일 실시 예에 따른, 주파수를 기초로 사용자 행동을 예측하는 것을 도시한 도면이다. 도 38은 본 발명의 일 실시 예에 따른, 주파수를 기초로 사용자 행동을 예측하는 것을 도시한 도면이다. 도 39는 본 발명의 일 실시 예에 따른, 제 1 오브젝트가 가상 오브젝트임을 사용자에게 알려주어야 하는 경우를 도시한 도면이다. 도 40은 본 발명의 일 실시 예에 따른, 변경된 제 1 가상 이미지를 단계별로 디스플레이하는 것을 도시한 도면 이다. 도 41은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 현실 방을 바라볼 때, 현실 방에 가상 이미지가 적용된 것을 도시한 도면이다. 도 42는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 현실 의자를 바라볼 때, 현실 의자 방 에 가상 이미지가 적용된 것을 도시한 도면이다. 도 43은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 가상 이미지로 다가갈 때, 가상 이미 지가 변하는 것을 도시한 도면이다. 도 44는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 가상 이미지로 계속하여 다가갈 때, 가상 이미지가 변하는 것을 도시한 도면이다. 도 45는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 가상 이미지로 다가갈 때, 가상 이미 지가 변하는 것을 도시한 도면이다. 도 46은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용하고 운동을 할 때, 배경에 가상 이미지가 적용된 것을 도시한 도면이다. 도 47은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용한 상태에서 가상 이미지를 보고 놀라는 행 동을 하면, 가상 이미지가 다르게 디스플레이되는 것을 도시한 도면이다. 도 48은 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용한 상태에서 가상 이미지를 보고 놀라는 행 동을 계속적으로 하면, 가상 이미지가 다르게 디스플레이되는 것을 도시한 도면이다. 도 49는 본 발명의 일 실시 예에 따른, 사용자가 XR 디바이스를 착용한 상태에서 실제 오브젝트를 가상 오브젝 트로 오인하고 다가가는 실시 예를 도시한 도면이다. 도 50은 본 발명의 일 실시 예에 따른, 현실 오브젝트에 가상 오브젝트가 추가된 것을 도시한 도면이다. 도 51은 본 발명의 일 실시 예에 따른, 현실 오브젝트와 가상 오브젝트를 구별하는 상황에서, 가상 이미지를 다 르게 디스플레이하는 것을 도시한 도면이다."}
