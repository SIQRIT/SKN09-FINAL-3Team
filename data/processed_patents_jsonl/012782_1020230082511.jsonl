{"patent_id": "10-2023-0082511", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0000589", "출원번호": "10-2023-0082511", "발명의 명칭": "도메인 변화에 강인한 오픈 의도 군집화를 이용하는 다중 도메인 대화 시스템 및 그 작동 방", "출원인": "포항공과대학교 산학협력단", "발명자": "이근배"}}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "도메인 변화에 강인한 오픈 의도 군집화를 이용하는 다중 도메인 대화 시스템으로서,원시 대화 데이터를 받고 상기 원시 대화 데이터의 사용자 발화에서 사용자 의도 클래스를 추출하는 언어모델-상기 언어모델은 다중 도메인 대화 데이터셋으로부터 추출된 서술어와 목적어 쌍(predicate and object pairs,POP) 형식의 데이터들에 대한 지도대조 손실함수를 목적함수로 사용하여 학습된 모델임-; 및상기 원시 대화 데이터의 복수의 POP에 대한 상위어 및 빈도를 기반으로 결정되는 POP 군집의 이름으로 상기 사용자 의도 클래스를 지정하는 명명부;를 포함하며,상기 원시 대화 데이터는 대화의 의도에 대한 레이블이 지정되지 않은 데이터이고,상기 사용자 의도 클래스는 상기 언어모델을 통해 상기 원시 대화 데이터로부터 미리 설정되거나 그룹화된 복수의 카테고리들 중 하나로 상기 의도가 유도된 클래스인, 다중 도메인 대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 언어모델은, 학습 과정에서, 상기 원시 대화 데이터의 의도가 나타나는 첫 번째 발화를 의존성 분석(dependency parsing)을 통해 상기 POP로 변환하고, 변환된 POP 데이터에 대한 지도대조 손실함수를 목적함수로이용하는, 다중 도메인 대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 언어모델은, 추론 과정에서, K-평균 군집화를 사용하여 상기 사용자 의도 클래스를 분류하는, 다중 도메인대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 언어모델은 상기 원시 대화 데이터의 임베딩을 얻고, 상기 임베딩에 K-평균 군집화 알고리즘을 적용해 상기 원시 대화 데이터의 의도가 있는 발화가 속하는 의도 군집을 찾고,상기 명명부는 의존구조 분석기에 의해 얻은 복수의 POP 중 가장 빈도가 높은 클래스에 기초하여 상기 의도 군집의 이름을 지정하는, 다중 도메인 대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 명명부는 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들의 상위어를 토대로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집의 이름을 지정하는, 다중 도메인 대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 4에 있어서,상기 명명부는 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들의 상위어 및 상기상위어의 상위어를 토대로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집의 이공개특허 10-2025-0000589-3-름을 지정하는, 다중 도메인 대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 언어모델의 백본 네트워크는 다중 도메인 데이터셋으로 사전학습된 센텐스버트(SBERT: Sentence-Bidirectional Encoder Representations from Transformers)를 포함하고, 상기 원시 대화 데이터는 다중 도메인에 속하지 않은 다른 도메인의 데이터인, 다중 도메인 대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 다중 도메인 대화 데이터셋은 네트워크 상에서 실시간 획득가능한 대화 데이터셋 또는 MultiWOZ 데이터셋의 적어도 하나 이상의 특정 버전을 포함하는, 다중 도메인 대화 시스템."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "도메인 변화에 강인한 오픈 의도 군집화를 이용하는 다중 도메인 대화 시스템의 작동 방법으로서,언어모델에 원시 대화 데이터를 넣는 단계-상기 언어모델은 다중 도메인 대화 데이터셋으로부터 추출된 서술어와 목적어 쌍(predicate and object pairs, POP) 형식의 데이터들에 대한 지도대조 손실함수를 목적함수로 사용하여 학습된 모델임-;상기 언어모델에 의해 상기 원시 대화 데이터의 사용자 발화에서 사용자 의도 클래스를 얻는 단계; 및상기 원시 대화 데이터의 복수의 POP에 대한 상위어 및 빈도를 기반으로 결정되는 POP 군집의 이름으로 상기 사용자 의도 클래스를 지정하는 단계;를 포함하고,상기 원시 대화 데이터는 대화의 의도에 대한 레이블이 지정되지 않은 데이터이고,상기 사용자 의도 클래스는 상기 언어모델을 통해 상기 원시 대화 데이터로부터 미리 설정되거나 그룹화된 복수의 카테고리들 중 하나로 그 의도가 유도된 클래스인, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 원시 대화 데이터에서 도메인별로 의도가 나타난 사용자 발화를 상기 복수의 카테고리들에 속한 클래스들의 의미 범주에 매핑하는 단계를 더 포함하는, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 9에 있어서,상기 언어모델의 학습 과정에서, 의존구조 분석기를 이용해 상기 원시 대화 데이터의 의도가 나타나는 첫 번째발화를 상기 POP로 변환하는 단계; 및 변환된 POP 데이터에 대한 지도대조 손실함수를 목적함수로 이용하는 단계를 더 포함하는, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 9에 있어서,상기 언어모델의 추론 과정에서, K-평균 군집화를 사용하여 상기 사용자 의도 클래스를 분류하는 단계를 더 포함하는, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서,상기 언어모델을 통해 상기 원시 대화 데이터의 임베딩을 얻는 단계; 및 상기 임베딩에 K-평균 군집화 알고리즘공개특허 10-2025-0000589-4-을 적용해 상기 원시 대화 데이터의 각 발화가 속하는 의도 군집을 찾는 단계를 더 포함하는, 다중 도메인 대화시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 9에 있어서,상기 지정하는 단계는, 상기 원시 대화 데이터로부터 의존구조 분석기에 의해 얻은 복수의 POP 중 가장 빈도가높은 클래스에 기초하여 상기 의도 군집의 이름을 지정하는, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 14에 있어서,상기 지정하는 단계는, 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들의 상위어를 토대로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집의 이름을 지정하는,다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 14에 있어서,상기 지정하는 단계는, 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들의 1차 상위어 및 상기 1차 상위어의 상위어를 토대로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집의 이름을 지정하는, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 9에 있어서,상기 언어모델의 백본 네트워크는 상기 다중 도메인 대화 데이터셋으로 사전학습된 센텐스버트(SBERT:Sentence-Bidirectional Encoder Representations from Transformers)를 포함하고, 상기 원시 대화 데이터는상기 다중 도메인 대화 데이터셋의 다중 도메인에 속하지 않는 다른 도메인의 데이터인, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 9에 있어서,상기 다중 도메인 대화 데이터셋은 네트워크 상에서 실시간 획득가능한 대화 데이터셋 또는 MultiWOZ 데이터셋의 적어도 하나 이상의 버전을 포함하는, 다중 도메인 대화 시스템의 작동 방법."}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "도메인 변화에 강인한 오픈 의도 군집화를 이용하는 다중 도메인 대화 시스템 및 그 작동 방법이 개시된다. 시스 템은, 원시 대화 데이터를 받고 원시 대화 데이터에 대한 사용자 의도 클래스를 추출하는 언어모델, 및 원시 대 화 데이터의 복수의 서술어와 목적어 쌍(POP)에 대한 상위어 및 빈도를 기반으로 결정되는 POP 군집의 이름으로 사용자 의도 클래스를 지정하는 명명부를 포함한다. 언어모델은 다중 도메인 대화 데이터셋으로부터 추출된 POP 형식의 데이터들에 대한 지도대조 손실함수를 목적함수로 사용하여 학습된 모델이다."}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다중 도메인 대화 의도 추출 기술에 관한 것으로, 보다 상세하게는, 목적 지향 대화 시스템에서 원시 대화 데이터의 의도를 자동으로 추출할 수 있는 도메인 변화에 강인한 오픈 의도 군집화를 이용하는 다중 도메 인 대화 시스템 및 그 작동 방법에 관한 것이다."}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "목적 지향 대화 시스템과 관련하여, 대화로부터 사용자의 의도를 이해하는 모델을 만드는 방법은 지도학습을 이 용한 경우와 비지도학습을 이용한 경우로 나눌 수 있다. 지도학습의 경우, 충분한 양의 사용자와 시스템 간의 대화 데이터셋을 이용함으로써 대화 시스템이 사용자의 의도를 이해하는 데 도움을 줄 수 있다. 특히 사용자의 의도 레이블이 있는 대화 데이터셋으로 분류 모델을 학습시키면 새로운 대화로부터 사용자의 의도를 보다 쉽게 추출할 수 있다. 그리고, 비지도학습의 경우, 사용자 의도를 파악하기 위해서는 일반적으로 군집화 방법을 사용한다. 예를 들어, 비지도학습의 군집화 방법으로는 K-평균 군집화 알고리즘을 기본으로 비슷한 크기의 군집을 우대하는 방법, 이상치를 고려한 밀도 기반의 군집화 알고리즘을 사용하는 방법 등이 있다. 한편, 기존의 언어모델은 훈련 데이터셋에 없는 도메인의 대화에서 의도를 추출할 때 그 정확도가 크게 떨어진 다. 따라서 새로운 도메인에 대하여 언어모델을 적용시키기 위해서는 의도 레이블이 있는 대화 데이터셋을 구축 하여 학습시킬 필요가 있다. 이러한 학습 과정은 통상 전문가의 지식을 필요로 하며 많은 비용이 소요된다. 전술한 바와 같이 기존의 목적 지향 대화 시스템에서는, 관광, 병원, 경찰, 호텔, 식당, 택시, 기차, 금융, 은 행, 보험 등의 다양한 도메인에서 사용자와 시스템 간의 대화 중에 사용자의 의도를 보다 정확하게 이해할 수 있는 방안이 요구되고 있다. 특히, 범용성을 높이고 비용을 절감하기 위해 사전 학습에 사용된 데이터셋의 도메 인과 다른 도메인에 대화 시스템에 사용하는 경우에도 실질적으로 성능이 저하되지 않는 새로운 다중 도메인 대 화 시스템이 요구되고 있다."}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 요구에 부응하기 위해 도출된 것으로, 본 발명의 목적은, 복수의 도메인들 간에 사용할 수 있는 다중 도메인 대화 데이터셋을 활용하여 언어모델을 미세 조정하고, 미세 조정된 언어모델에서 불필요한 정보의 아티팩트를 제거하기 위해 서술어-목적어 쌍의 상위어 및 빈도를 활용하는, 다중 도메인 대화 시스템 및 그 작동 방법을 제공하는데 있다."}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 측면에 따른 다중 도메인 대화 시스템은, 도메인 변화에 강인 한 오픈 의도 군집화를 이용하는 다중 도메인 대화 시스템으로서, 원시 대화 데이터를 받고 상기 원시 대화 데 이터의 사용자 발화에서 사용자 의도 클래스를 추출하는 언어모델-상기 언어모델은 다중 도메인 대화 데이터셋 으로부터 추출된 서술어와 목적어 쌍(predicate and object pairs, POP) 형식의 데이터들에 대한 지도대조 손실 함수를 목적함수로 사용하여 학습된 모델임-; 및 상기 원시 대화 데이터의 복수의 POP에 대한 상위어 및 빈도를 기반으로 결정되는 POP 군집의 이름으로 상기 사용자 의도 클래스를 지정하는 명명부;를 포함한다. 상기 원시 대화 데이터는 대화의 의도에 대한 레이블이 지정되지 않은 데이터이다. 상기 사용자 의도 클래스는 상기 언어 모델을 통해 상기 원시 대화 데이터로부터 미리 설정되거나 그룹화된 복수의 카테고리들 중 하나로 상기 의도가 유도된 클래스이다. 상기 언어모델은, 학습 과정에서, 상기 원시 대화 데이터의 의도가 나타나는 첫 번째 발화를 의존성 분석 (dependency parsing)을 통해 상기 POP로 변환하고, 변환된 POP 데이터에 대한 지도대조 손실함수를 목적함수로 이용할 수 있다. 상기 언어모델은, 추론 과정에서, K-평균 군집화를 사용하여 상기 사용자 의도 클래스를 분류할 수 있다. 상기 언어모델은 상기 원시 대화 데이터의 임베딩을 얻고, 상기 임베딩에 K-평균 군집화 알고리즘을 적용해 상 기 원시 대화 데이터의 의도가 있는 발화가 속하는 의도 군집을 찾도록 구성될 수 있다. 그리고, 상기 명명부는 의존구조 분석기에 의해 얻은 복수의 POP 중 가장 빈도가 높은 클래스에 기초하여 상기 의도 군집의 이름을 지 정하도록 구성될 수 있다. 상기 명명부는 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들의 상위어를 토대 로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집의 이름을 지정하도록 구성될 수 있다. 상기 명명부는 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들의 상위어 및 상기 상위어의 상위어를 토대로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집의 이 름을 지정하도록 구성될 수 있다. 상기 기술적 과제를 해결하기 위한 본 발명의 또 다른 측면에 따른 다중 도메인 대화 시스템의 작동 방법은, 도 메인 변화에 강인한 오픈 의도 군집화를 이용하는 다중 도메인 대화 시스템의 작동 방법으로서, 언어모델에 원 시 대화 데이터를 넣는 단계; 상기 언어모델로부터 상기 원시 대화 데이터의 사용자 발화에서 사용자 의도 클래 스를 얻는 단계; 및 상기 원시 대화 데이터의 복수의 POP에 대한 상위어 및 빈도를 기반으로 결정되는 POP 군집 의 이름으로 상기 사용자 의도 클래스를 지정하는 단계;를 포함한다.상기 언어모델은 다중 도메인 대화 데이터셋으로부터 추출된 서술어와 목적어 쌍(predicate and object pairs, POP) 형식의 데이터들에 대한 지도대조 손실함수를 목적함수로 사용하여 학습된 모델이다. 상기 원시 대화 데이터는 대화의 의도에 대한 레이블이 지정되지 않은 데이터이다. 상기 사용자 의도 클래스는 상기 언어모델을 통해 상기 원시 대화 데이터로부터 미리 설정되거나 그룹화된 복수의 카테고리들 중 하나로 그 의도가 유도된 클래스이다. 상기 작동 방법은, 상기 원시 대화 데이터에서 도메인별로 의도가 나타난 사용자 발화를 상기 복수의 카테고리 들에 속한 클래스들의 의미 범주에 매핑하는 단계를 더 포함할 수 있다. 상기 작동 방법은, 상기 언어모델의 학습 과정에서, 의존구조 분석기를 이용해 상기 원시 대화 데이터의 의도가 나타나는 첫 번째 발화를 상기 POP로 변환하는 단계; 및 변환된 POP 데이터에 대한 지도대조 손실함수를 목적함 수로 이용하는 단계를 더 포함할 수 있다. 상기 작동 방법은, 상기 언어모델의 추론 과정에서, K-평균 군집화를 사용하여 상기 사용자 의도 클래스를 분류 하는 단계를 더 포함할 수 있다. 상기 작동 방법은, 상기 언어모델을 통해 상기 원시 대화 데이터의 임베딩을 얻는 단계; 및 상기 임베딩에 K-평 균 군집화 알고리즘을 적용해 상기 원시 대화 데이터의 각 발화가 속하는 의도 군집을 찾는 단계를 더 포함할 수 있다. 상기 지정하는 단계는, 상기 원시 대화 데이터로부터 의존구조 분석기에 의해 얻은 복수의 POP 중 가장 빈도가 높은 클래스에 기초하여 상기 의도 군집의 이름을 지정하도록 구성될 수 있다. 상기 지정하는 단계는, 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들 및 상기 세부 단어들의 상위어를 토대로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집 의 이름을 지정하도록 구성될 수 있다. 상기 지정하는 단계는, 상기 복수의 POP 중 목적어에 세부 단어들이 등장하는 경우, 상기 세부 단어들과 상기 세부 단어들의 1차 상위어, 및 상기 1차 상위어의 상위어를 토대로 상기 복수의 POP 중 가장 많은 출현 개수를 가진 POP를 토대로 상기 의도 군집의 이름을 지정하도록 구성될 수 있다. 상기 언어모델의 백본 네트워크는 제1 도메인의 데이터셋으로 사전학습된 센텐스버트(SBERT: Sentence- Bidirectional Encoder Representations from Transformers)를 포함할 수 있다. 이 경우, 상기 원시 대화 데이 터는 상기 제1 도메인이 아닌 다른 제2 도메인의 데이터일 수 있다. 상기 다중 도메인 대화 데이터셋은 네트워크 상에서 실시간 획득가능한 대화 데이터셋 또는 MultiWOZ 데이터셋 의 적어도 하나 이상의 특정 버전을 포함할 수 있다."}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 목적 지향 대화 시스템에 있어서 관광, 병원, 경찰, 호텔, 식당, 택시, 기차, 금융, 은행, 보험 등의 다양한 도메인들 중 사전 학습에 사용된 데이터셋의 도메인과 다른 도메인에 적용하는 경우에도 실질 적으로 언어모델의 성능이 저하되지 않도록 하는 의존성 분석을 통해 도메인 변화에 강인한 오픈 의도 군집화 방법을 제공할 수 있다. 또한, 본 발명에 의하면, 챗봇 시스템이나 이와 유사한 자연어 처리 인터페이스 혹은 인공지능 인터페이스 등을 이용하는 다중 도메인 사용자-시스템 대화 시스템에서 도메인 변화에 관계없이 사용자와의 대화 또는 사용자 발 화 내 오픈 의도를 신뢰도 높게 파악할 수 있고, 이에 의해 대화 시스템에서 도메인 변화에 강건한 발화 표현을 구현하거나 도메인 변화에 강건한 대화 서비스를 제공할 수 있다. 또한, 본 발명에 의하면, 애프터서비스(after service, A/S), 고객서비스(customer service, C.S), 보험 (insurance), 은행(banking), 금융(finance), 여행(tourism), 예약, 문의, 응답, 콜센터, 고객상담 등의 도메 인들에서 선택되는 다중 도메인에 대한 사용자-시스템 대화 시스템에서 사용자의 의도를 더욱 정확하게 이해할 수 있는 프레임워크를 제공할 수 있다. 또한, 본 발명에 의하면, 사전 학습에 사용한 데이터셋의 도메인과 다른 도메인의 원시 대화 데이터에 대하여도 기존 기술 대비 정규화된 상호 정보(normalized mutual information, NMI) 점수, 정확도(accuracy, ACC) 지수 및 정밀도(precision) 지수가 더 높게 나타나는 목적 지향 대화 시스템을 제공할 수 있다.또한, 본 발명의 다중 도메인 대화 시스템을 사용하면, 사전 학습된 도메인과 다른 도메인에서도 사용자의 의도 를 보다 더 수월하게 이해할 수 있고, 따라서 기존 대화 시스템을 다른 도메인의 대화 서비스에 적용하는 경우 에 드는 비용을 줄일 수 있어 서비스 확장 속도를 높일 수 있다."}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 출원의 실시예들에서, 'A 및 B 중에서 적어도 하나'는 'A 또는 B 중에서 적어도 하나' 또는 'A 및 B 중 하나 이상의 조합들 중에서 적어도 하나'를 의미할 수 있다. 또한, 본 출원의 실시예들에서, 'A 및 B 중에서 하나 이 상'은 'A 또는 B 중에서 하나 이상' 또는 'A 및 B 중 하나 이상의 조합들 중에서 하나 이상'을 의미할 수 있다. 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어' 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 '직접 연결되어' 있다거나 '직접 접속되어'있다 고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, '포함 한다' 또는 '가진다' 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다.이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명의 일실시예에 따른 다중 도메인 대화 시스템의 개략적인 블록도이다. 도 1을 참조하면, 다중 도메인 대화 시스템(이하 간략히 '대화 시스템'이라고 한다)은 기본적으로 의존구조 분 석기(dependency parser, 20), 언어모델 및 명명부를 포함하여 구성될 수 있다. 또한, 대화 시스템은 음성 인식부, 대화 관리자, 응답 생성부 및 음성 합성부 중 적어도 하나를 더 포함하도록 구성 될 수 있다. 음성 인식부, 의존구조 분석기, 언어모델, 명명부, 대화 관리자, 응답 생성부 및 음성 합성부는 적어도 하나 이상의 프로세서에 탑재될 수 있다. 또한, 대화 시스템은 프로세서에 연결되는 사용자 발화 입력부 및 시스템 발화 출력부를 구비할 수 있다. 사용자 발화 입력부는 음성 인식부로 사용자 발화를 전달하는 마이크 등의 음성 입력 장치를 포함할 수 있다. 그리고, 시스템 발화 출력부는 음성 합성부로부터의 신호를 음성, 소리, 빛, 진동 등 의 출력 신호로 변환하거나 방출하는 스피커, 디스플레이 등의 출력 장치를 포함할 수 있다. 좀더 구체적으로 프로세서에 탑재할 수 있는 세부 구성들을 살펴보면, 먼저 음성 인식부는 사람이 말 하는 음성 언어나 사람이 말하는 음성 언어를 전달하는 장치로부터 입력되는 신호를 해석하여 그 내용을 문자 데이터로 전환하는 수단이나 이러한 수단에 대응하는 기능을 수행하는 구성부를 포함할 수 있다. 음성 인식부는 HMM(hidden Markov Model) 등을 사용하여 화자의 발성 음성인 발화를 통계적으로 모델링하도록 구성될 수 있다. 의존구조 분석기는 각 발화(utterance)에서 서술어-목적어 쌍(predicate and object pairs, POP) 또는 동 사-목적어 쌍(verb-object pairs, VOP)을 추출할 수 있다. 이러한 의존구조 분석기는 언어모델에서 K- 평균 군집화에 의해 획득된 의도 군집에 자동으로 군집 레이블 즉, 군집 이름을 생성하도록 동작할 수 있다. 이 러한 의존구조 분석기의 명명(naming) 기능은 별도의 수단이나 구성부 예컨대 후술하는 명명부에 의해 독립적인 형태로 구현될 수 있다. 언어모델은 각 발화의 의미 표현(semantic representation)을 얻기 위한 수단이나 이러한 수단에 상응하는 기능을 수행하는 구성부를 포함할 수 있다. 언어모델은 다중 도메인 발화 데이터셋으로 사전 훈련될 수 있 다. 이러한 언어모델은 분류모델로 지칭될 수 있다. 명명부는 원시 대화 데이터의 복수의 POP에 대한 상위어 및 빈도를 기반으로 결정되는 POP(이하 '제1 POP) 에 기초하여 의도 군집의 이름을 지정할 수 있다. 특히, 명명부는 서술어-목적어 쌍의 구성하는 목적어의 세부 단어들뿐만 아니라 세부 단어들의 상위어를 포함한 확장 세부 단어들을 토대로 복수의 POP에 대한 빈도를 계산하도록 구성될 수 있다. 게다가, 명명부는 구현에 따라서 세부 단어들, 세부 단어들의 상위어(제1 상위 어), 및 제1 상위어의 상위어(제2 상위어)를 포함한 추가 확장 세부 단어들을 토대로 복수의 POP에 대한 빈도를 계산하도록 구성될 수 있다. 대화 관리자는 명명부에 의해 이름이 지정된 의도 군집에 기초하여 원시 대화 데이터에 대한 응답을 결 정할 수 있다. 응답 생성부는 대화 관리자에 의해 결정된 응답에 기초하여 시스템 발화를 위한 음성 소스를 생성할 수 있다. 그리고 음성 합성부는 응답 생성부의 음성 소스를 시스템발화출력부에서 출력 가능한 형태로 변환할 수 있다. 이러한 대화 관리자, 응답 생성부 및 음성 합성부는 기존의 대화 시스템에서 사용하는 구성들 중 적어도 일부를 사용하여 구현될 수 있다. 도 2는 도 1의 다중 도메인 대화 시스템의 주요 작동 원리를 설명하기 위한 흐름도이다. 도 2를 참조하면, 먼저 대화 시스템은 언어 모델에 원시 대화 데이터를 넣을 수 있다(S21). 언어모델은 학습시 사용된 특정 도메인과 다른 도메인에 대해서도 원하는 수준 이상의 성능을 발휘할 수 있도록 다중 도메인 대화 데이터셋으로 사전 학습될 수 있다. 다중 도메인 대화 데이터셋은 MultiWOZ 데이터셋을 포함 할 수 있다. MultiWOZ 데이터셋은 기차 예약, 호텔 찾기 등의 여러 가지 도메인들에서 사용자와 챗봇의 대화로 이루어져 있으며, 사용자의 의도가 태깅되어 있다. 또한, 언어모델은 다중 도메인 대화 데이터셋으로부터 추출된 서술어-목적어 쌍(predicate and object pairs, POP) 형식의 데이터들에 대한 지도대조 손실함수를 목적함수로 사용하여 학습될 수 있다. 원시 대화 데이터는 대화의 의도에 대한 레이블이 지정되지 않은 데이터이다. 서술어-목적어 쌍(POP)은 동사-목적어 쌍(verv-objectpair, VOP)로 지칭될 수 있다. 다음, 대화 시스템은 언어모델로부터 임베딩을 얻고 K-평균 군집화 알고리즘에 의해 의도 군집을 얻을 수 있다 (S27). 의도 군집은 사용자 의도 클래스에 대응될 수 있다. 사용자 의도 클래스는 언어모델을 통해 원시 대화 데이터로부터 미리 설정되거나 그룹화된 복수의 카테고리들 중 하나로 상기의 의도가 유도되는 클래스이다. 다음, 대화 시스템은 상위어 및 빈도를 기반으로 결정되는 서술어-목적어 쌍 군집의 이름으로 사용자 의도 클래 스를 지정할 수 있다(S29). 도 3은 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 언어모델의 작동 원리를 설명하기 위한 흐름도이다. 도 3을 참조하면, 언어모델은 원시 대화 데이터의 임베딩을 얻는 과정(S33), 및 임베딩에 K-평균 군집화 알고리 즘을 적용하여 원시 대화 데이터의 의도 있는 발화가 속하는 의도 군집(intent cluster)을 찾는 과정(S35), 및 상위어 및 빈도를 기반으로 결정되는 서술어-목적어 쌍 군집으로 이름으로 사용자 의도 클래스를 지정하는 과정 (S37)을 포함하도록 구성될 수 있다. 언어모델의 백본 네트워크로는 사전학습된 센텐스버트(SBERT: Sentence-Bidirectional Encoder Representations from Transformers)를 사용할 수 있다. SBERT는 통상 BERT의 문장 임베딩을 응용하여 미세 조정될 수 있다. SBERT는 샴 네트워크 구조(siamese network"}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "structure)를 가지며 통상 분류(classification), 요약(summarization)등의 태스크에서 활용된다. 하지만, 일 반적인 SBERT 모델은 대화 발화와 다른 언어 패턴을 가진 서면 형식의 텍스트 데이터셋으로 사전 훈련된 모델이 므로, 실제의 대화 관련 태스크들에서 그 정확도가 현저하게 떨어질 수 있다. 이에 본 실시예에서, 언어모델은 사전 학습된 도메인 외에 다른 도메인의 사용자 발화도 올바른 임베딩으로 잘 나타낼 수 있도록 다중 도메인 공개 태스크 지향 대화 데이터셋(mult-domain public task-oriented dialogue dataset)을 이용하여 학습될 수 있다. 학습시, 언어모델은 미세 조정(fine-tuning)을 통해 사전 학습될 수 있다. 좀더 구체적으로, 언어모델은, 의존성 분석(dependency parsing)을 통해 얻어지는 원시 대화 데이터의 의도가 나타나는 첫 번째 발화를 서술어-목적어 쌍(POP)으로 변환하고, 변환된 POP 데이터에 대한 지도대조 손실함수 (supervised contrastive loss function, 간략히 supervised contrastive loss 또는 SCL)를 목적함수로 이용하 여 학습을 수행할 수 있다. 이러한 언어모델의 미세 조정 과정에 대하여는 도 7을 참조한 상세 설명에서 좀더 구체적으로 언급하기로 한다. 도 4는 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 명명부의 구성을 개략적으로 나타낸 블록도이다. 그 리고 도 5는 도 4의 명명부의 작동 원리를 설명하기 위한 흐름도이다. 도 4 및 도 5를 참조하면, 명명부(naming unit, 40)는 특정 규칙에 따라 결정되는 서술어-목적어 쌍(POP) 군집 의 이름으로 사용자 의도 클래스를 지정하며, 이를 위해 판단부, 제1 명명부 및 제2 명명부를 구비 할 수 있다. 판단부는 의존구조 분석기를 통해 원시 대화 데이터로부터 획득한 복수의 서술어-목적어 쌍(POP) 중 목적어 에 기설정 횟수나 빈도 미만의 세부 단어들이 등장하는지를 판단할 수 있다(S51). 특히, 판단부는 의존구조 분석기를 통해 원시 대화 데이터로부터 획득한 첫 번째 POP의 빈도 횟수가 기설정 가중치를 곱한 두 번째 POP의 빈도 횟수보다 큰지를 판별할 수 있다. 제1 명명부는, 위 판단 단계(S51)에서 세부 단어들이 기설정 횟수나 빈도 이상 등장하지 않을 때, 복수의 서술어-목적어 쌍(POP) 중 가장 빈도가 높은 POP의 클래스에 기초하여 의도 군집의 이름을 지정할 수 있다. 특 히, 제1 명명부는 첫 번째 POP의 빈도 횟수가 기설정 가중치를 곱한 두 번째 POP의 빈도 횟수보다 크면, 첫 번째 POP를 라벨로 선택할 수 있다. 의도 군집(intent cluster)은 언어모델에서 원시 대화 데이터로부터 얻은 임베딩에 K-평균 군집화 알고리즘을 적용하여 찾은 원시 대화 데이터의 의도 있는 발화가 속하는 군집을 지칭할 수 있다. 제2 명명부는, 위 판단 단계(S51)에서 세부 단어들이 기설정 횟수나 빈도 미만으로 등장할 때, 세부 단어들 과, 세부 단어들의 제1 상위어, 및/또는 제1 상위어의 상위어인 제2 상위어를 포함한 확장 세부 그룹들에 대한복수의 서술어-목적어 쌍(POP) 중 가장 많은 출현 빈도를 가진 POP를 의도 군집의 이름으로 지정할 수 있다. 이 름은 라벨에 대응될 수 있다. 한편, 전술한 대화 시스템은 의존성 분석을 통해 도메인 변화에 강인한 오픈 의도 군집화를 이용하는 것으로, 언어모델의 사전 학습을 위해 미세 조정(fine-tuning) 과정을 수행하도록 구성된다. 즉, 대화 시스템은 다중 도 메인 대화 데이터셋에서 서술어-목적어 쌍을 추출하여 언어모델을 미세 조정하고, 그에 의해 다중 도메인 대화 시스템에 적합한 새로운 언어모델 또는 분류모델을 준비하도록 구성될 수 있다. 다중 도메인 대화 데이터셋은 다중 도메인 공개 태스크 지향 대화 데이터셋을 포함할 수 있다. 다중 도메인 공 개 태스크 지향 대화 데이터셋은 MulitWOZ 데이터셋을 사용할 수 있다. 다중 도메인 공개 태스크 지향 대화 데이터셋에서, 스키마는 서로 다른 슬롯을 비범주형과 범주형의 두 가지 범 주로 나눌 수 있다. 비범주형 슬롯은 가능한 값들의 큰 집합이나 동적인 집합을 가진다. 온톨로지와 달리 스키 마는 그러한 비범주형 슬롯에 대해 미리 정의된 값 목록을 제공하지 않는다. 대신에 그러한 값은 대화 기록에서 추출될 수 있다. 다중 도메인 공개 태스크 지향 대화 데이터셋에서, 호텔 가격 범위 또는 호텔 유형과 같이 자연히 작은 유한 값 집합을 취하는 슬롯을 범주형이라고 한다. 온톨로지와 유사하게 스키마는 그러한 슬롯에 대해 가능한 모든 값들 을 나열한다. 부가설명(annotation) 중에, 대화 상태 내 슬롯 값들 및 사용자 또는 시스템 동작은 스키마에 정 의된 사전정의 후보 목록에서 선택될 수 있다. 이는 부가설명의 온전함과 일관성을 유지하는 데 도움이 될 수 있다. 각 도메인에 대해 범주형 및 비범주형 슬롯들을 정의하면 표 1과 같이 나타낼 수 있다. 표 1 도메인 범주형 슬롯 비범주형 슬롯 식당가격대, 면적, 북데이, 북피플 음식, 이름, 북타임 명소면적, 종류 이름 호텔가격대, 주차, 인터넷, 별갯수, 면적, 유형, 북피플, 북데이, 북스테이이름 텍시 목적지, 출발지, 도착시간, 출발시간 기차목적지, 출발지, 주간, 북피플 도착시간, 출발시간 버스주간 출발지, 목적지, 도착시간 병원- 진료과 경찰- 이름 전술한 다중 도메인 공개 태스크 지향 대화 데이터셋에서 슬롯을 범주형과 비범주형으로 나누는 것은 새로운 것 이 아니며, 많은 모델에서 가능한 슬롯 값들의 개수를 분류 기준으로 사용할 수 있다. 유사하게, 훈련 데이터셋 에서는 50개 미만의 서로 다른 슬롯 값들을 가진 슬롯을 범주형으로 분류하고 나머지를 비범주형으로 분류할 수 있다. 버스 및 경찰 도메인의 훈련 데이터셋은 대화를 거의 포함하고 있지 않기 때문에, 이 도메인에서 가능한 슬롯 값들의 개수는 슬롯의 실제 속성을 반영하지 않을 수 있다. 이와 같이, SBERT는 임계값 규칙을 따르는 대 신 다른 도메인의 유사한 슬롯을 참조하여 분류을 수행하도록 구성될 수도 있다. 또한, 다중 도메인 공개 태스크 지향 대화 데이터셋은 9개의 의도 유형을 가질 수 있다. 각 의도 유형에 따라 발화 임베딩을 학습하도록 언어모델이 미세 조정될 수 있다. 언어모델에서 데이터셋에서의 의도는 여러 차례에 걸쳐 나타날 수 있고, 일부 발화에서는 하나의 발화에 여러 의도가 포함되어 있을 수 있다. 한편으로, 전술한 언어모델의 미세 조정에서 이용되는 지도대조학습(SCL)은, 크로스-엔트로피 손실(cross- entropy loss)보다 언어모델 학습에 더 일반화되고 강인함을 보여주는 대조학습(constrastive learning, CL)의 개량형 버전이다. 기존 대조학습(CL)에서는 앵커(anchor) 및 그 증강 객체(augmented object)만을 포지티브 객체로 취급하고 나머 지를 네거티브 객체로 취급하지만, 본 실시예에 채용할 수 있는 지도대조학습(SCL)에서는 동일한 라벨의 객체들 을 포지티브 객체로 설정하고 나머지를 네거티브 객체로 설정할 수 있고, 그에 의해 보다 정확한 임베딩 표현 학습을 수행할 수 있다. 예를 들어, 랜덤하게 샘플링된 복수(예컨대, N개)의 객체들 에 대하여, 훈련에 사용할 미니 배치 (mini batch)를 2N 쌍으로 구성할 수 있으며, 이를 나타내면 수학식 1과 같다. 수학식 1"}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "미니 배치 에서, 은 최초 샘플링된 데이터이고, 은 최초 샘플링된 데이터의 확대된 쌍이다. 본 실시예의 언어모델의 미세 조정 과정에서는 전술한 데이터 확대를 위해 동의어 증강(synonym augmentation) 을 사용할 수 있다. 동의어 증강은 워드넷(WordNet) 기반 동의어 증강으로 구현될 수 있다. 동의어는 넓은 의미 에서 유의어를 포함할 수 있다. 전술한 언어모델의 전체 손실함수는 다음의 수학식 2와 같이 표현될 수 있다. 수학식 2"}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 2에서와 같이, 전체 손실함수(Lsup)는 각 미니 배치에서 구한 손실함수()의 합으로 표현될 수 있다. 각 미니 배치에서 구한 손실함수()는 다음의 수학식 3과 같이 표현될 수 있다. 수학식 3"}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3에서, Φ가 SBERT 인코더, y는 의도 라벨(intent label), τ는 분리 강도(separation strength)를 조 정하기 위한 스칼라 온도 파라미터을 각각 나타낸다. 수학식 2 및 수학식 3에서 알 수 있듯이, 본 실시예의 대화 시스템은 지도대조 손실함수로 각 미니 배치에서 구 한 손실함수()를 최소화하도록 학습될 수 있다. 즉, 모든 데이터에 대해 같은 라벨 즉, 포지티브 샘플 (positive sample)이면, 해당 내적(inner product) 값(분자에 대응함)을 최대화하고, 다른 라벨이면 즉, 네거 티브 샘플(negative sample)이면, 내적 값(분모에 대응함)을 최소화할 수 있다. 내적(inner product)은 가까우 면 즉, 임베딩이 비슷하면 그 값이 커진다. 전술한 언어모델의 학습 이전(before training)과 학습 이후(after training)의 발화 표현(utterance representation) 결과들을 각각 가시화하여 나타내면 도 6과 같다. 도 6에 도시한 바와 같이, 학습 이전의 발화 표현보다 학습 이후의 발화 표현의 군집화가 더욱 잘 수행되어 있 는 것을 확인할 수 있다. 도 7은 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 언어모델의 학습 과정을 설명하기 위한 흐름도이다. 도 7을 참조하면, 언어모델은 학습 과정에서 미세 조정(fine-tuning)을 포함할 수 있다. 구체적으로, 원시 텍스 트(raw text, 70)으로부터 의존성 분석(dependency parsing) 과정을 통해 동사-목적어(verb-object, 간략히 verb-obj) 쌍을 추출할 수 있다(S71). 동사-목적어 쌍은 서술어-목적어 쌍(POP)으로 지칭될 수 있다. 원시 데이터는, 예를 들어, 다음의 텍스트 데이터를 포함할 수 있다. \"Hi, I need to find a hotel to stey at. It doesn't need to have wifi.\" \"Book the train please. I'm also looking for a place to stay if you don't mind.\" \"I am looking for a train from London Kings Cross to Cambridge.\" 서술어-목적어 쌍(POP)은 SBERT를 백본 네트워크로 사용하는 언어모델(30a)의 입력 데이터(input data)로서 준 비될 수 있다. 이때 입력 데이터는 의존성 분석을 통해 원시 데이터로부터 동사와 목적어만을 포함하는 다 음의 텍스트 입력 데이터과 같이 추출될 수 있다. \"need find hotel stay need have wifi\" \"looking place stay mind\" \"looking train Cross Cambridge\" 준비된 입력 데이터를 언어모델(30a)에 넣으면(S73), 언어모델(30a)은 입력 데이터를 이용한 지도대조학습에서 지도대조 손실함수(supervised contrastive loss function)를 목적함수로 사용하여 학습을 수행할 수 있다 (S75). 도 8은 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 언어 모델의 추론 과정을 설명하기 위한 흐름도이다. 도 8을 참조하면, 언어모델(30a)은 추론(inference) 과정에서 원시 대화 데이터의 일종인 특정 원시 텍스트(raw text, 80)를 입력받을 수 있다(S81). 언어모델(30a)는 도 7의 사전 훈련된 언어모델일 수 있다. 원시 데이터 는 대화의 의도에 대한 레이블이 없는 데이터이다. 예를 들어, 원시 데이터는, 다음의 원시 대화 텍스트 데이터를 포함할 수 있다. 원시 대화 텍스트 데이터는 원시 대화 데이터로 지칭될 수 있다. \"I would love to add a dependent.\" \"Yes, we just adopted a new baby.\" \"I need to add my doughter to insurance.\" 원시 데이터를 언어모델(30a)에 넣으면(S81), 언어모델(30a)은 원시 데이터에 대한 지도대조학습에서 미세 조정된 언어모델(30a)을 이용하여 원시 대화 데이터의 임베딩을 얻고, 임베딩에 K-평균 군집화 알고리즘을 적용하여 원시 데이터의 각 발화가 속하는 의도 군집을 찾을 수 있다(S83). 언어모델(30a)은 의존구조 분석기에 의해 얻은 복수의 동사-목적어 쌍 또는 복수의 서술어-목적어 쌍들 중 가장 빈도가 높은 서술어-목적어 쌍(POP)을 의도 군집의 이름으로 지정할 수 있다. 또한, 언어모델(30a)은, 의존구조 분석기에 의해 얻은 복수의 동사-목적어 쌍 또는 복수의 서술어-목적어 쌍 중 목적어에서 세부 단어들이 기설정된 횟수나 빈도 미만으로 등장할 때, 세부 단어들과 세부 단어들의 상위어 (hypernym)를 확장된 세부 단어들로 고려하거나, 세부 단어들과 세부 단어들의 제1 상위어와 제1 상위어의 상위 어인 제2 상위어를 동일한 클래스로 처리하는 확장된 세부 단어들을 기준으로, 의존구조 분석기에 의해 얻은 복 수의 서술어-목적어 쌍들 중 가장 빈도가 높은 POP를 의도 군집의 이름으로 지정할 수 있다. 한편, 전술한 가장 빈도가 높은 쌍을 의도 군집의 이름으로 지정하는 과정은 언어모델(30a)에 의해 수행되는 것으로 한정되지 않고, 언어모델(30a)과 분리된 형태를 갖는 별도의 수단이나 구성부에 대응하는 명명부(naming unit)(도 1 또는 도 4의 40 참조)에 의해 수행될 수 있다. 위에서 살핀 바와 같이, 본 실시예의 다중 도메인 대화 시스템은 미세 조정 과정을 포함하는 학습 모드에서 발 화와 의도 레이블 간의 일치를 명확하게 하기 위해 확장된 의도 대화의 첫번째 발화만을 사용할 수 있고, 여러 의도를 포함하는 발화를 제외할 수 있다. 특히, 미세 조정 과정에서 의도와 무관한 단어나 발화 스타일을 제거 하기 위해, 의존구조 분석기를 사용하여 의도 대화의 첫번째 발화를 서술어-목적어 쌍으로 변환하거나추출하고, 추출된 서술어-목적어 쌍을 이용하여 지도대조학습(supervised contrastive learning, SCL)을 수행 할 수 있다. 지도대조학습에서는 지도대조 손실함수를 목적함수로 사용하여 SBERT를 백본 네트워크로 하는 언어 모델을 학습시킬 수 있다. 전술한 미세 조정 과정에서 수행된 미세 조정 데이터셋의 분석 결과를 나타내면 표 2와 같다. 표 2 의도 개수 레스토랑 찾기 3561 호텔 검색 3375 열차 찾기 3262 명소 찾기 2795 호텔 예약 1951 열차표 예매 1926 레스토랑 예약 1600 차량 탑승 1262 경찰 찾기 229 합계 19961 본 실시예의 미세 조정 과정은, 비지도 의도 유도(unsupervised intent induction)을 목표로 하기 때문에, 도메 인 전체에서 의도를 식별하기 위해 도메인 변화에 강인한 미세 조정을 필수적으로 수행한다. 이를 위해 본 실시 예에서는 종속성 분석(dependency parsing)을 수행하는 종속구조 분석기(dependency parser)를 사용하여 의도 대화의 발화에서 첫번째 동사-목적어(Verb-Object) 구조 혹은 서술어-목적어 구조를 추출한다. 이러한 추가적인 전처리에 의하면, 언어모델을 미세 조정할 때 관련 없는 단어 또는 발화 스타일의 영향을 제거할 수 있다. 한편, 본 실시예의 추론(inference) 과정에서는 발화와 의도 레이블 간의 일치를 명확하게 하기 위해 확장된 의 도 대화의 전체 발화를 사용할 수 있다. 즉, 추론시의 군집화에서 의도 대화의 전체 발화를 사용하면, 의도 대 화의 첫번째 발화나 초기 일부 발화에 기초하여 하나의 서술어-목적어 쌍을 추출하고 이를 사용하는 경우보다 정규화된 상호 정보(normalized mutual information, NMI) 점수 및 정확도(accuracy, ACC)에서 우수한 성능을 나타낼 수 있다(표 3 참조). 표 3 추론 데이터 NMI ACC 첫번째 발화 (서술어-목적어) 41.89 30.79 전체 발화 (전체 문장) 65.16 56.68 또한, 군집화(clustering) 결과의 설명 가능성을 향상시키기 위해 클러스터링 결과에서 의미 레이블을 자동으로 생성할 수 있다. 의도 이름을 동사와 목적어 쌍으로 나타내는 의도 데이터셋을 추출하는데 이어 종속구조 분석 기를 사용하여 유도된 군집(cluster)의 이름을 동사-목적어 형식 또는 서술어-목적어 형식으로 지정할 수 있다. 특히, 군집에서 일반적인 서술어-목적어 쌍을 세고 가장 일반적인 서술어-목적어 쌍을 사용하면서 의미 군집의 이름으로 해당 쌍을 구성할 수 있다. 그러나 이 방법은 개체에 자세한 단어가 나타날 때 적절한 레이블을 만들 지 못하는 한계가 있다. 예를 들어 \"call-son\"과 \"call-daughter\" 쌍을 \"call-child\"로 그룹화할 수 없다. 이 러한 한계를 극복하기 위해 본 실시예에서는 목적어의 상위어를 추가로 사용하도록 구성될 수 있다. 또한, 구현 에 따라서 상위어의 상위어를 더 사용하도록 구성될 수 있다. 보다 구체적으로는 복수의 서술어-목적어 쌍에서 복수의 서술어-상위어(목적어) 및 서술어-상위어(상위어(목적 어)) 쌍을 생성하고 그 중에 가장 일반적인 쌍을 계산하거나 선택하도록 구성될 수 있다. 이러한 명명(naming) 과정의 처리 결과에서. 가장 일반적인 쌍과 두 번째 빈도의 쌍이 기설정된 가중치(α) 이상 차이가 나지 않을 때 이 규칙을 사용할 수 있다. 가중치(α)는 1.5 내지 2.5, 보다 바람직하게는 2.0으로 설정될 수 있다. 상위어 는 워드넷(WordNet) 등의 자연어 처리 시스템을 통해 얻어질 수 있다. 이와 같이 본 실시예의 다중 도메인 대화 시스템은 상위어를 이용하는 확장된 세부 단어들에 기초하여 군집에서 서술어-목적어 쌍의 빈도를 이용하는 새로운 방식의 군집화 즉, 의미 군집을 생성할 수 있고, 그에 의해 상세한정보를 담고 있는 적절한 단어를 포함하는 군집 즉 의미 군집을 효과적으로 얻을 수 있다. 도 9는 본 실시예의 다중 도메인 대화 시스템의 언어모델(DORIC: DOmain Robust fine-tuning for open Intent Clustering through dpendency parsing)과 비교예의 모델(SBERT 기반의 Baseline)을 각각 다른 도메인의 대화 정보를 학습한 출력값을 시각화하여 나타낸 도면이다. 도 9를 참조하면, 각각 다른 영역 즉, 보험(Insurance), 은행(Banking), 금융(Finance), 여행(Tourism))의 대 화 정보를 학습한 비교예 모델(Basdline)과 본 실시예의 모델(DORIC)의 출력값을 시각화하여 나타낸 결과, 본 실시예의 모델(DORIC)이 같은 의도를 가진 대화 데이터를 더 가까운 공간으로 벡터화하는 것을 확인할 수 있다. 또한, 아래의 표 4는 DORIC를 보험상담 영역(domain)의 데이터셋에 적용한 예시이다. 실험 결과, 상위 3개로 뽑 힌 동사-목적어 쌍(TOP 3 Verb-Object Pairs)이 실제 예측해야하는 결과(Ground-truth, GT)에서 크게 차이나지 않게 예측된 것을 확인할 수 있다. 군집(cluster) 2번과 5번은 상위어를 사용한 결과로, 상의어의 상위어 사용 결과가 실제로 예측해야 하는 결과와 동일함을 확인할 수 있다. 표 4"}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "또한, 아래의 표 5는 DORIC를 은행 영역의 데이터셋에 적용한 예시이다. 보험 상담예시와 마찬가지로, 예측된 상위 3개의 동사-목적어 쌍(TOP3 Verb-Object Paris)이 실제 정답(Ground-truth)과 유사한 결과를 보이는 것을 확인할 수 있다. 그리고 상위어를 사용한 군집(3번 및 5번) 또한 실제 정답과 유사한 예측 결과를 나타내는 것 을 확인할 수 있다. 표 5"}
{"patent_id": "10-2023-0082511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 7, "content": "도 10은 본 발명의 다른 실시예에 따른 다중 도메인 대화 시스템에 대한 개략적인 블록도이다. 도 10을 참조하면, 대화 시스템은 적어도 하나의 프로세서 및 메모리를 포함할 수 있다. 또 한, 대화 시스템은 네트워크와 연결되어 통신을 수행하는 송수신 장치를 더 포함할 수 있다. 또한, 대화 시스템은 입력 인터페이스 장치, 출력 인터페이스 장치, 저장 장치 등을 더 포함 할 수 있다. 대화 시스템에 포함된 각각의 구성 요소들은 버스(bus, 1700)에 의해 연결되어 서로 통신을 수행할 수 있다. 프로세서는 메모리 및 저장 장치 중에서 적어도 하나에 저장된 프로그램 명령(program command)을 실행할 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU), 그래픽 처리 장치(graphics processing unit, GPU), 또는 본 발명의 실시예들에 따른 방법들이 수행되는 전용의 프로세서를의미할 수 있다. 프로세서는 도 1을 참조하여 설명한 프로세서에 대응될 수 있다. 프로그램 명령(program command)은 본 실시예의 다중 도메인 대화 시스템을 학습시키거나 동작시키기 위한 명령을 포함할 수 있다. 이러한 명령은 도 1의 프로세서에 탑재되는 구성요소들 각각의 동작이나 기능을 구현하기 위한 명령을 포함할 수 있다. 메모리 및 저장 장치 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 구성 될 수 있다. 예를 들어, 메모리는 읽기 전용 메모리(read only memory, ROM) 및 랜덤 액세스 메모리 (random access memory, RAM) 중에서 적어도 하나로 구성될 수 있다. 송수신 장치는 근거리 무선 네트워크나 케이블 연결, 위성과의 통신, 범용 기지국과의 유선 또는 무선 통 신, 모바일 에지 코아 네트워크나 코아 네트워크(core network)와의 아이디얼 백홀 링크(ideal backhaul link) 또는 넌(non)-아이디얼 백홀 링크의 연결 등을 위한 통신인터페이스나 서브통신시스템을 포함할 수 있다. 입력 인터페이스 장치는 키보드, 마이크, 터치패드, 터치스크린 등의 입력 수단들에서 선택되는 적어도 하나와 적어도 하나의 입력 수단을 통해 입력되는 신호를 기저장된 명령과 매핑하거나 처리하는 입력 신호 처리 부를 포함할 수 있다. 입력 인터페이스 장치는 도 1의 사용자 발화 입력부를 포함할 수 있다. 출력 인터페이스 장치는 프로세서의 제어에 따라 출력되는 신호를 기저장된 신호 형태나 레벨로 매 핑하거나 처리하는 출력 신호 처리부와, 출력 신호 처리부의 신호에 따라 진동, 빛 등의 형태로 신호나 정보를 출력하는 적어도 하나의 출력 수단을 포함할 수 있다. 적어도 하나의 출력 수단은 스피커, 디스플레이 장치, 프 린터, 광 출력 장치, 진동 출력 장치 등의 출력 수단들에서 선택되는 적어도 하나를 포함할 수 있다. 출력 인터 페이스 장치는 도 1의 시스템 발화 출력부를 포함할 수 있다. 전술한 본 실시예에 따른 방법들은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 매체에 기록되는 프로그램 명령은 본 발명을 위해 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 매체의 예에는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러(compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨터에 의해 실 행될 수 있는 고급 언어 코드를 포함한다. 상술한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 적어도 하 나의 소프트웨어 모듈로 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2023-0082511", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 다중 도메인 대화 시스템의 개략적인 블록도이다. 도 2는 도 1의 다중 도메인 대화 시스템의 주요 작동 원리를 설명하기 위한 흐름도이다. 도 3은 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 언어 모델의 작동 원리를 설명하기 위한 흐름도이다. 도 4는 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 명명부의 구성을 개략적으로 나타낸 블록도이다. 도 5는 도 4의 명명부의 작동 원리를 설명하기 위한 흐름도이다. 도 6은 도 1의 다중 도메인 대화 시스템의 언어 모델에 대한 학습 이전과 이후의 발화 표현을 나타낸 예시도이 다. 도 7은 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 언어 모델의 학습 과정을 설명하기 위한 흐름도이다. 도 8은 도 1의 다중 도메인 대화 시스템에 채용할 수 있는 언어 모델의 추론 과정을 설명하기 위한 흐름도이다. 도 9는 본 실시예의 다중 도메인 대화 시스템의 언어모델과 비교예의 모델을 각각 다른 도메인의 대화 정보를 학습한 출력값을 시각화하여 나타낸 도면이다. 도 10은 본 발명의 다른 실시예에 따른 다중 도메인 대화 시스템에 대한 개략적인 블록도이다."}
