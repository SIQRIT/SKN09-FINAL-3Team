{"patent_id": "10-2022-0085420", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0113118", "출원번호": "10-2022-0085420", "발명의 명칭": "시선 정보에 기초하여 치매를 식별하는 기법", "출원인": "주식회사 하이", "발명자": "김호영"}}
{"patent_id": "10-2022-0085420", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장치의 적어도 하나의 프로세서에 의해 치매를 식별하는 방법에 있어서, 상기 방법은:사용자 단말기에 디스플레이되는 화면의 제1 영역 상에 제1 객체가 디스플레이되도록 야기하는 제1 태스크를 수행하는 단계; 및기 설정된 조건이 만족된 경우, 상기 사용자 단말기의 상기 화면에 상기 제1 객체 대신 사용자의 시선의 이동을유도시키는 적어도 하나의 객체가 디스플레이되도록 야기하는 제2 태스크를 수행하는 단계;를 포함하는, 치매 식별 방법."}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 몇몇 실시예에 의하면 장치의 적어도 하나의 프로세서에 의해 치매를 식별하는 방법이 개시된다. 상기 방법은: 사용자 단말기에 디스플레이되는 화면의 제1 영역 상에 제1 객체가 디스플레이되도록 야기하는 제1 태스 크를 수행하는 단계; 및 기 설정된 조건이 만족된 경우, 상기 사용자 단말기의 상기 화면에 상기 제1 객체 대신 사용자의 시선의 이동을 유도시키는 적어도 하나의 객체가 디스플레이되도록 야기하는 제2 태스크를 수행하는 단 계;를 포함할 수 있다."}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 치매를 식별하는 기법에 관한 것으로, 구체적으로 테스트에 따른 사용자의 시선 정보를 이용하여 치 매를 식별하는 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "알츠하이머 질환(Alzheimer's Disease, AD)은 노화에 따라 수반되는 뇌 질환으로서, 점진적인 기억력 장애, 인 지력 결손, 개인 성격의 변화 등을 초래하는 질병이다. 그리고, 치매(dementia)는 정상적으로 생활해오던 사람 이 다양한 원인에 인해 뇌기능이 손상되면서 발생하는, 지속적이고 전반적인 인지 기능의 저하 상태를 의미한다. 여기서 인지 기능이란 기억력, 언어 능력, 시공간 파악 능력, 판단력 및 추상적 사고력 등 다양한 지 적 능력을 가리키는 것으로서, 각 인지 기능은 뇌의 특정 부위와 밀접한 관련이 있다. 치매의 가장 흔한 형태가 알츠하이머 질환이다. 알츠하이머 질환, 치매 또는 경도 인지 장애를 진단하기 위한 다양한 방법들이 제시되고 있다. 예컨대, 후각 조 직의 miR-206의 발현 수준을 이용하여 알츠하이머 질환 또는 경도 인지 장애를 진단하는 방법, 혈액 내에서 특 징적으로 증가하는 바이오 마커를 이용하여 치매를 진단하는 방법 등이 알려져 있다. 그러나, 후각 조직의 miR-206을 이용하기 위해서는 조직 검사에 필요한 특수 장비 또는 검사가 필요하고, 혈액 내의 바이오 마커를 이용하기 위해서는 침습적인 방법으로 환자의 혈액을 채취해야 하므로, 환자의 거부감이 상 대적으로 크다는 단점이 각각 존재한다. 따라서, 별도의 특수 장비 또는 검사 없이 환자가 거부감을 거의 느끼지 않는 방법으로 치매를 진단할 수 있는 방법을 개발할 필요성이 절실한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 특허출원번호 10-2019-0135908 (2019.02.01 출원)"}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 전술한 문제 및 다른 문제를 해결하는 것을 목적으로 한다. 본 개시의 몇몇 실시예가 이루고자 하는 기술적 과제는, 환자가 거부감을 거의 느끼지 않는 방법으로 정확하게 치매를 진단하는 것을 그 목적으로 한다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시의 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해 될 수 있을 것이다."}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 몇몇 실시예에 의한 장치의 적어도 하나의 프로세서에 의해 치매를 식별하는 방법은: 사용자 단말기 에 디스플레이되는 화면의 제1 영역 상에 제1 객체가 디스플레이되도록 야기하는 제1 태스크를 수행하는 단계; 및 기 설정된 조건이 만족된 경우, 상기 사용자 단말기의 상기 화면에 상기 제1 객체 대신 사용자의 시선의 이 동을 유도시키는 적어도 하나의 객체가 디스플레이되도록 야기하는 제2 태스크를 수행하는 단계; 를 포함할 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 제1 태스크 및 상기 제2 태스크를 기 설정된 횟수만큼 수행하는 단계;를 더 포함할 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 기 설정된 횟수만큼 상기 제2 태스크가 수행되는 동안 상기 사용자와 관 련된 시선 정보를 획득하는 단계; 상기 시선 정보를 치매 식별 모델에 입력하여 스코어 값을 산출하는 단계; 및 상기 스코어 값에 기초하여 치매 여부를 결정하는 단계;를 더 포함할 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 시선 정보는, 상기 제2 태스크가 상기 기 설정된 횟수만큼 수행되는 동 안 상기 사용자의 눈이 포함된 영상을 상기 장치가 상기 사용자 단말기로부터 수신한 후 상기 장치가 상기 영상 을 분석하여 생성될 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 시선 정보는, 상기 장치가 상기 사용자 단말기로부터 수신하는 정보로서, 상기 제2 태스크가 상기 기 설정된 횟수만큼 수행되는 동안 상기 사용자의 눈이 포함된 영상을 상기 사용자 단말기가 분석하여 생성될 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 시선 정보는, 상기 사용자가 기 설정된 시선 과제를 올바르게 수행한 횟 수에 대한 정보, 상기 사용자가 상기 기 설정된 시선 과제를 올바르게 수행하지 못한 횟수에 대한 정보, 사용자 의 시선이 기 설정된 시간 동안 특정 지점을 계속해서 응시하고 있는지에 대한 정보, 상기 적어도 하나의 객체 가 포함된 화면이 디스플레이된 시점부터 상기 사용자의 시선이 상기 적어도 하나의 객체 중 어느 하나의 객체 로 이동한 시점까지 소요된 시간에 대한 정보, 상기 사용자의 시선의 이동 속도에 대한 정보 및 상기 사용자의 시선이 상기 기 설정된 시선 과제와 관련된 지점을 정확하게 응시하고 있는지에 대한 정보 중 적어도 하나를 포 함할 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 적어도 하나의 객체는, 상기 제1 영역 상에 상기 제1 객체 대신 디스플 레이되는 텍스트와 상기 제1 영역과 상이한 제2 영역 및 제3 영역 각각에 디스플레이되는 제2 객체 및 제3 객체 를 포함하고, 상기 제1 영역은, 상기 제2 영역 및 상기 제3 영역 사이에 위치하고, 상기 기 설정된 시선 과제는: 상기 제2 객체 및 상기 제3 객체 중 상기 텍스트의 의미와 관련된 객체를 응시하는 과제; 상기 제2 객 체 및 상기 제3 객체 중 상기 텍스트의 의미와 관련 없는 객체를 응시하는 과제; 상기 제2 객체 및 상기 제3 객 체 중 상기 텍스트의 색상과 관련된 객체를 응시하는 과제; 및 상기 제2 객체 및 상기 제3 객체 중 상기 텍스트 의 색상과 관련 없는 객체를 응시하는 과제;중 적어도 하나를 포함할 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 적어도 하나의 객체는, 상기 제1 영역과 상이한 제2 영역 및 제3 영역 중 어느 하나의 영역에 디스플레이되는 시선 유도 객체를 포함하고, 상기 제1 영역은, 상기 제2 영역 및 상기 제3 영역 사이에 위치하고, 상기 기 설정된 시선 과제는: 상기 시선 유도 객체를 응시하는 과제; 및 상기 시선 유도 객체가 위치하는 방향과 반대 방향을 응시하는 과제; 중 적어도 하나를 포함할 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 기 설정된 조건은, 상기 제1 태스크가 수행되는 동안 획득된 영상을 분 석하여 상기 사용자가 상기 제1 객체를 기 설정된 시간 동안 응시하고 있다고 인식된 경우 만족될 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 기 설정된 조건은, 상기 사용자의 동공의 중심점 위치가 기 설정된 영역 내에 존재한다고 인식된 경우 만족될 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 기 설정된 영역의 크기는, 상기 동공의 크기에 따라 결정될 수 있다. 본 개시의 몇몇 실시예에 의하면, 상기 기 설정된 조건은, 상기 사용자의 동공의 좌표 값이 기 설정된 좌표 값 을 기 설정된 시간 동안 갖는 경우 만족될 수 있다. 본 개시의 몇몇 실시예에 의하면, 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램은 디바이스의 적어도 하나의 프로세서에서 실행되는 경우, 치매를 식별하는 단계들을 수행하며, 상기 단계들은: 사용자 단말기에 디 스플레이되는 화면의 제1 영역 상에 제1 객체가 디스플레이되도록 야기하는 제1 태스크를 수행하는 단계; 및 기 설정된 조건이 만족된 경우, 상기 사용자 단말기의 상기 화면에 상기 제1 객체 대신 사용자의 시선의 이동을 유 도시키는 적어도 하나의 객체가 디스플레이되도록 야기하는 제2 태스크를 수행하는 단계;를 포함할 수 있다. 본 개시의 몇몇 실시예에 의하면, 치매를 식별하는 장치: 적어도 하나의 프로그램 명령이 저장된 저장부; 및 상 기 적어도 하나의 프로그램 명령을 수행하는 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세 서는, 사용자 단말기에 디스플레이되는 화면의 제1 영역 상에 제1 객체가 디스플레이되도록 야기하는 제1 태스 크를 수행하고, 기 설정된 조건이 만족된 경우, 상기 사용자 단말기의 상기 화면에 상기 제1 객체 대신 사용자 의 시선의 이동을 유도시키는 적어도 하나의 객체가 디스플레이되도록 야기하는 제2 태스크를 수행할 수 있다. 본 개시에서 얻을 수 있는 기술적 해결 수단은 이상에서 언급한 해결 수단들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "또 다른 해결 수단들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 치매를 식별하는 기법의 효과에 대해 설명하면 다음과 같다. 본 개시의 몇몇 실시예에 의하면, 환자가 거부감을 거의 느끼지 않는 방법으로 정확하게 치매를 진단할 수 있다. 본 개시를 통해 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들"}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것 이다."}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 개시에 따른 장치 및 장치의 제어 방법의 다양한 실시예(들)를 상세하게 설명하 되, 도면 부호에 관계없이 동일하거나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설 명은 생략하기로 한다. 본 개시의 목적 및 효과, 그리고 그것들을 달성하기 위한 기술적 구성들은 첨부되는 도면과 함께 상세하게 후술 되어 있는 실시예들을 참조하면 명확해질 것이다. 본 개시의 하나 이상의 실시예들을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 적어도 하나의 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 본 개시의 용어들은 본 개시에서의 기능을 고려하여 정의된 용어들로써 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 또한, 첨부된 도면은 본 개시의 하나 이상의 실시예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 개시의 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 본 개시의 작성의 용이함만이 고려되어 부 여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 따라서, 이하에서 언급되는 제1 구성요소는 본 개시의 기술적 사상 내에서 제2 구성 요소 가 될 수도 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 즉, 달리 특정되지 않거나 단 수 형태를 지시하는 것으로 문맥상 명확하지 않은 경우, 본 개시와 청구범위에서 단수는 일반적으로 \"하나 또는 그 이상\"을 의미하는 것으로 해석되어야 한다. 본 개시에서, \"포함하는\", \"포함한다\" 또는 \"가지다\" 등의 용어는 본 개시상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"또는\"이라는 용어는 배타적 의미의 \"또는\"이 아니라 내포적 의미의 \"또는\"으로 이해되어야 한다. 즉, 달리 특정되지 않거나 문맥상 명확하지 않은 경우에, \"X는 A 또는 B를 이용한다\"는 자연적인 내포적 치환 중 하나를 의미하는 것으로 의도된다. 즉, X가 A를 이용하거나; X가 B를 이용하거나; 또는 X가 A 및 B 모두를 이용하는 경우, \"X는 A 또는 B를 이용한다\"가 이들 경우들 어느 것으로도 적용될 수 있다. 또한, 본 개시에 사 용된 \"및/또는\"이라는 용어는 열거된 관련 아이템들 중 하나 이상의 아이템의 가능한 모든 조합을 지칭하고 포 함하는 것으로 이해되어야 한다. 본 개시에서 사용되는 용어 \"정보\" 및 \"데이터\"는 서로 상호 교환 가능하도록 사용될 수 있다."}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다른 정의가 없다면, 본 개시에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시의 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 특별히 정의되어 있지 않는 한 과도하게 해석되지 않는다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있"}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다. 단지 본 개시의 몇몇 실시예들은 본 개시의 기술분야에서 통상의 지식을 가진 자에게 본 개시의 범주를 완 전하게 알려주기 위해 제공되는 것이며, 본 개시는 청구항의 범주에 의해 정의될 뿐이다. 그러므로 그 정의는 본 개시 전반에 걸친 내용을 토대로 내려져야 할 것이다. 본 개시의 몇몇 실시예에 따르면, 장치의 적어도 하나의 프로세서(이하, '프로세서'라고 지칭함)는 치매 식별 모델을 이용하여 사용자가 치매인지 여부를 결정할 수 있다. 구체적으로, 프로세서는 사용자의 시선 정보를 획 득한 후 시선 정보를 치매 식별 모델에 입력하여 스코어 값을 획득할 수 있다. 그리고, 프로세서는 스코어 값에 기초하여 사용자가 치매인지 여부를 결정할 수 있다. 이하에서는, 도 1 내지 도 8을 참조하여 치매를 식별하는 방법에 대해서 설명한다. 도 1은 본 개시의 몇몇 실시예에 따른 치매를 식별하는 시스템을 설명하기 위한 개략도이다. 도 1을 참조하면 치매를 식별하는 시스템은 치매를 식별하는 장치 및 치매 식별을 필요로 하는 사용자의 사용자 단말기를 포함할 수 있다. 그리고, 장치와 사용자 단말기는 유/무선 네트워크를 통 해 통신이 연결될 수 있다. 다만, 도 1에 도시된 시스템을 구성하는 구성요소들은 치매를 식별하는 시스템을 구 현하는데 있어서 필수적인 것은 아니어서, 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 본 개시의 장치는 유/무선 네트워크(wire/wireless network)를 통하여 사용자 단말기와 페어링 또는 연결(pairing or connecting) 가능하며, 이를 통해 소정 데이터를 송/수신할 수 있다. 이 경우, 유/무선 네트워크를 통해 송/수신되는 데이터는 송/수신 전에 변환(converting)될 수 있다. 여기서, “유/무선 네 트워크”라 함은, 장치와 사용자 단말기 사이에서 페어링 또는/및 데이터 송수신을 위해 다양한 통신 규격 내지 프로토콜을 지원하는 통신 네트워크를 통칭한다. 이러한 유/무선 네트워크는, 규격에 의해 현재 또는 향후 지원될 통신 네트워크를 모두 포함하며, 그를 위한 하나 또는 그 이상의 통신 프로토콜들을 모두 지 원 가능하다. 치매를 식별하는 장치는 프로세서, 저장부 및 통신부를 포함할 수 있다. 도 1에 도시된 구 성요소들은 장치를 구현하는데 있어서 필수적인 것은 아니어서, 본 개시에서 설명되는 장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 본 개시의 장치의 각 구성요소는 실제 구현되는 장치의 사양에 따라 통합, 추가, 또는 생략될 수 있 다. 즉, 필요에 따라, 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나 하나의 구성요소가 2 이상의 구성요 소로 세분화될 수 있다. 또한, 각 블록에서 수행하는 기능은 본 개시의 실시예를 설명하기 위한 것이며, 그 구 체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 본 개시에서 설명되는 장치는 데이터(data), 콘텐츠(content), 서비스(service) 및 애플리케이션 (application) 등을 송신 및 수신 중 적어도 하나 이상을 수행하는 모든 디바이스를 포함할 수 있다. 다만, 이 에 한정되는 것은 아니다. 본 개시의 장치에는 예를 들어, 서버(server), PC(Personal Computer), 마이크로프로세서, 메인프레임 컴 퓨터, 디지털 프로세서, 디바이스 제어기 등과 같은 고정형 디바이스(standing device) 스마트 폰(Smart Phone), 태블릿 PC(Tablet PC), 노트북(Notebook) 등과 같은 모바일 디바이스(mobile device or handheld device)가 모두 포함될 수 있다. 다만, 이에 한정되는 것은 아니다. 본 개시에서, \"서버\"라 함은, 다양한 종류의 사용자 단말기 즉, 클라이언트(client)로 데이터를 공급 또는 그로 부터 데이터를 수신하는 장치 혹은 시스템을 의미한다. 서버로 예컨대, 웹 페이지(web page), 웹 컨텐트 또는 웹 서비스(web content or web service)를 제공하는 웹 서버(Web server)나 포털 서버(portal server), 광고 데이터(advertising data)를 제공하는 광고 서버(advertising server), 컨텐트를 제공하는 컨텐트 서버 (content server), SNS(Social Network Service)를 제공하는 SNS 서버, 제조업체(manufacturer)에서 제공하는 서비스 서버(service server), VoD(Video on Demand)나 스트리밍(streaminng) 서비스 제공을 위한 MVPD(Multichannel Video Programming Distributor), 유료 서비스(pay service) 등을 제공하는 서비스 서버 등 이 포함될 수 있다. 본 개시에서 장치로 명명하는 경우, 그 의미는 문맥에 따라 서버를 의미하나, 고정형 디바이스 또는 모바 일 디바이스를 의미할 수도 있고 특별히 언급하지 않는다면 모두 포함하는 의미로 사용될 수도 있다. 프로세서는 응용 프로그램과 관련된 동작 외에도 통상적으로 장치의 전반적인 동작을 제어할 수 있다. 프로세서는 장치의 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거 나 저장부에 저장된 응용 프로그램을 구동함으로써, 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 프로세서는 저장부에 저장된 응용 프로그램을 구동하기 위하여 장치의 구성요소들 중 적어도 일 부를 제어할 수 있다. 나아가, 프로세서는 응용 프로그램의 구동을 위하여 장치에 포함된 구성요소들 중 적어도 둘 이상을 서로 조합하여 동작시킬 수 있다. 프로세서는 하나 이상의 코어로 구성될 수 있으며, 다양한 상용 프로세서들 중 임의의 프로세서일 수 있다. 예를 들어, 프로세서는 장치의 중앙 처리 장치(CPU: Central Processing Unit), 범용 그래픽 처리 장치 (GPUGP: General Purpose Graphics Processing Unit), 텐서 처리 장치(TPU: Tensor Processing Unit) 등 을 포함할 수 있다. 다만, 이에 한정되는 것은 아니다. 본 개시의 프로세서는 듀얼 프로세서 또는 기타 멀티프로세서 아키텍처로 구성될 수 있다. 다만, 이에 한 정되는 것은 아니다. 프로세서는 저장부에 저장된 컴퓨터 프로그램을 판독하여 본 개시의 몇몇 실시예에 따른 치매 식별 모델을 이용하여 사용자가 치매인지 여부를 식별할 수 있다. 저장부는, 장치의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 저장부는 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 장치의 동작을 위한 데이터들, 명령어들, 적어도 하나의 프로그램 명령을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일 부는, 무선 통신을 통해 외부 서버로부터 다운될 수 있다. 또한, 이러한 응용 프로그램 중 적어도 일부는, 장치 의 기본적인 기능을 위하여 출고 당시부터 장치 상에 존재할 수도 있다. 한편, 응용 프로그램은, 저 장부에 저장되고, 장치 상에 설치되어 프로세서에 의하여 장치의 동작(또는 기능)을 수행 하도록 구동될 수 있다. 저장부는 프로세서에서 생성하거나 결정한 임의의 형태의 정보 및 통신부를 통해 수신한 임의의 형태의 정보를 저장할 수 있다. 저장부는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 장치는 인터넷(internet) 상에서 저장부의 저장 기능을 수행하는 웹 스토리지(web storage)와 관련되어 동작될 수도 있다. 통신부는 장치와 유선/무선 통신 시스템 사이, 장치와 다른 장치 사이 또는 장치와 외부 서버 사이의 유선/무선 통신을 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 또한, 통신부는 장치 를 하나 이상의 네트워크에 연결하는 하나 이상의 모듈을 포함할 수 있다. 통신부는 유선/무선 인터넷 접속을 위한 모듈을 말하는 것으로 장치에 내장되거나 외장될 수 있다. 통신부는 유선/무선 신호를 송수신하도록 이루어질 수 있다. 통신부는 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV- DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등)에 따라 구축된 이동 통신망 상에서 기지국, 외부의 단말 및 서버 중 적어도 하나 와 무선 신호를 송수신할 수 있다. 무선 인터넷 기술로는, 예를 들어 WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등이 있을 수 있다. 다만, 상기에 서 나열되지 않은 인터넷 기술까지 포함한 범위에서 적어도 하나의 무선 인터넷 기술에 따라 통신부는 데 이터를 송수신할 수 있다. 더불어, 통신부는 근거리 통신(Short range communication)을 통해 신호를 송수신하도록 이루어질 수도 있 다. 통신부는 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless- Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여 근 거리 통신을 수행할 수 있다. 통신부는 근거리 통신망(Wireless Area Networks)을 통해 무선 통신을 지원 할 수 있다. 근거리 무선 통신망은 근거리 무선 개인 통신망(Wireless Personal Area Networks)일 수 있다. 본 개시의 몇몇 실시예에 따른 장치는 통신부를 통해 사용자 단말기와 유/무선 네트워크가 연결될 수 있다. 본 개시에서 사용자 단말기는 유/무선 네트워크(wire/wireless network)를 통하여 치매 식별 모델이 저장된 장치와 페어링 또는 연결(pairing or connecting) 가능하며, 이를 통해 소정 데이터를 송/수신 및 디스플레이할 수 있다. 본 개시에서 설명되는 사용자 단말기는 데이터(data), 콘텐츠(content), 서비스(service) 및 애플리케이션 (application) 등을 송신, 수신 및 디스플레이 중 적어도 하나 이상을 수행하는 모든 디바이스를 포함할 수 있 다. 그리고, 사용자 단말기는 치매인지 여부를 확인하고 싶어하는 사용자의 단말기를 의미할 수 있다. 다 만, 이에 한정되는 것은 아니다. 본 개시에서 사용자 단말기는 예를 들어, 휴대폰, 스마트 폰(smart phone), 태블릿 PC(tablet PC), 울트 라북(ultrabook) 등과 같은 이동 단말기(mobile device)를 포함할 수 있다. 다만, 이에 한정되는 것은 아니고, 사용자 단말기는 PC(Personal Computer), 마이크로프로세서, 메인프레임 컴퓨터, 디지털 프로세서, 디바이 스 제어기 등과 같은 고정형 디바이스(standing device)도 포함할 수 있다. 사용자 단말기는 프로세서, 저장부, 통신부, 영상 획득부, 디스플레이부 및 음 향 출력부를 포함할 수 있다. 도 1에 도시된 구성요소들은 사용자 단말기를 구현하는데 있어서 필수 적인 것은 아니어서, 본 개시에서 설명되는 사용자 단말기는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 본 개시의 사용자 단말기의 각 구성요소는 실제 구현되는 사용자 단말기의 사양에 따라 통합, 추가, 또는 생략될 수 있다. 즉, 필요에 따라, 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나 하나의 구성요소가 2 이상의 구성요소로 세분화될 수 있다. 또한, 각 블록에서 수행하는 기능은 본 개시의 실시예를 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 사용자 단말기의 프로세서, 저장부 및 통신부는 장치의 프로세서, 저장부 및 통신부와 동일한 구성 요소이므로, 중복되는 설명은 생략하고, 이하 차이점을 중심으로 설명한다. 본 개시에서 사용자 단말기의 프로세서는 치매 여부를 식별하기 위한 화면을 디스플레이하기 전에 제 1 객체를 화면의 제1 영역 상에 디스플레이하도록 디스플레이부를 제어할 수 있다. 그리고, 사용자 단말기 는 기 설정된 조건이 만족된 때 제1 객체 대신 사용자의 시선의 이동을 유도시키는 적어도 하나의 객체가 디스플레이되도록 디스플레이부를 제어할 수 있다. 이에 대한 자세한 설명은 도 2를 참조하여 후술한다. 한편, 치매 식별 모델을 이용한 연산을 수행하기 위해서는 높은 처리 속도 및 연산 능력이 필요하기 때문에 치 매 식별 모델은 장치의 저장부에만 저장되어 있고, 사용자 단말기의 저장부에는 저장되어 있지 않을 수 있다. 다만, 이에 한정되는 것은 아니다. 영상 획득부는 하나 또는 복수의 카메라를 포함할 수 있다. 즉, 사용자 단말기는 전면부 또는 후면부 중 적어도 하나에 하나 또는 복수의 카메라를 포함하고 있는 장치일 수 있다. 영상 획득부는 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화상 프레임을 처리할 수 있다. 처리된 화상 프레임은 디스플레이부에 표시되거나 저장부에 저장될 수 있다. 한편, 사용자 단말기 에 구비되는 영상 획득부는 복수의 카메라가 매트릭스 구조를 이루도록 매치될 수 있다. 이와 같이 매트릭스 구조를 이루는 카메라를 통하여 사용자 단말기에는 다양한 각도 또는 초점을 잦는 복수의 영상 정보가 입력될 수 있다. 본 개시의 영상 획득부는 적어도 하나의 라인을 따라 배열되는 복수의 렌즈를 포함할 수 있다. 복수의 렌 즈는 행렬(matrix) 형식으로 배열될 수 있다. 이러한 카메라는, 어레이 카메라로 명명될 수 있다. 영상 획득부 가 어레이 카메라로 구성되는 경우, 복수의 렌즈를 이용하여 다양한 방식으로 영상을 촬영할 수 있으며, 보다 나은 품질의 영상을 획득할 수 있다. 본 개시의 몇몇 실시예에 따르면, 영상 획득부는 사용자 단말기에 특정 화면이 디스플레이되는 것과 연동 하여 사용자 단말기의 사용자의 눈이 포함된 영상을 획득할 수 있다. 디스플레이부는 사용자 단말기에서 처리되는 정보를 표시(출력)할 수 있다. 예를 들어, 디스플레이부 는 사용자 단말기에서 구동되는 응용 프로그램의 실행 화면 정보 또는 이러한 실행 화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 다만, 이에 한정되는 것은 아니다. 본 개시의 몇몇 실시예에 따르면, 디스플레이부는 제1 태스크가 수행될 때, 화면의 제1 영역 상에 제1 객 체(예를 들어, 십자가 모양의 객체)를 디스플레이할 수 있다. 그리고, 디스플레이부는 제2 태스크가 수행 될 때 화면의 제1 영역 상에 제1 객체 대신 사용자의 시선의 이동을 유도시키는 적어도 하나의 객체를 디스플레 이할 수 있다. 음향 출력부는 통신부로부터 수신되거나 저장부에 저장된 오디오 데이터(또는 음향 데이터 등) 를 출력할 수 있다. 음향 출력부는 사용자 단말기에서 수행되는 기능과 관련된 음향 신호를 출력하기 도 한다. 음향 출력부는 리시버(receiver), 스피커(speaker), 버저(buzzer) 등을 포함할 수 있다. 즉, 음향 출력부 는 리시버(receiver)로 구현될 수도 있으며 라우드 스피커(loud speaker)의 형태로 구현될 수도 있다. 다 만, 이에 한정되는 것은 아니다. 본 개시의 몇몇 실시예에 따르면, 음향 출력부는 제1 태스크 또는 제2 태스크를 수행하는 것과 연동하여 기 설정된 음향(예를 들어, 제1 태스크 또는 제2 태스크를 통해 사용자가 수행해야 되는 작업을 설명하는 음 성)을 출력할 수 있다. 다만, 이에 한정되는 것은 아니다. 본 개시의 몇몇 실시예에 따르면, 장치는 사용자 단말기로부터 수신된 사용자의 눈이 포함된 영상을 획득하여 사용자의 치매 여부를 결정할 수 있다. 다만, 사용자 단말기는 고정 단말기가 아니기 때문에 영 상을 획득할 때 특수한 태스크를 거칠 필요가 있다. 이하, 도 2를 참조하여, 사용자의 눈이 포함된 영상을 획득 하기 위한 태스크를 설명한다. 도 2는 본 개시의 몇몇 실시예에 따른 장치가 치매 식별을 위한 영상을 획득하는 방법의 일례를 설명하기 위한 흐름도이다. 도 3은 본 개시의 몇몇 실시예에 따른 사용자 단말기에서 치매 식별을 위한 영상을 획득할 때 디스 플레이되는 화면의 일례를 설명하기 위한 도면이다. 도 4는 본 개시의 몇몇 실시예에 따라 사용자 단말기의 사 용자가 기 설정된 조건을 만족했는지 여부를 인식하는 방법의 일례를 설명하기 위한 도면이다. 도 5 및 도 6은 본 개시의 몇몇 실시예에 따른 사용자 단말기에서 시선 정보를 획득할 때 디스플레이되는 화면의 일례를 설명하 기 위한 도면들이다. 도 2 내지 도 6과 관련하여 도 1에서 상술한 바와 중복되는 내용은 다시 설명하지 않으며, 이하 차이점을 중심으로 설명한다. 도 2를 참조하면, 장치의 프로세서는 사용자 단말기에 디스플레이되는 화면의 제1 영역 상에 제 1 객체가 디스플레이도록 야기하는 제1 태스크를 수행할 수 있다(S110). 일례로, 장치의 프로세서는 제1 영역 상에 제1 객체가 포함된 화면을 생성하여 사용자 단말기에 전송할 수 있다. 이 경우, 사용자 단말기는 제1 객체가 제1 영역 상에 포함된 화면을 디스플레이할 수 있 다. 다른 일례로, 사용자 단말기의 저장부에 제1 객체가 제1 영역 상에 포함된 화면이 저장되어 있을 수 있다. 사용자 단말기의 프로세서는 장치에서 저장부에 저장되어 있는 상기 화면을 디스플 레이하라는 신호를 통신부를 통해 수신한 경우, 사용자 단말기에 상기 화면을 디스플레이하도록 디스 플레이부를 제어할 수 있다. 또 다른 일례로, 사용자 단말기의 저장부에 제1 객체의 이미지가 저장되어 있을 수 있다. 이 경우, 장치의 프로세서가 통신부를 통해 제1 객체가 포함된 화면을 디스플레이하라는 신호를 사용자 단말기에 전송한 경우, 사용자 단말기의 프로세서가 제1 영역 상에 제1 객체가 포함된 화면을 생성하여 디스플레이할 수 있다. 다만, 상술한 예시들을 일례에 불과하므로, 본 개시는 상술한 예시들에 한정되는 것은 아니다. 도 3을 참조하면, 사용자 단말기에 디스플레이되는 화면은 제1 영역(R1)에 제1 객체(O1)를 포함할 수 있다. 제1 객체(O1)는 사용자의 시선이 디스플레이되는 화면의 중앙에 올 수 있도록 유도하는 객체일 수 있다. 예를 들어, 제1 객체(O1)는 십자가 형상을 갖는 객체일 수 있다. 다만, 제1 객체(O1)는 상술한 예시에 한정되는 것은 아니고 다양한 형상 또는 모양을 가질 수 있다. 제1 영역(R1)은 화면의 정중앙에 위치하는 영역일 수 있다. 따라서, 제1 객체(O1)를 응시하는 사용자의 시선은 화면의 중앙으로 올 수 있다. 다만, 이에 한정되는 것은 아니다. 한편, 본 개시의 몇몇 실시예에 따르면, 사용자 단말기에 디스플레이되는 화면 상에는 현재 디스플레이되 는 화면을 통해 사용자가 수행해야하는 작업이 무엇인지 알려주는 내용의 메시지(M1)가 디스플레이될 수 있다. 예를 들어, 메시지(M1)는 현재 화면 상에 디스플레이되고 있는 제1 객체(O1)를 쳐다보라는 내용을 포함할 수 있 다. 더불어, 사용자 단말기는 디스플레이부를 통해 메시지(M1)를 화면 상에 디스플레이하는 것과 연 동하여 음향 출력부를 통해 메시지(M1)와 관련된 음향(예를 들어, 메시지(M1) 내에 포함된 내용을 설명하 는 음성)을 출력할 수도 있다. 이와 같이, 메시지(M1)와 함께 음향을 출력하여 사용자가 수행해야하는 작업을 사용자에게 인지시키는 경우 사용자가 현재 수행해야하는 작업이 무엇인지 명확하게 이해할 수 있다. 따라서, 단순 실수로 잘못된 작업을 수행할 가능성이 낮아질 수 있다. 다시, 도 2를 참조하면, 장치의 프로세서는 단계(S110)에서 제1 객체를 화면의 제1 영역 상에 디스플 레이한 경우, 기 설정된 조건이 만족되는지 여부를 확인할 수 있다(S120). 일례로, 사용자 단말기는 디스플레이되는 화면의 제1 영역(R1) 상에 제1 객체(O1)가 디스플레이되는 것(제 1 태스크를 수행하는 것)과 연동하여 사용자 단말기의 사용자의 눈이 포함된 영상을 영상 획득부를 통해 획득할 수 있다. 사용자 단말기에서 영상을 분석하여 기 설정된 조건이 만족되는지 여부를 확인할 수 있다. 그리고, 사용자 단말기에서 기 설정된 조건이 만족되었다고 인식된 경우, 사용자 단말기의 프 로세서는 통신부를 통해 기 설정된 조건이 만족되었다는 신호를 장치에 전송할 수 있다. 이 경 우, 장치는 기 설정된 조건이 만족되었다고 인식할 수 있다. 다른 일례로, 사용자 단말기는 디스플레이되는 화면의 제1 영역(R1) 상에 제1 객체(O1)가 디스플레이되는 것(제1 태스크를 수행하는 것)과 연동하여 사용자 단말기의 사용자의 눈이 포함된 영상을 영상 획득부를 통해 획득할 수 있다. 사용자 단말기는 획득된 영상을 장치에 전송하도록 통신부를 제어할 수 있다. 장치의 프로세서는 통신부를 통해 사용자의 눈이 포함된 영상을 수신한 경우, 상기 영상 을 분석하여 기 설정된 조건이 만족되는지 여부를 확인할 수 있다. 다만, 상술한 예시들은 일 예시에 불과할 뿐 본 개시는 상술한 예시들에 한정되는 것은 아니다. 기 설정된 조건은, 제1 태스크가 수행되는 동안(즉, 제1 객체(O1)가 제1 영역(R1) 상에 디스플레이되는 동안) 획득된 영상을 분석하여 제1 사용자가 제1 객체를 기 설정된 시간 동안 응시하고 있다고 인식된 경우 만족될 수 있다. 일례로, 도 4를 참조하면, 기 설정된 조건은 사용자(U)의 동공(E)의 중심점(M) 위치가 기 설정된 영역(Rs) 내에 기 설정된 시간 동안 존재한다고 인식된 경우 만족될 수 있다. 여기서, 기 설정된 영역(Rs)은 사용자의 눈이 디 스플레이부의 정중앙을 주시하고 있을 때 사용자(U)의 동공(E)의 중심점(M)이 위치할 수 있는 영역에 대응 할 수 있다. 구체적으로, 장치의 프로세서는 획득된 영상에 포함된 복수의 프레임 각각의 RGB 값 중 B 값만 이용 하여 복수의 프레임 각각에서 사용자(U)의 동공(E)의 위치를 확인할 수 있다. 즉, 프로세서는 복수의 프레 임 각각에서 기 설정된 임계 값을 초과하는 B 값을 갖는 영역이 동공(E)이 위치하는 영역이라고 인식할 수 있다. 그리고, 프로세서는 동공(E)이 위치하는 영역의 중심점의 위치가 기 설정된 영역(Rs) 내에 존재한다 고 인식한 경우 기 설정된 조건이 만족된다고 인식할 수 있다. 다만, 이에 한정되는 것은 아니고, 상술한 동공 (E)의 위치를 확인하는 방법은 사용자 단말기의 프로세서에 의해서 수행될 수도 있다. 다른 일례로, 기 설정된 조건은 사용자의 동공(E)의 좌표 값이 기 설정된 좌표 값을 기 설정된 시간 동안 갖는 경우 만족될 수 있다. 여기서, 동공(E)의 좌표 값은 동공(E)의 중심점(M)의 좌표 값일 수도 있고, 동공(E)의 테 두리가 갖는 좌표 값들일 수도 있다. 그리고, 기 설정된 좌표 값은 사용자가 사용자 단말기의 디스플레이 부의 정 중앙을 응시하고 있을 때 동공(E)이 위치하는 좌표 값일 수 있다. 다만, 이에 한정되는 것은 아니 다. 본 개시의 몇몇 실시예에 따르면, 프로세서는 획득된 영상에서 동공(E)과 배경을 구분할 수 있다. 그리고, 프로세서는 동공(E)의 위치에 해당하는 부분은 검정색으로 변경하고 배경에 해당하는 부분은 흰색으로 변 경하는 이진화(binarization) 과정을 거칠 수 있다. 그리고, 프로세서는 이진화 과정을 거친 후에 노이즈 를 제거하기 위해 플러드 필(flood fill)을 적용할 수 있다. 여기서, 플러드 필이란 검정 픽셀로 둘러싸인 흰 픽셀을 검정 픽셀로 바꾸고, 흰 픽셀로 둘러싸인 검정 픽셀은 흰 픽셀로 바꾸는 작업을 의미할 수 있다. 그 다 음, 프로세서는 획득된 영상을 이용하여 동공의 중심점의 위치가 기 설정된 영역(Rs) 내에 위치하는지 인 식할 수 있다. 본 개시의 몇몇 실시예에 따르면, 기 설정된 영역(Rs)의 크기는 동공(E)의 크기에 따라 결정될 수 있다. 사용자 의 동공(E)의 크기는 사용자 마다 다를 수 있기 때문에 동공의 크기에 따라 기 설정된 영역(Rs)의 크기가 달라 지면 기 설정된 조건이 만족되었는지 여부를 판단하는 것에 대한 정확도가 향상될 수 있다. 좀더 구체적으로, 프로세서는 사용자(U)의 눈이 포함된 영상을 획득한 경우, 영상을 분석하여 동공(E)의 크기를 인식할 수 있다. 그리고, 프로세서는 동공(E)의 크기에 기초하여 기 설정된 영역(Rs)의 크기를 결 정할 수 있다. 기 설정된 영역(Rs)의 크기는 동공(E)의 크기에 비례할 수 있다. 그리고, 기 설정된 영역(Rs)의 크기는 동공(E)의 크기 보다는 작을 수 있다. 본 개시의 몇몇 실시예에 따르면, 사용자 단말기의 프로세서는 제1 객체(O1)가 포함된 화면이 디스플 레이되는 동안 영상 획득부를 활성화하여 사용자의 눈이 포함된 영상을 획득할 수 있다. 이 경우, 프로세 서는 영상 내에 사용자의 눈이 포함되었는지 여부를 확인할 수 있다. 만약, 프로세서가 영상 내에 사 용자의 눈이 포함되어 있지 않다고 인식한 경우, 프로세서는 계속해서 영상을 획득하면서 제1 객체(O1)가 제1 영역(R1) 상에 위치하는 화면을 디스플레이하도록 디스플레이부를 제어할 수 있다. 다만, 이에 한정되 는 것은 아니다. 도 2를 다시 참조하면, 장치의 프로세서는 기 설정된 조건이 만족되지 않았다고 인식한 경우(S120, No), 제1 객체를 사용자 단말기에 디스플레이되는 화면의 제1 영역 상에 계속 디스플레이하도록 야기할 수 있다(S110). 한편, 장치는 기 설정된 조건이 만족되었다고 인식한 경우(S120, Yes), 장치의 프로세서는 사용 자 단말기가 화면에 제1 객체 대신 사용자의 시선의 이동을 유도시키는 적어도 하나의 객체가 디스플레이 되도록 야기하는 제2 태스크를 수행할 수 있다(S130). 단계(S130)와 관련된 일례로, 장치의 프로세서는 사용자 단말기가 제2 객체, 제3 객체 및 텍스 트를 포함하는 화면을 디스플레이하도록 야기하는 서브 태스크를 수행할 수 있다. 이 경우, 사용자 단말기(20 0)는 제1 객체 대신 텍스트를 제1 영역 상에 디스플레이하는 것과 연동하여 제2 영역 및 제3 영역 각각에 제2 객체 및 제3 객체를 디스플레이할 수 있다. 즉, 적어도 하나의 객체는, 제1 영역 상에 제1 객체 대신 디스플레 이되는 텍스트와 제1 영역과 상이한 제2 영역 및 제3 영역 각각에 디스플레이되는 제2 객체 및 제3 객체를 포함 할 수 있다. 좀더 구체적으로, 도 5를 참조하면, 기 설정된 조건이 만족되는 경우 사용자 단말기에 디스플레이되는 화 면은 제1 영역(R1)에 제1 객체(도 3의 O1) 대신 텍스트(T)를 포함할 수 있고, 제1 영역(R1)과 상이한 제2 영역 (R2) 및 제3 영역(R3) 각각에 제2 객체(O2) 및 제3 객체(O3)를 포함할 수 있다. 여기서, 제2 객체(O2), 제3 객 체(O3) 및 텍스트(T)를 포함하는 화면은 2000ms 동안 디스플레이될 수 있다. 다만, 이에 한정되는 것은 아니다. 제2 객체(O2) 및 제3 객체(O3)는 동일한 형상(예를 들어, 직경이 0.2cm인 원형 형상 등)을 갖고 색체만 서로 상 이할 수 있다. 이 경우, 제2 객체(O2) 및 제3 객체(O3) 중 어느 하나의 객체는 텍스트(T)가 의미하는 색상을 가 질 수 있고, 다른 객체는 텍스트(T)가 의미하는 색상과 다른 색상을 가질 수 있다. 다만, 이에 한정되는 것은 아니고, 제2 객체(O2) 및 제3 객체(O3)는 서로 다른 형상을 갖고 색체도 상이할 수도 있다. 제1 영역(R1)은 제2 영역(R2) 및 제3 영역(R3) 사이에 위치할 수 있다. 즉, 제2 영역(R2) 및 제3 영역(R3)이 정 중앙에 위치하는 제1 영역(R1)의 양 측면에 위치할 수 있다. 다만, 이에 한정되는 것은 아니다. 텍스트(T)는 색상 또는 형상을 의미하는 단어일 수 있다. 다만, 텍스트(T)의 의미는 상술한 예시에 한정되는 것 은 아니다. 만약, 텍스트(T)의 의미가 색상과 관련된 경우, 텍스트(T) 자체의 색상은 텍스트(T)가 의미하는 색상과 동일할 수도 있고 상이할 수도 있다. 다만, 이에 한정되는 것은 아니다. 한편, 본 개시의 몇몇 실시예에 따르면, 사용자 단말기에 디스플레이되는 화면 상에는 사용자가 수행해야 하는 기 설정된 시선 과제가 무엇인지 알려주는 내용의 메시지(M2)가 디스플레이될 수 있다. 여기서, 기 설정된 시선 과제는 사용자가 어떤 객체를 응시해야 하는지를 나타낼 수 있다. 몇몇 실시예에 따르면, 기 설정된 시선 과제는 제2 객체(O2) 및 제3 객체(O3) 중 텍스트(T)의 의미와 관련된 객 체를 응시하는 과제일 수 있다. 이 경우, 텍스트(T)의 의미는 형상과 관련될 수도 있고, 색상과 관련될 수도 있다. 다만, 텍스트(T)의 의미는 상술한 예시에 한정되는 것은 아니다. 일례로, 텍스트(T)가 빨강을 의미하고, 제2 객체(O2)는 빨간색을 갖고 제3 객체(O3)는 파란색을 가질 수 있다. 그리고, 화면에 디스플레이되는 메시지(M2)는 텍스트(T)가 가리키는 색상의 객체를 응시하라는 내용을 포함할 수 있다. 이 경우, 사용자가 제2 객체(O2)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 다른 일례로, 도면에 도시되지는 않았지만, 텍스트(T)가 원을 의미하고, 제2 객체(O2)는 원형 형상을 갖고 제3 객체(O3)는 사각형 형상을 가질 수 있다. 그리고, 화면에 디스플레이되는 메시지(M2)는 텍스트(T)가 가리키는 형상의 객체를 응시하라는 내용을 포함할 수 있다. 이 경우, 사용자가 제2 객체(O2)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 다른 몇몇 실시예에 따르면, 기 설정된 시선 과제는 제2 객체(O2) 및 제3 객체(O3) 중 텍스트(T)의 의미와 관련 없는 객체를 응시하는 과제일 수 있다. 이 경우, 텍스트(T)의 의미는 형상과 관련될 수도 있고, 색상과 관련될 수도 있다. 다만, 텍스트(T)의 의미는 상술한 예시에 한정되는 것은 아니다. 일례로, 텍스트(T)가 빨강을 의미하고, 제2 객체(O2)는 빨간색을 갖고 제3 객체(O3)는 파란색을 가질 수 있다. 그리고, 화면에 디스플레이되는 메시지(M2)는 텍스트(T)가 가리키는 색상을 갖지 않는 객체를 응시하라는 내용 을 포함할 수 있다. 이 경우, 사용자가 제3 객체(O3)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수 행하는 것일 수 있다. 다른 일례로, 텍스트(T)가 원을 의미하고, 제2 객체(O2)는 원형 형상을 갖고 제3 객체(O3)는 사각형 형상을 가 질 수 있다. 그리고, 화면에 디스플레이되는 메시지(M2)는 텍스트(T)가 가리키는 형상을 갖지 않는 객체를 응시 하라는 내용을 포함할 수 있다. 이 경우, 사용자가 제3 객체(O3)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 또 다른 몇몇 실시예에 따르면, 기 설정된 시선 과제는 제2 객체(O2) 및 제3 객체(O3) 중 텍스트(T) 자체의 색 상과 관련된 객체를 응시하는 과제일 수 있다. 이 경우, 텍스트(T) 자체의 색상은 텍스트(T)의 의미와 상이할 수도 있고, 텍스트(T)의 의미와 동일할 수도 있다. 일례로, 텍스트(T)가 빨강을 의미하고, 텍스트(T)의 색상이 빨간색일 수 있고, 제2 객체(O2)는 빨간색을 갖고 제3 객체(O3)는 파란색을 가질 수 있다. 그리고, 화면에 디스플레이되는 메시지(M2)는 텍스트(T)의 색상을 갖는 객체를 응시하라는 내용을 포함할 수 있다. 이 경우, 사용자가 제2 객체(O2)를 응시하는 것이 사용자가 기 설정 된 과제를 올바르게 수행하는 것일 수 있다. 다른 일례로, 텍스트(T)가 빨강을 의미하고, 텍스트(T)의 색상이 텍스트(T)의 의미와 상이한 파란색일 수 있고, 제2 객체(O2)는 빨간색을 갖고 제3 객체(O3)는 파란색을 가질 수 있다. 그리고, 화면에 디스플레이되는 메시지 (M2)는 텍스트(T)의 색상을 갖는 객체를 응시하라는 내용을 포함할 수 있다. 이 경우, 사용자가 제3 객체(O3)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 또 다른 몇몇 실시예에 따르면, 기 설정된 시선 과제는 제2 객체(O2) 및 제3 객체(O3) 중 텍스트(T) 자체의 색 상과 관련 없는 객체를 응시하는 과제일 수 있다. 이 경우, 텍스트(T) 자체의 색상은 텍스트(T)의 의미와 상이 할 수도 있고, 텍스트(T)의 의미와 동일할 수도 있다. 일례로, 텍스트(T)가 빨강을 의미하고, 텍스트(T)의 색상이 빨간색일 수 있고, 제2 객체(O2)는 빨간색을 갖고 제3 객체(O3)는 파란색을 가질 수 있다. 그리고, 화면에 디스플레이되는 메시지(M2)는 텍스트(T)의 색상을 갖지 않는 객체를 응시하라는 내용을 포함할 수 있다. 이 경우, 사용자가 제3 객체(O3)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 다른 일례로, 텍스트(T)가 빨강을 의미하고, 텍스트(T)의 색상이 텍스트(T)의 의미와 상이한 파란색일 수 있고, 제2 객체(O2)는 빨간색을 갖고 제3 객체(O3)는 파란색을 가질 수 있다. 그리고, 화면에 디스플레이되는 메시지 (M2)는 텍스트(T)의 색상을 갖지 않는 객체를 응시하라는 내용을 포함할 수 있다. 이 경우, 사용자가 제2 객체 (O2)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 한편, 사용자 단말기는 디스플레이부를 통해 메시지(M2)를 화면 상에 디스플레이하는 것과 연동하여 음향 출력부를 통해 메시지(M2)와 관련된 음향(예를 들어, 메시지(M2) 내에 포함된 내용을 설명하는 음 성)을 출력할 수도 있다. 이와 같이, 메시지(M2)와 함께 음향으로 사용자가 수행해야하는 기 설정된 시선 과제 를 사용자에게 인지시키는 경우 사용자가 현재 수행해야하는 기 설정된 시선 과제가 무엇인지 명확하게 이해할수 있다. 따라서, 단순 실수로 잘못된 시선 과제를 수행할 가능성이 낮아질 수 있다. 결과적으로, 기 설정된 시선 과제는 상기 제2 객체 및 상기 제3 객체 중 상기 텍스트의 의미와 관련된 객체를 응시하는 과제, 상기 제2 객체 및 상기 제3 객체 중 상기 텍스트의 의미와 관련 없는 객체를 응시하는 과제, 상 기 제2 객체 및 상기 제3 객체 중 상기 텍스트의 색상과 관련된 객체를 응시하는 과제 및 상기 제2 객체 및 상 기 제3 객체 중 상기 텍스트의 색상과 관련 없는 객체를 응시하는 과제 중 적어도 하나를 포함할 수 있다. 그 리고, 화면에 디스플레이되는 메시지(M2)에는 기 설정된 시선 과제가 무엇인지에 대한 내용이 포함될 수 있다. 단계(S130)와 관련된 다른 일례로, 장치의 프로세서는 사용자 단말기가 제1 영역과 상이한 제2 영역 및 제3 영역 중 어느 하나의 영역에 시선 유도 객체를 디스플레이하도록 야기하는 서브 태스크를 수행할 수 있다. 이 경우, 사용자 단말기는 제1 객체를 디스플레이하는 것 대신 제1 영역과 상이한 제2 영역 또는 제3 영역에 시선 유도 객체를 디스플레이할 수 있다. 즉, 적어도 하나의 객체는, 제1 영역과 상이한 제2 영역 및 제3 영역 중 어느 하나의 영역에 디스플레이되는 시선 유도 객체를 포함할 수 있다. 좀더 구체적으로, 도 6의 (a) 및 (b)를 참조하면, 기 설정된 조건이 만족되는 경우 사용자 단말기에 디스 플레이되는 화면은 도 3의 제1 영역(R1)과 상이한 제2 영역(R2) 및 제3 영역(R3) 중 어느 하나의 영역(R2)에 디 스플레이되는 시선 유도 객체(O4)를 포함할 수 있다. 여기서, 제2 영역(R2) 및 제3 영역(R3) 중 어느 하나의 영 역은 랜덤하게 선택될 수 있고, 시선 유도 객체(O4)를 포함하는 화면은 2000ms 동안 디스플레이될 수 있다. 다 만, 이에 한정되는 것은 아니다. 시선 유도 객체(O4)는 기 설정된 형상(예를 들어, 직경이 0.2cm인 원형 형상 등)과 기 설정된 색체(예를 들어, 빨간색)을 갖는 객체일 수 있다. 제1 영역(R1)은 제2 영역(R2) 및 제3 영역(R3) 사이에 위치할 수 있다. 즉, 제2 영역(R2) 및 제3 영역(R3)이 정 중앙에 위치하는 제1 영역(R1)의 양 측면에 위치할 수 있다. 다만, 이에 한정되는 것은 아니다. 한편, 본 개시의 몇몇 실시예에 따르면, 사용자 단말기에 디스플레이되는 화면 상에는 사용자가 수행해야 하는 기 설정된 시선 과제가 무엇인지 알려주는 내용의 메시지(M3, M4)가 디스플레이될 수 있다. 여기서, 기 설 정된 시선 과제는 사용자가 어떤 객체를 응시해야 하는지를 나타낼 수 있다. 도 6의 (a)를 참조하면, 기 설정된 시선 과제는 시선 유도 객체(O4)를 응시하는 과제일 수 있다. 그리고, 화면 에 디스플레이되는 메시지(M3)는 시선 유도 객체(O4)를 빠르게 응시하라는 내용을 포함할 수 있다. 이 경우, 사 용자가 시선 유도 객체(O4)를 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 도 6의 (b)를 참조하면, 기 설정된 시선 과제는 시선 유도 객체(O4)가 위치하는 방향과 반대 방향을 응시하는 과제일 수 있다. 그리고, 화면에 디스플레이되는 메시지(M4)는 시선 유도 객체(O4)를 빠르게 응시하라는 내용을 포함할 수 있다. 이 경우, 사용자가 시선 유도 객체(O4)의 반대 방향의 임의의 지점을 응시하는 것이 사용자가 기 설정된 과제를 올바르게 수행하는 것일 수 있다. 한편, 사용자 단말기는 디스플레이부를 통해 메시지(M3 또는 M4)를 화면 상에 디스플레이하는 것과 연동하여 음향 출력부를 통해 메시지(M3 또는 M4)와 관련된 음향(예를 들어, 메시지(M3 또는 M4) 내에 포 함된 내용을 설명하는 음성)을 출력할 수도 있다. 이와 같이, 메시지(M3 또는 M4)와 함께 음향으로 사용자가 수 행해야하는 기 설정된 시선 과제를 사용자에게 인지시키는 경우 사용자가 현재 수행해야하는 기 설정된 시선 과 제가 무엇인지 명확하게 이해할 수 있다. 따라서, 단순 실수로 잘못된 시선 과제를 수행할 가능성이 낮아질 수 있다. 결과적으로, 기 설정된 시선 과제는 시선 유도 객체를 응시하는 과제 및 시선 유도 객체가 위치하는 방향과 반 대 방향을 응시하는 과제 중 적어도 하나를 포함할 수 있다. 그리고, 화면에 디스플레이되는 메시지(M3 또는 M4)에는 기 설정된 시선 과제가 무엇인지에 대한 내용이 포함될 수 있다. 도 2를 다시 참조하면, 장치의 프로세서는 제1 태스크와 2 태스크를 기 설정된 횟수(예를 들어, 5 회)만큼 수행할 수 있다. 즉, 프로세서는 사용자 단말기에 도 3에 도시된 화면이 디스플레이되도록 야기한 후에 사용자의 시선이 중앙을 응시한다고 인식된 경우, 도 5 또는 도 6에 도시된 화면이 사용자 단말기 에 디스플레이되도록 야기하는 태스크를 기 설정된 횟수만큼 수행할 수 있다. 본 개시와 같이 테스트를 진행하기 전(즉, 제2 태스크를 수행하기 전)에 제1 태스크를 수행하여 사용자의 시선 이 중앙에 오도록 만들 경우, 사용자가 기존에 사용하고 있는 사용자 단말기에 별도의 구성요소를 추가하지 않더라도 정확하게 치매를 식별할 수 있다. 한편, 치매 환자가 아닌 일반인이 중앙을 응시하고 있지 않다가 화면의 좌측 또는 우측에 표시되는 객체를 응시 해야 하는 경우 시선이 빠르게 움직이지 못해 치매가 아닌 사람이 치매라고 결정될 수 있다. 따라서, 사용자가 중앙을 응시하고 있다가 화면의 좌측 또는 우측에 표시되는 객체를 응시해야 치매 식별의 정확도가 향상될 수 있다. 따라서, 본 개시는 제2 태스크를 수행하기 전에 사용자가 중앙을 응시할 수 있도록 제1 객체가 중앙에 포 함된 화면이 디스플레이될 수 있다. 한편, 본 개시의 몇몇 실시예에 따르면, 장치의 프로세서는 제2 태스크가 기 설정된 횟수만큼 수행되 는 동안 사용자와 관련된 시선 정보를 획득할 수 있다. 여기서, 시선 정보는 치매를 식별하기 위한 디지털 바이 오 마커(디지털 장치로부터 획득되는 바이오 마커)로 사용될 수 있다. 일례로, 사용자 단말기의 프로세서는 제2 태스크가 기 설정된 횟수만큼 수행되는 동안 사용자의 눈이 포함된 영상을 획득할 수 있다. 이 경우, 장치의 프로세서는 제2 태스크가 기 설정된 횟수만큼 수행 되는 동안 사용자의 눈이 포함된 영상을 통신부를 통해 사용자 단말기로부터 수신할 수 있다. 프로세 서는 상기 영상을 수신한 경우, 상기 영상을 분석하여 시선 정보를 생성할 수 있다. 다른 일례로, 사용자 단말기의 프로세서는 제2 태스크가 기 설정된 횟수만큼 수행되는 동안 사용자의 눈이 포함된 영상을 획득할 수 있다. 프로세서는 획득된 영상을 분석하여 시선 정보를 획득할 수 있다. 그 리고, 프로세서는 획득된 시선 정보를 장치에 전송하도록 통신부를 제어할 수 있다. 이 경우, 장치의 프로세서는 통신부를 통해 시선 정보를 사용자 단말기로부터 수신할 수 있다. 시선 정보는, 사용자가 기 설정된 시선 과제를 올바르게 수행한 횟수에 대한 정보, 사용자가 기 설정된 시선 과 제를 올바르게 수행하지 못한 횟수에 대한 정보, 사용자의 시선이 기 설정된 시간 동안 특정 지점을 계속해서 응시하고 있는지에 대한 정보, 적어도 하나의 객체가 포함된 화면이 디스플레이된 시점부터 사용자의 시선이 적 어도 하나의 객체 중 어느 하나의 객체로 이동한 시점까지 소요된 시간에 대한 정보(사용자의 반응이 지연된 시 간에 대한 정보), 사용자의 시선의 이동 속도에 대한 정보 및 사용자의 시선이 기 설정된 시선 과제와 관련된 지점을 정확하게 응시하고 있는지에 대한 정보 중 적어도 하나를 포함할 수 있다. 본 개시의 시선 정보는 다양한 종류의 디지털 바이오 마커들 중 치매 식별과 상관 계수가 높은 디지털 바이오 마커일 수 있다. 따라서, 시선 정보를 이용하여 치매 여부를 결정하는 경우 치매 식별의 정확도가 향상될 수 있 다. 본 개시의 몇몇 실시예에 따르면, 프로세서는 제1 태스크 및 제2 태스크를 수행하기에 앞서 사용자가 기 설정된 시선 과제를 확인할 수 있도록 예비 태스크를 수행할 수 있다. 여기서, 예비 태스크는 상술한 제1 태스 크 및 제2 태스크와 동일한 방식으로 진행되기 때문에 이에 대한 자세한 설명은 생략한다. 예비 태스크에서 획득된 시선 정보는 치매 식별 모델을 통해 치매 여부를 식별할 때 사용되지 않을 수 있다. 다 만, 이에 한정되는 것은 아니고 치매 식별 모델의 치매 식별의 정확도를 높이기 위해 예비 태스크에서 획득된 시선 정보도 치매 식별 모델에 같이 입력될 수도 있다. 한편, 본 개시의 몇몇 실시예에 따르면, 프로세서는 시선 정보를 획득한 경우, 시선 정보를 이용하여 사용 자의 치매 여부를 결정할 수 있다. 이에 대한 자세한 설명은 도 7을 참조하여 후술한다. 도 7은 본 개시의 몇몇 실시예에 따라 장치가 시선 정보를 이용하여 사용자의 치매 여부를 결정하는 방법의 일 례를 설명하기 위한 흐름도이다. 도 7은 본 개시의 몇몇 실시예에 따라 시선 정보를 획득하는 방법의 일례를 설 명하기 위한 도면이다. 도 7과 관련하여 도 1 내지 도 6에서 상술한 바와 중복되는 내용은 다시 설명하지 않으 며, 이하 차이를 중심으로 설명한다. 도 7을 참조하면, 장치의 프로세서는 기 설정된 횟수만큼 제2 태스크가 수행되는 동안 사용자와 관련 된 시선 정보를 획득할 수 있다(S210). 구체적으로, 프로세서는 기 설정된 횟수만큼 제2 태스크를 수행되는 동안 사용자의 눈이 포함된 영상을 분 석하여 동공을 인식할 수 있다. 프로세서는 동공을 인식한 후 동공의 좌표 값을 산출할 수 있다. 동공의 좌표 값은 동공의 중심점의 좌표 값일 수도 있고, 동공 전체의 좌표 값들일 수도 있다. 본 개시에서 시선 정보 는 동공의 좌표 값을 이용하여 생성될 수 있다. 시선 정보는, 사용자가 기 설정된 시선 과제를 올바르게 수행한 횟수에 대한 정보, 사용자가 기 설정된 시선 과 제를 올바르게 수행하지 못한 횟수에 대한 정보, 사용자의 시선이 기 설정된 시간 동안 특정 지점을 계속해서 응시하고 있는지에 대한 정보, 적어도 하나의 객체가 포함된 화면이 디스플레이된 시점부터 사용자의 시선이 적 어도 하나의 객체 중 어느 하나의 객체로 이동한 시점까지 소요된 시간에 대한 정보, 사용자의 시선의 이동 속 도에 대한 정보 및 사용자의 시선이 기 설정된 시선 과제와 관련된 지점을 정확하게 응시하고 있는지에 대한 정 보 중 적어도 하나를 포함할 수 있다. 다만, 이에 한정되는 것은 아니고, 시선 정보는 상술한 정보 보다 적거나 많은 정보를 포함할 수 있다. 또한, 치매 식별 모델의 치매 식별의 정확도를 향상시키기 위해서 시선 정보는 상 술한 정보를 전부 포함할 수 있다. 본 개시의 몇몇 실시예에 따르면, 프로세서는 기 설정된 횟수만큼 제1 태스크 및 제2 태스크를 수행한 경 우, 기 설정된 횟수 중 사용자가 기 설정된 시선 과제를 올바르게 수행한 횟수와 기 설정된 시선 과제를 올바르 게 수행하지 못한 횟수를 산출할 수 있다. 사용자의 시선이 기 설정된 시간 동안 특정 지점을 계속해서 응시하고 있는지에 대한 정보는 특정 시점에 사용 자의 동공이 특정 위치에서 움직이는지 여부에 기초하여 산출될 수 있다. 일례로, 사용자의 시선이 기 설정된 시간 동안 특정 지점을 계속해서 응시하고 있는지에 대한 정보는, 제1 객체 가 디스플레이되고 있는 동안 사용자의 동공이 특정 위치에서 움직이는지 여부에 기초하여 산출될 수 있다. 여 기서, 특정 위치는 동공이 제1 객체를 응시할 때 위치하게 되는 위치일 수 있고, 동공의 좌표 값이 기 설정된 임계 범위를 벗어날 때 동공이 움직였다고 판단될 수 있다. 다른 일례로, 사용자의 시선이 기 설정된 시간 동안 특정 지점을 계속해서 응시하고 있는지에 대한 정보는 사용 자의 동공이 움직인 후 맨 마지막으로 멈춘 위치에서 기 설정된 시간 동안 동공이 움직이지 않고 멈춰 있는지 여부에 기초하여 산출될 수 있다. 여기서, 특정 위치는 동공이 도 5의 제2 객체(O2) 또는 제3 객체(O3) 또는 도 6의 시선 유도 객체(O4)를 응시할 때 위치하게 되는 위치일 수 있고, 동공의 좌표 값이 기 설정된 임계 범위를 벗어날 때 동공이 움직였다고 판단될 수 있다. 치매 환자의 경우 한 지점을 오랜 시간 동안 응시하고 있지 못하기 때문에 사용자의 시선이 기 설정된 시간 동 안 특정 지점을 계속해서 응시하고 있는지에 대한 정보를 획득하여 치매 식별을 위한 디지털 바이오 마커로 활 용하는 경우 치매 식별의 정확도가 향상될 수 있다. 한편, 도 8을 참조하여 시선 정보에 포함된 정보를 획득하는 방법을 좀더 구체적으로 설명하면 다음과 같다. 도 8에서 x축은 시간과 관련된 축이고, y축은 시선이 움직인 거리 또는 화면의 중앙에서 사용자가 응시하는 객 체까지의 거리와 관련된 축일 수 있다. 그리고, 제1 선(L1)은 시간에 따라 화면의 중앙에서 사용자가 응시해야 하는 객체까지의 거리를 나타내는 선이고, 제2 선(L2)은 시간에 따라 사용자의 시선이 움직인 거리를 나타내는 선이다. 본 개시에서 도 5에서 상술한 화면이 디스플레이되는 경우 시선 정보를 획득하는 방법을 이하 설명한다. 본 개시에서 제1 시점(t1)은 텍스트, 제2 객체 및 제3 객체가 포함된 화면이 디스플레이되는 시점일 수 있다. 그리고, 텍스트, 제2 객체 및 제3 객체가 포함된 화면이 디스플레이된 후 사용자의 시선이 제2 객체 또는 제3 객체로 이동하기 시작한 시점이 제2 시점(t2)일 수 있다. 여기서, 제2 시점(t2)은 동공의 좌표가 정지된 상태에 서 움직이기 시작한 시점일 수 있다. 다만, 이에 한정되는 것은 아니다. 본 개시에서 사용자의 반응이 지연된 시간은 제2 객체와 제3 객체가 포함된 화면이 디스플레이된 시점인 제1 시 점(t1)부터 사용자의 시선이 제2 객체 또는 제3 객체로 이동한 시점인 제2 시점(t2)까지 소요된 시간을 의미할 수 있다. 한편, 사용자의 시선이 기 설정된 시선 과제와 관련된 지점(즉, 제2 객체 또는 제3 객체)를 정확하게 응시하고 있는지에 대한 정보는 사용자의 시선이 움직인 거리(D2)와 텍스트(T)에서 기 설정된 시선 과제와 관련된 지점 (제2 객체(O2) 또는 제3 객체(O3), 사용자가 응시해야하는 객체)까지의 거리(D1)를 이용하여 산출될 수 있다. 여기서, 사용자의 시선이 움직인 거리(D2)는 동공의 최초 좌표 값(동공이 움직이기 전에 동공이 위치한 지점에 서의 좌표 값)과 동공의 최종 좌표 값(동공이 움직인 후 맨 마지막으로 멈춘 지점에서의 좌표 값)을 이용하여 산출될 수 있다. 구체적으로, 사용자의 시선이 기 설정된 시선 과제와 관련된 지점(제2 객체 또는 제3 객체)을 정확하게 응시하 고 있는지에 대한 정보(즉, 사용자가 응시해야 하는 객체를 제대로 응시하고 있는지에 대한 정보)는 제2 거리(D2)를 제1 거리(D1)로 나눠서 나오는 값을 이용하여 산출될 수 있다. 여기서, 상기 값이 1에 가까울수록 사용 자의 시선이 기 설정된 시선 과제와 관련된 지점(제2 객체 또는 제3 객체)을 정확하게 응시하고 있다고 볼 수 있다. 한편, 본 개시에서 도 6에서 상술한 화면이 디스플레이되는 경우 시선 정보를 획득하는 방법을 이하 설명한다. 본 개시에서 제1 시점(t1)은 시선 유도 객체가 포함된 화면이 디스플레이되는 시점일 수 있다. 그리고, 시선 유도 객체가 포함된 화면이 디스플레이된 후 사용자의 시선이 이동하기 시작한 시점이 제2 시점 (t2)일 수 있다. 여기서, 제2 시점(t2)은 동공의 좌표가 정지된 상태에서 움직이기 시작한 시점일 수 있다. 다 만, 이에 한정되는 것은 아니다. 본 개시에서 사용자의 반응이 지연된 시간은 시선 유도 객체가 포함된 화면이 디스플레이된 시점인 제1 시점 (t1)부터 사용자의 시선이 이동한 시점인 제2 시점(t2)까지 소요된 시간을 의미할 수 있다. 한편, 사용자의 시선이 기 설정된 시선 과제와 관련된 지점을 정확하게 응시하고 있는지에 대한 정보는 사용자 의 시선이 움직인 거리(D2) 와 제1 영역(R1)에서 기 설정된 시선 과제와 관련된 지점(사용자가 응시해야하는 지 점)까지의 거리(D1)를 이용하여 산출될 수 있다. 여기서, 사용자의 시선이 움직인 거리(D2)는 동공의 최초 좌표 값(동공이 움직이기 전에 동공이 위치한 지점에서의 좌표 값)과 동공의 최종 좌표 값(동공이 움직인 후 맨 마지 막으로 멈춘 지점에서의 좌표 값)을 이용하여 산출될 수 있다. 구체적으로, 사용자의 시선이 시선 유도 객체 또는 시선 유도 객체의 반대편의 임의의 지점을 정확하게 응시하 고 있는지에 대한 정보(즉, 사용자가 응시해야 하는 객체를 제대로 응시하고 있는지에 대한 정보)는 제2 거리 (D2)를 제1 거리(D1)로 나눠서 나오는 값을 이용하여 산출될 수 있다. 여기서, 상기 값이 1에 가까울수록 사용 자의 시선이 기 설정된 시선 과제와 관련된 지점을 정확하게 응시하고 있다고 볼 수 있다. 본 개시에서 사용자의 시선의 이동 속도는 도 8에 도시된 위치 궤적을 미분해서 속도 값을 환원함으로써 산출된 수 있다. 다만, 이에 한정되는 것은 아니고, 사용자의 눈동자가 중앙에서 목표 지점까지 이동한 거리에 대한 정 보와 사용자의 눈동자가 중앙에서 목표 지점까지 이동할 때 소요된 시간에 대한 정보에 기초하여 산출될 수도 있고, 프로세서는 다양한 방법으로 사용자의 시선의 이동 속도를 산출할 수 있다. 한편, 도 7을 다시 참조하면, 프로세서는 단계(S210)에서 시선 정보를 획득한 경우, 시선 정보를 치매 식 별 모델에 입력하여 스코어 값을 산출할 수 있다(S220). 여기서, 치매 식별 모델은 시선 정보를 입력하였을 때 스코어 값을 산출할 수 있도록 기 학습된 뉴럴 네트워크 구조를 갖는 인공지능 모델을 의미할 수 있다. 그리고, 스코어 값은 크기에 따라 치매 여부를 인식할 수 있는 값을 의미할 수 있다. 본 개시의 몇몇 실시예에 따르면, 장치의 저장부는 기 학습된 치매 식별 모델을 저장하고 있을 수 있 다. 치매 식별 모델은, 학습용 데이터에 라벨링 된 라벨 데이터와 치매 식별 모델에서 출력된 예측 데이터 사이의 차이 값(에러)을 역전파(back propagation)하여 치매 식별 모델의 가중치를 업데이트하는 방법으로 학습될 수 있다. 본 개시에서 학습 데이터는 복수의 테스트 사용자가 자신의 테스트 장치를 통해 상술한 제1 태스크 및 제2 태스 크를 수행하여 획득된 시선 정보일 수 있다. 본 개시에서 테스트 사용자는, 경도 인지 장애가 존재하는 환자로 분류되는 사용자, 알츠하이머 환자로 분류되 는 사용자, 정상으로 분류되는 사용자 등을 포함할 수 있다. 다만 이에 한정되는 것은 아니다. 본 개시에서 테스트 장치는 학습 데이터를 확보할 때 다양한 테스트 사용자들이 테스트를 수행하는 장치를 의미 할 수 있다. 여기서, 테스트 장치는, 치매 식별에 사용되는 사용자 단말기와 동일하게 휴대폰, 스마트 폰 (smart phone), 태블릿 PC(tablet PC), 울트라북(ultrabook) 등과 같은 이동 단말기(mobile device)일 수 있다. 다만, 이에 한정되는 것은 아니다. 본 개시에서 라벨 데이터는 정상, 알츠하이머 환자 및 경도 인지 장애가 존재하는 환자인지 여부를 인지할 수 있는 스코어 값일 수 있다. 다만, 이에 한정되는 것은 아니다. 치매 식별 모델은 일반적으로 노드로 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이 러한 노드들은 뉴런(neuron)들로 지칭될 수도 있다. 신경망은 적어도 하나의 노드들을 포함하여 구성될 수있다. 신경망들을 구성하는 노드(또는 뉴런)들은 하나 이상의 링크에 의해 상호 연결될 수 있다. 치매 식별 모델 내에서, 링크를 통해 연결된 하나 이상의 노드들은 상대적으로 입력 노드 및 출력 노드의 관계 를 형성할 수 있다. 입력 노드 및 출력 노드의 개념은 상대적인 것으로서, 하나의 노드에 대하여 출력 노드 관 계에 있는 임의의 노드는 다른 노드와의 관계에서 입력 노드 관계에 있을 수 있으며, 그 역도 성립할 수 있다. 상술한 바와 같이, 입력 노드 대 출력 노드 관계는 링크를 중심으로 생성될 수 있다. 하나의 입력 노드에 하나 의 출력 노드가 링크를 통해 연결될 수 있으며, 그 역도 성립할 수 있다. 하나의 링크를 통해 연결된 입력 노드 및 출력 노드 관계에서 출력 노드의 데이터는 입력 노드에 입력된 데이터 에 기초하여 그 값이 결정될 수 있다. 여기서, 입력 노드와 출력 노드를 상호 연결하는 링크는 가중치(weight) 를 가질 수 있다. 가중치는 가변적일 수 있으며, 신경망이 원하는 기능을 수행하기 위해, 사용자 또는 알고리즘 에 의해 가변될 수 있다. 예를 들어, 하나의 출력 노드에 하나 이상의 입력 노드가 각각의 링크에 의해 상호 연결된 경우, 출력 노드는 상기 출력 노드와 연결된 입력 노드들에 입력된 값들 및 각각의 입력 노드들에 대응하는 링크에 설정된 가중치 에 기초하여 출력 노드 값을 결정할 수 있다. 상술한 바와 같이, 치매 식별 모델은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호 연결되어 신경망 내 에서 입력 노드 및 출력 노드 관계를 형성할 수 있다. 치매 식별 모델 내에서 노드들과 링크들의 개수 및 노드 들과 링크들 사이의 연관 관계, 링크들 각각에 부여된 가중치의 값에 따라, 치매 식별 모델의 특성이 결정될 수 있다. 치매 식별 모델은 하나 이상의 노드들의 집합으로 구성될 수 있다. 치매 식별 모델을 구성하는 노드들의 부분 집합은 레이어(layer)를 구성할 수 있다. 치매 식별 모델을 구성하는 노드들 중 일부는, 최초 입력 노드로부터 의 거리들에 기초하여, 하나의 레이어(layer)를 구성할 수 있다. 예를 들어, 최초 입력 노드로부터 거리가 n인 노드들의 집합은, n 레이어를 구성할 수 있다. 최초 입력 노드로부터 거리는, 최초 입력 노드로부터 해당 노드 까지 도달하기 위해 거쳐야 하는 링크들의 최소 개수에 의해 정의될 수 있다. 그러나, 이러한 레이어의 정의는 설명을 위한 임의적인 것으로서, 치매 식별 모델 내에서 레이어의 차수는 상술한 것과 상이한 방법으로 정의될 수 있다. 예를 들어, 노드들의 레이어는 최종 출력 노드로부터 거리에 의해 정의될 수도 있다. 최초 입력 노드는 치매 식별 모델 내의 노드들 중 다른 노드들과의 관계에서 링크를 거치지 않고 데이터(즉, 시 선 정보)가 직접 입력되는 하나 이상의 노드들을 의미할 수 있다. 또는, 치매 식별 모델 내에서, 링크를 기준으 로 한 노드 간의 관계에 있어서, 링크로 연결된 다른 입력 노드들을 가지지 않는 노드들을 의미할 수 있다. 이 와 유사하게, 최종 출력 노드는 치매 식별 모델 내의 노드들 중 다른 노드들과의 관계에서, 출력 노드를 가지지 않는 하나 이상의 노드들을 의미할 수 있다. 또한, 히든 노드는 최초 입력 노드 및 최후 출력 노드가 아닌 치매 식별 모델을 구성하는 노드들을 의미할 수 있다. 본 개시의 몇몇 실시예에 따른 치매 식별 모델은 입력 레이어의 노드의 개수가 출력 레이어의 노드의 개수보다 많을 수 있으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 감소하는 형태의 신경망일 수 있다. 그리고, 입력 레이어의 노드 각각에 사용자가 기 설정된 시선 과제를 올바르게 수행한 횟수에 대한 정보, 사용자가 기 설정된 시선 과제를 올바르게 수행하지 못한 횟수에 대한 정보, 사용자의 시선이 기 설정된 시간 동안 특정 지점을 계속해서 응시하고 있는지에 대한 정보, 상기 적어도 하나의 객체가 포함된 화면이 디스플레 이된 시점부터 상기 사용자의 시선이 상기 적어도 하나의 객체 중 어느 하나의 객체로 이동한 시점까지 소요된 시간에 대한 정보, 상기 사용자의 시선의 이동 속도에 대한 정보 및 상기 사용자의 시선이 상기 기 설정된 시선 과제와 관련된 지점을 정확하게 응시하고 있는지에 대한 정보가 입력될 수 있다. 다만, 이에 한정되는 것은 아 니다. 본 개시의 몇몇 실시예에 따르면, 치매 식별 모델은 딥 뉴럴 네트워크 구조를 가질 수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이 어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 딥 뉴럴 네트워크는 컨볼루션 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크 (RNN: recurrent neural network), 오토 인코더(auto encoder), GAN(Generative Adversarial Networks), 제한 볼츠만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워 크, U 네트워크, 샴 네트워크, 적대적 생성 네트워크(GAN: Generative Adversarial Network) 등을 포함할 수있다. 전술한 딥 뉴럴 네트워크의 기재는 예시일 뿐이며 본 개시는 이에 제한되지 않는다. 본 개시의 치매 식별 모델은 교사 학습(supervised learning) 방식으로 학습될 수 있다. 다만, 이에 한정되는 것은 아니고, 치매 식별 모델은 비교사 학습(unsupervised learning), 반교사학습(semi supervised learning), 또는 강화학습(reinforcement learning) 중 적어도 하나의 방식으로 학습될 수도 있다. 치매 식별 모델의 학습은 치매 식별 모델이 치매를 식별하는 동작을 수행하기 위한 지식을 뉴럴 네트워크에 적 용하는 과정일 수 있다. 치매 식별 모델은 출력의 오류를 최소화하는 방향으로 학습될 수 있다. 치매 식별 모델의 학습에서 반복적으로 학습 데이터(학습용 테스트 결과 데이터)를 치매 식별 모델에 입력시키고 학습 데이터에 대한 치매 식별 모델의 출력(뉴럴 네트워크를 통해 예측된 스코어 값)과 타겟(라벨 데이터로 사용된 스코어 값)의 에러를 계산하고, 에 러를 줄이기 위한 방향으로 치매 식별 모델의 에러를 치매 식별 모델의 출력 레이어에서부터 입력 레이어 방향 으로 역전파(backpropagation)하여 치매 식별 모델의 각 노드의 가중치를 업데이트 하는 과정이다. 업데이트 되는 각 노드의 연결 가중치는 학습률(learning rate)에 따라 변화량이 결정될 수 있다. 입력 데이터 에 대한 치매 식별 모델의 계산과 에러의 역전파는 학습 사이클(epoch)을 구성할 수 있다. 학습률은 치매 식별 모델의 학습 사이클의 반복 횟수에 따라 상이하게 적용될 수 있다. 예를 들어, 치매 식별 모델의 학습 초기에는 높은 학습률을 사용하여 치매 식별 모델이 빠르게 일정 수준의 성능을 확보하도록 하여 효율성을 높이고, 학습 후기에는 낮은 학습률을 사용하여 정확도를 높일 수 있다. 치매 식별 모델의 학습에서 학습 데이터는 실제 데이터(즉, 학습된 치매 식별 모델을 이용하여 처리하고자 하는 데이터)의 부분집합일 수 있으며, 따라서, 학습 데이터에 대한 오류는 감소하나 실제 데이터에 대해서는 오류가 증가하는 학습 사이클이 존재할 수 있다. 과적합(overfitting)은 이와 같이 학습 데이터에 과하게 학습하여 실 제 데이터에 대한 오류가 증가하는 현상이다. 과적합은 머신러닝 알고리즘의 오류를 증가시키는 원인으로 작용할 수 있다. 이러한 과적합을 막기 위하여 다양 한 최적화 방법이 사용될 수 있다. 과적합을 막기 위해서는 학습 데이터를 증가시키거나, 레귤라이제이션 (regularization), 학습의 과정에서 네트워크의 노드 일부를 비활성화하는 드롭아웃(dropout), 배치 정규화 레 이어(batch normalization layer)의 활용 등의 방법이 적용될 수 있다. 한편, 프로세서는 단계(S220)를 통해 스코어 값을 획득한 경우, 스코어 값에 기초하여 치매 여부를 결정할 수 있다(S230). 구체적으로, 프로세서는 스코어 값이 기 설정된 임계 값을 초과하는지 여부에 기초하여 치매 여부를 결정 할 수 있다. 일례로, 프로세서는 치매 식별 모델에서 출력된 스코어 값이 기 설정된 임계 값을 초과한다고 인식한 경우 사용자가 치매라고 결정할 수 있다. 다른 일례로, 프로세서는 치매 식별 모델에서 출력된 스코어 값이 기 설정된 임계 값 이하라고 인식한 경 우 사용자가 치매가 아니라고 결정할 수 있다. 상술한 예시는 일 예시에 불과할 뿐 본 개시는 상술한 예들에 한정되는 것은 아니다. 본 개시의 몇몇 실시예에 따르면, 장치의 프로세서는 상술한 제1 태스크 및 제2 태스크를 진행하기 앞서 사용자 식별 정보를 획득할 수 있다. 여기서, 사용자 식별 정보는 사용자의 나이 정보, 성별 정보, 이름, 주소 정보 등을 포함할 수 있다. 그리고, 사용자 식별 정보의 적어도 일부는 시선 정보와 함께 치매 식별 모델 의 입력 데이터로 이용될 수 있다. 구체적으로, 나이 정보 및 성별 정보는 시선 정보와 함께 치매 식별 모델의 입력 데이터로 이용될 수 있다. 이와 같이 사용자 식별 정보의 적어도 일부를 시선 정보와 함께 이용하여 치매 식별 모델에 입력한 후에 스코어 값을 획득하여 치매 여부를 식별하는 경우 치매 식별의 정확도가 보다 향상될 수 있다. 이 경우, 치매 식별 모델은 사용자 식별 정보의 적어도 일부와 시선 정보에 기초하여 학습이 완료된 모델일 수 있다. 인지 정상군 120명과 인지 저하군 9명이 자신의 사용자 단말기를 통해 치매 여부를 식별하는 실험을 진행한 바 있다. 이 실험의 목표는 기 학습된 치매 식별 모델의 정확도를 확인하는 것이었다. 구체적으로, 장치는 제 1 태스크 및 제2 태스크를 진행하여 획득된 시선 정보를 본 개시의 치매 식별 모델에 입력하여 생성된 스코어 값에 기초하여 치매 여부를 판별하였다. 상술한 실험을 통해 산출된 분류의 정확도는 80% 이상인 것을 확인하였다. 상술한 본 발명의 몇몇 실시예들 중 적어도 하나에 의하면, 환자가 거부감을 거의 느끼지 않는 방법으로 정확하 게 치매를 진단할 수 있다. 본 개시에서 장치는 상기 설명된 몇몇 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 몇몇 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다. 본 개시에서 설명되는 다양한 실시예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴 퓨터 또는 이와 유사한 디바이스로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 여기에 설명되는 몇몇 실시예는 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays, 프로세서, 제어기, 마이크로 컨트 롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 개시에서 설명되는 몇몇 실시예가 적어도 하나의 프로세서로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 개시에서 설명되는 절차 및 기능과 같은 몇몇 실시예는 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 개시에서 설명되는 하나 이상의 기능, 태스크 및 작동 을 수행할 수 있다. 적절한 프로그램 언어로 쓰여진 소프트웨어 애플리케이션으로 소프트웨어 코드(software code)가 구현될 수 있다. 여기서, 소프트웨어 코드는, 저장부에 저장되고, 적어도 하나의 프로세서에 의해 실행될 수 있다. 즉, 적어도 하나의 프로그램 명령이 저장부에 저장되어 있고, 적어도 하나의 프로그 램 명령이 적어도 하나의 프로세서에 의해 실행될 수 있다. 본 개시의 몇몇 실시예에 따른 장치의 적어도 하나의 프로세서가 치매 식별 모델을 이용하여 치매를 식별하는 방법은 장치에 구비된 적어도 하나의 프로세서가 읽을 수 있는 기록매체에 적어도 하나의 프로세서가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 적어도 하나의 프로세서가 읽을 수 있는 기록매체 는 적어도 하나의 프로세서에 의해 읽힐 수 있는 데이터가 저장되는 모든 종류의 기록 디바이스를 포함한 다. 적어도 하나의 프로세서가 읽을 수 있는 기록 매체의 예로는 ROM(Read Only Memory), RAM(Random Access Memory), CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장 디바이스 등이 포함된다. 한편, 본 개시에서 첨부된 도면을 참조하여 설명하였으나, 이는 실시예일 뿐 특정 실시예에 한정되지 아니하며,"}
{"patent_id": "10-2022-0085420", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "당해 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 변형실시가 가능한 다양한 내용도 청구범위에 따른 권리범위에 속한다. 또한, 그러한 변형실시들이 본 발명의 기술 사상으로부터 개별적으로 이해되어서는 안 된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2022-0085420", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 다양한 실시예들이 도면들을 참조로 설명되며, 여기서 유사한 참조 번호들은 총괄적으로 유사한 구성 요소들을 지칭하는데 이용된다. 이하의 실시예에서, 설명 목적을 위해, 다수의 특정 세부사항들이 하나 이상의 실시예들의 총체적 이해를 제공하기 위해 제시된다. 그러나, 그러한 실시예(들)가 이러한 구체적인 세부사항들 없이 실시될 수 있음은 명백할 것이다. 도 1은 본 개시의 몇몇 실시예에 따른 치매를 식별하는 시스템을 설명하기 위한 개략도이다. 도 2는 본 개시의 몇몇 실시예에 따른 장치가 치매 식별을 위한 영상을 획득하는 방법의 일례를 설명하기 위한 흐름도이다. 도 3은 본 개시의 몇몇 실시예에 따른 사용자 단말기에서 치매 식별을 위한 영상을 획득할 때 디스플레이되는 화면의 일례를 설명하기 위한 도면이다. 도 4는 본 개시의 몇몇 실시예에 따라 사용자 단말기의 사용자가 기 설정된 조건을 만족했는지 여부를 인식하는 방법의 일례를 설명하기 위한 도면이다. 도 5 및 도 6은 본 개시의 몇몇 실시예에 따른 사용자 단말기에서 시선 정보를 획득할 때 디스플레이되는 화면 들의 일례를 설명하기 위한 도면이다. 도 7은 본 개시의 몇몇 실시예에 따라 장치가 시선 정보를 이용하여 사용자의 치매 여부를 결정하는 방법의 일 례를 설명하기 위한 흐름도이다. 도 8은 본 개시의 몇몇 실시예에 따라 시선 정보를 획득하는 방법의 일례를 설명하기 위한 도면이다."}
