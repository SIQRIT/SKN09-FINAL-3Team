{"patent_id": "10-2023-0133737", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0050564", "출원번호": "10-2023-0133737", "발명의 명칭": "사용자의 움직임에 기반한 예술작품 창작 및 융합 시스템", "출원인": "장레베카", "발명자": "장레베카"}}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "웨어러블 장치, 서버 및 이미지 제공 장치를 포함하는 시스템의 제어 방법에 있어서,상기 웨어러블 장치가 사용자의 움직임에 대응되는 상기 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를획득하는 단계;상기 웨어러블 장치가 상기 획득된 제1 센싱 정보를 상기 서버로 전송하는 단계;상기 웨어러블 장치로부터 상기 제1 센싱 정보가 수신되면, 상기 서버가 상기 제1 센싱 정보에 대응되는 상기사용자의 모션 정보를 식별하는 단계;상기 서버가 상기 식별된 모션 정보를 상기 이미지 제공 장치로 전송하는 단계; 및상기 이미지 제공 장치가 상기 모션 정보에 매칭되는 궤적을 순차적으로 나타내는 이미지를 디스플레이하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 센싱 정보를 획득하는 단계는,상기 이미지 제공 장치가 제1 이미지를 디스플레이하는 동안 상기 웨어러블 장치가 상기 사용자의 움직임에 대응되는 상기 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득하고,상기 이미지를 디스플레이하는 단계는,상기 서버로부터 수신된 모션 정보에 기초하여 상기 이미지 제공 장치가 상기 제1 이미지가 디스플레이되는 영역에 상기 모션 정보에 매칭되는 궤적을 순차적으로 나타내는 제2 이미지를 디스플레이하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제어 방법은,상기 서버가 상기 제1 이미지를 식별하는 단계;상기 서버가 상기 식별된 제1 이미지를 이미지 분석 모델에 입력하여 상기 제1 이미지에 포함된 오브젝트 및 상기 제1 이미지가 포함하는 색깔을 식별하는 단계; 및상기 서버가 상기 식별된 오브젝트 및 색깔에 대응되는 상기 제1 이미지의 분위기 코드를 식별하는 단계;를 포함하고,상기 전송하는 단계는,상기 서버가 상기 식별된 모션 정보 및 상기 식별된 분위기 코드를 상기 이미지 제공 장치로 전송하고,상기 이미지를 디스플레이하는 단계는,상기 서버로부터 수신된 상기 모션 정보 및 상기 분위기 코드에 기초하여 상기 이미지 제공 장치가 상기 제1 이미지가 디스플레이되는 영역에 상기 모션 정보에 매칭되는 궤적을 나타내며, 상기 식별된 분위기 코드에 대응되는 모양 및 색깔로 이루어진 제2 이미지를 디스플레이하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,공개특허 10-2025-0050564-3-상기 시스템은,스피커를 더 포함하고,상기 모션 정보를 식별하는 단계는,상기 웨어러블 장치로부터 상기 제1 센싱 정보가 수신되면, 상기 서버가 상기 제1 센싱 정보에 대응되는 상기웨어러블 장치의 지면으로부터 높이를 식별하는 단계; 및상기 서버가 상기 식별된 높이에 대응되는 피치(Pitch)를 갖는 음을 식별하는 단계;를 포함하고,상기 제어 방법은,상기 서버가 상기 식별된 피치를 갖는 음에 대한 정보를 상기 스피커로 전송하는 단계; 및상기 서버로부터 수신된 상기 음에 대한 정보에 기초하여 상기 스피커가 상기 웨어러블 장치의 지면으로부터의높이에 대응되는 피치를 갖는 음을 출력하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 모션 정보를 식별하는 단계는,상기 서버가 상기 식별된 높이에 대응되는 기 설정된 색깔을 식별하는 단계;를 포함하고,상기 전송하는 단계는,상기 서버가 상기 식별된 기 설정된 색깔 정보를 상기 이미지 제공 장치로 전송하는 단계;를 포함하고,상기 이미지를 디스플레이하는 단계는,상기 서버로부터 수신된 기 설정된 색깔 정보에 기초하여 상기 이미지 제공 장치가 상기 웨어러블 장치의 지면으로부터의 높이에 대응되는 기 설정된 색깔로 상기 모션 정보에 매칭되는 궤적을 나타내는 이미지를 디스플레이하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제어 방법은,상기 스피커가 상기 음을 출력하지 않은 상태에서 상기 이미지 제공 장치가 상기 모션 정보에 매칭되는 궤적을나타내는 이미지를 디스플레이하고,상기 이미지 제공 장치가 상기 이미지를 모두 디스플레이한 상태에서 상기 스피커가 상기 음을 출력하는, 제어방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 웨어러블 장치의 상기 사용자의 신체의 일 영역에 대한 터치를 센싱한 제2 센싱 정보를 획득하는 단계;상기 웨어러블 장치가 상기 획득된 제2 센싱 정보를 상기 서버로 전송하는 단계;상기 웨어러블 장치로부터 상기 제2 센싱 정보가 수신되면, 상기 서버가 상기 제2 센싱 정보에 대응되는 터치정보를 식별하는 단계;상기 서버가 상기 식별된 터치 정보를 상기 이미지 제공 장치로 전송하는 단계; 및상기 이미지 제공 장치가 상기 터치 정보에 매칭되는 디스플레이 방식으로 이미지를 디스플레이하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2025-0050564-4-전자 장치의 제어 방법에 있어서,통신 인터페이스를 통해 웨어러블 장치로부터 사용자의 움직임에 대응되는 상기 웨어러블 장치의 움직임을 센싱한 제1 센싱 정보를 수신하는 단계; 상기 수신된 제1 센싱 정보에 대응되는 상기 사용자의 모션 정보를 식별하는 단계; 및상기 식별된 모션 정보를 통신 인터페이스를 통해 이미지 제공 장치로 전송하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 이미지를 디스플레이하는 단계는,상기 이미지 제공 장치에 의해 디스플레이된 상기 이미지 중 디스플레이된 시간이 기 설정된 시간 이상인 상기이미지 일부에 대한 디스플레이를 순차적으로 중지하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0133737", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "전자 장치의 프로세서의 의해 실행되어 상기 전자 장치가 제8항의 제어 방법을 수행하도록 하는 적어도 하나의인스트럭션이 저장된 비일시적 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "웨어러블 장치, 서버 및 이미지 제공 장치를 포함하는 시스템 및 이의 제어 방법이 개시된다. 본 개시에 따른 시 스템의 제어 방법은, 웨어러블 장치가 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득하는 단계; 웨어러블 장치가 획득된 제1 센싱 정보를 서버로 전송하는 단계; 웨어러블 장치로부터 제 1 센싱 정보가 수신되면, 서버가 제1 센싱 정보에 대응되는 사용자의 모션 정보를 식별하는 단계; 서버가 식별된 모션 정보를 이미지 제공 장치로 전송하는 단계; 및 이미지 제공 장치가 모션 정보에 매칭되는 궤적을 순차적으 로 나타내는 이미지를 디스플레이하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 사용자의 움직임에 기반한 예술작품 창작 및 융합 시스템에 관한 것으로, 더욱 상세하게는, 사용자의 움직임을 센싱하여 획득한 센싱 정보에 기초하여 미술작품, 음악작품을 새로이 창작하거나 기존 예술 작품과 융 합하는 시스템 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "가속도 센서, 자이로 센서 등을 통해 3차원 공간 상에서 사용자의 움직임, 회전, 동작을 센싱할 수 있고, 센싱 된 정보를 바탕으로 사용자 명령을 식별하거나 사용자에게 필요한 모션 정보를 제공할 수 있다. 가속도 센서, 자이로 센서와 같은 센서부를 이용한 사용자의 움직임 센싱은 기기의 소형화가 이루어지면서 사용 자가 직접 착용하는 기기 또는 사용자의 몸에 이식되는 기기를 통해 간편하게 이루어질 수 있다. 또한, 기기 정밀화를 통해 센싱 감도가 향상되면서, 미세한 진동, 떨림, 이동을 센싱할 수 있다."}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "종래 미술관, 전시회, 음악회에서는 미술작품, 음악작품과 같은 예술작품을 단순히 관객이 감상하는데 그치는 단방향 소통만이 이루어졌다. 따라서, 예술작품으로부터 받은 관객의 감상, 영감을 표출하여 이를 예술작품에 반영하거나 새로운 예술작품을 창작할 수 없었다. 따라서, 관객이 예술작품을 단순히 감상하는데 그치지 않고 직접 참여하면서 예술작품을 자신의 움직임과 융합 한 창작물을 도출해내거나 자신의 움직임만으로 예술작품을 새롭게 창조하는 등 예술작품과 관객 사이의 양방향 소통을 실현할 방법의 모색이 요청된다. 본 개시의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 개시의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 개시의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 실시 예에 따른 웨어러블 장치, 서버 및 이미지 제공 장치를 포함하는 시스템의 제어 방법은, 상기 웨어러블 장치가 사용자의 움직임에 대응되는 상기 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득하는 단계; 상기 웨어러블 장치가 상기 획득된 제1 센싱 정보를 상기 서버로 전송하는 단계; 상기 웨어러블 장치로부터 상 기 제1 센싱 정보가 수신되면, 상기 서버가 상기 제1 센싱 정보에 대응되는 상기 사용자의 모션 정보를 식별하 는 단계; 상기 서버가 상기 식별된 모션 정보를 상기 이미지 제공 장치로 전송하는 단계; 및 상기 이미지 제공 장치가 상기 모션 정보에 매칭되는 궤적을 순차적으로 나타내는 이미지를 디스플레이하는 단계;를 포함할 수 있 다. 한편, 상기 제1 센싱 정보를 획득하는 단계는, 상기 이미지 제공 장치가 제1 이미지를 디스플레이하는 동안 상 기 웨어러블 장치가 상기 사용자의 움직임에 대응되는 상기 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보 를 획득하고, 상기 이미지를 디스플레이하는 단계는, 상기 서버로부터 수신된 모션 정보에 기초하여 상기 이미 지 제공 장치가 상기 제1 이미지가 디스플레이되는 영역에 상기 모션 정보에 매칭되는 궤적을 순차적으로 나타 내는 제2 이미지를 디스플레이할 수 있다. 한편, 상기 제어 방법은, 상기 서버가 상기 제1 이미지를 식별하는 단계; 상기 서버가 상기 식별된 제1 이미지 를 이미지 분석 모델에 입력하여 상기 제1 이미지에 포함된 오브젝트 및 상기 제1 이미지가 포함하는 색깔을 식 별하는 단계; 및 상기 서버가 상기 식별된 오브젝트 및 색깔에 대응되는 상기 제1 이미지의 분위기 코드를 식별 하는 단계;를 포함하고, 상기 전송하는 단계는, 상기 서버가 상기 식별된 모션 정보 및 상기 식별된 분위기 코 드를 상기 이미지 제공 장치로 전송하고, 상기 이미지를 디스플레이하는 단계는, 상기 서버로부터 수신된 상기 모션 정보 및 상기 분위기 코드에 기초하여 상기 이미지 제공 장치가 상기 제1 이미지가 디스플레이되는 영역에 상기 모션 정보에 매칭되는 궤적을 나타내며, 상기 식별된 분위기 코드에 대응되는 모양 및 색깔로 이루어진 제 2 이미지를 디스플레이할 수 있다. 한편, 상기 시스템은, 스피커를 더 포함하고, 상기 모션 정보를 식별하는 단계는, 상기 웨어러블 장치로부터 상 기 제1 센싱 정보가 수신되면, 상기 서버가 상기 제1 센싱 정보에 대응되는 상기 웨어러블 장치의 지면으로부터 높이를 식별하는 단계; 및 상기 서버가 상기 식별된 높이에 대응되는 피치(Pitch)를 갖는 음을 식별하는 단계; 를 포함하고, 상기 제어 방법은, 상기 서버가 상기 식별된 피치를 갖는 음에 대한 정보를 상기 스피커로 전송하 는 단계; 및 상기 서버로부터 수신된 상기 음에 대한 정보에 기초하여 상기 스피커가 상기 웨어러블 장치의 지 면으로부터의 높이에 대응되는 피치를 갖는 음을 출력하는 단계;를 포함할 수 있다. 한편, 상기 모션 정보를 식별하는 단계는, 상기 서버가 상기 식별된 높이에 대응되는 기 설정된 색깔을 식별하 는 단계;를 포함하고, 상기 전송하는 단계는, 상기 서버가 상기 식별된 기 설정된 색깔 정보를 상기 이미지 제 공 장치로 전송하는 단계;를 포함하고, 상기 이미지를 디스플레이하는 단계는, 상기 서버로부터 수신된 기 설정 된 색깔 정보에 기초하여 상기 이미지 제공 장치가 상기 웨어러블 장치의 지면으로부터의 높이에 대응되는 기 설정된 색깔로 상기 모션 정보에 매칭되는 궤적을 나타내는 이미지를 디스플레이 할 수 있다. 한편, 상기 제어 방법은, 상기 스피커가 상기 음을 출력하지 않은 상태에서 상기 이미지 제공 장치가 상기 모션 정보에 매칭되는 궤적을 나타내는 이미지를 디스플레이하고, 상기 이미지 제공 장치가 상기 이미지를 모두 디스 플레이한 상태에서 상기 스피커가 상기 음을 출력할 수 있다. 한편, 상기 웨어러블 장치의 상기 사용자의 신체의 일 영역에 대한 터치를 싱한 제2 센싱 정보를 획득하는 단계; 상기 웨어러블 장치가 상기 획득된 제2 센싱 정보를 상기 서버로 전송하는 단계; 상기 웨어러블 장치로부 터 상기 제2 센싱 정보가 수신되면, 상기 서버가 상기 제2 센싱 정보에 대응되는 터치 정보를 식별하는 단계; 상기 서버가 상기 식별된 터치 정보를 상기 이미지 제공 장치로 전송하는 단계; 및 상기 이미지 제공 장치가 상 기 터치 정보에 매칭되는 디스플레이 방식으로 이미지를 디스플레이할 수 있다. 한편, 상기 이미지를 디스플레이하는 단계는, 상기 이미지 제공 장치에 의해 디스플레이된 상기 이미지 중 디스 플레이된 시간이 기 설정된 시간 이상인 상기 이미지 일부에 대한 디스플레이를 순차적으로 중지하는 단계;를 포함할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 통신 인터페이스를 통해 웨어러블 장치로부터 사용자의 움직임에 대응되는 상기 웨어러블 장치의 움직임을 센싱한 제1 센싱 정보를 수신하는 단계; 상기 수신된 제1 센 싱 정보에 대응되는 상기 사용자의 모션 정보를 식별하는 단계; 및 상기 식별된 모션 정보를 통신 인터페이스를 통해 이미지 제공 장치로 전송하는 단계;를 포함할 수 있다. 한편, 전자 장치의 프로세서의 의해 실행되어 상기 전자 장치의 제어 방법을 수행하도록 하는 적어도 하나의 인 스트럭션이 저장된 비일시적 컴퓨터 판독가능 기록매체는, 통신 인터페이스를 통해 웨어러블 장치로부터 사용자 의 움직임에 대응되는 상기 웨어러블 장치의 움직임을 센싱한 제1 센싱 정보를 수신하는 단계; 상기 수신된 제1 센싱 정보에 대응되는 상기 사용자의 모션 정보를 식별하는 단계; 및 상기 식별된 모션 정보를 통신 인터페이스 를 통해 이미지 제공 장치로 전송하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "관객이 예술작품을 단순히 감상하는데 그치지 않고 직접 참여하면서 예술작품을 자신의 움직임과 융합한 창작물 을 도출해내거나 자신의 움직임만으로 예술작품을 새롭게 창조하는 등 예술작품과 관객 사이의 양방향 소통을 실현할 수 있다. 또한, 예술작품과 관객의 양방향 소통을 통해 유아기, 청소년기 때 다채로운 미적 체험을 가능케 함으로써 예술 교육의 수준과 성과를 높일 수 있다."}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도면에 예 시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하려는 것 이 아니며, 본 개시의 실시 예의 다양한 변경(modifications), 균등물(equivalents), 및/또는 대체물 (alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유 사한 참조 부호가 사용될 수 있다. 본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위하여 제공되는 것이다. 본 개시에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 권리범위를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다.본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직 접 접속되어\" 있다고 언급된 때에는, 어떤 구성요소와 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소) 가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트 웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 실시 예에 있어서 '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 혹은 복수의 '부'는 특정 한 하드웨어로 구현될 필요가 있는 '모듈' 혹은 '부'를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하 나의 프로세서로 구현될 수 있다. 한편, 도면에서의 다양한 요소와 영역은 개략적으로 그려진 것이다. 따라서, 본 발명의 기술적 사상은 첨부한 도면에 그려진 상대적인 크기나 간격에 의해 제한되지 않는다. 이하에서는 첨부한 도면을 참고하여 본 개시에 따른 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른, 사용자의 움직임을 기반으로 한 예술작품의 융합 및 창작을 설명하기 위 한 도면이다. 도 1을 참조하면, 사용자는 신체의 일 영역, 예를 들어, 손, 손가락, 손목 등에 웨어러블 장치를 끼우거나 착용할 수 있다. 웨어러블 장치는 사용자의 움직임을 센서부를 통해 센싱하여 센싱 정보를 서버로 전송 하고, 서버는 웨어러블 장치로부터 수신된 센싱 정보에 기초한 모션 정보를 식별하여 이미지 제 공 장치, 예를 들어, 빔 프로젝터로 전송할 수 있다. 이미지 제공 장치는 서버로부터 수신된 사용자의 움직임에 대응되는 모션 정보에 따라 이미지 를 디스플레이할 수 있다. 도 2는 본 개시의 일 실시 예에 따른, 웨어러블 장치, 서버 및 이미지 제공 장치를 포함하는 시 스템을 설명하기 위한 도면이다. 도 2를 참조하면, 웨어러블 장치는 사용자의 손가락, 손목에 끼워지거나 사용자의 손에 쥐어진 상태로 사 용자의 움직임에 의해 3차원 공간 상에서 움직이는 휴대용 기기일 수 있다. 웨어러블 장치는 30mm x 30mm 의 초소형 크기로 설계될 수 있고, 입력 전압은 3.3 ~ 6V일 수 있으며, 5V일 때 0.5mA의 전류로 구동되는 저전 력 설계로 구현될 수 있으나, 웨어러블 장치의 크기, 전압, 전류 설계는 상술한 바에 국한되는 것은 아니 다. 다만, 이에 국한되는 것은 아니며, 웨어러블 장치는 사용자의 신체 중 일 영역, 예를 들어, 머리, 팔, 다 리, 무릎, 발 등에 장착되는 기기일 수 있다. 또한, 웨어러블 장치는 사용자가 손으로 잡은 상태에서 사용자의 움직임을 센싱할 수 있는 다양한 휴대용 기기, 예를 들어, 스마트폰(smartphone), 태블릿 PC(tablet Personal Computer), 모바일 기기일 수도 있다. 웨어러블 장치는 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱하여 센싱 정보를 획득 할 수 있다. 웨어러블 장치는 획득된 센싱 정보를 서버로 전송할 수 있다. 여기서, 웨어러블 장치 의 움직임은 3차원 공간 상에서의 이동, 회전, 진동 등일 수 있으나, 상술한 바에 국한되지 않는다. 서버는 들어 클라이언트에게 네트워크를 통해 서비스하는 컴퓨터인 서버일 수 있다. 서버는, FTP 서버, 웹 서버, 데이터 베이스 서버, 클라우드형 서버일 수 있으며, 서버는 리눅 스 등의 운영체제로 구축될 수 있다. 서버는 웨어러블 장치로부터 수신된 센싱 정보에 대응되는 사용자의 모션 정보를 식별할 수 있다. 여 기서, 사용자의 모션 정보는, 사용자의 신체 일 영역의 이동, 회전, 진동 등일 수 있으나, 이에 국한되는 것은 아니다. 서버는 식별된 모션 정보를 이미지 제공 장치로 전송할 수 있다. 이 때 서버는 이미지 제공 장 치로 모션 정보와 함께 디스플레이 제어 신호를 함께 전송할 수 있다. 이미지 제공 장치는, 예를 들어, 공간의 일 영역에 가시광선 영역의 전파를 조사하여 이미지, 영상을 디스 플레이하는 빔 프로젝터, 프로젝션 디스플레이 장치일 수 있으나, 이에 국한되지 않고, 태블릿 PC, TV, 전광판, 스크린 장치 등 이미지, 영상을 출력하여 사용자에게 제공할 수 있는 다양한 디스플레이 장치일 수 있다. 이미지 제공 장치는 서버로부터 수신됨 모션 정보에 기초하여 모션 정보에 매칭되는 궤적을 순차적으 로 나타내는 이미지를 디스플레이 할 수 있다. 즉, 이미지 제공 장치는 사용자가 움직이는 순서에 따른 궤 적을 순차적으로 디스플레이할 수 있다. 도 3a는 본 개시의 일 실시 예에 따른, 웨어러블 장치의 구성을 설명하기 위한 블록도이다. 도 3a를 참조하면, 웨어러블 장치는, 센서부, 사용자 인터페이스, 통신 인터페이스, 메모 리 및 프로세서를 포함할 수 있다. 다만, 웨어러블 장치의 구성은 이에 국한되지 않으며 이외의 장치 구성을 추가로 구비하거나 일 구성을 생 략할 수도 있다. 센서부는 웨어러블 장치를 착용하거나 휴대한 사용자의 상태를 센싱하고, 센싱된 상태에 대응하는 전 기 신호 또는 데이터 값을 생성할 수 있다. 일 실시예에 따르면, 센서부는, 예를 들면, 가속도 센서, 자이 로 센서, 지자기 센서, 그립 센서, 근접 센서, 웨어러블 장치의 위치 정보를 획득할 수 있는 GPS, 정전기 센서, 미세 전류 센서, 시간 측정 장치 등을 포함할 수 있다. 웨어러블 장치의 프로세서는 가속도 센서, 자이로 센서, 지자기 센서의 Calibrated raw data를 연산, 식별할 수 있고, 단시간 센서 위치추적(Short-Term Position Tracking) 연산을 수행할 수 있다. 자이로 센서의 센싱 감도는 250dps ~ 2000dps로, 가속도 센서의 센싱 감도는 2g ~ 16g로, Sensor Filter Factor는 1 ~ 50로 설정될 수 있다. 이외에도 다양한 Position Filter Parameters가 설정될 수 있다. 프로세서는 센서부를 통해 획득된 데이터에 기초하여 x,y,z축 Local 및 Global 위치, 속도 데이터를 식별할 수 있으며, Position Tracking Filter, 자세 offset설정 기능을 통해 사용자의 움직임, 자세에 대응되는 데이터를 식별할 수 있다. 프로세서는 센서부에 대한 자체 캘리브레이션 동작을 수행할 수 있으며, RAA(Robust Attitude Algorithm), RHA(Robust Heading Algorithm), AGC(Auto Gyroscope Calibration), AVC(Active Vibration Cancellation)에 대한 기능, 동작, 알고리즘을 포함할 수 있다. 센서부는 데이터 갱신 및 자세 데이터 출력속도에 대하여 1000Hz까지 지원 가능하며, 데이터 출력 모드는 ASCII출력모드, HEX(binary)출력모드가 가능하다. 또한, 센서부는 웨어러블 장치를 사용하는 사용자의 생체 정보를 획득하기 위한 생체 센서(예: 심박 수 센서, 체온 센서, PPG(Photoplethysmography)센서 등)를 포함할 수 있다. 프로세서는 센서부를 통해 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득할 수 있다. 여기서, 센싱 정보는 웨어러블 장치의 이동, 회전, 진동 등에 대한 정보를 포함할 수 있으나, 이에 국한되는 것은 아니다. 프로세서는 센서부를 통해 웨어러블 장치가 사용자의 신체의 일 영역과 맞닿는 터치를 센싱하여 제2 센싱 정보를 획득할 수 있다. 프로세서는 센서부를 통해 사용자의 심박수, 사용자의 체온을 센싱하여 제3 센싱 정보를 획득할 수 있다. 사용자 인터페이스는 버튼(button), 레버(lever), 스위치(switch), 터치(Touch)형 인터페이스 등을 포함 할 수 있고, 터치형 인터페이스는 터치 패널과 함께 구현된 디스플레이 화면 상에서 사용자의 터치로 입력을 받 는 방식으로 구현될 수 있다. 프로세서는 사용자 인터페이스를 통해 다양한 사용자 명령을 수신할 수 있다. 예를 들어, 프로세서 는 사용자 인터페이스를 통해 사용자의 움직임에 대응되는 웨어러블 장치의 움직임, 웨어러블 장치의 일 영역이 사용자의 신체의 일 영역과 맞닿는 터치, 사용자의 심박수, 사용자의 체온 등을 센싱하 는 센싱 동작을 수행하기 위한 사용자 명령을 수신할 수 있다. 통신 인터페이스는 무선 통신 인터페이스, 유선 통신 인터페이스 또는 입력 인터페이스를 포함할 수 있다. 무선 통신 인터페이스는, 무선 통신 기술이나 이동 통신 기술을 이용하여 각종 외부 장치와 통신을 수행할 수 있다. 이러한 무선 통신 기술로는, 예를 들어, 블루투스(Bluetooth), 저전력 블루투스(Bluetooth Low Energy), 캔(CAN) 통신, 와이 파이(Wi-Fi), 와이파이 다이렉트(Wi-Fi Direct), 초광대역 통신(UWB, ultrawide band), 지 그비(zigbee), 적외선 통신(IrDA, infrared Data Association) 또는 엔에프씨(NFC, Near Field Communication) 등이 포함될 수 있으며, 이동 통신 기술 로는, 3GPP, 와이맥스(Wi-Max), LTE(Long Term Evolution), 5G 등이 포함될 수 있다. 무선 통신 인터페이스는 전자기파를 외부로 송신하거나 또는 외부에서 전달된 전자기파를 수신할 수 있는 안테 나, 통신 칩 및 기판 등을 이용하여 구현될 수 있다. 유선 통신 인터페이스는 유선 통신 네트워크를 기반으로 각종 장치와 통신을 수행할 수 있다. 여기서, 유선 통 신 네트워크는, 예를 들어, 페어 케이블, 동축 케이블, 광섬유 케이블 또는 이더넷(Ethernet) 케이블 등 물리적 인 케이블을 이용하여 구현될 수 있다. 무선 통신 인터페이스 및 유선 통신 인터페이스는 실시 예에 따라 어느 하나가 생략될 수도 있다. 따라서, 웨어 러블 장치는 무선 통신 인터페이스만을 포함하거나 유선 통신 인터페이스만을 포함할 수 있다. 뿐만 아니 라, 웨어러블 장치는 무선 통신 인터페이스에 의한 무선 접속과 유선 통신 인터페이스에 의한 유선 접속을 모두 지원하는 통합된 통신 인터페이스를 구비할 수도 있다. 웨어러블 장치는 한 가지 방식의 통신 연결을 수행하는 한 개의 통신 인터페이스를 포함하는 경우에 국한되지 않고, 복수의 방식으로 통신 연결을 수행하는 복수의 통신 인터페이스를 포함할 수 있다. 프로세서는 통신 인터페이스를 통해 입력전압(VCC)에 대응되는 TX, RX UART통신 연결을 수행할 수 있 고, 넓은 범위의 통신 속도, 예를 들어, 9600bps ~ 921600bps로 통신 연결을 수행할 수 있다. 프로세서는 통신 인터페이스를 통해 서버와 통신 연결을 수행하여 획득된 센싱 정보를 서버 로 전송할 수 있다. 여기서, 센싱 정보는, 사용자의 움직임에 대응되는 웨어러블 장치의 움직임, 웨 어러블 장치의 일 영역이 사용자의 신체의 일 영역과 맞닿는 터치, 사용자의 심박수, 사용자의 체온 등에 대한 정보일 수 있으나, 이에 국한되는 것은 아니다.통신 인터페이스의 기능, 동작은 상술한 바에 국한되지 않으며, 프로세서는 통신 인터페이스를 통해 서버로 전송하는 다양한 정보, 신호를 이미지 제공 장치로 직접 전송할 수도 있다. 즉, 이 경우, 서버의 개입 없이 웨어러블 장치와 이미지 제공 장치가 직접 통신 연결을 수행하여 정보 를 송수신할 수 있다. 메모리는 각종 프로그램이나 데이터를 일시적 또는 비일시적으로 저장하고, 프로세서의 호출에 따라 서 저장된 정보를 프로세서에 전달한다. 또한, 메모리는, 프로세서의 연산, 처리 또는 제어 동 작 등에 필요한 각종 정보를 전자적 포맷으로 저장할 수 있다. 메모리는, 예를 들어, 주기억장치 및 보조기억장치 중 적어도 하나를 포함할 수 있다. 주기억장치는 롬 (ROM) 및/또는 램(RAM)과 같은 반도체 저장 매체를 이용하여 구현된 것일 수 있다. 롬은, 예를 들어, 통상적인 롬, 이피롬(EPROM), 이이피롬(EEPROM) 및/또는 마스크롬(MASK-ROM) 등을 포함할 수 있다. 램은 예를 들어, 디램 (DRAM) 및/또는 에스램(SRAM) 등을 포함할 수 있다. 보조기억장치는, 플래시 메모리 장치, SD(Secure Digital) 카드, 솔리드 스테이트 드라이브(SSD, Solid State Drive), 하드 디스크 드라이브(HDD, Hard Disc Drive), 자 기 드럼, 컴팩트 디스크(CD), 디브이디(DVD) 또는 레이저 디스크 등과 같은 광 기록 매체(optical media), 자기 테이프, 광자기 디스크 및/또는 플로피 디스크 등과 같이 데이터를 영구적 또는 반영구적으로 저장 가능한 적어 도 하나의 저장 매체를 이용하여 구현될 수 있다. 메모리는 센서부를 통해 획득된 센싱 정보를 저장할 수 있다. 여기서, 센싱 정보는, 사용자의 움직임 에 대응되는 웨어러블 장치의 움직임, 웨어러블 장치의 일 영역이 사용자의 신체의 일 영역과 맞닿는 터치, 사용자의 심박수, 사용자의 체온 등에 대한 정보일 수 있으나, 이에 국한되는 것은 아니다. 이외에도 메모리는 사용자 인터페이스를 통해 수신된 다양한 사용자 명령을 저장할 수 있다. 프로세서는, 전자 장치의 전반적인 동작을 제어한다. 구체적으로, 프로세서는 상술한 바와 메모리 를 포함하는 전자 장치의 구성과 연결되며, 상술한 바와 같은 메모리에 저장된 적어도 하나의 인스트 럭션을 실행함으로써, 전자 장치의 동작을 전반적으로 제어할 수 있다. 특히, 프로세서는 하나의 프로세서 로 구현될 수 있을 뿐만 아니라 복수의 프로세서로 구현될 수 있다. 프로세서는 다양한 방식으로 구현될 수 있다. 예를 들어, 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), NPU (Neural Processing Unit), 하드웨어 가속기 또는 머신 러닝 가속기 중 하나 이상을 포함할 수 있다. 하나 이상의 프로세서는 전자 장치의 다른 구성요소 중 하나 또는 임의의 조합을 제어할 수 있으며, 통신에 관한 동작 또는 데이터 처리를 수행할 수 있다. 하나 이상 의 프로세서는 메모리에 저장된 하나 이상의 프로그램 또는 명령어(instruction)을 실행할 수 있다. 예를 들어, 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 명령어를 실행함으로써, 본 개시의 일 실시 예에 따른 방법을 수행할 수 있다. 본 개시의 일 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의 해 수행될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 일 실시 예에 따른 방법에 의해 제 1 동작, 제 2 동작, 제 3 동작이 수행될 때, 제 1 동작, 제 2 동작, 및 제 3 동작 모두 제 1 프로세서 에 의해 수행될 수도 있고, 제 1 동작 및 제 2 동작은 제 1 프로세서(예를 들어, 범용 프로세서)에 의해 수행되 고 제 3 동작은 제 2 프로세서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 하나 이상의 프로세서는 하나의 코어를 포함하는 단일 코어 프로세서(single core processor)로 구현될 수 도 있고, 복수의 코어(예를 들어, 동종 멀티 코어 또는 이종 멀티 코어)를 포함하는 하나 이상의 멀티 코어 프 로세서(multicore processor)로 구현될 수도 있다. 하나 이상의 프로세서가 멀티 코어 프로세서로 구현되 는 경우, 멀티 코어 프로세서에 포함된 복수의 코어 각각은 온 칩(On-chip) 메모리와 같은 프로세서 내부 메모리를 포함할 수 있으며, 복수의 코어에 의해 공유되는 공통 캐시가 멀티 코어 프로세서에 포함될 수 있다. 또한, 멀티 코어 프로세서에 포함된 복수의 코어 각각(또는 복수의 코어 중 일부)은 독립적으로 본 개시의 일 실시 예에 따른 방법을 구현하기 위한 프로그램 명령을 판독하여 수행할 수도 있고, 복수의 코어 전 체(또는 일부)가 연계되어 본 개시의 일 실시 예에 따른 방법을 구현하기 위한 프로그램 명령을 판독하여 수행 할 수도 있다. 본 개시의 일 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 멀티 코어 프로세서에 포함 된 복수의 코어 중 하나의 코어에 의해 수행될 수도 있고, 복수의 코어에 의해 수행될 수도 있다. 예를 들어,일 실시 예에 따른 방법에 의해 제 1 동작, 제 2 동작, 및 제 3 동작이 수행될 때, 제 1 동작, 제2 동작, 및 제 3 동작 모두 멀티 코어 프로세서에 포함된 제 1 코어에 의해 수행될 수도 있고, 제 1 동작 및 제 2 동작은 멀티 코어 프로세서에 포함된 제 1 코어에 의해 수행되고 제 3 동작은 멀티 코어 프로세서에 포함된 제 2 코어에 의 해 수행될 수도 있다. 본 개시의 실시 예들에서, 프로세서는 하나 이상의 프로세서 및 기타 전자 부품들이 집적된 시스템 온 칩(SoC), 단일 코어 프로세서, 멀티 코어 프로세서, 또는 단일 코어 프로세서 또는 멀티 코어 프로세서에 포 함된 코어를 의미할 수 있으며, 여기서 코어는 CPU, GPU, APU, MIC, DSP, NPU, 하드웨어 가속기 또는 기계 학습 가속기 등으로 구현될 수 있으나, 본 개시의 실시 예들이 이에 한정되는 것은 아니다. 프로세서는 상술한 바와 같이 센서부, 사용자 인터페이스, 통신 인터페이스, 메모리 와 연결되어 다양한 장치 제어 동작을 수행할 수 있다. 도 3b는 본 개시의 일 실시 예에 따른, 서버의 구성을 설명하기 위한 블록도이다. 도 3b를 참조하면, 서버는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 다만, 이에 국한되는 것은 아니며, 추가적인 구성을 더 포함하거나 일 구성을 생략할 수도 있다. 통신 인터페이스의 일반적인 장치 구성, 기능 등을 도 3a에서 상술한 바와 같다. 프로세서는 통신 인터페이스를 통해 웨어러블 장치로부터 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱한 제1 센싱 정보를 수신할 수 있다. 프로세서는 통신 인터페이스를 통해 웨어러블 장치로부터 사용자의 신체의 일 영역과 웨어러블 장치가 맞닿은 터치를 센싱한 제2 센싱 정보를 수신할 수 있다. 이외에도 프로세서는 통신 인터페이스를 통해 웨어러블 장치로부터 사용자의 심박수, 체온 등을 센싱한 제3 센싱 정보를 수신할 수 있다. 프로세서는 통신 인터페이스를 통해 이미지 제공 장치로 디스플레이 제어 신호를 전송할 수 있 다. 프로세서는 통신 인터페이스를 통해 이미지 제공 장치로 모션 정보를 전송할 수 있다. 프로세서 는 통신 인터페이스를 통해 식별된 이미지의 분위기 코드를 이미지 제공 장치로 전송할 수 있다. 프로세서는 통신 인터페이스를 통해 웨어러블 장치의 지면으로부터의 높이에 대응되는 피치를 갖는 음에 대한 정보를 스피커로 전송할 수 있다. 프로세서는 통신 인터페이스를 통해 웨어러블 장치의 지면으로부터의 높이에 대응되는 기 설정 된 색깔 정보를 이미지 제공 장치로 전송할 수 있다. 프로세서는 통신 인터페이스를 통해 제2 센싱 정보에 대응되는 터치 정보를 이미지 제공 장치로 전송할 수 있다. 메모리의 일반적인 장치 구성, 기능 등을 도 3a에서 상술한 바와 같다. 메모리는 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱한 제1 센싱 정보, 사용자의 신 체의 일 영역과 웨어러블 장치가 맞닿은 터치를 센싱한 제2 센싱 정보, 사용자의 심박수, 체온 등을 센싱 한 제3 센싱 정보를 저장할 수 있다. 메모리는 이미지 제공 장치의 제어 정보를 저장할 수 있다. 메모리는 제1 센싱 정보에 대응되는 모션 정보, 제2 센싱 정보에 대응되는 터치 정보를 저장할 수 있다. 메모리는 이미지 분석 모델을 저장할 수 있다. 메모리는 이미지 분석 모델을 구성하는 노드, 레이어, 가중치, 파라미터 정보를 저장할 수 있다. 메모리는 이미지 제공 장치가 디스플레이하는 이미지에 포 함된 오브젝트 이미지가 포함하는 색깔에 대한 정보를 저장할 수 있다. 메모리는 이미지의 분위기 코드를 저장할 수 있다. 메모리는 웨어러블 장치의 지면으로부터의 높이에 대응되는 피치를 갖는 음에 대한 정보를 저장할 수 있다.메모리는 웨어러블 장치의 지면으로부터의 높이에 대응되는 기 설정된 색깔 정보를 저장할 수 있다. 이외에도 메모리는 사용자의 움직임, 터치 및 디스플레이 방식에 관한 다양한 정보를 저장할 수 있다. 프로세서의 일반적인 장치 구성, 기능 등을 도 3a에서 상술한 바와 같다. 프로세서는 이미지 제공 장치가 디스플레이하는 제1 이미지를 식별할 수 있다. 프로세서는 식별된 제1 이미지를 이미지 분석 모델에 입력하여 제1 이미지에 포함된 오브젝트 및 제1 이미 지가 포함하는 색깔을 식별할 수 있다. 프로세서는 식별된 오브젝트 및 색깔에 대응되는 제1 이미지의 분위기 코드를 식별할 수 있다. 프로세서는 통신 인터페이스를 통해 웨어러블 장치로부터 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱한 제1 센싱 정보를 수신할 수 있다. 프로세서는 수신된 제1 센싱 정보에 대응 되는 사용자의 모션 정보를 식별할 수 있다. 프로세서는 통신 인터페이스를 통해 웨어러블 장치의 사용자의 신체의 일 영역에 대한 터치를 센싱한 제2 센싱 정보를 수신할 수 있다. 프로세서는 제2 센싱 정보에 대응되는 터치 정보를 식별할 수 있 다. 다양한 실시 예로, 웨어러블 장치로부터 제1 센싱 정보가 수신되면, 프로세서는 제1 센싱 정보에 대 응되는 웨어러블 장치의 지면으로부터 높이를 식별할 수 있다. 프로세서는 식별된 높이에 대응되는 피치(Pitch)를 갖는 음을 식별할 수 있다. 프로세서는 식별된 높이에 대응되는 기 설정된 색깔을 식별할 수 있다. 프로세서는 식별된 모션 정보를 인터페이스를 통해 이미지 제공 장치로 전송할 수 있다. 프로세서 는 식별된 모션 정보 및 식별된 분위기 코드를 이미지 제공 장치로 전송할 수 있다. 프로세서는 식별된 피치를 갖는 음에 대한 정보를 통신 인터페이스를 통해 스피커로 전송할 수 있다. 프로세서는 식별된 기 설정된 색깔 정보를 통신 인터페이스를 통해 이미지 제공 장치로 전송할 수 있다. 도 3c는 본 개시의 일 실시 예에 따른, 이미지 제공 장치의 구성을 설명하기 위한 블록도이다. 도 3c를 참조하면, 이미지 제공 장치는 통신 인터페이스, 디스플레이부, 메모리, 프 로세서를 포함할 수 있으나, 상술한 장치 구성 외에 장치 구성을 추가로 더 포함할 수 있고, 일부 구성을 생략할 수도 있다. 통신 인터페이스의 일반적인 장치 구성 및 기능은 도 3a에서 상술한 바와 같다. 프로세서는 통신 인터페이스를 통해 서버로부터 다양한 디스플레이 제어 신호를 수신할 수 있다. 프로세서는 통신 인터페이스를 통해 사용자의 모션 정보, 터치 정보, 이미지의 분위기 코드, 기 설정 된 색깔 정보를 수신할 수 있다. 다만, 이에 국한되는 것은 아니며, 프로세서는 통신 인터페이스를 통해 서버 또는 웨어러블 장 치로부터 다양한 정보를 수신할 수 있다. 디스플레이부는 가시광선 영역의 전파를 공간의 일 영역에 조사하는 프로젝션 부일 수 있다. 다만, 디스플레이부는 상술한 프로젝션부에 국한되는 것은 아니며, 전광판, 스크린, LED, LCD로 이루어진 이미지, 영상 출력부 일 수도 있다. 프로젝션부는 이미지 제공 장치에서 출력하고자 하는 이미지를 투사면에 출력할 수 있다. 프로젝션부는 프 로젝션 렌즈를 포함할 수 있다. 투사면은 이미지가 출력되는 물리적 공간의 일부이거나 별도의 스크린일 수 있 다. 프로젝션부는 영상을 외부로 투사하는 구성이다. 본 개시의 일 실시 예에 따른, 프로젝션부는 다양한 투사 방식 (예를 들어, CRT(cathode-ray tube) 방식, LCD(Liquid Crystal Display) 방식, DLP(Digital LightProcessing) 방식, 레이저 방식 등)으로 구현될 수 있다. 일 예로, CRT 방식은 기본적으로 CRT 모니터와 원리가 동일하다. CRT 방식은 브라운관(CRT) 앞의 렌즈로 상을 확대시켜서 스크린에 이미지를 표시한다. 브라운관의 개 수에 따라 1관식과 3관식으로 나뉘며, 3관식의 경우 Red, Green, Blue의 브라운관이 따로 분리되어 구현될 수 있다. 다른 예로, LCD 방식은 광원에서 나온 빛을 액정에 투과시켜 이미지를 표시하는 방식이다. LCD 방식은 단판식과 3판식으로 나뉘며, 3판식의 경우 광원에서 나온 빛이 다이크로익 미러(특정 색의 빛만 반사하고 나머지는 통과 시키는 거울)에서 Red, Green, Blue로 분리된 뒤 액정을 투과한 후 다시 한 곳으로 빛이 모일 수 있다. 또 다른 예로, DLP 방식은 DMD(Digital Micromirror Device) 칩을 이용하여 이미지를 표시하는 방식이다. DLP 방식의 프로젝션부는 광원, 컬러 휠, DMD 칩, 프로젝션 렌즈 등을 포함할 수 있다. 광원에서 출력된 빛은 회전 하는 컬러 휠을 통과하면서 색을 띌 수 있다. 컬러 휠을 통화한 빛은 DMD 칩으로 입력된다. DMD 칩은 수많은 미 세 거울을 포함하고, DMD 칩에 입력된 빛을 반사시킨다. 프로젝션 렌즈는 DMD 칩에서 반사된 빛을 영상 크기로 확대시키는 역할을 수행할 수 있다. 또 다른 예로, 레이저 방식은 DPSS(Diode Pumped Solid State) 레이저와 검류계를 포함한다. 다양한 색상을 출 력하는 레이저는 DPSS 레이저를 RGB 색상별로 3개를 설치한 후 특수 거울을 이용하여 광축을 중첩한 레이저를 이용한다. 검류계는 거울과 높은 출력의 모터를 포함하여 빠른 속도로 거울을 움직인다. 예를 들어, 검류계는 최대 40 KHz/sec로 거울을 회전시킬 수 있다. 검류계는 스캔 방향에 따라 마운트되는데 일반적으로 프로젝터는 평면 주사를 하므로 검류계도 x, y축으로 나뉘어 배치될 수 있다. 한편, 프로젝션부는 다양한 유형의 광원을 포함할 수 있다. 예를 들어, 프로젝션부는 램프, LED, 레이저 중 적 어도 하나의 광원을 포함할 수 있다. 프로젝션부는 이미지 제공 장치의 용도 또는 사용자의 설정 등에 따라 4:3 화면비, 5:4 화면비, 16:9 와이 드 화면비로 이미지를 출력할 수 있고, 화면비에 따라 WVGA(854*480), SVGA(800*600), XGA(1024*768), WXGA(1280*720), WXGA(1280*800), SXGA(1280*1024), UXGA(1600*1200), Full HD(1920*1080) 등의 다양한 해상 도로 이미지를 출력할 수 있다. 한편, 프로젝션부는 이미지를 투사면에 출력하는 기능을 수행할 수 있다. 프로젝션부는 프로세서의 제어에 의해 출력 이미지를 조절하기 위한 다양한 기능을 수행할 수 있다. 디스플레이는 LCD(Liquid Crystal Display) 패널, OLED(Organic Light Emitting Diodes) 패널, AM- OLED(Active-Matrix Organic Light-Emitting Diode), LcoS(Liquid Crystal on Silicon), QLED(Quantum dot Light-Emitting Diode) 및 DLP(Digital Light Processing), PDP(Plasma Display Panel) 패널, 무기 LED 패널, Micro LED 패널 등 다양한 종류의 디스플레이 패널을 포함할 수 있으나, 이에 한정되는 것은 아니다. 한편, 디 스플레이는 터치 패널과 함께 터치스크린을 구성할 수도 있으며, 플렉서블(flexible) 패널로 이루어질 수도 있 다. 디스플레이는 2D 형태의 정사각형, 직사각형으로 구현될 수 있으나, 이에 국한되지 않고, 원형, 다각형, 3D 입 체 형태 등 다양한 형태로 구현될 수 있다. 디스플레이는 전자 장치의 표면 중 일 영역에 배치될 수 있으나, 이에 국한되지 않고 공간 상에 투영되는 3차원 공간 상에서 3차원 홀로그램으로 투영되거나, 2차원 평면상에 투영되는 프로젝션 형태로 구현될 수도 있다. 디스플레이는 전자 장치의 일 구성으로 포함될 수 있으나, 이에 국한되는 것은 아니며, 별도로 구비된 디스플레 이 장치가 전자 장치와 통신 인터페이스 또는 입출력 인터페이스를 통해 무선/유선으로 연결되어 프로세서 의 신호에 따른 이미지, 영상, GUI를 출력할 수 있다. 이 경우, 프로세서는 통신 인터페이스 또 는 입출력 인터페이스를 통해 무선/유선으로 디스플레이 장치와 연결을 수행하여 이미지, 영상, GUI 출력을 위 한 신호를 전송할 수 있다. 프로세서는 통신 인터페이스를 통해 서버로부터 수신된 사용자의 모션 정보에 매칭되는 궤적을 순차적으로 나타내는 이미지를 디스플레이하도록 디스플레이부를 제어할 수 있다. 프로세서는 제1 이미지가 디스플레이되는 영역에 사용자의 모션 정보에 매칭되는 궤적을 순차적으로 나타 내는 제2 이미지를 디스플레이하도록 디스플레이부를 제어할 수 있다. 프로세서는 통신 인터페이스를 통해 수신된 사용자의 모션 정보 및 분위기 코드에 기초하여 제1 이미 지가 디스플레이되는 영역에 사용자의 모션 정보에 매칭되는 궤적을 나타내며, 식별된 분위기 코드에 대응되는 모양 및 색깔로 이루어진 제2 이미지를 디스플레이하도록 디스플레이부를 제어할 수 있다. 여기서, 모양은 직선, 곡선, 원, 타원, 다각형 등일 수 있고, 색깔은 빨강, 주황, 노랑, 초록, 파랑, 보라 등일 수 있으나, 모양과 색깔은 상술한 바에 국한되지 않는다. 프로세서는 통신 인터페이스를 통해 서버로부터 수신된 기 설정된 색깔 정보에 기초하여 이미지 제공 장치가 웨어러블 장치의 지면으로부터의 높이에 대응되는 기 설정된 색깔로 모션 정보에 매칭되 는 궤적을 나타내는 이미지를 디스플레이하도록 디스플레이부를 제어할 수 있다. 프로세서는 통신 인터페이스를 통해 서버로부터 수신된 터치 정보에 매칭되는 디스플레이 방식 으로 이미지를 디스플레이 하도록 디스플레이부를 제어할 수 있다. 프로세서는 디스플레이된 상기 이미지 중 디스플레이된 시간이 기 설정된 시간 이상인 상기 이미지 일부에 대한 디스플레이를 순차적으로 중지 메모리의 일반적인 장치 구성 및 기능은 도 3a에서 상술한 바와 같다. 메모리는 프로세서가 디스플레이부를 제어하기 위한 다양한 인스트럭션, 제어 신호를 저장 할 수 있다. 메모리는 통신 인터페이스를 통해 수신된 사용자의 모션 정보, 터치 정보 등을 저장할 수 있다. 메모리는 디스플레이 방식, 예컨대, 디스플레이되는 컨텐츠의 모양, 색깔 등에 대한 정보를 저장할 수 있 다. 프로세서의 일반적인 장치 구성 및 기능은 도 3a에서 상술한 바와 같다. 프로세서는 통신 인터페이스, 디스플레이부, 메모리와 연결되어 상술한 바와 같이 이 미지 제공 장치의 장치 구성의 제어 동작을 수행할 수 있다. 상술한, 웨어러블 장치, 서버, 이미지 제공 장치로 이루어진 시스템의 기본적인 동작을 정리해 보면, 다음과 같다. 웨어러블 장치가 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득할 수 있다. 또한, 이미지 제공 장치가 제1 이미지를 디스플레이하는 동안 웨어러블 장치가 사용 자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득할 수도 있다. 웨어러블 장치가 획득된 제1 센싱 정보를 서버로 전송할 수 있다. 웨어러블 장치로부터 제1 센싱 정보가 수신되면, 서버가 제1 센싱 정보에 대응되는 사용자의 모션 정 보를 식별할 수 있다. 서버가 식별된 모션 정보를 이미지 제공 장치로 전송할 수 있다. 이미지 제공 장치가 모션 정보에 매칭되는 궤적을 순차적으로 나타내는 제1 이미지를 디스플레이 할 수 있 다. 또한, 서버로부터 수신된 모션 정보에 기초하여 이미지 제공 장치가 제1 이미지가 디스플레이되 는 영역에 모션 정보에 매칭되는 궤적을 순차적으로 나타내는 제2 이미지를 디스플레이할 수도 있다. 보다 구체적인 웨어러블 장치, 서버 및 이미지 제공 장치로 이루어진 시스템의 제어 방법은 도 4 내지 7과 함께 구체적으로 설명한다. 도 4는 본 개시의 일 실시 예에 따른, 웨어러블 장치, 서버 및 이미지 제공 장치의 동작을 설명 하기 위한 시퀀스도이다. 도 4를 참조하면, 서버는 제1 이미지를 식별할 수 있다(S405). 서버는 제1 이미지 정보를 이미지 제 공 장치로 전송할 수 있다(S410). 이미지 제공 장치는 서버로부터 수신된 제1 이미지 정보에 기 초하여 제1 이미지를 디스플레이할 수 있다(S415). 다만, 이에 국한되지 않고, 이미지 제공 장치가 제1 이미지를 먼저 디스플레이하고, 서버가 이미지 제공 장치로부터 수신된 정보에 기초하여 제1 이미지를 식별할 수도 있다. 여기서, 제1 이미지는 풍경화, 정물화, 인물화, 추상화 등 다양한 그림, 예컨대 유명한 화가들의 명화일 수 있 으나, 이에 국한되지 않고 다양한 그림, 이미지, 영상일 수 있다. 서버는 제1 이미지를 이미지 분석 모델에 입력하여 제1 이미지에 포함된 오브젝트 및 제1 이미지가 포함하 는 색깔을 식별할 수 있다(S420). 여기서, 이미지 분석 모델은 다양한 피사체, 오브젝트를 포함하는 이미지를 입력 데이터로 하여 기 학습된 기계 학습 모델, 신경망 모델일 수 있으나, 이에 국한되지 않는다. 또한, 오브젝트는 제1 이미지에 포함된 피사체일 수 있고, 보다 구체적으로, 인물, 물건, 동물, 식물, 하늘, 땅, 바다 등일 수 있으나, 이에 국한되는 것은 아니 다. 서버는 식별된 오브젝트 및 색깔에 대응되는 제1 이미지의 분위기 코드를 식별할 수 있다(S425). 분위기 코드는 긍정적인 분위기, 부정적인 분위기일 수 있으나, 보다 구체적으로, 기쁨, 슬픔, 놀람, 사랑, 평 화, 절망, 고통, 고독, 분노 등일 수 있다. 이 때, 분위기 코드가 긍정적인 분위기 부정적인 분위기로 구현되는 경우, 서버는 식별된 오브젝트 및 색 깔에 기초하여 제1 이미지의 분위기 스코어를 식별할 수 있다. 여기서, 분위기 스코어가 높을수록 긍정적인 분 위기, 분위기 스코어가 낮을수록 부정적인 분위기일 수 있다. 서버는 제1 이미지에 포함된 색깔이 무채색 대비 유채색이 많을수록, 색깔의 명도 또는 채도가 높을수록 분위기 스코어를 높게 식별할 수 있다. 서버는 제1 이미지에 포함된 색깔이 무채색 대비 유채색이 적을수 록, 색깔의 명도 또는 채도가 낮을수록 분위기 스코어를 낮게 식별할 수 있다. 또 다른 예로, 서버는 제1 이미지에 포함된 오브젝트가 연인이면, 분위기 코드를 사랑으로 식별할 수 있다. 서버는 제1 이미지에 포함된 오브젝트 중 하늘, 바다의 비중이 기 설정된 값 이상이면, 분위기 코드 를 평화로 식별할 수 있다. 서버는 제1 이미지에 포함된 오브젝트가 사람이 죽은 시체라면, 분위기 코드를 슬픔, 고통, 절망으로 식별할 수 있다. 이미지 제공 장치가 제1 이미지를 디스플레이하는 동안 웨어러블 장치는 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득할 수 있다(S430). 사용자의 움직임은 예를 들어, 3차원 공간 상에서의 이동, 회전, 진동 등일 수 있으나, 이에 국한되는 것은 아 니다. 웨어러블 장치는 획득된 제1 센싱 정보를 서버로 전송할 수 있다(S435). 서버는 제1 센싱 정보에 대응되는 사용자의 모션 정보를 식별할 수 있다(S440). 서버는 사용자의 모션 정보 및 식별된 분위기 코드를 이미지 제공 장치로 전송할 수 있다(S445). 이미지 제공 장치는 모션 정보 및 분위기 코드에 기초하여 빔 프로젝터가 제1 이미지가 디스플레이되는 영 역에 모션 정보에 매칭되는 궤적을 나타내며, 식별된 분위기 코드에 대응되는 모양 및 색깔로 이루어진 제2 이 미지를 디스플레이할 수 있다(S450). 보다 구체적으로, 식별된 분위기 코드가 긍정적인 분위기, 기쁨, 사랑, 평화라면, 이미지 제공 장치는 유 채색 중 명도와 채도가 높은 색으로 제2 이미지를 디스플레이 할 수 있다. 식별된 분위기 코드가 긍정적인 분위 기, 기쁨, 사랑, 평화라면, 이미지 제공 장치는 곡선, 원, 타원의 모양을 가진 제2 이미지를 디스플레이할 수 있다. 또한, 식별된 분위기 코드가 부정적인 분위기, 슬픔, 절망, 고통, 고독, 분노 등이라면, 이미지 제공 장치(30 0)는 무채색으로 제2 이미지를 디스플레이하거나, 유채색 중 명도와 채도가 낮은 색으로 제2 이미지를 디스플레 이할 수 있다. 식별된 분위기 코드가 부정적인 분위기, 슬픔, 절망, 고통, 고독, 분노 등이라면, 이미지 제공 장치는 지그재그 모양의 선, 굵기가 기 설정된 값 이상인 선을 디스플레이할 수 있다. 이외에도 웨어러블 장치는 센서부를 통해 사용자의 체온, 사용자의 심박수를 센싱한 제3 센싱 정보를 획득할 수 있다. 웨어러블 장치는 제3 센싱 정보를 서버로 전송할 수 있다. 서버는 수신된 제3 센싱 정보에 기초하여 사용자의 감정을 식별할 수 있다. 예를 들어, 서버는 사용 자의 심박수가 기 설정된 값 이상이거나 체온이 기 설정된 값 미만이면, 사용자의 감정을 기쁨, 흥분, 놀람, 분 노로 식별할 수 있다. 또한 서버는 사용자의 심박수가 기 설정된 값 이상이거나 체온이 기 설정된 값 미만이면, 사용자의 감정을 평화, 슬픔, 우울함으로 식별할 수 있다. 서버는 제1 이미지에 기초하여 식별된 분위기 코드 및 사용자의 식별된 감정의 유사도가 기 설정된 값 이 상인 경우에만 사용자의 모션 정보 및 식별된 분위기 코드를 이미지 제공 장치로 전송할 수 있다. 여기서, 서버는 제3 센싱 정보에 포함된 사용자의 심박수, 사용자의 체온을 감정 식별 모델에 입력하여 획 득된 감정 키워드의 특징 정보를 추출하여 감정 키워드의 의미를 식별할 수 있다. 서버는 감정 키워드의 의미에 대응되는 벡터 값과 식별된 분위기 코드에 대응되는 벡터 값을 잠재 공간 상에서 식별하여, 두 벡터가 이루는 각도가 작을수록, 두 벡터의 절대 값의 차이가 작을수록 사용자의 감정과 분위기 코드가 유사한 것으로 식별할 수 있다. 이와 같이 식별된 사용자의 감정과 분위기 코드의 유사도가 기 설정된 값 이상인 경우에만 사 용자의 모션 정보 및 식별된 분위기 코드를 이미지 제공 장치로 전송할 수 있다. 이미지 제공 장치는 식별된 분위기 코드에 대응되는 모양 및 색깔로 이루어진 제2 이미지를 디스플레이 할 수 있다. 즉, 이 경우, 제1 이미지의 분위기를 명확하게 이해한 사용자의 움직임에 따른 제2 이미지만이 디스플레이되도 록 하여 그림의 분위기를 이해하고 그에 맞는 감정을 느끼는 체험을 할 수 있다. 이미지 제공 장치는 제공 장치에 의해 디스플레이된 이미지 중 디스플레이된 시간이 기 설정된 간 이상인 이미지 일부에 대한 디스플레이를 순차적으로 중지할 수 있다. 따라서, 사용자의 움직임에 따라 나타나는 궤적 이미지는 기 설정된 시간 동안 디스플레이 되다가 순차적으로 사라지는 애니메이션 효과를 가질 수 있다. 도 5는 본 개시의 일 실시 예에 따른, 시스템이 사용자의 움직임과 미술작품을 융합한 이미지를 디스플레이하는 동작을 설명하기 위한 도면이다. 도 5를 참조하면, 이미지 제공 장치를 통해 제1 이미지가 디스플레이되는 동안 웨어러블 장치는 사용자의 다양한 움직임(1-1, 1-2, 1-3, 1-4, 1-5)에 대응되는 웨어러블 장치의 움직임을 센싱한 센싱 정 보를 획득할 수 있다. 웨어러블 장치는 센싱 정보를 서버로 전송하고, 서버는 웨어러블 장치의 움직임에 대응되 는 제2 이미지(3-1, 3-2, 3-3, 3-4, 3-5)를 제1 이미지가 디스플레이 되는 영역에 디스플레이 할 수 있다. 따라서, 사용자는 고전 명화, 디자인작품 등과 양방향으로 소통하면서 자신의 움직임에 따른 제2 이미지와 제1 이미지가 융합한 또 다른 예술작품을 탄생시킬 수 있다. 다양한 실시 예에 따르면, 사용자는 자신의 움직임에 기반하여 새로운 예술작품, 예를 들어, 미술과 음악이 결 합된 새로운 예술작품을 창작할 수도 있다. 도 6은 본 개시의 일 실시 예에 따른, 웨어러블 장치, 서버, 이미지 제공 장치 및 스피커의 동 작을 설명하기 위한 시퀀스도이다. 도 6을 참조하면, 이미지 제공 장치는 제1 이미지를 디스플레이할 수 있다(S605). 웨어러블 장치는 제1 이미지가 디스플레이되는 동안 사용자의 움직임에 대응되는 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득할 수 있다(S610). 웨어러블 장치는 제1 센싱 정보를 서버로 전송할 수 있다(S615). 서버는 제1 센싱 정보에 대응 되는 사용자의 모션 정보를 식별할 수 있다(S620). 서버는 제1 센싱 정보에 대응되는 웨어러블 장치의 지면으로부터의 높이를 식별할 수 있다(S625). 구체적으로, 서버는 웨어러블 장치의 초기 높이 정보를 획득할 수 있다. 여기서, 초기 높이 정보는 기 설정된 높이일 수 있으나, 웨어러블 장치의 사용자 인터페이스를 통해 사용자에 의해 입력된 값일 수도 있다. 서버는 웨어러블 장치로부터 수신된 제1 센싱 정보에 기초하여 웨어러블 장치의 지면으로부터 수직인 방향으로 움직인 거리를 식별할 수 있다. 서버는 웨어러블 장치의 초기 높이 정보 및 웨어러블 장치의 지면으로부터 수직인 방향으로 움 직인 거리에 기초하여 웨어러블 장치의 높이를 식별할 수 있다. 이외에도, 서버는 웨어러블 장치로부터 수신된 제1 센싱 정보에 기초하여 웨어러블 장치가 이미 지 제공 장치가 이미지를 디스플레이하는 영역에 대응되는 높이에 기초하여 웨어러블 장치의 높이를 식별할 수도 있다. 즉, 웨어러블 장치의 높이가 0부터 1까지의 범위라고 할 때, 서버는 웨어러블 장치의 모션 정보 에 매칭되는 궤적이 디스플레이되는 높이가 이미지 제공 장치가 이미지를 디스플레이하는 영역 중 가장 지 면에 가까운 높이와 일치할 때의 웨어러블 장치의 지면으로부터의 높이를 0으로 식별할 수 있다. 서버 는 웨어러블 장치의 모션 정보에 매칭되는 궤적이 디스플레이되는 높이가 이미지 제공 장치가 이미지를 디스플레이하는 영역 중 가장 지면에서 먼 높이와 일치할 때의 웨어러블 장치의 지면으로부터의 높이를 1로 식별할 수 있다. 서버는 식별된 높이에 대응되는 피치(Pitch)를 갖는 음을 식별할 수 있다(S630). 구체적으로, 식별된 높이 가 가장 낮은 높인 경우, 서버는 “도”를 식별하고, 식별된 높이가 높아질수록 “도”, “레”, “미”, “파”, “솔”, “라”, “시”, “도”에 대응되는 음을 식별할 수 있다. 그리고, 서버는 식별된 높이에 대응되는 기 설정된 색깔을 식별할 수 있다. 구체적으로, 식별된 높이가 가 장 낮은 높인 경우, 서버는 기 설정된 색깔로 “빨강”을 식별하고, 식별된 높이가 높아질수록 “빨강”, “주황”, “노랑”, “초록”, “파랑”, “보라”의 색깔을 식별할 수 있다. 서버는 사용자의 모션 정보를 이미지 제공 장치로 전송할 수 있다(S635). 그리고, 서버는 식별 된 기 설정된 색깔 정보를 이미지 제공 장치로 전송할 수 있다. 서버는 식별된 피치를 갖는 음에 대한 정보를 스피커로 전송할 수 있다(S640). 이미지 제공 장치는 수신된 모션 정보에 기초하여 제1 이미지가 디스플레이되는 영역에 모션 정보에 매칭 되는 궤적을 순차적으로 나타내는 제2 이미지를 디스플레이할 수 있다(S645). 그리고, 서버로부터 수신된 기 설정된 색깔 정보에 기초하여 이미지 제공 장치는 웨어러블 장치의 지면으로부터의 높이에 대응되 는 기 설정된 색깔로 모션 정보에 매칭되는 궤적을 나타내는 이미지를 디스플레이할 수 있다. 스피커는 수신된 음에 대한 정보에 기초하여 웨어러블 장치의 지면으로부터의 높이에 대응되는 음을 출력 할 수 있다(S650). 도 7은 본 개시의 일 실시 예에 따른, 시스템이 사용자의 움직임에 기반하여 창작된 미술작품과 음악작품을 제 공하는 동작을 설명하기 위한 도면이다. 도 7을 참조하면, 이미지 제공 장치는 사용자의 모션 정보에 매칭되는 궤적을 디스플레이한다. 궤적 이 미지는 웨어러블 장치의 높이에 대응하여 높이에 따라 다른 색깔로 디스플레이되며, 스피커는 웨어러블 장치의 높이에 대응되는 피치를 갖는 음을 출력할 수 있다. 그리고, 스피커가 음을 출력하지 않은 상태에서 이미지 제공 장치가 모션 정보에 매칭되는 궤적을 나타 내는 이미지를 디스플레이하고, 이미지 제공 장치가 이미지를 모두 디스플레이한 상태에서 스피커가 음 을 출력할 수도 있다. 즉, 사용자의 움직임에 따른 이미지와 음이 동시에 출력될 수도 있지만, 궤적 이미지를 모두 디스플레이 한 다음, 음이 출력되도록 할 수도 있다. 따라서, 사용자는 자신의 움직임에 기반하여 높이에 따라 다른 색깔로 이루어지며, 다른 피치를 갖는 음이 출력 되도록 하여 미술작품과 음악작품이 융합된 융합 예술작품을 탄생시킬 수 있다. 이미지 제공 장치는 제공 장치에 의해 디스플레이된 이미지 중 디스플레이된 시간이 기 설정된 간 이상인 이미지 일부에 대한 디스플레이를 순차적으로 중지할 수 있다. 따라서, 사용자의 움직임에 따라 나타나는 궤적 이미지는 기 설정된 시간 동안 디스플레이 되다가 순차적으로 사라지는 애니메이션 효과를 가질 수 있다. 다양한 실시 에로, 웨어러블 장치는 사용자의 신체의 일 영역에 대한 터치를 센싱한 제2 센싱 정보를 획득 할 수도 있다. 이 때, 제2 센싱 정보는 센서부의 정전기 센서에 의해 센싱된 것일 수 있으나, 이에 국한되 지 않는다. 웨어러블 장치는 획득된 제2 센싱 정보를 서버로 전송할 수 있다. 웨어러블 장치로부터 제2 센 싱 정보가 수신되면, 서버가 제2 센싱 정보에 대응되는 터치 정보를 식별할 수 있다. 서버는 식별된 터치 정보를 이미지 제공 장치로 전송할 수 있다. 이미지 제공 장치가 터치 정보 에 매칭되는 디스플레이 방식으로 이미지를 디스플레이할 수 있다. 여기서, 터치 정보에 매칭되는 디스플레이 방식이란, 원형으로 퍼져나가는 물결모양, 물방울 모양의 디스플레이 방식일 수 있으나, 이에 국한되는 것은 아 니다. 상술한 도 4의 실시 예와 도 6의 실시 예는 함께 결합될 수 있다. 서버는 이미지 제공 장치가 디스플레이하는 중인 제1 이미지를 식별할 수 있다. 서버는 제1 이 미지를 이미지 분석 모델에 입력하여 제1 이미지에 포함된 오브젝트 및 제1 이미지가 포함하는 색깔을 식별할 수 있다. 서버는 식별된 오브젝트 및 색깔에 대응되는 제1 이미지의 분위기 코드를 식별할 수 있다. 웨어러블 장치는 이미지 제공 장치에 의해 제1 이미지가 디스플레이되는 동안 사용자의 움직임에 대 응되는 웨어러블 장치의 움직임을 센싱하여 제1 센싱 정보를 획득할 수 있다. 웨어러블 장치는 제1 센싱 정보를 서버로 전송할 수 있다. 서버는 제1 센싱 정보에 대응되는 사용자의 모션 정보를 식별할 수 있다. 서버는 제1 센싱 정보에 대응되는 웨어러블 장치의 지면으로부터의 높이를 식별할 수 있다. 웨어러블 장치는 식별된 높이에 대응되는 피치를 갖는 음을 식별할 수 있다. 서버는 모션 정보 및 분위기 코드를 이미지 제공 장치로 전송할 수 있다. 서버는 식별된 피치를 갖는 음에 대한 정보를 스피커로 전송할 수 있다. 이미지 제공 장치는 수신된 모션 정보 및 분위기 코드에 기초하여 제1 이미지가 디스플레이되는 영역에 모 션 정보에 매칭되는 궤적을 나타내는 제2 이미지를 순차적으로 디스플레이할 수 있다. 스피커를 수신된 음에 대한 정보에 기초하여 웨어러블 장치의 지면으로부터의 높이에 대응되는 피치를 갖 는 음을 출력할 수 있다. 일 실시 예에 따르면, 본 문서에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치 들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스 토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시 적으로 생성될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2023-0133737", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2023-0133737", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 특정 실시 예의 양상, 특징 및 이점은 첨부된 도면들을 참조하여 후술되는 설명을 통해 보다 명확해 질 것이다. 도 1은 본 개시의 일 실시 예에 따른, 사용자의 움직임을 기반으로 한 예술작품의 융합 및 창작을 설명하기 위 한 도면이다. 도 2는 본 개시의 일 실시 예에 따른, 웨어러블 장치, 서버 및 이미지 제공 장치를 포함하는 시스템을 설명하기 위한 도면이다. 도 3a는 본 개시의 일 실시 예에 따른, 웨어러블 장치의 구성을 설명하기 위한 블록도이다. 도 3b는 본 개시의 일 실시 예에 따른, 서버의 구성을 설명하기 위한 블록도이다. 도 3c는 본 개시의 일 실시 예에 따른, 이미지 제공 장치의 구성을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시 예에 따른, 웨어러블 장치, 서버 및 이미지 제공 장치의 동작을 설명하기 위한 시퀀 스도이다. 도 5는 본 개시의 일 실시 예에 따른, 시스템이 사용자의 움직임과 미술작품을 융합한 이미지를 디스플레이하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른, 웨어러블 장치, 서버, 이미지 제공 장치 및 스피커의 동작을 설명하기 위 한 시퀀스도이다. 도 7은 본 개시의 일 실시 예에 따른, 시스템이 사용자의 움직임에 기반하여 창작된 미술작품과 음악작품을 제 공하는 동작을 설명하기 위한 도면이다."}
