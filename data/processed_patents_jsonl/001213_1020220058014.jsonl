{"patent_id": "10-2022-0058014", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0158352", "출원번호": "10-2022-0058014", "발명의 명칭": "인공지능 영상분석 기반의 산업현장 안전 관리 시스템", "출원인": "(주)포소드", "발명자": "전정희"}}
{"patent_id": "10-2022-0058014", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "산업현장에 설치되어 산업현장을 촬영한 영상데이터를 실시간 송출하는 네트워크 카메라부;상기 네트워크 카메라부로부터 상기 영상데이터를 수신하고, 딥러닝 모델을 이용하여 수신된 상기 영상데이터로부터 미리 정의된 객체 탐지 및 이벤트 검출을 수행하고, 탐지 및 검출 결과와 해당 영상데이터를 포함하는 데이터 패킷을 실시간 송출하는 엣지 컴퓨팅 장치부; 및상기 엣지 컴퓨팅 실행부로부터 수신된 데이터 패킷에 대한 영상과 객체 탐지 및 이벤트 검출 결과를 모니터링하고 기록하는 통합 관제 서버부를 포함하는 것을 특징으로 하는 인공지능 영상분석 기반의 산업현장 안전 관리시스템."}
{"patent_id": "10-2022-0058014", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 네트워크 카메라부는,상기 영상데이터를 H.264 형식의 RTSP(Real-Time Streaming Protocol) 패킷으로 변환하여 상기 엣지 컴퓨팅 장치부에 실시간 송출하는 것을 특징으로 하는 인공지능 영상분석 기반의 산업현장 안전 관리 시스템."}
{"patent_id": "10-2022-0058014", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 엣지 컴퓨팅 장치부는,상기 네트워크 카메라부로부터 수신되는 상기 RTSP 패킷에 대한 디코딩을 수행하여 RGB 이미지로 변환하는 디코딩 실행부;상기 디코딩 실행부를 통해 변환된 상기 RGB 이미지를 미리 정의된 제1 딥러닝 모델의 입력 값으로 입력 받아미리 정의된 객체 탐지 및 이벤트 검출을 수행하고, 객체 탐지 및 이벤트 검출 결과를 출력 값으로 출력하는 객체 탐지 및 이벤트 검출부;상기 RGB 이미지와 상기 객체 탐지 및 이벤트 검출 결과 간의 타임 시퀀스를 비교하여 동일한 시퀀스를 갖는RGB 이미지와 객체 탐지 및 이벤트 검출 결과를 H.264 형식의 스트림으로 생성하되, 상기 스트림 내에 객체 탐지 및 이벤트 검출 결과를 RGB 이미지에 대한 메타데이터로 생성하는 먹서(Muxer); 및상기 먹서를 통해 생성된 상기 스트림을 RTSP(Real-Time Streaming Protocol) 패킷으로 변환하고, 변환된 RTSP패킷을 상기 통합 관제 서버부로 송출하는 RTSP 서버부를 포함하는 것을 특징으로 하는 인공지능 영상분석 기반의 산업현장 안전 관리 시스템."}
{"patent_id": "10-2022-0058014", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 제1 딥러닝 모델은,상기 RGB 이미지에 대하여 사람에 대한 객체를 검출하고, 검출된 사람을 대상으로 ROI(Region Of Interest)를설정하여 ROI(Region Of Interest) 내에 미리 정의된 안전장비의 착용 유무를 탐지하여 사람의 안전장비 미착용에 대한 객체 탐지 결과를 출력하고,공개특허 10-2023-0158352-3-상기 RGB 이미지에 대하여 사람에 대하여 미리 정의된 이상행동 및 화재의 발생 유무를 판별하고, 이상행동 및화재 발생에 대한 이벤트 검출 결과를 출력하는 것을 특징으로 하는 인공지능 영상분석 기반의 산업현장 안전관리 시스템."}
{"patent_id": "10-2022-0058014", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 통합 관제 서버부는,상기 엣지 컴퓨팅 장치부로부터 사람의 안전장비 미 착용에 대한 객체 탐지 결과와, 사람의 이상행동 및 산업현장의 화재 발생에 대한 이벤트 검출 결과 중 적어도 하나의 결과를 수신하는 경우, 해당 현장에 대하여 미리 등록된 관리자에게 알림 또는 신고 조치를 취하거나, 해당 현장으로 안내 방송을 송출하는 것을 특징으로 하는 인공지능 영상분석 기반의 산업현장 안전 관리 시스템."}
{"patent_id": "10-2022-0058014", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 영상분석 기반의 산업현장 안전 관리 시스템에 관한 것으로, 해결하고자 하는 과제는 산업현 장을 촬영한 영상 내 객체와 이벤트에 대한 정보가 레이블링 된 학습 데이터를 기반으로 미리 학습된 딥러닝 모 델을 이용하여 작업 현장을 촬영한 영상(예: 동영상, 이미지)를 분석함으로써, 작업자들이 안전기준을 준수하는 (뒷면에 계속)"}
{"patent_id": "10-2022-0058014", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 인공지능 영상분석 기반의 산업현장 안전 관리 시스템에 관한 것이다."}
{"patent_id": "10-2022-0058014", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "산업현장의 동향으로는 사회문제로 대두되는 노령화에 맞물려 대부분 근로자의 연령 증가, 미숙련자의 증가, 여 성 근로자의 참여 확대 및 외국인 노동자의 건설시장 유입으로 재해발생 위험 또한 증가되고 있는 실정이다. 이러한 사고는 작업자의 실수나 돌발적인 주변환경 변화 및 안전하지 않은 절차나 절차의 부재로 인한 안전하지 않은 행동으로 인한 것이 대부분이다. 이러한 인명피해를 최소화하기 위해, 구조물의 건축이나 건설작업 시 작 업 자는 안전모나 헬멧 등과 같은 보호장비를 반드시 착용하는 등과 같이 안전기준을 준수하는 것이 필수적이다. 그러나, 실제 산업현장에서는 작업의 편의성이나 빠른 작업 처리를 위해 작업자들이 안전기준을 준수하지 않고 작업을 수행하는 것이 비일비재하다. 또한, 작업자들이 안전기준을 정확하게 숙지하지 못하여 제대로 된 조치를 취하지 않고 작업을 하는 경우도 있다. 이와 같이 안전기준을 준수하여 작업을 하지 않을 경우, 사고가 발생할 가능성이 높아지고, 사고에 따른 피해 규모가 커질 수 있다. 종래에는 산업현장에서 사고가 발생하는 것을 방지하기 위하여, 작업 현장의 관리자가 산업현장을 직접 돌아 다 니며 작업자들이 안전기준을 준수하며 작업하도록 지시하거나, 산업현장에 설치된 카메라(예: CCTV 카메라)를 통해 촬영된 산업현장 영상을 관제센터로 직접 송출하여 작업자들이 안전기준을 준수하며 작업하는지 여부를 모 니터링하였다. 그러나, 이러한 종래의 방법은 작업 관리자가 직접 안전기준을 준수하는지 여부를 확인하고, 이에 따른 지시를 내려야 하기 때문에 작업 관리자가 안전기준을 정확하게 숙지하고 정확한 지시를 내려야 한다는 문제가 있다. 또한, 규모가 큰 작업 현장의 경우 이러한 종래의 방법을 수행하기 위해 다수의 작업 관리자가 필요하며, 작업 현장에서 수많은 단위 작업들이 수행되기 때문에, 이러한 작업들을 일일이 확인하고 지시하기가 어렵다는 문제 가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-2313479호(등록일자: 2021년10월08일) (특허문헌 0002) 등록특허공보 제10-2136070호(등록일자: 2020년07월15일) (특허문헌 0003) 등록특허공보 제10-1033349호(등록일자: 2011년04월28일)"}
{"patent_id": "10-2022-0058014", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는, 산업현장을 촬영한 영상 내 객체와 이벤트에 대한 정보가 레이블링 된 학습 데이터를 기반 으로 미리 학습된 딥러닝 모델을 이용하여 작업 현장을 촬영한 영상(예를 들어 동영상, 이미지)를 분석함으로써, 작업자들이 안전기준을 준수하는지 여부에 따라 화재와 같은 사고 발생 여부를 판별할 수 있는 인공지능 영상분석 기반의 산업현장 안전 관리 시스템을 제공한다."}
{"patent_id": "10-2022-0058014", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 인공지능 영상분석 기반의 산업현장 안전 관리 시스템은, 산업현장에 설치되어 산업현 장을 촬영한 영상데이터를 실시간 송출하는 네트워크 카메라부; 상기 네트워크 카메라부로부터 상기 영상데이터 를 수신하고, 딥러닝 모델을 이용하여 수신된 상기 영상데이터로부터 미리 정의된 객체 탐지 및 이벤트 검출을 수행하고, 탐지 및 검출 결과와 해당 영상데이터를 포함하는 데이터 패킷을 실시간 송출하는 엣지 컴퓨팅 장치 부; 및 상기 엣지 컴퓨팅 실행부로부터 수신된 데이터 패킷에 대한 영상과 객체 탐지 및 이벤트 검출 결과를 모 니터링하고 기록하는 통합 관제 서버부를 포함한다. 또한, 상기 네트워크 카메라부는, 상기 영상데이터를 H.264 형식의 RTSP(Real-Time Streaming Protocol) 패킷 으로 변환하여 상기 엣지 컴퓨팅 장치부에 실시간 송출할 수 있다. 또한, 상기 엣지 컴퓨팅 장치부는, 상기 네트워크 카메라부로부터 수신되는 상기 RTSP 패킷에 대한 디코딩을 수 행하여 RGB 이미지로 변환하는 디코딩 실행부; 상기 디코딩 실행부를 통해 변환된 상기 RGB 이미지를 미리 정의 된 제1 딥러닝 모델의 입력 값으로 입력 받아 미리 정의된 객체 탐지 및 이벤트 검출을 수행하고, 객체 탐지 및 이벤트 검출 결과를 출력 값으로 출력하는 객체 탐지 및 이벤트 검출부; 상기 RGB 이미지와 상기 객체 탐지 및 이벤트 검출 결과 간의 타임 시퀀스를 비교하여 동일한 시퀀스를 갖는 RGB 이미지와 객체 탐지 및 이벤트 검출 결과를 H.264 형식의 스트림으로 생성하되, 상기 스트림 내에 객체 탐지 및 이벤트 검출 결과를 RGB 이미지에 대한 메타데이터로 생성하는 먹서(Muxer); 및 상기 먹서를 통해 생성된 상기 스트림을 RTSP(Real-Time Streaming Protocol) 패킷으로 변환하고, 변환된 RTSP 패킷을 상기 통합 관제 서버부로 송출하는 RTSP 서버부를 포함할 수 있다. 또한, 상기 제1 딥러닝 모델은, 상기 RGB 이미지에 대하여 사람에 대한 객체를 검출하고, 검출된 사람을 대상으 로 ROI(Region Of Interest)를 설정하여 ROI(Region Of Interest) 내에 미리 정의된 안전장비의 착용 유무를 탐지하여 사람의 안전장비 미착용에 대한 객체 탐지 결과를 출력하고, 상기 RGB 이미지에 대하여 사람에 대하여 미리 정의된 이상행동 및 화재의 발생 유무를 판별하고, 이상행동 및 화재 발생에 대한 이벤트 검출 결과를 출 력할 수 있다. 또한, 상기 통합 관제 서버부는, 상기 엣지 컴퓨팅 장치부로부터 사람의 안전장비 미 착용에 대한 객체 탐지 결 과와, 사람의 이상행동 및 산업현장의 화재 발생에 대한 이벤트 검출 결과 중 적어도 하나의 결과를 수신하는 경우, 해당 현장에 대하여 미리 등록된 관리자에게 알림 또는 신고 조치를 취하거나, 해당 현장으로 안내 방송 을 송출할 수 있다. 또한, 상기 네트워크 카메라부는, 상기 영상데이터에 산업현장의 위치식별코드를 포함시켜 송출하고, 상기 객체 탐지 및 이벤트 검출부는, 상기 객체 탐지 및 이벤트 검출부의 객체 탐지 결과로 안전장비의 미 착용이 탐지되 면, 안전장비의 미 착용이 탐지된 RGB 이미지, 해당 RGB 이미지의 위치식별코드 및 미 착용된 안전장비의 장비 식별코드를 각각 별도로 출력하고, 상기 엣지 컴퓨팅 장치부는, 상기 객체 탐지 및 이벤트 검출부로부터 출력되 는 상기 위치식별코드 및 상기 장비식별코드를 각각 수신하고, 수신된 RGB 이미지를 미리 정의된 제2 딥러닝 모 델의 입력 값으로 입력 받아 미리 정의된 안전장비 구호행동 유무를 판별하여 안전장비 구호행동에 대한 이벤트 를 검출하고, 안전장비 구호행동에 대한 이벤트 검출 시 상기 위치식별코드 및 상기 장비식별코드를 출력하는 안전장비 구호행동 검출부를 더 포함하고, 상기 인공지능 영상분석 기반의 산업현장 안전 관리 시스템은, 상기 안전장비 구호행동 검출부로부터 수신되는 상기 위치식별코드 및 상기 장비식별코드를 기반으로 해당 안전장비 를 자율주행동작을 통해 해당 현장으로 운반하기 위한 자율주행 장치부를 더 포함할 수 있다."}
{"patent_id": "10-2022-0058014", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 산업현장을 촬영한 영상 내 객체와 이벤트에 대한 정보가 레이블링 된 학습 데이터를 기반으 로 미리 학습된 딥러닝 모델을 이용하여 작업 현장을 촬영한 영상(예: 동영상, 이미지)를 분석함으로써, 작업자 들이 안전기준을 준수하는지 여부에 따라 화재와 같은 사고 발생 여부를 판별할 수 있는 인공지능 영상분석 기 반의 산업현장 안전 관리 시스템을 제공할 수 있다."}
{"patent_id": "10-2022-0058014", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나 이상의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 발명의 실시예에 따른 인공지능 영상분석 기반의 산업현장 안전 관리 시스템의 기본 구성을 나타낸 개요도이고, 도 2는 도 1에 도시된 본 발명의 실시예에 따른 시스템에서 엣지 컴퓨팅 장치부의 동작 개념을 좀 더 구체적으로 나타낸 도면이고, 도 3은 도 1에 도시된 인공지능 영상분석 기반의 산업현장 안전 관리 시스템의 세부 구성과 동작을 설명하기 위해 나타낸 블록도이고, 도 4는 본 발명의 실시예에 따른 작업자 안전장비 착용 유무 탐지 서비스 결과 예시를 나타낸 도면이고, 도 5는 본 발명의 실시예에 따른 작업자 이상행동 탐지 서비스결과 예시를 나타낸 도면이고, 도 6은 본 발명의 실시예에 따른 연기/불꽃 화재 탐지 서비스 결과 예시를 나타 낸 도면이고, 도 7은 본 발명의 실시예에 따른 딥러닝 모델의 추가 학습 방법을 설명하기 위해 나타낸 도면이며, 도 8은 본 발명의 실시예에 따른 딥러닝 모델 구축 방법의 개념을 설명하기 위해 나타낸 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 인공지능 영상분석 기반의 산업현장 안전 관리 시스템은 네트 워크 카메라, 엣지 컴퓨팅 장치부 및 통합 관제 서버부 중 적어도 하나를 포함할 수 있다. 상기 네트워크 카메라는, 산업현장에 각각 설치되어 다양한 객체(작업자)와 현장을 촬영하고, 촬영을 통해 생성된 영상데이터를 실시간 송출할 수 있다. 좀 더 구체적으로, 네트워크 카메라부는 영상데이터를 H.264 형식의 RTSP(Real-Time Streaming Protocol) 패킷으로 변환하여 엣지 컴퓨팅 장치부에 실시간 송출할 수 있다. 이러한 네트워크 카메라부는 인터넷 네트워크에 연결되어 있어 화상을 실시간으로 송출할 수 있으며, 다양한 종류의 IP(Internet Protocol) 카메라를 포함할 수 있다. 상기 엣지 컴퓨팅 장치부는, 네트워크 카메라부로부터 인터넷 네트워크를 통해 영상데이터를 수신하 고, 딥러닝 모델을 이용하여 수신된 영상데이터로부터 미리 정의된 객체 탐지 및 이벤트 검출을 수행하고, 탐지 및 검출 결과와 해당 영상데이터를 포함하는 데이터 패킷을 통합 관제 서버부로 실시간 송출할 수 있다. 여기서 엣지 컴퓨팅이란, 일반적으로 중앙 집중 서버가 모든 데이터를 처리하는 클라우드 컴퓨팅과 다르게 분산 된 소형 서버를 통해 실시간으로 처리하는 기술로, 인터넷에 연결된 다양한 기기들의 데이터 양이 폭증하면서 이를 처리하기 위해 사용되며, 방대한 데이터를 중앙 집중 서버가 아닌 분산된 소형 서버를 통해 실시간으로 처 리하는 기술이다. 즉, 모든 데이터를 클라우드로 보내서 분석하는 대신, 중요한 데이터를 실시간으로 처리하기 위한 기술이다. 이러한 엣지 컴퓨팅 장치부는 도 2에 도시된 바와 같이 디코딩 실행부, 객체 탐지 및 이벤트 검출부 , 먹서(Muxer) 및 RTSP(Real-Time Streaming Protocol) 서버부 중 적어도 하나를 포함할 수 있 다. 상기 디코딩 실행부는, 네트워크 카메라부로부터 실시간 수신되는 RTSP 패킷(비디오 패킷)에 대한 디 코딩(decoding)을 수행하여 이진 데이터인 RGB 이미지로 변환함으로써 해당 RTSP 패킷(비디오 패킷)에 대한 정 제 과정을 수행할 수 있다. RTSP 패킷(비디오 패킷)의 각 RGB 이미지 별로 시간 정보가 포함되어 있으며, 후술 하는 타임 시퀀스(Time-sequence)를 비교할 때 이용할 수 있다. 상기 객체 탐지 및 이벤트 검출부는, 디코딩 실행부를 통해 변환된 RGB 이미지를 제1 딥러닝 모델의 입력 값으로 입력 받아 미리 정의된 객체 탐지 및 이벤트 검출을 수행하고, 그 객체 탐지 및 이벤트 검출 결과 를 출력 값으로 출력할 수 있다. 좀 더 구체적으로 제1 딥러닝 모델은, RGB 이미지에 대하여 사람에 대한 객체를 검출하고, 검출된 사람을 대상 으로 ROI(Region Of Interest)를 설정하여 ROI(Region Of Interest) 내에 미리 정의된 안전장비의 착용 유무를 탐지하여 사람의 안전장비 미착용에 대한 객체 탐지 결과를 출력할 수 있다. 예를 들어, 작업자라는 사람 객체 를 검출하고, 검출된 작업자에 대하여 도 4에 도시된 바와 같이 ROI(연두색 박스)를 설정할 수 있으며, ROI 내 작업자의 머리 부분에 안전모의 착용 유무를 탐지할 수 있다. 이 밖에도 ROI 내 작업자의 얼굴 부분에 마스크의 착용 유무나 미리 정의된 다양한 안전장비들의 착용 여부를 탐지할 수 있다. 또한, 제1 딥러닝 모델은 RGB 이미지에 대하여 사람에 대하여 미리 정의된 이상행동 및 화재의 발생 유무를 판 별하고, 이상행동 및 화재 발생에 대한 이벤트 검출 결과를 출력할 수 있다. 예를 들어, 도 5에 도시된 바와 같 이 작업자의 쓰러짐과 구호행위 등과 관련하여 미리 정의된 이벤트를 검출할 수 있으며, 도 6에 도시된 바와 같 이 연기, 불꽃 등에 대한 객체를 검출하여 화재 발생 유무에 관한 이벤트를 검출하고 그 검출 결과를 출력할 수 있다. 상기 제1 딥러닝 모델은 자동 업데이트 기능을 구비할 수 있다. 일반적으로 인공지능 영상인식에 사용되는 딥러 닝 모델은 현장의 영상 수집 장치의 각도 및 피사 체까지의 거리, 날씨, 주변환경 등에 따라 정확도에 편차가 발생할 수 있는데, 모든 현장에서 영상인식률을 높이기 위해 각각 현장에 맞춤형 딥러닝 모델을 개발해야 하나 작업자 피로도 및 개발 비용이 상승하게 된다. 이에 따라, 제1 딥러닝 모델이 엣지 컴퓨팅 장치에 탑재되 어 도 7에 도시된 바와 같이 각각 설치 환경에 맞도록 자동 추가학습을 통한 미세조정(fine-tunning) 및 업데이 트 기능을 개발하여 적용할 수 있다. 상기 제1 딥러닝 모델의 제작 시, 도 8에 도시된 바와 같이 현장에서 수집된 영상데이터는 동영상 편집기를 이 용하여 이미지 데이터로 변환되며, 이 과정에서 'Python'을 이용한 동영상 편집기가 사용될 수 있다. 어노테이션 툴은 특정 이미지나 폴더내의 이미지들에서 원하는 객체를 선택하여 추후 딥러닝 모델을 생성하기 위한 보조 도구로서 활용되며, 영상 데이터는 이미지 데이터로 변환되고, 어노테이션 툴을 이용하여 작업자, 안전모, 마스 크 등 필요한 객체에 따라 라벨링 데이터가 제작될 수 있다. 상기 어노테이션 툴은, 도 9에 도시된 바와 같이, 이미지를 개별 혹은 폴더로 인식하여 화면에 표출하고 사용자 가 이 미지에서 헬멧, 마스크, 연기와 같은 객체 선택이 가능한 GUI로 구성될 수 있다. 여기서, 어노테이션 툴 의 작업 결과 선택한 객체의 라벨을 사용자가 입력하고 각 이미지 별 객체의 위치 데이터가 저장될 수 있으며, 어노테이션 결과는 'training set'과 'test set'으로 나누어 딥러닝 모델 개발 및 평가가 이루어질 수 있다. 동 영상편집, 어노테이션, 딥러닝 학습 일련의 과정은 이후 개발된 초기 딥러닝 모델 적용 후 현장에 따라 추가 학 습을 통해 미세조정(fine-tunning)을 거쳐야 개별 현장에서 신뢰성 있는 결과를 보일 수 있다. 현장 사용자가 상기한 과정을 수행하는 것은 불가능하며, 이 과정이 소프트웨어에서 자동으로 수행되어 업데이트 될 수 있도록 한다. 상기 먹서(Muxer)는, RGB 이미지와 상기 객체 탐지 및 이벤트 검출 결과 간의 타임 시퀀스를 비교하여 동 일한 시퀀스를 갖는 RGB 이미지와 객체 탐지 및 이벤트 검출 결과를 H.264 형식의 스트림으로 생성하되, 각 스 트림 내에 객체 탐지 및 이벤트 검출 결과를 RGB 이미지에 대한 메타데이터로 생성할 수 있다. 즉, 상술한 바와 같이 RGB 이미지와 객체 탐지 및 이벤트 검출 결과는 각각 시간 정보를 가질 수 있는데, 객체 탐지 및 이벤트 검출 결과는 RGB 이미지로부터 판단되기 때문에 객체 탐지 및 이벤트가 검출된 대상의 RGB 이미지와 동일한 시 간 정보를 갖게 된다. 이에, 객체 탐지 및 이벤트 검출 결과가 출력되면, 해당 결과를 도출하기 위해 사용된 RGB 이미지와 매칭 작업을 수행하기 위하여 시간 정보 즉 타임 시퀀스를 비교해 동일한 시퀀스를 갖는 RGB 이미 지와 객체 탐지 및 이벤트 검출 결과를 H.264 스트림으로 생성하며, 이때 스트림 내에서 객체 탐지 및 이벤트 검출 결과는 메타데이터로서 생성될 수 있다. 따라서, H.264 스트림은 서로 매칭된 RGB 이미지(RGB binary data)와 메타데이터(객체 탐지 및 이벤트 검출 결과)를 포함할 수 있다. 상기 RTSP(Real-Time Streaming Protocol) 서버부는, 먹서를 통해 생성된 H.264 스트림을 RTSP 패킷으로 변환하고, 변환된 RTSP 형식의 데이터 패킷을 통합 관제 서버부로 송출할 수 있다. 상기 통합 관제 서버부는, 엣지 컴퓨팅 실행부로부터 수신된 데이터 패킷에 대한 영상과 객체 탐지 및 이벤트 검출 결과를 모니터링하고 기록할 수 있다. 좀 더 구체적으로 통합 관제 서버부는, NVR(Network Video Recoding Server)와 VMS(Video Management system), RGB 영상 출력 장치 등을 포함하며, 엣지 컴퓨팅 장 치부로부터 사람의 안전장비 미 착용에 대한 객체 탐지 결과와, 사람의 이상행동 및 산업현장의 화재 발생 에 대한 이벤트 검출 결과 중 적어도 하나의 결과를 수신하는 경우, 해당 현장에 대하여 미리 등록된 관리자에 게 알림 또는 신고 조치를 취하거나, 해당 현장으로 안내 방송을 송출할 수 있다. 본 실시예에서 미리 등록된 관리자는 해당 산업현장을 안전 관리 업무를 담당하는 관리자나 소방 기관과 의료 기관 등을 의미하며, 해당 관 리자의 휴대통신단말로 알림 메시지, 알림 ARS 등을 송출할 수 있다. 또한, 작업자의 안전모, 안전마스크 등의 미 착용 또는 해당 현장의 화재 또는 침입자 발생 등의 이벤트 검출 시 해당 현장의 안내 방송 콘텐츠를 송출해 해당 현장에서 경고 안내 방송이 실시되도록 할 수 있다. 도 9는 본 발명의 실시예에 따른 자율주행 장치부가 추가된 인공지능 영상분석 기반의 산업현장 안전 관리 시스 템의 구성을 나타낸 개요도이고, 도 10은 본 발명의 실시예에 따른 안전장비 구호행동 검출부의 구성이 추가된 엣지 컴퓨팅 장치부의 구성을 나타낸 블록도이다. 상기 네트워크 카메라부는 산업현장을 촬영하여 생성한 영상데이터에 산업현장의 위치식별코드를 포함시켜 엣지 컴퓨팅 장치부로 송출할 수 있다. 예를 들어, 산업현장의 위치식별코드는 네트워크 카메라부의 IP주소일 수 있으며, 이와는 별도로 지역, 섹터, 실 등을 구분하기 위한 숫자와 영문을 혼합한 고유식별코드를 포함할 수 있다. 이러한 산업현장의 위치식별코드는 영상데이터에 추가되어 엣지 컴퓨팅 장치부로 전송될 수 있다. 상기 객체 탐지 및 이벤트 검출부는, 객체 탐지 검출 결과로서 안전장비의 미 착용이 탐지되면, 안전장비 의 미 착용이 탐지된 RGB 이미지와 해당 RGB 이미지의 위치식별코드 및 미 착용된 안전장비의 장비식별코드를 각각 별도로 출력할 수 있다. 또는, 객체 탐지 및 이벤트 검출부는 타임 시퀀스를 기준으로 스트림을 생성 할 때 해당 스트림에 위치식별코드와 장비식별코드를 추가할 수 있다. 즉, 객체 탐지 및 이벤트 검출부는 안전장비의 미 착용을 탐지한 RGB 이미지에 대한 위치정보와 어떠한 안전장비를 미 착용했는지에 대한 정보를 파악할 수 있으며, 스트림의 메타데이터로서 추가할 수도 있다.상기 엣지 컴퓨팅 장치부는, 객체 탐지 및 이벤트 검출부로부터 출력되는 RGB 이미지, 위치식별코드, 장비식별코드를 각각 수신하고, 수신된 해당 RGB 이미지를 미리 정의된 제2 딥러닝 모델의 입력 값으로 입력 받 아 미리 정의된 안전장비 구호행동 유무를 판별하여 안전장비 구호행동에 대한 이벤트를 검출하고, 안전장비 구 호행동에 대한 이벤트 검출 시 해당 위치식별코드 및 장비식별코드를 자율 주행 장치부로 출력하는 안전장 비 구호행동 검출부를 더 포함할 수 있다. 상기 안전장비 구호행동 검출부는 어느 위치의 산업현장에 어느 안전장비를 착용하지 않은 자가 해당 안전 장비를 원하는지를 영상 분석을 통해 추가적으로 파악할 수 있으며, 이에 따라 해당 산업현장에 필요한 안전장 비의 운반명령신호를 후술하는 자율주행 장치부로 출력할 수 있다. 이때, 안전장비 구호행동 검출부 는 위치식별코드를 기반으로 해당 현장에 배치된 자율주행 장치부로 안전장비의 운반명령신호를 전송할 수 있다. 상기 자율주행 장치부는, 안전장비 구호행동 검출부로부터 수신되는 위치식별코드 및 장비식별코드를 기반으로 해당 안전장비를 자율주행동작을 통해 해당 현장으로 운반할 수 있다. 이에, 해당 현장에서 특정 안전 장비가 없는 작업자가 자신이 안전장비가 없음을 관리자 또는 안내 방송을 통해 시스템이 알고 있음을 인 지하게 되면, 네트워크 카메라부 미리 약속된 행동이나 제스처 등을 행하여 안전장비의 운반 즉 안전장비 를 가져다 주기를 원한다는 신호를 주고 이를 안전장비 구호행동 검출부에서 인식하여 자율주행 장치부 를 통해 해당 안전장비를 안전하게 가져다 수 있다. 이는, 작업자의 특정 행동에 대하여 미리 약속된 명령 신호를 인지하는 것으로, 안전장비의 운반명령뿐만 아니라, 상황이 좋지 않은 작업자에 대한 구조 신호 인식을 처리할 수 있다. 상기 제2 딥러닝 모델은 자동 업데이트 기능을 구비할 수 있다. 일반적으로 인공지능 영상인식에 사용되는 딥러 닝 모델은 현장의 영상 수집 장치의 각도 및 피사 체까지의 거리, 날씨, 주변환경 등에 따라 정확도에 편차가 발생할 수 있는데, 모든 현장에서 영상인식률을 높이기 위해 각각 현장에 맞춤형 딥러닝 모델을 개발해야 하나 작업자 피로도 및 개발 비용이 상승하게 된다. 이에 따라, 제2 딥러닝 모델이 엣지 컴퓨팅 장치에 탑재되 어 도 7에 도시된 바와 같이 각각 설치 환경에 맞도록 자동 추가학습을 통한 미세조정(fine-tunning) 및 업데이 트 기능을 개발하여 적용할 수 있다. 상기 제2 딥러닝 모델의 제작 시, 도 8에 도시된 바와 같이 현장에서 수집된 영상데이터는 동영상 편집기를 이 용하여 이미지 데이터로 변환되며, 이 과정에서 'Python'을 이용한 동영상 편집기가 사용될 수 있다. 어노테이 션 툴은 특정 이미지나 폴더내의 이미지들에서 원하는 객체를 선택하여 추후 딥러닝 모델을 생성하기 위한 보조 도구로서 활용되며, 영상 데이터는 이미지 데이터로 변환되고, 어노테이션 툴을 이용하여 작업자, 안전모, 마스 크 등 필요한 객체에 따라 라벨링 데이터가 제작될 수 있다. 상기 어노테이션 툴은, 도 9에 도시된 바와 같이, 이미지를 개별 혹은 폴더로 인식하여 화면에 표출하고 사용자 가 이 미지에서 헬멧, 마스크, 연기와 같은 객체 선택이 가능한 GUI로 구성될 수 있다. 여기서, 어노테이션 툴 의 작업 결과 선택한 객체의 라벨을 사용자가 입력하고 각 이미지 별 객체의 위치 데이터가 저장될 수 있으며, 어노테이션 결과는 'training set'과 'test set'으로 나누어 딥러닝 모델 개발 및 평가가 이루어질 수 있다. 동 영상편집, 어노테이션, 딥러닝 학습 일련의 과정은 이후 개발된 초기 딥러닝 모델 적용 후 현장에 따라 추가 학 습을 통해 미세조정(fine-tunning)을 거쳐야 개별 현장에서 신뢰성 있는 결과를 보일 수 있다. 현장 사용자가 상기한 과정을 수행하는 것은 불가능하며, 이 과정이 소프트웨어에서 자동으로 수행되어 업데이트 될 수 있도록 한다. 이상에서 설명한 것은 본 발명에 의한 인공지능 영상분석 기반의 산업현장 안전 관리 시스템을 실시하기 위한 하나의 실시예에 불과한 것으로서, 본 발명은 상기 실시예에 한정되지 않고, 이하의 특허청구범위에서 청구하는 바와 같이 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변경 실시가 가능한 범위까지 본 발명의 기술적 정신이 있다고 할 것이다."}
{"patent_id": "10-2022-0058014", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 인공지능 영상분석 기반의 산업현장 안전 관리 시스템의 기본 구성을 나타낸 개요도이다. 도 2는 도 1에 도시된 본 발명의 실시예에 따른 시스템에서 엣지 컴퓨팅 장치부의 동작 개념을 좀 더 구체적으 로 나타낸 도면이다. 도 3은 도 1에 도시된 인공지능 영상분석 기반의 산업현장 안전 관리 시스템의 세부 구성과 동작을 설명하기 위 해 나타낸 블록도이다. 도 4는 본 발명의 실시예에 따른 작업자 안전장비 착용 유무 탐지 서비스 결과 예시를 나타낸 도면이다. 도 5는 본 발명의 실시예에 따른 작업자 이상행동 탐지 서비스 결과 예시를 나타낸 도면이다. 도 6은 본 발명의 실시예에 따른 연기/불꽃 화재 탐지 서비스 결과 예시를 나타낸 도면이다. 도 7은 본 발명의 실시예에 따른 딥러닝 모델의 추가 학습 방법을 설명하기 위해 나타낸 도면이다. 도 8은 본 발명의 실시예에 따른 딥러닝 모델 구축 방법의 개념을 설명하기 위해 나타낸 도면이다. 도 9는 본 발명의 실시예에 따른 자율주행 장치부가 추가된 인공지능 영상분석 기반의 산업현장 안전 관리 시스 템의 구성을 나타낸 개요도이다. 도 10은 본 발명의 실시예에 따른 안전장비 구호행동 검출부의 구성이 추가된 엣지 컴퓨팅 장치부의 구성을 나 타낸 블록도이다."}
