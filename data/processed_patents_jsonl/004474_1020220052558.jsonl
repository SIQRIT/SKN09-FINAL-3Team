{"patent_id": "10-2022-0052558", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0152961", "출원번호": "10-2022-0052558", "발명의 명칭": "무인점포에 비치된 상품의 도난을 방지하는 전자장치 및 이의 동작방법", "출원인": "한국정보통신주식회사", "발명자": "안종훈"}}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "무인점포에 비치된 상품의 도난을 방지하는 전자장치에 있어서,카메라부;상기 무인점포에 비치된 상품을 구매하는 구매자를 촬영한 영상을 저장하는 저장부; 및구매자가 상기 무인점포로 입장하는 경우, 상기 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성하도록 상기 카메라부를 제어하고, 상기 저장된 영상에 기초하여 상기 구매자의 외형에 대한 딥러닝을 수행하고, 상기 수행된 딥러닝 결과에 기초하여 상기 구매자를 특정하여 상기 얼굴 이미지와 매칭하고,상기 카메라부에 의해 촬영되는 영상에 기초하여, 상기 구매자에 의해 상기 상품이 피킹(picking)되는지 여부를판단하고,상기 상품의 ID(identification) 및 상기 구매자를 매칭하고,상기 구매자가 상기 상품을 결제하지 않은 상태에서 상기 무인점포의 결제구역을 이탈한 시점으로부터 기정의된시간이 도과한 경우, 상기 구매자에 대한 상기 얼굴 이미지, 상기 상품의 ID, 상기 구매자가 상기 무인점포의결제구역에서 이탈한 시간에 대한 정보를 점주의 사용자 단말로 전송하는, 프로세서;를 포함하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 카메라부에 의해 촬영된 영상에 기초하여, 상기 상품이 진열된 선반으로 진입하는 상기 구매자의 손의 방향을 판단하고,상기 판단된 손의 방향에 기초하여, 상기 구매자에 의해 상기 상품이 피킹되는지 여부를 판단하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 손의 방향은,상기 구매자의 상기 손의 이동 시작 점(start point) 및 상기 구매자의 상기 손의 이동 정지 점(stop point)을연결하는 벡터에 의해 결정되는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 프로세서는,상기 상품이 진열된 선반의 무게가 상기 상품의 무게만큼 변경되고, 상기 구매자와 상기 선반의 거리가 기정의된 거리 이내인 경우, 상기 구매자가 상기 상품을 피킹(picking)한 것으로 판단하는, 전자장치.공개특허 10-2023-0152961-3-청구항 5 제1항에 있어서,상기 프로세서는,상기 구매자가 복수의 상품을 피킹한 경우, 상기 복수의 상품의 ID 각각을 상기 구매자와 매칭하고,상기 구매자가 결제한 상품의 개수가 상기 복수의 상품의 개수보다 작은 경우, 상기 복수의 상품의 ID 및 상기구매자가 결제한 상품의 ID를 대조하여 누락된 상품을 특정하고, 상기 누락된 상품의 추가 결제를 요청하는GUI(graphic user interface)를 생성하여 디스플레이하고, 상기 누락된 상품의 추가 결제를 요청하는 음성 안내를 생성하여 출력하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 프로세서는,상기 상품의 미 결제 상태에서 상기 구매자가 상기 무인점포의 결제구역에서 이탈하는 경우, 출입문의 잠금을수행하고, 상기 출입문의 잠금 실행을 나타내는 노티(notification)를 상기 점주의 사용자 단말로 전송하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 프로세서는,상기 선반에 접근하는 상기 구매자의 손을 적어도 하나의 방향에서 촬영하도록 상기 카메라부를 제어하여 적어도 하나의 손 이미지를 생성하고, 상기 적어도 하나의 손 이미지를 저장하도록 상기 저장부를 제어하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 상기 적어도 하나의 손 이미지 중 적어도 하나의손 바닥 이미지를 획득하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프로세서는,상기 구매자가 피킹한 상품을 정상 결제한 경우, 상기 저장된 적어도 하나의 손바닥 이미지를 삭제하고,상기 구매자가 피킹한 상품을 미 결제한 경우, 상기 저장된 적어도 하나의 손바닥 이미지에서 지문 이미지를 획득하여 상기 구매자와 매칭하여 저장하도록 상기 저장부를 제어하는, 전자장치.공개특허 10-2023-0152961-4-청구항 10 제9항에 있어서,상기 프로세서는,상기 사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 상기 적어도 하나의 손바닥 이미지를 왼손 손바닥 이미지 및 오른손 손바닥 이미지 중 하나로 결정하고,상기 지문 이미지가 왼손 또는 오른손에 대응되는지를 나타내는 지시자를 생성하여 저장하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는,상기 구매자가 피킹한 상품을 미 결제한 경우, 상기 지문 이미지, 상기 지문 이미지가 왼손 또는 오른손에 대응되는지를 나타내는 지시자, 상기 구매자에 대한 상기 얼굴 이미지, 상기 상품의 ID, 미 결제 피해액 및 상기 구매자가 상기 무인점포의 결제구역에서 이탈한 시간에 대한 정보를 포함하는 미 결제 사건 프로파일을 생성하여외부 서버로 전송하는, 전자장치."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "무인점포에 비치된 상품의 도난을 방지하는 전자장치의 동작방법에 있어서,상기 무인점포에 비치된 상품을 구매하는 구매자를 촬영한 영상을 저장하는 과정;구매자가 상기 무인점포로 입장하는 경우, 상기 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성하는 과정; 상기 저장된 영상에 기초하여 상기 구매자의 외형에 대한 딥러닝을 수행하는 과정; 상기 수행된 딥러닝 결과에 기초하여 상기 구매자를 특정하여 상기 얼굴 이미지와 매칭하는 과정;카메라부에 의해 촬영되는 영상에 기초하여, 상기 구매자에 의해 상기 상품이 피킹(picking)되는지 여부를 판단하는 과정;상기 상품의 ID(identification) 및 상기 구매자를 매칭하는 과정; 및상기 구매자가 상기 상품을 결제하지 않은 상태에서 상기 무인점포의 결제구역을 이탈한 시점으로부터 기정의된시간이 도과한 경우, 상기 구매자에 대한 상기 얼굴 이미지, 상기 상품의 ID, 상기 구매자가 상기 무인점포의결제구역에서 이탈한 시간에 대한 정보를 점주의 사용자 단말로 전송하는 과정;을 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 상품이 피킹되는지 여부를 판단하는 과정은,상기 카메라부에 의해 촬영된 영상에 기초하여, 상기 상품이 진열된 선반으로 진입하는 상기 구매자의 손의 방향을 판단하는 과정; 및상기 판단된 손의 방향에 기초하여, 상기 구매자에 의해 상기 상품이 피킹되는지 여부를 판단하는 과정;을 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2023-0152961-5-제13항에 있어서,상기 손의 방향은,상기 구매자의 상기 손의 이동 시작 점(start point) 및 상기 구매자의 상기 손의 이동 정지 점(stop point)을연결하는 벡터에 의해 결정되는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 상품이 피킹되는지 여부를 판단하는 과정은,상기 상품이 진열된 선반의 무게가 상기 상품의 무게만큼 변경되고, 상기 구매자와 상기 선반의 거리가 기정의된 거리 이내인 경우, 상기 구매자가 상기 상품을 피킹(picking)한 것으로 판단하는 과정;을 더 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 구매자가 복수의 상품을 피킹한 경우, 상기 복수의 상품의 ID 각각을 상기 구매자와 매칭하는 과정; 및상기 구매자가 결제한 상품의 개수가 상기 복수의 상품의 개수보다 작은 경우, 상기 복수의 상품의 ID 및 상기구매자가 결제한 상품의 ID를 대조하여 누락된 상품을 특정하고, 상기 누락된 상품의 추가 결제를 요청하는GUI(graphic user interface)를 생성하여 디스플레이하고, 상기 누락된 상품의 추가 결제를 요청하는 음성 안내를 생성하여 출력하는 과정;을 더 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 상품의 미 결제 상태에서 상기 구매자가 상기 무인점포의 결제구역에서 이탈하는 경우, 출입문의 잠금을수행하고, 상기 출입문의 잠금 실행을 나타내는 노티(notification)를 상기 점주의 사용자 단말로 전송하는 과정;을 더 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 선반에 접근하는 상기 구매자의 손을 적어도 하나의 방향에서 촬영하도록 상기 카메라부를 제어하여 적어도 하나의 손 이미지를 생성하고, 상기 적어도 하나의 손 이미지를 저장하는 과정;을 더 포함하는, 전자장치의동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 상기 적어도 하나의 손 이미지 중 적어도 하나의손 바닥 이미지를 획득하는 과정;을 더 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2023-0152961-6-제19항에 있어서,상기 구매자가 피킹한 상품을 정상 결제한 경우, 상기 저장된 적어도 하나의 손바닥 이미지를 삭제하는 과정;및상기 구매자가 피킹한 상품을 미 결제한 경우, 상기 저장된 적어도 하나의 손바닥 이미지에서 지문 이미지를 획득하여 상기 구매자와 매칭하여 저장하는 과정;을 더 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 상기 적어도 하나의 손바닥 이미지를 왼손 손바닥 이미지 및 오른손 손바닥 이미지 중 하나로 결정하는 과정; 및상기 지문 이미지가 왼손 또는 오른손에 대응되는지를 나타내는 지시자를 생성하여 저장하는 과정;을 더 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 구매자가 피킹한 상품을 미 결제한 경우, 상기 지문 이미지, 상기 지문 이미지가 왼손 또는 오른손에 대응되는지를 나타내는 지시자, 상기 구매자에 대한 상기 얼굴 이미지, 상기 상품의 ID, 미 결제 피해액 및 상기 구매자가 상기 무인점포의 결제구역에서 이탈한 시간에 대한 정보를 포함하는 미 결제 사건 프로파일을 생성하여외부 서버로 전송하는 과정;을 더 포함하는, 전자장치의 동작방법."}
{"patent_id": "10-2022-0052558", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "무인점포에 비치된 상품의 도난을 방지하는 전자장치가 개시된다. 본 발명의 일 실시 예에 따른 무인점포에 비치 된 상품의 도난을 방지하는 전자장치는 카메라부, 상기 무인점포에 비치된 상품을 구매하는 구매자를 촬영한 영 상을 저장하는 저장부 및 구매자가 상기 무인점포로 입장하는 경우, 상기 구매자의 얼굴을 촬영하여 얼굴 이미지 (뒷면에 계속)"}
{"patent_id": "10-2022-0052558", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 무인점포에 비치된 상품의 도난을 방지하는 전자장치 및 이의 동작방법에 대한 것으로, 보다 상세하 게는 무인점포 내에서의 도난을 사전에 방지하고, 도난 발생 시 적발이 가능한 전자장치 및 이의 동작방법에 대 한 것이다."}
{"patent_id": "10-2022-0052558", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 빅데이터, 인공지능, 사물인터넷 등의 기술이 발달됨에 따라 실생활에 제공되는 서비스에 대한 전반적인 개선이 이루어지고 있다. 특히, 빅데이터에 기반하여 인간의 행위를 딥러닝함으로써 실 생활에 편의를 제공하고 사업 비용을 절감하는 기술이 발전하고 있다. 이러한 기술 발달은 계산대에 줄을 서고, 지갑에서 카드나 현금을 꺼내 결제를 진행하는 기존의 구매 및 결제 프로세스를 개선하고자 하는 욕구를 반영하여 오프라인 쇼핑 분야에 혁신적인 바람을 불어넣고 있다. 미국의 전자상거래 기업 아마존(Amazon)은 무인 결제시스템을 결합한 '아마존고(Amazon Go)' 서비스를 확대하고 있다. 아마존고는 자신의 개인정보에 대응되는 바코드를 찍고 점포에 입장하여 물건을 집어 매장을 나서기만 하 면 스마트폰의 어플리케이션과 연동되어 결제가 완료되는 시스템을 선보인 바 있다. 본 발명의 배경이 되는 기술의 일 예로, 대한민국 공개특허공보 제10-2021-0075833호(2021.06.23.)는 무인상점 에 출입을 원하는 사용자의 생체정보를 획득하는 사용자 인식 모듈, 사용자가 제공하는 카드에 저장된 생체정보 를 추출하는 카드 인식 모듈 및 사용자 인식 모듈에서 획득한 생체정보와 카드 인식 모듈에서 추출한 생체정보 를 비교하여 사용자를 인증하는 사용자 인증 모듈을 포함하는 무인상점에서의 사용자 인증 시스템을 개시한다."}
{"patent_id": "10-2022-0052558", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 바와 같이, 최근 무인점포가 활성화되고 있으나 무인점포 기술이 해결하지 못한 부분들이 있다. 예를 들 어, 무인점포 관련하여 담배, 주류와 같이 성인인증이 필요한 상품에 대한 성인인증 기술이나, 도난 방지 기술 에 대하여는 아직 보완해야 할 부분이 많은 실정이다. 본 발명은 상술한 문제점을 해결하기 위해 안출된 것으로, 본 발명은 무인점포 내에서 구매자의 행동을 추적함 으로써 상품의 도난을 방지하고, 미 결제 사건의 프로파일링을 통해서 도난 발생 시 신속하게 대응하는 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0052558", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 다양한 실시 예에 따른 무인점포에 비치된 상품의 도난을 방지하는 전자장치는 카메라부, 상기 무인 점포에 비치된 상품을 구매하는 구매자를 촬영한 영상을 저장하는 저장부 및 구매자가 상기 무인점포로 입장하 는 경우, 상기 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성하도록 상기 카메라부를 제어하고, 상기 저장된 영 상에 기초하여 상기 구매자의 외형에 대한 딥러닝을 수행하고, 상기 수행된 딥러닝 결과에 기초하여 상기 구매 자를 특정하여 상기 얼굴 이미지와 매칭하고, 상기 카메라부에 의해 촬영되는 영상에 기초하여, 상기 구매자에 의해 상기 상품이 피킹(picking)되는지 여부를 판단하고, 상기 상품의 ID(identification) 및 상기 구매자를 매 칭하고, 상기 구매자가 상기 상품을 결제하지 않은 상태에서 상기 무인점포의 결제구역을 이탈한 시점으로부터 기정의된 시간이 도과한 경우, 상기 구매자에 대한 상기 얼굴 이미지, 상기 상품의 ID, 상기 구매자가 상기 무 인점포의 결제구역에서 이탈한 시간에 대한 정보를 점주의 사용자 단말로 전송하는 프로세서를 포함할 수 있다. 또한, 본 발명의 다양한 실시 예에 따른 무인점포에 비치된 상품의 도난을 방지하는 전자장치의 동작방법은 상 기 무인점포에 비치된 상품을 구매하는 구매자를 촬영한 영상을 저장하는 과정, 구매자가 상기 무인점포로 입장 하는 경우, 상기 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성하는 과정, 상기 저장된 영상에 기초하여 상기 구매자의 외형에 대한 딥러닝을 수행하는 과정, 상기 수행된 딥러닝 결과에 기초하여 상기 구매자를 특정하여 상기 얼굴 이미지와 매칭하는 과정, 카메라부에 의해 촬영되는 영상에 기초하여, 상기 구매자에 의해 상기 상품 이 피킹되는지 여부를 판단하는 과정, 상기 상품의 ID 및 상기 구매자를 매칭하는 과정 및 상기 구매자가 상기 상품을 결제하지 않은 상태에서 상기 무인점포의 결제구역을 이탈한 시점으로부터 기정의된 시간이 도과한 경우, 상기 구매자에 대한 상기 얼굴 이미지, 상기 상품의 ID, 상기 구매자가 상기 무인점포의 결제구역에서 이 탈한 시간에 대한 정보를 점주의 사용자 단말로 전송하는 과정을 포함할 수 있다."}
{"patent_id": "10-2022-0052558", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시 예에 따르면, 본 발명은 무인점포 내에서 구매자의 행동을 추적함으로써 상품의 도난을 방지하고, 미 결제 사건의 프로파일링을 통해서 도난 발생 시 신속하게 대응하는 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0052558", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명의 바람직한 실시 예에 대한 동작원리를 상세히 설명한다. 또한, 발명에 대한 실시 예를 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 하기에서 사용되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로써, 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므 로 사용된 용어들의 정의는 본 명세서 전반에 걸친 내용 및 이에 상응한 기능을 토대로 해석되어야 할 것이다.도 1은 본 발명의 일 실시 예에 따른 무인점포 도난 방지 시스템에 대한 도면이다. 무인점포 도난 방지 시스템은 점주 사용자 단말, 무인점포 서버 및 외부 서버를 포함할 수 있다. 여기서, 점주 사용자 단말, 무인점포 서버 및 외부 서버는 PC, 태블릿 PC, 스마트폰, 서버 등 다양한 기기로 구현될 수 있다. 점주 사용자 단말은 무인점포의 점주가 사용하는 사용자 단말이다. 일반적으로, 점주 사용자 단말은 무인점포 외부에서 무인점포의 관리, 재고관리, 비용관리, 점포상황 모니터링 등을 수행할 수 있다. 일 예로, 점주 사용자 단말은 후술할 인점포 서버와의 통신을 통해 무인점포의 실시간 상황을 전달받 을 수 있다. 점주 사용자 단말은 무인점포에서 도난(또는 절도) 발생 시 관련 정보를 통지받을 수 있다. 점주 사용자 단말은 점주의 입력에 의해 무인점포 서버에 대한 제어 신호를 송신하여 도난 사건(또는 미 결제 사건)의 처리 과정을 진행할 수 있다. 무인점포 서버는 무인점포 도난 방지 시스템을 전반적으로 제어할 수 있다. 여기서, 무인점포 서버 는 전자장치, 전자기기, 서버, 사용자 단말 등 다양한 용어로 정의될 수 있다. 무인점포 서버는 구매자가 무인점포에 입장하는 순간부터 퇴장하는 순간까지 구매자를 촬영할 수 있다. 무 인점포 서버는 무인점포에 비치된 상품을 구매하는 구매자를 촬영한 영상을 저장하거나 저장된 영상을 삭 제할 수 있다. 일 예로, 무인점포 서버는 구매자가 무인점포로 입장하는 경우, 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성할 수 있다. 이 경우, 무인점포 서버는 저장된 영상에 기초하여 구매자의 외형에 대한 딥러닝을 수행 할 수 있다. 또한, 무인점포 서버는 딥러닝 결과에 기초하여 구매자를 특정하여 얼굴 이미지와 매칭할 수 있다. 머신 러닝의 일종인 딥러닝(deep learning) 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학습하는 과정을 포함할 수 있다. 딥러닝은 단계를 높여가면서 데이터들로부터 핵심적인 데이터를 추출하는 머신 러닝 알 고리즘의 집합을 나타낼 수 있다. 딥러닝 구조는 인공신경망(ANN)을 포함할 수 있으며, 예를 들어 딥러닝 구조는 CNN(convolutional neural network), RNN(recurrent neural network), DBN(deep belief network) 등 심층신경망(DNN)으로 구성될 수 있다. 본 실시 예에 따른 딥러닝 구조는 공지된 다양한 구조를 이용할 수 있다. 예를 들어, 본 발명에 따른 딥러닝 구 조는 CNN, RNN, DBN 등을 포함할 수 있다. RNN은, 자연어 처리 등에 많이 이용되고 있으며, 시간의 흐름에 따라 변하는 시계열 데이터(time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아 올려 인공신경망 구조를 구성할 수 있다. DBN은 딥러닝 기법인 RBM(restricted boltzman machine)을 다층으로 쌓아 구성되는 딥 러닝 구조를 포함할 수 있다. RBM 학습을 반복하여, 일정 수의 레이어가 되면 해당 개수의 레이어를 가지는 DBN 을 구성할 수 있다. CNN은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출되는 다음 뇌 속에서 복잡한 계산을 거쳐 그 결 과를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모사한 모델을 포함할 수 있다. 한편, 인공신경망의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight)를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공신경망은 학습에 의해 웨이 트(weight) 값을 지속적으로 업데이트시킬 수 있다. 또한, 인공신경망의 학습에는 역전파(back propagation) 등 의 방법이 사용될 수 있다. 또한, 무인점포 서버는 상품이 진열된 선반의 무게가 상품의 무게만큼 변경되고, 구매자와 선반의 거리가 기정의된 거리 이내인 경우, 구매자가 상기 상품을 피킹(picking)한 것으로 판단하고, 상품의 ID(identification) 및 구매자를 매칭할 수 있다. 또한, 무인점포 서버는 카메라부에 의해 촬영되는 영상에 기초하여, 구매자에 의해 상품이 피킹 (picking)되는지 여부를 판단할 수 있다. 무인점포 서버는 구매자가 상품을 결제하지 않은 상태에서 무인점포의 결제구역을 이탈한 시점으로부터 기 정의된 시간이 도과한 경우, 구매자를 피킹한 상품에 대한 미 결제자로 결정할 수 있다. 이 경우, 무인점포 서 버는 구매자에 대한 얼굴 이미지, 상품의 ID, 구매자가 무인점포의 결제구역에서 이탈한 시간에 대한 정보를 점주의 사용자 단말로 전송할 수 있다. 무인점포 서버는 점주의 사용자 단말로부터 미 결제 사건 발생 알림 요청을 수신하면, 구매자에 대한 얼굴 이미지를 디스플레이하여 무인점포에서 미 결제 사건이 발생한 사실을 공지할 수 있다. 외부 서버는 일 예로, 경찰청 서버일 수 있다. 무인점포 서버는 도난이 발생한 것으로 결정한 경우, 미 결제 사건범의 프로파일을 생성하고 생성된 프로파일을 외부 서버로 전송할 수 있다. 이 경우, 무인점 포 서버는 미 결제가 발생한 사실, 미 결제가 발생한 무인점포의 위치 정보 등을 프로파일 정보와 함께 외 부 서버로 전송하여 경찰의 조치를 구할 수 있다. 상술한 본 발명의 일 실시 예에 따르면, 무인점포 내에서 구매자의 행동을 추적함으로써 상품의 도난을 방지하 고, 구매자의 프로파일링을 통해서 도난 발생 시 신속하게 대응하는 방법을 제공할 수 있다. 일반적으로, 본원에서 개시되는 디바이스, 시스템, 및 방법은, 예를 들면, 범용 컴퓨팅 시스템, 서버-클라이언 트 컴퓨팅 시스템, 소비자-상인 컴퓨팅 시스템, 메인프레임 컴퓨팅 시스템, 클라우드 컴퓨팅 인프라 (infrastructure), 전화 컴퓨팅 시스템, 랩탑 컴퓨터, 데스크탑 컴퓨터, 스마트폰, 셀룰러 폰, 개인 휴대 정보 단말(personal digital assistant; PDA), 태블릿 컴퓨터, 및 다른 모바일 디바이스를 포함하는 다수의 상이한 디바이스 및 컴퓨터 시스템을 포함할 수 있고, 그 다수의 상이한 디바이스 및 컴퓨터 시스템 내에서 구현될 수 도 있다. 디바이스 및 컴퓨팅 시스템은 하나 이상의 데이터베이스와 다른 저장 장치, 서버, 및 추가 컴포넌트, 예를 들면, 프로세서, 모뎀, 단말 및 디스플레이, 컴퓨터 판독가능 매체, 알고리즘, 모듈 및 애플리케이션, 및 다른 컴퓨터 관련 컴포넌트를 구비할 수도 있다. 디바이스 및 컴퓨터 시스템 및/또는 컴퓨팅 인프라는 본원에서 개시되는 바와 같은 시스템 및 방법의 기능 및 프로세스를 수행하도록 구성되고, 프로그래밍되고, 적응된다. 도 2는 본 발명의 일 실시 예에 따른 무인점포 서버의 블록도이다. 도 2를 참조하면, 무인점포 서버는 카메라부, 저장부 및 프로세서를 포함할 수 있다. 카메라부는 적어도 하나의 카메라를 포함할 수 있다. 여기서, 카메라부는 무인점포의 입구, 무인점포 의 천장, 선반의 일 부분 등에 배치될 수 있다. 일 예로, 카메라부는 선반의 일 부분에 배치되어 선반에 수납(진열, 비치)되거나 다른 선반에 수납된 적어 도 하나의 상품을 촬영할 수 있다. 또한, 카메라부는 선반의 일 부분에 배치되어 선반에 수납된 상품을 피 킹(picking)하기 위해 진입하는 오브젝트 예를 들어, 구매자의 신체 중 일부, 또는 선반의 상 측, 하 측, 좌우 측에 배치된 다른 선반에 진입하는 오브젝트 예를 들어, 구매자의 신체 중 일부를 촬영할 수 있다. 상기 구매자 의 신체 중 일부는 구매자의 손일 수 있다. 일 예로, 카메라부는 점포 내 공간을 촬영할 수 있다. 예를 들어, 점포 내 공간은 복수의 공간으로 분할될 수 있는데, 카메라부에 포함되는 복수의 카메라는 상술한 복수의 공간 각각을 커버하도록 배치될 수 있다. 이 경우, 복수의 카메라는 상술한 복수의 공간 각각을 실시간으로 촬영할 수 있다. 이 경우, 복수의 카메라는 구매자를 트래킹하여 구매자의 외형을 촬영할 수 있다. 저장부는 휘발성 또는 비휘발성 기록 매체를 포함할 수 있다. 저장부는 하나 이상의 프로세서와 연결되는 것으로, 프로세서에 의해 실행될 때, 프로세서로 하 여금 무인점포 서버를 제어하도록 야기하는(cause) 코드들을 저장할 수 있다. 여기서, 저장부는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage medi a)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 이러한 저장부는 내장 메모리 및/ 또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD. CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, 또는 메모 리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 저장부는 다양한 데이터 또는 정보를 저장할 수 있다. 일 예로, 저장부는 카메라부에 의해 촬영 되는 실시간 이미지를 저장할 수 있다. 또한, 저장부는 프로세서에 의해 생성되는 사용자의 프로파일 을 저장할 수 있다. 또한, 프로세서에서 수행되는 판단, 결정 또는 연산 결과를 저장할 수 있다. 프로세서는 무인점포 서버를 전반적으로 제어할 수 있다. 특히, 프로세서는 무인점포에 비치된 상품의 도난을 방지하고, 도난 발생 시 조치를 취하는 동작을 수행할 수 있다.구체적으로, 프로세서는 무인점포에 비치된 상품을 구매하는 구매자를 촬영하도록 카메라부를 제어하 고, 촬영된 영상을 저장하도록 저장부를 제어할 수 있다. 또한, 프로세서는 구매자가 무인점포로 입장하는 경우, 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성하도 록 카메라부를 제어할 수 있다. 프로세서는 구매자의 얼굴 이미지를 구매자의 프로파일 정보로서 저 장부에 저장할 수 있다. 또한, 프로세서는 저장부에 기저장된 영상 또는 카메라부에 의해 촬영된 영상에 기초하여 상품 을 구매한 구매자를 특정할 수 있다. 일 예로, 프로세서는 자세 추정(pose estimation) 알고리즘을 이용한 딥러닝(deep learning)을 통하여 구 매자를 특정할 수 있다. 예를 들어, 도 3을 참조하면, 프로세서는 구매자의 영상을 딥러닝하여 이동하면서 다양한 동작을 취하는 구매자를 동일한 구매자로 특정할 수 있다. 또한, 프로세서는 스켈레톤(skeleton) 추출 알고리즘을 통해 구매자의 신체의 움직임(이동) 및 움직임의 방향을 추출할 수 있다. 또한, 프로세서는 컴퓨터 비전(vision) 기술 예를 들어, 옵티컬 플로우(optical flow)를 이용하여 사람의 신체의 움직임을 추출할 수 있다. 여기서, 프로세서는 수행된 딥러닝 결과에 기초하여 구매자를 특정하여 기저장된 얼굴 이미지를 매칭할 수 있다. 여기서, 기저장된 얼굴 이미지는 구매자의 얼굴을 포함하고, 배경화면의 적어도 일부를 삭제한 이미지일 수 있다. 한편, 프로세서는 구매자가 상품을 구매하였는지 여부를 판단할 수 있다. 일 예로, 상술한 선반은 무게 센서부를 포함할 수 있다. 무게 센서부는 상품의 무게 또는 선반의 무게 변화를 센싱할 수 있다. 무게 센서부는 상품이 선반에 추가되거나 이탈되는 경우 무게 변화를 센싱하고, 센싱 결과를 프로세서로 전송할 수 있다. 여기서, 프로세서는 상품이 진열된 선반의 무게가 상품의 무게만큼 변경 되고, 구매자와 상기 선반의 거리가 기정의된 거리 이내인 경우, 구매자가 상기 상품을 피킹(picking)한 것으로 판단할 수 있다. 일 예로, 도 4를 참조하면, 카메라부가 선반의 상측에 선반에 수납된 상품의 상단을 촬영한다고 가정한다. 프로세서는 선반에 진입하는 손의 여러가지 방향(A, B, C)을 판단할 수 있다. 여기서, 프로세서는 판단된 손의 방향에 기초하여, 구매자에 의해 상품이 피킹되는지 여부를 판단할 수 있 다. 여기서, 손의 방향은 구매자의 손의 이동 시작 점(start point) 및 구매자의 상기 손의 이동 정지 점(stop point)을 연결하는 벡터에 의해 결정될 수 있다. 구체적으로, 프로세서는 손의 이동 시작 점(start point) 및 손의 이동 정지 점(stop point)를 판단하고, 상기 손의 이동 시작 점 및 손의 이동 정지 점을 연결하는 제1 벡터를 생성할 수 있다. 또한, 프로세서는 피킹된 상품의 위치와 무인점포 내에 존재하는 적어도 하나의 구매자의 위치 간의 제2 벡터를 생성한다. 프로세 서는 상기 제1 벡터의 방향 및 상기 제2 벡터의 방향의 일치 여부에 따라 상기 적어도 하나의 구매자가 상 기 상품을 피킹하였는지 여부를 결정할 수 있다. 예를 들어, 프로세서는 상기 제1 벡터의 방향 및 상기 제 2 벡터의 방향이 기정의된 각도 내인 경우(또는 일치하는 경우), 상기 적어도 하나의 구매자에 의해 상기 상품 이 피킹된 것으로 판단할 수 있다. 여기서, 프로세서는 상술한 제1 벡터의 방향 및 제2 벡터의 방향을 비교한 결과에 더해, 상술한 선반의 무 게 변화와의 시점을 더 고려하여 상기 상품을 피킹한 구매자를 특정할 수 있다. 상술한 본 발명의 일 실시 예에서, 프로세서는 상품을 피킹한 구매자가 특정되면, 상품의 ID(identification) 및 상기 구매자를 매칭할 수 있다. 또한, 프로세서는 구매자의 미 결제 여부를 결정할 수 있다. 일 예로, 프로세서는 구매자가 상품을 결제하지 않은 상태에서 무인점포의 결제구역을 이탈한 시점으로부 터 기정의된 시간이 도과한 경우 구매자를 피킹한 상품에 대한 미 결제자로 결정할 수 있다. 여기서, 결제구역 은 무인 결제 키오스크 주변의 특정 범위, 무인점포의 입구 라인 등 무인점포의 사정에 맞게 적절하게 정해질 수 있다. 이 경우, 프로세서는 구매자에 대한 얼굴 이미지, 상품의 ID, 구매자가 무인점포의 결제구역에서 이탈한 시간에 대한 정보를 점주의 사용자 단말로 전송할 수 있다. 프로세서는 점주의 사용자 단말로부터 미 결제 사건 발생 알림 요청을 수신하면, 구매자에 대한 얼굴 이미지를 디스플레이하고, 미 결제 사건 발생 관련 안내 음성을 출력할 수 있다. 일 예로, 프로세서는 구매자가 복수의 상품을 피킹한 경우, 복수의 상품의 ID 각각을 구매자와 매칭할 수 있다. 프로세서는 구매자가 결제한 상품의 개수가 복수의 상품의 개수보다 작은 경우, 복수의 상품의 ID 및 구매자가 결제한 상품의 ID를 대조하여 누락된 상품을 특정할 수 있다. 또한, 프로세서는 누락된 상품 의 추가 결제를 요청하는 GUI(graphic user interface)를 생성하여 디스플레이하고, 누락된 상품의 추가 결제를 요청하는 음성 안내를 생성하여 출력할 수 있다. 일 예로, 프로세서는 상품의 미 결제 상태에서 구매자가 무인점포의 결제구역에서 이탈하는 경우, 출입문 의 잠금을 수행할 수 있다. 또한, 출입문의 잠금 실행을 나타내는 노티(notification)를 점주의 사용자 단말 로 전송할 수 있다. 한편, 프로세서는 미 결제자인 구매자의 프로파일 또는 미 결제 사건에 대한 프로파일을 생성할 수 있다. 구체적으로, 프로세서는 선반에 접근하는 구매자의 손을 적어도 하나의 방향에서 촬영하도록 카메라부를 제어하여 적어도 하나의 손 이미지를 생성할 수 있다. 이 경우, 프로세서는 적어도 하나의 손 이미지를 저 장하도록 저장부를 제어할 수 있다. 여기서, 프로세서는 사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 적어도 하나의 손 이미지 중 적어도 하나의 손 바닥 이미지를 획득할 수 있다. 프로세서는 획득된 손바닥 이미지에서 지문을 구분 또는 추출할 수 있다. 이를 위해, 프로세서는 지 문 검출에 대하여 딥러닝(Deep Learning) 등 머신 러닝(machine learning)을 수행할 수 있다. 이 경우, 상술한 저장부는 머신 러닝에 사용되는 데이터, 결과 데이터 등을 저장할 수 있다. 일 예로, 프로세서는 지문 영역의 경계를 추출할 수 있다. 프로세서는 지문 이미지의 레벨 값을 기반 으로, 2차원 배열에서 지문의 윤곽을 추출할 수 있다. 이 경우, 프로세서는 지문 영역을 회색조 (grayscale) 이미지로 변환할 수 있다. 또한, 프로세서는 지문 영역 내 화소들의 중간 값을 산출해 배열의 중간 값을 지정하여 지문 영역의 경계를 추출할 수 있다. 구체적으로, 프로세서는 지문 영역의 레벨 값을 기반으로 한 2차원 배열에서 미분값을 구하여 윤곽의 강도 와 방향을 계산할 수 있다. 여기서, 윤곽(edge)이란 사전적으로 물체의 외각을 나타내는 선을 의미하며, 이미지 처리의 차원에서는 이미지의 특징을 짓는 선 요소를 의미할 수 있다. 즉 경계선을 인지하는 것, 윤곽선에 해당 하는 픽셀을 구하는 것을 에지 추출(edge detection)이라고 한다. 윤곽은 이미지 안에서 픽셀의 값이 갑자기 변하는 곳이다. 즉 윤곽선은 다른 명암도를 가진 두 영역 사이의 경 계를 의미할 수 있으며, 픽셀의 밝기가 임계 값 보다 크게 변하는 부분을 의미할 수 있다. 여기서 임계값 은 경 계유무를 판단하는 임의의 기준치 값을 의미할 수 있다. 프로세서는 윤곽을 추출하는 알고리즘은 이미지를 미분한 그레디언트 벡터의 크기로 판단할 수 있다. 즉, 프로세서는 편미분 연산자의 계산에 근거하여 기울기를 구할 수 있다. 윤곽은 농담치가 급격히 변하는 부 분이기 때문에 함수의 변화분을 취하는 미분 연산이 윤곽선 추출에 사용될 수 있다. 미분에는 1차 미분(gradient)과 2차 미분(laplacian)이 있으며, 1차 미분 값에서 그래프 기울기의 크기로 이미 지에서 윤곽선의 존재 여부를 확인하고, 2차 미분 값에서 그래프 기울기의 부호로 윤곽선 픽셀의 밝고 어두운 부분의 위치를 확인할 수 있다. 윤곽을 추출하는 알고리즘은 sobel edge Detection, Canny edge Detection 등을 포함할 수 있다. 또한, 프로세 서는 지문 영역의 정확한 경계를 찾기 위하여, '밝은 값'과 '어두운 값'을 찾기 위해 지문 영역을 회색조 이미지로 변환할 수 있다. 프로세서는 지문 영역 내 화소들의 중간 값을 산출해 배열의 중간 값을 지정함으로써, 지문 영역의 경계를 추출할 수 있다. 즉, 프로세서는 회색조로 변환한 이미지를 이진화하여 중간 값을 추출하고 윤곽을 추출할 수 있다. 예를 들어, 이미지에 미분 방식을 적용하는 방법으로 마스크를 사용할 수 있다. 프로세서는 이미지의 3x3 픽셀에 마스크를 씌워 계산 후 중앙 픽셀을 결정하여 윤관선을 검출할 수 있다. 여기서, 마스크의 크기는 3x3이 일반적이나 5x5, 7x7 크기의 마스크도 적용 가능하며 마스크가 커지면 에지는 두꺼워져서 선명하게 나타날 수 있다. 또한, 프로세서는 마스크 영역 내의 픽셀들 중 중간 값을 대표 값으로 취하는 필터링을 수행할 수 있다. 중간 값을 이용하여 주변 값과의 차이에 따라 적응 가중치를 설정하여 필터 처리하므로 Spot noise와 같은 임펄 스성 노이즈를 줄여줄 수 있고, 이미지의 평활화(에지나 경계면 보호)가 가능하며, 선예도 차이가 크게 없으면 서 잡음제거를 수행할 수 있다. 본 발명의 일 실시 예에서, 프로세서는 지문 영역의 최종 에지 검출을 하기 전에 잡음을 제거하기 위해 중 간 값(median) 필터와 같은 smoothing 필터를 적용하고 에지 검출을 위해 공간 필터를 적용할 수 있다. 즉, 프 로세서는 배열의 중간 값에 기초하여 판단된 후보 동질 영역에 대해 재귀 호출을 수행하고, 재귀 호출 수 행 결과, 지문 이미지의 화소 값의 변화의 평균 값을 산출할 수 있다. 최종적으로, 프로세서는 구매자의 지문 이미지를 획득하여 저장부에 저장할 수 있다. 한편, 프로세서는 구매자가 피킹한 상품을 정상 결제한 경우, 저장된 적어도 하나의 손바닥 이미지를 삭제 하고, 구매자가 피킹한 상품을 미 결제한 경우, 저장된 적어도 하나의 손바닥 이미지에서 지문 이미지를 획득하 여 구매자와 매칭하여 저장하도록 저장부를 제어할 수 있다. 또한, 프로세서는 사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 적어도 하나의 손바닥 이미 지를 왼손 손바닥 이미지 및 오른손 손바닥 이미지 중 하나로 결정하고, 지문 이미지가 왼손 또는 오른손에 대 응되는지를 나타내는 지시자를 생성하여 저장할 수 있다. 또한, 프로세서는 구매자가 피킹한 상품을 미 결제한 경우, 지문 이미지, 지문 이미지가 왼손 또는 오른손 에 대응되는지를 나타내는 지시자, 구매자에 대한 상기 얼굴 이미지, 상품의 ID, 미 결제 피해액 및 구매자가 무인점포의 결제구역에서 이탈한 시간에 대한 정보 중 적어도 하나를 포함하는 미 결제자 프로파일 또는 미 결 제 사건 프로파일을 생성하여 경찰청 서버로 전송할 수 있다. 상술한 본 발명의 다양한 실시 예에 따르면, 무인점포 내에서 구매자의 행동을 추적함으로써 상품의 도난을 방 지하고, 구매자 또는 미 결제 사건의 프로파일링을 통해서 도난 발생 시 신속하게 대응할 수 있다. 도 5는 본 발명의 일 실시 예에 따른 전자장치의 세부 구성도이다. 도 5를 참조하면, 전자장치는 통신부, 저장부 및 프로세서를 포함한다. 통신부는 통신을 수행한다. 통신부는 BT(BlueTooth), WI-FI(Wireless Fidelity), ZigBee, IR(Infrared), NFC(Near Field Communication) 등과 같은 다양한 통신 방식을 통해 외부 전자기기와 통신을 수 행할 수 있다. 저장부는 전자장치를 구동시키기 위한 O/S(Operating System) 소프트웨어 모듈, 디스플레이 영역에서 제공되는 다양한 UI 화면을 구성하기 위한 데이터 등을 저장할 수 있다. 또한, 저장부는 읽고 쓰기가 가능하다. 프로세서는 저장부에 저장된 각종 프로그램을 이용하여 전자장치의 동작을 전반적으로 제어한다. 구체적으로, 프로세서는 RAM, ROM, 메인 CPU, 그래픽 처리부, 제1 내지 n 인터페이 스(535-1 ~ 535-n) 및 버스를 포함한다. 여기서, RAM, ROM, 메인 CPU, 그래픽 처리부, 제1 내지 n 인터페이스(535-1 ~ 535-n) 등 은 버스를 통해 서로 연결될 수 있다. 제1 내지 n 인터페이스(535-1 내지 535-n)는 상술한 각종 구성요소들과 연결된다. 인터페이스들 중 하나는 네트 워크를 통해 외부 장치와 연결되는 네트워크 인터페이스가 될 수도 있다. ROM에는 시스템 부팅을 위한 명령어 세트 등이 저장된다. 턴온 명령이 입력되어 전원이 공급되면, 메인 CPU는 ROM에 저장된 명령어에 따라 저장부에 저장된 O/S를 RAM에 복사하고, O/S를 실행시 켜 시스템을 부팅시킨다. 부팅이 완료되면, 메인 CPU는 저장된 각종 어플리케이션 프로그램을 RAM에 복사하고, RAM에 복 사된 어플리케이션 프로그램을 실행시켜 각종 동작을 수행한다. 메인 CPU는 저장부에 액세스하여, 저장부에 저장된 O/S를 이용하여 부팅을 수행한다. 그리고, 메인 CPU는 저장부에 저장된 각종 프로그램, 컨텐트, 데이터 등을 이용하여 다양한 동작을 수행한다. 그래픽 처리부는 연산부 및 렌더링부를 이용하여 아이콘, 이미지, 텍스트 등과 같은 다양한 객체를 포함하 는 화면을 생성한다. 도 6은 본 발명의 일 실시 예에 따른 무인점포에 비치된 상품의 도난을 방지하는 전자장치의 동작방법에 대한 흐름도이다. 도 6을 참조하면, 무인점포에 비치된 상품의 도난을 방지하는 전자장치의 동작방법은 무인점포에 비치된 상품을 구매하는 구매자를 촬영한 영상을 저장하는 과정(S610), 구매자가 무인점포로 입장하는 경우, 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성하는 과정(S620), 저장된 영상에 기초하여 구매자의 외형에 대한 딥러닝을 수행하 는 과정(S630), 수행된 딥러닝 결과에 기초하여 구매자를 특정하여 얼굴 이미지와 매칭하는 과정(S640), 카메라 부에 의해 촬영되는 영상에 기초하여, 구매자에 의해 상품이 피킹(picking)되는지 여부를 판단하는 과정 (S650), 상품의 ID 및 구매자를 매칭하는 과정(S660), 구매자가 상품을 결제하지 않은 상태에서 무인점포의 결 제구역을 이탈한 시점으로부터 기정의된 시간이 도과한 경우, 구매자에 대한 얼굴 이미지, 상품의 ID, 구매자가 무인점포의 결제구역에서 이탈한 시간에 대한 정보를 점주의 사용자 단말로 전송하는 과정(S670) 및 점주의 사 용자 단말로부터 미 결제 사건 발생 알림 요청을 수신하면, 구매자에 대한 얼굴 이미지를 디스플레이하고, 미 결제 사건 발생 관련 안내 음성을 출력하는 과정(S680)을 포함할 수 있다. 상술한 상품이 피킹되는지 여부를 판단하는 과정은 카메라부에 의해 촬영된 영상에 기초하여, 상품이 진열된 선 반으로 진입하는 구매자의 손의 방향을 판단하는 과정 및 상기 판단된 손의 방향에 기초하여, 상기 구매자에 의 해 상기 상품이 피킹되는지 여부를 판단하는 과정을 포함할 수 있다. 여기서, 상술한 손의 방향은 구매자의 손의 이동 시작 점(start point) 및 구매자의 손의 이동 정지 점(stop point)을 연결하는 벡터에 의해 결정될 수 있다. 또한, 상술한 상품이 피킹되는지 여부를 판단하는 과정은 상품이 진열된 선반의 무게가 상품의 무게만큼 변경되 고, 구매자와 선반의 거리가 기정의된 거리 이내인 경우, 구매자가 상품을 피킹(picking)한 것으로 판단하는 과 정을 더 포함할 수 있다. 상술한 전자장치의 동작방법은 구매자가 복수의 상품을 피킹한 경우, 복수의 상품의 ID 각각을 구매자와 매칭하 는 과정 및 구매자가 결제한 상품의 개수가 복수의 상품의 개수보다 작은 경우, 복수의 상품의 ID 및 구매자가 결제한 상품의 ID를 대조하여 누락된 상품을 특정하고, 누락된 상품의 추가 결제를 요청하는 GUI를 생성하여 디 스플레이하고, 누락된 상품의 추가 결제를 요청하는 음성 안내를 생성하여 출력하는 과정을 더 포함할 수 있다. 또한, 상술한 전자장치의 동작방법은 상품의 미 결제 상태에서 구매자가 무인점포의 결제구역에서 이탈하는 경 우, 출입문의 잠금을 수행하고, 출입문의 잠금 실행을 나타내는 노티를 점주의 사용자 단말로 전송하는 과정을 더 포함할 수 있다. 또한, 상술한 전자장치의 동작방법은 선반에 접근하는 구매자의 손을 적어도 하나의 방향에서 촬영하도록 카메 라부를 제어하여 적어도 하나의 손 이미지를 생성하고, 적어도 하나의 손 이미지를 저장하는 과정을 더 포함할 수 있다. 또한, 상술한 전자장치의 동작방법은 사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 적어도 하나 의 손 이미지 중 적어도 하나의 손 바닥 이미지를 획득하는 과정을 더 포함할 수 있다. 또한, 상술한 전자장치의 동작방법은 구매자가 피킹한 상품을 정상 결제한 경우, 저장된 적어도 하나의 손바닥 이미지를 삭제하는 과정 및 구매자가 피킹한 상품을 미 결제한 경우, 저장된 적어도 하나의 손바닥 이미지에서 지문 이미지를 획득하여 구매자와 매칭하여 저장하는 과정을 더 포함할 수 있다. 또한, 상술한 전자장치의 동작방법은 사람의 손 이미지에 대하여 수행된 딥러닝 결과에 기초하여, 적어도 하나 의 손바닥 이미지를 왼손 손바닥 이미지 및 오른손 손바닥 이미지 중 하나로 결정하는 과정 및 지문 이미지가 왼손 또는 오른손에 대응되는지를 나타내는 지시자를 생성하여 저장하는 과정을 더 포함할 수 있다. 또한, 상술한 전자장치의 동작방법은 구매자가 피킹한 상품을 미 결제한 경우, 지문 이미지, 지문 이미지가 왼 손 또는 오른손에 대응되는지를 나타내는 지시자, 구매자에 대한 얼굴 이미지, 상품의 ID, 미 결제 피해액 및 구매자가 무인점포의 결제구역에서 이탈한 시간에 대한 정보를 포함하는 미 결제 사건 프로파일을 생성하여 외 부 서버로 전송하는 과정을 더 포함할 수 있다. 한편, 상술한 본 발명의 다양한 실시 예에 따른 무인점포에 비치된 상품의 도난을 방지하는 전자장치의 동작방 법은 컴퓨터로 실행 가능한 프로그램 코드로 구현되어 다양한 비 일시적 판독 가능 매체(non-transitory computer readable medium)에 저장된 상태로 프로세서에 의해 실행되도록 각 서버 또는 기기들에 제공될 수 있 다. 일 예로, 무인점포에 비치된 상품을 구매하는 구매자를 촬영한 영상을 저장하는 과정, 구매자가 무인점포로 입 장하는 경우, 구매자의 얼굴을 촬영하여 얼굴 이미지를 생성하는 과정, 저장된 영상에 기초하여 구매자의 외형 에 대한 딥러닝을 수행하고, 수행된 딥러닝 결과에 기초하여 구매자를 특정하여 얼굴 이미지와 매칭하는 과정, 상품의 ID 및 구매자를 매칭하는 과정(S650), 구매자가 상품을 결제하지 않은 상태에서 무인점포의 결제구역을 이탈한 시점으로부터 기정의된 시간이 도과한 경우, 구매자에 대한 얼굴 이미지, 상품의 ID, 구매자가 무인점포 의 결제구역에서 이탈한 시간에 대한 정보를 점주의 사용자 단말로 전송하는 과정(S660) 및 점주의 사용자 단말 로부터 미 결제 사건 발생 알림 요청을 수신하면, 구매자에 대한 얼굴 이미지를 디스플레이하고, 미 결제 사건 발생 관련 안내 음성을 출력하는 과정을 수행하는 프로그램이 저장된 비일시적 판독 가능 매체(non-transitory computer readable medium)가 제공될 수 있다. 비 일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 이상으로, 본 발명의 실시 예들이 도시되고 설명되었지만, 당업자는 첨부된 청구항들 및 그에 동등한 것들에 의 해 정의되는 바와 같은 본 실시 예의 사상 및 범위를 벗어나지 않고 형태 및 세부 사항들에 있어 다양한 변경이 이루어질 수 있음을 이해할 것이다."}
{"patent_id": "10-2022-0052558", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 무인점포 도난 방지 시스템에 대한 도면이다. 도 2는 본 발명의 일 실시 예에 따른 무인점포 서버의 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 구매자를 촬영한 영상이다. 도 4는 본 발명의 일 실시 예에 따른 구매자의 손을 촬영한 영상이다. 도 5는 본 발명의 일 실시 예에 따른 전자장치의 세부 구성도이다. 도 6은 본 발명의 일 실시 예에 따른 무인점포에 비치된 상품의 도난을 방지하는 전자장치의 동작방법에 대한 흐름도이다."}
