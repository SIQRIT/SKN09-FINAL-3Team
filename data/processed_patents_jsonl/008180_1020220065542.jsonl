{"patent_id": "10-2022-0065542", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0166012", "출원번호": "10-2022-0065542", "발명의 명칭": "3차원 스캐너의 스캔 이미지 처리 방법, 장치 및 명령을 기록한 기록매체", "출원인": "주식회사 메디트", "발명자": "조영목"}}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서 및 상기 하나 이상의 프로세서에 의해 실행되기 위한 명령들이 저장된 하나 이상의 메모리를 포함하는 전자 장치에서 수행되는 3차원 스캐너의 스캔 이미지 처리 방법으로서,상기 3차원 스캐너로부터, 상기 3차원 스캐너의 스캔에 의해 생성된 대상체에 관한 2차원 이미지 셋 - 상기 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함함 - 을 획득하는 단계;상기 2차원 이미지 셋에 기초하여, 상기 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정된 영역을 검출하도록 학습된 인공 신경망에 입력 이미지를 입력하는 단계;상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 제1 영역을 검출하는 단계; 및상기 제1 영역에 기초하여 상기 대상체에 관한 3차원 스캔 데이터를 생성하는 단계;를 포함하는 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 영역은,상기 입력 이미지 내에서 금속에 해당하는 영역인, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 2차원 이미지 셋은,상기 3차원 스캐너를 통해 상기 대상체에 패턴이 있는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지;및상기 3차원 스캐너를 통해 상기 대상체에 패턴이 없는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지;를 포함하는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인공 신경망에 입력되는 입력 이미지는,상기 대상체에 패턴이 없는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지에 기초하여 생성되는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 인공 신경망에 입력 이미지를 입력하는 단계는,공개특허 10-2023-0166012-3-상기 2차원 이미지 셋에 포함되고 단일 색상 정보를 획득하기 위한 둘 이상의 2차원 이미지를 이용하여 RGB 이미지를 생성하는 단계; 및상기 RGB 이미지를 상기 인공 신경망에 입력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 인공 신경망은,상기 입력 이미지에 포함된 적어도 하나의 픽셀을 상기 적어도 하나의 사전 결정된 영역 중 대응되는 영역으로분류함으로써 상기 입력 이미지에 대한 세그멘테이션(segmentation) 결과를 출력하도록 학습되는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 대상체에 관한 3차원 스캔 데이터를 생성하는 단계는,상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생성하되 상기 제1 영역에 대응되는 좌표는 상기 3차원 스캔 데이터에 포함되지 않도록 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생성하되 상기 제1 영역에 대응되는 좌표는 상기 3차원 스캔 데이터에 포함되지 않도록 생성하는 단계는,상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생성할 때, 상기 2차원 이미지 셋에 포함된 각각의2차원 이미지 내에서 상기 제1 영역에 대응되는 픽셀의 값을 연산 대상에서 제외하고 생성함으로써 수행되는,방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 대상체에 관한 3차원 스캔 데이터를 생성하는 단계는,상기 2차원 이미지 셋에 포함된 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영역의 데이터를제거하는 단계; 및상기 제1 영역과 대응되는 영역의 데이터가 제거된 적어도 하나의 2차원 이미지를 이용하여 3차원 스캔 데이터를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,공개특허 10-2023-0166012-4-상기 2차원 이미지 셋에 포함된 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영역의 데이터를제거하는 단계는,상기 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영역에 포함된 픽셀의 값을 사전 설정된 값으로 변경하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 제1 영역을 검출하는 단계는,상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 서로 다른 복수의 제1 영역을 검출하는 단계를 포함하고,상기 3차원 스캔 데이터를 생성하는 단계는,상기 복수의 제1 영역이 서로 구별되도록 상기 3차원 스캔 데이터를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 전자 장치는 입력 장치를 더 포함하고,사용자로부터 상기 입력 장치를 통해 제1 영역의 포함 여부에 관한 사용자 입력을 획득하는 단계를 더포함하며,상기 3차원 스캔 데이터를 생성하는 단계는,상기 사용자 입력에 따라 상기 3차원 스캔 데이터에 상기 제1 영역에 대응되는 좌표가 포함되는지 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 장치에 있어서,3차원 스캐너와 통신 연결되는 통신 회로;메모리;디스플레이; 및하나 이상의 프로세서를 포함하고,상기 하나 이상의 프로세서는,상기 3차원 스캐너로부터, 상기 3차원 스캐너의 스캔에 의해 생성된 대상체에 관한 2차원 이미지 셋 - 상기 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함함 - 을 획득하고,상기 2차원 이미지 셋에 기초하여, 상기 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정된 영역을 검출하도록 학습된 인공 신경망에 입력 이미지를 입력하고,상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 제1 영역을 검출하고,공개특허 10-2023-0166012-5-상기 제1 영역에 기초하여 상기 대상체에 관한 3차원 스캔 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제1 영역은,상기 입력 이미지 내에서 금속에 해당하는 영역인, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 2차원 이미지 셋은,상기 3차원 스캐너를 통해 상기 대상체에 패턴이 있는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지;및상기 3차원 스캐너를 통해 상기 대상체에 패턴이 없는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지;를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 인공 신경망에 입력되는 입력 이미지는,상기 대상체에 패턴이 없는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지에 기초하여 생성되는, 전자장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 하나 이상의 프로세서는,상기 2차원 이미지 셋에 포함되고 단일 색상 정보를 획득하기 위한 둘 이상의 2차원 이미지를 이용하여 RGB 이미지를 생성하고,상기 RGB 이미지를 상기 인공 신경망에 입력하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 인공 신경망은,상기 입력 이미지에 포함된 적어도 하나의 픽셀을 상기 적어도 하나의 사전 결정된 영역 중 대응되는 영역으로분류함으로써 상기 입력 이미지에 대한 세그멘테이션(segmentation) 결과를 출력하도록 학습되는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,공개특허 10-2023-0166012-6-상기 하나 이상의 프로세서는,상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생성하되 상기 제1 영역에 대응되는 좌표는 상기 3차원 스캔 데이터에 포함되지 않도록 생성하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 하나 이상의 프로세서는,상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생성할 때, 상기 2차원 이미지 셋에 포함된 각각의2차원 이미지 내에서 상기 제1 영역에 대응되는 픽셀의 값을 연산 대상에서 제외하고 생성하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제13항에 있어서,상기 하나 이상의 프로세서는,상기 2차원 이미지 셋에 포함된 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영역의 데이터를제거하고,상기 제1 영역과 대응되는 영역의 데이터가 제거된 적어도 하나의 2차원 이미지를 이용하여 3차원 스캔 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 하나 이상의 프로세서는,상기 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영역에 포함된 픽셀의 값을 사전 설정된 값으로 변경하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제13항에 있어서,상기 하나 이상의 프로세서는,상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 서로 다른 복수의 제1 영역을 검출하고,상기 복수의 제1 영역이 서로 구별되도록 상기 3차원 스캔 데이터를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0065542", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "하나 이상의 프로세서에 의한 실행 시, 상기 하나 이상의 프로세서가 동작을 수행하도록 하는 명령들을 기록한비일시적 컴퓨터 판독 가능 기록매체에 있어서,상기 명령들은, 상기 하나 이상의 프로세서로 하여금,3차원 스캐너로부터, 상기 3차원 스캐너의 스캔에 의해 생성된 대상체에 관한 2차원 이미지 셋 - 상기 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함함 - 을 획득하고,상기 2차원 이미지 셋에 기초하여, 상기 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정된 영역을 검출공개특허 10-2023-0166012-7-하도록 학습된 인공 신경망에 입력 이미지를 입력하고,상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 제1 영역을 검출하고,상기 제1 영역에 기초하여 상기 대상체에 관한 3차원 스캔 데이터를 생성하도록 하는, 컴퓨터 판독 가능 기록매체."}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "3차원 스캐너의 스캔 이미지 처리를 위한 방법이 제안될 수 있다. 상기 방법은, 하나 이상의 프로세서 및 상기 하나 이상의 프로세서에 의해 실행되기 위한 명령들이 저장된 하나 이상의 메모리를 포함하는 전자 장치에서 수 행되는 방법으로서, 상기 3차원 스캐너로부터, 상기 3차원 스캐너의 스캔에 의해 생성된 대상체에 관한 2차원 이 미지 셋 - 상기 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함함 - 을 획득하는 단계; 상기 2차원 이미 지 셋에 기초하여, 상기 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정된 영역을 검출하도록 학습된 인 공 신경망에 입력 이미지를 입력하는 단계; 상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 제1 영역을 검출하는 단계; 상기 제1 영역에 기초하여 상기 대상체에 관한 3차원 스캔 데이터를 생성하는 단계를 포 함할 수 있다."}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 3차원 스캐너의 스캔 이미지 처리 방법에 관한 것으로서, 구체적으로는 3차원 스캐너(3D scanner)로 부터 수신한 이미지 내에서 특정 영역을 검출하고 이에 기초하여 3차원 스캔 데이터를 생성하는 방법에 관한 것 이다."}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 환자의 구강 정보를 획득하기 위하여, 환자의 구강 내부에 삽입하여 구강 내부의 이미지를 획득하 는 3차원 스캐너가 이용될 수 있다. 예를 들어, 의사는 3차원 스캐너를 환자의 구강 내부에 삽입하여, 환자의 치아, 치은 및/또는 연조직을 스캔함으로써, 환자의 구강에 대한 복수의 2차원 이미지를 획득하고, 3D 모델링 기술을 적용함으로써, 환자의 구강에 대한 2차원 이미지를 이용하여 환자의 구강에 대한 3차원 이미지를 구축할 수 있다. 이 때, 치료를 진행하고 있는 환자들의 경우 구강 내에 와이어, 보철 등의 교정장치, 크라운 등의 인공 치아가 존재할 수 있다. 종래에는 이러한 환자의 구강 정보를 획득하기 위해 교정장치를 제거한 후 환자의 구강을 스캔하여 3차원 이미 지를 구축하였다. 그러나 이는 3차원 이미지를 얻기 위해 소요되는 시간이 증가할 뿐 아니라, 교정장치를 제거 할 수 없는 경우에는 교정장치가 존재한 상태에서 환자의 구강을 스캔하였기 때문에 제대로 된 3차원 이미지를 획득할 수 없는 문제점이 있었다. 따라서, 당업계에서는 환자의 구강 내에 치료를 위한 장치가 존재하는 경우에도 환자의 구강에 대한 3차원 이미 지를 보다 정확하게 스캔하기 위한 기술의 수요가 증가해왔다."}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 3차원 스캐너로부터 수신한 이미지 내에서 특정 영역을 검출하고 이에 기초하여 3차원 스캔 데이터를 생성하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 한 측면으로서, 3차원 스캐너의 스캔 이미지 처리를 위한 방법이 제안될 수 있다. 상기 방법은, 하 나 이상의 프로세서 및 상기 하나 이상의 프로세서에 의해 실행되기 위한 명령들이 저장된 하나 이상의 메모리 를 포함하는 전자 장치에서 수행되는 방법으로서, 상기 3차원 스캐너로부터, 상기 3차원 스캐너의 스캔에 의해 생성된 대상체에 관한 2차원 이미지 셋 - 상기 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함함 - 을 획득하는 단계; 상기 2차원 이미지 셋에 기초하여, 상기 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정 된 영역을 검출하도록 학습된 인공 신경망에 입력 이미지를 입력하는 단계; 상기 인공 신경망의 출력에 기초하 여 상기 입력 이미지 내에서 제1 영역을 검출하는 단계; 및 상기 제1 영역에 기초하여 상기 대상체에 관한 3차 원 스캔 데이터를 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 제1 영역은, 상기 입력 이미지 내에서 금속에 해당하는 영역일 수 있다. 일 실시예에 있어서, 상기 2차원 이미지 셋은, 상기 3차원 스캐너를 통해 상기 대상체에 패턴이 있는 광을 조사 함으로써 획득된 적어도 하나의 2차원 이미지; 및 상기 3차원 스캐너를 통해 상기 대상체에 패턴이 없는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지를 포함할 수 있다.일 실시예에 있어서, 상기 인공 신경망에 입력되는 입력 이미지는, 상기 대상체에 패턴이 없는 광을 조사함으로 써 획득된 적어도 하나의 2차원 이미지에 기초하여 생성될 수 있다. 일 실시예에 있어서, 상기 인공 신경망에 입력 이미지를 입력하는 단계는, 상기 2차원 이미지 셋에 포함되고 단 일 색상 정보를 획득하기 위한 둘 이상의 2차원 이미지를 이용하여 RGB 이미지를 생성하는 단계; 및 상기 RGB 이미지를 상기 인공 신경망에 입력하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 인공 신경망은, 상기 입력 이미지에 포함된 적어도 하나의 픽셀을 상기 적어도 하나 의 사전 결정된 영역 중 대응되는 영역으로 분류함으로써 상기 입력 이미지에 대한 세그멘테이션(segmentation) 결과를 출력하도록 학습될 수 있다. 일 실시예에 있어서, 상기 대상체에 관한 3차원 스캔 데이터를 생성하는 단계는, 상기 2차원 이미지 셋에 기초 하여 상기 3차원 스캔 데이터를 생성하되 상기 제1 영역에 대응되는 좌표는 상기 3차원 스캔 데이터에 포함되지 않도록 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생성하되 상기 제1 영역에 대 응되는 좌표는 상기 3차원 스캔 데이터에 포함되지 않도록 생성하는 단계는, 상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생성할 때, 상기 2차원 이미지 셋에 포함된 각각의 2차원 이미지 내에서 상기 제1 영 역에 대응되는 픽셀의 값을 연산 대상에서 제외하고 생성함으로써 수행될 수 있다. 일 실시예에 있어서, 상기 대상체에 관한 3차원 스캔 데이터를 생성하는 단계는, 상기 2차원 이미지 셋에 포함 된 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영역의 데이터를 제거하는 단계; 및 상기 제1 영역과 대응되는 영역의 데이터가 제거된 적어도 하나의 2차원 이미지를 이용하여 3차원 스캔 데이터를 생성하 는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 2차원 이미지 셋에 포함된 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응 되는 영역의 데이터를 제거하는 단계는, 상기 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영 역에 포함된 픽셀의 값을 사전 설정된 값으로 변경하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 제1 영역을 검출하는 단계는, 상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 서로 다른 복수의 제1 영역을 검출하는 단계를 포함하고, 상기 3차원 스캔 데이터를 생성하는 단계는, 상기 복수의 제1 영역이 서로 구별되도록 상기 3차원 스캔 데이터를 생성하는 단계를 포함할 수 있다. 일 실시예에 있어서, 상기 방법이 수행되는 전자 장치는 입력 장치를 더 포함하고, 사용자로부터 상기 입력 장 치를 통해 제1 영역의 포함 여부에 관한 사용자 입력을 획득하는 단계를 더 포함하며, 상기 3차원 스캔 데이터 를 생성하는 단계는, 상기 사용자 입력에 따라 상기 3차원 스캔 데이터에 상기 제1 영역에 대응되는 좌표가 포 함되는지 여부를 결정하는 단계를 포함할 수 있다. 본 개시의 다른 측면에 따르면, 3차원 스캐너의 스캔 이미지 처리를 위한 전자 장치가 제안될 수 있다. 본 개 시의 한 측면에 따른 전자 장치는, 3차원 스캐너와 통신 연결되는 통신 회로; 메모리; 디스플레이; 및 하나 이 상의 프로세서를 포함하고, 상기 하나 이상의 프로세서는, 상기 3차원 스캐너로부터, 상기 3차원 스캐너의 스캔 에 의해 생성된 대상체에 관한 2차원 이미지 셋 - 상기 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함 함 - 을 획득하고, 상기 2차원 이미지 셋에 기초하여, 상기 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정된 영역을 검출하도록 학습된 인공 신경망에 입력 이미지를 입력하고, 상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 제1 영역을 검출하고, 상기 제1 영역에 기초하여 상기 대상체에 관한 3차원 스캔 데이 터를 생성하는 것을 특징으로 할 수 있다. 일 실시예에 있어서, 상기 제1 영역은, 상기 입력 이미지 내에서 금속에 해당하는 영역일 수 있다. 일 실시예에 있어서, 상기 2차원 이미지 셋은, 상기 3차원 스캐너를 통해 상기 대상체에 패턴이 있는 광을 조사 함으로써 획득된 적어도 하나의 2차원 이미지; 및 상기 3차원 스캐너를 통해 상기 대상체에 패턴이 없는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지를 포함할 수 있다. 일 실시예에 있어서, 상기 인공 신경망에 입력되는 입력 이미지는, 상기 대상체에 패턴이 없는 광을 조사함으로 써 획득된 적어도 하나의 2차원 이미지에 기초하여 생성될 수 있다. 일 실시예에 있어서, 상기 하나 이상의 프로세서는, 상기 2차원 이미지 셋에 포함되고 단일 색상 정보를 획득하 기 위한 둘 이상의 2차원 이미지를 이용하여 RGB 이미지를 생성하고, 상기 RGB 이미지를 상기 인공 신경망에 입력할 수 있다. 일 실시예에 있어서, 상기 인공 신경망은, 상기 입력 이미지에 포함된 적어도 하나의 픽셀을 상기 적어도 하나 의 사전 결정된 영역 중 대응되는 영역으로 분류함으로써 상기 입력 이미지에 대한 세그멘테이션(segmentation) 결과를 출력하도록 학습될 수 있다. 일 실시예에 있어서, 상기 하나 이상의 프로세서는, 상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터 를 생성하되 상기 제1 영역에 대응되는 좌표는 상기 3차원 스캔 데이터에 포함되지 않도록 생성할 수 있다. 일 실시예에 있어서, 상기 하나 이상의 프로세서는, 상기 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터 를 생성할 때, 상기 2차원 이미지 셋에 포함된 각각의 2차원 이미지 내에서 상기 제1 영역에 대응되는 픽셀의 값을 연산 대상에서 제외하고 생성할 수 있다. 일 실시예에 있어서, 상기 하나 이상의 프로세서는, 상기 2차원 이미지 셋에 포함된 적어도 하나의 2차원 이미 지 내에서 상기 제1 영역과 대응되는 영역의 데이터를 제거하고, 상기 제1 영역과 대응되는 영역의 데이터가 제 거된 적어도 하나의 2차원 이미지를 이용하여 3차원 스캔 데이터를 생성할 수 있다. 일 실시예에 있어서, 상기 하나 이상의 프로세서는, 상기 적어도 하나의 2차원 이미지 내에서 상기 제1 영역과 대응되는 영역에 포함된 픽셀의 값을 사전 설정된 값으로 변경할 수 있다. 일 실시예에 있어서, 상기 하나 이상의 프로세서는, 상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내 에서 서로 다른 복수의 제1 영역을 검출하고, 상기 복수의 제1 영역이 서로 구별되도록 상기 3차원 스캔 데이터 를 생성할 수 있다. 본 개시의 한 측면으로서, 3차원 스캐너의 스캔 이미지 처리를 위한 명령들을 기록한 비일시적 컴퓨터 판독 가 능 기록매체가 제안될 수 있다. 본 개시의 한 측면에 따른 컴퓨터 상에서 수행되기 위한 명령들을 기록한 비일 시적 컴퓨터 판독 가능 기록매체에 있어서, 상기 명령들은, 하나 이상의 프로세서에 의한 실행시, 상기 하나 이 상의 프로세서로 하여금, 3차원 스캐너로부터, 상기 3차원 스캐너의 스캔에 의해 생성된 대상체에 관한 2차원 이미지 셋 - 상기 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함함 - 을 획득하고, 상기 2차원 이미지 셋에 기초하여, 상기 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정된 영역을 검출하도록 학습된 인공 신경망에 입력 이미지를 입력하고, 상기 인공 신경망의 출력에 기초하여 상기 입력 이미지 내에서 제1 영역을 검출하고, 상기 제1 영역에 기초하여 상기 대상체에 관한 3차원 스캔 데이터를 생성하도록 할 수 있다."}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예에 따르면, 인공 신경망을 이용하여 스캔된 이미지 내에서 특정 영역을 검출하고 이에 기초하여 대상체에 관한 3차원 스캔 데이터를 생성하므로, 사용자가 특정 영역을 포함하지 않는 3차원 스캔 데 이터를 생성하고자 할 때, 해당 특정 영역은 3차원 스캔 데이터 내에서 표현되지 않을 수 있다. 이를 통해, 본 개시는 검진 또는 치료를 위해 불필요한 정보를 3차원 스캔 데이터 상에서 배제하고, 필요한 정보를 보다 정확 하고 간결하게 사용자에게 제공할 수 있다. 본 개시의 다양한 실시예에 따르면, 3차원 스캔 데이터에 포함된 복수의 제1 영역들이 사용자에게 시각적으로 구분되어 제공될 경우, 사용자는 3차원 스캔 데이터 내에 포함된 서로 다른 복수의 제1 영역을 빠르고 편리하게 구별할 수 있다."}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 실시예들은 본 개시의 기술적 사상을 설명하기 위한 목적으로 예시된 것이다. 본 개시에 따른 권리범 위가 이하에 제시되는 실시예들이나 이들 실시예들에 대한 구체적 설명으로 한정되는 것은 아니다. 본 개시에 사용되는 모든 기술적 용어들 및 과학적 용어들은, 달리 정의되지 않는 한, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 일반적으로 이해되는 의미를 갖는다. 본 개시에 사용되는 모든 용어들은 본 개시를 더욱 명확히 설명하기 위한 목적으로 선택된 것이며 본 개시에 따른 권리범위를 제한하기 위해 선택 된 것이 아니다. 본 개시에서 사용되는 \"포함하는\", \"구비하는\", \"갖는\" 등과 같은 표현은, 해당 표현이 포함되는 어구 또는 문 장에서 달리 언급되지 않는 한, 다른 실시예를 포함할 가능성을 내포하는 개방형 용어(open-ended terms)로 이 해되어야 한다. 본 개시에서 기술된 단수형의 표현은 달리 언급하지 않는 한 복수형의 의미를 포함할 수 있으며, 이는 청구범위 에 기재된 단수형의 표현에도 마찬가지로 적용된다. 본 개시에서 사용되는 \"제1\", \"제2\" 등의 표현들은 복수의 구성요소들을 상호 구분하거나, 동일한 구성요소를 일관되게 지칭하기 위해 사용될 뿐, 해당 구성요소들의 순서 또는 중요도를 한정하는 것은 아니다. 본 개시에서 사용되는 용어 \"부\"는, 소프트웨어, 또는 FPGA(field-programmable gate array), ASIC(application specific integrated circuit)과 같은 하드웨어 구성요소를 의미한다. 그러나, \"부\"는 하드 웨어 및 소프트웨어에 한정되는 것은 아니다. \"부\"는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있 고, 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서, \"부\"는 소프트웨 어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들 과, 프로세서, 함수, 속성, 프로시저, 서브루틴, 프로그램 코드의 세그먼트, 드라이버, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조, 테이블, 어레이 및 변수를 포함한다. 구성요소와 \"부\" 내에서 제공 되는 기능은 더 작은 수의 구성요소 및 \"부\"로 결합되거나 추가적인 구성요소와 \"부\"로 더 분리될 수 있다. 본 개시에서 사용되는 \"~에 기초하여\"라는 표현은, 해당 표현이 포함되는 어구 또는 문장에서 기술되는, 결정, 판단의 행위 또는 동작에 영향을 주는 하나 이상의 인자를 기술하는데 사용되며, 이 표현은 결정, 판단의 행위 또는 동작에 영향을 주는 추가적인 인자를 배제하지 않는다. 본 개시에서, 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 경우, 상기 어 떤 구성요소가 상기 다른 구성요소에 직접적으로 연결될 수 있거나 접속될 수 있는 것으로, 또는 새로운 다른 구성요소를 매개로 하여 연결될 수 있거나 접속될 수 있는 것으로 이해되어야 한다. 본 개시에서, 인공지능(artificial intelligence, AI)은 인간의 학습능력, 추론능력, 지각능력을 모방하고, 이 를 컴퓨터로 구현하는 기술을 의미하고, 기계 학습, 심볼릭 로직의 개념을 포함할 수 있다. 기계 학습(machine learning, ML)은 입력 데이터들의 특징을 스스로 분류 또는 학습하는 알고리즘 기술일 수 있다. 인공지능의 기 술은 기계 학습의 알고리즘으로써 입력 데이터들 분석하고, 그 분석의 결과를 학습하며, 그 학습의 결과에 기초 하여 기반으로 판단이나 예측을 할 수 있다. 또한, 기계 학습의 알고리즘을 활용하여 인간 두뇌의 인지, 판단 의 기능을 모사하는 기술들 역시 인공지능의 범주로 이해될 수 있다. 예를 들어, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어의 기술 분야가 포함될 수 있다. 본 개시에서, 기계 학습은 데이터를 처리한 경험을 이용해 신경망 모델을 훈련시키는 처리를 의미할 수 있다. 기계 학습을 통해 컴퓨터 소프트웨어는 스스로 데이터 처리 능력을 향상시키는 것을 의미할 수 있다. 신경망모델은 데이터 사이의 상관 관계를 모델링하여 구축된 것으로서, 그 상관 관계는 복수의 파라미터에 의해 표현 될 수 있다. 신경망 모델은 주어진 데이터로부터 특징들을 추출하고 분석하여 데이터 간의 상관 관계를 도출하 는데, 이러한 과정을 반복하여 신경망 모델의 파라미터를 최적화 해나가는 것이 기계 학습이라고 할 수 있다. 예를 들어, 신경망 모델은 입출력 쌍으로 주어지는 데이터에 대하여, 입력과 출력 사이의 매핑(상관 관계)을 학 습할 수 있다. 또는 신경망 모델은 입력 데이터만 주어지는 경우에도 주어진 데이터 사이의 규칙성을 도출하여 그 관계를 학습할 수도 있다. 본 개시에서, 인공 신경망, 인공지능 학습 모델, 기계 학습 모델 또는 신경망 모델은 인간의 뇌 구조를 컴퓨터 상에서 구현하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하며 가중치를 가지는 복수의 네트 워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하여, 서로 간의 연결 관계를 가질 수 있다. 인공 신경망에서 복수의 네 트워크 노드들은 서로 다른 깊이의 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주 고 받을 수 있다. 인공 신경망은, 예를 들어, 인공 신경망 모델(artificial neural network), 합성곱 신경망 모델(convolution neural network) 등일 수 있다. 이하, 첨부한 도면들을 참조하여, 본 개시의 실시예들을 설명한다. 첨부된 도면에서, 동일하거나 대응하는 구 성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예들의 설명에 있어서, 동일하거나 대응하는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나, 구성요소에 관한 기술이 생략되어도, 그러한 구 성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 도 1은 본 개시의 일 실시예에 따른 3차원 스캐너를 이용하여 환자의 구강에 대한 이미지를 획득하는 모습 을 도시한 도면이다. 다양한 실시예에 따르면, 3차원 스캐너는 대상체의 구강 내의 이미지를 획득하 기 위한 치과용 의료 기기일 수 있다. 예를 들어, 3차원 스캐너는 구강 스캐너(intraoral scanner)일 수 있다. 도 1에 도시된 것처럼 사용자(예: 치과 의사, 치과위생사)가 3차원 스캐너를 이용하여 대상체 (예: 환자)로부터 대상체의 구강에 대한 이미지를 획득할 수 있다. 다른 예로는, 사용자가 대상체 의 구강의 모양을 본뜬 진단 모델(예: 석고 모델, 인상(impression) 모델)로부터 대상체의 구강에 대한 이미지를 획득할 수도 있다. 이하에서는 설명의 편의를 위하여, 대상체의 구강을 스캐닝하여, 대상체 의 구강에 대한 이미지를 획득하는 것으로 설명하지만, 이에 제한되지 않으며, 대상체의 다른 부위(예: 대 상체의 귀)에 대한 이미지를 획득하는 것도 가능하다. 3차원 스캐너는 구강 내에 인입 및 인출이 가능 한 형태를 가질 수 있으며, 스캔 거리와 스캔 각도를 사용자가 자유롭게 조절할 수 있는 핸드헬드형 스캐너 (handheld scanner)일 수 있다. 다양한 실시예에 따른 3차원 스캐너는 대상체의 구강 내에 삽입되어 비 접촉식으로 구강 내부를 스캐 닝함으로써, 구강에 대한 이미지를 획득할 수 있다. 구강에 대한 이미지는 적어도 하나의 치아, 치은, 구강 내 에 삽입 가능한 인공 구조물(예를 들어, 브라켓 및 와이어를 포함하는 교정 장치, 임플란트, 의치(denture), 구 강 내 삽입되는 교정 보조 도구)을 포함할 수 있다. 3차원 스캐너는 광원(또는 프로젝터)을 이용하여 대상 체의 구강(예: 대상체의 적어도 하나의 치아, 치은)에 광을 조사할 수 있고, 대상체의 구강으로부 터 반사된 광을 카메라(또는, 적어도 하나의 이미지 센서)를 통해 수신할 수 있다. 다른 실시예에 따르면, 3차 원 스캐너는 구강의 진단 모델을 스캐닝함으로써, 구강의 진단 모델에 대한 이미지를 획득할 수도 있다. 구강의 진단 모델이 대상체의 구강의 모양을 본뜬 진단 모델인 경우, 구강의 진단 모델에 대한 이미지는 대 상체의 구강에 대한 이미지가 될 수 있다. 이하에서는, 설명의 편의를 위하여, 대상체의 구강 내부를 스캐 닝함으로써, 구강에 대한 이미지를 획득하는 경우를 가정하여 설명하도록 하지만, 이에 제한되는 것은 아니다. 다양한 실시예에 따른 3차원 스캐너는 카메라를 통해 수신한 정보에 기초하여, 대상체의 구강에 대한 표면 이미지를 2차원 이미지로서 획득할 수 있다. 대상체의 구강에 대한 표면 이미지는 대상체의 적어 도 하나의 치아, 치은, 인공 구조물, 대상체의 볼, 혀 또는 입술 중 적어도 하나를 포함할 수 있다. 대상 체의 구강에 대한 표면 이미지는 2차원 이미지일 수 있다. 다양한 실시예에 따른 3차원 스캐너에서 획득된 구강에 대한 2차원 이미지는 유선 또는 무선 통신 네트워 크를 통해 연결되는 전자 장치로 전송될 수 있다. 전자 장치는, 컴퓨터 장치 또는 휴대용 통신 장치 일 수 있다. 전자 장치는 3차원 스캐너로부터 수신한 구강에 대한 2차원 이미지에 기초하여 구강을 3차원적으로 나타내는 구강에 대한 3차원 이미지(또는, 3차원 구강 이미지, 3차원 구강 모델)를 생성할 수 있다. 전자 장치는 수신한 구강에 대한 2차원 이미지에 기초하여 구강의 내부 구조를 3차원적으로 모델링 (modeling)하여 구강에 대한 3차원 이미지를 생성할 수 있다.또 다른 실시예에 따른 3차원 스캐너는 대상체의 구강을 스캔하여 구강에 대한 2차원 이미지를 획득하 고, 획득한 구강에 대한 2차원 이미지에 기초하여 구강에 대한 3차원 이미지를 생성하며, 생성한 구강의 3차원 이미지를 전자 장치로 전송할 수도 있다. 다양한 실시예에 따른 전자 장치는 클라우드 서버(미도시)와 통신 연결될 수 있다. 상기의 경우, 전자 장 치는 대상체의 구강에 대한 2차원 이미지 또는 구강에 대한 3차원 이미지를 클라우드 서버에 전송할 수 있고, 클라우드 서버는 전자 장치로부터 수신한 대상체의 구강에 대한 2차원 이미지 또는 구강에 대한 3차원 이미지를 저장할 수 있다. 또 다른 실시예에 따르면, 3차원 스캐너는 대상체의 구강에 삽입하여 사용하는 핸드헬드형 스캐너 이외에도, 특정 위치에 고정시켜 사용하는 테이블 스캐너(미도시)가 사용될 수도 있다. 테이블 스캐너는 구강 의 진단 모델을 스캐닝함으로써 구강의 진단 모델에 대한 3차원 이미지를 생성할 수 있다. 상기의 경우, 테이 블 스캐너의 광원(또는 프로젝터) 및 카메라는 고정되어 있으므로, 사용자는 구강의 진단 모델을 움직이면서 구 강의 진단 모델을 스캐닝할 수 있다. 도 2a는 본 개시의 일 실시예에 따른 전자 장치 및 3차원 스캐너의 블록도이다. 전자 장치 및 3차원 스캐너는 유선 또는 무선 통신 네트워크를 통해 서로 통신 연결될 수 있으며, 다양한 데이터를 서로 송수신할 수 있다. 다양한 실시예에 따른 3차원 스캐너는, 프로세서, 메모리, 통신 회로, 광원, 카메라 , 입력 장치 및/또는 센서 모듈을 포함할 수 있다. 3차원 스캐너에 포함된 구성요소들 중 적어도 하나가 생략되거나, 다른 구성요소가 3차원 스캐너에 추가될 수 있다. 추가적으로 또는 대체적으 로 일부의 구성요소들이 통합되어 구현되거나, 단수 또는 복수의 개체로 구현될 수 있다. 3차원 스캐너 내 의 적어도 일부의 구성요소들은 버스(bus), GPIO(general purpose input/output), SPI(serial peripheral interface) 또는 MIPI(mobile industry processor interface) 등을 통해 서로 연결되어, 데이터 및/또는 시그 널을 주고 받을 수 있다. 다양한 실시예에 따른 3차원 스캐너의 프로세서는 3차원 스캐너의 각 구성요소들의 제어 및/또 는 통신에 관한 연산이나 데이터 처리를 수행할 수 있는 구성으로서, 3차원 스캐너의 구성요소들과 작동적 으로 연결될 수 있다. 프로세서는 3차원 스캐너의 다른 구성요소로부터 수신된 명령 또는 데이터를 메모리에 로드하고, 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 저장할 수 있다. 다양한 실시예에 따른 3차원 스캐너의 메모리는, 상기에 기재된 프로세서의 동작에 대한 인스트 럭션들을 저장할 수 있다. 다양한 실시예에 따르면, 3차원 스캐너의 통신 회로는 외부 장치(예: 전자 장치)와 유선 또는 무선 통신 채널을 설립하고, 외부 장치와 다양한 데이터를 송수신할 수 있다. 일 실시예에 따르면, 통신 회로 는 외부 장치와 유선으로 통신하기 위해서, 외부 장치와 유선 케이블로 연결되기 위한 적어도 하나의 포트 를 포함할 수 있다. 상기의 경우, 통신 회로는 적어도 하나의 포트를 통하여 유선 연결된 외부 장치와 통 신을 수행할 수 있다. 일 실시예에 따르면, 통신 회로는 셀룰러 통신 모듈을 포함하여 셀룰러 네트워크 (예: 3G, LTE, 5G, Wibro 또는 Wimax)에 연결되도록 구성할 수 있다. 다양한 실시예에 따르면, 통신 회로 는 근거리 통신 모듈을 포함하여 근거리 통신(예를 들면, Wi-Fi, Bluetooth, Bluetooth Low Energy(BLE), UWB)을 이용해 외부 장치와 데이터 송수신을 할 수 있으나, 이에 제한되지 않는다. 일 실시예에 따르면, 통신 회로는 비접촉식 통신을 위한 비접촉 통신 모듈을 포함할 수 있다. 비접촉식 통신은, 예를 들면, NFC(near field communication) 통신, RFID(radio frequency identification) 통신 또는 MST(magnetic secure transmission) 통신과 같이 적어도 하나의 비접촉 방식의 근접 통신 기술을 포함할 수 있다. 다양한 실시예에 따른 3차원 스캐너의 광원은 대상체의 구강을 향해 광을 조사할 수 있다. 예를 들어, 광원으로부터 조사되는 광은 소정 패턴(예: 서로 다른 색상의 직선 무늬가 연속적으로 나타나는 스 트라이프 패턴)을 갖는 구조광일 수 있다. 구조광의 패턴은, 예를 들어, 패턴 마스크 또는 DMD(digital micro- mirror device)를 이용하여 생성될 수 있지만, 이에 제한되는 것은 아니다. 다양한 실시예에 따른 3차원 스캐 너의 카메라는 대상체의 구강에 의해 반사된 반사광을 수신함으로써, 대상체의 구강에 대한 이미지를 획득할 수 있다. 카메라는, 예를 들어, 광 삼각 측량 방식에 따라서 3차원 이미지를 구축하기 위하여, 좌안 시야에 대응되는 좌측 카메라 및 우안 시야에 대응되는 우측 카메라를 포함할 수 있다. 카메라 는, CCD 센서 또는 CMOS 센서와 같은 적어도 하나의 이미지 센서를 포함할 수 있다.다양한 실시예에 따른 3차원 스캐너의 입력 장치는 3차원 스캐너를 제어하기 위한 사용자 입력 을 수신할 수 있다. 입력 장치는 사용자의 푸시 조작을 수신하는 버튼, 사용자의 터치를 감지하 는 터치 패널, 마이크를 포함하는 음성 인식 장치를 포함할 수 있다. 예를 들어, 사용자는 입력 장치(20 6)를 이용하여 스캐닝 시작 또는 정지를 제어할 수 있다. 다양한 실시예에 따른 3차원 스캐너의 센서 모듈은 3차원 스캐너의 작동 상태 또는 외부의 환경 상태(예: 사용자의 동작)을 감지하고, 감지된 상태에 대응하는 전기 신호를 생성할 수 있다. 센서 모듈은, 예를 들어, 자이로 센서, 가속도 센서, 제스처 센서, 근접 센서 또는 적외선 센서 중 적어도 하나 를 포함할 수 있다. 사용자는 센서 모듈을 이용하여 스캐닝 시작 또는 정지를 제어할 수 있다. 예를 들어, 사용자가 3차원 스캐너를 손에 쥐고 움직이는 경우, 3차원 스캐너는 센서 모듈을 통 해 측정된 각속도가 기 설정된 임계 값을 초과할 때, 프로세서 스캐닝 동작을 시작하도록 제어할 수 있다. 일 실시예에 따르면, 3차원 스캐너는, 3차원 스캐너의 입력 장치 또는 전자 장치의 입력 장치를 통해 스캔을 시작하기 위한 사용자 입력을 수신하거나, 3차원 스캐너의 프로세서 또는 전자 장치의 프로세서에서의 처리에 따라, 스캔을 시작할 수 있다. 사용자가 3차원 스캐너(20 0)를 통해 대상체의 구강 내부를 스캔하는 경우, 3차원 스캐너는 대상체의 구강에 대한 2차원 이 미지를 생성할 수 있고, 실시간으로 대상체의 구강에 대한 2차원 이미지를 전자 장치로 전송할 수 있 다. 전자 장치는 수신한 대상체의 구강에 대한 2차원 이미지를 디스플레이를 통해 표시할 수 있다. 또한, 전자 장치는 대상체의 구강에 대한 2차원 이미지에 기초하여, 대상체의 구강에 대한 3차원 이미지를 생성(구축)할 수 있으며, 구강에 대한 3차원 이미지를 디스플레이를 통해 표시할 수 있다. 전자 장치 는 생성되고 있는 3차원 이미지를 실시간으로 디스플레이를 통해 표시할 수도 있다. 다양한 실시예에 따른 전자 장치는 하나 이상의 프로세서, 하나 이상의 메모리, 통신 회로 , 디스플레이 및/또는 입력 장치를 포함할 수 있다. 전자 장치에 포함된 구성요소들 중 적어도 하나가 생략되거나, 다른 구성요소가 전자 장치에 추가될 수 있다. 추가적으로 또는 대체적으로 일부의 구성요소들이 통합되어 구현되거나, 단수 또는 복수의 개체로 구현될 수 있다. 전자 장치 내의 적 어도 일부의 구성요소들은 버스(bus), GPIO(general purpose input/output), SPI(serial peripheral interface) 또는 MIPI(mobile industry processor interface) 등을 통해 서로 연결되어, 데이터 및/또는 시그 널을 주고 받을 수 있다. 다양한 실시예에 따르면, 전자 장치의 하나 이상의 프로세서는 전자 장치의 각 구성요소들(예: 메모리)의 제어 및/또는 통신에 관한 연산이나 데이터 처리를 수행할 수 있는 구성일 수 있다. 하나 이상 의 프로세서는, 예를 들어, 전자 장치의 구성요소들과 작동적으로 연결될 수 있다. 하나 이상의 프 로세서는 전자 장치의 다른 구성요소로부터 수신된 명령 또는 데이터를 하나 이상의 메모리에 로드(load)하고, 하나 이상의 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 저장할 수 있 다. 다양한 실시예에 따르면, 전자 장치의 하나 이상의 메모리는 하나 이상의 프로세서의 동작에 대 한 인스트럭션들을 저장할 수 있다. 하나 이상의 메모리는 기계 학습 알고리즘에 따라 구축된 상관 모델 들을 저장할 수 있다. 하나 이상의 메모리는 3차원 스캐너로부터 수신되는 데이터(예를 들어, 구강 스캔을 통하여 획득된 구강에 대한 2차원 이미지)를 저장할 수 있다. 다양한 실시예에 따르면, 전자 장치의 통신 회로는 외부 장치(예: 3차원 스캐너, 클라우드 서버)와 유선 또는 무선 통신 채널을 설립하고, 외부 장치와 다양한 데이터를 송수신할 수 있다. 일 실시예에 따르면, 통신 회로는 외부 장치와 유선으로 통신하기 위해서, 외부 장치와 유선 케이블로 연결되기 위한 적어도 하나의 포트를 포함할 수 있다. 상기의 경우, 통신 회로는 적어도 하나의 포트를 통하여 유선 연 결된 외부 장치와 통신을 수행할 수 있다. 일 실시예에 따르면, 통신 회로는 셀룰러 통신 모듈을 포함하 여 셀룰러 네트워크(예: 3G, LTE, 5G, Wibro 또는 Wimax)에 연결되도록 구성할 수 있다. 다양한 실시예에 따르 면, 통신 회로는 근거리 통신 모듈을 포함하여 근거리 통신(예를 들면, Wi-Fi, Bluetooth, Bluetooth Low Energy(BLE), UWB)을 이용해 외부 장치와 데이터 송수신을 할 수 있으나, 이에 제한되지 않는다. 일 실시예에 따르면, 통신 회로는 비접촉식 통신을 위한 비접촉 통신 모듈을 포함할 수 있다. 비접촉식 통신은, 예를 들면, NFC(near field communication) 통신, RFID(radio frequency identification) 통신 또는 MST(magnetic secure transmission) 통신과 같이 적어도 하나의 비접촉 방식의 근접 통신 기술을 포함할 수 있다. 다양한 실시예에 따른 전자 장치의 디스플레이는 프로세서의 제어에 기반하여 다양한 화면을 표 시할 수 있다. 프로세서는 3차원 스캐너로부터 수신한 대상체의 구강에 대한 2차원 이미지 및/ 또는 구강의 내부 구조를 3차원적으로 모델링한 구강에 대한 3차원 이미지를 디스플레이를 통해 표시할 수 있다. 예를 들어, 특정 응용 프로그램을 통해 구강에 대한 2차원 이미지 및/또는 3차원 이미지를 표시할 수 있 다. 상기의 경우, 사용자는 구강에 대한 2차원 이미지 및/또는 3차원 이미지를 편집, 저장 및 삭제할 수 있다. 다양한 실시예에 따른 전자 장치의 입력 장치는, 전자 장치의 구성요소(예: 하나 이상의 프로세 서)에 사용될 명령 또는 데이터를 전자 장치의 외부(예: 사용자)로부터 수신할 수 있다. 입력 장치 는, 예를 들면, 마이크, 마우스 또는 키보드를 포함할 수 있다. 일 실시예에 따르면, 입력 장치는 디스플레이와 결합되어 다양한 외부 객체의 접촉 또는 근접을 인식할 수 있는 터치 센서 패널의 형태로 구 현될 수도 있다. 도 2b는 본 개시의 일 실시예에 따른 3차원 스캐너의 사시도이다. 다양한 실시예에 따른 3차원 스캐너 는 본체 및 프로브 팁을 포함할 수 있다. 3차원 스캐너의 본체는 사용자가 손으 로 그립하여 사용하기 용이한 모양으로 형성될 수 있다. 프로브 팁은 대상체의 구강으로 인입 및 인 출이 용이한 모양으로 형성될 수 있다. 또한, 본체는 프로브 팁과 결합 및 분리될 수 있다. 본체 내부에는, 도 2a에서 설명한 3차원 스캐너의 구성요소들이 배치될 수 있다. 본체의 일측 단부 에는 광원로부터 출력된 광이 대상체에 조사될 수 있도록 개구된 개구부가 형성될 수 있다. 개구부를 통해 조사된 광은, 대상체에 의해 반사되어 다시 개구부를 통해 유입될 수 있다. 개구부를 통해 유입된 반 사광은 카메라에 의해 캡쳐되어 대상체에 대한 이미지를 생성할 수 있다. 사용자는 3차원 스캐너(20 0)의 입력 장치(예: 버튼)를 이용하여 스캔을 시작할 수 있다. 예를 들어, 사용자가 입력 장치 를 터치하거나 가압하는 경우, 광원으로부터 광이 대상체에 조사될 수 있다. 일 실시예에 있어서, 사용자는 3차원 스캐너를 움직여가면서 대상체의 구강 내부를 스캔할 수 있 고, 이 경우, 3차원 스캐너는 대상체의 구강에 대한 적어도 하나의 2차원 이미지를 획득할 수 있다. 예를 들어, 3차원 스캐너는 대상체의 앞니가 포함된 영역에 대한 2차원 이미지, 대상체의 어금니 가 포함된 영역에 대한 2차원 이미지 등을 획득할 수 있다. 3차원 스캐너는 획득한 적어도 하나의 2차원 이미지를 전자 장치로 전송할 수 있다. 다른 실시예에 따르면, 사용자는 3차원 스캐너를 움직여가면서, 진단 모델을 스캔할 수도 있고, 그 과 정에서 진단 모델에 대한 적어도 하나의 2차원 이미지를 획득할 수도 있다. 이하에서는, 설명의 편의를 위하여, 대상체의 구강 내부를 스캐닝함으로써, 대상체의 구강에 대한 이미지를 획득하는 경우를 가정 하여 설명하도록 하지만, 이에 제한되는 것은 아니다. 도 3은 본 개시의 일 실시예에 따른 2차원 이미지 셋 및 3차원 스캔 데이터를 도시한 예시도이다. 본 개시의 일 실시예에 따른 전자 장치는 3차원 스캐너의 스캔에 의해, 적어도 하나의 2차원 이미지를 포함하는 2차원 이미지 셋을 획득하고, 획득한 2차원 이미지 셋에 기초하여 대상체에 관한 3차원 스캔 데 이터를 생성할 수 있다. 3차원 스캔 데이터는 3차원 좌표 평면 상에 표현될 수 있는 데이터로서, 복 수의 3차원 좌표값을 포함할 수 있다. 예를 들어, 전자 장치는 3차원 스캔 데이터로서, 3차원 좌표 값을 갖는 데이터 포인트의 집합인 포인트 클라우드(point cloud) 데이터 셋을 생성할 수 있다. 전자 장치 는, 포인트 클라우드 데이터 셋을 정렬(align)함으로써, 보다 적은 수의 데이터 포인트를 포함하는 3차원 스캔 데이터를 생성할 수 있다. 전자 장치는 3차원 스캔 데이터를 재구성(재구축)하여 갱신된 3차원 스캔 데이터를 생성할 수 있다. 예를 들어, 전자 장치는 푸아송 알고리즘을 사용하여, 로우 데이터로서 저장된 3차원 스캔 데이터의 적어도 일부 데이터를 병합하고, 복수의 데이터 포인트들을 재구성함으로써, 3차원 스캔 데이터에 포함된 데이터 포인트들이 시각적으로 표현되었을 때 폐쇄된 3차원 표면이 되도록 3차원 스캔 데이터 를 재구성할 수 있다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 동작 흐름도이다. 프로세서는, 단계 S410에서, 3차원 스 캐너로부터, 3차원 스캐너의 스캔에 의해 생성된 대상체에 관한 2차원 이미지 셋을 획득할 수 있다. 2차원 이미지 셋은 적어도 하나의 2차원 이미지를 포함할 수 있다. 본 개시에서 2차원 이미지 셋은, 3차원 스 캐너의 카메라와 대상체가 공간 상에서 서로 동일한 위치 관계를 유지하되, 스캔된 이미지의 상 태에 영향을 주는 광원이 서로 상이하게 제어되어 획득된 2차원 이미지들로 구성될 수 있다. 예컨대, 2차 원 이미지 셋은, 3차원 스캐너가, 카메라를 통해 대상체를 동일한 시점(viewpoint)에서 바라보면 서 광원의 색상, 광원에 의해 조사되는 광의 패턴 유무, 광원에 의해 조사되는 광 패턴의 간격또는 종류 등을 서로 상이하게 제어한 결과 생성된 적어도 하나의 2차원 이미지로 구성될 수 있다. 도 5는 본 개시의 일 실시예에 따른 2차원 이미지 셋에 포함되는 이미지를 나타낸 예시도이다. 2차원 이미지 셋은, 3차원 스캐너를 통해 대상체에 패턴이 있는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지 및 3 차원 스캐너를 통해 대상체에 패턴이 없는 광을 조사함으로써 획득된 적어도 하나의 2차원 이미지를 포함할 수 있다. 이하에서는 설명의 편의상 \"대상체에 패턴이 있는 광을 조사함으로써 획득된 2차원 이미지\"는 패턴이 있 는 이미지, \"대상체에 패턴이 없는 광을 조사함으로써 획득된 2차원 이미지\"는 패턴이 없는 이미지로 각각 간략 히 호칭될 수 있다. 패턴이 있는 이미지들(510a 내지 510g)은 3차원 스캐너가 대상체에 소정의 패턴 이 있는 광을 조사하고, 대상체로부터 반사된 패턴 광을 3차원 스캐너가 촬상함으로써 획득될 수 있다. 패턴이 있는 이미지들(510a 내지 510g)은 3차원 스캐너가 대상체를 향해 조사하는 패턴에 따라서 서로 구 별될 수 있으며 예를 들어, 패턴의 모양, 패턴의 간격, 패턴 내 명암비 등에 따라 구별될 수 있다. 패턴이 없 는 이미지들(530a 내지 530c)은 3차원 스캐너가 대상체에 패턴이 없는 광을 조사하고, 대상체로부터 반사된 광을 3차원 스캐너가 촬상함으로써 획득될 수 있다. 패턴이 없는 이미지들(530a 내지 530c)은 3차 원 스캐너가 대상체를 향해 조사하는 빛의 파장 및/또는 색상에 따라서 서로 구별될 수 있으며 예를 들어, 조사된 광의 색상이 적색(Red), 녹색(Green), 청색(Blue) 등으로 다름에 따라 서로 구별될 수 있다. 본 개시에 서, 패턴이 있는 이미지는 프로세서가 대상체에 관한 3차원 스캔 데이터를 생성할 때 이용하는 깊이 정보 및 형상 정보를 포함할 수 있다. 또한, 패턴이 없는 이미지는 프로세서가 대상체에 관한 3차원 스캔 데이 터를 생성할 때 이용하는 색상 정보를 포함할 수 있다. 상술한 바와 같이 본 개시는 적어도 하나의 패턴이 있 는 이미지와 적어도 하나의 패턴이 없는 이미지를 포함하는 2차원 이미지 셋에 기초하여 3차원 스캔 데이터를 생성함으로써 대상체를 촬상한 복수의 2차원 이미지로부터 대상체에 관한 3차원 스캔 데이터를 생성할 수 있다. 프로세서는, 단계 S420에서, 2차원 이미지 셋에 기초하여, 인공 신경망에 입력 이미지를 입력할 수 있다. 인공 신경망에 입력되는 입력 이미지는 2차원 이미지 셋에 기초하여 생성될 수 있다. 본 개시의 일 실시예에 있어서, 인공 신경망에 입력되는 입력 이미지는, 대상체에 패턴이 없는 광을 조사함으로 써 획득된 적어도 하나의 2차원 이미지에 기초하여 생성될 수 있다. 도 5를 다시 참조하면, 인공 신경망에 입 력되는 입력 이미지는 예를 들어, 패턴이 없는 적색 광을 대상체에 조사하여 획득된 2차원 이미지(530a), 패턴 이 없는 녹색 광을 대상체에 조사하여 획득된 2차원 이미지(530b), 패턴이 없는 청색 광을 대상체에 조사하여 획득된 2차원 이미지(530c) 중 적어도 하나에 기초하여 생성될 수 있다. 프로세서는 패턴이 없는 단색 광 을 조사함으로써 획득된 패턴이 없는 이미지를 인공 신경망에 입력되는 입력 이미지로 사용함으로써, 특정 파장 대의 광에서 보다 잘 검출되는 영역을 인공 신경망을 통해 잘 검출할 수 있다. 본 개시의 추가적인 실시예에 있어서, 프로세서는 3차원 스캐너가 패턴이 없는 백색 광을 대상체에 조사함으로써 획득된 2차원 이 미지로부터 인공 신경망에 입력되는 입력 이미지를 생성할 수도 있다. 여기서 3차원 스캐너가 대상체를 향해 조사하는 백색 광은 적색 광, 녹색 광 및 청색 광이 혼합된 결과로서 조사되는 광일 수 있다. 본 개시의 일 실시예에 있어서, 인공 신경망에 입력되는 입력 이미지는 RGB 이미지일 수 있다. 이 때, 프로세 서는 인공 신경망에 입력 이미지를 입력하기 위해, 2차원 이미지 셋에 포함되고 단일 색상 정보를 획득하 기 위한 둘 이상의 2차원 이미지를 이용하여 RGB 이미지를 생성하고, 생성된 RGB 이미지를 인공 신경망에 입력 할 수 있다. 프로세서는 패턴이 없는 적색 광을 대상체에 조사하여 획득된 2차원 이미지(530a), 패턴이 없는 녹색 광을 대상체에 조사하여 획득된 2차원 이미지(530b) 및 패턴이 없는 청색 광을 대상체에 조사하여 획 득된 2차원 이미지(530c)를 통합하여 하나의 RGB 이미지를 생성하고 이를 인공 신경망에 입력할 수 있다. 예를 들어, 단색 광에 따른 2차원 이미지의 각 픽셀은, 해당 단색 광의 밝기 또는 세기에 따른 하나의 스칼라 값을 가질 수 있다. 이 때 프로세서는 각 픽셀별 단색 광의 스칼라 값을 통해 해당 픽셀의 RGB 값(RGB 벡터)를 생성할 수 있다. 구체적으로, 패턴이 없는 이미지들(530a 내지 530c) 내의 특정 위치의 픽셀이 갖는 값이 각각 2차원 이미지(530a) 내에서 210, 2차원 이미지(530b) 내에서 112, 2차원 이미지(530c) 내에서 0인 경우, 프로세 서는 해당 특정 위치의 픽셀이 갖는 RGB 값을 (210, 112, 0)으로 결정할 수 있다. 프로세서는 위와 같은 방법으로 단일 색상 정보를 획득하기 위한 둘 이상의 2차원 이미지를 이용하여 RGB 이미지를 생성할 수 있 다. 프로세서는 생성된 RGB 이미지를 인공 신경망에 입력하여, 입력 이미지 내에서 제1 영역을 검출할 수 있다. 본 개시의 추가적인 실시예에 있어서, 3차원 스캐너가 패턴이 없는 백색 광을 대상체에 조사하고 그에 따라 프로세서가 2차원 이미지를 획득할 경우, 해당 2차원 이미지는 RGB 이미지일 수 있다. 도 6은 본 개시의 일 실시예에 따른 인공 신경망의 입출력 데이터를 개념적으로 나타낸 도면이다. 본 개시의 인공 신경망은 대상체에 관한 이미지 내에서 적어도 하나의 사전 결정된 영역을 검출하도록 학습된 인공 신경망일 수 있다. 여기서, 인공 신경망이 입력받는 \"대상체에 관한 이미지\"는, 전술한 바와 같이 3차원 스캐너에 의해 생성된 대상체에 관한 2차원 이미지 셋으로부터 생성된 이미지일 수 있다. 본 개시의 일 실시예에 따른 인공 신경망은, 입력 이미지에 포함된 적어도 하나의 픽셀을 적어도 하나의 사전 결정된 영역 중 대응되는 영역으로 분류함으로써 입력 이미지에 대한 세그멘테이션(segmentation) 결과를 출력하도록 학습될 수 있다. 본 개시에 있어서, 인공 신경망을 통해 분류되는 적어도 하나의 사전 결정된 영역은 예를 들어, 치은, 치아, 금속, 혀, 볼, 입술, 진단 모델 등을 포함할 수 있다. 본 개시의 인공 신경망 은 이미지의 각 픽셀별로 대응되는 영역의 번호가 라벨링된 하나 이상의 학습 이미지에 기초하여 학습될 수 있다. 인공 신경망은 학습 이미지를 입력받아 각 픽셀에 대해 대응되는 영역을 출력하고, 이를 라벨링 된 데이터와 비교한 후, 비교 결과에 따른 오차를 역전파(backpropagation)시키는 방식으로 노드 가중치를 갱신 함으로써 학습될 수 있다. 인공 신경망에 포함되는 복수의 노드 가중치, 편향값 또는 파라미터 등은 전자 장치 내에서 프로세서에 의해 학습될 수 있고, 외부 장치에서 학습된 후 전자 장치로 전송되어 프로세서에 의해 이용될 수도 있다. 프로세서는 학습된 인공 신경망에 입력 이미지를 입력하고, 인공 신경망으로부터 입력 이미지에 포함된 적어도 하나의 픽셀을 적어도 하나의 사전 결정된 영역 중 대응되는 영역으로 분류하는 세그멘테이션 결과를 획득할 수 있다. 도 7은 본 개시의 일 실시예에 따른 인공 신경망의 입출력 데이터를 예시적으로 나타낸 도면이다. 인공 신경망 은 입력 이미지를 입력받아 각 픽셀을 적어도 하나의 사전 결정된 영역으로 분류한 세그멘테이션 결 과를 출력할 수 있다. 참조번호 730은 시각적으로 표현된 세그멘테이션 결과를 나타낸다. 인공 신경망의 출력 데이터인 세그멘테이션 결과는 적어도 하나의 사전 결정된 영역을 포함할 수 있다. 예컨대, 세그멘테이션 결과는 그 대응되는 영역에 따라 A 영역, B 영역 및 C 영역을 포함할 수 있으며, 입력 이 미지 내에서 A 영역은 치은에 해당하는 영역, B 영역은 치아에 해당하는 영역, C 영역은 금속에 해당하는 영역일 수 있다. 프로세서는, 단계 S430에서, 인공 신경망의 출력에 기초하여 입력 이미지 내에서 제1 영역을 검출할 수 있 다. 본 개시의 일 실시예에 따른 프로세서가 인공 신경망의 출력에 기초하여 검출하는 제1 영역은 대상체 에 관한 이미지 상에서 금속에 해당하는 영역일 수 있다. 구체적으로, 금속에 해당하는 영역은 예를 들어, 대 상체에 관한 이미지 상에서 교정을 위한 와이어, 보철 등에 해당하는 영역일 수 있다. 예컨대, 프로세서 가 제1 영역으로서 검출하는 영역이 금속에 해당하는 영역일 경우, 프로세서는 인공 신경망의 출력인 세그 멘테이션 결과에서 C 영역을 제1 영역으로서 검출할 수 있다. 본 개시에서 제1 영역은 대상체에 관 한 3차원 스캔 데이터에서 제외되고자 하는 영역일 수 있으며, 이 경우 제1 영역은 \"제외 대상 영역\"으로 상호 교환적으로 호칭될 수 있다. 프로세서는, 단계 S440에서, 제1 영역에 기초하여 대상체에 관한 3차원 스캔 데이터를 생성할 수 있다. 본 개시의 일 실시예에 따른 프로세서는 2차원 이미지 셋에 기초하여 3차원 스캔 데이터를 생성하되 제1 영역에 대응되는 좌표는 3차원 스캔 데이터에 포함되지 않도록, 3차원 스캔 데이터를 생성할 수 있다. 구체적 으로, 본 개시의 일 실시예에 따른 프로세서는 2차원 이미지 셋에 기초하여 상기 3차원 스캔 데이터를 생 성할 때, 2차원 이미지 셋에 포함된 각각의 2차원 이미지 내에서 제1 영역에 대응되는 픽셀의 값을 연산 대상에 서 제외하고 3차원 스캔 데이터를 생성할 수 있다. 예를 들어, 2차원 이미지 셋에 포함된 복수의 2차원 이미지 들은 각각 동일한 객체를 서로 다른 패턴 또는 색상을 가진 광으로 촬영한 이미지일 있다. 이 경우 복수의 2차 원 이미지들은 서로 동일한 기준 좌표계(예: 2차원 좌표계)를 공유할 수 있다. 따라서, 프로세서는 2차원 이미지 셋에 포함된 각각의 2차원 이미지 내에서도 인공 신경망에 의해 검출된 제1 영역과 동일한 위치의 영역 을 결정할 수 있다. 그 결과 프로세서는 2차원 이미지 셋에 포함된 각각의 2차원 이미지 내에서 제1 영역 에 대응되는 픽셀의 값을 제외하고 3차원 스캔 데이터 생성함으로써 제외 대상 영역이 제외된 3차원 스캔 데이 터를 생성할 수 있다. 본 개시의 일 실시예에 따른 프로세서는 제1 영역에 기초하여 대상체에 관한 3차원 스캔 데이터를 생성하 기 위해, 2차원 이미지 셋에 포함된 적어도 하나의 2차원 이미지 내에서 제1 영역과 대응되는 영역의 데이터를 제거할 수 있다. 예를 들어, 프로세서는 2차원 이미지 셋에 포함된 적어도 하나의 2차원 이미지 내에서 제1 영역과 대응되는 영역에 포함된 픽셀의 값을 사전 설정된 값으로 변경할 수 있다. 사전 설정된 값은 디폴 트 값으로 지칭될 수 있으며, 예를 들어 \"-1\" 또는 \"0\" 등의 실수일 수 있다. 프로세서는 2차원 이미지 내의 제1 영역에 대응되는 픽셀의 값을 사전 설정된 값으로 변경함으로써 제1 영역에 대응되는 픽셀의 값이 나 타내는 정보를 제거할 수 있다. 제1 영역에 대응되는 픽셀의 값을 사전 결정된 값으로 변경함으로써, 프로세서 는 2차원 이미지 상의 해당 픽셀을 3차원 이미지 생성 시 연산 대상에서 배제할 수 있다. 본 개시의 일 실시예에 따른 프로세서는 제1 영역과 대응되는 영역의 데이터가 제거된 적어도 하나의 2차 원 이미지를 이용하여 3차원 스캔 데이터를 생성할 수 있다. 프로세서는 3차원 스캐너로부터 획득되 는 2차원 이미지 셋에 기초하여 제외의 대상이 되는 제1 영역(예: 금속 영역)을 2차원 이미지 상에서 검출하고, 검출 결과에 따라 2차원 이미지로부터 제1 영역을 제거함으로써, 3차원 스캔 데이터를 생성하기 전에 미리 제외 의 대상이 되는 영역을 연산 대상에서 배제할 수 있다. 그 후 프로세서는 생성된 3차원 스캔 데이터를 디 스플레이에 표시할 수 있다. 이와 같이 본 개시에 따른 프로세서는 3차원 스캔 데이터가 생성된 이 후에 생성된 3차원 스캔 데이터 내에서 제외 대상 영역을 제거하는 방법과 달리, 2차원 이미지를 획득하는 단계 에서 2차원 이미지의 획득과 동시에 실시간으로 2차원 이미지로부터 제외 대상 영역을 제거하고, 제외 대상 영 역이 제거된 적어도 하나의 2차원 이미지에 기초하여 3차원 스캔 데이터를 생성하는 방법을 수행함으로써, 연산 대상이 되는 데이터의 사이즈를 줄여 연산 부담을 낮추고 전체 연산 속도를 증가시킬 수 있다. 도 8은 본 개시의 일 실시예에 따른 3차원 스캔 데이터를 예시적으로 나타낸 도면이다. 참조번호 810 및 830은, 대상체에 관한 3차원 스캔 데이터에서 금속에 해당하는 영역이 포함된 경우와 제외된 경우를 각각 도시 한다. 본 개시에 따른 프로세서는 제1 영역에 기초하여 대상체에 관한 3차원 스캔 데이터를 생성할 때, 제1 영역에 대응되는 좌표는 3차원 스캔 데이터에 포함되지 않도록 할 수 있기 때문에, 사용자가 희망하지 않는 영역은 3차원 스캔 데이터 내에서 표현되지 않도록 할 수 있다. 이를 통해, 본 개시는 검진 또는 치료를 위해 불필요한 정보를 스캔 데이터 상에서 배제하고, 필요한 정보(환자의 고유 구강 정보)를 보다 정확하고 간결하게 사용자에게 제공할 수 있다. 본 개시의 추가적인 실시예예 따른 프로세서는 인공 신경망의 출력에 기초하여 입력 이미지 내에서 서로 다른 복수의 제1 영역을 검출하고, 검출된 복수의 제1 영역이 서로 구별되도록 3차원 스캔 데이터를 생성 할 수 있다. 프로세서는 3차원 스캔 데이터 내에서 복수의 제1 영역을 서로 구별하기 위해 예를 들어, 검 출된 각각의 제1 영역에 해당하는 픽셀을 3차원 스캔 데이터 내에서 서로 다른 숫자로 라벨링할 수 있다. 도 9는 본 개시의 일 실시예에 따라 복수의 제1 영역이 서로 구별되도록 생성된 3차원 스캔 데이터를 시각적으 로 표현한 예시도이다. 도 9에 도시된 3차원 스캔 데이터는, 볼 안쪽 영역, 치아 영역, 및 치은 영 역을 복수의 제1 영역으로서 포함한다. 프로세서는 3차원 스캐너를 통해 획득된 2차원 이미지 셋에 기초하여 인공 신경망에 입력될 입력 이미지를 생성하고, 생성된 입력 이미지를 인공 신경망에 입력하여 세그멘 테이션 결과를 획득함으로써, 복수의 제1 영역이 서로 구별되는 3차원 스캔 데이터를 생성할 수 있다. 이러한 3차원 스캔 데이터에 포함된 복수의 제1 영역들이 사용자에게 시각적으로 구분되어 제공될 경우, 사용자는 3차 원 스캔 데이터 내에 포함된 서로 다른 복수의 제1 영역을 빠르고 편리하게 구별할 수 있다. 본 개시의 추가적인 실시예에 따른 프로세서는 사용자로부터 입력 장치를 통해 제1 영역의 포함 여부 에 관한 사용자 입력을 획득할 수 있다. 프로세서는 3차원 스캔 데이터를 생성할 때, 획득된 사용자 입력 에 따라 3차원 스캔 데이터에 제1 영역에 대응되는 좌표가 포함되는지 여부를 결정할 수 있다. 도 10은 3차원 스캔 데이터 내에서 특정 영역의 포함 여부에 관한 사용자 입력을 수신하기 위한 사용자 인터페 이스 화면을 예시적으로 나타낸 도면이다. 도 10의 사용자 인터페이스 화면은 전자 장치의 디스플 레이를 통해 사용자에게 제공될 수 있다. 사용자는 사용자 인터페이스 화면의 소정의 영역을 터치 함으로써 전자 장치로 사용자 입력을 전송할 수 있다. 일례로, 사용자는 사용자 인터페이스 화면 내에서 \"치아\"에 관한 서브 화면을 통해 프로세서가 생성할 3차원 스캔 데이터 내에 \"치아\" 영역이 포함될 지 여부에 대한 사용자 입력을 전자 장치로 전송할 수 있다. 예를 들어 사용자는, \"치아\"에 관한 서브 화면을 터치함으로써 3차원 스캔 데이터 내에 \"치아\" 영역이 포함되지 않도록(Off) 할 수 있다. 프 로세서는 \"치아\"에 관한 서브 화면에 대해 아무런 사용자 입력이 수신되지 않을 경우(즉, default 상태의 경우) 3차원 스캔 데이터 내에 \"치아\" 영역을 포함시키도록 설정될 수 있다. 다른 일례로, 사용자는 사 용자 인터페이스 화면 내에서 \"금속\"에 관한 서브 화면을 통해 3차원 스캔 데이터 내에 \"금속\" 영 역의 포함 여부에 대한 사용자 입력을 전자 장치로 전송할 수 있다. 본 개시의 일 실시예에 있어서, 프로세서는 사용자 인터페이스 화면을 통해 복수의 제1 영역 각각의 포함 여부에 관한 사용자 입력을 획득할 수 있다. 프로세서는 복수의 제1 영역 각각의 포함 여부를 결정 할 수 있는 복수의 서브 화면들을 사용자에게 제공할 수 있다. 복수의 서브 화면들 각각에 대한 조작을 통해 사용자는 혀, 입술, 치아, 금속 등의 복수의 제1 영역 중 3차원 스캔 데이터 상에 표현되어야 하는 영역과 제외 되어야 하는 영역을 구분하고 그에 따른 3차원 스캔 데이터를 생성할 수 있다. 또한, 사용자는 금속 중에서도 교정 장치에 대응되는 제1 영역 및 보철 장치에 대응되는 제1 영역을 서로 구분할 수 있다. 상기 방법은 특정 실시예들을 통하여 설명되었지만, 상기 방법은 또한 컴퓨터로 읽을 수 있는 기록매체에 컴퓨 터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의 해 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장장치 등을 포함할 수 있다. 또한, 컴퓨 터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고, 상기 실시예들을 구현하기 위한 기능적인(functional) 프로그"}
{"patent_id": "10-2022-0065542", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "램, 코드 및 코드 세그먼트들은 본 개시가 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다. 이상 일부 실시예들과 첨부된 도면에 도시된 예에 의해 본 개시의 기술적 사상이 설명되었지만, 본 개시가 속하 는 기술 분야에서 통상의 지식을 가진 자가 이해할 수 있는 본 개시의 기술적 범위를 벗어나지 않는 범위에서 다양한 치환, 변형 및 변경이 이루어질 수 있다는 점을 알아야 할 것이다. 또한, 그러한 치환, 변형 및 변경은 첨부된 청구범위 내에 속하는 것으로 생각되어야 한다."}
{"patent_id": "10-2022-0065542", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 3차원 스캐너를 이용하여 환자의 구강에 대한 이미지를 획득하는 모습을 도 시한 도면이다. 도 2a는 본 개시의 일 실시예에 따른 전자 장치 및 3차원 스캐너의 블록도이다. 도 2b는 본 개시의 일 실시예에 따른 3차원 스캐너의 사시도이다. 도 3은 본 개시의 일 실시예에 따른 2차원 이미지 셋 및 3차원 스캔 데이터를 도시한 예시도이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 동작 흐름도이다. 도 5는 본 개시의 일 실시예에 따른 2차원 이미지 셋에 포함되는 이미지를 나타낸 예시도이다.도 6은 본 개시의 일 실시예에 따른 인공 신경망의 입출력 데이터를 개념적으로 나타낸 도면이다. 도 7은 본 개시의 일 실시예에 따른 인공 신경망의 입출력 데이터를 예시적으로 나타낸 도면이다. 도 8은 본 개시의 일 실시예에 따른 3차원 스캔 데이터를 예시적으로 나타낸 도면이다. 도 9는 본 개시의 일 실시예에 따라 복수의 제1 영역이 서로 구별되도록 생성된 3차원 스캔 데이터를 시각적으 로 표현한 예시도이다. 도 10은 3차원 스캔 데이터 내에서 특정 영역의 포함 여부에 관한 사용자 입력을 수신하기 위한 사용자 인터페 이스 화면을 예시적으로 나타낸 도면이다."}
