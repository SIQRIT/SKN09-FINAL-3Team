{"patent_id": "10-2009-0037594", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2010-0118744", "출원번호": "10-2009-0037594", "출원인": "재단법인 포항지능로봇연구소", "발명자": "이청재"}}
{"patent_id": "10-2009-0037594", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 기반 자연어 대화 장치에 있어서,음성의 사용자 발화를 입력받는 입력부;상기 입력부에서 입력받은 사용자 발화를 인식 신뢰도 점수에 따라 내림차순으로 정렬하고, 그 중 상위 N개의음성 인식 가설을 생성하는 음성 인식부;상기 음성 인식부에서 생성된 상기 N개의 음성 인식 가설과 대응되는 N개의 의미 구조체를 생성하는 입력 이해부;상기 N개의 음성 인식 가설과 상기 N개의 의미 구조체를 포함하는 사용자 입력에 의한 대화 예제와 아젠다(agenda)를 이용하여 인공 지능 에이전트(agent)의 행위를 추정하고 컨텐츠(contents)를 선택하는 대화 처리부;상기 대화 처리부에서 상기 사용자 입력이 처리되지 못한 경우 사용자에게 도움말을 제공하는 오류 처리부;상기 대화 처리부에서 추정된 인공지능 에이전트의 행위 및 선택된 컨텐츠를 이용하여 에이전트 발화를 생성하고 상기 행위 및 컨텐츠에 관한 정보를 화면상에 출력하는 출력 생성부;상기 에이전트 발화를 음성으로 합성하여 출력하는 음성 합성부를 포함하는 것을 특징으로 하는 음성 기반 자연어 대화 장치."}
{"patent_id": "10-2009-0037594", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 인식 신뢰도 점수는 언어 모델을 이용하여 문장의 자연스러운 정도를 수치화한 것 또는 음향 모델을 이용하여 기존에 추정되었던 문장과 일치하는 정도를 수치화한 것을 특징으로 하는 음성 기반 자연어 대화 장치."}
{"patent_id": "10-2009-0037594", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 대화 처리부는 상기 사용자 입력 중에서 현재 대화 상황에서 가능한 노드와 그에 상응하는 사용자 입력을선택하는 노드 선택부; 및상기 노드 선택부에서 선택된 노드와 사용자 입력을 이용하여 대화 예제를 선택하는 예제 선택부를 포함하는 것을 특징으로 하는 음성 기반 자연어 대화 장치."}
{"patent_id": "10-2009-0037594", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 도움말은 아젠다 도움말과 발화 도움말을 포함하며,상기 노드 선택부에서 노드 선택에 실패할 경우 상기 아젠다 도움말을 제공하며, 상기 예제 선택부에서 예제 선택에 실패할 경우 상기 발화 도움말을 제공하는 것을 특징으로 하는 음성 기반 자연어 대화 장치."}
{"patent_id": "10-2009-0037594", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "음성 기반 자연어 대화 방법에 있어서,음성의 사용자 발화를 입력받아 음성 인식 가설과 의미 구조체를 생성하는 단계;상기 생성된 음성 인식 가설과 의미 구조체를 바탕으로 인공 지능 에이전트의 행위를 추정하는 단계;상기 추정이 이루어지지 않을 경우 도움말을 제공하는 단계;상기 추정된 에이전트의 행위를 바탕으로 에이전트 발화를 생성하고 이를 출력하는 단계를 포함하는 것을 특징으로 하는 음성 기반 자연어 대화 방법.공개특허 10-2010-0118744-3-명 세 서발명의 상세한 설명 기 술 분 야본 발명은 자연어 대화 장치 및 그 방법에 관한 것으로, 보다 상세하게는 사용자와 자동 안내 인공 지능 에이전 [0001]트 간에 음성 인식 오류에 강인한 음성 기반 자연어 대화 장치 및 그 방법에 관한 것이다. 배 경 기 술일반적으로 인공 지능 에이전트의 입력 장치로 키보드와 마우스가 이용된다. 그러나 키보드와 마우스는 입력을 [0002]위해서 항상 손을 사용해야 한다는 점에서 최근의 다양한 환경에 적합하지 않다. 따라서, 자동차나 지능형 로봇등에서는 주로 음성 자체를 입력으로 이용한다. 음성을 입력으로 이용함으로써 보다 자유로운 환경에서 인공 지능 에이전트를 이용할 수 있다.기존의 인공 지능 에이전트에서 구현된 대화 방식은 독립적인 1개의 발화를 통해 간단한 음성 명령을 처리하거 [0003]나 1개의 음성 단어로 이루어진 부자연스러운 대화 명령을 처리하는 것이 일반적이다. 그러나 실제 사용자는 인공 지능 에이전트와의 대화에 있어서 인간과의 의사 소통과 마찬가지로, 이전 발화와 현재 발화가 문맥적으로연관성을 가지면서 여러 개의 단어가 연속적으로 나오는 자연어 대화를 통해서 문제를 해결하는 것을 선호한다.상기의 자연어 대화를 위하여 종래의 기술은 지능형 로봇의 행위를 예측하기 위해 태스크 오브젝트 기반의 대화 [0004]시스템이 이용되었다. 또한, 사용자 발화를 분석하여 이로부터 의미를 추출하고, 대화 예제 데이터베이스를 이용하는 사람과 인공 지능 에이전트 사이의 대화 관리 장치 및 그를 위한 대화 예제 기반의 대화 모델링 기법을통한 대화 관리 방법이 제시되었다. 그러나 이러한 종래 기술들은 실제 환경에서 주위의 잡음에 의해 사용자 입력에 생기는 음성 인식 오류를 적절히 처리할 수 없는 문제점이 있다.따라서 잡음에 강한 음성 기반 자연어 대화 장치 및 그 방법이 요구된다. [0005] 발명의 내용 해결 하고자하는 과제본 발명이 이루고자 하는 기술적 과제는 사용자와 자동 안내 인공 지능 에이전트 간에 음성 인식 오류에 강인한 [0006]음성 기반 자연어 대화 장치 및 그 방법을 제공하는 데 있다. 과제 해결수단일 양태에 있어서, 음성 기반 자연어 대화 장치를 제공한다. 상기 장치는 음성의 사용자 발화를 입력받는 입력 [0007]부, 상기 입력부에서 입력받은 사용자 발화를 인식 신뢰도 점수에 따라 내림차순으로 정렬하고, 그 중 상위 N개의 음성 인식 가설을 생성하는 음성 인식부, 상기 음성 인식부에서 생성된 상기 N개의 음성 인식 가설과 대응되는 N개의 의미 구조체를 생성하는 입력 이해부, 상기 N개의 음성 인식 가설과 상기 N개의 의미 구조체를 포함하는 사용자 입력에 의한 대화 예제와 아젠다(agenda)를 이용하여 인공 지능 에이전트(agent)의 행위를 추정하고컨텐츠(contents)를 선택하는 대화 처리부, 상기 대화 처리부에서 상기 사용자 입력이 처리되지 못한 경우 사용자에게 도움말을 제공하는 오류 처리부, 상기 대화 처리부에서 추정된 인공지능 에이전트의 행위 및 선택된 컨텐츠를 이용하여 에이전트 발화를 생성하고 상기 행위 및 컨텐츠에 관한 정보를 화면상에 출력하는 출력생성부, 상기 에이전트 발화를 음성으로 합성하여 출력하는 음성 합성부를 포함한다.상기 인식 신뢰도 점수는 언어 모델을 이용하여 문장의 자연스러운 정도를 수치화한 것 또는 음향 모델을 이용 [0008]하여 기존에 추정되었던 문장과 일치하는 정도를 수치화한 것일 수 있다. 상기 대화 처리부는 상기 사용자 입력중에서 현재 대화 상황에서 가능한 노드와 그에 상응하는 사용자 입력을 선택하는 노드 선택부, 상기 노드 선택부에서 선택된 노드와 사용자 입력을 이용하여 대화 예제를 선택하는 예제 선택부를 포함할 수 있다. 또한, 상기 도움말은 아젠다 도움말과 발화 도움말을 포함하며, 상기 노드 선택부에서 노드 선택에 실패할 경우 상기 아젠다 도움말을 제공하며, 상기 예제 선택부에서 예제 선택에 실패할 경우 상기 발화 도움말을 제공할 수 있다.다른 양태에 있어서, 음성 기반 자연어 대화 방법을 제공한다. 상기 방법은 음성의 사용자 발화를 입력받아 음 [0009]성 인식 가설과 의미 구조체를 생성하는 단계, 상기 생성된 음성 인식 가설과 의미 구조체를 바탕으로 인공 지공개특허 10-2010-0118744-4-능 에이전트의 행위를 추정하는 단계, 상기 추정이 이루어지지 않을 경우 도움말을 제공하는 단계, 상기 추정된에이전트의 행위를 바탕으로 에이전트 발화를 생성하고 이를 출력하는 단계를 포함한다. 효 과인식 신뢰도 점수가 높은 상위 N개의 음성 인식 가설을 이용하여 에이전트의 행위를 추정함으로써 잡은 환경에 [0010]강인한 음성 기반 자연어 대화 장치를 만들 수 있다. 또한, 선험 지식을 활용함으로써 사용자가 원하는 방향으로 대화를 유도할 수 있다. 다양한 종류의 자동 안내 인공 지능 에이전트에 적용될 수 있다. 발명의 실시를 위한 구체적인 내용이어서, 첨부된 도면을 참조하여 본 발명의 음성 기반 자연어 대화 장치 및 그 방법에 대하여 상세히 설명하기 [0011]로 한다.도 1은 본 발명의 음성 기반 자연어 대화 장치의 동작을 나타낸 흐름도이다. [0012]도 1을 참조하면, 입력부(100)는 음성의 사용자 발화를 입력받는다. 상기 사용자 발화는 마이크 등의 입력 장치 [0013]를 통해서 입력될 수 있다.음성 인식부(110)는 상기 입력부(100)에서 입력된 사용자 발화를 이용하여 N 개의 음성 인식 가설을 생성한다. [0014]상기 음성 인식 가설은 음성 인식된 문자열과 그것에 대한 인식 신뢰도 점수 등의 다양한 정보를 포함할 수 있다. 또한, 상위 N개의 음성 인식 가설을 생성함에 있어서, 인식 신뢰도 점수가 높은 순서에 따라 N개의 음성 인식 가설을 생성할 수 있다. 인식 신뢰도 점수는 음성 인식부에서 생성된 음성 인식 가설이 실제 사용자 발화와일치하는 정도를 수치화한 것이다. 인식 신뢰도 점수는 언어 모델을 통해서 문장이 얼마나 자연스러운지에 따라점수를 매겨 얻을 수도 있고, 음향 모델을 통해서 기존에 추정되었던 문장과 얼마나 비슷한지에 따라 점수를 매겨 얻을 수도 있다. 주위 환경에 의한 잡음으로 인해 음성 인식부가 최적이라고 추정하여 생성한 가설이 하위의음성 인식 가설보다 더 많은 오류를 포함할 수 있다. 따라서 음성 신뢰도 점수가 높은 N개의 음성 인식 가설을생성하여 음성 인식 오류에 대해 강인함을 향상시킬 수 있다.입력 이해부(120)는 상기 음성 인식부(110)에서 생성된 N개의 음성 인식 가설에 대응되는 N개의 의미 구조체를 [0015]생성한다. 의미 구조체는 상기 N개의 음성 인식 가설들이 대화 처리부(130)에 전달되기 전에 인공 지능 에이전트가 상기 사용자 발화의 의미를 파악하기 위해서 필요하다. 입력 이해부(120)는 각각의 음성 인식 가설을 음성언어 이해(spoken language understanding)를 통해 안내 도메인에 맞는 적절한 의미 구조체로 변환시킨다. 음성언어 이해를 위해서는 다양한 확률 모델 및 의미 기반 파서 등을 이용할 수 있다.의미 구조체는 인공 지능 에이전트가 사용자 발화를 이해할 수 있는 구조체로, 화행 및 주행 등의 사용자 의도 [0016]와 사용자 발화에서 주요한 개체명을 포함한다. 화행(dialog act)은 도메인과 무관한 발화내적 힘(illocutionary force)을 나타내는 레이블을 말한다. 화행의 예로 서술(Statement), 요청(Request), WH 의문문(WH-Question), YN 의문문(YN-Question) 등이 있다. 주행(main goal)은 도메인에 특화된 실제 사용자 목적을나타내는 레이블을 말한다. 이는 도메인에 따라서 달라질 수 있으며, 위치 검색(Search-Location), 사람 검색(Search-Person) 등이 포함될 수 있다. 예를 들어 음성 인식부(110)가 \"시장실이 어디지?\"라는 인식된 문자열을생성한다면 그에 상응하는 의미 구조체는 \"화행=WH-Question, 주행=Search-Location, 방이름=시장실\"로 표현될수 있다.대화 처리부(130)는 상기 음성 인식부(110)에서 생성된 N개의 음성 인식 가설과 상기 입력 이해부(120)에서 생 [0017]성된 N개의 의미 구조체를 바탕으로 적절한 인공 지능 에이전트의 행위를 추정한다. 이때에 대화의 처리를 위해대화 예제와 아젠다가 이용될 수 있다.대화 예제는 의미가 분석된 대화 말뭉치에서 사용자 입력에 대응되는 에이전트 행위 쌍(pair)으로 사용자 발화, [0018]언어 이해, 에이전트 행위 정보 등을 포함한다. 예를 들어, 사용자 발화로 \"연구실로 안내해 줘\"가 입력된다면,상기 입력 이해부는 상기 사용자 발화에 대응되도록 \"화행=Request, 주행=Guide-Location, Location-Name=연구실\"로 의미 구조체를 생성할 수 있다. 이때에 에이전트는 \"연구실로 안내하겠습니다\"와 같이 에이전트의 행위를추정함으로써, 사용자 입력과 에이전트의 행위가 쌍을 이루게 된다.아젠다는 선험 지식으로, 특정 도메인(예, 건물 안내, 날씨 안내, 길 안내 등)에 대한 일반적인 대화의 흐름을 [0019]방향성 그래프 형태로 나타낸 것이다. 각 노드는 대화가 완료되기 위해 거쳐야 하는 세부 태스크를 의미하며 링크는 그것들의 진행 방향을 의미한다. 아젠다는 방향성 그래프나 트리로 표현될 수 있으며 노드는 대화 말뭉치공개특허 10-2010-0118744-5-로부터 자동으로 추출된 대화 예제들 중에서 세부 태스크에 상응하는 사용자 의도를 가지는 대화 예제들을 포함하고 있다. 또한, 링크는 부모 노드와 자식 노드간의 전이 확률을 가진다.도 2는 건물 안내를 위한 에이전트에서 본 발명의 자연어 대화 장치의 대화 처리부(130)가 사용하는 아젠다의 [0020]예시도이다.단계 S200에서 사용자와 에이전트 간의 대화는 사용자에 대한 인사로 시작된다. [0021]단계 S210에서 상기 대화는 건물 안내를 요청하는 사용자 발화에 맞추어 링크를 따라 방 이름 검색(Search- [0022]Room), 위치 검색(Search-Location), 사람 이름 검색(Search-Person) 노드 등으로 진행된다.단계 S220에서 상기 대화는 단계 S210에 이어 층 검색(Search-Floor), 방 정보 검색(Search-Room [0023]Information), 전화번호 검색(Search-Telephone Number), 이메일 검색(Search-E-mail) 노드 등으로 진행된다.단계 S230에서 상기 대화는 단계 S220에서 이어서 사용자에 대한 안내로 진행된다. [0024]도 3은 본 발명의 음성 기반 자연어 대화 장치의 대화 처리부(130)를 현재의 대화 상황에 맞게 상세하게 나타낸 [0025]흐름도이다. 대화 처리부(330)에서 인공 지능 에이전트의 행위를 추정하기 위해서는 크게 노드 선택부(331)와 예제 선택 [0026](333)부를 거친다. 현재의 대화 상황은 상기 N개의 음성 인식 가설과 상기 N개의 의미 구조체를 포함하는 N개의사용자 입력(310) 이외에 담화 기록에 저장된 이전까지의 대화 정보(320)에 영향을 받는다. 상기 대화 정보는대화의 처음부터 이전 발화까지의 의미 구조체, 기선택된 대화 예제, 노드에 대한 정보 등을 포함할 수 있다.노드 선택부(331)는 상위 N개의 사용자 입력 중에서 현재 대화 상황에서 가능한 노드와 그에 상응하는 사용자 [0027]입력을 선택한다. 최적의 노드는 현재 상위 N개의 사용자 입력(310)과 담화 기록에 저장된 대화 정보(320)를 바탕으로 인식 신뢰도 점수, 노드 전이 점수 등의 다양한 점수 등을 이용하여 선택할 수 있다.예제 선택부(333)는 대화 처리부는 상기 노드 선택부(331)에서 선택된 사용자 입력과 노드를 이용하여 해당 노 [0028]드에 포함되는 대화 예제 중에서 의미적으로 가장 가까운 대화 예제를 선택한다.한편, 대화 처리부(130, 330)는 적절한 노드와 대화 예제를 선택하여 상황에 맞는 인공 지능 에이전트 행위를 [0029]추정해야 하나, 음성 인식 오류로 인해 사용자 입력에 잘못된 정보가 포함된 경우에는 대화 처리부가 처리를 하지 못하고 상기 사용자 입력을 거절할 수 있다. 이에 대해 오류 처리부(140, 340)는 상기 대화 처리부(130,330)에서 제대로 처리되지 못하고 거절된 사용자 입력에 대해서 오류 상태에 따른 도움말을 제공한다. 상기 도움말은 아젠다 도움말과 발화 도움말을 포함할 수 있다. 아젠다 도움말은 노드 선택이 실패한 경우(33 [0030]2)에 생성된다. 예를 들어, 사용자가 건물 안내를 받는 상황에서 어떤 세부 태스크를 수행해야 할지 모르는 경우에 상기 오류 처리부(140, 340)는 \"에이전트: 다음으로 <방이름 검색>, <사람 이름 검색>, <위치 검색> 등을할 수 있습니다.\"와 같은 아젠다 도움말을 제공할 수 있다. 한편, 발화 도움말은 예제 선택이 실패한 경우(334)에 생성된다. 예를 들어, 상기 건물 안내 상황에서 사용자가 어떻게 발화해야 할지 모르는 경우에 상기 오류처리부(140, 340)는 \"에이전트: 다음으로 '<방이름>은 어디에 있지?' 라고 말씀해주세요.\"와 같은 발화 도움말을 제공할 수 있다.상기 도움말을 제공하기 위해서 담화 기록에 저장된 대화 정보(320)와 아젠다를 이용하여 이전까지 진행된 대화 [0031]정보를 바탕으로 현재 대화 상황에서 가능한 세부 태스크의 정보와 그에 맞는 대화 예제를 선택한다.출력 생성부(150, 350)는 상기 대화 처리부(130, 330)와 상기 오류 처리부(140, 340)에서 추정된 인공 지능 에 [0032]이전트의 행위와 도움말 등의 선택된 컨텐츠를 바탕으로 실제 사용자에게 출력된 에이전트 발화를 생성한다. 상기 생성된 에이전트 발화는 화면으로 보내지므로, 화면상에 현재 선택된 콘텐츠에 대한 상세 정보와 현재 사용자가 하고자 하는 세부 태스크에 대한 정보가 나타날 수 있다. 또한, 상기 생성된 에이전트 발화는 음성 합성부(160)로 보내질 수 있다.음성 합성부(160)는 상기 출력 생성부(150)에서 생성된 에이전트 발화를 음성으로 합성하여 스피커를 통해 사용 [0033]자에게 전달한다.본 발명에 의하면, 음성 기반의 자동 안내 인공 지능 에이전트를 용이하게 구현할 수 있으며 잡음 환경에서 발 [0034]생하는 오류를 극복하기 위해 상위 N개의 음성 인식 가설을 이용하므로 음성 인식 오류에 강인한 음성 기반 자공개특허 10-2010-0118744-6-연어 대화 장치를 제공한다. 또한, 기발생된 오류에 대해 인공 지능 에이전트가 사용자에게 적절한 도움말을 제공하여 사용성을 향상시킬 수 있다. 향후 본 발명이 건물 안내를 위한 지능형 로봇을 비롯한 여러 모바일 단말기, 콜센터, 자동차 등에 적용될 수 있다. 가령, 자동차의 경우 길 안내를 위한 자동차 네비게이션 도메인에 적용되어 음성 기반의 네비게이션 시스템을 용이하게 구축할 수 있다.본 발명은 하드웨어, 소프트웨어 또는 이들의 조합으로 구현될 수 있다. 하드웨어 구현에 있어, 상술한 기능을 [0035]수행하기 위해 디자인된 ASIC(application specific integrated circuit), DSP(digital signal processing),PLD(programmable logic device), FPGA(field programmable gate array), 프로세서, 제어기, 마이크로 프로세서, 다른 전자 유닛 또는 이들의 조합으로 구현될 수 있다. 소프트웨어 구현에 있어, 상술한 기능을 수행하는모듈로 구현될 수 있다. 소프트웨어는 메모리 유닛에 저장될 수 있고, 프로세서에 의해 실행된다. 메모리 유닛이나 프로세서는 당업자에게 잘 알려진 다양한 수단을 채용할 수 있다.이상 본 발명에 대하여 실시예를 참조하여 설명하였지만, 해당 기술 분야의 통상의 지식을 가진 자는 본 발명의 [0036]기술적 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시켜 실시할 수 있음을 이해할 수 있을 것이다. 따라서 상술한 실시예에 한정되지 않고, 본 발명은 이하의 특허청구범위의 범위 내의 모든 실시예들을 포함한다고 할 것이다.도면의 간단한 설명도 1은 본 발명의 음성 기반 자연어 대화 장치의 동작을 나타낸 흐름도이다. [0037]도 2는 건물 안내를 위한 에이전트에서 본 발명의 자연어 대화 장치의 대화 처리부가 사용하는 아젠다의 예시 [0038]도이다.도 3은 본 발명의 음성 기반 자연어 대화 장치의 대화 처리부(130)를 현재의 대화 상황에 맞게 상세하게 나타 [0039]낸 흐름도이다. 공개특허 10-2010-0118744-7-도면 도면1공개특허 10-2010-0118744-8- 도면2공개특허 10-2010-0118744-9- 도면3공개특허 10-2010-0118744-10-"}
{"patent_id": "10-2009-0037594", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자와 자동 안내 인공 지능 에이전트 간에 음성 인식 오류에 강인한 음성 기반 자연어 대화 장치 및 그 방법 을 제공한다. 상기 자연어 대화 장치는 입력부, 음성 인식부, 입력 이해부, 대화 처리부, 오류 처리부, 출력 생 성부, 음성 합성부를 포함한다. 잡음 환경에 강인한 자연어 대화 장치를 제공할 수 있고, 다양한 종류의 자동 안 내 인공 지능 에이전트에 적용될 수 있다."}
{"patent_id": "10-2009-0037594", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자연어 대화 장치 및 그 방법에 관한 것으로, 보다 상세하게는 사용자와 자동 안내 인공 지능 에이전 트 간에 음성 인식 오류에 강인한 음성 기반 자연어 대화 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2009-0037594", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 인공 지능 에이전트의 입력 장치로 키보드와 마우스가 이용된다. 그러나 키보드와 마우스는 입력을 위해서 항상 손을 사용해야 한다는 점에서 최근의 다양한 환경에 적합하지 않다. 따라서, 자동차나 지능형 로봇 등에서는 주로 음성 자체를 입력으로 이용한다. 음성을 입력으로 이용함으로써 보다 자유로운 환경에서 인공 지 능 에이전트를 이용할 수 있다. 기존의 인공 지능 에이전트에서 구현된 대화 방식은 독립적인 1개의 발화를 통해 간단한 음성 명령을 처리하거 나 1개의 음성 단어로 이루어진 부자연스러운 대화 명령을 처리하는 것이 일반적이다. 그러나 실제 사용자는 인 공 지능 에이전트와의 대화에 있어서 인간과의 의사 소통과 마찬가지로, 이전 발화와 현재 발화가 문맥적으로 연관성을 가지면서 여러 개의 단어가 연속적으로 나오는 자연어 대화를 통해서 문제를 해결하는 것을 선호한다. 상기의 자연어 대화를 위하여 종래의 기술은 지능형 로봇의 행위를 예측하기 위해 태스크 오브젝트 기반의 대화 시스템이 이용되었다. 또한, 사용자 발화를 분석하여 이로부터 의미를 추출하고, 대화 예제 데이터베이스를 이 용하는 사람과 인공 지능 에이전트 사이의 대화 관리 장치 및 그를 위한 대화 예제 기반의 대화 모델링 기법을 통한 대화 관리 방법이 제시되었다. 그러나 이러한 종래 기술들은 실제 환경에서 주위의 잡음에 의해 사용자 입 력에 생기는 음성 인식 오류를 적절히 처리할 수 없는 문제점이 있다. 따라서 잡음에 강한 음성 기반 자연어 대화 장치 및 그 방법이 요구된다."}
{"patent_id": "10-2009-0037594", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용 해결 하고자하는 과제 본 발명이 이루고자 하는 기술적 과제는 사용자와 자동 안내 인공 지능 에이전트 간에 음성 인식 오류에 강인한 음성 기반 자연어 대화 장치 및 그 방법을 제공하는 데 있다. 과제 해결수단 일 양태에 있어서, 음성 기반 자연어 대화 장치를 제공한다. 상기 장치는 음성의 사용자 발화를 입력받는 입력 부, 상기 입력부에서 입력받은 사용자 발화를 인식 신뢰도 점수에 따라 내림차순으로 정렬하고, 그 중 상위 N개 의 음성 인식 가설을 생성하는 음성 인식부, 상기 음성 인식부에서 생성된 상기 N개의 음성 인식 가설과 대응되 는 N개의 의미 구조체를 생성하는 입력 이해부, 상기 N개의 음성 인식 가설과 상기 N개의 의미 구조체를 포함하 는 사용자 입력에 의한 대화 예제와 아젠다(agenda)를 이용하여 인공 지능 에이전트(agent)의 행위를 추정하고 컨텐츠(contents)를 선택하는 대화 처리부, 상기 대화 처리부에서 상기 사용자 입력이 처리되지 못한 경우 사용 자에게 도움말을 제공하는 오류 처리부, 상기 대화 처리부에서 추정된 인공지능 에이전트의 행위 및 선택된 컨 텐츠를 이용하여 에이전트 발화를 생성하고 상기 행위 및 컨텐츠에 관한 정보를 화면상에 출력하는 출력 생성부, 상기 에이전트 발화를 음성으로 합성하여 출력하는 음성 합성부를 포함한다. 상기 인식 신뢰도 점수는 언어 모델을 이용하여 문장의 자연스러운 정도를 수치화한 것 또는 음향 모델을 이용 하여 기존에 추정되었던 문장과 일치하는 정도를 수치화한 것일 수 있다. 상기 대화 처리부는 상기 사용자 입력 중에서 현재 대화 상황에서 가능한 노드와 그에 상응하는 사용자 입력을 선택하는 노드 선택부, 상기 노드 선택 부에서 선택된 노드와 사용자 입력을 이용하여 대화 예제를 선택하는 예제 선택부를 포함할 수 있다. 또한, 상 기 도움말은 아젠다 도움말과 발화 도움말을 포함하며, 상기 노드 선택부에서 노드 선택에 실패할 경우 상기 아 젠다 도움말을 제공하며, 상기 예제 선택부에서 예제 선택에 실패할 경우 상기 발화 도움말을 제공할 수 있다. 다른 양태에 있어서, 음성 기반 자연어 대화 방법을 제공한다. 상기 방법은 음성의 사용자 발화를 입력받아 음 성 인식 가설과 의미 구조체를 생성하는 단계, 상기 생성된 음성 인식 가설과 의미 구조체를 바탕으로 인공 지능 에이전트의 행위를 추정하는 단계, 상기 추정이 이루어지지 않을 경우 도움말을 제공하는 단계, 상기 추정된 에이전트의 행위를 바탕으로 에이전트 발화를 생성하고 이를 출력하는 단계를 포함한다. 효 과 인식 신뢰도 점수가 높은 상위 N개의 음성 인식 가설을 이용하여 에이전트의 행위를 추정함으로써 잡은 환경에 강인한 음성 기반 자연어 대화 장치를 만들 수 있다. 또한, 선험 지식을 활용함으로써 사용자가 원하는 방향으 로 대화를 유도할 수 있다. 다양한 종류의 자동 안내 인공 지능 에이전트에 적용될 수 있다. 발명의 실시를 위한 구체적인 내용 이어서, 첨부된 도면을 참조하여 본 발명의 음성 기반 자연어 대화 장치 및 그 방법에 대하여 상세히 설명하기 로 한다. 도 1은 본 발명의 음성 기반 자연어 대화 장치의 동작을 나타낸 흐름도이다. 도 1을 참조하면, 입력부는 음성의 사용자 발화를 입력받는다. 상기 사용자 발화는 마이크 등의 입력 장치 를 통해서 입력될 수 있다. 음성 인식부는 상기 입력부에서 입력된 사용자 발화를 이용하여 N 개의 음성 인식 가설을 생성한다. 상기 음성 인식 가설은 음성 인식된 문자열과 그것에 대한 인식 신뢰도 점수 등의 다양한 정보를 포함할 수 있 다. 또한, 상위 N개의 음성 인식 가설을 생성함에 있어서, 인식 신뢰도 점수가 높은 순서에 따라 N개의 음성 인 식 가설을 생성할 수 있다. 인식 신뢰도 점수는 음성 인식부에서 생성된 음성 인식 가설이 실제 사용자 발화와 일치하는 정도를 수치화한 것이다. 인식 신뢰도 점수는 언어 모델을 통해서 문장이 얼마나 자연스러운지에 따라 점수를 매겨 얻을 수도 있고, 음향 모델을 통해서 기존에 추정되었던 문장과 얼마나 비슷한지에 따라 점수를 매 겨 얻을 수도 있다. 주위 환경에 의한 잡음으로 인해 음성 인식부가 최적이라고 추정하여 생성한 가설이 하위의 음성 인식 가설보다 더 많은 오류를 포함할 수 있다. 따라서 음성 신뢰도 점수가 높은 N개의 음성 인식 가설을 생성하여 음성 인식 오류에 대해 강인함을 향상시킬 수 있다. 입력 이해부는 상기 음성 인식부에서 생성된 N개의 음성 인식 가설에 대응되는 N개의 의미 구조체를 생성한다. 의미 구조체는 상기 N개의 음성 인식 가설들이 대화 처리부에 전달되기 전에 인공 지능 에이전 트가 상기 사용자 발화의 의미를 파악하기 위해서 필요하다. 입력 이해부는 각각의 음성 인식 가설을 음성 언어 이해(spoken language understanding)를 통해 안내 도메인에 맞는 적절한 의미 구조체로 변환시킨다. 음성 언어 이해를 위해서는 다양한 확률 모델 및 의미 기반 파서 등을 이용할 수 있다. 의미 구조체는 인공 지능 에이전트가 사용자 발화를 이해할 수 있는 구조체로, 화행 및 주행 등의 사용자 의도 와 사용자 발화에서 주요한 개체명을 포함한다. 화행(dialog act)은 도메인과 무관한 발화내적 힘 (illocutionary force)을 나타내는 레이블을 말한다. 화행의 예로 서술(Statement), 요청(Request), WH 의문문 (WH-Question), YN 의문문(YN-Question) 등이 있다. 주행(main goal)은 도메인에 특화된 실제 사용자 목적을 나타내는 레이블을 말한다. 이는 도메인에 따라서 달라질 수 있으며, 위치 검색(Search-Location), 사람 검색 (Search-Person) 등이 포함될 수 있다. 예를 들어 음성 인식부가 \"시장실이 어디지?\"라는 인식된 문자열을 생성한다면 그에 상응하는 의미 구조체는 \"화행=WH-Question, 주행=Search-Location, 방이름=시장실\"로 표현될 수 있다. 대화 처리부는 상기 음성 인식부에서 생성된 N개의 음성 인식 가설과 상기 입력 이해부에서 생 성된 N개의 의미 구조체를 바탕으로 적절한 인공 지능 에이전트의 행위를 추정한다. 이때에 대화의 처리를 위해 대화 예제와 아젠다가 이용될 수 있다. 대화 예제는 의미가 분석된 대화 말뭉치에서 사용자 입력에 대응되는 에이전트 행위 쌍(pair)으로 사용자 발화, 언어 이해, 에이전트 행위 정보 등을 포함한다. 예를 들어, 사용자 발화로 \"연구실로 안내해 줘\"가 입력된다면, 상기 입력 이해부는 상기 사용자 발화에 대응되도록 \"화행=Request, 주행=Guide-Location, Location-Name=연구 실\"로 의미 구조체를 생성할 수 있다. 이때에 에이전트는 \"연구실로 안내하겠습니다\"와 같이 에이전트의 행위를 추정함으로써, 사용자 입력과 에이전트의 행위가 쌍을 이루게 된다. 아젠다는 선험 지식으로, 특정 도메인(예, 건물 안내, 날씨 안내, 길 안내 등)에 대한 일반적인 대화의 흐름을 방향성 그래프 형태로 나타낸 것이다. 각 노드는 대화가 완료되기 위해 거쳐야 하는 세부 태스크를 의미하며 링 크는 그것들의 진행 방향을 의미한다. 아젠다는 방향성 그래프나 트리로 표현될 수 있으며 노드는 대화 말뭉치로부터 자동으로 추출된 대화 예제들 중에서 세부 태스크에 상응하는 사용자 의도를 가지는 대화 예제들을 포함 하고 있다. 또한, 링크는 부모 노드와 자식 노드간의 전이 확률을 가진다. 도 2는 건물 안내를 위한 에이전트에서 본 발명의 자연어 대화 장치의 대화 처리부가 사용하는 아젠다의 예시도이다. 단계 S200에서 사용자와 에이전트 간의 대화는 사용자에 대한 인사로 시작된다. 단계 S210에서 상기 대화는 건물 안내를 요청하는 사용자 발화에 맞추어 링크를 따라 방 이름 검색(Search- Room), 위치 검색(Search-Location), 사람 이름 검색(Search-Person) 노드 등으로 진행된다. 단계 S220에서 상기 대화는 단계 S210에 이어 층 검색(Search-Floor), 방 정보 검색(Search-Room Information), 전화번호 검색(Search-Telephone Number), 이메일 검색(Search-E-mail) 노드 등으로 진행된다. 단계 S230에서 상기 대화는 단계 S220에서 이어서 사용자에 대한 안내로 진행된다. 도 3은 본 발명의 음성 기반 자연어 대화 장치의 대화 처리부를 현재의 대화 상황에 맞게 상세하게 나타낸 흐름도이다. 대화 처리부에서 인공 지능 에이전트의 행위를 추정하기 위해서는 크게 노드 선택부와 예제 선택 부를 거친다. 현재의 대화 상황은 상기 N개의 음성 인식 가설과 상기 N개의 의미 구조체를 포함하는 N개의 사용자 입력 이외에 담화 기록에 저장된 이전까지의 대화 정보에 영향을 받는다. 상기 대화 정보는 대화의 처음부터 이전 발화까지의 의미 구조체, 기선택된 대화 예제, 노드에 대한 정보 등을 포함할 수 있다. 노드 선택부는 상위 N개의 사용자 입력 중에서 현재 대화 상황에서 가능한 노드와 그에 상응하는 사용자 입력을 선택한다. 최적의 노드는 현재 상위 N개의 사용자 입력과 담화 기록에 저장된 대화 정보를 바 탕으로 인식 신뢰도 점수, 노드 전이 점수 등의 다양한 점수 등을 이용하여 선택할 수 있다. 예제 선택부는 대화 처리부는 상기 노드 선택부에서 선택된 사용자 입력과 노드를 이용하여 해당 노 드에 포함되는 대화 예제 중에서 의미적으로 가장 가까운 대화 예제를 선택한다. 한편, 대화 처리부(130, 330)는 적절한 노드와 대화 예제를 선택하여 상황에 맞는 인공 지능 에이전트 행위를 추정해야 하나, 음성 인식 오류로 인해 사용자 입력에 잘못된 정보가 포함된 경우에는 대화 처리부가 처리를 하 지 못하고 상기 사용자 입력을 거절할 수 있다. 이에 대해 오류 처리부(140, 340)는 상기 대화 처리부(130, 330)에서 제대로 처리되지 못하고 거절된 사용자 입력에 대해서 오류 상태에 따른 도움말을 제공한다. 상기 도움말은 아젠다 도움말과 발화 도움말을 포함할 수 있다. 아젠다 도움말은 노드 선택이 실패한 경우(33 2)에 생성된다. 예를 들어, 사용자가 건물 안내를 받는 상황에서 어떤 세부 태스크를 수행해야 할지 모르는 경 우에 상기 오류 처리부(140, 340)는 \"에이전트: 다음으로 <방이름 검색>, <사람 이름 검색>, <위치 검색> 등을 할 수 있습니다.\"와 같은 아젠다 도움말을 제공할 수 있다. 한편, 발화 도움말은 예제 선택이 실패한 경우(33 4)에 생성된다. 예를 들어, 상기 건물 안내 상황에서 사용자가 어떻게 발화해야 할지 모르는 경우에 상기 오류 처리부(140, 340)는 \"에이전트: 다음으로 '<방이름>은 어디에 있지?' 라고 말씀해주세요.\"와 같은 발화 도움말 을 제공할 수 있다. 상기 도움말을 제공하기 위해서 담화 기록에 저장된 대화 정보와 아젠다를 이용하여 이전까지 진행된 대화 정보를 바탕으로 현재 대화 상황에서 가능한 세부 태스크의 정보와 그에 맞는 대화 예제를 선택한다. 출력 생성부(150, 350)는 상기 대화 처리부(130, 330)와 상기 오류 처리부(140, 340)에서 추정된 인공 지능 에 이전트의 행위와 도움말 등의 선택된 컨텐츠를 바탕으로 실제 사용자에게 출력된 에이전트 발화를 생성한다. 상 기 생성된 에이전트 발화는 화면으로 보내지므로, 화면상에 현재 선택된 콘텐츠에 대한 상세 정보와 현재 사용 자가 하고자 하는 세부 태스크에 대한 정보가 나타날 수 있다. 또한, 상기 생성된 에이전트 발화는 음성 합성부 로 보내질 수 있다. 음성 합성부는 상기 출력 생성부에서 생성된 에이전트 발화를 음성으로 합성하여 스피커를 통해 사용 자에게 전달한다. 본 발명에 의하면, 음성 기반의 자동 안내 인공 지능 에이전트를 용이하게 구현할 수 있으며 잡음 환경에서 발 생하는 오류를 극복하기 위해 상위 N개의 음성 인식 가설을 이용하므로 음성 인식 오류에 강인한 음성 기반 자연어 대화 장치를 제공한다. 또한, 기발생된 오류에 대해 인공 지능 에이전트가 사용자에게 적절한 도움말을 제 공하여 사용성을 향상시킬 수 있다. 향후 본 발명이 건물 안내를 위한 지능형 로봇을 비롯한 여러 모바일 단말 기, 콜센터, 자동차 등에 적용될 수 있다. 가령, 자동차의 경우 길 안내를 위한 자동차 네비게이션 도메인에 적 용되어 음성 기반의 네비게이션 시스템을 용이하게 구축할 수 있다. 본 발명은 하드웨어, 소프트웨어 또는 이들의 조합으로 구현될 수 있다. 하드웨어 구현에 있어, 상술한 기능을 수행하기 위해 디자인된 ASIC(application specific integrated circuit), DSP(digital signal processing), PLD(programmable logic device), FPGA(field programmable gate array), 프로세서, 제어기, 마이크로 프로세 서, 다른 전자 유닛 또는 이들의 조합으로 구현될 수 있다. 소프트웨어 구현에 있어, 상술한 기능을 수행하는 모듈로 구현될 수 있다. 소프트웨어는 메모리 유닛에 저장될 수 있고, 프로세서에 의해 실행된다. 메모리 유닛 이나 프로세서는 당업자에게 잘 알려진 다양한 수단을 채용할 수 있다. 이상 본 발명에 대하여 실시예를 참조하여 설명하였지만, 해당 기술 분야의 통상의 지식을 가진 자는 본 발명의 기술적 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시켜 실시할 수 있음 을 이해할 수 있을 것이다. 따라서 상술한 실시예에 한정되지 않고, 본 발명은 이하의 특허청구범위의 범위 내 의 모든 실시예들을 포함한다고 할 것이다."}
