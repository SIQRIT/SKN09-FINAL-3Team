{"patent_id": "10-2020-0150998", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0064665", "출원번호": "10-2020-0150998", "발명의 명칭": "인공지능 모델을 분산 처리하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "이성호"}}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에서, 인공지능 모델을 분산 처리하는 방법에 있어서,분산 처리될 인공지능 모델을 획득하는 단계;상기 인공지능 모델을 분할하여, 병렬로 처리될 수 있는 복수 개의 분할 모델을 획득하는 단계;상기 복수 개의 분할 모델 중 연산량이 가장 많은 제1 분할 모델을 처리할 제1 처리 장치를 결정하는 단계;상기 제1 처리 장치에 의해 상기 제1 분할 모델이 처리되는데 소요되는 시간을 예측하는 단계;상기 예측된 시간에 기초하여, 상기 복수 개의 분할 모델 중 제2 분할 모델이 처리될 제2 처리 장치를 결정하는단계; 및상기 제1 처리 장치 및 상기 제2 처리 장치로, 상기 제1 분할 모델 및 상기 제2 분할 모델에 대한 처리를 요청함으로써, 상기 인공지능 모델을 분산 처리하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제2 처리 장치를 결정하는 단계는상기 제2 분할 모델에 대한 처리 예측 시간이 상기 예측된 시간 이내인, 적어도 하나의 장치를 식별하는 단계;및상기 식별된 적어도 하나의 장치 중에서, 상기 제2 분할 모델에 대한 각 장치의 처리 예측 시간을 제외한 적어도 하나의 기준에 기초하여, 상기 제2 분할 모델이 처리될 상기 제2 처리 장치를 결정하는 단계를 포함하고,상기 적어도 하나의 기준은, 상기 각 장치가 상기 제2 분할 모델을 처리하는 상황과 관련하여, 상기 제2 분할모델을 처리하기에 적합한지 여부를 판단하기 위한 기준을 포함하는, 방법."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 예측된 시간에 관한 정보는 상기 제2 처리 장치에서, 상기 제2 분할 모델을 처리하는 속도를 조절하여, 상기 예측된 시간 이내로 상기 제2 분할 모델을 처리하는데 이용되는, 방법."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 인공지능 모델이 가속 연산될 수 있는 연산자를 포함하는 경우, 상기 복수 개의 분할 모델은, 상기 가속 연산될 수 있는 연산자를 각각 개별적으로 포함하는, 적어도 하나의 분할 모델을 포함하는, 방법."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 인공지능 모델은,상기 인공지능 모델에 포함된, 분기점 및 합류점에 기초하여, 상기 복수 개의 분할 모델로 분할되는, 방법."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 제2 분할 모델이 복수 개의 하드웨어에 의해 처리되는 경우, 상기 복수 개의 하드웨어 간동작 전환되는데 소요되는 스위칭 시간에 기초하여, 상기 제2 처리 장치가 결정되는, 방법."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 공개특허 10-2022-0064665-2-상기 복수 개의 분할 모델 중 적어도 하나의 분할 모델에 대하여, 각 분할 모델의 처리 예측 시간에 기초하여,가드 타임 정보를 결정하는 단계;상기 가드 타임 정보에 기초하여, 설정된 시점까지, 상기 적어도 하나의 분할 모델의 처리 결과가 출력되지 않은, 분할 모델을 식별하는 단계; 및상기 식별된 분할 모델을 처리할 장치를 결정하고, 상기 결정된 장치로, 상기 식별된 분할 모델에 대한 처리를요청하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공지능 모델을 분산 처리하는 전자 장치에 있어서,분산 처리될 인공지능 모델에 관한 정보를 저장하는 메모리;상기 인공지능 모델을 분할하여, 병렬로 처리될 수 있는 복수 개의 분할 모델을 획득하고, 상기 복수 개의 분할모델 중 연산량이 가장 많은 제1 분할 모델을 처리할 제1 처리 장치를 결정하고, 상기 제1 처리 장치에 의해 상기 제1 분할 모델이 처리되는데 소요되는 시간을 예측하고, 상기 예측된 시간에 기초하여, 상기 복수 개의 분할모델 중 제2 분할 모델이 처리될 제2 처리 장치를 결정하는, 적어도 하나의 프로세서; 및 상기 제1 처리 장치 및 상기 제2 처리 장치로, 상기 제1 분할 모델 및 상기 제2 분할 모델에 대한 처리를 요청하기 위한 정보를 전송하는 통신부를 포함하는, 전자 장치."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는상기 제2 분할 모델에 대한 처리 예측 시간이 상기 예측된 시간 이내인, 적어도 하나의 장치를 식별하고,상기 식별된 적어도 하나의 장치 중에서, 상기 제2 분할 모델에 대한 각 장치의 처리 예측 시간을 제외한 적어도 하나의 기준에 기초하여, 상기 제2 분할 모델이 처리될 상기 제2 처리 장치를 결정하고,상기 적어도 하나의 기준은, 상기 각 장치가 상기 제2 분할 모델을 처리하는 상황과 관련하여, 상기 제2 분할모델을 처리하기에 적합한지 여부를 판단하기 위한 기준을 포함하는, 전자 장치."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 예측된 시간에 관한 정보는 상기 제2 처리 장치에서, 상기 제2 분할 모델을 처리하는 속도를 조절하여, 상기 예측된 시간 이내로 상기 제2 분할 모델을 처리하는데 이용되는, 전자 장치."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 인공지능 모델이 가속 연산될 수 있는 연산자를 포함하는 경우, 상기 복수 개의 분할 모델은, 상기 가속 연산될 수 있는 연산자를 각각 개별적으로 포함하는, 적어도 하나의 분할 모델을 포함하는, 전자 장치."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 인공지능 모델은,상기 인공지능 모델에 포함된, 분기점 및 합류점에 기초하여, 상기 복수 개의 분할 모델로 분할되는, 전자장치."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 제2 분할 모델이 복수 개의 하드웨어에 의해 처리되는 경우, 상기 복수 개의 하드웨어 간동작 전환되는데 소요되는 스위칭 시간에 기초하여, 상기 제2 처리 장치가 결정되는, 전자 장치."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는공개특허 10-2022-0064665-3-상기 복수 개의 분할 모델 중 적어도 하나의 분할 모델에 대하여, 각 분할 모델의 처리 예측 시간에 기초하여,가드 타임 정보를 결정하고,상기 가드 타임 정보에 기초하여, 설정된 시점까지, 상기 적어도 하나의 분할 모델의 처리 결과가 출력되지 않은, 분할 모델을 식별하고, 상기 식별된 분할 모델을 처리할 장치를 결정하고, 상기 결정된 장치로, 상기 식별된 분할 모델에 대한 처리를요청하는, 전자 장치."}
{"patent_id": "10-2020-0150998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항 내지 제7항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는기록매체."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "분산 처리될 인공지능 모델을 획득하고, 인공지능 모델을 분할하여, 병렬로 처리될 수 있는 복수 개의 분할 모델 을 획득하고, 복수 개의 분할 모델 중 연산량이 가장 많은 제1 분할 모델을 처리할 제1 처리 장치를 결정하고, 제1 처리 장치에 의해 상기 제1 분할 모델이 처리되는데 소요되는 시간을 예측하고, 예측된 시간에 기초하여, 복 수 개의 분할 모델 중 제2 분할 모델이 처리될 제2 처리 장치를 결정하고, 제1 처리 장치 및 제2 처리 장치로, 제1 분할 모델 및 제2 분할 모델에 대한 처리를 요청함으로써, 인공지능 모델을 분산 처리하는 방법이 제공된다."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 인공지능 모델을 분산 처리하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "온 디바이스(on-device) AI 기술에 따라서, 외부의 서버 장치와의 데이터 송수신 없이, 전자 장치에 구비된 인 공지능 모델에 기초하여 다양한 데이터들이 처리될 수 있다. 예를 들면, 전자 장치는 외부의 서버 장치를 이용 할 필요없이, 실시간으로 전자 장치에 포함된 인공지능 모델과 전자 장치의 하드웨어 구성에 의하여 다양한 동 작이 수행될 수 있다. 따라서, 온 디바이스 AI 기술에 의하면, 전자 장치에서 수집된 사용자의 민감한 정보를 포함할 수 있는 데이터를 외부로 전달하지 않고, 스스로 운용하므로, 사용자의 개인 정보 보호 및 데이터 처리 속도 면에서, 장점이 존재한다. 그러나, 온 디바이스 AI 기술에 따라서, 전자 장치 내에서 인공지능 모델이 처리되는 경우, 전자 장치에 구비된 하드웨어에 따라 처리 성능이 제한되는 문제점이 존재한다. 따라서, 사용자의 개인 정보 보호 및 데이터 처리 속도 면에서의 온 디바이스 AI 기술의 장점을 유지하면서, 전 자 장치의 하드웨어에 따른 처리 성능의 제한을 최소화할 수 있는, 인공지능 모델의 처리 방법이 필요하다."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시가 해결하고자 하는 과제는 전술한 문제를 해결하기 위한 것으로서, 인공지능 모델을 분산 처리하는 시 스템을 제공하기 위한 것이다. 또한, 상기 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공하는 데 있다. 해결하려는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제 들이 존재할 수 있다."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 전자 장치에서, 인공지능 모델 을 분산 처리하는 방법에 있어서, 분산 처리될 인공지능 모델을 획득하는 단계; 상기 인공지능 모델을 분할하여, 병렬로 처리될 수 있는 복수 개의 분할 모델을 획득하는 단계; 상기 복수 개의 분할 모델 중 연산량 이 가장 많은 제1 분할 모델을 처리할 제1 처리 장치를 결정하는 단계; 상기 제1 처리 장치에 의해 상기 제1 분 할 모델이 처리되는데 소요되는 시간을 예측하는 단계; 상기 예측된 시간에 기초하여, 상기 복수 개의 분할 모 델 중 제2 분할 모델이 처리될 제2 처리 장치를 결정하는 단계; 및 상기 제1 처리 장치 및 상기 제2 처리 장치 로, 상기 제1 분할 모델 및 상기 제2 분할 모델에 대한 처리를 요청함으로써, 상기 인공지능 모델을 분산 처리 하는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 인공지능 모델을 분산 처리하는 전자 장치에 있어서, 분산 처리될 인공지능 모델 에 관한 정보를 저장하는 메모리; 상기 인공지능 모델을 분할하여, 병렬로 처리될 수 있는 복수 개의 분할 모델을 획득하고, 상기 복수 개의 분할 모델 중 연산량이 가장 많은 제1 분할 모델을 처리할 제1 처리 장치를 결정 하고, 상기 제1 처리 장치에 의해 상기 제1 분할 모델이 처리되는데 소요되는 시간을 예측하고, 상기 예측된 시 간에 기초하여, 상기 복수 개의 분할 모델 중 제2 분할 모델이 처리될 제2 처리 장치를 결정하는, 적어도 하나 의 프로세서; 및 상기 제1 처리 장치 및 상기 제2 처리 장치로, 상기 제1 분할 모델 및 상기 제2 분할 모델에 대한 처리를 요청하기 위한 정보를 전송하는 통신부를 포함하는, 전자 장치를 제공할 수 있다. 또한, 본 개시의 제3 측면은, 제1 측면의 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 제공할 수 있 다."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 의하면 전자 장치의 하드웨어에 따른 처리 성능의 제한 없이, 전자 장치 주변의 다양한 장치를 활 용하여, 인공지능 모델을 빠르게 처리할 수 있다."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 일 실시 예에 의한 인공지능 모델을 분산 처리하는 일 예를 나타내는 블록도이다. 도 1을 참조하면, 일 실시 예에 의한 전자 장치는, 인공지능 모델을 복수 개의 처리 장치를 이용하 여 처리함으로써, 인공지능 모델이 처리된 결과에 기초한 다양한 서비스를 사용자에게 제공할 수 있다. 일 실시예에 따른 전자 장치는 다양한 형태로 구현될 수 있다. 예를 들어, 본 명세서에서 기술되는 전자 장치는, 디지털 카메라, 스마트 폰(smart phone), 스마트 TV(smart TV), 노트북 컴퓨터(laptop computer), 태블릿 PC, 전자북 단말기, 디지털방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 차량(vehicle) 등이 있을 수 있으나, 이에 한정 되는 것은 아니다. 본 명세서에서 기술되는 전자 장치는 사용자에 의해 착용될 수 있는 장치(wearable device)일 수 있다. 웨어러블 디바이스는 액세서리 형 장치(예컨대, 시계, 반지, 팔목 밴드, 발목 밴드, 목걸이, 안경, 콘택트 렌즈), 머리 착용형 장치(head-mounted-device(HMD)), 직물 또는 의류 일체형 장치(예: 전자 의복), 신체 부착형 장치(예컨대, 스킨 패드(skin pad)), 또는 생체 이식형 장치(예: implantablecircuit) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시 예에 의한 전자 장치는, 인공지능 모델의 분산 처리를 수행할 수 있는, 적어도 하나의 처리 장치(110, 120, 130)를 식별할 수 있다. 또한, 일 실시 예에 의한 전자 장치가, 적어도 하나의 처리 장치 (110, 120, 130)로서 식별될 수도 있다. 이하에서는, 전자 장치를 제외한 다른 장치들이 처리 장치(110, 120, 130)로서 식별되는 경우를 기준으로 설명하였다. 일 실시 예에 의한 적어도 하나의 처리 장치(110, 120, 130)는, 전자 장치와, 외부의 접근이 제한될 수 있는, 내부의 네트워크를 공유하거나, 물리적으로 가까운 위치에 존재하는 장치들 중에서, 식별될 수 있다. 일 예로, 전자 장치가 집안에 위치하며, 홈 네트워크에 연결되어 있는 경우, 적어도 하나의 처리 장치(110, 120, 130)는, 전자 장치와 동일하게, 집안에 위치하면서, 홈 네트워크에 연결된, 다양한 가전 제품(ex. TV, 냉장고, 세탁기, 로봇청소기, 데스크탑 컴퓨터, 스마트 스피커, 스마트폰, 태블릿) 중에서 식별될 수 있다. 따라서, 일 실시 예에 의한 전자 장치는, 인공지능 모델을 처리하기 위해, 외부 네트워크로 데이터 를 전송할 필요가 없으므로, 사용자의 민감한 정보를 포함할 수 있는, 상기 데이터가, 외부 네트워크로 전송하 는 과정에서, 유출될 위험이 제거될 수 있다. 일 실시 예에 의한 전자 장치는, 식별된 적어도 하나의 처리 장치(110, 120, 130)의 특성 정보 (capability information)를 획득할 수 있다. 또한, 전자 장치는, 각 처리 장치(110, 120, 130)의 특성 정보에 기초하여, 인공지능 모델의 분산 처리를 요청할 적어도 하나의 처리 장치를 결정할 수 있다. 일 실시 예에 의한 각각의 처리 장치(110, 120, 130)의 특성 정보는, 각 장치의 인공지능 모델에 대한 처 리 능력과 관련된 정보를 포함할 수 있다. 예를 들어, 특성 정보는, 각 장치를 나타내는 식별 정보(ex. 데스크 탑 컴퓨터, 공기청정기, 냉장고), 각 장치에 구비된 하드웨어(ex. CPU, GPU, 메모리 등)에 관한 정보, 각 장치 에 구비된 소프트웨어(ex. 운영체제 정보)에 관한 정보, 각 장치의 네트워크 정보(ex. IP(internet protocol) 주소, 네트워크 속도) 등을 포함할 수 있다. 또한, 일 실시 예에 의한 특성 정보는, 실시간으로 변경될 수 있고, 각 장치의 인공지능 모델에 대한 처리 능력과 관련된, 각 처리 장치(110, 120, 130)의 상태와 관련된 정보를 포함할 수 있다. 예를 들어, 특성 정보는, 각 처리 장치(110, 120, 130)의 배터리 잔량, 현재 처리 중인 프로세스의 개수, 현재 사용 가능한 메모 리 크기 등 각 처리 장치(110, 120, 130)에서, 인공지능 모델을 분산 처리하는 동작과 관련된 다양한 정보 를 포함할 수 있다. 상술한 예에 한하지 않고, 각 처리 장치의 특성 정보(110, 120, 130)는, 인공지능 모델을 분산 처리하는데 이용될 수 있는, 다양한 종류의 정보를 포함할 수 있다. 일 실시 예에 의한 특성 정보는, 각 처리 장치(110, 120, 130)의 상황 변화에 따라서, 실시간으로 변화될 수 있 다. 따라서, 각 처리 장치(110, 120, 130)는, 실시간으로 변화될 수 있는 특성 정보를 주기적으로 또는 특성 정 보가 기준값 이상 변화될 때마다 전자 장치에 제공할 수 있다. 일 실시 예에 의한 전자 장치는, 외부로부터 인공지능 모델의 처리 요청을 수신함에 따라, 인공지능 모델을 분산 처리하기 위한 동작을 수행할 수 있다. 다만, 이에 한하지 않고, 전자 장치는, 전자 장 치의 내부 동작에 따라서, 인공지능 모델의 처리가 필요한 경우, 일 실시 예에 의한 인공지능 모델 을 분산 처리하기 위한 동작을 수행할 수도 있다. 일 실시 예에 따라서 분산 처리되는 인공지능 모델은, 동작을 수행하기 위해 처리되는 인공지능 모델 전체 를 포함할 수 있으나, 이에 한하지 않고, 동작을 수행하기 위해 처리되는 인공지능 모델의 일부를 포함할 수도 있다. 일 실시 예에 의한 인공지능 모델은, 입력 정보를 처리하는, 복수 개의 연산자들, 예를 들면, 컨볼루션 (convolution), ReLU(Rectified Linear Unit), 맥스 풀링(Max pooling) 등의 다양한 연산자들의 조합에 기초하 여, 구성될 수 있다. 상술한 예에 한하지 않고, 인공지능 모델은, 다양한 종류의 구성 요소를 포함하여 구 성될 수 있다. 일 실시 예에 의한 전자 장치는, 처리 요청된 인공지능 모델을 분할하여, 복수 개의 분할 모델을 획 득할 수 있다. 일 실시 예에 의한 인공지능 모델은, 다양한 연산자들 간의 연결 관계에 따라서, 분할될 수 있다. 예를 들면, 인공지능 모델은, 병렬적으로 복수의 처리 장치에서 동시에 처리될 수 있는 인공지능 모델의 일부분에 기초하여, 복수 개의 분할 모델로, 분할될 수 있다. 일 실시 예에 의하면, 인공지능 모델 중 하나의 상위 연산자에서 복수 개의 하위 연산자로 연결되는 분기 점과, 상기 분기점 이하에 존재하는, 복수 개의 상위 연산자에서, 하나의 하위 연산자로 연결되는 합 류점에 기초하여, 병렬적으로 처리될 수 있는 부분이 식별될 수 있다. 일 실시 예에 의하면, 분기점 및 합류점을 기준으로, 병렬적으로 동시에 처리 가능한 복수 개의 부분이 식별됨으로써, 식별된 부분을 각 각 포함하는 복수 개의 분할 모델이 획득될 수 있다. 예를 들어, 인공지능 모델은, 분기점 및 합류점을 기준으로, 병렬적으로 동시에 처리될 수 있는 두 부분을 포함하는 분할 모델(110-2, 120-1) 및 나머지 부분을 각각 포함하는 분할 모델(110-1, 110-3)로 분할 될 수 있다. 또한, 일 실시 예에 의하면, 인공지능 모델은, 처리 장치의 하드웨어 특징에 따라, 가속 연산될 수 있는 부분을 기준으로, 분할될 수도 있다. 예를 들어, 인공지능 모델에 포함된 연산자들 중에서, 처리 장치에 구비된 하드웨어의 특징에 따라서, 가속 연산될 수 있는 연산자가 존재할 수 있다. 이 경우, 각 연산자마다 개 별적으로 최적의 처리 장치가 결정될 수 있도록, 상기 하드웨어 특징에 따라서, 가속 연산될 수 있는 연산자를 각각 개별적으로 포함하는 분할 모델이 획득될 수 있다. 상술한 예에 한하지 않고, 인공지능 모델은, 다양한 방법에 따라서, 복수 개의 분할 모델로 분할될 수 있 다. 일 실시 예에 의한 전자 장치는, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)이 처리될 적어도 하 나의 장치를 결정할 수 있다. 일 실시 예에 의하면 전자 장치에서 식별된 적어도 하나의 장치(110, 120, 130) 중에서, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)을 처리 요청할 제1 처리 장치 및 제2 처 리 장치를 결정할 수 있다. 일 실시 예에 의한 제1 처리 장치 및 제2 처리 장치는, 적어도 하나 의 장치(110, 120, 130) 중에서, 각각의 분할 모델(110-1, 110-2, 110-3, 120-1)을 처리하기에 적합하다고 판 단될 수 있다. 예를 들어, 적어도 하나의 장치(110, 120, 130) 중에서, 각 장치의 특성 정보에 기초하여, 제1 처리 장치 가 세 개의 분할 모델(110-1, 110-2, 110-3)을 가장 빠르고 정확하게 처리할 것으로 예측될 수 있다. 또한, 분 할 모델(120-1)는, 제1 처리 장치가 분할 모델(110-2)를 처리하는 동안, 병렬적으로 처리될 수 있으므로, 제1 처리 장치를 제외한, 적어도 하나의 장치(120, 130) 중에서, 제2 처리 장치가 분할 모델(120- 1)을 가장 빠르고 정확하게 처리할 것으로 예측될 수 있다. 일 실시 예에 의한 제1 처리 장치 및 제2 처리 장치는, 상술한 처리 속도 또는 정확도에 한하지 않고, 다양한 기준(ex. 유휴 상태 여부, 사용자 선호도, 배터리 잔량 등)에 따라서, 복수 개의 분할 모델(110- 1, 110-2, 110-3, 120-1)을 처리하기에 적합한 장치로 판단될 수 있다. 다만, 분할 모델(120-1)이 제1 처리 장치에 의해 가속 연산될 수 있는 연산자를 포함함에 따라서, 하나의 제1 처리 장치에 의한 두 분할 모델(110-2, 120-1)의 처리 시간이, 제1 처리 장치에 의한 분할 모델 (110-2)의 처리 시간 및 제2 처리 장치에 의한 분할 모델(120-1)의 처리 시간 중 더 긴 시간보다 짧게 예 측될 수 있다. 상술한 예에 한하지 않고, 제2 처리 장치에 의해 분할 모델(120-1)이 처리되는 경우보다 제1 처리 장치 에 의해 분할 모델(120-1)이 다른 분할 모델(110-2)과 함께 처리되는 것이 더 적합한 다양한 원인이 존재 할 수 있다. 이 경우, 하나의 제1 처리 장치에 의해 병렬적으로 처리될 수 있는 두 개의 분할 모델(110-2, 120-1)이 함 께 처리될 수도 있다. 다만, 일 실시 예에 의하면, 하나의 처리 장치에 의해, 병렬적으로 처리될 수 있는 복수 개의 분할 모델(110-2, 120-1)에 대한 처리 시간을 예측하는 경우, 각 분할 모델 간 스위칭 시간이 더 고려됨으로써, 처리 시간이 예측 될 수 있다. 예를 들어, 두 개의 분할 모델(110-2, 120-1)을 처리하는데 이용되는 하드웨어가 서로 다르고(ex. CPU 및 GPU), 두 개의 하드웨어가 동시에 동작할 수 없는 경우가 존재할 수 있다. 이 경우, 두 개의 분할 모델(110-2, 120-1) 중 하나가 어느 한 하드웨어에 처리된 후, 다른 하드웨어에 의해 나머지 분할 모델이 처리될 수 있도록, 동작되 는 하드웨어를 전환하기 위한 스위칭 시간이 추가로 소요될 수 있다. 따라서, 하나의 처리 장치에 대하여, 병렬적으로 처리될 수 있는 복수 개의 분할 모델(110-2, 120-1)에 대한 처리 시간은, 상술한 스위칭 시간이 더 고려 됨으로써, 예측될 수 있다. 일 실시 예에 의하면, 병렬적으로 동시에 처리될 수 있는 복수 개의 분할 모델(110-2, 120-1) 중 적어도 하나의 분할 모델의 연산량에 따라서, 처리될 장치가 결정될 수 있다. 일 실시 예에 의하면, 복수 개의 분할 모델(110- 2, 120-1) 중 연산량이 가장 많은 분할 모델에 대한 처리 장치가 먼저 결정된 후, 상기 먼저 결정된 처리 장치 에 기초하여, 나머지 분할 모델에 대한 처리 장치가 결정될 수 있다. 예를 들어, 분할 모델(110-2)의 연산량이 가장 많은 경우, 분할 모델(110-2)을 처리하기에 적합한 장치로서, 제 1 처리 장치가 먼저 결정될 수 있다. 일 실시 예에 의하면, 적어도 하나의 처리 장치(110, 120, 130) 중에 서, 제1 처리 장치가 분할 모델(110-2)을 처리하기에 가장 적합하다고 예측됨에 따라, 제1 처리 장치(11 0)가 분할 모델(110-2)을 처리할 장치로 결정될 수 있다. 일 실시 예에 의하면, 먼저 결정된 제1 처리 장치가 분할 모델(110-2)을 처리하는데 소요될 것으로 예측되 는 시간에 기초하여, 제1 처리 장치를 제외한 적어도 하나의 처리 장치(120, 130) 중, 다른 분할 모델 (120-1)을 처리할 장치가 결정될 수 있다. 일 실시 예에 의하면, 분할 모델(120-1)이 분할 모델(110-2)보다 빠르게 처리되어도, 병렬적으로 함께 처리되는 분할 모델(110-2)이 처리될 때까지, 분할 모델(110-3)이 처리되지 않음에 따라, 분할 모델(120-1)의 처리 결과 는 이용되지 않을 수 있다. 따라서, 제1 처리 장치를 제외한 다른 처리 장치(120,130)들에 의한 분할 모델(120-1)의 처리 시간이, 분 할 모델(110-2)의 처리 시간 이내인 것으로 예측되는 경우, 처리 시간 이외에 다른 기준에 기초하여, 상기 다른 처리 장치(120, 130)들 중 더 적합하다고 판단되는 장치가 분할 모델(120-1)에 대한 처리 장치로서 결정될 수 있다. 예를 들면, 분할 모델(120-1)의 처리 예측 시간이 제1 처리 장치에 의한 분할 모델(110-2)의 처리 예측 시간보다 짧은, 적어도 하나의 장치가 먼저 식별될 수 있다. 식별된 적어도 하나의 장치 중에서, 처리 예 측 시간 이외의 다른 기준에 기초하여, 분할 모델(120-1)이 처리될 장치가 결정될 수 있다. 일 실시 예에 의하면, 적어도 하나의 처리 장치(120, 130)에 대해 분할 모델(120-1)을 처리하는데 소요되는 시 간이, 제1 처리 장치의 처리 예측 시간 이내로 예측되는지 여부를 판단하고, 이에 기초하여, 분할 모델 (120-1)이 처리될 장치가 결정될 수 있다. 예를 들어, 제2 처리 장치 및 제3 처리 장치에 의한 분할 모델(120-1)의 처리 시간이 모두 제1 처리 장치의 처리 예측 시간 이내인 것으로 예측된 경우, 처리 시간 이외에 다른 기준에 기초하여, 제2 처리 장치 및 제3 처리 장치 중 하나가 분할 모델(120-1)을 처리 할 장치로 결정될 수 있다. 상술한 다른 기준은, 각각의 장치가 분할 모델(120-1)의 처리 장치로서 적합한지 판단하기 위한, 예측된 처리 시간 이외의 기준을 포함할 수 있다. 예를 들면, 상술한 다른 기준은, 각 처리 장치의 배터리 잔량, 사용자의 선호도, 처리 정확도 등을 포함할 수 있다. 일 실시 예에 의한 다른 기준은, 상술한 예에 한하지 않고, 분할 모 델(120-1)을 처리하는 각 처리 장치의 상황과 관련하여, 처리 시간 외에 분할 모델(120-1)의 처리하기에 적합한 처리 장치인지 여부를 판단할 수 있는 다양한 기준을 포함할 수 있다. 일 실시 예에 의한 전자 장치는, 각 분할 모델의 처리 장치가 결정된 결과에 따라서, 제1 처리 장치 및 제2 처리 장치로, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)의 처리 요청을 전송할 수 있다. 일 실시 예에 의한 제1 처리 장치 및 제2 처리 장치는, 전자 장치의 요청에 따라서, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)을 처리할 수 있다. 일 실시 예에 의한, 제2 처리 장치는, 자신이 처리하는 분할 모델(120-1)과 병렬적으로 함께 처리되는, 제 1 처리 장치에 의한 분할 모델(110-2)의 처리 시간에 기초하여, 분할 모델(120-1)을 처리할 수 있다. 예를 들면, 제2 처리 장치는, 자신의 상황 변화에 따라서, 제1 처리 장치에 의한 분할 모델(110-2)의 처리 가 완료되기 전의 적절한 시점에서, 분할 모델(120-1)이 처리 완료될 수 있도록 동작할 수 있다. 일 예로, 제2 처리 장치는 분할 모델(120-1)을 처리하는 중에, 새로운 프로세스를 처리하기 시작하는 등 다양한 원인에 따라서, 분할 모델(120-1)을 처리하는데 소요되는 시간이 증가될 수 있다. 다만, 제2 처리 장치는, 분할 모델(120-1)을 처리하는데 소요되는 시간이, 이전에 전자 장치에 의하 여 예측되었던 처리 시간보다 다소 길어지더라도, 제1 처리 장치에 의한 분할 모델(110-2)의 처리가 완료 될 것으로 예측되는 시점 이내에, 분할 모델(120-1)이 처리 완료될 수 있도록, 동작할 수 있다.일 실시 예에 의하면, 제1 처리 장치에 의한 분할 모델(110-2)이 처리 완료될 때까지, 분할 모델(120-1)의 처리 결과가 이용되는 분할 모델(110-3)이 처리되지 않으므로, 분할 모델(120-1)은 분할 모델(110-2)보다 빠르 게 처리 완료될 필요가 없다. 따라서, 일 실시 예에 의한 제2 처리 장치는, 제1 처리 장치에 의한 분 할 모델(110-2)의 처리 예측 시간에 관한 정보에 기초하여, 분할 모델(120-1)의 처리 속도를 조절할 수 있다. 일 실시 예에 의한 전자 장치는, 제2 처리 장치로 분할 모델(120-1)의 처리 요청을 전송할 때, 제1 처리 장치에 의한 분할 모델(110-2)의 처리 예측 시간에 관한 정보를 함께 제2 처리 장치로 전송할 수 있다. 상술한 예에 한하지 않고, 다양한 방법으로, 제1 처리 장치에 의한 분할 모델(110-2)의 처리 예 측 시간에 관한 정보가 제2 처리 장치에서 획득될 수 있다. 예를 들면, 제2 처리 장치가 제1 처리 장 치에 요청하여, 제1 처리 장치에 의한 분할 모델(110-2)의 처리 예측 시간에 관한 정보를 획득할 수 도 있다. 일 실시 예에 의한 전자 장치는, 제1 처리 장치 및 제2 처리 장치로 처리 요청을 전송할 때, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)을 함께 전송할 수 있다. 또는, 전자 장치는, 복수 개 의 분할 모델(110-1, 110-2, 110-3, 120-1) 대신에, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)을 나타 내는 식별 정보를 제1 처리 장치 및 제2 처리 장치로 전송할 수도 있다. 일 실시 예에 의한, 제1 처 리 장치 및 제2 처리 장치는 전자 장치로부터 수신한 상기 식별 정보에 기초하여, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)을 외부로부터 획득할 수도 있다. 상술한 예에 한하지 않고, 제1 처리 장치 및 제2 처리 장치는 전자 장치로부터 처리 요청된 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1)을 다양한 방법에 따라서, 획득할 수 있다. 일 실시 예에 의하면, 복수 개의 분할 모델(110-1, 110-2, 110-3, 120-1) 중 분할 모델(110-1)이 제1 처리 장 치에 의해 먼저 처리될 수 있다. 분할 모델(110-1)이 처리된 결과는, 두 개의 분할 모델(110-2, 120-1)이 제1 처리 장치 및 제2 처리 장치에서 처리되는데 이용될 수 있다. 일 실시 예에 의하면, 분할 모델(110-1)이 처리된 결과가 제2 처리 장치로 전달됨으로써, 분할 모델(120- 1)이 제2 처리 장치에 의해 처리될 수 있다. 분할 모델(110-1)이 처리된 결과는, 제1 처리 장치에서 직접 제2 처리 장치로 전달되거나, 제1 처리 장치에서 전자 장치를 통해 제2 처리 장치로 전달될 수도 있다. 또한, 두 개의 분할 모델(110-2, 120-1)이 처리된 결과는, 다음 순서의 분할 모델(110-3)이 제1 처리 장치(11 0)에서, 처리되는데 이용될 수 있다. 마찬가지로, 두 개의 분할 모델(110-2, 120-1)이 처리된 결과 중 제2 처리 장치에서 처리된 분할 모델(120-1)의 결과는, 제2 처리 장치에서 직접 제1 처리 장치로 전달되 거나, 제2 처리 장치에서 전자 장치를 통해 제1 처리 장치로 전달될 수도 있다. 상술한 예에 한하지 않고, 각 분할 모델(110-1, 110-2, 120-1)이 처리된 결과는 다양한 방법에 따라서, 다음 순 서의 분할 모델이 처리되는 장치로 전달될 수 있다. 또한, 분할 모델(110-3)이 처리된 결과는 최종적으로 전자 장치에 전달되어, 인공지능 모델에 기초 하여, 다양한 동작이 수행되는데 이용될 수 있다. 일 실시 예에 의하면, 각 분할 모델(110-1, 110-2, 110-3, 120-1)이 처리되는 시간에 대한 가드 타임(guard time)이 미리 설정될 수 있다. 일 실시 예에 의한 가드 타임은, 각 분할 모델(110-1, 110-2, 110-3, 120-1)이 제1 처리 장치 및 제2 처리 장치에 의한 처리 예측 시간에 기초하여, 결정될 수 있다. 예를 들면, 가 드 타임은, 처리 예측 시간보다 미리 정해진 상수 값만큼 더해진 시간으로 결정될 수 있다. 상술한 예에 한하지 않고, 가드 타임은, 처리 예측 시간과 같거나 더 긴 시간으로 다양한 방법에 따라 결정될 수 있다. 일 실시 예에 의한 가드 타임은, 제1 처리 장치 및 제2 처리 장치의 상태 변화 또는 다른 다양한 원 인으로 인하여, 미리 예측된 처리 시간보다, 각 분할 모델들이 처리되는 시간이 더 길어지는 경우를 대비하기 위하여, 미리 설정될 수 있다. 예를 들면, 각 처리 장치(110, 120)에서, 사용자의 요청에 따라, 새로운 동작이 수행되는 경우, 분할 모델을 처리하기 위한 자원(ex. 메모리 잔량, 배터리 잔량, 하드웨어 이용율 등)이 부족해 짐으로써, 분할 모델을 처리하는데 예측된 시간보다 더 오랜 시간이 걸리거나, 분할 모델의 처리가 불가능해 질 수 있다. 일 실시 예에 의하면, 전자 장치는 각 분할 모델(110-1, 110-2, 110-3, 120-1)의 가드 타임에 관한 정보 를 결정할 수 있다. 또한, 다른 처리 장치로부터 분할 모델의 처리 결과를 각 처리 장치가 직접 수신하는 경우,전자 장치는, 상기 처리 결과가 수신되는 분할 모델에 관한 가드 타임의 정보를 각 처리 장치(110, 120) 로 전달할 수 있다. 예를 들면, 제1 처리 장치는, 제2 처리 장치로부터 분할 모델(120-1)에 대한 처리 결과를 직접 수신 하는 경우, 분할 모델(120-1)에 대한 가드 타임에 관한 정보를 획득할 수 있다. 또한, 제2 처리 장치는, 제1 처리 장치로부터 분할 모델 (110-1)에 대한 처리 결과를 직접 수신하는 경우, 분할 모델(110-1)에 대 한 가드 타임에 관한 정보를 획득할 수 있다. 다만, 각 처리 장치(110, 120)가 전자 장치를 통해 분할 모델에 대한 처리 결과를 수신하는 경우, 전자 장치에서, 각 분할 모델에 대한 처리 결과를 모두 수신할 수 있으므로, 가드 타임에 관한 정보를 다른 처 리 장치로 전달하지 않을 수 있다. 일 실시 예에 의한 전자 장치 또는 각 처리 장치(110, 120)는 미리 설정된 가드 타임에 기초하여 설정된 시점까지, 분할 모델의 처리 결과가 수신되지 않는 경우, 다른 장치로, 상기 분할 모델에 대한 처리 요청을 전 송할 수 있다. 예를 들어, 제1 처리 장치로부터 분할 모델(110-1)의 처리 결과가, 미리 설정된 가드 타임에 기초하여 설 정된 시점까지, 전자 장치 또는 제2 처리 장치에서, 수신되지 않을 수 있다. 이 경우, 전자 장치 는, 제2 처리 장치 또는 제3 처리 장치로, 분할 모델(110-1)에 대한 처리 요청을 전송할 수 있 다. 또는, 전자 장치에서, 분할 모델(110-1)을 직접 처리할 수도 있다. 일 실시 예에 의하면, 전자 장치 , 제2 처리 장치 및 제3 처리 장치 중 다양한 기준(ex. 처리 예측 시간, 배터리 잔량, CPU 또 는 GPU 에서 처리 가능한 프로세스 개수 등)에 따라서, 분할 모델(110-1)을 처리하기에 적합하다고 판단되는 장 치에 의해 분할 모델(100-1)이 처리될 수 있다. 일 실시 예에 의한 가드 타임은, 병렬적으로 함께 처리되는 다른 분할 모델의 처리 예측 시간에 기초하여, 설정 될 수 있다. 예를 들어, 제2 처리 장치는, 자신의 상황 변화에 따라서, 제1 처리 장치에 의한 분할 모델(110-2)의 처리가 완료되기 전의 적절한 시점에서, 분할 모델(120-1)이 처리 완료되도록 동작할 수 있음을 고려하여, 분할 모델(120-1)에 대한 가드 타임이 설정될 수 있다. 일 예로, 분할 모델(120-1)에 대한 가드 타임 은, 제1 처리 장치에 의한 분할 모델(110-2)의 처리 예측 시간에 미리 설정된 상수값이 더해진 값으로 결 정될 수 있다. 일 실시 예에 의한 전자 장치는, 분할 모델을 처리하는 제1 처리 장치 또는 제2 처리 장치로, 지속적으로 폴링 메시지를 전송함으로써, 분할 모델이 처리 예측된 시점 또는 미리 설정된 시점까지 처리 가능 한지 여부를 확인할 수 있다. 일 실시 예에 의한 전자 장치는 폴링 메시지에 대한 각 처리 장치(110, 120)의 응답을 수신함으로써, 분할 모델이 처리 예측된 시점 또는 가드 타임에 따라 설정된 시점까지 처리 불가 능하다고 판단할 수 있다. 이 경우, 전자 장치는, 마찬가지로, 제2 처리 장치 및 제3 처리 장치 중 다양한 기준(ex. 처리 예측 시간, 배터리 잔량, CPU 또는 GPU 에서 처리 가능한 프로세스 개수 등)에 따라서, 분할 모델(110-1)을 처리하기에 적합하다고 판단되는 장치로, 처리 요청을 전송될 수 있다. 일 실시 예에 의한 전자 장치는, 분할 모델을 처리하는 장치에서, 처리 예측된 시점까지 처리되지 않는 경우를 대비하여, 하나의 분할 모델에 대해 복수 개의 처리 장치로, 처리 요청을 전송할 수 있다. 예를 들어, 분할 모델(120-1)에 대하여, 제2 처리 장치뿐만 아니라 제3 처리 장치에도, 처리 요청이 전송될 수 있다. 따라서, 일 실시 예에 의하면, 안정적으로 인공지능 모델의 분산 처리가 수행될 수 있다. 도 2는 일 실시 예에 의한 인공지능 모델이 분할되는 일 예를 나타낸 도면이다. 도 2를 참조하면, 일 실시 예에 의한 인공지능 모델은 분기점 및 합류점을 기준으로, 복수 개의 분할 모델로 분할될 수 있다. 예를 들면, 인공지능 모델은 분기점 위의 분할 모델(110-1), 분기점 과 합류점 사이의 분할 모델(110-2, 120-1) 및 합류점 아래의 분할 모델(110-3)로, 분할될 수 있다. 일 실시 예에 의하면, 분기점을 기준으로, 병렬적으로 동시에 처리될 수 있는 복수 개의 연산자가 존재할 수 있고, 합류점을 기준으로, 병렬적으로 처리되는 연산자들의 처리 결과가 하나의 연산자에 제공될 수 있 다. 따라서, 일 실시 예에 의하면, 분기점 및 합류점에 기초하여, 병렬적으로 동시에 처리 가능한지 여부에 따라서, 인공지능 모델이 분할될 수 있다. 상술한 예에 한하지 않고, 인공지능 모델은, 다양한 방법 및 기준에 따라서, 분할될 수 있다. 일 실시 예에 의하면, 복수 개의 분할 모델 중 분할 모델(110-2)은, 처리 장치의 하드웨어 특징에 따라, 가속 연산될 수 있는 적어도 하나의 연산자를 포함할 수 있다. 일 실시 예에 의하면, 분할 모델(110-2)은, 상기 적어도 하나의 연산자에 기초하여, 복수 개의 분할 모델들(210, 220, 230)로 다시 분할될 수 있다. 예를 들어, 210 및 230에 포함된 다른 연산자들은, CPU 또는 GPU에 의한 처리 속도가 실질적으로 차이가 나지 않으나, 220에 포함된 연산자들은, CPU에 의한 처리 속도에 비해, GPU에 의한 처리 속도가 상당히 클 수 있다. 일 실시 예에 의하면, 210 및 230에 포함된 연산자들 및 220에 포함된 연산자들의 특성에 따라서, 각 연산자들 마다 개별적으로 적합한 처리 장치가 결정될 수 있도록, 분할 모델(110-2)이 복수 개의 분할 모델들(210, 220, 230)로 다시 분할될 수 있다. 일 실시 예에 의한 복수 개의 분할 모델(210, 220, 230)은, 제1 처리 장치 및 제2 처리 장치 중에서 처리 장치가 각각 개별적으로 결정될 수 있다. 예를 들어, 제1 처리 장치는 CPU를 포함하나 GPU는 포함하 지 않는 장치일 수 있다. 또한, 제2 처리 장치는, CPU 및 GPU를 포함하나, 다른 사정(ex. 이미 다른 프로 세스를 처리 중이거나 배터리 잔량이 없음)으로 인해 처리 속도가 느린 장치일 수 있다. 따라서, 분할 모델 (210, 230) 및 분할 모델에 대한 처리 장치는, 각각 제1 처리 장치 및 제2 처리 장치로 결정될 수 있다. 다만, 처리 장치의 결정은, 분할 모델의 결과가 제1 처리 장치로 전달되고, 분할 모델의 결과가 제2 처리 장치로 전달되는데 소요되는 시간이 더 고려될 수 있다. 예를 들어, 각 분할 모델(210, 220)의 결과가 다른 장치로 전달되는데 소요되는 시간을 포함하여, 제1 처리 장 치 및 제2 처리 장치에 의해 분할 모델들(210, 220, 230)이 처리된 결과가 획득될 것으로 예측되는 시점이, 복수 개의 분할 모델(210, 220, 230)이 제1 처리 장치에서 처리될 때 분할 모델의 결과가 획 득될 것으로 예측되는 시점보다 늦을 수 있다. 이 경우, 복수 개의 분할 모델(210, 220, 230)의 처리 장치는 제 1 처리 장치로 결정될 수 있다. 상술한 예에 한하지 않고, 각 분할 모델(210, 220, 230)의 처리 장치는 다양한 방법 및 기준에 따라서 결정될 수 있다. 도 3은 일 실시 예에 의한 각 분할 모델(310, 320, 330)에 대한 처리 장치를 결정하는 방법을 설명하기 위한 도 면이다. 도 3을 참조하면, 일 실시 예에 의한 인공지능 모델은, 병렬적으로 동시에 처리될 수 있는 복수 개의 분할 모델 (310, 320, 330)로 분할될 수 있다. 일 실시 예에 의하면, 적어도 하나의 처리 장치 중에서, 각 분할 모델(310, 320, 330)을 처리할 장치가 결정될 수 있다. 일 실시 예에 의하면, 각 분할 모델(310, 320, 330)은, 각각 서로 다른 하드웨어(ex. CPU, GPU, NPU 등)에 의 하여 처리될 수 있는 연산자를 포함할 수 있다. 예를 들면, 분할 모델들(310, 320, 330) 중 분할 모델(310, 330)은, CPU에 의해 처리될 수 있고, 분할 모델은 GPU에 의해 처리될 수 있다. 따라서, 일 실시 예에 의하면, 하나의 처리 장치에 의하여, 서로 다른 하드웨어(ex. CPU, GPU)에 의해 복수 개 의 분할 모델들이 처리되는 경우, 하드웨어 전환에 따른 스위칭 시간이 추가로 소요될 수 있다. 예를 들어, 분할 모델(310, 320)에 대한 제1 처리 장치의 처리 예측 시간은, 각 분할 모델(310, 320)이 차 례대로 각각 다른 하드웨어, 즉, CPU 및 GPU에 의하여 처리되는데 소요되는 시간 및 CPU에서 GPU로 동작되는 하 드웨어의 전환에 의한 스위칭 시간을 더한 시간을 포함하는 값으로 결정될 수 있다. 반면에, 각 분할 모델(310, 320)이 각각 다른 처리 장치에 의해 처리됨에 따라, 하드웨어 전환 동작이 수행되지 않는 경우, 처리 예측 시간에 스위칭 시간이 포함되지 않을 수 있다. 예를 들어, 분할 모델은 제1 처리 장 치의 CPU에 의해 분할 모델은 제2 처리 장치의 GPU에 의해 처리되는 경우, 각 처리 장치에서는 하드웨어 전환 동작이 수행되지 않음에 따라서, 스위칭 시간은 고려되지 않을 수 있다. 일 실시 예에 의하면, 스위칭 시간을 고려하여 예측된 각 처리 장치에 의한 분할 모델의 처리 예측 시간에 기초 하여, 각 분할 모델이 처리될 장치가 결정될 수 있다. 도 4는 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 5는 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 4를 참조하면, 전자 장치는, 프로세서, 통신부 및 메모리을 포함할 수 있다. 그러 나, 도 4에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니다. 도 4에 도시된 구성 요 소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 도 4에 도시된 구성 요소보다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 예를 들면, 전자 장치는 도 5에 도시된 바와 같이, 일 실시예에 따른 전자 장치는, 프로세서 , 통신부 및 메모리 이외에 사용자 입력부, 출력부, 센싱부, 및 A/V 입 력부를 더 포함할 수도 있다. 사용자 입력부는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방 식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 사용자 입력부는, 인공지능 모델을 처리하기 위한 사용자 입력을 수신할 수 있다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레 이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 전자 장치에서 처리되는 정보를 표시 출력한다. 일 실시 예에 의하면, 디스플레이 부는 인공지능 모델이 처리된 결과와 관련된 정보를 표시 출력할 수 있다. 한편, 디스플레이부와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이부 는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발 광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 전자 장치의 구현 형태에 따라 전자 장치는 디스플레이부를 2개 이상 포함할 수도 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력한다. 진동 모터는 진동 신호를 출력할 수 있다. 또한, 진동 모터는 터치스크린에 터치가 입력되는 경우 진동 신호를 출력할 수도 있다. 일 실시 예에 의하면, 음향 출력부 및 진동 모터는 인공지능 모델 이 처리된 결과와 관련된 정보를 출력할 수 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 출력부, 센싱부, 통신부 , A/V 입력부 등을 전반적으로 제어할 수 있다. 전자 장치는 적어도 하나의 프로세서를 포함할 수 있다. 예를 들면, 전자 장치는 CPU(Central Processing Unit), GPU(Graphics Processing Unit), NPU(Neural Processing Unit) 등의 다양한 종류의 프로세서를 포함할 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리로부터 프로세서에 제공되거나, 통신부를 통해 수신되어 프로 세서로 제공될 수 있다. 예를 들면 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드 에 따라 명령을 실행하도록 구성될 수 있다. 일 실시 예에 의한 프로세서는 인공지능 모델을 분할하여, 병렬로 처리될 수 있는 복수 개의 분할 모델을 획득하고, 복수 개의 분할 모델 중 연산량이 가장 많은 제1 분할 모델을 처리할 제1 처리 장치를 결정할 수 있 다. 또한, 프로세서는, 제1 처리 장치에 의해 제1 분할 모델이 처리되는데 소요되는 시간을 예측하고, 예 측된 시간에 기초하여, 복수 개의 분할 모델 중 제2 분할 모델이 처리될 제2 처리 장치를 결정할 수 있다. 일 실시 예에 의한 프로세서는, 제2 분할 모델에 대한 처리 예측 시간이 제1 처리 장치에 의한 제1 분할 모델의 처리 예측 시간 이내인, 적어도 하나의 장치를 식별하고, 식별된 적어도 하나의 장치 중에서, 제2 분할 모델을 처리할 제2 처리 장치를 결정할 수 있다. 일 실시 예에 의하면, 프로세서는, 제2 분할 모델에 대 한 각 장치의 처리 예측 시간을 제외한 적어도 하나의 기준에 기초하여, 상기 식별된 적어도 하나의 장치 중에서, 제2 분할 모델이 처리될 상기 제2 처리 장치를 결정할 수 있다. 일 실시 예에 의한 적어도 하나의 기준은, 각 처리 장치가 제2 분할 모델을 처리하는 상황과 관련하여, 제2 분 할 모델을 처리하기에 적합한지 여부를 판단하기 위한 기준을 포함할 수 있다. 일 실시 예에 의하면, 제2 분할 모델의 처리 결과가 먼저 출력되어도, 제1 분할 모델의 처리 결과가 출력될 때 까지, 제2 분할 모델의 처리 결과는 다음 분할 모델의 처리에 이용되지 않은 상태로 대기할 수 있다. 따라서, 일 실시 예에 의한 제2 분할 모델은, 빠르게 처리될 필요가 없으므로, 제2 처리 장치는, 처리 시간 이외에 다른 적어도 하나의 기준에 따라서, 결정될 수 있다. 또한, 일 실시 예에 의하면, 위와 동일한 이유로, 제2 처리 장치는, 제2 분할 모델을 제1 분할 모델보다 빠르게 처리할 필요가 없다. 따라서, 제2 처리 장치는, 제1 분할 모델의 처리 예측 시간에 관한 정보를 이용하여, 제2 처리 장치의 상태에 따라서, 처리 속도를 적절히 조절하여, 제1 분할 모델의 처리 완료되기 전에, 제2 분할 모 델을 처리할 수 있다. 일 실시 예에 의한 제1 분할 모델의 처리 예측 시간에 관한 정보는, 전자 장치에서, 제2 처리 장치로 전 달될 수 있으나, 이에 한하지 않고, 제1 처리 장치에서 생성되어, 제2 처리 장치로 전달될 수도 있다. 일 실시 예에 의한 제1 분할 모델의 처리 예측 시간에 관한 정보는, 제1 처리 장치의 상태에 따라 처리 예측 시간이 실 시간으로 변화될 수 있다. 따라서, 제2 처리 장치는, 실시간으로 변화되는 제1 처리 장치의 처리 예측 시간의 정보를 획득하여, 제2 분할 모델을 적절한 속도로 처리할 수 있다. 센싱부는, 전자 장치의 상태 또는 전자 장치 주변의 상태를 감지하고, 감지된 정보를 프로세 서로 전달할 수 있다. 센싱부는, 지자기 센서(Geomagnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 통신부는, 전자 장치가 서버 또는 외부 장치(미도시)와 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부, 방송 수신부 를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다 양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 구현 예에 따라서 전자 장치가 방송 수신부를 포함하지 않을 수도 있다. 일 실시 예에 의한, 통신부는 외부로부터 분산 처리될 인공지능 모델에 대한 처리 요청을 수신할 수 있다. 또한, 일 실시 예에 의한, 통신부는 제1 처리 장치 및 제2 처리 장치로, 제1 분할 모델 및 제2 분 할 모델에 대한 처리를 요청하기 위한 정보를 전송할 수 있다. 상술한 예에 한하지 않고, 통신부는, 인공 지능 모델을 분산처리 하는데 필요한 정보를 송수신할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 일 실시 예에 의한 A/V 입력부는 인공지능 모델을 분산 처리하는데 필요한 데이터를 획득할 수 있다. 예 를 들면, A/V 입력부는, 인공지능 모델을 분산 처리하기 위한 사용자의 제스처 또는 음성 입력을 수신할 수 있다. 상술한 예에 한하지 않고, A/V 입력부는, 인공지능 모델을 분산 처리하는데 필요한 다양한 데이 터를 획득할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 일 실시 예에 의한 메모리는 인공지능 모델을 분산 처리하는데 필요한 다양한 데이터를 저장할 수 있다. 예를 들면, 메모리는, 분산 처리될 수 있는 인공지능 모델에 관한 정보를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 애플리케이션 별로 전자 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 프로세서 로 전달할 수 있다. 일부 실시예에 따른 터치 스크린 모듈은 터치 코드를 인식하고 분석할 수 있다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 터치스크린의 터치 또는 근접 터치를 감지하기 위해 터치스크린의 내부 또는 근처에 다양한 센서가 구비될 수 있다. 터치스크린의 터치를 감지하기 위한 센서의 일례로 촉각 센서가 있다. 촉각 센서는 사람이 느끼는 정도로 또는 그 이상으로 특정 물체의 접촉을 감지하는 센서를 말한다. 촉각 센서는 접촉면의 거칠기, 접촉 물체의 단 단함, 접촉 지점의 온도 등의 다양한 정보를 감지할 수 있다. 사용자의 터치 제스처에는 탭, 터치&홀드, 더블 탭, 드래그, 패닝, 플릭, 드래그 앤드 드롭, 스와이프 등이 있 을 수 있다. 알림 모듈은 전자 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 도 6은 일 실시 예에 의한 전자 장치에서 인공지능 모델을 분산 처리하는 방법을 나타낸 순서도이다. 도 6을 참조하면, 단계 610에서, 일 실시 예에 의한 전자 장치는, 분산 처리될 인공지능 모델을 획득할 수 있다. 일 실시 예에 의한 전자 장치는, 외부로부터 인공지능 모델에 대한 처리 요청을 수신함에 따라 서, 인공지능 모델의 분산 처리를 수행할 수 있다. 이에 한하지 않고, 외부 요청 없이, 전자 장치의 내부 동작에 따라서, 인공지능 모델의 분산 처리를 수행할 수도 있다. 일 실시 예에 의한 인공지능 모델은, 처리 요청을 전송하는 외부 장치(미도시)로부터 수신될 수 있다. 또는, 처 리 요청을 전송하는 외부 장치(미도시)로부터 수신된, 인공지능 모델의 식별 정보에 기초하여, 인공지능 모델을 다른 장치로부터 수신할 수도 있다. 상술한 예에 한하지 않고, 전자 장치는, 분산 처리하기 위한 인공지 능 모델을 다양한 방법에 따라서 획득할 수 있다. 단계 620에서, 일 실시 예에 의한 전자 장치는 인공지능 모델을 분할하여, 병렬로 처리될 수 있는 복수 개의 분할 모델을 획득할 수 있다. 일 실시 예에 의한 병렬로 처리될 수 있는 복수 개의 분할 모델은, 분기점 및 합류점에 기초하여 식별될 수 있다. 예를 들어, 복수 개의 분할 모델은, 동일한 하나의 분기점을 입력으로 하고, 동일한 하나의 합류점을 출력으로 하는 모델일 수 있다. 상술한 예에 한하지 않고, 복수 개의 분할 모델은 다양한 방법에 따라서, 획득될 수 있다. 일 실시 예에 의한 인공지능 모델이 처리 장치의 하드웨어 특징에 따라서, 가속 연산될 수 있는 연산자를 포함 할 수 있다. 일 실시 예에 의하면, 인공지능 모델이 분할됨으로써 획득된, 복수 개의 분할 모델은, 처리 장치의 하드웨어 특징에 따라서, 가속 연산될 수 있는 연산자를 각각 개별적으로 포함하는, 적어도 하나의 분할 모델을 포함할 수 있다. 따라서, 각각의 연산자마다 적합한 처리 장치가 결정될 수 있도록, 인공지능 모델이 추가적으 로 분할될 수 있다.단계 630에서, 일 실시 예에 의한 전자 장치는, 복수 개의 분할 모델 중 연산량이 가장 많은 제1 분할 모 델을 처리할 제1 처리 장치를 결정할 수 있다. 일 실시 예에 의한 제1 분할 모델은, 분기점 및 합류점을 각각 입력 및 출력으로 하는 분할 모델일 수 있다. 또 한, 일 실시 예에 의한 제1 분할 모델은, 인공지능 모델의 분기점 및 합류점 사이의 부분에 대한 분할 모델 중 연산량이 가장 많은 것으로 판단되는, 분할 모델일 수 있다. 일 실시 예에 의한 제1 분할 모델은, 직렬적인 복수 개의 분할 모델을 포함하는 분할 모델일 수 있다. 예를 들 어, 인공지능 모델의 분기점 및 합류점 사이의 복수 개의 라인을 따라서 복수 개의 분할 모델로 분할될 수 있고, 이중 어느 하나의 라인이 가속 연산될 수 있는 연산자를 포함함에 따라서, 상기 라인에 존재하는 적어도 하나의 연산자를 포함하는 직렬적인 복수 개의 분할 모델이 생성될 수 있다. 이 경우, 제1 분할 모델은, 상기 하나의 라인에 대해 생성된 직렬적인 복수 개의 분할 모델을 포함할 수 있다. 단계 640에서, 일 실시 예에 의한 전자 장치는, 제1 처리 장치에 의해 제1 분할 모델이 처리되는데 소요 되는 시간을 예측할 수 있다. 다만, 일 실시 예에 의하면, 직렬적인 복수 개의 분할 모델을 포함하는, 제1 분할 모델은, 적어도 하나의 제1 처리 장치에 의해 처리될 수 있다. 이 경우, 단계 640에서, 적어도 하나의 제1 처리 장치에 의해, 제1 분할 모델이 처리되는데 소요되는 시간이 예측될 수 있다. 또한, 일 실시 예에 의한 처리 예측 시간은, 제1 분할 모델이 복수 개의 하드웨어에 의해 처리되는지 여부에 따 라서, 결정될 수 있다. 예를 들어, 제1 분할 모델이, 복수 개의 하드웨어에 의해 처리될 것으로 예측되는 경우, 하드웨어 전환에 따른 스위칭 시간이 더 소요될 수 있다. 또한, 제1 분할 모델이 직렬적으로 분할되어, 복수 개 의 제1 처리 장치에 의해 처리되는 경우, 처리 장치들 간 처리 결과가 전달되는데 시간이 더 소요될 수 있다. 따라서, 제1 분할 모델에 대한 처리 예측 시간은, 상술한 스위칭 시간 및 처리 결과가 다른 장치로 전달되는데 소요되는 시간 중 적어도 하나가 더 고려됨으로써, 결정될 수 있다. 단계 650에서, 일 실시 예에 의한 전자 장치는, 단계 640에서 예측된 시간에 기초하여, 복수 개의 분할 모델 중 제2 분할 모델이 처리될 제2 처리 장치를 결정할 수 있다. 일 실시 예에 의한 제2 처리 장치는, 제1 분할 모델의 처리 예측 시간에 기초하여, 결정될 수 있다. 일 실시 예 에 의하면, 제2 분할 모델에 대한 각 처리 장치의 처리 예측 시간이, 제1 분할 모델의 처리 예측 시간 이내인 적어도 하나의 처리 장치가 식별될 수 있다. 일 실시 예에 의한 제2 분할 모델에 대한 각 처리 장치의 처리 예측 시간은, 제2 분할 모델이 복수 개의 하드웨 어에 의해 처리되는지 여부에 따라서, 결정될 수 있다. 예를 들어, 제2 분할 모델이, 각 처리 장치에 포함된 복 수 개의 하드웨어에 의해 처리될 것으로 예측되는 경우, 하드웨어 전환에 따른 스위칭 시간이 더 소요될 수 있 다. 따라서, 제2 분할 모델에 대한 각 처리 장치의 처리 예측 시간은, 상술한 스위칭 시간이 더 고려됨으로써, 결정될 수 있다. 또한, 제2 분할 모델이 직렬적으로 분할되어, 복수 개의 제2 처리 장치에 의해 처리되는 경우, 처리 장치들 간 처리 결과가 전달되는데 시간이 더 소요될 수 있다. 따라서, 제2 분할 모델에 대한 처리 예측 시간은, 상술한 스위칭 시간 및 처리 결과가 다른 장치로 전달되는데 소요되는 시간 중 적어도 하나가 더 고려됨으로써, 결정될 수 있다. 일 실시 예에 의한 전자 장치는, 각 처리 장치의 제2 분할 모델에 대한 처리 예측 시간이, 단계 640에서 예측된 제1 분할 모델의 처리 예측 시간 이내인 것으로 판단된 적어도 하나의 처리 장치 중에서, 제2 분할 모델 에 대한 각 처리 장치의 처리 예측 시간을 제외한 적어도 하나의 기준에 기초하여, 제2 분할 모델이 처리될 제2 처리 장치를 결정할 수 있다. 일 실시 예에 의한 적어도 하나의 기준은, 각 처리 장치가 제2 분할 모델을 처리하는 상황과 관련하여, 제2 분 할 모델을 처리하기에 적합한지 여부를 판단하기 위한 기준을 포함할 수 있다. 예를 들면, 각 처리 장치의 상태 또는 제2 분할 모델을 처리하는데 이용되는 자원에 관한 정보 등 다양한 기준에 기초하여, 제2 처리 장치가 결 정될 수 있다. 단계 660에서, 일 실시 예에 의한 전자 장치는, 단계 630 및 650에서 결정된 제1 처리 장치 및 제2 처리 장치로, 제1 분할 모델 및 제2 분할 모델에 대한 처리를 각각 요청하여, 인공지능 모델을 분산 처리할 수 있다. 일 실시 예에 의하면, 제2 처리 장치는, 제1 분할 모델이 제1 처리 장치에 의해 처리되는데 소요되는 시간에 대 하여 예측된 정보에 기초하여, 제2 분할 모델을 처리할 수 있다. 예를 들면, 제2 처리 장치는, 제1 분할 모델의처리 예측 시간 이내에, 제2 분할 모델이 처리될 수 있도록, 제2 분할 모델을 처리하는 속도를 제2 처리 장치의 현재 상태를 고려하여 조절할 수 있다. 예를 들면, 제2 처리 장치에서 새로운 프로세스가 시작됨에 따라서, 제2 분할 모델을 처리하는데 이용할 수 있는 제2 처리 장치의 자원이 줄어든 경우, 제2 처리 장치는, 줄어든 자원량 에 맞춰, 제2 분할 모델을 처리하는 속도를 느리게 조절할 수 있다. 일 실시 예에 의하면, 제2 분할 모델이 제1 분할 모델보다 먼저 처리되어도, 제2 분할 모델의 처리 결과는 제1 분할 모델의 처리 결과가 출력될 때까지, 이용되지 않고 대기할 수 있다. 일 실시 예에 의한 제1 분할 모델 및 제2 분할 모델의 처리 결과는, 합류점 이하의 연산자에서 함께 처리될 수 있으므로, 어느 하나의 처리 결과가 더 빠르게 나와도, 먼저 이용되지 않을 수 있다. 따라서, 제2 처리 장치는, 제2 분할 모델을 빠르게 처리할 필 요 없이, 제2 분할 모델을 처리하는 속도를 자신의 상황에 맞게 적절히 조절함으로써, 제1 분할 모델의 처리 예 측 시간 이내에 분할 모델을 처리할 수 있다. 도 7은 일 실시 예에 의한 복수 개의 분할 모델에 대한 처리 요청을 전송하는 방법을 나타낸 순서도이다. 도 7을 참조하면, 단계 710에서, 일 실시 예에 의한 전자 장치는, 인공지능 모델이 분할된 복수 개의 분 할 모델 중 연산량이 가장 많은 분할 모델에 대한 처리 예측 시간을 획득할 수 있다. 다만, 단계 710의 연산량 이 가장 많은 분할 모델은, 병렬적으로 함께 처리될 수 있는 다른 분할 모델이 존재하고, 분기점 및 합류점을 각각 입력 및 출력으로 하는 분할 모델일 수 있다. 상술한 예에 한하지 않고, 단계 710의 연산량이 가장 많은 분할 모델은, 다양한 특징을 가진 분할 모델일 수 있다. 단계 720에서, 일 실시 예에 의한 전자 장치는, 단계 710에서 획득된 처리 예측 시간에 기초하여, 다른 분할 모델에 대한 처리 장치를 결정할 수 있다. 일 실시 예에 의하면, 상술한 다른 분할 모델은, 단계 710의 연 산량이 가장 많은 분할 모델과 병렬적으로 함께 처리될 수 있고, 동일한 분기점 및 동일한 합류점을 각각 입력 및 출력으로 하는 분할 모델일 수 있다. 일 실시 예에 의하면, 단계 710의 처리 예측 시간 이내에, 상기 다른 분할 모델을 처리할 수 있는지에 따라서, 처리 장치가 결정될 수 있다. 단계 730에서, 일 실시 예에 의한 전자 장치는, 단계 710에서 획득된 처리 예측 시간에 기초하여, 동기화 정보 및 가드 타임 정보를 결정할 수 있다. 일 실시 예에 의한 동기화 정보는, 단계 710의 처리 예측 시간 이내에, 다른 분할 모델이 처리되는데 이용될 수 있는 정보이다. 예를 들면, 다른 분할 모델을 처리하는 장치는, 동기화 정보에 기초하여, 단계 710의 연산량이 가장 많은 분할 모델이 처리 완료되는 시점에 맞춰, 다른 분할 모델이 처리 완료될 수 있도록, 동작할 수 있다. 일 실시 예에 의한 가드 타임 정보는, 각 분할 모델을 처리하는 장치의 상황 변화에 따라서, 각 분할 모델의 처 리 예측 시간보다 상당히 늦게 처리되는지 여부를 판단하기 위한 기준으로 이용될 수 있다. 예를 들어, 단계 710의 분할 모델 및 단계 720의 다른 분할 모델의 가드 타임 정보는, 단계 710의 처리 예측 시 간에 미리 설정된 상수값을 더한 값을 포함할 수 있다. 일 실시 예에 의한, 단계 720의 다른 분할 모델은, 단계 710의 분할 모델의 처리 완료되는 시간에 맞춰 처리될 수 있으므로, 단계 710의 분할 모델의 가드 타임 정보와 동일하게 결정될 수 있다. 일 실시 예에 의한 단계 710의 처리 예측 시간은, 단계 710의 연산량이 가장 많은 분할 모델을 처리하는 장치의 상황 변화에 따라서, 실시간으로 변화될 수 있다. 일 실시 예에 의한 동기화 정보 및 가드 타임 정보는, 실시간 으로 변화되는 단계 710의 처리 예측 시간에 관한 정보가 전자 장치에서 획득됨에 따라, 실시간으로 변화 될 수 있다. 단계 740에서, 일 실시 예에 의한 전자 장치는, 복수 개의 분할 모델에 대한 처리 요청을 각 처리 장치로 전송할 수 있다. 또한, 단계 750에서, 일 실시 예에 의한 전자 장치는, 단계 730에서 결정된 동기화 정보 및 가드 타임에 관한 정보를 각 처리 장치로 전송할 수 있다. 일 실시 예에 의한 각 분할 모델의 가드 타임 정보는, 각 분할 모델을 처리하는 장치로 전달될 수 있다. 일 실 시 예에 의한 각 분할 모델을 처리하는 장치는, 가드 타임 정보에 기초하여, 분할 모델이 처리 완료되는 시점이 예측된 시점보다 상당히 늦어진 것으로 판단한 경우, 다른 장치에 의해 분할 모델이 처리될 수 있도록, 전자 장 치에 요청할 수 있다. 이에 한하지 않고, 가드 타임 정보는, 각 분할 모델의 처리 결과를 이용하는 다른 장치로 전달될 수도 있다. 일 실시 예에 의한 가드 타임 정보는, 분할 모델이 다른 장치에 의해 빠르게 처리될수 있도록, 다양한 장치로 전달되어 다양한 방법에 따라 이용될 수 있다. 일 실시 예에 의한 각 분할 모델의 가드 타임 정보는, 다른 장치로 전달되지 않고, 전자 장치에서 이용될 수도 있다. 예를 들면, 전자 장치는, 각 분할 모델의 가드 타임 정보에 기초하여, 설정된 시점까지, 각 분할 모델의 처리 결과가 출력되지 않은, 분할 모델을 식별할 수 있다. 전자 장치는, 식별된 분할 모델을 처리할 장치를 다시 결정하고, 결정된 장치로 식별된 분할 모델에 대한 처리를 요청할 수 있다. 따라서, 일 실시 예에 의한 전자 장치는 가드 타임 정보에 따라서, 분할 모델의 처리 결과의 출력이 늦어 지는지 여부를 판단할 수 있고, 분할 모델이 처리될 장치를 다시 결정하여, 최대한 빠른 시간 이내에 분할 모델 이 처리될 수 있도록, 동작할 수 있다. 일 실시 예에 의하면, 각 처리 장치에서 분할 모델이 처리되는 동안에, 단계 710의 분할 모델을 처리하는 장치 의 상황 변화에 따라서, 동기화 정보 및 가드 타임 정보가 실시간으로 변화될 수 있다. 일 실시 예에 의한 전자 장치는, 실시간으로 변화되는 동기화 정보 및 가드 타임 정보를 각 처리 장치로 주기적으로 전송할 수 있 다. 도 8은 일 실시 예에 의한 복수 개의 처리 장치를 이용하여 인공지능 모델을 분산 처리하는 방법을 나타낸 순서 도이다. 도 8을 참조하면, 단계 810-1, 810-2, 및 810-3에서, 일 실시 예에 의한 전자 장치는, 제1 처리 장치 , 제2 처리 장치 및 제3 처리 장치로부터 등록 정보를 수신할 수 있다. 일 실시 예에 의하면, 전자 장치와, 제1 처리 장치, 제2 처리 장치 및 제3 처리 장치가 동일한 네트워크로 연결 됨에 따라서, 등록 정보가 전송될 수 있다. 일 실시 예에 의한 등록 정보는, 각 처리 장치의 능력에 관한 정보를 포함할 수 있다. 일 실시 예에 의한 전자 장치는, 등록 정보에 기초하여, 인공지능 모델의 분할 모델들을 처리할 장치를 결정할 수 있다. 일 실시 예에 의한 전자 장치는, 수신된 등록 정보에 기초하여, 제1 처리 장치, 제2 처리 장치 및 제3 처리 장치를 인공지능 모델을 분산 처리하는데 이용될 수 있는 처리 장치로서, 미리 등록해 둘 수 있다. 단계 820에서, 일 실시 예에 의한 전자 장치는, 인공지능 모델에 대한 처리 요청을 수신함에 따라서, 단 계 830에서, 미리 등록된 장치 중에서, 인공지능 모델의 분할 모델이 처리될 장치를 결정할 수 있다. 일 실시 예에 의한 인공지능 모델에 대한 처리 요청은, 전자 장치 내부 동작에 따라, 인공지능 모델에 대 한 처리 동작이 수행될 수 있으나, 이에 한하지 않고, 외부로부터 인공지능 모델에 대한 처리 요청이 수신될 수 도 있다. 단계 830에서, 제1 처리 장치 및 제2 처리 장치가 인공지능 모델의 복수 개의 분할 모델이 처리될 장 치로서 결정된 경우, 단계 840-1 및 840-2에서, 복수 개의 분할 모델에 대한 처리 요청을 제1 처리 장치 및 제2 처리 장치로 전송할 수 있다. 일 실시 예에 의한 전자 장치는, 단계 840-1 및 840-2에서 전송되는 처리 요청에 더하여, 각 분할 모델에 대한 동기화 정보 및 가드 타임 정보를 더 전송할 수 있다. 단계 850-1 및 850-2에서, 분할 모델에 대한 처리 요청을 수신받은, 제1 처리 장치 및 제2 처리 장치(12 0)는, 제1 분할 모델 및 제2 분할 모델을 처리할 수 있다. 또한, 단계 860-1 및 860-2에서, 제1 분할 모델 및 제2 분할 모델이 처리된 결과가 전자 장치로 전송될 수 있다. 일 실시 예에 의한 제1 분할 모델의 일부가 처리되는데 제2 분할 모델이 처리된 결과가 이용될 수 있는 경우, 전자 장치는 제2 분할 모델의 처리 결과를 제1 처리 장치로 전달할 수 있다. 이에 한하지 않고, 제2 처리 장치가 직접 제1 처리 장치로 제2 분할 모델의 처리 결과를 전달할 수 있다. 단계 870에서, 일 실시 예에 의한 전자 장치는, 복수 개의 분할 모델이 처리된 결과에 기초하여, 인공지 능 모델을 분산 처리함으로써, 사용자에게 필요한 다양한 서비스를 제공할 수 있다. 일 실시 예에 의하면 전자 장치의 하드웨어에 따른 처리 성능의 제한 없이, 전자 장치 주변의 다양한 장치를 활 용하여, 인공지능 모델을 빠르게 처리할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다."}
{"patent_id": "10-2020-0150998", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-0150998", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 의한 인공지능 모델을 분산 처리하는 일 예를 나타내는 블록도이다. 도 2는 일 실시 예에 의한 인공지능 모델이 분할되는 일 예를 나타낸 도면이다. 도 3은 일 실시 예에 의한 각 분할 모델에 대한 처리 장치를 결정하는 방법을 설명하기 위한 도면이다. 도 4는 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 5는 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 6은 일 실시 예에 의한 전자 장치에서 인공지능 모델을 분산 처리하는 방법을 나타낸 순서도이다. 도 7은 일 실시 예에 의한 복수 개의 분할 모델에 대한 처리 요청을 전송하는 방법을 나타낸 순서도이다. 도 8은 일 실시 예에 의한 복수 개의 처리 장치를 이용하여 인공지능 모델을 분산 처리하는 방법을 나타낸 순서 도이다."}
