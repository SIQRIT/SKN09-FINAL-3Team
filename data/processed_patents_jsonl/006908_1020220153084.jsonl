{"patent_id": "10-2022-0153084", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0071207", "출원번호": "10-2022-0153084", "발명의 명칭": "환자의 의사소통을 위한 문자 입력장치 및 그 방법", "출원인": "주식회사 뉴로티엑스", "발명자": "정민경"}}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기설정된 입력 시간 동안 카메라를 이용하여 사용자의 얼굴 이미지를 획득하는 이미지 획득부;상기 입력 시간 동안 획득된 얼굴 이미지를 입력으로 하는 인공지능 기반의 의도 인식 알고리즘을 이용하여 상기 사용자의 의도를 판단하는 의도 판단부;상기 사용자의 의도 판단의 결과에 기초하여 기 설정된 문자 입력판을 시각화하는 입력판 시각화부 및 상기 문자 입력판을 주시하는 상기 사용자의 얼굴 이미지에 기초하여 문자 입력판에 구비된 복수의 문자 중 어느 하나의 문자를 출력하는 문자 출력부를 포함하는 문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 의도 판단부는,상기 입력 시간 동안 획득된 얼굴 이미지에 기초하여, 상기 사용자가 눈을 위로 뜬 것으로 판단되면 상기 사용자의 의도 판단의 결과로 '1' 값을 출력하고, 상기 사용자가 눈을 위로 뜬 것이 아닌 것으로 판단되면 상기 사용자의 의도 판단의 결과로 '0' 값을 출력하는문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 입력판 시각화부는,상기 사용자의 의도 판단의 결과로 '1' 값이 출력되면 상기 문자 입력판을 시각화하는문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 이미지 획득부는, 상기 입력 시간 동안 복수의 얼굴 이미지를 획득하고, 상기 의도 인식부는, 상기 복수의 얼굴 이미지 각각을 상기 의도 인식 알고리즘에 입력하여 복수의 의도 인식 결과를 획득하며, 상기획득된 복수의 의도 인식 결과의 평균 값이 기 설정된 의도 인식 임계값 이상인 경우 상기 사용자가 의사소통에대한 의도가 있는 것으로 판단하는 문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 문자 입력판은, 복수의 행과 복수의 열에 대응되는 위치에 상기 복수의 문자가 각각 배치되며, 범주 기반의 단어 입력판과 자음공개특허 10-2024-0071207-3-및 모음 입력판을 포함하는문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 입력판 시각화부는, 상기 범주 기반의 단어 입력판과 상기 자음 및 모음 입력판 중 어느 하나의 입력판을 시각화하고, 상기 어느 하나의 입력판에 대한 상기 사용자의 얼굴 이미지에 기초하여 다른 하나의 입력판의 시각화 여부를 판단하는 문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 입력판 시각화부는, 상기 어느 하나의 입력판에 대한 상기 사용자의 얼굴 이미지에 기초하여 상기 사용자가 기 설정된 임계 시간동안 눈을 감고 있는 것으로 판단되면, 상기 다른 하나의 입력판을 시각화하는문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 입력판 시각화부는, 상기 범주 기반의 단어 입력판 중 범주 선택판을 시각화한 이후, 상기 범주 선택판을 주시하는 상기 사용자의얼굴 이미지에 기초하여 '인사 범주판', '가족 범주판', '감정 및 기분 범주판', '일상 대화 범주판', '신체 범주판', '병원 및 증상 범주판', '옷, 청결 및 정리 범주판', '휴식 및 TV 범주판', '움직임 및 위치 범주판', '시간 및 날씨 범주판', '음식 범주판', '사물 범주판', '장소 범주판', '긴급 상황 범주판', '사람 범주판'중 어느 하나의 범주판을 시각화하는문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 문자 출력부는,상기 어느 하나의 범주판을 주시하는 상기 사용자의 얼굴 이미지에 기초하여 상기 어느 하나의 문자를 출력하는 문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서, 상기 문자 출력부는, 상기 문자 입력판을 주시하는 상기 사용자의 얼굴 이미지로부터 상기 복수의 행과 상기 복수의 열이 교차하는복수의 교차 영역 중 상기 사용자가 주시하는 영역에 위치하는 상기 어느 하나의 문자를 출력하는문자 입력장치."}
{"patent_id": "10-2022-0153084", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "이미지 획득부에서, 기설정된 입력 시간 동안 카메라를 이용하여 사용자의 얼굴 이미지를 획득하는 단계;의도 판단부에서, 상기 입력 시간 동안 획득된 얼굴 이미지를 입력으로 하는 인공지능 기반의 의도 인식 알고리공개특허 10-2024-0071207-4-즘을 이용하여 상기 사용자의 의도를 판단하는 단계;입력판 시각화부에서, 상기 사용자의 의도 판단의 결과에 기초하여 기 설정된 문자 입력판을 시각화하는 단계및 문자 출력부에서, 상기 문자 입력판을 주시하는 상기 사용자의 얼굴 이미지에 기초하여 문자 입력판에 구비된복수의 문자 중 어느 하나의 문자를 출력하는 단계를 포함하는 문자 입력방법."}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 문자 입력장치 및 그 방법에 관한 것으로서, 일실시예에 따른 문자 입력장치는 기설정된 입력 시간 동 안 카메라를 이용하여 사용자의 얼굴 이미지를 획득하는 이미지 획득부와, 입력 시간 동안 획득된 얼굴 이미지를 입력으로 하는 인공지능 기반의 의도 인식 알고리즘을 이용하여 사용자의 의도를 판단하는 의도 판단부와, 사용 자의 의도 판단의 결과에 기초하여 기 설정된 문자 입력판을 시각화하는 입력판 시각화부 및 문자 입력판을 주시 하는 사용자의 얼굴 이미지에 기초하여 문자 입력판에 구비된 복수의 문자 중 어느 하나의 문자를 출력하는 문자 출력부를 포함한다."}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 문자 입력장치 및 그 방법에 관한 것으로, 보다 상세하게는 눈동자의 움직임이 불안정한 환자의 원활 한 의사소통을 지원하기 위해 의도 판단 및 문자 입력을 수행하는 기술적 사상에 관한 것이다."}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "잠금 증후군(locked-in syndrome)은 의식은 있으나 전신 마비로 인하여 외부 자극에 반응하지 못하는 상태를 의 미하며, 평생 방안에 갇혀 살 수밖에 없고 외부와의 소통도 사실상 거의 불가능하여 감금 증후군으로 불리기도 한다. 이러한 잠금 증후군 환자들은 다른 사람과의 정상적인 의사소통을 위해 문자 입력장치를 필요로 하나, 기존의 장치는 환자의 사지 움직임이 정상적일 것으로 상정되어 있기 때문에, 특정 움직임 조차 불안정한 마비 환자에 게 적용하는데에는 한계를 보이고 있다. 구체적으로, 기존의 문자 입력장치는 아이트래커 등을 활용하여 환자의 의도를 인식하고 있으나, 이는 환자의 눈동자 움직임이 정상인 것을 가정하여 개발되었기 때문에 눈동자 움직임이 불안정한 환자의 의도를 인식함에 있어 매우 높은 제약이 따르고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1768106호, \"뇌-컴퓨터 인터페이스 기반 문자 입력 장치 및 방법\""}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 사용자의 얼굴 인식 및 눈동자 상태에 기반하는 인공지능 알고리즘을 이용하여 실시간으로 사용자의 의도 분석을 수행함으로써, 눈동자의 움직임이 불안정한 사용자의 의사소통을 가능하게 하는 문자 입력장치 및 그 방법을 제공하고자 한다. 또한, 본 발명은 눈동자의 움직임이 불안정한 사용자에게 최적화되어 보다 정교하게 사용자의 의도를 인식할 수 있는 문자 입력장치 및 그 방법을 제공하고자 한다. 또한, 본 발명은 사용자의 신체에 생체신호 모니터링 수단을 부착하지 않고 카메라만을 활용하여 사용자의 의도 인식 및 문자 입력을 수행함으로써, 사용자의 신체의 자유도 및 시스템의 이동성이 매우 높은 문자 입력장치 및 그 방법을 제공하고자 한다."}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른 문자 입력장치는 기설정된 입력 시간 동안 카메라를 이용하여 사용자의 얼굴 이미지 를 획득하는 이미지 획득부와, 입력 시간 동안 획득된 얼굴 이미지를 입력으로 하는 인공지능 기반의 의도 인식 알고리즘을 이용하여 사용자의 의도를 판단하는 의도 판단부와, 사용자의 의도 판단의 결과에 기초하여 기 설정 된 문자 입력판을 시각화하는 입력판 시각화부 및 문자 입력판을 주시하는 사용자의 얼굴 이미지에 기초하여 문자 입력판에 구비된 복수의 문자 중 어느 하나의 문자를 출력하는 문자 출력부를 포함할 수 있다. 일측에 따르면, 의도 판단부는 입력 시간 동안 획득된 얼굴 이미지에 기초하여, 사용자가 눈을 위로 뜬 것으로 판단되면 사용자의 의도 판단의 결과로 '1' 값을 출력하고, 사용자가 눈을 위로 뜬 것이 아닌 것으로 판단되면 사용자의 의도 판단의 결과로 '0' 값을 출력할 수 있다. 일측에 따르면, 입력판 시각화부는 사용자의 의도 판단의 결과로 '1' 값이 출력되면 문자 입력판을 시각화할 수 있다. 일측에 따르면, 이미지 획득부는 입력 시간 동안 복수의 얼굴 이미지를 획득하고, 의도 인식부는 복수의 얼굴 이미지 각각을 의도 인식 알고리즘에 입력하여 복수의 의도 인식 결과를 획득하며, 획득된 복수의 의도 인식 결 과의 평균 값이 기 설정된 의도 인식 임계값 이상인 경우 사용자가 의사소통에 대한 의도가 있는 것으로 판단할 수 있다. 일측에 따르면, 문자 입력판은 복수의 행과 복수의 열에 대응되는 위치에 복수의 문자가 각각 배치되며, 범주 기반의 단어 입력판과 자음 및 모음 입력판을 포함할 수 있다. 일측에 따르면, 입력판 시각화부는 범주 기반의 단어 입력판과 자음 및 모음 입력판 중 어느 하나의 입력판을 시각화하고, 어느 하나의 입력판에 대한 사용자의 얼굴 이미지에 기초하여 다른 하나의 입력판의 시각화 여부를 판단할 수 있다. 일측에 따르면, 입력판 시각화부는 어느 하나의 입력판에 대한 사용자의 얼굴 이미지에 기초하여 사용자가 기 설정된 임계 시간동안 눈을 감고 있는 것으로 판단되면, 다른 하나의 입력판을 시각화할 수 있다. 일측에 따르면, 입력판 시각화부는 범주 기반의 단어 입력판 중 범주 선택판을 시각화한 이후, 범주 선택판을 주시하는 사용자의 얼굴 이미지에 기초하여 '인사 범주판', '가족 범주판', '감정 및 기분 범주판', '일상 대화 범주판', '신체 범주판', '병원 및 증상 범주판', '옷, 청결 및 정리 범주판', '휴식 및 TV 범주판', '움직임 및 위치 범주판', '시간 및 날씨 범주판', '음식 범주판', '사물 범주판', '장소 범주판', '긴급 상황 범주판', '사람 범주판' 중 어느 하나의 범주판을 시각화할 수 있다. 일측에 따르면, 문자 출력부는 어느 하나의 범주판을 주시하는 사용자의 얼굴 이미지에 기초하여 어느 하나의 문자를 출력할 수 있다. 일측에 따르면, 문자 출력부는 문자 입력판을 주시하는 사용자의 얼굴 이미지로부터 복수의 행과 복수의 열이 교차하는 복수의 교차 영역 중 사용자가 주시하는 영역에 위치하는 어느 하나의 문자를 출력할 수 있다. 본 발명의 일실시예에 따른 문자 입력방법은 이미지 획득부에서 기설정된 입력 시간 동안 카메라를 이용하여 사 용자의 얼굴 이미지를 획득하는 단계와, 의도 판단부에서 입력 시간 동안 획득된 얼굴 이미지를 입력으로 하는 인공지능 기반의 의도 인식 알고리즘을 이용하여 사용자의 의도를 판단하는 단계와, 입력판 시각화부에서 사용 자의 의도 판단의 결과에 기초하여 기 설정된 문자 입력판을 시각화하는 단계 및 문자 출력부에서 문자 입력판 을 주시하는 사용자의 얼굴 이미지에 기초하여 문자 입력판에 구비된 복수의 문자 중 어느 하나의 문자를 출력 하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일실시예에 따르면, 본 발명은 사용자의 얼굴 인식 및 눈동자 상태에 기반하는 인공지능 알고리즘을 이용하여 실시간으로 사용자의 의도 분석을 수행함으로써, 눈동자의 움직임이 불안정한 사용자의 의사소통을 지원할 수 있다. 일실시예에 따르면, 본 발명은 눈동자의 움직임이 불안정한 사용자에게 최적화되어 보다 정교하게 사용자의 의 도를 인식할 수 있다. 일실시예에 따르면, 본 발명은 사용자의 신체에 생체신호 모니터링 수단을 부착하지 않고 카메라만을 활용하여 사용자의 의도 인식 및 문자 입력을 수행함으로써, 사용자의 신체의 자유도 및 시스템의 이동성을 극대화할 수 있다."}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시예 들은 다양한 형태로 실시될 수 있으며 본 명세서에 설명된 실시예들에 한정되지 않는다. 본 발명의 개념에 따른 실시예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시예 들을 도면에 예시하고 본 명세서에 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시예들을 특정한 개시형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 변경, 균등물, 또 는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한 정되어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만, 예를 들면 본 발 명의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하 게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 표현들, 예를 들면 \"~사이에\"와 \"바로~사이에\" 또는 \"~에 직접 이웃하는\" 등도 마찬가지로 해석 되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예들을 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 실시예들을 첨부된 도면을 참조하여 상세하게 설명한다. 그러나, 특허출원의 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1은 일실시예에 따른 문자 입력장치를 설명하는 도면이다. 도 1을 참조하면, 문자 입력장치는 사용자의 얼굴 인식 및 눈동자 상태에 기반하는 인공지능 알고리즘을 이용하 여 실시간으로 사용자의 의도 분석을 수행함으로써, 눈동자의 움직임이 불안정한 사용자의 의사소통을 지원할 수 있다. 또한, 문자 입력장치는 눈동자의 움직임이 불안정한 사용자에게 최적화되어 보다 정교하게 사용자의 의도를 인 식할 수 있다. 또한, 문자 입력장치는 사용자의 신체에 생체신호 모니터링 수단을 부착하지 않고 카메라만을 활용하여 사용자 의 의도 인식 및 문자 입력을 수행함으로써, 사용자의 신체의 자유도 및 시스템의 이동성을 극대화할 수 있다. 구체적으로, 문자 입력장치는 도면부호 100에 도시된 바와 같이, 사용자(환자)의 얼굴 이미지를 획득하고, 획득 된 얼굴 이미지를 인공지능 기반의 의도 인식 알고리즘을 통해 분석하여 사용자의 의도를 판단할 수 있다. 또한, 문자 입력장치는 사용자의 의도 판단의 결과에 기초하여 복수의 행과 복수의 열에 대응되는 위치에 복수 의 문자가 각각 배치되는 문자 입력판을 시각화한 이후, 문자 입력판을 주시하는 사용자의 얼굴 이미지를 분석 하여 복수의 문자 중 사용자가 의도한 문자를 인식하여 출력할 수 있다. 일실시예에 따른 문자 입력장치는 이후 실시예 도 2를 통해 보다 구체적으로 설명하기로 한다. 도 2는 일실시예에 따른 문자 입력장치를 보다 구체적으로 설명하는 도면이다. 도 2를 참조하면, 일실시예에 따른 문자 입력장치는 이미지 획득부, 의도 판단부, 입력판 시각 화부 및 문자 출력부를 포함할 수 있다. 일실시예에 따른 이미지 획득부는 기설정된 입력 시간 동안 카메라를 이용하여 사용자의 얼굴 이미지를 획 득할 수 있다. 바람직하게는, 이미지 획득부는 실시간으로 사용자의 얼굴 이미지를 획득할 수 있으며, 이하에서 설명하는 의도 판단부, 입력판 시각화부 및 문자 출력부 각각에서 사용되는 얼굴 이미지는 모두 이미지 획득부를 통해 획득될 수 있다. 일실시예에 따른 의도 판단부는 입력 시간 동안 획득된 얼굴 이미지를 입력으로 하는 인공지능 기반의 의 도 인식 알고리즘을 이용하여 사용자의 의도를 판단할 수 있다. 일측에 따르면, 의도 판단부는 입력 시간 동안 획득된 얼굴 이미지에 기초하여 사용자가 눈을 위로 뜬 것으로 판단되면 사용자의 의도 판단의 결과로 '1' 값을 출력하고, 사용자가 눈을 위로 뜬 것이 아닌 것으로 판단 되면 사용자의 의도 판단의 결과로 '0' 값을 출력할 수 있다. 일례로, 의도 판단부는 사용자가 기설정된 판단 시간을 초과하여 눈을 위로 뜬 것으로 판단되면 사용자의 의도 판단의 결과로 '1' 값을 출력할 수 있다. 즉, 의도 인식 알고리즘은 사용자의 시선 방향에 기초하여 사용자의 의도를 파악하는 알고리즘일 수 있다. 예를 들면, 의도 인식 알고리즘은 사용자의 얼굴 방향 및 시선의 변화량이 기설정된 판단 임계값 이상인 경우에 사용자가 의도가 있는 것으로 판단하는 알고리즘일 수 있다. 보다 구체적인 예를 들면, 의도 인식 알고리즘은 사용자의 얼굴이 카메라 또는 문자 입력판이 시각화되는 디스 플레이 장치의 방향을 향하고(1차 판단), 사용자가 눈을 위로 뜬 것으로 판단(2차 판단)되면 사용자가 의도가 있는 것으로 판단할 수 있다. 예를 들면, 의도 인식 알고리즘은 사용자의 얼굴 형태 및 시선의 변화량이 기설정된 판단 임계값 이상인 경우에 사용자가 의도가 있는 것으로 판단하는 알고리즘일 수도 있다. 보다 구체적인 예를 들면, 의도 인식 알고리즘은 입력 시간 동안 획득된 얼굴 이미지로부터 얼굴 영역을 인식하 고, 인식된 얼굴 영역에서 복수의 특징점을 추출하며, 추출된 복수의 추출점의 배치 상태에 기초하여 사용자의 얼굴 형태를 인식할 수 있다. 또한, 의도 인식 알고리즘은 기 학습된 얼굴 형태 데이터와 인식된 얼굴 형태 데이터를 비교하여 사용자가 의도 가 있는지 여부를 1차 판단하고, 사용자가 기설정된 판단 시간을 초과하여 눈을 위로 뜬 것인지를 판단하여 사 용자가 의도가 있는지 여부를 2차 판단하며, 1차 판단 및 2차 판단의 결과가 모두 의도가 있다고 판단되면 사용 자의 의도 판단의 결과로 '1' 값을 출력할 수 있다. 한편, 의도 인식 알고리즘은 사용자의 얼굴 방향에 따른 1차 판단 결과와, 사용자의 얼굴 형태에 따른 2차 판단 결과 및 시선의 변화량에 따른 3차 판단 결과에 기초하는 알고리즘으로, 1차 내지 3차 판단의 결과가 모두 의도 가 있다고 판단되면 사용자의 의도 판단의 결과로 '1' 값을 출력하여 보다 정교하게 사용자의 의도를 인식할 수 있다. 일측에 따르면, 의도 판단부는 의도 인식 알고리즘을 사전에 학습하고, 학습된 의도 인식 알고리즘에 기초 하여 사용자의 의도를 판단할 수 있다.구체적으로, 의도 판단부는 환자가 눈을 위로 뜨며 의도를 표현할 때와 그렇지 않을 때의 복수의 얼굴 이 미지를 획득하고, 획득된 복수의 환자의 얼굴 이미지 각각에 대하여 환자가 눈을 위로 떴을 때는 '1', 눈을 위 로 뜨지 않았을 때는 '0'으로 설정하여 프레임 단위로 라벨링을 수행할 수 있다. 또한, 의도 판단부는 라벨링된 얼굴 이미지 각각에 대한 전처리를 수행하여 기설정된 크기로 이미지를 조 정하고 정규화할 수 있으며, 일례로 기설정된 크기는 224 x 224일 수 있다. 또한, 의도 판단부는 전처리된 이미지를 활용하여 사전 훈련(pre-trained)된 의도 인식 알고리즘(일례로, Efficientnet-b0)을 미세 조정(fine-tuning)할 수 있으며, ONNX(open neural network exchange)를 사용하여 CPU에서의 동작 성능을 최적화할 수 있다. 일측에 따르면, 이미지 획득부는 입력 시간 동안 복수의 얼굴 이미지를 획득하고, 의도 인식부는 복 수의 얼굴 이미지 각각을 의도 인식 알고리즘에 입력하여 복수의 의도 인식 결과를 획득하며, 획득된 복수의 의 도 인식 결과의 평균 값이 기 설정된 의도 인식 임계값 이상인 경우 사용자가 의사소통에 대한 의도가 있는 것으로 판단할 수 있다. 구체적으로, 의도 인식부는 1초 동안 약 15회 반복하여 사용자의 복수의 얼굴 이미지(즉, 15장의 얼굴 이 미지)를 획득할 수 있다. 또한, 의도 인식부는 복수의 얼굴 이미지 각각을 입력으로 하는 YOLO-v3 기반의 얼굴 인식 알고리즘을 통 해 얼굴 영역을 정사각형 형태로 취득하고, 취득된 복수의 얼굴 영역 각각에 대한 전처리를 통해 기설정된 크기 로 이미지를 조정하고 정규화할 수 있으며, 전처리된 복수의 이미지(즉, 15장의 얼굴 이미지) 각각을 의도 인식 알고리즘에 입력하여 복수의 의도 인식 결과(즉, 15장의 '0' 또는 '1'로 판별된 결과값)을 획득할 수 있으며, 획득된 복수의 의도 인식 결과의 평균 값이 기 설정된 의도 인식 임계값 이상인 경우 사용자가 의사소통에 대한 의도가 있는 것으로 판단할 수 있다. 일측에 따르면, 의도 인식부는 얼굴 이미지에 대한 전처리를 통해 화질을 개선하고, 개선된 화질의 복수의 이미지 각각을 의도 인식 알고리즘에 입력할 수 있다. 예를 들면, 의도 인식부는 얼굴 이미지를 얼굴 이미지의 4배의 해상도를 갖는 고해상도 이미지로 변환하고, 고해상도로 변환된 이미지를 노이즈 제거필터에 통과시켜 노이즈를 제거한 이후, 노이즈가 제거된 이 미지를 다시 1/4배로 사이즈 축소시켜 화질을 개선할 수 있다. 일실시예에 따른 입력판 시각화부는 사용자의 의도 판단의 결과에 기초하여 기 설정된 문자 입력판을 시각 화할 수 있다. 일측에 따르면, 입력판 시각화부는 사용자의 의도 판단의 결과로 '1' 값이 출력되거나, 복수의 의도 인식 결과의 평균 값이 기 설정된 의도 인식 임계값 이상인 경우에 문자 입력판을 시각화할 수 있다. 일측에 따르면, 문자 입력판은 복수의 행과 복수의 열에 대응되는 위치에 복수의 문자가 각각 배치되며, 범주 기반의 단어 입력판과 자음 및 모음 입력판을 포함할 수 있다. 다시 말해, 입력판 시각화부는 행/열 구조 기반의 스펠러(speller)일 수 있다. 문자 입력판은 행/열이 기설정된 활성화 시간마다 순차적으로 활성화될 수 있으며, 문자 입력장치가 동작 하거나, 화면이 전환될 때마다 효과음이 발생될 수 있다. 일측에 따르면, 입력판 시각화부는 범주 기반의 단어 입력판과 자음 및 모음 입력판 중 어느 하나의 입력 판을 시각화하고, 어느 하나의 입력판에 대한 사용자의 얼굴 이미지에 기초하여 다른 하나의 입력판의 시각화 여부를 판단할 수 있다. 구체적으로, 입력판 시각화부는 어느 하나의 입력판에 대한 사용자의 얼굴 이미지에 기초하여 사용자가 기 설정된 임계 시간동안 눈을 감고 있는 것으로 판단되면, 다른 하나의 입력판을 시각화할 수 있다. 여기서, 범주 기반의 단어 입력판은 언어 치료사의 자문을 기반으로 의사, 간병인, 가족들과의 긴밀한 논의를 통해 실사용성을 높인 형태로 구성될 수 있으며, 상위 범주에서 하위 단어로 파생되어 입력이 수행될 수 있다. 보다 구체적으로, 입력판 시각화부는 범주 기반의 단어 입력판 중 범주 선택판을 시각화한 이후, 범주 선 택판을 주시하는 사용자의 얼굴 이미지에 기초하여 '인사 범주판', '가족 범주판', '감정 및 기분 범주판', '일 상 대화 범주판', '신체 범주판', '병원 및 증상 범주판', '옷, 청결 및 정리 범주판', '휴식 및 TV 범주판', '움직임 및 위치 범주판', '시간 및 날씨 범주판', '음식 범주판', '사물 범주판', '장소 범주판', '긴급 상황 범주판', '사람 범주판' 중 어느 하나의 범주판을 시각화할 수 있다. 일실시예에 따른 문자 출력부는 문자 입력판을 주시하는 사용자의 얼굴 이미지에 기초하여 문자 입력판에 구비된 복수의 문자 중 어느 하나의 문자를 출력할 수 있다. 일측에 따르면, 문자 출력부는 문자 입력판을 주시하는 사용자의 얼굴 이미지로부터 복수의 행과 복수의 열이 교차하는 복수의 교차 영역 중 사용자가 주시하는 영역에 위치하는 어느 하나의 문자를 출력할 수 있다. 또한, 문자 출력부는 어느 하나의 범주판을 주시하는 사용자의 얼굴 이미지에 기초하여 어느 하나의 문자 를 출력할 수 있다. 일측에 따르면, 문자 출력부는 복수의 교차 영역 중 사용자가 주시하는 영역과, 사용자가 주시하는 영역과 인접한 영역들의 크기를 기설정된 크기만큼 확대시킬 수 있으며, 크기가 확대된 영역들 중 어느 하나의 영역을 주시하는 사용자의 얼굴 이미지에 기초하여 어느 하나의 문자를 출력할 수도 있다. 예를 들면, 문자 출력부는 사용자가 주시하는 영역이 2행 3열이 교차하는 영역으로 판단되면 1행 2열, 1행 3열, 1행 4열, 2행 2열, 2행 3열, 2행 4열, 3행 2열, 3행 3열, 3행 4열이 각각 교차하는 영역(즉, 9개의 영 역)의 크기를 확대하고, 사용자가 주시하는 영역이 1행 1열이 교차하는 영역으로 판단되면 1행 1열, 1행 2열, 2 행 1열, 2행 2열이 각각 교차하는 영역(즉, 4개의 영역)의 크기를 확대하며, 확대된 복수의 영역 중 어느 하나 의 영역을 주시하는 사용자의 얼굴 이미지에 기초하여 어느 하나의 문자를 출력함으로써, 보다 정확하게 사용자 가 의도한 문자를 출력할 수 있다. 도 3a 내지 도 3b는 일실시예에 따른 자음 및 모음 입력판의 예시를 설명하는 도면이다. 도 3a 내지 도 3b를 참조하면, 일실시예에 따른 자음 및 모음 입력판은 사용자가 자주 입력하는 문자(도면부호 301 참조)를 고려하여 자음 및 모음이 최적화 배치될 수 있다. 구체적으로, 자음 및 모음 입력판은 1행 1열의 경우 스펠러의 동작을 두 번 기다려야하지만 3행 4열의 경우 스 펠러의 동작을 7번 기다려야하기 때문에, 이를 고려하여 자음 및 모음이 도면부호 302와 같이 최적화 배치될 수 있다. 도면부호 302에 따르면, 일실시예에 따른 자음 및 모음 입력판은 5행 6열로 구성되며, 1행 1열 내지 1행 6열 각 각에는 'v ', 'ㅇ', 'ㄴ', 'ㄹ', 'ㅓ', 'ㅂ'가 배치되고, 2행 1열 내지 2행 6열 각각에는 'ㅏ', 'ㅣ', 'ㅅ', 'ㅈ', 'ㅎ', 'ㅕ'가 배치되며, 3행 1열 내지 3행 6열 각각에는 'ㄱ', 'ㅗ', 'ㄷ', '<', 'ㅌ', 'ㅊ'이 배치되 고, 4행 1열 내지 4행 6열 각각에는 'ㅡ', 'ㅁ', 'ㅔ', 'ㅛ', 'ㅍ', 'ㅠ'가 배치되고, 5행 1열 내지 5행 4열 각각에는 'ㅜ', 'ㅐ', 'ㅋ', 'ㅑ'가 배치될 수 있다. 도 4a 내지 도 4q는 일실시예에 따른 범주 기반의 단어 입력판의 예시를 설명하는 도면이다. 도 4a 내지 도 4q를 참조하면, 일실시예에 따른 범주 기반의 단어 입력판은 도면부호 401의 고정 범주판과 도면 부호 402의 선택 범주판을 포함할 수 있으며, 일실시예에 따른 문자 입력장치는 도면부호 401의 고정 범주판과 도면부호 402의 선택 범주판 중 어느 하나의 범주판을 시각화할 수 있다. 예를 들면, 문자 입력장치는 도면부호 401의 고정 범주판을 시각화한 후 기설정된 선택 시간동안 사용자 고정 범주판을 주시하고 있지 않으면 도면부호 402의 선택 범주판을 시각화할 수 있으며, 마찬가지로 기설정된 선택 시간동안 사용자가 402의 선택 범주판을 주시하고 있지 않으면 도면부호 401의 고정 범주판을 다시 시각화할 수 있다. 도면부호 402의 선택 범주판은 3행 5열로 구성되며, 1행 1열 내지 1행 5열 각각에는 '인사', '가족', '감정/기 분', '일상 대화', '신체'라는 문자가 배치되고, 2행 1열 내지 2행 5열 각각에는 '병원/증상', '옷/청결/정리', '휴식/TV', '움직임/위치', '시간/날씨'라는 문자가 배치되며, 3행 1열 내지 3행 5열 각각에는 '음식', '사물', '장소', '긴급상황', '사람'라는 문자가 배치될 수 있다. 구체적으로, 문자 입력장치는 기설정된 주시 시간동안 사용자가 1행 1열의 영역을 주시하고 있는 것으로 판단되 면 도면부호 403의 '인사 범주판'을 시각화하고, 사용자가 1행 2열의 영역을 주시하고 있는 것으로 판단되면 도면부호 404의 '가족 범주판'을 시각화하며, 사용자가 1행 3열의 영역을 주시하고 있는 것으로 판단되면 도면부 호 405의 '감정 및 기분 범주판'을 시각화하고, 사용자가 1행 4열의 영역을 주시하고 있는 것으로 판단되면 도 면부호 406의 '일상 대화 범주판'을 시각화하며, 사용자가 1행 5열의 영역을 주시하고 있는 것으로 판단되면 도 면부호 407의 '신체 범주판'을 시각화할 수 있다. 또한, 문자 입력장치는 기설정된 주시 시간동안 사용자가 2행 1열의 영역을 주시하고 있는 것으로 판단되면 도 면부호 408의 '병원 및 증상 범주판'을 시각화하고, 사용자가 2행 2열의 영역을 주시하고 있는 것으로 판단되면 도면부호 409의 '옷, 청결 및 정리 범주판'을 시각화하며, 사용자가 2행 3열의 영역을 주시하고 있는 것으로 판 단되면 도면부호 410의 '휴식 및 TV 범주판'을 시각화하고, 사용자가 2행 4열의 영역을 주시하고 있는 것으로 판단되면 도면부호 411의 '움직임 및 위치 범주판'을 시각화하며, 사용자가 2행 5열의 영역을 주시하고 있는 것으로 판단되면 도면부호 412의 '시간 및 날씨 범주판'을 시각화할 수 있다. 또한, 문자 입력장치는 기설정된 주시 시간동안 사용자가 3행 1열의 영역을 주시하고 있는 것으로 판단되면 도 면부호 413의 '음식 범주판'을 시각화하고, 사용자가 3행 2열의 영역을 주시하고 있는 것으로 판단되면 도면부 호 414의 '사물 범주판'을 시각화하며, 사용자가 3행 3열의 영역을 주시하고 있는 것으로 판단되면 도면부호 415의 '장소 범주판'을 시각화하고, 사용자가 3행 4열의 영역을 주시하고 있는 것으로 판단되면 도면부호 416의 '긴급 상황 범주판'을 시각화하며, 사용자가 3행 5열의 영역을 주시하고 있는 것으로 판단되면 도면부호 417의 '사람 범주판'을 시각화할 수 있다. 한편, 문자 입력장치는 도면부호 403 내지 417의 범주판 중 어느 하나의 범주판에서 사용자가 주시하는 어느 하 나의 문자를 출력할 수 있으며, 이후 다시 도면부호 402의 선택 범주판을 시각화할 수 있다. 도 5는 일실시예에 따른 문자 입력방법을 설명하는 도면이다. 도 5를 참조하면, 510 단계에서 일실시예에 따른 문자 입력방법은 이미지 획득부에서, 기설정된 입력 시간 동안 카메라를 이용하여 사용자의 얼굴 이미지를 획득할 수 있다. 바람직하게는, 510 단계에서 일실시예에 따른 문자 입력방법은 이미지 획득부에서, 실시간으로 사용자의 얼굴 이미지를 획득할 수 있다. 다음으로, 520 단계에서 일실시예에 따른 문자 입력방법은 의도 판단부에서, 입력 시간 동안 획득된 얼굴 이미 지를 입력으로 하는 인공지능 기반의 의도 인식 알고리즘을 이용하여 사용자의 의도를 판단할 수 있다. 일측에 따르면, 520 단계에서 일실시예에 따른 문자 입력방법은 의도 판단부에서, 입력 시간 동안 획득된 얼굴 이미지에 기초하여 사용자가 눈을 위로 뜬 것으로 판단되면 사용자의 의도 판단의 결과로 '1' 값을 출력하고, 사용자가 눈을 위로 뜬 것이 아닌 것으로 판단되면 사용자의 의도 판단의 결과로 '0' 값을 출력할 수 있다. 일측에 따르면, 520 단계에서 일실시예에 따른 문자 입력방법은 사전에 학습된 의도 인식 알고리즘에 기초하여 사용자의 의도를 판단할 수 있다. 일측에 따르면, 일실시예에 따른 문자 입력방법은 510 단계 및 520 단계는 기설정된 입력 시간 동안 기설정된 횟수만큼 반복 수행될 수 있다. 구체적으로, 이미지 획득부는 입력 시간 동안 복수의 얼굴 이미지를 획득하고, 의도 인식부는 복수의 얼굴 이미 지 각각을 의도 인식 알고리즘에 입력하여 복수의 의도 인식 결과를 획득하며, 획득된 복수의 의도 인식 결과의 평균 값이 기 설정된 의도 인식 임계값 이상인 경우 사용자가 의사소통에 대한 의도가 있는 것으로 판단할 수 있다. 보다 구체적으로, 510 단계에서 일실시예에 따른 문자 입력방법은 이미지 획득부에서, 1초 동안 약 15회 반복하 여 사용자의 복수의 얼굴 이미지(즉, 15장의 얼굴 이미지)를 획득할 수 있다. 또한, 520 단계에서 일실시예에 따른 문자 입력방법은 의도 인식부에서, 복수의 얼굴 이미지 각각을 입력으로 하는 YOLO-v3 기반의 얼굴 인식 알고리즘을 통해 얼굴 영역을 정사각형 형태로 취득하고, 취득된 복수의 얼굴 영역 각각에 대한 전처리를 통해 기설정된 크기로 이미지를 조정하고 정규화할 수 있으며, 전처리된 복수의 이 미지(즉, 15장의 얼굴 이미지) 각각을 의도 인식 알고리즘에 입력하여 복수의 의도 인식 결과(즉, 15장의 '0' 또는 '1'로 판별된 결과값)을 획득할 수 있으며, 획득된 복수의 의도 인식 결과의 평균 값이 기 설정된 의도 인 식 임계값 이상인 경우 사용자가 의사소통에 대한 의도가 있는 것으로 판단할 수 있다.다음으로, 530 단계에서 일실시예에 따른 문자 입력방법은 입력판 시각화부에서, 사용자의 의도 판단의 결과에 기초하여 기 설정된 문자 입력판을 시각화할 수 있다. 일측에 따르면, 530 단계에서 일실시예에 따른 문자 입력방법은 입력판 시각화부에서, 사용자의 의도 판단의 결 과로 '1' 값이 출력되거나, 복수의 의도 인식 결과의 평균 값이 기 설정된 의도 인식 임계값 이상인 경우에 문 자 입력판을 시각화할 수 있다. 일측에 따르면, 530 단계에서 일실시예에 따른 문자 입력방법은 입력판 시각화부에서, 복수의 행과 복수의 열에 대응되는 위치에 복수의 문자가 각각 배치되며 범주 기반의 단어 입력판과 자음 및 모음 입력판을 포함하는 문 자 입력판을 시각화할 수 있다. 구체적으로, 530 단계에서 일실시예에 따른 문자 입력방법은 입력판 시각화부에서, 범주 기반의 단어 입력판과 자음 및 모음 입력판 중 어느 하나의 입력판을 시각화하고, 어느 하나의 입력판에 대한 사용자의 얼굴 이미지에 기초하여 다른 하나의 입력판의 시각화 여부를 판단할 수 있다. 예를 들면, 530 단계에서 일실시예에 따른 문자 입력방법은 입력판 시각화부에서, 어느 하나의 입력판에 대한 사용자의 얼굴 이미지에 기초하여 사용자가 기 설정된 임계 시간동안 눈을 감고 있는 것으로 판단되면, 다른 하 나의 입력판을 시각화할 수 있다. 여기서, 범주 기반의 단어 입력판은 언어 치료사의 자문을 기반으로 의사, 간병인, 가족들과의 긴밀한 논의를 통해 실사용성을 높인 형태로 구성될 수 있으며, 상위 범주에서 하위 단어로 파생되어 입력이 수행될 수 있다. 한편, 540 단계에서 일실시예에 따른 문자 입력방법은 입력판 시각화부에서, 범주 기반의 단어 입력판 중 범주 선택판을 시각화한 이후, 범주 선택판을 주시하는 사용자의 얼굴 이미지에 기초하여 '인사 범주판', '가족 범주 판', '감정 및 기분 범주판', '일상 대화 범주판', '신체 범주판', '병원 및 증상 범주판', '옷, 청결 및 정리 범주판', '휴식 및 TV 범주판', '움직임 및 위치 범주판', '시간 및 날씨 범주판', '음식 범주판', '사물 범주 판', '장소 범주판', '긴급 상황 범주판', '사람 범주판' 중 어느 하나의 범주판을 시각화할 수 있다. 다음으로, 540 단계에서 일실시예에 따른 문자 입력방법은 문자 출력부에서, 문자 입력판을 주시하는 사용자의 얼굴 이미지에 기초하여 문자 입력판에 구비된 복수의 문자 중 어느 하나의 문자를 출력할 수 있다. 일측에 따르면, 540 단계에서 일실시예에 따른 문자 입력방법은 문자 출력부에서, 문자 입력판을 주시하는 사용 자의 얼굴 이미지로부터 복수의 행과 복수의 열이 교차하는 복수의 교차 영역 중 사용자가 주시하는 영역에 위 치하는 어느 하나의 문자를 출력할 수 있다. 또한, 540 단계에서 일실시예에 따른 문자 입력방법은 어느 하나의 범주판을 시각화된 경우에 문자 출력부에서, 어느 하나의 범주판을 주시하는 사용자의 얼굴 이미지에 기초하여 어느 하나의 문자를 출력할 수 있다. 결국, 본 발명을 이용하면, 사용자의 얼굴 인식 및 눈동자 상태에 기반하는 인공지능 알고리즘을 이용하여 실시 간으로 사용자의 의도 분석을 수행함으로써, 눈동자의 움직임이 불안정한 사용자의 의사소통을 지원할 수 있다. 또한, 본 발명을 이용하면, 눈동자의 움직임이 불안정한 사용자에게 최적화되어 보다 정교하게 사용자의 의도를 인식할 수 있다. 또한, 본 발명을 이용하면, 사용자의 신체에 생체신호 모니터링 수단을 부착하지 않고 카메라만을 활용하여 사 용자의 의도 인식 및 문자 입력을 수행함으로써, 사용자의 신체의 자유도 및 시스템의 이동성을 극대화할 수 있 다."}
{"patent_id": "10-2022-0153084", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들면, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 장치, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.부호의 설명 200: 문자 입력장치 210: 이미지 획득부 220: 의도 판단부 230: 입력판 시각화부 240: 문자 출력부"}
{"patent_id": "10-2022-0153084", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일실시예에 따른 문자 입력장치를 설명하는 도면이다. 도 2는 일실시예에 따른 문자 입력장치를 보다 구체적으로 설명하는 도면이다. 도 3a 내지 도 3b는 일실시예에 따른 자음 및 모음 입력판의 예시를 설명하는 도면이다. 도 4a 내지 도 4q는 일실시예에 따른 범주 기반의 단어 입력판의 예시를 설명하는 도면이다. 도 5는 일실시예에 따른 문자 입력방법을 설명하는 도면이다."}
