{"patent_id": "10-2022-0134128", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0055987", "출원번호": "10-2022-0134128", "발명의 명칭": "통신 시스템의 물리 계층에 대한 인공 지능 및 기계 학습을 위한 시스템, 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "사브르 하미드"}}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장치로서,채널을 이용하여 신호를 수신하는 수신기;상기 채널에 관한 채널 정보의 표현(representation)을 전송하도록 구성된 전송기; 및적어도 하나의 프로세서를 포함하되,상기 적어도 하나의 프로세서는,상기 신호에 기초하여 상기 채널의 상태를 결정하고,기계 학습 모델을 사용하여 상기 채널의 상태를 기반으로 상기 채널 정보의 표현을 생성하도록 구성된, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 기계 학습 모델의 선택을 수행하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 적어도 하나의 프로세서는 상기 채널의 상태에 기초하여 상기 기계 학습 모델의 선택을 수행하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 수신기를 사용하여 수신된 모델 식별 정보에 기초하여 상기 기계 학습 모델을 활성화하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 기계 학습 모델을 수신하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 적어도 하나의 프로세서는 상기 기계 학습 모델에 대응하는 양자화 함수를 수신하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 기계 학습 모델을 훈련하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 적어도 하나의 프로세서는 양자화 함수를 사용하여 상기 기계 학습 모델을 훈련하도록 구성되는, 장치.공개특허 10-2023-0055987-3-청구항 9 제7항에 있어서, 상기 기계 학습 모델은 생성 모델이고, 상기 적어도 하나의 프로세서는 상기 표현에 기초하여 상기 채널 정보를 복원하도록 구성된 복원 모델을 사용하여 상기 생성 모델을 훈련하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 생성 모델은 인코더를 포함하고; 상기 복원 모델은 디코더를 포함하는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서는,상기 복원 모델에 대한 구성 정보를 수신하고, 상기 구성 정보를 기반으로 상기 생성 모델을 훈련하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서는 상기 생성 모델 및 상기 복원 모델의 공동 훈련을 수행하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 적어도 하나의 프로세서는 상기 공동 훈련에 기초하여 상기 복원 모델을 전송하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 상기 채널에 기초하여 상기 기계 학습 모델에 대한 훈련 데이터를 수집하도록구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 적어도 하나의 프로세서는 시간 차원 및 주파수 차원을 갖는 자원 윈도우에 기초하여 상기 훈련 데이터를수집하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는,변환된 채널 정보를 생성하기 위해 상기 채널 정보를 사전 처리하고, 상기 변환된 채널 정보에 기초하여 상기 채널 정보의 상기 표현을 생성하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항에 있어서, 공개특허 10-2023-0055987-4-상기 적어도 하나의 프로세서는 처리 시간을 사용하여 상기 기계 학습 모델을 훈련하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항에 있어서, 상기 적어도 하나의 프로세서는 링크 제어 정보로서 상기 채널 정보의 상기 표현을 전송하도록 구성되는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "장치로서,채널을 사용하여 신호를 전송하도록 구성된 전송기;상기 채널에 관한 채널 정보의 표현을 수신하도록 구성된 수신기; 및기계 학습 모델을 사용하여 상기 표현에 기초하여 상기 채널 정보를 구성하도록 구성된 적어도 하나의 프로세서를 포함하는, 장치."}
{"patent_id": "10-2022-0134128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "통신 시스템의 물리 계층에 대한 인공 지능 및 기계 학습을 위한 방법으로서,무선 장치에서, 상기 무선 장치에 대한 물리 계층 정보를 결정하는 단계;기계 학습 모델을 사용하여 상기 물리 계층 정보의 표현을 생성하는 단계; 및상기 무선 장치로부터, 상기 물리 계층 정보의 상기 표현을 전송하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "장치는 채널을 이용하여 신호를 수신하는 수신기, 상기 채널에 관한 채널 정보의 표현을 전송하도록 구성된 전송 기, 및 상기 신호에 기초하여 상기 채널의 상태를 결정하고, 기계 학습 모델을 사용하여 상기 채널의 상기 상태 를 기반으로 상기 채널 정보의 상기 표현을 생성하도록 구성된 하나 이상의 프로세서를 포함한다. 방법은 무선 장치에서, 상기 무선 장치에 대한 물리 계층 정보를 결정하는 단계, 기계 학습 모델을 사용하여 상기 물리 계층 정보의 표현을 생성하는 단계, 및 상기 무선 장치로부터, 상기 물리 계층 정보의 상기 표현을 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 통신 시스템에 관한 것으로, 특히 통신 시스템의 물리 계층에 대한 인공 지능 및 기계 학 습을 위한 시스템, 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무선 통신 시스템에서, 수신기는 전송기와 수신기 사이의 채널 조건에 기초하여 채널 상태 정보 또는 프리코딩 정보를 전송기에 제공할 수 있다. 전송기는 수신기로의 전송을 수행하기 위해 채널 상태 정보 또는 프리코딩 정 보를 사용할 수 있다."}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "이 배경기술 단락에 개시된 상기 정보는 본 발명의 배경에 대한 이해의 향상을 위한 것일 뿐이므로 선행 기술을 구성하지 않는 정보를 포함할 수 있다."}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예들이 해결하고자 하는 과제는 성능이 향상된 채널 점유 시간 공유를 위한 방법 및 장치를 제공하는 것이다."}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "장치는 채널을 이용하여 신호를 수신하는 수신기, 상기 채널에 관한 채널 정보의 표현을 전송하도록 구성된 전 송기, 및 상기 신호에 기초하여 상기 채널의 상태를 결정하고, 기계 학습 모델을 사용하여 상기 채널의 상기 상 태를 기반으로 상기 채널 정보의 상기 표현을 생성하도록 구성된 하나 이상의 프로세서를 포함할 수 있다. 상기 채널 정보는 채널 추정을 포함할 수 있다. 채널 정보는 프리코딩 정보를 포함할 수 있다. 상기 적어도 하나의 프로세서는 상기 기계 학습 모델의 선택을 수행하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 상기 채 널의 상기 조건에 기초하여 상기 기계 학습 모델의 상기 선택을 수행하도록 구성될 수 있다. 상기 적어도 하나 의 프로세서는 상기 수신기를 사용하여 수신된 모델 식별 정보에 기초하여 상기 기계 학습 모델을 활성화하도록구성될 수 있다. 장치는 매체 접속 제어(MAC) 신호 또는 무선 자원 제어(RRC) 신호 중 하나 이상을 사용하여 모 델 식별 정보를 수신하도록 구성될 수 있다. 적어도 하나의 프로세서는 전송기를 사용하여 기계 학습 모델의 선 택을 나타내도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 상기 기계 학습 모델을 수신하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 상기 기계 학습 모델에 대응하는 양자화 함수를 수신하도록 구성될 수 있 다. 상기 적어도 하나의 프로세서는 상기 기계 학습 모델을 훈련하도록 구성될 수 있다. 상기 적어도 하나의 프 로세서는 양자화 함수를 사용하여 상기 기계 학습 모델을 훈련하도록 구성될 수 있다. 양자화 함수는 미분 양자 화 함수를 포함할 수 있다. 양자화 함수는 근사 양자화 함수를 포함할 수 있다. 적어도 하나의 프로세서는 기계 학습 모델에 대한 구성 정보를 전송하도록 구성될 수 있다. 구성 정보는 하나 이상 또는 가중치 또는 하이퍼매 개변수를 포함할 수 있다. 상기 기계 학습 모델은 생성 모델이고, 상기 적어도 하나의 프로세서는 상기 표현에 기초하여 상기 채널 정보를 복원하도록 구성될 수 있는 복원 모델을 사용하여 상기 생성 모델을 훈련하도록 구 성될 수 있다. 상기 생성 모델은 인코더를 포함할 수 있고, 상기 복원 모델은 디코더를 포함할 수 있다. 상기 적어도 하나의 프로세서는 상기 복원 모델에 대한 구성 정보를 수신하고, 상기 구성 정보를 기반으로 상기 생성 모델을 훈련하도록 구성될 수 있다. 상기 구성 정보는 하나 이상의 가중치 또는 하이퍼매개변수를 포함할 수 있 다. 상기 적어도 하나의 프로세서는 상기 생성 모델 및 상기 복원 모델의 공동 훈련을 수행하도록 구성될 수 있 다. 상기 적어도 하나의 프로세서는 상기 공동 훈련에 기초하여 상기 복원 모델을 전송하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 상기 채널에 기초하여 상기 기계 학습 모델에 대한 훈련 데이터를 수집하도록 구성될 수 있다. 상기 적어도 하나의 프로세서는 시간 차원 및 주파수 차원을 갖는 자원 윈도우에 기초하여 상 기 훈련 데이터를 수집하도록 구성될 수 있다. 채널 정보는 채널 매트릭스를 포함할 수 있다. 채널 정보는 특이 값과 결합된 특이값 행렬을 포함할 수 있다. 채널 정보는 유니터리 매트릭스를 포함할 수 있다. 상기 적어도 하 나의 프로세서는 변환된 채널 정보를 생성하기 위해 상기 채널 정보를 사전 처리하고, 상기 변환된 채널 정보에 기초하여 상기 채널 정보의 상기 표현을 생성하도록 구성될 수 있다. 적어도 하나의 프로세서는 변환에 기초하 여 채널 정보를 사전 처리하고, 훈련 데이터에 기초하여 기계 학습 모델을 훈련하도록 구성될 수 있고, 여기서 훈련 데이터는 변환에 기초하여 처리될 수 있다. 적어도 하나의 프로세서는 변환에 기초하여 훈련 데이터를 처 리하도록 구성될 수 있다. 적어도 하나의 프로세서는 처리 허용을 사용하여 기계 학습 모델을 훈련하도록 구성 될 수 있다. 처리 허용은 처리 시간을 포함할 수 있다. 처리 허용은 신호를 기반으로 시작될 수 있다. 처리 허 용은 제어 신호를 기반으로 시작될 수 있다. 제어 신호는 매체 접속 제어(MAC) 신호 또는 무선 자원 제어(RRC) 신호 중 하나 이상을 포함할 수 있다. 적어도 하나의 프로세서는 링크 제어 정보로서 채널 정보의 표현을 전송 하도록 구성될 수 있다. 적어도 하나의 프로세서는 링크 제어 정보를 업링크 제어 정보(UCI)로서 전송하도록 구 성될 수 있다. 적어도 하나의 프로세서는 양자화된 표현을 생성하기 위해 채널 정보의 표현을 양자화하도록 구 성될 수 있다. 적어도 하나의 프로세서는 코딩된 표현을 생성하기 위해 양자화된 표현에 코딩 방식을 적용하고 적용하도록 구성될 수 있다. 코딩 방식은 극성 코딩 방식을 포함할 수 있고, 적어도 하나의 프로세서는 물리 제 어 채널을 사용하여 코딩된 표현을 전송하도록 구성될 수 있다. 코딩 방식은 저밀도 패리티 체크(LDPC) 코딩 방 식을 포함할 수 있고, 적어도 하나의 프로세서는 물리 공유 채널을 사용하여 코딩된 표현을 전송하도록 구성될 수 있다. 장치는 채널을 사용하여 신호를 전송하도록 구성된 전송기, 채널에 관한 채널 정보의 표현을 수신하도록 구성된 수신기, 및 기계 학습 모델을 사용하여 표현에 기초하여 채널 정보를 구성하도록 구성된 적어도 하나의 프로세 서를 포함할 수 있다. 기계 학습 모델은 복원 모델일 수 있고, 적어도 하나의 프로세서는 채널 정보의 표현을 생성하도록 구성될 수 있는 생성 모델을 사용하여 복원 모델을 훈련시키도록 구성될 수 있다. 적어도 하나의 프 로세서는 기계 학습 모델을 전송하도록 구성될 수 있다. 적어도 하나의 프로세서는 기계 학습 모델에 대응하는 역양자화 함수를 전송하도록 구성될 수 있다. 채널 정보의 표현은 변환된 채널 정보의 표현을 포함할 수 있고, 적어도 하나의 프로세서는 변환된 채널 정보에 기초하여 채널 정보를 구성하기 위해 기계 학습 모델의 출력을 사후 처리하도록 구성될 수 있다. 변환된 채널 정보의 표현은 변환에 기초할 수 있으며, 기계 학습 모델은 복원 모델일 수 있고, 적어도 하나의 프로세서는 변환된 채널 정보의 표현을 생성하도록 구성될 수 있는 생성 모델을 사용하여 복원 모델을 훈련하도록 구성될 수 있고, 적어도 하나의 프로세서는 변환에 기초하여 처리될 수 있는 훈련 데이터를 사용하여 복원 모델을 훈련하도록 구성될 수 있다. 적어도 하나의 프로세서는 기계 학습 모델의 선택을 수행하고, 전송기를 사용하여 기계 학습 모델의 선택을 지시하도록 구성될 수 있다. 방법은 무선 장치에서, 무선 장치에 대한 물리 계층 정보를 결정하는 단계, 기계 학습 모델을 사용하여 물리 계 층 정보의 표현을 생성하는 단계, 및 상기 무선 장치로부터 상기 물리 계층 정보의 표현을 전송하는 단계를 포 함한다. 기계 학습 모델은 생성 모델일 수 있고, 상기 방법은 표현에 기초하여 물리 계층 정보를 복원하도록 구 성될 수 있는 복원 모델을 사용하여 생성 모델을 훈련하는 단계를 더 포함한다. 방법은 무선 장치가 자원 윈도우에 기초하여 기계 학습 모델을 위한 훈련 데이터를 수집하는 단계를 더 포함할 수 있다. 물리 계층 정보는 채 널 행렬을 포함할 수 있다. 방법은 변환된 물리계층 정보를 생성하기 위해 물리계층 정보를 사전 처리하는 단계, 및 변환된 물리 계층 정보에 기초하여 물리 계층 정보의 표현을 생성하는 단계를 더 포함할 수 있다. 상 기 생성하는 단계는 처리 수당을 기준으로 수행될 수 있다. 방법은 무선 장치에서 수신된 모델 식별 정보에 기 초하여 기계 학습 모델을 활성화하는 단계를 더 포함할 수 있다. 물리 계층 정보의 표현은 업링크 제어 정보를 포함할 수 있다."}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "일부 무선 통신 시스템에서, 전송 디바이스는 전송 디바이스가 채널을 통해 수신 디바이스에 보다 효과적으로 전송할 수 있도록 하기 위해 채널 조건에 대한 피드백 정보를 제공하기 위해 수신 디바이스에 의존할 수 있다. 예를 들어, 5G 뉴라디오(NR) 시스템에서, 기지국(예를 들어, gNodeB 또는 gNB)은 다운링크(DL) 채널을 통해 참 조 신호를 사용자 장치(UE)로 전송할 수 있다. UE는 DL 채널에 대한 채널 상태를 결정하기 위해 참조 신호를 측 정할 수 있다. 그런 다음, UE는 업링크(UL) 채널을 통해 DL 채널 상의 채널 상태를 나타내는 피드백 정보(예를 들어, 채널 상태 정보(CSI))를 기지국으로 전송할 수 있다. 기지국은 피드백 정보를 사용하여 DL 채널을 통해, 예를 들어 빔포밍의 사용을 사용하여 UE에 전송하는 방식을 개선할 수 있다. 그러나, 채널 상태에 대한 피드백 정보를 전송하는 것은 오버헤드로서 비교적 많은 양의 자원을 소모할 수 있다. 피드백 정보를 전송하는 데 사용되는 데이터의 양을 줄이기 위해, 일부 무선 통신 시스템은 수신 디바이 스가 묵시적 및/또는 명시적 채널 조건 피드백을 전송 디바이스에 보낼 수 있도록 하기 위해 하나 이상의 유형의 코드북을 사용할 수 있다. 예를 들어 5G NR 시스템에서, 유형 I 코드북은 DL 채널 조건에 기초하여 UE에 의 해 선택된 미리 정의된 프리코딩 행렬 표시자(PMI)를 가리킬 수 있는 인덱스의 형태로 gNB에 암시적 CSI 피드백 을 제공하는 데 사용될 수 있다. 그러면 gNB는 DL 채널에서 빔포밍을 위해 PMI를 사용할 수 있다. 다른 예로, 유형 II 코드북은 UE가 DL 채널에서 빔포밍을 위해 PMI를 사용할 수 있는 gNB에 피드백될 수 있는 PMI를 유도할 수 있는 명시적 CSI 피드백을 제공하는 데 사용될 수 있다. 그러나 유형 I 코드북을 사용하게 되면 적절한 정확 도로 CSI 피드백을 제공하지 못할 수 있다. 또한, 유형 II 코드북을 사용하게 되면 UL 채널 상에서 상당한 양의 오버헤드 데이터의 전송을 여전히 수반할 수 있다. 본 개시에 따른 피드백 방식은 인공 지능(AI), 기계 학습(ML), 딥 러닝 등(이 중 일부 또는 전부는 개별적으로 및/또는 집합적으로 기계 학습 또는 ML로 지칭될 수 있음)을 사용하여 무선 통신 시스템에 대한 물리 계층 정보 의 표현을 생성할 수 있다. 예를 들어, 일부 실시 예에서, 피드백 방식은 채널 조건에 대한 피드백 정보의 표현 (예를 들어, 채널 행렬, 프리코딩 행렬 등의 표현)을 생성하기 위해 ML 모델을 사용할 수 있다. 표현은 피드백 정보의 압축, 인코딩 또는 그렇지 않으면 수정된 형태일 수 있으며, 이는 구현 세부 사항에 따라 장치 사이에서 피드백 정보를 전송하는 데 관련된 자원을 줄일 수 있다. 본 개시에 따른 피드백 방식은 또한 기계 학습을 사용하여 표현으로부터 물리 계층 정보를 복원할 수 있다. 예 를 들어, 일부 실시 예에서, 피드백 방식은 ML 모델을 사용하여 채널 조건에 대한 피드백 정보의 표현으로부터 피드백 정보, 또는 피드백 정보의 근사치를 복원할 수 있다. 편의상, ML 모델을 간단히 모델이라고 칭할 수 있 다. 입력의 표현(예를 들어, 채널 조건에 대한 피드백 정보와 같은 물리 계층 정보)을 생성하는 모델은 생성 모델로 지칭될 수 있다. 입력의 표현으로부터 입력 또는 입력의 근사를 복원하는 모델은 복원 모델로 지칭될 수 있다. 복원 모델의 출력은 복원된 입력으로 지칭될 수 있다. 따라서 복원된 입력은 생성 모델에 적용된 입력이거나 생 성 모델에 적용된 입력의 근사, 추정, 예측 등이 될 수 있다. 생성 모델과 해당 복원 모델은 한 쌍의 ML 모델 또는 한 쌍의 모델로 통칭될 수 있다. 일부 실시 예에서, 생성 모델은 인코더 모델로 구현될 수 있고/있거나 복 원 모델은 디코더 모델로 구현될 수 있다. 따라서 인코더 모델 및 디코더 모델은 한 쌍의 ML 모델 또는 한 쌍의 모델이라고도 할 수 있다. 임의의 모델은 하나 이상의 다른 모델과 모델을 구별하기 위해 제1 모델, 제2 모델, 모델 A, 모델 B 등으로 지 칭될 수 있으며, 모델에 사용된 레이블은 문맥에서 달리 명백하지 않는 한 모델의 유형을 암시하는 것은 아니다. 예를 들어, 한 쌍의 모델과 관련하여, 모델 A가 생성 모델을 참조한다면, 모델 B는 복원 모델을 참조할 수 있다. 노드는 기지국, UE, 또는 본 명세서에 개시된 바와 같은 하나 이상의 ML 모델을 사용할 수 있는 임의의 다른 장 치를 지칭할 수 있다. 노드의 추가 예는 논리적 노드, 물리 노드, 또는 이들의 조합이든지. UE 측 서버, 기지국 측 서버(예를 들어, gNB 측 서버), eNodeB, 마스터 노드, 보조 노드 등을 포함할 수 있다. 임의의 노드는 노드 를 하나 이상의 다른 노드와 구별하기 위해 제1 노드, 제2 노드, 노드 A, 노드 B 등으로 지칭될 수 있으며, 문 맥상 다르게 명백하지 않는 한 노드에 사용된 레이블은 노드 유형을 의미하지 않는다. 예를 들어, 일부 실시 예 에서, 제1 노드는 UE를 지칭할 수 있고 제2 노드는 기지국을 지칭할 수 있다. 그러나 일부 다른 실시 예에서, 제1 노드는 제1 UE를 지칭할 수 있고, 제2 노드는 제1 UE와의 사이드링크 통신을 위해 구성된 제2 UE를 지칭할 수 있다. 일부 예시적인 실시 예에서, 제1 노드는 제2 노드에 전송될 수 있는 특징 벡터를 생성하기 위해서, 채널 행렬, 프리코딩 행렬 등을 인코딩하는 제1 모델(예를 들어, 생성 모델)을 사용할 수 있다. 제2 노드는 원본 정보(예를 들어, 채널 행렬, 프리코딩 행렬 등) 또는 원본 정보의 근사를 복원하기 위해 특징 벡터를 디코딩하는 제2 모델 (예를 들어, 복원 모델)을 사용할 수 있다. 본 개시에 따른 일부 실시 예는 모델이 쌍으로 훈련될 수 있는 2-모델 훈련 방식을 구현할 수 있다. 예를 들어, 복원 모델은 생성 모델을 훈련하는 데 사용될 수 있고/있거나 생성 모델은 복원 모델을 훈련하는 데 사용될 수 있다. 일부 예시적인 구현에서, 한 쌍의 모델은 (예를 들어, 제1 노드에 대한) 인코더 모델이 (예를 들어, 제2 노드에 대한) 디코더 모델로 훈련될 수 있는 자동 인코더를 구현하도록 구성될 수 있다. 일부 실시 예에서, 제1 노드에 의한 추론에 사용될 수 있는 제1 모델(예를 들어, 생성 모델)은 제2 노드에 의한 추론을 위해 실제로 사용될 수 있는 제2 모델(예를 들어, 복원 모델)을 사용하여 훈련될 수 있다. 훈련은 예를 들어, 모델을 훈련(예를 들어, 오프라인)하고 추론에 사용하도록 훈련된 모델 중 하나 이상을 노드 중 하나 이상으로 전송할 수 있는 서버에 의해, 제1 노드, 제2 노드 및/또는 임의의 다른 장치에 의해 수행될 수 있다. 대안적으로, 또는 추가적으로, 제2 모델이 제2 노드에 의해 추론에 사용될 수 있는 실제 모델이 아니더라도, 제 1 모델은 제1 모델과 제2 모델 사이에 어느 정도의 매칭을 제공할 수 있는 제2 모델을 사용하여 훈련될 수 있다. 대안적으로, 또는 추가적으로, 제1 모델은 제2 모델에 대한 참조 모델을 사용하여 훈련될 수 있다. 대안 적으로, 또는 추가적으로, 제1 모델은 미리 결정된 값, 무작위 값 등으로 초기화될 수 있는 가중치, 하이퍼매개 변수 등의 값으로 구성될 수 있는 제2 모델을 사용하여 훈련될 수 있다. 일부 실시 예에서, 한 쌍의 모델은 동일하거나 상이한 훈련 데이터 세트를 사용하여, 동시에, 순차적(예를 들어, 제2 모델을 고정하는 동안 제1 모델을 훈련하고, 다음에 제1 모델을 고정하는 동안 제2 모델을 훈련하는 것을 번갈아 가며) 등으로 훈련될 수 있다. 일부 실시 예에서, 노드는 양자화기를 사용하여 물리 계층 정보의 표현을 통신 채널을 통해 더 쉽게 전송될 수 있는 형태로 변환할 수 있다. 예를 들어, 양자화기는 물리 계층 정보의 실수(예를 들어, 정수) 표현을 물리 업 링크 또는 다운링크 채널을 통한 전송을 위해 극성 인코더 또는 그 외 장치에 적용될 수 있는 이진 비트 스트림 으로 변환할 수 있다. 비슷하게, 노드는 비트스트림을 물리 계층 정보를 복원하는데 사용될 수 있는 물리 계층 정보의 표현으로 변환하기 위해 역양자화기를 사용할 수 있다. 일부 실시 예에서, 양자화기 또는 역양자화기는 ML 모델의 일부로 간주될 수 있다. 예를 들어, 생성 모델은 인코더 및 해당 양자화기를 포함할 수 있고/있거나, 복원 모델은 대응하는 역양자화기를 포함할 수 있다. 본 개시에 따른 일부 실시 예는 모델을 훈련 및/또는 노드 간에 모델을 전송하기 위한 하나 이상의 프레임워크 를 구현할 수 있다. 예를 들어, 제1 유형의 프레임워크에서, 제1 노드(노드 A)는 한 쌍의 모델(모델 A 및 모델 B)을 공동으로 훈련할 수 있다. 노드 A는 훈련된 모델 A를 추론에 사용할 수 있고 훈련된 모델 B를 추론에 훈련 된 모델 B를 사용할 수 있는 제2 노드(노드 B)로 전달할 수 있다. 제1 유형의 프레임워크의 변형에서, 노드 A는 훈련된 모델 A를 노드 B로 전달할 수 있으며, 노드 B는 훈련된 모델 A를 사용하여 추론에 사용하도록 자체 모델 B를 훈련할 수 있다. 제2 유형의 프레임워크에서, 참조 모델은 노드 A에 대한 모델 A로 설정되고 노드 B는 모델 A로 참조 모델을 사 용하여 모델 B를 훈련할 수 있다(예를 들어, 노드 A가 참조 모델을 추론을 위해 모델 A로 사용한다고 가정). 그 런 다음 노드 A는 추가 훈련 없이 참조 모델을 모델 A로 사용하거나, 노드 A는 모델 A로 사용하도록 참조 모델 을 훈련할 수 있다. 일부 실시 예에서, 다수의 참조 모델이 모델 A에 대해 설정될 수 있고, 노드 B는 모델 A에 대한 참조 모델 중 하나 이상에 해당하는 모델 B의 하나 이상의 버전을 훈련할 수 있다. 모델 A에 대한 다수의 참조 모델이 있는 실시 예에서, 노드 B는 모델 A에 대한 다수의 참조 모델을 기반으로 하나 이상의 모델 B 버전 을 훈련할 수 있고, 노드 B는 사용을 위해 모델 B의 어느 버전을 선택하여 사용할지 모델 B의 어떤 버전이 최고 의 성능을 제공하는지 등을 노드 A에 표시한다. 노드 B의 표시에 따라, 노드 A는 노드 B가 지시하는 모델 B에 해당하는 참조 모델을 진행할 수 있거나, 노드 A는 모델 A로 사용할 다른 모델을 선택할 수 있다. 제3 유형의 프레임워크에서, 노드 A는 예를 들어 사전 훈련된(예를 들어, 오프라인으로 훈련된), 훈련되지 않았 지만 초기 값으로 구성된 등의 임의의 초기 상태에 있을 수 있는 모델 A로 시작할 수 있다. 노드 B는 초기 상태 에 있을 수도 있는 모델 B로 시작할 수 있다. 일부 실시 예에서, 그들 자신의 모델을 훈련시키기 전에, 노드 A 및/또는 노드 B는 서로 매칭되는 (예를 들어, 함께 훈련되는) 모델을 가질 수 있다. 하나 또는 두 개의 노드는 일정 기간 동안 각자의 모델을 훈련할 수 있으며, 다음에 하나 또는 두 개의 노드는 훈련된 모델 값 및/또는 훈 련된 모델을 다른 노드와 공유할 수 있다. 예시적인 실시 예는 제1 노드(예를 들어, UE) 및 제2 노드(예를 들어, 기지국)가 한 쌍의 모델(e0,d0)을 가지고 있는 도 10과 관련하여 아래에 더 상세히 설명되며, 여기서 e0은 UE에서 초기 상태의 인코더 모델일 수 있고 d0은 기지국에서 초기 상태의 디코더 모델일 수 있다. 제3 유형의 프레임워크의 변형에서, 하나 또는 두 노드는 하나 이상의 추가 기간 동안 각각의 모델을 훈련할 수 있으며, 하 나 또는 두 노드는 예를 들어, 각 기간의 종료시, 교대하는 기간의 종료시, 및/또는 이와 유사한 때에, 훈련된 모델 값 및/또는 훈련된 모델을 다른 노드와 공유할 수 있다. 본 명세서에 개시된 임의의 프레임워크에서, 모델이 노드로 또는 노드로부터 전송될 때, 대응하는 양자화기 또 는 역양자화기가 이 모드와 함께 전송될 수 있다. 일부 실시 예에서, 훈련 데이터는 자원 윈도우(예를 들어, 시간 및/또는 주파수 자원의 윈도우)에 기초하여 수 집될 수 있다. 예를 들어, 노드는 특정 범위의 주파수(예를 들어, 부반송파, 부대역 등) 및 특정 시간 범위(예 를 들어, 심볼, 슬롯 등)에 대한 훈련 데이터(예를 들어, 채널 추정치)를 수집하도록 구성될 수 있다. 윈도우의크기는, 예를 들어, 노드가 메모리에 저장할 수 있는 훈련 데이터의 양에 기초하여 결정될 수 있다. 수집된 훈 련 데이터는 하나 이상의 노드에서 온라인 훈련에 사용하거나 오프라인 훈련을 위해 저장할 수 있다. 일부 실시 예에서, 사전 처리 및/또는 사후 처리는 한 쌍의 모델이 보다 효과적으로 작동하는 것을 가능하게 할 수 있다. 예를 들어, 하나 이상의 입력의 도메인 지식(예를 들어, 주파수 도메인 지식)은 하나 이상의 변환된 입력을 생성하기 위해 하나 이상의 입력의 적어도 일부에 대한 사전 처리 연산을 수행하는 데 사용될 수 있다. 하나 이상의 변환된 입력은 하나 이상의 변환된 입력의 표현을 생성하기 위해 생성 모델에 적용될 수 있다. 하 나 이상의 변환된 입력의 표현은 복원된 변환된 입력(예를 들어, 하나 이상의 변환된 입력, 또는 그 근사)을 생 성할 수 있는 복원 모델에 적용될 수 있다. 도메인 지식은 또한 원래의 하나 이상의 입력 또는 그 근사를 복구 하기 위해 복원된 변환된 입력에 대한 사후 처리 동작(예를 들어, 사전 처리 동작의 역)을 수행하는 데 사용될 수 있다. 구현 세부 사항에 따라, 변환 입력 및/또는 출력(예를 들어, 도메인 지식 기반)은 하나 이상의 입력 요소 간의 하나 이상의 상관 관계를 활용할 수 있으며, 이에 의해 생성 모델 및/또는 복원 모델의 처리 부담, 메모리 사용, 전력 소비 등을 감소시킬 수 있다. 일부 실시 예에서, 노드에는 모델에 대한 처리 시간이 제공될 수 있다. 예를 들어, 노드가 (예를 들어, 노드에 제공되거나 노드에 의해 수집되는 훈련 데이터 세트를 사용하여) 모델의 온라인 훈련을 수행하도록 구성된 경우, 노드는 미리 결정된 심볼 수 또는 그 외 시간 측정 내에서 모델을 업데이트할 것으로 예상될 수 있다. 본 개시에 따른 일부 실시 예는 모델의 다수의 모델 쌍이 하나 이상의 노드(예를 들어, 한 쌍의 노드)에 의한 사용을 위해 훈련, 전개 및/또는 활성화될 수 있는 방식을 구현할 수 있다. 예를 들어, 상이한 훈련된 모델 쌍 은 (예를 들어, 채널 행렬, 프리코딩 행렬 등의 경우) 상이한 채널 환경, 상이한 행렬 차원 등을 처리하도록 활 성화될 수 있다. 일부 실시 예에서, 한 쌍의 모델은 시그널링(예를 들어, RRC 시그널링, MAC-CE 시그널링 등)에 의해 활성화될 수 있다. 일부 실시 예에서, 제1 노드(예를 들어, gNB)는 또한 예를 들어 RRC, MAC CE 또는 동적 시그널링을 통해 현재 활성 모델을 전환하거나 비활성화하도록 제2 노드(예를 들어, UE)에 지시할 수 있다. 한 쌍의 모델은 모델 중 하나 이상을 훈련하고, 추론에 모델 중 하나 이상을 사용하는 등을 위해 활성화될 수 있다. 본 개시에 따른 일부 실시 예는 제1 노드에서 생성 모델에 의해 생성될 수 있고 복원을 위해 제2 노드로 전송될 수 있는 피드백 정보의 표현을 위한 하나 이상의 포맷을 구현할 수 있다. 예를 들어, 피드백 정보의 표현을 위 한 포맷은 업링크 제어 정보(UCI)의 일종으로 설정될 수 있다. 포맷은 예를 들어 UCI를 전송하는 데 사용되는 물리 채널의 유형에 따라 달라질 수 있는 하나 이상의 유형의 코딩(예를 들어, 극성 코딩, 저밀도 패리티 체크 (LDPC) 코딩 등)을 포함할 수 있다. 일부 실시 예에서, CSI 압축 성능은 예를 들어, 시간, 주파수 및/또는 공간 도메인에서 하나 이상의 상관 관계 를 활용함으로써, 및/또는 시간, 빈도 및/또는 공간에 걸쳐 훈련 데이터 세트를 정의함으로써, AI 및/또는 ML을 사용하여 개선될 수 있다. 본 개시는 통신 시스템의 물리 계층에 대한 인공 지능 및 기계 학습에 관한 많은 발명 원리를 포함한다. 이러한 원리는 독립적인 유용성을 가지며 개별적으로 구현될 수 있으며, 모든 실시 예가 모든 원리를 활용할 수 있는 것은 아니다. 또한 원리는 다양한 조합으로 구현될 수 있으며, 그 중 일부는 시너지 방식으로 개별 원칙의 이점 을 증폭시킬 수 있다. 예시를 위해, 일부 실시 예는 5G NR 시스템에서, 하나 이상의 UE, 기지국(예를 들어, gNB), 등 사이에서 채널 피드백 정보를 압축, 압축해제 및/또는 전송하는 것과 같은, 일부 특정 구현 세부사항 및/또는 애플리케이션의 맥락에서 설명될 수 있다. 하지만, 본 발명의 원리는 이러한 세부 사항 및/또는 애플리케이션으로 제한되지 않 으며 물리 계층 정보가 장치 중 임의의 것이 기지국, UE, 피어 디바이스 등인지에 관계없이, 및 채널이 UL 채널, DL 채널, 피어 채널 등인지에 관계없이 처리 및/또는 무선 장치 간에 전송될 수 있는 임의의 다른 컨텍스 트에 적용될 수 있다. 더욱이, 본 발명의 원리는 다른 유형의 셀룰러 네트워크(예를 들어, 4G LTE, 6G 및/또는 미래 세대의 셀룰러 네트워크), 블루투스, Wi-Fi 등과 같은 물리 계층 정보를 처리 및/또는 교환할 수 있는 모 든 유형의 무선 통신 시스템에 적용될 수 있다. 물리 계층을 위한 기계 학습 모델 도 1은 본 개시에 따른 무선 통신 장치의 실시 예를 도시한다. 장치는 입력으로서 물리 계층 정보를 수신하고 출력으로서 물리 계층 정보의 표현을 생성할 수 있는 기계 학습 모델을 포함할 수 있다. 일 부 구현에서, 장치는 화살표에 의해 도시된 바와 같이 물리 계층 정보의 표현을 하나 이상의 다른 장치에 전송할 수 있다. 물리 계층 정보의 표현은 물리 계층 정보의 압축, 인코딩, 암호화, 매핑, 또는 다르게 수정된 형태일 수 있다. 구현 세부 사항에 따라, 물리 계층 정보의 표현을 생성하기 위해 기계 학습 모델에 의한 물 리 계층 정보의 수정은 장치 사이에서 물리 계층 정보를 전송하는데 수반되는 자원을 감소시킬 수 있 다. 기계 학습 모델은 신경망(예를 들어, 심층 신경망), 선형 회귀, 로지스틱 회귀, 결정 트리, 선형 판별 분 석, 나이브 베이즈(naive Bayes), 지원 벡터 기계, 학습 벡터 양자화 등을 포함하여, 임의의 유형의 AI 및/또는 ML 모델 중 하나 이상으로 구현될 수 있다. 기계 학습 모델은 예를 들어, 생성 모델로 구현될 수 있다. 물리 계층 정보는 무선 통신 장치의 물리 계층의 동작과 관련된 임의의 정보를 포함할 수 있다. 예를 들어, 물리 계층 정보는 하나 이상의 물리 계층 채널, 신호, 빔 등에 관한 정보(예를 들어, 상태 정보, 프 리코딩 정보 등)를 포함할 수 있다. 물리 계층 채널의 예는 물리 방송 채널(PBCH), 물리 랜덤 액세스 채널 (PRACH), 물리 다운링크 제어 채널(PDCCH), 물리 다운링크 공유 채널(PDSCH), 물리 업링크 공유 채널(PUSCH) 중 하나 이상을 포함할 수 있다. 물리 업링크 제어 채널(PUCCH), 물리 사이드링크 공유 채널(PSSCH), 물리 사이드 링크 제어 채널(PSCCH), 물리 사이드링크 피드백 채널(PSFCH) 등 중 하나 이상을 포함할 수 있다. 물리 계층 신 호의 예는 1차 동기화 신호(PSS), 2차 동기화 신호(SSS), 채널 상태 정보 참조 신호(CSI-RS), 추적 참조 신호 (TRS), 사운딩 참조 신호(SRS) 등 중 하나 이상을 포함할 수 있다. 도 2는 본 발명에 따른 무선 통신 장치의 다른 실시 예를 도시한다. 장치는 물리 계층 정보의 표현을 입력으로서 수신하고, 표현이 기반으로 할 수 있는 물리 계층 정보의 복원을 출력으로서 생성할 수 있는 기계 학습 모델을 포함할 수 있다. 일부 구현들에서, 장치는 화살표로 나타낸 바와 같이 하나 이상의 다른 장치로부터 물리 계층 정보의 표현을 수신할 수 있다. 복원(복원된 입력으로 지칭될 수 있음)은 표현이 기반으로 할 수 있는 물리 계층 정보일 수 있거나, 표현이 기반으로 할 수 있는 물리 계층 정보의 근사, 추정, 예측 등일 수 있다. 복원은 표현이 기반으로 할 수 있는 물리 계층 정보의 압축해제, 디코딩, 복호화, 역-매핑 또는 수정된 형태일 수 있다. 기계 학습 모델은 신경망(예를 들어, 심층 신경망), 선형 회귀, 로지스틱 회귀, 결정 트리, 선형 판별 분 석, 나이브 베이즈, 지원 벡터 머신, 학습 벡터 양자화 등을 포함하는 임의의 유형의 AI 및/또는 ML 모델 중 하 나 이상으로 구현될 수 있다. 기계 학습 모델은 예를 들어, 복원 모델로 구현될 수 있다. 복원된 물리 계층 정보는 무선 통신 장치의 물리 계층의 동작에 관한 임의의 정보, 예를 들어, 도 1에 도 시된 실시 예와 관련하여 위에서 설명된 바와 같은 하나 이상의 채널, 신호 등을 포함할 수 있다. 특정 용도로 제한되지는 않지만, 도 1 및 도 2에 각각 도시된 무선 통신 장치(101 및 202)는 장치 사이로부터 물리 계층 정보의 전송을 용이하게 하기 위해 함께 사용될 수 있다. 예를 들어, 일부 실시 예에서, 장치는 모델이 생성 모델로서 구현되는 UE로서 구현될 수 있고, 장치는 모델이 복원 모델로서 구현될 수 있는 기지국으로서 구현될 수 있다. 이러한 실시 예에서, 생성 모델은 (예를 들어, 기지국에서 UE로의 DL 채널에 관한) 물리 계층 정보를 압축함으로써 표현을 생성할 수 있다. UE는 표현을 (예를 들 어, UL 채널을 사용하여) 기지국에 전송할 수 있다. 기지국은 복원된 물리 계층 정보를 생성할 수 있는 복 원 모델에 표현(208으로 표시됨)을 입력할 수 있다. 기지국은, 예를 들어 기지국으로부터 UE로의 DL 전송 을 용이하게 하기 위해 복원된 물리 계층 정보를 사용할 수 있다. 구현 세부 사항에 따라, 압축된 표현 의 형태로 물리 계층 정보를 전송하는 것은 물리 계층 정보를 전송하는 것과 연관된 UL 자원의 양을 감소시킬 수 있다. 2-모델 훈련 도 3은 본 개시에 따른 2-모델 훈련 방식의 실시 예를 예시한다. 도 3에 예시된 실시 예는 예를 들어, 도 1 및 도 2에 도시된 모델 중 하나 이상, 또는 본 명세서에서 개시된 임의의 다른 실시 예와 함께 사용될 수 있 다. 도 3을 참조하면, 훈련 데이터는 훈련 데이터의 표현을 생성할 수 있는 생성 모델에 적용될 수 있다. 복원 모델은 훈련 데이터의 표현에 기초하여 훈련 데이터의 복원을 생성할 수 있다. 일부 실시 예에서, 생성 모델은 표현을 통신 채널을 통해 전송될 수 있는 양자화된 형태(예를 들어, 비트 스트림)로 변환하기 위한 양자화기를 포함할 수 있다. 유사하게, 일부 실시 예에서, 복원 모델은 양자화된표현(예를 들어, 비트 스트림)을 복원된 훈련 데이터를 생성하기 위해 사용될 수 있는 형태로 변환할 수 있는 역양자화기를 포함할 수 있다. 생성 모델 및 복원 모델은, 예를 들어 생성 모델 및/또는 복원 모델에 훈련 피드백을 제공하기 위해 손실 함수를 사용함으로써 쌍으로 훈련될 수 있다. 훈련 피드백은 예를 들어, 경사 하 강법, 역전파 등을 사용하여 구현될 수 있다. 생성 모델 및 복원 모델 중 하나 또는 둘 모두가 하나 이상의 신경망으로 구현될 수 있는 실시 예에서, 훈련 피드백은 생성 모델 및/또는 복원 모델에 서 가중치, 하이퍼매개변수 등의 하나 이상의 값을 업데이트할 수 있다. 일부 실시 예에서, 손실 함수(예를 들어, 복원 손실로 적어도 부분적으로 구현될 수 있음)는 생성 모델 및 복원 모델을 훈련하여 원래 훈련 데이터에 근접하도록 복원된 훈련 데이터를 생성하도 록 동작할 수 있다. 이것은 예를 들어 손실 함수의 손실 출력을 줄이거나 최소화함으로써 달성될 수 있다. 예를 들어, 훈련 데이터가 x로 표현되고, 복원된 훈련 데이터가 로 표현된다면, 생성 모델은 함수 f(x)로 표현될 수 있고, 복원 모델은 함수 g(f(x))로 표현될 수 있으므로, 이 된다. 손실 함수는 로 표현될 수 있다. 따라서, 일부 실시 예에서, 한 쌍의 모델(303, 304)을 훈련하는 것은 훈 련 피드백을 사용하여 L을 감소시키거나 최소화하는 것을 포함할 수 있다. 훈련 데이터의 임의의 특정 유형의 표현에 제한되지는 않지만, 일부 실시 예에서, 한 쌍의 모델(303, 30 4)은 원래 훈련 데이터에 대한 훈련 데이터의 표현의 차원을 감소시키려고 할 수 있다. 예를 들어, 생성 모델은 표현을 저장 및/또는 전송하는 것과 연관된 오버헤드를 감소시킬 수 있는 훈련 데이터의 하나 이상의 특징(예를 들어, 잠재 특징)을 식별하거나 분리할 수 있는 특징 벡터를 생성하도록 훈련될 수 있다. 복원 모델은 표현에 기초하여, 원본 훈련 데이터 또는 그 근사를 복원하도록 유사하게 훈 련될 수 있다. 일단 훈련되면, 생성 모델 및/또는 복원 모델은 예를 들어, 도 1 및 도 2에 각각 도시된 무선 통신 장치(101 및 202) 중 하나 또는 둘 다, 또는 본 명세서에 개시된 임의의 다른 실시 예에서 추론을 위해 사용될 수 있다. 더구나, 도 3과 관련하여 설명된 2-모델 훈련 방식은 본 명세서에 개시된 바와 같이 모델을 훈련 및/ 또는 무선 장치 사이에서 모델을 전달하기 위한 하나 이상의 프레임워크와 함께 사용될 수 있다. 도 3과 관련하 여 설명된 훈련은 예를 들어, 무선 장치에서, 무선 장치에서, 다른 위치에서 (예를 들어, 장치(101 및 202) 둘 다의 원격 서버에서), 또는 이러한 위치의 조합에서와 같이, 어디에서나 수행될 수 있다. 더욱이, 일단 훈련되면, 생성 모델 및/또는 복원 모델 중 하나 또는 둘 모두가 추론에 사용하기 위해 다른 위 치로 전송될 수 있다. 일부 실시 예에서, 일단 훈련되면, 모델 중 하나는 폐기될 수 있고 나머지 모델은 예를 들어 별도로 훈련된 모델과 쌍으로 사용될 수 있다. 채널 정보 피드백을 위한 기계 학습 모델 도 4는 본 개시에 따른 채널 정보 피드백을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 도시한다. 도 4에 예시된 시스템은 도 1, 도 2, 및 도 3에 예시된 것들을 포함하여, 본 명세서에서 개시된 임의의 장 치, 모델, 훈련 방식 등을 구현하도록 사용되거나, 이들에 의해 구현될 수 있다. 도 4를 참조하면, 시스템은 제1 무선 장치 및 제2 무선 장치를 포함할 수 있다. 제1 무선 장치 는 채널을 통해 제2 무선 장치로부터의 전송을 수신하도록 구성될 수 있다. 채널을 통한 전송의 효율성(예를 들어, 효율성, 신뢰성, 대역폭 등)을 개선하기 위해, 제1 무선 장치는 예를 들어, 채 널을 통해 제2 무선 장치에 의해 전송된 하나 이상의 신호(예를 들어, 참조 신호)를 측정함으로써 획 득될 수 있는 채널 정보의 형태로 제2 무선 장치에 피드백을 제공할 수 있다. 제1 무선 장치는 채널 정보의 표현을 생성하기 위해, 이 예에서 생성 모델로서 구현될 수 있는 제1 기계 학습 모델을 사용할 수 있다. 제1 무선 장치는 예를 들어, 다른 채널, 신호 등을 사용 하여 표현을 제2 무선 장치로 전송할 수 있다. 표현은 채널 정보의 압축, 인코딩, 암호화, 매핑 또는 수정된 형태일 수 있다. 구현 세부 사항에 따라,표현을 생성하기 위해 기계 학습 모델에 의한 채널 정보의 수정은 채널 정보를 제2 무선 장치로 전송하는데 수반되는 자원을 감소시킬 수 있다. 제2 무선 장치는 이 예에서 복원 모델로서 구현될 수 있는 제2 기계 학습 모델에 채널 정보의 표현 을 적용할 수 있다. 복원 모델은 채널 정보의 복원을 생성할 수 있다. (복원된 입력으로 지칭될 수 있는) 복원은 표현이 기초할 수 있는 채널 정보, 또는 채널 정보의 근사, 추정, 예측 등일 수 있다. 복원은 채널 정보의 압축해제, 디코딩, 복호화, 역-매핑, 또는 달리 수정된 형태 일 수 있다. 제2 무선 장치는 채널 정보를 이용하여 채널을 통해 제1 무선 장치로 전송하 는 방식을 개선할 수 있다. 도 4에 도시된 시스템은 임의의 특정 장치(예를 들어, UE, 기지국, 피어 장치 등), 애플리케이션(예를 들 어, 4G, 5G, 6G, Wi-Fi, 블루투스 등) 및/또는 구현 세부 사항에 제한되지 않는다. 그러나 본 발명의 원리 중 일부를 설명하기 위해, 일부 예시적인 실시 예는 UE가 gNB로부터 상이한 DL 신호를 수신할 수 있는 5G NR 시스 템의 맥락에서 설명될 수 있다. 업링크 및 다운링크 전송 NR 시스템에서, UE는 gNB로부터 다양한 정보를 포함하는 DL 전송을 수신할 수 있다. 예를 들어, UE는 물리 다운 링크 공유 채널(PDSCH)로 지칭되는 시간 및 주파수 자원의 특정 구성으로 gNB로부터 사용자 데이터를 수신할 수 있다. gNB의 다중 접속(MAC) 계층은 UE 측의 해당 MAC 계층에 전달되도록 의도된 사용자 데이터를 제공할 수 있 다. UE의 물리(PHY) 계층은 PDSCH를 통해 수신된 물리 신호를 수신하고 이를 PDSCH 처리 체인에 대한 입력으로 적용할 수 있고, 그 출력은 UE에서 MAC 계층에 대한 입력으로서 공급될 수 있다. 유사하게, UE는 물리 다운링크 제어 채널(PDCCH))를 사용하여 gNB로부터 제어 데이터를 수신할 수 있다. 제어 데이터는 다운링크 제어 정보 (DCI)로 지칭될 수 있으며, gNB 측의 PDCCH 처리 체인을 통해 PDCCH 신호로 변환될 수 있다. UE는 물리 업링크 공유 채널(PUSCH) 및 물리 업링크 제어 채널(PUCCH)를 각각 사용하여 사용자 데이터 및 제어 정보를 전달하기 위해 UL 신호를 gNB에 보낼 수 있다. PUSCH는 데이터를 gNB에 전달하기 위해 UE MAC 계층에 의 해 사용될 수 있다. PUCCH는 업링크 제어 정보(UCI)로 지칭될 수 있는 제어 정보를 전달하는 데 사용될 수 있으 며, 이는 UE 측에서 PUCCH 처리 체인을 통해 PUCCH 신호로 변환될 수 있다. 채널 상태 정보 NR 시스템에서, UE는 채널 품질 표시자(CQI), 프리코딩 행렬 표시자(PMI), CSI 참조 신호 자원 표시자(CRI) 및/ 또는 순위 표시(RI)를 계산할 수 있는 채널 상태 정보(CSI) 생성기를 포함할 수 있으며, 이들 중 일부 또는 전 부는 UE에 서비스를 제공하는 하나 이상의 gNB에 보고될 수 있다. CQI는 적응 변조 및 코딩 및/또는 주파수 선 택적 자원 할당을 위한 변조 및 코딩 방식(MCS)과 연관될 수 있으며, PMI는 채널 종속 폐쇄 루프 다중 입력 다 중 출력 시스템에 사용될 수 있으며, RI는 유용한 전송 계층의 수에 해당할 수 있다. NR 시스템에서, CSI 생성은 gNB가 전송하는 CSI 참조 신호(CSI RS)를 기반으로 수행될 수 있다. UE는 예를 들어, CSI-RS 신호의 측정에 기초하여 채널 추정 및/또는 잡음 분산 추정을 수행함으로써, 다운링크 채널 상태 를 측정하고 CSI를 생성하기 위해 CSI-RS를 사용할 수 있다. NR 시스템에서, CSI는 미리 정의된 PMI를 가리킬 수 있는 인덱스의 형태로 gNB에 암시적 CSI 피드백을 제공할 수 있는 유형 I 코드북을 사용하여 서빙 gNB에 보고될 수 있다. 대안적으로, 또는 추가적으로, CSI는 UE가 DL 채널 조건에 기초하여 하나 이상의 지배적 고유 벡터 또는 특이 벡터를 결정할 수 있는 명시적 CSI 피드백을 제 공할 수 있는 유형 II 코드북을 사용하여 서빙 gNB에 보고될 수 있다. 그 다음, UE는 DL 채널에서 빔포밍을 위 해 PMI를 사용할 수 있는 gNB에 피드백될 수 있는 PMI를 유도하기 위해 지배적 고유 벡터 또는 특이 벡터를 사 용할 수 있다. 코드북의 사용은 예를 들어 제한된 수의 안테나 포트 및/또는 사용자가 있는 실시 예에서, 적절한 성능을 제공 할 수 있다. 그러나, 다수의 안테나 포트 및/또는 사용자가 있는 시스템(예를 들어, MIMO(다중 입력 다중 출력) 시스템)에서, 특히 주파수 분할 이중화(FDD)를 사용하는 시스템에서는, 유형 I 코드북의 상대적으로 낮은 해상 도로는 적절한 정확도로 CSI 피드백을 제공할 수 없다. 더욱이, 유형 II 코드북의 사용은 여전히 UL 채널 상에 서 상당한 양의 오버헤드 데이터의 전송을 수반할 수 있다. 구현 세부 사항에 따라, 본 개시에 따른 기계 학습에 기초한 채널 정보 피드백 방식의 일부 실시 예는 UE가 gNB 로의 UL 전송과 관련된 오버헤드를 감소시키면서 전체 CSI 정보를 gNB로 전송하는 것을 가능하게 할 수 있다. 더욱이, 본 발명의 원리는 UE가 CSI를 gNB에 보내는 것에 제한되는 것이 아니고, 제1 장치가 제2 장치에 채널 정보 피드백을 보낼 수 있는 임의의 상황에 적용될 수 있다(예를 들어, UE에서 gNB로의 업링크 채널에 대한 채 널 조건의 보고, UE 간의 사이드링크 채널에 대한 채널 조건 보고 등).예시적인 실시 예 도 5는 본 개시에 따른 다운링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 시스 템은 UE(노드 B로 지정될 수 있음) 및 gNB(노드 A로 지정될 수 있음)를 포함할 수 있다. gNB는 DL 신호의 전송(예를 들어, 참조 신호(RS) 전송)을 UE에 전송할 수 있으며, UE는 이 전송으로부터 측정을 추출할 수 있다. UE는, 예를 들어, 측정을 DL 물리 계층에 관한 특징 벡터로 인코딩하기 위한 인코더로서 구성될 수 있는 모델을 포함할 수 있다. 인코딩된 측정은 그 다음 양 자화기에 의해 양자화되고 UL 신호(예를 들어, 비트스트림)로서 gNB에 다시 전송될 수 있다. 일 부 실시 예에서, 노드에서 모델의 설명은 또한 양자화기 및/또는 역양자화기 설명, 예를 들어, 인코더 모델의 출력에서의 채널 정보(예를 들어, 실제 CSI 코드워드)를 양자화된 값 또는 비트 스트림에 매핑할 수 있고 다른 노드의 디코더 모델에서는 그 반대로 매핑할 수 있는 기능을 포함할 수 있다. gNB는 수신된 UL 신호 를 역양자화기에 적용하여 DL 물리 계층에 관한 정보(예를 들어, 필수 또는 선택적 정보)를 추출하기 위해 모델에 공급될 수 있는 등가 특징 벡터를 생성할 수 있다. 도 6은 본 개시에 따른 업링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 일부 측면에서, 도 6에 예시된 시스템은 도 5에 예시된 시스템과 유사할 수 있지만, 시스템은 다운링 크 물리 계층 정보 대신에 업링크 물리 계층 정보를 보고하도록 구성될 수 있다. 구체적으로, 시스템은 (노드 B로 지정될 수 있는) gNB 및 (노드 A로 지정될 수 있는) UE를 포 함할 수 있다. UE는 UL 신호의 전송(예를 들어, 참조 신호(RS) 전송)을 상기 전송으로부터 측정(61 8)을 추출할 수 있는 gNB에 전송할 수 있다. gNB는, 예를 들어, UL 물리 계층에 관한 특징 벡터로 측 정을 인코딩하기 위한 인코더로서 구성될 수 있는 모델을 포함할 수 있다. 그 다음 인코딩된 측정은 양자화기에 의해 양자화되고 DL 신호(예를 들어, 비트스트림)로서 UE에 다시 전송될 수 있다. UE는 수신된 DL 신호를 역양자화기에 적용하여 UL 물리 계층에 관한 정보(예를 들어, 필수 또는 선택적 정보)를 추출하기 위해 모델에 공급될 수 있는 등가 특징 벡터를 생성할 수 있다. 도 7은 본 개시에 따른 다운링크 물리 계층 채널 상태 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시 한다. 구현 세부 사항에 따라, 도 7에 예시된 시스템은 ML 모델을 사용하여 (예를 들어, 비교적 적은 수의 비트로) CSI를 압축하면서, gNB 또는 다른 기지국이 UE로부터의 전체 CSI 정보를 검색하도록 할 수 있고(대조적 으로, 예를 들어, 코드북 기반 포인터, 프리코딩 행렬 표시자 등에 대해), 따라서 CSI 전송과 관련된 업링크 자 원 오버헤드를 줄일 수 있다. 시스템은 UE 및 gNB를 포함할 수 있다. gNB는 UE가 DL 채널에 대한 CSI를 결정할 수 있도록 하는 CSI-RS 또는 복조 참조 신호(DMRS)와 같은 DL 참조 신호를 전송할 수 있다. UE는 CSI를 특징 벡터로 인코딩하기 위한 인코더로서 구성될 수 있는 ML 모델을 포함할 수 있다. UE는 또한 UL 신호를 사용하여 gNB에 전송될 수 있는 비트 스트림으로 특징 벡터를 양자 화할 수 있는 양자화기를 포함할 수 있다. gNB는 비트 스트림으로부터 특징 벡터를 복원할 수 있는 역양자화기를 포함할 수 있다. 그 다음, 특징 벡터는 CSI의 추정을 복원하기 위한 디코더로서 구성될 수 있는 ML 모델에 공급될 수 있다. 일부 실시 예에서, 성능 메트릭 은 인코더 모델, 디코더 모델, 양자화기, 및/또는 역양 자화기의 설계, 구성 및/또는 훈련의 정확도를 평가하는 데 사용될 수 있다. 예를 들어, 성능 메트릭 은 다음과 같이 채널 추정치 간의 오차 측정으로 구현될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기에서 H 및 는 각각 UE 및 gNB에서의 채널 추정(예를 들어, CSI)를 나타낼 수 있다. 이러한 성 능 메트릭은 예를 들어 gNB에 의해 추출된 채널 상태 정보의 정확도를 평가하는 데 유용할 수 있다. 추가적으로 또는 대안적으로, 시스템은 UE가 현재 채널 조건에 기초하여 프리코딩 행렬을 결정하기 위해 DL 참조 신호를 사용할 수 있게 하도록 구성될 수 있다. 그 다음, 프리코딩 행렬은 인코더 모델(70 3)에 의해 특징으로 인코딩되고, 양자화기에 의해 양자화되고, UL 신호를 사용하여 gNB로 전송 될 수 있다. gNB에서, 역양자화기는 프리코딩 행렬의 추정치를 복원하기 위해 디코더 모델에 적 용될 수 있는 특징 벡터를 복구할 수 있다. 예를 들어, 채널 실현 H의 경우, 적절한 프리코딩 행렬은 H=SΣD로 주어질 수 있는 H의 특이값 분해(SVD)를 사용하여 특이 벡터 S의 세트로 구현될 수 있고, 여기서 Σ는 대각 행 렬이고 D는 단일 행렬일 수 있다. 그러한 실시 예에서, 인코더 모델, 디코더 모델, 양자화기, 및/또는 역양자화기는 gNB가 단일 벡터(예를 들어, 행렬) S의 세트를 추출할 수 있도록 구성될 수 있 고, 그에 따라 성능 메트릭이 구현될 수 있다. 도 7에 도시된 실시 예는 다운링크 물리 계층 정보를 보고하지만, 다른 실시 예는 본 개시에 따른 유사한 원리를 사용하여 업링크 물리 계층 정보, 사이드링크 물리 정보 등을 보고하도록 구성될 수 있다. 모델 개발, 훈련 및 동작 인공 지능(AI), 기계 학습(ML), 딥 러닝 등(위에서 언급한 바와 같이 이들 중 일부 또는 전부는 개별적으로 및/ 또는 집합적으로 기계 학습 또는 ML로 지칭될 수 있음)은 본 개시에 따라 데이터의 하나 이상의 함수(예를 들어, 복소수 함수)를 추론하기 위한 기술을 제공할 수 있다. 기계 학습 과정에서, 데이터의 샘플이 ML 모델에 제공될 수 있으며, 이는 차례로 제공된 데이터 샘플을 사용하여 하나 이상의 함수를 결정하는 방법을 학습하기 위해 다양한 기계 학습 기술 중 하나를 적용할 수 있다. 예를 들어, 기계 학습 프로세스는 ML 모델이 데이터 샘 플 입력 x의 함수 f(x)를 학습하도록 허용할 수 있다. 앞서 언급한 바와 같이, ML 모델은 또한 모델이라고도 할 수 있다. 일부 실시 예에서, 기계 학습 프로세스(개발 프로세스라고도 함)는 훈련, 검증, 테스트 및/또는 추론(응용 단계 라고도 함)과 같은 하나 이상의 단계(단계라고도 함)에서 진행할 수 있다. 일부 실시 예는 이러한 단계 중 하나 이상을 생략하고/하거나 하나 이상의 추가 단계를 포함할 수 있다. 일부 실시 예에서, 하나 이상의 스테이지의 전부 또는 일부는 하나의 스테이지로 결합될 수 있고, 스테이지는 다중 스테이지로 분할될 수 있다. 또한, 단계 또는 그 일부의 순서는 변경될 수 있다. 훈련 단계에서, 모델은 하나 이상의 목표 작업을 수행하도록 훈련될 수 있다. 훈련 단계는 i) 데이터 샘플, 및 ii) 훈련 데이터 세트의 샘플(예를 들어, 각 샘플)에 대한 함수 f(x)의 결과를 포함할 수 있는 훈련 데이터 세 트의 사용을 포함할 수 있다. 훈련 단계에서, 하나 이상의 훈련 기술은 모델이 함수 f(x)처럼 동작하거나 이를 밀접하게 따를 수 있는 근사 관계(예를 들어, 근사 함수)를 학습할 수 있도록 한다. 검증 단계에서, 모델은 하나 이상의 목표 작업에 대한 훈련된 모델의 적합성을 평가하기 위해 (예를 들어, 초기 훈련을 수행한 후에) 테스트될 수 있다. 검증 결과가 만족스럽지 않은 경우 모델은 추가 훈련을 받을 수 있다. 검증 단계가 성공적인 결과를 제공하면 훈련 단계가 성공적으로 완료된 것으로 간주될 수 있다. 테스트 단계에서, 훈련된 모델은 하나 이상의 목표 작업에 대해 훈련된 ML 모델의 적합성을 평가하기 위해 테스 트될 수 있다. 일부 실시 예에서, 훈련된 모델은 훈련이 완료되고 검증이 성공적인 결과를 제공하지 않는 한 테 스트 단계로 진행하지 않을 수 있다. 추론 단계에서, 훈련된 모델은 하나 이상의 목표 태스크를 수행하기 위해 (예를 들어, 실제 애플리케이션에서) 사용된다. 테스트 및/또는 추론 단계에서, 모델은 훈련 단계의 샘플과 다를 수 있는 다른 데이터 샘플의 함수 값 f(x)를 결정하기 위해 훈련 단계를 통해 얻은 학습된 근사 함수를 사용할 수 있다. 일부 실시 예에서, 기계 학습 프로세스의 성공 및/또는 성능은 함수 f(x)에 대한 충분한 정보를 포함할 수 있는 충분히 큰 훈련 데이터 세트의 사용을 포함할 수 있으므로, 모델이 훈련 단계를 통해 함수 f(x)의 허용 가능하 게 근접한 근사값을 얻을 수 있도록 한다. 도 8은 본 개시에 따른 기계 학습 모델을 위한 학습 프로세스의 실시 예를 예시한다. 프로세스는 훈련 프 로세스가 초기화될 수 있는 단계에서 시작할 수 있다. 예를 들어, 모델의 구조가 결정될 수 있으며, 모델 의 값(예를 들어, 신경망 가중치, 하이퍼매개변수 등)이 초기화될 수 있으며, 적절한 수의 샘플로 훈련 데이터 세트가 구성될 수 있는 등이다. 단계에서, 초기화된 모델은 예를 들어, 경사 하강법, 역전파 등을 사용하여 신경망 가중치, 하이퍼매개변 수 등의 값을 업데이트함으로써, 훈련된 후보 모델의 구성을 결정하기 위해 훈련 데이터 세트를 사용하여 훈련될 수 있다. 일부 실시 예에서, 훈련 데이터 세트의 구성과 훈련 단계 사이에는 상호 관계가 있을 수 있다. 예를 들어, 훈련 단계는 완료하는 데 비교적 긴 시간이 소요될 수 있으며, 기간은 훈련 데이터 세트의 샘플 수에 따라 달라질 수 있다. 기간은 차례로 훈련 유형에 따라 달라질 수 있다. 예를 들어, 전체 훈련 및/또는 초기 훈련의 경우, 모델 이 초기화될 수 있고 많은 샘플(예를 들어, 모델 훈련을 위해 이전에 사용되지 않았을 수 있는 샘플)로 구성될 수 있는 큰 데이터 세트를 사용하여 훈련이 수행될 수 있다. 다른 예로, 부분 훈련 및/또는 업데이트 훈련의 경 우, 모델은 이전에 훈련되고 (또는 부분적으로 훈련되고), 이벤트(예를 들어, 새로운 데이터 샘플 획득, 모델의 성능 저하, 모델 업데이트 이벤트 등)는 모델의 수정 또는 적응을 프롬프트할 수 있다. 부분 훈련 및/또는 업데 이트 훈련의 경우, 모델은 전체 훈련 및/또는 초기 훈련에 사용되는 대규모 훈련 데이터 세트와 다를 수 있는 수정된 데이터 세트를 사용하여 훈련될 수 있다. 예를 들어, 수정된 훈련 데이터 세트는 초기 훈련에 사용된 전 체 데이터 세트의 하위집합, 새로 획득된 새로운 데이터 샘플의 세트, 또는 이들의 조합일 수 있다. 단계에서, 훈련된 후보 모델이 검증될 수 있다. 일부 실시 예에서, 검증 단계는 훈련 단계와 반 복적으로 수행될 수 있다. 예를 들어, 후보 모델이 검증 단계에서 실패하면, 새로운 후보 모델을 생성할 수 있는 훈련 단계로 돌아갈 수 있다. 일부 실시 예에서, 검증 성공 또는 실패(예를 들어, 분류 정확도, 최소 평균 제곱 오차(MMSE) 등)를 결정하기 위해 상이한 기준이 설정될 수 있다. 일부 실시 예에서, (예를 들어, 임계값을 초과하여 여러 번 실패한 후 또는 성능 기준이 특정 기간 또는 특정 수의 검증 단계 동안 임계값을 통과하지 못한 경우) 실패한 후보 모델은 훈련 단계로 돌아가는 것이 허용 되지 않고, 방법은 단계에서 종료될 수 있다. 다만, 검증 데이터를 이용한 후보 모델의 성능이 (예를 들어, 성공 또는 실패를 결정하는 기준에 따라) 적합하다고 판단되는 경우, 검증은 성공적인 것으로 간주될 수 있고 훈련된 후보 모델은 단계에서 테스트 단계로 전달될 수 있다. 단계에서, 검증 단계를 통과한 훈련된 모델 후보의 성능이 평가될 수 있다. 개발의 테스트 단계 동안 모델 의 성공 테스트 및/또는 실패를 선언하는 기준은 검증 단계에서 사용된 기준과 유사할 수 있다. 하지만, 테스트 단계 동안 기준과 함께 사용되는 하나 이상의 매개변수(예를 들어, 단계 수, 성능 임계값 등)는 검증 단계에서 사용된 것과 다를 수도 있고 다르지 않을 수 있다. 테스트가 성공적이면, 최종 모델로 지정되어 단계로 진행할 수 있다. 일부 실시 예에서, 모델이 테스트 단 계에 실패하면, 프로세스는 추가 훈련을 위해 단계에서 훈련 단계로 돌아갈 수 있다. 그러나 일부 실시 예 에서, 추가 훈련은 (예를 들어, 검증 단계 동안 사용된 것과 유사한 기준에 기초하여) 허용되지 않을 수 있고, 프로세스는 단계에서 종료될 수 있다. 모델 훈련 및 배포 프레임워크 본 개시에 따른 일부 실시 예는 모델을 훈련 및/또는 전개하기 위한 하나 이상의 프레임워크를 구현할 수 있다. 본 명세서에 개시된 프레임워크의 일부 실시 예에서, 노드에 의해 훈련 및/또는 개발된 하나 이상의 모델은 예 를 들어, 해당 애플리케이션에 대해 지정될 수 있는 하나 이상의 잠재적 테스트 사례에 대한 모델의 준수를 평 가하기 위해, 노드에 대한 하나 이상의 참조 모델에 대해 테스트될 수 있다. 본 명세서에 개시된 프레임워크의 임의의 실시 예에서, 양자화 함수는 양자화기 범위의 일부 또는 전체에 걸쳐 (예를 들어, 본질적으로 전체 범위에 걸쳐) 본질적으로 0의 도함수 값(예를 들어, 확률 1을 가짐)으로 미분 가 능하다. 구현 세부 사항에 따르면, 이로 인해 인코더 가중치 업데이트가 거의 또는 전혀 제공되지 않을 수 있는 역전파가 발생할 수 있다. 따라서, 일부 실시 예에서, 양자화 함수는 훈련 단계에서 로 지 칭될 수 있는 미분 가능한 함수(예를 들어, 참조 미분 가능한 양자화 함수)로 근사화될 수 있고, 실제 양자화 함수는 추론 단계에서 사용될 수 있다. 유사하게, 역양자화 함수는 훈련 단계에서 fdequantizer,approx(x)로 지칭될 수 있는 미분 가능 함수(예를 들어, 참조 미분 가능한 역양자화 함수)로 근사화될 수 있는 반면, 실제 역양자화 함 수는 추론 단계에서 사용될 수 있다. 일부 실시 예에서, 모델과 함께 사용되는 양자화기 또는 역양자화 함수는 해당 모델에 대한 완전한 설명의 일부로 간주될 수 있으며, 모델과 함께 또는 모델의 일부로 양도될 수 있다. 따라서, 본 명세서에서 공개된 프레임워크 중 하나를 사용하여, 제1 노드가 제2 노드와 훈련된 모델을 공유하는 경우 (예를 들어, 노드 A가 모델 A와 모델 B의 쌍을 훈련하면, 훈련된 모델 B를 노드 B로 보냄), 제1 모델은 또 한 예를 들어 RRC 시그널링을 통해, 제2 노드와 근사된 양자화 함수 및/또는 근사된 역양자화 함수 중 하나 또는 둘 다를 공유할 수 있다. 본 명세서에 개시된 프레임워크는 임의의 특정 애플리케이션 및/또는 구현 세부사항으로 제한되지 않지만, 일부 실시 예에서, 및 구현 세부사항에 따라, 프레임워크는 CSI 피드백 오버헤드를 줄일 수 있는 모델을 훈련 및/또 는 테스트하는 데 사용될 수 있다. 공동 훈련 프레임워크 일부 실시 예에서, 한 쌍의 모델(예를 들어, 모델 A 및 모델 B)은 두 노드(노드 A 또는 노드 B) 중 하나에 의해 공동으로 훈련될 수 있으며, 비훈련 노드에 대한 훈련된 모델은 추론에 사용하기 위해 비훈련 노드로 전달될 수 있다(예를 들어, 공동 훈련이 노드 A에 의해 수행되는 경우, 훈련된 모델 B가 노드 B로 전달될 수 있음). 예를 들어, CSI 압축의 맥락에서, 기지국은 한 쌍의 인코더 및 디코더 모델의 공동 훈련을 수행한 다음, 인코더 모델 을 UE에 전달할 수 있다. 인코더 모델은 또한 인코더로 지칭될 수 있고, 디코더 모델은 또한 디코더로 지칭될 수 있다. 공동 훈련 프레임워크의 일부 실시 예에서, 훈련된 모델 중 하나 또는 둘 모두의 추가 훈련(예를 들어, 미세 조 정)은 (예를 들어, 모델 중 하나 또는 둘 모두를 개선하거나 최적화하기 위해) 모델이 추론에 사용될 수 있는 노드에 의해 수행될 수 있다. 일부 실시 예에서, 추가 훈련은 예를 들어 진행 중인 통신 중에 하나 이상의 노드 에 의해 획득될 수 있는 온라인 데이터에 기반할 수 있다. 공동 훈련 프레임워크의 일부 실시 예에서, 훈련 노드는 대응하는 양자화기 및/또는 역양자화 함수(예를 들어, 근사 및/또는 미분 양자화 및/또는 역양자화 함수)을 사용하여 하나 또는 둘 모두의 모델을 훈련할 수 있다. 훈 련된 모델을 수신하는 노드는 또한 추가 훈련, 검증, 테스트, 추론 등을 위해 해당 양자화기 및/또는 역양자화 함수를 수신하여 사용할 수 있다. 일부 구현에서, 노드에 의한 모델의 공동 훈련은 대상 작업에 공동으로 매칭될 수 있는 모델을 생성할 수 있고, 따라서 개선되거나 최적화된 성능을 제공할 수 있다. 구현 세부 사항에 따라, 이러한 성능 향상은 모델을 다른 노드로 전달하는 것과 관련된 통신 오버헤드 및/또는 예를 들어, 다른 노드와 다른 제조업체에서 생산할 수 있 는 한 노드에서의 공동 훈련으로 인해 발생하는 모델 및/또는 노드 간의 불일치를 보충할 수 있다. 공동 훈련 프레임워크의 변형에서, 예를 들어, 하나의 노드는 기지국은 한 쌍의 인코더 및 디코더 모델을 공동 으로 훈련할 수 있다. 인코더 및 디코더 쌍은, 예를 들어, 위에서 설명된 바와 같은 참조 미분 양자화 및 역양 자화 함수를 사용하여 훈련될 수 있다. 그 다음, 기지국은 예를 들어 RRC 시그널링을 통해 훈련된 디코더 모델 을 UE와 공유할 수 있다. 그러나 기지국은 훈련된 인코더 모델을 UE와 공유할 수도 있고 공유하지 않을 수도 있 다. 기지국이 훈련된 인코더 모델을 UE와 공유하는 경우, UE는 훈련된 인코더 모델을 참조 인코더 모델로 사용 할 수 있다. 기지국이 훈련된 인코더 모델을 UE와 공유하지 않는 경우, UE는, 예를 들어, 무작위로 초기화된 가 중치, UE 구현을 위해 선택될 수 있는 가중치, 또는 임의의 다른 기반에 기초하여 참조 인코더 모델을 설정할 수 있다. UE는 다음에 기지국으로부터 수신한 훈련된 디코더 모델을 사용하여 참조 인코더 모델을 훈련할 수 있다. 참조 인코더 모델은 온라인으로 학습될 수 있다(동작 중에 수행될 수 있는 학습을 참조할 수 있음). 일부 구현에서, 온라인 훈련이 즉석에서 수행될 수 있다(동작 동안 수집될 수 있는 훈련 데이터(예를 들어, 채널 추정 H)를 사 용하여 수행된 훈련을 참조할 수 있음). 따라서, UE는 시간에 걸쳐 수집될 수 있는 채널 추정치 H를 사용하여 참조 인코더 모델을 훈련할 수 있다. 수집된 채널 추정치는 예를 들어 훈련 중 특정 지점에서 새로운 훈련 데이 터 세트로 사용될 수 있다. 더욱이, 수집된 채널 추정치 H는 또한 UE 또는 임의의 다른 장치에 의한 미래의 온 라인 및/또는 오프라인 훈련을 위해 저장될 수 있다. 그 다음 UE는 추론을 위해 훈련된 인코더 모델을 사용할 수 있다. UE는 또한 훈련된 인코더 모델을 기지국과 공 유할 수 있다. 훈련 절차는 더 많은 훈련 샘플, 예를 들어 채널 추정치 H가 훈련을 위해 UE에 의해 수집되고 사 용됨에 따라 계속될 수 있다. 도 9는 본 개시에 따른 한 쌍의 인코더 및 디코더 모델의 공동 훈련을 위한 방법의 예시적인 실시 예를 도시한 다. 단계에서 기지국은 Encref 및 Decref로 지칭될 수 있는 훈련 데이터 세트를 이용하여 한 쌍의 참조 인코 더 및 디코더 모델을 공동으로 훈련할 수 있다. 단계에서, 기지국은 참조 디코더 모델 Decref를 UE와 공유 할 수 있다. 단계에서, 기지국은 참조 인코더 모델을 UE와 공유할지 여부를 결정한다. 기지국이 UE와 참조인코더를 공유하는 경우, 단계에서, UE는 공유된 참조 인코더를 훈련을 위해 참조 인코더로 사용할 수 있 다. 기지국이 UE와 참조 인코더를 공유하지 않는 경우, 단계에서, UE는 예를 들어 랜덤 가중치를 사용하거 나 UE 구현에 기초한 가중치를 사용하는 등의 참조 인코더 모델을 설정할 수 있다. 단계에서 UE는 시점 ti 에서 참조 인코더 모델을 훈련할 수 있다. [UE는 시점 ti에서 참조 인코더 모델을 학습한다.] 시점 ti는 예를 들어, UE가 이전 시점 이후 충분한 채널 추정을 수행하고 수집한 시점으로 결정될 수 있다. 이것은 예를 들어 알고리즘 1에 도시된 바와 같이 구현될 수 있으며, 여기서 각 시점 ti에 대해, UE는 새로운 온라인 훈련 세트 Si 를 즉석에서 수집할 수 있고, 여기서 Si는 ti-1에서 ti까지의 채널 추정치를 포함할 수 있고, N은 UE 측에서 최대 온라인 훈련 수일 수 있다. 일부 구현에서는 알고리즘 1을 완료한 후, UE는 훈련된 인코더 모델을 기지국과 공 유할 수 있다. 알고리즘 1"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 명세서에 개시된 훈련 및 전개 프레임워크 중 임의의 것은 장치의 임의의 유형 및/또는 조합 및 임의의 유형 의 모델 및/또는 물리 계층 정보와 함께 사용될 수 있다. 예를 들어, 도 8에 도시된 실시 예에서, 기지국이 초 기 조인트 훈련을 수행하고 인코더 및 디코더가 훈련되고 채널 추정과 함께 사용될 수 있지만, 다른 실시 예에 서 공동 훈련은 UE 또는 임의의 다른 장치에 의해 수행될 수 있고 모델은 훈련되고 프리코딩 행렬 또는 임의의 다른 유형의 물리 계층 정보와 함께 사용될 수 있다. 일부 실시 예에서, UE 또는 기지국과 같은 노드는 윈도우 (예를 들어, 명시적 시간 및/또는 주파수 윈도우) 내에서 새로운 훈련 데이터를 수집할 수 있다. 수집된 데이터 는 예를 들어 노드가 모델을 훈련하는 데 사용할 수 있는 훈련 데이터 세트를 구성하는 데 사용될 수 있다. 윈 도우는 예를 들어 기지국에 의해 결정될 수 있는 시작 및/또는 종료 시간으로 구성될 수 있다. 일부 실시 예에 서, 데이터 수집 윈도우를 결정하기 위해 사용되는 타임라인은, 예를 들어, 하나 이상의 CSI-RS 자원으로부터 측정될 수 있다. 대안적으로, 또는 추가적으로, 온라인 훈련은 다음과 같이 수행될 수 있다. 제1 노드 기지국은 제1 모델을 가질 수 있고, 제2 노드는 제1 모델과 쌍을 형성할 수 있는 제2 모델을 가질 수 있다. 일부 실시 예에서, 제1 및 제2 노드는 연결 모드(예를 들어, RRC 연결 모드)에서 동작할 수 있다. 노드 중 하나 또는 둘 모두는 다른 노드에 의한 공유를 통해 모델을 획득할 수 있다. 이 예에서, 노드들 중 하나는 기지국일 수 있고 다른 노드는 UE일 수 있다. 기지국은 미리 결정된 온라인 훈련 데이터 세트로 UE를 구성할 수 있고, 두 노드는 각각의 모델을 업데이트하기 위해 미리 결정된 온라인 훈련 데이터 세트를 사용할 수 있다. 노드가 자신의 모델을 업데이트할 때, 다른 노드 의 다른 모델은 고정된 것으로 가정할 수 있다. 일부 실시 예에서, 하나 이상의 온라인 훈련 데이터 세트는 (예 를 들어, 사양의 일부로서) 지정될 수 있고/있거나, 제3 노드에 의해 UE 및/또는 기지국에 제공될 수 있다. 제1 노드가 제1 모델 (예를 들어, 인코더 또는 디코더)을 업데이트하면, 업데이트된 제1 모델을 제2 노드와 공유할 수 있다. 제2 노드는 제1 모델이 고정되었다고 가정하여 제2 모델을 훈련시키기 시작할 수 있다. 모델은 예를 들어 종료 시간에 도달할 때까지 주기적으로 모델을 훈련하고 고정하는 작업을 계속할 수 있다. 상술된 실시 예는 UE가 인코더를 업데이트하고 사용할 수 있는 맥락에서 설명될 수 있지만, 온라인 훈련에 따른 일부 실시 예에서, UE와 기지국 모두(또는 측대역 통신을 위해 구성된 두 개의 UE와 같은 한 쌍의 모델을 가진 두 개의 다른 노드)는 새로운 훈련 데이터를 수집하고 자신의 모델(예를 들어, 인코더 또는 디코더) 또는 두 모 델(예를 들어, 자동 인코더로 구성될 수 있는 인코더 및 디코더 모두)를 업데이트하는 데 사용할 수 있다. 일부 실시 예에서, 제1 노드는 훈련 데이터를 데이터 또는 제어 정보로 전송함으로써 새로 수집된 훈련 데이터 (예를 들어, 채널 행렬)를 제2 노드와 공유할 수 있다. 예를 들어, UE는 하나 이상의 채널 행렬의 이진 표현을 생성하고 업링크 전송, 즉 인코딩, 변조 등을 위한 일반적인 절차에 따라 PUSCH 또는 PUCCH를 사용하여 표현을전송할 수 있다. 대안적으로, 또는 추가적으로, UE는 인코더를 현재 훈련된대로 사용하여 획득한 채널 행렬을 인코딩할 수 있다. UE는 CSI 코드워드로 지칭될 수 있는 인코딩된 채널 행렬을 기지국으로 전송할 수 있다. 기지국은 다음에 현재 훈련된 디코더를 사용하여 채널 행렬을 복구할 수 있다. 이 때 기지국은 기지국에서 추가의 (예를 들어, 온라인) 훈련에 사용될 수 있는 새로운 훈련 데이터 세트에 복구된 채널 행렬을 포함할 수 있다. 일부 실시 예에서, 노드 간에 훈련 데이터를 교환하는 것 외에, 하나 이상의 노드는 최신 훈련 모델(예를 들어, 인코더 및/또는 디코더)을 다른 노드와 공유할 수도 있다. 훈련 데이터 및/또는 모델의 공유는 이러한 공유와 관련된 통신 오버헤드의 양을 관리할 수 있는 간격으로 수행될 수 있다(예를 들어, 모델이 업데이트될 때 전송 될 수 있음). 모델의 온라인 훈련이 있는 프레임워크에서, 노드는 수집된 물리 계층 정보(예를 들어, 시간 ti-1에서 시간 ti까 지의 CSI 행렬)를 저장하기 위해 메모리 버퍼를 사용할 수 있다. 구현 세부 사항에 따라, 노드는 모델을 업데이 트하기 위해 새로운 훈련 데이터를 사용하기 시작하기 전에 새로운 훈련 데이터 세트의 일부 또는 전부를 수집 할 수 있다. 그러나, 노드가 훈련 데이터 세트를 저장하기 위해 전용 메모리 버퍼를 사용하고 시간 ti-1와 시간 ti 사이의 간격이 특정 값을 초과하면, 시간 윈도우에서 CSI-RS의 수가 너무 커질 수 있으므로 훈련 데이터를 저장하는 데 관련된 메모리 양이 사용 가능한 버퍼 크기를 초과할 수 있다. 또한, 시간 ti-1과 시간 ti 사이의 간 격이 일반적으로 버퍼 오버플로를 방지할 만큼 충분히 짧은 경우에도, 노드는 비교적 짧은 주기를 가진 일부 참 조신호를 만날 수 있다(예를 들어, 상대적으로 많은 수의 참조 신호(예를 들어, CSI-RS)가 윈도우에서 구성될 수 있음), 이에 따라 참조신호에 기초하여 수집된 CSI 행렬은 사용 가능한 전용 메모리 버퍼를 초과할 수 있다. 일부 실시 예에서, 노드는 예를 들어 수집된 훈련 데이터로부터 구성된 훈련 데이터 세트의 크기와 관련될 수 있는 데이터 버퍼링 능력을 선언할 수 있다. 구현 세부 사항에 따라, 이것은 새로운 훈련 데이터에 대한 메모리 버퍼의 용량을 초과하는 문제를 줄이거나 방지할 수 있다. 예를 들어, 노드는 훈련 데이터를 획득하고/하거 나 획득된 훈련 데이터에 기초하여 모델을 업데이트하기 위한 시간 간격(예를 들어, 최대 시간 간격); 노드 가 훈련 세트를 구성하는 데 사용할 것으로 예상되는 시간 윈도우 내의 참조신호(예를 들어, CSI-RS)의 최대 수; 또는 훈련 데이터 세트를 구성하는 데 사용되는 참조 신호(예를 들어, CSI-RS)의 단락 주기성에 기초하 여 미리 결정된 메모리 버퍼 능력을 선언하거나 할당될 수 있다. 노드가 미리 결정된 메모리 버퍼 능력을 위반 할 수 있는 하나 이상의 참조신호 및/또는 시간 윈도우으로 구성되는 상황을 오류 경우로 간주할 수 있다. 대안적으로, 또는 추가적으로, 노드의 미리 결정된 메모리 버퍼 능력의 위반이 발생할 때 디폴트 동작이 정의될 수 있다. 예를 들어, 참조신호 및/또는 시간 윈도우의 구성이 노드의 메모리 버퍼 용량을 위반하는 경우, 노드 는 모델을 업데이트하기 위해 수집된 훈련 데이터의 하위집합을 저장 및/또는 사용할 수 있다. 예를 들어, UE가 윈도우 내에서 최대 Nmax CSI-RS를 보고하고, gNB가 윈도우 내에서 더 많은 수의 NCSI-RS CSI-RS를 구성하는 경우, UE는 모델을 업데이트하기 위해 NCSI-RS CSI-RS중에서 Nmax CSI-RS만을 사용할 수 있다. UE가 사용할 CSI-RS를 선 택하는 방법은 UE 구현 및/또는 하나 이상의 구성되고/되거나 고정된 규칙에 따라 결정될 수 있다(예를 들어, UE는 NCSI-RS 자원 중 최신 Nmax 자원을 사용할 수 있다). 일부 실시 예에서, 수집된 훈련 데이터에 대한 버퍼 크기는 예를 들어 사양을 포함하지 않고 노드 구현을 기반 으로 할 수 있다. 예를 들어, UE의 훈련 데이터 버퍼가 오버플로되면, UE는 새로 수집된 데이터(예를 들어, 행 렬) 저장을 중단하고 버퍼의 데이터로 모델 업데이트를 진행할 수 있다. 일부 실시 예에서, UE는 모델이 업데이 트되면 버퍼를 플러시한 다음에, 새로운 훈련 데이터를 다시 수집하기 시작한다. 일부 실시 예에서, UE는 새로운 훈련 데이터를 저장하기 위해 공유 버퍼를 사용할 수 있다. 공유 버퍼의 예는 다른 채널, 예를 들어 PDSCH 버퍼, 마스터 CCE LLR 버퍼 등을 저장하기 위해 이미 사용된 하나 이상의 버퍼를 포함할 수 있다. 이 실시 예에서, 공유 버퍼 공간은 다른 전용 용도에 따라 이미 완전히 또는 부분적으로 점유 되어 있을 수 있으므로 가용성에 따라 사용될 수 있다. 일부 실시 예에서, 수집된 훈련 데이터의 버퍼링은 노드 구현에 기초할 수 있다. 참조 모델을 사용한 훈련 프레임워크 본 개시에 따른 일부 프레임워크에서, 참조 모델은 노드 A에 대해 모델 A로 설정될 수 있으며, 노드 B는 (예를 들어, 노드 A가 참조 모델을 추론을 위해 모델 A로 사용한다고 가정하고) 참조 모델을 모델 A로 사용하여 모델B를 훈련할 수 있다. 노드 A는 다음에 추가 훈련 없이 참조 모델을 모델 A로 사용하거나, 노드 A는 모델 A로 사 용하도록 참조 모델을 훈련할 수 있다. 일부 실시 예에서, 노드 A에 대해 하나 또는 다수의 모델 A가 제공 및/ 또는 지정될 수 있으며, 노드 B는 노드 A에 대한 참조 모델 중 하나 또는 다수개라고 가정될 수 있는 노드 B에 서 모델 A를 사용하여 하나 이상의 모델 B를 훈련할 수 있다. 예를 들어, 노드 B는 모델 A에 대해 지정된 하나 의 참조 모델로 가정되는 모델 A를 사용하여 모델 B의 제1 버전을 훈련할 수 있다. 노드 B는 모델 A를 다른 참 조 모델 등으로 가정하여 모델 B의 제2 버전을 훈련할 수도 있다. 예를 들어, 참조 모델은 사양, 시그널링(예를 들어, UE가 RRC-연결된 후 기지국에서 UE로의 RRC 시그널링) 등을 통해 설정될 수 있다. 일부 실시 예에서, 노드 B는 모델 A의 다른 버전을 훈련하기 위해 어느 참조 모델을 선택했지에 대해 노드 A에 알릴 수 있다. 모델 A에 사용할 수 있는 참조 모델이 하나뿐인 경우, 참조 모델이 암시적으로 알려져 있기 때문 에 통신이 포함될 수 없다. 노드 B는 모델 B의 학습 버전에 사용할 수 있는 다수의 참조 모델 중 하나의 참조 모델을 노드 A에 알릴 수 있으며; 이 모델은 예를 들어 최상의 성능을 제공한 참조 모델에 해당할 수 있다. 대 안적으로, 또는 추가적으로, 노드 B는 노드 A에게 다수의 참조 모델 중 참조 모델의 하위집합을 알릴 수 있으며; 이 하위 집합은 최고 성능의 참조 모델의 모음을 포함할 수 있다. 노드 B에서 노드 A로의 임의의 시그널링에 관계없이, 노드 A는 어느 참조 모델을 선택했는지를 노드 B에 표시하 거나 표시하지 않을 수 있다. 참조 모델을 표시하게 되면 예를 들어 노드 A와 노드 B 사이에 공통된 이해를 설 정하는 데 유용할 수 있는 반면, 참조 모델을 표시하지 않으면 시그널링 오버헤드를 줄일 수 있다. 다수의 참조 모델이 있는 구현에서, 최고 성능 모델의 하위 집합이 하나의 참조 모델만 포함하면(예를 들어, 하나의 참조 모 델만이 노드 B에서 노드 A로 가장 성능이 좋은 참조 모델로 표시되면), 노드 A에 의한 선택이 노드 B에 의해 암 시적으로 알려질 수 있기 때문에 노드 A는 노드 B에 표시를 제공하지 않을 수 있다. 일단 노드 A에 대한 참조 모델이 설정되면, 노드 A는 모델 A로서 참조 모델을 사용하거나 참조 모델을 훈련시키 는 것을 진행할 수 있다. 구현 세부 사항에 따라, 참조 모델을 (예를 들어, 추가 훈련 또는 조정이 거의 또는 전혀 없이) 모델 A로 사용하게 되면 노드 B는 모델 A에 대한 참조 모델의 사용을 가정하여 모델 B를 훈련할 수 있기 때문에 두 모델 간에 비교적 높은 수준의 일치(예를 들어, 최상의 일치)를 제공할 수 있다. 다양한 버전의 모델 B를 학습하기 위해 노드 B에서 다수의 참조 모델을 사용하면, 노드 A는 모델 B의 훈련된 버전에 해당하는 참조 모델을 사용할 수 있으며; 이는 모델 B의 훈련된 버전 중 어느 것이 사용될지에 대한 노드 A와 노드 B 사 이에 공통된 이해를 확립하는 것을 포함할 수 있다(예를 들어, 노드 B는 모델 B의 어느 훈련된 버전이 사용되는 지를 노드 A와 통신할 수 있거나, 노드 A는 어느 모델을 사용할지에 대해 노드 B에 알릴 수 있음). 추가 훈련 없이 모델 A로 참조 모델을 사용하는 대신, 노드 A는 모델 A의 훈련을 지속할 수 있다. 이것은 예를 들어 참조 모델이 현재 네트워크 상태에 적합하지 않은 경우 유용할 수 있다(예를 들어, 모델이 CSI 압축 및 압 축 해제에 사용되는 경우 무선 환경). 따라서, 노드 A가 모델 A를 추가로 훈련(예를 들어, 조정 또는 최적화)하 도록 허용하면 모델이 현재 네트워크 상태와 일치할 수 있다. 하지만, 모델 B를 훈련할 때 모드 A를 노드 B에 의해 가정된 참조 모델로부터 변경하게 되면 두 모델 간에 잠재적인 불일치가 발생하여 성능이 저하될 수 있다. 일부 실시 예에서, 모델 A는 이러한 잠재적인 불일치를 극복하도록 훈련될 수 있다. 예를 들어, 모델 A를 훈련 하기 위해, 노드 B는 모델 B를 노드 A로 보낼 수 있으므로 모델 A의 훈련은 노드 B에 의해 모델 B로 사용되는 실제 모델을 기반으로 할 수 있다. 모델 B의 다수의 훈련된 버전이 있는 경우, 노드 B는 모델 B의 훈련된 버전의 하위 집합을 통신할 수 있고, 노 드 A는 모델 B의 통신된 버전에 대해 다수의 해당하는 모델 A를 훈련할 수 있다. 그러한 실시 예에서, 모델 A와 모델 B는 어느 쌍의 모델 A와 모델 B를 선택하여 사용할 것인지에 대한 공통된 이해를 구축하기 위해 통신할 수 있다. 구현 세부 사항에 따라, 모델 A의 다수의 버전을 공유하면 통신된 모델 중에서 가장 성능이 좋을 수 있는 모델 A와 모델 B의 최상의 쌍을 선택하여, 노드 A 및/또는 노드 B가 성능을 향상(예를 들어, 최적화)할 수 있도 록 한다. 또는, 통신 오버헤드를 줄이기 위해서, 노드 B는 모델 B의 다수의 버전 중 하나와 통신할 수 있고, 노 드 A는 통신된 버전의 모델 B에 해당하는 모델 A를 훈련할 수 있다. 대안적으로, 또는 추가적으로, 노드 A가 모델 A의 훈련을 진행하면, 노드 A는 노드 B가 사용하는 실제 모델 B를 모방하기 위해 모델 B의 평가판을 훈련할 수 있다. 시험 모델 B와 실제 모델 B 간의 유사성 수준은 모델 B의 설 계 및/또는 아키텍처, 모델 B의 평가판을 훈련하는 데 사용되는 훈련 데이터 세트, 및/또는 모델 B의 평가판을 훈련하는 데 사용되는 훈련 절차(예를 들어, 가중치, 초매개변수 등의 초기화)에 따라 달라질 수 있다. 노드 B에서 훈련된 모델 B의 다수의 훈련된 버전이 있는 경우, 노드 A는 모델 B의 다수의 해당 평가 버전을 훈련할 수 있다. 또는, 노드 A는 모델 A에 대해 사용 가능한 참조 모델 각각에 해당하는 모델 B의 평가 버전을 사용하여 다수의 모델 A를 훈련할 수 있으며; 이것은 특히 노드 B가 어느 참조 모델이나 모델을 선택했는지를 노드 B가 알려주기 전에 노드 A가 모델 A를 훈련하도록 할 수 있기 때문에 유용할 수 있다. 그러한 실시 예에서, 모델 A 와 모델 B는 어느 쌍의 모델 A와 모델 B를 선택하여 사용할 것인지에 대한 공통된 이해를 구축하기 위해 통신할 수 있다. 시험 모델 B와 실제 모델 B 사이의 불일치를 더 줄이기 위해, 노드 B는 노드 A와 일부 보조 정보를 공유할 수 있다. 구현 세부 사항에 따라, 보조 정보를 공유하면 노드 A가 실제 모델 B와 유사한 시험 모델 B를 생성하는 방식으로 시험 모델 B를 훈련하는 데 도움이 될 수 있다. 보조 정보의 예에는 초기화 값(예를 들어, 실제 모델 B를 훈련하기 위해 노드 B에서 사용하는 랜덤 시드, 초기 네트워크 가중치 등), 하나 이상의 최적화 알고리즘, 기능 선택에 사용되는 하나 이상의 알고리즘, 데이터 사전 처리에 사용되는 하나 이상의 알고리즘, 신경망 유형 에 대한 정보(예를 들어, 순환 신경망(RNN), 컨볼루션 신경망(CNN) 등), 모델 구조에 대한 정보(예를 들어, 계 층의 수, 계층 당 노드의 수 등), 훈련 데이터 세트에 대한 정보 등을 포함할 수 있다. 이 정보를 사용하는 것 은 노드의 구현에 (예를 들어 사양을 통해) 위임되거나 맡겨질 수 있다. 일부 실시 예에서, 노드 A 및/또는 노드 B에 대한 참조 모델은 예를 들어 테스트 목적으로 (예를 들어, 사양에 서) 지정될 수 있다. 이러한 실시 예는 노드 A 및/또는 노드 B에 의해 사용되는 모델의 표시를 포함하지 않을 수 있다. 예를 들어, UE는 gNB가 하나 이상의 참조 모델을 사용할 때 하나 이상의 성능 사양을 충족할 것으로 예상될 수 있다. 구현 세부 사항에 따라, 이것은 기계 학습 동작에 적합한 성능을 얻기 위해 노드에서 사용할 모델에 대한 배포 지침을 제공할 수 있다. 일부 실시 예에서, 예를 들어 사양의 일부로서 기계 학습 CSI 압축 태스크에 대해 하나 이상의 성능 요구사항이 설정될 수 있다. 참조 모델이 있는 프레임워크의 일부 실시 예에서, 노드는 대응하는 양자화기 및/또는 역양자화 함수(예를 들어, 근사 및/또는 미분 가능 양자화 및/또는 역양자화 함수)을 사용하여, 참조 모델을 포함한 모든 모델을 훈 련할 수 있으며, 임의의 모델은 또한 추가 훈련, 검증, 테스트, 추론 등을 위해 대응하는 양자화기 및/또는 역 양자화 함수를 사용할 수 있다. 최신 공유 값을 갖는 훈련 프레임워크 본 개시에 따른 일부 프레임워크에서, 노드 A는 초기 상태에 있을 수 있는 (예를 들어, 사전 훈련되고(예를 들 어, 오프라인 훈련되고), 훈련되지 않았지만 초기 값으로 구성되는 등) 모델 A로 시작할 수 있다. 노드 B는 초 기 상태에 있을 수도 있는 모델 B로 시작할 수 있다. 하나 또는 두 노드는 일정 기간 동안 각각의 모델을 훈련 할 수 있으며(훈련 주기 또는 반복이라고 할 수 있음), 하나 또는 두 노드는 훈련된 모델 값 및/또는 훈련된 모 델을 다른 노드와 공유하거나 공유하지 않을 수 있다. 일부 실시 예에서, 새로운 훈련 데이터 세트는 예를 들어 사이클의 시작 또는 끝에서 하나 또는 양쪽 노드에 직접 또는 간접적으로 제공될 수 있다. 노드 A와 노드 B는 예를 들어, 모델 교환 없이, 다른 노드에서 모델의 가중치에 대한 최신 지식으로 각자의 모델을 훈련할 수 있다. 제1 노드는 제2 노드(예를 들어, 기지국의 디코더)의 모델이 (예를 들어, 제2 노드에 의해 피드백되는) 최신 가 중치로 고정되어 있다고 가정하고 자신의 모델을 학습할 수 있다(예를 들어, UE는 인코더를 학습할 수 있음). 제1 노드는 자신의 모델을 훈련하고 가중치, 예를 들어 최대 횟수(예를 들어, 인코더의 경우 Ke 회) 업데이트한 다음에 업데이트된 모델 가중치를 제2 노드와 공유할 수 있다. 제2 노드에서도 동일한 절차가 구현될 수 있다. 구체적으로, 제2 노드가 제1 노드로부터 업데이트된 모델 가중치를 수신하면, 제2 노드는 모델을 훈련하고 그 가중치를 최대 횟수(예를 들어, 디코더의 경우 Kd 회) 업데이트할 수 있다, 제1 노드에서 모델의 모델 가중치가 제1 노드에서 공유된 최신 상태에서 고정된다고 가정한다. 그러면 제2 노드는 업데이트된 모델 가중치를 제1 노 드와 공유할 수 있다. 따라서, 제1 및/또는 제2 노드는 각각의 모델을 최대 횟수로 훈련한 다음 업데이트된 모 델 값을 다른 노드와 공유할 수 있다(이를 공유 주기 또는 반복이라고 할 수 있음). 이 프레임워크의 변형에서, 노드 중 하나 이상이 다른 노드와 모델 상태 정보(예를 들어, 가중치)를 공유한 후, 예를 들어 공유 주기가 끝날 때, 노드 중 하나 또는 둘 모두가 다른 공유 주기를 시작할 수 있다. 예를 들어, 두 노드는 다른 노드의 모델 값이 다른 노드가 공유하는 최신 값으로 고정되어 있다고 가정하여 모델을 훈련할 수 있다. 특정 시점에서 또는 특정 수의 훈련 주기가 (예를 들어, 다른 공유 주기의 끝에서) 제1 및/또는 제2 노드에 의해 수행된 후, 하나 또는 두 노드 모두 학습을 중지하고 최신 학습 모델을 서로 공유할 수 있다. 일부실시 예에서, 초기에, 공유 모델(예를 들어, 오프라인 학습, 핸드 쉐이킹 등을 통해 초기화될 수 있는 완전 공 유 모델)은 최근 공유 가중치의 초기 값으로 사용될 수 있다. 도 10은 본 개시에 따른 최신 공유 값으로 모델을 훈련시키는 방법의 예시적인 실시 예를 도시한다. 설명을 위 해, 도 10에 도시된 방법은 CSI에 대한 인코딩 모델을 갖는 UE 및 CSI에 대한 디코딩 모델을 갖는 기지국의 컨 텍스트에서 설명될 수 있지만, 원리는 임의의 유형의 노드 및/또는 물리 계층 정보에 적용될 수 있다. 도 10을 참조하면, 제1 공유 주기(1035-1)의 시작에서, 인코더 모델은 초기 상태 e0에 있을 수 있으며, 디코더 모델은 공유 포인트(1036-0)에 도시된 바와 같이 초기 상태 d0에 있을 수 있다. 초기 상태(e0,d0)의 인코더 및 디코더 모델은 모두 UE 및 기지국에 제공될 수 있다. 따라서 UE와 기지국은 모두 동일한 초기 상태에서 인코더 및 디코더 모델로 시작한다. UE는 다음에 M회의 훈련 사이클을 수행할 수 있다(예를 들어, 디코더 모델이 초기 상태 d0에서 유지되는 동안 인코더를 M회 훈련할 수 있음). UE가 M회의 훈련 사이클을 수행하는 동안, 기지국은 N회의 훈련 사이클을 수행할 수 있다(예를 들어, 인코더 모델이 초기 상태 e0에서 유지되는 동안 인코더를 N회 훈련한다). 예를 들어, M 번째 훈련 사이클 이후에 UE의 인코더 및 디코더 모델이 상태(eM,d0)를 가질 때까지, UE에 의한 제 1 훈련 주기 후 UE의 인코더 및 디코더 모델이 상태(e1,d0)를 가질 수 있고, UE에 의한 제2 훈련 주기 후 UE의 인코더 및 디코더 모델이 상태(e2,d0)를 가질 수 있는 등이다. 유사하게, N 번째 훈련 사이클 이후에 기지국의 인코더 및 디코더 모델은 상태(e0,dN)를 가질 때 까지, 기지국에 의한 제1 훈련 주기 후 기지국의 인코더 및 디코더 모델이 상태(e0,d1)를 가질 수 있고, 기지국에 의한 제2 훈련 주기 후 기지국의 인코더 및 디코더 모델이 상태(e0,d2) 등을 가질 수 있는 등이다. 공유 주기(1035-1)의 종료시 공유 지점(1036-1)에서, UE는 훈련된 인코더 모델을 기지국에 보낼 수 있고, 기지 국은 훈련된 디코더 모델을 UE에 보낼 수 있다. 따라서, UE와 기지국 모두 상태(eM,dN)를 갖는 인코더 및 디코더 모델을 가질 수 있다. 일부 실시 예에서, UE 및/또는 기지국은 이 시점에서 훈련을 중지하고 추론을 위해 훈련된 인코더 및 디코더 모 델을 사용하기 시작할 수 있다. 그러나, 일부 다른 실시 예에서, UE 및/또는 기지국 중 하나 또는 둘 모두는 다 른 공유 사이클(1035-2)을 시작할 수 있다. 예를 들어, UE는 다음에 디코더 모델이 상태 dN에 남아 있는 동안 인코더를 P회 훈련함으로써 P회 훈련 사이클을 수행할 수 있고, 기지국은 인코더 모델이 상태 eM에 유지되는 동 안 디코더를 Q회 훈련함으로써 Q회 훈련 사이클을 수행할 수 있다. 공유 주기(1035-2)의 종료시 공유 지점(1036-2)에서, UE는 훈련된 인코더 모델을 기지국에 보낼 수 있고, 기지 국은 훈련된 디코더 모델을 UE에 보낼 수 있다. 따라서, UE와 기지국 모두는 상태(eP,dQ)를 갖는 인코더 및 디코 더 모델을 가질 수 있다. UE 및/또는 기지국은 공유 사이클의 수와 공유 사이클당 훈련 사이클의 수를 수행할 수 있다. 도 10에 도시된 실시 예의 특별한 경우는 M≫N, 또는 N≫M이든, M 또는 N=0일 때이다. 예를 들어, N=0 및 M>0인 경우, 기지국은 공유 사이클 동안 디코더 모델을 업데이트하지 않을 수 있다(예를 들어, 임의의 훈련 사이클을 수행하지 않을 수 있음). 그러나 UE는 기지국과 공유하기 전에 인코더를 M회 훈련할 수 있다. 유사하게, M=0 및 N>0일 때, UE는 인코더 모델을 업데이트하지 않을 수 있는 반면 기지국은 디코더 모델을 UE와 공유하기 전에 N 회 업데이트할 수 있다. 구현 세부 사항에 따라, 이러한 특별한 경우 중 하나 이상은 예를 들어 노드 중 하나에 문제가 있거나 노드에서 온라인 훈련을 위한 훈련 데이터 세트를 얻을 수 없는 경우에 유용할 수 있다. 그러한 상황에서, 훈련 데이터에 대한 액세스(또는 더 준비된 액세스)가 있는 노드는 온라인 훈련을 계속할 수 있으며, 이를 통해 훈련을 계속하는 노드가 훈련 데이터에 대한 액세스가 없거나 제한된 다른 노드에 훈련된 모델을 제 공하는 것을 가능하게 할 수 있다. 특별한 경우는 교차 및/또는 교대의 방식으로 수행될 수도 있다. 예를 들어, 두 노드는 변수 M 또는 N 중 하나 가 0인 상태에서 시작할 수 있고 다른 변수는 0보다 클 수 있다. 해당 모델이 있는 모델이 0이 아닌 변수에 의 해 결정된 횟수만큼 업데이트되고 다른 노드와 공유되면, 0이 아닌 변수는 0 값을 가질 수 있지만 다른 변수는 0이 아니다. 이 프로세스는 M과 N이 교대로 0 값을 취하면서 계속될 수 있다. 이러한 교차되는 훈련 절차에 의하면 제1 노드(예를 들어, UE 또는 gNB)는 제2 노드에서의 모델이 고정된 동안 자신의 모델(예를 들어, 인코더 또는 디코더)을 여러번 훈련할 수 있다. 그 다음에, 제1 노드가 훈련된 모델을 제2 노드와 공유한 후, 제2 노드 는 제1 노드의 모델이 고정된 동안 그 모델을 여러번 학습할 수 있는 등이다. 일부 실시 예에서, 0이 아닌 변수의 값은 훈련된 모델 쌍의 성능에 영향을 미칠 수 있다. 예를 들어, 공유 지점 간의 시간이 상대적으로 크면, 훈련된 모델(eM,dN)은 예를 들어, 각 노드가 다음 공유 지점에서 공유될 모델과 크게 다를 수 있는 다른 쪽의 모델 가중치를 가정하여 학습하고 있는 경우, 상대적으로 성능이 좋지 않을 수 있 다. 예를 들어, 도 10에 도시된 실시 예에서, 기지국은 가중치 e0을 갖는 인코더를 가정하여 자신의 디코더를 훈련할 수 있고, 나중에 훈련된 디코더를 e0로부터 상당히 발산할 수 있는 새로운 인코더 모델 eM과 페어링할 수 있다. 따라서, 일부 실시 예에서 비교적 높은 빈도로 모델을 공유하는 것은 훈련된 모델의 성능을 향상시킬 수 있다. 본 명체서에 개시된 임의의 프레임워크에서, 노드는 대응하는 양자화 및/또는 역양자화 함수(예를 들어, 근사 및/또는 미분 양자화 및/또는 역양자화 함수)을 사용하여 참조 모델을 포함한 모든 모델을 훈련할 수 있으며, 임의의 모델은 또한 추가 훈련, 검증, 테스트, 추론 등을 위해 대응하는 양자화 및/또는 역양자화 함수를 사용 할 수 있다. 본 명세서에 개시된 임의의 프레임워크로, 하나 이상의 노드는 수집된 훈련 데이터 및/또는 데이터 세트(예를 들어, 채널 추정, 프리코딩 행렬 등)를 하나 이상의 모델을 훈련할 수 있는 다른 장치로 전송할 수 있다. 예를 들어, UE 및/또는 기지국은 수집된 온라인 훈련 데이터 및/또는 하나 이상의 모델을 업로드된 훈련 데이터를 사 용하여 모델 중 하나 이상을 훈련하고 하나 이상의 훈련된 모델을 UE 및/또는 기지국에 다운로드할 수 있는 서 버(예를 들어, 클라우드 기반 서버)에 업로드할 수 있다. 본 명세서에 개시된 프레임워크 중 임의의 것은 제1 유형의 노드가 다른 유형의 노드에 대한 모델을 훈련시키고 훈련된 모델을 제2 유형의 노드의 다수의 인스턴스와 공유할 수 있도록 수정될 수 있다. 예를 들어, 기지국은 그 디코더에 대한 인코더를 훈련할 수 있고 훈련된 인코더를 다수의 UE와 공유할 수 있다. UE 중 하나 이상은 공유 인코더를 적용하여 UE에서 CSI를 압축하고/하거나 추가 온라인 훈련을 위해 공유 인코더를 사용할 수 있다. 더욱이, 본 명세서에서 개시된 프레임워크 중 임의의 것은 노드 중 하나가 기지국이 아닌 시스템에서 구 현될 수 있으며, 예를 들어 사이드링크 통신을 위해 구성된 2개의 UE 또는 다른 피어 디바이스가 있다. 그러한 구현에서, UE는 자신의 인코더에 대한 디코더를 훈련하고 훈련된 디코더를 직접 추론 및/또는 추가 온라인 훈련 을 위한 (예를 들어, 가중치의) 초기 값의 소스로 사용할 수 있는 하나 이상의 다른 UE와 훈련된 디코더를 공유 할 수 있다. 모델 공유 메커니즘 일부 실시 예에서, 노드는 하나 이상의 업링크 및/또는 다운링크 채널, 신호 등과 같은 임의 유형의 통신 메커 니즘을 사용하여 모델, 가중치 등을 전송할 수 있다. 예를 들어 인코더 모델의 공유를 트리거하면, UE는 인코더 모델 및/또는 가중치를 gNB에 전송하기 위해 하나 이상의 MAC 제어 요소(MAC CE) PUSCH를 사용할 수 있다. 유사 하게, gNB는 하나 이상의 MAC CE PDSCH를 사용하여 하나 또는 다수의 UE에서 디코더 모델 및/또는 가중치를 전 송할 수 있다. 구현 세부 사항에 따라, 전체 가중치 세트를 공유하게 되면 모델이 상대적으로 클 수 있고 공유를 위해 상대적 으로 많은 양의 다운링크 및/또는 업링크 자원을 소비할 수 있기 때문에 비효율적일 수 있다. 일부 실시 예는 모델 북으로 지칭될 수 있는 양자화된 모델의 하나 이상의 세트를 설정할 수 있다. 노드가 모델 을 학습시킬 때, 공유가 요청되면 노드는 모델 북에 있는 양자화된 모델 중 하나에 모델을 매핑할 수 있다. 하 나 이상의 모델 북은 노드 간에 일반적으로 공유될 수 있다. 모드를 보내는 것보다, 노드는 모델 북에 매핑된 모델의 인덱스를 보낼 수 있다. 구현 세부 사항에 따라 모델 공유와 관련된 통신 자원이 줄어들 수 있다. 일부 실시 예에서, 모델에 대한 매개변수의 세트가 알려지면, 훈련의 최종 결과가 결정적으로 알려질 수 있다. 예를 들어, 훈련 세트, 초기 가중치를 결정하는 초기 랜덤 시드, 최적화 매개변수(예를 들어, 완전 히 정의된 최적화 매개변수) 및/또는 훈련 절차가 주어지면, 특정 수의 훈련 에포크(예를 들어, 훈련 주기)의 종료시 훈련된 모델은 고유하게 결정될 수 있다. 이러한 매개변수는 예를 들어 최소 기술 매개변수로 지칭될 수 있다. 최소 기술의 크기가 모델에 대한 가중치의 크기보다 작으면, 노드는 가중치가 아닌 최소한의 설명 매개변 수를 공유할 수 있다. 구현 세부 사항에 따라, 이것은 공유 모델과 관련된 통신 오버헤드를 줄일 수 있다.일부 실시 예에서, 모델의 하나 이상의 값(예를 들어, 노드에서 CSI 인코딩 및/또는 결정 모델의 가중치)은 벡 터 W(예를 들어, 가중치 요소의 벡터)에 배열될 수 있다. 전용 압축 자동 인코더 모델(예를 들어, 인코더 및 디 코더 모델 쌍)은 한 노드의 인코더 및 다른 노드의 디코더로 W를 압축하도록 훈련될 수 있다. CSI 모델의 공유 가 트리거 및/또는 요청되면, 노드는 CSI 모델의 벡터 W를 구성하고 이를 모델 압축 인코더로 인코딩하고 인코 딩된 벡터를 다른 노드로 보낼 수 있다. 다른 노드는 모델 압축 디코더를 사용하여 가중치 벡터 W를 복구할 수 있다. 구현 세부 사항에 따라 공유 모델과 관련된 통신 오버헤드를 줄일 수 있다. 온라인 훈련 처리 시간 노드가 모델의 온라인 훈련을 수행할 수 있는 실시 예에서, 노드는 훈련을 수행하기 위한 자원 허용(예를 들어, 처리 시간, 처리 자원 등의 허용)을 제공받을 수 있다. 이러한 허용은 노드에 의해 수집될 수 있는 온라인 훈련 데이터 세트(예를 들어, 노드에 의해 수행된 측정에 기초한 채널 추정) 또는 RRC가 구성(또는 복원)되거나 MAC- CE가 활성화될 수 있는 온라인 훈련 데이터 세트에 의한 훈련을 위해 제공될 수 있다. 자원 처리 시간 허용은 예를 들어 업데이트된 모델을 다른 노드와 공유하기 위해 노드가 업데이트를 완료할 것으로 예상되기 전에 노드 가 온라인 훈련 데이터 세트를 사용하여 모델을 업데이트하기에 충분한 시간을 가질 수 있도록 보장할 수 있다. 그러나 일부 실시 예에서, 노드는 처리 후 훈련된 모델을 공유할 것으로 예상되는지와 관계없이 처리 시간 여유 가 제공될 수 있다. 예를 들어, UE가 채널 추정치를 계산함으로써 온라인 훈련 데이터 세트를 수집할 수 있는 실시 예에서, UE는 온 라인 훈련 세트에 사용된 최신 CSI-RS의 마지막 심볼의 종료부터 NAIML,upadte 심볼로 결정되는 (예를 들어, 인코더 모델을 업데이트하기 위한) 일정량의 시간을 제공받을 수 있다. UE가 업데이트된 모델을 다른 노드(예를 들어, gNB)에 보고하도록 구성된 경우, UE는 훈련 세트의 최신 CSI-RS의 마지막 심볼부터 NAIML,report 심볼 보다 이전에 모델을 gNB에 보고할 것으로 예상되지 않는다. 다른 예로, UE가 UE에 대해 RRC 구성(또는 복원)되거나 MAC-CE 활성화된 온라인 훈련 데이터 세트를 사용하여 인코더의 온라인 훈련을 수행할 수 있는 실시 예에서, UE는 대응하는 RRC (재)구성이 완료되거나 MAC-CE 활성화 명령이 수신되는 최신 심볼부터 N개의 심볼 보다 이전에 인코더를 업데이트 및/또는 보고할 것으로 예상되지 않 을 수 있다. 도메인 지식을 기반으로 한 사전 처리 압축을 위해, 기계 학습 인코더는 입력 신호를 수신하고 디코더가 입력 신호를 복원하는 데 사용할 수 있는 출 력 특징 세트를 생성할 수 있다. 최대 압축으로, 출력 함수는 서로 독립적일 것으로 예상될 수 있으며, 그렇지 않으면 더 압축될 수 있다. 한 쌍의 기계 학습 모델이 입력으로부터 특징 벡터를 생성하고 특징 벡터로부터 입력을 복원할 수 있지만, 본 개시에 따른 일부 실시 예에서, 생성 모델로의 입력 및/또는 복원 모델로부터의 출력에 대해 하나 이상의 사전 처리 및/또는 사후 처리 동작이 수행될 수 있다. 구현 세부 사항에 따라, 이것은 모델 중 하나 또는 둘 모두의 처리 부담 및/또는 메모리 사용량을 감소하고, 모델 중 하나 또는 둘 모두의 정확도 및/또는 효율성을 개선하고, 및/또는 이와 유사한 것과 같은, 하나 이상의 잠재적인 이점을 제공할 수 있다. 일부 실시 예에서, 사전 처리 및/또는 사후 처리는 입력 신호의 도메인 지식에 기초할 수 있다. 일부 실시 예에 서, 사전 처리 및/또는 사후 처리는 구현 세부 사항에 따라 인코더에 대한 처리 부담을 줄일 수 있는 도메인 지 식으로부터의 보조 정보를 인코더에 제공할 수 있다. 예를 들어, 인코더에 의해 압축되어야 하는 벡터가 비교적 작은 변동을 갖는 저역 통과 신호로 특징지어질 수 있는 경우, 이산 푸리에 변환(DFT) 및/또는 역 DFT(IDFT)가 벡터의 주파수 도메인 표현을 분석하기 위해 수행될 수 있다. DFT 벡터의 DC 성분이 다른 성분보다 큰 경우(예 를 들어, 상당히 큰 경우), 신호는 변동이 낮으므로, 인코더/디코더 쌍에 대한 부담을 줄이기 위해 인코더에 의 한 압축 전에 사전 처리(디코더에 의한 압축 해제 후에 사후 처리)될 수 있는 것을 나타낼 수 있다. 일부 실시 예에서, DFT 및/또는 IDFT와 같은 변환 및/또는 역변환을 수행하게 되면 입력 벡터의 요소들 간의 상 관 수준에 대한 더 명확한 이해를 갖는 기계 학습 모델을 제공할 수 있다. 예를 들어, 일부 실시 예에서 (예를 들어, 본원에 개시된 임의의 프레임워크를 사용하여), CSI 행렬은 변환 (예를 들어, DFT/IDFT, 이산 코사인 변 환(DCT)/역 DCT(IDCT) 등)을 입력의 전체 또는 일부, 예를 들어 다른 CSI-RS 포트에 적용할 수 있는 사전 처리 기에 입력될 수 있다. 변환된 신호는 인코더에 입력되고 압축될 수 있다. 디코더 측에서, 디코더의 출력은 복원 된 입력 신호를 생성하기 위해 (예를 들어 사후 처리기로 구현될 수 있는) 사전 처리기 변환의 역 연산자에 적용될 수 있다. 도 11은 본 개시에 따른 사전 처리 및 사후 처리를 갖는 2-모델 훈련 방식의 예시적인 실시 예를 도시한다. 일 부 측면에서, 도 11에 예시된 실시 예는 도 3에 예시된 실시 예와 유사할 수 있고, 유사한 구성 요소는 동일한 숫자로 끝나는 참조 지정자로 식별될 수 있다. 하지만, 도 11에 도시된 실시 예는 사전 처리기 및 사후 처리기를 포함할 수 있다. 사전 처리기는 생성 모델에 적용되기 전에 훈련 데이터 에 임의의 유형의 변환을 적용할 수 있다. 유사하게, 사후 처리기는 최종 복원된 훈련 데이터 를 생성하기 위해 임의의 유형의 역변환(예를 들어, 사전 처리기에 의해 적용된 변환의 역)을 복원 모델의 출력에 적용할 수 있다. 일부 실시 예에서, 모델(1103 및 1104)을 훈련하기 위한 손실 함수는 실선(1139 및 1140)으로 도시된 바 와 같이 생성 모델의 입력과 복원 모델의 출력 사이에 정의될 수 있다. 그러나 일부 실시 예에서, 손실 함수는 점선(1141 및 1142)으로 도시된 바와 같이 사전 처리기의 입력과 사후 처리기의 출력 사이에 정의될 수 있다. 모델(1103, 1104)이 도 11에 도시된 바와 같이 훈련되면, 추론에 사용될 수 있다. 사전 처리 및/또는 사후 처리와 관련된 원리는 특정 구현 세부사항으로 제한되지 않지만, 본 발명의 원리를 설 명하기 위해, 도메인 지식에 기반한 사전 처리 및 사후 처리 CSI 행렬을 위한 방식의 예시적인 실시 예는 다음 과 같이 구현될 수 있다. Nrx×Ntx 크기의 채널 행렬을 사용하여, RX 및 TX 안테나의 각 쌍 (i,j)에 대해, 시간 및 주파수 윈도우 내의 모든 자원 요소(RE)에 대한 쌍에 대응하는 채널 요소는 크기 M×N의 결합 행렬 Hi,j를 얻 기 위해 연결될 수 있으며, 여기서 M 및 N은 윈도우의 CSI-RS의 부반송파 및 직교 주파수 분할 멀티플렉싱 (OFDM) 심볼의 수일 수 있다. 일부 실시 예에서, 행렬은 복소수로 가정될 수 있다. 사전 처리 방식의 예시적인 실시 예에서, Hi,j는 예를 들어 DFT 행렬을 사용하여 변환될 수 있다. Ufreq 및 Utime이 각각 M×M 및 N×N DFT 행 렬인 경우, 행렬 Hi,j는 다음과 같이 Xi,j로 변환될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이것은 Hi,j의 지연-도플러 표현(DDR)으로 지칭될 수 있다. 행렬 Hi,j는 다음과 같이 DDR에서 복원될 수 있다: 수학식 3"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "일부 실시 예에서, DDR 변환을 사용하면 희소 X 행렬이 생성될 수 있으며, 이는 차례로 학습 및 추론 복잡성을 완화할 수 있다. 일부 실시 예에서, 사전 처리 및/또는 사후 처리 변환을 사용하면 원래 훈련 세트가 해당 DDR 행렬을 변환할 수 있다. 이러한 실시 예에서, CSI 압축은 변환된 훈련 세트를 압축할 수 있는 있다. UE 측에서 사전 처리(예를 들 어, DDR 변환)가 수행될 수 있는 반면, 사후 처리(예를 들어, H를 복구하기 위한 DDR의 역)는 gNB 측에서 수행 될 수 있다. 일부 실시 예에서, 손실 함수는 (예를 들어, 인코더에 대한 변환된 행렬 입력과 도 11에 예시된 바와 같이 디코 더의 변환된 행렬 출력 사이에서) 변환된 행렬에 기초하여 정의될 수 있다. 일부 실시 예에서, 행렬 H는 각 공 간 채널, 예를 들어 각 전송 안테나(포트) 및 각 수신 안테나(포트) 쌍에 대한 시간 및/또는 주파수 도메인에서 개별 CSI 행렬의 합집합에 기초하여 구성될 수 있다. 하나 또는 여러 개의 모델이 각 공간 채널에 대해 훈련되 고 테스트될 수 있다. 일부 실시 예에서, H는 RE의 채널 행렬에 기초하여 구성될 수 있고, 예를 들어, 각각의 행렬은 Nr×Nt의 크기를 가질 수 있으며, 이 때 Nr 및 Nt는 각각 UE에서의 수신 안테나의 개수 및 gNB에서의 전 송 안테나의 개수일 수 있다.CSI 행렬 공식 일부 실시 예에서, UE가 압축할 수 있는 RE 또는 RE의 그룹의 CSI 정보는 CSI 행렬로 지칭될 수 있다. 다중입력 다중출력(MIMO) 채널을 분석한 결과, 용량 분포는 전송 안테나에 걸쳐 가능한 다른 전력 할당을 갖는 가우스 분 포일 수 있다. 채널 행렬이 Hr×t=UΣVH로서 분해되면, 용량 달성 분포는 먼저 를 설정하고 (여기서 x는 평 균과 단위 분산이 0인 독립적으로 동일한 확률 분포되는 가우스 랜덤 벡터) 다음에 수학식 4"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "의 각 요소를 물 채우기 알고리즘에 의해 주어진 전력 할당으로 곱하여 획득된다. i번째 채널에 대한 전력 할당 은 Pi, i=1,…, t일 수 있으며, 여기서 Pi는 채널 행렬 H의 특이값 분해로부터 획득될 수 있다. 그러므로, gNB에 서 사용되는 정보(예를 들어, gNB에서 요구하는 전체 정보)는 오른쪽 특이값 행렬 V와 특이값 자체 모두일 수 있다. 따라서, 일부 실시 예에서, CSI 행렬은 다음 중 임의의 하나 이상으로 공식화(예를 들어, 정의)될 수 있 다: (a) CSI 행렬은 채널 행렬 H로 공식화될 수 있다; (b) CSI 행렬은 V와 특이값의 연결로 공식화될 수 있다; 및/또는 (c) CSI 행렬은 행렬 U로 공식화될 수 있다. 일부 실시 예에서, UE는 RRC (재)구성, MAC-CE 명령을 통해 또는 DCI를 통해 동적으로 상술된 임의의 CSI 행렬 을 보고하도록 구성될 수 있다. CSI 행렬이 (b)(예를 들어, V와 특이값의 연결)에 따라 공식화되는 실시 예에서, UE는 또한 특이값만 보고하도록 구성될 수 있다. 모델 훈련을 위해, UE가 특정 CSI 행렬을 보고하도록 구성될 때 훈련 세트 및/또는 손실 함수는 적용 가능한 CSI 행렬에 기초하여 공식화될 수 있다. 예를 들어, UE가 V를 보고하도록 구성될 때, 훈련 세트는 추정된 채널 행렬들로부터 획득된 V 행렬들을 포함할 수 있고, 손실은 인코더에 입력된 V 행렬 및 디코더의 출력에서 복원된 V 행렬에 기초하여 공식화될 수 있다. 노드 능력 본 명세서에 공개된 프레임워크 중 하나의 구현은 예를 들어, 새로운 훈련 데이터를 저장하고, 노드 간에 모델 을 공유하고, 특정 유형의 신경망 아키텍처(예를 들어, 모델에 대한 CNN 또는 RNN)를 훈련 및/또는 적용하기 위 해, 메모리, 처리 및/또는 통신 자원와 같은 자원의 사용이 포함될 수 있다. UE와 같은 다른 노드는 신경망을 구현하기 위한 다른 능력을 가질 수 있다. 예를 들어, UE는 CNN을 지원할 수도 있고 지원할 수도 있지만 RNN은 지원하지 않을 수 있다. 일부 실시 예에서, UE는 특정 유형, 예를 들어, CNN, RNN 등과 같은 네트워크 유형의 신경망 아키텍처를 지원하기 위한 능력 및/또는 인코더 모델을 적용하기 위한 제한 및 능력을 반영하는 임의의 다른 측면을 보고할 수 있다. 일부 실시 예에서, 노드(예를 들어, UE)는 다음 중 임의의 수를 포함할 수 있는 목록을 사용하여 자신의 능력 및/또는 제한을 보고할 수 있다: (a) 하나 이상의 네트워크 유형, 예를 들어 CNN, RNN, 특정 유형의 RNN, 게이 트 순환 유닛(GRU), 장기 기억 장치(LSTM), 변환기 등; (b) 모델의 크기, 예를 들어 다수의 계층, CNN의 다수의 입력 및/또는 출력 채널, RNN의 다수의 은닉 상태 등과 관련된 하나 이상의 측면; 및/또는 (c) 기타 유형의 구 조적 제한. 보고된 능력에 따라, 노드(예를 들어, UE)는 노드의 보고된 제약 조건을 위반하고/하거나 노드의 선언된 능력을 초과하여 능력을 요구하는 인코더 모델을 훈련하거나 테스트할 것으로 예상되지 않을 수 있다. 일부 실시 예에 서, 이는 적용 가능한 프레임워크 및/또는 모델의 훈련/추론 위치에 관계없이 보장될 수 있다. 예를 들어, gNB 가 인코더 및 디코더를 사전 훈련시키고 인코더 및/또는 디코더를 UE와 공유할 수 있도록 프레임워크가 구현되 는 경우, UE는 인코더 모델이 자신의 능력을 위반할 것으로 예상하지 않을 수 있다. 또 다른 예로, 인코더 및 디코더의 하나 또는 여러 쌍이 오프라인으로 훈련되고 해당 사양(예를 들어, NR 사양)에 지정된 경우, UE는 해 당 모델이 자신의 능력을 위반할 것으로 예상하지 않을 수 있다. 일부 실시 예에서, UE는 시그널링을 통해 하나 이상의 모델을 활성화하는 능력을 보고할 수 있고 어떤 특정 인코더/디코더 쌍, 또는 그것이 지원할 수 있는 개별 인코더 또는 디코더를 선언할 수 있다. 그 다음, gNB는 어떤 인코더/디코더 쌍이 UE에 적용 가능한지를 UE에 지시할 수 있다. 표시는 예를 들어, 시스템 정보, RRC 구성, DCI의 동적 시그널링 등에 의해 제공될 수 있다. 온라인 훈련을 통한 조정 일부 프레임워크에서, UE와 같은 노드는 예를 들어, 새로운 훈련 데이터(예를 들어, 샘플)를 즉석에서 수집하거 나 오프라인 프로비저닝 및 하나 이상의 모델 업데이트를 기반으로 하여, 인코더 모델 또는 인코더 모델과 디코 더 모델 모두를 온라인으로 훈련할 것으로 예상될 수 있다. 노드가 인코더 모델만 업데이트하면 손실 함수도 디 코더 가중치에 따라 달라질 수 있으므로, 인코더 모델 튜닝 및/또는 최적화는 디코더 가중치 및/또는 모델에 따 라 달라질 수도 있다. 그러한 구현에서, 인코더가 gNB 측에서 사용될 수 있더라도, 노드는 디코더 모델의 제한 을 처리하는 능력을 선언할 수도 있다. 이러한 제한 사항은 다음과 같이 하나 이상 적용될 수 있다: 하나 이상의 온라인 훈련 기능 및/또는 미세 조정은 노드에 의해 능력으로 선언될 수 있다; 온라인 훈련을 지원 하는 능력을 보고하는 노드는 인코더 모델에 대해 지원되는 구조에 대한 제한을 추가로 보고할 수 있다; 온 라인 훈련을 지원하는 능력을 보고하는 노드는 디코더 모델에 대해 지원되는 구조에 대한 제한을 추가로 보고할 수 있다; 및/또는 인코더 및 디코딩 쌍을 포함하는 여러 모델이 사양에 지정된 경우, 노드는 인코더 및 디 코더 쌍 또는 노드가 지원할 수 있는 개별 인코더 및/또는 디코더를 나타내는 능력을 선언할 수 있다. 다수 쌍의 모델 일부 실시 예에서, 다수 쌍의 모델(예를 들어, 인코더/디코더 쌍)은 2개의 노드(예를 들어, UE 및 gNB)에서 동 작(예를 들어, 동시 동작)을 위해 훈련 및/또는 배치될 수 있다. 쌍은 a) 인코더와 디코더 모두, b) 인코더만, 또는 c) 디코더만 서로 다를 수 있다. 일부 실시 예에서, 여러 쌍의 모델은 다양한 채널 환경을 처리하도록 지 정될 수 있는 다양한 경우를 처리하도록 구성(예를 들어, 최적화)될 수 있으며 이는 차례로 훈련 및/또는 테스 트 데이터 세트의 다른 분포를 초래할 수 있다. 예를 들어 훈련 데이터의 다른 차원을 수용하기 위해 여러 쌍의 모델이 사용될 수 있다. 예를 들어, CSI 행렬의 차원은 CSI-RS 포트의 개수에 따라 결정될 수 있다. 일부 실시 예에서, UE가 상이한 차원을 갖는 제1 CSI 행렬 H1 및 제2 행렬 H2를 보고하는 경우, 단일 인코더 및 디코더 쌍은 서로 다른 크기의 행렬을 처리하는 데 사용될 수 있다. 그러한 실시 예에서 인코더 및 디코더는 다음과 같이 훈련될 수 있다. 인코더에 입력되는 행렬은 UE와 gNB 사이에서 일반적으로 이해될 수 있는 구성에서 0을 추가함으로써 고정된 크기를 갖도록 복원될 수 있다. 따 라서, 훈련 세트는 행렬을 하나의 고정된 행렬 크기로 변환하기 위해 위에서 설명된 바와 같이 0을 추가함으로 써 수정될 수 있는 상이한 크기의 행렬을 원래 포함할 수 있다. 통신 메커니즘은 예를 들어 UE에 의한 보고에서, 요청되는 CSI 행렬의 크기에 대해 gNB와 UE가 동일한 이해를 공유할 수 있도록 구현될 수 있다. 구현 세부 사항에 따라, 행렬 재차원화 기술이 모든 행렬 크기에 대해 작동할 수 있다. 대안적으로, 또는 추가적으로, 다수의 모델 쌍(예를 들어, 인코더/디코더 쌍)이 훈련될 수 있고, 여기서 상이한 모델 쌍은 상이한 CSI 행렬 크기를 처리하도록 구성될 수 있다. 일부 실시 예에서, 그리고 구현 세부사항에 따라, 복잡성을 증가시키지 않으면서 다수 쌍의 모델을 구현할 수 있다. 예를 들어, 다수 쌍의 모델이 있는 경우, CSI 보고가 특정 수의 CSI-RS 포트에 해당하는 CSI 행렬을 포함 하면, CSI 보고를 계산하기 위한 추론 시간은 단일 쌍보다 다중 쌍에서 더 작을 수 있다. 더구나, 각 RRC 구성 또는 MAC-CE 활성화가 특정 쌍에 해당하는 특정 경우에 대한 CSI 보고를 포함하면, UE는 UE 컨트롤러에 다른 모 델 중 하나 이상을 유지하면서 적용 가능한 모델을 모뎀에 로드할 수 있다. 구현 세부 사항에 따라 모뎀 내부 메모리 사용량을 줄일 수 있다. 다중 쌍을 갖는 실시 예에서, 다음 구성 중 임의의 것에 따라 상이한 쌍이 분류 될 수 있다: (a) 모델의 각 쌍은 특정 CSI 행렬 크기를 처리하도록 구성될 수 있다. 예를 들어, 한 쌍의 모델은 UE에 의해 특정 수의 수신 안테나와 연관되고 또한 특정 수의 포트를 갖는 CSI-RS에 기초하여 추정된 CSI 행렬 을 수신할 수 있다. UE는 자신의 수신 안테나 수를 하나의 보고로 또는 다른 수의 CSI-RS 포트에 대해 별도로 gNB에 보고할 수 있다. (b) 모델의 각 쌍은 훈련 및/또는 테스트 데이터 세트에 대해 상이한 분포를 처리하도록 구성될 수 있다. (c) 모델의 각 쌍은 훈련 및/또는 테스트 데이터 세트에 대해 서로 다른 채널 환경을 처리하도 록 구성될 수 있다. 훈련 세트 연결 및 모델 쌍 구성 모델 쌍이 서로 다른 경우를 처리하도록 구성될 수 있는 실시 예에서, 노드(예를 들어, UE 또는 기지국)는 상이 한 훈련 데이터 세트, 예를 들어 특정 케이스 또는 모델의 쌍(예를 들어, 인코더/디코더 쌍)에 대한 상이한 훈 련 데이터 세트로 구성될 수 있다. 따라서, UE 및/또는 기지국은 상이한 훈련 데이터 세트, 예를 들어 상이한쌍에 대한 각각의 데이터 세트를 소유할 수 있다. 노드(예를 들어, UE 또는 gNB)에 대한 트리거링이 발생하면, 노드는 또한 어떤 쌍의 모델이 훈련되어야 하는지에 대해 신호를 받을 수 있다. 예를 들어, 온라인 훈련을 통해, gNB는 특정 쌍 모델의 훈련을 시작하도록 UE에 지시할 수 있다. 새로운 데이터 세트를 수집함으로써 즉석 에서 온라인 훈련이 수행되면, 예를 들어, CSI-RS 포트의 수를 통해 CSI-RS와 인코더/디코더 쌍 사이에 연관이 제공될 수 있다. 여러 쌍의 모델이 학습되고 추론 단계에서 배포할 준비가 되면, 노드(예를 들어, UE)는 채널 행렬을 인코딩하는 데 어느 쌍을 사용할지를 알아야 할 필요가 있다. 예를 들어, 각 쌍은 인코딩할 CSI 행렬에 대한 특정 차원과 연관될 수 있다. 차원은 인코더 모델에 대한 입력 차원이라고 할 수 있다. 일부 실시 예에서, UE는 다음과 같이 CSI 행렬을 인코딩하기 위해 사용할 모델 쌍을 결정할 수 있다. CSI-RS는 암시적으로 또는 명시적으로 한 쌍의 모델과 연관될 수 있다. UE는 CSI-RS와 관련된 모델 쌍을 사용하여 CSI 행렬을 인코딩한다. 암묵적인 연관성으 로, CSI-RS는 UE에서 CSI-RS 포트의 수 및/또는 수신 안테나의 수에 기초하여 특정 쌍에 매핑될 수 있다. 따라 서, CSI RS로부터 획득된 CSI 행렬의 차원이 쌍의 입력 차원과 동일한 경우 CSI-RS는 쌍으로 매핑될 수 있다. 다수의 쌍이 동일한 적격 입력 차원을 갖는 경우, 참조 쌍은 예를 들어 UE와 gNB 사이에 설정될 수 있는 규칙에 기초하여 선택될 수 있다. 명시적 연관과 함께, CSI 행렬이 보고되는 CSI-RS는 RRC를 통해 구성되거나 예를 들 어 쌍 인덱스를 사용하여, DCI에서 동적으로 표시될 수 있다. 위에 설명된 구현들 중 임의의 것에서, UE가 입력 차원이 다른 한 쌍의 모델을 통해 CSI 행렬을 보고하도록 신 호를 받는 경우, UE는 행렬의 크기를 입력 차원에 일치시키기 위해 0을 추가할 수 있다. 그러나, UE는 CSI 행렬 보다 작은 입력 차원을 갖는 모델 쌍을 사용하여 CSI 행렬을 보고하도록 신호 보내는 것을 예측하지 않을 수 있 다. 축소된 모델 크기로 압축 일부 실시 예에서, 한 쌍의 모델은 CSI 행렬을 압축하고/하거나 CSI 행렬 요소 간의 중복성 및/또는 상관을 활 용하기 위해 자동 인코더로 구성될 수 있다. RE별로 CSI 행렬이 보고되면, 상관은 상이한 쌍의 전송 안테나(예 를 들어, CSI-RS 포트)와 수신 안테나 사이의 상이한 경로들 간의 공간적 상관일 수 있다. 구현 세부 사항에 따 라, 이러한 상관관계의 양은 제한될 수 있고, 따라서 자동 인코더는 CSI 행렬을 충분히 압축하지 못할 수 있다. 일부 실시 예에서, 자동 인코더의 압축 능력은 공간 상관으로 지칭될 수 있는, CSI 행렬의 요소들 간의 상관 및 /또는 중복성의 양과 관련될 수 있다. 무선 채널은 또한 시간 및/또는 주파수 도메인에서 상관될 수 있기 때문 에, 시간 및/또는 주파수 상관도 존재할 수 있다. 그러므로, 다수의 OFDM 심볼 및/또는 다수의 자원 요소(RE), 자원 블록(RB) 또는 부대역에 대한 추정된 채널이 단일 훈련 샘플로서 입력될 수 있다. 예를 들어, 여러 RE에 해당하는 채널 행렬은 자동 인코더에 대한 입력으로 지정될 수 있다. 본 개시에 따른 하나의 그러한 방법에서, UE는 훈련 데이터 세트를 형성하기 위한 시간 및/또는 주파수 자원 번들링을 지정할 수 있는 구성으로 RRC를 통 해 구성될 수 있다. 구현 세부 사항에 따라, 자동 인코더의 압축 성능은 상이한 주파수 및/또는 시간 자원에 걸쳐 다중 RE에 대한 CSI를 압축함으로써 개선될 수 있다. 따라서, 다중 RE의 결합된 CSI 행렬은 시간 및 주파수 윈도우에서 입력될 수 있다. 결합된 CSI 행렬은 그 다음 윈도우에서 RE의 개별 CSI 행렬을 연결함으로써 획득될 수 있다. 구현 세 부 사항에 따라 결합된 CSI 행렬은 채널의 시간 및 주파수 평탄도로 인해 요소 간에 상당한 상관 관계를 가질 가능성이 더 높을 수 있다. 따라서 모델이 결합된 CSI 행렬을 입력으로 사용하면, 개별 RE 행렬에서 작업하는 여러 모델보다 더 높은 수준으로 압축할 수 있다. 일부 실시 예에서, UE는 결합된 CSI 행렬을 결정하기 위해 UE 가 채용할 수 있는 RE를 표시할 수 있는 시간 및/또는 주파수 윈도우 및 하나 이상의 구성으로 구성될 수 있다. 이러한 구성은 결합된 행렬을 얻기 위해 훈련 및/또는 테스트 단계 모두에서 사용될 수 있다. CSI 행렬의 하위집합을 통한 입력 크기 감소 일부 실시 예에서, 자동 인코더는 특정 시간 및 주파수 윈도우에서 상이한 RE의 CSI 행렬을 인코딩할 수 있다. 채널이 채널 행렬의 요소 간의 상관 관계가 존재하지 않거나 특정 도메인(예를 들어, 시간 또는 주파수)에서 강 하지 않도록 되어 있는 경우, CSI 행렬의 합집합의 요소 세트는 상대적으로 강한 하위집합 내 요소 상관 관계 및 상대적으로 약한 하위집합 간 요소 상관 관계를 갖는 하위집합으로 분할될 수 있다. 예를 들어, 자동 인코더 가 동일한 OFDM 심볼에서 4개의 RE의 4개의 CSI 행렬을 압축하는 경우, 행렬은 다음과 같이 표시될 수 있다.수학식 5"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "주파수 도메인의 상관관계가 강하고, 공간 도메인(즉, 한 행렬의 요소 간)에 상관관계가 거의 없거나 전혀 없는 경우, 자동 인코더는 길이 4의 벡터를 압축하도록 구성되고, 자동 인코더는 다음 하위 집합에 대해 네 번 적용 될 수 있다: 하위집합 1(a1,b1,c1,d1); 하위집합 2(a2,b2,c2,d2); 하위집합 3(a3,b3,c3,d3); 및 하위집합 4(a4,b4,c4,d4). 그 다음, CSI 행렬은 예를 들어 동일한 디코더를 사용하여 4개의 벡터를 복원함으로써 디코더에서 복원될 수 있 다. 위에서 언급한 바와 같이, 하위집합은 하나 이상의 도메인에서 하나 이상의 상관관계를 활용할 수 있도록 선택될 수 있다. 추가 설명을 위해 위의 예에서, 공간 영역의 요소 사이에 상관 관계가 있는 경우, 상술된 하위 집합 선택은 네트워크가 CSI 행렬을 추가로 압축하기 위해 상관 관계를 이용하는 것을 방지할 수 있다. 대조적 으로, 다음 하위 집합 선택을 통해 주파수 및 공간 영역 모두에서 상관 관계를 활용할 수 있다: 하위집합 1(a1,a2,b1,b2); 하위집합 2(c1,c2,d1,d2); 하위집합 3(a3,a4,b3,b4); 및 하위집합 4(c3,c4,d3,d4). 일부 실시 예에서, 다음 프레임워크는 이 접근 방식을 기반으로 Nfeatures 입력 차원을 사용하여 축소된 모델 크기 에 사용될 수 있다. UE는 동일하거나 상이한 OFDM 심볼 상에 있을 수 있고 시간 및/또는 주파수 윈도우 내 에 있을 수 있는 M개의 RE의 CSI 행렬을 보고하도록 구성될 수 있다. 각각의 CSI 행렬은 N개의 요소를 가질 수 있다. UE는 M×N개의 요소를 (M×N)/Nfeatures개의 하위집합으로 나눌 수 있다. 하위집합 선택을 위해 UE와 gNB 간에 공통 규칙이 설정될 수 있다. 자동 인코더(예를 들어, 단일 자동 인코더)를 사용하여 각 하위 집 합의 Nfeature 개의 요소를 압축 및 복구할 수 있다. 위에서 설명한 예시적인 하위집합에서, M=N=4 및 Nfeatures=4이 다. 자원 요소 선택을 통한 입력 크기 축소 결합된 입력 행렬의 크기를 줄임으로써 인코더 네트워크의 크기를 줄일 수 있다. 일부 실시 예에서, 예를 들어 동일한 차원의 CSI 행렬 H1 및 H2을 갖는 윈도우에 두 개의 RE가 있는 경우, 결합된 행렬의 크기는 (a) 개별적인 RE별 행렬의 특정 요소를 제거하는 것으로 감소될 수 있다. 결합된 행렬은 H1 또는 H2와 동일한 차원을 갖도록 구성될 수 있지만, H1 또는 H2에서 (i,j) 요소를 선택적으로 선택하는 것에 의해서 이루어진다. 대안적으로, 또 는 추가적으로, 결합 행렬의 크기는 (b) 윈도우의 특정 RE에 대한 CSI 행렬을 배제할 수 있는 행렬을 구성하는 것으로 감소될 수 있다. 이들 예는 2개의 RE 및 2개의 CSI 행렬을 갖는 윈도우가 예시된 표 1에 예시되어 있다. 접근 방식 (a)를 사용하 면 결합된 행렬이 표 1에서와 같이 구성될 수 있는 반면, 접근 방식 (b)에 의하면 결합된 행렬은 두 행렬 중 하 나를 선택하여 구성될 수 있다. 표 1"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "CSI-RS 포트의 수 및 훈련 세트Nport 포트를 갖는 CSI-RS와 UE에서 Nr개의 수신 안테나를 통한 수신으로부터 추정 된 채널 행렬은 Nr×Mport의 차원을 가질 수 있다. 자동 인코더를 사용하여 행렬에서 중복성을 제거할 수 있다.일부 실시 예에서, 중복 패턴을 식별하고/하거나 이를 제거한다는 것은, 훈련 세트가 예를 들어 포트 수가 다른 CSI-RS에 해당하는, 다른 차원의 행렬을 포함하는 경우, 더 어려울 수 있다. 따라서 일부 실시 예에서, 본 명세 서에 개시된 임의의 방법에 대한 훈련 세트는 동일한 차원의 행렬을 유일하게 또는 대부분 포함할 수 있고/있거 나 동일한 수의 CSI-RS 포트와 연관될 수 있다. 따라서, UE는 훈련 세트, 또는 훈련 데이터 세트 행렬의 차원과 다른 차원을 갖는 훈련 세트를 초래하는 CSI 보고 및 측정 구성으로 구성될 것으로 예상되지 않을 수 있다. UCI 포맷 본 명세서에 개시된 임의의 프레임워크로, 생성 모델(예를 들어, ML 인코더)의 출력은 UCI의 유형으로 간주될 수 있다(예를 들어, 인공 지능, 기계 학습(AIML) CSI로 지칭될 수 있음). 일부 실시 예에서, AIML CSI는 연관된 CSI-RS 자원 및 보고 설정과 함께 CSI 보고 및 측정 구성으로부터 획득될 수 있다. 일부 실시 예에서, AIML CSI 는 PUCCH 또는 PUSCH를 통해 gNB로 전송될 수 있다(예를 들어, Rel-15 동작에 이어). 따라서, 업링크 UCI의 일 종으로 물리 계층 정보에 대한 피드백 정보의 표현 포맷이 정해질 수 있다. 포맷은 예를 들어 UCI를 전송하는 데 사용되는 물리 채널의 유형에 따라 달라질 수 있는, 하나 이상의 유형의 코딩(예를 들어, 극성 코딩, 저밀도 패리티 체크(LDPC) 코딩 등)을 포함할 수 있다. 일부 실시 예에서, PUCCH로 업링크 UCI의 유형(예를 들어, AIML CSI)을 전송할 때는 극성 코딩을 사용할 수 있는 반면, PUSCH로 전송할 때는 LDPC 코딩을 사용할 수 있다. 또한, CSI는 코딩 전에 양자화될 수 있다. 따라서 AIML CSI는 비트스트림(0 및 1)으로 양자화되고 극성 코더 또 는 LDPC 코더에 입력될 수 있다. 다양한 네트워크 벤더에 대한 적응성 UE가 네트워크에 접속할 때, 어떤 네트워크 벤더가 연결된 네트워크를 생성했는지 알지 못할 수 있다. 다른 벡 더는 기계 학습 모델에 대해 다른 훈련 기술 및/또는 네트워크 아키텍처를 사용할 수 있으므로, 이 정보의 가용 성은 UE 측의 훈련 모델에 영향을 미칠 수 있다. 따라서, 일부 실시 예에서, 네트워크 표시 또는 AI/ML 인덱스 는 시스템 정보를 통해 (예를 들어, SIB 중 하나를 통해) UE에 제공될 수 있다. 그런 다음 UE는 이 정보를 사용 하여 자신의 훈련을 특정 네트워크 벤더 구성에 적용할 수 있다. ML 모델 수명 주기 관리 일부 ML 애플리케이션에서, ML 모델의 성능은 시간이 지남에 따라 저하될 수 있으며, 훈련된 애플리케이션의 기 간 동안 적절하게 수행되지 않을 수 있다. 따라서, ML 모델은 동작 환경에서 발생할 수 있는 일시적인 변화, 예 를 들어, CSI 압축의 경우 무선 채널의 통계적 변화에 적응하기 위해 자주 업데이트될 수 있다. 본 개시에 따른 일부 실시 예는 수용 가능한 오버헤드를 갖는 하나 이상의 ML 모델의 효율적 및/또는 시기적절 한 업데이트를 가능하게 하는 관리 프레임워크를 제공할 수 있다. 그러한 프레임워크를 용이하게 하기 위해, 일 실시 예는 노드가 ML 모델의 성능을 추적할 수 있는 모델 모니터링을 구현할 수 있다. 일부 실시 예에서, 이것 은 노드가 ML 모델의 성능을 추적할 수 있는 모델 모니터링이 포함될 수 있다. 모델 모니터링은 다음과 같이 하 나 이상의 성능 메트릭을 기반으로 할 수 있다. 작업 기반 메트릭은 ML 모델에 의해 수행되는 작업의 성능 을 (예를 들어, 직접) 평가하는 데 사용할 수 있다. 예를 들어, 이러한 메트릭은 정확도, 평균 제곱 오차(MSE) 성능 등을 포함할 수 있다. 시스템 기반 메트릭을 사용하여 시스템의 전체 성능, 예를 들어, 시스템의 노드 에 의해 사용되는 ML 모델의 성능에 대한 덜 직접적인 측정을 제공할 수 있는 전송의 정확한 디코딩 또는 기타 시스템 수준 핵심 성과 지표(KPI)를 추적할 수 있다. ML 모델의 성능이 합의 및/또는 구성된 메트릭에 따라 수용할 수 없는 것으로 간주되는 경우, 관리 프레임워크 는 ML 모델 업데이트 절차를 시작할 수 있다. 예를 들면, 하나 이상의 합의 및/또는 구성된 메트릭에 따라 ML 모델 성능이 허용되지 않는 경우; 및/또는 ML 모델의 성능이 임계 시간보다 긴 특정 기간 동안 허용되지 않는 경우, 성능은 허용 불가능한 것으로 간주될 수 있다. 허용 불가능한 성능을 결정하기 위한 임계값은 구성된 및/또는 지정된 매개변수로 구현될 수 있다. 지속 시간은 i) 누적적으로 측정되어, 예를 들어 허용 불가능한 성능의 기간이 전역 카운터에 추가될 수 있으며, 전역 카운 터 값이 임계값과 비교되거나, ii) 연속적으로 측정되어, 예를 들어 임계값보다 더 큰 허용 불가능한 성능의 연 속적인 기간만이 고려될 수 있다. ML 모델의 성능이 허용할 수 없는 것으로 간주되는 경우, 관리 프레임워크는 다음 방식 중 하나로 구현될 수 있 는 업데이트 절차를 트리거할 수 있다. 관리 프레임워크는 예를 들어 도 8과 관련하여 설명된 대로 전체 훈 련 절차를 요구할 수 있다. 이 경우, ML 모델을 처음부터 다시 학습하거나 현재 ML 모델부터 다시 학습할 수 있 다. 이 경우 훈련은 최근에 획득했을 수 있는 추가 데이터 샘플의 유무에 관계없이 전체 훈련 데이터 세트를 사용할 수 있다. 관리 프레임워크는 ML 모델이 현재 ML 모델에서 시작하여 아마도 최근에 획득한 새로운 데이 터 샘플을 사용하여 재학습될 수 있는 부분적인 훈련을 요구할 수 있다. 훈련 및 테스트의 성능 지표 CSI 압축 작업에 대한 상이한 모델의 성능을 평가하기 위해, 본 개시에 따른 일부 실시 예는 CSI 압축의 양상에 초점을 맞출 수 있다. 그러한 실시 예에서, 상이한 모델들은 CSI 행렬을 압축하고 CSI 행렬을 복구하여 복구된 행렬이 실제 CSI 행렬에 가능한 한 근접하도록 각각의 능력에 기초하여 비교될 수 있다. 근접성의 결정은 CSI 행렬을 갖는 gNB의 동작과 관련될 수 있다. 예를 들어 gNB가 채널 행렬의 SVD를 Hr×t=UΣVH을 계산하여 오른쪽 특이 벡터 V를 사용하여 프리코더를 결정하면, 근접도는 인코더의 입력에서 V 와 디코더의 출력에서 복구된 V 사이에서 결정될 수 있다. 일부 실시 예에서, 두 행렬 간의 근접성 메트릭은 요소별로 구현될 수 있으며, 평균은 단일 손실 값을 제공하기 위해 일부 또는 모든 요소에 대해 취해질 수 있다. 대안적으로, 또는 추가적으로, 행렬에 하나 또는 몇 개의 잘 못된 요소를 갖게 되면 많은 잘못된 요소를 갖는 것만큼 해로울 수 있다. 이 경우, 손실 함수는 예를 들어, 행 렬의 모든 요소에 대한 요소별 오류의 최대값과 같은 행렬 방식 기반으로 결정될 수 있다. 일부 실시 예에서, CSI 인코더 및 디코더 모델의 성능은 시스템의 다른 블록과 함께 평가될 수도 있다. 예를 들 어, 블록 오류율(BLER)이 시스템 성능 메트릭으로 사용되는 경우, 서로 다른 CSI 모델 간의 비교는 결과 BLER를 기반으로 할 수 있다. 처리량, 자원 사용률 등과 같은 다른 시스템 KPI도 이 용도로 사용할 수 있다. BLER가 관심 메트릭인 실시 예에서, CSI 행렬에 의해 제공되는 정보를 사용하도록 gNB를 구성하는 것은 시스템 성능에 영향을 미칠 수 있다. 예를 들어, UE가 전송한 채널 행렬이 gNB에서 완전히 복구되고 채널 행렬이 랭크 1 채널을 나타낸다는 점에서 CSI 모델이 완벽하다고 가정하면, gNB가 랭크 2 PDSCH를 스케줄링하는 경우 디코딩 이 실패할 가능성이 있다. 그러므로, CSI 모델의 압축 기능과 시스템 성능 간의 연결을 설정하기 위해서, gNB 동작과 관련한 가정이 사용될 수 있다. 일부 실시 예에서, 함수 fgNB를 처리하는 gNB는 디코더의 출력, 예를 들 어 를 취하고 결과 BLER의 추정치를 로 제공하도록 정의될 수 있다. 훈련 중 손실 함수는 CSI 압축 및 gNB 운영 측면을 모두 고려하여 정의될 수 있다. 예를 들어, 손실은 다음과 같이 두 항의 가중 합으로 정의될 수 있다. 수학식 6"}
{"patent_id": "10-2022-0134128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기에서 α와 β는 훈련을 위한 하이퍼매개변수이다. 업링크 채널의 신뢰성 측면 일부 실시 예에서, CSI 코드워드라고도 하는 인코더의 출력은 디코더 측에서 오류 없이 이용 가능한 것으로 가 정될 수 있다. 따라서, CSI 코드워드는 PUCCH 및/또는 PUSCH 디코딩이 실패하지 않도록 무한 신뢰도로 업링크 채널에서 PUCCH 또는 PUSCH를 통해 전송될 수 있다. 그러나 어떤 경우에는 추론 단계에서, CSI 코드워드는 예를 들어 PUSCH/PUCCH 디코딩이 실패할 때 하나 이상의 오류와 함께 gNB(디코더)에 전달될 수 있다. 그러한 경우에, CSI 코드워드의 잡음 버전이 디코더에서 이용가능할 수 있다. 훈련 단계 동안 업링크 채널의 불완전성의 영향은 다음과 같이 모델링될 수 있다. 인코더에 대한 각 훈련 예제 입력에 대해, 인코더의 출력에서 CSI 코드워드는 x로 표시될 수 있다. 업링크 채널 의 불완전성을 고려할 때, 디코더 y에 대한 입력은 다음과 같이 모델링될 수 있다: 수학식 7 여기에서 ω는 업링크 채널의 디코딩 후 잔여 오차를 모델링할 수 있는 가산 잡음이다. 훈련 단계에서 가산 잡 음은 다음과 같이 생성될 수 있다. 방법 1에서, ω는 평균이 0이고 분산이 σ2인 가우스 랜덤 벡터로 모델링될 수 있다. 분산은 RRC 구성을 통해 UE에 표시되거나 UE 구현에 남겨질 수 있다. 방법 2에서, x와 y 사이의 채널은 각 훈련 예에 대해 PUCCH 및/또 는 PUSCH 디코딩을 수행하고, 잔차 오차 벡터 ω를 구하고, 다음에 벡터가 x에 추가되어 y를 얻는다고 가정함으 로써 모델링될 수 있다. 연합 학습 측면 연합 학습(FL)으로, 서버의 전역 모델은 서버에 연결된 여러 노드에서 개별 학습을 통해 학습하고 학습된 모델 을 서버와 공유할 수 있다. 서버는 다음에 수신된 모델에 대해 하나 이상의 작업을 수행하여 최종 모델을 얻을 수 있다. 그러한 배열은, 예를 들어, 프라이버시 측면 및/또는 노드의 데이터를 서버와 공유하지 않기 위한 요 구 사항에 동기를 부여할 수 있다. CSI 압축 사용 사례에서, 서버는 gNB로 간주될 수 있고 gNB에 연결된 다른 UE는 모델 업데이트 노드로 간주될 수 있다. 상이한 UE는 동일하거나 상이한 분포를 갖는 상이한 훈련 세트를 가질 수 있다. 분포가 동일하면, 각 UE는 모델을 자체 훈련 세트로 업데이트하고 모델을 gNB와 공유할 수 있다. 그 다음, gNB는 예를 들어 최종 모 델을 획득하기 위해 모델을 평균화하는 것과 같은 하나 이상의 동작을 수행할 수 있다. gNB는 획득한 최종 모델 을 자신의 모델을 공유한 UE와 공유할 수 있다. 최종 모델은 모든 참가자 UE에 대한 모든 훈련 세트의 합집합을 기반으로 훈련되기 때문에 개별 수신 모델보다 성능이 좋을 것으로 예상될 수 있다. 따라서 CSI 압축 성능을 향 상시키기 위해 FL이 사용될 수 있다. 다른 UE에서 사용 가능한 다른 분포의 경우, FL은 분포를 본 UE가 공유하 는 모델을 통해 특정 UE가 아직 보지 못한 분포를 캡처하는 데 도움이 될 수 있다. 어쨌든, FL은 UE가 관찰하는 다양한 환경을 고려한 모델을 얻는 데 사용될 수 있다. 본 개시에 따른 FL 프레임워크로, gNB는 UE의 그룹이 FL 그룹에 있도록 구성할 수 있다. 동일한 FL 그룹의 UE는 동일한 인코더 및/또는 디코더(예를 들어, 자동 인코더 또는 AE) 아키텍처를 갖도록 구성될 수 있다. 따라서, 인코더와 디코더는 실제로 훈련된 가중치는 서로 다를 수 있지만 계층 수, 단위 수, 활성화 기능 및 네트워크 구조를 정의하는 기타 매개변수 측면에서 동일한 구성을 갖는다. 인코더 및 디코더 모델에 대한 입력의 크기는 그룹의 UE에 대해 동일하거나 유사할 수 있다. 인코더에 대한 입 력은 또한 UE에 대해 동일하거나 유사한 의미를 가질 수 있다. 예를 들어, UE(예를 들어, 모든 UE)의 인코더에 대한 입력은 채널 행렬 또는 특이값 행렬 V일 수 있다. gNB는 모델을 업데이트하고 gNB와 업데이트를 공유하도 록 RRC, DCI 또는 MAC CE 명령을 통해 UE에 지시할 수 있다. 일부 실시 예에서, 그룹의 모든 UE가 동시에 업데 이트 절차에 참여하는 것은 아니다. gNB는 그룹 공통(GC) DCI를 통해 훈련, 하이퍼매개변수 및/또는 FL의 다른 측면에 관한 정보를 보낼 수 있으며, 여기서 동일한 FL 그룹의 UE는 RRC를 통해 구성된 DCI의 특정 부분을 가질 수 있다. 추가 실시 예 도 12는 본 개시에 따른 2-모델 방식을 사용하기 위한 시스템의 실시 예를 예시한다. 도 12에 예시된 실시 예는 하나 이상의 모델을 테스트하는 맥락에서 설명될 수 있지만, 동일하거나 유사한 실시 예는 본 명세서에서 개시 된 모델 중 임의의 것, 예를 들어, 훈련 후 도 3에 예시된 생성 모델 및/또는 복원 모델로 검증, 추 론 등을 위해 사용될 수도 있다. 도 12를 참조하면, 시스템은 생성 모델을 갖는 제1 노드(노드 1) 및 복원 모델을 갖는 제2 노드(노드 B)를 포함할 수 있다. 테스트 데이터는 테스트 데이터의 표현을 생성할 수 있는 생성 모 델에 적용될 수 있다. 복원 모델은 테스트 데이터의 표현에 기초하여 테스트 데이터의 복원 을 생성할 수 있다. 일부 실시 예에서, 생성 모델은 표현을 통신 채널을 통해 전송될 수 있 는 양자화된 형태(예를 들어, 비트 스트림)로 변환하기 위한 양자화기를 포함할 수 있다. 유사하게, 일부 실시 예에서, 복원 모델은 양자화된 표현(예를 들어, 비트 스트림)을 복원된 테스트 데이터를 생 성하기 위해 사용될 수 있는 형태로 변환할 수 있는 역양자화기를 포함할 수 있다. 생성 모델 및 복원 모델은 본 명세서에서 설명된 프레임워크 중 임의의 것을 사용하는 것을 포함하 는 임의의 방식으로 획득될 수 있다. 예를 들어, 공동 훈련 프레임워크를 사용하여, 생성 모델 및 복원 모델은 복원 모델을 노드 B로 전송할 수 있는 노드 A에서 쌍으로 훈련될 수 있다. 다른 실시 예는생성 모델 및 복원 모델을 획득 및/또는 훈련하기 위해서, 참조 모델이 있는 훈련 프레임워크, 최 신 공유 값이 있는 훈련 프레임워크, 또는 임의의 다른 프레임워크 및/또는 기술을 사용할 수 있다. 도 13은 본 개시에 따른 사용자 장치(UE)의 예시적인 실시 예를 예시한다. 도 13에 예시된 실시 예는 무 선 송수신기 및 송수신기 및/또는 UE의 임의의 다른 구성요소의 동작을 제어할 수 있는 제어 기를 포함할 수 있다. UE는, 예를 들어, 기지국으로부터의 하나 이상의 참조신호에 기초하여 채널 정보를 결정하는 단계, 기계 학습 모델을 사용하여 채널의 상태에 기초하여 채널 정보의 표현을 생성하는 단계, 채널 정보의 표현을 전송하는 단계, 예를 들어 윈도우 동안 훈련 데이터를 수집하는 단계, 예를 들어, CSI 행렬 에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이상의 ML 모델 쌍을 배포 및/또는 활성화하는 단계를 포함하여, 본 개시에서 설명된 모든 기능을 구현하기 위해 사용될 수 있다. 송수신기는 기지국으로/기지국으로부터 하나 이상의 신호를 전송/수신할 수 있으며, 이러한 전송/수신을 위한 인터페이스 유닛을 포함할 수 있다. 예를 들어, 송수신기는 기지국으로부터 하나 이상의 신호를 수 신할 수 있고/있거나 채널 정보의 표현을 UL 채널을 통해 기지국으로 전송할 수 있다. 제어기는, 예를 들어, 하나 이상의 프로세서 및 본 개시에서 설명된 임의의 기능을 구현하기 위한 코드를 실행하기 위한 하나 이상의 프로세서에 대한 명령을 저장할 수 있는 메모리를 포함할 수 있 다. 예를 들어, 제어기는 본 명세서에 개시된 바와 같이 하나 이상의 기계 학습 모델을 구현할 뿐만 아니 라, 기지국으로부터의 하나 이상의 참조신호에 기초하여 채널 정보를 결정하고, 기계 학습 모델을 사용하여 채 널의 상태에 기초하여 채널 정보의 표현을 생성하고, 채널 정보의 표현을 전송하고, 예를 들어, 윈도우 동안 훈 련 데이터를 수집하고, 예를 들어, CSI 행렬에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이상의 ML 모델 쌍을 배포 및/또는 활성화하는 등을 위해 구성된다. 도 14는 본 개시에 따른 기지국의 예시적인 실시 예를 예시한다. 도 14에 예시된 실시 예는 무선 송수신 기 및 송수신기 및/또는 기지국의 임의의 다른 구성요소의 동작을 제어할 수 있는 제어기 를 포함할 수 있다. 기지국은 예를 들어, DL 채널을 통해 UE에 하나 이상의 참조 신호를 전송하고, 채널 정보의 표현을 복원하고, 예를 들어, CSI 행렬에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이 상의 ML 모델 쌍을 배포 및/또는 활성화하는 단계를 포함하여, 본 개시에 설명된 모든 기능을 구현하기 위해 사 용될 수 있다 송수신기는 사용자 장치로/로부터 하나 이상의 신호를 전송/수신할 수 있고, 이러한 전송/수신을 위한 인 터페이스 유닛을 포함할 수 있다. 예를 들어, 송수신기는 DL 채널을 통해 UE에 하나 이상의 참조 신호를 전송하고/하거나 UL 채널을 통해 UE로부터 프리코딩 정보를 수신할 수 있다. 제어기는, 예를 들어, 하나 이상의 프로세서 및 본 개시에서 설명된 기지국 기능 중 임의의 것을 구현하기 위한 코드를 실행하기 위한 하나 이상의 프로세서에 대한 명령을 저장할 수 있는 메모리 를 포함할 수 있다. 예를 들어, 컨트롤러는 본 명세서에 개시된 하나 이상의 기계 학습 모델을 구현할 뿐 만 아니라, DL 채널을 통해 UE에 하나 이상의 참조 신호를 전송하고, 채널 정보의 표현을 복원하고, 예를 들어, CSI 행렬에 대해 사전 처리 및/또는 사후 처리를 수행하고, 하나 이상의 ML 모델 쌍을 배포 및/또는 활성화하는 등을 위해 사용될 수 있다. 도 13 및 14에 예시된 실시 예에서, 송수신기(1302 및 1402)는 증폭기, 필터, 변조기 및/또는 복조기, A/D 및/ 또는 DA 변환기, 안테나, 스위치, 위상 천이기, 검출기, 커플러, 도체, 전송선 등과 같은 RF 신호를 수신 및/또 는 전송하기 위해 다양한 구성요소로 구현될 수 있다. 제어기(1304 및/또는 1404)는 하드웨어, 소프트웨어, 및/ 또는 이들의 임의의 조합으로 구현될 수 있다. 예를 들어, 전체 또는 부분 하드웨어 구현은 조합 논리, 순차 논 리, 타이머, 카운터, 레지스터, 게이트 어레이, 증폭기, 합성기, 멀티플렉서, 변조기, 복조기, 필터, 벡터 프로 세서, 복합 프로그램 가능 논리 장치(CPLD), 필드 프로그램 가능 게이트 어레이(FPGA), 주문형 집적 회로 (ASIC), 시스템 온 칩(SOC), 상태 머신, ADC 및 DAC와 같은 데이터 변환기 등을 포함한다. 전체 또는 부분 소프 트웨어 구현은 하나 이상의 프로세서 코어, 메모리, 프로그램 및/또는 데이터 저장소 등을 포함할 수 있다. 로 컬 및/또는 원격에 위치할 수 있고 컨트롤러의 하나 이상의 기능을 수행하기 위한 명령을 실행하도록 프로그래 밍될 수 있다. 일부 실시 예는 임의의 유형의 메모리, 그래픽 처리 장치(GPU), 신경 처리 장치(NPU), 텐서 처리 장치(TPU) 등에 저장된 명령어를 실행하는, 마이크로컨트롤러와 같은 하나 이상의 프로세서, x86 프로세서와 같 은 복합 명령 세트 컴퓨터(CISC) 프로세서와 같은 CPU, 및/또는 ARM 프로세서 등과 같은 ㄱ가감소된 명령 세트 컴퓨터(RISC) 프로세서를 포함할 수 있다. 도 15는 본 개시에 따라 물리 계층 정보 피드백을 제공하기 위한 방법의 실시 예를 예시한다. 방법은 단계 에서 시작할 수 있다. 단계에서, 방법은 무선 장치에서 무선 장치에 대한 물리 계층 정보를 결정할 수 있다. 단계에서, 방법은 기계 학습 모델을 사용하여 물리 계층 정보의 표현을 생성할 수 있다. 단계 에서, 방법은 사용자 장치로부터, 무선 장치로부터 물리 계층 정보의 표현을 전송할 수 있다. 방법은 단 계에서 종료할 수 있다. 도 15에 도시된 실시 예 및 본 명세서에서 개시된 임의의 실시 예에서, 예시된 구성요소 및/또는 동작은 단지 예시일 뿐이다. 일부 실시 예는 다양한 추가 구성요소 및/또는 예시되지 않은 동작을 포함할 수 있으며, 일부 실시 예는 일부 구성요소 및/또는 동작을 생략할 수 있다. 더욱이, 일부 실시 예에서, 구성요소의 배열 및/또는 동작의 시간적 순서가 변경될 수 있다. 일부 구성 요소는 개별 구성 요소로 표시될 수 있지만, 일부 실시 예에 서, 별도로 표시된 일부 구성 요소는 단일 구성 요소로 통합될 수 있고/있거나, 단일 구성 요소로 표시된 일부 구성 요소는 다중 구성 요소로 구현될 수 있다. 본 명세서에 개시된 실시 예는 다양한 구현 세부사항의 맥락에서 설명될 수 있으며, 본 개시의 원칙은 이들 또 는 기타 특정 세부사항으로 제한되지 않는다. 일부 기능은 특정 구성 요소에 의해 구현되는 것으로 설명되었지 만, 다른 실시 예에서, 기능은 다른 위치에 있는 다른 시스템과 구성요소 사이에 분산될 수 있다. 구성 요소 또 는 요소에 대한 참조는 구성 요소 또는 요소의 일부만을 참조할 수 있다. 본 개시 및 청구범위에서 \"제1\" 및 \" 제2\"와 같은 용어의 사용은 이들이 변형된 것을 구별하기 위한 목적일 뿐이며 문맥상 다르게 명백하지 않는 한 공간적 또는 시간적 순서를 나타내지 않을 수 있다. 제1 것에 대한 언급은 제2 것의 존재를 의미하지 않을 수 있다. 더욱이, 위에서 설명된 다양한 세부사항 및 실시 예는 본 발명의 원리에 따른 추가적인 실시 예를 생성하 기 위해 결합될 수 있다. 편의상 섹션 제목 등과 같은 다양한 정리 지원이 제공될 수 있지만, 이러한 지원 및 본 개시의 원칙에 따라 배열된 주제는 이러한 조직적 지원에 의해 정의되거나 제한되지 않는다. 본 발명의 발명 원리는 본 발명의 개념을 벗어나지 않고 배열 및 세부 사항이 변경될 수 있으므로, 이러한 변경 및 수정은 다음 청구 범위에 속하는 것으로 간주된다."}
{"patent_id": "10-2022-0134128", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 반드시 일정한 비율로 도시된 것은 아니며 유사한 구조 또는 기능의 요소는 일반적으로 도면 전체에 걸 쳐 예시 목적으로 유사한 참조 번호 또는 그 부분으로 표시된다. 도면은 본 명세서에서 설명된 다양한 실시 예 의 설명을 용이하게 하기 위한 것일 뿐이다. 도면은 본 명세서에서 개시된 교시의 모든 측면을 설명하지 않으며 청구범위의 범위를 제한하지 않는다. 도면이 불분명하게 하는 것을 방지하기 위해 모든 구성 요소, 연결 등이 표시되지 않을 수 있으며 모든 구성 요소에 참조 번호가 있는 것은 아니다. 그러나 구성요소의 구성 패턴은 도 면에으로부터 쉽게 알 수 있다. 첨부된 도면은 본 명세서와 함께 본 발명의 일 실시 예를 도시한 것으로, 상세 한 설명과 함께 본 발명의 원리를 설명하기 위한 것이다. 도 1은 본 개시에 따른 무선 통신 장치의 실시 예를 도시한다. 도 2는 본 개시에 따른 무선 통신 장치의 다른 실시 예를 도시한다. 도 3은 본 개시에 따른 2-모델 훈련 방식의 실시 예를 예시한다. 도 4는 본 개시에 따른 채널 정보 피드백을 제공하기 위한 한 쌍의 모델을 갖는 시스템의 실시 예를 도시한다. 도 5는 본 개시에 따른 다운링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 도 6은 본 개시에 따른 업링크 물리 계층 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시한다. 도 7은 본 개시에 따른 다운링크 물리 계층 채널 상태 정보를 보고하기 위한 시스템의 예시적인 실시 예를 도시 한다. 도 8은 본 개시에 따른 기계 학습 모델을 위한 학습 프로세스의 실시 예를 도시한다. 도 9는 본 개시에 따른 한 쌍의 인코더 및 디코더 모델의 공동 훈련을 위한 방법의 예시적인 실시 예를 도시한 다. 도 10은 본 개시에 따른 최신 공유 값으로 모델을 훈련시키는 방법의 예시적인 실시 예를 도시한다. 도 11은 본 개시에 따른 사전 처리 및 사후 처리를 갖는 2-모델 훈련 방식의 예시적인 실시 예를 도시한다. 도 12는 본 개시에 따른 2-모델 방식을 사용하기 위한 시스템의 실시 예를 도시한다. 도 13은 본 개시에 따른 사용자 장치(UE)의 예시적인 실시 예를 도시한다. 도 14는 본 개시에 따른 기지국의 예시적인 실시 예를 도시한다. 도 15는 본 개시에 따른 물리 계층 정보 피드백을 제공하기 위한 방법의 실시 예를 도시한다."}
