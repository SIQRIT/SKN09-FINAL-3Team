{"patent_id": "10-2022-0042186", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0143383", "출원번호": "10-2022-0042186", "발명의 명칭": "3차원 객체 검출 장치 및 방법", "출원인": "현대자동차주식회사", "발명자": "임현규"}}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라; 저장부; 및프로세서;를 포함하고,상기 프로세서는,상기 카메라를 이용하여 2차원 이미지를 획득하고,상기 2차원 이미지를 세그먼테이션(segmentation)하여 프리 스페이스(free space)와 관련된 특징(feature) 정보를 획득하고,상기 2차원 이미지로부터 상기 2차원 이미지에 포함된 객체와 관련된 특징 정보를 획득하고,어텐션 매커니즘(attention mechanism)을 이용하여, 상기 프리 스페이스와 관련된 특징 정보 및 상기 객체와 관련된 특징 정보를 기반으로 어텐션 스코어(attention score)를 결정하고, 상기 어텐션 스코어를 기반으로 상기 객체의 3차원 위치 정보를 검출하는, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 프로세서는,상기 2차원 이미지를 세그먼테이션하여 복수 개의 영역으로 구분하고,상기 복수 개의 영역에 대하여 프리 스페이스의 예측(prediction)을 수행하고, 상기 예측을 수행하는 동작 결과에 기반하여 상기 프리 스페이스와 관련된 특징 정보를 획득하는, 3차원 객체검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 상기 프로세서는상기 객체와 관련된 특징 정보로부터 상기 어텐션 매커니즘에서 사용하는 쿼리(query)를 추출하고,상기 프리 스페이스와 관련된 특징 정보로부터 상기 어텐션 매커니즘에서 사용하는 키(key)를 추출하고,상기 쿼리 및 상기 키를 곱하여 상기 어텐션 스코어를 결정하는, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 프로세서는, 상기 어텐션 매커니즘에서 사용하는 값(value)을 상기 쿼리와 동일하게 결정하고,공개특허 10-2023-0143383-3-상기 어텐션 스코어에 상기 값(value)을 가중치로 적용하여 어텐션 값(attention value)을 결정하고,상기 어텐션 값을 디코딩하여 상기 3차원 위치 정보를 검출하는, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 3차원 위치 정보는 상기 객체의 3차원 좌표 정보를 포함하는, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 3에 있어서, 상기 프로세서는,상기 프리 스페이스와 관련된 특징 정보를 기 저장된 세그먼테이션 레퍼런스 정보와 비교하여, 상기 프리 스페이스와 관련된 특징 정보에 대한 세그먼테이션 손실(loss)을 결정하고,상기 세그먼테이션 손실을 고려하여 상기 프리 스페이스와 관련된 특징 정보로부터 상기 키를 추출하는, 3차원객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 4에 있어서, 상기 프로세서는,상기 3차원 객체의 위치 정보를 기 저장된 3차원 위치 레퍼런스 정보와 비교하여, 상기 3차원 객체의 위치 정보의 손실(loss)을 결정하는, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 프로세서는컨볼루션 신경망(convolutional neural network, CNN)의 계층 구조를 기반으로 상기 2차원 이미지로부터 상기객체와 관련된 특징 정보를 추출하는 백본망(backbone network)을 포함하는, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서, 상기 프로세서는,상기 객체와 관련된 특징 정보에 기반하여, 상기 2차원 이미지로부터 상기 객체의 2차원 및 3차원 디멘션(dimension), 및 상기 객체의 3차원 방향을 검출하는, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 1에 있어서,공개특허 10-2023-0143383-4-상기 카메라는 단안(monocular) 카메라인, 3차원 객체 검출 장치."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "카메라를 이용하여 2차원 이미지를 획득하는 단계;상기 2차원 이미지를 세그먼테이션(segmentation)하여 프리 스페이스(free space)와 관련된 특징(feature) 정보를 획득하는 단계;상기 2차원 이미지로부터 상기 2차원 이미지에 포함된 객체와 관련된 특징 정보를 획득하는 단계;어텐션 매커니즘(attention mechanism)을 이용하여, 상기 프리 스페이스와 관련된 특징 정보 및 상기 객체와 관련된 특징 정보를 기반으로 어텐션 스코어(attention score)를 결정하는 단계; 및상기 어텐션 스코어를 기반으로 상기 객체의 3차원 위치 정보를 검출하는 단계;를 포함하는, 3차원 객체 검출방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서, 상기 프리 스페이스와 관련된 특징 정보를 획득하는 단계는,상기 2차원 이미지를 세그먼테이션하여 복수 개의 영역으로 구분하는 단계; 상기 복수 개의 영역에 대하여 프리 스페이스의 예측(prediction)을 수행하는 단계; 및상기 예측을 수행하는 단계 결과에 기반하여 상기 프리 스페이스와 관련된 특징 정보를 획득하는 단계;를 포함하는, 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 11에 있어서,상기 어텐션 스코어를 결정하는 단계는,상기 객체와 관련된 특징 정보로부터 상기 어텐션 매커니즘에서 사용하는 쿼리(query)를 추출하는 단계;상기 프리 스페이스와 관련된 특징 정보로부터 상기 어텐션 매커니즘에서 사용하는 키(key)를 추출하는 단계;및상기 쿼리 및 상기 키를 곱하여 상기 어텐션 스코어를 결정하는 단계를 포함하는 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13항에 있어서,상기 어텐션 매커니즘에서 사용하는 값(value)을 상기 쿼리와 동일하게 결정하는 단계; 및상기 어텐션 스코어에 상기 값(value)을 가중치로 적용하여 어텐션 값(attention value)을 결정하는 단계;를 더포함하고,상기 3차원 위치 정보를 검출하는 단계는, 상기 어텐션 값을 디코딩하여 상기 3차원 위치 정보를 검출하는 것을특징으로 하는 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2023-0143383-5-청구항 14에 있어서,상기 3차원 위치 정보는 상기 객체의 3차원 좌표 정보를 포함하는 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 13에 있어서,상기 키를 획득하는 단계는,상기 프리 스페이스와 관련된 특징 정보를 기 저장된 세그먼테이션 레퍼런스 정보와 비교하여, 상기 프리 스페이스와 관련된 특징 정보에 대한 세그먼테이션 손실(loss)을 결정하는 단계; 및상기 세그먼테이션 손실을 고려하여 상기 프리 스페이스와 관련된 특징 정보로부터 상기 키를 추출하는 단계를포함하는 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 14에 있어서,상기 3차원 위치 정보를 기 저장된 위치 정보 레퍼런스 정보와 비교하여, 상기 3차원 위치 정보의 손실(loss)을결정하는 단계를 더 포함하는 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 11에 있어서,상기 객체와 관련된 특징 정보를 획득하는 단계는,컨볼루션 신경망(convolutional neural network, CNN)의 계층 구조를 기반으로 하는 백본망(backbone network)을 이용하여 상기 2차원 이미지로부터 상기 객체와 관련된 특징 정보를 추출하는 단계를 포함하는 3차원 객체검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 11에 있어서,상기 객체와 관련된 특징 정보에 기반하여, 상기 2차원 이미지로부터 상기 객체의 2차원 및 3차원 디멘션(dimension)을 검출하는 단계; 및 상기 객체와 관련된 특징 정보에 기반하여, 상기 2차원 이미지로부터 상기 객체의 방향을 검출하는 단계를 더포함하는 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 11에 있어서,상기 2차원 이미지는, 단안(monocular) 카메라를 이용하여 획득한 단안 이미지인, 3차원 객체 검출 방법."}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 3차원 객체 검출 장치 및 방법에 관한 것으로, 3차원 객체 검출 장치는 카메라 및 프로세서를 포함하 고, 상기 프로세서는, 상기 카메라를 이용하여 2차원 이미지를 획득하고, 상기 2차원 이미지를 세그먼테이션 (segmentation)하여 프리 스페이스(free space) 정보를 획득하고, 상기 2차원 이미지로부터 상기 2차원 이미지에 포함된 객체와 관련된 특징(feature) 정보를 추출하고, 어텐션 매커니즘(attention mechanism)을 이용하여, 상 기 프리 스페이스 정보 및 상기 추출한 특징 정보를 기반으로 어텐션 스코어(attention score)를 결정하고, 및 상기 어텐션 스코어를 기반으로 상기 이미지로부터 상기 객체의 3차원 위치 정보를 검출할 수 있다."}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 3차원 객체 검출 장치 및 방법에 관한 것으로, 보다 상세하게는 이미지에서 3차원 객체를 검출하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "단안(monocular) 카메라에 의해 획득되는 단안 이미지, 즉, 2차원(2-dimensional, 2D) 이미지는 깊이(depth) 정보가 없기 때문에, 단안 이미지로부터 3차원(3D) 정보를 검출하는데 어려움이 있다. 이러한 어려움을 해결하 기 위한 방안으로 앵커 기반 네트워크인 M3D-RPN(monocular 3D region proposal network)를 활용하여 객체를 검출하는 방안이 있다. 다만, 일반적으로 네트워크가 이미지의 어떠한 부분을 기반으로 3차원 정보를 검출하는 지에 대한 분석은 이루어지지 않으며, 이를 활용하여 더 효율적이고 정확하게 이미지로부터 3차원 정보를 검출 하는 방법이 요구된다. 선행기술문헌 비특허문헌 (비특허문헌 0001) G. Brazil and X. Liu, \"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection,\" 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 9286-9295, doi: 10.1109/ICCV.2019.00938. (비특허문헌 0002) Tom Van Dijk; Guido De Croon, \"How Do Neural Networks See Depth in Single Images?,\" 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, DOI: 10.1109/ICCV.2019.00227"}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시 예는, 단안 카메라에 의해 획득된 2차원 이미지로부터 3차원 객체를 검출하는 장치 및 방법을 제공하고자 한다. 본 발명의 다른 실시 예는, 이미지의 세그먼테이션(segmentation) 정보를 기반으로 3차원 객체의 위치 (location) 검출에 사용함으로써, 3차원 객체 검출의 성능을 향상시킬 수 있는 3차원 객체 검출 장치 및 방법을 제공하고자 한다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 3차원 객체 검출 장치는, 카메라, 저장부, 및 프로세서를 포함하고, 상기 프로세서는, 상기 카메라를 이용하여 2차원 이미지를 획득하고, 상기 2차원 이미지를 세그먼테이션 (segmentation)하여 프리 스페이스(free space)와 관련된 특징(feature) 정보를 획득하고, 상기 2차원 이미지 로부터 상기 2차원 이미지에 포함된 객체와 관련된 특징 정보를 획득하고, 어텐션 매커니즘(attention mechanism)을 이용하여, 상기 프리 스페이스와 관련된 특징 정보 및 상기 객체와 관련된 특징 정보를 기반으로 어텐션 스코어(attention score)를 결정하고, 상기 어텐션 스코어를 기반으로 상기 객체의 3차원 위치 정보를 검출할 수 있다. 일 실시 예에 따르면, 상기 프로세서는, 상기 2차원 이미지를 세그먼테이션하여 복수 개의 영역으로 구분하고, 상기 복수 개의 영역에 대하여 프리 스페이스의 예측(prediction)을 수행하고, 상기 예측을 수행하는 동작 결과 에 기반하여 상기 프리 스페이스와 관련된 특징 정보를 획득할 수 있다. 일 실시 예에 따르면, 상기 프로세서는, 상기 객체와 관련된 특징 정보로부터 상기 어텐션 매커니즘에서 사용하 는 쿼리(query)를 추출하고, 상기 프리 스페이스와 관련된 특징 정보로부터 상기 어텐션 매커니즘에서 사용하는 키(key)를 추출하고, 상기 쿼리 및 상기 키를 곱하여 상기 어텐션 스코어를 결정할 수 있다. 일 실시 예에 따르면, 상기 프로세서는, 상기 어텐션 매커니즘에서 사용하는 값(value)을 상기 쿼리와 동일하게 결정하고, 상기 어텐션 스코어에 상기 값(value)을 가중치로 적용하여 어텐션 값(attention value)을 결정하고, 상기 어텐션 값을 디코딩하여 상기 3차원 위치 정보를 검출할 수 있다. 일 실시 예에 따르면, 상기 3차원 위치 정보는 상기 객체의 3차원 좌표 정보를 포함할 수 있다. 일 실시 예에 따르면, 상기 프로세서는, 상기 프리 스페이스와 관련된 특징 정보를 기 저장된 세그먼테이션 레 퍼런스 정보와 비교하여, 상기 프리 스페이스와 관련된 특징 정보에 대한 세그먼테이션 손실(loss)을 결정하고, 상기 세그먼테이션 손실을 고려하여 상기 프리 스페이스와 관련된 특징 정보로부터 상기 키를 추출할 수 있다. 일 실시 예에 따르면, 상기 프로세서는, 상기 3차원 객체의 위치 정보를 기 저장된 3차원 위치 레퍼런스 정보와 비교하여, 상기 3차원 객체의 위치 정보의 손실(loss)을 결정할 수 있다. 일 실시 예에 따르면, 상기 프로세서는 컨볼루션 신경망(convolutional neural network, CNN)의 계층 구조를 기반으로 상기 2차원 이미지로부터 상기 객체와 관련된 특징 정보를 추출하는 백본망(backbone network)을 포함 할 수 있다. 일 실시 예에 따르면, 상기 프로세서는, 상기 객체와 관련된 특징 정보에 기반하여, 상기 2차원 이미지로부터 상기 객체의 2차원 및 3차원 디멘션(dimension), 및 상기 객체의 3차원 방향을 검출할 수 있다. 일 실시 예에 따르면, 상기 카메라는 단안(monocular) 카메라를 포함할 수 있다. 본 발명의 일 실시 예에 따른 3차원 객체 검출 방법은, 카메라를 이용하여 2차원 이미지를 획득하는 단계, 상기 2차원 이미지를 세그먼테이션(segmentation)하여 프리 스페이스(free space)와 관련된 특징(feature) 정보를 획 득하는 단계, 상기 2차원 이미지로부터 상기 2차원 이미지에 포함된 객체와 관련된 특징 정보를 획득하는 단계, 어텐션 매커니즘(attention mechanism)을 이용하여, 상기 프리 스페이스와 관련된 특징 정보 및 상기 객체와 관 련된 특징 정보를 기반으로 어텐션 스코어(attention score)를 결정하는 단계, 및 상기 어텐션 스코어를 기반으 로 상기 객체의 3차원 위치 정보를 검출하는 단계를 포함할 수 있다. 일 실시 예에 따르면, 상기 프리 스페이스와 관련된 특징 정보를 획득하는 단계는, 상기 2차원 이미지를 세그먼 테이션하여 복수 개의 영역으로 구분하는 단계, 상기 복수 개의 영역에 대하여 프리 스페이스의 예측 (prediction)을 수행하는 단계, 및 상기 예측을 수행하는 단계 결과에 기반하여 상기 프리 스페이스와 관련된 특징 정보를 획득하는 단계를 포함할 수 있다. 일 실시 예에 따르면, 상기 어텐션 스코어를 결정하는 단계는, 상기 객체와 관련된 특징 정보로부터 상기 어텐 션 매커니즘에서 사용하는 쿼리(query)를 추출하는 단계, 상기 프리 스페이스와 관련된 특징 정보로부터 상기 어텐션 매커니즘에서 사용하는 키(key)를 추출하는 단계, 및 상기 쿼리 및 상기 키를 곱하여 상기 어텐션 스코 어를 결정하는 단계를 포함할 수 있다. 일 실시 예에 따르면, 상기 어텐션 매커니즘에서 사용하는 값(value)을 상기 쿼리와 동일하게 결정하는 단계, 및 상기 어텐션 스코어에 상기 값(value)을 가중치로 적용하여 어텐션 값(attention value)을 결정하는 단계를 더 포함하고, 상기 3차원 위치 정보를 검출하는 단계는, 상기 어텐션 값을 디코딩하여 상기 3차원 위치 정보를 검출하는 것을 특징으로 할 수 있다. 일 실시 예에 따르면, 상기 3차원 위치 정보는 상기 객체의 3차원 좌표 정보를 포함할 수 있다. 일 실시 예에 따르면, 상기 키를 획득하는 단계는, 상기 프리 스페이스와 관련된 특징 정보를 기 저장된 세그먼 테이션 레퍼런스 정보와 비교하여, 상기 프리 스페이스와 관련된 특징 정보에 대한 세그먼테이션 손실(loss)을 결정하는 단계, 및 상기 세그먼테이션 손실을 고려하여 상기 프리 스페이스와 관련된 특징 정보로부터 상기 키 를 추출하는 단계를 포함할 수 있다. 일 실시 예에 따르면, 상기 3차원 객체 검출 방법은, 상기 3차원 위치 정보를 기 저장된 위치 정보 레퍼런스 정 보와 비교하여, 상기 3차원 위치 정보의 손실(loss)을 결정하는 단계를 더 포함할 수 있다. 일 실시 예에 따르면, 상기 객체와 관련된 특징 정보를 추출하는 단계는, 컨볼루션 신경망(convolutional neural network)의 계층 구조를 기반으로 하는 백본망(backbone network)을 이용하여 상기 2차원 이미지로부터 상기 객체와 관련된 특징 정보를 추출하는 단계를 포함할 수 있다. 일 실시 예에 따르면, 상기 3차원 객체 검출 방법은, 상기 객체와 관련된 특징 정보에 기반하여, 상기 2차원 이 미지로부터 상기 객체의 2차원 및 3차원 디멘션(dimension)을 검출하는 단계, 및 상기 객체와 관련된 특징 정보에 기반하여, 상기 2차원 이미지로부터 상기 객체의 방향을 검출하는 단계를 더 포함할 수 있다. 일 실시 예에 따르면, 상기 2차원 이미지는, 단안(monocular) 카메라를 이용하여 획득한 단안 이미지를 포함할 수 있다."}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 기술은 이미지의 세그먼테이션(segmentation) 정보를 기반으로 3차원 객체의 위치(location) 검출에 사용함 으로써, 3차원 객체 검출의 성능을 향상시킬 수 있다. 또한, 본 기술은 이미지의 세그먼테이션(segmentation) 정보를 이용하여 3차원 객체의 위치 검출 시 어텐션 (attention) 기법을 적용함으로써, 3차원 객체의 검출 성능을 향상시킬 수 있다. 또한, 본 기술은 단안(monocular) 이미지에서 3차원 객체를 검출 시, 이미지의 세그먼테이션을 통하여 프리 스 페이스(free space) 영역에 어텐션(예: 가중치)를 적용하여 3차원 객체의 검출 성능을 향상시킬 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시 예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시 예를 설명함에 있어, 관련된 공지 구성 또는 기능 에 대한 구체적인 설명이 본 발명의 실시 예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생 략한다. 본 발명의 실시 예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있 다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어 를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일 반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의 하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 명세서에서는 자율주행 인지 학습 데이터를 취득하는 과정 중 2차원 이미지(예: 단안(monocular) 이미지)를 활용하여 학습(train)한 결과를 활용하여 3차원 객체에 대한 정보를 예측하는 기술을 제시한다. 이하, 도 1 내지 도 4를 참조하여, 본 발명의 실시 예들을 구체적으로 설명하기로 한다. 도 1은 본 발명의 일 실시 예에 따른 3차원 객체 검출 장치를 도시한 블록도이다. 일 실시 예에 따르면, 3차원(3D) 객체 검출 장치는 차량에 장착되어 차량 주변의 객체(예: 사람(예: 보행자), 다른 차량, 주변 장애물, 동물, 및/또는 건물)에 대한 3차원 객체 정보(예: 객체의 3차원 위치 정보(3차원 좌표 정보), 3차원 방향, 및/또는 3차원 디멘션(dimension) 정보)를 검출할 수 있다. 일 실시 예에 따르면, 3차원 객체 검출 장치는 카메라, 저장부, 및 프로세서를 포함할 수 있다. 일 실시 예에 따르면, 카메라는 2차원 이미지를 획득할 수 있다. 카메라는 하나의 렌즈를 가지는 단 안(monocular) 카메라일 수 있다. 2차원 이미지는 단안 카메라를 이용하여 획득된 단안 이미지일 수 있다. 카 메라는 차량의 차폭 중심에 설치될 수 있으며, 차량의 전방, 측방, 및/또는 후방을 향하며 지면과 수평하게 설치될 수 있다. 일 실시 예에 따르면, 저장부는 카메라로부터 수신한 이미지(예: 2차원 이미지)를 저장할 수 있다. 저장부는 객체 검출을 위한 인공신경망 학습 알고리즘, 프로세서에 의해 학습된 결과, 프로세서(13 0)에 의해 실행되는 객체 검출 모델, 및/또는 객체 검출 결과를 저장할 수 있다. 저장부는 프로세서에 의해 실행되는 인스트럭션들(instructions)을 저장할 수 있다. 저장부는 플래시 메모리(flash memory), 하드디스크(hard disk), SSD(Solid State Disk), SD 카드(Secure Digital Card), eMMC(embedded multimedia card), UFS(universal flash storage), 착탈형 디스크 및/또는 웹 스토리지 (web storage)와 같은 저장매체와, RAM(Random Access Memory), SRAM(Static Random Access Memory), ROM(Read Only Memory), PROM(Programmable Read Only Memory), EEPROM(Electrically Erasable and Programmable ROM) 및/또는 EPROM(Erasable and Programmable ROM) 등과 같은 저장매체 중 적어도 하나를 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따르면, 프로세서는 카메라 및 저장부와 전기적으로 연결될 수 있다. 프로세서 는 3D 객체 검출 장치의 각 구성들의 동작 및/또는 후술하는 다양한 데이터 처리 및 계산을 수행할 수 있 다. 예를 들어, 프로세서는 메모리에 저장된 인스트럭션들을 실행함으로써, 후술하는 동작들을 수행할 수 있다. 일 실시 예에 따르면, 프로세서는 카메라를 이용하여 2차원 이미지를 획득할 수 있다. 프로세서(13 0)는 2차원 이미지를 세그먼테이션(segmentation)하여 프리 스페이스(free space)와 관련된 특징(feature) 정 보를 획득할 수 있다. 예를 들어, 프리 스페이스는 2차원 이미지에 포함된 객체들 중 지면과 관련된 객체를 의 미할 수 있다. 예를 들어, 프로세서는 2차원 이미지를 세그먼테이션하여 복수 개의 영역으로 구분하고, 복수 개의 영역에 대해 프리 스페이스의 예측(prediction)을 수행할 수 있다. 프로세서는 프리 스페이스의 예측 동작 결과 에 기반하여 프리 스페이스와 관련된 특징 정보를 획득할 수 있다. 예를 들어, 프리 스페이스와 관련된 특징 정보는 이미지 내의 각 영역이 프리 스페이스에 해당하는지를 나타내는 예측 결과(예: 신뢰도(confidence))을 포함할 수 있다. 예를 들어, 프로세서가 예측한 신뢰도가 높을수록 2차원 이미지 내의 해당 영역이 프리 스페이스일 가능성이 높음을 나타낼 수 있다. 예를 들어, 2차원 이미지에서 3차원 객체(예: 객체의 3차원 위치 정보)를 검출함에 있어서, 이미지 내 객체의 위치 또는 크기가 영향을 미칠 수 있으며, 이미지 내 객체의 위치 및 크기 중에서 상대적으로 객체의 위치가 객 체의 거리 추정 시에 더 큰 영향을 주는 요소일 수 있다(비특허문헌 2 참조). 또한, 이미지 내 검출되는 객체 는 지면과 맞닿아 있기 때문에, 프리 스페이스 영역으로 활용 가능하다. 일 실시 예에 따르면, 프로세서는 2차원 이미지로부터 획득(추출)한 프리 스페이스와 관련된 특징 정보를 이용하여 3차원 객체(예: 객체의 3차원 위치 정보)를 검출 시 가이드로서 활용할 수 있다. 이미지의 세그먼테 이션 태스크(task)는 후술하는 3차원 객체 검출 태스크(예: 객체의 3차원 위치 정보 검출 태스크)보다 상대적으 로 쉬운 태스크이기 때문에, 어텐션 매커니즘의 키(key)로 활용하기 용이할 수 있다. 즉, 프로세서는 상 대적으로 쉬운 세그먼테이션 태스크를 통하여 이미지 내에서 어텐션(attention)할 영역을 결정할 수 있다. 일 실시 예에 따르면, 프로세서는 2차원 이미지로부터 2차원 이미지에 포함된 객체와 관련된 특징 정보를 획득할 수 있다. 예를 들어, 객체와 관련된 특징 정보는 2차원 이미지로부터 추출한 3차원 객체 정보를 획득하 기 위한 특징을 포함할 수 있다. 예를 들어, 프로세서는 컨볼루션 신경망(convolutional neural network, CNN)의 계층 구조를 기반으로 2 차원 이미지로부터 객체와 관련된 특징 정보를 추출하는 백본망(backbone network)을 포함할 수 있다. 예를 들 어, CNN은 심층 신경망(deep neural network, DNN)의 한 종류로, 하나 이상의 컨볼루션 계층(convolution layer)과 통합 계층(pooling layer), 완전하게 연결된 계층(fully connected layer)들로 구성될 수 있다. CNN은 2차원 데이터(예: 2차원 이미지)의 학습에 적합한 구조를 가지고, 역전달 알고리즘(backpropagation algorithm)을 통해 훈련될 수 있다. 프로세서는 2차원 이미지에 대해 스케일 기반의 계층적 구조를 가지 는 백본망을 구성하고, 백본망을 통해 스케일별 데이터를 시계열 데이터로 치환하여 객체에 대한 특징 정보를 추출할 수 있다. 예를 들어, 프로세서는 앵커 기반 네트워크인 M3D-RPN(monocular 3D region proposal network)를 포함할 수 있고, 백본망은 M3D-RPN의 일부를 구성할 수 있다. 예를 들어, M3D-RPN은 2차원 이미지를 입력으로 수신하 고, 가상의 2차원 또는 3차원 앵커 박스(anchor)를 생성하고, 검출하려는 객체와 앵커 박스 사이의 정보 차이를 학습하여 3차원 객체를 검출하는 네트워크이다. 일 실시 예에 따르면, 프로세서는 어텐션 매커니즘(attention mechanism)을 이용하여, 프리 스페이스와 관 련된 특징 정보 및 객체와 관련된 특징 정보를 기반으로 어텐션 스코어(attention score)를 결정할 수 있다. 예 를 들어, 프로세서는 어텐션 매커니즘을 수행하는 어텐션 모듈을 포함할 수 있다. 어텐션 매커니즘은 예측 값을 내는 매 시점에 전체 입력을 다시 참고하여, 예측해야 할 값과 연관이 있는 것들 을 집중해서 참고하는 매커니즘으로, 영향을 받는 특징(쿼리(query)), 영향을 주는 특징(키(key)), 및 영향에 대한 가중치(값(value))를 이용하여 예측 결과를 출력하는 매커니즘이다. 예를 들어, 쿼리, 키, 및 값은 각각 행렬의 형태로 표현될 수 있다. 예를 들어, 어텐션 매커니즘에서, 예측 값에 대한 중요도(예: 어텐션 스코어 (attention score))는 쿼리와 키의 곱(내적)을 통하여 구해질 수 있다. 예를 들어, 프로세서는 백본망을 통하여 추출한 객체와 관련된 특징 정보로부터 쿼리 및 값을 추출할 수 있다. 프로세서는 이미지의 세그먼테이션을 통하여 획득한 세그먼테이션과 관련된 특징 정보로부터 키 값 을 추출할 수 있다. 일 실시 예에 따르면, 프로세서는, 프리 스페이스와 관련된 특징 정보를 기 저장된 세그먼테이션 레퍼런스 정보(예: 세그먼테이션 검증 자료(segmentation ground truth, segmentation GT))와 비교하여, 상기 프리 스페 이스와 관련된 특징 정보에 대한 세그먼테이션 손실(loss)을 결정할 수 있다. 세그먼테이션 GT는 세그먼테이션 과 관련된 특징 정보(예: 프리 스페이스 예측 결과)의 정확도를 검증하기 위한 기 저장된 데이터일 수 있다. 예를 들어, 세그먼테이션 손실은 세그먼테이션과 관련된 특징 정보(예: 프리 스페이스 예측 결과)를 세그먼테이 션 GT와 비교 분석하여 획득한 정확도 및/또는 오차 정보를 나타낼 수 있다. 프로세서는 세그먼테이션 손 실을 고려하여 프리 스페이스와 관련된 특징 정보로부터 키를 추출할 수 있다. 예를 들어, 프로세서는 객체와 관련된 특징 정보(예: 3차원 객체의 위치와 관련된 특징 정보)를 쿼리로 사 용하고, 세그먼테이션과 관련된 특징 정보를 키로 사용함으로써, 이미지 내의 프리 스페이스에 대한 영향도를 반영하여 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 프로세서는 객체와 관련된 특징 정보에서 프리 스페이스와 관련된 특징에 어텐션을 적용할 수 있다. 즉, 객체와 관련된 특징 정보 중에서 프리 스페이스와 유사한 특징을 갖는 특징일수록 어텐션 스코어가 더 큰 값을 가질 수 있다. 예를 들어, 이미지 내 객체의 거리(뎁스) 추정 시, 이미지 내 객체의 크기보다는 객 체의 위치가 더 큰 영향을 미치게 되며, 객체(예: 차량)는 지면과 맞닿아 있기 때문에 프리 스페이스 영역(예: 바닥 영역)에 특징을 고려할 경우, 객체의 거리 추정 시 정확도를 높일 수 있다. 프로세서는 어텐션 스코어를 기반으로 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 프로세서 는 어텐션 매커니즘에서 사용하는 값(value)을 쿼리와 동일하게 결정할 수 있다. 본 개시에서는 객체의 3 차원 위치 정보를 검출하는데 프리 스페이스와 관련된 키를 사용하는 것이 상대적으로 더 주요한 영향을 미치기 에 쿼리와 값이 동일한 경우를 가정하여 설명하나, 다양한 실시 예에 따르면, 프로세서는 어텐션 매커니즘 에서 사용하는 값(value)을 쿼리와 상이하게 결정할 수도 있다. 프로세서는 어텐션 스코어에 결정한 값을 가중치로 적용하여 어텐션 값(attention value)을 결정할 수 있 다. 예를 들어, 프로세서는 어텐션 스코어에 결정한 값을 곱(내적)하여 어텐션 값을 결정할 수 있다. 프 로세서는 어텐션 값을 디코딩하여 객체의 3차원 위치 정보를 검출할 수 있다. 일 실시 예에 따르면, 프로 세서는 3차원 객체의 위치 정보를 기 저장된 3차원 위치 레퍼런스 정보(예: 3차원 위치 ground truth)와 비교하여, 3차원 객체의 위치 정보의 손실(loss)을 결정할 수 있다. 프로세서는 3차원 객체의 위치 정보의 손실을 반영하여 최종적인 객체의 3차원 위치 정보를 검출할 수 있 다. 예를 들어, 3차원 위치 정보는 이미지 내 객체의 3차원 좌표 정보(예: (x3d, y3d, z3d))를 포함할 수 있다. 일 실시 예에 따르면, 프로세서는 어텐션 매커니즘을 이용함으로써, 객체의 3차원 위치 정보(예: 3 차원 거리)를 검출 시에, 3차원 객체의 뎁스 추정 시 영향도가 큰 프리 스페이스 여부를 반영하여 3차원 위치 정보 검출 성능을 향상시킬 수 있다. 일 실시 예에 따르면, 프로세서는 객체와 관련된 특징 정보에 기반하여 2차원 이미지로부터 객체의 2차원 디멘션 및/또는 3차원 디멘션(dimension)을 검출할 수 있다. 예를 들어, 객체의 2차원 디멘션은 이미지 내 객체의 2차원 크기(예: 폭(width) 및 높이(height))를 나타낼 수 있고, 3차원 디멘션은 이미지 내 객체의 3차원 크기(예: 폭(width), 높이(height), 및 길이(length))를 나타낼 수 있다. 객체의 2차원 디멘션 및 3차원 디멘 션은 객체의 2차원 및 3차원 중심점 정보를 더 포함할 수 있다. 프로세서는 객체와 관련된 특징 정보에 기반하여 2차원 이미지로부터 객체의 3차원 방향(예: 요(yaw))을 검출할 수 있다. 예를 들어, 프로세서는 3차원 객체 검출 장치(또는, 3차원 객체 검출 장치를 포함하는 차량)에 대한 이미지 내 객체의 각도를 검출할 수 있다. 예를 들어, 프로세서는 백본망을 통하 여 추출된 이미지 내 객체들에 대한 특징 정보를 이용하여 객체의 디멘션 및/또는 방향의 예측 값을 획득할 수 있다. 일 실시 예에 따르면, 프로세서는 객체의 디멘션 및/또는 방향의 예측 결과를 기 저장된 디멘션 레퍼런스 정보(디멘션 ground truth) 및/또는 방향 레퍼런스 정보(예: 방향 ground truth)와 비교하여, 객체의 디멘션 및 /또는 방향 예측 결과의 손실(loss)을 결정할 수 있다. 프로세서는 디멘션 및/또는 방향 예측 결과의 손 실을 반영하여 최종적으로 객체의 디멘션 정보 및/또는 방향 정보를 검출할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 3차원 객체 검출 장치의 구성을 도시한 도면이다. 예를 들어, 도 2는 3차 원 객체 검출 장치의 프로세서에 포함되거나, 또는 프로세서에 의해 구현되는 3차원 객체 검출 네트 워크를 도시한다. 예를 들어, 도 2의 3차원 객체 검출 네트워크는 프로세서에 의해 훈련(학 습)되는 3차원 객체 검출 모델 및/또는 인공지능 신경망(artificial neural network)을 나타낼 수 있다. 일 실시 예에 따르면, 3차원 객체 검출 네트워크는 백본망(backbone network), 세그먼테이션 네트워 크(segmentation network), 3차원 위치 검출 네트워크(3D location detection network), 및 디멘션/ 방향 검출 네트워크(dimension/orientation detection network)를 포함할 수 있다. 예를 들어, 3차원 객 체 검출 네트워크 중 적어도 일부(예: 백본망, 3차원 위치 검출 네트워크, 및 디멘션/방향 검출 네트워크)는 M3D-RPN(monocular 3D region proposal network)를 기반으로 구성될 수 있다. 일 실시 예에 따르면, 백본망은 컨볼루션 신경망(convolutional neural network, CNN)의 계층 구조를 기 반으로 2차원 이미지로부터 객체와 관련된 특징 정보를 추출할 수 있다. 예를 들어, 백본망은 심층 신경망 (deep neural network, DNN)으로서, 하나 이상의 컨볼루션 계층(convolution layer)과 통합 계층(pooling layer), 완전하게 연결된 계층(fully connected layer)들로 구성될 수 있다. 백본망은 2차원 데이터(예: 2차원 이미지)의 학습에 적합한 구조를 가지고, 역전달 알고리즘(backpropagation algorithm)을 통해 훈련될 수 있다. 백본망은 3차원 객체 검출 장치의 카메라로부터 2차원 이미지를 입력으로 수신할 수 있다. 예 를 들어, 백본망은 2차원 이미지로부터 특징 맵(feature map)을 추출할 수 있다. 백본망은 2차원 이 미지에 대해 스케일 기반의 계층적 구조를 구성하고, 스케일별 데이터를 시계열 데이터로 치환하여 이미지로부 터 객체에 대한 특징 정보를 추출할 수 있다. 백본망은 이미지로부터 추출한 세그먼테이션과 관련된 특징 정보(예: 이미지의 세그먼테이션 결과 생성한 정보)를 세그먼테이션 네트워크에 전달할 수 있다. 백본망 은 이미지로부터 추출한 객체와 관련된 특징 정보를 3차원 위치 검출 네트워크, 및 디멘션/방향 검출 네트워크에 전달할 수 있다. 일 실시 예에 따르면, 세그먼테이션 네트워크는 프리 스페이스 예측(free space prediction) 모듈 및 세그 먼테이션 레퍼런스 정보를 포함할 수 있다. 예를 들어, 프리 스페이스 예측 모듈은 백본망으로 부터 수신한 정보를 기반으로 이미지 내 각 영역에 대한 프리 스페이스 여부를 예측할 수 있다. 예를 들어, 프 리 스페이스 예측 모듈은 2차원 이미지를 세그먼테이션하여 구분된 복수 개의 영역 대해 프리 스페이스의 예측(prediction)을 수행하고, 예측 결과에 기반하여 프리 스페이스와 관련된 특징 정보를 획득할 수 있다. 예 를 들어, 프리 스페이스와 관련된 특징 정보는 이미지 내의 각 영역이 프리 스페이스에 해당하는지를 나타내는 신뢰도(confidence)를 포함할 수 있다. 예를 들어, 프로세서가 예측한 신뢰도가 높을수록 2차원 이미지 내의 해당 영역이 프리 스페이스일 가능성이 높음을 나타낼 수 있다. 예를 들어, 2차원 이미지에서 3차원 객체(예: 객체의 3차원 위치 정보)를 검출함에 있어서, 이미지 내 객체의 위치 또는 크기가 영향을 미칠 수 있으며, 이미지 내 객체의 위치 및 크기 중에서 상대적으로 객체의 위치가 객 체의 거리 추정 시에 더 큰 영향을 주는 요소일 수 있다. 또한, 이미지 내 검출되는 객체는 지면과 맞닿아 있기 때문에, 프리 스페이스 영역으로 활용 가능하다. 일 실시 예에 따르면, 프리 스페이스 예측 모듈은 2차원 이미지로부터 획득(추출)한 프리 스페이스와 관련 된 특징 정보를 어텐션 모듈에 제공하여 어텐션 모듈이 3차원 객체(예: 객체의 3차원 위치 정보)를 검출 시 가이드로서 활용하도록 할 수 있다. 예를 들어, 프리 스페이스 예측 모듈은 프리 스페이스와 관 련된 특징 정보로부터 어텐션 모듈에 제공할 키(key)를 추출할 수 있다. 프리 스페이스 예측 모듈은, 프리 스페이스와 관련된 특징 정보를 기 저장된 세그먼테이션 레퍼런스 정보(예: 세그먼테이 션 검증 자료(segmentation ground truth, segmentation GT))와 비교하여, 프리 스페이스와 관련된 특징 정보 에 대한 세그먼테이션 손실(loss)을 결정할 수 있다. 세그먼테이션 GT는 세그먼테이션과 관련된 특징 정보(예: 프리 스페이스 예측 결과)의 정확도를 검증하기 위한 기 저장된 데이터일 수 있다. 예를 들어, 세그먼테이션 손실은 세그먼테이션과 관련된 특징 정보(예: 프리 스 페이스 예측 결과)를 세그먼테이션 GT와 비교 분석하여 획득한 정확도 및/또는 오차 정보를 나타낼 수 있다. 프리 스페이스 예측 모듈은 세그먼테이션 손실을 고려하여 프리 스페이스와 관련된 특징 정보로부터 키 (key)를 추출하고, 키를 어텐션 모듈에 전달할 수 있다. 일 실시 예에 따르면, 3차원 위치 검출 네트워크는 3차원 위치 검출 모듈, 어텐션 모듈, 및 3차 원 위치 정보 레퍼런스 정보를 포함할 수 있다. 3차원 위치 검출 모듈은 백본망으로부터 수신 한 객체에 관련된 특징 정보로부터 어텐션 모듈에 제공할 쿼리(query) 및 값(value)를 추출할 수 있다. 일 실시 예에 따르면, 어텐션 모듈은 어텐션 매커니즘(attention mechanism)을 이용하여, 프리 스페이스와 관련된 특징 정보 및 객체와 관련된 특징 정보를 기반으로 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 어텐션 모듈은 하기의 수학식 1을 이용하여 어텐션 스코어를 결정할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예를 들어, 어텐션 모듈은 객체와 관련된 특징 정보(예: 3차원 객체의 위치와 관련된 특징 정보)를 쿼리로 사용하고, 세그먼테이션과 관련된 특징 정보를 키로 사용함으로써, 이미지 내의 프리 스페이스에 대한 영향도를 반영하여 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 어텐션 모듈은 객체와 관련된 특징 정보에서 프리 스페이스와 관련된 특징에 어텐션을 적용할 수 있다. 예를 들어, 객체와 관련된 특징 정보 중에서 프리 스페이스와 유사한 특징을 갖는 특징일수록 어텐션 스코어가 더 큰 값을 가질 수 있다. 예를 들어, 이미지 내 객체의 거리(뎁스) 추정 시, 이미지 내 객체의 크기 보다는 객체의 위치가 더 큰 영향을 미치게 되며, 객체(예: 차량)는 지면과 맞닿아 있기 때문에 프리 스페이스 영역(예: 바닥 영역)에 특징을 고려할 경우, 객체의 거리 추정 시 정확도를 높일 수 있다. 어텐션 모듈은 어텐션 스코어를 기반으로 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 어텐션 모듈은 어텐션 스코어를 기반으로 어텐션 값을 결정하고, 어텐션 값을 디코딩하여 3차원 위치 정보를 검출 할 수 있다. 어텐션 매커니즘은 예측 값을 내는 매 시점에 전체 입력을 다시 참고하여, 예측해야 할 값과 연관 이 있는 것들을 집중해서 참고하는 매커니즘으로, 영향을 받는 특징(쿼리(query)), 영향을 주는 특징(키(key)), 및 영향에 대한 가중치(값(value))를 이용하여 예측 결과(예: 3차원 위치 정보의 예측/추정 결과)를 출력하는 매커니즘이다. 쿼리, 키, 및 값은 각각 행렬의 형태로 표현될 수 있다. 예를 들어, 어텐션 모듈은 하기의 수학식 2를 이용하여 어텐션 값을 결정할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0042186", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 수학식 2에서, 는 스케일 조절 팩터(factor)로서 쿼리 및/또는 키 행렬의 크기에 대응하여 결정될 수 있다. 실질적으로 어텐션 값은 어텐션 스코어와 값의 곱에 비례하고, 어텐션 모듈은 어텐션 스코어를 기반 으로 3차원 위치 정보에 어텐션(중요도)을 적용할 수 있다. 어텐션 모듈은 수학식 2를 통하여 결정한 어텐션 값을 디코딩하여 객체의 3차원 위치 정보를 획득할 수 있 다. 예를 들어, 3차원 위치 정보는 3차원 좌표 정보(예: (x3d, y3d, z3d))를 포함할 수 있다. 어텐션 모듈 은 획득한 객체의 3차원 위치 정보를 기 저장된 3차원 위치 레퍼런스 정보(예: 3차원 위치 ground truth) 와 비교 분석하여, 객체의 3차원 위치 정보의 손실(loss)을 결정할 수 있다. 프로세서는 객체의 3차원 위치 정보의 손실을 반영하여 최종 객체의 3차원 위치 정보를 검출할 수 있다. 일 실시 예에 따르면, 3차원 위치 검출 네트워크는 객체의 3차원 위치 정보(예: 3차원 거리)를 검출 시, 어텐션 모듈을 통하여 3차원 객체의 뎁스 추정 시 영향도가 큰 프리 스페이스와 관련된 특징을 반영하여 3 차원 위치 정보 검출 성능을 향상시킬 수 있다. 일 실시 예에 따르면, 디멘션/방향 검출 네트워크는 디멘션/방향 검출 모듈 및 디멘션/방향 레퍼런스 를 포함할 수 있다. 일 실시 예에 따르면, 디멘션/방향 검출 모듈은 백본망으로부터 획득한 객체와 관련된 특징 정보(예: 특징 맵)을 기반으로 이미지 내 객체의 2차원 디멘션, 3차원 디멘션, 및/또는 3차원 방향을 추정할 수 있다. 예를 들어, 객체의 2차원 디멘션은 이미지 내 객체의 2차원 크기(예: 폭(width) 및 높이(height))를 나타낼 수 있고, 3차원 디멘션은 이미지 내 객체의 3차원 크기(예: 폭(width), 높이(height), 및 길이(length))를 나타낼 수 있다. 객체의 2차원 디멘션 및 3차원 디멘션은 객체의 2차원 및 3차원 중심점 정보를 더 포함할 수 있다. 예를 들어, 객체의 방향은 3차원 객체 검출 장치(또는, 3차원 객체 검출 장치를 포함하는 차량)에 대한 이미지 내 객체의 각도(예: 요(yaw))를 나타낼 수 있다. 예를 들어, 디멘션/방향 검출 모듈은 백본망을 통하 여 추출된 이미지 내 객체들에 대한 특징 정보를 이용하여 객체의 디멘션 및/또는 방향의 예측 값을 획득할 수 있다. 일 실시 예에 따르면, 디멘션/방향 검출 모듈은 객체의 디멘션 및/또는 방향의 예측 결과를 기 저장된 디 멘션 레퍼런스 정보(디멘션 ground truth) 및/또는 방향 레퍼런스 정보(예: 방향 ground truth)와 비교하 여, 객체의 디멘션 및/또는 방향 예측 결과의 손실(loss)을 결정할 수 있다. 디멘션/방향 검출 모듈은 디 멘션 및/또는 방향 예측 결과의 손실을 반영하여 최종적으로 객체의 2D 및 3D 디멘션 정보 및/또는 3D 방향 정 보를 검출할 수 있다. 이하, 도 3을 참조하여 본 발명의 일 실시 예에 따른 3차원 객체 검출 방법을 구체적으로 설명하기로 한다. 도 3은 본 발명의 일 실시 예에 따른 3차원 객체 검출 방법을 설명하기 위한 순서도이다. 이하에서는 도 1의 3차원 객체 검출 장치가 도 3의 프로세스를 수행하는 것을 가정한다. 또한, 도 3의 설 명에서, 장치에 의해 수행되는 것으로 기술된 동작은 3차원 객체 검출 장치의 프로세서에 의해 제어 되는 것으로 이해될 수 있다. 일 실시 예에 따르면, 310 단계에서, 3차원 객체 검출 장치는 카메라를 이용하여 2차원 이미지를 획득할 수 있 다. 일 실시 예에 따르면, 카메라는 2차원 이미지를 획득할 수 있다. 카메라는 하나의 렌즈를 가지는 단안 (monocular) 카메라일 수 있다. 2차원 이미지는 단안 카메라를 이용하여 획득된 단안 이미지일 수 있다. 일 실시 예에 따르면, 320 단계에서, 3차원 객체 검출 장치는 2차원 이미지를 세그먼테이션(segmentation)하여 프리 스페이스(free space)와 관련된 특징(feature) 정보를 획득할 수 있다. 예를 들어, 프리 스페이스는 2차원이미지에 포함된 객체들 중 지면과 관련된 객체를 의미할 수 있다. 예를 들어, 3차원 객체 검출 장치는 2차원 이미지를 세그먼테이션하여 복수 개의 영역으로 구분하고, 복수 개의 영역에 대해 프리 스페이스의 예측 (prediction)을 수행할 수 있다. 3차원 객체 검출 장치는 프리 스페이스의 예측 동작 결과에 기반하여 프리 스 페이스와 관련된 특징 정보를 획득할 수 있다. 예를 들어, 프리 스페이스와 관련된 특징 정보는 이미지 내의 각 영역이 프리 스페이스에 해당하는지를 나타내 는 예측 결과(예: 신뢰도(confidence))을 포함할 수 있다. 일 실시 예에 따르면, 3차원 객체 검출 장치는 2차원 이미지로부터 획득(추출)한 프리 스페이스와 관련된 특징 정보를 이용하여 3차원 객체(예: 객체의 3차원 위치 정보)를 검출 시 영향을 미치는 요인(factor)으로서 활용할 수 있다. 일 실시 예에 따르면, 330 단계에서, 3차원 객체 검출 장치는 2차원 이미지로부터 2차원 이미지에 포함된 객체 와 관련된 특징 정보를 획득할 수 있다. 예를 들어, 객체와 관련된 특징 정보는 2차원 이미지로부터 추출한 3 차원 객체 정보를 획득하기 위한 특징을 포함할 수 있다. 예를 들어, 3차원 객체 검출 장치는 컨볼루션 신경망(convolutional neural network, CNN)의 계층 구조를 기반 으로 하는 백본망(backbone network)을 이용하여 상기 2차원 이미지로부터 상기 객체와 관련된 특징 정보를 추 출할 수 있다. 3차원 객체 검출 장치는 2차원 이미지에 대해 스케일 기반의 계층적 구조를 가지는 백본망을 구 성하고, 백본망을 통해 스케일별 데이터를 시계열 데이터로 치환하여 객체에 대한 특징 정보를 추출할 수 있다. 일 실시 예에 따르면, 340 단계에서, 3차원 객체 검출 장치는 어텐션 매커니즘(attention mechanism)을 이용하 여, 프리 스페이스와 관련된 특징 정보 및 객체와 관련된 특징 정보를 기반으로 어텐션 스코어(attention score)를 결정할 수 있다. 어텐션 매커니즘은 예측 값을 내는 매 시점에 전체 입력을 다시 참고하여, 예측해야 할 값과 연관이 있는 것들을 집중해서 참고하는 매커니즘으로, 영향을 받는 특징(쿼리(query)), 영향을 주는 특 징(키(key)), 및 영향에 대한 가중치(값(value))를 이용하여 예측 값을 출력할 수 있다. 쿼리, 키, 및 값은 각 각 행렬의 형태로 표현될 수 있다. 예를 들어, 어텐션 매커니즘에서, 예측 값에 대한 중요도(예: 어텐션 스코어(attention score))는 쿼리와 키의 곱(내적)을 통하여 구해질 수 있다. 예를 들어, 3차원 객체 검출 장치는 백본망을 통하여 추출한 객체와 관련 된 특징 정보로부터 쿼리(query) 및 값(value)을 추출할 수 있다. 3차원 객체 검출 장치는 이미지의 세그먼테이션을 통하여 획득한 세그먼테이션과 관련된 특징 정보로부터 키 (key)를 추출할 수 있다. 일 실시 예에 따르면, 3차원 객체 검출 장치는, 프리 스페이스와 관련된 특징 정보를 기 저장된 세그먼테이션 레퍼런스 정보(예: 세그먼테이션 검증 자료(segmentation ground truth, segmentation GT))와 비교하여, 상기 프리 스페이스와 관련된 특징 정보에 대한 세그먼테이션 손실(loss)을 결정할 수 있다. 세그먼테이션 GT는 세그먼테이션과 관련된 특징 정보(예: 프리 스페이스 예측 결과)의 정확도를 검증하기 위한 기 저장된 데이터일 수 있다. 예를 들어, 세그먼테이션 손실은 세그먼테이션과 관련된 특징 정보(예: 프리 스 페이스 예측 결과)를 세그먼테이션 GT와 비교 분석하여 획득한 정확도 및/또는 오차 정보를 나타낼 수 있다. 3차원 객체 검출 장치는 세그먼테이션 손실을 고려하여 프리 스페이스와 관련된 특징 정보로부터 키를 추출하 수 있다. 예를 들어, 3차원 객체 검출 장치는 객체와 관련된 특징 정보(예: 3차원 객체의 위치와 관련된 특징 정보)를 쿼리로 사용하고, 세그먼테이션과 관련된 특징 정보를 키로 사용함으로써, 이미지 내의 프리 스페이스 에 대한 영향도를 반영하여 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 3차원 객체 검출 장치는 객체와 관련된 특징 정보에서 프리 스페이스와 관련된 특징에 가중치를 부 여할 수 있다. 즉, 객체와 관련된 특징 정보 중에서 프리 스페이스와 유사한 특징을 갖는 특징일수록 어텐션 스코어가 더 큰 값을 가질 수 있다. 예를 들어, 이미지 내 객체의 거리(뎁스) 추정 시, 이미지 내 객체의 크기 보다는 객체의 위치가 더 큰 영향을 미치게 되며, 객체(예: 차량)는 지면과 맞닿아 있기 때문에 프리 스페이스 영역(예: 바닥 영역)에 특징을 고려할 경우, 객체의 거리 추정 시 정확도를 높일 수 있다. 일 실시 예에 따르면, 350 단계에서, 3차원 객체 검출 장치는 어텐션 스코어를 기반으로 객체의 3차원 위치 정 보를 검출할 수 있다. 예를 들어, 3차원 객체 검출 장치는 어텐션 스코어에 어텐션 매커니즘에서 사용하는 값 (value)를 곱(내적)하여 어텐션 값(attention value)을 결정하고, 어텐션 값을 디코딩하여 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 3차원 객체 검출 장치는 어텐션 매커니즘에서 사용하는 값(value)을 쿼리와 동일하게 결정할 수 있 다. 본 개시에서는 객체의 3차원 위치 정보를 검출하는데 프리 스페이스와 관련된 키를 사용하는 것이 상대적 으로 더 주요한 영향을 미치기에 쿼리와 값이 동일한 경우를 가정하여 설명하나, 다양한 실시 예에 따르면, 3차 원 객체 검출 장치는 어텐션 매커니즘에서 사용하는 값(value)을 쿼리와 상이하게 결정할 수도 있다. 3차원 객 체 검출 장치는 어텐션 스코어에 결정한 값을 가중치로 적용하여 어텐션 값을 결정할 수 있다. 일 실시 예에 따르면, 3차원 객체 검출 장치는 3차원 객체의 위치 정보를 기 저장된 3차원 위치 레퍼런스 정보 (예: 3차원 위치 ground truth)와 비교하여, 3차원 객체의 위치 정보의 손실(loss)을 결정할 수 있다. 3차원 객체 검출 장치는 3차원 객체의 위치 정보의 손실을 반영하여 최종적으로 객체의 3차원 위치 정보를 검출할 수 있다. 예를 들어, 3차원 위치 정보는 이미지 내 객체의 3차원 좌표 정보(예: (x3d, y3d, z3d))를 포함할 수 있 다. 일 실시 예에 따르면, 3차원 객체 검출 장치는 어텐션 매커니즘을 이용함으로써, 객체의 3차원 위치 정보(예: 3 차원 거리)를 검출 시에, 3차원 객체의 뎁스 추정 시 영향도가 큰 프리 스페이스 여부를 반영하여 3차원 위치 정보 검출 성능을 향상시킬 수 있다. 일 실시 예에 따르면, 도 3에 도시되지는 않았으나, 3차원 객체 검출 장치는 객체와 관련된 특징 정보에 기반하 여 2차원 이미지로부터 객체의 2차원 및 3차원 디멘션(dimension)을 검출하거나, 및/또는 객체와 관련된 특징 정보에 기반하여 상기 2차원 이미지로부터 객체의 방향을 더 검출할 수 있다. 예를 들어, 3차원 객체 검출 장 치는 이미지 내 객체의 3차원 위치, 디멘션, 및 방향을 검출함으로써, 3차원 객체를 검출할 수 있다. 도 4는 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 도시한다. 도 4를 참조하면, 컴퓨팅 시스템은 버스를 통해 연결되는 적어도 하나의 프로세서, 메모리 , 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치, 스토리지, 및 네트워 크 인터페이스를 포함할 수 있다. 프로세서는 중앙 처리 장치(CPU) 또는 메모리 및/또는 스토리지에 저장된 명령어들에 대한 처리를 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 종류의 휘발성 또는 불휘발 성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(Read Only Memory) 및 RAM(Random Access Memory)을 포함할 수 있다. 따라서, 본 명세서에 개시된 실시 예들과 관련하여 설명된 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM과 같은 저장 매체(즉, 메모리 및/또는 스토리지)에 상주할 수도 있다. 예시적인 저장 매체는 프로세서에 커플링되며, 그 프로세서는 저장 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 저장 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 저장 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수 도 있다. 다른 방법으로, 프로세서 및 저장 매체는 사용자 단말기 내에 개별 컴포넌트로서 상주할 수도 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아 래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2022-0042186", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 3차원 객체 검출 장치를 도시한 블록도이다. 도 2는 본 발명의 일 실시 예에 따른 3차원 객체 검출 장치의 구성을 도시한 도면이다. 도 3은 본 발명의 일 실시 예에 따른 3차원 객체 검출 방법의 순서도이다. 도 4는 본 발명의 일 실시 예에 따른 컴퓨팅 시스템을 도시한다."}
