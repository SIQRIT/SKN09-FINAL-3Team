{"patent_id": "10-2023-0197634", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0156936", "출원번호": "10-2023-0197634", "발명의 명칭": "인공지능 추론을 위한 비선형 다차원 비용 함수", "출원인": "삼성전자주식회사", "발명자": "샤브타이 오메르"}}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "계산 그래프에 대한 알고리즘을 획득하는 단계;하드웨어 장치를 사용하여 상기 알고리즘을 수행하기 위한 성능 파라미터에 대한 초기 선형화 메트릭을 계산하는 단계;상기 초기 선형화된 메트릭과 상기 성능 파라미터에 대한 비선형 제약에 기초하여 업데이트된 선형화된 메트릭을 계산하는 단계; 및상기 업데이트된 선형화된 메트릭에 기초하여 상기 계산 그래프를 구현하도록 상기 하드웨어 장치를 프로그래밍하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 계산 그래프의 복수의 계층들을 식별하는 단계;상기 복수의 계층들을 복수의 시퀀스들로 그룹핑하는 단계; 및상기 복수의 시퀀스들로부터의 시퀀스들의 서브세트를 식별하기 위해 동적 프로그래밍 프로세스를 수행 - 상기초기 선형화된 메트릭은 시퀀스들의 서브세트에 기초하고, 상기 동적 프로그래밍 프로세스는 상기 성능 파라미터에 대한 선형성 제약에 기초함 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 복수의 계층들의 타일링(tiling)을 식별 - 상기 하드웨어 장치는 상기 타일링에 기초하여 프로그래밍됨 -하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 복수의 시퀀스들로부터 업데이트된 시퀀스들의 서브세트를 식별하기 위해 추가적인 동적 프로그래밍 프로세스를 수행 - 상기 업데이트된 선형화된 메트릭은 상기 업데이트된 시퀀스들의 서브세트에 기초하고, 상기 하드웨어 장치는 상기 업데이트된 시퀀스들의 서브세트에 기초하여 프로그래밍됨 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 성능 파라미터에 대한 초기 가중치를 결정하는 단계; 및상기 초기 선형화된 메트릭 및 상기 초기 가중치에 기초하여 상기 시퀀스들의 서브세트에 대한 초기 스코어를계산하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 초기 가중치를 포함하는 복수의 초기 가중치에 기초하여 상기 초기 선형화된 메트릭을 포함하는 복수의 선형화된 메트릭의 가중 합계를 계산 - 상기 초기 스코어는 상기 가중 합계에 기초함 - 하는 단계를 더 포함하는,공개특허 10-2024-0156936-3-방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 초기 스코어에 기초하여 상기 성능 파라미터에 대한 업데이트된 가중치를 결정하는 단계; 및상기 업데이트된 가중치 및 상기 업데이트된 선형화된 메트릭에 기초하여 상기 시퀀스들의 서브세트에 대한 업데이트된 스코어를 계산 - 상기 시퀀스들의 서브세트는 상기 업데이트된 스코어에 기초하여 선택됨 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,시퀀스들의 복수의 서브세트들에 대한 스코어들을 계산 - 상기 시퀀스들의 서브세트는 상기 스코어들에 기초하여 상기 시퀀스들의 복수의 서브세트들로부터 선택됨 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항에 있어서, 상기 초기 가중치 및 상기 비선형 제약에 기초하여 비선형 항을 계산 - 상기 초기 스코어는 상기 비선형 항에기초함 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 업데이트된 선형화된 메트릭에 기초하여 상기 알고리즘을 수행하기 위한 명령어들을 컴파일링 - 상기 하드웨어 장치는 상기 컴파일된 명령어들에 기초하여 프로그래밍됨 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 업데이트된 선형화된 메트릭에 기초하여 상기 하드웨어 장치에 대한 설계를 수정 - 상기 하드웨어 장치는상기 수정된 설계에 기초하여 프로그래밍됨 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 업데이트된 선형화된 메트릭에 기초하여 상기 계산 그래프에 대한 알고리즘을 수정 - 상기 하드웨어 장치는 상기 수정된 알고리즘에 기초하여 프로그래밍됨 - 하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "프로세서, 및 명령어들을 저장하고 상기 프로세서와 전자 통신하는 메모리를 포함하는 장치로서, 상기 프로세서는:계산 그래프에 대한 알고리즘을 획득하고;하드웨어 장치를 사용하여 상기 알고리즘을 수행하기 위한 성능 파라미터에 대한 초기 선형화 메트릭을 계산하고;상기 초기 선형화 메트릭, 및 상기 성능 파라미터에 대한 비선형 제약에 기초하여 업데이트된 선형화 메트릭을계산하고;상기 업데이트된 선형화된 메트릭에 기초하여 상기 계산 그래프를 구현하도록 상기 하드웨어 장치를 프로그래밍하도록 하는,명령어들을 실행하도록 구성되는, 장치.공개특허 10-2024-0156936-4-청구항 14 제13항에 있어서, 상기 프로세서는: 상기 계산 그래프의 복수의 계층을 식별하고;상기 복수의 계층을 복수의 시퀀스들로 그룹핑하고;동적 프로그래밍 프로세스를 수행하여 상기 복수의 시퀀스들로부터 시퀀스들의 서브세트를 식별 - 상기 초기 선형화된 메트릭은 상기 시퀀스들의 서브세트에 기초하고, 상기 동적 프로그래밍 프로세스는 상기 성능 파라미터에 대한 선형성 제약에 기초함 - 하도록 하는,명령어들을 실행하도록 더 구성되는, 장치."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 프로세서는:상기 복수의 계층들의 타일링을 식별 - 상기 하드웨어 장치는 상기 타일링에 기초하여 프로그래밍됨 - 하도록하는,명령어들을 실행하도록 더 구성되는, 장치."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 프로세서는:상기 복수의 시퀀스들로부터 업데이트된 시퀀스들의 서브세트를 식별하기 위해 추가적인 동적 프로그래밍 프로세스를 수행 - 상기 업데이트된 선형화된 메트릭은 상기 업데이트된 시퀀스들의 서브세트에 기초하고, 상기 하드웨어 장치는 상기 업데이트된 시퀀스들의 서브세트에 기초하여 프로그래밍됨 - 하도록 하는,명령어들을 실행하도록 더 구성되는, 장치."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 프로세서는:상기 성능 파라미터를 위한 초기 가중치를 결정하고;상기 초기 선형화된 메트릭 및 상기 초기 가중치에 기초하여 상기 시퀀스들의 서브세트에 대한 초기 스코어를계산하도록 하는,명령어들을 실행하도록 더 구성되는, 장치."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 프로세서는:상기 초기 가중치를 포함하는 복수의 초기 가중치들에 기초하여 상기 초기 선형화된 메트릭을 포함하는 복수의선형화된 메트릭의 가중 합계를 계산 - 상기 초기 스코어는 가중 합계에 기초함 - 하도록 하는,명령어들을 실행하도록 더 구성되는, 장치."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 공개특허 10-2024-0156936-5-상기 프로세서는: 상기 초기 스코어에 기초하여 상기 성능 파라미터에 대한 업데이트된 가중치를 결정하고;상기 업데이트된 가중치 및 상기 업데이트된 선형화된 메트릭에 기초하여 상기 시퀀스들의 서브세트에 대한 업데이트된 스코어를 계산 - 상기 시퀀스들의 서브세트는 상기 업데이트된 스코어에 기초하여 선택됨 - 하도록 하는,명령어들을 실행하도록 더 구성되는, 장치."}
{"patent_id": "10-2023-0197634", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "코드를 저장하는 비일시적 컴퓨터 판독가능 매체로서, 상기 코드는 프로세서에 의해 실행가능한 명령어들을 포함하며, 상기 명령어들은:계산 그래프에 대한 알고리즘을 획득하고;하드웨어 장치를 사용하여 상기 알고리즘을 수행하기 위한 성능 파라미터에 대한 초기 선형화 메트릭을 계산하고;상기 초기 선형화 메트릭 및 상기 성능 파라미터에 대한 비선형 제약에 기초하여 업데이트된 선형화 메트릭을계산하고;상기 업데이트된 선형화된 메트릭에 기초하여 상기 계산 그래프를 구현하도록 상기 하드웨어 장치를 프로그래밍하도록 하는 것인, 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 시스템들 및 기법들은 컴파일러가 그러한 트레이드오프들을 최적화할 수 있게 하고, 또한 특정 사용자 비용 함수에 대한 최적화(예를 들어, 복잡한 다차원 및 비선형 문제의 최적화)를 가능하게 한다. 또한, 본 발명 에 기술된 기법들은 다항 시간 내에 최적화될 수 있다. 따라서, 추론 작업들은 전력 소비, 유휴 시간, 계산의 효 율성, 시스템 자원 등의 관점에서 (예를 들어, 특정 애플리케이션들에 기초하여) 최적화될 수 있다. 예를 들어, 본 발명에 기술된 시스템들 및 기법들을 활용함으로써, 하드웨어 설계자들은 전문화된 작업들의 효율적인 처리에 서 중요한 요소들인 런타임, 전력 소비, 및 자원 사용 간의 트레이드오프의 균형을 맞출 수 있다."}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다음은 일반적으로 인공 지능(AI) 추론 최적화에 관한 것으로, 보다 상세하게는 인공 지능 추론 엔진을 위한 복 잡한 비선형 다차원 비용 함수(non-linear multi-dimensional cost function)에 관한 것이다."}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "AI는 자동화, 데이터 분석 및 의사결정을 가능하게 함으로써 다양한 산업을 변화시켜 왔다. 일부 양태들에서, AI 모델들은 신경망들을 통한 대량의 데이터의 처리를 포함할 수 있는 머신 러닝 기술들을 사용하여 구축된다. 예로서, AI 추론은 이전에 학습된 패턴들에 기초하여 예측 또는 결정들을 내리는 것과 같은 프로세스들을 포함 한다. 그러한 것은 새로운 데이터를 머신 러닝 모델에 공급하는 것을 포함할 수 있고, 머신 러닝 모델은 그 다 음 알고리즘들을 사용하여 데이터를 분석 및 해석한다 (예를 들어, 예측 또는 결정으로 이어짐). 머신 러닝 모 델은 유사한 데이터의 큰 데이터세트에 대해 트레이닝될 수 있고, 머신 러닝 모델이 패턴들을 인식 및 분류하고 새로운 데이터에 기초하여 예측을 하도록 할 수 있다. 일부 측면에서, 전통적인 하드웨어(예를 들어, 전통적인 중앙 처리 장치(CPU) 하드웨어)는 AI 추론의 고성능 요 구 사항에 최적화되지 않을 수 있으므로, 성능 및 효율을 향상시키기 위해 전문화된 하드웨어가 개발되었다. 일 부 경우, 그래픽 처리 장치(GPU), 필드-프로그래밍 가능 게이트 어레이(FPGA) 및 애플리케이션-특정 집적 회로 (ASIC)는 AI 추론 작업의 처리를 가속화하기 위해 전문화(예를 들어, 재구성, 최적화 등)될 수 있다. 예를 들어, GPU는 병렬 처리를 수행하는 능력으로 인해 AI 추론을 수행하도록 적응될 수 있고, FPGA는 특정 AI 추론 작업을 수행하도록 프로그래밍될 수 있으며, ASIC는 특정 AI 추론 작업을 수행하도록 설계된 맞춤형 구축 회로 등일 수 있다. 그러나, 추론은 런타임(예를 들어, 계산 레이턴시), 전력(예를 들어, 전력 소비 및/또는 배터리 요구 사항), 시 스템 자원(예를 들어, 메모리 대역폭, 하드웨어 영역) 등의 관점에서 비용이 많이 들 수 있다. 다양한 처리 기 술 및 하드웨어 설계 고려 사항에 대하여 특수 처리 유닛, 메모리 계층들 및 아키텍처 최적화를 사용하여 이러 한 트레이드오프의 균형을 맞추려는 시도를 할 수 있다. AI의 사용이 계속해서 증가함에 따라, 보다 효율적이고보다 강력한 AI 솔루션에 대한 필요가 증가하고 있다. 인공 지능 추론 엔진을 위한 복잡한 비선형 다차원 비용 함수를 위한 방법, 장치, 비일시적 컴퓨터 판독 가능 매체 및 시스템이 기술된다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체 및 시스템의 하나 이상의 양태는 계 산 그래프에 대한 알고리즘을 획득하는 단계; 하드웨어 장치를 사용하여 알고리즘을 수행하기 위한 성능 파라미 터에 대한 초기 선형화된 메트릭을 계산하는 단계; 초기 선형화된 메트릭(initial lineaized metric) 및 성능 파라미터에 대한 비선형 제약(non-linear constraint)에 기초하여 업데이트된 선형화된 메트릭을 계산하는 단계; 및 업데이트된 선형화된 메트릭에 기초하여 계산 그래프를 구현하도록 하드웨어 장치를 프로그래밍하는 단계를 포함한다."}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "인공 지능(AI)은 이미지 및 음성 인식으로부터 자연어 처리 및 자율 시스템에 이르기까지 많은 현대 응용의 필 수 부분이 되었다. AI 기술은 종종 트레이닝 및 추론과 같은 작업을 처리하는 것을 포함할 수 있다. 예를 들어, 트레이닝 프로세스는 AI 모델이 대량의 데이터에 노출됨으로써 특정 작업을 수행하도록 가르치는 것을 포 함할 수 있다. 트레이닝 프로세스 동안, AI 모델은 데이터에서 패턴 및 관계를 식별하는 것을 학습하고, 그 모 델은 이러한 트레이닝을 사용하여 새로운(예를 들어, 보이지 않는) 데이터를 사용하여 예측 또는 결정을 내린다. AI 추론은 입력 데이터에 기초하여 결정 또는 예측을 하기 위해 새로운 입력 데이터를 처리하는 트레이 닝된 AI 모델을 사용하는 것을 포함한다. 효율적이고 정확한 AI 추론을 가능하게 하기 위해, 특화된 처리 기술들 및 특화된 하드웨어가 개발되었다. 예컨 대, 파이프라인화(pipelining), 병렬화(parallelism) 및 벡터화(vectorization)와 같은 아키텍처 최적화는 계 산의 효율성 향상, 유휴 시간 감소 등에 의해 런타임 및 전력 소비를 감소시키는 것을 목표로 할 수 있다. 더욱 이, 메모리 계층들은 상이한 레벨의 메모리 대역폭 및 용량을 제공하도록 구현될 수 있다 (예컨대, 메모리 자원 들의 크기 및 계층을 최적화하는 것은 메모리 사용과 전력 소비 사이의 트레이드오프의 균형을 맞출 수 있다). 추론(예를 들어, 컨볼루션 신경망(CNN) 추론)은 런타임, 전력 및 시스템 자원의 관점에서 비용이 많이 들 수 있 다. 일부 예들에서, 에지 AI 하드웨어 가속기들은 그러한 비용들을 낮추기 위해 작은 캐시(cache)를 포함할 수 있지만, 그러한 구현들은 영역 비용이 많이 들 수 있다. 더 나아가, 서로 다른 컴파일 시간 결정이 런타임, 전 력 및 시스템 자원 비용들 사이의 트레이드오프(trade-off)에 영향을 미칠 수 있다. 예로서, 다른 애플리케이션 컴파일과 대조적으로, CNN 그래프는 수백만 동작들에 있어서 결정론적이다. 이러한 도메인 특정 접근법은 추론 실행에 우선하여 심층 최적화를 가능하게 한다. 원하는 런타임, 전력 및 대역폭은 크게 상이하고 사용자 관점에 서 비-선형 방식이 될 수 있다. 본 명세서에 기술된 기법들은 컴파일러가 그러한 트레이드오프들을 최적화할 수 있게 하여 특정 사용자 비용 함 수(예를 들어, 복잡한 다차원 및 비선형 문제의 최적화)에 대한 최적화를 가능하게 한다. 더욱이, 본 명세서에 기술된 기법들은 (예를 들어, CNN 알고리즘 계층들의 양에 대해 다른 방법들이 근사치들 또는 지수 런타임 (exponential runtime)을 제안할 수 있는 반면) 다항 시간 (polynomial time)에서 최적화된다. 본 명세서에 더 상세히 기술된 바와 같이, 본 발명의 하나 이상의 양태들은 에지 AI 하드웨어 가속기 성능을 최적화할 수 있다. 더욱이, 본 명세서에 기술된 최적화 알고리즘들은 임의의 A-사이클 계산-그래프(예를 들어, CNN에 제한되지 않 음)에 대하여 일반적일 뿐만 아니라 다양한 계산 유닛들(예를 들어, 중앙 처리 유닛(CPU), 그래픽 처리 유닛 (GPU), 신경 처리 유닛(NPU) 등)에 대한 일반적일 수 있다.따라서, AI 추론 태스크는 전력 소비, 유휴 시간, 계산의 효율성, 시스템 자원 등의 관점에서 최적화(예를 들어, 특정 애플리케이션에 기초)될 수 있다. 예를 들어, 하드웨어 설계자는 본 발명에 기술된 시스템 및 기법 을 활용함으로써, 전문화된 AI 작업들의 효율적인 처리에 있어서 중요한 요소인 런타임, 전력 소비 및 자원 사 용 간의 트레이드오프의 균형을 맞출 수 있다. 본 발명의 실시예들은 컴퓨팅 시스템에서와 같은 다양한 컨텍스트에서 사용될 수 있다. 예컨대, 본 발명내용에 기초한 컴퓨팅 시스템은 이하에 더 상세히 기술되는 바와 같이, 임의의 A-사이클 계산-그래프에 대한 최적화 알 고리즘을 구현할 수 있다. 컴퓨팅 시스템 컨텍스트에서, 본 발명적 개념의 하나 이상의 양태들은 도 1 및 도 2 를 참조하여 제공된다. 더욱이, 예시적인 AI 추론 최적화에 관한 상세한 사항들은 도 3 및 도 4를 참조하여 제 공된다. 예시적인 신경망 그래프들 및 동적 프로그래밍 다이어그램들이 도 5a, 5b, 6, 7 및 8을 참조하여 제공 된다. 시스템 아키텍처 도 1은 본 발명의 양태들에 따른 컴퓨팅 시스템의 예시를 보여준다. 컴퓨팅 시스템은 도 2를 참조하 여 기술된 대응 요소의 예시이거나 그 양태들을 포함한다. 일 양태에서, 도 1의 예시적인 컴퓨팅 시스템은 사용자, 장치, 서버, 데이터베이스, 및 클라우드를 포함한다. 예를 들어, 장치(11 0)는 예를 들어, 머신 러닝 모델의 생성 및 테스트, 머신 러닝 작업의 수행, 신경망의 구현 등과 같은 다양한 컴퓨팅 작업을 위해 사용자(예를 들어, 엔지니어, 연구자, 과학자 등)에 의해 사용될 수 있다. 일부 양태들에서, 장치는 퍼스널(personal) 컴퓨터, 데스크탑(desktop) 컴퓨터, 랩탑(laptop) 컴퓨터, 메 인프레임(mainframe) 컴퓨터, 팜탑(palmtop) 컴퓨터, 퍼스널 어시스턴트(personal assistant), 모바일 장치 , 또는 임의의 다른 적절한 프로세싱 장치와 같은 컴퓨팅 장치를 포함할 수 있다. 일부 예들에서, 장 치는 머신 러닝의 계산 요구들을 처리하기 위해 다양한 하드웨어 및 소프트웨어(예를 들어, 프로세서, 그 래픽 카드 등)를 구비할 수 있다. 서버는 다양한 네트워크들 중 하나 이상의 네트워크를 통해 링크된 사용자들에게 하나 이상의 기능들 을 제공할 수 있다. 일부 경우들에서, 서버는 서버의 모든 양태들의 제어를 담당하는 마이크로프로세 서를 포함하는 단일 마이크로프로세서 보드를 포함한다. 일부 경우들에서, 파일 전송 프로토콜(FTP) 및 단순 네 트워크 관리 프로토콜(SMP)과 같은 다른 프로토콜들도 사용될 수 있지만, 서버는 마이크로프로세서 및 프 로토콜들을 사용하여 하이퍼텍스트 전달 프로토콜(HTTP), 및 단순 메일 전달 프로토콜(SMTP)을 경유하여 하나 이상의 네트워크에 있는 장치들/사용자들과 데이터를 교환한다. 일부 경우들에서, 서버는 (예를 들어, 웹 페이지들을 디스플레이하기 위해) 하이퍼텍스트 마크업 언어(HTML) 포맷된 파일들을 송신 및 수신하도록 구성된 다. 다양한 실시예들에서, 서버는 범용 컴퓨팅 장치, 퍼스널 컴퓨터, 랩탑 컴퓨터, 메인프레임 컴퓨터, 슈 퍼컴퓨터, 또는 임의의 다른 적절한 처리 장치를 포함한다. 일부 양태들에서, 서버는 머신 러닝 모델들 및 알고리즘들을 호스팅하여, 네트워크 상의 다른 컴퓨터들(예를 들어, 장치)에 대한 액세스를 가능하게 할 수 있다. 예를 들어, 일부 경우들에서, 서버는 (예를 들어, 신경망 알고리즘들, 대용량 데이터 등을 처리 하는 것에 의한 것과 같은) 머신 러닝 애플리케이션들을 가능하게 하기 위해 계산 전력을 제공할 수 있다. 데이터베이스는 데이터의 기관화된 집합이다. 일 예로, 데이터베이스는 스키마로 알려진 특정된 포맷 으로 데이터를 저장한다. 데이터베이스는 단일 데이터베이스, 분산 데이터베이스, 복수의 분산 데이터베이스, 또는 긴급 백업 데이터베이스로 구조화될 수 있다. 일부 경우들에서, 데이터베이스 컨트롤러는 데이터베이스 내의 데이터 저장 및 처리를 관리할 수 있다. 일부 경우들에서, 사용자 가 데이터베이스 컨트롤러와 상호작용한다. 다른 경우들에서, 데이터베이스 컨트롤러는 사용자 상호작용 없이 자동으로 동작할 수 있다. 일부 경우들에서, 데이터베이스는 머신 러닝 모델들을 트 레이닝하는데 사용되는 데이터 세트들을 저장하는데 사용될 수 있다. 일 예로, 데이터베이스는 데이터를 저장 및 관리하기 위한 중앙 위치를 제공하여 모델 개발 프로세스들 및 머신 러닝 작업들의 구현 동안 등에 데 이터의 더 용이한 액세스 및 조작을 허용할 수 있다. 클라우드는 데이터 저장 및 컴퓨팅 전력과 같은 컴퓨터 시스템 자원의 주문 가용성(on-demand availability)을 제공하도록 구성된 컴퓨터 네트워크이다. 일부 예에서, 클라우드는 사용자에 의한 능동적인 관리 없이 자원을 제공한다. 클라우드라는 용어는 종종 인터넷을 통해 많은 사용자가 이용 할 수 있는 데이터 센터를 기술하는 데 사용된다. 일부 대규모 클라우드 네트워크는 중앙 서버로부터 복수의 위치에 걸쳐 분산된 기능을 갖는다. 서버는, 사용자에 대한 직접 또는 가까운 연결을 갖는 경 우, 에지 서버로 지정된다. 일부 경우들에서, 클라우드는 단일 기관으로 제한된다. 다른 예들에서,클라우드는 많은 기관들에게 이용가능하다. 일 예에서, 클라우드는 복수의 에지 라우터들 및 코어 라 우터들을 포함하는 다중-계층 통신 네트워크를 포함한다. 다른 예에서, 클라우드는 단일 물리적 위치에서 의 스위치들의 국부적 집합에 기초한다. 일부 양태들에서, 클라우드는 (예컨대, 로컬 서버 또는 디바이스 상에서 보다 오히려) 데이터를 저장 및 처리하는 데 사용되는 원격 서버들의 네트워크를 포함하거나 또는 이를 지칭할 수 있다. 머신 러닝에서, 클라우드는 그 머신 러닝 모델들을 호스팅하고 트레이닝 및 추 론을 위한 확장가능한 기반(scalable infrastructure)을 제공하는 데 사용될 수 있다. 본 발명의 하나 이상의 양태들에 따르면, 컴퓨팅 시스템은 사용자들이 가치 있는 통찰들 및 의사결정 을 구동할 수 있는 복잡한 모델들을 효율적으로 생성하고 배치하는 것을 가능하게 할 수 있다. 일부 양태들에서, 시스템들 및 기법들은 CNN들 및 AI 추론 엔진들의 하드웨어 구현의 맥락에서 기술될 수 있다. 다만, 본 발명은 이에 제한되지 않는다. 예컨대, 기술된 시스템들 및 기법들은 (예컨대, 복잡한 다차원 및 비선 형 문제를 최적화하기 위해) A-사이클 그래프로서 수행될 수 있는 계산들로 일반화될 수 있다. 예컨대, 컴파일 러는 다양한 애플리케이션들에 대한 전력, 런타임 및 대역폭을 최적화하여, 최소의 자원 사용으로 머신 러닝 제 품들의 효율적인 구현을 가능하게 할 수 있다. 도 2는 본 발명의 양태들에 따른 컴퓨팅 시스템의 예를 보여준다. 일 양태에서, 컴퓨팅 시스템은 프 로세서 유닛, 메모리 유닛, I/O 컴포넌트, 머신 러닝 컴포넌트, 메트릭 업데이트 컴포넌트 , 동적 프로그래밍 컴포넌트, 및 컴파일러를 포함한다. 컴퓨팅 시스템은 도 1을 참조하여 기술된 대응 요소의 예 또는 그 양태들을 포함한다. 예컨대, 일부 구현들에서, 컴퓨팅 시스템은 장치(11 0)로서 또는 서버로서 구현될 수 있다. 일부 구현들에서, 컴퓨팅 시스템은 장치, 서버, 데 이터베이스 및 클라우드(125, 여기서 컴퓨팅 시스템의 컴포넌트들, 및 컴퓨팅 시스템에 의해 수 행되는 동작들은 다양한 구성들에 따라 장치, 서버, 데이터베이스 및 클라우드에 걸쳐 분 산될 수 있다. 본 명세서에서 더 상세히 기술된 바와 같이, 컴퓨팅 시스템은 AI 추론 엔진에 대한 복잡한 비선형 다차원 비용 함수를 최적화하도록 구현될 수 있다. 프로세서 유닛은 지능형 하드웨어 장치(예를 들어, 범용 처리 컴포넌트, 디지털 신호 프로세서(DSP), 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 마이크로컨트롤러, 애플리케이션 특정 집적 회로(ASIC), 필드 프로그 램 가능 게이트 어레이(FPGA), 프로그램가능 로직 장치, 이산 게이트 또는 트랜지스터 로직 컴포넌트, 이산 하 드웨어 컴포넌트, 또는 이들의 임의의 조합)이다. 일부 경우들에서, 프로세서 유닛은 메모리 컨트롤러를 사용하여 메모리 어레이를 동작시키도록 구성된다. 다른 경우들에서, 메모리 컨트롤러는 프로세서 유닛 내 에 통합된다. 일부 경우들에서, 프로세서 유닛은 다양한 기능들을 수행하기 위해 메모리에 저장된 컴퓨터 판독 가능 명령어들을 실행하도록 구성된다. 일부 실시예들에서, 프로세서 유닛은 모뎀 처리, 베이스밴드 처리, 디지털 신호 처리, 또는 전송 처리를 위한 특수 목적 컴포넌트들을 포함한다. 메모리 유닛(예를 들어, 메모리 장치)의 예는 랜덤 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 또는 하 드 디스크를 포함한다. 메모리 유닛의 예는 솔리드 스테이트 메모리 및 하드 디스크 드라이브를 포함한다. 일부 예에서, 메모리 유닛은, 실행될 때 프로세서 유닛으로 하여금 본 명세서에 기술된 다양한 기능 을 수행하게 하는 명령어들을 포함하는 컴퓨터-판독가능, 컴퓨터- 실행가능 소프트웨어를 저장하는 데 사용된다. 일부 경우들에서, 메모리 유닛은 무엇보다도 주변 컴포넌트들 또는 장치들과의 상호작용과 같은 기본적인 하드웨어 또는 소프트웨어 동작을 제어하는 기본 입출력 시스템(BIOS)을 포함한다. 일부 경우들에서, 메모리 컨트롤러는 메모리 셀들을 동작시킨다. 예를 들어, 메모리 컨트롤러는 로우 디코더, 컬럼 디코더, 또는 둘 모두를 포함할 수 있다. 일부 경우들에서, 메모리 유닛 내의 메모리 셀들은 논리 상태의 형태로 정보를 저장한다. I/O 컴포넌트(예를 들어, I/O 컨트롤러)는 장치에 대한 입력 및 출력 신호를 관리할 수 있다. I/O 컴포넌 트는 또한 장치에 통합되지 않은 주변기기들을 관리할 수 있다. 일부 경우들에서, I/O 컴포넌트는 외 부 주변기기로의 물리적 연결 또는 포트를 나타낼 수 있다. 일부 경우들에서, I/O 컴포넌트는 iOS®, ANDROID®, MS-DOS®, MS-WINDOS®, OS/2®, UNIX®, 리눅스®, 또는 다른 공지된 운영체제를 활용할 수 있다. 다른 경우들에서, I/O 컴포넌트는 모뎀, 키보드, 마우스, 터치스크린, 또는 이와 유사한 장치를 나타내거 나 이와 상호작용할 수 있다. 일부 경우들에서, I/O 컴포넌트는 프로세서 유닛의 일부로서 구현될 수 있다. 일부 경우들에서, 사용자는, I/O 컴포넌트를 통해, 또는 I/O 컴포넌트에 의해 제어되는 하드웨 어 컴포넌트들을 통해, 장치와 상호작용할 수 있다. 일부 양태들에 따르면, 머신 러닝 컴포넌트는 계산 그래프에 대한 알고리즘을 획득한다. 일부 예들에서, 머신 러닝 컴포넌트는 계산 그래프의 계층들의 세트를 식별한다. 일부 예들에서, 머신 러닝 컴포넌트(22 0)는 계층들의 세트를 시퀀스들의 세트로 그룹화한다. 일부 예들에서, 머신 러닝 컴포넌트는 계층들의 세 트의 타일링을 식별하며, 여기서 하드웨어 장치는 타일링에 기초하여 프로그램된다. 일부 양태들에 따르면, 메트릭 업데이트 컴포넌트는 하드웨어 장치를 사용하여 알고리즘을 수행하기 위한 성능 파라미터에 대한 초기 선형화된 메트릭을 계산한다. 일부 예들에서, 메트릭 업데이트 컴포넌트는 초 기 선형화된 메트릭 및 성능 파라미터에 대한 비선형 제약에 기초하여 업데이트된 선형화된 메트릭을 계산한다. 일부 예들에서, 메트릭 업데이트 컴포넌트는 성능 파라미터에 대한 초기 가중치를 결정한다. 일부 예들에 서, 메트릭 업데이트 컴포넌트는 초기 가중치를 포함하는 초기 가중치들의 세트에 기초하여 초기 선형화된 메트릭을 포함하는 선형화된 메트릭 세트의 가중 합계를 계산하며, 여기서 초기 스코어는 가중 합계에 기초한다. 일부 예들에서, 메트릭 업데이트 컴포넌트는 초기 스코어에 기초하여 성능 파라미터에 대한 업 데이트된 가중치를 결정한다. 일부 양태들에 따르면, 동적 프로그래밍 컴포넌트는 업데이트된 선형화된 메트릭에 기초하여 계산 그래프 를 구현하도록 하드웨어 장치를 프로그래밍한다. 일부 예들에서, 동적 프로그래밍 컴포넌트는 시퀀스들의 세트로부터의 시퀀스들의 서브세트를 식별하기 위해 동적 프로그래밍 프로세스를 수행하며, 여기서 초기 선형화 된 메트릭은 시퀀스들의 서브세트에 기초하고, 동적 프로그래밍 프로세스는 성능 파라미터에 대한 선형성 제약 에 기초한다. 일부 예들에서, 동적 프로그래밍 컴포넌트는 시퀀스들의 세트로부터의 업데이트된 시퀀스들 의 서브세트를 식별하기 위해 추가적인 동적 프로그래밍 프로세스를 수행하며, 여기서 업데이트된 선형화된 메 트릭은 업데이트된 시퀀스들의 서브세트에 기초하고, 하드웨어 장치가 업데이트된 시퀀스들의 서브세트에 기초 하여 프로그래밍된다. 일부 예들에서, 동적 프로그래밍 컴포넌트는 초기 선형화된 메트릭 및 초기 가중치 에 기초하여 시퀀스들의 서브세트에 대한 초기 스코어를 계산한다. 일부 예들에서, 동적 프로그래밍 컴포넌트 는 업데이트된 가중치 및 업데이트된 선형화된 메트릭에 기초하여 시퀀스들의 서브세트에 대한 업데이트된 스코어를 계산하며, 여기서 시퀀스들의 서브세트는 업데이트된 스코어에 기초하여 선택된다. 일부 예들에서, 동 적 프로그래밍 컴포넌트은 시퀀스들의 서브세트들의 세트에 대한 스코어들을 각각 계산하며, 시퀀스들의 서브세트는 그 스코어들에 기초하여 시퀀스들의 서브세트들의 세트로부터 선택된다. 일부 예들에서, 동적 프로 그래밍 컴포넌트는 초기 가중치 및 비선형 제약에 기초하여 비선형 항을 계산하며, 여기서 초기 스코어는 비선형 항에 기초한다. 일부 예들에서, 동적 프로그래밍 컴포넌트는 업데이트된 선형화된 메트릭에 기초하 여 하드웨어 장치에 대한 설계를 수정하며, 여기서 하드웨어 장치는 수정된 설계에 기초하여 프로그래밍된다. 일부 예들에서, 동적 프로그래밍 컴포넌트는 업데이트된 선형화된 메트릭에 기초하여 계산 그래프에 대한 알고리즘을 수정하며, 여기서 하드웨어 장치는 수정된 알고리즘에 기초하여 프로그래밍된다. 일부 양태들에 따르면, 컴파일러는 업데이트된 선형화된 메트릭에 기초하여 알고리즘을 수행하기 위한 명 령어들을 컴파일하고, 여기서 하드웨어 장치는 컴파일된 명령어들에 기초하여 프로그래밍된다. 인공지능 추론 최적화 도 3은 방법의 예시와 본 발명의 양상들에 따른 계산 그래프에 대한 알고리즘을 최적화 및 컴파일하기 위 한 사용자(컴퓨팅 장치)와 서버 사이의 동작들의 예시적인 흐름도를 보여준다. 일부 예들에서, 이러한 동작들은 장치의 기능적 요소들을 제어하기 위한 코드들의 세트를 실행하는 프로세서를 포함하는 시스템에 의해 수행된다. 추가적으로 또는 대안적으로, 특정 프로세스들은 특수 목적 하드웨어를 사용하여 수행된다. 일반적으 로, 이러한 동작들은 본 발명의 양상들에 따라 기술된 방법들 및 프로세스들에 따라 수행된다. 일부 경우들에서, 본 명세서에 기술된 동작들은 다양한 서브 스텝들로 구성되거나, 다른 동작들과 함께 수행된다. 동작에서, 시스템은 계산 그래프에 대한 알고리즘(예를 들어, 신경망 알고리즘)을 서버에 제공한다. 일부 경우들에서, 이 단계의 동작들은 도 1을 참조하여 기술된 바와 같이 사용자를 지칭하거나, 또는 사용자에 의해 수행될 수 있다. 일부 경우들에서, 이 단계의 동작들은 도 1을 참조하여 기술된 바와 같이, 장치를 지칭하거나, 또는 그에 의해 수행될 수 있다. 동작에서, 상기 시스템은 계산 그래프의 계층들을 시퀀스들로 분할한다. 일부 경우들에서, 이 단계의 동작 들은 도 1 및 도 2를 참조하여 기술된 바와 같은 컴퓨팅 시스템을 지칭하거나, 이에 의해 수행될 수 있다. 일부 경우들에서, 이 단계의 동작들은 도 2를 참조하여 기술된 바와 같은 머신 러닝 컴포넌트를 지칭하거나, 이에 의 해 수행될 수 있다. 동작에서, 시스템은 계산 그래프를 구현하기 위한 시퀀스들의 최적화된 서브세트를 결정한다. 일부 경우들 에서, 이 단계의 동작들은 도 1 및 도 2를 참조하여 전술된 바와 같은 컴퓨팅 시스템을 지칭하거나, 이에 의해 수행될 수 있다. 일부 경우들에서, 이 단계의 동작들은 도 2를 참조하여 전술된 바와 같은 동적 프로그래밍 컴 포넌트를 지칭하거나, 이에 의해 수행될 수 있다. 동작에서, 시스템은 시퀀스들의 최적화된 서브세트에 기초하여 알고리즘을 수행한다. 일부 경우들에서, 이 단계의 동작들은 도 1 및 도 2를 참조하여 전술된 바와 같은 컴퓨팅 시스템을 지칭하거나, 이에 의해 수행될 수 있다. 일부 경우들에서, 이 단계의 동작들은 도 2를 참조하여 전술된 바와 같은 컴파일러를 지칭하거나, 이에 의해 수행될 수 있다. 도 4는 본 발명의 양태들에 따른 인공 지능 추론 최적화를 위한 방법의 예를 보여준다. 일부 예들에서, 이 러한 동작들은 장치의 기능적 요소들을 제어하기 위한 코드들의 세트를 실행하는 프로세서를 포함하는 시스템에 의해 수행된다. 추가적으로 또는 대안적으로, 특정 프로세스들은 특수 목적 하드웨어를 사용하여 수행된다. 일 반적으로, 이러한 동작들은 본 발명의 양태들에 따라 기술된 방법들 및 프로세스들에 따라 수행된다. 일부 경우 들에서, 본 명세서에 기술된 동작들은 다양한 서브스텝들로 구성되거나, 다른 동작들과 함께 수행된다. 동작에서, 시스템은 계산 그래프에 대한 알고리즘을 획득한다. 일부 경우들에서, 이 단계의 동작들은 도 2 를 참조하여 기술된 바와 같은 머신 러닝 컴포넌트를 지칭하거나, 이에 의해 수행될 수 있다. 동작에서, 시스템은 하드웨어 장치를 사용하여 알고리즘을 수행하기 위한 성능 파라미터에 대한 초기 선형 화된 메트릭을 계산한다. 일부 경우들에서, 이 단계의 동작들은 도 2를 참조하여 기술된 바와 같은 메트릭 업데 이트 컴포넌트를 지칭하거나, 이에 의해 수행될 수 있다. 동작에서, 시스템은 초기 선형화된 메트릭 및 성능 파라미터에 대한 비선형 제약에 기초하여 업데이트된 선형화된 메트릭을 계산한다. 일부 경우들에서, 이 단계의 동작들은 도 2를 참조하여 기술된 바와 같은 메트릭 업데이트 컴포넌트를 지칭하거나, 이에 의해 수행될 수 있다. 동작에서, 시스템은 업데이트된 선형화된 메트릭에 기초하여 계산 그래프를 구현하도록 하드웨어 장치를 프로그램한다. 일부 경우들에서, 이 단계의 동작들은 도 2를 참조하여 기술된 바와 같은 동적 프로그래밍 컴포 넌트를 지칭하거나, 이에 의해 수행될 수 있다. 따라서, AI 추론 엔진에 대한 복잡한 비선형 다차원 비용 함수에 대한 방법, 장치, 비일시적 컴퓨터 판독 가능 매체 및 시스템이 기술된다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체 및 시스템의 하나 이상의 양태는 계 산 그래프에 대한 알고리즘을 획득하는 것; 하드웨어 장치를 사용하여 알고리즘을 수행하기 위한 성능 파라미터 에 대한 초기 선형화된 메트릭을 계산하는 것; 초기 선형화된 메트릭 및 성능 파라미터에 대한 비선형 제약에 기초하여 업데이트된 선형화된 메트릭을 계산하는 것; 및 업데이트된 선형화된 메트릭에 기초하여 계산 그래프 를 구현하도록 하드웨어 장치를 프로그래밍하는 것을 포함한다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예는 계산 그래프의 복수의 계층을 식별하는 단계를 더 포함한다. 일부 예는 복수의 계층을 복수의 시퀀스로 그룹화하는 단계를 더 포함한다. 일부 예는 복 수의 시퀀스로부터 시퀀스의 서브세트를 식별하기 위해 동적 프로그래밍 프로세스를 수행하는 단계를 더 포함하 며, 여기서 초기 선형화된 메트릭은 시퀀스의 서브세트에 기초하고, 동적 프로그래밍 프로세스는 성능 파라미터 에 대한 선형성 제약에 기초한다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예는 복수의 계층의 타일링(tiling)을 식별하 는 단계를 더 포함하며, 여기서 하드웨어 장치는 상기 타일링에 기초하여 프로그래밍된다. 방법, 장치, 비일시적 컴퓨터 판독가능 매체, 및 시스템의 일부 예는 복수의 시퀀스들로부터 업데이트된 시퀀스 들의 서브세트를 식별하기 위해 추가적인 동적 프로그래밍 프로세스를 수행하는 것을 더 포함하고, 여기서 업데 이트된 선형화된 메트릭은 업데이트된 시퀀스들의 서브세트에 기초하고, 하드웨어 장치는 업데이트된 시퀀스들 의 서브세트에 기초하여 프로그래밍된다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예들은 성능 파라미터에 대한 초기 가중치를 결정하는 단계를 더 포함한다. 일부 예들은 초기 선형화된 메트릭 및 초기 가중치에 기초하여 시퀀스들의 서브 세트에 대한 초기 스코어를 계산하는 단계를 더 포함한다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예는, 초기 가중치를 포함하는 복수의 초기 가 중치에 기초하여 초기 선형화된 메트릭을 포함하는 복수의 선형화된 메트릭의 가중 합계를 계산하는 단계를 더포함하며, 여기서 초기 스코어는 가중 합계에 기초한다. 방법, 장치, 비일시적 컴퓨터 판독가능 매체, 및 시스템의 일부 예들은, 초기 스코어에 기초하여 성능 파라미터 에 대한 업데이트된 가중치를 결정하는 것을 더 포함한다. 일부 예들은 업데이트된 가중치 및 업데이트된 선형 화된 메트릭에 기초하여 시퀀스들의 서브세트에 대한 업데이트된 스코어를 계산하는 것을 더 포함하며, 여기서 시퀀스들의 서브세트는 업데이트된 스코어에 기초하여 선택된다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예들은 시퀀스들의 복수의 서브세트들에 대한 스코어들을 계산하는 것을 더 포함하며, 여기서 시퀀스들의 서브세트는 스코어들에 기초하여 시퀀스들의 복수의 서브세트들로부터 선택된다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예는 초기 가중치 및 비-선형 제약에 기초하여 비-선형 항을 계산하는 것을 더 포함하며, 여기서 초기 스코어는 비-선형 항에 기초한다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예들은 업데이트된 선형화된 메트릭에 기초하 여 알고리즘을 수행하기 위한 명령어들을 컴파일링 하는 것을 더 포함하고, 여기서 하드웨어 장치는 그 컴파일 된 명령어들에 기초하여 프로그래밍된다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예는 업데이트된 선형화된 메트릭에 기초하여 하드웨어 장치에 대한 설계를 수정하는 것을 더 포함하며, 여기서 하드웨어 장치는 수정된 설계에 기초하여 프 로그래밍된다. 방법, 장치, 비일시적 컴퓨터 판독 가능 매체, 및 시스템의 일부 예는 업데이트된 선형화된 메트릭에 기초하여 계산 그래프에 대한 알고리즘을 수정하는 것을 더 포함하며, 여기서 하드웨어 장치는 수정된 알고리즘에 기초하 여 프로그래밍된다. 신경망 그래프들 도 5a는 본 발명의 양태들에 따른 신경망 그래프(500-a)의 예를 보여준다. 도 5b는 본 발명의 양태들에 따른 신 경망 그래프(500-b) 및 신경망 그래프(500-c)의 예를 보여준다. 신경망 그래프는 도 6 및 도 7을 참조하여 기술된 대응 요소들 중 하나 이상의 예들일 수 있거나, 그의 양태들을 포함할 수 있다. 일 양태에서, 신경망 그 래프들은 노드들, 에지들, 및 시퀀스들을 포함한다. 노드들은 도 6을 참조하여 기술 된 대응 요소들 중 하나 이상의 양태들의 예들이거나, 그를 포함할 수 있다. 에지들은 도 6을 참조하여 기 술된 대응 요소들 중 하나 이상의 양태들의 예들이거나, 그를 포함할 수 있다. 시퀀스들은 도 6을 참조하 여 기술된 대응 요소들 중 하나 이상의 양태들의 예들이거나, 그를 포함할 수 있다. 인공 신경망(ANN)은 인간 뇌의 뉴런에 느슨하게 대응할 수 있는 복수의 연결된 노드(즉, 인공 뉴런)을 포 함하는 하드웨어 또는 소프트웨어 구성 요소이다. 각각의 연결(예컨대, 에지)은 (뇌에서 물리적 시냅스들 과 같이) 하나의 노드로부터 다른 노드로 신호를 전송한다. 노드가 신호를 수신하면, 노드는 그 신호를 처리한 다음 처리된 신호를 다른 연결된 노드로 전송한다. 일부 경우들에서, 노드 사이의 신 호들은 실수들을 포함하고, 각각의 노드의 출력은 그 입력들의 합의 함수에 의해 계산된다. 일부 예들에서, 노드들은 다른 수학적 알고리즘들(예컨대, 입력들로부터 출력으로서 최대를 선택하는 것) 또는 그 노드를 활성화하기 위한 임의의 다른 적합한 알고리즘을 사용하여 그들의 출력을 결정할 수 있다. 각각 의 노드 및 에지는 신호가 처리되고 전송되는 방법을 결정하는 하나 이상의 노드 가중치들과 연관된 다. 트레이닝 프로세스 동안, 이러한 가중치들은 결과의 정확성을 향상시키기 위해 (즉, 현재 결과와 목표 결과 사 이의 차이에 어떤 방식으로든 대응하는 손실 함수를 최소화함으로써) 조정된다. 에지의 가중치는 노드들 사이에서 전송되는 신호의 세기를 증가시키거나 감소시킨다. 일부 경우들에서, 노드들은 그 미만에 서 신호가 전혀 전송되지 않는 임계치를 갖는다. 일부 예들에서, 노드들은 계층들로 집성된다. 상이한 계 층들은 그들의 입력들에 대해 상이한 변환들을 수행한다. 초기 계층(예컨대, 입력 노드(505 'In'일 수 있거나, 또는 이를 포함할 수 있는)은 입력 계층으로 알려져 있고 마지막 계층은 출력 계층(예컨대, 출력 노드(505 'Out'일 수 있거나, 이를 포함할 수 있는)으로 알려져 있다. 일부 경우들에서, 신호들은 특정 계층들을 복수 회 횡단한다. CNN은 컴퓨터 비전 또는 이미지 분류 시스템에서 일반적으로 사용되는 신경망의 클래스이다. 일부 경우들에서, CNN은 최소한의 사전-프로세싱으로 디지털 이미지들의 프로세싱을 가능하게 할 수 있다. CNN은 컨볼루션(또는교차-상관) 히든 계층들(convolution hidden layers)의 사용으로 특징지어질 수 있다. 이러한 계층들은 결과를 다음 계층에 시그널링하기 전에 컨볼루션 동작을 입력에 적용한다. 각각의 컨볼루션 노드는 제한된 입력 필드 (즉, 수신 필드)에 대한 데이터를 프로세싱할 수 있다. CNN의 정방향 패스 동안, 각 계층의 필터들은 입력 볼륨 에 걸쳐 컨볼루션되어, 필터와 입력 사이의 내적(dot product)을 계산할 수 있다. 트레이닝 프로세스 동안, 그 필터들은 입력 내의 특정 특징을 검출할 때 활성화되도록 수정될 수 있다. 도 5a, 도 5b 및 도 6은 4개의 연산(예를 들어, 제1 연산 'Op1', 제2 연산 'Op2', 제3 연산 'Op3', 제4 연산 'Op4')만을 포함하는 선형 네트워크를 나타내는 신경망 그래프의 다양한 예를 나타낸다. 도 5a, 도 5b, 도 6 및 도 7의 예들에 따르면, 신경망 계산 그래프(예를 들어, 신경망 그래프(500-a), 신경망 그래프(500-b), 등)는 신경망(예를 들어, ANN, CNN 등)에서의 연산들 및 데이터 흐름의 그래픽 표현이다. 예시적으로, 도 5a 및 도 5b에서, 신경망 그래프(500-a) 및 신경망 그래프(500-b)는 일련의 상호 연결된 노드들 을 포함한다. 각 노드는 입력 데이터를 몇가지 방식으로 변환하는 수학적 연산(예를 들어, 일부 제1 연산 'Op1', 제2 연산 'Op2', 제3 연산 'Op3', 제4 연산 'Op4' 등)을 나타낼 수 있다. 경우들에서, 노드들 은 계층들로 그룹화될 수 있고, 각 계층은 특정 기능(예를 들어, 컨볼루션 또는 풀링)을 수행한다. 도 5a에서, 신경망 그래프(500-a)는 엔티티들의 집합 사이의 관계를 나타낸다. 엔티티들은 노드들을 포함 할 수 있거나, 이를 지칭할 수 있다. 관계들은 에지들을 포함하거나, 이를 지칭할 수 있다. 신경망 그래프 들에서, 각각의 에지는 (예를 들어, 데이터 흐름의 방향을 따르는) 방향을 가질 수 있다. 일부 신경 망들에서, 동작들은 프로세싱을 위해 시퀀스들로 그룹핑될 수 있다. 예컨대, 도 5b에서, 노드들은 프 로세싱을 위해 그룹핑되는 대응하는 동작들을 나타낼 수 있는 시퀀스들로 그룹핑될 수 있다. 주어진 네트워크에 대해 추론을 수행할 때, 각각의 동작은 입력 및 출력 데이터를 갖는다. 이 데이터는 외부 메 모리(예를 들어, DRAM(dynamic random access memory) 또는 내부 메모리(예를 들어, SRAM(static random access memory) 내의 추론 엔진 내부에 저장될 수 있다. 예를 들어, 데이터를 엔진 내부에 저장하기로 선택할 때, 동작들의 시퀀스가 설정된다(예를 들어, 외부 메모리로 유출되지 않고 실행됨). 시퀀스 내에서, 동작 들의 처리는 DRAM보다 더 빠르고 전력 효율적일 수 있는 메모리의 유형인 SRAM을 사용한다. 일부 경우들에서, 시퀀스 내의 SRAM을 사용하는 것은 그 시퀀스 내의 데이터의 더 빠른 처리를 허용한다. 그러나, 시퀀 스 외부의 동작들은 DRAM을 사용할 수 있다. DRAM은 SRAM보다 느리고 전력 효율이 적을 수 있지만, 더 높 은 용량을 가질 수 있는 메모리의 유형이다. 일부 경우들에서, 시퀀스 외부의 DRAM을 사용하는 것은 더 효 율적인 메모리 활용 및 더 많은 양의 데이터의 처리를 허용한다. 일 예에서, 신경망 그래프(500-a)는 복수의 노드들을 갖는 시퀀스들을 포함하지 않는다. 즉, 각 동작 'Op1', 'Op2', 'Op3' 및 'Op4'는 별개로 수행된다. 이 예에서, 각 동작으로부터의 데이터는 DRAM에 개별적으로 입출력될 수 있다. 반면, 신경망 그래프(500-b)는 복수의 동작들(예를 들어, 'Op1' 및 'Op2')을 나타내는 노드들을 포함하는 시퀀스를 포함한다. 이 예에서, 동작들 'Op1' 및 'Op2'의 데이터는 프로세싱 및 SRAM으로의 입출력을 위해 그룹화될 수 있는 반면, 동작들 'Op3' 및 'Op4'의 데이터는 DRAM으로 입출력될 수 있다. 유사하게, 신경망 그래프(500-c)는 연산 'Op1', 'Op2' 및 'Op3'을 나타내는 노드들을 포함하는 시퀀스 를 포함하며, 여기서 연산 'Op1', 'Op2' 및 'Op3'의 데이터는 프로세싱 및 SRAM으로의 입출력을 위해 그룹 화될 수 있고; 연산 'Op4'의 데이터는 DRAM으로 입출력될 수 있다. 시퀀스에서의 동작들을 연결하는 것은 메모리 대역폭을 절약할 수 있다 (예를 들어, 그에 의해 전력을 절 약할 수도 있다). 시퀀스는 또한, 그 데이터(예를 들어, DRAM에)를 기록하고 판독하는 데 걸리는 시간이 절약되고 있기 때문에 런타임을 절약할 수 있다. 일부 경우들에서, 수신 필드로 인해, 긴 시퀀스는 또한 계산 및 메모리 대역폭을 증가시킬 수 있다. 따라서, 시퀀스들의 구성을 최적화하는 것은 성능을 최적화할 수 있다. 일부 경우들에서, 신경망 그래프는 각각의 동작이 시퀀스들 중 정확히 하나에 속하도록 시퀀스들 의 조합을 선택함으로써 \"해결\"될 수 있다. 도 6은 본 발명의 양태들에 따른 예시적인 신경망 그래프들(600-a 내지 600-h)을 보여준다. 신경망 그래프들 (600a-h)은 도 5 및 도 7을 참조하여 기술된 대응 요소들 중 하나 이상의 예들일 수 있거나, 이들의 양태들을 포함할 수 있다. 일 양태에서, 신경망 그래프들(600a-h)은 노드들, 에지들 및 시퀀스들을 포함 할 수 있다. 노드들은 도 5를 참조하여 기술된 대응 요소들 중 하나 이상의 예들이거나, 이들의 양태들을 포함할 수 있다. 에지들은 도 5를 참조하여 기술된 대응 요소들 중 하나 이상의 예들이거나, 이들의 양태들을 포함할 수 있다. 시퀀스들은 도 5를 참조하여 기술된 대응 요소들 중 하나 이상의 예들이거나, 이들 의 양태들을 포함할 수 있다. 일부 예들에서, 복수의 노드들은 시퀀스를 형성하도록 조합될 수 있다. 일부 예들에서, 단일 층 또는 동작을 나타내는 단일 노드는 또한 시퀀스로서 고려될 수 있고, 타일들로 분할될 수 있다. 일부 예들 에서, 프로세서는 처리 전에 내부 메모리에 데이터를 저장하거나 레지스터할 수 있다. 컨볼루션 동작들을 위한 처리를 수행할 때, 데이터 조각들이 (복수의 상이한 출력들을 얻기 위해) 여러 번 사용될 수 있다. 따라서, 효 율적인 시퀀스 세트를 선택함으로써, 본 발명의 실시예들은 일부 데이터 조각들이 메모리로 판독되는 횟수를 감 소시킴으로써 프로세서의 효율을 증가시킬 수 있다. 본 명세서에 기술된 시스템들 및 기법들은 비-선형 다차원 비용 함수(메트릭)가 주어진 CNN 추론을 단순화 및 최적화할 수 있다. 본 명세서에 기술된 바와 같이, 계산들의 데이터 및 파라미터들(텐서들)을 AI 가속기의 내부 메모리에 맞추기 위해, 텐서들의 일부(예를 들어, 대부분)는 (예를 들어, 본 명세서에 더 상세히 기술된 바와 같이, 예를 들어, 도 8을 참조하여) 타일링될 수 있다. 각각의 타일은 (예를 들어, 전력 및 런타임 모두에서) 더 많은 계산 및 대역폭 오버헤드를 추가할 수 있다. 런타임 및 대역폭(대역폭 전력뿐만 아니라)을 감소시키기 위해, 시퀀싱이 또한 사용될 수 있다. 그래프에 대한 최적의 시퀀스 경계를 선택하는 것은 어려운데, 이는 각각의 시퀀스 경계의 변화가 그 이웃에 영 향을 미치기 때문에(예를 들어, 전체 그래프에 따라 지수 복잡도를 초래한다). 그러나, 메트릭(예를 들어, (대 역폭, 전력, 런타임)의 비용)이 선형인 경우, 메모이제이션(memoization)(예를 들어, 그래프 끝에서 시작하여 역방향으로 가는) 접근법이 적용될 수 있다. 이 접근법은 의 복잡도 문제를 해결할 수 있다. 메모이제이 션 기법을 임의의 비선형 함수에 적용하기 위해, 메트릭은 예측된 포인트에서 선형화될 수 있다. 그렇지 않으면, 예측된 포인트가 재평가될 수 있고, 그 프로세스는 반복된다. 최적의 시퀀스를 찾기 위한 하나의 접근법은 시퀀스들의 모든 조합들을 시도(예를 들어, 테스트)하는 것을 포함 할 수 있다. 그러나, 이 접근법은 의 순서에서 복수의 조합들을 테스트하는 것을 포함할 수 있다. 더 나 아가, 테스트는 길고 복잡한 네트워크들에서 수렴하지 않을 수 있다. 선형 네트워크에서 그래프를 해결하는 개의 상이한 타입의 시퀀스들 및 그 그래프를 해결하는 시퀀스들의 개의 상이한 조합들이 있을 수 있다. 따라서, 도 6의 예(즉, 4개의 연산이 있는 경우)에서, 개의 상이한 시퀀스들: [1], [2],"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[3], [4], [1-2], [2-3], [3-4], [1-3], [2-4], [1-4] 및 그 그래프를 해결하는 시퀀스들의 개의 상이한 조합들: [1, 2, 3, 4], [1-2, 3, 4], [1, 2-3, 4], [1, 2, 3-4],[1-2, 3-4], [1-3, 4], [1, 2-4], [1- 4]. 신경망(예를 들어, 계산 그래프)은 수백 개의 계층들로부터 구축될 수 있으며, 모든 옵션을 시도하는 접근 방식 은 너무 복잡하다. CNN 그래프 위에 메모이제이션을 적용하기 위해, 예시적인 알고리즘은 그 그래프 끝으로 시 작하여, 현재 시작 노드로부터 가능한 각각의 중간 노드까지 매번 새로운 서브그래프를 에뮬레이트하 는, 역순으로 진행하고, 이들 옵션 중에서 최선을 선택한다. 그 알고리즘이 그래프 소스 노드들에 도달하 면, 그 알고리즘은 선형화된 메트릭을 최적화하는 시퀀스의 체인을 평가한다(예를 들어, 본 명세서에 더 상세히 기술된 바와 같이, 예를 들어, 도 7을 참조). 도 7은 본 발명의 양태들에 따른 동적 프로그래밍 다이어그램의 예를 보여준다. 일 양태에서, 도 7의 예시 적인 동적 프로그래밍 다이어그램은 신경망 그래프들(705-a 내지 705-j)을 포함한다. 신경망 그래프들 은 도 5 및 도 6을 참조하여 기술된 대응하는 요소들 중 하나 이상의 예들이거나 그 양태들을 포함할 수 있다. 동적 프로그래밍 다이어그램은 (예를 들어, 신경망 그래프(705-a 내지 705-j)를 통하는 것과 같이 CNN 그 래프를 통한) 메모이제이션 기법의 하나 이상의 양태를 예시할 수 있다. 예를 들어, 제1 반복(예를 들어, '반복 1')은 그래프 끝(예를 들어, 신경망 그래프(705-j)으로 시작할 수 있고, 동적 프로그래밍 다이어그램은 역 순으로 진행할 수 있다 (예를 들어, 각각의 가능한 중간 노드를 통해 현재 시작 노드로부터 새로운 서브그래프를 매번 에뮬레이트하고, 그 옵션들로부터 최상의 것을 평가). 그 알고리즘이 그래프 소스 노드들에 도달할 때, 선형화된 메트릭을 최적화하는 시퀀스의 체인을 평가한다. 일부 양태들에서, 도 7은 선형성이 주어진 최상의 시퀀스 조합들의 재귀적 선택을 보여준다. 각각의 시퀀스의 평가(예를 들어, 각각의 신경망 그래프의 평가)는 선형화된 메트릭에 대해 가산적일 수 있고, 하드웨어 에 뮬레이터를 사용하여 별개로 평가될 수 있다. 선형화된 메트릭을 갖는 것은 시퀀스 선택을 해결할 뿐만 아니라 컴파일러가 시퀀스들 각각을 독립적으로 최적화하여 동일한 메트릭을 최소화할 수 있게 할 수 있다. 선형화된 스코어는 이후 원래 메트릭과 비교될 수 있고, 선형화된 메트릭이 업데이트될 수 있고, 그 프로세스는 선형화된 메트릭과 원래 메트릭이 수렴할 때까지 반복될 수 있으며(예를 들어, 프로세스가 완료되면, 원래 메트릭이 최적 화될 수 있다). 다차원 비-선형 비용 함수는 수학식 에 따라 설명될 수 있다."}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "일부 양태들에서, 그 제한은 예를 들어, 프로젝트 요건들, 설계 제약들, 트레이드오프 최적화들 등을 나타낼 수 있다. 예를 들어, 그 제한은 전력 제한, 런타임(또는 레이턴시) 제한, 대역폭(메모리) 제한 등을 나타낼 수 있 다. 일 예로서, 구현에 대한 예시적인 제한/제약은 20mA 미만의 전력을 포함할 수 있다. 그러한 예에서, 비용 함수는 20mA까지 선형일 수 있고, 20mA부터 비용 함수는 지수 함수가 될 수 있다(예를 들어, 비용을 반영하기 위해). 본 명세서에서 논의된 바와 같이, 메모이제이션에 의한 동적 프로그래밍으로 다차원 비용 함수를 해결하기 위해, 함수는 (예를 들어, 본 명세서에 기술된 기법에 따라) 선형화될 수 있다."}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 의 값은 가정된 작업점(working point)을 이용하여 계산될 수 있다. 일단 전체 그래프 비용이 계산되면, 모든 차원들이 제한들 미만이거나 또는 비용 함수가 하나 이상의 차원들에 서 제한을 초과하는 최적 작업점에 도달한다. 이후 시나리오에서, 최적 해법을 찾기 위해, 선형 비용 함수 가중 치 가 업데이트될 수 있다. 일단, 가중치들이 업데이트되면, 그 흐름은 다시 시작될 수 있고, 최적 해법을 찾을 때까지 반복될 수 있다. 예를 들어, (예를 들어, 수학식 을 참조하는 것과 같은) 본 명세서에 기술된 비용 함수들은 선형 성분 및 비 선형 성분을 갖는 구간적 함수들 (piecewise functions)일 수 있다. 일반적으로, 이러한 구간적 비용 함수는 복 수의(예를 들어, 2개의) 서브 함수들에 의해 정의될 수 있으며, 각각의 서브 함수는 특정 도메인 또는 구간에 걸쳐 적용될 수 있다. 따라서 상이한 서브 함수들은 조건문들 또는 부등식들을 사용하여 정의될 수 있으며, 이 러한 서브 함수들을 조합함으로써 전체 비용 함수가 구성될 수 있다. 결과적인 구간적 비용 함수는 그 도메인에 걸쳐 연속적일 수 있으며, 지정된 구간들 내에서 입력 가변변수들의 값에 따라 상이한 형태 또는 값들을 취할 수 있다. 예를 들어, 비용 함수는 한계(예를 들어, ) 아래의 측정값들(예를 들어, )에 대한 선형 성분(예를 들어, 와 같은 선형 함수) 및 한계와 같거나 초과하는 측정값들에 대한 비선형 컴포넌트(예를 들어, 와 같은, 비선형 함수)를 포함할 수 있다. i는 서로 다른 한계들(예를 들어, 대역폭 'bw', 런타임 'rt', 등)에 대한 서로 다른 요구사항들을 나타낼 수 있다. 본 명세서에서 더 상세히 기술된 바와 같이, 동적 프로그래밍 기법들은 비용 함수의 선형 함수 컴포넌트를 가정할 수 있다. 예로서, 네트워크(예를 들어, 신경망 그래프(500, 600, 700) 등으로 표현되는 네트워크와 같은, 4개의 동작 선 형 네트워크)는 표 1과 관련하여 아래에 나타낸 하나 이상의 양태에 따라 최적화될 수 있다. 표 1 <차원들 (A, B 및 C) 당 시퀀스 값> 메트릭 A B C 가중치들 0.5 1 1 한계 6 6 6 시퀀스[1] 1 2 3 [1,2] 3 1 3 [1,2,3] 5 1 5 [1,2,3,4] 8 3 6"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[2] 2 3 4 [2.3] 5 1 2 [2,3,4] 6 1 3"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[3] 2 2 4 [3,4] 3 5 3"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "[4] 4 2 1 표 1은 3차원 비용 값들(A, B, 및 C)을 나타낼 수 있고, 각각의 차원마다 매칭되는 가중치 및 한계를 갖는다. 예를 들어, 표 내의 값들은 선택적인 시퀀스에 따라 주어진다. 표 2 <선택적 그래프 시퀀스 조합들의 목록> 조합들 A B C 전체 스코어반복 1반복 2"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "[1],[2],[3],[4] 9 9 12 1225.5 25.5 228 [1,2][3][4] 9 5 8 517.5 17.5 220 [1,2,3][4] 9 3 6 313.5 13.5 216 [1,2,3,4] 8 3 6 213 13 193"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "[1],[2,3],[4] 10 5 6 416 16 241"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "[1],[2,3,4] 7 3 6 112.512.5 170 [1,2][3,4]6 6 6 15 15150"}
{"patent_id": "10-2023-0197634", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "[1][2][3,4] 6 10 10 823 23 158 여기서, 표 2는 각 시퀀스 조합에 대한 누적된 차원 값을 나타낼 수 있다. 상기 \"전체 스코어\"(overall score) 열은 시퀀스 조합의 실제 비선형 스코어를 나타낼 수 있다. 다만, 다른 네트워크(예를 들어, 수십 개의 계층로 부터 결합될 수 있는)의 경우, 모든 조합을 나열하는 것은 런타임 및 메모리 측면에서 실현 가능하지 않을 수 있다. 따라서, 본 명세서에서 설명되는 메모이제이션을 갖는 동적 프로그래밍 기술이 구현될 수 있다. 예컨대, 도 7의 예에서, 신경망 그래프(705-a)는 13의 스코어이고, 신경망 그래프(705-b)는 8.5+5=13.5의 스코어이고, 신경망 그래프(705-c)는 5.5+9.5=15의 스코어이고, 신경망 그래프(705-d)는 5.5+7=12.5의 스코어이고, 신경망 그래프(705-e)는 7의 스코어이고, 신경망 그래프(705-f)는 5.5+5=10.5의 스코어이고, 신경망 그래프(705-g)는 8+9.5=17.5의 스코어이고, 신경망 그래프(705-h)는 9.5의 스코어이고, 신경망 그래프(705-i)는 7+5=12의 스코어 이고, 신경망 그래프(705-j)는 5의 스코어를 가질 수 있다. 표 2(예를 들어, 도 7)에 나타낸 바와 같이, 반복 1의 최상의 스코어는 12.5이지만, 치수 A의 값은 제한보다 크 다. 이 때문에, 그 선형 가중치들은 업데이트될 수 있고 절차는 반복될 수 있다. 더 나아가, 반복 2에서, 최적 의 솔루션에 (예를 들어, 획득, 결정 등) 도달될 수 있다. 그러한 반복 프로세스는 가중치가 (예를 들어, 시간 의 최소 변화를 가지고) 수렴할 때까지 계속될 수 있다. 도 8은 본 발명의 양태들에 따른 데이터 표현 다이어그램의 예를 보여준다. 일 양태에서, 데이터 블롭(data blob)은 타일들(예컨대, 타일(805-a) 및 타일(805-b))을 포함한다. 예컨대, 데이터 블롭은 데 이터의 큰 세트(또는 블롭)를 포함하거나 이를 지칭할 수 있다. 일부 양태들에서, 데이터 블롭은 처리를 위한 타일들(예컨대, 타일들(805-a 및 805-b) 및 시퀀스들(예컨대, 시퀀스들(515, 615) 등)로 표현될 수 있다.일부 경우들에서, 데이터 블롭은 (예를 들어, 이진 형태 등과 같은 단일 엔티티로서 저장될 수 있는) 데이 터의 집합을 포함하거나 이를 지칭할 수 있다. 데이터 블롭은 데이터, 정보, 이미지, 비디오 등과 같은 임 의의 유형의 정보를 나타낼 수 있다. 일부 양태들에서, 타일은 더 큰 2차원(또는 3차원) 데이터세트의 더 작은, 직사각형(또는 정사각형) 서브세트로 정의될 수 있다. 타일은 애플리케이션에 따라, 고정된 크기 또 는 가변적인 크기일 수 있다. 데이터 블롭을 더 작은 타일들로 분할함으로써, 성능을 향상시키고 메 모리 사용을 감소시킬 수 있는 (예를 들어, 데이터세트의 가시적인 부분 상에만) 타일 단위로 프로세싱 및 렌더 링이 수행될 수 있다. 다른 한편으로, 시퀀스는 일부 순서로 프로세싱되거나 분석되는 일련의 데이터 아이템들 (예를 들어, 동작들)을 포함하거나 이를 지칭할 수 있다. 예를 들어, 도 8은 (x, y, z) 차원의 데이터 블롭이 y 차원에서 2개(예를 들어, 타일(805-a) 및 타일 (805-b))로 타일링되는 것을 보여준다. 특정 동작에 대해 추론을 수행할 때, 데이터의 크기는 입력 데이터의 크 기 및 가중치에 의해 정의될 수 있다. 추론 엔진이 일부 전체 필요 메모리 크기보다 작은 내부 메모리를 가질 때, 그 데이터는 분할될 수 있고 그 동작은 타일들에서 처리될 수 있다. 그 타일은 데이터 블롭(80 0)의 하나 이상의 차원에서 수행될 수 있다. 일부 양태에서, 시퀀스가 복수 회, 각각의 상이한 타일마다 처리될 때, 타일링 및 시퀀싱은 함께 정의될 수 있다. 본 명세서에 기술된 기술 및 도면은 예시적인 구성들을 나타내며, 청구범위 내의 모든 구현들을 나타내는 것은 아니다. 예컨대, 동작들 및 단계들은 재배열되거나, 결합되거나 또는 다른 방식으로 수정될 수 있다. 또한, 구 조들 및 장치들은 컴포넌트들 간의 관계를 나타내고 기술된 개념들을 모호하게 하는 것을 피하기 위해 블록 다 이어그램의 형태로 표현될 수 있다. 유사한 컴포넌트들 또는 특징들은 동일한 명칭을 가질 수 있지만 상이한 도 면들에 대응하는 상이한 참조 번호들을 가질 수 있다. 본 발명에 대한 일부 수정은 당업자에게 용이하게 명백할 수 있고, 본 명세서에서 정의된 원리들은 개시내용의 범위를 벗어나지 않고 다른 변형예들에 적용될 수 있다. 따라서, 본 발명은 본 명세서에 기술된 예들 및 설계들 에 제한되지 않고, 본 명세서에 개시된 원리들 및 신규 특징들과 일치하는 가장 넓은 범위를 부여받는다. 기재된 시스템 및 방법은 범용 프로세서, DSP, ASIC, FPGA 또는 다른 프로그램 가능 로직 장치, 이산 게이트 또 는 트랜지스터 로직, 이산 하드웨어 컴포넌트, 또는 이들의 임의의 조합을 포함하는 장치에 의해 구현되거나 수 행될 수 있다. 범용 프로세서는 마이크로프로세서, 종래의 프로세서, 컨트롤러, 마이크로컨트롤러, 또는 상태 머신일 수 있다. 프로세서는 또한 컴퓨팅 장치(예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프 로세서, DSP 코어와 연동하는 하나 이상의 마이크로프로세서, 또는 이들의 임의의 다른 구성)의 조합으로 구현 될 수 있다. 따라서, 본 명세서에 기재된 기능은 하드웨어 또는 소프트웨어로 구현될 수 있고, 프로세서, 펌웨 어, 또는 이들의 임의의 조합에 의해 실행될 수 있다. 프로세서에 의해 실행되는 소프트웨어로 구현되는 경우, 기능은 컴퓨터 판독 가능 매체 상의 명령어 또는 코드의 형태로 저장될 수 있다. 컴퓨터 판독 가능 매체는 비일시적 컴퓨터 저장 매체 및 코드 또는 데이터의 전송을 용이하게 하는 임의의 매체 를 포함하는 통신 매체 모두를 포함한다. 비일시적 저장 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체일 수 있다. 예를 들어, 비일시적 컴퓨터 판독 가능 매체는 RAM, ROM, 전기적으로 소거 가능한 프로 그램가능 읽기 전용 메모리(EEPROM), 콤팩트 디스크(CD) 또는 다른 광 디스크 스토리지, 자기 디스크 스토리지, 또는 데이터 또는 코드를 운반하거나 저장하기 위한 임의의 다른 비일시적 매체를 포함할 수 있다. 또한 컴포넌트들을 연결하는 것을 컴퓨터 판독 가능 매체라고 적절히 명명할 수도 있다. 예를 들어, 동축 케이 블, 광섬유 케이블, 트위스트 페어(twisted pair), 디지털 가입자 회선(DSL), 또는 적외선, 라디오 또는 마이크 로파 신호와 같은 무선 기술을 사용하여 웹사이트, 서버 또는 기타 원격 소스로부터 코드 또는 데이터를 전송하 는 경우, 동축 케이블, 광섬유 케이블, 트위스트 페어, DSL 또는 무선 기술은 매체의 정의에 포함된다. 매체들 의 조합들도 컴퓨터 판독 가능 매체들의 범위 내에 포함된다. 본 발명 및 이어지는 청구항들에서, \"또는\"이라는 단어는 예를 들어 X, Y, 또는 Z의 목록이 X, Y, 또는 XY, 또 는 XY, 또는 YZ 또는 XYZ을 의미하도록 하는 포괄적인 리스트를 나타낸다. 또한 \"~에 기초하는\" 이라는 문구는 조건들의 폐쇄된 세트를 나타내기 위해 사용되지 않는다. 예를 들어, \"조건 A에 기초하여\" 로 기술되는 단계는 조건 A 및 조건 B 둘 모두에 기초할 수 있다. 다시 말해서, \"~에 기초하여\" 라는 문구는 \"적어도 부분적으로 기 초하여\"를 의미하는 것으로 해석되어야 한다. 또한, 단수형 단어는 \"적어도 하나\"를 나타낸다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면6 도면7 도면8"}
{"patent_id": "10-2023-0197634", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 본 발명의 양태들에 따른 예시적인 컴퓨팅 시스템들을 보여준다. 도 3은 본 발명의 양태들에 따른 예시적인 인공 지능(AI) 추론 최적화 동작들의 흐름도를 나타낸다. 도 4는 본 발명의 양태들에 따른 AI 추론 최적화를 위한 방법의 일례를 나타낸다. 도 5a, 도 5b 및 도 6은 본 발명의 양태들에 따른 신경망 그래프들의 예들을 나타낸다. 도 7은 본 발명의 양태들에 따른 동적 프로그래밍 다이어그램의 일 예를 나타낸다. 도 8은 본 발명의 양태들에 따른 데이터 표현 다이어그램의 일 예를 나타낸다."}
