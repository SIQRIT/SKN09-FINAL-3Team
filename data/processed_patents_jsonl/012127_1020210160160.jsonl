{"patent_id": "10-2021-0160160", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0069854", "출원번호": "10-2021-0160160", "발명의 명칭": "음향 특성 기반 불안 및 스트레스 예측 방법 및 장치", "출원인": "서울대학교산학협력단", "발명자": "고현웅"}}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대상자의 음성을 녹음하여 음성 샘플을 생성하도록 구성된 음성 입력부;상기 대상자의 인구통계학적 정보를 수신하도록 구성된 데이터 입력부;상기 생성된 음성 샘플에서 음성 특성을 추출하는 음성 특성 추출부; 및상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 심리 상태를 예측하도록 미리 학습된 예측모델을 포함하되,상기 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록미리 학습된 제1 예측 모델; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함하는, 음성 특성 기반 불안 및 스트레스 예측 장치."}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 인구통계학적 정보는 상기 대상자의 연령, 성별 및 교육연수를 포함하는 것을 특징으로 하는, 음성 특성기반 불안 및 스트레스 예측 장치."}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 음성 특성 추출부는 음성의 기본 주파수(fundamental frequency), 발화 속도, 발화 시간, 발화 길이, 휴기정도, 휴기 횟수, 휴기 구간 길이, 쉼머(Shimmer), 지터(Jitter), 포만트(formant), 비음 대 소음 비율(harmonic-to-noise ratio), 라우드니스(loudness), 스펙트럼 수치(spectral centroid) 멜 주파수 켑스트럼 계수(MFCC ,Mel Frequency Cepstral Coefficients), 아이덴티티 벡터(i-vector), 조음 속도, 영교차율(zcr,zero-crossing rate), 음성 확률(vp, voicing probability), 선 스펙트럼 순서쌍(LSP, line spectral paris),주기 변동(Period perturbation), 진폭 변동 지수(APQ, amplitude perturbation quotient), 강성(Stiffness),에너지(Energy), 강도(목소리의 크기, Intensity), 엔트로피(Entropy) 중 적어도 하나를 상기 음성 특성으로 추출하는 것을 특징으로 하는, 음성 특성 기반 불안 및 스트레스 예측 장치."}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 음성 특성 추출부는 상기 음성 샘플에서 인간의 음성을 선별하는 전처리를 수행하는 인공 신경망 모형을포함하며,상기 음성 특성 추출부는 전처리된 음성 샘플에서 상기 음성 특성을 추출하는 것을 특징으로 하는, 음성 특성기반 불안 및 스트레스 예측 장치."}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0069854-3-제1 항에 있어서, 상기 제1 예측 모델은 입력된 상기 음성 특성과 상기 인구통계학적 정보를 기초로 불안 점수를 결과로출력하고, 상기 제2 예측 모델은 입력된 상기 음성 특성과 상기 인구통계학적 정보를 기초로 스트레스 점수를 결과로 출력하며, 상기 불안 점수는 STAI(State-Trait Anxiety Inventory)에 따른 20점 내지 80점 범위에서 결정되며, 상기 스트레스 점수는 PHQ-9(Patient Health Questionnaire-9)에 따른 0점 내지 27점 범위에서 결정되는 것을특징으로 하는, 음성 특성 기반 불안 및 스트레스 예측 장치."}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 제1 예측 모델은 다변량 회귀 분석 모형을 포함하며, 상기 다변량 회귀 분석 모형은 하기 수학식 1과 같이표현되는 것을 특징으로 하는, 음성 특성 기반 불안 및 스트레스 예측 장치.[수학식 1](여기서, X-1 내지 Xp는 독립 변수로서 예측 모델에 입력되는 입력 값으로 p개의 음성 특성 및 인구통계학적 정보에 각각 대응되고, 내지 는 독립 변수의 회귀 계수인 상수 값에 해당하며, 는 초기 상수 값에 해당하고, 는 불안 점수에 해당한다)"}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5 항에 있어서, 상기 제2 예측 모델은 다변량 회귀 분석 모형을 포함하며, 상기 다변량 회귀 분석 모형은 하기 수학식 2과 같이표현되는 것을 특징으로 하는, 음성 특성 기반 불안 및 스트레스 예측 장치.[수학식 2](여기서, X-1 내지 Xp는 독립 변수로서 예측 모델에 입력되는 입력 값으로 p개의 음성 특성 및 인구통계학적 정보에 각각 대응되고, 내지 는 독립 변수의 회귀 계수인 상수 값에 해당하며, 는 초기 상수 값에 해당하고, 는 스트레스 점수에 해당한다)"}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 제1 예측 모델은 입력된 상기 음성 특성과 상기 인구통계학적 정보를 기초로 불안 점수를 결과로 출력하도록 학습된 콘볼루션 신경망(Convolution Neural Network, CNN) 기반의 인공 신경망 모델이며, 공개특허 10-2022-0069854-4-상기 제2 예측 모델은 입력된 상기 음성 특성과 상기 인구통계학적 정보를 기초로 스트레스 점수를 결과로 출력하도록 학습된 콘볼루션 신경망(Convolution Neural Network, CNN) 기반의 인공 신경망 모델인 것을 특징으로하는, 음성 특성 기반 불안 및 스트레스 예측 장치."}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "대상자의 음성을 녹음하여 음성 샘플을 생성하는 단계;상기 대상자의 인구통계학적 정보를 수신하는 단계;상기 생성된 음성 샘플에서 음성 특성을 추출하는 단계; 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는 단계를포함하되,상기 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록미리 학습된 제1 예측 모델; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함하고, 상기 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는단계는 상기 제1 예측 모델을 통해 상기 대상자의 불안 정도를 예측하는 단계; 및 상기 제2 예측 모델을 통해상기 대상자의 스트레스 정도를 예측하도록 단계 중 적어도 하나를 포함하는, 음성 특성 기반 불안 및 스트레스예측 방법."}
{"patent_id": "10-2021-0160160", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터 판독 가능 명령을 저장하는 컴퓨터 판독 가능 기록매체로서, 상기 명령은 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서가 단계들을 수행하도록 하며, 상기 단계들은,대상자의 음성을 녹음하여 음성 샘플을 생성하는 단계;상기 대상자의 인구통계학적 정보를 수신하는 단계;상기 생성된 음성 샘플에서 음성 특성을 추출하는 단계; 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는 단계를 포함하고,상기 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록미리 학습된 제1 예측 모델; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함하고, 상기 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는단계는 상기 제1 예측 모델을 통해 상기 대상자의 불안 정도를 예측하는 단계; 및 상기 제2 예측 모델을 통해상기 대상자의 스트레스 정도를 예측하도록 단계 중 적어도 하나를 포함하는, 기록매체."}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "대상자의 음성을 이용하여 대상자의 불안 및 스트레스를 예측하는 방법 및 장치가 제공된다. 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 장치는 대상자의 음성을 녹음하여 음성 샘플을 생성하도록 구성된 음성 입력부; 상기 대상자의 인구통계학적 정보를 수신하도록 구성된 데이터 입력부; 상기 생성된 음성 샘플에서 음성 특성을 추출하는 음성 특성 추출부; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 심리 상태를 예측하도록 미리 학습된 예측 모델을 포함하되, 상기 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록 미리 학습된 제1 예측 모델; 및 상기 음성 특성과 상기 인 구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하 나를 포함한다."}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 대상자의 음성을 이용하여 대상자의 불안 및 스트레스를 예측하는 방법으로, 불안이나 스트레스에 취 약한 사람들을 대상으로 비침습적 방법을 통하여 현재 정서 상태, 구체적으로 불안 정도 및 스트레스 정도를 정 량적으로 예측하는 방법 및 장치를 제공할 수 있다. [국가지원 연구개발에 대한 설명] 1. 본 연구는 과학기술정보통신부, 정보통신방송혁신인재양성(R&D) 사업 [의료 빅데이터 융합 전문가 인력 양성 을 위한 비정형 빅데이터의 정형화 기술 및 분석 플랫폼 개발, 과제고유번호: 1711126101, 세부과제번호: 2018- 0-01833-004] 지원에 의하여 이루어진 것이다.2. 본 연구는 과학기술정보통신부, 정보통신방송혁신인재양성(R&D) 사업 [의료 빅데이터를 활용한 뇌질환 예측 예방 기술개발 및 전문 인력 양성, 과제고유번호: 1711125764, 세부과제번호: 2017-0-01630-005] 지원에 의하여 이루어진 것이다."}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "4차 산업과 함께 데이터 산업 및 인공지능 산업이 발달하면서 이를 필두로 디지털 헬스케어 시장이 활성화 되고 있다. 특히, 정신 건강 영역은 디지털 헬스케어 시장에서 발전 가능성이 높은 분야로 각광받고 있다. 정신 건강 영역 중 불안이란 신체적 혹은 정신적으로 위협을 인지하였을 때 나타나는 반응으로 안정이 되지 않 은 심리 혹은 정서 상태를 의미한다. 정신 건강 영역 중 스트레스란 정신 및 신체적 자극을 일으키는 심리적, 신체적 반응으로 나타나는 적응을 의미한다. 일상생활에서 불안 및 스트레스는 흔히 경험하는 반응이나, 불안과 스트레스의 강도가 심해지면 염증반응 등의 생물학적인 변화를 일으켜 각종 정신질환의 원인이 될 수 있다. 종래 불안 및 스트레스를 검사하기 위해서는 대면 진료가 필요하며, 설문지 평가, 호르몬 검사 및 종합 심리 검 사 등을 통해 종래 불안 및 스트레스 면밀한 검사를 진행하였다. 대면 진료를 위해 정신 건강 클리닉을 방문하 여야 된다는 제약은 불안 및 스트레스 장애를 조기에 검사 받게 하는 환자의 접근성을 더욱 감소시키는 요인으 로 작용하였다. 또한, 최근 코로나-19의 여파로 대면 진료가 더욱 제한 받는 상황을 감안할 때, 비대면으로 간단하게 이상 수준 의 불안 및 스트레스를 진단하는 방법이 요구되고 있으며, 이러한 비대면 방식의 불안 및 스트레스를 예측하는 방법 및 장치는 비대면 중심 헬스케어 산업에 이점을 가져다 줄 것으로 예상된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허 제10-2016-0035319호"}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 음성의 음향학적 특성을 이용하여 불안 및 스트레스를 예측하기 위한 방법 및 장치에 관한 것으로, 음성인식 마이크, AI 스피커 혹은 스마트 기기를 이용하여 대화 상대자의 응답을 수집하고 음향학적 특성을 추 출하여 추출된 음향학적 특성을 통해 대화 상대자의 불안 및 스트레스 수준을 예측하는 방법 및 장치에 관한 것 이다."}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 장치는 대상자의 음성을 녹음하여 음성 샘플을 생성하도록 구성된 음성 입력부; 상기 대상자의 인구통계학적 정보를 수신하도록 구성된 데이터 입력부; 상기 생성된 음성 샘플에서 음성 특성을 추출하는 음성 특성 추출부; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 심리 상태를 예측하도록 미리 학습된 예측 모델을 포함하되, 상기 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록 미리 학습된 제1 예측 모델; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함한다. 본 발명의 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 방법은 대상자의 음성을 녹음하여 음성 샘플을 생성하는 단계; 상기 대상자의 인구통계학적 정보를 수신하는 단계; 상기 생성된 음성 샘플에서 음성 특성을 추 출하는 단계; 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예 측하는 단계를 포함하되, 상기 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록 미리 학습된 제1 예측 모델; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상 기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함하고, 상기 예측 모 델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는 단계는 상기제1 예측 모델을 통해 상기 대상자의 불안 정도를 예측하는 단계; 및 상기 제2 예측 모델을 통해 상기 대상자의 스트레스 정도를 예측하도록 단계 중 적어도 하나를 포함한다. 본 발명의 실시예에 따른 기록매체는 컴퓨터 판독 가능 명령을 저장하는 컴퓨터 판독 가능 기록매체로서, 상기 명령은 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서가 단계들을 수행하도록 하며, 상기 단계들은, 대상자의 음성을 녹음하여 음성 샘플을 생성하는 단계; 상기 대상자의 인구통계학적 정보를 수 신하는 단계; 상기 생성된 음성 샘플에서 음성 특성을 추출하는 단계; 예측 모델에 상기 음성 특성과 상기 인구 통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는 단계를 포함하고, 상기 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록 미리 학습된 제1 예측 모델; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함하고, 상기 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력 하여 상기 대상자의 심리 상태를 예측하는 단계는 상기 제1 예측 모델을 통해 상기 대상자의 불안 정도를 예측 하는 단계; 및 상기 제2 예측 모델을 통해 상기 대상자의 스트레스 정도를 예측하도록 단계 중 적어도 하나를 포함한다."}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 음향 특성 기반 불안 및 스트레스 예측 방법 및 장치는 음성의 특징만을 이용하여 당 사자의 불안 및 스트레스 수준을 예측할 수 있으며, 대면 의사진료 및 설문지 방법으로 측정해야 했던 기존 방 법에 수반되는 기존에 시간적, 공간적, 자원적 한계를 극복할 수 있으며, 대면 상황을 꺼려하는 사람들을 대상 으로도 진단을 지원할 수 있다."}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부한 도면을 참조하여 설명한다. 본 발명은 도면에 도시된 실시 예를 참 고로 설명되었으나 이는 하나의 실시 예로서 설명되는 것이며, 이것에 의해 본 발명의 기술적 사상과 그 핵심 구성 및 작용은 제한되지 않는다. 도 1 및 도 2를 참조하면, 본 발명의 실시예에 따른 불안 및 스트레스 예측 장치은 음성 입력부, 데이 터 입력부, 음성 특성 추출부, 예측 모델 및 데이터 저장부를 포함한다. 불안 및 스트레스 예측 장치는, 전적으로 하드웨어이거나, 또는 부분적으로 하드웨어이고 부분적으로 소프 트웨어인 측면을 가질 수 있다. 예컨대, 본 명세서의 불안 및 스트레스 예측 장치 및 이에 포함된 각 부는, 특정 형식 및 내용의 데이터를 전자통신 방식으로 주고받기 위한 장치 및 이에 관련된 소프트웨어를 통칭할 수 있다. 본 명세서에서 \"부\", \"모듈(module)\", \"서버(server)\", \"장치\", \"장치\" 또는 \"단말\" 등의 용어는 하드웨 어 및 해당 하드웨어에 의해 구동되는 소프트웨어의 조합을 지칭하는 것으로 의도된다. 예를 들어, 여기서 하드 웨어는 CPU 또는 다른 프로세서(processor)를 포함하는 데이터 처리 기기일 수 있다. 또한, 하드웨어에 의해 구 동되는 소프트웨어는 실행중인 프로세스, 객체(object), 실행파일(executable), 실행 스레드(thread of execution), 프로그램(program) 등을 지칭할 수 있다. 또한, 불안 및 스트레스 예측 장치를 구성하는 각각의 모듈은 반드시 물리적으로 구분되는 별개의 구성요소 를 지칭하는 것으로 의도되지 않는다. 도 1에서 음성 입력부, 데이터 입력부, 음성 특성 추출부 , 예측 모델 및 데이터 저장부는 서로 구분되는 별개의 블록으로 도시되나, 이는 불안 및 스트 레스 예측 장치을 구성하는 장치를 해당 장치에 의해 실행되는 동작에 의해 단지 기능적으로 구분한 것이다. 따라서, 실시예에 따라서는 음성 입력부, 데이터 입력부, 음성 특성 추출부, 예측 모델 및 데이터 저장부는 일부 또는 전부가 동일한 하나의 장치 내에 집적화될 수 있다. 예를 들어, 불안 및 스트레스 예측 장치는 AI 스피커와 같은 음성 인식과 데이터 처리 능력을 가진 장치를 통해 구현될 수 있다. 다만 이에 한정되는 것은 아니며, 상기 구성들은 하나 이상이 다른 부와 물리적으로 구분되는 별개의 장 치로 구현될 수도 있으며, 분산 컴퓨팅 환경 하에서 서로 통신 가능하게 연결된 컴포넌트들일 수도 있다. 음성 입력부는 대상자의 음성 샘플을 생성한다. 음성 입력부는 대상자의 음성을 일정 주파수로 녹음 하여 음성 샘플을 생성하도록 구성될 수 있다. 음성 입력부는 콘덴서 마이크 및 이를 제어하기 위한 장치 를 포함할 수 있으며, 16Hz 이상의 주파수로 대상자의 음성을 녹음하여 음성 샘플을 생성할 수 있다. 대상자는 녹음이 가능한 조용한 방에서 그림 묘사, 표준 문단 발화 및 이야기 회상하기 과제 중 적어도 하나를 실시하여 자연 발화 또는 낭독 발화를 하게 되며, 음성 입력부는 이러한 대상자의 발화를 녹음하여 음성 샘플을 생 성하게 된다. 데이터 입력부는 대상자의 인구통계학적 정보를 수신한다. 인구통계학적 정보는 적어도 대상자의 연령, 성 별, 교육연수(교육을 받은 학력 정도)를 포함한다. 데이터 입력부를 통해 입력되는 자료는 대상자의 연령, 성별, 교육연수를 확인할 수 있거나, 이러한 정보들을 추출할 수 있는 데이터를 의미한다. 예시적으로, 인구통 계학적 정보는 대상자의 문진 자료를 통해 습득될 수 있다. 문진 자료는 환자의 연령, 성별, 교육연수와 관련된 정보를 포함할 수 있으며, 훈련된 전문의의 의학적 판단을 이용하여 생성되는 자료에 해당하며, 기타 의료진 및 환자의 보호자 관리하에 수집된 자료일 수 있다. 데이터 입력부는 상술한 문진 자료를 통해 인구통계학적 정보를 수신할 수 있으나, 이에 한정되는 것은 아니다. 몇몇 실시예에서, 대상자의 인구통계학적 정보는 대상자 가 직접 입력한 정보일 수 있다. 음성 입력부, 데이터 입력부를 통해 입력된 데이터들은 데이터 저장부에 저장될 수 있다. 데이 터 저장부는 입력된 데이터들이 저장되거나, 후술하는 예측 모델의 데이터 처리에 필요한 임시 또는 일시 적 저장 공간을 제공하도록 구성될 수 있다. 음성 특성 추출부는 입력된 대상자의 음성 샘플에서 환자의 음성 특성을 추출할 수 있다. 음성 특성 추출 부는 음성 샘플의 음운 특성, 근원 특성, 스펙트럼 특성과 관련된 음성 특성을 추출할 수 있다. 구체적으 로, 음성 특성 추출부는 대상자 음성의 기본 주파수(fundamental frequency), 발화와 관련된 정보(발화 속 도, 발화 시간, 발화 길이) 휴기와 관련된 정보(휴기 정도, 휴기 횟수, 휴기 구간 길이), 쉼머(Shimmer), 지터 (Jitter), 포만트(formant), 비음 대 소음 비율(harmonic-to-noise ratio), 라우드니스(loudness), 스펙트럼 수치(spectral centroid) 멜 주파수 켑스트럼 계수(MFCC ,Mel Frequency Cepstral Coefficients), 아이덴티티 벡터(i-vector), 조음 속도, 영교차율(zcr, zero-crossing rate), 음성 확률(vp, voicing probability), 선 스 펙트럼 순서쌍(LSP, line spectral paris), 주기 변동(Period perturbation), 진폭 변동 지수(APQ, amplitude perturbation quotient), 강성(Stiffness), 에너지(Energy), 강도(목소리의 크기, Intensity), 엔트로피 (Entropy) 중 적어도 하나를 음성 특성으로 추출할 수 있다. 여기서, 음성 특성 추출부은 음성 샘플을 정량화하기 위한 전처리 과정을 먼저 수행할 수 있다. 전처리 과 정을 통해 음성 샘플의 시간, 주파수 등이 일정하도록 조정될 수 있다. 또한, 전처리 과정을 통해 사람의 음성 과 사람의 음성이 아닌 부분이 구분될 수 있다. 음성 특성 추출부은 입력된 음성 샘플에서 사람의 음성만 을 선별하도록 학습된 인공 신경망 모형(예를 들어, 합성곱 신경망)을 포함할 수 있으며, 학습된 인공 신경망 모형을 통해 상술한 사람의 음성만을 선별하는 전처리를 수행할 수 있다. 음성 특성 추출부는 전처리된 음성 샘플에서 음성의 기본 주파수(fundamental frequency), 발화 속도, 발 화 시간, 발화 길이, 휴기 정도, 휴기 횟수, 휴기 구간 길이, 쉼머(Shimmer), 지터(Jitter), 포만트(formant), 비음 대 소음 비율(harmonic-to-noise ratio), 라우드니스(loudness), 스펙트럼 수치(spectral centroid) 멜 주파수 켑스트럼 계수(MFCC ,Mel Frequency Cepstral Coefficients), 아이덴티티 벡터(i-vector), 조음 속도, 영교차율(zcr, zero-crossing rate), 음성 확률(vp, voicing probability), 선 스펙트럼 순서쌍(LSP, line spectral paris), 주기 변동(Period perturbation), 진폭 변동 지수(APQ, amplitude perturbation quotient), 강성(Stiffness), 에너지(Energy), 강도(목소리의 크기, Intensity), 엔트로피(Entropy) 중 적어도 하나를 포 함하는 음성 특성을 추출할 수 있다. 음성 특성 추출부는 공개된 음성 특성 추출 프로그램(예를 들어, Praat)를 이용하여 음운, 근원, 스펙트럼 영역에 해당하는 음성 특성을 추출할 수도 있다. 예측 모델은 음성 특성 추출부에서 추출된 음성 특성과 데이터 입력부를 통해 제공된 인구통계 학적 정보를 통해 대상자의 심리 상태를 예측하도록 미리 학습된 상태일 수 있다. 여기서, 대상자의 심리 상태 는 대상자의 스트레스 정도와 대상자의 불안 정도 중 적어도 하나를 포함한다. 예측 모델은 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록 미리 학습된 제1 예측 모델 ; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함한다. 제1 예측 모델은 회귀 모형 또는 기계학습 모형을 포함할 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 대상자의 불안 점수를 결과로 출력할 수 있다. 여기서, 불안 점수는 STAI(State-Trait Anxiety Inventory)에 따른 20점 내지 80점 범위에서 결정될 수 있다. 구체적으로, 제1 예측 모델은 다변량 회귀 분석 모형을 포함하며, 다변량 회귀 분석 모형은 하기 수학식 1 과 같이 표현될 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "(여기서, X-1 내지 Xp는 독립 변수로서 예측 모델에 입력되는 입력 값으로 p개의 음성 특성 및 인구통계학적 정 보에 각각 대응되고, 내지 는 독립 변수의 회귀 계수인 상수 값에 해당하며, 는 초기 상수 값에 해당 하고, 는 불안 점수에 해당한다) 상술한 수학식 1에 기초하여 구성된 제1 예측 모델은 불안 점수를 출력할 수 있으며, 제1 예측 모델 의 불안 점수에 기초하여 대상자의 불안 정도를 확인할 수 있다. 또한, 제1 예측 모델은 콘볼루션 신경망(Convolution Neural Network, CNN) 기반의 인공 신경망 모델로 구현될 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 대상자의 불안 점수를 결과로 출력할 수 있다. 여기서, 불안 점수는 STAI(State-Trait Anxiety Inventory)에 따른 20점 내지 80점 범위에서 결정될 수 있다. 제2 예측 모델은 회귀 모형 또는 기계학습 모형을 포함할 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 스트레스 점수를 결과로 출력할 수 있다. 여기서, 상기 스트레스 점수는 PHQ-9(Patient Health Questionnaire-9)에 따른 0점 내지 27점 범위에서 결정될 수 있다. 예시적으로, 제2 예측 모델는 다변량 회귀 분석 모형을 포함하며, 다변량 회귀 분석 모형은 하기 수학식 2 과 같이 표현될 수 있다. [수학식 2]"}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(여기서, X-1 내지 Xp는 독립 변수로서 예측 모델에 입력되는 입력 값으로 p개의 음성 특성 및 인구통계학적 정 보에 각각 대응되고, 내지 는 독립 변수의 회귀 계수인 상수 값에 해당하며, 는 초기 상수 값에 해당 하고, 는 스트레스 점수에 해당한다) 상술한 수학식 2에 기초하여 구성된 제2 예측 모델은 스트레스 점수를 출력할 수 있으며, 제2 예측 모델 의 스트레스 점수에 기초하여 대상자의 스트레스 정도를 확인할 수 있다. 또한, 제2 예측 모델은 콘볼루션 신경망(Convolution Neural Network, CNN) 기반의 인공 신경망 모델로 구현될 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 스트레스 점수를 결과로 출력할 수 있다. 여기서, 상기 스트레스 점수는 PHQ-9(Patient Health Questionnaire-9)에 따른 0점 내지 27점 범위에서 결정될 수 있다. 본 발명의 실시예에 따른 음향 특성 기반 불안 및 스트레스 예측 장치는 음성의 특징만을 이용하여 당사자의 불 안 및 스트레스 수준을 예측할 수 있으며, 대면 의사진료 및 설문지 방법으로 측정해야 했던 기존 방법에 수반 되는 기존에 시간적, 공간적, 자원적 한계를 극복할 수 있으며, 대면 상황을 꺼려하는 사람들을 대상으로도 진단을 지원할 수 있다. 이하, 본 발명의 다른 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 방법을 설명하도록 한다. 도 3은 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 방법의 순서도이다. 본 방법은 도 1 및 도 2에 따 른 예측 장치에서 수행될 수 있으며, 본 실시예의 설명을 위해 도 1, 도 2 및 관련 설명이 참조될 수 있다. 도 3을 참조하면, 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 방법은 대상자의 음성을 녹음하여 음성 샘플을 생성하는 단계(S100); 상기 대상자의 인구통계학적 정보를 수신하는 단계(S110); 상기 생성된 음성 샘플 에서 음성 특성을 추출하는 단계(S120); 및 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는 단계(S130)를 포함한다. 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 방법의 각 단계에서 단계(S100)와 단계(S110)는 설명의 편의를 위해 순차적으로 기재하고 설명하는 것으로, 기재 순서에 국한되어 순차적으로 수행되는 것은 아니다. 몇몇 실시예에서, 단계(S110)가 단계(S100)보다 먼저 수행될 수도 있다. 또한, 상기 예측 방법이 수행되기 이전 예측 모델을 학습하는 단계가 먼저 수행될 수 있다. 대상자의 음성을 녹음하여 음성 샘플을 생성한다(S100). 대상자는 녹음이 가능한 조용한 방에서 그림 묘사, 표준 문단 발화 및 이야기 회상하기 과제 중 적어도 하나를 실시하여 자연 발화 또는 낭독 발화를 하게 되며, 이러한 대상자의 발화를 녹음하여 음성 샘플을 생성하게 된다. 음성 입력부는 콘덴서 마이크 및 이를 제어하기 위한 장치를 포함할 수 있으며, 16Hz 이상의 주파수 로 대상자의 음성을 녹음하여 음성 샘플을 생성할 수 있다. 상기 대상자의 인구통계학적 정보를 수신한다(S110). 상기 인구통계학적 정보는 상기 대상자의 연령, 성별 및 교육연수를 포함한다. 예시적으로, 인구통계학적 정보 는 대상자의 문진 자료를 통해 습득될 수 있다. 문진 자료는 환자의 연령, 성별, 교육연수와 관련된 정보를 포 함할 수 있으며, 훈련된 전문의의 의학적 판단을 이용하여 생성되는 자료에 해당하며, 기타 의료진 및 환자의 보호자 관리하에 수집된 자료일 수 있다. 데이터 입력부는 상술한 문진 자료를 통해 인구통계학적 정보를 수신할 수 있으나, 이에 한정되는 것은 아니다. 몇몇 실시예에서, 대상자의 인구통계학적 정보는 대상자가 직접 입력한 정보일 수 있다. 다음으로, 생성된 음성 샘플에서 음성 특성을 추출한다(S120). 입력된 대상자의 음성 샘플에서 환자의 음성 특성이 추출될 수 있다. 환자의 음성 샘플을 정량화하기 위한 전처 리 과정에 인공 신경망 모형이 활용될 수 있다. 전처리 과정을 통해 음성 샘플의 시간, 주파수 등이 일정하도록 조정될 수 있다. 또한, 입력된 음성 샘플이 다수인 경우 음성 샘플을 선별하기 위한 전처리 과정이 수행될 수 있다. 음성 특성 추출부는 전처리된 음성 샘플에서 음성의 기본 주파수(fundamental frequency), 발화 속 도, 발화 시간, 발화 길이, 휴기 정도, 휴기 횟수, 휴기 구간 길이, 쉼머(Shimmer), 지터(Jitter), 포만트 (formant), 비음 대 소음 비율(harmonic-to-noise ratio), 라우드니스(loudness), 스펙트럼 수치(spectral centroid) 멜 주파수 켑스트럼 계수(MFCC ,Mel Frequency Cepstral Coefficients), 아이덴티티 벡터(i- vector), 조음 속도, 영교차율(zcr, zero-crossing rate), 음성 확률(vp, voicing probability), 선 스펙트럼 순서쌍(LSP, line spectral paris), 주기 변동(Period perturbation), 진폭 변동 지수(APQ, amplitude perturbation quotient), 강성(Stiffness), 에너지(Energy), 강도(목소리의 크기, Intensity), 엔트로피 (Entropy) 중 적어도 하나를 포함하는 음성 특성을 추출할 수 있다. 다음으로, 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측 한다(S130). 예측 모델은 음성 특성 추출부에서 추출된 음성 특성과 데이터 입력부를 통해 제공된 인구통계 학적 정보를 통해 대상자의 심리 상태를 예측하도록 미리 학습된 상태일 수 있다. 여기서, 대상자의 심리 상태 는 대상자의 스트레스 정도와 대상자의 불안 정도 중 적어도 하나를 포함한다. 예측 모델은 상기 음성 특 성과 상기 인구통계학적 정보를 기초로 상기 대상자의 불안 정도를 예측하도록 미리 학습된 제1 예측 모델 ; 및 상기 음성 특성과 상기 인구통계학적 정보를 기초로 상기 대상자의 스트레스 정도를 예측하도록 미리 학습된 제2 예측 모델 중 적어도 하나를 포함한다. 예측 모델에 상기 음성 특성과 상기 인구통계학적 정보를 입력하여 상기 대상자의 심리 상태를 예측하는 단계 (S130)는 상기 제1 예측 모델을 통해 상기 대상자의 불안 정도를 예측하는 단계; 및 상기 제2 예측 모델을 통해 상기 대상자의 스트레스 정도를 예측하도록 단계 중 적어도 하나를 포함한다. 제1 예측 모델은 회귀 모형 또는 기계학습 모형을 포함할 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 대상자의 불안 점수를 결과로 출력할 수 있다. 여기서, 불안 점수는 STAI(State-Trait Anxiety Inventory)에 따른 20점 내지 80점 범위에서 결정될 수 있다. 구체적으로, 제1 예측 모델은 다변량 회귀 분석 모형을 포함하며, 다변량 회귀 분석 모형은 하기 수학식 1 과 같이 표현될 수 있다. [수학식 1]"}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(여기서, X-1 내지 Xp는 독립 변수로서 예측 모델에 입력되는 입력 값으로 p개의 음성 특성 및 인구통계학적 정 보에 각각 대응되고, 내지 는 독립 변수의 회귀 계수인 상수 값에 해당하며, 는 초기 상수 값에 해당 하고, 는 불안 점수에 해당한다) 상술한 수학식 1에 기초하여 구성된 제1 예측 모델은 불안 점수를 출력할 수 있으며, 제1 예측 모델 의 불안 점수에 기초하여 대상자의 불안 정도를 확인할 수 있다. 또한, 제1 예측 모델은 콘볼루션 신경망(Convolution Neural Network, CNN) 기반의 인공 신경망 모델로 구현될 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 대상자의 불안 점수를 결과로 출력할 수 있다. 여기서, 불안 점수는 STAI(State-Trait Anxiety Inventory)에 따른 20점 내지 80점 범위에서 결정될 수 있다. 제2 예측 모델은 회귀 모형 또는 기계학습 모형을 포함할 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 스트레스 점수를 결과로 출력할 수 있다. 여기서, 상기 스트레스 점수는 PHQ-9(Patient Health Questionnaire-9)에 따른 0점 내지 27점 범위에서 결정될 수 있다. 예시적으로, 제2 예측 모델는 다변량 회귀 분석 모형을 포함하며, 다변량 회귀 분석 모형은 하기 수학식 2 과 같이 표현될 수 있다. [수학식 2]"}
{"patent_id": "10-2021-0160160", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "(여기서, X-1 내지 Xp는 독립 변수로서 예측 모델에 입력되는 입력 값으로 p개의 음성 특성 및 인구통계학적 정 보에 각각 대응되고, 내지 는 독립 변수의 회귀 계수인 상수 값에 해당하며, 는 초기 상수 값에 해당 하고, 는 스트레스 점수에 해당한다) 상술한 수학식 2에 기초하여 구성된 제2 예측 모델은 스트레스 점수를 출력할 수 있으며, 제2 예측 모델 의 스트레스 점수에 기초하여 대상자의 스트레스 정도를 확인할 수 있다. 또한, 제2 예측 모델은 콘볼루션 신경망(Convolution Neural Network, CNN) 기반의 인공 신경망 모델로 구현될 수 있으며, 상기 음성 특성과 상기 인구통계학적 정보를 기초로 스트레스 점수를 결과로 출력할 수 있다. 여기서, 상기 스트레스 점수는 PHQ-9(Patient Health Questionnaire-9)에 따른 0점 내지 27점 범위에서 결정될 수 있다. 본 발명의 실시예에 따른 음향 특성 기반 불안 및 스트레스 예측 방법은 음성의 특징만을 이용하여 당사자의 불 안 및 스트레스 수준을 예측할 수 있으며, 대면 의사진료 및 설문지 방법으로 측정해야 했던 기존 방법에 수반 되는 기존에 시간적, 공간적, 자원적 한계를 극복할 수 있으며, 대면 상황을 꺼려하는 사람들을 대상으로도 진 단을 지원할 수 있다.이러한 실시예들에 따른 음성 특성 기반 불안 및 스트레스 예측 방법은, 애플리케이션으로 구현되거나 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이제까지 본 발명에 대하여 그 바람직한 실시예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통 상의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시예들은 한정적인 관점이 아니라 설명적인 관점에서 고 려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다. 실험예 상술한 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 방법 및 장치의 제1 예측 모델 및 제2 예측 모델 을 각각 구축하고, 구축된 제1 예측 모델 및 제2 예측 모델을 검증하는 실험을 수행하였다. 제1 예측 모델 및 제2 예측 모델의 구축을 위한 대상자는 총 82명으로, 서울대학교 학생들을 대상으로 음성 및 심리 상태 정보를 획득하였다. 대상자의 평균연령 22.2±4.50세, 남성 40명, 여성 42명, 평균교육연수 13.4± 2.24이다. 대상자의 음성을 정량화 하기 위하여, 먼저 인공신경망 모형(합성곱 신경망)을 활용하여 음성 샘플에 대한 전처 리를 수행하였다. 즉, 입력된 음성 샘플이 다수인 경우 사람의 음성 샘플을 선별하기 위한 전처리 과정이 먼저 수행되어 학습에 노이즈 데이터가 입력되는 것을 방지하였다. 전처리된 음성에 대하여 자동화된 음성 특성 추출 방법을 활용하여 음성의 음성 특성을 추출하였다. 음성의 기본 주파수(fundamental frequency(f0) mean, f0 std), 발화와 관련된 정보(발화 속도, 발화 시간, 발화 길이), 휴기(pause)와 관련된 정보(pause rate, pause count, pause duration mean, pause duration standard deviation(std)), 쉼머(Shimmer), 지터(Jitter), 포만 트(formant), 비음 대 소음 비율(harmonic-to-noise ratio), 라우드니스(loudness), 스펙트럼 수치(spectral centroid mean, spectral centroid std)와 같은 음성 특성이 각각 추출되었다. 인구 통계학적 정보(연령, 성별, 교육연수)와 추출된 각각의 음성 특성을 입력 값으로 하고, 대상자들이 책정한 불안 점수(State-Trait Anxiety Inventory, STAI)가 출력 값이 되는 제1 예측 모델을 상기 수학식 1과 같은 다 변량 회귀 분석 모형 기반으로 구축하였다. 또한, 인구 통계학적 정보(연령, 성별, 교육연수)와 추출된 각각의 음성 특성을 입력 값으로 하고, 대상자들이 책정한 스트레스 점수(Patient Health Questionnaire-9, PHQ-9)가 출력 값이 되는 제2 예측 모델을 상기 수학 식 2와 같은 다변량 회귀 분석 모형 기반으로 구축하였다. 구축된 제1 예측 모델과 제2 예측 모델에 대한 예측 성능을 테스트하였다. 도 4는 인구 통계학 및 음성 특성을 고려한 불안 예측 결과를 도시한 그래프로, 제1 예측 모델의 성능을 나타낸 다. 도 4를 참조하면, R-squared 값이 0.583을 나타난 것을 알 수 있다. 도 5는 인구 통계학 및 음성 특성을 고 려한 스트레스 예측 결과를 도시한 그래프로, 제2 예측 모델의 성능을 나타낸다. 도 5를 참조하면, R-squared 값이 0.716을 나타난 것을 알 수 있다. 이와 달리, 본원 발명의 음성 특성 기반 불안 및 스트레스 예측 방법 및 장치는 비침습적인 방법을 사용한 검사 를 통해서 사용자의 심리 상태(불안, 스트레스 정도)를 예측하는 것으로, AI스피커/스마트폰/태블릿/PC 등을 통 해 진행할 수 있는 시간, 공간, 전문가를 초월한 예측 방법으로 병원 아닌 곳에서 편하게 검사를 진행할 수 있 는 사용자 편의성을 제공할 수 있다.부호의 설명 10: 불안 및 스트레스 예측 장치 100: 음성 입력부 110: 데이터 입력부 120: 음성 특성 추출부 130: 예측 모델 140: 데이터 저장부"}
{"patent_id": "10-2021-0160160", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 장치의 구성을 도시한 블록도이다. 도 2는 본 발명의 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 장치의 동작 과정에 예시적으로 도시한 다. 도 3은 본 발명의 실시예에 따른 음성 특성 기반 불안 및 스트레스 예측 방법의 순서를 도시한 블록도이다. 도 4는 인구 통계학 및 음성 특성을 고려한 불안 예측 결과를 도시한 그래프이다. 도 5는 인구 통계학 및 음성 특성을 고려한 스트레스 예측 결과를 도시한 그래프이다."}
