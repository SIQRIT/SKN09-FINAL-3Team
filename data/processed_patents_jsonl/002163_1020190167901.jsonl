{"patent_id": "10-2019-0167901", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0076558", "출원번호": "10-2019-0167901", "발명의 명칭": "인공지능 서비스 대화모델의 학습 문구 품질 검증 장치 및 방법", "출원인": "주식회사 엘지유플러스", "발명자": "신광수"}}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력된 대화 의도 별 하나 이상의 학습 문구를 임베딩하기 위한 임베딩부;대화 의도가 다른 임베딩된 두 학습 문구 간의 유사도를 계산하기 위한 유사도계산부;동일 대화 의도 내 임베딩된 모든 학습 문구의 응집도를 계산하기 위한 응집도계산부; 및상기 계산된 유사도 및 응집도를 기초로 대화 의도 내 특정 학습 문구를 유사 발화 문구로 선택하여 추출하기위한 유사문구추출부;를 포함하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 임베딩부는 .CVS(Comma-Separated Value) 포맷의 학습 문구를 입력하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 유사도계산부는 코사인(Cosine) 유사도 계산 방식으로 유사도를 계산하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 코사인(Cosine) 유사도 계산 방식은 사이킷-런(Scikit-learn)의 코사인 유사도(Cosine Similarity) 방식을 포함하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 응집도계산부는 동일 대화 의도 내 임베딩된 모든 학습 문구의 평균 유사도를 응집도로 산출하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 유사문구추출부는 응집도가 해당 기준보다 낮고 유사도가 해당 기준보다 높은 학습 문구를 유사 발화 문구로 선택하여 추출하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 임베딩부는 입력된 학습 문구를 텐서플로우 허브(TensorFlow hub) 방식을 통해 임베딩하는 것을 특징으로하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "(a) 입력된 대화 의도 별 하나 이상의 학습 문구를 임베딩하기 위한 단계;공개특허 10-2021-0076558-3-(b) 대화 의도가 다른 임베딩된 두 학습 문구 간의 유사도를 계산하기 위한 단계;(c) 동일 대화 의도 내 임베딩된 모든 학습 문구의 응집도를 계산하기 위한 단계; 및(d) 상기 계산된 유사도 및 응집도를 기초로 대화 의도 내 특정 학습 문구를 유사 발화 문구로 선택하여 추출하기 위한 단계; 를 포함하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 단계 (a)는 .CVS(Comma-Separated Value) 포맷의 학습 문구를 입력하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 단계 (b)는 코사인(Cosine) 유사도 계산 방식으로 유사도를 계산하는 것을 특징으로 하는 인공지능 서비스대화모델의 학습 문구 품질 검증 방법."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 코사인(Cosine) 유사도 계산 방식은 사이킷-런(Scikit-learn)의 코사인 유사도(Cosine Similarity) 방식을 포함하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 단계 (c)는 동일 대화 의도 내 임베딩된 모든 학습 문구의 평균 유사도를 응집도로 산출하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 단계 (d)는 응집도가 해당 기준보다 낮고 유사도가 해당 기준보다 높은 학습 문구를 유사 발화 문구로 선택하여 추출하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 단계 (a)는 입력된 학습 문구를 텐서플로우 허브(TensorFlow hub) 방식을 통해 임베딩하여 벡터화 하는 것을 특징으로 하는 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제8항 내지 제14항 중 어느 한 항의 상기 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법을 컴퓨터에서실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제8항 내지 제14항 중 어느 한 항의 상기 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법을 하드웨어와결합하여 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록 매체에 저장된 애플리케이션."}
{"patent_id": "10-2019-0167901", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제8항 내지 제14항 중 어느 한 항의 상기 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법을 컴퓨터에서공개특허 10-2021-0076558-4-실행시키기 위하여 컴퓨터로 읽을 수 있는 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2019-0167901", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 예시적인 실시예는 인공지능 서비스 대화모델의 학습 문구 중 대화 의도는 다르지만 문장이 유사하여 혼동을 줄 수 있는 유사 발화 문구들을 사전에 자동으로 인지하고 해당 문구들의 수정을 통해 의도분류 정확도 개선 및 편의성을 개선 할 수 있는 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치 및 방법에 관한 것으 로, 본 발명의 일 측면에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치는, 입력된 대화 의도 별 하나 이상의 학습 문구를 임베딩하기 위한 임베딩부; 대화 의도가 다른 임베딩된 두 학습 문구 간의 유사도를 계 산하기 위한 유사도계산부; 동일 대화 의도 내 임베딩된 모든 학습 문구의 응집도를 계산하기 위한 응집도계산부; 및 상기 계산된 유사도 및 응집도를 기초로 대화 의도 내 특정 학습 문구를 유사 발화 문구로 선 택하여 추출하기 위한 유사문구추출부를 포함할 수 있다."}
{"patent_id": "10-2019-0167901", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 서비스 대화모델의 학습 문구 품질을 검증하기 위한 기술에 관한 것이다."}
{"patent_id": "10-2019-0167901", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 대화모델은 모델 개발자 또는 서비스 운영 담당자가 기존 대화 시나리오나 상담 이력 등의 데이터 를 대화의도 기준으로 레이블링하여 학습을 하고 있다. 이때 다량의 학습문구를 사용하기 때문에 대화의도 간 구분하기 힘든 유사 발화 문구들이 존재할 수 있는데, 이 경우 해당 유사 발화 문구들은 대화의도 분류 성공률 을 저하시킬 수 있다. 따라서, 룰기반/딥러닝기반 방식에 상관없이 학습 전 데이터 전처리 단계에서 대화의도(Intent) 별 학습문구들 간 유사 발화 문구들을 수작업으로 확인, 제거 또는 수정하는 과정이 필요한데, 이러한 수작업은 많은 시간이 소요되며 휴먼에러 또한 발생하기 때문에 자동화를 통해 의도분류의 정확도/편의성 등을 개선할 필요가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2011-0099434호(2011.09.08.)"}
{"patent_id": "10-2019-0167901", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래의 문제점을 해결하기 위한 것으로, 그 목적은 인공지능 서비스 대화모델의 학습 문구 중 대화 의도는 다르지만 문장이 유사하여 혼동을 줄 수 있는 유사 발화 문구들을 사전에 자동으로 인지하고 해당 문구들의 수정을 통해 의도분류 정확도 개선 및 편의성을 개선 할 수 있는, 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2019-0167901", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위하여 본 발명의 일 측면에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 장 치는, 입력된 대화 의도 별 하나 이상의 학습 문구를 임베딩하기 위한 임베딩부; 대화 의도가 다른 임베딩된 두 학습 문구 간의 유사도를 계산하기 위한 유사도계산부; 동일 대화 의도 내 임베딩된 모든 학습 문구의 응집도를 계산하기 위한 응집도계산부; 및 상기 계산된 유사도 및 응집도를 기초로 대화 의도 내 특정 학습 문구를 유사 발화 문구로 선택하여 추출하기 위한 유사문구추출부를 포함할 수 있다. 상기 임베딩부는 .CVS(Comma-Separated Value) 포맷의 학습 문구를 입력할 수하는 있고, 상기 유사도계산부는 코사인(Cosine) 유사도 계산 방식으로 유사도를 계산할 수 있으며, 상기 코사인(Cosine) 유사도 계산 방식은 사 이킷-런(Scikit-learn)의 코사인 유사도(Cosine Similarity) 방식을 포함할 수 있다. 상기 응집도계산부는 동일 대화 의도 내 임베딩된 모든 학습 문구의 평균 유사도를 응집도로 산출할 수 있고, 상기 유사문구추출부는 응집도가 해당 기준보다 낮고 유사도가 해당 기준보다 높은 학습 문구를 유사 발화 문구 로 선택하여 추출할 수 있다. 전술한 목적을 달성하기 위하여 본 발명의 다른 측면에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법은, (a) 입력된 대화 의도 별 하나 이상의 학습 문구를 임베딩하기 위한 단계; (b) 대화 의도가 다른 임베 딩된 두 학습 문구 간의 유사도를 계산하기 위한 단계; (c) 동일 대화 의도 내 임베딩된 모든 학습 문구의 응집 도를 계산하기 위한 단계; 및 (d) 상기 계산된 유사도 및 응집도를 기초로 대화 의도 내 특정 학습 문구를 유사 발화 문구로 선택하여 추출하기 위한 단계를 포함할 수 있다.상기 단계 (a)는 .CVS(Comma-Separated Value) 포맷의 학습 문구를 입력할 수 있고, 상기 단계 (b)는 코사인 (Cosine) 유사도 계산 방식으로 유사도를 계산할 수 있으며, 상기 코사인(Cosine) 유사도 계산 방식은 사이킷- 런(Scikit-learn)의 코사인 유사도(Cosine Similarity) 방식을 포함할 수 있다. 상기 단계 (c)는 동일 대화 의도 내 임베딩된 모든 학습 문구의 평균 유사도를 응집도로 산출할 수 있고, 상기 단계 (d)는 응집도가 해당 기준보다 낮고 유사도가 해당 기준보다 높은 학습 문구를 유사 발화 문구로 선택하여 추출할 수 있으며, 상기 단계 (a)는 입력된 학습 문구를 텐서플로우 허브(TensorFlow hub) 방식을 통해 임베딩 하여 벡터화 할 수 있다. 전술한 목적을 달성하기 위하여 본 발명의 또 다른 측면에 따르면, 상기 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체가 제공될 수 있다. 전술한 목적을 달성하기 위하여 본 발명의 또 다른 측면에 따르면, 상기 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법을 하드웨어와 결합하여 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록 매체에 저장된 애플리케 이션이 제공될 수 있다. 전술한 목적을 달성하기 위하여 본 발명의 또 다른 측면에 따르면, 상기 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법을 컴퓨터에서 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록 매체에 저장된 컴퓨터 프로그램이 제공될 수 있다."}
{"patent_id": "10-2019-0167901", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이 본 발명의 다양한 측면에 따르면, 인공지능 서비스 대화모델의 학습 문구 중 대화 의도는 다르지만 문장이 유사하여 혼동을 줄 수 있는 유사 발화 문구들을 사전에 자동으로 인지하고 해당 문구 들의 수정을 통해 의도분류 정확도 개선 및 편의성을 개선 할 수 있다. 즉, 기존에는 서비스/챗봇 대화 모델 생성 후 검증단계에서 의도분류 성공률이 낮은 경우, 학습 문구 등을 수작 업을 통해 전수 조사하고 문제가 되는 문장에 대해서 리뷰, 수정 반영하는 절차대로 진행된 반면, 본 발명에 따 르면 대화모델 생성 전 자동으로 학습문장의 품질 평가가 수행이 되므로 의도분류 저하를 사전에 방지할 수 있 는 효과가 있다."}
{"patent_id": "10-2019-0167901", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부도면을 참조하여 본 발명의 실시예에 대해 구체적으로 설명한다. 각 도면의 구성요소들에 참조부호를 부가함에 있어서 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가 지도록 한다. 또한, 본 발명의 실시예에 대한 설명 시 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 도 1은 본 발명의 예시적인 실시예에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치의 구성도로, 동 도면에 도시된 바와 같이, 입력부, 전처리부, 임베딩부, 유사도계산부, 응집도계산부, 및 유사문구추출부를 포함할 수 있다. 입력부는 대화 모델의 학습 문구를 입력하기 위한 것으로, 예를 들어, 대화 모델 담당자가 도 2와 같이 정 리된 대화의도(Intent) 별 학습 문구를 .CSV(Comma-Separated Value) 포맷의 파일 형태로 만들어 시스템으로 업로드 하면 입력부는 이를 입력 처리할 수 있다.전처리부는입력부를 통해 입력된 학습 문구 데이터에서 공백제거, 불용어 제거 등의 전처리를 수행하기 위 한 것이다. 임베딩부는 입력된 .CSV(Comma-Separated Value) 포맷의 대화 의도 별 하나 이상의 학습 문구를 임베딩 (Embedding)하기 위한 것으로, 입력된 학습 문구를 텐서플로우 허브(TensorFlow hub) 방식을 통해 임베딩하여 벡터화 할 수 있다. 예를 들어, 임베딩부는 아래의 표 1과 같이 학습 문구를 대응하는 특정 벡터 값으로 임베딩할 수 있다. 표 1 학습문구 임베딩 벡터 값 파이브지 약정 할인 해지 [-0.03649221 0.02498418 -0.03456857 0.02827227 0.00471277] 5G 약정할인이 뭔가요 [-0.02732556 -0.00821852 -0.00794602 0.06356855 -0.03726532] 폰케어플러스 보상 문의 [-0.01732556 -0.00821852 -0.00494602 0.06357855 -0.01726532] 유사도계산부는 임베딩부를 통해 임베딩된 학습 문구에서 대화 의도가 다른 두 학습 문구 간의 유사도 를 도 3에 예시된 바와 같이 계산하기 위한 것으로, 예를 들어, 유사도는 코사인(Cosine) 유사도 계산 방식을 통해 계산할 수 있고, 코사인(Cosine) 유사도 계산 방식은 사이킷-런(Scikit-learn)의 코사인 유사도(Cosine Similarity) 방식을 포함할 수 있으며, 코사인 값이 클수록 유사도가 높으며 유사도 값은 0~1 사이의 값으로 정 의될 수 있다. 유사도계산부에서 계산된 유사도 값의 일 예를 설명하면, 도 3에 예시된 바와 같이, 대화의도 1 '5G_Clea r'에 속한 학습 문구 '5G 약정 해지'와 대화의도 2 '5G_outlineReq'에 속한 학습 문구 '5G 약정 할인이 뭔가 요'간의 유사도 값은 0.764919이고, 대화의도 1 '5G_Clear'에 속한 학습 문구 '5G 약정 할인 해지'와 대화의도 2 '5G_outlineReq'에 속한 학습 문구 '5G 약정 할인'간의 유사도 값은 0.847193 등으로 산출될 수 있으며, 이와 같이 대화의도 1의 학습 문구와 대화의도 2의 학습 문구를 각각 매칭하고 매칭된 두 학습문구 간의 유사도를 코 사인(Cosine) 유사도 계산 방식을 통해 계산하도록 한다. 응집도계산부는 동일 대화 의도 내 임베딩된 모든 학습 문구의 응집도를 계산하기 위한 것으로, 예를 들어, 동일 대화 의도 내 임베딩된 모든 학습 문구의 평균 유사도를 응집도로 산출할 수 있다. 응집도계산부에서 계산된 응집도 값의 일 예를 설명하면, 도 4에 예시된 바와 같이, 대화의도 1 '5G_Clea r'에 속한 학습 문구의 응집도는 0.217600이고, 대화의도 2 '5G_outlineReq'에 속한 학습 문구의 응집도는 0.388721 등과 같이 산출될 수 있다. 유사문구추출부는 유사도계산부를 통해 계산된 유사도 및 응집도계산부를 통해 계산된 응집도를 기 초로 대화 의도 내 특정 학습 문구를 유사 발화 문구로 선택하여 추출하기 위한 것으로, 예를 들어, 응집도가 해당 기준보다 낮고 유사도가 해당 기준보다 높은 학습 문구를 유사 발화 문구로 선택하여 추출할 수 있다. 유사문구추출부에서 추출되는 유사 발화 문구의 일 예를 도 3의 유사도 계산 예시도 및 도 4의 응집도 계산 예시도를 참조하여 설명하면, 응집도가 상대적으로 낮은(실제로는 기 설정된 해당 기준보다 낮은) '5G_Clear' 대화의도에서 유사도가 상대적으로 높은(실제로는 기 설정된 해당 기준보다 높은) 학습 문구인 '5G 약정 할인 해지' 문구가 유사 발화 문구로 선택되어 추출될 수 있다. 유사문구추출부는 전술한 바와 같이 혼동되는 학습 문구(또는 문장)을 판별하고 해당 대화의도(Intent)에서 제외하여 별도 파일로 생성할 수 있다. 따라서, 모델 운영 담당자는 데이터 전처리 단계에서 본 발명의 장치를 통해 의도분류 성공률을 저하시킬 수 있 는 문장들을 미리 제거할 수 있으며, 해당 문장들을 추후 수정 반영할 수도 있다. 도 5는 본 발명의 예시적인 실시예에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법의 흐름도로, 도 1의 장치에 적용되므로 해당 장치의 동작과 병행하여 설명한다. 먼저, 입력부는 도 2와 같이 정리된 대화의도(Intent) 별 학습 문구를 .CSV(Comma-Separated Value) 포맷 의 형태로 입력 처리하고(S501), 전처리부는 입력된 학습 문구 데이터에 대해 공백제거, 불용어 제거 등의전처리를 수행한다(S503). 이어, 임베딩부는 단계 S501에서 입력되어 단계 S503에서 전처리된 .CSV(Comma-Separated Value) 포맷의 대화 의도 별 학습 문구를 예를 들어 텐서플로우 허브(TensorFlow hub) 방식을 통해 임베딩하여 표 1과 같이 벡 터화하고(S505), 유사도계산부는 단계 S505에서 임베딩부를 통해 임베딩된 학습 문구에서 대화 의도가 다른 두 학습 문구 간의 유사도를 도 3에 예시된 바와 같이 계산하되, 전술한 바와 같이 유사도는 코사인 (Cosine) 유사도 계산 방식을 통해 계산할 수 있고, 코사인(Cosine) 유사도 계산 방식은 사이킷-런(Scikit- learn)의 코사인 유사도(Cosine Similarity) 방식을 포함할 수 있으며, 코사인 값이 클수록 유사도가 높으며 유 사도 값은 0~1 사이의 값으로 정의될 수 있다(S507). 이어, 응집도계산부는 동일 대화 의도 내 임베딩된 모든 학습 문구의 응집도를 계산하되, 예를 들어, 동일 대화 의도 내 임베딩된 모든 학습 문구의 평균 유사도를 계산하고 계산된 평균유사도 값을 응집도 값으로 정의 할 수 있고, 응집도 계산 예시는 도 4에 도시된 바와 같다(S509). 마지막으로, 유사문구추출부는 단계 S507에서 유사도계산부를 통해 계산된 유사도 및 단계 S509에서 응 집도계산부를 통해 계산된 응집도를 기초로 대화 의도 내 특정 학습 문구를 유사 발화 문구로 선택하여 추 출하되, 응집도가 해당 기준보다 낮고 유사도가 해당 기준보다 높은 학습 문구를 유사 발화 문구로 선택하여 추 출할 수 있으며, 예를 들어, 도 4의 응집도 예시도에서 응집도가 상대적으로 낮은(실제로는 기 설정된 기준보다 낮은) '5G_Clear' 대화의도 내의 학습 문구 중, 도 3의 유사도 예시도에서 유사도가 상대적으로 높은(실제로는 기 설정된 기준보다 높은) 학습 문구인 '5G 약정 할인 해지' 문구를 유사 발화 문구로 선택하여 추출할 수 있다 (S511). 전술한 바와 같이 본 발명의 방법에 따르면 유사 발화 문구(또는 문장)를 판별하고 해당 대화의도(Intent)에서 제외하여 별도 파일로 생성할 수 있으며, 이에 따라 모델 운영 담당자는 데이터 전처리 단계에서 본 발명의 방 법을 통해 의도분류 성공률을 저하시킬 수 있는 문장들을 미리 제거할 수 있으며, 해당 문장들을 추후 수정 반 영할 수도 있다. 한편, 전술한 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법에 따르면 해당 방법을 컴퓨터에서 실행시 키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체를 구현할 수 있다. 또 한편, 전술한 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법에 따르면 해당 방법을 하드웨어와 결합 하여 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록 매체에 저장된 애플리케이션을 구현할 수 있다. 또 다른 한편, 전술한 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법에 따르면 해당 방법을 컴퓨터에서 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록 매체에 저장된 컴퓨터 프로그램을 구현할 수 있다. 예를 들어, 전술한 바와 같이 본 발명의 예시적인 실시예에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법은 다양한 컴퓨터로 구현되는 동작을 수행하기 위한 프로그램 명령을 포함하는 컴퓨터 판독가능 기록 매체 또는 이러한 기록 매체에 저장된 애플리케이션으로 구현될 수 있다. 상기 컴퓨터 판독 가능 기록 매체는 프로그램 명령, 로컬 데이터 파일, 로컬 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 기록 매체는 본 발명의 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이 프와 같은 자기 매체, CD-ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크와 같은 자기-광 매체, 및 롬, 램, 플 래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그 램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴 퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2019-0167901", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 예시적인 실시예에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 장치의 구성도, 도 2는 대와 의도 별 학습 문구의 예시도, 도 3은 유사도 계산 예시도, 도 4는 응집도 계산 예시도, 도 5는 본 발명의 예시적인 실시예에 따른 인공지능 서비스 대화모델의 학습 문구 품질 검증 방법의 흐름도이다."}
