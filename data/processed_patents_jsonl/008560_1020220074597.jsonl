{"patent_id": "10-2022-0074597", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0173840", "출원번호": "10-2022-0074597", "발명의 명칭": "효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법 및 장치", "출원인": "동국대학교 산학협력단", "발명자": "장혜령"}}
{"patent_id": "10-2022-0074597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치에 있어서, 이진 뉴럴 네트워크 학습을 위한 이진화 단계를 수행하는 이진화부; 및상기 이진 뉴럴 네트워크 학습에 필요한 미분 값을 산출하는 미분계산부를 포함하는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치."}
{"patent_id": "10-2022-0074597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 미분계산부는보조 변수 값을 사용하여 미분 값을 근사하여 계산하는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치."}
{"patent_id": "10-2022-0074597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 이진화부는가중치를 이진화 하는 가중치 이진화부 및 부호 함수를 사용하여 활성화 결과 값을 이진화 하는 활성화 이진화부를 포함하는효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치."}
{"patent_id": "10-2022-0074597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치가 수행하는 학습 방법에 있어서,가중치를 이진화 하는 단계;활성화 결과 값을 이진화 하는 단계; 및실수 값 가중치를 미분하는 단계를 포함하는효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법."}
{"patent_id": "10-2022-0074597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 실수 값 가중치를 미분하는 단계는보조 변수 값을 사용하여 미분 값을 근사하여 계산하는 공개특허 10-2023-0173840-3-효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법."}
{"patent_id": "10-2022-0074597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항 및 제5항 중 어느 하나의 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법을 실행하는 컴퓨터가 판독 가능한 기록매체에 기록된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 경량화 신경망에 관한 것으로, 미분 값 자체를 근사하여 효율적으로 계산하고, 그 값을 가중치들에 전 달하여 학습하는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법 및 장치에 대한 것이다. 본 발명의 일 실시 예에 따르면, 메모리나 전원, 연산능력이 부족한 모바일 장치 또는 소형 기기의 환경에서 인공지능 신경 망 학습과 실행을 할 수 있다."}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 경량화 신경망에 관한 것으로, 미분 값 자체를 근사하여 효율적으로 계산하고, 그 값을 가중치들에 전달하여 학습하는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법 및 장치에 대한 것이다."}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능은 인간의 지적 능력이 요구되는 문제를 기계가 스스로 해결하는 능력을 갖출 수 있도록 주력하는 연구 분야로서, 다음과 같은 요소들로 인해 큰 발전을 이루었다 첫번째, 인공신경망 (Artificial Neural Networks, ANNs) 기반의 인공지능 모델은 미분(Gradient, 그래디언트) 기반의 효율적인 학습 방법(이른바 역전파 알고리즘)을 가능케 하였다. 두번째, 다양한 기기들을 이용하여 대규모의 데이터를 생성하고 수집할 수 있는 체계가 마련되었다. 마지막으로 세번째, 대규모의 데이터를 저장하고 복잡한 구조의 인공지능 모델을 이용한 학습에 요구되는 대규 모의 연산량을 처리할 수 있는 컴퓨팅 자원이 풍부해 졌다. 이러한 요소들을 기반으로 컴퓨터 비전, 자연어 처 리와 같은 복잡한 문제 해결을 요하는 다양한 분야로 인공지능의 적용이 확장되며, 산업이나 사회 구조에 큰 변 화를 일으키는 기술로 각광받고 있다. 하지만 해결하고자 하는 문제의 복잡도에 따라 인공신경망 구조의 복잡도가 증가하며 특히 많은 개수의 뉴런과 많은 수의 층(layer)으로 이루어진 인공신경망 구조를 필요로 한다. 이러한 심층신경망(Deep Neural Networks) 은 학습과 추론 두 가지 측면에서 많은 계산량을 요구하며, 결과적으로 많은 자원을 소모한다. 이로 인해 모바 일 기기 및 사물인터넷 기기와 같이 배터리나 메모리, 연산 능력에 제약 조건을 갖고 있는 환경에서는 심층신경 망 기반의 일반적인 인공지능 모델과 학습 방법이 원활하게 동작하지 않는 문제가 발생할 가능성이 크다. 이에 인공신경망 혹은 심층신경망의 학습과 추론에 요구되는 자원을 줄이는 대표적인 방법 중 하나는 경량화신 경망을 사용해 문제를 해결하는 것으로, 신경망의 뉴런이 가지는 가중치들을 압축하는 가중치 양자화 (Quantization) 기법과 중요도가 적은 가중치를 가지치기(Pruning)하는 기법이 존재한다. 양자화 기법은 32비트 실수 값(float) 형태의 값을 갖는 가중치를 적은 비트로 압축하여 32비트 소수점 연산을 대체하는 방법으로 각 가중치의 저장 용량을 줄일 수 있다. 극단적으로는 -1과 1의 값을 갖도록 양자화 할 수 있다. 반면, 가지치기 기법은 신경망을 이루는 가중치 중 크기가 작아 그 중요도가 덜한 가중치를 제거, 혹은 가지치기, 하는 방법으 로 그 결과 모델의 복잡도와 크기를 줄일 수 있다. 이러한 경량화 신경망 중 하나인 이진 뉴럴 네트워크 (Binary Neural Network, BNN)는 신경망을 이루는 각 가중 치(파라미터)와 액티베이션 결과값을 가장 작은 비트 수인 1비트로 양자화 하여 이진 값을 가지도록 함으로써 모델의 복잡도를 최대한으로 줄인 모델이다. 이진 뉴럴 네트워크의 가중치와 액티베이션 값은 -1와 +1 (혹은 0 과 1)로 이루어져 훨씬 적은 자원을 사용하여 연산을 수행할 수 있지만, 이진화 과정으로 인해 기존의 역전파 학습기법을 적용할 수 없다. 구체적으로, 가중치의 이진화에는 부호(Sign) 함수가 사용되는데, 부호 함수의 미 분(그래디언트)은 대부분의 경우 0이다. 한편, 근대의 인공지능 학습은 가중치에 대한 미분(그래디언트)으로 학습의 오차를 수정해 나가기 때문에, 기존 의 학습 기법을 이진 뉴럴 네트워크에 직접 적용할 수 없다는 어려움이 존재한다. 이에 이진 뉴럴 네트워크의 이진화 과정으로 인한 에너지 효율성의 향상에도 불구하고, 이를 학습에 활용하기 위해서는 어떻게 효율적으로미분(그래디언트)을 계산해야 하는지에 대한 고려가 필요하다. 이러한 문제를 해결하기 위한 연구로, 미분 가능한 함수로 부호 함수를 근사(approximation)하여 기존의 학습 기법을 적용하는 방법들이 주로 제시되었다. 부호 함수를 근사하는 함수를 사용하여 미분(그래디언트)을 계산하 는 것은 기존의 학습 기법들을 큰 문제없이 적용할 수 있다는 장점을 가지고 있으나, 정확한 이진 뉴럴 네트워 크의 미분(그래디언트) 값을 계산하지 못한다는 단점이 존재한다. 반면, 부호 함수 기반의 결정론 적인 (deterministic) 이진화 과정 대신 확률적인(probabilistic) 이진화 과정을 사용하는 연구 방법론은 미분(그래 디언트) 값을 계산할 수 있다는 장점을 가지고 있으나, 이진화 과정에서 더 많은 복잡도를 요구하며 하드웨어 상 구현이 명확하지 않다는 점에서 아직 활발한 연구가 진행되지 않았다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 등록특허공보 제10-2345409호 “컨볼루션 뉴럴 네트워크에서 컨볼루션 연산을 가속하 는 프로세서 및 프로세서의 동작 방법”(공개일자: 2021년 03월 10일)"}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 부호 함수 근사 기법이나 확률적 이진화 방법과 달리 미분(그래디언트) 값 자체를 근사하여 효율적으 로 계산하고, 그 값을 가중치들에 전달하여 학습하는 이진 뉴럴 네트워크의 학습 방법을 제공한다. 본 발명은 양자화 된 값의 미분을 근사하여 계산하기 위한 보조 변수 값을 활용해 부호 함수가 가중치를 그대로 이진화 함으로 적은 자원으로도 동작하는 경량화 신경망을 제공한다."}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치를 제공한다. 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 이진 뉴럴 네트워 크 학습을 위한 이진화 단계를 수행하는 이진화부 및 이진 뉴럴 네트워크 학습에 필요한 미분 값을 산출하는 미 분계산부를 포함할 수 있다. 본 발명의 다른 일 측면에 따르면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법 및 이를 실행하 는 컴퓨터 프로그램을 제공한다. 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법 및 이를 실행하는 컴 퓨터 프로그램은 가중치를 이진화 하는 단계, 활성화 결과 값을 이진화 하는 단계 및 실수 값 가중치를 미분하 는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시 예에 따르면, 메모리나 전원, 연산능력이 부족한 모바일 장치 또는 소형 기기의 환경에서 인 공지능 신경망 학습과 실행을 할 수 있다. 또한 본 발명의 일 실시 예에 따르면, 이진 뉴럴 네트워크의 이진화가 간단하므로 가중치와 곱해지는 각 층의 결과를 이진화하여 XNOR 이진 연산을 대체할 수 있어 연산 복잡도를 줄여 효과적으로 활용할 수 있다. 또한 본 발명의 일 실시 예에 따르면, 컴퓨팅 자원이 부족한 기기에서 인공 신경망 학습이 가능하므로 인공지능 적용 분야를 확장할 수 있다."}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하 고 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하 려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불 필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서 및 청구항에서 사용되는 단수 표현은, 달리 언급하지 않는 한 일반적으로 \"하나 이상\"을 의미하는 것으로 해석되어야 한다. 이하, 본 발명의 바람직한 실시 예를 첨부도면을 참조하여 상세히 설명하기로 하며, 첨부 도면을 참조하여 설명 함에 있어, 동일하거나 대응하는 구성 요소는 동일한 도면번호를 부여하고 이에 대한 중복되는 설명은 생략하기 로 한다. 도 1은 이진 뉴럴 네트워크의 구조 예시이다. 이진 뉴럴 네트워크는 신경망을 이루는 각 가중치(파라미터)와 액티베이션 결과값을 가장 작은 비트 수인 1비트 로 양자화 하여 이진 값을 가지도록 함으로써 인공지능 모델의 복잡도를 최대한으로 줄인 모델이다. 이진 뉴럴 네트워크의 가중치와 액티베이션 값은 -1과 1(혹은 0과 1)로 이루어져 훨씬 적은 자원을 사용하여 연산을 수행 할 수 있지만, 이진화 과정으로 인해 기존의 역전파 학습 기법을 적용할 수 없다. 구체적으로 가중치의 이진화 에 사용되는 부호(Sign) 함수의 미분(그래디언트)는 대부분의 경우 0이다. 근래의 인공지능 학습은 가중치에 대 한 미분(그래디언트)으로 학습의 오차를 수정해 나가기 때문에, 이진화 과정으로 인해 에너지 효율성이 향상됨 에도 불구하고, 이진 뉴럴 네트워크에는 이진화된 가중치에 미분 기반 학습 기법을 적용할 수가 없다. 또한, 부 호 함수를 근사하는 함수를 사용하여 연산하는 경우 미분(그래디언트) 값을 계산하기 용이하나 정확한 이진화가 이루어지지 않으므로 연산의 효율성을 얻을 수 없다. 본 발명은 미분(그래디언트) 값 자체를 근사하여 효율적으로 계산하고, 그 값을 가중치들에 전달하여 학습하는 이진 뉴럴 네트워크를 구현할 수 있다. 도 2 내지 도 5는 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치를 설명하기 위한 도면들이다. 도 2를 참조하면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 이진화부 및 미분계 산부를 포함할 수 있다. 이진화부는 이진 뉴럴 네트워크 학습을 위한 이진화 단계를 수행할 수 있다. 이진화부는 뉴럴 네트워 크의 전체적인 연산이 이진 값을 통해 진행되도록 한다. 이진화부는 가중치와 각 레이어( layer)의 활성화(Activation, 액티베이션) 결과값을 모두 이진화 할 수 있다. 가중치와 활성화(Activation, 액티베이션) 결과값이 모두 이진화 되면, 이진 뉴럴 네트워크에서는 모든 연산이 XNOR로 가능해지기 때문에 연산의 복잡도 또한 줄어들어 학습과 실행에 요구되는 에너지 소모가 급격하 게 줄어든다. 도 3을 참조하면, 이진화부는 가중치 이진화부 및 활성화 이진화부를 포함할 수 있다. 가중치 이진화부는 뉴럴 네트워크의 모든 가중치들에 대해 이진화 할 수 있다. 가중치 이진화부는 부 호(Sign) 함수를 사용하여 가중치를 이진화 할 수 있다. 예를 들면, 가중치 이진화부는 입력 x의 값이 0보 다 크거나 같으면 +1을 출력하고, x의 값이 0보다 작으면 -1을 출력할 수 있다. 가중치 이진화부는[수학식 1]에서와 같이 실수 값의 가중치 w를 이진화하여 wb 를 산출한다. 수학식 1"}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "활성화 이진화부는 이진화 된 가중치의 값을 활용해 여러 레이어(layer)의 활성화(Activation, 액티베이션) 결과 값을 계산하고 부호(Sign) 함수를 사용하여 활성화(Activation, 액티베이션) 결과 값을 이진 화 할 수 있다. 활성화 이진화부는 이전 레이어(layer)의 뉴런 들로부터 받은 입력 값과 이진화 된 가중치 의 곱을 합해 를 계산하고, 이를 부호 함수(Sign)를 사용해 이진화 할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 4를 참조하면, 이진화부는 부호(Sign) 함수를 사용하는 결정론적(deterministic) 이진화 방법을 이용하 므로 입력 값에 따라 항상 일정한 이진화가 이루어지며, 32비트 실수 값을 1비트로 축소하기 때문에 대략 32배 만큼 적은 메모리를 사용해 구현 가능하다. 자세히 설명하면, 도 4(a)는 결정론적 이진화를 위한 부호 함수이고, 도 4(b)는 부호 함수의 미분(그래디언트)이다. 이진화부는 정방향에서 이루어지는 가중치와 활성화(액티베이션)의 이진화를 수행하여, 실수 값 가중치 w 의 값에 대한 이진화 된 가중치 값 wb를 구할 수 있다. 다시 도 2를 참조하면, 미분계산부는 이진 뉴럴 네트워크 학습에 필요한 미분(그래디언트) 값을 효율적으 로 산출할 수 있다. 미분계산부는 부호 함수를 통한 이진화로 인해 대부분의 영역에서 미분(그래디언트) 값이 0인 문제를 해결 하기 위해 보조 변수 값을 사용하여 미분 값을 근사하여 계산할 수 있다. 예를 들면, 미분계산부는 Straight Through Estimator (STE) 기법을 사용할 수 있다. 미분계산부는 연쇄 규칙(chain rule)에 의해 미분(그래디언트) 값을 [수학식 3]과 같이 계산한다. 수학식 3"}
{"patent_id": "10-2022-0074597", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이진 뉴럴 네트워크에서는 일반적으로 신경망의 손실 함수(L)를 이진화 된 가중치wb 에 대해 미분하지만, 이는 부호 함수의 특성 상 대부분의 경우 0의 값을 가지는 문제가 발생할 수 있다. 자세히 설명하면, 결정론적 이진화로 인해 의 값은 대부분 0의 값을 가지므로 유의미한 학습을 위해, Straight Through Estimator(STE) 기법에서는 의 값을 1로 가정하여, 미분(그래디언트) 값을 계산하도록 한다. 하지만 Straight Through Estimator(STE) 기법에서는 이진화 된 값과 실제 실수 값의 범위 차이가 큰 경우 오차 가 커지는 문제점이 있다. 도 5를 참조하면, 미분계산부는 오차가 커지는 것을 방지하기 위해 실수 값을 -1과 +1 사이로 제한 (clipping)하는 방법을 사용한다. 도 5(a)는 부호 함수의 미분(그래디언트)이고, 도5(b)는 역방향 과정에서 실 수 값을 -1과 1 사이로 제한(clipping)하는 Straight Through Estimator(STE) 기반 미분 계산에서 사용되는 근 사 함수이다. 미분계산부는 역방향에서의 손실 함수(L)를 실수 값 가중치 w에 대해서 미분하여 값 자체를 학습하여 보조 변수 값으로 활용할 수 있다 도 6은 본 발명의 일 실시예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법을 도시한 도면 이다. 이하 설명하는 각 과정은 단계에서 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치를 구성하 는 각 기능부가 수행하는 과정이나, 본 발명의 간결하고 명확한 설명을 위해 각 단계의 주체를 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치로 통칭하도록 한다. 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치 는 초기값 w를 랜덤하게 설정하고, 도6에 도시 한 바와 같이 이진 뉴럴 네트워크 학습을 수행할 수 있다. 도 6을 참조하면, 단계 S610에서 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치 는 각 레이어 (layer)에서 실수 값 가중치와 부호 함수를 사용해 가중치를 이진화 한다. 단계 S620에서 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 이진화 된 가중치와 여러 레 이어에 걸쳐 정방향으로 활성화(Activation, 액티베이션) 결과 값을 계산해 이진화 한다. S630 단계에서 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치 는 손실 함수를 구하고, 역방향 으로 STE를 사용해 실수 값 가중치의 미분(그래디언트)을 계산한다. S640 단계에서 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 경사 하강법을 이용해 실수 값 가중치를 업데이트한다. 예를 들면, Adam, AdaGrad, RMSProp 등의 경사 하강법을 이용해 학습 속도를 개선할 수 있다. S650단계에서 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 미분(그래디언트) 값이 일정 값보다 작으면 학습을 종료한다. 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 미분(그래 디언트) 값과 일정 값을 비교하여 미분(그래디언트) 값이 일정 값보다 작아질 때까지 S610 단계로 되돌아가 이 를 반복적으로 수행한다. 도 7 및 도 8을 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 예 시 도면들이다. 도 7을 참조하면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 실수 값 가중치와 부호 함 수를 사용해 가중치를 이진화하고, 활성화 결과 값을 산출해 이진화 한다. 또한 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 이진화 과정으로 각 레이어(layer)에 걸쳐 정방향으로 수행하여 손실 함수 를 산출할 수 있다. 도 8을 참조하면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 역방향에서는 손실 함수를 STE 기반으로 실수 값 가중치에 대해 미분하고, 가중치 미분 값을 학습하여 보조 변수로 활용할 수 있다.도 9 내지 도 12는 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 뉴럴 네트워크 학습 장치의 실험 결과 예시 도면들이다. 효율적인 미분 계산을 이용한 뉴럴 네트워크 학습 장치의 성능을 확인하기 위해 ECG200, ECG5000 및 ECGThorax의 총 3개의 데이터 셋을 활용하여 실험하였다. 각각의 데이터 셋은 심전도 데이터이고, 이를 통해 효 율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치가 심장 이상을 분류하는 분류(Classification) 문제를 학습한 실험 결과들이다. 도 9는 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치가 실험에 사 용한 이진 뉴럴 네트워크 구조를 간단히 표현한 예시 도면이다. 도 9를 참조하면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 입력 레이어, 출력 레이 어와 2개의 은닉 레이어로 구성할 수 있다. 실험에서 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 2개의 은닉 레이어가 가지는 뉴런의 수를 데이터 셋에 따라 달리하였다. 자세히 설명하면, 효율적 인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 ECG200과 ECG5000 데이터 셋에서는 각 레이어마다 뉴런을 1024개 설정하였고, ECGThorax 데이터 셋은 4096개의 뉴런을 설정하였다. 도 10의 예시는 ECG200 데이터 셋을 기준으로 정상적인 심장 박동과 허혈성 심질환의 심장 박동을 비교한 예시 로 심장 박동 이상의 분류 기준이다. 도 11및 도12는 본 발명의 일시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크의 학습 결과 예시 들이다. ECG200 데이터 셋 환경에서는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치가 ECG200 데이터 셋을 이용해 200개의 심장 박동 중 어떤 박동이 이상이 있는지 분류하는 이진 분류 실험을 하였다. 효율적인 미 분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 ECG200 데이터 셋에서 100개는 학습 데이터로 사용하고, 100개는 테스트 데이터로 사용하여 학습하였다. 도 11(a)은 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치가 ECG200 데이터 셋으로 학습한 이 진 뉴럴 네트워크의 정확도 예시이다. 도 11(b)는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 ECG200 데이터 셋에 대한 학습 곡선 예시이다. 도 11(b)의 예시를 보면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 학습을 잘 수행하 여 초반에 정확도가 상승하고 손실이 감소하는 것을 확인할 수 있다. 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 50번 정도의 학습이 진행된 이후부터는 점차 테스트 셋의 손실이 증가하며, 과적합 되는 모습을 나타낸다. 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 테스트 정확도는 93% 정도 이다. 도 12를 참조하면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 ECG5000 데이터 셋과 ECGThorax 데이터 셋에서도ECG200데이터 셋과 비슷하게 STE 기반 학습 알고리즘이 잘 동작한다. 도 12(a)는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치가 수행한 ECG5000 데이터 셋에 대 한 학습 결과 예시이다. ECG5000 데이터 셋 환경에서는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 테스트 정확도는 94.62% 정도 이고, 100번째 학습부터 정확도가 약해지는 것을 확인할 수 있다. ECG5000 데이터 셋 환경에서는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 500개의 학습 데이터와 4500개의 테스트 데이터로 정상 박동 1개와 4개의 이상 박동으로 5중 클래스를 분류하는 문제를 실험 하였다. 도 12(b)는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치가 수행한 ECGThorax 데이터 셋에 대한 학습 결과 예시이다. ECGThorax 데이터 셋 환경에서는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 테스트 정확도는 9121% 정도 이고, 2000번 반복될 때 까지 성능은 크게 악화되지 않았다. ECGThorax 데이터 셋 환경에서는 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 태아의 박 동이 어떤 상태인지 42 클래스로 분류하는 문제로, 1800개의 학습 데이터와 1965개의 테스트 데이터로 나누어 실험하였다. 표 1 DATA SET BNN(STE) (FULL-PRECISION) NN (OPTIMIZED) NN ECG5000 94.62% 94.62% 94.73% ECGTHORAX 91.21% 92.73% 94.68% ECG200 93% 94% 89.05% [표 1]은 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 학습 정확도와 기존의 뉴럴 네트워 크(NN) 학습 정확도를 표시한 것이다. 이진화 과정을 전혀 거치치 않은 뉴럴 네트워크(FULL-PRECISION NN)의 경 우 공통적으로 4096 뉴런 2층의 모델을 사용하여 학습하였고, OPTIMIZED NN의 경우 가장 좋은 성능을 가지는 종래의 연구 모델(start-of-the-art)을 의미한다.[표 1]을 참조하면, 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치는 다양한 데이터에 적용될 수 있고, 각각의 다른 모델을 사용하여 모델의 구조 또한 가 변 될 수 있다. 이는 모바일 단말기나 스마트 기기를 기반으로 하는 다양한 헬스케어 관련된 실제 응용에서 효 율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 활용성이 다양함을 의미한다. 상술한 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨터 가 읽을 수 있는 코드로 구현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매 체(CD, DVD, 블루레이 디스크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨터 구비형 하드 디스크)일 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인터 넷 등의 네트워크를 통하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상 기 다른 컴퓨팅 장치에서 사용될 수 있다. 이상에서, 본 발명의 실시 예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설 명되었다고 해서, 본 발명이 반드시 이러한 실시 예에 한정되는 것은 아니다. 즉, 본 발명의 목적 범위안에서라 면, 그 모든 구성요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 도면에서 동작들이 특정한 순서로 도시되어 있지만, 반드시 동작들이 도시된 특정한 순서로 또는 순차적 순서로 실행되어야만 하거나 또는 모든 도시 된 동작들이 실행되어야만 원하는 결과를 얻을 수 있는 것으로 이해되어서 는 안 된다. 특정 상황에서는, 멀티태스킹 및 병렬 처리가 유리할 수도 있다. 더욱이, 위에 설명한 실시 예 들 에서 다양한 구성들의 분리는 그러한 분리가 반드시 필요한 것으로 이해되어서는 안 되고, 설명된 프로그램 컴 포넌트들 및 시스템들은 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패 키지 될 수 있음을 이해하여야 한다. 이제까지 본 발명에 대하여 그 실시 예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통상의 지식 을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시 예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모 든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0074597", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 이진 뉴럴 네트워크의 구조 예시. 도 2 내지 도 5는 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치를 설명하기 위한 도면들 도 6은 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 방법을 도시한 도 면. 도 7 및 도 8을 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 예 시 도면들. 도 9 내지 도 12는 본 발명의 일 실시 예에 따른 효율적인 미분 계산을 이용한 이진 뉴럴 네트워크 학습 장치의 실험 결과 예시 도면들."}
