{"patent_id": "10-2022-0073793", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0173277", "출원번호": "10-2022-0073793", "발명의 명칭": "로봇 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "임배석"}}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 있어서,청소 대상 영역의 타입에 따른 청소 시나리오 및 신경망 모델이 저장된 메모리;카메라;거리 센서;구동부; 및상기 카메라를 통해 획득된 이미지 및 상기 거리 센서를 통해 획득된 거리 데이터를 상기 신경망 모델에 입력하여 상기 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득하고, 상기 획득된 타입 정보에 대응되는 청소 시나리오를 상기 메모리로부터 획득하고, 상기 획득된 청소 시나리오에 기초하여 상기 구동부를 제어하는 프로세서;를 포함하며, 상기 구동부는,모터;회전 가능하도록 설계된 플레이트;상기 플레이트 상에 배치되며 지면과 일정한 각도로 기울어진 슬로프(slope)를 구비한 레일;상기 레일 상에서 왕복 가능하도록 배치된 슬라이더; 일 측이 상기 슬라이더에 결합되며 상기 슬라이더가 상기 레일 상에서 왕복함에 따라 상기 지면과 일정한 각도를 유지하며 이동하는 암(Arm); 및상기 암의 타 측에 결합된 석션부;를 포함하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 신경망 모델은,이미지 및 거리 데이터가 입력되면, 상기 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를출력하도록 학습되거나, 상기 이미지에 포함된 오브젝트에 대한 정보를 출력하도록 학습되며, 상기 프로세서는, 상기 신경망 모델로부터 상기 이미지에 포함된 오브젝트에 대한 정보가 획득되면, 상기 획득된 오브젝트에 대한정보에 기초하여 상기 이미지에 포함된 청소 대상 영역에 대한 타입 정보를 획득하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 구동부는, 상기 석션부의 일측에 결합된 제1 와이어; 및상기 석션부의 상기 일측에서 상기 제1 와이어와 일정 거리 이격되어 결합된 제2 와이어;를 더 포함하며, 상기 프로세서는, 공개특허 10-2023-0173277-3-상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제1 각도를 유지하도록 상기 제1 와이어를 제1방향으로 와인딩(winding)하며,상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제2 각도를 유지하도록 상기 제2 와이어를 제2방향으로 와인딩하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는, 상기 청소 대상 영역에 인접한 오브젝트가 이동 가능한 오브젝트로 식별되면, 상기 석션부가 상기 오브젝트에접촉되도록 상기 제1 와이어를 상기 제1 방향으로 와인딩하며, 상기 석션부가 상기 오브젝트에 접촉되면, 상기 플레이트가 일 방향으로 회전되도록 상기 모터를 제어하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 프로세서는,상기 오브젝트가 이동 불가능한 오브젝트인 것으로 식별되면, 상기 오브젝트의 이동을 요청하는 가이드 UI(UserInterface)를 제공하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 프로세서는, 상기 청소 대상 영역이 특정 타입이면, 상기 제1 와이어를 상기 제1 방향으로 와인딩하고, 상기 청소 대상 영역이 상기 특정 타입 외의 타입이면, 상기 제2 와이어를 상기 제2 방향으로 와인딩하는,로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,상기 청소 대상 영역과 상기 지면의 단차가 임계 값 이상인 경우, 상기 슬라이더를 후방으로 이동시켜 상기 청소 대상 영역으로 상기 석션부의 위치를 제어하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 거리 센서는,라이다(LIDAR) 센서;를 포함하며,상기 프로세서는,상기 청소를 수행하는 동안 상기 라이다 센서를 통해 획득된 거리 데이터에 기초하여 상기 슬라이더를제어하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는,공개특허 10-2023-0173277-4-상기 이미지에서 청소 불가능한 영역이 식별되면, 청소 불가능한 영역을 가이드하는 UI를 제공하는, 로봇."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "구동부를 포함하는 로봇의 제어 방법에 있어서,카메라를 통해 획득된 이미지 및 거리 센서를 통해 획득된 거리 데이터를 신경망 모델에 입력하여 상기 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득하는 단계;상기 획득된 타입 정보에 대응되는 청소 시나리오를 획득하는 단계; 및상기 획득된 청소 시나리오에 기초하여 상기 구동부를 제어하여 청소를 수행하는 단계;를 포함하며,상기 구동부는,모터, 회전 가능하도록 설계된 플레이트, 상기 플레이트 상에 배치되며 지면과 일정한 각도로 기울어진 슬로프(slope)를 구비한 레일, 상기 레일 상에서 왕복 가능하도록 배치된 슬라이더, 일 측이 상기 슬라이더에 결합되며 상기 슬라이더가 상기 레일 상에서 왕복함에 따라 상기 지면과 일정한 각도를 유지하며 이동하는 암(Arm) 및상기 암의 타 측에 결합된 석션부를 포함하는, 제어 방법."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 신경망 모델은,이미지 및 거리 데이터가 입력되면, 상기 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를출력하도록 학습되거나, 상기 이미지에 포함된 오브젝트에 대한 정보를 출력하도록 학습되며, 상기 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득하는 단계는, 상기 신경망 모델로부터 상기 이미지에 포함된 오브젝트에 대한 정보가 획득되면, 상기 획득된 오브젝트에 대한정보에 기초하여 상기 이미지에 포함된 청소 대상 영역에 대한 타입 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 구동부는, 상기 석션부의 일측에 결합된 제1 와이어 및 상기 석션부의 상기 일측에서 상기 제1 와이어와 일정 거리 이격되어 결합된 제2 와이어를 더 포함하며, 상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제1 각도를 유지하도록 상기 제1 와이어를 제1방향으로 와인딩(winding)하는 단계; 및상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제2 각도를 유지하도록 상기 제2 와이어를 제2방향으로 와인딩하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제1 와이어를 제1 방향으로 와인딩하는 단계는,상기 청소 대상 영역에 인접한 오브젝트가 이동 가능한 오브젝트로 식별되면, 상기 석션부가 상기 오브젝트에접촉되도록 상기 제1 와이어를 상기 제1 방향으로 와인딩하며,상기 제어 방법은,상기 석션부가 상기 오브젝트에 접촉되면, 상기 플레이트를 일 방향으로 회전시키는 단계;를 더 포함하는, 제어방법.공개특허 10-2023-0173277-5-청구항 14 제12항에 있어서,상기 오브젝트가 이동 불가능한 오브젝트인 것으로 식별되면, 상기 오브젝트의 이동을 요청하는 가이드 UI(UserInterface)를 제공하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 제1 와이어를 제1 방향으로 와인딩하는 단계는,상기 청소 대상 영역이 특정 타입이면, 상기 제1 와이어를 상기 제1 방향으로 와인딩하고,상기 제2 와이어를 제2 방향으로 와인딩하는 단계는,상기 청소 대상 영역이 상기 특정 타입 외의 타입이면, 상기 제2 와이어를 상기 제2 방향으로 와인딩하는, 제어방법."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 청소를 수행하는 단계는,상기 청소 대상 영역과 상기 지면의 단차가 임계 값 이상인 경우, 상기 슬라이더를 후방으로 이동시켜 상기 청소 대상 영역으로 상기 석션부를 위치시키는, 제어 방법."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 청소를 수행하는 단계는,상기 청소를 수행하는 동안 라이다 센서를 통해 획득된 거리 데이터에 기초하여 상기 슬라이더를 이동시키는,제어 방법."}
{"patent_id": "10-2022-0073793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 이미지에서 청소 불가능한 영역이 식별되면, 청소 불가능한 영역을 가이드하는 UI를 제공하는 단계;를 더포함하는, 제어 방법."}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇이 개시된다. 로봇은 청소 대상 영역의 타입에 따른 청소 시나리오 및 신경망 모델이 저장된 메모리, 카메라, 거리 센서, 구동부 및 프로세서를 포함한다. 프로세서는 카메라를 통해 획득된 이미지 및 거리 센서를 통해 획득된 거리 데이터를 신경망 모델에 입력하여 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득하고, 획득된 타입 정보에 대응되는 청소 시나리오를 메모리로부터 획득하고, 획득된 청소 시나리오 에 기초하여 구동부를 제어할 수 있다. 구동부는 모터, 회전 가능하도록 설계된 플레이트, 플레이트 상에 배치되 며 지면과 일정한 각도로 기울어진 슬로프(slope)를 구비한 레일, 레일 상에서 왕복 가능하도록 배치된 슬라이더, 일 측이 슬라이더에 결합되며 슬라이더가 레일 상에서 왕복함에 따라 지면과 일정한 각도를 유지하며 이동하는 암(Arm) 및 암의 타 측에 결합된 석션부를 포함할 수 있다."}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇 및 그 제어 방법에 관한 것으로, 보다 상세하게는 공간을 주행하며 청소 태스크를 수행하는 로 봇 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 실내 공간에 배치되어 사용자에게 서비스를 제공하는 로봇에 대한 기술 개발이 활발해지고 있다. 로봇은 실내 공간을 주행하며 청소, 가이드, 서빙, 패트롤 또는 긴급 상황 대처 등과 같이 다양한 서비스를 제공할 수 있다. 특히, 사용자의 개입 없이 스스로 공간을 청소하는 로봇에 대한 수요는 나날이 높아지고 있다. 로봇이 청소 서비스를 제공하는 경우, 공간의 구조적 특성 또는 공간 내에 위치한 장애물로 인해 공간 내에 로 봇이 주행할 수 없는 사각지대가 형성될 수 있으며, 이로 인해 원활한 서비스 제공이 어려워진다는 문제점이 있 었다. 이에 따라, 다양한 타입의 청소 영역에 대하여 만족스러운 청소 서비스를 제공할 수 있는 방법에 대한 지속적인 요구가 있었다."}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 개시의 목적은 이미지 및 거리 데이터에 기초하여 청소 대상 영역 에 대한 타입 정보를 획득하고, 획득된 타입 정보에 대응되는 청소 시나리오에 기초하여 청소를 수행하는 로봇 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 발명의 일 실시 예에 따른 로봇은, 청소 대상 영역의 타입에 따른 청소 시나리오 및 신경망 모델이 저장된 메모리, 카메라, 거리 센서, 구동부 및 상기 카메라를 통해 획득된 이미지 및 상기 거리 센서를 통해 획득된 거리 데이터를 상기 신경망 모델에 입력하여 상기 이미지에 포함된 적어도 하 나의 청소 대상 영역에 대한 타입 정보를 획득하고, 상기 획득된 타입 정보에 대응되는 청소 시나리오를 상기 메모리로부터 획득하고, 상기 획득된 청소 시나리오에 기초하여 상기 구동부를 제어하는 프로세서를 포함하며, 상기 구동부는, 모터, 회전 가능하도록 설계된 플레이트, 상기 플레이트 상에 배치되며 지면과 일정한 각도로 기울어진 슬로프(slope)를 구비한 레일, 상기 레일 상에서 왕복 가능하도록 배치된 슬라이더, 일 측이 상기 슬 라이더에 결합되며 상기 슬라이더가 상기 레일 상에서 왕복함에 따라 상기 지면과 일정한 각도를 유지하며 이동 하는 암(Arm) 및 상기 암의 타 측에 결합된 석션부를 포함할 수 있다. 여기서, 상기 신경망 모델은, 이미지 및 거리 데이터가 입력되면, 상기 이미지에 포함된 적어도 하나의 청소 대 상 영역에 대한 타입 정보를 출력하도록 학습되거나, 상기 이미지에 포함된 오브젝트에 대한 정보를 출력하도록 학습되며, 상기 프로세서는, 상기 신경망 모델로부터 상기 이미지에 포함된 오브젝트에 대한 정보가 획득되면, 상기 획득된 오브젝트에 대한 정보에 기초하여 상기 이미지에 포함된 청소 대상 영역에 대한 타입 정보를 획득 할 수 있다. 또한, 상기 구동부는, 상기 석션부의 일측에 결합된 제1 와이어 및 상기 석션부의 상기 일측에서 상기 제1 와이 어와 일정 거리 이격되어 결합된 제2 와이어를 더 포함하며, 상기 프로세서는, 상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제1 각도를 유지하도록 상기 제1 와이어를 제1 방향으로 와인딩(winding)하며, 상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제2 각도를 유지하도록 상기 제2 와이어를 제2 방향으로 와인딩할 수 있다. 여기서, 상기 프로세서는, 상기 청소 대상 영역에 인접한 오브젝트가 이동 가능한 오브젝트로 식별되면, 상기 석션부가 상기 오브젝트에 접촉되도록 상기 제1 와이어를 상기 제1 방향으로 와인딩하며, 상기 석션부가 상기 오브젝트에 접촉되면, 상기 플레이트가 일 방향으로 회전되도록 상기 모터를 제어할 수 있다. 또한, 상기 프로세서는, 상기 오브젝트가 이동 불가능한 오브젝트인 것으로 식별되면, 상기 오브젝트의 이동을 요청하는 가이드 UI(User Interface)를 제공할 수 있다. 또한, 상기 프로세서는, 상기 청소 대상 영역이 특정 타입이면, 상기 제1 와이어를 상기 제1 방향으로 와인딩하 고, 상기 청소 대상 영역이 상기 특정 타입 외의 타입이면, 상기 제2 와이어를 상기 제2 방향으로 와인딩할 수 있다. 또한, 상기 프로세서는, 상기 청소 대상 영역과 상기 지면의 단차가 임계 값 이상인 경우, 상기 슬라이더를 후 방으로 이동시켜 상기 청소 대상 영역으로 상기 석션부의 위치를 제어할 수 있다. 또한, 상기 거리 센서는, 라이다(LIDAR) 센서를 포함하며, 상기 프로세서는, 상기 청소를 수행하는 동안 상기 라이다 센서를 통해 획득된 거리 데이터에 기초하여 상기 슬라이더를 제어할 수 있다. 또한, 상기 프로세서는, 상기 이미지에서 청소 불가능한 영역이 식별되면, 청소 불가능한 영역을 가이드하는 UI 를 제공할 수 있다. 한편, 본 발명의 일 실시 예에 따른 로봇의 제어 방법은, 카메라를 통해 획득된 이미지 및 거리 센서를 통해 획 득된 거리 데이터를 신경망 모델에 입력하여 상기 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득하는 단계, 상기 획득된 타입 정보에 대응되는 청소 시나리오를 획득하는 단계 및 상기 획득된 청소 시나리오에 기초하여 상기 구동부를 제어하여 청소를 수행하는 단계를 포함하며, 상기 구동부는, 모터, 회전 가능하도록 설계된 플레이트, 상기 플레이트 상에 배치되며 지면과 일정한 각도로 기울어진 슬로프(slope)를 구비 한 레일, 상기 레일 상에서 왕복 가능하도록 배치된 슬라이더, 일 측이 상기 슬라이더에 결합되며 상기 슬라이 더가 상기 레일 상에서 왕복함에 따라 상기 지면과 일정한 각도를 유지하며 이동하는 암(Arm) 및 상기 암의 타 측에 결합된 석션부를 포함할 수 있다. 여기서, 상기 신경망 모델은, 이미지 및 거리 데이터가 입력되면, 상기 이미지에 포함된 적어도 하나의 청소 대 상 영역에 대한 타입 정보를 출력하도록 학습되거나, 상기 이미지에 포함된 오브젝트에 대한 정보를 출력하도록 학습되며, 상기 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득하는 단계는, 상기 신경망 모델로부터 상기 이미지에 포함된 오브젝트에 대한 정보가 획득되면, 상기 획득된 오브젝트에 대한 정보에 기초하여 상기 이미지에 포함된 청소 대상 영역에 대한 타입 정보를 획득할 수 있다. 또한, 상기 구동부는, 상기 석션부의 일측에 결합된 제1 와이어 및 상기 석션부의 상기 일측에서 상기 제1 와이 어와 일정 거리 이격되어 결합된 제2 와이어를 더 포함하며, 상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제1 각도를 유지하도록 상기 제1 와이어를 제1 방향으로 와인딩(winding)하는 단계 및 상기 청소 대상 영역의 타입에 따라 상기 석션부가 상기 지면과 제2 각도를 유지하도록 상기 제2 와이어를 제2 방향으로 와인딩하는 단계를 더 포함할 수 있다. 여기서, 상기 제1 와이어를 제1 방향으로 와인딩하는 단계는, 상기 청소 대상 영역에 인접한 오브젝트가 이동 가능한 오브젝트로 식별되면, 상기 석션부가 상기 오브젝트에 접촉되도록 상기 제1 와이어를 상기 제1 방향으로 와인딩하며, 상기 제어 방법은, 상기 석션부가 상기 오브젝트에 접촉되면, 상기 플레이트를 일 방향으로 회전시 키는 단계를 더 포함할 수 있다. 또한, 상기 오브젝트가 이동 불가능한 오브젝트인 것으로 식별되면, 상기 오브젝트의 이동을 요청하는 가이드 UI(User Interface)를 제공하는 단계를 더 포함할 수 있다. 또한, 상기 제1 와이어를 제1 방향으로 와인딩하는 단계는, 상기 청소 대상 영역이 특정 타입이면, 상기 제1 와 이어를 상기 제1 방향으로 와인딩하고, 상기 제2 와이어를 제2 방향으로 와인딩하는 단계는, 상기 청소 대상 영 역이 상기 특정 타입 외의 타입이면, 상기 제2 와이어를 상기 제2 방향으로 와인딩할 수 있다. 또한, 상기 청소를 수행하는 단계는, 상기 청소 대상 영역과 상기 지면의 단차가 임계 값 이상인 경우, 상기 슬 라이더를 후방으로 이동시켜 상기 청소 대상 영역으로 상기 석션부를 위치시킬 수 있다. 또한, 상기 청소를 수행하는 단계는, 상기 청소를 수행하는 동안 라이다 센서를 통해 획득된 거리 데이터에 기 초하여 상기 슬라이더를 이동시킬 수 있다. 또한, 상기 이미지에서 청소 불가능한 영역이 식별되면, 청소 불가능한 영역을 가이드하는 UI를 제공하는 단계 를 더 포함할 수 있다."}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시 예에 따르면, 로봇이 다양한 타입의 청소 영역에 대하여 만족스러운 청소 서비스를 제공 할 수 있으므로, 사용자의 편의가 향상될 수 있다."}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 개시에서 '사용자'는 로봇으로부터 서비스를 제공받는 사람을 의미할 수 있으나, 이에 한정되는 것은 아니다. 도 1은 로봇의 청소 서비스 제공에 관해 개략적으로 설명하기 위한 도면이다. 본 개시의 일 실시 예에 따른 로봇은 특정 공간에 배치되며, 공간에 거주하거나 일시 방문한 사용자에게 다양한 서비스를 제공할 수 있다. 로봇은 사용자에게 청소, 가이드, 서빙, 패트롤 또는 긴급 상황 대처 등 의 서비스를 제공할 수 있으나, 본 명세서에서는 로봇이 청소 서비스를 제공하는 것을 전제로 로봇의 동작을 설명하도록 한다. 공간을 주행하며 청소 서비스를 제공하는 로봇은 공간 내에 위치한 오브젝트와 임계 거리 이내로 이격된 것으로 식별되면 오브젝트와 인접한 영역에 대한 청소 시나리오에 기초하여 청소를 수행할 수 있다. 예를 들어, 로봇은 오브젝트에 의해 형성된 코너에 대응되는 청소 시나리오에 기초하여 코너 영역을 청소할 수 있다. 예를 들어, 로봇은 코너를 포함하는 이미지 및 거리 데이터를 획득하고, 획득된 이미지 및 거리 데이 터에 기초하여 이미지에 포함된 코너 타입의 청소 영역을 식별할 수 있다. 또한, 로봇은 식별된 영역 에 대응되는 청소 시나리오를 획득하고, 획득된 청소 시나리오에 기초하여 청소를 수행할 수 있다. 또한, 로봇은 특정한 타입의 청소 대상 영역을 효과적으로 청소하기 위해 로봇의 본체를 기준으로 청 소가 가능한 범위를 가변적으로 조절할 수 있는 특수한 형태의 구동부를 포함할 수 있다. 로봇은 획득된청소 시나리오에 기초하여 구동부를 제어함으로써 식별된 청소 대상 영역을 효과적으로 청소할 수 있다. 이하에서는, 이미지 및 거리 데이터에 기초하여 청소 대상 영역에 대한 타입 정보를 획득하고, 획득된 타입 정 보에 대응되는 청소 시나리오에 기초하여 청소를 수행하는 다양한 실시 예에 대해 좀더 구체적으로 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 블록도이다. 도 2에 따르면, 본 개시의 일 실시 예에 따른 로봇은 메모리, 카메라, 거리 센서, 구동부 및 프로세서를 포함할 수 있다. 메모리는 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따라 로봇에 임베디드된 메모리 형태로 구현되거나, 로봇에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 로봇의 구동을 위한 데이터의 경우 로봇에 임베디드된 메모리에 저장 되고, 로봇의 확장 기능을 위한 데이터의 경우 로봇에 탈부착이 가능한 메모리에 저장될 수 있다. 한 편, 로봇에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 또 한, 로봇에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구 현될 수 있다. 일 예에 따른 메모리는 청소 대상 영역의 타입에 따른 청소 시나리오 및 청소 영역의 타입 정보 획득에 활 용되는 신경망 모델을 저장할 수 있다. 일 예에 따르면, 신경망 모델은 이미지 및 거리 데이터가 입력되면 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 출력하도록 학습된 모델일 수 있다. 이 경우 신경망 모델은 이미지 및 거리 데이터가 입력되면 이미지에 포함된 복수의 세그먼트(Segment) 영역 각각 또는 서로 다른 세그먼트가 접하고 있는 영역 중 청소가 가능한 영역(이하, 청소 대상 영역)의 타입 정보를 출력하도록 학습된 모델일 수 있다. 다른 예에 따르면, 신경망 모델은 이미지 및 거리 데이터가 입력되면 이미지에 포함된 오브젝트에 대한 정보를 출력하도록 학습된 모델일 수 있다. 이 경우 신경망 모델은 이미지 및 거리 데이터가 입력되면 이미지에 포함된 복수의 세그먼트 각각에 대한 정보를 출력할 수 있다. 카메라는 로봇의 주변의 오브젝트를 포함하는 이미지를 획득하는 구성이다. 카메라는 오브젝트 에 의해 반사되어 수신되는 가시광 기타 광학 신호를 이미지 센서로 포커싱하는 렌즈 및 가시광 기타 광학 신호 를 감지할 수 있는 이미지 센서를 포함할 수 있다. 여기서, 이미지 센서는 복수의 픽셀로 구분되는 2D의 픽셀 어레이를 포함할 수 있다. 프로세서는 가시광선 또는 적외선 등 다양한 파장대의 광학 신호를 카메라의 렌즈를 통해 수신하고, 수신된 광학 신호를 카메라의 이미지 센서를 통해 처리하여 이미지를 획득할 수 있다. 또한, 일 예에 따른 카메라는 뎁스(Depth) 카메라로 구현될 수 있으며, 이 경우 프로세서는 카메라를 통해 뎁스 이 미지를 획득할 수 있다. 한편, 카메라는 복수의 렌즈 및 복수의 이미지 센서를 포함하는 카메라 모듈의 형태로 구현될 수 있다. 일 예에 따르면, 카메라는 두 개의 렌즈와 두 개의 이미지 센서를 포함하는 스테레오 카메라(stereo camera) 일 수 있으나 이에 한정되는 것은 아니다. 거리 센서는 거리 데이터를 획득할 수 있다. 구체적으로, 거리 센서는 로봇의 위치와 오브젝트 의 위치와의 거리를 측정하고, 측정 결과에 기초하여 거리 데이터를 획득할 수 있다. 일 예에 따른 거리 센서 는 라이다(LIDAR, Light Detection And Ranging), RADAR(RAdio Detection And Ranging) 또는 SONAR((RAdio Detection And Ranging) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 구동부는 로봇의 주행 및 청소 서비스 제공을 위한 구성이다. 로봇의 주행과 관련하여, 구동부 는 프로세서의 제어에 따라 주행 방향 및 주행 속도를 조절할 수 있다. 일 예에 따른 구동부는로봇이 주행하기 위한 동력을 발생시키는 동력발생장치(예: 사용 연료(또는 에너지원)에 따라 가솔린 엔진 (engine), 디젤 엔진, LPG(liquefied petroleum gas) 엔진, 전기 모터 등), 주행 방향을 조절하기 위한 조향 장치(예: 기계식 스티어링(manual steering), 유압식 스티어링(hydraulics steering), 전자식 스티어링 (electronic control power steering, EPS) 등), 동력에 따라 로봇을 주행시키는 주행 장치(예: 바퀴, 프 로펠러 등) 등을 포함할 수 있다. 또한, 구동부는 로봇의 주행 타입(예: 휠 타입, 보행 타입, 비행 타입 등)에 따라 변형 실시될 수 있다. 로봇의 청소 기능과 관련하여, 구동부는 프로세서의 제어에 따라 청소 대상 영역에 분포하고 있 는 이물질을 흡입하여 제거할 수 있다. 일 예에 따른 구동부는 모터, 회전 가능하도록 설계된 플레이트, 플레이트 상에 배치되며 지면과 일정한 각도로 기울어진 슬로프(slope)를 구비한 레일, 레일 상에서 왕복 가능 하도록 배치된 슬라이더, 일 측이 슬라이더에 결합되며 슬라이더가 레일 상에서 왕복함에 따라 지면과 일정 각 도를 유지하며 이동하는 암(Arm) 및 암의 타측에 결합된 석션부를 포함할 수 있다. 또한, 구동부는 석션부의 일측에 결합된 제1 와이어 및 석션부의 일측에서 제1 와이어와 일정 거리 이격되 어 결합된 제2 와이어를 포함할 수 있다. 프로세서는 로봇의 동작을 전반적으로 제어한다. 구체적으로, 프로세서는 로봇의 각 구성 과 연결되어 로봇의 동작을 전반적으로 제어할 수 있다. 예를 들어, 프로세서는 메모리, 카메라 , 거리 센서 및 구동부와 연결되어 로봇의 동작을 제어할 수 있다. 일 실시 예에 따라 프로세서는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세 서(microprocessor), 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), NPU(Neural Processing Unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)) 등 다양한 이름으로 명명될 수 있으나, 본 명세서에서는 프로세서로 기재한다. 프로세서는 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또한, 프로세서는 SRAM 등의 휘발성 메모리를 포함 할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 카메라를 통해 획득된 이미지 및 거리 센서를 통해 획 득된 거리 데이터를 메모리에 저장된 신경망 모델에 입력하여 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득할 수 있다. 일 예에 따라 이미지 및 거리 데이터가 입력되면 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 출력하도록 학습된 신경망 모델을 활용하는 경우, 프로세서는 신경망 모델을 통해 출력된 결과 값 에 기초하여 별도의 후처리 없이 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득할 수 있다. 여기서, 청소 대상 영역의 타입은 노멀(Normal), 얕은 틈, 코너, 깊은 틈, 좁은 틈 또는 단차 영역 중 적 어도 하나일 수 있으나 이에 한정되는 것은 아니다. 다른 예에 따르면, 신경망 모델은 이미지 및 거리 데이터가 입력되면 이미지에 포함된 오브젝트에 대한 정보를 출력하도록 학습된 모델일 수 있다. 이러한 방식으로 학습된 신경망 모델을 활용하는 경우, 프로세서는 신 경망 모델을 통해 출력된 오브젝트에 대한 정보에 기초하여 별도의 후처리를 통해 이미지에 포함된 적어도 하나 의 청소 대상 영역에 대한 타입 정보를 획득할 수 있다. 구체적으로, 프로세서는 후처리를 통해 이미지에 포함된 세그먼트에 대응되는 오브젝트들 간의 관계에 기초하여 청소 대상 영역의 타입 정보를 획득할 수 있다. 이어서, 프로세서는 메모리에 저장된 복수의 청소 시나리오 중 획득된 타입 정보에 대응되는 청소 시 나리오를 식별할 수 있다. 프로세서는 식별된 청소 시나리오에 기초하여 구동부를 제어함으로써 청소 대상 영역에 대한 청소를 수행할 수 있다. 또한, 프로세서는 청소 대상 영역의 타입에 따라 석션부가 지면과 제1 각도를 유지하도록 제1 와이어를 제 1 방향으로 와인딩하거나 석션부가 지면과 제2 각도를 유지하도록 제2 와이어를 제2 방향으로 와인딩할 수 있다. 여기서, 프로세서는 청소 대상 영역에 인접한 오브젝트가 이동 가능한 오브젝트로 식별되면 석션부 가 오브젝트에 접촉되도록 제1 와이어를 제1 방향으로 와인딩하며, 석션부가 오브젝트에 접촉되면 플레이트가 일 방향으로 회전되도록 모터를 제어할 수 있다. 또한, 프로세서는 오브젝트가 이동 불가능한 오브젝트인 것으로 식별되면 오브젝트의 이동을 요청하는 가 이드 UI(User Interface)를 제공할 수 있다.또한, 프로세서는 청소 대상 영역이 특정 타입인 것으로 식별되면 제1 와이어를 제1 방향으로 와인딩하고, 청소 대상 영역이 특정 타입 외의 타입이면 제2 와이어를 제2 방향으로 와인딩할 수 있다. 또한, 프로세서는 청소 대상 영역과 지면의 단차가 임계 값 이상인 경우, 슬라이더를 후방으로 이동시켜 청소 대상 영역으로 석션부의 위치를 제어할 수 있다. 또한, 거리 센서가 라이다(LIDAR) 센서를 포함하는 경우, 프로세서는 청소를 수행하는 동안 라이다 센서를 통해 획득된 거리 데이터에 기초하여 청소 대상 영역에 대한 타입 정보를 획득하고, 획득된 타입 정보에 대응되는 청소 시나리오에 기초하여 슬라이더를 제어할 수 있다. 또한, 프로세서는 이미지에서 청소 불가능한 영역이 식별되면, 청소 불가능한 영역을 가이드하는 UI를 제 공할 수도 있다. 여기서, 청소 불가능한 영역은 이미지에 포함된 오브젝트 자체 및 로봇의 폼 팩터를 고려 할 때 청소를 전혀 수행할 수 없는 영역은 물론 청소를 수행하는 경우 오브젝트의 파손 등의 문제가 발생할 수 있는 영역을 포함할 수 있으나 이에 한정되는 것은 아니다. 도 3a 및 도 3b는 본 개시의 일 실시 예에 따른 암의 동작을 설명하기 위한 도면이다. 구동부는 모터를 포함할 수 있다. 구동부는 로봇의 주행 및 청소 기능과 관계되는 단일한 모터 를 포함할 수도 있으며, 주행에 관계되는 제1 모터와 청소 기능에 관계되는 제2 모터를 포함할 수도 있다. 구동부는 회전 가능하도록 설계된 플레이트를 포함할 수 있다. 플레이트는 지면과 수직한 방향 을 기준으로 회전 가능하도록 설계될 수 있으며, 플레이트 상에는 지면과 일정한 각도로 기울어진 슬로프 를 구비한 레일이 배치될 수 있다. 일 예에 따르면, 레일은 한 쌍의 직선형 레일로 구현될 수 있으나 이에 한정되는 것은 아니다. 레일은 슬라이더와 결합할 수 있으며, 레일과 슬라이더의 결합부에는 베어링 등의 부속이 포함될 수 있다. 슬라이더는 레일상에서 왕복 가능하도록 배치되며, 일 예에 따른 슬라이더는 한 쌍의 레일에 대응되는 한쌍의 결합부를 포함할 수 있다. 슬라이더는 암과 결합된 구성이다. 암은 슬라이더가 레일 상에서 왕복함에 따라 지면 과 일정한 각도를 유지하며 이동할 수 있다. 이 경우, 암은 레일에 포함된 슬로프를 따라서 지면과 일정한 각도를 유지하며 이동할 수 있다. 암이 슬라이더와 결합한 일 측에는 힌지 등이 포함되어 암 의 원활한 동작을 도울 수 있다. 암의 타 측에는 석션부가 결합될 수 있다. 석션부는 청소 대상 영역에 분포된 이물질을 흡입하 여 제거하기 위한 흡입부 및 석션부가 청소 대상 영역에 인접한 오브젝트에 접촉할 경우 석션부와 오 브젝트 간의 마찰력을 증대시키기 위한 논슬립(non-slip) 부재 등을 포함할 수 있다. 암은 석션부의 동작을 제어하기 위한 와이어를 포함할 수 있다. 예를 들어, 와이어는 석션 부의 일측에 결합된 제1 와이어 및 석션부의 일측에서 제1 와이어와 일정 거리 이격되어 결합된 제2 와이어를 포함할 수 있으나, 이에 한정되는 것은 아니다. 도 3a에 따르면, 프로세서는 슬라이더가 암의 반대 방향으로 이동하도록 제어할 수 있다. 이 경 우 암은 슬라이더의 이동 방향으로 함께 이동하며, 그 결과 레일 밖으로 돌출된 암의 길이 는 단축될 수 있다. 즉, 슬라이더의 후퇴에 따라 로봇의 위치를 기준으로 로봇이 청소할 수 있 는 범위는 감소할 수 있다. 또한, 슬라이더의 후퇴에 따라 석션부가 지면으로부터 이격된 거리는 증가할 수 있다. 이 경우 석션 부에 의한 이물질 흡입이 원활하게 이루어지지 않을 수 있기 때문에, 프로세서는 모터를 통해 와이어를 제어하여 석션부가 지면에 가까워지도록 석션부의 위치를 조정할 수 있다. 도 3b에 따르면, 프로세서는 슬라이더가 암의 방향으로 이동하도록 제어할 수 있다. 이 경우 암 은 슬라이더의 이동 방향으로 함께 이동하며, 그 결과 레일 밖으로 돌출된 암의 길이는 신 장될 수 있다. 즉, 슬라이더의 전진에 따라 로봇의 위치를 기준으로 로봇이 청소할 수 있는 범 위는 증가할 수 있다. 또한, 슬라이더의 전진에 따라 석션부가 지면으로부터 이격된 거리는 감소할 수 있다. 이 경우 석션 부가 지면에 일시적으로 접합되거나 주행 중에 석션부와 지면의 마찰이 야기될 수 있기 때문에, 프로 세서는 모터를 통해 와이어를 제어하여 석션부가 지면과 멀어지도록 석션부의 위치를조정할 수 있다. 도 4는 본 개시의 일 실시 예에 따른 석션부의 동작을 설명하기 위한 도면이다. 도 4에 따르면, 모터에 의한 와이어의 와인딩(winding)에 의하여 지면과 석션부 사이의 각도가 조정될 수 있다. 예를 들어, 석션부는 지면을 기준으로 제1 각도 이상 제2 각도 이하의 범위를 갖도록 구 동될 수 있다. 석션부는 모터에 의한 와이어의 와인딩에 따라 지면을 기준으로 슬로프가 기울어 진 각도보다 더 작은 각도(이하, 제1 각도)를 유지할 수도 있고, 슬로프가 기울어진 각도보다 더 작은 각도(이 하, 제2 각도)를 유지할 수도 있다. 석션부가 지면과 제1 각도를 유지하는 경우에는 로봇이 청소 대 상 영역과 인접한 오브젝트를 이동시키는 동작을 수행할 수 있으며, 석션부가 지면과 제2 각도를 유지하는 경우에는 로봇이 통상적인 청소 서비스를 제공할 수 있다. 로봇이 통상적인 청소 서비스를 제공하는 과정에서 석션부는 슬로프의 경사 방향보다 아래로 꺾인 상 태를 유지할 수 있다. 일 예에 따르면, 프로세서는 청소 대상 영역의 타입 정보에 기초하여 청소 대상 영역에 인접한 오브젝트를 이동시킬 필요가 있는지 식별할 수 있다. 오브젝트를 이동시킬 필요가 있는 것으로 식별되면, 프로세서는 석션부의 일측에 결합된 제1 와이어를 제1 방향으로 와인딩하여 석션부가 지면과 제1 각도를 유지하 도록 모터를 제어할 수 있다. 이 경우 석션부는 슬로프의 경사 방향보다 위로 꺾인 상태를 유지 할 수 있다. 또한, 프로세서는 청소 대상 영역에 인접한 오브젝트가 이동 가능한 오브젝트로 식별되면, 석션부가 오브젝트에 접촉되도록 제1 와이어를 제1 방향으로 와인딩 하도록 모터를 제어할 수 있다. 프로세서 는 석션부가 오브젝트에 접촉되면 플레이트가 일 방향으로 회전되도록 모터를 제어하여 오브젝 트를 이동시킬 수 있다. 또한, 프로세서는 청소 대상 영역이 특정 타입이면 제1 와이어를 제1 방향으로 와인딩할 수 있다. 예를 들 어, 프로세서는 청소 대상 영역이 ‘좁은 틈’으로 식별되면 제1 와이어를 제1 방향으로 와인딩한 후 청소 대상 영역에 인접한 오브젝트를 이동시킬 수 있다. 만일 청소 대상 영역이 특정 타입 외의 타입이면, 프로세서 는 제2 와이어를 제1 방향으로 와인딩하여 통상적인 청소 서비스를 제공할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 신경망 모델에 대해 설명하기 위한 도면이다. 본 개시에 따른 청소 대상 영역에 대한 타입 정보 획득과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모 리에 저장된 신경망 모델에 따라 입력 데이터를 처리할 수 있으며, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는 특정 신경망 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 메모리에 저장된 신경망 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 신경망 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 신경망 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 다양한 실시 예가 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 신경망 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치 들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신 경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 신경망 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 신경망 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값 이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나,전술한 예에 한정되지 않는다. 본 개시의 일 실시 예에 따르면, 신경망 모델은 카메라를 통해 획득된 이미지 및 거리 센서 를 통해 획득된 거리 데이터가 입력되면 이미지에 포함된 세그먼트 및 세그먼트의 타입을 출력하도록 학습된 모델일 수 있다. 여기서, 세그먼트의 타입은 바닥, 벽, 슬로프 또는 장애물과 같이 이 미지에 포함된 오브젝트에 대한 정보일 수도 있고, 노멀(Normal), 얕은 틈, 코너, 깊은 틈, 좁은 틈 또는 단차 영역과 같이 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보일 수도 있다. 도 6a 내지 도 6d는 본 개시의 일 실시 예에 따른 다양한 청소 시나리오에 대해 설명하기 위한 도면이다. 도 6a에 따르면, 로봇은 청소 대상 영역의 타입이 ‘얕은 틈’인 것으로 식별하고, 얕은 틈에 대응되 는 청소 시나리오에 기초하여 청소를 수행할 수 있다. 예를 들어, 로봇은 석션부를 얕은 틈 상 에 위치시킨 상태에서 얕은 틈을 따라 주행하며 청소를 수행할 수 있다. 도 6b에 따르면, 로봇은 청소 대상 영역의 타입이 ‘코너’인 것으로 식별하고, 코너에 대응되는 청 소 시나리오에 기초하여 청소를 수행할 수 있다. 예를 들어, 로봇의 석션부가 코너를 구성하는 오브젝트와 근접한 상태를 유지하면서 플레이트를 회전시켜 청소를 수행할 수 있다. 이 과정에서, 프로세 서는 로봇의 위치를 기준으로 로봇이 청소할 수 있는 범위를 가변적으로 조절하기 위해 모터 를 통해 슬라이더를 왕복운동 시킬 수 있다. 도 6c에 따르면, 로봇은 청소 대상 영역의 타입이 ‘깊은 틈’인 것으로 식별하고, 깊은 틈에 대응되 는 청소 시나리오에 기초하여 청소를 수행할 수 있다. 예를 들어, 로봇은 플레이트가 제1 방향 또는 제2 방향으로 교번적으로 회전하도록 모터를 제어할 수 있다. 플레이트의 교번적인 회전 동작과 동시 에 로봇 깊은 틈을 따라 주행하는 경우, 이를 통해 석션부가 깊은 틈 내부로 진입한 정도 가 지속적으로 변화하면서 청소가 수행되기 때문에 짧은 시간 내에 보다 넓은 범위에 대한 청소가 수행될 수 있 다. 도 6d에 따르면, 로봇은 청소 대상 영역의 타입이 ‘좁은 틈’인 것으로 식별하고, 좁은 틈에 대응되 는 청소 시나리오에 기초하여 청소를 수행할 수 있다. 예를 들어, 로봇은 좁은 틈이 시작되는 지점과 끝나 는 지점 사이의 영역을 청소하기 위해 슬라이더를 왕복운동 시킬 수 있다. 이를 통해 암이 로봇(10 0)의 본체를 기준으로 돌출되거나 회수되는 동작이 연속적으로 일어날 수 있으므로, 좁은 틈에 대한 효율 적인 청소가 가능해진다. 도 7a 및 도 7b는 본 개시의 일 실시 예에 따른 오브젝트 이동 가부에 따른 로봇의 동작을 설명하기 위한 도면 이다. 도 7a에 따르면, 로봇은 로봇의 스펙을 기초로 이동 가능한 오브젝트가 인접한 청소 대상 영역 을 청소할 수 있다. 청소 과정에서 로봇은 오브젝트가 이동 가능한 오브젝트인 것인지 여부를 식별할 수 있다. 예를 들어, 로봇은 이미지 및 거리 데이터를 신경망 모델에 입력하여 출력된 결과에 기초하여 오 브젝트가 이동 가능한 오브젝트인 것으로 식별하고, 석션부가 오브젝트에 접촉되도록 모터(14 1)를 통해 와이어를 제어할 수 있다. 석션부가 오브젝트에 접촉되면, 프로세서는 플레이트가 일 방향으로 회전하도록 모터를 제 어하여 오브젝트를 이동시킬 수 있다. 이후 프로세서는 오브젝트의 기존 위치와 인접한 영역을 청소하도록 구동부를 제어할 수 있다. 도 7b에 따르면, 로봇은 사용자 인터페이스를 더 포함할 수 있다. 로봇은 로봇의 스펙을 기초로 이동 불가능한 오브젝트가 인접한 청소 대상 영역을 청소하는 과정에서 이미지 및 거리 데이터를 신경망 모델에 입력하여 출력된 결과에 기초하여 오브젝트가 이동 불가능한 오브젝트인 것으로 식별하고, 오브젝트의 이동을 요청하는 가이드 UI를 사용자 인터페이스를 통해 제공할 수 있다. 일 예에 따른 가이드 UI는 사용자로 하여금 오브젝트를 이동시키도록 주위를 환기하는 텍스트, 확인 버튼 및 무시 버튼 등의 정보를 포함할 수 있다. 여기서, 사용자가 확인 버튼을 선택하는 경우 로봇은 구동을 중지하고 오브젝트가 이동될 때까지 대기할 수 있다. 반대로, 사용자가 무시 버튼 을 선택하는 경우 로봇은 오브젝트의 이동과 무관하게 다음 청소 대상 영역을 청소하기 위해 현 위치를 벗어날 수 있다.도 8은 본 개시의 일 실시 예에 따른 로봇의 단차 영역에 대한 청소 동작을 설명하기 위한 도면이다. 도 8에 따르면, 로봇이 위치한 공간 내에는 지면과 임계 값 이상의 단차를 갖는 영역(이하, 단차 영역)을 형성하는 오브젝트가 배치되어 있을 수 있다. 일 예에 따른 프로세서는 청소 대상 영역인 단차 영역 이 지면과 임계 값 이상의 단차를 가지는 것으로 식별되면 슬라이더를 후방으로 이동시켜 단차 영역으로 석션부의 위치를 제어할 수 있다. 이 과정에서 암이 레일에 포함된 슬로프를 따라 로봇의 본체 방향으로 회수되므로 석션부 가 지면과 이격된 거리는 증가하며, 그에 따라 석션부가 단차 영역과 적정한 거리로 이격된 상태가 유지될 수 있다. 한편, 로봇은 상술한 방식 이외에도 와이어를 와인딩하여 석션부가 단차 영역과 적정한 거리로 이격된 상태가 유지되도록 모터를 제어할 수 있음은 물론이다. 도 9는 본 개시의 일 실시 예에 따른 로봇의 구성을 구체적으로 설명하기 위한 블록도이다. 도 9에 따르면, 로봇은 메모리, 카메라, 거리 센서, 구동부, 프로세서, 사용자 인터페이스 및 통신 인터페이스를 포함할 수 있다. 도 9에 도시된 구성 중 도 2에 도시된 구성과 중 복되는 구성에 대해서는 자세한 설명을 생략하도록 한다. 카메라는 RGB 카메라와 적외선 카메라를 포함하는 카메라 모듈의 형태로 구현될 수 있다. 일 예 에 따르면, 카메라는 가시광 센서를 포함하는 RGB 카메라와 적외선 센서를 포함하는 적외선 카메라 를 포함할 수 있으며, 이 경우 프로세서는 RGB 카메라를 통해 획득된 가시광 이미지, 적외선 카 메라를 통해 획득된 적외선 이미지 및 거리 데이터를 신경망 모델에 입력하여 청소 대상 영역에 대한 타입 정보를 획득할 수 있다. 거리 센서는 LIDAR, RADAR 및 SONAR를 포함할 수 있다. LIDAR는 고출력 레이저 펄스를 발사해, 레이저가 오브젝트에 도달한 후 다시 반사되어 돌아오는 시간을 측 정할 수 있다(Tof, Time of Flight 방식). 이를 통해 LIDAR는 오브젝트에 이르는 거리 데이터를 획득할 수 있다. 또한, LIDAR는 오브젝트 표면 영역에 대응되는 포인트 클라우드에 기초하여 오브젝트의 형태에 관한 데이 터 역시 획득할 수 있다. 프로세서는 로봇이 청소를 수행하는 동안 LIDAR를 통해 획득된 거리 데이터에 기초하여 석션부가 오브젝트와 충돌하지 않는 범위 내에서 청소 범위가 조정되도록 모터를 통해 슬라이드를 제어할 수 있다. RADAR는 LIDAR와 같은 방식(ToF)으로 오브젝트에 이르는 거리 데이터를 획득할 수 있다. 다만, RADAR는 LIDAR와 달리 전파를 이용하며, 전파가 오브젝트에 반사되어 돌아오는 시간을 측정하여 오브 젝트까지의 거리 데이터를 획득할 수 있다. SONAR는 음파를 활용해 오브젝트까지의 거리 데이터를 획득할 수 있는 장비이다. 일 예에 따른 SONAR(13 3)는 원추 형상의 화각을 가질 수 있으며, 음파가 오브젝트에 반사되어 돌아오는 시간을 측정하여 오브젝트까지 의 거리 데이터를 획득할 수 있다. 프로세서는 카메라를 통해 획득된 이미지 및 LIDAR, RADAR 및 SONAR를 통해 각각 획 득된 복수의 거리 데이터들에 기초하여 청소 대상 영역에 대한 타입 정보를 획득할 수 있다. 구동부는 모터, 플레이트, 레일, 슬라이더, 암, 석션부 및 와이어를 포함할 수 있다. 구동부에 포함된 각 구성에 대해서는 전술하였으므로 여기에서는 자세한 설명을 생략하도 록 한다. 사용자 인터페이스는 로봇이 사용자와 인터렉션(Interaction)을 수행하는 데 관여하는 구성이다. 예 를 들어 사용자 인터페이스는 디스플레이, 터치 스크린, 버튼, 조그(Jog) 다이얼, 스위치, 근접 센서, 다 양한 타입의 생체 센서, 마이크 또는 스피커 중 적어도 하나를 포함할 수 있으나 이에 한정되는 것은 아니다. 프로세서는 청소 대상 영역에 인접한 오브젝트의 이동이 불가능한 경우에는 사용자 인터페이스를 통 해 오브젝트의 이동을 요청하는 가이드 UI를 제공할 수 있으며, 카메라를 통해 획득된 이미지에서 청소 불 가능한 영역이 식별되면 사용자 인터페이스를 통해 청소 불가능한 영역을 가이드하는 UI를 제공할 수 있다. 통신 인터페이스는 다양한 타입의 데이터를 입력 및 출력할 수 있다. 예를 들어, 통신 인터페이스는 AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜(Coaxial) 등과 같은 통신 방식 을 통해 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들어 웹 하드)와 다양한 타입의 데이터를 송수신할 수 있다. 프로세서는 사용자 인터페이스를 통해 각종 UI를 제공할 수도 있으나, 통신 인터페이스를 통해 UI 정보를 사용자 단말로 전송함으로써 각종 UI를 제공할 수도 있다. 또한, 본 개시에 따른 신경망 모델을 활용 한 청소 대상 영역의 타입 정보 획득 동작이 외부 장치(예: 서버 등)를 통해 이루어지는 경우, 프로세서는 카메라를 통해 획득된 이미지 및 거리 센서를 통해 획득된 거리 데이터를 외부 장치로 전송하도록 통 신 인터페이스를 제어하고, 통신 인터페이스를 통해 외부 장치로부터 청소 대상 영역의 타입 정보를 수신할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 제어 방법을 설명하기 위한 흐름도이다. 본 개시의 일 실시 예에 따른 제어 방법은 카메라를 통해 획득된 이미지 및 거리 센서를 통해 획득된 거리 데이 터를 신경망 모델에 입력하여 이미지에 포함된 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득한다 (S1010). 이어서, 획득된 타입 정보에 대응되는 청소 시나리오를 획득한다(S1020). 마지막으로, 획득된 청소 시나리오에 기초하여 구동부를 제어하여 청소를 수행할 수 있다(S1030). 여기서, 구동부는 모터, 회전 가능하도록 설계된 플레이트, 플레이트 상에 배치되며 지면과 일정한 각도로 기울 어진 슬로프(slope)를 구비한 레일, 레일 상에서 왕복 가능하도록 배치된 슬라이더, 일 측이 슬라이더에 결합되 며 슬라이더가 레일 상에서 왕복함에 따라 지면과 일정한 각도를 유지하며 이동하는 암(Arm) 및 암의 타 측에 결합된 석션부를 포함할 수 있다. 여기서, 신경망 모델은 이미지 및 거리 데이터가 입력되면 이미지에 포함된 적어도 하나의 청소 대상 영역에 대 한 타입 정보를 출력하도록 학습되거나, 이미지에 포함된 오브젝트에 대한 정보를 출력하도록 학습되며, 적어도 하나의 청소 대상 영역에 대한 타입 정보를 획득하는 단계(S1010)에서는 신경망 모델로부터 이미지에 포함된 오 브젝트에 대한 정보가 획득되면 획득된 오브젝트에 대한 정보에 기초하여 이미지에 포함된 청소 대상 영역에 대 한 타입 정보를 획득할 수 있다. 또한, 구동부는 석션부의 일측에 결합된 제1 와이어 및 석션부의 일측에서 제1 와이어와 일정 거리 이격되어 결 합된 제2 와이어를 더 포함하며, 이 경우 제어 방법은 청소 대상 영역의 타입에 따라 석션부가 지면과 제1 각도 를 유지하도록 제1 와이어를 제1 방향으로 와인딩(winding)하는 단계 및 청소 대상 영역의 타입에 따라 석션부 가 지면과 제2 각도를 유지하도록 제2 와이어를 제2 방향으로 와인딩하는 단계를 더 포함할 수 있다. 여기서, 제1 와이어를 제1 방향으로 와인딩하는 단계는 청소 대상 영역에 인접한 오브젝트가 이동 가능한 오브 젝트로 식별되면 석션부가 오브젝트에 접촉되도록 제1 와이어를 제1 방향으로 와인딩하며, 이 경우 제어 방법은 석션부가 오브젝트에 접촉되면 플레이트를 일 방향으로 회전시키는 단계를 더 포함할 수 있다. 또한, 오브젝트가 이동 불가능한 오브젝트인 것으로 식별되면 오브젝트의 이동을 요청하는 가이드 UI(User Interface)를 제공하는 단계를 더 포함할 수 있다. 또한, 제1 와이어를 제1 방향으로 와인딩하는 단계는 청소 대상 영역이 특정 타입이면 제1 와이어를 제1 방향으 로 와인딩하고, 제2 와이어를 제2 방향으로 와인딩하는 단계는 청소 대상 영역이 특정 타입 외의 타입이면 제2 와이어를 제2 방향으로 와인딩할 수 있다. 또한, 청소를 수행하는 단계(S1030)에서는 청소 대상 영역과 지면의 단차가 임계 값 이상인 경우 슬라이더를 후 방으로 이동시켜 청소 대상 영역으로 석션부를 위치시킬 수 있다. 또한, 청소를 수행하는 단계(S1030)에서는 청소를 수행하는 동안 라이다 센서를 통해 획득된 거리 데이터에 기 초하여 슬라이더를 이동시킬 수 있다. 또한, 이미지에서 청소 불가능한 영역이 식별되면 청소 불가능한 영역을 가이드하는 UI를 제공하는 단계를 더 포함할 수 있다.또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은 기존 로봇에 대한 소프트웨어 업그레이드, 또는 하 드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 로봇에 구비된 임베디드 서버 또는 적어도 하나의 외부 서버를 통 해 수행되는 것도 가능하다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의 하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 로봇의 프로세싱 동작을 수행하기 위한 컴퓨터 명령어 (computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저 장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 로봇에서의 처리 동작을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0073793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해 되어져서는 안될 것이다."}
{"patent_id": "10-2022-0073793", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 로봇의 청소 서비스 제공에 관해 개략적으로 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 설명하기 위한 블록도이다. 도 3a 및 도 3b는 본 개시의 일 실시 예에 따른 암의 동작을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 석션부의 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 신경망 모델에 대해 설명하기 위한 도면이다. 도 6a 내지 도 6d는 본 개시의 일 실시 예에 따른 다양한 청소 시나리오에 대해 설명하기 위한 도면이다. 도 7a 및 도 7b는 본 개시의 일 실시 예에 따른 오브젝트 이동 가부에 따른 로봇의 동작을 설명하기 위한 도면 이다. 도 8은 본 개시의 일 실시 예에 따른 로봇의 단차 영역에 대한 청소 동작을 설명하기 위한 도면이다.도 9는 본 개시의 일 실시 예에 따른 로봇의 구성을 구체적으로 설명하기 위한 블록도이다. 도 10은 본 개시의 일 실시 예에 따른 제어 방법을 설명하기 위한 흐름도이다."}
