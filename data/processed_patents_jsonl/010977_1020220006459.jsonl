{"patent_id": "10-2022-0006459", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0110918", "출원번호": "10-2022-0006459", "발명의 명칭": "영상 처리 방법, 장치 및 이를 포함하는 차량", "출원인": "현대자동차주식회사", "발명자": "최종현"}}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 정보를 획득하고,그라운드 트루쓰(Ground Truth)를 입력하고,객체 인식 모델에 상기 이미지 정보를 입력하여, 상기 이미지 정보에 포함된 객체의 위치 및 종류를 포함하는인식 정보를 출력하고,상기 출력된 인식 정보 및 상기 그라운드 트루쓰(Ground Truth)를 기초로 오인식 데이터를 생성하고,상기 오인식 데이터를 처리한 것에 기초하여, 상기 객체 인식 모델의 취약 패턴맵을 생성하고,상기 취약 패턴맵 및 적어도 하나의 기저장된 이미지 정보를 기초로 취약 데이터베이스를 분류하는 영상 처리방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 취약 패턴맵을 생성하는 것은,상기 오인식 데이터를 처리한 것을 기초로, 상기 오인식 데이터의 특징점 기여도 및 입출력 민감도 중 적어도하나에 기초하여, 상기 오인식 데이터의 미리 정해진 크기의 패턴맵을 생성하는 영상 처리 방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 취약 데이터베이스를 분류하는 것은,상기 기저장된 이미지 정보 및 상기 취약 패턴맵을 기초로 유사도를 산출하고, 상기 산출된 유사도를 기초로 취약 데이터베이스를 분류하는 영상 처리 방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 취약 데이터베이스를 분류하는 것은,상기 산출된 유사도가 미리 정해진 값보다 큰 것에 응답하여, 상기 기저장된 이미지 정보를 상기 취약 데이터베이스로 분류하는 영상 처리 방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 객체 인식 모델은,합성곱 신경망(CNN, Convolutional Neural Networks)을 기초로 학습된 모델인 영상 처리 방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 영상 처리 방법은,상기 객체 인식 모델 및 상기 취약 패턴맵를 기초로, 상기 객체 인식 모델의 취약 커널을 선별하되, 상기 선별된 취약 커널을 상기 취약 데이터베이스를 기초로 학습시키는 영상 처리 방법.공개특허 10-2023-0110918-3-청구항 7 제6항에 있어서,상기 취약 커널을 선별하는 것은,상기 객체 인식 모델의 커널 별 상기 취약 패턴맵에 대한 민감도를 산출하고,상기 산출된 민감도가 미리 정해진 민감도 이상인 커널을 취약 커널로 선별하는 영상 처리 방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 취약 데이터베이스를 기초로 학습시키는 것은,상기 취약 데이터베이스를 미리 정해진 비율로 제1 취약 데이터베이스 및 제2 취약 데이터베이스로 무작위 분류하되,상기 제1 취약 데이터베이스를 기초로 상기 취약 커널을 학습시키는 영상 처리 방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 취약 커널을 학습시키는 것은,상기 학습의 각 에폭(Epoch)마다 상기 제2 취약 데이터베이스를 기초로 상기 객체 인식 모델의 성능도를 산출하되, 상기 산출된 성능도가 미리 정해진 값보다 높은 경우, 상기 취약 커널의 학습을 중단하는 영상 처리 방법."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "이미지 정보를 획득하는 이미지 센서;그라운드 트루쓰(Ground Truth)를 입력하는 입력부; 및상기 이미지 정보를 처리하는 프로세서를 포함하는 제어부;를 포함하되,상기 제어부는,객체 인식 모델에 상기 이미지 정보를 입력하여, 상기 이미지 정보에 포함된 객체의 위치 및 종류를 포함하는인식 정보를 출력하고,상기 출력된 인식 정보 및 상기 그라운드 트루쓰(Ground Truth)를 기초로 오인식 데이터를 생성하되,상기 오인식 데이터를 처리한 것에 기초하여, 상기 객체 인식 모델의 취약 패턴맵을 생성하고,상기 취약 패턴맵 및 적어도 하나의 기저장된 이미지 정보를 기초로 취약 데이터베이스를 분류하는 영상 처리장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 취약 패턴맵을 생성하는 것은,상기 오인식 데이터를 처리한 것을 기초로, 상기 오인식 데이터의 특징점 기여도 및 입출력 민감도 중 적어도하나에 기초하여, 상기 오인식 데이터의 미리 정해진 크기의 패턴을 생성하는 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 취약 데이터베이스를 분류하는 것은,상기 기저장된 이미지 정보 및 상기 취약 패턴맵을 기초로 유사도를 산출하고, 상기 산출된 유사도를 기초로 취공개특허 10-2023-0110918-4-약 데이터베이스를 분류하는 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 취약 데이터베이스를 분류하는 것은,상기 산출된 유사도가 미리 정해진 값보다 큰 것에 응답하여, 상기 기저장된 이미지 정보를 상기 취약 데이터베이스로 분류하는 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 객체 인식 모델은,합성곱 신경망(CNN, Convolutional Neural Networks)을 기초로 학습된 모델인 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제어부는,상기 객체 인식 모델 및 상기 취약 패턴맵을 기초로, 상기 객체 인식 모델의 취약 커널을 선별하되, 상기 선별된 취약 커널을 상기 취약 데이터베이스를 기초로 학습시키는 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 취약 커널을 선별하는 것은,상기 객체 인식 모델의 커널 별 상기 취약 패턴맵에 대한 민감도를 산출하고,상기 산출된 민감도가 미리 정해진 민감도 이상인 커널을 취약 커널로 선별하는 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 취약 데이터베이스를 기초로 학습시키는 것은,상기 취약 데이터베이스를 미리 정해진 비율로 제1 취약 데이터베이스 및 제2 취약 데이터베이스로 무작위 분류하되,상기 제1 취약 데이터베이스를 기초로 상기 취약 커널을 학습시키는 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 취약 커널을 학습시키는 것은,상기 학습의 각 에폭(Epoch)마다 상기 제2 취약 데이터베이스를 기초로 상기 객체 인식 모델의 성능도를 산출하되, 상기 산출된 성능도가 미리 정해진 값보다 높은 경우, 상기 취약 커널의 학습을 중단하는 영상 처리 장치."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항에 따른 영상 처리 방법을 실행시킬 수 있는 프로그램이 저장된 기록 매체."}
{"patent_id": "10-2022-0006459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제10항 내지 제18항 중 어느 한 항에 있어서,공개특허 10-2023-0110918-5-상기 영상 처리 장치를 포함하는 차량."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 처리 방법, 장치 및 이를 포함하는 차량에 있어서, 영상 처리 방법은, 이미지 정보를 획득하고, 그라운드 트루쓰(Ground Truth)를 입력하고, 객체 인식 모델에 상기 이미지 정보를 입력하여, 상기 이미지 정보에 포함된 객체의 위치 및 종류를 포함하는 인식 정보를 출력하고, 상기 출력된 인식 정보 및 상기 그라운드 트루쓰(Ground Truth)를 기초로 오인식 데이터를 생성하고, 상기 오인식 데이터를 처리한 것에 기초하여, 상기 객체 인식 모델 의 취약 패턴맵을 생성하고, 상기 취약 패턴맵 및 적어도 하나의 기저장된 이미지 정보를 기초로 취약 데이터베 이스를 분류할 수 있다."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 처리 방법, 장치 및 이를 포함하는 차량에 관한 것이다. 보다 상세하게는, 딥러닝 모델의 취약 커널을 학습시킬 수 있는 영상 처리 방법, 장치 및 이를 포함하는 차량에 관한 것이다."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율 주행은 일부 또는 완전한 운전자의 개입 없이 차량 시스템이 자체적으로 차량 운행을 수행하는 것을 의미 한다. 이를 구현하기 위해서는 다양한 상황 또는 변수를 제어할 수 있는 알고리즘이 필요하다. 이에, 많은 데이 터로부터 다양한 특징을 스스로 분석할 수 있는 인간의 신경망 구조를 본딴 인공 신경망 구조가 적용된 딥러닝 알고리즘이 자율 주행에 적용되고 있다. 이러한 딥러닝 알고리즘의 정확도는 차량의 주변 환경에 따라 영향을 많이 받을 수 있다. 이에, 딥러닝 알고리 즘의 신뢰도를 높이기 위한 다양한 기술들이 개발되고 있으나, 아직까지 많은 딥러닝 알고리즘들이 일정 이상의 정확도를 제공하지 못하는 한계가 있다. 한편, 종래의 딥러닝 알고리즘은, 해당하는 모델의 현재 문제점만을 해결하기 위하여 집중적으로 학습하는 것이 모델을 전체적으로 학습하는 방식을 채택하고 있다. 그러나, 이는, 모델의 강점만이 지속적으로 학습되는 반면 약점은 오히려 더욱 약화될 수 있는 문제점이 있다. 또한, 종래의 딥러닝 알고리즘은, 모델 그 자체와 그 동작에 대한 설명 없이 훈련을 지속하여 실제 도로에서의 불확실성을 가중시키는 문제점이 있다."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 딥러닝 모델의 취약점을 중점적으로 학습시킬 수 있는 영상 처리 방법, 장치 및 이를 포함하는 차량 을 제공할 수 있다."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 의한 영상 처리 방법은, 이미지 정보를 획득하고, 그라운드 트루쓰(Ground Truth)를 입력하고, 객체 인식 모델에 상기 이미지 정보를 입력하여, 상기 이미지 정보에 포함된 객체의 위치 및 종류를 포함하는 인식 정보를 출력하고, 상기 출력된 인식 정보 및 상기 그라운드 트루쓰(Ground Truth)를 기초로 오인식 데이터를 생 성하고, 상기 오인식 데이터를 처리한 것에 기초하여, 상기 객체 인식 모델의 취약 패턴맵을 생성하고, 상기 취 약 패턴맵 및 적어도 하나의 기저장된 이미지 정보를 기초로 취약 데이터베이스를 분류할 수 있다. 상기 취약 패턴맵을 생성하는 것은, 상기 오인식 데이터를 처리한 것을 기초로, 상기 오인식 데이터의 특징점 기여도 및 입출력 민감도 중 적어도 하나에 기초하여, 상기 오인식 데이터의 미리 정해진 크기의 패턴맵을 생성 할 수 있다. 상기 취약 데이터베이스를 분류하는 것은, 상기 기저장된 이미지 정보 및 상기 취약 패턴맵을 기초로 유사도를 산출하고, 상기 산출된 유사도를 기초로 취약 데이터베이스를 분류할 수 있다. 상기 취약 데이터베이스를 분류하는 것은, 상기 산출된 유사도가 미리 정해진 값보다 큰 것에 응답하여, 상기 기저장된 이미지 정보를 상기 취약 데이터베이스로 분류할 수 있다. 상기 객체 인식 모델은, 합성곱 신경망(CNN, Convolutional Neural Networks)을 기초로 학습된 모델일 수 있다. 상기 영상 처리 방법은, 상기 객체 인식 모델 및 상기 취약 패턴맵를 기초로, 상기 객체 인식 모델의 취약 커널 을 선별하되, 상기 선별된 취약 커널을 상기 취약 데이터베이스를 기초로 학습시킬 수 있다. 상기 취약 커널을 선별하는 것은, 상기 객체 인식 모델의 커널 별 상기 취약 패턴맵에 대한 민감도를 산출하고, 상기 산출된 민감도가 미리 정해진 민감도 이상인 커널을 취약 커널로 선별할 수 있다. 상기 취약 데이터베이스를 기초로 학습시키는 것은, 상기 취약 데이터베이스를 미리 정해진 비율로 제1 취약 데 이터베이스 및 제2 취약 데이터베이스로 무작위 분류하되, 상기 제1 취약 데이터베이스를 기초로 상기 취약 커 널을 학습시킬 수 있다. 상기 취약 커널을 학습시키는 것은, 상기 학습의 각 에폭(Epoch)마다 상기 제2 취약 데이터베이스를 기초로 상 기 객체 인식 모델의 성능도를 산출하되, 상기 산출된 성능도가 미리 정해진 값보다 높은 경우, 상기 취약 커널 의 학습을 중단할 수 있다. 일 실시예에 따른 영상 처리 장치는, 이미지 정보를 획득하는 이미지 센서, 그라운드 트루쓰(Ground Truth)를 입력하는 입력부 및 상기 이미지 정보를 처리하는 프로세서를 포함하는 제어부를 포함하되, 상기 제어부는, 객 체 인식 모델에 상기 이미지 정보를 입력하여, 상기 이미지 정보에 포함된 객체의 위치 및 종류를 포함하는 인 식 정보를 출력하고, 상기 출력된 인식 정보 및 상기 그라운드 트루쓰(Ground Truth)를 기초로 오인식 데이터를 생성하되, 상기 오인식 데이터를 처리한 것에 기초하여, 상기 객체 인식 모델의 취약 패턴맵을 생성하고, 상기 취약 패턴맵 및 적어도 하나의 기저장된 이미지 정보를 기초로 취약 데이터베이스를 분류할 수 있다."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 영상 처리 방법, 장치 및 이를 포함하는 차량은, 딥러닝 모델의 취약점을 중점적으로 학습시 킬 수 있다."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 자율 주행은 일부 또는 완전한 운전자의 개입 없이 차량 시스템이 자체적으로 차량 운행을 수행하는 것을 의미 한다. 이를 구현하기 위해서는 다양한 상황 또는 변수를 제어할 수 있는 알고리즘이 필요하다. 이에, 많은 데이 터로부터 다양한 특징을 스스로 분석할 수 있는 인간의 신경망 구조를 본딴 인공 신경망 구조가 적용된 딥러닝 알고리즘이 자율 주행에 적용되고 있다. 이러한 딥러닝 알고리즘의 정확도는 차량의 주변 환경에 따라 영향을 많이 받을 수 있다. 이에, 딥러닝 알고리 즘의 신뢰도를 높이기 위한 다양한 기술들이 개발되고 있으나, 아직까지 많은 딥러닝 알고리즘들이 일정 이상의 정확도를 제공하지 못하는 한계가 있다. 한편, 종래의 딥러닝 알고리즘은, 해당하는 모델의 현재 문제점만을 해결하기 위하여 집중적으로 학습하는 것이 아닌 모델을 전체적으로 학습하는 방식을 채택하고 있다. 그러나, 이는, 모델의 강점만이 지속적으로 학습되는 반면 약점은 오히려 더욱 약화될 수 있는 문제점이 있다. 또한, 종래의 딥러닝 알고리즘은, 모델 그 자체와 그 동작에 대한 설명 없이 훈련을 지속하여 실제 도로에서의 불확실성을 가중시키는 문제점이 있다. 본원의 일 실시예에 의한 영상 처리 방법, 장치 및 이를 포함하는 차량은, 상술한 문제점을 해결하기 위한 것일 수 있다. 다만, 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 차량은 도로나 선로를 주행할 수 있는 운송 수단을 의미한다. 이하 설명의 편 의를 위하여, 사륜 자동차를 예를 들어, 차량에 대해 설명하도록 한다. 그러나, 차량의 실시예는 이에 한정되지 않는다. 차량은 차량의 겉 부분과 사람 및/또는 화물을 싣는 골격을 포함하여 예를 들어, 엔진실, 트렁크, 범퍼, 지붕, 옆판, 바닥 등을 포함하는 차체와 차량이 주행하기 위해 필요한 필수 장치를 포함하여, 예를 들어, 엔진, 동력 전달 장치, 조향 장치, 브레이크 등을 포함하는 차대를 포함할 수 있다. 한편, 차량의 차체와 차대에 관한 일반적 설명은 생략하도록 한다. 이하 첨부된 도면들을 참고하여 본 발명의 작용 원리 및 실시예들에 대해 설명한다. 도 1은 일 실시예에 의한 차량의 구성을 설명하기 위한 블록도이다. 이하에서는, 간략하게 일 실시예에 의 한 차량 및 그에 포함된 영상 처리 장치에 대하여 설명한 후, 영상 처리 방법에 대하여 자세히 서술하 도록 한다. 도 1을 참조하면, 차량은 이미지 센서, 입력부 및 제어부를 포함하는 영상 처리 장치 및 레이더, 라이더, 구동 장치, 제동 장치, 조향 장치, 디스플레이와 오디오 를 포함할 수 있다. 다만, 이에 한정되는 것은 아니다. 본원의 일 실시에에 따른 차량은 영상 처리 장 치에 포함된 제어부와 별도로 적어도 하나의 제어부(미도시)를 포함하여 차량의 전반적인 제어를 수행할 수 있다. 즉, 영상 처리 장치만을 위한 제어부와 차량의 전반적인 제어를 수행하는 별도 의 제어부(미도시)를 포함할 수 있다. 이미지 센서는 차량의 주변을 향하도록 배치되어 차량의 주변을 향하는 시야(Field Of View)를 가 질 수 있다. 예시적으로, 이미지 센서는 차량의 프론트 윈드 쉴드에 설치될 수 있으나 위치에 제한되 는 것은 아니다. 이미지 센서는 광을 전기 신호로 변환하는 복수의 포토 다이오드들을 포함할 수 있으며, 복수의 포토 다이 오드들이 2차원 매트릭스로 배치될 수 있다. 이미지 센서는 예시적으로 2차원으로 이루어진 이미지를 포함 하는 이미지 정보를 생성할 수 있으며, 시간의 흐름에 따라 배열된 2차원으로 이루어진 복수의 이미지를 포함하 는 이미지 정보를 생성할 수 있다. 입력부는 외부 장치 및/또는 서버로부터 각종 정보를 입력 받을 수 있다. 보다 구체적으로, 입력부는 외부 장치 및/또는 서버 물리적 연결 및/또는 무선 연결을 기초로 그라운드 트루쓰(Ground Truth)를 입력 받을수 있다. 여기에서 그라운드 트루쓰는 이미지 정보 내 객체에 대한 위치 및/또는 종류를 포함하는 데이터를 의 미할 수 있다. 즉, 머신러닝의 관점에서, 그라운드 트루쓰(Ground Truth)는 학습하고자 하는 데이터의 결과 값 및/또는 정답에 대한 설명을 포함하는 데이터를 의미할 수 있다. 즉, 입력부는 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때 사용될 입력 데이 터 등을 획득할 수 있다. 입력부는 가공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 제어부 는 예를 들어, 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 제어부는 프로세서 및 메모리를 포함할 수 있다. 프로세서는 적어도 하나의 프로세서를 포함할 수 있다. 예를 들어, 프로세서는 머신러닝을 위한 러닝 프로 세서를 포함하여, 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학습된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데이터에 대하여 결 과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기초로 이용될 수 있 다. 보다 상세하게, 프로세서는 이미지 정보를 입력하여, 객체의 위치 및 종류를 포함하는 인식 정보를 출력하 는 객체 인식 모델을 저장하는 객체 인식 프로세서와, 상기 객체 인식 프로세서에서 출력된 인식 정보 및 입력 부를 통해 획득한 그라운드 트루쓰(Ground Truth)를 기초로 오인식 데이터를 생성하는 오인식 데이터 생성 프로세서와, 상기 생성된 오인식 데이터를 처리하여 상기 객체 인식 모델의 취약 패턴을 생성하는 취약 패턴 생 성 프로세서와, 상기 생성된 취약 패턴 및 상기 객체 인식 모델을 기초로 상기 객체 인식 모델의 취약 커널을 선별하는 취약 커널 선별 프로세서와, 상기 취약 패턴 및 적어도 하나의 기저장된 이미지 정보를 기초로 취약 데이터베이스를 분류하는 취약 데이터베이스 생성 프로세서 및 상기 취약 데이터베이스 및 상기 취약 커널을 기 초로 상기 취약 커널을 학습시키는 러닝 프로세서를 포함할 수 있다. 다만, 이에 한정되는 것은 아니다. 즉, 프 로세서의 개수에 제한되는 것은 아니며, 상술한 프로세서의 개수보다 적거나 많게 구현될 수 있음을 이해할 수 있다. 메모리는 전술한 동작 및 후술하는 동작을 수행하는 프로그램을 저장할 수 있으며, 프로세서는 저장 된 프로그램을 실행시킬 수 있다. 메모리와 프로세서가 복수인 경우에, 이들이 하나의 칩에 집적되는 것도 가능하고, 물리적으로 분리된 위치에 마련되는 것도 가능하다. 메모리는 데이터를 일시적으로 기억하 기 위한 S램(Static Random Access Memory, S-RAM), D랩(Dynamic Random Access Memory) 등의 휘발성 메모리를 포함할 수 있다. 또한, 메모리는 제어 프로그램 및 제어 데이터를 장기간 저장하기 위한 롬(Read Only Memory), 이피롬(Erasable Programmable Read Only Memory: EPROM), 이이피롬(Electrically Erasable Programmable Read Only Memory: EEPROM) 등의 비휘발성 메모리를 포함할 수 있다. 프로세서는 각종 논리 회로와 연산 회로를 포함할 수 있으며, 메모리로부터 제공된 프로그램에 따라 데이터를 처리하고, 처리 결 과에 따라 제어 신호를 생성할 수 있다. 보다 구체적으로, 메모리는 이미지 센서 및/또는 입력부에서 획득한 데이터, 학습 데이터, 기저 장된 이미지 정보, 학습 히스토리 등을 저장할 수 있다. 이에 따라 프로세서는 이미지 센서로부터 획득한 이미지 정보 및 입력부로부터 획득한 그라운드 트루쓰(Ground Truth)를 수신하고, 상기 이미지 정보 및 그라운드 트루쓰(Ground Truth)를 기초로 객체 인식 모 델의 학습을 수행할 수 있다. 이하에서는, 본원의 일 실시예에 의한 영상 처리 방법을 도 2 내지 도 10을 참조하여 설명하도록 한다. 도 2 내 지 도 10은 상술한 이미지 센서, 입력부 및 제어부를 포함하는 영상 처리 장치에 의하여 동작되거나, 상기 영상 처리 장치를 포함하는 차량에 의하여 수행될 수 있다. 따라서, 이하에서 설명 하는 영상 처리 방법에 대하여 설명한 내용은 영상 처리 장치 및/또는 차량에 대한 설명에도 동일하게 적용될 수 있다. 딥 러닝 (deep learning) 알고리즘은 머신 러닝(Machine learning) 알고리즘의 하나로 인간의 신경망을 본딴 인 공 신경망에서 발전된 모델링 기법을 의미한다. 인공 신경망은 다층 계층 구조로 구성될 수 있다. 인공 신경망(Artifical Neural Network; ANN)은 입력 층, 출력 층, 그리고 상기 입력 층과 출력 층 사이에 적 어도 하나 이상의 중간 층 (또는 은닉 층, Hidden layer)(예를 들어 커널(Kernel))을 포함하는 계층 구조로 구 성될 수 있다. 딥러닝 알고리즘은, 이와 같은 다중 계층 구조에 기반하여, 층간 활성화 함수(Activationfunction)의 가중치를 최적화(Optimization)하는 학습을 통해 결과적으로 신뢰성 높은 결과를 도출할 수 있다. 본원의 일 실시예에 의한 영상 처리 방법은 차량의 주변을 촬영한 이미지 정보를 기초로, 객체를 인식하는 객체 인식 모델을 학습시키기 위한 방법일 수 있다. 여기에서 객체는 예를 들어, 상기 이미지 정보에 포함된 오 브젝트에 관한 것으로서, 예를 들어, 보행자 및/또는 차량 및/또는 사이클리스트 등을 포함할 수 있다. 다만, 객체의 유형에 제한되는 것은 아니다. 본원의 일 실시예에 의한 영상 처리 방법에 적용 가능한 딥러닝 알고리즘은 예를 들어, 합성곱 신경망 (Convolutional Neural Network; CNN)을 포함할 수 있다. 다만, 이에 한정되는 것은 아니다. 실시예에 따라 다 른 딥러닝 알고리즘이 적용될 수 있음을 이해할 수 있다. 합성곱 신경망(Convolutional Neural Network; CNN)은 기존의 데이터에서 지식을 추출하여 학습 과정이 수행되 는 기법과 달리, 데이터의 특징을 추출하여 특징들의 패턴을 파악하는 구조를 갖는 것을 특징으로 한다. 상기 합성곱 신경망(Convolutional Neural Network; CNN)은 콘볼루션(Convolution) 과정과 풀링(Pooling) 과정을 통 해 수행될 수 있다. 다시 말해, 상기 합성곱 신경망(Convolutional Neural Network; CNN)은 콘볼루션 층과 풀 링 층이 복합적으로 구성된 알고리즘을 포함할 수 있다. 여기서, 콘볼루션 층에서는 데이터의 특징을 추출하는 과정(에를 들어, 합성곱 과정(콘볼루션 과정))이 수행된다. 상기 콘볼루션 과정은 데이터에 각 성분의 인접 성 분들을 조사해 특징을 파악하고 파악한 특징을 한장으로 도출하는 과정으로써, 하나의 압축 과정으로써 파라미 터의 개수를 효과적으로 줄일 수 있다. 풀링 층에서는 콘볼루션 과정을 거친 레이어의 사이즈를 줄여주는 과정 (예를 들어,, 풀링 과정)이 수행된다. 상기 풀링 과정은 데이터의 사이즈를 줄이고 노이즈를 상쇄시키고 미세한 부분에서 일관적인 특징을 제공할 수 있다. 일 예로, 상기 합성곱 신경망(Convolutional Neural Network; CN N)은 정보 추출, 문장 분류, 얼굴 인식 등 여러 분야에 활용될 수 있다. 한편, 합성곱 신경망(Convolutional Neural Network; CNN)은 기공지된 기술이므로, 자세한 설명은 이하 생략한다. 도 2는 일 실시예에 의한 영상 처리 방법을 설명하기 위한 순서도이다. 도 2를 참조하면, 본원의 일 실시예에 의한 영상 처리 방법은, 객체 인식 단계(S100), 오인식 데이터 생성 단계 (S200), 취약 패턴 생성 단계(S300), 취약 커널 선별 단계(S400), 취약 데이터베이스 생성 단계(S500) 및 취약 커널 학습 단계(S600)를 포함할 수 있다. 객체 인식 단계(S100)에서 영상 처리 장치는 이미지 센서가 획득한 이미지 정보를 객체 인식 모델에 입력하여 상기 이미지 정보에 포함된 객체의 위치 및 종류를 포함하는 인식 정보를 출력할 수 있다. 여기에서 객체 인식 모델은 이미지 정보를 입력받아 상기 이미지 정보에 포함된 객체의 위치와 종류를 인식하여 객체의 위치 및 종류를 포함하는 바운딩 박스(Bounding box)를 포함하는 인식 정보를 출력할 수 있도록 훈련된 인공지능 모델일 수 있다. 보다 구체적으로, 객체 인식 모델은 예를 들어, 합성곱 신경망(Convolutional Neural Network; CNN) 알고리즘을 통해 학습된 모델일 수 있다. 즉, 객체 인식 모델은 이미지 정보를 입력받아, 이미지 정보 내의 객체의 위치와 객체의 종류 등을 포함하는 정 보를 2차원 바운딩 박스(Bounding box)로 출력하게 되는데, 예시적으로, 상기 객체의 위치와 정보를 Semantic Segmentation, 원기둥 등의 다른 형태로 인식하는 알고리즘이 적용되어, 인식 형태가 변경될 수 있다. 즉, 출력 되는 객체의 위치와 종류를 포함하는 인식 정보의 형태에 제한되는 것은 아니며, 보다 상세하게는 종래에 공지 된 객체 인식 모델 및/또는 향후 개발될 객체 인식 모델이 적용될 수 있음을 이해할 수 있다. 한편, 객체 인식 단계(S100)에서, 영상 처리 장치는 이미지 센서가 획득한 이미지 정보가 아닌, 입력 부를 통해 입력된 이미지 정보를 객체 인식 모델에 입력하여, 상기 이미지 정보에 포함된 객체의 위치 및 종류를 포함하는 인식 정보를 출력할 수 있다. 즉, 본원의 실시예에 따라서, 영상 처리 장치는 이미지 센 서를 포함하지 아니하고, 입력부 및 제어부만을 포함할 수도 있다. 다만, 이에 한정되는 것은 아니다. 도 3은 일 실시예에 의한 영상 처리 방법의 객체 인식 단계를 설명하기 위한 도면이다. 도 3을 참조하면, 객체 인식 단계(S100)에서, 영상 처리 장치는 이미지 센서가 획득한 이미지 정보 (RI1, RI2, 쪋)를 객체 인식 모델(DL)에 입력하여 객체의 종류 및 위치를 포함하는 인식 정보(DT1, DT2, 쪋)를 출력할 수 있다. 즉, 객체 인식 모델(DL)은 RAW 상태의 이미지 정보로 입력되고, 바운딩 박스 형태를 포함하는 인식 정보(DT1, DT2 쪋)를 출력할 수 있다. 이에 따라, 영상 처리 장치는 이미지 센서가 획득한 이미 지 정보(RI1, RI2, 쪋)를 처리한 것에 기초하여, 상기 이미지 정보(RI1, RI2 쪋)에 포함된 객체를 식별할 수 있다. 또한, 객체 인식 단계(S100)에서 영상 처리 장치는, 이미지 센서가 획득한 이미지 정보(RI1, RI2 쪋) 및 상기 객체 인식 모델을 통해 출력된 인식 정보(DT1, DT2 쪋)를 메모리로 전달할 수 있다. 이에 따라서, 메모리는 이미지 센서가 획득한 로우 데이터(Raw Data)에 해당하는 이미지 정보(RI1, RI2 쪋) 및 객 체 인식 모델(DL)이 출력한 인식 정보(DT1, DT2 쪋)를 무선 및/또는 유선으로 수신하여 저장할 수 있다. 한편, 메모리는 이미지 정보(RI1, RI2 쪋) 및 이에 대응되는 인식 정보(DT1, DT2 쪋)를 합성하여 저장할 수 있다. 즉, 제1 이미지 정보(RI1) 및 이에 대응되는 객체 인식 모델(DL)의 출력 제1 인식 정보(DT1)를 하나의 이미지로 합성함으로써, 객체 인식 모델(DL)이 인식한 객체를 함께 표시되도록 할 수 있다. 도 4는 일 실시예에 의한 영상 처리 방법의 오인식 데이터 생성 단계를 설명하기 위한 도면이다. 도 4를 참조하면, 오인식 데이터 생성 단꼐(S200)에서, 영상 처리 장치는 객체 인식 단계(S100)에서 객체 인식 모델(DL)의 출력한 인식 정보(DT) 및 그라운드 트루쓰(Ground Truth)를 기초로 오인식 데이터(WI)를 생성 할 수 있다. 보다 구체적으로, 오인식 데이터 생성 단계(S200)에서, 영상 처리 장치는 객체 인식 단계(S100)에서 생성 된 이미지 정보(RI) 및 인식 정보(DT)를 합성한 이미지와 입력부에서 수신한 그라운드 트루쓰(Ground Truth)(GT1, GT2 쪋)를 비교하여 객체 인식 모델의 오인식을 판별할 수 있다. 예시적으로, 입력부는 사용 자로부터 딥러닝 모델을 최초 훈련할 때 사용한 라벨링 툴(Labeling Tool)을 이용하여 이미지 정보(RI)에 대응 되는 인식 정보(DT)를 포함하는 그라운드 트루쓰(Ground Truth)를 획득할 수 있다. 이에 따라서, 오인식 데이터 생성 단계(S200)에서 영상 처리 장치는 입력부를 통해 획득한 그라운드 트루쓰(GT), 객체 인식 단계(S100)에서 이미지 센서가 획득한 이미지 정보(RI) 및 객체 인식 모델(DL)이 상기 이미지 정보(RI)를 입력으로 출력한 인식 정보(DT)를 기초로 오인식 데이터(Corner case)(WI)를 분류할 수 있다. 보다 상세하게, 도 4에 도시된 바에 따르면, 제2 이미지 정보(RI2) 및 제2 인식 정보(DT2)를 참조하면, 객체 인 식 단계(S100)에서 영상 처리 장치는 장애물(경고판)을 보행자로 인식한 것을 이해할 수 있다. 다만, 그라 운드 트루쓰(GT2)를 참조하면, 경고판(장애물)에 대한 라벨링 데이터를 포함하지 않고, 두명의 보행자에 대한 라벨링 데이터를 포함하고 있다. 그라운드 트루쓰(GT)와 이미지 정보(RI)에 대응되는 인식 정보(DT) 간의 비교 에 따라서, 영상 처리 장치는 오인식 데이터(Corner case(WI))를 분류(생성)할 수 있다. 즉, 영상 처리 장치는 객체 인식 모델(DL)이 출력한 인식 정보(DT)에서 객체의 위치 및/또는 객체의 종류 중 적어도 하나가 그라운드 트루쓰(GT)와 상이한 경우, 해당하는 이미지 정보(RI)를 오인식 데이터(WI)로 분류 할 수 있다. 한편, 영상 처리 장치가 오인식 데이터(WI)로 분류하는 것은 기학습된 오인식 데이터 분류 모델 및/또는 향후 개발될 오인식 데이터 분류 모델이 적용될 수 있음을 이해할 수 있다. 예시적으로, 영상 처리 장치는 객체 인식 모델(DL)이 출력한 인식 정보(DT), 이미지 정보(RI) 및 그라운드 트루쓰(GT)를 입력으로 오인식 데이 터(WI)를 출력하도록 miOU 알고리즘이 적용될 수 있다. 다만, 이에 한정되는 것은 아니고, 오인식 데이터 분류 모델은, 오인식 데이터(WI)를 출력하도록 적합한 알고리즘이 적용될 수 있다. 이에 따라, 오인식 데이터 생성 단계(S200)에서, 영상 처리 장치는 객체 인식 모델(DL)이 출력한 인식 정 보(DT)와 그라운드 트루쓰(Ground Truth)가 상이한 오인식 데이터(WI)를 생성할 수 있다. 즉, 여기에서 오인식 데이터(WI)는, 객체 인식 모델(DL)이 인식 정보(DT)를 그라운드 트루쓰(Ground Truth)와 상이하게 출력하는 경 우의 입력 이미지 정보(RI)를 의미할 수 있다. 도 5는 일 실시예에 의한 영상 처리 방법의 취약 패턴 생성 단계를 설명하기 위한 도면이다. 도 5를 참조하며, 취약 패턴 생성 단계(S300)에서, 영상 처리 장치는 오인식 데이터(WI)를 처리한 것에 기 초하여 객체 인식 모델(DL)의 취약 패턴맵을 생성할 수 있다. 여기에서 취약 패턴맵이란, 오인식 데이터(WI)에 대한 객체 인식 모델(DL)이 출력하는 인식 정보(DT)가 그라운드 트루쓰(GT)와 상이한 경우가 발생하는 이미지 정보의 적어도 일부분을 의미할 수 있다. 다만, 이에 한정되는 것은 아니다. 보다 구체적으로, 취약 패턴 생성 단계(S300)는, 특징점 기여도 추출 단계(S310) 및 입출력 민감도 추출 단계 (S320)를 포함할 수 있다. 이에 따라서, 취약 패턴 생성 단계(S300)에서, 영상 처리 장치는 오인식 데이터(WI)의 특징점 기여도가 높은 영역의 제1 취약 패턴(WP1) 및 상기 오인식 데이터(WI)의 입출력 민감도가 높은 영역의 제2 취약 패턴(WP2)을 산출하고, 상기 제1 취약 패턴(WP1) 및 제2 취약 패턴(WP2)을 처리한 것을 기초로, 중첩되는 영역의 제3 취약 패턴(WP)을 생성할 수 있다. 즉, 취약 패턴(WP)은 오인식 데이터(WI)의 높은 특징점 기여도 또는 높은 입출력 민감도 중 적어도 하나를 기초로 생성된 것일 수 있다. 이에 따라, 영상 처리 장치는 취약 패턴(WP)의 스케일링(Scaling)을 통해 여러 스케일의 취약 패턴(WP)을 채널 방향으로 조합한 취약 패턴맵(WM)을 생성할 수 있다. 다만, 이에 한정되는 것은 아니다. 다른 실시예로, 취약 패턴 생성 단계(S300)에서, 영상 처리 장치는, 특징점 기여도 추출 단계(S310)만을 기초로 취약 패턴맵(WM)을 생성할 수 있으며, 입출력 기여도 추출 단계(S320)만을 기초로 취약 패턴맵(WM)을 생 성할 수 있음을 이해할 수 있다. 또한, 상술한 바와 같이, 특징점 기여도 추출 단계(S310) 및 입출력 기여도 추 출 단계(S320)를 모두 거쳐 생성된 제1 취약 패턴(WP1) 및 제2 취약 패턴(WP2)의 중첩되는 영역을 기초로 합성 된 취약 패턴(WP)을 생성하여 취약 패턴맵(WM)을 생성할 수 있음을 이해할 수 있다. 한편, 이하에서는, 설명의 편의상 오인식 데이터(WI)를 하나의 이미지 정보(RI)로 취급하여 설명하도록 한다. 다만, 이에 한정되는 것은 아니고, 오인식 데이터(WI)는 오인식 데이터 생성 단계(S200)에서 생성된 적어도 두 개의 이미지 정보를 포함할 수 있으며, 상기 적어도 두개의 이미지 정보 각각에 대하여 취약 패턴 생성 단계 (S300)를 수행할 수 있음을 이해할 수 있다. 특징점 기여도 추출 단계(S310)에서, 영상 처리 장치는 오인식 데이터(WI)를 처리한 것을 기초로 상기 오 인식 데이터(WI)에 포함된 이미지 정보의 객체 인식 모델(DL) 내부 특징점 기여도를 계산함으로써, 상기 오인식 데이터(WI)의 특징점 기여도를 추출할 수 있다. 보다 구체적으로, 특징점 기여도 추출 단계(S310)에서, 영상 처리 장치는, 오인식 데이터(WI)를 입력하여, 객체 인식 모델(DL)의 합성곱 레이어(Convolution Layer)가 생성하는 특징맵(Feature mapt)의 활성화 함수 (Activation Function)를 순전파(Forward propagation)로 계산할 수 있다. 이후, 해당 레이어(Layer)에 대하여 역전파(Back Propagation)를 계산함으로써, 경사도(Gradient)를 산출할 수 있다. 이에 따라서, 영상 처리 장치는 상기 산출된 경사도(Gradient)와 활성화 함수(Activation Funtion)를 곱 연산 후 평균을 구하여 특징점의 각 위치의 출력에 대한 기여도를 산출할 수 있다. 보다 구체적으로, 하기 식 1 을 기초로 특징점 기여도 추출 단계(S310)에서, 영상 처리 장치는 입력된 오인식 데이터(WI)의 각 픽셀 위 치에 해당하는 특징점 기여도를 도출할 수 있다. [식 1]"}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기에서, L(i,j)는, 픽셀 좌표(i,j)에 해당하는 특징점 기여도를 의미하며, 는, 활성화 함수(Activation Function)를 의미하고, Z는 오인식 데이터(WI)의 픽셀 개수를 의미하며, 는 출력 score 값을 의미하며, ReLU는 relu 함수를 의미할 수 있다. 이에 따라서, 특징점 기여도 추출 단계(S310)에서, 영상 처리 장치는 오인식 데이터(WI)에 각 픽셀에 대응 되는 특징점 기여도를 추출할 수 있다. 여기에서, 특징점 기여도가 높은 좌표는, 오인식에 기여를 많이하고 있 는 좌표로 해석될 수 있음을 이해할 수 있다. 도 5를 참조하면, 특징점 기여도 추출 단계(S310)에서 영상 처리 장치는 오인식 데이터(WI)를 입력으로, 오인식 데이터(WI)의 좌표에 대응되는 특징점 기여도 맵을 생성할 수 있다. 이에 따라서, 영상 처리 장치 는 상기 특징점 기여도 맵을 기초로, 미리 정해진 값보다 높은 특징점 기여도를 갖는 좌표를 식별할 수 있다. 이 경우, 영상 처리 장치는 상기 특징점 기여도가 높은 좌표들을 기초로 제1 취약 패턴(WP1)을 산출할 수 있다. 여기에서, 미리 정해진 값은, 실험적 및/또는 경험적으로 설정된 값 및/또는 사용자가 원하는 제1 취약 패턴(WP1)의 넓이에 따라서 설정될 수 있음을 이해할 수 있다. 보다 구체적으로, 보다 넓은 취약 패턴의 넓이를 원하는 경우, 사용자는 미리 정해진 값을 설정된 값보다 낮게 설정할 수 있다. 다만, 이에 한정되는 것은 아니 다. 한편, 특징점 기여도 추출 단계(S310)에서, 영상 처리 장치는 상술한 제1 취약 패턴(WP1)을 산출하는 알고 리즘이 적용되는 것에 한정되는 것은 아니다. 즉, 적용되는 기술에 한정되는 것은 아니고, 객체 인식 모델(DL) 의 입출력 관계 또는 특징맵(Feature map)을 해석할 수 있는 종래의 개발된 기술(예를 들어, GRAD-CAM++, SHAP, SCORECAM, 쪋)이 적용될 수 있으며, 향후 개발될 기술이 적용될 수 있음을 이해할 수 있다. 한편, 입출력 민감도 추출 단계(S320)에서, 영상 처리 장치는 오인식 데이터(WI)를 처리한 것을 기초로 상 기 오인식 데이터(WI)의 입출력 민감도를 산출할 수 있다. 보다 구체적으로, 입출력 민감도 추출 단계S에서, 영상 처리 장치는, 오인식 데이터(WI)를 입력하여, 상기 입력된 오인식 데이터(WI)를 슈퍼픽셀(Superpixel)로 나눌 수 있다. 여기에서 슈퍼픽셀(superpixel)이란, 상기 오인식 데이터(WI)에 포함된 각각의 픽셀들 중 지각적으로(Perceptually) 의미있는 픽셀들을 모아 분류된 적어도 하나의 픽셀들의 그룹을 의미할 수 있다. 여기에서, 영상 처리 장치는 기존의 개발된 알고리즘 및 향후 개발될 알고리즘이 적용되어 오인식 데이터 (WI)를 슈퍼픽셀(Superpixel)로 그룹화할 수 있다. 예시적으로, Felzenwalb & Huttenlocher 알고리즘이 적용되 어, 영상 처리 장치는 오인식 데이터(WI)를 적어도 하나의 슈퍼픽셀(Superpixel)로 분류할 수 있다. 이에 따라, 입출력 민감도 추출 단계(S320)에서, 영상 처리 장치는 분류된 적어도 하나의 슈퍼픽셀 (Superpixel)을 입력으로, 객체 인식 모델의 네트워크에 순전파(Forward Propagation)로 계산하여 결과를 출력 한 뒤, 기존 결과 대비 변화량을 계산할 수 있다. 즉, 복수의 슈퍼픽셀(Superpixel)로 나뉘어진 경우, 각각의 슈퍼픽셀(Superpixel)에 대응되는 기존 결과 대비 변화량을 계산할 수 있다. 이에 따라, 입출력 민감도 추출 단계(S320)에서, 영상 처리 장치는 각각의 슈퍼픽셀(Superpixel)에 대응되 는 변화량을 입출력 민감도로 식별할 수 있다. 보다 구체적으로, 영상 처리 장치는 상기 각각의 슈퍼픽셀 (Superpixel)에 대응되는 변화량이 미리 정해진 값보다 높은 슈퍼픽셀(Superpixel)에 대응되는 영역을 제2 취약 패턴(WP2)로 식별할 수 있다. 다만, 이에 한정되는 것은 아니고, 다른 실시예로, 영상 처리 장치는, 상기 슈퍼픽셀(Superpixel)에 대응되는 변화량들 중 가장 높은 변화량을 갖는 적어도 두 개의 슈퍼픽셀(Superpixel) 을 식별하고, 상기 슈퍼픽셀(Superpixel)에 대응되는 영역들을 제2 취약 패턴(WP2)로 식별할 수 있다. 한편, 특징점 기여도 추출 단계(S320)에서, 영상 처리 장치는 상술한 제2 취약 패턴(WP2)을 산출하는 알고 리즘이 적용되는 것에 한정되는 것은 아니다. 즉, 적용되는 기술에 한정되는 것은 아니고, 객체 인식 모델(DL) 의 입출력 관계 또는 특징맵(Feature map)을 해석할 수 있는 종래의 개발된 기술(예를 들어, GRAD-CAM++, SHAP, SCORECAM, 쪋)이 적용될 수 있으며, 향후 개발될 기술이 적용될 수 있음을 이해할 수 있다. 정리하면, 취약 패턴 생성 단계(S300)에서, 영상 처리 장치는 오인식 데이터(WI)를 입력으로, 생성된 특징 점 기여도 맵을 기초로, 미리 정해진 값보다 높은 특징점 기여도를 식별하고, 상기 높은 특징점 기여도를 기초 로 제1 취약 패턴(WP1)을 식별할 수 있다. 이 경우, 영상 처리 장치는 미리 설정된 넓이에 따라, 상기 제1 취약 패턴(WP1)을 스케일링(Scaling)하여 취약 패턴맵(WM)을 생성할 수 있다. 또한, 취약 패턴 생성 단계(S300)에서, 영상 처리 장치는, 오인식 데이터(WI)를 입력으로, 상기 오인식 데 이터(WI)에 포함된 픽셀 좌표를 슈퍼픽셀(Superpixel)로 분류하되, 상기 슈퍼픽셀(Superpixel)을 입력으로, 순 전파(Forward propagation)계산하여 기존 결과 대비 변화량을 계산하여, 상기 변화량이 높은 순서대로 적어도 하나의 슈퍼픽셀(Superpixel)을 식별하고, 상기 식별된 슈퍼픽셀(Superpixel)의 영역을 제2 취약 패턴(WP2)로 식별할 수 있다. 이 경우, 영상 처리 장치는 미리 설정된 넓이에 따라, 상기 제2 취약 패턴(WP2)을 스케일 링(Scaling)하여 취약 패턴맵(WM)을 생성할 수 있다. 한편, 영상 처리 장치는 특징점 기여도 추출 단계(S310) 및 입출력 민감도 추출 단계(S320)를 거쳐 획득한 제1 취약 패턴(WP1) 및 제2 취약 패턴(WP2)을 합성하여, 취약 패턴(WP)을 생성할 수 있다. 보다 상세하게, 영상 처리 장치는 취약 패턴 생성 단계(S300)에서, 제1 취약 패턴(WP1) 및 제2 취약 패턴(WP2) 중 중첩되는 영 역에 대한 취약 패턴(WP)을 생성하고 상기 취약 패턴(WP)을 기초로, 미리 설정된 넓이에 따라, 스케일링 (Scaling)하여 취약 패턴맵(WM)을 생성할 수 있다. 다만, 이에 한정되는 것은 아니다. 즉, 취약 패턴 생성 단계(S300)에서, 영상 처리 장치는 오인식 데이터 생성 단계(S200)에서 획득한 오인식 데이터(WI)를 입력으로 취약 패턴맵(WM)을 생성할 수 있다. 이에 따라 생성된 취약 패턴맵(WM)은, 현재 모델이 가진 문제점을 사용자가 인식할 수 있는 방식으로 제공될 수 있다. 도 6은 일 실시예에 의한 영상 처리 방법의 취약 커널 선별 단계를 설명하기 위한 순서도이다. 도 6을 참조하면, 취약 커널 선별 단계(S400)는 취약 패턴맵(WM) 및 객체 인식 모델(DL)을 기초로 객체 인식 모 델(DL)의 제i 커널의 만감도 산출 단계(S410), 상기 산출된 민감도를 스케일링하는 단계(S420), 상기 스케일링 된 민감도가 미리 정해진 값보다 큰지 판별하는 단계(S430), 상기 미리 스케일링된 민감도가 미리 정해진 값보 다 큰 것에 응답하여, 상기 제i 커널의 경사도(Gradient)를 활성화하는 단계(S440), 상기 미리 스케일링된 민감 도가 미리 정해진 값보다 작은 것에 응답하여, 상기 제i 커널의 경사도(Gradient)를 비활성화하는 단계(S450) 및 상기 활성화 또는 비활성화 단계(S440, S450) 이후 제i+1 커널에 대하여 민감도 산출하는 단계(S410)를 반복 수행하는 단계(S460)를 포함할 수 있다. 객체 인식 모델(DL)의 합성곱 레이어(Convolution Layer)의 각 커널(Kernel 또는 Filter)들은, 입력된 이미지 정보 상에 특정 패턴에 활성화(Activation)되어 상기 이미지 정보의 사물을 인식하게 된다. 즉, 특정한 패턴에 대하여 활성화(Activation)되는 커널들이 존재하므로, 취약한 커널들에 대하여만 학습을 수행하는 경우, 기존의 잘 학습된 커널들의 정보를 보존하는 현저한 효과를 제공할 수 있다. 또한, 학습하는 커널들의 개수가 줄어들어, 학습 파라미터의 개수가 줄어들고, 이에 따라 학습에 요하는 비용(예를 들어, 컴퓨팅 파워(Computing power), 시간)이 감소할 수 있다. 또한, 약점을 더욱 약화시킬 수 있는 기존의 학습 알고리즘의 문제점에 대항 하여, 오인식 데이터(Corner case)(WI)를 보다 현저히 줄일 수 있는 효과를 제공할 수 있다. 민감도 산출 단계(S410)에서, 영상 처리 장치는 취약 패턴 생성 단계(S300)에서 획득한 취약 패턴맵(WM)을 기초로 제i 커널의 민감도를 산출할 수 있다. 보다 구체적으로, 민감도 산출 단계(S410)에서, 영상 처리 장치 는 하기 식 2를 기초로 제i 커널의 민감도를 산출할 수 있다. [식 2]"}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기에서, 는, 제i 커널의 민감도를 의미하며, Nt는, 취약 패턴맵(WM)의 개수를 의미하고, abs는 절대값 연 산자를 의미하되, 는 제i 커널을 의미하고, 는, 제j 취약 패턴 맵을 의미할 수 있다. 이에 따라, 민감도 산출 단계(S410)에서, 영상 처리 장치는 취약 패턴 생성 단계(S300)에서 생성된 취약 패턴맵(WM) 및 객체 인식 모델(DL)의 제i 커널을 입력하여, 제i 커널의 민감도를 산출할 수 있다. 스케일링 하는 단계(S420)에서, 영상 처리 장치는 상기 산출된 제i 커널의 민감도를 기초로 스케일링 (Scaling)할 수 있다. 예시적으로, 영상 처리 장치는 제i 커널의 민감도를 0 내지 1스케일링(Scaling)할 수 있다. 즉, 영상 처리 장치는 최대 민감도를 1로, 최저 민감도를 0으로 스케일링(Scaling)하도록 함으로 써, 스케일링된 민감도를 기초로 취약 커널을 식별할 수 있다. 이에 따라, 판별하는 단계(S430)에서, 영상 처리 장치는 상기 스케일링(Scaling)된 민감도를 기초로, 미리 정해진 값과 비교할 수 있다. 여기에서 미리 정해진 값은, 경험적 및/또는 실험적으로 설정된 값으로서, 미리 정해진 값이 보다 높은 경우에 있어서, 비용(예를 들어, 컴퓨팅 파워(Computing power), 시간)이 감소할 수 있 는 효과를 제공하거나, 낮은 경우에 있어서, 모델 학습의 신뢰도가 높아지는 효과를 제공할 수 있다. 예시적으 로, 미리 정해진 값은 0.5로 설정될 수 있다. 경사도를 활성화하는 단계(S440)에서, 영상 처리 장치는, 제i 커널의 민감도가 미리 정해진 값보다 큰 경 우에 응답하여, 훈련시 경사도(Gradient)를 활성화(Activation)시킬 수 있다. 또한, 경사도를 비활성화하는 단계(S450), 영상 처리 장치는 제i 커널의 민감도가 미리 정해진 값보다 작 은 경우에 응답하여, 훈련시 경사도(Gradient)를 비활성화할 수 있다. 즉, 경사도(Gradient)를 0으로 계산할 수 있다. 정리하면, 경사도를 활성화하는 단계 및 비활성화하는 단계(S440, S450)에서 영상 처리 장치는 하기 식 3 에 기초하여, 제i 커널에 대하여 경사도(Gradient)를 계산할 수 있다.[식 3]"}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기에서, 는 훈련중 파라미터 경사도(Gradient)를 의마하되, r은, 미리 정해진 값을 의미할 수 있으며,"}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "는, 제i 커널의 민감도를 의미할 수 있다. 이에 따라서, 취약 커널 선별 단계(S400)에서, 영상 처리 장치는 제i 커널에 대하여 경사도(Gradient)를 다르게 적용(활성화 또는 비활성화)함으로써, 추후 경사도(Gradient)가 적용된 제i 커널에 대하여만 모델 학습 을 수행할 수 있다. 한편, 객체 인식 모델(DL)의 커널은 복수개 있으므로, 반복 수행하는 단계(S460)에서, 영상 처리 장치는, 제i 커널에 대하여 민감도를 산출하고, 상기 산출된 민감도를 기초로 상기 제i 커널의 학습 경사도의 활성화 또 는 비활성화를 결정(경사도를 계산)한 후, 제i+1 커널에 대하여 민감도를 산출하는 단계(S410)부터 진행함으로 써, 객체 인식 모델(DL)에 포함된 모든 커널에 대하여 취약 커널만을 선별할 수 있다. 즉, 영상 처리 장치(10 0)는, 객체 인식 모델(DL)의 커널들 중, 경사도(Gradient)가 활성화(Activation)된 커널들에 대하여 학습을 진 행하며, 비활성화된 커널들에 대하여는 학습을 진행하지 않게 된다. 다만, 이에 한정되는 것은 아니다. 도 7은 일 실시예에 의한 영상 처리 방법의 취약 데이터베이스 생성 단계를 설명하기 위한 순서도이다. 도 7을 참조하면, 취약 데이터베이스 생성 단계(S500)는, 취약 패턴맵(WM) 및 기저장된 제i 이미지 정보의 합성 곱(Convolution) 계산하는 단계(S510), 상기 취약 패턴맵(WM) 및 상기 제i 이미지 정보의 유사도 맵 생성 단계 (S520), 상기 유사도 맵의 최대값을 식별하는 단계(S530), 상기 식별된 최대값이 미리 정해진 값보다 큰지 판별 하는 단계(S540), 상기 식별된 최대값이 미리 정해진 값보다 큰 것에 응답하여, 상기 제i 이미지 정보를 취약 데이터베이스로 분류하는 단계(S550) 및 상기 식별된 최대값이 미리 정해진 값보다 작은 것에 응답하여, 기저장 된 제i+1 이미지 정보 및 취약 패턴맵(WM)의 합성곱(Convolution) 계산하는 단계(S510)를 재수행하는 단계 (S560)를 포함할 수 있다. 즉, 취약 데이터베이스 생성 단계(S500)에서, 영상 처리 장치는, 취약 패턴 생성 단계(S300)에서 생성된 취약 패턴맵(WM) 및 기저장된 이미지 정보들을 기초로, 기저장된 이미지 정보들에 포함된 객체 인식 모델(DL)에 대하여 취약한 이미지 정보들을 취약 데이터베이스로 분류(선별)할 수 있다. 즉, 영상 처리 장치는 기저장 된 적어도 하나의 이미지 정보들 중 객체 인식 모델(DL)에 취약한 이미지 정보들을 분류함으로써, 객체 인식 모 델(DL)을 학습시키기 위한 데이터 세트를 생성하는 것일 수 있다. 다만, 이에 한정되는 것은 아니다. 한편, 기저장된 이미지 정보는 예를 들어, 이미지 센서가 획득한 이미지 정보 및/또는 기저장된 이미지 정 보를 포함할 수 있다. 즉, 종래에 저장된 이미지 정보가 활용될 수 있음을 이해할 수 있다. 예를 들어, 기저장 된 이미지 정보는 적어도 하나의 이미지 정보를 포함하여, 복수개의 이미지 정보를 포함할 수 있다. 보다 구체적으로, 합성곱(Convolution) 계산하는 단계(S510)에서, 영상 처리 장치는 기저장된 이미지 정보 는 제i 이미지 정보 및 취약 패턴 생성 단계(S300)에서 생성된 취약 패턴맵(WM)의 합성곱 연산을 수행할 수 있 다. 이에 따라서, 유사도 맵 생성 단계(S520)에서, 영상 처리 장치는, 상기 합성곱(Convolution) 계산하는 단 계(S510)에서 산출된 합성곱 결과의 채널방향 평균을 연산함으로써, 상기 취약 패턴맵 및 제i 이미지 정보의 유 사도 맵을 생성할 수 있다. 즉, 절대값 합성곱은 코사인 유사도를 뜻하며, 내적은 유사한 패턴에 대하여 높은 값을 가지는 성질이 있으므로, 영상 처리 장치가 생성한 유사도 맵은, 기저장된 이미지 정보와 취약 패턴 맵(WM) 간의 유사 패턴이 있는 경우, 높은 값을 가지게 된다. 따라서, 유사도 맵은 기저장된 적어도 하나의 이 미지 정보 중 취약 패턴맵(WM)과 유사한 패턴을 포함하고 있는 정도를 정량적으로 확인할 수 있다. 보다 구체적으로, 영상 처리 장치는 하기 식 4를 기초로, 취약 패턴맵(WM) 및 기저장된 제i 이미지 정보의 유사도 맵을 생성할 수 있다.[식 4]"}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기에서, 는, 제i 이미지 정보와 취약 패턴맵의 유사도 맵을 의미하며, 는, 취약 패턴맵(M W)의 좌표(m,n) 값, 는, 이미지 입력을 의미하고, 은, 코사인 유사도를 의미하며, Mean은, 평균 연산자를 의미하되, C는 RGB 채널을 의미하고, k1은, 취약 패턴맵(WM)의 크기, k2는, 이미지의 크기를 의 미할 수 있다. 즉, 영상 처리 장치는 상기 식 4를 기초로, 기저장된 제i 이미지 정보 및 취약 패턴맵(WM)을 기초로, 합성 곱 계산 단계(S510) 및 유사도 맵 생성 단계(S520)를 수행할 수 있다. 한편, 유사도 맵(SM)의 최대값을 식별하는 단계(S530)에서, 영상 처리 장치는, 상기 유사도 맵 생성 단계 (S520)에서 생성된 유사도 맵(SMi)에서의 최대값을 식별할 수 있다. 이에 따라, 영상 처리 장치는 유사도 맵(SMi)의 최대값이 미리 정해진 값보다 큰지 여부를 판별할 수 있다. 즉, 영상 처리 장치는 유사도 맵 생 성 단계(S520)에서 제i 이미지 정보를 입력으로 생성된 유사도 맵(SMi)의 각 좌표당 채널방향 평균값이 보다 구체적으로, 취약 데이터베이스 분류 단계에서(S550), 영상 처리 장치는 유사도 맵(SMi)의 최대값을 식별하는 단계(S530)에서 식별한 유사도 최대값이 미리 정해진 값보다 큰 것에 응답하여, 상기 합성곱 계산 단 계 및 유사도 맵 생성 단계(S520)에서 이용한 제i 이미지 정보를 취약 데이터베이스로 분류(생성)할 수 있 다. 즉, 상술한 바와 같이, 유사도 맵의 최대값이 큰 경우, 제i 이미지 정보와 취약 패턴맵(WM) 간의 유사한 정 도가 높다는 것을 의미할 수 있으므로, 이는 높은 신뢰도를 가지고 취약 데이터에 해당한다는 것을 이해할 수 있다. 여기에서, 미리 정해진 값은, 예시적으로, 0.7이 적용될 수 있으나, 이에 한정되는 것은 아니다. 즉, 미리 정해 진 값은 실험적 및/또는 경험적으로 설정될 수 있다. 한편, 영상 처리 장치는, 미리 정해진 값이 커질수록 유사도 맵(SMi)과 이미지 정보간의 유사도가 높은 이미지 정보를 취약 데이터베이스로 분류하므로, 취약 데이터 베이스로 분류되는 이미지 정보가 감소하는 경향을 이해할 수 있다. 즉, 사용자는 취약 데이터베이스의 양적 개 수를 조절하기 위하여 실험적 및/또는 경험적으로 설정할 수 있다. 한편, 재수행하는 단계(S560)에서, 영상 처리 장치는, 유사도 맵(SMi)의 최대값을 식별하는 단계(S530)에 서 식별한 유사도 최대값이 미리 정해진 값보다 작은 것에 응답하여, 제i+1 이미지 정보에 대하여, 상기 합성곱 계산 단계(S510), 유사도 맵 생성 단계(S520), 최대값 식별 단계(S530), 및, 상기 식별된 최대값이 미리 정해진 값보다 큰지 판별하는 단계(S540)를 재수행할 수 있다. 이에 따라서, 영상 처리 장치는, 기저장된 적어도 하나의 이미지 정보 모두에 대하여, 취약 데이터베이스를 분류할 수 있다. 즉, 재수행하는 단계(S560)에서 영상 처리 장치는, 기저장된 이미지 정보의 개수와 i가 같아질 때까지 기 저장된 이미지 정보 각각에 대하여 합성곱 연산 및 유사도 맵을 생성함으로써, 기저장된 모든 이미지 정보를 분 류할 수 있다. 이에 따라서, 취약 데이터베이스 생성 단계(S500)에서, 영상 처리 장치는 기저장된 적어도 하나의 이미지 정보 및 취약 패턴맵(WM)을 기초로 취약 데이터베이스를 생성(분류)할 수 있다. 도 8은 일 실시예에 의한 영상 처리 방법의 취약 데이터베이스 생성 단계를 설명하기 위한 개념도이다. 도 8을 참조하면, 취약 데이터베이스 생성 단계(S500)에서, 영상 처리 장치는 기저장된 이미지 정보(I1, I2 쪋) 및 취약 패턴맵(WM)을 기초로 유사도 맵(SM1, SM2)을 생성할 수 있다. 보다 구체적으로, 취약 데이터베이스 생성 단계(S500)에 포함된 합성곱 계산 단계(S510)에서, 영상 처리 장치 는, 기저장된 제1 이미지 정보(I1) 및 취약 패턴맵(WM)의 합성곱(Convolution)을 계산할 수 있다. 이에 따라, 취약 데이터베이스 생성 단계(S500)에 포함된 유사도 맵 생성 단계(S520)에서, 영상 처리 장치(10 0)는, 상기 합성곱 계산 단계(S510)에서 수행한 결과의 채널 방향 평균을 계산함으로써, 유사도 맵(SM1)을 생성 할 수 있다. 보다 상세하게, 도면에 도시된 경우와 같이, 제1 이미지 정보(I1)는 취약 패턴맵(WM)과 유사한 패턴을 가지고 있지 않으므로, 영상 처리 장치가 합성곱 계산 단계(S510) 및 유사도 맵 생성 단계(S520)를 거쳐 출력하는 유사도 맵(SM1)은 전체적으로 작은 값을 가지도록 출력되는 것을 이해할 수 있다. 또한, 제2 이미지 정보(I2)는 취약 패턴맵(WM)과 유사한 패턴을 중앙에 포함하고 있으므로, 영상 처리 장치가 합성곱 계산 단계(S510) 및 유사도 맵 생성 단계(S520)를 거쳐 출력하는 유사도 맵(SM2)은 상기 제2 이미지 정보(I2)의 중앙 부분에 높 은 유사도 값을 가지도록 출력되는 것을 이해할 수 있다. 이에 따라서, 도 8을 참조하면, 취약 데이터베이스 생성 단계(S500)에서, 영상 처리 장치는 제1 이미지 정보(I1)를 기초로 생성된 유사도 맵(SM1)의 최대 값 및 제2 이미지 정보(I2)를 기초로 생성된 유사도 맵(SM2) 의 최대값을 식별하되, 상기 식별된 최대값이 미리 정해진 값보다 큰 것에 응답하여, 취약 데이터베이스로 생성 (분류)할 수 있다. 예시적으로, 제1 이미지 정보(I1)를 기초로 생성된 유사도 맵(SM1)의 최대값이 0.3이고, 제2 이미지 정보(I2)를 기초로 생성된 유사도 맵(SM2)의 최대값이 0.8인 경우, 미리 정해진 값이 0.8로 설정되면, 영상 처리 장치는 제2 이미지 정보(I2)를 취약 데이터베이스로 분류(생성)할 수 있다. 도 9는 일 실시예에 의한 영상 처리 방법의 취약 커널 학습 단계를 설명하기 위한 순서도이다. 도 9를 참조하면, 취약 커널 학습 단계(S600)에서, 영상 처리 장치는, 취약 커널 선별 단계(S400)에서 선 별(예를 들어, 경사도(Gradient)를 활성화 또는 비활성화)한 객체 인식 모델(DL)의 커널들을 집중적으로 취약 데이터베이스 생성 단계(S500)에서 획득한 취약 데이터베이스를 기초로 학습시킬 수 있다. 취약 커널 학습 단계(S600)는, 데이터베이스 무작위 분류 단계(S610), 취약 커널 학습 단계(S620), 성능도 산출 단계(S630), 상기 성능도 산출 단계(S630)에서 산출된 성능도가 미리 정해진 값보다 큰지 판별하는 단계(S640) 및 객체 인식 모델 업데이트 단계(S650)를 포함할 수 있다. 데이터베이스 무작위 분류 단계(S610)에서, 영상 처리 장치는, 취약 데이터베이스 생성 단계(S500)에서 획 득한 취약 데이터베이스를 미리 정해진 비율로 제1 취약 데이터베이스 및 제2 취약 데이터베이스로 무작위 분류 할 수 있다. 여기에서, 제1 취약 데이터베이스는, 취약 커널 선별 단게(S400)에서 선별된 취약 커널(Kernel)(또 는, 파라미터(Parameter))을 학습시키기 위한 데이터세트로 입력될 수 있는 이미지 정보 세트이며, 제2 취약 데 이터베이스는, 상기 제1 취약 데이터베이스를 입력으로 학습시킨 객체 인식 모델(DL)을 평가하기 위한 데이터세 트로 입력될 수 있는 이미지 정보 세트일 수 있다. 다만, 이에 한정되는 것은 아니다. 여기에서, 미리 정해진 비율은, 실험적 및/또는 경험적으로 설정될 수 있는 비율로서, 예시적으로, 9:1의 비율로 적용될 수 있다. 이후, 취약 커널 학습 단계(S620)에서, 영상 처리 장치는 상기 데이터베이스 무작위 분류 단계(S610)에서 분류한 제1 취약 데이터베이스를 기초로 취약 커널 선별 단계(S400)에서 선별된 취약 커널을 학습시킬 수 있다. 보다 구체적으로, 영상 처리 장치는, 예시적으로, 경사하강법을 통해 상기 제1 취약 데이터베이스를 기초 로, 취약 커널을 학습시킬 수 있다. 즉, 취약 커널 선별 단계(S400)에서 커널에 적용한 훈련 경사도(Gradient) 에 따라서, 경사도가 0(비활성)으로 계산된 커널은 학습이 진행되지 않으며, 경사도가 활성화(Activation)된 커 널은 학습이 진행되게 된다. 이에 따라서, 영상 처리 장치는 기존의 잘 학습된 커널(Kernel)의 정보를 보 존하며, 취약한 커널(Kernel)만을 선별적으로 학습하기 때문에 컴퓨팅 파워(Computing Power)가 감소하는 효과 를 제공할 수 있다. 다만, 이에 한정되는 것은 아니다. 다른 실시예로, 취약 커널 학습 단계(S620)에서, 영상 처리 장치는, 객체 인식 모델(DL)의 하단부 커널 (Kernel)에 대하여 훈련 경사도(Gradient)를 0(비활성)으로 계산하고, 상단부 커널(Kernel)에 대하여 훈련 경사 도(Gradient)를 활성화(Activation)함으로써, 객체 인식 모델(DL)의 상단부 커널(Kernel)에 대하여만 학습을 진 행할 수 있다. 이는, 객체 인식 모델(DL)의 하단부 커널(Kernel)이 상단부 커널(Kernel)과 비교하여 민감도가 높다는 가정하에 적용되는 것일 수 있다. 다만, 이에 한정되는 것은 아니다. 즉, 취약 커널 학습 단계(S620)에서, 영상 처리 장치는 취약 커널 선별 단계(S400)를 거쳐 선별된 취약 커 널만을 학습하는 것에 한정되는 것이 아니고, 다른 종래의 알고리즘 및/또는 향후 개발될 알고리즘에 따라 선별 된 커널에 대하여만 학습시킬 수 있다. 정리하면, 취약 커널 학습 단계(S620)는, 다른 방식의 커널 선별 단계 (미도시)를 거쳐 선별된 커널을 학습하는 단계일 수 있다. 한편, 성능도 산출 단계에서, 영상 처리 장치는, 상술한 취약 커널 학습 단계(S620)를 통해 학습된 객체 인식 모델(DL) 및 데이터베이스 무작위 분류 단계(S620)를 통해 분류된 제2 취약 데이터베이스를 기초로, 상기 학습된 객체 인식 모델(DL)의 성능도를 산출할 수 있다. 보다 구체적으로, 성능도 산출 단계(S630)에서, 영상 처리 장치는, 취약 커널 학습 단계(S620)를 통해 학 습된 객체 인식 모델(DL)에 제2 취약 데이터베이스를 입력으로 출력된 인식 정보(DT)에 대한 성능도를 산출할수 있다. 여기에서 성능도는 F1 Score가 적용될 수 있다. F1 Score는 일반적 기술이므로, 자세한 설명은 생략한 다. 이에 따라, 판별하는 단계(S640)에서, 영상 처리 장치는, 상기 성능도 산출 단계(S630)에서 산출된 성능도 가 미리 정해진 값보다 큰지 여부를 판단할 수 있다. 여기에서 미리 정해진 값은, 사용자가 원하는 신뢰도 및/ 또는 정확도를 위해 설정되는 경험적 및/또는 실험적 값일 수 있다. 보다 구체적으로, 객체 인식 모델 업데이트 단계(S650)에서, 영상 처리 장치는, 성능도 산출 단계에 서 산출된 성능도가 미리 정해진 값보다 큰 것에 응답하여, 취약 커널 학습 단계(S620)에서 학습된 객체 인식 모델로 기존의 객체 인식 모델을 업데이트할 수 있다. 한편, 영상 처리 장치는, 성능도 산출 단계에서 산출된 성능도가 미리 정해진 값보다 작은 것에 응답 하여, 제1 취약 데이터베이스를 기초로 취약 커널의 학습(S620)을 재수행할 수 있다. 즉, 취약 커널 학습 단계 (S600)에서, 영상 처리 장치는, 취약 커널 학습의 각 에폭(Epoch) 마다, 성능도 평가를 수행하고, 산출된 성능도가 사용자가 미리 설정한 값보다 크지 않은 경우, 학습을 재수행할 수 있다. 다만, 이에 한정되는 것은 아니다. 이에 따라서, 상술한 영상 처리 방법은, 객체 인식 모델의 오인식 및/또는 미인식 케이스를 특정하여 완화시킬 수 있는 효과를 제공할 수 있다. 본 발명에 적용 가능한 일 예로, 영상 처리 장치는 차량 시스템 내 자율 주행을 제어하는 자율 주행 제어 장치에 연결되어 상기 자율 주행 제어 장치가 이용하는 딥러닝 알고리즘을 설정 및/또는 선택하여 상기 자 율 주행 제어 장치로 제공할 수 있다. 본 발명에 따른 영상 처리 장치는 앞서 상술한 다양한 영상 처리 방법에 따라 동작할 수 있다. 또한, 본원의 일 실시예에 의한 차량은 상술한 영상 처리 장치를 포함할 수 있다. 이에 따라, 상술한 영상 처리 방법에서 설명한 동작은 차량에 의하여 수행될 수 있다. 전술한 차량의 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구성 요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야 에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 한편, 차량의 일부 구성요소는 소프트웨어 및/또는 Field Programmable Gate Array(FPGA) 및 주문형 반도 체(ASIC, Application Specific Integrated Circuit)와 같은 하드웨어 구성요소일 수 있다. 한편, 본원의 일 실시예에 의한 영상 처리 방법은, 상술한 바에 제한되는 것은 아니다. 본원의 일 실시예에 의한 영상 처리 방법은, 영상 처리 시스템(미도시)에 의하여 수행될 수 있다. 한편, 이하에 서 설명하는 본원의 일 실시예에 의한 영상 처리 시스템은, 영상 처리 방법에 대하여 설명했던 중복되는 내용과 차별되는 내용을 중점적으로 설명하도록 한다. 본원의 일 실시예에 의한 영상 처리 시스템은, 차량 및 영상 처리 장치를 포함할 수 있다. 즉, 차량 과 영상 처리 장치는 별도로 마련될 수 있다. 보다 구체적으로, 차량은, 이미지 센서, 통신부 및 제어부를 포함할 수 있다. 여기에서 제어부는 상기 이미 지 센서로부터 수신한 이미지 정보를 입력으로 상기 이미지 정보에 포함된 객체의 종류 및 위치를 출력하는 객 체 인식 모델을 저장하고, 상기 객체 인식 모델을 기초로 차량의 주변을 향하여 촬영되는 이미지 정보를 입 력으로, 상기 차량의 주변의 객체의 위치와 종류를 출력할 수 있다. 여기에서, 객체 인식 모델은, 기학습되 어, 제어부의 메모리에 저장된 인공지능 모델일 수 있다. 또한, 제어부는, 이미지 센서로부터 획득한 이미지 정보를 영상 처리 장치로 전송하도록 제어 신호를 출력 할 수 있다. 제어부는, 이미지 센서로부터 획득한 이미지 정보를 객체 인식 모델에 입력하여 출력한 인식 정보 를 함께 영상 처리 장치로 전송하도록 제어 신호를 출력할 수 있다. 한편, 영상 처리 장치는 제어부 및 통신부를 포함할 수 있다. 영상 처리 장치의 통신부는 차량의 통신부를 통해 전달받은 차량의 이미지 센서가 획득한 이미지 정보 및 차량의 제어부가 출력한 상기 이미지 정보에 포함된 객체의 인식 정보를 수신할 수 있다. 이에 따 라, 영상 처리 장치의 제어부는 상기 수신된 이미지 정보 및 객체 인식 정보를 저장할 수 있다. 또한, 영상 처리 장치는 상기 차량의 제어부에 저장된 객체 인식 모델과 동일한 모델을 메모리에 저장할 수 있 다. 한편, 영상 처리 장치는, 저장된 객체 인식 모델을 업데이트하도록 새로 학습된 객체 인식 모델을 포함하 는 업데이트 정보를 차량으로 전송하도록 통신부를 제어하는 신호를 생성할 수 있다. 도 10은 일 실시예에 의한 영상 처리 방법을 설명하기 위한 순서도이다. 보다 상세하게, 도 10은, 일 실시예에 의한 영상 처리 시스템이 수행하는 영상 처리 방법을 설명하기 위한 순서도이다. 영상 처리 시스템이 수행하는 영상 처리 방법은, 앞서 설명된 영상 처리 방법, 영상 처리 장치 및 이를 포함하 는 차량에 대한 설명과 동일하게 적용될 수 있다. 다만, 영상 처리 시스템이 수행하는 영상 처리 방법은, 각 단 계가 수행하는 주체가 다르게 적용될 수 있음을 이해할 수 있다. 도 10을 참조하면, 차량은, 이미지 정보를 획득할 수 있다(S710). 이에 따라, 차량은 상기 이미지 정보 를 영상 처리 장치로 전송할 수 있다. 또한, 영상 처리 장치는 그라운드 트루쓰(Ground Truth)를 입력할 수 있다(S720). 또한, 차량은, 객체 인식 모델에 상기 이미지 정보를 입력하여 상기 이미지 정보에 포함된 객체의 종류 및 위치를 포함하는 인식 정보를 출력할 수 있다(S730). 이에 따라, 차량은 상기 인식 정보를 영상 처리 장치 로 전송할 수 있다. 또한, 영상 처리 장치는 상기 차량으로부터 전송받은 인식 정보 및 그라운드 트루쓰(Ground Turth)를 기초로 오인식 데이터를 생성할 수 있다(S740). 또한, 영상 처리 장치는, 상기 오인식 데이터를 기초로 상기 객체 인식 모델의 취약 패턴맵을 생성할 수 있다(S750). 또한, 영상 처리 장치는, 상기 취약 패턴맵 및 적어도 하나의 기저장된 이미지 정보를 기초로 취약 데이터 베이스를 분류할 수 있다(S760). 또한, 영상 처리 장치는, 상기 취약 패턴맵 및 상기 객체 인식 모델을 기초로 취약 커널을 선별할 수 있다 (S770). 또한, 영상 처리 장치는, 상기 선별된 커널을 상기 취약 데이터베이스로 훈련할 수 있다(S780). 이에 따라, 영상 처리 장치는 S780단계에서 훈련된 객체 인식 모델을 포함하는 업데이트 정보를 차량으로 전송하도록 통신부를 제어하는 신호를 생성할 수 있다. 또한, 차량은 영상 처리 장치로부터 수신한 업데이트 정보를 기초로 기존의 객체 인식 모델을 업데이 트할 수 있다(S790). 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 전술한 프로그램은, 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상 기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, 기계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필요한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들을 상기 컴퓨터의 프 로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있다. 또한, 이러한 코 드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴 퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는지 등에 대한 통 신 관련 코드를 더 포함할 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다."}
{"patent_id": "10-2022-0006459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2022-0006459", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 의한 차량의 구성을 설명하기 위한 블록도이다. 도 2는 일 실시예에 의한 영상 처리 방법을 설명하기 위한 순서도이다. 도 3은 일 실시예에 의한 영상 처리 방법의 객체 인식 단계를 설명하기 위한 도면이다. 도 4는 일 실시예에 의한 영상 처리 방법의 오인식 데이터 생성 단계를 설명하기 위한 도면이다. 도 5는 일 실시예에 의한 영상 처리 방법의 취약 패턴 생성 단계를 설명하기 위한 도면이다. 도 6은 일 실시예에 의한 영상 처리 방법의 취약 커널 선별 단계를 설명하기 위한 순서도이다. 도 7은 일 실시예에 의한 영상 처리 방법의 취약 데이터베이스 생성 단계를 설명하기 위한 순서도이다. 도 8은 일 실시예에 의한 영상 처리 방법의 취약 데이터베이스 생성 단계를 설명하기 위한 개념도이다. 도 9는 일 실시예에 의한 영상 처리 방법의 취약 커널 학습 단계를 설명하기 위한 순서도이다. 도 10은 일 실시예에 의한 영상 처리 방법을 설명하기 위한 순서도이다."}
