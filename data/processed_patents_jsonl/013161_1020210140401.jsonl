{"patent_id": "10-2021-0140401", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0079428", "출원번호": "10-2021-0140401", "발명의 명칭": "비디오에서 객체를 검출하는 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "수, 징타오"}}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 프레임 이미지들을 포함하는 비디오의 프레임 이미지(로부터 객체를 검출하는 방법에 있어서,타겟 템플릿 세트에 기초하여, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계; 및상기 검출된 객체에 관한 정보를 출력하는 단계를 포함하고,상기 타겟 템플릿 세트는,하나 이상의 타겟 템플릿을 포함하고,상기 하나 이상의 타겟 템플릿의 각각은,상기 비디오의 상기 프레임 이미지의 이전 프레임 이미지들 중 상기 객체를 포함하는 것으로 결정된 각각의 프레임 이미지에서의 상기 객체의 정보를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 타겟 템플릿 세트는,초기 타겟 템플릿를 더 포함하고,상기 초기 타겟 템플릿은,상기 비디오의 프레임 이미지들 중 상기 객체를 포함하는 것으로 사용자에 의하여 결정된 프레임 이미지에서의상기 객체의 정보, 또는상기 비디오와 독립되고, 상기 객체를 포함하는 별도의 이미지를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프레임 이미지로부터 상기 객체를 검출하는 단계는,상기 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징을 융합하여 타겟융합 특징을 결정하는 단계;상기 타겟 융합 특징에 기초하여, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역을 획득하는 단계; 및상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역을 결정하는 단계공개특허 10-2022-0079428-3-를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 하나 이상의 타겟 후보 영역을 획득하는 단계는,상기 프레임 이미지 내에서 복수의 검색 영역을 결정하는 단계;상기 복수의 검색 영역의 각각의 이미지 특징을 추출하여 검색 영역 특징를 획득하는 단계;상기 복수의 검색 영역의 각각의 검색 영역 특징과 상기 타겟 융합 특징의 상관도를 계산하는 단계; 및상기 상관도에 기초하여 상기 복수의 검색 영역 중 상기 하나 이상의 타겟 후보 영역을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 타겟 템플릿 세트를 갱신하는 단계를 더 포함하고,상기 타겟 템플릿 세트를 갱신하는 단계는,상기 타겟 템플릿 세트의 상기 타겟 융합 특징 및 상기 타겟 영역의 유사도를 계산하는 단계; 및상기 유사도가 임계값보다 작은 경우, 상기 타겟 영역을 타겟 템플릿으로 상기 타겟 템플릿에 추가하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 프레임 이미지로부터 상기 객체를 검출하는 단계는,상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역을 획득하는 단계; 및상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역을 결정하는 단계를 포함하고,상기 방법은,상기 타겟 영역이 미리 결정된 조건을 만족하는 경우, 상기 타겟 템플릿 세트를 갱신하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 타겟 템플릿 세트를 갱신하는 단계는,상기 타겟 템플릿 세트의 모든 타겟 템플릿들의 각각 및 상기 타겟 영역의 유사도를 계산하는 단계; 및공개특허 10-2022-0079428-4-상기 유사도의 모두가 임계값보다 작은 경우, 상기 타겟 영역을 타겟 템플릿으로 상기 타겟 템플릿에 추가하는단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프레임 이미지로부터 상기 객체를 검출하는 단계는,상기 타겟 템플릿 세트 및 간섭 템플릿 세트에 기초하여, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계를 포함하고,상기 간섭 템플릿 세트는,하나 이상의 간섭 템플릿을 포함하고,상기 하나 이상의 간섭 템플릿의 각각은,상기 비디오의 상기 프레임 이미지의 이전 프레임 이미지들 중 상기 객체의 검출을 방해한 간섭 객체에 관한 정보를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프레임 이미지로부터 상기 객체를 검출하는 단계는,상기 타겟 템플릿 세트 및 상기 간섭 테플릿 세트에 기초하여, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역을 획득하는 단계; 및상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역을 결정하는 단계는,상기 하나 이상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각타겟 템플릿과의 매칭 정도를 계산하는 단계;상기 하나 이상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각간섭 템플릿과의 매칭 정도를 계산하는 단계;상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도 및 상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도에 기초하여, 상기 타겟 후보 영역의 각각의타겟 매칭 정도를 계산하는 단계; 및상기 타겟 후보 영역의 각각의 타겟 매칭 정도에 기초하여, 상기 하나 이상의 타겟 후보 영역 중 하나의 타겟영역을 결정하는 단계공개특허 10-2022-0079428-5-를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 타겟 후보 영역의 각각의 타겟 매칭 정도를 계산하는 단계는,상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도의 평균값 또는 중간값,또는상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도의 평균값 또는 중간값에 기초하여 상기 타겟 후보 영역의 각각의 타겟 매칭 정도를 계산하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 하나 이상의 타겟 후보 영역을 획득하는 단계는,상기 타겟 템플릿 세트에 기초하여, 타겟 융합 특징을 결정하는 단계;상기 간섭 템플릿 세트에 기초하여, 간섭 융합 특징을 결정하는 단계; 및상기 타겟 융합 특징 및 상기 간섭 융합 특징에 기초하여, 상기 프레임 이미지로부터 상기 하나 이상의 타겟 후보 영역을 획득하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 타겟 템플릿 세트에 기초하여, 타겟 융합 특징을 결정하는 단계는,상기 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징을 융합하여 상기타겟 융합 특징을 결정하는 단계를 포함하고,상기 간섭 템플릿 세트에 기초하여, 간섭 융합 특징을 결정하는 단계는,상기 간섭 템플릿 세트에 포함된 간섭 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징을 융합하여 상기간섭 융합 특징을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 타겟 템플릿 세트에 기초하여, 타겟 융합 특징을 결정하는 단계는,상기 타겟 템플릿 세트에 포함된 모든 타겟 템플릿에 기초하여, 상기 타겟 융합 특징을 결정하는 단계를 포함하고,공개특허 10-2022-0079428-6-상기 간섭 템플릿 세트에 기초하여, 간섭 융합 특징을 결정하는 단계는,상기 간섭 템플릿 세트에 포함된 모든 간섭 템플릿에 기초하여, 상기 간섭 융합 특징을 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 간섭 템플릿 세트를 갱신하는 단계를 더 포함하고,상기 간섭 템플릿 세트를 갱신하는 단계는,상기 하나 이상의 타겟 후보 영역 중 상기 타겟 영역을 제외한 다른 타겟 후보 영역의 일부 또는 전부를 간섭템플릿으로 상기 간섭 템플릿에 추가하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 간섭 템플릿 세트를 갱신하는 단계를 더 포함하고,상기 간섭 템플릿 세트를 갱신하는 단계는,상기 간섭 템플릿 세트의 상기 간섭 융합 특징 및 다른 타겟 후보 영역의 일부 또는 전부의 유사도를 계산하는단계; 및상기 다른 타겟 후보 영역의 일부 또는 전부 중 상기 유사도가 임계값보다 작은 타겟 후보 영역을 간섭 템플릿으로 상기 간섭 템플릿에 추가하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "전자 장치에 있어서,메모리와 프로세서를 포함하고,상기 메모리는 컴퓨터 프로그램을 저장하고,상기 프로세서는 상기 컴퓨터 프로그램이 수행될 때 제1항의 방법을 구현하도록 구성된전자 장치."}
{"patent_id": "10-2021-0140401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "비일시적 컴퓨터 판독가능 기록매체에 있어서,컴퓨터 프로그램을 저장하고, 상기 컴퓨터 프로그램은 제1항의 방법을 구현하기 위해 프로세서에 의해 실행되는것인,공개특허 10-2022-0079428-7-비일시적 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능, 객체 추적, 객체 검출, 이미지 처리 등 분야에 적용될 수 있는 타겟 객체 검출 방법 및 장치가 개시 된다. 하나 이상의 타겟 템플릿을 포함하는 타겟 템플릿 세트에 기초하여, 복수의 프레임 이미지들을 포함하는 비디오의 프레임 이미지로부터 객체가 검출된다. 타겟 템플릿 세트를 이용함으로써, 객체 검출 및 추적의 정확 도가 향상된다."}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 개시는, 비디오에서 객체를 추적하고 검출하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비주얼 객체 추적(visual object tracking)은 컴퓨터 비전(computer vision) 기술에서 중요한 연구 분야 중 하 나이다. 객체 추적 기술은, 일반적으로, 사람, 동물, 항공기, 자동차 등과 같이, 움직이는 객체(moving object)를 추적(track)하는데 사용된다. 움직이는 객체를 추적하는 과정에서, 추적할 타겟 객체(target object to be tracked)는, 비디오의 제1 프레임 (first frame)(초기 프레임(initial frame)이라고도 함)에서 지시(indicate)될 수 있다. 객체 추적 알고리즘은, 상기 비디오의 후속 프레임들에서 타겟 객체에 대한 계속적인 추적을 수행하고, 타겟 객체의 프레 임 내 위치 정보를 제공한다. 객체 추적을 위하여, 제1 프레임에서 지시(indicate)된 타겟 객체에 기초하여 상기 타겟 객체와 연관된 템플릿 정보(template information)가 추출된다. 후속 비디오 프레임들(subsequent video frames)의 검색 영역(search region) 내에서, 복수의 다른 후보 영역들(candidate regions)과 상기 템플릿 정보 간의 매칭 정도가 계산되고, 가장 매칭되는 후보 영역이 타겟 객체의 위치로 결정된다. 일 실시예에 따르면, 복수의 프레임 이미지들을 포함하는 비디오의 프레임 이미지(a frame image of a video comprising a plurality of frame images)로부터 객체(object)를 검출(detect)하는 방법이 제공된다. 이 방법 은, 타겟 템플릿 세트(target tempage set)에 기초하여, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계, 및 상기 검출된 객체에 관한 정보(information regarding the detected object)를 출력(output)하는 단계를 포 함한다. 상기 타겟 템플릿 세트는, 하나 이상의 타겟 템플릿(one or more target templates)을 포함한다. 상 기 하나 이상의 타겟 템플릿의 각각은, 상기 비디오의 상기 프레임 이미지의 이전 프레임 이미지들(previous frame images) 중 상기 객체를 포함하는 것으로 결정된 각각의 프레임 이미지(respective frame image)에서의 상기 객체의 정보를 포함한다. 일 실시예에 따르면, 상기 타겟 템플릿 세트는, 초기 타겟 템플릿(initial target template)를 더 포함할 수 있 다. 상기 초기 타겟 템플릿은, 상기 비디오의 프레임 이미지들 중 상기 객체를 포함하는 것으로 사용자에 의하 여 결정된 프레임 이미지에서의 상기 객체의 정보를 포함할 수 있다. 또는, 상기 초기 타겟 템플릿은, 상기 비 디오와 독립(independent)되고, 상기 객체를 포함하는 별도의 이미지(separate image)를 포함할 수 있다. 일 실시예에 따르면, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계는, 상기 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징(image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)을 결정하는 단계, 상기 타겟 융합 특징에 기초하여, 상기 프레임 이미지 내에 서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역(target candidate area)을 획득하는 단 계, 및 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역(target area)을 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 하나 이상의 타겟 후보 영역을 획득하는 단계는, 상기 프레임 이미지 내에서 복수의 검색 영역을 결정하는 단계, 상기 복수의 검색 영역의 각각의 이미지 특징을 추출(extract)하여 검색 영역 특징 (search area feature)를 획득하는 단계, 상기 복수의 검색 영역의 각각의 검색 영역 특징과 상기 타겟 융합 특 징의 상관도(correlation)를 계산하는 단계, 및 상기 상관도에 기초하여 상기 복수의 검색 영역 중 상기 하나 이상의 타겟 후보 영역을 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 방법은, 상기 타겟 템플릿 세트를 갱신(update)하는 단계를 더 포함할 수 있다. 상 기 타겟 템플릿 세트를 갱신하는 단계는, 상기 타겟 템플릿 세트의 상기 타겟 융합 특징 및 상기 타겟 영역의유사도(similarity)를 계산하는 단계, 및 상기 유사도가 임계값보다 작은 경우, 상기 타겟 영역을 타겟 템플릿 으로 상기 타겟 템플릿에 추가(add)하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계는, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역(target candidate area)을 획득하는 단계, 및 상 기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역(target area)을 결정하는 단계를 포함할 수 있다. 또한, 상기 방법은, 상기 타겟 영역이 미리 결정된 조건을 만족하는 경우, 상기 타겟 템플릿 세트를 갱신 (update)하는 단계를 더 포함할 수 있다. 일 실시예에 따르면, 상기 타겟 템플릿 세트를 갱신하는 단계는, 상기 타겟 템플릿 세트의 모든 타겟 템플릿들 의 각각 및 상기 타겟 영역의 유사도(similarity)를 계산하는 단계, 및 상기 유사도의 모두가 임계값보다 작은 경우, 상기 타겟 영역을 타겟 템플릿으로 상기 타겟 템플릿에 추가(add)하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계는, 상기 타겟 템플릿 세트 및 간섭 템플릿 세트(interference templage set)에 기초하여, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계를 포함할 수 있다. 상기 간섭 템플릿 세트는, 하나 이상의 간섭 템플릿(interference template)을 포함한다. 상 기 하나 이상의 간섭 템플릿의 각각은, 상기 비디오의 상기 프레임 이미지의 이전 프레임 이미지들 중 상기 객 체의 검출을 방해(interfere with the detection of the object)한 간섭 객체(interfere object)에 관한 정보 를 포함한다. 일 실시예에 따르면, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계는, 상기 타겟 템플릿 세트 및 상기 간섭 테플릿 세트에 기초하여, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역(target candidate area)을 획득하는 단계, 및 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역(target area)을 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역을 결정하는 단계는, 상기 하 나 이상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템 플릿과의 매칭 정도(matching degree)를 계산하는 단계, 상기 하나 이상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도(matching degree)를 계산하는 단계, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도 및 상기 타겟 후 보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도에 기초하여, 상기 타겟 후보 영역의 각각의 타겟 매칭 정도를 계산하는 단계, 및 상기 타겟 후보 영역의 각각의 타겟 매칭 정도에 기초하여, 상기 하나 이상의 타겟 후보 영역 중 하나의 타겟 영역을 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 타겟 후보 영역의 각각의 타겟 매칭 정도를 계산하는 단계는, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도의 평균값 또는 중간값, 및/또는 상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도의 평균값 또는 중간값에 기초하여 상기 타겟 후보 영역의 각각의 타겟 매칭 정도를 계산하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 하나 이상의 타겟 후보 영역을 획득하는 단계는, 상기 타겟 템플릿 세트에 기초하여, 타겟 융합 특징(integrated target feature)을 결정하는 단계, 상기 간섭 템플릿 세트에 기초하여, 간섭 융합 특징(integrated inteference feature)을 결정하는 단계, 및 상기 타겟 융합 특징 및 상기 간섭 융합 특징에 기초하여, 상기 프레임 이미지로부터 상기 하나 이상의 타겟 후보 영역을 획득하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 타겟 템플릿 세트에 기초하여, 타겟 융합 특징을 결정하는 단계는, 상기 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징을 융합(integrate)하여 상기 타겟 융합 특징을 결정하는 단계를 포함할 수 있다. 상기 간섭 템플릿 세트에 기초하여, 간섭 융합 특징을 결정하는 단계는, 상기 간섭 템플릿 세트에 포함된 간섭 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징을 융합 (integrate)하여 상기 간섭 융합 특징을 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 타겟 템플릿 세트에 기초하여, 타겟 융합 특징을 결정하는 단계는, 상기 타겟 템플릿 세트에 포함된 모든 타겟 템플릿에 기초하여, 상기 타겟 융합 특징을 결정하는 단계를 포함할 수 있다. 상기 간섭 템플릿 세트에 기초하여, 간섭 융합 특징을 결정하는 단계는, 상기 간섭 템플릿 세트에 포함된 모든 간섭 템플릿에 기초하여, 상기 간섭 융합 특징을 결정하는 단계를 포함할 수 있다. 일 실시예에 따르면, 상기 방법은, 상기 간섭 템플릿 세트를 갱신(update)하는 단계를 더 포함할 수 있다. 일 예에 따르면, 상기 간섭 템플릿 세트를 갱신하는 단계는, 상기 하나 이상의 타겟 후보 영역 중 상기 타겟 영역을 제외한 다른 타겟 후보 영역의 일부 또는 전부를 간섭 템플릿으로 상기 간섭 템플릿에 추가(add)하는 단계를 포함할 수 있다. 다른 예에 따르면, 상기 간섭 템플릿 세트를 갱신하는 단계는, 상기 간섭 템플릿 세트의 상기 간섭 융합 특징 및 상기 다른 타겟 후보 영역의 일부 또는 전부의 유사도를 계산하는 단계, 및 상기 다른 타겟 후보 영역의 일부 또는 전부 중 상기 유사도가 임계값보다 작은 타겟 후보 영역을 간섭 템플릿으로 상기 간섭 템플릿에 추가하는 단계를 포함할 수 있다. 실시예들에 따르면, 하나 이상의 타겟 템플릿이 타겟 템플릿 세트에 포함되어 있으므로, 타겟 템플릿 세트에 포 함된 정보가 더 풍부하게 되고, 타겟 객체를 검출하기 위해 제1 프레임 이미지만 사용하는 것을 피할 수 있다. 즉, 타겟 템플릿 세트는 타겟 객체의 나타날 수 잇는 다양한 특징 정보를 기록하므로, 타겟 객체의 정보를 보다 포괄적으로 설명할 수 있고, 이를 통해 타겟 객체 검출의 정확도가 향상된다."}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에 대한 특정한 구조적 또는 기능적 설명들은 단지 예시를 위한 목적으로 개시된 것으로서, 다양한 형 태로 변경되어 구현될 수 있다. 따라서, 실제 구현되는 형태는 개시된 특정 실시예로만 한정되는 것이 아니며, 본 개시의 범위는 실시예들로 설명한 기술적 사상에 포함되는 변경, 균등물, 또는 대체물을 포함한다. \"제1\" 또는 \"제2\" 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성 요소를 다른 구성요소로부터 구별하는 목적으로만 해석되어야 한다. 예를 들어, \"제1 구성요소\"는 \"제2 구성요 소\"로 명명될 수 있고, 유사하게 \"제2 구성요소\"는 \"제1 구성요소\"로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함으 로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 개시에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 실시예들을 첨부된 도면들을 참조하여 상세하게 설명한다. 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부여하고, 이에 대한 중복되는 설명은 생략하기로 한 다.타겟 객체를 추적할 때, 조명의 변화, 스케일의 변화, 배경 간섭(background interference), 시야 범위 밖으로 벗어남, 평면 내 회전, 저해상도(low resolution), 빠른 모션, 모션 블러(motion blur), 폐색(occlusion) 등의 영향으로, 추적되는 타겟 객체의 특징 정보가 변경될 수 있다. 이는 객체 식별 및/또는 객체 추적의 정확도를 떨어뜨릴 수 있다. 여기에 개시된 실시예들은 상기의 문제점들 중 적어도 하나를 해결할 수 있는 객체 검출 방 법을 제공한다. 이 방법들은, 단말 장치, 서버 등일 수 있는 다양한 전자 장치들에 의하여 실행될 수 있다. 일 실시예에서, 복수의 프레임 이미지들을 포함하는 비디오의 프레임 이미지(a frame image of a video comprising a plurality of frame images)로부터 객체(object)를 검출(detect) 및/또는 추적(track)하는 방법 이 제공된다. 상기 방법은, 타겟 템플릿 세트(target tempage set)에 기초하여, 프레임 이미지로부터 객체를 검출 및/또는 추 적하고, 검출된 객체에 관한 정보(information regarding the detected object)를 출력(output)한다. 상기 방법은, 비디오에서 타겟 객체(target object)를 추적하고 검출하는데 사용될 수 있고, 또는 임의의 프레 임 이미지으로부터 타겟 객체를 검출하는데 사용될 수도 있으며, 이에 제한되지 않는다. 실시예들이 적용될 수 있는 비디오의 소스(source)는 제한되지 않는다. 예를 들어, 비디오 소스는, 영화일 수 도 있으며, CCTV 영상, 모니터링 영상, 스포츠 이벤트 라이브 비디오 등과 같이, 가시광 카메라(visible light camera)를 통해 촬영된 비디오일 수도 있다. 일 실시예에 따른 객체 검출 방법은, 시각적 객체 추적(visual object tracking)에 적용될 수 있다. 시각적 객 체 추적은, 중요한 컴퓨터 비전 연구 과제로 중 하나로서, 일상 생활에서 다양한 실제 응용을 갖는다. 예를 들 어, 일 실시예에 따른 객체 추적/검출은, 모니터링 영상으로부터 타겟 객체(예, 용의자, 실종 아동, 실종 노인, 실종 동물 등)를 찾거나, 스포츠 이벤트 라이브 비디오로부터 타겟 선수를 고정(locate)하는데 사용될 수 있다. 또한, 일 실시예에 따른 객체 추적/검출은, 모니터링 영상으로부터 차량이 이동한 경로을 결정하는 데에도 사용 될 수 있고, 또는 비행 중인 소형 항공기를 추적하는 데에도 사용될 수 있다. 또 다른 예로서, 일 실시예에 따 른 객체 추적/검출은, 스마트 폰에서, 카메라 포커싱, 비디오 효과 생성, 움직이는 물체 분석 등을 돕기 위해 사용될 수 있다. 실시예들에 따른 객체 추적/검출은, 실제의 필요에 따라 적용되는 시나리오가 결정될 수 있으 며, 이에 제한되지 않는다. 비디오 추적 및/또는 검출에 적용되는 경우, 타겟 템플릿 세트(target template set)는, 하나 이상의 타겟 템플 릿(one or more target templates)을 포함한다. 상기 하나 이상의 타겟 템플릿의 각각은, 비디오의 해당 프레임 이미지의 이전 프레임 이미지들(previous frame images) 중 하나에 대응한다. 상기 하나 이상의 타겟 템플릿의 각각은, 비디오의 해당 프레임 이미지의 이전 프레임 이미지들(previous frame images) 중 타겟 객체를 포함하 는 것으로 결정된 각각의 프레임 이미지(respective frame image)에서의 상기 객체의 정보를 포함한다. 상기 객 체의 정보는 타겟 객체가 위치한 이미지 영역일 수 있다. 상기 타겟 객체(target object)는 움직이는 사람, 동물, 교통수단(자동차, 항공기 등)과 같이 추적 및/또는 검 출하고자 하는 객체로 이해될 수 있다. 추적 및/또는 검출하고자 하는 타겟 객체는 실제 필요에 따라 선택될 수 있으며, 여기서 그 어떤 제한도 하지 않는다. 선택적으로, 비디오에서 추적할 대상(즉, 상기 타겟 객체)은 사용자의 지시(indication)에 의해 결정될 수 있으며, 또는 이미 알려진 객체의 이미지에 의해 결정될 수도 있 다. 예를 들어, 사용자는 비디오에서 타겟 객체가 처음 나타나는 비디오 프레임에 어떤 객체를 지시함으로써 타겟 객체를 결정할 수 있으며, 이렇게 사용자에 의하여 선택된 이미지 영역은 타겟 객체의 초기 타겟 템플릿 (initial target template)으로 이용될 수 있다. 또는, 초기 타겟 템플릿은 이미 알려진 객체의 이미지일 수 있다. 예를 들어, 특정 인물을 검색하는 경우, 상기 인물의 사진을 초기 타겟 템플릿으로 사용할 수 있다. 상기 타겟 템플릿 세트는, 메모리, 하드 디스크 등과 같은 저장장치(storage)에 저장된다. 여기서는 타겟 템플 릿 세트를 저장하는 저장장치를 \"타겟 메모리(target memory)\"로 부른다. 타겟 템플릿 세트에 포함되는 타겟 템플릿은, 비디오의 검출된 프레임 이미지에서 타겟 객체의 검출 결과에 대응하는 이미지 영역(즉, 각 프레임 이미지에서 타겟 객체가 위치한 영역)을 포함할 수 있다. 예를 들어, 타겟 템플릿은, 프레임 이미지에서 타겟 객체가 위치한 이미지 영역일 수 있다. 즉, 프레임 이미지에서 타겟 객체를 포함한 이미지 영역이 타겟 템플릿 으로 사용될 수 있다. 물론, 실시예에 따라, 타겟 템플릿 세트에 저장되는 타겟 템플릿은, 해당 이미지 영역의 특징 정보(feature information)일 수도 있다. 예를 들어, 타겟 템플릿은, 이미지로부터 추출된, 이미지 영역 을 나타내는 이미지 특징 정보일 수도 있다. 즉, 프레임 이미지에서 타겟 객체를 포함한 이미지 영역으로부터 추출된 특징 정보가 타겟 템플릿으로 사용될 수 있다. 또한, 타겟 템플릿 세트에 포함되는 타겟 템플릿은, 각프레임 이미지에서 검출된 타겟 객체의 위치 정보일 수 있다. 또한, 타겟 템플릿 세트는, 초기 타겟 템플릿(initial target template)를 포함할 수 있다. 초기 타겟 템플릿 은, 비디오의 프레임 이미지들 중 목표 객체를 포함하는 것으로 사용자에 의하여 결정된 프레임 이미지에서의 목표 객체의 정보일 수 있다. 예를 들어, 사용자는 비디오에서 타겟 객체가 처음으로 나타난 프레임 이미지에 서 초기 타겟 템플릿을 결정할 수 있다. 사용자는, 타겟 객체가 처음으로 나타난 프레임 이미지에서, 추적하고 자 하는 타겟 객체를 지시(indicate)하거나 타겟 객체를 포함하는 이미지 영역을 지정할 수 있다. 이렇게 지정 된 이미지 영역이 초기 타겟 템플릿으로 사용될 수도 있고, 상기 이미지 영역의 특징 정보가 초기 타겟 템플릿 으로 사용될 수도 있다. 일 실시예에서, 초기 타겟 템플릿은, 타겟 객체를 추적하려는 비디오와 독립(independent)되고, 타겟 객체를 포 함하는 별도의 이미지(separate image)로부터 획득될 수 있다. 예를 들어, 특정 인물을 추적 및/또는 식별하고 는 경우, 상기 인물의 사진 또는 상기 인물의 사진의 이미지 특징 정보가 초기 타겟 템플릿으로 사용할 수 있다. 타겟 템플릿 세트는, 초기 타겟 템플릿에 추가하여, 타겟 객체가 이미 검출된 다른 프레임 이미지들에 대응하는 타겟 템플릿을 더 포함할 수 있다. 예를 들어, 비디오에서, 타겟 객체를 검출/추적하려고 하는 프레임 이미지 의 이전 프레임 이미지들 중 적어도 하나의 프레임 이미지에 대응하는 타겟 템플릿을 더 포함할 수 있다. 예를 들어, 해당 프레임 이미지(subject frame image)가 제2 프레임 이미지인 경우, 이전 프레임 이미지 (previous frame image)는 제1 프레임 이미지이다. 제1 프레임 이미지에 타겟 객체가 포함된 것으로 판단된 경 우, 타겟 템플릿 세트는, 제1 프레임 이미지에서 타겟 객체를 포함한 이미지 영역에 관한 정보(제1 타겟 템플릿)를 포함할 수 있다. 해당 이미지가 제3 프레임 이미지인 경우, 이전 프레임 이미지(previous frame images)는 제1 프레임 이미지 및 제2 프레임 이미지를 포함한다. 제1 프레임 이미지 및 제2 프레임 이미지에 타겟 객체가 포함된 것으로 판단된 경우, 타겟 템플릿 세트는, 제1 프레임 이미지에서 타겟 객체를 포함한 이미지 영역(타겟 영역(target area))에 관한 정보(제1 타겟 템플릿) 및 제2 프레임 이미지에서 타겟 객체를 포함한 이미지 영역에 관한 정보(제2 타겟 템플릿)를 포함할 수 있다. 일 실시예에서, 해당 프레임 이미지에 대해, 해당 프레임 이미지의 모든 이전 프레임 이미지들에 대응하는 타겟 템플릿의 모두가 타겟 템플릿 세트에 포함될 수 있다. 실시예에 따라서, 타겟 템플릿 세트가, 이전 프레임 이미지들 중 타겟 객체를 포함한 것으로 판단된 모든 프레 임 이미지들에 대응하는 타겟 템플릿을 포함하지 않고, 일부의 타겟 템플릿만 포함될 수 있다. 예를 들어, 해 당 프레임 이미지에 대해, 해당 프레임 이미지의 모든 이전 프레임 이미지들 중 특정 조건을 만족하는 타겟 템 플릿만 타겟 템플릿 세트에 포함될 수 있다. 상기 특정 조건은, 실시예에 따라 구성될 수 있다. 예를 들어, 새로운 타겟 템플릿은, 타겟 템플릿 세트에 이미 저장된 타겟 템플릿들과의 유사도(similarity), 매 칭 정도(matching degree) 등에 따라, 타겟 템플릿 세트에 포함될지 여부가 결정될 수 있다. 예를 들어, 유사 도 또는 매칭 정도가 임계값보다 작으면, 새로운 타겟 템플릿은 타겟 템플릿 세트에 포함될 수 있다. 이렇게 함으로써, 타겟 템플릿 세트에 이미 포함된 타겟 템플릿들과 비슷한 타겟 템플릿(유사도가 임계값보다 높은 타 겟 템플릿)은 타겟 템플릿 세트에 추가되지 않도록 할 수 있다. 기존의 타겟 템플릿들(existing target tempates)과 유사한 타겟 템플릿을 추가하지 않도록 함으로써, 이후의 데이터 계산량을 효과적으로 줄일 수 있 다. 해당 프레임 이미지에서 타겟 객체를 검출할 때 사용되는 타겟 템플릿 세트는, 해당 프레임 이미지에 따라 다를 수 있다. 예를 들어, 50번째 프레임 이미지에서 타겟 객체를 검출할 때 사용하는 타겟 템플릿 세트는, 200번째 프레임 이미지에서 타겟 객체를 검출할 때 사용하는 타겟 템플릿 세트와 다를 수 있다. 유사하게, 사용되는 타 겟 템플릿 세트에 포함되는 카겟 템플릿의 수도 다를 수 있다. 비디오에서 타겟 객체를 추적 및/또는 검출할 때, 해당 프레임 이미지에 대해, 타겟 템플릿 세트를 통해, 해당 프레임 이미지에 대해 타겟 객체의 검출을 수행하여 타겟 객체의 검출 결과(detection results)를 얻을 수 있다. 검출 결과는, 해당 프레임 이미지에서 타겟 객체를 포함하는 것으로 판단된 이미지 영역(image area), 상기 이미지 영역의 이미지 특성 정보(image feature information), 또는 해당 프레임 이미지에서의 타겟 객체 의 위치 정보일 수 있다. 또한, 상기 검출 결과는, 이들의 신뢰도를 추가로 포함할 수 있다. 신뢰도는 검출결과를 처리하는데 사용될 수 있으며, 값의 범위는 [0, 1]일 수 있다. 일 실시예에 따르면, 타겟 템플릿 세트를 통해, 프레임 이미지에서 타겟 객체에 대해 검출 및/또는 추적을 진행 하고, 프레임 이미지에서의 타겟 객체의 검출 결과를 획득한다. 이 방법에 따르면, 타겟 템플릿 세트가 초기 타겟 템플릿뿐만 아니라 이전 프레임 이미지들에서 타겟 객체가 위치한 이미지 영역에 대응하는 타겟 템플릿도 포함하기 때문에, 타겟 템플릿 세트에 포함된 정보가 더 풍부해진다. 즉, 타겟 템플릿 세트에 포함된 타겟 템 플릿의 다양성으로 인해, 타겟 객체 검출에 사용될 수 있는 정보가 더 풍부해지고, 검출 결과의 정확도 또한 향 상된다. 일 실시예에 따르면, 프레임 이미지로부터 상기 객체를 검출하는 단계는, 타겟 템플릿 세트 및 간섭 템플릿 세 트(interference templage set)에 기초하여, 상기 프레임 이미지로부터 상기 객체를 검출하는 단계를 포함한다. 간섭 템플릿 세트는, 하나 이상의 간섭 템플릿(interference template)을 포함한다. 상기 하나 이상의 간섭 템 플릿의 각각은, 상기 비디오의 상기 프레임 이미지의 이전 프레임 이미지들 중 상기 객체의 검출을 방해 (interfere with the detection of the object)한 간섭 객체(interfere object)에 관한 정보를 포함한다. 간섭 객체는, 간섭물(interfering object), 즉 타겟 객체의 검출을 방해(interfere)할 수 있는 객체라고도 할 수 있다. 간섭 객체는, 비디오의 프레임 이미지에서 추적되는 타겟 객체와 (시각적으로) 유사한 물체, 텍스처 (비물체) 또는 모양일 수 있다. 상기 간섭 템플릿 세트는, 메모리, 하드 디스크 등과 같은 저장장치(storage)에 저장된다. 여기서는 간섭 템플 릿 세트를 저장하는 저장장치를 \"간섭 메모리(interference memory)\"로 부른다. 간섭 템플릿 세트에 포함되는 간섭 템플릿은, 비디오의 프레임 이미지들에서 타겟 객체의 검출을 방해한 간섭 객체를 포함하는 이미지 영역 (즉, 프레임 이미지에서 간섭 객체가 위치한 영역)을 포함할 수 있다. 예를 들어, 간섭 템플릿은, 프레임 이미 지에서 타겟 객체에 대응하는 간섭 객체가 위치한 이미지 영역일 수 있다. 즉, 프레임 이미지에서 간섭 객체를 포함한 이미지 영역이 간섭 템플릿으로 사용될 수 있다. 또는, 간섭 템플릿은, 프레임 이미지에서 타겟 객체를 포함한 것으로 판단된 이미지 영역(타겟 영역)을 제외한 다른 이미지 영역을 포함할 수 있다. 물론, 실시예에 따라, 간섭 템플릿 세트에 저장되는 간섭 템플릿은, 간섭 객체를 포함한 이미지 영역의 특징 정보(feature information)일 수도 있다. 예를 들어, 간섭 템플릿은, 이미지로부터 추출된, 이미지 영역을 나타내는 이미지 특징 정보일 수도 있다. 즉, 각 프레임 이미지에서 간섭 객체를 포함한 이미지 영역으로부터 추출된 특징 정보 가 간섭 템플릿으로 사용될 수 있다. 또한, 간섭 템플릿 세트에 포함되는 간섭 템플릿은, 프레임 이미지에서 검출된 간섭 객체의 위치 정보일 수 있다. 일 실시예에서, 간섭 템플릿 세트는, 타겟 객체에 대응하는 간섭 템플릿들을 포함한다. 간섭 템플릿들의 각각 은, 해당 프레임 이미지(subject frame image)의 이전 프레임 이미지들(previous image frames)에서 타겟 객체 의 간섭 객체가 위치한 이미지 영역이다. 예를 들어, 해당 프레임 이미지가 제3 프레임 이미지인 경우, 이전 프레임 이미지들은, 제1 프레임 이미지 및 제2 프레임 이미지를 포함한다. 타겟 객체가 제1 프레임 이미지에서 사용자에 의하여 선택(select)된 경우, 초 기 타겟 템플릿은, 제1 프레임 이미지 중 사용자에 의하여 선택된 이미지 영역이다. 또한, 사용자의 선택에 의 하여 제1 프레임 이미지로부터 간섭 객체도 선택될 수 있다. 이 경우, 선택된 간섭 객체에 대응하는 이미지 영 역에 관한 정보가 간섭 템플릿 세트에 추가될 수 있다. 선택적으로, 제1 프레임 이미지에 대해 타겟 체에 대응 하는 간섭 객체의 검출을 진행하지 않을 수 있다. 즉, 제1 프레임으로부터 간섭 객체의 검출을 진행하지 않을 수 있다. 제2 프레임 이미지에 대해 타겟 객체가 검출될 때, 복수의 타겟 후보 영역들를 얻게 되고, 복수의 타겟 후보 영 역들 중 타겟 객체가 포함된 것으로 결정된 타겟 영역 외의 타겟 후보 영역들(이미지 영역들)의 일부 또는 전부 가 타겟 객체의 간섭 객체가 위치한 이미지 영역으로 결정될 수 있다. 이는 간섭 템플릿으로 간섭 템플릿 세트 에 추가될 수 있다. 제3 프레임 이미지에 대해 타겟 객체를 검출할 때, 타겟 템플릿 세트에 포함된 타겟 템플릿(제1 프레임으로부터 획득된 타겟 템플릿 및 제2 프레임으로부터 획득된 타겟 템플릿) 및 간섭 템플릿 세트에 포함된 간섭 템플릿들 (제2 프레임 이미지로부터 획득된 간섭 템플릿)이 이용될 수 있다. 또한, 제3 프레임 이미지에 대해 타겟 객체 가 검출될 때, 동일한 방법에 의하여, 제3 프레임 이미지로부터 추가의 간섭 템플릿을 얻을 수 있다. 일 실시예에서, 프레임 이미지로부터 타겟 객체를 검출할 때, 타겟 템플릿 세트와 간섭 템플릿 세트의 두 가지 정보를 모두 고려할 수 있다. 즉, 타겟 템플릿 세트와는 유사도가 높고 간섭 템플릿 세트와는 유사도가 낮은타겟 객체를 검출할 수 있다. 간섭 객체에 관한 정보는, 예를 들어, 이전 프레임 이미지에서 간섭 객체를 포함하는 것으로 판단된 이미지 영 역(image area), 상기 이미지 영역의 이미지 특성 정보(image feature information), 또는 이전 프레임 이미지 에서의 간섭 객체의 위치 정보일 수 있다. 비디오에서 타겟 객체는, 조명 변환, 타겟 객체의 회전, 빠른 움직임, 모션 블러, 폐색, 변형, 및 배경 간섭 등 때문에 다양한 변화를 가진다. 실시예들에 따르면, 타겟 메모리(또는 타겟 템플릿 세트)는 타겟 객체의 이러한 변화들을 기억함으로써, 타겟 객체가 보다 정확하게 식별 및 추적될 수 있다. 또한, 실시예들에 따르면, 간섭 메모리(또는 간섭 템플릿 세트)는 타겟 객체의 검출을 방해하는 간섭 객체의 이 미지 특징을 기억하기 때문에, 타겟 객체의 검출에 있어서 간섭 객체의 영향을 제거하거나 줄일 수 있다. 타겟 메모리(또는 타겟 템플릿 세트)와 간섭 메모리(또는 간섭 템플릿 세트)를 통합(integrate)하여 타겟 객체 를 검출하는 이러한 방법은, 타겟 객체의 다양한 특징을 종합적으로 반영할 수 있을 뿐 아니라, 간섭 객체의 부 정적 영향을 제거하거나 줄임으로써, 타겟 객체의 식별 및/또는 추적의 정확도를 크게 향상시킬 수 있다. 일 실시예에서, 프레임 이미지로부터 상기 객체를 검출하는 단계는, 상기 프레임 이미지 내에서 상기 객체를 포 함하는 것으로 판단되는 하나 이상의 타겟 후보 영역(target candidate area)을 획득하는 단계, 및 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역(target area)을 결정하는 단계를 포함한다. 타겟 후보 영역은, 프레임 이미지에서 타겟 객체의 가능한 위치를 나타내는 후보 영역(candidate area), 앵커 영역(anchor region), 앵커 박스(anchor box) 또는 앵커(anchor)로 불릴 수도 있다. 타겟 후보 영역의 위치 및 크기는 다양할 수 있다. 일 실시예에서, 이미지 프레임에서 타겟 객체를 검출할 때, 타겟 템플릿 세트를 이용하여, 이미지 프레임으로부 터 하나 이상의 타겟 후보 영역이 획득될 수 있다. 일 실시예에서, 상기 하나 이상의 타겟 후보 영역을 획득하는 단계는, 상기 프레임 이미지 내에서 복수의 검색 영역(a plurality of search areas)을 결정하는 단계, 상기 복수의 검색 영역의 각각의 이미지 특징을 추출 (extract)하여 검색 영역 특징(search area feature)를 획득하는 단계, 상기 복수의 검색 영역의 각각의 검색 영역 특징과 상기 타겟 융합 특징의 상관도(correlation)를 계산하는 단계, 및 상기 상관도에 기초하여 상기 복 수의 검색 영역 중 상기 하나 이상의 타겟 후보 영역을 결정하는 단계를 포함할 수 있다. 예를 들어, 해당 프레임 이미지(subject frame image)로부터 복수의 검색 영역 박스들(search area box)을 얻 을 수 있다. 예를 들어, 이전 프레임에서 타겟 객체를 포함하는 것으로 판단된 영역의 주위에 대해 복수의 검 색 영역 박스들을 설정할 수 있다. 일 실시예에 따르면, 이 검색 영역 박스들의 이미지들이 모두 타겟 후보 영 역이 될 수도 있다. 또 다른 실시예에 따르면, 각 검색 영역 박스의 이미지는 타겟 템플릿 세트의 각 타겟 템 플릿과 하나씩(one by one) 매칭될 수 있다. 또는, 각 검색 영역 박스의 이미지는, 타겟 템플릿 세트의 모든 타겟 템플릿들을 융합(integrate)하여 얻어진 융합 템플릿(integration template)과 매칭될 수 있다. 상기 매 칭 후, 매칭 정도가 높은 하나 이상의 검색 영역들이 타겟 후보 영역들로 선택된다. 그 다음 타겟 후보 영역들 중에서 타겟 영역이 선택되고, 타겟 영역에 기초하여 타겟 객체의 검출 결과가 얻어진다. 실시예들은, 사전에 훈련된 신경망 모델에 의해 구현될 수 있음을 이해할 수 있다. 도 1은 일 실시예에 따른 객체 추적 방법을 구현하는 신경말 모델을 도시한다. 도 1에서, 운동 선수의 스포츠 장면을 포함하는 비디오가, 예로서, 제공된다. 비디오에서 추적하려고 하는 타 겟 객체는 특정 운동 선수(\"타겟 운동 선수(target player)\"라고 할 수 있음)이다. 현재 프레임 이미지 (current frame image)는, 타겟 운동 선수를 검출하려고 하는 비디오 내 프레임 이미지이다. 도 1의 실시 예에서, 사용자는, 비디오의 재생 중 타겟 객체(타겟 운동 선수)를 발견하면, 이 프레임 이미지에서 타겟 객체 를 지시(indicate)한다. 그러면, 이 프레임 이미지의 부분(이 부분은 타겟 객체를 포함함)의 정보가 초기 타겟 템플릿(initial target template)으로 사용된다. 메모리 풀(memory pool)은, 타겟 메모리(target memory)를 포함한다. 타겟 메모리는 타겟 템 플릿 세트(target template set)를 저장하는 저장공간(storage space)이다. 메모리 풀은, 메모리(memory), 하 드디스크(HDD), 플래시 메모리 등으로 구현될 수 있으며, 이에 제한되지 않는다. 타겟 템플릿 세트는, 초기 타 겟 템플릿 및 현재 프레임 이미지 이전의 프레임 이미지들에 대응하는 타겟 템플릿들을 저장한다.일 실시예에서, 현재 프레임 이미지에서 타겟 객체를 검출하기 위하여, 현재 프레임 이미지은 백본 네트워크(backbone network)에 입력된다. 백본 네트워크는, 신경망을 이용하여 이미지의 특징 (features)을 추출하는 네트워크로서, MobileNet, ResNet, Xception Network 등이 사용될 수 있으나, 이에 제 한되지 않는다. 백본 네트워크는 현재 프레임 이미지을 수신하고, 현재 프레임 이미지에 대응 하는 이미지 특징을 출력한다. 예를 들어, 백본 네트워크는 현재 프레임 이미지의 이미지 특징 으로, W x H x C를 출력할 수 있다. W x H x C는 특징맵(feature map)으로, W와 H는 각각 특징맵의 너비 (width)와 높이(height)를 나타내고, C는 특징맵의 채널 수(즉, 특징의 수)를 나타낸다. 또 다른 실시예에 따르면, 현재 프레임 이미지 내에서 복수의 검색 영역들(search areas)이 결정된다. 검 색 영역은, 현재 프레임 이미지 내에서 일부 이미지의 영역이다. 복수의 검색 영역의 각각은 백본 네트워 크(backbone network)에 입력된다. 백본 네트워크는, 복수의 검색 영역의 각각에 대한 검색 영역 특 징(search area feature)을 출력한다. 타겟 템플릿 세트에 저장된 타겟 템플릿들이 이미지인 경우, 하나 이상의 타겟 후보 영역을 획득하기 위해, 타 겟 메모리에 저장된 타겟 템플릿 세트의 타겟 템플릿들을 백본 네트워크에 입력한다. 백본 네트워크 는, 신경망을 이용하여 이미지의 특징(features)을 추출하는 네트워크로서, MobileNet, ResNet, Xception Network 등이 사용될 수 있으나, 이에 제한되지 않는다. 백본 네트워크는 백본 네트워크와 동일할 수도 있고 다를 수도 있다. 백본 네트워크는 타겟 템플릿들을 수신하고, 타겟 템플릿들에 대응하는 이미 지 특징들을 리콜 네트워크(recall network)에 출력한다. 또 다른 실시예에 따르면, 타겟 템플릿 세트에 저장된 타겟 템플릿들은 대응하는 이미지의 특징일 수 있다. 이 경우, 각 타겟 템플릿에 대응하는 이미지의 특징을 백본 네트워크를 통하여 추출할 필요가 없으므로, 타겟 템플릿은 직접(directly) 리콜 네트워크에 입력된다. 일 실시예에 따르면, 프로세서는, 리콜 네트워크, 상관도 계산부(correlation calculater) 및 앵커 처리기(anchor processor)를 포함할 수 있다. 리콜 네트워크, 상관도 계산부(correlation calculater) 및 앵커 처리기(anchor processor)는, 기능에 따른 개념적인 구분이며, 반드시 물리적 으로 분리되어 구현될 필요는 없다. 예를 들어, 리콜 네트워크, 상관도 계산부(correlation calculater) 및 앵커 처리기(anchor processor)는, 모두 프로세서에 의해 처리되는 다른 기능 들일 수 있으며, 설명의 편의상 구분된 것이다. 리콜 네트워크는, 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특 징(image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)을 출력한다. 리콜 네 트워크는, 신경망을 이용하여 입력된 이미지 특징들을 융합하는 네트워크로서, FFCNN(feature fusion convolutional neural network) 등이 사용될 수 있으나, 이에 제한되지 않는다. 상관도 계산부(correlation calculater)는, 현재 프레임 이미지의 이미지 특징과 타겟 융합 특 징의 상관도(correlation)를 계산한다. 또는, 상관도 계산부(correlation calculater)는, 현재 프레임 이미지 내 복수의 검색 영역들(search areas)의 각각의 검색 영역 특징과 타겟 융합 특징의 상관도 (correlation)를 계산한다. 상기 계산된 상관도에 기초하여, 복수의 검색 영역들 중 하나 이상의 타겟 후보 영 역(\"후보 앵커(candidate anchor)\"로 불리기도 한다)가 결정된다. 상관도 계산부(correlation calculater)에 의하여 생성된 상관도는 앵커 처리기(anchor processor) 에 입력된다. 앵커 처리기는 하나 이상의 타겟 후보 영역들(후보 앵커들)의 각각에 대한 신뢰도 (confidence) 및/또는 회귀 결과(regression results)를 출력할 수 있다. 일 실시예에서, 회귀 결과는 회귀 위치(regression position) (x, y, w, h)를 포함할 수 있다. 여기서, x와 y는 대응하는 타겟 후보 영역의 특 정 점(particular point)의 가로 좌표 및 세로 좌표를 나타낼 수 있다. 예를 들어, x와 y는 타겟 후보 영역의 중심점, 왼쪽 상단 모서리의 정점 등과 같이, 타겟 후보 영역에서 미리 결정된 임의의 정점의 가로 좌표 및 세 로 좌표일 수 있다. 또한, w와 h는 타겟 후보 영역의 너비(width)와 높이(height)를 나타낼 수 있다. 타겟 후보 영역들의 신뢰도(confidences) 및/또는 회귀 결과(regression results)에 따라, 복수의 타겟 후보 영역들(후보 앵커들) 중 하나의 타겟 후보 영역(최종 앵커(final anchor))이 선택된다. 선택된 타겟 후보 영역(최종 앵커(final anchor))의 신뢰도(confidence) 및/또는 회귀 결과(regression result)에 기초하여, 현재 프레임 이미지에서 타겟 객체의 위치 및 대응하는 검출 신뢰도(detection confidence)를 얻는다. 이렇게 검출된 타겟 객체에 관한 정보(information regarding the detected targetobject)가 출력된다. 또한, 현재 프레임 이미지에 대응하는 추적/검출 결과에 따라, 타겟 메모리를 갱신(update)한다. 예 를 들어, 검출된 타겟 후보 영역(최종 앵커(final anchor))이, 새로운 타겟 템플릿으로, 타겟 메모리에 추 가(add)된다. 이렇게, 타겟 메모리는 갱신되고, 갱신된 타겟 메모리는 다음 프레임 이미지의 타겟 객체의 검출 및/또는 추적에 사용된다. 일 실시예에 따르면, 프레임 이미지로부터 타겟 객체를 검출하는 단계는, 타겟 템플릿 세트 및 간섭 템플릿 세 트(interference templage set)에 기초하여, 상기 프레임 이미지로부터 타겟 객체를 검출하는 단계를 포함한다. 간섭 템플릿 세트는, 하나 이상의 간섭 템플릿(interference template)을 포함한다. 하나 이상의 간섭 템플릿 의 각각은, 비디오의 해당 프레임 이미지(subject frame image)의 이전 프레임 이미지들 중 상기 객체의 검출을 방해(interfere with the detection of the object)한 간섭 객체(interfere object)에 관한 정보를 포함한다. 일 실시예에 따르면, 프레임 이미지로부터 타겟 객체를 검출하는 단계는, 타겟 템플릿 세트에 기초하여 하나 이 상의 타겟 후보 영역을 획득하는 단계, 간섭 템플릿 세트에 기초하여, 상기 하나 이상의 타겟 후보 영역으로부 터 하나의 타겟 영역을 결정하는 단계, 및 상기 타겟 영역에 기초하여 타겟 객체를 검출하는 단계를 포함한다. 선택적으로, 현재 프레임 이미지로부터 타겟 객체를 검출할 때, 타겟 템플릿 세트 및 간섭 템플릿 세트에 따라, 현재 프레임 이미지에 대응하는 하나 이상의 타겟 후보 영역을 획득할 수 있으며, 구체적인 과정은 다음과 같다. 백본 네트워크를 통해, 메모리 풀의 타겟 템플릿 세트와 간섭 템플릿 세트로부터 이미지 특징들이 추출된다. 리콜 네트워크는, 추출된 이미지 특징들로부터 특징들을 융합한 융합 템플릿(integration template)을 획득한다. 현재 프레임 이미지에서 타겟 객체를 검출할 때, 현재 프레임 이미지의 여러 영역을 검색함으로써, 여러 검색 영역 박스들(search area box)이 얻어진다. 그 다음, 각 검색 영역 박스는 융합 템플릿과 매칭되고, 매칭 정도가 높은 하나 이상의 타겟 후보 영역이 획득(obtain)된다. 그 다음, 하나 이상의 타겟 후보 영역 중 에서 최종적으로 하나의 타겟 영역이 선택되고, 선택된 타겟 영역에 기초하여 현재 프레임 이미지에 대응하는 타겟 객체의 검출 결과가 획득된다. 선택적으로, 신경망 모델에서의 타겟 추적에 있어서, 타겟 메모리를 사용하는 것에 추가하여, 간섭 메모리가 사 용될 수 수 있으며, 구체적인 과정은 다음과 같다. 단계 1, 비디오 시퀀스로부터 제1 프레임 이미지가 선택된다. 단계 2, 사용자가 제1 프레임 이미지에서 타겟을 지시(indicate)한다. 지시(indication)에 따라, 제1 프레임 이미지에서 타겟 객체가 위치한 이미지 영역의 이미지 특징이 추출된다. 추출된 이미지 특징으로부터, 초기 타 겟 템플릿이 획득된다. 초기 타겟 템플릿은 타겟 템플릿 세트에 추가된다. 간섭 템플릿 세트는 비어(empty) 있다. 단계 3, 비디오 시퀀스의 제2 프레임 이미지가 선택된다. 타겟 템플릿 세트에 포함되어 있는 초기 타겟 템플릿 을 기반으로, 제2 프레임 이미지에서 타겟 객체의 타겟 위치가 예측되고, 예측 결과가 출력된다. 단계 4, 예측 결과를 기반으로, 제2 프레임 이미지에서 타겟 객체의 타겟 위치, 예측 신뢰도 등 추적 정보 (tracking information)가 출력된다. 단계 5, 제2 프레임 이미지의 예측 결과가 메모리 갱신 조건(memory update condition)을 만족하는지 여부가 판 단된다. 만족하는 경우, 타겟 템플릿 세트는 갱신되고, 그렇지 않은 경우 갱신되지 않는다. 예를 들어, 만족 하는 경우, 제2 프레임 이미지에 대응하는 타겟 템플릿이 타겟 템플릿 세트에 추가될 수 있다. 단계 6, 비디오 시퀀스의 제3 프레임 이미지가 선택된다. 이때, 타겟 템플릿 세트 및 간섭 템플릿 세트에 따라, 메모리 풀로부터 타겟 템플릿 세트 및 간섭 템플릿 세트가 로드(load)된다. 단계 7, 타겟 템플릿 세트 및 간섭 템플릿 세트에 기반하여, 후속 프레임 이미지(subsequent frame image)에서 타겟 객체의 타겟 위치가 예측되고, 예측 결과가 출력된다. 그 다음 후속 프레임에서도 동일한 방법으로 진행 된다. 상기의 방법을 보다 상세하게 설명하기 위하여 도 2에 도시된 예시를 참조하여 설명한다. 도 2는, 일 실시예에 따른 객체 추적 방법을 구현하는 신경말 모델을 도시한다. 도 2에서, 추적하려고 하는 타겟 객체는 특정 운동 선수(\"타겟 운동 선수(target player)\"라고 할 수 있음)이다. 현재 프레임 이미지(current frame image)는, 타겟 운동 선수를 검출하려고 하는 비디오 내 프레임 이미지이다. 도 2의 실시예에서, 사용자는, 비디오의 재생 중 타겟 객체(타겟 운동 선수)를 발견하면, 이 프레임 이미지에서 타겟 객체를 지시(indicate)한다. 그러면, 이 프레임 이미지의 부분(이 부분은 타겟 객 체를 포함함)의 정보가 초기 타겟 템플릿(initial target template)으로 사용된다. 메모리 풀(memory pool)은, 타겟 메모리(target memory)와 간섭 메모리(interference memory) 를 포함한다. 타겟 메모리는 타겟 템플릿 세트(target template set)를 저장하는 저장공간(storage space)이다. 간섭 메모리는 간섭 템플릿 세트(interference template set)를 저장하는 저장공간이다. 타겟 템플릿 세트는, 현재 프레임 이미지 이전의 프레임 이미지들에 대응하는 타겟 템플릿들을 저장한다. 타겟 템플릿은, 비디오의 프레임 이미지들에서 타겟 객체에 관한 정보이다. 예를 들어, 타겟 템플릿은, 타겟 객체를 포함하는 이미지 영역일 수 있으며, 또는 상기 이미지 영역의 특징 정보(feature information)일 수 있 다. 타겟 템플릿 세트는, 초기 타겟 템플릿를 더 저장할 수 있다. 간섭 템플릿 세트는, 현재 프레임 이미지 이전의 프레임 이미지들에 대응하는 간섭 템플릿들을 저장한다. 간섭 템플릿은, 비디오의 프레임 이미지들에서 타겟 객체의 검출을 방해한 간섭 객체에 관한 정보이다. 예를 들어, 간섭 템플릿은, 간섭 객체를 포함하는 이미지 영역일 수 있으며, 또는 상기 이미지 영역의 특징 정보 (feature information)일 수 있다. 일 실시예에서, 현재 프레임 이미지에서 타겟 객체를 검출하기 위하여, 현재 프레임 이미지의 전체 또는 일부(검색 영역)는, 백본 네트워크(backbone network)에 입력된다. 백본 네트워크는, 신경망을 이용하여 검색 영역 특징(search area feature)를 추출할 수 있다. 검색 영역 특징은, 검색 영역에 대응하는 이미지 특징(image feature)이다. 예를 들어, 백본 네트워크는, 현재 프레임 이미지의 검색 영역에 대응하는 검색 영역 특징으로, W x H x C를 출력할 수 있다. W x H x C는 특징맵(feature map)으로, W와 H는 각각 특징맵의 너비(width)와 높이(height)를 나타내고, C는 특징맵의 채널 수(즉, 특징의 수)를 나타낸다. 하나 이상의 타겟 후보 영역을 획득하기 위해, 메모리 풀의 타겟 메모리에 저장된 타겟 템플릿 세트 및 간섭 메모리에 저장된 간섭 템플릿 세트는 백본 네트워크에 입력된다. 백본 네트워크는, 타 겟 템플릿 세트의 각 타겟 템플릿에 대응하는 이미지 특징을 추출하고, 간섭 템플릿 세트의 각 간섭 템플릿에 대응하는 이미지 특징을 추출한다. 이 이미지 특징들은 리콜 네트워크로 입력된다. 일 실시예에 따르면, 프로세서는, 리콜 네트워크, 상관도 계산부(correlation calculater) 및 앵커 처리기(anchor processor)를 포함할 수 있다. 리콜 네트워크, 상관도 계산부(correlation calculater) 및 앵커 처리기(anchor processor)는, 기능에 따른 개념적인 구분이며, 반드시 물리적 으로 분리되어 구현될 필요는 없다. 예를 들어, 리콜 네트워크, 상관도 계산부(correlation calculater) 및 앵커 처리기(anchor processor)는, 모두 프로세서에 의해 처리되는 다른 기능 들일 수 있으며, 설명의 편의상 구분된 것이다. 리콜 네트워크는, 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특 징(image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)을 출력한다. 또한, 리 콜 네트워크는, 간섭 템플릿 세트에 포함된 간섭 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징 (image feature)을 융합(integrate)하여 간섭 융합 특징(integrated interference feature)을 출력한다. 리콜 네트워크는, 신경망을 이용하여 입력된 이미지 특징들을 융합하는 네트워크로서, FFCNN(feature fusion convolutional neural network) 등이 사용될 수 있으나, 이에 제한되지 않는다. 일 실시예에 따르면, 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징 (image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)이 결정된다. 그리고, 상 기 타겟 융합 특징에 기초하여, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역(target candidate area)가 획득(obtain)된다. 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역(target area)가 결정된다. 일 실시예에 따르면, 상관도 계산부(correlation calculater)는, 현재 프레임 이미지의 복수의 검색 영역들(search areas)의 각각에 대응하는 검색 영역 특징의 각각과 타겟 특징 커널(target feature kernel)(예를 들어, 타겟 융합 특징)의 상관도(correlation)를 계산한다. 상관도에 따라, 검색 영역들 중 하나 이상의 후보 앵커(타겟 후보 영역)이 결정된다. 예를 들어, 상관도의 값이 큰 K개의 후보 앵커(타겟 후보영역)가 선택되어, Top-K 후보 앵커(타겟 후보 영역)으로 기록된다. 일 실시예에 따르면, 상관도 계산부(correlation calculater)는, 또한, 검색 영역들(search areas)의 각 각에 대응하는 검색 영역 특징의 각각과 간섭 특징 커널(interference feature kernel)(예를 들어, 간섭 융합 특징)의 상관도(correlation)를 계산한다. 상관도에 따라, 검색 영역들 중 이 상관도(또는 매칭도)가 가 장 낮은 하나의 후보 앵커(타겟 후보 영역)가 선택된다. 선택된 후보 앵커(타겟 후보 영역)은 Bottom-1 후보 앵 커로 기록된다. 상관도 계산부(correlation calculater)에 의하여 생성된 상관도는 앵커 처리기(anchor processor) 에 입력된다. 앵커 처리기는 하나 이상의 타겟 후보 영역들(후보 앵커들)의 각각에 대한 신뢰도 (confidence) 및/또는 회귀 결과(regression results)를 출력할 수 있다. 일 실시예에서, 회귀 결과는 회귀 위 치(regression position) (x, y, w, h)를 포함할 수 있다. 여기서, x와 y는 대응하는 타겟 후보 영역의 특정 점(particular point)의 가로 좌표 및 세로 좌표를 나타낼 수 있다. 이에 기초하여, 현재 프레임 이미지 에서 타겟 객체의 위치 및 신뢰도가 결정될 수 있다. 타겟 후보 영역들의 신뢰도(confidences) 및/또는 회귀 결과(regression results)에 따라, 복수의 타겟 후보 영역들(후보 앵커들) 중 하나의 타겟 후보 영역(최종 앵커(final anchor))이 선택된다. 또한, 추적 결과에 따라 타겟 메모리와 간섭 메모리를 갱신하는 것도 가능하다. 예를 들어, 검출된 타겟 후보 영역(최종 앵커(final anchor))이, 새로운 타겟 템플릿으로, 타겟 메모리에 추가(add)될 수 있다. 또한, 최종적으로 선택된 타겟 후보 영역(최종 앵커(final anchor))을 제외한 복수의 타겟 후보 영역들(후보 앵커들) 중 일부 또는 전체가 간섭 메모리에 추가(add)될 수 있다. 일 실시예에서, 최종 앵 커와 가장 매칭도가 낮은 후보 앵커가 간섭 메모리에 추가될 수 있다. 도 3은 도 2에 따른 객체 추적 방법의 흐름도이다. 도 3을 참조하여, 도 2에 따른 객체 추적 방법이 설명된다. 단계에서, 타겟 메모리 및 간섭 메모리로부터, 각각, 타겟 템플릿 세트 및 간섭 템플릿 세트가 판독된다. 단계에서, 리콜 네트워크는, 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영 역의 이미지 특징(image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)(\"타겟 특징 커널(target feature kernel)\"이라고도 함)을 출력한다. 또한, 리콜 네트워크는, 간섭 템플릿 세트에 포함된 간섭 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특징(image feature)을 융합(integrat e)하여 간섭 융합 특징(integrated interference feature)(\"간섭 특징 커널(interference feature kernel)\"이 라고도 함)을 출력한다. 단계에서, 상관도 계산부(correlation calculater)는, 현재 프레임 이미지의 복수의 검색 영역 들(search areas)의 각각에 대응하는 검색 영역 특징의 각각과 타겟 융합 특징(타겟 특징 커널)의 상관도 (correlation)를 계산한다. 또한, 상관도 계산부(correlation calculater)는, 검색 영역들(search areas)의 각각에 대응하는 검색 영역 특징의 각각과 간섭 융합 특징(간섭 특징 커널)의 상관도 (correlation)를 계산한다. 단계에서, 단계의 상관도 계산 결과에 따라, 검색 영역들 중 하나 이상의 타겟 후보 영역이 결정된다. 단계에서, 하나 이상의 타겟 후보 영역의 신뢰도(confidences) 및/또는 회귀 결과(regression results)에 따라, 하나 이상의 타겟 후보 영역(후보 앵커) 중 하나의 타겟 후보 영역(최종 앵커(final anchor))이 선 택된다. 즉, 현재 프레임 이미지에서 타겟 객체를 포함하는 것으로 판단되는 하나의 타겟 영역(target area)이 결정된다. 이는, 현재 프레임 이미지에서 타겟 객체의 위치를 결정하는 것과 동일한 동작으로 이 해된다. 단계에서, 검출 결과에 따라, 타겟 메모리 및 간섭 메모리가 갱신된다. 도 4는 일 실시예에 따른 객체 추적 방법의 메모리 매칭을 설명하기 위한 도면이다. 도 4에 도시된 바와 같이, 메모리 풀은 타겟 메모리와 간섭 메모리를 포함한다. 타겟 메모리 는 타겟 템플릿 세트(target template set)를 저장한다. 간섭 메모리는 간섭 템플릿 세트 (interference template set)를 저장한다. 메모리 풀의 타겟 메모리에 저장된 타겟 템플릿 세트 및간섭 메모리에 저장된 간섭 템플릿 세트는 백본 네트워크에 입력된다. 백본 네트워크는, 타겟 템플릿 세트의 각 타겟 템플릿에 대응하는 이미지 특징을 추출한다. 백본 네트워 크는, 간섭 템플릿 세트의 각 간섭 템플릿에 대응하는 이미지 특징을 추출한다. 리콜 네트워크(recall network)는, 백본 네트워크로부터 수신한 타겟 템플릿들에 대응하는 이미지 특 징들(image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)을 생성한 다. 리콜 네트워크(recall network)는, 백본 네트워크로부터 수신한 간섭 템플릿들에 대응하는 이미 지 특징들(image feature)을 융합(integrate)하여 간섭 융합 특징(integrated intereference feature)457)을 생성한다. 상관도 계산부(correlation calculater)는, 현재 프레임 이미지의 복수의 검색 영역들(search areas)의 각각에 대응하는 검색 영역 특징의 각각과 타겟 융합 특징의 상관도(correlation)를 계산한다. 또한, 상관도 계산부(correlation calculater)는, 복수의 검색 영역들(search areas)의 각각에 대응하는 검색 영역 특징의 각각과 간섭 융합 특징의 상관도(correlation)를 계산한다. 상관도 계산부(correlation calculater)에 의하여 생성된 상관도는 앵커 처리기(anchor processor) 에 입력된다. 앵커 처리기는, 예를 들어, 신경망을 이용하여, 매칭 정도에 기초하여, 하나 이상의 앵커 (anchor)를 출력할 수 있다. 앵커 처리기는, 상관도 계산부에 의하여 출력된 검색 영역들의 각각에 대응하는 검색 영역 특징의 각각과 타겟 융합 특징의 상관도에 기초하여, K개의 앵커들(검색 영역 들)을 선택할 수 있다. 예를 들어, 상기 상관도에 기초한 매칭 정도에 따라, 매칭 정도가 높은 K개의 앵커들 (검색 영역들)이 선택될 수 있다. K는 1보다 크거나 같은 정수로 실시예에 따라 선택될 수 있다. 예를 들어, K는 3일 수 있다. 선택된 K개의 앵커들은, Top-K 앵커로 저장된다. Top-K 앵커는 타겟 후보 영역이 된다. 일 실시예에 따르면, 상관도 계산부(correlation calculater)는, Top-K 앵커들의 각각(또는 Top-K 앵커들의 각각에 대응하는 특징 정보)과 간섭 융합 특징의 상관도를 계산한다. 상관도 계산부 에 의하여, 타겟 후보 영역들과 간섭 융합 특징의 매칭 정도가 계산된다. 타겟 후보 영역들 중 간섭 융합 특징과 가장 낮은 매칭 정도를 가지는 하나의 타겟 후보 영역(후보 앵커)이 Bottom-1 앵커로 선 택된다. 이 선택된 Bottom-1 앵커가 타겟 객체의 타겟 영역으로 결정된다. 타겟 영역은, 현재 프레임 이 미지에서 타겟 객체가 위치하는 것으로 판단되는 위치에 대응(correspond)한다. 선택된 타겟 영역의 신뢰도(confidence) 및/또는 회귀 결과(regression result)에 기초하여, 현재 프레임 이미지에서의 타겟 객체의 위치에 대한 신뢰도(detection confidence)가 계산된다. 도 1, 도 2 및 도 4에 도시된 구성들은, 설명의 목적을 위한, 예시적인 것임을 이해할 수 있다. 실시예들은 이 러한 구성들에 제한되지 않는다. 예를 들어, 도 1, 도 2 및 도 4의 메모리 풀의 타겟 메모리에 저장된 타겟 템 플릿들 및 간섭 메모리에 저장된 간섭 템플릿들은 예시적이며, 비디오의 후속 프레임들에 따라 갱신될 수 있다. 도 1의 실시예와 도 2의 실시예의 차이점은, 도 1의 실시예는 타겟 객체를 검출하기 위하여 타겟 메모리(또는 타겟 템플릿들)를 사용하고, 도 2의 실시예는 타겟 객체를 검출하기 위하여 타겟 메모리(또는 타겟 템플릿들) 및 간섭 메모리(또는 간섭 템플릿들)을 함께 사용한다는 것이다. 실시예들을 통해, 타겟 메모리 및/또는 간섭 메모리에 기초하여 타겟 객체가 검출될 수 있다. 이러한 실시예들 을 사용하면, 타겟 객체가 이동할 때, 타겟 객체의 다양한 변화를 보다 포괄적으로 기록하고, 검출 정확도를 효 과적으로 향상시킬 수 있다. 일 실시예에 따르면, 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역을 결정하는 단계는, 상기 하나 이 상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과 의 매칭 정도(matching degree)를 계산하는 단계, 상기 하나 이상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도(matching degree)를 계산하는 단계, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도 및 상기 타겟 후 보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도에 기초하여, 상기 타겟 후보 영역의 각각의 타겟 매칭 정도를 계산하는 단계, 및 상기 타겟 후보 영역의 각각의 타겟 매칭 정도에 기초하여, 상기 하나 이상의 타겟 후보 영역 중 하나의 타겟 영역을 결정하는 단계를 포함한다. 이 실시예에서, 각 타겟 후보 영역과 각 타겟 템플릿 간의 매칭 정도가 얻어지며, 이는 제1 매칭 정도로 기록 (record)될 수 있다. 임의의 타겟 후보 영역에 대해, 타겟 후보 영역과 간섭 템플릿 세트의 각 간섭 템플릿 간의 매칭 정도가 계산되고, 타겟 후보 영영과 간섭 템플릿들 간의 복수의 매칭 정도가 얻을 질 수 있다. 이 복 수의 매칭 정도의 평균값(또는 중앙값)은, 해당 타겟 후보 영역과 간섭 템플릿 간의 매칭 정도로 선택된다. 각 타겟 후보 영역과 각 간섭 템플릿 간의 매칭 정도도 계산될 수 있고, 이는 제2 매칭 정도로 기록될 수 있다. 제1 매칭 정도의 값과 제2 매칭 정도의 값을 각각 1:1 대응하여 감산함으로써, 제1 타겟 매칭 정도(first target matching degree)가 계산될 수 있다. 제1 타겟 매칭 정도의 값이 가장 큰 타겟 후보 영역은 타겟 영역 으로 식별(identify)된다. 실시예에 따르면, 매칭 정도에 따라, 타겟 메모리와의 매칭도가 높고 간섭 메모리와의 매칭도가 낮은 타겟 후보 영역이 타겟 영역으로 식별될 수 있다. 이에 따르면, 현재 추적하는 타겟 객체를 타겟 템플릿들에 최대한 가까 운 객체를 선택할 수 있도록 하고, 동시에 간섭 템플릿들의 영향을 가장 적게 받는 객체를 선택할 수 있도록 한 다. 따라서, 타겟 객체의 검출의 정확도가 높아진다. 일 실시예에서, 타겟 템플릿 세트의 각 타겟 템플릿과 간섭 템플릿의 각 간섭 템플릿을 이용하여 타겟 객체의 검출 결과를 획득할 수 있다. 구체적으로, 타겟 템플릿 세트의 각 타겟 템플릿과 간섭 템플릿의 각 간섭 템플 릿을 각각 프레임 이미지 내 일부분에 대응하는 복수의 검색 영역 박스의 각각과 일대일 매칭시킴으로써, 하나 이상의 타겟 후보 영역을 획득할 수 있다. 그 다음, 상기 하나 이상의 타겟 후보 영역으로부터 타겟 객체에 대 응하는 하나의 타겟 영역을 선택하고, 상기 타겟 영역을 기초로 타겟 객체의 검출 결과를 획득할 수 있다. 상기는 예시일 뿐, 본 실시예는 이에 한정되지 않는다. 도 5는 일 실시예에 따른 간소화된 객체 검출 방법(light-weight object detection method)를 설명하기 위한 도면이다. 도 5에 도시된 바와 같이, 메모리 풀(memory pool)은, 타겟 메모리(target memory)와 간섭 메모리 (interference memory)를 포함한다. 타겟 메모리는 타겟 템플릿 세트(target template set)를 저장 한다. 간섭 메모리는 간섭 템플릿 세트(interference template set)를 저장한다. 본 실시에서, 타겟 템 플릿 세트에 포함되는 타겟 템플릿들의 각각은 대응하는 이미지 영역의 특징 벡터(feature vector)이다. 즉, 도 5에서, 는 타겟 메모리에 저장된 타겟 템플릿 세트 내 i번째 타겟 템플릿의 특징 벡터를 나타낸다 (denote). 또한, 간섭 템플릿 세트에 포함되는 간섭 템플릿들의 각각은 대응하는 이미지 영역의 특징 벡터 (feature vector)이다. 즉, 도 5에서, 는 간섭 메모리에 저장된 간섭 템플릿 세트 내 i번째 간섭 템플릿의 특징 벡터를 나타낸다. 도 5의 실시예에서 제1 프레임 이미지에 대응하는 타겟 템플릿은 타겟 메모리에 저장되지 않고, 별도로 입 력될 수 있다. 제1 프레임 이미지로부터 추출된 템플릿 이미지를 백본 네트워크 및 조정 레이어 (adjustment layer)를 통하여 처리함으로써, 초기 타겟 템플릿(initial target template)이 얻어진 다. 일 실시예에 따르면, 제1 프레임 이미지로부터 추출된 템플릿 이미지는, 비디오의 프레임 이미지들 중 타 겟 객체를 포함하는 것으로 사용자에 의하여 결정된 검색 영역(이미지 영역)의 이미지일 수 있다. 또 다른 실 시예에 따르면, 제1 프레임 이미지는 타겟 객체를 포함하는 이미지로서, 상기 비디오와 독립(independent)된 별 도의 이미지(separate image)일 수 있다. 타겟 템플릿은, 앞에서 설명한 바와 같이, 대응하는 이미지의 이미지 특성(image feature)을 나타낸다(represent). 현재 프레임 이미지로부터 복수 개의 검색 영역이 선택된다. 복수 개의 검색 영역은 현재 프레임 이미지 를 복수 개로 분할한 영역들일 수 있다. 복수 개의 검색 영역들은 서로 일부 영역이 중복될 수 있다. 이 전 프레임에서 타겟 객체의 타겟 영역이 결정된 경우, 이전 프레임의 타겟 영역의 위치에 기반하여, 현재 프레 임에서 복수 개의 검색 영역들을 결정될 수 있다. 복수 개의 검색 영역들의 각각을 백본 네트워크 및 조 정 레이어(adjustment layer)를 통하여 처리함으로써, 검색 영역에 대응하는 검색 영역 특징이 얻어 진다. 백본 네트워크(540, 550)는, 신경망을 이용하여 이미지의 특징(features)을 추출하는 네트워크로서, MobileNet, ResNet, Xception Network 등이 사용될 수 있으나, 이에 제한되지 않는다. 도 5에서, 백본 네트워크에 의하여 출력된 특징 정보(feature information)은 조정 레이어(553, 543)에 의하여 조정(adjust)되지만, 실시예에 따 라서 생략될 수 있다. 조정 레이어(553, 543)는 백본 네트워크에 의하여 출력된 특징 정보(feature information) 중 일부 정보만을 추출(extract)하거나 특징 정보의 값을 조정할 수 있다.상관도 계산부(correlation calculater)는, 검색 영역에 대응하는 검색 영역 특징과 초기 타겟 템플 릿(initial target template)의 상관도(correlation)를 계산한다. 예를 들어, 상관도 계산부는 깊 이 상관 방법(depthwise correlation method)를 사용하여, 상관도를 계산할 수 있다. 상관도 계산부(correlation calculater)에 의하여 생성된 상관도는 앵커 처리기(anchor processor) 에 입력된다. 앵커 처리기는, 상기 상관도에 기초한 매칭 정도에 따라, 매칭 정도가 높은 K개의 앵커들 (검색 영역들)을 Top-K 앵커들로 선택한다. 선택된 앵커(검색 영역)는 타겟 후보 영역으로 식별된다. K개의 타겟 후보 영역들의 각각에 대하여, 예를 들어 계산기(computing function)에 의하여, 수학식 1의 스코어(score)가 계산된다. 수학식 1"}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 타겟 메모리에 저장된 타겟 템플릿 세트 내 i번째 타겟 템플릿의 특징 벡터를 나타낸다(denote). 는 간섭 메모리에 저장된 간섭 템플릿 세트 내 i번째 간섭 템플릿의 특징 벡터를 나타낸다. 는 K개의 타 겟 후보 영역들(Top-K 앵커들) 중 k번째 타겟 후보 영역(앵커)의 특징 벡터를 나타낸다. 는 와 의 상관도를 계산한 매칭값을 나타낸다. 는 타겟 메모리에 저장된 타겟 템플릿 세트 내 i번째 타겟 템플릿의 가중치를 나타낸다. 는 간섭 메모리에 저장된 간섭 템플릿 세트 내 i번째 간섭 템플릿의 가중치를 나타낸다. m1은 타겟 템플릿 세트에 포함된 타겟 템플릿들의 개수이고, m2는 간섭 템플릿 세트에 포함된 간섭 템플릿들의 개수이다. 그리고, 수학식 1에 의하여 계산된 스코어가 가장 큰 타겟 후보 영역이 타겟 영역(최종 앵커)로 선택된다. 이는 수학식 2로 나타낼 수 있다. 수학식 2"}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 1과 수학식 2를 통해, 타겟 템플릿 세트들에 포함된 타겟 템플릿들과는 가장 유사하면서, 간섭 템플릿 세트들에 포함된 간섭 템플릿들과는 가장 덜 유사한 타겟 후보 영역이 타겟 영역(최종 앵커)로 선택된다. 타겟 템플릿들의 수(m1) 및 간섭 템플릿들의 수(m2)는, 타겟 객체를 식별할 현재 프레임 이미지에 따라 다를 수 있다. 실시예에 따라, 타겟 템플릿 세트 내 모든 타겟 템플릿들의 가중치의 합은 1이고, 초기 타겟 템플릿의 가중치가 가장 높게 설정될 수 있다. 그러나, 타겟 템플릿들의 가중치의 설정 방법은 이에 제한되지 않고, 다양한 방법 으로 설정될 수 있다. 실시예에 따라, 간섭 템플릿 세트 내 모든 간섭 템플릿들의 가중치의 합은 1이고, 각 간섭 템플릿의 가중치는 각 간섭 템플릿이 위치한 이미지 영역과 타겟 객체가 위치한 이미지 영역 사이의 거리에 따라 설정될 수 있다. 그러나, 간섭 템플릿들의 가중치의 설정 방법은 이에 제한되지 않고, 다양한 방법으로 설정될 수 있다. 일 실시예에 따르면, 제1 프레임 이미지에 대응하는 이미지 특징(초기 타겟 템플릿)을 추출한 후, 이 초기 타겟 템플릿은 타겟 메모리에 저장될 수 있다. 그러면, 그 다음부터는 초기 타겟 템플릿을 타겟 메모리로 부터 로드(load)하여 사용할 수 있다. 도 6은 다른 실시예에 따른 간소화된 객체 검출 방법(light-weight object detection method)를 설명하기 위한 도면이다. 도 6에 도시된 바와 같이, 메모리 풀(memory pool)은, 타겟 메모리(target memory)만을 포함하고, 간섭 메모리(interference memory)는 포함하지 않는다. 타겟 메모리는 타겟 템플릿 세트(target template set)를 저장한다. 본 실시에서, 타겟 템플릿 세트에 포함되는 타겟 템플릿들의 각각은 대응하는 이미지 영역의 특징 벡터(feature vector)이다. 즉, 도 6에서, 는 타겟 메모리에 저장된 타겟 템플릿 세트 내 i번째 타겟 템플릿의 특징 벡터를 나타낸다(denote). 현재 프레임 이미지로부터 복수 개의 검색 영역이 선택된다. 복수 개의 검색 영역들의 각각은, 백본 네트 워크 및 조정 레이어(adjustment layer)를 통하여 처리되고, 검색 영역에 대응하는 검색 영역 특징 이 얻어진다. 타겟 객체를 포함하는 초기 이미지는, 백본 네트워크 및 조정 레이어(adjustment layer)를 통하 여 처리되고, 초기 이미지에 대응하는 이미지 특징이 얻어진다. 이 이미지 특징은 초기 타겟 템플릿(initial target template)으로 사용된다. 상관도 계산부(correlation calculater)는, 검색 영역에 대응하는 검색 영역 특징과 초기 타겟 템플 릿(initial target template)의 상관도(correlation)를 계산한다. 상관도 계산부(correlation calculater)에 의하여 생성된 상관도는 앵커 처리기(anchor processor)에 입력된다. 앵커 처리기 는, 상기 상관도에 기초하여, 상관도가 높은 K개의 앵커들(검색 영역들)을 Top-K 앵커들로 선택한다. 선택된 앵커(검색 영역)는 타겟 후보 영역으로 식별된다. K개의 타겟 후보 영역들의 각각에 대하여, 예를 들어 계산기(computing function)에 의하여, 에 의하 여, 수학식 3의 스코어(score)가 계산된다. 수학식 3"}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 타겟 메모리에 저장된 타겟 템플릿 세트 내 i번째 타겟 템플릿의 특징 벡터를 나타낸다(denote). 는 K개의 타겟 후보 영역들(Top-K 앵커들) 중 k번째 타겟 후보 영역(앵커)의 특징 벡터를 나타낸다. 는 와 의 상관도를 계산한 매칭값을 나타낸다. 는 타겟 메모리에 저장된 타겟 템플릿 세트 내 i번째 타겟 템플릿의 가중치를 나타낸다. m1은 타겟 템플릿 세트에 포함된 타겟 템플릿들의 개수이다. 그리고, 수학식 3에 의하여 계산된 스코어가 가장 큰 타겟 후보 영역(Top-1 앵커)이 타겟 영역(최종 앵커)(69 0)로 선택된다. 이는 수학식 4로 나타낼 수 있다. 수학식 4"}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "일 실시예에 따르면, 초기 타겟 템플릿은, 위에서 설명된 발명과 다르게, 타겟 템플릿 세트에 포함된 타겟 타겟 템플릿들의 모두 또는 일부의 융합 템플릿으로 대체될 수 있다. 일 실시예에 따른 방법은, 상기 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이 미지 특징(image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)을 결정하고, 상 기 타겟 융합 특징에 기초하여, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역(target candidate area)을 획득할 수 있다. 그리고, 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역(target area)가 결정된다.상기 하나 이상의 타겟 후보 영역을 획득하는 단계는, 상기 프레임 이미지 내에서 복수의 검색 영역을 결정하는 단계, 상기 복수의 검색 영역의 각각의 이미지 특징을 추출(extract)하여 검색 영역 특징(search area featur e)를 획득하는 단계, 상기 복수의 검색 영역의 각각의 검색 영역 특징과 상기 타겟 융합 특징의 상관도 (correlation)를 계산하는 단계, 및 상기 상관도에 기초하여 상기 복수의 검색 영역 중 상기 하나 이상의 타겟 후보 영역을 결정하는 단계를 포함할 수 있다. 일 실시예에서, 하나 이상의 타겟 후보 영역으로부터 타겟 영역을 결정할 때, 아래의 방법이 사용될 수 있다. 임의의 타겟 후보 영역에 대해, 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도를 계산하여, 복수의 매칭 정 도를 얻는다. 해당 복수의 매칭 정도의 평균값은, 해당 타겟 후보 영역과 타겟 템플릿 간의 매칭 정도로 취해 질 수 있다. 마지막으로, 각 타겟 후보 영역 중 상기 매칭 정도가 가장 높은 타겟 후보 영역을 최종 타겟 영역 으로 취한다. 일 실시예에 따르면, 최종 타겟 영역이 미리 결정된 조건을 만족하는 경우, 타겟 템플릿 세트를 갱신(update)하 는 단계를 더 포함할 수 있다. 상기 타겟 템플릿 세트를 갱신하는 단계는, 상기 타겟 템플릿 세트의 타겟 융합 특징 및 최종 타겟 영역의 유사 도(similarity)를 계산하는 단계, 및 상기 유사도가 임계값보다 작은 경우, 최종 타겟 영역을 타겟 템플릿으로 상기 타겟 템플릿에 추가(add)하는 단계를 포함할 수 있다. 상기 타겟 템플릿 세트를 갱신하는 단계는, 상기 타겟 템플릿 세트의 모든 타겟 템플릿들의 각각 및 최종 타겟 영역의 유사도(similarity)를 계산하는 단계, 및 상기 유사도의 모두가 임계값보다 작은 경우, 최종 타겟 영역 을 타겟 템플릿으로 상기 타겟 템플릿에 추가(add)하는 단계를 포함할 수 있다. 선택적으로, 최종 타겟 영역과 타겟 템플릿 세트 중 각 타겟 템플릿 간의 유사도(similarity)를 계산할 수 있다. 계산된 유사도의 모두가 설정된 임계값(예, 0.9 등) 이하이면, 최종 타겟 영역에 대응하는 타겟 템플릿 이 타겟 템플릿 세트에 추가될 수 있다. 또는, 계산된 유사도에 대응하는 융합 유사도(예, 계산된 유사도들의 평균값)가 설정된 임계값(예, 0.9 등) 이하이면, 최종 타겟 영역에 대응하는 타겟 템플릿이 타겟 템플릿 세트에 추가될 수 있다. 이에 따르면, 최종 타겟 영역이 기존의 타겟 템플릿 세트에 포함된 타겟 템플릿들과 유사한 경우, 타겟 템플릿 세트에 포함되지 않는다. 이미 포함된 타겟 템플릿들과 유사한 최종 타겟 영역은, 기존의 타겟 템플릿 세트의 성능을 크게 향상시키지 않기 때문이다. 또한, 타겟 템플릿 세트의 갱신을 통해 타겟 템플릿 세트가 타겟 객체 의 최신 특징을 포함할 수 있으므로, 타겟 템플릿 세트의 무결성(integrity)을 향상시킨다. 일 실시예에 따르면, 상기 간섭 템플릿 세트를 갱신(update)하는 단계를 더 포함할 수 있다. 일 실시예에서, 하나 이상의 타겟 후보 영역 중 최종 타겟 영역을 제외한 다른 타겟 후보 영역의 일부 또는 전 부를 간섭 템플릿으로 상기 간섭 템플릿에 추가(add)할 수 있다. 예를 들어, Top-K 앵커 중 Bottom-1 앵커 이 외의 앵커에 대응하는 이미지 영역(또는 이 이미지 영역의 이미지 특징)이 간섭 템플릿으로 선택될 수 수 있다. 대안적인 실시예에 따르면, 하나 이상의 타겟 후보 영역 중 최종 타겟 영역을 제외한 다른 타겟 후보 영역의 일 부 또는 전부에 대해, 간섭 템플릿 세트의 간섭 융합 특징과의 유사도가 계산된다. 계산된 유사도가 임계값보 다 작은 타겟 후보 영역은, 간섭 템플릿으로 간섭 템플릿에 추가될 수 있다. 이에 따르면, 간섭 템플릿에 추가 될 것으로 선택된 후보 간섭 영역(candidate interference area)이 기존의 간섭 템플릿 세트에 포함된 간섭 템 플릿들과 유사한 경우, 간섭 템플릿 세트에 포함되지 않는다. 이미 포함된 간섭 템플릿들과 유사한 후보 간섭 영역은, 기존의 간섭 템플릿 세트의 성능을 크게 향상시키지 않기 때문이다. 일 실시예에 따르면, 프레임 이미지 중 타겟 객체가 위치한 타겟 영역 및 해당 타겟 객체에 대한 가능 간섭 객 체(possible interference object)가 위치한 후보 간섭 영역(이미지 영역)이 획득된다. 가능 간섭 객체가 위치 하는 후보 간섭 영역에 대해, 해당 후보 간섭 영역과 타겟 영역 간의 제1 유사도 및 해당 후보 간섭 영역과 간 섭 템플릿 세트 중의 각 간섭 템플릿 간의 제2 유사도를 결정한다. 각 가능 간섭 객체가 위치한 후보 간섭 영 역에 대한 제1 유사도 및 제2 유사도에 기초하여, 간섭 템플릿 세트의 갱신 여부를 결정한다. 일 실시예에 따르면, 임의의 가능 간섭 객체가 위치한 이미지 영역(후보 간섭 영역)에 대하여, 해당 이미지 영 역과 타겟 영역의 제1 유사도(해당 제1 유사도는 해당 이미지 영역과 타겟 영역 사이의 거리를 나타낼 수 있 음)을 결정하고, 해당 이미지 영역과 간섭 템플릿 세트 중 각 간섭 템플릿의 제2 유사도(해당 제2 유사도는 해 당 이미지 영역과 각 간섭 템플릿의 유사도를 나타낼 수 있음)을 결정할 수 있다. 그런 다음, 제1 유사도와 제2 유사도에 기초하여, 후보 간섭 영역들 중에서 간섭 템플릿 세트에 포함할 후보 간섭 영역을 결정할 수 있다. 예를 들어, 제1 유사도가 크고, 제2 유사도가 작은 후보 간섭 영역을 간섭 템플릿 세트에 포함할 후보 간섭 영 역으로 선택할 수 있다. 이하, 도면을 참조하여 타겟 메모리 및/또는 간섭 메모리의 갱신(update)을 설명한다. 도 7은 일 실시예에 따른 메모리 갱신을 설명하기 위한 도면이다. 도 7에 도시된 바와 같이, 최종적으로 선택된 Bottom-1 앵커는, 현재 프레임 이미지에서 타겟 객체가 위치 하는 것으로 판단된 이미지 영역에 대한 정보이다. 즉, Bottom-1 앵커는 타겟 영역(최종 앵커)이다. Bottom-1 앵커는, 이미지 영역일 수 있고, 또는 상기 이미지 영역에 대한 이미지 특징(image feature)을 나타내는 특징 맵(feature map)일 수 있으나, 이에 제한되지 않는다. 타겟 객체의 검출 결과(예를 들어, Bottom-1 앵커)와 타겟 메모리에 저장된 타겟 템플릿 세트의 타겟 템플릿들이 비교된다. 타겟 객체의 검출 결과와 타겟 템플릿 세트의 유사도(similarity)이 임계값 미만인지 판 단한다. 일 예에서, 타겟 템플릿 세트의 모든 타겟 템플릿들의 각각 및 타겟 영역의 유사도(similarity) 가 계산된다. 다른 예에서, 타겟 템플릿 세트의 타겟 융합 특징 및 상기 타겟 영역의 유사도(similarity)가 계 산된다. 다시 말하면, 검출된 타겟 영역이 타겟 메모리에 이미 저장되어 있는 타겟 템플릿들과 어느 정도 유사한지를 판단한다. 유사도가 임계값(예를 들어, 90%) 미만이면, 검출된 타겟 영역에 기초하여, 타겟 메모리에 저장된 타겟 템플릿 세트가 갱신된다. 예를 들어, 검출된 타겟 영역은, 새로운 타겟 템플릿으로, 타겟 템플릿 세트에 추가(add)된다. 유사도가 임계값(예를 들어, 90%) 이상이면, 타겟 메모리 는 갱신되지 않는다. Top-K 후보 앵커들 중에서, 타겟 영역으로 선택된 Bottom-1 앵커를 제외한 나머지 앵커들 중 Bottom- K2 후보 앵커들을 후보 간섭 앵커들(candidate interference anchors)로 선택한다. Top-K 후보 앵커들 중 Bottom-1 앵커를 찾기 위하여, 타겟 템플릿 세트 및 간섭 템플릿 세트를 이용하여, Top-K 후보 앵커들에 대한 매칭 정도가 계산된다. Top-K 후보 앵커들 중 가장 큰 매칭 정도를 가지는 앵커가 Bottom-1 앵커로 선택된다. 그리고, Top-K 후보 앵커들 중 작은 점수의 매칭 정도를 가지는 K2개의 앵커들이 Bottom-K2 후보 앵커들로 결정된다. 후보 간섭 앵커들의 각각과 현재 프레임 이미지에서 검출된 타겟 객체(타겟 영역)의 위치 사이의 거리가 계산된다. 후보 간섭 앵커와 타겟 객체의 위치 사이의 거리가 임계값도다 큰지 여부가 판단된다. 상기 거리가 임계값보다 큰 경우, 이 후보 간섭 앵커는, 간섭 객체에 포함될 수 있다. 상기 거리가 임계값보다 작은 경우, 이 후보 간섭 앵커는, 간섭 객체가 아닌 것으로 간주되고, 이 후보 간섭 앵커에 관한 정보는 버려진 다(discard). 선택된 간섭 객체와 간섭 메모리에 저장된 간섭 템플릿 세트의 간섭 템플릿들이 비교된다. 간섭 객 체와 간섭 템플릿 세트의 유사도(similarity)가 임계값 미만인지 판단한다. 일 예에서, 간섭 템플릿 세트 의 모든 간섭 템플릿들의 각각 및 간섭 객체의 유사도(similarity)가 계산된다. 다른 예에서, 간섭 템플 릿 세트의 간섭 융합 특징 및 간섭 객체의 유사도가 계산된다. 다시 말하면, 검출된 간섭 객체가 간 섭 메모리에 이미 저장되어 있는 간섭 템플릿들과 어느 정도 유사한지를 판단한다. 유사도가 임계값(예를 들어, 90%) 미만이면, 검출된 간섭 객체에 기초하여, 간섭 메모리에 저장된 간섭 템플릿 세트가 갱신 된다. 예를 들어, 검출된 간섭 객체는, 새로운 간섭 템플릿으로, 간섭 템플릿 세트에 추가(add)된다. 유 사도가 임계값(예를 들어, 90%) 이상이면, 간섭 메모리는 갱신되지 않는다. 일 실시예에 따르면, 타겟 객체의 검출 결과에 따라, 타겟 템플릿 세트 및 간섭 템플릿 세트에 대한 유지 (maintenance) 및 갱신이 수행될 수 있다. 즉, 타겟 메모리와 간섭 메모리를 최신 상태로 유지하여, 다음 타겟 객체의 검출를 위해, 보다 풍부하고 다양한 정보를 제공하고, 검출 정확도를 향상시킬 수 있다. 표 1은, 타겟 메모리와 간섭 메모리를 모두 이용하지 않은 경우(타겟 템플릿 세트와 간섭 템플릿 세트를 모두 이용하지 않은 경우)(case 1), 타겟 메모리만 이용한 경우(타겟 템플릿 세트만 이용한 경우)(case 2), 타겟 메 모리와 간섭 메모리를 모두 이용한 경우(타겟 템플릿 세트와 간섭 템플릿 세트를 모두 이용한 경우)(case 3)의 객체 검출/추적의 성공률 및 정확도를 나타낸다.표 1"}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "표 1에서 설명된 바와 같이, 타겟 메모리만 이용한 경우(타겟 템플릿 세트만 이용한 경우)(case 2), 및 타겟 메 모리와 간섭 메모리를 모두 이용한 경우(타겟 템플릿 세트와 간섭 템플릿 세트를 모두 이용한 경우)(case 3) 모 두, 타겟 메모리와 간섭 메모리를 모두 이용하지 않은 경우(타겟 템플릿 세트와 간섭 템플릿 세트를 모두 이용 하지 않은 경우)(case 1)와 비교하여, 성공률 및 정확도가 향상되었음을 알 수 있다. 또한, 타겟 메모리와 간 섭 메모리를 모두 이용한 경우(타겟 템플릿 세트와 간섭 템플릿 세트를 모두 이용한 경우)(case 3)가, 타겟 메 모리만 이용한 경우(타겟 템플릿 세트만 이용한 경우)(case 2)와 비교하여, 정확도가 향상되었음을 알 수 있 다.도 8은 일 실시예에 따른 객체 검출 장치의 블록도이다. 객체 검출 장치는, 메모리와 프로세서를 포함하는 전자 장치로 구현될 수 있다. 객체 검출 장치는, 복수의 프레임 이미지들을 포함하는 비디오의 프레임 이미지(a frame image of a video comprising a plurality of frame images)로부터 객체(object)를 검출(detect)하는 타겟 객체 처리 모듈을 포함할 수 있다. 객체 검출 장치는, 타겟 템플릿 세트(target tempage set)에 기초하여, 상기 프레임 이미지로부터 상기 객 체를 검출하고, 상기 검출된 객체에 관한 정보(information regarding the detected object)를 출력(output)할 수 있다. 객체 검출 장치는, 타겟 템플릿 세트에 포함된 타겟 템플릿들의 각각에 대응하는 이미지 영역의 이미지 특 징(image feature)을 융합(integrate)하여 타겟 융합 특징(integrated target feature)을 결정하고, 타겟 융합 특징에 기초하여, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영 역(target candidate area)을 획득할 수 있다. 객체 검출 장치는, 상기 하나 이상의 타겟 후보 영역으로 부터 하나의 타겟 영역(target area)을 결정할 수 있다. 객체 검출 장치는, 프레임 이미지 내에서 복수의 검색 영역을 결정하고, 복수의 검색 영역의 각각의 이미 지 특징을 추출(extract)하여 검색 영역 특징(search area feature)를 획득할 수 있다. 객체 검출 장치 는, 상기 복수의 검색 영역의 각각의 검색 영역 특징과 상기 타겟 융합 특징의 상관도(correlation)를 계산하고, 상기 상관도에 기초하여 상기 복수의 검색 영역 중 상기 하나 이상의 타겟 후보 영역을 결정할 수 있 다. 객체 검출 장치는, 타겟 템플릿 세트의 상기 타겟 융합 특징 및 상기 타겟 영역의 유사도(similarity)를 계산할 수 있다. 객체 검출 장치는, 상기 유사도가 임계값보다 작은 경우, 상기 타겟 영역을 타겟 템플릿 으로 상기 타겟 템플릿에 추가(add)함으로써, 타겟 템플릿 세트를 갱신할 수 있다. 객체 검출 장치는, 타겟 템플릿 세트의 모든 타겟 템플릿들의 각각 및 검출된 타겟 영역의 유사도 (similarity)를 계산할 수 있다. 객체 검출 장치는, 상기 유사도의 모두가 임계값보다 작은 경우, 상기 타 겟 영역을 타겟 템플릿으로 상기 타겟 템플릿에 추가(add)함으로써, 타겟 템플릿 세트를 갱신할 수 있다. 객체 검출 장치는, 타겟 템플릿 세트 및 간섭 테플릿 세트에 기초하여, 상기 프레임 이미지 내에서 상기 객체를 포함하는 것으로 판단되는 하나 이상의 타겟 후보 영역(target candidate area)을 획득할 수 있다. 객체 검출 장치는, 상기 하나 이상의 타겟 후보 영역으로부터 하나의 타겟 영역(target area)을 결정할 수 있다. 객체 검출 장치는, 하나 이상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도(matching degree)를 계산할 수 있다. 객체 검출 장치는, 상기 하나 이상의 타겟 후보 영역의 각각에 대해, 상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각 간 섭 템플릿과의 매칭 정도(matching degree)를 계산할 수 있다. 객체 검출 장치는, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도 및 상기 타겟 후보 영역의 각각과 상기 간섭 템 플릿 세트의 각 간섭 템플릿과의 매칭 정도에 기초하여, 상기 타겟 후보 영역의 각각의 타겟 매칭 정도를 계산 할 수 있다. 객체 검출 장치는, 상기 타겟 후보 영역의 각각의 타겟 매칭 정도에 기초하여, 상기 하나 이 상의 타겟 후보 영역 중 하나의 타겟 영역을 결정할 수 있다. 여기서, 상기 타겟 후보 영역의 각각의 타겟 매 칭 정도를 계산할 때, 객체 검출 장치는, 상기 타겟 후보 영역의 각각과 상기 타겟 템플릿 세트의 각 타겟 템플릿과의 매칭 정도의 평균값 또는 중간값, 및/또는 상기 타겟 후보 영역의 각각과 상기 간섭 템플릿 세트의 각 간섭 템플릿과의 매칭 정도의 평균값 또는 중간값에 기초하여 상기 타겟 후보 영역의 각각의 타겟 매칭 정도 를 계산할 수 있다. 객체 검출 장치는, 타겟 템플릿 세트에 기초하여, 타겟 융합 특징(integrated target feature)을 결정하고, 상기 간섭 템플릿 세트에 기초하여, 간섭 융합 특징(integrated inteference feature)을 결정할 수 있다. 객체 검출 장치는, 상기 타겟 융합 특징 및 상기 간섭 융합 특징에 기초하여, 상기 프레임 이미지 로부터 상기 하나 이상의 타겟 후보 영역을 획득할 수 있다. 예를 들어, 객체 검출 장치는, 간섭 템플릿 세트의 간섭 융합 특징 및 상기 다른 타겟 후보 영역의 일부 또는 전부의 유사도를 계산하고, 상기 다른 타겟 후보 영역의 일부 또는 전부 중 상기 유사도가 임계값보다 작은 타겟 후보 영역을 간섭 템플릿으로 상기 간섭 템플릿에 추가할 수 있다. 도 9는 일 실시예에 따른 객체 검출을 위한 전자 장치의 블록도이다. 일 실시예에 따른 전자 장치는 프로세서, 네트워크 인터페이스 및 저장장치(storage)를 포 함할 수 있다. 또한, 전자 장치는, 사용자 인터페이스 및 적어도 하나의 통신 버스를 더 포함 할 수 있다. 통신 버스는 이들 구성요소들 간의 연결 및 통신을 실현하기 위해 사용된다. 사용자 인터페 이스는, 디스플레이(display) 및 키보드(keyboard)를 포함할 수 있고, 선택적으로, 표준 유선/무선 인터페 이스를 더 포함할 수 있다. 네트워크 인터페이스는, 표준 유선 인터페이스 및/또는 무선 인터페이스(예, Wi-Fi 인터페이스)를 포함할 수 있다. 저장장치는, 고속 RAM 메모리를 포함할 수 있고, 적어도 하나의 디 스크 메모리, Flash Memory와 같은 비휘발성 메모리(non-volatile memory)를 포함할 수도 있다. 저장장치 는, 또한, 전자장치에 착탈될 수 있는 착탈식 저장 장치(removable storage device)일 수 있다. 저 장장치는 운영 체제, 네트워크 통신 모듈, 사용자 인터페이스 모듈 및 장치 제어 응용 프로그램 등을 저장 할 수 있다. 네트워크 인터페이스는, 네트워크 통신 기능을 제공할 수 있다. 사용자 인터페이스는, 사용자를 위한 입력 인터페이스를 제공하는데 사용된다. 프로세서는 저장장치에 저장된 장치 제어 애 플리케이션을 호출하는데 사용될 수 있다. 어떤 구현에서, 전자 장치는 내장된 각 기능 모듈을 통해, 도 1내지 도 7에서 설명된 방법을 실행할 수 있 다. 구체적인 내용은 앞에서 제공하는 구현 방법을 참조하면 되며, 여기서 더 반복하지 않는다. 실시예에 따라서, AI 모델을 통해, 복수의 모듈 중 적어도 하나 이상의 모듈이 구현될 수 있다. AI와 관련된 기능은 비휘발성 메모리, 휘발성 메모리 및 프로세서에 의해 수행될 수 있다. 프로세서는 하나 이상의 프로세 서를 포함할 수 있다. 이때, 하나 이상의 프로세서는 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP) 등과 같은 범용 프로세서 또는 그래픽 처리 장치(GPU), 비주얼 처리 장치(VPU)와 같은 순수 그래픽 처리 장치, 및/또 는 신경 처리 장치(NPU)와 같은 AI 전용 프로세서일 수 있다. 하나 이상의 프로세서는 비휘발성 메모리 및 휘발성 메모리에 저장된 사전 정의된 동작 규칙 또는 인공 지능 (AI) 모델에 따라 입력 데이터의 처리를 제어한다. 하나 이상의 프로세서는, 훈련 또는 학습을 통해 사전 정의 된 동작 규칙 또는 인공 지능 모델을 제공한다. 여기서, 학습(training)을 통한 제공은, 복수의 학습 데이터에 학습 알고리즘을 적용하여 사전 정의된 동작 규칙이나 원하는 특성을 가진 AI 모델을 얻는 것을 의미한다. 학 습은, 실시예에 따른 AI가 수행되는 장치 자체에서 수행될 수 있고, 및/또는 별도의 서버/시스템에 의해 구현될 수 있다. AI 모델에는 복수의 신경망 레이어가 포함될 수 있다. 각 레이어에는 복수의 가중치 값이 있고, 하나의 레이어 계산은 이전 레이어의 계산 결과와 현재 레이어의 복수의 가중치를 통해 수행된다. 신경망의 예로, 컨볼루션 신경망(CNN), 심층 신경망(DNN), 순환 신경망(RNN), 제한된 볼츠만 머신(RBM), 심층 신뢰 신경망(DBN), 양방향 순환 신경망(BRDNN), 생성적 대립쌍 네트워(GAN) 및 심층 Q 네트워크를 포함하지만, 이에 제한되지 않는다. 학습 알고리즘은, 복수의 학습 데이터를 이용하여 소정의 타겟 장치(예, 로봇)를 훈련하여 타겟 장치가 결정 또 는 예측하도록 인에이블, 허용 또는 제어하는 방법이다. 학습 알고리즘의 예로, 지도 학습(supervised learning), 비지도 학습(unsupervised learning), 반 지도 학습(Semi-supervised learning) 또는 강화 학습 (reinforcement learning)을 포함하나 이에 제한되지 않는다. AI 모델은, 이미지 데이터를 AI 모델의 입력 데이터로 사용하여, 비디오의 임의의 한 프레임 이미지에서 타겟 객체의 검출 결과를 얻을 수 있다. 해당 AI 모델은 훈련을 통해 얻을 수 있다. 여기서, \"훈련을 통한 획득 (obtain by training)\"이란 훈련 알고리즘을 통해 다수의 훈련 데이터로 기본 AI 모델을 훈련시켜 원하는 특징 (또는 목적)을 수행하도록 구성된 미리 정의된 연산 규칙 또는 AI 모델을 획득하는 것을 의미한다. AI 모델에는 복수의 신경망 계층이 포함될 수 있다. 복수의 신경망 계층 각각은 복수의 가중치 값을 포함하고, 신경망 계산 은 이전 계층의 계산 결과와 복수의 가중치 값 사이의 계산에 의해 수행된다. 이상에서 설명된 실시예들은 시각적 이해에 적용될 수 있다. 시각적 이해(visual understanding)는, 인간의 시 각처럼 인식하고 처리하는 기술로, 예를 들어 객체 인식(object recognition), 객체 추적(object tracking), 이미지 검색, 인간 인식, 장면 인식, 3D 재구성/포지셔닝 또는 이미지 증강을 포함한다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수의 프로세서 또는 하나의 프로 세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구 성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 포함할 수 있으며 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구 성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 위에서 설명한 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 또는 복수의 소프트웨어 모듈로서 작동하 도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2021-0140401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 이를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2021-0140401", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 객체 추적 방법을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 객체 추적 방법을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 객체 추적 방법의 흐름도이다. 도 4는 일 실시예에 따른 객체 추적 방법의 메모리 매칭을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 간소화된 객체 검출 방법(light-weight object detection method)를 설명하기 위한 도면이다. 도 6은 다른 실시예에 따른 간소화된 객체 검출 방법(light-weight object detection method)를 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 메모리 갱신을 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 객체 검출 장치의 블록도이다. 도 9는 일 실시예에 따른 객체 검출을 위한 전자 장치의 블록도이다."}
