{"patent_id": "10-2023-7010854", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0054896", "출원번호": "10-2023-7010854", "발명의 명칭": "인공 지능을 위한 효율적인 게임플레이 트레이닝", "출원인": "구글 엘엘씨", "발명자": "마츠 네이선 선"}}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버 방법으로서.하나 이상의 서버 컴퓨팅 시스템으로부터 원격 클라이언트 컴퓨팅 디바이스로 프로그램 인터페이스를 통해, 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 게임 애플리케이션을 위한 게임플레이 데이터 모델을 제공하는 단계와;프로그래밍 인터페이스를 통해 원격 클라이언트 컴퓨팅 디바이스로부터, 제공된 게임플레이 데이터 모델을 사용하여 액터 컴포넌트에 의해 생성된 추론에 적어도 부분적으로 기초하여 상기 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트에 의해 게임 애플리케이션 내에서 수행된 인공 게임플레이 액션들으로부터 생성된관찰 데이터를 수신하는 단계와;하나 이상의 서버 컴퓨팅 시스템에 의해, 수신된 관측 데이터에 기초하여 게임플레이 데이터 모델을 수정하는단계와; 그리고원격 클라이언트 컴퓨팅 디바리스로 프로그래밍 인터페이스를 통해, 수정된 게임플레이 데이터 모델을 제공하는단계를 포함하는 것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 하나 이상의 서버 컴퓨팅 시스템에 의해 프로그램 인터페이스를 통해, 게임 애플리케이션의 하나 이상의 출력상태 각각을 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트의 입력 변수와 연관시키는 제어 정보를 수신하는 단계를 더 포함하는 것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 게임 애플리케이션의 하나 이상의 출력 상태는,게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준위치에 대한 객체의 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체와 연관된 모션벡터, 게임 애플리케이션의 가상 환경의 하나 이상의 양태에 관한 지오메트리 정보, 및/또는 게임 애플리케이션의 게임플레이와 관련된 하나 이상의 게임 내 보상 표시자를 포함하는 그룹 중 하나 이상을 포함하는 것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,하나 이상의 서버 컴퓨팅 시스템에 의해, 액터 컴포넌트에 대한 하나 이상의 출력 변수 각각을 게임 애플리케이션의 인간 사용자가 사용할 수 있는 액션과 연관시키는 제어 정보를 수신하는 단계를 더 포함하는 것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서, 상기 게임플레이 데이터 모델을 수정하는 단계는,게임 애플리케이션의 인간 사용자에 의해 게임 애플리케이션 내에서 수행된 게임플레이 액션들에 기초하여 생성된 추가 관찰 데이터에 더 기초하는 것을 특징으로 하는 서버 방법.공개특허 10-2023-0054896-3-청구항 6 제5항에 있어서, 상기 추가 관찰 데이터에 기초하여 게임플레이 데이터 모델을 수정하는 단계는 심층 학습 인공 지능을 사용하여게임플레이 데이터 모델을 수정하는 단계를 포함하는 것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서, 인공 게임플레이 액션들에 기초하여 게임 애플리케이션에 대한 테스트 데이터를 생성하는 단계를 더 포함하는것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 적어도 하나의 미리 정의된 기준을 충족하는 관찰 데이터의 집계를 수신한 것에 응답하여 그 수신된 관찰 데이터에 기초하여 게임플레이 데이터 모델을 수정하는 단계를 더 포함하는 것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 적어도 하나의 기준은,정의된 지속 기간, 정의된 관찰 데이터 양 및 원격 클라이언트 컴퓨팅 디바이스에서 수신된 명시적 요청 중 적어도 하나를 포함하는 것을 특징으로 하는 서버 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항의 방법을 수행하는 컴퓨터 시스템."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로세서를 조작하여 제1항 내지 제9항 중 어느 한 항의방법을 수행하는 실행 가능한 명령들을 저장하는 비-일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "서버로서,네트워크 인터페이스;하나 이상의 프로세서; 및실행 가능한 명령 세트를 저장하는 메모리를 포함하고, 상기 실행 가능한 명령 세트는 하나 이상의 프로세서를조작하여:게임 애플리케이션의 하나 이상의 출력 상태 각각을 입력 변수와 연관시키는 제어 정보에 적어도 부분적으로 기초하여, 게임 애플리케이션을 위한 게임플레이 데이터 모델을 생성하고;프로그래밍 인터페이스를 통해, 생성된 게임플레이 데이터 모델을 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트에 제공하고;액터 컴포넌트로부터 프로그래밍 인터페이스를 통해, 생성된 게임플레이 데이터 모델을 사용하여 액터 컴포넌트에 의해 생성된 추론에 기초하여 액터 컴포넌트에 의해 게임 애플리케이션 내에서 수행된 인공 게임플레이 액션들로부터 생성된 관찰 데이터를 수신하고;수신된 관찰 데이터에 기초하여 상기 생성된 게임플레이 데이터 모델을 수정하고; 그리고액터 컴포넌트로 프로그래밍 인터페이스를 통해, 게임 애플리케이션 내에서 추가 인공 게임플레이 액션을 수행할 때 액터 컴포넌트에 의한 사용을 위해 상기 수정된 게임플레이 데이터 모델을 제공하는 것을 특징으로 하는공개특허 10-2023-0054896-4-서버."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 원격 클라이언트 컴퓨팅 디바이스는 게임 애플리케이션의 인스턴스를 실행하고, 그리고상기 관찰 데이터는 원격 클라이언트 컴퓨팅 디바이스에 의해 실행된 게임 애플리케이션의 인스턴스내에서 액터컴포넌트에 의해 수행된 인공 게임플레이 액션들로부터 생성되는 것을 특징으로 하는 서버."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서, 상기 실행 가능한 명령 세트는,하나 이상의 프로세서를 추가로 조작하여, 프로그래밍 인터페이스를 통해, 게임 애플리케이션의 하나 이상의 출력 상태 각각을 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트의 입력 변수와 연관시키는 제어정보를 수신하는 것을 특징으로 하는 서버."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 게임 애플리케이션의 하나 이상의 출력 상태는,게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준위치에 대한 객체의 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체와 연관된 모션벡터, 게임 애플리케이션의 가상 환경의 하나 이상의 양태에 관한 지오메트리 정보, 및/또는 게임 애플리케이션의 게임플레이와 관련된 하나 이상의 게임 내 보상 표시자를 포함하는 그룹 중 하나 이상을 포함하는 것을 특징으로 하는 서버."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항 내지 제15항 중 어느 한 항에 있어서, 상기 실행 가능한 명령 세트는,하나 이상의 프로세서를 추가로 조작하여, 프로그래밍 인터페이스를 통해, 액터 컴포넌트에 대한 하나 이상의출력 변수 각각을 게임 애플리케이션의 인간 사용자가 사용할 수 있는 액션과 연관시키는 제어 정보를 수신하는것을 특징으로 하는 서버."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항 내지 제16항 중 어느 한 항에 있어서, 상기 실행 가능한 명령 세트는,하나 이상의 프로세서를 추가로 조작하여, 프로그램 인터페이스를 통해, 게임 애플리케이션의 인간 사용자에 의해 게임 애플리케이션 내에서 수행된 게임 플레이 액션들로부터 생성된 추가 관찰 데이터를 수신하고, 그리고상기 게임플레이 데이터 모델을 수정하는 것은 수신된 추가 관찰 데이터에 더 기초하는 것을 특징으로 하는 서버."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 수신된 추가 관찰 데이터에 기초하여 게임플레이 데이터 모델을 수정하는 것은 심층 학습 인공 지능을 사용하여게임플레이 데이터 모델을 수정하는 것을 포함하는 것을 특징으로 하는 서버."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2023-0054896-5-방법으로서,하나 이상의 프로세서에 의해 실행되는 액터 컴포넌트에 의해, 하나 이상의 원격 서버 컴퓨팅 시스템에서 실행되는 기계 학습 컴포넌트로부터 프로그래밍 인터페이스를 통해, 게임 애플리케이션을 위한 게임플레이 데이터모델을 수신하는 단계와;하나 이상의 프로세서에 의해, 게임 애플리케이션의 인스턴스를 실행하는 단계와;기계 학습 컴포넌트로 프로그래밍 인터페이스를 통해, 게임플레이 데이터 모델을 사용하여 액터 컴포넌트에 의해 생성된 추론에 적어도 부분적으로 기초하여 액터 컴포넌트에 의해 게임 애플리케이션의 실행 인스턴스 내에서 수행된 인공 게임플레이 액션들로부터 생성된 관찰 데이터를 제공하는 단계와; 그리고하나 이상의 원격 서버 컴퓨팅 시스템에서 실행되는 기계 학습 컴포넌트로부터 프로그래밍 인터페이스를 통해,제공된 관찰 데이터에 적어도 부분적으로 기초한 수정된 게임플레이 데이터 모델을 수신하는 단계를 포함하는것을 특징으로 하는 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 수정된 게임플레이 데이터 모델을 사용하여 액터 컴포넌트에 의해 생성된 추가 추론에 적어도 부분적으로 기초하여 하나 이상의 추가 인공 게임플레이 액션을 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제19항 또는 제20항에 있어서, 인공 게임플레이 액션들에 기초하여 게임 애플리케이션에 대한 테스트 데이터를 생성하는 단계를 더 포함하는것을 특징으로 하는 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제19항 내지 제21항 중 어느 한 항에 있어서, 상기 게임플레이 데이터 모델은,게임 애플리케이션의 하나 이상의 출력 상태 각각을 액터 컴포넌트의 입력 변수와 연관시키는 제어 정보에 적어도 부분적으로 기초하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 게임 애플리케이션의 하나 이상의 출력 상태는,게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준위치에 대한 객체의 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체와 연관된 모션벡터, 게임 애플리케이션의 가상 환경의 하나 이상의 양태에 관한 지오메트리 정보, 및/또는 게임 애플리케이션의 게임플레이와 관련된 하나 이상의 게임 내 보상 표시자를 포함하는 그룹 중 하나 이상을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제19항 내지 제23항 중 어느 한 항에 있어서,상기 게임플레이 데이터 모델은,액터 컴포넌트에 대한 하나 이상의 출력 변수 각각을 게임 애플리케이션의 인간 사용자가 사용할 수 있는 액션과 연관시키는 제어 정보에 적어도 부분적으로 기초하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제19항 내지 제24항 중 어느 한 항에 있어서,공개특허 10-2023-0054896-6-수정된 게임플레이 데이터 모델이 추가 관찰 데이터에 추가로 기초하도록, 게임 애플리케이션의 인간 사용자에의해 게임 애플리케이션 내에서 수행된 게임플레이 액션들로부터 생성된 추가 관찰 데이터를 생성하는 단계를더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제19항 내지 제25항 중 어느 한 항의 방법을 수행하는 컴퓨터 시스템."}
{"patent_id": "10-2023-7010854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로세서를 조작하여 제19항 내지 제25항 중 어느 한 항의방법을 수행하는 실행 가능한 명령들을 저장한 비-일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2023-7010854", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "원격 학습 서비스에 의해 생성된 하나 이상의 게임플레이 데이터 모델에 기초하여 게임 애플리케이션에서 실시간 게임플레이 액션을 실행하기 위해 로컬로 실행되는 액터 컴포넌트를 트레이닝하기 위한 시스템 및 방법이 설명된 다. 게임 애플리케이션을 위한 게임플레이 데이터 모델은 원격 학습 서비스를 실행하는 하나 이상의 서버 컴퓨팅 시스템으로부터 클라이언트 컴퓨팅 디바이스로 제공된다. 제공된 게임플레이 데이터 모델을 사용하여 액터 컴포 넌트에 의해 생성된 추론에 적어도 부분적으로 기초하여, 로컬 액터 컴포넌트에 의해 수행된 인공 게임플레이 액 션들의 게임 내 결과에 기초하여 로컬 액터 컴포넌트에 의해 관찰 데이터가 생성된다. 수신된 관찰 데이터에 기 초하여, 원격 학습 서비스는 게임플레이 데이터 모델을 수정하고 그 수정된 게임플레이 데이터 모델을 로컬 액터 컴포넌트에 제공하여 향후 인공 게임플레이 액션들을 개선한다."}
{"patent_id": "10-2023-7010854", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소비자급 그래픽 처리 장치(GPU), 광범위한 광대역 가용성 및 시장 원리가 결합되어 상당한 범위와 복잡성을 지 닌 게임을 만들었다. 최신 게임은 이전 게임보다 더 복잡할 뿐만 아니라 게임이 설계되고 플레이되는 방식의 근 본적인 변화를 반영한다. 단순한 선형 실내 수준은 거대한 실사적 야외 공간으로 대체되었고 스크립팅된 시퀀스 는 동적 시뮬레이션으로 대체되었으며 절차주의는 거의 무한한 다양성을 가진 세계를 가능하게 했다. 게임플레이 방식의 극적인 변화에도 불구하고 게임을 테스트하는 방식은 크게 변하지 않았다. 게임은 기본적으 로 고차원 상태 공간 내부의 시스템 간에 복잡하고 긴급한 상호 작용이 있는 시뮬레이션이므로 단위 테스트와 같은 코드 중심 방법론의 유용성이 제한된다. 결과적으로, 게임 테스트는 주로 수동 프로세스이며 반복적으로 게임을 플레이하고 결함을 찾는 사람에게 크게 의존한다. 안타깝게도 이러한 팀은 최신 게임의 복잡성으로 더 이상 확장할 수 없어 출시가 지연되고 제품 품질이 저하된다. 원격 학습 서비스에 의해 생성된 하나 이상의 게임플레이 데이터 모델에 기초하여 게임 애플리케이션에서 실시 간 게임플레이 액션을 실행하도록 로컬로 실행되는 액터(actor) 컴포넌트가 트레이닝되는 실시예가 본 명세서에 서 설명된다. 게임 애플리케이션을 위한 게임플레이 데이터 모델은 원격 학습 서비스를 실행하는 하나 이상의 서버 컴퓨팅 시스템으로부터 클라이언트 컴퓨팅 디바이스로 제공된다. 제공된 게임플레이 데이터 모델을 사용하 여 액터 컴포넌트에 의해 생성된 추론에 적어도 부분적으로 기초하여, 로컬 액터 컴포넌트에 의해 수행된 인공 게임플레이 액션의 게임 내 결과에 근거하여 로컬 액터 컴포넌트에 의해 관찰 데이터가 생성된다. 수신된 관찰 데이터에 기초하여, 원격 학습 서비스는 게임플레이 데이터 모델을 수정하고, 수정된 게임플레이 데이터 모델을 로컬 액터 컴포넌트에 제공하여 향후 인공 게임플레이 액션을 개선한다. 관찰 데이터에 기초하여 게임플레이 데 이터 모델을 수정하는 것은 특히 원격 클라이언트 컴퓨팅 디바이스에 의해 로컬로 생성되고 그로부터 수신된 관 찰 데이터를 사용하여 (예를 들어, 실시간으로) 게임플레이 데이터 모델을 업데이트하는 것을 포함할 수 있다. 특정 실시예에서, 방법은 하나 이상의 서버 컴퓨팅 시스템으로부터 원격 클라이언트 컴퓨팅 디바이스로 프로그 램 인터페이스를 통해, 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 게임 애플리케이션을 위한 게임플레이 데이터 모델을 제공하는 단계와; 프로그래밍 인터페이스를 통해 원격 클라이언트 컴퓨팅 디바이스로부터, 제공 된 게임플레이 데이터 모델을 사용하여 액터 컴포넌트에 의해 생성된 추론에 적어도 부분적으로 기초하여 상기 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트에 의해 게임 애플리케이션 내에서 수행된 인공 게임플레이 액션들으로부터 생성된 관찰 데이터를 수신하는 단계와; 하나 이상의 서버 컴퓨팅 시스템에 의해, 수신된 관측 데이터에 기초하여 게임플레이 데이터 모델을 수정하는 단계와; 그리고 원격 클라이언트 컴퓨팅 디 바리스로 프로그래밍 인터페이스를 통해, 수정된 게임플레이 데이터 모델을 제공하는 단계를 포함할 수 있다. 방법은 하나 이상의 서버 컴퓨팅 시스템에 의해 프로그램 인터페이스를 통해, 게임 애플리케이션의 하나 이상의 출력 상태 각각을 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트의 입력 변수와 연관시키는 제 어 정보를 수신하는 단계를 더 포함할 수 있다. 게임 애플리케이션의 하나 이상의 출력 상태는 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객 체의 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체와 연관된 모션 벡터, 게임 애 플리케이션의 가상 환경의 하나 이상의 양태에 관한 지오메트리 정보, 및/또는 게임 애플리케이션의 게임플레이 와 관련된 하나 이상의 게임 내 보상 표시자를 포함하는 그룹 중 하나 이상을 포함할 수 있다. 방법은 하나 이상의 서버 컴퓨팅 시스템에 의해, 액터 컴포넌트에 대한 하나 이상의 출력 변수 각각을 게임 애 플리케이션의 인간 사용자가 사용할 수 있는 액션과 연관시키는 제어 정보를 수신하는 단계를 더 포함할 수 있 다. 게임플레이 데이터 모델을 수정하는 단계는 게임 애플리케이션의 인간 사용자에 의해 게임 애플리케이션 내에서 수행된 게임플레이 액션들에 기초하여 생성된 추가 관찰 데이터에 더 기초할 수 있다. 추가 관찰 데이터에 기초하여 게임플레이 데이터 모델을 수정하는 단계는 심층 학습 인공 지능을 사용하여 게임 플레이 데이터 모델을 수정하는 단계를 포함할 수 있다. 방법은 인공 게임플레이 액션들에 기초하여 게임 애플리케이션에 대한 테스트 데이터를 생성하는 단계를 더 포 함할 수 있다. 방법은 관찰 데이터를 예를 들어 관찰 데이터의 배치(batch) 형태로, 하나 이상의 서버 컴퓨팅 시스템으로 전송 하기 전에 원격 클라이언트 컴퓨팅 디바이스에서 관찰 데이터를 집계하는 단계를 더 포함할 수 있다. 이것은 하 나 이상의 서버 컴퓨팅 시스템과 원격 클라이언트 컴퓨팅 디바이스 간의 통신에서 데이터 트래픽을 줄일 수 있 다. 수신된 관찰 데이터에 기초하여 게임플레이 데이터 모델을 수정하는 단계는 적어도 하나의 미리 정의된 기 준을 충족하는 관찰 데이터의 집계에 응답하여 수행될 수 있다. 적어도 하나의 기준은 예를 들어, 정의된 지속 기간, 정의된 관찰 데이터 양(예를 들어, 바이트 또는 기타 측정 수향으로 측정됨) 및 예를 들어 원격 클라이언 트 컴퓨팅 디바이스에서 수신된, 하나 이상의 서버 컴퓨팅 시스템으로부터의 명시적 요청 중 적어도 하나를 포 함할 수 있다. 특정 실시예에서, 서버는 네트워크 인터페이스, 하나 이상의 프로세서 및 실행 가능한 명령 세트를 저장하는 메 모리를 포함할 수 있다. 실행 가능한 명령 세트는 하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로세 서를 조작하여: 게임 애플리케이션의 하나 이상의 출력 상태 각각을 입력 변수와 연관시키는 제어 정보에 적어 도 부분적으로 기초하여, 게임 애플리케이션을 위한 게임플레이 데이터 모델을 생성하고; 프로그래밍 인터페이 스를 통해, 생성된 게임플레이 데이터 모델을 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트에 제공하고; 액터 컴포넌트로부터 프로그래밍 인터페이스를 통해, 생성된 게임플레이 데이터 모델을 사용하여 액 터 컴포넌트에 의해 생성된 추론에 기초하여 액터 컴포넌트에 의해 게임 애플리케이션 내에서 수행된 인공 게임 플레이 액션들로부터 생성된 관찰 데이터를 수신하고; 수신된 관찰 데이터에 기초하여 상기 생성된 게임플레이 데이터 모델을 수정하고; 그리고 액터 컴포넌트로 프로그래밍 인터페이스를 통해, 게임 애플리케이션 내에서 추 가 인공 게임플레이 액션을 수행할 때 액터 컴포넌트에 의한 사용을 위해 상기 수정된 게임플레이 데이터 모델 을 제공할 수 있다. 원격 클라이언트 컴퓨팅 디바이스는 관찰 데이터가 원격 클라이언트 컴퓨팅 디바이스에 의해 실행된 게임 애플 리케이션의 인스턴스 내의 액터 컴포넌트에 의해 수행된 인공 게임플레이 액션들로부터 생성되도록 게임 애플리 케이션의 인스턴스를 실행할 수 있다. 실행 가능한 명령 세트는 프로그래밍 인터페이스를 통해, 게임 애플리케 이션의 하나 이상의 출력 상태 각각을 원격 클라이언트 컴퓨팅 디바이스에서 실행되는 액터 컴포넌트의 입력 변 수와 연관시키는 제어 정보를 수신하도록 하나 이상의 프로세서를 추가로 조작할 수 있다. 게임 애플리케이션의 하나 이상의 출력 상태는 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체의 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체와 연관된 모션 벡터, 게임 애플리케이션의 가상 환경의 하나 이상의 양태에 관 한 지오메트리 정보, 및/또는 게임 애플리케이션의 게임플레이와 관련된 하나 이상의 게임 내 보상 표시자를 포 함하는 그룹 중 하나 이상을 포함할 수 있다. 실행 가능한 명령 세트는 프로그래밍 인터페이스를 통해, 액터 컴포넌트에 대한 하나 이상의 출력 변수 각각을 게임 애플리케이션의 인간 사용자가 사용할 수 있는 액션과 연관시키는 제어 정보를 수신하도록 하나 이상의 프 로세서를 추가로 조작할 수 있다. 실행 가능한 명령 세트는 프로그램 인터페이스를 통해, 게임 애플리케이션의 인간 사용자에 의해 게임 애플리케 이션 내에서 수행된 게임 플레이 액션들로부터 생성된 추가 관찰 데이터를 수신하도록 하나 이상의 프로세서를추가로 조작할 수 있으며, 게임플레이 데이터 모델을 수정하는 것은 수신된 추가 관찰 데이터에 더 기초한다. 수신된 추가 관찰 데이터에 기초하여 게임플레이 데이터 모델을 수정하는 것은 심층 학습 인공 지능을 사용하여 게임플레이 데이터 모델을 수정하는 것을 포함할 수 있다. 특정 실시예에서, 클라이언트 방법은 하나 이상의 프로세서에 의해 실행되는 액터 컴포넌트에 의해, 하나 이상 의 원격 서버 컴퓨팅 시스템에서 실행되는 기계 학습 컴포넌트로부터 프로그래밍 인터페이스를 통해, 게임 애플 리케이션을 위한 게임플레이 데이터 모델을 수신하는 단계와; 하나 이상의 프로세서에 의해, 게임 애플리케이션 의 인스턴스를 실행하는 단계와; 기계 학습 컴포넌트로 프로그래밍 인터페이스를 통해, 게임플레이 데이터 모델 을 사용하여 액터 컴포넌트에 의해 생성된 추론에 적어도 부분적으로 기초하여 액터 컴포넌트에 의해 게임 애플 리케이션의 실행 인스턴스 내에서 수행된 인공 게임플레이 액션들로부터 생성된 관찰 데이터를 제공하는 단계와; 그리고 하나 이상의 원격 서버 컴퓨팅 시스템에서 실행되는 기계 학습 컴포넌트로부터 프로그래밍 인터 페이스를 통해, 제공된 관찰 데이터에 적어도 부분적으로 기초한 수정된 게임플레이 데이터 모델을 수신하는 단 계를 포함할 수 있다. 클라이언트 방법은 수정된 게임플레이 데이터 모델을 사용하여 액터 컴포넌트에 의해 생성된 추가 추론에 적어 도 부분적으로 기초하여 하나 이상의 추가 인공 게임플레이 액션을 수행하는 단계를 더 포함할 수 있다. 클라이언트 방법은 인공 게임플레이 액션들에 기초하여 게임 애플리케이션에 대한 테스트 데이터를 생성하는 단 계를 더 포함할 수 있다. 게임플레이 데이터 모델은 게임 애플리케이션의 하나 이상의 출력 상태 각각을 액터 컴포넌트의 입력 변수와 연 관시키는 제어 정보에 적어도 부분적으로 기초할 수 있다. 게임 애플리케이션의 하나 이상의 출력 상태는 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치 에 대한 객체의 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체와 연관된 모션 벡 터, 게임 애플리케이션의 가상 환경의 하나 이상의 양태에 관한 지오메트리 정보, 및/또는 게임 애플리케이션의 게임플레이와 관련된 하나 이상의 게임 내 보상 표시자를 포함하는 그룹 중 하나 이상을 포함할 수 있다. 게임플레이 데이터 모델은 액터 컴포넌트에 대한 하나 이상의 출력 변수 각각을 게임 애플리케이션의 인간 사용 자가 사용할 수 있는 액션과 연관시키는 제어 정보에 적어도 부분적으로 기초할 수 있다. 클라이언트 방법은 수정된 게임플레이 데이터 모델이 추가 관찰 데이터에 추가로 기초하도록, 게임 애플리케이 션의 인간 사용자에 의해 게임 애플리케이션 내에서 수행된 게임플레이 액션들로부터 생성된 추가 관찰 데이터 를 생성하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-7010854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기술된 기술의 실시예는 게임 애플리케이션의 개발자(\"게임 개발자\"라고도 함)가 인공 지능(AI)을 활용하여 하나 이상의 게임 애플리케이션(예를 들어, 비디오 게임 또는 기타 시뮬레이션)을 플레이하고 테스트 할 수 있는 실행 가능한 액터 컴포넌트를 트레이닝할 수 있다. 본 명세서에서 참조의 용이함을 위해 게임플레이 트레이너(Gameplay Trainer: GT) 시스템으로 지칭될 수 있는 이러한 기술의 다양한 실시예는 게임 개발자가 게 임 애플리케이션에 링크할 수 있는 소프트웨어 개발 키트(SDK) 및 그 SDK가 특정 게임 애플리케이션과 관련된 게임플레이 모델을 트레이닝하는데 사용하는 원격 학습 서비스를 모두 활용할 수 있다. 따라서, 매우 높은 수준 으로, 게임과 GT 시스템 간의 상호 작용은 게임과 인간 플레이어 간의 상호 작용과 유사할 수 있다. 게임은 GT 시스템으로 전송되는 출력을 생성하는데, GT 시스템은 해당 출력에 응답하는 방법을 평가하고, GT 시스템이 수 행하려는 인공(적인) 게임플레이 액션을 다시 보낸다. 그런 다음 게임은 이러한 액션을 적용하고, 새로운 출력을 생성하며, 그리고 주기를 반복한다. 특정 실시예에서, 게임플레이 트레이너는 게임 플레이 데이터 모델을 사용하여 하나 이상의 게임 애플리케이션 을 플레이하고 테스트하기 위해 로컬로 실행되는 인공 지능(AI) 액터 컴포넌트와 함께 원격 학습 서비스를 게임 개발자에게 제공한다. 적어도 일부 실시예에서, 로컬로 실행되는 액터 컴포넌트에 의해 사용되는 게임플레이 데 이터 모델은 액터 컴포넌트에 의해 게임 애플리케이션 내에서 수행된 인공 게임플레이 액션으로부터 수집된 관 찰 데이터에 기초하여 (GT 학습 서비스를 통해) GT 시스템에 의해 생성된다. 따라서, GT 시스템은 비용 민감도, 예측 가능성 및 통합 용이성을 비롯하여 게임 개발의 다양한 목표에 맞는 솔루션을 제공한다. 따라서 GT 시스템 의 특정 실시예는 게임 개발자가 GT 시스템을 게임 애플리케이션에 신속하게 통합하고 유용한 게임플레이 데이 터 모델을 생성할 수 있게 하는 솔루션을 제공한다. 특정 실시예에서, GT 시스템은 대중적인 프레임워크를 지원하고 및/또는 공통 참조 용어를 활용하기 위해 하나 이상의 애플리케이션 프로그래밍 인터페이스(여기에서 사용되는 API는 애플리케이션 프로그래밍 인터페이스 또 는 임의의 다른 적절한 프로그래밍 인터페이스를 나타낼 수 있음)를 제공할 수 있다. 다양한 실시예에서, 게임 애플리케이션 개발자가 이러한 API의 사용을 게임 애플리케이션에 통합하기 위해 플랫폼별 소프트웨어 개발 키 트(SDK)가 제공될 수 있다. 게임플레이 트레이너 시스템은 게임 개발자에게 유용하고 유연하며 트레이닝 가능하고 게임 애플리케이션에서 단순히 '승리(winning)'하는 것 이상의 목표를 향해 진행할 수 있는 솔루션을 제공한다. 하나의 비-제한적인 예 로서, 게임 애플리케이션을 위한 게임플레이 데이터 모델은 GT 시스템의 액터 컴포넌트가 게임 애플리케이션의 인간 플레이어가 게임 세계에서 진행할 수 없게 될 가능성이 있는, 즉 인간 플레이어가 '고착(stuck)'될 가능성 이 있는 게임 세계의 하나 이상의 영역을 결정하도록 허용할 수 있다. 다른 비-제한적 예로서, 게임플레이 데이 터 모델은 GT 시스템의 액터 컴포넌트가 하나 이상의 게임 세계 적들이 게임 세계에서 자신의 위치에 대해 부적 절하게 권한을 부여받았다고, 즉 예를 들어 플레잉 게임에서 낮은 수준 또는 중간 수준의 캐릭터와의 조우(만남)에 의해 보증되는 것보다 더 강력하거나 덜 강력하다고 판단하도록 허용할 수 있다. 따라서, 특정 실 시예에서, GT는 각각이 게임 세계에서 하나 이상의 고유한 목표와 관련된 게임 애플리케이션을 위한 다수의 게 임플레이 데이터 모델의 신속한 개발을 강조할 수 있다. 대안적으로, GT 시스템은 GT 시스템에 제공되고 및/또 는 GT 시스템 자체에 의해 식별되는 하나 이상의 사용자 지정 파라미터를 통해 식별되는 목표와 같은 다수의 목 표를 포함하거나 이를 향해 진행하는 단일 게임플레이 데이터 모델을 개발할 수 있다. 게임 애플리케이션과 관련하여 기술 및 실시예가 본 명세서에 설명되어 있지만, 대안적인 실시예가 다른 컨텍스 트(예를 들어, 자율 차량, 자율 로봇 공학 등)에서 행동 데이터 모델 및/또는 자동화(automated) 에이전트를 생 성하기 위해 다양한 시뮬레이션 시나리오와 함께 이용될 수 있음을 이해할 것이다. 유사하게, 게임 애플리케이 션 테스팅과 관련하여 기술 및 실시예가 본 명세서에서 설명되지만, 이러한 행동 데이터 모델 및/또는 자동화 에이전트는 다른 컨텍스트(예를 들어, 자동화 플레이 에이전트 또는 \"봇\" 개발, 게임 내 자율 동료 캐릭터, 인 간 플레이어와의 플레이를 위한 일반화된 자동화 에이전트 개발 등)에서 생성 및/또는 활용될 수 있다. GT 시스템의 실시예는 개별 게임 애플리케이션의 하나 이상의 측면을 테스트하기를 원하는 한 명 이상의 개발자 에게 다양한 이점을 제공할 수 있다. 일 예로, 개발자가 원격으로 실행되는 게임을 테스트하는 것이 유리할 수 있다. 특정 실시예에서 GT 액터 컴포넌트는 GT 시스템에 의해 테스트되는 게임 애플리케이션의 실행 인스턴스와 관련하여 로컬로 실행된다. 그러나, GT 시스템은 의미하는 대역폭 및 대기 시간 제한을 포함하여 공용 인터넷을 통과하는 게임에 대한 연결을 통해 이러한 테스트를 가능하게 한다. 또 다른 예로서, GT 시스템은 일반적으로 게임 개발자에게 적지 않은 비용인 이러한 테스트에 사용되는 컴퓨팅 리소스를 줄일 수 있다. 본 명세서에 설명된 기술을 사용하면 게임 애플리케이션의 개별 인스턴스를 대량으로 테스트할 수 있지만, 이러한 기술을 통해 GT 시스템은 단일 인스턴스에서 유용한 AI를 효과적으로 트레이닝할 수 있다. 다른 예로, GT 시스템은 하나 이상의 관련 게임 엔진(일반적으로 게임 물리 및 그래픽 렌더링과 같은 공통의 저 수준 서비스를 제공하는 대규모 코드베이스)에 대한 기본(native) 지원을 통해 하나 이상의 게임 애플리케이션 을 테스트할 수 있다. 다양한 실시예에서, GT 시스템과 관련된 하나 이상의 SDK는 공유 로직을 위한 미리 컴파 일된 라이브러리뿐만 아니라 이러한 다양한 게임 엔진(예를 들어, 유니티(Unity), 언리얼(Unreal) 및 pure C++) 각각에 대해 제공될 수 있다. 특정 실시예에서, GT 시스템은 게임 애플리케이션에 대해 정의된 하나 이상의 파라미터에 기초하여 게임 애플리 케이션에 대한 초기 게임플레이 모델을 생성할 수 있다. 일반적으로, 정의된 파라미터는 일반적으로 GT 액터 컴 포넌트로 3가지 유형의 정보, 예를 들어 관찰(플레이어가 임의의 주어진 시간에 경험하는 게임 상태), 액션(플 레이어가 게임에서 수행할 수 있는 논리적 상호 작용); 및 보상(GT 액터 컴포넌트가 얼마나 잘하고 있는지 또는 잘못하고 있는지를 나타내는 표시)을 제공한다. 도 1은 네트워크화된 게임 트레이닝 시스템의 예시적인 실시예를 도시한다. 네트워크화된 게임 트레이닝 시스템은 로컬 컴퓨팅 시스템에서 실행되는 GT 액터 컴포넌트의 인스턴스를 포함하며, 이는 GT 액터 컴포넌트로부터 게임플레이 액션을 수신하는 게임 애플리케이션도 실행하고 있다. GT 액터 컴포넌트 는 인터넷 또는 다른 중재 네트워크와 같은 하나 이상의 컴퓨터 네트워크를 통해 하나 이상의 원격 서버에서 실행되는 GT 학습 서비스에 통신 가능하게 결합된다. 도시된 실시예에서, GT 액터 컴포넌트 는 인공 게임플레이 액션을 생성하여 게임 애플리케이션에 제공하고, 게임 애플리케이션으로부 터 관찰 데이터 및 게임 내 보상 표시자(reward indicator)를 수신하고, 이 정보의 일부 또는 전부를 관찰 경험 데이터로서 GT 학습 서비스에 제공한다. 차례로, GT 학습 서비스는 수신된 관찰 경험 데이 터를 사용하여, 전체 게임플레이 및 GT 액터 컴포넌트가 게임 애플리케이션에 제공하는 개별 인공 게임플 레이 액션 모두를 개선하기 위해 게임 애플리케이션과 관련된 하나 이상의 게임플레이 모델을 생성, 개선(refine) 및/또는 GT 액터 컴포넌트에 제공한다. 이 프로세스의 다양한 지점에서, GT 시스템은 (GT 학습 서비스 및/또는 GT 액터 컴포넌트를 통 해) 게임 애플리케이션과 관련된 테스트 데이터를 생성할 수 있다. 특정 실시예에서, 게임 애플리케이션 과 관련된 게임 개발자는 (예를 들어 GT 학습 서비스 및/또는 GT 액터 컴포넌트의 프로그래밍 인터페이스를 통해) 이러한 테스트 데이터의 하나 이상의 유형 및 방식을 지정할 수 있다. 또한, 특정 실시예에 서 GT 시스템은 GT 시스템에 의해 저장된 정의된 기준에 기초하는 것과 같이 생성할 테스트 데이터의 하나 이상 의 양태를 결정할 수 있다. 이러한 실시예에서, 정의된 기준은 게임 애플리케이션이 자격이 있는 것으로 결정되는 하나 이상의 유형의 게임 애플리케이션과 연관될 수 있다. 예를 들어, GT 시스템에 의해 생성될 테스 트 데이터에 대한 정의된 제1 기준 세트는 2차원 플랫폼 게임 유형과 연관되고, 제2 세트는 3차원 플랫폼 게임 유형과 연관되고, 제3 세트는 레이싱 게임 유형과 연관되며, 제4 세트는 오픈 월드 롤플레잉 게임 등과 연관될 수 있다. 전술한 바와 같이, 특정 시나리오에서 GT 액터 컴포넌트에 의한 인공 게임플레이 액션은 게임 애플리케이 션에 대해 정의된 하나 이상의 파라미터에 기초하여 GT 시스템에 의해 생성된 하나 이상의 게임플레 이 데이터 모델에 적어도 부분적으로 기초할 수 있다. 이러한 파라미터는 게임 애플리케이션의 개발 자(비제한적 예로서)에 의해 GT 시스템의 프로그래밍 인터페이스를 통해 제공될 수 있다. 예를 들어, 초기 게임플레이 모델은 게임 애플리케이션의 하나 이상의 출력 상태 각각을 GT 액터 컴포넌트의 입력 변 수와 연관시키는 제어 정보 및/또는 게임 애플리케이션에 대한 하나 이상의 입력 상태 각각을 GT 액터 컴포넌트 의 출력 변수와 연관시키는 제어 정보에 기초할 수 있다. 특정 실시예에서, 이러한 제어 정보는 GT 액터 컴포넌트의 하나 이상의 입력 및/또는 출력 변수 각각을 게임 애플리케이션의 인간 사용자에게 이용 가능 한 관찰 또는 액션과 연관시킬 수 있다. 예를 들어, GT 액터 컴포넌트의 출력 변수는 게임 애플리케이션에 서 가상 캐릭터의 움직임을 나타낼 수 있으며, 출력 변수는 게임플레이 동안 인간 사용자에 의해 이용될 물리적 입력 디바이스를 통한 가상 캐릭터의 움직임에 대응한다. GT 액터 컴포넌트의 이러한 출력 변수는 그러한 게임플레이 동안 인간 사용자가 이용할 수 있는 임의의 액션 또는 관찰에 대응할 수 있다. 특정 실시예에서, GT API는 게임 애플리케이션 개발자가 GT SDK가 GT 제어 정보에 매핑하는 높은 수준의 프리미티브(예를 들어, \"조 이스틱\", \"엔티티\" 등)로 입력 및 출력을 설명할 수 있으므로 게임 애플리케이션 개발자가 기계 학습에 대한 전 문 지식을 실행할 필요 없이 API에 액세스할 수 있도록 한다. 특정 실시예에서, 제어 정보는 GT 액터 컴포넌트에 의한 입력 변수로서 사용하기 위한 게임 애플리케이션 의 하나 이상의 출력 상태를 포함할 수 있다. 비-제한적인 예로서, 이러한 출력 상태는 게임 애플리케이션 의 가상 환경 내의 플레이어 기준 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체의 위치, 게임 애플리케이션의 가상 환경 내의 플레이어 기준 위치에 대한 객체와 관련된 모션 벡터, 게임 애플리케이션의 가상 환경의 하나 이상의 측면(aspect)에 관한 지오메트리(geometry) 정보, 및 /또는 게임 애플리케이션 내의 게임플레이와 관련된 스코어 또는 기타 게임 내 보상 표시자를 포함할 수 있다. 일반적으로, 제어 정보는 인간 플레이어가 관찰할 수 있는 게임 애플리케이션의 임의의 특면을 GT 액터 컴포넌트 입력 변수와 연관시킬 수 있다. 일부 실시예에서, GT 시스템은 또한 GT 액터 컴포넌트의 인공 게임플레이 액션으로 인해 발생된 관찰 경험 데이터를 수신할 때 사용되는 것과 유사한 방식으로 예를 들어 게임 애플리케이션과 관련된 하 나 이상의 게임플레이 모델을 생성하거나 수정하기 위해, 한 명 이상의 인간 플레이어에 의해 게임 애플리케이 션에 제공되는 게임플레이 액션으로 인해 발생하는 관찰 경험 데이터를 수신할 수 있다. 일 예로서, GT 액 터 컴포넌트의 출력 변수는 GT 액터 컴포넌트가 게임 애플리케이션 내의 지원 상태를 나타내도 록 허용할 수 있는데, 예를 들어 GT 액터 컴포넌트가 게임 애플리케이션에서 GT 액터 컴포넌트 가 정의된 지속 시간 또는 시도 횟수 동안 극복할 수 없었던 장애물을 만나는 경우, GT 시스템은 통신을 개시하여 한 명 이상의 인간 플레이어에게 프롬프트하여, 해당 장애물을 극복하는 방법을 설명하기 위한 하나 이상의 게임플레이 액션을 제공할 수 있다. 인간이 제공한 게임플레이 액션으로 인해 발생된 관찰 경험 데이터 는 GT 학습 서비스에 제공되며, GT 학습 서비스는 GT 액터 컴포넌트가 이후에 조우할 때 해당 장애물 및/또는 다른 장애물을 극복할 수 있도록 하는 방식으로 게임플레이 모델을 수정한다. 게임을 할 수 있는 AI를 트레이닝시키는 한 가지 접근 방식은 강화 학습(RL)이다. RL에서, 개발자는 AI가 점점 더 최적의 전략을 자율적으로 학습하는데 사용하는 신호인 승리에 대한 보상과 패배에 대한 페널티를 제공한다. 안타깝게도, RL은 매우 인상적인 결과를 보여주었지만, RL 알고리즘은 일반적으로 플레이어를 트레이닝하기 위 한 수백만 또는 수십억 개의 데이터 프레임과 같은 높은 데이터 소비(비효율적인 샘플)와 관련이 있으며, 이는 일반적으로 시간과 컴퓨팅 리소스 측면에서 개발자에게 영향을 미치는 비용이다. 이러한 알고리즘은 또한 수용 가능한 결과를 달성하기 위해 상당한 도메인 지식과 하이퍼파라미터 조정을 활용하여 결과가 매우 가변적인 경 향이 있다. 따라서 특정 실시예는 하나 이상의 인간 플레이어가 게임을 하는 것을 관찰하는 것에 기초하여 AI를 트레이닝하 는 모방 학습(IL: Imitation Learning) 기계 학습 기술을 활용한다. RL과 달리, 에이전트가 스스로 최적의 정책 을 찾아야 하는 경우, IL은 인간 전문가의 행동을 효과적으로 재현한다. 일반화된 IL 정책은 사람 데모에서 포 착된 것과 유사하지만 동일하지는 않은 시나리오에서 잘 수행된다. 이 문제는 일반적으로 소수의 공통 테마 (mechanics)에 대한 다수의 변형(레벨)으로 구축되는 게임에서 특히 심각하다. 특정 변형만 학습할 수 있지만 기본 테마를 학습할 수 없는 AI는 그다지 효과적인 도구(tool)가 아니다. GT 시스템은 효과적으로 일반화하는 관찰을 사용한다. 예를 들어, 3D 정보가 절대 좌표가 아닌 GT 액터 컴 포넌트의 관점을 기준으로 표현되는 자기 중심적 관찰은 GT 학습 서비스가 트레이닝 환경과 독립적인 이동(movement) 및 목표(aiming) 정책을 포함하는 게임플레이 데이터 모델을 생성할 수 있도록 한다. 따라서, 다양한 실시예에서, GT 시스템은 하나 이상의 추가 기준, 즉 어려운 장애물에 직면하는 것 이외의 기준에 기초하여 관련 게임플레이 모델의 개선을 위해 인간이 제공한 게임플레이 액션으로부터 발생하는 관찰 경험 데이터를 수신하도록 결정할 수 있다. 비-제한적 예로서, GT 시스템은 이러한 데이터를 제 공하도록 선택한 하나 이상의 식별된 인간 플레이어와 관련된 모든 세션 또는 세션의 서브세트에 대해; 게임 애 플리케이션의 하나 이상의 식별된 부분과 관련된 게임플레이 액션에 대해; 정기적 또는 예정된 간격 동안 이러한 데이터를 수신할 수 있다. 일부 실시예에서, 개발자들은 GT 학습 서비스가 하나 이상의 게임플레이 모델을 수정하고 이에 따라 GT 액터 컴포넌트를 업데이트하면서 게임 애플리케이션을 실시간으로 플레이함으로써 GT 학습 서비스 에 트레이닝 데이터를 제공할 수 있다. 이러한 방식으로, GT 시스템은 개발자들에게 GT 학습 서비스 의 품질에 관한 대화형 피드백을 제공하고 그들이 GT 시스템에 문제가 발생하는 경우 적시에 정정 (corrections)을 제공할 수 있도록 한다. 일부 실시예에서, 개발자들은 GT 액터 컴포넌트의 동시 인스턴스 를 원하는 만큼 생성하여 게임 애플리케이션을 대규모로 플레이하고 테스트할 수 있다. 더욱이, 특정 실시예에 서, GT 시스템은 어떤 게임플레이 데이터 모델 또는 모델들이 게임 내 보상 기준과 관련하여 더 잘 수행하는지를 결정하는 것과 같은 다양한 보상 기준에 기초하여 다수의 게임플레이 데이터 모델을 평가할 수 있다. 따라서 GT 시스템은 다가오는(upcoming) 추론을 위해 활용할 모델로서 최고 성능의 게임플레이 데이터 모델을 선택할 수 있다. 이러한 자동화된 평가는 GT 시스템이 트레이닝된 게임플레이 데이터 모델을 \"정련(polish)\"할 수 있게 한다. 도 2는 다른 네트워크화된 GT 시스템의 예시적인 실시예를 도시한다. 도 1의 네트워크(화된) 시스템 과 같이, 네트워크 시스템은 게임 애플리케이션도 실행하고 있는 로컬 컴퓨팅 시스템에서 실행 되는 GT 액터 컴포넌트의 인스턴스를 포함한다. (컴퓨터 네트워크(들)를 통해 GT 학습 서비스에 통신 가능하게 연결된) GT 액터 컴포넌트는 인공 게임플레이 액션을 게임 애플리케이션에 제공 하고, 게임 애플리케이션으로부터 관찰 데이터를 수신하고, 그리고 결과적인 관찰 경험 데이터를 GT 학습 서비스에 제공한다. 그러나, 여기에서, 게임 애플리케이션은 GT 액터 컴포넌트로부 터 인공 게임플레이 액션을 수신할 수 있고, 또한 다양한 시간에 다양한 기준에 따라, 일반 게임 세션의 방식으로 게임 애플리케이션에 의해 생성된 디스플레이 정보(일반적으로 오디오, 시각, 촉각 및/또는 기타 인식 정보를 포함함)를 인지하는 하나 이상의 인간 플레이어로부터의 다른 게임플레이 액션을 수신할 수 있다. 게임 애플리케이션이 GT 액터 컴포넌트로부터, 인간 플레이어(들) 또는 둘 다 로부터 게임플레이 액션을 수신하는지 여부에 관계없이, GT 액터 컴포넌트는 게임 애플리케이션으로 부터 관찰 데이터를 수신하고 결과적인 관찰 경험 데이터를 GT 학습 서비스에 제공한다. 전술한 바와 같이, 특정 실시예 및 구현에서 GT 액터 컴포넌트는 게임플레이 트레이너 SDK를 포함할 수 있 으며, 여기에는 개발자들이 (SDK를 게임 애플리케이션의 프로그램 코드에 통합함으로써와 같이) 게임 애플리케 이션에 통신적으로 연결(또는 \"링크\")할 수 있는 실행 가능한 명령 및 사전 컴파일된 라이브러리뿐만 아니 라 개발자들이 GT 시스템의 하나 이상의 컴포넌트와 프로그래밍 방식의 상호 작용(programmatic interactions)을 가능하게 하는데 사용할 수 있는 API가 포함된다. GT 시스템의 하나 이상의 구성 요소와 프로그래밍 방식의 상호 작용을 가능하게 한다. 특정 실시예에서, GT 시스템은 유니티(Unity), 언리얼 (Unreal) 및 C++(예를 들어, 독점 엔진용)와 같은 여러 대중적인 게임 개발 프레임워크 각각을 지원하기 위해 상이한 SDK를 포함할 수 있다. 이러한 각 SDK는 동일한 기능(예를 들어, 관찰/액션 수집/전송 및 온-디바이스 추론)을 제공할 수 있지만 종종 언어 및 엔진별 바인딩을 사용하여 관용적인 방식으로 제공한다. 도 3은 하나 이상의 실시예에 따라 구현된 GT 시스템의 개략적인 블록도를 도시한다. 도시된 실시예에서, 하나 이상의 원격 GT 서버는 GT API, 저장 설비 및 GT 학습 서비스의 실행 인스턴스를 포 함한다. 클라이언트 컴퓨팅 시스템은 게임 애플리케이션의 인스턴스와 GT 액터 컴포넌트의 인스 턴스를 실행하고 있다. GT 서버(들) 및 클라이언트 컴퓨팅 시스템 각각은 고정되거나 이동 가능할 수 있고, 데스크탑 또는 기타 컴퓨터(예를 들어, 태블릿, 슬레이트 등), 데이터베이스 서버, 네트워크 저장 디바이 스 및 기타 네트워크 디바이스, 스마트폰 및 기타 휴대폰, 가전 제품, 게임 콘솔 시스템, 디지털 음악 플레이어 디바이스, 휴대용 게임 디바이스, PDA, 호출기, 전자 수첩, 인터넷 기기, 텔레비전 기반 시스템(예를 들어, 셋 탑 박스 및/또는 개인용/디지털 비디오 레코더 사용), 및 적절한 통신 기능을 포함하는 다양한 기타 소비자 제 품과 같은 다양한 컴퓨팅 디바이스의 인스턴스가 포함될 수 있다.. 본 명세서의 다른 곳에서 언급된 바와 같이, GT 학습 서비스는 다양한 정보(예를 들어, 인증 정보, 게임플 레이 데이터 모델, 관찰 데이터)를 GT 액터 컴포넌트와 교환한다. 예시된 실시예에서, GT 학습 서비스 의 실시예는 예를 들어 설명된 기술을 구현하는 자동화 동작들을 수행하도록 원격 GT 서버(들)를 구 성하는 방식으로 GT 학습 서비스의 소프트웨어 명령들을 실행하기 위해 하나 이상의 하드웨어 프로세서(들)를 사용함으로써 설명된 기술 중 적어도 일부를 수행하기 위해 원격 GT 서버(들)의 메모리(미 도시)에서 실행한다. 이러한 자동화 동작들의 일부로서, GT 학습 서비스는 저장 설비의 데이터 구조 를 포함하여 다양한 유형의 데이터를 저장 및/또는 검색할 수 있다. 저장 설비는 게임플레이 데이터 모델을 하나 이상의 클라이언트 컴퓨팅 시스템(예를 들어, 클라이언 트 컴퓨팅 시스템)에 제공하는 것의 일부로서 게임플레이 데이터 모델을 생성하고 저장하기 위해 GT 시스템에 의해(특히, GT 학습 서비스에 의해) 사용되는 다양한 정보를 저장한다. 저장 설비에 의해 저장된 다른 정보에는 개발자 정보(하나 이상의 게임 애플리케이션 개발자에 관한 액세스 및 프로젝 트 정보를 포함할 수 있음); 게임 애플리케이션 정보(제어 정보, 게임플레이 관찰 데이터, 그 게임플 레이 관찰 데이터의 분석 및/또는 평가는 물론 하나 이상의 특정 게임 애플리케이션에 관한 이력 정보를 포함할 수 있음); 게임 세션 정보 및 트레이닝 데이터(GT 학습 서비스에 의해 하나 이상의 게임플레이 데이터 모델 생성의 일부로서 그리고 다른 동작들을 위해 사용 및 저장될 수 있음)가 포함된다. 특정 구현 에서, 저장 설비는 GT 시스템 내에 통합되거나 GT 시스템에 의해 직접 작동될 수 있고, 다른 구 현에서, 저장 설비에 의해 제공되는 기능의 일부 또는 전부는 하나 이상의 제3자 네트워크 액세스 가능 저 장 서비스 제공자에 의해 제공될 수 있다. 특정 실시예에서, GT 학습 서비스에는 또한 예를 들어 개발자 정보의 측면을 활용하고 수정함으로써 개발자들을 인증하고 그들의 프로젝트에 대한 메타 데이터를 추적하 는 논리가 포함되어 있다. GT 학습 서비스와의 상호작용(예를 들어, 게임 애플리케이션 개발자 및/또는 클라이언트 컴퓨팅 시스템 에 의한 상호작용)은 GT API를 통해 수행된다. 도시된 실시예에서, GT API는 원격 GT 서버 와 클라이언트 컴퓨팅 시스템 사이에 게임플레이 데이터 모델 및 관찰 데이터를 전달하기 위한 프로그래밍 인터페이스뿐만 아니라 액세스 제어 설비를 제공한다. 특정 실시예에서, GT 시스템의 사용은 식별된 개발자와 관련된 하나 이상의 프로젝트에 관한 다양한 다른 정보와 함께 개발자 정보의 일부로서 저장될 수 있는 것과 같은 하나 이상의 취소 가능한 API 키에 의해 제한될 수 있다. 이러한 키는 예를 들어 관찰 및 게임플레이 액션(인공적이거나 인간 플레이어에 의해 생성된 것)을 포함하여 개발자가 제출 한 모든 데이터를 인덱싱하는데 사용될 수 있다. 이러한 실시예에서, 개발자들은 자신이 제출한 데이터에만 액 세스할 수 있으며 해당 데이터의 다양한 측면(예를 들어, 전송 및/또는 삭제)을 추가로 제어할 수 있다. 따라서, 특정 실시예에서, API 요청은 개발자가 인증에 사용되는 유효한 서버 제공 API 키를 제공하도록 요구할 수 있으며 GT 학습 서비스와의 상호 작용 전반에 걸쳐 사용될 수 있다. 이러한 방식으로, GT 시스템은 API 호출 및 수집된 데이터가 발신(originating) 개발자와 연관되는 것을 보장한다. 개발자용(developer-facing) GT API 뒤에, GT 학습 서비스는 액터/학습자(Actor/Learner) 패턴을 구 현하는데, 여기에서 GT 액터 컴포넌트는 게임 애플리케이션과 관련된 하나 이상의 게임플레이 데이터 모델을 생성 및 업데이트/수정함으로써 게임플레이 액션으로 변환하기 위해 GT 학습 서비스에 대한 게임플 레이 관찰을 수집 및 생성한다. 도시된 실시예에서, GT 액터 컴포넌트 및 그의 기계 학습 플랫폼 (MLP)은 게임 애플리케이션과 다양한 상호 작용을 수행하여, GT API를 통해 GT 학습 서비스 로부터 수신된 하나 이상의 로컬 게임플레이 데이터 모델에 기초하여 게임 애플리케이션의 인간 플레 이어의 액션들을 시뮬레이션한다. 예를 들어, 로컬 게임플레이 데이터 모델에 기초한 게임플레이 액션들은 액션 적용기를 통해 게임 애플리케이션에 공급될 수 있으며, 이는 컨트롤러 모듈을 작동시켜 그 렇지 않으면 인간 플레이어에 의해 작동될 게임 컨트롤러의 기능을 통해 이러한 게임 플레이 액션의 실행 을 시뮬레이션한다. 이러한 게임플레이 액션들은 액션 보고기를 통해 MLP에 보고된다. 게임플레이 액 션 자체는 GT 액터 컴포넌트의 출력 변수(미도시)를 통해 시뮬레이션에 대한 변경을 초래하고, 추가 환경 관찰은 로컬 관찰 데이터를 생성하기 위한 기초로서 수집된다. 다양한 실시예에서, GT 액터 컴포넌트는 GT SDK(개발자가 자신의 게임 애플리케이션에 연결하고 GT API를 통해 상호 작용하는데 사용하는 코드 및 미리 컴파일된 라이브러리(미도시))에 포함되거나 GT SDK를 사용하여 생성될 수 있으며, 로컬 관찰 데이터를 수집 및 생성하기 위해 온-디바이스 추론(예를 들어, 게임 플 레이 데이터 모델을 사용하여 게임 내 행동 및 결과에 대한 하나 이상의 예측을 추론으로서 생성)을 수행 한다. GT 학습 서비스는 SDK로부터 데이터를 수집하고, 저장 설비을 통해 데이터를 저장하고, 새로운 게임플레이 데이터 모델을 트레이닝하고, 그리고 GT API를 통해 GT 액터 컴포넌트에 이러한 게 임플레이 데이터 모델을 다시 제공하는데 필요한 인프라를 제공한다. 이러한 방식으로, GT SDK는 관찰/액션 수 집 및 온-디바이스 추론을 제공하고, 또한 개발자용 API와 GT 학습 서비스 간의 어댑터 역할을 한다. GT 학습 서비스는 원격 GT 서버(들)에 의해 실행되고 다양한 알고리즘을 사용하여 게임플레이 데이터 모 델을 트레이닝한다. 특정 실시예에서, 모델 트레이닝 알고리즘 중 하나 이상은 텐서 플로우 또는 다른 기계 학 습 플랫폼과 같은 기계 학습 플랫폼(MLP)의 동작들에 기초할 수 있다. 마찬가지로, 온-디바이스 추론은 MLP(TensorFlow 또는 다른 기계 학습 플랫폼을 다시 포함할 수 있음)를 사용하여 수행될 수 있다. 로컬 게 임플레이 데이터 모델은 GT 학습 서비스로부터 검색되며, 특정 실시예에서 관찰 및 액션을 게임플레 이 데이터 모델의 입력 및 출력 변수에 매핑하는 방법을 설명하는 제어 정보를 포함할 수 있다. GT API를 사용하면 게임 애플리케이션 개발자가 게임 애플리케이션의 논리적 입력 및 출력을 설명하는 파 라미터뿐만 아니라 AI가 특정 시점에서 얼마나 잘 수행하는지에 대한 피드백을 정의할 수 있다. 구체적으로, GT 시스템은 개발자들이 하나 이상의 게임 애플리케이션(예를 들어, 게임 애플리케이션) 각각에 대해 하나 이 상의 관찰 파라미터, 액션 파라미터 및 보상 파라미터를 정의할 수 있게 한다. (관찰 데이터 생성으로 인한) 관 찰 파라미터는 플레이어가 주어진 시간에 경험하는 게임 상태를 설명하며, 여기에는 1인칭 슈팅 게임에서 가시 적인 적들의 위치 또는 레이싱 게임에서 플레이어의 자동차에서 레이스트랙까지의 거리와 같은 정보가 포함될 수 있다. 액션 파라미터는 플랫폼 게임에서 점프하거나 레이싱 게임에서 스티어링 휠의 위치와 같이 플레이어가 게임에서 수행할 수 있는 논리적인 게임플레이 액션을 설명(기술)한다. 보상 파라미터는 GT 액터 컴포넌트(30 5)가 얼마나 잘 수행되고 있는지에 대한 피드백을 제공하기 위해 하나 이상의 메트릭을 설정(establish)하고 따 라서 게임플레이 액션에 응답하여 게임 애플리케이션의 출력 상태를 제공한다. 특정 시나리오 및 실시예에서, 이러한 파라미터에는 플레이어가 게임 애플리케이션에서 점수를 얻는 방법과 유사한 숫자 값이 포함될 수 있지 만 다른 파라미터도 포함될 수 있다. 예를 들어, 보상 파라미터에는 정의된 기간 동안 조우 시에 또는 특정 게 임 세션 동안 플레이어가 가한 평균 또는 최대 피해량뿐만 아니라 게임 세션 종료 시의 간단한 승/패 신호가 포 함될 수 있다. 이 접근 방식은 모든 관련 출력을 수백 Kbits/s(4K 비디오의 경우 수십 Mbits/s)로 전송할 수 있게 하고 GT 액 터 컴포넌트가 복잡한 컴퓨터 비전 문제를 동시에 해결하지 않고 게임 애플리케이션을 플레이하는 방 법을 학습하는 데 집중할 수 있게 한다. 이 프로세스에서, 게임 애플리케이션 개발자는 GT 학습 서비스와 공유하는 데이터에 대해 더 많은 제어 권한을 갖게 된다. 게다가, 이 접근 방식은 독립 실행형 게임 클라이언트 와 서버 기반 게임 애플리케이션에서 동일하게 잘 작동한다. 또한, GT 시스템은 게임이 관찰을 전송하고 액션을 다시 수신하는 사이의 불가피한 수십 밀리초(또는 그 이상)의 대기 시간(latency)으로 인한 심각한 부정 적인 영향 없이 작동한다. 이러한 대기 시간은 게임 애플리케이션이 일반적으로 초당 30프레임 이상(프레임당 33.3ms 미만)으로 실행된다는 점을 감안할 때 게임 플레이 액션에 대한 서버 입력에 의존하는 대체 솔루션의 경 우 특히 문제가 될 수 있으며, 이는 서버와 클라이언트 컴퓨팅 간의 왕복 시간(round trip)보다 짧은 시간일 수 있다. 특정 실시예에서, GT 시스템은 원격 GT 서버와 클라이언트 컴퓨팅 시스템 사이에서 비동기식으 로 동작하여, 예를 들어, 한 프레임에 기초하여 관찰 데이터를 생성하고, 시뮬레이션을 진행하고, 그런 다음 몇 프레임 후에 하나 이상의 게임플레이 액션을 적용한다. 이러한 비동식 동작들은 GT 시스템의 액터/학습자 (actor/learner) 아키텍처에 의해 활용되는데, 여기서 GT 액터는 게임플레이 데이터 모델을 사용하여 게임 플레이 관찰을 게임플레이 액션으로 빠르게 변환하고, GT 학습 서비스는 액터 컴포넌트에 의해 생성된 관 찰 데이터, 액션 및 보상과 게임 애플리케이션과의 상호 작용에 기초하여 새로운 게임플레이 데이터 모델 을 생성한다. AI 동작들을 이 두 컴포넌트로 분리하면 GT 학습 서비스가 안전한 기계 학습 알고리즘과 상 당한 양의 컴퓨팅 리소스를 활용하는 동안 액터 컴포넌트는 추론을 수행하는 시간보다 더 많은 대기 시간을 유 발하지 않고 게임 플레이 관찰을 게임 플레이 액션으로 변환할 수 있다. 이 아키텍처에는 공용 인터넷을 통과하는 것과 관련된 대기 시간을 피하는 것 외에도 많은 이점이 있다. 이 아 키텍처는 (매우 컴퓨팅 집약적인) 트레이닝과 (단일 CPU의 일부에서 수행될 수 있는) 추론 간의 비대칭성과 자 연스럽게 일치한다. GT 액터 컴포넌트에서 경험을 배치(batching)하고 압축함으로써, GT 시스템은 관 련 QPS(초당 쿼리 수)를 ~30x까지, 대역폭을 ~10x까지 줄일 수 있다. 게임은 본질적으로 대화형 매체이다. 안타깝게도, 기존의 ML 워크플로우는 대화형이 아니며 데이터의 제출과 해 당 데이터에 기초한 모델의 생성 사이에 몇 분 또는 몇 시간이 걸린다. GT 시스템은 게임플레이 데이터 모 델을 실시간으로 트레이닝함으로써 이 문제를 해결한다. 특정 실시예에서, GT 학습 서비스가 관찰 데이터 (기존의 게임플레이 데이터 모델을 사용하여 GT 액터 컴포넌트에 의해 수행된 액션에 기초하는지 여부 또 는 하나 이상의 인간 플레이어에 의해 수행된 액션에 기초하는지 여부)를 수신하자마자, GT 학습 서비스는 종종 이전 데모(시연) 및/또는 게임플레이 데이터 모델의 결과를 기반으로 해당 데이터에 대한 트레이닝 모델을 시작한다. 관찰 및 액션의 간결한 표현 덕분에, 새로운 게임플레이 데이터 모델이 몇 초 만에 생성될 수 있다. 이러한 게임플레이 데이터 모델은 인간 플레이어에 의해 상기 제출된 데모에 대해 지속적으로 평가될 수 있으므 로, 새로운 게임플레이 데이터 모델은 GT 액터 컴포넌트에 의해 사용 중인 현재 게임플레이 데이터 모델을 능가 하는 경우에만 GT 액터 컴포넌트에 제공된다. 따라서, 전술한 바와 같이, GT 시스템은 게임 애플리케이션 개발자에게 완전한 실시간 및 대화형인 트레이 닝 경험을 제공한다. 게임 애플리케이션 개발자는 AI를 트레이닝시키기 위해, 게임 애플리케이션의 하나 이상의 출력 상태 각각을 클라이언트 컴퓨팅 디바이스에서 실행하는 액터 컴포넌트의 입력 변수와 연관시키는 제어 정 보를 정의하고 제공할 수 있지만, 게임 애플리케이션 개발자는 단순히 게임 컨트롤러를 들고 게임을 플레이함으 로써 AI를 트레이닝시킬 수도 있다. 게임을 몇 라운드 플레이한 후, 게임 애플리케이션 개발자는 컨트롤러를 내 려놓고 AI가 게임을 플레이하는 것을 지켜볼 수 있다. AI가 문제가 있는 상태를 만나면, 게임 애플리케이션 개 발자는 단지 컨트롤러를 들고, 올바른 행동을 시연한 다음 AI가 다시 제어하도록 한다. 그 결과는 매우 경험적 이고 제어 가능한 서비스이다. GT 학습 서비스가 게임플레이 데이터 모델을 생성하기 위해, GT 액터 컴포넌트는 로컬 관찰 데이터 (게임플레이 관찰, 액션 및 보상을 포함함)를 GT 학습 서비스에 주기적으로 전송한다. (인간 플레이어 를 통한 것과 같은) 인간의 게임플레이 시연을 통해 학습할 때, 이 관찰 데이터는 게임을 하는 동안 인간 이 취한 액션으로부터 도출된다. 특정 실시예에서, 이 경험 데이터는 게임 개발 회사의 직원, 소비자 플레이어 또는 이들의 조합에 의해 생성될 수 있다. 새로운 배치의 관찰 데이터를 수신한 후, GT API는 각각 새로운 게임플레이 데이터 모델을 생성하라는 요 청을 나타내는 새로운 할당(assignment, 과제)를 생성한다. 할당들은 할당 큐를 통해 GT 학습 서비스 에 제공된다. GT 학습 서비스는 게임플레이 액션, 관찰 데이터, 보상 및 할당에 포함된 특정 파라미터를 결합하고, MLP가 이해할 수 있는 포멧으로 변환하고, 새로운 게임플레이 데이터 모델을 생성/평가하 는데 필요한 논리를 포함한다. 이러한 게임플레이 데이터 모델은 일회용으로 설계되며, 특정 실시예에서는 재개 가능한 ML 체크포인트로 상태를 표현할 수 있다. 일단 GT 학습 서비스가 과제에 대한 작업을 완료하면, 응답적으로 생성된 게임플레이 데이터 모델이 게임 플레이 데이터 모델의 일부로서 저장된다. GT 학습 서비스는 클라이언트 컴퓨팅 시스템 내의 온 -디바이스 추론에 사용하기 위해 업데이트된 게임플레이 데이터 모델을 GT 액터 컴포넌트에 제공한다. GT 액터 컴포넌트는 적어도 일부 실시예에서 개발자의 게임과의 실시간 상호작용을 지원하기 위해 밀리초 정도의 추론을 수행할 수 있다. 서버 측에서, GT 학습 서비스는 특정 실시예에서 추가 관찰 데이터를 수십 초 정도의 지속 시간(예를 들어 30초 미만)으로 새로운 게임플레이 데이터 모델로 변환할 수 있다. 본 명세서에 표시된 개별 컴포넌트 및 모듈은 컴포넌트 수준 구조 및 특정 데이터플로우 동작들을 설명하기 위 한 목적의 예로 제공되지만, 다양한 실시예에서 특정 컴포넌트 및 모듈의 다른 배열이 본 명세서에 제시된 기술 을 실현할 수 있음을 이해할 것이다. 도 4는 GT 학습 서버 및 클라이언트 컴퓨팅 시스템 모두에서의 동작들을 포함하는 GT 시스템의 동작 루틴의 개요를 나타내는 블록 흐름도이다. 클라이언트 컴퓨팅 시스템은 하나 이상의 실시예에 따른 게임 애플리케이션 및 GT 액터 컴포넌트(가령, 도 1 및 2의 GT 액터 컴포넌트 또는 도 3의 GT 액터 컴포넌 트)를 실행하고 있다. 루틴은 GT 학습 서버가 게임플레이 데이터 모델을 클라이언트 컴퓨팅 시스템에 제공하고는 블록 에서 시작하고, 클라이언트 컴퓨팅 시스템은 블록에서 GT API를 통해 게임플레이 데이터 모델을 수신한다. 본 명세서의 다른 곳에서 더 자세히 설명된 바와 같이, 특정 실시예에서 GT 학습 서버에 의해 초기에 제공된 게임플레이 데이터 모델은 해당 게임 애플리케이션에 대해 정의된 하나 이상의 파라미터에 기초할 수 있고, 게임 관찰 파라미터, 게임 액션 파라미터(예를 들어, 제어 정보) 및 게임 보상 파라미터의 조 합을 포함할 수 있다. 또한, 초기 게임플레이 데이터 모델(및 후속 게임플레이 데이터 모델)은 하나 이상 의 인간 플레이어로부터 생성된 관찰 데이터에 적어도 부분적으로 기초할 수 있다. 게임플레이 데이터 모델이 블록에서 수신된 후, 루틴은 클라이언트 컴퓨팅 시스템이 게임플레이 데이터 모델을 사용하여 게임플레이에 관한 관찰 데이터를 생성하는 블록으로 진행한다. 블록에서, 클라이언트 컴퓨팅 시스템은 생성된 관찰 데이터를 API를 통해 GT 학습 서버에 제공한다. 특정 실시예에서 관찰 데이터 및 게임플레이 액션은 그러한 정보가 하나 이상의 기준에 응답하여 GT 학습 서비 스에 제공될 때까지 클라이언트 컴퓨팅 시스템에서 (예를 들어, GT 액터 컴포넌트, 예를 들어, 도 3 의 GT 액터 컴포넌트에 의해) 집계될 수 있다. 예를 들어, 도 3을 참조하면, 로컬 관찰 데이터(게임 플레이 액션 정보 포함)의 제공은 명시적 요청 등에 응답하여, 정의된 양의 관찰 데이터가 생성된 후 정의된 지 속 기간 이후에 시작될 수 있다. 블록에서, GT 학습 서버는 게임플레이 데이터 모델을 사용하여 클라이언트 컴퓨팅 시스템 에 의해 생성된 관찰 데이터를 수신하고, 루틴은 블록으로 진행한다. 블록에서, GT 학습 서버는 새로 수신된 관찰 데이터에 기초하여 게임플레이 데이터 모델을 수정한다. 블록에서, GT 학습 서버는 수정된 게임플레이 데이터 모델을 API를 통해 클라이언트 컴퓨 팅 시스템에 제공한다. 블록에서, 클라이언트 컴퓨팅 시스템은 수정된 게임플레이 데이터 모델 을 수신하고, 수정된 게임플레이 데이터 모델을 사용하여 게임플레이 액션에 기초하여 추가 관찰 데이터를 수집하고 생성하기 위해 블록으로 돌아간다. 유사하게, 블록에서 수정된 게임플레이 데이터 모델 을 제공한 후, GT 학습 서버는 클라이언트 컴퓨팅 시스템으로부터 업데이트된 관찰 데이터를 수 신하기 위해 블록으로 복귀한다. 일부 실시예에서, 전술한 기술의 특정 양태는 소프트웨어를 실행하는 처리 시스템의 하나 이상의 프로세서에 의 해 구현될 수 있다. 소프트웨어는 비-일시적 컴퓨터 판독 가능 저장 매체에 저장되거나 유형적으로 구현된 하나 이상의 실행 가능한 명령 세트를 포함한다. 소프트웨어는 하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로세서를 조작하여 위에서 설명한 기술의 하나 이상의 양태를 수행하는 명령 및 특정 데이터를 포함할 수 있 다. 비-일시적 컴퓨터 판독 가능 저장 매체는 예를 들어 자기 또는 광학 디스크 저장 디바이스, 플래시 메모리 와 같은 솔리드 스테이트 저장 디바이스, 캐시, RAM 또는 기타 비휘발성 메모리 디바이스 또는 디바이스들 등을 포함할 수 있다. 비-일시적 컴퓨터 판독 가능 저장 매체에 저장된 실행 가능 명령들은 소스 코드, 어셈블리 언어 코드, 객체 코드 또는 하나 이상의 프로세서에 의해 해석되거나 실행 가능한 기카 명령 포멧일 수 있다. 컴퓨터 판독 가능 저장 매체는 명령 및/또는 데이터를 컴퓨터 시스템에 제공하기 위해 사용하는 동안 컴퓨터 시 스템에 의해 액세스 가능한 임의의 저장 매체 또는 저장 매체의 조합을 포함할 수 있다. 이러한 저장 매체는 광 학 매체(예를 들어, CD, DVD, Blu-Ray 디스크), 자기 매체(예를 들어, 플로피 디스크, 자기 테이프 또는 자기 하드 드라이브), 휘발성 메모리(예를 들어, RAM 또는 캐시), 비휘발성 메모리(예를 들어, ROM 또는 플래시 메모 리), 또는 MEMS(Microelectromechanical System) 기반 저장 매체를 포함할 수 있지만 이에 한정되지 않는다. 컴퓨터 판독 가능 저장 매체는 컴퓨팅 시스템(예를 들어, 시스템 RAM 또는 ROM)에 내장되거나, 컴퓨팅 시스템 (예를 들어, 자기 하드 드라이브)에 고정적으로 부착되거나, 컴퓨팅 시스템(예를 들어, 광 디스크 또는 USB 기 반 플래시 메모리)에 제거 가능하게 부착되거나 유선 또는 무선 네트워크(예를 들어, NAS(Network Accessible Storage))를 통해 컴퓨터 시스템에 연결될 수 있다. 일반적인 설명으로 위에서 설명한 모든 활동 또는 요소가 필요한 것은 아니며 특정 활동 또는 디바이스의 일부 가 필요하지 않을 수 있으며, 설명된 것 외에도 하나 이상의 추가 활동이 수행되거나 요소가 포함될 수 있다. 또한, 활동들이 나열되는 순서가 반드시 수행되는 순서는 아니다. 또한, 구체적인 실시예를 참조하여 개념이 설 명되었다. 그러나, 당업자라면 하기 청구범위에 기재된 본 발명의 범위를 벗어나지 않고 다양한 수정 및 변경이 이루어질 수 있음을 이해할 것이다. 따라서, 명세서 및 도면은 제한적인 의미가 아닌 예시적인 것으로 간주되어 야 하며, 이러한 모든 변형은 본 개시의 범위 내에 포함되도록 의도된다. 이점, 다른 장점 및 문제에 대한 해결책은 특정 실시예와 관련하여 위에서 설명되었다. 그러나 이점, 장점, 문 제에 대한 솔루션 및 이점, 장점 또는 솔루션이 발생하거나 더 두드러지게 만들 수 있는 모든 기능은 일부 또는 모든 청구의 중요하거나 필요하거나 필수적인 기능으로 해석되어서는 안 된다. 더욱이, 위에서 개시된 특정 실 시예는 개시된 주제가 상이하지만 본 명세서의 교시의 혜택을 받는 당업자에게 명백한 동등한 방식으로 수정 및 실시될 수 있기 때문에 단지 예시적인 것이다. 아래의 청구 범위에 기술된 것 외에 본 명세서에 표시된 구성 또 는 설계의 세부 사항에 대한 제한은 없다. 따라서, 위에 개시된 특정 실시예가 변경되거나 수정될 수 있고 그러 한 모든 변형이 개시된 주제의 범위 내에서 고려된다는 것이 명백하다. 따라서, 본 명세서에서 추구하는 보호는 아래의 청구범위에 설명된 바와 같다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2023-7010854", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명은 첨부된 도면을 참조함으로써 당업자에게 더 잘 이해될 수 있고, 그것의 많은 특징 및 이점이 명백해 진다. 다른 도면에서 동일한 참조 기호를 사용하면 유사하거나 동일한 항목을 나타낸다. 도 1은 일부 실시예에 따른 예시적인 네트워크화된 게임 트레이닝 시스템을 도시한다. 도 2는 일부 실시예에 따른 다른 예시적인 네트워크화된 게임 트레이닝 시스템을 도시한다. 도 3은 하나 이상의 실시예에 따라 구현되는 게임플레이 트레이너(GT) 시스템의 개략적인 블록도를 도시한다. 도 4는 하나 이상의 실시예에 따른 GT 시스템의 작동 루틴의 개요를 나타내는 블록 흐름도이다."}
