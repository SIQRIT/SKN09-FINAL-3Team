{"patent_id": "10-2021-0181081", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0097248", "출원번호": "10-2021-0181081", "발명의 명칭": "구동중인 시스템 내의 컴포넌트의 불량을 테스트할 수 있는 시스템 및 그 방법", "출원인": "주식회사 딥엑스", "발명자": "김녹원"}}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "구동중인 시스템 내의 컴포넌트를 테스트할 수 있는 시스템 온 칩(SoC)로서,회로를 각기 포함하는 복수의 기능 컴포넌트와;상기 복수의 기능 컴포넌트들이 서로 통신할 수 있도록 하는 시스템 버스와;상기 복수의 기능 컴포넌트들 중에서 하나 이상의 기능 컴포넌트들에 연결되는 하나 이상의 래퍼(wrapper)와;그리고ICT(in-system component tester)를 포함하고,상기 ICT는:상기 하나 이상의 래퍼를 통하여, 상기 복수의 기능 컴포넌트들의 상태를 모니터하는 과정;유휴 상태(idle state)의 적어도 하나의 기능 컴포넌트를 CUT(component under test)로 선택하는 과정;상기 하나 이상의 래퍼를 통하여, 상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트를 테스트하는 과정;상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트에 대해 상기 시스템 버스로부터의 액세스로 인하여 충돌이 검출되는 것에 기초하여, 상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트에 대한 테스트를 중단(stop)하는 과정; 그리고상기 중단에 기초하여, 상기 적어도 하나의 기능 컴포넌트의 연결을 상기 시스템 버스로 되돌리는(return back)과정을 수행하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 ICT는:상기 적어도 하나의 기능 컴포넌트의 연결을 상기 시스템 버스로 되돌린 후, 모니터링 과정의 결과로서 상기 적어도 하나의 기능 컴포넌트가 다시 상기 유휴 상태로 확인된 경우, 상기 선택 과정을 다시 진행하는 시스템 온칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 충돌에 관한 백-오프 타이머가 만료된 이후에, 상기 선택 과정이 다시 진행되는 시스템온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 복수의 기능 컴포넌트는:하나 이상의 UPU(universal processing unit)을 포함하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 UPU는 하나 이상의 CPU(central processing unit);하나 이상의 GPU(graphic processing unit); 그리고ANN(artificial neural network) 모델을 위한 연산을 수행하도록 설정된 하나 이상의 NPU(neural processingunit)공개특허 10-2022-0097248-3-중에서 하나 이상을 포함하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 복수의 기능 컴포넌트는적어도 하나의 메모리;적어도 하나의 메모리 컨트롤러; 그리고적어도 하나의 I/O(input and output) 컨트롤러중에서 하나 이상을 더 포함하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 ICT는:상기 테스트를 위하여, 상기 하나 이상의 래퍼에게, 상기 CUT로 선택된 상기 하나 이상의 기능 컴포넌트의 연결을 상기 시스템 버스로부터 격리하라고 지시하는 과정을 더 수행하도록 설정되는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 ICT는:상기 복수의 기능 컴포넌트들의 상태를 모니터하도록 설정된 검출기와;상기 ICT의 동작을 관리하도록 설정된 스케줄러와;테스트 입력 데이터를 생성하도록 설정된 생성기와; 그리고상기 CUT로 상기 테스트 입력 데이터를 주입하고, 상기 테스트 입력 데이터를 처리한 상기 CUT로부터 획득되는테스트 결과를 분석하는 테스터중에서 하나 이상을 포함하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 테스트 입력 데이터는 미리 정해진 테스트 데이터 또는 시드(seed)에 기초하여 생성된 랜덤 비트 스트림(random bit stream)인, 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 ICT는상기 테스트가 완료된 이후, 상기 CUT로 선택된 상기 하나 이상의 기능 컴포넌트로부터 획득되는 테스트 결과를분석하는 과정과; 그리고상기 하나 이상의 기능 컴포넌트가 정상이라고 분석되는 것에 기초하여, 상기 하나 이상의 기능 컴포넌트의 연결을 상기 시스템 버스 또는 다른 시스템 연결로 되돌리는(return back) 과정을 더 수행하도록 설정되는 시스템온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 ICT는:상기 하나 이상의 기능 컴포넌트가 결함이 있다고 분석되는 것에 기초하여, 상기 하나 이상의 기능 컴포넌트를비활성화하는 과정을 더 수행하도록 설정되는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트를 모방(imitate)하도록 설정된 FPGA(fieldprogrammable gate array)를 더 포함하는 시스템 온 칩.공개특허 10-2022-0097248-4-청구항 13 제12항에 있어서, 상기 FPGA의 주소는 폐지(revoke)되고, 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트의 주소로 대체되는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 비활성화하는 과정은:상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트의 주소를 폐지(revoke)하는 과정을 포함하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 비활성화하는 과정은:상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트를 파워 오프 하거나 혹은 턴 오프 하는 과정을 포함하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 비활성화하는 과정은:상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트를 상기 시스템 버스로부터 격리하거나 또는 컷 오프하는 과정을 포함하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 ICT는 상기 복수의 기능 컴포넌트가 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트의 스페어 컴포넌트를포함하는 경우, 상기 스페어 컴포넌트를 활성화하는 과정을 더 수행하도록 설정된 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항에 있어서, 상기 테스트는 상기 SoC가 잘못 제조되었거나(mal-manufactured), 손상되었거나(compromised)혹은 고장(breaks down)났는지를 검증하기 위한 것이고,상기 테스트는 상기 SoC가 공장으로부터 출하되기 이전 그리고 상기 SoC가 출하된 이후에도 반복적으로 수행되는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항에 있어서, 상기 테스트는 기능 테스트와는 다른 스캔 테스트이고,상기 스캔 테스트를 위하여, 상기 ICT는 각 CUT 내의 복수의 플리-플롭들을 서로 연결하고, 테스트 입력을 적어도 하나의 플리-플롭으로 주입하고, 상기 CUT가 결함이 있는지 아니면 정상인지를 구동 중에 분석하기 위하여상기 플리-플롭의 결합 로직의 동작으로부터 테스트 결과를 획득하는 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항에 있어서, 상기 복수의 기능 컴포넌트는 NPU를 포함하고, 상기 NPU는 복수의 프로세싱 엘리먼트 어레이를 포함하고,상기 NPU는 상기 복수의 프로세싱 엘리먼트 어레이 내의 적어도 하나 프로세싱 엘리먼트를 선택하여 테스트 하도록 구성된, 시스템 온 칩."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "공개특허 10-2022-0097248-5-구동중인 시스템 온 칩(SoC) 내의 컴포넌트를 테스트하는 방법으로서,복수의 기능 컴포넌트들의 상태를 모니터링하는 단계와;유휴 상태(idle state)의 적어도 하나의 기능 컴포넌트를 CUT(component under test)로 선택하는 단계와;상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트를 테스트하는 단계와;상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트에 대해 시스템 버스로부터의 액세스로 인하여 충돌이 검출되는 것에 기초하여, 상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트에 대한 테스트를 중단(stop)하는단계와; 그리고상기 중단에 기초하여, 상기 적어도 하나의 기능 컴포넌트의 연결을 상기 시스템 버스로 되돌리는(return back)단계를 포함하는 방법."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 적어도 하나의 기능 컴포넌트의 연결을 상기 시스템 버스로 되돌린 후, 모니터링 단계의 결과로서 상기 적어도 하나의 기능 컴포넌트가 다시 상기 유휴 상태로 확인된 경우, 상기 선택 단계로 돌아가는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제21항에 있어서, 테스트를 위하여, 상기 CUT로 선택된 상기 하나 이상의 기능 컴포넌트의 연결을 상기 시스템 버스로부터 격리시키는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제21항에 있어서,상기 테스트가 완료된 이후, 상기 CUT로 선택된 상기 하나 이상의 기능 컴포넌트로부터 획득된 테스트 결과를분석하는 단계와; 그리고상기 하나 이상의 기능 컴포넌트가 정상이라고 분석되는 것에 기초하여, 상기 하나 이상의 기능 컴포넌트의 연결을 상기 시스템 버스로 되돌리는(return back) 단계를 더 수행하는 방법."}
{"patent_id": "10-2021-0181081", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제21항에 있어서, 상기 하나 이상의 기능 컴포넌트가 결함이 있다고 분석되는 것에 기초하여, 상기 하나 이상의 기능 컴포넌트를비활성화는 단계를 더 포함하는 방법."}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "구동중인 시스템 내의 컴포넌트를 테스트할 수 있는 시스템 온 칩(SoC)이 제시된다. 상기 시스템 온 칩은: 회로 를 각기 포함하는 복수의 기능 컴포넌트와; 상기 복수의 기능 컴포넌트들이 서로 통신할 수 있도록 하는 시스템 버스와; 상기 복수의 기능 컴포넌트들 중에서 하나 이상의 기능 컴포넌트들에 연결되는 하나 이상의 래퍼 (뒷면에 계속)"}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 구동중인 시스템의 불량 테스트에 관한 것이다."}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(artificial intelligence: AI)도 점차 발전하고 있다. AI는 인간의 지능, 즉 인식(Recognition), 분 류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정(Control/Decision making) 등을 할 수 있는 지능을 인공적으로 모방하는 것을 의미한다. 또한, 최근에는 인공지능(AI)을 위한 연산 속도를 가속하기 위하여, NPU(Neural processing unit)가 개발되고 있다.다른 한편, 여러가지 반도체 부품들로 구성된 시스템은 PCB(Printed circuit board) 기반 보드 레벨 시스템으로 구현된다. 반도체 제조 공정 기술의 발전으로 고집적도 구현이 가능해짐에 따라 여러 가지 반도체 부품, 예를 들어, 프로 세서, 메모리, 주변 장치 등을 하나의 칩에 구현하는 시스템 온 칩(System on Chip; SoC), 또는 여러 가지 반 도체 부품, 예를 들어, 프로세서, 메모리, 주변 장치 등을 하나의 패키지에 구현하는 시스템 인 패키지(System in Package; SiP)이 제안되고 있다. SoC는 전체 시스템을 칩 하나에 담은 반도체를 말하는 것으로서, 연산 기억 데이터 전환 소자 등 주요 반도체 소자가 하나의 칩에 구현되는 기술을 의미한다. SiP는 전체 시스템을 하나에 패키지에 담은 반도체를 말하는 것으로서, 연산 기억 데이터 전환 소자 등 주요 반도체 소자가 하나의 패키지에 구현되는 기술을 의미한다. 즉, 컴퓨터 중앙처리장치(CPU), 디지털 신호처리 칩(DSP), 마이크로 컨트롤러(MCU) 등을 하나의 반도체 다이(die) 또는 패키지(package)에 통합하여, 칩 또는 패키지 자체가 하나의 시스템이 되도록 하는 것이다. 이처럼 여러가 지 기능을 가진 반도체가 하나의 칩으로 통합되면 보드 공간이 크게 줄어들어, 각종 전자 제품의 크기를 축소시 킬 수 있다. 또한 여러개의 반도체를 별도로 만드는 것에 비해 반도체 제조비용이 훨씬 저렴해지고, 그로 인해 전자 제품의 판매 단가도 낮출 수 있다. 따라서 모든 부품 기능을 집적하는 SoC 또는 SiP 기술은 고성능·저 비용·소형화로 집약되는 첨단 디지털시대의 핵심 부품기술로 떠오르고 있다."}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 발명자는 NPU를 SoC 또는 SiP 내에 통합하게 되면, 보드 기판의 크기가 줄어들게 되고, 결국 전자 제 품의 크기를 혁신적으로 작게 만들 수 있다는 것을 인식하였다. 또한, 본 개시의 발명자는 NPU를 SoC 또는 SiP 내에 통합하게 되면, 각각의 반도체를 개별로 제조하는 것에 비 하여. 제조비용을 절감할 수 있다는 것을 인식하였다. 그러나, 여러 반도체 부품이 SoC 또는 SiP 내에 통합되게 되면, 본 개시의 발명자는 복잡도가 크게 증가될 수 있고 그로 인해 제조 과정에서 불량율도 증가할 수 있다는 것을 인식하였다. 제조 과정에서 불량은 공장 출하 전 테스트에서 발견될 수도 있지만, SoC 또는 SiP 내에 통합된 일부 부품에 대한 미세한 불량은 공장 출하 전 테스트에서는 발견되지 않고, 사용자에게 인계될 수도 있다. 이러한 미세 불량은 반복적인 사용에 의한 피로 스 트레스(fatigue stress) 혹은 물리적인 스트레스에 의하여 점차 증폭되어, 최종적으로는 SoC 또는 SiP 가 오동 작을 일으키도록 할 수 있다. SoC 또는 SiP가 사용자의 엔터테인먼트를 위한 전자 제품에 장착되어 있다면 이러한 오동작은 크게 문제되지 않 을 수 있지만, 본 개시의 발명자는 SoC 또는 SiP가 미션 크리티컬(mission critical)한 제품에 장착되어 있을 경우는 상황이 다를 수 있다는 것을 인식하였다. 특히, 본 개시의 발명자는 SoC 또는 SiP 내의 NPU가 불량, 결함 또는 손상으로 오동작을 하게 되면, 엉뚱한 인 공지능(AI) 연산 결과를 출력할 수 있는 문제점을 인식하였다. 예를 들어, 본 개시의 발명자는 NPU를 포함하는 SoC 또는 SiP가 차량의 자율 주행을 위해 차량, 드론(Drone), UAM(Urban Air Mobility), UAV(unmanned aerial vehicle)에 장착되는 전자 기기, AI 로봇에 장착되는 전자 기 기에서 사용될 경우, NPU의 불량, 결함 또는 손상은 예측하지 못한 AI 연산 결과를 출력할 수 있다는 사실을 인 식하였다. 따라서, 본 개시의 발명자는 공장 출하 전에만 수행할 수 있었던 테스트를 구동중인 SoC 또는 SiP 내에서도 수 행할 수 있도록 하는 방안을 제시할 필요가 있다고 인식하였다. 즉, 테스트를 통해서 불량을 감지하는 것이 필요하다는 사실을 인식하였다."}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 개시에 따르면, 구동중인 시스템 내의 컴포넌트를 테스트할 수 있는 시스템 온 칩(SoC)이 제시 된다. 상기 시스템 온 칩은: 회로를 각기 포함하는 복수의 기능 컴포넌트와; 상기 복수의 기능 컴포넌트들이 서 로 통신할 수 있도록 하는 시스템 버스와; 상기 복수의 기능 컴포넌트들 중에서 하나 이상의 기능 컴포넌트들에 연결되는 하나 이상의 래퍼(wrapper)와; 그리고 ICT(in-system component tester)를 포함할 수 있다. 상기 ICT는: 상기 하나 이상의 래퍼를 통하여, 상기 복수의 기능 컴포넌트들의 상태를 모니터하는 과정; 유휴 상태(idle state)의 적어도 하나의 기능 컴포넌트를 CUT(component under test)로 선택하는 과정; 상기 하나 이상의 래퍼 를 통하여, 상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트를 테스트하는 과정; 상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트에 대해 상기 시스템 버스로부터의 액세스로 인하여 충돌이 검출되는 것에 기초하 여, 상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트에 대한 테스트를 중단(stop)하는 과정; 그리고 상기 중단에 기초하여, 상기 적어도 하나의 기능 컴포넌트의 연결을 상기 시스템 버스로 되돌리는(return back) 과정 을 수행할 수 있다. 상기 ICT는: 상기 적어도 하나의 기능 컴포넌트의 연결을 상기 시스템 버스로 되돌린 후, 모니터링 과정의 결과 로서 상기 적어도 하나의 기능 컴포넌트가 다시 상기 유휴 상태로 확인된 경우, 상기 선택 과정을 다시 진행할 수 있다. 상기 충돌에 관한 백-오프 타이머가 만료된 이후에, 상기 선택 과정이 다시 진행될 수 있다. 상기 복수의 기능 컴포넌트는: 하나 이상의 UPU(universal processing unit)을 포함할 수 있다. 상기 UPU는: 하나 이상의 CPU(central processing unit); 하나 이상의 GPU(graphic processing unit); 그리고 ANN(artificial neural network) 모델을 위한 연산을 수행하도록 설정된 하나 이상의 NPU(neural processing unit) 중에서 하나 이상을 포함할 수 있다. 상기 복수의 기능 컴포넌트는: 적어도 하나의 메모리; 적어도 하나의 메모리 컨트롤러; 그리고 적어도 하나의 I/O(input and output) 컨트롤러 중에서 하나 이상을 더 포함할 수 있다. 상기 ICT는: 상기 테스트를 위하여, 상기 하나 이상의 래퍼에게, 상기 CUT로 선택된 상기 하나 이상의 기능 컴 포넌트의 연결을 상기 시스템 버스로부터 격리하라고 지시하는 과정을 더 수행할 수 있다. 상기 ICT는: 상기 복수의 기능 컴포넌트들의 상태를 모니터하도록 설정된 검출기와; 상기 ICT의 동작을 관리하 도록 설정된 스케줄러와; 테스트 입력 데이터를 생성하도록 설정된 생성기와; 그리고 상기 CUT로 상기 테스트 입력 데이터를 주입하고, 상기 테스트 입력 데이터를 처리한 상기 CUT로부터 획득되는 테스트 결과를 분석하는 테스터 중에서 하나 이상을 포함할 수 있다. 상기 테스트 입력 데이터는 미리 정해진 테스트 데이터 또는 시드(seed)에 기초하여 생성된 랜덤 비트 스트림 (random bit stream)일 수 있다. 상기 ICT는: 상기 테스트가 완료된 이후, 상기 CUT로 선택된 상기 하나 이상의 기능 컴포넌트로부터 획득되는 테스트 결과를 분석하는 과정과; 그리고 상기 하나 이상의 기능 컴포넌트가 정상이라고 분석되는 것에 기초하여, 상기 하나 이상의 기능 컴포넌트의 연결을 상기 시스템 버스 또는 다른 시스템 연결로 되돌리는 (return back) 과정을 더 수행하도록 설정될 수 있다. 상기 ICT는: 상기 하나 이상의 기능 컴포넌트가 결함이 있다고 분석되는 것에 기초하여, 상기 하나 이상의 기능 컴포넌트를 비활성화하는 과정을 더 수행하도록 설정될 수 있다. 상기 시스템 온 칩은: 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트를 모방(imitate)하도록 설정 된 FPGA(field programmable gate array)를 더 포함할 수 있다. 상기 FPGA의 주소는 폐지(revoke)되고, 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트의 주소로 대체될 수 있다. 상기 비활성화하는 과정은: 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트의 주소를 폐지(revok e)하는 과정을 포함할 수 있다. 상기 비활성화하는 과정은: 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트를 파워 오프 하거나 혹 은 턴 오프 하는 과정을 포함할 수 있다. 상기 비활성화하는 과정은: 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트를 상기 시스템 버스로 부터 격리하거나 또는 컷 오프하는 과정을 포함할 수 있다. 상기 ICT는: 상기 복수의 기능 컴포넌트가 상기 결함이 있다고 분석된 상기 하나 이상의 기능 컴포넌트의 스페 어 컴포넌트를 포함하는 경우, 상기 스페어 컴포넌트를 활성화하는 과정을 더 수행하도록 설정될 수 있다. 상기 테스트는 상기 SoC가 잘못 제조되었거나(mal-manufactured), 손상되었거나(compromised) 혹은 고장 (breaks down)났는지를 검증하기 위한 것일 수 있다. 상기 테스트는 상기 SoC가 공장으로부터 출하되기 이전 그 리고 상기 SoC가 출하된 이후에도 반복적으로 수행될 수 있다. 상기 테스트는 기능 테스트와는 다른 스캔 테스트일 수 있다. 상기 스캔 테스트를 위하여, 상기 ICT는 각 CUT 내의 복수의 플리-플롭들을 서로 연결하고, 테스트 입력을 적어도 하나의 플리-플롭으로 주입하고, 상기 CUT가 결함이 있는지 아니면 정상인지를 구동 중에 분석하기 위하여 상기 플리-플롭의 결합 로직의 동작으로부터 테스 트 결과를 획득할 수 있다. 본 명세서의 다른 일 개시에 따르면, 구동중인 시스템 온 칩(SoC) 내의 컴포넌트를 테스트하는 방법이 제시된다. 상기 방법은: 복수의 기능 컴포넌트들의 상태를 모니터링하는 단계와; 유휴 상태(idle state)의 적어 도 하나의 기능 컴포넌트를 CUT(component under test)로 선택하는 단계와; 상기 CUT로 선택된 상기 적어도 하 나의 기능 컴포넌트를 테스트하는 단계와; 상기 CUT로 선택된 상기 적어도 하나의 기능 컴포넌트에 대해 시스템 버스로부터의 액세스로 인하여 충돌이 검출되는 것에 기초하여, 상기 CUT로 선택된 상기 적어도 하나의 기능 컴 포넌트에 대한 테스트를 중단(stop)하는 단계와; 그리고 상기 중단에 기초하여, 상기 적어도 하나의 기능 컴포 넌트의 연결을 상기 시스템 버스로 되돌리는(return back) 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 공장 출하 전에만 수행할 수 있었던 테스트를 구동중인 SoC 또는 SiP 내에서도 수행할 수 있 다. 본 개시에 따르면, 테스트 결과를 기초로 불량을 감지할 수 있다. 본 개시에 따르면, 공장 출하 전 발견되지 않았던 SoC 또는 SiP 내의 미세 불량이, 반복적인 구동으로 인한 피 로 스트레스(fatigue stress) 혹은 물리적인 스트레스에 의하여 점차 증폭되더라도, 이를 발견해낼 수 있는 장 점이 있다. 본 개시에 따르면, SoC 또는 SiP 내의 NPU가 불량, 결함 또는 손상으로 엉뚱한 인공지능(AI) 연산 결과를 출력 하는 것을 검출할 수 있는 장점이 있다. 따라서, 본 개시에 따르면, 차량의 자율 주행, 드론(Drone), UAM(Urban Air Mobility), UAV(unmanned aerial vehicle) 또는 AI 로봇에 장착되는 SoC 또는 SiP의 높은 신뢰성을 보장할 수 있다. 본 개시는 SoC를 위주로 설명하였지만, 본 개시는 SoC에만 한정되는 것은 아니며, 본 개시의 내용은 SIP(System in Package) 혹은 PCB(Printed circuit board) 기반 보드 레벨 시스템에도 적용될 수 있다."}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것으로, 본 개시의 개념에 따 른 실시 예들은 다양한 형태로 실시될 수 있으며 본 개시의 개념에 따른 실시 예들은 다양한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있으므로 특정 실시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따 른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 실시 예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더 욱 명확히 전달하기 위함이다. <용어의 정의> 이하, 본 명세서에서 제시되는 개시들의 이해를 돕고자, 본 명세서에서 사용되는 용어들에 대하여 간략하게 정 리하기로 한다. NPU: 신경망 프로세싱 유닛(Neural Processing Unit)의 약어로서, CPU(Central processing unit)과 별개로 인 공 신경망 모델의 연산을 위해 특화된 프로세서를 의미할 수 있다. ANN: 인공 신경망(artificial neural network)의 약어로서, 인간의 지능을 모방하기 위하여, 인간 뇌 속의 뉴런 들(Neurons)이 시냅스(Synapse)를 통하여 연결되는 것을 모방하여, 노드들을 레이어(Layer: 계층) 구조로 연결 시킨, 네트워크를 의미할 수 있다. 인공 신경망의 구조에 대한 정보: 레이어의 개수에 대한 정보, 레이어 내의 노드의 개수, 각 노드의 값, 연산 처리 방법에 대한 정보, 각 노드에 적용되는 가중치 행렬에 대한 정보 등을 포함하는 정보이다. 인공 신경망의 데이터 지역성에 대한 정보: 신경망 프로세싱 유닛이 별개의 메모리에 요청하는 데이터 접근 요 청 순서에 기반하여 신경망 프로세싱 유닛이 처리하는 인공신경망모델의 연산 순서를 예측하게 하는 정보이다. DNN: 심층 신경망(Deep Neural Network)의 약어로서, 보다 높은 인공 지능을 구현하기 위하여, 인공 신경망의 은닉 레이어의 개수를 늘린 것을 의미할 수 있다. CNN: 컨볼루션 신경망(Convolutional Neural Network)의 약어로서, 인간 뇌의 시각 피질에서 영상을 처리하는 것과 유사한 기능을 하는 신경망이다. 컨볼루션 신경망은 영상처리에 적합한 것으로 알려져 있으며, 입력 데이 터의 특징들을 추출하고, 특징들의 패턴을 파악하기에 용이한 것으로 알려져 있다. 커널: CNN에 적용되는 가중치 행렬을 의미할 수 있다. 이하, 첨부한 도면을 참조하여 본 개시의 바람직한 실시 예를 설명함으로써, 본 개시를 상세히 설명한다. 이하, 본 개시의 실시 예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 개시에 따른 신경망 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 1에 도시된 신경망 프로세싱 유닛(neural processing unit, NPU)은 인공 신경망을 위한 동작을 수행하 도록 특화된 프로세서이다. 인공 신경망은 여러 입력 또는 자극이 들어오면 각각 가중치를 곱해 더해주고, 추가적으로 편차를 더한 값을 활 성화 함수를 통해 변형하여 전달하는 인공 뉴런들이 모인 네트워크를 의미한다. 이렇게 학습된 인공 신경망은 입력 데이터로부터 추론(inference) 결과를 출력하는데 사용될 수 있다. 상기 신경망 프로세싱 유닛은 전기/전자 회로로 구현된 반도체일 수 있다. 상기 전기/전자 회로라 함은 수 많은 전자 소자, (예컨대 트렌지스터, 커패시터)를 포함하는 것을 의미할 수 있다. 상기 신경망 프로세싱 유닛 은 프로세싱 엘리먼트(processing element: PE) 어레이, NPU 내부 메모리, NPU 스케줄러, 및 NPU 인터페이스를 포함할 수 있다. 프로세싱 엘리먼트 어레이, NPU 내부 메모리, NPU 스케줄 러, 및 NPU 인터페이스 각각은 수많은 트렌지스터들이 연결된 반도체 회로일 수 있다. 따라서, 이들 중 일부는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서만 식별될 수 있다. 예컨대, 임의 회로 는 프로세싱 엘리먼트 어레이으로 동작하기도 하고, 혹은 NPU 스케줄러로 동작될 수도 있다. 상기 신경망 프로세싱 유닛은 프로세싱 엘리먼트 어레이, 프로세싱 엘리먼트 어레이에서 추론될 수 있는 인공신경망모델을 저장하도록 구성된 NPU 내부 메모리, 및 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 프로세싱 엘리먼트 어레이 및 NPU 내부 메모리를 제어하도록 구성 된 NPU 스케줄러를 포함할 수 있다. 여기서, 인공신경망모델은 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 포함할 수 있다. 인공신경망모델은 특정 추론 기능을 수행하도록 학습된 AI 인식모델을 의 미할 수 있다. 프로세싱 엘리먼트 어레이는 인공 신경망을 위한 동작을 수행할 수 있다. 예를 들어, 입력 데이터가 입력 되었을 때, 프로세싱 엘리먼트 어레이는 인공 신경망이 학습을 수행하도록 할 수 있다. 학습이 완료된 이 후, 입력 데이터가 입력되었을 때, 프로세싱 엘리먼트 어레이는 학습 완료된 인공 신경망을 통해 추론 결 과를 도출하는 동작을 수행할 수 있다. NPU 인터페이스는 시스템 버스를 통해서 도 5a, 도 6a 또는 도 6b에 도시된 ANN 구동 장치 내의 다양한 구 성요소들, 예컨대 메모리와 통신할 수 있다. 예를 들면, 신경망 프로세싱 유닛은 NPU 인터페이스를 통해서 도 5a, 도 6a 또는 도 6b에 도시된 메 모리에 저장된 인공신경망모델의 데이터를 NPU 내부 메모리으로 불러올 수 있다. NPU 스케줄러는 신경망 프로세싱 유닛의 추론 연산을 위한 프로세싱 엘리먼트 어레이의 연산 및 NPU 내부 메모리의 읽기 및 쓰기 순서를 제어하도록 구성된다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 분석하여 프로세싱 엘리먼 트 어레이 및 NPU 내부 메모리을 제어하도록 구성될 수 있다. NPU 스케줄러는 프로세싱 엘리먼트 어레이에서 작동할 인공신경망모델의 구조를 분석하거나 또는 제 공받을 수 있다. 인공신경망모델이 포함할 수 있는 인공 신경망의 데이터는 각각의 레이어의 노드 데이터, 레이 어들의 배치 데이터 지역성 정보 또는 구조에 대한 정보, 각각의 레이어의 노드를 연결하는 연결망 각각의 가중 치 데이터를 저장할 수 있다. 인공 신경망의 데이터는 NPU 스케줄러 내부에 제공되는 메모리 또는 NPU 내 부 메모리에 저장될 수 있다. NPU 스케줄러는 도 5a, 도 6a 또는 도 6b에 도시된 메모리에 액세 스하여 필요한 데이터를 활용할 수 있다. 단, 이에 제한되지 않으며, 즉, 인공신경망모델의 노드 데이터 및 가 중치 데이터 등의 데이터에 기초하여 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 생성할 수 있다. 가중치 데이터는 가중치 커널로 지칭되는 것도 가능하다. 노드 데이터는 피처 맵으로 지칭되는 것도 가능 하다. 예를 들면, 인공신경망모델의 구조가 정의된 데이터는 인공신경망모델을 설계하거나 또는 학습이 완료될 때 생성될 수 있다. 단, 이에 제한되지 않는다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 인공신경망모델 의 연산 순서를 스케줄링 할 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 인공신경망모델 의 레이어의 노드 데이터 및 연결망의 가중치 데이터가 저장된 메모리 어드레스 값을 획득할 수 있다. 예를 들 면, NPU 스케줄러는 메모리에 저장된 인공신경망모델의 레이어의 노드 데이터 및 연결망의 가중치 데이터 가 저장된 메모리 어드레스 값을 획득할 수 있다. 따라서 NPU 스케줄러는 구동할 인공신경망모델의 레이어 의 노드 데이터 및 연결망의 가중치 데이터를 메모리에서 가져와서 NPU 내부 메모리에 저장할 수 있 다. 각각의 레이어의 노드 데이터는 대응되는 각각의 메모리 어드레스 값을 가질 수 있다. 각각의 연결망의 가 중치 데이터는 대응되는 각각의 메모리 어드레스 값을 가질 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보, 예를 들면, 인공신경망모델 의 인공 신경망의 레이어들의 배치 데이터 지역성 정보 또는 구조에 대한 정보에 기초해서 프로세싱 엘리먼트 어레이의 연산 순서를 스케줄링 할 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 스케줄링 하기 때문에, 일반적인 CPU의 스케줄링 개념과 다르게 동작할 수 있다. 일반적인 CPU의 스케줄링은 공평성, 효율성, 안정성, 반응 시간 등을 고려하여, 최상의 효율을 낼 수 있도록 동작한다. 즉, 우선 순위, 연산 시간 등을 고려 해서 동일 시간내에 가장 많은 프로세싱을 수행하도록 스케줄링 한다. 종래의 CPU는 각 프로세싱의 우선 순서, 연산 처리 시간 등의 데이터를 고려하여 작업을 스케줄링 하는 알고리 즘을 사용하였다. 이와 다르게 NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 프 로세싱 순서를 결정할 수 있다. 더 나아가면, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보 및/또는 사용 하려는 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 프로세싱 순서를 결정할 수 있다. 단, 본 개시는 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보에 제한되지 않는다. 예 를 들면, 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보는 NPU 내부 메모리의 메모리 크기, NPU 내부 메모리의 계층(hierarchy) 구조, 프로세싱 엘리먼트들(PE1 to PE12)의 개수 데이터, 프로세싱 엘리먼트들(PE1 to PE12)의 연산기 구조 중 적어도 하나 이상의 데이터를 활용하여 프로세싱 순서를 결정할 수 있다. 즉, 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보는 NPU 내 부 메모리의 메모리 크기, NPU 내부 메모리의 계층(hierarchy) 구조, 프로세싱 엘리먼트들(PE1 to PE12)의 개수 데이터, 및 프로세싱 엘리먼트들(PE1 to PE12)의 연산기 구조 중 적어도 하나 이상의 데이터 포함 할 수 있다. 단, 본 개시는 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보에 제한되 지 않는다. NPU 내부 메모리의 메모리 크기는 메모리 용량에 대한 정보를 포함한다. NPU 내부 메모리(12 0)의 계층(hierarchy) 구조는 각각의 계층 구조에 대한 구체적인 계층 간의 연결 관계에 대한 정보를 포함한다. 프로세싱 엘리먼트들(PE1 to PE12)의 연산기 구조는 프로세싱 엘리먼트 내부의 구성요소들에 대한 정보를 포함 한다. 본 개시의 일 예시에 따른, 신경망 프로세싱 유닛은 적어도 하나의 프로세싱 엘리먼트, 적어도 하나의 프 로세싱 엘리먼트에 의해서 추론될 수 있는 인공신경망모델을 저장할 수 있는 NPU 내부 메모리, 및 인공신 경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 적어도 하나의 프로세싱 엘리먼트 및 NPU 내 부 메모리을 제어하도록 구성된 NPU 스케줄러를 포함할 수 있다. 그리고 NPU 스케줄러는 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보를 더 제공받도록 구성될 수 있다. 또한 신경 망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보는 NPU 내부 메모리의 메모리 크기, NPU 내부 메모리의 계층(hierarchy) 구조, 적어도 하나의 프로세싱 엘리먼트의 개수 데이터, 및 적어도 하 나의 프로세싱 엘리먼트의 연산기 구조 중 적어도 하나의 데이터를 포함할 수 있다. 인공신경망모델의 구조에 의하면, 각 레이어 별 연산은 순차적으로 수행된다. 즉, 인공신경망모델의 구조가 확 정될 경우, 레이어 별 연산순서가 정해질 수 있다. 이러한 인공신경망모델의 구조에 따른 연산의 순서 또는 데 이터 흐름의 순서를 알고리즘 레벨에서의 인공신경망모델의 데이터 지역성으로 정의할 수 있다. 컴파일러가 인공신경망모델이 신경망 프로세싱 유닛에서 실행되도록 컴파일 할 경우, 신경망 프로세싱 유 닛-메모리 레벨에서의 인공신경망모델의 인공신경망 데이터 지역성이 재구성될 수 있다. 즉, 컴파일러, 인공신경망모델에 적용된 알고리즘들, 및 신경망 프로세싱 유닛의 동작 특성에 따라서 신경 망 프로세싱 유닛-메모리 레벨에서의 인공신경망모델의 데이터 지역성이 구성될 수 있다. 예를 들면, 동일한 인공신경망모델의 경우에도 신경망 프로세싱 유닛이 해당 인공신경망모델을 연산하는 방식, 예를 들면, 특징맵 타일링(feature map tiling), 프로세싱 엘리먼트의 스테이셔너리(Stationary) 기법 등, 신경망 프로세싱 유닛의 프로세싱 엘리먼트 개수, 신경망 프로세싱 유닛내 특징맵 및 가중치 등 의 캐쉬 메모리 용량, 신경망 프로세싱 유닛내의 메모리 계층 구조, 해당 인공신경망모델을 연산 처리하기 위한 신경망 프로세싱 유닛의 연산 동작의 순서를 결정해 주는 컴파일러의 알고리즘 특성 등에 따라서 처 리하고자 하는 인공신경망모델의 인공신경망 데이터 지역성이 다르게 구성될 수 있다. 왜냐하면, 상술한 요인들 에 의해서 동일한 인공신경망모델을 연산 처리하더라도 신경망 프로세싱 유닛이 클럭 단위로 매 순간 필요 한 데이터의 순서를 상이하게 결정할 수 있기 때문이다 컴파일러는 신경망 프로세싱 유닛의 워드 단위로 신경망 프로세싱 유닛-메모리 레벨에서 인공신경망모델의 인공신경망 데이터 지역성이 구성하여 물리적인 연산 처리에 필요한 데이터의 순서를 결정할 수 있다. 다르게 설명하면, 신경망 프로세싱 유닛-메모리 레벨에서 존재하는 인공신경망모델의 인공신경망 데이터 지역성 이란 신경망 프로세싱 유닛이 메모리에 요청하는 데이터 접근 요청 순서에 기반하여 신경망 프로세싱 유닛 이 처리하는 인공신경망모델의 연산 순서를 예측하게 하는 정보로 정의될 수 있다. NPU 스케줄러는 인공신경망의 데이터 지역성 정보 또는 구조에 대한 정보를 저장하도록 구성될 수 있다. 즉, NPU 스케줄러는 적어도 인공신경망모델의 인공 신경망의 데이터 지역성 정보 또는 구조에 대한 정보만 활용하더라도 프로세싱 순서를 결정할 수 있다. 즉, NPU 스케줄러는 인공 신경망의 입력 레이어부터 출력 레이어 까지의 데이터 지역성 정보 또는 구조에 대한 정보를 활용하여 연산 순서를 결정할 수 있다. 예를 들면, 입력 레이어 연산이 제1 순위로 스케줄링 되고 출력 레이어 연산이 마지막으로 스케줄링 될 수 있다. 따라서, NPU 스케줄러가 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 제공받는 경우, 인공신경 망모델의 모든 연산 순서를 알 수 있다. 따라서 모든 스케줄링 순서를 결정할 수 있는 효과가 있다. 더 나아가서, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보 및 신경망 프 로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보를 고려하여 프로세싱 순서를 결정할 수 있으며 결정된 순서 별 프로세싱 최적화도 가능하다. 따라서, NPU 스케줄러가 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보 및 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보를 모두 제공받는 경우, 인공신경망모델의 데이터 지역 성 정보 또는 구조에 대한 정보에 의해서 결정된 스케줄링 순서 각각의 연산 효율을 보다 더 향상시킬 수 있는 효과가 있다. 예를 들면, NPU 스케줄러는 4개의 레이어의 인공 신경망 레이어들과 각각의 레이어들을 연결 하는 3개의 레이어의 가중치 데이터들을 가지는 연결망 데이터를 획득할 수 있다. 이러한 경우 NPU 스케줄러 가 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 기초로 프로세싱 순서를 스케줄링 하는 방법에 대하여 예를 들어 아래에서 설명한다. 예를 들면, NPU 스케줄러는 추론 연산을 위한 입력 데이터를 인공신경망모델의 입력 레이어인 제1 레이어 의 노드 데이터로 설정하고, 제1 레이어의 노드 데이터와 제1 레이어에 대응되는 제1 연결망의 가중치 데이터의 MAC(multiply and accumulate) 연산을 먼저 수행하도록 스케줄링 할 수 있다. 단, 본 개시의 예시들은 MAC 연 산에 제한되지 않으며, 인공 신경망 연산은 다양하게 변형실시 될 수 있는 곱셈기 및 덧셈기를 활용하여 인공신 경망 연산을 수행하는 것도 가능하다. 이하 단지 설명의 편의를 위해서 해당 연산을 제1 연산이라 지칭하고, 제 1 연산의 결과를 제1 연산 값이라 지칭하고, 해당 스케줄링을 제1 스케줄링이라 지칭할 수 있다. 예를 들면, NPU 스케줄러는 제1 연산 값을 제1 연결망에 대응되는 제2 레이어의 노드 데이터로 설정하고, 제2 레이어의 노드 데이터와 제2 레이어에 대응되는 제2 연결망의 가중치 데이터의 MAC 연산을 제1 스케줄링 이 후에 수행하도록 스케줄링 할 수 있다. 이하 단지 설명의 편의를 위해서 해당 연산을 제2 연산이라 지칭하고, 제2 연산의 결과를 제2 연산 값이라 지칭하고, 해당 스케줄링을 제2 스케줄링이라 지칭할 수 있다. 예를 들면, NPU 스케줄러는 제2 연산 값을 제2 연결망에 대응되는 제3 레이어의 노드 데이터로 설정하고, 제3 레이어의 노드 데이터와 제3 레이어에 대응되는 제3 연결망의 가중치 데이터의 MAC 연산을 제2 스케줄링에 수행하도록 스케줄링 할 수 있다. 이하 단지 설명의 편의를 위해서 해당 연산을 제3 연산이라 지칭하고, 제3 연 산의 결과를 제3 연산 값이라 지칭하고, 해당 스케줄링을 제3 스케줄링이라 지칭할 수 있다. 예를 들면, NPU 스케줄러는 제3 연산 값을 제3 연결망에 대응되는 출력 레이어인 제4 레이어의 노드 데이 터로 설정하고, 제4 레이어의 노드 데이터에 저장된 추론 결과를 NPU 내부 메모리에 저장하도록 스케줄링 할 수 있다. 이하 단지 설명의 편의를 위해서 해당 스케줄링을 제4 스케줄링이라 지칭할 수 있다. 정리하면, NPU 스케줄러는 제1 스케줄링, 제2 스케줄링, 제3 스케줄링, 및 제4 스케줄링 순서대로 연산이 수행되도록 NPU 내부 메모리과 프로세싱 엘리먼트 어레이를 제어할 수 있다. 즉, NPU 스케줄러 는 설정된 스케줄링 순서대로 연산이 수행되도록 NPU 내부 메모리과 프로세싱 엘리먼트 어레이를 제 어하도록 구성될 수 있다. 정리하면, 본 개시의 일 예시에 따른 신경망 프로세싱 유닛은 인공 신경망의 레이어들의 구조와, 구조에 대응되는 연산 순서 데이터에 기초하여, 프로세싱 순서를 스케줄링 하도록 구성될 수 있다. 예를 들면, NPU 스케줄러는 인공신경망모델의 인공 신경망의 입력 레이어부터 출력 레이어 까지의 데이터 지역성 정보 또는 구조에 대한 정보를 기초로, 프로세싱 순서를 스케줄링 하도록 구성될 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초한 스케줄링 순서를 활용하여 NPU 내부 메모리을 제어하여 신경망 프로세싱 유닛의 연산 가동율을 향상시킬 수 있고, 메모리 재사용율을 향상시킬 수 있는 효과가 있다. 본 개시의 일 예시에 따른 신경망 프로세싱 유닛에서 구동되는 인공 신경망 연산의 특성상 하나의 레이어 의 연산 값이 다음 레이어의 입력 데이터가 되는 특성을 가질 수 있다. 이에, 신경망 프로세싱 유닛은 스케줄링 순서에 따라서 NPU 내부 메모리을 제어하여, NPU 내부 메모 리의 메모리 재사용율을 향상시킬 수 있는 효과가 있다. 메모리 재사용은 메모리에 저장된 데이터를 몇 번 읽는지 횟수로 판단할 수 있다. 예를 들면, 메모리에 특정 데이터를 저장한 다음, 특정 데이터를 1회만 읽은 후 해당 데이터를 삭제하거나 덮어쓰기 하면, 메모리 재사용율은 100%가 될 수 있다. 예를 들면, 메모리에 특정 데 이터를 저장한 다음, 특정 데이터를 4회 읽은 후, 해당 데이터를 삭제하거나 덮어쓰기 하면, 메모리 재사용율은 400%가 될 수 있다. 즉, 메모리 재사용율은 한번 저장된 데이터의 재사용 횟수로 정의될 수 있다. 즉, 메모리 재사용은 메모리에 저장된 데이터 또는 특정 데이터가 저장된 특정 메모리 어드레스를 재사용한다는 것을 의미 할 수 있다. 구체적으로 설명하면, NPU 스케줄러가 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 제 공받도록 구성되고, 제공받은 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 의해서 인공 신경 망의 연산이 진행되는 순서 데이터를 파악할 수 있는 경우, NPU 스케줄러는 인공신경망모델의 특정 레이어 의 노드 데이터와 특정 연결망의 가중치 데이터의 연산 결과가 대응되는 다음 레이어의 노드 데이터가 된다는 사실을 인식하였다. 따라서 NPU 스케줄러는 특정 연산 결과가 저장된 메모리 어드레스의 값을 이어지는 다음 연산에서 재사용 할 수 있다. 따라서 메모리 재사용율이 향상될 수 있다. 예를 들면, 상술한 제1 스케줄링의 제1 연산 값은 제2 스케줄링의 제2 레이어의 노드 데이터로 설정된다. 구체 적으로 설명하면, NPU 스케줄러는 NPU 내부 메모리에 저장된 제1 스케줄링의 제1 연산 값에 대응되는 메모리 어드레스 값을 제2 스케줄링의 제2 레이어의 노드 데이터에 대응되는 메모리 어드레스 값으로 재설정할 수 있다. 즉, 메모리 어드레스 값을 재사용할 수 있다. 따라서 NPU 스케줄러가 제1 스케줄링의 메모리 어 드레스의 데이터를 재사용함으로 써, NPU 내부 메모리은 별도의 메모리 쓰기 동작 없이 제2 스케줄링의 제 2 레이어 노드 데이터로 활용할 수 있는 효과가 있다. 예를 들면, 상술한 제2 스케줄링의 제2 연산 값은 제3 스케줄링의 제3 레이어의 노드 데이터로 설정된다. 구체 적으로 설명하면, NPU 스케줄러는 NPU 내부 메모리에 저장된 제2 스케줄링의 제2 연산 값에 대응되는 메모리 어드레스 값을 제3 스케줄링의 제3 레이어의 노드 데이터에 대응되는 메모리 어드레스 값으로 재설정할 수 있다. 즉, 메모리 어드레스 값을 재사용할 수 있다. 따라서 NPU 스케줄러가 제2 스케줄링의 메모리 어 드레스의 데이터를 재사용함으로 써, NPU 내부 메모리은 별도의 메모리 쓰기 동작 없이 제3 스케줄링의 제 3 레이어 노드 데이터로 활용할 수 있는 효과가 있다. 예를 들면, 상술한 제3 스케줄링의 제3 연산 값은 제4 스케줄링의 제4 레이어의 노드 데이터로 설정된다. 구체 적으로 설명하면, NPU 스케줄러는 NPU 내부 메모리에 저장된 제3 스케줄링의 제3 연산 값에 대응되는 메모리 어드레스 값을 제4 스케줄링의 제4 레이어의 노드 데이터에 대응되는 메모리 어드레스 값으로 재설정할 수 있다. 즉, 메모리 어드레스 값을 재사용할 수 있다. 따라서 NPU 스케줄러가 제3 스케줄링의 메모리 어 드레스의 데이터를 재사용함으로 써, NPU 내부 메모리은 별도의 메모리 쓰기 동작 없이 제4 스케줄링의 제 4 레이어 노드 데이터로 활용할 수 있는 효과가 있다. 더 나아가서, NPU 스케줄러는 스케줄링 순서와 메모리 재사용 여부를 판단해서 NPU 내부 메모리을 제 어하도록 구성되는 것도 가능하다. 이러한 경우 NPU 스케줄러가 인공신경망모델의 데이터 지역성 정보 또 는 구조에 대한 정보를 분석해서 효율적인 스케줄링을 제공할 수 있는 효과가 있다. 또한 메모리 재사용이 가능 한 연산에 필요한 데이터를 중복해서 NPU 내부 메모리에 저장하지 않을 수 있기 때문에 메모리 사용량을 저감할 수 있는 효과가 있다. 또한 NPU 스케줄러는 메모리 재사용만큼 저감된 메모리 사용량을 계산해서 NPU 내부 메모리을 효율화 할 수 있는 효과가 있다. 더 나아가서, NPU 스케줄러는 신경망 프로세싱 유닛의 데이터 지역성 정보 또는 구조에 대한 정보에 기초해서, NPU 내부 메모리의 리소스 사용량, 프로세싱 엘리먼트들(PE1 to PE12)의 리소스 사용량을 모니 터링 하도록 구성될 수 있다. 따라서 신경망 프로세싱 유닛의 하드웨어 리소스 활용 효율을 향상시킬 수 있는 효과가 있다. 본 개시의 일 예시에 따른 신경망 프로세싱 유닛의 NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 활용하여 메모리를 재사용할 수 있는 효과가 있다. 부연 설명하면, 인공신경망모델이 심층 신경망일 경우, 레이어의 개수 및 연결망의 개수가 상당히 증가할 수 있 으며, 이러한 경우 메모리 재사용의 효과가 더욱더 극대화될 수 있는 효과가 있다. 즉, 만약 신경망 프로세싱 유닛이 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보 및 연산 순서를 파악하지 않을 경우, NPU 스케줄러는 NPU 내부 메모리에 저장된 값들의 메모리 재사용 여부를 판단할 수 없다. 따라서, NPU 스케줄러는 각각의 프로세싱에 필요한 메모리 어드레스를 불필요하게 생성하 고, 실질적으로 동일한 데이터를 하나의 메모리 어드레스에서 다른 메모리 어드레스로 복사해야 한다. 따라서 불필요한 메모리 읽기 쓰기 작업이 발생되며, NPU 내부 메모리에 중복되는 값들이 저장되게 되어, 불필요 하게 메모리가 낭비되는 문제가 발생할 수 있다. 프로세싱 엘리먼트 어레이는 인공 신경망의 노드 데이터와 연결망의 가중치 데이터를 연산하도록 구성된 복수의 프로세싱 엘리먼트들(PE1 to PE12)이 배치된 구성을 의미한다. 각각의 프로세싱 엘리먼트는 MAC (multiply and accumulate) 연산기 및/또는 ALU (Arithmetic Logic Unit) 연산기를 포함할 수 있다. 단, 본 개 시에 따른 예시들은 이에 제한되지 않는다. 도 2에서는 예시적으로 복수의 프로세싱 엘리먼트들이 도시되었지만, 하나의 프로세싱 엘리먼트 내부에 MAC을 대체하여, 복수의 곱셈기(multiplier) 및 가산기 트리(adder tree)로 구현된 연산기들이 병렬로 배치되어 구성 되는 것도 가능하다. 이러한 경우, 프로세싱 엘리먼트 어레이는 복수의 연산기를 포함하는 적어도 하나의 프로세싱 엘리먼트로 지칭되는 것도 가능하다. 프로세싱 엘리먼트 어레이는 복수의 프로세싱 엘리먼트들(PE1 to PE12)을 포함하도록 구성된다. 도 2에 도 시된 복수의 프로세싱 엘리먼트들(PE1 to PE12)은 단지 설명의 편의를 위한 예시이며, 복수의 프로세싱 엘리먼 트들(PE1 to PE12)의 개수는 제한되지 않는다. 복수의 프로세싱 엘리먼트들(PE1 to PE12)의 개수에 의해서 프로 세싱 엘리먼트 어레이의 크기 또는 개수가 결정될 수 있다. 프로세싱 엘리먼트 어레이의 크기는 N x M 행렬 형태로 구현될 수 있다. 여기서 N 과 M은 0보다 큰 정수이다. 프로세싱 엘리먼트 어레이는 N x M 개의 프로세싱 엘리먼트를 포함할 수 있다. 즉, 프로세싱 엘리먼트는 1개 이상일 수 있다. 프로세싱 엘리먼트 어레이의 크기는 신경망 프로세싱 유닛이 작동하는 인공신경망모델의 특성을 고려 하여 설계할 수 있다. 부연 설명하면, 프로세싱 엘리먼트의 개수는 작동할 인공신경망모델의 데이터 크기, 요구 되는 동작 속도, 요구되는 소비 전력 등을 고려하여 결정될 수 있다. 인공신경망모델의 데이터 크기는 인공신경 망모델의 레이어 수와 각각의 레이어의 가중치 데이터 크기에 대응되어 크기가 결정될 수 있다. 따라서, 본 개시의 일 예시에 따른 신경망 프로세싱 유닛의 프로세싱 엘리먼트 어레이의 크기는 제한 되지 않는다. 프로세싱 엘리먼트 어레이의 프로세싱 엘리먼트들의 개수가 증가할수록 작동하는 인공신경망 모델의 병렬 연산 능력이 증가되나, 신경망 프로세싱 유닛의 제조 비용 및 물리적인 크기가 증가될 수 있 다. 예를 들면, 신경망 프로세싱 유닛에서 작동되는 인공신경망모델은 30개의 특정 키워드를 감지하도록 학습 된 인공 신경망, 즉 AI 키워드 인식모델일 수 있으며, 이러한 경우, 신경망 프로세싱 유닛의 프로세싱 엘 리먼트 어레이의 크기는 연산량 특성을 고려하여 4 x 3로 설계될 수 있다. 다르게 설명하면, 신경망 프로 세싱 유닛은 12개의 프로세싱 엘리먼트들을 포함할 수 있다. 단, 이에 제한되지 않으며, 복수의 프로세싱 엘리먼트들(PE1 to PE12)의 개수는 예를 들면, 8개 내지 16,384 범위 내에서 선택되는 것도 가능하다. 즉, 본 개시의 예시들은 프로세싱 엘리먼트의 개수에 제한되지 않는다. 프로세싱 엘리먼트 어레이는 인공 신경망 연산에 필요한 덧셈, 곱셈, 누산 등의 기능을 수행하도록 구성된 다. 다르게 설명하면, 프로세싱 엘리먼트 어레이는 MAC(multiplication and accumulation) 연산을 수행하 도록 구성될 수 있다. 이하 프로세싱 엘리먼트 어레이 중 제1 프로세싱 엘리먼트(PE1)를 예를 들어 설명한다. 도 2는 본 개시에 적용될 수 있는 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적인 개념도이다. 본 개시의 일 예시에 따른 신경망 프로세싱 유닛은 프로세싱 엘리먼트 어레이, 프로세싱 엘리먼트 어 레이에서 추론될 수 있는 인공신경망모델을 저장하도록 구성된 NPU 내부 메모리 및 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 프로세싱 엘리먼트 어레이 및 NPU 내부 메모리 을 제어하도록 구성된 NPU 스케줄러를 포함하고, 프로세싱 엘리먼트 어레이는 MAC 연산을 수행 하도록 구성되고, 프로세싱 엘리먼트 어레이는 MAC 연산 결과를 양자화해서 출력하도록 구성될 수 있다. 단, 본 개시의 예시들은 이에 제한되지 않는다. NPU 내부 메모리은 메모리 크기와 인공신경망모델의 데이터 크기에 따라 인공신경망모델의 전부 또는 일부 를 저장할 수 있다. 제1 프로세싱 엘리먼트(PE1)는 곱셈기, 가산기, 누산기, 및 비트 양자화 유닛을 포함할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않으며, 프로세싱 엘리먼트 어레이는 인공 신경망의 연 산 특성을 고려하여 변형 실시될 수도 있다. 곱셈기는 입력 받은 (N)bit 데이터와 (M)bit 데이터를 곱한다. 곱셈기의 연산 값은 (N+M)bit 데이터 로 출력된다. 여기서 N과 M은 0보다 큰 정수이다. (N)bit 데이터를 입력 받는 제1 입력부는 변수같은 특성을 가 지는 값을 입력 받도록 구성될 수 있고 (M)bit 데이터를 입력 받는 제2 입력부는 상수 같은 특성을 가지는 값을 입력 받도록 구성될 수 있다. NPU 스케줄러가 변수 값과 상수 값 특성을 구분할 경우, NPU 스케줄러 는 NPU 내부 메모리의 메모리 재사용율을 증가시킬 수 있는 효과가 있다. 단, 곱셈기의 입력 데이터 는 상수 값과 변수 값에 제한되지 않는다. 즉, 본 개시의 예시들에 따르면, 프로세싱 엘리먼트의 입력 데이터는 상수 값과 변수 값의 특성을 이해하여 동작할 수 있기 때문에, 신경망 프로세싱 유닛의 연산 효율을 향상 시킬 수 있다. 하지만 신경망 프로세싱 유닛은 입력 데이터의 상수 값 및 변수 값의 특징에 제한되지 않는 다. 여기서 변수 같은 특성을 가지는 값의 의미 또는 변수의 의미는, 해당 값이 저장된 메모리 어드레스의 값의 경 우, 들어오는 입력 데이터가 갱신될 때마다 갱신된다는 것을 의미한다. 예를 들면, 각 레이어의 노드 데이터는 인공신경망모델의 가중치 데이터가 반영된 MAC 연산 값일 수 있으며, 해당 인공신경망모델로 동영상 데이터의 객체 인식 등을 추론할 경우, 매 프레임마다 입력 영상이 바뀌기 때문에, 각 레이어의 노드 데이터는 변하게 된 다. 여기서 상수 같은 특성을 가지는 값의 의미 또는 상수의 의미는, 해당 값이 저장된 메모리 어드레스의 값의 경 우, 들어오는 입력 데이터의 갱신과 상관없이 보존된다는 것을 의미한다. 예를 들면, 연결망의 가중치 데이터는 인공신경망모델의 고유한 추론 판단 기준으로, 해당 인공신경망모델로 동영상 데이터의 객체 인식 등을 추론하 더라도, 연결망의 가중치 데이터는 변하지 않을 수 있다. 즉, 곱셈기는 하나의 변수와 하나의 상수를 입력 받도록 구성될 수 있다. 부연 설명하면, 제1 입력부에 입 력되는 변수 값은 인공 신경망의 레이어의 노드 데이터일 수 있으며, 노드 데이터는 인공 신경망의 입력 레이어 의 입력 데이터, 은닉 레이어의 누산 값, 및 출력 레이어의 누산 값일 수 있다. 제2 입력부에 입력되는 상수 값 은 인공 신경망의 연결망의 가중치 데이터일 수 있다. NPU 스케줄러는 상수 값의 특성을 고려하여 메모리 재사용율을 향상시키도록 구성될 수 있다. 변수 값은 각 레이어의 연산 값이며, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 재사용 가능한 변수 값을 인식하고, 메모리를 재사용 하도록 NPU 내부 메모리을 제 어할 수 있다. 상수 값은 각 연결망의 가중치 데이터이며, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구 조에 대한 정보에 기초하여 반복 사용되는 연결망의 상수 값을 인식하고, 메모리를 재사용 하도록 NPU 내부 메 모리을 제어할 수 있다. 즉, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 재사용 가능 한 변수 값 및 재사용 가능한 상수 값을 인식하고, NPU 스케줄러는 메모리를 재사용 하도록 NPU 내부 메모 리을 제어하도록 구성될 수 있다. 프로세싱 엘리먼트는 곱셈기의 제1 입력부 및 제2 입력부 중 하나의 입력부에 0이 입력될 때, 연산을 하지 않더라도 연산 결과가 0이 된다는 사실을 알기 때문에, 곱셈기가 연산을 하지 않도록 동작을 제한할 수 있 다. 예를 들면, 곱셈기의 제1 입력부 및 제2 입력부 중 하나의 입력부에 0이 입력될 때, 곱셈기는 제로 스키핑(zero skipping) 방식으로 동작하도록 구성될 수 있다. 제1 입력부 및 제2 입력부에 입력되는 데이터의 비트 폭(bit width)은 인공신경망모델의 각각의 레이어의 노드 데이터 및 가중치 데이터의 양자화에 따라서 결정될 수 있다. 예를 들면, 제1 레이어의 노드 데이터가 5bit로 양자화 되고 제1 레이어의 가중치 데이터가 7bit로 양자화될 수 있다. 이러한 경우 제1 입력부는 5bit 데이터를 입력 받도록 구성되고, 제2 입력부는 7bit 데이터를 입력 받도록 구성될 수 있다. 신경망 프로세싱 유닛은 NPU 내부 메모리에 저장된 양자화된 데이터가 프로세싱 엘리먼트의 입력부들 에 입력될 때 양자화된 비트 폭이 실시간으로 변환되도록 제어할 수 있다. 즉, 레이어 마다 양자화 된 비트 폭 이 다를 수 있으며, 프로세싱 엘리먼트는 입력되는 데이터의 비트 폭이 변환될 때 실시간으로 비트 폭 정보를 신경망 프로세싱 유닛에서 제공받아서 실시간으로 비트 폭을 변환시켜서 입력 데이터를 생성하도록 구성될 수 있다. 누산기는 (L)loops 횟수만큼 가산기를 사용하여 곱셈기의 연산 값과 누산기의 연산 값을 누산 한다. 따라서 누산기의 출력부와 입력부의 데이터의 비트 폭은 (N+M+log2(L))bit로 출력될 수 있다. 여기서 L은 0보다 큰 정수이다. 누산기는 누산이 종료되면, 초기화 신호(initialization reset)를 인가 받아서 누산기 내부에 저장된 데이터를 0으로 초기화 할 수 있다. 단, 본 개시에 따른 예시들은 이에 제한되지 않는다. 비트 양자화 유닛은 누산기에서 출력되는 데이터의 비트 폭을 저감할 수 있다. 비트 양자화 유닛 은 NPU 스케줄러에 의해서 제어될 수 있다. 양자화된 데이터의 비트 폭은 (X)bit로 출력될 수 있다. 여기서 X는 0보다 큰 정수이다. 상술한 구성에 따르면, 프로세싱 엘리먼트 어레이는 MAC 연산을 수행하도 록 구성되고, 프로세싱 엘리먼트 어레이는 MAC 연산 결과를 양자화해서 출력할 수 있는 효과가 있다. 특히 이러한 양자화는 (L)loops가 증가할수록 소비 전력을 더 절감할 수 있는 효과가 있다. 또한 소비 전력이 저감되 면 발열도 저감할 수 있는 효과가 있다. 특히 발열을 저감하면 신경망 프로세싱 유닛의 고온에 의한 오동 작 발생 가능성을 저감할 수 있는 효과가 있다. 비트 양자화 유닛의 출력 데이터(X)bit은 다음 레이어의 노드 데이터 또는 합성곱의 입력 데이터가 될 수 있다. 만약 인공신경망모델이 양자화되었다면, 비트 양자화 유닛은 양자화된 정보를 인공신경망모델에서 제공받도록 구성될 수 있다. 단, 이에 제한되지 않으며, NPU 스케줄러는 인공신경망모델을 분석하여 양자 화된 정보를 추출하도록 구성되는 것도 가능하다. 따라서 양자화된 데이터 크기에 대응되도록, 출력 데이터 (X)bit를 양자화 된 비트 폭으로 변환하여 출력될 수 있다. 비트 양자화 유닛의 출력 데이터(X)bit는 양자 화된 비트 폭으로 NPU 내부 메모리에 저장될 수 있다. 본 개시의 일 예시에 따른 신경망 프로세싱 유닛의 프로세싱 엘리먼트 어레이는 곱셈기, 가산기 , 누산기, 및 비트 양자화 유닛을 포함한다. 프로세싱 엘리먼트 어레이는 비트 양자화 유 닛에 의해서 누산기에서 출력되는 (N+M+log2(L))bit의 비트 폭의 데이터를 (X)bit의 비트 폭으로 저 감할 수 있다. NPU 스케줄러는 비트 양자화 유닛을 제어하여 출력 데이터의 비트 폭을 LSB(least significant bit)에서 MSB(most significant bit)까지 소정 비트 만큼 저감할 수 있다. 출력 데이터의 비트 폭 이 저감되면 소비 전력, 연산량, 메모리 사용량이 저감될 수 있는 효과가 있다. 하지만 비트 폭이 특정 길이 이 하로 저감될 경우, 인공신경망모델의 추론 정확도가 급격히 저하될 수 있는 문제가 발생될 수 있다. 따라서, 출 력 데이터의 비트 폭 저감, 즉, 양자화 수준은 인공신경망모델의 추론 정확도 저감 수준 대비 소비 전력, 연산 량, 메모리 사용량 저감 정도를 비교하여 결정할 수 있다. 양자화 수준의 결정은 인공신경망모델을 목표 추론 정확도를 결정하고, 비트 폭을 점진적으로 저감하면서 테스트 하는 방법으로 결정하는 것도 가능하다. 양자화 수준은 각각의 레이어의 연산 값마다 각각 결정될 수 있다. 상술한 제1 프로세싱 엘리먼트(PE1)에 따르면 곱셈기의 (N)bit 데이터와 (M)bit 데이터의 비트 폭을 조절 하고, 비트 양자화 유닛에 의해서 연산 값(X)bit의 비트 폭을 저감함으로 써, 프로세싱 엘리먼트 어레이 는 MAC 연산 속도를 향상시키면서 소비 전력을 저감할 수 있는 효과가 있으며, 인공 신경망의 합성곱 (convolution)연산을 보다 더 효율적으로 할 수 있는 효과도 있다. 신경망 프로세싱 유닛의 NPU 내부 메모리은 프로세싱 엘리먼트 어레이의 MAC 연산 특성 및 소비 전력 특성을 고려하여 구성된 메모리 시스템일 수 있다. 예를 들면, 신경망 프로세싱 유닛은, 프로세싱 엘리먼트 어레이의 MAC 연산 특성 및 소비 전력 특성 을 고려하여 프로세싱 엘리먼트 어레이의 연산 값의 비트 폭을 저감하도록 구성될 수 있다. 신경망 프로세싱 유닛의 NPU 내부 메모리은 신경망 프로세싱 유닛의 소비 전력을 최소화하도록 구성될 수 있다. 신경망 프로세싱 유닛의 NPU 내부 메모리은 작동되는 인공신경망모델의 데이터 크기 및 연산 단계를 고려하여 저전력으로 메모리를 제어하도록 구성된 메모리 시스템일 수 있다.신경망 프로세싱 유닛의 NPU 내부 메모리은 인공신경망모델의 데이터 크기 및 연산 단계를 고려하여 가중치 데이터가 저장된 특정 메모리 어드레스를 재사용하도록 구성된 저전력 메모리 시스템일 수 있다. 신경망 프로세싱 유닛은 비선형성을 부여하기 위한 여러 가지 활성화 함수를 제공할 수 있다. 예를 들면, 시그모이드 함수, 하이퍼볼릭 탄젠트 함수, 또는 ReLU함수를 제공할 수 있다. 활성화 함수는 MAC 연산 이후에 선택적으로 적용될 수 있다. 활성화 함수가 적용된 연산 값은, 활성화 맵으로 지칭될 수 있다. 도 3은 도 1에 도시된 신경망 프로세싱 유닛의 변형예를 나타낸 예시도이다. 도 3에 도시된 신경망 프로세싱 유닛은 도 1에 예시적으로 도시된 프로세싱 유닛과 비교하면, 프로세 싱 엘리먼트 어레이를 제외하곤 실질적으로 동일하기 때문에, 이하 단지 설명의 편의를 위해서 중복 설명 은 생략할 수 있다. 도 3에 예시적으로 도시된 프로세싱 엘리먼트 어레이는 복수의 프로세싱 엘리먼트들(PE1 to PE12) 외에, 각각의 프로세싱 엘리먼트들(PE1 to PE12)에 대응되는 각각의 레지스터 파일들(RF1 to RF12)을 더 포함할 수 있 다. 도 3에 도시된 복수의 프로세싱 엘리먼트들(PE1 to PE12) 및 복수의 레지스터 파일들(RF1 to RF12)은 단지 설명 의 편의를 위한 예시이며, 복수의 프로세싱 엘리먼트들(PE1 to PE12) 및 복수의 레지스터 파일들(RF1 to RF12) 의 개수는 제한되지 않는다. 복수의 프로세싱 엘리먼트들(PE1 to PE12) 및 복수의 레지스터 파일들(RF1 to RF12)의 개수에 의해서 프로세싱 엘리먼트 어레이의 크기 또는 개수가 결정될 수 있다. 프로세싱 엘리먼트 어레이 및 복수의 레지스터 파일들(RF1 to RF12)의 크기는 N x M 행렬 형태로 구현될 수 있다. 여기서 N 과 M은 0보다 큰 정수이다. 프로세싱 엘리먼트 어레이의 어레이 크기는 신경망 프로세싱 유닛이 작동하는 인공신경망모델의 특성 을 고려하여 설계할 수 있다. 부연 설명하면, 레지스터 파일의 메모리 크기는 작동할 인공신경망모델의 데이터 크기, 요구되는 동작 속도, 요구되는 소비 전력 등을 고려하여 결정될 수 있다. 신경망 프로세싱 유닛의 레지스터 파일들(RF1 to RF12)은 프로세싱 엘리먼트들(PE1 to PE12)과 직접 연결 된 정적 메모리 유닛이다. 레지스터 파일들(RF1 to RF12)은 예를 들면, 플립플롭, 및/또는 래치 등으로 구성될 수 있다. 레지스터 파일들(RF1 to RF12)은 대응되는 프로세싱 엘리먼트들(RF1 to RF12)의 MAC 연산 값을 저장하 도록 구성될 수 있다. 레지스터 파일들(RF1 to RF12)은 NPU 시스템 메모리와 가중치 데이터 및/또는 노드 데이터를 제공하거나 제공받도록 구성될 수 있다. 도 4는 예시적인 인공신경망모델을 설명하는 개략적인 개념도이다. 이하 신경망 프로세싱 유닛에서 작동될 수 있는 예시적인 인공신경망모델(110a)의 연산에 대하여 설명한다. 도 4의 예시적인 인공신경망모델(110a)은 신경망 프로세싱 유닛에서 학습되거나 또는 별도의 기계 학습 장 치에서 학습된 인공 신경망일 수 있다. 인공신경망모델(110a)은 객체 인식, 음성 인식 등 다양한 추론 기능을 수행하도록 학습된 인공 신경망일 수 있다. 인공신경망모델(110a)은 심층 신경망(DNN, Deep Neural Network)일 수 있다. 단, 본 개시의 예시들에 따른 인공신경망모델(110a)은 심층 신경망에 제한되지 않는다. 예를 들어, 인공신경망모델(110a)은 VGG, VGG16, DenseNet 및, encoder-decoder structure를 갖는 FCN (Fully Convolutional Network), SegNet, DeconvNet, DeepLAB V3+, U-net와 같은 DNN (deep neural network), SqueezeNet, Alexnet, ResNet18, MobileNet-v2, GoogLeNet, Resnet-v2, Resnet50, Resnet101, Inception-v3 등의 모델로 구현될 수 있다. 단, 본 개시는 상술한 모델들에 제한되지 않는다. 또한 인공신경망모델(110a)은 적어도 두 개의 서로 다른 모델들에 기초한 앙상블 모델일 수도 있다. 인공신경망모델(110a)은 신경망 프로세싱 유닛의 NPU 내부 메모리에 저장될 수 있다. 혹은 인공신경 망모델(110a)은 메모리에 저장된 다음 인공신경망모델(110a) 동작 시 신경망 프로세싱 유닛에 로딩되 는 방식으로 구현되는 것도 가능하다. 이하 도 4를 참조하여 예시적인 인공신경망모델(110a)에 의환 추론 과정이 신경망 프로세싱 유닛에 의해서 수행되는 것에 관해 설명한다.인공신경망모델(110a)은 입력 레이어(110a-1), 제1 연결망(110a-2), 제1 은닉 레이어(110a-3), 제2 연결망 (110a-4), 제2 은닉 레이어(110a-5), 제3 연결망(110a-6), 및 출력 레이어(110a-7)을 포함하는 예시적인 심층 신경망 모델이다. 단, 본 개시는 도 4에 도시된 인공신경망모델에만 제한되는 것은 아니다. 제1 은닉 레이어 (110a-3) 및 제2 은닉 레이어(110a-5)는 복수의 은닉 레이어로 지칭되는 것도 가능하다. 입력 레이어(110a-1)는 예시적으로, x1 및 x2 입력 노드를 포함할 수 있다. 즉, 입력 레이어(110a-1)는 2개의 입력 값에 대한 정보를 포함할 수 있다. 도 1 또는 도 3에 도시된 NPU 스케줄러는 입력 레이어(110a-1)로 부터의 입력 값에 대한 정보가 저장되는 메모리 어드레스를 도 1 또는 도 3에 도시된 NPU 내부 메모리에 설정할 수 있다. 제1 연결망(110a-2)은 예시적으로, 입력 레이어(110a-1)의 각각의 노드를 제1 은닉 레이어(110a-3)의 각각의 노 드로 연결시키기 위한 6개의 가중치 값에 대한 정보를 포함할 수 있다. 도 1 또는 도 3에 도시된 NPU 스케줄러 는 제1 연결망(110a-2)의 가중치 값에 대한 정보가 저장되는 메모리 어드레스를 NPU 내부 메모리에 설정할 수 있다. 각각의 가중치 값은 입력 노드 값과 곱해지고, 곱해진 값들의 누산된 값이 제1 은닉 레이어 (110a-3)에 저장된다. 제1 은닉 레이어(110a-3)는 예시적으로 a1, a2, 및 a3 노드를 포함할 수 있다. 즉, 제1 은닉 레이어(110a-3)는 3개의 노드 값에 대한 정보를 포함할 수 있다. 도 1 또는 도 3에 도시된 NPU 스케줄러는 제1 은닉 레이어 (110a-3)의 노드 값에 대한 정보를 저장시키기 위한 메모리 어드레스를 NPU 내부 메모리에 설정할 수 있다. 제2 연결망(110a-4)은 예시적으로, 제1 은닉 레이어(110a-3)의 각각의 노드를 제2 은닉 레이어(110a-5)의 각각 의 노드로 연결시키기 위한 9개의 가중치 값에 대한 정보를 포함할 수 있다. 도 1 또는 도 3에 도시된 NPU 스케 줄러는 제2 연결망(110a-4)의 가중치 값에 대한 정보를 저장시키기 위한 메모리 어드레스를 NPU 내부 메모 리에 설정할 수 있다. 상기 제2 연결망(110a-4)의 가중치 값은 제1 은닉 레이어(110a-3)로부터 입력되는 노드 값과 각기 곱해지고, 곱해진 값들의 누산된 값이 제2 은닉 레이어(110a-5)에 저장된다. 제2 은닉 레이어(110a-5)는 예시적으로 b1, b2, 및 b3 노드를 포함할 수 있다. 즉, 제2 은닉 레이어(110a-5)는 3개의 노드 값에 대한 정보를 포함할 수 있다. NPU 스케줄러는 제2 은닉 레이어(110a-5)의 노드 값에 대한 정보를 저장시키기 위한 메모리 어드레스를 NPU 내부 메모리에 설정할 수 있다. 제3 연결망(110a-6)은 예시적으로, 제2 은닉 레이어(110a-5)의 각각의 노드와 출력 레이어(110a-7)의 각각의 노 드를 연결하는 6개의 가중치 값에 대한 정보를 포함할 수 있다. NPU 스케줄러는 제3 연결망(110a-6)의 가 중치 값에 대한 정보를 저장시키기 위한 메모리 어드레스를 NPU 내부 메모리에 설정할 수 있다. 제3 연결 망(110a-6)의 가중치 값은 제2 은닉 레이어(110a-5)로부터 입력되는 노드 값과 각기 곱해지고, 곱해진 값들의 누산된 값이 출력 레이어(110a-7)에 저장된다. 출력 레이어(110a-7)는 예시적으로 y1, 및 y2 노드를 포함할 수 있다. 즉, 출력 레이어(110a-7)는 2개의 노드 값에 대한 정보를 포함할 수 있다. NPU 스케줄러는 출력 레이어(110a-7)의 노드 값에 대한 정보를 저장시 키기 위해 메모리 어드레스를 NPU 내부 메모리에 설정할 수 있다. 즉, NPU 스케줄러는 프로세싱 엘리먼트 어레이에서 작동할 인공신경망모델의 구조를 분석하거나 또는 제공받을 수 있다. 인공신경망모델이 포함할 수 있는 인공 신경망의 정보는 각각의 레이어의 노드 값에 대한 정 보, 레이어들의 배치 데이터 지역성 정보 또는 구조에 대한 정보, 각각의 레이어의 노드를 연결하는 연결망 각 각의 가중치 값에 대한 정보를 포함할 수 있다. NPU 스케줄러는 예시적인 인공신경망모델(110a)의 데이터 지역성 정보 또는 구조에 대한 정보를 제공받았 기 때문에, NPU 스케줄러는 인공신경망모델(110a)의 입력부터 출력까지의 연산 순서를 파악할 수 있다. 따라서, NPU 스케줄러는 각각의 레이어의 MAC 연산 값들이 저장되는 메모리 어드레스를 스케줄링 순서를 고려해서 NPU 내부 메모리에 설정할 수 있다. 예를 들면, 특정 메모리 어드레스는 입력 레이어(110a-1)와 제1 연결망(110a-2)의 MAC 연산 값일 수 있으며, 동시에 제1 은닉 레이어(110a-3)의 입력 데이터 일 수 있다. 단 본 개시는 MAC 연산 값에 제한되지 않으며, MAC 연산 값은 인공 신경망 연산 값으로 지칭되는 것도 가능하다. 이때, NPU 스케줄러는 입력 레이어(110a-1)와 제1 연결망(110a-2)의 MAC 연산 결과가 제1 은닉 레이어 (110a-3)의 입력이 될 것을 알기 때문에, 동일한 메모리 어드레스를 사용하도록 제어할 수 있다. 즉, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 MAC 연산 값을 재사용할 수 있다. 따라서 NPU 시스템 메모리가 메모리 재사용 기능을 제공할 수 있는 효과가 있다. 즉, NPU 스케줄러는 스케줄링 순서에 따른 인공신경망모델(110a)의 MAC 연산 값을 NPU 내부 메모리의 임의 메모리 어드레스에 지정된 특정 영역에 저장하고, MAC 연산 값이 저장된 특정 영역에서 다음 스케줄링 순 서의 MAC 연산의 입력 데이터로 사용될 수 있다. 제1 프로세싱 엘리먼트(PE1) 관점에서의 MAC 연산 MAC 연산을 제1 프로세싱 엘리먼트(PE1) 관점에서 자세히 설명한다. 제1 프로세싱 엘리먼트(PE1)는 제1 은닉 레 이어(110a-3)의 a1 노드의 MAC 연산을 수행하도록 지정될 수 있다. 첫째, 제1 프로세싱 엘리먼트(PE1)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 x1 노드 데이터를 입 력하고, 제2 입력부에 x1 노드와 a1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0이 다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값은 1이 될 수 있다. 둘째, 제1 프로세싱 엘리먼트(PE1)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 x2 노드 데이터를 입 력하고, 제2 입력부에 x2 노드와 a1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 x1 노드 데이터와 x1 노드와 a1 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 a1 노드에 대응되는 x1 노드와 x2 노드의 MAC 연산 값을 생성한다. 셋째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누산된 값에 따라 적절히 조절될 수 있다. 부연 설명하면, (L)loops가 증가할 수록, 출력되는 값의 비트 폭이 증가되게 된다. 이때 NPU 스케줄러는 제1 프로세싱 엘리먼트(PE1)의 연산 값의 비트 폭이 (x)bit이 되도록 소정의 하위 비트를 제거할 수 있다. 제2 프로세싱 엘리먼트(PE2) 관점에서의 MAC 연산 MAC 연산을 제2 프로세싱 엘리먼트(PE2) 관점에서 자세히 설명한다. 제2 프로세싱 엘리먼트(PE2)는 제1 은닉 레 이어(110a-3)의 a2 노드의 MAC 연산을 수행하도록 지정될 수 있다. 첫째, 제2 프로세싱 엘리먼트(PE2)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 x1 노드 데이터를 입 력하고, 제2 입력부에 x1 노드와 a2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0이 다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값은 1이 될 수 있다. 둘째, 제2 프로세싱 엘리먼트(PE2)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 x2 노드 데이터를 입 력하고, 제2 입력부에 x2 노드와 a2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 x1 노드 데이터와 x1 노드와 a2 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 a2 노드에 대응되는 x1 노드와 x2 노드의 MAC 연산 값을 생성한다. 셋째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누 산된 값에 따라 적절히 조절될 수 있다. 제3 프로세싱 엘리먼트(PE3) 관점에서의 MAC 연산 MAC 연산을 제3 프로세싱 엘리먼트(PE3) 관점에서 자세히 설명한다. 제3 프로세싱 엘리먼트(PE3)는 제1 은닉 레 이어(110a-3)의 a3 노드의 MAC 연산을 수행하도록 지정될 수 있다.첫째, 제3 프로세싱 엘리먼트(PE3)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 x1 노드 데이터를 입 력하고, 제2 입력부에 x1 노드와 a3 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0이 다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값은 1이 될 수 있다. 둘째, 제3 프로세싱 엘리먼트(PE3)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 x2 노드 데이터를 입 력하고, 제2 입력부에 x2 노드와 a3 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 x1 노드 데이터와 x1 노드와 a3 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 a3 노드에 대응되는 x1 노드와 x2 노드의 MAC 연산 값을 생성한다. 셋째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누 산된 값에 따라 적절히 조절될 수 있다. 따라서, 신경망 프로세싱 유닛의 NPU 스케줄러는 3개의 프로세싱 엘리먼트(PE1 내지 PE3)를 동시에 사용하여 제1 은닉 레이어(110a-3)의 MAC 연산을 수행할 수 있다. 제4 프로세싱 엘리먼트(PE4) 관점에서의 MAC 연산 MAC 연산을 제4 프로세싱 엘리먼트(PE4) 관점에서 자세히 설명한다. 제4 프로세싱 엘리먼트(PE4)는 제2 은닉 레 이어(110a-5)의 b1 노드의 MAC 연산을 수행하도록 지정될 수 있다. 첫째, 제4 프로세싱 엘리먼트(PE4)는 곱셈기의 제1 입력부에 제1 은닉 레이어(110a-3)의 a1 노드 데이터를 입력하고, 제2 입력부에 a1 노드와 b1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0 이다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값 은 1이 될 수 있다. 둘째, 제4 프로세싱 엘리먼트(PE4)는 곱셈기의 제1 입력부에 제1 은닉 레이어(110a-3)의 a2 노드 데이터를 입력하고, 제2 입력부에 a2 노드와 b1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 a1 노드 데이터와 a1 노드와 b1 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 b1 노드에 대응되는 a1 노드와 a2 노드의 MAC 연산 값을 생성한다. 이때, (L)loops의 카운터 값은 2가 될 수 있다. 셋째, 제4 프로세싱 엘리먼트(PE4)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 a3 노드 데이터를 입 력하고, 제2 입력부에 a3 노드와 b1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 2일 경우, 이전 단계에서 연산 된 b1 노드에 대응되는 a1 노드와 a2 노드의 MAC 연산 값이 저장되었다. 따라서 가산기는 b1 노드에 대응되는 a1 노드, a2 노드 및 a3 노드의 MAC 연산 값을 생성한다. 넷째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누 산된 값에 따라 적절히 조절될 수 있다. 제5 프로세싱 엘리먼트(PE5) 관점에서의 MAC 연산 MAC 연산을 제5 프로세싱 엘리먼트(PE5) 관점에서 자세히 설명한다. 제5 프로세싱 엘리먼트(PE5)는 제2 은닉 레 이어(110a-5)의 b2 노드의 MAC 연산을 수행하도록 지정될 수 있다. 첫째, 제5 프로세싱 엘리먼트(PE5)는 곱셈기의 제1 입력부에 제1 은닉 레이어(110a-3)의 a1 노드 데이터를 입력하고, 제2 입력부에 a1 노드와 b2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0 이다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값은 1이 될 수 있다. 둘째, 제5 프로세싱 엘리먼트(PE5)는 곱셈기의 제1 입력부에 제1 은닉 레이어(110a-3)의 a2 노드 데이터를 입력하고, 제2 입력부에 a2 노드와 b2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 a1 노드 데이터와 a1 노드와 b2 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 b2 노드에 대응되는 a1 노드와 a2 노드의 MAC 연산 값을 생성한다. 이때, (L)loops의 카운터 값은 2가 될 수 있다. 셋째, 제5 프로세싱 엘리먼트(PE5)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 a3 노드 데이터를 입 력하고, 제2 입력부에 a3 노드와 b2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 2일 경우, 이전 단계에서 연산 된 b2 노드에 대응되는 a1 노드와 a2 노드의 MAC 연산 값이 저장되었다. 따라서 가산기는 b2 노드에 대응되는 a1 노드, a2 노드 및 a3 노드의 MAC 연산 값을 생성한다. 넷째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누 산된 값에 따라 적절히 조절될 수 있다. 제6 프로세싱 엘리먼트(PE6) 관점에서의 MAC 연산 MAC 연산을 제6 프로세싱 엘리먼트(PE6) 관점에서 자세히 설명한다. 제6 프로세싱 엘리먼트(PE6)는 제2 은닉 레 이어(110a-5)의 b3 노드의 MAC 연산을 수행하도록 지정될 수 있다. 첫째, 제6 프로세싱 엘리먼트(PE6)는 곱셈기의 제1 입력부에 제1 은닉 레이어(110a-3)의 a1 노드 데이터를 입력하고, 제2 입력부에 a1 노드와 b3 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0 이다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값 은 1이 될 수 있다. 둘째, 제6 프로세싱 엘리먼트(PE6)는 곱셈기의 제1 입력부에 제1 은닉 레이어(110a-3)의 a2 노드 데이터를 입력하고, 제2 입력부에 a2 노드와 b3 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 a1 노드 데이터와 a1 노드와 b3 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 b3 노드에 대응되는 a1 노드와 a2 노드의 MAC 연산 값을 생성한다. 이때, (L)loops의 카운터 값은 2가 될 수 있다. 셋째, 제6 프로세싱 엘리먼트(PE6)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 a3 노드 데이터를 입 력하고, 제2 입력부에 a3 노드와 b3 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 2일 경우, 이전 단계에서 연산 된 b3 노드에 대응되는 a1 노드와 a2 노드의 MAC 연산 값이 저장되었다. 따라서 가산기는 b3 노드에 대응되는 a1 노드, a2 노드 및 a3 노드의 MAC 연산 값을 생성한다. 넷째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누 산된 값에 따라 적절히 조절될 수 있다. 따라서, 신경망 프로세싱 유닛의 NPU 스케줄러는 3개의 프로세싱 엘리먼트(PE4 내지 PE6)를 동시에 사용하여 제2 은닉 레이어(110a-5)의 MAC 연산을 수행할 수 있다. 제7 프로세싱 엘리먼트(PE7) 관점에서의 MAC 연산 MAC 연산을 제7 프로세싱 엘리먼트(PE7) 관점에서 자세히 설명한다. 제7 프로세싱 엘리먼트(PE7)는 출력 레이어 (110a-7)의 y1 노드의 MAC 연산을 수행하도록 지정될 수 있다. 첫째, 제7 프로세싱 엘리먼트(PE7)는 곱셈기의 제1 입력부에 제2 은닉 레이어(110a-5)의 b1 노드 데이터를 입력하고, 제2 입력부에 b1 노드와 y1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0이다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값 은 1이 될 수 있다. 둘째, 제7 프로세싱 엘리먼트(PE7)는 곱셈기의 제1 입력부에 제2 은닉 레이어(110a-5)의 b2 노드 데이터를 입력하고, 제2 입력부에 b2 노드와 y1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 b1 노드 데이터와 b1 노드와 y1 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 y1 노드에 대응되는 b1 노드와 b2 노드의 MAC 연산 값을 생성한다. 이때, (L)loops의 카운터 값은 2가 될 수 있다. 셋째, 제7 프로세싱 엘리먼트(PE7)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 b3 노드 데이터를 입 력하고, 제2 입력부에 b3 노드와 y1 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 2일 경우, 이전 단계에서 연산 된 y1 노드에 대응되는 b1 노드와 b2 노드의 MAC 연산 값이 저장되었다. 따라서 가산기는 y1 노드에 대응되는 b1 노드, b2 노드 및 b3 노드의 MAC 연산 값을 생성한다. 넷째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누 산된 값에 따라 적절히 조절될 수 있다. 제8 프로세싱 엘리먼트(PE8) 관점에서의 MAC 연산 MAC 연산을 제8 프로세싱 엘리먼트(PE8) 관점에서 자세히 설명한다. 제8 프로세싱 엘리먼트(PE8)는 출력 레이어 (110a-7)의 y2 노드의 MAC 연산을 수행하도록 지정될 수 있다. 첫째, 제8 프로세싱 엘리먼트(PE8)는 곱셈기의 제1 입력부에 제2 은닉 레이어(110a-5)의 b1 노드 데이터를 입력하고, 제2 입력부에 b1 노드와 y2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 0일 경우, 누산된 값이 없기 때문에, 누산된 값은 0 이다. 따라서 가산기의 연산 값은 곱셈기의 연산 값과 동일할 수 있다. 이때, (L)loops의 카운터 값 은 1이 될 수 있다. 둘째, 제8 프로세싱 엘리먼트(PE8)는 곱셈기의 제1 입력부에 제2 은닉 레이어(110a-5)의 b2 노드 데이터를 입력하고, 제2 입력부에 b2 노드와 y2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연 산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 1일 경우, 이전 단계에서 연산 된 b1 노드 데이터와 b1 노드와 y2 노드 사이의 가중치 곱셈 값이 저장되었다. 따라서 가산기는 y2 노드에 대응되는 b1 노드와 b2 노드의 MAC 연산 값을 생성한다. 이때, (L)loops의 카운터 값은 2가 될 수 있다. 셋째, 제8 프로세싱 엘리먼트(PE8)는 곱셈기의 제1 입력부에 입력 레이어(110a-1)의 b3 노드 데이터를 입 력하고, 제2 입력부에 b3 노드와 y2 노드 사이의 가중치 데이터를 입력한다. 가산기는 곱셈기의 연산 값과 누산기의 연산 값을 더한다. 이때 (L)loops가 2일 경우, 이전 단계에서 연산 된 y2 노드에 대응되는 b1 노드와 b2 노드의 MAC 연산 값이 저장되었다. 따라서 가산기는 y2 노드에 대응되는 b1 노드, b2 노드 및 b3 노드의 MAC 연산 값을 생성한다. 넷째, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 제1 프로 세싱 엘리먼트(PE1)의 MAC 연산을 종료할 수 있다. 이때 초기화 신호(initialization Reset)를 입력해서 누산기 를 초기화할 수 있다. 즉, (L)loops의 카운터 값을 0으로 초기화 할 수 있다. 비트 양자화 유닛은 누 산된 값에 따라 적절히 조절될 수 있다. 따라서, 신경망 프로세싱 유닛의 NPU 스케줄러는 2개의 프로세싱 엘리먼트(PE7 내지 PE8)를 동시에 사용하여 출력 레이어(110a-7)의 MAC 연산을 수행할 수 있다. 제 8 프로세싱 엘리먼트(PE8)의 MAC 연산이 끝나면, 인공신경망모델(110a)의 추론 연산이 마무리 될 수 있다. 즉, 인공신경망모델(110a)은 하나의 프레임의 추론 연산을 완료했다고 판단될 수 있다. 만약 신경망 프로세싱 유닛이 실시간으로 동영상 데이터를 추론한다면, 입력 레이어(110a-1)의 x1 및 x2 입력 노드에 다음 프레 임의 영상 데이터가 입력될 수 있다. 이때, NPU 스케줄러는 입력 레이어(110a-1)의 입력 데이터를 저장한 메모리 어드레스에 다음 프레임의 영상 데이터를 저장할 수 있다. 이러한 과정을 프레임마다 반복하면 신경망 프로세싱 유닛은 실시간으로 추론 연산을 처리할 수 있다. 또한 한번 설정된 메모리 어드레스를 재사용할수 있는 효과가 있다"}
{"patent_id": "10-2021-0181081", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 4의 인공신경망모델(110a)의 경우를 요약하면, 신경망 프로세싱 유닛은 인공신경망모델(110a)의 추론 연산을 위해서 NPU 스케줄러가 인공신경망모델(110a)의 데이터 지역성 정보 또는 구조에 대한 정보에 기초 하여, 연산 스케줄링 순서를 결정할 수 있다. NPU 스케줄러는 연산 스케줄링 순서에 기초하여 NPU 내부 메 모리에 필요한 메모리 어드레스를 설정할 수 있다. NPU 스케줄러는 인공신경망모델(110a)의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여, 메모리를 재사용 하는 메모리 어드레스를 설정할 수 있다. NPU 스케줄러는 추론 연산에 필요한 프로세싱 엘리먼트들(PE1 내지 PE8)을 지정하여 추론 연산을 수행할 수 있 다. 부연 설명하면, 하나의 노드에 연결되는 가중치 데이터가 L개 만큼 증가하면, 프로세싱 엘리먼트의 누산기의 (L)loops의 횟수를 L-1로 설정할 수 있다. 즉, 누산기는 인공 신경망의 가중치 데이터가 증가하더라도, 누산기 의 누적 횟수를 증가시킴으로써 추론 연산을 용이하게 수행할 수 있는 효과가 있다. 즉, 본 개시의 일 예시에 따른 신경망 프로세싱 유닛의 NPU 스케줄러는 입력 레이어(110a-1), 제1 연 결망(110a-2), 제1 은닉 레이어(110a-3), 제2 연결망(110a-4), 제2 은닉 레이어(110a-5), 제3 연결망(110a-6), 및 출력 레이어(110a-7)의 데이터 지역성 정보 또는 구조에 대한 정보를 포함하는 인공신경망모델의 데이터 지 역성 정보 또는 구조에 대한 정보에 기초하여 프로세싱 엘리먼트 어레이 및 NPU 내부 메모리을 제어 할 수 있다. 즉, NPU 스케줄러는 입력 레이어(110a-1)의 노드 데이터, 제1 연결망(110a-2)의 가중치 데이터, 제1 은닉 레이어(110a-3)의 노드 데이터, 제2 연결망(110a-4)의 가중치 데이터, 제2 은닉 레이어(110a-5)의 노드 데이터, 제3 연결망(110a-6)의 가중치 데이터, 및 출력 레이어(110a-7)의 노드 데이터에 대응되는 메모리 어드레스 값들 을 NPU 메모리 시스템에 설정할 수 있다. 이하, NPU 스케줄러의 스케줄링에 대하여 자세히 설명한다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 인공신경망모델의 연산 순서를 스케줄링 할 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 인공신경망모델 의 레이어의 노드 데이터 및 연결망의 가중치 데이터가 저장된 메모리 어드레스 값을 획득할 수 있다. 예를 들면, NPU 스케줄러는 메인 메모리에 저장된 인공신경망모델의 레이어의 노드 데이터 및 연결망의 가 중치 데이터가 저장된 메모리 어드레스 값을 획득할 수 있다. 따라서 NPU 스케줄러는 구동할 인공신경망모 델의 레이어의 노드 데이터 및 연결망의 가중치 데이터를 메인 메모리에서 가져와서 NPU 내부 메모리에 저 장할 수 있다. 각각의 레이어의 노드 데이터는 대응되는 각각의 메모리 어드레스 값을 가질 수 있다. 각각의 연 결망의 가중치 데이터는 대응되는 각각의 메모리 어드레스 값을 가질 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보, 예를 들면, 인공신경망모델 의 인공 신경망의 레이어들의 배치 데이터 지역성 정보 또는 구조에 대한 정보에 기초해서 프로세싱 엘리먼트 어레이의 연산 순서를 스케줄링 할 수 있다. 예를 들면, NPU 스케줄러는 4개의 인공 신경망 레이어들과 각각의 레이어들을 연결하는 3개의 레이어의 가 중치 값들을 가지는 가중치 데이터, 즉, 연결망 데이터를 획득할 수 있다. 이러한 경우 NPU 스케줄러가 인 공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 기초로 프로세싱 순서를 스케줄링 하는 방법에 대 하여 예를 들어 아래에서 설명한다. 예를 들면, NPU 스케줄러는 추론 연산을 위한 입력 데이터를 인공신경망모델(110a)의 입력 레이어(110a- 1)인 제1 레이어의 노드 데이터로 설정하고, 제1 레이어의 노드 데이터와 제1 레이어에 대응되는 제1 연결망의 가중치 데이터의 MAC 연산을 먼저 수행하도록 스케줄링 할 수 있다. 이하 단지 설명의 편의를 위해서 해당 연산 을 제1 연산이라 지칭하고, 제1 연산의 결과를 제1 연산 값이라 지칭하고, 해당 스케줄링을 제1 스케줄링이라 지칭할 수 있다. 예를 들면, NPU 스케줄러는 제1 연산 값을 제1 연결망에 대응되는 제2 레이어의 노드 데이터로 설정하고, 제2 레이어의 노드 데이터와 제2 레이어에 대응되는 제2 연결망의 가중치 데이터의 MAC 연산을 제1 스케줄링 이 후에 수행하도록 스케줄링 할 수 있다. 이하 단지 설명의 편의를 위해서 해당 연산을 제2 연산이라 지칭하고, 제2 연산의 결과를 제2 연산 값이라 지칭하고, 해당 스케줄링을 제2 스케줄링이라 지칭할 수 있다. 예를 들면, NPU 스케줄러는 제2 연산 값을 제2 연결망에 대응되는 제3 레이어의 노드 데이터로 설정하고, 제3 레이어의 노드 데이터와 제3 레이어에 대응되는 제3 연결망의 가중치 데이터의 MAC 연산을 제2 스케줄링에 수행하도록 스케줄링 할 수 있다. 이하 단지 설명의 편의를 위해서 해당 연산을 제3 연산이라 지칭하고, 제3 연 산의 결과를 제3 연산 값이라 지칭하고, 해당 스케줄링을 제3 스케줄링이라 지칭할 수 있다. 예를 들면, NPU 스케줄러는 제3 연산 값을 제3 연결망에 대응되는 출력 레이어(110a-7)인 제4 레이어의 노 드 데이터로 설정하고, 제4 레이어의 노드 데이터에 저장된 추론 결과를 NPU 내부 메모리에 저장하도록 스 케줄링 할 수 있다. 이하 단지 설명의 편의를 위해서 해당 스케줄링을 제4 스케줄링이라 지칭할 수 있다. 추론 결과 값은 다양한 구성요소들에 전달되어 활용될 수 있다. 예를 들면, 추론 결과 값이 특정 키워드를 감지한 결과 값이라면, 신경망 프로세싱 유닛은 추론 결과를 중 앙 처리 장치에 전달하여, 특정 키워드에 대응되는 동작을 수행할 수 있다. 예를 들면, NPU 스케줄러는 제1 스케줄링에서 제1 내지 제3 프로세싱 엘리먼트(PE1 내지 PE3)를 구동할 수 있다. 예를 들면, NPU 스케줄러는 제2 스케줄링에서 제4 내지 제6 프로세싱 엘리먼트(PE4 내지 PE6)를 구동할 수 있다. 예를 들면, NPU 스케줄러는 제3 스케줄링에서 제7 내지 제8 프로세싱 엘리먼트(PE7 내지 PE8)를 구동할 수 있다. 예를 들면, NPU 스케줄러는 제4 스케줄링에서 추론 결과를 출력할 수 있다. 정리하면, NPU 스케줄러는 제1 스케줄링, 제2 스케줄링, 제3 스케줄링, 및 제4 스케줄링 순서대로 연산이 수행되도록 NPU 내부 메모리과 프로세싱 엘리먼트 어레이를 제어할 수 있다. 즉, NPU 스케줄러 는 설정된 스케줄링 순서대로 연산이 수행되도록 NPU 내부 메모리과 프로세싱 엘리먼트 어레이를 제 어하도록 구성될 수 있다. 정리하면, 본 개시의 일 예시에 따른 신경망 프로세싱 유닛은 인공 신경망의 레이어들의 구조와, 구조에 대응되는 연산 순서 데이터에 기초하여, 프로세싱 순서를 스케줄링 하도록 구성될 수 있다. 스케줄링 되는 프로 세싱 순서는 적어도 하나 이상일 수 있다, 예를 들면, 신경망 프로세싱 유닛이 모든 연산 순서를 예측 할 수 있기 때문에, 다음 연산을 스케줄링 하는 것도 가능하고, 특정 순서의 연산을 스케줄링 하는 것도 가능하다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초한 스케줄링 순서를 활용하여 NPU 내부 메모리을 제어하여 메모리 재사용율을 향상시킬 수 있는 효과가 있다. 본 개시의 일 예시에 따른 신경망 프로세싱 유닛에서 구동되는 인공 신경망 연산의 특성상 하나의 레이어 의 연산 값이 다음 레이어의 입력 데이터가 되는 특성을 가질 수 있다. 이에, 신경망 프로세싱 유닛은 스케줄링 순서에 따라서 NPU 내부 메모리을 제어하면, NPU 내부 메모 리의 메모리 재사용율을 향상시킬 수 있는 효과가 있다. 구체적으로 설명하면, NPU 스케줄러가 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보를 제 공받도록 구성되고, 제공받은 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 의해서 인공 신경 망의 연산이 진행되는 순서를 파악할 수 있는 경우, NPU 스케줄러는 인공신경망모델의 특정 레이어의 노드 데이터와 특정 연결망의 가중치 데이터의 연산 결과가 대응되는 레이어의 노드 데이터가 된다는 사실을 파악할 수 있다. 따라서 NPU 스케줄러는 해당 연산 결과가 저장된 메모리 어드레스의 값을 이어지는 다음 연산에 서 재사용할 수 있다. 예를 들면, 상술한 제1 스케줄링의 제1 연산 값은 제2 스케줄링의 제2 레이어의 노드 데이터로 설정된다. 구체 적으로 설명하면, NPU 스케줄러는 NPU 내부 메모리에 저장된 제1 스케줄링의 제1 연산 값에 대응되는 메모리 어드레스 값을 제2 스케줄링의 제2 레이어의 노드 데이터에 대응되는 메모리 어드레스 값으로 재설정할 수 있다. 즉, 메모리 어드레스 값을 재사용할 수 있다. 따라서 NPU 스케줄러가 제1 스케줄링의 메모리 어 드레스 값 재사용함으로 써, NPU 내부 메모리은 별도의 메모리 쓰기 동작 없이 제2 스케줄링의 제2 레이어 노드 데이터로 활용할 수 있는 효과가 있다. 예를 들면, 상술한 제2 스케줄링의 제2 연산 값은 제3 스케줄링의 제3 레이어의 노드 데이터로 설정된다. 구체 적으로 설명하면, NPU 스케줄러는 NPU 내부 메모리에 저장된 제2 스케줄링의 제2 연산 값에 대응되는 메모리 어드레스 값을 제3 스케줄링의 제3 레이어의 노드 데이터에 대응되는 메모리 어드레스 값으로 재설정할수 있다. 즉, 메모리 어드레스 값을 재사용할 수 있다. 따라서 NPU 스케줄러가 제2 스케줄링의 메모리 어 드레스 값을 재사용함으로 써, NPU 내부 메모리은 별도의 메모리 쓰기 동작 없이 제3 스케줄링의 제3 레이 어 노드 데이터로 활용할 수 있는 효과가 있다. 예를 들면, 상술한 제3 스케줄링의 제3 연산 값은 제4 스케줄링의 제4 레이어의 노드 데이터로 설정된다. 구체 적으로 설명하면, NPU 스케줄러는 NPU 내부 메모리에 저장된 제3 스케줄링의 제3 연산 값에 대응되는 메모리 어드레스 값을 제4 스케줄링의 제4 레이어의 노드 데이터에 대응되는 메모리 어드레스 값으로 재설정할 수 있다. 즉, 메모리 어드레스 값을 재사용할 수 있다. 따라서 NPU 스케줄러가 제3 스케줄링의 메모리 어 드레스 값을 재사용함으로 써, NPU 내부 메모리은 별도의 메모리 쓰기 동작 없이 제4 스케줄링의 제4 레이 어 노드 데이터로 활용할 수 있는 효과가 있다. 더 나아가서, NPU 스케줄러는 스케줄링 순서와 메모리 재사용 여부를 판단해서 NPU 내부 메모리을 제 어하도록 구성되는 것도 가능하다. 이러한 경우 NPU 스케줄러가 인공신경망모델의 데이터 지역성 정보 또 는 구조에 대한 정보를 분석해서 최적화된 스케줄링을 제공할 수 있는 효과가 있다. 또한 메모리 재사용이 가능 한 연산에 필요한 데이터를 중복해서 NPU 내부 메모리에 저장하지 않을 수 있기 때문에 메모리 사용량을 저감할 수 있는 효과가 있다. 또한 NPU 스케줄러는 메모리 재사용만큼 저감된 메모리 사용량을 계산해서 NPU 내부 메모리을 최적화할 수 있는 효과가 있다. 본 개시의 일 예시에 따른 신경망 프로세싱 유닛은 제1 프로세싱 엘리먼트(PE1)의 제1 입력인 (N)bit 입력 은 변수 값을 입력 받고, 제2 입력은 (M)bit 입력은 상수 값을 입력 받도록 구성될 수 있다. 또한 이러한 구성 은 프로세싱 엘리먼트 어레이의 다른 프로세싱 엘리먼트 들에게 동일하게 설정될 수 있다. 즉, 프로세싱 엘리먼트의 하나의 입력은 변수 값을 입력 받고, 다른 입력은 상수 값을 입력 받도록 구성될 수 있다. 따라서 상수 값의 데이터 갱신 횟수를 저감할 수 있는 효과가 있다. 이때, NPU 스케줄러는 인공신경망모델(110a)의 데이터 지역성 정보 또는 구조에 대한 정보를 활용하여 입 력 레이어(110a-1), 제1 은닉 레이어(110a-3), 제2 은닉 레이어(110a-5) 및 출력 레이어(110a-7)의 노드 데이 터는 변수(variable)로 설정하고, 제1 연결망(110a-2)의 가중치 데이터, 제2 연결망(110a-4)의 가중치 데이터, 및 제3 연결망(110a-6)의 가중치 데이터는 상수(constant)로 설정할 수 있다. 즉 NPU 스케줄러는 상수 값 과 변수 값을 구분할 수 있다. 단, 본 개시는 상수와 변수 데이터 타입에 제한되지 않으며, 본질적으로, 자주 가변 되는 값과, 그러지 않은 값을 구분하여 NPU 내부 메모리의 재사용율을 향상시킬 수 있다. 즉, NPU 시스템 메모리는 신경망 프로세싱 유닛의 추론 연산이 지속되는 동안 NPU 시스템 메모리 에 저장된 연결망들의 가중치 데이터를 보존하도록 구성될 수 있다. 따라서 메모리 읽기 쓰기 동작을 저감 할 수 있는 효과가 있다. 즉, NPU 시스템 메모리는 추론 연산이 지속되는 동안 NPU 시스템 메모리에 저장된 MAC 연산 값을 재 사용 하도록 구성될 수 있다. 즉, 프로세싱 엘리먼트 어레이의 각각의 프로세싱 엘리먼트의 제1 입력부의 입력 데이터(N)bit가 저장된 메모리 어드레스의 데이터 갱신 횟수는 제2 입력부의 입력 데이터(M)bit가 저장된 메모리 어드레스의 데이터 갱 신 횟수보다 더 많을 수 있다. 즉, 제2 입력부의 데이터 갱신 횟수 제1 입력부의 데이터 갱신 횟수보다 적어질 수 있는 효과가 있다. 이하, 인공 신경망 중에서 심층 신경망(DNN, Deep Neural Network)의 한 종류인 컨볼루션 신경망(CNN, Convolutional Neural Network)에 대해서 집중적으로 설명하기로 한다. 컨볼루션 신경망은 하나 또는 여러 개의 컨볼루션 레이어(convolutional layer)과 통합 레이어(pooling layer), 완전하게 연결된 레이어(fully connected layer)들의 조합일 수 있다. 컨볼루션 신경망은 2차원 데이터 의 학습 및 추론에 적합한 구조를 가지고 있으며, 역전달(Backpropagation algorithm)을 통해 학습될 수 있다. 도 5a은 컨볼루션 신경망의 기본 구조를 설명하기 위한 도면이다. 도 5a을 참조하면, 입력 이미지는 특정 크기의 행과 특정 크기의 열로 구성된 2차원적 행렬로 표시될 수 있다. 입력 이미지는 복수의 채널을 가질 수 있는데, 여기서 채널은 입력 데이터 이미지의 컬러 성분의 수를 나타낼 수 있다. 컨볼루션 과정은 입력 이미지를 지정된 간격으로 순회하면서 커널과 합성곱 연산을 수행하는 것을 의미한다. 컨볼루션 신경망은 현재 레이어에서 다음 레이어로 갈 때, 합성곱(컨볼루션)을 통해 레이어간의 가중치를 반영 하여 다음 레이어에 전달될 수 있다. 예를 들면, 합성곱(컨볼루션)은, 두 개의 주요 파라미터에 의해 정의되는데, 입력 이미지의 크기(통상적으로 1 Х1, 3Х3 또는 5Х5 행렬)와 출력 피처 맵(Feature Map)의 깊이(커널의 수)는 컨볼루션에 의해 연산될 수 있다. 이들 컨볼루션은, 깊이 32에서 시작하여, 깊이 64로 계속되며, 깊이 128 또는 256에서 종료될 수 있다. 합성곱(컨볼루션)은, 3D 입력 피처 맵 위로 3Х3 또는 5Х5 크기의 이들 윈도우를 슬라이딩하고, 모든 위치에서 정지하고, 주변 피처의 3D 패치를 추출함으로써 동작할 수 있다. 이러한 각 3D 패치는 가중치라고 하는 동일한 학습 가중치 행렬을 갖는 텐서 곱을 통해 1D 벡터로 변환될 수 있 다. 이러한 벡터는 3D 출력 맵으로 공간적으로 재조립될 수 있다. 출력 피처 맵의 모든 공간 위치는 입력 피처 맵의 동일한 위치에 대응될 수 있다. 컨볼루션 신경망은, 학습 과정동안 많은 그라디언트 업데이트 반복에 걸쳐 학습되는 커널(즉, 가중치 행렬)과 입력 데이터 간의 합성곱(컨볼루션) 동작을 수행하는 컨볼루션 레이어를 포함할 수 있다. (m, n)을 커널 크기라 고 하고 W를 가중치 값이라고 설정하면, 컨볼루션 레이어는 내적을 계산함으로써 입력 데이터와 가중치 행렬의 합성곱(컨볼루션)을 수행할 수 있다. 커널이 입력 데이터를 가로질러 슬라이딩하는 단차 크기를 보폭이라고 하며, 커널 면적(mХn)을 수용장 (receptive field)이라고 할 수 있다. 동일한 컨볼루션 커널이 입력의 상이한 위치에 걸쳐 적용되며, 이는 학습 되는 커널의 수가 감소시킨다. 이것은, 또한, 위치 불변 학습을 가능하게 하며, 중요한 패턴이 입력에 존재하는 경우, 컨볼루션 필터는 시퀀스의 위치에 관계없이 그 패턴을 학습할 수 있다. 컨볼루션 신경망은, 입력 데이터가 특정 출력 추정값으로 이어지도록 조정되거나 학습될 수 있다. 컨볼루션 신 경망은, 출력 추정값이 실측 자료(ground truth)에 점진적으로 일치하거나 근접할 때까지 출력 추정값과 실측 자료 간의 비교에 기초하여 역전파(backpropagation)를 이용하여 조정될 수 있다. 컨볼루션 신경망은, 실측 자료와 실제 출력 간의 차이에 기초하는 뉴런들 간의 가중치를 조정함으로써 학습될 수 있다. 도 5b는 컨볼루션 신경망의 동작을 이해하기 쉽게 나타낸 종합도이다. 도 5b을 참조하면, 예시적으로 입력 이미지가 5 x 5 크기를 갖는 2차원적 행렬인 것으로 나타나 있다. 또한, 도 5b에는 예시적으로 3개의 노드, 즉 채널 1, 채널 2, 채널 3이 사용되는 것으로 나타내었다. 먼저, 레이어 1의 합성곱 동작에 대해서 설명하기로 한다. 입력 이미지는 레이어 1의 첫 번째 노드에서 채널 1을 위한 커널 1과 합성곱되고, 그 결과로서 피처 맵1이 출력 된다. 또한, 상기 입력 이미지는 레이어 1의 두 번째 노드에서 채널 2를 위한 커널 2와 합성곱되고 그 결과로서 피처 맵 2가 출력된다. 또한, 상기 입력 이미지는 세 번째 노드에서 채널 3을 위한 커널 3과 합성곱되고, 그 결 과로서 피처 맵3이 출력된다. 다음으로, 레이어 2의 폴링(pooling) 동작에 대해서 설명하기로 한다. 상기 레이어 1 로부터 출력되는 피처 맵1, 피처 맵2, 피처 맵3은 레이어 2의 3개의 노드로 입력된다. 레이어 2 는 레이어 1로부터 출력되는 피처 맵들을 입력으로 받아서 폴링(pooling)을 수행할 수 있다. 상기 폴링이라 함 은 크기를 줄이거나 행렬 내의 특정 값을 강조할 수 있다. 폴링 방식으로는 최대값 폴링과 평균 폴링, 최소값 폴링이 있다. 최대값 폴링은 행렬의 특정 영역 안에 값의 최댓값을 모으기 위해서 사용되고, 평균 폴링은 특정 영역내의 평균을 구하기 위해서 사용될 수 있다. 도 5b의 예시에서는 5 x 5 행렬의 피처맵이 폴링에 의하여 4x4 행렬로 크기가 줄어지는 것으로 나타내었다. 구체적으로, 레이어 2의 첫 번째 노드는 채널 1을 위한 피처 맵1을 입력으로 받아 폴링을 수행한 후, 예컨대 4x4 행렬로 출력한다. 레이어 2의 두 번째 노드는 채널 2을 위한 피처 맵2을 입력으로 받아 폴링을 수행한 후, 예컨대 4x4 행렬로 출력한다. 레이어 2의 세 번째 노드는 채널 3을 위한 피처 맵3을 입력으로 받아 폴링을 수행 한 후, 예컨대 4x4 행렬로 출력한다. 다음으로, 레이어 3의 합성곱 동작에 대해서 설명하기로 한다. 레이어 3의 첫 번째 노드는 레이어 2의 첫 번째 노드로부터의 출력을 입력으로 받아, 커널 4와 합성곱을 수행하 고, 그 결과를 출력한다. 레이어 3의 두 번째 노드는 레이어 2의 두 번째 노드로부터의 출력을 입력으로 받아, 채널 2를 위한 커널 5와 합성곱을 수행하고, 그 결과를 출력한다. 마찬가지로, 레이어 3의 세 번째 노드는 레이 어 2의 세 번째 노드로부터의 출력을 입력으로 받아, 채널 3을 위한 커널 6과 합성곱을 수행하고, 그 결과를 출 력한다. 이와 같이 합성곱과 폴링이 반복되고 최종적으로는, 도 5a과 같이 fully connected로 출력될 수 있다. 해당 출 력은 다시 이미지 인식을 위한 인공 신경망으로 입력될 수 있다. 이하에서는 SoC를 위주로 설명되지만, 본 명세서의 개시는 SoC에만 한정되는 것은 아니며, 본 개시의 내용은 SiP(System in Package) 혹은 PCB(Printed circuit board) 기반 보드 레벨 시스템에도 적용될 수 있다. 예를 들어, 각 기능 컴포넌트는 독립 반도체 칩으로 구현되고, PCB 상에 형성된 전기 전도성 패턴(electrically conductive pattern)에 의해서 구현되는 시스템 버스를 통해 서로 연결되는 형태로 구현될 수 있다. 도 6은 도 1 또는 도 3에 도시된 NPU를 포함하는 SoC(system on chip)의 예시적인 아키텍처를 나타낸 예시도이 다. 도 6을 참조하면, 예시적인 SoC은 복수의 기능 컴포넌트들(functional components)과, 시스템 버스 와 ICT(In-system Component Tester)와, 그리고 복수의 래퍼들(test wrappers)(700a, 700b,쪋 , 700g; 총 칭하여 700으로 표기할 수 있음)를 포함할 수 있다. 래퍼는 서로 통신하는 구성요소들의 인터페이스를 맞출 수 있다. 따라서, 래퍼는 인터페이스 회로로 지칭되는 것도 가능하다. 상기 복수의 기능 컴포넌트들은 NPU 코어들의 어레이(100-1)와, CPU(central processing unit) 코어들의 어레 이와, GPU(graphics processing unit) 코어들의 어레이와, 내부 메모리와, 메모리 컨트롤러 와, I/O(input output) 인터페이스와 FPGA(field programmable gate array)을 포함할 수 있다. 단 본 개시의 예시들을 이에 제한되지 않으며, 상기 복수의 기능 컴포넌트들 중 적어도 일부는 삭제되는 것도 가능하다. 단 본 개시의 예시들을 이에 제한되지 않으며, 상술한 상기 복수의 기능 컴포넌트들 이외의 다른 기 능 컴포넌트를 더 포함하는 것도 가능하다. 상기 NPU, CPU, 그리고 GPU는 통합하여 UPU(universal processing unit), APU(application processing unit) 혹은 ADPU(application-dedicated processing unit)라고 호칭될 수도 있다. 상기 어레이(110-1) 내의 개별 NPU 코어는 도 1 또는 도 3에 도시된 NPU를 의미하는 것일 수 있다. 다시 말해서, 도 1 또는 도 3에 도시된 NPU가 복수 개수로 포함된 어레이(110-a)가 도 6에 나타나 있다. 마찬가지로, CPU 코어도 복수 개수로 어레이 내에 포함될 수 있다. 그리고, GPU 코어도 복수 개수로 어레 이 내에 포함될 수 있다. 상기 NPU 코어들의 어레이(100-1)는 래퍼(700a)을 통해 시스템 버스에 연결될 수 있다. 마찬가지로, 상기 CPU 코어들의 어레이는 래퍼(700b)을 통해 시스템 버스에 연결될 수 있다. 그리고 GPU 코어들의 어레 이는 래퍼(700c)을 통해 시스템 버스에 연결될 수 있다. 상기 내부 메모리는 래퍼(700d)을 통해 시스템 버스에 연결될 수 있다. 상기 내부 메모리는 상 기 CPU 코어, GPU 코어, NPU 코어에 의하여 공용(share)될 수 있다. 상기 외부 메모리와 연결되는 메모리 컨트롤러은 래퍼(700e)를 통해 시스템 버스에 연결될 수 있다. 상기 시스템 버스는 반도체 다이(die) 위에 형성된 전기 전도성 패턴(electrically conductive pattern) 에 의해서 구현될 수 있다. 상기 시스템 버스는 고속 통신을 가능하게 한다. 예를 들어, 상기 CPU 코어, GPU 코 어, NPU 코어는 상기 시스템 버스를 통하여 상기 내부 메모리로부터 데이터를 읽어내거나 혹은 데이 터를 상기 내부 메모리 내에 기록할 수 있다. 또한, 상기 CPU 코어, GPU 코어, NPU 코어는 상기 메모리 컨 트롤러를 통하여 외부 메모리로부터 데이터를 읽어내거나 혹은 데이터를 상기 외부 메모리에 기록할 수 있 다. 상기 ICT는 전용의 시그널링 채널을 통해 시스템 버스에 연결될 수 있다. 또한 상기 ICT는 전용 의 시그널링 채널을 통해 복수의 래퍼들과 연결될 수 있다.각 래퍼는 상기 ICT와 전용 시그널링 채널을 통해 연결될 수 있다. 또한, 각 래퍼는 전용의 시 그널링 채널을 통해 시스템 버스에 연결될 수 있다. 또한, 각 래퍼는 전용의 시그널링 채널을 통해 상기 SoC 내의 각 기능 컴포넌트(functional components)에 연결될 수 있다. 이를 위해, 각 래퍼는 상기 SoC 내의 각 기능 컴포넌트(functional components)와 상기 시스템 버스 사이에 위치되도록 설계될 수 있다. 예를 들어, 제1 래퍼(700a)는 상기 NPU 코어들의 어레이(100-1)와, 상기 시스템 버스와 그리고 상기 ICT와 전용의 시그널링 채널들을 통해 연결될 수 있다. 그리고 제2 래퍼(700b)는 상기 CPU 코어들의 어레 이와, 상기 시스템 버스와 그리고 상기 ICT와 전용의 시그널링 채널들을 통해 연결될 수 있다. 래퍼(700c)는 상기 GPU 코어들의 어레이와, 상기 시스템 버스와 그리고 상기 ICT와 전용의 시그 널링 채널들을 통해 연결될 수 있다. 제4 래퍼(700d)는 상기 내부 메모리와, 상기 시스템 버스와 그 리고 상기 ICT와 전용의 시그널링 채널들을 통해 연결될 수 있다. 제5 래퍼(700e)는 상기 메모리 컨트롤러 와, 상기 시스템 버스와 그리고 상기 ICT와 전용의 시그널링 채널들을 통해 연결될 수 있다. 제 6 래퍼(700f)는 상기 I/O 인터페이스와, 상기 시스템 버스와 그리고 상기 ICT와 전용의 시그널 링 채널들을 통해 연결될 수 있다. 상기 I/O 인터페이스에는 제7 래퍼(700g)가 추가로 연결될 수 있다. 제 7 래퍼(700g)를 통해서 외부와 통신을 하도록 구성될 수 있다. 상기 ICT는 상기 시스템 버스를 직접 모니터링 하거나 혹은 각 래퍼를 통해, 상기 복수의 기능 컴포넌트들의 상태를 모니터링할 수 있다. 각 기능 컴포넌트는 유휴 상태(idle state)이거나 사용 상태(busy state)일 수 있다. 유휴 상태의 기능 컴포넌트가 찾아지면, 상기 ICT는 해당 기능 컴포넌트를 테스트될 컴포넌트(component under test: CUT)로 선택할 수 있다. 만약 복수의 기능 컴포넌트들이 유휴 상태인 경우, 상기 ICT는 미리 설정된 규칙에 따라 어느 하나의 기능 컴포넌트를 CUT로 선택할 수 있다. 만약 복수의 기능 컴포넌트들이 유휴 상태인 경우, 상기 ICT는 랜덤으로 어느 하나의 기능 컴포넌트를 CUT 로 선택할 수 있다. 그러면, 상기 ICT는 상기 CUT로 선택된 기능 컴포넌트와 상기 시스템 버스 간의 연결을 차단하거나, 상기 시스템 버스로부터 격리(isolate)시킬 수 있다. 이를 위해서, 상기 ICT는 상기 CUT로 선택된 기능 컴포넌트와 연결된 래퍼로 하여금 상기 차단 또는 격리를 지시할 수 있다. 보다 구체적으로, 상기 ICT는 상기 CUT로 선택된 기능 컴포넌트와 상기 시스템 버스 간의 연결을 상기 래 퍼를 통해 차단시킨 후, 상기 래퍼가 상기 CUT로 선택된 기능 컴포넌트를 대신하여, 상기 시스템 버 스로 시그널을 전송하도록 지시할 수 있다. 이때, 상기 시스템 버스로 전송되는 시그널은, 상기 CUT 로 선택된 기능 컴포넌트가 유휴 상태일 때 상기 시스템 버스로 전송하는 시그널일 수 있다. 이를 위해, 해당 래퍼는, 상기 CUT로 선택된 기능 컴포넌트가 상기 유휴 상태일 때, 상기 시스템 버스로 전송하 는 시그널을 모니터링(혹은 overhear)하여 저장할 수 있다. 그리고, 해당 래퍼는 상기 저장된 시그널을 재 생성하여 상기 시스템 버스로 전송할 수 있다. 한편, 해당 래퍼는 또한, 상기 시스템 버스로부 터의 시그널을 검출할 수 있다. 이후, 상기 ICT는 상기 CUT로 선택된 기능 컴포넌트에 대해서 테스트를 수행할 수 있다. 구체적으로, 상기 규칙은 수행 미션에 따른 우선순위 규칙, 기능 컴포넌트들 간의 우선순위에 대한 규칙, 해당 기능 컴포넌트에 대한 스페어(spare) 존재 유무에 따른 규칙, 테스트 횟수로 정의되는 규칙, 이전 테스트 결과 로 정의되는 규칙 중 하나 이상을 포함할 수 있다. 예를 들어, 수행 미션에 따른 우선순위 규칙이 CPU를 통한 연산 보다 GPU를 통한 연산이 더 높은 우선순위를 갖 는다고 지시하는 경우, 유휴 상태의 CPU와 GPU 중에서 GPU에 대해 우선적으로 테스트가 수행될 수 있다. 기능 컴포넌트들 간의 우선 순위에 대한 규칙이 GPU의 우선순위 보다 CPU의 우선 순위가 높다고 지시할 경우, 유휴 상태의 CPU와 GPU 중에서 CPU에 대해 우선적으로 테스트가 수행될 수 있다. 스페어 존재 유무에 대한 규칙에 대 해서 예를 들어 설명하면, GPU는 코어가 3개이고, CPU는 코어가 6개인 경우, 코어의 개수가 더 적은 GPU에 대해 서 우선적으로 테스트가 수행될 수 있다. 상기 테스트 횟수로 정의되는 규칙에 따르면, CPU에 대해서 이전에 3 회 테스트가 수행되었고, GPU에 대해서는 이전에 5회 테스트가 수행되었다면, 이전 테스트 수행 횟수가 더 적은 CPU에 대해서 우선적으로 테스트가 수행될 수 있다. 이전 테스트 결과로 정의되는 규칙에 따르면, CPU에 대한 이전 테스트 결과 이상 증상이 발견되었고, GPU에 대한 이전 테스트 결과는 정상이라면, CPU에 대해서 우선적으로 테스트가 수행될 수 있다. 상기 테스트를 시작하려는 시점 혹은 상기 테스트를 수행하는 도중에, 상기 CUT로 선택된 기능 컴포넌트에 대한 상기 시스템 버스로부터의 액세스로 인하여 충돌이 발생되면, 상기 ICT는 상기 충돌을 검출할 수 있 다. 그러면, 상기 ICT는 상기 테스트를 중지하고, 충돌에 대한 백-오프(back-off) 타이머를 구동할 수 있다. 그리고, 상기 ICT는 상기 CUT로 선택되었던 기능 컴포넌트의 연결을 상기 시스템 버스로 반환할 수 있다. 한편, 상기 충돌에 대한 백 오프 타이머가 만료하면, 상기 ICT는 해당 기능 컴포넌트가 다시 유휴 상태로 진입하는지 모니터링할 수 있다. 만약 해당 기능 컴포넌트가 다시 유휴 상태로 진입하게 되면, 상기 ICT는 해당 기능 컴포넌트를 다시 CUT로 선택할 수 있다. 만약 상기 충돌이 검출되지 않았다면, 상기 ICT는 상기 테스트를 계속 진행하고, 테스트가 완료되면 그 테 스트 결과를 분석할 수 있다. 상기 테스트는 상기 잘못 제조되었는지, 아니면 손상(compromised)되었는지, 아니면 고장났는지를 판별하기 위 한 것일 수 있다. 상기 손상 또는 고장은 반복적인 사용으로 인한 피로 스트레스(fatigue stress)로 인한 것일 수도 있고 또는 물리적인 스트레스, 예컨대 열, EMP(electromagnetic pulse) 등에 의한 것일 수 있다. 즉, 상기 테스트 결과를 기초로 불량을 감지하도록 구성될 수 있다. 상기 테스트가 NPU에 대해서 수행될 경우에 대해서 설명하기로 한다. 테스트는 후술하는 바와 같이 2가지 종류 즉 기능 테스트와 스캔 테스트가 있다. 먼저 상기 NPU에 대해서 기능 테스트를 수행하는 경우, 상기 ICT는 미리 정해진 ANN 테스트 모델과 테스트 입력이 상기 NPU에 입력될 수 있다. 상기 NPU가 상기 입력된 ANN 테스트 모델을 이용하여 상기 테스트 입력에 대한 추론 결과를 출력하면, 상기 ICT는 의도된 추론 결과와 상기 NPU로부터의 추론 결과를 비교하여, 상 기 NPU가 정상적인지 아니면 문제가 있는지를 분석할 수 있다. 예를 들어, 상기 ANN 테스트 모델이 미리 정해진 CNN이고, 상기 테스트 입력이 간단한 테스트 이미지라면, 상기 NPU는 상기 ANN 테스트 모델을 이용하여 상기 테 스트 이미지에 대해서, 합성곱 연산과 폴링을 수행하여 fully connected layer를 출력할 수 있다. 다음으로, 상기 NPU에 대해서 스캔 테스트를 수행하는 경우, 후술하는 바와 같이 상기 ICT는 상기 NPU 내 의 플리-플롭(flip-flop)들을 스캔 체인으로 엮을 수 있다. 그리고, 상기 ICT은 테스트 입력을 적어도 하 나의 플리-플롭으로 주입하고, 상기 NPU가 결함이 있는지 아니면 정상인지를 구동 중에 분석하기 위하여 상기 플리-플롭의 결합 로직의 동작으로부터 테스트 결과를 획득할 수 있다. 상기 ICT에 의해서 수행되는 상기 테스트는 공장에서 대량 생산(mass production)된 SoC를 출하하기 전에 양품을 판별하기 위해서 수행하는 테스트일 수 있다. 주목할 점은, 본 개시에 의하면 이와 같이 양품 판별을 위 한 테스트가 상기 SoC의 구동중에도 수행될 수 있다는 점이다. 즉, 기존에는 SoC가 공장에서 출하되기 전에만 양품 판별 테스트가 가능했었으나, 본 개시는 SoC 내 복수 기능 컴포넌트들 중에서 유휴 상태인 기능 컴포넌트 들을 찾아내어 순차적으로 테스트함으로써, 구동중인 SoC에 대해서도 양품 테스트를 할 수 있게 하는 장점이 있 다. 상기 테스트 분석 결과, 해당 기능 컴포넌트가 정상이라고 판단되면, 상기 ICT는 해당 기능 컴포넌트와의 연결을 상기 시스템 버스로 반환할 수 있다. 구체적으로, 상기 ICT는 해당 래퍼와 상기 시스템 버스 간의 연결을 해제하고, 해당 기능 컴포넌트와 상기 시스템 버스 간의 연결을 재개시킬 수 있다. 더 구체적으로, 상기 ICT는 해당 기능 컴포넌트는 초기화하여 상기 시스템 버스에 연결될 수 있도록 한 후, 해당 래퍼에게 시스템 버스로 전송하는 시그널을 중단하라고 지시할 수 있다. 그러나, 테스트 분석 결과가 비정상이라고 판단되면, 상기 ICT는 상기 테스트를 몇회 더 반복할 수 있다. 몇 회 반복된 테스트 결과 해당 기능 컴포넌트가 비정상이라고 판단되면, 즉 상기 SoC 내에서 해당 기능 컴포넌 트가 잘못 제조되었거나, 손상이 되었거나 혹은 고장이 났다고 판단되면, 상기 ICT는 해당 기능 컴포넌트 를 비활성화(deactivate)시킬 수 있다. 대안적으로, 1회 테스트 분석 결과에 포함된 에러 코드가 상기 SoC 내에서 해당 기능 컴포넌트가 잘못 제조되었 거나, 손상이 되었거나 혹은 고장이 났다는 것을 나타내면, 상기 ICT는 해당 기능 컴포넌트를 비활성화(deactivate)시킬 수 있다. 상기 해당 기능 컴포넌트를 비활성화시키기 위하여, 상기 ICT는 상기 비정상인 기능 컴포넌트를 시스템 버 스로부터 격리(isolate)시키기 위하여, 상기 비정상인 기능 컴포넌트의 연결을 차단(cut-off 또는 disconnect)하거나 끊을 수 있다. 또는, 상기 비정상인 기능 컴포넌트를 비활성화시키기 위하여, 상기 ICT(60 0)는 상기 해당 기능 컴포넌트에 대한 전원 공급을 차단(즉, 파워 오프 또는 턴 오프)할 수 있다. 이와 같이 전 원 공급을 차단하면, 비정상적인 기능 컴포넌트가 오동작을 일으키는 것을 방지함과 아울러 SoC의 전력 소모를 절감할 수 있는 장점이 있다. 또한, 상기 비정상적인 기능 컴포넌트를 비활성화시키기 위하여, 상기 ICT는 상기 시스템 버스 상에 서 상기 해당 기능 컴포넌트의 어드레스를 철회(revoke)하거나, 혹은 삭제시키기 위한 시그널을 상기 시스템 버 스로 전송할 수 있다. 즉, 상기 ICT는 상기 시스템 버스 상에서 사용되는 어드레스들을 가지고 있는 컴포넌트에게 상기 비정상적인 기능 컴포넌트의 어드레스를 삭제해달라는 시그널을 전송할 수 있다. 한편, 상기 비활성화가 완료되면, 상기 ICT는 해당 기능 컴포넌트에 대한 스페어(spare)가 존재하는지 판 단할 수 있다. 만약 스페어가 존재하지만, 비활성화 상태인 경우 상기 ICT는 해당 스페어를 활성화시킬 수 있다. 그리고, 상기 ICT는 상기 시스템 버스 상에서 사용되는 어드레스들의 테이블을 가지고 있는 컴 포넌트에게 상기 테이블 내에서 상기 활성화된 스페어의 어드레스를 갱신해달라는 요청을 포함하는 시그널을 전 송할 수 있다. 만약 비활성화 상태였던 상기 스페어가 상기 시스템 버스 상에서 어드레스를 할당 받지 못하였다면, 상기 ICT는 상기 비정상적인 기능 컴포넌트의 어드레스를 상기 스페어에게 재할당되도록 하는 시그널을 상기 시 스템 버스로 전송할 수 있다. 그리고, 상기 ICT는 해당 스페어가 유휴 상태인지 모니터링한 후, 테스트를 수행할 수 있다. 만약, 상기 비활성화된 기능 컴포넌트에 대한 스페어가 존재하지 않는 경우, 상기 ICT는 상기 FPGA가 상기 비활성화된 기능 컴포넌트와 동일한 동작을 흉내 낼 수 있도록 하기 위하여, 상기 FPGA가 프로그래밍 되도록 할 수 있다. 상기 FPGA의 프로그래밍을 위한 정보는 상기 내부 메모리에 저장되어 있을 수 있 다. 또는 상기 FPGA의 프로그래밍을 위한 정보는 상기 FPGA의 캐쉬 메모리에 저장되어 있을 수 있다. 이와 같이 상기 FPGA가 상기 비활성화된 기능 컴포넌트와 동일한 동작을 흉내내도록 프로그래밍되면, 상기 ICT는 시스템 버스에서 사용되는 어드레스 테이블을 갱신해달라는 요청을 포함하는 시그널을 전송할 수 있다. 대안적으로, 상기 비정상적인 기능 컴포넌트의 어드레스를 상기 FPGA에게 재할당되도록 하는 요청을 포함하는 시그널을 상기 시스템 버스로 전송할 수 있다. 다시 말해서, 상기 FPGA의 기존 어드레스는 폐지 (revoke)되고, 상기 비정상적인 기능 컴포넌트의 어드레스로 대체될 수 있다. 다른 한편, 도 6a에 도시된 바와 달리, FPGA는 시스템 버스에 바로 연결되는 것이 아니라, 별도의 래 퍼를 통해 시스템 버스에 연결될 수도 있다. 즉, 상기 시스템 버스와 상기 FPGA 사이에 별도의 래퍼가 추가될 수 있다. 또한, 적어도 하나의 기능 컴포넌트가 비정상으로 판단되면, SoC는 SoC와 통신할 수 있는 디스플레이 장치에 경 고 메시지를 표시하도록 구성될 수 있다. 또한, 적어도 하나의 기능 컴포넌트가 비정상으로 판단되면, SoC는 SoC와 통신할 수 있는 서버에 경고 메시지를 송신하도록 구성될 수 있다. 여기서 서버는 제조사의 서버 또는 서비스 센터의 서버일 수 있다. 이상에서 설명 한 바와 같이, 본 개시는 ICT와 래퍼를 SoC 내에 통합시킴으로써, SoC가 구동중인 상태에서도 테스트를 수행할 수 있도록 한다. 이하에서는, 전술한 내용에 대한 이해를 높이기 위하여, 목차로 구분하여 보다 상세하게 설명하기로 한다. I. 구동중 테스트가 중요한 이유 자율 컴퓨팅 시스템에서 하드웨어 결함에 의해서 야기될 수 있는 잠재적인 사고를 방지하기 위하여, 다양한 연 구가 있어왔다. 다양한 연구 중에는 운용 전 테스트(pre-deployment test)가 있다. 이 테스트 기법은 고객에게 판매되기 전에 모든 하드웨어 설계를 점검하는 것이다. 제조 이후에 설계는 다양한 관점으로 테스트되어, 실제 동작시 발견될 수 있는 다양한 문제를 검출하고 수정한다. 예를 들어, 칩 설계를 테스트하기 위하여 테스트 패턴을 제공함으로써 입력에 대한 스캔과 출력 결과에 대한 검사를 수행할 수 있다. 비록 이러한 기법이 제품 출하 전에 하드웨어 설계에 대한 잠재적인 문제를 최소화할 수 있기는 하지만, 직접 회로(IC)의 노후화, 외부 환경, 복잡한 설계의 취약성으로 인하여 발생할 지도 모르는 구동중(runtime) 결함에 대한 문제는 해결하지 못한다. 이와 같이 전술한 운용 전 테스트는 하드웨어 결함을 효과적으로 해결할 수 없기 때문에, 본 발명자는 구동중에 테스트할 수 있는 방법에 관심을 갖기 시작하였다. 테스트 메커니즘 관점에서, 운용 전 테스트와 운용 후 테스트는 서로 유사할 수도 있지만, 언제 테스트를 할 수 있는지는 극명하게 차이가 있다. 특히, 운용 전 테스트는 특정한 시간에만 테스트를 할 수 있고, 일반적으로는 제조 직후 잠깐 동안에만 가능하다. 반면에, 구동중 테스트는 일반적인 동작 상황에서 언제든지 테스트를 할 수 있다. 이러한 운용 중 테스트에는 2가지 테스트 기법, 즉 기능 테스트와 스캔 테스트가 존재할 수 있다. 상기 기능 테스트는 테스트 입력을 생성하고, 생성된 테스트 입력을 원래의 설계에 입력한 후 나오는 출력 결과 를 의도된 패턴과 비교하는 것이다. 다른 방식으로, 원래의 설계에 기반하여, 상기 기능 테스트는 입력과 출력 시그널을 모니터링하여, 이상 현상을 검출할 수 있다. 상기 스캔 테스트는 원래의 설계 내에 스캔 테스트를 위한 아키텍처를 삽입하고, 테스트 패턴을 가능한 다양하 게 만들어내야 한다. 이와 같이, 스캔 아키텍처와 테스트 패턴을 준비한 이후에는, 다양한 방식으로 구동중 테 스트를 수행할 수 있게 된다. 상기 스캔 테스트를 위하여, 상기 ICT는 각 CUT 내의 복수의 플리-플롭들을 서로 연결하고, 테스트 입력을 적어 도 하나의 플리-플롭으로 주입하고, 상기 CUT가 결함이 있는지 아니면 정상인지를 구동 중에 분석하기 위하여 상기 플리-플롭의 결합 로직의 동작으로부터 테스트 결과를 획득할 수 있다. 도 7은 플리-플롭을 스캔하는 예를 나타낸다. 하드웨어 설계를 보다 쉽게 하기 위하여 그리고 제조 결함을 최소화기 위하여, 테스트 가능한 설계(Design for testability; DFT)를 적용하는 것은 매우 중요하다. 이를 위하여, 스캔 테스트를 위한 아키텍처를 설계에 반영하고, 검출가능한 모든 결함에 대한 특정 비율의 테스 트 범위를 정의하여 테스트를 수행할 수 있다. D 타입의 플리-플롭을 사용하는 경우, 스캔 테스트를 위한 아키텍처는 쉽게 설계에 반영될 수 있다. 테스트 도 중에는, CUT 내의 모든 플리-플롭들은 D 플리-플롭과 멀티플렉서(multiplexer)를 포함하는 스캔 플리-플롭들로 동작될 수 있다. 상기 플리-플롭은 일반적인 D 타입 플리-플롭에 비하여 도 7에 도시된 바와 같이 2개의 추가적인 핀, 즉 SE(scan enable) 핀과 SI (scan in) 핀을 사용할 수 있다. 상기 SI 핀은 테스트 입력을 위한 것이고, 상기 SE 핀은 일반 동작을 위한 입력(D 핀)과 테스트 동작을 위한 테스트 입력(SI) 간에 스위칭을 가능하게 한다. 도 8은 하드웨어 설계 내에 스캔 테스트를 위한 아키텍처가 추가된 에를 나타낸다. 도시된 바와 같이, 스캔 플리-플롭 내의 모든 SE 핀들은 SE(scan_enable) 포트들과 연결되어 있고, 각 플리-플 롭의 SI 핀은 이전 플리-플롭 혹은 스캔 입력 포트의 Q 핀과 연결되어 있고, 각 플리-플롭의 Q 핀은 다음 플리- 플롭의 SI 핀과 연결되어 있다. 이러한 연결들은 다중 스캔 체인을 만들어 낸다. 즉, 플리-플롭들은 서로 엮이게 되어 스캔 체인을 만들어 낸다. SE(scan_enable) 포트가 인에이블되면, 모든 스캔 플리-플롭들은 SI 핀으로부터의 데이터가 플리-플롭을 거쳐 Q 핀으로 전달되도록 하고, 따라서 데이터는 scan_in 포트에서 대응하는 scan_out 포트로 전달될 수 있다. 각 스 캔 체인 상의 모든 플리-플롭들은 scan_in 포트로부터의 테스트 입력을 scan_out 포트로 쉬프트시킨다. 스캔 체인 상에서 플리-플롭들의 개수가 작아질 수록, 데이터를 쉬프트하는 속도는 더 빨리질 수 있다. 그러나, 각 스캔 체인 상에서 플리-플롭의 개수와 스캔 체인의 개수는 서로 상호 의존적일 수 있다. 스캔 체인을 더 많 이 만들어 낼수록 각 스캔 체인 상에는 더 적은 플리-플롭들이 존재할 수 있다. II. ICT를 통한 테스트 전술한 테스트는 백그라운드(background) 작업으로서 수행되기 때문에, 시스템 성능의 하락 없이, 테스트를 수 행할 수 있다. 테스트의 대상이 될 컴포넌트의 동작을 모니터링하는 것에 기초하여, ICT는 해당 컴포넌트가 유 휴 상태인지를 판단할 수 있다. 해당 컴포넌트가 유휴 상태에 있을 때 테스트를 수행하기 때문에, 시스템의 성 능 하락을 야기하지 않을 수 있다. ICT는 CUT의 동작 상태를 시스템 버스 상에서 지속적으로 모니터링하고, CUT 는 예측되지 않은 액세스에 대해서 응답할 수 있다. 만약 CUT에 대한 액세스가 발생한다면, 상기 CUT를 테스트 동작에서 일반 동작으로 스위칭함으로써, CUT를 복구하고 상기 CUT를 일반 동작으로 회귀(come back)시킬 수 있 다. 상기 스위칭을 위해 약간의 시간 지연이 발생할 수 있다. 본 개시는 상기 시간 지연 동안에 시스템 버스를 효율적으로 사용할 있도록 함으로써, 상기 복구로 인한 시스템 성능 저하를 최소화할 수 있다. II-1. SoC 또는 SiP 아키텍처의 복잡성 증가 직접 회로(Integrated Circuit: IC)의 설계는 날이 갈수록 복잡해지고 있고, 직접도 역시 크게 증가하고 있다. SoC 또는 SiP는 직접도가 매우 높은 반도체로서, 일부 기능 컴포넌트의 결함은 전체 시스템 성능의 하락을 야기 할 수 있다. 따라서, SoC 내의 기능 컴포넌트들에 대해서 결함 유무를 파악하기 위한 테스트를 수행하는 것이 날로 중요해지고 있다. 도 9a는 도 6에 도시된 SoC를 동작 관점에서 간략하게 나타낸 예시도이다. 상기 기능 컴포넌트(혹은 IP)는 3개의 타입, 1) 내부 프로세서, 2) 인터페이스 또는 통신 제어기, 3) 메모리로 구분될 수 있다. 도 9에는 기능 컴포넌트(혹은 IP) (100/200/300)과, 내부 메모리, 메모리 컨트롤러, 시스템 버스, ICT, 복수의 래퍼들과, I/O 인터페이스가 나타나 있다. 상기 기능 컴포넌트(혹은 IP)(100/200/300)는 인코딩, 디코딩, 암호화 그리고 복호화, 그리고 연산 등과 관련된 기능을 수행할 수 있다. 이러한 상기 기능 컴포넌트(혹은 IP)(100/200/300)는 상기 내부 메모리로부터 로 우 데이터를 획득하고, 특정한 알고리즘으로 상기 데이터를 처리한다. 상기 처리가 완료되면, 완료를 알리는 시 그널과 함께 출력 데이터를 전송할 수 있다. 상기 내부 메모리는 ROM(Read Only Memory) 혹은 RAM(random access memory)일 수 있다. 상기 ROM은 비휘 발성 메모리(Non Volatile Memory)에 해당되고, 상기 RAM은 휘발성 메모리(Volatile Memory)에 해당할 수 있다. 휘발성 메모리는 전원이 공급된 경우에만 데이터를 저장하고, 전원 공급이 차단되면 저장된 데이터가 소멸되는 메모리일 수 있다. 휘발성 메모리는 정적 랜덤 액세스 메모리 (Static Random Access Memory; SRAM), 동적 랜 덤 액세스 메모리 (Dynamic Random Access Memory; DRAM) 등을 포함할 수 있다. 상기 내부 메모리는 SSD(solid state drive), 플래시 메모리 (flash memory), MRAM(magnetic random access memory), PRAM(phase change RAM), FeRAM(ferroelectric RAM) 하드디스크, 플래시 메모리 등을 포함할 수 있으며, SRAM(synchronous random access memory), DRAM(dynamic random access memory)등을 포함할 수 있 다. 상기 I/O 인터페이스는 상기 SoC 또는 SiP가 다양한 외부 하드웨어와 통신할 수 있도록 하기 위하여 다양한 프 로토콜 및 기능을 지원할 수 있다. 그런데, SoC 또는 SiP가 자율 시스템에 장착되어 사용될 때, 트랜지스터의 노후화 또는 물리적인 충격, 혹은 사 용 환경 등에 의해 손상될 가능성이 있다. 특히, SoC 또는 SiP 내의 기능 컴포넌트(혹은 IP)가 중요 데이터를 처리하고 있는 경우, 상기 손상은 잘못된 출력 데이터를 생성할 수 있고, 그로 인해 자율 시스템의 정확도를 크 게 떨어뜨릴 수 있다. 이를 방지하고자, 도시된 바와 같이 ICT는 시스템 버스를 모니터링하고, 기능 컴포넌트 (100/200/300), 내부 메모리, 메모리 컨트롤러 그리고 I/O 인터페이스를 래퍼를 통하여 혹은 시스템 버스를 통하여 상태를 모니터링하고, 유휴 상태의 기능 컴포넌트가 찾아지면, 상기 ICT 는 해당 기능 컴포넌트를 CUT로 선택한 후, 테스트를 수행할 수 있다. 도 9a에는 시스템 일반 동작시 시스템 버스와의 연결이 굵은 선의 화살표로 나타나 있고, ICT 및 래퍼의 시그널 이 얇은 선의 화살표로 나타나 있다. 도 9b는 NPU에 대한 테스트를 수행하기 위한 구성을 나타낸 예시도이다. 도 9b를 참조하면, NPU는 NPU에 대한 테스트를 수행할 수 있도록, 다른 구성 요소를 더 포함할 수 있다. 구체적으로, 도 1 또는 도 3에 도시된 구성 요소 외에도, 랜덤 번호 생성기, 미리 정의된 테스트 데이터 저장부, 템프 레지스터 중 적어도 하나가 NPU에 선택적으로 더 포함될 수 있는 것으로, 도 9b에 나타나 있 다. NPU 내부 테스트를 위해서 MUX가 NPU 내부 메모리와 프로세싱 엘리먼트 어레이 사이에 배치 될 수 있다. MUX는 프로세싱 엘리먼트 어레이를 테스팅하도록 구성된 구성요소와 NPU 내부 메모리를 스위칭하도록 구성될 수 있다. 랜덤 번호를 사용하여 프로세싱 엘리먼트 어레이를 테스팅 하는 방법에 대하여 설명한다. 도 9b에 도시된 NPU 내부의 랜덤 번호 생성기는 미리 정해진 시드(seed)에 기초하여 랜덤 번호를 생성할 수 있다. 프로세 싱 엘리먼트 어레이 중 적어도 하나는 MUX에 의해서 선택되어 NPU불량 여부를 테스팅 할 수 있다. 상기 ICT는 래퍼(700a)를 통하여 상기 NPU의 상태를 모니터링하고, 상기 NPU가 유휴 상태라고 판단되면, 상기 NPU에게 테스트를 시작하라고 명령할 수 있다. 구체적인 예를 들면, 상기 ICT는 상기 NPU에 포함된 복수의 PE들 적어도 하나를 선택하여 테스트를 시작하라고 명령할 수 있다. 구체적인 예를 들면, 상기 ICT는 상기 NPU에 포함된 복수의 PE들 중에서 일정 비율의 PE들(예컨대, 전체 PE들 중 20%의 PE들)이 유휴 상태라고 판단되면, 상기 NPU에게 테스트를 시작하라고 명령할 수 있다. 다르게 설명하면, 전체 PE 중 유휴 PE 비율이 임계 값 이상일 경우, 테스트를 시작하라고 명령할 수 있다. 구체적인 예를 들면, 상기 ICT는 상기 NPU에 포함된 복수의 PE들 중에서 일정 비율의 PE들(예컨대, 전체 PE들 중 50%의 PE들)을 선택하여 상기 NPU에게 테스트를 시작하라고 명령할 수 있다. 상기 NPU에 대한 테스트가 수행되면, 상기 NPU의 추론 속도, 즉 IPS(inference per second)가 저하될 수 있다. 구체적으로, 테스트되는 PE의 개수에 따라서 추론 속도가 저하될 수 있다. 구체적인 예를 들면, 전체 PE 들 중에서 50%의 PE들이 테스트되면, 추론 속도는 약 50% 정도 저하될 수 있고, 전체 PE들 중 30%의 PE들이 테 스트되면, 테스트 중 추론 속도가 약 30% 정도 저하될 수 있다. 따라서, 일 예시에 따르면, 상기 테스트에 따른 속도 저하가 개선되도록, 상기 NPU는 여분의 PE들을 더 포 함할 수 있다. 다른 예를 들어, 상기 NPU가 미리 정해진 IPS(inference per second) 값 이하로 동작 시, 상기 ICT 는 상기 NPU에게 테스트를 실시하라고 지시할 수 있다. 구체적으로, 상기 NPU가 최대 100 IPSs로 동 작할 수 있다고 가정하고, 임계 IPS 값은 30 IPS이라고 가정하면, 상기 ICT는 상기 NPU가 30 IPS이 상으로 동작되면 남는 시간에 상기 NPU에게 테스트를 수행하라고 지시할 수 있다. 예를 들면 상기 NPU가 40 IPS로 동작할 때 남는 60 IPS를 이용하여 테스트를 수행할 수 있다. 따라서, 실질적인 NPU의 속 도 저하가 발생되지 않을 수 있다. 다른 예를 들어, 상기 ICT는 메모리에서 상기 NPU 내부 메모리로 전달되는 데이터가 지연되어, 상기 NPU가 유휴 상태가 되거나 혹은 데이터 부족 구간에 진입하면, 상기 NPU에게 테스트를 수행하라 고 지시할 수 있다. 상기 NPU에 대한 테스트가 수행되면, 상기 NPU내의 각 PE에 대응되는 레지스터 파일(RF)는 미리 정해 진 테스트 입력 데이터로 초기화되고, 대응하는 PE는 상기 레지스터 파일(RF) 내의 테스트 입력 데이터에 따라 추론을 수행할 수 있다. 상기 미리 정해진 테스트 입력 데이터는 상기 NPU에 대한 기능 테스트 또는 부분적인 기능 테스트일 수 있다. 상기 NPU에 대한 테스트가 수행되면, 전술한 바와 같이 상기 NPU 내부의 랜덤 번호 생성기는 랜덤 번 호를 생성한다. 그러면, 상기 레지스터 파일(RF)은 상기 생성된 랜덤 번호에 의해서 초기화되고, 대응하는 PE는 상기 레지스터 파일(RF) 내의 랜덤 번호에 따라 추론을 수행한다. 대안적으로, ICT는 래퍼(700b)를 통하여 CPU로 하여금 상기 NPU 내의 레지스터 파일(RF)에게 테스트 입력 데이터를 주입하라고 명령할 수 있다. 상기 NPU에 대한 테스트가 수행되면, 상기 NPU내의 복수 레지스터 파일들(RF)은 단일 테스트 입력 데 이터로 초기화되고, 대응하는 PE는 상기 레지스터 파일(RF) 내의 테스트 입력 데이터에 따라 추론을 수행할 수 있다. 구체적으로 NPU 내부의 복수 PE들은 동일한 단일 테스트 입력 데이터를 기초로 테스트되고, 추론 결 과를 출력할 수 있다.대안적으로, 상기 NPU에 대한 테스트가 수행되면, 상기 NPU내의 알부 레지스터 파일들(RF)은 특정 테 스트 입력 데이터에 기초하여 초기화되고, 대응하는 PE는 상기 레지스터 파일(RF) 내의 테스트 입력 데이터에 따라 추론을 수행할 수 있다. 상기 레지스터 파일(RF)은 각 PE 내의 플리-플롭들을 리셋하고, 전술한 바와 같이 PE들에게 테스트 입력 데이터 를 전달할 수 있다. 각각의 RF크기는 예를 들면 1Kb일 수 있다. II-2. 래퍼의 필요성 도 10은 래퍼의 동작을 나타낸 예시도이다. 전술한 바와 같이, ICT는 SoC 또는 SiP의 구동중에 SoC 또는 SiP 내부의 많은 기능 컴포턴트들(즉, IP, I/O 인 터페이스, 메모리 등)을 테스트할 수 있다. 이를 위해서, 우선 CUT로 선택된 기능 컴포넌트에 대해 테스트를 수 행하는 도중에, 해당 기능 컴포넌트에 대해 시스템 버스로부터의 액세스로 인한 충돌 문제를 해결해야 한다. 상기 충돌 문제를 해결하기 위하여, 상기 기능 컴포넌트가 유휴 상태인지를 모니터링한 후, 상기 유휴 상태로 모니터링되면 상기 기능 컴포넌트를 일반 동작 모드에서 테스트 동작 모드로 스위칭한 후, 테스트를 수행해야 한다. 상기 테스트 도중 상기 충돌이 검출되면, 상기 기능 컴포넌트를 다시 일반 동작 모드로 전환시켜야 한다. 상기 일반 동작 모드로 전환시킨 후에는, 상기 기능 컴포넌트가 입력 데이터를 올바르게 처리할 수 있어야 한다. 이를 위해서, 도시된 래퍼가 각 기능 컴포넌트와 시스템 버스 사이에 배치되어야 한다. 상기 래퍼 는 각 동작 모드를 위한 입력 및 출력을 선택적으로 제어할 수 있는 멀티플렉서 게이트(multiplexer gates)들을 포함할 수 있다. 도시된 바와 같이, TEST_ENABLE 포트가 ON되면, 테스트 백터가 CUT에 입력될 수 있고, TEST_OUTPUT 포트는 출력 을 전송할 수 있다. 상기 래퍼로부터 출력되는 일반 데이터는 시스템 버스를 통하여 다른 기능 컴포넌트들 로 전달될 수 있다. 반면, 테스트 결과는 상기 ICT로 직접 전달될 수 있다. 상기 ICT는 외부 메모리 혹은 내부 메모리로부터 테스트를 위한 테스트 벡터를 수신하고, 상기 테스트를 수행한 결과를 내부 메모리 혹 은 외부 메모리에 저장하거나 혹은 외부로 전송할 수 있다. 구동중인 SoC 또는 SiP의 테스트를 수행하기 위하여, ICT는 여러 과정을 수행할 수 있다. 첫 번째로, ICT는 일정한 규칙에 기초하여, 테스트를 수행할 기능 컴포넌트를 CUT로 선택할 수 있다. SoC 또는 SiP가 구동중이기 때문에, 상기 CUT는 여전히 시스템 버스로부터의 액세스에 대해서 응답할 수 있어야 한다. 따라서, 가능한 유휴 상태로 있는 기능 컴포넌트를 CUT로 선택하는 것이 효과적일 수 있다. 이를 위하여, ICT는 기 능 컴포넌트가 유휴 상태로 진입하는지를 모니터링할 수 있다. 해당 기능 컴포넌트가 유휴 상태에 진입하면, 래 퍼는 TEST_ENABLE 포트를 턴온할 수 있다. ICT는 테스트 벡터를 TEST_ENABLE 포트를 통하여 해당 CUT로 주입시킬 수 있다. 상기 ICT는 테스트 결과를 상기 래퍼의 TEST_OUPUT 포트를 통하여 상기 CUT로부터 수집하고, 분석할 수 있다. 상기 테스트 결과가 문제가 검출되었다고 나타내면, 상기 ICT는 후 동작(Post Action)을 수행할 수 있다. 상기 테스트 도중, 시스템 버스로부터 상기 CUT에 대한 일반적인 액세스가 검출되면, 상기 ICT는 상기 시스템 버스로부터의 액세스를 일시적으로 지연시킨 후, 상기 테스트 동작을 즉시 중지시 킬 수 있다. 그런 다음, 상기 ICT는 상기 CUT의 레지스터 설정을 위한 이전 값들을 복구(recover)하고, 상 기 래퍼의 TEST_ENABLE 포트를 턴오프시킬 수 있다. 상기 CUT의 일반 동작을 위한 모든 준비가 완료되면, 상기 ICT는 상기 CUT와의 입출력을 위한 연결을 상기 시스템 버스로 반환하도록, 상기 래퍼를 제어할 수 있다. 도 11은 ICT의 내부 구성을 나타낸 예시도이다. 도 11를 참조하면, ICT은 설정 데이터(CONF_DATA) 복원기, 상태 검출기(state detector), 스케 줄러(scheduler), 테스터(test), 테스트 벡터(test vector) 생성기, 호스트 인터페이스, 후 동작(POST_ACT) 수행기를 포함할 수 있다. 상기 상태 검출기는 SoC 칩 또는 SiP 내의 기능 컴포넌트들의 상태가 유휴 상태인지 아니면 사용중(busy) 상태(혹은 처리중(processing) 상태)인지를 검출할 수 있다. 임의의 기능 컴포넌트가 유휴 상태로 진입하면, 상기 상태 검출기는 상기 스케줄러에게 해당 기능 컴포넌트의 ID(C_ID)를 전달함으로써, 테스트를 수행 할 수 있도록 할 수 있다. 상기 스케줄러는 상기 ICT의 전체 동작을 관리할 수 있다. 상기 스케줄러는 상기 상태 검출기 로부터 해당 기능 컴포넌트의 상태를 수신하고, 테스트를 트리거링할 수 있다. 상기 스케줄러는 컴포 넌트의 ID를 상기 테스터로 전달할 수 있다. 상기 테스터는 래퍼를 제어하고, 테스트 벡터를 전달하고, 테스트 결과를 획득한 후, 상기 테스트 결 과가 의도된 테스트 결과에 부합하는지를 비교한 후, 상기 테스트 결과를 상기 후 동작 수행기로 전달할 수 있다. 그리고 상기 테스터는 CUT로 선택된 기능 컴포넌트를 위한 레지스터 설정을 원래의 값으로 복원 할 수 있다. 상기 테스트 벡터 생성기는 테스트 벡터(혹은 미리 정의된 테스트 입력 데이터)와 그리고 대응하는 의도된 테스트 결과를 생성할 수 있다. 상기 테스트 벡터 생성기는 버퍼, 메모리 인터페이스, 상기 테스트 벡터와 상기 의도된 텍스트 결과를 저장하는 메모리, 랜덤 번호 생성기를 포함할 수 있다. 테스트가 시작되면, 상기 테 스트 벡터의 생성을 위한 테스트 패턴이 상기 버퍼 내에 로딩될 수 있다. 상기 랜덤 번호 생성기는 상기 테스트 벡터를 생성하기 위해서 사용될 수 있다. 상기 랜덤 번호 생성기는 상기 메모리가 모든 테스트 벡터를 저장하지 않을 수 있도록 하면서도, 테스트 벡터가 다양하게 생성될 수 있도록 한다. 상기 후 동작 수행기는 상기 테스터로부터 문제가 발견된 기능 컴포넌트의 ID(예컨대, C_ID)를 수신 하면, 후 동작을 수행할 수 있다. 상기 후 동작은 상기 문제가 있는 기능 컴포넌트를 격리시키거나, 사용자 혹 은 원격 호스트 장비에게 이를 알리는 기능을 수행할 수 있다. 상기 호스트 인터페이스는 상기 테스트 과정 중에서 문제가 발견된 기능 컴포넌트에 대해 사용자에게 보고 하거나 혹은 원격 호스트 장비에게 보고할 수 있다. 만약 테스트 동작과 관련하여 변경사항이 있다면, 상기 호 스트 인터페이스는 원격 호스트 장비에게 이를 알릴 수 있다. 상기 설정 데이터 복원기는 상기 테스트가 완료되거나 상기 테스트 과정중에 시스템 버스로부터 CUT 로 선택된 기능 컴포넌트에 대한 액세스가 검출되면, 상기 테스터가 상기 CUT를 일반 동작 모드로 스위칭 시키기 위하여, 상기 CUT의 레지스터 세팅을 복원할 수 있다. 대부분의 기능 컴포넌트들은 일반 동작을 위하여 특정한 레지스터 설정 값을 가질 수 있다. 따라서, 상기 설정 데이터 복원기는 상기 테스트가 수행되기 전 에 기능 컴포넌트의 레지스터 설정 값을 저장하고, 상기 CUT를 일반 동작 모드로 스위칭해야 할 때 상기 레지스 터 설정의 값을 상기 기능 컴포넌트에 복원시킬 수 있다. II-3. 기능 컴포넌트의 유휴 상태 검출 도 12는 ICT가 기능 컴포넌트가 유휴 상태인지를 모니터링하는 동작을 상세하게 나타낸 블록도이다. 기능 컴포넌트가 일반 동작 모드로 있는 중에 유휴 상태인지를 검출하기 위하여, ICT는 2가지 기법을 사용 할 수 있다. 첫 째로, 동작 여부를 직접적으로 혹은 간접적으로 나타내는 일부 하드웨어 시그널에 기초하여, ICT는 해당 컴포넌트가 유휴 상태인지 아니면 사용중 상태인지를 모니터링할 수 있다. 예를 들어, 해당 기 능 컴포넌트의 전력 소모를 줄이기 위하여 해당 기능 컴포넌트의 연결을 해제시키기 위한 파워 게이팅 제어 신 호를 ICT가 모니터링할 수 있다. 또한, 동작 여부를 간적접으로 나타내는 출력 신호 혹은 상기 기능 컴포 넌트 내부에서 동작 여부와 관련된 정보를 저장하는 레지스터의 값에 기초하여, 상기 ICT는 해당 기능 컴 포넌트가 유휴 상태인지를 판단할 수 있다. 두 번째로, 상기 ICT는 래퍼를 통하여 시스템 버스로부터 의 시그널을 모니터링 하거나 특정 시간 구간 동안에 상기 기능 컴포넌트의 입력/출력 포트를 모니터링함으로써, 상기 ICT는 해당 기능 컴포넌트가 유휴 상태인지를 판단할 수 있다. II-4. 액세스 충돌에 대한 처리 도 13은 시스템 버스 상에서 동작하는 마스터(master), 슬래이브(slave), 아비터(arbiter) 간에 동작을 나타낸 예시도이다. 시스템 버스 상에서 마스터는 슬래이브를 사용하려는 주체일 수 있고, 슬래이브는 마스터에 의해서 사용되는 주 체일 수 있고, 상기 아비터(arbiter)는 상기 마스터와 상기 슬래이브 사이에서 조정과 결정을 수행하는 주체일 수 있다. 도 13에 도시된 슬래이브는 CUT로 선택된 기능 컴포넌트일 수 있고, 상기 아비터는 ICT일 수 있다. 상기 CUT로 선택된 기능 컴포넌트에 대해 테스트가 진행되는 도중, 일반 동작을 위한 액세스가 상기 시스템 버 스로부터 검출되면, 상기 ICT은 상기 CUT를 이전의 상태로 복구시키는데 일정 이상의 시간을 필요로 할 수 있다. 따라서, 상기 ICT는 마스터로부터의 시스템 액세스를 일시 중지시키기 위하여 HREADY 신호를 일시적으로 비활성화(또는 de-assert)시키고, 테스트 활동을 중지하고, CUT의 레지스터 설정을 복구하고, 래퍼 로 입력되는 혹은 출력되는 데이터의 방향을 변경할 수 있다. 상기 슬래이브인 CUT가 상기 마스터와 작업을 수 행할 준비가 완료되면, HREADY 신호가 턴-온될 수 있다. 그러나, 본 개시에 따르면, ICT는 버스 분리 동작을 위 하여 약간의 시간 지연을 유도할 수 있다. 구체적인 과정에 대해서 설명하면 다음과 같다. 첫 번째로, 마스터는 버스 액세스를 위하여 HBUSREQ 신호를 활성화(또는 assert)한다. 두 번째로, 조정 (arbitration) 혹은 결정 과정에서, 상기 아비터는 버스 액세스를 허용하기 위하여 HGRANT 신호를 활성화(또는 assert)한다. 그러면, 마스터는 상기 시스템 버스를 통해서 데이터를 슬래이브인 CUT로 전송할 수 있다. 만약 상기 ICT가 테스트를 위한 처리 동작을 수행중이라면, 상기 ICT는 현재 마스터를 나타내는 비트와 함께 HSPLIT 신호를 상기 아비터로 전송하고, 동시에 HRESP 신호 내에 SPLIT 신호를 활성화(또는 assert)시킨다. 상기 활성 화(assertion) 이후, 상기 마스터는 상기 CUT에 대한 액세스를 무효화(nullify)시키고, 상기 아비터는 상기 마 스터의 개입 없이 상기 조정 혹은 결정 과정을 진행한다. 상기 CUT가 상기 마스터로부터의 액세스에 대해서 응 답할 준비가 완료되면, 상기 ICT는 상기 HSPLIT 신호를 비활성화하고, 상기 마스터는 상기 CUT를 액세스하려는 자신의 작업을 재개하기 위하여, 상기 아비터로부터의 허가(grant)를 대기한다. 도 14는 SoC 칩 또는 SiP 내에 쉬프트 레지스터가 추가된 예를 나타낸다. 본 개시의 발명자는 상기 I/O 인터페이스에 대한 액세스는 시스템 버스 상에서 충돌을 야기하지 않을 수 있다는 사실을 인식하였다. 예를 들어, 상기 타겟 CUT가 마스터인 경우, 상기 I/O 인터페이스를 통해 연결된 외부 기기 는 자기 스스로 액세스를 요청하지 않기 때문에, 충돌은 발생하지 않을 수 있다. 따라서, CUT가 슬래이브일 때 발생하는 충돌 문제를 해결하는데 에만 집중하는 것이 효과적일 수 있다. 대신에, 외부 기기로부터 CUT로 전달되는 데이터를 상기 복구 시간 동안에 지연시키기 위하여, 쉬프트 레지스터 가 SoC의 포트와 상기 CUT의 외부 인터페이스 포트 사이에 추가될 수 있다. 상기 쉬프트 레지스터는 상기 CUT가 복구되는 시간 동안에 SoC 외부로부터 입력되는 액세스 시그널을 저장하기 위하여 추가될 수 있다. 상기 CUT가 준비 완료되면, 상기 액세스 시그널들이 상기 쉬프트 레지스터에 의해서 재 생성되어 출력될 수 있다. 상기 쉬프트 레지스터의 깊이는 상기 CUT가 일반 동작으로 복구되는데 필요한 클럭 사이클의 개수에 따라 결정 될 수 있다. 특히, 하나 이상의 기능 컴포넌트가 SoC 외부로부터의 시그널을 수신해야 하는 경우, 쉬프트 레지 스터의 깊이는 가변될 수 있어야 한다. 이 경우, 상기 쉬프트 레지스터의 깊이는 상기 ICT에 의해서 결정될 수 있다. II-5. ICT의 동작 순서 도 15는 ICT의 동작 순서를 나타낸 예시도이다. 도 15을 참조하면, ICT가 구동중인 테스트 시작과 관련된 타이머가 만료(S601)하면, ICT는 임의 기능 컴포넌트 가 유휴 상태인지를 모니터링하고, 유휴 상태에 있는 기능 컴포넌트를 검출해낸다(S603). 그러면, 상기 ICT는 테스트 준비 절차를 수행한다(S605). 상기 테스트 준비 절차는 상기 기능 컴포넌트를 CUT로 선택한 다음, 상기 CUT로 선택된 기능 컴포넌트를 시스템 버스로부터 격리시키고, 테스트 입력 데이터로서 테스 트 벡터를 생성하는 것을 포함할 수 있다. 상기 시스템 버스로부터 격리시킨다는 것은, 상기 ICT가 상기 CUT로 선택된 기능 컴포넌트와 통신하는 래퍼 상에서 입력 및 출력의 방향을 변경하는 것을 의미할 수 있다. 그리고, 상기 ICT는 테스트 입력 데이터인 테스트 벡터를 상기 CUT로 주입시킨다(S607). 상기 테스트가 정상적으로 완료되면, 상기 ICT는 테스트 결과를 검사한다(S609). 상기 검사를 위하여, 상기 ICT 는 상기 테스트 결과가 의도된 테스트 결과에 부합하는지를 비교할 수 있다. 상기 테스트 결과가 상기 CUT로 선택된 기능 컴포넌트에 문제(즉, 결함 혹은 손상 등)가 없다는 것을 나타내면, 상기 ICT는 상기 기능 컴포넌트를 일반 동작 상태로 복구시킬 수 있다(S611). 한편, 상기 테스트 준비중 혹은 상기 테스트 수행 도중에 시스템 버스로부터 상기 CUT로 선택된 기능 컴포넌트 에 대한 액세스가 검출되면, 상기 ICT는 상기 CUT로 선택된 기능 컴포넌트를 일반 동작 상태로 복구시킬 수 있다(S613). 상기 복구는 상기 CUT로 선택된 기능 컴포넌트의 레지스터 설정 값을 복구하고, 상기 CUT로 선택된 기능 컴포넌트와 통신하는 래퍼 상에서 입력 및 출력의 방향을 원래대로 되돌리는 것을 의미할 수 있다. 이 경우, 상기 ICT는 백-오프 타이머를 구동하고(S615), 상기 백-오프 타이머가 만료하면, S603 과정으로 궤환 할 수 있다. 한편, 상기 테스트 결과가 상기 CUT로 선택된 기능 컴포넌트에 문제(즉, 결함 혹은 손상 등)가 있다는 것을 나 타내면, 상가 ICT는 후 동작을 수행할 수 있다(S617). II-6. 내부 메모리에 대한 테스트 도 16은 내부 메모리에 대한 테스트 과정을 이해하기 쉽게 나타낸 블록도이다. 내부 메모리에 대한 테스트는 기능 컴포넌트에 대한 테스트와 다를 수 있다. 이하에서는 내부 메모리에 대한 2 가지 테스트 기법이 제시된다. 첫 째는, 상기 내부 메모리로부터 데이터를 읽어내는 과정에서 에러 검출 코드를 이용하여 에러를 검출하는 기 법이다. 만약 읽어낸 과정에서 획득된 에러 검출 코드가, 미리 정해진 에러 검출 코드와 다르다면, 상기 ICT는 에러로 판별할 수 있다. 두 번째는, 일반적인 동작 중에 하드(hard)한 방식으로 읽기-쓰기 테스트를 수행하는 기법이다. 도 16은 두 번째 기법을 나타낸다. 상기 내부 메모리를 감싸고 있는 테스트 로직은, 시스템이 구동중일 때에 읽 기-쓰기 테스트를 수행하고, 시스템 버스로부터의 액세스는 바이패스(bypass)할 수 있다. 테스트를 완벽하게 처 리하기 위하여, 상기 ICT 내의 테스터는 주소 관리를 책임질 수 있다. 도시된 일시적(temporally) 레지스터 파 일은 테스트로 인하여 삭제될 위험이 있는 원본 데이터를 일시적으로 저장 저장할 수 있다. 테스트가 수행 완료 되면, 상기 일시적 레지스터 파일 내의 상기 원본 데이터가 상기 내부 메모리 내로 다시 기록될 수 있다. 만약 테스트 수행 도중에, 예측 불가능한 액세스가 발생하면, 시스템 버스 상의 데이터가 상기 일시 레지스터 파일 내에 기록될 수 있고, 반대로 상기 일시 레지스터 파일 내의 데이터는 상기 시스템 버스로 이동될 수 있다. 전술한 바와 같은 테스트 기법은 내부 메모리 뿐만 아니라, 외부 메모리에도 동일하게 적용될 수 있다. II-7. 테스트 후의 동작 SoC 또는 SiP 내에 하드웨어 결함이 있다면, 상기 테스트 후의 동작은 매우 중요할 수 있다. 예를 들어, 사용자 에게 결함 여부를 알려서, 사용의 중단을 권고할 수 있다. 이를 위해, 도 11에 도시된 후 동작(Post Action) 수 행기는 결함이 검출된 기능 컴포넌트에 대한 정보 그리고 결함을 야기한 테스트 입력 데이터(즉, 테스트 벡터)에 대한 정보를 제공할 수 있다. 전술한 정보는 결함이 있는 기능 컴포넌트의 위치를 사용자가 알 수 있도 록 할 수 있다. 상기 결함이 검출된 기능 컴포넌트에 대한 사용은 중단되어야 하고, 격리되어야 한다. 상기 결 함이 있는 기능 컴포넌트가 시스템 전체의 성능을 저하시키는 것을 방지하기 위하여, 해당 기능 컴포넌트의 출 력 시그널은 미리 정해진 신호로 대체될 수 있다. 또는, 해당 기능 컴포넌트는 리셋되거나, 게이팅될 수 있다. 또는 해당 기능 컴포넌트에 대해서 파워 게이팅이 수행될 수 있다. 한편, 상기 기능 컴포넌트가 격리되는 경우, SoC 또는 SiP는 다른 문제에 직면하게 될 수 있다. 일부 기능 컴포 넌트에 결함이 있더라도, SoC 또는 SiP가 여전히 동작될 수 있도록 하기 위한 방안이 제시되어야 한다. 예를 들 어, 상기 SoC 또는 SiP가 높은 신뢰성이 요구되는 제품에 장착되는 경우라면, 상기 SoC 또는 SiP는 일부 기능 컴포넌트에 대한 스페어(spare)를 추가로 포함해야 할 수 있다. 만약 일부 기능 컴포넌트에 결함이 있다면, 해 당 기능 컴포넌트를 대신하여 스페어가 동작될 수 있다. 그러나 일부 기능 컴포넌트에 대한 중복적인 배치는, 반도체 면적을 증가시키는 요인이 될 수 있다. 이러한 문제점을 해결하기 위하여, SoC 또는 SiP 내에 프로그래 밍 가능한 로직을 추가하는 것이 효과적일 수 있다. III. SoC 또는 SiP 구동중에 기능 테스트 또는 기능들의 조합에 대한 테스트 도 17은 랜덤 번호 생성기를 이용하여 기능 테스트를 수행하는 과정을 나타낸 예시도이다. 기능 테스트는 테스트 입력 데이터(예컨대, 텍스트 벡터)를 CUT에 주입하고, CUT로부터의 출력이 의도된 출력과 일치하는지를 비교하는 테스트이다. 상기 비교에 기초하여 올바르게 평가하기 위하여, 각 입력 데이터는 의도된 출력을 정확하게 유도할 수 있어야 한다. 상기 테스트 입력 데이터는 모든 결함이 검출될 수 있도록, 테스트 범위가 높아야 한다. 특정한 설계에서, 기능 테스트를 위해 2가지의 테스트 입력 데이터가 존재할 수 있다. 첫 째로, XOR 연산과 연 결된 랜덤 번호 생성기는 도 17에 도시된 테스트 동작을 위하여 사용될 수 있다. 일반적으로, 랜덤 번호 생성기 는 입력 시드(seed)에 기초하여 슈도(pseudo) 랜덤 번호 스트림을 생성할 수 있다. 상기 랜덤 번호 스트림은 상 기 래퍼를 통해 상기 CUT로 주입되고, 출력은 XOR 연산을 통해 테스트 결과 레지스터에 누적하여 저장된다. 테 스트가 완료되면, 상기 테스트 결과 레지스터에 저장된 값들은 상기 테스트 입력 데이터에 대응하는 의도된 결 과와 비교될 수 있다. 만약 상기 비교 결과 차이가 있다면, 에러가 통지된다. 두번째로, 테스트 입력 데이터를 위한 모든 테스트 패턴과 그리고 대응하는 예측 결과가 각기 고정되고, 상기 SoC 또는 SiP 내의 내부 메모리 혹은 외부 메모리에 저장될 수 있다. 상기 메모리로부터의 테스트 입력 데이터 (즉, 테스트 벡터)가 CUT로 입력되면, 상기 CUT로부터의 출력과 그리고 상기 테스트 입력 데이터에 대응하는 의 도된 결과가 서로 비교될 수 있다. SoC 또는 SiP의 구동 중에 기능 테스트를 수행하기 위하여, ICT는 데이터를 전송하고, 시스템 버스와 통신하고 그리고 CUT의 상태를 모니터링하는 중요한 역할을 수행한다. 특히, ICT는 해당 CUT가 유휴 상태인 경우 언제 테 스트를 수행해야 하는지를 결정할 수 있다. 테스트 과정 중에, 랜덤 번호 생성기는 테스트 입력 데이터로서 랜 덤 번호 스트림을 생성하고, 상기 테스트 입력 데이터를 상기 CUT로 전송한다. 만약 테스트 결과와 의도된 테스 트 결과 간에 차이가 있다면, ICT는 해당 정보를 상기 후 동작 수행기로 전송한다. 기능 테스트는 SoC 내의 기능 컴포넌트들을 사용할 수 있기 때문에, 일반적으로 테스트 동작을 위한 주파수는 일반 동작을 위한 주파수 보다 낮거나 같아야만, 타이밍이 달라지는 것(즉, 타이밍 위반)을 피할 수 있다. 일반 동작 중에, 테스트를 실시간으로 하기 위하여, 테스트를 해당 기능 컴포넌트가 유휴 상태일 때 수행하는 것이 효과적이다. 따라서, 어쩔 수 없이 높은 주파수로 테스트가 수행될 수 있다. IV. DFT(discrete Fourier transform)와 ICT의 조합을 이용한 SoC 또는 SiP 의 구동중(runtime) 테스트 IV-1. 다중 클럭 도 18a는 다중 클럭의 예시를 나타내고, 도 18b는 다중 클럭 하에서 테스터의 동작을 나타낸 예시도이고, 도 18c는 테스트 입력 데이터의 경로를 나타낸다. 테스트 수행 도중, 하나의 테스트 입력 데이터(즉, 테스트 벡터)를 주입하는 것과 관련하여, 2가지의 기법이 존 재할 수 있다. 첫 번째 기법은 도 18a에 도시된 \"데이터를 쉬프트하는\" 시간 구간을 이용하는 것이다. SE(scan enable) 포트가 인에이블되고, 플리-플롭(flip-flop)의 출력 Q가 다른 플리-플롭의 입력 D로 연결되는 것이다. 이러한 연결은 플리-플롭들의 체인을 통하여 스캔 입력을 스캔 출력으로 연결하는 스캔 체인을 만들 수 있다. 따라서, 설계된 모든 결합 로직(combinational logic)은 디스에이블될 수 있고, 데이터 경로(즉, 플리-플롭으로 부터 다른 플리-플롭으로의 경로)에 대한 기준 로직 셀이 존재하지 않을 수 있다. Tcycle 을 클럭 구간이라고 정의하고, Tlaunch를 제1 플리-플롭의 클럭 소스로부터 CK 핀으로의 시간 지연이라 정의 하고, Tcapture를 클럭 소스로부터 제2 플리-플롭의 CP 핀으로의 시간 지연이라고 정의하고, Tclk2q를 제1 플리-플 롭의 CK로부터 Q 핀으로의 시간 지연이라고 정의하고, Tdpmax를 제1 플리-플롭의 Q로부터 제2 플리-플롭의 D으로 의 시간 지연이라고 정의 할 때, Tcycle > Tlaunch + Tclk2q + Tdpmax + Tsetup + Tmargin - Tcapture일 수 있다. 스캔 테스트가 인에이블되었을 때, 스캔 테스트의 관점에서 Tdpmax는 0으로 줄어줄 수 있다. 이상적으로 Tdpmax는 0 일 수 있다. 그러나, 타이밍 위반을 해결하기 위하여, 여러 인버터 또는 버퍼가 추가되는 경우 시간 지연은 0 보다 클 수 있다. 대안적으로, Tdpmax >> Tclk2q + Tsetup + Tlaunch - Tcapture 일 수 있다. \"데이터를 쉬프트 하는\" 시간 구간 동안에는 더 높은 주파수로 처리될 수 있다. 도 18a에 도시된 \"데이터를 캡쳐하는\" 시간 구간 동안에는 스캔 인에이블 핀이 비활성화되고, 그로 인해 기능 컴포넌트는 다시 활성화되고, 데이터 경로 상에서 결합 로직(combinational logic)이 활성화될 수 있다. 데이터 를 캡쳐하는 동안 시간 타이밍의 위반을 해소하기 위하여, \"데이터를 쉬프트하는\" 시간 구간에서 일단에 위치한클럭과 \"데이터를 캡쳐하는\" 시간 구간에서의 일단에 위치한 클럭 간에 시간 지연이 추가될 수 있다. 이러한 일단들의 클럭들 간에 지연은 일반 동작을 위한 클럭 사이클과 같거나 혹은 더 길 수 있다. 쉬프트되는 값에 해당하는 스캔 체인 상에서의 플리-플롭의 최대 개수에 기초하여, \"데이터를 쉬프트 하는\" 시간 구간이 언 제 완료되는지를 검출하기 위하여 카운터를 추가할 수 있고, \"데이터를 캡쳐하는\" 시간 구간에서의 시간 지연을 관리하기 위하여 또 다른 카운터를 추가할 수 있다. 도 18b에서 테스트 블록은 2개의 입력 클럭을 수신한다. 하나는 일반 동작을 위해서 사용되는 f_clk이고, 다른 하나는 \"데이터를 쉬프트\"하기 위한 sclk일 수 있다. 상기 테스터 블록 내에 \"클럭 설정기(clock configuration)\"를 삽입함으로써, s_clk 신호가 상기 \"데이터를 쉬프트하는\" 구간 및 \"데이터를 캡쳐하는\" 구간 모두에서 사용될 수 있도록 설정될 수 있다. 일반 동작을 위한 f_clk와 테스트 동작을 위한 s_clk 간에 스위칭을 제어하기 위하여, CUT에 대응하는 TE 시그 널이 사용될 수 있다. ICT 내의 테스트 블록은 스케줄러로부터 컴포넌트의 ID(즉 C_ID)를 수신하면, 테스트를 수행할 준비가 된다. 디코더를 통하여 이용가능한, CUT들의 TE들이 테스트 프로세스를 인에블시킬 수 있다. 도 19a 및 도 19b는 기능 컴포넌트의 예시를 나타내고, 도 19b는 ICT 내의 테스터로 테스트 입력 데이터(예컨대, 테스트 벡터)가 주입되는 예를 나타낸다. SoC 또는 SiP 구동 중 테스트에서 DFT(discrete Fourier transform)를 적용하기 위해서, CUT 내에는 스캔 체인 (scan chain)이 추가되고, 스캔 플리-플롭에 의해서 모든 플립-플롭들이 둘러쌓여질 수 있다. 스캔 입력, 스캔 출력 그리고 TEST_ENABLE 및 SCAN_ENABLE 시그널링은 ICT 내의 테스터로 연결되고, CUT의 원래 입력 및 원래의 출력은 테스터와 그리고 래퍼를 통하여 시스템 버스와 통신할 수 있다. 도 19b에 도시된 바와 같이 테스터 패턴을 저장하는 메모리의 관점에서, 블록은 4개의 부분들로 나뉠 수 있다. 첫 번째 부분은 입력 쉬프트 벡터를 저장하는 부분이고, 두 번째 부분은 출력 쉬프트 벡터를 저장하는 부분이고, 세번째 부분은 입력 켑쳐 벡터를 저장하기 위한 부분이고, 네 번째 부분은 출력 캡쳐 벡터를 저장하 는 부분이다. 테스트를 시작하기 위하여, 입력 쉬프트 데이터는 메모리로부터 로딩되어 테스터를 통하여 CUT로 입력된다. 각 스캔 체언에서 모든 플리-폴롭이 쉬프트 벡터로 채워진 후, 스캔 입력과 초기 입력을 위한 값을 포함하는 제 1 입력 캡쳐 벡터가 로딩되면, 모든 스캔 출력과 초기 출력을 위한 값들을 포함하는 제1 출력 캡쳐 벡터가 로딩 되고, 이어서 실제 출력 캡쳐 데이터와 비교될 수 있다. 로딩된 각 쉬프트 벡터는 출력 쉬프트 데이터를 수반하 고, 실제 출력 데이터와 출력 쉬프트 벡터 또는 출력 캡쳐 벡터 간에 비교가 수행될 수 있다. 도 20은 DFT를 이용한 테스트 과정을 나타내고, 도 21은 테스트 과정 동안에 쉬프트 데이터 및 캡쳐 데이터의 예를 나타낸다. 데이터를 쉬프트하는 단계에서, scan_enable 포트가 인에이블 되면, 결합 로직(combinational logic) 없이, 플 리-플롭들을 통하여 SCAN_IN 포트가 SCAN_OUT 포트와 연결될 수 있다. 모든 플리-폴롭들이 상기 입력 쉬프트 벡 터로부터 쉬프트된 값들을 갖게 되기 까지, 입력 쉬프트 벡터는 모든 스캔 체인에 로딩될 수 있다. 각 클럭 사 이클에서 하나의 쉬프트 값이 하나의 플리-플롭을 통과할 수 있다(즉, 이전 플리-폴립의 D 핀은 다음 플리-플롭 의 D 핀으로 연결될 수 있다. 캡쳐링 단계에서, scan_enable 포트가 디스이에블되면, 모든 플리-폴롭들의 D 핀들이 이전 플리-폴롭의 Q 핀들 과 연결되지 않고, 직접 결합 로직으로 연결될 수 있다. 캡쳐 벡터 출력이 양극(+) 클럭 에지에서 결합 로직을 통하여 모든 플리-플롭들의 Q 출력으로 로딩될 수 있다. 데이터 전달 과정은 첫 번째 데이터 캡쳐 단계에서, 출력 데이터를 의도된 출력 데이터와 비교하기 위하여 준비 되고, 이후 매 양극(positive)의 클럭 에지에서 비교가 수행된다. 모든 테스트 벡터 입력들이 로딩되고, 과정은 제1 데이터 쉬프트 단계로 회기되고, 각 과정이 다시 시작된다. 도 21에서는 쉬프트 및 캡쳐 과정을 나타낸다. 도 21에 도시된 네모 상자는 플리-플롭을 나타내고, 각 스캔 체 인에서 모든 플리-플롭들이 데이터 쉬프트 단계의 마지막에 모두 채워지는 것이 나타나 있다. 도 22는 테스트 모드에서 일반 동작 모드로 전환하는 예를 나타낸다. 도 22를 참조하여 알 수 있는 바와 같이, 출력 테스트 모드 동안에 데이터 쉬프트 과정과 캡쳐 단계가 반복될 수 있다. 만약 해당 CUT에 대해 액세스가 발생하게 되면, 해당 CUT를 일반 동작 모드로 복구하고, 테스트는 백-오프될 수 있다. 이후 일정 시간 구간 동안 스킵 모드가 진행되고, 그 이후 다시 출력 테스트 모드가 진행될 수 있다. 도 23은 플리-플롭들이 스캔 체인 상에서 동작되는 예를 나타내고, 도 24는 일반 동작 모드로 동작 하는 CUT의 일부를 나타낸다. 시스템 버스로부터 CUT에 대한 예기치 않은 액세스가 발생하는 경우, TEST_ENABLE는 디스에이블 되고, 데이터의 쉬프팅 또는 캡쳐링은 빠르게 중단될 수 있다. 그리고, CUT는 일반 동작 모드로 복구되고, 테스트는 백-오프될 수 있다. 상기 CUT가 다시 유휴 상태로 진입하면, 테스트를 위해 이전의 데이터 쉬프트 단계가 다시 시작될 수 있다. 그 러나 일반 동작 모드로부터 테스트 동작 모드로 전환된 이후 첫 번째 쉬프트 단계에서는, 출력 결과의 비교는 비활성화되고, 다음번 캡쳐링 단계부터 출력 결과의 비교가 수행될 수 있다. 즉, 도 23에 도시된 바와 같이 스캔 체인에서 모든 플리-플롭들에는 쉬프트된 입력 값들이 로딩되지 않으며, 비 교는 수행되지 않을 수 있다. V. 시뮬레이션 전술한 내용에 대해서 검증하기 위하여, Synopsys 사의 전자 설계 자동화 툴을 이용하여 부 케이스들에 대해서 간단한 것 부터 복잡한 것까지 시뮬레이션을 수행하였다. 검증이 성공적으로 수행되면, 소프트웨어 코드로 구현 된 디자인은 논리 게이트로 변환될 수 있을 것이다. 다음 단계로서, 모든 DFF(D-flip-flop)들은 스캔 플리-플롭 으로 대체될 수 있고, 스캔 체인들이 생성될 수 있다. 테스트가 커버하는 범위를 높히기 위하여 netlist는 반복 적으로 수정되고, 검사될 수 있다. ATPG 툴은 테스트 벡터와 그리고 의도된 결과를 생성하는데 사용될 수 있다. Netlist가 삽입된 스캔 및 테스트 패턴이 준비되면, ICT가 설계에 적용될 수 있다. 각 테스트 케이스에 대한 세 부 내용은 도면을 참조하여 설명하기로 한다. 도 25는 시뮬레이션을 위한 과정을 나타낸 예시도이다. --------도시된 시뮬레이션 과정은 Synopsys 사의 설계 컴파일러 툴을 이용한 것이다. --라이브러리 패키지 내 에 포함된 구간, 전환, 정전용량, 타이밍 정보 등과 같은 타이밍 제약에 기반하여, DC (design compiler) 툴이 소프트웨어 코드를 논리 게이트 수준으로 변환하는데 이용될 수 있다 모든 제약이 충족될 때 가지 최적화가 반 복적으로 수행될 수 있다. 만약 설계가 요구 사항을 만족시키지 못하는 경우, 제약 사항은 조정될 수 있다. 전술한 타이밍 제약을 포함하는 DC 툴의 출력은 DFT(design for test)의 입력으로 사용될 수 있다. 스캔 테스트 주입 단계에서, 스캔 포트의 개수 및 스캔 체인이 세팅될 수 있다. 일반적으로 설계시 추가적인 포 트를 최소화하기 위하여, 원래의 입력과 출력 포트를 사용하여 스캔 포트를 생성할 수 있다. 게다가, 입력 스캔 포트의 개수는 스캔 체인의 개수와 동일하고, 스캔 체인의 개수가 증가할 수록, 데이터를 쉬프트하기 위한 쉬프 트 컬럭 사이클의 개수는 줄어들 수 있다. 따라서 스캔 체인의 개수를 최대화하는 것이 테스트를 위한 최선의 선택일 수 있다. 스캔 세팅이 완료되면, DFT 컴파일러가 모든 플리-플롭들을 스캔을 위한 플리-플롭들로 대체시 킬 수 있고, 스캔 입력(scan_in) 핀과, 스캔 출력(scan_out) 핀을 서로 연결함으로써, 스캔 체인을 생성할 수 있다. 추가적인 연결과 스캔 플리-플롭들은 설계가 더 복잡하게 되도록 하고, 데이터 경로 대부분에서 시간 지 연을 야기하기 때문에, DFT 컴파일러는 스캔 체인들이 연결된 이후에 파워 및 타이밍을 계속하여 최적화할 수 있다. 스캔 테스트 주입이 완료된 다음에, DFT 규칙을 따르는 DFT DRC는 모든 테스트 연결들이 연결되어 있는지 를 확인한다. 테스트 입력 데이터(즉, 테스트 벡터)가 준비 완료된다. 테스트 범위를 확인하기 위하여 그리고 테스트 패턴을 생성하기 위하여 DFT 컴파일러의 출력은 Synopsys 사의 Tetramax로 입력된다. 테스트 범위가 의도된 요구 사항에 미치지 못하는 경우, 설계를 수정하기 위하여 스캔 테 스트 주입 단계가 다시 수행될 수 있다. 이 작업은 원하는 테스트 범위를 얻을 때 까지 반복될 수 있다. V-1. 설계에 대한 실험 설계에 대한 실험으로서, JPEG 이미지 인코더가 사용될 수 있다. 이 테스트는 약 265118개의 결합 셀, 72345개 의 순차적 셀 그리고 31439 개의 인버터/버퍼 셀을 사용할 수 있다. 셀 라이브러리 정보에 기초하여, 그리고 많 은 임계 값들을 기초로 수행해본 결과, 타이밍 제약을 충족하는 주파수는 100 MHz인 것으로 확인되었고, 테스트 페턴을 쉬프트하기 위한 주파수는 1 GHz인 것이 확인되었다. 약 512개의 스캔 체인이 사용되고, 각 스캔 체인에 서 플리-플롭들의 개수는 최대 75개가 사용되었다. 따라서 테스트 패턴을 쉬프트하기 위해서 사용되는 시간 구간은 75 ns에 해당하는 약 75 싸이클로 확인되었다. 데이터를 캡쳐링하는 데에는 1개의 사이클이 소모되고, 이 는 약 10ns에 해당한다. 약 256 테스트 패턴이 입력되고, 각 테스트 패턴은 쉬프팅을 위해서 약 75 개의 테스트 벡터를 포함하고, 캡쳐링을 위해서 약 1개의 테스트 벡터가 사용될 수 있다. 1개의 테스트 구간을 완료하기 위 해서 13260 (156*75 + 156*10) ns이 걸리게 되었다. 도 26은 JPEG 이미지 인코더를 위한 테스트 아키텍처를 나타낸다. 전술한 바와 같이 제어가능한 그리고 관측가능한 노드들의 비율이 테스트를 위해서 충분한지 확인하기 위하여 Tetramax가 테스트 범위 범위를 확인하기 위해서 사용되었다. 일반적으로, 테스트를 위하여, 99.97%의 테스트 범위 및 1483.5 킬로 바이트(K bytes)가 이 테스트를 위해서 사용되었다. 파워 소모 관점에서, 각 테스트는 다른 종류의 입력들로 측정되었다. 하기의 표 1은 각 입력에 대한 내부 파워, 스위칭 파워 그리고 누설되는 파워를 각기 나타낸다. 특히, 테스트 모드 및 일반 모드에 대해서 제어 불가능한 입력들이 먼저 구현되었다. 이를 정적 파워 측정이라고 한다. 파워 컴파일러 툴로 입력된 후, 테스트 모드에서 파워 소모를 추정하기 위하여 TE (test_enable) 포트가 턴온되고, 일반 동작 모드의 파워 소모를 추정하기 위해 서 TE (test_enable) 포트가 턴 오프되었다. 두 번째로, 파워 소모를 추정하기 위하여 특정한 시간 간격으로 입 력들을 제어하였다. 이를 동적 파워 추정이라고 한다. 입력들을 제어하는 것은 3개로 구분될 수 있다. 첫 째로, 테스트 모드가 턴-온되고, 테스트 패턴이 제공된다. 둘째로, 테스트 모드가 턴-오프되고, 일반 동작을 위한 입 력이 제공된다. 세번 째로 각 테스트 패턴에 대한 테스트가 완료된 이후, 일반 동작 모드로 전환된다. 이들에 대한 전력 소모치를 얻기 이하여, 테스트 모드 및 일반 동작 모드 간에 스위칭이 수행된다. 아래의 표는 JPEG 이미지 인코더의 파워 소모치이다. 표 1 파워 소모의 타입 Uncontrollable input Control input (114360 ns) 테스트 모드일반 동작 모드테스트 모드 일반 동작 모드Switch_F_S 스위칭 파워 (mw) 265.4368 3.4659 945.5015 76.6824 622.9294 내부(Internal) 파워 (mw)487.6708 2.9630 1.5978e+03109.4660 1.0651e+03 누설(Leakage) 파워 (mw)4.05 4.0645 4.0479 4.058 4.0502 전체 파워 (mw) 757.1588 10.4934 2.5474e+03190.2058 1.6921e+03 JPEG 이미지 인코더와 유사하게, AES(Advanced Encryption Standard)를 위한 기능 컴포넌트에 대해서 테스트를 수행하였다. 또한, 자율 주행 차에서 이미지 분류를 위한 기능 컴포넌트에 대해서도 테스트를 수행하였다. 아래 는 그 결과를 나타낸다.아래의 표 2는 AES 설계를 나타낸다. 표 2 결합 셀(combinational cell)의 개수 160261 순차 셀의 개수 11701 버퍼/인버터의 개수 22377 전체 영역 400464.797234 일반 동작 모드의 주파수 100Mhz 테스트 모드의 주파수 1 Ghz Tshift 46ns Tcapture 10ns 테스트 패턴의 개수 315 테스트의 범위 100 % 메모리 사이즈 948.5 KBytes 아래의 표 3은 AES를 위한 기능 컴포넌트에 대한 테스트를 나타낸다. 표 3 파워 추정치 (mW)No control input Control input (402ns) 일반 동작 모드 & 테스트 모드 스캔 모드 일반 동작 모드스캔 모드 일반 동작 모드 스위칭 파워 59.7507 23.0733 213.8727 1.7887 135.5754 내부 파워 106.2405 32.7560 307.6255 2.6223 192.9561 누설 파워 1.3456 1.3455 1.3456 1.3516 1.3459 전체 파워 167.3375 57.1769 522.8372 5.7625 329.8691 아래의 표 4는 CONVO2에 대한 세부 내용이다. 표 4 결합 셀(combinational cell)의 개수 2245932 순차 셀의 개수 424695 버퍼/인버터의 개수 154510 일반 동작 모드의 주파수 50Mhz 테스트 모드의 주파수 1 Ghz Tshift 829ns Tcapture 20ns 테스트 패턴의 개수 183 테스트의 범위 100 % 메모리 사이즈 18.634 Mbytes 아래의 표 5는 CONVO2에 대한 파워 소모를 나타낸다. 표 5 파워 추정치 (mW)No control input 모드 스캔 모드 일반 동작 모드 스위칭 파워 3721.1 390.9510 내부 파워 5759.5 633.5883 누설 파워 0.427 0.426 전체 파워 9540.8 1070 기능 테스트와 스캔 주입을 통한 테스트는 각기 장단점이 있다. 스캔 주입을 통한 테스트는 기능 테스트에 비해 서 더 많은 메모리를 사용하고, 시간이 지연되는 단점이 있지만, 테스트의 범위가 더 넓다는 장점이 있다. 특히, SoC 또는 SiP가 자율 주행 자동차, 드론(Drone), UAM(Urban Air Mobility), UAV(unmanned aerial vehicle)와 같이 높은 신뢰도를 요구하는 제품에 장착될 경우, 테스트 범위가 넓은 스캔 주입 방식의 테스트가 유리하다. 또한, 스캔 주입 방식의 테스는, 테스트 동작을 위한 주파수를 높일 수 있고, 이는 테스트 시간을 줄 일 수 있도록 한다. 테스트하는데 오랜 시간이 걸릴 경우, 자동차 사고의 가능성을 그만큼 높일 수 있기 때문에, 바람직하지 않다. 스캔 주입 방식의 테스트는 테스트 동작을 위한 주파수를 높일 수 있기 때문에, 유휴 시간 동안에 더 많은 테스트 패턴을 주입시킬 수 있고, SoC 또는 SiP 내의 하드웨어 결함이 더 빨리 검출될 수 있도록 한다. 물론, 일반적인 기능 테스트는 전력 소모가 더 적은 장점은 있지만, 자율 주행 자동차, 드론 (Drone), UAM(Urban Air Mobility), UAV(unmanned aerial vehicle)와 같이 높은 신뢰도가 요구되는 환경에서는 전력 소모량은 중요 사항이 아닐 수 있다. 지금까지는 SoC를 위주로 설명되지만, 본 명세서의 개시는 SoC에만 한정되는 것은 아니며, 본 개시의 내용은 SIP(System in Package) 혹은 PCB(Printed circuit board) 기반 보드 레벨 시스템에도 적용될 수 있다. 예를 들어, 각 기능 컴포넌트는 독립 반도체 칩으로 구현되고, PCB 상에 형성된 전기 전도성 패턴(electrically conductive pattern)에 의해서 구현되는 시스템 버스를 통해 서로 연결되는 형태로 구현될 수 있다. 본 명세서와 도면에 나타난 본 개시의 예시들은 본 개시의 기술 내용을 쉽게 설명하고 본 개시의 이해를 돕기 위해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 지금까지 설명한 예시들 이외 에도 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명 한 것이다."}
{"patent_id": "10-2021-0181081", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 신경망 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 2는 본 개시에 적용될 수 있는 프로세싱 엘리먼트 어레이 중 하나의 프로세싱 엘리먼트를 설명하는 개략적인 개념도이다. 도 3은 도 1에 도시된 신경망 프로세싱 유닛의 변형예를 나타낸 예시도이다. 도 4는 예시적인 인공신경망모델을 설명하는 개략적인 개념도이다. 도 5a은 컨볼루션 신경망의 기본 구조를 설명하기 위한 도면이다. 도 5b는 컨볼루션 신경망의 동작을 이해하기 쉽게 나타낸 종합도이다. 도 6은 도 1 또는 도 3에 도시된 NPU를 포함하는 SoC(system on chip)의 예시적인 아키텍처를 나타낸 예시도이 다. 도 7은 플리-플롭을 스캔하는 예를 나타낸다. 도 8은 하드웨어 설계 내에 스캔 테스트를 위한 아키텍처가 추가된 에를 나타낸다. 도 9a는 도 6에 도시된 SoC를 동작 관점에서 간략하게 나타낸 예시도이다. 도 9b는 NPU에 대한 테스트를 수행하기 위한 구성을 나타낸 예시도이다. 도 10은 래퍼의 동작을 나타낸 예시도이다.도 11은 ICT의 내부 구성을 나타낸 예시도이다. 도 12는 ICT가 기능 컴포넌트가 유휴 상태인지를 모니터링하는 동작을 상세하게 나타낸 블록도이다. 도 13은 시스템 버스 상에서 동작하는 마스터(master), 슬래이브(slave), 아비터(arbiter) 간에 동작을 나타낸 예시도이다. 도 14는 SoC 칩 내에 쉬프트 레지스터가 추가된 예를 나타낸다. 도 15는 ICT의 동작 순서를 나타낸 예시도이다. 도 16은 내부 메모리에 대한 테스트 과정을 이해하기 쉽게 나타낸 블록도이다. 도 17은 랜덤 번호 생성기를 이용하여 기능 테스트를 수행하는 과정을 나타낸 예시도이다. 도 18a는 다중 클럭의 예시를 나타내고, 도 18b는 다중 클럭 하에서 테스터의 동작을 나타낸 예시도이고, 도 18c는 테스트 입력 데이터의 경로를 나타낸다. 도 19a 및 도 19b는 기능 컴포넌트의 예시를 나타내고, 도 19b는 ICT 내의 테스터로 테스트 입력 데이터(예컨대, 테스트 벡터)가 주입되는 예를 나타낸다. 도 20은 DFT를 이용한 테스트 과정을 나타낸다. 도 21은 테스트 과정 동안에 쉬프트 데이터 및 캡쳐 데이터의 예를 나타낸다. 도 22는 테스트 모드에서 일반 동작 모드로 전환하는 예를 나타낸다. 도 23은 플리-플롭들이 스캔 체인 상에서 동작되는 예를 나타낸다. 도 24는 일반 동작 모드로 동작 하는 CUT의 일부를 나타낸다. 도 25는 시뮬레이션을 위한 과정을 나타낸 예시도이다. 도 26은 JPEG 이미지 인코더를 위한 테스트 아키텍처를 나타낸다."}
