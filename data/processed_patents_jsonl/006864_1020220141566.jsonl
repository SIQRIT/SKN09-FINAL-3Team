{"patent_id": "10-2022-0141566", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0062440", "출원번호": "10-2022-0141566", "발명의 명칭": "인공 지능", "출원인": "루먼랩 주식회사", "발명자": "임재현"}}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 기반의 영상 분석을 통한 영유아 발달 관리 시스템에 있어서, 영유아의 보호자가 애플리케이션을 이용하여 상기 영유아의 행동영상을 촬영하도록 하는 영상 촬영부; 상기 행동영상을 기반으로 딥러닝 모델 훈련을 위한 훈련 데이터를 생성하는 영상 전처리부; 상기 생성된 훈련 데이터 세트를 이용하여 상기 행동영상의 공간적 특성 및 시간적 특성을 분석하고, 상기 분석결과에 따라 상기 영유아의 발달장애 또는 발달지연 여부를 예측하는 AI 모델부; 상기 AI 모델부의 예측 결과를 이용하여, 상기 행동영상에 대한 발달장애 및 발달지연 예측의 결과값을 산출하는 예측값 처리부; 및 상기 예측값 처리부로부터 산출된 결과값에 기반하여, 예측 결과 그래프를 생성하여 상기 애플리케이션을 통해출력하는 결과부;를 포함하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 영상 촬영부는, 상기 애플리케이션을 통해 상기 영유아의 특정 신체부위의 목표 행동이 촬영되도록 하기 위한 행동 가이드라인을 표시하는, 촬영 가이드부를 포함하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 영상 촬영부는, 상기 애플리케이션을 통해 지정된 사용자로 상기 행동영상을 실시간으로 전송하고, 상기 사용자로부터 상기 행동영상에 대한 피드백을 수신하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 촬영 가이드부는, 상기 수신된 피드백을 음성 또는 문자 데이터의 형태로 상기 행동영상과 함께 출력하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 영상 전처리부는, 상기 영상 촬영부에서 촬영된 영상에서 상기 영유아의 안면을 비식별화 처리하고, 상기 비식별화 처리된 영상을 지정된 길이, 시작/종료 시간, 또는 프레임 개수에 따른 청크로 추출하는, 영유아발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 공개특허 10-2023-0062440-3-상기 영상 전처리부는, 상기 영상에서 상기 영유아의 신체 영역을 추출하고, 외부 사용자로부터 신체부위 각각에서의 행동에 대한 발달상태를 확인하고, 상기 추출된 청크에 상기 확인된 발달상태를 반영하여 상기 훈련 데이터로 생성하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 AI 모델부는, 상기 훈련 데이터를 이용하여, 상기 행동영상의 발달상태를 예측하기 위한 딥러닝 모델을 생성하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 AI 모델부는, 상기 영상의 신체부위를 추출하여 정형 데이터로 변환하고, 상기 영상에서 상기 정형 데이터 외의 비정형 데이터를 확인하며, 상기 추출된 청크의 시계열 특성을 반영하고, 상기 정형 데이터 및 상기 비정형 영상 데이터의 공간적 및 시간적 특성을 학습하도록 상기 딥러닝 모델을 설계하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 예측값 처리부는, 상기 설계된 딥러닝 모델을 이용하여 상기 행동영상에 대한 예측을 수행하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 결과부는, 상기 산출된 예측 결과 그래프 또는 상기 예측의 결과값을 상기 영유아 발달 관리 시스템의 데이터베이스에 저장하는, 영유아 발달 관리 시스템."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영유아 발달 관리 시스템에서 인공 지능 기반의 영상 분석을 수행하는 영유아 발달 관리 방법에 있어서, 영상 촬영부에 의해, 영유아의 보호자가 애플리케이션을 이용하여 상기 영유아의 행동영상을 촬영하는 동작; 영상 전처리부에 의해, 상기 행동영상을 기반으로 딥러닝 모델 훈련을 위한 훈련 데이터를 생성하는 동작; AI 모델부에 의해, 상기 생성된 훈련 데이터 세트를 이용하여 상기 행동영상의 공간적 특성 및 시간적 특성을분석하고, 상기 분석 결과에 따라 상기 영유아의 발달장애 또는 발달지연 여부를 예측하는 동작; 예측값 처리부에 의해, 상기 AI 모델부의 예측 결과를 이용하여, 상기 행동영상에 대한 발달장애 및 발달지연예측의 결과값을 산출하는 동작; 및 결과부에 의해, 상기 예측값 처리부로부터 산출된 결과값에 기반하여, 예측 결과 그래프를 생성하여 상기 애플리케이션을 통해 출력하는 동작;을 포함하는, 영유아 발달 관리 방법."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2023-0062440-4-제11항에 있어서, 상기 애플리케이션을 통해 상기 영유아의 특정 신체부위의 목표 행동이 촬영되도록 하기 위한 행동 가이드라인을 표시하는 동작; 및 상기 애플리케이션을 통해 지정된 사용자로 상기 행동영상을 실시간으로 전송하고, 상기 사용자로부터 상기 행동영상에 대한 피드백을 수신하는 동작; 및 상기 수신된 피드백을 음성 또는 문자 데이터의 형태로 상기 행동영상과 함께 출력하는 동작;을 더 포함하는,영유아 발달 관리 방법."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 영상 촬영부에서 촬영된 영상에서 상기 영유아의 안면을 비식별화 처리하는 동작; 상기 비식별화 처리된 영상을 지정된 길이, 시작/종료 시간, 또는 프레임 개수에 따른 청크로 추출하는 동작;및 상기 영상에서 상기 영유아의 신체 영역을 추출하고, 외부 사용자로부터 신체부위 각각에서의 행동에 대한 발달상태를 확인하고, 상기 추출된 청크에 상기 확인된 발달상태를 반영하여 상기 훈련 데이터로 생성하는 동작;을더 포함하는, 영유아 발달 관리 방법."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 훈련 데이터를 이용하여, 상기 행동영상의 발달상태를 예측하기 위한 딥러닝 모델을 생성하는 동작; 상기 영상의 신체부위를 추출하여 정형 데이터로 변환하고, 상기 영상에서 상기 정형 데이터 외의 비정형 데이터를 확인하는 동작; 및 상기 추출된 청크의 시계열 특성을 반영하고, 상기 정형 데이터 및 상기 비정형 영상 데이터의 공간적 및 시간적 특성을 학습하도록 상기 딥러닝 모델을 설계하는 동작;을 더 포함하는, 영유아 발달 관리 방법."}
{"patent_id": "10-2022-0141566", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 설계된 딥러닝 모델을 이용하여 상기 행동영상에 대한 예측을 수행하는 동작; 및 상기 산출된 예측 결과 그래프 또는 상기 예측의 결과값을 상기 영유아 발달 관리 시스템의 데이터베이스에 저장하는 동작;을 더 포함하는, 영유아 발달 관리 방법."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 다양한 실시예에 따른, 인공 지능 기반의 영상 분석을 통한 영유아 발달 관리 시스템은, 영유아의 보 호자가 애플리케이션을 이용하여 상기 영유아의 행동영상을 촬영하도록 하는 영상 촬영부, 상기 행동영상을 기반 으로 딥러닝 모델 훈련을 위한 훈련 데이터를 생성하는 영상 전처리부, 상기 산출된 훈련 데이터 세트를 이용하 여 상기 행동영상의 공간적 특성 및 시간적 특성을 분석하고, 상기 분석 결과에 따라 상기 영유아의 발달장애 또 는 발달지연 여부를 예측하는 AI 모델부, 상기 AI 모델부의 예측 결과를 이용하여, 상기 행동영상에 대한 발달장 애 및 발달지연 예측의 결과값을 산출하는 예측값 처리부 및 상기 예측값 처리부로부터 산출된 결과값에 기반하 여, 예측 결과 그래프를 생성하여 상기 애플리케이션을 통해 출력하는 결과부를 포함할 수 있으며, 그 외 다양한 실시예가 가능할 수 있다."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI 기반의 영상 분석을 통한 영유아 발달장애 및 발달지연을 조기에 예측하고 관리하는 서비스 플랫 폼 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 영유아를 포함한 아동의 발달장애 및 발달지연에 대한 진단 결과는 보호자 및 아동이 아동심리 상 담사와 같은 전문가의 상담을 진행하여 확인할 수 있다. 최근 모바일 기기와 통신기술이 발전함에 따라 보호자가 소유한 모바일 장치 및 기기에서 동영상 촬영을 통해 아동의 행동영상을 수집하는 것이 가능해졌다. 이에 따라 보호자는 스스로 아동의 행동영상을 촬영함과 더불어 메신저 및 애플리케이션 등의 매체를 통해 전문가의 평가를 확인할 수 있다. 그럼에도 불구하고 발달장애 및 발달지연에 대한 전문가의 소견은 오프라인 아동발달센터 혹은 의료기관에서 아 동의 행동을 전문가가 직접 관찰하여야 한다는 문제가 있으며, 해당 분야에서는 여전히 전통적인 검사방식을 고 수하고 있는 상황이다. 또한, 종래의 기술은 보호자가 아동의 발달상태를 전문가와 확인하기 위해 오프라인 아동발달센터를 직접 방문 하여 발달평가 프로토콜(예, Bayley-III, K-DST 등)에서 제시하는 문항을 수행하고 전문가가 이를 관찰하여 판 단을 내리는 것이 일반적이다. 하지만, 보호자는 오프라인 아동발달센터를 방문하기 전 전문가와 일정을 조율해야 하며, 상담 대기기간이 많게 는 수년 이상인 경우가 존재한다. 이러한 문제점을 해결하고자 보호자가 수행할 수 있는 프로토콜 문항을 탑재 한 애플리케이션 및 웹페이지가 등장하고 있으나 아동이 수행하는 행동영상에 대한 분석이나 전문가의 종합적인 판단을 포함되지 않아, 여전히 전문가의 분석 및 소견을 확인할 수 없다는 문제점이 있다."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 모바일 장치 및 기기에서 보호자가 손쉽게 촬영할 수 있는 영유아를 포함한 아동의 행동영상 에 대해 딥러닝 기술을 활용하여 영상 분석을 진행한 후 아동의 발달장애 및 발달지연의 가능성을 실시간으로 예측하여 보호자와 전문가에게 제시할 수 있다."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 문제점을 해결하기 위해 제안된 본 발명의 다양한 실시예에 따른, 인공 지능 기반의 영상 분석을 통한 영유아 발달 관리 시스템은, 영유아의 보호자가 애플리케이션을 이용하여 상기 영유아의 행동영상을 촬영하도록 하는 영상 촬영부, 상기 행동영상을 기반으로 딥러닝 모델 훈련을 위한 훈련 데이터를 생성하는 영상 전처리부, 상기 산출된 훈련 데이터 세트를 이용하여 상기 행동영상의 공간적 특성 및 시간적 특성을 분석하고, 상기 분석 결과에 따라 상기 영유아의 발달장애 또는 발달지연 여부를 예측하는 AI 모델부, 상기 AI 모델부의 예측 결과를 이용하여, 상기 행동영상에 대한 발달장애 및 발달지연 예측의 결과값을 산출하는 예측값 처리부 및 상기 예측 값 처리부로부터 산출된 결과값에 기반하여, 예측 결과 그래프를 생성하여 상기 애플리케이션을 통해 출력하는 결과부를 포함할 수 있다. 또한, 본 발명의 다양한 실시예에 따른, 영유아 발달 관리 시스템에서 인공 지능 기반의 영상 분석을 수행하는 영유아 발달 관리 방법에 있어서, 영상 촬영부에 의해, 영유아의 보호자가 애플리케이션을 이용하여 상기 영유 아의 행동영상을 촬영하는 동작, 영상 전처리부에 의해, 상기 행동영상을 기반으로 딥러닝 모델 훈련을 위한 훈 련 데이터를 생성하는 동작, AI 모델부에 의해, 상기 생성된 훈련 데이터 세트를 이용하여 상기 행동영상의 공 간적 특성 및 시간적 특성을 분석하고, 상기 분석 결과에 따라 상기 영유아의 발달장애 또는 발달지연 여부를 예측하는 동작, 예측값 처리부에 의해, 상기 AI 모델부의 예측 결과를 이용하여, 상기 행동영상에 대한 발달장 애 및 발달지연 예측의 결과값을 산출하는 동작 및 결과부에 의해, 상기 예측값 처리부로부터 산출된 결과값에 기반하여, 예측 결과 그래프를 생성하여 상기 애플리케이션을 통해 출력하는 동작을 포함할 수 있다."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 인공 지능 기반의 영상 분석을 통한 영유아 발달 관리 시스템에서는, 보호자가 촬영한 아동의 행동영상에 대해 딥러닝 기술을 활용하여 영상 분석을 수행하고, 아동의 발달장애 및 발달지연의 가능성을 실시 간으로 예측하며, 예측 결과를 제공함에 따라, 영유아의 발달상태에 대한 전문가의 상담, 치료 지원 및 관리를 실시간으로 제공받을 수 있다."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이에 한정되지 않으며, 다양한 효과에 대해서는 이하에서 각 실시예를 참조하여 상세히 후술 하기로 한다."}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면 에 예시하고 상세하게 설명하고자 한다. 그러나, 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변 경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구성요소들은 상기 용어 들에 의해 한정되지는 않으며, 단지 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예 를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 예를 들어, 'A 및/또는 B'는 'A 또는 B 중 적어도 하나'의 의미로 해석될 수 있다. 또한, '/'는 '및' 또는 '또는'으로 해석될 수 있다. 본 명세서에서 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함 하는 것으로 이해되어야 하고, \"포함한다\" 등의 용어는 설시된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요 소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또한, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수 도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 특히, 본 명세서에서 영상(IMAGE)은, 동영상(VIDEO)를 포함하는 의미로 해석되어야 한다. 도 1은 본 발명의 다양한 실시예에 따른 AI 기반의 영상 분석을 통한 영유아 발달 관리 시스템을 도시한 블록도 이다. 도 1을 참조하면, 영유아 발달 관리 시스템은 영상 촬영부, 영상 전처리부, AI 모델부, 예측값 처리부 및 결과부를 포함할 수 있다. 예컨대, 사용자(예, 아동의 보호자)의 전자 장치에는 상기 영유 아 발달 관리 시스템으로 접속하기 위한 애플리케이션이 설치될 수 있다. 본 발명의 다양한 실시예에 따르면, 보호자가 상기 애플리케이션을 사용하여 아동의 행동영상을 촬영하고 상기 영유아 발달 관리 시스템의 서버에 업로드함에 따라, 영유아 발달 관리 시스템에서는 AI 기반으로 영상을 분석 하여 아동의 발달장애 및 발달지연 가능성을 조기에 예측할 수 있다. 본 발명의 다양한 실시예에 따르면, 상기 영상 촬영부에서는 보호자가 애플리케이션에서 제시하는 발달평 가 프로토콜 기반의 수행과제에 해당하는 아동의 행동영상을 촬영하고, 촬영된 영상이 영유아 발달 관리 시스템 으로 업로드 되도록 제어할 수 있다. 영상 촬영부의 하위 구성에 대한 구체적인 내용은 도 2에서 설명한다. 본 발명의 다양한 실시예에 따르면, 영상 전처리부에서는 영상 촬영부에서 산출된 아동의 행동영상을 기반으로 딥러닝 모델 훈련을 위한 훈련 데이터 세트를 구성할 수 있다. 영상 전처리부의 하위 구성에 대 한 구체적인 내용은 도 5에서 설명한다. 본 발명의 다양한 실시예에 따르면, AI 모델부에서는 영상 전처리부에서 산출된 훈련 데이터 세트를 활용하여 아동의 행동영상의 공간적 특성과 시간적 특성을 분석하여 발달장애 및 발달지연 여부를 예측하는 딥 러닝 모델이 훈련될 수 있다. AI 모델부의 하위 구성에 대한 구체적인 내용은 도 14에서 설명한다. 본 발명의 다양한 실시예에 따르면, 예측값 처리부는 AI 모델부에서 훈련된 딥러닝 모델의 시계열 예 측을 활용하여 예측 결과 그래프를 산출하고, 보호자가 업로드한 아동의 행동영상에 대한 발달장애 및 발달지연 예측의 결과값을 산출할 수 있다. 예측값 처리부의 하위 구성에 대한 내용은 도 17에서 설명한다. 본 발명의 다양한 실시예에 따르면, 결과부는 예측값 처리부에서 산출된 예측 결과 그래프, 예측 결 과값 및 동영상 정보를 영유아 발달 관리 시스템의 데이터베이스로 전송할 수 있다. 예컨대, 결과부는 사 용자가 촬영한 아동 행동영상에 대해 딥러닝 모델의 예측값, 그래프, 임계값 및 예측 보정값 등을 종합적으로 구성한 별도의 데이터를 영유아 발달 관리 시스템의 데이터베이스로 전송하여 데이터베이스화 할 수 있다. 도 2는 본 발명의 다양한 실시예에 따른 영상 촬영부의 구성을 도시한 블록도이다. 도 2를 참조하면, 영상 촬영부는 촬영 가이드부, 동영상 촬영부 및 동영상 검증부를 포함 할 수 있다. 본 발명의 일 실시예에 따르면, 영상 촬영부는 아동심리 상담사 등의 전문가와 관리자가 설정한 언어, 인 지, 대근육, 소근육 행동영상의 촬영과제를 보호자의 아동이 수행하도록 유도하고 보호자가 이를 동영상으로 촬 영하여 애플리케이션을 통해 서버로 업로드하도록 할 수 있다. 본 발명의 다양한 실시예에 따르면, 촬영 가이드부에서는 보호자가 주어진 과제의 방향을 올바르게 이해하 고 아동의 행동영상을 손쉽게 촬영할 수 있도록 동영상 촬영 가이드라인을 제공할 수 있다. 예컨대, 촬영 가이 드부에서는 애플리케이션을 통해 사진 혹은 동영상 형태의 촬영 가이드라인을 보호자에게 제시하여, 보호 자가 가이드라인을 통해 과제를 올바르게 이해함과 더불어 유효한 아동의 행동영상을 촬영하도록 할 수 있다. 본 발명의 다양한 실시예에 따르면, 동영상 촬영부는 보호자가 아동을 촬영할 때, 동영상 내의 등장인물의 현재위치를 나타내어 유효한 동영상을 촬영할 수 있도록 지원할 수 있다. 예컨대, 동영상 촬영부에서는 인 공지능 기반의 인체 검출(human detection) 기술을 적용하여 동영상 내의 등장인물을 검출하고 등장인물의 검출 상태를 표시할 수 있다. 본 발명의 다양한 실시예에 따르면, 동영상 촬영부에서는 기준 위치를 중심으로 동영상의 등장인물의 위치 상태를 나타내는 사각형을 해당 등장인물에 중첩하여 표시할 수 있다. 예컨대, 동영상 촬영부는 기준 위치 에서 제1 거리만큼 치우친 경우 녹색의 사각형을 해당 등장인물에 중첩하여 표시할 수 있다. 이로써, 유효한 아동의 행동영상에 대한 식별력을 제고하고, 동영상을 시청하는 보호 또한, 동영상 촬영부는 상기 사각형을 제1 거리보다 먼 제2 거리에 위치한 등장인물의 경우에는 황색으로 표시하고, 제2 거리보다 멀거나 기준 거리를 초과하여 치우진 등장인물에는 적색으로 표시할 수 있다. 본 발명의 다양한 실시예에 따르면, 동영상 검증부는 촬영이 완료된 동영상에 대해, 중심적중률(Center Fitting Ratio, CFR)을 이용하여 데이터 유효성을 검증할 수 있다. 예컨대, 동영상 검증부는 동영상 촬영 부로부터 산출된 아동의 행동영상에서 등장인물 위치에 따른 사각형의 중심좌표, 높이, 너비 등을 활용하 여 동영상의 유효성을 판단할 수 있다. 이후, 동영상 검증부는 동영상의 유효성 판단 결과에 따라 사용자 의 동영상을 서버에 업로드할 수 있다. 도 3은 본 발명의 제1 실시예에 따라, 영유아 발달 관리 시스템에서 보호자가 과제를 이해하여 유효한 동영상을 촬영하도록 하는 가이드라인을 제공하는 동작을 도시한 도면이다. 도 3을 참조하면, 영유아 발달 관리 시스템에서의 영상 촬영부는 촬영 가이드부를 이용하여 보호자에 게 애플리케이션의 화면 혹은 웹 페이지를 제공하여, 보호자가 유효한 동영상을 촬영하도록 할 수 있다. 본 발명의 제1 실시예에 따르면, S011 동작에서 촬영 가이드부는, 애플리케이션 또는 웹 사이트를 통해 촬 영 전 가이드라인을 제공할 수 있다. 예컨대, 촬영 가이드부는 보호자가 아동의 행동영상 촬영에 앞서 등 장인물이 포함되는 배경의 변인을 최소화하기 위해 촬영 전 가이드라인으로서 무늬가 없는 책상 또는 배경에서 촬영할 것을 제안할 수 있다. 본 발명의 제1 실시예에 따르면, S012 동작에서 촬영 가이드부는, 애플리케이션 또는 웹 사이트를 통해 촬 영 중 가이드라인을 제공할 수 있다. 예컨대, 촬영 가이드부는 보호자가 동영상 촬영을 수행할 때 등장인 물이 촬영기기의 화각을 벗어나지 않도록 유도하기 위해, 등장인물이 화각 내에 있는 경우(좋은예) 및 화각을 벗어난 경우(나쁜예)가 표시되도록 할 수 있다. 본 발명의 제1 실시예에 따르면, S013 동작에서 촬영 가이드부는, 애플리케이션 또는 웹 사이트를 통해, 전문가가 시청하고 평가하기 위한 목표 행동의 특정 신체부위를 촬영하도록 하기 위한 행동 가이드라인을 제공 할 수 있다. 예컨대, 행동 가이드라인에는 특정 신체부위(예, 손, 소근육, 대근육)의 특정 행동(예, “약간 위 에서 촬영해 주세요”, “아이를 따라가며 촬영해요”)을 취할 것을 요청하는 정보가 포함될 수 있다. 본 발명의 제1 실시예에 따르면, 촬영 가이드부는 촬영 중인 아동의 신체부위 형태를 확인하고, 목표 행동 에 해당하는 표시를 촬영 중인 영상에서 해당 신체부위 상에 실시간으로 표시할 수 있다. 예컨대, 촬영 가이드 부는 상기 표시가 행동영상에서 아동의 움직임에 따라 이동하도록 제어하고, 아동의 행동이 표시에서 벗어 난 정도에 따라 상기 표시를 다양한 색으로 표시할 수 있다. 본 발명의 제1 실시예에 따르면, 상기 표시는 각 신체부위의 형태로 행동영상에서 해당 신체부위에 중첩되어 표 시될 수 있으며, 애플리케이션의 사용자(예, 보호자 또는 전문가)가 특정 신체부위에 해당하는 표시를 선택함에 따라 선택된 표시에 대응하는 신체부위가 확대되어 표시될 수 있다. 본 발명의 제1 실시예에 따르면, 영상 촬영부는 촬영 중인 아동의 행동영상을 지정된 사용자와 공유하도록 제어할 수 있다. 예컨대, 상기 애플리케이션은 아동의 보호자와 더불어 전문가에 의해 접속될 수 있다. 본 발명의 제1 실시예에 따르면, 촬영 가이드부는 행동영상이 촬영 중인 경우, 상기 전문가의 전자 장치에 설치된 애플리케이션으로 상기 촬영 중인 행동영상의 위치 정보(예, 링크, URL(uniform resource locator), 웹 주소)를 전송할 수 있다. 이후, 전문가가 상기 전송된 위치 정보를 선택함에 따라, 전문가의 전자 장치에서는 애플리케이션을 통해 촬영 중인 행동영상이 표시될 수 있다. 본 발명의 제1 실시예에 따르면, 전문가가 행동영상을 시청하면서 음성 또는 문자 데이터를 입력하면, 촬영 가 이드부는 보호자의 전자 장치에 설치된 애플리케이션을 통해 전문가의 음성 또는 문자 데이터를 수신할 수 있다. 이후, 보호자의 전자 장치에서는 촬영되는 행동영상이 표시됨과 동시에 전문가의 음성 또는 문자 데이터 가 실시간으로 출력될 수 있다. 본 발명의 제1 실시예에 따르면, 보호자는 애플리케이션을 통해 아동의 행동영상을 촬영하면서 촬영 중인 행동 영상을 전문가와 공유할 수 있다. 더불어 보호자는 애플리케이션을 통해 촬영 중인 행동영상에 대한 전문가의 피드백을 실시간으로 수신함에 따라 피드백을 반영하여 행동영상을 촬영할 수 있어, 목표 행동의 촬영 정확도를 높일 수 있다. 도 4는 본 발명의 제2 실시예에 따라, 영유아 발달 관리 시스템에서 보호자에게 아동 행동영상의 위치를 실시간 으로 알리는 동작을 도시한 도면이다. 도 4를 참조하면, 영유아 발달 관리 시스템의 영상 촬영부는 동영상 촬영부를 이용하여, 아동 행동영 상을 촬영하고, 촬영 중인 아동 행동영상에서 등장인물 위치가 한 쪽 방향으로 치우치지 않도록 보호자에게 실 시간으로 알릴 수 있다. 본 발명의 제2 실시예에 따르면, S021 동작에서 동영상 촬영부는 촬영중인 아동 행동영상에서 등장인물이 촬영영역의 중앙 또는 중앙으로부터 지정된 거리 이내에 위치하는 경우 녹색의 사각형을 등장인물에 중첩하여 표시할 수 있다. 예컨대, 동영상 촬영부는 중심적중률을 산출하여, 산출된 중심적중률이 지정된 값 미만인 지에 따라 등장인물이 촬영영역의 중앙 또는 중앙으로부터 지정된 거리 이내에 위치하는지 여부를 판단할 수 있 다. 상기 중심적중률은 아래의 수학식 1을 이용하여 산출된다. 수학식 1은 본 발명의 제2 실시예에 따른, 등장인물 위치에 대한 중심적중률의 산출식이다. 수학식 1"}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "width 는 동영상이 촬영되는 화각의 가로 길이이다. centerx는 딥러닝 모델에 의해 검출되는 인물영역의 중심좌 표 x이다. patient는 수동으로 설정하는 값으로 중심적중률이 민감하게 동작하기를 원치 않는 경우 0.0~0.2 사 이의 실수값을 할당하여 색상의 변화속도를 둔화시킬 수 있다. 본 발명의 제2 실시예에 따르면, 동영상 촬영부는 중심적중률을 활용하여 보호자에게 표현되는 등장인물의 영역에 대한 R, G, B 색상값을 설정할 수 있다. 예컨대, 동영상 화각의 가로 길이가 100 픽셀이고, 검출된 인물 의 centerx가 49이고, patient 값이 0.0이라고 가정했을 때, 중심적중률은 99%로 산출될 수 있다. 본 발명의 제2 실시예에 따르면, S022 동작에서 동영상 촬영부는 촬영 중인 아동 행동영상에서 등장인물이 촬영영역의 바깥 쪽으로 이동하고 있는 경우, 적색과 녹색을 혼합한 황색의 사각형을 등장인물에 중첩하여 표시 할 수 있다. 본 발명의 제2 실시예에 따르면, S023 동작에서 동영상 촬영부는 촬영 중인 아동 행동영상에서 등장인물이 촬영영역의 경계면에 위치한 경우에 적색의 사각형을 등장인물에 중첩하여 표시할 수 있다. 본 발명의 제2 실시예에 따라, 영유아 발달 관리 시스템에서는 촬영 중인 아동 행동영상에 대해 실시간으로 등 장인물의 위치를 색상에 따라 표시함에 따라, 보호자는 표시된 색상을 확인하여 아동 행동영상의 촬영 시에 등 장인물이 중심에서 벗어나지 않도록 촬영할 수 있다. 본 발명의 제2 실시예에 따르면, 동영상 촬영부는 촬영 중인 아동 행동영상에 대해, 등장인물의 각도를 3 차원으로 표시할 수 있다. 예컨대, 동영상 촬영부는 등장인물의 신체부위가 정면 방향을 향하는지 여부를 판단할 수 있다. 본 발명의 제2 실시예에 따르면, 등장인물의 촬영 대상 신체부위가 정면을 행하지 않고 미리 설정된 각도 이상 으로 회전되어 있을 수 있다. 예컨대, 아동의 얼굴 부위가 정면을 향하지 않고 위를 보거나 뒤로 돌아있는 상황 일 수 있다. 이때, 동영상 촬영부는, 목표 촬영 영역을 표시하는 사각형 표시에 목표 회전 방향을 더 표시할 수 있다. 이에 따라, 보호자는 목표 회전 방향을 더 확인하여 등장인물을 목표 회전 방향에 따라 이동시켜 촬영하도록 할 수 있다. 도 5는 본 발명의 다양한 실시예에 따른 영상 전처리부의 구성을 도시한 블록도이다. 도 5를 참조하면, 영상 전처리부는 1차 특징 추출부, 2차 특징 추출부 및 훈련 데이터 생성부 를 포함할 수 있다. 본 발명의 다양한 실시예에 따르면, 영상 전처리부는 AI 모델부에서 사용할 딥러닝 모델을 위한 훈련 데이터 세트를 보호자가 촬영한 아동의 행동영상을 이용하여 생성할 수 있다. 본 발명의 다양한 실시예에 따르면, 1차 특징 추출부는 동영상의 기본적인 형태를 변환할 수 있다. 1차 특 징 추출부의 하위 구성에 대한 구체적인 내용은 도 6에서 설명한다. 본 발명의 다양한 실시예에 따르면, 2차 특징 추출부는 비식별화된 아동의 행동영상을 기반으로 정형 및 비정형 데이터 세트를 생성할 수 있다. 2차 특징 추출부의 하위 구성에 대한 내용은 도 8에서 설명한다. 본 발명의 다양한 실시예에 따르면, 훈련 데이터 생성부는 1차 및 2차 특징 추출부(210, 220)에서 산출된 데이터를 훈련 데이터 세트로 생성할 수 있다. 예컨대, 훈련 데이터 생성부는 상기 1차 및 2차 특징 추출 부에서 생성된 정형 및 비정형 데이터를 취합하여 데이터베이스화하고, 머신러닝, 딥러닝 모델의 훈련에 필요한 데이터 세트로 구성한 후 AI 모델부로 전달할 수 있다. 본 발명의 다양한 실시예에 따르면, 훈련 데이터 생성부는 정형 및 비정형 데이터의 각 유형에 따라 애플 리케이션과 영유아 발달 관리 시스템의 데이터베이스에서 부여한 사용자 별 고유 식별자(unique identifier, UID)로 해당 데이터를 식별할 수 있도록 구성할 수 있다. 도 6은 본 발명의 제3 실시예에 따른 영상 전처리부의 1차 특징 추출부 구성을 도시한 블록도이다. 도 6을 참조하면, 1차 특징 추출부는 해상도 변환부, 프레임 변환부 및 비식별 처리부를 포함할 수 있다. 본 발명의 제3 실시예에 따르면, 해상도 변환부에서는 동영상의 해상도를 확인하여, 미리 지정된 n 해상도 미만의 영상은 업스케일링을 수행하고, n 해상도를 초과하는 영상은 다운스케일링을 수행할 수 있다. 예컨대, 해상도는 360p, 720p, 1080p 등의 n 값으로 관리자에 의해 지정되고, 해상도 변환부는 딥러닝 기반의 픽셀 초해상화(pixel super resolution) 기술을 활용하여 동영상의 스케일을 조정할 수 있다. 본 발명의 제3 실시예에 따르면, 프레임 변환부에서는 해상도 변환부에서 조정된 동영상을 기준으로 n값의 프레임 변수를 정의하여 동영상의 프레임레이트(frames per second, FPS)를 변환할 수 있다. 상기 프레임 변수 의 n값은 1, 2, 4, 8, 16, 20, 24, 30 등의 값일 수 있다. 예컨대, 해상도 변환부에서 변환된 동영상의 총 길이가 10,000 프레임이고 30 FPS 일 때, 프레임 변수의 n값을 10으로 지정하는 경우, 프레임 변환부는 동영상의 총 길이가 3,333 프레임으로 구성되는 새로운 동영상을 생성할 수 있다. 본 발명의 제3 실시예에 따르면, 비식별 처리부는 원본 동영상 혹은 프레임 변환부에서 산출된 동영 상을 기반하고, 안면인식 딥러닝 알고리즘과 안면 비식별화 알고리즘을 복합적으로 이용하여, 동영상 내 등장인 물에 대한 안면정보를 비식별화할 수 있다. 예컨대, 비식별 처리부는 MTCNN(multi-task cascaded convolution neural network) 또는 Mobilenet-SSD 얼굴 검출기(face detector) 등의 딥러닝 모델을 사용하여 안면영역을 검출하고, 픽셀 모자이크, 가상 안면생성 등의 딥러닝 모델을 사용하여 안면영역을 비식별화하여 동 영상의 비식별화를 수행할 수 있다. 도 7은 본 발명의 제3 실시예에 따른 영상 전처리부의 비식별 처리부에서 안면 인식 및 비식별화를 동영상에 적 용하는 동작을 도시한 도면이다. 도 7을 참조하면, 비식별 처리부는 애니매이션에 대한 비식별화를 수행할 수 있다. 본 발명의 제3 실시예에 따르면, S031 동작에서 비식별 처리부는 사용자가 촬영한 아동 행동영상의 원본을 확인할 수 있다. 본 발명의 제3 실시예에 따르면, S032 동작에서 비식별 처리부는 딥러닝 안면 인식 기술을 활용하여 아동 행동영상 내에서 안면 영역을 검출할 수 있다. 본 발명의 제3 실시예에 따르면, 전술된 S032 동작에서 안면 영역을 검출함에 따라, S033 동작에서 비식별 처리 부은 픽셀 모자이크 방법을 활용하여 상기 검출된 안면 영역에 대한 안면 비식별화를 수행할 수 있다. 또한, 본 발명의 제3 실시예에 따르면, 전술된 S032 동작에서 안면 영역을 검출함에 따라, S034 동작에서 비식 별 처리부는 딥러닝 모델을 활용하여 가상의 안면을 재생성하고, 생성된 가상의 안면을 상기 검출된 안면 영역에 적용시킬 수 있다. 본 발명의 제3 실시예에 따라, 비식별 처리부에 의해 아동 행동영상에서 촬영되는 안면을 비식별화함에 따 라, 아동의 행동영상이 외부로 유출되더라도 애플리케이션에 접속된 사용자(예, 보호자 또는 전문가) 외의 사용 자에 의해 아동의 안면이 식별되지 않도록 할 수 있다. 도 8은 본 발명의 다양한 실시예에 따른 영상 전처리부의 2차 특징 추출부 구성을 도시한 블록도이다. 도 8을 참조하면, 2차 특징 추출부는 영상정보 추출부, 청크 추출부, 키포인트 추출부, 라 벨 프레임 추출부, 신체 영역 추출부 및 픽셀 변화량 추출부를 포함할 수 있다. 본 발명의 제4 실시예에 따르면, 영상정보 추출부는 동영상에서 추출할 수 있는 일반정보인 동영상 길이, 촬영 기기정보, 촬영 시간을 조회하여 2차원 정수 형태의 데이터프레임으로 생성할 수 있다. 예컨대, 영상정보 추출부는 촬영시간이 오후 11시 35분이었다면, 하루를 정오를 기준으로 43,200 이내의 값으로 표현할 수 있다. 즉, 영상정보 추출부는 촬영 시간을 41,700의 정수값으로 표현하고, 오전과 오후의 여부는 0과 1로 표현할 수 있다. 본 발명의 제5 실시예에 따르면, 청크 추출부는 n개의 프레임 개수와 n번의 프레임 스킵(frameskip) 변수 를 설정하여 n개의 프레임으로 구성되는 프레임 그룹을 추출하며, 프레임 그룹을 추출하는 연산과정 중에 건너 뛰는 프레임 간격을 설정된 n번의 프레임 스킵 변수로 설정할 수 있다. 예컨대, 청크 추출부는 슬라이딩 윈도우 기법을 활용하여 프레임을 이동시켜 상기 프레임 그룹을 추출할 수 있다. 본 발명의 제5 실시예에 따르면, 청크 추출부는 프레임 개수를 128로 설정하고, 프레임 스킵 변수를 8로 설정할 수 있다. 이때, 청크 추출부는 동영상의 처음부터 끝까지 8 프레임씩 건너뛰면서 매 이동 시 마다 이동지점 이후의 128 개의 프레임을 프레임 그룹으로 추출하여 청크로 생성할 수 있다. 예컨대, 청크 추출부 은 프레임 그룹을 추출할 때, 프레임 스킵 변수가 2로 설정된 경우, 2 프레임만큼 청크 내부에서 프레임을 건너뛰면서 64개의 프레임 개수인 총 64인 청크를 추출할 수 있다. 본 발명의 제5 실시예에 따르면, 청크 추출부는 프레임 개수를 4, 8, 16, 20, 24, 32, 40, 64 등의 정수 값으로 설정하고, 프레임 스킵 변수는 0, 1, 2, 4, 8, 16 등의 값을 사용할 수 있으며, 그 외 다양한 값이 사용 될 수 있다. 한편, 청크 추출부는 프레임 스킵 변수가 0으로 설정된 경우는 무작위성을 부여하여 n개의 프 레임 개수만큼 전체 동영상에서 프레임을 무작위 선택하여 청크를 구성할 수 있다. 본 발명의 제6 실시예에 따르면, 키포인트 추출부는 동영상 내 등장인물의 머리, 목, 어깨, 팔, 손목, 손 가락, 다리, 발 등의 25개 내지 33개의 신체부위를 OpenPose, MediaPipe 등의 딥러닝 모델을 활용하여 좌표값을 추정할 수 있다. 본 발명의 제7 실시예에 따르면, 라벨 프레임 추출부에서는 아동심리 상담사 등 아동의 발달상태를 평가할 수 있는 전문가가 보호자가 업로드한 아동의 행동영상에 대한 발달장애 및 발달지연 여부를 판단하도록 할 수 있다. 본 발명의 제7 실시예에 따르면, 라벨 프레임 추출부는 업로드된 동영상에 대한 종합적인 발달상태를 정수 및 실수로 표현하고, 해당 동영상에 대해 전문가 평가의 근거가 되는 핵심동작의 시작지점과 끝 지점의 프레임 번호와 시간 그리고 해당 시점의 전문가 평가를 정수 및 실수로 표현할 수 있다. 예컨대, 전문가는 Bayley-III 발달평가 프로토콜의 한 문항을 보호자에게 부여한 경우, 보호자가 촬영한 아동의 행동영상을 전문가가 시청한 후 레이블을 부여할 수 있다. 이후, 영유아 발달 관리 시스템의 데이터베이스에서는 상기 부여된 레이블의 값을 활용하여 청크를 별도로 분리하고 데이터화 할 수 있다. 본 발명의 제8 실시예에 따르면, 신체영역 추출부는 딥러닝 기반의 인체 검출 기술을 활용하여 동영상 내 등장인물의 영역을 추정하여 자동으로 세분화(segmentation) 한 후 추출할 수 있다. 본 발명의 제9 실시예에 따르면, 픽셀 변화량 추출부는 신체영역 추출부에서 산출된 등장인물 영역에 대한 좌표값을 연산보조 데이터로서 활용하며, 딥러닝 기반의 옵티컬 플로우(optical flow) 기술을 활용하여 동 영상의 각 프레임 간의 픽셀 변화량을 추정하여 RGB 형태로 변화량을 표시할 수 있다. 예컨대, 픽셀 변화량 추출부는 신체영역 추출부에서 산출된 신체영역 좌표값을 기반으로 동영상 프레임에서 배경영역과 인물 영역을 분리한 후, 각 영역에 대한 픽셀 변화량을 추정하여 별도의 프레임으로 나타낼 수 있다. 표 1은 본 발명의 다양한 실시예에 따른 동영상에서 추출할 수 있는 일반정보를 도시한 표이다. 표 1"}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 1을 참조하면, 동영상의 일반정보는 각 프레임의 식별 정보(caseid), 촬영 시작 시간(recorded_time), 동영 상 길이의 정수값(time_int), 촬영 시간(예, morning, afternoon, night) 프레임 길이(length_frames), 각 프 레임 시간(lenth_seconds), 해상도 등을 포함할 수 있으며, 그 외에 촬영 기기정보 등 다양한 정보가 포함될 수 있다. 도 9는 본 발명의 제5 실시예에 따른 2차 특징 추출부의 청크 추출부에 의해 아동의 행동영상으로부터 변환된 훈련용 청크 구성을 도시한 도면이다. 도 9를 참조하면, 청크 추출부는 슬라이딩 윈도우 기법에 추가 변수를 적용하여 촬영된 아동의 행동영상을 훈련용 청크로 변환시킬 수 있다. 본 발명의 제5 실시예에 따르면, 청크 추출부는 프레임 변수의 크기만큼 윈도우(청크)(S501)의 크기를 지 정할 수 있다. 예컨대, 프레임 변수의 값은 원본 동영상의 프레임레이트를 고려하여 1, 2, 4, 8, 16, 32, 64, 128, 256 등의 n값일 수 있다. 본 발명의 제5 실시예에 따르면, 청크 추출부는 청크를 구성할 때 프레임 스킵 변수 값(S052)의 크기만큼 각 윈도우 내부에서 청크를 건너뛰면서(또는, 제거하면서) 생성할 수 있다. 본 발명의 제5 실시예에 따르면, 청크 추출부는 프레임 스킵 변수 값의 크기만큼 청크를 구성하는 프레임 (S503)을 건너뛰면서 청크의 시작지점을 표현할 수 있다. 도 10은 본 발명의 제6 실시예에 따른 2차 특징 추출부의 키포인트 추출부에서 동영상 내 등장인물의 주요 신체 부위를 추출하여 정형 데이터로 변환하는 동작을 도시한 도면이다. 도 10을 참조하면, S061 동작에서 키포인트 추출부는 딥러닝 모델(예, OpenPose)을 활용하여 인물의 신체 부위 좌표값을 추정할 수 있다. 본 발명의 제6 실시예에 따르면, S062 동작에서 키포인트 추출부는 딥러닝 모델(예, MediaPipe)을 활용하 여 인물의 신체부위 좌표값 중 손가락 영역을 특정하고, 추정할 수 있다. 도 11은 본 발명의 제7 실시예에 따른 라벨 프레임 추출부에서 비식별화 처리된 아동의 행동영상을 참고하여 아 동의 발달상태를 평가할 수 있는 전문가가 발달장애 및 발달지연 여부를 라벨링하는 동작을 도시한 도면이다. 도 11을 참조하면, 라벨 프레임 추출부는 1차 특징 추출부에서 산출된 동영상(S071)을 표시할 수 있 다. 본 발명의 제7 실시예에 따르면, S072 동작에서 라벨 프레임 추출부는 특정 동작의 성공 여부를 나타내는 라벨값, 추가 라벨값 또는 동작에 대한 정보가 입력되는 라벨 목록(S072)을 표시할 수 있다. 예컨대, 전문가는 동영상을 확인하면서 전체적인 라벨값, 판단의 근거가 된 시점과 영역을 나타내는 추가 라벨값 또는 동작에 대 한 정보를 상기 라벨 목록(S072)에 더 입력시킬 수 있다. 본 발명의 제7 실시예에 따라 산출되는 라벨값은 영유아 발달 관리 시스템의 데이터베이스에 저장되고 훈련 데 이터 생성부로 전달될 수 있다. 이후, 훈련 데이터 생성부에서는 라벨값을 반영하여 기 생성된 훈련 데이터를 갱신할 수 있다. 본 발명의 제7 실시예에 따르면, AI 모델부에는 갱신된 훈련 데이터를 이용하여 아동의 행동영상에 대한 발달장애 및 발달지연의 예측을 수행함에 따라, 예측의 결과값에 대한 정확도를 높일 수 있다. 도 12는 본 발명의 제8 실시예에 따른 신체영역 추출부에서 딥러닝 모델을 활용하여 아동의 행동영상 내 등장인 물을 추출하는 동작을 도시한 도면이다. 도 12를 참조하면, 신체영역 추출부에서는 인체 세분화 기술이 적용된 딥러닝 모델을 활용하여 배경 영역 과 등장인물 영역을 분리하고, 상기 분리된 영역들을 서로 다른 색상으로 표시할 수 있다. 본 발명의 제8 실시예에 따르면, S081 동작에서 신체영역 추출부는 검출된 배경영역에 대한 음영처리를 수 행할 수 있다. 예컨대, 음영영역 처리의 강도는 애플리케이션의 사용자 및/또는 제공자에 의해 투명도 혹은 명 암이 설정될 수 있다. 본 발명의 제8 실시예에 따르면, S082 동작에서 신체영역 추출부는 검출된 등장인물의 영역들 각각을 서로 다른 색상으로 처리하여 딥러닝 모델의 결과로 표시할 수 있다. 예컨대, 신체영역 추출부는 상기 등장인물 의 영역들 각각에 대해 사용된 딥러닝 모델에 따라 신체부위를 서로 다른 색상으로 표현할 수 있다. 도 13은 본 발명의 제9 실시예에 따른 픽셀 변화량 추출부에서 딥러닝 모델을 활용하여 아동의 행동영상 내 등 장인물이 취하는 행동의 변화를 추정하는 동작을 도시한 도면이다. 도 13을 참조하면, 픽셀 변화량 추출부는 옵티컬 플로우 기술 기반의 딥러닝 모델을 활용하여 신체부위의 영역이 추출된 동영상의 각 프레임 간의 픽셀 변화량을 추정할 수 있다. 본 발명의 제9 실시예에 따르면, S091 동작에서 픽셀 변화량 추출부는, 동영상 내에서 운동량이 상대적으 로 적은 신체영역에 대해 지정된 색상(예, 하늘색)으로 표시할 수 있다. 본 발명의 제9 실시예에 따르면, S092 동작에서 픽셀 변화량 추출부는, 아동이 물체를 들고 흔드는 행위를 하는 상황에서 상대적으로 운동량이 큰 물체와 손에 대해 지정된 색상(예, 적색)으로 표시할 수 있다. 본 발명의 제9 실시예에 따르면, 픽셀 변화량 추출부는 S091 및 S092 동작에 따라 산출된 새로운 영상을 별도의 데이터로 취급하여 훈련 데이터로 사용할 수 있다. 도 14는 본 발명의 다양한 실시예에 따른 AI 모델부의 구성을 도시한 블록도이다. 도 14를 참조하면, AI 모델부는 모델 훈련부, 모델 예측부 및 모델 검증부를 포함할 수 있 다. 본 발명의 다양한 실시예에 따르면, AI 모델부는 훈련 데이터 생성부에서 생성하는 훈련 데이터 세트 를 활용하여 아동 행동영상의 발달장애 및 발달지연 여부를 예측하는 딥러닝 모델을 생성할 수 있다. 본 발명의 제10 실시예에 따르면, 모델 훈련부는 딥러닝 모델을 생성하여 훈련할 수 있다. 예컨대, 모델 훈련부에서는 아동 행동영상의 데이터의 유형이 다양함에 따라, 복수 개의 딥러닝 모델을 훈련할 수 있다. 예컨대, 상기 데이터는 정형 데이터와 비정형 데이터를 포함할 수 있다. 본 발명의 제10 실시예에 따르면, 상기 정형 데이터는 일반정보 데이터와 키포인트 데이터를 포함할 수 있다. 상기 키포인트 데이터는 DNN 모델과 RNN, LSTM, bi-LSTM, GRU 등의 시계열 모델을 조합하여 데이터의 시계열성 이 설정될 수 있다. 이에 따라, 데이터의 시계열성이 반영된 딥러닝 모델이 설계 및 제공될 수 있다. 본 발명의 제10 실시예에 따르면, 모델 훈련부는 비정형 데이터의 유형인 영상정보 기반의 데이터들을 이 용하여, 공간적 도메인과 시간적 도메인이 혼합된 시공간(spatial-temporal) 도메인의 특징을 반영하는 딥러닝 모델을 생성할 수 있다. 예컨대, 모델 훈련부는 CNN, 3D CNN, 3D Resnet, transformer 모델이 혼합된 딥 러닝 모델을 설계할 수 있다. 본 발명의 제11 실시예에 따르면, 모델 훈련부는 교차 검증(cross validation) 기법을 활용하여 딥러닝 모 델을 훈련할 수 있다. 예컨대, 모델 훈련부는 0(음성 레이블) 또는 1(양성 레이블)로 라벨링되는 레이블의 음성 및 양성 레이블의 비율이 7:3 이상으로 불균형을 이루는 경우, 교차 검증 기법에 따른 각 폴드(fold)의 데 이터를 구성할 때 양성 레이블은 전체를 사용하고 음성 데이터는 폴드의 구성을 사용할 수 있다. 이때, 모델 훈 련부는 음성 및 양성 레이블의 비율을 1:1로 조정하기 위해 음성 레이블에 대해 언더샘플링 기법을 활용하여 음성 및 양성 레이블의 비율을 동일하게 조정한 후 훈련시킬 수 있다. 특히, 상기 제11 실시예에 따르면, 라벨링되는 레이블의 비율이 7:3의 불균형을 유지한 채, 폴드를 구성하고, 이에 대한 언더샘플링 수행 시, 음성 데이터의 수가 지나치게 작아지는 문제점이 개선되는 장점이 있다. 즉, 본 발명의 실시예에 따르면, 레이블 비율이 미리 설정된 기준을 초과하는 불균형인 경우, 폴드는 음성 데이 터에 대하여만 구성될 수 있다. 본 발명의 다양한 실시예에 따르면, 모델 예측부는 모델 훈련부에서 훈련된 딥러닝 모델을 영유아 발 달 관리 시스템에 적용하여, 상기 훈련된 딥러닝 모델이 적용된 상태로 영유아 발달 관리 시스템에서 아동심리 상담사 등의 전문가가 부여한 아동 행동영상의 레이블을 예측하도록 할 수 있다. 예컨대, 모델 예측부는 아동의 행동영상에서 특정한 동작이 나타나는 부분에 대해, 전문가가 판단한 해당 구간의 점수와 딥러닝 모델이 회귀 및 분류를 수행한 점수가 같은 값으로 예측되도록 할 수 있다. 본 발명의 다양한 실시예에 따르면, 딥러닝 모델의 예측 성능을 높이기 위해 모델 훈련부는 예측한 확률을 독립변수로 구성하여 이를 예측 모델에 포함시킬 수 있다. 예컨대, 모델 예측부에서 산출되는 딥러닝 모델 의 예측값은 아동 행동영상의 구간별 시계열 예측 및 동영상 전체에 대한 예측값을 포함할 수 있다. 본 발명의 제12 실시예에 따르면, 모델 검증부는 모델 훈련부와 모델 예측부에서 구성되는 딥러 닝 모델에 대한 신뢰성을 검증하기 위해 ROC-AUC, Accuracy, Sensitivity, Specificity, Precision, Recall의 6가지 성능 평가지표를 이용할 수 있다. 예컨대, 모델 검증부는 상기 딥러닝으로부터 산출되는 아동 행동 영상의 발달장애 및 발달지연 여부에 대한 예측값의 신뢰성을 검증하기 위해 딥러닝 모델 검증을 수행할 수 있 다. 도 15는 본 발명의 제10 실시예에 따른 영상 전처리부에서 정형 및 비정형 데이터가 혼재된 상황에서 시계열 특 성을 반영하여 딥러닝 모델을 설계하는 동작을 도시한 도면이다. 도 15를 참조하면, S101 동작에서 1차 특징 추출부는 산출된 동영상에 대한 기본정보, 오전, 오후 여부 등 의 정형 데이터를 비디오 정보(video information)로 나타내고, 2차 특징 추출부는 산출된 비정형 데이터 를 청크로 나타낼 수 있다. 예컨대, 영상 전처리부는, 훈련 데이터 생성부에서 생성되는 사용자 별 고유 식별자가 구성된 데이터를 이용하여 딥러닝 모델을 설계할 수 있다. 본 발명의 제10 실시예에 따르면, S102 동작에서 영상 전처리부는 시계열 특성을 반영할 수 있는 딥러닝 모델을 사용할 수 있다. 예컨대, 상기 딥러닝 모델은 RNN, LSTM, bi-LSTM, GRU 등의 모델이 될 수 있으며, 영상 전처리부는 상기 딥러닝 모델들 중 적어도 하나를 이용할 수 있다. 본 발명의 제10 실시예에 따르면, 영상 전처리부는 비정형 영상 데이터의 공간적-시간적 특성을 학습하기 위한 딥러닝 모델을 설계할 수 있다. 예컨대, 영상 전처리부는 합성곱 신경망(convolution neural network) 기법, 잔차(residual) 개념이 적용된 인셉션(inception) 모델 및 ResNet(residual network) 모델을 활용하여 공간적 특징맵을 추출하여 공간적 특성을 훈련할 수 있다. 이후, 영상 전처리부는 시간적 특성을 공간적 특징맵을 3차원 형태로 구성하고, 3D CNN, 3D ResNet 구조 등을 활용하여 딥러닝 모델을 구성할 수 있다. 본 발명의 제10 실시예에 따르면, S103 동작에서 영상 전처리부는 각 모델의 출력 뉴런을 구성할 수 있다. 본 발명의 제10 실시예에 따르면, S104 동작에서 영상 전처리부는 정형 및 비정형 데이터가 훈련되는 중간 의 출력 뉴런들을 합하여 별도의 DNN 모델 레이어를 구성할 수 있다. 본 발명의 제10 실시예에 따르면, S105 동작에서 영상 전처리부는 딥러닝 모델을 이용하여 최종 예측값을 산출할 수 있다. 도 16은 제11 실시예에 따른 모델 훈련부에서 교차 검증(cross validation) 기법을 활용하여 딥러닝 모델을 훈 련하는 동작을 도시한 도면이다. 도 16을 참조하면, S111 동작에서 모델 훈련부는 N개의 폴드(N-fold) 단위로 교차 검증을 수행함에 따라 음성 및 양성 레이블을 폴드 단위로 구분할 수 있다. 예컨대, 모델 훈련부는 음성 대 양성 레이블의 비율 이 9:1이라고 가정했을 때, 양성 레이블은 폴드 단위로 구성되도록 유지하고, 나머지 음성 레이블의 9 비율에 대해 매 폴드 마다 선택되도록 구성할 수 있다. 본 발명의 제11 실시예에 따르면, S112 동작에서 모델 훈련부는 i 번째 폴드(i th fold)의 음성 레이블 데 이터를 확인할 수 있다. 본 발명의 제11 실시예에 따르면, S113 동작에서 모델 훈련부는 전술된 S112에서 확인한 i 번째 폴드의 음 성 레이블 데이터를 양성 레이블 개수로 언더샘플링(under sample)하고, 이전에 저장된 양성 레이블과 병합하여 i 번째 폴드의 훈련 데이터로 구성할 수 있다. 도 17은 본 발명의 제12 실시예에 따른 예측값 처리부의 구성을 도시한 블록도이다. 도 17을 참조하면, 예측값 처리부는 정규화부, 임계값 적용부 및 판단부를 포함할 수 있다. 본 발명의 제12 실시예에 따르면, 정규화부는 AI 모델부에서 산출된 시계열의 각 구간에 대한 예측값 을 정규화하여 그래프로 산출할 수 있다. 예컨대, 정규화부는 훈련된 딥러닝 모델의 예측값이 프레임 단위 혹은 청크 단위의 시계열로 산출되는 것을 고려하여, 스무딩(smoothing) 기법을 이용하여 예측값의 민감도를 보 정하고, 민감도가 보정된 예측값으로 새로운 그래프를 산출할 수 있다. 이로써, 각 청크와 그 예측값을 동시에 확인할 수 있게 되어, AI 모델의 판단을 보다 쉽게 이해할 수 있는 장점 이 있다. 일 실시예에 따르면, 상기 스무딩 기법과 후술되는 임계값의 적용 방법은, AI 모델의 민감성을 보완하기 위한 예측값의 보정에 사용될 수 있다. 본 발명의 제12 실시예에 따르면, 임계값 적용부는 정규화부에서 산출된 그래프를 기준으로 임계값 변수를 설정하고 이를 초과하는 값에 대해 해당 과제 행동의 성공 여부를 판단할 수 있다. 예컨대, Bayley-III, K-DST와 같은 아동 발달평가 프로토콜에서는, 각 과제 행동의 성공 여부에 따라 현재 아동의 신체발달 수준이 월령으로 평가될 수 있다. 본 발명의 제12 실시예에 따르면, 임계값 적용부는 임계값을 딥러닝 모델의 예측이 평가기준에 최대한 근 접하도록 결과를 보정할 수 있다. 예컨대, 임계값 적용부는 딥러닝 모델의 정확한 판단을 유도하기 위해 임계값 변수값이 임상심리 전문가, 딥러닝 모델 개발자, 시스템 관리자 등에 의해 수동 설정될 수 있는 기능을 제공할 수 있다. 본 발명의 제12 실시예에 따르면, 판단부는 임계값 적용부에서 산출하는 아동 행동영상의 발달장애 및 발달지연 예측 보정값에 대해 최종 가능성을 산출할 수 있다. 도 18은 본 발명의 제13 실시예에 따른 AI 모델부에서 동영상 청크의 시계열 구간 당 예측값을 정규화하여 산출 하는 동작을 도시한 그래프이다. 도 18을 참조하면, S131 동작에서 AI 모델부는 딥러닝 모델의 예측인 y값을 성공확률로써 표현할 수 있다. 예컨대, AI 모델부는 예측값이 높을수록 주어지는 과제의 동작이 잘 수행되는 것으로 확인할 수 있다. S132 동작에서 AI 모델부는 상기 그래프 상에 프레임 번호를 시계열 순서에 따라 왼쪽에서 오른쪽으로 표 현할 수 있다. 예컨대, 각 동영상 청크는 시작되는 지점을 나타낼 수 있다. 본 발명의 제13 실시예에 따른 프레임(S133 내지 S134)은, AI 모델부에 의해 임상심리 전문가가 아동 행동 영상을 보고 평가한 레이블에 대한 청크이다. 예컨대, S133의 청크는 성공적으로 레이블 된 청크이고, S134의 청크는 실패로 레이블 된 청크일 수 있다. S135 동작에서 AI 모델부는 임계값을 경계(boundary)로 표현할 수 있다. 예컨대, AI 모델부는 0.5의 값을 기준으로 양성과 음성 레이블을 구분하여 그래프에 표시할 수 있다. 더불어, 임상심리 전문가, 관리자 등 이 상기 임계값을 설정함에 따라 딥러닝 모델의 예측 성능이 보완될 수 있다. 본 발명에 따른 실시예는 다양한 수단, 예를 들어, 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결 합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 일 실시예는 하나 또는 그 이상의 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서, 콘트롤러, 마이크로 콘트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 또한, 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 일 실시예는 이상에서 설명된 기능 또는 동작들을 수행하는 모듈, 절차, 함수 등의 형태로 구현되어, 다양한 컴퓨터 수단을 통하여 판독 가능한 기록매체에 기록 될 수 있다. 여기서, 기록매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함 할 수 있다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨 터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예컨대 기록매체는 하드 디스크, 플로피 디스 크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD-ROM(Compact Disk Read Only Memory), DVD(Digital Video Disk)와 같은 광 기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체 (Magneto-Optical Media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치를 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이러한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 아울러, 본 발명에 따른 장치나 단말은 하나 이상의 프로세서로 하여금 앞서 설명한 기능들과 프로세스를 수행 하도록 하는 명령에 의하여 구동될 수 있다. 예를 들어 그러한 명령으로는, 예컨대 JavaScript나 ECMAScript 명 령 등의 스크립트 명령과 같은 해석되는 명령이나 실행 가능한 코드 혹은 컴퓨터로 판독 가능한 매체에 저장되 는 기타의 명령이 포함될 수 있다. 나아가 본 발명에 따른 장치는 서버 팜(Server Farm)과 같이 네트워크에 걸 쳐서 분산형으로 구현될 수 있으며, 혹은 단일의 컴퓨터 장치에서 구현될 수도 있다. 또한, 본 발명에 따른 장치에 탑재되고 본 발명에 따른 방법을 실행하는 컴퓨터 프로그램(프로그램, 소프트웨어, 소프트웨어 애플리케이션, 스크립트 혹은 코드로도 알려져 있음)은 컴파일 되거나 해석된 언어나 선험적 혹은 절차적 언어를 포함하는 프로그래밍 언어의 어떠한 형태로도 작성될 수 있으며, 독립형 프로그램이 나 모듈, 컴포넌트, 서브루틴 혹은 컴퓨터 환경에서 사용하기에 적합한 다른 유닛을 포함하여 어떠한 형태로도 전개될 수 있다. 컴퓨터 프로그램은 파일 시스템의 파일에 반드시 대응하는 것은 아니다. 프로그램은 요청된 프 로그램에 제공되는 단일 파일 내에, 혹은 다중의 상호 작용하는 파일(예컨대, 하나 이상의 모듈, 하위 프로그램 혹은 코드의 일부를 저장하는 파일) 내에, 혹은 다른 프로그램이나 데이터를 보유하는 파일의 일부(예컨대, 마 크업 언어 문서 내에 저장되는 하나 이상의 스크립트) 내에 저장될 수 있다. 컴퓨터 프로그램은 하나의 사이트 에 위치하거나 복수의 사이트에 걸쳐서 분산되어 통신 네트워크에 의해 상호 접속된 다중 컴퓨터나 하나의 컴퓨 터 상에서 실행되도록 전개될 수 있다. 설명의 편의를 위하여 각 도면을 나누어 설명하였으나, 각 도면에 서술되어 있는 실시예들을 병합하여 새로운 실시예를 구현하도록 설계하는 것도 가능하다. 또한, 본 발명은 상술한 바와 같이 설명된 실시예들의 구성과 방 법이 한정되게 적용될 수 있는 것이 아니라, 상술한 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들 의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다. 또한, 이상에서는 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 명세서는 상술한 특정의 실시예에 한정"}
{"patent_id": "10-2022-0141566", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "되지 아니하며, 청구 범위에서 청구하는 요지를 벗어남이 없이 당해 명세서가 속하는 기술분야에서 통상의 지식 을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형 실시들은 본 명세서의 기술적 사상이 나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2022-0141566", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 다양한 실시예에 따른 AI 기반의 영상 분석을 통한 영유아 발달 관리 시스템을 도시한 블록도 이다. 도 2는 본 발명의 다양한 실시예에 따른 영상 촬영부의 구성을 도시한 블록도이다. 도 3은 본 발명의 제1 실시예에 따라, 영유아 발달 관리 시스템에서 보호자가 과제를 이해하여 유효한 동영상을 촬영하도록 하는 가이드라인을 제공하는 동작을 도시한 도면이다. 도 4는 본 발명의 제2 실시예에 따라, 영유아 발달 관리 시스템에서 보호자에게 아동 행동영상의 위치를 실시간 으로 알리는 동작을 도시한 도면이다. 도 5는 본 발명의 다양한 실시예에 따른 영상 전처리부의 구성을 도시한 블록도이다. 도 6은 본 발명의 제3 실시예에 따른 영상 전처리부의 1차 특징 추출부 구성을 도시한 블록도이다. 도 7은 본 발명의 제3 실시예에 따른 영상 전처리부의 비식별 처리부에서 안면 인식 및 비식별화를 동영상에 적 용하는 동작을 도시한 도면이다. 도 8은 본 발명의 다양한 실시예에 따른 영상 전처리부의 2차 특징 추출부 구성을 도시한 블록도이다. 도 9는 본 발명의 제5 실시예에 따른 2차 특징 추출부의 청크 추출부에 의해 아동의 행동영상으로부터 변환된 훈련용 청크 구성을 도시한 도면이다. 도 10은 본 발명의 제6 실시예에 따른 2차 특징 추출부의 키포인트 추출부에서 동영상 내 등장인물의 주요 신체 부위를 추출하여 정형 데이터로 변환하는 동작을 도시한 도면이다. 도 11은 본 발명의 제7 실시예에 따른 라벨 프레임 추출부에서 비식별화 처리된 아동의 행동영상을 참고하여 아 동의 발달상태를 평가할 수 있는 전문가가 발달장애 및 발달지연 여부를 라벨링하는 동작을 도시한 도면이다. 도 12는 본 발명의 제8 실시예에 따른 신체 영역 추출부에서 딥러닝 모델을 활용하여 아동의 행동영상 내 등장 인물을 추출하는 동작을 도시한 도면이다. 도 13은 본 발명의 제9 실시예에 따른 픽셀 변화량 추출부에서 딥러닝 모델을 활용하여 아동의 행동영상 내 등 장인물이 취하는 행동의 변화를 추정하는 동작을 도시한 도면이다. 도 14는 본 발명의 다양한 실시예에 따른 AI 모델부의 구성을 도시한 블록도이다. 도 15는 본 발명의 제10 실시예에 따른 영상 전처리부에서 정형 및 비정형 데이터가 혼재된 상황에서 시계열 특 성을 반영하여 딥러닝 모델을 설계하는 동작을 도시한 도면이다. 도 16은 제11 실시예에 따른 모델 훈련부에서 교차 검증 기법을 활용하여 딥러닝 모델을 훈련하는 동작을 도시 한 도면이다. 도 17은 본 발명의 제12 실시예에 따른 예측값 처리부의 구성을 도시한 블록도이다. 도 18은 본 발명의 다양한 실시예에 따른 AI 모델부에서 동영상 청크의 시계열 구간 당 예측값을 정규화하여 산 출된 그래프이다."}
