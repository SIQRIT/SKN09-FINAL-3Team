{"patent_id": "10-2022-0184924", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0102661", "출원번호": "10-2022-0184924", "발명의 명칭": "라이더 기반 객체인식 시스템 및 방법", "출원인": "경북대학교 산학협력단", "발명자": "박대진"}}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체 인식 시스템으로서,라이다(LiDAR) 센서로부터 점 구름 데이터를 포함하는 제1 이미지를 수신하는 이미지 수신부;상기 제1 이미지에서 지면 및 벽면이 제거된 제2 이미지를 생성하는 지면 데이터 제거부;상기 제2 이미지에 포함된 점 구름 데이터에 기초하여 상기 제2 이미지에 포함된 객체들을 그룹화한 제3 이미지를 생성하는 클러스터링부;상기 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초하여 타겟 객체가 식별된 제4 이미지를 생성하는 타겟 객체 식별부; 및상기 제4 이미지에서 포함된 상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 객체 인식부를포함하는 것을 특징으로 하는, 객체 인식 시스템."}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 제1 이미지에서 지면 및 벽면을 제거하는 과정은,상기 점 구름 데이터에 기초하여 상기 제1 이미지에 포함된 평면들을 특정하는 과정;상기 특정된 평면들의 면적을 계산하는 과정;상기 계산된 면적의 크기가 미리 설정된 값 이상인 평면들을 추출하는 과정; 및 상기 추출된 평면에 해당하는 점 구름 데이터를 제거하는 과정으로 수행되는 것을 특징으로 하는, 객체 인식 시스템."}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 제1 이미지에서 지면 및 벽면을 제거하는 과정은, RANSAC 알고리즘(Random SAmple Consensus Algorithm)으로 수행되는 것을 특징으로 하는, 객체 인식 시스템."}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "에 있어서,상기 타겟 객체를 식별하는 과정은,상기 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초하여 상기 그룹화된 객체들의 점 구름에 포함된 점들 간 중심거리, 점 구름에 포함되는 점의 개수, 점 구름의 크기, 점 구름의 밑면의 넓이 및 점 구름의높이가 포함된 제1 데이터를 계산하는 과정;상기 제1 데이터에 기초하여 점 구름에 포함된 점들 간 중심거리 및 점 구름에 포함된 점들 간 밀도 관계 정보를 포함하는 제2 데이터를 계산하는 과정;상기 제1 데이터에 기초하여 점 구름의 밑면의 넓이 및 점 구름의 높이 관계 정보를 포함하는 제3 데이터를 계산하는 과정; 및상기 제2 데이터 및 제3 데이터에 기초하여 타겟 객체를 식별하는 과정으로 수행되는 것을 특징으로 하는, 객체인식 시스템."}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 객체들을 그룹화하는 과정은,최근접 이웃 알고리즘(Nearest Neiborhood Algorithm)으로 수행되는 것을 특징으로 하는, 객체 인식 시스템.공개특허 10-2024-0102661-4-청구항 6"}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 제2 데이터 및 제3 데이터에 기초하여 타겟 객체를 식별하는 과정은,파인 그레인드(Fine-grained) KNN 알고리즘으로 학습시킨 분류 모델에 기초하여 수행되는 것을 특징으로 하는,객체 인식 시스템."}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 6에 있어서,상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 과정은,상기 타겟 객체의 2차원 이미지에서 차지하는 영역을 계산하는 과정; 및상기 계산된 영역에 기초하여 이차원 이미지 물체인식 알고리즘을 수행하여 객체를 인식하는 과정으로 수행되는것을 특징으로 하는, 객체 인식 시스템."}
{"patent_id": "10-2022-0184924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "객체 인식 방법으로서,라이다(LiDAR) 센서로부터 점 구름 데이터를 포함하는 제1 이미지를 수신하는 단계;상기 제1 이미지에서 지면 및 벽면이 제거된 제2 이미지를 생성하는 단계;상기 제2 이미지에 포함된 점 구름 데이터에 기초하여 상기 제2 이미지에 포함된 객체들을 그룹화한 제3 이미지를 생성하는 단계;상기 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초하여 타겟 객체가 식별된 제4 이미지를 생성하는 단계; 및상기 제4 이미지에서 포함된 상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 단계를 포함하는것을 특징으로 하는, 객체 인식 방법."}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 객체 인식 시스템으로서, 라이다(LiDAR) 센서로부터 점 구름 데이터를 포함하는 제1 이미지를 수신하 는 이미지 수신부, 상기 제1 이미지에서 지면 및 벽면이 제거된 제2 이미지를 생성하는 지면 데이터 제거부, 상 기 제2 이미지에 포함된 점 구름 데이터에 기초하여 상기 제2 이미지에 포함된 객체들을 그룹화한 제3 이미지를 생성하는 클러스터링부, 상기 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초하여 타겟 객체가 식별된 제4 이미지를 생성하는 타겟 객체 식별부 및 상기 제4 이미지에서 포함된 상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 객체 인식부를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 라이더 기반 객체인식 시스템 및 방법에 관한 것으로, 보다 상세하게는, 인공지능 모델을 활용하여 객체를 인식하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율주행차량에서 라이다(LiDAR)와 같은 3D 데이터 센서를 활용한 주변 물체인식 알고리즘의 정확도는 많은 연 구가 진행 중에 있으나 정확도가 높아짐에 따라 높은 성능의 하드웨어와 복잡한 구조가 요구되고 있다. 이러한 물체인식 알고리즘은 주행 중 많은 프로세서를 수행하고 관리해야 하는 자율주행차량의 메인 프로세서에 큰 부 하로 작용할 수 있다. 자율주행 차량 주변을 인식하는데 사용되는 데이터는 사용되는 센서에 따라 카메라로 대표되는 2D 이미지 데이 터와 LiDAR, 레이더와 같은 센서들이 수집하는 3D 데이터로 나누어질 수 있다. 3D 센서 데이터는 측정 대상의 물리적 특징을 가지고 있으므로 카메라 센서가 인식에 이상적인 상태의 이미지를 얻기 힘든 환경에서 보다 신뢰 성 있는 정보를 얻을 수 있다는 장점이 존재한다. 다만, 3D 센서 데이터는 2D 이미지 데이터 보다 크기가 크기 때문에 데이터 처리에 보다 많은 리소스와 복잡한 알고리즘을 필요로 한다. 실제로 현재 발표된 3D 센서 데이터 기반 물체인식 알고리즘들은 그 정확도와 처리속도가 높지만, 높은 사양의 GPU 구동 환경을 요구하고 있다. 한편, 자율주행 차량의 DCU(Driving Control Unit)은 차량 주행 중 발생하는 다양한 이벤트를 실시간으로 처리 하여야 하므로, 자율주행 알고리즘의 리소스를 감소시키는 것은 차량 시스템 측면에서 해결해야할 중요 과제라 고 볼 수 있다. 하지만 경량화를 위하여 2D 이미지 기반 주변 인식만을 수행하기에는 3D 센서 데이터가 제공하 는 물리적 정보의 신뢰성이 주는 이득을 무시하기 어럽다. 이에 3D 센서 데이터가 가진 높은 신뢰도의 물리적 정보를 이용하여 2D 이미지 기반 물체인식의 단점을 보완하고 정확도를 높일 수 있는 방법이 필요한 실정이다."}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위한 본 발명의 목적은 적은 연산량 및 낮은 사양의 프로세서를 통하여 물체를 실시간으로 정확하게 인식할 수 있는 시스템 및 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 객체 인식 시스템으로서, 라이다(LiDAR) 센서로부터 점 구름 데이터를 포함하는 제1 이미지를 수신하는 이미지 수신부, 상기 제1 이미지에서 지면 및 벽면이 제거된 제 2 이미지를 생성하는 지면 데이터 제거부, 상기 제2 이미지에 포함된 점 구름 데이터에 기초하여 상기 제2 이미 지에 포함된 객체들을 그룹화한 제3 이미지를 생성하는 클러스터링부, 상기 제3 이미지에 포함된 그룹화된 객체 들의 점 구름 데이터에 기초하여 타겟 객체가 식별된 제4 이미지를 생성하는 타겟 객체 식별부 및 상기 제4 이 미지에서 포함된 상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 객체 인식부를 포함하는 것 을 특징으로 한다. 또한, 상기 제1 이미지에서 지면 및 벽면을 제거하는 과정은, 상기 점 구름 데이터에 기초하여 상기 제1 이미지 에 포함된 평면들을 특정하는 과정, 상기 특정된 평면들의 면적을 계산하는 과정, 상기 계산된 면적의 크기가 미리 설정된 값 이상인 평면들을 추출하는 과정 및 상기 추출된 평면에 해당하는 점 구름 데이터를 제거하는 과 정으로 수행되는 것을 특징으로 한다. 또한, 상기 제1 이미지에서 지면 및 벽면을 제거하는 과정은, RANSAC 알고리즘(Random SAmple Consensus Algorithm)으로 수행되는 것을 특징으로 한다. 또한, 상기 객체들을 그룹화하는 과정은, 상기 제2 이미지에 포함된 점 구름 데이터에 포함된 점들 간 거리를 계산하는 단계, 상기 계산된 거리가 임계 값 이하인 점들을 그룹화하는 단계 및 상기 그룹화된 점들을 특정 색 으로 표시하는 과정으로 수행되는 것을 특징으로 한다. 또한, 상기 객체들을 그룹화하는 과정은, 최근접 이웃 알고리즘(Nearest Neiborhood Algorithm)으로 수행되는 것을 특징으로 한다. 또한, 상기 타겟 객체를 식별하는 과정은, 상기 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초 하여 상기 그룹화된 객체들의 점 구름에 포함된 점들 간 중심거리, 점 구름에 포함되는 점의 개수, 점 구름의 크기, 점 구름의 밑면의 넓이 및 점 구름의 높이가 포함된 제1 데이터를 계산하는 과정, 상기 제1 데이터에 기 초하여 점 구름에 포함된 점들 간 중심거리 및 점 구름에 포함된 점들 간 밀도 관계 정보를 포함하는 제2 데이 터를 계산하는 과정, 상기 제1 데이터에 기초하여 점 구름의 밑면의 넓이 및 점 구름의 높이 관계 정보를 포함하는 제3 데이터를 계산하는 과정 및 상기 제2 데이터 및 제3 데이터에 기초하여 타겟 객체를 식별하는 과정으 로 수행되는 것을 특징으로 한다. 또한, 상기 제2 데이터 및 제3 데이터에 기초하여 타겟 객체를 식별하는 과정은, 파인 그레인드(Fine-grained) KNN 알고리즘으로 학습시킨 분류 모델에 기초하여 수행되는 것을 특징으로 한다. 또한, 상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 과정은, 상기 타겟 객체의 2차원 이미 지에서 차지하는 영역을 계산하는 과정 및 상기 계산된 영역에 기초하여 이차원 이미지 물체인식 알고리즘을 수 행하여 객체를 인식하는 과정으로 수행되는 것을 특징으로 한다. 상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 객체 인식 방법으로서 라이다(LiDAR) 센서로부터 점 구 름 데이터를 포함하는 제1 이미지를 수신하는 단계, 상기 제1 이미지에서 지면 및 벽면이 제거된 제2 이미지를 생성하는 단계, 상기 제2 이미지에 포함된 점 구름 데이터에 기초하여 상기 제2 이미지에 포함된 객체들을 그룹 화한 제3 이미지를 생성하는 단계, 상기 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초하여 타 겟 객체가 식별된 제4 이미지를 생성하는 단계 및 상기 제4 이미지에서 포함된 상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 라이더 기반 객체인식 시스템 및 방법을 통하여 라이다 센서를 통하여 수집한 3D 데이터를 3D 컨볼루션과 같은 인공신경망에 사용되는 높은 복잡도의 연산을 수행하지 않는 방식으로 객체를 식별할 수 있다. 또한 라이다 데이터에 존재하는 물리적 특징에서 얻을 수 있는 높은 신뢰도 하에서 객체를 인식할 수 있다. 또 한 2차원 이미지가 취약한 과노출, 저조도 환경에서 정확도를 크게 향상시킬 수 있다. 또한 2D 이미지 기반 물체인식이 취약한 영역을 3D 센서 데이터의 처리를 통하여 보정함으로써 정확성을 높일 수 있다. 또한 3D 데이터 기반 CNN 물체인식 보다 더 적은 연산량을 통해 더 낮은 사양의 프로세서에서 객체를 정확하게 인식할 수 있다. 다만, 본 발명의 실시 예들에 따른 라이더 기반 객체인식 시스템 및 방법이 달성할 수 있는 효과는 이상에서 언"}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "급한 것들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다.제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명에 따른 라이더 기반 객체인식 시스템의 개념도이다. 도 1을 참조하면, 본 발명에 따른 라이더 기반 객체인식 시스템은 라이다 센서와 네트워크를 통해 상호 연결될 수 있다. 라이더 기반 객체인식 시스템과 라이다(LiDAR) 센서 네트워크를 통하여 데이터 송수신 동작을 수행할 수 있다. 네트워크(network)는 WiFi(wireless fidelity)와 같은 무선인터넷, WiBro(wireless broadband internet) 또는 WiMax(world interoperability for microwave access)와 같은 휴대인터넷, GSM(global system for mobile communication) 또는 CDMA(code division multiple access)와 같은 2G 이동통신망, WCDMA(wideband code division multiple access) 또는 CDMA2000과 같은 3G 이동통신망, HSDPA(high speed downlink packet access) 또는 HSUPA(high speed uplink packet access)와 같은 3.5G 이동통신망, LTE(long term evolution)망 또는 LTE-Advanced망과 같은 4G 이동통신망, 및 5G 이동통신망 등을 포함할 수 있다. 도 2는 본 발명에 따른 라이더 기반 객체인식 시스템의 블록도이고, 도 3은 본 발명에 따른 라이더 기반 객체인 식 시스템의 동작을 구현하기 위한 시스템 코드를 도시한 것이다. 도 2 및 도 3을 함께 참조하면, 본 발명에 따른 라이더 기반 객체인식 시스템은 라이더 센서와 연계하여 서비스 제공에 필요한 동작을 수행할 수 있다. 본 발명에 따른 이미지에 포함된 객체를 인식하는 시스템 은 서버의 역할을 수행할 수 있다. 또한 본 발명에 따른 라이더 기반 객체인식 시스템은 라이다 센서에서 수신한 점 구름 데이터의 클러스터 링을 통해 물리적 정보를 획득하고, 이를 기계학습을 통해 학습한 모델로 ROI를 설정하여 2D 이미지 물체 인식 알고리즘을 보완하는 방법일 수 있다. 도 3을 참조하여, 본 발명에 따른 라이더 기반 객체인식 시스템의 동작을 개략적으로 설명하면 다음과 같 다. 라이더 기반 객체인식 시스템은 라이다 센서에서 전달받은 라이다 센서 점 구름 데이터의 클러스터링 을 위하여 클러스터링에 방해되는 지면 데이터를 탐색 및 제거할 수 있다. 이후, 라이더 기반 객체인식 시스템은 탐색한 평면을 점 구름 데이터에서 제거하는 과정을 유효한 평면이 탐색되는 동안 반복한 후, 지면 데 이터가 제거된 점 구름 데이터를 거리기반 클러스터링을 통하여 여러 개의 오브젝트로 분리할 수 있다. 라이더 기반 객체인식 시스템은 분리된 각 오브젝트의 물리적 특성을 추출한 뒤, 사전에 학습된 분류모델 을 통해 해당 오브젝트를 1차적으로 분류할 수 있고, 분류된 오브젝트의 좌표를 2D 좌표로 변경하여 새로운 2D 프레임을 생성할 수 있다. 최종적으로 라이더 기반 객체인식 시스템은 생성된 각 2D 프레임 내부의 이미 지에 경량형 2D 물체 인식 딥러닝 알고리즘을 적용하여 해당 영역 내부의 객체를 파악할 수 있다. 한편, 본 발명에 따른 라이더 기반 객체인식 시스템은 상기 동작을 수행하는 이미지 수신부, 지면 데이터 제거부, 클러스터링부, 타겟 객체 식별부 및 객체 인식부의 논리적 구성요소를 포 함할 수 있다. 이하에서 라이더 기반 객체인식 시스템의 구체적인 동작을 상세히 설명한다. 다시 도 2를 참조하면, 본 발명에 따른 이미지 수신부는 라이다 센서로부터 점 구름 데이터를 포함하는 제 1 이미지를 수신할 수 있다. 라이다 센서에 의해 제공되는 데이터는 KIT(Karlsruhe Institute of Technology) 에서 제공하는 LiDAR 데이터 셋일 수 있다. 데이터 셋은 3D 점 구름 데이터, 차량을 기준으로 4방향 + 버드아이 1방향 카메라로 수집한 2D 이미지 데이터, 8종류 대상의 위치 정보를 가진 라벨 데이터와 데이터 측정 시 환경 데이터를 포함할 수 있다. 라이다 센서의 레이저는 방사형으로 진행되므로 객체와 센서간의 거리가 짧을수록 객체를 구성하는 점 데이터의 밀도가 높아질 수 있다. 또한 객체와 센서와의 거리가 커질수록 객체와 센서 사이에 광학적 간섭이 존재하여 점 의 개수는 더 감소할 수 있다. 따라서 객체와 센서 간의 거리와 객체의 점 밀도는 반비례하며 그 비율은 객체의 크기에 영향을 받으므로 거리에 상관없이 이를 통해 객체를 분류할 수 있다. 라이다 센서에 의해 획득되는 점 구름 데이터에 포함되는 점 구름은 3차원 영역에 존재하여 그 영역을 육면체로 나타낼 수 있다. 이때 이 육면체의 형태는 객체마다 상이할 수 있다. 예를 들어, 차량과 보행자의 경우 차량은 보다 납작한 육면체의 형태를 가질 수 있고, 보행자의 경우 높이가 높은 길쭉한 육면체의 형태를 가질 수 있다. 즉, 점 구름 영역의 밑면의 넓이와 높이의 비율을 통하여 해당 물체를 분류할 수 있다. 이 두 가지 방식을 모두 만족하는 물체를 분류 대상 물체로 판단하여 분류해낸 물체들의 3차원 위치 좌표를 2차원 좌표로 변환하여 ROI 를 생성한 후, 생성된 ROI 내부의 이미지에 2D 기반 물체 인식 알고리즘을 적용하여 물체 인식을 수행할 수 있 다. 본 발명에 따른 지면 데이터 제거부는 제1 이미지에서 지면 및 벽면이 제거된 제2 이미지를 생성할 수 있 다. 여기서, 제1 이미지에서 지면 및 벽면을 제거하는 과정은, 상기 점 구름 데이터에 기초하여 상기 제1 이미지에 포함된 평면들을 특정하는 과정은, 특정된 평면들의 면적을 계산하는 과정, 계산된 면적의 크기가 미리 설정된 값 이상인 평면들을 추출하는 과정 및 추출된 평면에 해당하 는 점 구름 데이터를 제거하는 과정으로 수행될 수 있다. 여기서, 제1 이미지에서 지면 및 벽면을 제거하는 과 정은, RANSAC 알고리즘(Random SAmple Consensus Algorithm)으로 수행될 수 있다. 도 3은 본 발명에 따른 라이 더 기반 객체인식 시스템의 동작을 구현하기 위한 시스템 코드를 도시한 것이다. 도 4는 본 발명에 따른 라이더 기반 객체인식 시스템이 지면 및 벽면을 제거하는 과정을 도시한 개념도이다. 도 4를 참조하면, 본 발명에 따른 지면 데이터 제거부는 이후 단계에서 수행되는 클러스터링 과정이 용이하게 수행될 수 있도록 지면 및 벽면 데이터를 제거할 수 있다. 객체와 지면의 점 데이터는 인접하게 위치하고 그 거 리도 유사할 수 있다. 따라서 지면 데이터가 존재하는 상태에서 클러스터링이 수행될 경우, 지면 위의 물체들은 하나의 클러스터로 인식되어 정상적인 분리 과정이 수행되지 않을 수 있다. 따라서 클러스터링을 수행하기 전 점 구름 데이터에서 지면에 해당하는 데이터가 제거되어야 할 수 있다. 본 발명에 따른 지면 데이터 제거부는 점 구름 내부에서 가장 큰 평면을 식별하여 해당 영역을 제거하는 방법으로 지면 및 벽면 데이터를 제거할 수 있다. 지면 데이터 제거부는 데이터 내에서 영역이 가장 큰 평 면을 지면 또는 벽면으로 인식하고 이를 제거할 수 있다. 지면 데이터 제거부는 인식된 평면의 크기가 일 정 값 이하가 될 때까지 반복적으로 지면 데이터 제거과정을 수행할 수 있다. 이를 통하여 지면 데이터 제거부 는 지면 데이터와 건물과 같은 수직 벽면 데이터를 제거할 수 있다. 지면 데이터 제거부는 이러한 과 정에서RANSAC 알고리즘을 이용하여 평면을 탐색하고 탐색한 평면의 크기가 일정 이상일 경우 지면-벽면으로 고 려하여 해당 부분을 점 구름 데이터에서 삭제할 수 있다.다시 도 2를 참조하면, 본 발명에 따른 클러스터링부는 제2 이미지에 포함된 점 구름 데이터에 기초하여 제2 이미지에 포함된 객체들을 그룹화한 제3 이미지를 생성할 수 있다. 여기서, 클러스터링부가 객체들을 그룹화하는 과정은, 상기 제2 이미지에 포함된 점 구름 데이터에 포함된 점들 간 거리를 계산하는 과정, 계산된 거리가 임계 값 이하인 점들을 그룹화하는 과정 및 상기 그룹화된 점들 을 특정 색으로 표시하는 과정으로 수행될 수 있다. 여기서, 객체들을 그룹화하는 과정은 최근접 이웃 알고리즘 (Nearest Neiborhood Algorithm)으로 수행될 수 있다. 도 5는 본 발명에 따른 라이더 기반 객체인식 시스템이 객체를 클러스터링하는 과정을 도시한 개념도이다. 도 5 를 참조하면, 클러스터링부는 점 구름 데이터의 각 점들은 3차원 좌표와 함께 측정한 센서와의 거리 데이 터를 활용하여 클러스터링 동작을 수행할 수 있다. 클러스터링부는 하나의 객체를 구성하는 인접한 점들은 유사한 거리 데이터를 보유할 수 있고, 이를 통하여 유사한 거리 데이터를 가진 점들을 점들 간의 거리를 기준 으로 클러스터링을 수행할 수 있다. 이때, 데이터는 kdtree 구조를 이용하여 정렬되어 클러스터링 알고리즘에 의해 분리될 수 있다. 본 발명에 따른 클러스터링부는 클러스터링 알고리즘으로 최근접 이웃 알고리즘(Nearest Neiborhood Algorithm)을 사용하여 클러스터링을 수행할 수 있다. 클러스터링부는 최종적으로 분리된 각 클러스터들 (그룹화된 그룹들)은 각각 개별 객체로 라벨링되어 객체 인식 단계로 전달될 수 있다. 클러스터링이 완료된 점 구름 데이터들은 각기 다른 색으로 구분되어 각각의 독립된 객체로 분리될 수 있다. 다시 도 2를 참조하면, 본 발명에 따른 타겟 객체 식별부는 제3 이미지에 포함된 그룹화된 객체들의 점 구 름 데이터에 기초하여 타겟 객체가 식별된 제4 이미지를 생성할 수 있다. 타겟 객체를 식별하는 과정은, 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초하여 그룹화된 객 체들의 점 구름에 포함된 점들 간 중심거리, 점 구름에 포함되는 점의 개수, 점 구름의 크기, 점 구름의 밑면의 넓이 및 점 구름의 높이가 포함된 제1 데이터를 계산하는 과정, 제1 데이터에 기초하여 점 구름에 포함된 점들 간 중심거리 및 점 구름에 포함된 점들 간 밀도 관계 정보를 포함하는 제2 데이터를 계산하는 과정, 제1 데이터 에 기초하여 점 구름의 밑면의 넓이 및 점 구름의 높이 관계 정보를 포함하는 제3 데이터를 계산하는 과정 및 제2 데이터 및 제3 데이터에 기초하여 타겟 객체를 식별하는 과정으로 수행될 수 있다. 이 때, 제2 데이터 및 제3 데이터에 기초하여 타겟 객체를 식별하는 과정은 파인 그레인드(Fine-grained) KNN 알고리즘으로 학습시킨 분류 모델에 기초하여 수행될 수 있다. 도 6은 본 발명에 따른 라이더 기반 객체인식 시스템이 타겟 객체를 식별하는 과정을 도시한 개념도이다. 타겟 객체 식별부는 클러스터링 단계에서 분리된 객체들에서 분류에 사용할 특성들을 획득할 수 있다. 구체적으 로 타겟 객체 식별부는 점 구름에 포함된 점들 간 중심거리, 점 구름에 포함되는 점의 개수, 점 구름의 크 기, 점 구름의 밑면의 넓이 및 점 구름의 높이를 획득할 수 있다. 이후, 타겟 객체 식별부는 '‘거리-점의 밀도’, ‘밑면-높이’의 관계 데이터를 사전에 fine-grained KNN 알고리즘으로 학습시킨 분류 모델을 사용하여 타겟 객체(예를 들어, 차량)인지 여부를 판단할 수 있다. 도 6을 참조하면, 타겟 객체인 차량으로 판단된 객체 에 점 구름에 표시가 됨을 확인할 수 있다. 다시 도 2를 참조하면, 본 발명에 따른 객체 인식부는 제4 이미지에서 포함된 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식할 수 있다. 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 과정은, 타겟 객체의 2차원 이미지에서 차지하는 영역을 계산하는 과정 및 계산된 영역에 기초하여 이차원 이미지 물체 인식 알고리즘을 수행하여 객체를 인식하는 과정으로 수행될 수 있다. 도 7은 본 발명에 따른 라이더 기반 객체인식 시스템이 최종적으로 객체를 식별하는 과정을 도시한 개념도이다. 도 7을 참조하면, 객체 인식부는 타겟 객체인 차량으로 판단된 객체의 2차원 이미지에서의 영역을 계산하 여 2D 이미지 물체인식 알고리즘을 적용할 수 있다. 2차원 물체인식 알고리즘은 2차원 CNN 모델일 수 있다. 도 7 에는 인식한 3차원 좌표를 바탕으로 변환된 2차원 영역이 카메라로 촬영한 이미지에 오버레이 된 결과가 나타 나있다. 객체 인식부는 최종적으로 2D 기반 물체 인식 알고리즘은 전달된 영역 내의 이미지에서 객체 인식 을 수행할 수 있다.도 8은 본 발명에 따른 라이더 기반 객체인식 방법을 도시한 흐름도이다. 도 8을 참조하면, 본 발명의 일 실시예에 따른 객체 인식 방법은 라이다(LiDAR) 센서로부터 점 구름 데이터를 포함하는 제1 이미지를 수신하는 단계(S100), 상기 제1 이미지에서 지면 및 벽면이 제거된 제2 이미지를 생성하 는 단계(S200), 상기 제2 이미지에 포함된 점 구름 데이터에 기초하여 상기 제2 이미지에 포함된 객체들을 그룹 화한 제3 이미지를 생성하는 단계(S300), 상기 제3 이미지에 포함된 그룹화된 객체들의 점 구름 데이터에 기초 하여 타겟 객체가 식별된 제4 이미지를 생성하는 단계(S400) 및 상기 제4 이미지에서 포함된 상기 타겟 객체의 2차원 이미지 정보에 기초하여 객체를 인식하는 단계(S500)를 포함할 수 있다. 도 9는 4가지 모델의 프레임당 평균 수행 시간 값을 도시한 그래프이다. 도 9를 참조하면, 본 발명에 따른 라이더 기반 객체인식 시스템의 처리시간이 가장 짧은 것을 확인할 수 있다. 실험에 사용된 환경은 다음과 같다. 물체 인식 알고리즘은 Ubuntu 18.04 환경의 PC에서 수행되었으며, Nvidia GTX 3060 GPU와 Cuda library를 이용한 가속을 적용하여 수행하였다. 본 발명에 따른 라이더 기반 객체인식 시스템의 최종단계 2D 기반 물체인식 알고리즘은 SSD-ResNet을 사 용하였다. 또한 라이더 기반 객체인식 시스템과의 비교를 위해 2D 이미지 물체인식 알고리즘 YOLO v4, SSD-ResNet과 3D 점 구름 데이터 물체인식 알고리즘 pointpillars를 사용하였다. LiDAR 점 구름 데이터의 클러스터링과 의미론적 오브젝트 인식은 최종 물체 인식 프로세스와 분리되어 별개의 임베디드 프로세서에서 수행하였다. 본 발명에서는 NXP社의 LX2160ARDB 개발보드를 클러스터 프로세서로 사용하 였다. 해당 프로세서는 16개의 Cortex-A72, 2.2GHz 코어로 구성되어 되어 있다. 위 분리된 프로세서에서 지면 데이터 제거와 클러스터링은 PCL 라이브러리를 사용하여 수행하였다. 본 발명에서는 추적하고자 하는 대상 물체로 데이터 셋에서 라벨링된 다양한 대상들 중 차량(Car)으로 한정하였 다. 또한 환경에 따른 물체 인식의 정확도 변화를 확인하기 위하여 2D 이미지의 밝기를 50% 감소시킨 경우와 50% 증가시킨 경우에 대하여 물체인식을 추가적으로 수행하였다. 도 9의 그래프는 4가지 모델의 한 프레임 당 수행 시간 결과이다. GPU 동작을 기본 환경으로 사용하는 pointpillars 모델의 수행환경을 기준으로 각 모델들을 GPU 가속 환경에서 동작하였다. 먼저 2D 기반 이미지 추 적 알고리즘인 Yolo v4의 경우 가장 긴 수행시간인 21ms의 결과가 나타났고, SSD-ResNet은 8ms, 제안한 클러스 터링을 수행한 SSD-ResNet은 15ms의 수행시간을 보였다. 본 발명에 따른 라이더 기반 객체인식 시스템은 사전에 클러스터링과 의미론적 분류를 수행하는 시간이 추가되었고, 분할된 각 이미지 프레임마다 개별적인 물체 인식을 수행하기 때문에 일반적인 SSD-ResNet과 비교 하여 수행시간이 다소 증가하였다. 3D기반 알고리즘인 pointpillars는 16ms로 제안한 모델보다 프레임당 1ms 더 긴 처리시간을 보였다. 하기 표 1은 이러한 데이터를 정리한 것이다. (표 1)"}
{"patent_id": "10-2022-0184924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 10은 4가지 모델의 차량 추적 정확도 값을 도시한 그래프이다. 도 10을 참조하면, 4가지 모델의 KITTI set의 원본 데이터와 특수한 상황을 고려하여 수정된 이미지 데이터에 대한 차량 추적 정확도 결과를 확인할 수 있다. Yolo v4 모델이 정확도 81.92%로 가장 높은 정확도를 보였고 경 량화 모델인 SSD-ResNet이 가장 낮은 68.21%의 정확도를 보였다.3D 기반 인식 알고리즘 pointpillars는 74.81%의 정확도를 가졌다. 클러스터를 수행한 SSD-ResNet은 71.84%의 정확도로 클러스터를 수행하지 않은 경우보다 약 6.6% 높은 값을 보였다. 입력 이미지의 밝기 값을 50% 감소시 킨 이미지의 경우 Yolo v4 모델은 22.3%의 정확도 감소를 보였다. SSD-ResNet 역시 25.23%의 정확도 감소가 발생하였다. 대신 본 발명에 따른 라이더 기반 객체인식 시스템(100 0)은 약 7%의 감소량을 보여 64.85%의 정확도로 2D 이미지를 사용하는 모델 들 중 가장 높은 정확도를 보였다. 입력 이미지의 밝기 값을 50% 증가시킨 이미지의 경우 Yolo v4는 2.27%, SSD-ResNet은 11.8%, 제안한 모델은 2%의 정확도 감소량을 보였다. 본 발명에 따른 라이더 기반 객체인식 시스템은 Yolo v4에 비교하여 일반적인 경우와 밝기 값이 증가된 경우에는 10% 정도 낮은 정확도를 가지지만, 밝기 값이 감소된 경우에는 5.3% 더 높은 정확도를 가진다. 수행시 간의 경우도 프레임당 약 6ms 짧아 Yolo v4 대비 28.57%의 수행시간감소가 발생하였다. pointpillar 모델에 비 해서는 모든 경우에서 낮은 정확도를 보였으나 일반적인 경우에는 2.46%의 정확도 차이를 가지며 제안된 모델이 프레임 당 수행시간이 6.25% 짧은 것을 확인하였다. 본 발명의 실시예에 따른 방법의 동작은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 프로그램 또 는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결 된 컴퓨터 시스템에 분산되어 분산 방식으로 컴퓨터로 읽을 수 있는 프로그램 또는 코드가 저장되고 실행될 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 프로그램 명령은 컴파일러 (compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 발명의 일부 측면들은 장치의 문맥에서 설명되었으나, 그것은 상응하는 방법에 따른 설명 또한 나타낼 수 있 고, 여기서 블록 또는 장치는 방법 단계 또는 방법 단계의 특징에 상응한다. 유사하게, 방법의 문맥에서 설명된 측면들은 또한 상응하는 블록 또는 아이템 또는 상응하는 장치의 특징으로 나타낼 수 있다. 방법 단계들의 몇몇 또는 전부는 예를 들어, 마이크로프로세서, 프로그램 가능한 컴퓨터 또는 전자 회로와 같은 하드웨어 장치에 의 해(또는 이용하여) 수행될 수 있다. 몇몇의 실시예에서, 가장 중요한 방법 단계들의 하나 이상은 이와 같은 장 치에 의해 수행될 수 있다. 실시예들에서, 프로그램 가능한 로직 장치(예를 들어, 필드 프로그머블 게이트 어레이)가 여기서 설명된 방법들 의 기능의 일부 또는 전부를 수행하기 위해 사용될 수 있다. 실시예들에서, 필드 프로그머블 게이트 어레이는 여기서 설명된 방법들 중 하나를 수행하기 위한 마이크로프로세서와 함께 작동할 수 있다. 일반적으로, 방법들 은 어떤 하드웨어 장치에 의해 수행되는 것이 바람직하다. 이상 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청 구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0184924", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부도면은 본 발명에 대한 실시예를 제공하 고, 상세한 설명과 함께 본 발명의 기술적 사상을 설명한다. 도 1은 본 발명에 따른 라이더 기반 객체인식 시스템의 개념도이다. 도 2는 본 발명에 따른 라이더 기반 객체인식 시스템의 블록도이다. 도 3은 본 발명에 따른 라이더 기반 객체인식 시스템의 동작을 구현하기 위한 시스템 코드를 도시한 것이다. 도 4는 본 발명에 따른 라이더 기반 객체인식 시스템이 지면 및 벽면을 제거하는 과정을 도시한 개념도이다. 도 5는 본 발명에 따른 라이더 기반 객체인식 시스템이 객체를 클러스터링하는 과정을 도시한 개념도이다. 도 6은 본 발명에 따른 라이더 기반 객체인식 시스템이 타겟 객체를 식별하는 과정을 도시한 개념도이다. 도 7은 본 발명에 따른 라이더 기반 객체인식 시스템이 최종적으로 객체를 식별하는 과정을 도시한 개념도이다. 도 8은 본 발명에 따른 라이더 기반 객체인식 방법을 도시한 흐름도이다. 도 9는 4가지 모델의 프레임당 평균 수행 시간 값을 도시한 그래프이다. 도 10은 4가지 모델의 차량 추적 정확도 값을 도시한 그래프이다."}
