{"patent_id": "10-2022-0186011", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0103652", "출원번호": "10-2022-0186011", "발명의 명칭": "인공 지능 알고리즘을 제공하는 방법, 인공 지능 알고리즘의 동작 방법, 전자 장치, 기록 매", "출원인": "삼성전자주식회사", "발명자": "이성희"}}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 알고리즘의 입력으로 제공될 반도체의 스펙트럼에 대한 제1 데이터 셋(data set)과, 상기 인공 지능알고리즘으로부터 출력될 반도체의 구조에 대한 제2 데이터 셋을 로드하는 단계; 상기 제1 데이터 셋을 기초로, 상기 반도체의 스펙트럼에 대한 OOD(Out Of Distribution) 지수를 반도체마다 계산하는 단계;반도체 별 OOD 지수를 기준으로 제1 및 제2 데이터 셋들을 적어도 하나의 학습 데이터 셋으로 군집 샘플링(clustering sampling)함으로써, 상기 제1 및 제2 데이터 셋들에 대한 데이터 스플릿(data split)을 수행하는단계; 및상기 적어도 하나의 학습 데이터 셋을 학습한 복수의 인공 지능 알고리즘들 중에서, 최적의 인공 지능 알고리즘을 제공하는 단계를 포함하는, 인공 지능 알고리즘을 제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 OOD 지수를 계산하는 단계는,상기 제1 데이터 셋의 차원을 축소하기 위한 PCA(Principal Component Analysis)를 수행함으로써, 상기 제1 데이터 셋에 대한 제1 및 제2 주성분을 추출하는 단계;상기 제1 및 제2 주성분들로 이루어진 벡터들을 기초로, 벡터들 간의 유클리드 거리(Euclidean distance) 및 벡터들과 원점 사이의 코사인 거리(cosine distance)를 곱한 값을 상기 반도체마다 산출하는 단계; 및상기 유클리드 거리와 상기 코사인 거리의 곱에 대한 평균 값을 반도체 별로 정규화(normalization)함으로써,정규화된 값을 상기 OOD 지수로 추출하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘을 제공하는방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 데이터 스플릿을 수행하는 단계는,상기 반도체 별 OOD 지수에 따라 순차적으로 상기 제1 및 제2 데이터 셋들을 미리 설정된 비율로 각각 할당된학습 데이터 셋의 훈련(train) 그룹, 검증(valid) 그룹, 및 테스트(test) 그룹으로 샘플링하는 것을 특징으로하는, 인공 지능 알고리즘을 제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 데이터 스플릿을 수행하는 단계는,상기 반도체 별 OOD 지수가 작은 내림차순으로, 상기 제1 및 제2 데이터 셋들을, 상기 훈련 그룹, 상기 검증 그룹, 및 상기 테스트 그룹으로 샘플링하는 것을 특징으로 하는, 인공 지능 알고리즘을 제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3 항에 있어서,상기 데이터 스플릿을 수행하는 단계는,상기 반도체 별 OOD 지수가 큰 오름차순으로, 상기 제1 및 제2 데이터 셋들을, 상기 훈련 그룹, 상기 검증공개특허 10-2024-0103652-3-그룹, 및 상기 테스트 그룹으로 샘플링하는 것을 특징으로 하는, 인공 지능 알고리즘을 제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3 항에 있어서,상기 적어도 하나의 학습 데이터 셋은,제1 학습 데이터 셋, 및 제2 학습 데이터 셋을 포함하고,상기 데이터 스플릿을 수행하는 단계는,상기 반도체 별 OOD 지수가 작은 내림차순으로, 상기 제1 및 제2 데이터 셋들을, 상기 제1 학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트 그룹으로 샘플링하는 단계; 및상기 반도체 별 OOD 지수가 큰 오름차순으로, 상기 제1 및 제2 데이터 셋들을, 상기 제2 학습 데이터 셋의 훈련그룹, 검증 그룹, 및 테스트 그룹으로 샘플링하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘을제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 최적의 인공 지능 알고리즘을 제공하는 단계는,상기 제1 및 제2 데이터 셋들에서 상기 제1 학습 데이터 셋의 상기 검증 그룹 및 상기 테스트 그룹으로 각각 분류된 제1 검증 데이터와 제1 테스트 데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 상기 제1 검증 데이터와 상기 제1 테스트 데이터 각각에 대한 평가 지표들을 추출하는 단계;상기 제1 및 제2 데이터 셋들에서 상기 제2 학습 데이터 셋의 상기 검증 그룹 및 상기 테스트 그룹으로 각각 분류된 제2 검증 데이터와 제2 테스트 데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 상기 제2 검증 데이터와 상기 제2 테스트 데이터 각각에 대한 평가 지표들을 추출하는 단계; 및상기 제1 검증 데이터와 상기 제1 테스트 데이터 각각에 대한 RMSE들과, 상기 제2 검증 데이터와 상기 제2 테스트 데이터 각각에 대한 RMSE들을 기초로, 상기 복수의 인공 지능 알고리즘들 중 상기 최적의 인공 지능 알고리즘을 선택하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘을 제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 최적의 인공 지능 알고리즘을 제공하는 단계는,상기 제1 및 제2 데이터 셋들에서 상기 적어도 하나의 학습 데이터 셋의 테스트(test) 그룹으로 분류된 테스트데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 제1 평가 지표를 추출하는 단계;상기 제1 및 제2 데이터 셋들에서 상기 적어도 하나의 학습 데이터 셋의 검증(valid) 그룹으로 분류된 검증 데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 제2 평가 지표를 추출하는 단계; 상기 복수의 인공 지능 알고리즘들마다 상기 제1 평가 지표에 대한 상기 제2 평가 지표의 비율을 계산하는단계; 및상기 복수의 인공 지능 알고리즘들 중 상기 제1 평가 지표와 상기 비율의 곱이 가장 작은 인공 지능 알고리즘을상기 최적의 인공 지능 알고리즘으로 선택하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘을 제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2024-0103652-4-제8 항에 있어서,상기 제1 평가 지표를 추출하는 단계는,학습된 반도체의 OOD 지수에 의해 결정되는 학습 영역 내에서 제1 평가 지표와, 상기 학습된 반도체의 OOD 지수에 의해 결정되는 학습 영역 외에서 제1 평가 지표를 추출하고,상기 최적의 인공 지능 알고리즘으로 선택하는 단계는,예측될 반도체의 OOD 지수에 따라, 상기 학습 영역 내에서 제1 평가 지표와 상기 비율의 곱이 가장 작은 제1 인공 지능 알고리즘과, 상기 학습 영역 외에서 제1 평가 지표와 상기 비율의 곱이 가장 작은 제2 인공 지능 알고리즘을 상기 최적의 인공 지능 알고리즘으로 선택하는 것을 특징으로 하는, 인공 지능 알고리즘을 제공하는 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "각 반도체의 스펙트럼이 실측(actual measurement)된 정보를 나타내는 스펙트럼 데이터를 수신하는 단계;상기 각 반도체의 스펙트럼에 대한 OOD 지수를 반도체마다 계산하는 단계;인공 지능 알고리즘을 통해, 복수의 OOD 지수들 중 기준 값보다 작은 OOD 지수를 갖는 반도체의 구조를 상기 스펙트럼 데이터로부터 예측하는 단계; 및학습 완료된 복수의 인공 지능 알고리즘들 중에서, 상기 기준 값보다 크거나 같은 OOD 지수를 이용하여 최적의인공 지능 알고리즘을 상기 인공 지능 알고리즘으로 제공하는 단계를 포함하는, 인공 지능 알고리즘의 동작 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 인공 지능 알고리즘으로 제공하는 단계는,상기 스펙트럼 데이터를 포함하는 제1 데이터 셋과, 상기 복수의 OOD 지수들 각각을 갖는 반도체들의 구조가 실측된 정보를 나타내는 구조 계측 데이터를 포함하는 제2 데이터 셋을 로드하는 단계; 상기 제1 데이터 셋을 기초로 상기 복수의 OOD 지수들을 계산하는 단계;반도체 별 OOD 지수를 기준으로 제1 및 제2 데이터 셋들을 적어도 하나의 학습 데이터 셋으로 군집 샘플링함으로써, 상기 제1 및 제2 데이터 셋들에 대한 데이터 스플릿을 수행하는 단계; 및상기 적어도 하나의 학습 데이터 셋을 학습한 복수의 인공 지능 알고리즘들 중에서, 최적의 인공 지능 알고리즘을 제공하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘의 동작 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 복수의 OOD 지수들을 계산하는 단계는,상기 제1 데이터 셋의 차원을 축소하기 위한 PCA를 수행함으로써, 상기 제1 데이터 셋에 대한 제1 및 제2 주성분을 상기 반도체마다 추출하는 단계;상기 제1 및 제2 주성분들로 이루어진 벡터들을 기초로, 벡터들 간의 유클리드 거리, 및 벡터들과 원점 사이의코사인 거리를 곱한 값을 상기 반도체마다 산출하는 단계; 및상기 유클리드 거리와 상기 코사인 거리의 곱에 대한 평균 값을 반도체 별로 정규화함으로써, 상기 반도체마다정규화된 값을 OOD 지수로 추출하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘의 동작 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,상기 적어도 하나의 학습 데이터 셋은,공개특허 10-2024-0103652-5-제1 학습 데이터 셋, 및 제2 학습 데이터 셋을 포함하고,상기 데이터 스플릿을 수행하는 단계는,반도체 별 OOD 지수가 작은 내림차순으로, 상기 제1 및 제2 데이터 셋들을, 상기 제1 학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트 그룹으로 샘플링하는 단계; 및상기 반도체 별 OOD 지수가 큰 오름차순으로, 상기 제1 및 제2 데이터 셋들을, 상기 제2 학습 데이터 셋의 훈련그룹, 검증 그룹, 및 테스트 그룹으로 샘플링하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘의동작 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 최적의 인공 지능 알고리즘을 제공하는 단계는,상기 제1 및 제2 데이터 셋들에서 상기 제1 학습 데이터 셋의 상기 검증 그룹 및 상기 테스트 그룹으로 각각 분류된 제1 검증 데이터와 제1 테스트 데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 상기 제1 검증 데이터와 상기 제1 테스트 데이터에 대한 평가 지표들을 추출하는 단계;상기 제1 및 제2 데이터 셋들에서 상기 제2 학습 데이터 셋의 상기 검증 그룹 및 상기 테스트 그룹으로 각각 분류된 제2 검증 데이터와 제2 테스트 데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 상기 제2 검증 데이터와 상기 제2 테스트 데이터에 대한 평가 지표들을 추출하는 단계; 및상기 제1 검증 데이터와 상기 제1 테스트 데이터에 대한 평가 지표들과, 상기 제2 검증 데이터와 상기 제2 테스트 데이터에 대한 평가 지표들을 기초로, 상기 복수의 인공 지능 알고리즘들 중 상기 최적의 인공 지능 알고리즘을 선택하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘의 동작 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 최적의 인공 지능 알고리즘을 제공하는 단계는,상기 제1 및 제2 데이터 셋들에서 상기 적어도 하나의 학습 데이터 셋의 테스트 그룹으로 분류된 테스트 데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터제1 평가 지표를 추출하는 단계;상기 제1 및 제2 데이터 셋들에서 상기 적어도 하나의 학습 데이터 셋의 검증 그룹으로 분류된 검증 데이터를상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 제2평가 지표를 추출하는 단계; 상기 복수의 인공 지능 알고리즘들마다 상기 제1 평가 지표에 대한 상기 제2 평가 지표의 비율을 계산하는단계; 및상기 복수의 인공 지능 알고리즘들 중 상기 제1 평가 지표와 상기 비율의 곱이 가장 작은 인공 지능 알고리즘을상기 최적의 인공 지능 알고리즘으로 선택하는 단계를 포함하는 것을 특징으로 하는, 인공 지능 알고리즘의 동작 방법."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "인공 지능 알고리즘 제공 방법을 실행하기 위한 명령어들을 저장하는 메모리; 및상기 명령어들을 실행하도록 구성된 프로세서를 포함하고,상기 프로세서는,인공 지능 알고리즘의 입력으로 제공될 반도체의 스펙트럼에 대한 제1 데이터 셋과, 상기 인공 지능 알고리즘으로부터 출력될 반도체의 구조에 대한 제2 데이터 셋을 로드하고,공개특허 10-2024-0103652-6-상기 제1 데이터 셋을 기초로, 상기 반도체의 스펙트럼에 대한 OOD 지수를 반도체마다 계산하고,반도체 별 OOD 지수를 기준으로 제1 및 제2 데이터 셋들을 적어도 하나의 학습 데이터 셋으로 군집 샘플링함으로써, 상기 제1 및 제2 데이터 셋들에 대한 데이터 스플릿을 수행하고,상기 적어도 하나의 학습 데이터 셋을 학습한 복수의 인공 지능 알고리즘들 중에서, 최적의 인공 지능 알고리즘을 제공하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 프로세서는,상기 제1 데이터 셋의 차원을 축소하기 위한 PCA를 수행함으로써, 상기 제1 데이터 셋에 대한 제1 및 제2 주성분을 상기 반도체마다 추출하고, 상기 제1 및 제2 주성분들로 이루어진 벡터들을 기초로, 벡터들 간의 유클리드 거리, 및 벡터들과 원점 사이의코사인 거리를 곱한 값을 상기 반도체마다 산출하고,상기 유클리드 거리와 상기 코사인 거리의 곱에 대한 평균 값을 반도체 별로 정규화함으로써, 상기 반도체마다정규화된 값을 OOD 지수로 추출하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16 항에 있어서,상기 프로세서는,상기 반도체 별 OOD 지수에 따라 순차적으로 상기 제1 및 제2 데이터 셋들을 미리 설정된 비율로 각각 할당된학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트(test) 그룹으로 샘플링하는 것을 특징으로 하는, 전자장치."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16 항에 있어서,상기 프로세서는,상기 제1 및 제2 데이터 셋들에서 상기 적어도 하나의 학습 데이터 셋의 테스트 그룹으로 분류된 테스트 데이터를 상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터제1 평가 지표를 추출하고,상기 제1 및 제2 데이터 셋들에서 상기 적어도 하나의 학습 데이터 셋의 검증 그룹으로 분류된 검증 데이터를상기 복수의 인공 지능 알고리즘들 각각에 적용함으로써, 상기 복수의 인공 지능 알고리즘들 각각으로부터 제2평가 지표를 추출하고,상기 복수의 인공 지능 알고리즘들마다 상기 제1 평가 지표에 대한 상기 제2 평가 지표의 비율을 계산하고,상기 복수의 인공 지능 알고리즘들 중 상기 제1 평가 지표와 상기 비율의 곱이 가장 작은 인공 지능 알고리즘을상기 최적의 인공 지능 알고리즘으로 선택하는 단계를 포함하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0186011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19 항에 있어서,상기 프로세서는,학습된 반도체의 OOD 지수에 의해 결정되는 학습 영역 내에서 제1 평가 지표를 추출하고,상기 학습된 반도체의 OOD 지수에 의해 결정되는 학습 영역 외에서 제1 평가 지표를 추출하고,예측될 반도체의 OOD 지수에 따라, 상기 학습 영역 내에서 제1 평가 지표와 상기 비율의 곱이 가장 작은 제1 인공 지능 알고리즘과, 상기 학습 영역 외에서 제1 평가 지표와 상기 비율의 곱이 가장 작은 제2 인공 지능 알고공개특허 10-2024-0103652-7-리즘을 상기 최적의 인공 지능 알고리즘으로 선택하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능 알고리즘을 제공하는 방법, 인공 지능 알고리즘의 동작 방법, 전자 장치, 기록 매체, 및 컴퓨터 프로 그램이 개시된다. 본 개시의 기술적 사상에 따른 인공 지능 알고리즘을 제공하는 방법은, 반도체의 스펙트럼과 반도체의 구조에 대한 데이터 셋들을 로드하는 단계, 반도체의 스펙트럼에 대한 OOD 지수를 반도체마다 계산하는 단계, 반도체 별 OOD 지수를 기준으로 데이터 셋들을 적어도 하나의 학습 데이터 셋으로 군집 샘플링함으로써, 데이터 스플릿을 수행하는 단계, 및 적어도 하나의 학습 데이터 셋을 학습한 복수의 인공 지능 알고리즘들 중에 서, 최적의 인공 지능 알고리즘을 제공하는 단계를 포함한다."}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 기술적 사상은 전자 장치에 관한 것이며, 보다 구체적으로 인공 지능 알고리즘을 제공하는 방법, 인 공 지능 알고리즘의 동작 방법, 전자 장치, 기록 매체, 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "오늘날 반도체 제조 공정의 크기 축소와 복잡성 증가로 인해 이러한 공정의 계측이 한계에 이르고 있으며, 엄격 한 공정 한계에서 요구하는 사양 내에서 계측 도구를 유지하기가 매우 어렵다. 측정 결과와 관련된 정확도, 공 정 견고성, 정밀도, 매칭 및 기타 불확실성은 현재 방법으로는 달성하기가 매우 어렵다. 최근, 인공 지능 알고리즘을 이용하여 반도체의 구조를 예측하는 기술이 활발이 연구되고 있다. 그런데, HARC(High-Aspect-Ratio-Contact) 에칭 등으로 제조된 반도체의 구조가 복잡하기 때문에, 실측데이터를 확보하 는데 많은 비용과 시간이 소요될 수 있다. 또한, 구조 예측을 위한 데이터 샘플이 적거나 데이터 샘플의 노이즈 가 큰 경우, 같은 모델을 이용하더라도 데이터 스플릿의 조건에 따라 인공 지능 알고리즘의 과적합 (Overfitting)이 발생할 수도 있다. 따라서, 적은 양의 데이터만으로도 견고하고 일관된 인공 지능 알고리즘이 필요하다."}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 사상은, 적은 양의 데이터로도 과적합성을 방지하고 견고한(robust) 인공 지능 알고리즘을 제 공하기 위한 방법, 전자 장치, 기록 매체, 및 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 기술적 사상에 따른 인공 지능 알고리즘을 제공하는 방법은, 인공 지능 알고리즘의 입력으로 제공될 반도체의 스펙트럼에 대한 제1 데이터 셋과, 상기 인공 지능 알고리즘으로부터 출력될 반도체의 구조에 대한 제 2 데이터 셋을 로드하는 단계; 상기 제1 데이터 셋을 기초로, 상기 반도체 의 스펙트럼에 대한 OOD 지수를 반도 체마다 계산하는 단계; 반도체 별 OOD 지수를 기준으로 제1 및 제2 데이터 셋들을 적어도 하나의 학습 데이터 셋으로 군집 샘플링함으로써, 상기 제1 및 제2 데이터 셋들에 대한 데이터 스플릿을 수행하는 단계; 및 상기 적 어도 하나의 학습 데이터 셋을 학습한 복수의 인공 지능 알고리즘들 중에서, 최적의 인공 지능 알고리즘을 제공 하는 단계를 포함한다. 또한, 본 개시의 기술적 사상에 따른 인공 지능 알고리즘의 동작 방법은, 각 반도체의 스펙트럼이 실측(actual measurement)된 정보를 나타내는 스펙트럼 데이터를 수신하는 단계; 상기 각 반도체 의 스펙트럼에 대한 OOD 지 수를 반도체 마다 계산하는 단계; 인공 지능 알고리즘을 통해, 복수의 OOD 지수들 중 기준 값보다 작은 OOD 지 수를 갖는 반도체의 구조를 상기 스펙트럼 데이터로부터 예측하는 단계; 및 학습 완료된 복수의 인공 지능 알고 리즘들 중에서, 기준 값보다 크거나 같은 OOD 지수를 이용하여 최적의 인공 지능 알고리즘을 상기 인공 지능 알 고리즘으로 제공하는 단계를 포함한다. 또한, 본 개시의 기술적 사상에 따른 전자 장치는, 인공 지능 알고리즘 제공 방법을 실행하기 위한 명령어들을 저장하는 메모리; 및 상기 명령어들을 실행하도록 구성된 프로세서를 포함한다. 상기 프로세서는, 인공 지능 알 고리즘의 입력으로 제공될 반도체의 스펙트럼에 대한 제1 데이터 셋과, 상기 인공 지능 알고리즘으로부터 출력 될 반도체의 구조에 대한 제2 데이터 셋을 로드하고, 상기 제1 데이터 셋을 기초로, 상기 반도체의 스펙트럼에 대한 OOD 지수를 반도체마다 계산하고, 반도체 별 OOD 지수를 기준으로 제1 및 제2 데이터 셋들을 적어도 하나 의 학습 데이터 셋으로 군집 샘플링함으로써, 상기 제1 및 제2 데이터 셋들에 대한 데이터 스플릿을 수행하고, 상기 적어도 하나의 학습 데이터 셋을 학습한 복수의 인공 지능 알고리즘들 중에서, 최적의 인공 지능 알고리즘 을 제공한다. 이 외에도, 본 개시의 실시예들을 구현하기 위해, 컴퓨터로 판독 가능한 컴퓨터 프로그램이 제공될 수 있다. 이 외에도, 본 개시의 실시예들을 구현하기 위해, 명령어들을 저장하는 기록 매체가 제공될 수 있다."}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 기술적 사상에 의하면, 적은 양의 데이터로도 과적합성을 방지하고 견고한(robust) 인공 지능 알고리 즘을 제공하는 효과가 있다. 또한, 본 개시의 기술적 사상에 의하면, 복잡한 반도체의 구조에 대해 인공 지능 알고리즘의 정합성을 확보하는 데 소요되는 시간을 감소시키는 효과가 있다. 또한, 본 개시의 기술적 사상에 의하면, 잦은 공정의 개선(revision)에 따라 인공 지능 알고리즘을 학습하는데 소요되는 비용을 감소시키는 효과가 있다. 본 개시의 실시예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 아니하며, 언급되지 아니한"}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "다른 효과들은 이하의 기재로부터 본 개시의 실시예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확 하게 도출되고 이해될 수 있다. 즉, 본 개시의 실시예들을 실시함에 따른 의도하지 아니한 효과들 역시 본 개시"}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "의 실시예들로부터 당해 기술분야의 통상의 지식을 가진 자에 의해 도출될 수 있다."}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 개시의 실시예에 대해 상세히 설명한다. 도 1은 본 개시의 예시적인 실시예들에 따른 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 시스템은 제1 측정 장치, 전자 장치, 및 제2 측정 장치를 포함할 수 있 다. 제1 측정 장치는 반도체(WF)의 스펙트럼을 실측(actual measurement)하는 장치일 수 있다. 제1 측정 장치 는 광을 반도체(WF)에 조사하여, 스펙트럼 데이터를 전자 장치에 제공할 수 있다. 스펙트럼 데이터는반도체(WF)의 스펙트럼이 실측(actual measurement)된 정보를 나타낼 수 있다. 반도체(WF)가 복수인 경우, 제1 측정 장치는 반도체(WF)마다 각 반도체의 스펙트럼을 측정하고, 각 반도체의 스펙트럼 데이터를 전자 장치 에 제공할 수 있다. 본 개시의 반도체(WF)는 반도체 웨이퍼, 반도체 웨이퍼에 포함된 반도체 칩 또는 반도체 칩들, 또는 반도체 칩 에 포함된 반도체 소자 등을 지칭할 수 있다. 전자 장치는 서버, 개인 컴퓨터, 노트북, 휴대용 통신 단말기, 스마트 폰 등과 같은 컴퓨팅 장치에 해당될 수 있다. 전자 장치는 인공 지능 알고리즘을 이용하여 스펙트럼 데이터로부터 반도체(WF)의 구조를 예측할 수 있다. 인공 지능 알고리즘의 입력은, 반도체(WF)의 스펙트럼(즉, 스펙트럼 데이터)일 수 있다. 그리고, 인공 지능 알 고리즘의 출력은, 반도체(WF)의 구조(즉, 구조 데이터)일 수 있다. 일부 실시예들에서, 전자 장치는 프로세서 및 메모리를 포함할 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어할 수 있다. 프로세서는 AI(Artificial Intelligence) 데이터 연산을 위한 전용 회로인 엑셀레이터를 포함할 수 있다. 엑셀레이터는 프로세서의 특정 기능을 전문적으로 수행하는 기능 블록일 수 있다. 엑셀레이터는 GPU(Graphic Processing Unit), NPU(Neural Processing Unit), 또는 DPU(Data Processing Unit)를 포함할 수 있다. GPU는 그래픽 데이터 처리 를 전문적으로 수행하는 블록일 수 있다. NPU는 AI 계산과 인퍼런스(Inference)를 전문적으로 수행하기 위한 블 록일 수 있다. DPU는 데이터 전송을 전문적으로 하는 블록일 수 있다. 이하에서, 프로세서는 인공 지능 알 고리즘의 동작 방법을 수행하는 NPU로 구현될 수 있다. 프로세서는 메모리에 저장된 명령어들을 실행할 수 있다. 일부 실시예들에서, 명령어들은 인공 지능 알고리즘의 동작 방법을 실행하기 위한 것일 수 있다. 일부 실시예들에서, 프로세서는 인공 지능 알고리즘 의 입력으로 제공될 반도체의 스펙트럼에 대한 제1 데이터 셋과, 인공 지능 알고리즘으로부터 출력될 반도체의 구조에 대한 제2 데이터 셋을 로드할 수 있다. 그리고, 프로세서는 제1 데이터 셋을 기초로 반도체마다 반 도체의 스펙트럼에 대한 OOD 지수를 계산할 수 있다. 그리고, 프로세서는 반도체 별 OOD 지수를 기준으로 제1 및 제2 데이터 셋들을 적어도 하나의 학습 데이터 셋으로 군집 샘플링함으로써, 제1 및 제2 데이터 셋들에 대한 데이터 스플릿을 수행할 수 있다. 그리고, 프로세서는, 적어도 하나의 학습 데이터 셋을 통해 학습 완료된 복수의 인공 지능 알고리즘들 중에서, 최적의 인공 지능 알고리즘을 제공할 수 있다. 일부 실시예들에서, 반도체의 구조는, 예를 들면, VNAND Channel Hole CD Profile, DRAM STI(Shallow Trench Isolation), DRAM BCAT(Buried Channel Array Transistor) Gate, DRAM BCAT GBC(Gate Buried Contact), DRAM BCAT GBL(Gate Bit Line) 등을 포함할 수 있다. 하지만, 이에 한정되는 것은 아니다. 메모리는 인공 지능 알고리즘 제공 방법을 실행하기 위한 명령어들을 저장할 수 있다. 인공 지능 알고리즘 제공 방법을 실행하기 위한 명령어들은, 컴퓨터 프로그램의 코드로 메모리에 저장될 수 있다. 일부 실시예들에서, 메모리는, ROM(Read-Only Memory), MRAM(Magnetic RAM), 스핀전달토크 MRAM(Spin- Transfer Torque MRAM), Conductive bridging RAM(CBRAM), FeRAM(Ferroelectric RAM), PRAM(Phase RAM), 저항 메모리(Resistive RAM) 등과 같은 비휘발성 메모리(non-volatile memory)로 구현될 수 있다. 하지만, 이에 한 정되는 것은 아니다. 다른 실시예들에서, 메모리는, DRAM (Dynamic Random-Access Memory), SDRAM (Synchronous DRAM), DDR SDRAM (Double Data Rate SDRAM), LPDDR SDRAM (Low Power Double Data Rate SDRAM), GDDR SDRAM (Graphics Double Data Rate SDRAM), DDR2 SDRAM, DDR3 SDRAM, DDR4 SDRAM, DDR5 SDRAM 등과 같은 휘발성 메모리로 구현될 수 있다. 제2 측정 장치는 반도체(WF)의 구조를 실측(actual measurement)하는 장치일 수 있다. 제2 측정 장치 는 실측된 정보를 나타내는 구조 계측 데이터를 전자 장치에 제공할 수 있다. 전자 장치는 구조 계측 데이터를 인공 지능 알고리즘을 학습시키는 데에 이용할 수 있다. 구체적으로, 전 자 장치는 임의의 반도체(WF)에 대한 스펙트럼 데이터 및 구조 계측 데이터를 포함하는 데이터 셋을 인공 지은 알고리즘에 학습시킬 수 있다. 전자 장치는 OCD(Optical Critical Dimension) 계측, 전자빔(electron beam: e-beam) 계측, x-ray 계측, 소자 특성 계측 등을 예측하는 장비로 이용될 수 있다.도 2는 본 개시의 예시적인 실시예들에 따른 인공 지능 알고리즘의 동작 방법을 설명하기 위한 흐름도이다. 도 2를 참조하면, 도 2에 도시된 인공 지능 알고리즘의 동작 방법은 도 1에 도시된 전자 장치에 의해 수행 될 수 있다. 스펙트럼 데이터를 수신하는 단계가 수행된다(S210). 스펙트럼 데이터는 각 반도체의 스펙트럼이 실측된 정보를 나타내는 데이터일 수 있다. 도 1을 참조하여 예를 들면, 프로세서는 제1 측정 장치로부터 스펙트럼 데이터를 수신할 수 있다. 각 반도체의 스펙트럼에 대한 OOD(Out of Distribution) 지수를 계산하는 단계가 수행된다(S220). 예측 대상에 해당되는 반도체의 개수가 복수이면, 반도체의 스펙트럼에 대한 OOD 지수가 반도체마다 계산될 수 있다. 도 1을 참조하여 예를 들면, 프로세서는 스펙트럼 데이터를 기초로 OOD 지수를 계산할 수 있다. OOD 지수는 인공 지능 알고리즘의 학습 데이터의 분포와 다른 분포를 갖는 데이터의 분포도를 나타낼 수 있다. 본 개시에 따른 반도체의 스펙트럼에 대한 OOD 지수는, 인공 지능 알고리즘의 학습 영역에서 스펙트럼 데이터의 분포도를 나타 낼 수 있다. 반도체의 스펙트럼에 대한 OOD 지수가 학습 영역 내에 포함되면, 인공 지능 알고리즘이 해당 반도 체의 구조를 정확히 예측할 확률이 상대적으로 높을 수 있다. 한편, 반도체의 스펙트럼에 대한 OOD 지수가 학습 영역 외에 포함되면, 인공 지능 알고리즘이 해당 반도체의 구조를 정확히 예측할 확률이 상대적으로 낮을 수 있 다. OOD 지수와 기준 값(예, 도 2에 도시된 \"TH\")을 비교하는 단계가 수행된다(S230). OOD 지수가 상대적으로 작다 면, 현재 전자 장치에 구비된 인공 지능 알고리즘만으로도, 스펙트럼 데이터로부터 반도체(WF)의 구조가 예측될 수 있다. 한편, OOD 지수가 상대적으로 크다면, 현재 전자 장치에 구비된 인공 지능 알고리즘으로 반도체(WF)의 구조가 예측되지 않을 수 있다. 이 경우, 최적의 인공 지능 알고리즘이 필요할 수 있다. 그러므로, 단계 S230은 인공 지능 알고리즘을 업데이트하기 위한 것일 수 있다. 일부 실시예들에서, 기준 값은 \"1\"일 수 있으나, 이에 한정되는 것은 아니다. OOD 지수가 기준 값보다 작으면(S230, 예), 인공 지능 알고리즘을 통해 스펙트럼 데이터로부터 반도체의 구조를 예측하는 단계가 수행된다(S240). 구체적으로, 인공 지능 알고리즘을 통해, 복수의 OOD 지수들 중 기준 값보다 작은 OOD 지수를 갖는 반도체의 구조가 스펙트럼 데이터로부터 예측될 수 있다. 도 1을 참조하여 예를 들면, 프 로세서는 인공 지능 알고리즘을 통해 스펙트럼 데이터로부터 반도체(WF)의 구조를 예측할 수 있다. OOD 지수가 기준 값보다 이상이면(S230, 아니오), OOD 지수를 기초로 최적의 인공 지능 알고리즘을 제공하는 단 계가 수행된다(S250). 구체적으로, 데이터 셋을 통해 학습 완료된 복수의 인공 지능 알고리즘들 중 가장 우수한 성능을 갖는 최적의 인공 지능 알고리즘이 제공될 수 있다. 도 1을 참조하여 예를 들면, 프로세서는 스펙 트럼 데이터와 구조 계측 데이터를 학습 데이터 셋으로 구성하고, 학습 데이터 셋을 복수의 인공 지능 알고리즘 들 각각에 학습시키며, 학습 완료된 복수의 인공 지능 알고리즘들 중 성능이 가장 우수한 최적의 인공 지능 알 고리즘을 제공할 수 있다. 일부 실시예들에서, 기존의 반도체에 대한 데이터 셋을 학습한 복수의 인공 지능 알고리즘들 중에서 기준 값보 다 크거나 같은 OOD 지수를 이용하여 최적의 인공 지능 알고리즘이 선택될 수 있다. 최적의 인공 지능 알고리즘 을 선택하는 실시예는 도 12A 내지 도 14를 참조하여 후술된다. 일부 실시예들에서, 복수의 인공 지능 알고리즘들은, 반도체의 스펙트럼 데이터를 포함하는 제1 데이터 셋과 구 조 계측 데이터를 포함하는 제2 데이터 셋을 학습할 수 있다. 여기서, 구조 계측 데이터는, 복수의 OOD 지수들 각각을 갖는 반도체들의 구조가 측정 장치(예, 제2 측정 장치)에 의해 실측된 정보를 나타낼 수 있다. 예 를 들면, 구조 계측 데이터는 기존의 반도체의 구조가 실측된 정보와 신규 반도체의 구조가 실측된 정보를 포함 할 수 있다. 여기서, 신규 반도체의 OOD 지수는 기준 값보다 크거나 같을 수 있다. 도 1을 참조하여 예를 들면, 프로세서는 제2 측정 장치로부터 구조 계측 데이터를 수신할 수 있다. 전술한 바에 의하면, 적은 양의 데이터로도 과적합성을 방지하고 견고한(robust) 인공 지능 알고리즘을 제공함 으로써, 인공 지능 알고리즘을 학습하는데 소요되는 비용과 시간을 감소시키는 효과가 있다. 또한, 전술한 바에 의하면, 복잡한 반도체의 구조에 대해 인공 지능 알고리즘의 정합성을 확보하는데 소요되는 시간(예, TAT(Turn Around Time))을 감소시키는 효과, 및 잦은 공정의 개선(revision)에 따라 인공 지능 알고 리즘을 학습하는데 소요되는 비용을 감소시키는 효과가 있다. 도 3은 본 개시의 예시적인 실시예들에 따른 최적의 인공 지능 알고리즘을 제공하는 방법을 설명하기 위한 흐름 도이다. 도 3을 참조하면, 도 3에 도시된 방법은 도 2에 도시된 단계 S260에 대응될 수 있다. 또는, 도 3에 도시된 방법 은 도 2에 도시된 방법과 별개로 도 1에 도시된 전자 장치에서 수행될 수 있다. 데이터 셋(data set)을 로드하는 단계가 수행된다(S310). 구체적으로, 제1 데이터 셋과 제2 데이터 셋이 전자 장치에 로드될 수 있다. 제1 데이터 셋은, 인공 지능 알고리즘의 입력으로 제공될 반도체의 스펙트럼에 대 한 데이터를 포함할 수 있다. 즉, 제1 데이터 셋은 각 반도체의 스펙트럼 데이터를 포함할 수 있다. 제2 데이터 셋은 인공 지능 알고리즘으로부터 출력될 반도체의 구조에 대한 데이터를 포함할 수 있다. 즉, 제2 데이터 셋은 각 반도체의 구조 계측 데이터를 포함할 수 있다. OOD 지수를 계산하는 단계가 수행된다(S320). 구체적으로, 제1 데이터 셋을 기초로, 반도체의 스펙트럼에 대한 OOD 지수를 반도체마다 계산하는 단계가 수행된다. 이에 따라, 복수의 OOD 지수들이 계산될 수 있다. 데이터 스플릿(data split)을 수행하는 단계가 수행된다(S330). 데이터 스플릿은 로드된 데이터 셋들을 학습 데 이터 셋으로 샘플링하기 위한 동작일 수 있다. 일부 실시예들에서, 데이터 스플릿은 로드된 데이터 셋들을 학습 데이터 셋의 훈련(train) 그룹, 검증(valid) 그룹, 및 테스트(test) 그룹으로 분류할 수 있다. 훈련 그룹은 스 펙트럼 데이터 및 구조 계측 데이터를 포함하고, 테스트 그룹은 스펙트럼 데이터를 포함할 수 있다. 훈련 그룹, 검증 그룹, 및 테스트 그룹 간의 비율은 다양하게 설정될 수 있다. 예를 들면, 훈련 그룹, 검증 그룹, 및 테스 트 그룹의 비율은 \"70(%):10(%):20(%)\"일 수 있다. 하지만, 이에 한정되는 것은 아니며, 훈련 그룹, 검증 그룹, 및 테스트 그룹의 총 비율이 100%이면서, 각 그룹의 비율이 다양하게 설정될 수 있다. 이하에서는 설명의 편의 상 훈련 그룹, 검증 그룹, 및 테스트 그룹의 비율은 \"70:10:20\"인 것으로 가정한다. 본 개시의 학습 데이터 셋의 종류는 적어도 하나일 수 있다. 2개 이상의 학습 데이터 셋들 각각은 서로 다른 샘 플링 방식에 따라서 분류된 것일 수 있다. 단계 S330에 대한 일부 실시예들에서, 반도체 별 OOD 지수를 기준으로 제1 및 제2 데이터 셋들을 적어도 하나의 학습 데이터 셋으로 군집 샘플링(clustering sampling)함으로써, 제1 및 제2 데이터 셋들에 대한 데이터 스플릿 을 수행하는 단계가 수행된다. 적어도 하나의 학습 데이터 셋을 이용하여 복수의 인공 지능 알고리즘들을 학습시키는 단계가 수행된다(S340). 적어도 하나의 학습 데이터 셋을 통해 학습 완료된 복수의 인공 지능 알고리즘들 중에서, 최적의 인공 지능 알 고리즘을 제공하는 단계가 수행된다(S350). 도 4는 본 개시의 예시적인 실시예들에 따른 OOD 지수를 계산하는 단계를 설명하기 위한 흐름도이다. 도 4를 참조하면, 하나 이상의 OOD 지수를 계산하는 단계는, 단계 S410, 단계 S420, 및 단계 S430을 포함할 수 있다. 다차원의 스펙트럼에 대해 주성분들을 추출하는 단계가 수행된다(S410). 제1 데이터 셋에 포함되는 스펙트럼 데 이터의 경우, 스펙트럼의 차원의 수가, 예를 들어, 1000개 정도로, 매우 많을 수 있다. 스펙트럼의 차원의 수가 많을수록(또는, 스펙트럼의 차원이 복잡할수록), 인공 지능 알고리즘을 통해 반도체의 스펙트럼으로부터 반도체 의 구조를 예측하는 것이 어려울 수 있다. 따라서, 반도체의 구조를 예측할 확률을 높이기 위해, 다차원의 스펙 트럼에서 일부 주성분들을 추출할 필요가 있다. S410에 대한 일부 실시예들에서, 제1 데이터 셋의 차원을 축소하기 위한 PCA(Principal Component Analysis)를 수행함으로써, 제1 데이터 셋에 대한 2차원의 제1 및 제2 주성분을 반도체마다 추출하는 단계가 수행된다. 제1 및 제2 주성분들로 이루어진 벡터들을 기초로, 벡터들 간의 유클리드 거리(Euclidean distance) 및 벡터들 과 원점 사이의 코사인 거리(cosine distance)를 곱한 값을 반도체마다 산출하는 단계가 수행된다(S420). 유클리드 거리와 코사인 거리의 곱에 대한 평균 값을 반도체 별로 정규화(normalization)함으로써, 반도체마다 정규화된 값을 OOD 지수로 추출하는 단계가 수행된다(S430). 도 5는 본 개시의 예시적인 실시예들에 따른 PCA 맵을 나타낸 도면이다. 일부 실시예들에서, 학습 데이터 셋은 훈련 그룹, 검증 그룹, 및 테스트 그룹으로 분류될 수 있다. 본 개시의 훈련 그룹은 \"Train\"으로 지칭되거나 도면에 표시되고, 본 개시의 검증 그룹은 \"Valid\"로 지칭되거나 도면에 표 시되며, 본 개시의 테스트 그룹은 \"Blind Test\"(또는 \"Test\")로 지칭되거나 도면에 표시된다. 한편, 반도체(예,도 1에 도시된 반도체(WF))는 웨이퍼로 지칭하기로 한다. 도 4 및 도 5를 참조하면, 도 5에 도시된 \"Train 웨이퍼\"를 나타내는 점들은, 학습 데이터 셋의 훈련 그룹에 포 함되는 스펙트럼의 제1 및 제2 주성분들(PCA1, PCA2)을 포함하는 벡터들이다. 이때, 도 5에 도시된 \"Train 웨이 퍼\"를 나타내는 점들은 하나 이상의 웨이퍼에 대한 스펙트럼의 제1 및 제2 주성분들(PCA1, PCA2)을 포함하는 벡 터들일 수 있다. 도 5에 도시된 \"Blind test 웨이퍼\"를 나타내는 점들은, 학습 데이터 셋의 테스트 그룹에 포함 되는 스펙트럼 데이터의 제1 및 제2 주성분들(PCA1, PCA2)을 포함하는 벡터들이다. 이때, 도 5에 도시된 \"#6\",\"#7\", 및 \"#8\"은, 블라인드 테스트할 웨이퍼의 번호 또는 식별번호(Identification)일 수 있다. 도 5에서 블라인드 테스트할 웨이퍼의 번호가 6번, 7번, 및 8번인 것으로 가정한다. 웨이퍼의 구조, 성질, 제조 공정 등의 이유로, 하나의 웨이퍼에 대한 스펙트럼이 일정하게 실측되지 않을 수 있 다. 또는, 하나의 웨이퍼에 포함된 반도체 칩의 개수, 웨이퍼의 형태 등의 이유로, 하나의 웨이퍼 내의 실측할 위치마다 스펙트럼이 다를 수 있다. 이에 따라, 스펙트럼의 제1 및 제2 주성분들(PCA1, PCA2)을 포함하는 벡터 가 분산될 수 있다. 예를 들면, \"Train 웨이퍼\"에 대응되는 벡터들, \"Blind test 웨이퍼 #6\"에 대응되는 벡터들, \"Blind test 웨이퍼 #7\"에 대응되는 벡터들, 및 \"Blind test 웨이퍼 #8\"에 대응되는 벡터들이 도 5에 도시된 바와 같이 분포될 수 있다. 도 6은 도 5에 도시된 PCA 맵에서 유클리드 거리와 코사인 거리를 설명하기 위한 도면이다. 도 4, 도 5, 및 도 6을 참조하면, \"Train 웨이퍼\"에 대응되는 벡터들, \"Blind test 웨이퍼 #6\"에 대응되는 벡터 들, \"Blind test 웨이퍼 #7\"에 대응되는 벡터들, 및 \"Blind test 웨이퍼 #8\"에 대응되는 벡터들 간의 유클리드 거리가 계산될 수 있다. 예를 들면, \"Train 웨이퍼\"에 대응되는 벡터들 중 하나인 제1 벡터(V1)와 \"Blind test 웨이퍼 #7\"에 대응되는 벡터들 중 하나인 제2 벡터(V2) 간의 유클리드 거리가 계산될 수 있다. 한편, \"Train 웨이퍼\"에 대응되는 벡터들, \"Blind test 웨이퍼 #6\"에 대응되는 벡터들, \"Blind test 웨이퍼 #7\"에 대응되는 벡터들, 및 \"Blind test 웨이퍼 #8\"에 대응되는 벡터들 간의 코사인 거리가 계산될 수 있다. 예 를 들면, 제1 벡터(V1), 제2 벡터(V2), 및 원점(OP) 간의 코사인 거리는 아래와 같은 [수학식 1]과 같이 계산될 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 제1 벡터(V1), 제2 벡터(V2), 및 원점(OP) 사이의 각도이다. 도 7은 반도체 별 유클리드 거리와 코사인 거리의 곱의 평균값을 예시적으로 나타낸 도면이다. 도 4, 도 6, 및 도 7을 참조하면, \"Train 웨이퍼 #11\", \"Train 웨이퍼 #14\", 및 \"Train 웨이퍼 #15\"는 도 6에 도시된 \"Train 웨이퍼\"에 해당되며, 훈련 그룹(도 7에 도시된 \"Train\")에 포함되는 웨이퍼일 수 있다. 그리고, \"#11\",\"#14\", 및 \"#15\"는, 훈련 그룹(도 7에 도시된 \"Train\")에 속한 웨이퍼의 번호일 수 있다. \"Blind test 웨이퍼 #6\", \"Blind test 웨이퍼 #7\", 및 \"Blind test 웨이퍼 #8\"은 테스트 그룹(도 7에 도시된 \"Blind Tes t\")에 포함되는 웨이퍼일 수 있다. \"Train 웨이퍼 #11\", \"Train 웨이퍼 #14\", \"Train 웨이퍼 #15\", \"Blind test 웨이퍼 #6\", \"Blind test 웨이퍼 #7\", 및 \"Blind test 웨이퍼 #8\" 각각에 대하여, 유클리드 거리와 코사인 거리의 곱(ED*CD)이 도 7에 도시된 바 와 같이 계산되어 표시될 수 있다. 이때, 도 7에 도시된 곱(ED*CD)의 값은, 예시적으로 표시된 것이다. 설계자, 평가자, 엔지니어 등의 사용자가 용이하게 해석 및 분석할 수 있도록, 도 7에 도시된 각 웨이퍼에 대한 유클리드 거리와 코사인 거리의 곱(ED*CD)의 평균 값이 웨이퍼마다 계산되고, 각 웨이퍼에 대한 평균 값이 정규 화될 수 있다. 정규화된 평균 값이 스펙스럼에 대한 OOD 지수로 추출될 수 있다. 훈련 그룹(도 7에 도시된 \"Train\")에 포함되는 \"Train 웨이퍼 #11\", \"Train 웨이퍼 #14\", 및 \"Train 웨이퍼 #15\"는 인공 지능 알고리즘의 훈련(트레이닝)에 이용되므로, 이들의 정규화된 평균 값들은 학습 영역 내에 포함 될 수 있다. 본 개시의 학습 영역은, 예를 들어, 0 내지 1 사이의 범위를 가질 수 있다. 한편, 테스트 그룹(도 7에 도시된 \"Blind Test\")의 경우, 이들의 정규화된 평균 값들은 학습 영역 내에 포함되 거나 학습 영역 외에 포함될 수 있다. 예를 들면, \"Blind test 웨이퍼 #6\"의 정규화된 평균 값은 학습 영역 내 에 포함되고, \"Blind test 웨이퍼 #7\"의 정규화된 평균 값 및 \"Blind test 웨이퍼 #8\"의 정규화된 평균 값은 학습 영역 외에 포함될 수 있다. 하지만, 이에 한정되는 것은 아니다. 도 8a 및 도 8b는 웨이퍼 별 정규화된 OOD 지수의 평균 값과 특정 예측 모델의 다양한 평가 지표 오차들 간의 상관도를 예시적으로 나타낸 도면이다. 도 8a의 상관도는 웨이퍼 별 정규화된 OOD 지수와 모델 오차 간의 상관 도를 나타내고, 도 8b의 상관도는 블라인드 테스트할 웨이퍼 별 실측 값과 예측 값의 상관도와, 블라인드 테스 트할 웨이퍼 별 OOD 지수와 평균 제곱근 오차(Root Mean Square Error: RMSE)의 예측 값의 상관도를 나타낸다. 도 8a를 참조하면, 훈련 그룹(도 8a에 도시된 \"Train\")에 포함되는 웨이퍼 별 OOD 지수는 정규화된 평균 값으로 추출될 수 있다. 훈련 그룹(도 8a에 도시된 \"Train\")에 포함되는 웨이퍼 별 OOD 지수는 학습 범위 내(예를 들면, 0 이상 1 이하의 범위)에 포함될 수 있다. 한편, 테스트 그룹들(도 8a에 도시된 \"Blind Test 1차\", \"Blind Test 2차\")에 포함되는 웨이퍼 별 OOD 지수도 정규화된 평균 값으로 추출될 수 있다. 여기서, 일부 웨이퍼들(예, 도 8a에 도시된 \"#6\",\"#2\", \"#3\")은 학습 범 위 내에 포함되고, 일부 웨이퍼들(예, 도 8a에 도시된 \"#7\",\"#8\", \"#1\")은 학습 범위 내에 포함되지 않을 수 있 다. 테스트 그룹들(도 8a에 도시된 \"Blind Test 1차\", \"Blind Test 2차\")에 대한 OOD 지수가 증가할수록, 모델 오 차가 증가하는 경향이 있을 수 있다. 테스트 그룹들(도 8a에 도시된 \"Blind Test 1차\", \"Blind Test 2차\")에 대한 OOD 지수가 감소할수록, 모델 오차가 감소하는 경향이 있을 수 있다. 여기서, 모델 오차는 인공 지능 알고 리즘의 다양한 평가 지표들로 나타낼 수 있다. 평가 지표는, 예를 들면, RMSE, MAE(Mean Absolute Error), MSE(Mean Squared Error), MAPE(Mean Absolute Percentage Error), MPE(Mean Percentage Error), 및/또는 R2 score(또는 R squared)을 포함할 수 있다. 이에 따르면, OOD 지수를 통해 인공 지능 알고리즘에 대한 예측 가능 성이 확인될 수 있다. 이하에서는, 평가 지표는 RMSE인 것으로 가정한다. 도 8b를 참조하면, 1차 테스트 그룹(도 8b에 도시된 \"Blind Test 1차\")에서 학습 범위 내에 포함되는 OOD 지수 를 갖는 웨이퍼(예, 도 8b에 도시된 \"#6\")의 경우, 웨이퍼의 구조 계측에 대한 실측값과 예측값을 나타내는 점 들이 직선 상에 매우 가까이 위치함으로써, 실측값과 예측값이 상대적으로 일치하는 경향을 나타낼 수 있다. 한 편, 1차 테스트 그룹(도 8b에 도시된 \"Blind Test 1차\")에서 학습 범위 외에 포함되는 OOD 지수를 갖는 웨이퍼 (예, 도 8b에 도시된 \"#7\",\"#8\"))의 경우, 웨이퍼의 구조 계측에 대한 실측값과 예측값을 나타내는 점들이 일직 선으로부터 멀리 위치함으로써, 실측값과 예측값이 상대적으로 일치하지 않는 경향을 나타낼 수 있다. 2차 테스트 그룹(도 8b에 도시된 \"Blind Test 2차\")에서 학습 범위 내에 포함되는 OOD 지수를 갖는 웨이퍼(예, 도 8b에 도시된 \"#2\",\"#3\")의 경우, 웨이퍼의 구조 계측에 대한 실측값과 예측값을 나타내는 점들이 직선 상에 매우 가까이 위치할 수 있다. 한편, 2차 테스트 그룹(도 8b에 도시된 \"Blind Test 2차\")에서 학습 범위 외에 포 함되는 OOD 지수를 갖는 웨이퍼(예, 도 8b에 도시된 \"#1\"))의 경우, 웨이퍼의 구조 계측에 대한 실측값과 예측 값을 나타내는 점들이 일직선으로부터 멀리 위치할 수 있다. 1차 테스트 그룹(도 8b에 도시된 \"Blind Test 1차\")에서 학습 범위 내에 포함되는 OOD 지수를 갖는 웨이퍼(예, 도 8b에 도시된 \"#6\")의 경우, OOD 지수와 RMSE가 상대적으로 작을 수 있다. 이에 따라, 인공 지능 알고리즘을 통한 예측이 용이할 수 있다. 한편, 1차 테스트 그룹(도 8b에 도시된 \"Blind Test 1차\")에서 학습 범위 외에 포 함되는 OOD 지수를 갖는 웨이퍼(예, 도 8b에 도시된 \"#7\",\"#8\"))의 경우, OOD 지수와 RMSE가 상대적으로 클 수 있다. 이에 따라, 인공 지능 알고리즘을 통한 예측이 어려울 수 있다. 2차 테스트 그룹(도 8b에 도시된 \"Blind Test 2차\")에서 학습 범위 내에 포함되는 OOD 지수를 갖는 웨이퍼(예, 도 8b에 도시된 \"#2\",\"#3\")의 경우, OOD 지수와 RMSE가 상대적으로 작을 수 있다. 한편, 2차 테스트 그룹(도 8b 에 도시된 \"Blind Test 2차\")에서 학습 범위 외에 포함되는 OOD 지수를 갖는 웨이퍼(예, 도 8b에 도시된 \"# 1\"))의 경우, OOD 지수와 RMSE가 상대적으로 클 수 있다. 도 9는 본 개시의 예시적인 실시예들에 따른 데이터 스플릿을 수행하는 단계를 설명하기 위한 흐름도이다. 도 9에 도시된 데이터 스플릿은, 학습 모델을 생성하고 합습 모델을 검증하기 위해 수행될 수 있다. 도 9에 도 시된 데이터 스플릿을 수행하는 단계는, 도 3에 도시된 단계 S330에 대응될 수 있다. 일부 실시예들에서, 데이 터 스플릿을 수행하는 단계는, 반도체 별 OOD 지수에 따라 순차적으로, 제1 및 제2 데이터 셋들을 미리 설정된 비율로 각각 할당된 학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트 그룹으로 샘플링할 수 있다. 도 9를 참조하면, 내림차순으로, 제1 및 제2 데이터 셋을 제1 학습 데이터 셋에 군집 샘플링하는 단계가 수행된 다(S910). 구체적으로 예를 들면, 제1 및 제2 데이터 셋들이, 반도체 별 OOD 지수가 작은 내림차순으로, 제1 학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트 그룹으로 샘플링될 수 있다. 오름차순으로, 제1 및 제2 데이터 셋을 제2 학습 데이터 셋에 군집 샘플링하는 단계가 수행된다(S920). 구체적 으로 예를 들면, 제1 및 제2 데이터 셋들이, 반도체 별 OOD 지수가 큰 오름차순으로, 제2 학습 데이터 셋의 훈 련 그룹, 검증 그룹, 및 테스트 그룹으로 샘플링될 수 있다. 제1 및 제2 데이터 셋을 제3 학습 데이터 셋에 랜덤 샘플링하는 단계가 수행된다(S930). 실시예에 따라, 단계 S910 및/또는 단계 S920이 수행되고 단계 S930는 생략될 수 있다. 즉, 일 실시예에에서 단 계 S910만이 수행될 수 있고, 다른 실시예에에서 단계 S920만이 수행될 수 있고, 또 다른 실시예에에서 단계 S910 및 단계 S920만이 수행될 수도 있다. 도 10a, 도 10b, 및 도 10c는 OOD 지수의 내림차순으로 데이터를 군집 샘플링하는 실시예를 설명하기 위한 도면 이다. 도 10a를 참조하면, 도 10a에 도시된 그래프에서 가로축은 웨이퍼 ID(Identification)를 나타내고, 도 10a에 도 시된 그래프에서 세로축은 스펙트럼에 대한 OOD 지수를 나타낸다. 일부 실시예들에서, 반도체 별 OOD 지수가 작 은 내림차순으로, 제1 및 제2 데이터 셋들이, 학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트 그룹으로 샘 플링될 수 있다. 도 10a를 참조하여 예를 들면, 가장 큰 OOD 지수를 갖는 웨이퍼부터 소정의 OOD 지수를 갖는 웨이퍼까지, 해당 웨이퍼의 스펙트럼 데이터와 구조 계측 데이터가 훈련 그룹 및 검증 그룹에 분류될 수 있다. 이때, 훈련 그룹과 검증 그룹의 비율은 70(%):10(%)로 설정될 수 있다. 즉, 제1 및 제2 데이터 셋들 전체의 약 80%가 훈련 그룹 및 검증 그룹으로 분류될 수 있다. 제1 및 제2 데이터 셋들 중 훈련 그룹 및 검증 그룹으로 분 류되지 않은 20%의 데이터 셋들은 테스트 그룹(또는 블라인드 테스트 그룹)으로 분류될 수 있다. 도 10b를 참조하면, 도 10b에 도시된 PCA 맵에서, 테스트 그룹으로 분류된 데이터 셋들(도 10b에 도시된 \"Blind Test\")의 벡터들(예, 도 10b에 도시된 점들)은 원점(예, 제1 및 제2 주성분들(PCA1, PCA2)이 0인 점)에 가깝게 위치할 수 있다. 한편, 훈련 그룹 및 검증 그룹으로 분류된 데이터 셋들(도 10b에 도시된 \"Train\")의 벡터들은 원점으로부터 멀리 분산될 수 있다. 도 10c를 참조하면, 도 10c에 도시된 그래프는 학습 횟수(number of trial)에 대한 RMSE를 나타낸다. 학습 횟수 가 상대적으로 적음에도 불구하고, 테스트 그룹으로 분류된 데이터 셋들(도 10c에 도시된 \"Blind Test\")에 대한 RMSE가 상대적으로 낮은 값(예를 들면, 1보다 작은 값)을 가질 수 있다. 이에 따르면, OOD 지수의 내림차순으로 제1 및 제2 데이터 셋들을 군집 샘플링하는 데이터 스플릿을 수행함으로써, 상대적으로 적은 학습 횟수로도 상 대적으로 낮은 과적합성(Overfitting)을 인공 지능 알고리즘을 유도할 수 있는 장점이 있다. 다시 말해, 상대적 으로 적은 학습 횟수로도 인공 지능 알고리즘의 과적합성(Overfitting)을 조절(또는 제어)할 수 있는 효과가 있 다. 또한, 데이터 셋을 논리적으로 정렬하기 위한 학습 횟수를 감소시킴으로써, 비용과 시간을 절약하는 효과가 있다. 도 11a, 도 11b, 및 도 11c는 OOD 지수의 오름차순으로 데이터를 군집 샘플링하는 실시예를 설명하기 위한 도면 이다. 도 11a를 참조하면, 도 11a에 도시된 그래프에서 가로축은 웨이퍼 ID를 나타내고 세로축은 스펙트럼에 대한 OOD 지수를 나타낸다. 일부 실시예들에서, 반도체 별 OOD 지수가 큰 오름차순으로, 제1 및 제2 데이터 셋들이, 학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트 그룹으로 샘플링될 수 있다. 도 11a를 참조하여 예를 들면, 가장 작은 OOD 지수를 갖는 웨이퍼부터 소정의 OOD 지수를 갖는 웨이퍼까지, 제1 및 제2 데이터 셋들 전체의 약 80% 가 훈련 그룹 및 검증 그룹으로 분류될 수 있다. 소정의 OOD 지수를 갖는 웨이퍼부터 가장 큰 OOD 지수를 갖는 웨이퍼까지, 제1 및 제2 데이터 셋들 전체의 약 20%가 테스트 그룹으로 분류될 수 있다. 도 11b를 참조하면, 도 11b에 도시된 PCA 맵에서, 테스트 그룹으로 분류된 데이터 셋들(도 11b에 도시된 \"Blind Test\")의 벡터들(예, 도 11b에 도시된 점들)은 원점(예, 제1 및 제2 주성분들(PCA1, PCA2)이 0인 점)으로부터 멀리 분산될 수 있다. 한편, 훈련 그룹 및 검증 그룹으로 분류된 데이터 셋들(도 10b에 도시된 \"Train\")의 벡터 들은 원점에 가까이 위치할 수 있다. 도 11c를 참조하면, 도 11c에 도시된 그래프는 학습 횟수(number of trial)에 대한 RMSE를 나타낸다. 학습 횟수 가 상대적으로 적음에도 불구하고, 테스트 그룹으로 분류된 데이터 셋들(도 10c에 도시된 \"Blind Test\")에 대한 RMSE가 상대적으로 높은 값(예를 들면, 1보다 큰 값)을 가질 수 있다. 이에 따르면, OOD 지수의 오름차순으로 제1 및 제2 데이터 셋들을 군집 샘플링하는 데이터 스플릿을 수행함으로써, 상대적으로 적은 학습 횟수로도 상대적으로 높은 과적합성(Overfitting)을 인공 지능 알고리즘을 유도할 수 있는 효과가 있다. 다시 말해, 상대적 으로 적은 학습 횟수로도 인공 지능 알고리즘의 과적합성(Overfitting)을 조절(또는 제어)할 수 있는 효과가 있 다. 또한, 데이터 셋을 논리적으로 정렬하기 위한 학습 횟수를 감소시킴으로써, 비용과 시간을 절약하는 효과가 있다. 한편, 데이터 셋을 랜덤 샘플링하는 데이터 스플릿에 의하면, 상대적으로 많은 학습을 수행하더라도 인공 지능 알고리즘의 과적합성(Overfitting)을 조절하기 어려운 경우가 있다. 따라서, 본 개시의 OOD 지수의 순서에 따른 군집 샘플링에 의하면, 강건한(robust) 인공 지능 알고리즘을 제공할 수 있는 효과가 있다. 도 12a 및 도 12b는 최적의 인공 지능 알고리즘을 선택하는 일부 실시예들을 설명하기 위한 도면이다. 도 9 및 도 12a를 참조하면, 제1 검증 데이터와 제1 테스트 데이터 각각에 대한 평가 지표들을 추출하는 단계가 수행된다(S1210). 제1 검증 데이터는 도 9의 제1 학습 데이터 셋의 검증 그룹에 포함되는 데이터일 수 있다. 즉, 제1 검증 데이터는 제1 및 제2 데이터 셋들에서 제1 학습 데이터 셋의 검증 그룹으로 분류된 것일 수 있다. 제1 테스트 데이터는 도 9의 제1 학습 데이터 셋의 테스트 그룹에 포함되는 데이터일 수 있다. 즉, 제1 테스트 데이터는 제1 및 제2 데이터 셋들에서 제1 학습 데이터 셋의 테스트 그룹으로 분류된 것일 수 있다. 도 9의 제1 학습 데이터 셋은 제1 및 제2 데이터 셋들이 OOD 지수의 내림차순으로 군집 샘플링된 것일 수 있다. 일부 실시예들에서, 평가 지표는 RMSE일 수 있다. 단계 S1210에 대한 실시예를 구체적으로 예를 들면, 제1 검증 데이터와 제1 테스트 데이터가 복수의 인공 지능 알고리즘들 각각에 적용됨으로써, 복수의 인공 지능 알고리즘 들 각각으로부터 제1 검증 데이터에 대한 RMSE와 제1 테스트 데이터에 대한 RMSE가 추출될 수 있다. 다른 실시 예들에서, 평가 지표는 MAE(Mean Absolute Error), MSE(Mean Squared Error), MAPE(Mean Absolute Percentage Error), MPE(Mean Percentage Error), 및/또는 R2 score일 수 있다. 제2 검증 데이터와 제2 테스트 데이터 각각에 대한 평가 지표들을 추출하는 단계가 수행된다(S1220). 제2 검증 데이터는 제1 및 제2 데이터 셋들에서 도 9의 제2 학습 데이터 셋의 검증 그룹으로 분류된 것일 수 있다. 제2 테스트 데이터는 제1 및 제2 데이터 셋들에서 도 9의 제2 학습 데이터 셋의 테스트 그룹으로 분류된 것일 수 있 다. 도 9의 제2 학습 데이터 셋은 제1 및 제2 데이터 셋들이 OOD 지수의 오름차순으로 군집 샘플링된 것일 수 있다. 일부 실시예들에서, 평가 지표는 RMSE일 수 있다. 단계 S1220에 대한 실시예를 구체적으로 예를 들면, 제2 검증 데이터와 제2 테스트 데이터가 복수의 인공 지능 알고리즘들 각각에 적용됨으로써, 복수의 인공 지능 알고리즘 들 각각으로부터 제2 검증 데이터에 대한 RMSE와 제2 테스트 데이터에 대한 RMSE가 추출될 수 있다. 제3 검증 데이터와 제3 테스트 데이터 각각에 대한 평가 지표들을 추출하는 단계가 수행된다(S1230). 제3 검증 데이터는 도 9의 제3 학습 데이터 셋의 검증 그룹으로 분류된 데이터일 수 있다. 제3 테스트 데이터는 도 9의 제3 학습 데이터 셋의 테스트 그룹으로 분류된 데이터일 수 있다. 도 9의 제3 학습 데이터 셋은 제1 및 제3 데 이터 셋들이 랜덤 샘플링된 것일 수 있다. 검증 데이터와 테스트 데이터 각각에 대한 평가 지표들을 기초로 복수의 인공 지능 알고리즘들 중 최적의 인공 지능 알고리즘을 선택하는 단계가 수행된다(S1240). 일부 실시예에서 평가 지표가 RMSE인 경우, 최적의 인공 지 능 알고리즘이, 제1 검증 데이터에 대한 RMSE, 제1 테스트 데이터에 대한 RMSE, 제2 검증 데이터에 대한 RMSE, 및 제2 테스트 데이터에 대한 RMSE를 기초로, 복수의 인공 지능 알고리즘들 중에서 선택될 수 있다. S1240에 대 한 실시예는 도 12b를 참조하여 후술된다. 일부 실시예들에서, 최적의 인공 지능 알고리즘은, 복수의 인공 지능 알고리즘들 중 적어도 하나의 인공 지능 알고리즘일 수 있다. 예를 들면, 최적의 인공 지능 알고리즘은 복수의 인공 지능 알고리즘들 중 가장 우수한 성 능을 갖는 하나의 인공 지능 알고리즘일 수 있다. 다른 예를 들면, 복수의 인공 지능 알고리즘들 중 학습 영역 내에서 가장 우수한 성능을 갖는 하나의 인공 지능 알고리즘이 학습 영역 내에서 최적의 인공 지능 알고리즘으 로 선택되고, 복수의 인공 지능 알고리즘들 중 학습 영역 외에서 가장 우수한 성능을 갖는 하나의 인공 지능 알 고리즘이 학습 영역 내에서 최적의 인공 지능 알고리즘으로 선택될 수 있다. 도 9 및 도 12b를 참조하면, 데이터 스플릿 조건(DSC)은 제1 학습 데이터 셋(LDS1), 제2 학습 데이터 셋(LDS2), 및 제3 학습 데이터 셋(LDS3)을 포함할 수 있다. 실시예에 따라, 데이터 스플릿 조건(DSC)은 제1 학습 데이터 셋(LDS1) 및 제2 학습 데이터 셋(LDS2)만을 포함할 수도 있다. 제1 학습 데이터 셋(LDS1)은 OOD 지수 내림차순 군집 샘플링(DSD)에 의해 분류된 데이터 셋을 포함할 수 있다. 즉, 제1 학습 데이터 셋(LDS1)은 ODD 지수의 내림차순으로 군집 샘플링된 제1 및 제2 데이터 셋들을 포함할 수 있다. 제2 학습 데이터 셋(LDS2)은 OOD 지수 오름차순 군집 샘플링(ASD)에 의해 분류된 데이터 셋을 포함할 수 있다. 즉, 제2 학습 데이터 셋(LDS2)은 ODD 지수의 오름차순으로 군집 샘플링된 제1 및 제2 데이터 셋들을 포함할 수 있다. 제3 학습 데이터 셋(LDS3)은 랜덤 샘플링(RND)에 의해 분류된 데이터 셋을 포함할 수 있다. 즉, 제3 학습 데이 터 셋(LDS3)은 랜덤 샘플링된 제1 및 제2 데이터 셋들을 포함할 수 있다. 제1 내지 제3 학습 데이터 셋들(LDS1, LDS2, LDS3)에서 훈련 그룹, 검증 그룹 및 테스트 그룹 간의 샘플링 비율 은, 70(%):10(%):20(%)일 수 있다. 하지만, 이에 한정되는 것은 아니다. 제1 내지 제3 학습 데이터 셋들(LDS1, LDS2, LDS3)은 알고리즘 그룹(AIG)에 제공될 수 있다. 알고리즘 그룹(AIG)은 복수의 인공 지능 알고리즘들(AI_A, AI_B, AI_C, AI_D)을 포함할 수 있다. 도 12b에서 4 종류의 인공 지능 알고리즘이 도시되어 있으나, 이에 한정되는 것은 아니다. 복수의 인공 지능 알고리즘들 (AI_A, AI_B, AI_C, AI_D)은 제1 내지 제3 학습 데이터 셋들(LDS1, LDS2, LDS3) 각각을 학습할 수 있다. 각 학습 데이터 셋에 대한 평가 지표가 추출될 수 있다. 평가 지표가 RMSE인 것을 가정하면, 복수의 인공 지능 알고리즘들(AI_A, AI_B, AI_C, AI_D) 각각을 통해 각 학습 데이터 셋에 대한 RMSE가 추출될 수 있다. 예를 들면, 각 알고리즘 별로, 테스트 RMSE와 검증 RMSE가 추출될 수 있다. 테스트 RMSE는 테스트 데이터에 대한 RMSE일 수 있다. 검증 RMSE는 검증 데이터에 대한 RMSE일 수 있다. 랜덤 샘플링(RND), OOD 지수 내림차순 군집 샘플링(DSD), 및 OOD 지수 오름차순 군집 샘플링(ASD) 각각의 테스 트 RMSE를 나타내는 그래프가 도 12b에 도시되어 있다. 한편, 테스트 데이터 및 검증 데이터 각각에 대한 평가 지표들 간의 비율이 추출될 수 있다. 예를 들면, 테스트 RMSE에 대한 검증 RMSE의 비율(도 12b에 도시된 \"Test RMSE/Valid RMSE\")이 각 인공 지능 알고리즘마다 추출될 수 있다. 랜덤 샘플링(RND), OOD 지수 내림차순 군집 샘플링(DSD), 및 OOD 지수 오름차순 군집 샘플링(ASD) 각 각의 비율(도 12b에 도시된 \"Test RMSE/Valid RMSE\")을 나타내는 그래프가 도 12b에 도시되어 있다. 한편, 테스트 RMSE와 비율(도 12b에 도시된 \"Test RMSE/Valid RMSE\")의 곱이, 각 인공 지능 알고리즘 및 각 샘 플링 방식(예, 랜덤 샘플링(RND), OOD 지수 내림차순 군집 샘플링(DSD), 및 OOD 지수 오름차순 군집 샘플링 (ASD))마다, 계산될 수 있다. 일부 실시예들에서, 복수의 인공 지능 알고리즘들(AI_A, AI_B, AI_C, AI_D) 중 전 술한 곱의 값이 가장 작은 인공 지능 알고리즘이 최적의 인공 지능 알고리즘으로 선택될 수 있다. 도 13a 및 도 13b는 최적의 인공 지능 알고리즘을 선택하는 다른 실시예들을 설명하기 위한 도면이다. 도 13a를 참조하면, 복수의 인공 지능 알고리즘들 각각으로부터 테스트 데이터에 대한 제1 평가 지표를 추출하 는 단계가 수행된다(S1310). 여기서, 테스트 데이터는 제1 및 제2 데이터 셋들에서 학습 데이터 셋의 테스트 그 룹으로 분류된 것일 수 있다. 이때, 학습 데이터 셋은, 예를 들면, 제1 내지 제3 학습 데이터 셋들(LDS1, LDS2, LDS3) 중 적어도 하나일 수 있다. 이하에서는, 학습 데이터 셋은 제1 학습 데이터 셋(LDS1) 또는 제2 학습 데이 터 셋(LDS2)인 것으로 가정한다. 제1 평가 지표는, 예를 들면, 테스트 RMSE(도 12b의 \"Test RMSE\" 참조)일 수 있다. 단계 S1310에 대한 실시예를 구체적으로 예를 들면, 테스트 데이터가 복수의 인공 지능 알고리즘들 각각에 적용 됨으로써, 복수의 인공 지능 알고리즘들 각각으로부터 제1 RMSE들이 추출될 수 있다. 복수의 인공 지능 알고리즘들 각각으로부터 검증 데이터에 대한 제2 평가 지표를 추출하는 단계가 수행된다 (S1320). 여기서, 검증 데이터는 제1 및 제2 데이터 셋들에서 학습 데이터 셋(예, LDS1 또는 LDS2)의 검증 그룹 으로 분류된 것일 수 있다. 제2 평가 지표는, 예를 들면, 검증 RMSE(도 12b의 \" Valid RMSE\" 참조)일 수 있다. 단계 S1320에 대한 실시예를 구체적으로 예를 들면, 검증 데이터가 복수의 인공 지능 알고리즘들 각각에 적용됨 으로써, 복수의 인공 지능 알고리즘들 각각으로부터 제2 RMSE들이 추출될 수 있다. 복수의 인공 지능 알고리즘들마다 제1 평가 지표에 대한 제2 평가 지표의 비율을 계산하는 단계가 수행된다 (S1330). 여기서, 비율은 \"제1 RMSE/제2 RMSE\", 또는 \"Test RMSE/Valid RMSE\" 등과 같은 수식으로 나타낼 수 있다. 복수의 인공 지능 알고리즘들 중 제1 평가 지표와 비율의 곱이 가장 작은 인공 지능 알고리즘을 최적의 인공 지능 알고리즘으로 선택하는 단계가 수행된다(S1340). 도 13b를 참조하면, 데이터 스플릿 조건(DSC')은 학습 데이터 셋(LDS)을 포함할 수 있다. 학습 데이터 셋(LDS) 은 OOD 지수의 순서에 따라 샘플링된 데이터 셋을 포함할 수 있다. 즉, 학습 데이터 셋(LDS)은 OOD 지수의 순서 에 군집 샘플링된 제1 및 제2 데이터 셋들을 포함할 수 있다. 예를 들면, 학습 데이터 셋(LDS)은 도 12b의 제1 학습 데이터 셋(LDS1) 또는 제2 학습 데이터 셋(LDS2)일 수 있다. 학습 데이터 셋(LDS)에서 훈련 그룹, 검증 그 룹 및 테스트 그룹 간의 샘플링 비율은, 70(%):10(%):20(%)일 수 있다. 하지만, 이에 한정되는 것은 아니다. 학 습 데이터 셋(LDS)은 알고리즘 그룹(AIG')에 제공될 수 있다. 알고리즘 그룹(AIG')은 복수의 인공 지능 알고리즘들(AI_A', AI_B', AI_C', AI_D')을 포함할 수 있다. 도 13b 에서 4 종류의 인공 지능 알고리즘이 도시되어 있으나, 이에 한정되는 것은 아니다. 복수의 인공 지능 알고리즘 들(AI_A', AI_B', AI_C', AI_D')은 학습 데이터 셋(LDS)을 학습할 수 있다. 복수의 인공 지능 알고리즘들(AI_A', AI_B', AI_C', AI_D') 각각을 통해 학습 데이터 셋(LDS)에 대한 RMSE가 추출될 수 있다. 예를 들면, 각 알고리즘 별로, 테스트 RMSE와 검증 RMSE가 추출될 수 있다. 테스트 RMSE는 테 스트 데이터에 대한 RMSE이며, 도 13a의 제1 RMSE로 지칭될 수 있다. 검증 RMSE는 검증 데이터에 대한 RMSE이며, 도 13a의 제2 RMSE로 지칭될 수 있다. 각 알고리즘에서의 테스트 RMSE를 나타내는 그래프가 도 13b에 도시되어 있다. 그리고, 테스트 RMSE에 대한 검 증 RMSE의 비율(도 13b에 도시된 \"Test RMSE/Valid RMSE\")이 각 인공 지능 알고리즘마다 추출될 수 있다. 각 알고리즘에서의 비율(도 12b에 도시된 \"Test RMSE/Valid RMSE\")을 나타내는 그래프가 도 13b에 도시되어 있다. 한편, 테스트 RMSE와 비율(도 12b에 도시된 \"Test RMSE/Valid RMSE\")의 곱(예, Test RMSE * (Test RMSE/Valid RMSE))이, 각 인공 지능 알고리즘마다, 계산될 수 있다. 복수의 인공 지능 알고리즘들(AI_A', AI_B', AI_C', AI_D') 중 전술한 곱의 값이 가장 작은 인공 지능 알고리즘이 최적의 인공 지능 알고리즘으로 선택될 수 있다. 도 14는 최적의 인공 지능 알고리즘을 선택하는 또 다른 실시예들을 설명하기 위한 도면이다. 도 14의 실시예들은, 기존 학습 데이터의 기준 값보다 큰 학습 영역을 벗어난 신규 스펙트럼 데이터에 대해 구 조를 예측하기 위한 것일 수 있다. 도 7, 도 13A 및 도 14를 참조하면, 단계 S1310에 대한 일부 실시예들에서, 학습된 반도체의 OOD 지수에 의해 결정되는 학습 영역 내에서 제1 RMSE(RMSE1)가 추출될 수 있다. 또한, 학습된 반도체의 OOD 지수에 의해 결정되는 학습 영역 외에서 제1 RMSE(RMSE1)를 추출될 수 있다. 도 7 및 도 14를 참조하여 예를 들면, 테스트(또는 블라인드 테스트)할 웨이퍼는 \"Blind test 웨이퍼 #6\", \"Blind test 웨이퍼 #7\", \"Blind test 웨이퍼 #8\"인 것으로 가정한다. 이 경우, \"Blind test 웨이퍼 #6\"는 학 습 영역 내에 포함되고, \"Blind test 웨이퍼 #7\" 및 \"Blind test 웨이퍼 #8\"은 학습 영역 외에 포함될 수 있다. 인공 지능 알고리즘의 종류는 4개인 것으로 가정한다. 각 알고리즘 별 제2 RMSE(RMSE2)는 1.06, 0.94, 0.80, 1.12으로 추출된 것으로 가정한다. 학습 영역 내에서 각 알고리즘 별 제1 RMSE(RMSE1)는, 2.21. 16.73, 1.03, 2.28로 추출된 것으로 가정한다. 학습 영역 외에서 각 알고리즘 별 제1 RMSE(RMSE1)는, 1.82. 14.60, 7.62, 1.60으로 추출된 것으로 가정한다. 인공 지능 알고리즘 A의 경우, \"Blind test 웨이퍼 #7\" 및 \"Blind test 웨이퍼 #8\"에 대한 실측값과 예측값이 \"Blind test 웨이퍼 #6\"보다 상대적으로 더 일치하는 경향을 나타낼 수 있다. 인공 지능 알고리즘 B의 경우, \"Blind test 웨이퍼 #6\", \"Blind test 웨이퍼 #7\" 및 \"Blind test 웨이퍼 #8\"에 대한 실측값과 예측값이 대체 적으로 일치하지 않는 경향을 나타낼 수 있다. 인공 지능 알고리즘 C의 경우, \"Blind test 웨이퍼 #6\"에 대한 실측값과 예측값이 \"Blind test 웨이퍼 #7\" 및 \"Blind test 웨이퍼 #8\"보다 상대적으로 더 일치하는 경향을 나 타낼 수 있다. 인공 지능 알고리즘 C는 \"Blind test 웨이퍼 #6\"에 적합할 수 있다. 인공 지능 알고리즘 D의 경 우, \"Blind test 웨이퍼 #7\" 및 \"Blind test 웨이퍼 #8\"에 대한 실측값과 예측값이 \"Blind test 웨이퍼 #6\"보 다 상대적으로 더 일치하는 경향을 나타낼 수 있다. 인공 지능 알고리즘 D는 \"Blind test 웨이퍼 #7\" 및 \"Blind test 웨이퍼 #8\"에 적합할 수 있다. 단계 S1340에 대한 일부 실시예들에서, 예측될 반도체의 OOD 지수에 따라, 학습 영역 내에서 제1 RMSE(RMSE1)와 비율(예, RMSE1/RMSE2)의 곱(예, RMSE1 * (RMSE1/RMSE2))이 가장 작은 제1 인공 지능 알고리즘이 최적의 인공 지능 알고리즘으로 선택되거나, 학습 영역 외에서 제1 RMSE(RMSE1)와 비율(예, RMSE1/RMSE2)의 곱(예, RMSE1 * (RMSE1/RMSE2))이 가장 작은 제2 인공 지능 알고리즘이 최적의 인공 지능 알고리즘으로 선택될 수 있다. 학습영역 내에서 제1 RMSE(RMSE1)와 비율(예, RMSE1/RMSE2)의 곱(예, RMSE1 * (RMSE1/RMSE2))이 가장 작은 인공 지 능 알고리즘은, 인공 지능 알고리즘 C일 수 있다. 그리고, 학습 영역 외에서 제1 RMSE(RMSE1)와 비율(예, RMSE1/RMSE2)의 곱(예, RMSE1 * (RMSE1/RMSE2))이 가장 작은 인공 지능 알고리즘은, 인공 지능 알고리즘 D일 수 있다. 이 경우, 최적의 인공 지능 알고리즘은 인공 지능 알고리즘 E일 수 있다. 즉, 반도체 별 계산된 OOD 지수 값을 활용하여, 학습 영역 내에서 적용 가능한 인공 지능 알고리즘 C가 자동으로 선택되거나, 학습 영역 외에서 적용 가능한 인공 지능 알고리즘 D가 자동으로 선택될 수 있다. 도 15는 본 개시의 예시적인 실시예들에 따른 시스템의 동작 방법을 설명하기 위한 개념도이다. 도 15를 참조하면, 시스템은 실측 계측 데이터 셋을 로딩할 수 있다(도 15의 1511 참조). 실측 계측 데이터 셋 은 제2 데이터 셋일 수 있다. 실측 계측 데이터 셋은 인공 지능 알고리즘의 입력(도 15의 \"입력 X(스펙트럼)\" 참조)에 이용될 수 있다. 시스템은 실측 스펙트럼 데이터 셋을 로딩할 수 있다(도 15의 1512 참조). 실측 스펙 트럼 데이터 셋은 제1 데이터 셋일 수 있다. 실측 스펙트럼 데이터 셋은 인공 지능 알고리즘의 출력(도 15의 \" 입력 Y(구조 계측)\" 참조)에 이용될 수 있다. 시스템은 실측 스펙트럼 데이터 셋을 기초로 PCA를 수행하여 스펙트럼의 주성분을 추출할 수 있다(도 15의 1521 참조). 스펙트럼의 주성분을 추출하는 실시예는 도 4를 참조하여 전술한 바와 같다. 시스템은 PCA를 통해 추출된 스펙트럼의 주성분들을 벡터화한다(도 15의 1522 참조). 스펙트럼의 주성분들을 포 함하는 벡터들은 도 5 및 도 6에 도시된 바와 같다. 시스템은 스펙트럼의 주성분들로 구성된 벡터들을 이용하여 OOD 지수를 계산한다(도 15의 1523 참조). OOD 지수 를 계산하는 실시예는 도 7을 참조하여 전술한 바와 같다. 시스템은 각 웨이퍼에 대한 OOD 지수들, 실측 계측 데이터 셋, 및 실측 스펙트럼 데이터 셋을 이용하여 데이터 스플릿을 수행할 수 있다(도 15의 1530 참조). 데이터 스플릿의 샘플링 방식은, 랜덤 샘플링, OOD 지수 내림차 순 군집 샘플링, 및 OD 지수 오름차순 군집 샘플링을 포함할 수 있다. 본 개시의 데이터 스플릿에 의하면, 복수 의 학습 데이터 셋들(1531, 1532, 1533)이 생성될 수 있다. 복수의 학습 데이터 셋들(1531, 1532, 1533)은 각 각 랜덤 샘플링, OOD 지수 내림차순 군집 샘플링, 및 OD 지수 오름차순 군집 샘플링 각각에 의해 구분되는 데이 터 셋들을 포함할 수 있다. 각 샘플링 방식에서 학습 데이터 셋의 훈련 그룹, 검증 그룹, 및 테스트 그룹 간의 비율은 7:1:2일 수 있다. 하지만, 이에 한정되는 것은 아니다. 데이터 스플릿에 대한 실시예는 도 9 내지 도 11c를 참조하여 전술한 바와 같다. 시스템은 적어도 하나의 학습 데이터 셋을 이용하여 최적의 알고리즘을 제공할 수 있다(도 15의 1540 참조). 여 기서, 알고리즘은 전술한 인공 지능 알고리즘에 해당된다. 구체적으로, 시스템은 적어도 하나의 학습 데이터 셋 을 복수의 알고리즘들(1541_1, 1541_2, 1541_N)에 학습시킬 수 있다. 알고리즘의 개수는 N개일 수 있다. N은 2 이상의 정수일 수 있다. 시스템은 학습 완료된 복수의 알고리즘들(1541_1, 1541_2, 1541_N)에 대한 모델 정합성 을 확인할 수 있다(도 15의 1542 참조). 여기서, 모델 정합성은, 테스트 데이터에 대한 RMSE(도 15의 \"RMSE@Test\" 참조)를 통해 확인될 수 있다. 모델 정합성을 확인하는 실시예는, 도 12a 내지 도 13b를 참조하여 전술한 바와 같다. 시스템은 학습 완료된 복수의 알고리즘들(1541_1, 1541_2, 1541_N)에 대한 모델 과적합성을 확인할 수 있다(도 15의 1543 참조). 여기서, 모델 과적합성은, 제1 RMSE에 대한 제2 RMSE의 비율(도 15의 \"RMSE@Test/RMSE@Valid\" 참조)를 통해 확인될 수 있다. 모델 과적합성을 확인하는 실시예는, 도 12a 내지 도 13b를 참조하여 전술한 바와 같다. 시스템은 학습 완료된 복수의 알고리즘들(1541_1, 1541_2, 1541_N) 각각의 모델 성능을 측정할 수 있다(도 15의 1544 참조). 여기서, 모델 성능은 모델 정합성과 모델 과적합성의 곱을 통 해 확인될 수 있다. 시스템은 학습 완료된 복수의 알고리즘들(1541_1, 1541_2, 1541_N) 중 가장 우수한 모델 성 능을 갖는 알고리즘을 최적의 알고리즘으로 제공한다. 가장 우수한 모델 성능은 모델 정합성과 모델 과적합성의 곱이 가장 작은 것일 수 있다. 한편, 시스템은 실시간 라인 스펙트럼 데이터를 측정할 수 있다(도 15의 1550 참조). 실시간 라인 스펙트럼 데 이터는, 도 1을 참조하여 예를 들면, 제1 측정 장치에 실측된 스펙트럼 데이터의 일부 또는 전부일 수 있 다. 시스템은 실시간 라인 스펙트럼 데이터에 대한 OOD 지수와 기준 값을 비교할 수 있다(도 15의 1561 참조). 여기 서, 실시간 라인 스펙트럼 데이터에 대한 OOD 지수는 정규화된 평균 값이고, 기준 값은 1일 수 있으나, 이에 한 정되는 것은 아니다. 실시간 라인 스펙트럼 데이터에 대한 OOD 지수가 기준 값보다 크면(도 15의 1561의 No 참조). 시스템은 기준 값 보다 큰 OOD 지수를 갖는 웨이퍼의 신규 실측 계측 데이터를 획득할 수 있다(도 15의 1562 참조). 신규 실측 계 측 데이터는, 도 1을 참조하여 예를 들면, 제2 측정 장치에 실측된 구조 계측 데이터일 수 있다. 신규 실 측 계측 데이터는 실측 계측 데이터 셋에 병합될 수 있다. 시스템은 신규 스펙트럼 데이터를 획득할 수 있다(도 15의 1563 참조). 신규 스펙트럼 데이터는 도 1을 참조하 여 예를 들면, 제1 측정 장치에 실측된 스펙트럼 데이터일 수 있다. 신규 스펙트럼 데이터는 실측 스펙트 럼 데이터 셋에 병합될 수 있다. 실시간 라인 스펙트럼 데이터에 대한 OOD 지수가 기준 값보다 작으면(도 15의 1561의 Yes 참조). 시스템은 최적 의 알고리즘을 통해 라인 스펙트럼 데이터로부터 반도체의 구조를 실시간 예측한다(도 15의 1570 참조). 시스템에 의해 수행되는, 최적의 인공 지능 알고리즘을 토해 실시간 라인 스펙트럼 데이터로부터 반도체의 구조 를 예측하는 동작과, 최적의 인공 지능 알고리즘을 제공하는 동작이 순환되거나 반복될 수 있다(도 15의 1580 참조). 전술한 비율(도 15의 \"RMSE@Test/RMSE@Valid\" 참조)과 를 통해 확인될 수 있다. 모델 과적합성을 확인하는 실시 예는, 도 12a 내지 도 13b를 참조하여 전술한 바와 같다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다. 본 개시의 범위 또는 기술적 사상을 벗어나지 않고 본 개시의 구조가 다양하게 수정되거나 변경될 수 있음은 이 분야에 숙련된 자들에게 자명하다. 상술한 내용을 고려하여 볼 때, 만약 본 개시의 수정 및 변경이 아래의 청구 항들 및 동등물의 범주 내에 속한다면, 본 개시가 이 발명의 변경 및 수정을 포함하는 것으로 여겨진다. 이상에서와 같이 도면과 명세서에서 예시적인 실시예들이 개시되었다. 본 명세서에서 특정한 용어를 사용하여 실시예들을 설명되었으나, 이는 단지 본 개시의 기술적 사상을 설명하기 위한 목적에서 사용된 것이지 의미 한"}
{"patent_id": "10-2022-0186011", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "정이나 특허청구범위에 기재된 본 개시의 범위를 제한하기 위하여 사용된 것은 아니다. 그러므로 본 기술분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라 서, 본 개시의 진정한 기술적 보호범위는 첨부된 특허청구범위의 기술적 사상에 의해 정해져야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9 도면10a 도면10b 도면10c 도면11a 도면11b 도면11c 도면12a 도면12b 도면13a 도면13b 도면14 도면15"}
{"patent_id": "10-2022-0186011", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적인 실시예들에 따른 시스템을 설명하기 위한 도면이다. 도 2는 본 개시의 예시적인 실시예들에 따른 인공 지능 알고리즘의 동작 방법을 설명하기 위한 흐름도이다. 도 3은 본 개시의 예시적인 실시예들에 따른 최적의 인공 지능 알고리즘을 제공하는 방법을 설명하기 위한 흐름 도이다. 도 4는 본 개시의 예시적인 실시예들에 따른 OOD 지수를 계산하는 단계를 설명하기 위한 흐름도이다. 도 5는 본 개시의 예시적인 실시예들에 따른 PCA 맵을 나타낸 도면이다. 도 6은 도 5에 도시된 PCA 맵에서 유클리드 거리와 코사인 거리를 설명하기 위한 도면이다. 도 7은 반도체 별 유클리드 거리와 코사인 거리의 곱의 평균값을 예시적으로 나타낸 도면이다. 도 8a 및 도 8b는 웨이퍼 별 정규화된 OOD 지수의 평균 값과 특정 예측 모델의 다양한 평가 지표 오차들 간의 상관도를 예시적으로 나타낸 도면이다. 도 9는 본 개시의 예시적인 실시예들에 따른 데이터 스플릿을 수행하는 단계를 설명하기 위한 흐름도이다. 도 10a, 도 10b, 및 도 10c는 OOD 지수의 내림차순으로 데이터를 군집 샘플링하는 실시예를 설명하기 위한 도면 이다. 도 11a, 도 11b, 및 도 11c는 OOD 지수의 오름차순으로 데이터를 군집 샘플링하는 실시예를 설명하기 위한 도면 이다. 도 12a 및 도 12b는 최적의 알고리즘을 선택하는 일부 실시예들을 설명하기 위한 도면이다. 도 13a 및 도 13b는 최적의 알고리즘을 선택하는 다른 실시예들을 설명하기 위한 도면이다. 도 14는 최적의 알고리즘을 선택하는 또 다른 실시예들을 설명하기 위한 도면이다. 도 15는 본 개시의 예시적인 실시예들에 따른 시스템의 동작 방법을 설명하기 위한 개념도이다."}
