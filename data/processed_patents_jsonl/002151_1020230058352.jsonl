{"patent_id": "10-2023-0058352", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0161741", "출원번호": "10-2023-0058352", "발명의 명칭": "인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 시스템 및 방법", "출원인": "충북대학교 산학협력단", "발명자": "김성훈"}}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영상 데이터를 전처리하기 위한 전처리부;전처리된 영상 데이터를 증강시키는 데이터 증강(data augmentation) 과정을 수행하기 위한 데이터 증강부;증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하기 위한 극 좌표계 변환부; 및극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을 통해 학습을 진행하고, 컨택트렌즈의 불량을검출하기 위한 AI 학습부를 포함하는 콘택트렌즈 제조 공정에서의 불량 검출 시스템."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델인 것을 특징으로 하는 콘택트렌즈 제조 공정에서의 불량검출 시스템."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델인 것을 특징으로 하는 콘택트렌즈 제조 공정에서의 불량 검출 시스템."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델인 것을 특징으로 하는 콘택트렌즈 제조 공정에서의 불량 검출 시스템."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "에 있어서, 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델인 것을 특징으로 하는 콘택트렌즈 제조 공정에서의 불량검출 방법."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델인 것을 특징으로 하는 콘택트렌즈 제조 공정에서의 불량 검출 방법."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델인 것을 특징으로 하는 콘택트렌즈 제조 공정에서의 불량 검출 방법."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "콘택트렌즈 제조 공정에서의 불량 검출 방법을 컴퓨터로 실행시킬 수 있는 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체에서, 불량 검출 시스템에서 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영상 데이터를 전처리하는 단계;상기 불량 검출 시스템에서 전처리된 영상 데이터를 증강시키는 데이터 증강(data augmentation) 과정을 수행하는 단계;상기 불량 검출 시스템에서 증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하는 단계; 및상기 불량 검출 시스템에서 극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을 통해 학습을 진행하고, 컨택트렌즈의 불량을 검출하는 단계를 포함하는 방법을 컴퓨터로 실행시킬 수 있는 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서, 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델인 것을 특징으로 하는 방법을 컴퓨터로 실행시킬 수 있는프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델인 것을 특징으로 하는 방법을 컴퓨터로 실행시킬 수 있는 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0058352", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2024-0161741-4-청구항 11에 있어서, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델인 것을 특징으로 하는 방법을 컴퓨터로 실행시킬수 있는 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 콘택트렌즈 제조 공정에서의 불량 검출 시스템에 관한 것으로서, 콘택트렌즈 제조 공정에서 촬영된 콘 택트렌즈의 원본 영상 데이터를 전처리하기 위한 전처리부, 전처리된 영상 데이터를 증강시키는 데이터 증강 (data augmentation) 과정을 수행하기 위한 데이터 증강부, 증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평 면으로 변환하기 위한 극 좌표계 변환부 및 극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을 통 해 학습을 진행하고, 컨택트렌즈의 불량을 검출하기 위한 AI 학습부를 포함한다. 본 발명에 의하면, 인공지능을 이용하여 콘택트렌즈 제조 공정에서의 불량을 검출함으로써, 콘택트렌즈 제조 공 정에서 보다 정확하고 신속하게 불량 여부를 검출하고, 제조 공정 상에서 소모되는 인력과 시간을 절감하고, 생 산성을 향상시킬 수 있는 효과가 있다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 콘택트렌즈 제조 공정에서의 불량 검출 기술에 관한 것으로서, 더욱 상세하게는 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 기술에 관한 것이다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "4차 산업혁명의 핵심기술 중 하나인 인공지능(AI, Artificial Intelligence)은 조직의 비용을 절감하고 서비스 품질, 조정, 생산성을 향상시키는 수단이 되었다. 또한, 인공지능은 지난 30년간 가장 혁신적인 기술이라는 평 가를 받고 있으며 산업계에 폭넓은 변화를 가져올 것으로 예상된다. 특히, 컴퓨터가 데이터로부터 학습을 통하 여 특정한 기능을 수행할 수 있는 머신 러닝(Machine Learning)의 발전으로 인공지능 연구는 폭넓은 분야에 걸 쳐 적용이 되고 있다. 제조 산업의 품질검사에 대해서도 인공지능을 도입하여 공정의 효율성을 높일 수 있다. 기존의 머신 비전 (Machine Vision) 기술에 인공지능 기술이 더해진 AI 비전검사를 통해 제품에 대한 검사를 좀더 정확하고 효율 적으로 진행할 수 있다. 검사과정에서 획득한 제품 영상 데이터를 통해 자동으로 양품과 불량품을 구별해 낼 수 있으며, 이러한 기술은 수작업으로 이루어지는 검사 공정과 비교하면 더 빠르고 효율적으로 검사를 진행할 수 있도록 한다. 이러한 인공지능 기술이 수요기업에 적용될 경우, 다양한 개선효과를 기대할 수 있을 뿐만 아니라, 수요기업의 생산성과 불량율에 직접적으로 연관되며, 따라서 제조 산업에서의 인공지능 기술은 통상의 인공지능 기술과는 달리 고신뢰성, 고정밀성, 실시간성을 요구하는 제조 현장에 적용 가능한 기술이어야 한다. 콘택트렌즈 제조 공정에서 영상 촬영 장비를 이용하여 제품의 불량을 검사하는 공정이 필수적이며, 이러한 검사 공정은 콘택트렌즈 제조 과정에서 발생한 결함을 영상 촬영 장비를 통하여 검출하는 과정으로서, 콘택트렌즈 제 품 포장 및 출하 바로 직전 단계에서 수행된다. 따라서 검사 공정에서는 높은 수준의 검사의 신뢰성, 실시간성, 정확성 등이 요구된다. 도 1은 콘택트렌즈 제조 공정에서 콘택트렌즈 영상 데이터의 불량 판정 기준을 도식화한 것이다. 도 1에서 콘택트렌즈 제조 공정에서 물이 담긴 용기에 콘택트렌즈를 투입한 후, 조명을 통제하여 촬영하는 방식 으로 콘택트렌즈 영상 데이터를 획득할 수 있다. 도 1을 참조하면, 물방울(air bubble)이 발생하는 콘택트렌즈 영상 데이터는 큰 문제가 없지만, 영상 데이터에 서 기포(bubble)와 에지(edge)로 분류되는 객체가 존재할 경우 해당 생산품은 불량으로 처리된다. 도 2는 콘택트렌즈 영상 데이터에서 불량 판정을 위한 검출 대상 객체를 예시한 것이다. 도 2의 (a)에서 콘택트렌즈 영상 촬영시 일시적으로 생성된 공기방울이 존재하는 경우로서, 양품으로 분류한다. (b)에서 콘택트렌즈 제작 중 공기가 침투하여 발생하는 기포(n_bubble)이며, 결함으로 검출해야 할 객체이다. (a)에서 원형 안쪽이 난반사로 인하여 명암이 뚜렷하게 발생하는 반면, (b)에서 속이 비어 있는 도넛의 형태를 띄게 된다. (c)는 콘택트렌즈 제작 시, 원료액이 부족하여 발생하는 결함으로서 주로 콘택트렌즈의 외곽 부분을 따라 존재 한다(b_bubble). (d)는 일반적인 에지 결함의 형태로서 콘택트렌즈의 가장자리가 뜯어진 경우(n_edge)이며, (e)는 렌즈 내부까지 찢어진 경우(b_edge)이고, (f)는 주로 2~4 픽셀(pixel) 사이의 미세하게 끊어진 형태이다 (i_edge). (d),(e),(f)의 경우 모두 결함으로써 검출해야 할 객체이다. 콘택트렌즈 영상 데이터에서 어떠한 객 체도 발견되지 않는 경우, 양품으로 분류한다. 콘택트렌즈 제조 과정에서 동일한 생산품이 반복적으로 생산되는 특징상 유사한 배경을 지니게 되지만, 촬영 시 명암 등 카메라 상태의 변화와 설비 떨림 등 상태의 변화와 같은 제조 환경의 변화가 일어날 수 있다. 이로 인 해 콘택트렌즈 영상 데이터의 결함 특성은 매우 다양한 형태로 나타나게 된다. 따라서 이들 제조 환경 변화에 견고하게 작동할 수 있는 콘택트렌즈 영상에서 발생하는 에지 결함을 검출하는 기법이 요구된다.컴퓨터를 활용한 영상 데이터의 분석기법 중 이목이 집중되고 있는 분야가 머신 러닝(machine learning)의 한 분야인 딥 러닝(deep learning)을 이용한 방법이다. 머신 러닝은 알고리즘을 이용해 데이터 특성을 분석하고, 이를 통해 학습하며, 학습한 내용을 기반으로 판단이나 예측을 하는 기법을 말한다. 딥 러닝은 여러 층을 가진 인공신경망(Artificial Neural Network)을 사용하여 학습을 수행하는 방법이다. 기존의 머신 러닝 연구 방식에 서는 특징을 사람이 직접 추출하였지만, 딥 러닝을 사용할 경우, 인공신경망 내에서 이들 특징을 추출하여 학습 하기 때문에 시간적인 노력을 대폭 줄일 수 있고, 오류가 반영될 가능성을 줄일 수 있다는 장점이 있다. 특히 딥 러닝의 많은 분야 중 CNN(Convolutional Neural Network)계열의 인공신경망은 영상처리분야에서 뛰어난 성능 을 보여 각광을 받고 있다. 이러한 CNN으로 대표되는 딥러닝 기반 영상분석은 그 목적에 따라서 분류(classification), 객체 검출(object detection) 등으로 나눌 수 있다. 분류는 영상 내의 단일 객체의 클래스를 분류하는 방법을 말하며, 객체 검출 은 다중 객체의 클래스를 분류하고 위치를 검출하는 기법을 말한다. 대표적으로 사용되고 있는 딥러닝 기반의 객체 검출 기법에는 YOLO(You Only Look Once), Faster-RCNN, SSD(Single shot multibox detector)등이 있다. 하지만, 이러한 방법들은 통상적으로 일정수준 이상의 성과를 나타내고 있으나, 제조 공정 등의 높은 정확성을 요구하는 경우에는 바로 적용하기에 부적합하다. 특히, 콘택트렌즈 제조 공정에서 도넛 형태의 특성을 항상 나 타내는 기포 결함에 비하여 에지 결함의 경우 크기와 모양이 매우 다양하여 검출율이 상대적으로 저조하다. 에 지 결함은 콘택트렌즈의 원형 가장자리에서 발생한다는 위치적인 특성을 지니고 있으며, 원형의 패턴이 변형됨 으로써 발생한다. 하지만, 기존의 객체 검출 기법은 이러한 특징을 검출하는데 있어 불리하다. 에지 결함 자체 의 공통된 특성이 존재한다기보다는 원형 가장자리의 패턴에서부터 생성되는 형태이기 때문에 기존의 특징 추출 방법으로는 효율적으로 이를 검출해낼 수 없다는 문제가 있다. 도 3은 콘택트렌즈 제조 공정에서 반복 패턴을 나타내는 에지 불량 특성을 이용한 검출 방식을 설명하기 위한 도면이다. 도 3을 참조하면, 콘택트렌즈 제조 공정에서 에지 불량의 경우, 유사한 배경이 반복적으로 생산되는 영상 데이 터의 특성상, 배경 패턴에서 나타나는 특성을 이용하여 불량 검출에 접근한다면 더 나은 결과를 얻을 수 있다. 콘택트렌즈의 경우, 크기와 형태가 유사한 원형의 가장자리를 가지고 있으며, 에지 결함의 경우 이 가장자리에 걸쳐서 형성된다는 특징을 지닌다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 10-2262016"}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명은 인공지능을 이용하여 콘택트렌즈 제조 공정에서 획득하는 영상 데이터를 분석하여 다수의 결함의 위치와 종류를 검출할 수 있는 불량 검출 시스 템 및 방법을 제공하는데 그 목적이 있다. 본 발명의 목적은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이와 같은 목적을 달성하기 위한 본 발명은 콘택트렌즈 제조 공정에서의 불량 검출 시스템에 관한 것으로서, 콘 택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영상 데이터를 전처리하기 위한 전처리부, 전처리된 영상 데 이터를 증강시키는 데이터 증강(data augmentation) 과정을 수행하기 위한 데이터 증강부, 증강된 데이터를 직 교 좌표계 평면에서 극 좌표계 평면으로 변환하기 위한 극 좌표계 변환부 및 극 좌표계 평면으로 변환된 데이터 에 대해 인공지능 학습 모델을 통해 학습을 진행하고, 컨택트렌즈의 불량을 검출하기 위한 AI 학습부를 포함한다. 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델일 수 있다. 또한, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델일 수 있다. 또한, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델일 수 있다. 본 발명의 콘택트렌즈 제조 공정에서의 불량 검출 방법에서, 불량 검출 시스템에서 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영상 데이터를 전처리하는 단계, 상기 불량 검출 시스템에서 전처리된 영상 데이터를 증강시키는 데이터 증강(data augmentation) 과정을 수행하는 단계, 상기 불량 검출 시스템에서 증강된 데이터 를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하는 단계 및 상기 불량 검출 시스템에서 극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을 통해 학습을 진행하고, 컨택트렌즈의 불량을 검출하는 단계를 포함 한다. 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델일 수 있다. 또한, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델일 수 있다. 또한, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델일 수 있다. 본 발명의 콘택트렌즈 제조 공정에서의 불량 검출 방법을 컴퓨터로 실행시킬 수 있는 프로그램을 기록한 컴퓨터 로 읽을 수 있는 기록매체에서, 불량 검출 시스템에서 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영 상 데이터를 전처리하는 단계, 상기 불량 검출 시스템에서 전처리된 영상 데이터를 증강시키는 데이터 증강 (data augmentation) 과정을 수행하는 단계, 상기 불량 검출 시스템에서 증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하는 단계 및 상기 불량 검출 시스템에서 극 좌표계 평면으로 변환된 데이터에 대해 인 공지능 학습 모델을 통해 학습을 진행하고, 컨택트렌즈의 불량을 검출하는 단계를 포함한다. 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델일 수 있다. 또한, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델일 수 있다. 또한, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델일 수 있다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 인공지능을 이용하여 콘택트렌즈 제조 공정에서의 불량을 검출함으로써, 콘택트렌즈 제조 공 정에서 보다 정확하고 신속하게 불량 여부를 검출하고, 제조 공정 상에서 소모되는 인력과 시간을 절감하고, 생 산성을 향상시킬 수 있는 효과가 있다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하 고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 갖고 있다. 일반 적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 갖는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미 로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부 여하고 이에 대한 중복되는 설명은 생략하기로 한다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체 적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 본 발명은 콘택트렌즈 제조 공정에서의 불량 검출 시스템에 관한 것으로서, 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영상 데이터를 전처리하기 위한 전처리부, 전처리된 영상 데이터를 증강시키는 데이터 증강 (data augmentation) 과정을 수행하기 위한 데이터 증강부, 증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하기 위한 극 좌표계 변환부 및 극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을통해 학습을 진행하고, 컨택트렌즈의 불량을 검출하기 위한 AI 학습부를 포함한다. 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델일 수 있다. 또한, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델일 수 있다. 또한, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델일 수 있다. 본 발명의 콘택트렌즈 제조 공정에서의 불량 검출 방법에서, 불량 검출 시스템에서 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영상 데이터를 전처리하는 단계, 상기 불량 검출 시스템에서 전처리된 영상 데이터를 증강시키는 데이터 증강(data augmentation) 과정을 수행하는 단계, 상기 불량 검출 시스템에서 증강된 데이터 를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하는 단계 및 상기 불량 검출 시스템에서 극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을 통해 학습을 진행하고, 컨택트렌즈의 불량을 검출하는 단계를 포함 한다. 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델일 수 있다. 또한, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델일 수 있다. 또한, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델일 수 있다. 본 발명의 콘택트렌즈 제조 공정에서의 불량 검출 방법을 컴퓨터로 실행시킬 수 있는 프로그램을 기록한 컴퓨터 로 읽을 수 있는 기록매체에서, 불량 검출 시스템에서 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영 상 데이터를 전처리하는 단계, 상기 불량 검출 시스템에서 전처리된 영상 데이터를 증강시키는 데이터 증강 (data augmentation) 과정을 수행하는 단계, 상기 불량 검출 시스템에서 증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하는 단계 및 상기 불량 검출 시스템에서 극 좌표계 평면으로 변환된 데이터에 대해 인 공지능 학습 모델을 통해 학습을 진행하고, 컨택트렌즈의 불량을 검출하는 단계를 포함한다. 상기 인공지능 학습 모델은 머신러닝 기반 학습 모델일 수 있다. 또한, 상기 머신러닝 기반 학습 모델은 딥러닝 기반 학습 모델일 수 있다. 또한, 상기 딥러닝 기반 학습 모델은 CNN 인공신경망 기반 학습 모델일 수 있다. 도 4는 본 발명의 일 실시예에 따른 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 시스템의 구성을 개략적으로 도시한 블록도이다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 시스 템은 전처리부, 데이터 증강부, 극 좌표계 변환부, AI 학습부를 포함한다. 전처리부는 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 영상 데이터를 전처리하는 역할을 한다. 본 발명의 일 실시예에서 전처리부는 가우시안 블러 과정, 적응형 이진화 과정, 허프 원 검출(Hough circle detection) 알고리즘 수행 과정, 관심 영역 추출 과정을 포함한다. 데이터 증강부는 전처리된 영상 데이터를 증강시키는 데이터 증강(data augmentation) 과정을 수행한다. 극 좌표계 변환부는 증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하는 역할을 한다. AI 학습부는 극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을 통해 학습을 진행하고, 컨택 트렌즈의 불량을 검출한다. 본 발명의 일 실시예에서 AI 학습부는 머신러닝 기반 학습 모델을 통해 학습을 진행할 수 있다. 보다 구체 적으로 AI 학습부는 딥러닝 기반 학습 모델을 통해 학습을 진행할 수 있다. 보다 구체적으로 AI 학습부 는 CNN 인공신경망 기반 학습 모델을 통해 학습을 진행할 수 있다. 본 발명의 일 실시예에서 극 좌표계 변환부는 인공지능 학습을 위해, 극 좌표계 평면으로 변환한 데이터를 검증 데이터셋(Validation Dataset)과 학습 데이터셋(Training Dataset)으로 분리할 수 있다. 그리고, AI 학습부는 검증 데이터셋과 학습 데이터셋을 입력으로 하여 인공지능 학습 모델을 통해 학습을 진행할 수 있다. 도 5는 본 발명의 일 실시예에 따른 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 방법을 도시한 흐름도이고, 도 6은 본 발명의 일 실시예에 따른 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 방 법에서 전처리 과정을 도시한 흐름도이다. 도 5 및 도 6을 참조하면, 콘택트렌즈 제조 공정에서의 불량 검출 시스템은 콘택트렌즈 제조 공정에서 촬영된 콘택트렌즈의 원본 이미지를 전처리한다(S110). 본 발명의 일 실시예에서 전처리 하는 단계(S110)는 가우시안 블러 단계(S111), 적응형 이진화 단계(S113), 허 프 원 검출 알고리즘 수행 단계(S115), 관심 영역 추출 단계(S117)를 포함한다. 그리고, 전처리된 영상 데이터를 증강시키는 데이터 증강(data augmentation) 과정을 수행한다(S120). 그리고, 증강된 데이터를 직교 좌표계 평면에서 극 좌표계 평면으로 변환하는 극 좌표계 변환 단계를 수행한다 (S130). 그리고, 극 좌표계 평면으로 변환된 데이터에 대해 인공지능 학습 모델을 통해 학습을 AI 학습 단계를 진행하고 (S140), 컨택트렌즈의 불량을 검출한다(S150). 본 발명의 일 실시예에서 AI 학습 단계(S140)는 머신러닝 기반 학습 모델을 통해 학습을 진행할 수 있다. 보다 구체적으로 AI 학습 단계(S140)는 딥러닝 기반 학습 모델을 통해 학습을 진행할 수 있다. 보다 구체적으로 AI 학습 단계(S140)는 CNN 인공신경망 기반 학습 모델을 통해 학습을 진행할 수 있다. 본 발명의 일 실시예에서 극 좌표계 변환 단계(S130)에서 인공지능 학습을 위해, 극 좌표계 평면으로 변환한 데 이터를 검증 데이터셋(Validation Dataset)과 학습 데이터셋(Training Dataset)으로 분리할 수 있다. 그리고, AI 학습 단계(S140)에서 검증 데이터셋과 학습 데이터셋을 입력으로 하여 인공지능 학습 모델을 통해 학습을 진행할 수 있다. 본 발명에서는 콘택트렌즈 영상에서 발생하는 불량 에지 결함이 렌즈 가장자리를 따라서 형성된다는 특징을 이 용하여, 원형의 형태를 지닌 콘택트렌즈 가장자리를 단순화해서 분석하는 방안을 제안한다. 이를 위하여 본 발 명에서는 콘택트렌즈 영상 데이터를 전처리한 후, 극 좌표계 평면으로 영상을 변환하여 분석하는 방법을 제안한 다. 본 발명에서 콘택트렌즈 제조 공정 중에서 카메라를 이용하여 콘택트렌즈 원본 영상 데이터를 촬영할 수 있다. 예를 들어, 콘택트렌즈 원본 영상 데이터는 카메라로부터 촬영된 영상으로서, 조명을 달리하며 촬영된 2장의 영 상이 1쌍을 이루고 있으며, 각각 2048 × 2448 픽셀의 크기를 지닌 1채널의 그레이 스케일 영상 데이터일 수 있 다. 예를 들어, 기본적인 조명에서 촬영된 영상은 주로 기포의 검출에 유리한 특성을 지니고 있고, 공기방울과 기포의 특징 역시 명확하게 차이가 발생하며, 반전시킨 조명에서의 촬영된 영상은 주로 에지 결함의 특징에 대 하여 판단에 용이하도록 촬영된다는 특징을 지니고 있다. 따라서, 2개의 영상 모두 분석에 필요한 특징을 담고 있으므로, 이를 적절히 결합하는 과정이 필요하다. 본 발명에서 수집된 원본 영상 데이터에 대한 전처리는 가우시안 블러, 적응형 이진화, 허프 원 검출 알고리즘, 관심영역추출, 영상결합으로 이루어져 있으며, 주로 불필요한 배경을 제거하고 관심 영역을 특정시키는데 중점 을 두고 있다. 관심 영역이 특정되면, 해당 영역만 추출하여 분석에 사용한다. 전처리된 데이터는 콘택트렌즈에 서 발생하는 불량 클래스 균형을 맞추기 위하여 데이터 증강을 실행한다. 이후, 원형으로 이루어진 가장자리의 특성을 극대화하기 위하여 직교 좌표 평면에서 극 좌표 평면으로 영상데이터를 변형한다. 본 발명에서 제안된 딥러닝 모델은 극 좌표계 영상데이터를 효율적으로 분석하도록 설계된 모델로서, 기존의 YOLOv5 모델 구조을 기 반으로 수정된 모델 구조로 설계된다. 본 발명에서 하나의 콘택트렌즈를 촬영한 두 유형의 영상데이터에 대한 관심 영역 추출을 위한 전처리 작업과 데이터 증강 작업을 수행한다. 관심 영역 추출은 두 유형의 영상 데이터에서 불필요한 배경을 제거하며, 분석의 대상이 되는 콘택트렌즈가 위치한 영역을 특정하는데 집중하기 위해 수행된다. 데이터 증강 작업은 영상에 결함 을 표시하는 과정과 영상에서 발생하는 결함의 클래스 불균형이 존재할 경우, 이를 해소하기 위한 과정으로 구 성된다. 도 7은 본 발명의 일 실시예에 따른 콘택트렌즈 영상 데이터에 대한 전처리 과정을 도시한 것이다. 도 7은 두 유형의 콘택트렌즈 원본 영상 데이터를 이용하여 불량을 효율적으로 검출하기 위해 관심 영역을 추출하는 과정 을 나타낸 것이다. 도 7을 참조하면, 전처리 과정은 우선 두 영상 데이터에 대해 가우시안 불러(Gaussian blur)를 통해 영상에서 발생하는 잡음을 제거하고, 적응적 이진화(adaptive binarization)와 허프 원 검출(Hough circle detection)을 통해 관심 영역을 추출하고, 두 영상을 하나로 통합한다. 이렇게 전처리된 데이터는 딥러닝 학습 모델의 입력으 로 사용된다. 가우시안 블러는 필터링 대상 픽셀과 인접 픽셀들이 모두 같은 가중치를 사용하여 평균치를 계산하는 평균값 필 터의 단점을 보완한 방법으로, 가까운 픽셀에는 큰 가중치를 두고, 멀리 있는 픽셀에는 작은 가중치를 사용하여 잡음을 제거하는 방법이다. 적응형 이진화는 영상의 하나의 픽셀에 대하여 인접 픽셀 영역을 설정한 후, 해당 영역내에서 임계치를 따로 적 용하는 방식으로서, 모든 픽셀에 대하여 이러한 과정을 수행하면 지역적인 밝기를 고려한 이진화가 수행된다. 본 발명에서 허프 원 검출 알고리즘을 적용하여, 콘택트렌즈의 경계를 나타나는 원을 표현할 수 있다. 본 발명에서 영상을 이진화시켜 경계선을 추출한 영상 데이터에서 허프 원 알고리즘을 이용하여 원형을 검출할 수 있다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, (xI, yI)은 경계선상의 픽셀을 나타내고, H는 원을 나타낸다. (xI, yI)가 H로 나타내어지는 원에 위치해 있다면, 1을 반환하고, 반환 값들을 누적시킨 것이 원으로 검출되는 알고리즘이며, 이때 (x0, y0,r)은 원의 중심 과 반지름을 각각 나타낸다. 본 발명에서 콘택트렌즈의 가장자리가 원형이기 때문에 이 특성을 이용하여 렌즈 외부의 배경과, 분석대상이 되는 관심 영역(ROI, Region Of Interest)을 구분할 수 있다. 본 발명에서 허프 원 검출 알고리즘을 수행한 후 관심 영역을 추출하는 과정이 수행된다. 이는 원본 영상 데이 터 2048×2448 픽셀을 대상으로, 전처리를 통해 찾아낸 원의 중심 좌표 값과 반지름을 사용하여 관심 영역을 추 출한다. 이때, 반지름은 영상 데이터마다 약간의 차이는 있지만 대부분 780픽셀로 측정되며, 상하좌우 여백은 40픽셀을 설정하여 여유를 둔다. 해당 과정을 진행한 후, 데이터는 일괄적으로 크기를 조절하여 1500×1500 픽 셀의 정사각형 형태로 변환한다. 이 과정에서 반지름은 715픽셀, 여백은 36픽셀 정도로 조정되며, 불필요한 배 경을 제거한 상태가 된다. 또한 본 발명에서는 이 과정에서 오리지널 데이터를 채널방향으로 합성하여 2채널의 영상을 생성하는데, RGB(Red, Green, Blue)로 구성된 채널 중, Blue 채널에 반전 조명 영상을 사용하고, Green 채널에 기본 조명 영상을 사용하고, Red채널은 사용하지 않는다. 본 발명에서 전처리를 통하여 추출된 영상 데이터에 대하여 불량 객체 레이블링(labeling) 작업을 수행한다. 불 량 객체 레이블링 작업이란 인공지능이 학습할 수 있는 형태로 데이터를 가공하고 구축하는 작업을 뜻한다. 본 발명에서 불량 객체의 종류와 불량 객체가 존재하는 위치에 대한 정보를 특정하는 것이 되며, 위치정보는 좌 상 단과 우 하단의 x, y 좌표를 통하여 특정된다. 불량 검출 대상이 되는 결함클래스에 대한 불균형이 존재할 경우, 데이터 증강 작업이 필요하다. 어느 특정 클 래스가 대다수를 차지하고 있을 경우, 인공지능 학습 모델은 소수의 클래스를 무시하는 형태로 학습될 가능성이 높다. 소수의 클래스를 무시하더라도 다수의 클래스에 대한 적중을 높이는 것이 전체 성능이 높기 때문이다. 따 라서, 이러한 불량 객체 클래스 불균형문제가 존재하면 만족할 만한 분석결과를 얻을 수가 없다. 따라서, 본 발명에서는 불량 객체 클래스에 대한 균형을 확인하여 소수의 클래스에 대한 증강 작업을 실시한다. 우선, 상하좌우의 플립(flip)을 통하여 데이터의 양을 4배로 증강시키고, 그후 45도씩의 회전(rotation)시킨 데 이터를 추가한다. 이때, 90도, 180도 구간과 270도 구간은 데이터가 플립에 의하여 데이터가 중복되므로 제외하 고, 4배의 증강을 실행하였다. 이러한 데이터 증강 과정은 모든 데이터에 대하여 행해진 것이 아니며, 소수의 불량 객체 클래스가 포함 되어 있는 데이터에 한해서만 실행된다. 콘택트렌즈 영상데이터에서 발생하는 에지 결함의 특성을 살펴보면, 콘택트렌즈 가장자리는 원형으로 형성되고, 에지 결함은 이 가장자리에서 의존적으로 발생한다는 것이다. 따라서 콘택트렌즈의 가장자리를 중점적으로 분석 할 수 있는 방법이 필요하다. 이를 위하여, 본 발명에서는 극 좌표 평면으로의 변환을 통하여 콘택트렌즈의 가 장자리를 직선으로 단순화한다. 이를 통해 에지 결함이 발생하는 경우, 직선에서 이탈하는 형태를 띄기 때문에 쉽게 특성을 파악할 수 있다. 또한, 변환된 영상을 분해하고, 재결합하여 공간정보를 확대할 수 있다. 이를 통 하여 분석에 사용할 수 있는 정보의 양을 늘릴 수 있다. 도 8은 직교 좌표 평면과 극 좌표 평면을 예시한 것이다. 도 8을 참조하면, 직교 좌표 평면상의 픽셀 (i,j)은 극 좌표 변환 수식을 통하여 극 좌표 평면의 (r,θ)으로 이 동된다. 본 발명에서는 콘택트렌즈 가장자리가 영상의 중심점 (Cx, Cy)와 반지름 r 인 원으로 표현되어 있다고 가정한다. 극 좌표 변환 평면상에 나타나는 콘택트렌즈 변환 영상은 원의 중심과 반지름 사이의 픽셀을 샘플링하면서 재구성될 수 있으며, 이에 대한 상세한 수식은 다음과 같다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 발명에서 수학식 를 통하여 증강된 데이터를 극 좌표계 평면으로 변환한다. 수학식 에서의 (i,j)는 직 교 좌표계에서의 임의의 점을 의미하고, (Cx, Cy)는 원의 중심을 의미하고, (r,θ)는 극 좌표 평면에서의 좌표를 의미한다. 이때, 영상 데이터 상의 중점 좌표가 (0,0)에 위치하기 때문에 이를 원의 중심으로 이동시켜주는 과 정이 필요하다. 이 과정을 통하여 변형된 중심에서의 좌표는 (x,y)로 표현되며, 이를 사용하여 수학식 , 에 따라 (r,θ)를 계산한다. 도 9는 본 발명에서 극 좌표 영상 변환 과정 중 분할을 설명하기 위한 도면이다. 도 9를 참조하면, 영상데이터는 일종의 행렬이므로 상단부터 y좌표가 증가하는 형태이다. 따라서, 1,2사분면과 3,4사분면이 뒤집힌 형태로 표현된다. 전술한 수학식에 의하여 극 좌표계로 변형된 데이터는 직교 좌표계 상의 원의 반지름(r)만큼의 가로 길이를 가지며, 2πr 만큼의 세로 길이를 가지게 된다. 즉, 종횡비가 1: 2π 인 직 사각형의 형태를 가지게 된다. 이러한 형태는 주로 정사각형형태의 필터를 사용하는 딥 러닝 모델에 적용하기에 는 부적합하므로 임의의 개수로 분할한다. 그리고, 분할과 함께 가장자리 영역의 정보추출을 위하여 불필요한 원 내부는 제거하고, 2m 의 가로 길이를 가진 l 개의 영상으로 변환 후, 횡방향으로 결합한다. 이를 통하여 분 석 대상이 되는 영역을 선택적으로 확장시킬 수 있다. 도 10은 본 발명에서 극 과표 변환을 통한 데이터 확장성을 설명하기 위한 도면이다. 도 10을 참조하면, 입력되는 원본 영상 데이터와 극 좌표로 변환된 영상 데이터의 가로와 세로의 길이는 같다. 직선으로 변환된 전체 원주를 l 만큼의 영역으로 분할하며, 콘택트렌즈 경계를 나타내는 원의 반지름을 r이라 하고, 원본 영상 데이터에의 원에서 영상의 경계까지의 여백을 m 이라 할 때, 최적의 l 은 다음 수학식에 의해 계산된다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "그리고, 극 좌표계로 변환된 총 원주 길이 TC(Transformed Circumference)와 데이터의 확장율 DER(Data Expansion Rate)은 다음 수학식과 같이 나타낼 수 있다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "l 과 TC 값이 결정되면, 전술한 수학식 , 에 의하여 (r,θ)에 해당하는 픽셀을 매핑하기 위하여 dθ가 사 용되고, 이에 대한 수학식은 다음과 같다. 수학식 은 실제로 극 좌표 영상 변환 과정에서 고려해야할 θ의 단위를 구하기 위한 수식이다. 즉, dθ의 단 위마다 해당하는 픽셀 값을 새로운 평면에 입력해야 한다. 본 발명의 일 실시예에서 반지름 r이 715픽셀이고, 여백 m이 36 픽셀인 1500×1500 픽셀의 영상의 경우, 인공지 능 학습에 있어 너무 많은 연산량을 요구하므로 그대로 넣기에는 부적합하다. 따라서 640×640 영상으로 리사이 즈를 수행하며, 여기서 영상의 한 변의 길이인 s가 640으로 계산된다. 한 변의 길이가 640으로 정해질 경우, 반 지름 r은 304픽셀, 여백m은 16픽셀이 된다. 따라서 최적의 l은 수학식에 의하여 20이 된다. 그리고, TC는 12,800 픽셀이 되며, 데이터 확장률 DER은 약 6.7배가 된다. 또한, 이 경우 변환에 사용되는 dθ 의 값은 0.028 ° 가 된다. 이러한 과정을 통하여 변환된 영상은 계산 과정에서 완벽한 정사각형의 형태가 아닐 수 있으 며, 이때는 보간법을 사용하여 정사각형의 형태로 보정한다. 이때 사용되는 보간법은 INTER_AREA 보간법으로서, 주로 영상 축소에 사용되는 방법이며, 픽셀 공간의 관계에 의하여 픽셀 값을 리샘플링하는 기법이다. 도 11은 본 발명에서 레이블링된 데이터의 1차 변환에 대해 설명하기 위한 도면이다. 도 11을 참조하면, 레이블링된 데이터의 변환은 변환된 임의의 점 (θ,r)에서 θ 의 최소값과 최대값, r의 최소 값과 최대값으로 객체를 감싸는 사각형을 특정 지을 수 있다. 도 11의 (a)와 (b)의 경우는 이에 대한 예시이며, 위치한 사분면의 순서나 경계에 영향을 받지 않는 일반적인 경우이다. 그러나, 도 11의 (c)처럼 특수한 경우가 발생할 수 있는데, θ 가 0 인 직선, 즉 x축의 양의 방향을 의미하는 직선으로 레이블링이 분단되는 경우가 발생할 수 있으며, 이때는 레이블링을 2개로 나누어 처리한다. 1차 변환이 완료된 좌표는 분할이 되지 않은 영상에 대한 좌표이기 때문에 2차 변환이 필요하다. 본 발명에서 2 차 변환은 영상의 분할 및 결합에 의해 계산된다. 도 12는 본 발명에서 2차 변환을 위한 의사 코드를 나타낸 것이다. 도 12를 참조하면, 의사 코드는 입력으로 영상의 분할 수, 여백, x축의 길이, y축의 길이 등 영상에 대한 정보 와, 1차 변환이 완료된 좌표를 사용한다. 여백은 x좌표의 특정에 있어서 분석 영역에 해당하는지에 대한 것을 구분할 수 있는 지표가 되며, 분할 수는 y좌표의 위치 재조정을 위한 계산에 사용된다. 즉, 분할된 영상의 세로 길이로 1차변환이 완료된 y좌표를 나누게 되면 정수 부분과 소수 부분이 도출된다. 이때, 정수 부분은 몇 번째 분할 영상에 들어가게 될 것인지를 결정하며, 소수 부분은 해당 분할영상안에서 새로운 y좌표를 의미하게 된다. 본 발명에서 인공지능 학습 모델은 딥 러닝 모델로 구현될 수 있고, 보다 구체적으로 CNN 인공신경망 구조의 학 습 모델로 구현될 수 있다. 본 발명의 일 실시예에서 인공지능 학습 모델로 구현되는 딥 러닝 모델로서, YOLOv5s의 구조를 일부 수정한 모 델을 제안할 수 있다. 도 13은 본 발명에서 콘볼루션 레이어의 형태에 따른 특성 맵의 변화를 보여주는 도면이다. 도 13에서 묘사하는 것은 실제로 구현되는 것이 아닌 활성화 함수에 들어가기 이전의 형태를 설명한 것이고, 콘볼루션 레이어 내부 의 가중치 또한 상수로 취급하여 단순화한 개념이다. 또한, 활성화함수가 적용되지 않은 상태이기 때문에 색이 나타내는 절대적인 값이 아니고, 상대적인 수치를 생각해서 판단한다. 도 13에서 보는 바와 같이, 극 좌표 평면으로 맵핑(mapping)된 영상은 상하로 직선 형태의 가장 자리를 갖는다. Conv 레이어는 왼쪽에서 오른쪽으로 슬라이딩 하며 콘볼루션을 수행한다. Vertical 형태는 가장자리 특성을 강 화하는 것에 효율적이고, Horizontal 형태는 결함의 특성을 추출하는데 효율적이고, Basic 형태는 노이즈 제거 에 효율적이다. 따라서, 본 발명에서는 Horizontal 형태를 통과한 결과를 유지하면서 노이즈를 제거하는 것이 주된 학습 방향이 된다. 도 14는 기존의 YOLOv5 콘볼루션 레이어 클래스와 변형된 레이어 클래스를 도시한 것이다. 도 14에서 k는 필터 의 크기를 결정하는 매개변수이다. 도 14 (a)에서 보는 바와 같이, 기존의 YOLOv5 k값을 입력받아 사용하는 콘볼루션 레이어 클래스를 미리 정의해 두고 사용한다. 이를 변형한 (b)의 Horizontal Conv 레이어는 1 x N형태의 콘볼루션 레이어를 활용한 형태를 의 미하는 것으로서 결함의 특성을 추출하고, (c)의 Vertical Conv 레이어는 N x 1형태의 콘볼루션 레이어를 활용 한 형태를 의미하는 것으로서 가장자리 영역을 유지한다. 기존의 YOLOv5에서 사용하는 활성화 함수는 SiLU(Sigmoid Linear Unit)이고, SiLU함수는 Sigmoid 함수에 입력 값을 곱한 형태이며, 2차원에서 ReLU등의 다른 함수에 비하여 출력이 유연하다. 그러나, 콘택트렌즈에서 발생하 는 에지 결함(i-edge)의 경우, SiLU 활성화함수를 사용할 경우, 특성에 대한 출력이 0으로 수렴하고, 음수 부분 의 특성을 제대로 활용할 수 없기 때문에 부적합하다. 도 15는 SiLU 함수와 tanh 함수를 도시한 그래프이다. 도 15에서 보는 바와 같이, tanh함수는 y축을 기준으로 음수와 양수 부분이 대칭을 이루고 있는 형태이기 때문 에 i_edge 결함처럼 픽셀 값이 주변에 비해 매우 어두운 특성을 띄고 있는 경우, 이를 반영하기에 적합하다. 따 라서 본 발명에서 Horizontal Conv와 Vertical Conv 레이어에서는 활성화 함수로 tanh를 사용한다. 도 16은 YOLOv5의 기본 구조를 도시한 것이다. 도 16을 참조하면, YOLOv5는 크게 백본(Backbone), 넥(Neck), 헤드(Head)의 3부분으로 구분할 수 있다. 백본 (Backbone)의 주된 역할은 입력 영상의 특성을 추출하여 특성맵으로 변형시키는 것이고, CSPdarknet을 사용한다. 헤드(Head)는 객체 클래스에 대한 예측과 바운딩 박스의 예측 작업을 수행한다. 넥(Neck)은 백본 (Backbone)과 헤드(Head) 사이에서 특성맵을 재구축, 결합, 정제하는 역할을 수행한다. YOLOv5는 여러가지 버전 이 존재하는데, s가 가장 가벼운 모델로서 가장 빠르고, x가 가장 무거운 모델로서 정확도는 가장 높지만 속도 는 가장 느리다. 여기서, C3 모듈은 백본 CSPdarknet 을 구성하는 핵심 모듈로서, 3개의 Conv 레이어와 n개의 보틀넥 (bottleneck)으로 구성된다. 도 17은 기존 YOLOv5 백본 구조와 변형된 초기 레이어 구조를 도시한 것이다. 도 17을 참조하면, 기존 CSPdarknet은 최초 2번의 콘볼루션 레이어층을 거치면서 1차적인 기본 특성맵을 형성한 후, C3 모듈을 반복적으로 수행하여 특성맵을 조정한다. 본 발명에서는 CSPdarknet에서 최초 2번의 콘볼루션을 호리즌털(Horizontal) Conv 레이어로 교체한다. 이를 통하여 본 발명에서는 결합의 특성을 유지하면서 초기 특 성맵을 구축한다. 기존의 N × N 형태의 콘볼루션을 사용할 경우, 노이즈 처리에 좋은 성능을 보이지만, i_edge 결함의 경우, 같이 유실될 가능성이 높다. 본 발명에서 제안된 호리즌털(Horizontal) 레이어의 특징은 i_edge 결함의 특성을 극대화할 수 있는 레이어이고, 노이즈 처리에 있어서는 반복되는 C3 모듈에서 수행하는 구조를 통하여 해결한다. CSPdarknet의 핵심은 C3 모듈이라고 할 수 있으며, C3 모듈은 3장의 콘볼루션 레이어와 N번의 보틀넥 (Bottleneck)으로 구성되고, 백본에서 4회에 걸쳐 C3 모듈이 수행된다. 도 18은 기존의 C3 모듈과 변형된 C3 모듈을 도시한 것이다. 도 18을 참조하면, 기존의 C3 모듈은 1 × 1 콘볼루션 레이어을 사용하여 채널을 조절하는 역할과 가중치에 대 한 정보 수집을 진행하고, 보틀넥(Bottleneck)안에서도 역시 비슷한 과정을 N번 반복한다. 이때, 입력 영상에서 1 × 1 콘볼루션을 따로 진행하여 병렬처리하고, 보틀넥(bottleneck)에서 나온 결과물과 결합한다. 그리고, 이 를 다시 한번 1 × 1 콘볼루션을 진행하여 채널 정제를 수행한다. 본 발명에서는 기존 C3 모듈을 변형한 모델을 제안한다. 구체적으로 호리즌털(Horizontal) 콘볼루션 레이어를 보틀넥(bottleneck) 레이어에 들어가지 않는 1 × 1 콘볼루션 레이어와 교체한다. 또한 보틀넥(Bottleneck)에 들어가는 콘볼루션은 1 × N 형태와 N × 1 형태의 콘볼루션 레이어를 병렬적으로 진행하여 결합한다. 즉, 횡방 향의 특성만을 숏컷 형태로 넘겨서 결합한다. 이는 기본적으로 N × N 형태의 콘볼루션과 같지만, 연산량을 줄 이고, 노이즈를 제거하는 역할을 한다. 마지막으로 최종 1 × 1 콘볼루션 레이어에서는 합쳐진 특성맵을 정제하 는 역할을 수행하도록 그대로 배치한다. 본 발명에서는 이러한 과정을 수행하는 변형된 C3 모듈을 PolarC3 모듈 이라고 명명하기로 한다. 도 19는 YOLOv5의 백본 구조와 본 발명에서 제안하는 백본 구조를 도시한 것이다. 도 19를 참조하면, 본 발명에서 제안하는 딥러닝 모델의 백본(Backbone) 구조는 YOLOv5의 기본 구조에서 결함 형태를 유지하면서 최초 입력층을 변경하고, C3 모듈을 수정한 것이다. 도 20은 본 발명에서 제안하는 백본 및 넥 구조를 도시한 것이다. 도 20을 참조하면, PolarC3 모듈을 YOLOv5의 백본(Backbone) 및 (Neck)에 위치시킨 구조가 도시되어 있다. 기 존 YOLOv5에서 초기 2번의 C3 모듈을 PolarC3 모듈로 교체하고, 2번의 모듈 사이에 호리즌털(Horizontal) Conv 를 추가한 것이다. 또한, 넥(Neck) 부분에서 가장 낮은 수준의 C3 모듈을 교체한 것이다. 이러한 변형을 통해서 구축된 본 발명에서 제안하는 최종 딥러닝 모델의 형태는 도 21과 같다. 도 21은 본 발명에서 제안하는 딥러닝 모델의 전체적인 구조를 도시한 것이다. 도 21을 참조하면, 붉은 점선으로 표시된 영역은 결함 및 가장자리의 특성이 헤드(Head) 영역까지 전달되는 경 로를 나타낸 것이다. 초반의 특성맵을 구축하는 부분에서 호리즌털(Horizontal) Conv 과 PolarC3 모듈을 이용하 여 특성을 최대한 남기도록 설정하고, 이를 넥(Neck)에서 받아 헤드(Head)까지 연결시키는 형태로 구축된다. 이 를 위해 넥(Neck)부분에서의 C3 모듈을 PolarC3 모듈로 변형한 것이다. 이러한 일련의 과정을 통하여 본 발명에 서 제안하는 극 좌표 변환 영상 분석에 적합한 딥러닝 모델로 수정한 것이다. 본 발명에서 제안하는 극 좌표계 변환 기법을 적용한 딥러닝 모델의 성능을 평가하기 위해 실험을 진행하였다. 도 22는 본 발명의 실험을 진행한 컴퓨터 하드웨어와 소프트웨어의 환경을 나타낸 도표이다. 본 발명의 실험에 사용된 원본 데이터는 동일한 콘택트렌즈에 대하여 조명을 달리해 촬영한 흑색과 백색의 영상 이 1쌍을 이룬다. 원본 영상의 크기는 2048×2448 픽셀이며, 전처리 후 영상 크기는 1500×1500 픽셀, 극 좌표 변환후 영상 크기는 750x750 픽셀이다. 단, 모델 학습 및 검증에 입력되는 크기는 모두 640×640 픽셀이다. 데 이터 증강 전 총 영상수는 3678개이며, 증강 후 영상 수는 총 6331개이다. 도 23은 본 발명의 실험에서 영상 내 객체의 클래스 정보를 나타낸 것이다. 도 23에서 보는 바와 같이, 에지(일반)(n_edge)의 경우 증강전 10578개, 증강후 11740개, 에지(찢어 짐)(b_edge)의 경우 증강전 778개, 증강후 4002개, 에지(끊어짐)(i_edge)의 경우 증강 전 1171개, 증강 후 2429개이다. 전술한 바와 같이, 데이터 증강은 데이터 불균형을 해결하기 위하여 수행되고, 에지(찢어짐)과 에 지(끊어짐)의 개수를 늘리는데 주로 수행되었다. 이후, 25%의 데이터를 검증용으로 설정하여 4748개의 학습용 데이터(train dataset)와, 1583개의 검증 데이터(Validation dataset)로 분할하였다. 본 발명의 실험에서 전술한 데이터셋을 사용하여 극 좌표 변환을 수행하였으며, 입력 크기는 640×640으로 동일 하고, 분할 횟수를 4로 설정하였다. 도 24는 본 발명의 실험에서 실험데이터 변환을 예시한 것이다. 도 24에서 (a)는 원본 영상을 나타내며, (b)는 실제로 본 발명에서 제안된 모델에 입력 영상이 되는 데이터를 나타낸 예시이다. 도 25는 본 발명의 실험에서 비교 모델의 하이퍼파라미터 설정값을 예시한 도표이다. 도 25에서 보는 바와 같이, Faster-RCNN, YOLOv5s, 극 좌표영상을 이용한 YOLOv5s, 본 발명에서 제안하는 딥러 닝 모델의 네 개의 비교 모델을 예시하고, 하이퍼파라미터를 최대한 동일하게 설정하였다. 이중 epoch는 콜백함 수를 두어 100번이상 성능의 향상이 없다면 학습조기종료가 가능하게 하였다. 본 발명의 실험 결과에 대하여 정밀도, 재현율, F1점수 및 평균정밀도의 평가지표를 사용하여 콘택트렌즈 데이 터셋에 대한 모델들의 성능을 평가하였다. 정밀도(Precision)가 나타내는 개념은 관련 객체만을 식별하는 모델의 성능이다. 즉, 검출한 객체 중 올바른 객 체의 비율을 나타낸다. 아래 수식은 정밀도의 계산을 나타내는 것이다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, TP(True Positive)는 올바른 탐지, FP(False Positive)는 오탐지를 나타낸다. 재현율(Recall)은 모든 관련 객체를 찾아내는 모델의 성능을 나타낸다. 즉, 검출해낸 객체와 검출해야하는 객체 의 비율을 나타내는 지표이다. 아래 수식은 재현율의 계산을 나타낸 것이다. 여기서, FN(False Negative)는 미탐지를 나타낸다. 정밀도와 재현율 모두 모델의 성능을 나타내는 지표이지만, 트레이드오프(Trade-Off)관계에 있으므로, 어느 수 준 이상의 재현율이 되면 정밀도가 감소하게 된다. 반대의 경우 재현율이 매우 낮으면 정밀도는 높게 된다. 따 라서 어느 하나의 지표만 높다면 모델의 성능이 반드시 좋다고 할 수는 없으며, 두가지 지표를 종합적으로 고 려할 필요가 있다. F1점수는 재현율과 정밀도의 조화평균값이다. 정밀도와 재현율을 종합적으로 고려하는 방법 중 하나로서, 주로 클래스간의 불균형이 심할 때 사용된다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "평균정밀도(mean Average Precision, mAP)을 나타내는 수식은 다음과 같다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "AP(Average Precision)는 IoU(intersection over union)의 임계값에 따른 정밀도의 평균을 의미한다. 이때 IoU 란 객체 탐지의 정확도를 평가하는 지표 중 하나로서, 실제와 예측의 중복되는 영역의 크기를 0~1 사이의 숫자 로 표시하는 것이다. 도 26은 IoU(intersection over union)를 나타낸 것이다. 도 26에서 보는 바와 같이, IoU=(실제와 예측의 중복 영역)/(실제와 예측의 전체 영역) 이다. 이때, 특정 IoU 임계치보다 높게 달성한 경우, TP로 간주하게 되며, 이 조건하에서 정밀도를 측정한다. 일반적으로 0.5부터 0.95까지의 IoU 임계치에서 정밀도를 평균한 값을 AP라 한다."}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "본 발명의 실험에서 극 좌표 변환 이전의 원본 데이터셋과, 극 좌표 변환영상 데이터셋의 2종류에 대하여 실험 을 진행하였으며, Faster-RCNN, YOLOv5s, 극 좌표 변환 영상을 이용한 YOLOv5s, 극 좌표 변환 영상을 이용한 본 발명에서 제안하는 딥러닝 모델에 대한 실험을 진행하고, 그 결과를 도시한 것이 도 27 내지 도 29이다. 도 27은 본 발명의 실험에서 원본 영상을 이용한 YOLOv5s의 실험 결과를 도시한 그래프이고, 도 28은 본 발명의 실험에서 극 좌표 변환 영상을 이용한 YOLOv5s의 실험 결과를 도시한 그래프이고, 도 29는 본 발명의 실험에서 극 좌표 변환 영상을 이용한 본 발명에서 제안한 딥러닝 모델의 실험 결과를 도시한 그래프이다. 도 27 내지 도 29의 각 그래프의 obj loss는 각 제안 지역 내에 객체의 존재여부를 얼마나 잘 예측했는가 하는 지표이며, box loss는 객체가 존재한다고 판단했을 경우, 모델이 객체의 좌표를 얼마나 잘 예측하고 있는지를 나타내는 지표이고, cls loss는 객체의 종류를 얼마나 잘 예측했는가를 나타내는 지표이다. 이러한 세가지 지표 는 학습데이터와 검증데이터의 2종류로 각각 나누어져 있다. Precision과 recall은 각각 정밀도와 재현율을 나 타내며, mAP_0.5는 IoU 0.5 임계치에서의 평균정밀도를 나타내고, mAP_0.5:0.95는 IoU 0.5에서 0.95까지의 평 균정밀도를 나타낸다. 도 27 내지 도 29를 참조하면, 원본 영상을 사용한 모델에 비하여, 극 좌표 변환 영상을 사용한 모델은 두가지 모델 둘 다 상대적으로 빠른 훈련데이터의 수렴속도를 보여준다. 특히 box loss의 경우, 기존의 방법은 대략 100번째 epoch에서 0.04이하로 떨어지는 반면, 극 좌표 평면을 이용한 경우, 약 20~30번째 epoch사이에서 0.04 이하로 떨어지는 것을 확인할 수 있다. 극 좌표 평면과 YOLOv5s를 이용한 모델의 경우, val/obj loss가 0.018에 서 오히려 발산하는 모습을 보이고 있다. 즉, 결함이 있는 지역에 대한 예측이 떨어진다. 또한, epoch가 191에 서 멈춘 것을 확인할 수 있었다. 이는 전술한 바와 같이 학습조기종료가 된 결과이며, 91번째의 학습결과에서 100번의 epoch동안 결과가 증가하지 않았음을 알 수 있다.도 29의 본 발명에서 제안한 딥러닝 모델의 경우, val/obj loss, box loss, cls loss 3가지의 경우 모두 빠르 게 수렴하고 안정적으로 유지하는 것을 확인할 수 있었다. 하지만, obj loss와 box loss의 경우는 기존의 방법 은 0.02, 0.008 수준까지 하강하지만, 제안된 방법은 0.038, 0.017까지 감소하고 그 이후는 더 이상 성능이 나 아지지 않았던 모습을 보였다. 단, cls loss의 경우 기존 방법은 0.0027 이었던 것에 비하여 본 발명에서 제안 하는 방법은 0.0009까지 감소하는 모습을 보였다. 정밀도와 재현율은 극 좌표 평면 변환영상을 사용한 경우, 역시 빠른 수렴속도를 보인다. 하지만, 극 좌표 평면 과 기존의 YOLOv5s를 사용한 경우, 어느 한점에 수렴하지 못하고 결과가 변동하는 경향을 보였다. 도 27에서 원본 영상과 YOLOv5s를 사용한 기존의 방법은 정밀도는 0.9, 재현율은 0.82를 기록하였다. 도 29에서 본 발명에서 제안하는 딥러닝 모델의 경우, 정밀도는 0.91, 재현율은 0.89를 기록하였다. 즉, 정밀도 보다 재현율 측면에서 더 향상폭이 높은 결과를 기록하였고, 이는 기존의 방법과 비교했을 시, 찾아낸 객체 중 관련 객체일 확률은 비슷하지만, 관련 객체 자체를 찾아내는 성능은 본 발명에서 제안하는 방법이 더 뛰어나다 고 할 수 있다. 도 30은 본 발명의 실험에서 비교 대상 모델들에 대한 종합적인 성능 지표를 정리한 도표이다. 도 30을 참조하면, Faster-RCNN과 YOLOv5s의 결과는 모든 부분에 있어서 YOLOv5s가 성능이 좋았다. 다만, F1 점수의 경우, 매우 격차가 적은 것을 확인할 수 있는데, F1 score의 의미는 정밀도와 재현율의 조화평균이기 때 문에 Faster-RCNN의 경우, YOLOv5s와 비교했을 시, 정밀도와 재현율의 격차가 적다는 것을 알 수 있다. 또한, i-edge 결함의 경우 매우 저조한 정밀도를 기록하였다. 이는 콘볼루션 레이어가 심화됨에 따라서 작은 객체는 그 특성이 유실되는 현상과 관련이 있다고 유추할 수 있으며, 이에 대한 해결책이 존재하지 않는 Faster-RCNN의 경우는 매우 성능이 낮게 측정된다. YOLOv5s와 극 좌표 변환영상을 이용한 YOLOv5s의 경우를 비교하면, 모든 부분에 있어서 극 좌표 변환 이전의 YOLOv5s가 나은 성능을 보였다. 특히 n_edge와 i_edge의 경우 b_edge에 비하여 크게 성능이 하락한 것을 확인할 수 있었고, map는 27%하락하였다. 기존 영상과 YOLOv5s를 이용한 모델과 본 발명에서 제안하는 딥러닝 모델을 비교하면, F1점수와 mAP@.5에 있어 서 더 나은 성능을 보였다. F1점수는 3%상승을 하였고, mAP@.5는 1.7%가 성능개선이 되었다. 또한, b_edge와 i_edge에서는 검출율이 개선되었다. 도 31은 본 발명의 실험에서 YOLOv5s와 본 발명에서 제안하는 딥러닝 모델의 F1 점수를 비교한 그래프이다. 도 31에서 (a)는 YOLOv5s의 F1 점수를 나타낸 그래프이고, (b)는 본 발명에서 제안하는 딥러닝 모델의 F1 점수를 나타낸 그래프이다. 도 31에서 Confidence score란 신뢰점수를 말하는 것으로서, 특정구역내에 객체가 위치할 확률을 예측한 점수를 말하며, 클래스의 종류는 상관하지 않으며, 객체가 있는지 또는 없는지에 대해서만 예측 한 점수를 말한다. YOLO알고리즘에 있어서, 신뢰점수란 실제로 탐지를 실행할 때, 사용하게 되는 매개변수로서 의 의미를 지니게 된다. 도 31 (a)의 경우, 원본영상을 이용한 YOLOv5s에 대한 실험 결과이며, 신뢰점수가 0.491이다. 신뢰점수가 0.491 이란 것은 0.491 이하의 영역에서는 객체 검출을 하지 않고 넘어갔을 경우 가장 높은 점수를 얻었다는 것을 의 미한다. 도 31 (b)의 경우, 본 발명에서 제안한 딥러닝 모델에 대한 실험 결과이며, 신뢰점수가 0.447이다. 여기서, 0.8 이상의 신뢰점수가 되면 급격히 F1점수가 감소하는 것을 확인할 수 있는데, 이는 val/obj loss가 높았던 것과 관련이 있다. 한편, 본 발명의 실시예에 따른 콘택트렌즈 제조 공정에서의 불량 검출 방법은 컴퓨터로 읽을 수 있는 기록매체 에 컴퓨터가 읽을 수 있는 코드로서 구현되는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템 에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 예컨대, 컴퓨터가 읽을 수 있는 기록매체로는 롬(ROM), 램(RAM), 시디-롬(CD-ROM), 자기 테이프, 하드디스크, 플로피디스크, 이동식 저장장치, 비휘발성 메모리(Flash Memory), 광 데이터 저장장치 등이 포함된다. 또한, 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터 통신망으로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 읽을 수 있는 코드로서 저장되고 실행될 수 있다.이상 본 발명을 몇 가지 바람직한 실시 예를 사용하여 설명하였으나, 이들 실시 예는 예시적인 것이며 한정적인"}
{"patent_id": "10-2023-0058352", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "것이 아니다. 본 발명이 속하는 기술분야에서 통상의 지식을 지닌 자라면 본 발명의 사상과 첨부된 특허청구범 위에 제시된 권리범위에서 벗어나지 않으면서 다양한 변화와 수정을 가할 수 있음을 이해할 것이다."}
{"patent_id": "10-2023-0058352", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 콘택트렌즈 제조 공정에서 콘택트렌즈 영상 데이터의 불량 판정 기준을 도식화한 것이다. 도 2는 콘택트렌즈 영상 데이터에서 불량 판정을 위한 검출 대상 객체를 예시한 것이다. 도 3은 콘택트렌즈 제조 공정에서 반복 패턴을 나타내는 에지 불량 특성을 이용한 검출 방식을 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 시스템의 구성을 개략적으로 도시한 블록도이다. 도 5는 본 발명의 일 실시예에 따른 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 방법을 도시한 흐름도이다. 도 6은 본 발명의 일 실시예에 따른 인공지능을 이용한 콘택트렌즈 제조 공정에서의 불량 검출 방법에서 전처리 과정을 도시한 흐름도이다. 도 7은 본 발명의 일 실시예에 따른 콘택트렌즈 영상 데이터에 대한 전처리 과정을 도시한 것이다. 도 8은 직교 좌표 평면과 극 좌표 평면을 예시한 것이다. 도 9는 본 발명에서 극 좌표 영상 변환 과정 중 분할을 설명하기 위한 도면이다. 도 10은 본 발명에서 극 과표 변환을 통한 데이터 확장성을 설명하기 위한 도면이다. 도 11은 본 발명에서 레이블링된 데이터의 1차 변환에 대해 설명하기 위한 도면이다. 도 12는 본 발명에서 2차 변환을 위한 의사 코드를 나타낸 것이다. 도 13은 본 발명에서 콘볼루션 레이어의 형태에 따른 특성 맵의 변화를 보여주는 도면이다. 도 14는 기존의 YOLOv5 콘볼루션 레이어 클래스와 변형된 레이어 클래스를 도시한 것이다. 도 15는 SiLU 함수와 tanh 함수를 도시한 그래프이다. 도 16은 YOLOv5의 기본 구조를 도시한 것이다. 도 17은 기존 YOLOv5 백본 구조와 변형된 초기 레이어 구조를 도시한 것이다. 도 18은 기존의 C3 모듈과 변형된 C3 모듈을 도시한 것이다. 도 19는 YOLOv5의 백본 구조와 본 발명에서 제안하는 백본 구조를 도시한 것이다. 도 20은 본 발명에서 제안하는 백본 및 넥 구조를 도시한 것이다. 도 21은 본 발명에서 제안하는 딥러닝 모델의 전체적인 구조를 도시한 것이다. 도 22는 본 발명의 실험을 진행한 컴퓨터 하드웨어와 소프트웨어의 환경을 나타낸 도표이다. 도 23은 본 발명의 실험에서 영상 내 객체의 클래스 정보를 나타낸 것이다. 도 24는 본 발명의 실험에서 실험데이터 변환을 예시한 것이다. 도 25는 본 발명의 실험에서 비교 모델의 하이퍼파라미터 설정값을 예시한 도표이다. 도 26은 IoU(intersection over union)를 나타낸 것이다. 도 27은 본 발명의 실험에서 원본 영상을 이용한 YOLOv5s의 실험 결과를 도시한 그래프이다. 도 28은 본 발명의 실험에서 극 좌표 변환 영상을 이용한 YOLOv5s의 실험 결과를 도시한 그래프이다. 도 29는 본 발명의 실험에서 극 좌표 변환 영상을 이용한 본 발명에서 제안한 딥러닝 모델의 실험 결과를 도시 한 그래프이다. 도 30은 본 발명의 실험에서 비교 대상 모델들에 대한 종합적인 성능 지표를 정리한 도표이다. 도 31은 본 발명의 실험에서 YOLOv5s와 본 발명에서 제안하는 딥러닝 모델의 F1 점수를 비교한 그래프이다."}
