{"patent_id": "10-2019-0156158", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0066651", "출원번호": "10-2019-0156158", "발명의 명칭": "전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "이경훈"}}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,회로를 포함하는 통신부;마이크;적어도 하나의 인스트럭션(instruction) 및 대화 히스토리 정보를 저장하는 적어도 하나의 메모리; 및상기 적어도 하나의 인스트럭션을 실행하는 프로세서;를 포함하고,상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 마이크를 통해 입력된 사용자 음성을 제1 대화 시스템을 저장하는 서버로 전송할 지 여부를 결정하고,상기 사용자 음성을 상기 서버로 전송하는 것으로 결정되면, 상기 사용자 음성 및 상기 저장된 대화 히스토리정보 중 적어도 일부를 상기 서버로 전송하도록 상기 통신부를 제어하고,상기 통신부를 통해, 상기 서버로부터 상기 사용자 음성과 관련된 대화 히스토리 정보를 수신하며,상기 수신된 대화 히스토리 정보를 상기 메모리에 저장하도록 제어하는 전자 장치."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 메모리는 상기 사용자 음성에 대한 응답을 제공하기 위한 제2 대화 시스템을 저장하고,상기 제2 대화 시스템은 제2 ASR 모듈(Automatic Speech Recognition)을 포함하며,상기 프로세서는,상기 제2 ASR 모듈을 통해 상기 사용자 음성에 대응되는 텍스트 및 상기 사용자 음성의 음성 인식 신뢰도 값을획득하고,상기 사용자 음성의 음성 인식 신뢰도 값을 바탕으로 상기 사용자 음성을 상기 서버로 전송할지 여부를 결정하는 전자 장치."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값 이하인 경우, 상기 사용자 음성 또는 상기 사용자 음성에 대응되는 텍스트 중 적어도 하나를 상기 서버로 전송하는 것으로 결정하고,상기 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값을 초과할 경우, 상기 제2 대화 시스템을 통해 상기 사용자 음성에 대한 응답 및 상기 사용자 음성과 관련된 대화 히스토리 정보를 획득하는 전자 장치."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제2 대화 시스템은 제2 NLU(Natural Language Understanding) 모듈을 포함하고,상기 프로세서는,상기 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값을 초과할 경우, 상기 제2 NLU 모듈을 통해 상기 사용자공개특허 10-2021-0066651-3-음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값 및 도메인을 획득하고,상기 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값 및 도메인 중 적어도 하나를 바탕으로 상기사용자 음성에 대응되는 텍스트를 상기 서버로 전송할지 여부를 결정하는 전자 장치."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는,상기 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값이 제2 임계값 이하인 경우, 상기 사용자 음성에 대응되는 텍스트를 상기 서버로 전송하는 것으로 결정하고,상기 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값이 제2 임계값을 초과할 경우, 상기 제2 대화시스템을 통해 상기 사용자 음성에 대한 응답 및 상기 사용자 음성과 관련된 대화 히스토리 정보를 획득하는 전자 장치."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "서버에 있어서,회로를 포함하는 통신부;제1 대화 시스템 및 적어도 하나의 인스트럭션(instruction)을 저장하는 적어도 하나의 메모리; 및상기 적어도 하나의 인스트럭션을 실행하는 프로세서;를 포함하고,상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써,전자 장치로부터, 상기 전자 장치로 입력된 사용자 음성에 대응되는 텍스트 및 상기 전자 장치에 저장된 대화히스토리 정보를 상기 통신부를 통해 수신하고,상기 대화 히스토리 정보를 바탕으로 상기 제1 대화 시스템을 통해 상기 텍스트에 대한 언어 분석을 수행하고,상기 수행된 언어 분석에 따른 결과를상기 전자 장치로 전송하도록 상기 통신부를 제어하는 것을 특징으로하며, 상기 수신된 텍스트는 상기 전자 장치에 저장된 제2 대화 시스템을 통해 처리된 것을 특징으로 하는 서버."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 텍스트 및 대화 히스토리 정보를 바탕으로 언어 분석을 수행하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 획득하고, 상기 텍스트만을 바탕으로 언어 분석을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 획득하며,상기 제1 언어 분석 신뢰도 값 및 상기 제2 언어 분석 신뢰도 값을 바탕으로 상기 제1 언어 분석 결과 및 상기제2 언어 분석 결과 중 하나를 상기 전자 장치로 전송하도록 상기 통신부를 제어하는 서버."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 제1 언어 분석 신뢰도 값이 상기 제2 언어 분석 신뢰도 값보다 높은 경우, 상기 제1 언어 분석 결과를 상기 전자 장치로 전송하도록 상기 통신부를 제어하고,상기 제2 언어 분석 신뢰도 값이 상기 제1 언어 분석 신뢰도 값보다 높은 경우, 상기 제2 언어 분석 결과 중 상기 텍스트의 도메인과 관련된 정보를 바탕으로 상기 텍스트를 상기 전자 장치에 전송할지 여부를 결정하는공개특허 10-2021-0066651-4-서버."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프로세서는,상기 텍스트의 도메인과 관련된 정보를 통해 상기 텍스트의 도메인을 상기 전자 장치가 처리할 수 있는지 여부를 식별하고,상기 텍스트의 도메인을 상기 전자 장치가 처리할 수 있다고 식별되면, 상기 제2 언어 분석 결과를 상기 전자장치에 전송하도록 상기 통신부를 제어하는 서버."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는,상기 텍스트의 도메인을 상기 전자 장치가 처리할 수 없다고 식별되면, 상기 제2 언어 분석 결과를 바탕으로 상기 사용자 음성에 대한 응답 및 상기 사용자 음성과 관련된 대화 히스토리 정보를 획득하는 서버."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "대화 히스토리 정보 및 제2 대화 시스템을 저장하는 메모리를 포함하는 전자 장치의 제어 방법에 있어서,입력된 사용자 음성을 제1 대화 시스템을 포함하는 서버로 전송할 지 여부를 결정하는 단계;사용자 음성을 서버로 전송하는 것으로 결정되면 사용자 음성 및 저장된 대화 히스토리 정보 중 적어도 일부를서버로 전송하는 단계;서버로부터 사용자 음성과 관련된 대화 히스토리 정보를 수신하는 단계; 및수신된 대화 히스토리 정보를 저장하는 단계;를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제2 대화 시스템은 제2 ASR 모듈(Automatic Speech Recognition)을 포함하며,상기 결정하는 단계는,상기 제2 ASR 모듈을 통해 상기 사용자 음성에 대응되는 텍스트 및 상기 사용자 음성의 음성 인식 신뢰도 값을획득하는 단계; 및상기 사용자 음성의 음성 인식 신뢰도 값을 바탕으로 상기 사용자 음성을 상기 서버로 전송할지 여부를 결정하는 단계;를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 결정하는 단계는,상기 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값 이하인 경우, 상기 사용자 음성 또는 상기 사용자 음성에 대응되는 텍스트 중 적어도 하나를 상기 서버로 전송하는 것으로 결정하고,상기 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값을 초과할 경우, 상기 제2 대화 시스템을 통해 상기 사용자 음성에 대한 응답 및 상기 사용자 음성과 관련된 대화 히스토리 정보를 획득하는 단계;를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2021-0066651-5-제13항에 있어서,상기 제2 대화 시스템은 제2 NLU(Natural Language Understanding) 모듈을 포함하고,상기 결정하는 단계는,상기 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값을 초과할 경우, 상기 제2 NLU 모듈을 통해 상기 사용자음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값 및 도메인을 획득하는 단계; 및상기 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값 및 도메인 중 적어도 하나를 바탕으로 상기사용자 음성에 대응되는 텍스트를 상기 서버로 전송할지 여부를 결정하는 단계;를 포함하는 전자 장치의 제어방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 결정하는 단계는,상기 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값이 제2 임계값 이하인 경우, 상기 사용자 음성에 대응되는 텍스트를 상기 서버로 전송하는 것으로 결정하고,상기 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값이 제2 임계값을 초과할 경우, 상기 제2 대화시스템을 통해 상기 사용자 음성에 대한 응답 및 상기 사용자 음성과 관련된 대화 히스토리 정보를 획득하는 단계;를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1 대화 시스템을 저장하는 적어도 하나의 메모리를 포함하는 서버의 제어 방법에 있어서,전자 장치로부터, 상기 전자 장치로 입력된 사용자 음성에 대응되는 텍스트 및 상기 전자 장치에 저장된 대화히스토리 정보를 수신하는 단계;상기 대화 히스토리 정보를 바탕으로 상기 제1 대화 시스템을 통해 상기 텍스트에 대한 언어 분석을 수행하는단계; 및상기 수행된 언어 분석에 따른 결과를상기 전자 장치로 전송하는 단계;를 포함하며,상기 수신된 텍스트는 상기 전자 장치에 저장된 제2 대화 시스템을 통해 처리된 것을 특징으로 하는 서버의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 수행하는 단계는,상기 텍스트 및 대화 히스토리 정보를 바탕으로 언어 분석을 수행하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 획득하고 상기 텍스트만을 바탕으로 언어 분석을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 획득는 단계; 및상기 제1 언어 분석 신뢰도 값 및 상기 제2 언어 분석 신뢰도 값을 바탕으로 상기 제1 언어 분석 결과 및 상기제2 언어 분석 결과 중 하나를 상기 전자 장치로 전송하는 단계;를 포함하는 서버의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 전송하는 단계는,상기 제1 언어 분석 신뢰도 값이 상기 제2 언어 분석 신뢰도 값보다 높은 경우, 상기 제1 언어 분석 결과를 상기 전자 장치로 전송하고,상기 제2 언어 분석 신뢰도 값이 상기 제1 언어 분석 신뢰도 값보다 높은 경우, 상기 제2 언어 분석 결과 중 상공개특허 10-2021-0066651-6-기 텍스트의 도메인과 관련된 정보를 바탕으로 상기 텍스트를 상기 전자 장치에 전송할지 여부를 결정하는단계;를 포함하는 서버의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 전송하는 단계는,상기 텍스트의 도메인과 관련된 정보를 통해 상기 텍스트의 도메인을 상기 전자 장치가 처리할 수 있는지 여부를 식별하는 단계; 및상기 텍스트의 도메인을 상기 전자 장치가 처리할 수 있다고 식별되면, 상기 제2 언어 분석 결과를 상기 전자장치에 전송하는 단계;를 포함하는 서버의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 전송하는 단계는,상기 텍스트의 도메인을 상기 전자 장치가 처리할 수 없다고 식별되면, 상기 제2 언어 분석 결과를 바탕으로 상기 사용자 음성에 대한 응답 및 상기 사용자 음성과 관련된 대화 히스토리 정보를 획득하는 단계;를 포함하는서버의 제어 방법."}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치 및 이의 제어 방법이 제공된다. 본 전자 장치는 회로를 포함하는 통신부, 마이크, 적어도 하나의 인스 트럭션(instruction)을 저장하는 메모리 및 적어도 하나의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세 서는 적어도 하나의 인스트럭션을 실행함으로써 마이크를 통해 입력된 사용자 음성을 제1 대화 시스템을 포함하 는 서버로 전송할 지 여부를 결정하고, 상기 사용자 음성을 상기 서버로 전송하는 것으로 결정되면, 상기 사용자 음성 및 상기 저장된 대화 히스토리 정보 중 적어도 일부를 상기 서버로 전송하도록 상기 통신부를 제어하고, 상 기 통신부를 통해, 상기 서버로부터 상기 사용자 음성과 관련된 대화 히스토리 정보를 수신하며, 상기 수신된 대 화 히스토리 정보를 상기 메모리에 저장하도록 제어할 수 있다."}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법에 관한 것으로서, 더욱 상세하게는 입력된 사용자 음성에 대한 음성 인 식 결과를 바탕으로 사용자 음성에 대한 응답을 제공하기 위한 대화 시스템을 결정하는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 규칙 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공 지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 규칙 기반 스마트 시스템은 점차 딥러닝 기반 인공 지능 시스템으로 대체되고 있다. 인공 지능 기술은 기계학습(예로, 딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습시키는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 특히, 언어적 이해는 인간의 언어/문자를 인식하 고 응용/처리하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 한편, 사용자는 기계학습을 활용한 음성 인식 기술을 수행하기 위해서 디바이스 또는 서버에 저장된 인공 지능 시스템을 활용할 수 있다. 기존에는, 디바이스의 네트워크 상황에 따라서 디바이스 또는 서버에 저장되어 있는 인공 지능 시스템 중 하나가 선택되면, 선택된 인공 지능 시스템만을 음성 인식 기술을 수행하기 위하여 사용하 였다. 기존에는 디바이스의 네트워크 상황이 변경될 때, 사용되는 인공 지능 시스템이 스위칭(Switching)되는데, 스위 칭되는 인공 지능 시스템간에는 수행했던 작업 정보가 공유 되지 않았다. 따라서, 스위칭된 인공 지능 시스템은 요청받은 작업을 수행하기 위해 필요한 정보를 획득하기 위한 질문을 반복해야 한다는 한계가 존재하였다."}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해결하기 위해 안출된 것으로, 본 개시의 목적은 사용자 음성의 음성 인식 결과를 바탕으로 사용자 음성에 대한 응답을 제공할 대화 시스템을 결정하고, 결정된 대화 시스템에 사용자 음성 및 대 화 히스토리 정보를 입력하여 사용자 음성에 대한 응답을 제공하는 전자 장치 및 이의 제어 방법을 제공함에 있 다."}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른 전자 장치는 회로를 포함하는 통신부, 마이크, 적어도 하나의 인스트럭션(instruction)을 저장하는 메모리 및 상기 적어도 하나의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 마이크를 통해 입력된 사용자 음성을 제1 대화 시스템을 포함하는 서버로 전송할 지 여부를 결정하고, 상기 사용자 음성을 상기 서버로 전송 하는 것으로 결정되면, 상기 사용자 음성 및 상기 저장된 대화 히스토리 정보 중 적어도 일부를 상기 서버로 전 송하도록 상기 통신부를 제어하고, 상기 통신부를 통해, 상기 서버로부터 상기 사용자 음성과 관련된 대화 히스 토리 정보를 수신하며, 상기 수신된 대화 히스토리 정보를 상기 메모리에 저장하도록 제어할 수 있다. 한편, 상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른 서버는, 회로를 포함하는 통신부, 제1 대화 시스 템 및 적어도 하나의 인스트럭션을 저장하는 적어도 하나의 메모리 및 상기 적어도 하나의 인스트럭션을 실행하 는 프로세서를 포함하고, 상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써, 전자 장치로부터, 상기 전자 장치로 입력된 사용자 음성에 대응되는 텍스트 및 상기 전자 장치에 저장된 대화 히스토리 정보를 상 기 통신부를 통해 수신하고, 상기 대화 히스토리 정보를 바탕으로 상기 제1 대화 시스템을 통해 상기 텍스트에 대한 언어 분석을 수행하고, 상기 수행된 언어 분석에 따른 결과를상기 전자 장치로 전송하는 것을 특징으로 하 며, 상기 수신된 텍스트는 상기 전자 장치에 저장된 제2 대화 시스템을 통해 처리된 것을 특징으로 할 수 있다. 한편, 상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른 전자 장치의 제어 방법은 입력된 사용자 음성을 제1 대화 시스템을 포함하는 서버로 전송할 지 여부를 결정하는 단계, 사용자 음성을 서버로 전송하는 것으로 결정되면 사용자 음성 및 저장된 대화 히스토리 정보 중 적어도 일부를 서버로 전송하는 단계, 서버로부터 사용 자 음성과 관련된 대화 히스토리 정보를 수신하는 단계 및 수신된 대화 히스토리 정보를 저장하는 단계를 포함 할 수 있다. 한편, 상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른 제1 대화 시스템을 저장한 메모리를 포함하는 서 버의 제어 방법은 전자 장치로부터, 상기 전자 장치로 입력된 사용자 음성에 대응되는 텍스트 및 상기 전자 장 치에 저장된 대화 히스토리 정보를 수신하는 단계, 상기 대화 히스토리 정보를 바탕으로 상기 제1 대화 시스템 을 통해 상기 텍스트에 대한 언어 분석을 수행하는 단계 및 상기 수행된 언어 분석에 따른 결과를 상기 전자 장 치로 전송하도록 상기 통신부를 제어하는 단계를 포함하며, 상기 수신된 텍스트는 상기 전자 장치에 저장된 제2 대화 시스템을 통해 처리된 것을 특징으로 할 수 있다."}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 개시의 다양한 실시예에 의해, 전자 장치는 입력된 사용자 음성을 바탕으로 사용자 음성을 입력할 대화 시스템을 결정하고, 결정된 대화 시스템에 사용자 음성 및 대화 히스토리 정보를 제공하여 사용자 음성에 대한 응답을 획득함으로써, 사용자는 더욱 편리하게 음성 인식 기술을 활용할 수 있다. 그리고, 전자 장치는 전자 장치에 저장된 대화 시스템 또는 서버에 저장된 대화 시스템 중 적어도 하나를 통해 사용자 음성에 대한 응답을 획득함으로써, 사용자는 어떤 대화 시스템을 사용하는지 모르더라도 자연스러운 사 용자 음성에 대한 응답을 제공받을 수 있다."}
{"patent_id": "10-2019-0156158", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 개시의 다양한 실시예에 대해 설명하기로 한다. 도 1a은 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 1a에 도시된 바와 같이, 본 개시의 일 실시예에 따른, 전자 장치는 입력된 사용자 음성(예를 들면, '서래 마을로 길 안내 해줘')을 제1 대화 시스템을 포함하는 서버로 전송할 지 여부를 결정할 수 있다. 구 체적으로, 전자 장치는 사용자 음성을 제2 대화 시스템에 입력하여 사용자 음성의 신뢰도 값(예를 들어, 음성 인식 신뢰도 값 또는 언어 분석 신뢰도 값) 또는 도메인을 획득하고, 획득한 신뢰도 값 또는 도메인 을 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 전자 장치가 사용자 음성 을 서버로 전송할지 여부를 결정하는 과정은 도 2a를 참조하여 구체적으로 설명하도록 한다. 한편, 도메인(Domain)은, 음성 또는 텍스트에 대한 의미 분석의 결과로 획득되는 데이터의 일종으로, 음성 또는 텍스트에 대응하는 사용자 의도의 유형 내지는 음성 또는 텍스트에 대응되는 제어 명령의 유형에 따라 구분된 일종의 카테고리를 의미한다. 예를 들어, '오늘 날씨 알려줘'라는 사용자 음성이 입력된 경우, 사용자 음성의 도메인은 'weather'일 수 있다. 도메인은 사용자 의도 또는 제어 명령과 동일할 수도 있으며, 하나의 도메인은 복수 개의 사용자 의도 또는 제어 명령을 포함할 수도 있다. 한편, 대화 시스템(Dialogue system)은 입력된 사용자 음성을 인식 및 분석하여 사용자 음성에 대한 응답을 제 공하는 인공지능 모델(Artificial Intelligence Model)을 포함할 수 있다. 서버에 저장되어 있는 제1 대 화 시스템은, 전자 장치에 저장된 제2 대화 시스템보다 많은 양의 학습 데이터를 사용하여 학습된 인공지 능 모델이거나, 전자 장치에 저장된 제2 대화 시스템의 데이터 량 보다 많은 데이터 량을 갖는 인공지능 모델일 수 있다. 많은 양의 학습 데이터를 사용하여 학습된 인공지능 모델은, 상대적으로 적은 양의 학습 데이 터를 사용하여 학습된 인공지능 모델에 비해, 동일한 입력 음성에 대해 높은 신뢰도를 갖는 인식 결과를 출력할 수 있다. 또한, 많은 양의 학습 데이터를 사용하여 학습된 인공지능 모델은, 상대적으로 적은 양의 학습 데이터 를 사용하여 학습된 인공지능 모델에 비해, 더 많은 도메인과 관련된 음성을 처리하여 전자 장치가 도메인과 관 련된 기능을 수행하도록 제어할 수 있다. 마찬가지로, 많은 데이터 량을 갖는 인공지능 모델은, 상대적으로 적 은 데이터 량을 갖는 인공지능 모델에 비해, 동일한 입력 음성에 대해 높은 신뢰도를 갖는 인식 결과를 출력할 수 있다. 또한, 많은 데이터 량을 갖는 인공지능 모델은, 상대적으로 적은 데이터 량을 갖는 인공지능 모델에 비해, 더 많은 도메인과 관련된 음성을 처리하여 전자 장치가 도메인과 관련된 기능을 수행하도록 제어할 수 있 다. 일반적으로 많은 데이터 량을 갖는 인공지능 모델은, 상대적으로 적은 데이터 량을 갖는 인공지능 모델에 비해, 많은 양의 학습 데이터를 사용하여 학습된 모델이다. 따라서, 제1 대화 시스템은 제2 대화 시스템에 비해 사용자 음성에 대해 신뢰도 값이 높은 음성 인식 결과 또는 신뢰도 값이 높은 언어 분석 결과를 출력할 수 있다. 또한, 제1 대화 시스템은 제2 대화 시스템이 처리하지 못하는 도메인과 관련된 기능을 수행할 수 있다. 한편, 일 실시예로, 사용자 음성을 서버로 전송하는 것으로 결정되면, 전자 장치는 사용자 음성 및 저장된 대화 히스토리 정보 중 적어도 일부를 제1 대화 시스템을 포함하는 서버로 전송할 수 있다. 한편, 또 다른 실시예로, 전자 장치는 제2 대화 시스템의 제2 ASR 모듈을 통해 획득된 사용자 음성에 대응되는 텍스트 및 저장된 대화 히스토리 정보의 적어도 일부를 서버에 전송할 수 있다. 대화 히스토리 정보는 사용자 음성과 관련되며, 사용자 음성이 입력되기 이전에 획득한 음성 인식 결과, 언어 분석 결과 또는 대화 시스템의 응답에 대한 정보를 포함한다. 또한, 대화 히스토리 정보는 사용자 음성이 입력되기 이전에 전자 장치가 수행했던 작업에 대한 정보 및 사용자 음성이 입력될 당시의 전 자 장치의 상태 정보 등을 더 포함할 수 있다. 그리고, 서버는 전자 장치로부터 수신된 사용자 음성에 대응되는 텍스트 및 전자 장치에 저 장된 대화 히스토리 정보의 적어도 일부를 제1 대화 시스템에 입력하여 사용자 음성에 대응되는 텍스트에 대한 언어 분석을 수행할 수 있다. 한편, 또 다른 실시예로, 전자 장치로부터 사용자 음성을 수신한 경우, 서버는 제1 대화 시스템을 통해 사용자 음성에 대응되는 텍스트를 획득할 수 있다. 그리고, 서버는 텍스트에 대한 언어 분석에 따른 결과를 전자 장치에 전송할 수 있다. 구체적으로, 서버는 텍스트를 대화 히스토리 정보를 바탕으로 언어 분석하여 제1 언어 분석 결과 및 제1 언어 분석 신 뢰도 값을 획득하고, 텍스트 만을 바탕으로 언어 분석하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 획득할 수 있다. 그리고, 서버는 제1 및 제2 언어 분석 신뢰도 값을 바탕으로 제1 언어 분석 결과 및 제2 언어 분석 결과 중 하나를 전자 장치에 전송할 수 있다. 서버의 동작에 대한 실시예는 도 2b를 참조 하여 구체적으로 설명하도록 한다. 한편, 일 실시예로, 전자 장치는 서버로부터 사용자 음성과 관련된 대화 히스토리 정보를 수신하 여 저장할 수 있다. 도 1a에 도시된 사용자 음성과 관련된 대화 히스토리 정보는 '서래마을'이라는 지명의 위치로 길 안내를 요구하는 상황 정보일 수 있다. 구체적으로, 대화 히스토리 정보는 길 안내를 요구하는 상황 에 대한 정보,'서래 마을'이라는 길 안내의 목적지에 대한 정보, 전자 장치 상에 길 안내 서비스를 제공할 수 있는 어플리케이션이 설치되어 있는지에 대한 애플리케이션 정보 및 전자 장치가 서버와 통신 연 결이 수행되었는지에 대한 정보를 포함할 수 있다. 한편, 일 실시예로, 길 안내를 요구하는 상황에 대한 정보 및 '서래마을'이라는 길 안내의 목적지에 대한 정보 는 음성 인식 결과 및 언어 분석 결과를 통해 획득한 정보일 수 있다. 대화 히스토리 정보의 형태는 음성 또는 자연어 형태일 수 있으나, 제한되지 않는다. 그리고, 일 실시예로, 대화 히스토리 정보는 사용자 음성 또는 사용자 음성에 대한 텍스트의 적어도 일부를 포 함할 수 있다. 또한, 대화 히스토리 정보는 대화 시스템이 제공한 응답에 대한 정보를 더 포함할 수 있다. 구체 적으로, 대화 시스템이 제공한 응답에 대한 정보는 대화 시스템이 제공한 응답 메시지에 대한 자연어 문장의 적 어도 일부 또는 대화 시스템이 자연어 문장을 생성하기 위해 사용한 정보의 적어도 일부일 수 있다. 한편, 전자 장치는 서버로부터 사용자 음성에 대응되는 응답을 수신하고, 응답에 대응되는 동작 을 수행하도록 제어할 수 있다. 일 실시예로, 전자 장치는 서버로부터 '서래 마을이라는 지명의 위치 로 길 안내를 수행'하는 사용자 음성에 대한 응답을 수신할 수 있다. 여기서, 응답은 전자 장치를 통 해 출력될 응답 메시지에 대한 정보를 의미하며, 응답 메시지에 대한 정보는 전자 장치가 출력할 자연어 문장 또는 자연어 문장을 생성하기 위한 정보를 포함할 수 있다. 또한, 응답은 전자 장치가 수행할 동작에 대한 정보를 의미하며, 동작에 대한 정보는 전자 장치에서 실행할 애플리케이션에 대한 정보 또는 수행할 애플리케이션의 상세 기능에 대한 정보를 포함할 수 있다. 예를 들면, 전자 장치는 서버로부터 수신한 응답에 대응되도록, '서래마을로 길 안내를 시작합니다' 라는 메시지를 음성의 형태로 출력하거나 텍스트의 형태로 표시할 수 있다. 또한, 전자 장치는 수신된 응 답에 대응되도록 길을 안내하는 어플리케이션을 실행하고 '서래 마을'이라는 지명의 위치로 길 안내를 시작하는 상세 기능을 수행할 수 있다. 한편, 도 1a에 도시된 바와 같이, 추가 사용자 음성(예를 들어, '거기에서 찍은 사진 보여줘')이 입력되면, 전자 장치는 입력된 추가 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 구체적으로, 전자 장치는 추가 사용자 음성을 제2 대화 시스템에 입력하여 서버에 전송할지 여부를 결정할 수 있다. 전자 장치가 추가 사용자 음성을 서버로 전송할지 여부를 결정하는 과정은 도 2a를 참조하 여 구체적으로 설명하도록 한다. 추가 사용자 음성을 서버로 전송하지 않는 것으로 결정되면, 전자 장치는 제2 대화 시스템에 기 저장된 대화 히스토리 정보 중 사용자 음성과 관련된 대화 히스토리 정보를 이용하여 추가 사용자 음성(2 0)을 음성 인식 또는 언어 분석하고, 추가 사용자 음성에 대한 응답 및 추가 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 사용자 음성과 관련된 대화 히스토리 정보는, 추가 사용자 음성이 입력되기 이전에 입력 또는 응답되었던 대화와 관련된 정보를 포함할 수 있다. 이 때, 전자 장치는 소정의 횟수를 기 설정하여, 이전에 입력 또는 응답되었던 대화 중 기 설정된 횟수 내에서 입력 또는 응답되었던 대화 와 관련된 정보를 획득할 수 있다. 또한, 전자 장치는 추가 사용자 음성에 대한 음성 인식 또는 언어 분석을 수행하여, 이전에 입력 또는 응답되었던 대화 중 음성 인식 결과 또는 언어 분석 결과와 관련된 대화에 대한 정보를 획득할 수 있다. 즉, 전자 장치는 추가 사용자 음성이 입력되기 전에 서버로부터 수신된 사용자 음성과 관련 된 대화 히스토리 정보를 활용하여 추가 사용자 음성과 관련된 대화 히스토리 정보 및 응답을 획득할 수 있 다. 일 실시예로, 전자 장치는 사용자 음성과 관련된 대화 히스토리 정보 중'서래마을'이라는 지명의 위치로 길 안내를 요구하는 상황 정보를 통해 추가 사용자 음성에 포함된 '거기'라는 음성에 대응되는 텍스 트는 '서래 마을'이라는 지명을 의미하는 것이라고 식별할 수 있다. 그리고, 추가 사용자 음성과 관련된 대화 히스토리 정보는, '서래마을'과 관련된 사진 검색을 요구하는 상 황에 대한 정보, 전자 장치내에 저장된 사진들 검색할 수 있는 애플리케이션이 설치되어 있다는 애플리케 이션 정보 및 제2 사용자 음성이 입력될 당시의 전자 장치와 서버간의 통신 연결 상태 정보를 포 함할 수 있으나 이는 일 실시예에 불과하다. 또한, 전자 장치는 추가 사용자 음성에 대한 응답에 대응되는 기능을 수행할 수 있다. 일 실시예로, 전자 장치는 추가 사용자 음성에 대한 응답으로 '서래 마을에서 찍은 사진입니다'라는 음성을 출력할 수 있다. 그리고, 전자 장치는 응답에 대응되도록 사진을 표시할 수 있는 어플리케이션을 실행하여 저장된 사진 중 위치 정보가 '서래 마을'인 사진을 표시하도록 제어할 수 있다. 즉, 전자 장치가 입력된 추가 사 용자 음성을 제1 대화 시스템에 입력하여 음성 형태의 응답 메시지를 출력하고, 특정 애플리케이션을 실행 하는 일련의 과정은 앞서 사용자 음성과 관련하여 설명된 서래마을로 길 안내를 하는 실시예와 유사하게 동 작할 수 있다. 도 1b는 본 개시의 일 실시예에 따른, 전자 장치가 입력된 사용자 음성을 전송할 대화 시스템을 결정하는 과정을 설명하기 위한 도면이다. 일 실시예로, 도 1b의 (a)에 도시된 바와 같이, '길 안내해줘'라는 사용자 음성이 입력되면, 전자 장치 는 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 사용자 음성을 제2 대화 시스템의 제2 ASR 모듈에 입력하여 사용자 음성에 대응되는 텍스트 및 음성 인식 신뢰 도 값을 획득할 수 있다. 일 실시예로, 음성 인식 신뢰도 값이 제1 임계값을 초과할 경우, 전자 장치는 제2 대화 시스템을 통해 사 용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 그리고, 전자 장치는 사용자 음성과 관련된 대화 히스토리 정보를 저장할 수 있다. 사용자 음성과 관련된 대화 히스토리 정보는 사용자가 길 안내를 요구하는 상황에 대한 정보, 길 안내를 수행할 수 있는 어플리케이션의 설 치 여부에 대한 정보 등을 포함할 수 있으나 이에 한정되지 않는다. 한편, 본 개시에 기재된 임계값은 기설정된 값일 수 있으나 이는 일 실시예에 불과하며 사용자 명령에 의해 변경될 수 있음은 물론이다. 그리고, 전자 장치는 사용자 음성에 대한 응답을 제공할 수 있다. 예를 들어, 전자 장치는 도 1b 의 (a)에 도시된 바와 같이 “어디로 가시나요”라는 길 안내를 수행할 목적지를 묻는 응답 메시지를 제공할 수 있다. 한편, 도 1b의 (b)에 도시된 바와 같이, 이전 사용자 음성에 대한 응답에 대응되는 '서래 마을'이라는 사용 자 음성이 입력되면, 전자 장치는 사용자 음성을 서버에 전송할 지 여부를 결정할 수 있다. 사용자 음성에 대한 음성 인식 신뢰도 값이 제1 임계값 이하인 경우, 전자 장치는 사용자 음성 및 기저장된 이전 사용자 음성과 관련된 대화 히스토리 정보를 서버에 전송할 수 있다. 그리고, 일 실시예로, 서버는 수신된 사용자 음성 및 이전 사용자 음성과 관련된 대화 히스토리 정보를 바탕으로 제1 대화 시스템을 통해 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스 토리 정보를 획득할 수 있다. 구체적으로, 서버는 현재 사용자가 길 안내를 요구하고 있다는 상황 정보가 포함된 이전 사용자 음성과 관련된 대화 히스토리 정보를 이용하여 사용자 음성에 대응되는 텍스트의 의도는 '서래 마을'이라는 목적지로 길 안내를 요구하는 것임을 파악할 수 있다. 그리고, 서버는 제1 대화시스템을 통해 사용자 음성에 대한 응답(예를 들어, “서래마을로 길 안내를 시작합니다”라는 응답 메시지 및 서래마을로 길 안내를 수행하는 어플리케이션과 관련된 정보) 및 사용자 음성과 관련된 대화 히스토리 정보(예를 들어, 서래 마을이라는 목적지로 길 안내를 수행하고 있는 상황에 대한 정보, 길 안내를 수행하는 어 플리케이션에 대한 정보)를 획득할 수 있다. 그리고, 서버는 전자 장치에게 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 전송할 수 있다. 그리고, 도 1b의 (c)에 도시된 바와 같이, 이전 사용자 음성에 대한 응답에 대응되는 '아 거기 날씨는 지금 어때?'라는 사용자 음성이 입력 되면, 전자 장치는 다시 사용자 음성을 서버에 전송할 지 여부를 결정할 수 있다. 사용자 음성 의 음성 인식 신뢰도 값이 제1 임계값을 초과할 경우, 전자 장치는 이전 사용자 음성과 관련된 대 화 히스토리 정보를 통해 현재 사용자 음성에 대응되는 텍스트에 포함된 '거기'라는 단어의 의미는 '서래 마을'이라는 목적지임을 식별할 수 있다. 그리고, 전자 장치는 제2 대화 시스템을 통해 현재 사용자 음성 에 대한 응답 및 사용자 음성과 관련된 정보를 획득할 수 있다. 사용자 음성에 대한 응답은 현재 서래 마을의 날씨에 대한 메시지(예를 들어, “서래마을 날씨는 현재 흐리고 기온은 15도 입니다”)일 수 있다. 그리고, 사용자 음성과 관련된 대화 히스토리 정보는 서래 마을의 날씨를 물어본 상황 정보 및 현재 서래마 을 날씨에 대한 정보를 포함할 수 있다. 즉, 도 1b에 도시된 바와 같이, 전자 장치는 지속적으로 입력되는 사용자 음성 및 사용자 음성에 대한 대 화 히스토리 정보를 저장된 제2 대화 시스템 또는 서버에 저장된 제1 대화 시스템 중 적어도 하나를 이용 하여 사용자 음성에 대한 응답을 획득할 수 있다. 도 2a는 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법을 설명하기 위한 도면이다. 우선, 전자 장치는 입력된 사용자 음성을 제1 대화 시스템을 포함하는 서버로 전송하는지 여부를 결 정할 수 있다(S210-1). 구체적으로, 전자 장치는 사용자 음성을 제2 대화 시스템에 입력하여 사용자 음성 의 신뢰도 값 또는 도메인 획득하고, 획득한 신뢰도 값 또는 도메인을 바탕으로 사용자 음성을 서버로 전 송할지 여부를 결정할 수 있다. 일 실시예로, 전자 장치는 제2 대화 시스템의 제2 ASR 모듈을 통해, 사용자 음성에 대응되는 텍스트 및 사 용자 음성의 음성 인식 신뢰도 값(confidence score)을 획득할 수 있다. 음성 인식 신뢰도 값은 사용자 음성이 얼마나 정확하게 인식되어 텍스트로 변환되었는지를 나타내는 수치다. 그리고, 전자 장치는 사용자 음성의 음성 인식 신뢰도 값을 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 예를 들면, 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값 이하인 경우, 전자 장치 는 사용자 음성을 서버로 전송하는 것으로 결정할 수 있다. 한편, 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값을 초과할 경우, 전자 장치는 제2 대화 시스템을 통해 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 제2 ASR 모듈과 관련된 실시예는 도 3a을 참조하여 구체 적으로 설명하도록 한다. 또 다른 실시예로, 전자 장치는 제2 대화 시스템의 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값을 획득할 수 있다. 언어 분석 신뢰도 값은 사용자 음성에 대응되는 텍스트의 의미를 어느 정도의 신뢰도를 가지고 분석하여 결정하였는지에 대한 수치이다. 그리고, 전자 장치는 사용자 음성의 언어 분석 신뢰도 값을 바탕으로 사용자 음성을 서버로 전송 할지 여부를 결정할 수 있다. 예를 들면, 사용자 음성의 언어 분석 신뢰도 값이 제2 임계값 이하인 경우, 전자 장치는 사용자 음성을 서버로 전송하는 것으로 결정할 수 있다. 그리고, 사용자 음성의 언어 분석 신 뢰도 값이 제2 임계값을 초과할 경우, 전자 장치는 제2 대화 시스템을 통해 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 언어 분석 신뢰도 값과 관련된 실시예는 도 3b를 참조하여 구체적으로 설명하도록 한다. 또 다른 실시예로, 전자 장치는 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트의 도메인(Domain) 및 도메인과 관련된 정보를 획득할 수 있다. 그리고, 전자 장치는 획득한 도메인과 관련된 정보를 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 도메인과 관련된 실시예는 도 3c를 참조하여 구체적으로 설명하도록 한다. 또 다른 실시예로, 전자 장치는 전자 장치의 상태 정보를 바탕으로 사용자 음성을 서버로 전송 할 지 여부를 결정할 수 있다. 일 실시예에 따른, 전자 장치는 현재 전자 장치의 배터리 충전 양, 서버와의 통신 연결 상태 등을 바탕으로 사용자 음성을 서버로 전송할 지 여부를 결정할 수 있다. 전자 장치 의 상태 정보와 관련된 실시예는 도 3d을 참조하여 구체적으로 설명하도록 한다. 또 다른 실시예로, 전자 장치는 사용자로부터 선택된 대화 시스템에 따라 사용자 음성을 서버로 전송 할 지 여부를 결정할 수 있다. 일 실시예로, 서버에 저장된 대화 시스템이 선택되면, 전자 장치는 사 용자 음성을 서버로 전송하는 것으로 결정할 수 있다. 사용자 선택과 관련된 실시예는 도 3e을 참조하여 구체적으로 설명하도록 한다. 한편, 사용자 음성을 서버로 전송하는 것으로 결정되면, 전자 장치는 사용자 음성(또는, 사용자 음성 에 대응되는 텍스트) 및 대화 히스토리 정보 중 적어도 일부를 서버로 전송할 수 있다(S220-1). 따라서, 서버의 제1 대화 시스템은, 수신된 대화 히스토리 정보를 이용하여 사용자 음성에 대한 응답 및 사용자 음 성과 관련된 대화 히스토리 정보를 출력할 수 있다. 전자 장치는 서버로부터 사용자 음성에 대한 대화 히스토리 정보를 수신할 수 있다(S230-1). 또한, 전자 장치는 사용자 음성에 대한 응답을 수신할 수 있다. 그리고, 전자 장치는 수신한 사용자 음성과 관련된 대화 히스토리 정보를 저장할 수 있으며(S240-1), 서버로부터 받은 응답에 기초하여 사용자 음성에 대한 응답 메시지를 제공할 수 있다. 도 2b는 본 개시의 일 실시예에 따른, 서버의 제어 방법을 설명하기 위한 도면이다. 우선, 서버는 전자 장치에 입력된 사용자 음성에 대응되는 텍스트 및 전자 장치에 저장된 대화 히스토리 정보를 전자 장치로부터 수신할 수 있다(S210-2). 한편, 또 다른 실시예로, 서버는 전자 장 치로부터 전자 장치에 입력된 사용자 음성 및 전자 장치에 저장된 대화 히스토리 정보를 수신할 수 있다. 이 경우, 서버는 사용자 음성을 제1 대화 시스템의 제1 ASR 모듈에 입력하여 사용자 음성에 대응 되는 텍스트를 획득할 수 있다. 그리고, 서버는 대화 히스토리 정보를 바탕으로 제1 대화 시스템을 통해 텍스트에 대한 언어 분석을 수행 할 수 있다(S220-2). 구체적으로, 서버는 텍스트 및 대화 히스토리 정보를 바탕으로 언어 분석을 수행하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 획득하고, 텍스트만을 바탕으로 언어 분석을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 획득할 수 있다. 현재 전자 장치로부터 수신된 사용자 음성에 대응되는 텍스트가 이전에 전자 장치에 입력된 사용자 음성과 관련된 음성에 대응되는 텍스트인 경우, 서버는 이전에 입력된 사용자 음성과 관련된 대화 히스토 리 정보를 활용하여 현재 수신된 텍스트에 대해 언어 분석 수행하는 것이 텍스트만을 바탕으로 언어 분석 수행 하는 것보다 사용자 의도를 정확하게 파악할 수 있다. 한편, 현재 전자 장치로부터 수신된 사용자 음성에 대응되는 텍스트가 이전에 입력된 사용자 음성과는 독립적인 음성인 경우, 서버는 이전에 입력된 사용자 음성과 관련된 대화 히스토리 정보를 무시하고 텍스트만을 바탕으로 언어 분석 수행하는 것이 사용자 의도를 정 확하게 파악할 수 있다. 따라서, 서버는 텍스트를 각각 다른 방식으로 언어 분석 수행하여 제1 및 제2 언 어 분석 신뢰도 값을 획득하고 이를 비교함으로써 전자 장치에 입력된 사용자 음성에 대응되는 텍스트가 이전 사용자 음성과 관련된 음성에 대응되는 텍스트인지 혹은 이전 사용자 음성과는 관련 없는 독립적인 발화에 대응되는 텍스트인지 구분할 수 있다. 언어 분석 수행 과정의 구체적인 과정은 도 5를 참조하여 구체적으로 설 명하도록 한다. 그리고, 서버는 수행된 언어 분석에 따른 결과를 전자 장치에 전송할 수 있다(S230-2). 구체적으로, 제1 언어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값을 초과할 경우, 서버는 제1 언어 분석 결과를 전자 장치에 전송할 수 있다. 한편, 또 다른 실시예로, 제1 언어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값 이하인 경우, 서버는 제2 언어 분석 결과 중 텍스트의 도메인에 대한 정보를 바탕으로 언어 분석 결과를 전자 장치에 전송할 지 여 부를 결정할 수 있다. 일 실시예로, 텍스트의 도메인이 전자 장치가 처리할 수 있는 경우, 서버는 제 2 언어 분석 결과를 전자 장치에 전송할 수 있다. 또 다른 예로, 텍스트의 도메인이 전자 장치가 처 리할 수 없는 경우, 서버는 제2 언어 분석 결과를 바탕으로 제1 대화 시스템을 통해 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 그리고, 서버는 획득된 사용자 음성 에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 전자 장치에 전송할 수 있다.도 3a은 본 개시의 일 실시예에 따른, 전자 장치가 음성 인식 신뢰도 값을 바탕으로 사용자 음성을 서버 로 전송할지 여부를 결정하는 과정을 설명하기 위한 도면이다. 우선, 전자 장치는 입력된 사용자 음성을 제2 대화 시스템에 입력할 수 있다(S310). 그리고, 전자 장치 는 제2 대화 시스템의 제2 ASR 모듈을 통해 사용자 음성에 대응되는 텍스트 및 음성 인식 신뢰도 값을 획 득할 수 있다(S320). 구체적으로, 전자 장치는 제2 ASR 모듈을 통해 어느 정도의 신뢰도를 가지고 입력된 사용자 음성을 인식하여 텍스트로 변환하였는지에 대한 수치를 획득할 수 있다. 음성 인식 신뢰도 값은 0 또는 1의 값일 수 있으며 1에 가까울수록 높은 신뢰도를 가지고 사용자 음성을 인식하여 텍스트로 변환하였음을 의미 한다. 그리고, 전자 장치는 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값을 초과하는지 여부를 식별할 수 있 다(S330). 일 실시예로, 사용자 음성에 대응되는 텍스트 중 일부가 제2 ASR 모듈의 언어 모델에 의해 학습되지 않은 텍스트를 포함하면, 전자 장치는 제2 ASR 모듈을 통해 사용자 음성의 음성 인식 신뢰도 값을 제1 임 계값 이하로 판단할 수 있다. 예를 들면, '서래 마을로 길 안내해줘'라는 사용자 명령이 입력되었을 때 '서래마 을'이라는 텍스트가 제2 ASR 모듈의 언어 모델에 의해 학습되지 않은 경우, 전자 장치는 제2 ASR 모듈을 통해 사용자 음성의 음성 인식 신뢰도 값을 제1 임계값 이하로 판단할 수 있다. 일 실시예로, 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값을 초과하는 경우, 전자 장치는 제2 대화 시스템을 통해 사용자 음성과 관련된 대화 히스토리 정보 및 응답을 획득할 수 있다(S330). 사용자 음성의 음성 인식 신뢰도 값이 제1 임계값 이하인 경우, 전자 장치는 사용자 음성을 서버로 전송하는 것으로 결정 할 수 있다(S350). 도 3b는 본 개시의 일 실시예에 따른, 전자 장치가 언어 분석 신뢰도 값을 바탕으로 사용자 음성을 서버 로 전송할지 여부를 결정하는 과정을 설명하기 위한 도면이다. 전자 장치는 입력된 사용자 음성을 제2 대화 시스템에 입력할 수 있다(S410). 그리고, 전자 장치는 제2 대화 시스템의 제2 NLU 모델을 통해 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값을 획득할 수 있다(S420). 즉, 전자 장치는 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트를 어느 정도의 신뢰 도를 가지고 분석하여 이해하였는지에 대한 수치를 획득할 수 있다. 언어 분석 신뢰도 값은 0 또는 1의 값일 수 있으며 1에 가까울수록 높은 신뢰도를 가지고 사용자 음성에 대응되는 텍스트를 분석하여 이해하였음을 의미한 다. 그리고, 전자 장치는 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값이 제2 임계값을 초과하 는지 여부를 식별할 수 있다(S430). 일 실시예로, 사용자 음성에 대응되는 텍스트 중 일부가 학습되지 않은 언 어를 포함하는 경우, 전자 장치는 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트의 언어 분석 신뢰 도 값을 제2 임계값 이하로 판단할 수 있다. 일 실시예로, 언어 분석 신뢰도 값이 제2 임계값 초과한 경우, 전자 장치는 제2 대화 시스템을 통해 사용 자 음성에 대한 응답 및 대화 히스토리 정보를 획득할 수 있다(S440). 만약, 언어 분석 신뢰도 값이 제2 임계값 이하인 경우, 전자 장치는 사용자 음성을 서버로 전송하는 것으로 결정할 수 있다(S450). 도 3c는 본 개시의 일 실시예에 따른, 전자 장치가 사용자 음성에 대응되는 텍스트의 도메인과 관련된 정 보를 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정하는 과정을 설명하기 위한 도면이다. 전자 장치는 입력된 사용자 음성을 제2 대화 시스템에 입력할 수 있다(S510). 그리고, 전자 장치는 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트의 도메인 및 도메인과 관련된 정보를 획득할 수 있다 (S520). 도메인과 관련된 정보는 도메인이 제1 또는 제2 대화 시스템의 전용 도메인인지 아니면 각 대화 시스템 이 모두 처리할 수 있는 도메인인지와 관련된 정보 및 해당 도메인에 대한 처리 여력 정보를 포함할 수 있다. 일 실시예로, 'ASTC 학회 주소 알려줘'라는 사용자 음성이 입력되면, 전자 장치는 제2 NLU 모듈을 통해'주 소(location)'라는 도메인과 '주소'가 제1 또는 제2 대화 시스템의 전용 도메인인지 대한 정보를 획득할 수 있 다. 한편, 전자 장치는 도메인과 관련된 정보를 바탕으로 제2 대화 시스템이 사용자 음성을 처리할 수 있는지 에 대해 판단할 수 있다(S536). 일 실시예로, '주소'가 제1 대화 시스템 전용 도메인이라는 정보를 획득한 경우, 전자 장치는 입력된 사용자 음성을 제2 대화 시스템에서 처리할 수 없다고 판단할 수 있다. 또 다른 실시예로, '주소'가 제2 대화 시스템 전용 도메인이거나 제1 대화 시스템 및 제2 대화 시스템이 모두 처리할 수 있는 도메인이라는 정보를 획득한 경우, 전자 장치는 입력된 사용자 음성을 제2 대화 시스템에서 처리할 수 있다고 판단할 수 있다. 도메인과 관련된 정보를 바탕으로 제2 대화 시스템이 사용자 음성을 처리할 수 없다고 판단되면, 전자 장치 는 사용자 음성을 서버로 전송할 수 있다(S540). 도메인과 관련된 정보를 바탕으로 제2 대화 시스템 이 사용자 음성을 처리할 수 있다고 판단되면, 전자 장치는 사용자 음성을 서버로 전송하지 않고 (S550), 제2 대화 시스템을 통해 사용자 음성과 관련된 대화 히스토리 정보 및 응답을 획득할 수 있다. 도 3d은 본 개시의 일 실시예에 따른, 전자 장치가 전자 장치의 상태 정보를 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정하는 과정을 설명하기 위한 순서도이다. 우선, 전자 장치는 사용자 음성을 입력받을 수 있다(S610). 그리고, 전자 장치는 전자 장치의 상태 정보를 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다(S620). 일 실시예로, 전자 장치는 서버와의 통신 연결 상태를 바탕으로 사용자 음성을 입력할 대화 시스템을 결정할 수 있다. 예를 들어, 서버와 통신 연결이 수행되지 않은 경우, 전자 장치는 사용자 음성을 서 버에 전송하지 않고 제2 대화 시스템에 입력하여 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 한편, 추가 사용자 음성이 입력되는 동안 서버와 통신 연결이 수행되면, 전자 장치는 추가 사용자 음 성을 제2 대화 시스템에 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 즉, 서버와 통신 연결이 수행되면, 전자 장치는 제2 대화 시스템에서 획득한 사용자 음성의 신뢰도 값 및 도메인을 바탕으로 사용 자 음성을 서버로 전송할지 여부를 결정할 수 있다. 또 다른 실시예로, 서버에 사용자 음성 및 대화 히스토리 정보 중 적어도 일부를 전송하였으나 임계 시간 내에 사용자 음성과 관련된 대화 히스토리 정보를 수신하지 못한 경우, 전자 장치는 서버와 통신 연 결 상태가 좋지 않다고 식별할 수 있다. 그리고, 전자 장치는 사용자 음성을 서버로 전송하지 않을 것으로 결정하고, 제2 대화 시스템에 사용자 음성을 입력하여 사용자 음성과 관련된 대화 히스토리 정보를 획득 할 수 있다. 또 다른 실시예로, 전자 장치는 전자 장치의 배터리 충전 상태를 바탕으로 사용자 음성을 서버 로 전송할지 여부를 결정할 수 있다. 전자 장치의 배터리 충전양이 임계 값 이하인 경우, 전자 장치 는 배터리 소모량를 줄이기 위하여 사용자 음성을 서버에 전송하지 않는 것으로 결정할 수 있다. 그리고, 전자 장치는 제2 대화 시스템에 사용자 음성을 입력하여 사용자 음성과 관련된 대화 히스토리 정보를 획득 할 수 있다. 도 3e는 본 개시의 일 실시예에 따른, 전자 장치가 사용자 음성에 대한 응답을 제공할 대화 시스템을 선택 하는 과정을 설명하기 위한 도면이다. 본 개시의 일 실시예에 따른, 사용자 음성에 대한 응답을 제공할 대화 시스템이 선택되면, 전자 장치는 사 용자 음성에 대한 응답을 제공할 대화 시스템을 선택된 대화 시스템으로 결정할 수 있다. 한편, 도 3e에는 전자 장치가 스마트폰으로 구현되어 있고 입력부는 터치 스크린으로 구현되어 있으나 이는 일 실시예에 불 과하다. 즉, 전자 장치는 다양하게 구현된 입력부를 통해 사용자 음성에 대한 응답을 제공할 대화 시 스템을 선택하는 사용자 명령을 수신할 수 있다. 일 실시예로, 도 3e에 도시된 바와 같이, 전자 장치는 사용자 음성에 대한 응답을 제공할 대화 시스템을 선택할 수 있는 UI를 표시할 수 있다. 서버에 저장된 제1 대화 시스템을 나타내는 UI가 터치 스크린 을 통해 선택되면, 전자 장치는 사용자 음성을 서버로 전송할 수 있다. 그리고, 사용자로부터 전자 장치에 내장된 제2 대화 시스템을 나타내는 UI가 터치 스크린을 통해 선택되면, 전자 장치는 사 용자 음성을 제2 대화 시스템에 입력하여 사용자 음성과 관련된 대화 히스토리 정보 및 사용자 음성에 대한 응답을 획득할 수 있다. 도 4a는 본 개시의 일 실시예에 따른, 전자 장치의 구성을 간략히 도시한 블록도이다. 도 4a에 도시된 바와 같 이, 전자 장치는 통신부, 마이크, 메모리 및 프로세서를 포함할 수 있다. 도 4에 도 시된 구성은 본 개시의 실시예들을 구현하기 위한 예시도이며, 통상의 기술자에게 자명한 수준의 적절한 하드웨 어 및 소프트웨어 구성들이 전자 장치에 추가로 포함될 수 있다. 통신부는 다양한 통신 방식을 통해 외부의 장치와 통신을 수행할 수 있다. 통신부가 외부 장치와 통 신 연결되는 것은 제3 기기(예로, 중계기, 허브, 엑세스 포인트, 서버 또는 게이트웨이 등)를 거쳐서 통신하는 것을 포함할 수 있다. 한편, 통신부는 외부 장치와 통신을 수행하기 위해 다양한 통신 모듈을 포함할 수 있다. 일 예로, 통신부 는 무선 통신 모듈을 포함할 수 있으며, 예를 들면, LTE, LTE-A(LTE Advance), 5G(5TH Generation), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), 또는 GSM(Global System for Mobile Communications) 등 중 적어도 하 나를 사용하는 셀룰러 통신 모듈을 포함할 수 있다. 또 다른 예로, 무선 통신 모듈은, 예를 들면, WiFi(wireless fidelity), 블루투스, 블루투스 저전력(BLE), 지그비(Zigbee), 중 적어도 하나를 포함할 수 있 다. 마이크는 사용자 음성을 입력받기 위한 구성으로, 전자 장치 내부에 구비될 수 있으나, 이는 일 실시 예에 불과할 뿐, 전자 장치의 외부에 구비되어 전자 장치와 전기적으로 연결되거나 통신부를 통 해 통신 연결될 수 있다. 메모리는 전자 장치의 적어도 하나의 다른 구성요소에 관계된 인스트럭션(Instruction) 또는 데이터 를 저장할 수 있다. 인스트럭션은 프로그래밍 언어(programming language)에서 전자 장치에 대한 하나의 동작 문장(action statement)이며, 전자 장치가 직접 수행할 수 있는 프로그램의 최소 단위이다. 일 실시 예로, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는 전자 장치에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 또한, 메모리 에는 디스플레이의 디스플레이 영역에 표시될 각종 화면을 구성하기 위한 프로그램 및 데이터 등이 저장될 수 있다. 특히, 메모리는 제2 대화 시스템을 실행하기 위한 프로그램을 저장할 수 있다. 이때, 제2 대화 시스템은 전자 장치에 대한 다양한 서비스를 제공하기 위한 개인화된 프로그램이다. 또한, 메모리는 제2 대화 시스템과 관련된 대화 히스토리 정보를 획득하기 위한 프로그램 및 제2 대화 시스템과 관련된 대화 히스토리 정 보를 저장할 수 있다. 또한, 메모리는 서버로부터 제1 대화 시스템과 관련한 대화 히스토리 정보를 획득하기 위한 프로그램 및 제1 대화 시스템과 관련된 대화 히스토리 정보를 저장할 수 있다. 그리고, 일 실시 예로 메모리는 제2 대화 시스템이 실행되는 동안 대화 히스토리 정보를 저장할 수 있고, 제2 대화 시스템 의 수행이 종료될 때 메모리에 저장된 대화 히스토리 정보는 삭제될 수 있다. 한편, 메모리에는 도 4a에 도시된 바와 같이 다양한 소프트웨어 모듈이 저장될 수 있다. 각 소프트웨어 모 듈은 프로세서에 의해 제어될 수 있다. 구체적으로, 메모리에 저장된 각 소프트웨어 모듈은 프로세서 제어에 의해 휘발성 메모리(예를 들어, DRAM(Dynamic Random-Access Memory) 및 SRAM(Static RAM) 등)에 로딩될 수 있다. 휘발성 메모리는 프로세서와 연동될 수 있는 별개의 구성요소로 구현될 수 있으나 이는 일 실시예에 불과하며 휘발성 메모리는 프로세서의 일 구성요소로서 프로세서에 포함된 형태로 구현 될 수도 있다. 한편, 휘발성 메모리는 저장된 정보를 유지하기 위해서는 지속적인 전력 공급이 필요한 메모리를 말한다. Voice Assistant Client 모듈은 프로세서 제어에 의해 마이크를 통해 입력된 사용자 음성을 다 른 소프트웨어 모듈이 처리할 수 있도록 휘발성 메모리 중 제1 저장 영역에 기록 및 저장할 수 있다. 한편, 본 개시를 설명함에 있어서, 휘발성 메모리의 제1 내지 제5 저장 영역은 각 소프트웨어 모듈이 특정 데이터를 처리하기 위해 휘발성 메모리 내에 특정 데이터가 저장되어 있는 저장 영역을 액세스 하는 과정을 설명하기 위한 것으로, 각 저장 영역은 별개의 저장 영역일 수 있으나 이는 일 실시예에 불과하며, 일부 저장 영역은 또 다른 일 부 저장 영역의 구성요소로서 포함되는 형태로 구현될 수 있다. Coordinator 모듈은 휘발성 메모리 중 제2 저장 영역에 액세스하여, 제2 저장 영역에 기록 및 저장된 사용 자 음성의 음성 인식 신뢰도 값, 언어 분석 신뢰도 값을 바탕으로 사용자 음성 또는 사용자 음성에 대응되는 텍 스트 중 적어도 하나를 서버로 전송할지 여부를 결정할 수 있다. 또 다른 예로, Coordinator 모듈은 휘발성 메모리 중 제3 저장 영역에 액세스하여 사용자 음성에 대응되는 텍스트의 도메인, 언어 분석 신뢰도 값 을 바탕으로 사용자 음성에 대응되는 텍스트 또는 사용자 음성 중 적어도 하나를 서버로 전송할지 여부를 결정하는 과정은 추후 프로세서의 동작을 참조하여 구체적으로 설명하도록 한다. 한편, 제2 ASR 모듈(105-1)은 휘발성 메모리 중 제1 저장 영역에 액세스하여, 제1 저장 영역에 기록 및 저장된 사용자 음성에 대해 음성 인식을 수행하고, 인식된 사용자 음성에 대응되는 텍스트를 출력할 수 있다. 또한, 제 2 ASR 모듈(105-1)은 각 사용자 음성에 대한 음성 인식 신뢰도 값을 산출할 수 있다. 음성 인식 신뢰도 값은 제 2 ASR 모듈(105-1)이 어느 정도의 신뢰도를 가지고 입력된 사용자 음성을 인식하여 텍스트로 변환하였는지를 수 치화한 값이다. 따라서, 음성 인식 신뢰도 값이 높다는 것은 제2 ASR 모듈(105-1)이 사용자 음성을 더 확실하게 인식하여 사용자 음성에 대응되는 텍스트로 변환했음을 의미할 수 있다. 그리고, 제2 ASR 모듈(105-1)이 출력한 사용자 음성에 대응되는 텍스트 및 음성 인식 신뢰도 값은 프로세서 제어에 의해 휘발성 메모리의 제2 저 장 영역에 기록 및 저장할 수 있다. 본 개시의 일 실시예로, 사용자 음성에 대응되는 텍스트 중 일부가 제2 ASR 모듈(105-1)의 언어 모델(미도시)에 학습되지 않은 경우, 제2 ASR 모듈(105-1)은 음성 인식 신뢰도 값을 제1 임계값 이하로 산출할 수 있다. 예를 들어, '서래마을에 있는 CDE 빌딩 전화 번호 알려줘'라는 사용자 음성이 마이크를 통해 입력될 때, 사용자 음성에 대응되는 텍스트 중 제2 ASR 모듈(105-1)의 언어 모델에 의해 학습되지 않은 'CDE 빌딩'을 포함하고 있 으면, 제2 ASR 모듈(105-1)은 입력된 사용자 음성에 대한 음성 인식 신뢰도 값을 제1 임계값 이하로 산출할 수 있다. 한편, 제2 NLU(Natural Language Understanding) 모듈(105-2)은 휘발성 메모리의 제2 저장 영역에 액세스하여, 제2 저장 영역에 기록 및 저장되어 있는 사용자 음성에 대응되는 텍스트를 바탕으로 도메인(domian), 의도 (Intent) 및 의도를 파악하는데 필요한 파라미터(parameter)(또는, 슬롯(slot))로 나누어진 매칭 규칙을 이용하 여 사용자의 의도 및 파라미터를 결정할 수 있다. 구체적으로, 하나의 도메인(예: 알람)은 복수의 의도(예: 알 람 설정, 알람 해제)를 포함할 수 있고, 하나의 의도는 복수의 파라미터(예: 시간, 반복 횟수, 알림음 등)을 포 함할 수 있다. 그리고, 매칭 규칙은 NLU Database(미도시)에 저장될 수 있다. 그리고, 제2 NLU 모듈(105-2)는 형태소, 구 등의 언어적 특징(예: 문법적 요소)를 이용하여 사용자 입력으로부터 추출된 단어의 의미를 파악하 고, 파악된 단어의 의미를 도메인 및 의도에 매칭시켜 사용자의 의도를 결정할 수 있다. 그리고, 제2 NLU 모듈 (105-2)이 출력한 언어 분석 신뢰도 값 및 사용자 음성에 대응되는 텍스트의 도메인, 의도, 파라미터 등은 프로 세서 제어에 의해 휘발성 메모리의 제3 저장 영역에 기록 및 저장될 수 있다. 예를 들어, 제2 ASR 모듈(105-2)를 통해 텍스트로 변환된 사용자 음성이 '서래마을로 길 안내해줘'인 경우, 제2 NLU 모듈(105-2)은 '서래 마을', '길 안내'등의 단어의 의미를 파악하여 사용자가 '서래 마을'이라는 지명의 위 치로 경로 안내를 요구한다는 의도를 획득할 수 있다. 그리고, 제2 NLU 모듈(105-2)은 제2 ASR 모듈을 통해 획득한 사용자 음성에 대응되는 텍스트에 대한 언어 분석 신뢰도 값을 산출할 수 있다. 언어 분석 신뢰도 값은 제2 NLU 모듈(105-2)이 어느 정도의 신뢰도를 가지고 사용 자 음성에 대응되는 텍스트를 분석하여 이해하였는지에 대한 수치다. 따라서, 언어 분석 신뢰도 값이 높다는 것 은 제2 NLU 모듈(105-2)이 사용자 음성에 대응되는 텍스트를 더 확실하게 언어 분석하여 사용자의 의도를 파악 했다는 것을 의미할 수 있다. 제2 DM(Dialogue Manager) 모듈(105-3)은 휘발성 메모리의 제3 저장 영역에 액세스하여, 제3 저장 영역에 기록 및 저장되어 있는 사용자의 의도에 대한 정보가 명확한지 여부를 판단할 수 있다. 구체적으로, 제2 DM 모듈 (105-3)은 파라미터의 정보가 충분한지 여부에 기초하여 사용자의 의도가 명확한지 여부를 판단할 수 있다. 그 리고, 제2 DM 모듈(105-3)은 제2 NLU 모듈(105-2)을 통해 파악된 의도 및 파라미터에 기초하여 동작을 수행할 수 있는 경우, 사용자 입력에 대응되는 태스크를 수행한 결과(또는, 응답)를 생성할 수 있다. 그리고, 제2 DM 모듈(105-3)이 출력한 사용자 입력에 대응되는 결과 및 응답은 프로세서 제어에 의해 휘발성 메모리의 제4 저장 영역에 저장될 수 있다.예를 들어, 제2 NLU 모듈(105-2)에서 '서래마을'이라는 지명의 위치로 경로 안내를 요구하는 사용자 의도를 파 악한 경우, 제2 DM 모듈(105-3)은 서래마을로 길 안내를 시작한다는 의미의 응답을 생성할 수 있다. 한편, 또 다른 예로, 제2 DM 모듈(105-3)은 서버로부터 수신되어 휘발성 메모리에 저장된 사용자 음성에 대응되는 텍스트에 대한 언어 분석 결과를 바탕으로 서버의 제1 NLU 모듈(205-2)에 의해 파악된 사용자의 의도가 명 확한지 여부를 판단할 수 있다. 판단하는 과정은 전술하였으므로 중복되는 설명은 생략하도록 한다. 제2 NLG(Natural Language Generator) 모듈(105-4)은 휘발성 메모리 중 제4 저장 영역에 액세스하여, 제4 저장 영역에 기록 및 저장된 사용자 음성에 대한 응답을 텍스트 형태로 변경할 수 있다. 텍스트 형태로 변경된 정보 는 자연어 발화의 형태일 수 있다. 예를 들어, 제2 NLG 모듈(105-4)은 휘발성 메모리에 기록 및 저장된 서래마 을로 길 안내를 시작한다는 의미의 응답을 바탕으로 '서래마을로 길 안내를 시작합니다'라는 텍스트를 출력할 수 있다. 제2 NLG 모듈(105-4)에 의해 출력된 텍스트는 프로세서 제어에 의해 휘발성 메모리의 제5 저장 영역에 기록 및 저장될 수 있다. 그리고, 텍스트 형태로 변경된 사용자 음성에 대한 응답은 전자 장치에 표시될 수 있다. 또 다른 예로, TTS(Text to Speech Synthesis) 모듈(미도시)이 휘발성 메모리의 제5 저장 영 역에 액세스하여, 제5 저장 영역에 기록 및 저장된 텍스트를 음성 형태로 변경하여 출력할 수 있다. 한편, 제2 대화 시스템 데이터(105-7)는 제2 대화 시스템에 포함된 소프트웨어 모듈을 학습시키기 위한 학 습 데이터가 저장되어 있을 수 있다. 제2 Context Understanding 모듈(또는, 제2 대화 히스토리 정보 이해부)(105-5)은 입력된 사용자 음성을 바탕으 로 사용자 음성이 입력되기 전에 전자 장치가 수행했던 작업에 대한 정보, 사용자 음성에 포함된 대화 상 황 정보 및 사용자 음성이 입력될 당시의 전자 장치의 상태 정보를 식별할 수 있다. 예를 들어, 사용자 음 성이 '서래마을로 길 안내해줘'인 경우, 제2 Context Understanding 모듈(105-5)은 사용자 음성을 바탕으로 '서 래마을'이라는 지명의 위치로 길 안내를 요구하는 상황 정보, 전자 장치 상에 길 안내 서비스를 제공할 수 있는 어플리케이션이 설치되어 있는지에 대한 정보를 식별할 수 있다. 그리고, 제2 Context Generator 모듈(또는, 제2 대화 히스토리 정보 생성부)(105-6)은 휘발성 메모리에 기록 및 저장된 정보를 바탕으로 대화 히스토리 정보를 생성하고, 생성된 대화 히스토리 정보를 대화 히스토리 데이터 에 저장할 수 있다. 대화 히스토리 데이터는 대화 히스토리 정보가 기설정된 조건(예를 들어, 저장된 순서 등)으로 분류된 데이터 베이스일 수 있다. 한편, 프로세서는 메모리와 전기적으로 연결되어 전자 장치의 전반적인 동작 및 기능을 제어할 수 있다. 특히, 프로세서는 메모리에 저장되어 있는 제2 대화 시스템을 실행하기 위한 프로그램의 인 스트럭션을 실행함으로써, 마이크를 통해 입력된 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 구체적으로, 프로세서는 사용자 음성을 제2 대화 시스템에 입력하여 사용자 음성의 신뢰도 값 또는 도메인을 획득하고, 획득한 사용자 음성의 신뢰도 값 또는 도메인을 바탕으로 사용자 음성을 서버로 전송 할지 여부를 결정할 수 있다. 일 실시예로, 프로세서는 제2 대화 시스템의 제2 ASR 모듈을 통해 사용자 음성에 대응되는 텍스트 및 사용 자 음성의 음성 인식 신뢰도 값을 획득하고, 음성 신뢰도 값을 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 구체적으로, 프로세서는 제2 ASR 모듈을 통해 획득한 사용자 음성의 음성 인식 신 뢰도 값이 제1 임계값을 초과하는지에 따라 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 또 다른 실시예로, 프로세서는 제2 대화 시스템의 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트의 언어 분석 신뢰도 값을 획득하고, 언어 분석 신뢰도 값을 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 구체적으로, 프로세서는 제2 NLU 모듈을 통해 획득한 사용자 음성에 대응되는 텍스트의 언어 분석 신뢰도 값이 제2 임계값을 초과하는지에 따라 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 또 다른 실시예로, 프로세서는 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트의 도메인 및 도메인과 관련된 정보를 획득할 수 있다. 그리고, 프로세서는 도메인과 관련된 정보를 바탕으로 사용자 음성을 서버 로 전송할지 여부를 결정할 수 있다. 일 실시예로, 제2 NLU 모듈을 통해 사용자 음성에 대응되는 텍스트의 도메인이 제2 대화 시스템에서 처리할 수 없다는 정보를 획득하면, 프로세서는 사용자 음성을 서버로 전송하는 것으로 결정할 수 있다.또 다른 실시예로, 프로세서는 전자 장치의 상태를 바탕으로 사용자 음성을 서버로 전송할지 여 부를 결정할 수 있다. 일 실시예로, 프로세서는 전자 장치와 서버와 통신 연결 상태 또는 전자 장치의 배터리 충전 상태 등을 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 또 다른 실시예로, 프로세서는 입력부를 통해 선택된 사용자 음성에 대한 응답을 제공할 대화 시스템 에 따라 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 예를 들면, 입력부를 통해 사용자 음성에 대한 응답을 제공할 대화 시스템으로 제1 대화 시스템이 선택되면, 프로세서는 입력되는 모든 사용 자 음성을 서버로 전송하는 것으로 결정할 수 있다. 한편, 일 실시예로 사용자 음성을 서버로 전송하는 것으로 결정하면, 프로세서는 저장된 대화 히스토 리 정보 중 적어도 일부를 제1 대화 시스템을 포함하는 서버로 전송하도록 통신부를 제어할 수 있다. 그리고, 프로세서는 통신부를 통해 서버로부터 사용자 음성과 관련된 대화 히스토리 정보 및 사 용자 음성에 대한 응답을 수신하고, 수신한 대화 히스토리 정보를 메모리에 저장할 수 있다. 그리고, 프로 세서는 수신한 사용자 음성에 대한 응답에 대응되는 동작을 수행하거나, 수신한 응답에 대응하는 응답 메 시지를 출력할 수 있다. 예를 들면, 프로세서는 사용자 음성에 대한 응답에 대응되는 UI를 표시하도록 디 스플레이를 제어하거나, 응답에 대응되는 어플리케이션을 실행할 수 있다. 또한, 프로세서는 사용자 음성에 대한 응답에 대응하는 응답 메시지를 음성의 형태로 출력하거나, 텍스트의 형태로 표시할 수 있다. 한편, 일 실시예로, 마이크를 통해 추가 사용자 음성이 입력되면, 프로세서는 추가 사용자 음성을 제 2 대화 시스템에 입력하여 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 만약, 추가 사용자 음 성을 서버로 전송하지 않는 것으로 결정되면, 프로세서는 제2 대화 시스템에 기저장된 대화 히스토리 정보 중 사용자 음성과 관련된 대화 히스토리 정보를 이용하여 추가 사용자 음성 음성 인식 또는 언어 분석하고, 추가 사용자 음성에 대한 응답 및 추가 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 한편, 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로세서, GPU(graphics- processing Unit), VPU (Visual Processing Unit) 등과 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데 이터를 처리하도록 제어한다. 기정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 다수의 학습 데이터들에 학습 알고리즘을 적용함으로써, 원하는 특성 의 기정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 각 레이어는 복수의 가중치(weight values)을 갖 고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치의 연산을 통해 레이어의 연산을 수행한다. 신 경망의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks)이 있으며, 본 개시에서의 신경망은 명시한 경우 를 제외하고 전술한 예에 한정되지 않는다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)을 훈련시켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘은 명시한 경우를 제외하고 전술 한 예에 한정되지 않는다. 도 4b는 본 개시의 일 실시예에 따른, 서버의 구성을 간략히 도시한 블록도이다. 도 4b에 도시된 바와 같 이 서버는 통신부, 메모리 및 프로세서를 포함할 수 있다. 도 4b에 도시된 구성은 본 개시 의 실시예들을 구현하기 위한 예시도이며, 통상의 기술자에게 자명한 수준의 적절한 하드웨어 및 소프트웨어 구성들이 서버에 추가로 포함될 수 있다. 통신부는 다양한 통신 방식을 통해 외부의 장치(예를 들어, 전자 장치)와 통신을 수행할 수 있다. 통 신부가 외부의 장치와 통신 연결되는 것은 제3 기기(예로, 중계기, 허브, 엑세스 포인트, 게이트웨이 등) 를 거쳐서 통신하는 것을 포함할 수 있다. 한편, 통신부는 외부 장치와 통신을 수행하기 위해 다양한 통신 모듈을 포함할 수 있다. 통신 모듈에 대한 설명은 도 4a를 참조하여 설명하였으므로 중복되는 설명은 생략하도록 한다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서에 의해 액세스되며, 프로 세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어는 메 모리, 프로세서 내 롬(미도시), 램(미도시) 또는 서버에 장착되는 메모리 카드(미도시)(예를 들 어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 또한, 메모리에는 디스플레이의 디스플레이 영 역에 표시될 각종 화면을 구성하기 위한 프로그램 및 데이터 등이 저장될 수 있다. 그리고, 메모리는 제1 대화 시스템 및 적어도 하나의 인스트럭션을 저장할 수 있다. 특히, 메모리는 제1 대화 시스템을 실행하기 위한 프로그램을 저장할 수 있다. 제1 대화 시스템은 사용자 에게 다양한 서비스를 제공하기 위한 개인화된 프로그램이다. 또한, 메모리는 제1 대화 시스템과 관련된 대화 히스토리 정보를 획득하기 위한 프로그램 및 제1 대화 시스템과 관련된 대화 히스토리 정보를 저장할 수 있다. 또한, 메모리는 전자 장치로부터 제2 대화 시스템과 관련한 대화 히스토리 정보를 획득하기 위 한 프로그램 및 제2 대화 시스템과 관련된 대화 히스토리 정보를 저장할 수 있다. 그리고, 일 실시예로 메모리 는 제1 대화 시스템이 실행되는 동안 대화 히스토리 정보를 저장할 수 있고, 제1 대화 시스템의 수행이 종 료될 때 메모리에 저장된 대화 히스토리 정보는 삭제될 수 있다. 그리고, 메모리에는 도 4b에 도시된 바와 같이 다양한 소프트웨어 모듈이 포함된 제1 대화 시스템를 저장할 수 있다. 각 소프트웨어 모듈은 프로세서에 의해 제어될 수 있다. 한편, 서버에 저장되어 있는 제1 대화 시스템의 제1 ASR 모듈(205-1), 제1 NLU 모듈(205-2), 제1 DM 모듈(205-3), 제1 NLG 모듈(205-4), 제1 Context Understanding(또는, 제1 대화 히스토리 정보 이해부)(205- 5), 제1 Context Generator(또는, 제1 대화 히스토리 정보 생성부)(205-6) 및 제1 대화 시스템 데이터(205- 7)는 제2 대화 시스템에 각각 대응되는 모듈과 동일한 기능을 수행할 수 있다. 한편, 제1 대화 시스템에 포함된 제1 ASR 모듈(205-1)의 언어 모델에 저장된 데이터 양은 제2 ASR 모듈 (105-1)에 포함된 언어 모델에 저장된 데이터 양에 비해 많을 수 있다. 또한, 제1 대화 시스템의 경우 제2 대화 시스템에 비해 처리할 수 있는 데이터 양이 많을 수 있다. 그리고, 본 개시의 일 실시예에 따른, 제1 대화 시스템에 포함된 제1 NLU 모듈(205-2)은 전자 장치로 부터 수신된 전자 장치에 입력된 사용자 음성에 대응되는 텍스트를 대화 히스토리 정보를 바탕으로 언어 분석을 수행할 수 있다. 구체적으로, 제1 NLU 모듈(205-2)는 대화 히스토리 정보를 바탕으로 언어 분석을 수행 하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 출력하고, 텍스트만을 바탕으로 언어 분석을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 출력할 수 있다. 그리고, 제1 NLU 모듈(205-2)이 출력한 언 어 분석 신뢰도 값 및 언어 분석 결과는 프로세서 제어에 의해 휘발성 메모리에 기록 및 저장될 수 있다. 일 실시예로, 제1 NLU 모듈(205-2)은 대화 히스토리 정보를 통해 사용자 음성에 대응되는 텍스트의 도메인 및 의도를 파악할 수 있다. 전자 장치에 입력된 사용자 음성에 대응되는 텍스트가 '서래 마을'이고 전자 장치 로부터 수신된 대화 히스토리 정보에 현재 사용자가 길 안내를 요구하는 상황 정보가 포함된 경우, 제1 NLU 모듈(205-2)은 대화 히스토리 정보를 통해 텍스트의 도메인은 길 안내와 관련된 'Location'이고, 의도는 ' 서래 마을'이라는 목적지로 길 안내를 요구하는 것임을 파악할 수 있다. 따라서, 대화 히스토리 정보를 이용하 여 텍스트에 대한 언어 분석을 수행하는 경우, 제1 NLU 모듈(205-2)은 텍스트에 대한 도메인 분류 및 의도를 파 악 과정은 생략할 수 있다. 그리고, 제1 NLU 모듈(205-2)는 제1 언어 분석 결과를 출력하고, 어느 정도의 신뢰 도를 가지고 사용자 음성에 대응되는 텍스트를 분석하여 이해하였는지에 대한 수치인 제1 언어 분석 신뢰도 값 을 출력할 수 있다. 한편, 제1 NLU 모듈(205-2)이 대화 히스토리 정보를 바탕으로 텍스트에 대해 언어 분석을 수행하는 동안 텍스트 만으로 언어 분석을 수행할 수 있다. 즉, 제1 NLU 모듈(205-2)은 대화 히스토리 정보를 활용하지 않고 텍스트의도메인을 분류하고 의도를 파악하는 동작을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 출력할 수 있다. 위 실시예의 경우, 사용자 음성에 대응되는 텍스트와 대화 히스토리 정보가 연관되어 있으므로 제1 언 어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값보다 높을 수 있다. 본 개시의 또 다른 실시예로, 제1 NLU 모듈(205-2)은 텍스트만을 바탕으로 언어 분석을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 출력할 수 있다. 예를 들어, 사용자 음성에 대응되는 텍스트가 '그거 말고, 베이징 날씨 알려줘'이고 대화 히스토리 정보는 현재 사용자가 길 안내를 요구하는 상황 정보인 경우, 제1 NLU 모듈(205-2)는 대화 히스토리 정보는 무시하고 텍스트에 대한 언어 분석을 수행하여 텍스트의 도메인은 날씨와 관련된 'Weather'이고 의도는 '베이징'이라는 지역의 날씨를 알려달라는 것임을 파악할 수 있다. 그리고, 제1 NLU 모듈(205-2)은 어느 정도의 신뢰도를 갖고 텍스트를 분석하여 이해하였는지에 대한 수치인 제2 언어 분석 신뢰도 값을 출력할 수 있다. 한편, 제1 NLU 모듈(205-2)는 텍스트만을 바탕으로 언어 분석을 수행하는 동안 대화 히스토리 정보를 바탕으로 텍스트에 대한 언어 분석을 수행하여 제1 언어 분석 신뢰도 값 및 제1 언어 분석 결과를 출력할 수 있다. 제1 NLU 모듈(205-2)는 대화 히스토리 정보을 통해 획득할 수 있는 도메인은 'Location'이라고 파악할 수 있다. 다 만, 사용자 음성에 대응되는 텍스트의 도메인은 'Weather'이며 대화 히스토리 정보에 대응되는 사용자 음성과는 독립적인 발화이므로 제2 언어 분석 신뢰도 값이 제1 언어 분석 신뢰도 값보다 높을 수 있다. 한편, 프로세서는 메모리와 전기적으로 연결되어 서버의 전반적인 동작 및 기능을 제어할 수 있 다. 특히, 프로세서는 메모리에 저장되어 있는 제1 대화 시스템을 실행하기 위한 프로그램의 인스트 럭션을 실행할 수 있다. 특히, 프로세서는 통신부를 통해 전자 장치로부터 전자 장치에 입 력된 사용자 음성에 대응되는 텍스트 및 전자 장치에 저장된 대화 히스토리 정보를 수신할 수 있다. 다만, 이는 일 실시예에 불과하며, 프로세서는 통신부를 통해 전자 장치에 입력된 사용자 음성을 수신 할 수 있다. 이 때, 프로세서는 제1 대화 시스템을 통해 사용자 음성에 대응되는 텍스트를 획득할 수 있다. 그리고, 프로세서는 대화 히스토리 정보를 바탕으로 제1 대화 시스템을 통해 텍스트에 대한 언어 분석을 수행할 수 있다. 구체적으로, 프로세서는 텍스트 및 대화 히스토리 정보를 바탕으로 언어 분석을 수행하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 획득하고, 텍스트 만을 언어 분석 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 획득할 수 있다. 프로세서는 텍스트를 다른 방식으로 언어 분석 수행 하여 제1 및 제2 언어 분석 결과를 획득함으로써 전자 장치에 입력된 사용자 음성에 대응되는 텍스트가 이 전 사용자 음성과 관련된 음성에 대응되는 텍스트인지 이전 사용자 음성과는 관련 없는 독립적인 발화에 대응되 는 텍스트인지 구분할 수 있다. 그리고, 프로세서는 제1 언어 분석 신뢰도 값 및 제2 언어 분석 신뢰도 값을 바탕으로 제1 언어 분석 결과 및 제2 언어 분석 결과 중 하나를 전자 장치에 전송할 수 있다. 일 실시예로, 제1 언어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값보다 높은 경우, 프로세서는 제1 언어 분석 결과를 전자 장치에 전송하도록 통신부를 제어할 수 있다. 또 다른 실시예로, 제2 언어 분석 신뢰도 값이 제1 언어 분석 신뢰도 값보다 높 은 경우, 프로세서는 제2 언어 분석 결과 중 텍스트의 도메인과 관련된 정보를 바탕으로 텍스트를 전자 장 치에 전송할지 여부를 결정할 수 있다. 일 실시예로, 프로세서는 텍스트의 도메인이 전자 장치가 처리할 수 있는 도메인인지 여부를 식별할 수 있다. 예를 들어, 텍스트의 도메인이 메모리에 저장된 데이터를 이용해서 처리될 수 있는 도메인인 경 우, 프로세서는 텍스트의 도메인이 전자 장치가 처리할 수 없는 도메인이라고 식별할 수 있다. 또 다 른 예로, 텍스트의 도메인이 전자 장치에 저장된 데이터를 이용해서만 처리될 수 있는 도메인인 경우, 프 로세서는 텍스트의 도메인을 전자 장치가 처리할 수 있는 도메인이라고 식별할 수 있다. 또 다른 예 로, 전자 장치가 처리할 수 있는 도메인 또는 서버가 처리할 수 있는 도메인은 사용자의 입력에 의해 결정될 수 있다. 일 실시예로, 텍스트의 도메인을 전자 장치가 처리할 수 있다고 식별되면, 프로세서는 제2 언어 분석 결과를 전자 장치에 전송하도록 통신부를 제어할 수 있다. 또 다른 예로, 텍스트의 도메인을 전자 장 치가 처리할 수 없다고 식별되면, 프로세서는 제2 언어 분석 결과를 바탕으로 사용자 음성에 대한 응 답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 그리고, 프로세서는 획득된 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 전자 장치에 전송하도록 통신부를 제어할 수 있다.한편, 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작될 수 있다. 인공지 능과 관련된 기능(예를 들어, 학습하는 과정 등)은 전술하였으므로 중복되는 설명은 생략하도록 한다. 도 5는 본 개시의 일 실시예에 따른, 서버의 제어 방법을 설명하기 위한 순서도이다. 일 실시예로, 서버는 전자 장치로부터 전자 장치에 입력된 사용자 음성에 대응되는 텍스트 및 전자 장치에 저장된 대화 히스토리 정보를 수신할 수 있다(S710). 한편, 일 실시예로, 전자 장치로부 터 사용자 음성이 입력되면, 서버는 사용자 음성을 제1 대화 시스템의 제1 ASR 모듈을 통해 사용자 음성에 대응되는 텍스트를 획득할 수 있다. 그리고, 서버는 텍스트 및 대화 히스토리 정보를 바탕으로 언어 분석을 수행하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 획득하고 텍스트 만을 바탕으로 언어 분석 수행하여 제2 언어 분석 결과 및 제2 언 어 분석 신뢰도 값을 획득할 수 있다(S720). 구체적으로, 서버는 대화 히스토리 정보에 포함된 사용자 음 성에 대응되는 텍스트의 도메인 및 의도에 대한 정보를 이용하여 텍스트에 대한 언어 분석을 수행하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 획득할 수 있다. 즉, 서버가 텍스트에 대한 언어 분석을 수행할 때 추가적인 텍스트의 도메인 및 의도의 분류 과정을 생략할 수 있다. 그리고, 또 다른 예로, 서버는 대화 히스토리 정보를 이용하지 않고 텍스트 자체의 도메인 및 의도를 분류하는 언어 분석 과정을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 획득할 수 있다. 그리고, 서버는 제1 언어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값보다 높은지 여부를 식별할 수 있다 (S730). 즉, 서버는는 제1,2 언어 분석 신뢰도 값을 비교함으로써 전자 장치에 입력된 사용자 음성에 대응되는 텍스트가 이전에 전자 장치에 입력된 사용자과 관련된 음성에 대응되는 텍스트인지 혹은 독립적 인 발화에 대응되는 텍스트인지 여부를 식별할 수 있다. 제1 언어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값보다 높은 경우, 서버는 제1 언어 분석 결과를 전자 장치에 전송할 수 있다(S730-Y). 즉, 현재 전자 장치에 입력된 사용자 음성에 대응되는 텍스트가 이전에 전자 장치에 입력된 사용자 음성과 관련된 텍스트라고 식별된 경우, 서버는 제1 언어 분석 결과를 전 자 장치에 전송할 수 있다. 제1 언어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값보다 낮은 경우, 서버 는 텍스트의 도메인이 전자 장치에서 처리 가능한지 여부를 식별할 수 있다(S730-N). 텍스트의 도메인이 전자 장치에서 처리 가능하다고 식별되면, 서버는 제2 언어 분석 결과를 전자 장 치에 전송할 수 있다(S740). 그리고, 텍스트의 도메인이 전자 장치에서 처리 가능하지 않다고 식별되면 서 버는 제1 대화 시스템을 통해 제2 언어 분석 결과를 바탕으로 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다(S750). 그리고, 서버는 사용자 음성에 대한 응답 및 대화 히 스토리 정보를 전자 장치에 전송할 수 있다(S760). 도 6a 및 도 6b는 본 개시의 다른 실시예로, 전자 장치 및 서버에 포함된 대화 시스템의 소프트웨어 모듈간의 동작을 설명하기 위한 도면이다. 즉, 도 4a 및 도 4b 도시된 것과는 다르게 전자 장치 및 서버 각각은 도 6a 및 도 6b에 도시된 바와 같이 소프트웨어 모듈을 메모리(130, 220)에 저장할 수 있다. 한편, 도 4a 및 도 4b를 참조하여 설명한 내용과 중복되는 설명은 생략하도록 한다. 제2 대화 시스템의 제2 Context sharer 모듈(또는, 제2 대화 히스토리 정보 공유 모듈)은 제1 대화 시스템 과 대화 히스토리 정보를 공유할 수 있다. 일 실시예로, 제2 Context sharer모듈은 서버에 저장 되어 있는 대화 히스토리 정보(또는, 데이터)(330-2)를 요청하는 신호를 서버로 전송할 것을 요청하는 신 호를 출력할 수 있다. 그리고, 프로세서는 서버에 대화 히스토리 정보(330-2)를 요청하는 신호를 서 버에 전송하도록 통신부를 제어할 수 있다. 그리고, 프로세서는 서버로부터 대화 히스토리 정보(330-2)를 통신부를 통해 수신할 수 있다. 또한, 프로세서는 서버로부터 대화 히스토리 정보 공유를 요청하는 신호를 통신부를 통해 수신 할 수 있다. 프로세서가 대화 히스토리 정보를 요청하는 신호를 통신부를 통해 수신하면, 제2 Context sharer 모듈은 대화 히스토리 정보(또는, 데이터)(330-1)를 서버로 전송할 것을 요청하는 신 호를 출력할 수 있다. 그리고, 프로세서는 출력된 신호를 바탕으로 대화 히스토리 정보를 서버로 전 송하도록 통신부를 제어할 수 있다.또 다른 실시예로, 전자 장치 및 서버에 포함된 대화 시스템의 소프트웨어 모듈은 도 6b에 도시된 것 과 같이 구현될 수 있다. 한편, 도 4a 및 도 4b를 참조하여 설명한 내용과 중복되는 설명은 생략하도록 한다. 제2 대화 시스템의 Execute Manager 모듈(또는, 실행 매니저 모듈)은 휘발성 메모리에 기록 및 저장 되어 있는 제1 대화 시스템 또는 제2 대화 시스템에서 획득한 사용자 음성에 대한 응답에 대응되는 기능을 수행하도록 제어할 수 있다. 예를 들면, '서래 마을로 길 안내해줘'라는 사용자 음성에 대한 응답을 수신하면, Execute Manager 모듈은 서래 마을로 길을 안내하는 네비게이션 어플리케이션을 실행하도록 제어할 수 있 다. 한편, 일 실시예로, 제1 대화 시스템으로부터 사용자 음성에 대한 응답을 통신부를 통해 수신하면, Execute Manager 모듈은 응답의 캐시 정보를 제2 대화 시스템에 전송할 수 있다. 도 7은 본 개시의 일 실시예에 따른, 전자 장치와 서버의 동작을 설명하기 위한 시퀀스도이다. 우선, 사용자 음성이 입력되면(S810), 전자 장치는 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다(S820). 구체적으로, 전자 장치는 사용자 음성을 제2 대화 시스템에 입력하여 사용자 음성의 음성 인 식 신뢰도 값, 도메인, 언어 분석 신뢰도 값을 획득하고, 획득한 사용자 음성의 음성 인식 신뢰도 값, 언어 분 석 신뢰도 값 및 도메인을 바탕으로 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다. 전자 장 치가 사용자 음성을 서버로 전송할지 여부를 결정하는 과정은 도 2를 참조하여 설명하였으므로 중복 되는 설명은 생략하도록 한다. 사용자 음성을 서버로 전송하지 않는 것으로 결정되면, 전자 장치는 제2 대화 시스템을 통해 사용자 음성에 대한 응답 및 사용자 음성에 대한 대화 히스토리 정보를 획득할 수 있다(S820-N). 한편, 사용자 음성을 서버로 전송하는 것으로 결정되면, 전자 장치는 기 저장된 대화 히스토리 정보 및 사용자 음성에 대응되는 텍스트를 제1 대화 시스템을 포함하는 서버로 전송할 수 있다(S820-Y). 한편, 또 다른 실시예로, 전자 장치는 사용자 음성을 서버에 전송할 수 있다. 그리고, 서버는 대화 히 스토리 정보를 바탕으로 텍스트에 대한 언어 분석을 수행할 수 있다(S830). 구체적으로, 서버는 텍스트 및 대화 히스토리 정보를 바탕으로 언어 분석을 수행하여 제1 언어 분석 결과 및 제1 언어 분석 신뢰도 값을 획득 하고, 텍스트만을 바탕으로 언어 분석을 수행하여 제2 언어 분석 결과 및 제2 언어 분석 신뢰도 값을 획득할 수 있다. 그리고, 서버는 언어 분석에 따른 결과를 전자 장치에 전송할 수 있다(S840). 일 실시예로, 제1 언어 분석 신뢰도 값이 제2 언어 분석 신뢰도 값보다 높은 경우, 서버는 제1 언어 분석 결과를 전자 장치 에 전송할 수 있다. 또 다른 실시예로, 제2 언어 분석 신뢰도 값이 제1 언어 분석 신뢰도 값보다 높은 경우, 서 버는 제2 언어 분석 결과 중 텍스트의 도메인과 관련된 정보를 바탕으로 텍스트의 도메인이 전자 장치 에서 처리될 수 있는 도메인인지 여부를 식별할 수 있다. 예를 들어, 텍스트의 도메인이 전자 장치에 서 처리될 수 있는 도메인인 경우, 서버는 제2 언어 분석 결과를 전자 장치에 전송할 수 있다. 또 다 른 예로, 텍스트의 도메인이 전자 장치에서 처리될 수 없는 도메인인 경우, 서버는 제2 언어 분석 결 과를 바탕으로 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다. 한편, 전자 장치는 서버로부터 수신된 결과를 바탕으로 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다(S850). 그리고, 전자 장치는 사용자에게 음성을 제공하고 대 화 히스토리 정보를 저장할 수 있다(S860). 즉, 전자 장치와 서버는 대화 히스토리 정보를 공유하여 각 대화 시스템이 원활하게 사용자 음성에 대한 응답을 출력할 수 있도록 한다. 한편, 도 8은 본 개시의 다른 실시예에 따른, 전자 장치와 서버간의 동작을 설명하기 위한 시퀀스도 이다. 사용자 음성이 입력되면(S910), 전자 장치는 사용자 음성을 서버로 전송할지 여부를 결정할 수 있다 (S920). 서버에 사용자 음성을 전송하는 것으로 결정되면, 전자 장치는 대화 히스토리 정보 및 사용 자 음성을 서버에 전송할 수 있다(S930). 서버는 제1 대화 시스템을 통해 사용자 음성에 대한 응답및 대화 히스토리 정보를 획득할 수 있다(S940). 그리고, 서버는 사용자 음성에 대한 응답을 전자 장치 에 전송하고(S950), 전자 장치는 수신한 응답을 제공할 수 있다(S960). 그리고, 추가 사용자 음성이 입력되면 전자 장치는 추가 사용자 음성을 서버로 전송할 지 여부를 결 정할 수 있다(S965). 서버로 사용자 음성을 전송하지 않는 것으로 결정되면, 전자 장치는 사용자 음 성에 대한 대화 히스토리 정보 요청을 위한 신호를 서버에 전송할 수 있다(S970). 신호를 수신하면, 서버 는 사용자 음성에 대한 대화 히스토리 정보를 전자 장치에 전송할 수 있다(S975). 사용자 음성에 대 한 대화 히스토리 정보를 수신하면, 전자 장치는 제2 대화 시스템을 통해 추가 사용자 음성에 대한 응답 및 대화 히스토리 정보를 획득할 수 있다(S980). 구체적으로, 전자 장치는 서버로부터 수신된 사용자 음성과 관련된 대화 히스토리 정보 및 추가 사용자 음성을 제2 대화 시스템에 입력하여 추가 사용자 음성과 관 련된 대화 히스토리 정보를 획득할 수 있다. 그리고, 전자 장치는 추가 사용자 음성에 대한 응답을 제공하 고, 추가 사용자 음성과 관련된 대화 히스토리 정보를 저장할 수 있다(S985). 도 9는 본 개시의 일 실시예에 따른, 전자 장치 및 서버의 동작을 설명하기 위한 도면이다. 도 8과 중복되는 설명은 생략하도록 한다. 사용자 음성이 입력되면(S1010), 전자 장치는 사용자 음성을 제2 대화 시스템에 입력하고(S1020), 서버 에 전송할 수 있다(S1030). 도 9에는 전자 장치가 사용자 음성을 제2 대화 시스템에 입력한 이후에 서버에 전송하는 것으로 도시되어 있으나, 각 단계(S1030, S1040)에 따른 동작은 동시 또는 기설정된 시간 차 이내에 수행될 수 있다. 한편, 서버는 제2 대화 시스템을 통해 사용자 음성에 대한 응답 및 사용자 음성과 관련된 대화 히스토리 정보를 획득할 수 있다(S1040). 그리고, 서버는 사용자 음성에 대한 응답을 전자 장치에 전송할 수 있다(S1050). 한편, 전자 장치는 수신한 사용자 음성에 대한 응답의 캐시 정보를 획득할 수 있다(S1050). 구체적으로, 사용자 음성에 대한 응답과 관련된 데이터를 캐싱(Caching)한 캐시 정보를 획득할 수 있다(S1060). 그리고, 전 자 장치는 사용자 음성에 대한 응답을 제공하고 캐시 정보를 저장할 수 있다(S1070). 그리고, 추가 사용자 음성이 입력되고(S1080), 사용자로부터 사용자 음성에 대한 응답을 제공할 대화 시스템으 로 제2 대화 시스템이 결정되면, 전자 장치는 캐쉬 정보를 바탕으로 추가 사용자 음성에 대한 응답 및 추 가 사용자 음성과 관련된 대화 정보를 획득할 수 있다(S1090). 그리고, 전자 장치는 추가 사용자 음성에 대한 응답을 제공하고, 추가 사용자 음성과 관련된 대화 히스토 리 정보를 저장할 수 있다(S1095). 도 10은 본 개시의 일 실시예에 따른, 전자 장치의 구성을 상세히 도시한 블록도이다. 도 10에 도시한 바 와 같이, 전자 장치는 통신부, 마이크, 메모리, 프로세서, 디스플레이, 스피커 , 및 입력부를 포함할 수 있다. 한편, 통신부, 마이크, 메모리 및 프로세서는 도 4a에서 설명하였으므로, 중복되는 설명은 생략하기로 한다. 디스플레이는 프로세서의 제어에 따라 다양한 정보를 표시할 수 있다. 특히, 디스플레이는 프로 세서 제어에 따라 사용자 음성에 대한 응답 에 대응되는 UI를 표시할 수 있다. 그리고, 디스플레이는 터치 패널과 함께 터치 스크린으로도 구현될 수 있다. 그러나 상술한 구현으로 한정 되는 것은 아니며, 디스플레이는 전자 장치의 유형에 따라 다르게 구현될 수 있다. 스피커는 오디오 처리부(미도시)에 의해 디코딩이나 증폭, 노이즈 필터링과 같은 다양한 처리 작업이 수행 된 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지를 출력하는 구성이다. 특히, 스피커는 사용자 음성에 대응되는 응답을 음성 형태로 출력할 수 있다. 다만, 스피커는 일 실시예에 불과할 뿐, 오 디오 데이터를 출력할 수 있는 다른 출력 단자로 구현될 수도 있다. 입력부는 다양한 사용자 입력을 수신하여 프로세서로 전달할 수 있다. 특히, 입력부는 터치 센 서, (디지털) 펜 센서, 압력 센서, 키, 또는 마이크를 포함할 수 있다. 터치 센서는, 예를 들면, 정전식, 감압 식, 적외선 방식, 또는 초음파 방식 중 적어도 하나의 방식을 사용할 수 있다. (디지털) 펜 센서는, 예를 들면,터치 패널의 일부이거나, 별도의 인식용 쉬트를 포함할 수 있다. 키는, 예를 들면, 물리적인 버튼, 광학식 키, 또는 키패드를 포함할 수 있다. 입력부가 터치 센서로 구현된 경우는 도 7을 참조하여 설명하였으므로 중 복되는 설명은 생략하도록 한다. 한편, 본 개시의 다양한 실시예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 개시에 기재된 기술을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 부프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시의 다양한 실시예들에 따른 전자 장치는, 예를 들면, 스마트폰, 태블릿 PC, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 서버, PDA, 의료기기, 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 어떤 실시예들에서, 전자 장치는, 예를 들면, 텔레비전, 냉장고, 에어컨, 공기 청정기, 셋톱 박스, 미디어 박스(예: 삼성 HomeSyncTM, 애 플TVTM, 또는 구글 TVTM) 중 적어도 하나를 포함할 수 있다. 한편, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장 치)를 지칭할 수 있다. 이하에서는 도면을 참조하여 본 개시에 대해 더욱 상세히 설명하도록 한다. 본 개시의 다양한 실시예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호 출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시예들에 따른 전자 장치(예: 전자 장치 )를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어하에 다른 구성요소들을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인 터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 신호(signal)를 포함하지 않으 며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 개시에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경 우에, 컴퓨터 프로그램 제품(예를 들어, 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어 플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다 양한 실시예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차 적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2019-0156158", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 개시의 일 실시예에 따른, 전자 장치가 입력된 사용자 음성을 전송할 대화 시스템을 결정하는 과정 을 설명하기 위한 도면, 도 1b는 본 개시의 일 실시예에 따른, 전자 장치가 입력된 사용자 음성을 전송할 대화 시스템을 결정하는 과정 을 설명하기 위한 도면,도 2a는 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법을 설명하기 위한 순서도, 도 2b는 본 개시의 일 실시예에 따른, 서버의 제어 방법을 설명하기 위한 순서도, 도 3a, 도 3b, 도 3c, 도 3d 및 도 3e는 본 개시의 일 실시예에 따른, 전자 장치가 사용자 음성을 서버로 전송 할 지 여부를 결정하는 과정을 설명하기 위한 순서도, 도 4a는 본 개시의 일 실시예에 따른, 전자 장치서버의 구성을 간략히 도시한 도면, 도 4b는 본 개시의 일 실시예에 따른, 서버의 구성을 간략히 도시한 도면, 도 5는 본 개시의 일 실시예에 따른, 서버서버의 제어 방법을 설명하기 위한 순서도, 도 6a 및 도 6b는 본 개시의 일 실시예에 따른, 서버전자 장치의 소프트 웨어 모듈과 서버의 소프트 웨어의 모 듈간의 동작을 설명하기 위한 도면, 도 7, 도 8 및 도 9는 본 개시의 일 실시예에 따른, 전자 장치와 서버 간의 동작을 설명하기 위한 시퀀스도, 도 10은 본 개시의 일 실시예에 따른, 전자 장치의 구성을 상세히 도시한 블록도이다."}
