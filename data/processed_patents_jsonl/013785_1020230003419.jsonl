{"patent_id": "10-2023-0003419", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0030944", "출원번호": "10-2023-0003419", "발명의 명칭": "뉴럴 네트워크 모델을 이용하여 차선 폴리라인을 생성하는 장치 및 방법", "출원인": "포티투닷 주식회사", "발명자": "정성균"}}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "뉴럴 네트워크 모델을 이용하여 폴리라인(polylines) 이미지를 생성하는 방법에 있어서, 차량에 탑재된 적어도 하나의 센서로부터 소정의 도로에 대한 기본 이미지를 획득하는 단계;상기 기본 이미지를 이용하여 다중 스케일 이미지 피쳐(feature)를 추출하는 단계;제1 뉴럴 네트워크 모델에 상기 다중 스케일 피쳐를 입력 데이터로 입력하고, 상기 제1 뉴럴 네트워크 모델의출력 데이터로써 조감도 피쳐(BEV feature)를 획득하는 단계; 및 제2 뉴럴 네트워크 모델에 상기 조감도 피쳐를 입력 데이터로 입력하고, 상기 제2 뉴럴 네트워크 모델의 출력데이터로써 상기 소정의 도로에 대한 폴리라인 이미지를 획득하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제1 뉴럴 네트워크 모델은, 상기 복수의 이미지 피쳐의 픽셀 좌표(pixel coordinate)와 상기 조감도 피쳐의 그리드(grid) 간 양방향 비교를통해 산출된 트랜슬레이션(translation) 손실을 이용하여 학습되는 것인, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 트렌슬레이션 손실은, 상기 픽셀 좌표에 룩업 테이블 함수를 적용한 값과 상기 그리드 값의 차이를 나타내는 제1 값과, 상기 픽셀 좌표 값과 상기 그리드 값에 룩업 테이블 역함수를 적용한 값의 차이를 나타내는 제2 값에 기초하여 결정되는 것인, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 방법은,제3 뉴럴 네트워크 모델에 상기 조감도 피쳐를 입력 데이터로 입력하고, 상기 제3 뉴럴 네트워크 모델의 출력데이터로써 상기 조감도 피쳐의 그리드 별 높이 값을 획득하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 제3 뉴럴 네트워크 모델의 높이 손실은, 차선 마커를 이용하여 상기 조감도 피쳐의 그리드에 z값을 보간하여 획득된 수도 실측 맵(pseudo ground truthmap)의 높이 값에 기초하여 결정되는 것인, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,공개특허 10-2024-0030944-3-상기 제2 뉴럴 네트워크 모델은 임베딩 오프셋 손실(embedding offset loss)을 이용하여 학습되며,상기 오프셋 손실은, 상기 소정의 도로에 포함된 복수의 차선들 각각에 대응하는 복수의 클러스터들에 대해 전경 픽셀들 각각이 상기복수의 클러스터들 중 소정의 클러스터에 해당될 확률에 기초하여 결정되는 것인, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 제2 뉴럴 네트워크 모델은 시드 확률 손실(seed probability loss)을 이용하여 학습되며,상기 시드 확률 손실은, 상기 조감도 피쳐에 포함된 복수의 픽셀들 중, 전경에 포함되는 픽셀에 대해서는 제1 수식을 적용하고, 후경에포함되는 픽셀에 대해서는 제2 수식을 적용함으로써 결정되는 것인, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 제2 뉴럴 네트워크 모델은 순서 손실(order loss)을 이용하여 학습되며,상기 순서 손실은,상기 조감도 피쳐에 포함된 복수의 픽셀들 중에서 전경 픽셀들 각각이 포함된 클러스터에 대응하는 차선에대해, 상기 전경 픽셀들의 순서(order)를 이용하여 결정되는 것인, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 방법은,상기 소정의 도로에 대한 폴리라인 이미지에 기초하여, 상기 소정의 도로를 주행 중인 차량을 제어하기 위한 제어 신호를 생성하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "폴리라인 이미지를 생성하는 뉴럴 네트워크 장치에 있어서,적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써 뉴럴 네트워크를 구동하는 프로세서를 포함하고,상기 프로세서는,차량에 탑재된 적어도 하나의 센서로부터 소정의 도로에 대한 기본 이미지를 획득하고,상기 기본 이미지를 이용하여 다중 스케일 이미지 피쳐를 추출하고,제1 뉴럴 네트워크 모델에 상기 다중 스케일 피쳐를 입력 데이터로 입력하고, 상기 제1 뉴럴 네트워크 모델의출력 데이터로써 조감도 피쳐(BEV feature)를 획득하고, 제2 뉴럴 네트워크 모델에 상기 조감도 피쳐를 입력 데이터로 입력하고, 상기 제2 뉴럴 네트워크 모델의 출력데이터로써 상기 소정의 도로에 대한 폴리라인 이미지를 획득하는 것인, 뉴럴 네트워크 장치."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항의 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0003419", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2024-0030944-4-뉴럴 네트워크 모델을 이용하여 차선 폴리라인(lane polyline)을 생성하는 방법에 있어서, 차량에 탑재된 적어도 하나의 센서로부터 획득된 소정의 도로에 대한 기본 이미지를 획득하는 단계;상기 기본 이미지를 뉴럴 네트워크 모델에 대한 입력 데이터로 입력하는 단계; 및상기 뉴럴 네트워크 모델을 구동하여, 상기 기본 이미지로부터 조감도 피쳐를 생성하고 상기 생성된 조감도 피쳐에 기초하여 차선 폴리라인을 출력 데이터로 획득하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 뉴럴 네트워크 모델을 이용하여 차선 폴리라인을 생성하는 방법 및 장치에 관한 것이다. 본 개시의 일 실시 예에 따른 방법은, 차량에 탑재된 적어도 하나의 센서로부터 획득된 기본 이미지를 이용하여 다중 스케일 이미지 피쳐를 추출할 수 있다. 또한 방법은, 제1 뉴럴 네트워크 모델에 다중 스케일 피쳐를 입력 데이터로 입력 하고, 제1 뉴럴 네트워크 모델의 출력 데이터로써 조감도 피쳐를 획득할 수 있다. 또한 방법은, 제2 뉴럴 네트워 크 모델에 조감도 피쳐를 입력 데이터로 입력하고, 제2 뉴럴 네트워크 모델의 출력 데이터로써 소정의 도로에 대 한 폴리라인 이미지를 획득할 수 있다. 본 개시에서는 상술한 뉴럴 네트워크 모델로부터 획득된 차선 폴리라인에 대해 별도의 처리 과정을 거치지 않고 차량 제어에 활용이 가능하다."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 뉴럴 네트워크 모델을 이용하여 차선 폴리라인을 생성하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술과 차량 산업의 융합으로 인해 빠르게 차량의 스마트화가 진행되고 있다. 스마트화로 인해, 차량 은 단순한 기계적 장치에서 스마트카로 진화하고 있으며, 특히 스마트카의 핵심기술로 자율 주행이 주목받고 있 다. 자율 주행이란 운전자가 핸들과 가속페달, 브레이크 등을 조작하지 않아도 차량 스스로 목적지까지 찾아가 는 기술이다. 최근에는 기술의 발전으로 차선이탈 경고 시스템이나 차선유지와 같은 안전운전 보조시스템, 차량 자동 제어시 스템 등이 개발되어 실용화가 급속하게 진행되고 있다. 특히, 주행차선의 검출은 자율주행 차량에서의 주요 과 제를 해결하는 핵심기술 중의 하나로서, 국제적인 관심 속에 많은 연구가 활발히 진행되고 있다. 주행차선의 검출은 안전 운전에 지대한 영향을 미치게 되므로, 차선의 위치를 추정하고 판단하기 위해 여러 가 지 센서들을 활용하여 정확한 주행차선을 검출하고 있다. 예컨대, 이미지 센서, 레이더(RADAR) 또는 라이다 (LIDAR)센서 등 다양한 센서들이 차선의 검출이나 차량 전방의 물체 인식을 위해 단독 또는 융합된 형태로 자율 주행 차량제어 시스템 구현에 사용되고 있다."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 뉴럴 네트워크 모델을 이용하여 차선 폴리라인을 생성하는 장치 및 방법을 제공하는데 있다. 본 발명 이 해결하고자 하는 과제는 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 과제 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해보다 분명하게 이해될 것이다. 또한, 본 발명이 해결하고자 하는 과제 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음 을 알 수 있을 것이다."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 뉴럴 네트워크 모델을 이용하 여 폴리라인(polylines) 이미지를 생성하는 방법에 있어서, 차량에 탑재된 적어도 하나의 센서로부터 소정의 도 로에 대한 기본 이미지를 획득하고, 기본 이미지를 이용하여 다중 스케일 이미지 피쳐(feature)를 추출하는 단 계; 제1 뉴럴 네트워크 모델에 상기 다중 스케일 피쳐를 입력 데이터로 입력하고, 상기 제1 뉴럴 네트워크 모델 의 출력 데이터로써 조감도 피쳐(BEV feature)를 획득하는 단계; 및 제2 뉴럴 네트워크 모델에 상기 조감도 피 쳐를 입력 데이터로 입력하고, 상기 제2 뉴럴 네트워크 모델의 출력 데이터로써 상기 소정의 도로에 대한 폴리 라인 이미지를 획득하는 단계;를 포함하는, 방법을 제공할 수 있다. 본 개시의 제 2 측면은, 뉴럴 네트워크 모델을 이용하여 차선 폴리라인을 생성하는 장치에 있어서, 적어도 하나 의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행함으로써 뉴럴 네트워크를 구동하는 프로 세서를 포함하고, 상기 프로세서는, 차량에 탑재된 적어도 하나의 센서로부터 소정의 도로에 대한 기본 이미지를 획득하고, 상기 기본 이미지를 이용하여 다중 스케일 이미지 피쳐를 추출하고, 제1 뉴럴 네트워크 모델에 상 기 다중 스케일 피쳐를 입력 데이터로 입력하고, 상기 제1 뉴럴 네트워크 모델의 출력 데이터로써 조감도 피쳐 (BEV feature)를 획득하고, 제2 뉴럴 네트워크 모델에 상기 조감도 피쳐를 입력 데이터로 입력하고, 상기 제2 뉴럴 네트워크 모델의 출력 데이터로써 상기 소정의 도로에 대한 폴리라인 이미지를 획득하는 것인, 뉴럴 네트 워크 장치를 제공할 수 있다. 본 개시의 제 3 측면은, 제 1 측면에 따른 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다. 이 외에도, 본 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 개시의 과제 해결 수단에 의하면, 본 개시에서는 뉴럴 네트워크 모델의 end-to-end 학습을 통해 조감 도 피쳐로부터 소정의 도로에 대한 차선 폴리라인을 높은 정확도로 획득할 수 있다. 또한, 본 개시에서는 뉴럴 네트워크 모델로부터 획득된 차선 폴리라인에 대해 별도의 처리 과정을 거치지 않고 차량 제어에 활용할 수 있다."}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다. \"매커니즘\", \"요소\", \"수단\" 및 \"구성\" 등과 같은 용어는 넓게 사용될 수 있으며, 기계적 이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하에서, '차량'은 자동차, 버스, 오토바이, 킥보드 또는 트럭과 같이 기관을 가지고 사람이나 물건을 이동시 키기 위해 이용되는 모든 종류의 운송 수단을 의미할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율 주행 차량을 구현 할 수 있다. 자율 주행 차량에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센서 들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율 주행 차량의 전면에 장착된 이미지 센서 및/또는 이 벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율 주행 차량의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율 주행 차량 주변의 보행자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율 주행 차량 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율 주행 차량의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화각 (FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있다. 자율 주행 장치는, 자율 주행 차량의 센서들이 수집한 정보를 실시간으로 처리하여 자율 주행 차량의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서들(42-45)을 포함하며, 복수의 센서들(42-45)은 이미지 센서, 이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어 하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율 주행 차량의 센서가 획득한 영상 데이터의 예시를 나타낸 도면이다. 도 3 을 참조하면, 영상 데이터는 자율 주행 차량의 전면에 장착된 센서가 획득한 데이터일 수 있다. 따라서 영 상 데이터에는 자율 주행 차량의 전면부, 자율 주행 차량과 같은 차로의 선행 차량, 자율 주행 차 량 주변의 주행 차량, 배경 및 차선(55, 56) 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율 주행 차량의 전면부와 배경이 나타나는 영역 의 데이터는 자율 주행 차량의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율 주 행 차량의 전면부와 배경은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율 주행 차량의 안전한 운행에 있 어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함되 는 영역의 데이터는 자율 주행 차량의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율 주행 차량의 전면부와 배경이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있다. 또한, 자율 주행 장치는 현재 차량이 주행 중인 도로에 포함된 차선(55, 56)을 검출할 수 있다. 예를 들어, 자 율 주행 장치는 영상 처리를 통해 영상 데이터에서 차선에 해당될 확률이 높은 차선 픽셀들을 검출하고, 검 출한 차선 픽셀들을 특정한 차선 모델로 피팅(fitting)하여 전방의 차선 배치 상황을 결정할 수 있다. 일 실시예에서, 자율 주행 장치는 뉴럴 네트워크 모델을 이용하여 영상 데이터에서 차선 픽셀들을 검출할 수 있다. 뉴럴 네트워크 모델은 영상 데이터에서 차선에 대응되는 차선 픽셀들을 검출하도록 학습 (training)된 모델이다. 뉴럴 네트워크 모델에는 영상 데이터가 입력되고, 뉴럴 네트워크 모델은 영상 데이 터에 포함된 각 영상 픽셀이 차선(55, 56)에 해당할 확률을 나타내는 확률 정보를 출력할 수 있다. 자율 주 행 장치는 픽셀 별 확률 정보에 기초하여 차선 픽셀들을 결정할 수 있다. 예를 들어, 자율 주행 장치는 영상 데 이터의 영상 픽셀들 중 뉴럴 네트워크 모델에 의해 결정된 확률 값이 임계 값보다 큰 영상 픽셀들을 차선 픽셀들로 결정할 수 있다. 도 4는 일 실시예에 따른 이미지 인코딩 및 뷰 변환을 수행하는 방법을 설명하기 위한 예시적인 도면이다. 도 4를 참조하면, 차선 폴리라인 생성 장치는 이미지 인코더(image encoder) 및 뷰 변환기(view transformer)를 포함할 수 있다. 이미지 인코더는 기본 이미지를 입력 데이터로 이용할 수 있다. 기본 이미지는 차량에 탑재된 적어도 하나의 센서로부터 획득된 차량이 주행 중인 도로에 대한 이미지일 수 있다. 예를 들어, 차량에 탑재된 적어도 하나의 센서는 도 2에서 설명된 센서부로 구현될 수 있다. 이미지 인코더는 기본 이미지를 피쳐 피라미드 네트워크(feature pyramid network)에 적용하여 다중 스케일(multi-scale) 이미지 피쳐를 추출할 수 있다. 피쳐 피라미드 네트워크는 bottom-up 과정 및 top-down 과정으로 구성될 수 있다. bottom-up 과정 은 CNN(convolution neural network)을 이용하여 기본 이미지의 해상도를 1/2씩 낮추어 복수의 제1 피쳐 맵을 생성하는 포워딩(forwarding) 과정일 수 있다. 예를 들어, bottom-up 과정에서는 ResNet50이 이용되고 기본 이미지 대비 1/8, 1/16, 1/32, 1/64 크기의 제1 피쳐 맵이 생성될 수 있다. top-down 과정은 bottom-up 과정에서 생성된 최종 제1 피쳐 맵을 2배씩 업-샘플링(up- sampling)하여 복수의 제2 피쳐 맵을 생성하고, 복수의 제2 피쳐 맵과 복수의 제1 피쳐 맵을 결합하여 다중 스 케일 이미지 피쳐를 추출하는 과정일 수 있다. 뷰 변환기는 이미지 인코더에서 추출된 다중 스케일 이미지 피쳐에 대한 뷰 변환을 수행하여 조 감도 피쳐(BEV feature)를 생성할 수 있다. 조감도 피쳐를 생성하는 방법에 대해서는 도 5에서 후술 하기로 한다. 도 5a는 일 실시예에 따른 조감도 피쳐를 생성하는 방법을 설명하기 위한 예시적인 도면이다. 도 5a를 참조하면, 차선 폴리라인 생성 장치에 포함된 뷰 변환기가 도시된다. 뷰 변환기는 이미지 피 쳐를 입력 받고, 소정의 단계를 거쳐 조감도 피쳐를 생성할 수 있다. 구체적으로 뷰 변환기는, 제1 단계에서 이미지 피쳐의 높이(height) 차원에서 붕괴(collapse)시 키고, 제2 단계에서 이미지 피쳐를 포함하는 다중 스케일 이미지 피쳐를 깊이(depth) 차원으로 스트 레치 시키며, 제3 단계에서 카메라 파라미터를 이용하여 리샘플링(resampling)함으로써, 조감도 피쳐(52 0)를 생성할 수 있다. 한편, 차선 폴리라인 생성 장치는 조감도 피쳐 fBEVc에 호모그래피 변환(homography transformation) Hc를 적용하여 정규 좌표(canonical coordinate)로 리맵(remap)할 수 있다. 구체적으로, 차선 폴리라인 생성 장치는 수학식 1에 따라 조감도 피쳐 fBEVc에 호모그래피 변환을 적용할 수 있다. 수학식 1에서, I는 기본 이미지, 는 이미지 인코더 함수, 는 뷰 변환기, K는 소정의 도로를 촬영하는 카메라 관련 파라미터(예를 들어,초점 거리, 카메라 주점 등), R은 차량 좌표계-카메라 좌표계 간 회전 변환, t는 차량 좌표계-카메라 좌표계 간 이동 변환을 의미한다. 또한, z=0이란 것은, 수학식 1에 따른 결과 값인 변환된 조감도 피쳐 fBEV가 XY 평면 상 의 값인 것을 의미한다. 수학식 1"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "차선 폴리라인 생성 장치는, 변환된 조감도 피쳐 fBEV를 뉴럴 네트워크 모델의 입력 데이터로 이용하고, 소정의 도로에 대한 차선 폴리라인을 출력 데이터로 이용함으로써, 뉴럴 네트워크 모델을 학습시킬 수 있다. 뉴럴 네트 워크 모델의 학습 방법에 대해서는 도 6a 내지 도 6b에서 후술하기로 한다. 도 5b는 일 실시예에 따른 제1 뉴럴 네트워크 모델의 학습 과정을 설명하기 위한 예시적인 도면이다. 도 5b의 제1 뷰 변환기(541a)는 도 5a의 뷰 변환기에 대응될 수 있다. 제1 뷰 변환기(541a)는 이미지 피쳐 (542a)를 입력 받고, 도 5a에서 상술한 방법에 따라 조감도 피쳐 (543a)를 생성할 수 있다. 한편, 뷰 변환 과정에서 불완전한 기하 변환(imperfect geometry transformation)과 정보 손실이 발생할 수 있 다. 본 개시에서는 이를 개선하기 위해 즉, 불완전한 기하 변환을 커버(cover)하고 정보 손실을 최소화하기 위 해, 제1 뉴럴 네트워크 모델을 이용할 수 있다. 제1 뉴럴 네트워크 모델은 뷰 변경에 관계없이 일관성을 유지하는 트랜슬레이션 손실 (translation loss)을 이용하여 학습될 수 있다. 즉, 3D 차선 어노테이션 및 카메라 포즈 매개 변수가 알려진 상황에서, 본 개시에서는 제1 뉴럴 네트워크 모델을 이용하여 차선과 연관된 이미지 피쳐 및 조감도 피쳐를 함께 학습할 수 있다. 구체적으로, 제1 뉴럴 네트워크 모델은 복수의 이미지 피쳐 (542b)의 픽셀 좌표(pixel coordinate)와 조 감도 피쳐 (543b)의 그리드(grid) 간 양방향 비교를 통해 산출된 트랜슬레이션 손실 을 이용 하여 학습될 수 있다. 트랜슬레이션 손실 은 아래 수학식 2와 같이 표현될 수 있다. 수학식 2"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 2를 참조하면, 픽셀 좌표 에 룩업 테이블 함수 h()를 적용한 값 과 그리드 값 의 차이를 나 타내는 제1 값과, 픽셀 좌표 값 과 그리드 값 에 룩업 테이블 역함수 h-1()를 적용한 값 h-1( )의 차이를 나타내는 제2 값에 기초하여, 트랜슬레이션 손실 이 결정될 수 있다. 또한, 트랜슬레이션 손실 이 최소화되도록 제1 뉴럴 네트워크 모델의 제2 뷰 변환기(541b)의 파라미터를 최적화하는 과정에서, 트랜슬레이션 손실 에 의해 계산된 그래디언트의 역전파가 제2 뉴 럴 네트워크 모델 및 제3 뉴럴 네트워크 모델에 영향을 주지 않도록 하기 위해, 본 개시에서는 제1 뉴럴 네트워크 모델을 제2 뉴럴 네트워크 모델 및 제3 뉴럴 네트워크 모델과 분리(detach)하여시스템을 구성할 수 있다. 즉, 도 5b에서는 모델 간 분리된 특성을 도시하기 위해 이미지 피쳐 (542a) 및 조 감도 피쳐 (543a)와, 이미지 피쳐 (542b) 및 조감도 피쳐 (543b)를 다른 표기로 표시하였으나, 서 로 대응되는 피쳐 간 값은 동일할 수 있다. 한편, 제2 뉴럴 네트워크 모델 및 제3 뉴럴 네트워크 모델에 대한 설명은 도 6a 내지 도 6b에서 후술 하기로 한다. 도 6a는 일 실시예에 따른 제2 뉴럴 네트워크 모델의 동작 방법을 설명하기 위한 예시적인 도면이다. 도 6a를 참조하면, 제2 뉴럴 네트워크 모델이 도시된다. 차선 폴리라인 생성 장치는 변환된 조감도 피쳐 를 제2 뉴럴 네트워크 모델의 입력 데이터로 입력하고, 제2 뉴럴 네트워크 모델의 출력 데이터 로써 소정의 도로에 대한 차선 폴리라인(또는, 폴리라인 이미지)를 획득할 수 있다. 제2 뉴럴 네트워크 모델에는 변환된 조감도 피쳐가 입력 데이터로 입력될 수 있다. 변환된 조감도 피 쳐는 상기 수학식 1을 통해 산출된 결과 값일 수 있다. 변환된 조감도 피쳐에 기설정된 적어도 하나 의 레이어 및 손실 함수가 적용됨으로써, 제2 뉴럴 네트워크 모델의 출력 데이터로써 차선 폴리 라인이 획득될 수 있다. 일 실시예에서, 제2 뉴럴 네트워크 모델은 아래 수학식 3에 따른 손실 함수 값이 최소가 되도록 학 습될 수 있다. 수학식 3에서 I는 기본 이미지, 은 뉴럴 네트워크 모델, K는 소정의 도로를 촬영하는 카메라 관련 파라미터(예를 들어, 초점 거리, 카메라 주점 등), R은 카메라 좌표계, t는 차량 좌표계를 의미한 다. 는 소정의 도로에 대한 차선 폴리라인의 ground truth 값이고, 는 소정의 도로에 대한 차선 폴리 라인의 제2 뉴럴 네트워크 모델을 통해 예측된 값을 의미한다. 수학식 3"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "본 개시에서는 호모그래피 함수를 이용하지 않고, 제2 뉴럴 네트워크 모델의 end-to-end 학습을 통해 소정 의 도로에 대한 차선 폴리라인을 획득할 수 있다. 본 개시에서는 이를 위해 제2 뉴럴 네트워크 모델 학습 에 이용되는 적어도 하나의 손실 함수(loss function)을 설정할 수 있다. 손실 함수에 대한 구체적인 내용은 이 하에서 후술하기로 한다. 도 6b는 일 실시예에 따른 제2 뉴럴 네트워크 모델 및 제3 뉴럴 네트워크 모델의 학습 과정을 설명하기 위한 예 시적인 도면이다. 도 6b를 참조하면, 차선 폴리라인 생성 장치는 제2 뉴럴 네트워크 모델에 조감도 피쳐 를 입력 데 이터로 입력하고, 제2 뉴럴 네트워크 모델의 출력 데이터로써 소정의 도로에 대한 폴리라인 이미지를 획득 할 수 있다. 이 때, 제2 뉴럴 네트워크 모델은 임베딩 오프셋 손실 을 이용하여 학습될 수 있다. 오프셋 손실 손실 은, 소정의 도로에 포함된 복수의 차선들 각각에 대응하는 복수의 클러스터들에 대해 전경 픽셀들 각각이 복수의 클러스터들 중 소정의 클러스터에 해당될 확률에 기초하여 결정될 수 있다. 임베딩 오프셋 손실 에 대해서는 이하의 수학식 6 관련 부분에서 더 자세하게 설명하기로 한다. 또한, 제2 뉴럴 네트워크 모델은 시드 확률 손실 을 이용하여 학습될 수 있다. 시드 확률 손실"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "는, 조감도 피쳐 에 포함된 복수의 픽셀들 중, 전경에 포함되는 픽셀에 대해서는 제1 수식을 적용하고,후경에 포함되는 픽셀에 대해서는 제2 수식을 적용함으로써 결정될 수 있다. 시드 확률 손실 에 대해서는 이하의 수학식 5 관련 부분에서 더 자세하게 설명하기로 한다. 또한, 제2 뉴럴 네트워크 모델은 순서 손실 을 이용하여 학습될 수 있다. 순서 손실 은, 조감도 피쳐 에 포함된 복수의 픽셀들 중에서 전경 픽셀들 각각이 포함된 클러스터에 대응하는 차선에 대해, 전경 픽셀들의 순서를 이용하여 결정될 수 있다. 순서 손실 에 대해서는 이하의 수학식 9 관련 부분에서 더 자세하게 설명하기로 한다. 제2 뉴럴 네트워크 모델 임베딩 오프셋 손실 , 시드 확률 손실 , 순서 손실 중 적어도 어느 하나의 손실이 최소가 되도록 학습될 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 제3 뉴럴 네트워크 모델에 조감도 피쳐를 입력 데이터로 입력 하고, 제3 뉴럴 네트워크 모델의 출력 데이터로써 조감도 피쳐의 그리드 별 높이 값을 획득할 수 있다. 이 때, 제3 뉴럴 네트워크 모델은 높이 손실 을 이용하여 학습될 수 있다. 높이 손실 는, 차 선 마커를 이용하여 조감도 피쳐 의 그리드에 z값을 보간하여 획득된 수도 실측 맵(pseudo ground truth map)의 높이 값 에 기초하여 결정될 수 있다. 높이 손실 은 아래 수학식 4와 같이 표현될 수 있다. 수학식 4"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 4를 참조하면, 높이 손실 은 수도 실측 맵의 높이 값 와 조감도 피쳐 그리드의 높이 값 간의 평균 제곱 오차(mean square error)로 산출될 수 있다. 한편, 제3 뉴럴 네트워크 모델에는 컨벌루션 레이어들 사이에 고정된 커널 웨이트 값을 갖는 가우시안 필 터 레이어가 적용될 수 있다. 가우시안 필터 레이어는 주변 그리드(neighboring grid)의 높이가 급격하게 변하 는 것을 방지할 수 있다. 본 개시에서는 제2 뉴럴 네트워크 모델을 이용하여 차선의 중심(centroid)에 대한 x-변위(x- displacement), y-변위(y-displacement)의 공간 임베딩을 예측하고, 차선에 해당될 가능성을 예측함으로써 폴리 라인을 생성할 수 있다. 또한, 본 개시에서는 제3 뉴럴 네트워크 모델을 이용하여 지면에서 노면(road surface)의 높이를 조밀하게(densely) 예측할 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 추가 뉴럴 네트워크 모델을 더 포함할 수 있다. 추가 뉴럴 네 트워크 모델을 이용하여 이미지 피쳐 내 차선 영역과 관련된 피쳐에 더 집중시키는 역할을 수행할 수 있다. 도 7a 내지 도 7b는 일 실시예에 따른 시드 확률 손실을 설명하기 위한 예시적인 도면이다. 도 7a 내지 도 7b를 참조하면, 픽셀 좌표계가 도시된다. 차선 폴리라인 생성 장치는 조감도 피쳐의 공간 좌표 시스템을 임베딩 좌표 시스템으로 변환함으로써 픽셀 좌표계를 생성할 수 있다. 도 7a를 참조하면, 픽셀 좌표계에 포함된 점 표시는 픽셀을 나타내고, 직선 표시는 차선을 나타 낸다. 조감도 이미지 생성 장치는 제2 뉴럴 네트워크 모델에 적용되는 적어도 하나의 손실 함수(또는, 손실)로써, 시 드 확률 손실(seed probability loss)을 설정할 수 있다. 시드 확률은 픽셀 좌표계 상의 복수의 픽셀들 각 각이 전경(foreground) 또는 후경(background) 중 어느 카테고리에 해당되는지 여부에 따라 값이 달라진다. 여 기서 전경이란, 차량, 차선 등의 객체를 의미하고, 후경이란 배경을 의미한다. 픽셀 좌표계 상의 소정의 픽셀이 후경으로 결정된 경우, 차선 폴리라인 생성 장치는 해당 픽셀의 시드 확률을 0으로 결정할 수 있다. 또 한, 픽셀 좌표계 상의 소정의 픽셀이 전경에 해당될 확률이 높을수록, 차선 폴리라인 생성 장치는 해당 픽 셀의 시드 확률을 1에 가까운 값을 갖도록 결정할 수 있다. 픽셀 좌표계 상의 복수의 픽셀들은 전경을 나타내는 전경 픽셀 또는 후경을 나타내는 후경 픽셀로 구분되 는데, 도 7b를 참조하면, 픽셀 좌표계 상의 복수의 픽셀들 제1 픽셀 그룹은 전경 픽셀에 해당하고, 제2 픽셀 그룹은 후경 픽셀에 해당된다. 일 실시예에서, 차선 폴리라인 생성 장치는 복수의 픽셀들 중, 전경에 해당되는 전경 픽셀에 대해서는 제1 수식 을 적용하고, 후경에 해당되는 후경 픽셀에 대해서는 제2 수식을 적용함으로써, 제1 수식 및 제2 수식으로 구성 된 시드 확률 손실을 설정할 수 있다. 조감도 이미지 생성 장치는 소정의 도로에 포함된 복수의 차선들 각각에 대응하는 복수의 클러스터들에 대해, 전경 픽셀들 각각이 복수의 클러스터들 중 소정의 클러스터에 해당될 확률을 산출할 수 있다. 차선 폴리라인 생 성 장치는 전경 픽셀의 픽셀 값 및 산출된 확률에 기초하여 제1 수식을 설정할 수 있다. 한편, 클러스터에 해당 될 확률을 산출하는 방법에 대해서는 도 8a 내지 도 8c에서 후술하기로 한다. 또한, 차선 폴리라인 생성 장치는 전경 픽셀의 픽셀 값 및 후경 픽셀의 픽셀 값 간의 불균형을 보정하기 위해, 스케일링 인자(scaling factor)를 더 적용하여 제1 수식을 설정할 수 있다. 또한, 차선 폴리라인 생성 장치는 후경 픽셀의 픽셀 값에 기초하여 제2 수식을 설정할 수 있다. 상술한 제1 수식 및 제2 수식이 포함된 시드 확률 손실은 아래 수학식 5로 표현될 수 있다. 일 실시예에서, 제2 뉴럴 네트워크 모델은 아래 수학식 5에 따른 시드 확률 손실 값이 최소가 되도록 학습될 수 있다. 수학식 4에서 우변의 첫번째 항은 상술한 제1 수식, 두번째 항은 상술한 제2 수식일 수 있다. 또한, 수학식 4에 서 N은 픽셀 좌표계에 포함된 픽셀의 개수, 는 스케일링 인자, qi는 i번째 픽셀이 시드 예측 값, Sk는 전 경, bg는 후경, 는 픽셀 좌표계 상의 i번째 임베딩 좌표 ei가 k번째 클러스터에 해당될 확률을 의 미한다. 수학식 5"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 8, "content": "도 8a 내지 도 8c는 임베딩 오프셋 손실을 설명하기 위한 예시적인 도면이다. 도 8a 내지 도 8c를 참조하면, 픽셀 좌표계가 도시된다. 도 8a를 참조하면, 픽셀 좌표계에 포함된 제 1 직선 표시 및 제2 직선 표시는 서로 다른 차선을 나타낸다. 차선 폴리라인 생성 장치는 제2 뉴럴 네트워크 모델에 적용되는 적어도 하나의 손실 함수(또는, 손실)로써, 임 베딩 오프셋 손실(embedding offset loss)을 설정할 수 있다. 임베딩 오프셋은 픽셀 좌표계 상의 i번째 임 베딩 좌표 ei가 k번째 클러스터에 해당될 확률을 나타낸다. 여기서 클러스터는, 소정의 도로에 포함된 복수의 차 선들 각각에 대해 설정될 수 있다. 픽셀 좌표계 상의 i번째 픽셀이 k번째 클러스터의 중심에 가깝게 위치 할수록, 차선 폴리라인 생성 장치는 해당 확률 값 을 1에 가깝게 결정할 수 있다.도 8b를 참조하면, 각 픽셀 음영 표시는 소정의 클러스터에 해당될 확률을 시각화하여 표시한 것으로, 음영 표 시가 진할수록 소정의 클러스터에 해당될 확률 값이 큰 것을 의미한다. 도 8a에서 제1 직선 표시에 가깝게 위치했던 제1 픽셀 및 제2 직선 표시에 가깝게 위치했던 제2 픽셀은 소정의 클러스터에 해당될 확률 값이 매우 크므로, 도 8b에서 음영 표시가 진하게 표시된 것을 알 수 있다. 한편, 차선 폴리라인 생성 장 치는 소정의 클러스터에 해당될 확률은 전경 픽셀들에 대해서만 산출할 수 있고, 후경 픽셀들에 대해서는 계산 을 생략할 수 있다. 도 8c를 참조하면, 클러스터별로 픽셀들이 뭉친 것이 도시된다. 상술한 조감도 피쳐는 공간 좌표(spatial coordinates)를 갖는데, 차선 폴리라인 생성 장치는 제2 뉴럴 네트워크 모델을 구동하여 공간 좌표를 갖는 조감 도 피쳐를 이차원 임베딩 좌표(embedding coordinates)로 변환할 수 있다. 차선 폴리라인 생성 장치는 임베딩 좌표 상의 제1 픽셀을 제1 클러스터에 대한 중심점 (centroid), 제2 픽셀을 제2 클러스터에 대한 중심점으로 설정할 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 조감도 피쳐에 포함된 복수의 픽셀들 중에서 전경에 해당되는 전경 픽셀들을 추출할 수 있다. 또한, 차선 폴리라인 생성 장치는 소정의 도로에 포함된 복수의 차선들 각각에 대응 하는, 임베딩 좌표 상의 복수의 클러스터들에 대해, 전경 픽셀들 각각이 복수의 클러스터들 중 소정의 클 러스터에 해당될 확률을 산출할 수 있다. 또한, 차선 폴리라인 생성 장치는 산출된 확률을 이용하는 임베딩 오 프셋 손실을 설정하고, 임베딩 오프셋 손실을 이용하여 제2 뉴럴 네트워크 모델을 학습시킬 수 있다. 또한, 차선 폴리라인 생성 장치는 임베딩 좌표 상의 복수의 클러스터들 각각에 대한 중심점 및 클러스터를 형성하기 위한 고정 마진(fixed margin)을 설정할 수 있다. 차선 폴리라인 생성 장치는 중심점 및 고정 마진을 이용하여, 전경 픽셀들 각각이 복수의 클러스터들 중 소정의 클러스터에 해당될 확률을 산출할 수 있다. 또한, 차선 폴리라인 생성 장치는 전경 픽셀들 각각이 임베딩 좌표 상의 복수의 클러스터들 중 소정의 클 러스터에 해당될 확률을 산출하기 위해, 클러스터링 임계 확률 값을 설정할 수 있다. 차선 폴리라인 생성 장치 는 중심점, 고정 마진 및 클러스터링 임계 확률 값을 이용하여, 전경 픽셀들 각각이 복수의 클러스터들 중 소정 의 클러스터에 해당될 확률을 산출할 수 있다. 제2 뉴럴 네트워크 모델은 아래 수학식 6에 따른 임베딩 오프셋 손실 값이 최소가 되도록 학습될 수 있다. 수학식 6에서 K는 클러스터 개수, 는 서포트 벡터 머신 관련 손실(예를 들어, Lovasz hinge loss)을 의미한다. 수학식 6"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "또한, 전경 픽셀들 각각이 임베딩 좌표 상의 복수의 클러스터들 중 소정의 클러스터에 해당될 확률인 는 아래 수학식 7에 따라 산출될 수 있다. 수학식 7에 따르면 는 가우시안 분포를 따른다. 수학식 7 또한, 수학식 7의 는 아래 수학식 8에 따라 산출될 수 있다. 수학식 8에서 R은 임베딩 공간에서 클러스 터를 형성하기 위한 고정 마진, Pr-은 클러스터링 임계 확률 값을 나타낸다. 수학식 8"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 10, "content": "도 9는 일 실시예에 따른 순서 손실을 설명하기 위한 예시적인 도면이다. 차선 폴리라인 생성 장치는 제2 뉴럴 네트워크 모델에 적용되는 적어도 하나의 손실 함수(또는, 손실)로써, 순 서 손실(ordinal loss)을 설정할 수 있다. 여기서 순서란, 폴리라인에 대응하는 차선의 시작과 끝에 대한 순서 를 의미한다. 차선 폴리라인 생성 장치는 픽셀 좌표계 상의 소정의 픽셀이 차선의 시작점(starting point)에 가 까울수록 순서 값은 0에 가까운 값으로 결정하고, 차선의 끝점(ending point)에 가까울수록 순서 값은 0에 가까 운 값으로 결정할 수 있다. 도 9를 참조하면, 픽셀 좌표계 상의 각 픽셀이 차선의 시작점과 끝점 사이에서 어느 순서로 배치되는지가 도시 된다. 도 9의 순서 값 1 및 순서 값 2는 각기 다른 차선(또는, 클러스터)에 대한 결과값을 나타낸다. 도 9에서 음영 표시가 진할수록 소정의 픽셀이 차선의 끝점에 가까운 것을 나타낸다. 일 실시예에서, 차선 폴리라인 생성 장치는 조감도 피쳐에 포함된 복수의 픽셀들 중에서 전경에 해당되는 전경 픽셀들을 추출할 수 있다. 또한, 차선 폴리라인 생성 장치는 소정의 도로에 포함된 차선에 대한 상기 전경 픽셀 들 각각의 순서를 이용하는 순서 손실을 설정하고, 순서 손실을 이용하여 제2 뉴럴 네트워크 모델을 학습시킬 수 있다. 또한, 차선 폴리라인 생성 장치는 순서 손실을 설정하기 위해, 전경 픽셀들 각각이 포함된 클러스터를 식별하고, 식별된 클러스터에 대응하는 차선에 대해, 전경 픽셀들의 순서(order) 값을 결정할 수 있다. 차선 폴 리라인 생성 장치는 전경 픽셀들 각각에 대한 순서 값을 이용함으로써 순서 손실을 설정할 수 있다. 또한, 차선 폴리라인 생성 장치는 순서 값을 결정하기 위해, 차선의 시작점에 가까운 전경 픽셀일수록 제1 값에 가까운 값을 갖고, 차선의 끝점에 가까운 전경 픽셀일수록 제2 값에 가까운 값을 갖도록, 전경 픽셀들의 순서 값을 결정할 수 있다. 차선 폴리라인 생성 장치는 smooth L1 알고리즘을 이용하여 상기 순서 손실을 설정할 수 있으나, 이용되는 알고 리즘은 이에 제한되지 않는다. 제2 뉴럴 네트워크 모델은 아래 수학식 9에 따른 순서 손실 값이 최소가 되도록 학습될 수 있다. 수학 식 9에서 dn은 n번째 픽셀의 순서 값을 의미하고, 0에서 1사이의 값을 갖는다. 은 ground truth 값을 의미한 다. 수학식 9"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "한편, smooth L1 알고리즘은 수학식 10으로 표현될 수 있다. 수학식 10"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "차선 폴리라인 생성 장치는 임베딩 오프셋 손실, 시드 확률 손실 및 순서 손실 중 적어도 어느 하나가 최소가 되도록 제2 뉴럴 네트워크 모델을 학습시킬 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 아래 수학식 11에 따른 최종 손실이 최소가 되도록 제2 뉴럴 네트워 크 모델을 학습시킬 수 있다. 수학식 11에서 는 각 항의 중요도에 따라 다르게 설정될 수 있다. 수학식 11"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "또한, 차선 폴리라인 생성 장치는 임베딩 오프셋 손실, 시드 확률 손실, 순서 손실, 트렌슬레이션 손실 및 높이 손실 중 적어도 어느 하나가 최소가 되도록 제1 내지 제3 뉴럴 네트워크 모델을 학습시킬 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 아래 수학식 12에 따른 최종 손실이 최소가 되도록 제1 내지 제3 뉴 럴 네트워크 모델을 학습시킬 수 있다. 수학식 12에서 는 각 항의 중요도에 따라 다르게 설정될 수 있다. 수학식 12"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 14, "content": "도 10은 일 실시예에 따른 뉴럴 네트워크 모델을 이용하여 차선 폴리라인을 생성하는 설명하기 위한 흐름도이다. 도 10을 참조하면, 단계 1010에서, 차선 폴리라인 생성 장치는 차량에 탑재된 적어도 하나의 센서로부터 획득된 소정의 도로에 대한 기본 이미지를 획득할 수 있다. 단계 1020에서, 차선 폴리라인 생성 장치는 기본 이미지를 이용하여 다중 스케일 이미지 피쳐를 추출할 수 있다. 단계 1030에서, 차선 폴리라인 생성 장치는 제1 뉴럴 네트워크 모델에 다중 스케일 피쳐를 입력 데이터로 입력 하고, 제1 뉴럴 네트워크 모델의 출력 데이터로써 조감도 피쳐를 획득할 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 복수의 이미지 피쳐의 픽셀 좌표(pixel coordinate)와 상기 조감도 피쳐의 그리드(grid) 간 양방향 비교를 통해 산출된 트랜슬레이션(translation) 손실을 이용하여, 제1 뉴럴 네 트워크 모델을 학습시킬 수 있다. 트렌슬레이션 손실은, 픽셀 좌표에 룩업 테이블 함수를 적용한 값과 그리드 값의 차이를 나타내는 제1 값과, 픽 셀 좌표 값과 상기 그리드 값에 룩업 테이블 역함수를 적용한 값의 차이를 나타내는 제2 값에 기초하여 결정될수 있다. 트렌슬레이션 손실은 상술한 수학식 2와 같이 표현될 수 있다. 단계 1040에서, 차선 폴리라인 생성 장치는 제2 뉴럴 네트워크 모델에 조감도 피쳐를 입력 데이터로 입력하고, 제2 뉴럴 네트워크 모델의 출력 데이터로써 소정의 도로에 대한 폴리라인 이미지를 획득할 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 임베딩 오프셋 손실(embedding offset loss)을 이용하여 제2 뉴럴 네트워크 모델을 학습시킬 수 있다. 오프셋 손실은, 소정의 도로에 포함된 복수의 차선들 각각에 대응하는 복수 의 클러스터들에 대해 전경 픽셀들 각각이 복수의 클러스터들 중 소정의 클러스터에 해당될 확률에 기초하여 결 정될 수 있다. 또한, 차선 폴리라인 생성 장치는 시드 확률 손실(seed probability loss)을 이용하여 제2 뉴럴 네트워크 모델 을 학습시킬 수 있다. 시드 확률 손실은, 조감도 피쳐에 포함된 복수의 픽셀들 중, 전경에 포함되는 픽셀에 대 해서는 제1 수식 을 적용하고, 후경에 포함되는 픽셀에 대해서는 제2 수식 을 적용함으로써 결정될 수 있다. 또한, 차선 폴리라인 생성 장치는 순서 손실(order loss)을 이용하여 제2 뉴럴 네트워크 모델을 학습시킬 수 있 다. 순서 손실은, 조감도 피쳐에 포함된 복수의 픽셀들 중에서 전경 픽셀들 각각이 포함된 클러스터에 대응하는 차선에 대해, 상기 전경 픽셀들의 순서(order)를 이용하여 결정될 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 임베딩 오프셋 손실, 시드 확률 손실 및 순서 손실 중 적어도 어느 하나가 최소가 되도록 뉴럴 네트워크 모델을 학습시킬 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 제3 뉴럴 네트워크 모델에 조감도 피쳐를 입력 데이터로 입력하고, 제3 뉴럴 네트워크 모델의 출력 데이터로써 조감도 피쳐의 그리드 별 높이 값을 획득할 수 있다. 제3 뉴럴 네트워크 모델의 높이 손실은, 차선 마커를 이용하여 상기 조감도 피쳐의 그리드에 z값을 보간하여 획 득된 수도 실측 맵(pseudo ground truth map)의 높이 값에 기초하여 결정될 수 있다. 일 실시예에서, 차선 폴리라인 생성 장치는 소정의 도로에 대한 폴리라인 이미지에 기초하여, 소정의 도로를 주 행 중인 차량을 제어하기 위한 제어 신호를 생성할 수 있다. 예를 들어, 차선 폴리라인 생성 장치는 폴리라인 이미지를 이용하여 차량의 차선 유지 상태, 차선 변경 상태, 차선 이탈 상태 등을 결정하고, 결정된 상태에 기 초하여 제어 신호를 생성할 수 있다. 도 11은 일 실시예에 따른 차선 폴리라인 생성 장치의 블록도이다. 도 11을 참조하면, 차선 폴리라인 생성 장치는 통신부, 프로세서 및 DB를 포함할 수 있다. 도 11의 차선 폴리라인 생성 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도"}
{"patent_id": "10-2023-0003419", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "11에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자 라면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적 어도 하나를 포함할 수 있다. DB는 차선 폴리라인 생성 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서 의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 차선 폴리라인 생성 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 차선 폴리 라인 생성 장치의 동작을 제어할 수 있다. 프로세서는 도 1 내지 도 10에서 상술한 차선 폴리라인 생성 장치의 동작 중 적어도 일부를 제어할 수 있다. 차선 폴리라인 생성 장치 및 자율 주행 장치는 동일한 장치이거나, 각 장치에서 수행되는 적어도 일부의 동작이 동일할 수 있다.프로세서는 ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예로, 차선 폴리라인 생성 장치는 이동성을 가지는 전자 장치일 수 있다. 예를 들어, 차선 폴리라 인 생성 장치는 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 내비게이션, 카메라가 탑재된 디바이스 및 기타 모바일 전자 장치로 구현될 수 있다. 또한, 차선 폴 리라인 생성 장치는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 장치로 구현될 수 있다. 다른 실시예로, 차선 폴리라인 생성 장치는 차량 내에 임베디드 되는 전자 장치일 수 있다. 예를 들어, 차선 폴리라인 생성 장치는 생산 과정 이후 튜닝(tuning)을 통해 차량 내에 삽입되는 전자 장치일 수 있 다. 또 다른 실시예로, 차선 폴리라인 생성 장치는 차량 외부에 위치하는 서버일 수 있다. 서버는 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구 현될 수 있다. 서버는 차량에 탑재된 장치들로부터 차선 폴리라인을 생성하기 위해 필요한 데이터를 수신하고, 수신한 데이터에 기초하여 차량의 이동 경로를 결정할 수 있다. 또 다른 실시예로, 차선 폴리라인 생성 장치에서 수행되는 프로세스는 이동성을 가지는 전자 장치, 차량 내에 임베디되는 전자 장치 및 차량 외부에 위치하는 서버 중 적어도 일부에 의해 수행될 수 있다. 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 일 실시예에 따르면, 본 개시의 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다.도면 도면1 도면2 도면3 도면4 도면5a 도면5b 도면6a 도면6b 도면7a 도면7b 도면8a 도면8b 도면8c 도면9 도면10 도면11"}
{"patent_id": "10-2023-0003419", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4는 일 실시예에 따른 이미지 인코딩 및 뷰 변환을 수행하는 방법을 설명하기 위한 예시적인 도면이다. 도 5는 일 실시예에 따른 조감도 피쳐를 생성하는 방법을 설명하기 위한 예시적인 도면이다. 도 6은 일 실시예에 따른 뉴럴 네트워크 모델의 동작 방법을 설명하기 위한 예시적인 도면이다. 도 7a 내지 도 7b는 일 실시예에 따른 시드 확률 손실을 설명하기 위한 예시적인 도면이다. 도 8a 내지 도 8c는 임베딩 오프셋 손실을 설명하기 위한 예시적인 도면이다. 도 9는 일 실시예에 따른 순서 손실을 설명하기 위한 예시적인 도면이다. 도 10은 일 실시예에 따른 뉴럴 네트워크 모델을 이용하여 차선 폴리라인을 생성하는 설명하기 위한 흐름도이다. 도 11은 일 실시예에 따른 차선 폴리라인 생성 장치의 블록도이다."}
