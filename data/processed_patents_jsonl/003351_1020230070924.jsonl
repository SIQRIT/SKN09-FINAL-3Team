{"patent_id": "10-2023-0070924", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0172506", "출원번호": "10-2023-0070924", "발명의 명칭": "하이브리드 인공지능신경망 학습장치 및 그 방법", "출원인": "국립한밭대학교 산학협력단", "발명자": "최근호"}}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 이미지데이터셋을 입력데이터로 입력시키는 데이터입력부;상기 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴(flatten)을 수행하여 합성곱신경망(CNN)출력값으로 출력하는 합성곱신경망(CNN)학습부;상기 출력된 합성곱신경망(CNN)출력값이 입력될 경우 인코딩하여 차원이 축소된 잠재변수를 출력하는 인코더부;상기 출력된 잠재변수를 디코딩하여 상기 합성곱신경망(CNN)출력값과 동일한 차원의 디코딩출력값을 생성하는디코더부; 및상기 생성된 디코딩출력값이 입력될 경우 시계열학습을 수행하여 순환신경망(RNN)출력값으로 이미지분류를 수행하는 순환신경망(RNN)학습부;를 포함하는 하이브리드 인공지능신경망 학습장치."}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 합성곱신경망(CNN)학습부는,3차원 데이터인 상기 입력데이터에 대해 상기 플래턴을 수행하여 1차원 데이터로 생성하는하이브리드 인공지능신경망 학습장치."}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 합성곱신경망(CNN)학습부는,복수의 이미지 내에 존재하는 각 픽셀값을 하나의 독립변수로 생성하는 방식으로 상기 플래턴을 수행하는하이브리드 인공지능신경망 학습장치."}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 순환신경망(RNN)학습부는,LSTM(long short term memory)알고리즘 및 BiLSTM(bidirectional long short term memory)알고리즘 중에서 선택된 어느 하나의 순환신경망(RNN)모델을 이용하여 상기 시계열학습을 수행하는하이브리드 인공지능신경망 학습장치."}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "복수의 이미지데이터셋을 입력데이터로 데이터입력부에 입력시키는 단계;공개특허 10-2024-0172506-3-상기 데이터입력부로부터 합성곱신경망(CNN)학습부에 상기 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴(flatten)을 수행하여 합성곱신경망(CNN)출력값으로 출력하는 단계;상기 합성곱신경망(CNN)학습부로부터 인코더부에 상기 출력된 합성곱신경망(CNN)출력값이 입력될 경우 인코딩하여 차원이 축소된 잠재변수를 출력하는 단계;상기 인코더부로부터 디코더부에 상기 출력된 잠재변수를 디코딩하여 상기 합성곱신경망(CNN)출력값과 동일한차원의 디코딩출력값을 생성하는 단계; 및상기 디코더부로부터 순환신경망(RNN)학습부에 상기 생성된 디코딩출력값이 입력될 경우 시계열학습을 수행하여순환신경망(RNN)출력값으로 이미지분류를 수행하는 단계;를 포함하는 하이브리드 인공지능신경망 학습방법."}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 합성곱신경망(CNN)출력값으로 출력하는 단계는,상기 합성곱신경망(CNN)학습부에서 3차원 데이터인 상기 입력데이터에 대해 상기 플래턴을 수행하여 1차원 데이터로 생성하는하이브리드 인공지능신경망 학습방법."}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 합성곱신경망(CNN)출력값으로 출력하는 단계는,복수의 이미지 내에 존재하는 각 픽셀값을 하나의 독립변수로 생성하는 방식으로 상기 플래턴을 수행하는하이브리드 인공지능신경망 학습방법."}
{"patent_id": "10-2023-0070924", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 이미지분류를 수행하는 단계는,상기 순환신경망(RNN)학습부에서 LSTM(long short term memory)알고리즘 및 BiLSTM(bidirectional long shortterm memory)알고리즘 중에서 선택된 어느 하나의 순환신경망(RNN)모델을 이용하여 상기 시계열학습을 수행하는하이브리드 인공지능신경망 학습방법."}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 하이브리드 인공지능신경망 학습장치 및 그 방법에 관한 것으로, 복수의 이미지데이터셋을 입력데이터 로 입력시키는 데이터입력부; 상기 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴(flatte n)을 수행하여 합성곱신경망(CNN)출력값으로 출력하는 합성곱신경망(CNN)학습부; 상기 출력된 합성곱신경망(CN N)출력값이 입력될 경우 인코딩하여 차원이 축소된 잠재변수를 출력하는 인코더부; 상기 출력된 잠재변수를 디코 딩하여 상기 합성곱신경망(CNN)출력값과 동일한 차원의 디코딩출력값을 생성하는 디코더부; 및 상기 생성된 디코 딩출력값이 입력될 경우 시계열학습을 수행하여 순환신경망(RNN)출력값으로 이미지분류를 수행하는 순환신경망 (RNN)학습부;를 포함함으로써, 합성곱신경망(CNN)과 순환신경망(RNN)을 조합한 하이브리드 기법을 통해 이미지 분류 성능을 향상시킬 수 있다."}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴을 수행하여 출력하고, 이를 인코 딩하여 차원이 축소된 잠재변수를 출력하며, 출력된 잠재변수를 디코딩하여 합성곱신경망(CNN)출력값과 동일한 차원의 디코딩출력값을 생성한 후에, 생성된 디코딩출력값에 대한 시계열학습을 수행하여 이미지분류를 수행하 여 출력함으로써, 합성곱신경망(CNN)과 순환신경망(RNN)을 조합한 하이브리드 기법을 통해 이미지 분류 성능을 향상시킬 수 있는 하이브리드 인공지능신경망 학습장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "잘 알려진 바와 같이, 인간은 끊임없이 과학기술을 발전시켜 왔는데, 그 중에서도 데이터를 활용한 기술은 인공 지능 분야에 커다란 진전을 보여 왔고 앞으로 4차 산업혁명 시대를 선도하는 중요한 분야가 될 것으로 기대되고 있다. 특히, 컴퓨터 비전(Computer Vision) 기술의 발전으로 인해 이미지와 영상 영역에서 점증적인 발전을 거듭하여 현재는 빅데이터와 인공지능이 결합한 형태로 인간의 인식능력 범위까지 확대되고 있다. 한편, 컴퓨터 비전의 분야 중에서 이미지 분류(Image Classification)는 이미지가 주어졌을 때 해당 이미지가 속하는 클래스를 검출하는 것으로, 카테고리(Class)별로 분류된 이미지를 이용하여 인공지능모델을 훈련하고, 이미지가 어느 카테고리에 속하는지 예측하는 기법인데, 특정한 입력 이미지가 정해져 있는 라벨(label) 중 어 떤 라벨에 해당하는지 구별하는 것이다. 여기에서, 인공지능모델은 예를 들면, 합성곱신경망(CNN, convolution neural network), 순환신경망(RNN, recurrent neural network) 등이 이용될 수 있고, 합성곱신경망 또는 순환신경망 단독으로 이용될 경우 이미지 분류에서 한계가 있기 때문에, 합성곱신경망과 순환신경망을 조합한 CRNN(convolution recurrent neural network) 등이 제안되고 있다. 하지만, 상술한 바와 같은 CRNN모델의 경우 입력값들은 이미지 내 동일 위상에 있는 픽셀값들이 서로 다른 순서 로 나타나기 때문에 이미지 내 배열 순서를 정확하게 학습하기 어렵다는 한계점이 있어 이미지 분류 성능을 향 상시키기 위한 다양한 시도가 이루어지고 있는 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국공개특허 제10-2020-0065832호(2020.06.09.공개)"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴을 수행하여 출력하고, 이를 인코 딩하여 차원이 축소된 잠재변수를 출력하며, 출력된 잠재변수를 디코딩하여 합성곱신경망(CNN)출력값과 동일한 차원의 디코딩출력값을 생성한 후에, 생성된 디코딩출력값에 대한 시계열학습을 수행하여 이미지분류를 수행하 여 출력함으로써, 합성곱신경망(CNN)과 순환신경망(RNN)을 조합한 하이브리드 기법을 통해 이미지 분류 성능을 향상시킬 수 있는 하이브리드 인공지능신경망 학습장치 및 그 방법을 제공하고자 한다. 본 발명의 실시예들의 목적은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아 래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 복수의 이미지데이터셋을 입력데이터로 입력시키는 데이터입력부; 상기 입력데이 터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴(flatten)을 수행하여 합성곱신경망(CNN)출력값으로 출력하는 합성곱신경망(CNN)학습부; 상기 출력된 합성곱신경망(CNN)출력값이 입력될 경우 인코딩하여 차원이 축 소된 잠재변수를 출력하는 인코더부; 상기 출력된 잠재변수를 디코딩하여 상기 합성곱신경망(CNN)출력값과 동일 한 차원의 디코딩출력값을 생성하는 디코더부; 및 상기 생성된 디코딩출력값이 입력될 경우 시계열학습을 수행 하여 순환신경망(RNN)출력값으로 이미지분류를 수행하는 순환신경망(RNN)학습부;를 포함하는 하이브리드 인공지 능신경망 학습장치가 제공될 수 있다. 또한, 본 발명의 일 측면에 따르면, 상기 합성곱신경망(CNN)학습부는, 3차원 데이터인 상기 입력데이터에 대해 상기 플래턴을 수행하여 1차원 데이터로 생성하는 하이브리드 인공지능신경망 학습장치가 제공될 수 있다. 또한, 본 발명의 일 측면에 따르면, 상기 합성곱신경망(CNN)학습부는, 복수의 이미지 내에 존재하는 각 픽셀값 을 하나의 독립변수로 생성하는 방식으로 상기 플래턴을 수행하는 하이브리드 인공지능신경망 학습장치가 제공 될 수 있다.또한, 본 발명의 일 측면에 따르면, 상기 순환신경망(RNN)학습부는, LSTM(long short term memory)알고리즘 및 BiLSTM(bidirectional long short term memory)알고리즘 중에서 선택된 어느 하나의 순환신경망(RNN)모델을 이 용하여 상기 시계열학습을 수행하는 하이브리드 인공지능신경망 학습장치가 제공될 수 있다. 본 발명의 다른 측면에 따르면, 복수의 이미지데이터셋을 입력데이터로 데이터입력부에 입력시키는 단계; 상기 데이터입력부로부터 합성곱신경망(CNN)학습부에 상기 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴(flatten)을 수행하여 합성곱신경망(CNN)출력값으로 출력하는 단계; 상기 합성곱신경망(CNN)학습부로 부터 인코더부에 상기 출력된 합성곱신경망(CNN)출력값이 입력될 경우 인코딩하여 차원이 축소된 잠재변수를 출 력하는 단계; 상기 인코더부로부터 디코더부에 상기 출력된 잠재변수를 디코딩하여 상기 합성곱신경망(CNN)출력 값과 동일한 차원의 디코딩출력값을 생성하는 단계; 및 상기 디코더부로부터 순환신경망(RNN)학습부에 상기 생 성된 디코딩출력값이 입력될 경우 시계열학습을 수행하여 순환신경망(RNN)출력값으로 이미지분류를 수행하는 단 계;를 포함하는 하이브리드 인공지능신경망 학습방법이 제공될 수 있다. 또한, 본 발명의 다른 측면에 따르면, 상기 합성곱신경망(CNN)출력값으로 출력하는 단계는, 상기 합성곱신경망 (CNN)학습부에서 3차원 데이터인 상기 입력데이터에 대해 상기 플래턴을 수행하여 1차원 데이터로 생성하는 하 이브리드 인공지능신경망 학습방법이 제공될 수 있다. 또한, 본 발명의 다른 측면에 따르면, 상기 합성곱신경망(CNN)출력값으로 출력하는 단계는, 복수의 이미지 내에 존재하는 각 픽셀값을 하나의 독립변수로 생성하는 방식으로 상기 플래턴을 수행하는 하이브리드 인공지능신경 망 학습방법이 제공될 수 있다. 또한, 본 발명의 다른 측면에 따르면, 상기 이미지분류를 수행하는 단계는, 상기 순환신경망(RNN)학습부에서 LSTM(long short term memory)알고리즘 및 BiLSTM(bidirectional long short term memory)알고리즘 중에서 선 택된 어느 하나의 순환신경망(RNN)모델을 이용하여 상기 시계열학습을 수행하는 하이브리드 인공지능신경망 학 습방법이 제공될 수 있다."}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴을수행하여 출력하고, 이를 인코 딩하여 차원이 축소된 잠재변수를 출력하며, 출력된 잠재변수를 디코딩하여 합성곱신경망(CNN)출력값과 동일한 차원의 디코딩출력값을 생성한 후에, 생성된 디코딩출력값에 대한 시계열학습을 수행하여 이미지분류를 수행하 여 출력함으로써, 합성곱신경망(CNN)과 순환신경망(RNN)을 조합한 하이브리드 기법을 통해 이미지 분류 성능을 향상시킬 수 있다."}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 실시예들에 대한 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후 술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되 는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 하이브리드 인공지능신경망 학습장치의 블록구성도이고, 도 2 내지 도 9는 본 발명의 일 실시예에 따른 하이브리드 인공지능신경망 학습장치의 상세 구성을 설명하기 위한 도면이다. 도 1 내지 도 9를 참조하면, 본 발명의 일 실시예에 따른 하이브리드 인공지능신경망 학습장치는 데이터입력부 , 합성곱신경망학습부, 인코더부, 디코더부, 순환신경망학습부 등을 포함할 수 있다. 먼저, 본 발명의 일 실시예에 따른 하이브리드 인공신경망 학습장치에서 사용되는 인공지능신경망에 대해 설명 하면, 딥러닝(deep learning)은 신경망이 확장된 개념으로, 딥러닝알고리즘에는 대표적으로 심층신경망(DNN, Deep Neural Network), 합성곱신경망(CNN, Convolution Neural Network), 순환신경망(RNN, Recurrent Neural Network) 등이 있다. 이러한 딥러닝알고리즘은 데이터의 특성과 종류, 목표 등에 따라 사용되는 알고리즘이 달라지는데, 딥러닝은 AND, OR, XOR 문제 중에서 XOR가 두 개의 클래스로 구분하는 선을 찾을 수 없다는 점을 해결하기 위해 시작되었 고, 이러한 신경망은 분석 데이터로부터 반복적인 학습과정을 거처 패턴을 찾아내고, 이를 일반화하여 예측하는 문제에 있어서 유용하게 이용되는 기법으로 알려져 있다. 여기에서, 신경망은 크게 입력층(input layer), 은닉층(hidden layer) 및 출력층(output layer)으로 구성되며, 각 층은 여러 노드로 구성되는데, 입력층은 독립변수의 값을 받아들이는 역할을 하고, 은닉층은 독립변수의 값 을 이용하여 복잡한 수많은 계산을 수행하며, 출력층은 분석의 결과값을 출력해주는 역할을 담당한다. 한편, 합성곱신경망(CNN)은 이미지 분류에 특화된 딥러닝알고리즘으로, 이미지를 분석하여 사전에 정의된 클래 스로 분류 및 예측할 수 있는데, 이미지는 [넓이×높이×깊이]로 표현될 수 있고, 합성곱신경망(CNN)은 이러한 이미지의 모든 정보를 한 번에 입력받아 분석하지 않고, 이미지의 각 부분을 따로 학습한 후에, 이를 종합하여 전체 이미지의 정보를 파악할 수 있다. 이러한 합성곱신경망(CNN)은 이와 유사한 원리로 이미지를 분류할 때에도 이미지 전체가 아닌 이미지의 각 부분 을 학습하여 종합적으로 분석함으로써 분류의 정확도를 높이고자 한 알고리즘으로 도 2에 도시한 바와 같은 합 성곱신경망(CNN)에서 수행하는 합성곱 과정을 보면, 32×32×3의 픽셀크기를 갖는 이미지가 입력될 경우 이미지 의 각 부분을 학습하는 과정에서 필터(filter)를 이용할 수 있고, 5×5×3의 픽셀 크기를 가진 필터는 각 픽셀 마다 임의의 가중치를 포함하고 있는데, 이 필터를 이미지에 씌운 후, 이미지의 각 픽셀에 있는 값과 필터에 대 응되는 부분에 있는 가중치를 곱하여 가중합 한 하나의 값을 해당 영역으로부터 도출할 수 있다. 상술한 바와 같은 구조를 반복적으로 수행하여 최종적으로 완전연결계층(fully connected layer)을 생성하여 분 류를 수행할 수 있는데, 예를 들어 채널(예를 들면, 컬러, 흑백 등)에서 3채널인 컬러는 1:1로 합성곱 한 후 3 개의 값을 합산하고, 합성곱의 결과로 생성되는 이미지의 크기는 원본 이미지보다 작아지게 되며, 합성곱이 여 러 번 진행되어 이미지의 크기는 더욱 작아지게 되고, 이미지의 크기가 너무 작아지게 되면 유용한 정보의 손실 이 발생할 수 있으므로 이미지 크기가 작아지는 것을 방지하고, 이미지의 모서리 부분임을 알려주기 위해 패딩 (Padding) 기법을 사용할 수 있다. 한편, 합성곱신경망(CNN)에서 사용되는 풀링(Pooling)은 합성곱을 통해 생성된 이미지와 관련해서 과잉 적합을 완화하고, 왜곡된 이미지 보정하며, 일반화 가능성을 높이기 위해 크기를 재조정(resize)하는 작업으로, 대표적 으로 맥스풀링(max pooling)을 사용하는데, 특정 크기의 필터를 변환하려는 이미지에 씌우고, 해당 영역에서 가 장 큰 값 중 하나를 선택하여 해당 영역의 대표값으로 만들어주는 기법이다. 또한, 합성곱신경망(CNN)에서 사용되는 플래터닝(Flattening)은 합성곱과 풀링을 여러 차례 반복적으로 수행하 면서 최종적으로 여러 개의 결과 이미지를 생성하고, 이 최종 결과 이미지는 플래터닝을 거쳐 신경망 모델의 입 력값으로 사용하기 적합한 형태로 변환되는데, 플래터닝은 여러 이미지내에 있는 각 픽셀값을 하나의 독립변수 로 만들어 주는 것으로 예를 들어, 5×5×1 크기의 최종 이미지가 100개 생성되었을 경우, 독립변수의 개수는 5 ×5×1×100 = 2,500개이고, 독립변수들은 신경망에 전달되어 각 노드와 학습한 후 클래스별로 분류될 수 있다. 한편, 순환신경망(RNN)은 현재 상태에 대한 분석 결과를 도출하기 위해 현재 시점에서의 x값뿐만 아니라 이전 상태에 관한 정보도 함께 이용하는데, 도 3에 도시한 바와 같이 벡터 x0의 값이 입력될 경우 이를 이용하여 신 경망에서와 같은 학습을 수행한 후에, 두 번째 벡터 x1의 값이 입력될 경우 x1값뿐만 아니라 이전 단계에서 학 습된 분석값(hidden state)도 함께 이용하여 학습을 수행할 수 있다. 즉, 순환신경망(RNN)은 새로운 x벡터가 들어왔을 때 현 x벡터의 값만 이용하여 예측값을 추정하는 것이 아니라, 이전 x벡터들의 결과값을 함께 분석에 활용할 수 있으며, 경사하강법과 체인룰(chain rule)을 이용한 역전파 방 식으로 가중치를 업데이트할 수 있다. 하지만, 순환신경망(RNN)은 입력되는 x값이 많은 경우엔 기울기 소실(Gradient vanishing)이 일어나는데, 기울 기 소실은 모든 기울기가 1보다 작은 경우에 발생하며, 이 경우 가중치의 업데이트가 잘 이루어지지 않기 때문 에 이것을 해결하기 위해 LSTM(long short term memory) 알고리즘을 사용할 수 있다. 상술한 바와 같은 LSTM은 입력되는 x값의 시퀀스(sequence)가 길어질 경우 발생하게 되는 기울기 소실 문제에 대한 해결책으로 제안된 알고리즘으로, 순환신경망(RNN)알고리즘에 메모리 셀이라는 개념을 추가하였다. 그 이유는, 순환신경망(RNN)이 현 상태에 대한 학습 시 이전 단계에서 학습된 결과를 함께 반영하는데, 너무 오 래된 학습결과까지 반영하게 될 경우 잘못된 예측값을 줄 수 있고, 입력되는 x에 따라 이전 단계에서 학습된 결 과를 반영하지 않는 것이 더 좋은 결과를 보여줄 때도 있기 때문이다. 이에 따라, LSTM은 도 4에 도시한 바와 같이 메모리 셀을 이용하여 현 단계에서의 모델 학습 시 이전 단계에서 학습된 결과를 반영하는 양을 조절하여 위에서 언급된 문제들을 해결하고자 하였으며, 메모리 셀은 과거의 경험 을 얼마만큼 반영할지를 결정하는 값이라고 할 수 있다. 한편, BiLSTM(bidirectional long short term memory)은 순환신경망(RNN)이나 LSTM은 입력값을 시간 순서대로 입력하기 때문에 결과물이 직전 패턴을 기반으로 수렴하는 경향을 보인다는 한계가 있어, 이를 해결하기 위해 양방향 순환신경망(Bi-RNN)이 제안되었는데, 기존의 순방향에 역방향을 은닉층에 추가하여 성능을 향상 시켰지 만, 데이터 길이가 길고 층이 깊으면, 과거의 정보가 손실되는 단점이 있다. 이를 해결하기 위해 BiLSTM이 제안되었는데, 출력값에 대한 손실을 최소화하는 과정에서 모든 파라미터가 동시 에 학습되는 종단 간 학습이 가능하며, 단어와 구(Phrase)간 유사성을 입력 벡터에 내재화하여 성능을 개선하고, 데이터 길이가 길어도 성능이 저하되지 않는 장점이 있으며, 2개의 LSTM 계층을 사용할 경우 계층의 단어 순서를 조정할 수 있는데, 도 5에 도시한 바와 같이 첫번째 LSTM 계층은 기존과 동일하게 입력 문장을 왼 쪽에서 오른쪽으로 처리하고, 추가된 두 번째 LSTM 계층은 입력 문장의 단어 순서를 반대로 처리할 수 있다. 예를 들면, A-B-C의 순서로 처리되는 과정이 C-B-A의 역순서로 처리될 수 있으며, 단계마다 두 모델에서 나온 2 개의 히든벡터(Hidden Vector)는 학습된 가중치를 통해 하나의 히든벡터로 생성할 수 있다. 한편, 합성곱신경망(CNN)과 순환신경망(RNN)을 결합하여 학습을 수행할 수 있고, 그 결합방식에 따라 예를 들어 순차적 결합방식과 병렬적 결합방식으로 구분할 수 있는데, 순차적 결합방식의 경우 도 6에 도시한 바와 같이 이미지 내 특징 추출을 위한 합성곱신경망(CNN)과 시계열적 요소를 인식하기 위한 순환신경망(RNN)의 조합으로 구성될 수 있고, 다양한 크기의 이미지를 입력 받아 특징을 추출한 뒤, 순환신경망(RNN)을 활용해 예측된 분류 값을 출력할 수 있다. 상술한 바와 같은 인공지능신경망을 이용하여 본 발명의 실시예에 따른 하이브리드 인공지능신경망 학습장치를 구축할 수 있는데, 도 1 및 도 7에 도시한 바와 같이 합성곱과 풀링을 적용시켜 나온 결과물을 플래턴을 수행한 후, 이 플래턴 된 값을 순환신경망(RNN)의 입력값으로 바로 입력시키는 대신에, 이 값들을 인코더에 통과시켜 인코딩된 잠재변수로 차원을 축소시킨 후, 이 잠재변수를 다시 디코더에 통과시켜 원래의 입력값과 동일한 차원 의 출력값을 생성한다. 이후 이 디코더의 출력값을 순환신경망(RNN)의 입력값으로 입력시키게 되는데, 이러한 변환 과정은 분류 모델을 학습할 때 순환신경망(RNN)에 입력되는 픽셀값의 순서까지최적화하여 학습할 수 있게 함으로써, 최적의 입력 순 서를 검출할 수 있으며, 이를 통해 이미지 내 픽셀값들이 고정된 순서로, 그리고 동일한 위상에 있는 픽셀값들 이 서로 다른 순서로 순환신경망(RNN)에 입력됨으로써 나타날 수 있는 이미지 분류의 한계점을 개선하여, 더욱 향상된 성능의 하이브리드모델을 제공할 수 있을 뿐만 아니라 이를 이미지 분류 학습에 활용하여 이미지 분류 성능을 향상시킬 수 있다. 한편, 본 발명의 실시예에 따른 하이브리드 인공지능신경망 학습장치의 구성부를 구체적으로 설명하면, 데이터 입력부는 복수의 이미지데이터셋을 입력데이터로 입력시키는 구성부로, 도 8에 도시한 바와 같은 복수의 이미지데이터셋을 입력데이터로 입력시킬 수 있다. 예를 들면, 본 발명의 일 실시예에서 사용한 데이터셋은 이미지데이터로 구성된 CIFAR-10 데이터셋으로, 이 데 이터셋은 합성곱신경망(CNN) 학습 알고리즘으로 사용되고 있는 오픈 데이터셋이고, 도 8에 도시한 바와 같이, 10개의 클래스로 구성된 컬러 이미지데이터를 포함하고 있으며, 각 이미지데이터는 32×32의 해상도 크기를 가질 수 있다. 여기에서, 본 발명의 일 실시예에서 활용되는 하이브리드모델의 성능을 향상시키기 위해 다음과 같은 작업을 수 행할 수 있는데, 첫째, 본 발명의 일 실시예에서 활용되는 하이브리드모델의 학습 및 이미지 분류 과정을 적어 도 3회씩 반복 수행할 수 있고, 둘째, 매 학습 및 이미지 분류 과정마다 하이브리드모델의 성능을 검증하기 위 한 검증데이터셋을 다르게 설정하여 검증할 수 있다. 이를 위해, 예를 들어 CIFAR-10에서 제공하는 고정된 검증데이터셋을 이용하지 않고, CIFAR-10에서 제공하는 학 습데이터 50,000개를 학습 및 이미지 분류 과정마다 7:3의 비율로 랜덤하게 분할하여 학습데이터셋과 검증데이 터셋으로 구성할 수 있다. 또한, 본 발명의 일 실시예에서 활용되는 하이브리드모델의 성능을 향상시키기 위해 입력데이터에 대한 전처리 를 수행할 수 있는데, 입력데이터들은 데이터 전체의 평균을 빼주고 표준편차로 나누어 주는 표준화를 진행한 후 학습을 위해 입력할 수 있으며, 모든 전처리 작업과 모델 개발은 파이썬(python)을 이용하여 수행할 수 있다. 합성곱신경망학습부는 데이터입력부로부터 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴(flatten)을 수행하여 합성곱신경망(CNN)출력값으로 출력하는 구성부로, 3차원 데이터인 입력데이터 에 대해 플래턴을 수행하여 1차원 데이터로 생성하되, 복수의 이미지 내에 존재하는 각 픽셀값을 하나의 독립변 수로 생성하는 방식으로 플래턴을 수행할 수 있다. 예를 들면, 합성곱신경망학습부는 데이터입력부로부터 입력되는 입력데이터인 이미지에 대해 합성곱 과 풀링 작업을 반복적으로 수행하는 방식으로 차원 축소 및 정규화를 수행한 이미지의 특징을 추출할 수 있고, 학습된 3차원 데이터를 플레터닝하여 이미지데이터를 1차원으로 펼쳐 생성할 수 있으며, 이러한 1차원데이터는 인코더부로 전달될 수 있다. 인코더부는 합성곱신경망학습부를 통해 출력된 합성곱신경망(CNN)출력값이 입력될 경우 인코딩하여 차원이 축소된 잠재변수(Latent variable)를 출력하는 구성부로, 합성곱신경망학습부의 출력값인 플래터닝 된 1차원데이터를 입력값으로 받아, 인코딩을 수행하여 차원이 축소된 잠재변수를 생성할 수 있고, 생성된 잠재 변수는 디코더부로 전달될 수 있다. 디코더부는 인코더부를 통해 출력된 잠재변수를 디코딩하여 합성곱신경망(CNN)출력값과 동일한 차원 의 디코딩출력값을 생성하는 구성부로, 인코더부로부터 전달되는 잠재변수를 다시 디코딩하여 인코더부 의 입력값과 동일한 차원(즉, 1차원)의 출력값을 생성할 수 있으며, 이러한 디코딩출력값은 순환신경망학 습부로 전달될 수 있다. 상술한 바와 같은 인코더부 및 디코더부에서 생성 및 처리되는 잠재변수에 대해 도 9를 참조하여 구 체적으로 설명하면, 인코더부에 합성곱신경망(CNN)출력값이 입력될 경우, 인코더부는 이 입력값을 인 코딩하여 압축시키는 역할을 수행할 수 있으며, 이렇게 압축된 의미 있는 값을 잠재변수라고 한다. 즉, 잠재변수는 입력값의 정보를 모두 포함하면서 입력값보다 더 작은 차원으로 표현된 값을 의미하는데, 잠재 변수는 이 후, 디코더부에 입력되어 인코더부의 입력값인 합성곱신경망(CNN)출력값과 동일한 차원으 로 변환될 수 있는데, 인코더부의 입력값인 합성곱신경망(CNN)출력값과 차원이 같더라도 입력값이 가진 정 보를 재구성한 결과물이라고 할 수 있다. 상술한 바와 같은 잠재변수의 생성 과정을 보다 구체적으로 설명하면, 인코더부에 입력되는 입력값의 노드 들은 1번 은닉층의 각 노드와 연결된 가중치를 이용하여 가중합을 계산할 수 있고, 이 값은 활성화 함수를 거쳐 1번 은닉층의 각 노드의 값이 되는데, 여기에서 입력값의 노드 수(차원)는 독립변수의 수와 같고, 1번 은닉층의 노드의 수(차원)는 입력값의 노드 수보다 작게 구성될 수 있다. 이 후, 1번 은닉층의 노드들은 다음 2번 은닉층의 각 노드와 연결된 가중치를 이용하여 가중합을 계산할 수 있 고, 이 값은 활성화 함수를 거쳐 2번 은닉층의 각 노드의 값이 되는데, 여기에서도 2번 은닉층의 노드의 수는 1 번 은닉층의 노드 수보다 작게 구성될 수 있다. 상술한 바와 같은 과정이 기 설정된 횟수만큼 반복된 후, 필요에 따라 설정된 충분히 작은 노드의 수(즉, 기 설 정된 개수의 노드 수)를 가진 은닉층이 생성되었을 때, 이 은닉층을 잠재변수라 하며, 이러한 잠재변수를 생성 하는 과정이 인코더부에서 수행되는 인코딩을 의미한다.상술한 바와 같은 과정을 통해 생성된 잠재변수는 디코더부에 입력되어 디코딩될 수 있는데, 입력된 잠재 변수는 다시 인코딩 과정에서 수행한 작업과 반대되는 디코딩 과정을 통해 원래 입력값(즉, 합성곱신경망(CNN) 출력값)과 동일한 노드의 수를 가진 은닉층을 최종적으로 생성할 수 있고, 이를 디코딩출력값이라고 하며, 이러 한 디코딩출력값을 생성하는 과정이 디코더부에서 수행되는 디코딩을 의미한다. 순환신경망학습부는 디코딩부를 통해 생성된 디코딩출력값이 입력될 경우 시계열학습을 수행하여 순 환신경망(RNN)출력값으로 이미지분류를 수행하는 구성부로, 예를 들면, LSTM(long short term memory)알고리즘 및 BiLSTM(bidirectional long short term memory)알고리즘 중에서 선택된 어느 하나의 순환신경망(RNN)모델을 이용하여 시계열학습을 수행할 수 있다. 예를 들면, 순환신경망학습부는 디코더부의 디코딩출력값을 입력값으로 입력시키고, LSTM 또는 BiLSTM의 알고리즘 특성을 사용하여 시계열 학습을 수행한 후, 최종적으로 출력되는 순환신경망(RNN)출력값을 통해 이미지를 분류할 수 있다. 한편, 아래의 표 1은 본 발명의 일 실시예에 따른 하이브리드 인공지능신경망 학습장치의 각 구성부인 데이터입 력부, 합성곱신경망학습부, 인코더부, 디코더부 및 순환신경망학습부에서 수행되는 레이어별 학습에 대해 나타내고 있는데, CNN 영역은 데이터입력부 및 합성곱신경망학습부를 포함하고, 인코더영역은 인코더부 및 디코더부를 포함하며, RNN영역은 순환신경망학습부를 나타 낸다. 표 1"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "따라서, 본 발명의 일 실시예에 따르면, 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴을 수행하여 출력하고, 이를 인코딩하여 차원이 축소된 잠재변수를 출력하며, 출력된 잠재변수를 디코딩하여 합성 곱신경망(CNN)출력값과 동일한 차원의 디코딩출력값을 생성한 후에, 생성된 디코딩출력값에 대한 시계열학습을 수행하여 이미지분류를 수행하여 출력함으로써, 합성곱신경망(CNN)과 순환신경망(RNN)을 조합한 하이브리드 기 법을 통해 이미지 분류 성능을 향상시킬 수 있다. 도 10은 본 발명의 다른 실시예에 따라 하이브리드 인공지능신경망을 이용하여 학습하는 과정을 나타내는 플로 우차트이다. 도 10을 참조하면, 복수의 이미지데이터셋을 입력데이터로 데이터입력부에 입력시킬 수 있다(단계210). 예를 들면, 본 발명의 다른 실시예에서 사용한 데이터셋은 이미지데이터로 구성된 CIFAR-10 데이터셋으로, 이 데이터셋은 합성곱신경망(CNN) 학습 알고리즘으로 사용되고 있는 오픈 데이터셋이고, 10개의 클래스로 구성된 컬러 이미지데이터를 포함하고 있으며, 각 이미지데이터는 32×32의 해상도 크기를 가질 수 있다. 또한, 본 발명의 다른 실시예에서 활용되는 하이브리드모델의 성능을 향상시키기 위해 입력데이터에 대한 전처 리를 수행할 수 있는데, 입력데이터들은 데이터 전체의 평균을 빼주고 표준편차로 나누어 주는 표준화를 진행한 후 학습을 위해 입력할 수 있다. 그리고, 데이터입력부로부터 합성곱신경망학습부에 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴을 수행하여 합성곱신경망출력값으로 출력할 수 있다(단계220). 상기 합성곱신경망출력값으로 출력하는 단계에서는, 합성곱신경망학습부에서 3차원 데이터인 입력데 이터에 대해 플래턴을 수행하여 1차원 데이터로 생성할 수 있고, 복수의 이미지 내에 존재하는 각 픽셀값을 하 나의 독립변수로 생성하는 방식으로 플래턴을 수행할 수 있다. 예를 들면, 합성곱신경망학습부에서는 데이터입력부로부터 입력되는 입력데이터인 이미지에 대해 합 성곱과 풀링 작업을 반복적으로 수행하는 방식으로 차원 축소 및 정규화를 수행한 이미지의 특징을 추출할 수 있고, 학습된 3차원 데이터를 플레터닝하여 이미지데이터를 1차원으로 펼쳐 생성할 수 있으며, 이러한 1차원데 이터는 인코더부로 전달될 수 있다. 다음에, 합성곱신경망학습부로부터 인코더부에 출력된 합성곱신경망출력값이 입력될 경우 인코딩하여 차원이 축소된 잠재변수를 출력할 수 있다(단계230). 예를 들면, 인코더부에서는 합성곱신경망학습부의 출력값인 플래터닝된 1차원데이터를 입력값으로 받 아, 인코딩을 수행하여 차원이 축소된 잠재변수를 생성할 수 있고, 생성된 잠재변수는 디코더부로 전달될 수 있다. 또한, 인코더부로부터 디코더부에 출력된 잠재변수를 디코딩하여 합성곱신경망출력값과 동일한 차원 의 디코딩출력값을 생성할 수 있다(단계240). 예를 들면, 디코더부에서는 인코더부로부터 전달되는 잠재변수를 다시 디코딩하여 인코더부의 입력값과 동일한 차원(즉, 1차원)의 출력값을 생성할 수 있으며, 이러한 디코딩출력값은 순환신경망학습부(15 0)로 전달될 수 있다. 다음에, 디코더부로부터 순환신경망학습부에 생성된 디코딩출력값이 입력될 경우 시계열학습을 수행 하여 순환신경망출력값으로 이미지분류를 수행할 수 있다(단계250). 상기 이미지분류를 수행하는 단계에서는, 순환신경망학습부에서 LSTM알고리즘 및 BiLSTM알고리즘 중 에서 선택된 어느 하나의 순환신경망(RNN)모델을 이용하여 시계열학습을 수행할 수 있다. 예를 들면, 순환신경망학습부에서는 디코더부의 디코딩출력값을 입력값으로 입력시키고, LSTM 또는 BiLSTM의 알고리즘 특성을 사용하여 시계열 학습을 수행한 후, 최종적으로 출력되는 순환신경망(RNN)출력값을 통해 이미지를 분류할 수 있다. 따라서, 본 발명의 다른 실시예에 따르면, 입력데이터가 입력될 경우 합성곱과 풀링을 반복 수행한 후, 플래턴 을 수행하여 출력하고, 이를 인코딩하여 차원이 축소된 잠재변수를 출력하며, 출력된 잠재변수를 디코딩하여 합 성곱신경망(CNN)출력값과 동일한 차원의 디코딩출력값을 생성한 후에, 생성된 디코딩출력값에 대한 시계열학습 을 수행하여 이미지분류를 수행하여 출력함으로써, 합성곱신경망(CNN)과 순환신경망(RNN)을 조합한 하이브리드 기법을 통해 이미지 분류 성능을 향상시킬 수 있다. 이하에서는, 상술한 바와 같은 본 발명의 실시예에 따른 하이브리드 인공지능신경망 학습장치 및 그 방법을 통 해 학습된 하이브리드 기법에 대한 실험 결과에 대해 설명하기로 한다. 먼저, 본 발명의 실시예에서는 기존 이미지 학습에 많이 사용되고 있는 합성곱신경망(CNN)알고리즘과, 합성곱신 경망(CNN)과 순환신경망(RNN)을 연결한 이미지 분류에 사용되는 CRNN알고리즘과, 본 발명의 실시예에 따른 하이 브리드모델인 ECRNN알고리즘을 각각 사용하여 구성된 모델을 학습시키고, 그 결과를 다음과 같이 비교 분석하였 다. 첫째, 합성곱신경망(CNN)알고리즘과 CRNN알고리즘을 사용한 모델의 정확도(accuracy)를 비교하는 실험을 통해, 합성곱신경망(CNN)알고리즘 대비 CRNN알고리즘의 성능 개선 효과를 분석하였다.둘째, 합성곱신경망(CNN)알고리즘과 본 발명의 실시예에 따른 ECRNN알고리즘을 사용한 모델의 정확도를 비교하 는 실험을 통해, 합성곱신경망(CNN)알고리즘 대비 ECRNN알고리즘의 성능 개선 효과를 분석하였다. 셋째, CRNN알고리즘과 ECRNN알고리즘을 사용한 모델의 정확도를 비교하는 실험을 통해, CRNN알고리즘 대비 ECRNN알고리즘의 성능 개선 효과를 분석하였다. 마지막으로, CRNN알고리즘과 ECRNN알고리즘에서 사용하는 순환신경망(RNN)계열의 알고리즘인 LSTM과 BiLSTM의 정확도를 비교하는 실험을 진행하였다. 상기 첫째 경우에 대해 학습을 진행한 경우 합성곱신경망(CNN)알고리즘 대비 CRNN알고리즘의 정확도를 비교한 결과는 아래 표 2에 나타낸 바와 같다. 표 2"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기한 바와 같이, 비교 대상이 되는 합성곱신경망(CNN)알고리즘은 73.25%의 정확도를 보인 반면, CRNN알고리즘 은 최고 74.52%의 정확도를 보여, 최대 1.27%p 만큼 더 높은 정확도를 보였고, 대응표본 t검정(paired t- test)의 수행 결과 통계적으로 유의한 것으로 나타났다. 그리고, CRNN알고리즘 내부의 은닉층의 노드 수에 따른 정확도차이를 살펴보면, 1개의 은닉층으로 구성된 LSTM 과 2개의 은닉층으로 구성된 LSTM 모두 은닉층의 노드 수가 16개일 때가 32개일 때보다 약간 더 높은 정확도를 보였다. 반면에 BiLSTM의 경우, 1개의 은닉층으로 구성된 BiLSTM과 2개의 은닉층으로 구성된 BiLSTM 모두 은닉층의 노드 수가 32개일 때가 16개일 때 보다 약간 더 높은 정확도를 보였다. 상기 둘째 경우에 대해 학습을 진행한 경우 합성곱신경망(CNN)알고리즘과 본 발명의 실시예에 따른 ECRNN알고리 즘의 정확도를 비교한 결과는 아래 표 3과 같이 나타낸 바와 같다. 표 3"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "상기한 바와 같이, ECRNN알고리즘은 은닉층의 개수가 1개이고 은닉층의 노드 수가 16일 때 77.08%의 가장 높은 정확도를 보여, 합성곱신경망(CNN)알고리즘의 정확도 73.25% 보다 3.83%p 더 높은 정확도를 보였다. 또한, ECRNN알고리즘 내부의 은닉층의 개수에 따른 정확도 차이를 살펴보면, LSTM과 BiLSTM 모두 은닉층별 노드 의 수에 상관없이 은닉층의 개수가 1개일 때가 2개일 때보다 약간 더 높은 정확도를 보여주었다.추가적으로, ECRNN알고리즘 내부의 은닉층의 노드수에 따른 정확도 차이를 살펴보면, LSTM과 BiLSTM 모두 은닉 층의 개수에 상관없이 은닉층별 노드의 수가 16개일 때가 32개일 때보다 약간더 높은 정확도를 보여주었다. 상기 셋째 경우에 대해 학습을 진행한 경우 CRNN알고리즘과 본 발명의 실시예에 따른 ECRNN알고리즘의 정확도를 비교한 결과는 아래 표 4에 나타낸 바와 같다. 표 4"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "상기에 나타낸 바와 같이, ECRNN알고리즘이 CRNN알고리즘보다 최대 2.56%p 더 높은 정확도를 보이는 것으로 나 타났으며, 전체적인 결과를 보면 ECRNN알고리즘은 은닉층의 개수와 은닉층별 노드의 수를 달리 하였을 때에도 모든 경우에 있어서, CRNN알고리즘 보다 더 높은 정확도를 보였으며, 모두 통계적으로 유의하게 나타났다. 상기 마지막 경우에 대해 학습을 진행한 경우 CRNN알고리즘과 본 발명의 실시예에 따른 ECRNN에서 사용하는 LSTM과 BiLSTM에 따른 정확도 비교한 결과는 아래 표 5에 나타낸 바와 같다. 표 5"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "상기에서 나타낸 바와 같이, CRNN알고리즘에서 LSTM을 사용하였을 때와 BiLSTM을 사용하였을 때의 결과를 비교 하면, 은닉층의 개수가 1개인 경우 은닉층 노드의 수가 16개일 때 LSTM이 통계적으로 유의한 0.68%p 더 높은 정 확도를 보였고, 은닉층의 개수가 2개인 경우 은닉층별 노드의 수가 32개일 때 BiLSTM이 통계적으로 유의한 1.42%p 더높은 정확도를 보였다. 하지만, LSTM과 BiLSTM은 각각 정확도가 가장 높게 나왔을 때를 비교하였을 경우, BiLSTM이 LSTM 보다 다소 높 게 나타났으나, 통계적으로 유의하지 않게 나타났다. 또한, ECRNN알고리즘에서 LSTM을 사용하였을 때와 BiLSTM을 사용하였을 때의 결과를 비교하면, 은닉층의 개수가 1개인 경우 은닉층 노드의 수가 16개일 때 BiLSTM이 통계적으로 유의한 1.11%p 더 높은 정확도를 보였고, 은닉 층의 개수가 2개인 경우 두 알고리즘 간 정확도 차이는 통계적으로 유의하지 않게 나타났다.그리고, LSTM과 BiLSTM을 사용하여 학습한 경우에서 각각 정확도가 가장 높게 나왔을 때를 비교하였을 경우, BiLSTM이 LSTM 보다 통계적으로 유의한 1.11%p 더 높은 정확도를 보였다. 상술한 바와 같이 본 발명의 실시예에 따른 하이브리드 인공지능신경망 학습장치 및 그 방법에서 제시한 하이브 리드모델은 기존에 제안된 CRNN알고리즘의 한계점을 개선하기 위해 인코더와 디코더에 기반한 합성곱신경망 (CNN)과 순환신경망(RNN)의 새로운 하이브리드 방식을 제안하였으며, 기존의 합성곱신경망(CNN) 및 CRNN과 본 발명의 실시예에 따른 ECRNN의 정확도 비교를 위해 다양한 실험을 진행한 결과, CRNN과 ECRNN 모두 합성곱신경 망(CNN)보다 더 높은 정확도를 보이는 것으로 나타났다. 특히, 본 발명의 실시예에 따른 ECRNN은 합성곱신경망(CNN) 대비 CRNN보다 더 높은 정확도 향상을 보이는 것으 로 나타났는데, 본 발명의 실시예에 따른 ECRNN의 최고 정확도는 77.08%로 CRNN의 최고 정확도 74.52% 보다 2.56%p 더 높은 정확도를 보이는 것으로 나타났다. 또한, 본 발명의 실시예에 따른 ECRNN의 경우, 은닉층의 개수가 2개 보다는 1개, 은닉층별 노드의 수가 32개 보 다는 16개일 때, 더 높은 정확도를 보이는 것으로 나타났다. 상술한 바와 같이 본 발명의 실시예에 따른 하이브리드 인공지능신경망 학습장치 및 그 방법에서 제시한 하이브 리드모델은 기존에 많은 선행연구에서 주로 사용해 오던 합성곱신경망(CNN)과 순환신경망(RNN)의 하이브리드기 법이 가지고 있었던 한계점을 제시하고, 이를 인코더와 디코더의 개념을 응용하여 개선한 새로운 합성곱신경망 (CNN)-순환신경망(RNN) 하이브리드기법을 제시하였고, 다양한 알고리즘 비교 실험을 통해, 새로운 하이브리드기 법의 효과성을 검증함으로써 인코더와 디코더 개념의 적용 가능성을 넓혔으며, 새로운 하이브리드기법은 기존 하이브리드기법에 비해, 복잡도가 많이 증가하지 않아 모델 학습 시간과 인프라구축 비용 측면에서 이점을 가진 다. 또한, 본 발명의 실시예에 따른 하이브리드 인공지능신경망 학습장치 및 그 방법에서 제시한 하이브리드모델은 필기체 인식, 포털 등의 동식물명 인식, 의료분야에서의 영상 이미지 판독, 관세분야에서의 수입물품 이미지를 바탕으로 한 HS코드 추천 등 정확한 이미지 분류가 필요한 다양한 분야에서 제공되는 서비스의 품질을 향상시킬 수 있음을 기대할 수 있다. 이상의 설명에서는 본 발명의 다양한 실시예들을 제시하여 설명하였으나 본 발명이 반드시 이에 한정되는 것은"}
{"patent_id": "10-2023-0070924", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "아니며, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명의 기술적 사상을 벗어나지 않는 범 위 내에서 여러 가지 치환, 변형 및 변경이 가능함을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0070924", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 하이브리드 인공지능신경망 학습장치의 블록구성도이고, 도 2 내지 도 9는 본 발명의 일 실시예에 따른 하이브리드 인공지능신경망 학습장치의 상세 구성을 설명하기 위 한 도면이며, 도 10은 본 발명의 다른 실시예에 따라 하이브리드 인공지능신경망을 이용하여 학습하는 과정을 나타내는 플로 우차트이다."}
