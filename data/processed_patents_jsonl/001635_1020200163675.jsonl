{"patent_id": "10-2020-0163675", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0075521", "출원번호": "10-2020-0163675", "발명의 명칭": "인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템 및 그 방법", "출원인": "경희대학교 산학협력단", "발명자": "김녹원"}}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 장치를 이용한 방법에있어서,상기 뉴럴 네트워크 장치가 BNN모델에서 BNN매개변수를 물리적 매개변수 및 하이퍼 매개변수로 분류하는 단계;상기 뉴럴 네트워크 장치가 상기 물리적 매개변수 및 상기 하이퍼 매개변수를 이용하여 최적의 파라미터를 획득하는 단계;상기 뉴럴 네트워크 장치가 상기 최적의 파라미터를 이용하여 상기 BNN모델에서 최소채널크기를 산출하는 단계;를 포함하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 물리적 매개변수는 컨볼루션 레이어(Convolutional Layer)의 수, 채널(필터) 크기, 커널 크기, 배치 정규화(Batch Normalization) 유무 및 풀링 계층(Pooling Layer) 유무를 포함하고,상기 하이퍼 매개변수는 최적화 기기(Optimizer), 학습률(learning rate) 및 모멘텀(Momentum)을 포함하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 최적화 기기는 배치 경사 하강(Batch Gradient Descent) 알고리즘, 확률적 경사 하강(StochasticGradient Descent, SGD) 알고리즘, 경사 하강(Gradient Descent) 알고리즘, 미니 배치 경사 하강(Mini-BatchGradient Descent) 알고리즘, 모멘텀(Momentum) 알고리즘, 아다그라드(Adagrad) 알고리즘, 알엠에스프롭(RMSprop) 알고리즘 및 아담(Adam) 알고리즘 중 적어도 하나의 알고리즘을 포함하는, 인공지능 기술을 이용한적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 최적의 파라미터를 획득하는 단계는,상기 하이퍼 매개변수에 포함된 상기 최적화 기기의 알고리즘을 이용하여 최적알고리즘을 산출하는 단계;상기 하이퍼 매개변수에 포함된 상기 학습률을 이용하여 BNN에서 가중치 및 커널 업데이트의 강도를 조절하는최적학습률을 산출하는 단계; 및상기 하이퍼 매개변수에 포함된 상기 모멘텀을 이용하여 BNN에서 운동량값을 고려하여 최적모멘텀을 산출하는단계;를 포함하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 최적알고리즘을 산출하는 단계는,상기 최적화 기기에 포함된 적어도 하나의 알고리즘 사이의 최적의 알고리즘조합을 산출하는 단계; 및공개특허 10-2022-0075521-3-상기 최적의 알고리즘조합의 비율을 산출하는 단계;를 포함하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 최적알고리즘은,커널 크기가 3 x 3인 경우 Adam 알고리즘과 SGD 알고리즘의 비율이 3 : 7 이고,커널 크기가 5 x 5인 경우 Adam 알고리즘과 SGD 알고리즘의 비율이 6 : 4 인, 인공지능 기술을 이용한 적층형저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,커널 크기가 3 x 3 및 커널 크기가 5 x 5인 경우 동일한 최적학습률을 갖고,상기 최적학습률은 0.03 학습률을 가지는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제4항에 있어서,상기 최적모멘텀은,커널 크기가 3 x 3인 경우 0.5 모멘텀의 값을 가지고,커널 크기가 5 x 5인 경우 0.6 모멘텀의 값을 가지는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서,상기 최적의 파라미터를 획득하는 단계는,상기 배치 정규화 및 상기 풀링 계층의 존재유무를 판단하는 단계;를 포함하는, 인공지능 기술을 이용한 적층형저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,컨볼루션 레이어의 수가 4이고, 채널 크기가 9이고, 커널 크기가 3 x 3인 경우, 상기 배치 정규화는 상기 컨볼루션 레이어 각각에 포함되는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 배치 정규화는 상기 컨볼루션 레이어 각각에 포함되지 않는 경우, 8%의 정확도가 차이나는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,공개특허 10-2022-0075521-4-상기 배치 정규화는 에 의해 연산 수행되는, 인공지능 기술을 이용한 적층형저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,컨볼루션 레이어의 수가 4이고, 채널 크기가 9이고, 커널 크기가 3 x 3인 경우, 상기 풀링 계층은 상기 컨볼루션 레이어 중 마지막 2개의 계층에 위치하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서,상기 최소채널크기를 산출하는 단계는,상기 최소채널크기의 정확성을 판단하는 단계;를 포함하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 최소채널크기가 8인 경우, 커널 크기가 3 x 3인 일 때 정확도가 96% 이상인, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 최소채널크기를 산출하는 단계는,상기 최소채널크기별로 계층별 에러율을 적용하여 상기 최소채널크기의 정확성을 판단하는 단계;를 더포함하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 최소채널크기가 8이고, 커널 크기가 3 x 3인 인 경우,40nm 노드에서 정확도가 94.069%이고, 20nm 노드에서 정확도가 93.777%이며, 10nm 노드에서 정확도가93.07%인, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항에 있어서,상기 뉴럴 네트워크 장치가 상기 최소채널크기를 이용하여 최소편차를 갖는 RRAM의 계층을 최적화하는 단계;를포함하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 방법."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항 내지 제18항 중 적어도 하나의 방법을 뉴럴 네트워크 장치에 의해 수행하는, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 시스템."}
{"patent_id": "10-2020-0163675", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2022-0075521-5-하드웨어인 컴퓨터와 결합되어, 제1항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템 및 그 방법이 제공된다. 상기 방법 은, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트워크 장치를 이용한 방 법에 있어서, 상기 뉴럴 네트워크 장치가 BNN모델에서 BNN매개변수를 물리적 매개변수 및 하이퍼 매개변수로 분 류하는 단계; 상기 뉴럴 네트워크 장치가 상기 물리적 매개변수 및 상기 하이퍼 매개변수를 이용하여 최적의 파 라미터를 획득하는 단계; 상기 뉴럴 네트워크 장치가 상기 최적의 파라미터를 이용하여 상기 BNN모델에서 최소채 널크기를 산출하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템 및 그 방법에 관한 것으로써, 더욱 구체적으로 BNN(Binary Neural Networks) 모델에서 BNN모델매개변수를 물리적 매개변수 및 하이퍼 매개변수로 분류하여 최적의 파라미터를 획득하고, 획득한 파라미터를 이용하여 높은 정확도와 최소 편차를 갖 는 최소크기의 채널값을 산출하고, 산출된 채널값을 이용하여 적층형 저항 변환 메모리(3D RRAM)의 계층을 최적 화기 위한 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템 및 그 방법에 관한 것 이다."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간의 신경계를 닮은 뉴로모픽 프로세서(neuromorphic processor)에 관한 관심이 증대되고 있다. 인간의 신경 계에 존재하는 뉴런(neuron)과 시냅스(synapse)에 각각 대응되는, 뉴런 회로와 시냅스 회로를 설계하여, 뉴로모 픽 프로세서를 구현하고자 하는 연구가 있어 왔다. 이와 같은 뉴로모픽 프로세서는 BNN(Binary Neural Networks), Convolutional Neural Network(CNN), Recurrent Neural Network(RNN), Feedforward Neural Network(FNN) 등과 같은 다양한 뉴럴 네트워크(neural network)들을 구동하기 위한 뉴럴 네트워크 장치로 이용 될 수 있고, 데이터 분류(classification) 또는 이미지 인식 (recognition)과 같은 분야에서 활용될 수 있다. 최근 뉴럴 네트워크 기술이 발전함에 따라, 다양한 종류의 전자 시스템에서 뉴럴 네트워크 장치를 사용하여 입 력 데이터를 분석하고 유효한 정보를 추출하는 연구가 활발히 진행되고 있다. 뉴럴 네트워크 장치는 복잡한 입력 데이터에 대한 많은 양의 연산을 필요로 한다. 뉴럴 네트워크 장치가 입력을 실시간으로 분석하고, 정보를 추출하기 위해서 뉴럴 네트워크 연산을 효율적으로 처리할 수 있는 기술이 요구된 다. 특히, 스마트폰과 같은, 저전력 고성능 임베디드 시스템은 제한된 리소스를 가지므로, 복잡한 입력 데이터 를 처리하는데 필요한 연산량을 감소시키면서도 정확도 손실을 최소화할 수 있는 기술이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2018-0129211호"}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템 및 그 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 실시예에 따른 인공지능 기술을 이용한 적층형 저항 변화 메모리 소 자의 계층 최적화 방법은, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하는 뉴럴 네트 워크 장치를 이용한 방법에 있어서, 상기 뉴럴 네트워크 장치가 BNN모델에서 BNN매개변수를 물리적 매개변수 및 하이퍼 매개변수로 분류하는 단계; 상기 뉴럴 네트워크 장치가 상기 물리적 매개변수 및 상기 하이퍼 매개변수 를 이용하여 최적의 파라미터를 획득하는 단계; 상기 뉴럴 네트워크 장치가 상기 최적의 파라미터를 이용하여 상기 BNN모델에서 최소채널크기를 산출하는 단계;를 포함할 수 있다.본 발명의 일 실시예에 있어서, 상기 물리적 매개변수는 컨볼루션 레이어(Convolutional Layer)의 수, 채널(필 터) 크기, 커널 크기, 배치 정규화(Batch Normalization) 유무 및 풀링 계층(Pooling Layer) 유무를 포함하고, 상기 하이퍼 매개변수는 최적화 기기(Optimizer), 학습률(learning rate) 및 모멘텀(Momentum)을 포함할 수 있 다. 본 발명의 일 실시예에 있어서, 상기 최적화 기기는 배치 경사 하강(Batch Gradient Descent) 알고리즘, 확률적 경사 하강(Stochastic Gradient Descent, SGD) 알고리즘, 경사 하강(Gradient Descent) 알고리즘, 미니 배치 경사 하강(Mini-Batch Gradient Descent) 알고리즘, 모멘텀(Momentum) 알고리즘, 아다그라드(Adagrad) 알고리 즘, 알엠에스프롭(RMSprop) 알고리즘 및 아담(Adam) 알고리즘 중 적어도 하나의 알고리즘을 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 최적의 파라미터를 획득하는 단계는, 상기 하이퍼 매개변수에 포함된 상기 최적화 기기의 알고리즘을 이용하여 최적알고리즘을 산출하는 단계; 상기 하이퍼 매개변수에 포함된 상기 학습 률을 이용하여 BNN에서 가중치 및 커널 업데이트의 강도를 조절하는 최적학습률을 산출하는 단계; 및 상기 하이 퍼 매개변수에 포함된 상기 모멘텀을 이용하여 BNN에서 운동량값을 고려하여 최적모멘텀을 산출하는 단계;를 포 함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 최적알고리즘을 산출하는 단계는, 상기 최적화 기기에 포함된 적어도 하나 의 알고리즘 사이의 최적의 알고리즘조합을 산출하는 단계; 및 상기 최적의 알고리즘조합의 비율을 산출하는 단 계;를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 최적알고리즘은, 커널 크기가 3 x 3인 경우 Adam 알고리즘과 SGD 알고리즘 의 비율이 3 : 7 이고, 커널 크기가 5 x 5인 경우 Adam 알고리즘과 SGD 알고리즘의 비율이 6 : 4일 수 있다. 본 발명의 일 실시예에 있어서, 커널 크기가 3 x 3 및 커널 크기가 5 x 5인 경우 동일한 최적학습률을 갖고, 상 기 최적학습률은 0.03 학습률을 가질 수 있다. 본 발명의 일 실시예에 있어서, 상기 최적모멘텀은, 커널 크기가 3 x 3인 경우 0.5 모멘텀의 값을 가지고, 커널 크기가 5 x 5인 경우 0.6 모멘텀의 가질 수 있다. 본 발명의 일 실시예에 있어서, 상기 최적의 파라미터를 획득하는 단계는, 상기 배치 정규화 및 상기 풀링 계층 의 존재유무를 판단하는 단계;를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 컨볼루션 레이어의 수가 4이고, 채널 크기가 9이고, 커널 크기가 3 x 3인 경우, 상기 배치 정규화는 상기 컨볼루션 레이어 각각에 포함될 수 있다. 본 발명의 일 실시예에 있어서, 상기 배치 정규화는 상기 컨볼루션 레이어 각각에 포함되지 않는 경우, 8%의 정 확도가 차이날 수 있다. 본 발명의 일 실시예에 있어서, 상기 배치 정규화는 에 의해 연산 수행될 수 있다. 본 발명의 일 실시예에 있어서, 컨볼루션 레이어의 수가 4이고, 채널 크기가 9이고, 커널 크기가 3 x 3인 경우, 상기 풀링 계층은 상기 컨볼루션 레이어 중 마지막 2개의 계층에 위치할 수 있다. 본 발명의 일 실시예에 있어서, 상기 최소채널크기를 산출하는 단계는, 상기 최소채널크기의 정확성을 판단하는 단계;를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 최소채널크기가 8인 경우, 커널 크기가 3 x 3인 일 때 정확도가 96% 이상 일 수 있다. 본 발명의 일 실시예에 있어서, 상기 최소채널크기를 산출하는 단계는, 상기 최소채널크기별로 계층별 에러율을 적용하여 상기 최소채널크기의 정확성을 판단하는 단계;를 더 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 최소채널크기가 8이고, 커널 크기가 3 x 3인 인 경우, 40nm 노드에서 정확 도가 94.069%이고, 20nm 노드에서 정확도가 93.777%이며, 10nm 노드에서 정확도가 93.07%일 수 있다.본 발명의 일 실시예에 있어서, 상기 뉴럴 네트워크 장치가 상기 최소채널크기를 이용하여 최소편차를 갖는 RRAM의 계층을 최적화하는 단계;를 포함할 수 있다. 또한, 상술한 과제를 해결하기 위한 본 발명의 다른 일실시예에 따른 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템은, 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화하 는 뉴럴 네트워크 방법을 뉴럴 네트워크 장치에 의해 수행할 수 있다. 본 발명의 일실시예에 따른 프로그램은 하드웨어인 컴퓨터와 결합되어, 상기 인공지능 기술을 이용한 적층형 저 항 변화 메모리 소자의 계층 최적화 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능 기술을 이용하여 최소편차를 갖는 적층형 저항 변화 메모리 소자의 계층 최적화할 수 있다. 즉, 3D 가중치 매트릭스 크기를 최소화함으로써, RRAM 시냅스를 사용하는 하드웨어 프로세서에서 더욱 효과적일 수 있다. 본 발명에 따르면, 드론(drone), 첨단 운전자 보조 시스템(Advanced Drivers Assistance System; ADAS) 등과 같은 로봇 장치, 스마트 TV, 스마트폰, 의료 디바이스, 모바일 디바이스, 영상 표시 디바이스, 계측 디바이스, IoT 디바이스 등에 적용될 수 있으며, 이 외에도 다양한 종류의 전자 디바이스들 중 적어도 하나에 탑재됨으로 써, 다양한 전자 디바이스에 적용되어 다양한 사용자에게 고품질의 서비스 제공이 가능하다."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 “포함한다 (comprises)” 및/또는 “포함하는(comprising)”은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, “및/또 는”은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 “제1”, “제2” 등이 다양한구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되 는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 발명의 일실시예에 따른 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스 템을 설명하기 위한 개념도이다. 도 1에 도시된 바와 같이, 본 발명의 일실시예인 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템은 뉴럴 네트워크 장치에 의해 BNN(Binary Neural Networks) 모델의 필터의 크기를 최소화 하기 위해 BNN 모델의 매개변수를 최적화할 수 있다. 본 발명의 일실시예에 따른 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스템의 동작은 다음과 같다. 도 2는 본 발명의 일실시예에 따른 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자 의 계층 최적화 방법을 설명하기 위한 도면이고, 도 3은 도 2에 도시된 최적의 파라미터를 획득하는 방법을 설 명하기 위한 도면이며, 도 4 및 도 5는 도 3에 도시된 최적의 알고리즘조합을 산출하는 방법을 설명하기 위한 도면이고, 도 6 및 도 7은 도 3에 도시된 최적학습률을 산출하는 방법을 설명하기 위한 도면이며, 도 8 및 도 9 는 도 3에 도시된 최적모멘텀을 산출하는 방법을 설명하기 위한 도면이고, 도 10 내지 도 12는 도 3에 도시된 배치 정규화 및 풀링 계층의 존재유무를 설명하기 위한 도면이며, 도 13 및 도 14는 도 2에 도시된 최소채널크 기를 산출하는 방법을 설명하기 위한 도면이고, 도 15 및 도 16은 도 2에 도시된 최소편차를 갖는 RRAM의 계층 을 최적화하는 방법을 설명하기 위한 도면이다. 본 실시예에서, 뉴럴 네트워크 장치는 CPU가 NVIDIA RTX 2080 Ti이고, CPU RAM이 11GB이며, CPU cores가 4532이고, 파이토치(pytorch)로 코딩된 조건에서 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계 층 최적화 방법을 수행하였지만, 이에 한정되지 않는다. 또한, 표 1을 참고하여 커널 크기(Kernel Size), 채널 크기(Channel Size) 및 컨볼루션 레이어(Convolutional Layer)에 대한 다양한 조건에서 100 epoch로 100회를 기초로 실시할 수 있지만, 이에 한정하지 않는다. 표 1 Kernel Size Convolutional Layer Channel Size 3 x 3 2 10 15 20 4 10 15 20 6 10 15 20 5 x 5 2 10 15 20 4 10 15 20 6 10 15 20 우선, 도 2에 도시된 바와 같이 뉴럴 네트워크 장치는 BNN모델에서 BNN매개변수를 물리적 매개변수 및 하이 퍼 매개변수로 분류할 수 있다(S10). 여기서, 물리적 매개변수는 컨볼루션 레이어(Convolutional layer)의 수, 채널(필터) 크기, 커널 크기, 배치 정 규화(Batch Normalization) 유무 및 풀링 계층(Pooling Layer) 유무를 포함할 수 있지만, 이에 한정하지 않는 다. 또한, 하이퍼 매개변수는 최적화 기기(Optimizer), 학습률(learning rate) 및 모멘텀(Momentum)을 포함할 수 있지만, 이에 한정하지 않고 은닉 유닛의 수, 미니배치 크기, 은닉층의 개수, 학습률 감쇠률(learning rate decay)을 포함할 수 있다. 다음으로, 뉴럴 네트워크 장치는 물리적 매개변수 및 상기 하이퍼 매개변수를 이용하여 최적의 파라미터를 획득할 수 있다(S12). 구체적으로, 도 3에 도시된 바와 같이, 뉴럴 네트워크 장치는 하이퍼 매개변수에 포함된 최적화 기기의 알 고리즘을 이용하여 최적알고리즘을 산출할 수 있다(S100). 여기서, 최적화 기기의 알고리즘은 오차를 구할 때 전체 데이터를 고려하는 배치 경사 하강(Batch Gradient Descent) 알고리즘과, 매개변수 값 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 확률적 경사 하강(Stochastic Gradient Descent, SGD) 알고리즘, 정해진 양에 대해서만 계산하여 매개 변수의 값을 조정하는 경사 하강(Gradient Descent) 알고리즘, 전체 데이터를 계산하는 것보다 빠르며, SGD보다 안정적인 미니 배치 경사 하강(Mini-Batch Gradient Descent) 알고리즘, 관성이라는 물리학의 법칙을 응용한 모 멘텀(Momentum) 알고리즘, 각 매개변수에 서로 다른 학습률을 적용한 아다그라드(Adagrad) 알고리즘, 아다그라 드 알고리즘의 학습률이 감소하는 단점을 개선한 알엠에스프롭(RMSprop), 알엠에스프롭과 모멘텀의 장점을 합친 아담(Adaptive Moment Estimation, Adam) 알고리즘을 포함할 수 있다. 본 실시예에서, 최적알고리즘을 산출하기 위해 뉴럴 네트워크 장치는 최적의 정확도가 낮지만, 모든 데이터 에 대해 가중치를 조절하는 것이 아니라 랜덤 추출데이터에 대해 가중치를 조절해서 속도가 개선되는 SGD 알고 리즘과, 알엠에스프롭 알고리즘과 모멘텀 알고리즘의 장점을 합친 아담 알고리즘을 이용하여 최적의 알고리즘조 합을 산출할 수 있다. 즉, 뉴럴 네트워크 장치는 커널 크기가 3 x 3인 경우 아담 알고리즘과 SGD 알고리즘 의 비율이 3 : 7 이고, 커널 크기가 5 x 5인 경우 아담 알고리즘과 SGD 알고리즘의 비율이 6 : 4 인 최적의 알 고리즘조합을 산출할 수 있다. 다시 말하면, 뉴럴 네트워크 장치는 아담 알고리즘과 SGD 알고리즘 사이의 최적의 비율을 산출할 수 있다. 아담 알고리즘이 높은 경우와 SGD 알고리즘이 높은 경우를 비교하여 가장 높은 정확도를 갖는 최적의 비율을 산 출할 수 있다. 예를 들어, 아담 알고리즘과 SGD 알고리즘의 비율이 1 : 9, 아담 알고리즘과 SGD 알고리즘의 비율이 2 : 8, 아 담 알고리즘과 SGD 알고리즘의 비율이 3 : 7, 아담 알고리즘과 SGD 알고리즘의 비율이 4 : 6, 아담 알고리즘과 SGD 알고리즘의 비율이 5 : 5, 아담 알고리즘과 SGD 알고리즘의 비율이 6 : 4, 아담 알고리즘과 SGD 알고리즘의 비율이 7 : 3, 아담 알고리즘과 SGD 알고리즘의 비율이 8 : 1 및 아담 알고리즘과 SGD 알고리즘의 비율이 9 : 1 인 조건에 대하여 반복 실시하여 최적의 비율인 커널 크기가 3 x 3인 경우 아담 알고리즘과 SGD 알고리즘의 비 율이 3 : 7 이고, 커널 크기가 5 x 5인 경우 아담 알고리즘과 SGD 알고리즘의 비율이 6 : 4 인 최적의 알고리즘 조합을 산출할 수 있다. 구체적으로, 도 4를 참조하면 커널 크기가 3 x 3인 경우, 컨볼루션 레이어 개수가 2인 경우 채널 크기(도 4(a) 참조)와 컨볼루션 레이어 개수가 4인 경우 채널 크기(도 4(b)참조)와, 컨볼루션 레이어 개수가 6인 경우 채널 크기(도 4(c)참조)의 변화에 따라 아담 알고리즘과 SGD 알고리즘의 비율이 3 : 7인 경우에 가장 정확도가 높은 것을 알 수 있다. 또한, 도 5를 참조하면 커널 크기가 5 x 5인 경우, 컨볼루션 레이어 개수가 2인 경우 채널 크기(도 5(a)참조)와 컨볼루션 레이어 개수가 4인 경우 채널 크기(도 5(b)참조)와, 컨볼루션 레이어 개수가 6인 경우 채널 크기(도 5(c)참조)의 변화에 따라 아담 알고리즘과 SGD 알고리즘의 비율이 3 : 7인 경우에 가장 정확도가 높은 것을 알 수 있다. 다음, 뉴럴 네트워크 장치는 하이퍼 매개변수에 포함된 학습률을 이용하여 BNN에서 가중치 및 커널 업데이 트의 강도를 조절하는 최적학습률을 산출할 수 있다(S110). 즉, 뉴럴 네트워크 장치는 커널 크기가 3 x 3 및 커널 크기가 5 x 5인 경우 동일한 0.03의 최적학습률을 산출할 수 있다.예를 들어, 뉴럴 네트워크 장치는 0.01에서 0.1까지 한번 학습할 때 얼만큼 학습해야 하는 것에 대한 의미 를 갖는 학습률을 비교 및 분석하여 99%의 정확도를 갖는 0.03의 최적학습률을 산출할 수 있다. 구체적으로, 도 6을 참조하면 커널 크기가 3 x 3인 경우, 컨볼루션 레이어 개수가 2인 경우 채널 크기(도 6(a) 참조)와 컨볼루션 레이어 개수가 4인 경우 채널 크기(도 6(b)참조)와, 컨볼루션 레이어 개수가 6인 경우 채널 크기(도 6(c)참조)의 변화에 따라 학습률이 0.03인 경우에 가장 정확도가 높은 것을 알 수 있다. 또한, 도 7을 참조하면 커널 크기가 5 x 5인 경우, 컨볼루션 레이어 개수가 2인 경우 채널 크기(도 7(a)참조)와 컨볼루션 레이어 개수가 4인 경우 채널 크기(도 7(b)참조)와, 컨볼루션 레이어 개수가 6인 경우 채널 크기(도 7(c)참조)의 변화에 따라 학습률이 0.03인 경우에 가장 정확도가 높은 것을 알 수 있다. 다음, 뉴럴 네트워크 장치는 하이퍼 매개변수에 포함된 모멘텀을 이용하여 BNN에서 운동량값을 고려하여 최 적모멘텀을 산출할 수 있다(S120). 즉, 뉴럴 네트워크 장치는 커널 크기가 3 x 3인 경우 모멘텀이 0.5이고, 커널 크기가 5 x 5인 경우 모멘텀이 0.6인 최적모멘텀을 산출할 수 있다. 예를 들어, 뉴럴 네트워크 장치는 훈련시간을 줄이 위해 최적의 운동량값을 산출하기 위해 0.1에서 1.0까지 각각 다른 운동량 값을 고려하여 커널 크기가 3 x 3인 경우 모멘텀이 0.5이고, 커널 크기가 5 x 5인 경우 모멘 텀이 0.6인 최적모멘텀을 산출할 수 있다. 구체적으로, 도 8을 참조하면 커널 크기가 3 x 3인 경우, 컨볼루션 레이어 개수가 2인 경우 채널 크기(도 8(a) 참조)와 컨볼루션 레이어 개수가 4인 경우 채널 크기(도 8(b)참조)와, 컨볼루션 레이어 개수가 6인 경우 채널 크기(도 8(c)참조)의 변화에 따라 모멘텀이 0.5인 경우에 가장 정확도가 높은 것을 알 수 있다. 또한, 도 9를 참조하면 커널 크기가 5 x 5인 경우, 컨볼루션 레이어 개수가 2인 경우 채널 크기(도 9(a)참조)와 컨볼루션 레이어 개수가 4인 경우 채널 크기(도 9(b)참조)와, 컨볼루션 레이어 개수가 6인 경우 채널 크기(도 9(c)참조)의 변화에 따라 모멘텀이 0.6인 경우에 가장 정확도가 높은 것을 알 수 있다. 다음, 뉴럴 네트워크 장치는 배치 정규화의 존재유무를 판단할 수 있다(S130). 즉, 뉴럴 네트워크 장치(1 0)는 컨볼루션 레이어에 배치 정규화가 필요한지 여부를 판단할 수 있다. 예를 들어, 도 10을 참조하면 컨볼루션 레이어의 수가 4이고, 채널 크기가 9이고, 커널 크기가 3 x 3인 경우, 컨볼루션 레이어 각각에 배치 정규화가 필요할 수 있다. 여기서, 배치 정규화는 다음의 수학식 1에 의해 연산될 수 있다. 스칼라값을 가지는 요소들을 독립적으로 정규 화를 위해 n차원의 입력x = {x, x, …x(n)}에 대해 수학식 1을 이용하여 연산할 수 있다. 수학식 1"}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, 컨볼루션 레이어 각각에 배치 정규화가 포함되지 않는 경우, 도 11을 참조하면 8%의 정확도가 차이날 수 있지만, 이에 한정하지 않는다. 다음, 뉴럴 네트워크 장치는 풀링 계층의 존재유무를 판단할 수 있다(S140). 즉, 뉴럴 네트워크 장치는 컨볼루션 레이어에 풀링 계층이 존재하는지 유부를 판단할 수 있다. 예를 들어, 도 10을 참조하면 컨볼루션 레이어의 수가 4이고, 채널 크기가 9이고, 커널 크기가 3 x 3인 경우, 풀링 계층은 컨볼루션 레이어 중 마지막 2개의 계층에 위치할 수 있다. 다시 말하면, 풀링 계층은 컨볼루션 레이어 중 마지막 2개의 계층에 위치하는 경우, 도 12를 참조하면 가장 높 은 정확도를 가지는 것을 알 수 있다. 한편, 배치 정규화의 존재유무를 판단하는 S130 단계는 풀링 계층의 존재유무를 판단하는 S140 단계 이후에 수 행될 수 있지만, 이에 한정하지 않고 동시에 수행될 수 있다.다음으로, 뉴럴 네트워크 장치는 최적의 파라미터를 이용하여 BNN모델에서 최소채널크기를 산출할 수 있다 (S30). 즉, 뉴럴 네트워크 장치는 최소채널크기의 정확성을 판단하여 그에 대응하는 최소채널크기를 산출할 수 있다. 예를 들어, 뉴럴 네트워크 장치는 채널 크기는 9에서 시작하여 하나씩 낮춰가면서 산출할 수 있다. 이때, 채널 크기는 컨볼루션 레이어의 개수와 상관없을 수 있다. 구체적으로, 도 13을 참조하면, 최소채널크기가 8인 경우, 커널 크기가 3 x 3인 일 때 정확도가 96% 이상인 것 을 알 수 있다. 즉, BNN모델에서 정확도를 유지하거나 높이면서 적층형 저항 변화 메모리 소자의 계층을 최소화 할 수 있다. 또한, 뉴럴 네트워크 장치는 최소채널크기별로 계층별 에러율을 적용하여 최소채널크기의 정확성을 판단할 수 있다. 예를 들어, 도 14를 참조하면 최소채널크기가 8이고, 커널 크기가 3 x 3인 인 경우, 40nm 노드에서 정확도가 94.069%이고, 20nm 노드에서 정확도가 93.777%이며, 10nm 노드에서 정확도가 93.07%일 수 있다. 마지막으로, 뉴럴 네트워크 장치는 최소채널크기를 이용하여 최소편차를 갖는 RRAM의 계층을 최적화할 수 있다(S40) 도 15를 참조하면, 뉴럴 네트워크 장치는 50의 채널 크기를 정확유를 유지하면서 80%이상 감소시켜 채널 크 기를 8로 최적화할 수 있다. 이와 같은 뉴럴 네트워크 장치는 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 방 법을 수행하기 위한 각종 휴대 가능한 전자통신기기를 포함할 수 있다. 예를 들어, 별도의 스마트 기기로써, 스 마트폰(Smart phone), PDA(Personal Digital Assistant), 테블릿(Tablet), 웨어러블 디바이스(Wearable Device, 예를 들어, 워치형 단말기(Smartwatch), 글래스형 단말기(Smart Glass), HMD(Head Mounted Display)등 포함) 및 각종 IoT(Internet of Things) 단말과 같은 다양한 단말을 포함할 수 있지만 이에 한정하는 것은 아니 다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상 주할 수도 있다."}
{"patent_id": "10-2020-0163675", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2020-0163675", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 시스 템을 설명하기 위한 개념도이다. 도 2는 본 발명의 일실시예에 따른 인공지능 기술을 이용한 적층형 저항 변화 메모리 소자의 계층 최적화 방법 을 설명하기 위한 도면이다. 도 3은 도 2에 도시된 최적의 파라미터를 획득하는 방법을 설명하기 위한 도면이다. 도 4 및 도 5는 도 3에 도시된 최적의 알고리즘조합을 산출하는 방법을 설명하기 위한 도면이다. 도 6 및 도 7은 도 3에 도시된 최적학습률을 산출하는 방법을 설명하기 위한 도면이다. 도 8 및 도 9는 도 3에 도시된 최적모멘텀을 산출하는 방법을 설명하기 위한 도면이다. 도 10 내지 도 12는 도 3에 도시된 배치 정규화 및 풀링 계층의 존재유무를 설명하기 위한 도면이다. 도 13 및 도 14는 도 2에 도시된 최소채널크기를 산출하는 방법을 설명하기 위한 도면이다. 도 15 및 도 16은 도 2에 도시된 최소편차를 갖는 RRAM의 계층을 최적화하는 방법을 설명하기 위한 도면이다."}
