{"patent_id": "10-2021-0019366", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0047498", "출원번호": "10-2021-0019366", "발명의 명칭": "온-디바이스", "출원인": "삼성전자주식회사", "발명자": "시안 지안웨이"}}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 트랜시버(transceiver);적어도 하나의 메모리; 및상기 적어도 하나의 트랜시버 및 상기 적어도 하나의 메모리와 결합된 적어도 하나의 프로세서에 있어서, 상기 적어도 하나의 프로세서는: 상기 적어도 하나의 트랜시버를 통해, 상기 적어도 하나의 프로세서에 의해 동작되는 신뢰 실행 환경(trustedexecution environment: TEE)에서 인공지능(artificial intelligence: AI) 모델을 수신하고; 상기 TEE에서, 상기 TEE 외부의 소스(source)로부터 추론 요청 및 입력 데이터를 수신하고; 상기 TEE 내의 프로세서 자원들(processor resources)에 의해 수행되는 내부 계산(internal calculation)과상기 TEE 외부의 프로세서 자원들에 의해 수행되는 외부 계산(external calculation) 간에 추론 결과 계산을 분할하며(partition); 상기 내부 계산 및 상기 외부 계산의 결과들에 기초하여, 상기 추론 결과를 산출하도록 구성된, 적어도 하나의프로세서를 포함하는, 전자 장치."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 추론 결과의 상기 계산을 분할하기 위해, 상기 적어도 하나의 프로세서는:상기 추론 결과의 상기 계산에 대한 계산 작업부하(computation workload)를 결정하고;상기 계산 작업부하의 계산-과중 부분(computation-heavy portion)을 상기 TEE 외부의 상기 프로세서 자원들에의해 수행되는 상기 외부 계산의 적어도 일부로서 할당하도록 구성된, 전자 장치."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 추론 결과의 상기 계산을 분할하기 위해, 상기 적어도 하나의 프로세서는,상기 TEE 외부의 상기 프로세서 자원들에 할당된, 상기 계산 작업부하의 상기 계산-과중 부분에 제공되는 데이터를 상기 TEE 내의 상기 프로세서 자원들에 의해 수행되는 상기 내부 계산의 적어도 일부로서 난독화하도록(obfuscate) 구성된, 전자 장치."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 데이터를 난독화하기 위해, 상기 적어도 하나의 프로세서는,상기 AI 모델의 가중치 행렬(weight matrix)을 적어도 두 개의 행렬들로 분할하도록(split) 구성된, 전자 장치."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 데이터를 난독화하기 위해, 상기 적어도 하나의 프로세서는,상기 AI 모델의 가중치 행렬의 하나 이상의 파라미터들을 랜덤하게(randomly) 섭동하도록(perturb) 구성된, 전자 장치."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 계산 작업부하의 상기 계산-과중 부분은 컨볼루션(convolution)을 포함하는, 전자 장치."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2022-0047498-3-제1항에 있어서, 상기 적어도 하나의 프로세서는, 상기 TEE 내의 상기 프로세서 자원들을 이용하여, 상기 추론요청을 수신하기 전에 상기 내부 계산의 적어도 일부를 수행하도록 더 구성된, 전자 장치."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "적어도 하나의 트랜시버, 적어도 하나의 메모리, 및 적어도 하나의 프로세서를 포함하는 전자 장치에서 인공지능(AI) 모델 보호 방법에 있어서,상기 적어도 하나의 트랜시버를 통해, 상기 적어도 하나의 프로세서에 의해 동작되는 신뢰 실행 환경(TEE)에서AI 모델을 수신하는 단계;상기 TEE에서, 상기 TEE 외부의 소스로부터 추론 요청 및 입력 데이터를 수신하는 단계;상기 적어도 하나의 프로세서에 의해, 상기 TEE 내의 프로세서 자원들에 의해 수행되는 내부 계산과 상기 TEE외부의 프로세서 자원들에 의해 수행되는 외부 계산 간에 추론 결과 계산을 분할하는(partitioning) 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 내부 계산 및 상기 외부 계산의 결과들에 기초하여, 상기 추론 결과를 산출하는 단계를 포함하는, AI 모델 보호 방법."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 추론 결과의 상기 계산을 분할하는 단계는:상기 추론 결과의 상기 계산에 대한 계산 작업부하를 결정하는 단계; 및상기 계산 작업부하의 계산-과중 부분을 상기 TEE 외부의 상기 프로세서 자원들에 의해 수행되는 상기 외부 계산의 적어도 일부로서 할당하는 단계를 포함하는, AI 모델 보호 방법."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 추론 결과의 상기 계산을 분할하는 단계는, 상기 TEE 외부의 상기 프로세서 자원들에 할당된, 상기 계산 작업부하의 상기 계산-과중 부분에 제공되는 데이터를 상기 TEE 내의 상기 프로세서 자원들에의해 수행되는 상기 내부 계산의 적어도 일부로서 난독화하는(obfuscating) 단계를 포함하는, AI 모델 보호 방법."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 데이터를 난독화하는 단계는 상기 AI 모델의 가중치 행렬을 적어도 두 개의 행렬들로 분할하는(splitting) 단계를 포함하는, AI 모델 보호 방법."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 데이터를 난독화하는 단계는 상기 AI 모델의 가중치 행렬의 하나 이상의 파라미터들을랜덤하게 섭동하는(perturbing) 단계를 포함하는, AI 모델 보호 방법."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 계산 작업부하의 상기 계산-과중 부분은 컨볼루션(convolution)을 포함하는, AI 모델 보호 방법."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 TEE 내의 상기 프로세서 자원들을 이용하여, 상기 추론 요청을 수신하기 전에 상기 내부 계산의 적어도 일부를 수행하는 단계를 더 포함하는, AI 모델 보호 방법."}
{"patent_id": "10-2021-0019366", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제8항 내지 제14항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체.공개특허 10-2022-0047498-4-"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치는 적어도 하나의 트랜시버, 적어도 하나의 메모리, 및 적어도 하나의 트랜시버 및 적어도 하나의 메모 리와 결합된 적어도 하나의 프로세서를 포함한다. 적어도 하나의 프로세서는, 적어도 하나의 트랜시버를 통해, 신뢰 실행 환경(trusted execution environment: TEE)에서 AI 모델을 수신하도록 구성된다. 적어도 하나의 프로 세서는 또한 TEE 외부의 소스로부터 추론 요청 및 입력 데이터를 수신하도록 구성된다. 적어도 하나의 프로세서 는 추론 결과의 계산을 TEE 내의 프로세서 자원들에 의해 수행되는 내부 계산과 TEE 외부의 프로세서 자원들에 의해 수행되는 외부 계산 간에 분할하도록 더 구성된다. 또한, 적어도 하나의 프로세서는 내부 계산 및 외부 계 산의 결과들에 기초하여 추론 결과를 산출하도록 구성된다."}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 기계학습 시스템에 관한 것이다. 보다 구체적으로, 본 개시는 온-디바이스(on-device) 인 공지능(artificial intelligence: AI) 모델 파라미터 런타임(run-time) 보호를 위한 방법 및 시스템에 관한 것 이다."}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사용자 데이터 수집 및 통신 비용을 피하기 위해 서비스 제공업체들이 사용자 장치들 상에서 로컬하게 인공지능 (artificial intelligence: AI) 모델들을 실행하는 것이 점점 더 보편화되고 있다. 그러나, AI 모델들은 소중한 자산이며, AI 모델들을 직접 공개(releasing)하면 AI 모델들을 복제 및 무단 사용의 위험에 노출시키게 된다. 또한, 모델 파라미터들은 AI 모델들을 트레이닝하는 데 이용되는 트레이닝 데이터에 관한 숨겨진 정보를 포함하 고, 따라서 모델 파라미터들을 공개하면 프라이버시 위험이 발생할 수 있다."}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 온-디바이스(on-device) 인공지능(artificial intelligence: AI) 모델 파라미터 런타임(run-time) 보호를 위한 방법 및 시스템을 제공한다."}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1 실시예에서, 전자 장치는 적어도 하나의 트랜시버(transceiver), 적어도 하나의 메모리, 및 상기 적어도 하 나의 트랜시버 및 상기 적어도 하나의 메모리와 결합된 적어도 하나의 프로세서를 포함한다. 상기 적어도 하나 의 프로세서는, 상기 적어도 하나의 트랜시버를 통해, 신뢰 실행 환경(trusted execution environment: TEE)에 서 AI 모델을 수신하도록 구성된다. 상기 적어도 하나의 프로세서는 또한 상기 TEE 외부의 소스로부터 추론 요 청(inference request) 및 입력 데이터를 수신하도록 구성된다. 상기 적어도 하나의 프로세서는 추론 결과의 계 산을 상기 TEE 내부의 프로세서 자원들(processor resources)에 의해 수행되는 내부 계산(internal calculation)과 상기 TEE 외부의 프로세서 자원들에 의해 수행되는 외부 계산(external calculation) 간에 분 할하도록(partition) 더 구성된다. 또한, 상기 적어도 하나의 프로세서는, 상기 내부 계산 및 상기 외부 계산의 결과들에 기초하여, 상기 추론 결과를 산출하도록 구성된다. 제2 실시예에서, AI 모델 보호 방법은 TEE에서 AI 모델을 수신하는 단계를 포함한다. 상기 방법은 또한 상기 TEE 외부의 소스로부터 추론 요청 및 입력 데이터를 수신하는 단계를 포함한다. 상기 방법은 추론 결과의 계산 을 상기 TEE 내부의 프로세서 자원들에 의해 수행되는 내부 계산과 상기 TEE 외부의 프로세서 자원들에 의해 수 행되는 외부 계산 간에 분할하는(partitioning) 단계를 더 포함한다. 또한, 상기 방법은, 상기 내부 계산 및 상 기 외부 계산의 결과들에 기초하여, 상기 추론 결과를 산출하는 단계를 포함한다. 제3 실시예에서, 비일시적 컴퓨터 판독가능 매체는 컴퓨터 프로그램을 구현한다. 상기 컴퓨터 프로그램은, 실행 되는 경우, 전자 장치의 적어도 하나의 프로세서로 하여금, 적어도 하나의 트랜시버를 통해, TEE에서 AI 모델을 수신하도록 하는 명령어들(instructions)을 포함한다. 상기 컴퓨터 프로그램은 또한, 실행되는 경우, 상기 적어 도 하나의 프로세서로 하여금 상기 TEE 외부의 소스로부터 추론 요청 및 입력 데이터를 수신하도록 하는 명령어 들을 포함한다. 상기 컴퓨터 프로그램은, 실행되는 경우, 상기 적어도 하나의 프로세서로 하여금 추론 결과의 계산을 상기 TEE 내부의 프로세서 자원들에 의해 수행되는 내부 계산과 상기 TEE 외부의 프로세서 자원들에 의 해 수행되는 외부 계산 간에 분할하도록(partition) 하는 명령어들을 더 포함한다. 또한, 상기 컴퓨터 프로그램 은, 실행되는 경우, 상기 적어도 하나의 프로세서로 하여금 상기 내부 계산 및 상기 외부 계산의 결과들에 기초 하여, 상기 추론 결과를 산출하도록 하는 명령어들을 포함한다."}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "기타 기술적 특징들은 이하의 특징들, 설명들, 및 청구항들로부터 본 개시가 속하는 기술분야의 숙련된 자에 의 해 쉽게 명확해질 수 있다. 하기 상세한 설명에 착수하기 전에, 본 특허 문서 전체에 걸쳐 사용되는 특정 단어들 및 문구들의 정의를 설명 하는 것이 바람직하다. \"전송하다(transmit)\", \"수신하다(receive)\", 및 \"통신하다(communicate)\"라는 용어들뿐 아니라 그 파생어들은 직접 및 간접 통신 모두를 포괄한다. \"포함하다(include)\" 및 \"구비한다(comprise)\"라 는 용어들 및 그 파생어들은 제한 없는 포함을 의미한다. \"또는(or)\"이라는 용어는 \"및/또는(and/or)\"을 의미하 는 포괄적인 용어이다. \"~와 연관된(associated with)\"이라는 문구 및 그 파생문구들은 포함하다(include), ~내 에 포함되다(be included within), ~와 상호연결되다(interconnect with), 함유하다(contain), ~내에 함유되다 (be contained within), ~에 또는 ~와 연결하다(connect to or with), ~에 또는 ~와 결합하다(couple to or with), ~와 통신가능하다(be communicable with), ~와 협력하다(cooperate with), 인터리빙하다(interleave), 병치하다(juxtapose), ~에 근접하다(be proximate to), ~에 또는 ~와 결속되다(be bound to or with), 가지다 (have), ~의 특성을 가지다(have a property of), ~에 또는 ~와 관계성을 가지다(have a relationship to or with) 등을 의미한다. 또한, 하기 설명되는 다양한 기능들(functions)은 하나 이상의 컴퓨터 프로그램들에 의해 구현되거나 또는 지원 될 수 있으며, 상기 하나 이상의 컴퓨터 프로그램들 각각은 컴퓨터 판독가능 프로그램 코드로 구성되고 컴퓨터 판독가능 매체에서 구현된다. \"애플리케이션(application)\" 및 \"프로그램(program)\"이라는 용어들은 하나 이상 의 컴퓨터 프로그램들, 소프트웨어 구성요소들, 명령어들(instructions)의 세트들, 프로시저들(procedures), 기 능들(functions), 객체들(objects), 클래스들(classes), 인스턴스들(instances), 관련 데이터, 또는 적절한 컴 퓨터 판독가능 프로그램 코드의 구현에 적합한(adapted) 이들의 일부를 의미한다. \"컴퓨터 판독가능 프로그램 코드\"라는 문구는, 소스 코드(source code), 객체 코드(object code), 및 실행가능 코드(executable code)를 포함하는 모든 유형의 컴퓨터 코드를 포함한다. \"컴퓨터 판독가능 매체\"라는 문구는, 읽기 전용 메모리(read only memory: ROM), 랜덤 액세스 메모리(random access memory: RAM), 하드 디스크 드라이브, 컴팩트 디스크 (compact disc: CD), 디지털 비디오 디스크(digital video disc: DVD), 또는 다른 어떤 유형의 메모리와 같이, 컴퓨터에 의해 액세스될 수 있는 어떠한 유형의 매체라도 포함한다. \"비일시적(non-transitory)\" 컴퓨터 판독가 능 매체는 일시적인 전기적 또는 기타 신호들을 전송하는 유선, 무선, 광학적, 또는 기타 통신 링크들을 제외한 다. 비일시적 컴퓨터 판독가능 매체는 데이터가 영구적으로 저장될 수 있는 매체들 및, 다시쓰기가능 (rewritable) 광디스크 또는 소거가능(erasable) 메모리 장치와 같이, 데이터가 저장되고 추후에 덮어 쓰일 (overwritten) 수 있는 매체들을 포함한다. 본 명세서에서, 특징(feature)(번호(number), 기능(function), 동작(operation), 또는 부품(part)과 같은 구성 요소(component)와 같은 것)을 \"가진다(have)\", \"가질 수 있다(may have)\", \"포함한다(include)\", 또는 \"포함 할 수 있다(may include)\"와 같은 용어들 및 문구들은 상기 특징의 존재를 나타내며 다른 특징들의 존재를 배제 하지 않는다. 또한, 본 명세서에서, \"A 또는 B(A or B)\", \"A 및/또는 B 중 적어도 하나(at least one of A and/or B)\", 또는 \"A 및/또는 B 중 하나 이상(one or more of A and/or B)\"이라는 문구들은 A와 B의 모든 가능 한 조합들을 포함할 수 있다. 예를 들면, \"A 또는 B\", \"A 및 B 중 적어도 하나\", 및 \"A 또는 B 중 적어도 하 나\"는 적어도 하나의 A(at least one A)를 포함하는 것, 적어도 하나의 B(at least one B)를 포함하는 것, 또는 적어도 하나의 A 및 적어도 하나의 B를 포함하는 것을 모두 나타낼 수 있다. 또한, 본 명세서에서, \"제1(first)\" 및 \"제2(second)\"라는 용어들은 중요도와 상관 없이 다양한 구성요소들을 수식할 수 있으며 상기 구성요소들을 제한하지 않는다. 이러한 용어들은 단지 하나의 구성요소를 다른 것과 구별하기 위해 사용된다. 예를 들면, 제1 사용자 장치 및 제2 사용자 장치는, 상기 장치들의 순서 또는 중요도와 상관 없이, 서로 다른 사용자 장치들을 나타낼 수 있다. 본 개시의 범위를 벗어나지 않고, 제1 구성요소가 제2 구성요소로 표기될 수 있고 그 반대도 마찬가지이다. 어떤 구성요소(예를 들면, 제1 구성요소)가 다른 구성요소(예를 들면, 제2 구성요소)와 (작동 가능하게 (operatively) 또는 통신 가능하게(communicatively)) \"결합(coupled with/to)\" 또는 \"연결(connected with/to)\"된다고 언급될 때, 상기 구성요소는 상기 다른 구성요소와 직접 또는 제3 구성요소를 통해 결합 또는 연결될 수 있음을 이해할 수 있을 것이다. 반면에, 어떤 구성요소(예를 들면, 제1 구성요소)가 다른 구성요소 (예를 들면, 제2 구성요소)와 \"직접 결합(directly coupled with/to)\" 또는 \"직접 연결(directly connected with/to)\"된다고 언급될 때, 상기 구성요소와 상기 다른 구성요소 사이에 다른 구성요소(예를 들면, 제3 구성요 소)가 개재되지 않음을 이해할 수 있을 것이다. 본 명세서에서, \"~하도록 구성된(또는 설정된)(configured (or set) to)\"이라는 문구는, 상황에 따라, \"~에 적 합한(suitable for)\", \"~할 능력이 있는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도록 적합화된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~할 수 있는(capable of)\"이라는 문구들과 상호 교환적으로 사용될 수 있다. \"~하도록 구성된(또는 설정된)\"이라는 문구가 본질적으로 \"~하도록 하드웨어적으로 특별히 설계된(specifically designed in hardware to)\"이라는 의미를 나타내는 것은 아니다.오히려, \"~하도록구성된\"이라는 문구는 장치가 다른 장치 또는 부품들과 함께 동작을 수행할 수 있음을 의미할 수 있다. 예를 들 면, \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"라는 문구는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써 상기 동작들을 수행할 수 있는 범용(generic-purpose) 프로세서(예를 들 면, CPU 또는 애플리케이션 프로세서), 또는 상기 동작들을 수행하기 위한 전용(dedicated) 프로세서(예를 들면, 내장형(embedded) 프로세서)를 의미할 수 있다. 본 명세서에서 사용된 용어들 및 문구들은 단지 본 개시의 일부 실시예들을 설명하기 위해 제공되는 것이지 본 개시의 다른 실시예들의 범위를 제한하고자 제공되는 것이 아니다. 문맥상 명확히 달리 언급되지 않는 한 \"a\", \"an\", 및 \"the\"라는 단수 형태들은 복수 형태의 언급을 포함한다는 것을 이해해야 할 것이다. 본 명세서에서 사 용되는, 기술적 및 과학적 용어들 및 문구들을 포함하는, 모든 용어들 및 문구들은 본 개시의 실시예들이 속하"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "는 기술분야의 통상의 지식을 가진 자에 의해 통상적으로 이해되는 바와 동일한 의미들을 가진다. 통상적으로"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "사용되는 사전들에서 정의된 바와 같은, 용어들 및 문구들은 관련 기술분야의 맥락에서 그 의미와 일치하는 의 미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명시적으로 정의되지 않는 한 이상적이거나 지나치게 형식적 인 의미로 해석되어서는 안 된다는 것을 또한 이해할 것이다. 경우에 따라서, 본 명세서에 정의된 용어들 및 문 구들은 본 개시의 실시예들을 배제하는 것으로 해석될 수 있다. 본 개시의 실시예들에 따른 \"전자 장치\"의 예들은 스마트폰, 태블릿 개인용 컴퓨터(personal computer: PC), 휴 대 전화(mobile phone), 비디오폰, 전자책 단말기(e-book reader), 데스크탑(desktop) PC, 랩탑(laptop) 컴퓨 터, 노트북 컴퓨터, 워크스테이션, 개인 휴대 정보 단말기(personal digital assistant: PDA), 휴대용 멀티미 디어 플레이어(portable multimedia player: PMP), MP3 플레이어, 모바일 의료 장치, 카메라, 또는 웨어러블 장치(예를 들면, 스마트 안경, 머리 착용형 장치(head-mounted device: HMD), 전자 의류(electronic clothes), 전자 팔찌, 전자 목걸이, 전자 액세서리, 전자 문신, 스마트 거울, 또는 스마트 워치(smart watch)) 중 적어도 하나를 포함할 수 있다. 전자 장치의 다른 예들은 스마트 가전제품을 포함한다. 상기 스마트 가전제품의 예들은 텔레비전, 디지털 비디오 디스크(digital video disc: DVD) 플레이어, 오디오 플레이어, 냉장고, 에어컨, 청소 기, 오븐, 전자레인지, 세탁기, 드라이기, 공기 청정기, 셋탑 박스(set-top box), 가정 자동화 제어 패널(home automation control panel), 보안 제어 패널, TV 박스(예를 들면, 삼성 홈싱크(SAMSUNG HOMESYNC), 애플 TV(APPLETV), 또는 구글 TV(GOOGLE TV)), 스마트 스피커 또는 통합 디지털 어시스턴트(integrated digital assistant)(예를 들면, 삼성 갤럭시 홈(SAMSUNG GALAXY HOME), 애플 홈팟(APPLE HOMEPOD), 또는 아마존 에코 (AMAZON ECHO))를 갖춘 스피커, 게임 콘솔(예를 들면, 엑스박스(XBOX), 플레이스테이션(PLAYSTATION), 또는 닌 텐도(NINTENDO)), 전자 사전, 전자 키(key), 캠코더(camcorder), 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 전자 장치의 또 다른 예들은 다양한 의료 장치들(예를 들면, 다양한 휴대용 의료 측정 장치들(혈당 측정 장치, 심박 측정 장치, 또는 체온 측정 장치와 같은 것), 자기공명 혈관조영(magnetic resonance angiography: MRA) 장치, 자기공명 영상(magnetic resonance imaging: MRI) 장치, 컴퓨터 단층촬영(computed tomography: CT) 장치, 영상화 장치, 또는 초음파 장치), 네비게이션 장치, 범지구 위치확인 시스템(global positioning system: GPS) 수신기, 사고 데이터 기록장치(event data recorder: EDR), 비행 데이터 기록장치(flight data recorder: FDR), 자동차 인포테인먼트(infotainment) 장치, 항해(sailing) 전자 장치(예를 들면, 항해 네비게 이션 장치 또는 자이로컴퍼스(gyro compass)), 항공전자기기(avionics), 보안 장치들, 차량용 헤드 유닛들 (vehicular head units), 산업용 또는 가정용 로봇들, 자동 현금 입출금기들(automatic teller machines: ATMs), 판매시점 관리(point of sales: POS) 장치들, 또는 사물인터넷(Internet of Things: IoT) 장치들(예를 들면, 전구, 다양한 센서들, 전기 또는 가스 계량기, 스프링클러(sprinkler), 화재 경보기(fire alarm), 온도 조절장치(thermostat), 가로등, 토스터(toaster), 피트니스 장비, 온수 탱크, 히터(heater), 또는 보일러) 중 적어도 하나를 포함한다. 전자 장치의 다른 예들은 가구 또는 건물/구조물(building/structure)의 적어도 일부, 전자 보드(electronic board), 전자 서명(electronic signature) 수신 장치, 프로젝터(projector), 또는 다양 한 측정 장치들(예를 들면, 물, 전기, 가스, 또는 전자파 측정 장치들)을 포함한다. 본 개시의 다양한 실시예들 에 따르면, 전자 장치는 상기 열거된 장치들 중 하나 또는 이들의 조합일 수 있다는 것에 유의해야 한다. 본 개 시의 일부 실시예들에 따르면, 상기 전자 장치는 플렉서블(flexible) 전자 장치일 수 있다. 본 명세서에 개시된 상기 전자 장치는 상기 열거된 장치들에 제한되지 않으며 기술 발전에 따라 새로운 전자 장치들을 포함할 수 있 다. 하기 설명에서, 전자 장치들은, 본 개시의 다양한 실시예들에 따라, 첨부된 도면을 참조하여 설명된다. 본 명세 서에서, \"사용자(user)\"라는 용어는 상기 전자 장치를 사용하는 인간 또는 다른 장치(예를 들면, 인공지능 (artificial intelligent) 전자 장치)를 나타낼 수 있다.기타 특정 단어들 및 문구들에 대한 정의들은 본 특허 문서 전체에 걸쳐 제공될 수 있다. 본 개시가 속하는 기 술분야의 통상의 지식을 가진 자는, 대부분은 아닐지라도 많은 경우, 그러한 정의들이 그와 같이 정의된 단어들 및 문구들의 선행(prior) 사용뿐만 아니라 향후(future) 사용에도 적용됨을 이해해야 할 것이다. 본 출원에서의 어떤 설명도 어떤 특정 요소, 단계, 또는 기능이 청구 범위(claim scope)에 포함되어야 하는 필 수 요소임을 암시하는 것으로 해석되어서는 안 된다. 특허 대상(patented subject matter)의 범위는 오직 청구 항들에 의해서만 정의된다."}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "하기에서 논의되는 도 1 내지 도 13e 및 본 개시의 다양한 실시예들은 첨부된 도면을 참조하여 설명된다. 그러 나, 본 개시는 이러한 실시예들에 제한되지 않으며 이들에 대한 모든 변경 및/또는 균등물 또는 치환물들도 또 한 본 개시의 범위에 속함을 이해해야 할 것이다. 온-디바이스(on-device) 인공지능(artificial intelligence: AI) 추론을 수행함으로써, 문자(texting) 또는 검 색(searching) 서비스를 위한 자연어 인식(natural language recognition), 사용자 장치들을 이용하여 촬영된 이미지들을 위한 이미지 인식 서비스, 또는 기타 AI 서비스들을 제공하는 것과 같이, 편리하고 효율적인 AI 서 비스들이 상기 사용자 장치들 상에서 수행될 수 있다. 온-디바이스 AI 추론을 제공하기 위해, 모델 소유자 (model owner)는 장치에 설치된 AI 서비스를 통해 상기 장치상에 모델을 배포할(deploy) 수 있다. 상기 장치 상 에 설치된 애플리케이션과 같은, 클라이언트(client)는 상기 AI 서비스에, 상기 장치에 의해 캡처된 이미지에 대해 이미지 인식을 수행하라는 요청과 같은 추론을 요청할 수 있다. 상기 AI 서비스는 상기 모델 및 상기 추론 요청에 대한 입력 데이터를 계산용 가속기(accelerator)에 제공할 수 있다. 상기 AI 서비스는 상기 가속기로부 터 계산의 결과를 수신하여 추론 결과를 상기 클라이언트에 제공하며, 상기 클라이언트는 상기 추론 결과를 사용자에게 표시할 수 있다. 그러한 온-디바이스 AI 추론은 AI 추론을 수행하기 위해 사용자 장치들을 편리하고 효율적으로 이용할 수 있게 하지만, AI 모델이, 컴퓨터, 모바일 장치, 또는 사물인터넷(Internet of Things: IoT) 장치와 같은, 어떤 엔드 포인트(end point) 상에서 실행 중인 경우, 악성 사용자 또는 애플리케이션과 같 은, 해커가 모델 파라미터들과 같은 모델 정보를 도용할 수 있다. 본 개시는 온-디바이스 AI 모델 파라미터 런타임(run-time) 보호를 위한 시스템 및 방법을 제공한다. 상기 시스 템 및 방법은 전자 장치의 신뢰 실행 환경(trusted execution environment: TEE) 내에서 AI 추론들의 하나 이 상의 부분들의 실행 및, 모델 파라미터들 또는 AI 모델의 계층들로부터의 중간 입력들 또는 출력들과 같은, 상 기 AI 모델의 특정 측면들(aspects)을 검출(detection)로부터 난독화 및 보호하는 것을 지원한다. TEE는 기밀성 (confidentiality) 및 무결성(integrity)과 관련하여 상기 TEE 내에 로딩되는 코드 및 데이터를 보호하는 프로 세서의 보안 영역에서의 환경이다. 상기 TEE는 격리되어(isolated) 비-TEE에서의 운영 체제(operating syste m)와 병렬로 실행되며 사용자 대면(user-facing) 운영 체제보다 더 안전하다. 일부 TEE들은 데이터를 보호하기 위해 하드웨어 및 소프트웨어를 모두 이용하는 하이브리드 접근법을 이용하므로, 많은 애플리케이션들을 위해 충분한 보안 수준을 제공한다. TEE들의 예들에는 ARM 트러스트존(ARM TRUSTZONE) 및 인텔(INTEL) SGX가 포함되 지만, 본 명세서에서는 어떤 적절한 TEE라도 이용될 수 있다. TEE에서 실행되는 신뢰되는(trusted) 애플리케이 션들은 장치의 메인 프로세서, 주변장치들, 및 메모리의 모든 기능(full power)에 액세스할 수 있지만, 하드웨 어 격리(hardware isolation)는 이러한 애플리케이션들을 상기 메인 운영 체제에서 실행되는 사용자-설치 애플 리케이션들로부터 보호한다. 상기 TEE 내에서의 소프트웨어 및 암호화(cryptographic) 격리는 또한 내부에 포함 된 상기 신뢰되는 애플리케이션들을 서로 보호할 수 있다. 본 개시는 또한, TEE를 지원하고 전자 장치 상에서 상기 TEE와 상기 비-TEE 간의 보안 채널을 지원하는 하나 이 상의 계산 프로세서들(computation processors)을 포함하는, 엔드포인트 또는 전자 장치를 제공한다. 본 개시의 상기 시스템 및 방법은, 상기 AI 모델의 측면들을 보호하면서 AI 추론 요청들을 처리하는 효율을 증가시키거나 또는 최대화하도록, 상기 TEE 내의 처리 자원들(processing resources)과 상기 TEE 외부의 처리 자원들 간에 추 론을 위한 계산 작업부하(computation workload)를 분할하는 것을 더 제공한다. 도 1은 본 개시의 다양한 실시예들에 따른 예시적 네트워크 구성을 도시한다. 도 1에 도시한 네트워크 구 성의 실시예는 단지 예시를 위한 것이다. 네트워크 구성의 다른 실시예들이 본 개시의 범위를 벗어나 지 않고 이용될 수 있다. 본 개시의 실시예들에 따르면, 전자 장치는 네트워크 구성에 포함된다. 전자 장치는 버스, 프로세서, 메모리, 입/출력(input/output: I/O) 인터페이스, 디스플레이, 통신 인터페이 스, 및 센서 중 적어도 하나를 포함할 수 있다. 일부 실시예들에서, 전자 장치는 이들 구성요소 들 중 적어도 하나를 제외하거나 또는 적어도 하나의 다른 구성요소를 추가할 수 있다. 버스는 구성요소들 (120 내지 180)을 서로 연결하고 상기 구성요소들 간에 통신들(예를 들면, 제어 메시지들 및/또는 데이터)을 전 달하기 위한 회로를 포함한다. 프로세서는 중앙 처리 장치(central processing unit: CPU), 그래픽 처리 장치(graphics processor unit: GPU), 애플리케이션 프로세서(application processor: AP), 또는 통신 프로세서(communication processor: CP) 중 하나 이상을 포함한다. 프로세서는 전자 장치의 다른 구성요소들 중 적어도 하나에 대한 제어 및/ 또는 통신에 관련된 동작 또는 데이터 처리를 수행할 수 있다. 본 개시의 다양한 실시예들에 따르면, 프로세서 는 TEE 및 비-TEE를 모두 운용할 수 있으며, 여기서 프로세서의 프로세서 자원들은, 상기 TEE 내에서 특정 AI 모델 데이터를 난독화하면서(obfuscating) 상기 장치에 대해 AI 서비스들을 수행하도록, 상기 TEE와 상 기 비-TEE 간에 할당된다. 그러한 AI 서비스들의 수행 시에, 프로세서의 TEE 프로세서 자원들 및 비-TEE 프로세서 자원들은 특정 작업을 수행하기 위해 분할될 수 있는데, 예를 들어 보다 과중한(heavier) 계산 작업은 상기 비-TEE 프로세서 자원들에 할당하면서 보다 경미한(lighter) 작업은 특정 모델 데이터를 난독화하게 될 상 기 TEE 프로세서 자원들에 할당할 수 있다. 일부 실시예들에서, 별개의 프로세서들이 상기 TEE 및 비-TEE에서 동작할 수 있다. 메모리는 휘발성 및/또는 비휘발성 메모리를 포함할 수 있다. 예를 들면, 메모리는 전자 장치의 적어도 하나의 다른 구성요소에 관련된 명령들(commands) 및 데이터를 저장할 수 있다. 본 개시의 실시예들에 따르면, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수 있다. 프로그램은, 예를 들면, 커 널, 미들웨어, 애플리케이션 프로그래밍 인터페이스(application programming interface: API), 및/또는 애플리케이션 프로그램(또는 \"애플리케이션\")을 포함한다. 커널, 미들웨어,또는 API의 적어도 일부는 운영 체제(operating system: OS)로 표시될 수 있다. 일부 실시예들에서, 메모 리는, 상기 전자 장치, 제1 외부 전자 장치, 제2 외부 전자 장치, 또는 서버에 저장 될 수 있는, AI 모델에 의해 이용되는 외부 메모리일 수 있다. 메모리는 또한 상기 비-TEE에서 동작하는 엔티티들(entities)에 액세스할 수 없는 TEE에 의해 이용되는 보안 저장 영역(secure storage area)을 포함할 수 있다. 커널은 다른 프로그램들(예를 들면, 미들웨어, API, 또는 애플리케이션)에서 구현되는 동 작들 또는 기능들(functions)을 수행하는 데 이용되는 시스템 자원들(예를 들면, 버스, 프로세서, 또 는 메모리)을 제어 또는 관리할 수 있다. 커널은, 미들웨어, API, 또는 애플리케이션(14 7)이 전자 장치의 개별 구성요소들에 액세스하여 상기 시스템 자원들을 제어 또는 관리할 수 있도록 하는, 인터페이스를 제공한다. 애플리케이션은, 발화(utterance), 이미지, 데이터 예측, 또는 기타 요청과 같은, 추론 요청을 수신하는 비-TEE에서 실행되는 애플리케이션을 포함할 수 있다. 애플리케이션은 또한 전자 장 치 상의 다른 애플리케이션들로부터의 AI 추론 요청들을 처리하는 비-TEE에서 실행되는 AI 서비스를 포함 할 수 있다. 애플리케이션은, AI 모델들의 구성들(configurations)을 관리하고, TEE 인증(attestation)을 수행하고, AI 모델들을 수신, 관리, 및 저장하고, 및/또는 AI 모델의 하나 이상의 부분들을 실행하는 프로세스 들과 같은, TEE 애플리케이션 프로세스들을 더 포함할 수 있다. 미들웨어는, 예를 들면, API 또는 애플리케이션이 커널과 데이터를 통신할 수 있도록 하기 위한 중계기(relay)로서 기능할 수 있다. 복수의 애플리케이션들이 제공될 수 있다. 미들웨어는, 예 를 들면, 전자 장치의 시스템 자원들(예를 들면, 버스, 프로세서, 또는 메모리)을 이용하 는 우선 순위를 복수의 애플리케이션들 중 적어도 하나에 할당함으로써, 애플리케이션들로부터 수신 된 작업 요청들(work requests)을 제어할 수 있다. API는 애플리케이션이 커널 또는 미들웨어 로부터 제공되는 기능들(functions)을 제어할 수 있도록 하는 인터페이스이다. 예를 들면, API는 파 일링 제어(filing control), 윈도우 제어, 이미지 처리, 또는 텍스트 제어를 위한 적어도 하나의 인터페이스 또 는 기능(예를 들면, 명령(command))을 포함한다. 일부 실시예들에서, API는 외부 소스로부터 AI 모델들을 요청 또는 수신하는 기능들을 포함할 수 있다. I/O 인터페이스는, 예를 들면, 사용자 또는 다른 외부 장치들로부터 입력된 명령들 또는 데이터를 전자 장 치의 다른 구성요소(들)에 전달할 수 있는, 인터페이스로서의 역할을 한다. I/O 인터페이스는 또한 전자 장치의 다른 구성요소(들)로부터 수신한 명령들 또는 데이터를 사용자 또는 다른 외부 장치에 출력할 수 있다. 디스플레이는, 예를 들면, 액정 디스플레이(liquid crystal display: LCD), 발광 다이오드(light emitting diode: LED) 디스플레이, 유기 발광 다이오드(organic light emitting diode: OLED) 디스플레이, 양 자점 발광 다이오드(quantum-dot light emitting diode: QLED) 디스플레이, 마이크로 전자기계 시스템 (microelectromechanical systems: MEMS) 디스플레이, 또는 전자종이 디스플레이를 포함한다. 디스플레이(16 0)는 또한, 다초점 디스플레이와 같은, 깊이 인식(depth-aware) 디스플레이일 수 있다. 디스플레이는 사용 자에게, 예를 들면, 다양한 콘텐츠(예를 들면, 텍스트, 이미지들, 비디오들, 아이콘들(icons), 또는 기호들 (symbols))를 표시할 수 있다. 디스플레이는 터치스크린을 포함할 수 있고, 예를 들면, 전자 펜 (electronic pen) 또는 사용자의 신체 일부를 이용한, 터치, 제스처, 근접(proximity), 또는 호버링(hovering) 입력을 수신할 수 있다. 통신 인터페이스는, 예를 들면, 상기 전자 장치와 외부 전자 장치(예를 들면, 제1 외부 전자 장치 , 제2 외부 전자 장치, 또는 서버) 간의 통신을 설정할 수 있다. 예를 들면, 통신 인터페이스 는, 외부 전자 장치와 통신하기 위해, 무선 또는 유선 통신을 통해 네트워크(162 또는 164)와 연결될 수 있다. 통신 인터페이스는 유선 또는 무선 트랜시버(transceiver) 또는, 전자 장치에 제공되는 AI 모 델들에 관한 통신 인터페이스에 의해 수신되는 신호들과 같은, 신호들을 전송 및 수신하는 다른 어떤 구성 요소일 수 있다. 상기 무선 통신은, 셀룰러 통신 프로토콜(cellular communication protocol)로서, 예를 들면, 롱텀 에벌루션 (long term evolution: LTE), 롱텀 에벌루션 어드밴스드(long term evolution-advanced: LTE-A), 5세대 무선 시스템(5th generation wireless system: 5G), 밀리미터파(millimeter-wave) 또는 60 GHz 무선 통신, 무선 USB, 코드 분할 다중 접속(code division multiple access: CDMA), 광대역 코드 분할 다중 접속(wideband code division multiple access: WCDMA), 범용 이동 통신 시스템(universal mobile telecommunication system:UMTS), 무선 광대역(wireless broadband: WiBro), 또는 세계 이동 통신 시스템(global system for mobile communication: GSM) 중 적어도 하나를 이용할 수 있다. 상기 유선 통신은, 예를 들면, 범용 직렬 버스 (universal serial bus: USB), 고선명 멀티미디어 인터페이스(high definition multimedia interface: HDMI), 권장 표준 232(recommended standard 232: RS-232), 또는 재래식 전화 서비스(plain old telephone service: POTS) 중 적어도 하나를 포함할 수 있다. 네트워크는, 컴퓨터 네트워크(예를 들면, 로컬 영역 네트워크 (local area network: LAN) 또는 광역 네트워크(wide area network: WAN)), 인터넷, 또는 전화 네트워크와 같 은, 적어도 하나의 통신 네트워크를 포함한다. 전자 장치는, 물리량을 계량하거나 전자 장치의 활성화 상태를 검출하고 계량 또는 검출된 정보를 전 기 신호로 변환할 수 있는, 하나 이상의 센서들을 더 포함한다. 예를 들면, 하나 이상의 센서들은, 장면들(scenes)의 이미지들을 캡처하는 데 이용될 수 있는, 하나 이상의 카메라들 또는 기타 영상화 센서들을 포함할 수 있다. 센서(들)은 또한 하나 이상의 터치 입력용 버튼들, 하나 이상의 마이크들(microphones), 제스처 센서, 자이로스코프 또는 자이로 센서, 기압(air pressure) 센서, 자기 센서 또는 자력계, 가속도 센서 또는 가속도계, 그립(grip) 센서, 근접 센서, 컬러(color) 센서(예를 들면, 적녹청(red green blue: RGB) 센서), 생체물리(bio-physical) 센서, 온도 센서, 습도 센서, 조도(illumination) 센서, 자외선(ultraviolet: UV) 센서, 근전도(electromyography: EMG) 센서, 뇌파(electroencephalogram: EEG) 센서, 심전도 (electrocardiogram: ECG) 센서, 적외선(infrared: IR) 센서, 초음파 센서, 홍채(iris) 센서, 또는 지문 센서 를 포함할 수 있다. 센서(들)은, 하나 이상의 가속도계들, 자이로스코프들, 및 다른 구성요소들을 포함할 수 있는, 관성 측정 유닛을 더 포함할 수 있다. 또한, 센서(들)은 본 명세서에 포함된 센서들 중 적어도 하나를 제어하기 위한 제어 회로를 포함할 수 있다. 이러한 센서(들) 중 어떤 것이라도 전자 장치 내 에 위치할 수 있다. 제1 외부 전자 장치 또는 제2 외부 전자 장치는 웨어러블 장치 또는 전자 장치-장착가능 웨어러블 장 치(예를 들면, HMD)일 수 있다. 전자 장치가 제1 외부 전자 장치(예를 들면, HMD)에 장착되는 경우, 전자 장치는 통신 인터페이스를 통해 제1 외부 전자 장치와 통신할 수 있다. 전자 장치는, 별도의 네트워크의 관여 없이 제1 외부 전자 장치와 통신하도록, 제1 외부 전자 장치와 직접 연결될 수 있다. 전자 장치는 또한, 하나 이상의 카메라들을 포함하는, 안경과 같은 증강 현실(augmented reality) 웨어러블 장치일 수 있다. 제1 및 제2 외부 전자 장치들(102 및 104) 및 서버는 각각 전자 장치와 동일 유형 또는 상이한 유형 의 장치일 수 있다. 본 개시의 특정 실시예들에 따르면, 서버는 하나 이상의 서버들의 그룹을 포함한다. 또한, 본 개시의 특정 실시예들에 따르면, 전자 장치에서 실행되는 동작들 전부 또는 일부는 다른 전자 장 치 또는 다수의 다른 전자 장치들(예를 들면, 제1 및 제2 외부 전자 장치들(102 및 104) 또는 서버)에서 실행될 수 있다. 또한, 본 개시의 특정 실시예들에 따르면, 전자 장치가 자동적으로 또는 요청에 따라 어 떤 기능 또는 서비스를 수행해야 하는 경우, 전자 장치는, 자체적으로 또는 추가적으로 상기 기능 또는 서 비스를 실행하는 대신에, 다른 장치(예를 들면, 제1 및 제2 외부 전자 장치들(102 및 104) 또는 서버)에게 이와 연관된 적어도 일부 기능들을 수행하도록 요청할 수 있다. 다른 전자 장치(예를 들면, 제1 및제2 외부 전 자 장치들(102 및 104) 또는 서버)는 상기 요청된 기능들 또는 추가 기능들을 실행하고 실행 결과를 전자 장치에 전달할 수 있다. 전자 장치는 상기 수신된 결과를 그대로 또는 추가적으로 처리함으로써 요청 된 기능 또는 서비스를 제공할 수 있다. 이를 위해, 예를 들면, 클라우드 컴퓨팅, 분산 컴퓨팅(distributed computing), 또는 클라이언트-서버 컴퓨팅 기법이 이용될 수 있다. 도 1은 전자 장치가 네트워크를 통해 제2 외부 전자 장치 또는 서버와 통신하기 위해 통신 인터페이스를 포함하는 것을 도시하 고 있지만, 본 개시의 실시예들에 따르면, 전자 장치는 별도의 통신 기능 없이 독립적으로 동작될 수 있다. 서버는 전자 장치(또는 이것의 적절한 서브세트(subset))와 동일 또는 유사한 구성요소들(110 내지 180)을 포함할 수 있다. 서버는 전자 장치 상에서 구현되는 동작들(또는 기능들) 중 적어도 하나를 수행함으로써 전자 장치의 구동을 지원할 수 있다. 예를 들면, 서버는, 전자 장치 내에 구현되 는 프로세서를 지원할 수 있는, 처리 모듈 또는 프로세서를 포함할 수 있다. 도 1은 네트워크 구성의 일 예를 도시하고 있지만, 도 1에 대해 다양한 변경이 이루어질 수 있다. 예를 들 면, 네트워크 구성은 각 구성요소를 어떤 개수로 어떤 적절한 배치로도 포함할 수 있다. 일반적으로, 컴퓨 팅 및 통신 시스템들은 매우 다양한 구성으로 구현되며, 도 1은 본 개시의 범위를 어떤 특정한 구성에도 제한하 지 않는다. 도 1은 본 특허 문서에 개시된 다양한 특징들이 이용될 수 있는 하나의 동작 환경을 도시하고 있지만, 이러한 특징들은 다른 어떤 적절한 시스템에서도 이용될 수 있다. 도 2는 본 개시의 다양한 실시예들에 따른 예시적 AI 모델 보호 아키텍처를 도시한다. 도 2에 도시한 바와 같이, 아키텍처는, 도 1의 전자 장치를 나타낼 수 있는, 전자 장치를 포함한다. 전자 장치(20 1)는 비-TEE와 병렬로 동작하는 TEE를 포함한다. 비-TEE는 애플리케이션을 포함할 수 있는 하나 이상의 애플리케이션들, 및 AI 서비스를 포함한다. AI 서비스는 하나 이상의 애플리케이션 들로부터 추론 요청들(inference requests)을 수신한다. 비-TEE는 또한, 일부 실시예들에서 프로세서 일 수도 있는, 디지털 신호 프로세서(digital signal processor: DSP), 그래픽 처리 장치(graphics processing unit: GPU), 또는 신경망 처리 장치(neural processing unit: NPU)와 같은, 가속기를 포함할 수 있다. 온-디바이스 AI 추론들은 전적으로 비-TEE 내에서 수행될 수 있으며, 이러한 경우에 AI 서비스는 애 플리케이션들로부터 요청들을 수신하고 계산을 위해 모델 및 입력 데이터를 가속기에 제공한다. 비- TEE AI 추론들은 AI 추론들을 수행하기 위해 사용자 장치들이 편리하고 효율적으로 이용될 수 있도록 하지만, AI 모델이 어떤 엔드 포인트(end point)에서 실행되고 있는 경우, 해커가 모델 정보를 도용할 수 있다. 아키텍 처는 이 문제에 대한 해결책을 제공한다. 아키텍처는 또한, 일부 실시예들에서 프로세서일 수 있는, 애플리케이션 프로세서(AP)와 같은, 계산 프로세서(computation processor)를 포함할 수 있다. 계산 프로세서는 보안(secure) TEE 내에 서 AI 서비스를 위한 AI 계산들을 수행한다. AI 모델은, 모델 및 그 모델 파라미터들을 전자 장 치의 비-TEE로부터 완전히 난독화된 상태로 또는 비밀로 유지하기 위해, 계산 프로세서에 제공 된다. 일부 실시예들에서, AI 모델은, 통신 인터페이스와 같은, 트랜시버를 통해 전자 장치로 전송된다. 아키텍처를 이용한 추론 요청에 대한 하나의 예시적 프로세스 흐름은 애플리케이션으로부터 AI 추론 요청을 수신하는 단계를 포함한다. 상기 AI 추론 요청은, 사용자가 제공한 발화(utterance)에 대해 자연어 이해 (natural language understanding)를 수행하라는 요청, 전자 장치에 의해 캡처, 수신, 또는 액세스된 이 미지에 대해 이미지 인식(image recognition)을 수행하라는 요청, 사용자 행동 예측(user behavioral prediction)과 같은 예측을 제공하라는 요청, 또는 기타 AI 추론 프로세스들과 같이, 입력을 처리하고 추론 결 과를 제공하라는 요청을 포함할 수 있다. AI 서비스는 상기 추론 요청 및 입력 데이터를 TEE 내의 계 산 프로세서에 제공한다. 계산 프로세서는, 상기 제공된 입력들을 처리하여, 발화에 대한 슬롯 태깅 (slot tagging), 이미지의 범주화(categorizing), 또는 기타 결과들과 같은, 최종 추론 결과를 제공하기 위해, AI 모델을 이용하여 완전한 추론 결정을 수행한다. TEE 내의 계산 프로세서는 상기 추론 결과를 비-TEE 내의 AI 서비스에 제공하고, AI 서비스는 상기 추론 결과를 애플리케이션에 반환하 여 애플리케이션이 상기 결과를 사용자에게 제공하거나 상기 결과를 달리 이용할 수 있도록 한다. AI 모델 은 오직 TEE 내에서 액세스되거나 이용되고 모델을 이용한 모델 파라미터들 또는 계산들이 TEE 외부에서는 허용되지 않기 때문에, 도 2의 아키텍처는 AI 모델의 안전하고 보호된 실행을 제공한 다. 도 2는 AI 모델 보호 아키텍처의 일 예를 도시하고 있지만, 도 2에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, TEE 및 비-TEE는 각 구성요소를 어떤 개수로 어떤 적절한 배치로도 포함할 수 있거나 또 는 다른 구성요소들을 포함할 수 있다. 예를 들면, TEE는 AI 모델 및/또는 그 파라미터들을 저장하기 위한 보안 스토리지(secure storage)를 포함할 수도 있다. TEE는 또한, TEE 인증을 수행하기 위한 인증 프 로세서(attestation processor), AI 모델 구성을 관리하기 위한 구성 관리자(configuration manager), 상이한 저장된 AI 모델들을 관리하기 위한 모델 관리자(model manager), 또는 계산 프로세서와 함께 모델의 실행 을 용이하게 하기 위한 모델 프로세서(model processor)와 같은, 다른 구성요소들을 포함할 수 있다. 일반적으 로, 컴퓨팅 아키텍처들은 매우 다양한 구성으로 구현되며, 도 2는 본 개시의 범위를 어떤 특정한 구성에도 제한 하지 않는다. 또한, 도 2는 본 특허 문서에 개시된 다양한 특징들이 이용될 수 있는 하나의 동작 환경을 도시하 고 있지만, 이러한 특징들은 다른 어떤 적절한 시스템에서도 이용될 수 있다. 도 3은 본 개시의 다양한 실시예들에 따른 예시적 양자간(two-party) AI 모델 계산 및 보호 아키텍처를 도 시한다. 도 2와 관련하여 설명한 바와 같이, 오직 입력들 및 출력들만이 TEE와 비-TEE 간에 전달되도록 하면서 TEE로 AI 모델을 실행하면 악성 당사자들이 상기 AI 모델 또는 그 파라미터들에 액세스할 수 없는, 보안 아키텍 처가 제공된다. 그러나, 경우에 따라, AI 모델을 전적으로 TEE 내에서 실행하는 것에 비효율성이 있을 수 있다.예를 들면, TEE 내에, 병렬 계산(parallel computation)과 같은, AI 계산에 최적화된 계산 유닛 또는 프로세서 가 없을 수 있다. TEE는 AI 계산을 효율적으로 실행하기 위한 라이브러리 지원(library support)이 부족할 수 있다. TEE는 제한된 메모리를 가질 수 있으므로, 대규모 AI 계산을 수용하는 데 문제를 야기할 수 있다. AI 모 델을 전적으로 TEE 내에서 실행함에 있어 이러한 또는 기타 문제들은 큰 성능 손실을 초래할 수 있다. 일부 경 우에, 비-TEE에서 수행되는 AI 계산은 TEE에서보다 10배 내지 40배 더 빠를 수 있고 보다 큰 전력 효율성을 제 공할 수 있다. 따라서, 일부 실시예들에서, 도 2의 아키텍처는 보다 적은 계산이 필요한 AI 태스크들에 이 용될 수 있지만, AI 모델 및 그 파라미터들을 악성 당사자들로부터 여전히 보호하면서 효율성을 증가시키기 위 해, 더 큰 계산 태스크에 대해서는 다른 아키텍처 스킴들(schemes)이 이용될 수 있다. 상기 효율성 문제들을 완화하기 위해, 도 3의 아키텍처는, AI 추론 계산을 TEE와 비-TEE 간에 할당하여, AI 모델에 대한 TEE의 보안성을 제공하면서 비-TEE의 성능 및 전력 효율을 최대한 활용한다. 행렬 곱셈들과 같 은 집중적 계산들(intensive computations)은, 원본 모델 파라미터들을 비-TEE에 개시하지 않고, 비-TEE에 의해 수행될 수 있다. TEE 내 계산들을 최소화하여 계산 효율 손실을 제한할 수 있다. 일부 실시예들에서, TEE와 비- TEE 간의 계산의 위임(delegating)은, 도 2와 관련하여 설명한 바와 같이 AI 모델을 전적으로 TEE 내에서 처리 하는 것에 비해, 10배 이상 빠른 계산 속도까지 제공할 수 있다. 도 3에 도시한 바와 같이, 아키텍처는, 도 1의 전자 장치를 나타낼 수 있는, 전자 장치를 포함 한다. 전자 장치는 비-TEE와 병렬로 동작하는 TEE를 포함한다. 비-TEE는 애플리케이션 을 포함할 수 있는 하나 이상의 애플리케이션들, 및 AI 서비스를 포함한다. AI 서비스는 하나 이상의 애플리케이션들로부터 추론 요청들을 수신한다. 비-TEE는 또한, 일부 실시예들에서 프로 세서일 수 있는, DSP, GPU, 또는 NPU와 같은, 가속기를 포함한다. TEE는, 비-TEE 내의 가 속기와, 일부 실시예들에서 프로세서일 수 있는, TEE 내에서 동작하는 애플리케이션 프로세서와 같은, 계산 프로세서 간에 계산들을 할당하는, 보안(secure) 양자간(two-party) 계산 프로세서를 포 함한다. AI 모델은, 모델 및 그 모델 파라미터들을 전자 장치의 비-TEE로부터 난독화된 상 태로 또는 비밀로 유지하기 위해, 보안 양자간 계산 프로세서에 제공된다. 일부 실시예들에서, AI 모델 은, 통신 인터페이스와 같은, 트랜시버를 통해 전자 장치로 전송된다. 아키텍처를 이용한 추론 요청에 대한 하나의 예시적 프로세스 흐름은 애플리케이션으로부터 AI 추론 요청을 수신하는 단계를 포함한다. 상기 AI 추론 요청은, 사용자가 제공한 발화에 대해 자연어 이해를 수행하라 는 요청, 전자 장치에 의해 캡처, 수신, 또는 액세스된 이미지에 대해 이미지 인식을 수행하라는 요청, 사 용자 행동 예측과 같은 예측을 제공하라는 요청, 또는 기타 AI 추론 프로세스들과 같이, 입력을 처리하고 추론 결과를 제공하라는 요청을 포함할 수 있다. AI 서비스는 상기 추론 요청 및 입력 데이터를 TEE 내의 보안 양자간 계산 프로세서에 제공한다. 보안 양자간 계산 프로세서는 상기 추론 결과의 계산을 계산 프로세서와 가속기 간에 어떻게 분할할지를 결정한다. 예를 들면, 보안 양자간 계산 프로세서는 추론 결과의 계산을, 계산 프로세서와 같은, TEE 내의 프로세서 자원들에 의해 수행되는 내부 계산 (internal calculation)과, 가속기와 같은, TEE 외부의 프로세서 자원들에 의해 수행되는 외부 계산 (external calculation) 간에 분할할 수 있다. 일부 실시예들에서, 보안 양자간 계산 프로세서는 상기 추 론 결과의 계산에 대한 계산 작업부하(computation workload)를 결정하고, 상기 계산의 행렬 곱셈 또는 컨볼루 션 부분과 같이, 상기 계산 작업부하의 계산-과중(computation-heavy) 부분은 비-TEE 내의 프로세서 자원 들에 의해 수행되는 상기 외부 계산의 적어도 일부로서 할당한다. 일부 실시예들에서, 상기 추론 결과의 계산을 분할하기 위해, 보안 양자간 계산 프로세서는 TEE 외부 의 프로세서 자원들에 할당된 상기 계산 작업부하의 계산-과중 부분에 제공된 데이터를, TEE 내의 프로세 서 자원들에 의해 수행되는, 상기 내부 계산의 적어도 일부로서 난독화한다. 예를 들면, 일부 실시예들에서, 데 이터 또는 모델 파라미터들은, 상기 AI 모델의 가중치 행렬(weight matrix)을 두 개의 행렬들로 분할하는 (splitting) 계산 프로세서에 의해 난독화될 수 있으며, 이는 상기 원본 가중치 행렬을 난독화하기 위해 후술되는 바와 같이 수행될 수 있다. 상기 두 개의 행렬들은 비-TEE 내의 가속기에 제공되고, 가속기 는 상기 두 개의 행렬들을 이용하여 계산된 계산 결과들을 보안 양자간 계산 프로세서로 반환한다. 계산 프로세서는, 비-TEE에는 AI 모델의 상기 원본 가중치 행렬이 제공되지 않도록, 상기 계산 결과들을 이용하여 상기 결과들을 비-난독화된(non-obfuscated) 결과로 변환할 수 있다. 일부 실시예들에서, 계 산 프로세서는, 가중치 행렬 또는 중간 계층 입력들 (intermediary layer inputs)과 같은, 하나 이상의 파라미터들을 섭동하고(perturb) 상기 섭동된(perturbed) 파라미터들을 가속기로 전달할 수 있다. 상기 섭 동된 파라미터들을 이용하여 가속기로부터 계산 결과들을 수신하는 경우, 계산 프로세서는 상기 결과들을 비섭동된(unperturbed) 결과들로 변환한다. 일부 실시예들에서, 모델 파라미터들의 난독화(obfuscating), 분할(splitting), 또는 섭동(perturbing) 및 사전계산(precomputation) 결과들의 저장과 같은, 상기 내부 계산 의 적어도 일부는 상기 추론 요청을 수신하기 전에 TEE에서 수행된다. 예를 들면, TEE는, 가중치 행 렬들과 같은, 난독화된 모델 파라미터들을 미리 사전계산하여, 상기 난독화된 파라미터들이 추론 요청 수신 시 이용가능하도록 할 수 있다. 보안 양자간 계산 프로세서는 계산 프로세서 및 가속기로부터의 상기 결과들을 이용하여 추론 결정을 완료한다. TEE 내의 보안 양자간 계산 프로세서는 상기 추론 결과를 비-TEE 내의 AI 서 비스에 제공한다. AI 서비스는 상기 추론 결과를 애플리케이션에 반환하여, 상기 애플리케이션 이 상기 결과를 사용자에게 제공하거나 또는 상기 결과를 달리 이용하도록 할 수 있다. 도 3은 양자간 AI 모델 계산 및 보호 아키텍처의 일 예를 도시하고 있지만, 도 3에 대해 다양한 변경이 이 루어질 수 있다. 예를 들면, TEE 및 비-TEE는 각 구성요소를 어떤 개수로 어떤 적절한 배치로 포함하 거나 또는 다른 구성요소들을 포함할 수 있다. 예를 들면, TEE는 AI 모델 및/또는 그 파라미터들을 저장하기 위한 보안 스토리지를 포함할 수도 있다. TEE는 또한, TEE 인증을 수행하기 위한 인증 프로세서, AI 모델 구성을 관리하기 위한 구성 관리자, 상이한 저장된 AI 모델들을 관리하기 위한 모델 관리자, 또는 계산 프로세서와 함께 모델의 실행을 용이하게 하기 위한 모델 프로세서와 같은, 다른 구성요소들을 포함할 수 있다. 일반적으로, 컴퓨팅 아키텍처들은 매우 다양한 구성으로 구현되며, 도 3은 본 개시의 범위를 어떤 특정한 구성에도 제한하지 않는다. 또한, 도 3은 본 특허 문서에 개시된 다양한 특징들이 이용될 수 있는 하나의 동작 환경을 도시하고 있지만, 이러한 특징들은 다른 어떤 적절한 시스템에서도 이용될 수 있다. 도 4a 및 도 4b는 본 개시의 다양한 실시예들에 따른 다른 예시적 AI 모델 보호 아키텍처를 도시한다. 도 3과 관련하여 설명한 바와 같이, AI 추론에 대한 계산을 TEE와 비-TEE 간에 분할함으로써, TEE의 보안성을 AI 모델에 제공하면서 비-TEE의 성능 및 전력 효율이 최대한 이용된다. 행렬 곱셈들과 같은 집중적 계산들은, 원본 모델 파라미터들을 비-TEE에 개시하지 않고, 비-TEE에 의해 수행될 수 있다. TEE 내 계산들을 최소화하여계산 효율 손실을 제한할 수 있다. 도 4a 및 도 4b에 도시한 바와 같이, 아키텍처는, 도 1의 전자 장치를 나타낼 수 있는, 전자 장치 를 포함한다. 전자 장치는 비-TEE와 병렬로 동작하는 TEE를 포함한다. 비-TEE는 애 플리케이션을 포함할 수 있는 하나 이상의 애플리케이션들, 및 AI 서비스를 포함한다. AI 서비 스는 하나 이상의 애플리케이션들로부터 추론 요청들을 수신한다. 비-TEE는 또한, 일부 실시예 들에서 프로세서일 수 있는, DSP, GPU, 또는 NPU와 같은, 가속기를 포함한다. TEE는, 일부 실 시예들에서 보안 양자간 계산 프로세서일 수 있는, 모델 프로세서를 포함한다. 모델 프로세서는, 비-TEE 내의 가속기와, 일부 실시예들에서 프로세서일 수 있는, TEE 내 에서 동작하는, 애플리케이션 프로세서와 같은, 계산 프로세서 간에 계산들을 할당한다. TEE는 또한 모델 관리자, 보안 스토리지, 구성 관리자, 및 인증 관리자를 포함한다. AI 모델은, 모델 및 그 모델 파라미터들을 전자 장치의 비-TEE로부터 완전히 난독화된 상 태로 또는 비밀로 유지하기 위해, 모델 관리자에 제공된다. 일부 실시예들에서, AI 모델은, 통신 인 터페이스와 같은, 트랜시버를 통해 전자 장치로 전송된다. 전자 장치와 통신하는 모델 핸들러 (model handler)는, 하나 이상의 모델 개발자들(model developers)로부터, 하나 이상의 AI 모델들 을 수신할 수 있고 이어서 AI 모델들을 전자 장치에 제공할 수 있다. 일부 실시예들에서, 모델 관리 자는 모델 관리자에 의해 수신된 AI 모델을 보안 스토리지에 저장한다. 일부 실시예들에서, 모델 관리자는 추론 요청이 TEE에 의해 수신되는 런타임에 AI 모델을 요청할 수 있다. 아키텍처를 이용한 추론 요청에 대한 하나의 예시적 프로세스 흐름은 애플리케이션으로부터 AI 추론 요청을 수신하는 단계를 포함한다. AI 추론 요청은, 사용자가 제공한 발화에 대해 자연어 이해를 수 행하라는 요청, 전자 장치에 의해 캡처, 수신, 또는 액세스된 이미지에 대해 이미지 인식을 수행하라는 요 청, 사용자 행동 예측과 같은 예측을 제공하라는 요청, 또는 기타 AI 추론 요청들과 같이, 입력을 처리하고 추 론 결과를 제공하라는 요청을 포함할 수 있다. AI 서비스는 추론 요청 및 입력 데이터를 TEE에 제공한다. 일부 실시예들에서, 모델 관리자는 AI 추론 요청에 이용될 AI 모델을 보 안 스토리지에서 검색하거나 또는 모델 핸들러로부터 AI 모델을 수신한다. 일부 실시예들에서, 모델 관리자는 또한, 상기 AI 추론 요청을 수신하기 전에 보안 스토리지에 저장되었던, 사전계산된(precomputed) 난독화된 또는 섭동된 모델 파라미터들을 검색할 수 있다. 모델 관리자는 또한 인증 관리자로부터 인증(attestation)이 성공적이라는 하나 이상의 알림들 (notifications)을 수신할 수 있다. 인증(attestation)은 소프트웨어가 그 신원(identity)을 증명하는 메커니 즘이며, 여기서 목표는, 모델 핸들러와 같은 원격 당사자에게, TEE 내의 상기 소프트웨어 및 구성요 소들이 온전하고(intact) 신뢰할 수 있음을 증명하는 것이다. 일부 실시예들에서, 인증 관리자는, TEE 내의 상기 구성요소들이 AI 모델을 사용하도록 신뢰되고 인증되었는지(authorized) 확인하기 위 해, 서명된(signed) 인증 데이터를, 모델 핸들러와 같은, 신뢰되는 인증 기관(certification authority: CA)에 전송할 수 있다. 일부 실시예들에서, 상기 인증 데이터는, 예를 들면, 공개 및 개인 키 쌍(public and private key pair)을 생성하고, 해시값(hash value)을 생성하고, 상기 암호화 키들 및 해시값을 이용하여 인증 서(certification)를 생성함으로써, 암호화될 수 있다. 일부 실시예들에서, 이 데이터는 CA로 전송되며, CA는 TEE 애플리케이션들 또는 구성요소들이 신뢰할 수 있는지 여부를 결정하기 위해 해시값들을 신뢰 수준들 (trust levels)에 매핑하는 데이터베이스에서 상기 해시값을 조회할(look up) 수 있다. 일부 실시예들에서, 인 증 프로토콜들은 TEE와 상기 CA 간의 상호 인증(mutual authentication)을 허용하도록 양방향으로 실행될 수 있으며, 이에 의해 TEE도, 예를 들면, TEE가 악성 피싱 사이트(phishing site)에 도달하지 않는 지 확인하기 위해, 상기 CA의 신원을 확인할 수 있다. 그러나, 상기 인증 프로세스는 인증 프로세스의 일 예일 뿐이며, 다른 인증 프로세스들이 본 개시의 범위를 벗어나지 않고 인증 관리자 및/또는 TEE에 의해 수행될 수 있음을 유의해야 한다. 모델 관리자는 또한, 구성 관리자로부터, AI 모델에 대한 구성 데이터를 검색하거나 제공받을 수 있다. 구성 관리자로부터의 구성 데이터는, 난독화된 데이터 또는 섭동된 데이터로, AI 모델의 어 느 계층 또는 계층들을 보호해야 하는지, 계산을 위해 어느 처리 유닛들(예를 들면, AP, GPU, DSP, 또는 NPU)을 이용해야 하는지, 데이터를 TEE와 비-TEE 간에 분할할지 여부, TEE 내에서 모든 계산들을 실행 할지 여부(예를 들면, AI 추론 요청이 계산 집중적이지 않은 경우), AI 모델의 실행 횟수, 또는 기타 AI 모델 구성 옵션들과 같은, 구성들(configurations) 또는 옵션들(options)을 포함할 수 있다. 인증을 수행하는 단계, AI 모델 및 임의의(any) 사전계산된 난독화된 모델 파라미터들을 검색하는 단계, 및 구성 관리자를 이용하여 어떻게 AI 모델이 실행되어야 하는지를 구성하는 단계 이후에, 모델 관리 자는 상기 AI 모델 데이터를 모델 프로세서에 제공한다. 모델 프로세서는 입력 데이터를 이용하여 AI 모델의 실행을 용이하게 한다. 모델 프로세서는 또한 계산 프로세서와 가속기 사이에서와 같이, TEE와 비-TEE 사이의 추론 결과의 계산 작업부하를 분할할 수 있다. 예를 들 면, 모델 프로세서는 계산 프로세서와 같은, TEE 내의 프로세서 자원들에 의해 수행되는 내부 계산과, 가속기와 같은, TEE 외부의 프로세서 자원들에 의해 수행되는 외부 계산 간에 추 론 결과의 계산을 분할할 수 있다. 일부 실시예들에서, 모델 프로세서가 추론 결과의 계산을 위 한 계산 작업부하를 분할하는 경우, 모델 프로세서는, 상기 계산의 행렬 곱셈 또는 컨볼루션 부분과 같은, 계산 작업부하의 계산-과중 부분을, 비-TEE 내의, 가속기와 같은, 프로세서 자원들 에 의해 수행되는 외부 계산의 적어도 일부로서 할당할 수 있다. 모델 프로세서는 또한, 데이터 난독 화 및 난독화된 파라미터 복원, 활성화, 및/또는 풀링(pooling)과 같은, 계산 작업부하의 계산-경미 부분 을, TEE 내의, 계산 프로세서와 같은, 프로세서 자원들에 의해 수행되는 내부 계산의 적어 도 일부로서 할당할 수 있다. 일부 실시예들에서, 계산의 어떤 부분들을 계산 프로세서와 가속기 간 에 분할할지에 대한 할당은, 예를 들면, 구성 관리자에 의해 제공되는 상기 구성 데이터의 일부로, 모델 프로세서에 제공될 수 있다. 일부 실시예들에서, 상기 추론 결과의 계산을 분할하기 위해, 모델 프로세서는 계산 프로세서를 통해 특정 데이터 또는 모델 파라미터들을, TEE 내의 프로세서 자원들에 의해 수행되는, 상기 내부 계산의 적어 도 일부로서 난독화하고, TEE 외부의 프로세서 자원들에 할당된 계산 작업부하의 계산-과중 부분 에 난독화된 데이터를 제공한다. 예를 들면, 일부 실시예들에서, 데이터 또는 모델 파라미터들은, AI 모델의 가중치 행렬을 두 개의 행렬들로 분할하는여(splitting) 계산 프로세서에 의해 난독화될 수 있으며, 이는 상기 원본 가중치 행렬을 난독하기 위해 후술되는 바와 같이 수행될 수 있다. 상기 두 개의 행렬 들은 비-TEE 내의 가속기에 제공되고, 가속기는 외부 결과들을 TEE 내의 모델 프로세 서로 반환한다. 계산 프로세서는 외부 결과들을 이용하여 외부 결과들을 비-난독화된 결과 로 변환 또는 복원하고 내부 결과들을 산출할 수 있다. 이에 따라 비-TEE에는 AI 모델의 상기 원본 가중치 행렬이 제공되지 않는다. 일부 실시예들에서, 계산 프로세서는, 가중치 행렬 또는 중간 계층입력들과 같은, 하나 이상의 파라미터들을 섭동하고 상기 섭동된 파라미터들(perturbed parameters) 을 가속기 로 전달할 수 있다. 상기 섭동된 파라미터들을 이용하여 가속기로부터 외부 결과들을 수신하는 경우, 계산 프로세서는 외부 결과들을 비섭동된 결과들로 변환 또는 복원한다. 일부 실시예들에서, 모델 파라미터들의 난독화, 분할, 또는 섭동 및 보안 스토리지에 사전계산 결과들의 저장과 같은, 상기 내 부 계산의 적어도 일부는 상기 추론 요청을 수신하기 전에 TEE에서 수행된다. 예를 들면, TEE는, 가 중치 행렬들과 같은, 난독화된 모델 파라미터들을 미리 사전계산하여, 상기 난독화된 파라미터들이 추론 요청 수신 시 이용가능하도록 할 수 있다. 모델 프로세서는 계산 프로세서 및 가속기로부터의 결과들(446 및 448)을 이용하여 추론 결정을 완료한다. 예를 들면, 최종 출력이 내부 결과들로서 도출될 때까지 AI 모델의 다수의 계층들이 수행 될 수 있으며, 추론 결과는 상기 최종 출력을 이용하여 생성된다. TEE 내의 모델 프로세서는 상 기 추론 결과를 비-TEE 내의 AI 서비스에 제공한다. AI 서비스는 상기 추론 결과를 애플리케이 션에 반환하여, 상기 애플리케이션이 상기 결과를 사용자에게 제공하거나 또는 상기 결과를 달리 이용하도 록 할 수 있다. 도 4a 및 도 4b는 AI 모델 보호 아키텍처의 다른 예를 도시하고 있지만, 도 4a 및 도 4b에 대해 다양한 변 경이 이루어질 수 있다. 예를 들면, TEE 및 비-TEE는 각 구성요소를 어떤 개수로 어떤 적절한 배치로 포함하거나 또는 다른 구성요소들을 포함할 수 있다. 특정 예로서, 도 4a의 구성요소들은, 예를 들면, 모델 관 리자 및 모델 프로세서가 본 개시에서 설명하는 바와 같은 두 구성요소들의 기능들을 수행하는 동일 구성요소가 되도록, 결합될 수 있다. 다른 특정 예로서, 모델 프로세서 및 계산 프로세서와 관련하여 본 개시에서 설명한 바와 같은 기능들은, 모델 프로세서 또는 계산 프로세서 중 하나와 같이, 동일 구성요소들에 의해 제공될 수 있다. 일반적으로, 컴퓨팅 아키텍처들은 매우 다양한 구성으로 구현되며, 도 4a 및 도 4b는 본 개시의 범위를 어떤 특정한 구성에도 제한하지 않는다. 또한, 도 4a 및 도 4b는 본 특허 문서에 개시된 다양한 특징들이 이용될 수 있는 하나의 동작 환경을 도시하고 있지만, 이러한 특징들은 다른 어떤 적절 한 시스템에서도 이용될 수 있다. 도 5는 본 개시의 다양한 실시예들에 따른 예시적 AI 모델 보호 프로세스를 도시한다. 설명의 편의를 위해, 프로세스는 도 1의 상기 전자 장치, 상기 외부 전자 장치들(102, 104) 또는 서버 중 어떤 것의 프로세서(들)에 의해 실행되거나 또는 달리 이용되는 것으로 설명될 수 있다. 일부 실시예들에서, 프 로세스는 도 4a 및 도 4b와 관련하여 설명한 아키텍처에 의해 이용될 수 있다. 그러나, 프로세스 는 어떤 적절한 장치(들)에 의해서도 그리고 어떤 적절한 시스템에서도 이용될 수 있다. 블록에서, 프로세서는, 예를 들면, TEE 내의 모델 관리자와 같은 모델 관리자를 통해, AI 모델을 수 신하고 상기 AI 모델을, 보안 스토리지와 같은, 보안 스토리지에 저장한다. 결정 블록에서, 상기 프 로세서는, 예를 들면, 모델 관리자를 통해, 난독화된 데이터가 런타임 전에(추론 요청을 수신하기 전에) 사전계산되어야 하는지 결정한다. 경우에 따라, 상기 AI 모델에 대한 구성 데이터는 난독화된 데이터가 사전계 산되어야 함을 나타낼 수 있다. AI 추론 요청이 상기 TEE 외부의 소스로부터 상기 TEE 내의 구성요소들에 의해 수신되는 경우, 적어도 일부의 난독화된 데이터는 런타임에 계산될 필요가 없도록, 난독화된 데이터가 사전계산 되어 상기 TEE에 저장될 수 있어, AI 추론 결과를 계산하는 속도를 높일 수 있다. 상기 프로세서가 결정 블록 에서 상기 난독화가 사전계산되어야 한다고 결정하는 경우, 블록에서, 상기 프로세서는, 예를 들면, 모델 프로세서와 같은 모델 프로세서를 통해, 난독화된 데이터를 제공한다. 일부 실시예들에서, 계산 프로 세서와 같은 계산 프로세서는, 본 개시의 다양한 실시예들에서 설명한 바와 같이, 상기 사전계산된 난독화 된 데이터를 계산한다. 상기 사전계산된 난독화된 데이터는 상기 보안 스토리지에 저장된다. 블록에서, 애플리케이션과 같은, 상기 비-TEE 내의 클라이언트는, 상기 비-TEE 내의, AI 서비스(40 8)와 같은, AI 서비스에 AI 추론을 요청한다. 상기 클라이언트는 또한, 발화(utterance) 데이터 또는 이미지 데 이터와 같은, 하나 이상의 입력들을 포함하는 입력 데이터를 상기 AI 서비스에 제공한다. 블록에서, 상기 AI 서비스는 상기 입력 데이터와 함께 추론 요청을 상기 TEE에 전송한다. 블록에서, 상기 프로세서는, 예 를 들면, 상기 모델 관리자를 통해, 보안 스토리지로부터 AI 모델 및 임의의(any) 사전계산된 난독화된 데이터 를 독출하고, 구성 관리자와 같은, 구성 관리자로부터 AI 모델 구성을 수신한다. 상기 프로세서는 또한, 예를 들면, 인증 관리자와 같은 인증 관리자를 통해, 상기 TEE의 보안을 확인하기 위해 인증을 수행할 수 있다. 상기 프로세서는, 예를 들면, 상기 모델 관리자를 통해, 상기 모델, 모델 구성, 및 임의의(any) 난독화된 데이터를 상기 모델 프로세서에 제공할 수 있다. 블록에서, 상기 프로세서는, 예를 들면, 상기 모델 프로 세서를 통해, 상기 AI 추론 요청에 기초하여 추론 결과를 결정하기 위한 계산 작업부하를, 계산 프로세서와 같은, TEE-내(in-TEE) 계산 유닛과, 가속기와 같은, 비-TEE 계산 유닛 간에 분할한다. 예를 들면, 상기 프로세서는, 상기 AI 모델의 가중치들 또는 다음 계층으로 제공될 계층 출력들을 분할(splitting) 또는 섭동하 는 것과 같이, 데이터 난독화와 같은 내부 계산 태스크들을 할당할 수 있다. 상기 프로세서는 또한, 활성화 함 수들(activation functions)의 수행 또는 풀링(pooling)과 같은, 태스크들을 상기 TEE 내의 상기 계산 프로세 서에 할당할 수 있다. 상기 프로세서는, 행렬 곱셈들 또는 컨볼루션들과 같은, 보다 과중한 작업부하 태스크들 을 상기 비-TEE 가속기에 의해 수행되는 외부 계산들로서 할당할 수 있다. 데이터의 난독화를 상기 TEE 처리 자 원들에 할당함으로써, 원본 모델 파라미터들은, 상기 원본 모델 파라미터들이 난독화되는 상기 TEE에 잔류할 수 있다. 상기 난독화된 파라미터들은 상기 보다 과중한 작업부하 태스크들을 수행하기 위해 상기 비-TEE 가속기에 제공된다. 상기 보다 과중한 작업부하 태스크들의 결과들은 상기 TEE에 제공되며, 여기서 상기 결과들은 비-난 독화된 결과들로 다시 변환 또는 복원될 수 있다. 블록에서, 상기 프로세서는, 예를 들면, 상기 모델 프로세서를 통해, 상기 TEE로 분할되어 상기 TEE에 의 해 수행되는 하나 이상의 내부 계산들 및 상기 비-TEE로 분할되어 상기 비-TEE에 의해 수행되는 하나 이상의 외 부 계산들에 기초하여, 추론 결과를 산출한다. 예를 들면, 상기 AI 모델의 각 계층에 대해, 특정 모델 파라미터 들이 상기 TEE에 의해 난독화될 수 있고, 이는 행렬 곱셈들 또는 컨볼루션들과 같은 계산 태스크들을 위해 상기 비-TEE로 전달되며, 결과들은, 상기 AI 모델의 각 계층이 처리되고 최종 출력이 도출될 때까지 변환 또는 복원 된다. 상기 TEE와 상기 비-TEE 간에 분할된 다수의 반복들(iterations) 또는 태스크들이 있을 수 있으며, 이러 한 반복들은 상기 모델 아키텍처에 따라 특정 순서로 수행될 수 있음을 이해할 것이다. 블록에서, 상기 TEE는, 상기 추론 결과를 상기 클라이언트에 출력하기 위해, 상기 추론 결과를 상기 비-TEE 내의 상기 AI 서비 스에 제공한다. 프로세스는 블록에서 종료된다. 도 5는 AI 모델 보호 프로세스의 일 예를 도시하고 있지만, 도 5에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 일련의 단계들로 도시되어 있지만, 도 5의 다양한 단계들은 중첩되거나, 병렬로 발생하거나, 상이한 순서 로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 특정 예로서, 일부 실시예들에서, 상기 TEE가 데이터의 사전 계산을 수행하지 않도록 사전구성되는 경우, 결정 블록은 회피될 수 있다. 다른 특정 예로서, 모든 AI 추 론 계산들이 상기 TEE 내에서 수행되는 일부 실시예들에서(예를 들면, 특정 추론이 보다 덜-집중적인(less- intensive) 계산들을 이용하는 경우), 상기 프로세서가 블록에서 상기 TEE 내에서 전체 추론을 계산하고 결과를 상기 비-TEE 내의 상기 AI 서비스들로 출력하도록, 블록은 회피될 수 있다. 도 6은 본 개시의 다양한 실시예들에 따른 예시적 AI 모델 파라미터 난독화 프로세스를 도시한다. 설명의 편의를 위해, 프로세스는 도 1의 상기 전자 장치, 상기 외부 전자 장치들(102, 104) 또는 서버 중 어떤 것의 프로세서(들)에 의해 실행되거나 또는 달리 이용되는 것으로 설명될 수 있다. 일부 실시예들 에서, 프로세스는 도 4a 및 도 4b와 관련하여 설명된 아키텍처에 의해 이용될 수 있다. 그러나, 프로 세스는 어떤 적절한 장치(들)에 의해서도 그리고 어떤 적절한 시스템에서도 이용될 수 있다. 본 개시의 다양한 실시예들에서, TEE와 비-TEE 간의 양자간 계산들(two-party computations)은 사전계산 (precomputation), 위임(delegation), 및 복원(recovery)의 3단계(three phases)로 분할될 수 있다. 상기 사전 계산 단계는, 상기 TEE에 의한 런타임 전에, 난독화된 모델 파라미터들의 생성을 포함한다. 난독화된 모델 파라 미터들 및 입력들의 생성은 또한, 상기 AI 모델에 대한 구성 설정들에 따른 런타임 시에, 또는 보안 스토리지에 이전에 저장된 사전계산된 모델 파라미터들이 AI 추론 요청들에서 이용되어 소진됨으로 인해, 발생할 수 있다. 상기 위임 단계는 런타임 동안 상기 TEE와 상기 비-TEE 간에 태스크를 분할하는(partitioning) 단계를 포함한다. 예를 들면, 상기 TEE는 모델 파라미터들 또는 입력들의 난독화와 같은 태스크들 및, 활성화 함수들의 적용, 풀링(pooling), 배치 정규화(batch normalization), 정류 선형 유닛(rectified linear unit: ReLU) 함수 들의 수행, 또는 다른 태스크들과 같은, 기타 태스크들을 위임 받을 수 있다. 상기 비-TEE는, 상기 TEE에 의해 상기 비-TEE에 제공된 난독화된 데이터를 이용한 행렬 곱셈들과 같은, 보다 계산-과중한 태스크들을 위임 받을 수 있다. 상기 복원 단계는 상기 TEE가 상기 비-TEE로부터 행렬 곱셈들의 결과들과 같은 결과들 또는 출력들을 수신하고, 예를 들면, 상기 TEE에 의한 데이터의 이전의 분할(splitting) 및/또는 섭동에 기초하여, 분할된 데 이터를 재결합하고 및/또는 섭동된 데이터를 리버싱(reversing)함으로써, 진정한 비-난독화된 결과들을 복원하 기 위해 상기 결과들의 노이즈를 제거하는(de-noising) 단계를 포함한다. 상기 복원 단계 이후, 상기 TEE는 상 기 AI 모델 또는 신경망(neural network)의 다음 계층으로 진행하여 출력 계층에 도달할 때까지 위임 및 복원을 반복한다. 블록에서, 상기 프로세서는, 예를 들면, 모델 프로세서를 통해, 비-TEE와 같은 상기 비-TEE로부 터 추론 요청을 수신한다. 결정 블록에서, 상기 프로세서는, 예를 들면, 모델 관리자를 통해, 사전계산된 난독화된 가중치들이, 보안 스토리지와 같은, 보안 스토리지에 저장되어 있는지 여부를 결정한다. 보 안 스토리지에 저장되어 있는 경우, 블록에서, 상기 프로세서는 상기 보안 스토리지에서 상기 사전계 산된 난독화된 가중치들을 검색한다. 보안 스토리지에 저장되어 있지 않은 경우, 블록에서, 상기 프 로세서는, 예를 들면, 계산 프로세서를 통해, 예를 들면, AI 모델의 가중치들을 분할(splitting) 및/또는 섭동함으로써, 난독화된 가중치들을 계산한다. 난독화된 데이터는 상기 AI 모델의 구성에 따라 사전계산 단계 시에 또는 블록에서의 런타임 시에 계산될 수 있다. 예를 들면, 상기 TEE 내의 상기 프로세서는, 가중치 행렬 W를 분할 또는 섭동하고, 결과 가중치들을 사전 계산 단계 또는 추론 요청의 수신에 응답한 런타임시에 보 안 스토리지에 저장함으로써, 데이터를 난독화할 수 있다. 도 7를 참조하면, 도 7은, 본 개시의 다양한 실시예들에 따른, 덧셈 분할(additive splitting) 및 위임 행렬 곱 셈(delegating matrix multiplication)에 의해 모델 파라미터들을 난독화하는 예시적 프로세스를 도시한 다. 예를 들면, 덧셈 분할을 수행하기 위해, TEE 내의 상기 프로세서는, 가중치 행렬 또는 벡터의 각 성분 (entry) w에 대해, 각 성분 w를 합이 w인 둘 이상의 부분들로 랜덤하게 분할한다. 예를 들면, w는 w = w1 + w2 가 되도록 두 부분으로 분할될 수 있다. 일부 실시예들에서, 이는, 오버헤드(overhead)를 줄이기 위해, 한 번 수행되어 상기 보안 스토리지에 저장될 수 있다. 본 예에서, w1을 생성하기 위해, 상기 프로세서는 미리 결정된 범위 내에서 실수를 w1으로 랜덤하게 선택한다. 하나의 예시적 범위는 이며, 여기서 p는 부동소수점 수 정밀도(floating point number precision)이고 k 및 m은, 임의의 i에 대해, 가 오버플 로우(overflow)를 야기할 정도로 너무 크지 않거나 또는 상기 부동소수점 수 정밀도를 넘어설 정도로 너무 작지 않다는 것에 기초하여 도출된 작은 양의 정수들이다. 다음으로 상기 프로세서는 w2 = w - w1을 설정할 수 있다. 도 7에 도시한 바와 같이, 덧셈 분할의 이 예는 이에 따라, 보다 과중한 계산을 위해, 예를 들면, 가속기 에 의한 사용을 위해, 비-TEE로 전달될 수 있는, 두 행렬들 W1 및 W2를 생성한다. 일부 실시예들에서, 가속 기는, W1 및 W2를 개별적으로 입력 벡터 X와 곱하여 Z1 및 Z2를 산출함으로써, 행렬 곱셈들과 같은 보다 과 중한 계산들을 수행할 수 있으며, 여기서 Z1 및 Z2는 각각 상기 입력 벡터 X와 W1 및 W2를 곱한 결과들이다. Z1 및 Z2는 TEE로 다시 전달되어 상기 계층 출력 Z로 재결합된다. W는 몇 개의 행렬로도 분할될 수 있음을 이 해할 것이다. 도 7에 도시한 바와 같은 일부 실시예들에서, 상기 데이터를 더 모호하게 하기 위해, W1 및 W2는, W1의 각 w를 세트 A 내의 랜덤 상수 ai와 곱하여 행렬 W'을 산출하고 W2의 각 w를 세트 B 내의 랜덤 상수 bi와 곱하여 행렬 W\"를 산출함으로써, 섭동될 수 있다. 도 7에 도시한 바와 같이, 상이한 a 값들 또는 상이한 b 값들이 각각 W1 및 W2의 상이한 행들(rows)에 사용될 수 있다. 본 프로세스에서의 연산들(operations) 중 어떤 것에서도 결과적 인 값들은 반올림 또는 반내림될 수 있다. 일부 실시예들에서, W1에 대한 랜덤 값들 ai 및 bi는 의사 난수 (pseudorandom number) 생성기를 이용하여 생성될 수 있다. 본 예에서, 행렬 곱셈을 비-TEE에 위임하기 위 해 두 행렬들 W' and W\"는 비-TEE로 전달되며, 여기서 비-TEE는 W' 및 W\" 각각과 입력 벡터 X의 행 렬 곱셈을 수행하여 Z' = XW' 및 Z\" = XW\"이 되도록 한다. 비-TEE는, 실제 출력 Z의 복원을 수행하기 위해, Z' 및 Z\"를 TEE로 전달한다. 따라서, 비- TEE는 본 예에서 실제(real) 모델 파라미터들을 결코 보지 못한다. 일부 실시예들에서, X는 제1 계층에 대 한 실제 입력들일 수 있으며, 비-TEE에 액세스할 수 있는 악성 당사자가 상기 계산들을 리버싱하여 실제 파라미터들, 입력, 또는 출력들을 획득할 수 없도록, X는 후속 계층들을 위해 TEE에 의해 난독화될 수 있 다. TEE에 의해 실제 출력 Z를 복원하기 위해, 상기 프로세서는 Z'의 각 z를, 이전에 상기 난독화 프로세 스에서 W'을 산출하는 데 이용된, 상응하는 a 값으로 나눈다. 유사하게, 상기 프로세서는 Z\"의 각 z를, 이전에 상기 난독화 프로세스에서 W\"를 산출하는 데 이용된, 상응하는 b 값으로 나눈다. Z를 완전히 복원하기 위해, Z1 및 Z2는 가산적으로 결합(additively combined)되어 도 7에 도시된 바와 같이 Z를 제공한다. 도 6으로 다시 돌아가면, 모델 파라미터들 또는 입력들을 난독화하는 다른 예시적 기법들은 곱셈 분할 (multiplicative splitting), 개별 선형 변환(individual linear transformation), 배치 선형 변환(batch linear transformation), 또는 희소 랜덤화(sparse randomization)를 포함할 수 있다. 상기 TEE에 의해 데이터 를 더 모호하게 하기 위해 본 개시에서 설명하는 난독화 기법들은 결합될 수도 있음을 이해할 것이다. 본 개시의 다양한 실시예들에서 곱셈 분할은, 가중치 행렬 또는 벡터의 각 가중치 w에 대해, 가중치 w를 가 되도록 곱(product)이 w인 둘 이상의 부분들로 분할하는 단계를 포함한다. 덧셈 분할과 마찬 가지로, w1을 생성하기 위해, 상기 프로세서는 미리 결정된 범위 내에서 실수를 w1으로서 랜덤하게 선택한다. 하 나의 예시적 범위는 이며, 여기서 p는 부동소수점 수 정밀도이고 k 및 m은, 임의의 i에 대해, 가 오버플로우를 야기할 정도로 너무 크지 않거나 또는 상기 부동소수점 수 정밀도를 넘어설 정 도로 너무 작지 않다는 것에 기초하여 도출된 작은 양의 정수들이다. 다음으로 상기 프로세서는 를 설정할 수 있다. 덧셈 분할과 관련하여 나타낸 바와 같이, W1 및 W2 내의 성분들(entries)은, 상기 AI 모델을 처리하는 데 이용되는 구성에 기초하여, W' 및 W\"를 산출하도록 더 섭동될 수 있다. 개별 선형 변환을 수행하기 위해, 상기 행렬 또는 벡터의 각 성분 w에 대해, 상기 프로세서는 성분 w를 aw + b로 변경한다. 덧셈 또는 곱셈 분할에서와 같이 w1에 대해 랜덤 값들을 선택하는 것과 유사하게, a 및 b 는 aw + b가 너무 크거나 너무 작지 않도록 선택될 수 있다. a = 1 또는 b = 0으로 설정하는 것과 같이, 특별한 경우들이 이용될 수도 있으며, 이에 따라, 각 성분 w는 w + b 또는 aw로 각각 변경된다. 배치 선형 변환을 수행하기 위해, 전체 행렬 또는 벡터에 대해 또는 상기 행렬 또는 벡터의 각 행(row) 또는 열(column)에 대해, 상기 프로세서는 상기 행렬 또는 벡터 W 를 aW + B로 변경한다. 덧셈 또는 곱셈 분할에서와 같이 w1에 대해 랜덤 값들을 선택하는 것과 유사하게, a 및 B 는 aW + B가 너무 크거나 너무 작지 않도록 선택될 수 있다. a = 1 또는 B = 0으로 설정하는 것과 같이, 특별 한 경우들이 이용될 수도 있으며, 이에 따라, W는 W + B 또는 aW로 각각 변경된다. 희소 랜덤화를 수행하기 위 해, 상기 프로세서는 W에서 여러 성분들 w를 랜덤하게 선택하고 이들 선택된 성분들을, 예를 들면, 분할 (splitting) 또는 선형 변환을 통해, 섭동한다. 희소 랜덤화는 계산 오버헤드를 감소시키는 데 이용될 수 있다. 일부 실시예들에서, W의 각 성분은 확률 p로 선택될 수 있다. 일부 실시예들에서, k개의 성분들이 W의 각 행 또 는 열에서 랜덤하게 선택될 수 있다. 블록에서, 상기 프로세서는 행렬 곱셈, 컨볼루션, 또는 기타 계산-과중 연산들을, 가속기와 같은, 상 기 비-TEE에 위임하고, 상기 난독화된 가중치들 및 임의의(any) 난독화된 입력 데이터를 상기 비-TEE에 제공한 다. 일부 실시예들에서, 제1 계층 입력들은 난독화되지 않는다. 블록에서, 상기 프로세서는 상기 비-TEE로 부터 계산 결과들을 수신한다. 블록에서, 상기 프로세서는 분할된 값들을 재결합하고 및/또는 섭동들을 리 버싱함으로써 상기 결과들의 노이즈를 제거하거나(de-noise) 또는 복원한다. 결정 블록에서, 상기 TEE 내 의 상기 프로세서는 상기 최종 출력에 도달하기 위해 상기 AI 모델로부터 추가적인 계층들이 처리되어야 하는지 여부를 결정한다. 그러한 경우, 블록에서, 상기 프로세서는, 상기 AI 모델의 다음 계층에 이용될 난독화된 입력 데이터를 제공하기 위해, 상기 계층 출력을 난독화한다. 본 개시의 다양한 실시예들에서 설명하는 바와 같 이, 다음 계층 입력을 위해 상기 계층 출력들을 난독화하는 것은 상기 비-TEE가 상기 모델 파라미터들을 파악하 는 것을 방지한다. 일부 실시예들에서, 상기 TEE 내의 상기 프로세서는 또한, 활성화 함수들의 적용 또는 풀링 (pooling)의 수행과 같은, 다른 계층 함수들을 수행할 수 있다. 프로세스는 결정 블록으로 다시 이동하여 상기 보안 스토리지에서 더 많은 난독화된 가중치들이 제공 되는지 여부를 결정한다. 일부 실시예들에서, 특정한 수의 난독화된 가중치 세트들이 상기 보안 스토리지에 저 장될 수 있다. 예를 들면, 7개의 난독화된 가중치 세트들이 보안 스토리지에 저장된 경우, 프로세스는 블 록에서 다시 결정 블록으로 루프-반복하고(loop), 모든 세트들이 사용될 때까지, 블록에서 상기 저장된 난독화된 가중치들을 검색할 수 있다. 7개의 세트들 모두를 사용하는 경우, 상기 프로세서는, 상기 AI 추론에 대한 최종 출력이 도출될 때까지, 매 계층마다 블록에서 추가적인 세트들을 생성할 수 있다. 블록 에서, 상기 TEE 내의 상기 프로세서는 상기 AI 모델로부터의 최종 결과들에 기초하여, 추론 결과를 결정한 다. 블록에서, 상기 프로세서는 상기 추론 결과를 상기 비-TEE로 전달하여 상기 결과가 사용자에게 수여되 거나 또는 달리 이용되도록 한다. 상기 프로세스는 블록에서 종료된다. 도 6은 AI 모델 파라미터 난독화 프로세스의 일 예를 도시하고 있지만, 도 6에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 일련의 단계들로 도시되어 있지만, 도 6의 다양한 단계들은 중첩되거나, 병렬로 발생하거나, 상이한 순서로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 특정 예로서, 일부 실시예들에서, 결정 블록 은, 효율성을 높이기 위해, 오직 제1 루프에서만 수행될 수 있다. 상기 제1 루프 시, 상기 프로세서가 저 장된 난독화된 가중치들이 없다고 결정하는 경우(이는 현재 저장된 다른 난독화된 가중치들이 없을 가능성이 높 음을 나타냄), 이 확인(check)은 후속 루프들에서는 스킵(skip)될 수 있다. 결정 블록은 또한, 상기 TEE가 데이터의 사전계산을 수행하지 않도록 미리 구성된 경우, 회피될 수 있다.도 8a 및 도 8b는 본 개시의 다양한 실시예들에 따른 예시적 TEE 사전계산 프로세스를 도시한다. 설명의 편의를 위해, 프로세스는 도 1의 상기 전자 장치, 상기 외부 전자 장치들(102, 104) 또는 서버 중 어떤 것의 프로세서(들)에 의해 실행되거나 또는 달리 이용되는 것으로 설명될 수 있다. 일부 실시예들 에서, 프로세스는 도 4a 및 도 4b와 관련하여 설명된 아키텍처에 의해 이용될 수 있다. 그러나, 프로 세스는 어떤 적절한 장치(들)에 의해서도 그리고 어떤 적절한 시스템에서도 이용될 수 있다. 본 개시의 일부 실시예들에서, 가중치들을 분할 및/또는 섭동함으로써 생성된 랜덤화된 노이즈-있는(noisy) 가 중치 행렬들 또는 벡터들과 같은, 난독화된 데이터의 사전계산은 전자 장치가 유휴 상태인(idle) 동안 수행될 수 있다. 결과적으로, 난독화된 데이터는, 보안 스토리지와 같은, 보안 스토리지에 저장되어 다음 AI 추론 요청에 사용될 준비가 되어 있게 된다. 상기 가중치들의 사전계산은 AI 추론을 처리하는 런타임 시 효율성을 높 일 수 있다. 도 8a에 도시한 바와 같이, 블록에서, 상기 프로세서는, 예를 들면, 구성 관리자와 같은 구성 관리자를 통해, 난독화된 데이터의 사전계산을 위한 설정들을 포함하는 구성 데이터(configuration data) 를 수신한다. 상기 구성 데이터는, 사전계산을 얼마나 자주 수행할지, 보안 스토리지에 얼마나 많은 사전계산들 을 저장할지, 및/또는 난독화된 데이터를 언제 사전계산할지(예를 들면, 모델의 전개(deployment) 시간, 상기 전자 장치가 유휴 상태인 때, 상기 전자 장치가 충전 중인 때, 하루 중 특정 시간, 및/또는 기타 시간들)에 대 한 초기 설정과 같은, 설정들을 포함할 수 있다. 일부 실시예들에서, 상기 초기 설정들은, 상기 프로세서가 상 기 장치를 이용하여 수행되는 AI 추론들의 빈도(frequency)를 결정할 때까지, 사전계산을 제공하지 않을 수 있 다. 블록에서, 상기 프로세서는, AI 서비스와 같은, AI 서비스 및/또는, AI 추론들을 요청하는, 애플리케 이션과 같은, 애플리케이션들의 사용 빈도를 추적한다. 예를 들면, 상기 프로세서는 일주일과 같은 일정 시간 동안 AI 추론이 요청되는 횟수를 기록할(log) 수 있다. 상기 AI 추론들은 또한, 사용되는 특정 AI 모델에 기초하여, 분류 또는 범주화될 수 있다. 결정 블록에서, 상기 프로세서는, 상기 장치가 유휴 상태인지 또 는 상기 설명한 바와 같은 다른 시간들인지 여부와 같이, 난독화된 모델 파라미터들을 사전계산할 적절한 시간 에 도달했는지 여부를 결정한다. 그렇지 않은 경우, 프로세스는 블록으로 돌아간다. 그 외의 경우, 블록에서, 상기 프로세서는, 상기 구성 데이터 및 AI 서비스 및 애플리케이션 사용의 추적 에 기초하여, 저장할 난독화된 가중치 세트의 수를 결정한다. 일부 실시예들에서, 제1 모델을 이용한 이미지 검 출을 위한 AI 추론이 일주일에 세 번 요청되는 경우, 상기 프로세서는, 적절한 시간에, 이미지 검출 AI 모델과 함께 사용하기 위해 세 개의 난독화된 모델 파라미터 세트들이 생성되어야 한다고 결정할 수 있다. 이는 세 개 의 이미지 검출 추론 요청들을 수행하기에 충분한 난독화된 모델 파라미터들을 제공하여, 일주일 동안의 AI 추 론 요청들의 추정량에 대비한다. 본 예에서, 상기 구성 설정들은, 난독화된 모델 파라미터들이 소진된 보안 스 토리지를 보충하기 위해, 사전계산이 오직 일주일에 한 번만 수행되도록 할 수 있다. 상기 설정들이 상기 장치 가 유휴 상태이거나 충전 중일 때마다 세트들이 생성될 수 있도록 하는 경우와 같이, 사전계산이 보다 자주 수 행되는 실시예들에서, 상기 프로세서가 상기 보안 스토리지에 세 개의 세트들이 유지되어야 하지만 단지 하나의 세트만 남아 있다고 결정하는 경우, 두 개의 세트들이 더 사전계산될 수 있다. 다른 예로서, 사용자가, 하루에 20번과 같이, 보다 자주 발화(utterance) 추론들을 요청하는 경우, 상기 프로세서는 하루 사용량(usage)의 변동 (variations)을 감당하기 위해 30개의 난독화된 세트들 또는 추정되는 주간 사용량을 감당하기 위해 210개의 세 트들(상기 보안 스토리지의 크기가 허용하는 경우)을 생성할 것을 결정할 수 있다. 세트들을 생성하는 시간은, 매시간, 매일, 매주, 또는 매월과 같이, 어떤 시간이라도 될 수 있음을 이해할 것이다. 생성할 세트들의 수는 상기 프로세서가 AI 모델이 사용될 것으로 추정하는 시간 동안의 총 횟수에 비례하지 않을 수 있다는 것도 또한 이해할 것이다. 예를 들면, 상기 프로세서는 사용자가 발화 검출 AI 모델을 일주일에 50번 사용한다고 결정할 수 있지만, 상기 프로세서는 단지 25개의 세트들만 생성할 수 있다. 일부 실시예들에서, 사전계산을 위해 생성할 타이밍 및 생성할 세트 수를 제어하기 위한 정확한(exact) 파라미터들은 모델 개발자에 의해 구성될 수 있다. 사용자가 마침 일정 시간 동안 평소보다 더 많은 AI 추론들을 요청하는 경 우와 같이, 사전계산된 파라미터들인 소진된 경우, 추가적인 난독화된 파라미터들이 런타임에 계산될 수 있다는 것도 또한 이해할 것이다. 일부 실시예들에서, 사전계산될 수 있는 난독화된 가중치 세트들의 수를 제한하는 레이트 제한(rate limit)이 이용될 수 있다. 섭동된 가중치들의 사전계산은 장치 하드웨어 또는 소프트웨어로부터 전형적으로 생성되는 랜 덤성(randomness)을 이용할 수 있다. 상기 프로세서는 사전계산 시 랜덤성이 소진되지 않게 하도록 구성될 수 있다. 이는 전형적으로, 매우 짧은 시간에 대량의 섭동된 가중치들이 계산되어야 하는 경우, 발생한다. 랜덤성 이 소진된 후, 섭동된 가중치들을 생성하는 것은 어려울 수 있다. 그러한 상황을 피하기 위해, 레이트 제한 정책(rate limit policy)이 상기 TEE에 의해 시행될 수 있다. 생성할 난독화된 파라미터 세트들의 수를 결정하기 위한 사용 빈도 및 기타 기준(criteria) 외에도, 난독화된 파라미터들의 사전계산은, 하드웨어 및 소프트웨어 구성 및 사전계산 시 시스템 부하(load)와 같은 장치들의 세부사항(specifics)에 따라, 적절한 레이트에서 수행 될 수 있다. 상기 레이트 제한은, 생성할 난독화된 파라미터 세트들의 수에 대한 제한 또는 상한(ceiling)으로 작용하는, 문턱 파라미터 수(threshold number of parameters)일 수 있다. 블록에서, 상기 프로세서는, 예를 들면, 상기 모델 관리자를 통해, 상기 보안 스토리지로부터 상기 AI 모 델에 대한, 가중치들과 같은, 모델 파라미터들을 검색한다. 블록에서, 상기 프로세서는 상기 구성 데이터 에 기초하여 파라미터 값들을 변경함으로써 상기 검색된 모델 파라미터들을 난독화한다. 예를 들면, 상기 구성 데이터는 난독화된 파라미터들이 덧셈 분할, 곱셈 분할, 개별 선형 변환, 배치 선형 변환, 및 희소 랜덤화 중 하나 이상에 의해 생성되도록 할 수 있다. 블록에서, 상기 사전계산된 난독화된 가중치들은 상기 TEE 내의 보안 스토리지에 저장된다. 결정 블록에서, 상기 프로세서는 블록에서 결정된 특정 수의 난독화된 파 라미터 세트들이 생성 및 저장되었는지 여부를 결정한다. 그렇지 않은 경우, 프로세스는 블록으로 돌 아가 상기 AI 모델에서 추가적인 파라미터들을 검색한다. 그 외의 경우, 프로세스는, 도 8b에 도시한 바와 같이, 블록으로 이동한다. 블록에서, 상기 프로세서는 하나 이상의 런타임 추론 요청들을 수신한다. 결정 블록에서, 상기 프로 세서는 상기 하나 이상의 추론 요청들의 수가 상기 레이트 제한 정책에 의해 설정된 상기 레이트 제한을 초과하 는지 여부를 결정한다. 일부 실시예들에서, 사전계산 시 랜덤성이 소진되지 않도록 하는 것 외에도, 상기 프로 세서는 또한, 런타임 계산 시에, 예를 들면, 블록들(808 내지 814)에서 생성된 것과 같은, 사전계산된 파라미터 들이 다른 추론 요청들 동안 이미 사용된 경우에 추론 요청이 수신될 때, 랜덤성이 소진되지 않게 하도록 구성 될 수 있다. 상기 레이트 제한에 도달한 경우, 블록에서, 상기 프로세서는 상기 하나 이상의 추론 요청들 에 대해 서비스 거부 응답을 발행한다. 추론 요청들이 추론 레이트 제한을 초과하는 높은 레이트로 들어오는 경 우, 상기 TEE는, 경우에 따라, 이것이 고장(malfunction)의 증상을 나타내거나 또는 악성 활동(malicious activity)을 나타낼 수 있기 때문에, 상기 요청들의 서비스를 거부할 수 있다. 정당한(legitimate) 요청들에 대 한 서비스를 거부하는 가능성을 줄이기 위해, 사전계산된 난독화된 파라미터들의 수에 대해 충분한 마진 (margin)이 허용될 수 있고, 이에 따라 합리적이고(reasonable) 및/또는 정당한(legitimate) 추론 버스트 레이 트 인상(inference burst rate hike)이 수용될 수 있다. 블록에서 서비스의 거부가 발행되는 경우, 프로세 스는 블록에서 종료된다. 상기 프로세서가, 결정 블록에서, 상기 추론 레이트 제한에 도달하지 않았다고 결정하는 경우, 프로세스 는 결정 블록으로 이동한다. 결정 블록에서, 상기 프로세서는 이전에 계산된 파라미터들이 소진 되었는지 여부를 결정한다. 그러한 경우, 블록에서, 상기 프로세서는 난독화된 파라미터 세트의 수를 조절 하고 새로운 난독화된 파라미터들을 계산한다. 프로세스는 다음에, 상기 프로세서가 상기 새롭게 생성된 난독화된 가중치들이 상기 레이트 제한들을 초과하는지 여부를 결정하는, 결정 블록으로 다시 이동하여, 랜덤성이 소진되지 않도록 한다. 상기 레이트 제한에 도달한 경우, 상기 프로세서는 블록에서 서비스의 거 부를 발행할 수 있다. 결정 블록에서, 파라미터들이 소진되지 않은 경우, 또는 블록을 통해 새로운 난독화된 파라미터들이 성공적으로 생성된 경우, 프로세스는 블록으로 이동한다. 블록에서, 본 명세서에 개시된 다양한 실시예들에 따라, 상기 프로세서는 수신된 추론 요청에 응답한다. 결정 블록에서, 상기 프로세서는 블록 에서 수신된 추가적인 요청들이 처리되어야 하는지 여부를 결정한다. 그러한 경우, 프로세스는 결정 블록으로 다시 이동한다. 그렇지 않은 경우, 프로세스는 블록에서 종료된다. 도 8a 및 도 8b는 TEE 사전계산 프로세스의 일 예를 도시하고 있지만, 도 8a 및 도 8b에 대해 다양한 변경이 이 루어질 수 있다. 예를 들면, 일련의 단계들로 도시되어 있지만, 도 8a 및 도 8b의 다양한 단계들은 중첩되거나, 병렬로 발생하거나, 상이한 순서로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 특정 예로서, 프로세스(80 0)는 상기 TEE 내에서 수행되는 것으로 설명되어 있지만, 블록은 상기 TEE 외부에서 수행될 수 있다. 예를 들면, 비-TEE 프로세스들 또는 애플리케이션들은 상기 애플리케이션들 또는 AI 서비스가 AI 추론을 요청하는 때 를 추적하고 AI 요청을 상기 TEE에 전송할 수 있다. 결정 블록의 요건들에 도달한 경우, 상기 비-TEE 프로 세스들은, 상기 TEE가 추적된 빈도 데이터를 이용하여 난독화된 모델 파라미터들을 생성하도록, 상기 추적된 빈 도 데이터를 상기 TEE에 제공할 수 있다. 다른 특정 예로서, 일부 실시예들에서, 블록은, 예를 들면, 상기 구성 데이터가, 일주일에 한 번 또는 상기 장치가 유휴 상태인 경우와 같이, 특정 간격으로 또는 특정 시간에고정된 수의 모델 파라미터 세트들이 생성되도록 하는 경우, 수행되지 않을 수 있다. 도 9는 본 개시의 다양한 실시예들에 따른 예시적 행렬 곱셈 프로세스를 도시한다. 설명의 편의를 위해, 프로세스는 도 1의 상기 전자 장치, 상기 외부 전자 장치들(102, 104) 또는 서버 중 어떤 것의 프로세서(들)에 의해 실행되거나 또는 달리 이용되는 것으로 설명될 수 있다. 일부 실시예들에서, 프로세 스는 도 4a 및 도 4b와 관련하여 설명한 아키텍처에 의해 이용될 수 있다. 그러나, 프로세스는 어떤 적절한 장치(들)에 의해서도 그리고 어떤 적절한 시스템에서도 이용될 수 있다. 도 9에 도시한 바와 같이, 행렬 곱셈을 수행하는 목표는 Z = WX를 계산하는 것이며, 여기서 W는 가중치 행렬이 고, X는 입력이며, Z는 출력이다. 도 9의 예에서, 상기 예를 명확히 예시할 목적으로 실제(actual) 값들이 제공 되지만, 어떤 값이라도 이용될 수 있음을 이해할 것이다. 비-TEE가 AI 모델의 실제 모델 파라미터들에 액 세스하는 것을 방지하기 위해, 가중치 행렬 W는, 난독화된 가중치들을 비-TEE에 제공하기 전에, TEE 에 의해 난독화된다. 본 예에서, 상기 프로세서는 덧셈 분할에 의해 W를 분할한다. 덧셈 분할을 수행하는 하나 의 예시적 프로세스는 앞에서 설명되었다. 도 9에서의 덧셈 분할의 예는 두 개의 행렬들 W1 및 W2를 생성한다. 그러나, W는 몇 개의 행렬들로도 분할될 수 있음을 이해할 것이다. 상기 데이터를 더 모호화하기 위해, 상기 TEE 내의 상기 프로세서는, W1의 각 행을 랜덤 상수 ai와 곱하여 행렬 W'를 산출하고 W2의 각 행을 세트 B 내의 랜덤 상수 bi와 곱하여 행렬 W\"를 산출함으로써, W1 및 W2를 섭동한다. 본 프로세스의 단계들 중 어떤 것에서도 결과적인 값들은 반올림되거나 또는 반내림될 수 있다. 일부 실시예들 에서, W1, ai 및 bi에 대한 랜덤 값들은 의사 난수 발생기를 이용하여 생성될 수 있다. 상기 프로세서는, 예를 들면, 가속기에 의해, 행렬 곱셈을 수행하기 위해, 두 개의 행렬들 W' 및 W\"를 비-TEE로 전달한다. 비-TEE는, Z' = XW' 및 Z\" = XW\"가 되도록, W' 및 W\" 각각에 입력 X를 곱한다. 비-TEE는, 실제 출력 Z의 복원을 수행하기 위해, Z' 및 Z\"를 TEE로 전달한다. 따라서, 비-TEE는 실제(real) 모델 파라미터 들을 결코 보지 못한다. 상기 비-TEE는 Z' 및 Z\"를 볼 수 있고 각 행 i에 대해 식 를 수립하려고 시도할 수 있지만, 비-TEE는 ai 및 bi에 대한 값들을 알지 못하기 때문에, 비-TEE는 실제 결과들을 결정할 수 없다. 실제 출력 Z를 복원하기 위해, TEE 내의 상기 프로세서는 Z'의 각 성분을 상기 난독화 프로세스에서 이전 에 사용된 동일한 상수들 ai로 나누어 Z1를 산출한다. 유사하게, 상기 프로세서는 Z\"의 각 성분을 상기 난독화 프로세스에서 이전에 사용된 동일한 상수들 bi로 나누어 Z2를 산출한다. 진정한 결과 Z = WX를 완전히 복원하기 위해, Z1 및 Z2는 가산적으로 결합되어 Z를 산출하고, 결과적인 Z는 신경망 네트워크 또는 AI 모델의 다음 계층 에 사용될 수 있다. 도 9는 행렬 곱셈 프로세스의 일 예를 도시하고 있지만, 도 9에 대해 다양한 변경이 이루어질 수 있다. 예를 들 면, 일련의 단계들로 도시되어 있지만, 도 9의 다양한 단계들은 중첩되거나, 병렬로 발생하거나, 상이한 순서로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 또한, 프로세스는 예로서 덧셈 분할을 이용하고 있지만, 곱셈 분할, 개별 선형 변환, 배치 선형 변환, 또는 희소 랜덤화와 같은, 다른 기법들이 모델 파라미터들을 난독 화하는 데 이용될 수 있다. 컨볼루션 심층 학습 네트워크는, 계산 비용이 많이 드는, 컨볼루션 계층들(convolutional layers) 및 완전 연결 계층들(fully connected layers)을 포함한다. 예를 들면, 이러한 계층들에서의 행렬 곱셈들은 계산이 과중하다. 상기 컨볼루션 계층들에서의 행렬 곱셈들은 필터 W 및 임의의 서브-행렬 Xs를 이용한 WXs의 계산을 포함한다. 상 기 완전 연결 계층들에서의 행렬 곱셈들은 모델 파라미터들 W 및 입력 X를 이용한 WX의 계산을 포함한다. 이들 과 같은 계산-과중 태스크들은 상기 비-TEE에 위임될 수 있지만, 반면에 오버헤드가 적은 계산들(예를 들면, 데 이터의 난독화 및 활성화 함수들의 수행, 풀링(pooling), 정규화(normalization) 또는 표준화 (standardization), 또는 기타 태스크들)은 상기 TEE에 의해 수행될 수 있다. AI 모델의 다수의 계층들을 수행하는 경우, 상기 비-TEE로부터 데이터를 모호한 상태로 유지하는 데 문제가 발 생할 수 있다. 예를 들면, 노이즈 제거 이후의 출력 Z가 후속 처리를 위해 상기 비-TEE에 제공되는 경우, 상기 비-TEE에 액세스할 수 있는 악성 사용자 또는 애플리케이션은 식 Z = WX를 수립할 수 있다. 충분한 수의 쿼리들 (queries) 이후에, 상기 악성 사용자 또는 애플리케이션은 잠재적으로 W를 풀고 상기 모델 파라미터들에 액세스할 수 있다. 이 문제를 해결하기 위해, 완전 연결 계층들에 대해, 상기 TEE 내의 상기 프로세서는, 활성화 함수 X = f(Z)를 실행하고, 예를 들면, 선형 변환에 의해, 다음 계층 입력 X에 노이즈를 더하여 X' = cX + D가 되도 록 하는, 태스크를 위임 받을 수 있다. 상기 프로세서는 난독화된 입력 X'를 상기 비-TEE에 전송한다. 다음 계 층을 계산하기 위해, 상기 비-TEE 내의 상기 프로세서는 Z' = W'X'가 되도록 난독화된 출력을 계산한다. 상기 TEE 내의 상기 프로세서는 Z = (Z' - W'D) / c에 의해 실제 출력을 복원할 수 있다. 컨볼루션 계층들에 대해, 상기 TEE 내의 프로세서는 출력 Z에 대해 풀링(pooling)을 수행하고 풀링 결과들을 상 기 비-TEE에 전송할 수 있으며, 이에 따라, 상기 비-TEE에 액세스할 수 있는 사용자 또는 애플리케이션이 상기 모델 파라미터들을 결정하는 것이 더 어려워진다. 본 개시의 다양한 실시예들에서 설명되는 바와 같이, 난독화 된 가중치들의 사전계산은, 상기 TEE에서의 활성화 및 풀링과 같은 태스크들을 수행하는 것의 효율성 영향 (efficiency impact)을 완화하기 위해, 수행될 수 있다. 도 10은 본 개시의 다양한 실시예들에 따른 예시적 컨볼루션 변환 다이어그램을 도시한다. 컨볼루션은 계 산 비용이 많이 드는 연산일 수 있다. 컨볼루션은 입력 행렬 X에 걸쳐 필터 W를 슬라이딩하는 단계 및 X의 각 서브-행렬 Xs와 W의 내적(dot product)을 계산하는 단계를 포함한다. 따라서, 컨볼루션 연산은 상기 비-TEE 가 속기에 위임될 수 있지만, 필터 W는 상기 비-TEE에 제공되지 않을 수 있거나 또는 모델 파라미터들이 발견 가능 해질(discoverable) 수 있다. 다이어그램은, 필터 데이터를 행렬 W로 결합하고 입력 데이터를 행렬 X로 결합함으로써, 컨볼루션을 Z = WX의 행렬 곱셈으로 변환하는 단계를 도시한다. 그러나, 입력 X 및 출력 Z는 행 렬들이므로, 상기 비-TEE에 액세스할 수 있는 악성 사용자 또는 애플리케이션은 각 행 i 및 각 열 j에 대해 식 를 수립할 수 있어, 상기 악성 사용자 또는 애플리케이션은 두 개를 초과하는 식들로 변수들 ai 및 bi에 대한 해를 구하여 상기 모델 파라미터들에 액세스할 수 있다. 이 문제를 해결하기 위해, 상기 비-TEE 에 의해 Z = WX의 행렬 곱셈을 수행한 후, 상기 TEE 내의 프로세서는 출력 Z에 대해 풀링(pooling)을 수행하고 오직 Z의 풀링 결과만을(Z 자체가 아니라) 상기 비-TEE에 전송할 수 있다. 컨볼루션 데이터를 행렬 곱셈으로 변 환한 후, 상기 행렬 곱셈은 본 개시의 AI 모델 보호의 다양한 실시예들에서 이용된다. 도 11a, 도 11b, 도 11c, 도 11d, 및 도 11e는 본 개시의 다양한 실시예들에 따른 예시적 다층 AI 모델 보호 프 로세스를 도시한다. 보다 구체적으로, 도 11a는 프로세스의 컨볼루션 계층 부분을 도시하고, 도 11b는 프로세스의 제1 완전 연결 계층 부분을 도시하고, 도 11c는 프로세스의 제1 완전 연결 계층 부분의 예시적인 신경망 표현을 도시하고, 도 11d는 프로세스의 후속 완전 연결 계층 부분을 도시하며, 도 11e는 프로세스의 후속 완전 연결 계층 부분의 예시적인 신경망 표현을 도시한다. 설명의 편의를 위해, 프로세스는 도 1의 상기 전자 장치, 상기 외부 전자 장치들(102, 104) 또는 서버 중 어 떤 것의 프로세서(들)에 의해 실행되거나 또는 달리 이용되는 것으로 설명될 수 있다. 일부 실시예들에서, 프로세스는 도 4a 및 도 4b와 관련하여 설명한 아키텍처에 의해 이용될 수 있다. 그러나, 프로세스 는 어떤 적절한 장치(들)에 의해서도 그리고 어떤 적절한 시스템에서도 이용될 수 있다. 프로세스는, AI 모델의 컨볼루션 계층들 및 완전 연결 계층들에 사용되는 난독화된 모델 파라미터들에 대 해, 도9 및 도 10에서 설명한 것과 같은, 기법들을 이용한다. 예를 들면, 도 11a에서, 상기 컨볼루션 계층들은, 도 10과 관련하여 설명한 바와 같이, 행렬 곱셈들을 이용하도록 변환된다. 또한, 도 11a, 도 11b, 및 도 11d 각 각에서, 도 9와 관련하여 설명한 바와 같이, 덧셈 분할 및 분할된 행렬들의 섭동이 수행된다. 도 11a에 도시한 바와 같이, 단계에서, TEE 내의 프로세서는 m n 형태의 가중치 행렬 W를 검색한다. 단계에서, 상기 프로세서는 가중치 행렬 W에 대해 덧셈 분할을 수행하여 W = W1 + W2가 되도록 두 개의 행 렬들 W1 및 W2를 생성한다. 단계에서, 상기 프로세서는 랜덤 대각 행렬들 A = [a1, ..., am] 및 B = [b1, ..., bm]를 생성한다. 일부 실시예들에서, A 및 B는 각 요청에 대해 새롭게 생성된다. 단계에서, 상기 프로세서는 섭동된 행렬 들 W' = AW1 and W\" = BW2를 계산함으로써 행렬들 W1 및 W2를 섭동하며, 여기서 W1의 각 i번째 행은 ai로 스케일 링되고 W2의 각 i번째 행은 bi로 스케일링된다. 일부 실시예들에서, 단계들(1102 내지 1108)은, 전술한 바와 같이, AI 추론 요청을 수신하기 전에 사전계산될 수 있다. 단계에서, 비-TEE 내의 프로세서는 입력 X를 생성 또는 수신한다. 단계에서, 비-TEE 내 의 상기 프로세서는 TEE에 가중치들을 요청한다. 단계에서, 섭동된 가중치 행렬들 W' 및 W\"는 TEE로부터 비-TEE 내에 수신된다. 단계에서, 비-TEE 내의 상기 프로세서는 출력들 Z' 및 Z\"를 계산하며, 여기서 Z' = W'X 및 Z\" = W\"X 이다. 단계에서, 상기 프로세서는 출력들 Z' 및 Z\"의 노이 즈를 제거하기 위한 요청을 TEE에 전송한다. 단계에서, TEE 내의 상기 프로세서는 출력들 Z' 및 Z\"의 노이즈를 제거하여 Z1 = [zij / ai, Z'의 각 zij에 대해] 및 Z2 = [zij / bi, Z\"의 각 zij에 대해]가 되도 록 한다. 단계에서, 상기 프로세서는 Z1 및 Z2를 가산적으로 결합하여 Z = Z1 + Z2가 되도록 한다. 단계 에서, TEE 내의 상기 프로세서는 출력 Z에 대해 활성화 및 풀링(pooling)을 수행하여 Y = f(Z)가 되도록 한다. 단계에서, TEE 내의 상기 프로세서는 활성화 및 풀링 Y의 결과들을 비-TEE에 제 공한다. 단계에서, 비-TEE 내의 상기 프로세서는 Y를 다음 계층에 대한 입력으로서 제공한다. 일부 실시예들에서, 단계들(1106 내지 1128)은 상기 AI 모델에서의 모든 컨볼루션 계층들이 처리될 때까지 반복된다 (입력이 이미 제공됨에 따라 단계는 스킵(skip)될 수도 있음). 단계에서, 출력 계층은 상기 컨볼루 션 계층들의 결과를 하나 이상의 완전 연결 계층들로 출력한다. 도 11a에서 수행되는 컨볼루션 프로세스는, 도 2와 관련하여 설명한 바와 같이, 전적으로 상기 TEE 내에서 컨볼 루션들을 수행하는 것보다 더 효율적인 컨볼루션 계산을 제공한다. 예를 들면, 계산이 완전히 상기 TEE 내에서 수행되는 경우, 곱셈 연산들은 의 연산 개수를 가질 수 있고, 덧셈 연산들은 의 연산 개수 를 가질 수 있다. 그러나, W가 행렬이고 X가 행렬인 하기 표 1에 나타낸 바와 같이, 계산들이 도 11a와 같이 분할되는 경우 상기 TEE의 효율성이 향상된다. 비-TEE가 더 많은 계산들을 수행하지만, 상기 비-TEE 는 더 빠른 속도로 계산들을 수행하기 위해 가속기를 이용할 수 있어, TEE에서만 계산하는 것보다 전반적인 이 점을 제공한다. [표 1]"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "제1 완전 연결 계층이 프로세스의 일부로서 처리되는 도 11b에 나타낸 바와 같이, 단계에서, TEE 내의 상기 프로세서는 형태의 가중치 행렬 W를 검색한다. 단계에서, 상기 프로세서는 가 중치 행렬 W에 대해 덧셈 분할을 수행하여 W = W1 + W2가 되도록 두 개의 행렬들 W1 및 W2를 생성한다. 단계 에서, 상기 프로세서는 랜덤 대각 행렬들 A = [a1, ..., am] 및 B = [b1, ..., bm]를 생성한다. 일부 실시 예들에서, A 및 B는 각 요청에 대해 새롭게 생성된다. 단계에서, 상기 프로세서는 섭동된 행렬들 W' = AW1 및 W\" = BW2를 계산함으로써 행렬들 W1 및 W2를 섭동하며, 여기서 W1의 각 i번째 행은 ai로 스케일링되고 W2 의 각 i번째 행은 bi로 스케일링된다. 일부 실시예들에서, 단계들(1132 내지 1138)은, 전술한 바와 같이, AI 추 론 요청을 수신하기 전에 사전계산될 수 있다. 단계에서, 비-TEE 내의 상기 프로세서는, 본 실시예에서 상기 AI 모델의 컨볼루션 계층들로부터의 최종 출력인, 입력 X를 생성 또는 수신한다. 단계에서, 비-TEE 내의 상기 프로세서는 TEE에 가 중치들을 요청한다. 단계에서, 섭동된 가중치 행렬들 W' 및 W\"는 비-TEE에 의해 TEE로부터 수 신된다. 단계에서, 비-TEE 내의 상기 프로세서는 출력들 Z' 및 Z\"를 계산하며, 여기서 Z' = W'X 및 Z\" = W\"X 이다. 단계에서, 상기 프로세서는 출력들 Z' 및 Z\"의 노이즈를 제거하기 위한 요청을 TEE 에 전송한다. 단계에서, TEE 내의 상기 프로세서는 출력들 Z' 및 Z\"의 노이즈를 제거하여 Z1 = [zi/ ai, Z'의 각 zi에 대해] 및 Z2 = [zi / bi, Z\"의 각 zi 에 대해]가 되도록 한다. 단계에서, 상기 프로세 서는 Z1 및 Z2를 가산적으로 결합하여 Z = Z1 + Z2가 되도록 한다. 단계에서, TEE 내의 상기 프로세 서는 출력 Z에 대해 활성화 함수를 수행하여 Y = f(Z)가 되도록 한다. 단계에서, 도 11d에 도시한 바와 같이, 후속 완전 연결 계층이 실행된다. 도 11c에 도시한 바와 같이, 상기 제1 완전 연결 계층에 대해, 상기 프 로세서는 가중치들 W에 의해 입력들 X를 변경하고, 상기 프로세서는 상기 결과들에 활성화 함수를 적용하여 다 음 계층에 대한 출력 Y를 산출한다. 도 11b에서 수행되는 상기 제1 완전 연결 계층의 프로세스는, 도 2와 관련하여 설명한 바와 같이, 전적으로 상 기 TEE 내에서 계산을 수행하는 것보다 더 효율적인 계산을 제공한다. 예를 들면, 계산이 전적으로 상기 TEE 내 에서 수행되는 경우, 곱셈 연산들은 의 연산 개수를 가질 수 있고, 덧셈 연산들은 의 연산 개수 를 가질 수 있다. 그러나, W가 행렬이고 X가 n차원 벡터인 하기 표 2에 나타낸 바와 같이, 계산들이 도 11b와 같이 분할되는 경우 상기 TEE의 효율성이 향상된다. 비-TEE가 더 많은 계산들을 수행하지만, 상기 비-TEE 는 더 빠른 속도로 계산들을 수행하기 위해 가속기를 이용할 수 있어, TEE에서만 계산하는 것보다 전반적인 이 점을 제공한다. [표 2]"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 제1 완전 연결 계층 이후의 후속 완전 연결 계층이 프로세스의 일부로서 처리되는 도 11d에 도시한 바와 같이, 단계에서, TEE 내의 상기 프로세서는 형태의 가중치 행렬 W를 검색한다. 단계 에서, 상기 프로세서는 가중치 행렬 W에 대해 덧셈 분할을 수행하여 W = W1 + W2가 되도록 두 개의 행렬들 W1 및 W2를 생성한다. 단계에서, 상기 프로세서는 랜덤 대각 행렬들 A = [a1, ..., am] 및 B = [b1, ..., bm]를 생성한다. 단계에서, 상기 프로세서는 섭동된 행렬들 W' = AW1 및 W\" = BW2를 계산함으로써 행렬들 W1 및 W2를 섭동 하며, 여기서 W1의 각 i번째 행은 ai로 스케일링되고 W2의 각 i번째 행은 bi로 스케일링된다. 또한, 단계 에서, 상기 프로세서는 랜덤 값 c 및 행렬 D 내의 랜덤 값들을 생성한다. 일부 실시예들에서, D는 d개의 0이 아 닌 값들을 갖는 희소 벡터이며 여기서 d << n이다. 일부 실시예들에서, 단계들(1158 내지 1164)은, 전술한 바와 같이, AI 추론 요청을 수신하기 전에 사전계산될 수 있다. 단계에서, TEE 내의 상기 프로세서는(이전의 완전 연결 계층으로부터 X를 받음) 선형 변환을 이용하 여 변환된 X'를 계산하여 X' = cX + D가 되도록 한다. 단계에서, TEE 내의 상기 프로세서는 난독화 된 가중치들 W' 및 W\" 및 난독화된 입력 X'를 비-TEE에 제공한다. 단계에서, 비-TEE 내의 상 기 프로세서는 출력들 Z' 및 Z\"를 계산하며, 여기서 Z' = W'X' 및 Z\" = W\"X'이다. 단계에서, 상기 프로세 서는 출력들 Z' 및 Z\"의 노이즈를 제거하기 위한 요청을 TEE에 전송한다. 단계에서, 상기 프로세서 는 단계에서 수행된 상기 선형 변환을 리버싱함으로써 출력들 Z' 및 Z\"의 노이즈를 제거하여 Z3 = (Z' - W'D) / c 및 Z4=(Z\" - W\"D) / c가 되도록 한다. 단계에서, 상기 프로세서는 단계에서 수행된 섭동 들을 리버싱함으로써 출력들 Z3 및 Z4의 노이즈를 더 제거하여 출력들 Z1 및 Z2를 산출하여, Z1 = [zi / ai, Z3의 각 zi에 대해] 및 Z2 = [zi / bi, Z4의 각 zi에 대해]가 되도록 한다. 단계에서, 상기 프로세서는 Z1 및 Z2 를 가산적으로 결합하여 Z = Z1 + Z2가 되도록 한다. 단계에서, TEE 내의 상기 프로세서는 출력 Z에 대해 활성화 함수를 수행하여 Y = f(Z)가 되도록 한다. 단계에서, 최종 출력에 도달할 때까지, 도 11d와동일한 프로세스를 이용하여 임의의(any) 후속 완전 연결 계층들이 실행된다. 도 11e에 도시한 바와 같이, 상기 제1 계층 이후의 완전 연결 계층들에 대해, 상기 프로세서는 상기 이전 계층으로부터의 출력을 입력들 X로서 취 하고 가중치들 W에 의해 입력들 X를 변경한다. 다음에, 상기 프로세서는, 모든 계층들이 처리될 때까지, 상기 결과들에 활성화 함수를 적용하여 상기 모델 내의 후속 계층에 대한 출력 Y를 산출한다. 도 11d에서 수행되는 상기 후속 완전 연결 계층들의 프로세스는, 도 2와 관련하여 설명한 바와 같이, 전적으로 상기 TEE 내에서 계산을 수행하는 것보다 더 효율적인 계산을 제공한다. 예를 들면, 계산이 전적으로 상기 TEE 내에서 수행되는 경우, 곱셈 연산들은 의 연산 개수를 가질 수 있고, 덧셈 연산들은 의 연산 개 수를 가질 수 있다. 그러나, W가 행렬이고, X가 n차원 벡터이고, D는 d개의 0이 아닌 값들을 갖는 희소 벡터인 표 3에 나타낸 바와 같이, 계산들이 도 11d와 같이 분할되는 경우 상기 TEE의 효율성이 향상된다. 비- TEE가 더 많은 계산들을 수행하지만, 상기 비-TEE는 더 빠른 속도로 계산들을 수행하기 위해 가속기를 이용할 수 있어, TEE에서만 계산하는 것보다 전반적인 이점을 제공한다. [표 3]"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 11a, 도 11b, 도 11c, 도 11d, 및 도 11e는 다층 AI 모델 보호 프로세스의 일 예를 도시하고 있지만, 도 11a, 도 11b, 도 11c, 도 11d, 및 도 11e에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 일련의 단계들로 도시되어 있지만, 도 11a, 도 11b, 도 11c, 도 11d, 및 도 11e에서의 다양한 단계들은 중첩되거나, 병렬로 발생 하거나, 상이한 순서로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 또한, 프로세스는 예로서 덧셈 분 할 및 섭동을 이용하고 있지만, 곱셈 분할, 개별 선형 변환, 배치 선형 변환, 또는 희소 랜덤화와 같은, 다른 기법들이 모델 파라미터들을 난독화하는 데 이용될 수 있다. 도 12는 본 개시의 다양한 실시예들에 따른 예시적 선형 변환 프로세스를 도시한다. 설명의 편의를 위해, 프로세스는 도 1의 상기 전자 장치, 상기 외부 전자 장치들(102, 104) 또는 서버 중 어떤 것의 프로세서(들)에 의해 실행되거나 또는 달리 이용되는 것으로 설명될 수 있다. 일부 실시예들에서, 프로세 스는 도 4a 및 도 4b와 관련하여 설명한 아키텍처에 의해 이용될 수 있다. 그러나, 프로세스 는 어떤 적절한 장치(들)에 의해서도 그리고 어떤 적절한 시스템에서도 이용될 수 있다. 도 12에 도시한 바와 같이, 행렬 곱셈을 수행하는 목표는 Z = WX를 계산하는 것이며, 여기서 W는 가중치 벡터이 고, X는 입력이며, Z는 출력이다. 비-TEE는 W를 알지 못한 채 Z = WX를 계산하는 것이므로, TEE는 W' = aW + B가 되도록 W를 선형 변환할 수 있으며, 여기서 B는 희소 행렬이다. 일부 실시예들에서, a = 1이다. 도 12에 도시된 예는 상기 예를 명확히 예시할 목적으로 실제(actual) 값들을 이용하지만, 어떤 값들이라도 이 용될 수 있음을 이해할 것이다. 가중치 행렬 W의 각 값에 a를 곱하고, B 내의 상응하는 값들이 가산되어 W'를 산출한다. 본 예에서, a 및 B를 생성하기 위해, 상기 프로세서는 미리 결정된 범위들 내에서 a 및 B에 대해 실 수를 랜덤하게 선택한다. 도 12의 단계들 중 어떤 것에서도 결과적인 값들은 또한 반올림되거나 또는 반내림될 수 있다. 난독화된 가중치 행렬 W'는 비-TEE에 제공된다. 가속기와 같은, 상기 비-TEE 내의 프로세서는 Z' = XW'가 되도록 W' 및 입력 벡터 X를 이용하여 행렬 곱셈 을 수행한다. 비-TEE는, 실제 출력 Z의 복원을 수행하기 위해, Z'를 TEE로 전달한다. 따라서, 비- TEE는 실제 모델 파라미터들에 액세스하지 못한다. 실제 출력 Z를 복원하기 위해, TEE 내의 상기 프 로세서는 비-TEE로부터 수신된 Z'를 취하고, 상기 난독화 프로세스에서 이전에 사용된 a 및 B를 이용하고원본 입력 벡터 X를 이용하여, Z = (Z' - BX) / a를 계산한다. AI 모델의 다수의 계층들을 수행하는 경우, 상기 비-TEE로부터 데이터를 모호한 상태로 유지하는 데 문제가 발 생할 수 있다. 예를 들면, 노이즈가 제거된 후의 출력 Z가 후속 처리를 위해 상기 비-TEE에 제공되는 경우, 상 기 비-TEE에 액세스할 수 있는 악성 사용자 또는 애플리케이션은 식 Z = WX를 수립할 수 있다. 충분한 수의 쿼 리들(queries) 이후에, 상기 악성 사용자 또는 애플리케이션은 잠재적으로 W를 풀고 상기 모델 파라미터들에 액 세스할 수 있다. 이 문제를 해결하기 위해, 완전 연결 계층들에 대해, 상기 TEE 내의 상기 프로세서는, 활성화 함수 X = f(Z)를 실행하고, 예를 들면, 선형 변환에 의해, 다음 계층 입력 X에 노이즈를 더하여 X' = cX+D가 되 도록 하는, 태스크를 위임 받을 수 있다. 상기 프로세서는 난독화된 입력 X'를 상기 비-TEE에 전송한다. 다음 계층을 계산하기 위해, 상기 비-TEE 내의 상기 프로세서는 Z' = W'X'가 되도록 난독화된 출력을 계산한다. 상기 TEE 내의 상기 프로세서는 Z = (Z' - W'D) / c에 의해 실제 출력을 복원할 수 있다. 도 12는 선형 변환 프로세스의 일 예를 도시하고 있지만, 도 12에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 일련의 단계들로 도시되어 있지만, 도 12의 다양한 단계들은 중첩되거나, 병렬로 발생하거나, 상이한 순 서로 발생하거나, 또는 몇 번이라도 발생할 수 있다. 또한, 프로세스는 예로서 선형 변환을 이용하고 있 지만, 덧셈 또는 곱셈 분할과 같은, 다른 기법들이 모델 파라미터들을 난독화하는 데 이용될 수 있다. 도 13a, 도 13b, 도 13c, 도 13d, 및 도 13e는 본 개시의 다양한 실시예들에 따른 다른 예시적 다층 AI 모델 보 호 프로세스를 도시한다. 보다 구체적으로, 도 13a는 프로세스의 컨볼루션 계층 부분을 도시하고, 도 13b는 프로세스의 제1 완전 연결 계층 부분을 도시하고, 도 13c는 프로세스의 제1 완전 연결 계 층 부분의 예시적인 신경망 표현을 도시하고, 도 13d는 프로세스의 후속 완전 연결 계층 부분을 도시하며, 도 13e는 프로세스의 후속 완전 연결 계층 부분의 예시적인 신경망 표현을 도시한다. 설명의 편의를 위해, 프로세스는 도 1의 상기 전자 장치, 상기 외부 전자 장치들(102, 104) 또는 서버 중 어떤 것의 프로세서(들)에 의해 실행되거나 또는 달리 이용되는 것으로 설명될 수 있다. 일부 실시예들 에서, 프로세스는 도 4a 및 도 4b와 관련하여 설명한 아키텍처에 의해 이용될 수 있다. 그러나, 프 로세스는 어떤 적절한 장치(들)에 의해서도 그리고 어떤 적절한 시스템에서도 이용될 수 있다. 프로세스는 데이터를 난독화하고 복원하기 위해, 도 12에서 설명한 것과 같은, 기법들을 이용한다. 예를 들면, 도 13a에서, 컨볼루션 계층들은 행렬 곱셈을 이용하기 위해 변환된다. 또한, 도 13a, 도 13b, 및 도 13d 각각에서, 가중치들 및/또는 입력들의 선형 변환은 도 12와 관련하여 설명한 바와 같이 수행된다. 도 13a에 도시한 바와 같이, 단계에서, TEE 내의 상기 프로세서는 가중치 행렬 W를 검색한다. 단계 에서, 상기 프로세서는 랜덤 노이즈 값 a 및 B 내의 랜덤 노이즈 값들을 생성하며, 여기서 B는 b개의 0이 아닌 값들을 갖는 희소 행렬이고 이다. 단계에서, 상기 프로세서는 W' = aW + B이 되도록 가 중치 행렬 W 를 W'로 변환한다. 일부 실시예들에서, 단계들(1302 내지 1306)은, 전술한 바와 같이, AI 추론 요 청을 수신하기 전에 사전계산될 수 있다. 단계에서, 비-TEE 내의 상기 프로세서는 입력 X를 생성 또는 수신한다. 단계에서, 비- TEE 내의 상기 프로세서는 TEE에 가중치들을 요청한다. 단계에서, 비-TEE 내의 상기 프로 세서는 TEE로부터 난독화된 가중치 행렬 W'를 수신한다. 도 10에 도시한 바와 같이, 컨볼루션은, 필터 데 이터를 행렬 W로 결합하고 입력 데이터를 행렬 X로 결합함으로써, Z = WX의 행렬 곱셈으로 변환될 수 있다. 악 성 사용자가 모델 파라미터들을 발견하는 것을 방지하기 위해, 상기 비-TEE에 의해 Z' = W'X의 행렬 곱셈을 수 행한 후, 상기 TEE 내의 상기 프로세서는 출력 Z에 대해 풀링(pooling)을 수행하고, 다음 컨볼루션 계층을 위해 오직 Z의 풀링 결과만을(Z 자체가 아니라) 상기 비-TEE에 전송한다. 본 개시의 다양한 실시예들에서 설명되는 바와 같이, 난독화된 가중치들의 사전계산은, 상기 TEE에서의 활성화 및 풀링과 같은 태스크들을 수행하는 것의 효율성 영향(efficiency impact)을 완화하기 위해, 수행될 수 있다. 도 13a로 다시 돌아가면, 비-TEE 내의 상기 프로세서는 출력들 Z'를 계산하며, 여기서 Z' = W'X 이다. 단 계에서, 상기 프로세서는 출력들 Z'의 노이즈를 제거하기 위한 요청을 TEE에 전송하고 또한 입력 X 를 제공할 수 있다. 단계에서, TEE 내의 상기 프로세서는, 도 12와 관련하여 전술한 바와 같이, Z = (Z' - BX) / a가 되도록 출력들 Z'의 노이즈를 제거한다. 단계에서, TEE 내의 상기 프로세서는 출력 Z에 대해 활성화 및 풀링을 수행하여 Y = f(Z)가 되도록 한다. 단계에서, TEE 내의 상기 프로세서는 활성화 및 풀링 Y의 결과들을, 다음 계층에 대한 입력으로서, 비-TEE에 제공한다. 일부 실시예들에서, 단 계들(1302 내지 1322)은 상기 AI 모델에서의 모든 컨볼루션 계층들이 처리될 때까지 반복된다(입력이 이미 제공됨에 따라 단계는 스킵(skip)될 수도 있음). 도 13a에서 수행되는 컨볼루션 프로세스는, 도 2와 관련하여 설명한 바와 같이, 전적으로 상기 TEE 내에서 컨볼 루션들을 수행하는 것보다 더 효율적인 컨볼루션 계산을 제공한다. 예를 들면, 계산들이 완전히 상기 TEE 내에 서 수행되는 경우, 곱셈 연산들은 개의 연산 개수를 가질 수 있고, 덧셈 연산들은 개의 연 산 개수를 가질 수 있다. 그러나, W가 행렬이고, X가 행렬이며, B는 b개의 0이 아닌 값들을 갖는 희 소 행렬인 표 4에 나타낸 바와 같이, 계산들이 도 13a와 같이 분할되는 경우 상기 TEE의 효율성이 향상된다. [표 4]"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "제1 완전 연결 계층이 프로세스의 일부로서 처리되는 도 13b에 도시한 바와 같이, TEE 내의 상기 프 로세서는 형태의 가중치 행렬 W를 검색한다. 단계에서, 상기 프로세서는 랜덤 노이즈 값 a 및 B 내 의 랜덤 노이즈 값들을 생성하며, 여기서 B는 b개의 0이 아닌 값들을 갖는 희소 행렬이고 이다. 단 계에서, 상기 프로세서는 W' = aW + B가 되도록 가중치 행렬 W를 W'로 변환한다. 일부 실시예들에서, 단 계들(1324 내지 1328)은, 전술한 바와 같이, AI 추론 요청을 수신하기 전에 사전계산될 수 있다. 단계에서, 비-TEE 내의 상기 프로세서는, 본 실시예에서 상기 AI 모델의 컨볼루션 계층들로부터의 최종 출력인, 입력 X를 생성 또는 수신한다. 단계에서, 비-TEE 내의 상기 프로세서는 TEE에 가 중치들을 요청한다. 단계에서, 난독화된 가중치 행렬 W'는 TEE로부터 비-TEE 내에 수신된다. 단계에서, 비-TEE 내의 상기 프로세서는 출력들 Z'을 계산하며, 여기서 Z' = W'X 이다. 단계에서, 상기 프로세서는 출력들 Z'의 노이즈를 제거하기 위한 요청을 TEE에 전송하고 또한 입력 X를 제공할 수 있다. 단계에서, TEE 내의 상기 프로세서는, 도 12와 관련하여 전술한 바와 같이, Z = (Z' - BX) / a가 되도록 출력들 Z'의 노이즈를 제거한다. 단계에서, TEE 내의 상기 프로세서는 출 력 Z에 활성화 함수를 적용하여 Y = f(Z)가 되도록 한다. 단계에서, TEE 내의 상기 프로세서는 활성 화 Y의 결과들을 다음 계층에 대한 입력으로서 비-TEE에 제공한다. 다음에, 후속 완전 연결 계층이, 도 13d에 도시한 바와 같이, 실행될 수 있다. 도 13c에 도시한 바와 같이, 상기 제1 완전 연결 계층에 대해, 상기 프로세서는 가중치들 W에 의해 입력들 X를 변경하고, 상기 프로세서는 상기 결과들에 활성화 함수를 적용하여 다음 계층에 대한 출력 Y를 산출한다. 도 13b에서 수행되는 상기 제1 완전 연결 계층의 프로세스는, 도 2와 관련하여 설명한 바와 같이, 전적으로 상 기 TEE 내에서 계산을 수행하는 것보다 더 효율적인 계산을 제공한다. 예를 들면, 계산들이 완전히 상기 TEE 내 에서 수행되는 경우, 곱셈 연산들은 개의 연산 개수를 가질 수 있고, 덧셈 연산들은 개의 연산 개수를 가질 수 있다. 그러나, W가 행렬이고, X가 n차원 벡터이며, B는 b개의 0이 아닌 값들을 갖는 희소 행렬인 표 5에 나타낸 바와 같이, 계산들이 도 13b와 같이 분할되는 경우 상기 TEE의 효율성이 향상된다. [표 5]"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "상기 제1 완전 연결 계층 이후의 후속 완전 연결 계층이 프로세스의 일부로서 처리되는 도 13d에 도시한 바와 같이, 단계에서, TEE 내의 상기 프로세서는 형태의 가중치 행렬 W를 검색한다. 단계 에서, 상기 프로세서는 랜덤 노이즈 값들 a 및 c 및 B 및 D 내의 랜덤 노이즈 값들을 생성하며, 여기서 B 는 b개의 0이 아닌 값들( )을 갖는 희소 행렬이고 D는 d개의 0이 아닌 값들(d << n)을 갖는 희소 벡 터이다. 단계에서, 상기 프로세서는 W' = aW + B가 되도록 가중치 행렬 W를 W'로 변환한다. 일부 실시예 들에서, 단계들(1324 내지 1328)은, 전술한 바와 같이, AI 추론 요청을 수신하기 전에 사전계산될 수 있다. 단계에서, TEE 내의 상기 프로세서는(이전의 완전 연결 계층으로부터 X를 받음) X' = cX + D가 되도 록 선형 변환을 이용하여 변환된 X'를 계산한다. 단계에서, TEE 내의 상기 프로세서는 난독화된 가 중치들 W' and W\" 및 난독화된 입력 X'를 비-TEE에 제공한다. 단계에서, 비-TEE 내의 상기 프 로세서는 출력 Z'를 계산하며, 여기서 Z' = W'X'이다. 단계에서, 상기 프로세서는 출력 Z'의 노이즈를 제 거하기 위한 요청을 TEE에 전송한다. 단계에서, TEE 내의 상기 프로세서는 단계에서 수 행된 상기 선형 변환을 리버싱함으로써 출력 Z'의 노이즈를 제거하여 Z = (Z' - BX' - aWD) / ac가 되도록 한다. 단계에서, TEE 내의 상기 프로세서는 출력 Z에 대해 활성화 함수를 수행하여 Y = f(Z)가 되도록 한 다. 단계에서, 최종 출력에 도달할 때까지, 임의의(any) 후속 완전 연결 계층들이 도 13d와 동일한 프로 세스를 이용하여 실행된다. 도 13e에 도시한 바와 같이, 상기 제1 계층 이후의 완전 연결 계층들에 대해, 상기 프로세서는 이전 계층으로부터의 출력을 입력들 X로 취하고 가중치들 W에 의해 입력들 X를 변경한다. 다음에, 상기 프로세서는, 모든 계층들이 처리될 때까지, 상기 결과들에 활성화 함수를 적용하여 상기 모델에서의 후속 계층에 대한 출력 Y를 산출한다. 도 13d에서 수행되는 상기 후속 완전 연결 계층들의 프로세스는, 도 2와 관련하여 설명한 바와 같이, 전적으로 상기 TEE 내에서 계산을 수행하는 것보다 더 효율적인 계산을 제공한다. 예를 들면, 계산들이 완전히 상기 TEE 내에서 수행되는 경우, 곱셈 연산들은 개의 연산 개수를 가질 수 있고, 덧셈 연산들은 개의 연산 개수를 가질 수 있다. 그러나, W가 행렬이고, X가 n차원 벡터이고, B가 b개의 0이 아닌 값들을 갖는 희소 행렬이며, D는 d개의 0이 아닌 값들을 갖는 희소 벡터인 표 6에 나타낸 바와 같이, 계산들이 도 13d와 같이 분 할되는 경우 상기 TEE의 효율성이 향상된다. [표 6]"}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 7, "content": "도 13a, 도 13b, 및 도 13d는 다층 AI 모델 보호 프로세스의 일 예를 도시하고 있지만, 도 13a, 도 13b, 및 도 13d에 대해 다양한 변경이 이루어질 수 있다. 예를 들면, 일련의 단계들로 도시되어 있지만, 도 13a, 도 13b, 및 도 13d에서의 다양한 단계들은 중첩되거나, 병렬로 발생하거나, 상이한 순서로 발생하거나, 또는 몇 번이라 도 발생할 수 있다. 또한, 프로세스는 예로서 선형 변환을 이용하고 있지만, 덧셈 또는 곱셈 분할과 같은, 다른 기법들이 모델 파라미터들을 난독화하는 데 이용될 수 있다."}
{"patent_id": "10-2021-0019366", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "본 개시가 예시적 실시예들과 함께 설명되었지만, 다양한 변경 및 변형이 본 개시가 속하는 기술분야의 숙련된 자에게 시사될 수 있다. 본 개시는 그러한 변경 및 변형이 첨부된 청구항들의 범위 내에 속하는 것으로 포함하 고자 한 것이다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8a 도면8b 도면9 도면10 도면11a 도면11b 도면11c 도면11d 도면11e 도면12 도면13a 도면13b 도면13c 도면13d 도면13e"}
{"patent_id": "10-2021-0019366", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시 및 그 이점들의 보다 완전한 이해를 위해, 이제, 첨부된 도면과 함께 이하의 설명이 이루어지며, 도면 에서 동일 참조 번호는 동일 부품을 나타낸다. 도 1은 본 개시의 다양한 실시예들에 따른 예시적 네트워크 구성을 도시한다. 도 2는 본 개시의 다양한 실시예들에 따른 예시적 인공지능(artificial intelligence: AI) 모델 보호 아키텍처 를 도시한다. 도 3은 본 개시의 다양한 실시예들에 따른 예시적 양자간(two-party) AI 모델 계산 및 보호 아키텍처를 도시한 다. 도 4a 및 도 4b는 본 개시의 다양한 실시예들에 따른 다른 예시적 AI 모델 보호 아키텍처를 도시한다. 도 5는 본 개시의 다양한 실시예들에 따른 예시적 AI 모델 보호 프로세스를 도시한다. 도 6은 본 개시의 다양한 실시예들에 따른 예시적 AI 모델 파라미터 난독화(obfuscation) 프로세스를 도시한다. 도 7은, 본 개시의 다양한 실시예들에 따른, 덧셈 분할(additive splitting) 및 위임 행렬 곱셈(delegating matrix multiplication)에 의해 모델 파라미터들을 난독화하는 예시적 프로세스를 도시한다. 도 8a 및 도 8b는 본 개시의 다양한 실시예들에 따른 예시적 신뢰 실행 환경 사전계산(trusted execution environment precomputation) 프로세스를 도시한다. 도 9는 본 개시의 다양한 실시예들에 따른 예시적 행렬 곱셈(matrix multiplication) 프로세스를 도시한다. 도 10은 본 개시의 다양한 실시예들에 따른 예시적 컨볼루션 변환 다이어그램(convolution transformation diagram)을 도시한다. 도 11a, 도 11b, 도 11c, 도 11d, 및 도 11e는 본 개시의 다양한 실시예들에 따른 예시적 다층(multi-layer) AI 모델 보호 프로세스를 도시한다. 도 12는 본 개시의 다양한 실시예들에 따른 예시적 선형 변환(linear transformation) 프로세스를 도시한다. 도 13a, 도 13b, 도 13c, 도 13d, 및 도 13e는 본 개시의 다양한 실시예들에 따른 다른 예시적 다층 AI 모델 보 호 프로세스를 도시한다."}
