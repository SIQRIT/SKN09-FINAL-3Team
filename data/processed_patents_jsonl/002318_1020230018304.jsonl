{"patent_id": "10-2023-0018304", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0105163", "출원번호": "10-2023-0018304", "발명의 명칭": "인공지능을 이용한 영상의 텍스트 인식 장치 및 그 방법", "출원인": "한양대학교 산학협력단", "발명자": "이종민"}}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 알고리즘 및 타겟영상이 저장되는 메모리; 및 프로세서;를 포함하되,상기 메모리는 상기 프로세서에 의해 실행 가능한,상기 인공지능 알고리즘을 통해 상기 타겟영상에 상응하는 텍스트 위치를 판단하는 프로그램 명령어들을 저장하고, 상기 인공지능 알고리즘은 복수의 브랜치로 구분되어 미리 설정된 학습데이터를 이용하여 다중 학습된 것인, 텍스트 인식 장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 알고리즘은 제1 브랜치를 포함하고,상기 제1 브랜치는 상기 타겟영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 의미론적 특징을추출하며, 상기 의미론적 특징을 이용하여 상기 텍스트 위치가 판단되는, 텍스트 인식 장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 인공지능 알고리즘은 제2 브랜치를 더 포함하고,상기 제2 브랜치는 상기 타겟영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 위치적 특징을 추출하며, 상기 위치적 특징을 이용하여 상기 텍스트 위치가 판단되는, 텍스트 인식 장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제2 브랜치는 상기 타겟영상의 특징과 단어 의미론적 특징이 입력되어 상기 위치적 특징을 추출하되,상기 단어 의미론적 특징은 상기 제1 브랜치에서 추출된 것인, 텍스트 인식 장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 학습영상에 포함된 캐릭터(character) 및 단어(word) 중하나 이상의 의미론적 특징을 학습한 제1 브랜치를 포함하고,공개특허 10-2024-0105163-3-상기 학습데이터는 정답캐릭터정보 및 정답단어정보 중 하나 이상과 상기 학습영상을 포함하는, 텍스트 인식 장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 상기 학습영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 위치적 특징을 학습한 제2 브랜치를 더 포함하고,상기 학습데이터는 정답캐릭터영역 및 정답단어영역 중 하나 이상과 학습영상을 더 포함하는, 텍스트 인식장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제2 브랜치는 상기 학습영상 및 정답중복영역을 이용하여 상기 학습영상에 포함된 중복영역의 특징을 학습한 것이고,상기 학습데이터는 정답중복영역을 더 포함하는, 텍스트 인식 장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제2 브랜치는 상기 학습영상의 특징과 학습단어 의미론적 특징이 입력되어 상기 위치적 특징을 학습한 것이되,상기 학습단어 의미론적 특징은 상기 제1 브랜치에서 추출된 것인, 텍스트 인식 장치."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능 알고리즘 및 타겟영상이 저장된 텍스트 인식 장치에서 수행되는 텍스 위치 판단 방법에 있어서,상기 타겟영상이 입력되는 단계; 및 상기 인공지능 알고리즘을 통해 상기 타겟영상에 상응하는 텍스트 위치를 판단하는 단계;를 포함하되, 상기 인공지능 알고리즘은 복수의 브랜치로 구분되어 미리 설정된 학습데이터를 이용하여 다중 학습된 것인, 텍스트 인식 방법."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 텍스트 위치를 판단하는 단계는,제1 브랜치가 상기 타겟영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 의미론적 특징을 추출하는 단계; 및 상기 의미론적 특징을 이용하여 상기 텍스트 위치를 판단하는 단계;를 포함하되,공개특허 10-2024-0105163-4-상기 인공지능 알고리즘은 상기 제1 브랜치를 포함하는, 텍스트 인식 방법."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 텍스트 위치를 판단하는 단계는,제2 브랜치가 상기 타겟영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 위치적 특징을 추출하는 단계; 및 상기 의미론적 특징 및 상기 위치적 특징을 이용하여 상기 텍스트 위치를 판단하는 단계;를 포함하는, 텍스트 인식 방법."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 위치적 특징을 추출하는 단계는,상기 제2 브랜치에 상기 타겟영상의 특징과 단어 의미론적 특징이 입력되는 단계; 및 상기 제2 브랜치가 상기 위치적 특징을 추출하는 단계;를 포함하되,상기 단어 의미론적 특징은 상기 제1 브랜치에서 추출된 것인, 텍스트 인식 방법."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 학습영상에 포함된 캐릭터(character) 및 단어(word) 중하나 이상의 의미론적 특징을 학습한 제1 브랜치를 포함하고,상기 학습데이터는 정답캐릭터정보 및 정답단어정보 중 하나 이상과 상기 학습영상을 포함하는, 텍스트 인식 방법."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 상기 학습영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 위치적 특징을 학습한 제2 브랜치를 더 포함하고,상기 학습데이터는 정답캐릭터영역 및 정답단어영역 중 하나 이상과 학습영상을 더 포함하는, 텍스트 인식방법."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제2 브랜치는 상기 학습영상 및 정답중복영역을 이용하여 상기 학습영상에 포함된 중복영역의 특징을 학습한 것이고,공개특허 10-2024-0105163-5-상기 학습데이터는 정답중복영역을 더 포함하는, 텍스트 인식 방법."}
{"patent_id": "10-2023-0018304", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 제2 브랜치는 상기 학습영상의 특징과 학습단어 의미론적 특징이 입력되어 상기 위치적 특징을 학습한 것이되,상기 학습단어 의미론적 특징은 상기 제1 브랜치에서 추출된 것인, 텍스트 인식 방법."}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 영상의 텍스트를 인식하는 장치 및 그 방법에 대한 것으로서, 보다 상세하게는 인공지능을 이용하여 영상의 텍스트를 자동으로 인식하는 장치 및 그 방법에 대한 것이다. 본 발명의 일 실시예에 따른 텍스트 인식 장치는, 인공지능 알고리즘 및 타겟영상이 저장되는 메모리 및 프로세 서를 포함하고, 당해 메모리는 프로세서에 의해 실행 가능하고, 인공지능 알고리즘을 통해 상기 타겟영상에 상응 하는 텍스트 위치를 판단하는 프로그램 명령어들을 저장할 수 있으며, 이때 인공지능 알고리즘은 복수의 브랜치 로 구분되어 미리 설정된 학습데이터를 이용하여 다중 학습된 것일 수 있다."}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상의 텍스트를 인식하는 장치 및 그 방법에 대한 것으로서, 보다 상세하게는 인공지능을 이용하여 영상의 텍스트를 자동으로 인식하는 장치 및 그 방법에 대한 것이다."}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "동영상이나 사진의 텍스트를 인식하는 분야에서, 텍스트의 영역을 인식하는 방법은 회귀 기반 방법론 (Regression-based Methods)과 분할 기반 방법론(Segmentation-based Methods)으로 구분될 수 있다. 회귀 기반 방법론은 직접적으로 경계 상자를 추론하는 방법이다. 예를 들어, 객체 탐지에서 주로 사용되는 Single Shot Detector(SSD)를 수정해 합성곱 커널(Convolutional Kernel)과 앵커 상자(Anchor Box)를 문자 탐 지에 적합한 크기로 변경해 사용하는 방법이 공개되어 있다(Minghui Liao 外 2인, A single-shot oriented scene text detector. IEEE Transactions on Image Processing, 27:3676-3690, 2018.). 회귀 기반 방법들 은 구조적인 한계점 때문에 불규칙하거나 변형된 형태의 텍스트에 대해 정확한 경계 상자를 표현하기 어려운 문 제가 있고, 장면 문자의 다양한 비율과 크기로 인해 모든 문자 수준의 특성이 고려되지 않아 단어의 일부 영역 만을 탐지하는 문제(Sub-text Problem)도 발생될 수 있다. 분할 기반 방법론은 픽셀 수준의 분할 지도를 생성하고 후처리 과정을 통해 단어 수준의 경계 상자를 추론하는 방법이다. 예를 들어, 축소된 단어 수준 경계 상자를 이용해 분할 지도를 생성하고 최소한의 크기부터 점진적으 로 확장하며 최종 결과를 도출하는 방법이 공개되어 있다(Wenhai Wang 외 6, Shape robust text detection with progressive scale expansion network. In Proc. CVPR, pages 9336-9345, 2019.). 한편, 최근에는 문자 수준 경계 상자를 추론하는 문자 기반 방법론(Character-based Methods)이 제시되고 있다. 문자 기반 방법론은 단어의 일부 영역만 탐지되는 문제점을 해결하기 위해 문자 수준의 영역을 탐지하고 단어 수준으로 연결하는 방법이다. 예를 들어, 문자 영역과 문자와 문자 사이 영역의 분할 지도를 생성하고 두개의 분할 지도를 연결하여 단어 수준 경계 상자를 추론하는 방법이 공개되어 있다(Youngmin Baek 外 4. Character region awareness for text detection. In Pro. CVPR, pages 9365-9374, 2019.). 문자 기반 방법론에 의할 경 우 전역 문맥(Global Context) 정보가 고려되지 않아 여전히 완전한 단어 영역을 탐지하지 못하는 문제가 남아 있다."}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위하여, 문자와 단어 수준의 특징을 모두 고려하여 영상의 텍스트를 인식 하는 장치 및 그 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 인공지능 알고리즘 및 타겟영상이 저장되는 메모리; 및 프로세서;를 포함하되, 상기 메모리는 상기 프로세서에 의해 실행 가능한, 상기 인공지능 알고리즘을 통해 상기 타겟영상에 상응하는 텍스트 위치를 판단하는 프로그램 명령어들을 저장하 고, 상기 인공지능 알고리즘은 복수의 브랜치로 구분되어 미리 설정된 학습데이터를 이용하여 다중 학습된 것인, 텍스트 인식 장치가 개시된다. 실시예에 따라, 상기 인공지능 알고리즘은 제1 브랜치를 포함하고, 상기 제1 브랜치는 상기 타겟영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 의미론적 특징을 추출하며, 상기 의미론적 특징을 이용하여 상기 텍스트 위치가 판단될 수 있다. 실시예에 따라, 상기 인공지능 알고리즘은 제2 브랜치를 더 포함하고, 상기 제2 브랜치는 상기 타겟영상에 포함 된 캐릭터(character) 및 단어(word) 중 하나 이상의 위치적 특징을 추출하며, 상기 위치적 특징을 이용하여 상 기 텍스트 위치가 판단될 수 있다. 실시예에 따라, 상기 제2 브랜치는 상기 타겟영상의 특징과 단어 의미론적 특징이 입력되어 상기 위치적 특징을 추출하되, 상기 단어 의미론적 특징은 상기 제1 브랜치에서 추출된 것일 수 있다. 실시예에 따라, 상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 학습영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 의미론적 특징을 학습한 제1 브랜치를 포함하고, 상기 학습데이터는 정답캐릭터 정보 및 정답단어정보 중 하나 이상과 상기 학습영상을 포함할 수 있다. 실시예에 따라, 상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 상기 학습영상에 포함된 캐릭터 (character) 및 단어(word) 중 하나 이상의 위치적 특징을 학습한 제2 브랜치를 더 포함하고, 상기 학습데이터 는 정답캐릭터영역 및 정답단어영역 중 하나 이상과 학습영상을 더 포함할 수 있다. 실시예에 따라, 상기 제2 브랜치는 상기 학습영상 및 정답중복영역을 이용하여 상기 학습영상에 포함된 중복영 역의 특징을 학습한 것이고, 상기 학습데이터는 정답중복영역을 더 포함할 수 있다. 실시예에 따라, 상기 제2 브랜치는 상기 학습영상의 특징과 학습단어 의미론적 특징이 입력되어 상기 위치적 특 징을 학습한 것이되, 상기 학습단어 의미론적 특징은 상기 제1 브랜치에서 추출된 것일 수 있다. 본 발명의 다른 실시예에 따르면, 인공지능 알고리즘 및 타겟영상이 저장된 텍스트 인식 장치에서 수행되는 텍 스 위치 판단 방법에 있어서, 상기 타겟영상이 입력되는 단계; 및 상기 인공지능 알고리즘을 통해 상기 타겟영 상에 상응하는 텍스트 위치를 판단하는 단계;를 포함하되, 상기 인공지능 알고리즘은 복수의 브랜치로 구분되어 미리 설정된 학습데이터를 이용하여 다중 학습된 것인, 텍스트 인식 방법이 개시된다. 실시예에 따라, 상기 텍스트 위치를 판단하는 단계는, 제1 브랜치가 상기 타겟영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 의미론적 특징을 추출하는 단계; 및 상기 의미론적 특징을 이용하여 상기 텍스트 위치를 판단하는 단계;를 포함하되, 상기 인공지능 알고리즘은 상기 제1 브랜치를 포함할 수 있다. 실시예에 따라, 상기 텍스트 위치를 판단하는 단계는, 제2 브랜치가 상기 타겟영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 위치적 특징을 추출하는 단계; 및 상기 의미론적 특징 및 상기 위치적 특징을 이 용하여 상기 텍스트 위치를 판단하는 단계;를 포함할 수 있다. 실시예에 따라, 상기 위치적 특징을 추출하는 단계는, 상기 제2 브랜치에 상기 타겟영상의 특징과 단어 의미론 적 특징이 입력되는 단계; 및 상기 제2 브랜치가 상기 위치적 특징을 추출하는 단계;를 포함하되, 상기 단어 의 미론적 특징은 상기 제1 브랜치에서 추출된 것일 수 있다. 실시예에 따라, 상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 학습영상에 포함된 캐릭터(character) 및 단어(word) 중 하나 이상의 의미론적 특징을 학습한 제1 브랜치를 포함하고, 상기 학습데이터는 정답캐릭터 정보 및 정답단어정보 중 하나 이상과 상기 학습영상을 포함할 수 있다. 실시예에 따라, 상기 인공지능 알고리즘은 상기 학습데이터를 이용하여 상기 학습영상에 포함된 캐릭터 (character) 및 단어(word) 중 하나 이상의 위치적 특징을 학습한 제2 브랜치를 더 포함하고, 상기 학습데이터는 정답캐릭터영역 및 정답단어영역 중 하나 이상과 학습영상을 더 포함할 수 있다. 실시예에 따라, 상기 제2 브랜치는 상기 학습영상 및 정답중복영역을 이용하여 상기 학습영상에 포함된 중복영 역의 특징을 학습한 것이고, 상기 학습데이터는 정답중복영역을 더 포함할 수 있다. 실시예에 따라, 상기 제2 브랜치는 상기 학습영상의 특징과 학습단어 의미론적 특징이 입력되어 상기 위치적 특 징을 학습한 것이되, 상기 학습단어 의미론적 특징은 상기 제1 브랜치에서 추출된 것일 수 있다."}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 텍스트 인식 장치는 문자와 단어 수준의 특징을 모두 고려하여 영상의 텍스트를 인식할 수 있으 므로 다양한 방식으로 표기된 다국어를 정확하게 인식할 수 있다."}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 기술적 사상은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 이를 상세히 설명하고자 한다. 그러나, 이는 본 개시의 기술적 사상을 특정한 실시 형태에 대 해 한정하려는 것이 아니며, 본 개시의 기술적 사상의 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함 하는 것으로 이해되어야 한다. 본 개시의 기술적 사상을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 기술적 사상 의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본원의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별 기호에 불과 하다. 또한, 본원에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존 재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것 이다. 또한, 본원에 기재된 \"~부\", \"~기\", \"~자\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하 며, 이는 프로세서(Processor), 마이크로 프로세서(Micro Processer), 마이크로 콘트롤러(Micro Controller), CPU(Central Processing Unit), GPU(Graphics Processing Unit), APU(Accelerate Processor Unit), DSP(Digital Signal Processor), ASIC(Application Specific Integrated Circuit), FPGA(Field Programmable Gate Array) 등과 같은 하드웨어나, 소프트웨어, 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 그리고 본원에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기능 별로 구분한 것에 불과함을 명확히 하 고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이하에서 설명할 구성부 각각은 자신이 담 당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있 으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의해 전담되어 수행될 수도 있음은 물론이 다. 이하, 본 개시의 기술적 사상에 따른 다양한 실시예들을 차례로 상세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 텍스트 인식 장치를 설명하기 위한 구성도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 텍스트 인식 장치는 카메라(CAMERA, 110), 메모리(MEMORY, 120) 및 프로세서(PROCESSOR, 130)를 포함할 수 있다. 카메라는 영상에 대한 데이터를 생성하는 구성으로서, 특히 타겟영상을 생성할 수 있다. 여기서 타겟영상 은 사진 및/또는 동영상으로서, 숫자, 문자, 기호 등이 촬영된 멀티미디어 데이터일 수 있다. 예를 들어, 카메 라는 자동차 번호판 인식을 위해 설치된 것으로서, 출입하는 자동차의 번호판 부분을 촬영하여 타겟영상을 생성할 수 있다. 다른 예를 들어, 카메라는 도로, 건물 등을 촬영하여 타겟영상을 생성할 수도 있다. 카메 라에서 생성된 타겟영상은 메모리에 저장될 수 있다. 한편, 타겟영상은 텍스트 인식 장치의 카 메라에서 생성된 것에 한정되지 않고, 다른 장치에서 생성된 멀티미디어 데이터도 해당될 수 있다. 따라서, 타겟영상을 생성한 장치는 본 발명의 권리범위를 제한할 수 없다. 메모리는 텍스트 인식 장치 의 동작을 위한 각종 정보 및 프로그램 명령어들이 저장되는 구성으로서, 하드 디스크(Hard Disk), SSD(Solid State Drive) 등과 같은 기억장치일 수 있다. 특히 메모리는 카메라 에서 생성되는 타겟영상을 저장할 수 있다(물론 타겟영상은 카메라 외 다른 장치에서 생성된 것일 수 있다). 또한, 메모리는 프로세서에 의해 실행 가능한 '텍스트 인식 동작'을 실행시키기 위한 인공지 능 알고리즘 기타 프로그램 명령어들을 저장할 수 있다. 프로세서는 텍스트 인식 장치의 전반적인 동작을 제어할 수 있는 중앙처리장치(CPU)로서, 특히 메모 리에 저장된 인공지능 알고리즘, 기타 프로그램 명령어들을 이용하여 타겟영상을 분석하고, 타겟영상에 포 함된 덱스트를 자동 인식할 수 있다. 이하, 프로세서의 제어에 의해 타겟영상에 포함된 텍스트를 인식하는 동작에 대해 설명한다. 도 2는 본 발명의 일 실시예에 따른 텍스트 인식 장치의 동작을 설명하기 위한 흐름도이다. 도 2를 참조하면, 프로세서에 의해 타겟영상의 텍스트가 인식되기 위해, 메모리에 저장된 인공지능 알고리즘을 학습시키는 것을 확인할 수 있다. 즉, 먼저 인공지능 알고리즘을 학습시키기 위한 학습데이터세트를 생성하고(Learning Data-set Generating, 210), 생성된 학습데이터세트를 이용하여 인공지능 알고리즘의 복수의 브랜치를 학습시키고(1st and 2nd Artificial Intelligence Learning, 220-1 및 220-2), 분석 및 판단의 대상 이 되는 타겟영상 생성하며(Target data Generating, 230)(물론 타겟영상은 다른 장치에서 생성된 것일 수 있음), 학습된 인공지능 알고리즘을 이용하여 타겟영상이 분석되어 타겟영상에 포함된 텍스트가 인식될 수 있다 (Target Data Analysis, 240). 학습데이터세트 생성 동작 및 인공지능 알고리즘 학습 동작(220-1 및 220-2)은 외부 장치(미도시)에서 수 행된 후 메모리에 저장될 수도 있을 것이다. 즉, 인공지능 알고리즘의 학습을 위한 동작들은 텍스트 인식 장치가 아닌 다른 장치에서 수행될 수도 있는 것이다. 이하 도 2의 각 동작에 대해 보다 상세하게 설명한 다. 도 3은 본 발명의 일 실시예에 따른 텍스트 인식 장치의 인공지능 학습을 위한 학습데이터세트 생성 동작에 대 한 순서도이고, 도 4는 본 발명의 일 실시예에 따른 각 브랜치에서 생성된 분할지도에 대한 예시 이미지이며, 도 5는 본 발명의 일 실시예에 따른 정답 분할 지도에 대한 예시 이미지이다. 먼저, 도 3을 참조하여 도 2의 학습데이터세트 생성 동작을 상세하게 설명한다. 여기서 학습데이터세트는 메모리에 저장된 인공지능 알고리즘을 학습시키기 위한 데이터 세트일 수 있다. 또한, 도 3의 각 단계들은 텍스트 인식 장치에서 수행될 수 있고, 다른 장치에서 수행될 수도 있다. 따라서, 도 3의 각 단계들이 수행되는 장치는 별도 한정하지 않고 설명한다. 단계 S310에서, 학습영상에 상응하는 캐릭터정보가 생성될 수 있다. 여기서, 학습영상은 인공지능 알고리즘 학 습에 활용될 사진 또는 동영상과 같은 멀티미디어 데이터일 수 있다. 또한, 캐릭터정보는 학습영상에 포함된 캐 릭터(Character, 문자, 영어의 알파벳 등)에 대한 정보일 수 있다. 예를 들어, 캐릭터정보는 분할 지도(Image Segmentation Map) 형식으로 생성될 수 있다. 도 4에는 본 발명의 일 실시예에 따른 인공지능 알고리즘의 학습에 사용되는 분할 지도들이 예시된다. 본 발명 의 일 실시예에 따른 인공지능 알고리즘은 의미론적 브랜치(Semantic Branch) 및 위치적 브랜치(Detection Branch)와 같은 2 이상의 브랜치로 형성되어 조인트 학습될 수 있다. 또한, 브랜치 각각에 상응하는 분할 지도 가 학습에 사용될 수 있다. 도 4에서, 캐릭터정보는 각 캐릭터에 상응하는 복수의 캐릭터 분할 지도를 포 함할 수 있다. 예를 들어, 제a 캐릭터정보(410-a)는 학습영상에 캐릭터 중 'a'가 포함된 경우 생성되는 분할 지 도로서, 제a 캐릭터정보(410-a)에는 학습영상에 표시된 'a'의 위치가 표시될 수 있다. 다른 예를 들어, 제z 캐 릭터정보(410-z)는 학습영상에 캐릭터 중 'z'가 포함된 경우 생성되는 분할 지도로서, 제z 캐릭터정보(410-z)에 는 학습영상에 표시된 'z'의 위치가 표시될 수 있으며, 학습영상에 포함된 'z'가 복수인 경우, 학습영상에 표시 된 모든 'z'의 위치가 표시될 수 있다(도 4의 예시에서는 'z'가 2개임). 다시 도 3을 참조하면, 단계 S320에서, 학습영상에 상응하는 단어정보가 생성될 수 있다. 여기서, 단어정보는 학습영상에 포함된 단어(word)에 대한 정보일 수 있다. 예를 들어, 단어정보는 분할 지도(Image Segmentation Map) 형식으로 생성될 수 있다. 도 4를 참조하면, 단어정보는 학습영상에 단어가 포함된 경우 생성되는 분할 지도일 수 있다. 단어정보 에는 학습영상에 포함된 단어의 위치가 배경과 다른 색상의 박스로 표시될 수 있다. 단어정보에 형성 된 박스의 개수에 의해 학습영상에 포함된 단어의 개수가 인지될 수 있을 것이다. 또한, 단어정보에 형성 된 박스의 크기에 의해 학습영상에 포함된 단어의 크기도 인지될 수 있을 것이다. 실시예에 따라 단어정보(42 0)에는 학습영상에 포함된 단어가 박스와 매칭되어 포함될 수도 있을 것이다. 다시 도 3을 참조하면, 단계 S330에서, 학습영상에 상응하는 '캐릭터영역'이 생성될 수 있다. 여기서, 캐릭터영 역은 학습영상에 포함된 각 캐릭터 영역의 위치에 대한 정보로서, 학습영상 내 개별 캐릭터의 픽셀 위치에 대한 정보일 수 있다. 예를 들어, 학습영상에 10개의 캐릭터가 포함되고, 캐릭터영역은 사각형으로 형성되는 경우를 가정한다. 이때, '캐릭터영역'은 10개의 사각형 박스의 위치에 상응하는 정보일 수 있고, 각 사각형 박스에는 1 개의 캐릭터가 위치될 수 있을 것이다. 여기서, 캐릭터영역은 분할 지도(Image Segmentation Map) 형식으로 생 성될 수 있다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 캐릭터영역은 학습영상에 포함된 모든 캐릭터의 위치가 표 시된 단일의 분할 지도로 생성될 수 있다. 이때, 캐릭터영역인 분할 지도는 캐릭터가 사각형의 경계 상자 안에 국한되어 있는 문제를 해결하고자 각 캐릭터 상자의 중심으로부터 형성된 2차원 가우시안 확률이 형성된 분할 지도로 생성될 수 있을 것이다. 도 5를 참조하면, 임의의 학습영상에 6개의 캐릭터(e, t, f, i, v, e)가 포함되고, 각 캐릭터에 상응하는 6개의 박스가 표시된 경우가 예시된다. 당해 학습영상에 상응하는 캐릭터영역은 6개의 박스에 상응하 는 가우시안 확률이 형성된 확률 지도임을 확인할 수 있다. 다시 도 3을 참조하면, 단계 S340에서, 학습영상에 상응하는 '단어영역'이 생성될 수 있다. 여기서, 단어영역은 학습영상에 포함된 각 단어 영역의 위치에 대한 정보로서, 학습영상 내 개별 단어의 픽셀 위치에 대한 정보일 수 있다. 예를 들어, 학습영상에 4개의 단어가 포함되고, 단어영역은 사각형으로 형성되는 경우를 가정한다. 이 때, '단어영역'은 4개의 사각형 박스의 위치에 상응하는 정보일 수 있고, 각 사각형 박스에는 1개의 단어가 위 치될 수 있을 것이다. 여기서, 단어영역은 분할 지도(Image Segmentation Map) 형식으로 생성될 수 있다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 단어영역은 학습영상에 포함된 모든 단어의 위치가 표시된 단일의 분할 지도로 생성될 수 있다. 이때, 단어영역인 분할 지도는 하나의 단어에 상응하는 복수의 캐릭 터 박스의 중심을 잇는 선(line)을 포함하여 생성될 수 있다. 도 5를 참조하면, 임의의 학습영상에 2개의 단어(et 및 five)가 포함되고, 각 단어에 상응하는 2개의 라인 이 표시된 경우가 예시된다. 당해 학습영상에 상응하는 단어영역은 2개의 라인에 상응하는 라인이 형 성된 확률 지도임을 확인할 수 있다. 이때, 단어영역에 형성된 라인의 두께는 학습영상에 형성된 단 어의 크기에 상응하여 생성될 수 있을 것이다. 즉, 학습영상에 형성된 2개의 단어의 크기가 상이할 경우,단어영역에는 크기가 큰 단어에 상응하는 라인이 더 두껍게 형성될 수 있을 것이다. 다시 도 3을 참조하면, 단계 S350에서, 학습영상에 상응하는 '중복영역'이 생성될 수 있다. 여기서, 중복영역은 학습영상에 포함된 단어들이 겹쳐있는 경우, 겹쳐진 영역의 위치에 대한 정보로서, 학습영상 내 단어들이 겹쳐 진 영역의 픽셀 위치에 대한 정보일 수 있다. 예를 들어, 학습영상에 4개의 단어가 포함되고, 그 중 2개의 단어 가 서로 일부분 겹쳐진 경우를 가정한다. 이때, 겹쳐진 2개의 단어 각각에 대한 박스 중 상호 겹쳐진 부분이 있 다면, 그 겹쳐진 부분이 중복영역으로 설정될 수 있다. 여기서, 중복영역은 분할 지도(Image Segmentation Map) 형식으로 생성될 수 있다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 중복영역에는 학습영상에 포함된 모든 캐릭터 박스의 외곽 라인이 표시되어 있다. 또한, 중복영역에는 중복된 영역에 상응하는 도형이 형성되어 있다. 당해 도형의 내부는 외곽선과 동일한 색상으로 형성되어 캐릭터 박스의 외곽 라인과 구별될 수 있다. 도 5를 참조하면, 임의의 학습영상에 2개의 단어(et 및 five)가 포함되고, 각 단어의 일부 영역이 서로 겹 쳐있는 경우가 예시된다. 당해 학습영상에 상응하는 중복영역은 캐릭터박스의 라인과 단어가 중복된 부분에 대한 도형이 형성된 확률 지도임을 확인할 수 있다. 중복영역에 형성된 도형이 복수인 경우, 도형 내부의 색상을 통해 캐릭터박스의 외곽 라인인지, 단어의 중복된 부분인지 구별될 수 있을 것이다. 다시 도 3을 참조하면, 단계 S360에서, 학습데이터세트가 생성될 수 있다. 예를 들어, 학습데이터세트는 다음과 같은 데이터들이 포함되어, 학습데이터세트를 통해 어떤 캐릭터(또는 숫자) 및/또는 단어가 어디에 위치되어 있 는지 인지될 수 있다. 학습영상 학습영상에 상응하는 캐릭터정보 학습영상에 상응하는 단어정보 학습영상에 상응하는 캐릭터영역 학습영상에 상응하는 단어영역 학습영상에 상응하는 중복영역 한편, 상술한 방법을 통해 학습데이터세트를 수동으로 생성할 경우 매우 많은 인력 및/또는 시간이 필요할 수 있다. 따라서, 상술한 방법으로 생성된 학습데이터세트를 통해 인공지능 알고리즘을 사전 학습(Pre-train)시키 고, 학습된 딥러닝 알고리즘을 통해 학습데이터세트가 슈도 레이블링(Pseudo labelling)될 수도 있다. 학습데이 터세트가 슈도 레이블링되어 생성되는 동작은 미리 공개된 방법과 대동소이하므로, 이에 대한 구체적인 설명은 생략될 수 있다. 도 6은 본 발명의 일 실시예에 따른 텍스트 인식 장치의 인공지능 알고리즘이 학습되는 과정을 설명하기 위한 순서도이고, 도 7은 본 발명의 일 실시예에 따른 인공지능 알고리즘의 구조도이다. 이하, 도 6 내지 도 7을 참 조하여, 본 발명의 일 실시예에 따른 인공지능 알고리즘의 복수의 브랜치 학습 동작(도 2의 220-1 및 220-2)을 상세하게 설명한다. 단계 S610에서, 백본 네트워크를 이용하여 학습영상의 피쳐가 추출될 수 있다. 예를 들어, 학습영상은 백본 네 트워크(VGG-16)에 입력되고, 백본 네트워크(VGG-16) 및 FPN(Feature Pyramid Network)을 통해 학습영상의 피쳐 (feature)가 추출될 수 있다. 단계 S620에서, 추출된 학습영상의 피쳐, 캐릭터정보 및/또는 단어정보를 이용하여 인공지능 알고리즘이 학습될 수 있다. 여기서, 본 발명의 일 실시예에 따른 인공지능 알고리즘은 복수의 브랜치로 구분되어 다중 학습(Multi-task learning)될 수 있다. 예를 들어, 인공지능 알고리즘이 제1 브랜치(1st Branch) 및 제2 브랜치(2nd Branch)로 구분된 경우를 예시로 설명한다. 또한, 제1 브랜치는 영상 내 텍스트의 의미론적 특징을 추출하기 위한 인공지 능 알고리즘 브랜치(Semantic branch)이고, 제2 브랜치는 영상 내 텍스트의 위치적 특징을 검출하기 위한 인공 지능 알고리즘 브랜치(Detection branch)일 수 있다. 따라서, 인공지능 알고리즘의 제1 브랜치는 학습영상의 피 쳐, 캐릭터 정보 및/또는 단어정보를 이용하여 학습될 수 있다. 단계 S630에서, 학습 중인 인공지능 알고리즘의 제1 브랜치는 입력된 타겟영상의 캐릭터 의미론적 특징(fc) 및/ 또는 단어 의미론적 특징(fw)을 추출할 수 있다. 제1 브랜치가 단계 S620과 같은 학습을 통해 캐릭터 의미론적 특징(fc) 및/또는 단어 의미론적 특징(fw)을 추출하는 동작은 공개된 방법들과 대동소이할 수 있으므로, 이에 대한 구체적인 설명은 생략될 수 있다. 단계 S640에서, 추출된 학습영상의 피쳐, 캐릭터영역, 단어영역 및/또는 중복영역을 이용하여 인공지능 알고리 즘, 특히 제2 브랜치가 학습될 수 있다. 이때, 제2 브랜치는 제1` 브랜치에서 생성된 단어 의미론적 특징(fw, 이하 '제1 특징정보'라 칭함)이 추가로 입력되어 학습될 수 있다. 이러한 다중 작업 학습(Multi-task Learnin g)을 통해 캐릭터영역, 단어영역 및/또는 중복영역만을 통해 학습할 경우 발생될 수 있는 부정확하거나 일부 끊 어진 경계 상자를 추론하는 문제점이 방지될 수 있다. 단계 S650에서, 본 발명의 일 실시예에 따른 인공지능 알고리즘은 제1 브랜치에 상응하는 제1 손실함수 (Lsemantic) 및 제2 브랜치에 상응하는 제2 손실함수(Ldetection)의 합이 최소값이 되도록 학습될 수 있다. 즉, 인공지능 알고리즘에 상응하는 손실함수는 아래 수학식과 같을 수 있다. [수학식1]"}
{"patent_id": "10-2023-0018304", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한편, 제1 손실함수(Lsemantic) 및/또는 제2 손실함수(Ldetection)는 각 브랜치의 학습에 사용되는 것으로서, 통상의 손실함수와 대동소이하므로, 이에 대한 구체적인 설명은 생략될 수 있다. 다시 도 2를 참조하면, 메모리에는 학습된 인공지능 알고리즘에 의해 텍스트 위치가 인식될 타겟영상들이 저장되어 있을 수 있다(230, Target Data Generating). 타겟영상들은 텍스트 인식 장치에서 직접 생성된 영상(동영상 및 이미지)들이거나 타 장치에서 생성되어 메모리에 저장된 영상들일 수 있다. 프로세서는 메모리에 저장된 학습된 인공지능 알고리즘을 이용하여 타겟영상들에 포함된 텍스트들을 자동으로 인지할 수 있다. 예를 들어, 프로세서는 인공지능 알고리즘을 이용하여 타겟영상들을 분석한 후, 타겟영상들에 포함된 텍스트들의 위치 및/또는 내용을 자동으로 인지할 수 있다(240, Target Data Analysis). 도 7을 참조하면, 프로세서는 메모리에 저장된 프로그램 명령어들을 실행하여 타겟영상이 백본 네트워크에 입력되도록 할 수 있다. 백본 네트워크(720, VGG-16) 및 피쳐 피라미드 네크워크(730, Feature Pyramid Network, FPN)는 입력된 타겟영상의 피쳐(feature)를 추출할 수 있다. 또한, 프로세서는 메모리에 저장된 프로그램 명령어들을 실행하여 추출된 타겟영상의 피쳐를 학 습된 인공지능 알고리즘에 입력할 수 있다. 예를 들어, 타겟영상의 피쳐는 인공지능 알고리즘의 제1 브랜치(Semantic Branch)에 입력될 수 있다. 제1 브랜치는 입력된 피쳐를 통해 단어 의미론적 특징(fw)을 생성 할 수 있다. 또한, 타겟영상의 피쳐는 인공지능 알고리즘의 제2 브랜치(Detection Branch)에 입력될 수 있 다. 이때, 제2 브랜치(Detection Branch)에는 제1 브랜치에서 생성된 단어 의미론적 특징(fw)이 타겟영상 의 피쳐와 함께 입력될 수 있다. 상술한 동작에 의해, 인공지능 알고리즘은 타겟영상에 상응하는 다음과 같은 결과를 추출할 수 있다. 타겟영상에 포함된 캐릭터의 의미론적 특징(fc) 타겟영상에 포함된 단어의 의미론적 특징(fw) 타겟영상에 포함된 캐릭터의 위치(예를 들어, 사각형 박스 형태) 타겟영상에 포함된 단어의 위치(예를 들어, 단어를 구성하는 각 캐릭터의 사각형 박스 중간을 연결하 는 라인 형태) 타겟영상에 포함된 중복된 영역(예를 들어, 캐릭터 박스 중 중복된 부분) 프로세서는 인공지능 알고리즘에서 출력된 타겟영상의 상기 5가지 정보를 이용하여 타겟영상에 상응하는 단어의 위치를 출력할 수 있다. 예를 들어, 프로세서는 메모리에 저장된 프로그램 명령어들을 실행하여, 타켓영상에 포함된 단어의 위치를 경계상자의 형태로 출력할 수 있다. 인공지능 알고리즘에 서 출력된 정보들을 통해 타겟영상에 포함된 단어의 위치를 특정하는 방법은 당업자에 있어서 자명한 사항 인 바, 이에 대한 구체적인 설명은 생략될 수 있다. 상술한 본 발명에 따른 타겟영상의 텍스트 인식 동작은 컴퓨터로 읽을 수 있는 기록 매체인 메모리에 컴퓨 터가 읽을 수 있는 코드로서 구현되는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터 시스템에 의 하여 해독될 수 있는 데이터가 저장된 모든 종류의 기록 매체를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 통신망으로 연결된 컴퓨터 시스템에 분산되어, 분산방식 으로 읽을 수 있는 코드로서 저장되고 실행될 수 있다. 따라서, 프로세서는 메모리에 저장된 프로그 램 명령어(코드)를 실행시켜 상술한 타겟영상의 텍스트 인식 동작이 수행되도록 할 수 있다. 이상, 본 발명을 바람직한 실시예를 들어 상세하게 설명하였으나, 본 발명은 상기 실시 예에 한정되지 않고, 본 발명의 기술적 사상 및 범위 내에서 당 분야에서 통상의 지식을 가진 자에 의하여 여러가지 변형 및 변경이 가 능하다."}
{"patent_id": "10-2023-0018304", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 발명의 일 실시예에 따른 텍스트 인식 장치를 설명하기 위한 구성도이다. 도 2는 본 발명의 일 실시예에 따른 텍스트 인식 장치의 동작을 설명하기 위한 흐름도이다. 도 3은 본 발명의 일 실시예에 따른 텍스트 인식 장치의 인공지능 학습을 위한 학습데이터세트 생성 동작에 대 한 순서도이다. 도 4는 본 발명의 일 실시예에 따른 각 브랜치에서 생성된 분할지도에 대한 예시 이미지이다. 도 5는 본 발명의 일 실시예에 따른 정답 분할 지도에 대한 예시 이미지이다. 도 6은 본 발명의 일 실시예에 따른 텍스트 인식 장치의 인공지능 알고리즘이 학습되는 과정을 설명하기 위한 순서도이다. 도 7은 본 발명의 일 실시예에 따른 인공지능 알고리즘의 구조도이다."}
