{"patent_id": "10-2021-7008257", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0038977", "출원번호": "10-2021-7008257", "발명의 명칭": "딥 러닝 훈련 임무를 위한 프로세서 메모리 최적화 방법 및 장치", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "왕, 하이펑"}}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법에 있어서,제1 프로세서는 사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요청하기 위한 것인 단계;상기 제1 프로세서는 제1 경로와 제2 경로로부터 최적 경로를 결정하되, 상기 제1 경로에서 제1 컴퓨팅 유닛의계산 결과는 상기 제1 컴퓨팅 유닛에서 제2 컴퓨팅 유닛에 직접 도달하고, 상기 제2 경로에서 상기 제1 컴퓨팅유닛의 계산 결과는 제2 프로세서의 메모리에서 스왑 조작이 수행된 후 상기 제2 컴퓨팅 유닛에 도달하고, 상기제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 제2 컴퓨팅유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 단계;상기 제1 프로세서는 상기 최적 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계는,상기 제1 프로세서가 상기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하는 단계;상기 제1 프로세서는 상기 상태 정보에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계를 포함하는것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 상태 정보는,배치 크기, 훈련 샘플의 길이, 상기 계산 결과가 상기 그래픽 메모리를 점유한 공간의 크기, 상기 그래픽 메모리의 스왑 속도, 상기 그래픽 메모리의 나머지 공간의 크기 중 적어도 하나를 포함하되,상기 배치 크기는 상기 그래픽 메모리에 로딩되는 훈련 샘플의 크기를 지시하기 위한 것이고, 상기 그래픽 메모리의 스왑 속도는 단위 시간 내에 상기 그래픽 메모리에서 제2 프로세서의 메모리에 도달하는 데이터의 양을 지시하기 위한 것인 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항 내지 제 3 항 중 어느 한 항에 있어서, 상기 최적 경로는 상기 제2 경로이고, 상기 제1 프로세서가 제1경로와 제2 경로로부터 최적 경로를 결정하는 단계 후에,상기 제1 프로세서는 상기 적어도 하나의 중간 컴퓨팅 유닛으로부터 제 3 컴퓨팅 유닛을 결정하되, 상기 제 3컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛에 인접하고 상기 제2 컴퓨팅 유닛 앞에 위치한 컴퓨팅 유닛인 단계;상기 제1 프로세서는 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가하는 단계를더 포함하는 것을 특징으로 하는 방법.공개특허 10-2021-0038977-3-청구항 5 제 4 항에 있어서, 상기 스왑 동작은 스왑 아웃 동작 및 스왑 인 동작을 포함하고, 상기 제1 프로세서가 상기제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가하는 단계 이후에,상기 제1 프로세서는 상기 제1 컴퓨팅 유닛에 대응되는 연산을 수행하여 상기 계산 결과를 획득하는 단계;상기 제1 프로세서가 상기 계산 결과를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 계산 결과에대해 상기 스왑 아웃 동작을 수행하도록 하는 단계;상기 제1 프로세서는 상기 제 3 컴퓨팅 유닛에 대응되는 연산이 완료되었는지 여부를 판단하고, 상기 제1 프로세서가 상기 제 3 컴퓨팅 유닛에 대응되는 연산을 완료하면 지시 정보를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 제1 컴퓨팅 유닛의 계산 결과에 대해 상기 스왑 인 동작을 수행하도록 하는 단계;상기 제1 프로세서는 상기 제 3 컴퓨팅 유닛의 계산 결과와 상기 스왑 인 동작이 수행 완료된 계산 결과에 따라상기 제2 컴퓨팅 유닛에 대응되는 연산을 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항 또는 제 5 항에 있어서, 상기 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계후에,상기 제1 프로세서는 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송었되는지 여부를판단하는 단계;상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송되면, 상기 그래픽 메모리로부터 상기제1 컴퓨팅 유닛의 계산 결과가 점유하는 공간을 해제시키는 단계를 더 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항 내지 제 3 항 중 어느 한 항에 있어서, 상기 제1 프로세서는 텐서 프로세서(TPU) 또는 그래픽 프로세서(GPU)인 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 장치에 있어서,사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요청하기 위한 것인 수신 모듈;제1 경로와 제2 경로로부터 최적 경로를 결정하되, 상기 제1 경로에서 제1 컴퓨팅 유닛의 계산 결과는 상기 제1컴퓨팅 유닛에서 제2 컴퓨팅 유닛에 직접 도달하고, 상기 제2 경로에서 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리에서 스왑 조작이 수행된 후 상기 제2 컴퓨팅 유닛에 도달하고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 제2 컴퓨팅 유닛 사이에 적어도하나의 중간 컴퓨팅 유닛이 존재하는 처리 모듈;상기 최적 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 전송 모듈을포함하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 처리 모듈은 상기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하고, 상기 상태 정보에 따라 제1 경공개특허 10-2021-0038977-4-로와 제2 경로로부터 최적 경로를 결정하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 상기 상태 정보는,배치 크기, 훈련 샘플의 길이, 상기 계산 결과가 상기 그래픽 메모리를 점유한 공간의 크기, 상기 그래픽 메모리의 스왑 속도, 상기 그래픽 메모리의 나머지 공간의 크기 중 적어도 하나를 포함하되,상기 배치 크기는 상기 그래픽 메모리에 로딩되는 훈련 샘플의 크기를 지시하기 위한 것이고, 상기 그래픽 메모리의 스왑 속도는 단위 시간 내에 상기 그래픽 메모리에서 제2 프로세서의 메모리에 도달하는 데이터의 양을 지시하기 위한 것을 특징으로 하는 장치."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 8 항 내지 제10 항 중 어느 한 항에 있어서, 상기 최적 경로는 상기 제2 경로이고, 상기 처리 유닛은 제1 경로와 제2 경로로부터 최적 경로를 결정한 후에 또한, 상기 적어도 하나의 중간 컴퓨팅 유닛에서 제3 컴퓨팅 유닛을 결정하되, 상기 제3 컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛과 인접하고 상기 제2 컴퓨팅 유닛 앞에 위치한 컴퓨팅 유닛이고, 상기 제3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑동작의 의존 관계을 추가하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 스왑 동작은 스왑 아웃 동작 및 스왑 인 동작을 포함하고, 상기 처리 유닛은 상기 제 3컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가한 후에 또한, 상기 제1 컴퓨팅 유닛에 대응되는 연산을 수행하여 상기 계산 결과를 획득하고, 상기 계산 결과를 상기 제2 프로세서로 전송하여 상기 제2프로세서가 상기 계산 결과에 대해 상기 스왑 아웃 동작을 수행하도록 하고, 상기 제 3 컴퓨팅 유닛에 대응되는연산이 완료되었는지 여부를 판단하고, 상기 제1 프로세서가 상기 제 3 컴퓨팅 유닛에 대응되는 연산을 완료하면 지시 정보를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 제1 컴퓨팅 유닛의 계산 결과에 대해상기 스왑 인 동작을 수행하도록 하고, 상기 제 3 컴퓨팅 유닛의 계산 결과와 상기 스왑 인 동작이 수행 완료된계산 결과에 따라 상기 제2 컴퓨팅 유닛에 대응되는 연산을 수행하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항 또는 제12 항에 있어서,상기 처리 모듈은 제1 경로와 제2 경로로부터 최적 경로를 결정한 후에 또한, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송었되는지 여부를 판단하고, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기제2 프로세서의 메모리로 전송되면 상기 그래픽 메모리에서 상기 제1 컴퓨팅 유닛의 계산 결과가 점유하는 공간을 해제시키는 것을 특징으로 하는 장치."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 8 항 내지 제10 항 중 어느 한 항에 있어서, 상기 제1 프로세서는 텐서 프로세서(TPU) 또는 그래픽 프로세서(GPU)인 것을 특징으로 하는 장치."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "적어도 하나의 프로세서; 및공개특허 10-2021-0038977-5-상기 적어도 하나의 프로세서와 통신 연결되는 메모리;를 포함하되,여기서, 상기 메모리는 적어도 하나의 프로세서에 의해 실행 가능한 명령을 저장하고, 상기 명령은 상기 적어도하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1 항 내지 제 7 항 중 어느 한 항에 따른방법을 실행할 수 있도록 하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제 7 항 중 어느 한 항에 따른 방법을 수행하도록 하는 것을 특징으로 하는 비 일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2021-7008257", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1 프로세서는 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하기 위한 경로를 결정하되, 상기 제1컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 단계;상기 제1 프로세서는 상기 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 단계를 포함하는 것을 특징으로 하는 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법."}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법 및 장치를 개시하며, 인공 지능"}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 해당 방법에서는 계산 결과를 전달하기 위한 최적 경로를 결정하고 최적 경로를 사용하여 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하여 그래픽 메모리의 점유를 방지하고 동시에 그래픽 메모리 스왑으로 인한 GPU의 컴퓨팅 유닛의 사용률이 낮은 문제를 방지함으로써, 대부분의 임무의 훈련 속도가 거의 감소되지 않도록 한다. 대 표 도 - 도2"}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2021-0038977 CPC특허분류 G06T 1/60 (2013.01) G06F 2212/302 (2013.01)명 세 서 청구범위 청구항 1 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법에 있어서, 제1 프로세서는 사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요청하 기 위한 것인 단계; 상기 제1 프로세서는 제1 경로와 제2 경로로부터 최적 경로를 결정하되, 상기 제1 경로에서 제1 컴퓨팅 유닛의 계산 결과는 상기 제1 컴퓨팅 유닛에서 제2 컴퓨팅 유닛에 직접 도달하고, 상기 제2 경로에서 상기 제1 컴퓨팅 유닛의 계산 결과는 제2 프로세서의 메모리에서 스왑 조작이 수행된 후 상기 제2 컴퓨팅 유닛에 도달하고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 제2 컴퓨팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 단계; 상기 제1 프로세서는 상기 최적 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전 송하는 단계를 포함하는 것을 특징으로 하는 방법. 청구항 2 제1 항에 있어서, 상기 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계는, 상기 제1 프로세서가 상기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하는 단계; 상기 제1 프로세서는 상기 상태 정보에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계를 포함하는 것을 특징으로 하는 방법. 청구항 3 제2 항에 있어서, 상기 상태 정보는, 배치 크기, 훈련 샘플의 길이, 상기 계산 결과가 상기 그래픽 메모리를 점유한 공간의 크기, 상기 그래픽 메모 리의 스왑 속도, 상기 그래픽 메모리의 나머지 공간의 크기 중 적어도 하나를 포함하되, 상기 배치 크기는 상기 그래픽 메모리에 로딩되는 훈련 샘플의 크기를 지시하기 위한 것이고, 상기 그래픽 메모 리의 스왑 속도는 단위 시간 내에 상기 그래픽 메모리에서 제2 프로세서의 메모리에 도달하는 데이터의 양을 지 시하기 위한 것인 것을 특징으로 하는 방법. 청구항 4 제1 항 내지 제 3 항 중 어느 한 항에 있어서, 상기 최적 경로는 상기 제2 경로이고, 상기 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계 후에, 상기 제1 프로세서는 상기 적어도 하나의 중간 컴퓨팅 유닛으로부터 제 3 컴퓨팅 유닛을 결정하되, 상기 제 3 컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛에 인접하고 상기 제2 컴퓨팅 유 닛 앞에 위치한 컴퓨팅 유닛인 단계; 상기 제1 프로세서는 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가하는 단계를 더 포함하는 것을 특징으로 하는 방법.청구항 5 제 4 항에 있어서, 상기 스왑 동작은 스왑 아웃 동작 및 스왑 인 동작을 포함하고, 상기 제1 프로세서가 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가하는 단계 이후에, 상기 제1 프로세서는 상기 제1 컴퓨팅 유닛에 대응되는 연산을 수행하여 상기 계산 결과를 획득하는 단계; 상기 제1 프로세서가 상기 계산 결과를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 계산 결과에 대해 상기 스왑 아웃 동작을 수행하도록 하는 단계; 상기 제1 프로세서는 상기 제 3 컴퓨팅 유닛에 대응되는 연산이 완료되었는지 여부를 판단하고, 상기 제1 프로 세서가 상기 제 3 컴퓨팅 유닛에 대응되는 연산을 완료하면 지시 정보를 상기 제2 프로세서로 전송하여 상기 제 2 프로세서가 상기 제1 컴퓨팅 유닛의 계산 결과에 대해 상기 스왑 인 동작을 수행하도록 하는 단계; 상기 제1 프로세서는 상기 제 3 컴퓨팅 유닛의 계산 결과와 상기 스왑 인 동작이 수행 완료된 계산 결과에 따라 상기 제2 컴퓨팅 유닛에 대응되는 연산을 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법. 청구항 6 제 4 항 또는 제 5 항에 있어서, 상기 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계 후에, 상기 제1 프로세서는 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송었되는지 여부를 판단하는 단계; 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송되면, 상기 그래픽 메모리로부터 상기 제1 컴퓨팅 유닛의 계산 결과가 점유하는 공간을 해제시키는 단계를 더 포함하는 것을 특징으로 하는 방법. 청구항 7 제1 항 내지 제 3 항 중 어느 한 항에 있어서, 상기 제1 프로세서는 텐서 프로세서(TPU) 또는 그래픽 프로세서 (GPU)인 것을 특징으로 하는 방법. 청구항 8 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 장치에 있어서, 사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요청하기 위한 것인 수 신 모듈; 제1 경로와 제2 경로로부터 최적 경로를 결정하되, 상기 제1 경로에서 제1 컴퓨팅 유닛의 계산 결과는 상기 제1 컴퓨팅 유닛에서 제2 컴퓨팅 유닛에 직접 도달하고, 상기 제2 경로에서 상기 제1 컴퓨팅 유닛의 계산 결과가 상 기 제2 프로세서의 메모리에서 스왑 조작이 수행된 후 상기 제2 컴퓨팅 유닛에 도달하고, 상기 제1 컴퓨팅 유닛 과 상기 제2 컴퓨팅 유닛은 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 제2 컴퓨팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 처리 모듈; 상기 최적 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 전송 모듈을 포함하는 것을 특징으로 하는 장치. 청구항 9 제 8 항에 있어서, 상기 처리 모듈은 상기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하고, 상기 상태 정보에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정하는 것을 특징으로 하는 장치. 청구항 10 제 9 항에 있어서, 상기 상태 정보는, 배치 크기, 훈련 샘플의 길이, 상기 계산 결과가 상기 그래픽 메모리를 점유한 공간의 크기, 상기 그래픽 메모 리의 스왑 속도, 상기 그래픽 메모리의 나머지 공간의 크기 중 적어도 하나를 포함하되, 상기 배치 크기는 상기 그래픽 메모리에 로딩되는 훈련 샘플의 크기를 지시하기 위한 것이고, 상기 그래픽 메모 리의 스왑 속도는 단위 시간 내에 상기 그래픽 메모리에서 제2 프로세서의 메모리에 도달하는 데이터의 양을 지 시하기 위한 것을 특징으로 하는 장치. 청구항 11 제 8 항 내지 제10 항 중 어느 한 항에 있어서, 상기 최적 경로는 상기 제2 경로이고, 상기 처리 유닛은 제1 경 로와 제2 경로로부터 최적 경로를 결정한 후에 또한, 상기 적어도 하나의 중간 컴퓨팅 유닛에서 제3 컴퓨팅 유 닛을 결정하되, 상기 제3 컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛과 인접 하고 상기 제2 컴퓨팅 유닛 앞에 위치한 컴퓨팅 유닛이고, 상기 제3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계을 추가하는 것을 특징으로 하는 장치. 청구항 12 제11 항에 있어서, 상기 스왑 동작은 스왑 아웃 동작 및 스왑 인 동작을 포함하고, 상기 처리 유닛은 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가한 후에 또한, 상기 제1 컴퓨팅 유닛에 대응 되는 연산을 수행하여 상기 계산 결과를 획득하고, 상기 계산 결과를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 계산 결과에 대해 상기 스왑 아웃 동작을 수행하도록 하고, 상기 제 3 컴퓨팅 유닛에 대응되는 연산이 완료되었는지 여부를 판단하고, 상기 제1 프로세서가 상기 제 3 컴퓨팅 유닛에 대응되는 연산을 완료하 면 지시 정보를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 제1 컴퓨팅 유닛의 계산 결과에 대해 상기 스왑 인 동작을 수행하도록 하고, 상기 제 3 컴퓨팅 유닛의 계산 결과와 상기 스왑 인 동작이 수행 완료된 계산 결과에 따라 상기 제2 컴퓨팅 유닛에 대응되는 연산을 수행하는 것을 특징으로 하는 장치. 청구항 13 제11 항 또는 제12 항에 있어서, 상기 처리 모듈은 제1 경로와 제2 경로로부터 최적 경로를 결정한 후에 또한, 상기 제1 컴퓨팅 유닛의 계산 결 과가 상기 제2 프로세서의 메모리로 전송었되는지 여부를 판단하고, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송되면 상기 그래픽 메모리에서 상기 제1 컴퓨팅 유닛의 계산 결과가 점유하는 공간 을 해제시키는 것을 특징으로 하는 장치. 청구항 14 제 8 항 내지 제10 항 중 어느 한 항에 있어서, 상기 제1 프로세서는 텐서 프로세서(TPU) 또는 그래픽 프로세서 (GPU)인 것을 특징으로 하는 장치. 청구항 15 적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리;를 포함하되, 여기서, 상기 메모리는 적어도 하나의 프로세서에 의해 실행 가능한 명령을 저장하고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1 항 내지 제 7 항 중 어느 한 항에 따른 방법을 실행할 수 있도록 하는 것을 특징으로 하는 전자 기기. 청구항 16 컴퓨터 명령이 저장된 비 일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1 항 내지 제 7 항 중 어느 한 항에 따른 방법을 수행하도록 하는 것을 특징으로 하는 비 일시적 컴퓨터 판독 가 능 저장 매체. 청구항 17 제1 프로세서는 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하기 위한 경로를 결정하되, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨 팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 단계; 상기 제1 프로세서는 상기 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하 는 단계를 포함하는 것을 특징으로 하는 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법. 발명의 설명 기 술 분 야 본 출원의 실시예는 딥 러닝 기술 분야에 관한 것으로, 특히 딥 러닝 훈련 임무를 위한 프로세서 메모리 최적화 방법 및 장치에 관한 것이다. 본 출원은 2019년 10월 18일 중국 전리국에 출원한 출원번호가 2019109963093이고, 출원의 명칭이 \"딥 러닝 훈 련 임무를 위한 프로세서 메모리 최적화 방법 및 장치\"인 중국 특허 출원의 우선권을 주장하며, 그 전부 내용은 인용을 통해 본 출원에 결합된다."}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 딥 러닝(Deep Learning)은 머신 러닝 연구 중 새로운 분야로, 인간 두뇌를 시뮬레이션하여 분석 및 학습을 수행하는 신경망을 구축함으로써, 인간 두뇌를 시뮬레이션하는 메커니즘으로 이미지, 소리와 텍스트 등의 데이 터를 해석하고자 하는 것이다. 딥 러닝의 보다 일반적인 응용은 이미지 인식과 음성 인식 등이다. 응용 과정에 서 얼굴 인식 모델, 음성 인식 모델 등과 같은 딥 러닝 모델을 훈련시켜야 한다. 일반적으로 그래픽 프로세서(Graphics Processing Unit, GPU)와 같은 프로세서를 사용하여 딥 러닝 모델을 훈련 한다. GPU는 여러 컴퓨팅 유닛, 소량의 제어 유닛 및 저장 유닛을 포함한다. GPU의 컴퓨팅 유닛의 사용률을 충 분히 높이기 위해서는 매번 훈련하는 임무 수를 늘려야 하며, 임무 수는 컴퓨팅 유닛이 훈련 샘플에 대해 더하 기, 빼기, 곱하기, 나누기, 적분 등의 연산을 수행하는 횟수를 말한다. 분명한 것은 매번 GPU 그래픽 메모리에 로딩되는 훈련 샘플 수가 많을수록 임무 수가 많아진다. 이 중 매번 GPU 그래픽 메모리에 로딩되는 훈련 샘플의 수를 배치 크기(batch size)라고도 한다. 다만 GPU 그래픽 메모리의 크기는 일정하며, 즉 GPU의 저장 유닛의 수량이 일정하다. 딥 러닝 모델이 비교적 복 잡할 경우, 배치 크기가 커짐에 따라 GPU 그래픽 메모리가 대량 점유되어, 딥 러닝 모델의 훈련을 완성할 수 없 게 된다. 따라서 딥 러닝 모델 훈련 과정에서 GPU 그래픽 메모리에 대한 최적화는 시급히 해결해야 할 문제이다."}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원의 실시예는 계산 결과를 전송하기 위한 최적 경로를 결정함으로써, 최적 경로를 사용하여 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하여, 그래픽 메모리 점유를 방지하면서, 그래픽 메모리 스왑으로 인한 GPU의 컴퓨팅 유닛의 사용률 저하 문제를 방지하는, 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최 적화 방법 및 장치를 제공한다."}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1 측면에서, 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법에 따르 면, 제1 프로세서는 사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요 청하기 위한 것인 단계; 제1 경로와 제2 경로로부터 최적 경로를 결정하되, 상기 제1 경로에서 제1 컴퓨팅 유닛 의 계산 결과는 상기 제1 컴퓨팅 유닛에서 제2 컴퓨팅 유닛에 직접 도달하고, 상기 제2 경로에서 상기 제1 컴퓨 팅 유닛의 계산 결과는 제2 프로세서의 메모리에서 스왑 조작이 수행된 후 상기 제2 컴퓨팅 유닛에 도달하고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 단계; 상기 최적 경로를 통해 상기 제1 컴 퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 단계를 포함한다. 이런 방안을 사용하여 계산 결 과를 전송하기 위한 최적 경로를 결정하고, 최적 경로를 사용하여 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하여 그래픽 메모리를 점유하는 것을 방지하고, 동시에 그래픽 메모리 스왑으로 인한 GPU의 컴퓨 팅 유닛의 사용률이 낮은 문제를 방지함으로써 대부분의 임무의 훈련 속도가 거의 감소되지 않도록 한다. 또한 실제 훈련 환경에서 그래픽 메모리 점유는 일반적으로 훈련 샘플의 번호에 따라 피크치를 가지며, 일반적으로 소수의 샘플만 피크치 경우에 도달할 수 있다. 본 출원의 실시예에 따른 방안을 사용하면 극히 적은 경우에 대 해서만 스왑(swap) 동작을 동적으로 늘려 피크치 그래픽 메모리 사용 수요를 충족시킴으로써 스토리지 오버플로 로 인한 훈련 실패를 방지할 수 있으며, 대부분의 비피크치 상황에서는 스왑 동작을 늘릴 필요가 없고, 그래픽 메모리 스왑으로 인한 오버 헤드를 방지하고 훈련 속도를 보장한다. 일 가능한 설계에 있어서, 상기 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계는, 상기 제1 프로세서가 상기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하는 단계; 상기 제1 프로세서는 상기 상태 정보에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계를 포함한다. 이 방안을 사용하여, 일 가능한 설계에 있어서, 상기 상태 정보는, 배치 크기, 훈련 샘플의 길이, 상기 계산 결과가 상기 그래픽 메 모리를 점유한 공간의 크기, 상기 그래픽 메모리의 스왑 속도, 상기 그래픽 메모리의 나머지 공간의 크기 중 적 어도 하나를 포함하되, 상기 배치 크기는 상기 그래픽 메모리에 로딩되는 훈련 샘플의 크기를 지시하기 위한 것 이고, 상기 그래픽 메모리의 스왑 속도는 단위 시간 내에 상기 그래픽 메모리에서 제2 프로세서의 메모리에 도 달하는 데이터의 양을 지시하기 위한 것이다. 이 방안을 사용하여, 일 가능한 설계에 있어서, 상기 최적 경로는 상기 제2 경로이고, 상기 제1 프로세서가 제1 경로와 제2 경로로부 터 최적 경로를 결정하는 단계 후에, 상기 제1 프로세서는 상기 적어도 하나의 중간 컴퓨팅 유닛으로부터 제 3 컴퓨팅 유닛을 결정하되, 상기 제 3 컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛에 인접하고 상기 제2 컴퓨팅 유닛 앞에 위치한 컴퓨팅 유닛인 단계; 제1 프로세서는 상기 제 3 컴퓨팅 유 닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가하는 단계를 더 포함한다. 이 방안을 사용하여, 일 가능한 설계에 있어서, 상기 스왑 동작은 스왑 아웃 동작 및 스왑 인 동작을 포함하고, 상기 제1 프로세서는 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가하는 단계 이후에, 상기 제1 컴퓨 팅 유닛에 대응되는 연산을 더 수행하여 상기 계산 결과를 획득하는 단계; 상기 계산 결과를 상기 제2 프로세서 로 전송하여 상기 제2 프로세서가 상기 계산 결과에 대해 상기 스왑 아웃 동작을 수행하도록 하는 단계; 상기 제 3 컴퓨팅 유닛에 대응되는 연산이 완료되었는지 여부를 판단하고, 상기 제1 프로세서가 상기 제 3 컴퓨팅 유 닛에 대응되는 연산을 완료하면 지시 정보를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 제1 컴퓨 팅 유닛의 계산 결과에 대해 상기 스왑 인 동작을 수행하도록 하는 단계; 상기 제 3 컴퓨팅 유닛의 계산 결과와 상기 스왑 인 동작이 수행 완료된 계산 결과에 따라 상기 제2 컴퓨팅 유닛에 대응되는 연산을 수행하는 단계를 더 포함한다. 이 방안을 사용하여, 일 가능한 설계에 있어서, 상기 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정하는 단계 후에, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송었되는지 여부를 판단하는 단계; 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송되면, 상기 그래픽 메모리로부터 상기 제1 컴퓨팅 유닛의 계산 결과가 점유한 공간을 해제시키는 단계를 더 포함한다. 이 방안을 사용하여,일 가능한 설계에 있어서, 상기 제1 프로세서는 텐서 프로세서(TPU) 또는 그래픽 프로세서(GPU)이다. 제2 측면에서, 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 장치는, 사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요청하기 위한 것인 수 신 모듈; 제1 경로와 제2 경로로부터 최적 경로를 결정하되, 상기 제1 경로에서 제1 컴퓨팅 유닛의 계산 결과는 상기 제1 컴퓨팅 유닛에서 제2 컴퓨팅 유닛에 직접 도달하고, 상기 제2 경로에서 상기 제1 컴퓨팅 유닛의 계산 결과가 제 2 프로세서의 메모리에서 스왑 조작이 수행된 후 상기 제2 컴퓨팅 유닛에 도달하고, 상기 제1 컴퓨팅 유닛과 상 기 제2 컴퓨팅 유닛은 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 처리 모듈; 상기 최적 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 전송 모듈을 포함한다. 일 가능한 설계에 있어서, 상기 처리 모듈은 상기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하고, 상기 상태 정보에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정한다. 일 가능한 설계에 있어서, 상기 상태 정보는, 배치 크기, 훈련 샘플의 길이, 상기 계산 결과가 상기 그래픽 메 모리를 점유한 공간의 크기, 상기 그래픽 메모리의 스왑 속도, 상기 그래픽 메모리의 나머지 공간의 크기 중 적 어도 하나를 포함하되, 상기 배치 크기는 상기 그래픽 메모리에 로딩되는 훈련 샘플의 크기를 지시하기 위한 것 이고, 상기 그래픽 메모리의 스왑 속도는 단위 시간 내에 상기 그래픽 메모리에서 제2 프로세서의 메모리에 도 달하는 데이터의 양을 지시하기 위한 것이다. 일 가능한 설계에 있어서, 상기 최적 경로는 상기 제2 경로이고, 상기 처리 유닛은 제1 경로와 제2 경로로부터 최적 경로를 결정한 후에 또한 상기 적어도 하나의 중간 컴퓨팅 유닛에서 제3 컴퓨팅 유닛을 결정하되, 상기 제 3 컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛과 인접하고 상기 제2 컴퓨팅 유닛 앞에 위치한 컴퓨팅 유닛이고, 상기 제3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계을 추 가한다. 일 가능한 설계에 있어서, 상기 스왑 동작은 스왑 아웃 동작 및 스왑 인 동작을 포함하고, 상기 처리 유닛은 상 기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가한 후에 또한, 상기 제1 컴퓨팅 유닛 에 대응되는 연산을 수행하여 상기 계산 결과를 획득하고, 상기 계산 결과를 상기 제2 프로세서로 전송하여 상 기 제2 프로세서가 상기 계산 결과에 대해 상기 스왑 아웃 동작을 수행하도록 하고, 상기 제 3 컴퓨팅 유닛에 대응되는 연산이 완료되었는지 여부를 판단하고, 상기 제1 프로세서가 상기 제 3 컴퓨팅 유닛에 대응되는 연산 을 완료하면 지시 정보를 상기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 제1 컴퓨팅 유닛의 계산 결 과에 대해 상기 스왑 인 동작을 수행하도록 하고, 상기 제 3 컴퓨팅 유닛의 계산 결과와 상기 스왑 인 동작이 수행 완료된 계산 결과에 따라 상기 제2 컴퓨팅 유닛에 대응되는 연산을 수행한다. 일 가능한 설계에 있어서, 상기 처리 모듈은 제1 경로와 제2 경로로부터 최적 경로를 결정한 후에 또한, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송었되는지 여부를 판단하고, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송되면 상기 그래픽 메모리에서 상기 제1 컴퓨팅 유닛의 계산 결과가 점유하는 공간을 해제시킨다. 일 가능한 설계에 있어서, 상기 제1 프로세서는 텐서 프로세서(TPU) 또는 그래픽 프로세서(GPU)이다. 제 3 측면에서, 본 출원의 실시예에 따른 전자 기기는, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리;를 포함하되, 여기서, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령을 저장하고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1 측면 또는 제1 측면의 임의의 가 능한 구현 방법을 실행할 수 있도록 한다. 제 4 측면에서, 본 출원의 실시예에 따른 명령을 포함하는 컴퓨터 프로그램 제품은 전자 기기 상에서 실행될 때 전자 기기 컴퓨터가 제1 측면 또는 제1 측면의 다양한 가능한 구현 방식 중의 방법을 수행하도록 한다.제 5 측면에서, 본 출원의 실시예에 따른 저장 매체에 있어서, 상기 저장 매체에는 명령이 저장되고, 상기 명령 이 전자 기기에서 실행될 때 전자 기기가 제1 측면 또는 제1 측면의 다양한 가능한 구현 방식 중의 방법을 실행 하도록 한다. 제 6 측면에서, 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법은, 제 1 프로세서는 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하기 위한 경로를 결정하되, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨 팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 단계; 상기 제1 프로세서는 상기 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 단계를 포함한다."}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 출원의 실시예는 다음과 같은 장점 또는 유익한 효과가 있다. 즉, 계산 결과를 전송하기 위한 최적 경로를 결정하고, 최적 경로를 사용하여 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송함으로써, 그래픽 메 모리를 점유하는 것을 방지하면서, 그래픽 메모리 스왑으로 인한 GPU의 컴퓨팅 유닛의 낮은 사용률 문제를 방지 한다. 이로부터 대부분의 임무의 훈련 속도가 거의 감소되지 않는다. 또한 실제 훈련 환경에서 그래픽 메모리 점유는 일반적으로 훈련 샘플 번호에 따라 피크치를 가지며 일반적으로 소수의 샘플만 피크에 도달할 수 있다. 본 출원의 실시예에 따른 방안을 사용하면 극히 적은 경우에만 스왑 조작을 동적으로 늘려 피크치 그래픽 메모 리의 사용 수요를 충족시킴으로써 스토리지 오버플로로 인한 훈련 실패를 방지할 수 있으며, 대부분의 비피크치 경우에는 스왑 동작을 늘릴 필요가 없기에 그래픽 메모리 스왑으로 인한 오버 헤드를 방지하고 훈련 속도를 보 장한다. 상술한 선택적 방식의 기타 효과는 아래에서 특정 실시예와 결합하여 설명될 것이다."}
{"patent_id": "10-2021-7008257", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부 도면을 결합하여 본 출원의 예시적 실시예에 대해 설명한다. 여기에는 본 출원의 실시예의 다 양한 세부내역을 포함하여 쉽게 이해할 수 있도록 한다. 이들은 단지 예시적인 것으로 간주하여야 한다. 따라서, 당업자는, 여기에 기재된 실시예에 대해 다양한 변형 및 수정을 가할 수 있으며, 본 출원의 범위와 정 신을 벗어나지 않는 것으로 간주하여야 한다. 마찬가지로, 명확성과 간결성을 위하여, 아래의 기재에서 공지 기 능과 구조에 대한 설명을 생략한다. 현재 통상적으로 GPU를 사용하여 딥 러닝 모델의 훈련을 완성한다. GPU에는 소량의 제어 유닛, 저장 유닛 및 대 량의 컴퓨팅 유닛이 포함되어 동시성이 좋고, 컴퓨팅 유닛의 수가 5120개 심지어 그 이상에 이를 수 있다. GPU 의 컴퓨팅 유닛의 사용률을 높이기 위해서는 매번 GPU의 그래픽 메모리에 로딩되는 훈련 샘플 수를 늘려야 하며, 매번 GPU의 그래픽 메모리에 로딩되는 훈련 샘플 수를 배치 크기(batch size)라고도 한다. 그러나 GPU의 그래픽 메모리 크기가 제한되어, 배치 크기를 무한히 늘릴 수 없으므로, 훈련하여 딥 러닝 모델을 얻을 수 없게 된다.이를 감안하여, 본 출원의 실시예는 계산 결과를 전송하기 위한 최적 경로를 결정함으로써, 최적 경로를 사용하 여 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하여, 그래픽 메모리의 점유를 방지하면서 그래픽 메모리 스왑으로 인한 GPU의 컴퓨팅 유닛의 낮은 사용률 문제를 방지하는 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 제공한다. 도 1은 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법의 운영 환경의 도면이다. 도 1을 참조하면, 전자 기기는 단말기일 수 있고 서버 등일 수도 있다. 전자 기기에는 적어도 두 개 의 프로세서, 즉 제1 프로세서와 제2 프로세서가 설치되고, 제1 프로세서에는 대량의 컴퓨팅 유닛 및 소의 저장 유닛과 제어 유닛이 포함되고, 제2 프로세서는 저장 공간이 큰 메모리 장치와 직접 연결되며, 메모리 장치는 메 모리 스틱, 솔리드 스테이트 드라이브 디스크(Solid State Disk 또는 Solid State Drive, SSD)일 수 있다. 제1 프로세서의 저장 유닛을 제1 프로세서의 그래픽 메모리라고 하고, 제2 프로세서에 직접 연결된 메모리 장치를 제2 프로세서의 메모리라고 하며, 제1 프로세서는 GPU, 텐서 프로세서(TPU) 등일 수 있다. 본 출원의 실시예에서 제1 프로세서는 딥 러닝 모델을 얻기 위해 훈련 샘플에 대해 훈련을 수행하는데 사용되고, 훈련 과정에서 제2 컴퓨팅 유닛이 제1 컴퓨팅 유닛의 계산 결과를 사용해야 하는 경우, 제1 컴퓨팅 유닛은 계산 결과를 출력한다. 해당 계산 결과는 제1 프로세서의 그래픽 메모리에 저장된다. 제1 프로세서는 해 당 계산 결과가 어느 경로를 통해 제2 컴퓨팅 유닛에 도달할지를 판단한다. 예를 들어, 제1 경로를 통해 제1 컴 퓨팅 유닛에서 제2 컴퓨팅 유닛으로 직접 도달하거나; 또는 그래픽 메모리 스왑을 기반으로 제2 경로를 통해 제 2 컴퓨팅 유닛에 도달한다. 해당 계산 결과가 그래픽 메모리 스왑을 통해 제2 컴퓨팅 유닛에 도달하면, 제2 프 로세서는 스왑(swap) 동작을 통해 그래픽 메모리의 데이터를 제2 프로세서의 메모리로 스왑한 후 제2 컴퓨팅 유 닛으로 전송한다. 그래픽 메모리 중의 데이터가 제2 프로세서의 메모리로 스왑되면, 제1 프로세서는 계산 결과 가 점유하는 그래픽 메모리를 해제하여 그래픽 메모리에 대한 최적화를 실현할 수 있다. 이하에서는 전술한 도 1을 기반으로 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모 리 최적화 방법을 상세히 설명한다. 예시적으로 도 2를 참조할 수 있다. 도 2는 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법의 흐름도이며, 본 실시예는 아래의 단계를 포함한다. 101, 제1 프로세서는 사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요 청하기 위한 것이다. 예시적으로, 얼굴 인식 모델, 이미지 분류 모델, 음성 인식 모델 등과 같은 딥 러닝 모델의 훈련이 필요한 경우, 사용자는 클릭 조작, 터치 조작 등을 통해 전자 기기에 요청 명령을 입력하고, 전자 기기의 제1 프로세서 는 해당 딥 러닝 모델 훈련을 요청하기 위한 요청 명령을 수신하고 인식한다. 102, 상기 제1 프로세서는 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하기 위한 경로를 결정한다. 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유 닛과 상기 제2 컴퓨팅 유닛 사이에는 적어도 하나의 중간 컴퓨팅 유닛이 존재한다. 예시적으로, 제1 프로세서에 포함된 각 컴퓨팅 유닛은 독립적이지 않고 서로 의존 관계를 갖는다. 예를 들어, 제2 컴퓨팅 유닛의 계산은 제1 컴퓨팅 유닛의 계산 결과에 의존하고, 동시에 제1 컴퓨팅 유닛과 제2 컴퓨팅 유 닛 사이에 여러 개의 중간 컴퓨팅 유닛이 있으며, 제1 컴퓨팅 유닛의 계산 결과는 여러 개의 중간 컴퓨팅 유닛 에 의해 순차적으로 처리된 후, 마지막 하나의 중간 컴퓨팅 유닛(이하 제 3 컴퓨팅 유닛이라고 함)에 의해 제2 컴퓨팅 유닛에 입력된다. 제2 컴퓨팅 유닛은 제1 컴퓨팅 유닛의 계산 결과와 제 3 컴퓨팅 유닛의 계산 결과를 사용해야 하므로, 제1 컴퓨팅 유닛에 의해 계산 결과를 얻은 후, 해당 계산 결과가 그래픽 메모리를 많이 점유 한다면, 해당 계산 결과가 제1 경로를 통과할 때, 즉 제1 컴퓨팅 유닛에서 제2 컴퓨팅 유닛으로 직접 전달되는 경우, 해당 계산 결과는 줄곧 제1 프로세서의 그래픽 메모리에 저장되어야 하며, 이때 제1 프로세서의 그래픽 메모리를 점유하게 된다. 따라서 제2 경로, 즉, 그래픽 메모리 스왑을 통해 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전달하고, 다시 말하면, 제1 컴퓨팅 유닛에서 계산 결과를 얻은 후, 스왑 동작을 통해 해당 계 산 결과가 제2 프로세서의 메모리로 스왑되고, 그 다음 제2 컴퓨팅 유닛에 도달한다. 그러나 스왑 동작은 계산 결과를 제1 프로세서의 그래픽 메모리에서 제2 프로세서의 메모리로 스왑해야 하지만, 제2 프로세서와 메모리는 고속 직렬 컴퓨터 확장(Peripheral Component Interconnect Express, PCIE) 버스를 통해 연결되고, 해당 PCIE 버스의 시스템 대역폭이 비교적 낮기 때문에, 제2 프로세서에서 메모리로 복사되는데 많은 시간이 소요되어 배 치 크기(batch size)를 증가시키더라도 제1 프로세서의 컴퓨팅 유닛의 사용률이 향상되지 않게 된다. 또한 제2경로를 채택하면 많은 양의 그래픽 메모리를 해제할 수 있으므로 대규모 파라미터의 딥 러닝 모델의 훈련을 구 현할 수 있다. 상술한 바에 따르면, 제1 경로는 제1 프로세서의 그래픽 메모리를 점유하고 대규모 파라미터의 딥 러닝 모델의 훈련을 실현할 수 없으며, 제2 경로는 제1 프로세서의 컴퓨팅 유닛의 사용률의 저하를 초래한다. 따라서 본 단 계에서 제1 프로세서는 제1 경로와 제2 경로로부터 최적 경로를 결정하여, 단점을 최소화한다. 또한, 제1 컴퓨 팅 유닛에 입력되는 훈련 샘플은 지속적으로 변화하고, 제1 컴퓨팅 유닛의 계산 결과는 동적으로 변하기 때문에 제1 프로세서에 의해 결정된 최적 경로도 동적으로 변한다. 예를 들어, 제1 프로세서의 그래픽 메모리에 로딩되 는 1개 배치의 훈련 샘플이 1024 개이고, 해당 1024 개의 훈련 샘플에 길이가 128, 512 등인 훈련 샘플이 포함 되는 것으로 가정하면, 길이가 128인 훈련 샘플에 있어서, 제1 컴퓨팅 유닛이 해당 훈련 샘플을 훈련하여 얻은 계산 결과가 작기에 점유하는 그래픽 메모리가 비교적 작고, 제2 경로를 통해 해당 계산 결과를 전송하면 스왑 시간이 증가되어 딥 러닝 모델의 훈련 속도가 느려진다. 그러므로 제1 프로세서에 의해 결정되는 최적 경로는 제1 경로이고; 길이가 512인 훈련 샘플에 있어서, 제1 컴퓨팅 유닛이 해당 훈련 샘플을 훈련하여 얻은 계산 결 과는 비교적 크기에 점유하는 그래픽 메모리가 비교적 크고, 제1 경로를 통해 전송하면 제1 프로세서의 그래픽 메모리를 점유하고 딥 러닝 모델 훈련이 실패하므로 제1 프로세서가 결정한 최적 경로는 제2 경로이다. 103, 제1 프로세서는 상기 최적 경로를 통해 상기 제1 컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전 송한다. 예시적으로, 최적 경로가 제1 경로인 경우, 제1 프로세서는 제1 프로세서의 그래픽 메모리에 제1 컴퓨팅 유닛의 계산 결과를 저장하고, 해당 계산 결과가 제2 컴퓨팅 유닛에 도달한 후 제1 프로세서는 해당 계산 결과가 점유 하는 그래픽 메모리를 해제한다. 최적 경로가 제2 경로인 경우 제1 프로세서는 제1 컴퓨팅 유닛의 계산 결과를 제2 프로세서로 전송하여 제2 프로세서가 해당 계산 결과에 대해 스왑 인(swap_in) 동작 및 스왑 아웃 (swap_out) 동작과 같은 스왑(swap) 동작을 실행하도록 한다. 제1 컴퓨팅 유닛의 계산 결과가 제2 프로세서의 메모리에 도달하면, 즉 스왑 인 동작을 수행한 후 제1 프로세서는 해당 계산 결과가 점유하는 그래픽 메모리를 해제한다. 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법에서, 제1 프로세서는 딥 러닝 모델 훈련을 요청하는 요청 명령을 수신한 후에 제1 경로와 제2 경로로부터 최적 경로를 결정하고, 해 당 제1 경로는 제1 컴퓨팅 유닛에서 제2 컴퓨팅 유닛으로 직접 도달하는 것이고, 제2 경로는 그래픽 메모리 스 왑을 통해 제2 컴퓨팅 유닛에 도달하는 것이며, 그 다음 제1 프로세서는 최적 경로를 통해 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송한다. 이런 방안을 사용하면 계산 결과를 전송하기 위한 최적 경로를 결 정하고, 최적 경로를 사용하여 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송함으로써, 그래픽 메모 리의 점유를 방지하고 그래픽 메모리 스왑으로 인한 GPU의 컴퓨팅 유닛의 낮은 사용률 문제를 방지하고, 대부분 의 임무의 훈련 속도가를 거의 감소되지 않도록 한다. 또한 실제 훈련 환경에서 그래픽 메모리 점유는 훈련 샘 플의 번호에 따라 일반적으로 피크치를 가지며, 일반적으로 소량의 샘플만 피크치에 도달할 수 있다. 본 실시예 에 따른 방안을 사용하면 극히 적은 경우에 대해서만 동적으로 스왑 동작을 늘려 피크치 그래픽 메모리의 사용 수요를 충족시킬 수 있고 스토리지 오버플로로 인한 훈련 실패를 방지할 수 있으며, 대부분 비피크치 경우에 대 해서는 스왑 동작을 늘릴 필요가 없고 그래픽 메모리 스왑으로 인한 오버 헤드를 방지하고 훈련 속도를 보장한 다. 이하에서는 상술한 실시예 중의 제1 프로세서가 어떻게 최적 경로를 결정하는지에 대해 상세히 설명한다. 가능한 구현 방식에서, 제1 프로세서가 제1 경로와 제2 경로로부터 최적 경로를 결정할 때, 제1 프로세서는 상 기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하고, 상기 상태 정보에 따라, 제1 경로와 제2 경로로부터 최적 경로를 결정한다. 예시적으로, 제1 프로세서의 그래픽 메모리의 상태 정보는 제1 프로세서의 그래픽 메모리의 상태를 지시하기 위 한 것이다. 제1 프로세서는 그래픽 메모리의 상태 정보에 따라 제1 컴퓨팅 유닛의 계산 결과를 전송할 경로를 결정할 수 있다. 예를 들어, 상태 정보가 사용 가능한 그래픽 메모리가 크다는 것을 지시할 경우, 제1 경로를 통해 계산 결과를 전송하여 그래픽 메모리 스왑에서 지나치게 긴 스왑 동작으로 인해 딥 러닝 모델의 훈련 속도 가 느려지는 문제를 방지한다. 또 다른 예로, 제1 컴퓨팅 유닛의 계산 결과가 비교적 크고 제1 경로를 통해 전 송될 경우 그래픽 메모리가 항상 점유되는 문제가 발생하므로 제1 프로세서가 결정한 최적 경로는 제2 경로이다.이런 방안을 사용하여 제1 프로세서가 그래픽 메모리의 상태 정보에 따라 최적 경로를 결정하는 목적을 실현한 다. 상술한 실시예에서, 선택적으로, 상태 정보는 배치 크기(batch size), 훈련 샘플의 길이, 상기 계산 결과가 상 기 그래픽 메모리를 점유한 공간의 크기 및 상기 그래픽 메모리의 스왑 속도, 상기 그래픽 메모리의 남은 공간 크기 중 적어도 하나를 포함한다. 여기서 상기 배치 크기는 상기 그래픽 메모리에 로딩된 훈련 샘플의 수량을 지시하기 위한 것이고, 상기 그래픽 메모리의 스왑 속도는 단위 시간 내에 상기 그래픽 메모리에서 제2 프로세 서의 메모리에 도달하는 데이터 양을 지시하기 위한 것이다. 예시적으로, 제1 프로세서는 그래픽 메모리의 현재 상태 정보에 따라 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨 팅 유닛으로 전송할 경로를 결정할 수 있다. 다음은 일부 구현 사례이다. 예시적으로, 도 3을 참조하면, 도3은 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법의 예시적 도면이다. 도 3을 참조하면, 제1 프로세서에 포함된 컴퓨팅 유닛은 컴퓨팅 유닛 b, 컴퓨팅 유닛 c, 컴퓨팅 유닛 d 및 컴퓨 팅 유닛 e를 포함하고, 컴퓨팅 유닛 b의 계산 결과(텐서(tensor) b)는 컴퓨팅 유닛 c 및 컴퓨팅 유닛 e에서 사 용되며, 컴퓨팅 유닛 c와 컴퓨팅 유닛 d는 컴퓨팅 유닛 b와 컴퓨팅 유닛 e 사이의 중간 컴퓨팅 유닛이다. 이 중, 제1 컴퓨팅 유닛은 컴퓨팅 유닛 b이고, 제2 컴퓨팅 유닛은 컴퓨팅 유닛이며, 제 3 컴퓨팅 유닛은 컴퓨팅 유 닛 d이다. 도 3을 참조하면, 제1 프로세서가 컴퓨팅 유닛 b에 대응하는 연산을 수행한 후, 계산 결과, 즉 텐서 b가 생성된 다. 컴퓨팅 유닛 c와 컴퓨팅 유닛 b가 직접 연결되어 있기 때문에 계산 결과는 컴퓨팅 유닛 c로 직접 전송되고, 컴퓨팅 유닛 b와 컴퓨팅 유닛 e 사이에 중간 컴퓨팅 유닛이 있으며, 즉, 컴퓨팅 유닛 e는 컴퓨팅 유닛 d의 계산 결과인 텐서 d를 얻은 후에만 텐서 b와 텐서 d를 사용하는데, 이 과정에서 컴퓨팅 유닛 e는 제1 프로세서가 컴 퓨팅 유닛 c와 컴퓨팅 유닛 d의 대응 연산을 수행하기를 기다려야 한다. 이때, 제1 프로세서는 아래 몇가지 방 식을 통해, 제1 경로를 통해 텐서 b가 사용될 때까지 그래픽 메모리에 텐서 b를 저장할 것인지, 또는 제2 경로 를 통해 텐서 b를 제2 프로세서의 메모리로 스왑할 것인지 판단할 수 있다. 방식 1, 제1 프로세서는 텐서 b의 크기에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정한다. 예시적으로, 텐서 b의 크기는 텐서 b가 그래픽 메모리를 점유한 공간의 크기를 지시하고, 텐서 b가 100KB와 같 은 특정 임계값보다 작 으면 제1 프로세서는 최적 경로를 제1 경로로 결정하고, 그렇지 않으면 제1 프로세서는 최적 경로를 제2 경로로 결정한다. 텐서 b가 임계값보다 작을 때 제1 경로를 경유하는 이유는 텐서 b가 비교적 작을 때 절약할 수 있는 메모리 공간은 제한되어 있지만, 스왑 동작을 수행하면 시간이 낭비되기 때문이다. 이 과정에서 임계값의 결정은 사전에 크기가 다른 텐서 b가 스왑 동작을 호출하는 시간을 통계하여 얻을 수 있다. 방식 2, 제1 프로세서는 그래픽 메모리의 스왑 속도에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정한다. 예시적으로, 제2 경로를 채택한 경우, 제1 컴퓨팅 유닛의 계산 결과가 그래픽 메모리에서 제1 프로세서의 메모 리에 도달하는 과정을 스왑 아웃(swap_out) 동작이라고 하고, 그 다음 해당 계산 결과가 제1 프로세서의 메모리 로부터 제2 프로세서의 그래픽 메모리에 도달하는 과정을 스왑 인(swap_in) 동작이라고 한다. 딥 러닝 모델 훈 련 과정에 다른 스토리지 스왑 동작이 있을 것이다. 방식 2를 사용하여 최적 경로를 결정하는 경우, 디폴트로 제1 경로를 통해 텐서 b를 전달하고, 일부 훈련 샘플을 선택하여 실제 테스트를 수행하고, 실제 테스트 결과에 따라 스왑 인 동작의 시간 길이와 캐쉬 동작의 시간 길이를 얻고, 스왑 인 동작의 시간 길이와 스왑 아웃 동작 의 시간 길이에 따라 그래픽 메모리의 스왑 속도를 결정할 수 있으며, 그래픽 메모리 스왑 속도는 텐서와 스왑 시간의 비율이다. 그래픽 메모리 스왑 속도가 일정한 임계값보다 작으면 제1 경로를 최적 경로로 하고, 그래픽 메모리 스왑 속도가 일정한 임계값보다 크면 제2 경로를 최적 경로로 한다. 방식 3, 제1 프로세서는 훈련 샘플의 크기에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정한다. 예시적으로, 훈련 샘플의 크기는 훈련 샘플의 길이로도 지칭될 수 있다. 제1 프로세서에 대한 딥 러닝 모델의 훈련의 요구는 일반적으로 훈련 샘플의 크기와 관련된다. 현재 훈련 샘플의 크기가 특정 임계값보다 작으면 제1 경로를 최적 경로로 한다. 현재 훈련 샘플의 크기가 특징 임계값보다 큰 경우, 제2 경로를 최적 경로로 한다. 방식 4, 제1 프로세서는 서로 다른 텐서 b의 스왑 동작으로 절약할 수 있는 그래픽 메모리의 크기를 비교하여, 제1 경로와 제2 경로로부터 최적 경로를 결정한다. 예시적으로, 제1 프로세서는 길이가 다른 훈련 샘플을 선택하여 각각 제1 경로와 제2 경로를 통과시키고, 각 훈 련 샘플의 텐서 b의 스왑 동작으로 절약할 수 있는 그래픽 메모리의 크기를 통계하고, 절약할 수 있는 그래픽메모리의 크기에 따라 임계값을 설정한다. 절약된 그래픽 메모리의 크기가 설정된 임계값을 초과하면 제2 경로 를 최적 경로로 하고, 절약되는 그래픽 메모리의 크기가 설정된 임계값을 초과하지 않으면 제1 경로를 최적 경 로로 한다. 방식 5, 제1 프로세서는 서로 다른 텐서 b의 스왑 동작으로 절약할 수 있는 그래픽 메모리의 크기 및 증가하는 스왑 시간을 비교하고, 절약되는 그래픽 메모리의 크기와 증가되는 스왑 시간에 따라 단위 시간당 절약되는 그 래픽 메모리의 크기를 결정하고, 나아가 단위 시간당 절약되는 그래픽 메모리의 크기에 따라 제1 경로와 제2 경 로로부터 최적 경로를 결정한다. 이 중 단위 시간당 절약되는 그래픽 메모리의 크기는 텐서 b에 대해 스왑 동작 을 수행하여 절약되는 그래픽 메모리의 크기와 증가되는 스왑 시간의 비율과 같다. 방식 6, 제1 프로세서는 그래픽 메모리의 남은 공간의 크기에 따라 제1 경로와 제2 경로로부터 최적 경로를 결 정한다. 예시적으로, 제1 프로세서는 현재 입력 샘플의 길이 및 사전 통계된 결과에 따라 현재 그래픽 메모리의 점유 상 황을 예측하고, 현재 사용 가능한 그래픽 메모리의 크기를 결합하여 단위 시간에 절약되는 그래픽 메모리 수량 이 큰 텐서를 선택하여 스왑 동작을 수행하고, 절약 후의 그래픽 메모리의 점유가 현재 사용 가능한 그래픽 메 모리의 크기를 충족하면 나머지 텐서는 모두 제1 경로를 최적 경로로 한다. 본 실시예에 따른 방안을 사용하여 그래픽 메모리의 상태 정보에 따라 최적 경로를 유연하게 결정하는 목적을 구현한다. 다시 도 3을 참조하면, 최적 경로가 제1 경로인 경우 텐서 b는 굵은 검은색 실선으로 표시된 경로, 즉 제1 경로 를 통해 제2 컴퓨팅 유닛, 즉 컴퓨팅 유닛 e로 전달된다. 최적 경로가 제2 경로인 경우 테너 b는 점선으로 표시 된 경로, 즉 제2 경로를 통해 제2 컴퓨팅 유닛으로 전달된다. 도면에서 텐서 b'와 텐서 b의 차이점은 텐서 b는 제1 프로세서의 그래픽 메모리에 저장되고 텐서 b'는 제2 프로세서의 메모리에 저장된다는 것이다. 또한 도면에 서 텐서(tensor) c는 컴퓨팅 유닛 c의 계산 결과를 나타내고 텐서 d는 컴퓨팅 유닛 d의 계산 결과를 나타낸다. 상술한 실시예에서, 너무 일찍 스왑 인 동작이 실행되어 텐서 b'가 컴퓨팅 유닛 e에 도달하는 것을 방지하기 위 해, 본 출원의 실시예에서는, 최적 경로가 제2 경로인 경우, 제1 프로세서는 제1 경로와 제2 경로로부터 최적 경로를 결정한 후, 상기 적어도 하나의 중간 컴퓨팅 유닛으로부터 제 3 컴퓨팅 유닛을 더 결정하고, 상기 제 3 컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛에 인접하고, 그리고 상기 제2 컴 퓨팅 유닛 앞에 위치한 컴퓨팅 유닛이며, 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계 를 추가한다. 예시적으로, 다시 도 3을 참조하면, 제2 프로세서는 스왑 아웃 동작(swap_out) 및 스왑 인 동작(swap_in)을 포 함하는 스왑 동작을 수행하기 위한 것이다. 제2 프로세서는 컴퓨팅 유닛 d의 계산 결과를 획득한 후에야 컴퓨팅 유닛 e에 대응하는 연산을 수행할 수 있다. 제2 프로세서가 너무 일찍 스왑 동작 중의 스왑 인(swap_in) 동작을 실행하는 것을 방지하기 위해, 스왑 인 동작에 대한 컴퓨팅 유닛 d의 의존을 추가하여 컴퓨팅 유닛 d에 대응하 는 연산이 수행된 후에 스왑 인 동작이 시작되도록 한다. 본 실시예에서, 제 3 컴퓨팅 유닛과 스왑 동작 사이의 의존 관계를 증가함으로써, 스왑 동작이 너무 일찍 실행 됨에 따라 야기되는 그래픽 메모리의 점유를 방지한다. 이하에서는 상술한 실시예에서 의존 관계를 추가한 후, 제1 프로세서가 딥 러닝 모델의 훈련을 어떻게 수행하는 지에 대해 상세히 설명한다. 가능한 구현 방식에서, 제1 프로세서가 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가한 후, 상기 제1 컴퓨팅 유닛에 대응되는 연산을 더 수행하여 상기 계산 결과를 얻고, 상기 계산 결과를 상 기 제2 프로세서로 전송하여 상기 제2 프로세서가 상기 계산 결과에 대해 스왑 아웃 동작을 수행하도록 한다. 그 후, 제1 프로세서는 상기 제 3 컴퓨팅 유닛에 대응되는 연산이 완료되었는지 여부를 판단하고, 상기 제1 프 로세서가 상기 제 3 컴퓨팅 유닛에 대응되는 연산을 완료하면, 상기 제2 프로세서에 지시 정보를 전송하여 상기 제2 프로세서가 상기 제1 컴퓨팅 유닛의 계산 결과에 대해 스왑 인 동작을 수행하도록 하고, 제1 프로세서는 상 기 제 3 컴퓨팅 유닛의 계산 결과 및 상기 스왑 인 동작 수행 완료 후의 계산 결과에 따라 상기 제2 컴퓨팅 유 닛에 대응되는 연산을 수행한다. 예시적으로 다시 도 3을 참조하면, 컴퓨팅 유닛 d와 스왑 인 동작 간의 의존 관계를 추가한 후, 딥 러닝 모델 훈련 과정에 제1 프로세서는 컴퓨팅 유닛 b, 컴퓨팅 유닛 c, 컴퓨팅 유닛 d, 컴퓨팅 유닛 e에 대응되는 연산을순차적으로 수행한다. 제1 프로세서는 컴퓨팅 유닛 b에 대응되는 연산을 수행 완료하여 텐서 b를 얻은 후, 해당 텐서 b를 상기 제2 프로세서로 전송하여, 상기 제2 프로세서가 상기 계산 결과에 대해 스왑 아웃 동작을 수행하 도록 함으로써, 텐서 b를 제1 프로세서의 그래픽 메모리에서 제2 프로세서의 메모리로 이동시켜 텐서 b'를 획득 한다. 그 후, 제1 프로세서는 텐서 b에 따라 컴퓨팅 유닛 c에 대응되는 연산을 수행하여 텐서 c를 획득하고, 텐 서 c에 따라 컴퓨팅 유닛 d에 대응되는 연산을 수행하여 텐서 d를 획득한다. 제1 프로세서는 컴퓨팅 유닛 d에 대응되는 연산이 완료된 것으로 판단된 후, 지시 정보를 제2 프로세서로 전송하고, 여기서 해당 지시 정보는 텐 서 b'에 대해 스왑 인 동작을 수행하도록 제2 프로세서에 지시하하기 위한 것이다. 마지막으로 제1 프로세서는 텐서 d와 텐서 b'를 입력으로 하여 컴퓨팅 유닛 e에 대응되는 연산을 수행한다. 본 실시예에서, 제 3 컴퓨팅 유닛과 스왑 동작의 의존 관계를 증가시킴으로써, 스왑 동작이 너무 일찍 수행됨에 따라 야기되는 그래픽 메모리의 점유를 방지한다. 상술한 실시예에서, 상기 제1 프로세서는 제1 경로와 제2 경로로부터 최적 경로를 결정한 후, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전송었되는지 여부도 판단한다. 상기 제1 컴퓨팅 유닛의 계 산 결과가 상기 제2 프로세서의 메모리로 전송되면, 상기 그래픽 메모리에서 상기 제1 컴퓨팅 유닛의 계산 결과 가 점유하는 공간을 해제한다. 예시적으로 다시 도 3을 참조하면, 최적 경로가 제2 경로인 경우, 제1 프로세서가 텐서 b를 획득한 후 해당 텐 서 b를 컴퓨팅 유닛 c로 전달하고 스왑 아웃 동작을 통해 제2 프로세서의 메모리로 전달하는데 성공하면, 그래 픽 메모리에서 텐서 b가 점유하는 공간을 해제한다. 본 실시예에서, 계산 결과에 대한 스왑 아웃 동작이 수행 완료된 후, 계산 결과가 점유하는 그래픽 메모리를 즉 시 해제함으로써, 그래픽 메모리가 점유됨에 따라 야기되는 훈련 속도가 느리거나 훈련이 불가능한 것을 방지하 는 목적을 달성한다. 상기에서는 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법의 구체적 인 구현을 설명하였다. 다음은 본 출원의 방법 실시예를 실행하는데 사용될 수 있는 본 출원의 장치 실시예이다. 본 출원의 장치 실시예에서 공개되지 않은 세부 사항은 본 출원의 방법 실시예를 참조한다. 도 4는 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 장치의 구조도이다. 해당 장치는 전자 기기에 집적되거나 전자 기기로 구현될 수 있으며, 전자 기기는 단말기 또는 서버 등일 수. 도 4에 도시된 바와 같이, 본 실시예에서, 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 장치(10 0)는, 사용자에 의해 입력된 요청 명령을 수신하되, 상기 요청 명령은 딥 러닝 모델의 훈련을 요청하기 위한 것인 수 신 모듈; 제1 경로와 제2 경로로부터 최적 경로를 결정하되, 상기 제1 경로에서, 제1 컴퓨팅 유닛의 계산 결과는 상기 제 1 컴퓨팅 유닛으로부터 제2 컴퓨팅 유닛에 직접 도달하고, 상기 제2 경로에서, 상기 제1 컴퓨팅 유닛의 계산 결 과는 제2 프로세서의 메모리에서 스왑 동작이 수행 완료된 후 상기 제2 컴퓨팅 유닛에 도달하고, 상기 제1 컴퓨 팅 유닛과 상기 제2 컴퓨팅 유닛은 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛 사 이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 처리 모듈; 상기 최적 경로를 통해 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하기 위한 전송 모듈을 포 함할 수 있다. 일 가능한 설계에 있어서, 상기 처리 모듈은 상기 제1 프로세서의 그래픽 메모리의 상태 정보를 결정하고, 상기 상태 정보에 따라 제1 경로와 제2 경로로부터 최적 경로를 결정한다. 일 가능한 설계에 있어서, 상기 상태 정보는, 배치 크기, 훈련 샘플의 길이, 상기 계산 결과가 상기 그래픽 메모리를 점유한 공간의 크기, 상기 그래픽 메모 리의 스왑 속도, 상기 그래픽 메모리의 나머지 공간의 크기 중 적어도 하나를 포함하고, 여기서 상기 배치 크기 는 상기 그래픽 메모리에 로딩되는 훈련 샘플 수량을 지시하기 위한 것이고, 상기 그래픽 메모리의 스왑 속도는 단위 시간당 상기 그래픽 메모리에서 제2 프로세서의 메모리에 도달하는 데이터의 양을 지시하기 위한 것이다. 일 가능한 설계에 있어서, 상기 최적 경로는 상기 제2 경로이고, 상기 처리 모듈은 또한 제1 경로와 제2 경 로로부터 최적 경로를 결정한 후, 또한 상기 적어도 하나의 중간 컴퓨팅 유닛으로부터 제 3 컴퓨팅 유닛을 결정하고, 상기 제 3 컴퓨팅 유닛은 상기 적어도 하나의 중간 컴퓨팅 유닛 중 상기 제2 컴퓨팅 유닛에 인접하고, 상 기 제2 컴퓨팅 유닛 앞에 위치한 컴퓨팅 유닛이고, 상기 제3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가한다. 일 가능한 설계에 있어서, 상기 스왑 동작은 스왑 아웃 동작과 스왑 인 동작을 포함하고, 상기 처리 모듈은 상기 제 3 컴퓨팅 유닛과 상기 제2 프로세서의 스왑 동작의 의존 관계를 추가한 후, 또한 상기 제1 컴퓨팅 유닛 에 대응되는 연산을 수행하여 상기 계산 결과를 얻고, 상기 계산 결과를 상기 제2 프로세서로 전송하여 상기 제 2 프로세서가 상기 계산 결과에 대해 상기 스왑 아웃 동작을 수행하도록 하고, 상기 제 3 컴퓨팅 유닛에 대응되 는 연산이 완료되었는지 여부를 판단하고, 상기 제1 프로세서가 상기 제 3 컴퓨팅 유닛에 대응되는 연산을 완료 하면 상기 제2 프로세서에 지시 정보를 전송하여 상기 제2 프로세서가 상기 제1컴퓨팅 유닛의 계산 결과에 대해 상기 스왑 인 동작을 수행하도록 하고, 상기 제3 컴퓨팅 유닛의 계산 결과와 상기 스왑 인 동작 수행 완료 후의 계산 결과에 따라 상기 제2 컴퓨팅 유닛에 대응되는 연산을 수행한다. 일 가능한 설계에 있어서, 상기 처리 모듈은 제1 경로와 제2 경로로부터 최적 경로를 결정한 후, 또한 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리에 전송었되는지 여부를 판단하고, 상기 제1 컴퓨팅 유닛의 계산 결과가 상기 제2 프로세서의 메모리로 전달되면 상기 그래픽 메모리로부터 상기 제1 컴퓨팅 유닛의 계산 결과가 점유하는 공간을 해제한다. 일 가능한 설계에 있어서, 상기 제1 프로세서는 텐서 프로세서(TPU) 또는 그래픽 프로세서(GPU)이다. 본 출원의 실시예에 따른 장치는 상기와 같은 실시예 중 제1 프로세서에 의해 실행되는 방법에 사용될 수 있으 며, 그 구현 원리와 기술적 효과는 유사하므로 여기서 중복하지 않을 것이다. 본 출원의 실시예들에 따르면, 본 출원은 전자 기기 및 판독 가능한 저장 매체를 더 제공한다. 도 5는 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 구현하기 위 한 전자 기기의 블록도이다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크 스테이션, 개인용 디지털 단말기, 서버, 블레이드 서버, 메인 프레임 컴퓨터 및 기타 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터 를 나타내기 위한 것이다. 전자 기기는 개인용 디지털 처리, 셀 폰, 스마트 폰, 웨어러블 기기 및 기타 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 나타낼 수도 있다. 본 문에 따른 부재, 이들의 연결과 관계, 및 이들의 기능은 단지 예시일 뿐이며, 본 문에 기재된 및/또는 요구되는 본 출원의 구현을 한정하려는 것은 아 니다. 도 5에 도시된 바와 같이, 해당 전자 기기는 하나 또는 복수의 프로세서, 메모리 및 고속 인터페이스 및 저속 인터페이스를 포함하는 각 부재를 연결시키기 위한 인터페이스를 포함한다. 각 부재는 서로 다른 버스 를 사용하여 서로 연결되며 공통 메인 보드에 장착되거나 필요에 따라 다른 방식으로 장착될 수 있다. 프로세서 는 전자 기기에서 실행되는 명령을 처리할 수 있으며, 외부 입/출력 장치(예를 들면 인터페이스에 연결된 디스 플레이 기기)에 GUI의 그래픽 정보를 표시하기 위해 메모리 중 또는 메모리 상에 저장된 명령을 포함한다. 다른 실시 방식에서, 필요한 경우 다수의 프로세서 및/또는 다수의 버스와 다수의 메모리가 함께 사용될 수 있다. 마 찬가지로 여러 전자 기기를 연결할 수 있으며, 각 기기는 부분 필요한 동작을 제공한다(예를 들면, 서버 어레이, 블레이드 서버 그룹 또는 다중 프로세서 시스템으로서). 도 5에서는 하나의 프로세서를 예로 든다. 메모리는 바로 본 출원에 따른 비일시적 컴퓨터 판독 가능 저장매체이다. 여기서, 상기 메모리는 적어도 하나의 프로세서에 의해 실행될 수 있는 명령이 저장되어, 상기 적어도 하나의 프로세서가 본 출원에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 수행하도록 한다. 본 출원의 비일시적 컴퓨터 판 독 가능 저장매체는 컴퓨터 명령을 저장하고, 해당 컴퓨터 명령은 컴퓨터가 본 출원에 따른 딥 러닝 훈련 임무 를 위한 프로세서 그래픽 메모리 최적화 방법을 수행하도록 한다. 메모리는 비일시적 컴퓨터 판독 가능 저장매체로서, 비일시적 소프트웨어 프로그램, 비일시적 컴퓨터 실행 가능 프로그램 및 모듈, 예컨대 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최 적화 방법에 대응되는 프로그램 명령/모듈(예를 들어, 도 4에 도시된 수신 모듈, 처리 모듈과 전송 모 듈)을 저장할 수 있다. 프로세서는 메모리에 저장된 비일시적 소프트웨어 프로그램, 명령 및 모 듈을 실행하여, 서버의 다양한 기능 응용 및 데이터 처리를 수행한다. 즉, 상술한 방법 실시예 중 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 구현한다. 메모리는 프로그램 저장 영역과 데이터 저장 영역을 포함할 수 있다. 여기서, 프로그램 저장 영역은 운영 체제, 적어도 하나의 기능에 필요한 응용 프로그램을 저장할 수 있다. 데이터 저장 영역은 전자 기기가 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 실행하기 위해 구축하는 데이터 등을 저장할 수 있다. 한편, 메모리는 고속 랜덤 액세스 메모리를 포함할 수 있고, 예를 들어 적어도 하나의 자기 저장장치, 플 래시 메모리, 또는 기타 비일시적 솔리드 스테이트 저장장치와 같은 비일시적 메모리를 포함할 수도 있다. 일부 실시예에서, 메모리는 선택적으로 프로세서에 대해 원격으로 설치된 메모리를 포함할 수 있고, 이러 한 원격 메모리는 네트워크를 통해 전자기기에 연결될 수 있다. 상술한 네트워크의 실예로서 인터넷, 인트라넷, 근거리 통신망, 이동 통신망 및 그 조합을 포함하지만 이에 한정되지 않는다. 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 위한 전자기기는 입력 장치와 출력 장치 를 더 포함할 수 있다. 프로세서, 메모리, 입력 장치 및 출력 장치는 버스 또는 기타 방식으로 연결될 수 있으며, 도 5에서는 버스를 통해 연결되는 것을 예로 들고 있다. 입력 장치는 입력되는 숫자 또는 문자 부호 정보를 수신할 수 있고, 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화에 관련된 키 신호 입력을 생성할 수 있다. 예를 들어 터치 스크린, 키패드, 마우스, 트랙 패드, 터치패널, 지시레버, 하나 또는 복수의 마우스 버튼, 트랙볼, 조종레버 등 입력장치일 수 있다. 출력 장 치는 디스플레이 기기, 보조 조명 장치(예를 들어, LED) 및 촉각 피드백 장치(예를 들어, 진동모터) 등을 포함할 수 있다. 해당 디스플레이 기기는, 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이와 플라즈마 디스플레이 등을 포함할 수 있지만 이에 한정되지 않는다. 일부 실시 방식에서, 디스플레이 기기는 터치 스크린 일 수 있다. 여기에 기재되는 시스템 및 기술의 다양한 실시 방식은 디지털 전자 회로 시스템, 집적 회로 시스템, 전용 ASIC(전용 집적 회로), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있다. 이러 한 다양한 실시 방식은 하나 또는 복수의 컴퓨터 프로그램에서 구현되는 것을 포함할 수 있고, 해당 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그래머블 프로세서를 포함하는 프로그래머블 시스템 상에서 실행 및/또는 해석될 수 있으며, 해당 프로그래머블 프로세서는 전용 또는 범용 프로그래머블 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력장치, 및 적어도 하나의 출력장치로부터 데이터와 명령을 수신할 수 있으며, 데이터와 명령을 해당 저장 시스템, 해당 적어도 하나의 입력장치, 및 해당 적어도 하나의 출력장치로 전송한다. 이러한 컴퓨팅 프로그램(프로그램, 소프트웨어, 소프트웨어 응용, 또는 코드라고도 불리운다)은 프로그래머블 프로세서의 기계적 명령을 포함하고, 고급 프로세스 및/또는 객체 지향 프로그래밍 언어, 및/또는 어셈블리/기 계적 언어를 이용하여 이러한 컴퓨팅 프로그램을 구현할 수 있다. 예컨대 본문에서 사용되는 용어 \"기계 판독 가능 매체\"와 “컴퓨터 판독 가능 매체”는 기계적 명령 및/또는 데이터를 프로그래머블 프로세서로 제공하기 위한 임의의 컴퓨터 프로그램 제품, 기기, 및/또는 장치(예를 들어, 자기 디스크, 광 디스크, 메모리, 프로그래 머블 논리 디바이스(PLD))를 가리키고, 기계 판독 가능 신호인 기계적 명령을 수신하는 기계 판독 가능 매체를 포함한다. 용어 “기계 판독 가능 신호”는 기계적 명령 및/또는 데이터를 프로그래머블 프로세서로 제공하기 위한 임의의 신호를 가리킨다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터 상에서 여기에 기재되는 시스템 및 기술을 실시할 수 있으며, 해당 컴퓨터는 사용자에게 정보를 표시하기 위한 표시장치(예를 들어, CRT(캐소드레이 튜브) 또는 LCD(액정 디 스플레이) 모니터); 및 키보드와 지향 장치(예를 들어, 마우스 또는 트랙볼)를 구비하고, 사용자는 해당 키보드 와 해당 지향장치를 통해 입력을 컴퓨터로 제공할 수 있다. 기타 종류의 장치는 또한 사용자와의 인터랙션을 제 공할 수 있다. 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각적 피드백, 청각적 피드백, 또는 촉각적 피드백)일 수 있고; 임의의 형태(사운드 입력, 음성 입력 또는 촉각 입 력)을 통해 사용자로부터의 입력을 수신할 수 있다. 여기에 기재되는 시스템과 기술은 백그라운드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버로서), 또 는 중간부재를 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프론트 엔드 부재를 포함하는 컴퓨팅 시스 템(예를 들어, 그래픽 유저 인터페이스 또는 인터넷 브라우저를 구비하는 사용자 컴퓨터, 사용자는 해당 그래픽 유저 인터페이스 또는 해당 인터넷 브라우저를 통해 여기에 기재되는 시스템 및 기술의 실시방식과 인터랙션할 수 있다), 또는 이러한 백그라운드 부재, 중간 부재, 또는 프론트 엔드 부재를 포함하는 임의의 조합의 컴퓨팅 시스템에서 실시될 수 있다. 임의의 형태 또는 매채의 디지털 데이터 통신(예를 들어, 통신망)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신망의 예시로서, 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷을 포함한 다.컴퓨터 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 멀리 떨어져 있으 며 통상적으로 통신망을 통해 인터랙션한다. 상응한 컴퓨터 상에서 실행되며 서로 클라이언트-서버 관계를 가지 는 컴퓨터 프로그램을 통해 클라이언트와 서버의 관계를 생성한다. 본 출원의 실시예는 또한, 제1 프로세서는 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송하기 위한 경로를 결정하되, 상기 제 1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛은 상기 제1 프로세서에 포함되고, 상기 제1 컴퓨팅 유닛과 상기 제2 컴퓨팅 유닛 사이에 적어도 하나의 중간 컴퓨팅 유닛이 존재하는 단계; 제1 프로세서는 상기 경로를 통해 상기 제 1컴퓨팅 유닛의 계산 결과를 상기 제2 컴퓨팅 유닛으로 전송하는 단계를 포함하는 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 제공한다. 본 출원의 실시예의 기술 방안에 따르면, 제1 프로세서가 딥 러닝 모델의 훈련을 요청하는 요청 명령을 수신한 후, 제1 경로와 제2 경로로부터 최적 경로를 결정하고, 해당 제1 경로는 제1 컴퓨팅 유닛으로부터 제2 컴퓨팅 유닛에 직접 도달하기 위한 것이고, 제2 경로는 그래픽 메모리 스왑을 통해 제2 컴퓨팅 유닛에 도달하는 것이며, 그 다음 제1 프로세서는 최적 경로를 통해 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송한 다. 이런 방안을 사용하여 계산 결과를 전송하기 위한 최적 경로를 결정하고, 최적 경로를 사용하여 제1 컴퓨팅 유닛의 계산 결과를 제2 컴퓨팅 유닛으로 전송함으로써, 그래픽 메모리의 점유를 방지하고, 동시에 그래픽 메모 리 스왑으로 인한 GPU의 컴퓨팅 유닛의 낮은 사용률 문제를 방지하여, 대부분의 임무의 훈련 속도가 거의 감소 되지 않는다. 또한 실제 훈련 환경에서 그래픽 메모리 점유는 일반적으로 훈련 샘플 번호에 따라 피크치를 가지 며 일반적으로 소수의 샘플만 피크치에 도달할 수 있다. 본 출원의 실시예에 따른 방안을 사용하면 극소수의 경 우에 대해서만 스왑 조작을 동적으로 늘려 피크치 그래픽 메모리 사용 수요를 충족할 수 있기에 스토리지 오버 플로로 인한 훈련 실패를 방지하고, 대부분의 비피크치의 경우에 대하여 스왑 동작을 늘릴 필요가 없기에 그래 픽 메모리 스왑으로 인한 오버 헤드를 방지하고 훈련 속도를 보장한다. 상술한 다양한 형태의 프로세스를 사용하여 단계를 재정렬, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본발 출원에 개재된 각 단계들은 본 출원에서 개시된 기술 방안의 원하는 결과를 구현할 수 있는 한 병렬 로 실행하거나, 순차적으로 또는 다른 순서로 실행될 수 있으며, 본문에서는 여기서 한정하지 않는다. 상술한 구체적인 실시 방식은, 본 출원의 보호범위에 대한 한정이 아니다. 본 분야의 통상의 지식을 가진 자라 면, 설계 수요와 기타 요소를 기초로, 다양한 수정, 조합, 서브 조합 및 대체를 가할 수 있음을 이해할 수 있을 것이다. 본 출원의 정신과 원칙 내에서 이루어진 모든 수정, 동등한 치환 등은 모두 본 출원의 보호 범위 내에 속한다."}
{"patent_id": "10-2021-7008257", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 방안에 대한 더 충분한 이해를 돕기 위한 것으로서, 본 출원에 대해 한정하지 않는다. 여기서, 도 1은 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법의 운영 환경의 도면이다. 도 2는 본 출원의 일 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법의 흐름도이 다. 도 3은 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법의 예시적 도면 이다. 도 4는 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 장치의 구조도이다. 도 5는 본 출원의 실시예에 따른 딥 러닝 훈련 임무를 위한 프로세서 그래픽 메모리 최적화 방법을 구현하기 위 한 전자 기기의 블록도이다."}
