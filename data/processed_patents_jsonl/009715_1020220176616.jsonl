{"patent_id": "10-2022-0176616", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0094380", "출원번호": "10-2022-0176616", "발명의 명칭": "CPU, GPU 및 FPGA를 통합한 AI로봇 임베디드 시스템", "출원인": "레드원테크놀러지 주식회사", "발명자": "문용선"}}
{"patent_id": "10-2022-0176616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모듈 타입의 다른 보드들이 장착되며, 장착된 보드들에서 제공하는 연동 신호들이 상호 연결되도록 중계하는 백-플레인 보드;적어도 하나 이상의 채널의 GSML 카메라 인터페이스들과, 적어도 하나 이상의 채널의 3D LiDAR 인터페이스가 장착되며, 모듈 타입으로 제작되어, 상기 백-플레인 보드에 연동되는 추가보드;모듈 타입으로 제작되어 상기 백-플레인 보드에 장착되며, 상기 GSML 카메라의 메인 연산 및 응용 어플리케이션처리를 수행하는 CPU/GPU 보드;모듈 타입으로 제작되어 상기 백-플레인 보드에 장착되며, 상기 GSML 카메라의 정보 전처리를 수행하는 FPGA 보드;모듈 타입으로 제작되어 상기 백-플레인 보드에 장착되며, 상기 GMSL 카메라 및 상기 3D LiDAR 카메라의 신호인터페이스를 제공하며, 해당 신호를 상기 FPGA 보드 상에서 처리가능한 신호로 변환하는 LiDAR-Vision 보드를포함하는 것을 특징으로 하는 AI로봇 임베디드 시스템."}
{"patent_id": "10-2022-0176616", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 CPU, GPU 및 FPGA가 융합한 통합 프로세서를 이용하여 데이터 연산처리를 수행함과 동시에 최대 3~4채 널의 GMSL 카메라 인터페이스 및 처리 알고리즘과 1채널 3D LiDAR 인터페이스 및 처리 알고리즘을 지원하며, 백 플레인 기반의 신호 인터페이스 구조를 갖는 모듈 타입으로 제작되며, PCle (PCI Express) 기반 인터커넥트 기술 을 적용함으로써 인공지능(AI) 기반 다채널 카메라 영상처리 및 실시간 병렬처리 시 2Gbps의 전송속도를 발휘할 수 있을 뿐만 아니라 기능 확장 및 유지보수를 간소화시켜, 운영의 편의성 및 효율성을 극대화시킬 수 있으며, 이기종 프로세서 간의 고속 데이터 교환이 가능한 AI로봇 임베디드 시스템에 관한 것이다."}
{"patent_id": "10-2022-0176616", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 CPU, GPU 및 FPGA를 통합한 AI로봇 임베디드 시스템에 관한 것으로서, 상세하게로는 CPU, GPU 및 FPGA가 융합한 통합 프로세서를 이용하여 데이터 연산처리를 수행함과 동시에 최대 3~4채널의 GMSL 카메라 인터 페이스 및 처리 알고리즘과 1채널 3D LiDAR 인터페이스 및 처리 알고리즘을 지원하며, 백플레인 기반의 신호 인 터페이스 구조를 갖는 모듈 타입으로 제작되며, PCle (PCI Express) 기반 인터커넥트 기술을 적용함으로써 인공 지능(AI) 기반 다채널 카메라 영상처리 및 실시간 병렬처리 시 2Gbps의 전송속도를 발휘할 수 있을 뿐만 아니라 기능 확장 및 유지보수를 간소화시켜, 운영의 편의성 및 효율성을 극대화시킬 수 있으며, 이기종 프로세서 간의 고속 데이터 교환이 가능한 AI로봇 임베디드 시스템에 관한 것이다."}
{"patent_id": "10-2022-0176616", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, 머신러닝 또는 딥러닝 알고리즘들이 컴퓨터 비전, 자연어 처리 등과 같은 다양한 분야에서 뛰어난 성능을 보임에 따라 대규모 병렬 컴퓨팅 환경의 필요성이 요구되고 있고 이와 더불어 병렬 연산 등 새로운 설계 가 가능한 임베디드 시스템에 관한 관심이 높아지고 있다. 특히, 임베디드 시스템 기술개발은 자율주행차, 로봇, IoT 기기 등의 엣지 디바이스에 적용 가능하다는 점에서 필수적이다. 또한 인공지능 분야로의 적용을 위해선 카메라와 LiDAR의 실시간 병렬처리가 필요하며 이를 위해선 2Gbps의 전 송속도가 요구되고 있다. 그러나 인공지능(AI) 분야에서는, 기술 적용에 요구되는 많은 계산량으로 인해 실제 2Gbps 전송속도를 가지는 임베디드 시스템이 없을 뿐만 아니라 임베디드 또는 엣지 디바이스의 적용이 어려운 상황이다. 즉 방대한 연산처리를 실시간 처리할 수 있는 임베디드 시스템에 대한 연구가 시급한 실정이다."}
{"patent_id": "10-2022-0176616", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 이러한 문제를 해결하기 위한 것으로, 본 발명의 해결과제는 CPU, GPU 및 FPGA가 융합한 통합 프로세 서를 이용하여 데이터 연산처리를 수행함으로써 인공지능(AI) 기반 다채널 카메라 영상처리 및 실시간 병렬처리가 가능하여, 연산처리로 인한 로딩, 부하 및 지체 현상을 방지할 수 있는 CPU, GPU 및 FPGA를 통합한 AI로봇 임베디드 시스템을 제공하기 위한 것이다. 또한 본 발명의 다른 해결과제는 로봇의 자율주행 어플리케이션 위한 최대 3~4채널의 GMSL 카메라 인터페이스 및 처리 알고리즘과 1채널 3D LiDAR 인터페이스 및 처리 알고리즘을 적용함으로써 인공지능(AI) 기반 다채널 카 메라 영상처리 및 실시간 병렬처리 속도를 더욱 개선시킬 수 있으며, 상세하게로는 병렬처리 시, 2Gbps의 전송 속도를 기대할 수 있는 CPU, GPU 및 FPGA를 통합한 AI로봇 임베디드 시스템을 제공하기 위한 것이다. 또한 본 발명의 또 다른 해결과제는 백플레인 기반의 신호 인터페이스 구조를 갖는 모듈 타입으로 제작됨으로써 기능 확장 및 유지보수를 간소화시켜, 운영의 편의성 및 효율성을 극대화시킬 수 있는 CPU, GPU 및 FPGA를 통합 한 AI로봇 임베디드 시스템을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0176616", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 본 발명의 해결수단은 모듈 타입의 다른 보드들이 장착되며, 장착된 보드들에서 제 공하는 연동 신호들이 상호 연결되도록 중계하는 백-플레인 보드; 적어도 하나 이상의 채널의 GSML 카메라 인터 페이스들과, 적어도 하나 이상의 채널의 3D LiDAR 인터페이스가 장착되며, 모듈 타입으로 제작되어, 상기 백-플 레인 보드에 연동되는 추가보드; 모듈 타입으로 제작되어 상기 백-플레인 보드에 장착되며, 상기 GSML 카메라의 메인 연산 및 응용 어플리케이션 처리를 수행하는 CPU/GPU 보드; 모듈 타입으로 제작되어 상기 백-플레인 보드 에 장착되며, 상기 GSML 카메라의 정보 전처리를 수행하는 FPGA 보드; 모듈 타입으로 제작되어 상기 백-플레인 보드에 장착되며, 상기 GMSL 카메라 및 상기 3D LiDAR 카메라의 신호 인터페이스를 제공하며, 해당 신호를 상기 FPGA 보드 상에서 처리가능한 신호로 변환하는 LiDAR-Vision 보드를 포함하는 것이다."}
{"patent_id": "10-2022-0176616", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 과제와 해결수단을 갖는 본 발명에 따르면 해결과제는 CPU, GPU 및 FPGA가 융합한 통합 프로세서를 이용하 여 데이터 연산처리를 수행함으로써 인공지능(AI) 기반 다채널 카메라 영상처리 및 실시간 병렬처리가 가능하여, 연산처리로 인한 로딩, 부하 및 지체 현상을 효과적으로 방지할 수 있게 된다. 또한 본 발명에 의하면 로봇의 자율주행 어플리케이션 위한 최대 3~4채널의 GMSL 카메라 인터페이스 및 처리 알 고리즘과 1채널 3D LiDAR 인터페이스 및 처리 알고리즘을 적용함으로써 인공지능(AI) 기반 다채널 카메라 영상 처리 및 실시간 병렬처리 속도를 더욱 개선시킬 수 있으며, 상세하게로는 병렬처리 시, 2Gbps의 전송속도를 기 대할 수 있다. 또한 본 발명에 의하면 백플레인 기반의 신호 인터페이스 구조를 갖는 모듈 타입으로 제작됨으로써 기능 확장 및 유지보수를 간소화시켜, 운영의 편의성 및 효율성을 극대화시킬 수 있게 된다."}
{"patent_id": "10-2022-0176616", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 일실시예를 설명한다. 도 1은 본 발명의 일실시예인 AI로봇 임베디드 시스템을 나타내는 구성도이고, 도 2는 도 1의 각 모듈을 설명하 기 위한 예시도이다.본 발명의 일실시예인 AI로봇 임베디드 시스템은 CPU, GPU 및 FPGA가 융합한 통합 프로세서를 이용하여 데이 터 연산처리를 수행함과 동시에 최대 3~4채널의 GMSL 카메라 인터페이스 및 처리 알고리즘과 1채널 3D LiDAR 인 터페이스 및 처리 알고리즘을 지원하며, 백플레인 기반의 신호 인터페이스 구조를 갖는 모듈 타입으로 제작되며, PCle (PCI Express) 기반 인터커넥트 기술을 적용함으로써 인공지능(AI) 기반 다채널 카메라 영상처 리 및 실시간 병렬처리 시 2Gbps의 전송속도를 발휘할 수 있을 뿐만 아니라 기능 확장 및 유지보수를 간소화시 켜, 운영의 편의성 및 효율성을 극대화시킬 수 있으며, 이기종 프로세서 간의 고속 데이터 교환이 가능하도록 하기 위한 것이다. 또한 본 발명의 AI로봇 임베디드 시스템은 도 1과 2에 도시된 바와 같이, CPU/GPU 보드와, FPGA 보드, LiDAR-Vision 보드, 백-플레인(BACKPLANE) 보드를 포함하고, 인공지능 기반 서비스 로봇의 메인 프로세서 및 영상처리 프로세서와 LiDAR-Vision 기반의 로봇 자율 항법 프로세서, 무인 경비로봇의 다채널 처리용 프로세 서 등과 같은 다양한 분야에 적용될 수 있다. 또한 본 발명의 AI로봇 임베디드 시스템은 백플레인 장착형 구조로 설계됨으로써 최대 3~4채널의 GMSL 카메 라 인터페이스와, 1채널의 3D LiDAR 인터페이스를 하나의 보드로 장착되게 된다. 이때 GMSL 카메라에 사용되는 커넥터는, ‘FAKRA RF 커넥터’와 ‘HSD 커넥터’로 구분되나, 본 발명에서는 ‘FAKRA RF 커넥터’를 적용하였다. 또한 본 발명의 AI로봇 임베디드 시스템은 백플레인 장착형 구조로 설계됨으로써 기존에 공지된 다양한 모듈 들이나 향후 개발될 모듈들의 탈부착이 정확하고 신속하게 이루어질 수 있다. 이때 백-플레인 보드의 신호들 은 이미 각 칩에서 검증을 완료한 부분이므로 추후 신호 처리 및 구현 과정에서의 리스크를 줄일 수 있다. CPU/GPU 보드는 GMSL 카메라의 메인 연산 및 응용 어플리케이션 처리가 수행되는 보드이다. FPGA 보드는 GMSL 카메라의 정보 전처리 기능 등을 수행하는 보드이다. LiDAR-Vision 보드는 최대 3~4채널의 GMSL 카메라 및 3D LiDAR 카메라 신호 인터페이스를 제공하며, 해당신호를 FPGA 보드 상에서 처리가능한 신호로 변환하는 보드이다. 백-플레인 보드는 CPU/GPU 보드, FPGA 보드 및 LiDAR-Vision 보드에서 제공하는 연동 신호들이 상 호 연결될 수 있도록 중계하는 보드이다. 도 3은 본 발명의 GMSL 카메라의 신호 변환 과정을 나타내는 개념도이다. 일반적으로, 카메라 신호를 프로세서에서 사용하기 위해서는 신호 변환 과정이 필요하다. 이에 따라 본 발명에 서는 도 3에 도시된 바와 같이, FPGA 보드가 GMSL 카메라의 신호를 전처리하므로 FPGA에서 처리가능한 신 호 형태로 변환되어야 한다. 이때 GMSL 카메라 신호는 일반적으로 다음과 같이 Parallel 및 MIPI 등으로 변환되 어 사용이 가능하지만, 본 발명에서는 FPGA 내에서의 구현성 및 가격적인 요소를 고려하여 PIO 방식을 적용하였 다. 또한 본 발명의 GSML 카메라의 보드는 최대 3~4채널의 GMSL 카메라의 신호를 Parallel 신호로 변환할 수 있 도록 설계되었고, 보드 구조는 공지된 GMSL 개발 킷에 기반한 구조를 적용하였고, 4개의 앵글형 타입의 FAKRA RF 커넥터를 적용하였다. 이때 보드 내 I2C 기반의 가변 저항기를 부착하여 카메라의 요구 전원에 맞게 GMSL 채널로 전송 하는 전원을 5~12V 범위 내에서 가변 적용할 수 있도록 설계하였다. 또한 GMSL Deserializer 칩에서 제공하는 병렬 I/O 신호의 구성을 변경하여 또한 영상 신호의 비트 수를 설정하 도록 구성하였다. 도 4는 도 1의 LiDAR-Vision 보드를 나타내는 개념도이다. LiDAR-Vision 보드는 도 4에 도시된 바와 같이, 고성능 3D LiDAR 센서를 연동이 가능한 GbE (Gigabit Ethernet) 인터페이스 방식이 적용되며, 상세하게로는 보드 상에는 GbE의 물리-층(RJ 커넥터, 마스네틱, PHY 등)으로만 구성되되, 데이터링크-층(GbE MAC)은 FPGA 보드 내의 IP 코어 형태로 적용할 수 있도록 하였다. 도 5는 도 1의 FPGA 보드의 구조를 설명하기 위한 개념도이고, 도 6은 도 5의 FPGA 보드의 신호 처리 인터페이 스를 설명하기 위한 개념도이다.도 5와 6의 FPGA 보드는 LiDAR-Vision 보드에서 측정되는 거리 및 영상 정보를 디코딩/전처리 하고 각 센 서들의 동작 및 설정을 제어하는 기능을 수행하는 보드로서, FPGA 보드와 센서 간의 기능 연계는 LiDAR-Vision 보드를 통하여 중계된다. 이러한 FPGA 보드는 1)LiDAR-Video 데이터 전송 기능과, 2)LiDAR-Video 설정 기능을 갖는다. FPGA 보드는 LiDAR-Video 데이터 전송 기능을 구현하기 위하여, AXI DMA 기반의 PCI Express 통신 구조에서 Write DMA (WDMA) 부분에 전처리된 LiDAR 및 Vision 데이터를 쓰기(Writing) 하여 PCI Express 통신을 상위 Host로 전송하는 구조를 적용할 수 있다. 또한 FPGA 보드는 LiDAR-Video 설정 기능을 구현하기 위하여, 기존에 설계된 AXI Lite 기반의 레지스터 인터 페이스를 이용하여 LiDAR 및 카메라의 동작 및 설정할 수 있다. 이러한 FPGA 보드는 도 6에 도시된 바와 같이, 응용 어플리케이션에 따라 간단한 시스템의 경우 FPGA 내부에 내장된 블록 메모리(36Kb x 325개)가 설치될 수 있으나, 복잡한 어플리케이션에 대응하기 위하여 외부에 별도의 512MB의 DDR3 SDRAM 메모리가 추가로 설계된다. 또한 FPGA 보드는 하드 카피된 MGT 고속 신호처리 단자를 이용한 PCI Express 통신을 지원하며, 최대 PCI Express Gen2 x4Lane을 지원할 수 있도록 설계된다. 또한 FPGA 보드는 백플레인 기반 PIO (parellel I/O) 단자를 통하여 최대 4채널의 GMSL 카메라의 신호를 수 신할 수 있으며, 백플레인 기반 GMII(or RGMII) 단자를 통하여 최대 1채널의 이더넷 기반의 LiDAR 신호를 수신 한다. 또한 FPGA 보드는 GMSL 카메라 설정을 위한 I2C 통신 단자가 백-플레인 보드를 통해 제공된다. 도 7은 도 1의 CPU/GPU 보드의 구조를 나타내는 개념도이다. 도 7의 CPU/GPU 보드는 FPGA 보드에서 처리된 LiDAR-Vision 정보를 이용하여 로봇, 인공지능 등의 응용 어플리케이션 알고리즘을 처리하는 보드이다. 또한 CPU/GPU 보드는 도 7에 도시된 바와 같이, 임베디드 시스템을 위한 기본적인 부속장치(프로세서, 메모 리, 플래쉬, 주변장치 등)들이 내장된다. 또한 CPU/GPU 보드는 FPGA 보드와의 통신을 위한 백플레인 인터커넥트 라인으로 PCI Express Gen2, x4Lane 규격이 적용되어, 해당 인터 커넥트를 통하여 FPGA 보드 상에서 처리된 영상 정보를 고속으로 취득할 수 있게 된다. 또한 CPU/GPU 보드는 외부 또는 원격 시스템과의 데이터 통신을 위하여 Gigabit Ethernet 통신 인터페이스가 설치되며, 키보드, 마우스 및 고속의 주변 장치들의 연결을 위하여 USB(3.0 및 2.0) 통신 인터페이스가 적용된 다. 도 8은 도 1의 백-플레인 보드의 신호 연결을 설명하기 위한 개념도이다. 도 8의 백-플레인 보드는 CPU/GPU 보드, FPGA 보드 및 LiDAR-Vision 보드에서 처리되는 신호를 백 플레인 상에서 연결/중계하기 위한 보드이다. 또한 백-플레인 보드는 백플레인 보드는 CPU/GPU 보드, FPGA 보드, LiDAR-Vision 보드에서 처리되는 신호를 백플레인 상에서 연결/중계해주는 기능을 수행하는 보드이다. 또한 백-플레인 보드를 통해 중계되는 신호는 도 8에 도시된 바와 같이, 전원신호( 24V, 3.3V(IO 기준 전 압)), 고속의 PCI Express 신호, Parallel IO 신호 등으로 구성된다. 이와 같이 본 발명의 일실시예인 CPU, GPU 및 FPGA를 통합한 AI로봇 임베디드 시스템은 CPU, GPU 및 FPGA가 융합한 통합 프로세서를 이용하여 데이터 연산처리를 수행함으로써 인공지능(AI) 기반 다채널 카메라 영상처리 및 실시간 병렬처리가 가능하여, 연산처리로 인한 로딩, 부하 및 지체 현상을 효과적으로 방지할 수 있게 된다. 또한 CPU, GPU 및 FPGA를 통합한 AI로봇 임베디드 시스템은 로봇의 자율주행 어플리케이션 위한 최대 3~4채 널의 GMSL 카메라 인터페이스 및 처리 알고리즘과 1채널 3D LiDAR 인터페이스 및 처리 알고리즘을 적용함으로써 인공지능(AI) 기반 다채널 카메라 영상처리 및 실시간 병렬처리 속도를 더욱 개선시킬 수 있으며, 상세하게로는 병렬처리 시, 2Gbps의 전송속도를 기대할 수 있다.또한 본 발명의 CPU, GPU 및 FPGA를 통합한 AI로봇 임베디드 시스템은 백플레인 기반의 신호 인터페이스 구 조를 갖는 모듈 타입으로 제작됨으로써 기능 확장 및 유지보수를 간소화시켜, 운영의 편의성 및 효율성을 극대 화시킬 수 있게 된다."}
{"patent_id": "10-2022-0176616", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예인 AI로봇 임베디드 시스템을 나타내는 구성도이다. 도 2는 도 1의 각 모듈을 설명하기 위한 예시도이다. 도 3은 본 발명의 GMSL 카메라의 신호 변환 과정을 나타내는 개념도이다. 도 4는 도 1의 LiDAR-Vision 보드를 나타내는 개념도이다. 도 5는 도 1의 FPGA 보드의 구조를 설명하기 위한 개념도이다. 도 6은 도 5의 FPGA 보드의 신호 처리 인터페이스를 설명하기 위한 개념도이다. 도 7은 도 1의 CPU/GPU 보드의 구조를 나타내는 개념도이다. 도 8은 도 1의 백-플레인 보드의 신호 연결을 설명하기 위한 개념도이다."}
