{"patent_id": "10-2021-0089632", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0009054", "출원번호": "10-2021-0089632", "발명의 명칭": "인공지능을 이용하여 휴대 전자기기 사용자의 보행 사고를 방지하기 위한 알림방법 및 이러한", "출원인": "(주)에리", "발명자": "김현석"}}
{"patent_id": "10-2021-0089632", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "휴대 전자기기의 전면에 구비된 디스플레이를 통해 화면이 표시되고 있는 상태에서, 후면에 배치된 카메라를 통해 주변 영상을 획득하는 (a)단계;상기 (a)단계에서 획득된 영상을 보행 주의물 학습데이터를 바탕으로 학습된 인공신경망에 입력하여 보행 주의물을 검출하는 (b)단계; 및상기 (b)단계에서의 보행 주의물 검출에 대응하여 상기 휴대 전자기기를 통해 사용자에게 알림을 알리는 (c)단계를 포함하는 보행주의 알림방법."}
{"patent_id": "10-2021-0089632", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 (c)단계는,상기 검출된 보행 주의물에 대한 알림을 상기 화면에 표시하는 단계를 포함하는 보행주의 알림방법."}
{"patent_id": "10-2021-0089632", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 인공신경망의 학습은,학습 이미지에 보행 주의물과 대응하는 바운딩 박스(bounding box)를 지정하고 상기 보행 주의물에 대한 정보를라벨링하는 단계를 포함하는 보행주의 알림방법."}
{"patent_id": "10-2021-0089632", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 인공신경망은,n 개의 레이어로 구성된 모바일넷(mobilenet)모델에서 n-2, n-1 및 n번째 레이어를 제거하고, n-3번째 레이어의결과값을 공통으로 입력받아 보행 주의물을 분류하는 분류기(classifier)와 보행 주의물을 탐지하는 객체 탐지기(object detector)를 포함하고,상기 분류기는,적어도 하나의 Average Pooling Layer및 적어도 4개의 Dense Layer를 포함하고,상기 객체 탐지기는,Convolutional Layer, Flatten Layer 및 Dense Layer를 포함하는 보행주의 알림방법."}
{"patent_id": "10-2021-0089632", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "전면에 디스플레이가 배치되고, 후면에 카메라가 배치되는 휴대 전자기기에 있어서,보행 주의물 검출 학습데이터를 바탕으로 학습된 CNN(Convolutional Neural Network)이 저장된 메모리;상기 디스플레이를 통해 화면이 표시되고 있는 상태에서 상기 카메라에 의해 획득된 주변 영상을 상기 CNN에 입력하여 보행 주의물을 검출하고, 보행 주의물 검출에 대응한 알림을 상기 디스플레이를 통해 표시하는 프로세서를 포함하는 휴대 전자기기."}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 보행주의 알림방법은, 휴대 전자기기의 전면에 구비된 디스플레이를 통해 화면이 표시되고 있는 상태 에서, 후면에 배치된 카메라를 통해 주변 영상을 획득하는 (a)단계와, 상기 (a)단계에서 획득된 영상을 보행 주 의물 학습데이터를 바탕으로 학습된 인공신경망에 입력하여 보행 주의물을 검출하는 (b)단계와, 상기 (b)단계에 서의 보행 주의물 검출에 대응하여 상기 휴대 전자기기를 통해 사용자에게 알림을 알리는 (c)단계를 포함한다."}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 휴대 전자기기를 이용한 보행주의 알림 방법 및 이러한 알림 방법에 따라 동작하는 휴대 전자기기에 관한 것이다."}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대 사회에서는 스마트폰(smart phone)을 보면서 이동하는 사례가 증가하고 있다. 이런 결과로 스몸비(스마트 폰과 좀비의 단어가 합성된 신조어) 라는 신조어가 발생할 정도이다. 또한 스몸비에 대한 부작용으로 충돌, 추 락, 교통사고 등이 발생하고 있다. 이러한 사고를 방지하기 위한 여러 연구가 진행되고 있다. 예를 들어, 계단의 측면 가장자리에 램프를 설치하고, 계단의 진입 측에 패드 발판을 설치하여 보행자가 패드 발판을 밟는 경우 램프가 작동하여 보행자에 게 계단이 있음을 인식하게 하는 방식이 있다. 그런데, 이와 같은 방식은 보행자가 스마트폰에 집중하고 있는 경우 램프를 인지하지 못할 가능성이 있을 뿐만 아니라 설치 비용이 많이 드는 문제가 있다. 다른 예로, 사용자가 횡단보도에 이르렀을 때, 신호등 등에 설치된 장치에서 사용자에게 음성으로 횡단보도가 있다는 것을 알려주거나 램프 등으로 주의를 환기시키는 방식이 있다. 이러한 방식은 보행자가 현재 집중하고 있는 것(즉, 스마트론)으로부터 직접 주의 경보를 받는 것이 아니라, 관심 밖의 주변 대상을 통한 간접적 방식 으로 주의가 환기되는 것에 불과하기 때문에 스마트폰에 집중하고 걷는 보행자로 인한 사고가 끊이지 않고 있다."}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 휴대 전자기기의 사용자가 상기 휴대 전자기기의 전면에 표시된 화면을 보 면서 보행을 하는 과정에서 계단, 횡단보도, 신호등 가로수, 인도 경계 등의 보행 주의물을 인식하지 못함으로 써 발생하는 안전사고를 예방하기 위한 보행주의 알림방법 및 휴대 전자기기를 제공하는 것이다."}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 보행주의 알림방법은, 휴대 전자기기의 전면에 구비된 디스플레이를 통해 화면이 표시되고 있는 상태 에서, 후면에 배치된 카메라를 통해 주변 영상을 획득하는 (a)단계와, 상기 (a)단계에서 획득된 영상을 보행 주 의물 학습데이터를 바탕으로 학습된 인공신경망에 입력하여 보행 주의물을 검출하는 (b)단계와, 상기 (b)단계에 서의 보행 주의물 검출에 대응하여 상기 휴대 전자기기를 통해 사용자에게 알림을 알리는 (c)단계를 포함한다. 상기 (a)단계는, 상기 카메라에 의해 촬영된 동영상에서 이미지 프레임을 추출하는 단계를 포함할 수 있다. 상기 (c)단계는, 상기 검출된 보행 주의물에 대한 알림을 상기 화면에 표시하는 단계를 포함할 수 있다. 상기 인공신경망의 학습은, 학습 이미지에 보행 주의물과 대응하는 바운딩 박스(bounding box)를 지정하고 상기 보행 주의물에 대한 정보를 라벨링하는 단계를 포함할 수 있다. 상기 인공신경망은, n 개의 레이어로 구성된 모바일넷(mobilenet)모델에서 n-2, n-1 및 n번째 레이어를 제거하 고, n-3번째 레이어의 결과값을 공통으로 입력받아 보행 주의물을 분류하는 분류기(classifier)와 보행 주의물 을 탐지하는 객체 탐지기(object detector)를 포함할 수 있다. 상기 분류기는 적어도 하나의 Average Pooling Layer및 적어도 4개의 Dense Layer를 포함할 수 있고, 상기 객 체 탐지기는 Convolutional Layer, Flatten Layer 및 Dense Layer를 포함할 수 있다. 다른 관점에 따르면, 본 발명은 전면에 디스플레이가 배치되고, 후면에 카메라가 배치되는 휴대 전자기기에 관 한 것으로, 상기 휴대 전자기기는, 보행 주의물 검출 학습데이터를 바탕으로 학습된 CNN(Convolutional Neural Network)이 저장된 메모리와, 상기 디스플레이를 통해 화면이 표시되고 있는 상태에서 상기 카메라에 의해 획득 된 주변 영상을 상기 CNN에 입력하여 보행 주의물을 검출하고, 보행 주의물 검출에 대응한 알림을 상기 디스플 레이를 통해 표시하는 프로세서를 포함한다."}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 보행주의 알림방법 및 휴대 전자기기는, 사용자가 휴대 전자기기의 전면에 표시된 화면을 보면서 보 행하는 중에도 카메라를 통해 주변의 보행 주의물을 자동으로 검출하고 이를 사용자에게 알려주기 때문에 보행 간의 안전사고를 예방할 수 있으며, 특히, 보행 주의물 검출이 기 학습된 인공신경망에 의해 매우 높은 정확도 로 이루어진다."}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2021-0089632", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 도 1은 본 발명의 일 실시예에 따른 보행주의 알림시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른 휴 대 전자기기의 블록도이다. 도 1 내지 도 2를 참조하면, 본 발명의 일 실시예에 따른 보행주의 알림시스템은 휴대 전자기기와, 통신 망을 통해 휴대 전자기기와 통신하는 학습서버를 포함할 수 있다. 휴대 전자기기는, 휴대폰, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 디지털방송용 단말 기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 슬레이트 PC(slate PC), 태블릿 PC(tablet PC) 또는 울트라북(ultrabook) 등을 포함하는 개념일 수 있다. 휴대 전자기기는 메모리, 프로세서, 입력부, 입출력 포트, 통신부, 디스플레이, 카메라 및/또는 스피커를 포함할 수 있다. 메모리는 제어부의 동작을 위한 알고리즘, 어플리케이션 또는 프로그램을 저장할 수 있고, 입/출력되는 데이터들(예를 들어, 폰북, 메시지, 정지영상, 동영상 등을 임시 저장할 수도 있다. 보행 주의물 검출을 위한 인공신경망이 메모리에 저장될 수 있다. 다만, 이에 한하지 않고, 상기 인공신경 망은 인터넷(internet) 상의 웹 스토리지(web storage)에 저장된 상태에서 전자기기와 연동될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마 이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램 (random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electricallyerasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 입력부는 사용자로부터 인가되는 휴대 전자기기의 동작 제어를 위한 제어명령에 대응하여 입력 데이터 를 발생시킨다. 입력부는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(정압/정전), 조그 휠, 조그 스위치 등으로 구성될 수 있다. 통신부는 통신망을 통해 정보를 송수신함으로써 통신망에 연결된 다른 기기(예를 들어, 학습서버 )와의 통신을 가능하게 하는 것이다. 통신부는 이동통신 모듈, 무선 인터넷 모듈 및 근거리 통신 모듈 중 적어도 하나를 포함할 수 있다. 디스플레이는 전자기기에서 처리되는 정보를 표시(출력)한다. 예를 들어, UI(User Interface) 또는 GUI(Graphic User Interface)가 디스플레이에 표시될 수 있다. 디스플레이는 전자기기의 전면을 구성할 수 있다. 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 이들 중 일부 디스플레이는 그를 통해 외부를 볼 수 있도록 투명형 또는 광투과형으로 구성될 수 있다. 이는 투 명 디스플레이라 호칭될 수 있는데, 상기 투명 디스플레이의 대표적인 예로는 TOLED(Transparant OLED) 등이 있 다. 카메라는 디지털 정지영상 또는 동영상을 획득하는 이미지 센서를 포함할 수 있으며, 상기 이미지 센서를 통해 획득된 영상은 메모리에 저장될 수 있다. 프로세서는 영상을 처리하여 디스플레이를 통해 표 시할 수 있다. 카메라는 전자기기의 후면을 구성할 수 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력할 수 있다. 음향 출력부는 전자기기에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음 등)과 관련된 음향 신 호를 출력하기도 한다. 특히, 음향 출력부는 인공신경망을 통해 보행 주의물이 검출된 경우, 사용자에게 이 를 알리는 알림음을 출력할 수 있다. 이러한 음향 출력부에는 리시버(receiver), 스피커(speaker), 버저 (buzzer) 등이 포함될 수 있다. 한편, 학습서버는 보행 주의물을 학습하는 머신러닝 디바이스이다. 학습서버는 인공신경망(Artificial Neural Network, ANN) 기반의 학습모델일 수 있다. 인공신경망은, 바람직하게는 합성곱 신경망(CNN: Convolutional Neural Network)이나, 반드시 이에 한정되어야 하는 것은 아니다. 이미 잘 알려진 것처럼 합성곱 신경망은 이미지 데이터 처리에 주로 사용되는 심층 신경망으 로, 컨볼루션(convolution)계층과 풀링(pooling) 계층을 이용하여 입력 데이터의 분향을 줄임으로서 복잡한 특 징을 추출할 수 있다. CNN은 입력 계층 다음에 컨볼루션, 렐루, 풀링 계층이 연결되고 이어서 완전연결(fully connected)계층이 이어 지고 최종적으로 소프트맥스 계층을 거쳐서 결과가 출력되는데, 컨볼루션 필터를 이미지의 각 부분에 순차적으 로 내적하기 때문에 가중치를 공유하고 입력 데이터의 크기를 줄일 수 있는 이점이 있다. CNN은 이미지 탐색 및 분류에 우수한 성능을 보이지만, 학습시에 자원을 많이 사용하는 점이 있다. 따라서, 연 산성능이 우수한 딥러닝머신, 예를 들어, 학습서버에서 동작하는 것은 무리가 없다. 그러나, 인공 신경망을 모바일 환경의 휴대 전자기기에 적용하기 위해서는 지원되는 자원의 제약으로 파라 미터(Parameter)를 줄여야 하므로 최소로 줄여야 적용이 가능하며, 성능도 유지해야 한다. 이러한 측면에서, 마지막 완전 연결 레이어(Fully Connected Layer: FC Layer)를 제외한 레이어 뒤에 비선형 배 치 표준 및 ReLU 또는 Leaky ReLU 함수가 적용된 모바일넷(Mobilenet) - CNN 모델을 적용하여 각 프레임별로 보 행 주의물을 검출하도록 구성될 수 있다. 도 3은 본 발명의 일 실시예에 따른 휴대 전자기기에서 보행주의 알림 어플리케이션이 구동되는 것을 보인 도면 이다. 전자기기(10, 이하 스마트폰을 예로 듦)는 카메라를 통해 획득한 영상에서 인공 신경망 기반의 보행 주의물 을 검출하는 어플리케이션(또는, 앱)을 탑재하고 있으며, 이러한 어플리케이션은 메모리에 저장될 수 있다. 스마트폰의 전면에 배치된 디스플레이를 통해 화면이 출력되는 중에, 스마트폰의 후면에 배치된 카 메라에 의해 영상이 획득될 수 있다. 즉, 사용자가 상기 화면을 보면서 보행하는 중에 카메라는 사용자 주변의 영상을 획득하게 된다. 한손으로 스마트폰을 든 상태에서 고개를 숙여 화면을 보면서 보행하는 일반적인 형태를 고려할 시, 이때 카메라에 의해 획득되는 영상은 통상 보행자의 전방 바닥에서 획득된다고 할 수 있다. 프로세서는, 카메라에 의해 획득된 영상을 인공신경망에 입력하여 상기 영상으로부터 보행 주의물(예를 들어, 계단, 횡단보도, 신호등 가로수, 인도 경계 등)을 검출할 수 있다. 이러한 보행 주의물 검출 과정은 프로 세서에 의해 구동되는 프로그램의 백그라운드 프로세스(background process)에서 실시되며, 이때 워킹 프로 세스(working process 또는 foreground process)에서는 디스플레이에 소정의 화면을 표시하는 것에 할당될 수 있다. 여기서, 디스플레이에 표시되는 화면은 현재 구동중인 별도의 어플리케이션(예를 들어, 메신저, 웹브라우져, 게임 등)일 수 있다. 보행 주의물을 검출하기 위한 카메라의 동작은, 바람직하게는, 디스플레이에 소정의 화면이 표시된 상 태에서 사용자가 보행 중일 때에 이루어질 수 있다. 이때, 사용자의 보행을 감지하는 센서(미도시)가 더 구비될 수 있다. 상기 센서는 자이로, 가속도계 및 GPS 모듈 중 적어도 하나를 포함할 수 있다. 다르게는, 상기 센서는 사용자의 생체 신호를 감지하는 것일 수 있으며, 예를 들어, 인체의 지문, 동공 또는 안면을 인식하는 센서일 수 있다. 다르게는, 보행 주의물을 검출하기 위한 카메라의 동작은, 입력부를 통해 입력된 보행 주의물 감지 명 령에 따라 이루어질 수 있다. 예를 들어, 디스플레이에 표시되는 화면에 보행 주의물 감지 메뉴가 생성되고, 사용자가 상기 메뉴를 선택한 경우 보행 주의물 감지를 위한 카메라의 동작이 실시될 수 있다. 한편, 프로세서는 카메라에 의해 획득된 동영상으로부터 기 설정된 간격으로 이미지 프레임(image frame)을 추출하고, 이렇게 추출된 이미지를 CNN에 입력하여 보행 주의물을 검출할 수 있다. 프로세서는, 바람직하게는, 동영상으로부터 100ms마다 이미지 프레임을 추출하나 반드시 이에 한정되어야 하는 것은 아니다. 도 4는 본 발명의 일 실시예에 따른 보행주의 알림방법에서 보행 주의물 학습 과정을 도시한 순서도이다. 도 4 를 참조하면, 본 발명의 일 실시예에서 이루어지는 인공신경망의 학습은 보행 주의물 학습을 위한 마련된 다수 의 이미지들을 CNN에 입력하기 위해 처리하는 전처리단계(S110)와, 전처리된 이미지를 CNN에 입력하여 보행 주 의물을 학습하는 단계(S120)를 포함할 수 있다. 이러한, 보행 주의물 학습은 학습서버에서 수행될 수 있다. 먼저, 계단, 횡단보도, 가로수, 인도 경계 등의 보행 주의물이 표현된 다수의 이미지를 준비한다. 이러한 이미 지들은 직접 촬영하거나, 인터넷 사이트를 통해 수집할 수 있다. 이렇게 마련된 학습(learning) 또는 훈련(training) 이미지들에 바운딩 박스(bounding box) 작업을 진행한다. 이 과정은 준비된 이미지들에서 보행 주의물에 경계박스를 표시하고, 상기 경계박스가 지시하는 보행 주의물의 정보를 라벨링(labelling)하는 단계(S110)를 포함할 수 있다. 이러한 작업은 labellmg, CVAT, LabelMe, Labelbox, VoTT, imglab, YOLO Mark, PixelAnnotaionTool, OpenLabeling, imagetagger, Alturos.ImageAnnotation, DeepLabel, MedTagger, Turktools, Pixie, OpenLabeler, Anno-Mage, CATMAID, makesense.ai, LOST, annotorious, sloth 등의 공지된 어플리케이션을 이용하여 수동 또는 자동으로 이루어질 수 있다. 이렇게 전처리된 데이터는 인공신경망이 훈련하는 정답지(Ground true)로 활용될 수 있다. 학습단계(S120)는 S110단계에서 준비된 라벨링된 이미지들을 인공신경망에 입력하여 보행 주의물을 학습하는 단 계이다. 전술한 바와 같이 상기 인공신경망은 CNN일 수 있으나, 반드시 이에 한정되어야 하는 것은 아니며, 공 지된 다른 ANN도 가능하다. 도 6은 신경망의 학습 결과를 검증한 바운딩 박스 로스 그래프(bounding box loss graph)이다. 도 7은 신경망의 학습 결과를 검증한 클래스 정확도 그래프(class accuracy graph)이다. 신경망을 통과하고, 학습된 자료에 대한 검증으로 Bounding Box의 Loss와 Class에 대한 Accuracy는 각각 다른 수식을 적용했다. Bounding Box에 대한 것은 Mean Squared Error를 적용하였으며, Class에 대한 것은Categorical Crossentropy를 적용했다. 도 6에서 보이는 바와 같이, Training Loss는 5.3이며, Validation Loss 103.1 이다. 이와 같은 이유는 Stair, Crosswalk이라는 전체 객체를 Bonding Box에 넣는 경우도 있고, 회전형 혹은 굴곡이 있는 계단의 경우 일부만 Bounding Box에 포함시켰기 때문이다. Training 곡선을 확인해 보면, 비교적 명확한 보행 주의물 구분 때문에 급속하게 Loss가 줄어드는 것을 확인할 수 있다. 그리고, 도 7을 참조하면, Class Accuracy는 Training시에 1에 수렴하고, Validation시에 0.978에 이르는 정확 도를 보이고 있다. 이러한 결과는 도 8을 통해서도 알 수 있다. 한편, S110단계에서의 학습 또는 훈련이 완료되면, 훈련결과를 스마트 폰으로 이식하여 보행 주의물 검출에 적 용할 수 있다. 휴대용 전자제품(특히, 스마트폰)은 아직 딥러닝 전용 머신에 비해서 전산능력(computing source)이나 자원(resource)가 부족하기 때문에 학습서버에서 학습된 결과를 바탕으로 보행 주의물 검출을 하게 된다. 특히, 스마트폰은 자원이 제한되어 있기 때문에 동시간에 이미지 인식과 표현을 하지 못하는 단점이 있다. 따라 서, 인공신경망을 이용한 보행 주의물 인식은 백그라운드에서 진행하고 사용자에게는 결과만 표현해 주는 방식 이 적합하다. 도 5는 본 발명의 일 실시예에 따른 보행주의 알림방법을 도시한 순서도이다. 도 5에 도시된 단계들은 휴대 전 자기기에서 실시될 수 있다. 구체적으로, 본 발명의 일 실시예에 따른 보행주의 알림방법은, 주변 영상 획 득단계(S210), 보행 주의물 검출 단계(S220), 보행 주의물 검출 판정 단계(S230), 경고 알림단계(S240)를 포함 할 수 있다. 주변 영상 획득단계(S210)는, 휴대 전자기기의 전면에 구비된 디스플레이를 통해 화면이 표시되고 있는 상태에서 후면에 배치된 카메라를 통해 주변 영상을 획득하는 단계이다. 전술한 바와 같이, 디스플레이를 통한 화면의 표시는 포그라운드(foreground) 프로세스에서 이루어지고, 카 메라를 통한 주변 영상의 획득과 처리는 백그라운드 프로세스에서 이루어질 수 있다. S220단계에서는, S210단계에서 획득된 영상을 보행 주의물 학습데이터를 바탕으로 학습된 인공신경망에 입력하 여 보행 주의물을 검출한다. 상기 인공신경망은, 바람직하게는, CNN이며, 전술한 바와 같이 학습서버에서 학습된 결과를 바탕으로 구성된 것일 수 있다. 여기서, CNN에 기반한 이미지 검출 과정은, 전술한 학습서버에서 학습 또는 훈련 과정에서 보행 주의물을 분류(classification)하는 것과 실질적으로 동일한 방식으로 이루어질 수 있다. 구체적으로, S210단계에서 획득된 영상이 CNN의 입력으로 입력되고, 인공지능 기반의 분류 작업을 통해 인공신 경망의 출력으로써 얻어진 결과를 바탕으로 보행 주의물을 판정하게 된다.(S220) S220단계에서 보행 주의물이 검출된 것으로 판정되면, 전자기기의 사용자가 이를 인지할 수 있게 알리는 단 계가 실시될 수 있다.(S230) S230단계에서의 알림은 음향 출력부 및 디스플레이 중 적어도 하나를 통해 이루어질 수 있다. 보행 주 의물을 검출하는 과정에 보행자가 디스플레이의 화면에 집중하고 있는 상태에서 이루어지기 때문에 디스플 레이의 화면을 통해 보행 주의물이 발견되었음을 알리는 메시지를 출력하거나, 상기 보행 주의물의 이미지 가 표시되도록 하는 것이 바람직하다. 도 9는 모바일넷 표준 모델의 구조도(MobileNet Body Architecture)이다. 도 10은 본 발명의 일 실시예에 따른 보행 주의물 검출 모델의 구조도이다. 도 9 내지 도 10을 참조하면, 본 발명의 일 실시예에 따른 보행 주의물 검출을 위한 인공신경망은 모바일에서도 사용 가능하도록 설계될 수 있으며, 이러한 측면에서 파라미터(Parameter)의 개수를 획기적으로 줄이는 동시에 성능이 저하되지 않아야 한다는 점을 전재로, 학계 및 재계에서 연구되고 있는 신경망을 채택하고 Transfer- Learning을 구현하였다. 보다 상세하게, '보행 주의물 검출을 위한 인공신경망'은 Google Inc.에서 발표한 모바일넷(Mobilenet v1) 표준 모델(도 9 참조.)을 구성하는 n개의 레이어(layer)에서 n-2번째부터 최종 n번째 레어어를 제거하였으며, n-3번 째 레이어의 결과를 이용하여 분류(classification)와 객체 탐지(object detection)을 수행하도록 구성된다. 여 기서, 분류는 Global average pooling Layer를 이용하며, 객체 탐지는 Convolutional Layer를 이용할 수 있다. 참고로, 도 9에 도시된 것은 표준규격에 해당하며, 실제 활용시에는 stride, filter shape, input size는 적절 하게 변경될 수 있다. 출원인은 여러가지 실험을 해본 결과 신경망에 입력되는 영상이 128*128*3인 경우 가장 빠른 학습이 이루어지고, 좋은 결과를 나온다는 것을 알 수 있었고, 이를 실시예에 적용하였다. 도 9 내지 도 10에서 보이는 바와 같이, '보행 주의물 검출을 위한 인공신경망'은 모바일넷의 Average Pooling Layer, Fully Connected Layer, 그리고 Softmax Layer는 사용하지 않으며, 13번째 Convolutional Layer에서 나 온 결과가 공통으로 입력되는 분류기(classifier)와 객체 탐지기(object detector)를 포함할 수 있다. 여기서, 상기 분류기는 영상에서 검출된 보행 주의물을 분류하는 것으로써, 1개의 Average Pooling Layer와 적 어도 하나의 Dense Layer를 포함하며, Class 정보를 얻도록 구성될 수 있다. 실시예에서와 같이 Dense Layer는 바람직하게는 4개이나, 반드시 이에 한정되어야 하는 것은 아니다. 상기 객체 탐지기는 영상에서 보행 주의물을 탐지하는 것으로써 적어도 하나의 Convolutional Layer, 적어도 하 나의 Flatten Layer 및 적어도 하나의 Dense Layer를 포함하며, Bounding Box의 정보를 얻도록 구성될 수 있다. 실시예에서 Convolutional Layer, Flatten Layer 및 Dense Layer는 각각 1개씩이나, 반드시 이에 한정되 어야 하는 것은 아니다. 한편, 실재 학습시에는 모바일넷은 학습되지 않고, 신규로 추가한 분류/객체 탐지를 위한 레이어들만 학습을 진 행할 수 있다. 한편, 전술한 '보행 주의물 검출을 위한 인공신경망'을 휴대용 가전기기(예를 들어, 스마트폰)에 적용하기 위해 서 Tensorflow-lite가 이용될 수 있다. Tensorflow-lite는, 백그라운드 스레드(Background Thread)에서 카메 라에 의해 영상이 획득되는 동안 100ms단위로 이미지 프레임이 추출되고, 그 추출된 이미지를 탐지 스레드 (Detection Thread)로 보낼 수 있다. Detection Thread에서는 Tensorflow Lite에 기 저장되어 있는 학습데이 터(즉, 전술한 학습과정에서 학습된 것)를 바탕으로 보행 주의물을 판단할 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2021-0089632", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 보행주의 알림시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른 휴대 전자기기의 블록도이다. 도 3은 본 발명의 일 실시예에 따른 휴대 전자기기에서 보행주의 알림 어플리케이션이 구동되는 것을 보인 도면 이다. 도 4는 본 발명의 일 실시예에 따른 보행주의 알림방법에서 보행 주의물 학습 과정을 도시한 순서도이다. 도 5는 본 발명의 일 실시예에 따른 보행주의 알림방법을 도시한 순서도이다. 도 6은 신경망의 학습 결과를 검증한 바운딩 박스 로스 그래프(bounding box loss graph)이다. 도 7은 신경망의 학습 결과를 검증한 클래스 정확도 그래프(class accuracy graph)이다. 도 8은 인공신경망을 통해 보행 주의물을 검출한 결과들이다. 도 9는 모바일넷 표준 모델의 구조도(MobileNet Body Architecture)이다. 도 10은 본 발명의 일 실시예에 따른 보행 주의물 검출 모델의 구조도이다."}
