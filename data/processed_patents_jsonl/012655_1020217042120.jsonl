{"patent_id": "10-2021-7042120", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0010560", "출원번호": "10-2021-7042120", "발명의 명칭": "이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 시스템 및 방법", "출원인": "에버씬 리미티드", "발명자": "테이치너 마이클"}}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 이미지 내에서 수행되는 동작을 결정하기 위한 시스템에 있어서,하나 이상의 명령어를 저장하기 위한 메모리; 및상기 메모리에 통신가능하게 커플링되고 상기 메모리 내의 상기 하나 이상의 명령어를 실행하도록 구성되고, 컨볼루션 신경망(convolutional neural network; CNN)을 채용하는 프로세서를 포함하고,상기 CNN은, 상기 입력 이미지에 대응하는 하나 이상의 중요 특징(significant features)을 추출하기 위한 미리 정의된 수의초기 단계 - 각각의 초기 단계는 제 1 계층 및 잔차 블록을 포함하고, 상기 제 1 계층은 컨볼루션 계층(convolution layer), 최대 풀링(pooling) 계층 및 평균 풀링 계층으로 구성된 그룹으로부터 선택됨 - ; 및상기 추출된 중요 특징을 하나 이상의 미리 정의된 클래스로 분류하기 위한 최종 단계 - 상기 최종 단계는 전역(global) 평균 풀링 계층 및 밀집 계층으로 형성됨 - 를 포함하는 것인, 입력 이미지 내에서 수행되는 동작을결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 미리 정의된 수의 초기 단계는 상기 입력 이미지에 대응하는 상기 중요 특징을 반복적으로 추출하도록 구성되는 것인, 입력 이미지 내에서 수행되는 동작을 결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 각각의 잔차 블록은 적어도 하나의 배치 정규화(batch normalization) 계층, 적어도 하나의 정류 선형 유닛, 및 일정한 수의 필터의 적어도 하나의 컨볼루션 계층을 포함하는 것인, 입력 이미지 내에서 수행되는 동작을 결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 입력 이미지는 1개 내지 30개의 범위 내의 이미지를 포함하는 것인, 입력 이미지 내에서 수행되는 동작을결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 최대 풀링 계층, 평균 풀링 계층 및 전역 평균 풀링 계층의 각각은 비선형 함수를 채용하여 대응하는 입력의 다운샘플링을 수행하는 것인, 입력 이미지 내에서 수행되는 동작을 결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 최대 풀링 계층은 상기 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위해 높은 중요도를갖는 복수의 픽셀을 추출하도록 구성되는 것인, 입력 이미지 내에서 수행되는 동작을 결정하기 위한 시스템.공개특허 10-2022-0010560-3-청구항 7 제 5 항에 있어서, 상기 평균 풀링 계층은 상기 입력 이미지 내의 정보를 압축된 형태로 인코딩하도록 구성되는 것인, 입력 이미지내에서 수행되는 동작을 결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 각각의 계층은 복수의 인공 뉴런을 포함하고, 상기 밀집 계층의 각각의 인공 뉴런은 상기 전역 평균 풀링 계층의 각각의 인공 뉴런과 접속되는 것인, 입력 이미지 내에서 수행되는 동작을 결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 각각의 컨볼루션 계층은 1의 스트라이드(stride) 값 및 일정한 수의 필터를 채용하는 것인, 입력 이미지 내에서수행되는 동작을 결정하기 위한 시스템."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법에 있어서,상기 입력 이미지를 수신하는 단계; 및컨볼루션 신경망(convolutional neural network; CNN)에 상기 입력 이미지를 제공하는 단계를 포함하고,상기 CNN은,상기 입력 이미지에 대응하는 하나 이상의 중요 특징을 추출하기 위한 미리 정의된 수의 초기 단계 - 각각의 초기 단계는 제 1 계층 및 잔차 블록을 포함하고, 상기 제 1 계층은 컨볼루션 계층, 최대 풀링 계층 및 평균 풀링계층으로 구성된 그룹으로부터 선택됨 - ; 및상기 추출된 중요 특징을 하나 이상의 미리 정의된 클래스로 분류하기 위한 최종 단계 - 상기 최종 단계는 전역평균 풀링 계층 및 밀집 계층으로 형성됨 - 를 포함하는 것인, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서, 상기 입력 이미지에 대응하는 상기 하나 이상의 중요 특징을 반복적으로 추출하는 단계를 더 포함하는, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서, 각각의 잔차 블록은 적어도 하나의 배치 정규화 계층, 적어도 하나의 정류 선형 유닛, 및 일정한 수의 필터의적어도 하나의 컨볼루션 계층을 포함하는 것인, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기위한 방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서, 상기 적어도 하나의 이미지는 1개 내지 30개의 범위 내의 이미지를 포함하는 것인, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법.공개특허 10-2022-0010560-4-청구항 14 제 10 항에 있어서, 상기 최대 풀링 계층, 평균 풀링 계층 및 전역 평균 풀링 계층의 각각은 비선형 함수를 채용하여 대응하는 입력의 다운샘플링을 수행하는 것인, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 상기 입력 이미지 내에서 상기 대상체에 의해 수행되는 동작을 결정하기 위해 높은 중요도를 갖는 복수의 픽셀을 추출하는 단계를 더 포함하는, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서, 상기 입력 이미지 내의 정보를 압축된 형태로 인코딩하기 위해 상기 평균 풀링 계층을 채용하는 단계를 더 포함하는, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 1 항에 있어서, 각각의 계층은 복수의 인공 뉴런을 포함하고, 상기 밀집 계층의 각각의 인공 뉴런은 상기 전역 평균 풀링 계층의 각각의 인공 뉴런과 접속되는 것인, 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 10 항에 있어서, 상기 컨볼루션 계층은 1의 스트라이드 값 및 일정한 수의 필터를 채용하는 것인, 입력 이미지 내에서 대상체에의해 수행되는 동작을 결정하기 위한 방법."}
{"patent_id": "10-2021-7042120", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "머신-판독가능한 비일시적 데이터 저장 매체에 기록된 소프트웨어 제품에 있어서, 상기 소프트웨어 제품은 제 1항에 청구된 방법을 구현하도록 컴퓨팅 하드웨어 상에서 실행가능한 것인, 소프트웨어 제품."}
{"patent_id": "10-2021-7042120", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "입력 이미지 내에서 수행되는 동작을 결정하기 위한 시스템은 하나 이상의 명령어를 저장하기 위한 메모리, 및 메모리에 통신가능하게 커플링되고 메모리에서 하나 이상의 명령어를 실행하도록 구성된 프로세서를 포함한다. 프로세서는 입력 이미지에 대응하는 하나 이상의 중요 특징을 추출하기 위한 미리 정의된 수의 초기 단계를 포함 하는 컨볼루션 신경망(CNN)을 채용하며, 각각의 초기 단계는 제 1 계층 및 잔차 블록을 포함하고, 제 1 계층은 컨볼루션 계층, 최대 풀링 계층 및 평균 풀링 계층으로 구성된 그룹에서 선택된다. CNN은 추출된 중요 특징을 하나 이상의 미리 정의된 클래스로 분류하기 위한 최종 단계를 포함하며, 최종 단계는 전역 평균 풀링 계층 및 밀집 계층으로 형성된다."}
{"patent_id": "10-2021-7042120", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 인공 지능에 관한 것이고, 보다 구체적으로, 이미지 내에서 대상체에 의해 수행되는 동작 을 결정하기 위한 시스템 및 방법에 관한 것이다. 더욱이, 본 개시는 머신 판독가능 비일시적 데이터 저장 매 체에 기록된 소프트웨어 제품에 관한 것이며, 여기서 소프트웨어 제품은 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위해 상기 언급된 방법을 구현하기 위해 컴퓨팅 하드웨어 상에서 실행가능하다."}
{"patent_id": "10-2021-7042120", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 기술의 발전과 함께, 컴퓨터는 사람들의 일상생활에서 점점 더 많이 사용되고 있다. 여기에는 통 신, 교육, 서비스 산업 등의 분야에서 컴퓨터를 사용하는 것을 포함하되 이에 한정되지 않는 개인용 컴퓨팅 애 플리케이션뿐만 아니라 사회적 관심과 관련된 기타 상업적 및 비상업적 목적을 위한 컴퓨터의 사용이 포함된다. 이러한 컴퓨터 사용에는 예를 들어 국방, 의학, 과학 연구 등이 포함될 수 있다. 특히, 상기 언급된 분야에서 사용량이 증가하고 있는 컴퓨팅 영역은 인공 지능, 머신 러닝 및 머신 비전이다. 예를 들어, 자율주행 시스템(예를 들어, 자율주행차)의 분야에서, 자율주행이 가능한 차량 주변의 대상체를 검 출하기 위해 머신 비전 및 인공 지능이 채용되고 있고, 그에 따라 차량이 안전하고 편리하며 안정적으로 대상체 주위를 탐색하게 한다. 또다른 예에서, 사람의 움직임을 검출하고 식별할 수 있는 센서를 갖는 디바이스는 국 가의 국경 지역 주변과 같은 방위 애플리케이션에서 점점 더 많이 사용되고 있다. 그러한 디바이스는 내부에 머신 비전 및 인공 지능을 채용하여 국가의 국경에 불법적으로 침투할 수 있는 사람들과 연관될 수 있는 잠재적 인 위협을 검출한다. 일반적으로, 상기 언급된 인공 지능, 머신 러닝 및 머신 비전 시스템은 환경 내의 대상체(예를 들어, 인간 또는 동물)의 존재를 검출하는 것뿐만 아니라 환경 내에서 대상체에 의해 수행되는 동작을 식별하는데에도 사용된다. 예를 들어, 인공 지능 시스템은 대상체에 의해 수행되는 동작을 식별하기 위해 컨볼루션 신경망을 채용할 수 있 다. 그러나, 이러한 컨볼루션 신경망은 그 용도에 따라 상이한 수의 필터, 또는 복수의 리던던트 계층을 필요 로하며, 그에 따라 대상체와 연관된 동작에 대한 결정이 느리고 비효율적일 수 있다. 따라서, 전술한 논의에 비추어, 환경에서 대상체에 의해 수행되는 동작을 식별하기 위해 컨볼루션 신경망을 채 용하는 기존 인공 지능 시스템과 연관된 단점을 극복할 필요가 있다. 본 개시는 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 개선된 시스템을 제공하고자 한다. 또한, 본 개시는 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 개선된 방법을 제공하고자 한다. 또한, 본 개시는 머신 판독가능 비일시적 데이터 저장 매체 상에 기록된 소프트웨어 제품을 제공하고자 하며, 여기서 소프트웨어 제품은 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 상기 언급된 방법 을 구현하기 위해 컴퓨팅 하드웨어 상에서 실행가능하다. 제 1 양태에 따르면, 본 개시의 실시예는 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 시 스템을 제공한다. 시스템은 하나 이상의 명령어를 저장하기 위한 메모리, 및 메모리에 통신가능하게 커플링되 고 메모리 내의 하나 이상의 명령어을 실행하도록 구성된 프로세서를 포함하고, 프로세서는 컨볼루션 신경망 (convolutional neural network; CNN)을 채용한다. CNN은 입력 이미지에 대응하는 하나 이상의 중요 특징 (significant features)을 추출하기 위한 미리 정의된 수의 초기 단계를 포함하며, 각각의 초기 단계는 제 1 계 층 및 잔차 블록을 포함하고, 제 1 계층은 컨볼루션 계층(convolution layer), 최대 풀링(pooling) 계층 및 평 균 풀링 계층으로 구성된 그룹으로부터 선택된다. CNN은 추출된 중요 특징을 하나 이상의 미리 정의된 클래스 로 분류하기 위한 최종 단계를 포함하며, 최종 단계는 전역 평균 풀링 계층 및 밀집 계층으로 형성된다. 제 2 양태에 따르면, 본 발명의 일 실시예는 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 방법을 제공한다. 방법은 입력 이미지를 수신하는 단계, 및 컨볼루션 신경망(CNN)에 입력 이미지를 제공하는 단계를 포함한다. CNN은, 입력 이미지에 대응하는 하나 이상의 중요 특징을 추출하기 위한 미리 정의된 수의 초기 단계를 포함하며, 각각의 초기 단계는 제 1 계층 및 잔차 블록을 포함하고, 제 1 계층은 컨볼루션 계층, 최대 풀링 계층 및 평균 풀링 계층으로 구성된 그룹으로부터 선택된다. CNN은 추출된 중요 특징을 하나 이상의 미리 정의된 클래스로 분류하기 위한 최종 단계를 포함하며, 최종 단계는 전역 평균 풀링 계층 및 밀집 계층으 로 형성된다. 제 3 양태에 따르면, 본 개시의 실시예는 머신 판독가능 비일시적 데이터 저장 매체에 기록된 소프트웨어 제품 을 제공하고, 여기서 소프트웨어 제품은 입력 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 전 술한 방법을 구현하기 위해 컴퓨팅 하드웨어 상에서 실행가능하다. 본 개시는 컨볼루션 신경망을 이용하여 이미지 내에서 대상체에 의해 수행되는 동작을 결정하는 시스템 및 방법 을 제공하고, 여기서 컨볼루션 신경망은 제한된 수의 계층, 일정한 수의 필터 및 필터의 다운사이징을 채용하고, 따라서 이미지 내의 대상체에 의해 수행되는 동작의 결정과 연관된 속도, 정확성 및 신뢰성을 향상시 킨다. 본 개시의 피쳐는 첨부된 청구범위에 의해 정의되는 바와 같은 본 개시의 범위를 벗어나지 않으면서 다양한 조 합으로 조합되는 것을 허용한다는 것이 인식될 것이다."}
{"patent_id": "10-2021-7042120", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음의 상세한 설명은, 본 개시의 실시형태 및 그들이 구현될 수 있는 방식을 예시한다. 본 개시를 실행하는 몇몇 모드가 개시되었지만, 기술 분야의 숙련된 자는, 본 개시를 실행하기 위한 또는 실시하기 위한 다른 실시 형태도 또한 가능하다는 것을 인식할 것이다. 개요에서, 본 개시의 실시예는 이미지 내의 대상체에 의해 수행되는 동작을 결정하기 위한 시스템 및 방법에 관 한 것이다. 도 1은 본 개시내용의 다양한 실시예가 실시될 수 있는 환경을 예시한다. 환경은 이미징 디바이스 및 동작 분류 시스템을 포함하고, 이들은 통신 네트워크를 통해 서로 통신가능하게 커플링된다. 통신 네트워크는 본 개시의 범위를 제한하지 않으면서, 임의의 적절한 유선 네트워크, 무선 네트워크, 이들의 조합 또는 임의의 다른 종래의 네트워크일 수도 있다. 몇몇 예는, 근거리 통신망(Local Area Network; LAN), 무선 LAN 연결, 인터넷 연결, 지점간(point-to-point) 연결, 또는 다른 네트워크 연결 및 이들 의 조합을 포함할 수도 있다. 이미징 디바이스는 비디오 스트림을 캡쳐하도록 구성된다. 본 개시의 한 실시형태에서, 이미징 디바이스 는 셀프 체크 아웃 시스템(Self-check out system; SCO)을 포함하는 소매점 체크 아웃 프로세스의 하나 이 상의 이미지를 캡쳐하도록 구성된다. 옵션 사항으로, 이미징 디바이스는, 인터넷 프로토콜(Internet protocol; IP) 카메라, 팬-틸트-줌(Pan-Tilt-Zoom; PTZ) 카메라, 열화상 카메라(thermal image camera) 또는 적외선 카메라를 포함하지만, 그러나 이들로 제한되지는 않는다. 동작 분류 시스템은 이미징 디바이스에 의해 캡처된 인간 동작 및 인간 활동의 이미지를 하나 이상의 미리 정의된 클래스로 분류하도록 구성된다. 동작 분류 시스템은 중앙 프로세싱 유닛(central processing unit; CPU), 조작 패널(operation panel; 108), 및 메모리를 포함한다. CPU는 프로세서, 컴퓨터, 마이크로컨트롤러, 또는 조작 패널 , 및 메모리와 같은 다양한 컴포넌트의 동작을 제어하는 다른 회로부(circuitry)이다. CPU는, 예를 들면, 메모리와 같은 휘발성 또는 불휘발성 메모리에 저장되는, 또는 다르게는 CPU에 제공되는 소프트웨어, 펌웨어, 및/또는 다른 명령어를 실행할 수도 있다. CPU는, 하나 이상의 시스템 버스, 케이블, 또는 다른 인터페이스와 같은 유선 또는 무선 연결을 통해, 조작 패널, 및 메모리에 연결될 수도 있다. 본 개시의 한 실시형태에서, CPU는, 로컬 네트워크 상의 모든 카메라에 대해, 실시간 대상체 검출 및 예측을 제공하기 위한 맞춤형 그래픽 프로세싱 유닛(Graphic processing unit; GPU) 서버 소프트웨어를 포함할 수도 있다. 조작 패널은 동작 분류 시스템을 위한 사용자 인터페이스일 수 있고, 물리적 키패드 또는 터치스크린 의 형태를 취할 수 있다. 조작 패널은 선택된 기능, 선호도, 및/또는 인증에 관련이 있는 입력을 하나 이상의 사용자로부터 수신할 수도 있고, 입력을 시각적으로 및/또는 청각적으로 제공 및/또는 수신할 수도 있다. 메모리는, 동작 분류 시스템의 동작을 관리함에 있어서 CPU에 의한 사용을 위한 명령어 및/또는 데이터를 저장하는 것 외에, 동작 분류 시스템의 하나 이상의 사용자와 관련되는 사용자 정보를 또한 포함 할 수도 있다. 예를 들면, 사용자 정보는 인증 정보(예를 들면, 사용자명/패스워드 쌍), 사용자 선호도, 및 다 른 사용자 고유의 정보를 포함할 수도 있다. CPU는, 조작 패널 및 메모리의 작동에 관련되는 제어 기능(예를 들면, 하나 이상의 제어 신호를 송신하는 것 및/또는 수신하는 것)을 제공하는 것을 돕기 위해 이 데이터에 액세스할 수도 있다. 도 2a 및 도 2b는 본 개시의 실시예에 따른, 동작 분류 시스템의 CPU의 블록도를 예시한다. CPU는 적어도 하나의 관심 동작 영역을 결정하기 위해 비디오 스트림의 각 프레임을 분석하도록 작동가능 한 컨볼루션 신경망(Convolutional Neural Network; CNN)을 채용하며, 여기서 적어도 하나의 관심 영역은 적어도 하나의 대상체를 포함한다. 예에서, 적어도 하나의 대상체는 사람, 대상체 예컨대 의류 아이템, 식료품, 지갑 및 등등일 수도 있고, 하나 이상의 동작은 한 사람이 자신의 주머니에서 지갑을 꺼내는 것, 사람 이 대기열에서 걷고 있는 것, 사람이 신용 카드를 긁는 것, 및 등등을 포함할 수도 있다. CNN은 SCO 스캔 영역(스캐닝 동작 관심 영역)의 비디오의 이미지 프레임을 손, 손에 든 대상체, 대상체, 신체 부위, 빈 스캐너 와 같은 클래스로 분류하도록 트레이닝될 수 있다. 각 클래스의 이미지 프레임 분류 기준은 다음과 같다: 손 - 이미지 프레임은 사람 손(들)을 나타낸다. 손에 든 대상체 - 이미지 프레임은 사용자의 손에 든 대상체를 나타낸다. 대상체 - 이미지 프레임은 대상체만을 나타낸다. 신체 부위 - 이미지 프레임은 인체 일부를 나타낸다. 빈 스캐너 - 이미지 프레임은 빈 스캐너만을 나타낸다. 본 발명의 일 실시예에서, CNN은 제 1 내지 제 6 스테이지(204a 내지 204f)(이하, 총칭하여 스테이지(20 4)라 함)로 형성된다. CNN은 부분적으로 컨볼루션 계층, 즉 입력에 컨볼루션을 적용하는 계층으로 구성된 신경망을 말한다. 또한, CNN의 스테이지의 수가 6개 초과일 수 있다는 것이 당업자에게 명백할 것이다. 본 명세서에서 언급되는 CNN은 적어도 하나의 관심 영역에서 적어도 하나의 대상체를 분류하기 위해 주로 사용되는 트레이닝된 심층 인공 신경망으로 정의된다. 특히 그들은, 얼굴, 개인, 도로 표지판 등을 식별할 수 있는 알고리즘이다. 본 명세서에서 사용되는 바와 같은 용어 \"신경망\"은, 각각이, 선택적으로, 로컬 메모리와 연관되는 프로세싱 요소의 고도로 상호접속된 네트워크를 포함할 수 있다. 또한, 신경망의 프로세싱 요소는 \" 인공 신경 단위\", \"인공 뉴런\", \"신경 단위\", \"뉴런\", \"노드\" 등일 수 있다. 게다가, 뉴런은 입력 또는 하나 이상의 다른 뉴런으로부터 데이터를 수신할 수 있고, 데이터를 프로세싱할 수 있고, 프로세싱된 데이터를 출력 또는 또 다른 하나 이상의 뉴런으로 전송할 수 있다. 본 발명의 일 실시예에서, CNN의 각 스테이지는 여러 계층으로 구성된다. 일 예에서, 각각의 스테이 지는 컨볼루션 계층, 최대 풀링 계층, 및 평균 풀링 계층으로 구성된 그룹으로부터 선택된 제 1 계층를 포 함한다. 최대 및 평균 풀링 계층은 대응하는 입력을 다운샘플링하도록 구성되어, 다른 계층의 사이즈를 줄이다. 각 스테이지에 대해, 제 1 계층 이외의 계층은 대응하는 잔차 블록을 형성한다. 본 발명의 일 실시예에서, 제 1 스테이지(204a)는 컨볼루션 계층(205a), 및 배치 정규화 계층(206a), 정류된 선 형 유닛(Rectified Linear Unit; RELU) 계층(208a), 다른 컨볼루션 계층(210a), 배치 정규화 계층(212a), 또다 른 RELU 계층(214a), 및 또다른 컨볼루션 층(216a)을 포함하는 제 1 잔차 블록을 포함한다. 나머지 제 2 내지 제 5 스테이지(204b 내지 204e)의 층은 도 2a 및 도 2b에 관해서 자명하며, 간결함을 위해 여기에서 다시 설명 할 필요는 없다. CNN에서, 각 컨볼루션 계층은 분류 작업을 지원하기 위해 구별되는 로컬 특징을 찾는데 사용되는 컨볼루션 커널의 그룹을 말한다. 기존 이미지 처리 파이프라인에서, 컨볼루션 커널은 특징 추출 단계로서 원본 이미지로 부터 응답 맵을 얻기 위해 손으로 제작(handcrafted)된다. 예를 들어, Sobel 커널 또는 Prewitt 커널은 에지 정보를 추출하는데 사용되는 반면, Gaussian 평활화 커널은 노이즈 감소된 흐릿한(blurred) 이미지를 얻는데 사 용된다. CNN 파이프라인에서 컨볼루션 커널은 무작위로 초기화되고 궁극적인 분류 성능을 향상시키기 위해 현 저성을 학습하도록 진화된다. 특징 맵의 스택은 계층 및 커널에 걸친 컨볼루션 연산에 의해 계산된다. 각 컨볼루션 계층(204a, 210a 및 216a)은 1의 스트라이드 값을 사용한다. 또한, CNN에서, 최대 풀링 계층(205b 및 205e) 각각은 대응하는 이전 컨볼루션 계층에 의해 생성된 특징 맵을 다운 샘플링하기 위해 비선형 함수를 사용한다. CNN의 맥락에서, 최대 풀링은 CNN을 얇게 하고 컨볼루션 대신 사용된다(가장 중요한 픽셀을 추출하고 정규화의 형태로 작동하는 것에 의해). 정규화는 적어도 하나의 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위해 높은 중요성을 갖는 복수의 픽셀을 추출하 는 것을 포함한다. 또한, CNN에서 평균 풀링 계층(205c 및 205d) 각각은 압축된 형태로 정보를 인코딩하기 위해 사용된다. 일 예에서, 평균 풀링 계층(205c 및 205d)은 입력을 직사각형 풀링 영역으로 분할하고 중요도가 높은 복수의 픽 셀의 평균 값을 계산함으로써 다운 샘플링을 수행한다. 또한, CNN에서, 배치 정규화 계층(206a 내지 206e) 각각은 배치 평균을 빼고 배치 표준 편차로 나눔으로써 이전 활성화 계층의 출력을 정규화한다. 또한, CNN에서, 각각의 RELU(214a 내지 214e)는 활성화 함수를 사용하기 위한 컴퓨팅 프로그램 또는 루틴 의 집합을 말하며, 이는 적어도 하나의 이미지에 대응하는 중요 특징을 사용하여 얻어진 반파 정류와 유사하다. 동작시, 제 1 내지 제 5 스테이지(204a 내지 204e)는 입력 이미지로부터 중요 특징을 추출하도록 구성된다. 본 명세서에 사용된 용어 \"중요 특징\"은 적어도 하나의 입력 이미지에서 픽셀 특성의 하나 이상의 변화를 지칭한다. 각 픽셀과 관련하여 사용되는 용어 \"픽셀 특성\"은 픽셀의 사이즈, 픽셀의 색상 및/또는 픽셀의 해상 도를 말한다. 구체적으로, 특징 추출 프로세스는 적어도 하나의 이미지로부터 원하는 특징 집합이 추출될 때까 지 반복적으로 수행된다. 본 발명의 일 실시예에서, 제 6 스테이지(204f)는 이전의 제 1 내지 제 5 스테이지(204a 내지 204e)의 출력(특 징)에 기초하여 실제 결정을 내리는 분류 스테이지이다. 제 6 스테이지(204f)는 전역 평균 풀링 층 및 밀 집 계층을 채용하여, 적어도 하나의 이미지 내에서 대상체에 의해 수행되는 동작을 결정한다. 전역 평균 풀링 계층은 3차원 텐서의 공간 차원을 줄이는데 사용되며, 밀집 계층은 모든 입력이 모든 출력에 가 중치(n_inputs * n_outputs 가중치가 있음)로 접속되는 선형 연산을 포함한다. 밀집 계층은 CNN의 공통 특징이며, 각 뉴런은 대응하는 이전 계층의 모든 뉴런에 완전히 접속되어 있다. 전역 평균 풀링 계층 은 다운샘플링을 수행하기 위해 비선형 함수를 채용한다. 일 예에서, 제 6 스테이지(204f)는 Hand, Hand+Object, Object, Bodypart, Empty Scanner의 5가지 클래스 중 하나로 입력 이미지를 분류한다. 본 개시내용의 다양한 실시예에서, CNN은 컨볼루션 계층 전체에 걸쳐 일정한 수의 필터를 사용하고, CNN이 일부 잔차 블록을 건너뛸 수 있게 하는 스트라이드 1만을 사용하는 컨볼루션 계층을 포함하는 잔차 블록을 사용한다. CNN은 최대/평균 풀링 계층를 주기적으로 적용하고 모든 계층에 걸쳐 필터 수를 일정하 게 유지함으로써 차원 감소 메커니즘을 활용한다. 일반적인 방법은 각 차원 감소 작업 후에 필터의 수를 두 배 로 늘리는 것이지만, 일정 값을 사용하면 네트워크의 폭이 트레이닝 하이퍼 파라미터로서 동작할 수 있다. CNN은, 매우 얇은 계층을 갖고 전체적으로 가볍고(140000개의 트레이닝가능한 파라미터), 128x128 컬러 이 미지에서 5가지 클래스(Hand, Hand+Object, Object, Bodypart, Empty Scanner)의 이미지를 분류하는 작업에서 ResNet 또는 DenseNet(17000000-58000000개의 트레이닝가능한 파라미터)에 기초하여 임의의 다른 미세 조정된 커스텀 지정 아키텍처와 거의 같은 성능을 발휘할 수 있다. 장점은 낮은 메모리 공간(약 450mb)과 다른 시스템 보다 3 내지 5배 빠른 추론 시간의 형태로 제공된다. CNN은 다음의 2가지 주요 원칙을 활용한다: - 심층 잔차 네트워크의 ID 매핑을 포함하는 2개의 컨볼루션 계층이 있는 전체 사전 활성화 잔차 블록 - 큰 학습 속도를 사용하는 신경망의 매우 빠른 트레이닝 포함하는 슈퍼 컨버전스 도 3을 참조하면, 본 개시의 실시예에 따른, 적어도 하나의 이미지 내에서 대상체에 의해 수행되는 동작을 결정 하는 방법의 단계들이 도시된다. 단계에서, 동작을 수행하는 대상체를 포함하는 적어도 하나의 이미 지가 수신된다. 단계에서, 컨볼루션 신경망에 대한 적어도 하나의 이미지가 제공된다. 단계에서, 적어도 하나의 이미지에 대응하는 중요 특징은, 컨볼루션 신경망과 연관된 컨볼루션 층, 최대 풀링 층, 및 평균 풀링 층을 사용하여 추출된다. 단계에서, 적어도 하나의 이미지에 대응하는 중요 특징은 전역 평균 풀링 계층 및 밀집 계층를 채용하여 분류되어, 적어도 하나의 이미지 내에서 대상체에 의해 수행되는 동작을 결정한다. 단계(302 내지 308)는 단지 예시일 뿐이고, 하나 이상의 단계가 추가되거나, 하나 이상의 단계가 제거되거나, 또는 하나 이상의 단계가 본 발명의 청구 범위를 벗어나지 않고 상이한 순서로 제공되는 다른 대안이 제공될 수 있다. 일 예에서, 방법은 컨볼루션 신경망과 연관된 복수의: 컨볼루션 계층, 최대 풀링 계층, 및 평균 풀링 계 층를 채용하여 적어도 하나의 이미지에 대응하는 중요 특징을 반복적으로 추출하는 단계를 포함한다. 다른 예 에서, 방법은 중요 특징을 추출한 후에 배치 정규화 계층 및 정류된 선형 유닛을 포함하는 적어도 하나의 잔차 블록을 채용하는 단계를 포함한다. 다른 예에서, 최대 풀링 계층, 평균 풀링 계층 또는 전역 평균 풀링 계층은 적어도 하나의 이미지의 다운 샘플링을 수행하기 위해 비선형 함수를 채용한다. 또 다른 예에서, 방법은 최대 풀링 계층을 채용하여 적어도 하나의 이미지를 정규화하는 단계를 포함하고, 여기서 정규화는 적어도 하나의 이 미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위해 높은 중요성을 갖는 복수의 픽셀을 추출하는 단계를 포함한다. 일 예에서, 방법은 압축된 형태로 적어도 하나의 이미지 내의 정보를 인코딩하기 위해 평균 풀링 계 층을 채용하는 단계를 포함한다. 다른 예에서, 방법은 각각의 층이 복수의 인공 뉴런을 포함하고, 밀집 계층의 복수의 인공 뉴런 각각이 전역 평균 풀링 계층의 복수의 인공 뉴런과 접속된다. 또 다른 예에서, 방법은 컨볼 루션 계층에 의해 1의 스트라이드 값을 채용하는 단계를 포함한다. 본 개시를 기술하는 맥락에서(특히 다음 청구범위의 맥락에서) 용어 \"a\" 및 \"an\" 및 \"the\" 및 유사한 지시어의 사용은, 여기에 달리 명시되지 않거나 문맥상 명백하게 모순되지 않는 한 단수 및 복수 모두를 포함하도록 구성 될 것이다. \"포함하는\", \"가지는\", \"구비하는\" 및 \"함유하는\"이라는 용어는 달리 언급되지 않는 한 개방형 용 어(즉, \"포함하지만 이에 제한되지 않는\"을 의미)로 해석되어야 한다. 본 명세서에서 값의 범위에 대한 언급은 본 명세서에서 달리 표시되지 않는 한 범위 내에 속하는 각각의 개별 값을 개별적으로 지칭하는 약식 방법으로 서 역할을 하기 위한 것일 뿐이며, 각각의 개별 값은 본 명세서에 개별적으로 인용된 것처럼 명세서에 통합된다. 여기에 설명된 모든 방법은 여기에 달리 표시되지 않거나 문맥상 명백하게 모순되지 않는 한 임의의 적절한 순서로 수행될 수 있다. 본 명세서에 제공된 임의의 예 및 모든 예 또는 예시적인 언어(예를 들어, \"~ 와 같은\")의 사용은 단지 본 개시를 더 잘 설명하기 위한 것이며 달리 청구되지 않는 한 본 개시의 범위를 제한 하지 않는다. 명세서의 어떤 언어도 본 개시의 실행에 필수적인 것으로 임의의 청구되지 않은 요소를 나타내는 것으로 해석되어서는 안 된다. 첨부된 청구범위에 의해 정의되는 바와 같은 본 발명의 범위를 벗어나지 않으면서, 상기에서 설명되는 본 발명 의 실시예에 대한 수정이 가능하다. 본 발명을 설명하고 본 발명의 권리를 주장하기 위해 사용되는 \"포함하 는\", \"함유하는\", \"통합하는\", \"구성되는\", \"가지는\", \"~인\"과 같은 표현은 비배타적인 방식으로, 즉, 명시적으 로 설명되지 않는 아이템, 컴포넌트 또는 요소가 또한 존재하는 것을 허용하는 방식으로 해석되도록 의도된다. 단수에 대한 언급은 복수에 관련되는 것으로 또한 해석되어야 한다. 첨부된 청구범위에서 괄호 안에 포함되는 숫자는 청구범위의 이해를 돕도록 의도되며 이들 청구범위에 의해 청구되는 주제를 어떤 식으로든 제한하는 것으로 해석되어서는 안된다.도면 도면1 도면2a 도면2b 도면3"}
{"patent_id": "10-2021-7042120", "section": "도면", "subsection": "도면설명", "item": 1, "content": "상기의 개요 뿐만 아니라, 예시적인 실시형태의 다음의 상세한 설명은, 첨부의 도면과 연계하여 판독될 때 더 잘 이해된다. 본 개시를 예시하는 목적을 위해, 본 개시의 예시적인 구성이 도면에서 도시된다. 그러나, 본 개시는 본원에서 개시되는 특정한 방법 및 수단으로 제한되지는 않는다. 또한, 기술 분야의 사람들은 도면이 일정 비율이 아니다는 것을 이해할 것이다. 가능한 곳에서는 어디서든, 같은 요소는 동일한 번호에 의해 나타 내어졌다. 이제, 본 개시의 실시형태가, 단지 예로서, 다음의 도면을 참조하여 설명될 것인데, 도면에서: 도 1은 본 개시의 다양한 실시형태가 실시될 수 있는 환경을 예시한다; 도 2a 및 도 2b는 본 발명의 일 실시예에 따른, 적어도 하나의 이미지 내에서 대상체에 의해 수행되는 동작을 결정하기 위한 컨볼루션 신경망(CNN)을 예시한다; 도 3은 본 개시의 실시예에 따른, 적어도 하나의 이미지 내에서 대상체에 의해 수행되는 동작을 결정하는 방법 의 단계의 예시이다. 첨부의 도면에서, 밑줄이 그어진 숫자는, 밑줄이 그어진 숫자가 위에 위치되는 아이템 또는 밑줄이 그어진 숫자 가 인접하는 아이템을 나타내기 위해 활용된다. 밑줄이 그어지지 않은 번호는, 밑줄이 그어지지 않은 번호를 아이템에 연결하는 라인에 의해 식별되는 아이템에 관련된다. 숫자에 밑줄이 없고 관련된 화살표가 수반되는 경우, 밑줄이 그어지지 않은 숫자는, 화살표가 가리키고 있는 일반적인 아이템을 식별하기 위해 사용된다."}
