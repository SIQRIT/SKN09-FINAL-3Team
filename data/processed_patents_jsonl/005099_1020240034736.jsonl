{"patent_id": "10-2024-0034736", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0042635", "출원번호": "10-2024-0034736", "발명의 명칭": "관심 영역 기반 프레임 구성 및 부복호화 방법", "출원인": "한화비전 주식회사", "발명자": "임정은"}}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기계를 위한 영상 부호화를 수행하는 인코딩 장치에 있어서,하나 이상의 프레임을 포함하는 제1 비디오 영상을 입력 받아, 상기 제1 비디오 영상의 제1 프레임에 대한 관심영역을 선택하는 관심 영역 선택부 및상기 제1 프레임에 대한 관심 영역이 선택되는 것에 응답하여, 상기 제1 프레임에 포함된 적어도 하나의 관심영역들에 대한 위치 및/또는 크기를 재구성하는 패킹을 수행하는 패킹 수행부를 포함하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 패킹 수행부는 상기 제1 프레임 내 선택된 관심 영역이 차지하는 비중이 미리 정해진 임계 값보다 크거나같은 경우, 패킹을 수행하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 미리 정해진 임계 값은 상기 제1 비디오 영상의 크기에 따라 적응적으로 결정되는 것인, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 제1 프레임에 포함된 적어도 하나의 관심 영역들에 대한 패킹을 수행하기 전에, 상기적어도 하나의 관심 영역들의 크기를 정규화한 후 패킹을 수행하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 제1 프레임에 포함된 적어도 하나의 관심 영역들에 대한 패킹을 수행하기 전에, 상기적어도 하나의 관심 영역들 각각에 대한 변환을 수행하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 패킹 수행부는, 상기 적어도 하나의 관심 영역들 각각에 대한 회전 변환을 수행하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 제1 프레임에 연속하는 일련의 프레임 단위로 패킹을 수행하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 제1 프레임에 포함된 적어도 하나의 관심 영역들의 ID 인덱스 값이 작은 순서로, 상기 제1 프레임의 스캐닝 순서에 따라 패킹을 수행하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2025-0042635-3-제1항에 있어서,상기 패킹 수행부는, 상기 제1 프레임의 좌측 상단을 기준으로 상기 적어도 하나의 관심 영역들에 대한 위치 및/또는 크기를 재구성하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 제1 프레임 내 상기 적어도 하나의 관심 영역들이 위치하지 않는 영역은, 미리 정해진 값으로 패딩하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 제1 프레임에 포함된 적어도 하나의 관심 영역들의 ID 인덱스 값이 가작 작은 관심영역을 패킹한 후, 나머지 관심 영역들 중 상기 패킹된 관심 영역의 우측 경계와 가장 유사한 관심 영역을 순차로 패킹하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 관심 영역 간의 유사한 정도는, 두 관심 영역의 높이 중 작은 길이를 기준으로 해당 영역의 경계에 대해 n픽셀의 평균 값의 차분 값에 의해 결정되는, -상기 n은 1 이상의 정수- 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 적어도 하나의 관심 영역들을 포함하는 새로운 크기의 프레임을 생성하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서,상기 패킹 수행부는, 상기 적어도 하나의 관심 영역들이 속한 CTU (coding tree unit)의 인덱스 및 상기 CTU 내에서 관심 영역의 좌상단 좌표를 기준으로 위치 값 및 차분 값에 대한 정보를 시그널링하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 CTU의 크기는 상기 제1 비디오 영상 시퀀스에서 동일하거나, 또는 각 프레임 별로 동일하도록 하는, 인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서,상기 패킹 수행부는, 패킹을 수행한 후, 상기 적어도 하나의 관심 영역들 전체 또는 일부의 크기를 정규화하는,인코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "기계를 위한 영상 복호화를 수행하는 디코딩 장치에 있어서,비트스트림을 입력 받아 영상 복호화를 수행하는 내부 복호화 수행기; 및제1 비디오 영상에 대한 관심 영역 기반 처리 정보를 수신하는 것에 응답하여, 상기 복호화된 영상에 대한 언패킹을 수행하는 언패킹 수행부를 포함하고,공개특허 10-2025-0042635-4-상기 언패킹 수행부는 상기 관심 영역 기반 처리 정보에 기반하여 상기 복호화된 영상에 포함된 적어도 하나의관심 영역들에 대한 위치 및/또는 크기를 상기 제1 비디오 영상의 원본 값으로 복원하도록 하는, 디코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 언패킹 수행부는, 상기 관심 영역 기반 처리 정보에 포함된 상기 적어도 하나의 관심 영역들의 위치 정보에 따라 상기 적어도 하나의 관심 영역들을 언패킹하는, 디코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 제1 비디오 영상에 포함된 일련의 프레임 그룹 단위로 상기 적어도 하나의 관심 영역의 ID 별 위치 정보및 위치에 대한 차분 값 정보를 이용하여 상기 일련의 프레임 그룹을 언패킹하는, 디코딩 장치."}
{"patent_id": "10-2024-0034736", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "명령어들을 기록하고 있는 비휘발성(non-volatile) 컴퓨터 판독가능 저장 매체로서,상기 명령어들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금:하나 이상의 프레임을 포함하는 제1 비디오 영상을 입력 받아, 상기 제1 비디오 영상의 제1 프레임에 대한 관심영역을 선택하는 단계와; 상기 제1 프레임에 대한 관심 영역이 선택되는 것에 응답하여, 상기 제1 프레임에 포함된 적어도 하나의 관심영역들에 대한 위치 및/또는 크기를 재구성하는 패킹을 수행하는 단계를 수행하도록 하는, 비일시적 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2024-0034736", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 예시는 기계를 위한 영상 부호화(VCM)를 수행하는 인코딩 장치를 제시한다. 상기 인코딩 장치는, 하나 이상의 프레임을 포함하는 제1 비디오 영상을 입력 받아, 상기 제1 비디오 영상의 제1 프레임에 대한 관심 영역을 선택하는 관심 영역 선택부 및 상기 제1 프레임에 대한 관심 영역이 선택되는 것에 응답하여, 상기 제1 프레임에 포함된 적어도 하나의 관심 영역들에 대한 위치 및/또는 크기를 재구성하는 패킹을 수행하는 패킹 수행 부를 포함할 수 있다."}
{"patent_id": "10-2024-0034736", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 관심 영역 기반 프레임 구성 및 부복호화 방법에 관한 것이다."}
{"patent_id": "10-2024-0034736", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보 통신 산업의 지속적인 발달을 통해 HD(High Definition) 해상도를 가지는 방송 서비스가 세계적으로 확산 되었다. 이러한 확산을 통해, 많은 사용자들이 고해상도이며 고화질인 영상(image) 및/또는 비디오(video)에 익숙해지게 되었고, 보다 높은 화질, 즉 4K 또는 8K 이상의 UHD(Ultra High Definition) 영상/비디오와 같은 고해상도, 고 품질의 영상/비디오에 대한 수요가 다양한 분야에서 증가되었다. 이러한 UHD 영상데이터를 코딩하는 기술은 2013년 표준 기술인 HEVC(High Efficiency Video Coding)를 통해 완성되었다. HEVC는 이전의 H.264/AVC 기술보다 더 높은 압축률과 더 낮은 복잡도를 갖는 차세대 영상 압축 기술이며, HD급, UHD급 영상의 방대한 데이터를 효과적으로 압축하기 위한 핵심 기술이다. HEVC는 이전의 압축 표준들과 같이 블록 단위의 부호화를 수행한다. 다만, H.264/AVC와 달리 하나의 프로파일만 존재하는 차이점이 있다. HEVC의 유일한 프로파일에 포함된 핵심 부호화 기술은 총 8개 분야로 계층적 부호화 구조 기술, 변환 기술, 양자화 기술, 화면 내 예측 부호화 기술, 화면 간 움직임 예측 기술, 엔트로피 부호화 기술, 루프 필터 기술 및 기타 기술이 있다. 2013년 HEVC 비디오 코덱 제정 이후, 4K, 8K를 비디오 영상을 이용한 실감 영상 및 가상 현실 서비스 등이 확대 됨에 따라 HEVC 대비 2배 이상 성능 개선을 목표로 하는 차세대 비디오 코덱인, 다용도 비디오 부호화(VVC: Versatile Video Coding) 표준이 개발되었다. VVC는 H.266으로 불린다. H.266(VVC)은 이전 세대 코덱인 H.265(HEVC)보다 2배 이상의 효율을 목표로 개발되었다. VVC는 처음에는 4K 이 상의 해상도를 감안하고 개발되었으나 점점 VR 시장의 확장으로 인한 360도 영상을 대응할 목적으로 무려 16K 수준의 초고해상도 영상처리용으로도 개발되었다. 또한 점차 디스플레이 기술의 발달로 HDR 시장이 확대됨에 따 라 이에 대응하기 위해 10비트 색심도는 물론이고 16비트 색심도를 지원하며 1000니트, 4000니트, 10000니트의 밝기 표현을 지원한다. 또한 VR시장과 360도 영상시장을 염두하여 개발되고 있기에 0~120 FPS 범위의 부분 프레 임 속도를 지원한다. <인공 지능의 발전> 인공지능(artificial intelligence: AI)도 점차 발전하고 있다. AI는 인간의 지능, 즉 인식(Recognition), 분 류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정(Control/Decision making) 등을 할 수 있는 지능을 인공적으로 모방하는 것을 의미한다. 인공 지능 기술의 발전 및 사물인터넷(Internet Of Things; IOT) 기기의 증가로 인해 기계 간 트래픽이 폭증할 것으로 예측되고, 기계(machine)에 의존하는 영상 분석이 널리 사용될 것으로 예측되고 있다. 그러나, 기계에 의해 분석되어야 할 영상이 기하급수적으로 증가될 것으로 예상됨에 따라, 서버의 부하 및 전력 소모 문제가 제기될 것으로 예측된다."}
{"patent_id": "10-2024-0034736", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 개시는 기계에 의한 영상 분석을 효과적으로 수행할 수 있도록 하기 위하여, 관심 영역 기반 프레임 구성 및 부복호화 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2024-0034736", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위하여, 본 명세서의 일 개시에 따르면, 기계를 위한 영상 부호화를 수행하는 인코딩 장치가 제공된다. 기계를 위한 영상 부호화를 수행하는 인코딩 장치는, 하나 이상의 프레임을 포함하는 제1 비디오 영상을 입력 받아, 상기 제1 비디오 영상의 제1 프레임에 대한 관심 영역을 선택하는 관심 영역 선택부 및 상기 제1 프레임 에 대한 관심 영역이 선택되는 것에 응답하여, 상기 제1 프레임에 포함된 적어도 하나의 관심 영역들에 대한 위 치 및/또는 크기를 재구성하는 패킹을 수행하는 패킹 수행부를 포함할 수 있다. 본 명세서의 일 개시에 따르면, 기계를 위한 영상 복호화를 수행하는 디코딩 장치는, 비트스트림을 입력 받아 영상 복호화를 수행하는 내부 복호화 수행기; 및 제1 비디오 영상에 대한 관심 영역 기반 처리 정보를 수신하는 것에 응답하여, 상기 복호화된 영상에 대한 언패킹을 수행하는 언패킹 수행부를 포함하고, 상기 언패킹 수행부 는 상기 관심 영역 기반 처리 정보에 기반하여 상기 복호화된 영상에 포함된 적어도 하나의 관심 영역들에 대한 위치 및/또는 크기를 상기 제1 비디오 영상의 원본 값으로 복원하도록 할 수 있다. 본 명세서의 일 개시에 따르면, 명령어들을 기록하고 있는 비휘발성(non-volatile) 컴퓨터 판독가능 저장 매체 로서, 상기 명령어들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금: 하 나 이상의 프레임을 포함하는 제1 비디오 영상을 입력 받아, 상기 제1 비디오 영상의 제1 프레임에 대한 관심 영역을 선택하는 단계와; 상기 제1 프레임에 대한 관심 영역이 선택되는 것에 응답하여, 상기 제1 프레임에 포 함된 적어도 하나의 관심 영역들에 대한 위치 및/또는 크기를 재구성하는 패킹을 수행하는 단계를 수행하도록 할 수 있다."}
{"patent_id": "10-2024-0034736", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 의하면, 기계에 의한 영상 분석을 효과적으로 수행할 수 있다."}
{"patent_id": "10-2024-0034736", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것으로, 본 개시의 개념에 따 른 실시 예들은 다양한 형태로 실시될 수 있으며 본 개시의 개념에 따른 실시 예들은 다양한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있으므로 특정 실시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따 른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 실시 예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더 욱 명확히 전달하기 위함이다. 이 문서는 비디오/영상 코딩에 관한 것이다. 예를 들어 이 문서에서 개시된 방법/실시예는 VVC (Versatile Video Coding) 표준 (ITU-T Rec. H.266), VVC 이후의 차세대 비디오/이미지 코딩 표준, 또는 그 이외의 비디오 코딩 관련 표준들(예를 들어, HEVC (High Efficiency Video Coding) 표준 (ITU-T Rec. H.265), EVC(essential video coding) 표준, AVS2 표준 등)과 관련될 수 있다. 이 문서에서는 비디오/영상 코딩에 관한 다양한 실시예들을 제시하며, 다른 언급이 없는 한 상기 실시예들은 서 로 조합되어 수행될 수도 있다. 이 문서에서 비디오(video)는 시간의 흐름에 따른 일련의 영상(image)들의 집합을 의미할 수 있다. 픽처 (picture)는 일반적으로 특정 시간대의 하나의 영상을 나타내는 단위를 의미하며, 슬라이스(slice)/타일(tile) 는 코딩에 있어서 픽처의 일부를 구성하는 단위이다. 슬라이스/타일은 하나 이상의 CTU(coding tree unit)을 포 함할 수 있다. 하나의 픽처는 하나 이상의 슬라이스/타일로 구성될 수 있다. 하나의 픽처는 하나 이상의 타일 그룹으로 구성될 수 있다. 하나의 타일 그룹은 하나 이상의 타일들을 포함할 수 있다. 픽셀(pixel) 또는 펠(pel)은 하나의 픽처(또는 영상)을 구성하는 최소의 단위를 의미할 수 있다. 또한, 픽셀에 대응하는 용어로서 '샘플(sample)'이 사용될 수 있다. 샘플은 일반적으로 픽셀 또는 픽셀의 값을 나타낼 수 있 으며, 루마(luma) 성분의 픽셀/픽셀값만을 나타낼 수도 있고, 크로마(chroma) 성분의 픽셀/픽셀 값만을 나타낼 수도 있다. 또는 샘플은 공간 도메인에서의 픽셀값을 의미할 수도 있고, 이러한 픽셀값이 주파수 도메인으로 변 환되면 주파수 도메인에서의 변환 계수를 의미할 수도 있다. 유닛(unit)은 영상 처리의 기본 단위를 나타낼 수 있다. 유닛은 픽처의 특정 영역 및 해당 영역에 관련된 정보 중 적어도 하나를 포함할 수 있다. 하나의 유닛은 하나의 루마 블록 및 두개의 크로마(ex. cb, cr) 블록을 포함 할 수 있다. 유닛은 경우에 따라서 블록(block) 또는 영역(area) 등의 용어와 혼용하여 사용될 수 있다. 일반적 인 경우, MxN 블록은 M개의 열과 N개의 행으로 이루어진 샘플들(또는 샘플 어레이) 또는 변환 계수(transform coefficient)들의 집합(또는 어레이)을 포함할 수 있다. 도 1은 비디오/영상 코딩 시스템의 예를 개략적으로 나타낸다. 도 1을 참조하면, 비디오/영상 코딩 시스템은 소스 디바이스(source device) 및 수신 디바이스(receive devic e)를 포함할 수 있다. 소스 디바이스는 인코딩된 비디오(video)/영상(image) 정보 또는 데이터를 파일 또는 스 트리밍 형태로 디지털 저장매체 또는 네트워크를 통하여 수신 디바이스로 전달할 수 있다. 상기 소스 디바이스는 비디오 소스(video source), 인코딩 장치(encoding apparatus), 전송부(transmitter)를 포함할 수 있다. 상기 수신 디바이스는 수신부(receiver), 디코딩 장치(decoding apparatus) 및 렌더러 (renderer)를 포함할 수 있다. 상기 인코딩 장치는 비디오/영상 인코딩 장치라고 불릴 수 있고, 상기 디코딩 장 치는 비디오/영상 디코딩 장치라고 불릴 수 있다. 송신기는 인코딩 장치에 포함될 수 있다. 수신기는 디코딩 장 치에 포함될 수 있다. 렌더러는 디스플레이부를 포함할 수도 있고, 디스플레이부는 별개의 디바이스 또는 외부 컴포넌트로 구성될 수도 있다. 비디오 소스는 비디오/영상의 캡쳐, 합성 또는 생성 과정 등을 통하여 비디오/영상을 획득할 수 있다. 비디오 소스는 비디오/영상 캡쳐 디바이스 및/또는 비디오/영상 생성 디바이스를 포함할 수 있다. 비디오/영상 캡쳐 디 바이스는 예를 들어, 하나 이상의 카메라, 이전에 캡쳐된 비디오/영상을 포함하는 비디오/영상 아카이브 등을 포함할 수 있다. 비디오/영상 생성 디바이스는 예를 들어 컴퓨터, 타블렛 및 스마트폰 등을 포함할 수 있으며 (전자적으로) 비디오/영상을 생성할 수 있다. 예를 들어, 컴퓨터 등을 통하여 가상의 비디오/영상이 생성될 수 있으며, 이 경우 관련 데이터가 생성되는 과정으로 비디오/영상 캡쳐 과정이 갈음될 수 있다. 인코딩 장치는 입력 비디오/영상을 인코딩할 수 있다. 인코딩 장치는 압축 및 코딩 효율을 위하여 예측, 변환, 양자화 등 일련의 절차를 수행할 수 있다. 인코딩된 데이터(인코딩된 비디오/영상 정보)는 비트스트림(bitstream) 형태로 출력될 수 있다. 전송부는 비트스트림 형태로 출력된 인코딩된 비디오/영상 정보 또는 데이터를 파일 또는 스트리밍 형태로 디지 털 저장매체 또는 네트워크를 통하여 수신 디바이스의 수신부로 전달할 수 있다. 디지털 저장 매체는 USB, SD, CD, DVD, 블루레이, HDD, SSD 등 다양한 저장 매체를 포함할 수 있다. 전송부는 미리 정해진 파일 포맷을 통하 여 미디어 파일을 생성하기 위한 엘리먼트를 포함할 수 있고, 방송/통신 네트워크를 통한 전송을 위한 엘리먼트 를 포함할 수 있다. 수신부는 상기 비트스트림을 수신/추출하여 디코딩 장치로 전달할 수 있다. 디코딩 장치는 인코딩 장치의 동작에 대응하는 역양자화, 역변환, 예측 등 일련의 절차를 수행하여 비디오/영상 을 디코딩할 수 있다. 렌더러는 디코딩된 비디오/영상을 렌더링할 수 있다. 렌더링된 비디오/영상은 디스플레이부를 통하여 디스플레 이될 수 있다. 도 2는 비디오/영상 인코딩 장치의 구성을 개략적으로 설명하는 도면이다. 이하 비디오 인코딩 장치라 함은 영상 인코딩 장치를 포함할 수 있다. 도 2를 참조하면, 인코딩 장치(10a)는 영상 분할부(image partitioner, 10a-10), 예측부(predictor, 10a-20), 레지듀얼 처리부(residual processor, 10a-30), 엔트로피 인코딩부(entropy encoder, 10a-40), 가산부(adder, 10a-50), 필터링부(filter, 10a-60) 및 메모리(memory, 10a-70)를 포함하여 구성될 수 있다. 예측부(10a-20)는 인터 예측부(10a-21) 및 인트라 예측부(10a-22)를 포함할 수 있다. 레지듀얼 처리부(10a-30)는 변환부 (transformer, 10a-32), 양자화부(quantizer 10a-33), 역양자화부(dequantizer 10a-34), 역변환부(inverse transformer, 10a-35)를 포함할 수 있다. 레지듀얼 처리부(10a-30)는 감산부(subtractor, 10a-31)를 더 포함할 수 있다. 가산부(10a-50)는 복원부(reconstructor) 또는 복원 블록 생성부(reconstructed block generator)로 불릴 수 있다. 상술한 영상 분할부(10a-10), 예측부(10a-20), 레지듀얼 처리부(10a-30), 엔트로피 인코딩부 (10a-40), 가산부(10a-50) 및 필터링부(10a-60)는 실시예에 따라 하나 이상의 하드웨어 컴포넌트(예를 들어 인 코더 칩셋 또는 프로세서)에 의하여 구성될 수 있다. 또한 메모리(10a-70)는 DPB(decoded picture buffer)를 포함할 수 있고, 디지털 저장 매체에 의하여 구성될 수도 있다. 상기 하드웨어 컴포넌트는 메모리(10a-70)를 내 /외부 컴포넌트로 더 포함할 수도 있다. 영상 분할부(10a-10)는 인코딩 장치(10a)에 입력된 입력 영상(또는, 픽처, 프레임)를 하나 이상의 처리 유닛 (processing unit)으로 분할할 수 있다. 일 예로, 상기 처리 유닛은 코딩 유닛(coding unit, CU)이라고 불릴 수 있다. 이 경우 코딩 유닛은 코딩 트리 유닛(coding tree unit, CTU) 또는 최대 코딩 유닛(largest coding unit, LCU)으로부터 QTBTTT (Quad-tree binary-tree ternary-tree) 구조에 따라 재귀적으로(recursively) 분할 될 수 있다. 예를 들어, 하나의 코딩 유닛은 쿼드 트리 구조, 바이너리 트리 구조, 및/또는 터너리 구조를 기반 으로 하위(deeper) 뎁스의 복수의 코딩 유닛들로 분할될 수 있다. 이 경우 예를 들어 쿼드 트리 구조가 먼저 적 용되고 바이너리 트리 구조 및/또는 터너리 구조가 나중에 적용될 수 있다. 또는 바이너리 트리 구조가 먼저 적 용될 수도 있다. 더 이상 분할되지 않는 최종 코딩 유닛을 기반으로 본 문서에 따른 코딩 절차가 수행될 수 있 다. 이 경우 영상 특성에 따른 코딩 효율 등을 기반으로, 최대 코딩 유닛이 바로 최종 코딩 유닛으로 사용될 수 있고, 또는 필요에 따라 코딩 유닛은 재귀적으로(recursively) 보다 하위 뎁스의 코딩 유닛들로 분할되어 최적 의 사이즈의 코딩 유닛이 최종 코딩 유닛으로 사용될 수 있다. 여기서 코딩 절차라 함은 후술하는 예측, 변환, 및 복원 등의 절차를 포함할 수 있다. 다른 예로, 상기 처리 유닛은 예측 유닛(PU: Prediction Unit) 또는 변환 유닛(TU: Transform Unit)을 더 포함할 수 있다. 이 경우 상기 예측 유닛 및 상기 변환 유닛은 각각 상술한 최 종 코딩 유닛으로부터 분할 또는 파티셔닝될 수 있다. 상기 예측 유닛은 샘플 예측의 단위일 수 있고, 상기 변 환 유닛은 변환 계수를 유도하는 단위 및/또는 변환 계수로부터 레지듀얼 신호(residual signal)를 유도하는 단 위일 수 있다. 유닛은 경우에 따라서 블록(block) 또는 영역(area) 등의 용어와 혼용하여 사용될 수 있다. 일반적인 경우, MxN 블록은 M개의 열과 N개의 행으로 이루어진 샘플들 또는 변환 계수(transform coefficient)들의 집합을 나타낼 수 있다. 샘플은 일반적으로 픽셀 또는 픽셀의 값을 나타낼 수 있으며, 휘도(luma) 성분의 픽셀/픽셀값만을 나 타낼 수도 있고, 채도(chroma) 성분의 픽셀/픽셀 값만을 나타낼 수도 있다. 샘플은 하나의 픽처(또는 영상)을 픽셀(pixel) 또는 펠(pel)에 대응하는 용어로서 사용될 수 있다. 감산부(10a-31)는 입력 영상 신호(원본 블록, 원본 샘플들 또는 원본 샘플 어레이)에서 예측부(10a-20)로부터 출력된 예측 신호(예측된 블록, 예측 샘플들 또는 예측 샘플 어레이)를 감산하여 레지듀얼 신호(레지듀얼 블록,레지듀얼 샘플들 또는 레지듀얼 샘플 어레이)를 생성할 수 있고, 생성된 레지듀얼 신호는 변환부(10a-32)로 전 송된다. 예측부(10a-20)는 처리 대상 블록(이하, 현재 블록이라 함)에 대한 예측을 수행하고, 상기 현재 블록에 대한 예측 샘플들을 포함하는 예측된 블록(predicted block)을 생성할 수 있다. 예측부(10a-20)는 현재 블록 또 는 CU 단위로 인트라 예측이 적용되는지 또는 인터 예측이 적용되는지 결정할 수 있다. 예측부는 각 예측모드에 대한 설명에서 후술하는 바와 같이 예측 모드 정보 등 예측에 관한 다양한 정보를 생성하여 엔트로피 인코딩부 (10a-40)로 전달할 수 있다. 예측에 관한 정보는 엔트로피 인코딩부(10a-40)에서 인코딩되어 비트스트림 형태로 출력될 수 있다. 인트라 예측부(10a-22)는 현재 픽처 내의 샘플들을 참조하여 현재 블록을 예측할 수 있다. 상기 참조되는 샘플 들은 예측 모드에 따라 상기 현재 블록의 주변(neighbor)에 위치할 수 있고, 또는 떨어져서 위치할 수도 있다. 인트라 예측에서 예측 모드들은 복수의 비방향성 모드와 복수의 방향성 모드를 포함할 수 있다. 비방향성 모드 는 예를 들어 DC 모드 및 플래너 모드(Planar 모드)를 포함할 수 있다. 방향성 모드는 예측 방향의 세밀한 정도 에 따라 예를 들어 33개의 방향성 예측 모드 또는 65개의 방향성 예측 모드를 포함할 수 있다. 다만, 이는 예시 로서 설정에 따라 그 이상 또는 그 이하의 개수의 방향성 예측 모드들이 사용될 수 있다. 인트라 예측부(10a- 22)는 주변 블록에 적용된 예측 모드를 이용하여, 현재 블록에 적용되는 예측 모드를 결정할 수도 있다. 인터 예측부(10a-21)는 참조 픽처 상에서 움직임 벡터에 의해 특정되는 참조 블록(참조 샘플 어레이)을 기반으 로, 현재 블록에 대한 예측된 블록을 유도할 수 있다. 이때, 인터 예측 모드에서 전송되는 움직임 정보의 양을 줄이기 위해 주변 블록과 현재 블록 간의 움직임 정보의 상관성에 기초하여 움직임 정보를 블록, 서브블록 또는 샘플 단위로 예측할 수 있다. 상기 움직임 정보는 움직임 벡터 및 참조 픽처 인덱스를 포함할 수 있다. 상기 움 직임 정보는 인터 예측 방향(L0 예측, L1 예측, Bi 예측 등) 정보를 더 포함할 수 있다. 인터 예측의 경우에, 주변 블록은 현재 픽처 내에 존재하는 공간적 주변 블록(spatial neighboring block)과 참조 픽처에 존재하는 시간적 주변 블록(temporal neighboring block)을 포함할 수 있다. 상기 참조 블록을 포함하는 참조 픽처와 상 기 시간적 주변 블록을 포함하는 참조 픽처는 동일할 수도 있고, 다를 수도 있다. 상기 시간적 주변 블록은 동 일 위치 참조 블록(collocated reference block), 동일 위치 CU(colCU) 등의 이름으로 불릴 수 있으며, 상기 시간적 주변 블록을 포함하는 참조 픽처는 동일 위치 픽처(collocated picture, colPic)라고 불릴 수도 있다. 예를 들어, 인터 예측부(10a-21)는 주변 블록들을 기반으로 움직임 정보 후보 리스트를 구성하고, 상기 현재 블 록의 움직임 벡터 및/또는 참조 픽처 인덱스를 도출하기 위하여 어떤 후보가 사용되는지를 지시하는 정보를 생 성할 수 있다. 다양한 예측 모드를 기반으로 인터 예측이 수행될 수 있으며, 예를 들어 스킵 모드와 머지 모드 의 경우에, 인터 예측부(10a-21)는 주변 블록의 움직임 정보를 현재 블록의 움직임 정보로 이용할 수 있다. 스 킵 모드의 경우, 머지 모드와 달리 레지듀얼 신호가 전송되지 않을 수 있다. 움직임 정보 예측(motion vector prediction, MVP) 모드의 경우, 주변 블록의 움직임 벡터를 움직임 벡터 예측자(motion vector predictor)로 이용하고, 움직임 벡터 차분(motion vector difference)을 시그널링함으로써 현재 블록의 움직임 벡터를 지시할 수 있다. 예측부(10a-20)는 후술하는 다양한 예측 방법을 기반으로 예측 신호를 생성할 수 있다. 예를 들어, 예측부는 하 나의 블록에 대한 예측을 위하여 인트라 예측 또는 인터 예측을 적용할 수 있을 뿐 아니라, 인트라 예측과 인터 예측을 동시에 적용할 수 있다. 이는 combined inter and intra prediction (CIIP)라고 불릴 수 있다. 또한, 예측부는 블록에 대한 예측을 위하여 인트라 블록 카피(intra block copy, IBC)를 수행할 수도 있다. 상기 인트 라 블록 카피는 예를 들어 SCC(screen content coding) 등과 같이 게임 등의 컨텐츠 영상/동영상 코딩을 위하여 사용될 수 있다. IBC는 기본적으로 현재 픽처 내에서 예측을 수행하나 현재 픽처 내에서 참조 블록을 도출하는 점에서 인터 예측과 유사하게 수행될 수 있다. 즉, IBC는 본 문서에서 설명되는 인터 예측 기법들 중 적어도 하 나를 이용할 수 있다. 인터 예측부(10a-21) 및/또는 인트라 예측부(10a-22)를 통해 생성된 예측 신호는 복원 신호를 생성하기 위해 이 용되거나 레지듀얼 신호를 생성하기 위해 이용될 수 있다. 변환부(10a-32)는 레지듀얼 신호에 변환 기법을 적용 하여 변환 계수들(transform coefficients)를 생성할 수 있다. 예를 들어, 변환 기법은 DCT(Discrete Cosine Transform), DST(Discrete Sine Transform), GBT(Graph-Based Transform), 또는 CNT(Conditionally Non- linear Transform) 등을 포함할 수 있다. 여기서, GBT는 픽셀 간의 관계 정보를 그래프로 표현한다고 할 때 이 그래프로부터 얻어진 변환을 의미한다. CNT는 이전에 복원된 모든 픽셀(all previously reconstructed pixel) 를 이용하여 예측 신호를 생성하고 그에 기초하여 획득되는 변환을 의미한다. 또한, 변환 과정은 정사각형의 동 일한 크기를 갖는 픽셀 블록에 적용될 수도 있고, 정사각형이 아닌 가변 크기의 블록에도 적용될 수 있다. 양자화부(10a-33)는 변환 계수들을 양자화하여 엔트로피 인코딩부(10a-40)로 전송되고, 엔트로피 인코딩부(10a- 40)는 양자화된 신호(양자화된 변환 계수들에 관한 정보)를 인코딩하여 비트스트림으로 출력할 수 있다. 상기 양자화된 변환 계수들에 관한 정보는 레지듀얼 정보라고 불릴 수 있다. 양자화부(10a-33)는 계수 스캔 순서 (scan order)를 기반으로 블록 형태의 양자화된 변환 계수들을 1차원 벡터 형태로 재정렬할 수 있고, 상기 1차 원 벡터 형태의 양자화된 변환 계수들을 기반으로 상기 양자화된 변환 계수들에 관한 정보를 생성할 수도 있다. 엔트로피 인코딩부(10a-40)는 예를 들어 지수 골롬(exponential Golomb), CAVLC(context-adaptive variable length coding), CABAC(context-adaptive binary arithmetic coding) 등과 같은 다양한 인코딩 방법을 수행할 수 있다. 엔트로피 인코딩부(10a-40)는 양자화된 변환 계수들 외 비디오/이미지 복원에 필요한 정보들(예컨대 신택스 요 소들(syntax elements)의 값 등)을 함께 또는 별도로 인코딩할 수도 있다. 인코딩된 정보(ex. 인코딩된 비디오/ 영상 정보)는 비트스트림 형태로 NAL(network abstraction layer) 유닛 단위로 전송 또는 저장될 수 있다. 상기 비디오/영상 정보는 어댑테이션 파라미터 세트(APS), 픽처 파라미터 세트(PPS), 시퀀스 파라미터 세트(SPS) 또 는 비디오 파라미터 세트(VPS) 등 다양한 파라미터 세트에 관한 정보를 더 포함할 수 있다. 또한 상기 비디오/ 영상 정보는 일반 제한 정보(general constraint information)을 더 포함할 수 있다. 본 문서에서 후술되는 시 그널링/전송되는 정보 및/또는 신택스 요소들은 상술한 인코딩 절차를 통하여 인코딩되어 상기 비트스트림에 포 함될 수 있다. 상기 비트스트림은 네트워크를 통하여 전송될 수 있고, 또는 디지털 저장매체에 저장될 수 있다. 여기서 네트워크는 방송망 및/또는 통신망 등을 포함할 수 있고, 디지털 저장매체는 USB, SD, CD, DVD, 블루레 이, HDD, SSD 등 다양한 저장매체를 포함할 수 있다. 엔트로피 인코딩부(10a-40)로부터 출력된 신호는 전송하는 전송부(미도시) 및/또는 저장하는 저장부(미도시)가 인코딩 장치(10a)의 내/외부 엘리먼트로서 구성될 수 있고, 또는 전송부는 엔트로피 인코딩부(10a-40)에 포함될 수도 있다. 양자화부(10a-33)로부터 출력된 양자화된 변환 계수들은 예측 신호를 생성하기 위해 이용될 수 있다. 예를 들어, 양자화된 변환 계수들에 역양자화부(10a-34) 및 역변환부(10a-35)를 통해 역양자화 및 역변환을 적용함으 로써 레지듀얼 신호(레지듀얼 블록 or 레지듀얼 샘플들)를 복원할 수 있다. 가산부(10a-50)는 복원된 레지듀얼 신호를 예측부(10a-20)로부터 출력된 예측 신호에 더함으로써 복원(reconstructed) 신호(복원 픽처, 복원 블록, 복원 샘플들 또는 복원 샘플 어레이)가 생성될 수 있다. 스킵 모드가 적용된 경우와 같이 처리 대상 블록에 대 한 레지듀얼이 없는 경우, 예측된 블록이 복원 블록으로 사용될 수 있다. 생성된 복원 신호는 현재 픽처 내 다 음 처리 대상 블록의 인트라 예측을 위하여 사용될 수 있고, 후술하는 바와 같이 필터링을 거쳐서 다음 픽처의 인터 예측을 위하여 사용될 수도 있다. 한편 픽처 인코딩 및/또는 복원 과정에서 LMCS (luma mapping with chroma scaling)가 적용될 수도 있다. 필터링부(10a-60)는 복원 신호에 필터링을 적용하여 주관적/객관적 화질을 향상시킬 수 있다. 예를 들어 필터링 부(10a-60)는 복원 픽처에 다양한 필터링 방법을 적용하여 수정된(modified) 복원 픽처를 생성할 수 있고, 상기 수정된 복원 픽처를 메모리(10a-70), 구체적으로 메모리(10a-70)의 DPB에 저장할 수 있다. 상기 다양한 필터링 방법은 예를 들어, 디블록킹 필터링, 샘플 적응적 오프셋(sample adaptive offset, SAO), 적응적 루프 필터 (adaptive loop filter), 양방향 필터(bilateral filter) 등을 포함할 수 있다. 필터링부(10a-60)는 각 필터링 방법에 대한 설명에서 후술하는 바와 같이 필터링에 관한 다양한 정보를 생성하여 엔트로피 인코딩부(10a-90)로 전달할 수 있다. 필터링 관한 정보는 엔트로피 인코딩부(10a-90)에서 인코딩되어 비트스트림 형태로 출력될 수 있다. 메모리(10a-70)에 전송된 수정된 복원 픽처는 인터 예측부(10a-80)에서 참조 픽처로 사용될 수 있다. 인코딩 장 치는 이를 통하여 인터 예측이 적용되는 경우, 인코딩 장치(10a)와 디코딩 장치에서의 예측 미스매치를 피할 수 있고, 부호화 효율도 향상시킬 수 있다. 메모리(10a-70)의 DPB는 수정된 복원 픽처를 인터 예측부(10a-21)에서의 참조 픽처로 사용하기 위해 저장할 수 있다. 메모리(10a-70)는 현재 픽처 내 움직임 정보가 도출된(또는 인코딩된) 블록의 움직임 정보 및/또는 이미 복원된 픽처 내 블록들의 움직임 정보를 저장할 수 있다. 상기 저장된 움직임 정보는 공간적 주변 블록의 움직 임 정보 또는 시간적 주변 블록의 움직임 정보로 활용하기 위하여 인터 예측부(10a-21)에 전달할 수 있다. 메모 리(10a-70)는 현재 픽처 내 복원된 블록들의 복원 샘플들을 저장할 수 있고, 인트라 예측부(10a-22)에 전달할 수 있다. 도 3은 비디오/영상 디코딩 장치의 구성을 개략적으로 설명하는 도면이다. 도 3을 참조하면, 디코딩 장치(10b)는 엔트로피 디코딩부(entropy decoder, 10b-10), 레지듀얼 처리부 (residual processor, 10b-20), 예측부(predictor, 10b-30), 가산부(adder, 10b-40), 필터링부(filter, 10b- 50) 및 메모리(memory, 10b-60)를 포함하여 구성될 수 있다. 예측부(10b-30)는 인터 예측부(10b-31) 및 인트라 예측부(10b-32)를 포함할 수 있다. 레지듀얼 처리부(10b-20)는 역양자화부(dequantizer, 10b-21) 및 역변환부 (inverse transformer, 10b-21)를 포함할 수 있다. 상술한 엔트로피 디코딩부(10b-10), 레지듀얼 처리부(10b- 20), 예측부(10b-30), 가산부(10b-40) 및 필터링부(10b-50)는 실시예에 따라 하나의 하드웨어 컴포넌트(예를 들 어 디코더 칩셋 또는 프로세서)에 의하여 구성될 수 있다. 또한 메모리(10b-60)는 DPB(decoded picture buffer)를 포함할 수 있고, 디지털 저장 매체에 의하여 구성될 수도 있다. 상기 하드웨어 컴포넌트는 메모리 (10b-60)을 내/외부 컴포넌트로 더 포함할 수도 있다. 비디오/영상 정보를 포함하는 비트스트림이 입력되면, 디코딩 장치(10b)는 도 2의 인코딩 장치에서 비디오/영상 정보가 처리된 프로세스에 대응하여 영상을 복원할 수 있다. 예를 들어, 디코딩 장치(10b)는 상기 비트스트림으 로부터 획득한 블록 분할 관련 정보를 기반으로 유닛들/블록들을 도출할 수 있다. 디코딩 장치(10b)는 인코딩 장치에서 적용된 처리 유닛을 이용하여 디코딩을 수행할 수 있다. 따라서 디코딩의 처리 유닛은 예를 들어 코딩 유닛일 수 있고, 코딩 유닛은 코딩 트리 유닛 또는 최대 코딩 유닛으로부터 쿼드 트리 구조, 바이너리 트리 구 조 및/또는 터너리 트리 구조를 따라서 분할될 수 있다. 코딩 유닛으로부터 하나 이상의 변환 유닛이 도출될 수 있다. 그리고, 디코딩 장치(10b)를 통해 디코딩 및 출력된 복원 영상 신호는 재생 장치를 통해 재생될 수 있다. 디코딩 장치(10b)는 도 2의 인코딩 장치로부터 출력된 신호를 비트스트림 형태로 수신할 수 있고, 수신된 신호 는 엔트로피 디코딩부(10b-10)를 통해 디코딩될 수 있다. 예를 들어, 엔트로피 디코딩부(10b-10)는 상기 비트스 트림을 파싱하여 영상 복원(또는 픽처 복원)에 필요한 정보(ex. 비디오/영상 정보)를 도출할 수 있다. 상기 비 디오/영상 정보는 어댑테이션 파라미터 세트(APS), 픽처 파라미터 세트(PPS), 시퀀스 파라미터 세트(SPS) 또는 비디오 파라미터 세트(VPS) 등 다양한 파라미터 세트에 관한 정보를 더 포함할 수 있다. 또한 상기 비디오/영상 정보는 일반 제한 정보(general constraint information)을 더 포함할 수 있다. 디코딩 장치는 상기 파라미터 세트에 관한 정보 및/또는 상기 일반 제한 정보를 더 기반으로 픽처를 디코딩할 수 있다. 본 문서에서 후술되는 시그널링/수신되는 정보 및/또는 신택스 요소들은 상기 디코딩 절차를 통하여 디코딩되어 상기 비트스트림으로부터 획득될 수 있다. 예컨대, 엔트로피 디코딩부(10b-10)는 지수 골롬 부호화, CAVLC 또는 CABAC 등의 코딩 방법을 기초로 비트스트림 내 정보를 디코딩하고, 영상 복원에 필요한 신택스 엘리 먼트의 값, 레지듀얼에 관한 변환 계수의 양자화된 값 들을 출력할 수 있다. 보다 상세하게, CABAC 엔트로피 디 코딩 방법은, 비트스트림에서 각 구문 요소에 해당하는 빈을 수신하고, 디코딩 대상 구문 요소 정보와 주변 및 디코딩 대상 블록의 디코딩 정보 혹은 이전 단계에서 디코딩된 심볼/빈의 정보를 이용하여 문맥(context) 모델 을 결정하고, 결정된 문맥 모델에 따라 빈(bin)의 발생 확률을 예측하여 빈의 산술 디코딩(arithmetic decoding)를 수행하여 각 구문 요소의 값에 해당하는 심볼을 생성할 수 있다. 이때, CABAC 엔트로피 디코딩 방 법은 문맥 모델 결정 후 다음 심볼/빈의 문맥 모델을 위해 디코딩된 심볼/빈의 정보를 이용하여 문맥 모델을 업 데이트할 수 있다. 엔트로피 디코딩부(10b-10)에서 디코딩된 정보 중 예측에 관한 정보는 예측부(10b-30)로 제 공되고, 엔트로피 디코딩부(10b-10)에서 엔트로피 디코딩이 수행된 레지듀얼에 대한 정보, 즉 양자화된 변환 계 수들 및 관련 파라미터 정보는 역양자화부(10b-21)로 입력될 수 있다. 또한, 엔트로피 디코딩부(10b-10)에서 디코딩된 정보 중 필터링에 관한 정보는 필터링부(10b-50)으로 제공될 수 있다. 한편, 인코딩 장치로부터 출력된 신호를 수신하는 수신부(미도시)가 디코딩 장치(10b)의 내/외부 엘리먼 트로서 더 구성될 수 있고, 또는 수신부는 엔트로피 디코딩부(10b-10)의 구성요소일 수도 있다. 한편, 본 문서 에 따른 디코딩 장치는 비디오/영상/픽처 디코딩 장치라고 불릴 수 있고, 상기 디코딩 장치는 정보 디코더(비디 오/영상/픽처 정보 디코더) 및 샘플 디코더(비디오/영상/픽처 샘플 디코더)로 구분할 수도 있다. 상기 정보 디 코더는 상기 엔트로피 디코딩부(10b-10)를 포함할 수 있고, 상기 샘플 디코더는 상기 역양자화부(10b-21), 역변 환부(10b-22), 예측부(10b-30), 가산부(10b-40), 필터링부(10b-50) 및 메모리(10b-60) 중 적어도 하나를 포함 할 수 있다. 역양자화부(10b-21)에서는 양자화된 변환 계수들을 역양자화하여 변환 계수들을 출력할 수 있다. 역양자화부 (10b-21)는 양자화된 변환 계수들을 2차원의 블록 형태로 재정렬할 수 있다. 이 경우 상기 재정렬은 인코딩 장 치에서 수행된 계수 스캔 순서를 기반하여 재정렬을 수행할 수 있다. 역양자화부(10b-21)는 양자화 파라미터(예 를 들어 양자화 스텝 사이즈 정보)를 이용하여 양자화된 변환 계수들에 대한 역양자화를 수행하고, 변환 계수들 (transform coefficient)를 획득할 수 있다. 역변환부(10b-22)에서는 변환 계수들를 역변환하여 레지듀얼 신호(레지듀얼 블록, 레지듀얼 샘플 어레이)를 획 득하게 된다. 예측부는 현재 블록에 대한 예측을 수행하고, 상기 현재 블록에 대한 예측 샘플들을 포함하는 예측된 블록 (predicted block)을 생성할 수 있다. 예측부는 엔트로피 디코딩부(10b-10)로부터 출력된 상기 예측에 관한 정 보를 기반으로 상기 현재 블록에 인트라 예측이 적용되는지 또는 인터 예측이 적용되는지 결정할 수 있고, 구체 적인 인트라/인터 예측 모드를 결정할 수 있다. 예측부는 후술하는 다양한 예측 방법을 기반으로 예측 신호를 생성할 수 있다. 예를 들어, 예측부는 하나의 블 록에 대한 예측을 위하여 인트라 예측 또는 인터 예측을 적용할 수 있을 뿐 아니라, 인트라 예측과 인터 예측을 동시에 적용할 수 있다. 이는 combined inter and intra prediction (CIIP)라고 불릴 수 있다. 또한, 예측부는 블록에 대한 예측을 위하여 인트라 블록 카피(intra block copy, IBC)를 수행할 수도 있다. 상기 인트라 블록 카피는 예를 들어 SCC(screen content coding) 등과 같이 게임 등의 컨텐츠 영상/동영상 코딩을 위하여 사용될 수 있다. IBC는 기본적으로 현재 픽처 내에서 예측을 수행하나 현재 픽처 내에서 참조 블록을 도출하는 점에서 인터 예측과 유사하게 수행될 수 있다. 즉, IBC는 본 문서에서 설명되는 인터 예측 기법들 중 적어도 하나를 이 용할 수 있다. 인트라 예측부(10b-32)는 현재 픽처 내의 샘플들을 참조하여 현재 블록을 예측할 수 있다. 상기 참조되는 샘플 들은 예측 모드에 따라 상기 현재 블록의 주변(neighbor)에 위치할 수 있고, 또는 떨어져서 위치할 수도 있다. 인트라 예측에서 예측 모드들은 복수의 비방향성 모드와 복수의 방향성 모드를 포함할 수 있다. 인트라 예측부 (10b-32)는 주변 블록에 적용된 예측 모드를 이용하여, 현재 블록에 적용되는 예측 모드를 결정할 수도 있다. 인터 예측부(10b-31)는 참조 픽처 상에서 움직임 벡터에 의해 특정되는 참조 블록(참조 샘플 어레이)을 기반으 로, 현재 블록에 대한 예측된 블록을 유도할 수 있다. 이때, 인터 예측 모드에서 전송되는 움직임 정보의 양을 줄이기 위해 주변 블록과 현재 블록 간의 움직임 정보의 상관성에 기초하여 움직임 정보를 블록, 서브블록 또는 샘플 단위로 예측할 수 있다. 상기 움직임 정보는 움직임 벡터 및 참조 픽처 인덱스를 포함할 수 있다. 상기 움 직임 정보는 인터 예측 방향(L0 예측, L1 예측, Bi 예측 등) 정보를 더 포함할 수 있다. 인터 예측의 경우에, 주변 블록은 현재 픽처 내에 존재하는 공간적 주변 블록(spatial neighboring block)과 참 조 픽처에 존재하는 시간적 주변 블록(temporal neighboring block)을 포함할 수 있다. 예를 들어, 인터 예측부 (10b-31)는 주변 블록들을 기반으로 움직임 정보 후보 리스트를 구성하고, 수신한 후보 선택 정보를 기반으로 상기 현재 블록의 움직임 벡터 및/또는 참조 픽처 인덱스를 도출할 수 있다. 다양한 예측 모드를 기반으로 인터 예측이 수행될 수 있으며, 상기 예측에 관한 정보는 상기 현재 블록에 대한 인터 예측의 모드를 지시하는 정보 를 포함할 수 있다. 가산부(10b-40)는 획득된 레지듀얼 신호를 예측부(10b-30)로부터 출력된 예측 신호(예측된 블록, 예측 샘플 어 레이)에 더함으로써 복원 신호(복원 픽처, 복원 블록, 복원 샘플 어레이)를 생성할 수 있다. 스킵 모드가 적용 된 경우와 같이 처리 대상 블록에 대한 레지듀얼이 없는 경우, 예측된 블록이 복원 블록으로 사용될 수 있다. 가산부(10b-40)는 복원부 또는 복원 블록 생성부라고 불릴 수 있다. 생성된 복원 신호는 현재 픽처 내 다음 처 리 대상 블록의 인트라 예측을 위하여 사용될 수 있고, 후술하는 바와 같이 필터링을 거쳐서 출력될 수도 있고 또는 다음 픽처의 인터 예측을 위하여 사용될 수도 있다. 한편, 픽처 디코딩 과정에서 LMCS (luma mapping with chroma scaling)가 적용될 수도 있다. 필터링부(10b-50)는 복원 신호에 필터링을 적용하여 주관적/객관적 화질을 향상시킬 수 있다. 예를 들어 필터링 부(10b-50)는 복원 픽처에 다양한 필터링 방법을 적용하여 수정된(modified) 복원 픽처를 생성할 수 있고, 상기 수정된 복원 픽처를 메모리, 구체적으로 메모리(10b-60)의 DPB에 전송할 수 있다. 상기 다양한 필터링 방법 은 예를 들어, 디블록킹 필터링, 샘플 적응적 오프셋(sample adaptive offset), 적응적 루프 필터(adaptive loop filter), 양방향 필터(bilateral filter) 등을 포함할 수 있다. 메모리(10b-60)의 DPB에 저장된 (수정된) 복원 픽처는 인터 예측부(10b-31)에서 참조 픽쳐로 사용될 수 있다. 메모리(10b-60)는 현재 픽처 내 움직임 정보가 도출된(또는 디코딩된) 블록의 움직임 정보 및/또는 이미 복원된 픽처 내 블록들의 움직임 정보를 저장할 수 있다. 상기 저장된 움직임 정보는 공간적 주변 블록의 움직임 정보 또는 시간적 주변 블록의 움직임 정보로 활용하기 위하여 인터 예측부(10b-31)에 전달할 수 있다. 메모리(10b- 60)는 현재 픽처 내 복원된 블록들의 복원 샘플들을 저장할 수 있고, 인트라 예측부(10b-32)에 전달할 수 있다. 본 명세서에서, 디코딩 장치(10b)의 예측부(10b-30), 역양자화부(10b-21), 역변환부(10b-22) 및 필터링부(10b- 50) 등에서 설명된 실시예들은 각각 인코딩 장치(10a)의 예측부(10a-20), 역양자화부(10a-34), 역변환부(10a- 35) 및 필터링부(10a-60) 등에도 동일 또는 대응되도록 적용될 수 있다. 상술한 바와 같이 비디오 코딩을 수행함에 있어 압축 효율을 높이기 위하여 예측을 수행한다. 이를 통하여 코딩 대상 블록인 현재 블록에 대한 예측 샘플들을 포함하는 예측된 블록을 생성할 수 있다. 여기서 상기 예측된 블 록은 공간 도메인(또는 픽셀 도메인)에서의 예측 샘플들을 포함한다. 상기 예측된 블록은 인코딩 장치 및 디코 딩 장치에서 동일하게 도출되며, 상기 인코딩 장치는 원본 블록의 원본 샘플 값 자체가 아닌 상기 원본 블록과 상기 예측된 블록 간의 레지듀얼에 대한 정보(레지듀얼 정보)를 디코딩 장치로 시그널링함으로써 영상 코딩 효 율을 높일 수 있다. 디코딩 장치는 상기 레지듀얼 정보를 기반으로 레지듀얼 샘플들을 포함하는 레지듀얼 블록 을 도출하고, 상기 레지듀얼 블록과 상기 예측된 블록을 합하여 복원 샘플들을 포함하는 복원 블록을 생성할 수 있고, 복원 블록들을 포함하는 복원 픽처를 생성할 수 있다. 상기 레지듀얼 정보는 변환 및 양자화 절차를 통하여 생성될 수 있다. 예를 들어, 인코딩 장치는 상기 원본 블 록과 상기 예측된 블록 간의 레지듀얼 블록을 도출하고, 상기 레지듀얼 블록에 포함된 레지듀얼 샘플들(레지듀 얼 샘플 어레이)에 변환 절차를 수행하여 변환 계수들을 도출하고, 상기 변환 계수들에 양자화 절차를 수행하여 양자화된 변환 계수들을 도출하여 관련된 레지듀얼 정보를 (비트스트림을 통하여) 디코딩 장치로 시그널링할 수 있다. 여기서 상기 레지듀얼 정보는 상기 양자화된 변환 계수들의 값 정보, 위치 정보, 변환 기법, 변환 커널, 양자화 파라미터 등의 정보를 포함할 수 있다. 디코딩 장치는 상기 레지듀얼 정보를 기반으로 역양자화/역변환 절차를 수행하고 레지듀얼 샘플들(또는 레지듀얼 블록)을 도출할 수 있다. 디코딩 장치는 예측된 블록과 상기 레지듀얼 블록을 기반으로 복원 픽처를 생성할 수 있다. 인코딩 장치는 또한 이후 픽처의 인터 예측을 위한 참 조를 위하여 양자화된 변환 계수들을 역양자화/역변환하여 레지듀얼 블록을 도출하고, 이를 기반으로 복원 픽처 를 생성할 수 있다. <VCM(Video coding for Machines)> 최근에 Surveillance, Intelligent Transportation, Smart City, Intelligent Industry, Intelligent Content 와 같은 다양한 산업 분야가 발전함에 따라 기계에 의해 소비되는 영상 또는 특징맵 데이터양이 증가하고 있다. 이에 반해, 현재 사용 중인 전통적인 영상 압축방식은 시청자가 인지하는 시각(Human Vision)의 특성을 고려해 개발된 기술이기에 불필요한 정보들을 포함하고 있어 기계 임무 수행에 비효율적이다. 따라서, 기계 임무 수행 에 대해 효율적으로 특징맵을 압축하기 위한 비디오 코덱 기술에 관한 연구가 요구되고 있다. 멀티미디어 부호화 국제표준화 그룹인 MPEG(Moving Picture Experts Group)에서 VCM(Video Coding for Machine) 기술이 논의되고 있다. VCM은 사람이 보는 시청자 시각 기준이 아닌 기계의 데이터 소비시각(Machine Vision)에 대한 기준의 영상 또는 특징맵 부호화 기술이다. 도 4a 내지 도 4d는 VCM 인코더와 VCM 디코더를 나타낸 예시도들이다. 도 4a을 참조하면, VCM 인코더(100a)와 VCM 디코더(100b)가 나타나 있다. VCM 인코더(100a)가 비디오 및/또는 특징맵을 인코딩하여 비트스트림으로 전송하면, VCM 디코더(100b)는 상기 비트스트림을 디코딩하여 출력할 수 있다. 이때, VCM 디코더(100b)는 하나 이상의 비디오 및/또는 특징맵을 출 력할 수 있다. 예를 들어, VCM 디코더(100b)는 머신을 이용한 분석을 위한 제1 특징맵을 출력할 수 있고, 사용 자에 의한 시청을 위한 제1 영상을 출력할 수 있다. 상기 제1 영상은 상기 제1 특징맵에 비하여 보다 고해상도 일 수 있다. 도 4b를 참조하면, VCM 인코더(100a)의 전단에는 특징맵을 추출하는 피처 추출기(Feature Extractor)가 연결될 수 있다. VCM 인코더(100a)는 피처 인코더(Feature Encoder)를 포함할 수 있다. VCM 디코더(100b)는 피처 디코더(Feature Decoder)와 비디오 재생성기(Video reconstructor)를 포함할 수 있다. 상기 피처 디코더는 비트스트림으로부터 특징맵(Feature Map)을 디코딩하여, 머신을 이용한 분석을 위한 제1 특징맵을 출력할 수 있다. 상기 비디오 재생성기는 비트스트림으로부터 사용자에 의한 시청을 위한 제1 영 상을 재생성하여 출력할 수 있다. 도 4c 참조하면, VCM 인코더의 전단에는 특징맵을 추출하는 피처 추출기(Feature Extractor)가 연결되어 있다. VCM 인코더(100a)는 피처 인코더를 포함할 수 있다.VCM 디코더(100b)는 피처 디코더를 포함할 수 있다. 상기 피처 디코더는 비트스트림으로부터 특징맵을 디코딩하 여, 머신을 이용한 분석을 위한 제1 특징맵을 출력할 수 있다. 즉, 비트스트림은 영상이 아닌 특징맵으로만 인 코딩 될 수 있다. 부연 설명하면, 특징맵은 영상을 기초로 머신의 특정 타스크를 처리하기 위한 특징에 대한 정 보를 포함한 데이터 일 수 있다. 도 4d를 참조하면, VCM 인코더(100a)의 전단에는 피처 추출기(Feature Extractor)가 연결되어 있을 수 있다. VCM 인코더(100a)는 피처 컨버터와 비디오 인코더를 포함할 수 있다. 상기 비디오 인코더는 도 2에 도시된 인코 딩 장치(10a)일 수 있다. 도 4d를 도시된 VCM 디코더(100b)는 비디오 디코더와 인버스 컨버터를 포함할 수 있다. 상기 비디오 디코더는 도 3에 도시된 디코딩 장치(10b)일 수 있다. <Semantics의 설명> 1) 일련의 프레임 그룹 단위: 예를 들어, GOP(group of picture) 단위 2) n: GOP 인덱스 3) p: 프레임 인덱스 4) m: 관심 영역 인덱스 5) RoI_Processing_flag: 현재 시퀀스가 관심 영역 기반 처리가 수행되었는지 여부를 나타내는 1-bit 플래그 6) num_of_GOPs: 한 시퀀스 내 GOP 수를 나타내는 정보 7) num_of_frames: 한 GOP 내 프레임 수를 나타내는 정보 8) num_of_RoIs: 한 프레임 내 관심 영역 수를 나타내는 정보 9) packing_flag(n): 일련의 프레임 그룹 단위 (GOP)로 패킹 수행 여부를 나타내는 1-bit 플래그 10) RoI_exist_region_LT, RoI_exist_region_LT: 픽처 내 관심 영역이 존재하는 영역의 좌상단 좌표 11) RoI_exist_region_RB, RoI_exist_region_RB: 픽처 내 관심 영역이 존재하는 영역의 우하단 좌표 12) Resize_RoI_flag(n)(p)(m): 관심 영역 별로 정규화의 수행 여부를 나타내는 1-bit 플래그 13) Hor_Resize_idx, Ver_Resize_idx: Resize_RoI_flag가 1인 관심 영역에 대해, 원본 크기로 리사이징하기 위 한 관심 영역의 가로/세로 리사이징 정도를 나타내는 인덱스 - 1 이상 정수 k에 대해, 각 관심 영역 마다 (Hor_Resize_idx >> k) 및 (Ver_Resize_idx >> k)로 리사이징을 수행할 수 있다. 14) Rotate_RoI_flag(n)(p)(m): 관심 영역 별로 변환 여부를 나타내는 1-bit 플래그, 1인 경우 관심 영역을 90도 회전 수행 15) upsamp_ratio_RoIs: 관심 영역의 업샘플링 레이트 정보, 해당 정보로 복원된 관심 영역 기반 처리된 영상 을 얻을 수 있다. 16) upsamp_ratio_nonRoIs: 비 관심 영역의 업샘플링 레이트 정보, 해당 정보로 복원된 비 관심 영역 영상을 얻 을 수 있다. 17) Filtering_RoI_flag(n)(p)(m): 관심 영역과 비 관심 영역 간 필터링 정보를 나타내는 1-bit 플래그, 1인 경우 Filter_idx를 파싱하여 특정 필터링 수행, 0인 경우 고정된 필터링 수행 - 각 관심 영역의 필터링 정보는 모든 프레임에서 동일할 수 있다. 18) Flip_RoI_flag(n)(p)(m): 관심 영역 별로 플립 여부를 나타내는 1-bit 플래그, 1인 경우 관심 영역을 가로 축으로 플립 수행 19)pos_RoI(n)(p)(m)[0], pos_RoI(n)(p)(m)[1]: 각 일련의 프레임 그룹 단위 (GOP) 내 첫 번째 프레임 내 존재 하는 관심 영역들의 위치 정보 - RoI_exist_region_LT, RoI_exist_region_LT, 중, 0이 아닌 값을 파싱한 경우, 일 예시로, RoI_exist_region_LT + pos_RoI(n)(m)[0], RoI_exist_region_LT + pos_RoI(n)(m)[1]이 m번째 관심 영역 최종 복원된 위치일 수 있다. - pos_diff_coding을 통해 얻은 위치 차분 값에 대해, 동일한 방법으로 관심 영역의 최종 복원된 위치를 구할 수 있다. 20)abs_pos_diff_greater0_flag_RoI(n)(p)(m)[0], abs_pos_diff_greater0_flag_RoI(n)(p)(m)[1]: 0번째 프레 임의 동일 관심 영역에 대해 x축 및 y축 위치 정보 차분 값의 절대 값이 0인지 여부를 나타내는 1-bit 플래그 21)abs_pos_diff_greater1_flag_RoI(n)(p)(m)[0], abs_pos_diff_greater1_flag_RoI(n)(p)(m)[1]: 0번째 프레 임의 동일 관심 영역에 대해 x축 및 y축 위치 정보 차분 값의 절대 값이 1인지 여부를 나타내는 1-bit 플래그 22)abs_pos_diff_minus2_RoI(i)(p)(j)[0], abs_pos_diff_minus2_RoI(i)(p)(j)[0]: 0번째 프레임의 동일 관심 영역에 대해 x축 및 y축 위치 정보 차분 값 절대 값의 -2의 해당하는 값을 나타내는 정보 23)pos_diff_sign_flag(i)(p)(j)[0], pos_diff_sign_flag(i)(p)(j)[1]: 0번째 프레임의 동일 관심 영역에 대해 x축 및 y축 부호 값을 나타내는 1-bit 플래그, 1인 경우 + 부호, 0인 경우 - 부호 24) bits_rtg_image_size는 rtg_image_size_x, rtg_image_size_y가 시그널링되는 비트 수를 지정 25) rtg_image_size_x, rtg_image_size_y는 패킹 이후 프레임의 너비 및 높이 26) org_image_size_x, org_image_size_y는 원본 프레임의 너비 및 높이 27) flag_rtg_image_size_difference는 패킹에 의해 원본 프레임 크기와 패킹 이후 프레임 크기가 상이한 지를 나타내는 1-bit 플래그 28) bits_rtg_to_org_difference는 rtg_to_org_difference_x 및 rtg_to_org_difference_y가 시그널링되는 비 트 수를 지정 29) rtg_to_org_difference_x, rtg_to_org_difference_y는 원본 프레임 크기와 패킹 이후 프레임 크기의 x축 및 y축의 차이 값 30) flag_rtg_rois는 관심 영역이 존재하는지 여부를 나타내는 1-bit 플래그31) bits_roi_pos는 roi_size_x[i] 및 roi_size_y[i] 신택스 요소가 시그널링되는 비트 수이며, 이는 시그널링되거나 계산됨 32) bit_num_rois는 num_rois 신택스 요소가 시그널링되는 비트 수를 지정 33) num_rois는 관심 영역의 수를 지정 34) roi_pos_x[i]는 원본 프레임 내에서 i번째 관심 영역의 x축 위치 35) roi_pos_y[i]는 원본 프레임 내에서 i번째 관심 영역의 y축 위치 36) roi_size_x[i]는 원본 프레임 내에서 i번째 관심 영역의 폭 37) roi_size_x[i]는 원본 프레임 내에서 i번째 관심 영역의 높이 도 5는 본 개시의 일 실시 예에 따른 관심 영역 기반 패킹을 수행하는 인코딩 장치에 포함되는 구성요소들의 블 록도이다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 기계를 위한 비디오 영상 부호화를 수행하여 비트스트림을 생 성할 수 있다. 인코딩 장치(10a)는 시간적 리샘플링 수행기, 공간적 리샘플링 수행기, 관심영역 기반 처리기, 내부 부호화 수행기를 포함할 수 있다. 도 5에 도시된 각 과정이 순서는 변경될 수 있다. 실 시 예에 따라, 시간적 리샘플링 수행기, 공간적 리샘플링 수행기는 생략될 수 있으며, 해당 과정들이 생략되는 경우 관심 영역 기반 처리된 영상이 내부 부호화 수행기의 입력으로 인가될 수 있다. 시간적 리샘플링 수행기는 원본 영상을 입력 받아 프레임 단위 샘플링을 수행하여 일부 프레임이 샘플링된 영상을 출력할 수 있다. 일 실시 예에서, 인코딩 장치(10a)는 시간적 리샘플링 과정에서 사용된 정보(일 예시로, 시간적 샘플링 레이트 등)를 디코딩 장치(10b)로 전송할 수 있다. 인코딩 장치(10a)는 선택적으로 시간 적 리샘플링 수행기를 적용할 수 있다.공간적 리샘플링 수행기는 원본 영상 또는 시간적 리샘플링이 수행된 영상을 입력 받아 각 프레임 또는 일 련의 프레임 단위로 공간적 해상도가 변경된 영상을 출력할 수 있다. 일 실시 예에서, 인코딩 장치(10a)는 공간 적 리샘플링 과정에 사용된 정보(일 예시로, 각 프레임의 공간적 샘플링 레이트 또는/및 일련의 프레임 단위의 공간적 샘플링 레이트 등)를 디코딩 장치(10b)로 전송할 수 있다. 인코딩 장치(10a)는 선택적으로 공간적 리샘 플링 수행기를 적용할 수 있다. 관심 영역 기반 처리기는 원본 영상 또는 시간적 리샘플링이 수행된 영상 또는 시간적 및 공간적 리샘플링 이 수행된 영상을 입력 받아 각 프레임 또는 일련의 프레임 단위 내 존재하는 관심 영역을 추출하고, 관심 영역 을 기반으로 처리된 영상을 출력할 수 있다. 인코딩 장치(10a)는 관심 영역을 추출하는 과정에 사용된 정보(일 예시로, 관심 영역 ID 정보, 관심 영역의 크기 정보, 패킹 정보 등)를 디코딩 장치(10b)로 전송할 수 있다. 관 심 영역 기반 처리기는, 프레임 분석부, 관심 영역 선택부, 및 패킹 수행부를 포함할 수 있다. 프레임 분석부는 영상을 입력받아 영상의 각 프레임에 존재하는 하나 이상의 관심 영역 후보들의 정보(예를 들 어, 관심 영역위치, 관심 영역 스코어 등)를 얻을 수 있다. 관심 영역 선택부는 프레임 분석부에서 얻은 관심 영역 후보들 중 내부 부호화 수행기를 통해 영상 부호화를 수 행할 관심 영역을 결정할 수 있다. 일 실시 예에서, 일부 프레임의 비 관심 영역 영상은 패킹 수행부를 거치지 않고, 곧바로 내부 부호화 수행기로 입력될 수 있다. 패킹 수행부는 영상의 각 프레임마다 선택된 관심 영역들을 이용하여 각 프레임을 재구성하는 패킹을 수행할 수 있다. 일 실시 예에서, 패킹 수행부는 프레임 내 선택된 관심 영역이 전체 원본 영상에서 차지하는 비중이 특정 임계 값보다 작은 경우, 프레임을 재구성하지 않을 수 있다. 즉, 전체 영상 중 관심 영역의 비중이 작은 경우 패킹 과정은 생략될 수 있다. 특정 임계 값은 고정된 값으로 설정될 수 있고, 원본 영상의 크기에 따라 적응적 으로 결정될 수 있다. 인코딩 장치(10a)는 프레임 단위 또는 일련의 프레임 단위로 패킹을 수행할지 여부를 결 정할 수 있다. 인코딩 장치(10a)는 일련의 프레임 그룹 단위로 패킹 수행 여부(packing_flag)를 시그널링할 수 있다. 관심 영역 기반 처리기를 구성하는 각 구성요소의 구체적인 동작은 도 6에서 상세히 설명하겠다. 내부 부호화 수행기는 관심 영역 기반 처리기에서 출력된 영상을 입력 받아 영상 부호화를 수행하여 비트스트림을 생성할 수 있다. 내부 부호화 수행기는 2D 비디오 인코더(AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9, 등)를 이용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 인코더를 이용 할 수 있다. 일 실시 예에서, 내부 부호화 수행기의 입력 영상의 색 공간을 YUV420, YUV444 등의 색공간으 로 변환한 후, 부호화가 수행될 수 있다. 이때, 실시 예에 따라, 부/복호화(인코더/디코더) 간의 약속에 의해 정의된 변환 방법을 통해 변환할 수 있고, 색공간 변환 정보를 디코딩 장치(10b)로 전송할 수 있다. 내부 부호화 수행기는 다운 샘플링 수행부 및 영상 부호화 수행부를 포함할 수 있다. 내부 부호화 수행기 는 관심 영역 기반 처리기를 통해 분석된 관심 영역 기반 처리된 영상에 대해 다운 샘플링을 수행하고, 영상 부호화를 수행할 수 있다. 내부 부호화 수행기는 관심 영역 기반 처리기를 통해 비 관심 영역으로 분리된 비 관심 영역 영상에 대해 관심 영역과 별개로 다운 샘플링을 수행하고, 영상 부호화를 수행할 수 있다. 일 실시 예에서, 내부 부호화 수행기는 관심 영역 기반 처리된 영상에 대해 매 프레임마 다 부호화를 수행할 수 있고, 비 관심 영역 영상에 대해서는 일련의 프레임 그룹 내 일부 프레임에 대해서만 부 호화를 수행할 수 있다. 다운 샘플링 수행부는, 영상 부호화 전에 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대해 각각 서로 다른 샘플링 레이트를 적용하여 다운 샘플링을 수행할 수 있다. 일 실시 예에서, 인코딩 장치(10a)는 다운 샘플 링이 수행된 경우 샘플링 레이트 정보(upsamp_ratio_RoIs, upsamp_ratio_nonRoIs)를 시그널화 하여 디코딩 장 치(10b)로 전송할 수 있다. 일 실시 예에서, 내부 부호화 수행기는 비디오 인코더(AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9, 등)를 이용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 인코더를 이용할 수 있다. 영상 부호 화 수행부는 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대해 동일한 비디오 인코더를 이용할 수 있고, 또는 서로 다른 비디오 인코더를 이용할 수 있다. 도 6은 본 개시의 일 실시 예에 따른 인코딩 장치의 관심 영역 기반 처리기에 포함되는 구성요소들의 블록도이 다.본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 비디오 영상에서 관심 영역을 분석 및 처리할 수 있다. 일 실 시 예에서 관심 영역 기반 처리기는 프레임 분석부, 관심 영역 선택부, 패킹 수행부를 포 함할 수 있다. 관심 영역 기반 처리기는 입력 영상에 대해 관심 영역을 추출하고, 관심 영역에 대한 영상 처리를 수행한 후, 관심 영역 기반 처리된 영상을 출력할 수 있다. 관심 영역 기반 처리기는 관심 영역으 로 추출되지 않은 나머지 영역에 대해 비 관심 영역 영상을 출력할 수 있다. 프레임 분석부는 영상의 각 프레임 내 존재하는 하나 이상의 관심 영역 후보들의 정보(일 예시로, 관심 영 역 위치, 관심 영역 점수(score) 등)를 분석할 수 있다. 프레임 분석부는, 분석 영역 선택 모듈 및 관심영 역 후보 추출 모듈을 포함할 수 있다. 분석 영역 선택 모듈은 하나 이상의 프레임 단위로 분석 영역을 선택할 수 있다. 프레임 분석부는 프레임 분석 이 수행될 영역을 선택한 후, 영상 내 일부 영역에 대해서만 프레임 분석을 수행할 수 있다. 인코딩 장치(10a) 는 프레임 분석이 수행된 일부 영역에 대한 정보(RoI_exist_region_LT, RoI_exist_region_RB)를 디코딩 장치 (10b)에 전송할 수 있다. 상기 일부 영역은 모든 영상에 대해 동일한 영역일 수 있다. 또는, 상기 일부 영역은 영상 및 영상 내 일련의 프레임 그룹 단위마다 상이할 수 있다. 인코딩 장치(10a)는 프레임 분석을 수행하지 않 은 영역을 디코딩 장치(10b)로 전송하지 않을 수 있다. 관심 영역 후보 추출 모듈은, 학습이 수행된 하나 이상의 컨볼루션 레이어로 구성된 딥 뉴럴 네트워크를 이용할 수 있다. 일 실시 예에서, 딥 뉴럴 네트워크는 객체 탐지(object detect)를 목적으로 학습된 네트워크일 수 있 고, 객체 추적(object tracing)을 목적으로 학습된 네트워크일 수 있다. 프레임 분석부는 프레임 단위, 또 는 일련의 프레임 단위로 관심 영역 후보를 추출할 수 있다. 프레임 분석부는 각 프레임 또는 일련의 프레 임 그룹에 대해 검출된 객체(관심 영역 후보)의 검출 정확도가 낮은 경우, 관심 영역 후보에서 제외할 수 있다. 관심 영역 후보 추출 모듈은 객체 추적을 목적으로 학습된 딥 뉴럴 네트워크를 사용하는 경우, 대응 관심 영역 선정 모듈은 생략될 수 있다. 일련의 프레임 그룹 단위로 대응 관심 영역 선정 모듈이 수행되는 경우, 프레임 분석부는 입력되는 첫 프 레임의 관심 영역 후보(검출된 객체)를 후보로 선정하여, 이후 프레임의 관심 영역 후보와 대응 관계를 통해 대 응 관심 영역을 선정할 수 있다. 일 실시 예에서, 대응 관계는 각 검출된 객체의 전체 영역 및/또는 일부 영역 간의 픽셀 간 유사성(일 예시로, cross-correlation 또는/및 픽셀 값의 histogram 비교 등)에 기반하여 결정될 수 있다. 프레임 분석부는 각 프레임 내 관심 영역 후보의 크기는 높이와 너비가 모두 4의 배수가 되도록 설정할 수 있다. 관심 영역 선택부는 관심 영역 후보들 중에서 관심 영역을 선택하고, 대응 관심 영역을 선정할 수 있다. 일 실시 예에서 관심 영역 선택부는 관심 영역 선택 모듈 및 대응 관심 영역 선정 모듈을 포함할 수 있다. 일 실시 예에서, 관심 영역은 영상의 주요한 부분을 포함한다고 판단된 것으로 부호화를 수행할 영역일 수 있다. 비 관심 영역은 프레임 내 관심 영역 외의 영역에 해당하고, 상대적으로 주요하지 않은 부분에 해당하기 때문에 부호화하지 않을 수 있고, 관심 영역의 주변 픽셀 값으로 채우거나, 중간 값으로 지정할 수 있다. 선택된 관심 영역은 각 프레임마다 상이할 수 있고, 일련의 프레임 그룹 단위마다 상이할 수 있다. 관심 영역 후보 추출 모듈에서 학습된 딥 뉴럴 네트워크를 사용하는 경우, 각 프레임 또는 일련의 프레임 그룹에 대해, 검 출된 객체(관심 영역 후보)의 검출 정확도가 낮은 경우, 관심 영역 후보에서 제외될 수 있고, 검출된 객체들이 관심 영역으로 선택될 수 있다. 일 실시 예에서, 검출 정확도에 대한 임계 값은 영상 전체에서 동일한 값일 수 있고, 일련의 프레임 그룹 단위마다 상이 값으로 설정될 수 있다. 관심 영역 선택부는 일련의 프레임 그룹 단위로 대응 관심 영역 선정 모듈을 수행하는 경우, 입력되는 첫 프레임의 관심 영역 후보(검출된 객체)를 후보로 선정하여, 이후 프레임의 관심 영역 후보와 대응 관계를 통해 대응 관심 영역을 선정할 수 있다. 일 실시 예에서, 대응 관계는 각 검출된 객체의 전체 영역 및/또는 일부 영 역 간의 픽셀 간 유사성(일 예시로, cross-correlation 또는/및 픽셀 값의 histogram 비교 등)에 기반하여 결정 될 수 있다. 관심 영역 선택부는 모든 관심 영역 후보의 크기를 특정 크기로 다운 샘플링 또는 업 샘플링한 후, 대응관 심 영역 선정 모듈을 적용할 수 있다. 상기 특정 크기는 영상의 해상도에 따라 결정될 수 있고, 또는 각 프레임 별 추출된 관심 영역 후보의 크기를 비교하여, 가장 작은 크기를 갖는 관심 영역의 크기로 결정될 수 있다.관심 영역 선택부는 관심 영역에 대해 ID를 부여할 수 있고, 예를 들어, 대응 관심 영역이 선정되는 단위 별로 ID를 부여할 수 있다. 한 프레임 내에서 관심 영역 후보 추출 모듈에서 추출된 관심 영역 후보들의 영역이 서로 겹치는 경우, 관심 영역 선택부는 겹치는 영역이 일정 임계 값을 넘는 경우, 해당 관심 영역들을 하나의 관심 영역으로 분류할 수 있다. 이때 임계 값은 프레임의 크기에 따라 결정될 수 있고, 관심 영역 후보의 크기 에 따라 결정될 수 있다. 현재 프레임의 관심 영역 중, 이전 프레임에 관심 영역과 대응되는 영역이 없는 경우, 관심 영역 선택부는 해당 관심 영역에 새로운 ID를 부여할 수 있다. 또는 관심 영역 선택부는 새로운 ID가 부여된 관심 영역의 경우, 순서상 더욱 이전 프레임들 중, 대응되는 관심 영역이 있는 경우, 새로운 ID가 아닌 대응되는 관심 영역 의 기존 ID를 부여할 수 있다. 관심 영역 선택부는 대응 관계를 구하는 방법을 이용하여 새로운 ID를 부여 할 지 기존 ID를 부여할지 결정할 수 있다. 패킹 수행부는 영상의 각 프레임마다 선택된 관심 영역들을 이용하여 각각이 새로운 프레임을 재구성하는 패킹을 수행하여 관심 영역 기반 처리된 영상을 생성할 수 있다. 일 실시 예에서, 프레임 내 선택된 관심영역이 차지하는 영역이 영상 크기와 비교하여 특정 임계 값보다 차이가 큰 경우, 패킹 수행부는 생략될 수 있다. 일 실시 예에서, 특정 임계 값은 고정된 임계 값일 수 있고, 현재 영상의 크기에 따라 적응적으로 결정될 수도 있다. 인코딩 장치(10a)는 프레임 단위로 또는 일련의 프레임 단위로 패킹 수행을 생략할지 결정할 수 있다. 인코딩 장치(10a)는 패킹 수행 전에 선택된 관심 영역들의 크기를 정규화할 수 있다. 정규화 크기의 높이와 너 비는 4의 배수일 수 있다. 정규화 크기는 관심 영역 ID마다 서로 상이할 수 있다. 정규화를 수행하는 단위는 관 심 영역 단위일 수 있고, 일련의 프레임 그룹 단위일 수 있다. 정규화가 수행되는 관심 영역의 경우, 관심 영역 의 원래 크기에 대한 정보(Resize_RoI_flag, Hor_Resize_idx, Ver_Resize_idx)가 시그널링될 수 있다. 정규화된 관심 영역 또는 정규화가 수행되지 않는 관심 영역에 대해, 변환 모듈이 수행될 수 있다. 변환 모듈은 회전 등의 과정일 수 있고, 회전은 특정 각도의 회전만 수행될 수 있다. (예를 들어, 90도) 첫 프레임의 각 관 심 영역의 종횡비(높이/너비)를 비교하여, 변환이 수행되는 관심 영역들을 선정할 수 있다. 종횡비가 1 이상인 관심 영역의 수가 1 미만인 관심 영역의 수보다 적은 경우, 패킹 수행부는 1 미만인 관심 영역을 90도 회 전하여 이후 패킹을 수행할 수 있다. 일 실시 예에서, 두 종류의 관심 영역의 수가 동일한 경우, 패킹 수행부 는 종횡비가 1 미만인 관심 영역을 90도 회전하여 이후 패킹을 수행할 수 있다. 변환 과정은 각 프레임마 다 독립적으로 수행될 수 있고, 일련의 프레임 단위로 수행될 수도 있다. 관심 영역의 변환이 수행된 경우, 변 환이 수행된 관심 영역은 변환 정보(Rotate_RoI_flag)가 시그널링될 수 있다. 패킹 수행부는 관심 영역에 대해 패킹을 수행할 수 있다. 패킹 수행부는 프레임 단위로 패킹을 수행 할 수 있다. 패킹 수행부는 패킹된 프레임 내 채워지지 않는 영역에 대해 일정 값으로 패딩을 수행할 수 있고, 이때 일정 값은 중간 값일 수 있다. 패킹된 프레임의 크기는 일련의 프레임 그룹 단위 내 각 프레임이 모 두 동일할 수 있다. 패킹 수행부는 각 관심 영역에 대해 ID 인덱스 값을 기준으로 패킹을 수행할 수 있다. 일 실시 예에서, 패 킹 수행부는 프레임에 대한 스캐닝 순서로 패킹을 수행할 수 있고, 예를 들어, 프레임 좌측 상단부터 Z 스 캔하는 스캐닝 순서에 따라 패킹을 수행할 수 있다. 관심 영역 사이 간격은 일정 픽셀 값일 수 있고, 해당 영역은 필터링을 수행할 수 있고, 각 관심 영역 경계의 대표 값으로 채울 수 있다. 각 관심 영역의 간격은 원본 영상과 동일하게 유지하면서, 각 관심 영역의 x좌표 및 y좌표 중 가장 작은 두 값 을 이용하여 프레임 좌상단 위치로 패킹을 수행할 수 있다. 패킹 이후 프레임의 크기는 원보 프레임 크기와 상 이할 수 있다. 패킹 수행부는 원본 영상에서 관심 영역을 선택한 후, 관심 영역이 존재하는 영역만을 새롭게 프레임으로 구성할 수 있다. 패킹 수행부는 각 관심 영역에 대해 ID 인덱스 값이 가장 작은 관심 영역을 프레임 좌상단 측에 패킹을 수 행한 후, 나머지 관심 영역들에 대해 패킹된 관심 영역의 우측 경계와 가장 유사한 관심 영역을 순차적/반복적 으로 패킹을 수행할 수 있다. 일 실시 예에서, 관심 영역 경계 간 유사성은 두 관심 영역의 높이 중, 작은 길이 를 기준으로 하여 해당 영역의 경계 1 이상 점수 n에 대해, n 픽셀의 평균 값의 차분 값으로 유사성을 판별할수 있다. 패킹 수행부는 유사성 판별 과정에서 각 관심 영역의 수직 방향 플립 전/후를 고려할 수 있다. 패킹 수행부는 관심 영역의 플립이 수행된 경우, 해당 정보 (Flip_RoI_flag)를 시그널링할 수 있다. 패킹 수행부는 일련의 프레임 단위로 패킹을 수행하는 경우 첫 프레임의 패킹 정보를 프레임 단위 내 모든 프레임에 적용할 수 있다. 패킹 수행부는 선택된 관심 영역이 중간 프레임부터 존재하는 경우, 해당 프레 임부터 새로운 관심 영역에 대해, 일련의 프레임 단위로 패킹을 수행할 수 있다. 패킹 수행부는 관심 영역 이 프레임 그룹 내 중간 프레임부터 존재하지 않는 경우, 해당 프레임부터 패킹 과정을 다시 수행할 수 있다. 패킹 수행부는 패킹된 관심 영역 정보에 대해 각 관심 영역의 좌상단 좌표를 기준으로 위치 값 및 차분 값 (pos_RoI, pos_diff_coding)을 시그널링 할 수 있다. 패킹된 관심 여영역의 정보는 각 관심 영역이 속한 CTU (Coding tree unit)의 인덱스 및 CTU 내에서 관심 영역의 좌상단 좌표를 기준으로 위치 값 및 차분 값을 시그널 링 할 수 있다. 각 CTU는 영상 시퀀스에서 동일한 크기를 가질 수 있으며, 각 프레임 별로 동일한 크기를 가질 수 있고, 1 이상 정부 M, N에 대해, MxN 크기를 갖는 영역일 수 있다. 각 CTU는 영상 프레임을 MxN으로 분할하 여 얻은 각 서브 블록일 수 있다. 패킹 수행부는 패킹을 수행한 후, 전체 관심 영역 또는 일부의 관심 영역의 크기를 정규화할 수 있다. 정 규화 크기의 높이와 너비는 4의 배수일 수 잇다. 정규화 크기는 관심 영역 ID 마다 서로 상이할 수 있다. 정규 화를 수행하는 단위는 관심 영역 단위일 수 있고, 일련의 프레임 단위일 수 있다. 정규화가 수행되는 관심 영역 의 경우, 관심 영역의 원래 크기에 대한 정보가 시그널링될 수 있다. 패킹 수행부는 패킹 이후 관심 영역 의 하단 또는/및 좌측이 CTU 또는/및 슬라이스의 일정 영역 이하 또는 이상을 차지하는 경우, 정규화를 수행할 수 있다. 일정 영역의 정의는 입력 영상의크기, 관심 영역의 크기 등을 기반하여 부/복호화기의 약속에 의해 결 정될 수 있다. 일 실시 예에서, 관심 영역의 높이 또는 너비만 정규화를 수행할 수 있고, 또는 높이 및 너비 모 두 정규화를 수행할 수 있다. 이때, 높이와 너비의 정규화 비율은 서로 상이할 수 있다. 도 7은 본 개시의 일 실시 예에 따른 관심 영역을 패킹하는 일 예시이다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 프레임에 포함된 하나 이상의 관심 영역에 대해 패킹을 수행 할 수 있다. 인코딩 장치(10a)의 패킹 수행부는 영상 각 프레임마다 선택된 관심 영역들을 이용하여 각각 의 새로운 프레임을 재구성하는 패킹을 수행하여 관심 영역 기반 처리된 영상을 생성할 수 있다. 도 7을 참조하면, (a)프레임은 제1 관심 영역, 제2 관심 영역, 및 제3 관심 영역를 포함한다. 인코딩 장치(10a)는 제1 관심 영역, 제2 관심 영역, 및 제3 관심 영역를 ID의 인덱스 값이 작은 순서로 프레 임의 좌상단 측에 Z 스캐닝 순서로 패킹을 수행할 수 있다. 일 실시 예에서, (a)와 같이 패킹 이후 프레임의 크 기는 원본 프레임의 크기와 상이할 수 있다. 또는, (b)와 같이 패킹 이후 프레임의 크기가 원본 프레임의 크기 가 동일할 수 있다. 각 관심 영역 사이 간격은 일정 픽셀 값일 수 있고, 해당 영역은 필터링을 수행할 수 있고, 또는/및 각 관심 영역 경계의 대표 값으로 채울 수 있다. (c)프레임은 각 관심 영역의 간격은 원본 영상과 동일하게 유지하면서, 각 관심 영역의 x 좌표 및 y 좌표 중 가 장 작은 두 값을 이용하여 프레임 좌상단 위치로 패킹을 수행할 수 있다. (d)프레임은 각 관심 영역의 간격은 원본 영상과 동일하게 유지하면서, 각 관심 영역의 x 좌표 및 y 좌표 중 가 장 작은 두 값을 이용하여 프레임 좌상단 위치로 패킹을 수행할 수 있다. 패킹 이후, 관심 영역이 존재하는 사 각형 영역을 새로운 프레임으로 설정할 수 있다. 이때, 새로운 프레임은 원본 프레임의 크기와 상이할 수 있다. 이는 일 실시 예에 따라 GOP단위 등의 특정 단위별로 수행될 수 있다. 도 8은 본 개시의 일 실시 예에 따른 관심 영역의 크기를 정규화하는 일 예시이다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 패킹이 수행된 이후, 전체 관심 영역 또는 일부의 관심 영역 의 크기를 정규화 할 수 있다. 정규화 크기의 높이와 너비는 4의 배수일 수 있다. 정규화 크기는 관심 영역 ID 마다 서로 상이할 수 있다. 정규화를 수행하는 단위는 관심 영역 단위일 수 있고, 일련의 프레임 그룹 단위일 수 있다. 정규화가 수행되는 관심 영역의 경우, 관심 영역의 원래 크기에 대한 정보가 시그널링 될 수 있다. 인 코딩 장치(10a)는 패킹 이후 관심 영역의 하단 또는/및 좌측이 CTU 또는/및 슬라이스의 일정 영역 이하 또는 이 상을 차지하는 경우, 정규화를 수행할 수 있다. 일정 영역의 정의는 입력 영상의 크기, 관심 영역의 크기 등을 기반하여 부/복호화기의 약속에 의해 결정될 수 있다. 관심 영역의 높이 또는 너비만 정규화를 수행할 수 있고,높이 및 너비 모두 정규화를 수행할 수 있다. 이때, 높이와 너비의 정규화 비율은 서로 상이할 수 있다. 도 8을 참조하면, (a)프레임에서 관심 영역의 하단 및 좌측이 CTU의 일정 영역 이하를 차지하는 경우, 관심 영역의 크기를 작게 정규화 할 수 있다. 또는, (b)프레임에서 관심 영역의 하단 및 좌측이 CTU의 일정 영역 이상을 차지하는 경우, 관심 영역의 크기를 크게 정규화 할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 인코딩 장치가 관심 영역 기반 패킹을 수행 방법을 나타내는 순서도이다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 영상에 포함된 프레임에서 관심 영역을 선택하고, 각 프레임 마다 선택된 관심 영역들을 이용하여 각각의 새로운 프레임을 재구성하는 패킹을 수행하여 관심 영역 기반 처리 된 영상을 생성할 수 있다. 인코딩 장치(10a)는 시간적 리샘플링 수행기, 공간적 리샘플링 수행기, 관심영역 기반 처리기, 내부 부호화 수행기를 포함할 수 있다. 도 9에 개시된 각 단계의 순서는 변경 될 수 있다. 실시 예에 따라, S910 단계 및/또는 S920 단계는 생략될 수 있으며, 해당 과정들이 생략되는 경우 관심 영역 기반 처리된 영상이 내부 부호화 수행기의 입력으로 인가될 수 있다. S910 단계에서, 인코딩 장치(10a)의 시간적 리샘플링 수행기는 원본 영상을 입력 받아 프레임 단위 샘플링 을 수행하여 일부 프레임이 샘플링된 영상을 출력할 수 있다. 일 실시 예에서, 인코딩 장치(10a)는 시간적 리샘 플링 과정에서 사용된 정보(일 예시로, 시간적 샘플링 레이트 등)를 디코딩 장치(10b)로 전송할 수 있다. 인코 딩 장치(10a)는 선택적으로 시간적 리샘플링 수행기를 적용할 수 있다. S920 단계에서, 인코딩 장치(10a)의 공간적 리샘플링 수행기는 원본 영상 또는 시간적 리샘플링이 수행된 영상을 입력 받아 각 프레임 또는 일련의 프레임 단위로 공간적 해상도가 변경된 영상을 출력할 수 있다. 일 실 시 예에서, 인코딩 장치(10a)는 공간적 리샘플링 과정에 사용된 정보(일 예시로, 각 프레임의 공간적 샘플링 레 이트 또는/및 일련의 프레임 단위의 공간적 샘플링 레이트 등)를 디코딩 장치(10b)로 전송할 수 있다. 인코딩 장치(10a)는 선택적으로 공간적 리샘플링 수행기를 적용할 수 있다. S930 단계에서, 인코딩 장치(10a)의 관심 영역 기반 처리기는 원본 영상 또는 시간적 리샘플링이 수행된 영상 또는 시간적 및 공간적 리샘플링이 수행된 영상을 입력 받아 각 프레임 또는 일련의 프레임 단위 내 존재 하는 관심 영역을 추출하고, 관심 영역을 기반으로 처리된 영상을 출력할 수 있다. 인코딩 장치(10a)는 관심 영 역을 추출하는 과정에 사용된 정보(일 예시로, 관심 영역 ID 정보, 관심 영역의 크기 정보, 패킹 정보 등)를 디 코딩 장치(10b)로 전송할 수 있다. S931 단계에서, 영역 기반 처리기의 프레임 분석부는 영상을 입력받아 영상의 각 프레임에 존재하는 하나 이상의 관심 영역 후보들의 정보(예를 들어, 관심 영역위치, 관심 영역 스코어 등)를 얻을 수 있다. S932 단계에서, 영역 기반 처리기의 관심 영역 선택부는 프레임 분석부에서 얻은 관심 영역 후보들 중 내부 부호화 수행기를 통해 영상 부호화를 수행할 관심 영역을 결정할 수 있다. 일 실시 예에서, 일부 프레 임의 비 관심 영역 영상은 패킹 수행부를 거치지 않고, 곧바로 내부 부호화 수행기로 입력될 수 있다. S933 단계에서, 영역 기반 처리기의 패킹 수행부는 영상의 각 프레임마다 선택된 관심 영역들을 이용 하여 각 프레임을 재구성하는 패킹을 수행할 수 있다. 일 실시 예에서, 패킹 수행부는 프레임 내 선택된 관심 영역이 전체 원본 영상에서 차지하는 비중이 특정 임계 값보다 작은 경우, 프레임을 재구성하지 않을 수 있다. 즉, 전체 영상 중 관심 영역의 비중이 작은 경우 패킹 과정은 생략될 수 있다. 특정 임계 값은 고정된 값으로 설정될 수 있고, 원본 영상의 크기에 따라 적응적으로 결정될 수 있다. 인코딩 장치(10a)는 프레임 단위 또는 일련의 프레임 단위로 패킹을 수행할지 여부를 결정할 수 있다. 인코딩 장치(10a)는 일련의 프레임 그룹 단위로 패킹 수행 여부(packing_flag)를 시그널링할 수 있다. S940 단계에서, 인코딩 장치(10a)의 내부 부호화 수행기는 관심 영역 기반 처리기에서 출력된 영상을 입력 받아 영상 부호화를 수행하여 비트스트림을 생성할 수 있다. 내부 부호화 수행기는 2D 비디오 인코더 (AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9, 등)를 이용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 인코더를 이용할 수 있다. 일 실시 예에서, 내부 부호화 수행기의 입력 영상의 색 공간을 YUV420, YUV444 등의 색공간으로 변환한 후, 부호화가 수행될 수 있다. 이때, 실시 예에 따라, 부/복호화(인코 더/디코더) 간의 약속에 의해 정의된 변환 방법을 통해 변환할 수 있고, 색공간 변환 정보를 디코딩 장치(10b) 로 전송할 수 있다. 내부 부호화 수행기는 다운 샘플링 수행부 및 영상 부호화 수행부를 포함할 수 있다. 내부 부호화 수행기 는 관심 영역 기반 처리기를 통해 분석된 관심 영역 기반 처리된 영상에 대해 다운 샘플링을 수행하고, 영상 부호화를 수행할 수 있다. 내부 부호화 수행기는 관심 영역 기반 처리기를 통해 비 관심 영역으로 분리된 비 관심 영역 영상에 대해 관심 영역과 별개로 다운 샘플링을 수행하고, 영상 부호화를 수행할 수 있다. 일 실시 예에서, 내부 부호화 수행기는 관심 영역 기반 처리된 영상에 대해 매 프레임마 다 부호화를 수행할 수 있고, 비 관심 영역 영상에 대해서는 일련의 프레임 그룹 내 일부 프레임에 대해서만 부 호화를 수행할 수 있다. 다운 샘플링 수행부는, 영상 부호화 전에 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대해 각각 서로 다른 샘플링 레이트를 적용하여 다운 샘플링을 수행할 수 있다. 일 실시 예에서, 인코딩 장치(10a)는 다운 샘플 링이 수행된 경우 샘플링 레이트 정보(upsamp_ratio_RoIs, upsamp_ratio_nonRoIs)를 시그널화 하여 디코딩 장 치(10b)로 전송할 수 있다. 일 실시 예에서, 내부 부호화 수행기는 비디오 인코더(AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9, 등)를 이용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 인코더를 이용할 수 있다. 영상 부호 화 수행부는 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대해 동일한 비디오 인코더를 이용할 수 있고, 또는 서로 다른 비디오 인코더를 이용할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 관심 영역 기반 언패킹을 수행하는 디코딩 장치에 포함되는 구성요소들의 블록도이다. 본 개시의 일 실시 예에 따른 디코딩 장치(10b)는 기계를 위한 영상 복호화를 수행할 수 있다. 상기 복호화는 전술한 부호화의 역과정이므로, 전술한 바를 중복하여 설명하지 않더라도, 전술한 내용이 제외되는 것은 아니다. 디코딩 장치(10b)는 내부 복호화 수행기, 관심 영역 기반 복원기, 공간적 복원 수행기, 시간적 복원 수행기, 및 후처리 필터 수행기를 포함할 수 있다. 각 과정의 순서는 변경될 수 있고, 관심 영역 기반 복원기, 공간적 복원 수행기 및 시간적 복원 수행기의 순서는 영상의 부호화 과정에서 각 대응 과정이 수행된 순서의 역 순으로 수행 될 수 있다. 내부 복호화 수행기는 비트스트림을 입력 받아 영상 복호화를 수행하여 복원된 영상을 생성할 수 있다. 실시 예 에 따라, 영상 복호화는 2D 비디오 복호화기(decoder)(AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9, 등)를 이 용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 복호화기를 이용할 수 있다. 실시 예에 따라, 복원된 영상의 색공간이 RGB444가 아닌 YUV420, YUV444, 등 중 하나인 경우, RGB444 공간으로 암시적 또는/그리 고 명시적으로 변환 후, 이후 영상 복호화 과정이 수행될 수 있다. 실시 예에 따라, 복원된 영상의 색공간을 다른 색공간으로 암시적 또는/그리고 명시적으로 변환 후, 이후 영상 복호화 과정이 수행될 수 있다. 내부 복호화 수행기는 영상 복호화 수행부 및 업샘플링 수행부를 포함할 수 있다. 내부 복호화 수행기는 비트스 트림을 입력받아 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대해 각각 영상 복호화 수행과 업샘플링을 수행할 수 있다. 실시 예에 따라, 각 과정의 순서는 변경 및 생략될 수 있다. 실시 예에 따라, 관심 영역 기반 처리된 영상과 비 관심 영역 영상은 복호화 이후 샘플링 레이트(upsamp_ratio_RoIs, upsamp_ratio_nonRoIs)를 전송받아 각각 업샘플링을 수행할 수 있다. 실시 예에 따라, 각 영상에 대한 업샘플링 방법은 Bilinear upsampling, bilateral upsampling, nearest-neighbor upsampling, 하나 이상의 컨볼루션 레이어가 포함된 딥 뉴럴 네트워크 중 하나를 고정적으로 사용할 수 있다. 실시 예에 따라, 복원된 관심 영역 기반 처리된 영상의 프레임 수와 복원된 비 관심 영역 영상의 프레임 수는 서로 상이할 수 있다. 관심 영역 기반 복원기는 실시 예에 따라, 복호화된 영상과 부호화기로부터 전송받은 관심 영역 기반 처리 정보 (일 예시로, 관심 영역 ID 정보, 관심 영역의 크기 정보, 패킹 정보 등)를 이용하여 관심 영역 기반 처리된 영 상을 복원할 수 있다. 관심 영역 기반 복원기는 언패킹 수행부 및 영상 재구성부를 포함할 수 있다. 관심 영역 기반 복원 과정은, 복원된 비관심 영역 영상은 영상 재구성부의 입력으로 인가되고, 복원된 관심 영역 기반 처 리된 영상은 언패킹 수행부의 입력으로 인가된 후, 언패킹 수행부의 출력이 영상 재구성부의 입력으로 인가될 수 있다. 언패킹 수행부는 복원된 관심 영역 기반 처리된 영상을 입력받아 각 관심 영역에 대해, 회전 및 원본 관심 영역의 크기로 복원과 각 관심 영역의 원본 위치로의 언패킹을 수행할 수 있다. 실시 예에 따라, 일련의 프레임 그룹 단위로 패킹 여부(packing_flag)를 전송받아, 패킹이 수행된 경우, 언패킹 수행부를 통해 복원된관심 영역을 얻을 수 있다. 언패킹 수행부의 상세한 동작은 도 11에서 후술하겠다. 영상 재구성부는 언패킹이 수행된 복원된 관심 영역과 복원된 비 관심 영역 영상을 입력받아 원본 영상으로의 복원을 수행할 수 있다. 영상 재구성부는 영역 경계 필터링 수행 모듈을 포함할 수 있다. 실시 예에 따라, 복원 된 관심 영역과 복원된 비 관심 영역 영상에 대해, 영역 경계 필터링 수행 모듈이 수행될 수 있다. 실시 예에 따라, 복원된 비 관심 영역 영상은 복원된 관심 영역의 각 프레임마다 존재할 수 있고, 일련의 프레 임 그룹 단위마다 하나의 복원된 비 관심 영역 영상이 존재할 수 있다. (일 예시로, 각 GOP 단위의 Intra frame 에 대해서만 복원된 비 관심 영역 영상이 존재할 수 있다.) 실시 예에 따라, 복원된 비 관심 영역 영상이 일련의 프레임 그룹 단위마다 하나가 존재하는 경우, 각 복원된 관심 영역의 프레임에 대해, 동일한 복원된 비 관심 영역 영상을 이용하여 복원 영상을 생성할 수 있다. 실시 예에 따라, 각 복원된 관심 영역에 대해, 해당 관심 영역의 경계와 대응 위치의 복원된 비 관심 영역 영상 의 경계의 서로 다른 필터링을 수행할 수 있다. 실시 예에 따라, 각 복원된 관심 영역에 대해, 해당 관심 영역 의 경계와 대응 위치의 복원된 비 관심 영역 영상의 경계의 픽셀 값의 차이에 따라, 암시적으로 필터링 방법을 결정할 수 있다. 실시 예에 따라, 특정 관심 영역에 대해, 필터링 방법(Filtering_RoI_flag, Filter_idx)을 부 호화기에서 전송받아, 필터링을 수행할 수 있다. 공간적 복원 수행기는 실시 예에 따라, 복호화된 영상 또는 복호화 및 관심 영역 기반 복원 영상과 부호화기로 부터 전송받은 공간적 리샘플링 과정에 사용된 정보 (일 예시로, 각 프레임의 공간적 샘플링 레이트 그리고/또 는 일련의 프레임 단위의 공간적 샘플링 레이트 등)를 이용하여 공간적 복원이 수행된 영상을 얻을 수 있다. 시간적 복원 수행기 실시 예에 따라, 상기 과정이 일부 또는 전체가 수행된 영상과 부호화기로부터 전송받은 시 간적 리샘플링 과정에 사용된 정보 (일 예시로, 시간적 샘플링 레이트 등)를 이용하여 시간적 복원이 수행된 영 상을 얻을 수 있다. 후처리 필터 수행기는 실시 예에 따라, 상기 과정이 일부 또는 전체가 수행된 영상에 대해, 필터링을 수행할 수 있다. 이때, 실시 예에 따라, 고정된 필터를 사용할 수 있고, 다수 개의 필터를 부호화기 및 복호화기의 약속에 의해 정의한 후, 부호화기로부터 필터 정보를 전송받아 필터링을 수행할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 디코딩 장치의 언패킹 수행부에 포함되는 구성요소들의 블록도이다. 본 개시의 일 실시 예에 따른 디코딩 장치(10b)는 인코딩 과정에서 패킹된 관심 영역들에 대해 언패킹을 수행하 여 원본 프레임 정보를 획득할 수 있다. 디코딩 장치(10b)의 언페킹 수행부는 관심 영역 언패킹 수행모듈, 괌심 영역 역변환 모듈, 및 관심 영역 리사이징 모듈을 포함할 수 있다. 도 11에 도식화된 언패킹 수행 과정의 순서 는 변경 및 생략될 수 있다. 언패킹 수행부는, 복원된 관심 영역 기반 처리된 영상을 입력받아 관심 영역에 대한 언패킹을 수행하고, 관심 영역을 역변환하고, 관심 영역의 리사이징 과정을 거쳐 복원된 관심 영역을 획득할 수 있다. 관심 영역 언패킹 수행 모듈은, 실시 예에 따라, 원본 영상 내 관심 영역이 존재하는 일부 영역의 정보 (RoI_exist_region_LT, RoI_exist_region_RB)를 전송받아, 해당 영역 내에서 언패킹을 수행할 수 있다. 관심 영역 언패킹 수행 모듈은, 실시 예에 따라, 각 관심 영역의 위치 정보(pos_RoI)를 전송받아, 각 프레임 내 관심 영역의 언패킹을 수행할 수 있다. 실시 예에 따라, 각 관심 영역의 위치 정보는 프레임 내의 x, y좌표를 파싱할 수 있고, 프레임 내의 CTU 인덱스를 파싱하고, 파싱한 인덱스로부터 유도한 CTU 내의 x, y좌표를 파싱하여 각 관심 영역의 원본 위치를 유도하여 언패킹을 수행할 수 있다. 실시 예에 따라, 일련의 프레임 그룹 단위로 각 관심 영역의 ID 별로 위치 정보 및 위치 정보 차분 값 정보(pos_RoI, pos_diff_coding)를 전송받아, 각 프레임 내 관심 영역의 언패킹을 수행할 수 있다. 실시 예에 따라, 각 관심 영역의 ID는 프레임 내 각각의 겹치지 않는 관심 영역마다 부여될 수 있고, 관심 영역이 존재하는 영역 전체에 1개의 ID가 부여될 수 있다. 실시 예에 따라, 위치 정보 차분 값은 프레임 사이의 관심 영역이 존재하는 CTU 인덱스 차분 값 및 x, y좌표의 차분값을 전송받아, 언패킹을 수행할 수 있다. 실시 예에 따라, 일련의 프레임 그룹 단위로 각 관심 영역의 ID 별로 플립 여부(Flip_RoI_flag)를 전송받아, 각 프레임 내 관심 영역의 언패킹을 수행할 수 있다. 관심 영역 역변환 모듈은, 실시 예에 따라, 일련의 프레임 그룹 단위로 각 관심 영역의 ID 별로 변환 정보 (Rotate_RoI_flag)를 전송받아, 각 관심 영역이 원본 관심 영역과 동일한 방향을 갖도록 변환을 수행할 수있다. 관심 영역 리사이징 모듈은, 실시 예에 따라, 언패킹 및 역변환이 수행된 관심 영역들에 대해, 부호화기에서 정 규화가 수행된 경우, 정규화 정보(Resize_RoI_flag, Hor_Resize_idx, Ver_Resize_idx)를 전송받아, 각 관심 영 역에 대해, 원본 관심 영역과 동일한 크기로 리사이징을 수행할 수 있다. 도 12는 본 개시의 일 실시 예에 따른 관심 영역을 언패킹하는 일 예시이다. 본 개시의 일 실시 예에 따른 디코딩 장치(10b)는 복원된 관심 영역 기반 처리된 영상을 입력 받아, 언패킹을 수행하여 복원된 관심 영역을 획득할 수 있다. 복원된 관심 영역 기반 처리된 영상은 인코딩 장치(10a)에 의해 영상 각 프레임마다 선택된 관심 영역들을 이용하여 각각의 새로운 프레임으로 재구성하는 패킹이 수행된 영상 이다. 도 12를 참조하면, (a)프레임은 좌측에 제1 관심 영역, 제2 관심 영역, 및 제3 관심 영역이 좌상단 측 에 패킹되어 있고, 패킹 정보를 인코딩 장치(10a)로부터 전송받아, 오른쪽과 같이 원본 영상 내 각 관심 영역의 위치, 크기 등을 복원할 수 있다. 패킹 정보는 각 관심 영역의 위치 정보를 포함하고, 위치 정보는 예를 들어 각 관심 영역의 ID 별로 위치 정보/위치 정보의 차분 값 정보일 수 있다. 실시 예에 따라 각 관심 영역의 위치 정보는 프레임 내의 x,y 좌표를 파싱할 수 있고, 프레임 내의 CTU 인덱스를 파싱하고, 파싱한 인덱스로부터 유 도한 CTU 내의 x,y 좌표를 파싱하여 각 관심 영역의 원본 위치를 유도하여 언패킹을 수행할 수 있다. (a)는 패 킹에 의해 원본 프레임 크기와 패킹 이후 프레임 크기가 상이하고, 프레임 원본 크기에 대한 정보를 언패킹을 수행할 수 있다. 실시 예에 따라, 각 관심 영역 사이 간격은 일정 픽셀 값일 수 있고, 해당 영역은 필터링이 적 용되어 있을 수 있고, 또는/및 각 관심 영역 경계의 대표 값으로 채워져있을 수 있다. (b)의 프레임은 원본 영상의 프레임 크기와 패킹 이후 프레임 크기가 동일하고, 각 관심 영역들의 위치 정보를 파싱하여 언패킹할 수 있다. (c)프레임은 각 관심 영역의 간격이 원본 영상과 동일하게 유지된채, 각 관심 영역의 x 좌표 및 y 좌표 중 가장 작은 두 값을 이용하여 프레임 좌상단 위치로 패킹되어 있어, 제1 관심 영역의 원본 위치 정보에 따라 제2 관심 영역 및 제3 관심 영역의 위치를 함께 언패킹할 수 있다. 도 12는 도 7 과정과 반대로 진행된다. (d)프레임은 각 관심 영역의 간격이 원본 영상과 동일하게 유지된 채, 패킹에 의해 원본 프레임 크기와 패킹 이 후 프레임 크기가 상이하고, 프레임 원본 크기에 대한 정보를 언패킹을 수행할 수 있다. 이는 프레임 원본 크기 와, 원본 프레임에서의 관심 영역이 존재하는 위치의 x 좌표 및 y 좌표를 이용하여 언패킹을 할 수 있다. 도 12 는 도 7 과정과 반대로 진행된다. 도 13은 본 개시의 일 실시 예에 따른 디코딩 장치가 관심 영역 기반 언패킹을 수행하는 방법을 나타내는 순서 도이다. 본 개시의 일 실시 예에 따른 디코딩 장치(10b)는 기계를 위한 영상 복호화를 수행할 수 있다. 디코딩 장치 (10b)는 내부 복호화 수행기, 관심 영역 기반 복원기, 공간적 복원 수행기, 시간적 복원 수행기, 및 후처리 필 터 수행기를 포함할 수 있다. 각 과정의 순서는 변경될 수 있고, 관심 영역 기반 복원기, 공간적 복원 수행기 및 시간적 복원 수행기의 순서는 영상의 부호화 과정에서 각 대응 과정이 수행된 순서의 역 순으로 수행될 수 있다. S1310 단계에서, 내부 복호화 수행기는 비트스트림을 입력 받아 영상 복호화를 수행하여 복원된 영상을 생성할 수 있다. 실시 예에 따라, 영상 복호화는 2D 비디오 복호화기(decoder)(AVC/H.264, HEVC/H.265, VVC/H.266, AV1, VP9, 등)를 이용할 수 있고, 하나 이상의 컨볼루션 레이어가 포함된 2D 비디오 복호화기를 이용할 수 있다. 실시 예에 따라, 복원된 영상의 색공간이 RGB444가 아닌 YUV420, YUV444, 등 중 하나인 경우, RGB444 공 간으로 암시적 또는/그리고 명시적으로 변환 후, 이후 영상 복호화 과정이 수행될 수 있다. 실시 예에 따라, 복원된 영상의 색공간을 다른 색공간으로 암시적 또는/그리고 명시적으로 변환 후, 이후 영상 복호화 과정이 수행될 수 있다. 내부 복호화 수행기는 영상 복호화 수행부 및 업샘플링 수행부를 포함할 수 있다. 내부 복호화 수행기는 비트스 트림을 입력받아 관심 영역 기반 처리된 영상과 비 관심 영역 영상에 대해 각각 영상 복호화 수행과 업샘플링을수행할 수 있다. 실시 예에 따라, 각 과정의 순서는 변경 및 생략될 수 있다. 실시 예에 따라, 관심 영역 기반 처리된 영상과 비 관심 영역 영상은 복호화 이후 샘플링 레이트(upsamp_ratio_RoIs, upsamp_ratio_nonRoIs)를 전송받아 각각 업샘플링을 수행할 수 있다. 실시 예에 따라, 각 영상에 대한 업샘플링 방법은 Bilinear upsampling, bilateral upsampling, nearest-neighbor upsampling, 하나 이상의 컨볼루션 레이어가 포함된 딥 뉴럴 네트워크 중 하나를 고정적으로 사용할 수 있다. 실시 예에 따라, 복원된 관심 영역 기반 처리된 영상의 프레임 수와 복원된 비 관심 영역 영상의 프레임 수는 서로 상이할 수 있다. S1320 단계에서, 관심 영역 기반 복원기는 실시 예에 따라, 복호화된 영상과 부호화기로부터 전송받은 관심 영 역 기반 처리 정보 (일 예시로, 관심 영역 ID 정보, 관심 영역의 크기 정보, 패킹 정보 등)를 이용하여 관심 영 역 기반 처리된 영상을 복원할 수 있다. 관심 영역 기반 복원기는 언패킹 수행부 및 영상 재구성부를 포함할 수 있다. 관심 영역 기반 복원 과정은, 복원된 비관심 영역 영상은 영상 재구성부의 입력으로 인가되고, 복원된 관 심 영역 기반 처리된 영상은 언패킹 수행부의 입력으로 인가된 후, 언패킹 수행부의 출력이 영상 재구성부의 입 력으로 인가될 수 있다. S1321 단계에서, 언패킹 수행부는 복원된 관심 영역 기반 처리된 영상을 입력받아 각 관심 영역에 대해, 회전 및 원본 관심 영역의 크기로 복원과 각 관심 영역의 원본 위치로의 언패킹을 수행할 수 있다. 실시 예에 따라, 일련의 프레임 그룹 단위로 패킹 여부(packing_flag)를 전송받아, 패킹이 수행된 경우, 언패킹 수행부를 통해 복원된 관심 영역을 얻을 수 있다. 언패킹 수행부의 상세한 동작은 도 11에서 후술하겠다. S1322 단계에서, 영상 재구성부는 언패킹이 수행된 복원된 관심 영역과 복원된 비 관심 영역 영상을 입력받아 원본 영상으로의 복원을 수행할 수 있다. 영상 재구성부는 영역 경계 필터링 수행 모듈을 포함할 수 있다. 실시 예에 따라, 복원된 관심 영역과 복원된 비 관심 영역 영상에 대해, 영역 경계 필터링 수행 모듈이 수행될 수 있 다. 실시 예에 따라, 복원된 비 관심 영역 영상은 복원된 관심 영역의 각 프레임마다 존재할 수 있고, 일련의 프레 임 그룹 단위마다 하나의 복원된 비 관심 영역 영상이 존재할 수 있다. (일 예시로, 각 GOP 단위의 Intra frame 에 대해서만 복원된 비 관심 영역 영상이 존재할 수 있다.) 실시 예에 따라, 복원된 비 관심 영역 영상이 일련의 프레임 그룹 단위마다 하나가 존재하는 경우, 각 복원된 관심 영역의 프레임에 대해, 동일한 복원된 비 관심 영역 영상을 이용하여 복원 영상을 생성할 수 있다. 실시 예에 따라, 각 복원된 관심 영역에 대해, 해당 관심 영역의 경계와 대응 위치의 복원된 비 관심 영역 영상 의 경계의 서로 다른 필터링을 수행할 수 있다. 실시 예에 따라, 각 복원된 관심 영역에 대해, 해당 관심 영역 의 경계와 대응 위치의 복원된 비 관심 영역 영상의 경계의 픽셀 값의 차이에 따라, 암시적으로 필터링 방법을 결정할 수 있다. 실시 예에 따라, 특정 관심 영역에 대해, 필터링 방법(Filtering_RoI_flag, Filter_idx)을 부 호화기에서 전송받아, 필터링을 수행할 수 있다. S1330 단계에서, 공간적 복원 수행기는 실시 예에 따라, 복호화된 영상 또는 복호화 및 관심 영역 기반 복원 영 상과 부호화기로부터 전송받은 공간적 리샘플링 과정에 사용된 정보 (일 예시로, 각 프레임의 공간적 샘플링 레 이트 그리고/또는 일련의 프레임 단위의 공간적 샘플링 레이트 등)를 이용하여 공간적 복원이 수행된 영상을 얻 을 수 있다. S1340 단계에서, 시간적 복원 수행기는 실시 예에 따라, 상기 과정이 일부 또는 전체가 수행된 영상과 부호화기 로부터 전송받은 시간적 리샘플링 과정에 사용된 정보 (일 예시로, 시간적 샘플링 레이트 등)를 이용하여 시간 적 복원이 수행된 영상을 얻을 수 있다. S1350 단계에서, 후처리 필터 수행기는 실시 예에 따라, 상기 과정이 일부 또는 전체가 수행된 영상에 대해, 필 터링을 수행할 수 있다. 이때, 실시 예에 따라, 고정된 필터를 사용할 수 있고, 다수 개의 필터를 부호화기 및 복호화기의 약속에 의해 정의한 후, 부호화기로부터 필터 정보를 전송받아 필터링을 수행할 수 있다. 도 14a 및 14b는 본 개시의 일 실시 예에 따른 패킹 정보에 대한 신택스(syntax)의 일 예시이다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 관심 영역에 대한 패킹 정보를 시그널링하여 디코딩 장치 (10b)에 전송할 수 있다. 도 14a 및 14b는 앞서 설명한 semantics에 따라 작성된 패킹 정보의 일 예시이다. 본 개시에 따른 신텍스에 대한 descriptor는 비디오 코덱(HEVC, VVC 등)의 표준 스펙에서 사용되는 descriptor(예 를 들어, context-adaptive arithmetic entropy-coded syntax element, unsigned integer 0-th order Exp-Golomb-coded syntax element 등)와 동일하다. 예를 들어, u(n)은 n 비트를 사용하는 부호 없는 정수(unsigned integer)를 나타내고, 신텍스 테이블에서 n이 “v”인 경우에는 비트 수는 다른 신텍스 구성요소의 값에 따라 달라지는 것을 나타낸다. 도 14a를 참조하면, 관심 영역 처리 여부를 나타내는 RoI_Processing_flag 값은 u로 설정되어 있고, 관심 영 역 처리가 된 관심 영역들에 대한 하나 이상의 정보를 구체화하고 있다. 도 14b를 참조하면, 위치 차분에 대한 값은 pos_diff_coding() 함수로 상세 정보를 저장 및 확인할 수 있다. 다양한 실시 예에서, 부/복호화기 간의 약속에 의해 semantics를 추가하거나, 변경 또는 삭제가 가능하다. 도 15는 본 개시의 일 실시 예에 따른 패킹 정보에 대한 신택스(syntax)의 일 예시이다. 본 개시의 일 실시 예에 따른 인코딩 장치(10a)는 관심 영역에 대한 패킹 정보를 시그널링하여 디코딩 장치 (10b)에 전송할 수 있다. 도 14는 앞서 설명한 semantics에 따라 작성된 패킹 정보의 일 예시이다. 도 15를 참조하면, 관심 영역 처리 여부를 나타내는 RoI_Processing_flag 값은 u로 설정되어 있고, 관심 영 역 처리가 된 관심 영역들에 대한 하나 이상의 정보를 구체화하고 있다. 다양한 실시 예에서, 부/복호화기 간의 약속에 의해 semantics를 추가하거나, 변경 또는 삭제가 가능하다. 본 명세서와 도면에 나타난 본 개시의 예시들은 본 개시의 기술 내용을 쉽게 설명하고 본 개시의 이해를 돕기 위해 특정 예를 제시한 것뿐이며, 본 명세서의 범위를 한정하고자 하는 것은 아니다. 지금까지 설명한 예시들 이외에도 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명한 것이다. 본 명세서에 기재된 청구항들은 다양한 방식으로 조합될 수 있다. 예를 들어, 본 명세서의 방법 청구항의 기술 적 특징이 조합되어 장치로 구현될 수 있고, 본 명세서의 장치 청구항의 기술적 특징이 조합되어 방법으로 구현 될 수 있다. 또한, 본 명세서의 방법 청구항의 기술적 특징과 장치 청구항의 기술적 특징이 조합되어 장치로 구 현될 수 있고, 본 명세서의 방법 청구항의 기술적 특징과 장치 청구항의 기술적 특징이 조합되어 방법으로 구현 될 수 있다."}
{"patent_id": "10-2024-0034736", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 비디오/영상 코딩 시스템의 예를 개략적으로 나타낸다. 도 2는 비디오/영상 인코딩 장치의 구성을 개략적으로 설명하는 도면이다. 도 3은 비디오/영상 디코딩 장치의 구성을 개략적으로 설명하는 도면이다. 도 4a 내지 도 4d는 VCM 인코더와 VCM 디코더를 나타낸 예시도들이다. 도 5는 본 개시의 일 실시 예에 따른 관심 영역 기반 패킹을 수행하는 인코딩 장치에 포함되는 구성요소들의 블 록도이다. 도 6은 본 개시의 일 실시 예에 따른 인코딩 장치의 관심 영역 기반 처리기에 포함되는 구성요소들의 블록도이 다. 도 7은 본 개시의 일 실시 예에 따른 관심 영역을 패킹하는 일 예시이다. 도 8은 본 개시의 일 실시 예에 따른 관심 영역의 크기를 정규화하는 일 예시이다. 도 9는 본 개시의 일 실시 예에 따른 인코딩 장치가 관심 영역 기반 패킹을 수행 방법을 나타내는 순서도이다. 도 10은 본 개시의 일 실시 예에 따른 관심 영역 기반 언패킹을 수행하는 디코딩 장치에 포함되는 구성요소들의 블록도이다. 도 11은 본 개시의 일 실시 예에 따른 디코딩 장치의 언패킹 수행부에 포함되는 구성요소들의 블록도이다. 도 12는 본 개시의 일 실시 예에 따른 관심 영역을 언패킹하는 일 예시이다. 도 13은 본 개시의 일 실시 예에 따른 디코딩 장치가 관심 영역 기반 언패킹을 수행하는 방법을 나타내는 순서 도이다. 도 14a 및 14b는 본 개시의 일 실시 예에 따른 패킹 정보에 대한 신택스(syntax)의 일 예시이다."}
