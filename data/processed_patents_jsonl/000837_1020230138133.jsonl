{"patent_id": "10-2023-0138133", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055622", "출원번호": "10-2023-0138133", "발명의 명칭": "대화를 수행하는 방법 및 장치", "출원인": "주식회사 자이냅스", "발명자": "강진범"}}
{"patent_id": "10-2023-0138133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자를 촬영한 이미지 및 상기 사용자에 의하여 입력된 제1 텍스트를 수신하는 단계;상기 이미지로부터 상기 사용자에 대응하는 시각 정보를 추출하는 단계; 및상기 제1 텍스트 및 상기 시각 정보가 변환된 제2 텍스트를 이용하여 상기 사용자의 문의 사항이 포함된 상기제1 텍스트에 최적화된 응답을 출력하는 단계;를 포함하고,상기 추출하는 단계는,이미지 및 텍스트 쌍으로 구성된 데이터셋을 통하여 사전 학습된 제1 모델을 이용하여 상기 시각 정보를 추출하는 대화를 수행하는 방법."}
{"patent_id": "10-2023-0138133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 시각 정보는,상기 사용자의 연령, 성별, 감정, 행동 및 상기 사용자가 착용한 물품 중 적어도 하나에 대한 정보를 포함하는방법."}
{"patent_id": "10-2023-0138133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 제1 텍스트는,상기 사용자가 입력한 텍스트 및 상기 사용자가 발화한 내용이 변환된 텍스트 중 적어도 하나를 포함하는 방법."}
{"patent_id": "10-2023-0138133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 출력하는 단계는,상기 시각 정보를 상기 제2 텍스트로 변환하는 단계;상기 제1 텍스트 및 상기 제2 텍스트 사이에 소정의 토큰(token)을 삽입함으로써 결합 데이터를 생성하는 단계;및상기 결합 데이터를 이용하여 스케일드 닷-프로덕트 어텐션(scaled dot-product attention) 연산 및 멀티 헤드어텐션(multi-head attention) 연산을 수행함으로써 상기 최적화된 응답을 생성하는 하는 방법."}
{"patent_id": "10-2023-0138133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 출력하는 단계는 사전 학습된 제2 모델을 이용하여 수행되는 방법."}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 측면에 따른 대면 대화를 수행하는 방법은, 사용자를 촬영한 이미지 및 상기 사용자에 의하여 입력된 제1 텍 스트를 수신하는 단계; 상기 이미지로부터 상기 사용자에 대응하는 시각 정보를 추출하는 단계; 및 상기 제1 텍 스트 및 상기 시각 정보가 변환된 제2 텍스트를 이용하여 상기 사용자의 문의 사항이 포함된 상기 제1 텍스트에 최적화된 응답을 출력하는 단계;를 포함한다."}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "대화를 수행하는 방법 및 장치에 관한다. 더욱 구체적으로, 사용자를 촬영한 이미지로부터 추출된 정보 및 사용 자가 입력한 문의 사항의 내용에 기초하여 최적화된 응답을 생성하는 방법 및 장치에 관한다."}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에 컴퓨터, 스마트 폰 등의 단말기를 이용하여 대화를 수행하는 서비스가 널리 보급되고 있다. 예를 들어, 채팅 창에 고객이 문의 사항을 텍스트로 입력하면, 문의 사항에 대한 응답을 채팅 창에 출력하는 채팅 서비스가 보급되고 있다. 한편, 인공지능 기술이 발전함에 따라, 채팅 서비스에도 인공지능 기술을 접목하려는 시도가 일어나고 있다. 예 를 들어, 고객이 입력한 문의 사항의 의도를 파악함으로써 응답을 출력하는 머신 러닝 기반의 채팅 서비스가 개 발되고 있다. 다만, 종래의 채팅 서비스는 텍스트 만에 기반하여 소통하는 것에 국한되므로, 사용자의 문의 사항에 대한 최적 화된 답변을 생성하는 것에 한계가 있다."}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "대면 대화를 수행하는 방법 및 장치를 제공하는 것에 있다. 또한, 상기 방법을 컴퓨터에서 실행시키기 위한 프 로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공하는 데 있다. 해결하려는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 따른 대면 대화를 수행하는 방법은, 사용자를 촬영한 이미지 및 상기 사용자에 의하여 입력된 제1 텍 스트를 수신하는 단계; 상기 이미지로부터 상기 사용자에 대응하는 시각 정보를 추출하는 단계; 및 상기 제1 텍 스트 및 상기 시각 정보가 변환된 제2 텍스트를 이용하여 상기 사용자의 문의 사항이 포함된 상기 제1 텍스트에 최적화된 응답을 출력하는 단계;를 포함한다. 상술한 방법에 있어서, 상기 추출하는 단계는, 이미지 및 텍스트 쌍으로 구성된 데이터셋을 통하여 사전 학습된 제1 모델을 이용하여 상기 시각 정보를 추출한다. 상술한 방법에 있어서, 상기 시각 정보는, 상기 사용자의 연령, 성별, 감정, 행동 및 상기 사용자가 착용한 물 품 중 적어도 하나에 대한 정보를 포함한다. 상술한 방법에 있어서, 상기 제1 텍스트는, 상기 사용자가 입력한 텍스트 및 상기 사용자가 발화한 내용이 변환 된 텍스트 중 적어도 하나를 포함한다. 상술한 방법에 있어서, 상기 출력하는 단계는, 상기 시각 정보를 상기 제2 텍스트로 변환하는 단계; 상기 제1 텍스트 및 상기 제2 텍스트 사이에 소정의 토큰(token)을 삽입함으로써 결합 데이터를 생성하는 단계; 및 상기 결합 데이터를 이용하여 스케일드 닷-프로덕트 어텐션(scaled dot-product attention) 연산 및 멀티 헤드 어텐 션(multi-head attention) 연산을 수행함으로써 상기 최적화된 응답을 생성한다. 상술한 방법에 있어서, 상기 출력하는 단계는 사전 학습된 제2 모델을 이용하여 수행된다. 다른 측면에 따른 컴퓨터로 읽을 수 있는 기록매체는 상술한 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기 록한 기록매체를 포함한다. 또 다른 측면에 따른 대면 대화를 수행하는 장치는 적어도 하나의 메모리; 및 적어도 하나의 프로세서;를 포함 하고, 상기 프로세서는, 사용자를 촬영한 이미지 및 상기 사용자에 의하여 입력된 제1 텍스트를 수신하고, 상기 이미지로부터 상기 사용자에 대응하는 시각 정보를 추출하고, 상기 제1 텍스트 및 상기 시각 정보가 변환된 제2 텍스트를 이용하여 상기 제1 텍스트에 최적화된 응답을 출력한다."}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "사용자에 의하여 입력된 텍스트 뿐 만 아니라 사용자를 나타내는 이미지로부터 추출된 정보를 함께 고려하여, 사용자의 문의 사항에 대한 응답을 생성한다. 사용자를 나타내는 정보를 함께 고려하여 응답을 생성하므로, 사 용자의 문의 사항에 대한 최적화된 응답을 생성할 수 있다. 또한, 사용자가 문의 사항을 입력한 의도를 파악하 기 위하여 수행되는 별도의 질문 및 답변 절차가 생략될 수 있다."}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시 예들에서 사용되는 용어는 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원 인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 명세서의 전반에 걸친 내용 을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"~ 유닛\", \"~ 모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 명세서에서 사용되는 \"제 1\" 또는 \"제 2\" 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명 하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나 의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 사용될 수 있다. 아래에서는 첨부한 도면을 참고하여 실시 예에 대하여 상세히 설명한다. 그러나 실시 예는 여러 가지 상이한 형 태로 구현될 수 있으며 여기에서 설명하는 예에 한정되지 않는다. 도 1은 일 실시예에 따른 대면 대화를 수행하는 방법의 일 예를 설명하기 위한 도면이다. 도 1을 참조하면, 대화 장치는 사용자의 문의 사항을 수신하고, 이에 대한 응답을 생성하여 출 력한다. 특히, 대화 장치는 사용자를 촬영한 이미지를 수신하고, 이미지로부터 추출된 시각 정 보와 문의 사항의 내용을 함께 고려하여 응답을 생성한다. 대화 서비스(채팅 서비스)는 일방의 문의 사항에 대하여 타방이 응답을 하는 서비스를 의미한다. 한편, 인공지 능 기술이 대화 서비스에 접목됨에 따라, 문의 사항에 대한 응답은 인공지능 모델에 의하여 생성될 수도 있다. 한편, 응답은 문의 사항의 내용에 따라 생성될 수 있으나, 이 경우 문의자가 원하는 최적의 응답이 되지 않을 수 있다. 예를 들어, 문의자가 20대 남성이고, 문의자가 여성 의류에 대한 문의 사항을 입력하였다고 가정하면, 문의 사항이 잘 못 기재되었거나, 문의자 자신이 아닌 다른 사람(예를 들어, 가족 등)을 위한 문의 사항일 수 있다. 이 경우, 문의 사항의 내용만을 기초로 하여 응답을 생성하는 경우 문의자가 원하는 응답이 아닐 수 있다. 일 실시예에 따른 대화 장치는 이미지로부터 추출된 시각 정보 및 문의 사항의 내용을 함께 고 려하여 응답을 생성한다. 대화 장치는 이미지를 분석함으로써 사용자의 연령, 성별, 감정, 행동, 사용자가 착용한 물품 등의 시각 정보를 추출한다. 그리고, 대화 장치는 문의 사항의 내용을 분석한다. 그리고, 대화 장치는 시각 정보와 문의 사항의 내용을 종합하여 응답을 생성한다. 따라서, 응답은 사용자에 관한 정보가 고려된 응답으로 생성된다. 한편, 일반적인 대화 서비스의 경우, 사용자의 정보 및 사용자가 문의 사항을 입력한 의도를 파악하기 위하여 수 회의 추가적인 질문 및 답변 절차가 진행된다. 다만, 일 실시예에 따른 대화 장치는 이미지로부터 사용자에 관한 정보를 추출하므로, 추가적인 질문 및 답변 절차가 수행됨이 없이 최적의 응답이 생성될 수 있다. 도 1에는 사용자가 남성 노인이고, 문의 사항이 자궁경부암에 대한 문의인 경우가 도시되어 있다. 이 경우, 대화 장치는, 문의 사항이 사용자에게 직접적인 관련이 없으며 다른 사람(예를 들어, 가족 등)을 위한 문의인지를 응답으로 생성할 수 있다. 즉, 대화 장치는 문의 사항의 내용 만을 고려한 응 답이 아닌 사용자에 관한 정보를 함께 고려한 응답을 생성할 수 있다. 이하, 도 2 내지 도 9를 참조하여, 대화 장치가 문의 사항에 대한 최적화된 응답을 출력하는 예를 상 세하게 설명한다. 도 2는 일 실시예에 따른 대면 대화를 수행하는 방법의 일 예를 설명하기 위한 흐름도이다. 210 단계에서, 대화 장치는 사용자를 촬영한 이미지 및 사용자에 의하여 입력된 제1 텍스트를 수신한다. 예를 들어, 이미지는 사용자의 현재 상태를 촬영한 이미지이거나, 기 촬영된 사용자의 이미지 일 수 있다. 이미 지는 스틸 이미지(still image)일 수도 있고, 무빙 이미지(moving image)일 수도 있다. 제1 텍스트는 문의 사항을 의미한다. 예를 들어, 제1 텍스트는 사용자가 입력 장치(예를 들어, 마우스, 키보드, 터치 스크린 등)를 통하여 직접 입력한 텍스트일 수 있다. 또는, 제1 텍스트는 사용자가 발화한 음성이 변환된 텍스트일 수도 있다. 예를 들어, 사용자의 발화 음성이 마이크를 통하여 입력되고, 입력된 발화 음성이 STT(Speech to Text) 변환을 거쳐 제1 텍스트로 생성될 수 있다. 이하, 도 3을 참조하여, 대화 장치가 이미지 및 제1 텍스트를 수신하는 일 예를 설명한다. 도 3은 일 실시예에 따른 대화 장치가 사용자로부터 이미지 및 문의 사항을 획득하는 일 예를 설명하기 위한 도 면이다. 도 3을 참조하면, 대화 장치는 이미지 및 제1 텍스트를 수신한다. 대화 장치는 메모리 및 프로세서를 포함하고, 데이터의 연산 능력을 갖는 장치일 수 있다. 예를 들어, 대화 장치는 데스크 탑 PC, 태블릿 PC, 노트북 PC, 스마트 폰, 웨어러블 디바이스, 키오스크(kiosk) 등이 해당될 수 있으나, 이에 한정되지 않는다. 한편, 대화 장치는 외부 디바이스(예를 들어, 서버 등)와 유선 또는 무선 통신으로 연결되어 상호 간에 데 이터를 송수신 할 수 있다. 이 경우, 대화 장치는 이미지 및 제1 텍스트를 수신하고, 이들을 외 부 디바이스로 전송할 수 있다. 외부 디바이스는 이미지 및 제1 텍스트를 분석하여 응답을 생성하고, 생성된 응답을 대화 장치로 전송할 수 있다. 그리고, 대화 장치는 수신된 응답을 출력할 수 있다. 이 때, 외부 디바이스가 응답을 생성하는 방법은 대화 장치가 응답을 생성하는 방법과 동일할 수 있다. 대화 장치가 응답을 생성하는 일 예는 220 단계 및 230 단계를 참조하여 후술한다. 이미지는 대화 장치에 구비된 카메라를 통하여 촬영될 수 있다. 일 예로서, 이미지는 사용 자의 현재 상태를 촬영한 스틸 이미지 또는 무빙 이미지일 수 있다. 다른 예로서, 이미지는 기 촬영 및 저장된 이미지일 수 있다. 이미지는 대화 장치의 디스플레이부의 일 영역에 표시될 수 있으나, 이 에 한정되지 않는다. 제1 텍스트는 대화 서비스를 통해서 입력된 사용자의 문의 사항을 의미한다. 일 예로서, 제1 텍스트 는 사용자가 대화 장치에 구비된 입력 장치를 통하여 직접 입력한 텍스트일 수 있다. 또는, 제1 텍스 트는 사용자가 발화한 음성이 변환된 텍스트일 수도 있다. 한편, 제1 텍스트는 디스플레이부의 일 영역에 표시될 수 있다. 또한, 제1 텍스트에 이어서 대화 장 치가 생성한 응답이 디스플레이부의 일 영역에 표시될 수 있다. 다시 도 2를 참조하면, 220 단계에서, 대화 장치는 이미지로부터 사용자에 대응하는 시각 정보를 추출한다. 예를 들어, 대화 장치는 이미지 및 텍스트 쌍으로 구성된 데이터셋을 통하여 사전 학습된 제1 모델을 이용 하여 시각 정보를 추출할 수 있다. 여기에서, 시각 정보는 사용자의 연령, 성별, 감정, 행동 및 상기 사용자가 착용한 물품 중 적어도 하나에 대한 정보를 포함할 수 있다. 이하, 도 4를 참조하여, 대화 장치가 제1 모델을 이용하여 시각 정보를 추출하는 예 및 제1 모델이 사전 학습되는 예를 설명한다. 도 4는 일 실시예에 따른 대화 장치가 이미지로부터 시각 정보를 추출하는 일 예를 설명하기 위한 도면이다. 도 4를 참조하면, 이미지 정보 추출 유닛은 이미지-텍스트 임베딩 모델 및 맵핑 네트워크 모델 를 포함한다. 이미지 정보 추출 유닛은 대화 장치에 포함되고, 이미지로부터 시각 정보를 추출한다. 맵핑 네트워크 모델은 이미지 임베딩 벡터(image embedding vector)와 텍스트 임베딩 벡터(text embedding vector)간의 매핑 정보를 포함한다. 사용자의 이미지는 맵핑 네트워크 모델에 입력되고, 이미지-텍스트 임베딩 모델로 전송된다. 그 리고, 이미지-텍스트 임베딩 모델은 이미지를 이미지 임베딩 벡터로 변환한다. 예를 들어, 이미 지 임베딩 벡터는 이미지에 대응하는 텍스트에 대한 정보를 포함할 수 있다. 구체적으로, 이미지-텍 스트 임베딩 모델은 이미지 임베딩 벡터가 텍스트에 대한 정보가 포함될 수 있도록 사전 학습될 수 있고, 이미지-텍스트 임베딩 모델이 사전 학습되는 예는 수학식 1을 참조하여 후술한다. 맵핑 네트워크 모델은 이미지 임베딩 벡터를 수신하고, 이미지 임베딩 벡터로부터 텍스트 임베 딩 가중치 값(text embedding weight value)을 예측한다. 그리고, 맵핑 네트워크 모델은 텍스트 임베딩 가중치 값을 시각 정보 변환부로 전송한다. 시각 정보 변환부의 동작 예는 도 6을 참조하여 후술한다. 한편, 맵핑 네트워크 모델은 이미지 및 텍스트 쌍으로 구성된 데이터셋을 통하여 사전 학습된다. 구체적으 로, 맵핑 네트워크 모델이 [이미지, 텍스트] 쌍으로 구성된 데이터셋으로 학습됨으로써, 입력된 이미지와 관련된 텍스트 임베딩 가중치 값이 예측될 수 있다. 예를 들어, 이미지와 텍스트는 각각 이미지 임베딩 벡터 및 텍스트 임베딩 벡터로 변환되어 학습에 이용된다. 구체적으로, 이미지는 이미지-텍스트 임베딩 모델을 통하여 이미지 임베딩 벡터로 변환된다. 예를 들어, 이미지-텍스트 임베딩 모델은 이미지 인코더 및 텍스트 인코더를 포함하고, 이미지 인코더 및 텍스트 인코더가 사전 학습됨에 따라 어떤 이미지가 어떤 텍스트와 쌍을 이루는지 예측될 수 있다. 구체적으로, 이미지가 입력되면, 이미지 인코더는 이미지를 이미지 임베딩 벡터로 변환하고, 이미지-텍스트 임 베딩 모델은 [이미지 임베딩 벡터, 텍스트 임베딩 벡터] 쌍을 예측한다. 반대로, 텍스트가 입력되면, 텍스 트 인코더는 텍스트를 텍스트 임베딩 벡터로 변환하고, 이미지-텍스트 임베딩 모델은 [텍스트 임베딩 벡터, 이미지 임베딩 벡터] 쌍을 예측한다. 예를 들어, 이미지-텍스트 임베딩 모델은 아래의 수학식 1에 기재된 contrastive loss를 사용하여 학습될 수 있으나, 이에 한정되지 않는다. 수학식 1"}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, X1은 이미지를 의미하고, f(X1)은 이미지 임베딩 벡터를 의미한다. 또한, X2는 텍스트를 의미하고, f(X2)는 텍스트 임베딩 벡터를 의미한다. 또한, 는 이미지 임베딩 벡터와 텍스트 임베딩 벡터 사이의 코사인 유사도(cosine similarity)를 의미한다. 또한, 는 이미지-텍스트 임베딩 모델(41 0)의 파라미터를 표시하는 기호를 의미한다. 는 X1과 X2가 동일한 데이터인지를 알려주는 라벨로서, 1 또 는 0으로 구성될 수 있다. 또한, m은 마진(margin)으로서 하이퍼파라미터 값을 의미한다. 텍스트 임베딩 벡터 및 이미지 임베딩 벡터는 연결(concatenation)되어 이미지- 맵핑 네트워크 모델의 입 력으로 사용된다. 맵핑 네트워크 모델은, 트랜스포머 디코더(transformer decoder)(도 6을 참조하여 후술함)가 다음 토큰을 예측한 결과 값과 원본 텍스트 사이의 차이가 줄어드는 방향으로, 자동 회귀(auto- regressive) 학습된다. 예를 들어, 맵핑 네트워크 모델은 아래의 수학식 2에 기재된 cross entropy loss 를 사용하여 학습될 수 있으나, 이에 한정되지 않는다. 수학식 2"}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서, p는 이미지-텍스트 임베딩 모델에서 생성된 이미지 임베딩 벡터를 의미하고, c는 트랜스포 머 인코더(transformer encoder)에 의하여 텍스트가 변환된 텍스트 임베딩 벡터를 의미한다. 여기에서, 트랜스 포머 인코더의 동작 예는 도 8을 참조하여 후술한다. 한편, 트랜스포머 인코더는 [텍스트 1, 텍스트 2, 응답] 쌍으로 구성된 데이터셋에 의하여 사전 학습될 수 있다. 예를 들어, 텍스트 1은 대화 장치가 동작하는 환경(예를 들어, 온라인, 오프라인)에서 맵핑 네트워 크 모델이 생성할 만한 문장으로 구성될 수 있다. 텍스트 2는 사용자가 물어볼 만한 질문(문의 사항)으로 구성될 수 있다. 응답은 원-핫 인코딩(one-hot encoding)되어 학습에 사용될 수 있다. 예를 들어, 트랜스포머 인코더는, 토크나이저(Tokenizer)에 의하여 인코딩된 텍스트 1 및 텍스트 2가 응답을 예 측하는 방법으로 학습이 진행될 수 있다. 이 때, 트랜스포머 인코더는 아래의 수학식 3에 기재된 categorical cross entropy loss를 사용하여 학습될 수 있으나, 이에 한정되지 않는다. 수학식 3"}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3에서, C는 클래스의 개수를 의미하고, N은 데이터의 수를 의미한다. 또한, t는 라벨의 값을 의미하며, y는 트랜스포머 인코더가 예측한 값을 의미한다. 다시 도 2를 참조하면, 230 단계에서, 대화 장치는 제1 텍스트 및 시각 정보가 변환된 제2 텍스트를 이용 하여 사용자의 문의 사항이 포함된 제1 텍스트에 최적화된 응답을 출력한다. 이 때, 대화 장치는 사전 학습된 제2 모델을 이용하여 최적화된 응답을 출력할 수 있다. 여기에서, 사전 학습된 제2 모델은 도 4를 참조하여 상술한 트랜스포머 인코더를 포함한다. 이하, 도 5 내지 도 8을 참조하여, 대화 장치가 제1 텍스트 및 제2 텍스트를 이용하여 최적화된 응답을 출 력하는 예를 구체적으로 설명한다. 도 5는 일 실시예에 따른 대화 장치가 문의 사항에 대한 최적화된 응답을 출력하는 일 예를 설명하기 위한 흐름 도이다. 510 단계에서, 대화 장치는 시각 정보를 제2 텍스트로 변환한다. 여기에서, 제2 텍스트는 이미지로부터 추출된 시각 정보를 나타내는 텍스트일 수 있다. 예를 들어, 시각 정보는 사용자의 연령, 성별, 감정, 행동, 사용자가 착용한 물품 등을 포함할 수 있으나, 이에 한정되지 않는다. 이하, 도 6을 참조하여 제2 텍스트가 생성되는 일 예를 설명한다. 도 6은 일 실시예에 따른 대화 장치가 시각 정보를 텍스트로 변환하는 일 예를 설명하기 위한 도면이다. 도 6을 참조하면, 시각 정보 변환 유닛은 대화 장치에 포함되고, 이미지로부터 추출된 시각 정보 를 제2 텍스트로 변환한다. 이 때, 이미지로부터 시각 정보가 추출되는 예는 도 4를 참조하여 상술한 바와 같다.시각 정보 변환 유닛은 시각 정보를 설명하는 제2 텍스트를 생성한다. 예를 들어, 시각 정보 변 환 유닛은 트랜스포머 디코더(transformer decoder) 및 토크나이저(Tokenizer)를 포함할 수 있으나, 이에 한정되지 않는다. 시각 정보 변환 유닛은 이미지 정보 추출 유닛으로부터 텍스트 임베딩 가중치 값을 수신한다. 그리고, 시각 정보 변환 유닛은 텍스트 임베딩 가중치 값을 이용하여 end-token이 생성될 때까지 신규 토 큰(token)들을 연속적으로 생성한다. 예를 들어, 새로운 토큰이 생성되는 방법은 Top-p Sampling, Top-k Sampling, Greedy Search, Beam Search 등이 있으나, 이에 한정되지 않는다. 여기에서, Top-p Sampling은 누적 확률이 확률 p(hyper-parameter)를 초과하는 단어만을 선별하는 방법을 의미하며, Top-k Sampling, Greedy Search, Beam Search는 통상의 기술자에게 자명한 방법이므로 구체적인 설명은 생략한다. 한편, 시각 정보 변환 유닛은 텍스트 임베딩 가중치 값으로부터 신규 토큰들을 생성하는 방식과 관련하여 사전 학습이 될 수 있다. 예를 들어, 시각 정보 변환 유닛에 포함된 토크나이저는 텍스트 임베딩 가중치 값으로부터 적절한 신규 토큰들이 생성될 수 있도록 사전 학습될 수 있고, 토크나이저의 사전 학습의 예는 도 3 을 참조하여 상술한 바와 같다. 시각 정보 변환 유닛은 신규 토큰들을 제2 텍스트로 변환한다. 예를 들어, 이미지가 웃고 있는 남성 노인을 촬영한 이미지라고 가정하면, 시각 정보 변환 유닛은 신규 토큰들을 이용하여 '한 남성 노인이 웃 고 있다'라는 제2 텍스트를 생성할 수 있다. 도 6에 도시된 제2 텍스트는 일 예에 불과하고, 동일한 이미지에 대해서도 추출된 시각 정보에 따라 다양한 제2 텍스트가 생성될 수 있다. 다시 도 5를 참조하면, 520 단계에서, 대화 장치는 제1 텍스트 및 제2 텍스트 사이에 소정의 토큰을 삽입 함으로써 결합 데이터를 생성한다. 이하, 도 7을 참조하여 결합 데이터가 생성되는 일 예를 설명한다. 도 7은 일 실시예에 따른 대화 장치가 결합 데이터를 생성하는 일 예를 설명하기 위한 도면이다. 도 7을 참조하면, 제1 텍스트 및 제2 텍스트가 소정의 토큰들(741, 742, 743)과 조합된 결합 데이터 의 예가 도시되어 있다. 결합 데이터는 도 8에 도시된 문장 검색 유닛에 의하여 생성될 수도 있 고, 대화 장치에 포함된 다른 유닛에 의하여 생성될 수도 있다. 예를 들어, 제1 텍스트와 제2 텍스트를 접목시키기 위하여, 토큰 'SEP'(742, 743)가 제1 텍스트 의 말미 및 제2 텍스트의 말미에 추가될 수 있다. 여기에서, 토큰 'SEP'(742, 743)는 결합 데이터 를 생성하기 위한 토큰의 일 예로서, 대화 장치의 설계에 따라 다른 토큰으로 대체될 수도 있다. 더 불어, 결합 데이터의 서두에는 토큰 'CLS'가 추가될 수 있다. 상술한 바에 의하여 생성된 결합 데이터는 문장 검색 유닛으로 전송되어 문자가 숫자로 변환된다. 다시 도 5를 참조하면, 530 단계에서, 대화 장치는 결합 데이터를 이용하여 스케일드 닷-프로덕트 어텐션 (scaled dot-product attention) 연산 및 멀티 헤드 어텐션(multi-head attention) 연산을 수행함으로써 최적 화된 응답을 생성한다. 이하, 도 8을 참조하여 최적화된 응답이 생성되는 일 예를 설명한다. 도 8은 일 실시예에 따른 대화 장치가 최적화된 응답을 생성하는 일 예를 설명하기 위한 도면이다. 도 8을 참조하면, 문장 검색 유닛은 대화 장치에 포함되고, 결합 데이터에 기초하여 최적화된 응답을 생성한다. 예를 들어, 문장 검색 유닛은 트랜스포머 인코더(transformer encoder) 및 토크나 이저(Tokenizer)를 포함할 수 있으나, 이에 한정되지 않는다. 문장 검색 유닛에 의하여 결합 데이터가 인코딩되면, 인코딩된 결합 데이터는 Token ID, PAD, SEP의 정보를 포함하게 된다. 여기에서, Token ID는 각각의 토큰별로 가지는 고유한 ID로서, 해당 문장에서 각 각의 토큰이 무엇인지 알려주는 역할을 한다. PAD는, 트랜스포머 인코더가 인코딩된 문장과 패딩(padding)을 구 분할 수 있도록 하는 역할을 한다. SEP는, 트랜스포머 인코더가 결합 데이터가 두 문장으로 구성되어 있는 지 여부를 판별할 수 있도록 하는 역할을 한다. 결합 데이터가 문장 검색 유닛에 전송되면, 트랜스포머 인코더에 의하여 스케일드 닷-프로덕트 어텐 션(scaled dot-product attention) 연산이 수행된다. 예를 들어, 트랜스포머 인코더는 총 12개의 인코더들로 구성되고, 각각의 인코더는 총 8개의 헤드(head)들로 구성될 수 있다. 이 헤드에서 스케일드 닷-프로덕트 어텐션 연산이 수행된다. 스케일드 닷-프로덕트 어텐션 연산을 통해서, 각각의 토큰이 어떤 토큰과 가장 연관성이 높은지 확인될 수 있으 며, 이에 따라 문맥 정보가 학습된다. 예를 들어, 스케일드 닷-프로덕트 어텐션 연산은 아래의 수학식 4에 의하 여 수행될 수 있다. 수학식 4"}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 4에서, Q는 쿼리 벡터(query vector), K는 키 벡터(key vector), V는 값 벡터(value vector)를 의미하 고, 는 키 벡터의 차원(dimension)을 의미한다. 상술한 바에 따라 각각의 헤드에서 수행된 스케일드 닷-프로 덕트 어텐션 연산 결과는 멀티-헤드 어텐션 연산을 통하여 연결(concatenation)된다. 예를 들어, 멀티-헤드 어 텐션 연산은 아래의 수학식 5에 의하여 수행될 수 있다. 수학식 5"}
{"patent_id": "10-2023-0138133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 5에서, 는 밀집 벡터(dense vector)로서, 차원을 정합시키는 기능을 한다. 문장 검색 유닛은 스케일드 닷-프로덕트 어텐션 연산의 결과를 softmax 함수에 적용하여 고유한 응답 ID(answer-ID)를 분류한다. 그리고, 문장 검색 유닛은 분류된 응답 ID 중에서 가장 점수(score)가 높은 응 답 ID에 대응하는 응답을 최적화된 응답으로 결정한다. 도 9는 일 실시예에 따른 대면 대화를 수행하는 장치의 일 예를 도시한 구성도이다. 도 9를 참조하면, 장치는 프로세서 및 메모리를 포함한다. 설명의 편의를 위하여, 도 9에는 본 발명과 관련된 구성요소들만이 도시되어 있다. 따라서, 도 9에 도시된 구성요소들 외에 다른 범용적인 구성요소 들이 장치에 더 포함될 수 있다. 또한, 도 9에 도시된 프로세서 및 메모리는 각각 독립된 장치 로 구현될 수도 있음은 본 발명과 관련된 기술 분야에서의 통상의 지식을 가진 자에게 자명하다. 장치는 대화 장치와 대응된다. 따라서, 장치는 도 1 내지 도 8을 참조하여 상술한 대화 장치 및 이에 포함된 유닛들이 수행하는 동작을 동일하게 수행한다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리할 수 있 다. 여기에서, 명령은 메모리 또는 외부 장치(예를 들어, 서버 등)로부터 제공될 수 있다. 또한, 프로세서 는 장치에 포함된 다른 구성요소들의 동작을 전반적으로 제어할 수 있다. 프로세서는 사용자를 촬영한 이미지 및 사용자에 의하여 입력된 제1 텍스트를 수신하고, 이미지로부터 사 용자에 대응하는 시각 정보를 추출할 수 있다. 그리고, 프로세서는 시각 정보를 제2 텍스트로 변환하고, 제1 텍스트 및 제2 텍스트를 이용하여 제1 텍스트에 최적화된 응답을 출력할 수 있다. 예를 들어, 프로세서는 제1 모델을 이용하여 이미지로부터 시각 정보를 추출할 수 있고, 제1 모델은 [이미 지, 텍스트] 쌍으로 구성된 데이터셋을 통하여 사전 학습될 수 있다. 예를 들어, 시각 정보는 사용자의 연령, 성별, 감정, 행동 및 사용자가 착용한 물품 중 적어도 하나에 대한 정 보를 포함할 수 있으나, 이에 한정되지 않는다. 예를 들어, 프로세서는 제1 텍스트 및 제2 텍스트 사이에 소정의 토큰을 삽입함으로써 결합데이터를 생성 할 수 있다. 그리고, 프로세서는 결합 데이터를 이용하여 스케일드 닷-프로덕트 어텐션(scaled dot- product attention) 연산 및 멀티 헤드 어텐션(multi-head attention) 연산을 수행함으로써 최적화된 응답을 생성할 수 있다. 이 때, 프로세서는 사전 학습된 제2 모델을 이용하여 최적화된 응답을 생성할 수 있고,제2 모델은 [텍스트 1, 텍스트 2, 응답] 쌍으로 구성된 데이터셋에 의하여 사전 학습될 수 있다. 프로세서는 다수의 논리 게이트들의 어레이로 구현될 수도 있고, 범용적인 마이크로 프로세서와 이 마이크 로 프로세서에서 실행될 수 있는 프로그램이 저장된 메모리의 조합으로 구현될 수도 있다. 예를 들어, 프로세서 는 범용 프로세서, 중앙 처리 장치(CPU), 마이크로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크 로제어기, 상태 머신 등을 포함할 수 한다. 일부 환경에서, 프로세서는 주문형 반도체(ASIC), 프로그램 가 능 로직 디바이스(PLD), 필드 프로그램 가능 게이트 어레이(FPGA) 등을 포함할 수도 있다. 예를 들어, 프로세서 는 디지털 신호 프로세서(DSP)와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, 디지털 신 호 프로세서(DSP) 코어와 결합된 하나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있다. 메모리는 비-일시적인 임의의 컴퓨터 판독 가능한 기록매체를 포함할 수 있다. 일 예로서, 메모리는 RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모 리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 다른 예로서, ROM, SSD, 플래시 메모리, 디스크 드라이브 등과 같은 비소멸성 대용량 저장 장치는 메모리와는 구분되는 별도의 영구 저장 장치일 수 있다. 또한, 메모리에는 운영체제(OS)와 적어도 하나의 프로그램 코 드(예를 들어, 도 1 내지 도 8을 참조하여 상술한 동작을 프로세서가 수행하기 위한 코드)가 저장될 수 있 다. 이러한 소프트웨어 구성요소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있 다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 장치에 직접 연결될 수 있는 기록 매체일 수 있고, 예를 들어, 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 또는, 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 모 듈을 통해 메모리에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 어플리케이션 의 설치 파일을 배포하는 파일 배포 시스템이 통신 모듈을 통해 제공하는 파일들에 의해 설치되는 컴퓨터 프로 그램(예를 들어, 도 1 내지 도 8을 참조하여 상술한 동작을 프로세서가 수행하기 위한 컴퓨터 프로그램 등)에 기반하여 메모리에 로딩될 수 있다. 상술한 바에 따르면, 사용자에 의하여 입력된 텍스트 뿐 만 아니라 사용자를 나타내는 이미지로부터 추출된 정 보를 함께 고려하여, 사용자의 문의 사항에 대한 응답을 생성한다. 사용자를 나타내는 정보를 함께 고려하여 응 답을 생성하므로, 사용자의 문의 사항에 대한 최적화된 응답을 생성할 수 있다. 또한, 사용자가 문의 사항을 입 력한 의도를 파악하기 위하여 수행되는 별도의 질문 및 답변 프로세스가 생략될 수 있다. 한편, 상술한 방법은 컴퓨터에서 실행될 수 있는 프로그램으로 작성 가능하고, 컴퓨터로 읽을 수 있는 기록매체 를 이용하여 상기 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 또한, 상술한 방법에서 사용 된 데이터의 구조는 컴퓨터로 읽을 수 있는 기록매체에 여러 수단을 통하여 기록될 수 있다. 상기 컴퓨터로 읽 을 수 있는 기록매체는 마그네틱 저장매체(예를 들면, 롬, 램, USB, 플로피 디스크, 하드 디스크 등), 광학적 판독 매체(예를 들면, 시디롬, 디브이디 등)와 같은 저장매체를 포함한다. 본 실시예와 관련된 기술 분야에서 통상의 지식을 가진 자는 상기된 기재의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 방법들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 하며, 권리 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점을 포함하는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0138133", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 대면 대화를 수행하는 방법의 일 예를 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 대면 대화를 수행하는 방법의 일 예를 설명하기 위한 흐름도이다. 도 3은 일 실시예에 따른 대화 장치가 사용자로부터 이미지 및 문의 사항을 획득하는 일 예를 설명하기 위한 도 면이다. 도 4는 일 실시예에 따른 대화 장치가 이미지로부터 시각 정보를 추출하는 일 예를 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 대화 장치가 문의 사항에 대한 최적화된 응답을 출력하는 일 예를 설명하기 위한 흐름 도이다. 도 6은 일 실시예에 따른 대화 장치가 시각 정보를 텍스트로 변환하는 일 예를 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 대화 장치가 결합 데이터를 생성하는 일 예를 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 대화 장치가 최적화된 응답을 생성하는 일 예를 설명하기 위한 도면이다. 도 9는 일 실시예에 따른 대면 대화를 수행하는 장치의 일 예를 도시한 구성도이다."}
