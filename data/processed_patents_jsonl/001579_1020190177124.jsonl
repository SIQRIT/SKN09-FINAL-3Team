{"patent_id": "10-2019-0177124", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0084129", "출원번호": "10-2019-0177124", "발명의 명칭": "로봇 청소기 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "송석훈"}}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇 청소기에 있어서,카메라;입력 이미지에서 오브젝트를 식별하도록 학습된 인공 지능 모델(Artificial Intelligence Model) 및 복수의 오브젝트 각각에 대응되는 형상 정보를 저장하는 메모리; 및상기 카메라 및 상기 메모리와 연결되어 상기 전자 장치를 제어하는 프로세서;를 포함하고,상기 프로세서는,상기 카메라에 의해 획득된 이미지를 상기 인공 지능 모델에 입력하여 상기 이미지에 포함된 오브젝트를 식별하고,상기 메모리에 저장된 상기 복수의 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정보를 획득하고,상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 로봇 청소기의 이동 경로를 설정하는,로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 메모리는, 상기 형상 정보 별 사이즈 정보를 더 저장하며, 상기 프로세서는, 상기 이미지에 기초하여 상기 형상 정보에 대응되는 사이즈 정보를 획득하거나, 상기 메모리에 저장된 사이즈정보에 기초하여 상기 형상 정보에 대응되는 사이즈 정보를 획득하는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 프로세서는,상기 오브젝트의 형상 정보에 기초하여 상기 오브젝트에 대응되는 평면 형상을 식별하고, 상기 오브젝트의 평면형상에 기초하여 상기 오브젝트를 회피하기 위한 상기 이동 경로를 설정하는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,장애물 감지 센서;를 더 포함하고,상기 프로세서는,상기 오브젝트에 대응되는 평면 형상 획득에 실패하면, 상기 장애물 감지 센서의 센싱 데이터에 기초하여 상기오브젝트를 회피하기 위한 상기 이동 경로를 설정하는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 메모리는,공개특허 10-2021-0084129-3-상기 복수의 오브젝트 별 회피 대상 여부에 대한 정보를 더 저장하고,상기 프로세서는,상기 회피 대상 여부에 대한 정보에 기초하여 상기 오브젝트가 회피 대상이 아닌 것으로 식별되면, 상기 오브젝트를 승월(climbing)하도록 상기 이동 경로를 설정하는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 오브젝트를 승월하는 동안 상기 로봇 청소기의 흡입 동작을 정지시키는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 메모리는, 제1 구역에 대응되는 오브젝트 별 제1 가중치 정보 및, 제2 구역에 대응되는 오브젝트 별 제2 가중치 정보를 더저장하며, 상기 프로세서는,상기 카메라에 의해 획득된 이미지에서 복수의 오브젝트가 식별되면, 상기 복수의 오브젝트 각각에 상기 제1 가중치 정보를 적용하여 제1 구역 예측 정보를 획득하고,상기 복수의 오브젝트 각각에 상기 제2 가중치 정보를 적용하여 제2 구역 예측 정보를 획득하며, 상기 제1 구역 예측 정보 및 상기 제2 구역 예측 정보에 기초하여 상기 로봇 청소기가 위치하는 구역을 상기 제1 구역 또는 상기 제2 구역 중 어느 하나로 식별하는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,통신 인터페이스;를 더 포함하며, 상기 프로세서는,상기 로봇 청소기가 위치하는 구역이 상기 제1 구역 또는 상기 제2 구역 중 어느 하나로 식별되면, 상기 식별된구역에 대한 식별 정보, 상기 식별된 구역에 대한 평면도 및 상기 구역에 위치한 상기 복수의 오브젝트 각각에대응되는 평면 형상을 외부 서버로 전송하도록 상기 통신 인터페이스를 제어하는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는,오브젝트를 인디케이팅하는 사용자 명령이 수신되면, 상기 이미지에서 식별된 오브젝트 중 상기 사용자 명령에대응되는 오브젝트를 식별하고,상기 로봇 청소기가 위치한 구역에 대한 평면도 및 상기 구역에 위치된 적어도 하나의 오브젝트에 대한 평면 형상에 기초하여 상기 로봇 청소기가 상기 식별된 오브젝트의 위치로 이동하도록 상기 로봇 청소기를 주행시키는,로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는,공개특허 10-2021-0084129-4-상기 메모리에 저장된 상기 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정보를 획득하고,상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 오브젝트 주변을 청소하기 위한 이동경로를 설정하는, 로봇 청소기."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "입력 이미지에서 오브젝트를 식별하도록 학습된 인공 지능 모델(Artificial Intelligence Model) 및 복수의 오브젝트 각각에 대응되는 형상 정보를 포함하는 로봇 청소기의 제어 방법에 있어서,카메라에 의해 획득된 이미지를 상기 인공 지능 모델에 입력하여 상기 이미지에 포함된 오브젝트를 식별하는 단계;상기 복수의 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정보를 획득하는 단계; 및상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 로봇 청소기의 이동 경로를 설정하는단계;를 포함하는 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 로봇 청소기는,상기 형상 정보 별 사이즈 정보를 더 포함하며,상기 형상 정보를 획득하는 단계는,상기 이미지에 기초하여 상기 형상 정보에 대응되는 사이즈 정보를 획득하거나, 상기 메모리에 저장된 사이즈정보에 기초하여 상기 형상 정보에 대응되는 사이즈 정보를 획득하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 이동 경로를 설정하는 단계는,상기 오브젝트의 형상 정보에 기초하여 상기 오브젝트에 대응되는 평면 형상을 식별하는 단계; 및 상기 오브젝트의 평면 형상에 기초하여 상기 오브젝트를 회피하기 위한 상기 이동 경로를 설정하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 이동 경로를 설정하는 단계는,상기 오브젝트에 대응되는 평면 형상 획득에 실패하면, 장애물 감지 센서의 센싱 데이터에 기초하여 상기 오브젝트를 회피하기 위한 상기 이동 경로를 설정하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 로봇 청소기는,상기 복수의 오브젝트 별 회피 대상 여부에 대한 정보를 더 포함하고,상기 이동 경로를 설정하는 단계는,상기 회피 대상 여부에 대한 정보에 기초하여 상기 오브젝트가 회피 대상이 아닌 것으로 식별되면, 상기 오브젝트를 승월(climbing)하도록 상기 이동 경로를 설정하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2021-0084129-5-제15항에 있어서,상기 오브젝트를 승월하는 동안 상기 로봇 청소기의 흡입 동작을 정지시키는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 로봇 청소기는,제1 구역에 대응되는 오브젝트 별 제1 가중치 정보 및, 제2 구역에 대응되는 오브젝트 별 제2 가중치 정보를 더저장하며,상기 카메라에 의해 획득된 이미지에서 복수의 오브젝트가 식별되면, 상기 복수의 오브젝트 각각에 상기 제1 가중치 정보를 적용하여 제1 구역 예측 정보를 획득하는 단계;상기 복수의 오브젝트 각각에 상기 제2 가중치 정보를 적용하여 제2 구역 예측 정보를 획득하는 단계; 및상기 제1 구역 예측 정보 및 상기 제2 구역 예측 정보에 기초하여 상기 로봇 청소기가 위치하는 구역을 상기 제1 구역 또는 상기 제2 구역 중 어느 하나로 식별하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 로봇 청소기가 위치하는 구역이 상기 제1 구역 또는 상기 제2 구역 중 어느 하나로 식별되면, 상기 식별된구역에 대한 식별 정보, 상기 식별된 구역에 대한 평면도 및 상기 구역에 위치한 상기 복수의 오브젝트 각각에대응되는 평면 형상을 외부 서버로 전송하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,오브젝트를 인디케이팅하는 사용자 명령이 수신되면, 상기 이미지에서 식별된 오브젝트 중 상기 사용자 명령에대응되는 오브젝트를 식별하는 단계; 및상기 로봇 청소기가 위치한 구역에 대한 평면도 및 상기 구역에 위치된 적어도 하나의 오브젝트에 대한 평면 형상에 기초하여 상기 로봇 청소기가 상기 식별된 오브젝트의 위치로 이동하도록 상기 로봇 청소기를 주행시키는단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 복수의 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정보를 획득하는 단계; 및상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 오브젝트 주변을 청소하기 위한 이동경로를 설정하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇 청소기가 개시된다. 로봇 청소기는 카메라, 입력 이미지에서 오브젝트를 식별하도록 학습된 인공 지능 모델 (Artificial Intelligence Model) 및 복수의 오브젝트 각각에 대응되는 형상 정보를 저장하는 메모리 및 상기 카메라 및 상기 메모리와 연결되어 상기 전자 장치를 제어하는 프로세서를 포함하고, 상기 프로세서는, 상기 카 메라에 의해 획득된 이미지를 상기 인공 지능 모델에 입력하여 상기 이미지에 포함된 오브젝트를 식별하고, 상기 메모리에 저장된 상기 복수의 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정보를 획득하고, 상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 로봇 청소기의 이동 경로를 설정한다."}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇 청소기 및 그 제어 방법에 관한 것으로, 더욱 상세하게는 로봇 청소기의 이동 경로를 설정하는 로봇 청소기 및 그 구동 방법에 관한 것이다."}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇 청소기는 사용자의 별도 조작 없이도, 스스로 주행하면서 이물질을 흡입함으로써, 청소하고자 하는 영역을 자동으로 청소하는 장치이다.로봇 청소기는 진행 방향에 산재한 장애물을 정확하고 효율적으로 감지하기 위하여 각종 센서를 구비한다. 로봇 청소기에 구비된 센서는 장애물의 위치 및 거리를 감지하고, 로봇 청소기는 감지 결과를 이용하여 진행 방향을 결정하게 된다. 종래에는, 가정 내에 다양한 유형의 장애물을 인식하는 방법 자체에 대해서만 연구가 진행되어왔을 뿐, 장애물 을 인식하여 이를 로봇 청소기의 이동 경로를 설정하기 위해 활용하는 구체적인 방법에 대해서는 연구가 다소 부족한 실정이다. 특히, 장애물을 인식하고, 장애물의 형태를 고려하여 로봇 청소기의 최적화된 이동 경로를 설정하기 위한 요구 가 있었다."}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 필요성에 따라 안출된 것으로, 본 발명의 목적은 장애물을 인식하여 로봇 청소기의 이동 경로 를 설정하는 로봇 청소기 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 로봇 청소기는, 카메라, 입력 이미지에서 오브 젝트를 식별하도록 학습된 인공 지능 모델(Artificial Intelligence Model) 및 복수의 오브젝트 각각에 대응되 는 형상 정보를 저장하는 메모리 및 상기 카메라 및 상기 메모리와 연결되어 상기 전자 장치를 제어하는 프로세 서를 포함하고, 상기 프로세서는, 상기 카메라에 의해 획득된 이미지를 상기 인공 지능 모델에 입력하여 상기 이미지에 포함된 오브젝트를 식별하고, 상기 메모리에 저장된 상기 복수의 형상 정보 중 상기 식별된 오브젝트 에 대응되는 형상 정보를 획득하고, 상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 로봇 청소기의 이동 경로를 설정한다. 여기서, 상기 메모리는, 상기 형상 정보 별 사이즈 정보를 더 저장하며, 상기 프로세서는, 상기 이미지에 기초 하여 상기 형상 정보에 대응되는 사이즈 정보를 획득하거나, 상기 메모리에 저장된 사이즈 정보에 기초하여 상 기 형상 정보에 대응되는 사이즈 정보를 획득할 수 있다. 또한, 상기 프로세서는, 상기 오브젝트의 형상 정보에 기초하여 상기 오브젝트에 대응되는 평면 형상을 식별하 고, 상기 오브젝트의 평면 형상에 기초하여 상기 오브젝트를 회피하기 위한 상기 이동 경로를 설정할 수 있다. 또한, 로봇 청소기는, 장애물 감지 센서를 더 포함하고, 상기 프로세서는, 상기 오브젝트에 대응되는 평면 형상 획득에 실패하면, 상기 장애물 감지 센서의 센싱 데이터에 기초하여 상기 오브젝트를 회피하기 위한 상기 이동 경로를 설정할 수 있다. 또한, 상기 메모리는, 상기 복수의 오브젝트 별 회피 대상 여부에 대한 정보를 더 저장하고, 상기 프로세서는, 상기 회피 대상 여부에 대한 정보에 기초하여 상기 오브젝트가 회피 대상이 아닌 것으로 식별되면, 상기 오브젝 트를 승월(climbing)하도록 상기 이동 경로를 설정할 수 있다. 여기서, 상기 프로세서는, 상기 오브젝트를 승월하는 동안 상기 로봇 청소기의 흡입 동작을 정지시킬 수 있다. 또한, 상기 메모리는, 제1 구역에 대응되는 오브젝트 별 제1 가중치 정보 및, 제2 구역에 대응되는 오브젝트 별 제2 가중치 정보를 더 저장하며, 상기 프로세서는, 상기 카메라에 의해 획득된 이미지에서 복수의 오브젝트가 식별되면, 상기 복수의 오브젝트 각각에 상기 제1 가중치 정보를 적용하여 제1 구역 예측 정보를 획득하고, 상 기 복수의 오브젝트 각각에 상기 제2 가중치 정보를 적용하여 제2 구역 예측 정보를 획득하며, 상기 제1 구역 예측 정보 및 상기 제2 구역 예측 정보에 기초하여 상기 로봇 청소기가 위치하는 구역을 상기 제1 구역 또는 상 기 제2 구역 중 어느 하나로 식별할 수 있다. 여기서, 로봇 청소기는, 통신 인터페이스를 더 포함하며, 상기 프로세서는, 상기 로봇 청소기가 위치하는 구역 이 상기 제1 구역 또는 상기 제2 구역 중 어느 하나로 식별되면, 상기 식별된 구역에 대한 식별 정보, 상기 식 별된 구역에 대한 평면도 및 상기 구역에 위치한 상기 복수의 오브젝트 각각에 대응되는 평면 형상을 외부 서버 로 전송하도록 상기 통신 인터페이스를 제어할 수 있다. 또한, 상기 프로세서는, 오브젝트를 인디케이팅하는 사용자 명령이 수신되면, 상기 이미지에서 식별된 오브젝트 중 상기 사용자 명령에 대응되는 오브젝트를 식별하고, 상기 로봇 청소기가 위치한 구역에 대한 평면도 및 상기 구역에 위치된 적어도 하나의 오브젝트에 대한 평면 형상에 기초하여 상기 로봇 청소기가 상기 식별된 오브젝트 의 위치로 이동하도록 상기 로봇 청소기를 주행시킬 수 있다. 여기서, 상기 프로세서는, 상기 메모리에 저장된 상기 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정 보를 획득하고, 상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 오브젝트 주변을 청소 하기 위한 이동 경로를 설정할 수 있다. 한편, 본 개시의 일 실시 예에 따른 입력 이미지에서 오브젝트를 식별하도록 학습된 인공 지능 모델(Artificial Intelligence Model) 및 복수의 오브젝트 각각에 대응되는 형상 정보를 포함하는 로봇 청소기의 제어 방법은, 카메라에 의해 획득된 이미지를 상기 인공 지능 모델에 입력하여 상기 이미지에 포함된 오브젝트를 식별하는 단 계, 상기 복수의 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정보를 획득하는 단계 및 상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 로봇 청소기의 이동 경로를 설정하는 단계를 포함한다. 여기서, 상기 로봇 청소기는, 상기 형상 정보 별 사이즈 정보를 더 포함하며, 상기 형상 정보를 획득하는 단계 는, 상기 이미지에 기초하여 상기 형상 정보에 대응되는 사이즈 정보를 획득하거나, 상기 메모리에 저장된 사이 즈 정보에 기초하여 상기 형상 정보에 대응되는 사이즈 정보를 획득하는 단계를 포함할 수 있다. 또한, 상기 이동 경로를 설정하는 단계는, 상기 오브젝트의 형상 정보에 기초하여 상기 오브젝트에 대응되는 평 면 형상을 식별하는 단계 및 상기 오브젝트의 평면 형상에 기초하여 상기 오브젝트를 회피하기 위한 상기 이동 경로를 설정하는 단계를 포함할 수 있다. 또한, 상기 이동 경로를 설정하는 단계는, 상기 오브젝트에 대응되는 평면 형상 획득에 실패하면, 장애물 감지 센서의 센싱 데이터에 기초하여 상기 오브젝트를 회피하기 위한 상기 이동 경로를 설정하는 단계를 포함할 수 있다. 또한, 상기 로봇 청소기는, 상기 복수의 오브젝트 별 회피 대상 여부에 대한 정보를 더 포함하고, 상기 이동 경 로를 설정하는 단계는, 상기 회피 대상 여부에 대한 정보에 기초하여 상기 오브젝트가 회피 대상이 아닌 것으로 식별되면, 상기 오브젝트를 승월(climbing)하도록 상기 이동 경로를 설정하는 단계를 포함할 수 있다. 여기서, 상기 오브젝트를 승월하는 동안 상기 로봇 청소기의 흡입 동작을 정지시키는 단계를 더 포함할 수 있다. 또한, 상기 로봇 청소기는, 제1 구역에 대응되는 오브젝트 별 제1 가중치 정보 및, 제2 구역에 대응되는 오브젝 트 별 제2 가중치 정보를 더 저장하며, 상기 카메라에 의해 획득된 이미지에서 복수의 오브젝트가 식별되면, 상 기 복수의 오브젝트 각각에 상기 제1 가중치 정보를 적용하여 제1 구역 예측 정보를 획득하는 단계, 상기 복수 의 오브젝트 각각에 상기 제2 가중치 정보를 적용하여 제2 구역 예측 정보를 획득하는 단계 및 상기 제1 구역 예측 정보 및 상기 제2 구역 예측 정보에 기초하여 상기 로봇 청소기가 위치하는 구역을 상기 제1 구역 또는 상 기 제2 구역 중 어느 하나로 식별하는 단계를 더 포함할 수 있다. 여기서, 제어 방법은, 상기 로봇 청소기가 위치하는 구역이 상기 제1 구역 또는 상기 제2 구역 중 어느 하나로 식별되면, 상기 식별된 구역에 대한 식별 정보, 상기 식별된 구역에 대한 평면도 및 상기 구역에 위치한 상기 복수의 오브젝트 각각에 대응되는 평면 형상을 외부 서버로 전송하는 단계를 더 포함할 수 있다. 또한, 제어 방법은, 오브젝트를 인디케이팅하는 사용자 명령이 수신되면, 상기 이미지에서 식별된 오브젝트 중 상기 사용자 명령에 대응되는 오브젝트를 식별하는 단계 및 상기 로봇 청소기가 위치한 구역에 대한 평면도 및 상기 구역에 위치된 적어도 하나의 오브젝트에 대한 평면 형상에 기초하여 상기 로봇 청소기가 상기 식별된 오 브젝트의 위치로 이동하도록 상기 로봇 청소기를 주행시키는 단계를 더 포함할 수 있다. 여기서, 제어 방법은, 상기 복수의 형상 정보 중 상기 식별된 오브젝트에 대응되는 형상 정보를 획득하는 단계 및 상기 형상 정보 및 상기 오브젝트와 관련된 사이즈 정보에 기초하여 상기 오브젝트 주변을 청소하기 위한 이 동 경로를 설정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 개시의 다양한 실시 예에 따르면, 장애물의 형태를 고려하여 로봇 청소기의 최적 이동 경 로를 설정할 수 있다.또한, 구역 내에 위치한 오브젝트 식별 결과에 기초하여 구역의 특성을 예측할 수 있다. 또한, 특정 오브젝트로 로봇 청소기를 이동시킬 수 있으며, 특정 오브젝트의 주변을 청소하도록 로봇 청소기를 제어할 수 있다. 또한, 오염 범위가 확대된 우려가 있는 오브젝트에 대해서는 회피 주행을 수행하도록 로봇 청소기를 제어할 수 있다."}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 로봇 청소기를 설명하기 위한 도면이다. 로봇 청소기는 전력에 의해 구동되어 자동으로 이물질을 흡입하기 위한 장치를 의미한다. 도 1에서는 로봇 청소기가 바닥 이물질을 흡입하기 위하여 바닥에 밀착되는 납작한 형태로 구현되는 경우를 상정하여 도시 하였으나 이는 일 실시 예에 불과할 뿐, 로봇 청소기는 다양한 형태 및 크기로 구현될 수 있다. 도 1를 참조하면, 본 개시의 일 실시 예에 따른 로봇 청소기는 카메라를 구비하여 로봇 청소기 에 인접하게 위치하는 오브젝트를 감지할 수 있다. 예를 들어, 로봇 청소기는 카메라를 통해 로봇 청 소기의 전방 이미지를 획득하고, 획득한 이미지에 기초하여 로봇 청소기의 주행 방향에 위치하는 오 브젝트를 식별할 수 있다. 여기서, 오브젝트는 로봇 청소기의 주행에 방해가 되거나, 로봇 청소기의 주행 간 구동 정지, 파손 또는 고장을 유발할 수 있는 각종 사물이나 상황을 의미할 수 있다. 예를 들어, 로봇 청소기가 가정집에서 구동되는 경우에, 오브젝트는 가구, 전가 기기, 러그(rug), 의류, 벽면, 계단, 문턱 (threshold) 등과 같이 다양할 수 있음은 물론이다. 본 개시의 일 실시 예에 따른 로봇 청소기는 식별된 오브젝트에 대한 정보에 기초하여 로봇 청소기의 이동 경로, 또는 주행 경로를 설정할 수 있다. 여기서, 식별된 오브젝트에 대한 정보는 오브젝트의 형상(또는, 형태) 정보 및 오브젝트와 관련된 사이즈 정보를 포함할 수 있다. 일 실시 예에 따른 로봇 청소기는 식별된 오브젝트에 대한 정보에 기초하여 로봇 청소기의 주행 간 해당 오브젝트를 회피하기 위한 이동 경로, 해당 오브젝트를 승월(climbing)(예를 들어, 해당 오브젝트 위를 타 고 넘어 주행)하기 위한 이동 경로 등을 설정할 수 있다. 이하에서는 로봇 청소기가 이동 경로를 설정하는 본 개시의 다양한 실시 예에 대해 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 로봇 청소기의 구성을 도시한 블록도이다. 도 2를 참조하면, 본 개시의 일 실시 예에 따른 로봇 청소기는 카메라, 메모리 및 프로세서 를 포함한다. 카메라는 로봇 청소기의 주변에 대한 하나 이상의 이미지를 획득하기 위한 구성이다. 카메라는 RGB 카메라, 3D 카메라 등으로 구현될 수 있다. 한편, 본 개시의 일 실시 예에 따른 로봇 청소기는 카메라 외에 감지 센서(미도시)를 추가적으로 더 포함할 수 있고, 로봇 청소기는 감지 센서의 센싱 데이터에 기초하여 오브젝트를 식별할 수도 있음은 물론 이다. 예를 들어, 감지 센서는 초음파 센서, 적외선 센서 등으로 구현될 수 있다. 일 실시 예에 따라 감지 센서 가 초음파 센서로 구현되는 경우, 로봇 청소기는 초음파 센사가 초음파 펄스를 방사하도록 제어할 수 있다. 이어서, 초음파 펄스가 물체에 반사되어 오는 반사파가 수신되면, 로봇 청소기는 그 사이의 경과 시 간을 계측하여 오브젝트와 로봇 청소기 간의 거리를 측정할 수 있다. 이 밖에, 초음파 센서는 초음파 근접 각 센서(ultrasonic proximity sensor)를 포함하여 다양한 방식으로 구현될 수도 있음은 물론이다. 적외선 센서 는 오브젝트가 가지고 있는 적외광 정보를 감지하는 소자이다. 로봇 청소기는 적외선 센서를 통해 획득한 적외광 정보에 기초하여 오브젝트를 식별할 수 있다.한편, 이에 한정되지 않으며, 감지 센서는 다양한 형태의 센서로 구현될 수 있다. 로봇 청소기는 감지 센 서의 센싱 데이터에 기초하여 오브젝트의 유무, 오브젝트의 위치, 오브젝트와의 거리 등을 분석하고, 분석 결과 에 기초하여 로봇 청소기의 이동 경로를 설정할 수 있다. 예를 들어, 로봇 청소기는 전방에 오브젝트 가 있다고 판단되면, 로봇 청소기는 로봇 청소기 자체를 우측 또는 좌측으로 회전시키거나, 후진시킬 수 있다. 메모리는 로봇 청소기를 구동시키기 위한 O/S(Operating System) 소프트웨어 모듈, 어플리케이션과 같은 다양한 데이터를 저장한다. 특히, 메모리에는 인공 지능 모델(Artificial Intelligence Model)이 저장될 수 있다. 구체적으로, 본 개 시의 일 실시 예에 따른 메모리는 입력 이미지에서 오브젝트를 식별하도록 학습된 인공 지능 모델이 저장 될 수 있다. 여기서, 인공 지능 모델은 다양한 오브젝트를 포함하는 복수의 샘플 이미지를 이용하여 학습된 모 델일 수 있다. 오브젝트를 식별한다는 것은, 오브젝트의 명칭, 종류 등 오브젝트에 대한 정보를 획득하는 것으 로 이해될 수 있다. 이 경우, 오브젝트에 대한 정보는, 해당 오브젝트를 식별한 인공 지능 모델이 출력하는 식 별된 오브젝트에 대한 정보일 수 있다 일 실시 예에 따른 인공 지능 모델은 인공지능 알고리즘 기반으로 복수의 영상에 기초하여 학습된 판단 모델로 서, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 학습된 판단 모델은 인간의 뇌 구조를 컴퓨터 상 에서 모의하도록 설계될 수 있으며 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 가지는 복수의 네트워 크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고 받는 뉴 런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 또한 학습된 판단 모델은, 일 예 로, 기계 학습(Machine Learning) 모델, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝(Deep Learning) 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면 서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 일 예로, 인공 지능 모델은 영상에 기초하여 학습된 CNN(Convolution Neural Network, 컨벌루션 신경망) 모델일 수 있다. CNN은 음성처리, 이미지 처리 등을 위해 고안된 특수한 연결구조를 가진 다층신경망이다. 한편, 인공 지능 모델은 CNN에 한정되지 않음은 물론이다. 예를 들어, 인공 지능 모델은 RNN(Recurrent Neural Network), LSTM(Long Short Term Memory Network), GRU(Gated Recurrent Units) 또는 GAN(Generative Adversarial Networks) 중 적어도 하나의 DNN(Deep Neural Network) 모델로 구현될 수 있다. 메모리에 저장된 인공지능 모델은, 다양한 학습 알고리즘을 통해 로봇 청소기 또는 별도의 서버/시스 템을 통해 학습된 것일 수 있다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)를 훈련시켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리 즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습 (semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘 은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 또한, 본 개시의 일 실시 예에 따른 메모리에는 복수의 오브젝트 각각에 대응되는 형상 정보가 저장될 수 있다. 여기서, 형상 정보는 해당 오브젝트의 대표 이미지, 오브젝트가 정형 오브젝트 또는 비정형 오브젝트에 해당하 는지에 대한 정보, 오브젝트를 다각도에서 바라본 이미지를 포함할 수 있다. 여기서, 오브젝트를 다각도에서 바라본 이미지는 오브젝트를 정면에서 바라본 이미지(예를 들어, 정면도(front view)), 오브젝트를 측면에서 바라본 이미지(예를 들어, 측면도(side view)), 오브젝트를 위에서 바라본 이미지 (예를 들어, 평면도(top view) 등을 포함할 수 있다. 다만, 이는 일 실시 예로서 이에 한정되지 않음은 물론이 다. 오브젝트의 대표 이미지는 오브젝트를 다각도에서 바라본 복수의 이미지 중 어느 하나를 의미할 수도 있고, 오브젝트에 이미지를 웹 크롤링(Web Crawling)하여 획득한 복수의 이미지 중 어느 하나를 의미할 수도 있음은 물론이다. 오브젝트가 정형 오브젝트 또는 비정형 오브젝트에 해당하는지에 대한 정보는 오브젝트가 변하지 않는 정형화된 형상 또는 고정된 형상(또는, 일정한 형태)을 가지는 오브젝트에 해당하는지, 또는 오브젝트가 고정된 형상을 가지지 않는 오브젝트에 해당하는지에 대한 정보를 의미할 수 있다. 예를 들어, 컵, 그릇 등은 고정된 형상을 가지는 정형 오브젝트에 해당하고, 액체류, 케이블(cable) 등은 고정된 형상을 가지지 않는 비정형 오브젝트에 해당할 수 있다. 복수의 오브젝트 각각에 대응되는 형상 정보에 대한 구체적인 설명은 도 5에서 추가적으로 하도록 한다. 프로세서는 로봇 청소기의 전반적인 동작을 제어한다. 일 실시 예에 따라 프로세서는 디지털 영상 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), AI(Artificial Intelligence) 프로세서, T-CON(Timing controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), 또는 커뮤니케이션 프로세서(communication processor(CP)), ARM 프로 세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고 리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 본 개시의 일 실시 예에 따른 프로세서는 카메라를 통해 획득된 이미지를 인공 지능 모델에 입력하여 이미지에 포함된 오브젝트를 식별할 수 있다. 이어서, 프로세서는 메모리에 저장된 복수의 오브젝트 각각에 대응되는 형상 정보 중 식별된 오브젝트에 대응되는 형상 정보를 획득할 수 있다. 이어서, 프로세서 는 획득된 형상 정보 및 오브젝트와 관련된 사이즈 정보에 기초하여 로봇 청소기의 이동 경로를 설정 할 수 있다. 이에 대한 구체적인 설명은 도 3을 참조하여 하도록 한다. 도 3은 본 개시의 일 실시 예에 따른 로봇 청소기의 이동 경로를 설명하기 위한 도면이다. 도 3을 참조하면, 본 개시의 일 실시 예에 따른 로봇 청소기는 가정집 내에서 동작할 수 있다. 로봇 청소 기에 구비된 카메라는 로봇 청소기의 주행 간 전방(또는, 기 설정된 방향)을 촬영하여 이미지를 획득할 수 있다. 이어서, 프로세서는 획득된 이미지를 인공 지능 모델에 입력하여 이미지에 포함된 오브젝 트, 예를 들어 로봇 청소기의 전방에 위치하는 오브젝트를 식별할 수 있다. 일 예로, 프로세서는 인 공 지능 모델을 이용하여 이미지에 포함된 화분(10-1)을 식별할 수 있다. 이어서, 프로세서는 복수의 형상 정보 중 화분(10-1)에 대응되는 형상 정보를 획득할 수 있다. 여기서, 오브젝트에 대응되는 형상 정보는 해당 오브젝트의 대표 이미지, 해당 오브젝트가 형상 또는 비형상 오 브젝트에 해당하는지에 대한 정보 등을 포함할 수 있다. 예를 들어, 화분(10-1)에 대응되는 형상 정보는 화분 (10-1)의 대표 이미지 및 화분(10-1)은 형상이 고정된 형상 오브젝트에 해당함을 나타내는 정보 등을 포함할 수 있다. 이어서, 프로세서는 카메라에 의해 획득된 이미지에 포함된 오브젝트 이미지에 기초하여 오브젝트의 사이즈 정보를 식별할 수 있다. 예를 들어, 프로세서는 오브젝트의 너비, 높이 정보를 식별할 수 있다. 도 3을 참조하면, 프로세서는 카메라에 의해 획득된 이미지에 포함된 화분(10-1) 이미지에 기초하여, 화 분(10-1)의 너비 및 높이 정보를 식별할 수 있다. 이어서, 프로세서는 식별된 오브젝트에 대응되는 형상 정보 및 오브젝트와 관련된 사이즈 정보에 기초하여 오브젝트의 실제 형상을 예측할 수 있다. 예를 들어, 식별된 오브젝트가 형상 오브젝트이면, 프로세서는 오브젝트에 대응되는 평면 형상을 식별할 수 있다. 이어서, 프로세서는 오브젝트의 평면 형상 및 오브젝트 의 사이즈 정보에 기초하여 오브젝트의 실제 형상 및 사이즈를 예측하고, 예측된 형상 및 사이즈에 기초하여 로 봇 청소기의 이동 경로를 설정할 수 있다. 여기서, 오브젝트의 평면 형상은 오브젝트를 다각도에서 바라본 복수의 이미지 중 오브젝트를 위에서 바라본 이미지(예를 들어, 평면도(top view))를 의미할 수 있다. 이에 대 한 구체적인 설명은 도 4를 참조하여 하도록 한다. 도 4는 본 개시의 일 실시 예에 따른 오브젝트에 대응되는 형상 정보를 설명하기 위한 도면이다. 도 4를 참조하면, 프로세서는 카메라를 통해 획득된 이미지에 기초하여 오브젝트를 식별할 수 있다. 예를 들어, 프로세서는 가정 내 침실 공간에 배치된 침대(10-2)를 식별할 수 있다. 이어서, 프로세서는 식별된 오브젝트에 대응되는 형상 정보를 획득할 수 있다. 도 4를 참조하면, 프로세서 는 메모리에 저장된 복수의 형상 정보 중 침대(10-2)에 대응되는 형상 정보를 획득할 수 있다. 특히, 프로세서는 형상 정보에 기초하여 오브젝트, 예를 들어, 침대(10-2)에 대응되는 평면 형상을 식별할 수 있 다. 여기서, 침대(10-2)에 대응되는 평면 형상은 침대(10-2)를 다각도에서 바라본 복수의 이미지 중 침대(10- 2)를 위에서 바라본 이미지(예를 들어, 평면도(top view))를 의미할 수 있다. 일 실시 예에 따른 프로세서는 오브젝트에 대응되는 사이즈 정보를 획득할 수 있다. 일 예로, 프로세서 는 메모리 저장된 형상 정보 별 사이즈 정보에 기초하여 식별된 오브젝트에 대응되는 사이즈 정보를 획득할 수 있다. 예를 들어, 메모리에는 침대(10-2)에 대응되는 형상 정보 별 복수의 사이즈 정보가 저장 될 수 있다. 프로세서는 카메라에 의해 획득된 이미지에 기초하여 침대(10-2)의 너비, 높이 또는 길 이 중 적어도 하나를 식별하고, 침대(10-2)의 형상 정보에 포함된 복수의 사이즈 정보 중 식별된 너비, 높이 또 는 길이 중 적어도 하나에 기초하여 침대(10-2)의 사이즈 정보를 획득할 수 있다. 한편, 이는 일 실시 예이며, 프로세서는 카메라에 의해 획득된 이미지에 기초하여 침대(10-2)의 너비, 높이 및 길이 등 침대(10-2)의 사이즈 정보를 획득할 수도 있음은 물론이다. 프로세서는 오브젝트에 대응되는 형상 정보에 기초하여 평면 형상을 식별하고, 식별된 평면 형상 및 오브 젝트의 사이즈 정보에 기초하여 실제 오브젝트의 평면 형상을 예측할 수 있다. 도 4를 참조하면, 프로세서(13 0)는 침대(10-2)에 대응되는 형상 정보에 기초하여 침대(10-2)의 평면 형상(예를 들어, 사각형)을 식별하고, 식 별된 평면 형상 및 침대(10-2)의 사이즈 정보에 기초하여 실제 침대(10-2)의 평면 형상(예를 들어, 실제 침대 (10-2)의 너비, 높이 및 길이)에 근접하도록 침대(10-2)의 평면 형상(또는, 평면도(top-view))를 예측(또는, 획 득)할 수 있다. 이어서, 프로세서는 오브젝트의 평면 형상에 기초하여 해당 오브젝트를 회피하기 위한 이동 경로를 설정할 수 있다. 예를 들어, 프로세서는 예측된 침대(10-2)의 평면 형상에 기초하여 침대(10-2)를 회피하여 공간 을 청소, 주행하기 위한 이동 경로를 설정할 수 있다. 일 실시 예에 따른, 로봇 청소기는 오브젝트를 감지하기 위한 별도의 센서 구비 없이도, 카메라를 통 해 획득된 이미지에 기초하여 오브젝트의 평면 형상을 실제 평면 형상에 근접하도록 예측하고, 예측된 평면 형 상에 기초하여 최적의 이동 경로를 설정할 수 있다. 한편, 본 개시의 일 실시 예에 따른 로봇 청소기는 식별된 오브젝트에 대한 정보에 기초하여 해당 오브젝 트를 회피하기 위한 이동 경로 외에도 해당 오브젝트를 승월(climbing)(예를 들어, 해당 오브젝트 위를 타고 넘 어 주행)하기 위한 이동 경로 등을 설정할 수 있다. 이에 대한 구체적인 설명은 도 5를 참조하여 하도록 한다. 도 5는 본 개시의 일 실시 예에 따른 오브젝트 별 형상 정보 및 회피 대상 여부에 대한 정보를 설명하기 위한 도면이다. 도 5를 참조하면, 본 개시의 일 실시 예에 따른 메모리에는 오브젝트 별 형상 정보 및 회피 대상 여부에 대한 정보가 저장될 수 있다. 예를 들어, 메모리에는 오브젝트의 종류, 오브젝트 별 대표 이미지, 오브젝트 별 오염 유발 여부 및 오브젝트 별 승월(climbing) 가능 여부에 대한 정보가 저장될 수 있다. 도 5는 오브젝트의 형상 정 보의 일 예시에 불과하며, 오브젝트의 형상 정보는 다양한 형태로 구현될 수 있음은 물론이다. 또한, 복수의 오 브젝트 각각에 대응되는 형상 정보는 외부 서버로부터 수신되어 메모리에 저장될 수도 있음은 물론이다. 도 5를 참조하면, 프로세서는 카메라에 의해 획득된 이미지에 기초하여 오브젝트를 식별하고, 식 별된 오브젝트에 대응되는 형상 정보를 획득할 수 있다. 예를 들어, 프로세서는 식별된 오브젝트 가 러그(rug)이면, 러그에 대응되는 형상 정보를 획득할 수 있다. 여기서, 러그에 대응되는 형상 정보는 러그의 대표 이미지, 러그의 정형 오브젝트 또는 비정형 오브젝트에 해당하는지에 대한 정보, 러그의 오염 유발 여부, 러그의 승월 가능 여부 등에 대한 정보를 포함할 수 있다. 여기서, 형상 정보에 포함된 승월 가능 여부에 대한 정보는 로봇 청소기의 주행 간 해당 오브젝트가 회피 대상 오브젝트에 해당하는지 또는 승월 대상 오브젝트(예를 들어, 타고 넘을 수 있는 오브젝트)에 해당하는지에 대한 정보를 포함할 수 있다. 도 5를 참조하면, 러그에 대응되는 형상 정보는 러그가 승월 가능한 오브젝트에 해당함을 나타내므로, 프로세서 는 식별된 오브젝트가 러그이면, 러그를 회피하는 것이 아니라, 승월하도록 이동 경로를 설정할 수 있다. 다른 예로, 프로세서는 식별된 오브젝트가 컵이면, 컵에 대응되는 형상 정보는 컵이 승월 가능한 오브젝트 에 해당하지 않음을 나타내므로, 컵을 회피하도록 로봇 청소기의 이동 경로를 설정할 수 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 식별된 오브젝트가 승월 가능한 오브젝트에 해당하면(또는, 회피 대상이 아닌 오브젝트에 해당하면), 해당 오브젝트를 승월하는 동안 로봇 청소기의 청소 모드를 변경할 수 있다.예를 들어, 로봇 청소기의 일반적인 청소 모드는 바닥 이물질, 오염 물질을 흡입하기 위해 흡입 동작을 수 행한다. 로봇 청소기가 식별된 오브젝트를 승월하는 동안 흡입 동작으로 인하여 오브젝트가 로봇 청소기 에 흡입된다면, 로봇 청소기의 구동 정지, 파손 또는 고장을 유발할 수 있으므로, 프로세서는 로봇 청소기가 오브젝트를 승월하는 동안 식별된 오브젝트에 기초하여 로봇 청소기의 청소 모드를 변경할 수 있다. 일 예로, 프로세서는 식별된 오브젝트를 승월하는 동안 로봇 청소기의 흡입 동작을 정지시 킬 수 있다. 다른 예로, 프로세서는 오브젝트를 승월하는 동안 로봇 청소기의 흡입 정도를 낮출 수도 있음은 물론이다. 도 6은 본 개시의 다른 실시 예에 따른 로봇 청소기의 이동 경로를 설명하기 위한 도면이다. 도 6을 참조하면, 본 개시의 일 실시 예에 따른 로봇 청소기는 장애물 감지 센서를 더 포함할 수 있다. 일 실시 예에 따라 프로세서는 오브젝트에 대응되는 평면 형상 획득에 실패하면, 장애물 감지 센서의 센싱 데 이터에 기초하여 오브젝트를 회피하기 위한 이동 경로를 설정할 수 있다. 예를 들어, 프로세서는 카메라에 의해 획득된 이미지를 인공 지능 모델에 입력하여 이미지에 포함된 오브젝트를 식별할 수 있다. 이어서, 프로세서는 오브젝트 별 복수의 형상 정보 중 식별된 오브젝트에 대 응되는 형상 정보를 획득할 수 있다. 여기서, 획득된 형상 정보는 식별된 오브젝트가 정형 오브젝트 또는 비정 형 오브젝트 중 어디에 해당하는지에 대한 정보를 포함할 수 있다. 일 실시 예에 따라 프로세서는 식별된 오브젝트가 비정형 오브젝트에 해당하면, 장애물 감지 센서의 센싱 데이터에 기초하여 해당 오브젝트를 회피하기 위한 이동 경로를 설정할 수 있다. 즉, 비정형 오브젝트는 형상이 고정되어 있지 않은 오브젝트를 의미하므로, 식별된 오브젝트가 비정형 오브젝트 이면, 프로세서는 식별된 오브젝트에 대한 평면 형상(즉, 평면도(top view))를 획득할 수 없다. 이 경우, 프로세서는 장애물 감지 센서의 센싱 데이터에 기초하여 식별된 오브젝트를 회피하기 위한 이동 경로를 설 정할 수 있다. 도 6을 참조하면, 케이블(10-3)은 비정형 오브젝트의 일 예시이다. 프로세서는 케이블(10-3)이 식별되면, 카메라에 의해 획득된 이미지 외에 장애물 감지 센서에 의해 획득된 센싱 데이터를 추가적으로 고려하여 케이블(10-3)을 회피하기 위한 이동 경로를 설정할 수 있다. 다만, 이는 일 실시 예로 이에 한정되지 않음은 물 론이다. 예를 들어, 프로세서는 식별된 오브젝트가 비정형 오브젝트에 해당하는 것으로 식별되면, 이미지 에 기초하여 해당 오브젝트의 너비, 높이 또는 길이 중 적어도 하나를 획득하여 최대 사이즈를 예측할 수 있다. 이어서, 프로세서는 해당 오브젝트에 대한 예측된 사이즈에 기초하여 이동 경로를 설정할 수 있다. 도 7은 본 개시의 다른 실시 예에 따른 로봇 청소기의 이동 경로를 설명하기 위한 도면이다. 도 7을 참조하면, 본 개시의 일 실시 예에 따른 프로세서는 식별된 오브젝트에 대응되는 형상 정보에 기초 하여 해당 오브젝트가 오염 유발의 우려가 있는 오브젝트에 해당하는지 여부를 식별할 수 있다. 도 5로 돌아가서, 메모리에는 오브젝트의 종류, 오브젝트 별 대표 이미지, 오브젝트 별 오염 유발 여부 및 오브젝트 별 승월(climbing) 가능 여부에 대한 정보가 저장될 수 있다. 여기서, 오브젝트 별 오염 유발 여부는 해당 오브젝트가 회피 대상 여부에 해당하지는 않으나, 로봇 청소기 가 해당 오브젝트를 승월하면 오염 범위가 확산될 우려가 있는지 여부를 의미할 수 있다. 예를 들어, 도 7을 참조하면, 액체류(10-4)는 회피 대상 오브젝트가 아니므로, 프로세서는 액체류(10-4)를 승월하여 주행하도록 로봇 청소기를 제어할 수 있다. 이 경우, 로봇 청소기의 하단에 위치하는 구동 부(예를 들어, 바퀴 등), 흡입부 등으로 인하여 공간 내에서 액체류(10-4)로 인한 오염 범위가 확산될 우려가 있다. 다른 예로, 애완동물의 배설물 등은 회피 대상 오브젝트는 아니나, 오염 유발이 우려되는 오브젝트 일 수 있다. 프로세서는 오브젝트의 형상 정보에 기초하여 오브젝트가 오염 유발 오브젝트로 식별되면, 해당 오브젝트 를 회피하기 위한 이동 경로를 설정할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 로봇 청소기가 위치하는 공간에 대한 평면도를 획득하는 방법을 설명하기 위한 도면이다. 도 8을 참조하면, 로봇 청소기는 맵 상의 구역들을 이동하면서 다양한 이미지를 촬영하고, 촬영된 이미지 를 복수의 인공지능 모델에 입력하여 구역 내에 위치하는 오브젝트들을 인식할 수 있다. 또한, 로봇 청소기는 공간을 복수의 구역으로 구분할 수 있다. 예를 들어, 로봇 청소기는 카메라 에 의해 획득된 이미지에 기초하여 바닥에 구분선 내지는 턱이 있는 지점, 이동 가능한 폭이 좁아지는 지 점, 벽이 있는 지점, 벽이 시작하는 지점, 벽이 끝나는 지점, 문이 있는 지점 등을 식별할 수 있다. 이어서, 프 로세서는 식별된 지점을 구역 간의 경계로 하여 공간(예를 들어, 가정집)을 복수의 구역(예를 들어, 거실, 침실, 화장실 또는 주방 등)으로 구분할 수 있다. 이하에서는 설명의 편의를 위해 구역이 하위 개념, 공간이 상 위 개념 즉, 구역의 집합을 의미하는 것으로 상정하여 설명하도록 한다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 복수의 구역 각각에 대응되는 구역 정보를 획득하기 위해 구역 내에 위치하는 오브젝트에 대한 정보를 이용할 수 있다. 여기서, 구역 정보는 복수의 구역 각각을 식별하 기 위한 정보를 의미할 수 있다. 구역 정보는, 복수의 구역 각각을 지칭하는 식별 명칭, 식별 번호 등으로 구성 될 수 있다. 또한, 구역 정보는, 복수의 구역 각각의 용도에 대한 정보를 포함할 수 있으며, 일 예로, 구역 정 보에 의해 복수의 구역은 각각 거실, 화장실, 침실 등으로 정의될 수도 있다. 또한, 오브젝트에 대한 정보는 오 브젝트의 명칭, 종류 등을 포함할 수 있다. 이에 대한 구체적인 설명은 도 9를 참조하여 하도록 한다. 도 9는 본 개시의 일 실시 예에 따른 로봇 청소기가 위치하는 공간에 대한 정보를 획득하는 방법을 설명하기 위 한 도면이다. 도 9를 참조하면, 본 개시의 일 실시 예에 따른 프로세서는 구역 내에서 식별된 오브젝트에 기초하여 해당 구역에 대응되는 구역 정보를 획득할 수 있다. 여기서, 구역 정보는 구역의 용도에 대한 정보, 구역의 명칭 등 을 포함할 수 있다. 예를 들어, 프로세서는 제1 구역에서 책장만이 식별되면, 제1 구역을 공부방으로 식별할 수 있다. 다른 예 로, 프로세서는 제2 구역에서 침대 및 책장이 식별되면, 제2 구역을 침실로 식별할 수 있다. 다만, 이는 일 예시들에 불과하다. 한편, 다른 예에 따라 제3 구역에서 TV만이 식별된 경우에 제3 구역은 공부방 또는 거실 등이 될 수도 있으므로 도 9에 도시된 바와 같은 표만을 이용하여 구역 정보를 획득하는 것은 신뢰도가 다소 떨 어지거나 불명확할 수 있다. 따라서, 본 개시의 일 실시 예에 따른 프로세서는 구역 별 가중치 정보를 이용하여 해당 구역에 대응되는 예측 정보를 획득할 수 있다. 일 실시 예에 따른 메모리에는 제1 구역에 대응되는 오브젝트 별 제1 가중치 정보 및, 제2 구역에 대응되 는 오브젝트 별 제2 가중치 정보가 저장될 수 있다. 가중치 정보는 하기의 표 1과 같은 형태일 수 있다. 표 1 j of Area i of k_obj.0 1 2 3 4 5 거실 공부방 방 주방 침실 화장실 0 에어컨 1 0.8 0.8 0.5 0.8 0.1 1 냉장고 0.2 0.1 0.1 1 0.1 0.1 2 TV 1 0.5 0.8 0.7 0.9 0.1 3 침대 0.2 0.2 0.5 0.1 1 0.1 4 소파 1 0.8 0.8 0.1 0.4 0.1 5 책장 0.8 1 0.7 0.1 0.3 0.1 6 세탁기 0.2 0.1 0.2 0.3 0.2 0.8 본 개시의 일 실시 예에 따른 프로세서는 구역 내에서 식별된 오브젝트에 표 1과 하기의 수학식 1을 이용 하여 복수의 구역 별 구역 예측 정보를 획득할 수 있다. [수학식 1] 일 예로, 프로세서는 카메라에 의해 획득된 이미지에서 복수의 오브젝트가 식별되면, 즉 특정 구역 내에서 복수의 오브젝트가 식별되면, 복수의 오브젝트 각각에 제1 가중치 정보를 적용하여 제1 공간 예측 정보를 획득 할 수 있다. 이어서, 프로세서는 복수의 오브젝트 각각에 제2 가중치 정보를 적용하여 제2 공간 예측 정보 를 획득할 수 있다. 예를 들어, 특정 구역에서 TV 및 소파가 식별된 경우를 상정할 수 있다. 이 경우, 프로세서는 표 1 및 수 학식 1에 기초하여 하기 표 2와 같이 복수의 구역 각각에 대응되는 구역 예측 정보를 획득할 수 있다. 표 2 j of Area i of k_obj.0 1 2 3 4 5 거실 공부방 방 주방 침실 화장실 0 에어컨 0 0 0 0 0 0 1 냉장고 0 0 0 0 0 0 2 TV 1 0.5 0.8 0.7 0.9 0.1 3 침대 0 0 0 0 0 0 4 소파 1 0.8 0.8 0.1 0.4 0.1 5 책장 0 0 0 0 0 0 6 세탁기 0 0 0 0 0 0 합계 2 1.3 1.6 0.8 1.3 0.2 TV와 소파는 타 구역 대비 상대적으로 거실 구역에 위치하는 경우가 많으므로, 거실에 대응되는 제1 가중치 정 보는 TV 및 소파에 높은 가중치를 부여하고, 세탁기 등에는 적은 가중치를 부여할 수 있다. 프로세서는 제1 구역 예측 정보 및 제2 구역 예측 정보에 기초하여 로봇 청소기가 위치하는 구역을 제1 구역 또는 제2 구역 중 어느 하나로 식별할 수 있다. 표 2를 참조하면, 특정 구역에서 TV 및 소파가 식별된 경우, 프로세서는 거실 구역에서 구역 예측 정보로 서 2를 획득하고, 화장실 구역에서 구역 예측 정보로서 0.2를 획득할 수 있다. 프로세서는 해당 특정 구역 을 거실 구역으로 식별할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 특정 오브젝트의 위치로 이동하는 로봇 청소기를 설명하기 위한 도면이다. 도 10을 참조하면, 본 개시의 일 실시 예에 따른 프로세서는 공간에 포함된 복수의 구역 각각에 구역 정보 를 부여할 수 있다. 예를 들어, TV 및 소파가 식별된 제1 구역을 거실로 식별하고, 세변대가 식별된 제2 구역을 화장실로 식별할 수 있다. 다른 예로, 화장대 및 침대가 식별된 제3 구역을 침실로 식별할 수 있다. 도 10에 도시된 구역에 대한 평면도 및 복수의 오브젝트에 대한 평면도를 공간의 맵 정보로 칭할 수 있다. 일 실시 예에 따른 로봇 청소기는 공간의 맵 정보를 서버로 전송할 수도 있고, 외부 장치(예를 들어, 사용자 단말 장치)로 전송하여 사용자에게 제공할 수도 있음은 물론이다. 한편, 본 개시의 일 실시 예에 따른 로봇 청소기는 사용자 명령을 수신할 수 있다. 일 예로, 사용자 명령 은 특정 오브젝트를 인디케이팅하는 명령일 수 있다. 여기서, 사용자 명령은 음성 명령, 텍스트 명령일 수도 있 고, 원격 제어 장치 또는 외부 장치로부터 수신되는 제어 명령을 의미할 수도 있음은 물론이다. 다른 예로, 사 용자 단말 장치가 공간의 맵 정보를 디스플레이하고, 로봇 청소기는 사용자 단말 장치를 통해 특정 오브젝 트를 인디케이팅하는 사용자 명령을 수신할 수도 있음은 물론이다. 일 예로, 프로세서는 특정 오브젝트를 인디케이팅하는 사용자 명령(예를 들어, “TV 주변 청소해줘”)이 수신되면, 공간의 맵 정보에 기초하여 사용자 명령에 대응되는 오브젝트의 위치를 식별할 수 있다. 예를 들어, 프로세서는 사용자 명령에 음성 인식을 수행하여 “TV 주변 청소해줘”에 포함된 TV를 식별할 수 있다. 이 어서, 프로세서는 구역에 대한 평면도 및 구역에 위치한 적어도 하나의 오브젝트에 대한 평면 형상에 기초 하여 공간 내에서 TV의 위치 정보를 획득할 수 있다. 이어서, 프로세서는 획득된 TV의 위치 정보에 기초하 여 로봇 청소기를 TV로 이동시킬 수 있다. 이어서, 프로세서는 사용자 명령에 따라 TV 주변을 청소하도록 로봇 청소기를 제어할 수 있다. 한편, 본 개시의 일 실시 예에 따른 프로세서는 로봇 청소기를 사용자 명령에 대응되는 오브젝트의 위치로 이동시켜 해당 오브젝트의 형상 정보에 기초하여 청소 동작을 수행할 수 있다. 예를 들어, 프로세서 는 사용자 명령에 대응되는 오브젝트의 형상 정보에 기초하여 해당 오브젝트를 회피하기 위한 최적의 이동 경로를 설정하고, 설정된 이동 경로에 기초하여 해당 오브젝트와의 충돌 없이(즉, 해당 오브젝트를 회피하여) 해당 오브젝트 주변을 청소하도록 로봇 청소기를 이동시킬 수 있다. 예를 들어, 프로세서는 사용자 명령에 따라 복수의 오브젝트 별 형상 정보에서 TV에 대응되는 형상 정보를 획득하고, TV에 대응되는 형상 정보에 기초하여 TV를 회피하기 위한 이동 경로를 획득할 수 있다. 이어서, 프로 세서는 TV를 회피하며 TV 주변을 효율적으로 청소하도록 로봇 청소기를 제어할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 로봇 청소기의 상세 블록도이다. 본 개시의 일 실시 예에 따른 로봇 청소기는 카메라, 메모리, 프로세서, 통신 인터페이스 및 사용자 인터페이스를 포함할 수 있다. 카메라는 RGB 카메라, 3D 카메라 등으로 구현될 수 있다. 3D 카메라는, TOF(Time Of Flight) 센서 및 적 외선 라이트를 포함하는 TOF 카메라로 구현될 수 있다. 3D 카메라는 IR 스테레오 센서를 포함할 수 있다. 카메 라는 CCD(Carge-Coupled Device), CMOS(Complementary Metal-Oxide Semiconductor) 등의 센서를 포함할 수 있으나, 이에 한정되는 것은 아니다. 카메라가 CCD를 포함하는 경우, CCD는 RGB(Red/Green/Blue) CCD, IR(Infrared) CCD 등으로 구현될 수 있다. 메모리는 입력 이미지에서 오브젝트를 식별하도록 학습된 인공 지능 모델을 저장할 수 있다. 한편, 메모리는 ROM, RAM(ex. DRAM(dynamic RAM), SDRAM(synchronous DRAM), DDR SDRAM(Double data rate SDRAM)) 등을 포함할 수 있으며, 하나의 칩 내에 프로세서와 함께 구현될 수도 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하 나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서 가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 디스플레이는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함하는 디스플레 이로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플 레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형태의 디스플레이 로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한편, 디스플레이는 터치 센서와 결합된 터치 스크린, 플렉시블 디스플레이(flexible display), 롤러블 디스 플레이(rollable display), 3차원 디스플레이(3D display), 복수의 디스플레이 모듈이 물리적으로 연결된 디스 플레이 등으로 구현될 수 있다. 프로세서는 상술한 다양한 실시 예에 따라 획득된 로봇 청소기의 상 태 정보를 출력하도록 디스플레이를 제어할 수 있다. 여기서, 상태 정보는, 로봇 청소기의 청소 모드, 배터리 관련 정보, 도킹 스테이션으로 복귀 여부 등 로봇 청소기의 구동에 관련된 다양한 정보 를 포함할 수 있다. 통신 인터페이스는, 로봇 청소기가 적어도 하나의 외부 장치와 통신을 수행하여 신호/데이터를 주고 받기 위한 구성이다. 이를 위해 통신 인터페이스는 회로를 포함할 수 있다. 통신 인터페이스는 무선 통신 모듈, 유선 통신 모듈 등을 포함할 수 있다. 무선 통신 모듈은 외부 서버 또는 외부 장치로부터 컨텐츠를 수신하기 위하여 와이파이 (WIFI) 통신 모듈, 블루 투스(bluetooth)모듈, 적외선 통신(IrDA, infrared data association)모듈, 3G(3세대) 이동통신 모듈, 4G(4세 대) 이동통신 모듈, 4세대 LTE(Long Term Evolution) 통신 모듈 중 적어도 하나를 포함을 포함할 수 있다. 유선 통신 모듈은 썬더볼트 포트, USB 포트 등의 유선 포트로 구현될 수 있다. 사용자 인터페이스는 하나 이상의 버튼, 키보드, 마우스 등을 포함할 수 있다. 또한, 사용자 인터페이스 는 디스플레이(도시되지 않음)와 함께 구현된 터치 패널 또는 별도의 터치 패드(도시되지 않음)를 포함할 수 있다. 사용자 인터페이스는 사용자의 명령 또는 정보를 음성으로 입력 받기 위해 마이크를 포함할 수도 있고, 사 용자의 명령 또는 정보를 모션 형태로 인식하기 위하여 카메라와 함께 구현될 수도 있다. 도 12는 본 개시의 일 실시 예에 따른 외부 서버와 통신을 수행하는 로봇 청소기를 설명하기 위한 도면이다. 도 11을 참조하면, 로봇 청소기는 스마트폰인 외부 장치들(300-1, 2) 및 서버 장치와 통신을 수행할 수 있다. 이 경우, 로봇 청소기는 공유기 등으로 구성된 중계 장치를 통해 외부 장치들(300-1, 300- 2, 300)과 통신을 수행할 수도 있다. 일 예로 프로세서는 로봇 청소기가 위치하는 구역이 제1 구역 또는 제2 구역 중 어느 하나로 식별되 면, 식별된 구역에 대한 식별 정보(예를 들어, 구역 정보), 식별된 구역에 대한 평면도 및 구역에 위치한 복수 의 오브젝트 각각에 대응되는 평면 형상을 외부 서버 또는 외부 장치(300-1, 300-2)로 전송하도록 통신 인터페 이스를 제어할 수 있다. 또한, 로봇 청소기는 스마트폰인 외부 장치(300-1) 또는 외부 장치(300-2)로부터 수신된 제어 신호에 따라 로봇 청소기가 위치하는 공간에 포함된 복수의 구역 중 어느 하나의 구역으로 이동하거나, 공간에 위치하 는 복수의 오브젝트 중 어느 하나의 오브젝트로 이동할 수 있다. 도 13은 본 개시의 일 실시 예에 따른 로봇 청소기의 제어 방법을 설명하기 위한 흐름도이다. 본 개시의 일 실시 예에 따른 입력 이미지에서 오브젝트를 식별하도록 학습된 인공 지능 모델(Artificial Intelligence Model) 및 복수의 오브젝트 각각에 대응되는 형상 정보를 포함하는 로봇 청소기의 제어 방법은, 우선 카메라에 의해 획득된 이미지를 인공 지능 모델에 입력하여 이미지에 포함된 오브젝트를 식별한다(S1310). 이어서, 복수의 형상 정보 중 식별된 오브젝트에 대응되는 형상 정보를 획득한다(S1320). 이어서, 형상 정보 및 오브젝트와 관련된 사이즈 정보에 기초하여 로봇 청소기의 이동 경로를 설정한다(S1330). 여기서, 로봇 청소기는, 형상 정보 별 사이즈 정보를 더 포함할 수 있다. 일 실시 예에 따른, 형상 정보를 획득 하는 S1320 단계는, 이미지에 기초하여 형상 정보에 대응되는 사이즈 정보를 획득하거나, 메모리에 저장된 사이 즈 정보에 기초하여 형상 정보에 대응되는 사이즈 정보를 획득하는 단계를 포함할 수 있다. 또한, 이동 경로를 설정하는 S1330 단계는, 오브젝트의 형상 정보에 기초하여 오브젝트에 대응되는 평면 형상을 식별하는 단계 및 오브젝트의 평면 형상에 기초하여 오브젝트를 회피하기 위한 이동 경로를 설정하는 단계를 포 함할 수 있다. 또한, 이동 경로를 설정하는 S1310 단계는, 오브젝트에 대응되는 평면 형상 획득에 실패하면, 장애물 감지 센서 의 센싱 데이터에 기초하여 오브젝트를 회피하기 위한 이동 경로를 설정하는 단계를 포함할 수 있다.또한, 로봇 청소기는, 복수의 오브젝트 별 회피 대상 여부에 대한 정보를 더 포함하고, 일 실시 예에 따른 이동 경로를 설정하는 S1330 단계는, 회피 대상 여부에 대한 정보에 기초하여 오브젝트가 회피 대상이 아닌 것으로 식별되면, 오브젝트를 승월(climbing)하도록 이동 경로를 설정하는 단계를 포함할 수 있다. 일 실시 예에 따른 제어 방법은 오브젝트를 승월하는 동안 로봇 청소기의 흡입 동작을 정지시키는 단계를 더 포 함할 수 있다. 또한, 로봇 청소기는, 제1 구역에 대응되는 오브젝트 별 제1 가중치 정보 및, 제2 구역에 대응되는 오브젝트 별 제2 가중치 정보를 더 저장하며, 일 실시 예에 따른 제어 방법은, 카메라에 의해 획득된 이미지에서 복수의 오 브젝트가 식별되면, 복수의 오브젝트 각각에 제1 가중치 정보를 적용하여 제1 구역 예측 정보를 획득하는 단계, 복수의 오브젝트 각각에 제2 가중치 정보를 적용하여 제2 구역 예측 정보를 획득하는 단계 및 제1 구역 예측 정 보 및 제2 구역 예측 정보에 기초하여 로봇 청소기가 위치하는 구역을 제1 구역 또는 제2 구역 중 어느 하나로 식별하는 단계를 더 포함할 수 있다. 일 실시 예에 따른 제어 방법은, 로봇 청소기가 위치하는 구역이 제1 구역 또는 제2 구역 중 어느 하나로 식별 되면, 식별된 구역에 대한 식별 정보, 식별된 구역에 대한 평면도 및 구역에 위치한 복수의 오브젝트 각각에 대 응되는 평면 형상을 외부 서버로 전송하는 단계를 더 포함할 수 있다. 또한, 일 실시 예에 따른 제어 방법은, 오브젝트를 인디케이팅하는 사용자 명령이 수신되면, 이미지에서 식별된 오브젝트 중 사용자 명령에 대응되는 오브젝트를 식별하는 단계 및 로봇 청소기가 위치한 구역에 대한 평면도 및 구역에 위치된 적어도 하나의 오브젝트에 대한 평면 형상에 기초하여 로봇 청소기가 식별된 오브젝트의 위치 로 이동하도록 로봇 청소기를 주행시키는 단계를 더 포함할 수 있다. 일 실시 예에 따른 제어 방법은, 복수의 형상 정보 중 식별된 오브젝트에 대응되는 형상 정보를 획득하는 단계 및 형상 정보 및 오브젝트와 관련된 사이즈 정보에 기초하여 오브젝트 주변을 청소하기 위한 이동 경로를 설정 하는 단계를 포함할 수 있다. 다만, 본 개시의 다양한 실시 예들은 로봇 청소기뿐 아니라, 이동이 가능한 모든 전자 장치에 적용될 수 있음은 물론이다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트 웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 로봇 청소기의 프로세싱 동작을 수행하기 위한 컴퓨터 명령어 (computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저 장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 디스플레이 장치에서의 처리 동작을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2019-0177124", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0177124", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 로봇 청소기를 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 로봇 청소기의 구성을 도시한 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 로봇 청소기의 이동 경로를 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 오브젝트에 대응되는 형상 정보를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 오브젝트 별 형상 정보 및 회피 대상 여부에 대한 정보를 설명하기 위한 도면이다. 도 6은 본 개시의 다른 실시 예에 따른 로봇 청소기의 이동 경로를 설명하기 위한 도면이다. 도 7은 본 개시의 다른 실시 예에 따른 로봇 청소기의 이동 경로를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 로봇 청소기가 위치하는 공간에 대한 평면도를 획득하는 방법을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 로봇 청소기가 위치하는 공간에 대한 정보를 획득하는 방법을 설명하기 위 한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 특정 오브젝트의 위치로 이동하는 로봇 청소기를 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시 예에 따른 로봇 청소기의 상세 블록도이다. 도 12는 본 개시의 일 실시 예에 따른 외부 서버와 통신을 수행하는 로봇 청소기를 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시 예에 따른 로봇 청소기의 제어 방법을 설명하기 위한 흐름도이다."}
