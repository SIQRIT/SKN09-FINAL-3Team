{"patent_id": "10-2023-0035765", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0120615", "출원번호": "10-2023-0035765", "발명의 명칭": "보행자의 위치를 결정하는 방법 및 장치", "출원인": "포티투닷 주식회사", "발명자": "서지원"}}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "보행자의 위치를 결정하는 방법에 있어서,카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 상기 차량 외부에 대한 복수의 레이더 측정값을 획득하는 단계;상기 복수의 이미지에 포함된 보행자 객체를 결정하는 단계;상기 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 상기 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후보값을 결정하는 단계;상기 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택하는 단계; 및상기 선택된 레이더 측정값에 기초하여 상기 보행자 객체의 최종 종방향 위치값을 결정하는 단계;를 포함하되,상기 복수의 이미지는 이전 이미지 및 현재 이미지를 포함하고,상기 최종 종방향 위치값을 결정하는 단계는,상기 이전 이미지에 대한 상기 보행자 객체의 제1 최종 종방향 위치값을 획득하는 단계;상기 현재 이미지에 대한 선택된 레이더 측정값을 획득하는 단계; 및 상기 제1 최종 종방향 위치값과 상기 선택된 레이더 측정값이 소정 거리 이내인 경우, 상기 선택된 레이더 측정값에 기초하여 상기 현재 이미지에 대한 제2 최종 종방향 위치값을 결정하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 복수의 객체 크기 후보값은 보행자가 가질 수 있는 신장(height) 범위를 소정의 간격으로 나눈 값인 것인,방법."}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 종방향 위치 후보값을 결정하는 단계는,상기 객체 크기 후보값, 상기 객체의 픽셀값 및 상기 카메라의 초점 거리(focal length)를 이용하여 상기 종방향 위치 후보값을 결정하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 레이더 측정값을 선택하는 단계는,상기 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값의 개수가 제1 임계값 이하 또는 제2임계값 이상인 경우, 상기 레이더 측정값을 선택하지 않는 단계;를 포함하고, 공개특허 10-2023-0120615-3-상기 제1 임계값은 상기 제2 임계값 보다 작은 값인, 방법."}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 보행자 객체의 최종 종방향 위치값을 결정하는 단계는,상기 선택된 레이더 측정값으로부터 도플러 속도를 산출하는 단계; 및상기 도플러 속도가 보행자가 가질 수 있는 속도 범위 이내인 경우, 상기 선택된 레이더 측정값에 기초하여 상기 보행자 객체의 최종 종방향 위치값을 결정하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "보행자의 위치를 결정하기 위한 장치에 있어서,적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써 연산을 수행하는 프로세서를 포함하고,상기 프로세서는,카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 상기 차량 외부에 대한 복수의 레이더 측정값을 획득하고, 상기 복수의 이미지에 포함된 보행자 객체를 결정하고,상기 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 상기 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후보값을 결정하고,상기 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택하며,상기 선택된 레이더 측정값에 기초하여 상기 보행자 객체의 최종 종방향 위치값을 결정하되,상기 복수의 이미지는 이전 이미지 및 현재 이미지를 포함하고,상기 최종 종방향 위치값을 결정하는 것은,상기 이전 이미지에 대한 상기 보행자 객체의 제1 최종 종방향 위치값을 획득하고,상기 현재 이미지에 대한 선택된 레이더 측정값을 획득하고,상기 제1 최종 종방향 위치값과 상기 선택된 레이더 측정값이 소정 거리 이내인 경우, 상기 선택된 레이더 측정값에 기초하여 상기 현재 이미지에 대한 제2 최종 종방향 위치값을 결정하는, 장치."}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "보행자의 위치를 결정하는 방법에 있어서,카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 상기 차량 외부에 대한 복수의 레이더 측정값을 획득하는 단계;상기 이미지에 포함된 보행자 객체를 결정하는 단계;상기 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 상기 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후보값을 결정하는 단계;상기 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택하는 단계;상기 선택된 레이더 측정값으로부터 도플러 속도를 산출하는 단계;상기 이미지 내 상기 보행자 객체의 팔다리 움직임에 기초하여, 상기 보행자 객체의 중간 상태를 결정하는단계; 및공개특허 10-2023-0120615-4-상기 도플러 속도가 소정의 값 이상이거나, 상기 보행자 객체의 중간 상태가 이동인 경우, 상기 보행자 객체의최종 상태를 이동으로 결정하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2023-0035765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "보행자의 위치를 결정하기 위한 장치에 있어서,적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써 연산을 수행하는 프로세서를 포함하고,상기 프로세서는,카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 상기 차량 외부에 대한 복수의 레이더 측정값을 획득하고, 상기 이미지에 포함된 보행자 객체를 결정하고,상기 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 상기 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후보값을 결정하고,상기 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택하며,상기 선택된 레이더 측정값으로부터 도플러 속도를 산출하고,상기 이미지 내 상기 보행자 객체의 팔다리 움직임에 기초하여, 상기 보행자 객체의 중간 상태를 결정하고,상기 도플러 속도가 소정의 값 이상이거나, 상기 보행자 객체의 중간 상태가 이동인 경우, 상기 보행자 객체의최종 상태를 이동으로 결정하는, 장치."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 보행자의 위치를 결정하기 위한 방법 및 장치에 관한 것이다. 본 개시의 일 실시 예에 따른 방법은, 카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 차량 외부에 대한 복수의 레이더 측정값을 획득할 수 있다. 또한, 방법은, 이미지에 포함된 보행자 객체를 결정하고, 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후보값을 결정할 수 있다. 또 한, 방법은, 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택하고, 선택된 레이더 측 정값에 기초하여 보행자 객체의 최종 종방향 위치값을 결정할 수 있다."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 보행자의 위치를 결정하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술과 차량 산업의 융합으로 인해 빠르게 차량의 스마트화가 진행되고 있다. 스마트화로 인해, 차량 은 단순한 기계적 장치에서 스마트카로 진화하고 있으며, 특히 스마트카의 핵심기술로 자율 주행이 주목 받고 있다. 자율 주행이란 운전자가 핸들과 가속페달, 브레이크 등을 조작하지 않아도 차량 스스로 목적지까지 찾아 가는 기술이다. 자율 주행 과정에서 보행자를 인식하고, 차량과 보행자 간의 거리를 산출하는 방법에 대한 연구가 요구되고 있 다. 카메라를 통한 보행자 인식 및 거리추정의 경우, 실제 세계의 객체를 2차원 이미지에 투영하였기 때문에 거리에 대한 정보가 많이 손실된다. 특히 보행자 위치 계산에 많이 사용되는 특징들(보행자의 키나 지면에 닿아있는 점)의 편차가 크기 때문에 오차가 크다. 레이더를 통한 보행자 인식 및 거리추정의 경우, 레이더는 객체를 분류하는 능력이 떨어지기 때문에 보행자인지 아닌지에 대한 판단이 어렵고, 특히나 보행자의 경우 신호세기가 작기 때문에 그 판단이 더욱 어렵다."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 보행자의 위치를 결정하는 방법 및 장치를 제공하는데 있다. 본 발명이 해결하고자 하는 과제는 이상 에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 과제 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해보다 분명하게 이해될 것이다. 또한, 본 발명이 해결하고자 하는 과 제 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 보행자의 위치를 결정하는 방 법에 있어서, 카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 상기 차량 외부에 대한 복수의 레이더 측정값을 획득하는 단계; 상기 이미지에 포함된 보행자 객체를 결정하는 단계; 상기 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 상기 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후 보값을 결정하는 단계; 상기 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택하는 단계; 및 상기 선택된 레이더 측정값에 기초하여 상기 보행자 객체의 최종 종방향 위치값을 결정하는 단계;를 포함하는 방법을 제공할 수 있다. 본 개시의 제 2 측면은, 보행자의 위치를 결정하기 위한 장치에 있어서, 적어도 하나의 프로그램이 저장된 메모 리; 및 상기 적어도 하나의 프로그램을 실행함으로써 연산을 수행하는 프로세서를 포함하고, 상기 프로세서는, 카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 상기 차량 외부에 대한 복수의 레 이더 측정값을 획득하고, 상기 이미지에 포함된 보행자 객체를 결정하고, 상기 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 상기 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후보값을 결정하고, 상기 종 방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택하며, 상기 선택된 레이더 측정값에 기초하여 상기 보행자 객체의 최종 종방향 위치값을 결정하는 것인, 장치를 제공할 수 있다. 본 개시의 제 3 측면은, 제 1 측면에 따른 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다. 이 외에도, 본 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 개시의 과제 해결 수단에 의하면, 본 개시에서는 레이더-카메라 센서퓨전을 통해, 레이더 측정값으로 부터 확인하기 어려운 보행자 객체를 식별할 수 있고, 카메라 이미지로부터 산출하기 어려운 차량과 보행자 간 의 거리를 보다 정확하게 측정할 수 있다. 뿐만 아니라, 본 개시의 과제 해결 수단에 의하면, 카메라를 이용하여 판단하기 어려운 종방향에 대한 이동/정 지판단과 레이더를 이용하여 판단하기 어려운 횡방향에 대한 이동/정지판단이 개선될 수 있다."}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다.\"매커니즘\", \"요소\", \"수단\" 및 \"구성\"등과 같은 용어는 넓게 사용될 수 있으며, 기계적이 고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하에서, '차량'은 자동차, 버스, 오토바이, 킥보드 또는 트럭과 같이 기관을 가지고 사람이나 물건을 이동시 키기 위해 이용되는 모든 종류의 운송 수단을 의미할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율 주행 차량을 구현 할 수 있다. 자율 주행 차량에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센서 들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율 주행 차량의 전면에 장착된 이미지 센서 및/또는 이 벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율 주행 차량의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율 주행 차량 주변의 보행자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율 주행 차량 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율 주행 차량의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화각 (FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있다. 자율 주행 장치는, 자율 주행 차량의 센서들이 수집한 정보를 실시간으로 처리하여 자율 주행 차량의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서들(42-45)을 포함하며, 복수의 센서들(42-45)은 이미지 센서, 이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어 하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율 주행 차량의 센서가 획득한 영상 데이터의 예시를 나타낸 도면이다. 도 3 을 참조하면, 영상 데이터는 자율 주행 차량의 전면에 장착된 센서가 획득한 데이터일 수 있다. 따라서 영 상 데이터에는 자율 주행 차량의 전면부, 자율 주행 차량과 같은 차로의 선행 차량, 자율 주행 차 량 주변의 주행 차량 및 비관심영역 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율 주행 차량의 전면부와 비관심영역이 나타나는 영역의 데이터는 자율 주행 차량의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율 주행 차량의 전면부와 비관심영역은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율 주행 차량의 안전한 운행에 있 어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함되 는 영역의 데이터는 자율 주행 차량의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율 주행 차량의 전면부와 비관심영역이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있 다. 도 4a 내지 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 카메라는 차량에 탑재되어 차량의 외부를 촬영할 수 있다. 카메라는 차량의 전방, 측방, 후방 등을 촬영할 수 있다. 보행자의 위치를 결정하는 장치(이하, '보행자 위치 결정 장치')는 카메라에서 촬영된 복수의 이미지를 획득할 수 있다. 카메라에서 촬영된 복수의 이미지에는 복수의 객체가 포함될 수 있다. 객체에 관한 정보는 객체 종류 정보 및 객체 속성 정보를 포함한다. 여기에서, 객체 종류 정보는 객체의 종류를 나타내는 인덱스 정보이며, 큰 범위인 그룹과 세부 범위인 클래스로 구성된다. 그리고, 객체 속성 정보는 객체 의 현재 상태에 대한 속성 정보를 나타내는 것이며, 움직임 정보, 회전 정보, 교통 정보, 색상 정보, 및 가시성 정보를 포함한다. 일 실시예에서, 객체 종류 정보에 포함되는 그룹 및 클래스는 아래의 표 1과 같을 수 있으나, 이에 제한되지 않 는다. 표 1"}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "또한, 객체 속성 정보에 포함되는 정보에는 Action, Rotate, Traffic info, color, Visibility 정보가 포함될 수 있다. Action 정보는 객체의 움직임 정보를 표현하며 정차, 주차, 이동 등으로 정의될 수 있다. 차량의 경우 정차, 주 차, 이동이 객체 속성 정보로 결정될 수 있고, 보행자의 경우 이동, 정지, 알수없음이 객체 속성 정보로 결정될 수 있고, 신호등과 같이 움직일 수 없는 객체의 경우 디폴트 값인 정지로 객체 속성 정보가 결정될 수 있다. Rotate 정보는 객체의 회전 정보를 표현하며 정면, 후면, 수평(horizontal), 수직(vertical), 측면 등으로 정의 될 수 있다. 차량의 경우 정면, 후면, 측면으로 객체 속성 정보가 정해질 수 있고, 가로 또는 세로 방향의 신호 등은 각각 수평 또는 수직으로 객체 속성 정보가 정해질 수 있다. Traffic info는 객체의 교통정보를 의미하며, 교통표지판의 지시, 주의, 규제, 보조 표지 등으로 정의될 수 있 다. Color는 객체의 색상 정보를 의미하며 객체의 색상, 신호등 및 교통표지판의 색상을 표현할 수 있다. 도 4a를 참조하면, 객체는 보행자일 수 있다. 이미지는 소정의 크기를 가질 수 있다. 복수의 이미지 에는 동일한 객체가 포함될 수 있으나, 차량이 도로를 따라 주행함에 따라 차량과 객체의 상대 적 위치는 계속 변하고, 또한 객체도 시간에 따라 이동을 함으로써, 이에 따라 동일한 객체라도 각 이미지 내에서의 위치가 달라지게 된다. 각 이미지에서 동일한 객체가 어떤 것인지 결정하기 위해 이미지 전체를 이용하는 경우, 데이터 전송량 및 연산 량이 상당히 커지게 된다. 이에 따라, 차량에 탑재되는 장치에서 엣지 컴퓨팅을 통해 처리되기 어렵고, 실시간 분석 또한 어렵다. 도 4b를 참조하면, 이미지에 포함된 바운딩 박스가 도시된다. 바운딩 박스는 객체에 대한 메타데이터로써, 바운딩 박스 정보에는 객체 종류 정보(그룹, 클래스 등), 이미지 상의 위치 정보, 크기 정보 등이 포함될 수 있다. 도 4b를 참조하면, 바운딩 박스 정보는 해당 객체가 보행자 클래스에 해당한다는 정보와, 객체의 좌 측 상단 꼭지점이 이미지 상의 (x, y) 에 위치한다는 정보, 객체의 크기가 w x h 라는 정보, 그리고 객체 가 이동 중이라는 현재 상태 정보(즉, Action 정보)를 포함할 수 있다. 도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 흐름도이다. 보행자 위치 결정 장치는 카메라로부터 복수의 이미지를 획득할 수 있다. 복수의 이미지는 이전 이미지 및 현재 이미지를 포함할 수 있다. 보행자 위치 결정 장치는 이전 이미지에서 제1 보행자 객체를 인식할 수 있다. 일 실시예에서, 보행자 위치 결정 장치는 이미지를 동일한 크기의 그리드로 나누고, 각 그리드에 대해 그리드 중앙을 중심으로 미리 정의된 형태로 지정된 경계박스의 개수를 예측하며 이를 기반으로 신뢰도를 계산할 수 있 다. 보행자 위치 결정 장치는 이미지에 객체가 포함되어 있는지, 또는 배경만 단독으로 있는지 여부를 결정하고, 높은 객체 신뢰도를 갖는 위치를 선택하여 객체 카테고리를 결정함으로써 결과적으로 객체를 인식할 수 있다. 다만, 본 개시에서 객체를 인식하는 방법은 이에 제한되지 않는다. 보행자 위치 결정 장치는 이전 이미지에서 인식된 제1 보행자 객체의 제1 위치 정보를 획득할 수 있 다. 도 4a 내지 도 4b에서 상술한 바와 같이, 제1 위치 정보는 이전 이미지 상의 제1 보행자 객체에 대응하는 바운딩 박스의 어느 하나의 꼭지점(예를 들어, 좌측 상단 꼭지점) 좌표 정보 및 가로, 세로 길이 정보 를 포함할 수 있다. 또한, 보행자 위치 결정 장치는 현재 이미지에서 인식된 제2 보행자 객체의 제2 위치 정보를 획득할 수 있다. 보행자 위치 결정 장치는 이전 이미지에서 인식된 제1 보행자 객체의 제1 위치 정보, 및 현재 이미지 에서 인식된 제2 보행자 객체의 제2 위치 정보 간의 유사도를 산출할 수 있다. 도 5를 참조하면, 제1 위치 정보 및 제2 위치 정보를 이용하여, 보행자 위치 결정 장치는 제1 보행자 객체 및 제2 보행자 객체 간 교집합 및 합집합을 산출할 수 있다. 보행자 위치 결정 장치는 합집합 영역 대비 교집합 영역의 값을 산출하고, 산출된 값이 임계값 이상인 경우 제1 보행자 객체 및 제2 보행자 객체(52 1)가 동일한 보행자 객체인 것으로 결정할 수 있다. 그러나, 보행자 객체 간의 동일성을 판별하는 방법은 상술한 방법으로 제한되지 않는다. 도 6은 일 실시예에 따른 객체 추적 방법을 설명하는 흐름도이다. 객체 추적은 연속된 시간에 대해 동일한 객체를 인식하는 것을 의미한다. 객체 추적(Object Tracking)은 Lidar, Camera 등의 센서로부터 정보를 입력 받아 객체(예를 들어, 상대차량, 보행자, 장애물)의 위치와 속도, 종류를 획득하는 동작이다. 객체 추적의 데이터 처리는 센싱 데이터 필터링 및 추적으로 분류될 수 있다. 추적은 클러 스터링(Clustering), 데이터 연계(Association), 객체의 움직임 예측(Prediction), 선택적인 트랙 리스트 업데 이트(Update) 및 객체 추적 동작을 포함한다. 여기서 객체 추적 동작은 머지(Merge), 추적 객체 분류 및 객체 추적 시동을 포함한다. 단계 610에서 보행자 위치 결정 장치는 센서로부터 Raw 데이터를 수신하고, 센싱 데이터를 필터링할 수 있다. 필터링은 추적을 실행하기 전, 센서의 Raw 데이터를 가공하는 과정이다. 보행자 위치 결정 장치는 관심 영역을 설정하여, 센싱 포인트의 개수를 줄이고, 그라운드 노이즈(ground noise) 제거를 통해, 추적에 필요한 객체 포 인트만을 분류할 수 있다. 단계 620에서 보행자 위치 결정 장치는 필터링된 센싱 데이터를 클러스터링하고, 연계 작업을 수행할 수 있다. 보행자 위치 결정 장치는 클러스터링을 통해, 하나의 객체에 생성된 여러 포인트를 군집화하여, 하나의 포인트 로 생성할 수 있다. 또한, 보행자 위치 결정 장치가 객체를 추적하기 위해, 클러스터링을 통해 생성된 포인트와 기존에 추적하고 있는 포인트들의 데이터를 연계(Association)하는 동작이 필요하다. 예를 들어, 보행자 위치 결정 장치는 기추적된 객체들을 순회하며, 현재 센서를 통해, 클러스터링된 객체의 포인트들 가운데, 기추적된 객체들의 포인트와 거리가 가장 가까운 클러스터링된 객체의 포인트를 선택하여, 양 데이터를 연계할 수 있다. 이러한 데이터 연계 동작에서 객체 추적 알고리즘의 정확도를 높이기 위해, 보행자 위치 결정 장치는 거리가 가 장 가까운 클러스터링된 객체의 포인트로 선택된 경우라도, 클러스터링된 객체의 움직임이 불확실하거나, 예측 될 수 없는 경우에는 제거할 수 있다. 이를 위해, 확률 기반의 알고리즘이 사용될 수 있다. 단계 630에서 보행자 위치 결정 장치는 객체의 움직임을 예측할 수 있다. 보다 자세하게, 보행자 위치 결정 장 치는 단계 610 및 단계 620을 통해, 측정된 객체의 움직임과 관련된 값들을 통해, 추적하는 객체들의 위치를 예 측할 수 있다. 이를 위해 확률 기반의 알고리즘이 사용될 수 있다. 만일, 측정된 객체의 움직임과 관련된 값이 없다면, 예측된 객체의 움직임이 측정된 객체의 움직임과 관련된 값이 될 수 있다. 이와 달리, 측정된 객체의 움직임과 관련된 값이 있다면, 객체의 움직임을 예측하는 단계를 통해, 객체의 움직임과 관련된 값은 갱신될 수 있다. 단계 640에서 보행자 위치 결정 장치는 선택적으로 트랙 리스트를 업데이트하고 객체 추척 동작을 수행할 수 있 다. 보행자 위치 결정 장치는 전술한 바와 같이 측정된 객체의 움직임과 관련된 값이 있는 경우, 객체 별로 관리되 는 트랙 리스트(track list)를 갱신할 수 있다. 이를 위해, 칼만 필터(Kalman Filter)가 이용될 수 있다. 또한, 보행자 위치 결정 장치는 객체 추적 동작을 수행하기 위해, 추적되는 객체와 일정 거리에서 비슷한 속도로 움직 이는 객체들을 하나의 객체로 머지(merge)하는 과정 및 추적되는 객체와 매칭되는 센싱 데이터의 포인트들이 임 계점 이하인 경우, 추적을 중지하는 추적 객체 분류 작업을 수행한 뒤, 객체 추적을 개시할 수 있다. 다만, 이 경우에도 센싱 데이터의 포인터가 고스트인지를 판단하기 위해 데이터 연계가 되지않은 센싱 데이터의 포인터는 검증 후, 객체 추적을 개시할 수 있다. 본 개시에서 객체 추적 방법은 상기 동작에 한정되지 않으며, 이와 유사한 목적의 객체 추적 알고리즘도 포함될 수 있다. 보행자 위치 결정 장치는 도 6에서 상술한 방법에 기초하여 복수의 이미지에 포함된 객체를 인식하고 객체 궤적 을 추적할 수 있다. 도 7은 일 실시예에 따른 객체의 종방향 위치 후보값을 결정하는 방법을 설명하기 위한 예시적인 도면이다. 보행자 위치 결정 장치는 이미지에 포함된 보행자 객체를 결정할 수 있다. 보행자 위치 결정 장치는 보행자 객체의 위치 정보를 획득할 수 있다. 위치 정보는 보행자 객체에 대응하는 바운딩 박스의 어 느 하나의 꼭지점 좌표 정보 및 가로, 세로 길이 정보를 포함할 수 있다. 보행자 위치 결정 장치는 보행자 객체에 대한 복수의 객체 크기 후보값을 설정할 수 있다. 일 실시예에서, 복수의 객체 크기 후보값은 보행자가 가질 수 있는 신장(height) 범위를 소정의 간격으로 나눈 값일 수 있다.도 7을 참조하면, 복수의 객체 크기 후보값은 1.5m, 1.6m, 1.7m, 1.8m 및 1.9m일 수 있다. 보행자 위치 결정 장치는 객체 크기 후보값, 객체의 픽셀값 및 카메라의 초점 거리(focal length)를 이용하여 종방향 위치 후보값을 결정할 수 있다. 구체적으로, 보행자 위치 결정 장치는, 아래의 수학식 1을 이용하여 종 방향 위치 후보값을 결정할 수 있다. 수학식 1에서 객체의 픽셀 높이는, 보행자 객체에 대응하는 바운딩 박스의 픽셀 높이(height)를 의미한다. 수학식 1"}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 7을 참조하면, 카메라의 초점 거리 및 객체의 픽셀 높이가 기설정된 값일 때, 객체 크기 후보값 1.5m, 1.6m, 1.7m, 1.8m 및 1.9m 각각에 대응하는 종방향 위치 후보값은 14.6m, 15.3m, 16.0m, 16.7m 및 17.4m가 된다. 즉, 이미지 내 보행자 객체에 대응하는 바운딩 박스의 위치 및 크기가 동일하더라도, 보행자 객체의 실제 신장이 클 수록, 보행자는 카메라가 탑재된 차량으로부터 더 멀리 위치한다. 한편, 카메라의 초점 거리 및 객체의 픽셀 높 이에 대한 수치는 예시에 불과하고, 카메라 종류가 달라질 경우 수치는 바뀔 수 있다. 한편, 보행자 위치 결정 장치는 카메라의 포지션을 고려하여 결정된 종방향 위치 후보값을 보정할 수 있다. 여 기서, 포지션은 촬영 방향, 앵글(angle), 샷(shot) 등 촬영되는 이미지에 변화를 줄 수 있는 다양한 팩터를 포 함하는 값일 수 있다. 예를 들어, 카메라의 포지션은 일정한 시간이 지남에 따라 바뀔 수 있다. 또는, 카메라의 포지션은 특정 이벤트 가 발생한 것에 응답하여 바뀔 수 있다. 또는, 카메라의 포지션은 외부 입력에 대응하여 바뀔 수 있다. 보행자 위치 결정 장치는 카메라의 앵글이 하늘 방향 또는 지면 방향으로 향한 상태인지, 또는 카메라의 촬영 방향이 정면 방향 또는 측면 방향으로 향한 상태인지를 고려하여, 종방향 위치 후보값을 보정할 수 있다. 도 8은 일 실시예에 따른 종방향 위치 후보값을 고려한 레이더 측정값을 선택하는 방법을 설명하기 위한 예시적 인 도면이다. 도 8을 참조하면, 카메라로부터 획득된 현재 이미지에 대응하는 버드아이뷰 좌표가 도시된다. 버드아이뷰 좌표에서 제1 위치는 카메라의 위치를 나타낸다. 또는, 제1 위치는 카메라가 탑재된 차량의 위 치를 나타낸다. 버드아이뷰 좌표에서 제3 위치 세트는, 보행자 객체에 대한 복수의 종방향 위치 후보값 각각을 나타 낸다. 도 7을 참조하여 설명하면, 보행자 객체에 대한 객체 크기 후보값이 1.5m, 1.6m, 1.7m, 1.8m 및 1.9m으로 설정된 경우, 객체 크기 후보값 각각에 대응하는 종방향 위치 후보값은 14.6m, 15.3m, 16.0m, 16.7m 및 17.4m가 된다. 즉, 보행자 위치 결정 장치는 버드아이뷰 좌표에서 제1 위치로부터 가장 가까운 제3 위치 세트 값을 객체 크기 후보값 '1.5m'에 대응하는 것으로 결정하고, 제1 위치로부터 가장 먼 제3 위치 세트 값은 객체 크기 후보값 '1.9m'에 대응하는 것으로 결정할 수 있다. 또한, 보행자 위치 결정 장치는 제3 위치 세트의 나머지 세 값 각각을 객체 크기 후보값 '1.6m', '1.7m' 및 '1.8m'에 대응하는 것으로 결정할 수 있다. 한편, 레이더는 차량에 탑재되어 차량의 외부 물체를 센싱할 수 있다. 레이더는 차량의 전방, 측방, 후방 등을 센싱할 수 있다. 보행자 위치 결정 장치는 레이더로부터 차량 외부에 대한 복수의 레이더 측정값을 획득할 수 있다. 버드아이뷰 좌표에는 복수의 레이더 측정값이 표시될 수 있다. 보행자 위치 결정 장치는 복수의 레이더 측정값 중에서, 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택할 수 있다. 도 8을 참조하면, 버드아이뷰 좌표에 표시된 복수의 레이더 측정값 중에 서, 보행자 위치 결정 장치는 제3 위치 세트 주변인 제2 위치에 표시된 레이더 측정값을 선택할 수 있다.보행자 위치 결정 장치는 제2 위치에 표시된 레이더 측정값에 기초하여 상기 보행자 객체의 최종 종방향 위치값을 결정할 수 있다. 일 실시예에서, 보행자 위치 결정 장치는 제2 위치를 보행자 객체의 최종 종방향 위치값으로 결정할 수 있 다. 다른 실시예에서, 보행자 위치 결정 장치는 제2 위치에 표시된 레이더 측정값을 칼만 필터에 적용하고, 칼 만 필터로부터 도출된 값을 최종 종방향 위치값으로 결정할 수 있다. 본 개시에서는, 카메라로부터 획득된 이미지를 이용하여 보행자 객체를 인식하고, 보행자 객체의 종방향 위치 후보값에 기초하여 매칭되는 레이더 측정값을 결정함으로써, 차량과 보행자 객체 간의 거리를 보다 정확하게 측 정할 수 있다. 도 9는 일 실시예에 따른 아웃라이어를 제거하는 방법을 설명하기 위한 예시적인 도면이다. 도 9를 참조하면, 카메라로부터 획득된 현재 이미지에 대응하는 버드아이뷰 좌표가 도시된다. 버드아이뷰 좌표에서 제1 위치는 카메라의 위치를 나타낸다. 또는, 제1 위치는 카메라가 탑재된 차량의 위 치를 나타낸다. 버드아이뷰 좌표에서 제2 위치에 표시된 레이더 측정값은, 도 8의 제2 위치에 표시된 레이더 측 정값에 대응된다. 보행자 위치 결정 장치는 제2 위치에 표시된 레이더 측정값에 기초하여 보행자 객체의 최종 종방향 위치값을 결정할 수 있다. 한편, 보행자 위치 결정 장치는 소정의 조건이 만족하는 경우, 레이더 측정값에 대한 아웃라이어를 제거할 수 있다. 이하에서 설명하는 다양한 실시예에 따라 아웃라이어가 제거됨에 따라, 보행자 위치 결정 장치는 제2 위치(92 0)에 표시된 레이더 측정값을 제3 위치로 보정할 수 있다. 일 실시예에서, 보행자 위치 결정 장치는 이전 이미지에 대해 결정된 보행자 객체의 최종 종방향 위치값을 고려 하여 현재 이미지에 대한 레이더 측정값의 아웃라이어를 제거할 수 있다. 도 5에서 상술한 방법에 따라, 보행자 위치 결정 장치는 이전 이미지에 포함된 제1 보행자 객체와 현재 이미지 에 포함된 제2 보행자 객체가 동일한 객체인 것을 결정할 수 있다. 또한, 보행자 위치 결정 장치는 현재 이미지 에 대한 레이더 측정값의 아웃라이어를 제거하기 위해, 이전 이미지에 포함된 제1 보행자 객체의 최종 종방향 위치값을 이용할 수 있다. 구체적으로, 보행자 위치 결정 장치는 이전 이미지에 대한 보행자 객체의 제1 최종 종방향 위치값을 획득할 수 있다. 또한, 보행자 위치 결정 장치는 현재 이미지에 대한 선택된 레이더 측정값을 획득할 수 있다. 보행자 위치 결정 장치는 제1 최종 종방향 위치값과 선택된 레이더 측정값이 소정 거리 이내인 경우, 선택된 레 이더 측정값에 기초하여 현재 이미지에 대한 제2 최종 종방향 위치값을 결정할 수 있다. 반면, 보행자 위치 결 정 장치는 제1 최종 종방향 위치값과 선택된 레이더 측정값이 소정 거리 이내가 아닌 경우, 현재 이미지에 대한 제2 최종 종방향 위치값을 결정하는데 선택된 레이더 측정값을 사용하지 않을 수 있다. 즉, 현재 이미지에 대한 선택된 레이더 측정값이, 이전 이미지의 제1 최종 종방향 위치값으로부터 소정 거리 이 내에 위치하지 않는 경우, 선택된 레이더 측정 값이 잘못된 값일 수 있으므로, 이 경우 보행자 위치 결정 장치 는 현재 이미지에 대한 제2 최종 종방향 위치값을 결정하는데 선택된 레이더 측정값을 사용하지 않을 수 있다. 한편, 소정 거리는 현재 이미지 및 이전 이미지 간 촬영 시간 간격 및 보행자 객체의 이동 속도 등을 고려하여 결정될 수 있다. 일 실시예에서, 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값의 개수가 제1 임계값 이하 또는 제2 임계값 이상인 경우, 보행자 위치 결정 장치는 레이더 측정값을 선택하지 않을 수 있다. 제1 임계값은 상기 제2 임계값 보다 작은 값일 수 있다. 레이더 측정값의 개수는 객체에 따라 달라지며 예를 들어, 차량은 보행자 보다 신호 반사 세기 및 반사 면적이 크므로, 차량에 대한 레이더 측정값의 개수는 보행자에 대한 레이더 측정값의 개수보다 많게 된다. 즉, 보행자가 아닌 객체(예를 들어, 차량)에 대한 레이더 측정값을 선택하는 것을 방지하기 위해, 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값의 개수가 제1 임계값 초과 및 제2 임계값 미만인 경우 에만, 보행자 위치 결정 장치는 레이더 측정값을 선택할 수 있다. 일 실시예에서, 보행자 위치 결정 장치는 선택된 레이더 측정값으로부터 보행자 객체의 도플러 속도를 산출할 수 있다. 구체적으로, 보행자 객체가 움직일 때 움직임에 의한 도플러 성분이 발생하여 보행자 객체의 도플러 속도가 산출될 수 있다. 도플러 속도가 보행자가 가질 수 있는 속도 범위 이내인 경우, 보행자 위치 결정 장치는 선택된 레이더 측정값 에 기초하여 보행자 객체의 최종 종방향 위치값을 결정할 수 있다. 반면, 도플러 속도가 보행자가 가질 수 있는 속도 범위 밖인 경우, 보행자 위치 결정 장치는 선택된 레이더 측정값을 사용하지 않을 수 있다. 도 10은 일 실시예에 따른 보행자 객체의 상태를 결정하는 방법을 설명하기 위한 흐름도이다. 도 10을 참조하면, 단계 1010에서, 보행자 위치 결정 장치는 선택된 레이더 측정값으로부터 보행자 객체의 도플 러 속도를 산출할 수 있다. 구체적으로, 보행자 객체가 움직일 때 움직임에 의한 도플러 성분이 발생하여 보행 자 객체의 도플러 속도가 산출될 수 있다. 단계 1020에서, 보행자 위치 결정 장치는 이미지 내 보행자 객체의 움직임에 기초하여, 보행자 객체의 중간 상 태를 결정할 수 있다. 구체적으로, 보행자 위치 경정 장치는 카메라로부터 획득된 복수의 이미지에 포함된 보행자 객체의 움직임이 확 인되는 경우, 보행자 객체의 중간 상태를 '이동'으로 결정하고, 보행자 객체의 움직임이 확인되지 않는 경우, 보행자 객체의 중간 상태를 '정지'로 결정할 수 있다. 단계 1030에서, 단계 1010에서 산출된 도플러 속도가 소정 값 이상인 경우 단계 1050으로 진행하고, 보행자 위 치 결정 장치는 보행자 객체의 최종 상태를 '이동'으로 결정할 수 있다. 반면, 단계 1010에서 산출된 도플러 속 도가 소정 값 미만인 경우, 단계 1040으로 진행될 수 있다. 단계 1040에서, 단계 1020에서 결정된 보행자 객체의 중간 상태가 '이동'인 경우 단계 1050으로 진행하고, 보행 자 위치 결정 장치는 보행자 객체의 최종 상태를 '이동'으로 결정할 수 있다. 반면, 단계 1020에서 결정된 보행 자 객체의 중간 상태가 '이동'이 아닌 경우, 단계 1060으로 진행될 수 있다. 단계 1060에서, 보행자 위치 결정 장치는 보행자 객체의 최종 상태를 '정지'로 결정할 수 있다. 즉, 단계 1010 에서 산출된 도플러 속도가 소정 값 미만이면서 동시에 단계 1020에서 결정된 보행자 객체의 중간 상태가 '정지'인 경우, 보행자 위치 결정 장치는 보행자 객체의 최종 상태를 '정지'로 결정할 수 있다. 한편, 보행자가 이동 중인 경우 움직임이 발생하게 된다. 카메라의 경우 보행자가 횡방향으로 이동할 때 발생하는 움직임은쉽게 감지하여 보행자의 횡방향에 대한 이동/ 정지 여부를 정확하게 판단할 수 있다. 반면, 보행자가 종방향으로 이동할 때 발생하는 움직임은 쉽게 감지하지 못하고, 이로 인해 보행자의 종방향에 대한 이동/정지 여부에 대한 판단은 상대적으로 부정확할 수 있다. 레이더의 경우 보행자가 종방향으로 이동할 때 움직임이 레이더 방향으로 발생하고 이로 인해 도플러 성분이 발 생하므로, 보행자의 종방향에 대한 이동/정지 여부를 정확하게 판단할 수 있다. 반면, 보행자가 횡방향으로 이 동할 때는 움직임이 레이더 방향과 수직이기 때문에 도플러 성분이 발생하지 않아, 보행자의 횡방향에 대한 이 동/정지 여부에 대한 판단은 상대적으로 부정확할 수 있다. 일 실시예에서, 도플러 속도가 소정 값 이상이고, 이미지에 기초하여 결정된 보행자 객체의 중간 상태가 '이 동'인 경우, 보행자 위치 결정 장치는 보행자 객체가 종방향 및 횡방향으로 이동 중인 것으로 결정할 수 있다. 또는, 보행자 위치 결정 장치는 도플러 속도가 소정 값 이상이지만, 이미지에 기초하여 결정된 보행자 객체의 중간 상태가 '정지'인 경우, 보행자 위치 결정 장치는 보행자 객체가 종방향으로는 이동 중이나 횡방향에 대해 서는 정지인 것으로 결정할 수 있다. 또는, 보행자 위치 결정 장치는 도플러 속도가 소정 값 미만이지만, 이미지에 기초하여 결정된 보행자 객체의 중간 상태가 '이동'인 경우, 보행자 위치 결정 장치는 보행자 객체가 횡방향으로는 이동 중이나 종방향에 대해 서는 정지인 것으로 결정할 수 있다. 본 개시에서는 레이더-카메라 센서퓨전을 통해, 레이더 측정값으로부터 확인하기 어려운 보행자 객체를 식별할 수 있고, 카메라 이미지로부터 산출하기 어려운 차량과 보행자 간의 거리를 보다 정확하게 측정할 수 있다. 또한, 카메라를 이용하여 판단하기 어려운 종방향에 대한 이동/정지판단과 레이더를 이용하여 판단하기 어려운 횡 방향에 대한 이동/정지판단이 개선될 수 있다. 도 11은 일 실시예에 따른 보행자의 위치를 결정하는 방법을 결정하는 방법의 흐름도이다. 도 11에 도시된, 보행자의 위치를 결정하는 방법은, 앞서 설명된 도면들에서 설명된 실시예들에 관련되므로, 이 하 생략된 내용이라 할지라도, 앞서 도면들에서 설명된 내용들은 도 11의 방법에도 적용될 수 있다. 도 11을 참조하면, 단계 1110에서 프로세서는 카메라로부터 차량 외부를 촬영하는 복수의 이미지를 획득하고, 레이더로부터 차량 외부에 대한 복수의 레이더 측정값을 획득할 수 있다. 카메라는 차량에 탑재되어 차량의 외부를 촬영할 수 있다. 카메라는 차량의 전방, 측방, 후방 등을 촬영할 수 있다. 프로세서는 카메라에서 촬영된 복수의 이미지를 획득할 수 있다. 카메라에서 촬영된 복수의 이미지에는 복수의 객체가 포함될 수 있다. 레이더는 차량에 탑재되어 차량의 외부 물체를 센싱할 수 있다. 레이더는 차량의 전방, 측방, 후방 등을 센싱할 수 있다. 프로세서는 레이더로부터 차량 외부에 대한 복수의 레이더 측정값을 획득할 수 있다. 단계 1120에서 프로세서는 이미지에 포함된 보행자 객체를 결정할 수 있다. 복수의 이미지는 이전 이미지 및 현재 이미지를 포함할 수 있다. 프로세서는, 이전 이미지에서 인식된 제1 보행 자 객체의 제1 위치 정보를 획득하고, 현재 이미지에서 인식된 제2 보행자 객체의 제2 위치 정보를 획득할 수 있다. 프로세서는 제1 위치 정보 및 제2 위치 정보 간의 유사도에 기초하여, 제1 보행자 객체와 제2 보행자 객 체가 동일한 보행자 객체인지 여부를 결정할 수 있다. 프로세서는 센서로부터 Raw 데이터를 수신하고, 센싱 데이터를 필터링할 수 있다. 또한, 프로세서는 필터링된 센싱 데이터를 클러스터링하고, 연계 작업을 수행할 수 있다. 또한, 프로세서는 객체의 움직임을 예측할 수 있 다. 또한, 프로세서는 선택적으로 트랙 리스트를 업데이트하고 객체 추척 동작을 수행할 수 있다. 단계 1130에서 프로세서는 보행자 객체에 대한 복수의 객체 크기 후보값을 설정하고, 복수의 객체 크기 후보값 각각에 대한 종방향 위치 후보값을 결정할 수 있다. 복수의 객체 크기 후보값은 보행자가 가질 수 있는 신장(height) 범위를 소정의 간격으로 나눈 값인 것일 수 있 다. 프로세서는, 객체 크기 후보값, 객체의 픽셀값 및 카메라의 초점 거리(focal length)를 이용하여 종방향 위치 후보값을 결정할 수 있다. 단계 1140에서 프로세서는 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값을 선택 할 수 있다. 프로세서는 레이더 측정값에 대한 아웃라이어를 제거할 수 있다. 일 실시예에서, 프로세서는 이전 이미지에 대한 보행자 객체의 제1 최종 종방향 위치값을 획득할 수 있다. 프로 세서는 현재 이미지에 대한 선택된 레이더 측정값을 획득할 수 있다. 제1 최종 종방향 위치값과 선택된 레이더 측정값이 소정 거리 이내인 경우, 프로세서는 선택된 레이더 측정값에 기초하여 현재 이미지에 대한 제2 최종 종방향 위치값을 결정할 수 있다. 일 실시예에서, 종방향 위치 후보값으로부터 소정 거리 이내에 위치한 레이더 측정값의 개수가 제1 임계값 이하 또는 제2 임계값 이상인 경우, 프로세서는 레이더 측정값을 선택하지 않을 수 있다. 일 실시예에서, 프로세서는 선택된 레이더 측정값으로부터 도플러 속도를 산출할 수 있다. 프로세서는 도플러 속도가 보행자가 가질 수 있는 속도 범위 이내인 경우, 선택된 레이더 측정값에 기초하여 보행자 객체의 최종 종방향 위치값을 결정할 수 있다. 단계 1150에서 프로세서는 선택된 레이더 측정값에 기초하여 보행자 객체의 최종 종방향 위치값을 결정 할 수 있다. 프로세서는 선택된 레이더 측정값을 칼만 필터에 적용함으로써 도출된 값을 상기 최종 종방향 위치값으로 결정 할 수 있다. 일 실시예에서, 프로세서는 선택된 레이더 측정값으로부터 도플러 속도를 산출하고, 이미지 내 상기 보행자 객 체의 움직임에 기초하여, 보행자 객체의 중간 상태를 결정할 수 있다. 도플러 속도가 소정의 값 이상이거나, 보행자 객체의 중간 상태가 이동인 경우, 프로세서는 보행자 객체의 최종 상태를 이동으로 결정할 수 있다. 반면, 도플러 속도가 소정의 값 미만이면서, 보행자 객체의 중간 상태가 정지 인 경우, 프로세서는 보행자 객체의 최종 상태를 정지로 결정할 수 있다. 도 12는 일 실시예에 따른 보행자 위치 결정 장치의 블록도이다. 도 12를 참조하면, 보행자 위치 결정 장치는 통신부, 프로세서 및 DB를 포함할 수 있 다. 도 12의 보행자 위치 결정 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 12"}
{"patent_id": "10-2023-0035765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라 면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적 어도 하나를 포함할 수 있다. DB는 보행자 위치 결정 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서 의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 보행자 위치 결정 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 보행자 위 치 결정 장치의 동작을 제어할 수 있다. 프로세서는 도 1 내지 도 11에서 상술한 보행자 위치 결정 장치의 동작 중 적어도 일부를 제어할 수 있다. 또한, 프로세서는 도 1 내지 도 11에서 상술한 방법을 이용하여 보행자의 위치를 결정하고, 이에 기초하 여 차량의 주행을 제어할 수 있다. 프로세서는 차량의 속도, 차량과 보행자 객체 간의 거리, 보행자 객체의 최종 상태 및 차량이 주행 중인 도로의 너비 중 적어도 어느 두개의 팩터에 기초하여 차량의 주행을 제어할 수 있다. 한편, 보행자의 위치를 결정하는 프로세서와, 차량의 주행을 제어하는 프로세서는 하드웨어적으로 구분되고, 별 도의 장치에 탑재될 수 있으나, 설명의 편의상 프로세서에 의해 수행되는 것으로 설명하기로 한다. 예를 들어, 차량의 속도가 기설정된 속도(예를 들어, 30km/h) 이상이고, 차량과 보행자 객체 간의 거리가 기설 정된 거리(예를 들어, 50m) 이하인 경우, 프로세서는 차량이 정지하도록 제어할 수 있다. 또는, 차량의 속도와 무관하게, 차량과 보행자 객체 간의 거리가 기설정된 거리(예를 들어, 50m) 이하이고, 도 로의 너비가 기설정된 너비(예를 들어, 3m) 이하이고, 보행자 객체가 '이동' 중인 경우, 프로세서는 차량 이 정지하도록 제어할 수 있다. 프로세서는 ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예로, 보행자 위치 결정 장치는 이동성을 가지는 전자 장치일 수 있다. 예를 들어, 보행자 위치 결정 장치는 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플 레이어, 네비게이션, 카메라가 탑재된 디바이스 및 기타 모바일 전자 장치로 구현될 수 있다. 또한, 보행자 위 치 결정 장치는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어 러블 장치로 구현될 수 있다.다른 실시예로, 보행자 위치 결정 장치는 차량 내에 임베디드 되는 전자 장치일 수 있다. 예를 들어, 보 행자 위치 결정 장치는 생산 과정 이후 튜닝(tuning)을 통해 차량 내에 삽입되는 전자 장치일 수 있다. 또 다른 실시예로, 보행자 위치 결정 장치는 차량 외부에 위치하는 서버일 수 있다. 서버는 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구 현될 수 있다. 서버는 차량에 탑재된 장치들로부터 차량의 이동 경로를 결정하기 위해 필요한 데이터를 수신하 고, 수신한 데이터에 기초하여 차량의 이동 경로를 결정할 수 있다. 또 다른 실시예로, 보행자 위치 결정 장치에서 수행되는 프로세스는 이동성을 가지는 전자 장치, 차량 내 에 임베디되는 전자 장치 및 차량 외부에 위치하는 서버 중 적어도 일부에 의해 수행될 수 있다. 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 일 실시예에 따르면, 본 개시의 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2023-0035765", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4a 내지 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 흐름도이다. 도 6은 일 실시예에 따른 객체 추적 방법을 설명하는 흐름도이다. 도 7은 일 실시예에 따른 객체의 종방향 위치 후보값을 결정하는 방법을 설명하기 위한 예시적인 도면이다. 도 8은 일 실시예에 따른 종방향 위치 후보값을 고려한 레이더 측정값을 선택하는 방법을 설명하기 위한 예시적 인 도면이다. 도 9는 일 실시예에 따른 아웃라이어를 제거하는 방법을 설명하기 위한 예시적인 도면이다. 도 10은 일 실시예에 따른 보행자 객체의 상태를 결정하는 방법을 설명하기 위한 흐름도이다. 도 11은 일 실시예에 따른 보행자의 위치를 결정하는 방법을 결정하는 방법의 흐름도이다.도 12는 일 실시예에 따른 보행자 위치 결정 장치의 블록도이다."}
