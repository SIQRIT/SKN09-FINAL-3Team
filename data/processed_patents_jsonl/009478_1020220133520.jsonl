{"patent_id": "10-2022-0133520", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0053431", "출원번호": "10-2022-0133520", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "한재호"}}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,컨텐츠 제공 장치 및 서버와 통신하는 통신 인터페이스;상기 컨텐츠 제공 장치의 식별 정보를 저장하는 메모리;디스플레이; 및상기 컨텐츠 제공 장치로부터 수신된 제1 컨텐츠를 표시하도록 상기 디스플레이를 제어하고,기 설정된 이벤트가 발생하면, 상기 통신 인터페이스를 통해, 상기 컨텐츠 제공 장치의 상기 식별 정보를 상기서버에 전송하고,상기 통신 인터페이스를 통해, 상기 식별 정보에 대응되는 UI 위치 정보를 상기 서버로부터 수신하고,상기 표시된 제1 컨텐츠를 제2 컨텐츠로 변경하기 위한 사용자 명령이 수신되면, 상기 제2 컨텐츠를 표시하도록상기 디스플레이를 제어하고,상기 수신된 UI 위치 정보에 기초하여 상기 제2 컨텐츠에 대응되는 컨텐츠 정보를 획득하는, 적어도 하나의 프로세서;를 포함하고,상기 UI 위치 정보는,복수의 이미지가 중첩되어 하나의 이미지로 병합된 결합 이미지로부터 획득되는 정보인, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 기 설정된 이벤트는,상기 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트, 상기 전자 장치의 업그레이드가 수행되는 이벤트 또는 상기 UI 위치 정보를 수신하기 위한 사용자 명령이 입력되는 이벤트 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 UI 위치 정보는,상기 결합 이미지를 입력 데이터로써 수신하는 인공 지능 모델로부터 출력 데이터로써 획득되는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 UI 위치 정보는,상기 결합 이미지를 입력 데이터로써 수신하여 노이즈 제거 이미지를 출력 데이터로서 획득하는 제1 인공 지능모델 및 상기 노이즈 제거 이미지를 입력 데이터로써 수신하여 상기 UI 위치 정보를 출력 데이터로서 획득하는제2 인공 지능 모델에 기초하여 획득되는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,공개특허 10-2024-0053431-3-상기 적어도 하나의 프로세서는,상기 획득된 컨텐츠 정보에 대응되는 신뢰도를 획득하고,상기 신뢰도가 임계값 이상이면, 상기 획득된 컨텐츠 정보에 대응되는 응답 정보를 표시하도록 상기 디스플레이를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 적어도 하나의 프로세서는,상기 신뢰도가 상기 임계값 미만이면, 상기 UI 위치 정보를 변경하기 위한 가이드 UI를 표시하도록 상기 디스플레이를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 UI 위치 정보는,컨텐츠와 관련된 정보가 표시되는 UI 영역의 위치를 포함하고,상기 가이드 UI는,상기 UI 영역의 위치를 이동시키기 위한 아이콘, 상기 UI 영역의 크기를 변경하기 위한 아이콘 또는 상기 UI 영역의 위치를 삭제하기 위한 아이콘 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 UI 위치 정보는 제1 UI 위치 정보이고,상기 적어도 하나의 프로세서는,상기 신뢰도가 상기 임계값 미만이면, 상기 통신 인터페이스를 통해, 상기 제1 UI 위치 정보와 상이한 제2 UI위치 정보를 요청하는 제어 신호를 상기 서버에 전송하고,상기 통신 인터페이스를 통해, 상기 제어 신호에 대응되는 제2 UI 위치 정보를 상기 서버로부터 수신하고,상기 제2 UI 위치 정보에 기초하여 상기 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하고, 상기 제2 컨텐츠 정보에 대응되는 제2 신뢰도를 획득하고,상기 제2 신뢰도가 상기 임계값 이상이면, 상기 획득된 제2 컨텐츠 정보에 대응되는 응답 정보를 표시하도록 상기 디스플레이를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서, 상기 UI 위치 정보는 제1 UI 위치 정보 및 제2 UI 위치 정보를 포함하고,상기 적어도 하나의 프로세서는,상기 제1 UI 위치 정보 또는 상기 제2 UI 위치 정보 중 하나에 기초하여 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 통신 인터페이스는,공개특허 10-2024-0053431-4-제1 통신 모듈 및 제2 통신 모듈을 포함하고,상기 적어도 하나의 프로세서는,상기 제1 통신 모듈을 통해, 상기 컨텐츠 제공 장치로부터 상기 제1 컨텐츠 및 상기 제2 컨텐츠를 수신하고,상기 제2 통신 모듈을 통해, 상기 서버로부터 상기 UI 위치 정보를 수신하는, 전자 장치."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컨텐츠 제공 장치 및 서버와 통신하고 상기 컨텐츠 제공 장치의 식별 정보를 저장하는 전자 장치의 제어 방법에있어서,상기 컨텐츠 제공 장치로부터 수신된 제1 컨텐츠를 표시하는 단계;기 설정된 이벤트가 발생하면, 상기 컨텐츠 제공 장치의 상기 식별 정보를 상기 서버에 전송하는 단계;상기 식별 정보에 대응되는 UI 위치 정보를 상기 서버로부터 수신하는 단계;상기 표시된 제1 컨텐츠를 제2 컨텐츠로 변경하기 위한 사용자 명령이 수신되면, 상기 제2 컨텐츠를 표시하는단계; 및상기 수신된 UI 위치 정보에 기초하여 상기 제2 컨텐츠에 대응되는 컨텐츠 정보를 획득하는 단계;를 포함하고,상기 UI 위치 정보는,복수의 이미지가 중첩되어 하나의 이미지로 병합된 결합 이미지로부터 획득되는 정보인, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 기 설정된 이벤트는,상기 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트, 상기 전자 장치의 업그레이드가 수행되는 이벤트 또는 상기 UI 위치 정보를 수신하기 위한 사용자 명령이 입력되는 이벤트 중 적어도 하나를 포함하는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 UI 위치 정보는,상기 결합 이미지를 입력 데이터로써 수신하는 인공 지능 모델로부터 출력 데이터로써 획득되는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 UI 위치 정보는,상기 결합 이미지를 입력 데이터로써 수신하여 노이즈 제거 이미지를 출력 데이터로서 획득하는 제1 인공 지능모델 및 상기 노이즈 제거 이미지를 입력 데이터로써 수신하여 상기 UI 위치 정보를 출력 데이터로서 획득하는제2 인공 지능 모델에 기초하여 획득되는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 제어 방법은,상기 획득된 컨텐츠 정보에 대응되는 신뢰도를 획득하는 단계; 및상기 신뢰도가 임계값 이상이면, 상기 획득된 컨텐츠 정보에 대응되는 응답 정보를 표시하는 단계;를 더 포함하는, 제어 방법.공개특허 10-2024-0053431-5-청구항 16 제15항에 있어서,상기 제어 방법은,상기 신뢰도가 상기 임계값 미만이면, 상기 UI 위치 정보를 변경하기 위한 가이드 UI를 표시하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 UI 위치 정보는,컨텐츠와 관련된 정보가 표시되는 UI 영역의 위치를 포함하고,상기 가이드 UI는,상기 UI 영역의 위치를 이동시키기 위한 아이콘, 상기 UI 영역의 크기를 변경하기 위한 아이콘 또는 상기 UI 영역의 위치를 삭제하기 위한 아이콘 중 적어도 하나를 포함하는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,상기 UI 위치 정보는 제1 UI 위치 정보이고,상기 제어 방법은,상기 신뢰도가 상기 임계값 미만이면, 상기 제1 UI 위치 정보와 상이한 제2 UI 위치 정보를 요청하는 제어 신호를 상기 서버에 전송하는 단계;상기 제어 신호에 대응되는 제2 UI 위치 정보를 상기 서버로부터 수신하는 단계;상기 제2 UI 위치 정보에 기초하여 상기 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하는 단계;상기 제2 컨텐츠 정보에 대응되는 제2 신뢰도를 획득하는 단계; 및상기 제2 신뢰도가 상기 임계값 이상이면, 상기 획득된 제2 컨텐츠 정보에 대응되는 응답 정보를 표시하는단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 UI 위치 정보는 제1 UI 위치 정보 및 제2 UI 위치 정보를 포함하고,상기 제2 컨텐츠에 대응되는 컨텐츠 정보를 획득하는 단계는,상기 제1 UI 위치 정보 또는 상기 제2 UI 위치 정보 중 하나에 기초하여 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 전자 장치는,제1 통신 모듈 및 제2 통신 모듈을 포함하고,상기 제2 컨텐츠를 표시하는 단계는,상기 제1 통신 모듈을 통해, 상기 컨텐츠 제공 장치로부터 상기 제1 컨텐츠 및 상기 제2 컨텐츠를 수신하고,상기 UI 위치 정보를 수신하는 단계는,공개특허 10-2024-0053431-6-상기 제2 통신 모듈을 통해, 상기 서버로부터 상기 UI 위치 정보를 수신하는, 제어 방법."}
{"patent_id": "10-2022-0133520", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 전자 장치는 컨텐츠 제공 장치 및 서버와 통신하는 통신 인터페이스, 컨텐츠 제공 장치의 식별 정보를 저장하 는 메모리, 디스플레이 및 컨텐츠 제공 장치로부터 수신된 제1 컨텐츠를 표시하도록 디스플레이를 제어하고, 기 설정된 이벤트가 발생하면, 통신 인터페이스를 통해, 컨텐츠 제공 장치의 식별 정보를 서버에 전송하고, 통신 인 터페이스를 통해, 식별 정보에 대응되는 UI 위치 정보를 서버로부터 수신하고, 표시된 제1 컨텐츠를 제2 컨텐츠 로 변경하기 위한 사용자 명령이 수신되면, 제2 컨텐츠를 표시하도록 디스플레이를 제어하고, 수신된 UI 위치 정 보에 기초하여 제2 컨텐츠에 대응되는 컨텐츠 정보를 획득하는 적어도 하나의 프로세서를 포함하고, UI 위치 정 보는 복수의 이미지가 중첩되어 하나의 이미지로 병합된 결합 이미지로부터 획득되는 정보이다."}
{"patent_id": "10-2022-0133520", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어방법에 관한 것으로, 더욱 상세하게는 화면에 표시되는 컨텐츠와 관련된 정보를 추출하는 전자 장치 및 그 제어방법에 대한 것이다."}
{"patent_id": "10-2022-0133520", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 장치는 컨텐츠 제공 장치(예를 들어, 셋탑 박스)로부터 컨텐츠를 표시하기 위한 화면(이미지)를 수신할 수 있다. 컨텐츠 제공 장치에서 제공하는 화면은 컨텐츠 제공 장치가 제공하는 컨텐츠 자체(예를 들어, 골프 채널 에서 제공하는 이미지 프레임) 및 컨텐츠와 관련된 정보(예를 들어, 채널 번호, 채널 이름, 컨텐츠 이름 등)를 포함하는 UI(User Interface)를 포함할 수 있다. 전자 장치는 컨텐츠 제공 장치로부터 단순히 이미지를 수신하는 것이기 때문에 컨텐츠와 관련된 정보를 자체적 으로 저장하기 어렵다. 따라서, 전자 장치는 OCR(optical character reader) 기능을 수행하거나 ACR(automatic content recognition) 기능을 수행하여 컨텐츠와 관련된 정보를 추출할 수 있다. 하지만, 전자 장치는 컨텐츠 제공 장치에서 제공하는 화면에 포함된 모든 영역을 분석하는 동작의 처리 시간이 오래 걸릴 수 있다. 따라서, 전자 장치는 컨텐츠 제공 장치가 컨텐츠 정보를 표시하는 특정 영역을 미리 저장하 여 특정 영역에 대해서만 컨텐츠 추출 동작을 수행할 수 있다. 하지만, 컨텐츠 제공 장치의 종류가 다양하고, 새로운 컨텐츠 제공 장치가 반복적으로 출시되고 있다는 점에서, 전자 장치는 모든 컨텐츠 제공 장치에 대응되는 UI 표시 영역을 미리 저장하는 것이 어려울 수 있다. 또한, 컨 텐츠 제공 장치마다 소프트웨어 업그레이드 등을 통해 UI 표시 영역을 변경할 수 있다는 점에서, 전자 장치가 이를 바로 반영하여 정상적으로 컨텐츠 정보를 추출하는 것이 어려울 수 있다. 또한, 전자 장치가 컨텐츠 제공 장치로부터 수신된 화면을 캡쳐하여 외부 서버에 전송하는 경우, 캡쳐된 화면 (이미지)에 특정 컨텐츠의 이미지가 포함될 수 있다는 점에서 컨텐츠 권리와 관련된 법적 문제가 발생할 수 있 다."}
{"patent_id": "10-2022-0133520", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 상술한 문제를 개선하기 위해 고안된 것으로, 본 개시의 목적은 복수의 이미지를 중첩된 결합 이미지 에 기초하여 획득된 UI 위치 정보를 수신하여 특정 영역에 대해서만 컨텐츠 정보를 추출하는 전자 장치 및 그의 제어 방법을 제공함에 있다. 다양한 실시 예에 따른 전자 장치는 컨텐츠 제공 장치 및 서버와 통신하는 통신 인터페이스, 상기 컨텐츠 제공 장치의 식별 정보를 저장하는 메모리, 디스플레이 및 상기 컨텐츠 제공 장치로부터 수신된 제1 컨텐츠를 표시하 도록 상기 디스플레이를 제어하고, 기 설정된 이벤트가 발생하면, 상기 통신 인터페이스를 통해, 상기 컨텐츠 제공 장치의 상기 식별 정보를 상기 서버에 전송하고, 상기 통신 인터페이스를 통해, 상기 식별 정보에 대응되 는 UI 위치 정보를 상기 서버로부터 수신하고, 상기 표시된 제1 컨텐츠를 제2 컨텐츠로 변경하기 위한 사용자 명령이 수신되면, 상기 제2 컨텐츠를 표시하도록 상기 디스플레이를 제어하고, 상기 수신된 UI 위치 정보에 기 초하여 상기 제2 컨텐츠에 대응되는 컨텐츠 정보를 획득하는 적어도 하나의 프로세서를 포함하고, 상기 UI 위치 정보는 복수의 이미지가 중첩되어 하나의 이미지로 병합된 결합 이미지로부터 획득되는 정보이다. 한편, 상기 기 설정된 이벤트는 상기 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트, 상기 전자 장치의 업그레이드가 수행되는 이벤트 또는 상기 UI 위치 정보를 수신하기 위한 사용자 명령이 입력되는 이벤트중 적어도 하나를 포함할 수 있다. 한편, 상기 UI 위치 정보는 상기 결합 이미지를 입력 데이터로써 수신하는 인공 지능 모델로부터 출력 데이터로 써 획득될 수 있다. 한편, 상기 UI 위치 정보는 상기 결합 이미지를 입력 데이터로써 수신하여 노이즈 제거 이미지를 출력 데이터로 서 획득하는 제1 인공 지능 모델 및 상기 노이즈 제거 이미지를 입력 데이터로써 수신하여 상기 UI 위치 정보를 출력 데이터로서 획득하는 제2 인공 지능 모델에 기초하여 획득될 수 있다. 한편, 상기 적어도 하나의 프로세서는 상기 획득된 컨텐츠 정보에 대응되는 신뢰도를 획득하고, 상기 신뢰도가 임계값 이상이면, 상기 획득된 컨텐츠 정보에 대응되는 응답 정보를 표시하도록 상기 디스플레이를 제어할 수 있다. 한편, 상기 적어도 하나의 프로세서는 상기 신뢰도가 상기 임계값 미만이면, 상기 UI 위치 정보를 변경하기 위 한 가이드 UI를 표시하도록 상기 디스플레이를 제어할 수 있다. 한편, 상기 UI 위치 정보는 컨텐츠와 관련된 정보가 표시되는 UI 영역의 위치를 포함하고, 상기 가이드 UI는 상 기 UI 영역의 위치를 이동시키기 위한 아이콘, 상기 UI 영역의 크기를 변경하기 위한 아이콘 또는 상기 UI 영역 의 위치를 삭제하기 위한 아이콘 중 적어도 하나를 포함할 수 있다. 한편, 상기 UI 위치 정보는 제1 UI 위치 정보이고, 상기 적어도 하나의 프로세서는 상기 신뢰도가 상기 임계값 미만이면, 상기 통신 인터페이스를 통해, 상기 제1 UI 위치 정보와 상이한 제2 UI 위치 정보를 요청하는 제어 신호를 상기 서버에 전송하고, 상기 통신 인터페이스를 통해, 상기 제어 신호에 대응되는 제2 UI 위치 정보를 상기 서버로부터 수신하고, 상기 제2 UI 위치 정보에 기초하여 상기 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하고, 상기 제2 컨텐츠 정보에 대응되는 제2 신뢰도를 획득하고, 상기 제2 신뢰도가 상기 임계값 이상이면, 상기 획득된 제2 컨텐츠 정보에 대응되는 응답 정보를 표시하도록 상기 디스플레이를 제어할 수 있다. 한편, 상기 UI 위치 정보는 제1 UI 위치 정보 및 제2 UI 위치 정보를 포함하고, 상기 적어도 하나의 프로세서는 상기 제1 UI 위치 정보 또는 상기 제2 UI 위치 정보 중 하나에 기초하여 제2 컨텐츠에 대응되는 제2 컨텐츠 정 보를 획득할 수 있다. 한편, 상기 통신 인터페이스는 제1 통신 모듈 및 제2 통신 모듈을 포함하고, 상기 적어도 하나의 프로세서는 상 기 제1 통신 모듈을 통해, 상기 컨텐츠 제공 장치로부터 상기 제1 컨텐츠 및 상기 제2 컨텐츠를 수신하고, 상기 제2 통신 모듈을 통해, 상기 서버로부터 상기 UI 위치 정보를 수신할 수 있다. 다양한 실시 예에 따른 컨텐츠 제공 장치 및 서버와 통신하고 상기 컨텐츠 제공 장치의 식별 정보를 저장하는 전자 장치의 제어 방법은 상기 컨텐츠 제공 장치로부터 수신된 제1 컨텐츠를 표시하는 단계, 기 설정된 이벤트 가 발생하면, 상기 컨텐츠 제공 장치의 상기 식별 정보를 상기 서버에 전송하는 단계, 상기 식별 정보에 대응되 는 UI 위치 정보를 상기 서버로부터 수신하는 단계, 상기 표시된 제1 컨텐츠를 제2 컨텐츠로 변경하기 위한 사 용자 명령이 수신되면, 상기 제2 컨텐츠를 표시하는 단계 및 상기 수신된 UI 위치 정보에 기초하여 상기 제2 컨 텐츠에 대응되는 컨텐츠 정보를 획득하는 단계를 포함하고, 상기 UI 위치 정보는 복수의 이미지가 중첩되어 하 나의 이미지로 병합된 결합 이미지로부터 획득되는 정보이다. 한편, 상기 기 설정된 이벤트는 상기 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트, 상기 전자 장치의 업그레이드가 수행되는 이벤트 또는 상기 UI 위치 정보를 수신하기 위한 사용자 명령이 입력되는 이벤트 중 적어도 하나를 포함할 수 있다. 한편, 상기 UI 위치 정보는 상기 결합 이미지를 입력 데이터로써 수신하는 인공 지능 모델로부터 출력 데이터로 써 획득될 수 있다. 한편, 상기 UI 위치 정보는 상기 결합 이미지를 입력 데이터로써 수신하여 노이즈 제거 이미지를 출력 데이터로 서 획득하는 제1 인공 지능 모델 및 상기 노이즈 제거 이미지를 입력 데이터로써 수신하여 상기 UI 위치 정보를 출력 데이터로서 획득하는 제2 인공 지능 모델에 기초하여 획득될 수 있다. 한편, 상기 제어 방법은 상기 획득된 컨텐츠 정보에 대응되는 신뢰도를 획득하는 단계 및 상기 신뢰도가 임계값 이상이면, 상기 획득된 컨텐츠 정보에 대응되는 응답 정보를 표시하는 단계를 더 포함할 수 있다. 한편, 상기 제어 방법은 상기 신뢰도가 상기 임계값 미만이면, 상기 UI 위치 정보를 변경하기 위한 가이드 UI를 표시하는 단계를 더 포함할 수 있다. 한편, 상기 UI 위치 정보는 컨텐츠와 관련된 정보가 표시되는 UI 영역의 위치를 포함하고, 상기 가이드 UI는 상 기 UI 영역의 위치를 이동시키기 위한 아이콘, 상기 UI 영역의 크기를 변경하기 위한 아이콘 또는 상기 UI 영역 의 위치를 삭제하기 위한 아이콘 중 적어도 하나를 포함할 수 있다. 한편, 상기 UI 위치 정보는 제1 UI 위치 정보이고, 상기 제어 방법은 상기 신뢰도가 상기 임계값 미만이면, 상 기 제1 UI 위치 정보와 상이한 제2 UI 위치 정보를 요청하는 제어 신호를 상기 서버에 전송하는 단계, 상기 제 어 신호에 대응되는 제2 UI 위치 정보를 상기 서버로부터 수신하는 단계, 상기 제2 UI 위치 정보에 기초하여 상 기 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하는 단계, 상기 제2 컨텐츠 정보에 대응되는 제2 신뢰도를 획득하는 단계 및 상기 제2 신뢰도가 상기 임계값 이상이면, 상기 획득된 제2 컨텐츠 정보에 대응되는 응답 정 보를 표시하는 단계를 더 포함할 수 있다. 한편, 상기 UI 위치 정보는 제1 UI 위치 정보 및 제2 UI 위치 정보를 포함하고, 상기 제2 컨텐츠에 대응되는 컨 텐츠 정보를 획득하는 단계는 상기 제1 UI 위치 정보 또는 상기 제2 UI 위치 정보 중 하나에 기초하여 제2 컨텐 츠에 대응되는 제2 컨텐츠 정보를 획득할 수 있다. 한편, 상기 전자 장치는 제1 통신 모듈 및 제2 통신 모듈을 포함하고, 상기 제2 컨텐츠를 표시하는 단계는 상기 제1 통신 모듈을 통해, 상기 컨텐츠 제공 장치로부터 상기 제1 컨텐츠 및 상기 제2 컨텐츠를 수신하고, 상기 UI 위치 정보를 수신하는 단계는 상기 제2 통신 모듈을 통해, 상기 서버로부터 상기 UI 위치 정보를 수신할 수 있 다."}
{"patent_id": "10-2022-0133520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 다양한 실시 예에 따라, 인공지능모델을 학습하는 과정 및 이용하는 과정을 설명하기 위한 도면이다. 도 1을 참조하면, 시스템은 적어도 하나의 전자 장치(100-1, 100-2), 전자 장치(100-3) 또는 서버 중 적어도 하나를 포함할 수 있다. 적어도 하나의 전자 장치(100-1, 100-2)는 각각 별도의 컨텐츠 제공 장치(10-1, 10-2)와 통신을 수행할 수 있다. 적어도 하나의 전자 장치(100-1, 100-2)는 컨텐츠를 제공(또는 표시)할 수 있는 기기를 의미할 수 있다. 적어도 하나의 전자 장치(100-1, 100-2)는 디스플레이 또는 스피커 중 적어도 하나를 포함하는 기기일 수 있다. 예를 들어, 적어도 하나의 전자 장치(100-1, 100-2)는 TV를 의미할 수 있다. 컨텐츠 제공 장치(10-1, 10-2)는 적어도 하나의 전자 장치(100-1, 100-2)에 연결되어 컨텐츠를 제공하는 기기를 의미할 수 있다. 예를 들어, 컨텐츠 제공 장치(10-1, 10-2)는 셋탑 박스 또는 OTT(Over The Top) 기기를 의미할 수 있다. 적어도 하나의 전자 장치(100-1, 100-2)는 서버와 통신을 수행할 수 있다. 서버는 인공지능모델을 학 습하고 학습 결과에 따른 결과를 저장 및 배포할 수 있다. 예를 들어, 적어도 하나의 전자 장치(100-1, 100-2)는 학습 데이터(결합 이미지)를 서버에 전송할 수 있다. 서버는 적어도 하나의 전자 장치(100-1, 100-2)로부터 수신된 학습 데이터(결합 이미지)를 통해 인 공지능모델에 대한 학습 동작을 수행할 수 있다. 이와 관련된 구체적인 동작은 도 8 내지 도 11에서 기재한다. 서버에 저장된 인공지능모델은 결합 이미지를 입력 데이터로 수신하여 결합 이미지에 포함된 UI의 위치 정 보를 출력 데이터로써 획득하는 모델일 수 있다. 서버는 인공지능모델을 통해 획득한 UI의 위치 정보를 저장하고 있을 수 있다. 그리고, 서버는 전자 장치(100-3)에 UI 위치 정보를 전송할 수 있다. 전자 장치(100-3)는 서버로부터 수신한 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다. 전자 장 치(100-3)는 컨텐츠 제공 장치(10-3)로부터 컨텐츠를 수신할 수 있다. 전자 장치(100-3)는 컨텐츠 제공 장치 (10-3)로부터 수신한 컨텐츠를 전자 장치(100-3)에 포함된 디스플레이에 표시할 수 있으며, 컨텐츠가 표시된 화면에서 UI 위치 정보(서버로부터 수신된 정보)에 기초하여 특정 정보를 추출할 수 있다. 전자 장치(100-3)는 적어도 하나의 전자 장치(100-1, 100-2)와 마찬가지로 디스플레이 또는 스피커 중 적어도 하나를 포함하는 기기일 수 있다. 예를 들어, 서버는 TV를 의미할 수 있다. 한편, 적어도 하나의 전자 장치(100-1, 100-2), 전자 장치(100-3) 등을 전자 장치로 기재할 수 있다. 또한, 컨텐츠 제공 장치(10-1, 10-2, 10-3)를 컨텐츠 제공 장치로 기재할 수 있다. 컨텐츠를 표시하는 다양한 전자 장치 중 일부(100-1, 100-2)는 학습 데이터를 제공하는 동작을 수행할 수 있으 며, 일부(100-3)는 단순히 서버에 컨텐츠 제공 장치(10-3)에 대응되는 UI 위치 정보를 수신하는 동작을 수 행할 수 있다. 하지만, 컨텐츠를 표시하는 동작이 동일하며 다양한 실시 예에 따라 단순히 일부 동작의 수행 여 부가 결정되는 것에 해당하므로, 컨텐츠를 표시하는 기기를 전자 장치로 통일하여 기재할 수 있다. 마찬가 지로 컨텐츠 제공 장치(10-1, 10-2, 10-3)도 컨텐츠 제공 장치로 기재할 수 있다. 도 2는 다양한 실시 예에 따라, 인공지능모델을 학습하는 과정 및 이용하는 과정을 설명하기 위한 도면이다. 도 2를 참조하면, 시스템은 적어도 하나의 전자 장치(100-1, 100-2), 전자 장치(100-3), 제1 서버(200- 1) 또는 제2 서버(200-2) 중 적어도 하나를 포함할 수 있다. 적어도 하나의 전자 장치(100-1, 100-2) 및 전자 장치(100-3)에 대한 설명을 도 1에서 기재하였는 바, 중복 설명을 생략한다. 도 1에서 기재한 서버는 복수의 서버(200-1, 200-2)로 구현될 수 있다. 제1 서버(200-1)는 학습 데이터(결 합 이미지)를 수신하여 노이즈가 제거된 이미지를 획득할 수 있다. 제1 서버(200-1)는 노이즈가 제거된 이미지 를 제2 서버(200-2)에 전송할 수 있다. 제2 서버(200-2)는 제1 서버(200-1)로부터 수신한 노이즈 제거 이미지에 기초하여 UI 위치 정보를 획득할 수 있 다. 그리고, 제2 서버(200-2)는 획득한 UI 위치 정보를 저장할 수 있다. 제2 서버(200-2)는 전자 장치(100-3)에 UI 위치 정보를 전송할 수 있다. 전자 장치(100-3)는 제2 서버(200-2)로부터 획득한 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다. 도 3은 다양한 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 3을 참조하면, 전자 장치는 통신 인터페이스, 메모리, 디스플레이 또는 적어도 하나의 프로세서 중 적어도 하나를 포함할 수 있다. 통신 인터페이스는 컨텐츠 제공 장치 및 서버와 통신할 수 있다. 메모리는 컨텐츠 제공 장치의 식별 정보를 저장할 수 있다. 디스플레이는 컨텐츠 제공 장치로부터 수신되는 컨텐츠를 표시할 수 있다. 적어도 하나의 프로세서는 컨텐츠 제공 장치로부터 수신된 제1 컨텐츠를 표시하도록 디스플레이 를 제어하고, 기 설정된 이벤트가 발생하면, 통신 인터페이스를 통해, 컨텐츠 제공 장치의 식별 정보를 서버에 전송하고, 통신 인터페이스를 통해, 식별 정보에 대응되는 UI 위치 정보를 서버로부 터 수신하고, 표시된 제1 컨텐츠를 제2 컨텐츠로 변경하기 위한 사용자 명령이 수신되면, 제2 컨텐츠를 표시하 도록 디스플레이를 제어하고, 수신된 UI 위치 정보에 기초하여 제2 컨텐츠에 대응되는 컨텐츠 정보를 획득 할 수 있으며, UI 위치 정보는 복수의 이미지가 중첩되어 하나의 이미지로 병합된 결합 이미지로부터 획득되는 정보일 수 있다. 다양한 실시 예에 따라, 제1 컨텐츠(제2 컨텐츠)를 표시하는 동작은 컨텐츠 제공 장치에서 제공하는 컨텐츠 자체를 표시하는 동작일 수 있다. 다양한 실시 예에 따라, 제1 컨텐츠(제2 컨텐츠)를 표시하는 동작은 컨텐츠 자체 및 컨텐츠와 관련된 정보를 함 께 표시하는 동작일 수 있다. 컨텐츠와 관련된 정보(컨텐츠 정보)는 채널 번호, 채널 이름, 컨텐츠 제공 시간"}
{"patent_id": "10-2022-0133520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또는 컨텐츠 이름 중 적어도 하나를 포함할 수 있다. 컨텐츠 정보는 메타 데이터 또는 컨텐츠 요약 정보로 기재 될 수 있다. 이와 관련된 구체적인 설명은 도 8에서 기재한다. 다양한 실시 예에 따라, 제1 컨텐츠(제2 컨텐츠)를 표시하는 동작은 컨텐츠 제공 장치에서 제공하는 화면 (또는 이미지)를 표시하는 동작을 의미할 수 있다. 컨텐츠 제공 장치에서 제공하는 화면(또는 이미지)는 컨 텐츠 자체 및 컨텐츠와 관련된 정보를 함께 포함할 수 있다. 또한, 컨텐츠와 관련된 정보는 컨텐츠 제공 장치 에서 기 설정된 영역(또는 위치 또는 좌표)에 고정적으로 표시될 수 있다. 예를 들어, 컨텐츠 제공 장치 가 제공하는 컨텐츠가 상이해도, 컨텐츠와 관련된 정보가 표시되는 위치는 고정적일 수 있다. 컨텐츠 제공 장치의 식별 정보는 컨텐츠 제공 장치를 나타내는 정보일 수 있다. 컨텐츠 제공 장치 의 식별 정보는 컨텐츠 제공 장치를 특정할 수 있는 이름 또는 모델명 중 적어도 하나를 포함할 수 있다. 식별 정보는 컨텐츠 제공 장치에 대응되는 UI 위치 정보를 검색하는데 이용될 수 있다. UI 위치 정보는 컨텐츠 정보를 표시하는 위치(또는 영역)를 나타내는 정보일 수 있다. 컨텐츠 정보는 컨텐츠와 관련된 정보일 수 있다. 컨텐츠 정보는 컨텐츠 제공 장치에서 제공하는 컨텐츠 자체(예를 들어, 복수의 이 미지 프레임)와 상이할 수 있다. 컨텐츠(제1 컨텐츠, 제2 컨텐츠)는 컨텐츠 제공 장치로부터 제공되는 이미지, 동영상, 방송 신호, 컨텐츠 정보 중 적어도 하나를 포함할 수 있다. 적어도 하나의 프로세서는 컨텐츠 제공 장치로부터 컨텐츠 정보를 수신할 수 있으며, 미리 지정된 영 역(컨텐츠 제공 장치의 고유 설정에 따른 영역)에 컨텐츠 정보를 표시할 수 있다. 적어도 하나의 프로세서는 기 설정된 이벤트의 발생 여부를 판단할 수 있다. 기 설정된 이벤트가 발생된 것으로 판단되면, 적어도 하나의 프로세서는 컨텐츠 제공 장치의 식별 정보를 서버에 전송할 수 있다. 한편, 기 설정된 이벤트는 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트, 전자 장치의 업그 레이드가 수행되는 이벤트 또는 UI 위치 정보를 수신하기 위한 사용자 명령이 입력되는 이벤트 중 적어도 하나 를 포함할 수 있다. 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트는 기 설정된 위치(또는 영역)에서 컨텐츠와 관련된 정보가 추출되지 않는 이벤트를 의미할 수 있다. 다양한 실시 예에 따라, 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트는 적어도 하나의 프로세서가 수집하는 컨텐츠 정보에 타겟 정보가 포함되지 않는 이 벤트일 수 있다. 타겟 정보는 채널 번호, 채널 이름, 컨텐츠 제공 시간 또는 컨텐츠 이름 중 적어도 하나를 포 함할 수 있다. 전자 장치의 업그레이드가 수행되는 이벤트는 주기적 또는 일시적으로 수행되는 전자 장치이 소프트 웨어 업그레이드와 관련된 제어 명령이 획득되는 이벤트일 수 있다. UI 위치 정보를 수신하기 위한 사용자 명령이 입력되는 이벤트는 사용자가 직접 UI 위치 정보를 서버에 요 청하는 이벤트일 수 있다. 서버는 전자 장치로부터 컨텐츠 제공 장치의 식별 정보를 수신할 수 있다. 그리고, 서버는 서버에 저장된 UI 테이블에서 전자 장치로부터 수신된 식별 정보에 대응되는 UI 위치 정보를 식별할 수 있다. UI 테이블은 식별 정보 및 UI 위치 정보가 맵핑되어 있을 수 있다. 따라서, 식별 정보가 수신되면, 서버는 UI 테이블에 기초하여 식별 정보에 대응되는 UI 위치 정보를 식별할 수 있다. 그리고, 서버는 식별된 UI 위치 정보를 전자 장치에 전송할 수 있다. UI 테이블에 관련된 구체적인 설명은 도 13 내지 도 16에서 기 재한다. 서버로부터 UI 위치 정보를 수신한 후, 적어도 하나의 프로세서는 컨텐츠 변경을 위한 사용자 명령을 수신할 수 있다. 예를 들어, 사용자 명령은 채널 변경일 수 있다. 사용자 명령이 수신되면, 적어도 하나의 프로 세서는 사용자 명령에 기초하여 제1 컨텐츠 대신 제2 컨텐츠를 표시하도록 디스플레이를 제어할 수 있다. 사용자 명령에 따라 제2 컨텐츠가 표시되면, 적어도 하나의 프로세서는 컨텐츠 제공 장치로부터 수신 한 컨텐츠 정보(컨텐츠와 관련된 정보)를 디스플레이에 표시할 수 있다. 다양한 실시 예에 따라, 적어도 하나의 프로세서는 사용자 명령이 수신된 시점으로부터 임계 시간(예를 들 어, 2초) 동안 컨텐츠 정보를 디스플레이에 표시할 수 있다. 임계 시간이 경과하면, 적어도 하나의 프로세 서는 더 이상 컨텐츠 정보를 디스플레이에 표시하지 않을 수 있다. 적어도 하나의 프로세서는 컨텐츠 제공 장치에서 제공하는 컨텐츠 정보만 컨텐츠와 분리하여 별도로 수신하지 않을 수 있다. 따라서, 적어도 하나의 프로세서는 컨텐츠 정보만을 판단하기 위해 별도의 분석 동작을 수행할 수 있다. 분석 동작은 화면에 표시되는 이미지를 캡쳐하여 OCR(optical character reader) 기능 을 수행하거나 ACR(automatic content recognition) 기능을 수행하는 것을 의미할 수 있다. 적어도 하나의 프로세서는 컨텐츠 정보가 디스플레이에 표시되는 동안, 디스플레이에 표시되는 화면을 캡쳐하여 캡쳐 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 캡쳐 이미지의 전체 영역 중 UI 위치 정보에 대응되는 영역에서 정보를 추출할 수 있다. UI 위치 정보에 대응되는 영역에서 컨텐츠 정보를 획득할 수 있다. 서버로부터 수신한 UI 위치 정보가 컨텐츠 제공 장치에 대응되는 정보라면, 컨텐츠 제공 장치에서 제공하는 컨텐츠 정보와 UI 위치 정보에 기초하여 추출되는 컨텐츠 정보가 일치할 수 있다. 서버로부터 수신한 UI 위치 정보가 컨텐츠 제공 장치에 대응되는 정보가 아니라면, 컨텐츠 제공 장치 에서 제공하는 컨텐츠 정보와 UI 위치 정보에 기초하여 추출되는 컨텐츠 정보가 일치하지 않을 수 있다. 적어도 하나의 프로세서는 컨텐츠 제공 장치에서 제공하는 컨텐츠 정보만을 별도로 수신하지 못할 수 있다. 따라서, 적어도 하나의 프로세서는 컨텐츠 제공 장치에서 제공하는 컨텐츠 정보와 UI 위치 정보 에 기초하여 추출되는 컨텐츠 정보의 완벽한 일치 여부를 판단하지 못할 수 있다. 따라서, 적어도 하나의 프로 세서는 UI 위치 정보에 기초하여 추출되는 컨텐츠 정보에 기 설정된 타겟 정보가 포함되어 있는지 여부를 판단할 수 있다. 여기서, 기 설정된 타겟 정보는 채널 번호, 채널 이름, 컨텐츠 제공 시간 또는 컨텐츠 이름 중 적어도 하나를 포함할 수 있다. UI 위치 정보에 기초하여 추출되는 컨텐츠 정보에 기 설정된 타겟 정보가 포함되면, 적어도 하나의 프로세서 는 UI 위치 정보가 컨텐츠 제공 장치에서 제공하는 컨텐츠 정보가 표시되는 위치와 일치한다고 판단할 수 있다. 한편, UI 위치 정보는 결합 이미지를 입력 데이터로써 수신하는 인공 지능 모델로부터 출력 데이터로써 획득될 수 있다. UI 위치 정보는 인공 지능 모델에 의하여 출력되는 결과 데이터일 수 있다. 또한, 결과 데이터의 UI 위치 정보 는 UI 테이블에 저장될 수 있다. UI 테이블은 서버에 저장될 수 있다. 인공 지능 모델은 결합 이미지를 입 력 데이터로써 수신하여 UI 위치 정보를 출력 데이터로써 출력하는 모델일 수 있다. 결합 이미지는 복수의 캡쳐 이미지에 기초하여 생성될 수 있다. 결합 이미지는 제1 컨텐츠에 대응되는 제1 이미 지 및 제2 컨텐츠에 대응되는 제2 이미지를 하나의 이미지로 중첩한 이미지일 수 있다. 결합 이미지를 생성하는 동작은 도 5 내지 도 9에서 기재한다. 한편, UI 위치 정보는 결합 이미지를 입력 데이터로써 수신하여 노이즈 제거 이미지를 출력 데이터로서 획득하 는 제1 인공 지능 모델 및 노이즈 제거 이미지를 입력 데이터로써 수신하여 UI 위치 정보를 출력 데이터로서 획 득하는 제2 인공 지능 모델에 기초하여 획득될 수 있다.인공 지능 모델(통합 인공 지능 모델)은 세부 동작을 구분함에 따라 제1 인공 지능 모델 및 제2 인공 지능 모델 을 포함할 수 있다. 제1 인공 지능 모델은 수신된 입력 이미지(결합 이미지)에서 노이즈로 판단되는 영역을 제거하여 출력 이미지 (노이즈 제거 이미지)를 획득하는 모델일 수 있다. 노이즈로 판단되는 영역은 텍스트(문자, 숫자를 포함하는 개 념)가 인식되지 않는 영역을 의미할 수 있다. 제1 인공 지능 모델과 관련된 설명은 도 10에서 기재한다. 제2 인공 지능 모델은 제1 인공 지능 모델의 출력 데이터(노이즈 제거 이미지)를 입력 데이터로 수신하여 UI 위 치 정보를 출력 데이터로써 획득하는 모델일 수 있다. UI 위치 정보는 수신된 입력 데이터(노이즈 제거 이미 지)에서 텍스트가 인식되는 영역의 위치를 포함할 수 있다. 제2 인공 지능 모델과 관련된 설명은 도 11에서 기 재한다. UI 위치 정보는 이미지 형태 또는 좌표 형태로 생성될 수 있다. UI 위치 정보는 UI 테이블에 저장될 수 있다. UI 테이블 및 UI 위치 정보에 대한 설명은 도 13 내지 도 14에서 기재한다. 다양한 실시 예에 따라, 제1 인공지능모델 및 제2 인공지능모델은 서버에 저장될 수 있다. 이와 관련된 설 명은 도 1에서 기재하였다. 다양한 실시 예에 따라, 제1 인공지능모델은 제1 서버(200-1)에 저장되고 제2 인공지능모델은 제2 서버(200- 2)에 저장될 수 있다. 이와 관련된 설명은 도 2에서 기재하였다. 다양한 실시 예에 따라, 제1 인공지능모델 및 제2 인공지능모델은 전자 장치에 저장될 수 있다. 이와 관련 된 설명은 도 22에서 기재하였다. 한편, 적어도 하나의 프로세서는 획득된 컨텐츠 정보에 대응되는 신뢰도를 획득하고, 신뢰도가 임계값 이 상이면, 획득된 컨텐츠 정보에 대응되는 응답 정보를 표시하도록 디스플레이를 제어할 수 있다. 신뢰도는 획득된 컨텐츠 정보(추출된 컨텐츠 정보)의 인식률을 나타낼 수 있다. 적어도 하나의 프로세서는 UI 위치 정보에 기초하여 추출되는 컨텐츠 정보에 기 설정된 타겟 정보가 포함되어 있는지 여부를 판단함으로써 신뢰도(인식률)를 획득할 수 있다. 여기서, 기 설정된 타겟 정보는 채널 번호, 채널 이름, 컨텐츠 제공 시간 또 는 컨텐츠 이름 중 적어도 하나를 포함할 수 있다. 예를 들어, 적어도 하나의 프로세서는 UI 위치 정보에 기초하여 추출된 정보에 타겟 정보가 포함되어 있는 지 여부를 판단할 수 있다. 예를 들어, 추출된 정보가 10개이고, 추출된 정보(10개) 중 타겟 정보를 포함하는 정보가 5개인 것으로 가정한다. 이 경우, 신뢰도(인식률)은 0.5(50%)일 수 있다. 신뢰도가 임계값(예를 들어, 60%) 이상이면, 적어도 하나의 프로세서는 UI 위치 정보가 컨텐츠 제공 장치 에 대응된다고 판단할 수 있다. 따라서, 적어도 하나의 프로세서는 UI 위치 정보를 컨텐츠 제공 장치 의 기본 UI 표시 위치로 설정할 수 있으며, UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다. 적어도 하나의 프로세서는 추출된 컨텐츠 정보에 대응되는 응답 정보를 생성(또는 식별)할 수 있다. 여기 서, 응답 정보는 사용자에게 제공되는 다양한 형태의 서비스 컨텐츠를 의미할 수 있다. 예를 들어, 응답 정보는 광고 컨텐츠, 추천 컨텐츠, 스케쥴 알림 등 사용자에게 제공되는 다양한 형태의 정보를 포함할 수 있다. 적어도 하나의 프로세서는 생성된(또는 식별된) 응답 정보를 사용자에게 제공할 수 있다. 구체적으로, 적 어도 하나의 프로세서는 응답 정보를 포함하는 UI를 생성할 수 있으며, 생성된 UI를 전자 장치에 기 설정된 레이아웃 또는 위치에 표시되도록 디스플레이를 제어할 수 있다. 또한, 생성된 UI는 팝업 형태로 디스플레이에 표시될 수 있다. 신뢰도와 관련된 구체적인 설명은 도 19에서 기재한다. 한편, 적어도 하나의 프로세서는 신뢰도가 임계값 미만이면, UI 위치 정보를 변경하기 위한 가이드 UI를 표시하도록 디스플레이를 제어할 수 있다. 한편, UI 위치 정보는 컨텐츠와 관련된 정보가 표시되는 UI 영역의 위치를 포함하고, 가이드 UI는 UI 영역의 위 치를 이동시키기 위한 아이콘, UI 영역의 크기를 변경하기 위한 아이콘 또는 UI 영역의 위치를 삭제하기 위한 아이콘 중 적어도 하나를 포함할 수 있다. UI 위치 정보를 변경하는 동작 및 가이드 UI에 표시되는 다양한 UI와 관련된 은 도 20 내지 도 21에서 기재한다.한편, UI 위치 정보는 제1 UI 위치 정보이고, 적어도 하나의 프로세서는 신뢰도가 임계값 미만이면, 통신 인터페이스를 통해, 제1 UI 위치 정보와 상이한 제2 UI 위치 정보를 요청하는 제어 신호를 서버에 전 송하고, 통신 인터페이스를 통해, 제어 신호에 대응되는 제2 UI 위치 정보를 서버로부터 수신하고, 제2 UI 위치 정보에 기초하여 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하고, 제2 컨텐츠 정보에 대응되는 제2 신뢰도를 획득하고, 제2 신뢰도가 임계값 이상이면, 획득된 제2 컨텐츠 정보에 대응되는 응답 정보를 표시 하도록 디스플레이를 제어할 수 있다. 이와 관련된 구체적인 동작은 도 17에서 기재한다. 한편, UI 위치 정보는 제1 UI 위치 정보 및 제2 UI 위치 정보를 포함하고, 적어도 하나의 프로세서는 제1 UI 위치 정보 또는 제2 UI 위치 정보 중 하나에 기초하여 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득할 수 있다. 이와 관련된 구체적인 동작은 도 18에서 기재한다. 한편, 통신 인터페이스는 제1 통신 모듈 및 제2 통신 모듈을 포함하고, 적어도 하나의 프로세서는 제 1 통신 모듈을 통해, 컨텐츠 제공 장치로부터 제1 컨텐츠 및 제2 컨텐츠를 수신하고, 제2 통신 모듈을 통해, 서버로부터 UI 위치 정보를 수신할 수 있다. 여기서, 제1 통신 모듈은 HDMI(High-Definition Multimedia Interface)를 이용하는 통신 인터페이스를 의미할 수 있다. 여기서, 제2 통신 모듈은 이더넷(Ethernet)을 이용하는 통신 인터페이스를 의미할 수 있다. 다양한 실시 예에 따른 전자 장치는 서버로부터 수신된 UI 위치 정보에 기초하여 캡쳐 이미지를 획득 한다. 적어도 하나의 프로세서는 UI 위치 정보에 기초하여 일부 영역에 대해서 컨텐츠 정보를 추출할 수 있다. 전체 영역이 아닌 UI 위치 정보에 기초하여 일부 영역에 대해서만 캡쳐 이미지를 분석하므로 처리 속도 및 처리 시간이 절약될 수 있다. 또한, 전자 장치는 연결되는 컨텐츠 제공 장치에 따라서 제공되는 컨텐츠 정보가 다양한 위치에 표시 (또는 제공될 수 있다. 전자 장치가 컨텐츠 제공 장치마다 상이한 컨텐츠 정보의 표시 위치를 알기 어 려우므로, 컨텐츠 제공 장치의 식별 정보에 적합한 UI 위치 정보를 서버로부터 수신할 수 있다. 사용 자는 역시 전세계에 판매되는 수많은 컨텐츠 제공 장치들에 대한 모든 UI 위치 정보를 서버에 입력하는 것 이 어려울 수 있다. 따라서, 복수의 전자 장치(100-1, 100-2) 등에 의하여 학습 데이터를 수신하여 자동으로 학 습 동작을 수행함으로써 다양한 컨텐츠 제공 장치에 대한 UI 위치 정보가 수집될 수 있다. 또한, UI 위치 정보는 인공 지능 모델에 의하여 수집 및 분석되므로, 사용자가 직접 UI 위치 정보를 입력하는 방법보다 정확도 내지 적용 가능성이 높아질 수 있다. 도 4는 도 3의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 4를 참조하면, 전자 장치는 통신 인터페이스, 메모리, 디스플레이, 적어도 하나의 프로 세서, 조작 인터페이스, 입출력 인터페이스, 스피커, 마이크 중 적어도 하나를 포함 할 수 있다. 본 명세서의 다양한 실시 예들에 따른 전자 장치는, 예를 들면, 스마트폰, 태블릿 PC, 이동 전화기, 데스 크탑 PC, 랩탑 PC, PDA, PMP(portable multimedia player) 중 적어도 하나를 포함할 수 있다. 어떤 실시 예들 에서, 전자 장치는, 예를 들면, 텔레비전, DVD(digital video disk) 플레이어, 미디어 박스 중 적어도 하 나를 포함할 수 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 장치와 통신을 수행하는 구성이다. 통신 인터페이스는 무선 통신 모듈 또는 유선 통신 모듈을 포함할 수 있다. 여기서, 각 통신 모 듈은 적어도 하나의 하드웨어 칩 형태로 구현될 수 있다. 무선 통신 모듈은 무선으로 외부 장치와 통신하는 모듈일 수 있다. 예를 들어, 무선 통신 모듈은 와이파이 모듈, 블루투스 모듈, 적외선 통신 모듈 또는 기타 통신 모듈 중 적어도 하나의 모듈을 포함할 수 있다. 와이파이 모듈, 블루투스 모듈은 각각 와이파이 방식, 블루투스 방식으로 통신을 수행할 수 있다. 와이파이 모 듈이나 블루투스 모듈을 이용하는 경우에는 SSID(service set identifier) 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하여, 이를 이용하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 적외선 통신 모듈은 가시 광선과 밀리미터파 사이에 있는 적외선을 이용하여 근거리에 무선으로 데이터를 전송 하는 적외선 통신(IrDA, infrared Data Association)기술에 따라 통신을 수행한다. 기타 통신 모듈은 상술한 통신 방식 이외에 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통신 칩을 포함할 수 있다. 유선 통신 모듈은 유선으로 외부 장치와 통신하는 모듈일 수 있다. 예를 들어, 유선 통신 모듈은 LAN(Local Area Network) 모듈, 이더넷 모듈, 페어 케이블, 동축 케이블, 광섬유 케이블 또는 UWB(Ultra Wide-Band) 모듈 중 적어도 하나를 포함할 수 있다. 메모리는 적어도 하나의 프로세서에 포함된 롬(ROM)(예를 들어, EEPROM(electrically erasable programmable read-only memory)), 램(RAM) 등의 내부 메모리로 구현되거나, 적어도 하나의 프로세서와 별도의 메모리로 구현될 수도 있다. 이 경우, 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디 드된 메모리 형태로 구현되거나, 전자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들 어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치 의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 전자 장 치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결 가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 디스플레이는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, PDP(Plasma Display Panel) 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 디스플레이내에는 a- si TFT(amorphous silicon thin film transistor), LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한편, 디스플레이 는 터치 센서와 결합된 터치 스크린, 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display, three-dimensional dispaly) 등으로 구현될 수 있다. 또한, 본 개시의 일 실시 예에 따른, 디스플레 이는 이미지를을 출력하는 디스플레이 패널뿐만 아니라, 디스플레이 패널을 하우징하는 베젤을 포함할 수 있다. 특히, 본 개시의 일 실시 예에 따른, 베젤은 사용자 인터렉션을 감지하기 위한 터치 센서(미도시)를 포함 할 수 있다. 적어도 하나의 프로세서는 전자 장치의 전반적인 제어 동작을 수행할 수 있다. 구체적으로, 적어도 하나의 프로세서는 전자 장치의 전반적인 동작을 제어하는 기능을 한다. 적어도 하나의 프로세서는 디지털 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), GPU(graphics- processing unit) 또는 커뮤니케이션 프로세서(communication processor(CP)), ARM(advanced reduced instruction set computer (RISC) machines) 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의 될 수 있다. 또한, 적어도 하나의 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또한, 적어도 하나의 프로세서는 메모리에 저장된 컴퓨터 실행가능 명령어(computer executable instructions)를 실행함으로써 다양한 기능을 수행할 수 있다. 조작 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기 능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린으로도 구현될 수 있다. 여기서, 버튼은 전자 장치의 본체 외관의 전면부나 측면부, 배면부 등의 임의의 영역에 형성된 기계적 버튼, 터치 패드, 휠 등과 같은 다 양한 유형의 버튼이 될 수 있다. 입출력 인터페이스는 HDMI(High Definition Multimedia Interface), MHL (Mobile High-Definition Link), USB (Universal Serial Bus), DP(Display Port), 썬더볼트(Thunderbolt), VGA(Video Graphics Array) 포트, RGB 포트, D-SUB(D-subminiature), DVI(Digital Visual Interface) 중 어느 하나의 인터페이스일 수 있 다. 입출력 인터페이스는 오디오 및 비디오 신호 중 적어도 하나를 입출력 할 수 있다. 구현 예에 따라, 입출력 인터페이스는 오디오 신호만을 입출력하는 포트와 비디오 신호만을 입출력하는 포트를 별개의 포트 로 포함하거나, 오디오 신호 및 비디오 신호를 모두 입출력하는 하나의 포트로 구현될 수 있다. 한편, 전자 장 치는 입출력 인터페이스를 통해 오디오 및 비디오 신호 중 적어도 하나를 외부 장치(예를 들어, 외부 디스플레이 장치 또는 외부 스피커)에 전송할 수 있다. 구체적으로, 입출력 인터페이스에 포함된 출력 포 트가 외부 장치와 연결될 수 있으며, 전자 장치는 오디오 및 비디오 신호 중 적어도 하나를 출력 포트를 통해 외부 장치에 전송할 수 있다. 여기서, 입출력 인터페이스는 통신 인터페이스와 연결될 수 있다. 입출력 인터페이스는 외부 기기로 부터 수신되는 정보를 통신 인터페이스에 전송하거나 통신 인터페이스를 통해 수신되는 정보를 외부 기기에 전 송할 수 있다. 스피커는 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지 등을 출력하는 구성요소일 수 있 다. 마이크는 사용자 음성이나 기타 소리를 입력 받아 오디오 데이터로 변환하기 위한 구성이다. 마이크 는 활성화 상태에서 사용자의 음성을 수신할 수 있다. 예를 들어, 마이크는 전자 장치의 상측이나 전 면 방향, 측면 방향 등에 일체형으로 형성될 수 있다. 마이크는 아날로그 형태의 사용자 음성을 수집하는 마이크, 수집된 사용자 음성을 증폭하는 앰프 회로, 증폭된 사용자 음성을 샘플링하여 디지털 신호로 변환하는 A/D 변환회로, 변환된 디지털 신호로부터 노이즈 성분을 제거하는 필터 회로 등과 같은 다양한 구성을 포함할 수 있다. 도 5는 결합 이미지를 생성하여 UI 위치 정보를 획득하는 동작을 설명하기 위한 흐름도이다. 도 5를 참조하면, 전자 장치는 컨텐츠 제공 장치의 식별 정보를 획득할 수 있다 (S505). 여기서, 컨텐츠 제공 장치는 전자 장치에 컨텐츠를 제공하는 기기(예를 들어, 셋탑 박스 또는 OTT 기기)일 수 있다. 전자 장치는 컨텐츠 제공 장치의 식별 정보를 획득할 수 있다. 전자 장치는 컨텐츠 제공 장치의 식별 정보 를 컨텐츠 제공 장치로부터 수신할 수 있다. 전자 장치는 제1 컨텐츠에 대응되는 제1 이미지를 획득할 수 있다 (S510). 전자 장치는 제1 컨텐츠를 디스플레이에 표시할 수 있다. 그리고, 전자 장치는 표시된 제1 컨텐츠에 대응되는 화면을 캡쳐하여 제1 이미지를 획득할 수 있다. 전자 장치는 제2 컨텐츠에 대응되는 제2 이미지를 획득할 수 있다 (S520). 전자 장치는 제2 컨텐츠를 디스플레이에 표시할 수 있다. 그리고, 전자 장치는 표시된 제2 컨텐츠에 대응되는 화면을 캡쳐하여 제2 이미지를 획득할 수 있다. 전자 장치는 제1 이미지 및 제2 이미지를 병합(또는 결합)하여 결합 이미지를 획득할 수 있다 (S520). 전 자 장치는 제1 이미지 및 제2 이미지를 중첩하여 하나의 이미지를 생성할 수 있다. 결합 이미지와 관련된 구체적인 설명은 도 8 및 도 9에서 기재한다. 전자 장치는 컨텐츠 제공 장치의 식별 정보 및 결합 이미지를 서버에 전송할 수 있다 (S525). 서버는 전자 장치로부터 컨텐츠 제공 장치의 식별 정보 및 결합 이미지를 수신할 수 있다. 서버(20 0)는 결합 이미지를 제1 인공지능모델에 입력하여 노이즈 제거 이미지를 획득할 수 있다 (S530). 제1 인공지능 모델은 결합 이미지를 입력 데이터로써 수신하여 노이즈 제거 이미지를 출력 데이터로써 출력하는 딥러닝 모델 일 수 있다. 제1 인공지능모델과 관련된 구체적인 설명은 도 10에서 기재한다. 서버는 노이즈 제거 이미지를 제2 인공지능모델에 입력하여 UI 위치 정보를 획득할 수 있다 (S530). 제2 인공지능모델은 노이즈 제거 이미지를 입력 데이터로써 수신하여 UI 위치 정보를 출력 데이터로써 출력하는 딥 러닝 모델일 수 있다. 제2 인공지능모델과 관련된 구체적인 설명은 도 11에서 기재한다.서버는 컨텐츠 제공 장치의 식별 정보와 UI 위치 정보를 맵핑한 UI 테이블을 저장할 수 있다 (S540). 서버 는 컨텐츠 제공 장치에 대응되는 UI 위치 정보를 맵핑한 UI 테이블을 생성할 수 있다. UI 테이블에서 맵핑 기준은 컨텐츠 제공 장치의 식별 정보가 이용될 수 있다. UI 테이블과 관련된 구체적인 설명은 도 15에서 기재 한다. 서버는 UI 테이블에 포함된 하나의 UI 위치 정보를 전자 장치에 전송할 수 있다 (S545). UI 위치 정 보는 전자 장치에 연결된 컨텐츠 제공 장치에 대응되는 정보일 수 있다. 전자 장치는 서버로부터 UI 위치 정보를 수신할 수 있다. 전자 장치는 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다 (S550). 전자 장치는 컨텐츠를 디스플레이에 표시할 수 있다. 그리고, 전자 장치는 표시된 컨텐츠를 포함하는 화면을 캡쳐하여 캡쳐 이미지를 획득할 수 있다. 전자 장치는 UI 위치 정보에 기초하여 캡쳐 이미지에서 컨텐츠 정보를 추출할 수 있다. 예를 들어, 전자 장치는 캡쳐 이미지의 전체 영역 중 UI 위치 정보에 포함된 위치에 대응되는 영역만을 분 석할 수 있다. 전자 장치는 컨텐츠 정보에 기초하여 응답 정보를 제공할 수 있다 (S555). 전자 장치는 UI 위치 정보 에 대응되는 영역에서 컨텐츠 정보를 획득할 수 있으며, 획득된 컨텐츠 정보에 대응되는 응답 정보를 획득할 수 있다. 그리고, 전자 장치는 획득된 응답 정보를 제공할 수 있다. 응답 정보는 획득된 컨텐츠 정보와 관련 된 추천 컨텐츠 또는 광고 컨텐츠 등을 포함할 수 있다. 도 6은 결합 이미지를 생성하는 장치와 UI 위치 정보를 요청하는 장치가 상이한 실시 예를 설명하기 위한 흐름 도이다. 도 6의 S605, S610, S615, S620, S625, S630, S635, S640, S645, S650, S655 단계는 S505, S510, S515, S520, S525, S530, S535, S540, S545, S550, S555 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 다만, S605 내지 S625 단계는 제1 전자 장치(100-1)가 수행하고, S650, S655 단계는 제1 전자 장치(100-1)와 상이한 제2 전자 장치(100-2)가 수행할 수 있다. 제2 전자 장치(100-2)는 기 설정된 이벤트가 발생했는지 여부를 식별할 수 있다 (S641). 기 설정된 이벤트는 기 존 UI 위치 정보에 기초하여 컨텐츠 정보가 추출되지 않는 이벤트, 업데이트 명령을 획득한 이벤트 또는 UI 위 치 정보를 수신하기 위한 사용자 명령을 획득한 이벤트 중 적어도 하나를 포함할 수 있다. 기존 UI 위치 정보에 기초하여 컨텐츠 정보가 추출되지 않는 이벤트는 제2 전자 장치(100-2)에 저장된 UI 위치 정보에 기초하여 추출된 컨텐츠 정보에 오류가 있음이 식별되는 이벤트 또는 제2 전자 장치(100-2)에 저장된 UI 위치 정보에 기초하여 컨텐츠 정보가 추출되지 않는 이벤트 중 적어도 하나를 포함할 수 있다. 기 설정된 이벤트가 발생하지 않으면 (S641-N), 전자 장치는 반복적으로 기 설정된 이벤트의 발생 여부를 확인할 수 있다. 기 설정된 이벤트가 발생하면 (S641-Y), 전자 장치는 컨텐츠 제공 장치의 식별 정보를 서버에 전송할 수 있다. 제2 전자 장치(100-2)는 컨텐츠 제공 장치와 연결될 수 있다. 다양한 실시 예에 따라, 제1 전자 장치(100-1)에 연결된 컨텐츠 제공 장치(10-1)와 제2 전자 장치(100-2)에 연 결된 컨텐츠 제공 장치(10-2)가 상이할 수 있다. 다양한 실시 예에 따라, 제1 전자 장치(100-1)에 연결된 컨텐츠 제공 장치(10-1)와 제2 전자 장치(100-2)에 연 결된 컨텐츠 제공 장치(10-2)가 동일할 수 있다. 서버는 제2 전자 장치(100-2)로부터 컨텐츠 제공 장치의 식별 정보를 수신할 수 있다. 서버는 UI 테 이블에 기초하여 제2 전자 장치(100-2)가 전송한 식별 정보(컨텐츠 제공 장치의 식별 정보)에 대응되는 UI 위치 정보를 식별할 수 있다 (S643). 그리고, 서버는 식별된 UI 위치 정보를 제2 전자 장치(100-2)에 전송할 수 있다 (S645). 제2 전자 장치(100-2)는 서버로부터 UI 위치 정보를 수신할 수 있다. 제2 전자 장치(100-2)는 서버로 부터 수신한 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다 (S650). 그리고, 제2 전자 장치(100-2)는 컨텐츠 정보에 기초하여 응답 정보를 제공할 수 있다 (S655). 도 7은 결합 이미지를 생성하는 동작을 설명하기 위한 흐름도이다. 도 7을 참조하면, 전자 장치는 결합 이미지를 생성하기 위한 이벤트를 식별할 수 있다 (S701). 결합 이미 지를 생성하기 위한 이벤트는 서버로부터 결합 이미지를 요청하는 제어 명령을 수신하는 이벤트, 기존 UI 위치 정보에 기초하여 컨텐츠 정보가 추출되지 않는 이벤트, 결합 이미지를 생성하기 위한 사용자 명령이 획득 되는 이벤트 중 적어도 하나를 포함할 수 있다. 전자 장치는 컨텐츠 제공 장치의 식별 정보를 획득할 수 있다 (S705). 또한, 전자 장치는 제1 컨텐츠 를 표시하기 위한 제1 사용자 입력을 수신할 수 있다 (S711). 제1 사용자 입력은 채널 변경 명령, 제1 컨텐츠를 제공하는 채널을 입력하는 명령 또는 제1 컨텐츠를 직접 선택하는 명령 중 적어도 하나를 포함할 수 있다. 전자 장치는 제1 사용자 입력이 수신된 제1 시점으로부터 임계 시간 동안 제1 컨텐츠에 대응되는 제1 이미 지를 획득할 수 있다 (S712). 제1 사용자 입력이 수신되면, 전자 장치는 제1 사용자 입력이 수신된 제1 시 점으로부터 임계 시간(예를 들어, 2초) 동안 제1 컨텐츠를 포함하는 화면을 캡쳐하여 제1 이미지를 획득할 수 있다. 여기서, 임계 시간 동안 획득되는 제1 이미지는 적어도 하나의 캡쳐 이미지일 수 있다. 다양한 실시 예에 따라, 캡쳐 동작이 수행되는 시간 간격이 1초라면, 전자 장치는 제1 사용자 입력이 수신 됨 시점(0초)에 기초하여 3개의 제1 이미지(0초, 1초, 2초)를 획득할 수 있다. 다양한 실시 예에 따라, 캡쳐 동작이 수행되는 시간 간격이 1초라면, 전자 장치는 제1 사용자 입력이 수신 됨 시점(0초)에 기초하여 2개의 제1 이미지(1초, 2초)를 획득할 수 있다. 전자 장치는 제2 컨텐츠를 표시하기 위한 제2 사용자 입력을 수신할 수 있다 (S716). 제2 사용자 입력은 채널 변경 명령, 제2 컨텐츠를 제공하는 채널을 입력하는 명령 또는 제2 컨텐츠를 직접 선택하는 명령 중 적어 도 하나를 포함할 수 있다. 다양한 실시 예에 따라, 제1 사용자 입력과 제2 사용자 입력이 동일한 종류의 명령일 수 있다. 다양한 실시 예에 따라, 제1 사용자 입력과 제2 사용자 입력이 상이한 종류의 명령일 수 있다. 전자 장치는 제2 사용자 입력이 수신된 제2 시점으로부터 임계 시간 동안 제2 컨텐츠에 대응되는 제2 이미 지를 획득할 수 있다 (S717). 제2 사용자 입력이 수신되면, 전자 장치는 제2 사용자 입력이 수신된 제2 시 점으로부터 임계 시간(예를 들어, 2초) 동안 제2 컨텐츠를 포함하는 화면을 캡쳐하여 제2 이미지를 획득할 수 있다. 여기서, 임계 시간 동안 획득되는 제2 이미지는 적어도 하나의 캡쳐 이미지일 수 있다. 전자 장치는 기 설정된 개수의 이미지를 획득하였는지 판단할 수 있다 (S721). 기 설정된 개수(예를 들어, 100개)의 이미지가 획득되지 않으면 (S721-N), 전자 장치는 S711, S712, S716, S717, S721 단계를 반복할 수 있다. 전자 장치는 미리 정해진 개수만큼 캡쳐 이미지가 획득될 때까지 반복하여 캡쳐 이미지를 저장할 수 있다. 기 설정된 개수(예를 들어, 100개)의 이미지가 획득되면 (S721-Y), 전자 장치는 획득된 이미지를 병합하여 결합 이미지를 획득할 수 있다 (S722). 그리고, 전자 장치는 컨텐츠 제공 장치의 식별 정보 및 결합 이미 지를 서버에 전송할 수 있다 (S725). 서버는 전자 장치로부터 컨텐츠 제공 장치의 식별 정보 및 결합 이미지를 수신할 수 있다. 그리고, 서버는 S730 내지 S740 단계를 수행할 수 있다. 도 8은 다양한 실시 예에 따라, 결합 이미지를 생성하는 동작을 설명하기 위한 도면이다. 도 8의 이미지(810-1)는 제1 컨텐츠에 대응되는 제1 이미지일 수 있다. 전자 장치는 10번 채널(A-Golf 채 널)에서 제공하는 제1 컨텐츠를 표시할 수 있다. 제1 컨텐츠는 전자 장치와 연결된 컨텐츠 제공 장치에서 제공될 수 있다. 캡쳐된 이미지(810-1)는 제1 컨텐츠와 관련된 정보를 포함할 수 있다. 예를 들어, 제1 컨텐츠 와 관련된 정보는 채널 번호(10번), 채널 이름(A-golf), 컨텐츠 제공 시간(14:00~15:00) 또는 컨텐츠 이름(golf history) 중 적어도 하나를 포함할 수 있다. 도 8의 이미지(810-2)는 제2 컨텐츠에 대응되는 제2 이미지일 수 있다. 전자 장치는 22번 채널(B-kids 채 널)에서 제공하는 제2 컨텐츠를 표시할 수 있다. 제2 컨텐츠는 전자 장치와 연결된 컨텐츠 제공 장치에서 제공될 수 있다. 캡쳐된 이미지(810-2)는 제2 컨텐츠와 관련된 정보를 포함할 수 있다. 예를 들어, 제2 컨텐츠 와 관련된 정보는 채널 번호(22번), 채널 이름(B-kids), 컨텐츠 제공 시간(14:00~15:00) 또는 컨텐츠 이름(Tom and Jerry) 중 적어도 하나를 포함할 수 있다.전자 장치는 제1 이미지(810-1) 및 제2 이미지(810-2)를 병합하여 결합 이미지를 획득할 수 있다. 결 합 이미지는 제1 이미지(810-1)와 제2 이미지(810-2)를 하나의 이미지로 중첩시킨 이미지일 수 있다. 중첩 기준은 각 이미지의 특정 픽셀 위치일 수 있다. 다양한 실시 예에 따라, 전자 장치는 제1 이미지(810-1)의 좌상단 픽셀 위치 및 제2 이미지(810-2)의 좌상 단 픽셀 위치를 기준으로 결합 이미지를 획득할 수 있다. 다양한 실시 예에 따라, 전자 장치는 제1 이미지(810-1)의 중심 픽셀 위치 및 제2 이미지(810-2)의 중심 픽셀 위치를 기준으로 결합 이미지를 획득할 수 있다. 결합 이미지는 복수의 이미지가 중첩된 이미지에 해당할 수 있다. 따라서, 사용자는 결합 이미지를 통해 특정 컨텐츠를 나타내는 정보가 직관적으로 인식하기 어려울 수 있다. 따라서, 결합 이미지를 별도의 기기에 전송된다 하여도, 특정 컨텐츠의 권리(예를 들어, 저작권)가 침해되지 않을 수 있다. 한편, 전자 장치는 3장의 이미지를 병합하여 결합 이미지를 생성할 수 있다. 도 9는 다양한 실시 예에 따라, 결합 이미지를 생성하는 동작을 설명하기 위한 도면이다. 도 9의 이미지(910-1)는 제1 컨텐츠에 대응되는 제1 이미지일 수 있다. 전자 장치는 1번 채널에서 제공하 는 제1 컨텐츠(A)를 표시할 수 있다. 제1 컨텐츠는 전자 장치와 연결된 컨텐츠 제공 장치에서 제공될 수 있다. 캡쳐된 이미지(910-1)는 제1 컨텐츠와 관련된 정보를 포함할 수 있다. 예를 들어, 제1 컨텐츠와 관련된 정보는 채널 번호(1번) 또는 컨텐츠 이름(content A) 중 적어도 하나를 포함할 수 있다. 도 9의 이미지(910-2)는 제2 컨텐츠에 대응되는 제2 이미지일 수 있다. 전자 장치는 2번 채널에서 제공하 는 제2 컨텐츠(B)를 표시할 수 있다. 제2 컨텐츠는 전자 장치와 연결된 컨텐츠 제공 장치에서 제공될 수 있다. 캡쳐된 이미지(910-2)는 제2 컨텐츠와 관련된 정보를 포함할 수 있다. 예를 들어, 제2 컨텐츠와 관련된 정보는 채널 번호(2번) 또는 컨텐츠 이름(content B) 중 적어도 하나를 포함할 수 있다. 도 9의 이미지(910-3)는 제3 컨텐츠에 대응되는 제3 이미지일 수 있다. 전자 장치는 3번 채널에서 제공하 는 제3 컨텐츠(C)를 표시할 수 있다. 제3 컨텐츠는 전자 장치와 연결된 컨텐츠 제공 장치에서 제공될 수 있다. 캡쳐된 이미지(910-3)는 제3 컨텐츠와 관련된 정보를 포함할 수 있다. 예를 들어, 제3 컨텐츠와 관련된 정보는 채널 번호(3번) 또는 컨텐츠 이름(content C) 중 적어도 하나를 포함할 수 있다. 전자 장치는 제1 이미지(910-1), 제2 이미지(910-2), 제3 이미지(910-3)를 병합하여 결합 이미지를 획득할 수 있다. 결합 이미지는 제1 이미지(910-1), 제2 이미지(910-2) 및 제3 이미지(910-3)를 하나의 이 미지로 중첩시킨 이미지일 수 있다. 중첩 기준은 각 이미지의 특정 픽셀 위치일 수 있다. 다양한 실시 예에 따라, 전자 장치는 3장을 초과하는 이미지들을 병합하여 결합 이미지를 생성할 수 있다. 그리고, 전자 장치는 결합 이미지를 서버에 전송할 수 있다. 도 10은 결합 이미지에 기초하여 노이즈 제거 이미지를 생성하는 동작을 설명하기 위한 도면이다. 도 10의 결합 이미지는 도 8의 결합 이미지에 대응될 수 있다. 서버는 결합 이미지를 제 1 인공지능모델에 입력하여 노이즈 제거 이미지를 획득할 수 있다. 서버는 제1 인공지능모델 에 결합 이미지를 입력 데이터로써 입력(또는 적용)하여 노이즈 제거 이미지를 출력 데이터로 써 획득할 수 있다. 제1 인공지능모델은 입력된 이미지에서 노이즈를 제거하는 딥러닝 모델일 수 있다. 노이즈로 판단되는 대 상은 텍스트(문자, 숫자를 포함하는 개념)가 인식되지 않는 객체 또는 영역일 수 있다. 제1 인공지능모델은 결합 이미지에서 노이즈로 판단되는 영역을 식별할 수 있다. 그리고, 제1 인공지능모델은 결합 이미지에서 노이즈 영역을 제거함으로써 노이즈 제거 이미지를 획 득할 수 있다. 다양한 실시 예에 따라, 제1 인공지능모델은 비지도학습으로 학습되는 모델일 수 있다. 제1 인공지능모델 은 결합 이미지를 학습 입력 데이터로써 수신하여 타겟(노이즈가 제거된 이미지)을 획득하기 위해 학습된 모델일 수 있다. 타겟과 관련된 정보는 사용자에 의해 미리 설정될 수 있다. 다양한 실시 예에 따라, 제1 인공지능모델은 지도학습으로 학습되는 모델일 수 있다. 제1 인공지능모델 은 결합 이미지를 및 결합 이미지에 대응되는 UI 위치 정보를 함께 학습 입력 데이터로써 수 신하여 타겟(노이즈가 제거된 이미지)을 획득하기 위해 학습된 모델일 수 있다. 여기서, 결합 이미지에 대응되는 UI 위치 정보는 사용자(제1 인공지능모델을 관리하는 개발자)에 의해 개별적으로 획득한 이미지 일 수 있다. 제1 인공지능모델은 이미 학습 동작이 수행된 모델임에도 불구하고, 서버로부터 수신된 결합 이미지 에 기초하여 학습 동작을 반복할 수 있다. 결과적으로, 제1 인공지능모델은 결합 이미지에 기 초하여 업데이트될 수 있다. 노이즈 제거 이미지는 결합 이미지에서 노이즈 영역이 제거된 이미지일 수 있다. 따라서, 노 이즈 제거 이미지는 텍스트(문자, 숫자를 포함하는 개념)가 인식되는 영역만을 포함할 수 있다. 도 11은 노이즈 제거 이미지에서 UI 위치 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 11의 노이즈 제거 이미지는 도 10의 결합 이미지에 대응될 수 있다. 서버는 노이즈 제거 이미지를 제2 인공지능모델에 입력하여 UI 위치 정보를 획득할 수 있다. 서버는 제2 인 공지능모델에 노이즈 제거 이미지를 입력 데이터로써 입력(또는 적용)하여 UI 위치 정보를 출 력 데이터로써 획득할 수 있다. 제2 인공지능모델은 입력된 이미지에서 UI를 표시하는 위치를 획득하는 딥러닝 모델일 수 있다. UI를 표시 하는 위치(또는 UI 위치 정보)는 텍스트(문자, 숫자를 포함하는 개념)를 표시하는 객체 또는 영역과 관련된 정 보일 수 있다. 여기서, UI는 컨텐츠와 관련된 정보를 나타내는 UI일 수 있다. 제2 인공지능모델은 노이즈 제거 이미지에서 UI를 표시하는 영역(1131, 1132, 1133)을 식별할 수 있 다. 그리고, 제2 인공지능모델은 노이즈 제거 이미지에서 UI를 표시하는 영역(1131, 1132, 1133)에 기초하여 UI 위치 정보(1141, 1142, 1143)를 획득할 수 있다. 여기서, UI를 표시하는 영역은 복수의 세부 영역(1131-1, 1131-2, 1131-3, 1131-4)을 포함할 수 있다. 또한, UI를 표시하는 영역으로부터 획득되는 UI 위치 정보는 세부 위치 정보(1141-1, 1141-2, 1141-3)를 포함할 수 있다. 다양한 실시 예에 따라, 제2 인공지능모델은 비지도학습으로 학습되는 모델일 수 있다. 제2 인공지능모델 은 노이즈 제거 이미지를 학습 입력 데이터로써 수신하여 타겟(컨텐츠와 관련된 정보를 나타내는 UI 가 표시되는 위치 정보)을 획득하기 위해 학습된 모델일 수 있다. 타겟과 관련된 정보는 사용자에 의해 미리 설 정될 수 있다. 다양한 실시 예에 따라, 제2 인공지능모델은 지도학습으로 학습되는 모델일 수 있다. 제2 인공지능모델 은 노이즈 제거 이미지를 및 노이즈 제거 이미지에 대응되는 UI 위치 정보를 함께 학습 입력 데이터로써 수신하여 타겟(컨텐츠와 관련된 정보를 나타내는 UI가 표시되는 위치 정보)을 획득하기 위해 학습된 모델일 수 있다. 여기서, 노이즈 제거 이미지에 대응되는 UI 위치 정보는 사용자(제2 인공지능모델 을 관리하는 개발자)에 의해 개별적으로 획득한 정보일 수 있다. 제2 인공지능모델은 이미 학습 동작이 수행된 모델임에도 불구하고, 서버로부터 수신된 노이즈 제거 이미지에 기초하여 학습 동작을 반복할 수 있다. 결과적으로, 제2 인공지능모델은 노이즈 제거 이미 지에 기초하여 업데이트될 수 있다. UI 위치 정보는 컨텐츠와 관련된 정보를 나타내는 UI가 표시되는 위치 정보를 포함할 수 있다. 따라서, UI 위치 정보는 텍스트(문자, 숫자를 포함하는 개념)가 인식되는 영역을 나타내는 정보일 수 있다. 도 11 에서는 UI 위치 정보가 하나의 이미지 형태인 것으로 표시하였지만, 구현 예에 따라, UI 위치 정보(114 0)는 좌표 정보로 기재될 수 있다. 이와 관련된 설명은 도 13 내지 도 15에서 기재한다. 도 12는 결합 이미지에 기초하여 노이즈 제거 이미지 및 UI 위치 정보를 획득하는 동작을 설명하기 위한 도면이 다. 도 12를 참조하면, 서버는 결합 이미지를 획득할 수 있다. 결합 이미지는 도 9의 결합 이미지 에 대응될 수 있다. 서버는 결합 이미지를 제1 인공지능모델에 입력하여 노이즈 제거 이미지를 획득할 수 있 다. 서버는 제1 인공지능모델에 결합 이미지를 입력 데이터로써 입력(또는 적용)하여 노이즈제거 이미지를 출력 데이터로써 획득할 수 있다. 서버는 노이즈 제거 이미지를 제2 인공지능모델에 입력하여 UI 위치 정보를 획득할 수 있다. 서버는 제2 인공지능모델에 노이즈 제거 이미지를 입력 데이터로써 입력(또는 적용)하여 UI 위치 정보를 출력 데이터로써 획득할 수 있다. 도 13은 다양한 실시 예에 따라, 복수의 UI 위치 정보가 저장된 UI 테이블을 설명하기 위한 도면이다. 도 13을 참조하면, UI 위치 정보는 이미지 정보 또는 좌표 정보 중 적어도 하나를 포함할 수 있다. 이미지 정보 는 UI가 표시되는 위치(또는 영역)를 이미지 형태로 나타낸 정보일 수 있다. 또한, 좌표 정보는 UI가 표시되는 위치(또는 영역)을 좌표 형태로 나타낸 정보일 수 있다. UI 테이블은 UI 위치를 나타내는 이미지 정보 또는 UI 위치를 나타내는 좌표 정보 중 적어도 하나를 포함 할 수 있다. 서버는 컨텐츠 제공 장치의 식별 정보(#01, #02) 및 컨텐츠 제공 장치의 식별 정보에 대응되 는 UI 위치 정보를 맵핑할 수 있다. 그리고, 서버는 맵핑 결과를 UI 테이블에 포함시켜 저장할 수 있다. 서버는 제1 UI 테이블을 저장하고 있을 수 있다. 컨텐츠 제공 장치의 식별 정보 및 결합 이미지가 수신되 면, 서버는 컨텐츠 제공 장치의 식별 정보에 대응되는 UI 위치 정보를 획득할 수 있다. 그리고, 서버(20 0)는 컨텐츠 제공 장치의 식별 정보와 UI 위치 정보를 맵핑할 수 있다. 서버는 맵핑 결과를 제1 UI 테이블 에 추가하여 제2 UI 테이블을 획득할 수 있다. 서버는 맵핑 결과를 포함하는 제2 UI 테이블을 저장할 수 있다. 도 14는 복수의 UI 위치 정보를 설명하기 위한 도면이다. 도 14를 참조하면, 서버는 컨텐츠 제공 장치에 대응되는 UI 위치 정보를 저장할 수 있다. 서버는 컨 텐츠 제공 장치마다 별개의 UI 위치 정보를 저장할 수 있다. 예를 들어, 서버는 제1 컨텐츠 제공 장치(식별 정보: #01)에 대응되는 UI 위치 정보를 저장할 수 있 다. 서버는 제2 컨텐츠 제공 장치(식별 정보: #02)에 대응되는 UI 위치 정보를 저장할 수 있다. 서 버는 제3 컨텐츠 제공 장치(식별 정보: #n)에 대응되는 UI 위치 정보를 저장할 수 있다. 다양한 실시 예에 따라, UI 위치 정보(1410, 1420, 1430)는 XML(extensible markup language)로 생성된 정보일 수 있다. 복수의 UI 위치 정보(1410, 1420, 1430)를 저장하고 있는 상태에서, 서버는 컨텐츠 제공 장치의 식별 정보 를 전자 장치(100-3)로부터 수신할 수 있다. 서버는 수신된 식별 정보에 대응되는 UI 위치 정보를 식별할 수 있다. 서버는 식별된 UI 위치 정보를 전자 장치(100-3)에 전송할 수 있다. 전자 장치(100-3)는 수신된 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다. 도 15는 다양한 실시 예에 따라, 복수의 UI 위치 정보가 저장된 UI 테이블을 설명하기 위한 도면이다. 도 15를 참조하면, 서버는 복수의 UI 위치 정보를 결합하여 하나의 UI 위치 정보를 획득할 수 있다. 복수 의 UI 위치 정보를 결합하는 이유는 컨텐츠 제공 장치의 식별 정보에 대응되는 UI 위치 정보를 찾을 수 없는 문 제 상황을 해결하기 위함이다. 서버는 새로 출시된 컨텐츠 제공 장치 또는 오래된 컨텐츠 제공 장치에 대 한 UI 위치 정보를 저장하고 있지 않을 수 있다. 따라서, 서버는 전자 장치(100-3)로부터 컨텐츠 제공 장 치의 식별 정보를 수신하여도 식별 정보에 대응되는 UI 위치 정보를 전송하지 못할 수 있다. 수신된 식별 정보에 대응되는 UI 위치 정보가 식별되지 않으면, 서버는 식별 정보에 대응되는 대표 UI 위 치 정보(기 설정된 UI 위치 정보)를 전자 장치(100-3)에 제공할 수 있다. 서버는 전자 장치(100-3)로부터 수신된 컨텐츠 제공 장치의 식별 정보와 완벽히 동일한 식별 정보를 저장 하고 있지 않을 수 있다. 서비스 회사에서 제공(또는 제조)한 컨텐츠 제공 장치는 일반적으로 공통의 코드 내지 공통의 구조를 갖고 있다. 따라서, 서버는 식별 정보에 포함된 일부 코드 또는 식별 정보의 구조 중 적어 도 하나에 기초하여 컨텐츠 제공 장치와 관련된 서비스 회사를 식별할 수 있다. 예를 들어, 서버는 식별 정보에 기초하여 제1 컨텐츠 제공 장치(#A-01) 및 제2 컨텐츠 제공 장치(#A-02)가 A 서비스 회사에서 제조된 기기임을 판단할 수 있다. 여기서, 서버는 제1 컨텐츠 제공 장치(#A-01)에 대응 되는 UI 위치 정보(P-A1) 및 제1 컨텐츠 제공 장치(#A-02)에 대응되는 UI 위치 정보(P-A2)를 UI 테이블에 저장 할 수 있다. 서버는 UI 위치 정보(P-A1) 및 UI 위치 정보(P-A2)를 결합하여 대표 UI 위치 정보(P-A0)를생성할 수 있다. 그리고, 전자 장치(100-3)로부터 수신된 컨텐츠 제공 장치의 식별 정보가 UI 테이블에 존재하 지 않으면, 서버는 식별 정보에 대응되는 서비스 회사(A)를 결정할 수 있다. 그리고, 서버는 결정된 서비스 회사(A)의 대표 UI 위치 정보(P-A0)를 전자 장치(100-3)에 전송할 수 있다. 도 16은 대표 UI 위치 정보를 생성하는 동작을 설명하기 위한 도면이다. 도 16을 참조하면, 서버는 UI 위치 정보(1640-1) 및 UI 위치 정보(1640-2)를 결합하여 하나의 대표 UI 위 치 정보를 획득할 수 있다. 대표 UI 위치 정보는 결합된 복수의 위치 정보를 모두 나타낼 수 있는 새로운 위치 정보를 포함할 수 있 다. 서버는 UI 위치 정보(1640-1)에 포함된 제1 위치 정보(또는 영역 정보) 및 UI 위치 정보(1640-2)에 포 함된 제2 위치 정보(또는 영역 정보)를 포함하는 제3 위치 정보(또는 영역 정보)를 획득할 수 있다. 그리고, 서 버는 제3 위치 정보(또는 영역 정보)에 기초하여 대표 UI 위치 정보를 생성할 수 있다. 도 17은 다양한 실시 예에 따라, UI 위치 정보에 대응되는 신뢰도를 산출하는 동작을 설명하기 위한 흐름도이다. 도 17을 참조하면, 서버는 컨텐츠 제공 장치의 식별 정보와 UI 위치 정보를 맵핑한 UI 테이블을 저장할 수 있다 (S1700). 전자 장치는 기 설정된 이벤트가 발생되는지 여부를 식별할 수 있다 (S1705). 기 설정된 이벤트는 기존 UI 위치 정보에 기초하여 컨텐츠 정보가 추출되지 않는 이벤트, 업데이트 명령을 획득한 이벤트 또는 UI 위치 정보 를 수신하기 위한 사용자 명령을 획득한 이벤트 중 적어도 하나를 포함할 수 있다. 기 설정된 이벤트가 발생하 면 (S1705-Y), 전자 장치는 컨텐츠 제공 장치의 식별 정보를 서버에 전송할 수 있다 (S1710). 서버는 전자 장치로부터 컨텐츠 제공 장치의 식별 정보를 수신할 수 있다. 그리고, 서버는 UI 테이블에 기초하여 식별 정보에 대응되는 제1 UI 위치 정보를 식별할 수 있다 (S1715). 서버는 UI 테이블 에 포함된 복수의 UI 위치 정보 중 식별 정보에 대응되는 제1 UI 위치 정보를 식별할 수 있다. 서버는 제1 UI 위치 정보를 전자 장치에 전송할 수 있다 (S1720). 전자 장치는 서버로부터 제1 UI 위치 정보를 수신할 수 있다. 전자 장치는 기 설정된 제어 명령 (예를 들어, 컨텐츠 변경) 및 제1 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다 (S1725). 사용자는 컨텐츠 변경 또는 채널 변경 명령을 입력할 수 있다. 컨텐츠 변경을 위한 사용자 입력 또는 채널 변경을 위한 사용자 입력이 수신되면, 전자 장치는 서버로부터 수신한 제1 UI 위치 정보에 기초하여 컨텐츠 정보 를 추출할 수 있다. 전자 장치는 추출된 컨텐츠 정보에 기초하여 제1 UI 위치 정보에 대응되는 제1 신뢰도를 획득할 수 있다 (S1730). 제1 신뢰도는 제1 UI 위치 정보에 기초하여 획득되는 컨텐츠 정보의 인식률일 수 있다. 기 설정된 제어 명령은 임계 횟수의 컨텐츠 변경 명령 또는 임계 횟수의 채널 변경 명령을 포함할 수 있다. 전 자 장치는 기 설정된 제어 명령이 수행될 때마다 제1 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다. 전자 장치는 추출된 컨텐츠 정보의 인식률에 기초하여 제1 신뢰도를 획득할 수 있다. 예를 들어, 10번의 컨텐츠 변경 명령이 있다고 가정한다. 1번의 컨텐츠 변경 명령이 수행될 때마다, 전자 장치 는 제1 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다. 전자 장치는 총 10번의 컨텐츠 정보 추출 동작을 수행할 수 있다. 전자 장치는 그리고 추출된 컨텐츠 정보의 인식률을 계산할 수 있다. 10번의 추출 동작 중 4번의 추출 동작에서 컨텐츠 정보가 비정상적으로 인식되거나 미인식 되었다고 가정한다. 인식률 은 60%이며, 제1 신뢰도는 0.6일 수 있다. 전자 장치는 제1 신뢰도가 임계값 이상인지 식별할 수 있다. 제1 신뢰도가 임계값 이상이면 (S1735-Y), 전 자 장치는 제1 UI 위치 정보를 컨텐츠 제공 장치의 UI 위치(기본 UI 위치)로 저장할 수 있다 (S1740). 그 리고, 전자 장치는 제1 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다 (S1745). 그리고, 전자 장 치는 컨텐츠 정보에 기초하여 응답 정보를 제공할 수 있다 (S1750). 제1 신뢰도가 임계값 이상이 아니면 (S1735-N), 전자 장치는 UI 위치 정보를 재요청하는 신호를 서버(20 0)에 전송할 수 있다 (S1755). 서버는 전자 장치로부터 UI 위치 정보를 재요청하는 신호를 수신할 수 있다. 서버는 UI 테이블 에 기초하여 식별 정보에 대응되는 제2 UI 위치 정보를 식별할 수 있다 (S1760). 여기서, 제2 UI 위치 정보는제1 UI 위치 정보와 상이할 수 있다. 전자 장치는 UI 테이블에서 우선적으로 식별 정보에 대응되는 UI 위치 정보 중 가장 정확도가 높은 제1 UI 위치 정보를 먼저 전자 장치에 전송할 수 있다. 하지만, 전자 장치로부터 S1755 단계에 따른 UI 위치 정보를 재요청하는 신호를 수신하면, 서버는 제1 UI 위치 정보와 다른 제2 UI 위치 정보를 서버에 전 송할 수 있다 (S1765). 제2 UI 위치 정보는 컨텐츠 제공 장치와 관련된 대표 UI 위치 정보(기 설정된 UI 위치 정보)일 수 있다. 전자 장치는 서버로부터 제2 UI 위치 정보를 수신할 수 있다. 제2 UI 위치 정보가 수신되면, 전자 장 치는 S1725 내지 S1750 단계를 반복할 수 있다. 전자 장치는 기 설정된 제어 명령(예를 들어, 컨텐츠 변경) 및 제2 UI 위치 정보에 기초하여 컨텐츠 정보 를 추출할 수 있다 (S1725). 전자 장치는 추출된 컨텐츠 정보에 기초하여 제2 UI 위치 정보에 대응되는 제2 신뢰도를 획득할 수 있다 (S1730). 제2 신뢰도는 제2 UI 위치 정보에 기초하여 획득되는 컨텐츠 정보의 인식률일 수 있다. 전자 장치는 제2 신뢰도가 임계값 이상인지 식별할 수 있다. 제2 신뢰도가 임계값 이상이면 (S1735-Y), 전 자 장치는 제2 UI 위치 정보를 컨텐츠 제공 장치의 UI 위치(기본 UI 위치)로 저장할 수 있다 (S1740). 그 리고, 전자 장치는 제2 UI 위치 정보에 기초하여 컨텐츠 정보를 추출할 수 있다 (S1745). 그리고, 전자 장 치는 컨텐츠 정보에 기초하여 응답 정보를 제공할 수 있다 (S1750). 도 18은 다양한 실시 예에 따라, UI 위치 정보에 대응되는 신뢰도를 산출하는 동작을 설명하기 위한 흐름도이다. 도 18의 S1800, S1805, S1810, S1825, S1830, S1835, S1840, S1845, S1850 단계는 도 17의 S1700, S1705, S1710, S1725, S1730, S1735, S1740, S1745, S1750 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 전자 장치로부터 컨텐츠 제공 장치의 식별 정보를 수신한 후, 서버는 UI 테이블에 기초하여 식별 정 보에 대응되는 제1 UI 위치 정보 및 제2 UI 위치 정보를 식별할 수 있다 (S1815). 서버는 식별된 제1 UI 위치 정보 및 제2 UI 위치 정보를 전자 장치에 전송할 수 있다 (S1820). 전자 장치는 서버로부터 제1 UI 위치 정보 및 제2 UI 위치 정보를 수신할 수 있다. 그리고, 전자 장 치는 S1825 내지 S1850 단계를 수행할 수 있다. 제1 신뢰도가 임계값 이상이 아니면 (S1835), 전자 장치는 제2 UI 위치 정보에 기초하여 컨텐츠 정보를 추 출하는 테스트 동작(제2 신뢰도를 구하는 동작)을 수행할 수 있다. 그리고, 전자 장치는 S1825 내지 S1850 동작을 반복 수행할 수 있다. 도 17의 실시 예는 제1 신뢰도가 임계값 이상이 아닌 경우, 전자 장치는 서버에 재요청 신호를 전송 하여 제2 UI 위치 정보를 수신하였다. 하지만, 도 18의 실시 예는 신뢰도 및 임계값을 비교하기 이전에 제1 UI 위치 정보 및 제2 UI 위치 정보를 한 번에 수신할 수 있다. 도 19는 UI 위치 정보를 변경하는 동작을 설명하기 위한 흐름도이다. 도 19의 S1900, S1905, S1910, S1915, S1920, S1925, S1930, S1935, S1940, S1945, S1950 단계는 도 18의 S1800, S1805, S1810, S1815, S1820, S1825, S1830, S1835, S1840, S1845, S1850 단계에 대응될 수 있다. 따라 서, 중복 설명을 생략한다. 신뢰도가 임계값 이상이 아니면, 전자 장치는 UI 위치를 변경하기 위한 가이드 UI를 제공할 수 있다 (S1955). 그리고, 전자 장치는 제공된 가이드 UI를 통해 사용자 입력을 수신할 수 있다. 전자 장치는 수신된 사용자 입력에 기초하여 UI 위치를 변경할 수 있다. 그리고, 전자 장치는 S1940 내지 S1950 단계를 수행할 수 있다. 가이드 UI와 관련된 설명은 도 20 및 도 21에서 기재한다. 다양한 실시 예에 따라, 제1 위치 정보를 통해 획득한 제1 신뢰도가 임계값 이상이 아니면, 전자 장치는 바로 가이드 UI를 제공할 수 있다. 다양한 실시 예에 따라, 제1 위치 정보를 통해 획득한 제1 신뢰도 및 제2 UI 위치 정보를 통해 획득한 제2 신뢰 도가 임계값 이상이 아니면, 전자 장치는 가이드 UI를 제공할 수 있다.도 20은 다양한 실시 예에 따라, UI 위치 정보를 변경하는 동작을 설명하기 도면이다. 도 20을 참조하면, 전자 장치는 UI 위치 정보(2011, 2012, 2013)에 기초하여 이미지에서 컨텐츠 정 보를 추출할 수 있다. 하지만, 해당 UI 위치 정보는 컨텐츠 제공 장치에서 제공하는 UI 위치와 일치하지 않을 수 있다. 따라서, 전자 장치는 UI 위치 정보에 기초하여 추출한 컨텐츠 정보를 정상적으로 인식하지 못할 수 있다. 따라서, 전자 장치는 기 설정된 이벤트(컨텐츠가 추출되지 않는 이벤트)가 발생하였다고 식별할 수 있다. 전자 장치는 가이드 UI를 제공할 수 있다. 가이드 UI는 팝업 형태로 제공될 수 있다. 가이드 UI는 컨텐츠 정보가 정상적으로 추출되지 않았음을 나타내는 텍스트 정보 또는 컨텐츠 정보를 추출하기 위한 추출 영역을 변경할 것을 가이드하기 위한 텍스트 정보 중 적어도 하나를 포함할 수 있다. 도 21은 다양한 실시 예에 따라, UI 위치 정보를 변경하는 동작을 설명하기 도면이다. 도 21을 참조하면, 전자 장치는 UI 위치 정보를 변경하기 위한 가이드 UI를 제공할 수 있다. 구체적으로, 전자 장치는 UI 위치 정보(2011, 2012, 2013)를 이동시키기 위한 아이콘(2011-1, 2012-1, 2013-1), UI 위 치 정보(2011, 2012, 2013)의 크기를 변경시키기 위한 아이콘(2011-2, 2012-2, 2013-2), UI 위치 정보(2011, 2012, 2013)를 삭제하기 위한 아이콘(2011-3, 2012-3, 2013-3) 중 적어도 하나를 표시할 수 있다. 아이콘(2011-1, 2012-1, 2013-1) 각각은 UI 위치 정보(2011, 2012, 2013)의 좌상단에 표시될 수 있다. 아이콘(2011-2, 2012-2, 2013-2) 각각은 UI 위치 정보(2011, 2012, 2013)의 우하단에 표시될 수 있다. 아이콘(2011-3, 2012-3, 2013-3) 각각은 UI 위치 정보(2011, 2012, 2013)의 중앙에 표시될 수 있다. 도 22는 다양한 실시 예에 따라, UI 위치 정보를 전자 장치에서 획득하는 동작을 설명하기 위한 흐름도이 다. 도 22의 S2205, S2210, S2215, S2220, S2230, S2235, S2240 단계는 도 5의 S505, S510, S515, S520, S530, S535, S540 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 다만, S2230, S2235, S2240 단계는 서버 가 아닌 전자 장치에서 수행될 수 있다. 도 5의 실시 예에서는 노이즈 제거 이미지, UI 위치 정보를 획득하는 동작이 서버에서 수행되었다. 하지만, 도 22의 실시 예에서는 노이즈 제거 이미지, UI 위치 정보를 획득하는 동작이 전자 장치에서 수행 될 수 있다. 그리고, 전자 장치는 컨텐츠 제공 장치의 식별 정보 및 UI 위치 정보가 맵핑된 UI 테이블을 생성할 수 있 다. 전자 장치는 UI 테이블을 서버에 전송할 수 있다. 서버는 전자 장치로부터 수신된 UI 테이블을 저장할 수 있다. 도 23은 다양한 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 23을 참조하면, 컨텐츠 제공 장치 및 서버와 통신하고 컨텐츠 제공 장치의 식별 정보를 저장하는 전자 장치 의 제어 방법은 컨텐츠 제공 장치로부터 수신된 제1 컨텐츠를 표시하는 단계 (S2305), 기 설정된 이벤트가 발생 하면, 컨텐츠 제공 장치의 식별 정보를 서버에 전송하는 단계 (S2310), 식별 정보에 대응되는 UI 위치 정보를 서버로부터 수신하는 단계 (S2315), 표시된 제1 컨텐츠를 제2 컨텐츠로 변경하기 위한 사용자 명령이 수신되면, 제2 컨텐츠를 표시하는 단계 (S2320) 및 수신된 UI 위치 정보에 기초하여 제2 컨텐츠에 대응되는 컨텐츠 정보를 획득하는 단계 (S2325)를 포함하고, UI 위치 정보는 복수의 이미지가 중첩되어 하나의 이미지로 병합된 결합 이 미지로부터 획득되는 정보이다. 한편, 기 설정된 이벤트는 제1 컨텐츠에 대응되는 컨텐츠 정보가 획득되지 않는 이벤트, 전자 장치의 업그레이 드가 수행되는 이벤트 또는 UI 위치 정보를 수신하기 위한 사용자 명령이 입력되는 이벤트 중 적어도 하나를 포 함할 수 있다. 한편, UI 위치 정보는 결합 이미지를 입력 데이터로써 수신하는 인공 지능 모델로부터 출력 데이터로써 획득될 수 있다. 한편, UI 위치 정보는 결합 이미지를 입력 데이터로써 수신하여 노이즈 제거 이미지를 출력 데이터로서 획득하 는 제1 인공 지능 모델 및 노이즈 제거 이미지를 입력 데이터로써 수신하여 UI 위치 정보를 출력 데이터로서 획 득하는 제2 인공 지능 모델에 기초하여 획득될 수 있다.한편, 제어 방법은 획득된 컨텐츠 정보에 대응되는 신뢰도를 획득하는 단계 및 신뢰도가 임계값 이상이면, 획득 된 컨텐츠 정보에 대응되는 응답 정보를 표시하는 단계를 더 포함할 수 있다. 한편, 제어 방법은 신뢰도가 임계값 미만이면, UI 위치 정보를 변경하기 위한 가이드 UI를 표시하는 단계를 더 포함할 수 있다. 한편, UI 위치 정보는 컨텐츠와 관련된 정보가 표시되는 UI 영역의 위치를 포함하고, 가이드 UI는 UI 영역의 위 치를 이동시키기 위한 아이콘, UI 영역의 크기를 변경하기 위한 아이콘 또는 UI 영역의 위치를 삭제하기 위한 아이콘 중 적어도 하나를 포함할 수 있다. 한편, UI 위치 정보는 제1 UI 위치 정보이고, 제어 방법은 신뢰도가 임계값 미만이면, 제1 UI 위치 정보와 상이 한 제2 UI 위치 정보를 요청하는 제어 신호를 서버에 전송하는 단계, 제어 신호에 대응되는 제2 UI 위치 정보를 서버로부터 수신하는 단계, 제2 UI 위치 정보에 기초하여 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득하는 단계, 제2 컨텐츠 정보에 대응되는 제2 신뢰도를 획득하는 단계 및 제2 신뢰도가 임계값 이상이면, 획득된 제2 컨텐츠 정보에 대응되는 응답 정보를 표시하는 단계를 더 포함할 수 있다. 한편, UI 위치 정보는 제1 UI 위치 정보 및 제2 UI 위치 정보를 포함하고, 제2 컨텐츠에 대응되는 컨텐츠 정보 를 획득하는 단계는 제1 UI 위치 정보 또는 제2 UI 위치 정보 중 하나에 기초하여 제2 컨텐츠에 대응되는 제2 컨텐츠 정보를 획득할 수 있다. 한편, 전자 장치는 제1 통신 모듈 및 제2 통신 모듈을 포함하고, 제2 컨텐츠를 표시하는 단계 (S2320)는 제1 통 신 모듈을 통해, 컨텐츠 제공 장치로부터 제1 컨텐츠 및 제2 컨텐츠를 수신하고, UI 위치 정보를 수신하는 단계 (S2315)는 제2 통신 모듈을 통해, 서버로부터 UI 위치 정보를 수신할 수 있다. 한편, 도 23과 같은 전자 장치의 제어 방법은 도 3 또는 도 4의 구성을 가지는 전자 장치 상에서 실 행될 수 있으며, 그 밖의 구성을 가지는 전자 장치 상에서도 실행될 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 및 디스플레이 장치 중 적어도 하나의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프 로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적 (non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장 매체가 신호(signal)를 포함 하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장 매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0133520", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0133520", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시 예에 따라, 인공 지능 모델을 학습하는 과정 및 이용하는 과정을 설명하기 위한 도면이다. 도 2는 다양한 실시 예에 따라, 인공 지능 모델을 학습하는 과정 및 이용하는 과정을 설명하기 위한 도면이다. 도 3은 다양한 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 4는 도 3의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 5는 결합 이미지를 생성하여 UI 위치 정보를 획득하는 동작을 설명하기 위한 흐름도이다. 도 6은 결합 이미지를 생성하는 장치와 UI 위치 정보를 요청하는 장치가 상이한 실시 예를 설명하기 위한 흐름 도이다. 도 7은 결합 이미지를 생성하는 동작을 설명하기 위한 흐름도이다. 도 8은 다양한 실시 예에 따라, 결합 이미지를 생성하는 동작을 설명하기 위한 도면이다. 도 9는 다양한 실시 예에 따라, 결합 이미지를 생성하는 동작을 설명하기 위한 도면이다. 도 10은 결합 이미지에 기초하여 노이즈 제거 이미지를 생성하는 동작을 설명하기 위한 도면이다. 도 11은 노이즈 제거 이미지에서 UI 위치 정보를 획득하는 동작을 설명하기 위한 도면이다. 도 12는 결합 이미지에 기초하여 노이즈 제거 이미지 및 UI 위치 정보를 획득하는 동작을 설명하기 위한 도면이 다. 도 13은 다양한 실시 예에 따라, 복수의 UI 위치 정보가 저장된 UI 테이블을 설명하기 위한 도면이다. 도 14는 복수의 UI 위치 정보를 설명하기 위한 도면이다. 도 15는 다양한 실시 예에 따라, 복수의 UI 위치 정보가 저장된 UI 테이블을 설명하기 위한 도면이다. 도 16은 대표 UI 위치 정보를 생성하는 동작을 설명하기 위한 도면이다. 도 17은 다양한 실시 예에 따라, UI 위치 정보에 대응되는 신뢰도를 산출하는 동작을 설명하기 위한 흐름도이다. 도 18은 다양한 실시 예에 따라, UI 위치 정보에 대응되는 신뢰도를 산출하는 동작을 설명하기 위한 흐름도이다.도 19는 UI 위치 정보를 변경하는 동작을 설명하기 위한 흐름도이다. 도 20은 다양한 실시 예에 따라, UI 위치 정보를 변경하는 동작을 설명하기 도면이다. 도 21은 다양한 실시 예에 따라, UI 위치 정보를 변경하는 동작을 설명하기 도면이다. 도 22는 다양한 실시 예에 따라, UI 위치 정보를 전자 장치에서 획득하는 동작을 설명하기 위한 흐름도이다. 도 23은 다양한 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
