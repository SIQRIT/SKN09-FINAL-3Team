{"patent_id": "10-2019-0140720", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0135126", "출원번호": "10-2019-0140720", "발명의 명칭": "압축 해제 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "이동수"}}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 압축 데이터가 저장된 메모리;상기 압축 데이터의 압축 방법과 관련된 복수의 논리 회로를 포함하며, 상기 압축 데이터가 입력되면, 상기 복수의 논리 회로를 통해 상기 압축 데이터의 압축을 해제하고, 상기 압축 해제된 데이터를 출력하는 디코더; 및상기 디코더로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 데이터를 획득하는 프로세서;를 포함하는압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 메모리는,상기 압축 데이터에 대응되는 대표 값 매트릭스를 더 저장하며,상기 프로세서는,상기 압축 해제된 데이터 및 상기 대표 값 매트릭스에 기초하여 상기 신경망 연산 가능한 형태의 데이터를 획득하며,상기 신경망 연산 가능한 형태의 데이터를 이용하여 상기 신경망 연산을 수행하고,상기 압축 해제된 데이터 및 상기 대표 값 매트릭스는,상기 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 획득된 매트릭스들인, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 메모리는,상기 압축 데이터에 대응되는 프루닝 인덱스 매트릭스를 더 저장하며,상기 프로세서는,상기 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터를 업데이트하며,상기 프루닝 인덱스 매트릭스는,상기 원본 매트릭스의 프루닝(pruning) 과정에서 획득된 매트릭스이고, 상기 압축 데이터를 획득하는 과정에서이용되는, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 메모리는,상기 압축 데이터에 대응되는 패치 정보를 더 저장하며,상기 프로세서는,상기 패치 정보에 기초하여 상기 압축 해제된 데이터에 포함된 상기 복수의 엘리먼트 중 일부의 바이너리 데이터 값을 변경하고,상기 패치 정보는,공개특허 10-2020-0135126-3-상기 압축 데이터를 획득하는 과정에서 발생하는 에러 정보를 포함하는, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 메모리는,상기 압축 데이터에 대응되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 더 저장하며,상기 프로세서는,상기 제1 프루닝 인덱스 매트릭스 및 상기 제2 프루닝 인덱스 매트릭스에 기초하여 프루닝 인덱스 매트릭스를획득하고,상기 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터를 업데이트하며,상기 프루닝 인덱스 매트릭스는,상기 원본 매트릭스의 프루닝 과정에서 획득된 매트릭스이고, 상기 압축 데이터를 획득하는 과정에서 이용되며,상기 제1 프루닝 인덱스 매트릭스 및 상기 제2 프루닝 인덱스 매트릭스는,상기 원본 매트릭스가 팩토라이즈(factorize)되어 획득된 제1 서브 매트릭스 및 제2 서브 매트릭스 각각에 기초하여 획득된, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서,상기 압축 해제된 데이터는,상기 원본 매트릭스를 인터리빙(Interleaving)한 후, 상기 인터리빙된 매트릭스를 양자화하여 획득된 매트릭스이고,상기 프로세서는,상기 신경망 연산 가능한 형태의 데이터를 상기 인터리빙에 대응되는 방식에 따라 디인터리빙하고,상기 디인터리빙된 데이터를 이용하여 상기 신경망 연산을 수행하는, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 프로세서는,매트릭스 형태로 배열된 복수의 연산 소자(Processing Element)를 포함하며,상기 복수의 연산 소자를 이용하여 상기 신경망 연산을 수행하는, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서,상기 압축 해제된 데이터는,상기 원본 매트릭스를 열의 개수 및 행의 개수가 동일한 복수의 매트릭스로 분할하고, 상기 분할된 복수의 매트릭스 중 하나를 양자화하여 획득된 매트릭스인, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 메모리는,상기 인공 지능 모델의 상기 신경망 연산에서 압축 해제되어 이용되는 타 압축 데이터를 더 저장하며,공개특허 10-2020-0135126-4-상기 압축 해제 장치는,상기 타 압축 데이터의 압축 방법과 관련된 복수의 타 논리 회로를 포함하며, 상기 타 압축 데이터가 입력되면,상기 복수의 타 논리 회로를 통해 상기 타 압축 데이터의 압축을 해제하고, 상기 압축 해제된 타 데이터를 출력하는 타 디코더;를 더 포함하고,상기 프로세서는,상기 타 디코더로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 타 데이터를 획득하며,상기 신경망 연산 가능한 데이터 및 상기 신경망 연산 가능한 타 데이터를 결합하여 각 엘리먼트가 복수의 바이너리 데이터를 포함하는 매트릭스를 획득하는, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 압축 해제 장치는,하나의 칩으로 구현된, 압축 해제 장치."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "압축 데이터의 압축 방법과 관련된 복수의 논리 회로를 포함하는 압축 해제 장치의 제어 방법에 있어서,상기 복수의 논리 회로가 인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 상기 압축 데이터를 수신하는 단계;상기 복수의 논리 회로가 상기 압축 데이터의 압축을 해제하고, 상기 압축 해제된 데이터를 출력하는 단계; 및상기 복수의 논리 회로로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 데이터를 획득하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 압축 해제된 데이터, 및 상기 압축 데이터에 대응되는 대표 값 매트릭스에 기초하여 상기 신경망 연산 가능한 형태의 데이터를 획득하는 단계; 및상기 신경망 연산 가능한 형태의 데이터를 이용하여 상기 신경망 연산을 수행하는 단계;를 더 포함하며,상기 압축 해제된 데이터 및 상기 대표 값 매트릭스는,상기 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 획득된 매트릭스들인, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 압축 데이터에 대응되는 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터를 업데이트하는 단계;를 더 포함하며,상기 프루닝 인덱스 매트릭스는,상기 원본 매트릭스의 프루닝(pruning) 과정에서 획득된 매트릭스이고, 상기 압축 데이터를 획득하는 과정에서이용되는, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 압축 데이터에 대응되는 패치 정보에 기초하여 상기 압축 해제된 데이터에 포함된 상기 복수의 엘리먼트중 일부의 바이너리 데이터 값을 변경하는 단계;를 더 포함하며,공개특허 10-2020-0135126-5-상기 패치 정보는,상기 압축 데이터를 획득하는 과정에서 발생하는 에러 정보를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 압축 데이터에 대응되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스에 기초하여 프루닝인덱스 매트릭스를 획득하는 단계; 및상기 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터를 업데이트하는 단계;를 더 포함하며,상기 프루닝 인덱스 매트릭스는,상기 원본 매트릭스의 프루닝 과정에서 획득된 매트릭스이고, 상기 압축 데이터를 획득하는 과정에서 이용되며,상기 제1 프루닝 인덱스 매트릭스 및 상기 제2 프루닝 인덱스 매트릭스는,상기 원본 매트릭스가 팩토라이즈(factorize)되어 획득된 제1 서브 매트릭스 및 제2 서브 매트릭스 각각에 기초하여 획득된, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 압축 해제된 데이터는,상기 원본 매트릭스를 인터리빙(Interleaving)한 후, 상기 인터리빙된 매트릭스를 양자화하여 획득된 매트릭스이고,상기 제어 방법은,상기 신경망 연산 가능한 형태의 데이터를 상기 인터리빙에 대응되는 방식에 따라 디인터리빙하는 단계;를 더포함하며,상기 신경망 연산을 수행하는 단계는,상기 디인터리빙된 데이터를 이용하여 상기 신경망 연산을 수행하는, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 신경망 연산을 수행하는 단계는,매트릭스 형태로 배열된 복수의 연산 소자(Processing Element)를 이용하여 상기 신경망 연산을 수행하는, 제어방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 압축 해제된 데이터는,상기 원본 매트릭스를 열의 개수 및 행의 개수가 동일한 복수의 매트릭스로 분할하고, 상기 분할된 복수의 매트릭스 중 하나를 양자화하여 획득된 매트릭스인, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 압축 해제 장치는,타 압축 데이터의 압축 방법과 관련된 복수의 타 논리 회로를 포함하며,공개특허 10-2020-0135126-6-상기 제어 방법은,상기 인공 지능 모델의 상기 신경망 연산에서 압축 해제되어 이용되는 상기 타 압축 데이터를 수신하는 단계;상기 복수의 타 논리 회로가 상기 타 압축 데이터의 압축을 해제하고, 상기 압축 해제된 타 데이터를 출력하는단계;상기 복수의 타 논리 회로로부터 출력되는 신경망 연산 가능한 형태의 타 데이터를 획득하는 단계; 및상기 신경망 연산 가능한 데이터 및 상기 신경망 연산 가능한 타 데이터를 결합하여 각 엘리먼트가 복수의 바이너리 데이터를 포함하는 매트릭스를 획득하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 압축 해제 장치는,하나의 칩으로 구현된, 제어 방법."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "압축 해제 장치가 개시된다. 본 압축 해제 장치는 인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 압 축 데이터가 저장된 메모리, 압축 데이터의 압축 방법과 관련된 복수의 논리 회로를 포함하며, 압축 데이터가 입 력되면, 복수의 논리 회로를 통해 압축 데이터의 압축을 해제하고, 압축 해제된 데이터를 출력하는 디코더 및 디 코더로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 데이터를 획득하는 프로세서를 포함한다."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공 지 능(Artificial Intelligence, AI) 시스템 및 그 응용 중 압축된 인공 지능 모델의 압축을 해제하기 위한 압축 해제 장치 및 그 제어 방법에 대한 것이다."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 딥러닝 모델의 성능 저하를 최소화하면서 압축률을 높이기 위해 프루닝(pruning) 및 양자화가 이용되고 있 다. 가령, 특정 값 이하인 weight가 0으로 프루닝된 weight matrix는 non-zero 값을 나타내는 제1 데이터 셋, 각 로우(row)의 non-zero weight의 수를 누적한 제2 데이터 및 각 non-zero값에 해당하는 column index를 저장 한 제3 데이터로 구분될 수 있다. 이후, 제1 내지 제3 데이터가 양자화될 수 있다. 한편, weight matrix는 딥러 닝 모델의 weight 파라미터를 matrix 형태로 표현한 것일 수 있다. 다만, 양자화된 데이터로부터 최초의 weight matrix를 복원하기 위해서는 양자화를 해제하고, 제1 내지 제3 데 이터로부터 최초의 weight matrix를 복원하는 과정이 필요하다. 즉, 최초의 weight matrix를 복원하기 전까지는 양자화된 데이터를 복수의 그룹으로 구분한 후, 각 그룹을 병렬적으로 처리하는 것이 불가능하다. 그에 따라, 압축 과정에서 압축률을 높이면서도 정확도를 유지하고, 압축 해제 과정에서 병렬적인 처리를 통해 연산 속도를 확보하기 위한 연구가 활발하게 이루어지고 있다."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 개시의 목적은 가령, 음성 인식이나 객체 인식에서 메모리 사용량 을 줄이고 고속 처리를 위해 데이터 용량이 축소된 인공 지능 모델을 이용하며, 데이터 용량이 축소된 인공 지 능 모델의 압축을 해제하는 압축 해제 장치 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는 인공 지능 모델의 신경망 연산에 서 압축 해제되어 이용되는 압축 데이터가 저장된 메모리, 상기 압축 데이터의 압축 방법과 관련된 복수의 논리 회로를 포함하며, 상기 압축 데이터가 입력되면, 상기 복수의 논리 회로를 통해 상기 압축 데이터의 압축을 해 제하고, 상기 압축 해제된 데이터를 출력하는 디코더 및 상기 디코더로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 데이터를 획득하는 프로세서를 포함한다. 여기서, 상기 메모리는 상기 압축 데이터에 대응되는 대표 값 매트릭스를 더 저장하며, 상기 프로세서는 상기 압축 해제된 데이터 및 상기 대표 값 매트릭스에 기초하여 상기 신경망 연산 가능한 형태의 데이터를 획득하며, 상기 신경망 연산 가능한 형태의 데이터를 이용하여 상기 신경망 연산을 수행하고, 상기 압축 해제된 데이터 및 상기 대표 값 매트릭스는 상기 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 획득된 매트릭스들일 수 있다. 그리고, 상기 메모리는 상기 압축 데이터에 대응되는 프루닝 인덱스 매트릭스를 더 저장하며, 상기 프로세서는 상기 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터를 업데이트하며, 상기 프루닝 인덱스 매트릭 스는 상기 원본 매트릭스의 프루닝(pruning) 과정에서 획득된 매트릭스이고, 상기 압축 데이터를 획득하는 과정 에서 이용될 수 있다. 여기서, 상기 메모리는 상기 압축 데이터에 대응되는 패치 정보를 더 저장하며, 상기 프로세서는 상기 패치 정 보에 기초하여 상기 압축 해제된 데이터에 포함된 상기 복수의 엘리먼트 중 일부의 바이너리 데이터 값을 변경 하고, 상기 패치 정보는 상기 압축 데이터를 획득하는 과정에서 발생하는 에러 정보를 포함할 수 있다. 한편, 상기 메모리는 상기 압축 데이터에 대응되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스 를 더 저장하며, 상기 프로세서는 상기 제1 프루닝 인덱스 매트릭스 및 상기 제2 프루닝 인덱스 매트릭스에 기 초하여 프루닝 인덱스 매트릭스를 획득하고, 상기 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터 를 업데이트하며, 상기 프루닝 인덱스 매트릭스는 상기 원본 매트릭스의 프루닝 과정에서 획득된 매트릭스이고, 상기 압축 데이터를 획득하는 과정에서 이용되며, 상기 제1 프루닝 인덱스 매트릭스 및 상기 제2 프루닝 인덱스 매트릭스는 상기 원본 매트릭스가 팩토라이즈(factorize)되어 획득된 제1 서브 매트릭스 및 제2 서브 매트릭스 각각에 기초하여 획득될 수 있다. 또한, 상기 압축 해제된 데이터는 상기 원본 매트릭스를 인터리빙(Interleaving)한 후, 상기 인터리빙된 매트릭 스를 양자화하여 획득된 매트릭스이고, 상기 프로세서는 상기 신경망 연산 가능한 형태의 데이터를 상기 인터리 빙에 대응되는 방식에 따라 디인터리빙하고, 상기 디인터리빙된 데이터를 이용하여 상기 신경망 연산을 수행할 수 있다. 한편, 상기 프로세서는 매트릭스 형태로 배열된 복수의 연산 소자(Processing Element)를 포함하며, 상기 복수 의 연산 소자를 이용하여 상기 신경망 연산을 수행할 수 있다. 또한, 상기 압축 해제된 데이터는 상기 원본 매트릭스를 열의 개수 및 행의 개수가 동일한 복수의 매트릭스로 분할하고, 상기 분할된 복수의 매트릭스 중 하나를 양자화하여 획득된 매트릭스일 수 있다. 한편, 상기 메모리는 상기 인공 지능 모델의 상기 신경망 연산에서 압축 해제되어 이용되는 타 압축 데이터를 더 저장하며, 상기 압축 해제 장치는 상기 타 압축 데이터의 압축 방법과 관련된 복수의 타 논리 회로를 포함하 며, 상기 타 압축 데이터가 입력되면, 상기 복수의 타 논리 회로를 통해 상기 타 압축 데이터의 압축을 해제하 고, 상기 압축 해제된 타 데이터를 출력하는 타 디코더를 더 포함하고, 상기 프로세서는 상기 타 디코더로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 타 데이터를 획득하며, 상기 신경망 연산 가능한 데이터 및 상기 신경망 연산 가능한 타 데이터를 결합하여 각 엘리먼트가 복수의 바이너리 데이터를 포함하는 매트릭스를 획득할 수 있다. 또한, 상기 압축 해제 장치는 하나의 칩으로 구현될 수 있다. 한편, 본 개시의 일 실시 예에 따른 압축 데이터의 압축 방법과 관련된 복수의 논리 회로를 포함하는 압축 해제 장치의 제어 방법은 상기 복수의 논리 회로가 인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 상기 압축 데이터를 수신하는 단계, 상기 복수의 논리 회로가 상기 압축 데이터의 압축을 해제하고, 상기 압축 해제 된 데이터를 출력하는 단계 및 상기 복수의 논리 회로로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 데이터를 획득하는 단계를 포함한다. 여기서, 상기 압축 해제된 데이터, 및 상기 압축 데이터에 대응되는 대표 값 매트릭스에 기초하여 상기 신경망 연산 가능한 형태의 데이터를 획득하는 단계 및 상기 신경망 연산 가능한 형태의 데이터를 이용하여 상기 신경 망 연산을 수행하는 단계를 더 포함하며, 상기 압축 해제된 데이터 및 상기 대표 값 매트릭스는 상기 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 획득된 매트릭스들일 수 있다. 그리고, 상기 압축 데이터에 대응되는 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터를 업데이트 하는 단계를 더 포함하며, 상기 프루닝 인덱스 매트릭스는 상기 원본 매트릭스의 프루닝(pruning) 과정에서 획 득된 매트릭스이고, 상기 압축 데이터를 획득하는 과정에서 이용될 수 있다.여기서, 상기 압축 데이터에 대응되는 패치 정보에 기초하여 상기 압축 해제된 데이터에 포함된 상기 복수의 엘 리먼트 중 일부의 바이너리 데이터 값을 변경하는 단계를 더 포함하며, 상기 패치 정보는 상기 압축 데이터를 획득하는 과정에서 발생하는 에러 정보를 포함할 수 있다. 한편, 상기 압축 데이터에 대응되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스에 기초하여 프 루닝 인덱스 매트릭스를 획득하는 단계 및 상기 프루닝 인덱스 매트릭스에 기초하여 상기 압축 해제된 데이터를 업데이트하는 단계를 더 포함하며, 상기 프루닝 인덱스 매트릭스는 상기 원본 매트릭스의 프루닝 과정에서 획득 된 매트릭스이고, 상기 압축 데이터를 획득하는 과정에서 이용되며, 상기 제1 프루닝 인덱스 매트릭스 및 상기 제2 프루닝 인덱스 매트릭스는 상기 원본 매트릭스가 팩토라이즈(factorize)되어 획득된 제1 서브 매트릭스 및 제2 서브 매트릭스 각각에 기초하여 획득될 수 있다. 또한, 상기 압축 해제된 데이터는 상기 원본 매트릭스를 인터리빙(Interleaving)한 후, 상기 인터리빙된 매트릭 스를 양자화하여 획득된 매트릭스이고, 상기 제어 방법은 상기 신경망 연산 가능한 형태의 데이터를 상기 인터 리빙에 대응되는 방식에 따라 디인터리빙하는 단계를 더 포함하며, 상기 신경망 연산을 수행하는 단계는 상기 디인터리빙된 데이터를 이용하여 상기 신경망 연산을 수행할 수 있다. 한편, 상기 신경망 연산을 수행하는 단계는 매트릭스 형태로 배열된 복수의 연산 소자(Processing Element)를 이용하여 상기 신경망 연산을 수행할 수 있다. 또한, 상기 압축 해제된 데이터는 상기 원본 매트릭스를 열의 개수 및 행의 개수가 동일한 복수의 매트릭스로 분할하고, 상기 분할된 복수의 매트릭스 중 하나를 양자화하여 획득된 매트릭스일 수 있다. 한편, 상기 압축 해제 장치는 타 압축 데이터의 압축 방법과 관련된 복수의 타 논리 회로를 포함하며, 상기 제 어 방법은 상기 인공 지능 모델의 상기 신경망 연산에서 압축 해제되어 이용되는 상기 타 압축 데이터를 수신하 는 단계, 상기 복수의 타 논리 회로가 상기 타 압축 데이터의 압축을 해제하고, 상기 압축 해제된 타 데이터를 출력하는 단계, 상기 복수의 타 논리 회로로부터 출력되는 신경망 연산 가능한 형태의 타 데이터를 획득하는 단 계 및 상기 신경망 연산 가능한 데이터 및 상기 신경망 연산 가능한 타 데이터를 결합하여 각 엘리먼트가 복수 의 바이너리 데이터를 포함하는 매트릭스를 획득하는 단계를 더 포함할 수 있다. 또한, 상기 압축 해제 장치는 하나의 칩으로 구현될 수 있다."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 압축 해제 장치는 복수의 논리 회로로 구현된 디코더를 이용 하여 매트릭스의 압축을 해제하고, 압축이 해제된 매트릭스로부터 복원 매트릭스를 획득하여 신경망 연산을 수 행할 수 있다."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공 지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 압축 해제 장치의 구성을 나타내는 블럭도이다. 압축 해제 장치는 압축된 인공 지능 모델의 압축을 해제하는 장치일 수 있다. 여기서, 압축된 인공 지능 모델은 압축 해제 후 신경망 연산에서 이용 가능한 데이터로서, 압축 해제 전에는 신경망 연산에 이용 불가능한 데이터일 수 있다. 예를 들어, 압축 해제 장치는 압축된 인공 지능 모델에 포함된 압축 데이터의 압축을 해제하여 최종적으로 신경망 연산 가능한 데이터(이하, 복원 데이터)를 획득하며, 복원 데이터를 이용하여 신경망 연산을 수행하는 장치일 수 있다. 예를 들어, 압축 해제 장치는 서버, 데스크탑 PC, 노트북, 스마트폰, 태블릿 PC, TV, 웨 어러블 기기 등에 메모리와 칩 사이에 존재하는 별도의 HW 형태로 구현될 수도 있고, SOC(System On Chip)로 구 현될 수도 있다. 또는, 압축 해제 장치는 CPU, GPU, DSP, NPU 등과 같은 칩 형태로 구현될 수도 있고, 회 로 형태로 구현될 수도 있으며, 칩 내부의 일 구성의 형태로 구현될 수도 있다. 다만, 이상과 같은 압축 해제 장치의 종류는 일 실시 예에 불과하며, 압축된 인공 지능 모델에 포함된 압 축 데이터의 압축을 해제하여 최종적으로 복원 데이터를 획득하며, 복원 데이터를 이용하여 신경망 연산을 수행 하는 장치라면 어떠한 장치라도 무방하다. 압축 해제 장치는 도 1에 도시된 바와 같이, 메모리, 디코더 및 프로세서를 포함한다. 메모리는 인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 압축 데이터를 저장할 수 있다. 예를 들어, 메모리는 압축 장치로부터 수신된 압축 데이터를 저장할 수 있다. 압축 데이터 및 압축되기 전의 인 공 지능 모델을 구성하는 데이터는 적어도 하나의 매트릭스 형태로 표현될 수 있다. 이하에서는 설명의 편의를 위하여 압축 데이터를 제1 매트릭스로서 설명하고, 제1 매트릭스가 압축 해제된 데이터를 제2 매트릭스로 설명한다. 제2 매트릭스는 후술할 대표 값 매트릭스와 함께 복원 데이터로 변환될 수 있다. 여기서, 제1 매트릭스는 제2 매트릭스가 압축 방법에 기초하여 압축된 매트릭스일 수 있다. 예를 들어, 제1 매 트릭스는 제2 매트릭스가 디코더를 구성하고 있는 XOR 게이트 등의 논리 회로에 기초하여 형성된 인코딩 매트릭스를 통하여 압축된 매트릭스일 수 있다. 제2 매트릭스는 인공 지능 모델에 포함된 원본 매트릭스(웨이트 (weight) 매트릭스)가 프루닝(Pruning)등을 통해 압축된 매트릭스이거나 원본 매트릭스가 양자화(quantizatio n)된 매트릭스일 수 있다. 또는, 제2 매트릭스는 프루닝된 원본 매트릭스의 양자화 과정에서 획득되는 바이너리 데이터를 포함하는 매트릭스일 수도 있다. 원본 매트릭스는 인공 지능 모델에 포함된 매트릭스로서, 인공 지능 모델의 학습 과정이 완료된 후 획득되는 매트릭스이며, 압축이 수행되지 않은 상태일 수 있다. 한편, 인코딩 매 트릭스는 제2 매트릭스의 압축에 이용되는 매트릭스로서, 디코더을 구성하는 논리 회로를 구현하는데 사용 되는 매트릭스일 수 있다. 제2 매트릭스를 압축하여 제1 매트릭스를 획득하는 구체적인 방법에 대하여는 도면을 통해 후술한다. 디코더는 압축 데이터의 압축 방법과 관련된 복수의 논리 회로를 포함할 수 있다. 인코딩 매트릭스를 이용 하여 압축을 수행하는 것을 예로 들면, 디코더는 인코딩 매트릭스에 기초하여 형성된 복수의 논리 회로를 포함할 수 있다. 논리 회로는 XOR 게이트일 수 있으나, 이에 한정되는 것은 아니다. 가령, 디코더는 인코 딩 매트릭스에 기초하여 각 입출력 단자가 연결된 복수의 XOR 게이트를 포함할 수 있다. 즉, 복수의 XOR 게이트 에 바이너리 데이터가 입력되면, 인코딩 매트릭스와 바이너리 데이터의 매트릭스 곱셈 결과가 출력되도록 각각 의 입출력 단자가 연결될 수 있다. 바이너리 데이터는 바이너리 양자화 되어 1bit로 표시되는 데이터를 의미하 나, 이에 한정되는 것은 아니며, 다른 양자화 방법을 통해서도 획득될 수 있다. 압축 방법을 설계하는 경우, 복수의 XOR 게이트를 랜덤하게 연결하여 디코더를 먼저 구현하고, 복수의 XOR 게이트 각각의 입력과 복수의 XOR 게이트 각각의 출력을 비교하여 인코딩 매트릭스를 획득할 수 있다. 또는, 0 및 1을 포함하는 인코딩 매트릭스를 먼저 생성하고, 인코딩 매트릭스에 기초하여 제2 매트릭스를 압축하여 제1 매트릭스를 획득할 수 있다. 이 경우, 압축 해제 장치의 구현 시, 인코딩 매트릭스에 대응되도록 복수의 XOR 게이트의 입출력 단자를 연결하여 디코더를 구현할 수도 있다. 디코더는 제1 매트릭스가 입력되면, 복수의 논리 회로를 통해 제1 매트릭스의 압축을 해제하고, 압축 해제 된 데이터를 출력할 수 있다. 예를 들어, 디코더는 제1 매트릭스에 포함된 제1 개수 단위의 바이너리 데이 터가 입력되면, 복수의 XOR 게이트를 통해 제1 개수보다 큰 제2 개수 단위의 바이너리 데이터를 출력할 수 있다. 가령, 디코더는 제1 매트릭스에 포함된 5개 단위의 바이너리 데이터를 순차적으로 입력받고, 복수의 XOR 게이트를 통해 9개 단위의 바이너리 데이터를 순차적으로 출력할 수 있다. 가령, 인코딩 매트릭스가 9 × 5 의 형태이면, 디코더는 5개의 입력 단자와 9개의 출력 단자를 포함할 수 있다. 그리고, 제1 매트릭스가 25 개의 엘리먼트(파라미터)를 갖는 경우, 디코더는 5개 단위의 바이너리 데이터를 5회 입력받고, 9개 단위의 바이너리 데이터를 5회 출력하여 총 45개의 엘리먼트를 출력할 수 있다. 프로세서는 디코더로부터 출력되는 바이너리 데이터로부터 제2 매트릭스를 획득할 수 있다. 상술한 예에서 프로세서는 5회 출력되는 9개 단위의 바이너리 데이터로부터 45개의 엘리먼트를 포함하는 제2 매트 릭스를 획득할 수 있다. 한편, 메모리는 제1 매트릭스에 대응되는 대표 값 매트릭스를 더 저장할 수 있다. 예를 들어, 메모리(11 0)는 압축 장치로부터 수신된 제1 매트릭스에 대응되는 대표 값 매트릭스를 저장할 수 있다. 대표 값 매트릭스 는 프루닝된 원본 매트릭스의 양자화 과정에서 획득되며, 프루닝된 원본 매트릭스에 포함된 복수의 엘리먼트를 대표하는 대표 값의 집합일 수 있다. 프로세서는 제2 매트릭스 및 대표 값 매트릭스에 기초하여 복원 매트릭스를 획득하며, 복원 매트릭스를 이 용하여 신경망 연산을 수행할 수 있다. 여기서, 제2 매트릭스 및 대표 값 매트릭스는 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 획득된 매트릭스들일 수 있다. 양자화란 데이터를 복수의 표본 값 중 하나로 변경 하는 것을 의미하며, 복수의 표본 값들로 표현되기 때문에 전체 데이터 용량을 축소할 수 있으나, 변경된 표본 값과 최초 데이터의 차이만큼 오차가 발생할 수 있다. 가령, 압축 장치는 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 대표 값 매트릭스 및 바이너리 양자화 데이터를 포함하는 제2 매트릭스를 획득할 수 있다. 여기서, 바이너리 양자화 데이터는 1bit로 표시되는 데이터 를 의미한다. 좀더 구체적인 예로서, 압축 장치는 원본 매트릭스에 포함된 기설정된 개수의 엘리먼트에 대하여 하나의 대표 값을 설정하고, 각 엘리먼트를 바이너리 양자화 데이터로 나타내는 방식으로 양자화를 수행할 수있다. 압축 장치는 이러한 방법으로 원본 매트릭스 전체에 대한 대표 값들을 포함하는 대표 값 매트릭스를 획득 하고, 원본 매트릭스에 포함된 엘리먼트들을 바이너리 양자화 데이터로 변환한 제2 매트릭스를 획득할 수 있다. 다만, 이에 한정되는 것은 아니며, 압축 장치는 얼마든지 다른 양자화 방법을 이용할 수도 있다. 프로세서는 제2 매트릭스 및 대표 값 매트릭스로부터 신경망 연산에 이용될 복원 매트릭스를 획득할 수 있 다. 여기서, 복원 매트릭스는 원본 매트릭스와는 다를 수 있다. 즉, 양자화 오차로 인하여 복원 매트릭스는 원 본 매트릭스와는 다를 수 있다. 다만, 후술할 압축 과정에서 원본 매트릭스를 이용한 신경망 연산의 결과와 복 원 매트릭스를 이용한 신경망 연산의 결과가 큰 차이가 나지 않도록 복원 매트릭스가 획득될 수 있으며, 이에 대하여는 후술한다. 프로세서는 매트릭스 형태로 배열된 복수의 연산 소자(Processing Element)를 포함하며, 복수의 연산 소자 를 이용하여 인공 지능 모델의 신경망 연산을 수행할 수 있다. 한편, 메모리는 제1 매트릭스에 대응되는 프루닝 인덱스 매트릭스를 더 저장할 수도 있다. 예를 들어, 메 모리는 압축 장치로부터 수신된 제1 매트릭스에 대응되는 프루닝 인덱스 매트릭스를 저장할 수도 있다. 프루닝 인덱스 매트릭스는 원본 매트릭스의 프루닝(pruning) 과정에서 획득된 매트릭스이며, 제2 매트릭스를 제 1 매트릭스로 압축하는 과정에서 이용될 수 있다. 먼저, 프루닝은 redundant한 웨이트를 제거하는 방법으로, 구체적으로 인공 지능 모델에 포함된 원본 매트릭스 에서 특정 엘리먼트(특정 딥러닝 파라미터)의 수치를 0으로 바꾸는 방법이다. 예를 들어, 압축 장치는 m × n의 원본 매트릭스에 포함된 복수의 엘리먼트 중 기설정된 값 이하의 엘리먼트를 0으로 변경하여 m × n의 원본 매 트릭스를 프루닝하고, m × n의 원본 매트릭스에 포함된 복수의 엘리먼트 각각이 프루닝 되었는지를 0 또는 1로 나타내는 m × n의 프루닝 인덱스 매트릭스를 획득할 수 있다. 그리고, 압축 장치는 인코딩 매트릭스에 기초하여 제2 매트릭스를 제1 매트릭스로 압축하는 과정에서 프루닝 인 덱스 매트릭스를 이용할 수 있다. 구체적으로, 압축 장치는 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터와 인코딩 매트릭스의 매트릭스 곱셈 결과가 제2 매트릭스에 포함된 제2 개수 단위의 대응되는 바이너리 데이터와 동일하도록 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터의 값을 결정하게 되는데, 이때 제1 개수가 제2 개수보다 작으므로 이를 만족시키는 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터의 값은 도출되지 않을 수도 있다. 이때, 압축 장치는 프루닝 인덱스 매트릭스에 기초하여 제2 매트릭스에 포함된 제2 개수 단위의 대응되는 바이너리 데이터 중 일부를 불필요한 데이터로 결정함으로써, 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터의 값을 결정할 수 있다. 이에 대한 구체적인 설명은 후술한다. 프로세서는 프루닝 인덱스 매트릭스에 기초하여 제2 매트릭스를 업데이트할 수 있다. 예를 들어, 프로세서 는 프루닝 인덱스 매트릭스에 기초하여 제2 매트릭스에 포함된 복수의 엘리먼트 중 일부를 0으로 변경할 수 있다. 다만, 이에 한정되는 것은 아니며, 메모리는 프루닝 인덱스 매트릭스를 저장하지 않을 수도 있다. 즉, 압 축 장치가 압축 해제 장치로 프루닝 인덱스 매트릭스를 제공하지 않는 경우, 압축 해제 장치는 제2 매트릭스를 제1 매트릭스로 압축하는 과정에서 프루닝 인덱스 매트릭스가 이용되지 않은 것으로 식별하고, 상술 한 제2 매트릭스에 포함된 복수의 엘리먼트 중 일부를 0으로 변경하는 동작을 생략할 수 있다. 또는, 압축 장치가 압축 해제 장치로 프루닝 인덱스 매트릭스를 제공할 수도 있으나, 제2 매트릭스를 제1 매트릭스로 압축하는 과정에서 프루닝 인덱스 매트릭스가 이용되지 않을 수도 있다. 이 경우, 압축 장치는 제2 매트릭스를 제1 매트릭스로 압축하는 과정에서 프루닝 인덱스 매트릭스가 이용되지 않았음을 나타내는 정보를 압축 해제 장치로 제공하고, 압축 해제 장치는 상술한 제2 매트릭스에 포함된 복수의 엘리먼트 중 일 부를 0으로 변경하는 동작을 생략할 수도 있다. 한편, 메모리는 제1 매트릭스에 대응되는 패치 정보를 더 저장할 수도 있다. 예를 들어, 메모리는 압 축 장치로부터 수신된 제1 매트릭스에 대응되는 패치 정보를 저장할 수도 있다. 여기서, 패치 정보는 제2 매트릭스를 제1 매트릭스로 압축하는 과정에서 발생하는 에러 정보를 포함할 수 있다. 구체적으로, 압축 장치는 제2 매트릭스를 제1 매트릭스로 압축하는 과정에서 프루닝 인덱스 매트릭스를 이용하 여 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터의 값을 결정할 수 있다. 다만, 프루닝 인덱스 매트 릭스를 이용하더라도, 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터의 값이 결정되지 않을 수도 있 다. 이 경우, 압축 장치는 오류의 개수를 최소화하도록 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터의 값을 결정할 수 있다. 가령, 압축 장치는 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터와 인코 딩 매트릭스의 매트릭스 곱셈 결과가 제2 매트릭스에 포함된 제2 개수 단위의 대응되는 바이너리 데이터와 차이 가 발생하는 비트수를 최소화하도록 제1 매트릭스에 포함될 제1 개수 단위의 바이너리 데이터의 값을 결정할 수 있다. 그리고, 압축 장치는 차이가 발생하는 비트수, 위치 등에 대한 정보를 패치 정보로 생성할 수 있다. 그리 고, 압축 장치는 압축 해제 과정에서 발생할 수 있는 오류를 해소하도록 패치 정보를 압축 해제 장치로 제 공할 수 있다. 프로세서는 패치 정보에 기초하여 제2 매트릭스에 포함된 복수의 엘리먼트 중 일부의 바이너리 데이터 값 을 변경할 수 있다. 예를 들어, 프로세서는 제2 매트릭스에 포함된 복수의 엘리먼트 중 패치 정보가 나타 내는 엘리먼트의 값이 0이면 1로 변경하고, 1이면 0으로 변경할 수 있다. 한편, 메모리는 제1 매트릭스에 대응되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 더 저장할 수도 있다. 예를 들어, 메모리는 압축 장치로부터 수신된 제1 매트릭스에 대응되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 저장할 수 있다. 이 경우, 압축 장치는 프루닝 인덱스 매트 릭스 대신 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 압축 해제 장치로 제공할 수 있 다. 먼저, 프루닝 인덱스 매트릭스는 상술한 바와 같이, 원본 매트릭스의 프루닝 과정에서 획득된 매트릭스일 수 있 다. 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스는 원본 매트릭스가 팩토라이즈(factorize)되어 획 득된 제1 서브 매트릭스 및 제2 서브 매트릭스 각각에 기초하여 획득될 수 있다. 팩토라이제이션 (factorization)은 일종의 인수분해로서, 매트릭스를 크기가 작은 두 개의 매트릭스로 분할하는 것을 의미하며, 가령 non-negative matrix factorization(NMF)와 같은 방법이 이용될 수 있다. 다만, 이에 한정되는 것은 아니 며, 얼마든지 다양한 방법이 이용될 수 있다. 압축 장치는 원본 매트릭스를 팩토라이즈하여 제1 서브 매트릭스 및 제2 서브 매트릭스를 획득하고, 제1 서브 매트릭스 및 제2 서브 매트릭스 각각을 프루닝하여 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스 를 획득할 수 있다. 이후, 압축 장치는 프루닝 인덱스 매트릭스를 이용한 경우의 신경망 연산의 결과와 제1 프 루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 이용한 경우의 신경망 연산의 결과를 비교하여 제1 프 루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 업데이트할 수 있다. 업데이트 방법은 제1 서브 매트릭 스 및 제2 서브 매트릭스 각각의 프루닝 레이트(pruning rate)를 변경하는 방법일 수 있다. 최종적으로, 압축 장치는 두 경우의 연산 결과의 차이가 임계 값 이내가 되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 획득할 수 있다. 압축 장치는 프루닝 인덱스 매트릭스를 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스로 변환함에 따라 데이터 용량을 축소시킬 수 있다. 가령, 압축 장치는 100 × 50의 프루닝 인덱스 매트릭스를 100 × 10의 제1 프루닝 인덱스 매트릭스 및 10 × 50의 제2 프루닝 인덱스 매트릭스로 변환할 수 있다. 이 경우, 압축 장치 는 5000의 데이터를 1000 + 500 = 1500의 데이터로 축소시킬 수 있다. 프로세서는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스에 기초하여 프루닝 인덱스 매트릭 스를 획득하고, 프루닝 인덱스 매트릭스에 기초하여 제2 매트릭스를 업데이트할 수 있다. 구체적으로, 제1 프루 닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스 각각은 바이너리 데이터를 포함하며, 프로세서는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 매트릭스 곱셈 연산하여 프루닝 인덱스 매트릭스를 획득할 수 있다. 프로세서는 프루닝 인덱스 매트릭스에 기초하여 제2 매트릭스에 포함된 복수의 엘리먼트 중 일부를 0으로 변경할 수 있다. 한편, 제2 매트릭스는 원본 매트릭스를 인터리빙(Interleaving)한 후, 인터리빙된 매트릭스를 양자화하여 획득 된 매트릭스일 수도 있다. 인터리빙은 매트릭스에 포함된 데이터의 순서를 일정 단위로 재배열시키는 것을 의미 한다. 즉, 압축 장치는 원본 매트릭스를 양자화하기 전에 인터리빙을 수행할 수도 있다. 프로세서는 복원 매트릭스를 인터리빙에 대응되는 방식에 따라 디인터리빙하고, 디인터리빙된 복원 매트릭 스를 이용하여 신경망 연산을 수행할 수도 있다. 인터리빙 및 디인터리빙 동작이 추가됨에 따라 양자화 과정에서 압축률이 향상될 수 있다. 가령, 원본 매트릭스 의 엘리먼트가 고르게 분포되지 않은 경우, 프루닝 인덱스 매트릭스가 1 또는 0이 연속됨에 따라 압축률 또는 정확도가 현저히 저하될 수 있다. 이때, 압축 대상이 되는 매트릭스를 인터리빙하는 경우, 프루닝 인덱스 매트 릭스의 randomness가 향상되어 압축률 및 정확도를 향상시킬 수 있다. 인터리빙 방식 및 디인터리빙 방식의 종 류에는 특별한 제한이 없으며, 압축 해제 수행 속도와 randomness에 따라 다양한 방식이 이용될 수 있다. 가령, turbo code에서 쓰이는 방식이 이용될 수도 있으며, 인터리빙 방식 및 디인터리빙 방식이 서로 대응된다면 특별 한 제한은 없다. 한편, 제2 매트릭스는 원본 매트릭스를 열의 개수 및 행의 개수가 동일한 복수의 매트릭스로 분할하고, 분할된 복수의 매트릭스 중 하나를 양자화하여 획득된 매트릭스일 수도 있다. 원본 매트릭스를 복수의 매트릭스로 분할하는 이점은 예를 들어, m × n의 원본 매트릭스에서 m 또는 n 중 하나 가 다른 하나보다 현저히 큰 경우에 있을 수 있다. 가령, 100 × 25의 원본 매트릭스를 100 × r의 매트릭스 및 r × 25의 매트릭스로 압축하는 경우, 일반적으로 r은 25보다 작은 수가 선택되며 압축률이 저하될 수 있다. 이 경우, 100 × 25의 원본 매트릭스를 25 × 25의 4개의 매트릭스로 구분하고, 각각을 압축하는 경우 압축률이 개 선될 수 있다. 또한, 원본 매트릭스를 복수의 매트릭스로 분할하는 경우 압축 과정에서 계산량도 줄일 수 있다. 즉, skewed 형태의 매트릭스를 squared 형태의 매트릭스로 분할한 후, 압축을 수행하는 것이 효율적일 수 있다. 한편, 메모리는 인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 제3 매트릭스를 더 저장할 수 있다. 예를 들어, 메모리는 압축 장치로부터 수신된 제3 매트릭스를 더 저장할 수 있다. 압축 해제 장치는 인코딩 매트릭스에 기초하여 제3 매트릭스릐각 입압축 방법과 관련된 복수의 타 논리 회 로를 포함하며, 제3 매트릭스가 입력되면, 복수의 타 논리 회로를 통해 타 압축 데이터의 압축을 해제하고, 압 축 해제된 타 데이터를 출력하는 타 디코더를 더 포함할 수도 있다. 여기서, 제3 매트릭스는 제4 매트릭스가 인 코딩 매트릭스에 기초하여 압축된 매트릭스일 수 있다. 그리고, 복수의 타 논리 회로는 복수의 타 XOR 게이트일 수 있다. 다만, 이에 한정되는 것은 아니며, 복수의 타 XOR 게이트는 인코딩 매트릭스와는 다른 타 인코딩 매트릭스에 기 초하여 각 입출력 단자가 연결될 수도 있다. 이 경우, 복수의 타 XOR 게이트에 입력되는 바이너리 데이터의 개 수와 출력되는 바이너리 데이터의 개수는 각각 제1 개수 및 제2 개수가 아닐 수도 있다. 그리고, 제3 매트릭스 는 제4 매트릭스가 타 인코딩 매트릭스에 기초하여 압축된 매트릭스일 수 있다. 프로세서는 타 디코더로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 제4 매트릭스를 획득하며, 제2 매트릭스 및 제4 매트릭스를 결합하여 각 엘리먼트가 복수의 바이너리 데이터를 포함하는 매트릭스를 획득 할 수 있다. 즉, 압축 해제 장치는 복수의 디코더를 포함할 수도 있다. 이는 원본 매트릭스에 포함된 각 엘리먼트가 복 수의 바이너리 데이터를 포함할 수 있기 때문이다. 가령, 압축 장치는 원본 매트릭스를 각 엘리먼트가 하나인 복수의 매트릭스로 분할할 수 있으며, 복수의 매트릭스 각각에 대한 양자화 및 압축을 수행할 수 있다. 가령, 원본 매트릭스의 각 엘리먼트가 두 개의 바이너리 데이터를 포함하는 경우, 압축 장치는 원본 매트릭스를 각 엘 리먼트가 하나의 바이너리 데이터를 포함하는 두 개의 매트릭스로 분할하고, 두 개의 매트릭스 각각을 양자화 및 압축하여 상술한 제1 매트릭스 및 제3 매트릭스를 획득할 수 있다. 그리고, 압축 장치는 제1 매트릭스 및 제 3 매트릭스를 압축 해제 장치로 제공할 수 있다. 압축 해제 장치는 디코더 및 타 디코더를 이용 하여 각각 제1 매트릭스 및 제3 매트릭스를 병렬 처리하고, 프로세서는 제2 매트릭스 및 제4 매트릭스를 병합하여 각 엘리먼트가 복수의 바이너리 데이터를 포함하는 매트릭스를 획득할 수 있다. 한편, 이상에서는 디코더가 메모리 및 프로세서의 사이에 배치된 것으로 설명하였다. 이 경우, 프로세서 내부에 구비된 내부 메모리는 압축이 해제된 데이터를 저장하기 때문에 용량이 큰 메모리가 필요 하고, 전력 소모가 상당할 수 있다. 다만, 프로세서 내부의 연산 소자 유닛에서 계산이 이루어지는 동안 압축을 해제할 수 있어 기존 하드웨어에 오버헤드를 주지 않고, 연산 소자 유닛의 연산 수행 시간에 대한 영향 력이 더 작아질 수 있다. 또한, 메모리와 프로세서 사이에 디코더가 배치될 수 있어 기존 accelerator 설계의 내용을 고치지 않고 마치 memory wrapper 형태로 설계가 가능할 수 있다. 이러한 구성은 압 축이 해제된 전체 데이터를 반복하여 이용하는 CNN(Convolutional Neural Network)에 좀더 적합할 수 있다. 다만, 이에 한정되는 것은 아니며, 압축 해제 장치는 하나의 칩으로 구현될 수도 있다. 이 경우, 메모리 는 칩 외부의 외부 메모리로부터 압축된 일부 데이터만을 수신하고, 압축된 일부 데이터만을 저장할 수 있 다. 그리고, 메모리는 연산 소자 유닛이 데이터를 요구할 때마다 on-the-fly로 압축을 해제하기 때문에 용량이 작은 메모리를 이용할 수 있고, 전력 소모도 감소할 수 있다. 다만, 메모리가 압축된 일부 데이터만 을 저장하기 때문에 연산 소자 유닛이 데이터를 요구할 때마다 압축 해제 및 디인터리빙이 수행되어 레이턴시가 증가하고, 장기적으로 전력 소모가 증가할 수도 있다. 또한, 기존 accelerator의 내부에 디코더가 추가되 어, 기존 설계를 많이 수정해야할 수도 있다. 이러한 구성은 압축된 일부 데이터를 일회적으로 이용하는 RNN(Recurrent neural network)에 좀더 적합할 수 있다. 압축 해제 장치는 이상과 같은 방법을 통해 압축을 해제하여 복원 매트릭스를 획득하고, 획득된 복원 매트 릭스를 이용하여 신경망 연산을 수행할 수 있다. 도 2는 본 개시의 일 실시 예에 따른 전자 시스템을 설명하기 위한 도면이다. 전자 시스템은 압축 장치 및 압축 해제 장치를 포함한다. 먼저, 압축 장치는 인공 지능 모델을 압축하는 장치일 수 있다. 예를 들어, 압축 장치는 인공 지능 모 델에 포함된 적어도 하나의 원본 매트릭스를 압축하는 장치로서, 서버, 데스크탑 PC, 노트북, 스마트폰, 태블릿 PC, TV, 웨어러블 기기 등과 같은 장치일 수 있다. 다만, 이는 일 실시 예에 불과하며, 압축 장치는 인공 지능 모델을 압축하여 인공 지능 모델의 데이터 크기 를 줄일 수 있는 장치라면 어떠한 장치라도 무방하다. 여기서, 원본 매트릭스는 웨이트 매트릭스일 수 있다. 압축 장치는 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 대표 값 매트릭스 및 제2 매트릭스를 획 득할 수 있다. 상술한 바와 같이, 양자화 방법에는 특별한 제한이 없다. 압축 장치는 인코딩 매트릭스에 기초하여 제2 매트릭스를 제1 매트릭스로 압축할 수 있다. 또는, 압축 장치 는 인코딩 매트릭스 및 원본 매트릭스에 포함된 복수의 엘리먼트의 프루닝 여부에 기초하여 제2 매트릭스를 제1 매트릭스로 압축할 수도 있다. 특히, 압축 장치가 프루닝 여부를 더 고려함에 따라 제2 매트릭스의 압 축률이 향상될 수 있다. 압축 장치는 제2 매트릭스로부터 제1 매트릭스만을 획득할 수 있다. 또는, 압축 장치는 제2 매트릭스로 부터 제1 매트릭스 및 패치 정보를 획득할 수도 있다. 특히, 압축 장치가 패치 정보를 더 이용함에 따라 제 2 매트릭스의 압축률이 향상될 수 있다. 다만, 패치 정보의 크기가 증가할수록 압축률이 감소할 수도 있다. 한편, 압축 장치는 인공 지능 모델에 포함된 원본 매트릭스를 프루닝하여 원본 매트릭스에 포함된 각 엘리 먼트의 프루닝 여부를 나타내는 프루닝 인덱스 매트릭스를 획득할 수 있다. 압축 장치는 프루닝 인덱스 매 트릭스를 압축 해제 장치로 제공할 수 있다. 또는, 압축 장치는 인공 지능 모델에 포함된 원본 매트릭스를 프루닝하여 원본 매트릭스에 포함된 각 엘리 먼트의 프루닝 여부를 나타내는 프루닝 인덱스 매트릭스를 획득하고, 상술한 방법을 이용하여 프루닝 인덱스 매 트릭스를 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스로 압축할 수도 있다. 압축 장치는 제 1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 압축 해제 장치로 제공할 수 있다. 압축 해제 장치는 압축 장치로부터 압축된 인공 지능 모델을 수신하고, 압축을 해제하여 신경망 연산 을 수행할 수 있다. 다만, 이에 한정되는 것은 아니며, 전자 시스템은 하나의 전자 장치로 구현될 수도 있다. 가령, 전자 장 치는 압축 장치와 동일한 방법으로 인공 지능 모델을 압축하고, 신경망 연산을 수행하는 경우에 압축 해제 장치와 동일한 방법으로 압축을 해제할 수도 있다. 이하에서는 설명의 편의를 위하여 압축 장치와 압축 해제 장치가 구분된 것으로 설명한다. 그리고, 압 축 장치의 압축 동작을 먼저 설명하고, 압축 해제 장치의 동작을 도면을 통해 좀더 구체적으로 설명하 도록 한다. 도 3a 내지 도 3d는 본 개시의 이해를 돕기 위한 제1 매트릭스, 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인 덱스 매트릭스의 획득 방법을 간략히 설명하기 위한 도면들이다. 도 3a는 인공 지능 모델에 포함된 원본 매트릭스의 일 예를 나타내는 도면으로, 원본 매트릭스는 m × n의 형태 일 수 있다. 예를 들어, 원본 매트릭스는 10000 × 8000의 형태일 수 있다. 그리고, 원본 매트릭스 내의 복수의 엘리먼트는 각각 32 비트일 수 있다. 즉, 원본 매트릭스는 32 비트인 엘리먼트를 10000 × 8000개 포함할 수 있 다. 다만, 이에 한정되는 것은 아니며, 원본 매트릭스의 크기 및 각 엘리먼트의 비트수는 얼마든지 다를 수도 있다.도 3b는 도 3a에 도시된 원본 매트릭스를 프루닝 및 양자화한 결과를 나타내는 도면이다. 압축 장치는 제1 임계 값에 기초하여 원본 매트릭스에 포함된 복수의 엘리먼트 각각을 프루닝하고, 복수의 엘리먼트 각각의 프루닝 여부를 바이너리 데이터로 나타내는 프루닝 인덱스 매트릭스를 획득할 수 있다. 예를 들어, 압축 장치는 원본 매트릭스에 포함된 복수의 엘리먼트 중 30보다 작은 엘리먼트를 0으로 변환하 고, 나머지 엘리먼트를 그대로 유지하는 방식으로 원본 매트릭스를 프루닝할 수 있다. 그리고, 압축 장치는 복수의 엘리먼트 중 0으로 변환된 엘리먼트는 0으로, 나머지 엘리먼트는 1로 변환하여 프루닝 인덱스 매트릭스 를 획득할 수 있다. 즉, 프루닝 인덱스 매트릭스는 원본 매트릭스와 크기가 동일하며, 0 또는 1을 포 함할 수 있다. 그리고, 압축 장치는 원본 매트릭스에 포함된 복수의 엘리먼트 중 프루닝되지 않는 엘리먼트들을 양자화하 여 대표 값 매트릭스와 바이너리 양자화된 데이터를 포함하는 제2 매트릭스를 획득할 수 있다. 압축 장치는 도 3a의 원본 매트릭스에서 n 개의 엘리먼트를 하나의 대표 값을 이용하여 양자화할 수 있다. 그에 따라, 도 3b에서는 m 개의 엘리먼트를 포함하는 대표 값 매트릭스를 도시하였다. 여기서, 하나의 대 표 값으로 양자화되는 엘리먼트의 개수 n은 일 실시 예에 불과하며, 얼마든지 다른 값이 이용될 수도 있으며, 다른 값이 이용되면 대표 값 매트릭스에 포함된 엘리먼트의 개수도 달라질 수 있다. 그리고, 압축 장치 는 바이너리 양자화된 데이터를 포함하는 제2 매트릭스를 획득할 수 있으며, 제2 매트릭스는 원 본 매트릭스와 크기가 동일하며, 0 또는 1을 포함할 수 있다. 압축 장치는 도 3c에 도시된 바와 같이, 인코딩 매트릭스에 기초하여 제2 매트릭스를 제1 매트릭스 로 압축할 수 있다. 제1 매트릭스에 포함된 엘리먼트의 개수는 제2 매트릭스에 포함된 엘리먼트의 개수보다 적다. 제1 매트릭스의 획득 방법에 대하여는 도 4에서 후술한다. 압축 장치는 도 3d에 도시된 바와 같이, 프루닝 인덱스 매트릭스를 제1 프루닝 인덱스 매트릭스(20-1) 및 제2 프루닝 인덱스 매트릭스(20-2)로 압축할 수 있다. 구체적으로, 압축 장치는 원본 매트릭스를 제1 서 브 매트릭스 및 제2 서브 매트릭스로 팩토라이즈하고, 제1 서브 매트릭스 및 제2 서브 매트릭스 각각을 프루닝 하여 제1 프루닝 인덱스 매트릭스(20-1) 및 제2 프루닝 인덱스 매트릭스(20-2)를 획득할 수 있다. 그리고, 압축 장치는 제1 프루닝 인덱스 매트릭스(20-1) 및 제2 프루닝 인덱스 매트릭스(20-2)의 매트릭스 곱셈 결과를 이용한 신경망 연산 결과가 프루닝 인덱스 매트릭스를 이용한 신경망 연산 결과에 근접하도록 제1 프루닝 인덱스 매트릭스(20-1) 및 제2 프루닝 인덱스 매트릭스(20-2)를 업데이트할 수 있다. 가령, 제1 프루닝 인덱스 매트릭스(20-1) 및 제2 프루닝 인덱스 매트릭스(20-2)의 매트릭스 곱셈 결과를 이용한 신경망 연산 결과의 정확 도가 낮아지면, 제1 서브 매트릭스 및 제2 서브 매트릭스 각각을 프루닝할 때 이용하는 프루닝 레이트를 낮추어 정확도를 향상시킬 수 있다. 이때, 제1 프루닝 인덱스 매트릭스(20-1) 및 제2 프루닝 인덱스 매트릭스(20-2)를 획득하기 위한 프루닝 레이트는 서로 다를 수 있다. 압축 장치는 이러한 과정을 반복하여 제1 프루닝 인덱 스 매트릭스(20-1) 및 제2 프루닝 인덱스 매트릭스(20-2)의 매트릭스 곱셈 결과를 이용한 신경망 연산 결과의 정확도를 향상시킬 수 있다. 도 3a 내지 도 3d에서는 압축 장치가 프루닝 및 양자화를 모두 수행하는 것으로 설명하였으나, 이에 한정되 는 것은 아니다. 예를 들어, 압축 장치는 프루닝을 수행하지 않고, 양자화를 수행할 수도 있다. 도 4는 본 개시의 이해를 돕기 위한 제1 매트릭스를 획득하는 방법을 설명하기 위한 도면이다. 도 4는 인코딩 매트릭스(A)를 이용하여 제2 매트릭스에 포함된 기설정된 개수의 엘리먼트(B)를 x로 압축하는 방 법을 도시하였다. x는 제1 매트릭스에 포함될 수 있다. 예를 들어, 제2 매트릭스에 포함된 9개의 바이너리 데이 터는 5개의 바이너리 데이터로 압축될 수 있다. 이때, 9개의 바이너리 데이터 중 프루닝된 데이터는 -로서 표시 되며, 압축 이후 복원될 필요가 없다. 즉, 도 4의 매트릭스 곱셈에 따라 9개의 방정식이 만들어질 수 있으나, - 를 포함하는 방정식은 고려할 필요가 없다. 그에 따라, 제2 매트릭스에 포함된 9개의 바이너리 데이터가 5개의 바이너리 데이터로 압축될 수 있다. 즉, 제1 매트릭스에 포함된 제1 개수 단위의 바이너리 데이터(x)와 인코딩 매트릭스(A)의 매트릭스 곱셈 결과는 제2 매트릭스에 포함된 제2 개수 단위의 대응되는 바이너리 데이터(B)와 동일할 수 있다. 여기서, 제2 개수는 제1 개수보다 크다. 압축 과정에서 제2 매트릭스에 포함된 제2 개수 단위의 바이너리 데이터는 제2 개수보다 작 은 제1 개수 단위의 바이너리 데이터로 변환되며, 변환된 바이너리 데이터들이 제1 매트릭스를 형성할 수 있다. 매트릭스 곱셈 과정에서, 각 바이너리 데이터 간의 곱셈 연산은 AND 게이트와 동일한 방식으로 수행되고, 곱셈연산 결과 간의 덧셈 연산은 XOR 게이트와 동일한 방식으로 수행될 수 있으며, AND 게이트는 XOR 게이트보다 계 산의 우선 순위가 높다. 여기서, 인코딩 매트릭스는 제1 타입의 엘리먼트 및 제2 타입의 엘리먼트를 포함하며, 인코딩 메트릭스에 포함 된 제1 타입의 엘리먼트의 개수 및 인코딩 매트릭스에 포함된 제2 타입의 엘리먼트의 개수는 서로 동일할 수 있 다. 예를 들어, 인코딩 매트릭스는 0 및 1을 포함하며, 0의 개수와 1의 개수는 동일할 수 있다. 다만, 이에 한 정되는 것은 아니며, 인코딩 매트릭스에 포함된 엘리먼트의 개수가 홀수인 경우, 0의 개수와 1의 개수 간의 차 이는 기설정된 개수(ex : 1개) 이내일 수도 있다. 한편, 도 4에 도시된 바와 같이, 프루닝된 데이터가 3개(-가 3개)인 경우, 5개의 바이너리 데이터로 나머지 6개 의 방정식을 만족하지 못할 수 있다. 따라서, 압축 장치는 5개의 바이너리 데이터로 성립하지 않는 방정식 의 개수 정보 및 마지막 방정식의 위치 정보를 패치 정보로 획득할 수 있다. 도 4의 10110은 압축된 5개의 바이너리 데이터를 나타내고, 01은 성립하지 않는 방정식의 개수 정보를 나타내며, 0110은 마지막 방정식 의 위치 정보일 수 있다. 여기서, 마지막 방정식의 위치 정보는 프루닝되지 않은 데이터를 기준으로 여섯 번째 임을 나타내는 것으로 설명하였으나, 이에 한정되는 것은 아니다. 예를 들어, 마지막 방정식의 위치 정보는 프루닝 여부와 무관하게 9개의 데이터를 기준으로 아홉 번째 임을 나타내도록 획득될 수도 있다. 한편, 매트릭스 곱셈 과정에서, 각 바이너리 데이터 간의 곱셈 연산은 AND 게이트와 동일한 방식으로 수행되고, 곱셈 연산 결과 간의 덧셈 연산은 XOR 게이트와 동일한 방식으로 수행될 수 있으며, AND 게이트는 XOR 게이트보 다 계산의 우선 순위가 높다. 설명의 편의를 위해, 도 4에서 도출된 x의 값인 10110을 이용하여 매트릭스 곱셈을 설명한다. A의 첫 번째 행과 x의 값인 10110의 매트릭스 곱셈은 프루닝에 따라 불필요한 데이터이므로 생략한다. A의 두 번째 행인 10010과 x의 값인 10110의 매트릭스 곱셈은 먼저, 각 자릿수 별로 AND 게이트와 동일한 방식으로 바이너리 데이터 간의 곱셈 연산이 수행된다. 즉, 1×1=1, 0×0=0, 0×1=0, 1×1=1, 0×0=0의 연산을 통해 1, 0, 0, 1, 0이 획득된다. 이후, 1, 0, 0, 1, 0이 XOR 게이트와 동일한 방식으로 덧셈 연산이 수행되어 최종적으로 0이 획득된 다. 구체적으로, 첫 번째 및 두 번째 바이너리 데이터 1, 0의 덧셈 연산으로 1이 획득되고, 연산 결과 1과 세 번째 바이너리 데이터 0의 덧셈 연산으로 1이 획득되며, 누적 연산 과 1과 네 번째 바이너리 데이터 1의 덧셈 연산으로 0이 획득되며, 누적 연산 결과 0과 다섯 번째 바이너리 데이터 0의 덧셈 연산으로 최종적으로 0이 획 득될 수 있다. 여기서, 연산 순서는 얼마든지 변경될 수 있으며, 연산 순서가 변경되더라도 최종 획득되는 값은 동일하다. 이러한 방식으로 A의 나머지 행과 10010 간의 매트릭스 곱셈이 수행될 수 있다. 다만, 상술한 바와 같이, 성립하지 않는 방정식(A의 마지막 행)이 있을 수 있으며, 이에 대한 연산 결과는 다음과 같다. A의 마지막 행인 00011과 x의 값인 10110의 매트릭스 곱셈은 먼저, 각 자릿수 별로 AND 게이트와 동일한 방식으로 바이너리 데이터 간의 곱셈 연산이 수행된다. 즉, 0×1=0, 0×0=0, 0×1=0, 1×1=1, 0×0=0의 연산을 통해 0, 0, 0, 1, 0이 획득된다. 이후, 0, 0, 0, 1, 0이 XOR 게이트와 동일한 방식으로 덧셈 연산이 수 행되어 최종적으로 1이 획득된다. 구체적으로, 첫 번째 및 두 번째 바이너리 데이터 0, 0의 덧셈 연산으로 0이 획득되고, 연산 결과 0과 세 번째 바이너리 데이터 0의 덧셈 연산으로 0이 획득되며, 누적 연산 결과 0과 네 번 째 바이너리 데이터 1의 덧셈 연산으로 1이 획득되며, 누적 연산 결과 1과 다섯 번째 바이너리 데이터 0의 덧셈 연산으로 최종적으로 1이 획득될 수 있다. 이는 최초의 B의 마지막 행의 값인 0과 일치하지 않으며, 압축 장치 는 이를 패치 정보로서 압축 해제 장치로 제공하며, 압축 해제 장치는 패치 정보에 기초하여 이 를 보완할 수 있다. 즉, 압축 해제 장치는 패치 정보에 기초하여 방정식이 성립하지 않는 행의 위치 정보 를 획득하고, 인코딩 매트릭스(A)와 x의 매트릭스 곱셈 결과 중 위치 정보에 대응되는 행의 바이너리 데이터를 다른 바이너리 데이터로 변환할 수 있다. 도 4의 예에서는 압축 해제 장치는 패치 정보에 기초하여 인코딩 매트릭스(A)와 x의 매트릭스 곱셈 결과 중 마지막 행의 값을 1에서 0으로 변환할 수 있다. 이상과 같이 압축 장치는 원본 매트릭스로부터 제1 매트릭스, 제1 프루닝 인덱스 매트릭스, 제2 프루닝 인 덱스 매트릭스 및 패치 정보를 획득할 수 있다. 다만, 이에 한정되는 것은 아니며, 압축 장치는 패치 정보를 이용하지 않는 방법으로 제2 매트릭스를 제1 매트릭스로 압축할 수도 있다. 가령, 도 4의 예에 따르면, 압축 장치는 x를 6개의 비트로 결정하여 패치 정 보의 생성을 방지할 수도 있다. 또는, 압축 장치는 프루닝을 수행하지 않고, 제2 매트릭스를 제1 매트릭스로 압축할 수도 있다. 가령, 도 4 의 예에서, 압축 장치는 9개의 방정식 간의 dependency에 기초하여 x의 비트의 개수를 결정할 수도 있다.즉, 압축 장치는 9개의 방정식 간의 dependency가 없다면, 9개의 비트를 포함하는 x를 획득하게 되고, 이 경우 압축이 이루어지지 않을 수도 있다. 또는, 압축 장치는 9개의 방정식 간의 dependency가 있다면, 9보 다 작은 수의 비트를 포함하는 x를 획득하게 되고, 이 경우 압축이 이루어질 수 있다. 도 5a 및 도 5b는 본 개시의 확장 실시 예에 따른 압축 해제 장치를 설명하기 위한 도면들이다. 먼저, 도 5a에 도시된 바와 같이, 압축 해제 장치는 복수의 디코더(D-Unit)를 포함할 수 있다. 압축 해제 장치는 외부 메모리, 복수의 디인터리버 및 프로세서(530-1)를 더 포함할 수 있다. 여기서, 외 부 메모리 및 프로세서(530-1)은 각각 도 1의 메모리 및 프로세서와 동일할 수 있다. 외부 메모리는 압축 장치로부터 제공된 복수의 제1 매트릭스를 저장할 수 있다. 여기서, 복수의 제1 매트릭스는 원본 매트릭스가 양자화 및 압축된 매트릭스일 수 있다. 이는 실제로 원본 매트릭스의 데이터가 매 우 크기 때문이며, 예를 들어 압축 장치는 도 6에 도시된 바와 같이, 원본 매트릭스를 복수의 매트릭스로 분할하고, 복수의 매트릭스 각각을 양자화 및 압축하여 복수의 제1 매트릭스를 획득할 수 있다. 압축 장치 는 복수의 제1 매트릭스를 외부 메모리로 제공할 수 있다. 복수의 디코더(D-Unit) 각각은 외부 메모리로부터 복수의 제1 매트릭스 중 하나를 입력받아 압축이 해제된 제2 매트릭스를 출력할 수 있다. 즉, 외부 메모리는 복수의 제1 매트릭스를 각각 복수의 디코더로 제공하 여 병렬적으로 압축을 해제할 수 있으며, parallelism이 향상될 수 있다. 다만, 이에 한정되는 것은 아니며, 압축 해제 장치는 도 6의 좌측 상단의 매트릭스가 압축된 데이터를 압 축 해제하고, 도 6의 좌측 상단에서 우측으로 인접한 매트릭스가 압축된 데이터를 압축 해제하는 방식과 같이, 순차적으로 압축된 데이터를 압축 해제할 수도 있다. 복수의 디코더 각각은 프로세서(530-1)의 내부 메모리(On-Chip Memory)로 압축이 해제된 제2 매트릭스를 전송할 수 있다. 이때, 복수의 디코더 각각은 디인터리버를 거쳐 제2 매트릭스를 전송할 수도 있다. 디인터리버의 동작을 설명하기 위해 먼저, 압축 장치의 인터리빙 동작을 설명한다. 압축 장치는 도 6과 같이 분할된 복수의 매트릭스 각각을 인터리빙할 수 있다. 압축 장치는 인터리빙된 복수의 매트릭스 각각을 양자화 및 압축할 수 있다. 디인터리버는 압축 장치의 인터리빙 동작에 대응될 수 있다. 즉, 디인터리버는 인터리빙된 매트 릭스를 디인터리빙하여 인터리빙되기 전의 매트릭스로 복원할 수 있다. 도 5a는 압축 해제 장치가 복수의 디인터리버를 포함하는 것으로 도시하였으나, 이에 한정되는 것은 아니다. 예를 들어, 압축 장치는 원본 매트릭스가 분할된 복수의 매트릭스 각각을 인터리빙하지 않고, 원본 매트릭스 자체를 인터리빙할 수도 있다. 이 경우, 압축 해제 장치는 하나의 디인터리버를 포함할 수도 있 다. 한편, 메모리는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스 및 패치 정보를 더 저장할 수 도 있다. 이 경우, 프로세서(530-1)는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스로부터 프루 닝 인덱스 매트릭스를 획득하고, 프루닝 인덱스 매트릭스 및 패치 정보에 기초하여 제2 매트릭스를 업데이트할 수도 있다. 한편, 도 5b에 도시된 바와 같이, 압축 해제 장치는 하나의 칩으로 구현될 수도 있다. 즉, 도 5b에서 압축 해제 장치는 프로세서(530-2)로서 도시되었으며, 프로세서(530-2)는 외부 메모리로부터 복수의 제1 매트릭스를 수신할 수 있다. 프로세서(530-2) 내부의 복수의 디코더 각각은 복수의 제1 매트릭스의 압축을 해제하여 프로세서(530-2)에 포함 된 연산 소자 유닛(PE Array)으로 복수의 제2 매트릭스를 전송할 수 있다. 이상과 같이 압축 과정에서 원본 매트릭스의 분할 및 인터리빙으로 인해 압축률 및 정확도가 향상되고, 복수의 디코더를 통해 병렬적으로 압축 해제를 수행할 수 있어 압축 해제를 효율적으로 수행할 수 있다. 도 7a 내지 도 7c는 본 개시의 일 실시 예에 따른 제1 매트릭스의 압축 해제 방법을 설명하기 위한 도면들이다. 도 7a는 9 × 5의 인코딩 매트릭스의 일 예를 나타내며, 압축 과정에서 9개 단위의 바이너리 데이터가 5개 단위 의 바이너리 데이터로 변환되었음을 나타낸다. 디코더는 도 7b에 도시된 바와 같이, 인코딩 매트릭스에 기초하여 각 입출력 단자가 연결된 복수의 XOR 게 이트로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 복수의 XOR 게이트가 아닌 다른 논리 회로를 이용하 여 디코더를 구현할 수도 있으며, 인코딩 매트릭스에 대응되는 동작을 수행할 수 있다면 얼마든지 다른 방 법이 이용될 수도 있다. 디코더는 제1 매트릭스에 포함된 복수의 바이너리 데이터를 제1 개수 단위로 입력받아 제2 매트릭스에 포 함될 제2 개수 단위의 복수의 바이너리 데이터를 출력할 수 있다. 즉, 디코더는 x0 부터 x4의 입력을 O1부터 O9로 출력할 수 있다. 가령, 디코더는 도 7c에 도시된 바 와 같이, 제1 매트릭스의 10110을 001111001로 변환할 수 있다. 프로세서는 패치 정보에 기초하여 001111001 중 일부 데이터의 값을 변경할 수 있다. 도 7c에서는 001111001 중 네 번째, 일곱 번째 데이터가 변경된 것으로 도시하였으며, 0은 1로, 1은 0으로 변경될 수 있다. 도 8a 및 도 8b는 본 개시의 일 실시 예에 따른 제2 매트릭스의 업데이트 동작을 설명하기 위한 도면들이다. 프로세서는 복수의 디코더 각각으로부터 각 엘리먼트가 1비트인 제2 매트릭스를 수신하고, 메모리로 부터 프루닝 인덱스 매트릭스를 수신할 수 있다. 또는, 프로세서는 메모리로부터 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스를 수신하고, 이로부터 프루닝 인덱스 매트릭스를 획득할 수도 있다. 프로세서는 도 8a에 도시된 바와 같이, 프루닝 인덱스 매트릭스에 기초하여 제2 매트릭스에서 프루닝된 엘 리먼트를 식별할 수 있다. 그리고, 프로세서는 도 8c에 도시된 바와 같이, 식별된 엘리먼트를 0으로 변환 할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 프로세서의 복수의 제2 매트릭스를 병합하는 방법을 설명하기 위한 도면이다. 도 9에서는 설명의 편의를 위해 프로세서가 두 개의 제2 매트릭스를 결합하는 것으로 설명한다. 압축 해제 장치는 복수의 디코더를 포함할 수 있으며, 복수의 디코더 각각은 제2 매트릭스를 프로세서 로 전송할 수 있다. 프로세서는 도 9에 도시된 바와 같이, 각 엘리먼트가 1비트인 제2 매트릭스 1 및 각 엘리먼트가 1비트인 제2 매트릭스 2를 결합하여 각 엘리먼트가 2비트인 결합된 제2 매트릭스를 획득할 수 있다. 프로세서는 프루닝 인덱스 매트릭스에 기초하여 각 엘리먼트가 2비트인 결합된 제2 매트릭스에서 프루닝된 엘리먼트를 0으로 변환할 수 있다. 다만, 이에 한정되는 것은 아니며, 마스킹 유닛은 3개 이상의 제2 매트릭스를 결합하여 결합된 제2 매트릭 스를 획득하고, 프루닝된 엘리먼트를 0으로 변환할 수도 있다. 도 10은 본 개시의 일 실시 예에 따른 압축 해제 장치의 제어 방법을 설명하기 위한 흐름도이다. 먼저, 압축 데이터의 압축 방법과 관련된 복수의 논리 회로가 인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 압축 데이터를 수신한다(S1010). 그리고, 복수의 논리 회로가 압축 데이터의 압축을 해제하고, 압축 해제된 데이터를 출력한다(S1020). 그리고, 복수의 논리 회로로부터 출력되는 데이터로부터 신경망 연산 가능한 형태의 데이터를 획득한다(S1030). 여기서, 압축 해제된 데이터, 및 압축 데이터에 대응되는 대표 값 매트릭스에 기초하여 신경망 연산 가능한 형 태의 데이터를 획득하는 단계 및 신경망 연산 가능한 형태의 데이터를 이용하여 신경망 연산을 수행하는 단계를 더 포함하며, 압축 해제된 데이터 및 대표 값 매트릭스는 인공 지능 모델에 포함된 원본 매트릭스를 양자화하여 획득된 매트릭스들일 수 있다. 그리고, 압축 데이터에 대응되는 프루닝 인덱스 매트릭스에 기초하여 압축 해제된 데이터를 업데이트하는 단계 를 더 포함하며, 프루닝 인덱스 매트릭스는 원본 매트릭스의 프루닝(pruning) 과정에서 획득된 매트릭스이고, 압축 데이터를 획득하는 과정에서 이용될 수 있다. 여기서, 압축 데이터에 대응되는 패치 정보에 기초하여 압축 해제된 데이터에 포함된 복수의 엘리먼트 중 일부 의 바이너리 데이터 값을 변경하는 단계를 더 포함하며, 패치 정보는 압축 데이터를 획득하는 과정에서 발생하 는 에러 정보를 포함할 수 있다. 한편, 압축 데이터에 대응되는 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스에 기초하여 프루닝 인덱스 매트릭스를 획득하는 단계 및 프루닝 인덱스 매트릭스에 기초하여 압축 해제된 데이터를 업데이트하는 단계를 더 포함하며, 프루닝 인덱스 매트릭스는 원본 매트릭스의 프루닝 과정에서 획득된 매트릭스이고, 압축데이터를 획득하는 과정에서 이용되며, 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인덱스 매트릭스는 원본 매 트릭스가 팩토라이즈(factorize)되어 획득된 제1 서브 매트릭스 및 제2 서브 매트릭스 각각에 기초하여 획득될 수 있다. 또한, 압축 해제된 데이터는 원본 매트릭스를 인터리빙(Interleaving)한 후, 인터리빙된 매트릭스를 양자화하여 획득된 매트릭스이고, 제어 방법은 신경망 연산 가능한 형태의 데이터를 인터리빙에 대응되는 방식에 따라 디인 터리빙하는 단계를 더 포함하며, 신경망 연산을 수행하는 단계는 디인터리빙된 데이터를 이용하여 신경망 연산 을 수행할 수 있다. 한편, 신경망 연산을 수행하는 단계(S1010)는 매트릭스 형태로 배열된 복수의 연산 소자(Processing Element)를 이용하여 신경망 연산을 수행할 수 있다. 또한, 압축 해제된 데이터는 원본 매트릭스를 열의 개수 및 행의 개수가 동일한 복수의 매트릭스로 분할하고, 분할된 복수의 매트릭스 중 하나를 양자화하여 획득된 매트릭스일 수 있다. 한편, 압축 해제 장치는 타 압축 데이터의 압축 방법과 관련된 복수의 타 논리 회로를 포함하며, 제어 방법은 인공 지능 모델의 신경망 연산에서 압축 해제되어 이용되는 타 압축 데이터를 수신하는 단계, 복수의 타 논리 회로가 타 압축 데이터의 압축을 해제하고, 압축 해제된 타 데이터를 출력하는 단계, 복수의 타 논리 회로로부 터 출력되는 신경망 연산 가능한 형태의 타 데이터를 획득하는 단계 및 신경망 연산 가능한 데이터 및 신경망 연산 가능한 타 데이터를 결합하여 각 엘리먼트가 복수의 바이너리 데이터를 포함하는 매트릭스를 획득하는 단 계를 더 포함할 수 있다. 또한, 압축 해제 장치는 하나의 칩으로 구현될 수 있다. 도 11a 내지 도 11d는 본 개시의 일 실시 예에 따른 인공 지능 모델의 학습 과정을 설명하기 위한 도면들이다. 도 11a는 학습이 완료되기 전의 인공 지능 모델의 일 예를 나타내는 도면으로, 인공 지능 모델은 두 개의 원본 매트릭스 W12, W23을 포함하며, 압축 장치는 Li-1의 입력값들을 W12에 입력하여 Li의 중간값을 획득하며, Li의 중간값들을 W23에 입력하여 Li+1의 최종값을 획득할 수 있다. 다만, 도 11a는 인공 지능 모델을 매우 간략 하게 도시한 것으로, 실제로는 도 11a보다 더 많은 매트릭스를 포함할 수 있다. 도 11b는 인공 지능 모델에 포함된 원본 매트릭스의 일 예를 나타내는 도면으로, 도 3a에서의 설명과 동일하다. 다만, 도 3a의 원본 매트릭스는 학습이 완료된 상태이고, 도 11b의 원본 매트릭스는 학습이 완료되기 전일 수 있다. 도 11c는 도 11b에 도시된 원본 매트릭스를 양자화한 결과를 나타내는 도면이다. 압축 장치는 원본 매트릭스에 포함된 복수의 엘리먼트 각각을 양자화하여 대표 값 매트릭스 및 바이 너리 양자화된 데이터를 포함하는 제2 매트릭스를 획득할 수 있다. 이때, 압축 장치는 도 3b와는 달 리 프루닝을 수행하지 않을 수 있다. 다만, 이에 한정되는 것은 아니며, 압축 장치는 프루닝을 수행할 수도 있으며, 프루닝을 수행하는 방법에 대하여는 후술한다. 압축 장치는 도 11d, 좌측의 제2 매트릭스를 압축하여 도 11d, 우측의 제1 매트릭스(1110-1)를 획득 할 수 있다. 제1 매트릭스(1110-1)에 포함된 엘리먼트의 개수는 제2 매트릭스에 포함된 엘리먼트의 개수 보다 적다. 압축 장치는 도 7a와 같은 인코딩 매트릭스에 기초하여 제2 매트릭스로부터 제1 매트릭스(1110-1)를 획득할 수 있다. 이러한 동작은 모두 인공 지능 모델의 학습 과정에 포함되어 있다. 또한, 도 11b 내지 도 11d 에서는 하나의 원본 매트릭스에 대하여만 설명하였으나, 인공 지능 모델의 학습 과정에서는 인공 지능 모델에 포함된 복수의 원본 매트릭스 전체가 도 11b 내지 도 11d와 같이 압축될 수 있다. 좀더 구체적으로 예를 들면, 도 11a의 W12는 양자화되고 도 11d의 우측과 같이 제1 인코딩 매트릭스에 기초하여 압축되어 Q12’으로서 저장된 상태일 수 있다. 또한, 도 11a의 W23은 양자화되고 도 11d의 우측과 같이 제2 인 코딩 매트릭스에 기초하여 압축되어 Q23’으로서 저장된 상태일 수 있다. 압축 장치는 Q12’을 제1 인코딩 매트릭스를 통해 압축을 해제하고, 양자화를 해제하여 W12를 획득하며, Q23’을 제2 인코딩 매트릭스를 통해 압 축을 해제하고, 양자화를 해제하여 W23을 획득할 수 있다. 그리고, 압축 장치는 W12 및 W23을 이용하여 feed forward 동작을 수행할 수 있다. 이때, 제1 인코딩 매트릭스 및 제2 인코딩 매트릭스는 도 7b와 같이 XOR 게이트로 구현될 수 있다. 즉, 압축 장치는 Q12’을 제1 인코딩 매트릭스를 통해 압축을 해제하는 경우, 0또는 1로 디지털화할 수 있다. 또한, 압축 장치는 Q23’을 제2 인코딩 매트릭스를 통해 압축을 해제하는 경 우, 0 또는 1로 디지털화할 수 있다. 이후, 압축 장치는 backward 동작을 수행하여 인공 지능 모델에 포함된 엘리먼트들을 업데이트할 수 있다. 다만, XOR 게이트를 이용하는 동작은 디지털 회로에 의한 동작으로 미분이 불가능하나, 업데이트 과정에서는 미 분이 필요하다. 그에 따라, 압축 장치는 XOR 게이트를 이용하는 동작을 하기의 수학식 1과 같이 미분이 가 능한 형태로 변환하여 인공 지능 모델을 학습할 수 있다. 입력값 중 0은 -1로 변환하여 수학식 1에 입력될 수 있다. [수학식 1]"}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1은 입력값이 a, b인 경우를 나타내나, 실제로 입력값은 두 개가 아닐 수도 있다. 입력값은 인코딩 매트 릭스의 크기, 하나의 로우에 포함된 1의 개수 등에 따라 달라질 수 있다. 그에 따라, 압축 장치는 하기의 수학식 2와 같이 좀더 일반적인 수학식을 이용하여 인공 지능 모델을 학습할 수 있다. [수학식 2]"}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, X는 XOR 게이트의 입력이며, m은 학습 속도를 조절하기 위한 변수로서, 각각은 하기와 같이 나타낼 수 있다. 도 13은 m의 값에 따른 출력을 나타내는 도면으로, 기울기가 변경됨에 따라 학습 속도가 달라질 수 있다. m의 값은 사용자에 의해 설정될 수 있다."}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 압축 장치는 XOR 게이트의 동작을 아날로그화하여 인공 지능 모델의 학습에 이용할 수 있다. 즉, XOR 게이트의 입력값은 실수로서 저장된 상태이나, 압축 장치는 추론(inference) 과정에서 XOR 게이트 의 입력값 중 음수를 0으로 양수를 1로 변환하게 된다. 즉, 압축 장치는 XOR 게이트의 입력값을 디지털화하 여 XOR 게이트와 같은 디지털 회로를 이용함에 따른 오차를 연산하게 된다. 그리고, 압축 장치는 backward 과정에서 full-precision 값을 유지하며, 미분이 가능한 형태의 수학식으로 내부 변수들을 업데이트할 수 있다. 즉, 압축 장치는 압축의 해제 과정에서 XOR 게이트가 이용되더라도, 미 분이 가능한 형태의 수학식을 이용함에 따라 XOR 게이트에 따른 동작을 인공 지능 모델의 학습 과정에 포함시켜 학습을 진행할 수 있다. 한편, 인공 지능 모델의 학습 과정에서 이용되는 loss 값은 하기의 수학식 3과 같다. 압축 장치는 수학식 3 과 같은 연산을 통해 인공 지능 모델을 학습할 수 있다. [수학식 3]"}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 -1과 1 사이의 값이므로, 는 점점 0에 가까워지게 된다. 즉, XOR 게이트의 입력의 개수 및 출력 개수가 많아질수록 학습이 어려워지게 된다. 그에 따라, 압축 장치 는 수학식 3에서 자기 자신(ex : i)의 미분은 tanh의 형태를 그대로 이용하고, 나머지(ex : j ≠ i)의 미분은 tanh를 sign으로 변환하여 인공 지능 모델을 학습할 수도 있다. 이 경우, XOR 게이트의 입출력의 개수와 무관하 게 backward path를 단순화할 수 있어 학습 속도가 향상될 수 있다. 도 14a는 수학식 3을 이용한 경우를 나타내 며, 도 14b는 수학식 3의 일부 tanh를 sign으로 변환한 경우를 나타낸다. 학습이 진행될수록 도 14b와 같이 0과 1 값으로 명확하게 구별되며 학습 속도가 향상될 수 있다. 압축 장치는 이상과 같이 학습이 완료되면, 인공 지능 모델에 포함된 복수의 원본 매트릭스에 각각 대응되 는 복수의 제1 매트릭스를 획득할 수 있다. 압축 장치는 이상과 같이 XOR 게이트의 동작을 인공 지능 모델에 포함시킨 상태로 학습을 수행할 수 있으며, 그에 따라 인공 지능 모델의 정확도를 유지하면서도 높은 수준의 압축률을 확보할 수 있다. 또한, 프루 닝 과정이 생략되고 패치 정보를 이용할 필요가 없어 연산 속도가 향상될 수 있다. 그리고, 도 1 내지 도 10의 경우, 일반적으로 프루닝 결과를 확인한 후, 인코딩 매트릭스의 크기가 결정될 수 있다. 반면에 XOR 게이트의 동작을 인공 지능 모델에 포함시킨 상태로 학습하는 경우, 임의로 인코딩 매트릭스 의 크기를 지정하여 프루닝이 없이도 fractional한 quantization bit 값을 설정할 수도 있다. 가령, 정수의 수 가 아닌 0.7 bit quantization도 가능할 수 있다. 한편, 압축 장치는 인공 지능 모델에 포함된 복수의 원본 매트릭스에 각각 대응되는 복수의 인코딩 매트릭 스를 이용할 수 있다. 가령, 압축 장치는 인공 지능 모델의 첫 번째 원본 매트릭스 및 마지막 원본 매트릭 스에는 상대적으로 낮은 압축률의 압축을 수행하기 위한 인코딩 매트릭스를 이용하고, 인공 지능 모델의 나머지 원본 매트릭스에는 상대적으로 높은 압축률의 압축을 수행하기 위한 인코딩 매트릭스를 이용할 수 있다. 이상과 같은 방법으로 압축이 이루어진 경우에도, 압축 해제 장치는 도 1과 같이 동작하여 압축을 해제할 수 있으며, 중복되는 설명이므로 생략한다. 도 12는 본 개시의 일 실시 예에 따른 학습 과정에서 프루닝을 수행하는 방법을 설명하기 위한 도면이다. 도 11a 내지 도 11d에서는 프루닝을 생략하고, XOR 게이트를 이용한 양자화를 인공 지능 모델에 포함시킨 학습 방 법을 설명하였으나, 압축 장치는 프루닝 및 XOR 게이트를 이용한 양자화를 인공 지능 모델에 포함시켜 인공 지능 모델을 학습할 수도 있다. 압축 장치는 엘리먼트(weight) 하나마다 XOR 게이트 2개를 이용하여 프루닝을 반영할 수 있다. 예를 들어, 압축 장치는 XOR 게이트 2개의 출력 (w, m)으로부터 최종 출력을 획득할 수 있다. w는 도 11a 내지 도 11d 에서 설명한 XOR 게이트의 출력이고, m은 프루닝을 반영하기 위한 값일 수 있다. 가령, 압축 장치는 (0, 0)이면 -1을 출력하고, (0, 1) 또는 (1, 0)이면 0을 출력하며, (1, 1)이면 +1을 출력할 수 있다. 압축 장치는 (w + m) / 2와 같은 수식을 통해 w, m으로부터 3가지의 값을 출력할 수 있으며, 이를 위해 입 력값이 0이면 -1로 변환하고, 1이면 +1로 변환하여 수식에 입력하게 된다. 압축 장치는 도 11a 내지 도 11d에서 설명한 방법으로 w의 학습을 수행하게 되며, 중복되는 설명은 생략한 다. 압축 장치는 w의 값이 임계 값 이하이면, w의 값과 반대 부호의 값으로 m을 설정하여 w를 최종적으로 0으로 변환하여 출력할 수 있다. 또는, 압축 장치는 w의 값이 임계 값을 초과하면, w의 값과 동일한 부호의 값으 로 m을 설정하여 w를 최종적으로 +1 또는 -1로 변환하여 출력할 수 있다. 이러한 방법을 통해 임계 값 이하의 w 를 0으로 변환하게 되어 프루닝하는 효과를 획득할 수 있다. 압축 장치는 이상과 같이 학습이 완료되면, 인공 지능 모델에 포함된 복수의 원본 매트릭스에 각각 대응되 는 복수의 제1 매트릭스를 획득할 수 있다. 다만, 도 1 내지 도 10과는 달리 별도의 프루닝 인덱스 매트릭스가 생성되지 않는다. 압축 장치는 이상과 같이 프루닝 및 XOR 게이트를 이용한 양자화를 인공 지능 모델에 포함시켜 인공 지능 모델을 학습을 수행할 수 있으며, 그에 따라 학습이 좀더 수월해지고, 정확도가 향상될 수도 있다 이상과 같은 방법으로 압축이 이루어진 경우에도, 압축 해제 장치는 도 1과 같이 동작하여 압축을 해제할 수 있으며, 중복되는 설명이므로 생략한다. 도 11a 내지 도 14b의 압축 장치의 동작 또는 압축 해제 장치의 동작은 모바일 장치, 데스크탑 PC 등 과 같은 전자 장치가 수행할 수도 있다. 예를 들어, 제1 전자 장치의 메모리는 학습이 완료되기 전의 인공 지능 모델 및 학습 과정에 필요한 샘플 데이터를 저장하며, 제1 전자 장치의 프로세서는 메모리에 저장된 데이터를 도 11a 내지 도 14b와 같은 방법으로 학습하며, 동시에 압축을 수행할 수도 있다. 그리고, 제2 전자 장치의 메모리는 학습 및 압축이 완료된 인공 지능 모델을 저장하며, 제2 전자 장치의 프로세 서는 메모리에 저장된 데이터를 도 2의 양자화 획득 매트릭스 유닛과 같이 처리하여 압축을 해제할 수도 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 압축 해제 장치는 복수의 XOR 게이트로 구현된 디코더를 이용 하여 매트릭스의 압축을 해제하고, 압축이 해제된 매트릭스로부터 복원 매트릭스를 획득하여 신경망 연산을 수 행할 수 있다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치(예: 전자 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세 서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저 장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신 호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시 적으로 저장됨을 구분하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어 (hardware) 또는 이들의 조합을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있 다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨 어 모듈들로 구현될 수 있다. 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 다양한 실시 예들에 따른 기기의 프로세싱 동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있 다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었 을 때 상술한 다양한 실시 예에 따른 기기에서의 처리 동작을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구 적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등이 있을 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작 들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생 략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2019-0140720", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0140720", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 압축 해제 장치의 구성을 나타내는 블럭도이다. 도 2는 본 개시의 일 실시 예에 따른 전자 시스템을 설명하기 위한 도면이다. 도 3a 내지 도 3d는 본 개시의 이해를 돕기 위한 제1 매트릭스, 제1 프루닝 인덱스 매트릭스 및 제2 프루닝 인 덱스 매트릭스의 획득 방법을 간략히 설명하기 위한 도면들이다. 도 4는 본 개시의 이해를 돕기 위한 제1 매트릭스를 획득하는 방법을 설명하기 위한 도면이다. 도 5a 및 도 5b는 본 개시의 확장 실시 예에 따른 압축 해제 장치를 설명하기 위한 도면들이다. 도 6은 본 개시의 일 실시 예에 따른 원본 매트릭스를 설명하기 위한 도면이다. 도 7a 내지 도 7c는 본 개시의 일 실시 예에 따른 제1 매트릭스의 압축 해제 방법을 설명하기 위한 도면들이다. 도 8a 및 도 8b는 본 개시의 일 실시 예에 따른 제2 매트릭스의 업데이트 동작을 설명하기 위한 도면들이다. 도 9는 본 개시의 일 실시 예에 따른 프로세서의 복수의 제2 매트릭스를 병합하는 방법을 설명하기 위한 도면이 다. 도 10은 본 개시의 일 실시 예에 따른 압축 해제 장치의 제어 방법을 설명하기 위한 흐름도이다.도 11a 내지 도 11d는 본 개시의 일 실시 예에 따른 인공 지능 모델의 학습 과정을 설명하기 위한 도면들이다. 도 12는 본 개시의 일 실시 예에 따른 학습 과정에서 프루닝을 수행하는 방법을 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시 예에 따른 m의 값의 영향을 설명하기 위한 도면이다. 도 14a 및 도 14b는 본 개시의 일 실시 예에 따른 학습 속도 향상을 설명하기 위한 도면들이다."}
