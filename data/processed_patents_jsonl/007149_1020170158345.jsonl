{"patent_id": "10-2017-0158345", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0060285", "출원번호": "10-2017-0158345", "발명의 명칭": "인공 지능 기반의 대화 시스템 및 그 응답 제어 방법", "출원인": "서울대학교산학협력단", "발명자": "정교민"}}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 기반의 대화 시스템에서 응답 제어 방법으로서,입력 메시지가 응답이 필요한 질문인지 판단하는 대화 인식 단계;상기 대화 인식에 기반하여 상기 입력 메시지에 대한 응답을 생성하는 단계;대화 이력에 기반하여 상기 입력 메시지와 상기 생성된 응답을 인코딩한 인코딩 벡터 사이의 유사도를 평가하는단계; 및상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하는 단계를 포함하는, 방법."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 입력 메시지에 대한 응답을 생성하는 단계는,상기 입력 메시지가 질문 형태인 경우, 상기 입력 메시지에 대한 응답을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 입력 메시지가 질문 형태가 아닌 경우, 상기 응답 메시지 출력 없이 상기 입력 메시지를 대화 이력 DB에저장하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 유사도를 평가하는 단계는,상기 입력 메시지와 상기 응답 중 적어도 하나를 복수개의 chunk로 분리하는 단계;상기 대화 이력에 기반하여, 상기 입력 메시지와 상기 응답에 대해 상기 복수개의 chunk 각각에 대한 단어-레벨RNN 인코딩을 수행하는 단계;상기 단어-레벨 RNN 인코딩에 기반하여 chunk-레벨 RNN 인코딩을 수행하는 단계; 및상기 chunk-레벨 RNN 인코딩의 마지막 hidden state 벡터에 기반하여 상기 입력 메시지와 상기 응답의 유사도를산출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 유사도를 산출하는 단계는, 상기 입력 메시지와 상기 응답 중 적어도 하나에 대한 상기 chunk-레벨 RNN 인코딩의 마지막 hidden state 벡터에 토픽 정보를 추가하여 인코딩된 벡터를 산출하는 단계; 및상기 토픽 정보가 추가 인코딩된 벡터에 기반하여 상기 입력 메시지와 상기 응답의 유사도를 산출하는 단계를포함하는, 방법."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2019-0060285-3-청구항 4 또는 청구항 5에 있어서,상기 유사도를 평가하는 단계는,상기 산출된 유사도가 미리 설정된 임계치보다 큰 값을 가지는지 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하는 단계는, 상기 인코딩 벡터 사이의 유사도가 미리 설정된 임계치보다 큰 값을 가지는 경우, 상기 생성된 응답을 상기 입력 메시지에 대한 응답 메시지로 출력하고,상기 인코딩 벡터 사이의 유사도가 미리 설정된 임계치 이하인 경우, 상기 입력 메시지에 대한 응답을 다시 생성하고 유사도 평가를 반복하여, 산출된 유사도가 미리 설정된 임계치보다 큰 값을 가지는 응답을 상기 입력 메시지에 대한 응답 메시지로 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공 지능 기반의 대화 시스템으로서,입력 메시지가 응답이 필요한 질문인지 결정하는 대화 인식 모듈;상기 결정에 기반하여 상기 입력 메시지에 대한 응답을 생성하는 응답 생성 모듈; 및대화 이력에 기반하여 상기 입력 메시지와 상기 생성된 응답을 인코딩한 인코딩 벡터 사이의 유사도를평가하고, 상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하도록 제어하는 응답 평가 모듈을 포함하는, 대화 시스템."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 상기 응답 생성 모듈은,상기 입력 메시지가 질문 형태인 경우, 상기 입력 메시지에 대한 응답을 생성하는, 대화 시스템."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 8에 있어서,상기 대화 인식 모듈은,상기 입력 메시지가 질문 형태가 아닌 경우, 상기 응답 메시지 출력 없이 상기 입력 메시지를 대화 이력 DB에저장하는, 대화 시스템."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "에 있어서,상기 응답 평가 모듈은, 상기 입력 메시지와 상기 응답 중 적어도 하나에 대한 상기 chunk-레벨 RNN 인코딩의 마지막 hidden state 벡터에 토픽 정보를 추가하여 인코딩된 벡터를 산출하고,상기 토픽 정보가 추가 인코딩된 벡터에 기반하여 상기 입력 메시지와 상기 응답의 유사도를 산출하는, 대화 시스템."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 11 또는 청구항 12에 있어서,상기 응답 평가 모듈은,상기 산출된 유사도가 미리 설정된 임계치보다 큰 값을 가지는지 결정하는, 대화 시스템."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 8에 있어서,상기 응답 평가 모듈은, 상기 인코딩 벡터 사이의 유사도가 미리 설정된 임계치보다 큰 값을 가지는 경우, 상기 생성된 응답을 상기 입력 메시지에 대한 응답 메시지로 출력하고,상기 인코딩 벡터 사이의 유사도가 미리 설정된 임계치 이하인 경우, 상기 입력 메시지에 대한 응답을 다시 생성하도록 상기 응답 생성 모듈로 피드백하고, 유사도 평가를 반복하여, 산출된 유사도가 미리 설정된 임계치보다 큰 값을 가지는 응답을 상기 입력 메시지에 대한 응답 메시지로 출력하는, 대화 시스템."}
{"patent_id": "10-2017-0158345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "명령들을 저장하고 있는 저장 매체로서, 상기 명령들은 적어도 하나의 프로세서에 의하여 실행될 때에 상기 적어도 하나의 프로세서로 하여금 적어도 하나의 단계를 수행하도록 설정된 것으로서, 상기 적어도 하나의 단계는,입력 메시지가 응답이 필요한 질문인지 판단하는 대화 인식 단계;상기 대화 인식에 기반하여 상기 입력 메시지에 대한 응답을 생성하는 단계;대화 이력에 기반하여 상기 입력 메시지와 상기 생성된 응답을 인코딩한 인코딩 벡터 사이의 유사도를 평가하는단계; 및상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하는 단계를 포함하는 동작을 실행시키기 위한 프로그램을 기록한 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공 지능 기반의 대화 시스템에서 응답 제어 방법은, 입력 메시지가 응답이 필요한 질문인지 결정하는 대화 인 식 단계와, 상기 대화 인식에 기반하여 상기 입력 메시지에 대한 응답을 생성하는 단계와, 대화 이력에 기반하여 상기 입력 메시지와 상기 생성된 응답을 인코딩한 인코딩 벡터 사이의 유사도를 평가하는 단계와, 상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하 는 단계를 포함한다."}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 지능 기반의 대화 시스템 및 그의 응답 제어 방법에 관한 것으로, 더욱 상세하게는 입력 메시지 에 대해 생성된 응답 메시지 쌍의 유사도 평가 피드백에 기반하여 적절한 응답 메시지 제공을 가능하게 하기 위 한 대화 시스템 및 응답 제어 방법에 관한 것이다."}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기술의 발전에 따라, 인간이 수행하던 육체 노동의 많은 부분이 기계 장치에 의해 대체되어 왔다. 최근에는 인 공 지능 기술 발전으로 인간의 정신적인 영역으로 여겨지는 많은 분야가 인공 지능에 의해 대체될 수 있을 것으 로 예상되고 있다. 특히, 인간의 언어를 인지하고 분석하여 인간과 구별이 어려울 정도로 적절한 대답을 내어 놓는 인공 지능 대화 시스템에 대한 연구가 활발하게 진행되고 있다. 이를 위해, 머신 러닝(Machine Learning) 기법을 활용한 인공 지능 대화 시스템이 논의되고 있다. 머신 러닝이란 많은 데이터를 분류 및 패턴화하고, 계속된 입력 데이터를 통해 이러한 분류 및 패턴화를 변경/ 수정해 나가는 방법을 통해 분류의 정확도를 높여가는 기법이다. 데이터를 분류하기 위한 머신 러닝의 알고리즘 중 하나로 인간의 두뇌에서 뉴런의 동작 원리에 기초한 신경망(Neural Network) 알고리즘이 특히 주목 받고 있 다. 이러한 신경망 알고리즘을 활용하더라도, 종래의 인공 지능 대화 시스템은 질문과 동떨어진 응답 또는 평이한 응답을 생성하거나 반복적인 응답을 생성할 수 있고, 미리 학습하지 못한 질문에 대해서는 적절한 응답을 찾을 수 없는 경우가 있었다."}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 입력된 메시지에 대해 보다 정확도가 높은 응답을 생성하기 위해, 입력 메시지에 대해 생성된 응답 메시지 쌍의 유사도 평가에 기반하여 적절한 응답 메시지를 도출하는 대화 시스템 및 그 응답 제어 방법을 제공 하는 것을 목적으로 한다."}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여, 본 발명의 일 측면에 따르면, 인공 지능 기반의 대화 시스템에서 응답 제어 방법 으로서, 입력 메시지가 응답이 필요한 질문인지 판단하는 대화 인식 단계와, 상기 대화 인식에 기반하여 상기 입력 메시지에 대한 응답을 생성하는 단계와, 대화 이력에 기반하여 상기 입력 메시지와 상기 생성된 응답을 인 코딩한 인코딩 벡터 사이의 유사도를 평가하는 단계와, 상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하는 단계를 포함하는 방법이 제공된다. 본 발명의 일 실시 예에 따르면, 상기 입력 메시지에 대한 응답을 생성하는 단계는, 상기 입력 메시지가 질문 형태인 경우, 상기 입력 메시지에 대한 응답을 생성하는 단계를 포함할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 입력 메시지가 질문 형태가 아닌 경우, 상기 응답 메시지 출력 없이 상기 입력 메시지를 대화 이력 DB에 저장하는 단계를 더 포함할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 유사도를 평가하는 단계는, 상기 입력 메시지와 상기 응답 중 적어도 하 나를 복수개의 chunk로 분리하는 단계와, 상기 대화 이력에 기반하여, 상기 입력 메시지와 상기 응답에 대해 상 기 복수개의 chunk 각각에 대한 단어-레벨 RNN 인코딩을 수행하는 단계와, 상기 단어-레벨 RNN 인코딩에 기반하 여 chunk-레벨 RNN 인코딩을 수행하는 단계와, 상기 chunk-레벨 RNN 인코딩의 마지막 hidden state 벡터에 기반 하여 상기 입력 메시지와 상기 응답의 유사도를 산출하는 단계를 포함할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 유사도를 산출하는 단계는, 상기 입력 메시지와 상기 응답 중 적어도 하 나에 대한 상기 chunk-레벨 RNN 인코딩의 마지막 hidden state 벡터에 토픽 정보를 추가하여 인코딩된 벡터를 산출하는 단계와, 상기 토픽 정보가 추가 인코딩된 벡터에 기반하여 상기 입력 메시지와 상기 응답의 유사도를 산출하는 단계를 포함할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 유사도를 평가하는 단계는, 상기 산출된 유사도가 미리 설정된 임계치보 다 큰 값을 가지는지 결정하는 단계를 포함할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하는 단계는, 상기 인코딩 벡터 사이의 유사도가 미리 설정된 임계 치보다 큰 값을 가지는 경우, 상기 생성된 응답을 상기 입력 메시지에 대한 응답 메시지로 출력하고, 상기 인코 딩 벡터 사이의 유사도가 미리 설정된 임계치 이하인 경우, 상기 입력 메시지에 대한 응답을 다시 생성하고 유 사도 평가를 반복하여, 산출된 유사도가 미리 설정된 임계치보다 큰 값을 가지는 응답을 상기 입력 메시지에 대 한 응답 메시지로 출력하는 단계를 포함할 수 있다.본 발명의 다른 측면에 따르면, 인공 지능 기반의 대화 시스템으로서, 입력 메시지가 응답이 필요한 질문인지 판단하는 대화 인식 모듈과, 상기 결정에 기반하여 상기 입력 메시지에 대한 응답을 생성하는 응답 생성 모듈과, 대화 이력에 기반하여 상기 입력 메시지와 상기 생성된 응답을 인코딩한 인코딩 벡터 사이의 유사도를 평가하고, 상기 유사도 평가에 기반하여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하 여 유사도를 다시 평가하도록 제어하는 응답 평가 모듈을 포함하는 대화 시스템이 제공된다. 본 발명의 일 실시 예에 따르면, 상기 응답 생성 모듈은, 상기 입력 메시지가 질문 형태인 경우, 상기 입력 메 시지에 대한 응답을 생성할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 대화 인식 모듈은, 상기 입력 메시지가 질문 형태가 아닌 경우, 상기 응 답 메시지 출력 없이 상기 입력 메시지를 대화 이력 DB에 저장할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 응답 평가 모듈은, 상기 입력 메시지와 상기 응답 중 적어도 하나를 복수 개의 chunk로 분리하고, 상기 대화 이력에 기반하여, 상기 입력 메시지와 상기 응답에 대해 상기 복수개의 chunk 각각에 대한 단어-레벨 RNN 인코딩을 수행하고, 상기 단어-레벨 RNN 인코딩에 기반하여 chunk-레벨 RNN 인코딩을 수행하고, 상기 chunk-레벨 RNN 인코딩의 마지막 hidden state 벡터에 기반하여 상기 입력 메시지와 상기 응답의 유사도를 산출할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 응답 평가 모듈은, 상기 입력 메시지와 상기 응답 중 적어도 하나에 대한 상기 chunk-레벨 RNN 인코딩의 마지막 hidden state 벡터에 토픽 정보를 추가하여 인코딩된 벡터를 산출하고, 상기 토픽 정보가 추가 인코딩된 벡터에 기반하여 상기 입력 메시지와 상기 응답의 유사도를 산출할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 응답 평가 모듈은, 상기 산출된 유사도가 미리 설정된 임계치보다 큰 값 을 가지는지 결정할 수 있다. 본 발명의 일 실시 예에 따르면, 상기 응답 평가 모듈은, 상기 인코딩 벡터 사이의 유사도가 미리 설정된 임계 치보다 큰 값을 가지는 경우, 상기 생성된 응답을 상기 입력메시지에 대한 응답 메시지로 출력하고, 상기 인코 딩 벡터 사이의 유사도가 미리 설정된 임계치 이하인 경우, 상기 입력 메시지에 대한 응답을 다시 생성하도록 상기 응답 생성 모듈로 피드백하고, 유사도 평가를 반복하여, 산출된 유사도가 미리 설정된 임계치보다 큰 값을 가지는 응답을 상기 입력 메시지에 대한 응답 메시지로 출력할 수 있다. 본 발명의 다른 일 측면에 따르면, 명령들을 저장하고 있는 저장 매체로서, 상기 명령들은 적어도 하나의 프로 세서에 의하여 실행될 때에 상기 적어도 하나의 프로세서로 하여금 적어도 하나의 단계를 수행하도록 설정된 것으로서, 상기 적어도 하나의 단계는, 입력 메시지가 응답이 필요한 질문인지 결정하는 대화 인식 단계와, 상기 대화 인식에 기반하여 상기 입력 메시지에 대한 응답을 생성하는 단계와, 대화 이력에 기반하여 상기 입력 메시 지와 상기 생성된 응답을 인코딩한 인코딩 벡터 사이의 유사도를 평가하는 단계와, 상기 유사도 평가에 기반하 여, 상기 생성된 응답을 응답 메시지로 출력하거나, 새로운 응답을 생성하여 유사도를 다시 평가하는 단계를 포 함하는 동작을 실행시키기 위한 프로그램을 기록한 컴퓨터 판독 가능한 저장 매체가 제공된다."}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시 예들에 따른 대화 시스템 및 응답 제어 방법은, 입력되는 메시지에 대해 상황에 강인한 응답을 생성할 수 있고, 신경망 알고리즘을 이용하여 응답의 정확도를 향상시킬 수 있게 한다. 또한, 특정 분야 의 전문 지식이 필요한 대화인 경우에도 응답의 정확도를 확률적으로 예측하고 보다 신뢰도 높은 응답을 제공할 수 있다. 이를 통해, 인간의 관여 없이도 정확도 높은 인공 지능 기반 대화를 가능하게 한다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 실시 예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이며, 후술되는 용어들은 본 발명의 실시 예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램 인스트럭션들(실행 엔진)에 의해 수 행될 수도 있으며, 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능 한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세 싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 블록도의 각 블록 또는 흐름도의 각 단계에서 설명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능 하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 블록도의 각 블록 또는 흐 름도의 각 단계에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 그리고 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되 는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수 행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수 행하는 인스트럭션들은 블록도의 각 블록 및 흐름도의 각 단계에서 설명되는 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록 또는 각 단계는 특정된 논리적 기능들을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있으며, 몇 가지 대체 실시 예들에서는 블록들 또는 단 계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 또는 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하며, 또한 그 블록들 또는 단 계들이 필요에 따라 해당하는 기능의 역순으로 수행되는 것도 가능하다. 이하, 첨부 도면을 참조하여 본 발명의 실시 예를 상세하게 설명한다. 그러나 다음에 예시하는 본 발명의 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 다음에 상술하는 실시 예에 한정되는 것은 아 니다. 본 발명의 실시 예는 당업계에서 통상의 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위하여 제공된다. 도 1은 본 발명의 일 실시 예에 따른 인공 지능 기반의 대화 시스템을 도시한다. 도 1을 참고하면, 본 발명의 일 실시 예에 따른 대화 시스템은 대화 인식 모듈, 응답 생성 모듈 , 응답 평가 모듈 및 대화 이력 DB(database)를 포함한다. 예를 들어, 대화 시스템은 사 용자의 메시지를 입력 받고, 대화 시스템의 복수의 모듈을 통해 적절한 답변을 생성하여 응답을 출력할 수 있다. 대화 인식 모듈은 입력 받은 메시지가 응답 생성 대상 메시지인지 여부를 확인한다. 예를 들어, 대화 인식 모듈은 사용자의 입력 메시지가 응답이 필요한 질문인지 여부를 메시지 분석을 통해 판단할 수 있다. 이를 위해 자연어 처리의 많은 기법들이 사용될 수 있다. 일 실시 예에 따라, 대화 인식 모듈은 메시지가 응답이 필요한 질문으로 판단한 경우 응답 생성 모듈로 메시지를 전달하고, 응답이 필요 없는 것으로 판단한 경우 대화 이력 DB에 저장하는 작업만 수행하도록 제어할 수 있다. 응답 생성 모듈은 전달 받은 메시지에 대해 적절한 응답을 생성한다. 일 실시 예에 따라, 응답 생성 모듈은 신경망 알고리즘의 Generative Model 학습을 통해 메시지에 대해 적절한 응답을 생성할 수 있 다. 응답 생성 모듈은 대화 이력 DB로부터의 이력 데이터를 더 고려하여 현재 시점에서 적절한 응답 을 생성할 수 있다. 또한, 응답 생성 모듈은 응답 평가 모듈로부터의 피드백에 기반하여 메시지(10 1)에 대한 다른 응답을 반복하여 생성할 수 있다. 응답 평가 모듈은 응답 생성 모듈에서 생성된 응답의 정확도를 평가할 수 있다. 응답 평가 모듈(13 0)은 응답 생성 모듈에서 생성한 응답을 출력하기 전에, 메시지에 대한 유사도에 기반하여 적절한 응 답인지 평가할 수 있다. 일 실시 예에 따라, 대화 이력 DB로부터의 이력 데이터에 기반하여 RNN(Recurrent Neural Network) 방식으로 인코딩된 메시지 및 응답의 유사도가 산출될 수 있다. 다른 실시 예에 따라, RNN으로 인코딩된 메시지 및 응답 중 적어도 하나에 관련분야 토픽 정보를 추가로 고려하여 유사도가 산출 될 수 있다. 응답 평가 모듈은 산출된 유사도에 따른 응답 평가 결과를 응답 생성 모듈에 피드백할 수 있다. 일 실시 예에 따라, 응답 평가 모듈은 산출된 유사도를 미리 설정된 임계치와 비교하여 임계치보다 큰 값 을 가지는 경우 응답을 출력하고, 임계치 이하 값을 가지는 경우에 평가 결과를 응답 생성 모듈에 피 드백하여 새로운 응답을 생성하게 제어할 수 있다. 다른 실시 예에 따라, 응답 평가 모듈은 산출된 유사도 를 응답 생성 모듈로 피드백하고, 응답 생성 모듈이 피드백된 유사도를 미리 설정된 임계치와 비교할 수 있다. 이 때, 응답 생성 모듈은 피드백된 유사도가 미리 설정된 임계치보다 큰 값을 가지는 경우 응답 을 출력하고, 임계치 이하 값을 가지는 경우에 새로운 응답을 생성하여 응답 평가 모듈로 다시 전달 할 수 있다. 대화 이력 DB는 통합하여 관리되는 입력 메시지와 응답 데이터의 집합이다. 대화 이력 DB는 대화 인 식 모듈, 응답 생성 모듈 및 응답 평가 모듈이 물리적 직접 연결 또는 유/무선 네트워크를 통해 액세스(access)할 수 있는 저장 장치에 수록된 데이터의 집합일 수 있다. 본 발명의 일 실시 예에 따른 대화 시스템은 사용자의 메시지 입력에 대해 응답을 출력하도록 전자 장치 상에 어플리케이션(application) 등의 형태로 구현될 수 있다. 이 때, 대화 인식 모듈, 응답 생 성 모듈 및 응답 평가 모듈 모두 상기 전자 장치에서 실행될 수 있고, 이들 중 적어도 하나는 상기 전자 장치의 외부 기기에서 실행될 수도 있다. 상기 모듈들 간의 데이터 송수신은 물리적 직접 연결 또는 유/무 선 통신 네트워크를 통해 이루어질 수 있다. 대화 인식 모듈, 응답 생성 모듈 및 응답 평가 모듈 의 동작들은 하나 이상의 프로세서(processor)에 의해 제어될 수 있다. 즉, 대화 인식 모듈, 응답 생 성 모듈 및 응답 평가 모듈의 동작들이 컴퓨터 프로그램의 형태로 하나 이상의 저장 매체에 저장되어, 하나 이상의 프로세서에 의해 실행되도록 제어될 수 있다. 예를 들어, 상기 전자 장치는 스마트폰, 태블릿(tablet) PC(personal computer), 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑(desktop) PC, 랩 탑(laptop) PC, 넷북(netbook) 컴퓨터, 워크스테이션(workstation), 서버(server), PDA(personal digital assistant), 미디어 박스, 게임 콘솔, 전자 사전 또는 웨어러블 장치(wearable device) 중 적어도 하나를 포함 할 수 있다. 웨어러블 장치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(HMD, head-mounted-device), 직물 또는 의류 일체형(예: 전자 의복), 신체 부착형(예: 스킨 패드 (skin pad) 또는 문신), 또는 생체 이식형 회로(implantable circuit) 중 적어도 하나를 포함할 수 있다. 다양 한 실시예들에서, 상기 전자 장치는 플렉서블(flexible)하거나, 또는 전술한 다양한 장치들 중 둘 이상의 조합 일 수 있다. 다만, 상기 전자 장치는 전술한 기기들에 한정되지 않는다. 본 발명의 일 실시 예에 따른 대화 시스템은 메시지를 입력 받고 응답을 출력하는 입/출력 장치 (미도시)를 더 포함할 수 있다. 입/출력 장치는, 예를 들면, 사용자 또는 외부 기기로부터 명령 또는 데이터를 입력 받거나, 또는 대화 시스템의 처리 결과 데이터를 출력할 수 있다. 예를 들어, 입력 장치는 터치 패널, 키보드, 마우스, 펜 센서, 마이크 등을 포함할 수 있고, 출력 장치는 디스플레이, 오디오 등을 포함할 수 있다. 본 발명은 입력 메시지에 대해 적절한 응답을 출력하기 위한 대화 시스템의 응답 제어 방법에 대해 구체적으로 설명한다. 특히, 생성된 응답이 적절한지 평가하기 위해 입력 메시지와 응답 간의 유사도를 산출하여 평가하는 방법을 제안한다. 이하, 도 2 내지 도 5는 유사도 평가에 기반하여 응답을 출력하는 대화 시스템의 동작과정을 설명의 편의를 위해 Generative Model에 기반하여 설명하나, 이에 한정되는 것은 아니다. 주어진 메시지에 대해 응답을 생성하는 종래의 인공 지능 기술은 크게 두 가지 기술이 있다. 먼저, Generative Model은 특정 데이터를 가지고 딥러닝(deep learning) 방식을 이용하여 입력 메시지에 대한 응답을 생성하는 모 델을 학습하는 방식이다. Generative Model은 어떤 메시지에 대해서도 응답을 생성할 수 있는 적응력이 뛰어난 대화 시스템을 제공할 수 있으나, 사용자가 의도한 문맥을 이해하지 못한 응답을 생성하거나 평이한 응답, 반복 적인 응답을 생성할 가능성이 있다. 다른 방법으로, Retrieval Model은 주어진 메시지-응답 쌍에 대한 데이터에 서 입력 메시지에 가장 적합한 응답을 검색한 후 가장 연관성이 높은 응답을 제공하는 모델을 학습하는 방식이 다. Retrieval Model은 주어진 메시지에 대해 구체적이고 명확한 응답을 생성할 수 있는 장점이 있으나, 미리 학습하지 못한 메시지에 대해서는 적절한 응답을 찾지 못하는 문제점을 갖는다. 종래 제안된 기술들의 이러한 문제 해결을 위해 본 발명은, Generative Model에 기반하여 응답을 생성하되, 응답의 정확도 평가에 기반하여 적절한 응답을 출력하기 위한 대화 시스템 및 응답 제어 방안을 제안한다. 이하, 도 2 내지 도 5를 참고하여 본 발명이 제안하는 평가에 기반한 대화 시스템의 응답 제어 방법이 도시된다. 도 2는 본 발명의 일 실시 예에 따른 응답 정확도 평가에 기반한 대화 시스템의 응답 생성 과정을 도시한 다. 도 2에 도시된 바와 같이, 대화 시스템의 응답 정확도 평가에 기반한 응답 생성 과정은 입력 메시지에 대 한 대화 인식 과정, 응답 생성 과정, 응답의 정확도 평가 과정, 및 정확도에 기반하여 응답을 출력하는 과정을 포함한다. 도 2를 참고하면, 대화 시스템은 입력 메시지에 대한 대화 인식 과정을 수행한다. 본 발명의 일 실시 예에 따라, 대화 시스템의 대화 인식 모듈에 의해 입력 메시지에 대한 대화 인식 과정이 수행될 수 있다. 예를 들어, 대화 시스템은 사용자의 입력 메시지를 자연어 처리 기법에 의한 메시지 분석을 통해 대화로 인식할 수 있다. 즉, 대화 시스템은 사용자의 입력 메시지가 응답이 필요한 질문인지 판단할 수 있 다. 일 실시 예에 따라, 대화 시스템은 입력 메시지가 응답이 필요한 질문으로 판단한 경우 메시지에 대한 응답 생성 과정을 진행할 수 있다. 대화 시스템은 응답이 필요 없는 것으로 판단한 경우 입력 메시지 를 대화 이력 DB에 저장하는 작업만 수행하도록 제어할 수도 있다. 이후, 대화 시스템은 응답 생성 과정을 수행한다. 본 발명의 일 실시 예에 따라, 대화 시스템의 응답 생성 모듈에 의해 입력 메시지에 대한 적절한 응답 생성 과정이 수행될 수 있다. 예를 들어, 대 화 시스템은 신경망 알고리즘의 Generative Model 학습을 통해 메시지에 대해 적절한 응답을 생성할 수 있 다. 대화 시스템은 대화 이력 DB로부터의 이력 데이터를 고려하여 현재 시점에서 적절한 응답을 생성 할 수 있다. 다음으로, 대화 시스템은 응답의 정확도 평가 과정을 수행한다. 본 발명의 일 실시 예에 따라, 대화 시스템의 응답 평가 모듈에 의해 생성된 응답에 대한 정확도 평과 과정이 수행될 수 있다. 예를 들어, 대화 시스템은 생성된 응답을 출력하기 전에, 메시지에 대한 유사도에 기반하여 응답의 정확도를 평 가할 수 있다. 정확도 평가를 위해, 대화 시스템은 대화 이력 DB로부터의 이력 데이터에 기반하여 RNN으로 인코딩된 메시지 및 응답의 유사도를 산출할 수 있다. 여기서, 메시지에 대한 적절한 응답(정답) 쌍은 유사도가 높고, 메시지에 대한 부적절한 응답(오답) 쌍은 유사도가 낮도록 학습될 수 있다. 다른 실시 예에 따 라, 대화 시스템은 RNN으로 인코딩된 메시지 및 응답 중 적어도 하나에 관련분야 토픽 정보를 추가로 고려 하여 유사도를 산출할 수 있다. 대화 시스템은 산출된 유사도를 미리 설정된 기준 값과 비교하는 방식으로 응답의 정확도를 평가할 수 있다. 마지막으로, 대화 시스템은 정확도에 기반하여 응답을 출력하는 과정을 수행한다. 본 발명의 일 실시 예에 따라, 대화 시스템의 응답 생성 모듈 또는 응답 평가 모듈에 의해 정확도에 기반하여 응답 을 출력하는 과정이 수행될 수 있다. 대화 시스템은 산출된 유사도를 미리 설정된 임계치와 비교하여 임계치보다 큰 값을 가지는 경우 정확도가 높다고 판단하여 응답을 출력하고, 임계치 이하 값을 가지는 경우에 새로운 응답을 생성하고 응답의 정확도를 평가하는 과정을 반복하도록 제어할 수 있다. 일 실시 예에 따라, 대 화 시스템의 응답 출력 지연 및 무한 루프(loop)를 방지하기 위해, 새로운 응답을 생성하고 응답의 정확도 를 평가하는 과정의 반복은 미리 설정된 횟수 이하 또는 일정 시간 내로 제한되도록 설정될 수 있다. 미리 설정 된 횟수 또는 시간 동안 응답을 새롭게 생성하였으나 임계치 이상의 유사도를 갖는 응답을 생성하지 못한 경우,대화 시스템은 생성하였던 응답 중에서 가장 유사도가 높았던 응답을 출력할 수 있다. 이를 위해, 생성된 응답은 모두 대화 이력 DB 또는 별도의 영역에 저장될 수 있다. 도 3은 본 발명의 일 실시 예에 따른 유사도 평가에 기반하여 정확도 높은 응답을 출력하기 위한 구체적 과정을 도시한다. 예를 들어, 도 3은 유사도 평가에 기반하여 응답을 출력하는 대화 시스템의 동작 과정을 도시한 다. 도 3에 도시된 바와 같이, 대화 시스템의 유사도 평가에 기반하여 정확도 높은 응답을 출력하기 위한 구체 적 과정은 입력 메시지 대화 인식 과정, 응답 생성 대상 판단 과정, 응답 생성 과정, 입력과 응 답 사이의 유사도 산출 과정, 유사도 평가 과정, 응답 출력 과정, 및 대화 이력 저장 과정(31 3)을 포함한다. 도 3을 참고하면, 대화 시스템은 입력 메시지에 대한 대화 인식 과정을 수행한다. 예를 들어, 대화 시스템은 사용자의 입력 메시지에 대해 자연어 처리 기법에 의한 메시지 분석을 수행할 수 있다. 이후, 대화 시스템은 입력 메시지에 대한 응답 생성 대상 판단 과정을 수행할 수 있다. 즉, 대화 시 스템은 자연어 처리 기법에 의해 분석된 메시지가 응답 생성이 필요한 질문인지 판단할 수 있다. 입력 메시지가 응답이 필요한 질문 형태인 것으로 판단한 경우, 대화 시스템은 메시지에 대한 응답 생성 과정을 진 행한다. 만일 질문 등의 형태가 아니어서 응답이 필요 없는 것으로 판단한 경우, 대화 시스템은 대화 이력 저장 과정을 수행한다. 입력 메시지가 응답이 필요한 질문인 것으로 판단한 경우, 대화 시스템은 응답 생성 과정을 수행한다. 예를 들어, 대화 시스템은 신경망 알고리즘의 Generative Model 학습을 통해 메시지에 대해 적 절한 응답을 생성할 수 있다. 대화 시스템은 또한 대화 이력 DB로부터의 이력 데이터를 고려하여 현 재 시점에서 적절한 응답을 생성할 수 있다. 다음으로, 대화 시스템은 입력과 응답 사이의 유사도 산출 과정을 수행한다. 응답의 적절성을 평가하 기 위해, 대화 시스템은 생성된 응답과 입력된 메시지 쌍의 유사도를 산출할 수 있다. 예를 들어, 대화 시 스템은 대화 이력 DB로부터의 이력 데이터에 기반하여 RNN으로 인코딩된 메시지 및 응답의 유사도를 각각 산출할 수 있다. 또한, 대화 시스템은 RNN으로 인코딩된 메시지 및 응답 중 적어도 하나에 관련분야 지식 정보를 추가로 고려하여 유사도를 산출할 수 있다. 일 실시 예에 따라, 대화 시스템의 응답 평가 모 듈에서 유사도를 산출하고, 응답 생성 모듈로 산출된 유사도에 기반한 피드백을 수행할 수 있다. 이후, 대화 시스템은 유사도 평가 과정을 수행한다. 예를 들어, 대화 시스템은 산출된 유사도를 미리 설정된 임계치와 비교하는 방식으로 유사도 평가 과정을 수행할 수 있다. 산출된 유사도가 미리 설정된 임 계치보다 큰 값을 가지는 경우, 대화 시스템은 응답 출력 과정을 수행한다. 산출된 유사도가 미리 설 정된 임계치 이하 값을 가지는 경우, 대화 시스템은 응답 생성 과정으로 돌아가 응답을 다시 생성하 고 유사도를 산출하는 과정을 반복한다. 일 실시 예에 따라, 대화 시스템의 응답 출력 지연 및 무한 루프 를 방지하기 위해, 새로운 응답을 생성하고 응답의 유사도를 산출하는 과정의 반복은 미리 설정된 횟수 이하 또 는 시간 이내로 제한되도록 설정될 수 있다. 미리 설정된 횟수 또는 시간 동안 응답을 새롭게 생성하였으나 임 계치 이상의 유사도를 갖는 응답을 생성하지 못한 경우, 대화 시스템은 생성하였던 응답 중에서 가장 유사 도가 높았던 응답을 출력할 수 있다. 산출된 유사도가 임계치보다 큰 값을 가지는 경우, 대화 시스템은 응답 출력 과정을 수행한다. 즉, 유사도 평가 과정에서 입력 메시지와 응답 간의 유사도가 임계치보다 큰 값을 갖는 것으로 판단된 경우, 메시지에 대해 관련성이 높은 적절한 응답이 생성된 것으로 보고 대화 시스템은 생성된 응답 메시지를 출 력한다. 마지막으로, 대화 시스템은 대화 이력 저장 과정을 수행한다. 일 실시 예에 따라, 대화 시스템 은 응답 메시지를 출력한 후 또는 입력된 메시지가 응답 생성 대상이 아니라고 판단된 경우, 입력된 메시지 및/ 또는 출력된 응답을 대화 이력 DB에 저장할 수 있다. 상술한 바와 같이, 대화 시스템은 입력된 메시지와 생성된 응답 사이의 유사도를 산출하여 일정 수준 이상 의 유사도를 갖는 응답이 생성될 때까지 응답 생성 과정을 반복함으로써, 입력 메시지에 대해 높은 정확도의 응 답을 제공할 수 있게 한다. 이하, 도 4 내지 도 5를 참고하여 본 발명이 제안하는 응답 평가를 위해 유사도를 산출하는 구체적인 방법이 도시된다. 도 4는 본 발명의 일 실시 예에 따른 질문과 응답 사이의 유사도를 산출하는 흐름도를 도시한다. 도 4를 참고하면, 응답 평가 모듈 내에 주어진 메시지(질문)와 응답 사이의 유사도를 산출하는 본 발명이 제안하는 HRDE(hierarchical recurrent dual encoder)가 도시된다. HRDE는 대화의 맥락을 고려하여 현재 생성된 응답의 정확도를 판단하기 위해 고안된 것이다. 예를 들어, 주어진 메시지와 응답 사이의 유사도란, 응답이 주어진 메시지에 대한 정답일 확률을 의미할 수 있다. 일 실시 예에 따라, HRDE는 메시지(질문)와 응답 내의 문장을 chunk로 나누고, 각 chunk 내에서 단어-레벨 RNN 인코딩(411, 413)을 수행한다. 그 다음, HRDE는 각 chunk에 대해 단어-레벨 RNN 인코딩된 시퀀스를 chunk-레벨 RNN(412, 414)으로 다시 인코딩하여 인코딩 벡터를 산출하고, 메시지와 응답의 인코딩 벡터의 유사 도를 획득한다. 이 때, chunk의 크기는 하나 이상의 단어를 포함하는 크기로 결정될 수 있고, chunk마다 포함되는 단어의 개수는 달라질 수 있다. 주어진 메시지와 응답을 chunk로 구분하고 단어-레벨 RNN 및 chunk-레 벨 RNN의 두 단계 RNN 인코딩을 수행함으로써, 주어진 메시지와 응답이 긴 문장인 경우에도 처음부터 끝까지 모 든 단어를 고려한 인코딩 벡터를 산출할 수 있다. 따라서, 두 단계 RNN 인코딩을 통해 주어진 메시지와 응답 간 에 더욱 정확한 유사도 판단이 가능해진다. chunk-레벨 RNN과 단어-레벨 RNN의 hidden state는 각각 <수학식 1> 및 <수학식 2>와 같이 산출될 수 있다. 수학식 1"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "<수학식 1> 및 <수학식 2>에서 fθ와 gθ는 각각 파라미터를 θ로 하는 단어-레벨 RNN과 chunk-레벨 RNN function을 의미한다. 예를 들어, RNN function 선택을 위해 본 발명에서는 LSTM(long short term memory)에 비해 적은 파라미터가 요구되면서 성능 경쟁력이 있는 GRU(gated recurrent unit)가 사용될 수 있다. hc,t는 단 어-레벨 RNN의 c번째 chunk의 t번째 단어의 hidden state를 의미하고, hc,t-1은 단어-레벨 RNN의 c번째 chunk의 t-1번째 단어의 hidden state를 의미하며, wc,t는 c번째 chunk의 t번째 단어를 의미한다. uc는 chunk-레벨 RNN의 c번째 chunk 시퀀스의 hidden state를 의미하고, hc는 단어-레벨 RNN의 c번째 chunk의 마지막 hidden state를 의미한다. <수학식 1>을 참고하면, 단어-레벨 RNN의 t-1번째 단어의 hidden state(hc,t-1)와 c번째 chunk의 t번째 단어 (wc,t)를 입력으로 하여, 단어-레벨 RNN의 c번째 chunk의 t번째 단어의 hidden state(hc,t)를 얻을 수 있다. 이러 한 방법으로 HRDE는 각 chunk 내에서 단어-레벨 RNN 인코딩(411, 413)을 수행할 수 있다. 이어서, <수학식 2>을 참고하면, chunk-레벨 RNN의 c-1번째 chunk 시퀀스의 hidden state (uc-1)와 단어-레벨 RNN의 c번째 chunk의 마지막 hidden state(hc)를 입력으로 하여, chunk-레벨 RNN의 c번째 chunk 시퀀스의 hidden state(uc)를 얻을 수 있다. 이러한 방법으로 HRDE는 각 chunk에 대해 단어-레벨 RNN 인코딩된 시퀀 스를 chunk-레벨 RNN(412, 414)으로 다시 인코딩한 인코딩 벡터를 산출할 수 있다. HRDE의 확대도에서는 이러한 <수학식 1>과 <수학식 2>에 따른 마지막 hidden state 인코딩 과정이 좀 더 구체적으로 도시된다. 먼저 질문 또는 응답은 c개의 chunk로 나눠진다. 그 후, 첫번째 chunk에서 1부터 t까 지의 단어-레벨 RNN의 hidden state(421-1)가 인코딩되고, 같은 방법으로 c번째 chunk에서 1부터 t’까지의 단 어-레벨 RNN의 hidden state(421-c)가 인코딩된다. 첫번째 chunk의 마지막 hidden state(h1)를 입력으로 첫번째chunk-레벨 RNN 인코딩된 hidden state(422-1) u1이 얻어지고, 첫번째 chunk-레벨 RNN hidden state(422-1)와 두번째 chunk의 마지막 hidden state h2를 입력으로 두번째 chunk-레벨 RNN 인코딩된 hidden state(422-2) u2가 얻어진다. 이와 같은 방식으로, 순차적으로 마지막 c번째 chunk-레벨 RNN hidden state(422-c) uc를 얻을 수 있 다. <수학식 1> 및 <수학식 2>를 통해 주어진 질문과 응답의 인코딩된 벡터간의 유사도는 <수학식 3>과 같이 도출될 수 있다. 수학식 3"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "<수학식 3>에서, p(label)은 질문과 응답의 인코딩된 벡터간 유사도를 의미하고, 와 는 각각 질문과 응답의 chunk-레벨 RNN의 마지막 hidden state의 인코딩 벡터를 의미한다. M은 유사도 계산을 위한 행렬을 의미 하고, b는 바이어스 값을 의미한다. 일 실시 예에 따라, 질문에 대한 정답, 즉 적절한 응답인 경우 해당 메시지(질문)-응답 쌍은 유사도가 높고, 질 문에 대한 오답, 즉 부적절한 응답인 경우 해당 메시지(질문)-응답 쌍은 유사도가 낮도록 학습할 수 있다. 예를 들어, 응답 평가 모듈은 질문과 응답의 인코딩된 벡터간 유사도인 p(label)이 미리 설정된 임계치보다 큰 지 판단하고, 임계치보다 큰 경우에는 응답을 사용자에게 출력할 수 있다. 이 때, p(label)이 미리 설정된 임계 치보다 작은 경우, 응답 평가 모듈은 평가 결과를 응답 생성 모듈로 피드백하여 새로운 응답을 생성 하도록 제어할 수 있다. 다른 실시 예에 따라, 응답 평가 모듈은 질문과 응답의 인코딩된 벡터간 유사도인 p(label) 자체를 응답 생성 모듈로 피드백하고, 응답 생성 모듈은 피드백된 p(label)이 미리 설정된 임계치보다 큰지 판단할 수 있다. p(label)이 임계치보다 큰 경우에는 응답 생성 모듈은 응답을 사용자에 게 출력하고, p(label)이 미리 설정된 임계치보다 작은 경우 응답 생성 모듈은 새로운 응답을 생성할 수 있다. 도 5는 본 발명의 일 실시 예에 따른 대화 내 잠재된 토픽 정보에 기반하여 질문과 응답 사이의 유사도를 산출 하는 흐름도를 도시한다. 도 5를 참고하면, 도 4에서 도시된 HRDE는 대화 내 잠재된 토픽을 추출하여 응답의 적절성 판단에 추가 정 보를 제공하는 LTC(latent topic clustering)를 더 포함할 수 있다. 일 실시 예에 따라, LTC는 HRDE에 의해 각 질문과 응답에 대한 단어-레벨 RNN 인코딩(411, 413)과 chunk-레벨 RNN 인코딩(412, 414)된 벡터를 latent topic memory 벡터와 비교하여, latent topic memory와의 연관도 정보가 추가된 인코딩 벡터를 산출한다. 도 5에서는 응답에 대해서만 LTC를 더 포함하나, 질문 혹 은 질문/응답 모두에 latent topic memory와의 연관도 정보를 추가 연산하는 LTC를 추가할 수 있다. LTC의 확대도에서, 단어-레벨 및 chunk-레벨 RNN 인코딩된 벡터에 latent topic memory 연관도 정보 를 추가 인코딩하는 과정이 구체적으로 도시된다. 도 5에서는 응답에 대해서만 latent topic 추가 인코딩을 수 행하나, 본 발명은 이에 제한되지 않는다. 먼저, 응답에 대해 단어-레벨 RNN 인코딩된 벡터를 chunk-레벨 인코딩하여 최종 hidden state의 인코 딩 벡터()를 얻는다. 이런 chunk-레벨 인코딩의 최종 인코딩 벡터를 입력으로 하여, 입력 인코딩 벡 터가 k번째 토픽으로 분류될 확률은 <수학식 4>와 같이 산출된다. 수학식 4"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "<수학식 4>에서, x는 입력 인코딩 벡터, 즉 를 의미하고, mk는 k번째 토픽 벡터를 의미한다. pk는 입력 인 코딩 벡터와 k번째 토픽 벡터의 유사도를 전체 K개의 토픽에 대해 정규화하는 softmax 연산을 거쳐 얻어지는, 입력 인코딩 벡터가 k번째 토픽으로 분류될 확률을 의미한다. 일 실시 예에 따라, mk는 각각의 토픽에 대한 다른 대화 데이터를 통해 학습된 정보일 수 있다. 토픽 정보가 추가된 인코딩 벡터는 <수학식 5> 및 <수학식 6>을 통해 산출될 수 있다. 수학식 5"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 6"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "<수학식 5>에서 pk는 입력 인코딩 벡터가 k번째 토픽으로 분류될 확률을 의미하고, mk는 k번째 토픽 벡터를 의미 한다. K는 전체 토픽의 개수를 의미하고, xk는 k번째 토픽 정보가 포함된 시퀀스를 의미한다. <수학식 6>에서 x 는 입력 인코딩 벡터, 즉 를 의미하고, e는 입력 인코딩 벡터에 k번째 토픽 정보가 포함된 시퀀스인 xk를 추가한 인코딩 벡터를 의미한다. <수학식 4> 내지 <수학식 6>에 따라 응답에 대해 잠재된 토픽 정보를 추가한 인코딩 벡터 e와 질문의 인코딩 벡 터간 유사도는 <수학식 7>과 같이 산출될 수 있다. 수학식 7"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "<수학식 7>에서, p(label)은 질문과 응답의 인코딩된 벡터간 유사도를 의미하고, 는 질문의 chunk-레벨 RNN의 마지막 hidden state의 인코딩 벡터를 의미하며, eu,A는 토픽 정보가 추가된 인코딩 벡터를 의미한다. M은 유사도 계산을 위한 행렬을 의미하고, b는 바이어스 값을 의미한다. 일 실시 예에 따라, 응답 평가 모듈은 토픽 정보가 추가된 질문과 응답의 인코딩된 벡터간 유사도인 p(label)이 미리 설정된 임계치보다 큰지 판단하고, 임계치보다 큰 경우에는 응답을 사용자에게 출력할 수 있다. p(label)이 미리 설정된 임계치보다 작은 경우, 응답 평가 모듈은 평가 결과를 응답 생성 모듈(12 0)로 피드백하여 새로운 응답을 생성하도록 제어할 수 있다. 다른 실시 예에 따라, 응답 평가 모듈은 토픽 정보가 추가된 질문과 응답의 인코딩된 벡터간 유사도인 p(label) 자체를 응답 생성 모듈로 피드백하고,응답 생성 모듈은 피드백된 p(label)이 미리 설정된 임계치보다 큰지 판단할 수 있다. p(label)이 임계치 보다 큰 경우에는 응답 생성 모듈은 응답을 사용자에게 출력하고, p(label)이 미리 설정된 임계치보다 작 은 경우 응답 생성 모듈은 새로운 응답을 생성할 수 있다. 토픽 정보는 질문 또는 응답 인코딩 벡터에 추 가되거나, 또는 질문 및 응답 인코딩 벡터 모두에 추가될 수 있다. 상술한 도 4 내지 도 5에서 제안된 HRDE와 LTC가 추가된 HRDE의 성능 평가를 위해, 연구용 공개 데이터 셋에서 각 방식에 의한 유사도 측정 결과가 이하 설명된다. <표 1>은 성능 평가를 위해 사용된 연구용 공개 데이터 셋들의 크기와 특성을 나타낸다. 표 1"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "Ubuntu 데이터 셋은 사용자들이 Ubuntu를 사용하다 궁금한 점이 있을 때, 포럼 상에서 사용자 간 질의 응답을 통해 문제를 해결한 데이터를 바탕으로 만들어진 데이터 셋이다. 예를 들어, 이러한 Ubuntu 데이터 셋은 2004년 부터 2017년까지 http://irclogs.ubuntu.com에서 얻을 수 있는 Ubuntu 챗 로그들로부터 획득될 수 있다. 사용 자들이 특정 주제에 관해서 주고 받은 t 시점까지의 챗팅 데이터가 주어지고, t+1 시점에 어떤 답변이 올 수 있 는지를 판단하여 정확도를 평가할 수 있는 데이터 셋이다. <표 1>에서 #tokens는 메시지 내의 평균 단어의 개수, #groups는 평균 문장의 개수, #tokens/groups는 문장당 평균 단어의 개수를 의미한다. Ubuntu 데이터 셋은 대화 상자에서 ({context}, {response}, flag)를 추출하여 처리되었다. 즉, Ubuntu 데이터 셋에서 {context}와 {response} 쌍이 주어진 메시지와 응답 쌍을 의미한다. 원 본 데이터가 Ubuntu-v1이 되고, train/valid/test를 시간별로 분리하여 실생활 구현을 모방한 데이터가 Ubuntu- v2가 된다. 본 발명이 제안하는 HRDE 또는 LTC가 추가된 HRDE 알고리즘을 사용하여 텍스트를 인코딩하기 위해 텍스트를 미리 정의된 기준에 의해 몇 개의 chunk 시퀀스로 분할해야 한다. 예를 들어, Ubuntu-v1 데이터 셋의 경우 테스트를 위해, {context} 부분을 문장 끝 구분 기호 ”_eos_”로 분리하여 나누고, {response}는 짧고 “ _eos_“를 포함하지 않으므로 분할하지 않았다. Ubuntu-v2 데이터 셋의 경우, Ubuntu-v1과 같이 {context} 부 분만 문장 끝 구분 기호 ”_eot_”로 분리하여 나누었다. Samsung QA 데이터 셋은 사용자들이 Samsung사의 제품을 사용하다 발생한 궁금증이나 이슈들을 웹페이지에 올려 서 답변을 받은 데이터 셋이다. 예를 들어, Samsung QA 데이터 셋은 http://www.samsung.com/us 및 https://answers.yahoo.com, http://answers.us.samsung.com과 같은 사이트에서 획득될 수 있다. 특정 제품에 관한 질의 응답 데이터 셋을 사용함으로써, 본 발명이 제안하는 모델이 더 전문적인 질의 응답에 대해서도 좋은 성능을 내는 상황에 강인한 모델인지 확인할 수 있다. 질문에 대한 답변들 중 회사가 인증한 고객의 답변을 선 택하여 답변의 신뢰성을 더욱 높게 유지하며, 이러한 답변이 없으면 그 질의 응답 쌍은 건너 뛰었다. 또한, 품 질 보증 쌍과 관련된 계층적 제품 카테고리(예를 들어, 휴대전화, TV/비디오, 악세서리 등) 정보를 크롤링한 메 타 정보를 수집하였다. Samsung QA 데이터 셋의 총 크기는 100,000 쌍 이상이며, <표 1>과 같이 데이터를 약 80,000/10,000/10,000 샘플로 분할하여 train/valid/test 세트를 만들었다. 트레이닝 세트를 생성하기 위해 QA 쌍 샘플을 정답으로 사용하고, 잘못된 세트를 생성하기 위해 트레이닝 세트 간의 정답을 음수 샘플링하여 ({question}, {answer}, flag)를 생성하였다. 즉, Samsung QA 데이터 셋에서 {question}과 {answer} 쌍이 주어 진 메시지와 응답 쌍을 의미한다. <표 1>과 같은 두 가지 데이터 셋 모두, 현재까지 주어진 정보를 바탕으로 다음에 주어진 답변이 적절한지를 판 단하는데 목적을 둔 데이터 셋이므로 본 발명에서 제안하는 응답 평가 알고리즘의 성능을 측정하는데 적절하다. 이하, <표 2> 내지 <표 4>는 본 발명이 제안하는 HRDE 또는 LTC가 추가된 HRDE 알고리즘과 기존 알고리즘 성능 을 비교하여 나타낸다. <표 2> 내지 <표 4>에 나타난 바와 같이, 본 발명이 제안하는 HRDE 또는 LTC가 추가된HRDE 알고리즘은 기존 알고리즘 대비 높은 질문-응답 유사도를 보임으로써 성능 면에서 비교 우위에 있음을 알 수 있다. 표 2"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "Ubuntu-v1 데이터 셋을 이용하는 경우 <표 2>에 나타난 바와 같이, 종래의 TF-IDF(term frequency, inverted document frequency) 방식, CNN(convolution neural network) 방식 및 LSTM(RNN의 한 종류) 방식에 의해 얻어 지는 질문과 응답 간의 유사도 보다 RDE(recurrent dual encoder), RDE-LTC, 및 본 발명이 제안하는 HRDE, HRDE-LTC가 더욱 높은 유사도를 얻을 수 있는 것으로 나타난다. 1 in 2 R@1은 2개의 정답 후보군 중 하나가 하 나의 정답일 확률을, 1 in 10 R@1은 10개의 정답 후보군 중 하나가 하나의 정답일 확률을, 1 in 10 R@2는 10개 의 정답 후보군 중 하나가 2위 이내의 정답일 확률을, 1 in 10 R@5는 10개의 정답 후보군 중 하나가 5위 이내의 정답일 확률을 의미한다. <표 2>에 나타난 바와 같이, 종래의 방식 보다 RDE 방식을 이용하는 경우가 높은 정확 도의 응답을 출력할 수 있었던 것을 알 수 있고, 특히 본 발명이 제안하는 HRDE, 그 중에서도 토픽 정보까지 추 가된 HRDE-LTC가 가장 높은 성능을 나타낸 것을 확인할 수 있다. 주목할 것은 RDE 방식에서도 LTC를 추가로 고 려하는 경우 RDE보다 높은 유사도를 획득할 수 있었다는 점이다. 표 3"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "Ubuntu-v2 데이터 셋을 이용하는 경우 <표 3>에 나타난 바와 같이, 종래의 LSTM(RNN의 한 종류) 방식, RNN 방식, CNN 방식, RNN-CNN 방식 및 Attention(RNN-CNN) 방식에 의해 얻어지는 질문과 응답 간의 유사도 보다 RDE, RDE-LTC, 및 본 발명이 제안하는 HRDE, HRDE-LTC가 대체로 더욱 높은 유사도를 얻을 수 있는 것으로 나타 난다. 특히 본 발명이 제안하는 토픽 정보까지 추가된 HRDE-LTC가 1 in 10 R@1을 제외하고는 가장 높은 성능을 나타낸 것을 확인할 수 있다.표 4"}
{"patent_id": "10-2017-0158345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "Samsung QA 데이터 셋을 이용하는 경우 <표 4>에 나타난 바와 같이, 기준이 되는 RDE방식에 의해 얻어지는 질문 과 응답 간의 유사도 보다 RDE-LTC, 및 본 발명이 제안하는 HRDE, HRDE-LTC가 더 높은 유사도를 얻을 수 있는 것으로 나타난다. 특히 본 발명이 제안하는 토픽 정보까지 추가된 HRDE-LTC가 가장 높은 성능을 나타낸 것을 확 인할 수 있다. 상술한 구체적인 실시예들에서, 발명에 포함되는 구성 요소는 제시된 구체적인 실시예에 따라 단수 또는 복수로 표현되었다. 그러나, 단수 또는 복수의 표현은 설명의 편의를 위해 제시한 상황에 적합하게 선택된 것으로서, 상술한 실시 예들이 단수 또는 복수의 구성 요소에 제한되는 것은 아니며, 복수로 표현된 구성 요소라 하더라도 단수로 구성되거나, 단수로 표현된 구성 요소라 하더라도 복수로 구성될 수 있다. 한편 발명의 설명에서는 구체적인 실시예에 관해 설명하였으나, 다양한 실시예들이 내포하는 기술적 사상의 범 위에서 벗어나지 않는 한도 내에서 여러 가지 변형이 가능함은 물론이다. 그러므로 본 발명의 범위는 설명된 실 시예에 국한되어 정해져서는 아니되며 후술하는 청구범위뿐만 아니라 이 청구범위와 균등한 것들에 의해 정해져 야 한다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2017-0158345", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 인공 지능 기반의 대화 시스템을 도시한다. 도 2는 본 발명의 일 실시 예에 따른 응답 정확도 평가에 기반한 대화 시스템의 응답 생성 과정을 도시한다. 도 3은 본 발명의 일 실시 예에 따른 유사도 평가에 기반하여 정확도 높은 응답을 출력하기 위한 구체적 과정을 도시한다.도 4는 본 발명의 일 실시 예에 따른 질문과 응답 사이의 유사도를 산출하는 흐름도를 도시한다. 도 5는 본 발명의 일 실시 예에 따른 대화 내 잠재된 토픽(latent topic) 정보에 기반하여 질문과 응답 사이의 유사도를 산출하는 흐름도를 도시한다."}
