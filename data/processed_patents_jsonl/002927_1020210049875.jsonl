{"patent_id": "10-2021-0049875", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0128358", "출원번호": "10-2021-0049875", "발명의 명칭": "인공지능 기반 감정 인식 장치 및 방법", "출원인": "주식회사 에이비에이치", "발명자": "한아람"}}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "얼굴을 포함하는 이미지를 기반으로 사람의 감정을 인식하기 위한 감정 인식 장치에 있어서,촬영을 통해 얼굴을 포함한 이미지를 획득하는 카메라부;상기 획득된 이미지에 대한 전처리를 수행하는 전처리부;상기 전처리된 이미지로부터 얼굴 관련 영역을 검출하는 검출부;상기 검출된 영역으로부터 특징점을 추출하고, 기저장된 감정별 특징점 패턴을 기반으로 상기 추출된 특징점에해당하는 감정으로 분류하는 분류부; 및상기 카메라부의 이미지 획득 프로세스, 상기 전처리부의 전처리 프로세스, 상기 검출부의 얼굴 관련 영역 검출프로세스 및 상기 분류부의 감정 분류 프로세스를 제어하는 제어부를 포함하며,상기 기저장된 감정별 특징점 패턴은 미리 설정된 종류의 감정을 기반으로 하는 복수개의 이미지를 포함하는 이미지 데이터 세트를 학습하여 획득한 것임을 특징으로 하는,인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 전처리부는,미리 설정된 규격으로 상기 입력된 이미지의 해상도를 변경하는 변경부;상기 변경된 이미지의 색상 채널을 변환하는 변환부;상기 변환된 이미지로부터 반사 성분의 상태를 나타내는 적어도 하나의 프레임을 추출하는 추출부; 및상기 추출된 적어도 하나의 프레임의 색상 성분을 반전시켜 원본 이미지에 반영하는 반영부를 포함하는 것을 특징으로 하는,인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 변경부는,상기 입력된 영상데이터의 해상도가 상기 미리 설정된 규격 보다 높으면, 상기 영역 보간법을 기반으로 상기 입력된 영상데이터의 해상도를 상기 미리 설정된 규격으로 낮추고,상기 입력된 영상데이터의 해상도가 상기 미리 설정된 규격 보다 낮으면, 상기 쌍 선형 보간법을 기반으로 상기입력된 영상데이터의 해상도를 상기 미리 설정된 규격으로 높이는 것임을 특징으로 하는,인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2021-0128358-2-제2항에 있어서,상기 변환부는, 상기 변경된 영상데이터의 이미지 채널을 RGB(Red, Green, Blue) 채널에서 LAB(Lightness, A,B) 채널로 변환하고,상기 추출부는, 상기 반사 성분 내의 빛의 정보에 해당하는 L(Lightness) 채널에 특정 필터를 사용하여 상기 변환된 영상데이터에 적용된 빛의 상태를 나타내는 적어도 하나의 프레임을 추출하는 것을 특징으로 하는,인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 검출부는,실시간 객체 인식이 가능한 YOLO(You Only Look Once)를 통해 얼굴 관련 영역을 라벨링함으로써 얼굴 관련 영역을 검출하는 것을 특징으로 하는,인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 검출부는,하르 캐스케이드 분류기(Haar Cascade Classifier)를 통해 얼굴 관련 영역을 탐지하고, 상기 탐지된 영역의 상,하, 좌, 우로 미리 설정된 픽셀만큼 확장하여 얼굴 관련 영역을 검출하는 것을 특징으로 하는,인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 분류부는,상기 전처리된 이미지에서 CNN(Convolutional Neural Networs) 알고리즘을 통해 특징점을 추출하는 것을 특징으로 하는,인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 CNN 알고리즘은,상기 특징점을 추출하기 위해 3X3 필터를 두개 구비하는 것을 특징으로 하는, 인공지능 기반 감정 인식 장치."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "장치에 의해 수행되는, 얼굴을 포함하는 이미지를 기반으로 사람의 감정을 인식하기 위한 감정 인식 방법에 있공개특허 10-2021-0128358-3-어서,촬영을 통해 얼굴을 포함한 이미지를 획득하는 단계;상기 획득된 이미지에 대한 전처리를 수행하는 단계;상기 전처리된 이미지로부터 얼굴 관련 영역을 검출하는 단계;상기 검출된 영역으로부터 특징점을 추출하는 단계; 및기저장된 감정별 특징점 패턴을 기반으로 상기 추출된 특징점에 해당하는 감정으로 분류하는 단계를 포함하며,상기 기저장된 감정별 특징점 패턴은 미리 설정된 종류의 감정을 기반으로 하는 복수개의 이미지를 포함하는 이미지 데이터 세트를 학습하여 획득한 것임을 특징으로 하는,인공지능 기반 감정 인식 방법."}
{"patent_id": "10-2021-0049875", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터와 결합되어, 제9항의 인공지능 기반 감정 인식 방법을 실행시키기 위하여 컴퓨터 판독 가능 기록매체에저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반 감정 인식 장치 및 방법에 관한 것으로, 본 발명의 일 실시예에 따른 감정 인식 장치는, 촬영을 통해 얼굴을 포함한 이미지를 획득하는 카메라부; 상기 획득된 이미지에 대한 전처리를 수행하는 전처리부; 상기 전처리된 이미지로부터 얼굴 관련 영역을 검출하는 검출부; 상기 검출된 영역으로부터 특징점을 추출하고, 기저장된 감정별 특징점 패턴을 기반으로 상기 추출된 특징점에 해당하는 감정으로 분류하는 분류부; 및 상기 카메라부의 이미지 획득 프로세스, 상기 전처리부의 전처리 프로세스, 상기 검출부의 얼굴 관련 영역 검 출 프로세스 및 상기 분류부의 감정 분류 프로세스를 제어하는 제어부를 포함하며, 상기 기저장된 감정별 특징점 패턴은 미리 설정된 종류의 감정을 기반으로 하는 복수개의 이미지를 포함하는 이미지 데이터 세트를 학습하여 획득한 것일 수 있다."}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반 감정 인식 장치 및 방법에 관한 것으로, 보다 상세하게는 얼굴을 포함하는 이미지를 기반으로 표정을 감지하여 그 사람의 감정을 인식할 수 있도록 하는 인공지능 기반 감정 인식 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴인식(Face Recognition) 기술은 1990년대 초기에 소개된 형상 기반 매칭 방법(appearance based matching method), 및 특징(faeture) 기반의 얼굴 인식이 주로 사용된다. 그러나, 얼굴인식은 카메라의 촬영 각도, 조명 의 방향, 자세, 표정의 변화 및 시간에 따른 얼굴의 변화에 다르게 인식된다. 특징(faeture) 기반의 얼굴 인식은 디지털 카메라, IoT 디바이스의 카메라 또는 스마트폰의 카메라로 촬영된 영 상 데이터를 haar-like feature를 이용한 검출 방법과 MCT(Modified Census Transform) 영상을 이용한 검출 방 법이 사용된다. 스마트폰의 카메라의 입력 영상에서 Haar-like feature로 학습된 얼굴 및 눈 검출기를 사용하여 얼굴의 윤곽선과 이마/눈/코/입을 검출하고, 원형의 눈동자를 검출하기 위해 관심 영역(ROI, Region of Interest)으로 설정된 눈 영역을 grayscale로 변환하며, 눈 영역에서 눈동자와 눈의 외곽선 영역이 추출되는 실 험에 의한 통계적인 임계값(threshold)을 사용하여 눈 이미지의 histogram(x축 각 픽셀의 화소값, y축 해당 화 소 값의 갯수)을 구하고 눈의 이미지를 이진화(binarization)한 후, 히스토그램 평활화(histogram equalization)를 통해 눈 영역의 사진의 전처리를 수행하며, 얼굴 영역에서 눈썹과 눈, 코, 입, 턱의 특징 데이 터를 검출하고, 텍스처 특징(Texture Faetures)과 형상 특징(Shape Features)을 추출하여 얼굴 인식 데이터베이 스에 저장된 얼굴 사진의 특징점들과 유사도를 비교하여 얼굴이 인식된다. 특히, 비전 인식은 컴퓨터, 로봇, 인공지능에게 시각을 부여해 이미지를 분석함으로써 유용한 정보를 생성하는 기술로써, 자율주행차, 산업용 로봇, 의료영상 진단기술, 스마트홈, 지능형 CCTV, 출입 통제, 안면인식, 공장 자율화 같은 다양한 산업 분야에서 적용될 수 있어 주목받고 있다. 한편, 종래의 비전인식 중 안면인식 기술은 주로 동일인 여부를 판단하여 사용자를 식별하는 보안 분야 중심으 로 연구 및 개발되었으며, 안면인식을 통해 사용자의 감정을 판단, 추적하는 기술에 대한 연구가 미비한 문제점 이 있었다. 따라서, 단순히 얼굴을 인식하는 것에서 그치지 않고, 사용자의 얼굴 표정을 인식하여 사용자의 감정을 보다 정 확하게 인식하도록 하는 기술이 개발될 필요가 있다.선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 제10-2019-0123371호 (공개일 : 2019년 11월 1일)"}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 바와 같은 문제점을 해결하기 위하여 제안된 것으로, 사용자의 감정을 인식하여 그에 맞는 서 비스를 제공하기 위해서 인공지능을 기반으로 사용자의 얼굴 표정을 감지하고, 감지된 얼굴 표정을 기반으로 사 용자의 감정을 인식할 수 있도록 하는 인공지능 기반 감정 인식 장치 및 방법을 제공함에 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 실시예에 따른 인공지능 기반 감정 인식 장치는, 촬영을 통해 얼굴 을 포함한 이미지를 획득하는 카메라부; 상기 획득된 이미지에 대한 전처리를 수행하는 전처리부; 상기 전처리 된 이미지로부터 얼굴 관련 영역을 검출하는 검출부; 상기 검출된 영역으로부터 특징점을 추출하고, 기저장된 감정별 특징점 패턴을 기반으로 상기 추출된 특징점에 해당하는 감정으로 분류하는 분류부; 및 상기 카메라부의 이미지 획득 프로세스, 상기 전처리부의 전처리 프로세스, 상기 검출부의 얼굴 관련 영역 검출 프로세스 및 상 기 분류부의 감정 분류 프로세스를 제어하는 제어부를 포함하며, 상기 기저장된 감정별 특징점 패턴은 미리 설 정된 종류의 감정을 기반으로 하는 복수개의 이미지를 포함하는 이미지 데이터 세트를 학습하여 획득한 것일 수 있다. 또한, 본 발명의 일 실시예에 따른 인공지능 기반 감정 인식 방법은, 촬영을 통해 얼굴을 포함한 이미지를 획득 하는 단계; 상기 획득된 이미지에 대한 전처리를 수행하는 단계; 상기 전처리된 이미지로부터 얼굴 관련 영역을 검출하는 단계; 상기 검출된 영역으로부터 특징점을 추출하는 단계; 및 기저장된 감정별 특징점 패턴을 기반으 로 상기 추출된 특징점에 해당하는 감정으로 분류하는 단계를 포함하며, 상기 기저장된 감정별 특징점 패턴은 미리 설정된 종류의 감정을 기반으로 하는 복수개의 이미지를 포함하는 이미지 데이터 세트를 학습하여 획득한 것일 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 사용자의 감정을 인식하여 그에 맞는 서비스를 제공하기 위해서 인공지능을 기반으로 사용자 의 얼굴 표정을 감지하고, 감지된 얼굴 표정을 기반으로 사용자의 감정을 인식할 수 있도록 한다."}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 공간적으로 상대적인 용어인 \"아래(below)\", \"아래(beneath)\", \"하부(lower)\", \"위(above)\", \"상부(upper)\" 등 은 도면에 도시되어 있는 바와 같이 하나의 구성요소와 다른 구성요소들과의 상관관계를 용이하게 기술하기 위 해 사용될 수 있다. 공간적으로 상대적인 용어는 도면에 도시되어 있는 방향에 더하여 사용시 또는 동작시 구성 요소들의 서로 다른 방향을 포함하는 용어로 이해되어야 한다. 예를 들어, 도면에 도시되어 있는 구성요소를 뒤 집을 경우, 다른 구성요소의 \"아래(below)\"또는 \"아래(beneath)\"로 기술된 구성요소는 다른 구성요소의 \"위 (above)\"에 놓여질 수 있다. 따라서, 예시적인 용어인 \"아래\"는 아래와 위의 방향을 모두 포함할 수 있다. 구성 요소는 다른 방향으로도 배향될 수 있으며, 이에 따라 공간적으로 상대적인 용어들은 배향에 따라 해석될 수 있 다. 명세서에서 사용되는 \"부\" 또는 \"모듈\"이라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미하며, \"부\" 또는 \"모듈\"은 어떤 역할들을 수행한다. 그렇지만 \"부\" 또는 \"모듈\"은 소프트웨어 또는 하드웨 어에 한정되는 의미는 아니다. \"부\" 또는 \"모듈\"은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\" 또는 \"모듈\"은 소 프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌 웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 \"부\" 또는 \"모듈\"들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\" 또는 \"모듈\"들로 결합되거나 추가적인 구성요소들과 \"부\" 또는 \"모듈\"들로 더 분리될 수 있다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 감정 인식 장치의 구성을 나타내는 블록도로서, 이때, 감정 인식 장치(10 0)는 서버일 수도 있다. 도 1을 참조하면, 감정 인식 장치는 카메라부, 전처리부, 검출부, 분류부 및 제어부 를 포함한다. 카메라부는 적어도 하나 이상의 카메라를 포함하며, 각 카메라를 이용하여 사용자를 촬영함으로써, 사용자 의 얼굴이 포함된 이미지를 획득한다. 이 카메라부는 검사 장치에 일체로 구비될 수도 있지만, 유선 또는 무선으로 연결될 수 있다. 예를 들어, 카메라부는 검사 장치와 블루투스(bluetooth) 통신, BLE(Bluetooth Low Energy) 통신, 근거리 무선 통신(Near Field Communication unit), WLAN(와이파이) 통신, 지그비(Zigbee) 통신, 적외선(IrDA, infrared Data Association) 통신, WFD(Wi-Fi Direct) 통신, UWB(ultra wideband) 통신, Ant+ 통신 WIFI 통신 방법을 이용하여 통신할 수 있으나, 이에 제한되지 않는다. 전처리부는 획득된 이미지를 얼굴 관련 영역을 검출하기 위한 딥러닝 학습 모델에 입력하기 위해 전처리를 수행한다. 이를 위해, 전처리부는 변경부, 변환부, 추출부 및 반영부를 포함할 수 있다. 먼저, 변경부는 미리 설정된 규격으로 그 입력된 이미지의 해상도를 변경한다. 여기서, 해상도는 이미지의 정밀도(선명도)를 나타내고, 반사 성분은 이미지에 적용된 빛을 의미한다. 구체적으로, 변경부는 획득된 이미지의 해상도를 변경하기 위해서 이웃 보간법(Nearest-neighbor interpolation), 쌍 선형 보간법(Bilinear interpolation), 비트 쌍 선형 보간법(Linear exact interpolation), 바이큐빅 보간법(Bicubic interpolation), 스플라인 보간법(Cubic Spline interpolation), 영 역 보간법(Area interpolation) 및 Lanczos 보간법 등 다양한 알고리즘에 따라 수행될 수 있다. 예를 들어, 변 경부는 입력된 이미지의 해상도가 미리 설정된 규격 보다 높으면, 영역 보간법을 기반으로 그 입력된 이미 지의 해상도를 미리 설정된 규격에 따라 낯춘다. 한편, 변경부는 입력된 이미지의 해상도가 미리 설정된 규격 보다 낮으면, 쌍 선형 보간법을 기반으로 그 입력된 이미지의 해상도를 미리 설정된 해상도에 따라 높인다. 여기서, 미리 설정된 규격은 사용자, 관리자 등에 의해 변경될 수 있는 것으로, 필요에 따라 변경하여 설정 가능하다. 변환부는 해상도가 변경된 이미지의 색상 채널을 변환한다. 이때, 변환부는 LAB 색공간을 이용하여 변경된 이미지의 반사 성분을 변경을 수행할 수 있다. 여기서, LAB 색공간은 이미지의 밝기와 색상 정보를 이용 하여 컬러를 표시하는 것으로, L값은 밝기(Lightness)를, A값은 빨간색-녹색(Red-Green)의 색상 정보를, B값은 파란색-노란색(Blue-Yellow)의 색상 정보를 나타낸다. 다시 말해, 변환부는 그 변경된 이미지의 채널을 RGB(Red, Green, Blue) 채널에서 LAB(Lightness, A, B) 채널로 변환한다. 한편, 추출부는 채널이 변환된 이미지로부터 반사 성분의 상태를 나타내는 적어도 하나의 프레임을 추출한 다. 즉, 반사 성분 내의 빛의 정보에 해당하는 L(Lightess) 채널에 특정 필터를 사용하여 앞서 채널이 변환된 영상데이터에 적용된 빛의 상태를 나타내는 적어도 하나의 프레임을 추출하는 것이다. 반영부는 그 추출된 적어도 하나의 프레임의 색상 성분을 반전시켜 원본 이미지에 반영한다. 이로써, 반 사 성분이 제거(감소)된 영상데이터를 획득할 수 있다. 이때, 원본 이미지에서 반전된 적어도 하나의 프레임에 대응하는 프레임을 검색하고, 그 검색된 프레임을 삭제 한 후, 반전된 적어도 하나의 프레임을 대체함으로써 반영할 수 있다. 한편, 그 검색된 프레임에서 반사 성분의 위치를 파악하고, 반전된 적어도 하나의 프레임에서 검색된 프레임 내의 반사 성분에 해당하는 위치를 파악하고, 검색된 프레임 내의 반사 성분 위치에 반전된 적어도 하나의 프레임 내의 반사 성분에 해당하는 부분 이미지를 크롭하여 덮어 씌운다. 즉, 반영하는 방법에는 다양한 방법이 적용될 수 있으며, 이를 한정하지 않는 다. 한편, 검출부는 전처리부에 의해 전처리된 이미지로부터 얼굴 관련 영역을 검출한다. 이때, 실시간 객체 인식이 가능한 YOLO(You Only Look Once)를 통해 얼굴 관련 영역을 라벨링함으로써 얼굴 관련 영역을 검출 할 수 있다. 또한, 검출부는 하르 캐스케이드 분류기(Haar Cascade Classifier)를 통해 얼굴 관련 영역을 탐지하고, 상 기 탐지된 영역의 상, 하, 좌, 우로 미리 설정된 픽셀만큼 확장하여 얼굴 관련 영역을 검출할 수 있다.분류부는 검출부로부터 검출된 얼굴 관련 영역으로부터 특징점을 추출하고, 기저장된 감정별 특징점 패턴을 기반으로 그 추출된 특징점에 해당하는 감정으로 사용자의 감정을 분류한다. 즉, 각 감정마다 동일한 특 징점 패턴이 반복되는 특징을 가지므로, 그 이미지의 특징점과 기저장된 감정별 특징점 패턴을 기반으로 사용자 의 감정을 분류하도록 하는 것이다. 이때, 분류부는 CNN(Convolutional Neural Networs) 알고리즘을 통해 특징점을 추출할 수 있으며, 이 CNN 알고리즘은 특징점을 추출하기 위해 3X3 필터를 두개 구비하도록 구성될 수 있다. 또한, 기저장된 감정별 특징 점 패턴은 미리 설정된 종류의 감정을 기반으로 하는 복수개의 이미지를 포함하는 이미지 데이터 세트를 학습하 여 획득한 것일 수 있다. 제어부는 앞서 설명한 카메라부의 이미지 획득 프로세스, 전처리부의 전처리 프로세스, 검출부 (!30)의 얼굴 관련 영역 검출 프로세스 및 분류부의 감정 분류 프로세스를 제어한다. 도 2는 본 발명의 일 실시예에 따른 감정 인식 방법을 나타내는 순서도이다. 먼저, 카메라부에 포함된 적어도 하나 이상의 카메라를 이용하여 사용자를 촬영함으로써, 사용자의 얼굴이 포함된 이미지를 획득한다(S201). S201 단계에 의해 이미지가 획득되면, 딥러닝 학습 모델에 입력하기에 적합하도록 전처리부가 그 획득된 이미지에 대한 전처리를 수행하고(S203), 검출부가 전처리된 이미지를 기반으로 딥러닝 학습 모델을 이용 하여 사용자의 얼굴 영역을 검출한다(S205). 이후, 분류부는 S205 단계에 의해 검출된 얼굴 관련 영역으로부터 특징점을 추출하고, 기저장된 감정별 특 징점 패턴을 기반으로 그 추출된 특징점에 해당하는 감정으로 사용자의 감정을 분류한다. 상술한 본 발명의 일 실시예에 따른 감정 인식 방법은, 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램 (또는 어플리케이션)으로 구현되어 매체에 저장될 수 있다. 도 3은 종래의 멀티레이어로 구성된 인공신경망을 기반으로 필기체를 인식하는 일 예를 나타내는 도면으로, 16X16 크기의 폰트를 갖는 필기체를 인식하는 경우에 대한 것이다. 도 3을 참조하면, 256개의 입력 노드, 100개의 히든 레이어(Hidden Layer), 26개의 출력 노드로 구성된 필기체 인식을 위한 인공신경망의 경우, 필요한 가중치와 바이어스는 총 28326개가 된다. 또한, 폰트의 크기가 커지거 나, 히든 레이어가 2단 이상이거나, 대소문자 또는 숫자까지 구별해야 하는 경우, 파라미터의 개수가 더욱 많아 진다. 즉, 완전 연결 신경망(Fully-connected neural network)의 경우 학습 시간, 망의 크기, 변수의 개수의 문제점이 있었다. 도 4 및 5는 본 발명의 일 실시예에 따른 감정 인식 장치에 적용되는 합성곱 신경망의 구조를 나타내는 도면이 다. 도 4를 참조하면, 합성곱 신경망에서는 앞서 설명한 도 3과 같은 합성곱(Convolution) 연산을 수행한다. 합성곱 연산은 영상처리 분야에서의 필터(Filter) 연산에 해당하며, 영상데이터로부터 특징점(Feature)을 추출하기 위 한 필터를 구현할 때 주로 사용된다. 구체적으로, 도 3과 같이 2차원의 입력데이터가 입력되면, 합성곱 필터(커널)의 윈도우를 일정 간격으로 이동하 며 입력데이터에 적용한다. 이와 같이 모든 데이터에 대하여 수행할 경우, 데이터의 개수는 훨씬 감소되면서도, 원래의 데이터의 특징을 나타낼 수 있는 데이터를 산출하게 되는 것이다. 합성곱 신경망은 공간적으로 인접한 신호들에 대한 상관관계를 비선형 필터를 적용하여 추출하는데, 이러한 비선형 필터를 여러 개 적용하면 다양한 로컬(local) 특징을 추출할 수 있다. 또한, 동일한 계수를 갖는 필터를 영상 전체에 반복적으로 적용하여 변수 의 수를 줄일 수 있다. 이를 위해, 본 발명의 일 실시예에 따른 감정 인식 장치는 CNN 알고리즘은 3X3 사이즈의 필터를 두개 사용 함으로써, 그 변수의 수를 줄일 수 있도록 한다. 구체적으로, 5X5 사이즈의 필터를 사용하는 경우에는 총 25개 의 변수를 갖지만, 3X3 사이즈의 필터를 사용하는 경우에는 9개의 변수를 갖는다. 이로써, 최종적으로 18개의 변수를 갖게 되기 때문에, 변수의 개수가 확연히 감소하는 효과가 있다. 다시 말해, 3X3 사이즈의 필터를 사용 하는 경우, 5X5 사이즈의 필터를 적용한 이미지의 크기와 동일한 이미지의 크기를 갖기 때문에, 동일한 효과를 갖지만, 그 변수가 감소하는 효과가 있는 것이다. 도 6은 본 발명의 일 실시예에 따른 감정 인식 장치에 적용되는 인공신경망의 구조를 나타내는 도면이고, 도 7 은 본 발명의 일 실시예에 따른 감정 인식 장치를 통해 얼굴을 포함하는 이미지를 기반으로 특징점을 추출한 일 예를 나타내는 도면이다. 분류부의 인공신경망은 합성곱 레이어(convolution layer)과 풀링 레이어(pooling layer)로 구성된 합성 곱 신경망을 사용할 수 있다. 구체적인 예로, 분류부의 인공신경망은 특징점 추출을 위해 캐스캐이드 레이 어(cascade layer)를 사용할 수 있다. 도 6에서와 같이 인공신경망이 구성되고, 다양한 레벨의 추상적 특성에 대응하는 다양한 레이어를 학습하는 경우, 첫 번째 레이어는 선형의 가버 특징(Gabor feature)과 유사하게 출력 될 수 있다. 두 번째 레이어는 첫 번째 레이어보다 복잡한 텍스처 특징(texture feature)을 출력할 수 있고, 세 번째 레이어는 두 번째 레이어보다 복잡한 특징(예를 들어, 높은 코, 큰 눈 등)을 출력할 수 있고, 네 번째 레 이어는 특정한 얼굴의 속성(웃음, 소리침, 파란 눈 등)을 출력할 수 있다. 또한, 이미지의 특징점과 미리 설정 된 종류의 감정을 기초로 인공신경망을 학습하는 경우, 도 7과 같이 사용자의 얼굴(안면)에 대한 이미지로부터 사용자의 감정을 추정할 수 있다. 도 8은 본 발명의 일 실시예에 따른 감정 인식 장치를 통해 특징점 패턴을 기반으로 감정을 분류하는 일 예를 나타내는 도면이다. 도 8을 참조하면, 미리 설정된 7개의 감정(중립, 행복, 놀람, 화남, 싫음, 두려움, 슬픔) 각각의 확률값으로 결 과가 산출될 수 있으며, 가장 높은 확률(93%)로 산출된 화남(Angry)을 사용자의 감정으로 추정하여, 사용자의 감정을 화남으로 분류할 수 있다. 일 실시예에서, 분류기의 인공신경망 학습을 위한 데이터셋으로는 Cohn-Kanade dataset, Japanese Female Facial Expression dataset, FER2013 dataset, MMI dataset, RAVDESS dataset, AffectNet dataset 등이 활용 될 수 있다. 일 실시예에서, 도면에 도시되지는 않았으나 본 발명의 일 실시예에 따른 감정 인식 장치는 출력부를 더 포함할 수 있다. 여기서, 출력부는 분류부에서 산출한 결과값을 디스플레이 화면을 통해 시각적으로 출력하거나, 음성 출력부를 통해 출력할 수 있으나, 이에 제한되지 않는다. 일 실시예에서, 도면에 도시되지는 않았으나 본 발명의 일 실시예에 따른 감정 인식 장치는 저장부를 더 포함할 수 있다. 여기서, 저장부는 획득되는 이미지는 물론, 각종 데이터들을 저장할 수 있다. 상기 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, 기계어 등 의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필요한 기능 들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들을 상기 컴퓨터 의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있다. 또한, 이러 한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함 할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다 른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하는지 등에 대 한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모델로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모델은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에"}
{"patent_id": "10-2021-0049875", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상주할 수도 있다.이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2021-0049875", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 감정 인식 장치의 구성을 나타내는 블록도이다. 도 2는 본 발명의 일 실시예에 따른 감정 인식 방법을 나타내는 순서도이다.도 3은 종래의 멀티레이어로 구성된 인공신경망을 기반으로 필기체를 인식하는 일 예를 나타내는 도면이다. 도 4 및 도 5는 본 발명의 일 실시예에 따른 감정 인식 장치에 적용되는 합성곱 신경망의 구조를 나타내는 도면 이다. 도 6은 본 발명의 일 실시예에 따른 감정 인식 장치에 적용되는 인공신경망의 구조를 나타내는 도면이다. 도 7은 본 발명의 일 실시예에 따른 감정 인식 장치를 통해 얼굴을 포함하는 이미지를 기반으로 특징점을 추출 한 일 예를 나타내는 도면이다. 도 8은 본 발명의 일 실시예에 따른 감정 인식 장치를 통해 특징점 패턴을 기반으로 감정을 분류하는 일 예를 나타내는 도면이다."}
