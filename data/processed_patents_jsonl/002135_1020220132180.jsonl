{"patent_id": "10-2022-0132180", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0166836", "출원번호": "10-2022-0132180", "발명의 명칭": "가변되는 내부 메모리를 포함하는 신경 프로세싱 유닛", "출원인": "주식회사 딥엑스", "발명자": "박정부"}}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 메모리 유닛들을 포함하는 내부 메모리; 및인공신경망모델의 복수의 연산 단계가 설정된 머신 코드의 오퍼레이션 스케줄링에 기반하여, 복수의 메모리 유닛들 각각에 입력 특징맵 도메인, 가중치 도메인, 및 출력 특징맵 도메인 중 적어도 하나의 도메인의 데이터의읽기 및 쓰기 동작을 제어하도록 구성된 컨트롤러를 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 머신 코드는 복수의 연산 단계들 대한 입력 특징맵 데이터, 가중치 데이터 및 출력 특징맵 데이터들의 정보를 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 머신 코드는 상기 인공신경망모델의 복수의 연산 단계 각각에 대한 입력 특징맵 데이터의 용량 정보, 가중치 데이터의 용량 정보 및 출력 특징맵 데이터의 용량 정보를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 머신 코드는 상기 인공신경망모델의 복수의 연산 단계들 중 동일한 데이터 지역성을 가지는 연산 단계에관한 정보를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 머신 코드는 인공신경망 데이터 지역성에 기초한 상기 인공신경망모델의 복수의 연산 단계 각각의 연산 순서 정보를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,메인 메모리로부터 데이터를 읽어들여, 상기 내부 메모리에 입력 특징맵 데이터 및 가중치 데이터를 기입하도록구성된 DMA(Direct Memory Access); 및상기 내부 메모리로부터 상기 입력 특징맵 데이터 및 상기 가중치 데이터를 입력 받아 연산하여, 출력 특징맵데이터를 생성하도록 구성된, 인공지능(AI) 연산부를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,입력 특징맵 데이터 및 가중치 데이터의 합성곱 연산을 수행하여 출력 특징맵 데이터를 생성하도록 구성된 적어도 하나의 프로세싱 엘리먼트를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,공개특허 10-2023-0166836-3-상기 머신 코드에 기초하여, 상기 복수의 메모리 유닛들 각각을 선택하도록 구성된 제1 내지 제3 선택기; 및 상기 제1 선택기를 통해 입력 특징맵 데이터를 입력 받도록 구성된 제1 입력부, 상기 제2 선택기를 통해 가중치데이터를 입력 받도록 구성된 제2 입력부, 및 제3 선택기를 통해 출력 특징맵 데이터를 출력하도록 구성된 출력부를 포함하는 프로세싱 엘리먼트를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 내부 메모리는,상기 복수의 메모리 유닛들과 연결된 가중치 멀티플렉서, 입력 특징맵 멀티플렉서 및 출력 특징맵 디멀티플렉서를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 도메인, 제2 도메인, 및 제3 도메인의 데이터를 저장하도록 구성된 복수의 메모리 유닛들을 포함하는 내부메모리;상기 제1 도메인의 데이터를 입력 받도록 구성된 제1 입력부, 상기 제2 도메인의 데이터를 입력 받도록 구성된제2 입력부, 및 제3 도메인의 데이터를 출력하도록 구성된 출력부를 포함하는, AI 연산부;상기 복수의 메모리 유닛들 중 상기 제1 도메인의 데이터가 저장된 메모리 유닛과 상기 제1 입력부를 연결하도록 구성된, 제1 선택기;상기 복수의 메모리 유닛들 중 상기 제2 도메인의 데이터가 저장된 메모리 유닛과 상기 제2 입력부를 연결하도록 구성된, 제2 선택기; 및상기 복수의 메모리 유닛들 중 상기 제3 도메인의 데이터가 저장될 메모리 유닛과 상기 출력부를 연결하도록 구성된, 제3 선택기를 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,인공신경망모델의 동일한 데이터 지역성을 분석한 머신 코드에 의해서 상기 제1 내지 제3 선택기를 제어하도록구성된 컨트롤러를 더 포함하고,상기 제1 선택기는, 상기 머신 코드에 정의된 연산 순서에 따라, 상기 제1 도메인의 데이터 중 적어도 일부를상기 AI 연산부에 입력하고,상기 제2 선택기는, 상기 머신 코드에 정의된 연산 순서에 따라, 상기 제2 도메인의 데이터 중 적어도 일부를상기 AI 연산부에 입력하고, 그리고상기 제3 선택기는, 상기 머신 코드에 정의된 연산 순서에 따라, 상기 제3 도메인의 데이터 중 적어도 일부를상기 복수의 메모리 유닛들 중 적어도 하나에 출력하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10 항에 있어서,상기 복수의 메모리 유닛들 각각은 서로 동일하거나 또는 서로 다른 소정의 메모리 용량을 가지도록 구성되고, 상기 복수의 메모리 유닛들 각각의 메모리 용량을 고려하여 각 연산 단계마다 상기 복수의 메모리 유닛들 각각에 상기 제1 내지 제3 도메인을 설정하도록 구성된 머신 코드를 실행하도록 구성된 컨트롤러를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10 항에 있어서,상기 내부 메모리를 제어하도록 구성된 컨트롤러를 더 포함하고,공개특허 10-2023-0166836-4-상기 컨트롤러는 동일한 데이터 지역성을 분석한 머신 코드에 기반하여, 다음 연산 단계에서 상기 제3 도메인의데이터를 제1 도메인의 데이터로 재설정 하도록 구성된, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10 항에 있어서,상기 제1 도메인은 입력 특징맵이고, 상기 제2 도메인은 가중치이고, 제3 도메인은 출력 특징맵이고, 다음 연산 단계에서 상기 입력 특징맵과 동일한 데이터 지역성을 가지는 상기 출력 특징맵이 재사용 되도록, 상기 제1 내지 제3 선택기를 이어지는 연산 단계들마다 각각 제어하도록 구성된 컨트롤러를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10 항에 있어서,상기 복수의 메모리 유닛들 중 상기 제1 도메인으로 설정된 메모리 유닛들은 제1 메모리 그룹이고, 상기 제2 도메인으로 설정된 메모리 유닛들은 제2 메모리 그룹이고, 상기 제3 도메인으로 설정된 메모리 유닛들은 제3 메모리 그룹인, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10 항에 있어서,상기 내부 메모리는,인공신경망모델의 연산에 지속적으로 필요한 고정되는 가중치, 입력 특징맵 및 출력 특징맵 중 어느 하나를 저장하도록 구성된 프리패치 메모리를 더 포함하는, 신경 프로세싱 유닛."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "적어도 하나의 인공신경망모델의 적어도 일부 데이터를 저장하도록 구성된 메인 메모리; 및상기 적어도 하나의 인공신경망모델의 적어도 일부 데이터를 특징맵 및 가중치로 구분하여 복수의 메모리 유닛들 중 특정 유닛에 선택적으로 저장하도록 구성된 가변 메모리; 상기 메인 메모리와 상기 가변 메모리 사이의 메모리 오퍼레이션을 제어하도록 구성된 직접 메모리 액세스(DMA)회로부; 및상기 특징맵과 상기 가중치를 상기 가변 메모리에서 입력 받아 인공신경망 추론 연산을 처리하도록 구성된 AI연산부;를 포함하는 신경 프로세싱 유닛;을 포함하는, 시스템."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서,상기 신경 프로세싱 유닛은, 상기 적어도 하나의 인공신경망모델의 적어도 하나의 동일한 데이터 지역성 정보를기초로, 상기 메인 메모리와 상기 가변 메모리 사이의 상기 특징맵의 중복된 데이터 통신을 저감하도록 컴파일된 머신 코드에 의해서 실행되도록 구성된, 시스템."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17 항에 있어서,상기 적어도 하나의 인공신경망모델이 컴파일 된 머신 코드에 의해서 상기 가변 메모리의 특징맵을 재사용하여특징맵 재사용이 없는 종래 기술 대비 소비 전력이 상대적으로 더 저감된, 시스템."}
{"patent_id": "10-2022-0132180", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,상기 적어도 하나의 인공신경망모델이 컴파일 된 머신 코드에 의해서 상기 가변 메모리의 특징맵을 재사용하여공개특허 10-2023-0166836-5-특징맵 재사용이 없는 종래 기술 대비 추론 연산 처리 시간이 상대적으로 더 저감된, 시스템."}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 예시에 따르면, 신경 프로세싱 유닛은 복수의 메모리 유닛들을 포함하는 내부 메모리; 및 인공신경 망모델의 복수의 연산 단계가 설정된 머신 코드의 오퍼레이션 스케줄링에 기반하여, 복수의 메모리 유닛들 각각 에 입력 특징맵 도메인, 가중치 도메인, 및 출력 특징맵 도메인 중 적어도 하나의 도메인의 데이터의 읽기 및 쓰 기 동작을 제어하도록 구성된 컨트롤러;를 포함할 수 있다."}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 가변되는 내부 메모리를 포함하는 신경 프로세싱 유닛 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간은 인식(recognition), 분류(classification), 추론(inference), 예측(predict), 조작/의사결정 (control/decision making) 등을 할 수 있는 지능을 갖추고 있다. 인공지능(Artificial Intelligence, AI)은 인간의 지능을 인공적으로 모방하는 것을 의미한다. 인간의 뇌는 뉴런(Neuron)이라는 수많은 신경세포로 이루어져 있다. 각각의 뉴런은 시냅스(synapse)라고 불리는 연결부위를 통해 수백 개에서 수천 개의 다른 뉴런들과 연결되어 있다. 인간의 지능을 모방하기 위하여, 생물학 적 뉴런의 동작원리와 뉴런 간의 연결 관계를 모델링한 것을, 인공신경망(Artificial Neural Network, ANN) 모 델이라고 한다. 즉, 인공신경망모델은 뉴런들을 모방한 노드들을 레이어(layer: 계층) 구조로 연결시킨 시스템 이다."}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공신경망모델은 레이어 수에 따라 '단층 신경망'과 '다층 신경망'으로 구분된다. 일반적인 다층 신경망은 입 력 레이어와 은닉 레이어, 출력 레이어로 구성된다. 입력 레이어(input layer)는 입력 데이터를 받아들이는 레 이어다. 은닉 레이어(hidden layer)는 입력 레이어와 출력 레이어 사이에 위치하며 입력 레이어로부터 신호를 받아 특징을 추출하여 출력 레이어로 전달하는 레이어이다. 출력 레이어(output layer)는 은닉 레이어로부터 신 호를 받아 외부로 출력하는 레이어이다. 다층 신경망에서 보다 높은 인공 지능을 구현하기 위해 은닉 레이어들의 개수를 늘린 심층신경망(Deep Neural Network, DNN)에는 여러 종류가 있다. 한편 합성곱 신경망(Convolutional Neural Network, CNN)이 입력 데이터 의 특징들을 추출하고, 추출된 특징들의 패턴을 파악하기에 용이한 것으로 알려져 있다. CNN 기반의 인공신경망모델은 합성곱 연산, 활성화 함수 연산, 풀링(pooling) 연산, 스트라이드(stride) 연산, 배치 정규화(batch-normalization) 연산, 스킵 커넥션(skip-connection) 연산, 접합(concatenation) 연산, 양 자화(quantization) 연산, 클리핑(clipping) 연산, 패딩(padding) 연산 등이 인공신경망의 구조(architectur e)에 따라 선별되어 처리될 수 있다. 인공신경망모델의 구조는 다수의 레이어들을 포함하도록 설계될 수 있다. 인공신경망모델의 각각의 레이어는 합 성곱 연산, 활성화 함수 연산, 풀링 연산, 스트라이드 연산, 배치 정규화 연산, 스킵 커넥션 연산, 접합 연산, 양자화 연산, 클리핑 연산, 패딩 연산 중 적어도 일부를 처리하도록 설계될 수 있다. 인공신경망모델의 각각의 레이어들 중 일부는 서로 직렬로 연결될 수 있다. 인공신경망모델의 각각의 레이어들 중 일부는 서로 병렬로 분기될 수 있다. 인공신경망모델의 각각의 레이어들 중 일부는 서로 병렬로 연결될 수 있다. 예를 들어, 합성곱 신경망(CNN)의 레이어 각각에서, 입력 데이터에 해당하는 입력 특징맵(Input feature map)과 가중치(Weight)에 해당하는 커널(kernel)은 복수의 채널로 구성된 행렬일 수 있다. 입력 특징맵과 커널의 합성 곱 연산이 수행되며, 각 채널에서 합성곱 연산과 풀링 출력 특징맵(output feature map)이 생성되고, 출력 특징 맵에 활성화 함수를 적용하여 해당 채널의 활성화맵(activation map)이 생성된다. 이후, 활성화맵에 대한 풀링 이 적용될 수 있다. 여기서 포괄적으로 활성화맵은 출력 특징맵으로 지칭될 수 있다. 본 개시의 발명자들은 상술한 인공신경망모델 처리에 최적화된 인공신경망 메모리 시스템의 프로세서인, 신경 프로세싱 유닛(neural processing unit; NPU)에 대해서도 연구하였다. 신경 프로세싱 유닛(NPU)은 상술한 인공신경망 연산에 필요한 합성곱 연산, 활성화 함수 연산, 풀링 연산, 스트 라이드 연산, 배치 정규화 연산, 스킵 커넥션 연산, 접합 연산, 양자화 연산, 클리핑 연산, 패딩 연산에 최적화 된 각각의 처리 회로를 포함하도록 구성될 수 있다. 본 개시의 발명자들은 보다 구체적으로 합성곱 신경망(CNN) 모델 처리에 최적화된 신경 프로세싱 유닛(neural processing unit; NPU)의 메모리 시스템에 대해서도 연구하였다. 신경 프로세싱 유닛(NPU)은 합성곱 연산을 수행하는 프로세싱 엘리먼트와 합성곱 연산에 필요한 데이터를 저장 하는 메모리를 포함한다. 신경 프로세싱 유닛(NPU)의 메모리는 입력 특징맵(Input feature map), 가중치 (Weight) 및 출력 특징맵(output feature map)을 저장해야 할 수 있다. 한편, 신경 프로세싱 유닛(NPU)을 구현하기 위한 하드웨어는 인공지능 전용 ASIC(Application Specific Integrated Circuit)일 수 있다. 인공지능 전용 ASIC에는 프로세싱 엘리먼트를 형성하는 영역을 확보하기 위하 여, 메모리가 형성되는 영역이 제한될 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 특히, 인공지능 전용 ASIC의 메모리의 용량에 비례하여 파운드리(foundry) 업체를 통해 3nm 내지 28nm 공정으로 대량 생산되는 인공지능 전용 ASIC의 양산 수율이 저하될 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 따라서 신경 프로세싱 유닛의 메모리 용량을 저감하여 인공지능 전용 ASIC의 생산 비용을 절감하고 인공지능 전 용 ASIC의 생산성을 향상시킬 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 하지만, 인공지능 전용 ASIC의 메모리의 용량이 저감될수록 특징맵과 가중치를 전용 ASIC에 저장할 공간이 부족 해진다. 따라서 메인 메모리에 특징맵과 가중치가 더 잦은 빈도로 타일링(tiling) 해서 저장해야 한다는 사실을 본 개시의 발명자들은 인식하였다. 또한, 인공지능 전용 ASIC과 메인 메모리 사이의 데이터 전송 량이 증가할수록 시스템의 필요 전력이 급증한다 는 사실을 본 개시의 발명자들은 인식하였다. 또한, 인공지능 전용 ASIC의 메모리가 종래의 단일 도메인을 가질 경우, 인공지능 전용 ASIC의 메모리는 프로세 싱 엘리먼트에 효율적으로 특징맵과 가중치를 제공할 수 없다는 사실을 본 개시의 발명자들은 인식하였다. 부연 설명하면, 종래의 단일 도메인의 메모리는 하나의 프로세싱 엘리먼트에 한 클럭의 가중치 데이터를 제공하 고, 다음 클럭에 한 클럭의 입력 특징맵 데이터를 순차적으로 제공할 수 있다. 그 다음 클럭에서 종래의 단일 도메인의 메모리는 프로세싱 엘리먼트로부터 한 클럭의 출력 특징맵 데이터를 제공받을 수 있다. 즉, 상기 메모 리 구조에 따르면, 프로세싱 엘리먼트는 세번의 클럭이 있어야 한번의 Multiply-Accumulate(MAC) 연산을 처리할 수 있다. 이에, 종래의 단일 도메인의 메모리는 처리 속도 관점에서 인공신경망 연산에 비효율적일 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 따라서, 본 개시의 발명자들은 특징맵과 가중치를 동시에 제공하기 위한 멀티 도메인의 메모리를 구현하였다. 즉, 본 개시의 발명자들은 인공지능 전용 ASIC의 메모리가 특징맵 도메인과 가중치 도메인을 가지도록 구현하였 다. 이에, 프로세싱 엘리먼트는 각각의 도메인의 메모리에서 하나의 특징맵과 하나의 가중치를 하나의 클럭에 제공받을 수 있을 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 즉, 메모리 구조에 의해서 프로세싱 엘 리먼트는 하나의 클럭에 한번의 MAC 연산을 처리할 수 있다. 이에, 멀티 도메인의 메모리는 처리 속도 관점에서 인공신경망 연산에 효율적일 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 하지만, 인공지능 전용 ASIC의 메모리 내부에 독립적인 특징맵 메모리 및 가중치 메모리를 구현할 경우, 각 도 메인의 메모리 용량은 고정된다는 사실을 본 개시의 발명자들은 인식하였다. 한편, 인공신경망모델의 구조를 분석하면, 인공신경망모델의 각각의 레이어는 상이한 크기의 특징맵과 상이한 크기의 가중치를 가진다. 이러한 경우 특정 도메인의 데이터는 다른 도메인의 메모리에 저장되지 못할 수 있다 는 사실을 본 개시의 발명자들은 인식하였다. 즉, 인공신경망모델의 구조에 따라서 인공지능 전용 ASIC의 멀티 도메인 메모리의 가동률(utilization rate)(%)이 상당히 저하될 수 있다는 사실을 본 개시의 발명자들은 인식하 였다. 예를 들면, 도 8에 도시된 일 예시의 인공신경망모델의 경우를 참조하면, 각 레이어 별로 특징맵과 가중 치의 데이터 크기가 상당히 달라 질 수 있다는 것을 본 개시의 발명자들은 인식하였다. 특히 도 8의 제1 레이어 의 경우 가중치의 데이터 크기가 특징맵에 비해서 상당히 작기 때문에, 가중치 도메인의 메모리는 실질적으로 사용될 수 없다는 사실을 본 개시의 발명자들은 인식하였다. 한편 도 8의 제1 레이어의 경우 특징맵의 데이터 크기가 가중치에 비해서 상대적으로 매우 크기 때문에, 특징맵 도메인의 메모리가 실질적으로 부족할 수 있는 경우가 발생한다는 사실을 본 개시의 발명자들은 인식하였다. 이에, 인공신경망모델의 연산 시 멀티 도메인의 메모리를 효과적으로 조절하는 것이 신경망 연산 처리 속도 향 상의 핵심이라고 본 개시의 발명자들은 인식하였다. 즉, 인공신경망모델을 처리할 때 신경 프로세싱 유닛(NPU)이 멀티 도메인의 메모리 제어를 적절히 하지 못할 경 우, 필요한 데이터를 사전에 캐슁(caching)하지 못할 수 있다. 이러한 경우, 신경 프로세싱 유닛(NPU)의 메모리 실효 대역폭 감소 및/또는 메모리의 데이터 제공 지연이 빈번히 발생할 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 또한 이러한 경우 신경 프로세싱 유닛(NPU)이 처리할 데이터를 공급받지 못하는 기아(starvation) 또는 대기(idle) 상태가 되어 실제연산을 할 수 없게 되어 연산 성능이 저하된다는 사실을 본 개시의 발명자들 은 인식하였다. 더 나아가서, 인공신경망모델의 구조를 분석하면, 사전에 신경 프로세싱 유닛(NPU)에게 필요한 데이터를 프리패 치(prefetch) 할 수 있다. 이에 신경 프로세싱 유닛(NPU)이 처리할 데이터를 공급받지 못하는 기아(starvation) 또는 대기(idle) 상태를 저감할 수 있다는 사실을 본 개시의 발명자들은 인식하였다. 본 개시가 해결하고자 하는 과제는, 내부 메모리를 인공신경망모델의 데이터 도메인에 기초하여 가변적으로 제 어할 수 있는 신경 프로세싱 유닛 및 이를 동작시키는 방법을 제공하는 것이다. 본 개시가 해결하고자 하는 다른 과제는, 신경 프로세싱 유닛에서 메모리의 크기를 최적화 시킬 수 있는 신경 프로세싱 유닛 및 이를 동작시키는 방법을 제공하는 것이다. 본 개시가 해결하고자 하는 다른 과제는, 내부 메모리를 인공신경망모델의 각 레이어 별로 데이터 도메인에 기 초하여 가변적으로 제어할 수 있는 신경 프로세싱 유닛 및 이를 동작시키는 방법을 제공하는 것이다. 본 개시가 해결하고자 하는 다른 과제는, 인공신경망모델의 연산 순서 및 데이터 도메인에 기초하여 내부 메모 리의 각 도메인의 용량 설정 스케줄링이 가능한 신경 프로세싱 유닛 및 이를 동작시키는 방법을 제공하는 것이다. 본 개시가 해결하고자 하는 다른 과제는, 메인 메모리의 데이터 전송 량이 저감 가능하도록 내부 메모리를 가변 적으로 제어할 수 있는 신경 프로세싱 유닛 및 이를 동작시키는 방법을 제공하는 것이다. 본 개시가 해결하고자 하는 다른 과제는, 신경 프로세싱 유닛(NPU)가 처리할 인공신경망모델의 구조를 분석하고, 가변 메모리의 메모리 유닛들을 제어하여, 이전 레이어의 출력 특징맵을 다음 레이어의 입력 특징맵 으로 재사용 하도록 가변 메모리의 메모리 유닛들을 제어하는 함으로써, 인공신경망모델의 연산 속도를 향상시 킬 수 있다. 다만, 본 개시의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 복수의 메모리 유닛들을 포함하는 내부 메모리; 및 인공신경 망모델의 복수의 연산 단계가 설정된 머신 코드의 오퍼레이션 스케줄링에 기반하여, 복수의 메모리 유닛들 각각 에 입력 특징맵 도메인, 가중치 도메인, 및 출력 특징맵 도메인 중 적어도 하나의 도메인의 데이터의 읽기 및 쓰기 동작을 제어하도록 구성된 컨트롤러;를 포함할 수 있다. 본 개시의 예시들에 따르면, 상기 머신 코드는 복수의 연산 단계들 대한 입력 특징맵, 가중치 및 출력 특징맵들 의 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 머신 코드는 인공신경망모델의 복수의 연산 단계 각각에 대한 입력 특징맵의 용량 정보, 가중치의 용량 정보 및 출력 특징맵의 용량 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 머신 코드는 인공신경망모델의 복수의 연산 단계들 중 동일한 데이터 지역성을 가 지는 연산 단계에 관한 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 머신 코드는 인공신경망 데이터 지역성에 기초한 인공신경망모델의 복수의 연산 단 계 각각의 연산 순서 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 메인 메모리로부터 데이터를 읽어들여, 내부 메모리에 입력 특징맵 데이터 및 가중치 데이터를 기입하도록 구성된 DMA(Direct Memory Access); 및 내부 메모리로부터 입력 특징맵 데이터 및 가중치 데이터를 입력 받아 연산하여 출력 특징맵을 생성하도록 구성된, 인공지능(AI) 연산부를 더 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 입력 특징맵 데이터 및 가중치 데이터의 합성곱 연산을 수행 하여 출력 특징맵 데이터를 생성하도록 구성된 적어도 하나의 프로세싱 엘리먼트를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 머신 코드에 기초하여, 복수의 메모리 유닛들 각각을 선택하 도록 구성된 제1 내지 제3 선택기; 및 제1 선택기를 통해 입력 특징맵 데이터를 입력 받도록 구성된 제1 입력부, 제2 선택기를 통해 가중치 데이터를 입력 받도록 구성된 제2 입력부, 및 제3 선택기를 통해 출력 특징 맵 데이터를 출력하도록 구성된 출력부를 포함하는 프로세싱 엘리먼트를 포함할 수 있다. 본 개시의 예시들에 따르면, 내부 메모리는, 복수의 메모리 유닛들과 연결된 가중치 멀티플렉서, 입력 특징맵 멀티플렉서 및 출력 특징맵 디멀티플렉서를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 제1 도메인, 제2 도메인, 및 제3 도메인의 데이터를 저장하 도록 구성된 복수의 메모리 유닛들을 포함하는 내부 메모리; 제1 도메인의 데이터를 입력 받도록 구성된 제1 입 력부, 제2 도메인의 데이터를 입력 받도록 구성된 제2 입력부, 및 제3 도메인의 데이터를 출력하도록 구성된 출 력부를 포함하는, AI 연산부; 복수의 메모리 유닛들 중 제1 도메인의 데이터가 저장된 메모리 유닛과 제1 입력 부를 연결하도록 구성된, 제1 선택기; 복수의 메모리 유닛들 중 제2 도메인의 데이터가 저장된 메모리 유닛과 제2 입력부를 연결하도록 구성된, 제2 선택기; 및 복수의 메모리 유닛들 중 제3 도메인의 데이터가 저장될 메모 리 유닛과 출력부를 연결하도록 구성된, 제3 선택기를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 인공신경망모델의 동일한 데이터 지역성을 분석한 머신 코드 에 의해서 제1 내지 제3 선택기를 제어하도록 구성된 컨트롤러를 포함할 수 있다. 본 개시의 예시들에 따르면, 제1 선택기는, 머신 코드에 정의된 연산 순서에 따라, 제1 도메인의 데이터 중 적 어도 일부를 AI 연산부에 입력하고, 제2 선택기는, 머신 코드에 정의된 연산 순서에 따라, 제2 도메인의 데이터 중 적어도 일부를 AI 연산부에 입력하고, 그리고 제3 선택기는, 머신 코드에 정의된 연산 순서에 따라, 제3 도 메인의 데이터 중 적어도 일부를 복수의 메모리 유닛들 중 적어도 하나에 출력하도록 구성될 수 있다. 본 개시의 예시들에 따르면, 복수의 메모리 유닛들 각각은 서로 동일하거나 또는 서로 다른 소정의 메모리 용량 을 가지도록 구성될 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 복수의 메모리 유닛들 각각의 메모리 용량을 고려하여 각 연 산 단계마다 복수의 메모리 유닛들 각각에 제1 내지 제3 도메인을 설정하도록 구성된 머신 코드를 실행하도록 구성된 컨트롤러를 더 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 내부 메모리를 제어하도록 구성된 컨트롤러를 더 포함할 수 있다. 컨트롤러는 동일한 데이터 지역성을 분석한 머신 코드에 기반하여, 다음 연산 단계에서 제3 도메인의 데 이터를 제1 도메인의 데이터로 재설정 하도록 구성될 수 있다. 본 개시의 예시들에 따르면, 제1 도메인은 입력 특징맵이고, 제2 도메인은 가중치이고, 제3 도메인은 출력 특징 맵일 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 다음 연산 단계에서 입력 특징맵과 동일한 데이터 지역성을 가지는 출력 특징맵이 재사용 되도록, 제1 내지 제3 선택기를 이어지는 연산 단계들 마다 각각 제어하도록 구성 된 컨트롤러를 포함할 수 있다. 본 개시의 예시들에 따르면, 복수의 메모리 유닛들 중 제1 도메인으로 설정된 메모리 유닛들은 제1 메모리 그룹 이고, 제2 도메인으로 설정된 메모리 유닛들은 제2 메모리 그룹이고, 제3 도메인으로 설정된 메모리 유닛들은 제3 메모리 그룹일 수 있다. 본 개시의 예시들에 따르면, 내부 메모리는 인공신경망모델의 연산에 지속적으로 필요한 고정되는 가중치, 입력 특징맵 및 출력 특징맵 중 어느 하나를 저장하도록 구성된 프리패치 메모리를 포함할 수 있다. 본 개시의 예시들에 따르면, 시스템은 적어도 하나의 인공신경망모델의 적어도 일부 데이터를 저장하도록 구성 된 메인 메모리; 및 적어도 하나의 인공신경망모델의 적어도 일부 데이터를 특징맵 및 가중치로 구분하여 복수 의 메모리 유닛들 중 특정 유닛에 선택적으로 저장하도록 구성된 가변 메모리; 메인 메모리와 가변 메모리 사이 의 메모리 오퍼레이션을 제어하도록 구성된 직접 메모리 액세스(DMA) 회로부; 및 특징맵과 가중치를 가변 메모 리에서 입력 받아 인공신경망 추론 연산을 처리하도록 구성된 AI 연산부;를 포함하는 신경 프로세싱 유닛을 포함할 수 있다 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은, 적어도 하나의 인공신경망모델의 적어도 하나의 동일한 데 이터 지역성 정보를 기초로, 메인 메모리와 가변 메모리 사이의 특징맵의 중복된 데이터 통신을 저감하도록 컴 파일 된 머신 코드에 의해서 실행되도록 구성될 수 있다. 본 개시의 예시들에 따르면, 시스템은 적어도 하나의 인공신경망모델이 컴파일 된 머신 코드에 의해서 가변 메 모리의 특징맵을 재사용하여 특징맵 재사용이 없는 종래 기술 대비 소비 전력이 상대적으로 더 저감될 수 있다. 본 개시의 예시들에 따르면, 시스템은 적어도 하나의 인공신경망모델이 컴파일 된 머신 코드에 의해서 가변 메 모리의 특징맵을 재사용하여 특징맵 재사용이 없는 종래 기술 대비 추론 연산 처리 시간이 상대적으로 더 저감 될 수 있다. 기타 예시의 구체적인 사항들은 상세한 설명 및 도면들에 포함된다."}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 동시에 인공신경망 연산에 필요한 가중치 및 특징맵 데이터를 멀티 도메인의 내부 메모리에 서 프로세싱 엘리먼트로 제공함으로써, 신경 프로세싱 유닛의 처리 속도가 향상될 수 있다. 본 개시에 따르면, 신경 프로세싱 유닛의 내부 메모리가 조절 가능한 데이터 도메인을 가짐으로써, 내부 메모리 의 가동률(%)을 최적화할 수 있다. 본 개시에 따르면, 신경 프로세싱 유닛의 내부 메모리가 조절 가능한 데이터 도메인 크기를 가짐으로써, 인공신 경망모델의 각 레이어 별 연산 시 내부 메모리 가동률(%)을 최적화할 수 있다. 본 개시에 따르면, 내부 메모리에 저장되는 데이터를 가변적으로 제어함으로써, 메모리 가동률(%)을 향상시킬 뿐만 아니라, 하나의 레이어에서 연산에 사용되지 않는 불필요한 데이터를 저장하지 않을 수 있다. 또한, 본 개시에 따르면, 최소한의 메모리 크기로 최대 저장 효율을 달성할 수 있어, 더 우수한 캐슁 성능을 제 공할 수 있다. 또한, 본 개시의 내부 메모리를 포함하는 신경 프로세싱 유닛에서 비효율적으로 메모리 크기를 증가시킬 필요가 없어짐으로써, ASIC 칩의 제조 수율이 올라갈 수 있다. 또한, 본 개시에서 내부 메모리 크기가 최적화됨으로써, 신경 프로세싱 유닛의 소비 전력 또한 감소될 수 있는 효과가 있다. 또한, 본 개시에 따르면, 신경 프로세싱 유닛과 메인 메모리의 데이터 전송 량이 저감 가능하도록 내부 메모리 를 가변적으로 제어하여 시스템의 소비전력을 저감할 수 있다. 본 개시가 해결하고자 하는 다른 과제는, 인공신경망모델의 각 레이어 별로 데이터 도메인에 기초하여 내부 메 모리의 용량 할당을 가변적으로 제어할 수 있는 신경 프로세싱 유닛 및 이를 동작시키는 방법을 제공하는 것이다. 또한 본 개시에 따르면, 인공신경망모델의 연산 순서 및 데이터 도메인에 기초하여 내부 메모리의 각 도메인의 용량 설정을 스케줄링을 하여, 신경 프로세싱 유닛의 성능을 향상시킬 수 있다. 또한, 본 개시에서 따르면, 신경 프로세싱 유닛이 이전 레이어의 출력 특징맵을 다음 레이어의 입력 특징맵으로 재사용 하도록 가변 메모리의 메모리 유닛들을 제어할 수 있다. 이에 메인 메모리와 가변 메모리 사이의 데이터 통신 량을 저감하고, 신경 프로세싱 유닛의 연산 속도를 향상시킬 수 있다. 개시에 따른 효과는 이상에서 예시된 내용에 의해 제한되지 않으며, 더욱 다양한 효과들이 본 개시 내에 포함된 다."}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것이다. 본 개시의 개념에 따른 실시 예들은 다양한 형태로 실시될 수 있으며 본 개시의 개념에 따른 실시 예들은 다양 한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된 다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있으므로 특정 실시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따 른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직 접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을한정하지 않는다. 예를 들면, 제1 사용자 기기와 제2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리범위를 벗어나지 않으면서 제1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 바꾸어 명명될 수 있다. 본 개시에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 예시의 범위를 한정하 려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인"}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술분야에서 통상의 지식을 가진 자에 의해 일반 적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시에 사용된 용어들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해 석될 수 없다. 본 개시에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 본 개시의 여러 예시들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하며, 당업자가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 예시들이 서로에 대하여 독립적으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다. 각 예시를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더 욱 명확히 전달하기 위함이다. 이하, 첨부한 도면을 참조하여 본 개시의 예시를 상세하게 설명한다. 도 1은 본 개시의 일 예시에 따른 가변 되는 가변 메모리를 포함하는 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 보다 구체적으로 도 1에서는 가변 메모리를 포함하는 신경 프로세싱 유닛 뿐만 아니라, 신경 프로세싱 유닛의 연산을 위한 복수의 주변 기기들을 추가로 도시하였다. 이에, 신경 프로세싱 유닛 및 복수의 주변 기기들은 시 스템(system)으로 지칭될 수 있다. 시스템의 일부 구성요소는 시스템 온칩(SoC)으로 구성될 수 있다. 도 1을 참조하면, 신경 프로세싱 유닛(Neural Processing Unit, NPU, 1000)은 프로세서(Processor, 2000), 메 인 메모리(Main Memory, 3000), 이미지 센서(Image Sensor, 4000), 및 디코더(Decoder, 5000)와 통신하여 다양 한 인공신경망 추론 기능을 수행하도록 구성될 수 있다. 신경 프로세싱 유닛, 프로세서, 메인 메모리, 이미지 센서, 및 디코더 등은 독 립적인 회로로 형성될 수 있으나, 이에 제한되지 않는다. 상술한 각각의 구성요소들은 그 동작 기능으로 구분한 것으로, 각각의 구성 요소는 회로 기판, 실리콘 기판, 저항 소자, 트랜지스터 등으로 구현될 수 있다. 상술한 프로세서(Processor), 메인 메모리(Main Memory), 이미지 센서(Image Sensor), 및 디코더(Decoder) 각각은 버스를 통해 통신하여 신경 프로세싱 유닛과 데이터를 주고받을 수 있다. 단, 이에 제한되지 않으며, 신경 프로세싱 유닛은 상술한 구성요소들 중 적어도 하나와 직접 연결 되도록 구성되는 것도 가능하다.신경 프로세싱 유닛는 인공신경망모델의 동작을 위해 특화된 프로세서이다. 특히, 신경 프로세싱 유닛 는 인공신경망모델에서 대부분의 연산량을 차지하는 합성곱 연산을 위해 특화될 수 있다. 신경 프로세싱 유닛은 컨트롤러(Controller, 100), DMA(Direct Memory Access, DMA, 200), 가변 메모리 (Variable Memory, 300) 및 적어도 하나의 프로세싱 엘리먼트 (Processing Elements, 400)를 포함할 수 있다. 컨트롤러는 DMA, 가변 메모리 및 복수의 프로세싱 엘리먼트들 각각이 인공신경망모델의 연 산과 관련된 동작을 제어하도록 구성될 수 있다. 컨트롤러는 DMA, 가변 메모리 및 복수의 프로 세싱 엘리먼트들 각각 직접적으로 연결되거나 간접적으로 연결되어, 서로 통신할 수 있다. 컨트롤러 는 가변 메모리의 용량 및 인공신경망모델의 구조 데이터에 기초하여 가변 메모리의 각각의 도메인의 용량을 조절할 수 있다. 여기서 가변 메모리는 캐시(cache) 메모리 또는 내부 메모리로 지칭되는 것도 가 능하다. 또한, 복수의 프로세싱 엘리먼트들 또는 프로세싱 엘리먼트(PE)는 인공지능(artificial intelligence; AI) 연산부로 지칭되는 것도 가능하다. DMA는 신경 프로세싱 유닛가 신경 프로세싱 유닛의 메인 메모리 등에 직접 접근하여 읽 기/쓰기를 하도록 구성된다. 신경 프로세싱 유닛는 DMA을 통해 메인 메모리로부터 인공신경망 모델과 관련된 다양한 데이터를 읽어올 수 있다. 메인 메모리는 시스템 온칩(SoC)에 내장되거나 또는 별 도의 메모리 장치로 구성될 수 있다. 가변 메모리는 신경 프로세싱 유닛의 온칩 영역에 배치된 메모리로 온칩 영역에서 처리되는 데이터 를 캐슁(caching)하거나 저장하기 위한 내부 메모리일 수 있다. 가변 메모리는 메인 메모리로부터 인공신경망모델의 연산에 필요한 적어도 일부의 데이터를 읽어 들여 저장할 수 있다. 가변 메모리는 각 도 메인의 메모리 용량 설정과 인공신경망모델의 레이어 별 데이터 크기에 따라 인공신경망모델의 전부 또는 일부 를 저장하도록 구성될 수 있다. 구체적으로, 가변 메모리는 메인 메모리로부터 입력 데이터에 해당하는 입력 특징맵(Input feature map)과 입력 특징맵의 합성곱 연산을 위한 가중치(Weight)에 해당하는 커널(kernel)을 읽어 들여 저장할 수 있 다. 또한, 가변 메모리는 복수의 프로세싱 엘리먼트들로부터 입력 특징맵과 가중치의 합성곱 연산 수 행 결과인 출력 특징맵(output feature map)을 읽어 들여 저장할 수 있다. 한편, 가변 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있으나, SRAM으로 구 성되는 것이 연산 처리 속도면에서 유리하다. 그리고, 가변 메모리는 적어도 하나의 메모리 유닛으로 구성 될 수 있다. 가변 메모리는 단일(homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메모리 유닛으로 구성될 수 있다. 즉, 가변 메모리의 메모리 유닛 각각은 입력 특징맵, 가중치 및 출력 특징맵 중 어느 하 나를 저장할 수 있다. 그리고, 가변 메모리의 메모리 유닛에 저장되는 데이터는 입력 특징맵, 가중치 및 출력 특징맵 중 어느 하 나로 고정된 것이 아니라, 필요에 따라 입력 특징맵, 가중치 및 출력 특징맵 중 다른 하나로 변경될 수 있다. 즉, 가변 메모리의 메모리 할당을 가변 함으로써, 가변 메모리의 사용 효율을 향상시킬 수 있다. 복수의 프로세싱 엘리먼트들는 MAC(multiplication and accumulation) 연산을 수행하도록 구성될 수 있다. 단, 본 개시는 이에 제한되지 않으며, 본 개시의 다양한 예시들에 따른 복수의 프로세싱 엘리먼트들(40 0)는 적어도 하나의 프로세싱 엘리먼트로 변형 실시될 수 있다. 복수의 프로세싱 엘리먼트들는 인공신경망의 입력 데이터에 해당하는 입력 특징맵(Input feature map)과 가중치(Weight)에 해당하는 커널(kernel)을 연산하도록 구성된다. 프로세싱 엘리먼트(PE)는 MAC(Multiply And Accumulate) 연산기, ALU(Arithmetic Logic Unit) 연산기 등을 포함할 수 있다. 도 1을 참조하면, 프로세싱 엘리먼트(PE)는 제1 입력부(input feature map), 제2 입력부(weight), 출력부 (output feature map), 곱셈기(multiplier), 덧셈기(adder) 및 누산기(accumulator)를 포함하도록 구성될 수 있다. 프로세싱 엘리먼트(PE)는 인공신경망모델 처리에 필요한 덧셈, 곱셈, 누산 등의 기능을 수행하도록 구성될 수 있다. 누산기(accumulator)는 루프(loops) 횟수만큼 가산기(adder)를 사용하여 곱셈기(multiplier)의 연산 값 과 누산기(accumulator)의 연산 값을 누산 한다. 누산기(accumulator)는 누산이 종료되면, 초기화 신호를 받아 서 누산기(accumulator) 내부에 저장된 데이터를 초기화 하도록 구성되는 것도 가능하다.예를 들면, 프로세싱 엘리먼트(PE)의 제1 입력부(input feature map)는 입력 특징맵을 입력 받도록 구성될 수 있다. 프로세싱 엘리먼트(PE)의 제2 입력부(weight)는 가중치를 입력 받도록 구성될 수 있다. 프로세싱 엘리먼 트(PE)의 출력부(output feature map)는 가중치와 입력 특징맵을 합성곱 연산한 출력 특징맵을 출력하도록 구성 될 수 있다. 본 개시의 일 예시에 따르면, 프로세싱 엘리먼트(PE)의 제1 입력부와 제2 입력부는 8비트 정수로 양자화된 데이 터를 입력 받도록 구성될 수 있다. 단, 이에 제한되지 않으며, 제1 입력부와 제2 입력부는 8비트 미만의 정수로 양자화된 데이터를 입력 받도록 구성되는 것도 가능하다. 이에 양자화된 데이터는 프로세싱 엘리먼트(PE)의 소 비 전력을 저감할 수 있는 효과가 있다. 프로세싱 엘리먼트(PE)의 제1 입력부(input feature map)는 가변 메모리와 통신하도록 연결될 수 있다. 프 로세싱 엘리먼트(PE)의 제2 입력부(weight)는 가변 메모리와 통신하도록 연결될 수 있다. 프로세싱 엘리먼 트(PE)의 출력부(output feature map)는 가변 메모리와 통신하도록 연결될 수 있다. 부연 설명하면, 본 개시의 예시들에 따른 출력 특징맵은 포괄적인 의미로 해석되어야 한다. 예를 들면, 출력 특 징맵은 합성곱 결과값일 수 있다. 단, 본 개시의 예시들은 이에 제한되지 않으며, 출력 특징맵은 합성곱 결과에 활성화 함수(activation function) 연산, 풀링(pooling) 연산, 스트라이드(stride) 연산, 배치 정규화(batch-normalization) 연산, 스 킵 커넥션(skip-connection) 연산, 접합(concatenation) 연산, 양자화(quantization) 연산, 클리핑(clipping) 연산, 패딩(padding) 연산 등의 알고리즘이 선택적으로 더 적용된 경우를 포함할 수 있다. 각각의 선택적인 알고리즘 처리를 위해서 프로세싱 엘리먼트(PE)는 추가적인 처리 회로부를 더 포함하거나, 또 는 프로세싱 엘리먼트(PE)의 출력부는 추가적인 처리 회로부와 연결되도록 구성될 수 있다. 여기서, 추가적인 처리 회로부의 출력부는 프로세싱 엘리먼트(PE)의 출력부(output feature map)로 지칭될 수 있다. 부연 설명하 면, 추가 회로부를 포함하는 프로세싱 엘리먼트(PE)는 AI 연산부로 지칭될 수 있다. 예를 들면, 프로세싱 엘리먼트(PE)의 제1 입력부(input feature map)는 가변 메모리의 제1 도메인과 통신 하도록 구성될 수 있다. 예를 들면, 프로세싱 엘리먼트(PE)의 제2 입력부(weight)는 가변 메모리의 제2 도메인과 통신하도록 구성 될 수 있다. 예를 들면, 프로세싱 엘리먼트(PE)의 출력부(output feature map)는 가변 메모리의 제3 도메인과 통신하도 록 구성될 수 있다. 다른 예를 들면, 프로세싱 엘리먼트(PE)의 제1 입력부(input feature map)는 가변 메모리의 특징맵 도메인 과 통신하도록 구성될 수 있다. 다른 예를 들면, 프로세싱 엘리먼트(PE)의 제2 입력부(weight)는 가변 메모리의 가중치 도메인과 통신하도 록 구성될 수 있다. 다른 예를 들면, 프로세싱 엘리먼트(PE)의 출력부(output feature map)는 가변 메모리의 특징맵 도메인과 통신하도록 구성될 수 있다. 여기서, 가변 메모리의 각각의 도메인은 프로세싱 엘리먼트(PE)와 독립적으로 통신하도록 구성될 수 있다. 단, 본 개시에 따른 실시예들은 이에 제한되지 않으며, 프로세싱 엘리먼트(PE)는 인공신경망모델의 연산 특성을 고려하여 변형 실시될 수도 있다. 예를 들면, 프로세싱 엘리먼트(PE)는 도 1에 도시된 곱셈기, 덧셈기 및 누산 기로 처리되는 MAC 연산기 구조에 제한되지 않으며, ALU (Arithmetic Logic Unit) 연산기, 또는 벡터 유닛 (vector unit)으로 구현되는 것도 가능하다. 컨트롤러는 가변 메모리에 저장된 출력 특징맵이 저장된 영역, 위치, 주소 등을 인식할 수 있다. 이 에, 컨트롤러는 가변 메모리에 저장된 출력 특징맵이 다음 레이어의 연산에서 입력 특징맵으로 재사 용 하도록, 가변 메모리를 제어할 수 있다. 즉, 각 연산 단계마다, 재사용 가능한 특징맵을 분석하여, 다 음 연산 단계에서 재사용 할 수 있다. 부연 설명하면, 컨트롤러는 인공신경망모델의 구조에 기초하여 출력 특징맵 도메인에 저장된 데이터를 다 음 레이어 연산에 활용될 입력 특징맵 도메인으로 변환시킬 수 있다.메인 메모리는 인공신경망모델의 연산에 필요한 데이터를 저장할 수 있다. 메인 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있으나, DRAM으로 구성되는 것이 데이터 저장 용량면에서 유리하다. 메인 메모리는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 메인 메모리는 단일 (homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메모리 유닛으로 구성될 수 있다. 메인 메모리는 적어도 하나의 인공신경망모델을 저장할 수 있다. 메인 메모리는 신경 프로세싱 유 닛에서 처리하고자 하는 인공신경망모델의 적어도 하나의 레이어의 적어도 일부의 가중치를 제공받을 수 있다. 신경 프로세싱 유닛는 서로 다른 인공신경망모델들을 번갈아 가면서 처리하도록 구성될 수 있다. 신경 프로세싱 유닛가 처리하는 인공신경망모델은 심층신경망모델(deep neural network model)일 수 있다. 따라서 인공신경망모델은 복수의 레이어를 포함할 수 있으며, 각각의 레이어는 각각의 특징맵과 각각의 가중치를 포함할 수 있다. 이미지 센서는 렌즈를 통해 들어오는 빛을 이미지 또는 영상 데이터로 생성하고, 생성된 이미지 또는 영 상 데이터는 인공신경망모델의 입력 특징맵으로 사용될 수 있다. 이미지 센서는 적어도 하나일 수 있으며, 예를 들면, 자율 주행 차량의 경우 복수개의 이미지 센서를 구비하도록 구성될 수 있다. 디코더는 인코딩 된 비트 스트림의 특징맵 또는 가중치를 디코딩하고, 디코딩 된 입력 특징맵 또는 가중 치는 인공신경망모델의 입력으로 사용될 수 있다. 여기서 비트 스트림은 MPEG 표준에 대응되는 비트 스트림일 수 있다, MPEG 표준은 예를 들면 MPEG-VCM(video coding for machine) 또는 MPEG-NNC(neural network compression)일 수 있다. 이하, 도 2 내지 도 4를 참조하여, 신경 프로세싱 유닛에 포함되는 가변 메모리의 동작을 설명한다. 도 2 내지 도 4에서는 설명의 편의를 위하여, 신경 프로세싱 유닛에 포함되는 가변 메모리와 복수의 프로세싱 엘리먼트만 도시하였다. 다만, 도 1에 도시된 구성요소를 참조하여 이하, 신경 프로세싱 유닛에 포함되는 가변 메모리의 동 작 설명한다. 도 2는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가중치 메모리와 특징맵 메모 리를 나타내는 도면이다. 도 3 및 4는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가중치 메모리, 입력 특 징맵 메모리 및 출력 특징맵 메모리를 나타내는 도면이다. 도 2를 참조하면, 가변 메모리는 가중치 메모리와 특징맵 메모리를 포함할 수 있다. 가중치 메모리는 가중치(Weight)를 저장하는 복수의 메모리 유닛들의 집합을 의미하고, 특징맵 메모리 는 입력 특징맵(Input feature map)과 출력 특징맵(output feature map) 중 어느 하나를 저장하는 복수의 메모리 유닛들의 집합을 의미할 수 있다. 가중치 메모리는 가변 메모리의 가중치 도메인으로 지칭될 수 있다. 특징맵 메모리는 가변 메모 리의 특징맵 도메인으로 지칭될 수 있다. 그리고, 각각의 인공신경망모델의 레이어 별로 가중치 메모리의 용량과 특징맵 메모리의 용량의 비율 은 달라질 수 있다. 즉, 각각의 인공신경망모델의 레이어 별로 가중치 메모리에 포함되는 복수의 메모리 유닛들의 개수는 달라질 수 있고, 특징맵 메모리에 포함되는 복수의 메모리 유닛들의 개수는 달라질 수 있 다. 즉, 신경 프로세싱 유닛는 각각의 인공신경망모델의 레이어의 특성에 대응하여 가중치 메모리와 특징맵 메모리의 유닛의 개수를 설정할 수 있다. 가변 메모리의 각각의 메모리 유닛의 크기는 서로 동일하게 구성될 수 있다. 예를 들면, 가변 메모리(30 0)의 각각의 메모리 유닛의 용량은 1 KByte, 2 KByte, 4 KByte, 8 KByte, 16 KByte, 32KByte, 64KByte, 128 KByte, 256 KByte, 512 KByte, 또는 1,024KByte로 구성될 수 있다. 단 본 개시의 예시들은 메모리 유닛의 용량 에 제한되지 않는다. 가변 메모리의 각각의 메모리 유닛의 크기는 각각 구성될 수 있다. 예를 들면, 가변 메모리의 각각의 메모리 유닛의 용량은 서로 상이할 수 있다. 또는 일부의 메모리 유닛의 용량은 4 KByte이고, 또 다른 일부의 메모리 유닛들의 용량은 32KByte일 수 있다. 단 본 개시의 예시들은 메모리 유닛의 용량에 제한되지 않는다.부연 설명하면, 본 개시의 예시들에 따르면, 메모리 유닛은 메모리 뱅크로 지칭되는 것도 가능하다. 예를 들면, 도 8 및 표 1을 참조하면, 제1 레이어 연산 시 컨트롤러는 가중치 메모리의 용량을 1 KByte로 설정할 수 있다. 또한, 제1 레이어 연산 시 컨트롤러는 특징맵 메모리의 용량을 552 KByte로 설정할 수 있다. 따라서, 가변 메모리는 도 8 및 표 1에 도시된 인공신경망모델의 제1 레이어 연산에 필요 한 메모리 용량을 확보할 수 있게 된다. 부연 설명하면, 신경 프로세싱 유닛은 처리할 인공신경망모델의 구조 데이터에 기초하여 가변 메모리 의 각각의 도메인의 용량을 제어할 수 있다. 여기서, 인공신경망모델의 구조 데이터는 인공신경망모델의 레이어의 개수, 각 레이어 연산 순서, 각 레이어의 특징맵 크기 및 가중치 크기 정보 등을 포함할 수 있다. 각 레이어의 특징맵의 크기는 입력 특징맵의 크기 및 출력 특징맵의 크기로 세분화될 수 있다. 이에 대해서는 도 3 및 도 4를 참조하여 후술한다.가변 메모리의 구조 데이터는 복수의 메모리 유닛의 개수, 각각의 메모리 유닛의 용량, 및 각각의 메모리 유닛의 주소 또는 식별 코 드 등을 포함할 수 있다. 또한, 가변 메모리의 구조 데이터는 현재 설정된 각 메모리 유닛의 도메인 정보를 포 함할 수 있다. 도 3 및 도 4를 참조하면, 특징맵 메모리는 입력 특징맵 메모리와(Input feature map memory)과 출 력 특징맵 메모리(output feature map memory)로 구성될 수 있다. 즉, 특징맵 메모리는 입력 특징맵 (Input feature map)을 저장하는 복수의 메모리 유닛들과 출력 특징맵(output feature map)를 저장하는 복수의 메모리 유닛들의 집합을 의미할 수 있다. 신경 프로세싱 유닛의 컴파일러는 특정 인공신경망모델을 처리 하기 위해서, 해당 인공신경망모델의 구조 데이터 및 가변 메모리의 구조 데이터에 기초하여 최적의 연산 스케줄링 할 수 있다. 가변 메모리에 기초한 최적의 연산 스케줄링은 인공신경망 모델의 각 레이어 별 연산 시 가변 메모리(30 0)의 가동률(%)이 최대화될 수 있는 것을 의미할 수 있다. 가변 메모리의 가동률(%)이 최대화되면, 메인 메모리에서 데이터를 최대로 캐슁할 수 있는 효과가 있다. 이에, 가변 메모리와 메인 메모리 의 데이터 전송 빈도가 저감될 수 있는 효과가 있다. 더 나아가서, 가변 메모리의 전체 용량이 신경 프로 세싱 유닛에서 처리하고자 하는 하나의 레이어의 가중치와 특징맵의 데이터 크기보다 작을 때, 가중치 또 는 특징맵을 타일링(tiling) 해야 할 수 있다. 이러한 경우에도, 가변 메모리의 가동률(%)이 최대화되면 신경 프로세싱 유닛에서 처리하는 타일(tile)의 개수가 최소화될 수 있는 효과가 있다. 부연 설명하면, 하나의 메모리 유닛은 하나의 도메인의 데이터를 저장하도록 구성될 수 있다. 단, 본 개시의 예 시들에 따른 메모리 유닛은 이에 제한되지 않으며, 하나의 메모리 유닛은 복수의 도메인의 데이터를 저장하는 것도 가능하다. 예를 들면, 하나의 메모리 유닛의 용량은 1,024KByte일 수 있다. 이때, 512KByte 크기의 입력 특징맵 데이터와 512KByte 크기의 출력 특징맵 데이터가 하나의 메모리 유닛에 저장되는 것도 가능하다. 부연 설명하면 가변 메모리가 dual-port SRAM일 경우, 해당 메모리 유닛은 읽기 동작과 쓰기 동작을 동시에 할 수 있 다. 따라서, 하나의 메모리 유닛에서 입력 특징맵 읽기와 출력 특징맵 쓰기를 동시에 처리하는 것도 가능하다. 또한, 읽기 동작과 쓰기 동작을 동시에 처리하기 위해서, 가변 메모리는 읽기 전용 멀티플렉서와 쓰기 전 용 멀티플렉서를 각각 구비하도록 구성되는 것도 가능하다. 부연 설명하면, 하나의 메모리 유닛은 입력 특징맵 도메인의 데이터와 가중치 도메인의 데이터를 저장하는 것도 가능하다. 예를 들면, 하지만 이러한 경우, 하나의 메모리 유닛에서 입력 특징맵 데이터와 가중치 데이터를 동 시에 읽어야 하기 때문에, 매 클럭마다 순차적으로 입력 특징맵과 가중치를 읽어야 할 수 있다. 따라서, 하나의 메모리 유닛에 입력 특징맵 데이터와 가중치를 같이 저장하는 것보다는, 입력 특징맵 데이터와 출력 특징맵 데 이터를 같이 저장하는 것이 상대적으로 더 효율적일 수 있다. 이에, 컴퍼일러는 하나의 메모리 유닛에 입력 특 징맵과 가중치가 동시에 저장되는 것을 지양한 머신 코드를 생성할 수 있다. 즉, 컴파일러는 각각의 레이어의 각각의 도메인에 대응되는 데이터의 크기를 분석하고, 하나의 메모리 유닛에 비효율 적인 복수의 도메인 할당을 제어할 수 있다. 부연 설명하면, 가변 메모리가 single-port SRAM일 경우, 컴파일러는 가능하면, 하나의 메모리 유닛에 하 나의 도메인의 데이터만 저장되도록 구성된 머신 코드를 생성할 수 있다. 컨트롤러는 신경 프로세싱 유닛에서 동작 가능하도록 컴파일(compile) 된 바이너리 파일에 포함된 인공신경망모델의 구조 데이터에 따라 가변 메모리를 제어하도록 구성될 수 있다. 예를 들면, 인공신경망모델의 구조 데이터는 Open Neural Network Exchange (ONNX), 파이토치(PyTorch), 텐서 플로우(TensorFlow) 등의 파일 포멧(format)에 포함된 데이터일 수 있다. 단, 본 개시는 특정 파일 포멧에 제한 되지 않는다. 컴파일러는 상기 파일 포멧 등을 가변 메모리의 구조 데이터에 기초하여 바이너리 파일로 변환시 킬 수 있다. 여기서 바이너리 파일은 신경 프로세싱 유닛의 동작을 제어할 수 있는 형식의 파일의 지칭할 수 있 다. 여기서, 바이너리 파일은 머신 코드로 지칭되는 것도 가능하다. 도 3을 참조하면, 컨트롤러는 특정 인공신경망모델의 제1 연산 단계에서 가중치 메모리, 입력 특징맵 메모리 및 출력 특징맵 메모리 각각의 용량을 서로 동일하게 설정할 수 있다. 즉, 제1 연산 단계에서 가중치 메모리를 구성하는 복수의 메모리 유닛들의 개수와 입력 특징맵 메모리를 구성하는 복수의 메 모리 유닛들의 개수와 입력 특징맵 메모리를 구성하는 복수의 메모리 유닛들의 개수는 동일하게 설정될 수 있다. 입력 특징맵 메모리 및 출력 특징맵 메모리는 특징맵 메모리로 지칭될 수 있다. 그리고 도 4를 참조하면, 제1 연산 단계에서 이어지는 제2 연산 단계에서 가변 메모리에 포함되는 가중치 메모리, 입력 특징맵 메모리 및 출력 특징맵 메모리 각각의 용량이 상이하게 설정될 수 있다. 즉, 제2 연산 단계에서 가중치 메모리를 구성하는 복수의 메모리 유닛들의 개수와 입력 특징맵 메모리 를 구성하는 복수의 메모리 유닛들의 개수와 출력 특징맵 메모리를 구성하는 복수의 메모리 유닛들의 개수는 상이할 수 있다. 즉, 특징맵 메모리를 구성하는 복수의 메모리 유닛들의 개수는 상이할 수 있다. 여기서 하나의 연산 단계는 신경 프로세싱 유닛의 복수의 프로세싱 엘리먼트들가 가변 메모리 의 각각의 도메인에 저장된 특정 입력 특징맵 데이터와 특정 가중치 데이터를 처리하는 하나의 단계를 의미할 수 있다. 예를 들면, 제1 연산 단계는 인공신경망모델의 제1 레이어의 연산일 수 있다. 제2 연산 단계는 인공신 경망모델의 제2 레이어의 연산일 수 있다. 예를 들면, 제1 연산 단계는 인공신경망모델의 제1 레이어의 제1 타일의 연산일 수 있다. 제2 연산 단계는 인공 신경망모델의 제1 레이어의 제2 타일의 연산일 수 있다. 컴파일러는 신경 프로세싱 유닛의 가변 메모리 의 메모리 크기와 인공신경망모델의 특정 레이어의 가중치와 특징맵의 데이터 크기를 기초로, 각 레이어 별로 타일의 개수를 결정하도록 구성될 수 있다. 예를 들어, 도 4에서, 제2 레이어에서 필요한 입력 특징맵 메모리의 용량이 큰 경우, 컨트롤러는 입 력 특징맵 메모리의 용량을 상대적으로 크게 설정하고, 가중치 메모리 및 출력 특징맵 메모리 각각의 용량을 상대적으로 작게 설정한다. 따라서 가변 메모리 전체 용량이 증가하지 않더라도 입력 특징 맵 메모리에 할당된 용량을 증가시킬 수 있다. 따라서 가변 메모리의 가동률(%)을 향상시키는 효과가 있다. 구체적으로, 제2 레이어에서 필요한 입력 특징맵 메모리의 용량이 큰 경우, 컨트롤러는 입력 특징맵 메모리를 구성하는 복수의 메모리 유닛들의 개수를 증가시키고, 가중치 메모리를 구성하는 복수의 메 모리 유닛들의 개수를 감소시키고 및 출력 특징맵 메모리를 구성하는 복수의 메모리 유닛들의 개수를 감소 시킨다. 입력 특징맵 메모리 및 출력 특징맵 메모리는 특징맵 메모리로 지칭될 수 있다. 부연 설명하면, 인공신경망모델의 각 레이어 별 특징맵 및 가중치의 크기는 사전에 정의될 수 있다. 따라서, 신 경 프로세싱 유닛는 특정 인공신경망모델을 처리할 때, 인공신경망모델의 각 레이어 별 특징맵 및 가중치 의 크기 정보를 기초로 신경 프로세싱 유닛의 동작을 스케줄링 할 수 있다. 예를 들면, 가변 메모리의 각각의 메모리 유닛의 용량은 특정 단위 일 수 있다. 예를 들면, 제1 그룹의 메 모리 유닛을 묶어서 가중치 메모리로 정의할 수 있다. 예를 들면, 제2 그룹의 메모리 유닛을 묶어서 입력 특징맵 메모리로 정의할 수 있다. 예를 들면, 제3 그룹의 메모리 유닛을 묶어서 출력 특징맵 메모리 로 정의할 수 있다. 이러한 정의는 각 연산 단계마다 다르게 설정될 수 있다. 컨트롤러는 기 분석된 연산 스케줄링 정보를 기초로 DMA 및 가변 메모리를 제어하도록 구성될 수 있다. 컨트롤러는 DMA를 제어하여 DMA가 가변 메모리를 제어하도록 구성될 수 있다. 특히, 인공신경망모델의 레이어 처리 순서, 각 레이어 별 특징맵 및 가중치의 크기 정보가 제공될 경우, 신경 프로세싱 유닛은 가중치 메모리의 용량 및 특징맵 메모리의 용량을 어떻게 할당할지를 사전에 결정할 수 있다. 따라서, 신경 프로세싱 유닛는 설정된 스케줄링 순서에 따라서 동작 가능하며, 가변 메 모리의 가중치 및 특징맵을 위한 용량 할당을 위한 스케줄링을 위한 별도의 연산을 하지 않을 수 있다. 따 라서, 인공신경망모델의 각 레이어의 가중치 크기 및 특징맵 크기를 분석한 정보에 기초하여 신경 프로세싱 유닛의 가변 메모리의 동작이 최적화될 수 있다. 여기서 상기 분석한 정보는 인공신경망모델을 컴파일 한 머신 코드에 포함될 수 있다. 이하, 도 5 내지 도 8를 참조하여, 신경 프로세싱 유닛에 포함되는 가변 메모리의 내부 구성 및 동작에 대 해서 구체적으로 설명한다. 도 5는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가변 메모리의 내부 구성을 나 타내는 도면이다. 도 6 및 7는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가중치 메모리, 입력 특 징맵 메모리 및 출력 특징맵 메모리를 구성하는 복수의 메모리 유닛들의 동작 예시를 나타내는 도면이다. 도 5를 참조하면, 가변 메모리는 복수의 메모리 유닛들, 입력 특징맵 멀티플렉서, 가중치 멀티플렉서 및 출력 특징맵 디멀티플렉서를 포함한다. 단, 본 개시의 예시들은 멀티플렉서 및 디멀티플렉서에 제한되지 않으며, 상기 멀티플렉서 및 디멀티플렉서는 스위치, 선택기, 분배기 등으로 지칭되는 것도 가능하다. 예를 들면, 입력 특징맵 멀티플렉서는 제1 선택기(selector)로 지칭될 수 있다. 예를 들면, 가중치 멀티플 렉서는 제2 선택기(selector)로 지칭될 수 있다. 예를 들면, 출력 특징맵 디멀티플렉서는 제3 선택기 (selector)로 지칭될 수 있다. 복수의 메모리 유닛들 각각은 입력 특징맵, 가중치 및 출력 특징맵 중 어느 하나를 저장할 수 있다. 그리고, 메 모리 유닛에 저장되는 데이터는 입력 특징맵, 가중치 및 출력 특징맵 중 어느 하나로 고정된 것이 아니라, 필요 에 따라 입력 특징맵, 가중치 및 출력 특징맵 중 다른 하나로 변경될 수 있다. 그리고, 복수의 메모리 유닛들 각각은 DMA를 통해 메인 메모리로부터 입력 특징맵 및 가중치 중 적 어도 하나를 읽어 들여 저장할 수 있다. 그리고, 복수의 메모리 유닛들 각각은 입력 특징맵과 가중치의 합성곱 연산 수행 결과인 출력 특징맵을 복수의 프로세싱 엘리먼트들로부터 읽어 들여 저장할 수 있다. 각각의 메 모리 유닛의 크기는 서로 동일하게 구성될 수 있다. 또는, 가변 메모리의 각각의 메모리 유닛의 크기는 각 각 특정 용량을 가지도록 개별 설정될 수 있다. 부연 설명하면, 본 개시의 예시들에 따른 출력 특징맵은 포괄적인 의미로 해석되어야 한다. 예를 들면, 출력 특 징맵은 합성곱 연산 결과값일 수 있다. 더 나아가서, 출력 특징맵은 합성곱 결과에 활성화 함수(activation function) 연산, 풀링(pooling) 연산, 스트라이드(stride) 연산, 배치 정규화(batch-normalization) 연산, 스 킵 커넥션(skip-connection) 연산, 접합(concatenation) 연산, 양자화(quantization) 연산, 클리핑(clipping) 연산, 패딩(padding) 연산 등의 알고리즘이 선택적으로 더 적용된 경우도 포함할 수 있다. 이에, 프로세싱 엘리 먼트(PE)는 추가 알고리즘을 위한 처리 회로부를 더 포함하도록 구성될 수 있다. 신경 프로세싱 유닛은 상기 알고리즘들 중 적어도 하나를 구현하기 위한 적어도 하나의 처리 회로부를 더 포함하도록 구성될 수 있다. 여기서, 추가적인 처리 회로부의 출력부는 프로세싱 엘리먼트(PE)의 출력부(output feature map)로 지칭될 수 있다. 예를 들면, 프로세싱 엘리먼트(PE)의 제1 입력부는 입력 특징맵 멀티플렉서와 연결될 수 있다. 예를 들면, 프로세싱 엘리먼트(PE)의 제2 입력부는 가중치 멀티플렉서와 연결될 수 있다. 예를 들면, 프로세싱 엘리먼트(PE)의 출력부는 출력 특징맵 디멀티플렉서와 연결될 수 있다. 따라서 가변 메모리는 프로세싱 엘리먼트(PE)의 제1 입력부, 제2 입력부 및 출력부 각각에 연결된 복수의 선택기들(예를 들면, 제1 선택기, 제2 선택기, 및 제3 선택기)을 통해, 하나의 클럭에 가중치 데이터 및 입력 특징맵 데이터를 전송하고 출력 특징맵 데이터를 전송 받을 수 있는 효과가 있다. 또한, 가변 메모리의 각 도메인의 메모리 용량의 비율을 각 연산 단계마다 조절하여, 인공신경망모델의 각 레이어 연산 단계마다 가변 메모리의 가동률(%)의 최대화할 수 있다. 상술하였듯이, 상기 각 연산 단계는 인공신경망모델의 하나의 레이어 연산 또는 하나의 레이어의 복수의 타일 중 하나의 연산일 수 있다. 부연 설명하면, 컨트롤러는 DMA와 입력 특징맵 멀티플렉서, 가중치 멀티플렉서 및 출력 특 징맵 디멀티플렉서를 제어할 수 있다. 따라서 컨트롤러는 특정 도메인이 할당된 각각의 메모리 유닛 에 데이터의 읽기 및 쓰기 동작을 제어할 수 있다. 따라서, 가변 메모리의 각각의 메모리 유닛은 특정 도 메인의 메모리로써 동작할 수 있다. 복수의 메모리 유닛들 각각은 입력 특징맵 멀티플렉서, 가중치 멀티플렉서 및 출력 특징맵 디멀티플 렉서와 통신하도록 구성될 수 있다. 복수의 메모리 유닛들 각각은 입력 특징맵 멀티플렉서, 가중치 멀티플렉서 및 출력 특징맵 디멀티플 렉서 중 어느 하나에 의해서 선택되도록 구성될 수 있다. 이에, 입력 특징맵 멀티플렉서, 가중치 멀 티플렉서 및 출력 특징맵 디멀티플렉서 중 어느 하나에 의해서 선택된 특정 메모리 유닛은 읽기 동작 또는 쓰기 동작을 수행할 수 있게 된다. 가변 메모리는 DMA에 연결될 수 있고, 가변 메모리의 복수의 메모리 유닛들은 입력 특징맵 멀티 플렉서, 가중치 멀티플렉서 및 출력 특징맵 디멀티플렉서 중 어느 하나와 통신할 수 있다. DMA는 각각의 메모리 유닛에 가중치 또는 특징맵이 액세스되도록 각각의 메모리 유닛의 읽기 동작 또는 쓰 기 동작을 제어할 수 있다. 입력 특징맵 멀티플렉서는 복수의 메모리 유닛들 중 적어도 하나에 저장된 입력 특징맵 데이터 중 일부를 복수의 프로세싱 엘리먼트들에 출력한다. 입력 특징맵 멀티플렉서는 복수의 프로세싱 엘리먼트들과 복수의 메모리 유닛들에 연결될 수 있다. 구체적으로 입력 특징맵 멀티플렉서의 복수의 입력부들은 복수의 메모리 유닛의 출력부와 연결된다. 그리 고, 입력 특징맵 멀티플렉서의 출력부는 복수의 프로세싱 엘리먼트들의 입력부에 연결된다. 보다 구 체적으로는 입력 특징맵 멀티플렉서의 출력부는 프로세싱 엘리먼트(PE)의 제1 입력부에 연결될 수 있다. 가중치 멀티플렉서는 복수의 메모리 유닛들 중 적어도 하나에 저장된 가중치 중 일부를 복수의 프로세싱 엘리먼트들에 출력한다. 가중치 멀티플렉서는 복수의 프로세싱 엘리먼트들과 복수의 메모리 유닛들에 연결될 수 있다. 구체적 으로 가중치 멀티플렉서의 복수의 입력부들은 복수의 메모리 블록의 출력부와 연결된다. 그리고, 가중치 멀티플렉서의 출력부는 복수의 프로세싱 엘리먼트들의 입력부에 연결된다. 보다 구체적으로는 가중치 멀티플렉서의 출력부는 복수의 프로세싱 엘리먼트들(PE)의 제2 입력부에 연결될 수 있다. 출력 특징맵 디멀티플렉서는 복수의 프로세싱 엘리먼트들에서 처리된 출력 특징맵을 복수의 메모리 유닛들 중 적어도 하나에 출력한다. 즉, 출력 특징맵 디멀티플렉서는 인공신경망모델의 레이어 각각의 연 산 스케줄링에 따라, 복수의 프로세싱 엘리먼트들에서 연산된 출력 특징맵을 복수의 메모리 유닛들 중 적 어도 하나에 출력한다. 출력 특징맵 디멀티플렉서는 복수의 프로세싱 엘리먼트들과 복수의 메모리 유닛들에 연결될 수 있다. 구체적으로, 출력 특징맵 디멀티플렉서의 복수의 출력부들은 복수의 메모리 블록의 입력부와 연결된다. 그 리고, 출력 특징맵 디멀티플렉서의 입력부는 복수의 프로세싱 엘리먼트들의 출력부에 연결된다. 보다 구체적으로는 출력 특징맵 디멀티플렉서의 입력부는 복수의 프로세싱 엘리먼트들(PE)의 출력부에 연결될 수 있다.컨트롤러는 인공신경망모델의 레이어 각각의 연산 순서에 따라, 복수의 메모리에 저장되는 데이터 를 스케줄링 할 수 있다. 즉, 컨트롤러는 인공신경망모델의 복수의 레이어 별로 연산 단계가 스케줄링 된 정보를 포함하는 머신 코 드에 기반하여, 복수의 메모리 유닛들 각각에 입력 특징맵, 가중치 및 출력 특징맵 중 어느 하나가 저장되도록 제어할 수 있다. 상술한 머신 코드는 신경 프로세싱 유닛 외부의 컴파일러에서 인공신경망모델을 분석하여, 인공신경망모델의 연 산 이전에 생성된 코드일 수 있다. 즉, 머신 코드는 신경 프로세싱 유닛이 처리할 특정 인공신경망모델을 분석하여, 상기 인공신경망모델의 복수의 레이어 각각에 대한 입력 특징맵, 가중치 및 출력 특징맵 정보를 포함 할 수 있다. 부연 설명하면, 상기 머신 코드는 신경 프로세싱 유닛의 가변 메모리의 구조 정보를 기 초로 생성된 머신 코드이기 때문에, 신경 프로세싱 유닛의 전용 머신 코드일 수 있다. 머신 코드는 컨트 롤러에 저장되는 것도 가능하다. 단, 본 개시의 예시들에 따른 머신 코드는 이에 제한되지 않으며, 머신 코드는 신경 프로세싱 유닛의 특정 위치에 제공되는 특정 메모리에 저장될 수 있다. 보다 구체적으로는, 머신 코드는 상기 인공신경망모델의 복수의 레이어 각각에 대한 입력 특징맵의 용량 정보, 가중치의 용량 정보 및 출력 특징맵의 용량 정보를 포함할 수 있다. 도 8은 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛에서 처리하는 예시적인 인공신경 망모델의 레이어 별 데이터 크기 정보를 나타내는 도면이다. 도 8에서는 인공신경망모델의 하나의 예인 Mobilenet V1 모델의 레이어 별 데이터 크기 정보를 도시하였고, 정 확한 데이터 크기 정보는 아래 표 1과 같다. Mobilenet V1 모델의 각각의 레이어는 적어도 가중치 데이터 크기, 입력 특징맵 데이터 크기 및 출력 특징맵 크 기를 포함한다. 예시적인 Mobilenet V1 인공신경망모델은 제1 레이어부터 제28 레이어까지 오름차순으로 연산해 야 온전한 추론 결과를 얻도록 설계된 것을 특징으로 한다. 각각의 레이어는 합성곱 연산, 활성화 함수 연산, 풀링 연산, 스트라이드 연산, 배치 정규화 연산, 스킵 커넥션 연산, 접합 연산, 양자화 연산, 클리핑 연산, 패 딩 연산 등의 정보를 더 포함할 수 있다. 다만, 가변 메모리의 제어 시 상기 정보는 필수적인 정보가 아니 기 때문에, 불필요한 설명은 생략하기로 한다. [표 1]"}
{"patent_id": "10-2022-0132180", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "Mobilenet V1 모델은 총 28개의 레이어로 구성되어 있으며, 복수의 레이어 각각의 입력 특징맵의 용량 정보, 가 중치의 용량 정보 및 출력 특징맵의 용량 정보는 상이할 수 있다. 컴파일러는 상술한 인공신경망모델을 연산 이전에 분석하여, 복수의 레이어 각각의 입력 특징맵의 용량 정보, 가중치의 용량 정보 및 출력 특징맵의 용량 정보를 포함하는 머신 코드를 생성할 수 있다. 또한, 머신 코드는 상기 인공신경망모델의 복수의 레이어 각각에서, 입력 특징맵, 가중치 및 출력 특징맵 각각 이 복수의 메모리 유닛들에 배치되는 위치에 대한 인공신경망 데이터 지역성(artificial neural network data locality)를 포함할 수 있다. 상술한 인공신경망 데이터 지역성이라 함은 복수의 레이어 각각에서 입력 특징맵, 가중치 및 출력 특징맵 각각 이 복수의 메모리 유닛들 중 어느 메모리 유닛에 저장되는지를 설정하는 데이터이다. 컴파일러는 인공신경망모델의 구조가 고정되어 있다는 점을 활용하여 인공신경망 데이터 지역성을 정의할 수 있 다. 따라서, 한번 정의된 인공신경망 데이터 지역성은 인공신경망모델의 구조가 변경되기 이전까지 동일하게 유 지될 수 있다. 따라서, 인공신경망 데이터 지역성을 활용하면, 특정 인공신경망모델의 각 연산 단계마다 신경 프로세싱 유닛 에 어떠한 데이터(예를 들면, 입력 특징맵 및 가중치)를 요청하고, 신경 프로세싱 유닛이 어떠한 데이터(예를 들면, 출력 특징맵)를 생성할지를 사전에 알 수 있게 된다. 따라서, 컨트롤러는 각 연산 단계 마다 필요한 각 도메인의 데이터 크기를 알 수 있다. 따라서, 컨트롤러는 각 연산 단계마다 필요한 각 도메인의 데이터 크기에 기초하여 각 연산 단계 마다 각 도메인에 필요한 가변 메모리의 메모리 유닛들의 개 수를 결정할 수 있다. 따라서, 컨트롤러는 각 연산 단계 마다 가변 메모리의 메모리 유닛들 각각을 특정 도메인의 메모리로 설정할 수 있다. 최종적으로, 컨트롤러는 인공신경망모델의 모든 레이어의 모든 연산 단계마다 가변 메모리의 메모리 유닛들의 도메인 설정이 스케줄링 된 머신 코드에 기초하여 동작되는 것도 가능하다. 이에, 신경 프로세싱 유닛 은 각 연산 단계마다 가변 메모리의 가동률(%)을 최대화할 수 있는 효과가 있다. 표 1에서 상술한 바와 같이, 복수의 레이어 각각의 입력 특징맵의 용량 정보, 가중치의 용량 정보 및 출력 특징 맵의 용량 정보는 상이할 수 있다. 복수의 레이어 각각에서 인공신경망 데이터 지역성 또한 상이할 수 있다. 컴파일러에서 인공신경망모델의 사전 분석으로 인하여, 인공신경망모델 복수의 레이어 각각의 연산 순서 또한 머신 코드에 기입될 수 있다. 따라서, 머신 코드는 상기 인공신경망모델의 복수의 레이어 각각의 연산 순서 정 보를 포함할 수 있다. 컴파일러는 가변 메모리의 전체 용량과 인공신경망모델의 각 레이어의 각 도메인의 데이터의 크기를 기초 로 타일링을 결정할 수 있다. 예를 들면, 도 8의 예시적인 인공신경망모델의 제3 레이어는 전체 레이어들 중에서 가장 큰 데이터 용량을 가진 다. 즉, 가중치 데이터 크기, 출력 특징맵 데이터 크기 및 입력 특징맵 데이터 크기의 총합은 1.2MByte이다. 만 약 가변 메모리의 메모리 용량이 2MByte일 경우, 모든 레이어는 타일링이 불필요 할 수 있다. 만약 가변 메모리의 메모리 용량이 1MByte일 경우, 제3 레이어 연산을 위해서 타일링이 요구될 수 있다. 이러한 경우, 제3 레이어 연산을 위해서 제3 레이어는 제1 타일 및 제2 타일로 구분되고 각 타일은 순차적으로 처리될 수 있다. 즉, 내부 메모리의 용량에 따라서, 컴파일러는 하나의 레이어를 하나의 연산 단계로 처리 또는 복수의 타일로 나누어진 복수의 연산 단계로 처리할 수 있다. 본 개시의 일 예시에 따르면, 인공신경망모델의 인공신경망 데이터 지역성을 활용하여, 가변 메모리의 제1 연산 단계와 제2 연산 단계의 데이터 지역성을 정의하는 것이 가능하다. 이에, 컴파일러는 가변 메모리에 서 복수의 연산 단계들에 동일한 데이터 지역성이 존재한다는 것을 분석하고, 동일한 데이터 지역성을 가지는 메모리 유닛들을 재사용 하도록 구성된 머신 코드를 생성할 수 있다. 이에, 컨트롤러는 머신 코드에 의해 서 가변 메모리를 제어하도록 구성될 수 있다. 예를 들면, 제1 연산 단계와 제2 연산 단계에서 동일한 데이터 지역성이 존재할 경우, 컨트롤러는 가변 메 모리를 제어하여 가변 메모리에 제1 연산 단계에서 저장된 데이터를 제2 연산 단계에서 재사용 할 수 있다. 여기서 데이터를 재사용 한다는 의미는, 가변 메모리에 저장된 출력 특징맵 데이터가 메인 메모리로 이동되지 않고, 다시 한번 프로세싱 엘리먼트(PE)에 입력 특징맵으로 재사용 된다는 것을 의미할 수 있다. 단, 본 개시의 예시들은, 특징맵에 제한되지 않으며, 동일한 데이터 지역성을 가지는 데이터 또한 재사용 될 수 있 다. 여기서, 예시적으로, 머신 코드에 정의된 제1 연산 단계는 도 8 및 표 1에 예시된 인공신경망모델의 제1 레이어 의 연산일 수 있다. 이어서 예시적으로, 머신 코드에 정의된 제2 연산 단계는 도 8 및 표 1에 예시된 인공신경 망모델의 제2 레이어의 연산일 수 있다. 먼저, 도 5 및 도 6을 참조하면, 인공신경망 데이터 지역성에 기초하여 예시적인 제1 연산 단계에서, 제1 내지 제4 메모리 유닛에는 제1 레이어의 입력 특징맵이 저장되고, 제5 및 제6 메모리 유닛에는 제1 레이어의 가중치 가 저장되고, 제7 내지 제N 메모리 유닛에는 제1 레이어의 출력 특징맵이 저장될 수 있다. 여기서 제1 레이어의 출력 특징맵은, 제1 레이어의 입력 특징맵과 제1 레이어의 가중치를 기초로 연산한 결과 값일 수 있다. 컨트롤러는 인공신경망모델의 각 연산 단계 별로 설정되는 머신 코드에 기반하여, DMA가 상기 복수의 메모리 유닛들 중 입력 특징맵 메모리로 설정된 제1 메모리 그룹에 입력 특징맵을 기입하도록 제어할 수 있다. 즉, 도 5 및 도 6을 참조하면, 컨트롤러는 머신 코드에 기입된 인공신경망 데이터 지역성에 기반하여 DMA를 제어할 수 있다. DMA는 메인 메모리에서 제1 연산 단계(예를 들면, 제1 레이어 연산 단 계)에 필요한 입력 특징맵을 읽어와서 제1 내지 제4 메모리 유닛 각각에 기입할 수 있다.제1 연산 단계(예를 들면, 제1 레이어 연산 단계)에 필요한 제1 레이어의 입력 특징맵이 저장된 제1 내지 제4 메모리 유닛은 제1 메모리 그룹으로 설정될 수 있으며, 입력 특징맵 도메인으로 정의될 수 있다. 제1 메모리 그룹에 제1 레이어의 입력 특징맵이 저장된 이후, 컨트롤러는 입력 특징맵 멀티플렉서 가 제1 메모리 그룹에 기입된 제1 레이어의 입력 특징맵을 복수의 프로세싱 엘리먼트들에 출력 하도록 입력 특징맵 멀티플렉서를 제어할 수 있다. 이에, 입력 특징맵 멀티플렉서가 복수의 프로세싱 엘리먼트들의 연산 타이밍에 맞추어, 제1 메모리 그룹에 기입된 제1 레이어의 입력 특징맵을 복수의 프로세싱 엘리먼트들에 출력할 수 있다. 한편, 컨트롤러는 머신 코드에 기반하여, DMA가 상기 복수의 메모리 유닛들 중 제2 메모리 그룹(31 2)에 가중치를 기입하도록 제어할 수 있다. 즉, 도 5 및 도 6을 참조하면, 컨트롤러는 머신 코드에 기입된 인공신경망 데이터 지역성에 기반하여 DMA를 제어할 수 있다. DMA는 메인 메모리에서 제1 연산 단계(예를 들면, 제1 레이어 연산 단 계)에 필요한 가중치를 읽어와서 제5 및 제6 메모리 유닛 각각에 기입할 수 있다. 제1 연산 단계(예를 들면, 제1 레이어 연산 단계)에 필요한 제1 레이어의 가중치가 저장된 제5 및 제6 메모리 유닛은 제2 메모리 그룹으로 설정될 수 있으며, 가중치 도메인으로 정의될 수 있다. 제2 메모리 그룹에 제1 레이어의 가중치가 저장된 이후, 컨트롤러는 가중치 멀티플렉서가 제2 메모리 그룹에 기입된 가중치를 복수의 프로세싱 엘리먼트들에 출력하도록 가중치 멀티플렉서를 제어할 수 있다. 이에, 가중치 멀티플렉서가 복수의 프로세싱 엘리먼트들의 연산 타이밍에 맞추어, 제2 메모리 그룹 에 기입된 가중치를 복수의 프로세싱 엘리먼트들에 출력할 수 있다. 상술하였듯이, 도 1을 다시 참조하면, 프로세싱 엘리먼트(PE)의 제1 입력부(input feature map)는 입력 특징맵 멀티플렉서와 통신할 수 있다. 이때, 프로세싱 엘리먼트(PE)의 제2 입력부(weight)는 가중치 멀티플렉서 와 통신할 수 있다. 이때, 입력 특징맵 멀티플렉서는 제1 메모리 그룹을 선택한다. 그리고 가중 치 멀티플렉서는 제2 메모리 그룹을 선택한다. 그리고, 제1 연산 단계에서, 컨트롤러는 머신 코드에 기반하여, 복수의 프로세싱 엘리먼트들을 제어 하여 합성곱 연산을 처리한다. 이에 프로세싱 엘리먼트(PE)의 출력부(output feature map)은 제1 레이어의 출력 특징맵을 출력한다. 이에, 출력 특징맵 멀티플렉서가 상기 복수의 메모리 유닛들 중 제3 메모리 그룹(31 3)에 출력 특징맵을 기입하도록 복수의 메모리 유닛들을 선택할 수 있다. 즉, 도 5 및 도 6을 참조하면, 컨트롤러는 머신 코드에 기입된 인공신경망 데이터 지역성에 기반하여, 출 력 특징맵 디멀티플렉서가 복수의 프로세싱 엘리먼트들로부터 제7 내지 제N 메모리 유닛 각각에 출력 특징맵을 기입하도록 제어할 수 있다. 제1 연산 단계(예를 들면, 제1 레이어 연산 단계)에서, 제1 레이어의 출력 특징맵이 저장된 제7 내지 제N 메모 리 유닛은 제3 메모리 그룹으로 설정될 수 있으며, 출력 특징맵 도메인으로 정의될 수 있다. 상술한 일련의 과정을 통해, 제1 연산 단계에서 가변 메모리에 효율적으로 가중치, 입력 특징맵 및 출력 특징맵이 할당되는 메모리를 변경 및 설정하는 예시를 설명하였다. 이에, 본 개시의 가변 메모리를 포함하는 신경 프로세싱 유닛은 내부 메모리(즉, 가변 메모리(30 0))의 각 도메인의 이용 효율을 향상시킬 뿐만 아니라, 하나의 레이어에서 연산에 사용되지 않는 불필요한 데이 터를 저장하지 않을 수 있다. 또한, 최소한의 메모리 크기로 최대 저장 효율을 달성할 수 있어, 더 우수한 캐슁 성능을 제공할 수 있다. 그리고, 본 개시의 내부 메모리를 포함하는 신경 프로세싱 유닛에서 비효율적으로 메모리 크기를 증가시킬 필요 가 없어짐으로써, ASIC 칩의 제조 수율이 올라갈 수 있다. 뿐만 아니라, 메모리 크기가 최적화됨으로써, 신경 프로세싱 유닛의 소비 전력 또한 감소될 수 있는 효과가 있다. 이하 도 5 내지 8을 참조하여 가변 메모리를 활용하여 제2 레이어 연산 시 제1 레이어의 출력 특징맵을 재 사용 하는 예시를 설명한다. 도 6을 참조하면, 제1 연산 단계의 출력 값인 제1 레이어의 출력 특징맵은 제3 메모리 그룹에 저장되어 있 다. 여기서 제3 메모리 그룹은 출력 특징맵 도메인으로 정의되어 있다. 도 7을 참조하면, 제2 연산 단계에서, 제3 메모리 그룹의 도메인은 출력 특징맵 도메인에서 입력 특징맵 도메인으로 재정의 될 수 있다. 부연 설명하면, 컨트롤러는 연산 단계가 바뀔 때, 가변 메모리에 정 의된 특정 메모리 그룹의 도메인을 다른 도메인으로 재정의하도록 구성될 수 있다. 그리고, 컨트롤러는 연 산 단계가 바뀔 때, 머신 코드에 포함된 인공신경망 데이터 지역성 정보에 기초하여, 가변 메모리의 동일 한 데이터 지역성을 가지는 메모리 유닛들에 저장된 데이터를 다음 연산에 재사용 할 수 있다. 즉, 제1 레이어의 출력 특징맵은 제2 레이어의 입력 특징맵으로 활용될 수 있다. 여기서 제2 레이어는 제1 레이 어의 다음 레이어를 의미할 수 있다. 여기서 컨트롤러는 제1 레이어의 출력 특징맵과 제2 레이어의 입력 특징맵의 데이터 지역성은 동일하게 판단할 수 있다. 따라서, 기 설정된 제3 메모리 그룹의 도메인을 변경 함으로 써, 실질적인 데이터 이동 없이 데이터를 재사용 할 수 있는 효과가 있다. 즉, 가변 메모리에 저장 된 출력 특징맵과 동일한 데이터 지역성을 가지는 다음 연산 단계의 입력 특징맵은 인공신경망 데이터 지역성 정보를 포함한 머신 코드에 의해서 재사용 될 수 있다. 상기 머신 코드는 가변 메모리의 각각의 메모리 유 닛들의 크기 및 인공신경망모델 각각의 레이어의 각각의 도메인 별 데이터 크기에 기초하여 컴파일 된 코드일 수 있다. 단 본 개시의 예시들은, 인공신경망모델의 모든 레이어에 제한되지 않으며, 머신 코드는 모든 레이어들 중 적어 도 두 개의 레이어에 대응되는 인공신경망 데이터 지역성 정보만 포함하는 것도 가능하다. 즉, 적어도 연속된 두 개의 연산 단계만 있더라도, 인공신경망 데이터 지역성의 동일 여부를 판단하는 것이 가능하다. 그리고 동일 한 데이터 지역성을 판단할 경우, 도메인 변경을 통해서 데이터 재사용이 가능한 효과가 있다. 부연 설명하면, 신경 프로세싱 유닛은 특정 레이어의 출력 특징맵이 다음 레이어의 입력 특징맵으로 활용 되는 인공신경망모델의 구조적인 특성 및 동일한 데이터 지역성을 가지는 데이터의 재사용 가능 특성을 활용하 도록 구성될 수 있다. 도 7을 참조하면, 제2 연산 단계에서, 제2 레이어의 입력 특징맵은 제7 내지 제N 메모리 유닛에 이미 저장되어 있다. 이때, 컨트롤러는 제1 레이어의 출력 특징맵은 제2 레이어의 입력 특징맵으로 재사용한다. 제7 내지 제N 메모리 유닛은 제3 메모리 그룹으로 유지될 수 있으며, 기 설정된 출력 특징맵 도메인은 입력 특징맵 도메인으로 재정의될 수 있다. 도 7을 참조하면, 제2 연산 단계에서, 제2 레이어의 가중치는 제1 내지 제2 메모리 유닛에 저장될 수 있다. 이 에, 컨트롤러는 DMA를 제어하여 메인 메모리로부터 제2 레이어의 가중치를 제1 내지 제2 메모 리 유닛에 저장할 수 있다. 제1 내지 제2 메모리 유닛은 제4 메모리 그룹으로 설정될 수 있으며, 가중치 도메인으로 정의될 수 있다. 도 7을 참조하면, 제2 연산 단계에서, 제2 레이어의 출력 특징맵은 제3 내지 제6 메모리 유닛에 저장될 수 있다. 이에, 컨트롤러는 복수의 프로세싱 엘리먼트들로부터 제2 레이어의 출력 특징맵을 제3 내지 제 6 메모리 유닛에 저장할 수 있다. 제3 내지 제6 메모리 유닛은 제5 메모리 그룹으로 설정될 수 있으며, 출 력 특징맵 도메인으로 정의될 수 있다. 각각의 메모리 그룹은 분석된 인공신경망 데이터 지역성에 따라 각 연산 단계마다 재설정될 수 있다. 여태까지 도 5 내지 도 8을 참조하여 인공신경망모델의 동일한 데이터 지역성을 분석하여 가변 메모리에서 도메인 변경을 통해서 출력 특징맵을 입력 특징맵으로 재사용 하는 예시를 설명하였다. 본 개시의 일 예시에 따 르면, 컴파일 된 머신 코드는 적어도 두개의 레이어를 분석하여, 가변 메모리에 저장된 특징맵을 재사용 할 수 있다. 부연 설명하면, 본 개시의 예시들에 따르면, 각각의 메모리 유닛은 각각의 메모리 뱅크로 지칭되는 것도 가능하 다. 각각의 메모리 유닛은 메모리 뱅크 식별 번호 또는 메모리 어드레스를 기초로 제어될 수 있다. 입력 특징맵 멀티플렉서는 입력 특징맵 도메인의 메모리 유닛들은 선택하도록 구성될 수 있다. 가중치 멀 티플렉서는 가중치 도메인의 메모리 유닛들을 선택하도록 구성될 수 있다. 출력 특징맵 멀티플렉서는 출력 특징맵 도메인의 메모리 유닛들은 선택하도록 구성될 수 있다. 컨트롤러는 신경 프로세싱 유닛의 가변 메모리의 구조 데이터 (예를 들면, 복수의 메모리 유닛 들 각각의 용량 및 개수) 및 인공신경망모델의 각각의 레이어의 크기 정보 (예를 들면, 각 레이어의 가중치의 크기 및 특징맵의 크기)에 기초하여 생성된 머신 코드에 의해서 가변 메모리를 제어할 수 있다.즉, 가변 메모리의 구조 데이터 및 인공신경망모델의 구조 데이터를 기초로, 컨트롤러는 특정 레이어 의 특정 데이터가 가변 메모리의 특정 메모리 유닛에 액세스되도록 DMA의 읽기 또는 쓰기 동작을 스 케줄링 할 수 있다. 여기서 스케줄링은 적어도 두 개의 레이어의 연산 단계에 관한 데이터 지역성을 포함할 수 있다. 부연 설명하면, 컨트롤러는 인공신경망모델의 복수의 레이어의 연산 순서 및 그것의 데이터 지역성을 분석 한 정보에 기초하여 데이터 재사용이 가능한 가변 메모리의 메모리 유닛의 도메인 할당을 스케줄링 할 수 있다. 도 8을 참조하여, 출력 특징맵 재사용의 효과에 관해서 부연 설명한다. 신경 프로세싱 유닛이 처리하는 인공신경망모델의 각각의 레이어는 소정의 데이터 크기를 가지는 출력 특징맵을 생성한다. 그리고 각각의 출력 특징맵이 다음 레이어의 입력 특징맵으로 재사용 될 경우, 신경 프로세싱 유닛은 메인 메모리에 출 력 특징맵을 전송하지 않을 수 있다. 따라서, 버스를 통한 메인 메모리의 데이터 전송량을 저감할 수 있는 효과가 있다. 이하에서는 본 발명의 다른 예시에 따른 가변 메모리(300')를 포함하는 신경 프로세싱 유닛에 대해서 설명한다. 본 발명의 다른 예시와 본 발명의 일 예시는 프리패치 메모리에 대해서만 차이점이 있으므로, 이를 중점적으로 설명한다. 도 9는 본 개시의 다른 예시에 따른 내부 메모리를 포함하는 신경 프로세싱 유닛의 내부 메모리의 내부 구성을 나타내는 도면이다. 도 9를 참조하면, 가변 메모리(300')는 복수의 메모리 유닛들, 입력 특징맵 멀티플렉서, 가중치 멀티플렉 서 및 출력 특징맵 디멀티플렉서를 포함할 뿐만 아니라, 프리패치 메모리를 더 포함할 수 있다. 프리패치 메모리는 인공신경망모델의 연산에 필요한 데이터를 선택적으로 저장할 수 있다. 즉, 프리패치 메모리는 DMA으로부터 인공신경망모델의 연산 중에 고정되는 가중치, 입력 특징맵 및 출력 특징맵 중 어느 하나를 선택적으로 특정 연산 단계동안 저장할 수 있다. 프리패치 메모리는 신경 프로세싱 유닛 에서 처리할 인공신경망모델의 각 레이어의 각 도메인의 데이터 크기를 기초로 특정 값을 특정 기간동안 저장할 수 있다. 예를 들면, 표 1을 참조하면, 제2 레이어의 가중치는 288 바이트이다. 또한, 제4 레이어의 가중치는 576 바이트 이다. 이러한 경우, 프리패치 메모리는 제2 레이어 및 제4 레이어의 가중치를 지속적으로 저장할 수 있다. 즉, 특정 데이터의 크기가 현저히 적은 경우, 불필요한 메인 메모리 접근 명령을 생략하기 위해, 제일 작 은 데이터의 크기 순서대로 특정 데이터를 프리패치 메모리에 상주시킬 수 있다. 상주된 가중치는 1회 추 론시마다 재사용되는 것이 가능하다. 예를 들면, 인공신경망모델이 초당 60프레임의 속도로 추론 연산을 수행할 경우, 제1 레이어의 가중치는 초당 60번 재사용될 수 있고 제2 레이어의 가중치도 초당 60번 재사용 될 수 있다. 또한, 저장하는 데이터의 크기 또 한 상대적으로 매우 작기 때문에, 전체 메모리 가동률에 실질적으로 영향을 주지 않을 수 있다. 다른 예를 들면, 인공신경망모델이 일렬로 연결된 레이어 이외에 분기(branch)를 가질 경우, 프리패치 메모리 에 하나의 분기에 대응되는 데이터를 저장할 수 있다. 이러한 값은 스킵 커넥션 연산 또는 접합 연산일 수 있다. 즉, 컴파일러는 신경 프로세싱 유닛의 프리패치 메모리의 메모리 유닛 정보, 인공신경망모델의 구조 정보 및 각 레이어의 각 도메인의 데이터 크기 정보를 분석하여 프리패치 메모리에 저장할 데이터를 결정 할 수 있다. 예를 들면, 컴파일러는 프리패치 메모리의 용량보다 작은 가중치 데이터들을 선택적으로 저장 하도록 결정할 수 있다. 예를 들면, 프리패치 메모리의 용량이 1,024 바이트일 경우, 288 바이트의 제2 레 이어의 가중치와 576 바이트의 제4 레이어의 가중치를 프리패치 메모리에 저장할 수 있다. 프리패치 메모리는 가변 메모리의 적어도 하나의 메모리 유닛일 수 있다. 단, 본 개시는 이에 제한되 지 않는다. 따라서 프리패치 메모리는 DMA, 입력 특징맵 멀티플렉서, 가중치 멀티플렉서, 및 출력 특징맵 디멀티플렉서와 각각 연결될 수 있다. 그리고, 복수의 프로세싱 엘리먼트들와 복수의 메모리 유닛들이 통신 중 일 때, DMA를 통해서, 인공 신경망모델의 연산에 필요한 데이터를 프리패치 메모리로부터 읽어 들일 수 있다.한편, 프리패치 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있으나, SRAM으로 구 성되는 것이 연산 처리 속도면에서 유리하다. 상술한 바와 같이, 본 개시의 다른 예시에서는 프리패치 메모리를 가변 메모리(300')(즉, 내부 메모리)에 더 포함시킴으로써, 복수의 프로세싱 엘리먼트들과 복수의 메모리 유닛들이 통신 중 일 때 연산에 필요한 데이터를 미리 불러들일 수 있다. 또한, 특정 데이터를 프리패치 메모리에 상주시킴으로 써 메모리 사용량 을 최소화하면서 특정 데이터를 반복하여 재사용할 수 있다. 이에, 신경 프로세싱 유닛의 연산 속도를 보다 향 상될 수 있다. 도 10은 시스템의 단위 동작 당 에너지 소모를 개략적으로 설명하는 표이다. 도 10을 참조하면, 시스템의 단위 동작 당 소비되는 에너지를 개략적으로 설명하는 표이다. 에너지 소모는 메모 리 액세스, 덧셈 연산 및 곱셈 연산으로 구분하여 설명할 수 있다. 도 10의 “Add”는 가산기(adder)를 의미한다. 가산기는 프로세싱 엘리먼트(PE)에 포함될 수 있다. 도 10의 “ Mult”는 곱셈기(multiplier)를 의미한다. 곱셈기는 프로세싱 엘리먼트(PE)에 포함될 수 있다. 도 10의 “Read”는 메모리 읽기 동작을 의미한다. 도 10의 “SRAM”은 가변 메모리에 대응될 수 있다. 도 10의 “DRAM”은 메인 메모리에 대응될 수 있다. “8b Add”는 가산기의 8비트 정수 덧셈 연산을 의미한다. 8비트 정수 덧셈 연산은 0.03pj의 에너지를 소비할 수 있다. “16b Add”는 가산기의 16비트 정수 덧셈 연산을 의미한다. 16비트 정수 덧셈 연산은 0.05pj의 에너지를 소비 할 수 있다. “32b Add”는 가산기의 32비트 정수 덧셈 연산을 의미한다. 32비트 정수 덧셈 연산은 0.1pj의 에너지를 소비할 수 있다. “16b FP Add”는 가산기의 16비트 부동소수점 덧셈 연산을 의미한다. 16비트 부동소수점 덧셈 연산은 0.4pj의 에너지를 소비할 수 있다. “32b FP Add”는 가산기의 32비트 부동소수점 덧셈 연산을 의미한다. 32비트 부동소수점 덧셈 연산은 0.9pj의 에너지를 소비할 수 있다. “8b Mult”는 곱셈기의 8비트 정수 곱셈 연산을 의미한다. 8비트 정수 곱셈 연산은 0.2pj의 에너지를 소비할 수 있다. “32b Mult”는 곱셈기의 32비트 정수 곱셈 연산을 의미한다. 32비트 정수 곱셈 연산은 3.1pj의 에너지를 소비 할 수 있다. “16b FP Mult”는 곱셈기의 16비트 부동소수점 곱셈 연산을 의미한다. 16비트 부동소수점 곱셈 연산은 1.1pj의 에너지를 소비할 수 있다. “32b FP Mult”는 곱셈기의 32비트 부동소수점 곱셈 연산을 의미한다. 32비트 부동소수점 곱셈 연산은 3.7pj의 에너지를 소비할 수 있다. 예를 들면, 신경 프로세싱 유닛이 32비트 부동소수점 곱셈을 하는 경우와 8비트 정수 곱셈을 하는 경우를 비교하면, 단위 동작 당 에너지 소모는 대략 18.5배 차이가 난다. “32b SRAM Read”는 신경 프로세싱 유닛의 가변 메모리가 SRAM(static random access memory)일 경우, 32비트의 데이터 읽기 액세스를 의미한다. 32비트의 데이터를 가변 메모리에서 읽어오는데 5pj의 에 너지를 소비할 수 있다. “32b DRAM Read”는 시스템의 메인 메모리가 DRAM일 경우, 32비트의 데이터 읽기 액세스를 의미한다. 32 비트 데이터를 메인 메모리에서 가변 메모리으로 읽어오는데 640pj의 에너지를 소비할 수 있다. 에 너지 단위는 피코-줄(pj)을 의미한다. DRAM으로 구성된 시스템의 메인 메모리에서 32비트 데이터를 읽어오는 경우와 SRAM으로 구성된 가변 메모 리에서 32비트 데이터를 읽어오는 경우 단위 동작 당 에너지 소모는 대략 128배 차이가 난다. 여기서 주목해야할 부분은, 메인 메모리에서 인공신경망모델의 데이터를 신경 프로세싱 유닛으로 복사할 때 상당한 소비 전력을 사용한다는 점이다. 다르게 설명하면, 가변 메모리에서 인공신경망모델의 동일한 데이터 지역성을 가지는 데이터를 재사용할 경우, 시스템 및 신경 프로세싱 유닛의 소비 전력을 상당히 저감할 수 있는 효과가 있다. 즉, 신경 프로세싱 유닛은 인공신경망모델의 구조 데이터 또는 인공신경망 데이터 지역성 정보에 기초하 여 가변 메모리 내부에 저장된 데이터의 재사용을 제어하고, 신경 프로세싱 유닛은 데이터 재사용 시 메인 메모리에 메모리 액세스 요청을 하지 않도록 구성될 수 있다. 즉, 본 개시의 일 예시에 따른 신경 프로세싱 유닛은 신경 프로세싱 유닛에서 작동될 인공신경망모 델의 구조 데이터 또는 인공신경망 데이터 지역성 정보에 기초하여, 메인 메모리에 메모리 액세스 요청을 최소 화할 수 있으며, 가변 메모리 내부에 저장된 데이터의 재사용 빈도를 증가시킬 수 있다. 따라서 가변 메모 리의 정적 메모리의 사용 빈도가 증가될 수 있으며, 신경 프로세싱 유닛의 소비 전력을 저감하고 연 산 속도를 향상시킬 수 있는 효과가 있다. 즉, 신경 프로세싱 유닛은 인공신경망모델의 구조 데이터 또는 인공신경망 데이터 지역성 정보에 기초하 여 가변 메모리 내부에 저장된 데이터의 재사용을 제어하고, 신경 프로세싱 유닛은 데이터 재사용 시 메인 메모리에 메모리 액세스 요청을 하지 않도록 구성될 수 있다. 도 11은 가변 메모리에서 출력 특징맵 재사용 적용 시 신경 프로세싱 유닛의 추론 속도를 변화를 설명하는 그래 프이다. 도 11을 참조하면, 종래의 방법으로 신경 프로세싱 유닛이 인공신경망모델의 1회 추론 연산을 처리하는 시간은 2.14ms로 측정되었다. 본 개시의 일 예시에 따른, 동일한 데이터 지역성을 기초로 특징맵 재사용이 적용 된 신경 프로세싱 유닛이 인공신경망모델의 1회 추론 연산을 처리하는 시간이 0.85ms로 측정되었다. 즉, 인공신경망모델의 인공신경망 데이터 지역성을 분석하여 신경 프로세싱 유닛이 특징맵을 재사용할 경우, 1회 추론 연산을 처리하는 시간이 2.14ms에서 0.85ms로 저감되었다. 즉, 동일한 인공신경망모델을 동일한 신경 프로세싱 유닛에서 처리하더라도, 서로 다른 도메인의 데이터가 동일 한 데이터 지역성을 가지는 것을 재사용하도록 구성된 머신 코드를 활용할 경우, 가변 메모리의 메모리 유 닛들의 도메인을 각각 제어하는 입력 특징맵 멀티플렉서, 가중치 멀티플렉서, 및 출력 특징맵 디멀티 플렉서를 제어하여 신경 프로세싱 유닛의 추론 속도를 종래 대비 상당히 향상시킬 수 있는 효과가 있다. 1회 추론에 2.14ms이 소요될 경우, 초당 467 frame per second(FPS)를 달성할 수 있다. 1회 추론에 0.85ms이 소요될 경우, 초당 1,176 FPS를 달성할 수 있다. 여기서 1회 추론은 신경 프로세싱 유닛이 도 8에 도시된 예시적인 인공신경망모델의 제1 레이어부터 제28 레이어까지 처리하는 것을 의미할 수 있다. 즉, 1회 추론은 인 공신경망모델의 모든 레이어를 처리하는 것을 의미할 수 있다. 부연 설명하면, 메인 메모리가 DRAM일 경우, 인공신경망모델이 저장된 메모리 어드레스에 액세스하기 위 해서는 Column Address Strobe (CAS) latency 및 Row Address Strobe (RAS) latency에 의해서 데이터 전송이 지연될 수 있다. 따라서, DMA가 메인 메모리에 빈번한 데이터 액세스 접근 요청을 보내는 것은 실질 적으로 신경 프로세싱 유닛의 처리 속도를 저하시킬 수 있으며, 메인 메모리에 의한 데이터 제공 지연 발 생시 신경 프로세싱 유닛의 연산 처리에 필요한 데이터 공급이 지연될 수 있다. 즉, 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 가변 메모리의 각 도메인의 크기를 각 연산 단계마다 조절하여, 가변 메모리의 각 도메인의 가동률을 각 연산 단계마다 최대화할 수 있는 효과가 있다. 또한, 컴파일러가 동일한 데이터 지역성을 가지는 출력 특징맵과 입력 특징맵을 분석할 경우, 도메인을 변경하면서 특징맵을 재사용할 수 있다. 이에, 신경 프로세싱 유닛의 처리 속도를 대폭 향상시킬 수 있는 효과가 있다. 또한, 컴파일러가 인공신경망모델의 구조 데이터를 제공받을 경우, 연산 단계마다 동일한 데이터 지역성을 가지 는 데이터의 재사용이 스케줄링 된 머신 코드를 생성할 수 있다. 도 12는 가변 메모리에서 출력 특징맵 재사용 적용 시 신경 프로세싱 유닛과 메인 메모리 사이의 데이터 전송량 을 비교하는 그래프이다. 도 12를 참조하면, 종래의 방법으로 신경 프로세싱 유닛이 인공신경망모델의 1회 추론 연산 시 신경 프로 세싱 유닛과 메인 메모리 사이의 데이터 전송량은 14.4Mbyte로 측정되었다. 본 개시의 일 예시에 따른, 동일한 데이터 지역성을 기초로 특징맵 재사용이 적용된 신경 프로세싱 유닛과 메인 메모리 사이의 데이터 전송량은 4.36Mbyte로 측정되었다. 즉, 인공신경망모델의 인공신경망 데이터 지역성을 분석하여 신경 프로세싱 유닛이 특징맵을 재사용할 경우, 1회 추론 연산 신경 프로세싱 유닛과 메인 메모리 사이의 데이터 전송량은 14.4MByte에서 4.36MByte로 저감되었다. 즉, 표 8을 다시 참조하면, 제1 레이어 에서 이미지 센서에서 150KByte의 입력 영상을 입력 특징맵으로 제공받을 수 있다. 이후, 모든 특징맵은 가변 메모리에서 각 연산단계마다 재사용 될 수 있다. 다만, 이러한 경우는, 가변 메모리의 용량이 각각의 레이어의 가중치, 입력 특징맵, 및 출력 특징맵의 데이터 크기보다 클 경우 가능하다. 만약 가변 메모리 의 용량이 각각의 레이어의 가중치, 입력 특징맵, 및 출력 특징맵의 데이터 크기보다 작을 경우, 타일링 알고리즘이 적용될 수 있다. 즉, 특징맵을 재사용하여 도 8의 인공신경망모델을 처리할 경우, 1회 추론 시 DRAM으로 구성된 메인 메모리 의 데이터 전송량이 종래 대비 10Mbyte 저감될 수 있다. 다시, 도 10을 참조하면, 단위 동작 당 에너지 소모는 메인 메모리가 가변 메모리 대비 대략 128배이다. 따라서, 특징맵 재사용으로 인해서, 메인 메모리에 의한 소비 전력 낭비를 최소화할 수 있다. 즉, 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 가변 메모리의 각 도메인의 크기를 각 연산 단계마다 조절하여, 메인 메모리에 불필요한 출력 특징맵을 전송하지 않을 수 있다. 만약, 신경 프로세싱 유닛이 제1 연산 단계의 출력 특징맵을 제2 연산 단계에서 재사용하는 것이 스케줄링 되어 있지 않다면, 컨트롤러는 내부 메모리의 가용 공간 확보를 위해서 출력 특징맵을 메인 메모리에 전송해야 할 수 있다. 이후, 메인 메모리에 저장된 출력 특징맵을 제2 연산 단계의 입력 특징맵으로 활용하기 위해서, DMA는 메인 메모리에 저장된 출력 특징맵을 내부 메모리로 다시 읽어올 수 있다. 즉, 이어지는 연산 단계에서 동일한 데이터 지역성을 분석하지 않을 경우, 불필요한 데이터 전송이 발생될 수 있다. 본 개시의 일 예시에 따른 신경 프로세싱 유닛은 데이터 지역성을 분석하고, 가변 메모리의 특정 도메인을 제어하 는 선택기, 예를 들면, 제1 내지 제3 선택기를 제어하여 특징맵을 재사용 할 수 있는 효과가 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 인공신경망모델의 데이터 지역성을 분석하고, 연속되 는 연산 단계에서 동일한 데이터 지역성을 가지는 데이터를 재사용 하도록 구성될 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 각각의 도메인을 가지는 가변 메모리 및 각각의 도메인을 제어하는 선택기들(331, 332, 333)을 포함할 수 있다. 본 개시의 예시들에 따르면, 가변 메모리의 각각의 도메인의 용량은 각 연산 단계마다 조절될 수 있다. 본 개시의 예시들에 따르면, 프로세싱 엘리먼트(PE)의 입력부 및 출력부는 각각의 도메인과 연결된 선택기들 (331, 332, 333)에 연결될 수 있다. 본 개시의 예시들에 따르면, 컨트롤러는 동일한 데이터 지역성의 존재가 분석된 머신 코드에 의해서 선택 기들(331, 332, 333)를 제어하여, 가변 메모리에 저장된 특징맵을 재사용할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 복수의 메모리 유닛들을 포함하는 내부 메모리; 및 인공신경 망모델의 복수의 연산 단계가 설정된 머신 코드의 오퍼레이션 스케줄링에 기반하여, 복수의 메모리 유닛들 각각 에 입력 특징맵 도메인, 가중치 도메인, 및 출력 특징맵 도메인 중 적어도 하나의 도메인의 데이터의 읽기 및 쓰기 동작을 제어하도록 구성된 컨트롤러;를 포함할 수 있다. 본 개시의 예시들에 따르면, 상기 머신 코드는 복수의 연산 단계들 대한 입력 특징맵, 가중치 및 출력 특징맵들 의 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 머신 코드는 인공신경망모델의 복수의 연산 단계 각각에 대한 입력 특징맵의 용량 정보, 가중치의 용량 정보 및 출력 특징맵의 용량 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 머신 코드는 인공신경망모델의 복수의 연산 단계들 중 동일한 데이터 지역성을 가 지는 연산 단계에 관한 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 머신 코드는 인공신경망 데이터 지역성에 기초한 인공신경망모델의 복수의 연산 단 계 각각의 연산 순서 정보를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 메인 메모리로부터 데이터를 읽어들여, 내부 메모리에 입력 특징맵 데이터 및 가중치 데이터를 기입하도록 구성된 DMA(Direct Memory Access); 및 내부 메모리로부터 입력 특징맵 데이터 및 가중치 데이터를 입력 받아 연산하여 출력 특징맵을 생성하도록 구성된, 인공지능(AI) 연산부 를 더 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 입력 특징맵 데이터 및 가중치 데이터의 합성곱 연산을 수행 하여 출력 특징맵 데이터를 생성하도록 구성된 적어도 하나의 프로세싱 엘리먼트를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 머신 코드에 기초하여, 복수의 메모리 유닛들 각각을 선택하 도록 구성된 제1 내지 제3 선택기; 및 제1 선택기를 통해 입력 특징맵 데이터를 입력 받도록 구성된 제1 입력부, 제2 선택기를 통해 가중치 데이터를 입력 받도록 구성된 제2 입력부, 및 제3 선택기를 통해 출력 특징 맵 데이터를 출력하도록 구성된 출력부를 포함하는 프로세싱 엘리먼트를 포함할 수 있다. 본 개시의 예시들에 따르면, 내부 메모리는, 복수의 메모리 유닛들과 연결된 가중치 멀티플렉서, 입력 특징맵 멀티플렉서 및 출력 특징맵 디멀티플렉서를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 제1 도메인, 제2 도메인, 및 제3 도메인의 데이터를 저장하 도록 구성된 복수의 메모리 유닛들을 포함하는 내부 메모리; 제1 도메인의 데이터를 입력 받도록 구성된 제1 입 력부, 제2 도메인의 데이터를 입력 받도록 구성된 제2 입력부, 및 제3 도메인의 데이터를 출력하도록 구성된 출 력부를 포함하는, AI 연산부; 복수의 메모리 유닛들 중 제1 도메인의 데이터가 저장된 메모리 유닛과 제1 입력 부를 연결하도록 구성된, 제1 선택기; 복수의 메모리 유닛들 중 제2 도메인의 데이터가 저장된 메모리 유닛과 제2 입력부를 연결하도록 구성된, 제2 선택기; 및 복수의 메모리 유닛들 중 제3 도메인의 데이터가 저장될 메모 리 유닛과 출력부를 연결하도록 구성된, 제3 선택기를 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 인공신경망모델의 동일한 데이터 지역성을 분석한 머신 코드 에 의해서 제1 내지 제3 선택기를 제어하도록 구성된 컨트롤러를 포함할 수 있다. 본 개시의 예시들에 따르면, 제1 선택기는, 머신 코드에 정의된 연산 순서에 따라, 제1 도메인의 데이터 중 적 어도 일부를 AI 연산부에 입력하고, 제2 선택기는, 머신 코드에 정의된 연산 순서에 따라, 제2 도메인의 데이터 중 적어도 일부를 AI 연산부에 입력하고, 그리고 제3 선택기는, 머신 코드에 정의된 연산 순서에 따라, 제3 도 메인의 데이터 중 적어도 일부를 복수의 메모리 유닛들 중 적어도 하나에 출력하도록 구성될 수 있다. 본 개시의 예시들에 따르면, 복수의 메모리 유닛들 각각은 서로 동일하거나 또는 서로 다른 소정의 메모리 용량 을 가지도록 구성될 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 복수의 메모리 유닛들 각각의 메모리 용량을 고려하여 각 연 산 단계마다 복수의 메모리 유닛들 각각에 제1 내지 제3 도메인을 설정하도록 구성된 머신 코드를 실행하도록 구성된 컨트롤러를 더 포함할 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 내부 메모리를 제어하도록 구성된 컨트롤러를 더 포함할 수 있다. 컨트롤러는 동일한 데이터 지역성을 분석한 머신 코드에 기반하여, 다음 연산 단계에서 제3 도메인의 데 이터를 제1 도메인의 데이터로 재설정 하도록 구성될 수 있다. 본 개시의 예시들에 따르면, 제1 도메인은 입력 특징맵이고, 제2 도메인은 가중치이고, 제3 도메인은 출력 특징 맵일 수 있다. 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은 다음 연산 단계에서 입력 특징맵과 동일한 데이터 지역성을 가지는 출력 특징맵이 재사용 되도록, 제1 내지 제3 선택기를 이어지는 연산 단계들 마다 각각 제어하도록 구성 된 컨트롤러를 포함할 수 있다. 본 개시의 예시들에 따르면, 복수의 메모리 유닛들 중 제1 도메인으로 설정된 메모리 유닛들은 제1 메모리 그룹 이고, 제2 도메인으로 설정된 메모리 유닛들은 제2 메모리 그룹이고, 제3 도메인으로 설정된 메모리 유닛들은 제3 메모리 그룹일 수 있다. 본 개시의 예시들에 따르면, 내부 메모리는 인공신경망모델의 연산에 지속적으로 필요한 고정되는 가중치, 입력 특징맵 및 출력 특징맵 중 어느 하나를 저장하도록 구성된 프리패치 메모리를 포함할 수 있다. 본 개시의 예시들에 따르면, 시스템은 적어도 하나의 인공신경망모델의 적어도 일부 데이터를 저장하도록 구성 된 메인 메모리; 및 적어도 하나의 인공신경망모델의 적어도 일부 데이터를 특징맵 및 가중치로 구분하여 복수 의 메모리 유닛들 중 특정 유닛에 선택적으로 저장하도록 구성된 가변 메모리; 메인 메모리와 가변 메모리 사이의 메모리 오퍼레이션을 제어하도록 구성된 직접 메모리 액세스(DMA) 회로부; 및 특징맵과 가중치를 가변 메모 리에서 입력 받아 인공신경망 추론 연산을 처리하도록 구성된 AI 연산부;를 포함하는 신경 프로세싱 유닛을 포 함할 수 있다 본 개시의 예시들에 따르면, 신경 프로세싱 유닛은, 적어도 하나의 인공신경망모델의 적어도 하나의 동일한 데 이터 지역성 정보를 기초로, 메인 메모리와 가변 메모리 사이의 특징맵의 중복된 데이터 통신을 저감하도록 컴 파일 된 머신 코드에 의해서 실행되도록 구성될 수 있다. 본 개시의 예시들에 따르면, 시스템은 적어도 하나의 인공신경망모델이 컴파일 된 머신 코드에 의해서 가변 메 모리의 특징맵을 재사용하여 특징맵 재사용이 없는 종래 기술 대비 소비 전력이 상대적으로 더 저감될 수 있다. 본 개시의 예시들에 따르면, 시스템은 적어도 하나의 인공신경망모델이 컴파일 된 머신 코드에 의해서 가변 메 모리의 특징맵을 재사용하여 특징맵 재사용이 없는 종래 기술 대비 추론 연산 처리 시간이 상대적으로 더 저감 될 수 있다. 본 명세서와 도면에 게시된 본 개시의 예시들은 본 개시의 기술내용을 쉽게 설명하고 본 개시의 이해를 돕기 위 해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 여기에 게시된 예시들 이외에도 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상 의 지식을 가진 자에게 자명한 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2022-0132180", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 예시에 따른 가변 되는 내부 메모리를 포함하는 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 2는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가중치 메모리와 특징맵 메모리를 나타내는 도면이다. 도 3 및 4는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가중치 메모리, 입력 특 징맵 메모리 및 출력 특징맵 메모리를 나타내는 도면이다. 도 5는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가변 메모리의 내부 구성을 나 타내는 도면이다. 도 6 및 7는 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가중치 메모리, 입력 특 징맵 메모리 및 출력 특징맵 메모리를 구성하는 복수의 메모리 유닛들을 동작 예시를 나타내는 도면이다. 도 8은 본 개시의 일 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛에서 처리하는 인공신경망모델의 레이어 별 데이터 크기 정보를 나타내는 도면이다. 도 9는 본 개시의 다른 예시에 따른 가변 메모리를 포함하는 신경 프로세싱 유닛의 가변 메모리의 내부 구성을 나타내는 도면이다. 도 10은 시스템의 단위 동작 당 에너지 소모를 개략적으로 설명하는 표이다. 도 11은 가변 메모리에서 출력 특징맵 재사용 적용 시 신경 프로세싱 유닛의 추론 속도를 변화를 설명하는 그래 프이다. 도 12는 가변 메모리에서 출력 특징맵 재사용 적용 시 신경 프로세싱 유닛과 메인 메모리 사이의 데이터 전송량 을 비교하는 그래프이다."}
