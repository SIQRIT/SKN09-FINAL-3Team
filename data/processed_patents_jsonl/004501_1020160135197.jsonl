{"patent_id": "10-2016-0135197", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0042702", "출원번호": "10-2016-0135197", "발명의 명칭": "인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 전자장", "출원인": "경북대학교 산학협력단", "발명자": "임경식"}}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자가 구비한 적어도 하나의 웨어러블 장치와 통신을 수행하는 통신부;상기 웨어러블 장치로부터 수신된 운동 데이터에서 움직임 데이터, 생체 데이터 및 음성 데이터를 추출하고, 상기 움직임 데이터를 기반으로 상기 사용자의 움직임 상태를 확인하고, 상기 생체 데이터와 상기 음성 데이터를기반으로 상기 사용자의 감정 상태를 예측하고, 상기 움직임 상태 및 상기 감정 상태를 기반으로 인공지능 모델을 통해 심리 처방 데이터를 확인하는 제어부; 및상기 심리 처방 데이터를 출력하는 표시부;를 포함하는 전자장치."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제어부는, 기 저장된 최고 기록 데이터와 상기 움직임 데이터의 비교결과에 따라 확인된 상기 사용자의 움직임 상태를 상기 표시부에 출력하는 전자장치."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제어부는, 상기 예측된 감정 상태에 대응하는 모델링 데이터를 생성하는 전자장치."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제어부는, 상기 생성된 모델링 데이터와 임계치 이상 유사한 모델링 데이터에 매핑되어 저장된 심리 처방 데이터를 인공지능 모델을 통해 확인하는 전자장치."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 심리 처방 데이터는, 상기 사용자의 움직임 및 감정 상태를 제어하기 위한 음성 데이터 및 시각 데이터를 포함하는 전자장치."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제어부는, 상기 심리 처방 데이터를 상기 적어도 하나의 웨어러블 장치로 전송하는 전자장치."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 공개특허 10-2018-0042702-3-상기 움직임 상태와 상기 감정 상태가 매핑된 모델링 데이터, 상기 모델링 데이터와 매핑된 상기 심리 처방 데이터를 저장하는 메모리;를 더 포함하는 전자장치."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "적어도 하나의 웨어러블 장치로부터 운동 데이터를 수신하는 동작;상기 운동 데이터에서 움직임 데이터를 기반으로 상기 사용자의 움직임 상태를 확인하는 동작; 상기 운동 데이터에서 생체 데이터와 음성 데이터를 추출하는 동작;상기 생체 데이터와 상기 음성 데이터를 기반으로 사용자의 감정 상태를 예측하는 동작;상기 움직임 상태 및 상기 감정 상태를 기반으로 인공지능 모델을 통해 심리 처방 데이터를 확인하는 동작; 및상기 심리 처방 데이터를 출력하는 동작;을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 움직임 상태를 확인하는 동작은, 기 저장된 최고 기록 데이터와 상기 확인된 움직임 데이터를 비교하는 동작; 및상기 비교결과에 따라 상기 사용자의 움직임 상태를 확인하는 동작;을 포함하는 방법."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 움직임 상태를 출력하는 동작;을 더 포함하는 방법."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 사용자의 감정 상태를 예측하는 동작은, 상기 예측된 감정 상태에 대응하는 모델링 데이터를 생성하는 동작; 을 더 포함하는 방법."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 심리 처방 데이터를 확인하는 동작은, 상기 생성된 모델링 데이터와 임계치 이상 유사한 모델링 데이터에 매핑되어 저장된 심리 처방 데이터를 인공지능 모델을 통해 확인하는 동작인 방법."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 심리 처방 데이터를 확인하는 동작은, 상기 사용자의 움직임 및 감정 상태를 제어하기 위한 음성 데이터 및 시각 데이터를 포함하는 상기 심리 처방공개특허 10-2018-0042702-4-데이터를 확인하는 동작인 방법."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 확인된 심리 처방 데이터를 상기 적어도 하나의 웨어러블 장치로 전송하는 동작;을 포함하는 방법."}
{"patent_id": "10-2016-0135197", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "움직임 데이터, 생체 데이터 및 음성 데이터를 포함하는 사용자의 운동 데이터를 획득하는 적어도 하나의 웨어러블 장치; 및상기 적어도 하나의 웨어러블 장치로부터 상기 운동 데이터를 수신하고, 상기 움직임 데이터를 기반으로 상기사용자의 움직임 상태를 확인하고, 상기 생체 데이터와 상기 음성 데이터를 기반으로 상기 사용자의 감정 상태를 예측하고, 상기 움직임 상태 및 상기 감정 상태를 기반으로 인공지능 모델을 통해 심리 처방 데이터를 확인하여 상기 적어도 하나의 웨어러블 장치로 전송하는 전자장치;를 포함하는 시스템."}
{"patent_id": "10-2016-0135197", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 전자장치, 방법 및 시스템에 관한 것으로, 사용자가 구비한 적어도 하나의 웨어러블 장치와 통신을 수행하는 통신부, 웨어러블 장치로부터 수신된 운동 데이터에서 움직임 데이터, 생체 데이터 및 음성 데이터를 추출하고, 움직임 데이터를 기반으로 사용자의 움직임 상태를 확인하고, 생체 데이터와 음성 데이터를 기반으로 사용자의 감정 상태를 예측 하고, 움직임 상태 및 감정 상태를 기반으로 인공지능 모델을 통해 심리 처방 데이터를 확인하는 제어부 및 심리 처방 데이터를 출력하는 표시부를 포함할 수 있고, 다른 실시 예로도 적용이 가능하다."}
{"patent_id": "10-2016-0135197", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 전자장치, 방 법 및 시스템에 관한 것으로서, 웨어러블 장치로부터 사용자의 운동 데이터를 획득하여 사용자 상태에 따라 사 용자를 독려할 수 있는 심리 처방 데이터를 제공하는 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방 하는 웨어러블 장치를 이용한 전자장치, 방법 및 시스템을 제공하는 것이다."}
{"patent_id": "10-2016-0135197", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 스마트 워치, 활동량 측정 밴드 등 사용자가 착용 가능한 웨어러블 장치를 이용하여 사용자의 움직임에 대한 센싱 정보를 수집하는 기술이 상용화되고 있다. 특히, 웨어러블 장치에서 수집된 센싱 정보를 이용하여 사 용자의 심박수, 운동량, 사용자의 스트레스 정도 및 사용자의 감정 상태 등을 확인한다. 사용자는 웨어러블 장 치와 연결된 전자장치를 통해 웨어러블 장치에서 확인된 센싱 정보를 시각적으로 또는 청각적으로 확인할 수 있 다. 사용자는 자신의 현재 움직임 상태 및 감정 상태를 확인할 수 있다. 그러나, 아직까지는 사용자가 자신의 움직임 상태 및 감정 상태를 직접 확인할 뿐, 이를 이용하여 보다 고차원 적인 서비스를 제공받을 수는 없다. 따라서, 사용자의 움직임 상태 및 감정 상태를 이용하여 고차원적인 서비스 를 제공하는 기술 개발의 필요성이 요구되고 있다."}
{"patent_id": "10-2016-0135197", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 배경 기술에 대응하여 도출된 것으로, 본 발명의 다양한 실시 예들은 웨어러블 장치에서 획득된 사용자의 움직임 상태 및 감정 상태를 기반으로 상담 치료를 대신할 수 있는 인공지능 모델을 통해 사용 자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 전자장치, 방법 및 시스템을 제공하는 것이다."}
{"patent_id": "10-2016-0135197", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이 용한 전자장치는, 사용자가 구비한 적어도 하나의 웨어러블 장치와 통신을 수행하는 통신부, 상기 웨어러블 장 치로부터 수신된 운동 데이터에서 움직임 데이터, 생체 데이터 및 음성 데이터를 추출하고, 상기 움직임 데이터 를 기반으로 상기 사용자의 움직임 상태를 확인하고, 상기 생체 데이터와 상기 음성 데이터를 기반으로 상기 사 용자의 감정 상태를 예측하고, 상기 움직임 상태 및 상기 감정 상태를 기반으로 인공지능 모델을 통해 심리 처방 데이터를 확인하는 제어부 및 상기 심리 처방 데이터를 출력하는 표시부를 포함한다. 또한, 제어부는, 기 저장된 최고 기록 데이터와 상기 움직임 데이터의 비교결과에 따라 확인된 상기 사용자의 움직임 상태를 상기 표시부에 출력한다. 또한, 제어부는, 상기 예측된 감정 상태에 대응하는 모델링 데이터를 생성한다. 또한, 제어부는, 상기 생성된 모델링 데이터와 임계치 이상 유사한 모델링 데이터에 매핑되어 저장된 심리 처방 데이터를 인공지능 모델을 통해 확인한다. 또한, 심리 처방 데이터는, 상기 사용자의 움직임 및 감정 상태를 제어하기 위한 음성 데이터 및 시각 데이터를 포함한다. 또한, 제어부는, 상기 심리 처방 데이터를 상기 적어도 하나의 웨어러블 장치로 전송한다. 또한, 움직임 상태와 상기 감정 상태가 매핑된 모델링 데이터, 상기 모델링 데이터와 매핑된 상기 심리 처방 데 이터를 저장하는 메모리를 더 포함한다. 아울러, 본 발명의 일 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 방법은, 적어도 하나의 웨어러블 장치로부터 운동 데이터를 수신하는 동작, 상기 운동 데이터에 서 움직임 데이터를 기반으로 상기 사용자의 움직임 상태를 확인하는 동작, 상기 운동 데이터에서 생체 데이터 와 음성 데이터를 추출하는 동작, 상기 생체 데이터와 상기 음성 데이터를 기반으로 사용자의 감정 상태를 예측 하는 동작, 상기 움직임 상태 및 상기 감정 상태를 기반으로 인공지능 모델을 통해 심리 처방 데이터를 확인하 는 동작 및 상기 심리 처방 데이터를 출력하는 동작을 포함한다. 또한, 움직임 상태를 확인하는 동작은, 기 저장된 최고 기록 데이터와 상기 확인된 움직임 데이터를 비교하는 동작 및 상기 비교결과에 따라 상기 사용자의 움직임 상태를 확인하는 동작을 포함한다. 또한, 움직임 상태를 출력하는 동작을 더 포함한다. 또한, 사용자의 감정 상태를 예측하는 동작은, 상기 예측된 감정 상태에 대응하는 모델링 데이터를 생성하는 동 작을 더 포함한다. 또한, 심리 처방 데이터를 확인하는 동작은, 상기 생성된 모델링 데이터와 임계치 이상 유사한 모델링 데이터에 매핑되어 저장된 심리 처방 데이터를 인공지능 모델을 통해 확인한다. 또한, 심리 처방 데이터를 확인하는 동작 은, 상기 사용자의 움직임 및 감정 상태를 제어하기 위한 음성 데이터 및 시각 데이터를 포함하는 상기 심리 처 방 데이터를 확인한다. 또한, 확인된 심리 처방 데이터를 상기 적어도 하나의 웨어러블 장치로 전송하는 동작을 포함한다. 아울러, 본 발명의 일 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 시스템은, 움직임 데이터, 생체 데이터 및 음성 데이터를 포함하는 사용자의 운동 데이터를 획득 하는 적어도 하나의 웨어러블 장치 및 상기 적어도 하나의 웨어러블 장치로부터 상기 운동 데이터를 수신하고, 상기 움직임 데이터를 기반으로 상기 사용자의 움직임 상태를 확인하고, 상기 생체 데이터와 상기 음성 데이터 를 기반으로 상기 사용자의 감정 상태를 예측하고, 상기 움직임 상태 및 상기 감정 상태를 기반으로 심리 처방 데이터를 확인하여 상기 적어도 하나의 웨어러블 장치로 전송하는 전자장치를 포함한다."}
{"patent_id": "10-2016-0135197", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 발명의 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이 용한 전자장치, 방법 및 시스템은, 웨어러블 장치에서 획득된 사용자의 움직임 상태 및 감정 상태를 기반으로 상담 치료를 대신할 수 있도록 함으로써, 상담 치료에 대한 거부감을 줄이고, 사용자에게 보다 쉽게 상담 치료 를 제공할 수 있는 효과가 있다. 또한, 본 발명의 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 전자장 치, 방법 및 시스템은, 웨어러블 장치에서 획득된 사용자의 움직임 상태 및 감정 상태를 기반으로 상담 치료를 제공함으로써, 상담 치료에 대한 시간 및 공간적 제약을 해소할 수 있는 효과가 있다. 또한, 본 발명의 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치를 이용한 전자장 치, 방법 및 시스템은, 웨어러블 장치에서 획득된 사용자의 움직임 상태 및 감정 상태를 기반으로 운동 중 상담치료를 실시간으로 제공함으로써, 사용자의 경기 능력을 향상시킬 수 있는 효과가 있다."}
{"patent_id": "10-2016-0135197", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 실시 예들을 보다 상세하게 설명하고자 한다. 이 때, 첨부된 도면에서 동일한 구성 요소는 가능한 동일한 부호로 나타내고 있음을 유의해야 한다. 그리고 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략할 것이다. 도 1은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치 를 이용한 시스템을 나타낸 도면이다. 도 1을 참조하면, 본 발명에 따른 시스템은 적어도 하나의 웨어러블 장치 및 전자장치를 포함한 다. 적어도 하나의 웨어러블 장치는 사용자의 신체에 구비 또는 착용되어 사용자의 운동 데이터를 측정한다. 운동 데이터는, 사용자의 움직임 데이터, 생체 데이터 및 음성 데이터를 포함한다. 이를 위해, 웨어러블 장치 는 가속도 센서 또는 자이로 센서 등을 포함하여 사용자의 움직임 데이터를 측정한다. 웨어러블 장치(10 0)는 심박수 모니터 센서, 심전도 모니터 센서 또는 피부전기저항 센서 등을 포함하여 사용자의 생체 데이터를 측정한다. 웨어러블 장치는 마이크 센서 등을 포함하여 사용자의 음성 데이터를 획득한다. 웨어러블 장치는 실시간으로 획득된 운동 데이터를 전자장치로 전송한다. 이를 위해, 웨어러블 장치 는 전자장치와 무선 또는 유선 통신을 수행한다. 웨어러블 장치는 USB케이블 등을 이용하여 전 자장치와 유선 통신을 수행한다. 웨어러블 장치는 와이파이(wireless fidelity), 블루투스 (Bluetooth), BLE(bluetooth low energy) 및 NFC(near field communications)를 포함하는 근거리 무선 통신 등 을 이용하여 전자장치와 무선 통신을 수행한다. 웨어러블 장치는 전자장치로부터 움직임 데이터를 기반으로 하는 사용자의 움직임 상태, 생체 데이터 와 음성 데이터를 기반으로 하는 감정 상태를 수신하여 이를 출력한다. 웨어러블 장치는 움직임 상태와 감 정 상태를 이용하여 전자장치에서 생성된 심리 처방 데이터를 수신하여 출력한다. 심리 처방 데이터는 사 용자의 움직임 및 감정 상태를 제어하기 위한 음성 데이터 및 시각 데이터를 포함하는 데이터로, 심리상담가 등 의 전문가가 제공하는 상담 치료의 내용이다. 이를 통해, 사용자는 시간 및 공간적 제약을 최소화한 상태로 상 담 치료를 받을 수 있다. 또한, 사용자는 운동 경기 중에 상담 치료를 받을 수 있어 경기 능력을 향상시킬 수 있다. 전자장치는 웨어러블 장치로 제공하기 위한 심리 처방 데이터를 생성하여 저장한다. 아울러, 전자장 치는 웨어러블 장치로부터 수신된 운동 데이터에서 웨어러블 장치를 구비한 사용자의 움직임 데 이터, 생체 데이터 및 음성 데이터를 추출한다. 전자장치는 움직임 데이터를 기반으로 사용자의 움직임 상 태를 확인하고, 생체 데이터와 음성 데이터를 기반으로 사용자의 감정 상태를 예측한다. 전자장치는 인공 지능 모델을 통해 움직임 상태 및 감정 상태를 기반으로 심리 처방 데이터를 확인하여 웨어러블 장치로 전 송한다. 전자장치의 동작에 대한 상세한 설명은 하기의 도 2에서 설명한다. 도 2는 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치 를 이용한 전자장치의 주요 구성을 나타낸 도면이다. 도 2를 참조하면, 본 발명에 따른 전자장치는 통신부, 입력부, 표시부, 메모리, 오디 오처리부 및 제어부를 포함한다. 통신부는 전자장치에서 통신을 수행한다. 통신부는 다양한 방식으로, 웨어러블 장치 등의 외부 장치와 통신을 수행한다. 예를 들면, 통신부는 무선 통신 또는 유선 통신 중 적어도 하나를 수행한다. 통신부는 이동 통신망 또는 데이터 통신망 중 적어도 어느 하나에 접속한다. 이를 위해, 통신부 는 와이파이(wireless fidelity), 블루투스(Bluetooth), BLE(bluetooth low energy) 및 NFC(near field communications)를 포함하는 근거리 무선 통신을 수행한다. 입력부는 전자장치의 사용자 입력에 대응하여, 입력데이터를 발생시킨다. 입력부는 적어도 하나 의 입력수단을 포함한다. 이러한 입력부는 키 패드(key pad), 돔 스위치(dome switch), 터치 패널(touch panel), 조그 셔틀(jog and shuttle), 터치 키(touch key) 중 적어도 하나를 포함한다. 표시부는 표시데이터를 출력한다. 액정 디스플레이(LCD; liquid crystal display), 발광 다이오드(LED; light emitting diode) 디스플레이, 유기 발광 다이오드(OLED; organic LED) 디스플레이 등을 포함할 수 있다. 표시부는 다수개의 발광 소자들을 포함할 수 있다. 표시부는 입력부와 결합되어 터치 스크린 (touch screen)으로 구현될 수 있다. 메모리는 전자장치의 동작 프로그램들을 저장한다. 메모리는 사용자의 움직임 데이터를 이용한 기록 데이터를 저장한다. 메모리는 모델링 데이터를 저장한다. 모델링 데이터는, 기록 데이터를 기반으로 하는 움직임 상태와, 생체 데이터 및 음성 데이터로부터 추출된 특징 데이터를 기반으로 하는 감정 상태의 매핑 에 의해 생성된 데이터이다. 메모리는 사용자의 모델링 데이터와 심리처방 데이터를 매핑하여 인공지능 모 델을 위한 인공지능 데이터를 저장한다. 심리 처방 데이터는, 감정 상태에 따른 일반적인 축하, 위로와 같은 감 정 동조이거나, 스포츠 심리학과 관련된 전문 상담내용 결과에 대응하는 심리 처방 문장을 포함하는 데이터일 수 있다. 심리 처방 데이터는, 사용자의 움직임 상태 및 감정 상태를 제어하기 위해 심리 처방 문장과 관련된 음성 데이터 및 시각 데이터이다. 오디오처리부는 오디오 신호를 처리한다. 이때, 오디오처리부는 스피커(SPK)와 마이크(MIC)를 포함한 다. 오디오처리부는 제어부에서 출력되는 오디오 신호를 스피커를 통해 재생한다. 오디오처리부(25 0)는 마이크에서 발생되는 오디오 신호를 제어부로 전달한다. 제어부는 적어도 하나의 웨어러블 장치로부터 운동 데이터를 수신하고, 운동 데이터에서 웨어러블 장 치를 구비한 사용자의 움직임 데이터, 생체 데이터 및 음성 데이터를 추출한다. 제어부는 움직임 데 이터를 기반으로 사용자의 움직임 상태를 확인하고, 생체 데이터와 음성 데이터를 기반으로 사용자의 감정 상태 를 예측한다. 제어부는 인공지능 모델을 통해 움직임 상태 및 감정 상태를 기반으로 심리 처방 데이터를 확인하여 웨어러블 장치로 전송한다. 우선적으로, 제어부는 기록 데이터, 모델링 데이터 및 심리 처방 데이터를 생성하여 메모리에 저장한 다. 제어부는 적어도 하나의 웨어러블 장치와 페어링을 통해 통신 연결을 수행한다. 제어부는 웨어러블 장치로부터 사용자의 운동 데이터를 수신한다. 제어부는 수신된 운동 데이터를 기반으로 웨 어러블 장치를 구비한 사용자의 움직임 데이터를 추출한다. 제어부는 추출된 움직임 데이터를 기록 데이터로 생성하여 저장한다. 제어부는 기 저장된 적어도 하나의 기록 데이터가 메모리에 존재할 경우, 움직임 데이터를 기 저장된 기록 데이터와 비교한다. 움직임 데이터가 최고 기록 데이터이면, 움직임 데이터로 최고 기록 데이터를 갱신한 다. 움직임 데이터가 최고 기록 데이터가 아니면, 움직임 데이터를 기록 데이터로 저장한다. 제어부는 움직임 데이터를 기반으로 사용자의 움직임 상태를 확인한다. 움직임 상태는, 사용자의 움직임 방향 및 움직임 속 도를 포함하고, 최고 기록 데이터를 기준으로 어느 정도의 강도를 갖는 움직임인지에 대한 수치를 포함한다. 이 를 위해, 최고 기록 데이터는 100의 수치를 갖는 정도의 강도에 대한 움직임일 수 있다. 제어부는 운동 데이터를 기반으로 웨어러블 장치를 구비한 사용자의 생체 데이터 및 음성 데이터에 대한 특징 데이터를 추출한다. 제어부는 기록 데이터와 추출된 특징 데이터로부터 예측된 감정 상태를 매 핑하여 모델링 데이터로 생성한다. 감정 상태는 생체 데이터, 음성 데이터에서 확인된 파형 및 텍스트 데이터로 감정 상태를 예측할 수 있는 인공지능 모델을 통해 확인할 수 있거나, 사용자로부터의 입력에 의해 확인할 수 있다. 제어부는 심리 처방 데이터를 입력한다. 심리 처방 데이터는, 감정 상태에 따른 일반적인 축하, 위로와 같 은 감정 동조이거나, 스포츠 심리학과 관련된 전문 상담내용 결과에 대응하는 심리 처방 문장을 포함하는 데이 터일 수 있다. 심리 처방 데이터는 사용자의 움직임 상태 및 감정 상태를 제어하기 위한 심리 처방 문장과 관련 된 음성 데이터 및 시각 데이터이다. 메모리에 모델링 데이터와 심리 처방 데이터를 매핑하여 인공지능 데이터를 저장한 이후에 제어부는 적어도 하나의 웨어러블 장치와의 통신 연결을 통해 웨어러블 장치로부터 운동 데이터를 수신한다. 제어부는 수신된 운동 데이터에서 웨어러블 장치를 구비한 사용자의 움직임 데이터를 추출하고, 움직 임 데이터를 기반으로 사용자의 움직임 상태를 출력한다. 제어부는 움직임 상태를 사용자가 구비한 웨어러 블 장치로 전송한다. 제어부는 운동 데이터에 포함된 데이터 중에서 사용자의 생체 데이터와 음성 데이터를 추출한다. 제어부 는 생체 데이터와 음성 데이터를 이용하여 사용자의 감정 상태를 예측한다. 제어부는 생체 데이터와 음성 데이터에서 특징 데이터를 추출하고, 특징 데이터를 인공지능 모델에 입력한다. 제어부는 이를 통해 감정 상태를 예측할 수 있다. 제어부는 예측된 감정 상태를 웨어러블 장치로 전송한다. 제어부는 메모리에 저장된 심리 처방 데이터 중에서 확인된 사용자의 움직임 상태와 예측된 감정 상 태에 대응되는 심리 처방 데이터를 인공지능 모델을 통해 확인한다. 제어부는 확인된 심리 처방 데이터를 웨어러블 장치로 전송한다. 도 3은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 데이터를 생성하는 방법을 설명하기 위한 흐름도이다. 도 3을 참조하면, 본 발명에 따르면 301동작에서 전자장치는 적어도 하나의 웨어러블 장치와 페어링 을 통해 통신 연결을 수행한다. 이를 위해, 전자장치는 무선 및 유선 통신을 이용하여 웨어러블 장치(10 0)와 연결한다. 303동작에서 웨어러블 장치는 사용자의 운동 데이터를 획득한다. 운동 데이터는, 사용자의 움직임 데이터, 생체 데이터 및 음성 데이터에 대한 정보를 포함한다. 이를 위해, 웨어러블 장치는 사용자 의 움직임 데이터 및 생체 데이터를 획득하기 위한 센서와 사용자의 음성 데이터를 획득하기 위한 마이크 센서 를 구비할 수 있다. 305동작에서 웨어러블 장치는 획득된 운동 데이터를 전자장치로 전송한다. 307동작에서 전자장치 는 수신된 운동 데이터에서 웨어러블 장치를 구비한 사용자의 움직임 데이터를 추출한다. 309동작에 서 전자장치는 추출된 움직임 데이터가 최고 기록 데이터인지 확인한다. 이를 위해, 전자장치는 기 저장된 적어도 하나의 기록 데이터와 확인된 움직임 데이터를 비교한다. 309동작의 확인결과, 확인된 움직임 데 이터가 최고 기록 데이터이면 전자장치는 311동작을 수행한다. 311동작에서 전자장치는 확인된 움직 임 데이터로 최고 기록 데이터를 갱신한 후 315동작을 수행한다. 이때, 전자장치는 움직임 데이터를 기반 으로 사용자의 움직임 상태를 확인한다. 309동작의 확인결과, 확인된 움직임 데이터가 최고 기록 데이터가 아니 면 전자장치는 313동작을 수행한다. 313동작에서 전자장치는 확인된 움직임 데이터를 기록 데이터로 메모리에 저장하고, 315동작을 수행한다. 315동작에서 전자장치는 움직임 데이터를 기반으로 사용자의 움직임 상태를 확인한다. 움직임 상태는, 사 용자의 움직임 방향 및 움직임 속도를 포함한다. 전자장치는 최고 기록 데이터를 기준으로 사용자의 움직 임 상태로부터 사용자 행동의 격렬함 정도, 안정됨 정도, 평범한 정도, 걸음 수 등의 정보를 확인한다. 전자장 치는 확인 결과에 따라 사용자의 움직임이 어느 정도의 강도를 갖는지에 대한 수치를 포함한다. 이를위해, 최고 기록 데이터는 100의 수치를 갖는 정도의 강도에 대한 움직임일 수 있다. 317동작에서 전자장치는 수신된 운동 데이터에서 웨어러블 장치를 구비한 사용자의 생체 데이터를 추 출한다. 생체 데이터는 심박수 모니터 센서, 심전도 모니터 센서 및 피부전기저항 센서로부터 획득된 사용자의 심박수, 심박변이도, 맥박, 체온, 피부 상의 저항 등에 대한 데이터일 수 있다. 319동작에서 전자장치는 수신된 운동 데이터에서 웨어러블 장치를 구비한 사용자의 음성 데이터를 추 출한다. 음성 데이터는 마이크 센서로부터 획득된 사용자의 음성 데이터에서 확인된 파형 및 음성 데이터를 기 반으로 변환된 텍스트 데이터일 수 있다. 321동작에서 전자장치는 모델링 데이터를 생성한다. 전자장치는 실시간으로 수집된 웨어러블 장치 를 구비한 사용자의 생체 데이터 및 음성 데이터에 대한 특징 데이터를 추출한다. 전자장치는 특징 데이터로부터 감정 상태를 예측하고, 예측된 감정 상태와 움직임 상태를 매핑하여 모델링 데이터로 생성한다. 감정 상태는 생체 데이터, 음성 데이터에서 확인된 파형 및 텍스트 데이터로 감정 상태를 예측할 수 있는 인공 지능 모델을 통해 확인할 수 있거나, 사용자로부터의 입력에 의해 확인할 수 있다. 323동작에서 전자장치는 심리 처방 데이터를 입력한다. 심리 처방 데이터는, 감정 상태에 따른 일반적인 축하, 위로와 같은 감정 동조이거나, 스포츠 심리학과 관련된 전문 상담내용 결과에 대응하는 심리 처방 문장을 포함하는 데이터일 수 있다. 심리 처방 데이터는 사용자의 움직임 상태 및 감정 상태를 제어하기 위한 심리 처 방 문장과 관련된 음성 데이터 및 시각 데이터이다. 325동작에서 전자장치는 생성된 인공지능 데이터를 메모리에 저장한다. 인공지능 데이터는, 모델링 데이터와 심리 처방 데이터를 매핑하여 저장될 수 있다. 아울러, 전자장치는 인공지능 모델의 학습을 통해 심리 처방 데이터를 예측할 수 있게 데이터를 분류하여, 모델링 데이터를 통해 예측된 심리 처방 데이터를 생성 한다. 도 4는 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 방법을 설 명하기 위한 흐름도이다. 도 4를 참조하면, 401동작에서 웨어러블 장치와 전자장치는 연결을 수행한다. 이를 위해, 웨어러블 장치와 전자장치는 페어링을 수행할 수 있고, 이미 페어링이 완료된 경우, 통신 채널의 연결을 수행 할 수 있다. 403동작에서 웨어러블 장치는 웨어러블 장치를 구비한 사용자에 대한 운동 데이터를 획 득한다. 운동 데이터는 웨어러블 장치에 구비된 센서들에 의해 획득된 센싱 정보로, 사용자의 움직임 데이 터, 생체 데이터 및 음성 데이터를 포함한다. 움직임 데이터는 가속도 센서 또는 자이로 센서로부터 획득된 사 용자의 움직임 방향, 움직임 속도 등에 대한 데이터일 수 있다. 생체 데이터는 심박수 모니터 센서, 심전도 모 니터 센서 및 피부전기저항 센서로부터 획득된 사용자의 심박수, 심박변이도, 맥박, 체온, 피부 상의 저항 등에 대한 데이터일 수 있다. 음성 데이터는 마이크 센서로부터 획득된 사용자의 음성 데이터일 수 있다. 405동작에서 웨어러블 장치는 획득된 운동 데이터를 전자장치로 전송한다. 407동작에서 전자장치 는 운동 데이터에 포함된 데이터 중에서 사용자의 움직임 데이터를 추출한다. 409동작에서 전자장치 는 추출된 움직임 데이터를 기반으로 사용자의 움직임 상태를 확인한다. 411동작은 전자장치는 확인된 움 직임 상태를 출력한다. 움직임 상태는, 사용자의 움직임 방향 및 움직임 속도를 포함한다. 전자장치는 최 고 기록 데이터를 기준으로 사용자의 움직임 상태로부터 사용자 행동의 격렬함 정도, 안정됨 정도, 평범한 정보 및 걸음 수 등의 정보를 확인한다. 전자장치는 최고 기록 데이터를 기준으로 어느 정도의 강도를 갖는 움 직임인지에 대한 수치를 포함한다. 이를 위해, 최고 기록 데이터는 100의 수치를 갖는 정도의 강도에 대한 움직 임일 수 있다. 413동작에서 전자장치는 확인된 움직임 상태를 사용자가 구비한 웨어러블 장치로 전송 한다. 415동작에서 웨어러블 장치는 수신된 움직임 상태를 출력한다. 이와 같이, 움직임 상태는 웨어러블 장치로 전송되기 때문에 411동작은 생략이 가능하다. 417동작에서 전자장치는 운동 데이터에 포함된 데이터 중에서 사용자의 생체 데이터와 음성 데이터를 추출 한다. 419동작에서 전자장치는 사용자의 감정 상태를 예측한다. 이를 위해, 전자장치는 사용자의 생 체 데이터와 음성 데이터에서 특징 데이터를 추출하고, 추출된 특징 데이터를 인공지능 모델에 입력한다. 421동 작에서 전자장치는 예측된 감정 상태를 출력한다. 423동작에서 전자장치는 예측된 감정 상태를 웨어 러블 장치로 전송한다. 425동작에서 웨어러블 장치는 수신된 감정 상태를 출력한다. 이와 같이, 감정상태는 웨어러블 장치로 전송되기 때문에 421동작은 생략이 가능하다. 427동작에서 전자장치는 모델링 데이터를 생성한다. 전자장치는 409동작에서 확인된 움직임 상태와, 419동작에서 확인된 감정 상태를 기반으로 모델링 데이터를 생성한다. 429동작에서 전자장치는 심리 처방 데이터를 확인한다. 전자장치는 생성된 모델링 데이터와 동일 또 는 유사한 모델링 데이터에 매핑되어 인공지능 모델에 저장 및 학습되어 있는 심리 처방 데이터를 확인한다. 심 리 처방 데이터는, 인공지능 모델을 통해 사용자에게 심리 처방할 데이터가 모델링 데이터와 함께 미리 학습된 인공지능 데이터이다. 심리 처방 데이터는, 감정 상태에 따른 일반적인 축하, 위로와 같은 감정 동조이거나, 스 포츠 심리학과 관련된 전문 상담내용 결과에 대응하는 심리 처방 문장을 포함하는 인공지능 데이터일 수 있다. 상담 처방 문장은 동기부여, 감정의 이완, 격려, 칭찬, 동조 등 사용자의 감정을 완화시키거나 증폭시키는 작용 을 한다. 431동작에서 전자장치는 확인된 심리 처방 데이터를 출력한다. 심리 처방 데이터는, 음성 데이터 및 시각 데이터일 수 있고, 음성 데이터인 경우, 사용자의 선호도에 따라 성별, 억양 등 여러 종류의 음성 데이터 중 선 택될 수 있다. 433동작에서 전자장치는 확인된 심리 처방 데이터를 웨어러블 장치로 전송한다. 435동 작에서 웨어러블 장치는 심리 처방 데이터를 출력한다. 이로 인해, 사용자는 심리 처방 데이터를 통해 자 신의 움직임 및 감정 상태를 최상으로 유지할 수 있다. 이와 같이, 심리 처방 데이터는 웨어러블 장치로 전송되기 때문에 431동작은 생략이 가능하다. 도 5는 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 웨어러블 장치를 이용한 전자장치에서의 방법을 설명하기 위한 순서도이다. 도 5를 참조하면, 501동작에서 제어부는 웨어러블 장치와 통신을 연결하기 위한 연결신호의 수신여부 를 확인한다. 503동작에서 제어부는 웨어러블 장치와 통신을 연결한다. 505동작에서 제어부는 웨어러블 장치로부터 웨어러블 장치를 구비한 사용자의 운동 데이터 수신 여부를 확인한다. 505동작 의 확인결과, 사용자의 운동 데이터가 수신되면 제어부는 507동작을 수행하고, 운동 데이터가 수신되지 않 으면 제어부는 505동작을 재수행한다. 507동작에서 제어부는 수신된 운동 데이터를 기반으로 사용자의 움직임 상태를 확인한다. 이는 도 6을 이 용하여, 보다 구체적으로 설명하기로 한다. 509동작에서 제어부는 수신된 운동 데이터를 기반으로 사용자 의 감정 상태를 예측한다. 이는 도 7을 이용하여, 보다 구체적으로 설명하기로 한다. 511동작에서 제어부는 모델링 데이터를 생성한다. 제어부는 507동작에서 수집된 웨어러블 장치 를 구비한 사용자의 움직임 데이터로부터의 움직임 상태와, 509동작에서 예측된 감정 상태를 기반으로 모델링 데이터를 생성한다. 513동작에서 제어부는 심리 처방 데이터를 확인한다. 제어부는 생성된 모델링 데 이터와 동일 또는 유사한 모델링 데이터에 매핑되어 인공지능 모델에 저장 및 학습된 심리 처방 데이터를 확인 한다. 심리 처방 데이터는, 인공지능 모델을 통해 사용자에게 심리 처방할 데이터가 모델링 데이터와 함께 미리 학습된 인공지능 데이터이다. 심리 처방 데이터는, 감정 상태에 따른 일반적인 축하, 위로와 같은 감정 동조이 거나, 스포츠 심리학과 관련된 전문 상담내용 결과에 대응하는 심리 처방 문장을 포함하는 인공지능 데이터일 수 있다. 상담 처방 문장은 동기부여, 감정의 이완, 격려, 칭찬, 동조 등 사용자의 감정을 완화시키거나 증폭시 키는 작용을 한다. 515동작에서 제어부는 확인된 심리 처방 데이터를 출력한다. 517동작에서 제어부는 확인된 심리 처방 데이터를 웨어러블 장치로 전송한다. 도 6은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 웨어러블 장치를 이용한 전자장치에서의 방법을 설명하기 위한 상세순서도이다. 도 6을 참조하면, 601동작에서 제어부는 운동 데이터에 포함된 데이터 중 사용자의 움직임 데이터를 추출 한다. 움직임 데이터는 가속도 센서 또는 자이로 센서로부터 획득된 사용자의 움직임 방향, 움직임 속도 등에 대한 데이터일 수 있다. 603동작에서 제어부는 추출된 움직임 데이터를 메모리에 기 저장된 최고 기 록 데이터와 비교한다. 605동작에서 제어부는 최고 기록 데이터와의 비교 결과에 따라 움직임 데이터에 대 한 움직임 상태를 확인한다. 움직임 상태는, 사용자의 움직임 방향 및 움직임 속도를 포함하고, 최고 기록 데이터를 기준으로 어느 정도의 강도를 갖는 움직임인지에 대한 수치를 포함한다. 607동작에서 제어부는 확인된 움직임 상태를 표시부에 출력한다. 움직임 상태는 웨어러블 장치 로 전송되기 때문에 607동작은 생략이 가능하다. 609동작에서 제어부는 확인된 움직임 상태를 웨어러블 장치에서 출력할 수 있도록 움직임 상태를 웨어러블 장치로 전송하고 도 5의 509동작으로 리턴한다. 도 7은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 웨어러블 장치를 이용한 전자장치에서의 방법을 설명하기 위한 상세순서도이다. 도 7을 참조하면, 701동작에서 제어부는 운동 데이터에 포함된 데이터 중 사용자의 생체 데이터 및 음성 데이터를 추출한다. 생체 데이터는 심박수 모니터 센서, 심전도 모니터 센서 및 피부전기저항 센서로부터 획득 된 사용자의 심박수, 심박변이도, 맥박, 체온, 피부 상의 저항 등에 대한 데이터일 수 있다. 음성 데이터는 마 이크 센서로부터 획득된 사용자의 음성 데이터일 수 있다. 703동작에서 제어부는 추출된 사용자의 생체 데이터 및 음성 데이터를 이용하여 사용자의 감정 상태를 예 측한다. 705동작에서 제어부는 예측된 감정 상태를 출력하고, 707동작에서 제어부는 예측된 감정 상 태를 웨어러블 장치로 전송한다. 감정 상태는 웨어러블 장치로 전송되기 때문에 705동작은 생략이 가 능하다. 감정 상태를 예측한 제어부는 도 5의 511동작으로 리턴한다. 한편, 본 명세서와 도면에 개시된 본 발명의 실시예들은 본 발명의 기술 내용을 쉽게 설명하고 본 발명의 이해 를 돕기 위해 특정 예를 제시한 것일 뿐이며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 즉 본 발명의 기 술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명한 것이다."}
{"patent_id": "10-2016-0135197", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치 를 이용한 시스템을 나타낸 도면이다. 도 2는 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하는 웨어러블 장치 를 이용한 전자장치의 주요 구성을 나타낸 도면이다. 도 3은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 데이터를 생성하는 방법을 설명하기 위한 흐름도이다. 도 4는 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 방법을 설 명하기 위한 흐름도이다. 도 5는 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 웨어러블 장치를 이용한 전자장치에서의 방법을 설명하기 위한 순서도이다. 도 6은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 웨어러블 장치를 이용한 전자장치에서의 방법을 설명하기 위한 상세순서도이다. 도 7은 본 발명의 실시 예에 따른 인공지능 모델을 통해 사용자의 감정과 행동을 심리 처방하기 위한 웨어러블 장치를 이용한 전자장치에서의 방법을 설명하기 위한 상세순서도이다."}
