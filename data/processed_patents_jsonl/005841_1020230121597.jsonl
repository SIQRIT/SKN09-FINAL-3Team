{"patent_id": "10-2023-0121597", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0038973", "출원번호": "10-2023-0121597", "발명의 명칭": "발화 특색을 보존하는 음성 변환 방법 및 장치", "출원인": "포항공과대학교 산학협력단", "발명자": "서영주"}}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 처리 장치가 제1 음성 정보 및 제2 음성 정보를 입력 받는 단계;상기 음성 처리 장치가 텍스트(Text) 특성 추출 모델을 이용하여 제1 음성 정보로부터 텍스트 특성을 추출하는단계; 상기 음성 처리 장치가 음높이 특성 추출 모델을 이용하여 제2 음성 정보로부터 음높이 특성을 추출하는 단계;및상기 음성 처리 장치가 음성 합성 모델을 이용하여 상기 언어적 특성 및 상기 음높이 특성을 기반으로 음성을변환하는 단계를 포함하되, 상기 음성 합성 모델은 학습과정에서 학습 데이터로 하나의 음성에서 사전 학습(Pre-training)된 텍스트 특성추출 모델이 추출한 텍스트 특성 및 사전 학습된 음높이 특성 추출 모델이 추출한 음높이 특성을 이용하여 학습된 모델이고, 상기 음성 합성 모델을 학습 하는 것은 상기 음성 합성 모델이 상기 학습데이터에 포함된 텍스트 특성 및 음높이 특성을 입력 받아 생성한 변환된 음성정보와 상기 음높이 특성을 기반으로 구축한 손실함수의 값이 최소가되도록 하는 것인, 발화 특색을 보존하는 음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 음성 정보 및 제2 음성 정보는 웨이브폼(Waveform), Spectrogram 및 Mel-spectrogram 중 하나의 형태를 가지는, 발화 특색을 보존하는 음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 텍스트 특성 추출 모델은 사전 학습(pre-training)된 언어 모델(Language Model)인, 발화 특색을 보존하는음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 음성 합성 모델은 디코더(Decoder) 및 보코더(Vocoder)을 포함하고, 발화 특색을 보존하는 음성 변환방법. 상기 디코더는 텍스트 특성 및 음높이 특성을 기반으로 변환된 음성 정보를 생성하고, 상기 보코더는 상기 변환된 음성 정보를 기반으로 음성을 변환하는, 발화 특색을 보존하는 음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 디코더는 트랜스포머(Transformer)기반의 디코더인, 발화 특색을 보존하는 음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 변환된 음성 정보는 Spectrogram 또는 Mel-spectrogram 형태를 가지는, 발화 특색을 보존하는 음성 변환공개특허 10-2025-0038973-3-방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 텍스트 특성 및 상기 음높이 특성은 1차원 벡터의 형태를 가지며, 상기 음성 합성 모델은 상기 텍스트 특성 및 음높이 특성을 결합(Cocnatenation)한 벡터를 입력 받는, 발화 특색을 보존하는 음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 학습데이터에 포함된 음높이 특성은 전처리가 된 것이고, 상기 전처리는 주파수 영역에서 와핑 후(wrapping)후 중앙 영역을 자르는 것, 정규화 하는 것 및 노이즈를 추가하는 것을 포함하는, 발화 특색을 보존하는 음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 음성 정보 및 제2 음성 정보를 입력 받는 입력장치; 텍스트(Text) 특성 추출 모델을 이용하여 제1 음성 정보로부터 텍스트 특성을 추출하고, 음높이 특성 추출 모델을 이용하여 제2 음성 정보로부터 음높이 특성을 추출하고, 음성 합성 모델을 이용하여 상기 언어적 특성 및 상기 음높이 특성을 기반으로 음성을 변환하는 연산장치; 및 상기 텍스트 특성 추출 모델, 음높이 특성 추출 모델 및 음성 합성 모델을 저장하는 저장장치; 를 포함하되,상기 음성 합성 모델은 학습과정에서 학습 데이터로 하나의 음성에서 사전 학습(Pre-training)된 텍스트 특성추출 모델이 추출한 텍스트 특성 및 사전 학습된 음높이 특성 추출 모델이 추출한 음높이 특성을 이용하여 학습된 모델이고, 상기 음성 합성 모델을 학습 하는 것은 상기 음성 합성 모델이 상기 학습데이터에 포함된 텍스트 특성 및 음높이 특성을 입력 받아 생성한 변환된 음성정보와 상기 음높이 특성을 기반으로 구축한 손실함수의 값이 최소가되도록 하는 것인, 발화 특색을 보존하는 음성 변환 장치."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제1 음성 정보 및 제2 음성 정보는 웨이브폼(Waveform), Spectrogram 및 Mel-spectrogram 중 하나의 형태를 가지는, 발화 특색을 보존하는 음성 변환 장치."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 텍스트 특성 추출 모델은 사전 학습(pre-training)된 언어 모델(Language Model)인, 발화 특색을 보존하는음성 변환 장치."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 음성 합성 모델은 디코더(Decoder) 및 보코더(Vocoder)을 포함하고, 상기 디코더는 텍스트 특성 및 음높이 특성을 기반으로 변환된 음성 정보를 생성하고, 상기 보코더는 상기 변환된 음성 정보를 기반으로 음성을 변환하는, 발화 특색을 보존하는 음성 변환 장치."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 공개특허 10-2025-0038973-4-상기 디코더는 트랜스포머(Transformer)기반의 디코더인, 발화 특색을 보존하는 음성 변환 장치."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 상기 변환된 음성 정보는 Spectrogram 또는 Mel-spectrogram 형태를 가지는, 발화 특색을 보존하는 음성 변환방법."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 상기 텍스트 특성 및 상기 음높이 특성은 1차원 벡터의 형태를 가지며, 상기 음성 합성 모델은 상기 텍스트 특성 및 음높이 특성을 결합(Cocnatenation)한 벡터를 입력 받는, 발화 특색을 보존하는 음성 변환 장치."}
{"patent_id": "10-2023-0121597", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서, 상기 학습데이터에 포함된 음높이 특성은 전처리가 된 것이고, 상기 전처리는 주파수 영역에서 와핑 후(wrapping)후 중앙 영역을 자르는 것, 정규화 하는 것 및 노이즈를 추가하는 것을 포함하는, 발화 특색을 보존하는 음성 변환 방법."}
{"patent_id": "10-2023-0121597", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "발화 특색을 보존하는 음성 변환 방법은 음성 처리 장치가 제1 음성 정보 및 제2 음성 정보를 입력 받는 단계; 상기 음성 처리 장치가 텍스트(Text) 특성 추출 모델을 이용하여 제1 음성 정보로부터 텍스트 특성을 추출하는 단계; 상기 음성 처리 장치가 음높이 특성 추출 모델을 이용하여 제2 음성 정보로부터 음높이 특성을 생성하는 단계; 및 상기 음성 처리 장치가 음성 합성 모델을 이용하여 상기 언어적 특성 및 상기 음높이 특성을 기반으로 음성을 변환하는 단계를 포함한다."}
{"patent_id": "10-2023-0121597", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술을 발화 특색을 보존하면서 음성을 변환하는 방법에 대한 것이다."}
{"patent_id": "10-2023-0121597", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 변환 기술은 한 사람(소스(Source) 화자)의 음성을 다른 사람(타깃(Target) 화자)의 음성으로 변환하는 기 술이다. 음성 변환 기술은 언어적 내용은 변하지 않고 음성 특징(음색, 음역 및 리듬 등)만을 변화하는 기술이 다. 최근 인공신경망에 기반한 인공지능 기술이 발전되기 시작하면서, 인공지능을 활용한 음성 변환 기술들이 개발되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 비특허문헌 Kim, et al. “A Convolutional Representation For Pitch Estimation, 2018”"}
{"patent_id": "10-2023-0121597", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "종래 음성 변환 방법은 음성 정보에 포함된 텍스트 특성만을 기반으로 음성을 변환하였다. 이에 종래 음성 변환 방법은 언어적 내용에 따라 음높이가 항상 동일하여 변환된 음성의 자연스러움이 떨어지는 문제점이 있었다. 또 한 종래 음성 변환 방법은 타깃 화자의 발화 특색을 고려하지 않고 음성을 변환하였다. 이에 음성 변환 방법은 타깃 화자가 고유하게 가지는 발화 특색을 보존하기 힘든 문제점이 있었다. 이하 설명하는 기술은 타깃 화자의 발화 특색을 보존하면서 음성을 변환할 수 있는 방법을 제공한다."}
{"patent_id": "10-2023-0121597", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "발화 특색을 보존하는 음성 변환 방법은 음성 처리 장치가 제1 음성 정보 및 제2 음성 정보를 입력 받는 단계; 상기 음성 처리 장치가 텍스트(Text) 특성 추출 모델을 이용하여 제1 음성 정보로부터 텍스트 특성을 추출하는단계; 상기 음성 처리 장치가 음높이 특성 추출 모델을 이용하여 제2 음성 정보로부터 음높이 특성을 추출하는 단계; 및 상기 음성 처리 장치가 음성 합성 모델을 이용하여 상기 언어적 특성 및 상기 음높이 특성을 기반으로 음성을 변환하는 단계를 포함한다."}
{"patent_id": "10-2023-0121597", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 기술을 이용하면 화자의 음성을 변환할 수 있다. 이때 타깃 화자의 발화 특색을 보존하면서 소스 화자의 음성을 변환할 수 있다. 즉 이하 설명하는 기술을 이용하면 음성 변환을 수행함에 있어 단순히 음색을 변화하는데 그치지 않고, 변환 대상 화자의 고유한 언어 습관, 특히 음높이에 관한 정보를 충분히 고려하여 음 성 변환이 가능하다. 또한 이하 설명하는 이용하면 딥러닝에 기반한 모델을 이용하여 화자의 음성을 변환할 수 있다."}
{"patent_id": "10-2023-0121597", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있다. 명세서의 도면에 이하 설 명하는 기술의 특정 실시 형태가 기재될 수 있다. 그러나, 이는 이하 설명하는 기술의 설명을 위한 것이며 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니다. 따라서 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경 물, 균등 물 내지 대체 물이 이하 설명하는 기술에 포함하는 것으로 이해되어야 한 다. 다양한 구성요소들을 설명하기 위해서 제1, 제2, A, B 등의 용어가 사용될 수 있다. 하지만 상기 용어는 단지 하나의 구성요소를 다른 구성요소들과 구별하기 위해서 사용될 뿐, 상기 용어로 해당 구성요소들을 한정하려고 하는 것이 아니다. 예를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. “및/또는” 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 이하 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함하는 것으 로 이해되어야 하고, \"포함한다\" 등의 용어는 기재된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성 부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 이하 도1을 통해 음성 처리 장치가 발화 특색을 보존하는 음성 변환 방법을 수행하는 전체적인 과정을 살펴본다. 도1은 음성 처리 장치가 발화 특색을 보존하는 음성 변환 방법을 수행하는 실시예 중 하나이다. 음성 처리 장치는 제1 음성 정보 및 제2 음성 정보를 입력 받을 수 있다. 음성 처리 장치는 텍스트 (Text) 특성 추출 모델을 이용하여 제1 음성 정보로부터 텍스트 특성을 추출할 수 있다. 음성 처리 장치는 음높이 특성 추출 모델을 이용하여 제2 음성 정보로부터 음높이 특성을 추출할 수 있다. 음성 처리 장치 는 상기 언어적 특성 및 상기 음높이 특성을 기반으로 음성을 변환할 수 있다. 이하 도2를 통해 발화 특색을 보존하는 음성 변환 방법을 구체적으로 설명한다. 도2는 발화 특색을 보존하는 음성 변환 방법의 실시예 중 하나이다. 음성 처리 장치는 제1 음성 정보 및 제2 음성 정보를 입력 받을 수 있다. 제1 음성 정보는 음성 변환을 할 음성에 대한 정보를 포함할 수 있다. 제2 음성 정보는 음성 변환 목적 음성에 대한 정보를 포함할 수 있다. 즉 음성 처리 장치는 한 사람(Source 화자)이 말한 제1 음성 정보를 다른 사람 (target 화자)이 말한 제2음성 정보의 음성으로 변환할 수 있다. 제1 음성 정보 및 제2 음성 정보는 웨이브 폼(Waveform)형태를 가질 수 있다. 또는 제1 음성 정보 및 제2음성 정보는 Spectrogram의 형태를 가질 수 있다. 더 구체적으로 제1 음성 정보 및 제2음성 정보는 Mel- spectrogram의 형태를 가질 수 있다. 음성 처리 장치는 텍스트(Text) 특성 추출 모델을 이용하여 제1 음성 정보로부터 텍스트 특성을 추출할 수 있다 . 텍스트 특성 추출 모델은 제1 음성 정보로부터 텍스트 특성을 추출하는 모델일 수 있다. 텍스트 특성 추출 모델 은 기계학습 기반의 모델일 수 있다. 구체적으로 텍스트 특성 추출 모델은 인공신경망 기반의 모델일 수 있다. 더 나아가 텍스트 특성 추출 모델은 사전 학습된(pre-training)된 언어모델(language model)일 수도 있다. 텍스트 특성 추출 모델은 제1 음성 정보로부터 텍스트 특성을 벡터 형태로 추출할 수 있다. 일 실시예로 텍스트 특성은 1차원 벡터의 형태를 가질 수 있다. 텍스트 특성은 음성에 포함된 텍스트에 대한 정보를 포함할 수 있다. 예를 들어 제1 음성 정보가 사람이 [안녕 하세요]를 소리내어 읽은 음성에 대한 것이라면, 텍스트 특성은 “안녕하세요”의 텍스트에 대한 특성을 포함할 수 있다. 음성 처리 장치는 음높이 특성 추출 모델을 이용하여 제2 음성 정보로부터 음높이 특성을 추출할 수 있다. 음높이 특성 추출 모델은 음성 정보로부터 음높이 특성을 추출하는 모델일 수 있다. 음높이 특성 추출 모델은 기계학습 기반의 모델일 수 있다. 구체적으로 음높이 특성 추출 모델은 인공신경망 기반의 모델일 수 있다. 음높이 특성 추출 모델은 제2 음성 정보로부터 음높이 특성을 벡터 형태로 추출할 수 있다. 일 실시예로 음높이 특성은 1차원 벡터의 형태를 가질 수 있다. 음높이 특성은 음성에 포함된 음높이에 대한 정보를 포함할 수 있다. 예를 들어 제2 음성 정보가 사람이 [안녕 하세요]를 소리내어 읽은 것이라면 음높이 특성은 사람이 [안녕하세요]를 읽을 때 나타나는 음높이 대한 특성을 포함할 수 있다. 음성 처리 장치는 음성 합성 모델을 이용하여 텍스트 특성 및 음높이 특성을 기반으로 음성을 변환할 수 있다 . 음성 처리 장치가 생성한 음성은 제1 음성 정보에 포함된 텍스트 특성에 제2 음성 정보에 포함된 음높이 특성이 반영된 음성일 수 있다. 즉 음성을 변환하는 것은 제1 음성을 제2 음성으로 변환하는 것을 포함할 수 있다. 음성 처리 장치는 음성을 변환하기 위해서 음성 합성 모델을 이용할 수 있다. 음성 합성 모델은 텍스트 특성 및 음높이 특성을 기반으로 변환된 음성을 생성하는 모델일 수 있다. 음성 합성 모델은 기계학습 기반의 모델일 수 있다. 구체적으로 음성 합성 모델은 인공신경망 기반의 모델일 수 있다. 음성 합성 모델은 트랜스포머 (Transformer)기반의 모델일 수 있다. 음성 합성 모델은 디코더(Decoder) 및 보코더(Vocoder)를 포함할 수 있다. 디코더는 텍스트 특성 및 음높이 특성을 기반으로 변환된 음성 정보를 생성할 수 있다. 변환된 음성 정보는 제1 음성 정보의 텍스트 특성과 제2 음성 정보의 음높이 특성이 반영된 음성에 대한 정보를 포함할 수 있다. 변환된음성 정보는 Spectrogram 및 Mel-spectrogram 중 하나의 형태를 가질 수 있다. 디코더는 텍스트 특성 및 음높이 특성을 결합(Concatenation)한 것을 입력 받을 수 있다. 또는 디코더는 텍스트 특성 및 음높이 특성을 결합한 벡터를 선형 투영(Linear Projection)한 것을 입력 받을 수도 있다. 보코더는 디코더의 출력값을 기반으로 음성을 변환할 수 있다. 예를 들어 보코더는 Mel-spectrum등을 기반으로 가청 음성 웨이브 폼을 생성할 수 있다. 이하 도3을 통해 음성 처리 장치가 음성 합성 모델을 학습하는 실시예를 살펴본다. 도3은 텍스트 특성 추출 모델, 음높이 특성 추출 모델 및 음성 합성 모델을 학습하는 실시예 중 하나를 보여준 다. 음성 정보는 텍스트 특성 추출 모델에 입력 될수 있다. 텍스트 특성 추출 모델은 음성 정보로부터 텍스트 특성 을 추출할 수 있다. 텍스트 특성 추출 모델은 사전학습 된 모델일 수 있다. 텍스트 특성은 1차원 벡터로 변환될 수 있다. 음성 정보는 음높이 특성 추출 모델에 입력될 수 있다. 음높이 특성 추출 모델은 음성 정보로부터 음높이 특성 을 추출할 수 있다. 음높이 특성 추출 모델은 사전학습 된 모델일 수 있다. 음높이 특성은 전처리될 수 있다. 음높이 특성은 1차원 벡터 형태로 변환될 수 있다. 전처리 과정은 데이터를 증강하는 과정을 포함할 수 있다. 전처리 과정은 주파수 영역에서 와핑 (wrapping) 후 중앙 부분을 자르는 과정, 정규화하는 과정 및 노이즈를 추가하는 과정을 포함할 수 있다. 1차원 벡터로 변환된 음높이 특성 및 텍스트 특성은 결합(Concatenation)될 수 있다. 결합된 음높이 특성 및 텍 스트 특성은 음성 합성 모델에 입력될 수 있다. 음성 합성 모델은 변환된 음성 정보를 생성할 수 있다. 변환된 음성 정보는 음높이 특성 추출 모델이 추출한 음높이 특성과 비교될 수 있다. 비교된 결과를 기반으로 손실값(Loss)을 계산할 수 있다. 음성 합성 모델은 손실 값이 최소가 되도록 파라미터가 업데이트 될 수 있다. 구체적으로 음성 합성 모델이 트랜스포머 디코더인 경우, 디코더의 파라미터가 업데이트 될 수 있다. 이하 도4를 통해 음성 처리 장치에 대해 설명한다. 도4는 음성 처리 장치의 실시예 중 하나의 구성이다. 음성 처리 장치는 도1에서 설명한 음성 처리 장치에 해당할 수 있다. 즉 음성 처리 장치는 전술 한 발화 특색을 보존하는 음성 변환 방법 을 수행하는 장치일 수 있다. 음성 처리 장치는 물리적으로 다양한 형태로 구현될 수 있다. 예를 들어 음성 처리 장치는 PC, 노트 북, 스마트기기, 서버 또는 데이터처리 전용 칩셋 등의 형태를 가질 수 있다. 음성 처리 장치는 입력장치, 저장장치, 연산장치, 출력장치, 인터페이스 장치 및 통신장치를 포함할 수 있다. 입력장치는 일정한 명령 또는 데이터를 입력 받는 인터페이스 장치(키보드, 마우스, 터치스크린 등)를 포 함할 수도 있다. 입력장치는 별도의 저장장치(USB, CD, 하드디스크 등)를 통하여 정보를 입력 받는 구성을 포함할 수도 있다. 입력장치는 입력 받는 데이터를 별도의 측정장치를 통하여 입력 받거나, 별도의 DB를 통하여 입력 받을 수도 있다. 입력장치는 통신장치을 통해 데이터를 유선 또는 무선 통신으로 입력 받을 수도 있다. 입력장치는 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 정보를 입력 받을 수 있다. 입력장치는 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 모델을 입력 받을 수 있다. 입력장치는 제1 음성 정보 및 제2 음성 정보를 입력 받을 수 있다. 입력장치는 텍스트 특성 추출 모 델을 입력 받을 수 있다. 입력장치는 음높이 특성 추출 모델을 입력 받을 수 있다. 저장장치는 일정한 정보를 저장하는 장치가 될 수도 있다. 저장장치는 입력장치를 통해 입력 받 은 정보를 저장할 수 있다. 저장장치는 연산장치가 연산하는 과정에서 생성되는 정보를 저장할 수 있 다. 즉 저장장치는 메모리를 포함할 수 있다. 저장장치는 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 정보를 저장할 수 있다. 저 장장치는 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 모델을 저장할 수 있다. 저장 장치는 제1 음성 정보 및 제2 음성 정보를 저장할 수 있다. 저장장치는 텍스트 특성 추출 모델을 저 장할 수 있다. 저장장치는 음높이 특성 추출 모델을 저장할 수 있다. 연산장치는 데이터를 처리하고, 일정한 연산을 처리하는 프로세서, AP, 프로그램이 임베디드 된 칩과 같은 장치일 수 있다. 연산장치는 음성 처리 장치를 제어하는 제어신호를 생성할 수 있다. 연산장치(33 0)는 음성 처리 장치에 포함된 입력장치, 저장장치, 출력장치, 인터페이스 장치 및 통신장치을 제어하는 제어신호를 생성할 수 있다. 연산장치는 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 연산을 할 수 있다. 연산장 치는 텍스트(Text) 특성 추출 모델을 이용하여 제1 음성 정보로부터 텍스트 특성을 추출할 수 있다. 연산 장치는 음높이 특성 추출 모델을 이용하여 제2 음성 정보로부터 음높이 특성을 추출할 수 있다. 연산장치 는 음성 합성 모델을 이용하여 상기 언어적 특성 및 상기 음높이 특성을 기반으로 음성을 변환할 수 있다. 출력장치는 일정한 정보를 출력하는 장치가 될 수도 있다. 출력장치는 데이터 과정에 필요한 인터페 이스, 입력된 데이터, 분석결과 등을 출력할 수도 있다. 출력장치는 디스플레이, 문서를 출력하는 장치, 스피커등과 같이 물리적으로 다양한 형태로 구현될 수도 있다. 출력장치는 저장장치에 저장된 정보를 출력할 수 있다. 출력장치는 연산장치가 연산하는 과정에서 생성된 정보를 출력할 수 있다. 출력장치 는 연산장치가 연산한 결과를 출력할 수 있다. 인터페이스 장치는 외부로부터 일정한 명령 및 데이터를 입력 받는 장치일 수 있다. 인터페이스 장치(35 0)는 음성 처리 장치를 제어하기 위한 제어신호를 입력 받을 수 있다. 인터페이스 장치는 음성 처리 장치가 분석한 결과를 출력할 수 있다. 인터페이스 장치는 물리적으로 연결된 입력 장치 또는 외부 저장장치로부터 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 정보를 입력 받을 수 있다. 통신장치는 유선 또는 무선 네트워크를 통해 일정한 정보를 수신하고 전송하는 구성을 의미할 수 있다. 통 신장치는 Wi-Fi(Wireless Fidelity), Wi-Fi Direct, 블루투스(Bluetooth), UWB(Ultra Wide Band) 또는 NFC(Near Field Communication), USB(Universal Serial Bus), 혹은 HDMI(High Definition Multimedia Interface), LAN(Local Area Network) 등과 같은 네트워크 통신을 수행할 수 있다. 통신장치는 음성 처리 장치를 제어하는데 필요한 제어 신호를 수신할 수 있다. 통신장치는 음성 처리 장치가 분석한 결과를 전송할 수 있다. 통신장치는 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 정 보를 수신받을 수 있다. 통신장치는 전술한 발화 특색을 보존하는 음성 변환 방법을 수행하는데 필요한 모 델을 수신 받을 수 있다. 전술한 발화 특색을 보존하는 음성 변환 방법은 컴퓨터에서 실행될 수 있는 실행가능한 알고리즘을 포함하는 프로그램(또는 어플리케이션)으로 구현될 수 있다. 상기 프로그램은 일시적 또는 비일시적 판독 가능 매체(non-transitory computer readable medium)에 저장되어 제공될 수 있다. 상기 일시적 판독 가능 매체는 스태틱 램(Static RAM，SRAM), 다이내믹 램(Dynamic RAM，DRAM), 싱크로너스 디 램 (Synchronous DRAM，SDRAM), 2배속 SDRAM(Double Data Rate SDRAM，DDR SDRAM), 증강형 SDRAM(Enhanced SDRAM，ESDRAM), 동기화 DRAM(Synclink DRAM，SLDRAM) 및 직접 램버스 램(Direct Rambus RAM，DRRAM) 과 같은 다양한 RAM을 의미한다. 상기 비일시적 판독 가능 매체는 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM (read-only memory), PROM (programmable read only memory), EPROM(Erasable PROM, EPROM) 또는 EEPROM(Electrically EPROM) 또는 플래시 메모리 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있 다. 본 실시예 및 본 명세서에 첨부된 도면은 전술한 기술에 포함되는 기술적 사상의 일부를 명확하게 나타내고 있 는 것에 불과하며, 전술한 기술의 명세서 및 도면에 포함된 기술적 사상의 범위 내에서 당업자가 용이하게 유추 할 수 있는 변형 예와 구체적인 실시예는 모두 전술한 기술의 권리범위에 포함되는 것이 자명하다고 할 것이다."}
{"patent_id": "10-2023-0121597", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 음성 처리 장치가 발화 특색을 보존하는 음성 변환 방법을 수행하는 실시예 중 하나이다. 도2는 발화 특색을 보존하는 음성 변환 방법의 실시예 중 하나이다. 도3은 텍스트 특성 추출 모델, 음높이 특성 추출 모델 및 음성 합성 모델을 학습하는 실시예 중 하나를 보여준 다. 도4는 음성 처리 장치의 실시예 중 하나의 구성이다."}
