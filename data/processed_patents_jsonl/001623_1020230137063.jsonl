{"patent_id": "10-2023-0137063", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0053584", "출원번호": "10-2023-0137063", "발명의 명칭": "로봇과 사용자 간의 인터랙션을 위한 터치 입력을 수신하는 터치 센서를 갖는 센서부를 포함", "출원인": "네이버 주식회사", "발명자": "김민수"}}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공간을 자율 주행하는 로봇에 있어서, 상기 로봇의 상단부에 마련되고, 사용자로부터의 터치 입력을 포함하는 제1 입력을 감지하도록 구성되는 적어도하나의 터치 센서를 포함하는 센서부; 상기 로봇을 구동하는 구동부; 및 상기 구동부의 동작을 제어하여 상기 로봇의 자세 또는 상기 로봇의 이동을 제어하고, 상기 센서부의 동작을 제어하는 제어부 를 포함하고, 상기 제어부는, 상기 제1 입력에 기반하여,상기 로봇이 특정한 모션을 수행하도록 상기 구동부 또는 상기 센서부의 동작을 제어하는 것 및 상기 제1 입력에 후속하는 상기 사용자로부터의 제2 입력을 감지하도록 상기 센서부의 동작을 제어하는 것중 적어도 하나를 수행하도록 구성되는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 특정한 모션은 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로봇이 지향하게 하도록 하는것인, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 로봇이 주행하고 있는 상태에서, 상기 제1 입력이 감지된 때,상기 제어부는, 상기 로봇의 주행을 정지시키고 상기 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로봇이 지향하게 하도록 상기 구동부의 동작을 제어하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제2 입력은 상기 터치 센서에 대한 추가적인 터치 입력 및 상기 센서부가 포함하는 마이크에 대한 상기 사용자로부터의 음성 입력 중 적어도 하나를 포함하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 제2 입력은 복수이고, 복수의 제2 입력들이 소정의 순서 또는 패턴으로 상기 사용자에 의해 입력됨에 따라,상기 제어부는, 상기 로봇이 상기 제2 입력들과 연관된 타겟 모션을 수행하거나, 상기 로봇이 상기 제2 입력들과 연관된 타겟 정보를 출력하도록, 상기 로봇을 제어하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 공개특허 10-2025-0053584-3-상기 타겟 모션 또는 상기 타겟 정보는 상기 사용자가 상기 로봇을 통해 수행하는 게임과 연관된 것이고, 상기 제1 입력은 상기 게임을 시작하기 위한 상기 로봇에 대한 입력인, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서, 상기 로봇은 상기 공간 내에서 서비스를 제공하는 서비스 로봇이고,상기 로봇이 상기 서비스의 제공을 위한 제1 작업의 완료를 실패하고 주행하고 있는 상태에서, 상기 제어부는, 상기 제1 입력이 감지된 때,상기 로봇의 주행을 정지시키고 상기 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로봇이 지향하게 하고, 상기 제2 입력이 감지된 때,상기 로봇이 상기 제1 작업을 다시 수행하도록 상기 로봇을 제어하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 로봇은 상기 공간 내에서 서비스를 제공하는 서비스 로봇이고,상기 로봇이 상기 서비스의 제공을 위한 제1 작업의 완료를 실패하고 주행하고 있는 상태에서, 상기 제어부는, 상기 제1 입력이 감지된 때,상기 제어부는, 상기 로봇의 주행을 정지시키고 상기 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로봇이 지향하게 하고, 상기 로봇이 상기 제1 작업을 다시 수행하도록 상기 로봇을 제어하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 터치 입력은 상기 터치 센서를 소정의 제1 면적 이상 접촉하는 터치 입력인, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 제어부는, 상기 터치 입력이 상기 터치 센서를 접촉하는 면적에 따라, 상기 로봇이 상이한 모션을 수행하도록 상기 구동부의 동작을 제어하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 터치 입력의 개수, 상기 터치 입력이 상기 터치 센서를 접촉하는 면적 및 상기 터치 입력의 방향에 따라변화하는 시각적 인디케이터를 출력하도록 구성되는 인디케이터 출력부를 더 포함하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 터치 센서는 상기 로봇의 상단부의 상기 로봇의 상면에서 상기 로봇의 둘레를 따라서 배치되고,상기 인디케이터 출력부는 상기 상면에서 상기 터치 센서가 배치되지 않은 중심 영역에 배치되고, 공개특허 10-2025-0053584-4-상기 터치 센서와 상기 인디케이터 출력부의 동작을 제어하는 상기 센서부의 컨트롤러가 상기 터치 센서 또는상기 인디케이터 출력부의 아래에서 배치되는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 터치 센서는 컨덕티브(conductive) 센서를 포함하는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 센서부는, 상기 터치 센서보다 상기 둘레에 더 가깝게 배치되는 적어도 하나의 카메라를 더 포함하고,상기 로봇의 상단부에는, 상기 컨트롤러의 하단에 배치되는 적어도 하나의 스피커; 및상기 상단부의 측면에 배치되는 적어도 하나의 추가 시각적 인디케이터 출력부가 더 마련되는, 로봇."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공간 내에서 이동하는 로봇 또는 상기 로봇을 제어하는 로봇 제어 시스템에 의해 수행되는, 로봇 제어 방법에있어서,상기 로봇은, 상기 로봇의 상단부에 마련되고, 사용자로부터의 터치 입력을 포함하는 제1 입력을 감지하도록 구성되는 적어도 하나의 터치 센서를 포함하는 센서부; 상기 로봇을 구동하는 구동부; 및 상기 구동부의 동작을제어하여 상기 로봇의 자세 또는 상기 로봇의 이동을 제어하고, 상기 센서부의 동작을 제어하는 제어부를 포함하고,상기 터치 입력을 포함하는 제1 입력을 감지하는 단계; 및 상기 제1 입력에 기반하여, 상기 로봇이 특정한 모션을 수행하도록 상기 구동부의 동작을 제어하는 것 및 상기제1 입력에 후속하는 상기 사용자로부터의 제2 입력을 감지하도록 상기 센서부의 동작을 제어하는 것 중 적어도하나를 수행하는 단계를 포함하는, 로봇 제어 방법."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제2 입력을 감지하는 단계; 및상기 제2 입력에 기반하여 상기 로봇이 타겟 모션을 수행하거나 타겟 정보를 출력하도록 상기 로봇을 제어하는단계를 더 포함하는, 로봇 제어 방법."}
{"patent_id": "10-2023-0137063", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 인디케이터 출력부를 통해, 상기 터치 입력의 개수, 상기 터치 입력이 상기 터치 센서를 접촉하는 면적 및 상기터치 입력의 방향에 따라 변화하는 시각적 인디케이터를 출력하는 단계를 더 포함하는, 로봇 제어 방법.공개특허 10-2025-0053584-5-청구항 18 제15항의 방법을 컴퓨터에서 실행시키기 위해 비-일시적인 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇의 상단부에 마련되고, 사용자로부터의 터치 입력을 포함하는 제1 입력을 감지하도록 구성되는 터치 센서를 포함하는 센서부, 로봇을 구동하는 구동부 및 구동부의 동작을 제어하여 로봇의 자세 또는 로봇의 이동을 제어하 고, 센서부의 동작을 제어하는 제어부를 포함하는 로봇이 제공된다. 로봇의 제어부는, 감지된 제1 입력에 기반하 여 로봇이 특정한 모션을 수행하도록 구동부의 동작을 제어하는 것 및/또는 제1 입력에 후속하는 사용자로부터의 제2 입력을 감지하도록 상기 센서부의 동작을 제어하는 것을 수행할 수 있다."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 로봇과의 인터랙션을 위해 사용자로부터의 입력을 감지하기 위한 센서를 포함하는 센서부와, 구 동부 및 제어부를 포함하는 로봇과, 로봇을 제어하는 방법에 관한 것이다."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율 주행 로봇 등을 비롯한 로봇은 실내 외 공간에서의 다양한 서비스의 제공을 위해 사용되고 있다. 이러한 로봇은, 특정한 작업을 수행하거나 서비스를 제공하기 위해 공간 내를 자율 주행하도록 구성된다. 다양한 서비스를 제공하는 로봇은 해당 로봇을 이용하고자 하는 사용자와 상호작용할 수 있다. 예컨대, 로봇은 터치 디스플레이와 같은 사용자 인터페이스를 구비하고 있을 수 있고, 사용자는 이러한 사용자 인터페이스를 통 해 로봇에 명령을 내리거나, 로봇이 소기의 정보를 출력하도록 할 수 있다. 그러나, 이러한 터치 디스플레이를 통해 로봇과 상호작용하는 방식은, 특히, 로봇이 주행 중인 경우나 동적인 작업을 수행하고 있는 경우에는, 사용자가 터치 디스플레이에 정확한 터치 입력을 제공하기가 어렵고, 따라서, 로봇과의 상호작용 역시 편리하게 이루어질 수 없다. 따라서, 로봇이 정지 상태에 있는 경우 뿐만 아니라, 로봇이 주행 중인 상태에서도, 사용자로부터의 입력을 통 해 로봇과의 상호작용(이하, 인터랙션이라고도 함)을 강화할 수 있도록 하는 기술이 요구된다. 한국등록특허 제10-1231771호는 로봇이 이동 또는 내부 고장 등의 의해 변경되는 외부 또는 내부의 환경 변화 및 상황 조건들에 적합한 반응 및 적절한 동작을 자율적으로 수행 가능 하도록 하기 위해 로봇 내부에 구비된 소프트웨어 컴포넌트 또는 외부의 서버로부터 다운받아 동적으로 재구성하는 로봇 소프트웨어 컴포넌트 동적 재 구성 방법에 관해 개시하고 있다. 상기에서 설명된 정보는 단지 이해를 돕기 위한 것이며, 종래 기술의 일부를 형성하지 않는 내용을 포함할 수 있으며, 종래 기술이 통상의 기술자에게 제시할 수 있는 것을 포함하지 않을 수 있다."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "로봇의 상단부에 마련되고, 사용자로부터의 터치 입력을 포함하는 제1 입력을 감지하도록 구성되는 터치 센서를 포함하는 센서부와, 감지된 제1 입력에 기반하여 로봇이 특정한 모션을 수행하도록 구동부의 동작을 제어하거나, 또는/추가적으로 제1 입력에 후속하는 사용자로부터의 제2 입력을 감지하도록 센서부의 동작을 제 어하는 제어부를 포함하는 로봇을 제공할 수 있다. 로봇의 상단부의 상면에서 로봇의 둘레를 따라 터치 센서를 배치하고, 터치 센서에 대한 터치 입력의 개수, 터 치 입력이 터치 센서를 접촉하는 면적 및 터치 입력의 방향에 따라 변화하는 시각적 인디케이터를 출력하도록 구성되는 인디케이터 출력부를 포함하는 로봇을 제공할 수 있다. 사용자로부터 터치 입력을 포함하는 제1 입력이 센서부에 의해 감지됨에 따라, 제1 입력의 방향 또는 사용자의 방향으로 로봇을 지향시키고, 사용자로부터 후속하는 제2 입력에 기반하여 로봇이 소기의 타겟 모션을 수행하게 하거나 타겟 정보를 출력하게 하도록 로봇을 제어하는 방법을 제공할 수 있다."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 있어서, 공간을 자율 주행하는 로봇에 있어서, 상기 로봇의 상단부에 마련되고, 사용자로부터의 터치 입력을 포함하는 제1 입력을 감지하도록 구성되는 적어도 하나의 터치 센서를 포함하는 센서부; 상기 로봇을 구 동하는 구동부; 및 상기 구동부의 동작을 제어하여 상기 로봇의 자세 또는 상기 로봇의 이동을 제어하고, 상기 센서부의 동작을 제어하는 제어부를 포함하고, 상기 제어부는, 상기 제1 입력에 기반하여, 상기 로봇이 특정한모션을 수행하도록 상기 구동부 또는 상기 센서부의 동작을 제어하는 것 및 상기 제1 입력에 후속하는 상기 사 용자로부터의 제2 입력을 감지하도록 상기 센서부의 동작을 제어하는 것 중 적어도 하나를 수행하도록 구성되는, 로봇이 제공된다. 상기 특정한 모션은 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로봇이 지향하게 하도록 하는 것일 수 있다. 상기 로봇이 주행하고 있는 상태에서, 상기 제1 입력이 감지된 때, 상기 제어부는, 상기 로봇의 주행을 정지시 키고 상기 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로봇이 지향하게 하도록 상기 구동부의 동작을 제어할 수 있다. 상기 제2 입력은 상기 터치 센서에 대한 추가적인 터치 입력 및 상기 센서부가 포함하는 마이크에 대한 상기 사 용자로부터의 음성 입력 중 적어도 하나를 포함할 수 있다. 상기 제2 입력은 복수이고, 복수의 제2 입력들이 소정의 순서 또는 패턴으로 상기 사용자에 의해 입력됨에 따라, 상기 제어부는, 상기 로봇이 상기 제2 입력들과 연관된 타겟 모션을 수행하거나, 상기 로봇이 상기 제2 입력들과 연관된 타겟 정보를 출력하도록, 상기 로봇을 제어할 수 있다. 상기 타겟 모션 또는 상기 타겟 정보는 상기 사용자가 상기 로봇을 통해 수행하는 게임과 연관된 것이고, 상기 제1 입력은 상기 게임을 시작하기 위한 상기 로봇에 대한 입력일 수 있다. 상기 로봇은 상기 공간 내에서 서비스를 제공하는 서비스 로봇이고, 상기 로봇이 상기 서비스의 제공을 위한 제 1 작업의 완료를 실패하고 주행하고 있는 상태에서, 상기 제어부는, 상기 제1 입력이 감지된 때, 상기 로봇의 주행을 정지시키고 상기 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로봇이 지향하게 하고, 상 기 제2 입력이 감지된 때, 상기 로봇이 상기 제1 작업을 다시 수행하도록 상기 로봇을 제어할 수 있다. 상기 로봇은 상기 공간 내에서 서비스를 제공하는 서비스 로봇이고, 상기 로봇이 상기 서비스의 제공을 위한 제 1 작업의 완료를 실패하고 주행하고 있는 상태에서, 상기 제어부는, 상기 제1 입력이 감지된 때, 상기 제어부는, 상기 로봇의 주행을 정지시키고 상기 제1 입력이 감지된 방향 또는 상기 사용자의 방향으로 상기 로 봇이 지향하게 하고, 상기 로봇이 상기 제1 작업을 다시 수행하도록 상기 로봇을 제어할 수 있다. 상기 터치 입력은 상기 터치 센서를 소정의 제1 면적 이상 접촉하는 터치 입력일 수 있다. 상기 제어부는, 상기 터치 입력이 상기 터치 센서를 접촉하는 면적에 따라, 상기 로봇이 상이한 모션을 수행하 도록 상기 구동부의 동작을 제어할 수 있다. 상기 로봇은 상기 터치 입력의 개수, 상기 터치 입력이 상기 터치 센서를 접촉하는 면적 및 상기 터치 입력의 방향에 따라 변화하는 시각적 인디케이터를 출력하도록 구성되는 인디케이터 출력부를 더 포함할 수 있다. 상기 터치 센서는 상기 로봇의 상단부의 상기 로봇의 상면에서 상기 로봇의 둘레를 따라서 배치되고, 상기 인디 케이터 출력부는 상기 상면에서 상기 터치 센서가 배치되지 않은 중심 영역에 배치되고, 상기 터치 센서와 상기 인디케이터 출력부의 동작을 제어하는 상기 센서부의 컨트롤러가 상기 터치 센서 또는 상기 인디케이터 출력부 의 아래에서 배치될 수 있다. 상기 터치 센서는 컨덕티브(conductive) 센서를 포함할 수 있다. 상기 센서부는, 상기 터치 센서보다 상기 둘레에 더 가깝게 배치되는 적어도 하나의 카메라를 더 포함하고, 상 기 로봇의 상단부에는, 상기 컨트롤러의 하단에 배치되는 적어도 하나의 스피커; 및 상기 상단부의 측면에 배치 되는 적어도 하나의 추가 시각적 인디케이터 출력부가 더 마련될 수 있다. 다른 일 측면에 있어서, 공간 내에서 이동하는 로봇 또는 상기 로봇을 제어하는 로봇 제어 시스템에 의해 수행 되는, 로봇 제어 방법에 있어서, 상기 로봇은, 상기 로봇의 상단부에 마련되고, 사용자로부터의 터치 입력을 포 함하는 제1 입력을 감지하도록 구성되는 적어도 하나의 터치 센서를 포함하는 센서부; 상기 로봇을 구동하는 구 동부; 및 상기 구동부의 동작을 제어하여 상기 로봇의 자세 또는 상기 로봇의 이동을 제어하고, 상기 센서부의 동작을 제어하는 제어부를 포함하고, 상기 터치 입력을 포함하는 제1 입력을 감지하는 단계; 및 상기 제1 입력 에 기반하여, 상기 로봇이 특정한 모션을 수행하도록 상기 구동부의 동작을 제어하는 것 및 상기 제1 입력에 후 속하는 상기 사용자로부터의 제2 입력을 감지하도록 상기 센서부의 동작을 제어하는 것 중 적어도 하나를 수행 하는 단계를 포함하는, 로봇 제어 방법이 제공된다. 상기 로봇 제어 방법은, 상기 제2 입력을 감지하는 단계; 및 상기 제2 입력에 기반하여 상기 로봇이 타겟 모션 을 수행하거나 타겟 정보를 출력하도록 상기 로봇을 제어하는 단계를 더 포함할 수 있다. 상기 로봇 제어 방법은, 인디케이터 출력부를 통해, 상기 터치 입력의 개수, 상기 터치 입력이 상기 터치 센서 를 접촉하는 면적 및 상기 터치 입력의 방향에 따라 변화하는 시각적 인디케이터를 출력하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "터치 입력과 같은 사용자로부터의 물리적인 입력을 통해 효과적으로 감지할 수 있도록 하는 상단부의 센서 배치 구조를 갖는 센서부를 포함하는 로봇을 제공할 수 있다. 로봇이 정지 상태에 있을 경우 뿐만 아니라, 주행 상태에 있는 경우에도 터치 입력과 같은 사용자로부터의 물리 적인 입력이 효과적으로 감지될 수 있고, 따라서, 로봇과 사용자 간의 인터랙션을 위한 로봇의 구동부 및/또는 센서부의 제어가 신뢰성 있게 이루어질 수 있다. 주행 중인 로봇의 상면을 터치하는 간단한 동작을 통해 해당 터치 입력의 방향이나 사용자의 방향으로 로봇을 지향시킬 수 있고, 추가적인 입력을 통해 로봇의 소기의 타겟 모션을 수행하도록 하거나, 소기의 타겟 정보를 출력하도록 할 수 있다. 로봇이 서비스 제공을 위한 작업(작업의 일부)를 완료하지 못하고 주행하고 있는 상태에서도, 로봇의 센서부에 대한 간단하고 직관적인 터치 입력을 통해, 로봇이 해당 미완료된 작업(작업의 일부)을 다시 수행하도록 할 수 있다."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 도 1은 일 실시예에 따른, 사용자로부터의 터치 입력을 포함하는 입력을 감지하기 위한 센서부가 상단부에 마련 된 로봇과 그 제어 방법을 나타낸다. 도 1에서는, 적어도 하나의 센서를 포함하는 센서부가 로봇의 상단부에 배치되고, 로봇의 이동 및 주행을 가능하게 하는 구성인 구동부와 구동부 및 센서부를 제어하기 위한 제어부가 로 봇의 하단부에 배치되는 로봇이 도시되었다. 구동부는 로봇의 자율 주행 플랫폼(즉, 주행 부)에 대응할 수 있다. 도 1에서 도시된 로봇은 공간 내를 주행할 수 있다. 로봇은 예컨대, 건물과 같은 실내 또는 실외의 공간에서 서비스를 제공하도록 구성되는 로봇일 수 있다. 한편, 로봇은 실내 또는 실외의 공간을 주행(또 는, 자율 주행)하는 여하한 종류의 이동 수단 또는 이동체로, 차량, 대차 등일 수 있다. 도시된 것처럼, 이러한 로봇은 (로봇) 제어 시스템에 의한 제어에 따라 공간 내에서 이동할 수 있다. 로봇이 이동(또는 주행)하는 공간은 로봇이 서비스를 제공하는 장소로서, 예컨대, 건물 또는 빌딩에 포함되는 실내 및/또는 실외의 공간을 나타낼 수 있다. 건물 또는 빌딩은 복수의 인원(이하, 사용자라 함)들이 근무 또는 상주하는 공간을 포함하며, 예컨대, 복수의 구획된 공간들을 포함할 수 있다. 공간은 건물의 일부(특 정 층 또는 해당 층 내의 부분 공간)를 나타낼 수 있다. 로봇이 서비스 로봇인 경우 로봇은 공간의 적어도 하나의 층에서 서비스를 제공하도록 구성될 수 있 다. 도 1에서는 하나의 로봇 만이 도시되었으나, 공간 내에서 배치되어 동작하는 로봇은 복수일 수 있다. 공간 내에서는 로봇의 각각이 이동하여 공간 내의 적절한 위치 또는 적절한 사용자에게 서비스를 제 공할 수 있다. 로봇이 제공하는 서비스는 예컨대, 택배 전달 서비스, 주문에 따른 음료(커피 등) 전달 서비스, 청소 서비 스, 및 기타 정보/콘텐츠 제공 서비스 중 적어도 하나를 포함할 수 있다. 로봇은 자율 주행을 통해 공간의 소정의 위치에서 또는 소정의 사용자에게 서비스를 제공하도록 구성될 수 있으며, 로봇의 (각각의) 이동 및 서비스의 제공은 로봇 제어 시스템에 의해 제어될 수 있다. 도시된 것처럼, 로봇은 센서부와 구동부 및 제어부를 포함하도록 구성될 수 있다. 센서부 는 로봇의 상단부에 마련될 수 있고, 구동부와 제어부는 로봇의 하단부에 마련될 수 있다. 또는 도시된 것과는 다르게 제어부는 하단부가 아니라 상단부에 마련될 수도 있고, 또는, 하단부와 상단부 사이의 중간부에 마련될 수도 있다. 센서부는 도시된 것처럼, 사용자로부터의 터치 입력을 포함하는 제1 입력을 감지하도록 구성될 수 있다. 이러한 센서부는 적어도 하나의 터치 센서를 포함할 수 있다. 터치 입력은 사용자에 의한 터치 센서에의 물리적인 접촉 또는 인터랙션을 의미할 수 있다. 한편, 센서부는 로봇의 공간 내에서의 자율 주행을 위해 공간 내의 주변 환경에 대한 센싱 정보와 로 봇의 움직임 또는 자세와 관련된 센싱 정보를 획득하도록 구성될 수 있다. 센서부는 이러한 센싱 정 보를 획득하기 위한 적어도 하나의 센서를 포함할 수 있다. 이러한 센서는 적어도 로봇의 전방 하측을 감 지하도록 구성될 수 있다. 또한, 센서는 도시되지는 않았으나 로봇의 상단에서 (그 상측을 포함하는) 주변 환경을 감지하도록 구성될 수도 있다. 이처럼, 센서부는 로봇이 장애물을 회피하고 자율 주행될 수 있도록 하기 위해 로봇의 주변 환 경과 로봇의 움직임 또는 자세를 감지하기 위한 목적의 센서와, 사용자로부터의 터치 입력을 포함하는 제1 입력 을 감지하기 위한 센서(예컨대, 터치 센서)를 포함할 수 있고, 또한, 센서부는 이들 센서를 제어하기 위한 컨트롤러에 해당하는 컴퓨팅 모듈을 더 포함할 수 있다. 구동부는 로봇을 구동시키는 장치를 포함할 수 있다. 구동부는 센서부로부터의 상기 센싱 정보에 기반한 로봇의 자율 주행을 위해 로봇을 구동하는 장치일 수 있다. 구동부는 제어부 를 통한 제어에 따라 로봇의 이동시키며, 로봇의 이동을 가능하게 하기 위한 장비를 포함할 수 있다. 구동부는 로봇의 주행을 위해 동작하는 전자 및/또는 기계 장치로서 적어도 하나의 모터, 모터 드라이버 및 기타 기구부를 포함할 수 있다. 예컨대, 로봇은 모터에 의해 바퀴가 동작하여 공간을 주행할 수 있다. 또한, 구동부는 로봇을 동작시키기 위한 배터리를 포함할 수 있다. 이러한 구동부는 로봇의 주행과 관련되는 장치들을 포함하여 로봇의 하단에 배치되는 구성으로 서, 주행 플랫폼으로도 명명될 수 있다. 로봇의 상단부와 하단부 사이에는 페이로드가 적재되는 공간이 마련될 수 있다. 페이로드는, 로봇에 적재되어 수납되어야 하는 화물 또는 물건을 나타낼 수 있고, 예컨대, 로봇이 제공하는 서비스와 연관된 것으로서, 음식물, 택배물, 청소 로봇이 파지하는 청소 용품 또는 쓰레기 등일 수 있다. 페이로드는 다양한 형 태 및 크기를 가질 수 있다. 말하자면, 페이로드는 로봇의 센서부 아래의 수납 공간에 적재된 물건을 나타낼 수 있다. 제어부는 구동부의 동작을 제어하여 로봇의 자세 또는 로봇의 이동을 제어하고(즉, 로봇 의 모션 또는 자율 주행을 제어하고), 센서부의 동작을 제어하기 위한 컴퓨팅 모듈일 수 있다. 실시예에서는, 제어부는, 센서부의 적어도 하나의 터치 센서를 통해 감지되는 터치 입력을 포함하는 제1 입력에 기반하여, 로봇이 특정한 모션을 수행하도록 구동부 또는 센서부의 동작을 제어할 수 있다. 예컨대, 제어부는 제1 입력에 따라 로봇이 특정한 자세를 취하게 하거나, 로봇이 특정 한 위치로 이동하게 할 수 있다. 일례로, 상기 특정한 모션은 제1 입력이 감지된 방향(또는, 사용자의 방향)으 로 로봇이 지향하게 하도록 하는 것일 수 있다. 즉, 로봇은 사용자에 의해 터치 입력이 적용된 방향 을 향하는 자세를 취할 수 있다. 이 때, 사용자는 로봇이 자신(또는 자신이 터치한 방향)을 지향하고 있음 을 시각적으로 인식할 수 있다. 로봇이 제1 입력이 감지된 방향으로 로봇을 지향하게 하는 구체적인 예시는 도 8a 및 도 8b를 참조하여 더 자세하게 후술된다. 제1 입력은 로봇이 정지 상태에 있는 경우 뿐만 아니라, 로봇이 주행 상태에 있는 경우에도 센서부 에 대해 입력될 수 있다. 로봇이 주행하고 있는 상태에서, 제1 입력이 감지된 때, 제어부는, 로 봇의 주행을 정지시키고 제1 입력이 감지된 방향(또는, 사용자의 방향)으로 로봇이 지향하게 하도록 구동부의 동작을 제어할 수 있다. 실시예에서는, 로봇의 상단에 센서부가 배치됨으로써, 센서부가 상기 제1 입력을 효과적으로 감 지할 수 있다. 말하자면, 사용자가 센서부에 상기 제1 입력을 손쉽게 입력할 수 있다. 따라서, 로봇 이 정지 상태에 있는 경우 뿐만 아니라, 로봇이 주행 상태에 있더라도 사용자는 로봇의 상단부의 상 면을 터치함으로써 센서부에 대해 제1 입력을 편리하게 입력할 수 있다. 이로서, 주행 중인 로봇에 대해 사용자가 인터랙션하고자 할 때, 사용자는 단순히 로봇의 상면을 터치하는 것으로 로봇의 주행 을 멈추게 하고, 사용자를 지향하게 할 수 있다. 또는/추가적으로, 제어부는, 상기 제1 입력에 기반하여, 제1 입력에 후속하는 사용자로부터의 제2 입력을 감지하도록 센서부의 동작을 제어할 수 있다. 예컨대, 제어부는 터치 입력 및/또는 음성 입력을 포함 하는 제2 입력이 센서부를 통해 감지될 수 있도록, 센서부를 동작시킬 수 있다. 말하자면, 제2 입력 은 센서부의 터치 센서에 대한 추가적인 터치 입력 및 센서부가 포함하는 마이크에 대한 사용자로부 터의 음성 입력 중 적어도 하나를 포함할 수 있다. 제어부는 이러한 제2 입력에 따라 로봇이 특정한 자세를 취하게 하거나, 로봇이 특정한 위치로 이동하게 할 수 있다. 또는, 제어부는 제2 입력에 따라 로봇이 특정한 작업을 수행하게 할 수도 있다. 예컨대, 제어부는 제2 입력에 따라 로봇이 제2 입력과 연관된 타겟 모션을 수행하거나, 제2 입력과 연관된 타겟 정보(콘텐츠)를 출력하도록 로봇을 제어 할 수 있다. 제1 입력 및/또는 제2 입력에 기반하여 로봇이 제어되는 보다 구체적인 예시에 대해서는 후술될 도 9a 내 지 도 9c와 도 10a 및 도 10b를 참조하여 더 자세하게 설명된다. 또한, 실시예에서는, 로봇의 상단에 센서부가 배치됨으로써, 자율 주행을 위해 필요한 주변 환경에 대한 정보(특히, 공간의 바닥면에 대한 정보)가 보다 효과적으로 감지될 수 있다. 예컨대, 로봇은 공간의 바닥면에 존재하는 굴곡, 턱, 절벽 등을 보다 효과적으로 감지할 수 있고, 바닥면에 위치하는 동적 및/또는 정 적 장애물을 보다 용이하게 파악할 수 있다. 센서부 및 로봇이 포함하는 보다 구체적인 구성들과, 로봇을 제어하는 구체적인 방법에 대해서 는 후술될 도 2 내지 도 12를 참조하여 더 자세하게 설명된다. 도 2는 일 실시예에 따른, 공간 내에서 이동하는 로봇을 나타내는 블록도이다. 전술한 것처럼, 로봇은 공간 내에서 서비스를 제공하기 위해 사용되는 서비스 로봇일 수 있다. 로봇 은 자율 주행을 통해 공간의 소정의 위치에서 또는 소정의 사용자에게 서비스를 제공할 수 있다. 로봇은 물리적인 장치일 수 있으며, 도시된 바와 같이, 제어부, 구동부, 센서부 및 통신부 를 포함할 수 있다. 제어부는 로봇에 내장된 물리적인 프로세서일 수 있으며, 별도로 도시하지는 않았으나, 경로 계획 처 리 모듈, 맵핑 처리 모듈, 구동 제어 모듈, 로컬리제이션 처리 모듈, 데이터 처리 모듈 및 서비스 처리 모듈을 포함할 수 있다. 이 때, 경로 계획 처리 모듈, 맵핑 처리 모듈 및 로컬리제이션 처리 모듈은 제어 시스템 과 통신이 이루어지지 않는 경우에도 로봇의 실내 자율 주행이 이루어질 수 있도록 하기 위해 실시예에 따 라 선택적으로 제어부에 포함되는 것일 수도 있다. 제어부의 적어도 일부는 전술한 로봇의 상단 에 마련되는 센서부 측(즉, 상단부 측)에 포함될 수도 있다. 통신부는 로봇이 다른 장치(다른 로봇/로봇 또는 제어 시스템 등)와 통신하기 위한 구성일 수 있다. 말하자면, 통신부는 다른 장치에 대해 데이터 및/또는 정보를 전송/수신하는, 로봇의 안테나, 데이터 버스, 네트워크 인터페이스 카드, 네트워크 인터페이스 칩 및 네트워킹 인터페이스 포트 등과 같은 하드 웨어 모듈 또는 네트워크 디바이스 드라이버(driver) 또는 네트워킹 프로그램과 같은 소프트웨어 모듈일 수 있 다. 구동부는 로봇의 이동을 제어하며 이동을 가능하게 하는 구성으로서 이를 수행하기 위한 장비를 포함 할 수 있다. 구동부는 로봇의 주행을 위해 동작하는 전자 및/또는 기계 장치로서 적어도 하나의 모터 를 포함할 수 있다. 예컨대, 로봇은 모터에 의해 바퀴가 동작하여 공간을 주행할 수 있다. 구동부는 로봇의 하단에 마련되는 주행 플랫폼을 나타낼 수 있다. 센서부는 로봇의 자율 주행 및 서비스 제공에 있어서 요구되는 데이터를 수집하기 위한 구성일 수 있 다. 센서부는 도 1을 참조하여 전술한 로봇의 상단부에 마련되는 센서부에 해당하는 구성으로서, 적어도 하나의 센서를 포함할 수 있다. 센서부에 포함되는 센서는, 전술한 사용자로부터의 터 치 입력을 감지하기 위한 적어도 하나의 터치 센서와 로봇의 주변 환경과 로봇의 움직임 또는 자세를 감지 하기 위한 목적의 센서(이하, 주행 관련 센서라고도 지칭함)를 포함할 수 있다. 및 센서부는 자율 주행 모 듈에 포함될 수 있고, 전술한 제어부의 적어도 일부에 해당하는 컴퓨팅 모듈을 포함하는 구성일 수 있다. 또는, 센서부는, 센서부를 구성하는 다수의 센서들을 제어하기 위한 컨트롤러에 해당하는 컴퓨팅 모 듈을 더 포함할 수 있다. 센서부는 상기 주행 관련 센서로서 고가의 센싱 장비를 포함하지 않을 수 있고, 단지 저가형 초음파 센서 및/또는 저가형 카메라 등과 같은 센서를 포함할 수 있다. 센서부는 전방 및/또는 후방의 다른 로봇이나 사람, 주변(공간 내의 바닥 등)의 장애물을 식별하기 위한 센서를 포함할 수 있다. 예컨대, 센서부는, 센 서로서, 뎁스(depth) 카메라, 적외선 카메라 또는 센서, RGB 카메라 등과 같은 비전(vision) 센서(비전 인 식을 위한 광학 센서 등) 및 거리 센서 중 적어도 하나를 포함할 수 있다. 이러한 주행 관련 센서를 통해, 주변 의 다른 로봇, 사람 및 기타 지물들이 인식될 수 있다. 이러한 주행 관련 센서는 해상도가 높고, 주변 환경에 대해 획득되는 정보량이 풍부하게 되는 것으로서 선택될 수 있다. 한편, 터치 센서는 로봇의 상단부의 상 면에 마련되는 것으로서, 예컨대, 컨덕티브(conductive) 센서를 포함할 수 있다. 컨덕티브 센서로 구성된 터치 센서는 전기적인 신호를 이용하여 사용자로부터의 터치를 감지할 수 있다. 센서부를 포함하는 상단부의 구성에 대해서는 후술될 도 5, 도 6 및 도 12를 참조하여 더 자세하게 설명된 다. 로봇은 전술한 제어부의 서비스 처리 모듈이 로봇 제어 시스템을 통해 수신되는 명령을 통신부 를 통해 또는 통신부와 데이터 처리 모듈을 통해 전달 받아 서비스 제공을 위해 구동부 및 도시 되지 않은 로봇 암 등을 작동시킬 수 있다. 서비스 처리 모듈은 제공해야 할 서비스를 위한 구동 명령을 구동 제어 모듈로 전달할 수 있고, 구동 제어 모듈은 구동 명령에 따라 로봇의 구동부와 로봇 암이 포함하 는 구성을 제어하여 서비스가 제공될 수 있도록 할 수 있다. 또한, 로봇은 서비스의 제공을 위해 필요한 정보/콘텐츠의 출력을 위한 스피커 및/또는 디스플레이 등을 더 포함할 수도 있다. 스피커 및/또는 디스플레이 등의 정보/콘텐츠 출력을 위한 구성은 로봇의 상단부에 배치될 수 있다. 한편, 로봇은 공간 내의 실내 맵을 생성하기 위해 사용되는 맵핑용 로봇(즉, 맵핑 로봇)과는 구별되는 것 일 수 있다. 로봇은 상기 주행 관련 센서로서 고가의 센싱 장비를 포함하지 않기 때문에 저가형 초음파 센 서 및/또는 저가형 카메라 등과 같은 센서의 출력값을 이용하여 실내 자율 주행을 처리할 수 있다. 한편, 로봇 이 기존에 로봇 제어 시스템과의 통신을 통해 실내 자율 주행을 처리한 적이 있다면, 제어 시스템으로부터 기존에 수신한 경로 데이터(예컨대, 경로에 대한 데이터)가 포함하는 맵핑 데이터 등을 더 활용 함으로써 저가의 센서들을 이용하면서도 보다 정확한 실내 자율 주행이 가능하게 될 수 있다. 다만, 실시예에 따라서는 로봇이 상기 맵핑 로봇을 겸할 수도 있을 것이다. 전술한 것처럼, 로봇이 로봇의 제어를 위한 센싱 정보를 로봇 제어 시스템으로 제공할 뿐이고, 로봇의 제어를 위한 알고리즘이 로봇 제어 시스템에서 실행되는 경우, 로봇은 브레인리스 로봇 에 해당할 수 있다. 말하자면, 전술한 제어부를 통한 구동부 및 센서부에 대한 제어는 로봇 제 어 시스템으로부터의 명령 또는 제어 신호를 통신부에 의해 제어부가 수신하여, 제어부를 통해 수행되는 것일 수 있다. 한편, 로봇의 각각은 기종이나 제공하는 서비스 등에 따라, 상이한 크기 및 형태를 가질 수 있고, 도면에 서 도시된 형태로 제한되지 않는다. 로봇을 제어하는 로봇 제어 시스템의 구성 및 동작에 대해서는 후술될 도 3 및 도 4를 참조하여 각각 더 자세하게 설명된다. 이상 도 1을 참조하여 전술된 기술적 특징에 대한 설명은, 도 2에 대해서도 그대로 적용될 수 있으므로 중복되 는 설명은 생략한다. 도 3 및 도 4는 일 실시예에 따른, 로봇을 제어하는 로봇 제어 시스템을 나타내는 블록도이다. 로봇 제어 시스템은 전술된 로봇의 공간 내에서의 이동(즉, 자율 주행)과 공간 내에서의 서비스의 제 공을 위한 로봇의 구성들의 동작(예컨대, 제어부를 통한 구동부 및 센서부에 대한 동작 제 어)을 제어하는 장치일 수 있다. 로봇 제어 시스템은 복수의 로봇 각각의 이동 및 로봇 각각의 서비스의 제공을 제어할 수 있다. 로봇 제어 시스템은 로봇과의 통신을 통해, 로봇이 서비스를 제공하기 위한 목적지로의 경로를 설정할 수 있고, 이러한 경로에 관한 정보를 로봇에게 전달할 수 있다. 로봇은 수신된 경로에 관한 정보에 따라 주행할 수 있고, 소정의 위치에서 또는 소정의 사용자의 위치에서 도시되지 않은 로봇 암을 제어하 여 서비스를 제공할 수 있다. 로봇 제어 시스템은 적어도 하나의 컴퓨팅 장치를 포함할 수 있다. 로봇 제어 시스템은 전술한 것처럼 로봇의 주행을 위한 경로를 설정하고 로봇의 이동을 제어하 는 장치일 수 있다. 로봇 제어 시스템은 적어도 하나의 컴퓨팅 장치를 포함할 수 있고, 공간 내 또는 공간 외부에 위치하는 서버로 구현될 수 있다. 로봇 제어 시스템은 도시된 것처럼, 메모리, 프로세서, 통신부 및 입출력 인터페이스(34 0)를 포함할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 비소멸성 대용량 기록장치는 메모리와 분리되어 별도의 영구 저장 장치로서 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요 소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터 에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨 터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가 능한 기록매체가 아닌 통신부를 통해 메모리에 로딩될 수도 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신부에 의해 프로세서로 제공될 수 있다. 예를 들어, 프 로세서는 메모리에 로딩된 프로그램 코드에 따라 수신되는 명령을 실행하도록 구성될 수 있다. 이러 한 프로세서는 도 4에서 도시된 것과 같은 구성들(410 내지 440)을 포함할 수 있다. 프로세서의 구성들(410 내지 440) 각각은 프로세서의 일부로서 소프트웨어 및/또는 하드웨어 모듈일 수 있고, 프로세서에 의해 구현되는 기능(기능 블록)을 나타낼 수 있다. 프로세서의 구성들(410 내지 44 0)에 대해서는 도 4를 참조하여 후술한다.통신부는 로봇 제어 시스템이 다른 장치(로봇 또는 다른 서버 등)와 통신하기 위한 구성일 수 있다. 말하자면, 통신부는 다른 장치에 대해 데이터 및/또는 정보를 전송/수신하는, 로봇 제어 시스템 의 안테나, 데이터 버스, 네트워크 인터페이스 카드, 네트워크 인터페이스 칩 및 네트워킹 인터페이스 포 트 등과 같은 하드웨어 모듈 또는 네트워크 디바이스 드라이버(driver) 또는 네트워킹 프로그램과 같은 소프트 웨어 모듈일 수 있다. 입출력 인터페이스는 키보드 또는 마우스 등과 같은 입력 장치 및 디스플레이나 스피커와 같은 출력 장치 와의 인터페이스를 위한 수단일 수 있다. 또한, 다른 실시예들에서 로봇 제어 시스템은 도시된 구성요소들보다 더 많은 구성요소들을 포함할 수도 있다. 도 4를 참조하여 프로세서의 구성들(410 내지 440)에 대해 더 자세하게 설명한다. 프로세서는 도시된 것처럼, 맵 생성 모듈, 로컬리제이션 처리 모듈, 경로 계획 처리 모듈 및 서비스 운영 모듈 을 포함할 수 있다. 이러한 프로세서가 포함하는 구성요소들은, 운영체제의 코드나 적어도 하나의 컴 퓨터 프로그램의 코드에 따른 제어 명령(instruction)에 따라 프로세서이 포함하는 적어도 하나의 프로세 서가 수행하는 서로 다른 기능들(different functions)의 표현들일 수 있다. 맵 생성 모듈은 공간 내부에서 자율 주행하는 (도시되지 않은) 맵핑 로봇이 목표 시설물의 (예컨대, 공간 의 내부에 대해 생성한 센싱 정보를 이용하여) 실내 맵을 생성하기 위한 구성요소일 수 있다. 이 때, 로컬리제이션 처리 모듈은 로봇로부터 네트워크를 통해 수신되는 센싱 정보와 맵 생성 모듈 을 통해 생성된 목표 시설물의 실내 맵을 이용하여 목표 시설물 내부에서의 로봇의 위치를 결정할 수 있다. 경로 계획 처리 모듈은 상술한 로봇로부터 수신된 센싱 정보와 생성된 실내 맵을 이용하여 로봇(10 0)의 실내 자율 주행을 제어하기 위한 제어 신호를 생성할 수 있다. 예컨대, 경로 계획 처리 모듈은 로봇 의 경로(즉, 경로 데이터)를 생성할 수 있다. 생성된 경로 데이터는 해당 경로를 따르는 로봇의 주행 을 위해 로봇에 대해 설정될 수 있다. 로봇 제어 시스템은 생성된 경로에 관한 정보를 네트워크를 통 해 로봇로 전송할 수 있다. 일례로, 경로에 관한 정보는 로봇의 현재 위치를 나타내는 정보, 현재 위 치와 실내 맵을 맵핑하기 위한 정보, 그리고 경로 계획 정보를 포함할 수 있다. 경로에 관한 정보에는 로봇 이 공간 내의 소정의 위치에서 또는 소정의 사용자에게 서비스를 제공하기 위해 주행해야 하는 공간의 목 적지에 관한 정보가 포함될 수 있다. 경로 계획 처리 모듈은 로봇을 위한 경로를 로봇에 대해 설정할 수 있다. 로봇 제어 시스템은 이러한 설정된 경로에 따라(즉, 설정된 경로를 따라) 로봇이 이 동하도록 로봇의 이동을 제어할 수 있다. 서비스 운영 모듈은 로봇이 공간 내에서 제공하는 서비스를 제어하기 위한 기능을 포함할 수 있다. 예를 들어, 로봇 제어 시스템 또는 공간을 운영하는 서비스 제공자는 로봇의 이용자나 제작자에게 로 봇 제어 시스템이 제공하는 서비스(예컨대, 클라우드 서비스)를 위한 IDE(Integrated Development Environment)를 제공할 수 있다. 이 때, 로봇의 이용자나 제작자는 로봇이 공간 내에서 제공하는 서 비스를 제어하기 위한 소프트웨어를 IDE를 통해 제작하여 로봇 제어 시스템에 등록할 수 있다. 이 경우, 서비스 운영 모듈은 해당 로봇과 연관하여 등록된 소프트웨어를 이용하여 로봇이 제공하는 서비 스를 제어할 수 있다. 구체적인 예로, 로봇이 사용자가 요청한 페이로드(예컨대, 음식물 또는 택배물)(3 0)를 해당 사용자의 위치로 전달하는 서비스를 제공한다고 가정하면, 로봇 제어 시스템은 로봇의 실 내 자율 주행을 제어하여 로봇이 해당 사용자의 위치로 이동하도록 제어할 뿐만 아니라, 목적 위치에 도착 한 경우 로봇 암 등을 제어함으로써 사용자에게 물건을 전달하고, 사용자 응대 음성을 출력하는 일련의 서비스 를 로봇이 제공하도록, 관련된 명령을 로봇에게 전달할 수 있다. 로봇 제어 시스템은 로봇을 제어하기 위한 컴퓨터 시스템으로서 서버일 수 있다. 로봇 제어 시스템 은 공간 또는 건물의 외부에 배치되는 서버로서, 클라우드 서버일 수 있다. 또는, 실시예에 따라서는 로봇 제어 시스템은 공간 또는 건물의 내부에 배치될 수도 있다. 후술될 상세한 설명에서, 로봇 제어 시스템 또는 로봇의 구성들(예컨대, 제어부, 프로세서 등)에 의 해 수행되는 동작은 설명의 편의상 로봇 제어 시스템 또는 로봇에 의해 수행되는 동작으로 설명될 수 있다. 또한, 도 5 내지 도 12를 참조하여 후술될 센서부 및 구동부의 제어를 비롯한 동작이나 도 11의 단계 들은 로봇 또는 로봇 제어 시스템에 의해 수행될 수 있다. 아래에서는 로봇에 의해 동작들이나 단계들이 수행되는 것을 중심으로 실시예를 설명하고, 로봇 제어 시스템에 의한 제어에 따라 로봇이 이들을 수행하는 것에 대한 중복되는 설명은 생략하는 경우가 있다. 또한, 로봇 또는 로봇 제어 시스템 의 구성들(예컨대, 제어부, 프로세서 등)에 의해 수행되는 동작이나 단계는 설명의 편의상 로봇 또는 로봇 제어 시스템에 의해 수행되는 것으로 설명될 수 있다. 이상 도 1 및 도 2를 참조하여 전술된 기술적 특징에 대한 설명은, 도 3 및 도 4에 대해서도 그대로 적용될 수 있으므로 중복되는 설명은 생략한다. 도 5는 일 예에 따른, 로봇의 상단부에 마련되는 사용자로부터의 터치 입력을 포함하는 입력을 감지하기 위한 센서부를 포함하는 로봇의 상단부를 나타내는 블록도이다. 도 5에서 도시된 것처럼, 로봇의 상단부에는 센서부에 포함되는 구성으로서 터치 센서가 배치될 수 있다. 또한, 상단부에는 센서부를 제어하기 위한 컨트롤러, 사용자로부터의 음성 입 력 또는 기타 외부 사운드 정보를 수신하기 위한 마이크, 사운드를 출력하기 위한 스피커, 로봇(10 0)의 외부 환경에 대한 정보를 캡쳐하기 위한 카메라, 사용자가 시인 또는 식별 가능한 인디케이터를 출력 하는 인디케이터 출력부가 배치될 수 있다. 청각적 인디케이터를 출력하는 인디케이터 출력부는 스피 커와 동일할 수 있다. 또는, 인디케이터 출력부는 시각적 인디케이터를 출력하는 구성요소(LED 및/또 는 디스플레이)를 포함할 수 있다. 여기서, 센서부는 마이크, 터치 센서, 카메라 및 컨트롤러를 포함할 수 있다. 다만, 실시예에 따라서는 센서부는 구성들(540 및 550) 중 적어도 하나를 더 포함하는 모듈로 구성될 수도 있다. 마이크는, 예컨대, 전술한 제2 입력으로서 사용자로부터의 음성 입력을 감지할 수 있다. 일례로, 전술한 제1 입력이 감지되면, 로봇은 제1 입력의 방향 또는 사용자의 방향으로 지향될 수 있다. 이 때, 로봇(10 0)이 주행 중인 경우에 제1 입력이 감지되면, 로봇은 주행을 정지하고 사용자의 방향 또는 사용자의 방향 으로 지향될 수 있다. 로봇이 제1 입력의 방향 또는 사용자의 방향으로 지향된 상태에서, 센서부는 제2 입력을 감지하도록 제어될 수 있다. 제2 입력으로서 사용자로부터의 음성 입력이 감지되면, 로봇은 해 당 음성 입력에 기반한 동작을 수행하도록 제어될 수 있다. 예컨대, 로봇의 제어부 또는 로봇 제어 시스템은 음성 입력에 해당하는 자연어를 처리함으로써, 로봇에 대한 명령을 식별할 수 있고, 해당 명령에 따른 동작을 수행하도록 로봇을 제어할 수 있다. 로봇 또는 로봇 제어 시스템은 자연어 처리에 있어서 인공지능 모듈(예컨대, 딥러닝 모듈, 뉴럴 네트워크 모듈, GPT(Chat GPT) 모듈 등)을 이용할 수 있다. 제2 입력이 감지됨에 따라, 제어부 또는 로봇 제어 시스템은 제2 입력과 연관된 타겟 모션을 수행하 거나, 또는 추가적으로 로봇이 상기 제2 입력과 연관된 타겟 정보를 출력하도록, 로봇을 제어할 수 있다. 한편, 도 6은 일 예에 따른, 로봇의 상단부에 마련되는 센서부에 포함된 구성요소들의 로봇의 상단부 내에서의 배치 구조를 나타낸다. 도시된 것처럼, 상단부에는 전술한 터치 센서에 대응하는 터치 센서, 전술한 카메라 및 마이크 에 해당하는 카메라/마이크, 전술한 인디케이터 출력부에 대응하는 LED 및 LCD(또는 메인 시각적 인 디케이터 출력부), 전술한 스피커에 대응하는 스피커, 전술한 컨트롤러에 대응하는 컨트롤러를 포함 할 수 있다. 상단부에서 구성들(510 내지 550)에 해당하는 구성들은 대칭적인 구조로 배치될 수 있다. 터치 센서는 로봇의 상단부(500, 600)의 로봇의 상면에서 로봇의 둘레를 따라서 배치될 수 있다. 인디케이터 출력부는 상기 상면에서 터치 센서가 배치되지 않은 중심 영역에 배치될 수 있다. 즉, 도 6에서처럼, 터치 센서는 상면의 로봇의 상면에서 로봇의 둘레를 따라서 배치되고, LCD(또는 메인 시각적 인디케이터 출력부)는 상면의 중심 영역에 배치될 수 있다. 터치 센서와 인디케이터 출력부의 동작을 제어하는 센서부의 컨트롤러가 터치 센서 또는 인디케이터 출력부의 아래에서 배치될 수 있다. 즉, 도 6에서처럼, 컨트롤러는 터치 센서의 아래에서 배치될 수 있다. 또한, 도 6에서 도시된 것처럼, 카메라는 로봇의 상면에서 로봇의 둘레 영역에서 배치될 수 있 다. 예컨대, 센서부가 포함할 수 있는 카메라는 터치 센서보다 둘레에 더 가깝게 배치될 수 있 고, 하나 또는 복수일 수 있다. 또한, 컨트롤러의 하단에서 하나 또는 복수의 스피커가 배치될 수 있 고, 상단부의 측면에는 적어도 하나의 추가 시각적 인디케이터 출력부(LED, 540)가 더 마련될 수 있다. 인디케이터 출력부 중에서 메인 인디케이터 출력부는, 사용자로부터의 제1 입력에 대응하는 시각적 인디케 이터를 출력하기 위한 구성일 수 있다. 또한, 메인 인디케이터 출력부는 사용자로부터의 제2 입력과 연관된 (시 각적인) 타겟 정보를 출력하기 위한 구성일 수 있다. 한편, 인디케이터 출력부 중에서 추가 인디케이터 출 력부는 보조적인 시각 정보(예컨대, 로봇의 동작 또는 주행 여부, 센서부가 제2 입력을 수신 가능한 상태에 있는지 여부, 로봇이 정상 상태인지 여부 등)를 출력하기 위한 구성일 수 있다. 관련하여, 도 12는 일 예에 따른, 로봇의 상단부에 마련되고 터치 입력을 감지하도록 구성되는 센서부를 나타낸 다. 도시된 것처럼, 로봇의 상단부(500, 600)의 상면에는 복수의 터치 센서들이 배치될 수 있다. 이러한 터치 센서들의 각각은 컨덕티브 센서를 포함할 수 있다. 터치 센서들은 로봇의 상면에서 로봇 의 둘레를 따라서 배치될 수 있다. 터치 센서들의 각각은 와이어를 통해 컨트롤러에 연 결될 수 있다. 컨트롤러는 전술한 컨트롤러에 대응할 수 있다. 컨트롤러에는 센서부에 전원을 공급하기 위한 케이블이 접속되어 있을 수 있다. 컨트롤러는 상단부의 중심 영역에 배치될 수 있 고, 터치 센서들 보다는 아래에 배치될 수 있다. 도 12에서는 설명의 편의상 전술한 메인 인디케이터 출 력부의 도시는 생략되었다. 실시예에서는, 컨덕티브 센서로 구성되는 복수의 터치 센서들이 로봇의 상면의 둘레를 따라 배치됨 으로써, 센서부가 사용자로부터의 터치 입력을 포함하는 제1 입력을 효과적으로 감지할 수 있다. 제1 입력 이 감지됨에 따라 인디케이터 출력부(메인 인디케이터 출력부)는 제1 입력에 대응하는 시각적 인디케이터 를 출력할 수 있다. 아래에서는 도 7을 참조하여, 일 예에 따른, 로봇의 센서부가 터치 입력을 포함하는 제1 입력을 감지하고, 감지 된 제1 입력에 대응하는 정보로서 시각적 인디케이터를 출력하는 방법을 나타낸다. 도 7에서는, 로봇의 상면이 도시되었고, 제1 입력으로서, 제1 터치 입력 및 제 2 터치 입력이 센서부의 터치 센서(510, 1210)를 통해 감지되는 예시가 도시되었다. 도시된 것처럼, 터치 센서는 사용자로부터의 터치 입력(730 또는 740)을 감지하기 위해 로봇의 상면 에 배치될 수 있다. 인디케이터 출력부(메인 인디케이터 출력부)는 (터치 센서(510, 1210)에 대해 입력되는) 터치 입력(730 또 는 740)의 개수, 터치 입력(730 또는 740)이 터치 센서(510, 1210)를 접촉하는 면적 및 터치 입력의 방향에 따 라 변화하는 시각적 인디케이터를 출력하도록 구성될 수 있다. 말하자면, 터치 입력(730 또는 740)에 대응하여 출력되는 시각적 인디케이터의 위치는 터치 입력(730 또는 740)의 위치를 따라 변화하며, 시각적 인디케이터의 크기는 터치 입력(730 또는 740)이 터치 센서(510, 1210)를 접촉하는 면적의 크기를 따라 변화하며(예컨대, 비례 관계), 시각적 인디케이터의 개수는 터치 입 력(730 또는 740)의 개수에 따라 변화할 수 있다. 도 12에서와 같이 제1 터치 입력 및 제 2 터치 입력 에 따라서는 두 개의 시각적 인디케이터가 출력될 수 있다. 한편, 제어부가 구동부 또는 센서부의 동작을 제어하도록 하기 위한 제1 입력을 위한 터치 입력 은 터치 센서(510, 1210)를 소정의 제1 면적 이상 접촉하는 터치 입력이어야 할 수 있다. 말하자면, 일정 크기 이상의 터치 입력만이 제어부가 구동부 또는 센서부의 동작을 제어하도록 하기 위한 명령이 될 수 있다. 시각적 인디케이터의 출력 역시 일정 크기 이상의 터치 입력에 대해서만 수행될 수 있다. 또는, 제어부는, (제1 입력에 포함되는) 터치 입력은 터치 센서를 접촉하는 면적에 따라, 로봇이 상이한 모션을 수행하도록 구동부의 동작을 제어할 수 있다. 말하자면, 제어부는 센서부를 통해 감지되 는 터치 입력의 크기에 따라 로봇을 상이하게 제어하도록 구성될 수 있다. 한편, 제2 입력이 터치 입력을 포함하는 경우에 있어서, 제2 입력에 대응하여서도 시각적 인디케이터와 유 사한 시각적 인디케이터가 출력될 수 있으며, 이에 대해서는 전술한 것과 동일한 설명이 적용될 수 있는 바 중 복되는 설명은 생략한다. 이상 도 1 내지 도 4를 참조하여 전술된 기술적 특징에 대한 설명은, 도 5 내지 도 7 및 도 12에 대해서도 그대 로 적용될 수 있으므로 중복되는 설명은 생략한다. 도 8a 및 도 8b는 일 예에 따른, 로봇의 센서부가 터치 입력을 포함하는 제1 입력을 감지함에 따라, 로봇이 제1 입력의 방향으로 지향되는 방법을 나타낸다. 제어부는 제1 입력에 따라 로봇이 특정한 자세를 취하게 하거나, 로봇이 특정한 위치로 이동하 게 할 수 있으며, 제1 입력이 감지된 방향으로 로봇이 지향하게 하도록 로봇을 제어할 수 있다. 즉, 로봇은 사용자에 의해 터치 입력이 적용된 방향을 향하는 자세를 취할 수 있다. 이 때, 사용자는 로봇 이 자신(또는 자신이 터치한 방향)을 지향하고 있음을 시각적으로 인식할 수 있다. 예컨대, 도 8a 및 도 8b에서 도시된 것처럼, 인디케이터 출력부에는 로봇이 제1 입력의 방향으로 지향되고 있음을 나타내 는 인디케이터가 표시될 수 있다. 일례로, 이러한 인디케이터는 로봇이 지향하는 방향을 나타내는 화살표 이거나, 또는, 제1 입력의 방향을 나타내는 로봇의 눈 또는 표정을 포함할 수 있다. 로봇이 제1 입력의 방향으로 지향되는 것은 로봇의 전방이 제1 입력의 방향을 향하게 되는 것일 수 있다. 로봇의 구조에 따라, 로봇이 전방 및 후방이 구분되지 않는 구조를 갖는 경우, 로봇은 인디케이 터 출력부에 표시되는 인디케이터를 통해, 자신이 제1 입력의 방향을 향해 지향되고 있음을 나타낼 수 있 다(도 8a 참조). 또는, 로봇이 전방 및 후방이 구분되는 구조를 갖는 경우, 로봇은 제1 입력의 방향 으로 전방이 향하도록 자세를 이동하여 제1 입력의 방향으로 지향될 수 있다. 이 때, 인디케이터 출력부에 는 마찬가지로 인디케이터가 표시될 수 있으나, 실시예에 따라서는 인디케이터가 표시되지 않을 수도 있다(도 8a 참조). 주행 중 제1 입력이 감지되는 경우, 로봇은 주행을 정지하고 제1 입력의 방향으로 지향될 수 있다. 사용자는 로봇이 자신(즉, 제1 입력의 방향)을 지향하고 있음을 시각적으로 인식할 수 있게 되는 바, 로봇 과 사용자 간의 인터랙션이 강화될 수 있고, 사용자는 손쉽게 로봇에 대해 후속하는 명령을 입력할 수 있다. 또한, 로봇이 제1 입력의 방향으로 지향하게 되면, 추가로, 스피커를 통해 사운드가 출력되거나, 전 술한 추가 시각적 인디케이터 출력부를 통해 시각적 인디케이터(예컨대, LED 출력 등)가 출력될 수 있다. 예컨 대, 로봇은 사용자를 카메라나 마이크를 통한 음성 입력에 기반하여 인식할 수 있고, 인식된 사 용자에 대해 'OO님 무엇을 도와드릴까요' 등과 같은 음성을 스피커를 통해 출력할 수 있다. 로봇에 의한 답변을 생성하기 위한 자연어 처리에 있어서는 인공지능 모듈(예컨대, 딥러닝 모듈, 뉴럴 네트워크 모듈, GPT(Chat GPT) 모듈 등)이 이용될 수 있다. 또는, 로봇은 주행하는 통로를 인식하여 통로가 일정 폭 이상 좁은 경우에, 카메라나 마이크를 통한 음성 입력에 기반하여 인식된 사용자에 대해 'OO님 지나가도 될까요?' 등과 같은 음성을 스피커를 통 해 출력할 수 있다. 이는 제1 입력이 없는 경우이거나, 제1 입력 이후 일정 시간 이상 사용자로부터의 추가 입 력이 없는 경우에 이루어지는 로봇의 제어 동작의 일 예일 수 있다. 또는, 도 8에서 도시된 것과는 달리, 로봇의 지향은 제1 입력이 감지된 방향이 아니라 제1 입력을 입력한 사용자에 대해 이루어질 수도 있다. 예컨대, 제1 입력이 감지되면 로봇은 카메라를 통해 제1 입력을 입력한 사용자를 인식할 수 있고, 사용자를 향해 지향, 즉, 사용자의 방향으로 지향되도록 제어될 수 있다. 이상 도 1 내지 도 7 및 도 12를 참조하여 전술된 기술적 특징에 대한 설명은, 도 8에 대해서도 그대로 적용될 수 있으므로 중복되는 설명은 생략한다. 도 9a 내지 도 9c는 일 예에 따른, 주행 중인 로봇의 센서부가 터치 입력을 포함하는 제1 입력을 감지함에 따라, 로봇이 미완료된 작업을 다시 수행하게 되는 방법을 나타낸다. 도 9a에서 도시된 것처럼, 로봇의 센서부는 사용자로부터 터치 입력을 포함하는 제1 입력을 감지할 수 있다. 이 때, 로봇은 주행하고 있는 상태일 수 있다. 또한, 로봇은 서비스의 제공을 위한 제1 작 업의 완료를 실패하고(즉, 제1 작업을 완료하지 못하고) 주행하고 있는 상태일 수 있다. 제1 작업의 완료의 실 패는, 예컨대, 로봇이 수거해야 할 택배 또는 화물을 수거하지 못한 것, 또는, 특정 위치 또는 사용자에게 배달해야 할 택배 또는 화물을 배달하지 못한 것일 수 있다. 또는, 제1 작업의 완료의 실패는 기타 로봇이 제공하는 서비스와 연관된 작업의 수행의 실패를 나타낼 수 있다. 도 9b에서 도시된 것처럼, 제1 입력이 감지됨에 따라 로봇은 주행을 정지하고 제1 입력의 방향 또는 사용 자의 방향으로 지향될 수 있다. 이 때, 도 9c에서 도시된 것처럼, 로봇은 상기 미완료된 작업을 수행하도록 제어될 수 있다. 로봇은 제1 입력에 후속하는 제2 입력이 없더라도 상기 미완료된 작업을 수행하도록 제어될 수 있다. 말하자면, 로봇 은 제1 입력이 감지된 때, (제어부에 의한 제어에 따라) 제1 입력이 감지된 방향(또는 사용자의 방향)으로 지향되고, 제1 작업을 다시 수행하도록 제어될 수 있다. 또는, 로봇은 제1 입력에 후속하는 제2 입력이 감지된 때 상기 제1 작업을 다시 수행하도록 제어될 수 있다. 이 때, 제2 입력은 사용자가 센서부 의 터치 센서에 대해 한 번 더 터치 입력을 가하는 것이거나, 음성 명령을 하는 것일 수 있다. 이에 따라, 로봇이 택배 인수나 택배 배달을 위해 사용자 주변으로 왔다가 사용자를 인식하지 못하고 돌아 가는 경우에 있어서도, 사용자 측에서 먼저 로봇에 대해 제1 입력을 가하는 것으로, 로봇이 (사용자 를 다시 인식하여) 사용자에 대한 택배 인수나 택배 배달을 다시 수행하게 할 수 있다. 이상 도 1 내지 도 8 및 도 12를 참조하여 전술된 기술적 특징에 대한 설명은, 도 9에 대해서도 그대로 적용될 수 있으므로 중복되는 설명은 생략한다. 도 10a 및 도 10b는 일 예에 따른, 로봇의 센서부에 대해 터치 입력을 포함하는 제1 입력이 감지되고 후속하는 제2 입력을 감지함에 따라, 로봇이 타겟 모션을 수행하고, 타겟 정보를 출력하는 방법을 나타낸다. 도 10a에서 도시된 것처럼, 로봇의 센서부는 사용자로부터 터치 입력을 포함하는 제1 입력을 감지할 수 있다. 이 때, 로봇은 주행하고 있는 상태일 수 있다. 제1 입력이 감지됨에 따라 로봇은 주행을 정 지하고 제1 입력의 방향(또는 사용자의 방향)으로 지향될 수 있다. 이 때, 로봇의 센서부는 후속하는 제2 입력을 수신하도록 제어될 수 있다. 도 10b에서 도시된 것처럼, 센서부는 제1 입력에 후속하는 제2 입력을 감지할 수 있고, 그에 따라, 로봇 은 제2 입력과 연관된 타겟 모션을 수행하거나, 또는 추가적으로 로봇이 상기 제2 입력과 연관된 타 겟 정보를 출력할 수 있다. 또는, 전술한 바와 같이, 로봇이 제1 입력을 감지하기 전에 제1 작업을 미완료한 상태로 주행하고 있는 경 우라면, 제2 입력이 감지됨에 따라, 로봇은 제1 작업을 다시 수행하도록 제어될 수 있다. 실시예에 따라서는, 제2 입력은 복수일 수 있다. 일례로, 제2 입력들은 소정의 순서나 패턴을 갖고 사용자에 의 해 입력되는 것일 수 있다. 복수의 제2 입력들이 소정의 순서 또는 패턴으로 사용자에 의해 입력됨에 따라, 제어부는, 로봇이 제 2 입력들과 연관된 타겟 모션을 수행하거나, 로봇이 제2 입력들과 연관된 타겟 정보를 출력하도록, 로봇을 제어할 수 있다. 이 때, 타겟 모션 또는 타겟 정보는 사용자가 로봇을 통해 수행하는 게임과 연관된 것일 수 있다. 한편, 제1 입력은 이러한 게임을 시작하기 위한 로봇에 대한 입력이 될 수 있다. 또는 제1 입력 이 감지된 후 적어도 한 번의 후속하는 제2 입력이 게임을 시작하기 위한 로봇에 대한 입력이 될 수도 있 다. 로봇은 사용자와 진행할 게임과 관련하여, 입력되어야 할 제2 입력들의 소정의 패턴, 순서 및 횟수 중 적 어도 하나에 대한 가이드 정보를 전술한 인디케이터 출력부에 출력할 수 있다. 사용자는 이러한 가이드 정 보를 인식한 후 터치 센서에 제2 입력들을 입력함으로써 로봇과 게임을 진행할 수 있다. 사용자에 의해 입 력된 제2 입력들이 소정의 패턴, 순서 및 횟수 중 적어도 하나에 매칭됨에 따라 로봇에 의해 수행되는 타 겟 모션이나 제공되는 타겟 정보는, 사용자가 수행하는 게임과 관련된 사용자에게 제공되는 보상일 수 있다. 이에 따라, 로봇과 사용자 간의 인터랙션이 더욱 강화될 수 있다. 이상 도 1 내지 도 9 및 도 12를 참조하여 전술된 기술적 특징에 대한 설명은, 도 10에 대해서도 그대로 적용될 수 있으므로 중복되는 설명은 생략한다. 도 11은 일 실시예에 따른, 사용자로부터의 터치 입력을 포함하는 제1 입력과 거기에 후속하는 제2 입력에 기반 하여 로봇을 제어하는 방법을 나타낸다. 도 11을 참조하여, 공간 내에서 이동하는 로봇 또는 로봇을 제어하는 로봇 제어 시스템에 의해 수행되는, 로봇 제어 방법에 대해 더 자세하게 설명한다. 단계에서, 로봇의 센서부는 터치 입력을 포함하는 제1 입력을 감지할 수 있다. 단계에서, 로봇의 제어부는 감지된 제1 입력에 기반하여, 로봇이 특정한 모션을 수행하도 록 로봇의 구동부의 동작을 제어할 수 있다. 또는/추가적으로, 제어부는 감지된 제1 입력에 후 속하는 사용자로부터의 제2 입력을 감지하도록 센서부의 동작을 제어할 수 있다. 예컨대, 제1 입력이 감지됨에 따라, 로봇은 제1 입력의 방향으로 지향되거나, 제1 입력을 입력한 사용자를 인식하여 해당 인식된 사용자의 방향으로 지향될 수 있다. 단계에서, 로봇의 제어부는 로봇의 인디케이터 출력부를 통해, 제1 입력이 포함하는 터치 입력의 개수, 제1 입력이 포함하는 터치 입력이 터치 센서를 접촉하는 면적 및 터치 입력의 방향에 따라 변화하 는 시각적 인디케이터를 출력할 수 있다. 단계에서, 로봇의 센서부는 제2 입력을 감지할 수 있다. 이 때, 센서부는 전술한 단계 에 의해 제2 입력을 감지하도록 동작이 제어된 것일 수 있다. 제2 입력은 제1 입력에 후속하는 입력으로 서, 터치 입력 및 음성 입력 중 적어도 하나를 포함할 수 있다. 단계에서, 로봇의 제어부는 제2 입력에 기반하여 로봇이 타겟 모션을 수행하거나 또는/추 가적으로 타겟 정보를 출력하도록 로봇을 제어할 수 있다. 단계들(1110 내지 1140)과 관련하여서는, 도 1 내지 도 10 및 도 12를 참조하여 전술한 내용이 동일하게 적용될 수 있다. 이상 도 1 내지 도 10 및 도 12를 참조하여 전술된 기술적 특징에 대한 설명은, 도 11에 대해서도 그대로 적용 될 수 있으므로 중복되는 설명은 생략한다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 소프트웨어 구성요소 또는 하드웨어 구성요소 및 소프 트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크 로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명 령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목 적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이 상의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto- optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드 뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2023-0137063", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9a 도면9b 도면9c 도면10a 도면10b 도면11 도면12"}
{"patent_id": "10-2023-0137063", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른, 사용자로부터의 터치 입력을 포함하는 입력을 감지하기 위한 센서부가 상단부에 마련 된 로봇과 그 제어 방법을 나타낸다. 도 2는 일 실시예에 따른, 공간 내에서 이동하는 로봇을 나타내는 블록도이다. 도 3 및 도 4는 일 실시예에 따른, 로봇을 제어하는 로봇 제어 시스템을 나타내는 블록도이다. 도 5는 일 예에 따른, 로봇의 상단부에 마련되는 사용자로부터의 터치 입력을 포함하는 입력을 감지하기 위한 센서부를 포함하는 로봇의 상단부를 나타내는 블록도이다. 도 6은 일 예에 따른, 로봇의 상단부에 마련되는 센서부에 포함된 구성요소들의 로봇의 상단부 내에서의 배치 구조를 나타낸다. 도 7은 일 예에 따른, 로봇의 센서부가 터치 입력을 포함하는 제1 입력을 감지하고, 감지된 제1 입력에 대응하 는 정보를 출력하는 방법을 나타낸다. 도 8a 및 도 8b는 일 예에 따른, 로봇의 센서부가 터치 입력을 포함하는 제1 입력을 감지함에 따라, 로봇이 제1 입력의 방향으로 지향되는 방법을 나타낸다. 도 9a 내지 도 9c는 일 예에 따른, 주행 중인 로봇의 센서부가 터치 입력을 포함하는 제1 입력을 감지함에 따라, 로봇이 미완료된 작업을 다시 수행하게 되는 방법을 나타낸다. 도 10a 및 도 10b는 일 예에 따른, 로봇의 센서부에 대해 터치 입력을 포함하는 제1 입력이 감지되고 후속하는 제2 입력을 감지함에 따라, 로봇이 타겟 모션을 수행하고, 타겟 정보를 출력하는 방법을 나타낸다. 도 11은 일 실시예에 따른, 사용자로부터의 터치 입력을 포함하는 제1 입력과 거기에 후속하는 제2 입력에 기반 하여 로봇을 제어하는 방법을 나타낸다. 도 12는 일 예에 따른, 로봇의 상단부에 마련되고 터치 입력을 감지하도록 구성되는 센서부를 나타낸다."}
