{"patent_id": "10-2022-0189350", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0106478", "출원번호": "10-2022-0189350", "발명의 명칭": "텍스트-수어 병렬 코퍼스 취득 방법 및 이를 위한 수어영상 전처리 기능을 가지는 수어영상", "출원인": "주식회사 이큐포올", "발명자": "이두희"}}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "텍스트-수어 병렬 코퍼스 취득 방법으로서,텍스트 문장에 대응하는 수어영상을 전처리하는 전처리 과정 및 전처리된 상기 수어영상을 분석하는 분석과정을포함하고,상기 전처리 과정은,수어영상 수신부에 수신되는 상기 수어영상을 수어형태소별로 구획하여 단편화하고 단편화된 상기 수어영상의프레임들에 대한 구조화 데이터를 생성하는 수어영상 단편화단계; 및단편화된 상기 수어영상의 신체 영역을 측정하여 미리 정해진 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구조화 데이터를 생성하는 정규화단계를 포함하고,상기 분석과정은,정규화된 상기 프레임들에서 ROI를 취득하는 ROI 취득단계; 및상기 ROI에서의 구간별 모션데이터를 분석하여 상기 수어형태소들에 대응하는 상기 프레임들의 요소 데이터를생성하여 저장하는 모션데이터 분석단계를 포함하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 수어영상 단편화단계 전에, 수신된 상기 수어영상의 데이터를 변환하여 상기 수어영상의해상도를 증가시키는 해상도 변환단계 및 상기 해상도 변환단계에서 변환된 상기 수어영상의 데이터에서 노이즈를 제거하는 노이즈 제거단계를 수행하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 ROI 취득단계는 상기 수어영상 속 수어 발화자의 신체 부위에 따라 구분된 복수의 ROI를취득하는 것을 포함하고,상기 모션데이터 분석단계는 취득된 복수의 상기 ROI에서의 움직임을 각각 분석하여 상기 ROI별로 구분된, 상기구간별 구조화 데이터를 가지는 프레임별 요소 데이터를 생성하여 저장하는 것을 포함하는 것을 특징으로 하는텍스트-수어 병렬 코퍼스 취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 ROI 취득단계는 상기 수어영상 속 수어 발화자의 손의 움직임에 대한 정보를 얻기 위한영역에 대한 핸드 제스쳐 ROI, 상반신의 움직임에 대한 정보를 얻기 위한 영역에 대한 상반신 ROI 및 머리움직임, 얼굴 움직임 또는 입 움직임에 대한 정보를 얻기 위한 영역에 대한 머리 ROI를 취득하는 것을 포함하고,상기 모션데이터 분석단계는, 상기 핸드 제스쳐 ROI에서의 핸드 제스쳐를 분석하여 수지 신호 및 비수지 핸드제스쳐에 대한 프레임별 수지 및 핸드 요소 데이터를 생성하고, 상기 상반신 ROI에서의 상반신의 움직임을 분석하여 상반신의 움직임에 대한 프레임별 상반신 요소 데이터를 생성하고, 상기 머리 ROI에서의 머리움직임, 얼굴움직임 또는 입 움직임을 분석하여 머리움직임, 얼굴 움직임 또는 입 움직임에 대한 프레임별 머리 요소 데이터를 생성하는 것을 포함하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 핸드 제스쳐 ROI에서의 핸드 제스쳐를 분석하여 상기 수어형태소별 왼손과 오른손의 시작지점과 끝 지점 및 상기 수어영상에서의 왼손과 오른손의 주요 동작영역에 대한 데이터를 추출하여 검색보조 데이터로 저장하는 검색보조 데이터 추출단계를 포함하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득방법.공개특허 10-2024-0106478-3-청구항 6 제1항에 있어서, 상기 수어영상 단편화단계는 수어형태소 영상이 저장된 수어형태소 영상데이터베이스를 통해학습한 수어영상의 단편화에 특화된 인공지능 프로그램을 이용하여 상기 수어영상의 각각의 형태소의 시작 프레임과 끝 프레임을 찾아내어 상기 수어영상에 대한 단편화를 수행하고,상기 분석과정 전에, 상기 구간별 구조화 데이터에서 상기 수어영상 속 수어 발화자에 따른 개별 특성을 제거하여 익명화하는 익명화단계를 수행하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 텍스트 문장에 대응하는 수어동작을 촬영하여 상기 수어영상을 생성하는 촬영단계; 및촬영된 상기 수어영상을 저장수단에 저장하는 저장단계를 포함하고,상기 촬영단계는 상기 수어동작을 하는 수어 발화자의 정면에서 촬영하는 제1카메라, 상기 수어 발화자의 정면방향에 대해 오른쪽으로 45도~60도인 오른쪽 전방 위치에서 촬영하는 제2카메라 및 상기 수어 발화자의 정면 방향에 대해 왼쪽으로 45도~60도인 왼쪽 전방 위치에서 촬영하는 제3카메라에 의해 수행되고,상기 저장단계는 상기 제1카메라~제3카메라에서 촬영된 수어영상의 데이터를 별도로 각각 저장하되, 동일한 수어임을 나타내는 정보와 촬영각도에 대한 정보를 함께 저장하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 텍스트 문장의 데이터와 상기 수어영상의 데이터 및 상기 수어영상에 대응하는 상기 프레임별 요소 데이터를 주석시스템의 디스플레이에 주석 GUI로 표시하고, 주석자가 상기 주석 GUI를 보면서 상기주석 GUI 상에서 상기 형태소들에 각각 대응하는 상기 프레임별 요소 데이터의 구간을 수정하여 저장하는 주석단계를 포함하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서, 상기 텍스트 문장의 데이터와 상기 수어영상의 데이터 및 상기 수어영상에 대응하는 상기 프레임별 요소 데이터를 주석시스템의 디스플레이에 주석 GUI로 표시하고, 주석자가 상기 주석 GUI를 보면서 상기주석 GUI 상에서 상기 형태소들에 각각 대응하는 상기 프레임별 요소 데이터의 구간을 수정하여 저장하는 주석단계를 포함하되,상기 주석 GUI에, 상기 모션데이터 분석단계에서 분석된 상기 프레임별 핸드 요소 데이터에서 상기 수어형태소별 왼손과 오른손의 시작 지점과 끝 지점 및 상기 수어영상에서의 왼손과 오른손의 주요 동작영역에 대한 데이터를 추출하여 수정된 상기 프레임별 요소 데이터에 포함하여 저장하고, 상기 수어형태소별 왼손과 오른손의 시작 지점과 끝 지점, 상기 수어영상의 왼손 및 오른손의 주요 동작영역을 표시하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득 방법."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "수어영상 수신부에 수신되는 수어영상을 수어형태소별로 구획하여 단편화하고 단편화된 상기 수어영상의 프레임들에 대한 구조화 데이터를 생성하기 위한 수어영상 단편화부;단편화된 상기 수어영상의 신체 영역을 측정하여 미리 정해진 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구조화 데이터를 생성하기 위한 정규화부;정규화된 상기 프레임들에서 ROI를 취득하는 ROI 취득부; 및상기 ROI에서의 구간별 모션데이터를 분석하여 상기 형태소들에 대응하는 상기 프레임들의 요소 데이터를 생성하는 모션데이터 분석부를 포함하는 것을 특징으로 하는 텍스트-수어 병렬 코퍼스 취득을 위한 수어영상 전처리기능을 가지는 수어영상 분석 시스템."}
{"patent_id": "10-2022-0189350", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 ROI 취득부는 상기 수어영상 속 수어 발화자의 신체 부위에 따라 구분된 복수의 ROI를공개특허 10-2024-0106478-4-취득하도록 구성되고,상기 모션데이터 분석부는 취득된 복수의 상기 ROI에서의 움직임을 각각 분석하여 상기 ROI별로 구분된 프레임별 요소 데이터를 생성하도록 구성된 것을 포함하는 것을 특징으로 하는 텍스트-수어 인공지능 번역엔진용 텍스트-수어 병렬 코퍼스 취득을 위한 수어영상 전처리 기능을 가지는 수어영상 분석 시스템."}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "저품질의 수어영상을 이용하여 고품질의 병렬 코퍼스를 얻을 수 있도록 해주고, 주석 시의 작업시간을 단축할 수 있도록 해주며, 높은 정확도로 비수지 신호에 대한 검수 및 수정을 할 수 있게 해주는 텍스트-수어 병렬 코퍼스 취득 방법이 개시된다. 상기 방법은 수어영상을 수어형태소별로 구획하여 단편화하고 단편화된 수어영상의 프레 임들에 대한 구조화 데이터를 생성하는 수어영상 단편화단계 및 단편화된 수어영상의 신체 영역을 측정하여 미리 정해진 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구조화 데이터를 생성하는 정규화단 계를 포함하는 전처리 과정과, 정규화된 프레임들에서 ROI를 취득하는 ROI 취득단계 및 ROI에서의 구간별 모션데 이터를 분석하여 수어형태소들에 대응하는 프레임들의 요소 데이터를 생성하여 저장하는 모션데이터 분석단계를 포함하는 분석과정을 포함하는 구성을 한다."}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 수어 관련 병렬 코퍼스(corpus) 취득에 관련된 것으로, 특히, 텍스트-수어 인공지능 번역엔진용 텍스 트-수어 병렬 코퍼스 취득에 적합하게 사용될 수 있는 방법 및 이를 위한 수어영상 전처리 기능을 가지는 수어 영상 분석 시스템에 관한 것이다."}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "한국어와 한국수어는 청각과 시각과 같이 각각 다른 감각 기관을 사용하는 언어이다. 시각언어인 한국수어에서 는 동시성이라는 특성을 가지게 되는데 동시성이란 단어를 순서대로 나열하는 형식이 아니라 한 공간에서 동시 에 발화하는 특성을 말한다. 이는 여타 국가의 수어에서도 마찬가지이다. 예를 들어, 한국어는 순서대로 '나는 산에 올랐다.'와 같이 순차적으로 표현이 된다면, 한국수어 등에서는 마치 그림이나 영상과 같이 한 공간에 산 및 산을 오르는 사람을 동시에 발화하게 된다. 시각적이고 동시에 발화되는 언어의 특성상, 수어에는 비수지 신 호가 반드시 들어가야 하는데, 그 이유는 수지 신호와 함께 사용되는 비수지 신호가 형용사, 부사, 의문사, 긍/ 부정 등의 여러 의미로 사용되기 때문이다. 비수지 신호는 음성언어에서의 억양, 강세, 리듬과 같은 역할을 하 며, 정서적인 정보의 구체적인 표현을 하기도 한다. 또한 부사의 기능을 하며 공손의 표현을 나타내기도 한다. 수어에서 비수지 신호는 수지 신호와 결합하여 사용되며 대체적으로 단일의 움직임보다 여러 신체부위의 움직임 을 복합적으로 사용한다. 또한 사람마다 같은 문장을 보고 떠올리는 이미지가 다르듯이 같은 수지를 사용하더라 도 생각하는 이미지마다 표현되는 비수지 신호는 다를 수 있다. 결합 형태가 다른 모든 종류의 비수지 신호를 특정할 수 없으니 분류하는 것 역시 불가능한 데, 이는 앞으로 표준화 등을 통해 해결해 나가야 할 문제이다. 비수지 신호를 세부적으로 분석하기 위해 신체부위 및 움직임으로 구분을 할 수는 있지만 구분된 움직임 하나하 나가 특정한 의미가 있다고 판단하기 어려운 부분이 있다. 비수지 신호가 사용된 예를 몇 가지 살펴보면 다음과 같다. 1. 비수지 신호가 형용사/부사로 사용된 예 한국어 문장인 '매우 많은 비가 내린다.'는 품사를 기준으로 '매우'는 부사, '많다'는 형용사로 분석할 수 있다. 위 문장의 의미를 한국수어로 표현하게 된다면 '비가 내린다'에 해당하는 수지와 '매우'(부사)와 '많다' (형용사)에 해당하는 비수지가 함께 사용된다. 해당 문장에서의 비수지는 제시된 리스트 기준 '얼굴-볼-볼을 부 풀리기', '얼굴-눈썹-내리기', '얼굴-눈-가늘게 뜨기'가 사용될 수 있다. 하지만 문장에서 비의 양, 강도, 방향, 발화자마다의 전하고자 하는 의도(위험, 긍정, 부정 등)에 따라 다양한 비수지 신호가 결합하거나 제외될 수 있다. 2. 비수지 신호가 의문/평서문으로 사용된 예 한국수어에서 '학교 갔어?'와 '학교 갔어.'는 비수지 신호 사용의 차이만을 가지고 발화할 수 있다. '학교 갔어'에 해당하는 수지에 '머리와 신체의 움직임-머리-끄덕이기'를 사용하면 평서문이 되고, '얼굴-눈썹-올리기', '얼굴-눈-크게 뜨기', '머리와 신체의 움직임-머리-끄덕이기'를 사용하면 의문문이 된다. 3. 비수지 신호와 수지 신호가 결합 되어있는 예 한국수어에서 '가능하다, 할 수 있다' 등의 의미가 있는 수어는 '마우스액션-입-벌리기'와 함께 사용되는 데 해 당 어휘와 비수지 신호의 관계가 매우 뚜렷하여 간혹 대화의 흐름에서 '마우스액션-입-벌리기'가 단독으로 쓰여 도 동일한 의미가 있을 수 있다. 같은 예시로 '거짓'을 의미하는 수지 신호와 '마우스액션-볼로 혀 내밀기'에서 비수지 신호가 단독으로 쓰일 수 있다. 따라서 농인과 청인 간의 의사소통 및 한국어-한국수어 등의 텍스트-수어 자동번역을 위한 인공지능 번역엔진을 개발하기 위해서는 대규모 병렬 코퍼스(예: 한국어-한국수어)가 필요하다. 대규모 병렬 코퍼스를 생성하기 위한 종래기술로는 공개번호 10-2021-0138311호(발명의 명칭: 언어 및 수어의 병렬 말뭉치 데이터의 생성 장치 및 방 법, 발명자: 최지훈 외 2, \"이하, 최지훈 등의 발명이라 함\")의 공개특허공보에 개시된 것이 있다. 최지훈 등의 발명은, 수어 모션 특징점과 수어 표제어를 대응시킨 수어 모션 리스트 및 수어영상의 분리된 자막 과 수어 표제어를 대응시킨 매핑 테이블을 이용하여 수어 모션 리스트와 매핑 테이블에 포함된 수어 표제어들의 유사도를 분석하여 최종 수어 표제어, 분리된 모션 특징점 및 분리된 자막이 상호 대응하도록 최종 수어 표제어 리스트를 생성하고 이에 기초하여 수어 말뭉치 데이터를 생성하는 것에 대한 것이다. 위와 같은 최지훈 등의 발명은, 수어 관련 병렬 코퍼스를 대량으로 만들 수는 있지만, 수어 관련 병렬 코퍼스의 생성에 존재하는 다음과 같은 문제점들을 해결하지는 못한다. 수어 관련 병렬 코퍼스에 다른 언어 간의 병렬 코퍼스보다 구조가 복잡하고 다양한 항목들이 존재함에 따라 말 뭉치 주석, 검수 과정에 많은 인원 및 시간이 소요된다는 문제점이 있다. 또한, 수어 관련 병렬 코퍼스는 다른 언어의 병렬 코퍼스와는 다르게 시간을 기준으로 수어문법과 관련된 항목 주석, 3D 공간정보 주석, 손 움직임 주석, 얼굴 표정 주석, 몸 움직임 주석 등 다양한 주석 항목들을 포함하고 있다. 특히, 수어 문법 측면에서 중요한 역할을 담당하고 있는 비수지(얼굴 표정, 상체 움직임 등) 신호에 대한 주석 및 검수 과정의 복잡함은 주석 및 검수에 다른 요소 대비 2.5~3배 정도의 시간이 있어야 하는 문제점이 있 다. 이는 대규모 병렬 코퍼스 구축 시의 대표적인 비효율 요소이다. 또한, 병렬 코퍼스 구축 시 수어영상의 품질은 병렬 코퍼스 품질을 좌우할 수 있는 중요한 부분인데, 기존의 병 렬 코퍼스 내 수어영상은 촬영 방법의 비표준화로 인해 품질이 떨어져 고품질의 텍스트-수어 병렬 코퍼스 구축 에 재활용하기가 어렵다는 문제점이 있다. 저품질의 수어영상은 자동 비수지 신호 추출뿐만 아니라 수동 비수지 신호 주석 시에도 낮은 정확도 및 추가 수정 사항을 발생시키고, 이는 추가 공수로 이어질 뿐만 아니라 저수준 의 결과물을 생산할 확률을 높인다."}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 고품질의 텍스트-수어 병렬 코퍼스, 예를 들어, 한국어 텍스트-수어 병렬 코퍼스를 대량으로 생성할 수 있는 텍스트-수어 병렬 코퍼스 취득 방법 및 이를 위한 수어영상 전처리 기능을 가지는 수어영상 분 석 시스템을 제공하는 데 있다. 본 발명의 다른 목적은 비수지 신호에 대한 주석 시의 작업시간 감소 및 높은 정확도를 달성할 수 있도록 해주 는 텍스트-수어 병렬 코퍼스 취득 방법 및 이를 위한 수어영상 전처리 기능을 가지는 수어영상 분석 시스템을 제공하는 데 있다. 본 발명의 또 다른 목적은 텍스트-수어 병렬 코퍼스를 신규로 구축하는 데 활용할 수 있을 뿐만 아니라 기존 저 품질의 병렬 코퍼스를 재활용하여 고품질의 병렬 코퍼스를 구축할 수 있도록 해주는 텍스트-수어 병렬 코퍼스 취득 방법 및 이를 위한 수어영상 전처리 기능을 가지는 수어영상 분석 시스템을 제공하는 데 있다. 본 발명의 또 다른 목적은 검색성이 뛰어나 애니메이션 생성 시간을 단축할 수 있는 텍스트-수어 병렬 코퍼스 취득 방법 및 이를 위한 수어영상 전처리 기능을 가지는 수어영상 분석 시스템을 제공하는 데 있다."}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 텍스트-수어 병렬 코퍼스 취득 방법은 텍스트-수어 병렬 코퍼스 취득 방법으로서, 텍스트 문장 에 대응하는 수어영상을 전처리하는 전처리 과정 및 전처리된 상기 수어영상을 분석하는 분석과정을 포함하고, 상기 전처리 과정은, 수어영상 수신부에 수신되는 상기 수어영상을 수어형태소별로 구획하여 단편화하고 단편화 된 상기 수어영상의 프레임들에 대한 구조화 데이터를 생성하는 수어영상 단편화단계; 및 단편화된 상기 수어영 상의 신체 영역을 측정하여 미리 정해진 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구 조화 데이터를 생성하는 정규화단계를 포함하고, 상기 분석과정은, 정규화된 상기 프레임들에서 ROI를 취득하는 ROI 취득단계; 및 상기 ROI에서의 구간별 모션데이터를 분석하여 상기 수어형태소들에 대응하는 상기 프레임들 의 요소 데이터를 생성하여 저장하는 모션데이터 분석단계를 포함하는 구성을 한다. 상기 수어영상 단편화단계 전에, 수신된 상기 수어영상의 데이터를 변환하여 상기 수어영상의 해상도를 증가시 키는 해상도 변환단계 및 상기 해상도 변환단계에서 변환된 상기 수어영상의 데이터에서 노이즈를 제거하는 노 이즈 제거단계를 수행하는 것이 바람직하다. 상기 ROI 취득단계는 상기 수어영상 속 수어 발화자의 신체 부위에 따라 구분된 복수의 ROI를 취득하는 것을 포 함하고, 상기 모션데이터 분석단계는 취득된 복수의 상기 ROI에서의 움직임을 각각 분석하여 상기 ROI별로 구분 된, 상기 구간별 구조화 데이터를 가지는 프레임별 요소 데이터를 생성하여 저장하는 것을 포함하는 것이 좋다. 상기 ROI 취득단계는 상기 수어영상 속 수어 발화자의 손의 움직임에 대한 정보를 얻기 위한 영역에 대한 핸드 제스쳐 ROI, 상반신의 움직임에 대한 정보를 얻기 위한 영역에 대한 상반신 ROI 및 머리움직임, 얼굴 움직임 또 는 입 움직임에 대한 정보를 얻기 위한 영역에 대한 머리 ROI를 취득하는 것을 포함하고, 상기 모션데이터 분석 단계는, 상기 핸드 제스쳐 ROI에서의 핸드 제스쳐를 분석하여 수지 신호 및 비수지 핸드 제스쳐에 대한 프레임 별 수지 및 핸드 요소 데이터를 생성하고, 상기 상반신 ROI에서의 상반신의 움직임을 분석하여 상반신의 움직임 에 대한 프레임별 상반신 요소 데이터를 생성하고, 상기 머리 ROI에서의 머리움직임, 얼굴 움직임 또는 입 움직 임을 분석하여 머리움직임, 얼굴 움직임 또는 입 움직임에 대한 프레임별 머리 요소 데이터를 생성하는 것을 포 함하는 것이 바람직하다. 상기 핸드 제스쳐 ROI에서의 핸드 제스쳐를 분석하여 상기 수어형태소별 왼손과 오른손의 시작 지점과 끝 지점 및 상기 수어영상에서의 왼손과 오른손의 주요 동작영역에 대한 데이터를 추출하여 검색보조 데이터로 저장하는 검색보조 데이터 추출단계를 포함하는 것이 좋다. 상기 수어영상 단편화단계는 수어형태소 영상이 저장된 수어형태소 영상데이터베이스를 통해 학습한 수어영상의 단편화에 특화된 인공지능 프로그램을 이용하여 상기 수어영상의 각각의 형태소의 시작 프레임과 끝 프레임을 찾아내어 상기 수어영상에 대한 단편화를 수행하고, 상기 분석과정 전에, 상기 구간별 구조화 데이터에서 상기 수어영상 속 수어 발화자에 따른 개별 특성을 제거하여 익명화하는 익명화단계를 수행하는 것이 바람직하다. 상기 텍스트 문장에 대응하는 수어동작을 촬영하여 상기 수어영상을 생성하는 촬영단계; 및 촬영된 상기 수어영 상을 저장수단에 저장하는 저장단계를 포함하고, 상기 촬영단계는 상기 수어동작을 하는 수어 발화자의 정면에 서 촬영하는 제1카메라, 상기 수어 발화자의 정면 방향에 대해 오른쪽으로 45도~60도인 오른쪽 전방 위치에서 촬영하는 제2카메라 및 상기 수어 발화자의 정면 방향에 대해 왼쪽으로 45도~60도인 왼쪽 전방 위치에서 촬영하 는 제3카메라에 의해 수행되고, 상기 저장단계는 상기 제1카메라~제3카메라에서 촬영된 수어영상의 데이터를 별 도로 각각 저장하되, 동일한 수어임을 나타내는 정보와 촬영각도에 대한 정보를 함께 저장하는 것이 좋다. 상기 텍스트 문장의 데이터와 상기 수어영상의 데이터 및 상기 수어영상에 대응하는 상기 프레임별 요소 데이터 를 주석시스템의 디스플레이에 주석 GUI로 표시하고, 주석자가 상기 주석 GUI를 보면서 상기 주석 GUI 상에서 상기 형태소들에 각각 대응하는 상기 프레임별 요소 데이터의 구간을 수정하여 저장하는 주석단계를 포함하는 것이 바람직하다. 상기 텍스트 문장의 데이터와 상기 수어영상의 데이터 및 상기 수어영상에 대응하는 상기 프레임별 요소 데이터 를 주석시스템의 디스플레이에 주석 GUI로 표시하고, 주석자가 상기 주석 GUI를 보면서 상기 주석 GUI 상에서 상기 형태소들에 각각 대응하는 상기 프레임별 요소 데이터의 구간을 수정하여 저장하는 주석단계를 포함하되, 상기 주석 GUI에, 상기 모션데이터 분석단계에서 분석된 상기 프레임별 핸드 요소 데이터에서 상기 수어형태소 별 왼손과 오른손의 시작 지점과 끝 지점 및 상기 수어영상에서의 왼손과 오른손의 주요 동작영역에 대한 데이 터를 추출하여 수정된 상기 프레임별 요소 데이터에 포함하여 저장하고, 상기 수어형태소별 왼손과 오른손의 시 작 지점과 끝 지점, 상기 수어영상의 왼손 및 오른손의 주요 동작영역을 표시하는 것이 바람직하다. 본 발명에 따른 텍스트-수어 병렬 코퍼스 취득을 위한 수어영상 전처리 기능을 가지는 수어영상 분석 시스템은 수어영상 수신부에 수신되는 수어영상을 수어형태소별로 구획하여 단편화하고 단편화된 상기 수어영상의 프레임 들에 대한 구조화 데이터를 생성하기 위한 수어영상 단편화부; 단편화된 상기 수어영상의 신체 영역을 측정하여 미리 정해진 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구조화 데이터를 생성하기 위 한 정규화부; 정규화된 상기 프레임들에서 ROI를 취득하는 ROI 취득부; 및 상기 ROI에서의 구간별 모션데이터를 분석하여 상기 형태소들에 대응하는 상기 프레임들의 요소 데이터를 생성하는 모션데이터 분석부를 포함하는 구 성을 한다. 상기 ROI 취득부는 상기 수어영상 속 수어 발화자의 신체 부위에 따라 구분된 복수의 ROI를 취득하도록 구성되 고, 상기 모션데이터 분석부는 취득된 복수의 상기 ROI에서의 움직임을 각각 분석하여 상기 ROI별로 구분된 프 레임별 요소 데이터를 생성하도록 구성된 것을 포함하는 것이 바람직하다."}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 저품질의 수어영상을 이용하여 고품질의 텍스트-수어 병렬 코퍼스를 대량으로 생성할 수 있 다. 본 발명에 따른 수어영상 전처리 과정을 거친 영상 데이터 및 구조화 데이터는 비수지 신호에 대한 주석 시의 작업시간을 단축할 수 있도록 해주고 높은 정확도로 비수지 신호에 대한 검수 및 수정을 할 수 있게 해준다. 본 발명에 따르면, 텍스트-수어 병렬 코퍼스를 신규로 구축할 수 있을 뿐만 아니라 기존의 병렬 코퍼스를 재활 용하여 고수준의 병렬 코퍼스를 생성할 수도 있다. 기존에 보유하고 있는 한국어-수어 병렬 코퍼스 내 수어영상 을 전처리하여 고품질의 수어영상으로 변환하고, 변환된 수어영상에서 비수지 신호에 해당하는 데이터를 추출하 여 자동 비수지 신호 분석 처리에 활용할 수 있다. 본 발명에 따른 텍스트-수어 병렬 코퍼스 취득 방법에 따른 전처리 및 분석과정을 거친 후에는 인공지능 기반의 3D 키포인트 예측 기술을 사용할 수 있어서 비수지 신호에 대한 주석 시 작업시간 감소 및 정확도를 높일 수 있 다."}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참고하여 본 발명의 바람직한 실시 예를 상세하게 설명한다. 도 1은 본 발명에 따른 수어영상 전처리 기능을 가지는 수어영상 분석 시스템의 구성도이고, 도 2는 도 1 시스 템에서의 수어영상에 대한 전처리 및 분석과정을 설명하기 위한 블록도, 도 3은 수어영상에 대한 주요 전처리 및 분석과정의 흐름도이다. 도 1에 나타낸 바와 같이 본 발명에 따른 수어영상 전처리 기능을 가지는 수어영상 분석 시스템은 하드디 스크, SSD 등의 보조기억장치에 설치된 운영체제(OS) 및 수어영상 전처리 소프트웨어와 분석 소프트 웨어를 갖추고 있다. 수어영상 전처리 소프트웨어로는 처리하기 위한 수어영상을 수신하기 위한 수어영상 수신부, 수신되 는 영상이 수어영상인지를 판단하기 위한 수어영상 판단부, 노이즈 저감을 위한 수어용 노이즈저감 처리부 , 수어영상을 형태소별로 구분하기 위한 수어영상 단편화부, 수어영상의 익명화를 위한 수어영상 익 명화 처리부, 수어영상의 해상도는 고해상도로, 바람직하게 초고해상도로 변환하기 위한 수어영상 해상도 변환부 및 수어영상의 신체 영역을 측정하여 이전 단계에서 정해지거나 설정된 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구조화 데이터를 생성하기 위한 수어 정규화 처리부가 설치된다. 수어영상 해상도 변환부로는 도 2에 나타낸 바와 같이 수어영상을 초고해상도로 변환하기 위한 초고해상도수어영상 변환부(126′)를 이용하는 것이 바람직하다. 분석 소프트웨어로는 얼굴 분석부, 마우스액션 분석부, 비수지(NMS) 강세 및 반복수 분석부 , 머리움직임 분석부, 상반신움직임 분석부, 핸드제스쳐 분석부 및 ROI 취득부가 설 치된다. 이들에 대해서는 뒤에서 도 2와 도 3을 참조하여 더 자세히 설명한다. 필요에 따라 여타 분석부들이 더 추가될 수 있음은 물론이다. 본 발명에 따른 수어영상 전처리 기능을 가지는 수어영상 분석 시스템은 수어영상 전처리 소프트웨어 및 분석 소프트웨어의 작동에 필요한 데이터가 저장되어 있거나 수어영상 전처리 소프트웨어 및 분석 소프트웨어에서 처리한 데이터가 저장되는 데이터베이스들을 구비한다. 본 발명에 따른 수어영상 전처리 기능을 가지는 수어영상 분석 시스템에 필요한 데이터베이스로는 수어영 상의 데이터가 저장된 수어영상 데이터베이스, 수어영상에 대응하는 한글 등의 텍스트 데이터가 저장된 텍 스트 데이터베이스, 수어형태소영상 데이터가 저장된 수어형태소영상 데이터베이스, 단편화된 수어영 상에 관련된 데이터가 저장되는 수어영상 단편화 데이터베이스, 단편화된 수어영상의 신체 영역을 측정하 여 미리 정해진 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구조화 데이터를 생성하여 정규화함에 따른 관련데이터가 저장되는 정규화 데이터베이스, 수어영상속 수어 발화자의 특성을 제거하여 익명화한 수어영상 관련데이터가 저장되는 수어영상 익명화 데이터베이스, 분석 소프트웨어에서 분석 되어 생성된 데이터가 저장되는 프레임별 요소 데이터베이스가 있다. 이들에 대해서도 뒤에서 도 2와 도 3 을 참조하여 더 자세히 설명한다. 그 외 입력부를 구성하는 마우스/키보드, 제어부, 램, 롬, 그래픽 관리 장치, 네트워 크 연결장치, USB 제어장치, 디스플레이 등은 일반 컴퓨터 시스템에서와 동일하므로 이들에 대 한 자세한 설명은 생략한다. 도 1에 나타낸 바와 같은 본 발명에 따른 수어영상 전처리 기능을 가지는 수어영상 분석 시스템은 텍스트 문장에 대응하는 수어영상을 전처리하는 전처리 과정 및 전처리된 수어영상을 분석하는 분석과정을 수행한다. 수어영상에 대한 전처리 과정 및 분석과정을 도 1~도 3을 함께 참조하면서 설명한다. 수어영상 전처리 과정은 다음과 같다. 수어영상 수신부에 영상데이터가 수신되면 수어영상 판단부가 수신되는 영상데이터가 수어영상인지를 판단하여, 수어영상이 아닌 동영상의 데이터는 무시하여 전처리 및 분석 하지 않는다(S1). 바람직하게, 수어영상 판단부가 S1을 수행할 때 수어 발화자의 신체 부위에 대한 움직임 정보를 얻기 위한 신체 기준범위를 설정한다. 하지만, 신체 기준범위는 미리 설정될 수도 있고, 이후의 여타 과 정에서도 설정될 수 있음은 물론이다. 이 S1이 반드시 필요한 것은 아니다. 예를 들어, 수어영상 전용 수어영상 데이터베이스에서만 수어영상을 수신하는 경우, S1은 필요하지 않다. 그리고 수어영상은 직접, 또는 인터 넷/인트라넷을 통해, 또는 여타의 다양한 경로를 통해 수어영상 데이터베이스에 저장될 수 있다. 수 어영상 데이터베이스에는 기존의 저품질의 텍스트-수어 병렬 코퍼스가 저장되어 있거나 수어영상촬영 캘리 브레이션부에서 촬영된 수어영상이 카메라 입력부 및/또는 인터넷/인트라넷을 통해 수어영상 데 이터베이스나 수어영상 수신부 등으로 입력될 수 있고, 인터넷에 연결된 여타 소스로부터 수어영상이 입력될 수 있다. 때에 따라 수어영상 데이터베이스를 거치지 않은 수어영상이 수어영상 수신부로 수 신될 수도 있음은 물론이다. 수어영상 해상도 변환부 또는 초고해상도 수어영상 변환부(126')는 수신되는 수어영상의 해상도를 고해상 도 수어영상으로, 바람직하게 초고해상도 수어영상으로 변환하고(S2), 수어용 노이즈저감 처리부는 고해상 도로 해상도가 증가되거나 초고해상도로 변환된 수어영상에서 노이즈를 저감시킨다(S3). 동영상의 해상도를 증가시키거나 초고해상도로 변환하는 과정 및 노이즈저감 과정은 기존에 알려진 프로그램이 나 AI 프로그램을 이용하여 수행할 수 있다. 하지만, 본 발명에서는 수어영상 중 배경과 하반신에 대한 영역은 제외하고 손과 머리 및 상반신에 대해서만 해상도를 증가, 바람직하게 초고해상도로 증가시키고, 노이즈를 저감 시킨다. 수어영상 단편화부는 수신되는 수어영상을 수어형태소별로 구획하여 단편화하고 단편화된 수어영상의 프레 임들에 대한 구조화 데이터를 생성하여 수어영상 단편화 데이터베이스에 저장한다(S4). 수어영상 단편화부 에서는 연속된 수어영상을 분석하여 각 수어형태소의 시작과 끝을 인식하고 수어영상 내 시간을 참고하여 수어형태소의 시작과 끝 시간을 기록한다. 수어영상 단편화 데이터베이스에는 수어영상의 시간을 기준으로구조화된 구조화 데이터가 저장된다. 각 수어형태소의 시작과 끝을 인식하기 위한 기술은 AI기술로서, 바람직하게, 수어형태소 영상이 저장된 수어형 태소 영상데이터베이스 등을 통해 학습한 수어영상의 단편화에 특화된 인공지능 프로그램을 이용하여 수어영상 의 각각의 형태소의 시작 프레임과 끝 프레임을 찾아내어 수어영상에 대한 단편화를 수행하는 것을 이용한다. 수어영상 단편화 과정에 수어형태소 영상데이터베이스가 참조될 수 있다. 이러한 단편화 과정은 이후의 주석과정 등에서 데이터의 정확도를 높이고 이후의 데이터 처리과정을 원활히 할 수 있도록 해준다. 단편화 과정에서 생성되는 구조화 데이터는 뒤에서 설명되는 도 4를 보면 알 수 있다. 수어 정규화처리부는 단편화된 수어영상의 신체 영역을 측정하여 이전 단계에서 정해지거나 미리 설정된 신체 기준범위를 넘어서는 영역에 대해서 오차값을 계산하여 구간별 구조화 데이터를 생성하여 정규화 데이터베 이스에 저장한다(S5). 오차값을 근거로 각각의 신체 부분에 대한 보정 데이터가 수어형태소별로 구간별 구 조화 데이터에 저장된다. 수어 정규화처리부에 의한 정규화 과정은 각 수어 발화자 마다 신체 사이즈가 달 라서 이후 진행될 비수지 기호 분석(머리움직임, 얼굴 분석, 상반신움직임 분석, 마우스액션 분석, 핸드제스쳐 분석, 비수지 강세 분석 등)의 정확도를 높이기 위한 것이다. 비수지 강세 및 반복수 분석부는 손동작 이외의 비수지 신호인 얼굴표정, 고개와 머리의 움직임, 입술의 움직임, 눈썹과 눈의 움직임, 어깨와 몸의 움직임 등 수지 신호와 함께 때로는 단독으로 자연스럽게 나타나는 것을 분석하기 위한 것이다. 정규화 과정에 사용되는 기술로는 최근접 이웃, 양선형, Lanczos3 보간법이 사용될 수 있고, 얼굴인식을 위해서 는 PCA, LDA 기술 등 수어 특징에 맞는 알고리즘이 사용될 수 있다. 또한, 본 발명에서는 상체(얼굴, 손, 어깨 등)에 대해서만 기준 영역을 설정하고 기준영역을 벗어나더라도 수어라고 인식할 수 있는 기술이 활용될 수 있 다. 또한, 수어영상을 별도로 수정하지 않고 수어영상의 시간을 기준으로 정규화 처리된 데이터만 별도의 정규 화 데이터베이스에 저장하여 저장 공간의 효율화도 같이 확보할 수 있다. 구간별 구조화 데이터에 대해서는 뒤에서 설명되는 도 5를 보면 알 수 있다. 필요한 경우, 정규화단계에서 생성된 구간별 구조화 데이터에서 수어영상 속 수어 발화자에 따른 개별 특성을 제거하여 일반화 또는 익명화하여 수어영상 익명화 데이터베이스에 저장하는 익명화단계를 수행할 수 있다 (S6). 상기와 같은 전처리 과정을 거친 수어영상과 그의 구조화 데이터는 분석 소프트웨어로 전달되어 분석이 이 루어진다. 분석 소프트웨어가 별도의 컴퓨터 시스템 또는 원격지에 설치된 경우, 분석과정을 거친 수어영 상과 그의 구조화데이터는 인터넷/인트라넷이나 각종 저장매체를 통해 분석 소프트웨어가 설치된 시 스템의 수어영상 및 구조화데이터 수신부를 거처 분석 소프트웨로 보내진다. 전처리 과정을 거친 수어영상에 대한 분석과정은 다음과 같다. 먼저, ROI 취득부가 정규화된 프레임들에서 ROI(Region of Interest)를 취득한다(S7). ROI 취득단계는 수 어영상 속 수어 발화자의 신체 부위에 따라 구분된 복수의 ROI를 취득한다. 예를 들어, 수어영상 속 수어 발화 자의 손의 움직임에 대한 정보를 얻기 위한 영역에 대한 핸드 제스쳐 ROI, 상반신의 움직임에 대한 정보를 얻기 위한 영역에 대한 상반신 ROI 및 머리움직임, 얼굴 움직임 또는 입 움직임에 대한 정보를 얻기 위한 영역에 대 한 머리 ROI를 취득한다. ROI는 수어영상 익명화 처리가 끝난 후 진행하는 것이 좋다. 이후 수어영상 데이터베이스 등으로부터의 수 어영상 및 앞서 처리된 구조화 데이터를 수신한다. ROI는 박스 형태의 영역으로도 설정할 수 있으며, 배경을 제 외한 상체의 픽셀만으로 ROI를 설정할 수 있다. 머리움직임을 포함한 하위 분석부에서는 ROI 취득부에서 획득한 영역 정보를 이용하여 분석이 필요한 영역 을 확인하고 구글(Google)의 Mediapipe 또는 Openpose 등을 이용하여 해당 영역에서의 뼈대정보를 추출하거나, 움직임 데이터를 분석할 수 있는 별도의 소프트웨어를 이용하여 해당 영역의 움직임을 분석한다. 수지 신호를 제외한, 분석하기 위한 비수지 신호의 예는 표 1에 나타내었다. 이러한 비수지 신호 각각에 대해서 는 앞에서 설명한 바와 같이 결합 형태에 따라 의미가 달라질 수 있는 부분이지만, 표준화 등을 통해 의미의 통 일해 나가야 할 것이고, 특히, 인공지능 번역엔진을 개발하는 데는 통일된 의미를 부여하여야 할 것이다.표 1"}
{"patent_id": "10-2022-0189350", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위와 같은 비수지 신호를 분석하기 위한 모션데이터 분석부를 구성하는 머리움직임 분석부, 얼굴 분석부 , 상반신움직임 분석부, 마우스액션 분석부, 핸드 제스쳐 분석부, 비수지(NMS) 강세 및 반 복수 분석부에서 해당 ROI에서의 구간별 모션데이터를 각각 분석하여 수어형태소에 대응하는 프레임들의 프레임별 요소 데이터를 생성하여 프레임별 요소 데이터베이스에 저장한다(S8). 예를 들면, 핸드 제스쳐 ROI에서의 핸드 제스쳐를 분석하여 수지 신호 및 비수지 핸드 제스쳐에 대한 프레임별 수지 및 핸드 요소 데이터를 생성하고, 상반신 ROI에서의 상반신의 움직임을 분석하여 상반신의 움직임에 대한 프레임별 상반신 요소 데이터를 생성하고, 머리 ROI에서의 머리움직임, 얼굴 움직임 및/또는 입 움직임을 분석 하여 머리움직임, 얼굴 움직임 및/또는 입 움직임에 대한 프레임별 머리 요소 데이터를 생성하여 프레임별 요소 데이터베이스에 저장한다. 이에 따라, 텍스트 문장에 대응되는 수어형태소들 각각에 대한 수지 신호와 비수지 신호에 대한 프레임 요소 데 이터를 얻을 수 있다. 각 수어형태소는 수지 신호에 대한 데이터만 가지는 것, 수지 신호와 1개의 비수지 신호 에 대한 데이터만 가지는 것, 수지 신호와 2개 이상의 복수의 비수지 신호에 대한 데이터를 가지는 것, 1개 또 는 복수 개의 비수지 신호에 대한 데이터만 가지는 것이 있을 수 있다. 프레임별 요소 데이터베이스에는 ROI별로 구분된, 구간별 구조화 데이터를 가지는 프레임별 요소 데이터가 저장된다. 이렇게 생성된 프레임별 요소 데이터는, 수어영상 데이터와 텍스트 데이터와 함께 주석 시스템에 제공되어 주석 자가 쉽고 빠르고 정확하게 주석을 할 수 있도록 해준다. 도 4는 단편화단계에서 생성되는 구조화 데이터의 일례를 나타낸 도면이고, 도 5는 정규화단계에서 생성된 구간 별 구조화데이터의 일례를 나타낸 도면이다. 도 4에 나타낸 바와 같이, 수어영상 단편화부에 의한 구조화 데이터(124a) 등은 JSON, XML 등의 데이터 형 식으로 작성되며, 수어영상파일 기본정보필드(F1)와 단편화정보 필드(F2)로 구분되어 표시된다. 수어영상파일 기본정보필드(F1)에는 수어영상의 파일명, 전체 길이, 파일 크기, 프레임 레이트 등에 대한 정보가 담기고, 단 편화정보 필드(F2)에는 수어형태소와 그의 시작 시간 및 끝 시간의 정보가 담긴다. 수어형태소 뒤의 대괄호 속 에 표시된 N은 전체 수어영상에서의 수어형태소의 개수에 대한 정보를 나타낸다. 수어 정규화 처리부에 의한, 구간별 구조화 데이터(127a)는 도 5에서 알 수 있는 바와 같이 수어영상 단편 화부에 의한 구조화 데이터(124a)에 정규화정보 필드(F3)가 추가된 구성을 한다. 정규화정보 필드(F3)에는 머리영역, 얼굴, 상반신, 마우스, 왼손, 오른손의 보정 데이터가 담긴다. 도 6은 ROI 취득부에서 취득하기 위한 ROI를 설명하기 위한 도면이고, 도 7은 ROI 취득부에서 생성되는 구조화 데이터의 예를 나타낸 도면이다.도 6에 나타낸 ROI는 영상을 분석하기 위한 공간을 수어영상 프레임(FR)을 토대로 화소(pixel)의 좌표를 이용하 여 설정한다. 입력된 수어영상은 발화(發話)하려는 문장 및 수어 발화자의 신체에 따라 수어를 인식해야 하는 영역이 각각 달라져 수어영상마다 ROI를 별도로 설정해야 정확도 높은 분석이 가능하다. 얻고자 하는 병렬 코퍼 스의 사용방법, 용도, 목적 등에 따라 단편화된 수어영상들의 영역의 ROI를 분석하여 그중 최대 ROI를 해당 수 어영상의 전체 ROI(R)로 설정할 수도 있고, 때에 따라 단편화된 수어영상의 형태소별로도 ROI를 설정할 수 있다. 예를 들어, 도 6에 나타낸 바와 같이, 머리움직임, 얼굴, 마우스액션의 움직임 데이터를 추출하기 위한 머리 ROI(R1), 상반신움직임의 데이터를 추출하기 위한 상반신 ROI(R2), 수지 신호를 포함한 핸드 제스쳐의 움 직임 데이터를 추출하기 위한 핸드 제스쳐 ROI(R3)로 구분하여 설정할 수 있고, 필요에 따라 ROI는 더 세분화되 어 설정될 수 있다. 바람직하게, 머리 ROI(R1) 내에는 얼굴표정을 읽기 위한 영역, 마우스 액션을 읽기 위한 영 역 등이 중첩되어 ROI가 설정될 수도 있다. ROI 취득부에서 생성되는 구조화 데이터(137a)는 도 7에 나타낸 바와 같이, 수어영상파일 기본정보 필드 (F1)와 ROI 정보 필드(F4)로 구분된다. 수어영상파일 기본정보 필드(F1)에 담기는 정보는 앞에서 설명한 것과 같고, ROI 정보 필드(F4)에는 전체 ROI 정보, 머리움직임 ROI 정보, 얼굴 ROI 정보, 마우스액션 ROI 정보, 왼손 ROI 정보, 오른손 ROI 정보 등이 담길 수 있다. 도 8은 주석 시스템의 주석 GUI의 일례를 나타낸 도면이고, 도 9는 주석 시스템의 주석 GUI의 다른 예를 나타낸 도면이다. 수어 주석작업은 수어에 능통한 전문가가 주석자로 참여하여 구간별로 수어영상을 반복 재생하면서 시간 순서로 또는 프레임 순서로 어떤 비수지 기호 또는 수어 형태소(수어 글로스)가 영상 속에서 표현되는지 수정/검수하는 절차를 의미한다. 이러한 주석작업 방법은 주석자의 수어 능력 및 주관적인 판단으로 오류가 발생할 수 있으며, 주석자마다 다른 판단 기준을 가지고 있어 같은 비수지 기호라도 다르게 주석될 수 있어 인공지능 번역엔진의 학습데이터로 활용 시 문제가 될 수 있다. 이에 따라 본 발명에서는 위 문제를 개선하기 위해 비수지 기호에(표 1 비수지 항목 리스트) 대해 일관된 기준을 적용하여 자동 분석 처리하도록 한다. 도 1 내지 도 7에서 설명한 전처리 과정 및 분석 과정을 거친 수어영상에 대한 프레임별 요소 데이터는 대응하 는 텍스트 문장의 데이터와 수어영상의 데이터와 함께 주석시스템의 메모리에 로딩되어 도 8 또는 도 9에 나타 낸 바와 같이 디스플레이에 주석 GUI로 표시된다. 여기에서, 주석이란 한국어 등의 텍스트 문장에 대응되 는 수어형태소 또는 수어 글로스(수지+비수지)에 대한 구간을 정하는 것으로 볼 수 있다. 주석자는 주석시스템(미도시)의 디스플레이에 표시된 도 8과 도 9에 나타낸 바와 같은 주석 GUI를 보면서 주석 GUI 상에서 형태소들에 각각 대응하는 프레임별 요소 데이터의 구간을 수정 또는 검수한 후 별도의 프레임별 요소 데이터베이스에 저장한다. 이런 과정으로 주석 과정을 거친 텍스트-수어 병렬 코퍼스를 얻을 수 있다. 도 8과 도 9에 나타낸 주석 GUI는 수어영상이 표시되는 영상 표시부, 수어영상의 프레임의 순서 또는 시간이 눈금 형태로 표시되는 프레임/시간 표시부, 텍스트 문장이 표시되는 텍스트 표시부, 수어형태 소 항목을 나타내는 글로스 우세, 글로스 비우세, 수지 신호의 오른손과 왼손 항목을 나타내는 우세손과 비우세 손, 머리 제스쳐, 마우스액션 등의 각종 비수지 신호의 항목을 나타내는 항목표시부, 각 항목의 프레임 범 위 또는 시간 범위를 나타내는 범위 표시부를 가진다. 주석자는 수어영상을 보면서 각각의 수어형태소별로 비수지 신호의 각 항목에 대한 프레임별 요소 데이터의 범위를 마우스 등의 입력수단으로 조정하여 각각의 수어 형태소에 대응하는 비수지 신호 항목들의 범위를 조정하는 과정으로 주석을 한다. 때에 따라, 도 9에 나타낸 바와 같이, 주석 GUI에 움직임영역을 나타낼 수 있는 움직임영역 표시부를 두어 특정 항목의 형태소를 선택하면 선택된 항목의 전체 수어영상에서의 주요 움직임영역이나 해당 수어형태소 별 선택된 항목의 움직임 위치나 범위 등을 나타내도록 할 수 있다. 움직임영역 표시부는 바람직하게, 16개의 영역으로 나누어져 있으며, 우세손(오른손잡이: 오른손, 왼손잡 이: 왼손)/비우세손(오른손잡이: 왼손, 왼손잡이: 오른손)의 움직임을 분석하여 시작 지점과 끝 지점(전체 영상 에 대해서는 영역) 및 각 손의 움직임이 가장 많은 영역을 분석하여 GUI형태로 보여 준다. 움직임영역 표시부 는 비수지 신호가 아닌 핸드 제스쳐 -우세손, 핸드 제스처-비우세손에 해당하는 수어형태소를 선택하면 해 당 영역에 표시한다. 해당 데이터는 구조화된 데이터로 저장되고 구조화된 데이터는 다시 GUI형태로 주석자에게 보여지며, 수정 또는 변경할 수 없는 영역이다. 우세손(오른손)/비우세손(왼손)의 움직임을 분석하여 시작 지점 과 끝 지점(전체 영상에 대해서는 영역) 및 각 손의 움직임이 가장 많은 영역에 대한 구조화된 데이터는 수어형태소별 유사도 분석 또는 검색 시 사용될 수 있다. 도 9에 나타낸 바와 같이, 화면에 표시된 주석 GUI에서 우세손/비우세손에 해당하는 수어형태소를 선택하 면, 모션데이터 분석단계에서 분석된 프레임별 핸드 요소 데이터에서 수어형태소별 왼손과 오른손의 시작 지점 (LS, RS)과 끝 지점(LE, RE) 및 상기 수어영상에서의 왼손과 오른손의 주요 동작영역(LM, RM)에 대한 데이터를 불러와서 움직임영역 표시부에 나타낼 수 있다. 이 경우, 핸드제스쳐 분석부에서 분석된 프레임별 요 소 데이터베이스의 정보가 이용된다. 움직임영역 표시부에 나타내기 위한 데이터는 모션데이터 분석단계에 서 미리 생성하거나 주석단계에서 생성할 수 있다. 이렇게 하면 주석자는 수어형태소별 왼손과 오른손의 시작 지점(LS, RS)과 끝 지점(LE, RE) 및 수어영상에서의 왼손과 오른손의 주요 동작영역(LM, RM)을 시각적으로 확인할 수 있다. 또한, 이들 데이터는 수어 애니메이션 제작 시 적합한 연관 수어형태소를 신속하게 검색할 수 있도록 해주는 것으로 검색보조 데이터의 역할을 한다. 도 9에서, 글로스 #1, 글로스 #2 등은 수어형태소를 의미하며, 한국어 문장에 대응되는 수어형태소를 순서대로 나타낸 것이다. 한국어와 한국수어는 1(한국어):1(한국수어)로 대응되지 않을 수 있고, 예를 들어 1:N이 될 수 도 있고, N:M이 될 수도 있다. 도 10은 수어영상 촬영 캘리브레이션부를 구성하는 수어영상 촬영시스템의 구성도, 도 11은 바람직한 수어영상 촬영방법을 설명하기 위한 측면도이고, 도 12는 바람직한 수어영상 촬영방법을 설명하기 위한 평면도이다. 때에 따라, 수어 발화자가 텍스트에 대응하는 수어를 하는 것을 직접 촬영하여 수어영상을 생성할 수 있다. 수어영상 촬영시스템에는 바람직하게 수어 발화자의 중앙 전방의 제1카메라, 수어 발화자의 우측 전방에 배치되는 제2카메라 및 수어 발화자의 좌측 전방에 배치되는 제3카메라와 같이 3대 의 카메라가 사용되며, 필요한 소프트웨어로는 3대 카메라의 동기화를 위한 수어영상 촬영 동기화실행부 , 촬영자에게 최적의 가이드라인에 대한 정보를 제공하기 위한 수어영상 촬영 가이드라인표시 처리부 , 촬영된 수어영상의 자동송신 등을 위한 수어영상 송신부 및 수어영상 저장부 등의 기능을 하 는 프로그램이 설치되어 있다. 촬영된 수어영상을 저장하기 위한 수어영상 데이터베이스는 자체적으로 구 비하는 것이 바람직하지만, 때에 따라 네트워크 연결장치를 통해 연결된 원격지의 데이터베이스가 이용될 수 있다. 그 외에 하드디스크, SSD 등의 보조기억장치, 운영체제(OS), 입력부를 구성하는 마우스/키보드, 제어 부, 램, 롬, 그래픽 관리 장치, USB 제어장치, 디스플레이는 일반 컴퓨터 시스 템에서와 동일하므로 이들에 대한 자세한 설명은 생략한다. 미설명 부호 200a는 수어영상 촬영시스템을 구 성하는 컴퓨터를 나타낸 것이다. 도 11과 도 12에서, A1의 FOV(field of view)는 100~120도가 적당하다. 단 수어 발화자가 양팔을 벌렸을 때 손끝이 모두 나와야 한다. A2와 A3는 제1카메라를 기준으로 대략 45~60도가 적당하고, D1과 D2는 수어 발화자가 오른팔과 왼팔을 벌렸을 때의 최대 길이이고, D3는 제1카메라와 수어 발화자 간의 거리 로 A1의 FOV의 설정에 따라 달라진다. 도 11에 나타낸 A4는 도 12 A1의 FOV(field of view) 중 높이 FOV를 의미하며, 수어 발화자가 팔을 아래로 내리거나 올렸을 때 손끝까지만 촬영되도록 한다. D4는 바닥에서 제1카메라의 렌즈의 중앙까지의 높이로서 상단부가 수어 발화자의 가슴 중앙에 위치하도록 한다. D5는 D3와 같다. 수어영상 촬영 시 프레임 레이트는 30~50FPS로 설정하는 것이 적당하다. 동영상 파일의 확장자는 동영상 지원 가능한 확장자 모두 가능하고, 비디오코덱은 H264 메인 프로파일(Main Profile) 이상으로 하고, 해상도는 1920 ×1080 이상으로 하고, 가로와 세로의 화면비는 16:9로 하는 것이 바람직하다. 바람직하게, 카메라 렌즈로는 싱 글타입 렌즈를 사용한다. 즉, 도 10의 수어영상 촬영 시스템을 이용하여 한국어 등의 텍스트 문장에 대응하는 수어동작을 촬영하고, 촬영된 수어영상을 수어영상 데이터베이스 등의 저장수단에 저장하였다가 필요한 곳으로 전송하거나 원격 지의 저장수단으로 전송할 수 있다. 카메라는 3대를 사용한 것을 예시하지만 4대 이상을 소정 각도로 간격을 두 고 배치하여 수어영상을 촬영할 수 있다. 제1카메라는 수어동작을 하는 수어 발화자의 정면에서 촬영하고, 제2카메라는 수어 발화자의 정면 방향에 대해 오른쪽으로 45도~60도인 오른쪽 전방 위치에서 촬영하고, 제3카메라는 수어 발화자의 정 면 방향에 대해 왼쪽으로 45도~60도인 왼쪽 전방 위치에서 촬영한다. 제1카메라~제3카메라(211, 212, 213)에서촬영된 수어영상의 데이터는 별도로 각각 저장하되, 동일한 수어영상임을 나타내는 정보와 촬영각도에 대한 정 보를 함께 저장하여 텍스트-수어 인공지능 번역엔진의 학습 시 연관성을 학습할 수 있도록 한다. 위의 설명에서는 한국어와 한국수어를 위주로 병렬 코퍼스를 취득하는 것을 예로 들어 설명하였으나, 여타 언어 와 그에 대응하는 수어의 병렬 코퍼스 취득에도 그대로 이용될 수 있다. 산업상 이용가능성 본 발명은 텍스트-수어 병렬 코퍼스를 대량으로 생성하는 데 이용될 수 있고, 텍스트-수어 인공지능 번역엔진을 학습시키기 위한 병렬 코퍼스 취득에 적합하게 이용될 수 있다. 또한, 본 발명에 따라 취득된 텍스트-수어 병렬 코퍼스는 애니메이션 제작에도 이용될 수 있다."}
{"patent_id": "10-2022-0189350", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 수어영상 전처리 기능을 가지는 수어영상 분석 시스템의 구성도, 도 2는 도 1 시스템에서의 수어영상에 대한 전처리 및 분석과정을 설명하기 위한 블록도, 도 3은 수어영상에 대한 주요 전처리 및 분석과정의 흐름도, 도 4는 단편화단계에서 생성되는 구조화 데이터의 일례를 나타낸 도면, 도 5는 정규화단계에서 생성된 구간별 구조화데이터의 일례를 나타낸 도면, 도 6은 ROI 취득부에서 취득하기 위한 ROI를 설명하기 위한 도면, 도 7은 ROI 취득부에서 생성되는 구조화 데이터의 예를 나타낸 도면, 도 8은 주석 시스템의 주석 GUI의 일례를 나타낸 도면, 도 9는 주석 시스템의 주석 GUI의 다른 예를 나타낸 도면, 도 10은 수어영상 촬영 캘리브레이션부를 구성하는 수어영상 촬영시스템의 구성도, 도 11은 바람직한 수어영상 촬영방법을 설명하기 위한 측면도, 도 12는 바람직한 수어영상 촬영방법을 설명하기 위한 평면도이다."}
