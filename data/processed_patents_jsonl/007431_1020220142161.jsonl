{"patent_id": "10-2022-0142161", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0065482", "출원번호": "10-2022-0142161", "발명의 명칭": "차량의 사고 발생 검출 방법 및 장치", "출원인": "포티투닷 주식회사", "발명자": "강승은"}}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량의 사고 발생 검출 방법으로서,상기 차량에 관한 데이터를 수집하는 단계;상기 수집된 데이터를 전처리하여 전처리 데이터를 획득하는 단계;상기 전처리 데이터에 기초하여 상기 차량의 예측 상태 값을 결정하는 단계; 및상기 예측 상태 값 및 상기 차량에 관한 데이터에 포함된 측정 상태 값에 기초하여 사고의 발생을 검출하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 차량에 관한 데이터는 서로 다른 센서로부터 수집된 복수의 데이터를 포함하고,상기 전처리 데이터를 획득하는 단계는,상기 복수의 데이터 각각에 시간 표기(timestamp)하여, 제1 데이터 및 제2 데이터를 생성하는 단계; 및상기 시간 표기에 기초하여 상기 제1 데이터 및 상기 제2 데이터를 동기화하여, 상기 전처리 데이터를 획득하는단계;를 포함하는,방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 예측 상태 값을 결정하는 단계는,상기 전처리 데이터를 차량 상태 예측 모델의 입력 데이터로 입력하는 단계; 및상기 차량 상태 예측 모델의 출력으로 상기 예측 상태 값을 획득하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 차량 상태 예측 모델은 사전 학습된 제1 모델 및 지속적으로 학습이 이루어지는 제2 모델을 포함하고,상기 예측 상태 값은 상기 제1 모델의 출력에 대응하는 제1 예측 상태 값 및 상기 제2 모델의 출력에 대응하는공개특허 10-2024-0065482-3-제2 예측 상태 값을 포함하는,방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 제2 모델은 상기 제1 모델을 복제하여 생성된 것인, 방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 방법은,상기 제2 모델의 학습이 완료된 것으로 결정하는 단계; 및상기 제1 모델을 상기 제2 모델로 업데이트하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 사고 발생을 검출하는 단계는,상기 예측 상태 값 및 상기 측정 상태 값에 기초하여 예측 오차를 산출하는 단계; 및상기 예측 오차가 임계값을 초과하는 것에 응답하여, 사고가 발생하였다고 결정하는 단계;를 포함하는,방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3 항에 있어서,상기 방법은,상기 차량 상태 예측 모델을 결정하는 단계;를 더 포함하고,상기 차량 상태 예측 모델을 결정하는 단계는,운전자 및 상기 차량에 관한 정보를 획득하는 단계;상기 획득된 운전자 및 차량에 관한 정보에 기초하여, 복수의 모델 중 어느 하나를 선택하는 단계; 및상기 선택된 모델을 상기 차량 상태 예측 모델로 로딩하는 단계;를 포함하는, 공개특허 10-2024-0065482-4-방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 검출된 사고에 관한 정보를 생성하는 단계; 및상기 사고에 관한 정보를 표시하기 위한 사고 정보 인터페이스를 생성하는 단계;를 더 포함하는,방법."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "차량의 사고 발생 검출 장치에 있어서,적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써 동작하는 프로세서;를 포함하되,상기 프로세서는,상기 차량에 관한 데이터를 수집하고,상기 수집된 데이터를 전처리하여 전처리 데이터를 획득하며,상기 전처리 데이터에 기초하여 상기 차량의 예측 상태 값을 결정하고,상기 예측 상태 값 및 상기 차량에 관한 데이터에 포함된 측정 상태 값에 기초하여 사고의 발생을 검출하는,장치."}
{"patent_id": "10-2022-0142161", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항에 따른 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 차량의 사고 발생 검출 방법 및 장치에 관한 것이다. 본 개시의 일 실시예에 따른 차량의 사고 발생 검출 방법은, 차량에 관한 데이터를 수집하고, 수집된 데이터를 전처리하여 전처리 데이터를 획득하며, 전처리 데이터에 기초하여 차량의 예측 상태 값을 결정하고, 예측 상태 값 및 차량에 관한 데이터에 포함된 측정 상태 값에 기초하여 사고의 발생을 검출하는 것을 포함할 수 있다."}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 차량의 사고 발생 검출 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 차량에 설치되는 블랙박스는 차량에 가해지는 충격을 감지하고, 충격 감지 전후의 영상을 저장하는 기능을 수행한다. 통상적으로 블랙박스가 사고를 감지하고 원인을 분석하는 데 가장 큰 역할을 수행하는 것이 현실이다. 한편, 최근에는 트럭, 버스, 택시 등의 모빌리티 서비스에 사용되는 차량을 원격의 서버에서 관리하는 클라우드 관제 시스템이 도입되고 있다. 클라우드 관제 시스템에서 차량에 설치된 통신 단말은 충격 이벤트 또는 사고와 관련된 정보를 즉시, 주기적으로, 또는, 서버 측의 요청 시에 관제 서버로 전송한다."}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술"}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 발명의 내용"}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 차량의 사고 발생 검출 방법 및 장치를 제공하는 데 있다. 본 개시가 해결하고자 하는 과제는 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 개시의 다른 과제 및 장점들은 하기의 설명에 의해 서 이해될 수 있고, 본 개시의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 개시가 해결하고자 하는 과제 및 장점들은 특허 청구범위에 나타난 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 제1 측면은, 차량의 사고 발생 검출 방법으로서, 상기 차량에 관한 데이터를 수집하는 단계; 상기 수 집된 데이터를 전처리하여 전처리 데이터를 획득하는 단계; 상기 전처리 데이터에 기초하여 상기 차량의 예측 상태 값을 결정하는 단계; 및 상기 예측 상태 값 및 상기 차량에 관한 데이터에 포함된 측정 상태 값에 기초하 여 사고의 발생을 검출하는 단계;를 포함하는 방법을 제공할 수 있다. 본 개시의 제2 측면은, 차량의 사고 발생 검출 장치에 있어서, 적어도 하나의 프로그램이 저장된 메모리; 및 상 기 적어도 하나의 프로그램을 실행함으로써 동작하는 프로세서;를 포함하되, 상기 프로세서는, 상기 차량에 관 한 데이터를 수집하고, 상기 수집된 데이터를 전처리하여 전처리 데이터를 획득하며, 상기 전처리 데이터에 기 초하여 상기 차량의 예측 상태 값을 결정하고, 상기 예측 상태 값 및 상기 차량에 관한 데이터에 포함된 측정 상태 값에 기초하여 사고의 발생을 검출하는 장치를 제공할 수 있다. 본 개시의 제3 측면은, 제1 측면에 따른 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 따르면, 사고 발생 상황에 대한 정확한 정보를 입체적으로 제공받을 수 있고, 사고로 인해 차량의 탑승자가 의식을 잃는 등의 신고가 불가능한 상황이더라도 사고처리자에게 사고 발생 검출 결과가 전달 될 수 있다. 또한, 본 개시의 실시예에 따르면, 영상, 센서 데이터 및 이를 기초로 한 해석 결과를 동시에 제공받을 수 있어, 사고 발생 여부 뿐만 아니라, 정확한 사고 원인 및 사고 정보를 효과적으로 파악할 수 있고, 특히 모빌리 티 서비스를 제공하는 운영자의 입장에서 다수의 차량을 관리하는 데 편리함을 제공할 수 있다. 또한, 사고와 관련된 법리적 다툼이 발생하는 경우, 객관적인 정보를 제공하는 역할을 수행할 수 있다."}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시예들로 한정되는 것이 아니라, 서로 다 른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이"}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다.\"매커니즘\", \"요소\", \"수단\" 및 \"구성\"등과 같은 용어는 넓게 사용될 수 있으며, 기계적이 고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하에서, '차량'은 자동차, 버스, 오토바이, 킥보드 또는 트럭과 같이 기관을 가지고 사람이나 물건을 이동시 키기 위해 이용되는 모든 종류의 운송 수단을 의미할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율 주행 차량을 구현 할 수 있다. 자율 주행 차량에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센서 (카메라를 포함함)들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율 주행 차량의 전면에 장착된 이미지 센서 및/또는 이벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율 주행 차량의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율 주행 차량 주변의 보행자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율 주행 차량 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율 주행 차량의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화각 (FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있다. 자율 주행 장치는, 자율 주행 차량의 센서들이 수집한 정보를 실시간으로 처리하여 자율 주행 차량의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서(카메라를 포함함)(42-45)를 포함하며, 복수의 센서들(42-45)은 이미지 센서, 이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어 하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율 주행 차량의 센서(카메라를 포함함)가 획득한 영상 데이터의 예시를 나타 낸 도면이다. 도 3을 참조하면, 영상 데이터는 자율 주행 차량의 전면에 장착된 센서가 획득한 데이터일 수있다. 따라서 영상 데이터에는 자율 주행 차량의 전면부, 자율 주행 차량과 같은 차로의 선행 차량 , 자율 주행 차량 주변의 주행 차량 및 배경 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율 주행 차량의 전면부와 배경이 나타나는 영역 의 데이터는 자율 주행 차량의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율 주 행 차량의 전면부와 배경은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율 주행 차량의 안전한 운행에 있 어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함되 는 영역의 데이터는 자율 주행 차량의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율 주행 차량의 전면부와 배경이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있다. 도 4는 차량 및 관제 서버를 포함하는 시스템의 일 예를 나타내는 도면이다. 일 실시예에 따른 시스템은 다수의 차량 및 관제 서버를 포함할 수 있다. 차량은 네트워크를 통하여 서로 간에 통신하거나, 다른 노드와 통신할 수 있다. 차량은 차량에 탑재된 장치로 이해될 수도 있으며, 차량에 탑재된 장치는 전술한 자율 주행 장치일 수 있다. 즉, 차량에 탑재된 장치 또는 자율 주행 장치는 다양한 센서로부터 수집된 데이터를 다 른 차량에 탑재된 장치, 자율 주행 장치 또는 관제 서버로 전송할 수 있다. 구체적으로, 차량은 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, 랩톱 및 기타 모바일 또는 비모바일 컴퓨팅 디바이스일 수 있다. 또한, 차량은 통신 기능 및 데이터 프로세싱 기능을 구비한 안경, 헤어 밴드 등의 웨어러블 디바이스일 수 있다. 차량은 네트워크를 통해 다른 장치와 통신을 수행할 수 있는 모든 종 류의 디바이스를 포함할 수 있다. 예를 들어, 차량은 터치 스크린을 구비하여 터치 입력 수단을 포함할 수 있다. 터치 스크린은 사용자의 제스처를 통해 소정의 정보가 입력될 수 있는 화면을 의미하며, 사용자의 제스처에는 탭(tap), 더블 탭(double tap), 프레스(press: touch&hold), 롱 프레스(long press), 드래그(drag), 패닝(panning), 플릭(flick), 드래 그 앤 드롭(drag&drop), 릴리스(release) 등이 있을 수 있다. 관제 서버는 네트워크를 통해, 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 차량 및 관제 서버는 네트워크를 이용하여 통신을 수행할 수 있다. 관제 서버는 네트워크를 통하여 차량과 데이터를 송수신하며, 관제 서버의 다양한 관제 기능을 수행하거나, 차량의 주행을 돕는 역할을 수행할 수 있다. 차량에서 수집되어 네트워크를 통해 전송될 수 있는 데이터는, 차량의 연식, 종류 등 차량 자체에 관한 데이터, 차량의 주변 환경과 관련하여 수집된 데이터, 온도, 연료량과 같은 차량 내부 의 상태를 확인하기 위해 수집된 데이터, 차량에 탑승한 운전자, 동승자 등에 관한 데이터 등을 포함할 수 있다. 이하에서, 본 개시의 다양한 실시예에 따른 차량의 사고 발생 검출 방법을 활용하기 위해 수행될 수 있는 제반 프로세스에 관하여 설명한다. 도 5는 차량의 사고 발생 검출을 위한 제반 프로세스를 설명하기 위한 흐름도이다. 본 개시에서, 사고 발생 검출을 위한 제반 프로세스는 차량과 관제서버 사이의 정보 송수신에 의하 여 수행될 수 있다. 도 5에서 차량은 차량 또는 차량에 탑재된 장치를 의미할 수도 있다. 단계 501 이전에, 차량에 장치가 장착될 수 있다. 장치는 다양한 종류의 데이터를 수집할 수 있는 센서 장치, 센서 장치에 의해서 수집된 데이터를 취합하고 전송할 수 있는 장치, 관제 서버와 다양한 데이터를 송수 신할 수 있는 장치 등을 포함할 수 있다. 단계 501에서, 차량은 관제 서버로 차량 및 장치 정보를 전송할 수 있다. 단계 502에서, 관제 서버는 수신된 차량 및 장치 정보를 등록할 수 있다. 관제 서버는 차량 및 장 치 정보를 등록함으로써, 차량으로부터 데이터를 수집할 준비를 수행하고, 수집될 데이터가 어떤 차량의 데이터 인지 식별할 수 있다. 단계 503에서, 관제 서버는 차량으로 사고 처리자 정보를 요청할 수 있다. 본 개시에서, 사고 처리 자는 차량에 사고가 발생하였을 때 사고 처리를 수행하는 사람을 지칭할 수 있다. 예를 들어, 사고 처리자는, 차량이 개인 소유의 것인 경우, 차량의 소유자, 가족 또는 친척일 수 있고, 차량이 렌터카 업체 소유의 것인 경 우, 렌터카 업체의 사고 처리 담당 부서 또는 담당 직원일 수 있다. 일 실시예에서, 차량은 관제 서버 의 요청에 응답하여, 운전자에게 사고 처리자 정보 입력 인터페이스를 제공할 수 있다. 또는, 운전자가 사용하는 단말에 설치된 어플리케이션을 통해 사고 처리자 정보 입력 인터페이스가 제공될 수 있다. 단계 504에서, 차량은 사고 처리자 정보를 입력 받을 수 있다. 단계 505에서, 차량은 관제 서버로 사고 처리자 정보를 전송할 수 있다. 단계 506에서, 관제 서버는 수신된 사고 처리자 정보에 기초하여 사고 처리자를 지정할 수 있다. 단계 507에서, 관제 서버는 차량으로 운전자 정보를 요청할 수 있다. 본 개시에서, 운전자 정보는 차량을 운전하려는 사람에 관한 정보를 지칭할 수 있으며, 운전자에게 맞춤형 서비스를 제공하기 위하여 필요할 수 있다. 예를 들어, 운전자는, 차량이 개인 소유의 것인 경우, 차량의 소유자, 가족 또는 친척일 수 있 고, 차량이 렌터카 업체 소유의 것인 경우, 차량의 대여자일 수 있다. 일 실시예에서, 차량은 관제 서버 의 요청에 응답하여, 운전자에게 운전자 정보 입력 인터페이스를 제공할 수 있다. 단계 508에서, 차량은 운전자 정보를 입력 받을 수 있다. 단계 509에서, 차량은 관제 서버로 운전자 정보를 전송할 수 있다. 단계 510에서, 관제 서버는 수신된 운전자 정보에 기초하여 운전자를 등록할 수 있다. 관제 서버는 데이터베이스에 차량 및 장치 정보, 사고 처리자 정보 및 운전자 정보 등을 저장하여, 이후 차량 사용과 관련하여, 본 개시의 다양한 실시예에 따른 차량의 사고 발생 검출 방법을 수행 또는 차량의 사고 발생 검출 서비스를 제공할 수 있다. 단계 511에서, 차량은 운전자 배정 정보를 전송할 수 있다. 운전자 배정 정보를 전송하는 것은, 차량을 사용하기 전 어떤 사용자가 차량을 운전할 것인지를 관제 서버에 알리는 것이다. 동일한 차량이더라도, 여러 운전자가 등록될 수 있기 때문에, 운전자 배정 정보를 전송하도록 구성될 수 있다. 단계 512에서, 관제 서버는 수신된 운전자 배정 정보에 기초하여 차량으로 맞춤형 서비스를 제공할 수 있다. 이하에서, 본 개시의 다양한 실시예에 따른 차량의 사고 발생 검출 방법에 관하여 설명한다. 도 6은 본 개시의 일 실시예에 따른 차량의 사고 발생 검출 방법의 흐름도이다. 이하에서, 다양한 실시예에 따른 동작들은 도 4의 관제 서버 또는 관제 서버에 포함된 프로세서에 의해 수행되는 것으로 이해될 수 있다. 본 개시의 다양한 실시예에 따른 차량의 사고 발생 검출 장치는 관제 서버와 실질적으로 동일하거나, 관 제 서버에 포함되거나 또는 관제 서버가 수행하는 기능의 일부로 구현되는 구성요소일 수 있다. 단계 610에서, 차량의 사고 발생 검출 장치는 차량에 관한 데이터를 수집할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치가 수집하는 차량에 관한 데이터는 차량(예컨대, 도 4의 차량 )으로부터 전송된 데이터일 수 있다. 일 실시예에서, 차량에 관한 데이터는 CAN(controller area network) 데이터, 전방, 후방, 측방 카메라로 촬영 된 영상 데이터, DMS(driving monitoring system) 카메라의 영상 데이터 및 감지 기능 데이터, IMU(inertial measurement unit) 데이터, GPS 데이터 등을 포함할 수 있다. 단계 620에서, 차량의 사고 발생 검출 장치는 수집된 데이터를 전처리하여 전처리 데이터를 획득할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치가 수집된 데이터를 전처리하는 것은 서로 다른 센서로부터 수집된 복수의 데이터에 대한 시간 동기화하는 것을 포함할 수 있다. 구체적으로, 차량에 관한 데이터는 서로 다른 센 서로부터 수집된 복수의 데이터를 포함할 수 있다. 차량의 사고 발생 검출 장치는 복수의 데이터 각각에 시간 표기(timestamp)를 할 수 있다. 시간 표기에 기초하여 복수의 데이터 각각을 동기화하여, 전처리 데이터를 획득 할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치가 수집된 데이터를 전처리하는 것은 센서 데이터의 축을 정렬하는 것을 포함할 수 있다. 도로의 요철, 기울기 등과 같은 외부 환경의 변화로 인해 차량의 센서 데이터에 오차가 발생하거나, 센서 간의 정합이 제대로 이루어지지 않을 수 있는데, 이 경우 센서 데이터의 축을 정렬함으로써 정확한 전처리 데이터를 획득할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치가 수집된 데이터를 전처리하는 것은 센서 데이터를 융합하는 것을 포함할 수 있다. 센서 데이터를 융합하는 것은, 센서들 마다 특정 외부 환경에 강인하거나 취약한 경향이 다른 바, 여러 센서의 데이터를 융합하여 주변 환경을 파악하기 위해 센서 퓨전 기술을 적용하는 것을 의미할 수 있 다. 차량의 사고 발생 검출 장치는 수집된 센서 데이터를 융합하여 전처리 데이터를 획득할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치가 수집된 데이터를 전처리하는 것은 운전 패턴을 인식하는 것을 포 함할 수 있다. 운전 패턴을 인식하는 것은 방지턱 검출, 급출발/급정거 패턴 인식 등 차량의 주행과 관련된 패 턴을 인식하는 것을 포함할 수 있다. 일 실시예에서, 운전 패턴을 인식하는 것은 인공지능 모델에 기초하여 수 행될 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치가 수집된 데이터를 전처리하는 것은 객체를 검출하는 것을 포함할 수 있다. 객체를 검출하는 것은 수집된 센서로부터 차선, 신호등, 보행자, 차량 등과 같은 객체를 인식, 구별, 라벨링하는 것을 포함할 수 있다. 일 실시예에서, 객체를 검출하는 것은 인공지능 모델에 기초하여 수행될 수 있다. 단계 630에서, 차량의 사고 발생 검출 장치는 전처리 데이터에 기초하여 차량의 예측 상태 값을 결정할 수 있다. 본 개시에서, 차량의 예측 상태 값은 차량의 특정 시점의 데이터에 기초하여 예측된 차량의 미래의 상태에 관한 데이터를 지칭할 수 있다. 즉, t 시점의 차량의 예측 상태 값은, t - 1 시점의 차량의 데이터에 기초하여 예측 된 차량의 상태에 관한 데이터를 지칭할 수 있다. 일 실시예에서, 차량의 예측 상태 값을 결정하는 것은 차량 상태 예측 모델에 의해서 수행될 수 있다. 구체적으 로, 차량의 사고 발생 검출 장치는 전처리 데이터를 차량 상태 예측 모델의 입력 데이터로 입력할 수 있다. 차 량 상태 예측 모델은 입력 데이터에 기초하여 예측 상태 값을 출력할 수 있고, 차량의 사고 발생 검출 장치는 출력된 예측 상태 값을 획득할 수 있다. 본 개시에서, 차량 상태 예측 모델은 입력된 데이터에 기초하여 차량의 예측 상태 값을 출력하는 모델을 지칭할 수 있다. 일 실시예에서, 차량 상태 예측 모델은 사전 학습된 모델(이하, '제1 모델'이라 함)을 포함할 수 있다. 본 개시 에서, 제1 모델은, 후술할 제2 모델과 달리, 사전에 학습이 이루어진 모델로서, 차량의 사고 발생 검출 과정에 서 추가적인 학습이 이루어지지 않는 모델을 지칭할 수 있다. 일 실시예에서, 차량 상태 예측 모델은 지속적으로 학습이 이루어지는 모델(이하, '제2 모델')을 포함할 수 있 다. 본 개시에서, 제2 모델은, 제1 모델과 달리, 지속적으로 학습이 이루어지는 모델을 지칭할 수 있다. 일 실 시예에서, 제2 모델은 제1 모델을 기반으로 할 수 있다. 즉, 제2 모델은 제1 모델을 복제하여 생성된 것일 수 있다. 일 실시예에서, 차량 상태 예측 모델은 제1 모델 및 제2 모델을 모두 포함할 수 있다. 즉, 차량의 사고 발생 검 출 장치는 제1 모델 및 제2 모델을 모두 사용하여, 예측 상태 값을 결정할 수 있다. 제2 모델이 차량의 동적 특성을 완전히 학습하기 전에는 안정하지 않은 결과를 출력할 수 있고, 안정한 결과를 출력하는 데 어느 정도 이상의 학습 시간이 필요할 수 있다. 이에 따라, 본 개시의 차량의 사고 발생 검출 장치 는 제1 모델 및 제2 모델을 함께 사용하여 예측 상태 값을 결정할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는, 제2 모델의 학습이 완료되기 전까지, 제1 모델에 기초하여 예측 상태 값을 획득할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는 제2 모델의 학습이 완료된 것으로 결정할 수 있고, 이에 대응하여 제1 모델을 제2 모델로 업데이트할 수 있다. 본 개시에서, 차량의 사고 발생 검출 장치는 제2 모델이 충분히 학습된 경우, 제2 모델의 학습이 완료된 것으로 결정할 수 있다. 차량의 사고 발생 검출 장치가 제2 모델의 학습이 완료된 것으로 결정하는 것에 관한 실시예는 후술한다. 단계 640에서, 차량의 사고 발생 검출 장치는 예측 상태 값 및 차량에 관한 데이터에 포함된 측정 상태 값에 기 초하여 사고의 발생을 검출할 수 있다. 본 개시에서, 측정 상태 값은, 예측 상태 값과 유사하게, 차량의 상태에 관한 데이터이지만, 예측 상태 값과 달 리, 실제로 측정된 차량의 상태에 관한 데이터를 지칭할 수 있다. 즉, t 시점의 차량의 측정 상태 값은 t 시점 의 차량의 상태에 관한 데이터를 지칭할 수 있다. 일 실시예에서, 측정 상태 값은 수집된 차량에 관한 데이터에 포함될 수 있다. 본 개시에서, 예측 상태 값 및 측정 상태 값은 사고의 발생을 검출하는 데 사용될 수 있다. 즉, 차량의 사고 발 생 검출 장치는 예측 상태 값 및 측정 상태 값에 기초하여 사고의 발생을 검출할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는 예측 상태 값 및 측정 상태 값에 기초하여 예측 오차를 산출할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는 산출된 예측 오차가 임계값을 초과하는 것에 응답하여, 사고가 발생하였다고 결정할 수 있다. 즉, 차량의 사고 발생 검출 장치는, 차량 상태 예측 모델에 기초하여 예 측된 상태 값과 실제로 측정된 상태 값에 차이가 허용할 수 있는 범위를 벗어나는 경우, 정상적이지 않은 상태 라고 간주하여, 사고가 발생하였다고 결정할 수 있다. 사고가 발생하였다고 결정하는 데 사용되는 임계값은 데 이터의 종류에 따라 상이하게 설정될 것이다. 일 실시예에서, 차량의 사고 발생 검출 장치는 사고가 발생하였다고 결정하는 것에 응답하여, 사고의 유형을 결 정할 수 있다. 일 실시예에서, 사고의 유형은, 임계값을 초과하는 예측 오차를 야기한 데이터의 종류, 값 등에 따라 결정될 수 있다. 예를 들어, 특정 방향으로 일정 시간 큰 각속도가 검출되는 경우, 사고의 유형은 전복 사 고 또는 블랙 아이스 사고로 결정될 수 있다. 예를 들어, 사고의 유형은, 차량의 자세가 일반적인 도로의 경사 범주를 넘어서는 구간 동안 유지되는 경우, 전복사고 또는 도랑에 빠진 사고로 결정될 수 있다. 예를 들어, 사 고의 유형은, 가속도계에 의한 데이터가 중력 가속도 방향과 크게 벌어지는 상황이 유지되는 경우, 전복사고로 결정될 수 있다. 예를 들어, 사고의 유형은, 액셀, 브레이크, 운전대 조작에 의한 가속 또는 감속 효과가 실제 반영된 가속도와 차이가 많은 경우, 충돌 사고로 결정될 수 있다. 예를 들어, 사고의 유형은, 보행자가 차량 진 행 경로상에 있으면 대인 사고로 결정될 수 있다. 예를 들어, 사고의 유형은, 차량에서 사람이 내린 다음 차량 주변을 살펴보면 긁힘 또는 찍힘 사고로 결정될 수 있다. 예를 들어, 사고의 유형은, 차선을 변경하는 도중 충 격이 발생하는 경우, 차간 충돌 사고로 결정될 수 있다. 전술한 예시는 단순히 예시로서 제공되며, 임의의 적합한 사고의 유형 결정 방식이 적용될 수 있다. 본 개시에서, 측정 상태 값은 제2 모델을 학습시키는 데 사용될 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는 제2 모델이 출력한 제2 예측 상태 값 및 측정 상태 값에 기초하 여 제2 모델의 파라미터를 조정할 수 있다. 구체적으로, 차량의 사고 발생 검출 장치는 제2 예측 상태 값 및 측 정 상태 사이의 손실을 산출할 수 있고, 산출된 오차를 기반으로 하는 손실 함수가 최소화되도록 제2 모델의 파 라미터를 조정할 수 있다. 본 개시에서, 측정 상태 값은 제2 모델의 학습 수준을 결정하는 데 사용될 수 있다. 전술한 바와 같이, 차량의 사고 발생 검출 장치는 제2 모델의 학습이 완료된 것으로 결정할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는 제2 예측 상태 값 및 측정 상태 값에 기초한 제2 모델 예측 오차 를 산출할 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는 제2 모델 예측 오차가 임계값 이하인 것에 응답하여, 제2 모델의 학습이 완료되었다고 결정할 수 있다. 다른 실시예에서, 차량의 사고 발생 검출 장치는 제2 모델의 학습 시간에 기초하여 제2 모델의 학습이 완료된 것으로 결정할 수 있다. 즉, 제2 모델의 학습 시간이 임계 시간을 초과하는 경우, 제2 모델의 학습이 완료된 것으로 결정될 수 있다. 또 다른 실시예에서, 차량의 사고 발생 검출 장치는 제2 모델의 학습 데이터 양에 기초하여 제2 모델의 학습이 완료된 것으로 결정할 수 있다. 즉, 제2 모델의 학습에 사용된 데이터가 임계량을 초과하는 경우, 제2 모델의학습이 완료된 것으로 결정될 수 있다. 이외에도, 제2 모델의 학습이 완료된 것으로 결정하는 임의의 방식이 적용될 수 있다. 정리하면, 제2 모델이 차량의 동적 특성을 학습하기 전에는 불안정한 결과를 출력할 수 있으므로, 본 개시의 차 량의 사고 발생 검출 장치는 초기에 제1 모델을 사용하여 차량의 사고 발생 검출을 수행하고, 지속적인 학습을 통해 제2 모델의 학습 수준이 임계 수준을 넘어서는 경우, 제2 모델로 제1 모델을 대체함으로써, 지속적으로 사 고 발생 검출의 수준을 개선하는 것이 가능하다. 본 개시에서, 차량 상태 예측 모델을 결정하는 단계가 더 수행될 수 있다. 도 7은 본 개시의 일 실시예에 따른 차량 상태 예측 모델이 결정되는 과정을 도시하는 흐름도이다. 단계 710에서, 차량의 사고 발생 검출 장치는 운전자 및 차량에 관한 정보를 획득할 수 있다. 차량의 사고 발생 검출 장치는 임의의 적합한 방식으로 운전자 및 차량에 관한 정보를 획득할 수 있다. 예를 들 어, 운전자 및 차량에 관한 정보는 차량(또는 차량에 탑재된 장치)으로부터 수신될 수 있다. 예를 들어, 차량의 사고 발생 검출 장치는, 도 5에 도시된 사고 발생 검출을 위한 제반 프로세스를 통해 운전자 및 차량에 관한 정 보를 획득할 수 있다. 일 실시예에서, 차량에 관한 정보는 차종, 차량의 제원, 차량의 사용 횟수, 주행 거리 정보 등 다양한 정보를 포함할 수 있다. 단계 720에서, 차량의 사고 발생 검출 장치는 획득된 운전자 및 차량에 관한 정보에 기초하여, 복수의 모델 중 어느 하나를 선택할 수 있다. 다시 말해, 차량의 사고 발생 검출 장치는 획득된 운전자 및 차량에 관한 정보에 기초하여 해당 운전자 및 해당 차량에 가장 적합하다고 판단되는 모델을 선택할 수 있다. 일 실시예에서, 복수의 모델은 데이터베이스에 저장 되어 있을 수 있다. 일 실시예에서, 차량의 사고 발생 검출 장치는, 운전자가 해당 차종에 대한 운전 이력이 있는지 여부를 결정할 수 있다. 일 실시예에서, 운전자가 해당 차종에 대한 운전 이력이 있는 경우, 차량의 사고 발생 검출 장치는 해 당 차종에 대하여 운전자에게 개인화된 모델을 선택할 수 있다. 일 실시예에서, 운전자가 해당 차종에 대한 운전 이력이 없는 경우, 차량의 사고 발생 검출 장치는, 해당 차종 에 대한 모델이 데이터베이스에 존재하는지 여부를 결정할 수 있다. 일 실시예에서, 해당 차종에 대한 모델이 데이터베이스에 존재하는 경우, 차량의 사고 발생 검출 장치는 해당 차종에 대한 모델을 선택할 수 있다. 일 실시예에서, 해당 차종에 대한 모델이 데이터베이스에 존재하지 않는 경우, 차량의 사고 발생 검출 장치는 해당 차종과 특성이 가장 유사한 차종에 대한 모델을 선택할 수 있다. 모델을 선택하는 이러한 일련의 과정을 통해, 차종마다 동적 특성이 상이함으로 인해 나타나는 추론 오차가 최 소화될 수 있고, 결과적으로 더 정확한 사고 발생 검출이 수행될 수 있다. 단계 730에서, 차량의 사고 발생 검출 장치는 선택된 모델을 차량 상태 예측 모델로 로딩할 수 있다. 단계 730 이후에, 차량의 사고 발생 검출 장치는, 차량 상태 예측 모델에 대해 추가적인 학습이 이루어진 경우, 추가 학습된 차량 상태 예측 모델을 저장 및 관리할 수 있다. 저장된 추가 학습된 차량 상태 예측 모델은 추후 에 차량 상태 예측 모델을 결정하기 위한 풀(pool)에 포함될 수 있다. 이러한 방식으로, 본 개시의 차량의 사고 발생 검출 장치는 가장 적합한 차량 상태 예측 모델을 결정하여 사용 할 수 있고, 지속적으로 차량 상태 예측 모델의 성능을 개선할 수 있다. 도 6과 관련하여 앞서 설명한 차량 상태 예측 모델과 관련된 다양한 실시예는 도 7에서 언급한 차량 상태 예측 모델에 대해서도 적용될 수 있다는 것을 통상의 기술자는 쉽게 이해할 수 있을 것이다. 도 7에 도시되거나 이와 관련하여 설명한 동작 중 일부는 생략될 수 있다. 본 개시에서, 사고 정보 인터페이스가 생성 및 표시되는 과정이 더 수행될 수 있다. 도 8은 본 개시의 일 실시예에 따른 사고 정보 인터페이스를 도시하는 도면이다. 본 개시에서, 사고 정보 인터페이스는 차량의 사고 발생 검출 장치를 사용하는 사용자가 사고에 관한 정보를 용 이하게 파악하기 위해 구성되는, 사고에 관한 정보를 표시하기 위한 인터페이스를 지칭할 수 있다. 차량의 사고 발생 검출 장치는, 시간 표기된 다양한 종류의 데이터를 시간 표기에 기초하여 동기화하고, 동기화 된 데이터에 기초하여 사고에 관한 정보를 생성할 수 있으며, 사고에 관한 정보를 표시하기 위한 사고 정보 인 터페이스를 생성할 수 있다. 도 8을 참조하면, 사고 정보 인터페이스는 대상 선택 영역, 영상 표시 영역, 이벤트 표시 영역 , 지도 표시 영역, 차량의 데이터 표시 영역 및 메모 입력 영역을 포함할 수 있다. 일 실시예에서, 대상 선택 영역은 사고 정보 인터페이스에 표시될 데이터에 대한 조건을 설정하도록 구성되는 영역일 수 있다. 예를 들어, 대상 선택 영역은 조회하고자 하는 차량의 번호를 입력할 수 있는 영역을 포함할 수 있다. 예를 들어, 대산 선택 영역은 조회하고자 하는 시간 구간을 입력할 수 있는 영역 을 포함할 수 있다. 일 실시예에서, 영상 표시 영역은 차량에 탑재된 카메라에 의해 수집된 영상 데이터를 표시하도록 구성되 는 영역일 수 있다. 예를 들어, 영상 표시 영역은 차량에 탑재된 전방 카메라에 의해 수집된 영상 데이터 를 표시하도록 구성될 수 있다. 일 실시예에서, 영상 표시 영역은 차량에 탑재된 다른 카메라(예컨대, 후 방 카메라, 측방 카메라, 운전자 모니터링 카메라 등)의 영상으로 전환하거나, 다른 카메라의 영상을 함께 볼 수 있도록 전환할 수 있도록 구성될 수 있다. 일 실시예에서, 영상 표시 영역은 재생 속도를 조절할 수 있 도록 구성될 수 있다. 일 실시예에서, 이벤트 표시 영역은 차량과 관련하여 발생한 이벤트를 나열하여 표시하도록 구성되는 영역 일 수 있다. 차량과 관련하여 발생한 이벤트는 수집된 차량에 관한 데이터에 기초하여 결정될 수 있다. 일 실시예에서, 지도 표시 영역은 차량의 위치 데이터에 기초한 지도를 표시하도록 구성되는 영역일 수 있 다. 일 실시예에서, 지도에 표시되는 차량의 위치는 대응하는 시간에서의 차량의 위치일 수 있다. 일 실시예에 서, 지도에는 설정된 시간 구간에서의 차량의 경로를 표시하도록 구성될 수 있다. 일 실시예에서, 차량의 데이터 표시 영역은 다양한 데이터의 변화를 표시하도록 구성되는 영역일 수 있다. 차량의 데이터 표시 영역은 다양한 종류의 데이터를 표시할 수 있고, 데이터가 표시되는 방식은, 데이터의 종류에 따라 적합하게 상이할 수 있다. 예를 들어, 차량의 데이터 표시 영역은 시간의 흐름에 따른 차량에 탑재된 센서에 의해 수집된 데이터의 수치 변화를 표시하는 그래프를 포함할 수 있다. 예를 들어, 차량의 데이 터 표시 영역은 시간의 흐름에 따른 영상 확보 여부 표시자를 포함할 수 있다. 예를 들어, 영상 확보 여부 표시자는 영상이 확보된 시구간은 녹색, 영상이 확보되지 않은 시구간은 회색 그리고 영상이 업로드 중인 시구 간은 하늘색으로 표시되는 표시자일 수 있다. 예를 들어, 차량의 데이터 표시 영역은 시간의 흐름에 따른 별 사고 발생 확률 표시자를 포함할 수 있다. 예를 들어, 사고 확률 표시자는 예측 오차와 임계값의 차이에 따 라 색상이 상이하게 표시되는 히트맵(heatmap)일 수 있다. 예를 들어, 차량의 데이터 표시 영역은 시간의 흐름에 따른 차량 문 개폐 표시자를 포함할 수 있다. 예를 들어, 차량의 데이터 표시 영역은 시간의 흐름 에 따른 기어 상태 표시자를 포함할 수 있다. 예를 들어, 기어 상태 표시자는 기어 상태가 P, N, R 또는 D인 시 구간 각각이 상이한 색상으로 표시되는 표시자일 수 있다. 예를 들어, 차량의 데이터 표시 영역은 시간의 흐름에 따른 엔진 상태 표시자를 포함할 수 있다. 예를 들어, 엔진 상태 표시자는 엔진 상태가 on, off 또는 ACC인 시구간 각각이 상이한 색상으로 표시되는 표시자일 수 있다. 일 실시예에서, 메모 입력 영역은 사고 정보 인터페이스는 차량의 사고 발생 검출 장치를 사용하는 사용자 가 메모를 입력하도록 구성되는 영역일 수 있다. 차량의 사고 발생 검출 장치를 사용하는 사용자는 메모 입력 영역과 상호작용하여 메모를 입력할 수 있고, 차량의 사고 발생 검출 장치는 메모가 입력되는 것에 응답하 여, 입력된 메모를 데이터베이스에 저장할 수 있다. 일 실시예에서, 사고 정보 인터페이스에 포함된 각 영역의 데이터는 시간 동기화되어 표시될 수 있다. 따 라서, 본 개시의 사고 정보 인터페이스에 따르면, 영상 데이터, 차량의 센서 데이터, 차량의 위치 데이터 등이 시간 동기화되어 표시될 수 있어 사용자로 하여금 용이하게 사고 발생과 연관된 분석을 할 수 있게 한다. 도 9는 일 실시예에 따른 차량의 사고 발생 검출 장치의 블록도이다. 도 9를 참조하면, 차량의 사고 발생 검출 장치는 통신부, 프로세서 및 DB를 포함할 수 있 다. 도 9의 차량의 사고 발생 검출 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도"}
{"patent_id": "10-2022-0142161", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "9에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있 다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적어 도 하나를 포함할 수 있다. DB는 차량의 사고 발생 검출 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세 서의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 결제 정보, 사용자 정보 등을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 차량의 사고 발생 검출 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등 을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 차량의 사고 발생 검출 장치의 동작을 제어할 수 있다. 프로세서는 도 1 내지 도 8에서 상술한 차량의 사고 발생 검출 장치의 동작 중 적어도 일부를 제어할 수 있다. 프로세서는 ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예로, 차량의 사고 발생 검출 장치는 이동성을 가지는 전자 장치일 수 있다. 예를 들어, 차량의 사 고 발생 검출 장치는 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미 디어 플레이어, 네비게이션, 카메라가 탑재된 디바이스 및 기타 모바일 전자 장치로 구현될 수 있다. 또한, 차 량의 사고 발생 검출 장치는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 장치로 구현될 수 있다. 다른 실시예로, 차량의 사고 발생 검출 장치는 차량 내에 임베디드되는 전자 장치일 수 있다. 예를 들어, 차량의 사고 발생 검출 장치는 생산 과정 이후 튜닝(tuning)을 통해 차량 내에 삽입되는 전자 장치일 수 있다. 또 다른 실시예로, 차량의 사고 발생 검출 장치는 차량 외부에 위치하는 서버일 수 있다. 서버는 네트워크 를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 서버는 차량에 탑재된 장치들로부터 차량의 이동 경로를 결정하기 위해 필요한 데이터를 수신 하고, 수신한 데이터에 기초하여 차량의 이동 경로를 결정할 수 있다. 또 다른 실시예로, 차량의 사고 발생 검출 장치에서 수행되는 프로세스는 이동성을 가지는 전자 장치, 차 량 내에 임베디드 되는 전자 장치 및 차량 외부에 위치하는 서버 중 적어도 일부에 의해 수행될 수 있다. 본 발명에 따른 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 일 실시예에 따르면, 본 개시의 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2022-0142161", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4는 차량 및 관제 서버를 포함하는 시스템의 일 예를 나타내는 도면이다. 도 5는 차량의 사고 발생 검출을 위한 제반 프로세스를 설명하기 위한 흐름도이다. 도 6은 본 개시의 일 실시예에 따른 차량의 사고 발생 검출 방법의 흐름도이다. 도 7은 본 개시의 일 실시예에 따른 차량 상태 예측 모델이 결정되는 과정을 도시하는 흐름도이다. 도 8은 본 개시의 일 실시예에 따른 사고 정보 인터페이스를 도시하는 도면이다. 도 9는 일 실시예에 따른 차량의 사고 발생 검출 장치의 블록도이다."}
