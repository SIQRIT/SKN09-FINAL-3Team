{"patent_id": "10-2023-0139892", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0056027", "출원번호": "10-2023-0139892", "발명의 명칭": "영상 처리 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "이현승"}}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 처리 장치(100)에 있어서,하나 이상의 인스트럭션을 저장하는 메모리(102); 및상기 메모리(102)에 저장된 상기 하나 이상의 인스트럭션을 실행하는 하나 이상의 프로세서(101)를 포함하고, 상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 입력 영상의 품질 및 상기 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하고, 상기 입력 영상의 품질 및 상기 시청 정보에 기초하여 학습 데이터를 생성하고, 상기 학습 데이터를 이용하여 상기 신경망 모델을 학습시키고, 상기 학습된 신경망 모델을 기반으로, 상기 입력 영상으로부터 화질 처리된 출력 영상을 획득하는, 영상 처리장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 시청 정보는 상기 입력 영상의 해상도 정보, 비트레이트 정보, 인코딩 정보, 컨텐츠의 종류, 컨텐츠의 장르, 주변 환경, 시청 거리, 사용자 정보 또는 하나 이상의 시청 정보의 조합을 포함하는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항 또는 제2 항에 있어서,상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 입력 영상의 컨텐츠의 종류 및/또는 컨텐츠의 장르를 포함하는 상기 시청 정보에 기초하여, 상기 컨텐츠의종류 및/또는 상기 컨텐츠의 장르에 해당하는 학습 영상을 제1 데이터로 획득하고,상기 제1 데이터에 속한 상기 학습 영상이 상기 입력 영상의 품질 값에 대응하는 화질을 갖도록 화질 열화된 영상을 제2 데이터로 획득하고, 상기 학습 데이터는 상기 제1 데이터 및 상기 제2 데이터를 포함하는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항 내지 제3 항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 입력 영상의 시청 정보에 대응하는 입력 영상의 비트레이트 정보, 해상도 정보, 및 인코딩 정보 중 하나이상의 압축 정보를 획득하고, 상기 입력 영상의 압축 화질, 블러 화질, 및 노이즈 중 하나 이상의 품질 값을 획득하고,상기 입력 영상의 품질 값 및 상기 압축 정보에 기초하여 상기 입력 영상을 화질 처리함으로써, 화질 열화된 영상을 획득하는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항 내지 제4 항 중 어느 한 항에 있어서,하나 이상의 센서를 더 포함하고,공개특허 10-2025-0056027-3-상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 하나 이상의 센서를 통해 상기 시청 정보에 대응하는 주변 환경 및/또는 시청 거리를 획득하고,상기 주변 환경 및/또는 상기 시청 거리에 기초하여 영상의 타겟 화질을 결정하고,상기 타겟 화질에 기초하여 상기 입력 영상의 화질을 조정함으로써, 상기 학습 데이터를 생성하고, 상기 영상의 타겟 화질은 선명도, 밝기, 대비, 및 채도 중 하나 이상의 화질을 포함하는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3 항에 있어서,상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 신경망 모델에 상기 제2 데이터에 속한 화질 열화된 영상을 입력시킴에 따라 출력된 영상과 상기 제1 데이터에 속한 상기 학습 영상의 차이가 최소가 되도록 상기 신경망 모델을 학습시키는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항 내지 제6 항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 입력 영상의 품질 및 상기 입력 영상에 대한 시청 정보에 대응하여 복수개의 참고 모델을 통해 신경망 모델을 획득하고, 상기 복수개의 참고 모델은 서로 다른 품질 값을 갖는 학습 영상들에 기초하여 학습된 화질 처리 모델, 서로 다른 종류의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델, 및 서로 다른 장르의 컨텐츠에 해당하는학습 영상들로 학습된 화질 처리 모델 중 적어도 하나를 포함하는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 복수개의 참고 모델에 대응하는 컨텐츠의 종류 및/또는 컨텐츠의 장르와 상기 입력 영상의 컨텐츠의 종류및/또는 컨텐츠의 장르를 비교하여 상기 복수개의 참고 모델 중 하나 이상의 참고 모델을 검색하고, 상기 검색된 참고 모델을 이용하여 상기 신경망 모델을 획득하는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7 항에 있어서,상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 복수개의 참고 모델에 대응하는 품질 값과 상기 입력 영상의 품질 값을 비교하여 상기 복수개의 참고 모델중 하나 이상의 참고 모델을 검색하고,상기 검색된 참고 모델을 이용하여 상기 신경망 모델을 획득하는, 영상 처리 장치(100)."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7 항 내지 제9 항 중 어느 한 항에 있어서,상기 하나 이상의 프로세서(101)는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 검색된 참고 모델이 복수개인 것에 기반하여, 상기 검색된 복수개의 참고 모델 각각에 가중치를 부여하고, 상기 가중치가 부여된 각각의 참고 모델을 가중 합(weighted sum)하여 상기 신경망 모델을 획득하고, 상기 가중치는 참고 모델에 대응하는 품질 값과 상기 입력 영상의 품질 값 간의 차이에 따라 결정되는, 영상 처리 장치(100).공개특허 10-2025-0056027-4-청구항 11 영상 처리 장치(100)의 동작 방법에 있어서,입력 영상의 품질 및 상기 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하는 단계(210); 상기 입력 영상의 품질 및 상기 시청 정보에 기초하여 학습 데이터를 생성하는 단계(220); 상기 학습 데이터를 이용하여 상기 신경망 모델을 학습시키는 단계(230); 및상기 학습된 신경망 모델을 기반으로, 상기 입력 영상으로부터 화질 처리된 출력 영상을 획득하는 단계(240)를포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 시청 정보는 상기 입력 영상의 해상도 정보, 비트레이트 정보, 인코딩 정보, 컨텐츠의 종류, 컨텐츠의 장르, 주변 환경, 시청 거리, 사용자 정보 또는 하나 이상의 시청 정보의 조합을 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항 또는 제12 항에 있어서,상기 입력 영상의 품질 및 상기 시청 정보에 기초하여 학습 데이터를 생성하는 단계(220)는,상기 입력 영상의 컨텐츠의 종류 및/또는 컨텐츠의 장르를 포함하는 상기 시청 정보에 기초하여, 상기 컨텐츠의종류 및/또는 상기 컨텐츠의 장르에 해당하는 학습 영상을 제1 데이터로 획득하는 단계; 및상기 제1 데이터에 속한 상기 학습 영상이 상기 입력 영상의 품질 값에 대응하는 화질을 갖도록 화질 열화된 영상을 제2 데이터로 획득하는 단계를 포함하고,상기 학습 데이터는 상기 제1 데이터 및 상기 제2 데이터를 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11 항 내지 제13 항 중 어느 한 항에 있어서,상기 입력 영상의 품질 및 상기 시청 정보에 기초하여 학습 데이터를 생성하는 단계(220)는,상기 입력 영상의 시청 정보에 대응하는 입력 영상의 비트레이트 정보, 해상도 정보, 및 인코딩 정보 중 하나이상의 압축 정보를 획득하는 단계; 상기 입력 영상의 압축 화질, 블러 화질, 및 노이즈 중 하나 이상의 품질 값을 획득하는 단계; 및상기 입력 영상의 품질 값 및 상기 압축 정보에 기초하여 상기 입력 영상을 화질 처리함으로써, 화질 열화된 영상을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항 내지 제14 항 중 어느 한 항에 있어서,상기 입력 영상의 품질 및 상기 시청 정보에 기초하여 학습 데이터를 생성하는 단계(220)는,하나 이상의 센서를 통해 상기 시청 정보에 대응하는 주변 환경 및/또는 시청 거리를 획득하는 단계; 상기 주변 환경 및/또는 상기 시청 거리에 기초하여 영상의 타겟 화질을 판단하는 단계; 및상기 타겟 화질에 기초하여 상기 입력 영상의 화질을 조정함으로써, 상기 학습 데이터를 생성하는 단계를 포함하고, 상기 영상의 타겟 화질은 선명도, 밝기, 대비, 및 채도 중 하나 이상의 화질을 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2025-0056027-5-제13 항에 있어서,상기 학습 데이터를 이용하여 상기 신경망 모델을 학습시키는 단계(230)는,상기 신경망 모델에 상기 제2 데이터에 속한 화질 열화된 영상을 입력시킴에 따라 출력된 영상과 상기 제1 데이터에 속한 상기 학습 영상의 차이가 최소가 되도록 상기 신경망 모델을 학습시키는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11 항 내지 제16 항 중 어느 한 항에 있어서,상기 입력 영상의 품질 및 상기 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하는 단계(210)는,상기 입력 영상의 품질 및 상기 입력 영상에 대한 시청 정보에 대응하여 복수개의 참고 모델을 통해 신경망 모델을 획득하는 단계를 포함하고,상기 복수개의 참고 모델은 서로 다른 품질 값을 갖는 학습 영상들에 기초하여 학습된 화질 처리 모델, 서로 다른 종류의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델, 및 서로 다른 장르의 컨텐츠에 해당하는학습 영상들로 학습된 화질 처리 모델 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서,상기 입력 영상의 품질 및 상기 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하는 단계(210)는,상기 복수개의 참고 모델에 대응하는 컨텐츠의 종류 및/또는 컨텐츠의 장르와 상기 입력 영상의 컨텐츠의 종류및/또는 컨텐츠의 장르를 비교하여 상기 복수개의 참고 모델 중 하나 이상의 참고 모델을 검색하는 단계; 및 상기 검색된 참고 모델을 이용하여 상기 신경망 모델을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17 항에 있어서,상기 입력 영상의 품질 및 상기 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하는 단계(210)는,상기 복수개의 참고 모델에 대응하는 품질 값과 상기 입력 영상의 품질 값을 비교하여 상기 복수개의 참고 모델중 하나 이상의 참고 모델을 검색하는 단계; 및상기 검색된 참고 모델을 이용하여 상기 신경망 모델을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0139892", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17 항 내지 제19 항 중 어느 한 항에 있어서,상기 검색된 참고 모델을 이용하여 상기 신경망 모델을 획득하는 단계는,상기 검색된 참고 모델이 복수개인 것에 기반하여, 상기 검색된 복수개의 참고 모델 각각에 가중치를 부여하는단계; 및상기 가중치가 부여된 각각의 참고 모델을 가중 합(weighted sum)하여 상기 신경망 모델을 획득하는 단계를 포함하고,상기 가중치는 참고 모델에 대응하는 품질 값과 상기 입력 영상의 품질 값 간의 차이에 따라 결정되는, 방법."}
{"patent_id": "10-2023-0139892", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 처리 장치 및 그 동작 방법이 제공된다. 영상 처리 장치는 하나 이상의 인스트럭션을 저장하는 메모리, 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 하나 이상의 프로세서를 포함한다. 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 입력 영상의 품질 및 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득한다. 하나 이상의 프로세서는 입력 영상의 품질 및 시청 정보에 기초 하여 학습 데이터를 생성한다. 하나 이상의 프로세서는 학습 데이터를 이용하여 신경망 모델을 학습시킨다. 하나 이상의 따른 프로세서는 학습된 신경망 모델을 기반으로, 입력 영상으로부터 화질 처리된 출력 영상을 획득한다."}
{"patent_id": "10-2023-0139892", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시예들은 영상 처리 장치 및 그 동작 방법에 관한 것으로, 보다 상세하게는 저화질의 영상을 화질 처리하여 고화질의 영상을 출력하는 영상 처리 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0139892", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 기술의 발전과 함께 다양한 형태의 학습 기반 업스케일링 방법들이 개발되고 있다. 학습 기반 업스케일 방법은 학습 영상의 품질과 실제 처리하는 입력 영상의 품질 특성이 유사할 경우에는 우수한 성능을 보이지만 처리될 영상의 특성이 학습 시 가정한 입력 화질과 차이가 있는 경우 화질 성능이 크게 저하되는 문제가 있다. 이러한 문제를 해결하기 위해서 AI 모델을 입력되는 데이터에 맞춰서 처리하여 적응 시키는 온 디바이스 러닝 (On-Device Learning) 연구가 진행되고 있다. 온 디바이스 러닝 연구 분야에서 최근 영상 처리 및 화질 개선에 대한 논문(ZSSR, CVPR 2018, Zero-Shot Super-Resolution using Deep Internal Learning, 이하 논문 1)이 발표 되었다. 논문 1은 ZSSR (Zero-Shot Super Resolution)로 명명되며, 입력 영상의 열화 특성에 맞게 자기 입력 영상을 사 용하여 데이터베이스(DB)를 구성하고 이를 이용하여 학습된 모델을 사용하여 영상을 확대하는 기술이다. ZSSR은 매번 입력 영상에 맞게 처음부터 새로 데이터베이스를 생성하고 이를 이용하여 모델을 학습시키므로, 학습 복잡 도가 높고, 화질의 변화가 심한 동영상에서는 적용하기 힘들다는 문제가 있다. 이러한 문제점을 개선하기 위해서 또 다른 논문(MetaSR, ECCV 2021, Fast Adaptation to Super-Resolution Networks via Meta-Learning, 이하 논문 2)이 발표되었다. 논문 2는 ZSSR의 학습 연산 복잡도를 줄이기 위해서 초기 메타 모델을 외부 데이터베이스로부터 학습하고 전이 학습(Transfer Learning)을 통해서 입력 영상의 특성 에 맞는 모델을 찾는 기술이다. 그러나, 논문 2의 기술은 하나의 메타 모델만을 이용하므로, 다양한 입력 영상 별 특성을 하나의 메타 모델에 모두 포함시키기에는 성능상의 제약이 있으며, 또한 엣지 디바이스(Edge Devic e)와 같은 저용량 네트워크를 사용하는 환경에서는 이러한 메타 모델의 한계는 온 디바이스 러닝의 성능을 제한 하는 요소가 된다. 논문 1 및 논문 2는 입력 영상을 참조하여 학습 DB를 구성하여 학습하기 때문에 입력 영상이 반복되는 윤곽선 특성을 가지는 빌딩이나 주기적인 텍스쳐가 포함되는 정지 영상의 경우에는 화질 개선 성능을 갖는다. 그렇지만 현실적으로는 기존 방법에서 가정한 영상 외에도 촬영, 전송, 압축 과정에서 열화가 발생된 영상이 많고 이러한 영상들은 화질 복원에 힌트가 되는 고주파 성분들이 손실되어 있고 또한 영상들 내에서 반복되는 성분도 찾기 어려운 경우가 많다. 그래서 자신의 영상 만으로는 학습 DB를 구성하는데 한계가 있으며 이는 성능 저하로 나타 난다. 또한, 기존의 방법은 정지 영상의 화질을 개선하기 위해 개발된 방법이므로, 동영상에는 적용하기 어렵다. 영상 별로 서로 독립적으로 학습된 모델은 학습의 수렴 정도, 학습 데이터베이스의 특성 차이로 인해서 복원 성능 편 차가 존재할 수 있다. 이로 인해서 매 프레임 별로 독립적인 모델을 적용할 경우 영상의 선명도 또한 매번 변화 하게 되어 시간적인 화질의 불균일 현상인 플리커(Flicker) 왜곡이 발생할 수 있다."}
{"patent_id": "10-2023-0139892", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 영상 처리 장치는 하나 이상의 인스트럭션을 저장하는 메모리, 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 하나 이상의 프로세서를 포함한다. 일 실시예에 따른 하나 이상의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 입력 영상의 품질 및 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득한다. 일 실시예에 따른 하나 이상의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 입력 영상의 품질 및 시청 정보에 기초하여 학습 데이터를 생성한다. 일 실시예에 따른 하나 이상의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 학습 데이터를 이용하 여 신경망 모델을 학습시킨다. 일 실시예에 따른 하나 이상의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 학습된 신경망 모델을 기반으로, 입력 영상으로부터 화질 처리된 출력 영상을 획득한다. 본 개시의 일 실시예에 따른 영상 처리 장치의 동작 방법은, 입력 영상의 품질 및 입력 영상에 대한 시청 정보 에 대응하여 신경망 모델을 획득하는 단계, 입력 영상의 품질 및 시청 정보에 기초하여 학습 데이터를 생성하는 단계, 학습 데이터를 이용하여 신경망 모델을 학습시키는 단계, 및 학습된 신경망 모델을 기반으로, 입력 영상 으로부터 화질 처리된 출력 영상을 획득하는 단계를 포함한다."}
{"patent_id": "10-2023-0139892", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기재 된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 명세서에서 “사용자”라는 용어는 영상 처리 장치를 이용하는 사람을 의미하며, 소비자, 평가자, 시청자, 관리자 또는 설치 기사를 포함할 수 있다. 또한, 명세서에서 “제조사”는 영상 처리 장치 및/또는 영 상 처리 장치에 포함된 구성 요소를 제조하는 제조사를 의미할 수 있다. 본 개시에서, '영상(image)'은 정지 영상, 픽처, 프레임, 복수의 연속된 정지 영상으로 구성된 동영상, 또는 비 디오를 나타낼 수 있다. 본 개시에서, 영상은 영상으로부터 의미 정보를 갖도록 잘라낸 패치(patch)를 나타낼 수도 있다. 본 개시에서 '신경망(neural network, 뉴럴 네트워크)'은 뇌 신경을 모사한 인공 신경망 모델의 대표적인 예시 로서, 특정 알고리즘을 사용한 인공 신경망 모델로 한정되지 않는다. 신경망은 심층 신경망(deep neural network)으로 참조될 수도 있다. 또한, 본 개시에서 '파라미터(parameter)'는 신경망을 이루는 각 레이어(layer)의 연산 과정에서 이용되는 값으 로서 예를 들어, 입력 값을 소정 연산식에 적용할 때 이용될 수 있다. 파라미터는 훈련의 결과로 설정되는 값으 로서, 필요에 따라 별도의 훈련 데이터(training data)를 통해 갱신될 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 영상 처리 장치가 화질 처리된 영상을 출력하는 것을 설명하기 위한 도면이다. 도 1을 참조하면, 일 실시예에 따른 영상 처리 장치는 영상을 처리하여 출력할 수 있는 전자 장치일 수 있 다. 일 실시예에 따른 영상 처리 장치는 디스플레이를 포함하는 다양한 형태로 구현될 수 있다. 예를 들어, 영상 처리 장치는 TV, 휴대폰, 태블릿 PC, 디지털 카메라, 캠코더, 노트북 컴퓨터(laptop computer), 데스크탑, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 착용형 기기(wearable device) 등과 같은 다양 한 전자 장치로 구현될 수 있다. 영상 처리 장치는 비디오를 출력할 수 있다. 비디오는 복수의 프레임들로 구성될 수 있다. 비디오는, 콘텐 츠 프로바이더들(contents providers)이 제공하는 텔레비전 프로그램이나 VOD(Video On Demand) 서비스를 통한 각종 영화나 드라마 등의 아이템을 포함할 수 있다. 콘텐츠 프로바이더는 소비자에게 비디오를 포함한 각종 콘 텐츠를 제공하는 지상파 방송국이나 케이블 방송국, OTT(Over The Top) 서비스 제공자, 또는 IPTV 서비스 제공 자를 의미할 수 있다. 비디오는 캡쳐 된 후 압축되어 전송되고, 영상 처리 장치에 의해서 복원되어 출력된 다. 비디오를 캡처하는데 사용되는 기기의 물리적 특성의 한계와 제한된 대역폭 등으로 인해 정보가 손실되면서영상의 왜곡이 발생하게 된다. 영상의 왜곡으로 인해 영상의 품질이 저하될 수 있다. 일 실시예에 따른 영상 처리 장치는 영상의 화질 처리를 수행할 수 있다. 예를 들어, 영상 처리 장치(10 0)는 입력 영상의 화질 처리를 수행함으로써, 출력 영상을 획득할 수 있다. 예를 들어, 영상 처리 장 치는 화질 처리 모델을 이용하여, 저해상도(또는 저화질)의 입력 영상을 업스케일링함으로써, 고해상도(또 는 고화질)의 출력 영상을 획득할 수 있다. 일 실시예에 따른 화질 처리 모델은 저해상도 영상을 고해상도 영상으로 변환할 수 있는 업스케일링 알고리즘을 구현하는 신경망(Neural Network) 모델을 포함할 수 있다. 예를 들어, 화질 처리 모델은, 입력 영상의 품 질에 기초하여 획득된 신경망 모델로부터, 입력 영상에 대응하는 학습 데이터를 이용하여 학습시킨 신경망 모델을 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 영상 처리 장치에 탑재된 화질 처리 모델을 기기 자체에서 실시 간으로 학습시킬 수 있다. 일 실시예에 따른 화질 처리 모델은, 메타 모델(meta model)로 지칭될 수 있다. 메타 모델은 새로운 데이터에 대해 빠르게 학습하거나 일반화할 수 있는 신경망 모델을 의미할 수 있다. 메타 모델은 클라우드 서버에 저장된 다양한 품질 정보에 대응한 학습 데이터를 이용하여 미리 학습된 뒤, 영상 처리 장치 에서 실제 영상의 화질을 처리하는데 이용될 수 있다. 영상 처리 장치는 실제 영상을 학습 데이터로 이용하여 메타 모델을 학습시킴으로써 도메인 갭 문제를 줄일 수 있다. 메타 모델은 다양한 화질 열화 시나리오 에 대해 미리 학습된 신경망이므로, 입력 영상을 기반으로 메타 모델의 파라미터를 조정하는 학습 과정이 간소화될 수 있다. 예를 들어, 메타 모델의 파라미터를 조정하는 경사 하강법(gradient decenet)에서의 반복 연 산 횟수가 감소할 수 있다. 영상 처리 장치는 온 디바이스 러닝을 통해 입력 영상에 적응적인 메타 모델(adaptive meta model)을 생성할 수 있다. 일 실시예에 따른 영상 처리 장치는 입력 영상의 품질 및 입력 영상에 대한 시청 정보를 고려하 여, 메타 모델을 학습시킬 수 있다. 입력 영상의 품질은 화질 분석기를 통해 분석된 영상의 열화 정도를 나타낼 수 있다. 입력 영상에 대한 시청 정보는 화질 분석기를 통해 분석된 영상의 열화 정도 외에 입력 영상이 갖는 속성, 특성 등에 관한 부가적 정보, 및 입력 영상 시청 당시의 시청 환경 등을 포함할 수 있다. 예를 들어, 입력 영상에 대한 시청 정보는 입력 영상의 압축 정보, 컨텐츠의 종류, 컨텐츠 의 장르 등을 포함할 수 있다. 또한, 입력 영상에 대한 시청 정보는 기기 주변 환경, 사용자와 기기 간의 시청 거리, 사용자 개인 정보 등을 포함할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 품질과 입력 영상에 대한 시청 정보를 고려하여 메타 모델의 학습 데이터를 생성할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 품질과 입력 영상 에 대한 시청 정보를 고려하여 메타 모델을 생성(또는 획득)할 수 있다. 일 실시예에 따른 영상 처리 장치는 입력 영상의 품질과 입력 영상에 대한 시청 정보를 고려하 여 메타 모델을 학습시킬 수 있다. 이에 따라, 영상 처리 장치는 입력 영상의 품질 및 사용자의 시청 환경에 맞춰 파라미터가 최적화된 메타 모델을 획득할 수 있다. 영상 처리 장치는 입력 영상의 품질 및 사용자의 시청 환경에 최적화된 파라미터를 갖는 메타 모델에 기초하여, 고해상도의 출력 영상을 생성 할 수 있다. 이하, 영상 처리 장치는 입력 영상의 품질과 입력 영상에 대한 시청 정보를 고려하여 메타 모델 을 학습시키는 방법에 대해 상세히 설명한다. 도 2는 일 실시예에 따른 영상 처리 장치가 입력 영상을 화질 처리하는 방법을 도시한 순서도이다. 도 2를 참조하면, 동작 210에서, 일 실시예에 따른 영상 처리 장치는 입력 영상의 품질 및 입력 영상에 대 한 시청 정보에 대응하여 신경망 모델을 획득할 수 있다. 일 실시예에 따른 영상 처리 장치는 입력 영상의 화질 또는 품질을 판단할 수 있다. 영상의 화질 또는 품 질은 영상의 열화 정도를 나타낼 수 있다. 영상 처리 장치는 영상의 압축 열화, 블러(blur) 정도, 노이즈 정도, 및 영상의 해상도 중 적어도 하나를 평가 또는 판단할 수 있다. 일 실시예에 따른 영상 처리 장치는 화질 분석기(또는 품질 분석부)를 이용하여 입력 영상의 화질을 분석 또는 평가할 수 있다 화질 분석기는 입력 영상의 화질을 분석 또는 평가하도록 훈련된 제1 뉴럴 네트워크를 포 함할 수 있다. 예를 들어, 제1 뉴럴 네트워크는 영상 화질 평가(Image Quality Assessment: IQA) 기술, 비디오화질 평가(Video Quality Assessment: VQA) 기술 등을 이용하여, 영상 또는 비디오의 화질을 평가하도록 훈련된 뉴럴 네트워크일 수 있다. 예를 들어, 영상 처리 장치는 제1 뉴럴 네트워크를 이용하여, 영상의 블러 품질을 나타내는 커널 시그마 (kernel sigma) 값과 영상의 압축 품질을 나타내는 퀄리티 팩터(QF: Quality Factor) 값을 품질 정보로 획득할 수 있다. 다만, 이에 한정되지 않는다. 이에 관해서는 도 4에서 상세히 설명한다. 일 실시예에 따른 영상 처리 장치는 입력 영상이 비디오 컨텐츠에 포함되는 복수의 프레임 영상들 중 어느 하나인 경우, 복수의 프레임 영상들 각각에 대한 품질 정보에 기초하여, 입력 영상의 품질 정보를 획득할 수 있 다. 일 실시예에 따른 영상 처리 장치는 입력 영상에 대한 시청 정보를 획득할 수 있다. 일 실시예에서, 시청 정보는 화질 분석기를 이용하여 판단된 입력 영상의 품질 정보 외에 영상 처리 장치가 획득한 부가 정보를 포함할 수 있다. 일 실시예에 따른 시청 정보는 영상의 압축 정보, 영상 수신 방식에 따른 컨텐츠의 종류, 컨텐 츠의 장르, 영상 처리 장치의 주변 환경, 영상 처리 장치와 사용자 간의 시청 거리, 및 사용자 정보 등을 포함할 수 있다. 컨텐츠의 종류 및/또는 컨텐츠의 장르는 컨텐츠의 특성으로 지칭될 수도 있다. 일 실시예에서, 영상 처리 장치는 서로 다른 해상도, 서로 다른 비트레이트, 또는 서로 다른 인코딩 정보 를 가지는 압축 영상들을 통해 영상의 압축 정보를 획득할 수 있다. 영상의 압축 정보는 압축 영상의 해상도 정 보, 비트레이트 정보, 및 인코딩 정보 등을 포함할 수 있다. 영상 처리 장치는 영상의 압축 정보를 통해 입력 영상이 고품질의 영상인지, 저품질의 영상인지 판단할 수 있다. 일 실시예에서, 영상 처리 장치는 영상 처리 장치에 연결된 외부 기기에 기초하여 컨텐츠의 종류를 판단 또는 식별할 수 있다. 컨텐츠의 종류는 영상 수신 방식에 따라 스트리밍 컨텐츠, 방송 컨텐츠, 블루레이 디스크, 또는 콘솔 게임 등을 포함할 수 있다. 예를 들어, 스트리밍 컨텐츠는 네트워크를 통해 스트리밍 서버로 부터 수신되고, 방송 컨텐츠는 셋톱 박스 또는 RF를 통해 방송국으로부터 수신될 수 있다. 블루레이 디스크는 블루레이 디스크 플레이어를 통해 수신되는 미디어 컨텐츠이고, 콘솔 게임은 게임기 또는 PC 등을 통해 수신되 는 그래픽 컨텐츠일 수 있다. 일 실시예에서, 영상 처리 장치는 컨텐츠의 장르를 식별할 수 있다. 예를 들어, 영상 처리 장치는 방 송국, OTT 서비스 제공자 등으로부터 수신한 컨텐츠에 대한 메타데이터 또는 편성표의 문자 정보를 통해 컨텐츠 의 장르를 식별할 수 있다. 예를 들어, 영상 처리 장치는 현재 실행하고 있는 프로그램의 속성이나 애플리 케이션의 카테고리, 속성 또는 타입을 식별함으로써, 컨텐츠의 장르를 식별할 수 있다. 컨텐츠의 장르는 뉴스, 스포츠, 드라마, 다큐멘터리, 예능, 게임, 영화, 화상 통화 등을 포함할 수 있다. 일 실시예에서, 영상 처리 장치는 조도 센서를 통해 영상 처리 장치 주변의 밝기 정보를 획득할 수 있다. 영상 처리 장치는 시청 시간 및/또는 시청 지역에 관한 정보를 통해 영상 처리 장치 주변의 밝 기 정보를 획득할 수 있다. 주변의 밝기 정보, 시청 시간, 시청 지역은 주변 환경을 나타낼 수 있다. 일 실시예 에서, 영상 처리 장치는 거리 센서를 통해 영상 처리 장치와 사용자 간의 시청 거리를 획득할 수 있 다. 일 실시예에 따른 영상 처리 장치는 사용자가 등록한 계정, 아이디, 식별 정보 등에 기초하여, 사용자 정보를 획득할 수 있다. 일 실시예에서, 영상 처리 장치는 하나 이상의 시청 정보가 조합된 조합 정보를 획득할 수 있다. 예를 들 어, 영상 처리 장치는 영상의 압축 정보, 영상 수신 방식에 따른 컨텐츠의 종류, 컨텐츠의 장르, 영상 처 리 장치의 주변 환경, 영상 처리 장치와 사용자 간의 시청 거리, 및 사용자 정보 중 하나 이상의 시 청 정보가 조합된 조합 정보를 기초로, 신경망 모델을 학습시킬 수 있다. 일 실시예에 따른 영상 처리 장치는 복수개의 참고 모델(reference model 또는 anchor model)을 이용하여 메타 모델을 획득할 수 있다. 참고 모델은 학습 영상을 이용하여 기 학습된 화질 처리 모델을 의미할 수 있다. 참고 모델은 영상 처리 장치의 메모리 또는 외부 데이터베이스 등에 저장되어 있을 수 있다. 일 실시예에서, 복수개의 참고 모델은 서로 다른 품질 값을 갖는 학습 영상들에 기초하여 학습된 화질 처리 모 델, 서로 다른 종류의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델, 및 서로 다른 장르의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 복수개의 참고 모델 각각을 학습하는 데 이용된 학습 영상들의 품질 값과 입력 영상의 품질 값을 비교하여, 입력 영상의 품질과 유사한 품질을 갖는 학습 영상으로 학습된 참고 모델을 검색할 수 있다. 일 실시예에 따른 영상 처리 장치는 복수개의 참고 모델 각각을 학습하는 데 이용된 학습 영상들의 컨텐츠 특성과 입력 영상의 컨텐츠 특성을 비교하여, 입력 영상의 컨텐츠 특성과 일치하는 컨텐츠에 해당하는 학습 영 상으로 학습된 참고 모델을 획득할 수 있다. 컨텐츠 특성이 일치한다는 것은 컨텐츠의 종류 또는 컨텐츠의 장르 가 서로 동일하거나 유사한 것을 포함할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 컨텐츠가 스 트리밍 컨텐츠인 경우, 스트리밍 컨텐츠에 해당하는 학습 영상으로 학습된 참고 모델을 획득할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 컨텐츠의 장르가 화상 통화인 경우, 인물 위주의 학습 영상으로 학습 된 참고 모델을 획득할 수 있다. 일 실시예에 따른 영상 처리 장치는 검색된 참고 모델이 복수개인 경우, 복수개의 참고 모델을 인터폴레이 션(interpolation)하여, 메타 모델을 생성할 수 있다. 예를 들어, 영상 처리 장치는 검색된 복수개의 참고 모델 각각에 가중치를 부여하고, 가중치가 부여된 각각의 참고 모델을 가중 합(weighted sum)하여 메타 모델을 생성할 수 있다. 여기서, 각 참고 모델에 부여되는 가중치는 참고 모델에 대응하는 품질 값과 입력 영상의 품질 값 간의 차이에 따라 결정될 수 있다. 또는, 각 참고 모델에 부여되는 가중치는 참고 모델에 대응하는 컨텐츠의 종류 또는 컨텐츠의 장르와 입력 영상의 컨텐츠의 종류 또는 컨텐츠의 장르 간의 차이에 따라 결정될 수 있다. 동작 220에서, 일 실시예에 따른 영상 처리 장치는 입력 영상의 품질 및 시청 정보 중 적어도 하나에 기초 하여 학습 데이터를 생성할 수 있다. 학습 데이터는 저해상도 영상과 고해상도 영상의 쌍(pair)을 포함할 수 있 다. 본 개시에서, 신경망 모델의 레이블에 해당하는 고해상도 영상을 제1 데이터로 지칭하고, 저해상도 영상을 제2 데이터로 지칭한다. 일 실시예에 따른 영상 처리 장치는 획득한 시청 정보에 대응하는 영상을 획득하고, 이를 학습 영상(제1 데이터)으로 이용할 수 있다. 예를 들어, 영상 처리 장치는 데이터베이스에 저장된 학습 데이터로부터 동 일 또는 유사한 종류, 장르를 갖는 컨텐츠에 해당하는 영상을 선별할 수 있다. 학습 데이터는 고화질 영상들을 포함할 수 있다. 학습 데이터는 외부 데이터 베이스에 저장되어 있거나, 또는 영상 처리 장치 내부 메모리 에 저장되어 있을 수 있다. 제1 데이터는 입력 영상 및 입력 영상과 동일 또는 유사한 특성(종류, 장르)을 갖는 컨텐츠에 해당하는 학습 영상을 포함할 수 있다. 이에 관해서는 도 9a에서 더욱 상세히 설명한다. 일 실시예에 따른 영상 처리 장치는 입력 영상의 카테고리를 식별하고, 식별된 카테고리에 속한 영상을 데 이터베이스에 저장된 학습 데이터로부터 선별할 수도 있다. 영상 처리 장치는 학습 데이터로부터 선별된 영상을 학습 영상(제1 데이터)으로 이용할 수 있다. 제1 데이터는 입력 영상 및 입력 영상의 카테고리에 속하는 학습 영상을 포함할 수 있다. 이에 관해서는 도 9b에서 더욱 상세히 설명한다. 일 실시예에 따른 영상 처리 장치는 입력 영상의 품질 값 및 압축 정보에 대응하는 화질을 갖도록 화질 열 화된 영상(제2 데이터)을 생성할 수 있다. 영상 처리 장치는 제1 데이터에 속한 학습 영상들을 열화시킴으 로써, 입력 영상의 열화 정도에 대응하여 학습 영상으로부터 열화된 영상을 생성할 수 있다. 또한, 일 실시예에 따른 영상 처리 장치는 제1 데이터에 속한 학습 영상들을 열화시킴으로써, 입력 영상의 압축 정보, 예컨대 입력 영상의 비트레이트 정보, 해상도 정보, 및 인코딩 정보 중 하나 이상의 압축 정보에 대응하여 학습 영상으 로부터 열화된 영상을 생성할 수 있다. 예를 들어, 영상 처리 장치는 선별된 학습 영상들을 압축 열화하거 나, 블러링(blurring)하거나, 노이즈를 추가하거나 다운 샘플링(down sampling)하는 방법 중 적어도 하나를 수 행하여, 화질 열화된 영상을 생성할 수 있다. 일 실시예에 따른 영상 처리 장치는 하나 이상의 센서를 통해 주변 환경 및/또는 시청 거리에 관한 정보를 획득하고, 주변 환경 및/또는 시청 거리에 대응하는 타겟 화질을 갖도록 화질 조정(adjusting)된 영상을 생성할 수 있다. 영상 처리 장치는 주변 환경 및/또는 시청 거리에 기초하여, 영상의 타겟 화질을 결정할 수 있다. 영상의 타겟 화질은 선명도, 밝기, 대비, 및 채도 중 하나 이상의 화질을 포함할 수 있다. 영상 처리 장 치는 타겟 화질에 기초하여 입력 영상의 선명도, 밝기, 대비, 및 채도 중 하나 이상의 비율을 증감함으로 써, 화질 조정된 영상을 생성할 수 있다. 화질 조정된 영상은 입력 영상 및 선별된 학습 영상을 포함하는 제1 데이터로부터 화질 조정된 제2 데이터로 지칭될 수 있다. 일 실시예에 따른 영상 처리 장치는 제1 데이터와 제1 데이터에 속한 학습 영상을 화질 처리하여 획득한 제2 데이터를 화질 처리 모델에 대한 학습 데이터로 이용할 수 있다. 동작 230에서, 일 실시예에 따른 영상 처리 장치는 학습 데이터를 이용하여 신경망 모델을 학습할 수 있다. 일 실시예에 따른 영상 처리 장치는 입력 영상의 화질을 처리하기 위한 화질 처리 모델을 입력 영상에 적 응적으로 학습시키는, 온 디바이스 러닝 동작을 수행할 수 있다. 영상 처리 장치는 선별된 학습 영상들(제 1 데이터)과, 학습 영상들을 화질 처리하여 획득한 화질 열화된 영상들(제2 데이터)을 학습 데이터로 이용하여, 메타 모델을 학습시킬 수 있다. 영상 처리 장치는 학습 데이터에 포함된 화질 열화된 영상을 메타 모델에 입력시켜, 메타 모델로부터 출력되는 영상과 학습 데이터에 포함된 고화질 학습 영상과의 차이(학습 에러 또는 로스(loss)) 가 최소가 되도록 메타 모델의 파라미터를 업데이트할 수 있다. 예를 들어, 영상 처리 장치는 경사 하강법(gradient descent) 알고리즘을 사용 하여 메타 모델을 학습시킬 수 있으나, 이에 제한되지 않는다. 동작 240에서, 일 실시예에 따른 영상 처리 장치는 학습된 신경망 모델을 기반으로, 입력 영상으로부터 화 질 처리된 출력 영상을 획득할 수 있다. 일 실시예에 따른 학습된 메타 모델(업데이트된 신경망 모델)은 입력 영상의 화질을 처리하도록 훈련된 제2 뉴 럴 네트워크를 포함할 수 있다. 예를 들어, 제2 뉴럴 네트워크는 저해상도 영상(Low Resolution, LR)을 고해상 도 영상(High Resolution, HR)으로 변환할 수 있는 초해상도(Super Resolution, SR) 알고리즘을 구현하는 추론 네트워크(Inference Network)일 수 있다. 일 실시예에 따른 출력 영상은 입력 영상보다 고해상도 또는 고화질의 영상일 수 있다. 일 실시예에 따른 영상 처리 장치는 입력 영상의 품질과 입력 영상에 대한 시청 정보를 고려하여 메타 모 델을 학습시킴으로써, 사용자의 시청 환경에 맞춰 최적화된 파라미터를 갖는 메타 모델을 획득할 수 있다. 영상 처리 장치는 입력 영상의 품질 및 사용자의 시청 정보에 최적화된 파라미터를 갖는 메타 모델에 기초하여, 고해상도의 출력 영상을 생성할 수 있다. 도 3은 일 실시예에 따른 영상 처리 장치의 내부 블록도이다. 도 3을 참조하면, 영상 처리 장치는 품질 분석부, 모델 학습부, 화질 처리부, 및 시청 정 보 수집부를 포함할 수 있다. 품질 분석부, 모델 학습부, 화질 처리부, 및 시청 정보 수집 부는 적어도 하나의 프로세서로 구현될 수 있다. 품질 분석부, 모델 학습부, 화질 처리부, 및 시청 정보 수집부는 메모리에 저장된 적어도 하나의 인스트럭션에 따라 동작할 수 있다. 일 실시예에 따른 품질 분석부는 입력 영상의 화질 또는 품질을 분석 또는 평가할 수 있다. 영상의 화질은 영상의 열화 정도를 나타낼 수 있다. 품질 분석부는 입력 영상의 압축 열화, 입력 영상의 압축 정도, 블러 (blur) 정도, 노이즈 정도, 영상의 해상도 중 적어도 하나를 평가 또는 결정할 수 있다. 일 실시예에 따른 품질 분석부는 입력 영상의 화질을 분석 또는 평가하도록 훈련된 뉴럴 네트워크를 이용 하여 입력 영상의 화질을 분석 또는 평가할 수 있다. 예를 들어, 뉴럴 네트워크는 영상 화질 평가(Image Quality Assessment: IQA) 기술, 비디오 화질 평가(Video Quality Assessment: VQA) 기술 등을 이용하여, 영상 또는 비디오의 화질을 평가하도록 훈련된 뉴럴 네트워크일 수 있다. 예를 들어, 제1 뉴럴 네트워크는 입력 영상 을 입력 받아 입력 영상의 블러 품질을 나타내는 kernel sigma 값과 영상의 압축 품질을 나타내는 Quality Factor(QF)를 출력하도록 훈련된 뉴럴 네트워크일 수 있다. 제1 뉴럴 네트워크의 구조는 도 4의 제1 뉴럴 네트 워크와 같이 표현될 수 있다. 출력된 입력 영상의 품질은 도 5와 같은 품질 평면 그래프에 표현될 수 있다. 일 실시예에 따른 영상 처리 장치는 입력 영상이 비디오 컨텐츠에 포함되는 복수의 프레임 영상들 중 어느 하나인 경우, 복수의 프레임 영상들 각각에 대한 품질 값에 기초하여, 입력 영상의 품질 값을 획득할 수 있다. 일 실시예에 따른 영상 처리 장치는 제1 시점의 입력 영상의 품질 값 및 제1 시점 이전의 과거 시점의 입 력 영상의 품질 값을 함께 고려하여, 제1 시점의 입력 영상에 대한 평균화된 품질 값을 획득할 수 있다. 일 실시예에서, 품질 분석부는 제1 시점의 입력 영상의 화질 값 및 제1 시점 이전의 과거 시점의 입력 영 상의 화질 값을 함께 고려하여, 제1 시점의 입력 영상에 대한 평균화된 화질 값을 획득할 수 있다. 일 실시예에서, 품질 분석부는 과거 샘플 N개에 대해서 단순 이동 평균 (Simple Moving Average)을 구하는 방법을 이용할 수 있다. 일 실시예에서, 품질 분석부는 과거 시점에 입력된 과거 영상의 화질 값과 현재 시점에 입력된 입력 영상의 화질 값을 합치고 이를 평균한 값을, 현재 시점에 입력된 입력 영상의 화질 값으로 결정할 수 있다. 또는, 일 실시예에서, 품질 분석부는 과거에 계산된 값과 현재 입력 값으로만 평균을 구하는 지수 이동 평 균(Exponential Moving Average) 방법을 이용할 수 있다. 일 실시예에서, 품질 분석부는 제1 시점에 획득 된 입력 영상의 화질 값 및 제1 시점 이전의 과거 시점에 입력된 입력 영상에 대해 구한 과거 시점 지수 이동 평균 화질 값을 함께 고려하여, 제1 시점에 입력된 입력 영상에 대한, 제1 시점 지수 이동 평균 화질 값을 획득 할 수 있다. 일 실시예에 따른 품질 분석부는 입력 영상의 품질 값을 모델 학습부에 제공할 수 있다. 일 실시예에 따른 시청 정보 수집부는 입력 영상에 대한 시청 정보를 수집 또는 획득할 수 있다. 일 실시 예에서, 시청 정보는 품질 분석부를 이용하여 판단된 입력 영상의 품질 정보 외에 영상 처리 장치가 획득한 부가 정보를 포함할 수 있다. 일 실시예에 따른 시청 정보는 영상의 압축 정보, 영상 수신 방식에 따른 컨텐츠의 종류, 컨텐츠의 장르, 영상 처리 장치의 주변 환경, 영상 처리 장치와 사용자 간의 시청 거 리, 및 사용자 정보 등을 포함할 수 있다. 컨텐츠의 종류 및/또는 컨텐츠의 장르는 컨텐츠의 특성으로 지칭될 수도 있다. 일 실시예에서, 시청 정보 수집부는 서로 다른 해상도, 서로 다른 비트레이트, 또는 서로 다른 인코딩 정 보를 가지는 압축 영상들을 통해 영상의 압축 정보를 획득할 수 있다. 영상의 압축 정보는 압축 영상의 해상도 정보, 비트레이트 정보, 및 인코딩 정보 등을 포함할 수 있다. 시청 정보 수집부는 영상의 압축 정보를 통 해 입력 영상이 고품질의 압축 영상인지, 저품질의 압축 영상인지 판단할 수 있다. 일 실시예에서, 시청 정보 수집부는 영상 처리 장치에 연결된 외부 기기에 기초하여 컨텐츠의 종류를 판단 또는 식별할 수 있다. 컨텐츠의 종류는 영상 수신 방식에 따라 스트리밍 컨텐츠, 방송 컨텐츠, 블루레이 디스크, 또는 콘솔 게임 등을 포함할 수 있다. 예를 들어, 스트리밍 컨텐츠는 네트워크를 통해 스트리밍 서버로 부터 수신되고, 방송 컨텐츠는 셋톱 박스 또는 RF를 통해 방송국으로부터 수신될 수 있다. 블루레이 디스크는 블루레이 디스크 플레이어를 통해 수신되는 미디어 컨텐츠이고, 콘솔 게임은 게임기 또는 PC 등을 통해 수신되 는 그래픽 컨텐츠일 수 있다. 일 실시예에서, 시청 정보 수집부는 컨텐츠의 장르를 식별할 수 있다. 예를 들어, 시청 정보 수집부 는 방송국, OTT 서비스 제공자 등으로부터 수신한 컨텐츠에 대한 메타데이터 또는 편성표의 문자 정보를 통해 컨텐츠의 장르를 식별할 수 있다. 예를 들어, 시청 정보 수집부는 현재 실행하고 있는 프로그램의 속성이 나 애플리케이션의 카테고리, 속성 또는 타입을 식별함으로써, 컨텐츠의 장르를 식별할 수 있다. 컨텐츠의 장르 는 뉴스, 스포츠, 드라마, 다큐멘터리, 예능, 게임, 영화, 화상 통화 등을 포함할 수 있다. 일 실시예에서, 시청 정보 수집부는 조도 센서를 통해 영상 처리 장치 주변의 밝기 정보를 획득할 수 있다. 조도 센서는 영상 처리 장치의 내부 또는 외부에 존재할 수 있다. 시청 정보 수집부는 시청 시 간 및/또는 시청 지역에 관한 정보를 통해 영상 처리 장치 주변의 밝기 정보를 획득할 수 있다. 주변의 밝 기 정보, 시청 시간, 시청 지역은 주변 환경을 나타낼 수 있다. 일 실시예에서, 시청 정보 수집부는 거리 센서를 통해 영상 처리 장치와 사용자 간의 시청 거리를 획득할 수 있다. 거리 센서는 영상 처리 장치 의 내부 또는 외부에 존재할 수 있다. 일 실시예에 따른 시청 정보 수집부는 주변의 밝기 정보, 시청 시간 및/또는 시청 지역에 관한 정보, 시청 거리 중 하나 이상을 이용하여, 영상의 타겟 화질을 결정할 수 있다. 타겟 화질은 선명도, 밝기, 대비, 및 채도 중 하나 이상을 포함할 수 있다. 타겟 화질은 모델 학습부 가 제1 데이터로부터 화질 조정된 제2 데이터를 생성하는 데에 이용될 수 있다. 일 실시예에 따른 시청 정보 수집부는 사용자가 등록한 계정, 아이디, 식별 정보 등에 기초하여, 사용자 정보를 획득할 수 있다. 일 실시예에 따른 시청 정보 수집부는 하나 이상의 시청 정보가 조합된 조합 정보를 획득할 수 있다. 예를 들어, 시청 정보 수집부는 영상의 압축 정보, 영상 수신 방식에 따른 컨텐츠의 종류, 컨텐츠의 장르, 영상 처리 장치의 주변 환경, 영상 처리 장치와 사용자 간의 시청 거리, 및 사용자 정보 중 하나 이상의 시청 정보가 조합된 조합 정보를 획득할 수 있다. 일 실시예에 따른 시청 정보 수집부는 시청 정보를 모델 학습부에 제공할 수 있다. 일 실시예에 따른 모델 학습부는 온 디바이스 러닝 동작을 수행할 수 있다. 온 디바이스 러닝 동작은 입력 영상의 화질을 처리하기 위한 화질 처리 모델을 입력 영상에 적응적으로 학습시키는 동작을 포함할 수 있다. 일 실시예에 따른 모델 학습부는 품질 분석부에서 제공한 입력 영상의 품질 및 시청 정보 수집부 에서 제공한 시청 정보에 대응하여 신경망 모델을 학습시킬 수 있다. 일 실시예에 따른 모델 학습부는 품질 분석부에서 제공한 입력 영상의 품질 및 시청 정보 수집부 에서 제공한 시청 정보에 대응하는 메타 모델을 생성할 수 있다. 일 실시예에 따른 모델 학습부는 품질 분석부에서 제공한 입력 영상의 품질 및 시청 정보 수집부 에서 제공한 시청 정보에 대응하는 학습 데이터를 생성할 수 있다. 일 실시예에 따른 모델 학습부는 생성된 메타 모델을 제1 영상에 대응하는 학습 데이터를 이용하여 학습 (전이 학습)시킴으로써, 업데이트된 모델을 생성할 수 있다. 일 실시예에 따른 모델 학습부는 업데이트된 모델을 화질 처리부에 제공할 수 있다. 일 실시예에 따른 모델 학습부의 동작은 도 8을 참조하여 자세히 후술하기로 한다. 일 실시예에 따른 화질 처리부는 모델 학습부에서 업데이트된 모델을 로딩하여, 업데이트된 모델을 이용하여, 입력 영상의 화질 처리를 수행할 수 있다. 화질 처리부는 입력 영상의 화질 처리를 수행하여, 출력 영상을 획득할 수 있다. 예를 들어, 화질 처리부는 영상의 화질을 처리하도록 훈련된 제2 뉴럴 네트 워크를 이용하여, 입력 영상의 화질 처리를 수행할 수 있다. 제2 뉴럴 네트워크는 저해상도 영상(Low Resolution, LR)을 고해상도 영상(High Resolution, HR)으로 변환할 수 있는 초해상도(Super Resolution, SR) 알고리즘을 구현하는 추론 네트워크(Inference Network)일 수 있다. 화질 처리부는 모델 학습부를 통 해 업데이트된 모델을 이용하여 입력 영상의 화질 처리를 수행할 수 있다. 화질 처리부는 업데이트된 모델 에 입력 영상을 적용함으로써, 출력 영상(고해상도 영상)을 획득할 수 있다. 도 4는 일 실시예에 따른 제1 뉴럴 네트워크의 구조를 나타내는 도면이다. 도 4를 참조하면, 제1 뉴럴 네트워크는 CNN(Convolution Neural Network), DCNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 기반의 신경망일 수 있다. 예를 들어, 제1 뉴럴 네트워크는 다양한 데이터들을 입력 받고, 입력된 데이터들을 분석하는 방법, 입력된 데이터들을 분류하는 방법, 및/또는 입력된 데이터들에서 결과 데이터 생성에 필요한 특징을 추출하는 방법 등 을 스스로 발견 또는 터득할 수 있도록 훈련될 수 있다. 제1 뉴럴 네트워크는 다수의 학습 데이터들에 학 습 알고리즘을 적용하여, 원하는 특성의 인공지능 모델로 만들어질 수 있다. 이러한 학습은 영상 처리 장치 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도 형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 실시 예에서의 학습 알고리즘은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 예를 들어, 제1 뉴럴 네트워크는 학습 데이터를 입력 값으로 하는 지도형 학습(supervised learning)을 통하여, 데이터 추론 모델로 학습될 수 있다. 일 실시예에서, 제1 뉴럴 네트워크는 입력 계층(input layer), 숨은 계층(hidden layer), 및 출력 계층 (output layer)을 포함할 수 있다. 일 실시예에서, 제1 뉴럴 네트워크는 숨은 계층으로 복수개의 히든 레 이어들을 포함하는 딥 뉴럴 네트워크(DNN)일 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 각 학습 영상 및 각 학습 영상에 대응하는 품질 값들을 학습 데이 터 셋을 포함하는 학습 DB를 이용하여 학습될 수 있다. 예를 들어, 학습 데이터 셋은 고해상도 영상을 다양한 방법으로 압축하거나 블러링하거나 또는 노이즈를 추가하여 생성된 열화 영상과 열화 영상의 품질 값(정답 또는 레이블)을 포함할 수 있다. 즉, 제1 뉴럴 네트워크는 제1 뉴럴 네트워크로 열화 영상이 입력되었을 때 열화 영상의 품질 값이 출력되도록 훈련될 수 있다. 예를 들어, 도 4에 도시된 제1 뉴럴 네트워크에는 R, G, B 채널들(RGB 3ch)을 포함하는 입력 영상이 입력 될 수 있다. 또는, Y, U, V 채널들(YUV 3ch)을 포함하는 제1 영상이 입력될 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 R, G, B 채널들(RGB 3ch) 또는 Y, U, V 채널들(YUV 3ch)을 포함하 는 입력 영상을 입력 받고, 입력 영상에 하나 이상의 커널(Kernel)들 또는 필터(Filter)들을 적용하여 컨볼루션 연산을 수행하여 특징 맵을 추출할 수 있다. 예컨대, 제1 뉴럴 네트워크는 입력 영상에 3X3 필터 32개를 적용하여 32채널을 출력할 수 있다. 제1 뉴럴 네트워크는 컨볼루션 연산의 대상을 좌측에서 우측으로, 상 단에서 하단으로 한 픽셀씩 스캔하면서, 커널에 포함되는 가중치 값들을 곱하여 합산함으로써, 결과 값을 생성할 수 있다. 컨볼루션 연산의 대상이 되는 데이터는 한 픽셀씩 이동하면서 스캔될 수도 있으나, 2개 픽셀 또는 그 이상의 픽셀 개수만큼 이동하면서 스캔될 수도 있다. 스캔 과정에서 입력 데이터가 이동하는 픽셀의 개수를 스트라이드(stride)라고 하며, 스트라이드의 크기에 따라 출력되는 특징 맵의 크기가 결정될 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 하나의 입력 영상에 대해서 두 종류의 품질 값이 출력되는, Single Input Multi Output 구조를 가질 수 있다. 또한, 일 실시예에 따른 제1 뉴럴 네트워크는 네트워크의 복잡도를 줄이기 위해서 특징을 추출하는 중간 레이어들은 공용으로 사용하고 마지막 단에서 출력을 분리시켜 영상의 품질 요소들을 출력하는 구조를 가질 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 풀링(pooling)을 통해 128 채널의 벡터를 획득하고, 이를 리니어 (linear) 네트워크를 통해서 256 채널의 벡터로 변환할 수 있다. 이후, 제1 뉴럴 네트워크는 256 채널의 벡터를 1차원으로 줄여 최종 결과를 획득할 수 있다. 실시예에서, 제1 뉴럴 네트워크는 입력 영상의 품질 값을 정의된 두 개의 품질 값으로 출력할 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 영상의 블러 품질을 나타내는 블러 시그마(blur sigma)(또는 Kernel Sigma) 및 영상의 압축 품질을 나타내는 압축 화질(Compression Factor, QF) 등을 결과 값들로 출력할 수 있다. Kernel Sigma와 QF는 압축된 영상이 가지는 열화 정도를 함축적으로 표현할 수 있다. 다만, 이에 한정 되지 않으며, 일 실시예에 따른 제1 뉴럴 네트워크는 블러 시그마(blur sigma 또는 Kernel Sigma)와 압축 화질 (Compression QF) 값 이외에도 다양한 형태의 품질 값들을 결과로 획득할 수 있다. 도 5는 일 실시예에 따른 다양한 영상들의 품질 정보를 나타낸 그래프이다. 도 5는 다양한 영상들의 화질을 분석한 결과를 품질 평면으로 나타낸 그래프로, 화질 분석기를 통해서 캡쳐한 동영상들의 품질을 분석한 결과를 2차원 그래프로 보여준다. 화질 분석기의 일 예로 도 3의 품질 분석기 및 도 4에 도시된 제1 뉴럴 네트워크를 포함할 수 있다. 도 5를 참조하면, 그래프의 가로 축은 Kernel Sigma 값을 나타내고, 세로 축은 영상의 압축 품질(Quality Factor, QF)을 나타낸다. Kernel Sigma 값은 영상의 블러 품질을 나타내는 값으로, Kernel Sigma 값이 클수록 블러 정도가 크고, Kernel Sigma 값이 작을수록 블러 정도가 작음을 나타낸다. QF는 압축으로 인한 열화 정도를 나타내는 것으로, QF 값이 작을수록 압축으로 인한 열화가 심하고, QF 값이 클수록 압축으로 인한 열화가 적음 을 나타낸다. 그래프에서 동일한 모양의 기호는 동일한 해상도를 갖는 영상의 품질 값을 나타낸다. 그래프에 도시 된 바와 같이 기호가 서로 동일한 동일 해상도의 영상들이라도 영상들의 품질 값은 다양하게 분포될 수 있다. 동일한 해상도를 가지는 영상들이라도 영상들의 취득, 전송, 저장 과정에서 발생하는 열화에 따라서 영상들은 다양한 품질들을 가질 수 있기 때문이다. 다만, 이는 하나의 실시 예로, 영상 처리 장치는 입력 영상을 분석하여 각 입력 영상의 Kernel Sigma, QF 외에도 또 다른 품질 요소를 더 획득할 수 있다. 예컨대, 영상 처리 장치(100a)는 입력 영상을 분석하여 입력 영상에 포함된 노이즈 정도를 나타내는 품질 요소를 더 획득할 수 있다. 이 경우, 영상 처리 장치가 획득 한 각 입력 영상의 품질 값은, Kernel Sigma, QF 및 노이즈 정도를 세 개의 축으로 나타내는 3차원 그래프로 표 현될 수 있다. 일 실시예에서, 영상 처리 장치는 화질 분석기를 이용하여 실시간으로 입력 영상의 다양한 품질의 값들을 분석할 수 있다. 도 6은 일 실시예에 따른 시청 정보의 종류를 나타내는 일 예이다. 도 6을 참조하면, 일 실시예에 따른 영상 처리 장치는 입력 영상과 함께 부가 정보에 해당하는 시청 정보 를 획득할 수 있다. 예를 들어, 영상 처리 장치는 시청 정보 수집부를 통해 시청 정보를 획득할 수 있다. 일 실시예에 따른 시청 정보는 영상의 압축 정보, 영상 수신 방식에 따른 컨텐츠의 종류, 컨텐츠의 장르, 영상 처리 장치의 주변 환경, 영상 처리 장치와 사용자 간의 시청 거리, 및 사 용자 정보 등을 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 시청 정보에 대응하여 학습 데 이터를 생성하거나, 메타 모델을 생성할 수 있다. 일 실시예에서, 영상의 압축 정보는 영상의 해상도 정보, 비트레이트 정보, 또는 인코딩 정보 등을 포함할 수 있다. 일 실시예에서, 영상 처리 장치는 서로 다른 해상도, 서로 다른 비트레이트, 또는 서로 다른 인 코딩 정보를 가지는 압축 영상을 수신할 수 있다. 예를 들어, 압축 영상은 동일한 원본 영상에 대해 8k, 4k, FHD, HD의 해상도를 가지는 압축 영상 데이터를 포함할 수 있다. 예를 들어, 압축 영상은 동일한 원본 영상에 대해 40Mbps, 30Mbps, 20Mbps, 10Mbps의 비트레이트를 가지는 압축 영상 데이터를 포함할 수 있다. 예를 들어, 압축 영상은 동일한 원본 영상에 대해 h.264, HEVC, AV1 등의 코덱 정보를 가지는 압축 영상 데이터를 포함할 수 있다. 영상의 압축 정보는 컨텐츠 프로바이더와 영상 처리 장치 간의 네트워크의 상태, 예컨대 트 래픽 발생 정도에 따라 결정될 수 있다. 일 실시예에 따른 영상 처리 장치는 컨텐츠 프로바이더로부터 수신한 입력 영상의 속성(attribute) 정보 또는 메타데이터(metadata)를 통해 영상의 압축 정보를 식별할 수 있다. 영상 처리 장치는 영상의 압 축 정보를 통해 입력 영상이 고품질의 영상인지, 저품질의 영상인지 판단할 수 있다. 예를 들어, 영상 처 리 장치는 고해상도 및 고비트레이트의 영상을 수신한 경우, 입력 영상을 고품질의 영상으로 판단하고, 저 해상도 및 저비트레이트의 영상을 수신한 경우, 입력 영상을 저품질의 영상으로 판단할 수 있다. 일 실시예에서, 컨텐츠의 종류는 영상 수신 방식에 따라 스트리밍 컨텐츠, 방송 컨텐츠, 블루레이 디스크, 또는 콘솔 게임 등을 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 영상 처리 장치에 연결된 외부 기기에 기초하여 컨텐츠의 종류 를 판단 또는 식별할 수 있다. 예를 들어, 영상 처리 장치는 네트워크를 통해 연결된 스트리밍 서버, 예컨대 OTT 서비스 제공자, 또는 IPTV 서비스 제공자로부터 수신한 VOD 컨텐츠, 실시간 방송 프로그램, 등을 포 함하는 스트리밍 컨텐츠를 수신할 수 있다. 스트리밍 컨텐츠는 클라우드 게임 서버로부터 수신한 클라우드 게임 을 더 포함할 수 있다. 영상 처리 장치는 스트리밍 방식으로 컨텐츠를 수신할 수 있다. 또한, 예를 들어, 영상 처리 장치는 셋톱 박스를 통해 연결된 지상파 방송국, 케이블 방송국 등으로부터 수신한 실시간 방송 프로그램과 같은 방송 컨텐츠를 수신할 수 있다. 또한, 예를 들어, 영상 처리 장치는 RF(Radio Frequency)를 통해 연결된 공중파 방송국으로부터 수신한 실시간 방송 프로그램과 같은 방송 컨텐츠를 수신할 수도 있다. 또한, 예를 들어, 영상 처리 장치는 블루레이 디스크 플레이어를 통해 재생되는 블루레이 디스크 형식의 미디어 컨텐츠를 수신할 수 있다. 또한, 예를 들어, 영상 처리 장치는 게임기 또는 인터넷을 통해 실행되 는 콘솔 게임의 그래픽 컨텐츠를 수신할 수 있다. 일 실시예에서, 컨텐츠의 장르는 뉴스, 스포츠, 드라마, 다큐멘터리, 예능, 게임, 영화, 화상 통화 등을 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 방송국, OTT 서비스 제공자 등으로부터 수신한 컨텐츠에 대한 메타데 이터를 획득하고, 메타데이터를 통해 컨텐츠의 장르를 식별할 수 있다. 컨텐츠에 대한 메타데이터는 컨텐 츠의 속성이나 컨텐츠를 설명해 주는 데이터로, 콘텐츠에 대한 부가적 정보를 나타내는 정보일 수 있다. 컨텐츠 에 대한 메타데이터는 현재 수신되는 방송과 함께 전송되는 편성표를 포함할 수 있다. 예를 들어, 영상 처리 장 치는 편성표의 문자 정보를 바탕으로 현재 시청하는 컨텐츠의 장르가 뉴스, 스포츠, 드라마, 예능, 다큐멘 터리 등에 해당하는 것을 판단할 수 있다. 컨텐츠에 대한 메타데이터는 캡쳐된 컨텐츠 화면에 출력된 문자나 로 고 등을 포함할 수도 있다. 또는, 일 실시예에 따른 영상 처리 장치는 현재 실행하고 있는 프로그램의 속성이나 애플리케이션의 카테 고리, 속성 또는 타입을 식별함으로써, 컨텐츠의 장르를 식별할 수 있다. 예를 들어, 영상 처리 장치(10 0)는 현재 실행하고 있는 애플리케이션의 속성을 바탕으로 현재 시청하는 컨텐츠의 장르가 영화, 게임, 뉴스, 스포츠, 화상 통화 등에 해당하는 것을 판단할 수 있다. 일 실시예에서, 영상 처리 장치의 주변 환경은 주변 밝기(밝음, 어두움), 시청 시간(오전, 오후, 저 녁, 밤), 또는 시청 지역(고위도 지역, 중위도 지역, 저위도 지역) 등을 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 조도 센서를 통해 영상 처리 장치 주변의 밝기 정보를 획득할 수 있다. 예를 들어, 영상 처리 장치는 조도 센서를 통해 주변의 밝음 정도, 어두움 정도를 판단할 수 있다. 일 실시예에 따른 영상 처리 장치는 시청 시간 및/또는 시청 지역에 관한 정보를 통해 영상 처리 장치 주변의 밝기 정보를 획득할 수 있다. 예를 들어, 영상 처리 장치는 시청 시간이 오전, 오후, 저녁, 밤 시간대 인지 판단하고, 영상 처리 장치 주변의 밝음 정도, 어두움 정도를 예측할 수 있다. 예를 들어, 영상 처리 장치는 시청 지역이 고위도 지역, 중위도 지역, 또는 저위도 지역인지 판단하고, 시청 지역과 시청 시간을 조합하여 주변의 밝음 정도, 어두움 정도를 예측할 수 있다. 일 실시예에 따른 영상 처리 장치는 거리 센서를 통해 영상 처리 장치와 사용자 간의 시청 거리(65 0)를 획득할 수 있다. 예를 들어, 영상 처리 장치는 거리 센서를 통해 영상 처리 장치와 사용자 간의 시청 거리가 긴 지, 짧은 지 여부를 판단할 수 있다. 일 실시예에 따른 영상 처리 장치는 주변 환경 및/또는 시청 거리에 기초하여, 입력 영상의 타 겟 화질을 결정할 수 있다. 타겟 화질은 선명도, 밝기, 대비, 및 채도 등을 포함할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 선명도, 밝기, 대비, 및 채도 중 하나 이상의 증감 비율을 결정할 수 있다. 영상 처리 장치는 입력 영상의 타겟 화질을 기반으로 학습 데이터를 생성할 수 있다. 예를 들어, 영상 처리 장 치는 입력 영상에 선명도, 밝기, 대비, 및 채도 중 하나 이상을 일정한 비율로 증감하는 형태로 화질을 조 정(adjusting)함으로써, 학습 데이터를 생성할 수 있다. 일 실시예에서, 사용자 정보는 성별(남성, 여성), 인종(백인, 황인, 흑인), 또는 연령(청소년, 청년, 중장 년, 노년) 등을 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 사용자가 등록한 계정, 아이디, 식별 정보 등에 기초하여, 사용자 정보를 획득할 수 있다. 도 7은 일 실시예에 따른 시청 정보의 조합 예들을 나타내는 도면이다. 도 7을 참조하면, 일 실시예에 따른 영상 처리 장치는 하나 이상의 시청 정보가 조합된 조합 정보를 획득 할 수 있다. 영상 처리 장치는 하나 이상의 시청 정보가 조합된 조합 정보에 기초하여, 학습 데이터를 생 성할 수 있다. 영상 처리 장치는 하나 이상의 시청 정보가 조합된 조합 정보에 기초하여, 메타 모델을 생 성할 수 있다. 도 7의 710을 참조하면, 컨텐츠의 종류가 스트리밍 컨텐츠인 경우, 컨텐츠에 대한 메타데이터 또는 실행 중인 애플리케이션의 속성을 통해 컨텐츠의 장르가 영화, 스포츠, 게임, 및 화상 통화로 분류될 수 있다. 예를 들어, 영상 처리 장치는 입력 영상이 스트리밍 컨텐츠이고, 영화 장르이고, FHD 해상도, 30Mbps의 비트레이트, 및 h.264 코텍의 압축 정보를 갖는다는 시청 정보를 획득할 수 있다. 예를 들어, 영상 처리 장치는 스트리밍 컨텐츠에 해당하는 학습 영상들로 학습된 참고 모델들 및 영화 장 르에 해당하는 학습 영상들로 학습된 참고 모델들 중 하나 이상의 참고 모델을 검색하고, 검색된 참고 모델을 이용하여 메타 모델을 획득할 수 있다. 예를 들어, 영상 처리 장치는 데이터베이스에 저장된 학습 데이터로부터 스트리밍 컨텐츠 및/또는 영화 장 르에 해당하는 학습 영상(제1 데이터)을 선별할 수 있다. 예를 들어, 영상 처리 장치는 FHD 해상도, 30Mbps의 비트레이트, 및 h.264 코텍의 압축 정보를 기초로 학 습 영상을 열화 처리함으로써, 열화된 영상(제2 데이터)을 획득할 수 있다. 영상 처리 장치는 제1 데이터 및 제2 데이터를 학습 데이터로 이용하여, 메타 모델을 학습시킬 수 있다. 도 7의 720을 참조하면, 컨텐츠의 종류가 방송 컨텐츠인 경우, 편성표를 통해 컨텐츠의 장르가 뉴스, 스포츠, 및 다큐멘터리로 분류될 수 있다. 예를 들어, 영상 처리 장치는 입력 영상이 방송 컨텐츠이고, 뉴스 장르 에 해당한다는 시청 정보를 획득할 수 있다. 예를 들어, 영상 처리 장치는 방송 컨텐츠에 해당하는 학습 영상들로 학습된 참고 모델들 및 뉴스 장르에 해당하는 학습 영상들로 학습된 참고 모델들 중 하나 이상의 참고 모델을 검색하고, 검색된 참고 모델을 이용하 여 메타 모델을 획득할 수 있다. 예를 들어, 영상 처리 장치는 데이터베이스에 저장된 학습 데이터로부터 방송 컨텐츠 및/또는 뉴스 장르에 해당하는 학습 영상(제1 데이터)을 선별할 수 있다. 도 7의 730을 참조하면, 예를 들어, 영상 처리 장치는 입력 영상의 시청 시간이 오전 시간대이고, 주변 밝 기가 밝고, 영상 처리 장치와 사용자 간의 시청 거리가 짧고, 사용자가 중장년이라는 시청 정보를 획득할 수 있다. 영상 처리 장치는 영상의 밝기 및 채도가 소정의 비율로 증가하도록 타겟 화질을 결정할 수 있다. 영상 처 리 장치는 타겟 화질에 기초하여 입력 영상의 밝기 및 채도를 조정함으로써, 학습 데이터를 생성할 수 있 다. 예를 들어, 영상 처리 장치는 제1 데이터에 타겟 화질을 적용하여, 화질이 조정된 제2 데이터를 생성 할 수 있다. 영상 처리 장치는 제1 데이터 및 제2 데이터를 학습 데이터로 이용하여, 메타 모델을 학습시 킬 수 있다. 도 8은 일 실시예에 따른 모델 학습부의 동작을 설명하기 위한 도면이다. 도 8을 참조하면, 모델 학습부는 학습 DB 생성부, 메타 모델 획득부 및 전이 학습부를 포 함할 수 있다. 일 실시예에서, 모델 학습부는 입력 영상의 품질 및 시청 정보를 기반으로 메타 모델을 획득하고, 입력 영 상의 품질 및 시청 정보에 대응하는 학습 데이터를 이용하여 메타 모델을 학습시켜 입력 영상에 적응적인 전이 모델을 생성할 수 있다. 일 실시예에서, 학습 DB 생성부는 입력 영상 및 시청 정보를 이용하여 입력 영상에 대응하는 학습 데이터 를 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 시청 정보에 대응하는 영상을 획득하고, 이를 학습 영상(제1 데이터) 으로 이용할 수 있다. 예를 들어, 학습 DB 생성부는 데이터베이스에 저장된 학습 데이터로부터 동일 또는 유사한 종류, 장르를 갖는 컨텐츠에 해당하는 영상을 선별할 수 있다. 학습 데이터는 고화질 영상들을 포 함할 수 있다. 학습 데이터는 외부 데이터 베이스에 저장되어 있거나, 또는 영상 처리 장치 내부 메모리에 저장되어 있을 수 있다. 제1 데이터는 입력 영상 및 입력 영상과 동일 또는 유사한 특성(종류, 장르)을 갖는 컨 텐츠에 해당하는 학습 영상을 포함할 수 있다. 또는, 일 실시예에 따른 학습 DB 생성부는 입력 영상의 카테고리를 식별할 수 있다. 예를 들어, 학습 DB 생성부는 입력 영상의 카테고리를 확률 값으로 식별할 수 있다. 학습 DB 생성부는 가장 확률 값이 높 은 카테고리를 입력 영상의 카테고리로 식별하고, 식별된 카테고리에 속한 영상을 데이터베이스에 저장되 어 있는 학습 데이터로부터 선별할 수 있다. 학습 DB 생성부는 입력 영상 및 입력 영상의 카테고리에 속하 는 학습 영상을 포함하는 제1 데이터를 획득할 수 있다. 또는, 일 실시예에 따른 학습 DB 생성부는 입력 영상과 동일한 카테고리에 속하는 영상들 중에, 기 설정된 개수의 영상들을 획득할 수 있다. 또는, 학습 DB 생성부는 입력 영상의 카테고리 중 확률 값이 높은 순서 대로 기 설정된 수의 카테고리를 식별하고, 식별된 카테고리에 속하는 영상들을 확률 값에 비례하여 획득할 수 도 있다. 예를 들어, 학습 DB 생성부는 입력 영상에 포함된 오브젝트가 강아지일 확률이 70%, 고양이일 확 률이 30%로 판단한 경우, 학습 데이터 중에 강아지 영상과 고양이 영상을 7:3의 비율로 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상의 품질 값 및 시청 정보에 대응하는 화질을 갖도록 화질 열 화된 영상(제2 데이터)을 생성할 수 있다. 학습 DB 생성부는 제1 데이터에 속한 학습 영상들을 열화시킴으 로써, 입력 영상의 열화 정도에 대응하여 학습 영상으로부터 열화된 영상을 생성할 수 있다. 예를 들어, 학습 DB 생성부는 선별된 학습 영상들을 압축 열화하거나, 블러링(blurring)하거나, 노이즈를 추가하거나 다운 샘플링(down sampling)하는 방법 중 적어도 하나를 수행하여, 화질 열화된 영상을 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 시청 정보 수집부로부터 입력 영상의 압축 정보를 수신할 수 있 다. 학습 DB 생성부는 제1 데이터에 속한 학습 영상들을 열화시킴으로써, 시청 정보에 속하는 입력 영상의 압축 정보, 예컨대 입력 영상의 비트레이트 정보, 해상도 정보, 및 인코딩 정보 중 하나 이상의 압축 정보에 대 응하여 학습 영상으로부터 열화된 영상을 생성할 수 있다. 또한, 일 실시예에 따른 학습 DB 생성부는 시청 정보 수집부로부터 주변 환경 및/또는 시청 거리에 관한 정보를 수신할 수 있다. 학습 DB 생성부는 주변 환경 및/또는 시청 거리에 기초하여 결정된 타겟 화 질에 관한 정보를 수신할 수 있다. 학습 DB 생성부는 제1 데이터에 속한 학습 영상들의 화질을 조정함으로 써, 화질 조정된 영상을 생성할 수 있다. 예를 들어, 학습 DB 생성부는 선별된 학습 영상들의 선명도, 밝기, 대비, 및 채도 중 하나 이상의 비율을 증감함으로써, 화질 조정된 영상을 생성할 수 있다. 화질 조정된 영 상은 제2 데이터로 지칭될 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 데이터와 제1 데이터에 속한 학습 영상을 화질 처리 또는 화질 조 정하여 획득한 제2 데이터를 메타 모델에 대한 학습 데이터로 이용할 수 있다. 일 실시예에서, 학습 DB 생성부 는 학습 데이터를 전이 학습부로 전송할 수 있다. 일 실시예에서, 메타 모델 획득부는 입력 영상의 품질 및 시청 정보에 대응하는 메타 모델을 획득할 수 있 다. 메타 모델 획득부 없이 랜덤한 초기 모델로부터 온 디바이스 러닝을 수행할 경우 오랜 시간의 학습 시 간이 요구된다. 그러나, 실시 예에 따르면 실시간으로 메타 모델 획득부를 통해 입력 영상의 품질에 맞는 모델을 선택하고, 선택된 모델을 이용하여 빠르게 메타 모델을 생성할 수 있다. 일 실시예에서, 메타 모델 획득부는 복수개의 참고 모델을 이용하여 메타 모델을 획득할 수 있다. 참고 모 델은 데이터베이스에 저장될 수 있다. 데이터베이스는 영상 처리 장치의 메모리 또는 외부 데이 터베이스 등에 대응할 수 있다. 제조사는 복수개의 참고 모델을 미리 생성하여 영상 처리 장치에 저장할 수 있으나, 이에 제한되지 않는다. 일 실시예에서, 복수개의 참고 모델은 서로 다른 품질 값을 갖는 학습 영상들에 기초하여 학습된 화질 처리 모 델, 서로 다른 종류의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델, 및 서로 다른 장르의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델 중 적어도 하나를 포함할 수 있다. 예컨대, 복수개의 참고 모델 이 제1 참고 모델 및 제2 참고 모델을 포함하는 경우, 제1 참고 모델은 제1 화질 값을 갖는 학습 영상들로 학습 된 화질 처리 모델이고, 제2 참고 모델은 제2 화질 값을 갖는 학습 영상들로 학습된 화질 처리 모델일 수 있다. 또는 제1 참고 모델은 제1 특성의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델이고, 제2 참고 모델 은 제2 특성의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델일 수 있다. 일 실시예에서, 복수개의 참고 모델은 각각 균일한 간격의 품질 값을 갖는 학습 영상들로 각각 학습될 수 있다. 또는, 일 실시예에서, 참고 모델에 대응하는 품질 값은, 학습 영상들의 품질 값 분포를 기반으로 결정될 수 있 다. 예컨대, 제조사는 학습 영상들을 분석하여 학습 영상들의 품질 값을 획득하고, 학습 영상들의 품질 값의 통 계적 분포를 통해서 대표 품질 샘플링 위치를 결정할 수 있다. 제조사는 대표 품질 샘플링 위치의 품질 값을 갖 는 영상들을 학습 데이터로 이용하여 참고 모델을 학습시킬 수 있다. 일 실시예에서, 메타 모델 획득부는 복수의 참고 모델 각각을 학습하는 데 이용된 영상들의 품질 값과 입 력 영상의 품질 값을 비교하여, 입력 영상의 화질과 유사한 화질을 갖는 학습 영상으로 학습된 참고 모델을 검 색할 수 있다. 일 실시예에서, 메타 모델 획득부는 복수개의 참고 모델 중에서, 입력 영상의 품질 값과 차이가 작은 품질 값을 갖는 영상들로 학습된 참고 모델을 기 정해진 개수만큼 검색할 수 있다. 예컨대, 메타 모델 획득부는 참고 모델 중에서, 입력 영상의 품질 값과의 차이가 기준 값 이내인 품질 값을 갖는 영상들로 학습된 참고 모델 을 검색할 수 있다. 일 실시예에서, 메타 모델 획득부는 참고 모델을 검색하는 데에 시청 정보를 더 이용할 수 있다. 예를 들 어, 메타 모델 획득부는 복수개의 참고 모델 각각을 학습하는 데 이용된 학습 영상들의 컨텐츠 특성과 입 력 영상의 컨텐츠 특성을 비교하여, 입력 영상의 컨텐츠 특성과 일치하는 컨텐츠에 해당하는 학습 영상으로 학 습된 참고 모델을 검색할 수 있다. 컨텐츠 특성이 일치한다는 것은 컨텐츠의 종류 또는 컨텐츠의 장르가 서로 동일하거나 유사한 것을 포함할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 컨텐츠가 스트리밍 컨 텐츠인 경우, 스트리밍 컨텐츠에 해당하는 학습 영상으로 학습된 참고 모델을 검색할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 컨텐츠의 장르가 화상 통화인 경우, 인물 위주의 학습 영상으로 학습된 참고 모 델을 검색할 수 있다. 일 실시예에서, 메타 모델 획득부는 검색된 참고 모델이 한 개인 경우, 검색된 한 개의 참고 모델을 메타 모델로 이용할 수 있다. 일 실시예에서, 메타 모델 획득부는 검색된 참고 모델이 복수개인 경우, 복수개의 참고 모델을 인터폴레이 션(interpolation)하여, 메타 모델을 획득할 수 있다. 일 실시예에서, 메타 모델 획득부는 검색된 복수개 의 참고 모델 각각에 가중치를 부여하고, 가중치가 부여된 각각의 참고 모델을 가중 합(weighted sum)하여 메타 모델을 획득할 수 있다. 일 실시예에서, 참고 모델에 부여되는 가중치는 참고 모델에 대응하는 품질 값과 입력 영상의 품질 값의 차이에 따라 결정될 수 있다. 예컨대, 참고 모델에 대응하는 품질 값과 입력 영상의 품질 값의 차이가 클수록 그 참고 모델에 부여되는 가중치 값은 작아지고, 참고 모델에 대응하는 품질 값과 입력 영상의 품질 값의 차이가 작을수 록 그 참고 모델에 부여되는 가중치 값은 커지게 된다. 또한, 일 실시예에서, 참고 모델에 부여되는 가중치는 참고 모델에 대응하는 컨텐츠의 종류 또는 컨텐츠의 장르 와 입력 영상의 컨텐츠의 종류 또는 컨텐츠의 장르 간의 차이에 따라 결정될 수 있다. 예컨대, 입력 영상이 스 트리밍 컨텐츠에 해당하는 경우, 그래픽 컨텐츠에 대응하는 참고 모델에 부여되는 가중치 값은 작을 수 있다. 예컨대, 입력 영상이 화상 통화 장르에 해당하는 경우, 영화 장르 또는 드라마 장르에 대응하는 참고 모델에 부 여되는 가중치 값은 클 수 있다. 일 실시예에서, 메타 모델 획득부는 획득한 메타 모델을 전이 학습부로 전송할 수 있다. 일 실시예에서, 전이 학습부는 메타 모델 획득부가 획득한 메타 모델을, 학습 DB 생성부로부터 수신한 학습 데이터를 이용하여 학습시킬 수 있다. 일 실시예에서, 전이 학습부는 경사 하강법 알고리즘을 사용 하여 메타 모델을 학습시킬 수 있다. 경사 하 강법은 1차 근삿값 발견용 최적화 알고리즘으로, 함수의 기울기(경사, gradient)를 구하고 경사의 절댓값이 낮 은 쪽으로 계속 이동시켜 함수값이 최소 값일 때의 x값을 찾는 방법이다. 일 실시예에서, 전이 학습부는 학습 데이터에 포함된 화질 열화된 영상(제2 데이터)을 메타 모델에 입력시 켜서 메타 모델로부터 출력되는 영상과, 학습 데이터에 포함된 학습 영상(제1 데이터)을 비교하여, 두 영상의 차이(학습 에러 또는 로스)를 함수의 기울기로 구하고, 기울기의 절대값이 최소가 될 때의 모델의 파라미터를 획득할 수 있다. 즉, 전이 학습부는 메타 모델에서 출력된 영상과 학습 데이터 셋에 포함된 고화질 영상의 정량적 차이가 최소가 되도록 메타 모델의 파라미터를 계속적으로 업데이트함으로써 메타 모델을 학습시켜 전이 모델을 획득할 수 있다. 일 실시예에서, 전이 학습부는 공지된 다양한 학습 알고리즘을 이용하여 메타 모델을 학습시킬 수 있다. 전이 학습부는 시스템의 제한 조건, 예컨대, 메모리, 연산기, 파워 등에 따라서 학습의 하이퍼 파라메터 (학습률, 배치 크기, 종료 조건 등) 및 최적화 알고리즘(SGD, Adam, Adamp sec)등을 선택적으로 적용할 수 있다. 일 실시예에서, 메타 모델 획득부 및 전이 학습부는 주기적으로, 또는 랜덤한 간격으로 전이 모델을 생성할 수 있다. 일 실시예에서, 메타 모델 획득부는 매 프레임 단위로, 또는 복수개의 프레임을 포함하는 장면(scene) 단위로, 또는 비디오의 콘텐츠 타입이 변경될 때 마다, 예컨대, 콘텐츠 타입이 뉴스였다가, 드라마 로 바뀌는 경우, 새로 메타 모델을 획득할 수 있다. 일 실시예에서, 전이 학습부는 메타 모델 획득부(32 3)가 새로 메타 모델을 획득할 때 마다, 메타 모델을 학습 시켜 전이 모델을 업데이트할 수 있다. 예컨대, 전이 학습부는 매 프레임 단위로, 또는 복수개의 프레임을 포함하는 장면(scene) 단위로, 또는 비디오의 콘텐츠 타입이 변경될 때 마다, 메타 모델을 학습시켜 새로운 전이 모델을 생성할 수 있다. 일 실시예에 따른 전이 학습부는 입력 영상에 맞게 적응적으로 학습된 전이 모델을 생성할 수 있다. 전이 학습부가 업데이트한 메타 모델은 화질 처리부에 로딩되어 화질 처리에 사용될 수 있다. 한편, 본 개시에서 학습 DB 생성부와 메타 모델 획득부는 각각 시청 정보를 이용하여 학습 데이터 및 메타 모델을 생성하는 것으로 예시하였으나, 이에 제한되지 않는다. 예를 들어, 시청 정보는 학습 DB 생성부 에만 전송되거나, 메타 모델 획득부에만 전송될 수도 있다. 도 9a는 일 실시예에 따른 학습 DB 생성부가 입력 영상과 관련된 학습 영상들을 획득하는 동작의 일 예를 설명 하기 위한 도면이다. 도 9a를 참조하면, 일 실시예에 따른 학습 DB 생성부는 입력 영상의 컨텐츠 특성과 유사한 특성을 가지는 영상을 외부 데이터베이스로부터 선별적으로 수집하여, 학습 영상(제1 데이터)를 생성할 수 있다 일 실시예에 따른 학습 DB 생성부는 시청 정보에 대응하는 영상을 획득하고, 시청 정보에 대응하는 영상을 학습 영상으로 이용할 수 있다. 예를 들어, 학습 DB 생성부는 외부 데이터베이스로부터 입력 영상의 컨텐츠 특성, 예컨대 컨텐츠의 종류나 장르에 대응하는 학습 영상을 선별할 수 있다. 외부 데이터베이스로부터 선별된 학습 영상은 제1 데이터에 저장될 수 있다. 외부 데이터베이스에는 스트리밍 컨텐츠, 방 송 컨텐츠, 미디어 컨텐츠, 또는 게임 그래픽 컨텐츠 등 다양한 종류의 컨텐츠에 해당하는 고화질의 학습 데이 터가 저장될 수 있다. 컨텐츠의 종류는 컨텐츠 프로바이더에 따라 상이할 수 있다. 또한, 외부 데이터베이스 에는 뉴스, 스포츠, 드라마, 다큐멘터리, 예능, 게임, 영화, 화상 통화 등 다양한 장르의 컨텐츠 별로 고 화질의 학습 데이터가 저장될 수 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상의 컨텐츠와 동일하거나 유사한 컨텐츠에 해당하는 영상을 학습 영상으로 선별할 수 있다. 예를 들어, 학습 DB 생성부는 입력 영상이 게임 컨텐츠인 경우, 그래픽 컨 텐츠에 해당하는 영상들을 학습 영상으로 선별할 수 있다. 예를 들어, 학습 DB 생성부는 입력 영상이 영화 장르 또는 화상 통화 장르인 경우, 사람 위주의 영상들을 학습 영상으로 선별할 수 있다. 일 실시예에 따른 학 습 DB 생성부는 외부 데이터베이스가 아닌, 영상 처리 장치의 내부 메모리에 저장된 학습 영상 들 중에서 선별할 수도 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상의 컨텐츠와 동일하거나 유사한 컨텐츠에 해당하는 학습 영 상 외부 데이터베이스로부터 획득하고, 이들을 포함하는 새로운 데이터베이스를 제1 데이터로 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상을 학습 영상으로 이용할 수도 있다. 예를 들어, 학습 DB 생 성부는 입력 영상으로부터 의미 정보를 갖도록 잘라낸 하나 이상의 패치(patch)를 학습 영상으로 이용할 수도 있다. 입력 영상에 대응한 하나 이상의 패치는 제1 데이터에 저장될 수 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상의 컨텐츠와 동일하거나 유사한 컨텐츠에 해당하는 학습 영 상 및 입력 영상을 포함하는 제1 데이터를 생성할 수 있다. 제1 데이터는 영상 처리 장치의 내 부 메모리에 저장될 수 있다. 제1 데이터에 속한 영상들은 메타 모델을 학습시키기 위한 고해상도 영상으 로 사용될 수 있다 도 9b는 일 실시예에 따른 학습 DB 생성부가 입력 영상과 관련된 학습 영상들을 획득하는 동작의 일 예를 설명 하기 위한 도면이다. 도 9b를 참조하면, 일 실시예에 따른 학습 DB 생성부는 입력 영상의 컨텐츠 특성과 유사한 특성을 가지는 영상을 외부 데이터베이스로부터 선별적으로 수집하여, 학습 영상(제1 데이터)를 생성할 수 있다 일 실시예에 따른 학습 DB 생성부는 학습 영상을 선별하기 위해 입력 영상에 대한 시청 정보 및 입력 영상 의 카테고리 정보를 이용할 수 있다. 학습 DB 생성부는 입력 영상이 속한 카테고리를 식별함으로써, 입력 영상의 카테고리에 속한 영상을 학습 영상으로 선별할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제3 뉴럴 네트워크를 이용하여, 입력 영상의 카테고리를 식별할 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크는 영상을 입력 받고, 입력된 영상으로부터 영상의 카테고리 를 분류하는 알고리즘, 또는 알고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집 합을 실행하는 하드웨어일 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크는 다양한 클래스 내지는 카테고리를 결과로 획득하기 위해 소프트맥 스 회귀(Softmax Regression) 함수를 이용할 수 있다. 소프트맥스 함수는 분류해야하는 정답지(클래스)가 여러 개인 경우, 즉, 다중 클래스를 예측할 때 이용될 수 있다. 소프트맥스 함수는 클래스의 총 개수를 k라고 할 때, k차원의 벡터를 입력 받아 각 클래스에 대한 확률을 추정할 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크(93 0)는 k차원의 벡터를 입력받고 이로부터 획득된 각 클래스에 대한 확률이 정답셋과 같아지도록 학습된 뉴럴 네 트워크일 수 있다. 다만, 이에 한정되는 것은 아니며, 제3 뉴럴 네트워크는 입력 영상으로부터 영상의 카 테고리를 분류할 수 있는 다양한 형태의 알고리즘으로 구현될 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크는 입력된 입력 영상의 카테고리 내지는 클래스에 대한 확률 값을 결 과로 획득할 수 있다. 예를 들어, 제3 뉴럴 네트워크는 입력 영상의 카테고리가 사람의 얼굴일 확률과 강 아지일 확률, 고양이일 확률, 건물일 확률을 각각 0.5, 0.2, 0.2, 0.1로 표현한 벡터를 결과 값으로 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 가장 확률 값이 높은 카테고리를 입력 영상의 카테고리로 식별할 수 있다. 예를 들어, 위 예에서, 학습 DB 생성부는 입력 영상의 카테고리가, 가장 벡터 값이 큰 카테고리인사람의 얼굴이라고 식별할 수 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상과 콘텐츠 특성과 유사한 영상들, 즉, 입력 영상과 동일한 카테고리 또는 유사한 카테고리에 포함된 영상을 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 입 력 영상과 유사한 카테고리에 포함된 영상을 외부 데이터베이스로부터 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 외부 데이터베이스가 아닌, 영상 처리 장치의 내부 메모리에 저장된 학습 영 상들 중에서 선별할 수도 있다. 일 실시예에 따른 외부 데이터베이스 또는 내부 메모리에는 다양한 종류의 카테고리를 갖는 영상들이 각 영상의 카테고리에 대한 인덱스 내지는 태그로 라벨링되어 저장되어 있을 수 있다. 학습 DB 생성부는 입력 영상과 유사한 카테고리의 인덱스로 식별되는 하나 이상을 영상을 외부 데이터베이 스로부터 획득하고, 이들을 포함하는 새로운 데이터베이스를 제1 데이터로 생성할 수 있다. 또는, 학습 DB 생성부는 입력 영상의 카테고리 중 확률 값이 높은 순서대로 기 정해진 수의 카테고리만을 식별하고, 식별된 카테고리에 속하는 영상들을 확률 값에 비례하여 획득할 수도 있다. 예를 들어, 학습 DB 생성 부는 제3 뉴럴 네트워크의 결과에 기초하여, 사람의 얼굴 영상, 강아지 영상, 고양이 영상을 외부 데 이터베이스로부터 각각 5:2:2의 비율로 획득할 수 있다. 학습 DB 생성부는 입력 영상에 대응한 하나 이상의 패치는 제1 데이터에 저장할 수 있다. 학습 DB 생성부는 입력 영상의 컨텐츠와 동일 유사한 컨텐츠 및 입력 영상으로부터 식별된 카테고리에 해 당하는 학습 영상을 포함하는 제1 데이터를 생성할 수 있다. 제1 데이터는 영상 처리 장치의 내 부 메모리에 저장될 수 있다. 제1 데이터에 속한 영상들은 메타 모델을 학습시키기 위한 고해상도 영상으 로 사용될 수 있다 도 10a는 일 실시예에 따른 학습 DB 생성부가 학습 데이터를 생성하는 동작의 일 예를 설명하기 위한 도면이다. 도 10a를 참조하면, 일 실시예에 따른 학습 DB 생성부는 제1 데이터에 포함된 영상들을 디그레이드 (degrade)하여 화질을 열화시킬 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 데이터에 포함된 영상들을 입력 영상의 품질 특성 및 시청 정보에 맞게 열화시킬 수 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상의 품질 값을 수신하고, 이에 대응하는 품질 값을 가지도록 수집한 영상들을 열화시킬 수 있다. 입력 영상의 품질 값은 따른 영상 처리 장치가 입력 영상의 화질을 분 석 또는 평가하여 획득한 품질 값일 수 있다. 일 실시예에 따른 입력 영상의 품질 값은 입력 영상의 블러 정도 를 나타내는 Kernel Sigma와 입력 영상의 압축 열화 정도를 나타내는 QF를 포함할 수 있다. 학습 DB 생성부 는 입력 영상과 동일한 정도의 블러와 압축 열화를 가지도록 제1 데이터에 포함된 영상들을 열화시킬 수 있다. 일 실시예에 따른 학습 DB 생성부는 입력 영상의 압축 정보를 수신하고, 이에 대응하는 압축 정보를 가지 도록 수집한 영상들을 열화시킬 수 있다. 입력 영상의 압축 정보는 입력 영상의 비트레이트 정보, 해상도 정보, 및 인코딩 정보 중 하나 이상을 포함할 수 있다. 학습 DB 생성부는 입력 영상과 동일한 정도의 비트레이트, 해상도, 또는 인코딩 정보를 가지도록 제1 데이터에 포함된 영상들을 열화시킬 수 있다. 예를 들어, 학습 DB 생성부는 제1 데이터에 포함된 영상들을 열화 하기 위해 필터링(Filtering)을 수 행할 수 있다. 학습 DB 생성부는 영상들에 블러 열화를 주기 위해서, 2차원 Kernel을 사용할 수 있다. 또 는 학습 DB 생성부는 움직임 열화를 모델링하기 위해 박스 블러(Box Blur)를 처리할 수 있다. 또는 학습 DB 생성부는 형태나 광학 블러를 주기 위해 가우시안(Gaussian) 필터를 사용할 수 있다. 또는 학습 DB 생 성부는 입력 영상의 압축 정보 중 해상도 정보를 기초로, 제1 데이터에 포함된 영상들을 다운 샘플링 (down sampling)할 수 있다. 일 실시예에 따른 학습 DB 생성부는 필터의 계수를 입력 영상이 가지는 블러에 맞추어서 조절할 수 있다. 열화는 일반적인 알려진 공간적 필터링을 통해서 수행되며, 신호 처리 분야의 저주파 통과 필터의 동작과 동일 할 수 있다. 구체적으로 열화는 2D Gaussian Kernel과의 Convolution 연산을 통해서 수행될 수 있다.일 실시예에 따른 학습 DB 생성부는 제1 데이터에 포함된 영상들을 화질 열화시킴으로써, 열화된 영 상들을 포함하는 제2 데이터를 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 데이터에 포함된 영상들과, 이들을 화질 열화시켜 생성한, 열화된 영상들을 포함하는 제2 데이터를 학습 데이터로 이용할 수 있다. 학습 DB 생성부는 제1 데이 터 및 제2 데이터를 전이 학습부에 전송할 수 있다. 일 실시예에 따른 전이 학습부는 제2 데이터에 포함된 화질 열화된 영상들을 메타 모델에 입력시켜, 메타 모델로부터 출력되는 영상과 제1 데이터에 포함된 화질 열화 전 영상들과의 차이가 최소가 되도록 메 타 모델의 파라미터를 업데이트할 수 있다. 도 10b는 일 실시예에 따른 학습 DB 생성부가 학습 데이터를 생성하는 동작의 일 예를 설명하기 위한 도면이다. 도 10b를 참조하면, 일 실시예에 따른 학습 DB 생성부는 제1 데이터에 포함된 영상들을 입력 영상의 시청 정보에 맞게 열화시킬 수 있다. 일 실시예에 따른 학습 DB 생성부는 주변 환경 및/또는 시청 거리에 기초하여 결정된 타겟 화질에 관한 정 보를 수신할 수 있다. 타겟 화질에 관한 정보는 영상의 선명도, 밝기, 대비 및 채도 중 하나 이상의 정보를 포 함할 수 있다. 학습 DB 생성부는 제1 데이터에 속한 학습 영상들의 화질을 조정함으로써, 화질 조정 된 영상을 생성할 수 있다. 예를 들어, 학습 DB 생성부는 선별된 학습 영상들의 선명도, 밝기, 대비, 및 채도 중 하나 이상의 비율을 증감함으로써, 화질 조정된 영상을 생성할 수 있다. 학습 DB 생성부는 선별된 학습 영상들의 선명도, 밝기, 대비, 및 채도 중 하나 이상의 비율이 증감한 영상들을 포함하는 제2 데이터 를 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 데이터에 포함된 영상들과, 이들을 화질 조정시켜 생성한 영 상들을 포함하는 제2 데이터를 학습 데이터로 이용할 수 있다. 학습 DB 생성부는 제1 데이터 및 제2 데이터를 전이 학습부에 전송할 수 있다. 일 실시예에 따른 전이 학습부는 제2 데이터에 포함된 화질 조정된 영상들을 메타 모델에 입력시켜, 메타 모델로부터 출력되는 영상과 제1 데이터에 포함된 화질 조정 전 영상들과의 차이가 최소가 되도록 메 타 모델의 파라미터를 업데이트할 수 있다. 도 11은 일 실시예에 따른 압축 과정에서 발생하는 열화를 학습 영상에 반영하는 방법을 설명하기 위한 도면이 다. 도 11을 참조하면, 로우 이미지 데이터(Raw image data)는 순서대로, 컬러 변환, 주파수 변환(DCT), 양자화 (Quantization), 부호화 코딩(Arithmetic Coding)을 거쳐 JPEG 압축 영상으로 인코딩될 수 있다. 인코딩된 영 상은 복호화, 역양자화(Dequantization), 역변환(Inverse DCT), 역 컬러변환 과정을 거쳐 복원될 수 있다. 일 실시예에 따른 학습 DB 생성부는 열화시킬 영상을 도 11에 도시된 순서대로 JPEG 인코딩 및 디코딩 하 여, 압축 열화된 영상을 획득할 수 있다. 인코딩/디코딩 과정에서 수행되는 엔트로피 코딩은 무손실 압축 방식이기 때문에, 엔트로피 코딩 및 엔트로피 디코딩 과정에서는 품질 열화가 발생하지 않는다. 따라서, 일 실시예에 따른 학습 DB 생성부는 열화시킬 영상에 대해 엔트로피 코딩 및 엔트로피 디코딩 과정은 생략하고, 도면 부호 1110으로 표기된 방법들만을 수행 하여, 압축 열화된 영상을 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 열화시킬 영상을 로우 이미지 데이터(Raw image data) 자리에 위치시 키고, 열화시킬 영상에 대해, 컬러 변환, 주파수 변환(DCT), 양자화(Quantization)를 수행하고, 양자화된 영상 을 역양자화(Dequantization), 역변환(Inverse DCT), 역 컬러변환하여, 압축 열화된 영상을 획득할 수 있다. 도 12는 일 실시예에 따른 메타 모델 획득부가 참고 모델을 이용하여 메타 모델을 획득하는 동작의 일 예를 설 명하기 위한 도면이다.도 12의 그래프는 품질 평면 그래프를 나타낸다. 품질 평면 그래프는 영상의 품질을 2개의 품질 요소로 나타낸 그래프로, 가로축은 품질 요소 1을 나타내고, 세로 축은 품질 요소 2를 나타낼 수 있다. 영상 처리 장치는 품질 분석부를 통해 실시간으로 입력 영상의 화질을 분석하여, 입력 영상의 품질 값을 획득할 수 있다. 입 력 영상의 품질 값은 도 12의 품질 평면 그래프 상에서 표현될 수 있다. 일 실시예에 따른 입력 영상의 화질 처리를 위한 메타 모델은 기 학습된 화질 처리 모델인 참고 모델에 기초하 여 생성될 수 있다. 참고 모델은 도 12의 품질 평면 그래프 상에서 표현될 수 있다. 일 실시예에 따른 품질 평면 그래프는 격자 형태로 N개의 포인트를 포함할 수 있다. 예를 들어, N개의 포인트들 각각에 대응하는 학습 영상들은 해당 품질을 가지도록 열화된 학습 영상들을 포함할 수 있다. 즉, 도 12의 그래 프에서 포인트들 각각은 각 포인트의 좌표 값에 해당하는 품질 값을 가지는 학습 영상들을 의미할 수 있다. 예 를 들어, 제1 포인트(Pt1)는 제1 포인트의 좌표 값(x1, y1)을 품질 값으로 가지는 학습 영상들을 의미하고, 제2 포인트(Pt2)는 제2 포인트의 좌표 값(x2, y1)을 품질 값으로 가지는 학습 영상들을 의미할 수 있다. 참고 모델을 생성하는 장치(참고 모델 생성 장치)는 열화 전 학습 영상들을 열화시켜 N개의 포인트들 각각에 대 한 학습 영상들을 생성할 수 있다. 참고 모델 생성 장치는 열화 전 학습 영상들과 열화 후 학습 영상들을 포함 하는 학습 데이터 셋을 이용하여, 화질 처리 모델을 훈련시킴으로써, 참고 모델을 생성할 수 있다. 예를 들어, 참고 모델 생성 장치는 열화 전 학습 영상들과 열화 전 학습 영상들을 제1 포인트(Pt 1)의 품질 값을 가지도록 열화시켜 획득한 학습 영상들을 학습 데이터로 이용하여, 화질 처리 모델을 학습시킴으로써, 제1 포인트(Pt1)에 대응하는 참고 모델 1을 생성할 수 있다. 참고 모델 1은 제1 포인트(Pt1)의 품질 값에 대응하는 열화 후 학습 영상들이, 열화 전 학습 영상들로 복원되도 록 학습된 화질 처리 모델일 수 있다. 또한, 참고 모델 1은 제1 포인트(Pt1)의 품질 값을 가지는 영상들의 화질 을 처리하기에 적합한 모델일 수 있다. 또한, 참고 모델 생성 장치는 열화 전 학습 영상들과 열화 전 학습 영상들을 제2 포인트(Pt2)의 품질 값을 가지 도록 열화시켜 획득한 학습 영상들을 학습 데이터 셋으로 이용하여, 화질 처리 모델을 학습시킴으로써, 제2 포 인트(Pt2)에 대응하는 참고 모델 2를 생성할 수 있다. 참고 모델 2는 제2 포인트(Pt2)의 품질 값에 대응하는 열화 후 학습 영상들이, 열화 전 학습 영상들로 복원되도 록 학습된 화질 처리 모델일 수 있다. 또한, 참고 모델 2는 제2 포인트(Pt2)의 품질 값을 가지는 영상들의 화질 을 처리하기에 적합한 모델일 수 있다. 일 실시예에 따른 참고 모델 생성 장치는 도 12에 도시된 격자 형태의 N개의 포인트들 각각에 대응하는 참고 모 델을 생성할 수 있다. 참고 모델 생성 장치는 균일 샘플링을 통해서 목표가 되는 학습 영상들의 품질 값의 위치 를 격자 형태의 N개의 포인트들 각각의 위치로 결정함으로써, N개의 참고 모델들이 균일한 간격의 품질 값을 갖 는 학습 영상들로 각각 학습되도록 할 수 있다. 다만, 이에 한정되는 것은 아니며, 참고 모델을 생성하는 장치는 학습 영상들의 품질 값 분포를 기반으로 참고 모델에 대응하는 품질 값을 결정할 수 있다. 예를 들어, 참고 모델 생성 장치는 학습 영상들을 분석하여, 학습 영상들의 품질 값을 획득하고, 학습 영상들의 품질 값의 통계적 분포를 통해서 대표 품질 샘플링 위치를 결정할 수 있다. 예를 들어, 참고 모델 생성 장치는 K-means clustering 알고리즘을 이용하여 대표 샘플링 위치를 결정 할 수 있다. K-means clustering 알고리즘은 데이터의 분포를 K개의 대표점으로 나타낼 경우 최소의 에러를 가 지는 지점을 찾는 알고리즘이다. 참고 모델 생성 장치는 학습 영상들의 품질 값 분포를 소정 개수, 예를 들어, K개의 클러스터(cluster)로 묶고, 각 클러스터에서 거리 차이의 분산이 최소가 되는 품질 값을 결정할 수 있다. 참고 모델 생성 장치는 결정된 품 질 값을 갖는 화질 열화 후 학습 영상들과, 그 영상들에 대응하는 화질 열화 전의 학습 영상들을 학습 데이터 셋으로 이용하여, 참고 모델을 학습시킬 수 있다. 이 경우, 높은 통계의 품질 값을 갖는 영상들을 학습 영상들 을 이용하여, 참고 모델을 학습시킬 수 있기 때문에, 참고 모델의 개수를 줄일 수 있다. 또한, 이와 같이 획득 된 참고 모델은 향후 메타 모델 생성 시에 이용 가능성이 보다 높아질 수 있다. 또한, 이와 같이 획득된 참고 모델을 이용하여 메타 모델을 생성할 경우, 연산 복잡도 및 메모리 사용량을 줄일 수 있다. 학습된 참고 모델들은 일 실시예에 따른 서버 또는 영상 처리 장치에 저장될 수 있다. 영상 처리 장치는 기 학습되어 저장되어 있는 참고 모델을 로딩하여 메타 모델을 획득할 수 있다. 보다 구 체적으로, 메타 모델 획득부는 기 학습된 참고 모델을 이용하여 실시간으로 메타 모델을 획득할 수 있다. 일 실시예에서, 메타 모델 획득부는 입력 영상의 품질 값에 적합한 메타 모델을 획득할 수 있다. 이를 위 해, 메타 모델 획득부는 품질 분석부가 판별한 입력 영상의 품질 값을 이용하여 입력 영상의 품질 값 과 유사한 품질 값을 갖는 학습 영상들로 학습된 참고 모델을 검색할 수 있다. 일 실시예에서, 메타 모델 획득부는 복수개의 참고 모델에 대응하는 화질 값과 입력 영상의 화질 값을 비 교하여 복수개의 참고 모델 중에서 하나 이상의 참고 모델을 검색할 수 있다. 일 실시예에서, 메타 모델 획득부는 거리 순으로 가장 가까운 최근접 참고 모델만 선택할 수도 있다. 예컨 대, 메타 모델 획득부는 입력 영상의 품질 값과 가장 가까운 품질 값을 갖는 학습 영상들로 학습된 참고 모델을 검색할 수 있다. 메타 모델 획득부는 참고 모델들을 학습시키는 데 이용된 학습 영상들의 품질 값 과 현재 입력되는 영상의 품질 값의 차이를 거리로 계산하여 거리 순으로 가까운 참고 모델을 검색할 수 있다. 일 실시예에서, 메타 모델 획득부는 복수개의 참고 모델 중에서, 입력 영상의 화질 값과의 차이가 기준 값 이내인 화질 값을 갖는 학습 영상들로 학습된 참고 모델들을 검색할 수 있다. 또는, 메타 모델 획득부는 복수개의 참고 모델 중에서, 입력 영상의 화질 값과의 차이가 가까운 순서대로 기 정해진 개수만큼의 화질 값을 갖는 학습 영상들로 학습된 참고 모델을 검색할 수도 있다. 도 12에서는 예컨대, 입력 영상이 별표 모양의 도형이 위치한 지점의 품질 값을 갖는다고 가정한다. 일 실시예 에서, 메타 모델 획득부는 도 10에 도시된 품질 평면 그래프 상에서, 별표 모양의 도형과 가까운 포인트, 즉, 입력 영상의 품질 값과 가까운 품질 값을 갖는 학습 영상들로 학습된 참고 모델을 검색할 수 있다. 도 12에 도시된 바와 같이, 입력 영상이 별표 모양이 표시된 지점의 품질 값을 가지는 경우, 메타 모델 획득부 는 도 12의 그래프 상에서 별표 모양과 가까운 포인트, 즉, 입력 영상의 품질 값과 가까운 품질 값을 가지 는 학습 영상들로 학습된 참고 모델을 검색할 수 있다. 메타 모델 획득부는 별표 모양과 가까운 제1 포인트(Pt1)에 대응하는 참고 모델 1, 제2 포인트(Pt2)에 대 응하는 참고 모델 2, 제3 포인트(Pt3)에 대응하는 참고 모델 3, 제4 포인트(Pt4)에 대응하는 참고 모델 4를 검 색 또는 선택할 수 있다. 도 12에서 메타 모델 획득부가 입력 영상의 품질 값을 이용하여 검색한 참고 모 델은 빗금친 포인트로 표현되어 있다. 메타 모델 획득부는 검색된 복수개의 참고 모델들을 보간(interpolation)하여 메타 모델을 획득할 수 있다. 복수개의 참고 모델들을 보간한다는 것은, 알려진 참고 모델들의 파라미터를 보간하여 메타 모델의 파라 미터로 이용하는 것을 의미할 수 있다. 메타 모델 획득부는 제1 영상의 품질 값과 참고 모델에 대응하는 품질 값의 차이(별표 모양의 위치와 참고 모델에 대응하는 품질 값의 위치 사이의 거리)를 이용하여, 가중치(보 간 계수)를 획득할 수 있다. 예를 들어, 메타 모델 획득부는 다음의 수학식 1과 같이 참고 모델들을 보간하여, 메타 모델을 획득할 수 있다. [수학식 1] 메타 모델 = W1 * 참고 모델 1 + W2 * 참고 모델 2 + … + WN * 참고 모델N 여기서, 참고 모델 1 내지 참고 모델 N은 참고 모델의 파라미터를 의미할 수 있다. W1 내지 WN은 각 참고 모델 에 적용되는 가중치이며, 가중치는 선택된 참고 모델들에 대응하는 품질 값과 입력 영상의 품질 값의 차이(별표 모양의 위치와 참고 모델에 대응하는 품질 값의 위치 사이의 거리)에 반비례하는 값으로 결정될 수 있다. 예컨 대, 가중치는 '1/(거리)'로 표현될 수 있다. 가중치들의 합은 1일 수 있다. 예컨대, 참고 모델에 대응하는 품 질 값과 입력 영상의 품질 값의 차이가 클수록 그 참고 모델에 부여되는 가중치 값은 작아지고, 참고 모델에 대 응하는 품질 값과 입력 영상의 품질 값의 차이가 작을수록 그 참고 모델에 부여되는 가중치 값은 커질 수 있다. 다만, 이에 한정되는 것은 아니며, 메타 모델 획득부는 복수개의 참고 모델들을 보간하여 메타 모델을 획 득하기 위해 다양한 방법을 이용할 수 있다. 예를 들어, 메타 모델 획득부는 선형 보간법, spline 보간법, 삼차 보간법(cubic interpolation), 선형 보간법을 2차원으로 확장시킨 쌍선형보간법 (bilinear interpolation), 삼차 보간법을 2차원으로 확장시킨 쌍삼차보간법(bicubic interpolation) 등 다양한 보간 방 법을 이용하여 참고 모델로부터 메타 모델을 획득할 수 있다.도 13은 일 실시예에 따른 메타 모델 획득부가 참고 모델을 이용하여 메타 모델을 획득하는 동작의 일 예를 설 명하기 위한 도면이다. 도 13의 그래프는 3차원 품질 평면 그래프를 나타낸다. 3차원 품질 평면 그래프는 영상의 품질을 2개의 품질 요 소와 1개의 시청 정보로 나타낸 그래프로, x축은 품질 요소 1을 나타내고, y 축은 품질 요소 2를 나타내고, z축 은 시청 정보를 나타낼 수 있다. 도 13의 그래프에서, 시청 정보는 컨텐츠 특성, 예컨대 컨텐츠의 종류 및 컨텐 츠의 장르인 것으로 예시하였으나, 이에 제한되지 않는다. 참고 모델 생성 장치는 컨텐츠의 종류 및 장르 별로 분류된 열화 전 학습 영상들을 열화시켜 N개의 포인트들 각 각에 대한 학습 영상들을 생성할 수 있다. 참고 모델 생성 장치는 열화 전 학습 영상들과 열화 후 학습 영상들 을 포함하는 학습 데이터를 이용하여, 화질 처리 모델을 훈련시킴으로써, 참고 모델을 생성할 수 있다. 참고 모 델은 서로 다른 종류의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델, 및 서로 다른 장르의 컨텐츠 에 해당하는 학습 영상들로 학습된 화질 처리 모델 중 적어도 하나를 포함할 수 있다. 예를 들어, 참고 모델 생성 장치는 컨텐츠 종류 및 장르 별로 분류된 열화 전 학습 영상들과 열화 전 학습 영상 들을 열화시켜 획득한 학습 영상들을 학습 데이터로 이용하여, 화질 처리 모델을 학습시킴으로써, 제5 포인트 (Pt5)에 대응하는 참고 모델 5를 생성할 수 있다. 참고 모델 5는 제5 포인트(Pt5)에 대응하는 컨텐츠의 영상들 의 화질을 처리하기에 적합한 모델일 수 있다. N개의 포인트들의 z축 값(z1)은 컨텐츠의 종류, 예컨대 스트리밍 컨텐츠, 방송 컨텐츠, 블루레이 디스크, 또는 콘솔 게임 등에 따라 결정될 수 있다. N개의 포인트들의 z축 값 (z1)은 컨텐츠의 장르, 예컨대 뉴스, 스포츠, 드라마, 다큐멘터리, 예능, 게임, 영화, 화상 통화에 따라 결정될 수 있다. 일 실시예에서, 메타 모델 획득부는 참고 모델을 검색하는 데에 시청 정보를 더 이용할 수 있다. 예를 들 어, 메타 모델 획득부는 복수개의 참고 모델 각각을 학습하는 데 이용된 학습 영상들의 컨텐츠 특성과 입 력 영상의 컨텐츠 특성을 비교하여, 입력 영상의 컨텐츠 특성과 일치하는 컨텐츠에 해당하는 학습 영상으로 학 습된 참고 모델을 검색할 수 있다. 컨텐츠 특성이 일치한다는 것은 컨텐츠의 종류 또는 컨텐츠의 장르가 서로 동일하거나 유사한 것을 포함할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 컨텐츠가 스트리밍 컨 텐츠인 경우, 스트리밍 컨텐츠에 해당하는 학습 영상으로 학습된 참고 모델을 검색할 수 있다. 예를 들어, 영상 처리 장치는 입력 영상의 컨텐츠의 장르가 화상 통화인 경우, 인물 위주의 학습 영상으로 학습된 참고 모 델을 검색할 수 있다. 일 실시예에서, 메타 모델 획득부는 검색된 참고 모델이 복수개인 경우, 복수개의 참고 모델을 인터폴레이 션(interpolation)하여, 메타 모델을 획득할 수 있다. 일 실시예에서, 메타 모델 획득부는 검색된 복수개 의 참고 모델 각각에 가중치를 부여하고, 가중치가 부여된 각각의 참고 모델을 가중 합(weighted sum)하여 메타 모델을 획득할 수 있다. 또한, 일 실시예에서, 수학식 1의 W1 내지 WN에 해당하는 참고 모델의 가중치는 참고 모델에 대응하는 컨텐츠의 종류 또는 컨텐츠의 장르와 입력 영상의 컨텐츠의 종류 또는 컨텐츠의 장르 간의 차이에 따라 결정될 수 있다. 예컨대, 입력 영상이 스트리밍 컨텐츠에 해당하는 경우, 그래픽 컨텐츠에 대응하는 참고 모델에 부여되는 가중 치 값은 작을 수 있다. 예컨대, 입력 영상이 화상 통화 장르에 해당하는 경우, 영화 장르 또는 드라마 장르에 대응하는 참고 모델에 부여되는 가중치 값은 클 수 있다. 다만, 이에 한정되는 것은 아니며, 메타 모델 획득부는 품질 요소 1과 시청 정보로 나타낸 2차원 품질 평 면 그래프에서 메타 모델을 획득할 수도 있다. 도 14는 일 실시예에 따른 모델 학습부의 동작을 설명하기 위한 도면이다. 도 14에 도시된 모델 학습부(320a)는 도 3의 모델 학습부의 일 예일 수 있다. 도 8에서 설명한 내용과 중 복되는 설명은 생략한다. 도 11을 참조하면, 모델 학습부(320a)는 학습 DB 생성부, 메타 모델 획득부, 전이 학습부 및 모 델 안정화부를 포함할 수 있다. 모델 학습부(320a)는 도 8의 모델 학습부와 달리 모델 안정화부(32 6)를 더 포함할 수 있다.일반적인 선형 시스템에서는 입력에 따른 출력이 예측 가능하나 딥러닝 모델에서는 학습 조건 및 초기 값에 따 라서 출력을 정확하게 예측하는 것이 불가능하다. 따라서, 품질 분석부가 영상의 화질을 평균화하는 것 만 으로는 화질 간 급격한 변화로 인해 발생하는 플리커(Flickering) 현상을 막기 어려울 수 있다. 특히 이미지 단 위 학습 방법들을 동영상에 적용할 경우, 화질 복원을 수행하는 전이 모델의 성능 편차로 인해서 연속된 영상들 간에 화질 차이로 인한 깜박임이 발생할 수 있다. 온 디바이스 러닝 시스템에서는 입력 환경의 변화에 따라 매 번 학습이 이뤄지기 때문에 모델의 안정적인 업데이트는 시스템의 안정화에 매우 중요한 요소이다. 일 실시예에서, 영상 처리 장치는 동영상에 포함된 영상들 간에 화질이 급변하는 문제를 해결하기 위해 모 델 안정화부를 이용하여 프레임 별 전이 모델의 성능 편차를 조절할 수 있다. 일 실시예에서, 모델 안정화부는 전이 모델들 간의 이동 평균 방법을 이용하여 전이 모델들을 안정화시킬 수 있다. 일 실시예에서, 모델 안정화부는 전이 모델들의 파라미터들을 평균하는 방법을 이용하여 전이 모 델들을 안정화시킬 수 있다. 일 실시예에서, 모델 안정화부는 단순 이동 평균이나 지수 이동 평균 방법을 사용하여 전이 모델들을 평균할 수 있다. 일 실시예에서, 모델 안정화부는 입력 영상을 기반으로 획득되어 학습된 메타 모델과, 이를 실제 입력 영 상에 적용하는 적용 모델을 구분하여, 현재 시점에 획득되어 학습된 메타 모델과 과거 시점에 획득되어 학습된 메타 모델을 이용하여 현재 시점의 입력 영상에 적용할 적용 모델을 획득할 수 있다. 예컨대, 모델 안정화부는 현재 입력된 영상에 대해 생성된 메타 모델과 과거에 입력된 영상들에 대해 생성 된 메타 모델들을 단순 이동 평균(Simple Moving Average)하여, 이를 현재 영상에 적용할 적용 모델로 구할 수 있다. 일 실시예에서, 모델 안정화부는 제1 시점에 획득되어 학습된 메타 모델 및 제1 시점 이전의 과거 시점에 획득되어 학습된 메타 모델들을 평균하여 제1 시점의 현재 영상에 적용할 적용 모델로 획득할 수 있다. 또는, 모델 안정화부는 과거에 획득된 메타 모델과 현재 입력 영상에 대해 구해진 메타 모델을 평균하는 지수 이동 평균(Exponential Moving Average) 방법을 이용하여, 현재 영상에 적용할 메타 모델을 구할 수 있다. 일 실시예에서, 모델 안정화부는 제1 시점 (t 시점)에 획득되어 학습된 메타 모델 및 t 시점 이전의 과거 시점의 과거 입력 영상에 적용한 메타 모델을 함께 고려하여, t 시점 지수 이동 평균 모델을 획득할 수 있다. t 시점 지수 이동 평균 모델은 t 시점에 입력되는 입력 영상에 실제 적용되어 화질 처리를 수행하는 메타 모델을 의미할 수 있다. 예컨대, 모델 안정화부는 아래 수학식 2를 이용하여 t 시점 지수 이동 평균 모델을 획득할 수 있다. [수학식 2] t 시점 지수 이동 평균 모델 = α * (t 시점에 학습된 모델) + (1-α)* (t-1 시점 지수 이동 평균 모델) 여기서 α(알파)는 수렴 속도나, 시스템의 안정성에 따라 결정될 수 있다. 수학식 2의 모델들은 메타 모델의 파 라미터 값의 집합이며 모델의 파라미터 값은 필터 가중치(weight)와 바이어스(bias)의 값들을 포함할 수 있다. 수학식 2는 아래와 같이 재배열되어 수학식 3으로 표현될 수 있다. [수학식 3] t 시점 지수 이동 평균 모델 = t-1 시점에 사용된 모델 + α * δ, 여기서, δ(델타 모델)= (t 시점에 학습된 모델) - (t-1시점 지수 이동 평균 모델)을 의미할 수 있다. 이는 과거 모델에 α 만큼의 δ(델타 모델)가 점진적으로 더해져서 업데이트는 되는 방식을 의미할 수 있다. 이 경우 모델 업데이트를 위한 곱셈 연산기의 수가 반으로 줄어드는 효과가 있어서 전력 소모가 감소될 수 있다. α 의 값은 다양한 조건에 따라서 고정값으로 사용될 수도 있으며, Scene의 변화, 컨텐츠의 변화 등에 의해서 새롭게 초기화 되거나 변화 가능하다. 일 실시예에서, 화질 처리부는 모델 안정화부에 의해 획득된 t 시점 지수 이동 평균 모델을 t 시점의 입력 영상에 적용하여 출력 영상을 획득할 수 있다. 즉, 일 실시예에서, 모델 안정화부는 t 시점의 입력 영상에 t 시점에 획득되어 학습된 메타 모델을 적용하는 대신, t 시점 지수 이동 평균 모델을 적용하여 입력 영상의 화질을 처리함으로써, 입력 영상에 대해 화질 처리된 출력 영상이 이전 시점에 출력된 영상들과 급격한 화 질 차이를 보이지 않도록 화질 안정화를 수행할 수 있다. 도 15는 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 블록도이다. 도 15를 참조하면, 도 11을 참조하면, 일 실시예에 따른 영상 처리 장치는 프로세서, 메모리, 및 통신부를 포함할 수 있다. 일 실시예에 따른 통신부는 외부 장치 또는 서버와 데이터 또는 신호를 송수신할 수 있다. 예를 들어, 통 신부는 와이-파이(Wi-Fi) 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈, LAN 모듈, 이더넷 (Ethernet) 모듈, 유선 통신 모듈 등을 포함할 수 있다. 이때, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태 로 구현될 수 있다. 와이 파이 모듈, 블루투스 모듈은 각각 Wi-Fi 방식, 블루투스 방식으로 통신을 수행한다. 와이 파이 모듈이나 블루투스 모듈을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하고, 이를 이용 하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신 모듈은 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation) 등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통 신 칩을 포함할 수 있다. 일 실시예에 따른 통신부는 서버로 모델 저장 조건을 전송할 수 있다. 일 실시예에 따른 통신부(10 3)는 서버로부터 모델 저장 조건에 대응하는 참고 모델을 수신할 수 있다. 일 실시예에 따른 프로세서는 영상 처리 장치의 전반적인 동작 및 영상 처리 장치의 내부 구성 요소들 사이의 신호 흐름을 제어하고, 데이터를 처리하는 기능을 수행한다. 프로세서는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 또한, 프로세서는 복수의 프로세서들을 포함할 수 있다. 예를 들어, 프로세서는 메인 프로세서(main processor, 도시되지 아니함) 및 서브 프로세서(sub processor, 도시되지 아니함)로 구현될 수 있다. 또한, 프로세서는 CPU(Cetral Processing Unit), GPU (Graphic Processing Unit) 및 VPU(Video Processing Unit) 중 적어도 하나를 포함할 수 있다. 또는, 실시예에 따라, CPU, GPU 및 VPU 중 적어도 하나를 통합한 SoC(System On Chip) 형태로 구현될 수 있다. 또는, 프로세서는 NPU(Neural Processing Unit)를 더 포함할 수 있다. 일 실시예에 따른 메모리는 영상 처리 장치를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 또한, 메모리에 저장되는 프로그램은 하나 이상의 인스트럭션들을 포함할 수 있다. 메모리에 저장된 프로그램(하나 이상의 인스트럭션들) 또는 어플리케이션은 프로세서에 의해 실행될 수 있다. 일 실시예에 따른 프로세서는 도 3의 품질 분석부, 모델 학습부, 화질 처리부 및 시청 정 보 수집부를 포함할 수 있으며, 품질 분석부, 모델 학습부, 화질 처리부 및 시청 정보 수 집부의 동작들을 수행할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 입력 영상 의 품질 및 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득한다. 일 실시예에 따른 프로세서 는 입력 영상의 품질 및 시청 정보에 기초하여 학습 데이터를 생성한다. 일 실시예에 따른 프로세서는 학 습 데이터를 이용하여 신경망 모델을 학습시킨다. 일 실시예에 따른 프로세서는 학습된 신경망 모델을 기 반으로, 입력 영상으로부터 화질 처리된 출력 영상을 획득한다. 일 실시예에 따른 시청 정보는 입력 영상의 해상도 정보, 비트레이트 정보, 인코딩 정보, 컨텐츠의 종류, 컨텐 츠의 장르, 주변 환경, 시청 거리, 사용자 정보 또는 하나 이상의 시청 정보의 조합을 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 입력 영상 의 컨텐츠의 종류 및/또는 컨텐츠의 장르를 포함하는 시청 정보에 기초하여, 컨텐츠의 종류 및/또는 컨텐츠의 장르에 해당하는 학습 영상을 제1 데이터로 획득할 수 있다. 일 실시예에 따른 프로세서는제1 데이터에 속한 학습 영상이 입력 영상의 품질 값에 대응하는 화질을 갖도록 화질 열화된 영상을 제2 데이터로 획득할 수 있 다. 학습 데이터는 제1 데이터 및 제2 데이터를 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 입력 영상 의 시청 정보에 대응하는 입력 영상의 비트레이트 정보, 해상도 정보, 및 인코딩 정보 중 하나 이상의 압축 정 보를 획득할 수 있다. 일 실시예에 따른 프로세서는 입력 영상의 압축 화질, 블러 화질, 및 노이즈 중 하 나 이상의 품질 값을 획득할 수 있다. 일 실시예에 따른 프로세서는 입력 영상의 품질 값 및 압축 정보에 기초하여 입력 영상을 화질 처리함으로써, 화질 열화된 영상을 획득할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 하나 이상 의 센서를 통해 시청 정보에 대응하는 주변 환경 및/또는 시청 거리를 획득할 수 있다. 일 실시예에 따른 프로 세서는 주변 환경 및/또는 시청 거리에 기초하여 영상의 타겟 화질을 결정할 수 있다. 일 실시예에 따른 프로세서는 타겟 화질에 기초하여 입력 영상의 화질을 조정함으로써, 학습 데이터를 생성할 수 있다. 영상 의 타겟 화질은 선명도, 밝기, 대비, 및 채도 중 하나 이상의 화질을 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 신경망 모 델에 제2 데이터에 속한 화질 열화된 영상을 입력시킴에 따라 출력된 영상과 제1 데이터에 속한 학습 영상의 차 이가 최소가 되도록 신경망 모델을 학습시킬 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 입력 영상 의 품질 및 입력 영상에 대한 시청 정보에 대응하여 복수개의 참고 모델을 통해 신경망 모델을 획득할 수 있다. 일 실시예에 따른 복수개의 참고 모델은 서로 다른 품질 값을 갖는 학습 영상들에 기초하여 학습된 화질 처리 모델, 서로 다른 종류의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델, 및 서로 다른 장르의 컨텐츠 에 해당하는 학습 영상들로 학습된 화질 처리 모델 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 복수개의 참고 모델에 대응하는 컨텐츠의 종류 및/또는 컨텐츠의 장르와 입력 영상의 컨텐츠의 종류 및/또는 컨텐츠의 장 르를 비교하여 복수개의 참고 모델 중 하나 이상의 참고 모델을 검색할 수 있다. 일 실시예에 따른 프로세서 는 검색된 참고 모델을 이용하여 신경망 모델을 획득할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 복수개의 참고 모델에 대응하는 품질 값과 입력 영상의 품질 값을 비교하여 복수개의 참고 모델 중 하나 이상의 참고 모 델을 검색할 수 있다. 일 실시예에 따른 프로세서는 검색된 참고 모델을 이용하여 신경망 모델을 획득할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 검색된 참 고 모델이 복수개인 것에 기반하여, 검색된 복수개의 참고 모델 각각에 가중치를 부여할 수 있다. 일 실시예에 따른 프로세서는 가중치가 부여된 각각의 참고 모델을 가중 합(weighted sum)하여 신경망 모델을 획득할 수 있다. 일 실시예에 따른 프로세서는 가중치는 참고 모델에 대응하는 품질 값과 입력 영상의 품질 값 간 의 차이에 따라 결정될 수 있다. 일 실시예에 따른 영상 처리 장치의 동작 방법은 입력 영상의 품질 및 입력 영상에 대한 시청 정보에 대응 하여 신경망 모델을 획득하는 단계, 입력 영상의 품질 및 시청 정보에 기초하여 학습 데이터를 생성하는 단계, 학습 데이터를 이용하여 신경망 모델을 학습시키는 단계, 및 학습된 신경망 모델을 기반으로, 입력 영상으로부 터 화질 처리된 출력 영상을 획득하는 단계를 포함한다. 일 실시예에 따른 입력 영상의 품질 및 시청 정보에 기초하여 학습 데이터를 생성하는 단계는, 입력 영상의 컨 텐츠의 종류 및/또는 컨텐츠의 장르를 포함하는 시청 정보에 기초하여, 컨텐츠의 종류 및/또는 컨텐츠의 장르에 해당하는 학습 영상을 제1 데이터로 획득하는 단계, 및 제1 데이터에 속한 학습 영상이 입력 영상의 품질 값에 대응하는 화질을 갖도록 화질 열화된 영상을 제2 데이터로 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 입력 영상의 품질 및 시청 정보에 기초하여 학습 데이터를 생성하는 단계는, 입력 영상의 시 청 정보에 대응하는 입력 영상의 비트레이트 정보, 해상도 정보, 및 인코딩 정보 중 하나 이상의 압축 정보를 획득하는 단계, 입력 영상의 압축 화질, 블러 화질, 및 노이즈 중 하나 이상의 품질 값을 획득하는 단계, 및 입 력 영상의 품질 값 및 압축 정보에 기초하여 입력 영상을 화질 처리함으로써, 화질 열화된 영상을 획득하는 단 계를 포함할 수 있다.일 실시예에 따른 입력 영상의 품질 및 시청 정보에 기초하여 학습 데이터를 생성하는 단계는, 하나 이상의 센 서를 통해 시청 정보에 대응하는 주변 환경 및/또는 시청 거리를 획득하는 단계, 주변 환경 및/또는 시청 거리 에 기초하여 영상의 타겟 화질을 판단하는 단계, 및 타겟 화질에 기초하여 입력 영상의 화질을 조정함으로써, 학습 데이터를 생성하는 단계를 포함할 수 있다. 영상의 타겟 화질은 선명도, 밝기, 대비, 및 채도 중 하나 이 상의 화질을 포함할 수 있다. 일 실시예에 따른 학습 데이터를 이용하여 신경망 모델을 학습시키는 단계는, 신경망 모델에 제2 데이터에 속한 화질 열화된 영상을 입력시킴에 따라 출력된 영상과 제1 데이터에 속한 학습 영상의 차이가 최소가 되도록 신경 망 모델을 학습시키는 단계를 포함할 수 있다. 일 실시예에 따른 입력 영상의 품질 및 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하는 단계는, 입력 영상의 품질 및 입력 영상에 대한 시청 정보에 대응하여 복수개의 참고 모델을 통해 신경망 모델 을 획득하는 단계를 포함할 수 있다. 복수개의 참고 모델은 서로 다른 품질 값을 갖는 학습 영상들에 기초하여 학습된 화질 처리 모델, 서로 다른 종류의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델, 및 서로 다른 장르의 컨텐츠에 해당하는 학습 영상들로 학습된 화질 처리 모델 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 입력 영상의 품질 및 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하는 단계는, 복수개의 참고 모델에 대응하는 컨텐츠의 종류 및/또는 컨텐츠의 장르와 입력 영상의 컨텐츠의 종류 및 /또는 컨텐츠의 장르를 비교하여 복수개의 참고 모델 중 하나 이상의 참고 모델을 검색하는 단계, 및 검색된 참 고 모델을 이용하여 신경망 모델을 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 입력 영상의 품질 및 입력 영상에 대한 시청 정보에 대응하여 신경망 모델을 획득하는 단계는, 복수개의 참고 모델에 대응하는 품질 값과 입력 영상의 품질 값을 비교하여 복수개의 참고 모델 중 하 나 이상의 참고 모델을 검색하는 단계, 및 검색된 참고 모델을 이용하여 신경망 모델을 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 검색된 참고 모델을 이용하여 신경망 모델을 획득하는 단계는, 검색된 참고 모델이 복수개인 것에 기반하여, 검색된 복수개의 참고 모델 각각에 가중치를 부여하는 단계, 및 가중치가 부여된 각각의 참고 모델을 가중 합(weighted sum)하여 신경망 모델을 획득하는 단계를 포함할 수 있다. 가중치는 참고 모델에 대응 하는 품질 값과 입력 영상의 품질 값 간의 차이에 따라 결정될 수 있다. 도 16은 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 상세 블록도이다. 도 16의 영상 처리 장치는 도 15의 영상 처리 장치의 일 실시예일 수 있다. 도 16을 참조하면, 일 실시예에 따른 영상 처리 장치는, 튜너부, 프로세서, 디스플레이부 , 통신부, 감지부, 입/출력부, 센서, 비디오 처리부, 오디오 처리부 , 오디오 출력부, 메모리, 전원부를 포함할 수 있다. 도 16의 통신부는 도 15의 통신부에, 도 16의 프로세서는, 도 15의 프로세서에 도 16의 메모리는 도 15의 메모리에 대응하는 구성일 수 있다. 따라서, 앞에서 설명한 내용과 동일한 내용은 생략하기로 한다. 일 실시예에 따른 디스플레이부는 프로세서에서 처리된 영상 신호, 데이터 신호, OSD 신호, 제어 신호 등을 변환하여 구동 신호를 생성한다. 디스플레이부는 PDP, LCD, OLED, 플렉시블 디스플레이 (flexible display)등으로 구현될 수 있으며, 또한, 3차원 디스플레이(3D display)로 구현될 수 있다. 또한, 디스플레이부는, 터치 스크린으로 구성되어 출력 장치 이외에 입력 장치로 사용되는 것도 가능하다. 일 실시예에 따른 튜너부는 유선 또는 무선으로 수신되는 방송 신호를 증폭(amplification), 혼합 (mixing), 공진(resonance)등을 통하여 많은 전파 성분 중에서 영상 처리 장치에서 수신하고자 하는 채널 의 주파수만을 튜닝(tuning)시켜 선택할 수 있다. 방송 신호는 오디오(audio), 비디오(video) 및 부가 정보(예 를 들어, EPG(Electronic Program Guide))를 포함한다. 튜너부는 지상파 방송, 케이블 방송, 위성 방송, 인터넷 방송 등과 같이 다양한 소스로부터 방송 신호를 수신할 수 있다. 튜너부는 아날로그 방송 또는 디지털 방송 등과 같은 소스로부터 방송 신호를 수신할 수 도 있다.일 실시예에 따른 통신부는 외부 제어 장치로부터 제어 신호 또는 제어 명령 등을 수신할 수 있다. 예를 들어, 통신부는 IR 통신 규격에 따라 외부 제어 장치와 신호를 송수신할 수 있는 IR 모듈을 포함할 수 있 다. 구체적으로, 통신부는 제어 장치로부터 사용자 입력(예를 들어, 제어 장치의 키 또는 버튼 입력 등) 에 대응하는 제어 신호 또는 제어 명령 등을 수신할 수 있다. 일 실시예에 따른 영상 처리 장치는 통신부 를 통해 네트워크에 연결되어 스트리밍 서버에 연결될 수 있다. 일 실시예에 따른 감지부는 사용자의 음성, 사용자의 영상 또는 사용자의 인터랙션을 감지하며, 마이크 , 카메라부 및 광 수신부를 포함할 수 있다. 마이크는 사용자의 발화(utterance)된 음성을 수신한다. 마이크는 수신된 음성을 전기 신호로 변 환하여 프로세서로 출력할 수 있다. 사용자 음성은 예를 들어, 영상 처리 장치의 메뉴 또는 기능 에 대응되는 음성을 포함할 수 있다. 예를 들어, 마이크는 디스플레이의 회전 명령에 대응하는 사용자 음 성을 수신하고, 수신된 음성을 전기 신호로 변환하여 프로세서로 출력할 수 있다. 카메라부는 카메라 인식 범위에서 제스처를 포함하는 사용자의 모션에 대응되는 영상(예를 들어, 연속되 는 프레임)을 수신할 수 있다. 프로세서는 수신된 모션의 인식 결과를 이용하여 영상 처리 장치에 표시되는 메뉴를 선택하거나 모션 인식 결과에 대응되는 제어를 할 수 있다. 예를 들어, 프로세서는 카메 라부로부터 영상을 수신하여, 수신한 영상으로부터 디스플레이의 회전에 대응하는 사용자의 모션을 인식 하고, 이에 대응하여, 디스플레이를 회전시킬 수 있다. 광 수신부는 외부의 제어 장치에서부터 수신되는 광 신호(제어 신호를 포함)를 디스플레이부의 베 젤의 광창(도시되지 아니함) 등을 통해 수신한다. 광 수신부는 제어 장치로부터 사용자 입력(예를 들어, 터치, 눌림, 터치 제스처, 음성, 또는 모션)에 대응되는 광 신호를 수신할 수 있다. 수신된 광 신호로부터 프 로세서의 제어에 의해 제어 신호가 추출될 수 있다. 일 실시예에 따른 입/출력부는, 영상 처리 장치의 외부에서부터 비디오(예를 들어, 동영상 등), 오 디오(예를 들어, 음성, 음악 등) 및 부가 정보(예를 들어, EPG 등) 등을 수신할 수 있다. 입/출력부는 HDMI (High-Definition Multimedia Interface), MHL(Mobile High-Definition Link), USB(Universal Serial Bus), DP(Display Port), 썬더볼트(Thunderbolt), VGA(Video Graphics Array) 포트, RGB 포트, D-SUB(D- subminiature), DVI(Digital Visual Interface), 컴포넌트 잭(component jack), PC 포트(PC port) 중 어느 하 나를 포함할 수 있다. 일 실시예에 따른 영상 처리 장치는 입/출력부를 통해 셋톱 박스, 게임 콘솔, PC 등에 연결될 수 있다. 일 실시예에 따른 센서는 영상 처리 장치의 주변 환경을 감지할 수 있다. 센서는 거리 센서 및 조도 센서를 포함할 수 있다. 거리 센서는 초음파 센서, IR(Infrared Radiation) 센서, TOF(Time Of Flight) 센서 등 영상 처리 장치 와 사용자와의 거리를 감지하는 다양한 센서를 포함할 수 있다. 거리 센서는 사용자와의 거리를 감 지하며, 센싱 데이터를 프로세서로 전달할 수 있다. 센싱 데이터는 시청 정보 수집부에서 수집될 수 있다. 조도 센서는 주변 조도를 감지할 수 있다. 조도 센서는 주변 빛의 양을 감지하여, 주변 밝기를 감 지할 수 있다. 조도 센서는 센싱 데이터를 프로세서로 전달할 수 있다. 센싱 데이터는 시청 정보 수집부에서 수집될 수 있다. 프로세서는 영상 처리 장치의 전반적인 동작 및 영상 처리 장치의 내부 구성 요소들 사이의 신호 흐름을 제어하고, 데이터를 처리하는 기능을 수행한다. 프로세서는 사용자의 입력이 있거나 기 설정 되어 저장된 조건을 만족하는 경우, 메모리에 저장된 OS(Operation System) 및 다양한 애플리케이션을 실 행할 수 있다. 프로세서는 영상 처리 장치의 외부에서부터 입력되는 신호 또는 데이터를 저장하거나, 영상 처리 장치에서 수행되는 다양한 작업에 대응되는 저장 영역으로 사용되는 램(RAM), 영상 처리 장치의 제 어를 위한 제어 프로그램이 저장된 롬(ROM) 및 프로세서(Processor)를 포함할 수 있다. 비디오 처리부는, 영상 처리 장치가 수신한 비디오 데이터에 대한 처리를 수행한다. 비디오 처리부 에서는 비디오 데이터에 대한 디코딩, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 해상도 변환 등과 같은 다양한 이미지 처리를 수행할 수 있다.오디오 처리부는 오디오 데이터에 대한 처리를 수행한다. 오디오 처리부에서는 오디오 데이터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 한편, 오디오 처리부는 복수의 컨텐츠에 대응되는 오디오를 처리하기 위해 복수의 오디오 처리 모듈을 구비할 수 있다. 오디오 출력부는 프로세서의 제어에 의해 튜너부를 통해 수신된 방송 신호에 포함된 오디오 를 출력한다. 오디오 출력부는 통신부 또는 입/출력부를 통해 입력되는 오디오(예를 들어, 음성, 사운드)를 출력할 수 있다. 또한, 오디오 출력부는 프로세서의 제어에 의해 메모리에 저장된 오디오를 출력할 수 있다. 오디오 출력부는 스피커, 헤드폰 출력 단자 또는 S/PDIF(Sony/Philips Digital Interface: 출력 단자 중 적어도 하나를 포함할 수 있다. 전원부는 프로세서의 제어에 의해 영상 처리 장치 내부의 구성 요소들로 외부의 전원 소스에 서부터 입력되는 전원을 공급한다. 또한, 전원부는 프로세서의 제어에 의해 영상 처리 장치 내부에 위치하는 하나 또는 둘 이상의 배터리(도시되지 아니함)에서부터 출력되는 전원을 내부의 구성 요소들에 게 공급할 수 있다. 메모리는 프로세서의 제어에 의해 영상 처리 장치를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 메모리는 도시되지 아니한 방송 수신 모듈, 채널 제어 모 듈, 볼륨 제어 모듈, 통신 제어 모듈, 음성 인식 모듈, 모션 인식 모듈, 광 수신 모듈, 디스플레이 제어 모듈, 오디오 제어 모듈, 외부 입력 제어 모듈, 전원 제어 모듈, 무선(예를 들어, 블루투스)으로 연결되는 외부 장치 의 전원 제어 모듈, 음성 데이터베이스, 또는 모션 데이터베이스를 포함할 수 있다. 메모리의 도시되지 아니한 모듈들 및 데이터 베이스는 영상 처리 장치에서 방송 수신의 제어 기능, 채널 제어 기능, 볼륨 제어 기 능, 통신 제어 기능, 음성 인식 기능, 모션 인식 기능, 광 수신 제어 기능, 디스플레이 제어 기능, 오디오 제어 기능, 외부 입력 제어 기능, 전원 제어 기능 또는 무선(예를 들어, 블루투스)으로 연결되는 외부 장치의 전원 제어 기능을 수행하기 위하여 소프트웨어 형태로 구현될 수 있다. 프로세서는 메모리에 저장된 이 들 소프트웨어를 이용하여 각각의 기능을 수행할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2023-0139892", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 영상 처리 장치가 화질 처리된 영상을 출력하는 것을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 영상 처리 장치가 입력 영상을 화질 처리하는 방법을 도시한 순서도이다. 도 3은 일 실시예에 따른 영상 처리 장치의 내부 블록도이다. 도 4는 일 실시예에 따른 제1 뉴럴 네트워크의 구조를 나타내는 도면이다. 도 5는 일 실시예에 따른 다양한 영상들의 품질 정보를 나타낸 그래프이다. 도 6은 일 실시예에 따른 시청 정보의 종류를 나타내는 일 예이다. 도 7은 일 실시예에 따른 시청 정보의 조합 예들을 나타내는 도면이다. 도 8은 일 실시예에 따른 모델 학습부의 동작을 설명하기 위한 도면이다. 도 9a는 일 실시예에 따른 학습 DB 생성부가 입력 영상과 관련된 학습 영상들을 획득하는 동작의 일 예를 설명 하기 위한 도면이다. 도 9b는 일 실시예에 따른 학습 DB 생성부가 입력 영상과 관련된 학습 영상들을 획득하는 동작의 일 예를 설명 하기 위한 도면이다. 도 10a는 일 실시예에 따른 학습 DB 생성부가 학습 데이터를 생성하는 동작의 일 예를 설명하기 위한 도면이다. 도 10b는 일 실시예에 따른 학습 DB 생성부가 학습 데이터를 생성하는 동작의 일 예를 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 압축 과정에서 발생하는 열화를 학습 영상에 반영하는 방법을 설명하기 위한 도면이 다. 도 12는 일 실시예에 따른 메타 모델 획득부가 참고 모델을 이용하여 메타 모델을 획득하는 동작의 일 예를 설 명하기 위한 도면이다. 도 13은 일 실시예에 따른 메타 모델 획득부가 참고 모델을 이용하여 메타 모델을 획득하는 동작의 일 예를 설 명하기 위한 도면이다. 도 14는 일 실시예에 따른 모델 학습부의 동작을 설명하기 위한 도면이다. 도 15는 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 블록도이다. 도 16은 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 상세 블록도이다."}
