{"patent_id": "10-2018-0089128", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0013907", "출원번호": "10-2018-0089128", "발명의 명칭": "비디오 특성에 부합하는 오디오 합성 방법", "출원인": "전자부품연구원", "발명자": "양종열"}}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오를 입력받는 단계;텍스트를 입력받는 단계;비디오에서 시계열적으로 특징(x)들을 추출하는 단계;텍스트로부터 음소 별로 특징(p)들을 추출하는 단계;(t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 단계;를 포함하는 것을 특징으로 하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,생성 단계는,(t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 각 특징(x)들 간의연관성들을 기초로 스코어(e)들을 계산하는 제1 계산단계; 및계산된 스코어(e)들을 이용하여, 오디오 스펙트럼 특징(St)을 생성하는 제1 생성단계;를 포함하는 것을 특징으로하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,제1 계산단계는,오디오 스펙트럼 특징(St-1)과 각 특징(x)들을 입력 받아 연관성들을 기초로 스코어(e)들을 계산하여 출력하도록학습된 인공지능 모델을 이용하여, 수행되는 것을 특징으로 하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서,제1 생성 단계는,계산된 스코어(e)들을 이용하여, 특징(x)들에 적용할 가중치(a)들을 계산하는 제2 계산단계; 및계산된 가중치(a)들을 이용하여, 오디오 스펙트럼 특징(St)을 생성하는 제2 생성단계;를 포함하는 것을 특징으로하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,공개특허 10-2020-0013907-3-제2 계산 단계는,계산된 스코어(e)들을 입력 받아 특징(x)들에 적용할 가중치(a)들을 계산하여 출력하도록 학습된 인공지능 모델을 이용하여, 수행되는 것을 특징으로 하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 4에 있어서,제2 생성 단계는,계산된 가중치(a)들을 이용하여, 스코어(e)들의 가중치 합(Zt)를 계산하는 단계; 및오디오 스펙트럼 특징(St-1)과 가중치 합(Zt)을 이용하여, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 단계;를 포함하는 것을 특징으로 하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,(t-1) 시점 까지의 오디오(yt-1)에, 오디오 스펙트럼 특징(St)을 이용하여 생성한 오디오를 부가하여, t 시점 까지의 오디오(yt)를 생성하는 단계;를 더 포함하는 것을 특징으로 하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,t 시점 까지의 비디오에 t 시점 까지의 오디오(yt)를 부가하는 단계;를 더 포함는 것을 특징으로 하는 오디오합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 6에 있어서,생성된 오디오 스펙트럼 특징(St)을 변환하는 단계;를 더 포함하는 것을 특징으로 하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "비디오와 텍스트를 입력받는 입력부;비디오에서 시계열적으로 특징(x)들을 추출하고, 텍스트로부터 음소 별로 특징(p)들을 추출하며, (t-1) 시점에비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 프로세서;를포함하는 것을 특징으로 하는 오디오 합성 시스템."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "비디오에서 시계열적으로 특징(x)들을 추출하는 단계;텍스트로부터 음소 별로 특징(p)들을 추출하는 단계;공개특허 10-2020-0013907-4-(t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 단계;를 포함하는 것을 특징으로 하는 오디오 합성 방법."}
{"patent_id": "10-2018-0089128", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "비디오에서 시계열적으로 특징(x)들을 추출하는 제1 추출부;텍스트로부터 음소 별로 특징(p)들을 추출하는 제2 추출부;(t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 생성부;를 포함하는 것을 특징으로 하는 오디오 합성 시스템."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비디오 특성에 부합하는 오디오 합성 방법이 제공된다. 본 발명의 실시예에 따른 오디오 합성 방법은, 비디오에 서 시계열적으로 특징(x)들을 추출하고, 텍스트로부터 음소 별로 특징(p)들을 추출하며, (t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로 t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성한다. 이에 의해, 비디오 특성 에 맞게 오디오를 합성하여, 비디오에 부합하는 음성 부가를 간편하게 수행할 수 있게 된다."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 오디오/음성 합성 방법에 관한 것으로, 더욱 상세하게는 시간에 따라 변화하는 비디오에 맞게 오디오 /음성을 합성하는 방법에 관한 것이다."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 합성은 입력된 텍스트를 특정 화자의 음성으로 생성하는 기술로, 이를 위해 화자의 음성 특성을 학습한 인 공지능 모델을 이용하고 있다. 하지만, 이는 비디오 환경을 고려하지 않는다. 따라서, 더빙 등의 목적으로, 합성된 음성을 비디오에 부가하여야 하는 경우, 비디오와 음성의 싱크를 맞추기 위해 음성에 대한 변환 작업이 필요한데, 이는 수작업에 의해 이루어지고 있는 실정이다. 하지만, 비디오에 수작업으로 음성을 부가하는 것은 매우 번거롭고 어려우며 많은 시간을 소요하는 작업이다. 이에, 비디오 특성에 부합하는 오디오 합성 방법의 모색이 요청된다."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 비디오에 대한 음성 부 가를 간편하게 수행하기 위한 방안으로, 비디오 특성에 맞게 오디오를 합성하는 방법을 제공함에 있다. 또한, 본 발명의 다른 목적은, 합성된 음성을 비디오 특성에 맞게 변환하여 비디오에 부가하기 위한 방법을 제 공함에 있다."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른, 오디오 합성 방법은, 비디오를 입력받는 단계; 텍스트 를 입력받는 단계; 비디오에서 시계열적으로 특징(x)들을 추출하는 단계; 텍스트로부터 음소 별로 특징(p)들을 추출하는 단계; (t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특 징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특 징(St)을 생성하는 단계;를 포함한다.그리고, 생성 단계는, (t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St- 1)과 각 특징(x)들 간의 연관성들을 기초로 스코어(e)들을 계산하는 제1 계산단계; 및 계산된 스코어(e)들을 이 용하여, 오디오 스펙트럼 특징(St)을 생성하는 제1 생성단계;를 포함할 수 있다. 또한, 제1 계산단계는, 오디오 스펙트럼 특징(St-1)과 각 특징(x)들을 입력 받아 연관성들을 기초로 스코어(e)들 을 계산하여 출력하도록 학습된 인공지능 모델을 이용하여, 수행될 수 있다. 그리고, 제1 생성 단계는, 계산된 스코어(e)들을 이용하여, 특징(x)들에 적용할 가중치(a)들을 계산하는 제2 계 산단계; 및 계산된 가중치(a)들을 이용하여, 오디오 스펙트럼 특징(St)을 생성하는 제2 생성단계;를 포함할 수 있다. 또한, 제2 계산 단계는, 계산된 스코어(e)들을 입력 받아 특징(x)들에 적용할 가중치(a)들을 계산하여 출력하도 록 학습된 인공지능 모델을 이용하여, 수행될 수 있다. 그리고, 제2 생성 단계는, 계산된 가중치(a)들을 이용하여, 스코어(e)들의 가중치 합(Zt)를 계산하는 단계; 및 오디오 스펙트럼 특징(St-1)과 가중치 합(Zt)을 이용하여, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되 는 오디오 스펙트럼 특징(St)을 생성하는 단계;를 포함할 수 있다. 또한, 본 발명의 실시예에 따른 오디오 합성 방법은, (t-1) 시점 까지의 오디오(yt-1)에, 오디오 스펙트럼 특징 (St)을 이용하여 생성한 오디오를 부가하여, t 시점 까지의 오디오(yt)를 생성하는 단계;를 더 포함할 수 있다. 그리고, 본 발명의 실시예에 따른 오디오 합성 방법은, t 시점 까지의 비디오에 t 시점 까지의 오디오(yt)를 부 가하는 단계;를 더 포함할 수 있다. 또한, 본 발명의 실시예에 따른 오디오 합성 방법은, 생성된 오디오 스펙트럼 특징(St)을 변환하는 단계;를 더 포함할 수 있다. 한편, 본 발명의 다른 실시예에 따른, 오디오 합성 시스템은, 비디오와 텍스트를 입력받는 입력부; 비디오에서 시계열적으로 특징(x)들을 추출하고, 텍스트로부터 음소 별로 특징(p)들을 추출하며, (t-1) 시점에 비디오에 합 성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 프로세서;를 포함한다. 한편, 본 발명의 다른 실시예에 따른, 오디오 합성 방법은, 비디오에서 시계열적으로 특징(x)들을 추출하는 단 계; 텍스트로부터 음소 별로 특징(p)들을 추출하는 단계; (t-1) 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 단계;를 포함한다. 한편, 본 발명의 다른 실시예에 따른, 오디오 합성 시스템은, 비디오에서 시계열적으로 특징(x)들을 추출하는 제1 추출부; 텍스트로부터 음소 별로 특징(p)들을 추출하는 제2 추출부; (t-1) 시점에 비디오에 합성할 오디오 를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 특징(x)들 간의 연관성들을 기초로, t 시점에 비디오에 합성할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St)을 생성하는 생성부;를 포함한다."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 비디오 특성에 맞게 오디오를 합성하여 비디오에 부합하 는 음성 부가를 간편하게 수행할 수 있게 되고, 음성을 비디오 특성에 맞게 변환하여 비디오 특성에 보다 부합 하는 음성 부가가 가능해진다."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 음성 합성 방법의 설명에 제공되는 도면이다. 본 발명의 실시예에 따른 음 성 합성 방법은, 인공지능 모델을 이용하여, 주어진 입력 비디오 특성에 맞게 음성을 합성한다. 구체적으로, 본 발명의 실시예에 따른 음성 합성 방법은, 입력 비디오의 환경, 구체적으로, 비디오의 길이와 화 자의 입모양에 맞도록, 텍스트로부터 음성을 합성한다. 이를 위해, 도 1에 도시된 바와 같이, 먼저, m의 길이를 갖는 입력 비디오(v1,v2,...,vm)에서 시계열적으로 n개 의 특징들(x1,x2,...,xn)을 추출한다. 특징들(x1,x2,...,xn)은 비디오(v1,v2,...,vm)에 등장하는 화자의 입모양(입 주변 얼굴)에 대한 특징들로, 비디오 인코더(Video Encoder)에 의해 추출된다. 그리고, 음성으로 합성할 입력 텍스트를 구성하는 k개의 음소 별로 특징들(p1,p2,...,pk)을 추출한다. 음소 특징 들(p1,p2,...,pk)은 텍스트 인코더(Text Encoder)에 의해 추출된다. 다음, (t-1) 시점에 비디오에 부가할 오디오를 생성하는데 이용되는 오디오 스펙트럼 특징(St-1)과 각 입모양 특 징들(x1,x2,...,xn) 간의 연관성들을 기초로 스코어들(et1,et2,...,etn)을 계산한다. 스코어들(et1,et2,...,etn)은 오디오 스펙트럼 특징(St-1)에 의해 결정되는 음성과 각 입모양 특징들(x1,x2,...,x n)에 의해 결정되는 음성들 간의 유사도를 나타낸다. 스코어들(et1,et2,...,etn)은 오디오 스펙트럼 특징(St-1)과 각 입모양 특징들(x1,x2,...,xn)을 입력 받아 연관성들 을 기초로 스코어들(et1,et2,...,etn)을 계산하여 출력하도록 학습된 인공지능 모델을 이용하여 계산된다. 또한, 계산된 스코어들(et1,et2,...,etn)을 이용하여, 각 입모양 특징들(x1,x2,...,xn)에 적용할 가중치들 (at1,at2,...,atn)을 계산한다. 가중치들(at1,at2,...,atn)도 계산된 스코어들(et1,et2,...,etn)을 입력 받아 각 입모양 특징들(x1,x2,...,xn)에 적 용할 가중치들(at1,at2,...,atn)을 계산하여 출력하도록 학습된 인공지능 모델을 이용하여 계산된다. 다음, 계산된 가중치들(at1,at2,...,atn)을 이용하여, 스코어들(et1,et2,...,etn)의 가중치 합(Zt)을 계산한다. 가 중치 합(Zt)의 계산식은 다음과 같다."}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "스코어 계산, 가중치 계산, 가중치 합 계산에 의해, 비디오와 시간에 따른 전체 유사도(연관성)가 가장 큰 음성 이 합성될 수 있다. 해당 과정을 모두 수행하는 하나의 인공지능 모델을 구성하여 활용할 수도 있음은 물론이다. 이후, 오디오 스펙트럼 특징(St-1)과 계산된 가중치 합(Zt)을 이용하여, t 시점에 비디오에 부가할 오디오를 생성 하는데 이용되는 오디오 스펙트럼 특징(St)을 생성한다.그리고, (t-1) 시점 까지의 오디오(yt-1)에, 오디오 스펙트럼 특징(St)을 이용하여 생성한 오디오를 가중 합으로 부가하여, t 시점 까지의 오디오(yt)를 생성한다. 다음, t 시점 까지의 비디오(vt)에 t 시점 까지의 오디오(yt)를 부가하여, 합성된 음성을 비디오와 결합한다. 도 2는 본 발명의 다른 실시예에 따른 음성 합성 방법의 설명에 제공되는 도면이다. 본 발명의 실시예에 따른 음성 합성 방법은, 비디오 길이와 화자의 입모양에서 나아가, 화자의 성별, 나이까지 맞추어 음성을 합성한다. 이를 위해, 도 2에 도시된 바와 같이, 먼저, 입력 비디오에서 화자의 입모양 특징을 추출하고(S110), 입력 텍스 트로부터 음소 특징들을 추출한다(S120). 입모양 특징 추출과, 음소 특징 추출에 대해서는 전술한 바 있으므로, 이들에 대한 상세한 설명은 생략한다. 한편, 본 발명의 실시예에서는, 입력 비디오에서 화자의 성별, 나이를 파악한다(S130). 화자의 성별, 나이 파악 은, 화자의 얼굴 이미지 및/또는 신체 이미지를 입력 받아 이를 분석하여 성별과 나이를 추론하여 출력하도록 학습된 인공지능 모델을 이용하여 수행될 수 있다. 다음, 스코어 계산, 가중치 계산, 가중치 합 계산에 의해, 비디오와 시간에 따른 전체 유사도(연관성)가 가장 큰 오디오 스펙트럼 특징을 추출한다(S140). 이 과정들에 대해서는 전술한 바 있으므로, 이들에 대한 상세한 설 명은 생략한다. 이후, S140단계에서 합성된 오디오 스펙트럼 특징을, S130단계에서 파악된 화자의 성별, 나이를 반영하여 변환 한다(S150). 그리고, 변환된 오디오 스펙트럼 특징과 가중치 합을 이용하여, 오디오를 생성한다(S160). 오디오 생성 과정에 대해서는 전술한 바 있으므로, 이에 대한 상세한 설명은 생략한다. 생성된 오디오는 비디오에 부가된다. 도 3은 본 발명의 또 다른 실시예에 따른 음성 합성 시스템의 블럭도이다. 본 발명의 다른 실시예에 따른 음성 합성 시스템은, 도 3에 도시된 바와 같이, 통신부, 출력부, 프로세서, 입력부 및 저장부 를 포함하는 컴퓨팅 시스템으로 구현할 수 있다. 통신부는 외부 기기와 외부 네트워크로부터 비디오와 텍스트를 입력받기 위한 통신 수단이다. 입력부는 사용자 설정 명령을 입력받기 위한 입력 수단이고, 출력부는 음성 합성 과정 및 결과, 비디 오, 합성된 음성이 부가된 비디오 등을 출력하기 위한 디스플레이와 스피커이다. 프로세서는 도 1 또는 도 2에 도시된 방법을 실행하여 음성 합성을 수행한다. 저장부는 프로세서가 동작함에 있어 필요한 저장 공간을 제공한다. 또한, 저장부는 비디오와 텍 스트를 저장하고 있을 수도 있다. 지금까지, 비디오 특성에 적응적인 오디오 합성 방법 및 시스템에 대해 바람직한 실시예를 들어 상세히 설명하 였다. 위 실시예에서는, 화자의 입모양에 맞게 음성을 합성하는 방법을 상정하였는데, 다른 상황으로 확대 적용할 수 있다. 이를 테면, 화면의 움직임 속도, 화면의 색감 변화 등을 기초로, 음성이 아닌 오디오를 합성하는 방법에 대해서는 본 발명의 실시예가 적용될 수 있다. 본 발명의 실시예에서는, 입력 비디오 특성에 맞게 오디오 합성/변환하여, 컨텐츠를 쉽게 제작할 수 있도록 하 였다. 한편, 본 실시예에 따른 장치와 방법의 기능을 수행하게 하는 컴퓨터 프로그램을 수록한 컴퓨터로 읽을 수 있는 기록매체에도 본 발명의 기술적 사상이 적용될 수 있음은 물론이다. 또한, 본 발명의 다양한 실시예에 따른 기 술적 사상은 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터로 읽을 수 있는 코드 형태로 구현될 수도 있다. 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터에 의해 읽을 수 있고 데이터를 저장할 수 있는 어떤 데이터 저장 장 치이더라도 가능하다. 예를 들어, 컴퓨터로 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광디스크, 하드 디스크 드라이브, 등이 될 수 있음은 물론이다. 또한, 컴퓨터로 읽을 수 있는 기록매체 에 저장된 컴퓨터로 읽을 수 있는 코드 또는 프로그램은 컴퓨터간에 연결된 네트워크를 통해 전송될 수도 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2018-0089128", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2018-0089128", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 음성 합성 방법의 설명에 제공되는 도면, 도 2는 본 발명의 다른 실시예에 따른 음성 합성 방법의 설명에 제공되는 도면, 그리고, 도 3은 본 발명의 또 다른 실시예에 따른 음성 합성 시스템의 블럭도이다."}
