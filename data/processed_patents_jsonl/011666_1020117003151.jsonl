{"patent_id": "10-2011-7003151", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2011-0057125", "출원번호": "10-2011-7003151", "출원인": "마이크로소프트 코포레이션", "발명자": "아마드, 나잠"}}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 구현된 시스템으로서, 다음의 컴퓨터 실행가능한 컴포넌트들:부하 분산 서버(load balancer server)(들)(111, 113, 115)을 데이터 센터(100)의 스위칭 시스템(130)과 인터페이싱하는 디멀티플렉서 컴포넌트(들)(125)를 포함하고;상기 부하 분산 서버(들)(111, 113, 115)는 상기 데이터 센터(100)에 의해 수신된 요청들을 복수의 요청 서비스서버들(request servicing servers)(117, 119, 121)에 분배하는 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 디멀티플렉서를 포함하는 TOR(top-of-rack) 스위치를 더 포함하는 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 디멀티플렉서는 스위치 또는 라우터의 일부인 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 디멀티플렉서는 상기 부하 분산 서버에 요청을 보내기 위해 라우팅 함수(routingfunction)를 이용하는 매핑 컴포넌트를 더 포함하는 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 디멀티플렉서 및 상기 부하 분산 서버들은 L2, L3, 또는 L4 네트워크 또는 그의 조합과연관되는 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 부하 분산 서버는 부하 분산 기능들에 맞추어지지 않은 랩톱, 퍼스널 컴퓨터 또는 상품머신(commodity machine)의 그룹으로부터 선택되는 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서, 상기 라우팅 함수는 복수의 MAC(media access control) 주소들에 지정 가능한 IP 주소로 MAC로테이션을 구현하는 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 분배된 시스템의 일부로서 부하 분산을 용이하게 하는 인공 지능 컴포넌트를 더 포함하는 컴퓨터 구현된 시스템."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨터 구현된 방법으로서, 다음의 컴퓨터 실행가능한 단계들:디멀티플렉서(들) 및 부하 분산 서버들을 통해 데이터 센터 내의 부하 분산 기능을 분배하는 단계(620); 및수신된 들어오는 요청을 상기 디멀티플렉서를 통해 상기 부하 분산 서버들에 보내는 단계(640)를 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 들어오는 요청들을 수용하기 위해 부하 분산 서버들의 수를 조정하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2011-0057125-3-제9항에 있어서, 작업 부하 분배 알고리즘들을 소프트웨어 코드로 실행하기 위해 부하 분산 서버들의 일부로서상품 컴퓨터들을 이용하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 부하 분산 서버들에 의해 요청 서비스 서버들 사이에 태스크들을 분배하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 환경 요인들에 기초하여 요청 서비스 서버들에 요청을 할당하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 스위치, 라우터, 또는 TOR(top-of-rack) 스위치들의 일부, 또는 그의 조합으로서 부하 분산 기능들을 구현하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, TOR 스위치(들)에 VIP ID(identity)를 할당하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서, 데이터 플로우들을 식별하기 위해 상기 디멀티플렉서에 의해 데이터 스트림들을 검사하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제9항에 있어서, 상기 보내는 단계는 네트워크 경로 인식(network path aware) 및 서비스 인식(service aware)인 지능적인 방식으로 수행되는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 디멀티플렉서로부터 상기 부하 분산 서버들로의 터널링 및 상기 부하 분산 서버들로부터상기 요청 서비스 서버들로의 터널링 중 적어도 하나를 이용하는 단계를 더 포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제9항에 있어서, 상기 요청 서비스 서버들로부터 기능을 오프로드하는(offloading) 상기 부하 분산 서버들을 더포함하는 컴퓨터 구현된 방법."}
{"patent_id": "10-2011-7003151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 구현된 시스템으로서, 다음의 컴퓨터 실행가능한 컴포넌트들:데이터 센터(100)의 스위칭 시스템(130)을 분배된 부하 분산 시스템(110)과 인터페이싱하기 위한 수단; 및상기 데이터 센터(100)에 의해 수신된 요청들을 복수의 요청 서비스 서버들(117, 119, 121)에 분배하기 위한 수단을 포함하는 컴퓨터 구현된 시스템.명 세 서배 경 기 술인터넷과 같은 글로벌 통신 네트워크들은 통신 및 데이터 전송 동작들을 위해 그러한 네트워크들에 의존하는 개 [0001]인 및 법인 사용자들의 수가 점점 더 많아짐에 따라 지금은 보편적이다. 통신 보안이 개선됨에 따라, 더 많은데이터가, 서버 호스트들과 같은, 소스들과 데스티네이션들 사이의 글로벌 통신 데이터 백본을 가로지를 것으로기대되고, 따라서 데이터를 처리하고 저장하는 엔티티들에 대한 수요가 증가하고 있다. 전형적으로, 그러한 증공개특허 10-2011-0057125-4-가된 수요들은 부하를 처리할 더 많은 스위칭 장치들 및 서버들을 추가하는 것에 의해 데스티네이션에서 다루어진다.네트워크 부하 분산들(load-balancers)은 서버들(예를 들면, \"호스트들\")의 컬렉션에 의해 호스팅되는 서비스들 [0002]에의 클라이언트 액세스를 제공한다. 클라이언트들은 부하 분산에(또는 부하 분산을 통하여) 접속하고, 부하분산은 클라이언트의 관점에서, 투명하게 그것들을 규칙들의 세트에 따라서 호스트에 전송한다. 일반적으로,부하 분산 컨텍스트는 세션들로서 표현되는 시퀀스들의 형태로 패킷들을 포함하고; 여기서 그러한 세션들은 전형적으로 \"분산된(balanced)\" 방식으로 이용 가능한 호스트들 사이에 할당되어야 한다. 또한, 각 세션의 모든패킷은 일반적으로, (예를 들면, \"세션 어피니티(session affinity)\"에 따라서) 호스트가 활동하는(alive) 동안은, 동일한 호스트에 보내져야 한다.이들 문제들을 다루기 위해, 데이터 센터 시스템들은 호스트들의 상태(예를 들면, 라이브니스(liveness)/부하 [0003](load))를 모니터하고 모든 활성 세션들의 테이블의 형태로 상태를 유지하는 모놀리식 부하 분산(monolithicload-balancer)을 이용한다. 새로운 세션이 도착하면, 부하 분산은 이용 가능한 최소 부하의 호스트(least-loaded host)를 선택하고 그 호스트에 세션을 할당한다. 마찬가지로 그리고 세션 어피니티를 제공하기 위해,부하 분산은 그것의 세션 테이블에 항목을 추가하는 것에 의해 그러한 할당/라우팅 판정을 \"기억\"해야만 한다.이 세션에 대한 후속의 패킷들이 부하 분산에 도착하면, 단일 테이블 조회가 정확한 호스트를 결정한다. 그러나, 개별 부하 분산은 단일 고장점(single point of failure) 및 병목 양쪽 모두일 수 있고, 여기서 그러한 세션 테이블의 사이즈(및 그에 의해 유지되는 상태의 양)는 증가된 처리량과 함께 증가하고 현존하는 세션 트래픽에 대한 라우팅 판정들은 상태 조회(패킷마다 한 번)를 필요로 한다. 이들 한계를 회피하는 것은 제휴하여 동작하는 다수의 모놀리식 부하 분산들(스케일 아웃(scale-out)), 및/또는 더 크고, 더 강력한 부하 분산들(스케일 업(scale-up))을 필요로 한다. 그러나, 이들 부하 분산들을 스케일-아웃하는 것은, 특히 부하 분산들 사이에 일관된 상태를 유지하는 필요 때문에, 복잡하다. 마찬가지로, 그것들을 스케일 업하는 것은, 고정된 하드웨어에서 비용 대비 처리량이 비선형적이기 때문에(예를 들면, 2배의 처리량이 가능한 부하 분산은 그 가격의 2배보다 현저히 더 많은 비용이 든다), 비용이 많이 든다. 또한, 모놀리식 부하 분산들의 신뢰성 염려는, 그러한시스템들의 고장이 상당한 비용 없이 쉽게 보상될 수 없기 때문에, 관련된 난제들을 더 증가시킨다.발명의 내용다음은 여기에 설명된 일부 양태들에 대한 기본적인 이해를 제공하기 위하여 간략한 개요를 제공한다. 이 개요 [0004]는 청구된 내용의 광범한 개관이 아니다. 그것은 청구된 내용의 중요한 또는 결정적인 요소들을 식별하기 위한것도 아니고 그것의 범위를 묘사하기 위한 것도 아니다. 그것의 유일한 목적은 뒤에 제공되는 보다 상세한 설명의 서론으로서 일부 개념들을 간략한 형태로 제공하는 것이다.본 혁신은 (다른 모놀리식/통합된 부하 분산(그것의 최대 용량은 여전히 저활용(under utilize)될 수 있다)을 [0005]추가하는 것과 대조적으로) 증가하는 수요에 연속적으로 적응하는 부하 분산 서버들 및 디멀티플렉서(들)(및/또는 멀티플렉서들)의 네트워크를 통해, 데이터 센터의 용량에 대한 점차적인 스케일링 및 증대(growth)를 가능하게 하는 분배된 부하 분산 시스템을 제공한다. 디멀티플렉서는 데이터 센터의 스위칭 시스템들과 부하 분산 서버들 사이의 인터페이스로서 기능할 수 있다(예를 들면, 10G 포트들을 갖는 L2 스위치들과 1G 포트를 갖는 PC들사이의 인터페이스로서 작용하는 디멀티플렉서). 그러한 부하 분산 서버들은, 전형적으로 특정한 부하 분산 목적에 맞추어지지 않은 일반 유형 머신들로 간주되는, 상품 머신들(commodity machines)(예를 들면, 퍼스널 컴퓨터, 랩톱 등)을 포함한다. 부하 분산 서버들은 가상 IP 주소들(VIP ID)를 더 포함할 수 있고, 그에 따라 애플리케이션들은 사용할 특정한 서버를 특정하지 않고 그들의 요청들을 그와 관련된 주소에 보낼 수 있고; 부하 분산은 상기 VIP를 개별 서버들을 나타내는 복수의 MAC(Media Access Control) 주소들에 매핑하는 것(MAC 로테이션)을 통해 일어날 수 있다. 또한, 그러한 부하 분산 서버들은 서버 고장들로부터 빠른 복구를 가능하게 하기위해 쌍들로 또는 보다 큰 세트들로 배열될 수 있다. 디멀티플렉서는 상기 요청을 데이터 스트림 패킷들의 검사에 기초하여 각각의 부하 분산 서버에 다시 보낸다(re-direct). 디멀티플렉서의 고장은 그것들을 각각의 버디(buddy) L2 스위치들에 부착된 버디 쌍들로 배열함으로써 사용자에게 은폐될 수 있고, 애플리케이션 서버 고장의 경우에는, 트래픽이 더 이상 고장난 애플리케이션 서버에 보내지지 않도록, 구성이 수정되거나 자동으로설정될 수 있다. 그러므로, 그리고 사용자의 관점에서, 이용 가능성(availability)이 유지된다.또한, 디멀티플렉서는 매핑 컴포넌트를 통해, 나중에 그것을 각각의 부하 분산(들)에 전송하기 위한, 들어오는 [0006]데이터 스트림의 IP 헤더들(예를 들면, 5-튜플(5-tuple), 소스 주소, 소스 포트, 데스티네이션 주소, 데스티네이션 포트, 프로토콜)을 검사할 수 있다. 따라서, 데이터 패킷들은 부하 분산 서버에 할당된 패킷의 속성들 및공개특허 10-2011-0057125-5-환경 요인들(예를 들면, 부하 분산 서버들에 대한 현재의 부하)에 기초하여 분할될 수 있다. 부하 분산 서버들은 또한 들어오는 요청들을 데이터 센터에 서비스하는 서버들(예를 들면, 요청 서비스 서버들(requestservicing servers), POD 서버들 등)의 동작에 관한 지식을 소유하고 있다. 따라서, 클라이언트 측으로부터 데이터 센터에 요청들을 제출하기 위해 단일 IP 주소가 이용되고, 이는 클라이언트에 제시된 복수의 요청 서비스서버들에 투명성을 제공한다.관련된 양태에서, 디멀티플렉서와 관련된 매핑 컴포넌트가 들어오는 데이터 스트림을 검사하고, 그와 관련된 모 [0007]든 패킷들을 부하 분산 서버에 할당할 수 있고(예를 들면, 무상태 매핑(stateless mapping)) - 여기서 데이터패킷들은 패킷의 속성들 및 서버들에 대한 현재의 부하 등과 같은 환경 요인들에 기초하여 분할된다. 그 후,요청들은 부하 분산 서버들로부터 요청 서비스 서버들로 전송될 수 있다. 그러한 배열은 시스템에 대한 안정성을 증가시킴과 동시에 그의 스케일링에 대한 융통성을 증가시킨다. 따라서, 부하 분산 기능/설계는 부하 분산및 스위칭 메커니즘들 양쪽 모두에 대한 탄력성 및 융통성을 증가시키도록 분해될 수 있다. 그러한 시스템은또한 시스템 사이즈가 증가할 때 일정한 정상 상태 호스트당 대역폭(constant steady-state per-hostbandwidth)을 유지하는 것을 용이하게 한다. 또한, 본 발명의 부하 분산 방식은 시스템 내의 변화하는 부하/트래픽 조건들에 신속하게 응답한다.일 양태에서, 요청들은 L2 캐시들에 의해 수신되고 디멀티플렉서에 의해 부하 분산 서버들(예를 들면, 물리적 [0008]및/또는 논리적 인터페이스들, 여기서 다수의 MAC 주소들이 VIP와 관련된다)의 전체에 걸쳐 분배될 수 있다.또한, 추가의 양태에서 부하 분산 기능들은, 그들의 기능을 더 강화하기 위해, TOR(top of rack) 스위치들의 일부로서 통합될 수 있고 - 여기서 VIP ID(identity)는 그러한 TOR 스위치들에 존재할 수 있고 이는 서버들의 랙(rack)이 VIP ID 또는 ID들에 보내진 요청들에 이용 가능한 모든 서버들의 계산 능력을 갖는 유닛으로서 작용할수 있게 한다.본 혁신의 방법에 따르면, 처음에 요청(들)이 데이터 센터에 의해 수신되고, 여기서 그러한 들어오는 요청은 0 [0009]개 또는 한개 이상의 스위치들을 통해 디멀티플렉서에 라우팅된다. 그러한 디멀티플렉서는 또한 상기 스위치들을 복수의 부하 분산 서버들과 인터페이싱하고, 여기서 디멀티플렉서는 상기 요청을 데이터 스트림 패킷들의 검사에 기초하여 각각의 부하 분산에 다시 보낸다. 본 혁신의 분배된 배열은 계산된 스케일링 및 증대를 가능하게 하고, 여기서 부하 분산 동작의 용량은 부하 분산 서버들의 수를 변경하는 것에 의해 조정되고; 따라서 서비스들의 저활용(underutilization)을 완화한다. 또한, 각 요청은 개념적으로는 모든 그러한 요청들이 데이터 센터와 관련된 단일 IP 주소에 제출되더라도 상이한 부하 분산 서버에 의해 처리될 수 있다.전술한 및 관련된 목적들의 달성을 위해, 청구된 내용의 특정한 예시적인 양태들이 다음의 설명 및 첨부된 도면 [0010]들과 관련하여 여기에 설명된다. 이들 양태들은 본 내용이 실시될 수 있는 다양한 방법들을 나타내고, 그것들모두는 청구된 내용의 범위 내에 있도록 의도된다. 다른 이점들 및 신규한 특징들은 도면들과 함께 고려될 때다음의 상세한 설명으로부터 명백해질 것이다.도면의 간단한 설명도 1은 본 혁신의 양태에 따른 분배된 부하 분산 시스템의 블록도를 예시한다. [0011]도 2는 데이터 센터 동작의 일부로서 모놀리식 및/또는 통합된 부하 분산을를 이용하는 종래 기술의 시스템을예시한다.도 3은 본 혁신의 추가의 양태에 따른 부하 분산 기능을 갖는 TOR(top-of-rack) 스위치들의 특정한 양태를 예시한다.도 4는 본 혁신의 양태에 따른 태스크들을 분배하는 방법을 예시한다.도 5는 본 혁신의 추가의 양태에 따른 매핑 컴포넌트를 갖는 추가의 부하 분산 시스템을 예시한다.도 6은 본 혁신의 추가의 양태에 따른 시스템의 일부로서 부하 분산 기능을 분배하는 특정한 방법을 예시한다.도 7은 요청 서비스 서버들과 관련된 랙들의 일부로서 부하 분산 서버들을 배치하는 부하 분배 시스템의 특정한양태를 예시한다.도 8은 본 혁신의 추가의 양태에 따른 부하 분산을 용이하게 하는 인공 지능 컴포넌트를 예시한다.도 9는 본 혁신의 양태들을 구현하기 위한 적합한 운영 환경의 개략 블록도를 예시한다.공개특허 10-2011-0057125-6-도 10은 본 혁신의 샘플-컴퓨팅 환경의 추가의 개략 블록도를 예시한다.발명을 실시하기 위한 구체적인 내용이제 첨부된 도면들을 참조하여 본 혁신의 다양한 양태들이 설명되며, 도면들에서 같은 번호들은 전체에 걸쳐서 [0012]같은 또는 대응하는 부분들을 지시한다. 그러나, 도면들 및 그에 관한 상세한 설명은 청구된 내용을 개시된 특정한 형태로 제한하도록 의도되어 있지 않다는 것을 이해해야 한다. 오히려, 그 의도는 청구된 내용의 정신 및범위 안에 분류되는 모든 변경들, 동등물들 및 대안들을 망라하고자 하는 것이다.도 1은 데이터 센터(100)의 용량에 대한 점차적인 스케일링 및 증대를 가능하게 하는, 본 혁신의 양태에 따른 [0013]분배된 부하 분산 시스템(110)에 대한 개략 블록도를 예시한다. 일반적으로, 데이터 센터(100)는 분배 처리를용이하게 하는 중앙 리포지토리를 나타내고(예를 들면, 클라이언트/서버), 여기서 애플리케이션들 및/또는 서버들은 그에 의해 호스팅될 수 있다(예를 들면, 데이터베이스들, 파일 서버들, 애플리케이션 서버들, 미들웨어등). 예를 들면, 데이터 센터(100)는 그의 분배 처리를 용이하게 하기 위해 웹 서비스들, 클라우드 서비스들,ERP(enterprise resource processing), 및 CRM(customer relationship management)을 위한 데이터, 코드, 또는처리 능력들 중 임의의 것을 포함할 수 있다. 또한, 그러한 데이터 센터(100)는 서버 랙들, 통신 랙들, 전력분배 랙들, 컴퓨터실 공기 조절 장치들 등을 포함할 수 있다. 유사하게, 그러한 데이터 센터와 관련된 데이터베이스들은 랙 항목 id, 이름, 데이터 센터, 콜로케이션(collocation), 로우(row), 캐비닛, 시작 슬롯 번호 및항목이 차지하는 슬롯들의 수를 포함하는 랙 레이아웃 테이블을 포함할 수 있다.분배된 부하 분산 시스템(110)은 디멀티플렉서(들)(125) 및 부하 분산에 전용되는 서버들(예를 들면, 부하 분산 [0014]서버들)(111, 113, 115)(1 내지 n, 여기서 n은 정수임)의 배열의 일부로서 구현될 수 있다. 이 출원에서 설명되는 바와 같이, 디멀티플렉서라는 용어는 전형적으로 요청 서비스 서버들에 걸쳐서 작업 부하를 분배하는 것을기술하는 것을 나타낸다. 그럼에도 불구하고, 외부 사용자들 또는 작업 부하의 소스들과 요청 서비스 서버 사이에 연결을 제공할 때는, 멀티플렉서 및/또는 디멀티플렉서가 더 구현될 수 있다. 디멀티플렉서(125)는 스위치 시스템(130)으로부터 트래픽을 획득하고 그것을 부하 분산 서버들(111, 113, 115)에 재분배할 수 있고, 여기서 그러한 부하 분산 서버들은, 전형적으로 특정한 부하 분산 용도로 맞추어지지 않은 일반 유형 머신들로 간주되는, 퍼스널 컴퓨터, 랩톱 등과 같은 상품 머신을 이용할 수 있다. 디멀티플렉서(125)는, 나중에 각각의 부하분산(들)에 전송하기 위한, 들어오는 데이터 스트림의 IP 헤더들(예를 들면, 5-튜플, 소스 주소, 소스 포트, 데스티네이션 주소, 데스티네이션 포트, 프로토콜)의 검사를 위한, 하드웨어 및 소프트웨어 컴포넌트들 양쪽 모두를 포함할 수 있고, 여기서 데이터 패킷들은 패킷의 속성들/환경 요인들(예를 들면, 부하 분산 서버들에 대한현재의 부하)에 기초하여 분할되어, 부하 분산 서버들(111, 113, 115)에 할당된다. 그러한 할당은 디멀티플렉서(125)와 관련되는 매핑 컴포넌트(도시되지 않음)를 통해 더 용이해질 수 있다. 예를 들면, 매핑 컴포넌트는(주어진 세션에 대한 패킷들의 순차적인 전달을 유지하기 위해) 라운드-로빈, 랜덤, 레이어-3/4 해싱과 같은 메커니즘 등을 이용하여 부하 분산 서버들(111, 113, 115)에 데이터 패킷들을 분배할 수 있다.마찬가지로, 부하 분산 서버들(111, 113, 115)은 그 후 라우팅 함수에 의해 결정된 복수의 요청 서비스 서버들 [0015](117, 119, 121)(1 내지 m, 여기서 m은 정수임)에 그의 서비싱을 위해 패킷들을 라우팅할 수 있다. 예를 들면,패킷 스트림의 라우팅은 다수의 세션들을 이용할 수 있고, 여기서 요청 서비스 서버에의 할당은 모든 그러한 요청 서비스 서버들(117, 119, 121)의 라이브니스 및 부하를 평가한 후에 일어난다. 달리 말하면, 부하 분산 서버들(111, 113, 115)은 들어오는 요청들을 데이터 센서에 서비스하는 서버들(117, 119, 121)(예를 들면, 요청서비스 서버들, POD 서버들 등)의 동작에 관한 지식을 소유하고 있다.데이터 센터(100) 내의 분배된 부하 분산의 그러한 배열은 데이터 센터(100)의 요건들에 기초하여 부하 분산 능 [0016]력들의 스케일링에 대한 융통성을 증가시킨다. 그러므로, 부하 분산 기능/설계는 부하 분산 및 스위칭 메커니즘들 양쪽 모두에 대한 탄력성 및 융통성을 증가시키도록 분해될 수 있다. 이것은 시스템 사이즈가 증가할 때일정한 정상 상태 호스트당 대역폭(constant steady-state per-host bandwidth)을 유지하는 것을 용이하게 한다. 또한, 본 발명의 부하 분산 방식은 시스템 내의 변화하는 부하/트래픽 조건들에 신속하게 응답한다. 도 1은 본질적으로 예시적이고 디멀티플렉서는 또한 스위치들 또는 라우터(들)의 일부일 수 있다는 것을 알아야 한다.관련된 양태에서, 복수의 서버들 사이에 일련의 요청들을 할당하는 것과 같은, 작업 부하를 분배하는 것은 2개 [0017]의 단계들로 분리될 수 있다. 제1 단계에서, 작업 부하는 제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘을 이용하여 복수의 부하 분산 서버들 사이에 분할될 수 있다. 제2 단계에서, 부하 분산 서버는 제공개특허 10-2011-0057125-7-1 단계에 의해 그것에 할당된 작업 부하를, 제2 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘을통해 복수의 요청 서비스 서버들 사이에 더 분배할 수 있다.예를 들면, 제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘은 주로 하드웨어로 구현되는 상당히 [0018]단순한 동작들을 이용함으로써 성능을 최대화하고, 필요한 세션 상태의 양을 감소시키고, 큰 작업 부하를 처리하는 비용을 최소화하도록 선택될 수 있다. 그러므로, 제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배알고리즘은 디멀티플렉서(125)라고 불릴 수 있다. 아래에 상세히 설명되는 바와 같이, 제1 유형의 하드웨어,소프트웨어, 및 작업 부하 분배 알고리즘에 대한 특정한 구현은, (1) 하드웨어로서의 복수의 스위치들 또는 라우터들, 소프트웨어로서의 링크 상태 프로토콜(예를 들면, OSPF), 세션 ID로서의 데스티네이션 IP 주소, 및 작업 부하 분배 알고리즘으로서의 같은 비용 다중 경로의 사용; (2) 하드웨어로서의 단일 스위치, (주요 스위치벤더의 용어로 포트-채널이라고도 불리는) 소프트웨어로서의 스위치의 링크 결합 능력, 및 알고리즘으로서의 스위치의 링크 결합 구현들에 의해 제공된 다양한 알고리즘들 중 하나(예를 들면, IP 5-튜플의 해시, 라운드 로빈등)의 사용을 포함할 수 있다.추가의 양태에 따르면, 제2 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘은 부하 분산 서버의 융 [0019]통성을 최대화하도록 선택될 수 있다. 전형적으로, 부하 분산 서버가, 그의 판정 프로세스의 일부로서 이용 가능한 정보(예를 들면, 서빙하고 있는 현재의 작업 부하; 적절한 요청 서비스 서버에 보내져야 하는 요청 또는작업 부하 항목의 딥 인스펙션(deep inspection); 다른 부하 분산 서버들이 서빙하고 있는 작업 부하; 멀티플렉서/디멀티플렉서를 구현하는 컴포넌트들의 작업 부하 또는 상태; 요청 서비스 서버들의 작업 부하 또는 상태;미래의 시간들에 대한 이들 엘리먼트들 중 임의의 것의 작업 부하 또는 상태에 관한 예측들 등에 관련된 정보)를 이용하는, 임의의 작업 부하 분배 알고리즘을 구현할 수 있는 것은 바람직하다. 또한, 부하 분산 서버가,암호화, 암호 해독, 인증, 또는 로깅과 같은 기능을 요청 서비스 서버들로부터 오프로드할 수 있는 것은 바람직하다. 제2 유형의 하드웨어에 대한 특정한 양태는 데이터 센터 서버들, 데스크톱/홈 컴퓨터들, 또는 랩톱들로서 일반적으로 이용되는 유형의 범용 컴퓨터일 수 있고 이는 그러한 장치들의 낮은 비용 및 임의의 원하는 기능을 구현하는 소프트웨어 및 알고리즘들을 수용하고 실행하는 그들의 능력 때문이다.제1 유형 및 제2 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘은, 예를 들면, 목표 비용, 목표 성 [0020]능, 및 현존하는 장비의 성능에 따라서 다양한 방법들로 조합될 수 있다는 것을 알아야 한다. 또한 본 혁신은상품 서버들이 이용될 수 있는 레벨로 작업 부하의 분해를 위한 상당히 단순한 고속 메커니즘(제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘); 및 요청 서비스 서버들에의 요청들의 원하는 분배를 구현하는것(예를 들면, 하드웨어에 상당한 투자의 필요 없이, 퍼스널 컴퓨터들에서 실행될 수 있는 임의의 소프트웨어를이용하는 것)을 가능하게 한다는 것도 알아야 한다. 또한, 본 혁신에 따른 배열은, 작업 부하가 증가하거나 감소할 때 작업 부하 분산 서버들의 수가 작업 부하에 부합하도록 각각 증가되거나 감소될 수 있도록, 점증적으로스케일링 가능하다. 분배된 부하 분산 시스템(110)에 더해지거나 그것으로부터 감해지는 입도(granularity)는종래의 시스템(예를 들면, 종래의 모놀리식 부하 분산들)에 대한 입도보다 현저히 미세한 그레인(grain)이다.개념적으로, 디멀티플렉서와 부하 분산 서버들 사이에 제1 네트워크, 및 부하 분산 서버들과 요청 서비스 서버 [0021]들 사이에 제2 네트워크가 존재할 수 있다. 그러한 네트워크들 각각은 임의의 수의 라우터들, 스위치들 또는링크들(예를 들면, 아무것도 없는 것을 포함함)로 구성될 수 있다. 또한, 전형적으로 제1 네트워크 또는 제2네트워크의 유형에는 어떤 제약도 존재하지 않는다. 예를 들면, 네트워크들은 레이어 2, 레이어 3, 또는 레이어 4 네트워크들 또는 그의 임의의 조합일 수 있다.도 2는 본 혁신의 분배된 부하 분산 서버들과 대조적으로, 모놀리식 부하 분산(들)(230, 232, 234)을 이용하는 [0022]종래의 부하 분산 시스템을 예시한다. 모놀리식 부하 분산(230, 232, 234)은 전형적으로 요청들을 데이터센터의 다양한 요청 서비스 서버들 사이에 퍼뜨린다. 예를 들면, 모놀리식 부하 분산(230, 232, 234)은 요청들을 \"백엔드\" 서버들(240) 중 하나의 백엔드 서버에 요청하고, 이 백엔드 서버는 통상적으로 모놀리식 부하 분산(230, 232, 234)에 응답한다 - 기능들의 내부 분리에 관하여 아는 데이터를 요청하는 클라이언트 없음. 내부네트워크의 구조를 은폐하여 커널의 네트워크 스택 또는 다른 포트들에서 실행하는 관련되지 않은 서비스들에대한 공격들을 막음으로써, 클라이언트들이 직접 백엔드 서버들과 접촉하는 것을 막을 때 추가적인 보안이 획득된다.데이터 센터(200)의 용량이 증가할 때, 다른 모놀리식 부하 분산이가 추가되지만, 그와 관련된 용량은 데이터 [0023]센터에 대한 다음 확장까지 미사용 상태로 남는다. 그러나, 이것은 하드웨어, 소프트웨어, 셋업, 및 관리에 관하여 값비싼 제안일 수 있다. 따라서, 모놀리식 부하 분산을 이용하는 것에 의해, 시스템의 증강은 데이터 센공개특허 10-2011-0057125-8-터의 점증적인 증대를 수용하도록 효율적으로 맞추어질 수 없다. 관련된 양태에서, 그러한 모놀리식 부하 분산은 전형적으로 백 엔드 서버들(240)의 동작을 알지 못하고 일반적으로 백 엔드 서버(240)와 관련된 머신들 사이에 지능적인 분배 선택들을 쉽게 공급하지 않는다.도 3은 본 혁신의 추가의 양태에 따른 분해된 및 분배된 부하 분산 시스템(300)에 대한 추가의 양태를 [0024]예시한다. 시스템(300)은 부하 분산 기능들이 TOR(top-of-rack) 스위치들(311, 313, 315)(1 내지 k, 여기서 k는 정수임)의 일부로서 통합될 수 있게 하여 그들의 기능을 더 강화하고 강화된 TOR을 형성한다.시스템(300)에서, VIP ID가 TOR 스위치들(311, 313, 315)에 존재할 수 있고, 이는, 예를 들면, 레이어 3 기능 [0025]들을 더 가능하게 할 수 있다. 전형적으로, TOR 스위칭은, 랙 내의 서버들에 대한 빠른 포트간 스위칭(port-to-port switching), 업링크의 예측 가능한 초과 신청 및 고장 격리 및 봉쇄를 돕는 보다 작은 스위칭 도메인들(랙당 1개)과 같은, 다양한 구조적 이점들을 공급할 수 있다. 그러한 배열에서 VIP(들)(350)는 다수의 TOR들에존재할 수 있다. 멀티플렉서/디멀티플렉서의 기능은 구름 윤곽(331)에 의해 도 3에 나타내어진 바와 같이 분배된 멀티플렉서/디멀티플렉서를 생성하기 위해 스위치들 및/또는 라우터들의 같은 비용의 다중 경로 라우팅 능력을 이용하여 구현될 수 있다. 그러므로, 부하 분산 서버들의 기능은 강화된 TOR에 존재할 수 있다.도 4는 본 혁신의 추가의 양태에 따른 분배된 부하 분산 시스템을 구현하는 추가의 방법(400)을 예시한다. 예 [0026]시적인 방법은 여기서 다양한 이벤트들 및/또는 액트들을 나타내는 일련의 블록들로서 예시되고 설명되지만, 본발명은 그러한 블록들의 예시된 순서에 의해 제한되지 않는다. 예를 들면, 일부 액트들 또는 이벤트들은, 본발명에 따라, 여기에 예시된 순서는 별문제로 하고, 상이한 순서들로 및/또는 다른 액트들 또는 이벤트들과 동시에 일어날 수 있다. 또한, 본 발명에 따른 방법을 구현하기 위해 예시된 블록들, 이벤트들 또는 액트들이 모두 다 요구되지 않을 수도 있다. 또한, 본 발명에 따른 예시적인 방법 및 다른 방법들은 여기에 예시되고 설명된 방법과 관련하여 구현될 수 있을 뿐만 아니라, 예시되거나 설명되지 않은 다른 시스템들 및 장치들과 관련하여 구현될 수도 있다는 것을 알 것이다. 처음에, 단계(410)에서는 요청이, 예를 들면, 그와 관련된 수의 패킷들을 갖는 데이터 스트림으로서, 데이터 센터에 의해 수신된다.다음으로 단계(420)에서는, 그러한 들어오는 데이터 패킷들이 플로우의 식별을 위한 필드들을 식별하기 위해 검 [0027]사될 수 있고, 여기서 동일한 플로우 내의 모든 패킷은 단계(430)에서 동일한 부하 분산 서버에서 종료하기 위해 동일한 경로를 따를 수 있다. 그러므로, 패킷들은 패킷들의 속성들 및 요청 서비스 서버들의 건강, 이용 가능성, 서비스 시간, 또는 부하; 부하 분산 서버들의 건강, 이용 가능성 또는 부하; 디멀티플렉서를 구현하는 컴포넌트들의 건강 또는 이용 가능성과 같은 환경 요인들에 기초하여 분할될 수 있고, 여기서 부하 분산 서버들로의 패킷들을 다시 보내는 것은, 부하 분산 서버들에 관련된, 네트워크 경로 인식 및 서비스 인식인 지능적인 방식으로 일어난다. 부하 분산들에의 플로우들의 할당에 영향을 미치는 요인들의 변화들에 응답하는 방식으로 부하 분산들에 플로우들을 보내기 위해, 일관된 해싱(consistent hashing)과 같은, 잘 알려진 기법들이 이용될 수있다. 다음으로 단계(440)에서는, 부하 분산 서버가, 예를 들면, 복수의 서비스 요청 서버들 사이에 관련된 태스크들을 분할할 수 있다.도 5는 본 혁신의 양태에 따른 부하 분산 서버들에의 무상태 매핑을 제공할 수 있는 매핑 컴포넌트(502)를 예시 [0028]한다. 매핑 컴포넌트(502)는 각 세션 패킷을 라우팅 함수(508)에 의해 미리 정의된 지정된 부하 분산 서버에보낼 수 있다. 세션은 몇 개의 프로토콜들, 다수의 개별 접속들을 스팬(span)할 수 있고, 불확정한 길이의 시간을 지속할 수 있는 2개의 네트워크 엔티티들 사이의 논리적인 일련의 요청들 및 응답들이라는 것에 유의한다.일부 공통의 세션 유형들은 TCP(Transmission Control Protocol), FTP(File Transfer Protocol), SSL(SecureSocket Layer), IPSec(IP Security)/L2TP(Layer 2 Tunneling Protocol), PPTP(Point-to-Point TunnelingProtocol), RDP(Remote Desktop Protocol) 등을 포함한다. 대부분의 프로토콜들에 대한 세션의 특징화는 정의가 명확하고, 따라서 각 세션에 대한 명백한 시작과 끝, 및 그러한 세션을 구별하기 위한 관련된 식별자가 존재한다. 그러나, 일부 세션 유형들은, 뚜렷한 시작을 갖지만, 유휴 타임아웃(idel timeout) 또는 최대 세션 지속기간과 같은 추론된 끝을 가질 수 있다.각 세션 패킷마다, 세션 ID(512)가 라우팅 함수(508)에의 입력으로서 이용되기 때문에, 세션 어피니티(session [0029]affinity)가 유지된다; 즉, 주어진 세션의 각 패킷은 동일한 부하 분산 서버에 라우팅될 수 있다. 또한, 매핑컴포넌트(502)는, 모든 부하 분산 서버들의 현재의 부하 상태를 고려하여, 부하 분산 서버의 어느 것에 각 세션이 할당되고 라우팅될 것인지를 결정한다.매핑 컴포넌트(502)는 각 세션 패킷을 검출하고, 예를 들면, 최초 세션 패킷, 및 최후 세션 패킷 상의 세션 [0030]ID(512) 및/또는 특별한 태그를 포함하는 라우팅 정보에 대하여 각 세션 패킷에 문의한다. 따라서, 최초 패킷공개특허 10-2011-0057125-9-또는 최후 패킷이 아닌 임의의 패킷은 중간 세션 패킷으로 간주된다. 또한, 세션 ID가 생성되고 할당되었을때, 그것은 전형적으로 후속의 세션들에 대하여 다시 사용되지 않을 것이고, 이에 따라 주어진 패킷이 속하는세션에 관하여 모호함이 없을 것이다. 일반적으로, 주어진 세션 ID는 세션에 대하여 고유하다고 가정될 수 있고, 그에 의해 표준 네트워크 원리들 또는 컴포넌트들에 의해 고유성이 제공된다.그러므로, 데이터 패킷들은 패킷의 속성들 및 환경 요인들(예를 들면, 부하 분산 서버들에 대한 현재의 부하)에 [0031]기초하여 분할되고, 부하 분산에 할당될 수 있다. 부하 분산 서버들은 또한 들어오는 요청들을 데이터 센터에서비스하는 다른 서버들(예를 들면, 요청 서비스 서버, POD 서버 등)의 동작에 관한 지식을 소유하고 있다. 따라서, 시스템(500)은 부하 분산 서버들 중 하나 이상에 대한 현재의 이용 가능성을 정의하는 하나 이상의 라우팅 함수들을 이용한다. 라우팅 함수는 또한 세션 어피니티를 유지하기 위해 동일한 세션의 패킷들이 계속해서동일한 데스티네이션 호스트에 라우팅되도록 데스티네이션 부하를 고려할 수 있다.도 6은 복수의 TOR 스위치들 사이에 부하 분산 능력들을 분배하는 방법을 예시한다. 처음에 단계(610)에서는 [0032]VIP ID가 TOR 스위치에 할당될 수 있고, 여기서 VIP가 다수의 TOR들에 할당되면, 같은 비용의 다중 경로 라우팅이 다수의 TOR들에 부하 분산할 수 있다. 다수의 MAC 주소들이 VIP와 관련되고, 여기서 그러한 가상 IP 주소는사용할 특정한 서버를 지정하지 않고 서버들에 서비스 요청들을 보낼 수 있다. 그러므로, TOR은 관련된 서버들에 해시 또는 라운드 로빈 알고리즘을 이용하여 트래픽을 다시 보낼 수 있다. 또한, 서버 고장의 경우에는, 트래픽이 더 이상 고장난 서버에 보내지지 않도록 구성이 수정되거나 자동으로 설정될 수 있다. 다음으로 단계(620)에서는, 부하 분산 기능들이 스위치들 사이에 분배될 수 있고, 여기서 부하 분산 서버는 그렇게 강화되는TOR 스위치의 일부로서 존재할 수 있다. 단계(630)에서는 서비스 데이터 센터에 의해 수신된 요청이 서비스 요청들과 관련된 패킷들을 처리하기 위해 TOR 스위치에 전송될 수 있다. 또한, 부하 분산 서버들에 관련된, 경로인식 및 서비스 인식인 지능적인 방식으로 관련된 서비스 서버들에 요청을 보내기 위해, 멀티플렉싱/디멀티플렉싱 능력들이 하드웨어 및/또는 소프트웨어 컴포넌트들의 형태로 TOR 스위치들의 일부로서 구현될 수 있다.도 7은 요청 서비스 서버들(704)과 관련된 랙들의 일부로서 부하 분산 서버(들)(702)을 배치하는 부하 분배 시 [0033]스템(700)의 추가의 양태를 예시한다. 그러한 배열은 서비스 요청 서버들의 일부로서 추가적인 부하 분산을 허용하고, 부하 분산 서버들은 요청 서빙 서버들로부터 임무를 더 오프로드할 수 있다. 디멀티플렉서(710)는 또한 들어오는 데이터 스트림들을 부하 분산 서버(들)(702)에 터널링하는 것을 허용한다. 터널(들)은 디멀티플렉서(710)로부터 부하 분산 서버(702)로(및/또는 부하 분산 서버들로부터 요청 서비스 서버들로) 확립될 수 있고,여기서 세션들은 그러한 터널을 통하여 교섭된다. 그러한 터널링은 또한 요청들의 유형 및/또는 관련된 스위치들(예를 들면, L2/L3)에 따라서 서비스 요청 서버들에 다른 터널들을 확립하는 것을 동반할 수 있다. 디멀티플렉서(710)는 또한 해싱 함수들에 기초하여 부하 분산 서버들을 지정할 수 있고, 여기서 부하 분산 서버들은 그후 서비스 요청 서버와 통신할 수 있다.예를 들면, 디멀티플렉서(710)는 이용 가능한 부하 분산 서버들 및/또는 서비스 요청 서버들에 분산된 방식으로 [0034]패킷 부하를 분배하는 동일한 라우팅 함수를 생성할 수 있다. 지정된 서버는, 예를 들면, 종래의 패킷 라우팅방식들 및 기술들에 따라서 계속해서 세션 패킷들을 수신한다. 그러므로, 세션 정보는 부하 분산을 용이하게하기 위해 라우팅 함수에 대비하여 처리될 수 있다. 디멀티플렉서는, 세션 어피니티를 유지하기 위해, 최후 패킷이 검출될 때까지 동일한 호스트에 동일한 세션의 세션 패킷들을 계속해서 라우팅한다.도 8은 들어오는 요청을 부하 분산 서버들 및/또는 서비스 요청 서버들 사이에 언제, 어디에, 어떻게 분배할지 [0035]를 추론하고 및/또는 결정하는 것을 용이하게 하기 위해 이용될 수 있는 인공 지능(AI) 컴포넌트(810)를 이용하는 시스템(800)을 예시한다. 여기서 사용될 때, \"인터페이스\"라는 용어는 일반적으로 이벤트들 및/또는 데이터를 통해 캡처된 관찰들의 세트로부터 시스템, 환경, 및/또는 사용자의 상태들을 추리하거나 추론하는 프로세스를 지시한다. 추론은 특정한 컨텍스트 또는 동작을 식별하기 위해 이용될 수 있고, 또는, 예를 들면, 상태들에대한 확률 분포를 생성할 수 있다. 추론은 확률적일 수 있다 - 즉, 데이터 및 이벤트들의 고려에 기초하여 흥미 있는 상태들에 대한 확률 분포의 계산. 추론은 또한 이벤트들 및/또는 데이터의 세트로부터 보다 높은 레벨의 이벤트들을 구성하기 위해 이용되는 기법들을 지시할 수 있다. 그러한 추론은, 이벤트들이 시간적으로 근접하게 상관되든 아니든 간에, 이벤트들 및 데이터가 하나의 또는 몇 개의 이벤트 및 데이터 소스들로부터 유래하든 간에, 관찰된 이벤트들 및/또는 저장된 이벤트 데이터의 세트로부터 새로운 이벤트들 또는 동작들의 구성으로 귀결된다.AI 컴포넌트(810)는 여기에 설명된 발명의 다양한 양태들을 용이하게 하는 것과 관련하여 위에 설명된 각종의 [0036]적합한 AI 기반 방식들 중 임의의 것을 이용할 수 있다. 예를 들면, 태스크들 및 부하들을 어떻게 지능적인 방공개특허 10-2011-0057125-10-식으로 분산(balance)할지를 명시적으로 또는 암시적으로 학습하기 위한 프로세스는 자동 분류 시스템 및 프로세스를 통해 용이해질 수 있다. 분류는 사용자가 자동으로 수행되기를 원하는 동작을 예지하거나 추론하기 위해 확률 및/또는 통계 기반 분석(예를 들면, 분석 유틸리티들 및 비용들을 계산에 넣는)을 이용할 수 있다. 예를 들면, SVM(support vector machine) 분류자(classifier)가 이용될 수 있다. 다른 분류 접근법들은 베이지안 네트워크, 결정 트리를 포함하고, 상이한 독립 패턴들을 제공하는 확률적 분류 모델들이 이용될 수 있다.여기서 사용된 분류는 또한 우선 순위의 모델들을 개발하기 위해 이용되는 통계적 회귀(statisticalregression)를 포함한다.본 명세서로부터 쉽게 이해되는 바와 같이, 본 혁신은 질문에 대해 어떤 응답을 반환할지를 미리 결정된 기준들 [0037]에 따라서 자동으로 결정하기 위해 분류자가 이용되도록 (예를 들면, 일반 훈련 데이터를 통해) 명시적으로 훈련될 뿐만 아니라 (예를 들면, 사용자 행동을 관찰하고, 외부 정보를 수신하는 것을 통해) 암시적으로 훈련되는분류자들을 이용할 수 있다. 예를 들면, 잘 이해되는 SVM들에 관하여, SVM들은 분류자 생성자 및 특징 선택 모듈 내의 학습 또는 훈련 단계를 통해 구성된다. 분류자는 입력 속성 벡터, x = (x1, x2, x3, x4, xn)을 그 입력이 클래스에 속하는 신뢰(confidence)에 매핑하는 함수이다 - 즉, f(x) = confidence(class).여기서 사용될 때, \"컴포넌트\", \"시스템\" 등의 용어들은, 하드웨어이든, 하드웨어와 소프트웨어의 조합이든, 소 [0038]프트웨어 또는 실행 중의 소프트웨어이든 간에, 컴퓨터 관련 엔티티를 지시하도록 의도된다. 예를 들면, 컴포넌트는 프로세서에서 실행하는 프로세스, 프로세서, 개체, 인스턴스, 실행 파일, 실행의 스레드, 프로그램 및/또는 컴퓨터일 수 있지만, 이에 제한되는 것은 아니다. 예로서, 컴퓨터에서 실행하는 애플리케이션 및 컴퓨터는 양쪽 모두 컴포넌트일 수 있다. 하나 이상의 컴포넌트들이 프로세스 및/또는 실행의 스레드 내에 존재할 수있고 컴포넌트는 하나의 컴퓨터에 국한되거나 및/또는 2개 이상의 컴퓨터들 사이에 분배될 수 있다.\"예시적인\"이라는 단어는 여기서 예, 실례 또는 예시의 역할을 하는 것을 의미하기 위해 사용된다. 여기서 \"예 [0039]시적인\"으로 기술된 임의의 양태들 또는 설계는 반드시 다른 양태들 또는 설계들에 비하여 선호되거나 유리한것으로 해석되어서는 안 된다. 유사하게, 예들은 여기서 단지 명료성과 이해를 위해 제공되고 본 혁신 또는 그의 부분을 어떻게든 제한하도록 의도되어 있지 않다. 다수의 추가적인 또는 대안적인 예들이 제시되었을 수 있지만, 간결성을 위해 생략되었다는 것을 알아야 한다.또한, 본 혁신의 전부 또는 부분들은 개시된 혁신을 구현하도록 컴퓨터를 제어하는 소프트웨어, 펌웨어, 하드웨 [0040]어 또는 그의 임의의 조합을 생성하기 위해 표준 프로그래밍 및/또는 엔지니어링 기법들을 이용하는 시스템, 방법, 장치, 또는 제조물로서 구현될 수 있다. 예를 들면, 컴퓨터 판독가능 매체는 자기 저장 장치들(예를 들면,하드 디스크, 플로피 디스크, 자기 테이프 등), 광 디스크들(예를 들면, CD(compact disk), DVD(digitalversatile disk) 등), 스마트 카드, 및 플래시 메모리 장치들(예를 들면, 카드, 스틱, 키 드라이브 등)을 포함할 수 있지만 이에 제한되는 것은 아니다. 또한, 전자 메일을 송수신하는 데 또는 인터넷 또는 LAN(local areanetwork)과 같은 네트워크에 액세스하는 데 이용되는 것들과 같은 컴퓨타 판독가능 전자 데이터를 운반하기 위해 반송파가 이용될 수 있다는 것을 알아야 한다. 물론, 숙련된 당업자들은 청구된 내용의 범위 또는 정신으로부터 벗어나지 않고 이 구성에 많은 수정들이 이루어질 수 있다는 것을 인지할 것이다.개시된 내용의 다양한 양태들에 대한 컨텍스트를 제공하기 위하여, 도 9 및 10뿐만 아니라 다음의 설명은 개시 [0041]된 내용의 다양한 양태들이 구현될 수 있는 적합한 환경에 대한 간략한, 일반적인 설명을 제공하도록 의도되어있다. 본 내용은 위에서 컴퓨터 및/또는 컴퓨터들에서 실행하는 컴퓨터 프로그램의 컴퓨터 실행가능 명령어들의 일반적인 컨텍스트에서 설명되었지만, 숙련된 당업자들은 본 혁신은 또한 다른 프로그램 모듈들과 조합하여구현될 수 있다는 것을 인지할 것이다. 일반적으로, 프로그램 모듈은 특정 태스크를 수행하고 및/또는 특정 추상 데이터 유형을 구현하는 루틴, 프로그램, 컴포넌트, 데이터 구조 등을 포함한다. 또한, 숙련된 당업자들은본 혁신적인 방법들은 단일 프로세서 또는 멀티프로세서 컴퓨터 시스템, 미니컴퓨팅 장치, 메인프레임 컴퓨터뿐만 아니라, 퍼스널 컴퓨터, 핸드-헬드 컴퓨팅 장치(예를 들면, PDA(personal digital assistant), 전화기, 시계 등), 마이크로프로세서 기반 또는 프로그램가능한 가전제품 또는 산업 전자 기기 등을 포함하는, 다른 컴퓨터 시스템 구성들을 사용하여 실시될 수 있다는 것을 알 것이다. 예시된 양태들은 또한 통신 네트워크를 통해연결되어 있는 원격 처리 장치들에 의해 태스크가 수행되는 분배 컴퓨팅 환경들에서 실시될 수도 있다.그러나, 설사 본 혁신의 모든 양태들은 아닐지라도, 일부 양태들은 독립 실행형 컴퓨터들에서 실시될 수 있다.분배 컴퓨팅 환경에서, 프로그램 모듈은 로컬 및 원격 메모리 저장 장치 둘다에 위치할 수 있다.도 9를 참조하여, 컴퓨터(912)를 포함하는 본 혁신의 다양한 양태들을 구현하기 위한 예시적인 환경(910)이 설 [0042]명된다. 컴퓨터(912)는 처리 장치(914), 시스템 메모리(916), 및 시스템 버스(918)를 포함한다. 시스템 버스공개특허 10-2011-0057125-11-(918)는 시스템 메모리(916)를 포함한, 그러나 이에 제한되지 않는, 시스템 컴포넌트들을 처리 장치(914)에 연결한다. 처리 장치(914)는 다양한 이용 가능한 프로세서들 중 어느 것이라도 될 수 있다. 듀얼 마이크로프로세서들 및 기타 멀티프로세서 아키텍처도 처리 장치(914)로서 이용될 수 있다.시스템 버스(918)는 메모리 버스 또는 메모리 컨트롤러, 주변 버스 또는 외부 버스, 및/또는 임의의 각종의 이 [0043]용 가능한 버스 아키텍처들을 이용하는 로컬 버스를 포함하는 몇몇 유형의 버스 구조(들) 중 어느 것이라도 될수 있고, 이용 가능한 버스 아키텍처들은, 11 비트 버스, ISA(Industrial Standard Architecture), MSA(MicroChannel Architecture), EISA(Extended ISA), IDE(Intelligent Drive Electronics), VLB(VESA local bus),PCI(Peripheral Component Interconnect), USB(Universal Serial Bus), AGP(Advanced Graphics Port),PCMCIA(Personal Computer Memory Card International Association bus), 및 SCSI(Small Computer SystemsInterface)를 포함하지만 이에 제한되는 것은 아니다.시스템 메모리(916)는 휘발성 메모리(920) 및 비휘발성 메모리(922)를 포함한다. 시동 중과 같은 때에, 컴퓨터 [0044](912) 내의 구성요소들 사이의 정보 전송을 돕는 기본 루틴들을 포함하는 기본 입/출력 시스템(BIOS)은 비휘발성 메모리(922)에 저장된다. 예로서, 비휘발성 메모리(922)는 ROM(read only memory), PROM(programmableROM), EPROM(electrically programmable ROM), EEPROM(electrically erasable ROM), 또는 플래시 메모리를 포함할 수 있지만, 이에 제한되는 것은 아니다. 휘발성 메모리(920)는, 외부 캐시 메모리로서 작용하는,RAM(random access memory)을 포함한다. 예로서, RAM은 SRAM(synchronous RAM), DRAM(dynamic RAM),SDRAM(synchronous DRAM), DDR SDRAM(double data rate SDRAM), ESDRAM(enhanced SDRAM), SLDRAM(SynchlinkDRAM), 및 DRRAM(direct Rambus RAM)와 같은 다수의 형태들로 이용 가능하지만, 이에 제한되는 것은 아니다.컴퓨터(912)는 또한 이동식/비이동식, 휘발성/비휘발성 컴퓨터 저장 매체를 포함한다. 도 9는 디스크 저장 장 [0045]치(924)를 예시하고, 여기서 각 디스크 저장 장치(924)는 자기 디스크 드라이브, 플로피 디스크 드라이브, 테이프 드라이브, 재즈(Jaz) 드라이브, 집(Zip) 드라이브, LS-60 드라이브, 플래시 메모리 카드, 또는 메모리 스틱을 포함하지만, 이에 제한되는 것은 아니다. 또한, 디스크 저장 장치(924)는, CD-ROM(compact disk ROM) 디바이스, CD-R(CD recordable) 드라이브, CD-RW(CD rewritable) 드라이브 또는 DVD-ROM(digital versatile diskROM) 드라이브를 포함하지만, 이에 제한되지 않는, 다른 저장 매체와 별도로 또는 조합하여 저장 매체를 포함할수 있다. 디스크 저장 장치들(924)의 시스템 버스(918)에의 연결을 용이하게 하기 위해, 전형적으로 인터페이스(926)와 같은 이동식 또는 비이동식 인터페이스가 이용된다.도 9는 사용자들과 적합한 운영 환경(910)에서 설명된 기본 컴퓨터 리소스들 사이의 매개로서 작용하는 소프트 [0046]웨어를 설명한다는 것을 알아야 한다. 그러한 소프트웨어는 운영 체제(928)를 포함한다. 디스크 저장 장치(924)에 저장될 수 있는, 운영 체제(928)는 컴퓨터 시스템(912)의 리소스들을 제어하고 할당하는 역할을 한다.시스템 애플리케이션들(930)은 시스템 메모리(916)에 또는 디스크 저장 장치(924) 상에 저장된 프로그램 모듈들(932) 및 프로그램 데이터(934)를 통하여 운영 체제(928)에 의한 리소스들의 관리를 이용한다. 여기에 설명된다양한 컴포넌트들은 다양한 운영 체제들 또는 운영 체제들의 조합들을 사용하여 구현될 수 있다는 것을 알아야한다.사용자는 입력 장치(들)(936)를 통하여 컴퓨터(912)에 명령들 또는 정보를 입력한다. 입력 장치들(936)은, 마 [0047]우스, 트랙볼, 스타일러스, 터치 패드와 같은 포인팅 장치, 키보드, 마이크, 조이스틱, 게임 패드, 위성안테나, 스캐너, TV 튜너 카드, 디지털 카메라, 디지털 비디오 카메라, 웹 카메라 등을 포함하지만, 이에 제한되는 것은 아니다. 이들 및 기타 입력 장치들은 인터페이스 포트(들)(938)를 통해 시스템 버스(918)를 통하여처리 장치(914)에 접속된다. 인터페이스 포트(들)(938)는, 예를 들면, 직렬 포트, 병렬 포트, 게임 포트, 및USB(universal serial bus)를 포함한다. 출력 장치(들)(940)는 입력 장치(들)(936)와 동일한 유형의 포트들중 일부를 이용한다. 따라서, 예를 들면, USB 포트는 컴퓨터(912)에 입력을 제공하고, 컴퓨터(912)로부터 출력장치(940)에 정보를 출력하기 위해 이용될 수 있다. 출력 어댑터(942)는 특수한 어댑터들을 필요로 하는 여러출력 장치들(940) 중에서, 모니터, 스피커, 및 프린터 같은 일부 출력 장치들(940)이 있는 것을 예시하기 위해제공된다. 출력 어댑터들(942)은, 예로서, 출력 장치(940)와 시스템 버스(918) 사이의 연결의 수단을 제공하는비디오 및 사운드 카드들을 포함하지만, 이에 제한되는 것은 아니다. 원격 컴퓨터(들)(944)와 같은 다른 장치들 및/또는 장치들의 시스템들이 입력 및 출력 능력들 양쪽 모두를 제공한다는 것에 유의해야 한다.컴퓨터(912)는 원격 컴퓨터(들)(944)와 같은 하나 이상의 원격 컴퓨터로의 논리적 접속을 사용하여 네트워크화 [0048]된 환경에서 동작할 수 있다. 원격 컴퓨터(들)(944)는 퍼스널 컴퓨터, 서버, 라우터, 네트워크 PC, 워크스테이션, 마이크로프로세서 기반 기구, 피어 장치 또는 다른 공통의 네트워크 노드 등일 수 있고, 전형적으로 컴퓨터공개특허 10-2011-0057125-12-(912)와 관련하여 설명된 구성요소들 중 다수 또는 그 전부를 포함한다. 간결성을 위하여, 메모리 저장 장치(946)만이 원격 컴퓨터(들)(944)와 함께 예시되어 있다. 원격 컴퓨터(들)(944)는 네트워크 인터페이스(948)를통하여 컴퓨터(912)에 논리적으로 연결되고 그 후 통신 연결(950)을 통해 물리적으로 연결된다. 네트워크 인터페이스(948)는 LAN(local-area networks) 및 WAN(wide-area networks)과 같은 통신 네트워크들을 포함한다.LAN 기술들은 FDDI(Fiber Distributed Data Interface), CDDI(Copper Distributed Data Interface), 이더넷/IEEE 802.3, 토큰 링/IEEE 802.5 등을 포함한다. WAN 기술들은 포인트-투-포인트 링크들, ISDN(IntegratedServices Digital Networks) 같은 회선 교환 네트워크들 및 그의 변형들, 패킷 교환 네트워크들, 및DSL(Digital Subscriber Lines)을 포함하지만 이에 제한되는 것은 아니다.통신 연결(들)(950)은 네트워크 인터페이스(948)를 버스(918)에 연결하기 위해 이용되는 하드웨어/소프트웨어를 [0049]지시한다. 통신 연결(950)은 예시의 명확성을 위해 컴퓨터(912) 내부에 도시되어 있지만, 그것은 컴퓨터(912)의 외부에 있을 수도 있다. 네트워크 인터페이스(948)에의 연결을 위해 필요한 하드웨어/소프트웨어는, 단지예시를 위해, 통상의 전화기 등급 모뎀, 케이블 모뎀 및 DSL 모뎀을 포함하는 모뎀들, ISDN 어댑터들, 및 이더넷 카드들과 같은 내부 및 외부 기술들을 포함한다.도 10은 본 혁신의 양태에 따른 분배된 부하 분산의 일부로서 이용될 수 있는 샘플-컴퓨팅 환경(1000)의 개략 [0050]블록도이다. 시스템(1000)은 하나 이상의 클라이언트(들)(1010)를 포함한다. 클라이언트(들)(1010)는 하드웨어 및/또는 소프트웨어(예를 들면, 스레드, 프로세스, 컴퓨팅 장치)일 수 있다. 시스템(1000)은 또한 하나 이상의 서버(들)(1030)를 포함한다. 서버(들)(1030)도 하드웨어 및/또는 소프트웨어(예를 들면, 스레드, 프로세스, 컴퓨팅 장치)일 수 있다. 서버들(1030)은, 예를 들면, 여기에 설명된 컴포넌트들을 이용하여 변환들을 수행하는 스레드들을 수용할 수 있다. 클라이언트(1010)와 서버(1030) 사이에 송신되도록 적응된 하나의 가능한통신은 2개 이상의 컴퓨터 프로세스들 사이에 송신되도록 적응된 데이터 패킷의 형태일 수 있다. 시스템(1000)은 클라이언트(들)(1010)와 서버(들)(1030) 사이의 통신을 용이하게 하기 위해 이용될 수 있는 통신 프레임워크(1050)를 포함한다. 클라이언트(들)(1010)는 클라이언트(들)(1010)에 로컬인 정보를 저장하기 위해 이용될수 있는 하나 이상의 클라이언트 데이터 저장소(들)(1060)에 동작 가능하게 연결된다. 유사하게, 서버(들)(1030)는 서버들(1030)에 로컬인 정보를 저장하기 위해 이용될 수 있는 하나 이상의 서버 데이터저장소(들)(1040)에 동작 가능하게 연결된다.위에 설명된 것은 다양한 예시적인 양태들을 포함한다. 물론, 이들 양태들을 설명하기 위해 상상할 수 있는 모 [0051]든 컴포넌트들 또는 방법들의 조합을 설명하는 것은 불가능하지만, 통상의 숙련된 당업자는 많은 추가의 조합들및 치환들이 가능하다는 것을 인지할 수 있다. 따라서, 여기에 설명된 양태들은 부속된 청구항들의 정신 및 범위 안에 있는 모든 그러한 변경들, 수정들 및 변형들을 포함하도록 의도된다.또한, \"포함한다\"는 용어가 상세한 설명 또는 청구항들에서 사용되는 한에는, 그러한 용어는 \"comprising\"이라 [0052]는 용어가 청구항에서 전이 단어로서 이용될 때 해석되는 바와 같이 그 \"comprising\"과 유사한 방식으로 포괄적이도록 의도된다.공개특허 10-2011-0057125-13-도면도면1공개특허 10-2011-0057125-14-도면2공개특허 10-2011-0057125-15-도면3공개특허 10-2011-0057125-16-도면4공개특허 10-2011-0057125-17-도면5공개특허 10-2011-0057125-18-도면6공개특허 10-2011-0057125-19-도면7공개특허 10-2011-0057125-20-도면8공개특허 10-2011-0057125-21-도면9공개특허 10-2011-0057125-22-도면10공개특허 10-2011-0057125-23-"}
{"patent_id": "10-2011-7003151", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "데이터 센터에서 부하 분산 기능들을 분배하는 시스템들 및 방법들. 디멀티플렉서들 및 부하 분산 서버들의 네 트워크는 계산된 스케일링 및 증대 동작을 가능하게 하고, 여기서 부하 분산 동작의 용량은 부하 분산 서버들의 수를 변경하는 것에 의해 조정될 수 있다. 따라서, 부하 분산 기능/설계는 데이터 센터의 부하 분산 및 스위칭 메커니즘들 양쪽 모두에 대한 탄력성 및 융통성을 증가시키도록 분해될 수 있다."}
{"patent_id": "10-2011-7003151", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷과 같은 글로벌 통신 네트워크들은 통신 및 데이터 전송 동작들을 위해 그러한 네트워크들에 의존하는 개 인 및 법인 사용자들의 수가 점점 더 많아짐에 따라 지금은 보편적이다. 통신 보안이 개선됨에 따라, 더 많은 데이터가, 서버 호스트들과 같은, 소스들과 데스티네이션들 사이의 글로벌 통신 데이터 백본을 가로지를 것으로 기대되고, 따라서 데이터를 처리하고 저장하는 엔티티들에 대한 수요가 증가하고 있다. 전형적으로, 그러한 증가된 수요들은 부하를 처리할 더 많은 스위칭 장치들 및 서버들을 추가하는 것에 의해 데스티네이션에서 다루어 진다. 네트워크 부하 분산들(load-balancers)은 서버들(예를 들면, \"호스트들\")의 컬렉션에 의해 호스팅되는 서비스들 에의 클라이언트 액세스를 제공한다. 클라이언트들은 부하 분산에(또는 부하 분산을 통하여) 접속하고, 부하 분산은 클라이언트의 관점에서, 투명하게 그것들을 규칙들의 세트에 따라서 호스트에 전송한다. 일반적으로, 부하 분산 컨텍스트는 세션들로서 표현되는 시퀀스들의 형태로 패킷들을 포함하고; 여기서 그러한 세션들은 전 형적으로 \"분산된(balanced)\" 방식으로 이용 가능한 호스트들 사이에 할당되어야 한다. 또한, 각 세션의 모든 패킷은 일반적으로, (예를 들면, \"세션 어피니티(session affinity)\"에 따라서) 호스트가 활동하는(alive) 동안 은, 동일한 호스트에 보내져야 한다. 이들 문제들을 다루기 위해, 데이터 센터 시스템들은 호스트들의 상태(예를 들면, 라이브니스(liveness)/부하 (load))를 모니터하고 모든 활성 세션들의 테이블의 형태로 상태를 유지하는 모놀리식 부하 분산(monolithic load-balancer)을 이용한다. 새로운 세션이 도착하면, 부하 분산은 이용 가능한 최소 부하의 호스트(least- loaded host)를 선택하고 그 호스트에 세션을 할당한다. 마찬가지로 그리고 세션 어피니티를 제공하기 위해, 부하 분산은 그것의 세션 테이블에 항목을 추가하는 것에 의해 그러한 할당/라우팅 판정을 \"기억\"해야만 한다. 이 세션에 대한 후속의 패킷들이 부하 분산에 도착하면, 단일 테이블 조회가 정확한 호스트를 결정한다. 그러 나, 개별 부하 분산은 단일 고장점(single point of failure) 및 병목 양쪽 모두일 수 있고, 여기서 그러한 세 션 테이블의 사이즈(및 그에 의해 유지되는 상태의 양)는 증가된 처리량과 함께 증가하고 현존하는 세션 트래픽 에 대한 라우팅 판정들은 상태 조회(패킷마다 한 번)를 필요로 한다. 이들 한계를 회피하는 것은 제휴하여 동 작하는 다수의 모놀리식 부하 분산들(스케일 아웃(scale-out)), 및/또는 더 크고, 더 강력한 부하 분산들(스케 일 업(scale-up))을 필요로 한다. 그러나, 이들 부하 분산들을 스케일-아웃하는 것은, 특히 부하 분산들 사이 에 일관된 상태를 유지하는 필요 때문에, 복잡하다. 마찬가지로, 그것들을 스케일 업하는 것은, 고정된 하드웨 어에서 비용 대비 처리량이 비선형적이기 때문에(예를 들면, 2배의 처리량이 가능한 부하 분산은 그 가격의 2배 보다 현저히 더 많은 비용이 든다), 비용이 많이 든다. 또한, 모놀리식 부하 분산들의 신뢰성 염려는, 그러한 시스템들의 고장이 상당한 비용 없이 쉽게 보상될 수 없기 때문에, 관련된 난제들을 더 증가시킨다. 다음은 여기에 설명된 일부 양태들에 대한 기본적인 이해를 제공하기 위하여 간략한 개요를 제공한다. 이 개요 는 청구된 내용의 광범한 개관이 아니다. 그것은 청구된 내용의 중요한 또는 결정적인 요소들을 식별하기 위한 것도 아니고 그것의 범위를 묘사하기 위한 것도 아니다. 그것의 유일한 목적은 뒤에 제공되는 보다 상세한 설 명의 서론으로서 일부 개념들을 간략한 형태로 제공하는 것이다. 본 혁신은 (다른 모놀리식/통합된 부하 분산(그것의 최대 용량은 여전히 저활용(under utilize)될 수 있다)을 추가하는 것과 대조적으로) 증가하는 수요에 연속적으로 적응하는 부하 분산 서버들 및 디멀티플렉서(들)(및/또 는 멀티플렉서들)의 네트워크를 통해, 데이터 센터의 용량에 대한 점차적인 스케일링 및 증대(growth)를 가능하 게 하는 분배된 부하 분산 시스템을 제공한다. 디멀티플렉서는 데이터 센터의 스위칭 시스템들과 부하 분산 서 버들 사이의 인터페이스로서 기능할 수 있다(예를 들면, 10G 포트들을 갖는 L2 스위치들과 1G 포트를 갖는 PC들 사이의 인터페이스로서 작용하는 디멀티플렉서). 그러한 부하 분산 서버들은, 전형적으로 특정한 부하 분산 목 적에 맞추어지지 않은 일반 유형 머신들로 간주되는, 상품 머신들(commodity machines)(예를 들면, 퍼스널 컴퓨 터, 랩톱 등)을 포함한다. 부하 분산 서버들은 가상 IP 주소들(VIP ID)를 더 포함할 수 있고, 그에 따라 애플 리케이션들은 사용할 특정한 서버를 특정하지 않고 그들의 요청들을 그와 관련된 주소에 보낼 수 있고; 부하 분 산은 상기 VIP를 개별 서버들을 나타내는 복수의 MAC(Media Access Control) 주소들에 매핑하는 것(MAC 로테이 션)을 통해 일어날 수 있다. 또한, 그러한 부하 분산 서버들은 서버 고장들로부터 빠른 복구를 가능하게 하기 위해 쌍들로 또는 보다 큰 세트들로 배열될 수 있다. 디멀티플렉서는 상기 요청을 데이터 스트림 패킷들의 검 사에 기초하여 각각의 부하 분산 서버에 다시 보낸다(re-direct). 디멀티플렉서의 고장은 그것들을 각각의 버 디(buddy) L2 스위치들에 부착된 버디 쌍들로 배열함으로써 사용자에게 은폐될 수 있고, 애플리케이션 서버 고 장의 경우에는, 트래픽이 더 이상 고장난 애플리케이션 서버에 보내지지 않도록, 구성이 수정되거나 자동으로 설정될 수 있다. 그러므로, 그리고 사용자의 관점에서, 이용 가능성(availability)이 유지된다. 또한, 디멀티플렉서는 매핑 컴포넌트를 통해, 나중에 그것을 각각의 부하 분산(들)에 전송하기 위한, 들어오는 데이터 스트림의 IP 헤더들(예를 들면, 5-튜플(5-tuple), 소스 주소, 소스 포트, 데스티네이션 주소, 데스티네 이션 포트, 프로토콜)을 검사할 수 있다. 따라서, 데이터 패킷들은 부하 분산 서버에 할당된 패킷의 속성들 및환경 요인들(예를 들면, 부하 분산 서버들에 대한 현재의 부하)에 기초하여 분할될 수 있다. 부하 분산 서버들 은 또한 들어오는 요청들을 데이터 센터에 서비스하는 서버들(예를 들면, 요청 서비스 서버들(request servicing servers), POD 서버들 등)의 동작에 관한 지식을 소유하고 있다. 따라서, 클라이언트 측으로부터 데 이터 센터에 요청들을 제출하기 위해 단일 IP 주소가 이용되고, 이는 클라이언트에 제시된 복수의 요청 서비스 서버들에 투명성을 제공한다. 관련된 양태에서, 디멀티플렉서와 관련된 매핑 컴포넌트가 들어오는 데이터 스트림을 검사하고, 그와 관련된 모 든 패킷들을 부하 분산 서버에 할당할 수 있고(예를 들면, 무상태 매핑(stateless mapping)) - 여기서 데이터 패킷들은 패킷의 속성들 및 서버들에 대한 현재의 부하 등과 같은 환경 요인들에 기초하여 분할된다. 그 후, 요청들은 부하 분산 서버들로부터 요청 서비스 서버들로 전송될 수 있다. 그러한 배열은 시스템에 대한 안정성 을 증가시킴과 동시에 그의 스케일링에 대한 융통성을 증가시킨다. 따라서, 부하 분산 기능/설계는 부하 분산 및 스위칭 메커니즘들 양쪽 모두에 대한 탄력성 및 융통성을 증가시키도록 분해될 수 있다. 그러한 시스템은 또한 시스템 사이즈가 증가할 때 일정한 정상 상태 호스트당 대역폭(constant steady-state per-host bandwidth)을 유지하는 것을 용이하게 한다. 또한, 본 발명의 부하 분산 방식은 시스템 내의 변화하는 부하/트 래픽 조건들에 신속하게 응답한다. 일 양태에서, 요청들은 L2 캐시들에 의해 수신되고 디멀티플렉서에 의해 부하 분산 서버들(예를 들면, 물리적 및/또는 논리적 인터페이스들, 여기서 다수의 MAC 주소들이 VIP와 관련된다)의 전체에 걸쳐 분배될 수 있다. 또한, 추가의 양태에서 부하 분산 기능들은, 그들의 기능을 더 강화하기 위해, TOR(top of rack) 스위치들의 일 부로서 통합될 수 있고 - 여기서 VIP ID(identity)는 그러한 TOR 스위치들에 존재할 수 있고 이는 서버들의 랙 (rack)이 VIP ID 또는 ID들에 보내진 요청들에 이용 가능한 모든 서버들의 계산 능력을 갖는 유닛으로서 작용할 수 있게 한다. 본 혁신의 방법에 따르면, 처음에 요청(들)이 데이터 센터에 의해 수신되고, 여기서 그러한 들어오는 요청은 0 개 또는 한개 이상의 스위치들을 통해 디멀티플렉서에 라우팅된다. 그러한 디멀티플렉서는 또한 상기 스위치들 을 복수의 부하 분산 서버들과 인터페이싱하고, 여기서 디멀티플렉서는 상기 요청을 데이터 스트림 패킷들의 검 사에 기초하여 각각의 부하 분산에 다시 보낸다. 본 혁신의 분배된 배열은 계산된 스케일링 및 증대를 가능하 게 하고, 여기서 부하 분산 동작의 용량은 부하 분산 서버들의 수를 변경하는 것에 의해 조정되고; 따라서 서비 스들의 저활용(underutilization)을 완화한다. 또한, 각 요청은 개념적으로는 모든 그러한 요청들이 데이터 센 터와 관련된 단일 IP 주소에 제출되더라도 상이한 부하 분산 서버에 의해 처리될 수 있다. 전술한 및 관련된 목적들의 달성을 위해, 청구된 내용의 특정한 예시적인 양태들이 다음의 설명 및 첨부된 도면 들과 관련하여 여기에 설명된다. 이들 양태들은 본 내용이 실시될 수 있는 다양한 방법들을 나타내고, 그것들 모두는 청구된 내용의 범위 내에 있도록 의도된다. 다른 이점들 및 신규한 특징들은 도면들과 함께 고려될 때 다음의 상세한 설명으로부터 명백해질 것이다."}
{"patent_id": "10-2011-7003151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이제 첨부된 도면들을 참조하여 본 혁신의 다양한 양태들이 설명되며, 도면들에서 같은 번호들은 전체에 걸쳐서 같은 또는 대응하는 부분들을 지시한다. 그러나, 도면들 및 그에 관한 상세한 설명은 청구된 내용을 개시된 특 정한 형태로 제한하도록 의도되어 있지 않다는 것을 이해해야 한다. 오히려, 그 의도는 청구된 내용의 정신 및 범위 안에 분류되는 모든 변경들, 동등물들 및 대안들을 망라하고자 하는 것이다. 도 1은 데이터 센터의 용량에 대한 점차적인 스케일링 및 증대를 가능하게 하는, 본 혁신의 양태에 따른 분배된 부하 분산 시스템에 대한 개략 블록도를 예시한다. 일반적으로, 데이터 센터는 분배 처리를 용이하게 하는 중앙 리포지토리를 나타내고(예를 들면, 클라이언트/서버), 여기서 애플리케이션들 및/또는 서버 들은 그에 의해 호스팅될 수 있다(예를 들면, 데이터베이스들, 파일 서버들, 애플리케이션 서버들, 미들웨어 등). 예를 들면, 데이터 센터는 그의 분배 처리를 용이하게 하기 위해 웹 서비스들, 클라우드 서비스들, ERP(enterprise resource processing), 및 CRM(customer relationship management)을 위한 데이터, 코드, 또는 처리 능력들 중 임의의 것을 포함할 수 있다. 또한, 그러한 데이터 센터는 서버 랙들, 통신 랙들, 전력 분배 랙들, 컴퓨터실 공기 조절 장치들 등을 포함할 수 있다. 유사하게, 그러한 데이터 센터와 관련된 데이터 베이스들은 랙 항목 id, 이름, 데이터 센터, 콜로케이션(collocation), 로우(row), 캐비닛, 시작 슬롯 번호 및 항목이 차지하는 슬롯들의 수를 포함하는 랙 레이아웃 테이블을 포함할 수 있다. 분배된 부하 분산 시스템은 디멀티플렉서(들) 및 부하 분산에 전용되는 서버들(예를 들면, 부하 분산 서버들)(111, 113, 115)(1 내지 n, 여기서 n은 정수임)의 배열의 일부로서 구현될 수 있다. 이 출원에서 설명 되는 바와 같이, 디멀티플렉서라는 용어는 전형적으로 요청 서비스 서버들에 걸쳐서 작업 부하를 분배하는 것을 기술하는 것을 나타낸다. 그럼에도 불구하고, 외부 사용자들 또는 작업 부하의 소스들과 요청 서비스 서버 사 이에 연결을 제공할 때는, 멀티플렉서 및/또는 디멀티플렉서가 더 구현될 수 있다. 디멀티플렉서는 스위 치 시스템으로부터 트래픽을 획득하고 그것을 부하 분산 서버들(111, 113, 115)에 재분배할 수 있고, 여기 서 그러한 부하 분산 서버들은, 전형적으로 특정한 부하 분산 용도로 맞추어지지 않은 일반 유형 머신들로 간주 되는, 퍼스널 컴퓨터, 랩톱 등과 같은 상품 머신을 이용할 수 있다. 디멀티플렉서는, 나중에 각각의 부하 분산(들)에 전송하기 위한, 들어오는 데이터 스트림의 IP 헤더들(예를 들면, 5-튜플, 소스 주소, 소스 포트, 데 스티네이션 주소, 데스티네이션 포트, 프로토콜)의 검사를 위한, 하드웨어 및 소프트웨어 컴포넌트들 양쪽 모두 를 포함할 수 있고, 여기서 데이터 패킷들은 패킷의 속성들/환경 요인들(예를 들면, 부하 분산 서버들에 대한 현재의 부하)에 기초하여 분할되어, 부하 분산 서버들(111, 113, 115)에 할당된다. 그러한 할당은 디멀티플렉 서와 관련되는 매핑 컴포넌트(도시되지 않음)를 통해 더 용이해질 수 있다. 예를 들면, 매핑 컴포넌트는 (주어진 세션에 대한 패킷들의 순차적인 전달을 유지하기 위해) 라운드-로빈, 랜덤, 레이어-3/4 해싱과 같은 메 커니즘 등을 이용하여 부하 분산 서버들(111, 113, 115)에 데이터 패킷들을 분배할 수 있다. 마찬가지로, 부하 분산 서버들(111, 113, 115)은 그 후 라우팅 함수에 의해 결정된 복수의 요청 서비스 서버들 (117, 119, 121)(1 내지 m, 여기서 m은 정수임)에 그의 서비싱을 위해 패킷들을 라우팅할 수 있다. 예를 들면, 패킷 스트림의 라우팅은 다수의 세션들을 이용할 수 있고, 여기서 요청 서비스 서버에의 할당은 모든 그러한 요 청 서비스 서버들(117, 119, 121)의 라이브니스 및 부하를 평가한 후에 일어난다. 달리 말하면, 부하 분산 서 버들(111, 113, 115)은 들어오는 요청들을 데이터 센서에 서비스하는 서버들(117, 119, 121)(예를 들면, 요청 서비스 서버들, POD 서버들 등)의 동작에 관한 지식을 소유하고 있다. 데이터 센터 내의 분배된 부하 분산의 그러한 배열은 데이터 센터의 요건들에 기초하여 부하 분산 능 력들의 스케일링에 대한 융통성을 증가시킨다. 그러므로, 부하 분산 기능/설계는 부하 분산 및 스위칭 메커니 즘들 양쪽 모두에 대한 탄력성 및 융통성을 증가시키도록 분해될 수 있다. 이것은 시스템 사이즈가 증가할 때 일정한 정상 상태 호스트당 대역폭(constant steady-state per-host bandwidth)을 유지하는 것을 용이하게 한 다. 또한, 본 발명의 부하 분산 방식은 시스템 내의 변화하는 부하/트래픽 조건들에 신속하게 응답한다. 도 1 은 본질적으로 예시적이고 디멀티플렉서는 또한 스위치들 또는 라우터(들)의 일부일 수 있다는 것을 알아야 한 다. 관련된 양태에서, 복수의 서버들 사이에 일련의 요청들을 할당하는 것과 같은, 작업 부하를 분배하는 것은 2개 의 단계들로 분리될 수 있다. 제1 단계에서, 작업 부하는 제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분 배 알고리즘을 이용하여 복수의 부하 분산 서버들 사이에 분할될 수 있다. 제2 단계에서, 부하 분산 서버는 제1 단계에 의해 그것에 할당된 작업 부하를, 제2 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘을 통해 복수의 요청 서비스 서버들 사이에 더 분배할 수 있다. 예를 들면, 제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘은 주로 하드웨어로 구현되는 상당히 단순한 동작들을 이용함으로써 성능을 최대화하고, 필요한 세션 상태의 양을 감소시키고, 큰 작업 부하를 처리 하는 비용을 최소화하도록 선택될 수 있다. 그러므로, 제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘은 디멀티플렉서라고 불릴 수 있다. 아래에 상세히 설명되는 바와 같이, 제1 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘에 대한 특정한 구현은, 하드웨어로서의 복수의 스위치들 또는 라 우터들, 소프트웨어로서의 링크 상태 프로토콜(예를 들면, OSPF), 세션 ID로서의 데스티네이션 IP 주소, 및 작 업 부하 분배 알고리즘으로서의 같은 비용 다중 경로의 사용; 하드웨어로서의 단일 스위치, (주요 스위치 벤더의 용어로 포트-채널이라고도 불리는) 소프트웨어로서의 스위치의 링크 결합 능력, 및 알고리즘으로서의 스 위치의 링크 결합 구현들에 의해 제공된 다양한 알고리즘들 중 하나(예를 들면, IP 5-튜플의 해시, 라운드 로빈 등)의 사용을 포함할 수 있다. 추가의 양태에 따르면, 제2 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘은 부하 분산 서버의 융 통성을 최대화하도록 선택될 수 있다. 전형적으로, 부하 분산 서버가, 그의 판정 프로세스의 일부로서 이용 가 능한 정보(예를 들면, 서빙하고 있는 현재의 작업 부하; 적절한 요청 서비스 서버에 보내져야 하는 요청 또는 작업 부하 항목의 딥 인스펙션(deep inspection); 다른 부하 분산 서버들이 서빙하고 있는 작업 부하; 멀티플렉 서/디멀티플렉서를 구현하는 컴포넌트들의 작업 부하 또는 상태; 요청 서비스 서버들의 작업 부하 또는 상태; 미래의 시간들에 대한 이들 엘리먼트들 중 임의의 것의 작업 부하 또는 상태에 관한 예측들 등에 관련된 정보) 를 이용하는, 임의의 작업 부하 분배 알고리즘을 구현할 수 있는 것은 바람직하다. 또한, 부하 분산 서버가, 암호화, 암호 해독, 인증, 또는 로깅과 같은 기능을 요청 서비스 서버들로부터 오프로드할 수 있는 것은 바람직 하다. 제2 유형의 하드웨어에 대한 특정한 양태는 데이터 센터 서버들, 데스크톱/홈 컴퓨터들, 또는 랩톱들로 서 일반적으로 이용되는 유형의 범용 컴퓨터일 수 있고 이는 그러한 장치들의 낮은 비용 및 임의의 원하는 기능 을 구현하는 소프트웨어 및 알고리즘들을 수용하고 실행하는 그들의 능력 때문이다. 제1 유형 및 제2 유형의 하드웨어, 소프트웨어, 및 작업 부하 분배 알고리즘은, 예를 들면, 목표 비용, 목표 성 능, 및 현존하는 장비의 성능에 따라서 다양한 방법들로 조합될 수 있다는 것을 알아야 한다. 또한 본 혁신은 상품 서버들이 이용될 수 있는 레벨로 작업 부하의 분해를 위한 상당히 단순한 고속 메커니즘(제1 유형의 하드 웨어, 소프트웨어, 및 작업 부하 분배 알고리즘); 및 요청 서비스 서버들에의 요청들의 원하는 분배를 구현하는 것(예를 들면, 하드웨어에 상당한 투자의 필요 없이, 퍼스널 컴퓨터들에서 실행될 수 있는 임의의 소프트웨어를 이용하는 것)을 가능하게 한다는 것도 알아야 한다. 또한, 본 혁신에 따른 배열은, 작업 부하가 증가하거나 감 소할 때 작업 부하 분산 서버들의 수가 작업 부하에 부합하도록 각각 증가되거나 감소될 수 있도록, 점증적으로 스케일링 가능하다. 분배된 부하 분산 시스템에 더해지거나 그것으로부터 감해지는 입도(granularity)는 종래의 시스템(예를 들면, 종래의 모놀리식 부하 분산들)에 대한 입도보다 현저히 미세한 그레인(grain)이다. 개념적으로, 디멀티플렉서와 부하 분산 서버들 사이에 제1 네트워크, 및 부하 분산 서버들과 요청 서비스 서버 들 사이에 제2 네트워크가 존재할 수 있다. 그러한 네트워크들 각각은 임의의 수의 라우터들, 스위치들 또는 링크들(예를 들면, 아무것도 없는 것을 포함함)로 구성될 수 있다. 또한, 전형적으로 제1 네트워크 또는 제2 네트워크의 유형에는 어떤 제약도 존재하지 않는다. 예를 들면, 네트워크들은 레이어 2, 레이어 3, 또는 레이 어 4 네트워크들 또는 그의 임의의 조합일 수 있다. 도 2는 본 혁신의 분배된 부하 분산 서버들과 대조적으로, 모놀리식 부하 분산(들)(230, 232, 234)을 이용하는 종래의 부하 분산 시스템을 예시한다. 모놀리식 부하 분산(230, 232, 234)은 전형적으로 요청들을 데이터센터 의 다양한 요청 서비스 서버들 사이에 퍼뜨린다. 예를 들면, 모놀리식 부하 분산(230, 232, 234)은 요청들을 \"백엔드\" 서버들 중 하나의 백엔드 서버에 요청하고, 이 백엔드 서버는 통상적으로 모놀리식 부하 분산 (230, 232, 234)에 응답한다 - 기능들의 내부 분리에 관하여 아는 데이터를 요청하는 클라이언트 없음. 내부 네트워크의 구조를 은폐하여 커널의 네트워크 스택 또는 다른 포트들에서 실행하는 관련되지 않은 서비스들에 대한 공격들을 막음으로써, 클라이언트들이 직접 백엔드 서버들과 접촉하는 것을 막을 때 추가적인 보안이 획득 된다. 데이터 센터의 용량이 증가할 때, 다른 모놀리식 부하 분산이가 추가되지만, 그와 관련된 용량은 데이터 센터에 대한 다음 확장까지 미사용 상태로 남는다. 그러나, 이것은 하드웨어, 소프트웨어, 셋업, 및 관리에 관 하여 값비싼 제안일 수 있다. 따라서, 모놀리식 부하 분산을 이용하는 것에 의해, 시스템의 증강은 데이터 센터의 점증적인 증대를 수용하도록 효율적으로 맞추어질 수 없다. 관련된 양태에서, 그러한 모놀리식 부하 분산 은 전형적으로 백 엔드 서버들의 동작을 알지 못하고 일반적으로 백 엔드 서버와 관련된 머신들 사이 에 지능적인 분배 선택들을 쉽게 공급하지 않는다. 도 3은 본 혁신의 추가의 양태에 따른 분해된 및 분배된 부하 분산 시스템에 대한 추가의 양태를 예시한다. 시스템은 부하 분산 기능들이 TOR(top-of-rack) 스위치들(311, 313, 315)(1 내지 k, 여기서 k 는 정수임)의 일부로서 통합될 수 있게 하여 그들의 기능을 더 강화하고 강화된 TOR을 형성한다. 시스템에서, VIP ID가 TOR 스위치들(311, 313, 315)에 존재할 수 있고, 이는, 예를 들면, 레이어 3 기능 들을 더 가능하게 할 수 있다. 전형적으로, TOR 스위칭은, 랙 내의 서버들에 대한 빠른 포트간 스위칭(port- to-port switching), 업링크의 예측 가능한 초과 신청 및 고장 격리 및 봉쇄를 돕는 보다 작은 스위칭 도메인들 (랙당 1개)과 같은, 다양한 구조적 이점들을 공급할 수 있다. 그러한 배열에서 VIP(들)는 다수의 TOR들에 존재할 수 있다. 멀티플렉서/디멀티플렉서의 기능은 구름 윤곽에 의해 도 3에 나타내어진 바와 같이 분배 된 멀티플렉서/디멀티플렉서를 생성하기 위해 스위치들 및/또는 라우터들의 같은 비용의 다중 경로 라우팅 능력 을 이용하여 구현될 수 있다. 그러므로, 부하 분산 서버들의 기능은 강화된 TOR에 존재할 수 있다. 도 4는 본 혁신의 추가의 양태에 따른 분배된 부하 분산 시스템을 구현하는 추가의 방법을 예시한다. 예 시적인 방법은 여기서 다양한 이벤트들 및/또는 액트들을 나타내는 일련의 블록들로서 예시되고 설명되지만, 본 발명은 그러한 블록들의 예시된 순서에 의해 제한되지 않는다. 예를 들면, 일부 액트들 또는 이벤트들은, 본 발명에 따라, 여기에 예시된 순서는 별문제로 하고, 상이한 순서들로 및/또는 다른 액트들 또는 이벤트들과 동 시에 일어날 수 있다. 또한, 본 발명에 따른 방법을 구현하기 위해 예시된 블록들, 이벤트들 또는 액트들이 모 두 다 요구되지 않을 수도 있다. 또한, 본 발명에 따른 예시적인 방법 및 다른 방법들은 여기에 예시되고 설명 된 방법과 관련하여 구현될 수 있을 뿐만 아니라, 예시되거나 설명되지 않은 다른 시스템들 및 장치들과 관련하 여 구현될 수도 있다는 것을 알 것이다. 처음에, 단계에서는 요청이, 예를 들면, 그와 관련된 수의 패킷 들을 갖는 데이터 스트림으로서, 데이터 센터에 의해 수신된다. 다음으로 단계에서는, 그러한 들어오는 데이터 패킷들이 플로우의 식별을 위한 필드들을 식별하기 위해 검 사될 수 있고, 여기서 동일한 플로우 내의 모든 패킷은 단계에서 동일한 부하 분산 서버에서 종료하기 위 해 동일한 경로를 따를 수 있다. 그러므로, 패킷들은 패킷들의 속성들 및 요청 서비스 서버들의 건강, 이용 가 능성, 서비스 시간, 또는 부하; 부하 분산 서버들의 건강, 이용 가능성 또는 부하; 디멀티플렉서를 구현하는 컴 포넌트들의 건강 또는 이용 가능성과 같은 환경 요인들에 기초하여 분할될 수 있고, 여기서 부하 분산 서버들로 의 패킷들을 다시 보내는 것은, 부하 분산 서버들에 관련된, 네트워크 경로 인식 및 서비스 인식인 지능적인 방 식으로 일어난다. 부하 분산들에의 플로우들의 할당에 영향을 미치는 요인들의 변화들에 응답하는 방식으로 부 하 분산들에 플로우들을 보내기 위해, 일관된 해싱(consistent hashing)과 같은, 잘 알려진 기법들이 이용될 수 있다. 다음으로 단계에서는, 부하 분산 서버가, 예를 들면, 복수의 서비스 요청 서버들 사이에 관련된 태 스크들을 분할할 수 있다. 도 5는 본 혁신의 양태에 따른 부하 분산 서버들에의 무상태 매핑을 제공할 수 있는 매핑 컴포넌트를 예시 한다. 매핑 컴포넌트는 각 세션 패킷을 라우팅 함수에 의해 미리 정의된 지정된 부하 분산 서버에 보낼 수 있다. 세션은 몇 개의 프로토콜들, 다수의 개별 접속들을 스팬(span)할 수 있고, 불확정한 길이의 시 간을 지속할 수 있는 2개의 네트워크 엔티티들 사이의 논리적인 일련의 요청들 및 응답들이라는 것에 유의한다. 일부 공통의 세션 유형들은 TCP(Transmission Control Protocol), FTP(File Transfer Protocol), SSL(Secure Socket Layer), IPSec(IP Security)/L2TP(Layer 2 Tunneling Protocol), PPTP(Point-to-Point Tunneling Protocol), RDP(Remote Desktop Protocol) 등을 포함한다. 대부분의 프로토콜들에 대한 세션의 특징화는 정의 가 명확하고, 따라서 각 세션에 대한 명백한 시작과 끝, 및 그러한 세션을 구별하기 위한 관련된 식별자가 존재 한다. 그러나, 일부 세션 유형들은, 뚜렷한 시작을 갖지만, 유휴 타임아웃(idel timeout) 또는 최대 세션 지속 기간과 같은 추론된 끝을 가질 수 있다. 각 세션 패킷마다, 세션 ID가 라우팅 함수에의 입력으로서 이용되기 때문에, 세션 어피니티(session affinity)가 유지된다; 즉, 주어진 세션의 각 패킷은 동일한 부하 분산 서버에 라우팅될 수 있다. 또한, 매핑 컴포넌트는, 모든 부하 분산 서버들의 현재의 부하 상태를 고려하여, 부하 분산 서버의 어느 것에 각 세션 이 할당되고 라우팅될 것인지를 결정한다. 매핑 컴포넌트는 각 세션 패킷을 검출하고, 예를 들면, 최초 세션 패킷, 및 최후 세션 패킷 상의 세션 ID 및/또는 특별한 태그를 포함하는 라우팅 정보에 대하여 각 세션 패킷에 문의한다. 따라서, 최초 패킷또는 최후 패킷이 아닌 임의의 패킷은 중간 세션 패킷으로 간주된다. 또한, 세션 ID가 생성되고 할당되었을 때, 그것은 전형적으로 후속의 세션들에 대하여 다시 사용되지 않을 것이고, 이에 따라 주어진 패킷이 속하는 세션에 관하여 모호함이 없을 것이다. 일반적으로, 주어진 세션 ID는 세션에 대하여 고유하다고 가정될 수 있 고, 그에 의해 표준 네트워크 원리들 또는 컴포넌트들에 의해 고유성이 제공된다. 그러므로, 데이터 패킷들은 패킷의 속성들 및 환경 요인들(예를 들면, 부하 분산 서버들에 대한 현재의 부하)에 기초하여 분할되고, 부하 분산에 할당될 수 있다. 부하 분산 서버들은 또한 들어오는 요청들을 데이터 센터에 서비스하는 다른 서버들(예를 들면, 요청 서비스 서버, POD 서버 등)의 동작에 관한 지식을 소유하고 있다. 따 라서, 시스템은 부하 분산 서버들 중 하나 이상에 대한 현재의 이용 가능성을 정의하는 하나 이상의 라우 팅 함수들을 이용한다. 라우팅 함수는 또한 세션 어피니티를 유지하기 위해 동일한 세션의 패킷들이 계속해서 동일한 데스티네이션 호스트에 라우팅되도록 데스티네이션 부하를 고려할 수 있다. 도 6은 복수의 TOR 스위치들 사이에 부하 분산 능력들을 분배하는 방법을 예시한다. 처음에 단계에서는 VIP ID가 TOR 스위치에 할당될 수 있고, 여기서 VIP가 다수의 TOR들에 할당되면, 같은 비용의 다중 경로 라우팅 이 다수의 TOR들에 부하 분산할 수 있다. 다수의 MAC 주소들이 VIP와 관련되고, 여기서 그러한 가상 IP 주소는 사용할 특정한 서버를 지정하지 않고 서버들에 서비스 요청들을 보낼 수 있다. 그러므로, TOR은 관련된 서버들 에 해시 또는 라운드 로빈 알고리즘을 이용하여 트래픽을 다시 보낼 수 있다. 또한, 서버 고장의 경우에는, 트 래픽이 더 이상 고장난 서버에 보내지지 않도록 구성이 수정되거나 자동으로 설정될 수 있다. 다음으로 단계 에서는, 부하 분산 기능들이 스위치들 사이에 분배될 수 있고, 여기서 부하 분산 서버는 그렇게 강화되는 TOR 스위치의 일부로서 존재할 수 있다. 단계에서는 서비스 데이터 센터에 의해 수신된 요청이 서비스 요 청들과 관련된 패킷들을 처리하기 위해 TOR 스위치에 전송될 수 있다. 또한, 부하 분산 서버들에 관련된, 경로 인식 및 서비스 인식인 지능적인 방식으로 관련된 서비스 서버들에 요청을 보내기 위해, 멀티플렉싱/디멀티플렉 싱 능력들이 하드웨어 및/또는 소프트웨어 컴포넌트들의 형태로 TOR 스위치들의 일부로서 구현될 수 있다. 도 7은 요청 서비스 서버들과 관련된 랙들의 일부로서 부하 분산 서버(들)을 배치하는 부하 분배 시 스템의 추가의 양태를 예시한다. 그러한 배열은 서비스 요청 서버들의 일부로서 추가적인 부하 분산을 허 용하고, 부하 분산 서버들은 요청 서빙 서버들로부터 임무를 더 오프로드할 수 있다. 디멀티플렉서는 또 한 들어오는 데이터 스트림들을 부하 분산 서버(들)에 터널링하는 것을 허용한다. 터널(들)은 디멀티플렉 서로부터 부하 분산 서버로(및/또는 부하 분산 서버들로부터 요청 서비스 서버들로) 확립될 수 있고, 여기서 세션들은 그러한 터널을 통하여 교섭된다. 그러한 터널링은 또한 요청들의 유형 및/또는 관련된 스위치 들(예를 들면, L2/L3)에 따라서 서비스 요청 서버들에 다른 터널들을 확립하는 것을 동반할 수 있다. 디멀티플 렉서는 또한 해싱 함수들에 기초하여 부하 분산 서버들을 지정할 수 있고, 여기서 부하 분산 서버들은 그 후 서비스 요청 서버와 통신할 수 있다. 예를 들면, 디멀티플렉서는 이용 가능한 부하 분산 서버들 및/또는 서비스 요청 서버들에 분산된 방식으로 패킷 부하를 분배하는 동일한 라우팅 함수를 생성할 수 있다. 지정된 서버는, 예를 들면, 종래의 패킷 라우팅 방식들 및 기술들에 따라서 계속해서 세션 패킷들을 수신한다. 그러므로, 세션 정보는 부하 분산을 용이하게 하기 위해 라우팅 함수에 대비하여 처리될 수 있다. 디멀티플렉서는, 세션 어피니티를 유지하기 위해, 최후 패 킷이 검출될 때까지 동일한 호스트에 동일한 세션의 세션 패킷들을 계속해서 라우팅한다. 도 8은 들어오는 요청을 부하 분산 서버들 및/또는 서비스 요청 서버들 사이에 언제, 어디에, 어떻게 분배할지 를 추론하고 및/또는 결정하는 것을 용이하게 하기 위해 이용될 수 있는 인공 지능(AI) 컴포넌트를 이용하 는 시스템을 예시한다. 여기서 사용될 때, \"인터페이스\"라는 용어는 일반적으로 이벤트들 및/또는 데이터 를 통해 캡처된 관찰들의 세트로부터 시스템, 환경, 및/또는 사용자의 상태들을 추리하거나 추론하는 프로세스 를 지시한다. 추론은 특정한 컨텍스트 또는 동작을 식별하기 위해 이용될 수 있고, 또는, 예를 들면, 상태들에 대한 확률 분포를 생성할 수 있다. 추론은 확률적일 수 있다 - 즉, 데이터 및 이벤트들의 고려에 기초하여 흥 미 있는 상태들에 대한 확률 분포의 계산. 추론은 또한 이벤트들 및/또는 데이터의 세트로부터 보다 높은 레벨 의 이벤트들을 구성하기 위해 이용되는 기법들을 지시할 수 있다. 그러한 추론은, 이벤트들이 시간적으로 근접 하게 상관되든 아니든 간에, 이벤트들 및 데이터가 하나의 또는 몇 개의 이벤트 및 데이터 소스들로부터 유래하 든 간에, 관찰된 이벤트들 및/또는 저장된 이벤트 데이터의 세트로부터 새로운 이벤트들 또는 동작들의 구성으 로 귀결된다. AI 컴포넌트는 여기에 설명된 발명의 다양한 양태들을 용이하게 하는 것과 관련하여 위에 설명된 각종의 적합한 AI 기반 방식들 중 임의의 것을 이용할 수 있다. 예를 들면, 태스크들 및 부하들을 어떻게 지능적인 방식으로 분산(balance)할지를 명시적으로 또는 암시적으로 학습하기 위한 프로세스는 자동 분류 시스템 및 프로 세스를 통해 용이해질 수 있다. 분류는 사용자가 자동으로 수행되기를 원하는 동작을 예지하거나 추론하기 위 해 확률 및/또는 통계 기반 분석(예를 들면, 분석 유틸리티들 및 비용들을 계산에 넣는)을 이용할 수 있다. 예 를 들면, SVM(support vector machine) 분류자(classifier)가 이용될 수 있다. 다른 분류 접근법들은 베이지 안 네트워크, 결정 트리를 포함하고, 상이한 독립 패턴들을 제공하는 확률적 분류 모델들이 이용될 수 있다. 여기서 사용된 분류는 또한 우선 순위의 모델들을 개발하기 위해 이용되는 통계적 회귀(statistical regression)를 포함한다. 본 명세서로부터 쉽게 이해되는 바와 같이, 본 혁신은 질문에 대해 어떤 응답을 반환할지를 미리 결정된 기준들 에 따라서 자동으로 결정하기 위해 분류자가 이용되도록 (예를 들면, 일반 훈련 데이터를 통해) 명시적으로 훈 련될 뿐만 아니라 (예를 들면, 사용자 행동을 관찰하고, 외부 정보를 수신하는 것을 통해) 암시적으로 훈련되는 분류자들을 이용할 수 있다. 예를 들면, 잘 이해되는 SVM들에 관하여, SVM들은 분류자 생성자 및 특징 선택 모 듈 내의 학습 또는 훈련 단계를 통해 구성된다. 분류자는 입력 속성 벡터, x = (x1, x2, x3, x4, xn)을 그 입 력이 클래스에 속하는 신뢰(confidence)에 매핑하는 함수이다 - 즉, f(x) = confidence(class). 여기서 사용될 때, \"컴포넌트\", \"시스템\" 등의 용어들은, 하드웨어이든, 하드웨어와 소프트웨어의 조합이든, 소 프트웨어 또는 실행 중의 소프트웨어이든 간에, 컴퓨터 관련 엔티티를 지시하도록 의도된다. 예를 들면, 컴포 넌트는 프로세서에서 실행하는 프로세스, 프로세서, 개체, 인스턴스, 실행 파일, 실행의 스레드, 프로그램 및/ 또는 컴퓨터일 수 있지만, 이에 제한되는 것은 아니다. 예로서, 컴퓨터에서 실행하는 애플리케이션 및 컴퓨터 는 양쪽 모두 컴포넌트일 수 있다. 하나 이상의 컴포넌트들이 프로세스 및/또는 실행의 스레드 내에 존재할 수 있고 컴포넌트는 하나의 컴퓨터에 국한되거나 및/또는 2개 이상의 컴퓨터들 사이에 분배될 수 있다. \"예시적인\"이라는 단어는 여기서 예, 실례 또는 예시의 역할을 하는 것을 의미하기 위해 사용된다. 여기서 \"예 시적인\"으로 기술된 임의의 양태들 또는 설계는 반드시 다른 양태들 또는 설계들에 비하여 선호되거나 유리한 것으로 해석되어서는 안 된다. 유사하게, 예들은 여기서 단지 명료성과 이해를 위해 제공되고 본 혁신 또는 그 의 부분을 어떻게든 제한하도록 의도되어 있지 않다. 다수의 추가적인 또는 대안적인 예들이 제시되었을 수 있 지만, 간결성을 위해 생략되었다는 것을 알아야 한다. 또한, 본 혁신의 전부 또는 부분들은 개시된 혁신을 구현하도록 컴퓨터를 제어하는 소프트웨어, 펌웨어, 하드웨 어 또는 그의 임의의 조합을 생성하기 위해 표준 프로그래밍 및/또는 엔지니어링 기법들을 이용하는 시스템, 방 법, 장치, 또는 제조물로서 구현될 수 있다. 예를 들면, 컴퓨터 판독가능 매체는 자기 저장 장치들(예를 들면, 하드 디스크, 플로피 디스크, 자기 테이프 등), 광 디스크들(예를 들면, CD(compact disk), DVD(digital versatile disk) 등), 스마트 카드, 및 플래시 메모리 장치들(예를 들면, 카드, 스틱, 키 드라이브 등)을 포함 할 수 있지만 이에 제한되는 것은 아니다. 또한, 전자 메일을 송수신하는 데 또는 인터넷 또는 LAN(local area network)과 같은 네트워크에 액세스하는 데 이용되는 것들과 같은 컴퓨타 판독가능 전자 데이터를 운반하기 위 해 반송파가 이용될 수 있다는 것을 알아야 한다. 물론, 숙련된 당업자들은 청구된 내용의 범위 또는 정신으로 부터 벗어나지 않고 이 구성에 많은 수정들이 이루어질 수 있다는 것을 인지할 것이다. 개시된 내용의 다양한 양태들에 대한 컨텍스트를 제공하기 위하여, 도 9 및 10뿐만 아니라 다음의 설명은 개시 된 내용의 다양한 양태들이 구현될 수 있는 적합한 환경에 대한 간략한, 일반적인 설명을 제공하도록 의도되어 있다. 본 내용은 위에서 컴퓨터 및/또는 컴퓨터들에서 실행하는 컴퓨터 프로그램의 컴퓨터 실행가능 명령어들 의 일반적인 컨텍스트에서 설명되었지만, 숙련된 당업자들은 본 혁신은 또한 다른 프로그램 모듈들과 조합하여 구현될 수 있다는 것을 인지할 것이다. 일반적으로, 프로그램 모듈은 특정 태스크를 수행하고 및/또는 특정 추 상 데이터 유형을 구현하는 루틴, 프로그램, 컴포넌트, 데이터 구조 등을 포함한다. 또한, 숙련된 당업자들은 본 혁신적인 방법들은 단일 프로세서 또는 멀티프로세서 컴퓨터 시스템, 미니컴퓨팅 장치, 메인프레임 컴퓨터뿐 만 아니라, 퍼스널 컴퓨터, 핸드-헬드 컴퓨팅 장치(예를 들면, PDA(personal digital assistant), 전화기, 시 계 등), 마이크로프로세서 기반 또는 프로그램가능한 가전제품 또는 산업 전자 기기 등을 포함하는, 다른 컴퓨 터 시스템 구성들을 사용하여 실시될 수 있다는 것을 알 것이다. 예시된 양태들은 또한 통신 네트워크를 통해 연결되어 있는 원격 처리 장치들에 의해 태스크가 수행되는 분배 컴퓨팅 환경들에서 실시될 수도 있다. 그러나, 설사 본 혁신의 모든 양태들은 아닐지라도, 일부 양태들은 독립 실행형 컴퓨터들에서 실시될 수 있다. 분배 컴퓨팅 환경에서, 프로그램 모듈은 로컬 및 원격 메모리 저장 장치 둘다에 위치할 수 있다. 도 9를 참조하여, 컴퓨터를 포함하는 본 혁신의 다양한 양태들을 구현하기 위한 예시적인 환경이 설 명된다. 컴퓨터는 처리 장치, 시스템 메모리, 및 시스템 버스를 포함한다. 시스템 버스는 시스템 메모리를 포함한, 그러나 이에 제한되지 않는, 시스템 컴포넌트들을 처리 장치에 연 결한다. 처리 장치는 다양한 이용 가능한 프로세서들 중 어느 것이라도 될 수 있다. 듀얼 마이크로프로 세서들 및 기타 멀티프로세서 아키텍처도 처리 장치로서 이용될 수 있다. 시스템 버스는 메모리 버스 또는 메모리 컨트롤러, 주변 버스 또는 외부 버스, 및/또는 임의의 각종의 이 용 가능한 버스 아키텍처들을 이용하는 로컬 버스를 포함하는 몇몇 유형의 버스 구조(들) 중 어느 것이라도 될 수 있고, 이용 가능한 버스 아키텍처들은, 11 비트 버스, ISA(Industrial Standard Architecture), MSA(Micro Channel Architecture), EISA(Extended ISA), IDE(Intelligent Drive Electronics), VLB(VESA local bus), PCI(Peripheral Component Interconnect), USB(Universal Serial Bus), AGP(Advanced Graphics Port), PCMCIA(Personal Computer Memory Card International Association bus), 및 SCSI(Small Computer Systems Interface)를 포함하지만 이에 제한되는 것은 아니다. 시스템 메모리는 휘발성 메모리 및 비휘발성 메모리를 포함한다. 시동 중과 같은 때에, 컴퓨터 내의 구성요소들 사이의 정보 전송을 돕는 기본 루틴들을 포함하는 기본 입/출력 시스템(BIOS)은 비휘발 성 메모리에 저장된다. 예로서, 비휘발성 메모리는 ROM(read only memory), PROM(programmable ROM), EPROM(electrically programmable ROM), EEPROM(electrically erasable ROM), 또는 플래시 메모리를 포 함할 수 있지만, 이에 제한되는 것은 아니다. 휘발성 메모리는, 외부 캐시 메모리로서 작용하는, RAM(random access memory)을 포함한다. 예로서, RAM은 SRAM(synchronous RAM), DRAM(dynamic RAM), SDRAM(synchronous DRAM), DDR SDRAM(double data rate SDRAM), ESDRAM(enhanced SDRAM), SLDRAM(Synchlink DRAM), 및 DRRAM(direct Rambus RAM)와 같은 다수의 형태들로 이용 가능하지만, 이에 제한되는 것은 아니다. 컴퓨터는 또한 이동식/비이동식, 휘발성/비휘발성 컴퓨터 저장 매체를 포함한다. 도 9는 디스크 저장 장 치를 예시하고, 여기서 각 디스크 저장 장치는 자기 디스크 드라이브, 플로피 디스크 드라이브, 테이 프 드라이브, 재즈(Jaz) 드라이브, 집(Zip) 드라이브, LS-60 드라이브, 플래시 메모리 카드, 또는 메모리 스틱 을 포함하지만, 이에 제한되는 것은 아니다. 또한, 디스크 저장 장치는, CD-ROM(compact disk ROM) 디바 이스, CD-R(CD recordable) 드라이브, CD-RW(CD rewritable) 드라이브 또는 DVD-ROM(digital versatile disk ROM) 드라이브를 포함하지만, 이에 제한되지 않는, 다른 저장 매체와 별도로 또는 조합하여 저장 매체를 포함할 수 있다. 디스크 저장 장치들의 시스템 버스에의 연결을 용이하게 하기 위해, 전형적으로 인터페이 스와 같은 이동식 또는 비이동식 인터페이스가 이용된다. 도 9는 사용자들과 적합한 운영 환경에서 설명된 기본 컴퓨터 리소스들 사이의 매개로서 작용하는 소프트 웨어를 설명한다는 것을 알아야 한다. 그러한 소프트웨어는 운영 체제를 포함한다. 디스크 저장 장치 에 저장될 수 있는, 운영 체제는 컴퓨터 시스템의 리소스들을 제어하고 할당하는 역할을 한다. 시스템 애플리케이션들은 시스템 메모리에 또는 디스크 저장 장치 상에 저장된 프로그램 모듈들 및 프로그램 데이터를 통하여 운영 체제에 의한 리소스들의 관리를 이용한다. 여기에 설명된 다양한 컴포넌트들은 다양한 운영 체제들 또는 운영 체제들의 조합들을 사용하여 구현될 수 있다는 것을 알아야 한다. 사용자는 입력 장치(들)를 통하여 컴퓨터에 명령들 또는 정보를 입력한다. 입력 장치들은, 마 우스, 트랙볼, 스타일러스, 터치 패드와 같은 포인팅 장치, 키보드, 마이크, 조이스틱, 게임 패드, 위성 안테나, 스캐너, TV 튜너 카드, 디지털 카메라, 디지털 비디오 카메라, 웹 카메라 등을 포함하지만, 이에 제한 되는 것은 아니다. 이들 및 기타 입력 장치들은 인터페이스 포트(들)를 통해 시스템 버스를 통하여 처리 장치에 접속된다. 인터페이스 포트(들)는, 예를 들면, 직렬 포트, 병렬 포트, 게임 포트, 및 USB(universal serial bus)를 포함한다. 출력 장치(들)는 입력 장치(들)와 동일한 유형의 포트들 중 일부를 이용한다. 따라서, 예를 들면, USB 포트는 컴퓨터에 입력을 제공하고, 컴퓨터로부터 출력 장치에 정보를 출력하기 위해 이용될 수 있다. 출력 어댑터는 특수한 어댑터들을 필요로 하는 여러 출력 장치들 중에서, 모니터, 스피커, 및 프린터 같은 일부 출력 장치들이 있는 것을 예시하기 위해 제공된다. 출력 어댑터들은, 예로서, 출력 장치와 시스템 버스 사이의 연결의 수단을 제공하는 비디오 및 사운드 카드들을 포함하지만, 이에 제한되는 것은 아니다. 원격 컴퓨터(들)와 같은 다른 장치 들 및/또는 장치들의 시스템들이 입력 및 출력 능력들 양쪽 모두를 제공한다는 것에 유의해야 한다. 컴퓨터는 원격 컴퓨터(들)와 같은 하나 이상의 원격 컴퓨터로의 논리적 접속을 사용하여 네트워크화 된 환경에서 동작할 수 있다. 원격 컴퓨터(들)는 퍼스널 컴퓨터, 서버, 라우터, 네트워크 PC, 워크스테이 션, 마이크로프로세서 기반 기구, 피어 장치 또는 다른 공통의 네트워크 노드 등일 수 있고, 전형적으로 컴퓨터와 관련하여 설명된 구성요소들 중 다수 또는 그 전부를 포함한다. 간결성을 위하여, 메모리 저장 장치 만이 원격 컴퓨터(들)와 함께 예시되어 있다. 원격 컴퓨터(들)는 네트워크 인터페이스를 통하여 컴퓨터에 논리적으로 연결되고 그 후 통신 연결을 통해 물리적으로 연결된다. 네트워크 인터 페이스는 LAN(local-area networks) 및 WAN(wide-area networks)과 같은 통신 네트워크들을 포함한다. LAN 기술들은 FDDI(Fiber Distributed Data Interface), CDDI(Copper Distributed Data Interface), 이더넷 /IEEE 802.3, 토큰 링/IEEE 802.5 등을 포함한다. WAN 기술들은 포인트-투-포인트 링크들, ISDN(Integrated Services Digital Networks) 같은 회선 교환 네트워크들 및 그의 변형들, 패킷 교환 네트워크들, 및 DSL(Digital Subscriber Lines)을 포함하지만 이에 제한되는 것은 아니다. 통신 연결(들)은 네트워크 인터페이스를 버스에 연결하기 위해 이용되는 하드웨어/소프트웨어를 지시한다. 통신 연결은 예시의 명확성을 위해 컴퓨터 내부에 도시되어 있지만, 그것은 컴퓨터 의 외부에 있을 수도 있다. 네트워크 인터페이스에의 연결을 위해 필요한 하드웨어/소프트웨어는, 단지 예시를 위해, 통상의 전화기 등급 모뎀, 케이블 모뎀 및 DSL 모뎀을 포함하는 모뎀들, ISDN 어댑터들, 및 이더 넷 카드들과 같은 내부 및 외부 기술들을 포함한다. 도 10은 본 혁신의 양태에 따른 분배된 부하 분산의 일부로서 이용될 수 있는 샘플-컴퓨팅 환경의 개략 블록도이다. 시스템은 하나 이상의 클라이언트(들)를 포함한다. 클라이언트(들)는 하드웨 어 및/또는 소프트웨어(예를 들면, 스레드, 프로세스, 컴퓨팅 장치)일 수 있다. 시스템은 또한 하나 이 상의 서버(들)를 포함한다. 서버(들)도 하드웨어 및/또는 소프트웨어(예를 들면, 스레드, 프로세 스, 컴퓨팅 장치)일 수 있다. 서버들은, 예를 들면, 여기에 설명된 컴포넌트들을 이용하여 변환들을 수 행하는 스레드들을 수용할 수 있다. 클라이언트와 서버 사이에 송신되도록 적응된 하나의 가능한 통신은 2개 이상의 컴퓨터 프로세스들 사이에 송신되도록 적응된 데이터 패킷의 형태일 수 있다. 시스템(100 0)은 클라이언트(들)와 서버(들) 사이의 통신을 용이하게 하기 위해 이용될 수 있는 통신 프레임워 크를 포함한다. 클라이언트(들)는 클라이언트(들)에 로컬인 정보를 저장하기 위해 이용될 수 있는 하나 이상의 클라이언트 데이터 저장소(들)에 동작 가능하게 연결된다. 유사하게, 서버 (들)는 서버들에 로컬인 정보를 저장하기 위해 이용될 수 있는 하나 이상의 서버 데이터 저장소(들)에 동작 가능하게 연결된다. 위에 설명된 것은 다양한 예시적인 양태들을 포함한다. 물론, 이들 양태들을 설명하기 위해 상상할 수 있는 모 든 컴포넌트들 또는 방법들의 조합을 설명하는 것은 불가능하지만, 통상의 숙련된 당업자는 많은 추가의 조합들 및 치환들이 가능하다는 것을 인지할 수 있다. 따라서, 여기에 설명된 양태들은 부속된 청구항들의 정신 및 범 위 안에 있는 모든 그러한 변경들, 수정들 및 변형들을 포함하도록 의도된다. 또한, \"포함한다\"는 용어가 상세한 설명 또는 청구항들에서 사용되는 한에는, 그러한 용어는 \"comprising\"이라 는 용어가 청구항에서 전이 단어로서 이용될 때 해석되는 바와 같이 그 \"comprising\"과 유사한 방식으로 포괄적 이도록 의도된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2011-7003151", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 혁신의 양태에 따른 분배된 부하 분산 시스템의 블록도를 예시한다. 도 2는 데이터 센터 동작의 일부로서 모놀리식 및/또는 통합된 부하 분산을를 이용하는 종래 기술의 시스템을 예시한다. 도 3은 본 혁신의 추가의 양태에 따른 부하 분산 기능을 갖는 TOR(top-of-rack) 스위치들의 특정한 양태를 예시 한다. 도 4는 본 혁신의 양태에 따른 태스크들을 분배하는 방법을 예시한다. 도 5는 본 혁신의 추가의 양태에 따른 매핑 컴포넌트를 갖는 추가의 부하 분산 시스템을 예시한다. 도 6은 본 혁신의 추가의 양태에 따른 시스템의 일부로서 부하 분산 기능을 분배하는 특정한 방법을 예시한다. 도 7은 요청 서비스 서버들과 관련된 랙들의 일부로서 부하 분산 서버들을 배치하는 부하 분배 시스템의 특정한 양태를 예시한다. 도 8은 본 혁신의 추가의 양태에 따른 부하 분산을 용이하게 하는 인공 지능 컴포넌트를 예시한다. 도 9는 본 혁신의 양태들을 구현하기 위한 적합한 운영 환경의 개략 블록도를 예시한다.도 10은 본 혁신의 샘플-컴퓨팅 환경의 추가의 개략 블록도를 예시한다."}
