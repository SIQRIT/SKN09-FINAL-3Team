{"patent_id": "10-2024-0119354", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0043274", "출원번호": "10-2024-0119354", "발명의 명칭": "생성형 ＡＩ 기반 3차원 이미지 재구성 서비스 제공 시스템", "출원인": "주식회사 스피나이", "발명자": "이준수"}}
{"patent_id": "10-2024-0119354", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "2차원 이미지인 X-Ray 이미지를 생성형 AI(Generative Aritificial Intelligence)에 입력하고, 상기 2차원 이미지에 기하여 3차원 이미지인 CT(Computed Tomography) 이미지를 출력하는 사용자 단말; 및상기 2차원 이미지를 수신하는 수신부, 상기 생성형 AI에 상기 2차원 이미지를 입력하는 입력부, 상기 생성형AI로부터 상기 2차원 이미지에 기한 3차원 이미지를 출력하도록 하는 출력부, 상기 사용자 단말로 상기 3차원이미지를 전달하는 전달부를 포함하는 재구성 서비스 제공 서버;를 포함하는 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템."}
{"patent_id": "10-2024-0119354", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 생성형 AI는,GAN(Generative Adversarial Network) 기반 AI이고,상기 GAN 기반 AI는 PerX2CT 또는 X2CT GAN(Generative Adversarial Network)인 것을 특징으로 하는 생성형 AI기반 3차원 이미지 재구성 서비스 제공 시스템."}
{"patent_id": "10-2024-0119354", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 PerX2CT 또는 X2CT GAN의 인코더(Encoder) 아키텍처인 ResNet 기반 아키텍처를, DenseNet, SENet, ResNext, WideRestNet, ConvNeXt, ViT, EfficientNetV2, SwinViT, MobileNet, ShuffleNet,NASNet, MnasNet, SqueezeNet, RegNet, GhostNet, PNASNet, Xception, DarkNet, EfficientNet, HRNet,BoTNet, TResNet, DeepLab, Fast R-CNN, Faster R-CNN, YOLO, SSD, RetinaNet, FPN, U-Net, SegNet, PSPNet,FCN, DeepLabV3+, DANet, BiSeNet, PointNet, PointNet++, Dynamic Graph CNN 및 DETR 중 적어도 하나의 컨볼루션넷(ConvolutionNet) 기반 아키텍처로 변경하는 것을 특징으로 하는 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템."}
{"patent_id": "10-2024-0119354", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 재구성 서비스 제공 서버는,상기 생성형 AI를 모델링할 때, 학습 데이터셋의 전처리(Pre-Processing) 과정에서, 3차원 이미지에 테두리가추가된 패딩(Padding) 영역에, 상기 패딩 영역이 패딩임을 표시하는 플래그(Flag) 및 좌표를 저장하여 상기 패딩 영역이 학습에 이용되지 않도록 처리하는 학습효율증가부;를 더 포함하는 것을 특징으로 하는 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템."}
{"patent_id": "10-2024-0119354", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0043274-3-제 1 항에 있어서,상기 재구성 서비스 제공 서버는,상기 생성형 AI를 모델링할 때, 학습 데이터셋의 전처리(Pre-Processing) 과정에서, 2차원 이미지로 입력된 일반(General) X-Ray를 합성(Synthetic) X-Ray와 유사하게 만들도록 전처리하는 입력품질유지부;를 더 포함하는 것을 특징으로 하는 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템."}
{"patent_id": "10-2024-0119354", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 재구성 서비스 제공 서버는,상기 3차원 이미지인 CT 이미지를 이용하여 상기 CT 이미지 내 포함된 구조물의 용적을 측정하기 위하여, 상기CT 이미지의 CT 슬라이스의 픽셀값을 기반으로 상기 구조물의 면적을 계산하고, 상기 CT 슬라이스 간 간격을 이용하여 총 용적을 산출하는 구조물용적산출부;를 더 포함하고,상기 구조물은, 척추, 골반 및 대퇴골 중 어느 하나인 것을 특징으로 하는 생성형 AI 기반 3차원 이미지 재구성서비스 제공 시스템."}
{"patent_id": "10-2024-0119354", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 재구성 서비스 제공 서버는,상기 사용자 단말에서 업로드한 수술 전 촬영된 CT 이미지와, 수술 중 촬영된 2차원 이미지로부터 상기 3차원이미지로 재구성된 CT 이미지 간을 매칭(Matching)시켜 화면에 제공하는 수술내비부;를 더 포함하는 것을 특징으로 하는 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템이 제공되며, 2차원 이미지인 X-Ray 이미지를 생성형 AI(Generative Aritificial Intelligence)에 입력하고, 2차원 이미지에 기하여 3차원 이미지인 CT(Computed Tomography) 이미지를 출력하는 사용자 단말 및 2차원 이미지를 수신하는 수신부, 생성형 AI에 2차원 이미지를 입력하는 입력부, 생성형 AI로부터 2차원 이미지에 기한 3차원 이미지를 출력하도록 하는 출력부, 사용자 단말로 3차원 이미지를 전달하는 전달부를 포함하는 재구성 서비스 제공 서버를 포함한다."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템에 관한 것으로, 2D 이미지인 X-Ray 이미지 로부터 3D 이미지인 CT 이미지를 생성형 AI 기반으로 재구성할 수 있는 시스템을 제공한다."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "CT(Computed Tomography)는 시각적으로 정확한 3D 구조를 제공하기 때문에 주로 골절 진단에 일반적으로 사용되 지만, 간혹 수술 중에는 3D 구조 확인이 필요한 경우가 많으며, 이 경우 O-Arm과 같은 이동식 CT 장비가 사용될 수 있으나, 이 장비는 고가의 비용으로 인해 많은 병원에서 도입이 어렵다. 특히, O-Arm과 같은 장비는 설치와 유지 비용이 높고, 대다수의 병원에서는 접근성이 제한적이다. 또, 이동식 CT는 X-Ray에 비해 상대적으로 구매 비용이 높고, 전기 사용량이 많으며, 방사선 노출량이 X-Ray에 비해 수 십 배 높기 때문에, 수술실에서는 주로 이동식 CT 대신 이동식 X-Ray가 사용되고 있다. 하지만, X-Ray는 2차원(2D) 이미지만을 제공하기 때문에, 의료 진은 2D 이미지로부터 대상의 3차원 이미지를 머릿속으로만 상상하여 판단해야 하는 어려움이 있다. 또한, 임 산부에게는 방사선 노출을 최소화 해야 하므로, CT 촬영이 어려운 경우가 많고 소아 또한 CT 촬영을 위해서 수 면제 투여 후 촬영이 필요한 경우가 많아, CT를 촬영하기 어렵고 X-Ray를 이용하여 진단을 내려야 하는 경우가 빈번하다. 이에, X-Ray의 2D 이미지로부터 CT의 3D 이미지를 생성하는 방법이 연구 및 개발되었는데, 이와 관련하여 선행 기술인 한국공개특허 제2024-0050645호(2024년04월19일 공개) 및 한국공개특허 제2022-0028448호(2022년03월08 일 공개)에는, X-Ray 영상을 입력하면 CT 영상을 생성하도록 GAN(Generative Adversarial Network) 모델을 이용하는 구성과, 역으로 MRI나 CT와 같은 3D 이미지에서 2D 이미지인 가상 X-Ray를 생성하는 구성이 각각 개시되 어 있다. 다만, 전자의 경우 GAN에 기반한다고 기재되어 있지만, GAN의 생성자(Generator)의 인코더 아키텍처가 ResNet 기반이므로, 깊이, 너비 및 해상도를 증가시키는데 성능 향상이 제한되는 문제가 발생한다. 후자의 경우에는 3D 이미지에서 2D 이미지로 오히려 차원을 낮추는 구성이지 2D 이미지에서 3D 이미지를 생성하는 구성이 아니다. 최근 X-Ray 이미지로부터 CT 이미지를 생성하도록 PerX2CT 및 X2CT GAN 모델이 개발되었으나, 이는 주 로 ResNet 기반의 인코더 아키텍처를 사용하여 해상도 및 성능 향상에 한계가 있다. 특히, PerX2CT 모델은 128 ×128 해상도의 이미지를 생성하는 데 그쳐, 일반적인 CT의 해상도(512×512) 보다 낮고, 진단 시 정확도에 제 약이 있다. 이에, X-Ray 이미지로부터 CT 이미지를 생성할 때 성능 향상에 한계를 극복할 수 있는 모델의 연구 및 개발이 요구된다."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는, X-Ray 이미지에서 CT 이미지를 생성할 때 PerX2CT이나 X2CT GAN 모델과 같은 생성형 AI 를 이용하되, 생성자의 인코더 아키텍처를 ResNet 기반에서 EfficientNet 기반으로 변경함으로써 성능 향상에 한계를 제거하고, 생성형 AI를 모델링할 때 입력하는 학습 데이터셋의 전처리 과정에서, 패딩(Padding) 영역을 학습하지 않도록 플래그 및 좌표를 지정하여 저장하며, 학습 데이터셋의 입력 이미지인 일반 X-Ray 이미지를 합 성 X-Ray 이미지와 같이 유사하게 변환함으로써 입력 데이터의 품질을 균일하게 맞출 수 있고, CT 이미지를 생 성한 후 구조물의 용적을 측정하여 제공하며, 수술 전 CT 이미지와 수술 중 X-Ray로 생성한 CT 이미지 간 매칭 을 통하여 수술 내비게이션을 제공할 수 있는, 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템을 제공 할 수 있다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으 며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 발명의 일 실시예는, 2차원 이미지인 X-Ray 이미지 를 생성형 AI(Generative Aritificial Intelligence)에 입력하고, 2차원 이미지에 기하여 3차원 이미지인 CT( Computed Tomography) 이미지를 출력하는 사용자 단말 및 2차원 이미지를 수신하는 수신부, 생성형 AI에 2차원 이미지를 입력하는 입력부, 생성형 AI로부터 2차원 이미지에 기한 3차원 이미지를 출력하도록 하는 출력부, 사 용자 단말로 3차원 이미지를 전달하는 전달부를 포함하는 재구성 서비스 제공 서버를 포함한다."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단 중 어느 하나에 의하면, 고해상도 CT 이미지를 생성할 수 있으므로 객체의 세 부 구조를 정확하게 파악, 진단 및 분석할 수 있고, 불필요한 패딩 영역을 학습에서 제외시킴으로써 학습 효율 성을 증가시키며, 입력 데이터의 품질을 일관되게 유지함으로써 생성형 AI의 CT 이미지 추론 성능을 향상시킬 수 있고, 생성형 AI의 생성자의 인코더 아키텍처를 EfficientNet 기반으로 바꿈으로써 성능 및 연산 효율성을 동시에 높일 수 있으며, 정확한 구조물 용적을 측정할 수 있고, 수술 내비게이션으로 사용하는 것과 같이 다양 한 임상적 응용을 가능케 하여 수술의 정확도와 효율성을 향상시킬 수 있다."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 명세서 전체에서 사용되는 정도의 용어 \"약\", \"실질적으로\" 등은 언급된 의미에 고유한 제조 및 물질 허용오차 가 제시될 때 그 수치에서 또는 그 수치에 근접한 의미로 사용되고, 본 발명의 이해를 돕기 위해 정확하거나 절 대적인 수치가 언급된 개시 내용을 비양심적인 침해자가 부당하게 이용하는 것을 방지하기 위해 사용된다. 본 발명의 명세서 전체에서 사용되는 정도의 용어 \"~(하는) 단계\" 또는 \"~의 단계\"는 \"~ 를 위한 단계\"를 의미하지 않는다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1 개의 유닛이 2 개 이상의 하드웨어를 이용하여 실현되어도 되고, 2 개 이상의 유닛이 1 개의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어 에 한정되는 의미는 아니며, '~부'는 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객 체 지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회 로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또 는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기 술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 본 명세서에서 있어서, 단말과 매핑(Mapping) 또는 매칭(Matching)으로 기술된 동작이나 기능 중 일부는, 단말 의 식별 정보(Identifying Data)인 단말기의 고유번호나 개인의 식별정보를 매핑 또는 매칭한다는 의미로 해석 될 수 있다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템을 설명하기 위한 도면이다. 도 1을 참조하면, 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템은, 적어도 하나의 사 용자 단말, 재구성 서비스 제공 서버, 적어도 하나의 촬영 단말을 포함할 수 있다. 다만, 이러 한 도 1의 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템은, 본 발명의 일 실시예에 불과하므로, 도 1을 통하여 본 발명이 한정 해석되는 것은 아니다. 이때, 도 1의 각 구성요소들은 일반적으로 네트워크(Network, 200)를 통해 연결된다. 예를 들어, 도 1에 도시 된 바와 같이, 적어도 하나의 사용자 단말은 네트워크를 통하여 재구성 서비스 제공 서버와 연 결될 수 있다. 그리고, 재구성 서비스 제공 서버는, 네트워크를 통하여 적어도 하나의 사용자 단말 , 적어도 하나의 촬영 단말과 연결될 수 있다. 또한, 적어도 하나의 촬영 단말은, 네트워크 를 통하여 재구성 서비스 제공 서버와 연결될 수 있다. 여기서, 네트워크는, 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미하는 것으로, 이러한 네트워크의 일 예에는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN:Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), 5G NR(New Radio), 6G(6th Generation of Cellular Networks), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷 (Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스(Bluetooth) 네트워크, NFC(Near- Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 하기에서, 적어도 하나의 라는 용어는 단수 및 복수를 포함하는 용어로 정의되고, 적어도 하나의 라는 용어가 존재하지 않더라도 각 구성요소가 단수 또는 복수로 존재할 수 있고, 단수 또는 복수를 의미할 수 있음은 자명 하다 할 것이다. 또한, 각 구성요소가 단수 또는 복수로 구비되는 것은, 실시예에 따라 변경가능하다 할 것이다. 적어도 하나의 사용자 단말은, 생성형 AI 기반 3차원 이미지 재구성 서비스 관련 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 이용하여 X-Ray와 같은 2차원 이미지에 기반하여 CT와 같은 3차원 이미지를 출력 하는 사용자(User)의 단말일 수 있다. 이때, 사용자는 의료진일 수 있으나 이에 한정되는 것은 아니다. 여기서, 적어도 하나의 사용자 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터 로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 내비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데 스크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 사용자 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 사용자 단말은, 예 를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 내비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 재구성 서비스 제공 서버는, 생성형 AI 기반 3차원 이미지 재구성 서비스 웹 페이지, 앱 페이지, 프로그램 또는 애플리케이션을 제공하는 서버일 수 있다. 그리고, 재구성 서비스 제공 서버는, 생성형 AI의 인코더 아키텍처를 ResNet 기반에서 EfficientNet 기반으로 변경하는 서버일 수 있다. 또, 재구성 서비스 제공 서버 는, 생성형 AI를 모델링할 때 필요한 학습 데이터셋을 구축하는 서버일 수 있다. 이때, 재구성 서비스 제 공 서버는 학습 데이터셋 내 패딩 영역을 표시하고 이 패딩 영역이 생성형 AI에서 학습되지 않도록 설정하 는 서버일 수 있다. 또, 재구성 서비스 제공 서버는 학습 데이터셋에 포함된 입력 데이터인 일반 X-Ray 이미지를 합성 X-Ray 이미지와 같이 변환되도록 처리함으로써 입력 데이터의 품질을 일관되게 유지하는 서버일 수 있다. 그리고, 재구성 서비스 제공 서버는 3D 이미지인 CT 이미지로부터 구조물의 용적을 측정하는 서 버일 수 있다. 또, 재구성 서비스 제공 서버는 수술 전 CT 이미지와, 수술 중 X-Ray로 재구성된 CT 이미 지 간을 비교하여 수술 내비게이션을 제공하는 서버일 수 있다. 여기서, 재구성 서비스 제공 서버는, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 내비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스 크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 적어도 하나의 촬영 단말은, 생성형 AI 기반 3차원 이미지 재구성 서비스 관련 웹 페이지, 앱 페이지, 프 로그램 또는 애플리케이션을 이용하여 X-Ray 또는 CT 이미지를 재구성 서비스 제공 서버로 업로드하도록 X-Ray 기기 또는 CT 기기와 연결된 단말일 수 있다. 여기서, 적어도 하나의 촬영 단말은, 네트워크를 통하여 원격지의 서버나 단말에 접속할 수 있는 컴퓨터로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 내비게이션, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스 크톱(Desktop), 랩톱(Laptop) 등을 포함할 수 있다. 이때, 적어도 하나의 촬영 단말은, 네트워크를 통해 원격지의 서버나 단말에 접속할 수 있는 단말로 구현될 수 있다. 적어도 하나의 촬영 단말은, 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, 내비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(CodeDivision Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 도 2는 도 1의 시스템에 포함된 재구성 서비스 제공 서버를 설명하기 위한 블록 구성도이고, 도 3 및 도 4는 본 발명의 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스가 구현된 일 실시예를 설명하기 위한 도 면이다. 도 2를 참조하면, 재구성 서비스 제공 서버는, 수신부, 입력부, 출력부, 전달부, 학 습효율증가부, 입력품질유지부, 구조물용적산출부, 수술내비부를 포함할 수 있다. 본 발명의 일 실시예에 따른 재구성 서비스 제공 서버나 연동되어 동작하는 다른 서버(미도시)가 적어도 하나의 사용자 단말 및 적어도 하나의 촬영 단말로 생성형 AI 기반 3차원 이미지 재구성 서비스 애플 리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 전송하는 경우, 적어도 하나의 사용자 단말 및 적어도 하 나의 촬영 단말은, 생성형 AI 기반 3차원 이미지 재구성 서비스 애플리케이션, 프로그램, 앱 페이지, 웹 페이지 등을 설치하거나 열 수 있다. 또한, 웹 브라우저에서 실행되는 스크립트를 이용하여 서비스 프로그램이 적어도 하나의 사용자 단말 및 적어도 하나의 촬영 단말에서 구동될 수도 있다. 여기서, 웹 브라우 저는 웹(WWW: World Wide Web) 서비스를 이용할 수 있게 하는 프로그램으로 HTML(Hyper Text Mark-up Language)로 서술된 하이퍼 텍스트를 받아서 보여주는 프로그램을 의미하며, 예를 들어 크롬(Chrome), 에지 (Microsoft Edge), 사파리(Safari), 파이어폭스(FireFox), 웨일(Whale), UC 브라우저 등을 포함한다. 또한, 애플리케이션은 단말 상의 응용 프로그램(Application)을 의미하며, 예를 들어, 모바일 단말(스마트폰)에서 실 행되는 앱(App)을 포함한다. 도 2를 참조하면, 수신부는, 2차원 이미지를 수신할 수 있다. 이때 2차원 이미지는 X-Ray일 수 있다. <생성형 AI> 입력부는, 생성형 AI에 2차원 이미지를 입력할 수 있다. 생성형 AI는, GAN(Generative Adversarial Network) 기반 AI일 수 있다. 또, 생성형 AI는 지도학습기반 AI일 수 있다. 또, 생성형 AI는 ① PerX2CT 또 는 ② X2CT GAN(Generative Adversarial Network)일 수 있다. 이때, 생성형 AI는 확률적 생성 모델, 오토인코 더(Auto Encoder), 생성적 대립 신경망인 GAN(Generative Adversarial Network) 등을 포함하는데, 본 발명의 일 실시예에서는 지도학습모델 및 GAN 기반 모델을 이용할 수 있다. 이때, 도 4a는 PerX2CT, 도 4b는 X2CT GAN 의 구조를 도시한다. 도 4a를 참조하면, ① PerX2CT는 두 개의 정면(Posterior-Anterior, PA 또는 Anterior- Posterior, AP) 및 측면(LATeral, LAT) X-Ray 이미지(ImagePA, ImageLat)를 입력으로 사용하여 3D 이미지인 CT 이미지를 재구성하는 모델이다. 이 모델은 X-Ray 이미지 투영(Projecting) 방식을 반영하여 각 좌표에 대해 서 로 다른 특징 조합(Combination)을 제공함으로써 3D 위치에 대한 정보를 얻는 모델이다. PerX2CT는 도 4a와 같 이 2D 인코더(Encoder, E)와 디코더(Decoder, D) 구조를 사용하여 컴퓨팅 복잡도를 줄이고, 빠른 추론 시간을 제공하면서도, 높은 해상도를 가지도록 CT 부분을 재구성할 수 있다. 이 외의 상세한 내용은 논문(Kyung, Daeun, Kyungmin Jo, Jaegul Choo, Joonseok Lee, and Edward Choi. \"Perspective projection-based 3d CT reconstruction from biplanar X-rays.\" In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1-5. IEEE, 2023.)을 참조하기로 한다. ② X2CT GAN는 도 4b 및 도 4c를 참조하면, X2CT GAN도 PerX2CT와 같이 두 개의 정면(Anterior-Posterior, AP) 및 측면(LATeral, LAT) X-Ray 이미지를 입력으로 사용하여 CT 이미지를 재구성하기 위해 GAN을 이용하는 모델이 다. 이 모델은 GAN의 구조를 이용하여 보다 현실적이고 고해상도의 CT 이미지를 생성할 수 있으며, 특히 초저 밀도 뷰(View) 재구성 문제를 해결하는 데 강점을 가진다. X2CT GAN은 일반적인 3D 디코더를 사용하여 깊이 (Depth)축(Z-Axis)을 따라 동일한 특징을 복제함으로써 3D 구조를 재구성한다. 이 외의 상세한 내용은 논문 (Yang CJ, Lin CL, Wang CK, Wang JY, Chen CC, Su FC, Lee YJ, Lui CC, Yeh LR, Fang YD. Generative Adversarial Network(GAN) for Automatic Reconstruction of the 3D Spine Structure by Using Simulated Bi- Planar X-ray Images. Diagnostics (Basel). 2022 Apr 30;12:1121. doi: 10.3390/diagnostics12051121. PMID: 35626277; PMCID: PMC9139385.)을 참조하기로 한다. 이때, 본 발명의 일 실시예에서는, PerX2CT 또는 X2CT GAN의 인코더(Encoder) 아키텍처인 ResNet 기반 아키텍처 를, 다른 더 효율적인 컨볼루션넷(ConvolutionNet) 기반 아키텍처로 변경할 수 있다. 이때, 컨볼루션넷 기반 아키텍처는, DenseNet, SENet, ResNext, WideRestNet, ConvNeXt, ViT, EfficientNetV2, SwinViT, MobileNet,ShuffleNet, NASNet, MnasNet, SqueezeNet, RegNet, GhostNet, PNASNet, Xception, DarkNet, EfficientNet, HRNet, BoTNet, TResNet, DeepLab, Fast R-CNN, Faster R-CNN, YOLO, SSD, RetinaNet, FPN, U-Net, SegNet, PSPNet, FCN, DeepLabV3+, DANet, BiSeNet, PointNet, PointNet++, Dynamic Graph CNN 및 DETR 중 적어도 하 나일 수 있다. 바람직하게는, 이 중에서도 EfficientNet을 이용할 수 있고, 버전은 V2를 이용할 수 있다. <생성형 AI_인코더 아키텍처 변경> 도 4d를 참조하면, EfficientNet은 이미지 분류, 객체 탐지, 세그멘테이션 등 다양한 컴퓨터 비전 작업에서 높 은 성능을 달성하기 위해 설계된 신경망 아키텍처이다. EfficientNet은 모델의 효율성과 성능을 동시에 극대화 하기 위해 다음 표 1과 같은 주요 개념과 기술을 도입하였다. 표 1 주요 개념 기술 복합 스케일링(Compound Scaling)전통적인 모델 확장은 주로 네트워크의 깊이, 너비, 입력 이미지 의 해상도 중 하나만을 조정하는 반면, EfficientNet은 이 세 가 지를 균형 있게 조정함. 이를 통해 모델 크기를 확대할 때, 성 능과 효율성을 모두 극대화할 수 있음 기본 구조(Baseline Network) EfficientNet은 MBConv 블록을 기반으로 하는 MobileNetV2에서 영감을 받음. MBConv 블록은 깊이별 분리 합성곱(Depthwise Separable Convolution)과 확장 레이어(Expansion Layer)를 결 합하여 계산 비용을 줄이면서도 높은 성능을 제공함. 자동화된 모델 설계(Neural Architecture Search, NAS)EfficientNet의 기본 네트워크는 NAS를 통해 설계됨. NAS는 최 적의 네트워크 구조를 자동으로 탐색하고 설계하는 기법으로, 이 를 통해 인공지능 모델의 성능을 극대화할 수 있음. Swish(SiLU) 활성화 함수 EfficientNet은 ReLU 대신 Swish 활성화 함수를 사용함. Swish 함수는 f(x)=xσ(x)로 정의되는데, 네트워크의 비선형성을 증가 시켜 성능을 향상시킬 수 있음. 이러한 특징으로 인하여 EfficientNet은 다양한 비전 작업에서 탁월한 성능을 발휘하며, 특히 이미지넷 (ImageNet) 데이터셋에서 높은 정확도를 기록했다. EfficientNet의 성공은 복합 스케일링과 NAS 기법의 유효성 을 입증했고, 이후 많은 연구에서 이 접근 방식을 채택하게 되었다. 또 도 4e와 같이 ResNet에 비해 높은 정확 도를 가지면서, 파라미터의 수는 적은 것으로 확인되었다.도 4f와 같은 EfficientNetV2는 EfficientNet의 후속 모델로, 이미지 분류와 같은 다양한 컴퓨터 비전 작업에서 높은 성능을 달성하는데 중점을 둔 효율적인 신경망 이다. EfficientNetV2는 EfficientNet과 달리, Stage 1 내지 Stage 3에 Fused-MBConv를 도입하여 정확도를 약 0.3% 향상시켰다. 또한, 학습 중에 점차적으로 입력 이미지의 해상도를 증가시키는 점진적 학습 기법을 도입하 여, 더 빠르고 안정적인 훈련 과정을 가능하게 한다. 또, 네트워크 구조를 개선하여 새로운 층 구성 방식, Swish 활성화 함수, 그리고 향상된 블록 구조를 통해 성능을 최적화하였다. 학습 데이터에 관하여 모델의 일반 화 능력을 높이기 위해 다양한 데이터 증강(Data Augmentation) 기법이 사용되는데, 이는 모델이 더 다양한 상 황에서 잘 작동하도록 도와준다. 도 4g를 참조하면, EfficientNetV2의 성능이 EfficientNet에 비하여 얼마나 향상되었는지 확인할 수 있다. 덧붙여서, 본 발명의 일 실시예에서는 EfficientNet를 적용한 모델(생성형 AI)의 특징 추출(Feature Extraction) 성능을 향상시키기 위해 ImageNet 21K 데이터셋(Dataset)으로 기 학습된 가중치(Pre-Trained Weights)를 이용할 수 있고, 이에 따라 모델의 특징 추출 능력을 강화하고 추론 시간을 단축시킬 수 있다. 특 히, 기 설정된 레이어(Layer)를 고정(Freeze)하여 기 학습된 가중치를 충분히 활용하도록 전이학습(Transfer Learning)을 이용할 수 있다. 이때, 전이학습이란 기존 이미지에서 학습한 정보를 가져와 현재 모델에 활용하 는 것을 의미한다. 방대한 자료를 통해 미리 학습한 가중치(Weight)값을 가져와 본 발명의 모델(생성형 AI)에 사용하는 방법이다. 즉, 모델의 입력 레이어(Input Layer)에서부터 기 설정된 레이어까지 상술한 바와 같이 고 정하여 척추 데이터셋에 대해 효과적으로 학습할 수 있도록 할 수 있다. 또, 로컬 특징맵(Feature Map)을 저수 준(Low-Level)의 특징맵을 포함하는 레이어에서 추출하여 입력으로 들어온 X-Ray 이미지 데이터셋으로부터 실제 유사한 CT 이미지를 재구성할 수 있도록 한다. 이때, 상술한 바와 같이 인코더 아키텍처에 EfficientNetV2를 활용할 수 있는데, EfficientNetV2을 기반으로 X-Ray 이미지로부터 로컬 특징맵을 추출할 수 있다. <EfficientNetV2 인코더> 도 4h를 참조하면, EfficientNetV2 인코더를 만들기 위해 첫 번째로, 입력 부분(Stem, Stage0)과 나머지 7 가 지 Stage 중 Stem 및 Stage1까지를 고정(Freeze)하여 초기 학습의 불필요성을 줄인다. 여기서, 도 4h는 EfficientNetV2 아키텍처(구조)이고, 여기서 Stage 1에서 Stage 3에 대응하는 Fused-MBConv는 도 4f의 우측, Stage 4 내지 Stage 6에 대응하는 MBConv는 도 4f의 좌측에 그 구조가 상세히 개시되어 있다. 여기서, Stem과 Stage1까지를 고정한 후, ImageNet 21K로 미리 학습된 가중치(Pre-Trained Weight)를 적용할 수 있고, 입력 레 이어부터 효과적인 성능을 내기 위한 특정 레이어(Stage 2)까지 고정하여, Spine 데이터셋에 대해 학습을 실시 함으로써, 전이학습(Transfer Learning)의 이점을 최대한 활용할 수 있다. 두 번째로, Stage 3에서 로컬 특징맵을 추출한다. 종래기술에 따른 ResNet-101 기반 인코더에서는, 레이어 2(Layer2)에서 추출하는 것으로 이미지 저수준 특징을 추출했는데, 본 발명의 일 실시예에서도 마찬가지로 EfficientNetV2 인코더에서 초기에 특징맵을 추출하여 저수준 특징을 추출할 수 있다. Stage 1까지는 학습된 가중치를 고정하여 활용하고, Stage 3에서 특징을 추출함으로써 X-Ray 이미지에 적합한 로컬 특징맵을 추출할 수 있다. 즉, 로컬 특징맵을 저수준의 특징맵을 내포하는 부분에서 추출함으로써 X-Ray로부터 실제로 유사한 CT를 재구성할 수 있도록 한다. 이 과정에서 추출되는 잠재공간(Latent Space)의 차원은 EfficientNetV2의 Stage3의 채널에 맞게 512에서 64로 조정(Tuning)할 수 있다. 이렇게 감소된 차원으로 더 큰 사이즈의 이미지 에도 더 빠르게 불필요한 연산을 줄일 수 있다. 또, 이렇게 변경된 인코더의 구조에 맞게 디코더(Decoder)의 하이퍼파라미터의 구조도 변경하여 더 커진 입력 사이즈(Input Size)의 특징을 학습할 수 있도록 한다. 출력부는, 생성형 AI로부터 2차원 이미지에 기한 3차원 이미지를 출력하도록 할 수 있다. 전달부는, 사용자 단말로 3차원 이미지를 전달할 수 있다. 사용자 단말은, 2차원 이미지인 X- Ray 이미지를 생성형 AI(Generative Aritificial Intelligence)에 입력하고, 2차원 이미지에 기하여 3차원 이 미지인 CT(Computed Tomography) 이미지를 출력할 수 있다. <생성형 AI 모델링_학습 데이터셋_전처리_패딩 제외> 학습효율증가부는, 생성형 AI를 모델링할 때, 학습 데이터셋의 전처리(Pre-Processing) 과정에서, 3차원 이미지에 테두리가 추가된 패딩(Padding) 영역에, 패딩 영역이 패딩임을 표시하는 플래그(Flag) 및 좌표를 저장 하여 패딩 영역이 학습에 이용되지 않도록 처리할 수 있다. 이때 패딩이란 액자에 테두리나 인쇄할 때 여백과 같이 2차원 이미지에 테두리를 둘러주는 것이다. 이러한 패딩은 의미가 없는 픽셀로 채워지게 되므로, 사실상 학습할 이미지 영역이 아니다. 이 과정은 CT 이미지의 리샘플링(Resampling) 과정에서 픽셀 사이의 거리를 (1,1,1)로 조정하면서 잘라내기(Crop)를 할 때, 패딩이 추가된 경우 이 부분이 학습되지 않도록 설정하는 것이다. 예를 들어 척추가 포함된 CT 이미지에 검은색으로 모두 테두리가 채워져있다면, 이 부분을 아무리 학습해봤자 효과도 없고 시간 및 자원만 낭비하게 된다. 이에 따라 본 발명의 일 실시예에서는 패딩이 포함되었는지(플래 그-isPartial), 포함되었다면 어디에 위치하는지(좌표)를 h5 파일에 저장하도록 하고, 이 패딩이 포함된 영역을 학습하지 않도록 설정함으로써 학습 효율을 증가시킬 수 있다. 이때, h5는, 대용량 데이터를 저장하는 데 사용 되는 HDF(계층적 데이터 형식) 중 하나인데, 많은 양의 데이터를 다차원 배열 형태로 저장하는 데 사용된다. <생성형 AI 모델링_학습 데이터셋_전처리_품질 균일화> 입력품질유지부는, 생성형 AI를 모델링할 때, 학습 데이터셋의 전처리(Pre-Processing) 과정에서, 2차원 이미지로 입력된 일반(General) X-Ray를 합성(Synthetic) X-Ray와 유사하게 만들도록 전처리할 수 있다. 일반 X-Ray는 Raw Data로 그 품질이 균일하지 않을 수 있다. 이에 따라, 데이터 증강 등의 기법으로 학습 데이터셋 구축을 위해 생성 또는 합성된 X-Ray와 유사하도록 전처리를 할 수 있다. 이를 위하여, CT 이미지를 기반으로 합성(Synthetic) X-Ray 이미지 데이터셋을 구축한다. 일반 X-Ray는 원천 데이터(Raw Data)로 그 품질이 균일하 지 않을 수 있는 반면, 이러한 합성 X-Ray 이미지 데이터셋은 균일한 데이터 품질을 가진다. 다만, 이러한 기 법으로 학습 데이터셋을 구축했을 때, 생성 또는 합성된 X-Rahy와 유사한 입력 X-Ray 이미지가 요구된다. 이에 따라, 일반 X-Ray 이미지를 합성 X-Ray 이미지와 유사하게 변환하기 위하여 스타일 전이(Style Transfer) 기법 을 적용할 수 있다. 이 기법을 통해 입력 이미지의 일관성을 유지하여 모델의 정확도를 높이고, 더욱 일관된 재구성 결과를 도출할 수 있도록 한다. 이 과정을 통해 다양한 품질의 일반 X-Ray 이미지가 모델 학습에 일관 된 입력으로 사용되도록 전처리된다. <구조물 용적 산출> 구조물용적산출부는, 3차원 이미지인 CT 이미지를 이용하여 CT 이미지 내 포함된 구조물의 용적을 측정하 기 위하여, CT 이미지의 CT 슬라이스의 픽셀값을 기반으로 구조물의 면적을 계산하고, CT 슬라이스 간 간격을이용하여 총 용적을 산출할 수 있다. 이때, 구조물은, 척추, 골반 및 대퇴골 중 어느 하나일 수 있으나, 나열 된 것들로 한정되지 않고 열거되지 않은 이유로 배제되지 않는다. 즉 각 CT 슬라이스에서 구조물에 대응하는 면적을 계산하고, 이 면적을 각 슬라이스별로 합하면 구조물의 용적을 산출할 수 있다. <수술 전-수술 중 CT 이미지 비교> 수술내비부는, 사용자 단말에서 업로드한 수술 전 촬영된 CT 이미지와, 수술 중 촬영된 2차원 이미지 로부터 3차원 이미지로 재구성된 CT 이미지 간을 매칭(Matching)시켜 화면에 제공할 수 있다. 즉 수술 전 CT 이미지와 수술 중 X-Ray로 재건된 CT 이미지 간을 비교해보면, 실시간으로 정확한 위치 정보를 제공할 수 있어 수술의 정확성과 효율성을 높일 수 있다. 이하, 상술한 도 2의 재구성 서비스 제공 서버의 구성에 따른 동작 과정을 도 3 및 도 4를 예로 들어 상세히 설 명하기로 한다. 다만, 실시예는 본 발명의 다양한 실시예 중 어느 하나일 뿐, 이에 한정되지 않음은 자명하다 할 것이다. 도 3a를 참조하면, (a) 재구성 서비스 제공 서버는 [2D 이미지-3D 이미지]의 학습 데이터셋을 구축하고, 생성형 AI에 2D 이미지를 입력으로 넣으면 3D 이미지가 출력되도록 모델링할 수 있다. 그리고, (b)와 같이 생 성형 AI가 GAN 기반인 경우, 이 생성자의 인코더를 ResNet 기반이 아닌 EfficientNetV2 기반으로 변경할 수 있 다. 또, (c)와 같이 생성형 AI를 모델링할 때 학습 데이터셋의 3D 이미지에 패딩 영역이 있다면 이의 좌표를 제공하여 이 부분은 학습에서 제외하도록 하고, (d)와 같이 일반 X-Ray를 합성 X-Ray처럼 다듬는 전처리를 수행 함으로써, 입력 데이터의 품질을 균일하게 만들어서 학습 효과를 높이도록 할 수 있다. 또 도 3b의 (a)와 같이 구조물의 용적을 산출할 수 있고, (b)와 같이 수술 전 및 중의 3D 이미지 간 매칭을 수행할 수 있다. 물론 수 술 전 3D 이미지인 CT 이미지는 실제로 CT에서 촬영된 이미지이고, 수술 중 3D 이미지인 CT 이미지는 2D 이미지 인 X-Ray에서 촬영된 이미지로 만든(재건, 재생성) 이미지이다. 또 (c)와 같이 X-Ray의 해상도를 128에서 512로 증가시켜 3D 이미지가 고해상도로 재생성될 수 있도록 한다. 이때 해상도를 높이는 방법은, 기존의 128×128 해상도의 X-Ray 학습 데이터셋에서, 512×128 해상도의 X-Ray 학습 데이터셋을 구축하도록 전처리를 할 수 있다. 즉, 고해상도의 X-Ray 이미지에서 저해상도 X-Ray 이미지를 생성한 후 이 둘을 매핑해두고, 이 둘의 관계를 학습시킴으로써 이후 저해상도 X-Ray 이미지가 들어와도 고해상 도 X-Ray 이미지를 생성하도록 만드는 것이다. 이 방법이 영상 해상도 향상(Image Super Resolution, ISR) 기 법인데, 영상에 대한 저해상도, 고해상도 샘플의 차이를 학습하여 입력으로 주어지는 저해상도 영상을 고해상도 영상으로 재생성시키는 작업이다. 이는 딥러닝 및 GAN 등 다양한 모델이 이용될 수 있다. 이를 통하여 저해상 도 X-Ray가 들어오더라도 고해상도 X-Ray로 변환하고, 또 이를 적층시켜 CT 이미지를 생성함으로써 고해상도 CT 이미지를 생성할 수 있게 된다. 또 (d)와 같이 이미 학습된 가중치를 본 모델에 이용하는 전이학습을 이용할 수 있다. 본 발명의 일 실시예에 따른 플랫폼에서 제공하는 구성 및 효과를 정리하면 이하 표 2와 같다. 표 2 구성 효과 영상 해상도 향상 기법 3D 이미지를 만드는데 원재료가 되는 2D 이미지의 해상도를 높 여, 각 구조물의 세부 구조를 더욱 정확하게 진단 및 판단할 수 있음. 인코더 아키텍처 변환 ResNet→EfficientNetV2로 변환함으로써 모델 성능 및 연산 효 율성을 모두 높임. 전이학습을 이용하여 적은 학습으로도 높은 학습 효과를 얻을 수 있음. 학습데이터셋 전처리_패딩 제외 학습데이터셋 중 패딩 부분을 학습에서 제외시켜 학습 효율 증 가 학습데이터셋 전처리_품질 유지 학습데이터셋 중 입력 이미지의 일관성을 유지하여 CT 이미지로 의 추론 성능 향상 구조물 용적 측정 CT 이미지의 CT 슬라이스로부터 면적을 산출하고, 각 면적을 모두 더함으로써 용적을 정확하게 산출 수술 내비게이션 수술전 CT 이미지(CT 촬영)-수술중 CT 이미지(X-Ray 촬영-X- Ray 이미지로부터 생성)의 비교로 수술 내비게이션으로 이용 도 2에서 설명한 바와 같이, 도 4a는 PerX2CT의 구조, 도 4b 및 도 4c는 X2CT GAN(Generative Adversarial Network)의 구조를 나타낸다. 도 4d 및 도 4e는 EfficientNet의 구조 및 효과, 도 4f 및 도 4g는EfficientNetV2의 구조와 효과, 도 4h는 EfficientNetV2의 구조(아키텍처)를 나타낸다. 상세한 내용은 도 2를 통하여 설명했으므로 중복된 내용은 생략한다. 이와 같은 도 2 내지 도 4의 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법에 대해서 설명되지 아니한 사항은 앞서 도 1을 통해 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법에 대하여 설명된 내용과 동일 하거나 설명된 내용으로부터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다. 도 5는 본 발명의 일 실시예에 따른 도 1의 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템에 포함된 각 구성들 상호 간에 데이터가 송수신되는 과정을 나타낸 도면이다. 이하, 도 5를 통해 각 구성들 상호간에 데 이터가 송수신되는 과정의 일 예를 설명할 것이나, 이와 같은 실시예로 본원이 한정 해석되는 것은 아니며, 앞"}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "서 설명한 다양한 실시예들에 따라 도 5에 도시된 데이터가 송수신되는 과정이 변경될 수 있음은 기술분야에 속 하는 당업자에게 자명하다. 도 5를 참조하면, 재구성 서비스 제공 서버는, 2차원 이미지를 수신한다(S5100). 그리고, 재구성 서비스 제공 서버는, 생성형 AI에 2차원 이미지를 입력하고(S5200), 생성형 AI로부터 2차원 이 미지에 기한 3차원 이미지를 출력한다(S5300), 또, 재구성 서비스 제공 서버는, 사용자 단말로 3차원 이미지를 전달한다(S5400). 상술한 단계들(S5100~S5400)간의 순서는 예시일 뿐, 이에 한정되지 않는다. 즉, 상술한 단계들(S5100~S5400)간 의 순서는 상호 변동될 수 있으며, 이중 일부 단계들은 동시에 실행되거나 삭제될 수도 있다. 이와 같은 도 5의 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법에 대해서 설명되지 아니한 사항은 앞 서 도 1 내지 도 4를 통해 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법에 대하여 설명된 내용과 동일 하거나 설명된 내용으로부터 용이하게 유추 가능하므로 이하 설명을 생략하도록 한다. 도 5를 통해 설명된 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법은, 컴퓨터에 의해 실행되는 애플리케이션이나 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형 태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있 고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨 터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모 듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 전술한 본 발명의 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법은, 단말기에 기본적 으로 설치된 애플리케이션(이는 단말기에 기본적으로 탑재된 플랫폼이나 운영체제 등에 포함된 프로그램을 포함 할 수 있음)에 의해 실행될 수 있고, 사용자가 애플리케이션 스토어 서버, 애플리케이션 또는 해당 서비스와 관 련된 웹 서버 등의 애플리케이션 제공 서버를 통해 마스터 단말기에 직접 설치한 애플리케이션(즉, 프로그램)에 의해 실행될 수도 있다. 이러한 의미에서, 전술한 본 발명의 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법은 단말기에 기본적으로 설치되거나 사용자에 의해 직접 설치된 애플리케이션(즉, 프로 그램)으로 구현되고 단말기 등의 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다."}
{"patent_id": "10-2024-0119354", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3a 도면3b 도면4a 도면4b 도면4c 도면4d 도면4e 도면4f 도면4g 도면4h 도면5"}
{"patent_id": "10-2024-0119354", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 시스템을 설명하기 위한 도면이다. 도 2는 도 1의 시스템에 포함된 재구성 서비스 제공 서버를 설명하기 위한 블록 구성도이다. 도 3 및 도 4는 본 발명의 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스가 구현된 일 실시예를 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 생성형 AI 기반 3차원 이미지 재구성 서비스 제공 방법을 설명하기 위한 동 작 흐름도이다."}
