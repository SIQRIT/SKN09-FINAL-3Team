{"patent_id": "10-2008-0125755", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2010-0067274", "출원번호": "10-2008-0125755", "출원인": "삼성전자주식회사", "발명자": "이강희"}}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "지능형 로봇의 대화 진행을 관장하는 대화관리자를 가지는 대화시스템;상기 지능형 로봇이 상기 대화에 따라 수행해야 할 작업의 목표, 계획 및 행동을 관리하며 리더 에이전트, 액션에이전트 및 상호작용 에이전트를 가지는 작업계획시스템;을 포함하는 판단시스템을 구비하는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 리더 에이전트는 상위 수준의 목표를 유지하면서 다른 에이전트를 통합 및 조정하는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 액션 에이전트는 하드웨어와 관련된 센싱 및 구동을 제어하는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 상호작용 에이전트는 상기 대화관리자 상태를 모니터링하여 상기 작업계획시스템의 작업의 목표, 계획 및행동에 반영하는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 판단시스템은 상황인식부를 더 포함하며,상기 상황인식부는 대화상황이나 작업수행상황 또는 센서입력상황을 종합하여 필요한 정보를 상기 대화시스템또는 작업계획시스템에 전송하는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 판단시스템은 데이터베이스를 더 포함하며,상기 데이터베이스는 상기 지능형 로봇에 발생하는 정보를 저장하는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 대화시스템과 상기 작업계획시스템은 동종 또는 이종의 통신프로토콜을 통해 결합되는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 대화관리자는 화자의 대화 입력에 대한 의미 이해 및 종합적 상황 판단을 하여 대답을 생성하는 지능형 로봇."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "지능형 로봇의 대화 진행을 관장하는 대화관리자를 포함하는 대화시스템과 상기 지능형 로봇이 상기 대화에 따라 수행해야 할 작업의 목표, 계획 및 행동을 관리하며 리더 에이전트, 액션 에이전트 및 상호작용 에이전트를포함하는 작업계획시스템;을 포함하는 지능형 로봇의 제어방법에 있어서,공개특허 10-2010-0067274-2-상기 상호작용 에이전트를 부동상태(idle state)로 천이시키는 단계;상기 대화관리자가 사용자 인터페이스를 감지하는 단계;상기 사용자 인터페이스가 감지되면 상기 로봇은 사용자인터페이스주목(user interface attending)을 수행하는단계;상기 사용자인터페이스주목(user interface attending)이 수행되면 상기 대화관리자는 상기 사용자와 컬앤컴(call and come)대화를 수행하는 단계;를 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 컬앤컴(call and come)대화를 수행하면 상기 상호작용 에이전트를 동작상태(busy state)로 천이시키는 단계;를 더 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 상호작용 에이전트를 동작상태로 천이시키기 전에 사용자 인터페이스가 추가로 발생하는지 감지하는 단계;를 더 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 사용자 인터페이스가 추가로 발생하면 사용자인터페이스동작중단대화(user interface busy interruptdialog)를 수행하는 단계;를 더 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 상호작용 에이전트가 동작상태(busy state)로 천이되면 사용자 인터페이스가 추가로 발생하는지 감지하는단계;를 더 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 사용자 인터페이스가 추가로 발생한 것으로 확인되면 업무동작중주목(task busy attending)을 수행하는 단계;를 더 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 업무동작중주목(task busy attending)이 수행되면 업무동작중단대화(task busy interrupt dialog)를 수행하는 단계;를 더 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 10 항에 있어서,상기 상호작용 에이전트가 동작상태(busy state)로 천이되면 업무상주목(task attending)을 수행하는 단계;를더 포함하는 지능형 로봇의 제어방법."}
{"patent_id": "10-2008-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 업무상주목(task attending)이 수행되면 업무특정대화(task specific dialog)를 수행하는 단계;를 더 포공개특허 10-2010-0067274-3-함하는 지능형 로봇의 제어방법.명 세 서발명의 상세한 설명 기 술 분 야본 발명은 지능형 로봇 및 그 제어방법에 관한 것으로서, 보다 상세하게는 대화시스템과 작업계획시스템을 포함 [0001]하는 판단시스템을 구비하는 지능형 로봇 및 그 제어방법에 관한 것이다. 배 경 기 술오늘날 일반적인 로봇의 대화시스템은 휴머노이드 서비스 로봇 뿐만 아니라 가전이나 휴대폰 등 인공지능 에이 [0002]전트들이 존재하며 어디든지 임베딩 될 수 있는 시스템에 주로 쓰이고 있으며, 로봇의 작업계획시스템은 사람과의 상호작용이나 대화가 필요없는 산업용 로봇 등에 널리 쓰이고 있다. 한편, 상술한 로봇의 대화시스템 및 작업계획시스템은 각각 복잡한 구성요소들을 가지고 있으며, 독립적으로도 [0003]훌륭한 모달리티를 지니고 있고, 인공지능적으로 작동이 가능하기 때문에 가정이나 사무실에서 사용자와 대화를하면서 서비스를 제공하는데 필요한 판단시스템의 설계에 관한 연구는 주먹구구식으로 이루어지고 있다.실제적으로 독립적인 시스템인 로봇의 대화시스템과 작업계획시스템을 결합하여 판단시스템을 제작하다 보면 대 [0004]화시스템이 주가 되어 작업계획시스템을 제어할 수도 있고, 반대로 작업계획시스템이 주가 되어 대화시스템을제어할 수도 있다. 즉, 일을 하다가 대화를 할 수도 있고, 대화를 하다가 다른 일을 수행할 수도 있고, 대화를 하던 도중에 다른 센서입력을 받을 수도 있고, 대화없이 임의의 스케쥴된 일을 수행해야 할 경우도 있으므로판단시스템 설계 시 수많은 경우의 수를 고려하여 설계를 하여야 한다. 예를 들면, 하나의 두뇌의 일부분이 대화도 담당하고, 두뇌의 다른 부분이 주로 인간의 행동을 계획 및 실행하면 조화롭게 되지만 판단 시스템의 경우작업의 우선순위, 사용자의 즉각적인 입력, 로봇 본연의 임무 등을 소홀히 하지 않으면서 수많은 경우의 수를고려하는 좋은 메카니즘을 구현하지 못하면 시스템 자체가 매우 복잡해지거나 조악해지기 쉽고, 좋은 성능을 기대하기 어렵게 된다. 발명의 내용 과제 해결수단본 발명의 일측면에 의하면 로봇의 작업계획시스템과 대화시스템 중 어느 하나의 시스템의 기능도 축소하지 않 [0005]으면서 결합된 판단시스템의 설계 메카니즘을 제시하고자 한다.또한, 본 발명의 다른 측면에 의하면 1차원적인 입출력의 개수가 다차원적인 인식, 사고, 행동의 종류별 입출력 [0006]의 개수로 증가될 수 있는 다차원의 FSM(Finite State Machine)으로 설계된 작업계획시스템을 제시하고자 한다.이를 위한 본 발명의 일실시예에 의한 지능형 로봇은 지능형 로봇의 대화 진행을 관장하는 대화관리자를 포함하 [0007]는 대화시스템;과 상기 지능형 로봇이 상기 대화에 따라 수행해야 할 작업의 목표, 계획 및 행동을 관리하며 리더 에이전트, 액션 에이전트 및 상호작용 에이전트를 포함하는 작업계획시스템;을 포함하는 것이 바람직하다.상기 리더 에이전트는 상위 수준의 목표를 유지하면서 다른 에이전트를 통합 및 조정하는 것이 바람직하다. [0008]상기 액션 에이전트는 하드웨어와 관련된 센싱 및 구동을 제어하는 것이 바람직하다. [0009]상기 상호작용 에이전트는 상기 대화관리자 상태를 모니터링하여 상기 작업계획시스템의 작업의 목표, 계획 및 [0010]행동에 반영하는 것이 바람직하다.상기 판단시스템은 상황인식시스템을 더 포함하며, 상기 상황인식시스템은 대화상황이나 작업수행상황 또는 센 [0011]서입력상황을 종합하여 필요한 정보를 상기 대화시스템 또는 작업계획시스템에 전송하는 것이 바람직하다.상기 판단시스템은 데이타베이스를 더 포함하며, 상기 데이타베이스는 상기 지능형 로봇에 발생하는 정보를 저 [0012]장하는 것이 바람직하다.상기 대화시스템과 상기 작업계획시스템은 동종 또는 이종의 통신프로토콜을 통해 결합되는 것이 바람직하다. [0013]공개특허 10-2010-0067274-4-상기 대화관리자는 화자의 대화 입력에 대한 의미 이해 및 종합적 상황 판단을 하여 대답을 생성하는 것이 바람 [0014]직하다.그리고, 본 발명의 일실시예에 의한 지능형 로봇의 제어방법은 지능형 로봇의 대화 진행을 관장하는 대화관리자 [0015]를 포함하는 대화시스템과 상기 지능형 로봇이 상기 대화에 따라 수행해야 할 작업의 목표, 계획 및 행동을 관리하며 리더 에이전트, 액션 에이전트 및 상호작용 에이전트를 포함하는 작업계획시스템;을 포함하는 지능형 로봇의 제어방법에 있어서, 상기 상호작용 에이전트를 부동상태(idle state)로 천이시키는 단계;와 상기 대화관리자가 사용자 인터페이스를 감지하는 단계;와 상기 사용자 인터페이스가 감지되면 상기 로봇은 사용자인터페이스주목(user interface attending)을 수행하는 단계;와 상기 사용자인터페이스주목(user interface attending)이수행되면 상기 대화관리자는 상기 사용자와 컬앤컴(call and come)대화를 수행하는 단계;를 포함하는 것이 바람직하다.상기 컬앤컴(call and come)대화를 수행하면 상기 상호작용 에이전트를 동작상태(busy state)로 천이시키는 단 [0016]계;를 더 포함하는 것이 바람직하다.상기 상호작용 에이전트를 동작상태로 천이시키기 전에 사용자 인터페이스가 추가로 발생하는지 감지하는 단 [0017]계;를 더 포함하는 것이 바람직하다.상기 사용자 인터페이스가 추가로 발생하면 사용자인터페이스동작중단대화(user interface busy interrupt [0018]dialog)를 수행하는 단계;를 더 포함하는 것이 바람직하다.상기 상호작용 에이전트가 동작상태(busy state)로 천이되면 사용자 인터페이스가 추가로 발생하는지 감지하는 [0019]단계;를 더 포함하는 것이 바람직하다.상기 사용자 인터페이스가 추가로 발생한 것으로 확인되면 업무동작중주목(task busy attending)을 수행하는 단 [0020]계;를 더 포함하는 것이 바람직하다.상기 업무동작중주목(task busy attending)이 수행되면 업무동작중단대화(task busy interrupt dialog)를 수행 [0021]하는 단계;를 더 포함하는 것이 바람직하다.상기 상호작용 에이전트가 동작상태(busy state)로 천이되면 업무상주목(task attending)을 수행하는 단계;를 [0022]더 포함하는 것이 바람직하다.상기 업무상주목(task attending)이 수행되면 업무특정대화(task-specific-dialog)를 수행하는 단계;를 더 포 [0023]함하는 것이 바람직하다.한편, 상술한 본 발명의 일실시예에 의한 지능형 로봇의 판단시스템은 3가지의 멀티 에이전트 시스템을 가짐으 [0024]로서 관심(concern)의 분리를 지원하고, 이를 통해 개발의 편의를 용이하게 한다. 발명의 실시를 위한 구체적인 내용이하에서는 첨부도면을 참조하여 본 발명에 대해 상세히 설명한다. [0025]도 1은 본 발명의 일실시예에 의한 지능형 로봇의 판단시스템의 개략적인 구성도이다. [0026]도 1에 도시한 바와 같이, 본 발명의 일실시예에 의한 판단시스템(1)은 도메인(domain)에 독립적인 대화가 가능 [0027]한 대화시스템(10)과, 복수개의 에이전트를 구비하여 관심의 분리가 가능하며 개발의 편의성을 용이하게 하는작업계획시스템(20)과, 지능형 로봇에 관련된 배경정보나 과거정보 등을 저장하고 있는 데이터베이스(30)와, 로봇의 주변 상황이나 센서입력상황 등을 인식하는 상황인식부(40)를 포함할 수 있다.대화시스템(10)은 컴포넌트(component) 간에 메시지-패싱(message-passing) 통신방식을 사용하여 통신할 수 있 [0028]는 아키텍쳐이며, 음성 인식(speech recognition), 음성 이해(spoken language understanding), 발화(languagegeneration)등의 기능을 할 수 있으며, 그 기능 수행과정에 대해서는 구체적으로 후술한다.인식서버(1)는 외부의 음성을 인식하는 서버로서 사용자와 상호작용 시 입력부분이 된다. 또한, 문장 인식 즉, [0029]텍스트의 인식도 가능하며 인식된 음성 또는 텍스트에 관한 정보를 파싱부(2)에 전송한다.공개특허 10-2010-0067274-5-파싱부(parsing,2)는 인식된 음성 또는 텍스트의 각각의 단어를 구분해준다. 예를 들어, \"bring me the cup\"이 [0030]라는 음성 또는 텍스트가 입력되면 \"bring\", \"me\", \"the cup\"로 단어를 구분함으로서, 동작과 관련된 명령어\"bring\"과 대상과 관련된 \"me\"와 타켓인 \"cup\"를 분리하여 의미적 요소를 추출하고, 그 의미를 이해하게 된다.대화관리자(dialog manager,3)는 대화 테이블을 형성함으로서 대화 진행을 종합적으로 관장하며, 화자에 의해 [0031]들어온 입력에 대한 의미 이해 및 종합적인 상황 판단을 하여 텍스트 대답까지 생성하게 된다.언어발생부(language generation,4)는 대화관리자(3)에서 발생한 텍스트의 단어들을 조합하여 문장을 생성한다. [0032]이 때, 사용자의 설정에 따라 한국어 또는 영어 등의 언어종류 선택이 가능하다.음성합성부(synthesis theta,5)는 언어발생부(4)에서 발생한 텍스트 즉, 문장을 음성으로 합성하게 되며, 텍스 [0033]트 입출력부(6)는 상술한 구성 없이 바로 허브(7)를 통해 대화관리자(3)로 텍스트를 전송할 때 사용된다. 한편, 허브(7)는 상술한 모든 구성간에 통신을 가능하게 해주는 중앙서버를 의미한다. [0034]한편, 상술한 대화시스템은 올림푸스 시스템(Olympus System)으로서 CMU LTI의 Carbonell 및 Rudnicky 교수에 [0035]의해 개발되어 사용되는 기술로서 공지기술이다.한편, 작업계획시스템(20)은 복수개의 에이전트 즉, 상호작용 에이전트(interaction agent, 13), 리더 에이전트 [0036](leader agent, 16), 액션 에이전트(action agent, 19)를 도입하여 작업 수행 및 실행을 행하는 메커니즘으로서 그 구체적인 동작에 대해 살펴본다.상호작용 에이전트(13)는 대화시스템(10)의 대화관리자(3)의 상태를 계속 모니터링하여 반영하게 되며, 대화관 [0037]리자(3)로부터 인터럽트를 받기도 한다. 또한, 대화관리자(3)로부터 전송된 정보(information)와 목표(goal)을해석하고. 리더 에이전트(16)가 상위 수준의 목표에 해당하는 행동을 개시시킬 수 있도록 한다.리더 에이전트(16)는 상호작용 에이전트(13)에서 해석된 상위 수준의 목표(high-level-goal)을 유지하면서 다른 [0038]에이전트들을 통합 및 조정한다.액션 에이전트(19)는 로봇의 하드웨어와 관련된 센싱(sensing)과 구동(actuation)에 관련된 업무(task)들을 담 [0039]당한다.한편, 본 발명의 일실시예에 의한 작업계획시스템(20)은 상술한 것과 같이 멀티 에이전트 시스템(multi agent [0040]system)으로 구성되므로 관심(concern)의 분리를 지원하고, 이를 통해 개발의 편의를 용이하게 할 수 있다. 예를 들어, 하나의 에이전트를 테스트 목적의 간단한 기본 기능(harness)을 지닌 에이전트 또는 프로그램 등으로대체함으로서 단독으로 테스트를 가능하게 할 수도 있다.한편, 데이터베이스(30)는 로봇이 동작하는데 필요한 프로그램 데이터 및 미리 정해지는 다양한 설정값들을 저 [0041]장하며, 웹으로부터 필요한 정보를 제공받는 웹부(23)와, 짧은 기간 동안 정보를 저장할 수 있는 STM(ShortTerm Memory,26)과, 긴 시간 동안 정보를 저장할 수 있는 LTM(Long Term Memory,29)을 포함할 수 있다.한편, 상황인식부(40)는 매우 복잡한 대화 상황이나 작업수행 상황 또는 센서입력상황 등을 종합하여 가장 적합 [0042]한 상황을 인식하고, 그 정보를 대화시스템(10)과 작업계획시스템(20)에 전송한다. 예를 들어, \"bring me thecup\"라는 명령을 사용자가 로봇에 음성 또는 텍스트로 입력했을 때, 상황인식부(40)는 사용자의 명령과 외부 상황 즉, 계절 등을 인식하여 여름에는 찬물을 가져오고, 겨울에는 뜨거운 물을 가져오는 등 가장 적합한 상황에따른 행동 정보를 전송하게 된다. 한편, 각 에이전트간에 통신방법에 대해 간단히 설명한다. [0043]첫째로, 작업계획시스템(20)과 대화관리자(3)간에는 동종 또는 이종의 통신프로토콜을 통해 결합될 수 있다. 이 [0044]때, 이종 프로토콜로 결합될 경우에는 미들웨어를 두어 서로간의 통신이 원활하게 할 수 있다. 또한, 작업계획시스템(20)과 대화관리자(3)는 서로간에 비동기적으로 메시지를 보내며 반응을 하게 된다. 예를 들면, 작업계획시스템(20)은 업무 수행 중 대화관리자(3)가 대화를 개시하도록 통신할 수 있으며, 대화관리자(3)는 작업계획시스템(20)이 사용자와 상호작용을 하며 업무 수행을 할 때 인터럽트할 수 있다. 둘째로, 대화관리자(3)로부터 상호작용 에이전트(13)간의 통신을 알아보면, 대화관리자(3)에서 발생하는 이벤트 [0045]들은 상호작용 에이전트(13)로 지속적으로 전달되어야 한다. 이 때, 대화관리자(3)를 통한 주목 요청 뿐만 아니라 상술한 여러 가지 사용자인터페이스 등에 의한 주목 요청(attending request)에 대해서도 동일한 방식으로다루어져야 한다. 예를 들어, 로봇이 자신의 이름을 부르는 주목 요청이나 접촉 혹은 손뼉을 치는 등의 주목 요공개특허 10-2010-0067274-6-청에 대해서도 동일하게 반응해야 한다. 또한, 대화가 끝나면 대화종료신호도 전송이 되어야 한다.셋째로, 대화관리자(3)로부터 작업계획시스템(20)으로의 통신을 알아보면, 대화 중에 사용자에 의해 요구되는 [0046]목표(goals)는 리더 에이전트(16)에 전송이 된다. 또한, 목표(goal)는 다른 모달리티를 통해 제시되더라도 동일한 방법으로 전송이 되어야 한다.넷째로, 상호작용 에이전트(13)로부터 대화관리자(3)로의 통신을 알아보면, 대화관리자(3)는 시스템의 전체의 [0047]상태에 대해 알지 못한다. 따라서, 상호작용 에이전트(13)가 FSM(Finite State Machine)의 새로운 상태(state)로 진입할 때 대화관리자(3)에게새로운 상태와 관련된 모든 정보를 전달해야 한다.다섯번째로, 작업계획시스템(20)으로부터 대화관리자(3)로의 통신을 알아보면, 작업계획시스템(20)은 대화와 [0048]관련있는 로봇의 일시적 상태를 모두 전송해야 한다. 예를 들어, 즉시 실행을 필요로 하는 임의의 업무가 리더에이전트(16)의 큐(queue)에 있는지 여부, 대화 도중에 배터리가 방전되어 충전 스테이션으로 돌아오기 위해 대화를 중단해야 하는 상태에 있는지 여부 등에 관한 정보를 전송해야 한다.도 2a는 본 발명의 일실시예에 의한 로봇과 사용자의 초기 인터페이스에 관한 동작을 설명하기 위한 [0049]흐름도이다.도 2a에 도시한 바와 같이, 본 발명의 일실시예에 의한 로봇에 전원이 인가되면 초기화를 수행한다. 즉, 상술한 [0050]로봇의 시스템을 리셋하여 초기화를 시킨다.(s10) 이 때, 로봇의 상호작용 에이전트(13)는 부동상태(idlestate)로 천이되어 사용자의 명령을 대기한다.(s20) 또한, 부동상태에서 임의의 사용자 인터페이스 요소(UserInterface Component)등은 로봇의 주목(attending)요청을 낼 수 있으며, 사용자 인터페이스 요소들은 복수개가존재할 수 있다. 예를 들면, 특정 주목을 의미하는 단어(예를 들면, \"이리 와\", \"컴온\", \"주목\", \"로봇\"등)나손뼉 소리, 접촉, 무선 조종(remote control), 호출 버튼(call button) 등이 사용자 인터페이스 요소가 될 수있다.한편, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목(user interface attending)을 하 [0051]게 된다. 여기서 로봇이 사용자에게 주목(attending)을 하는 것은 적절한 거리에서 그 사람과 마주 대면하는 것과 같은 사회적 규범이라고 할 수 있다. 또한, 주목은 주목에 대한 사용자의 요구에 즉시 자극되기 시작한다.이는 로봇 주도의 업무(task)의 시작을 방지해주며, 동시에 다수의 사용자들이 로봇의 주목을 요구할 때 결정이우유부단한 상황을 예방해준다. 만약, 사용자 인터페이스 요소에 의한 주목이 실패하면 상호작용 에이전트(13)는 부동 상태로 돌아간다.(s40)도 2b는 본 발명의 일실시예에 의한 로봇과 사용자의 초기 대화에 관한 동작을 설명하기 위한 흐름도이다. [0052] 도 2a에서 설명한 것과 같이, 본 발명의 일실시예에 의한 로봇은 초기화를 수행 후 부동상태(idle state)로 천 [0053]이되며, 상술한 것처럼 \"로봇\"과 같은 사용자의 음성 호출 등의 사용자 인터페이스 요소에 의해 로봇의 주목 요청이 입력되면 사용자 주목(user interface attending)을 수행함으로서 대화 준비를 완료하게 된다.(s10,s20,s40) 또한, 로봇은 사용자에게 주목함으로서 대화 준비가 완료되면 사용자와 컬앤컴(call and come) 대화를 수행한 [0054]다. 예를 들면, 사용자가 로봇에게 \"이리와\"라고 명령을 하고 로봇이 \"예, 주인님\"이라 대답을 한 후, 사용자가\"나한테 컵을 가져와\"라고 하면 로봇이 \"예, 주인님\"이라고 대답하는 방식으로 대화를 수행하게 되는 것이다.이 때, 대화관리자(3)는 컬앤컴 대화가 끝난 후 또는 대화 도중 작업계획시스템(20)에 목표(goal)를 제시할 수도 있으며, 제시된 목표는 리더 에이전트(16)의 큐(queue)에 저장된다. 대화가 종료되면 로봇은 사용자의 명령에 의해 큐(queue)에 저장된 업무를 수행하며, 대화관리자(3)가 대화의 완료를 나타내는 신호를 보내면 로봇은다시 부동상태(idle state)로 천이한다.(s50)도 2c는 본 발명의 일실시예에 의한 로봇이 업무 수행 중 사용자와 대화하는 동작을 설명하기 위한 흐름도이다. [0055]도 2a 및 도 2b에 설명한 것처럼, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목을 한 [0056]후 컬앤컴 대화를 수행한 후 상호작용 에이전트(13)는 부동상태(idle state)에서 동작상태(busy state)로 천이된다. 여기서 동작상태(busy state)는 로봇의 주목을 받는 임의의 비대화 상태를 표현한다. 또한, 동작상태는상호작용 에이전트(13)가 부동상태(idle state)일 경우 리더 에이전트(16)에 의해서만 천이 될 수 있다.(s10,s20,s60)그리고, 동작상태에서 사용자와 업무에 대해 상호작용을 하기위해 업무상 주목(task attending)을 하게 된다. [0057]또한, 로봇의 업무상 주목으로 대화준비가 되면, 사용자가 지시한 작업의 수행과정에서 필요한 업무특정대화공개특허 10-2010-0067274-7-(Task-Specific-dialog)를 할 수 있다.(s70,s80)예를 들어, 컬앤컴(call and come)대화에서 전달된 업무가 \"컵을 나에게 가져와\"였다면 업무특정대화(Task- [0058]Specific-dialog)에서는 \"여기 가져왔습니다\", \"더 시킬일 없습니까?\"등의 대화를 관장하게 된다.즉, 로봇이 수행해야 할 하나의 목표(goal)는 사람과 상호작용을 필요로 하므로 리더 에이전트(16)는 물품의 전 [0059]달, 도움 요청, 발음을 명확히 해달라는 요청 등 어떤 특정한 업무를 위한 대화 즉, 업무특정대화(Task-Specific-dialog)를 시작할 수 있다. 그리고, 상호작용 에이전트(13)는 업무가 완료되면 동작상태에서 부동상태로 천이하게 된다.도 2d는 본 발명의 일실시예에 의한 로봇의 사용자와 대화동작을 설명하기 위한 제어흐름도이다. [0060]또한, 도 2d는 도 2a 내지 도 2c를 합성한 흐름도로서, 도 2a 내지 도 2c와같은 블록에 대해서는 동일한 부호를 [0061]병기한다. 본 발명의 일실시예에 의한 로봇에 전원이 인가되면 초기화(initialization)를 수행한다. 즉, 상술한 로봇의 시 [0062]스템을 리셋하여 초기화를 시킨다.(s10) 다음으로, 로봇의 리더 에이전트(16)는 상호작용 에이전트(13)를 부동상태(idle state)로 천이시킴으로서 사용 [0063]자의 명령을 대기한다.(s20) 다음으로, 대화관리자(3)는 부동상태에서 임의의 사용자 인터페이스 요소(User Interface Component)가 발생하 [0064]여 로봇의 주목(attending)요청이 있는지 확인한다. 즉, 사용자 인터페이스 요소 즉, 특정 주목을 요구하는 단어(예를 들면, \"이리 와\", \"컴온\", \"주목\", \"로봇\"등)나 손뼉 소리, 접촉, 무선 조종(remote control), 호출버튼(call button)의 누름 등이 발생한 것으로 확인되면 그 정보를 상호작용 에이전트(13)에 전달한다. 한편,대화 관리자(3)에서 발생하는 이벤트들은 상호작용 에이전트(13)에 지속적으로 전달된다.(s30)다음으로, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목(user interface attending)을 [0065]하게 된다. 여기서 로봇이 사용자에게 주목(attending)을 하는 것은 적절한 거리에서 그 사람과 마주 대면하는것과 같은 사회적 규범이라고 할 수 있다. 또한, 주목은 주목에 대한 사용자의 요구에 즉시 자극되기 시작한다.이는 로봇 주도의 업무(task)의 시작을 방지해주며, 동시에 다수의 사용자들이 로봇의 주목을 요구할 때 결정이우유부단한 상황을 예방해준다.(s40)다음으로, 로봇은 사용자에게 주목함으로서 대화 준비가 완료되면 사용자와 컬앤컴(call and come) 대화를 수행 [0066]한다. 예를 들면, 사용자가 로봇에게 \"이리와\"라고 명령을 하고 로봇이 \"예, 주인님\"이라 대답을 한 후, 사용자가 \"나한테 컵을 가져와\"라고 하면 로봇이 \"예, 주인님\"이라고 대답하는 방식으로 대화를 수행하게 되는것이다.(s50)다음으로, 상호작용 에이전트(13)는 부동상태(idle state)로 천이된다.(s60) [0067]다음으로, 상호작용 에이전트(13)는 부동상태(idle state)에서 동작상태(busy state)로 천이된다. 여기서 동작 [0068]상태(busy state)는 로봇의 주목을 받는 임의의 비대화 상태를 표현한다. 또한, 동작상태는 상호작용 에이전트(13)가 부동상태(idle state)일 경우 리더 에이전트(16)에 의해서만 천이 될 수 있다.(s70)다음으로, 동작상태에서 사용자와 업무에 대해 상호작용을 하기위해 업무상 주목(task attending)을 하게 된 [0069]다.(s80)다음으로, 로봇의 업무상 주목으로 대화준비가 되면, 사용자가 지시한 작업의 수행과정에서 필요한 업무특정대 [0070]화(Task-Specific-dialog)를 할 수 있다.예를 들어, 컬앤컴(call and come)대화에서 전달된 업무가 \"컵을 나에게 가져와\"였다면 업무특정대화(Task- [0071]Specific-dialog)에서는 \"여기 가져왔습니다\", \"더 시킬일 없습니까?\"등의 대화를 관장하게 된다. 또다른 예로컬앤컴 대화에서 전달된 업무가 \"우리 딸 영이에게 점심을 줘\"였다면 업무 특정대화에서는 \"영이님 점심 가지고왔습니다\", \"영이님 점심 드실 시간입니다\", \"영이님 점심 다 드시면 제가 치워드리겠습니다\" 등의 대화를 관장하게 된다.(s90)도 3a는 본 발명의 일실시예에 의한 로봇이 업무 수행중 다른 사용자에 의해 주목 요청이 들어올 경우의 로봇의 [0072]동작을 설명하기 위한 흐름도이다.도 2d에 설명한 것처럼, 사용자 인터페이스 요소(user interface component)가 있는 것으로 확인되면 로봇은 사 [0073]공개특허 10-2010-0067274-8-용자인터페이스주목(user interface attending)으로 대화준비를 완료한 후 컬앤컴(call and come)대화를 수행하고, 상호작용 에이전트(13)는 동작 상태(busy state)로 천이되며 다시 부동상태(idle state)로 돌아올 때 큐(queue)에 저장되어 있는 업무를 수행해야 한다. 이 때, 어떤 다른 사용자가 로봇의 주목을 요청한다면 다른 사용자와의 대화는 본래의 주목 요청에 의한 대화 즉, 컬앤컴대화(call and come dialog)와 달라야만 한다. 따라서, 로봇은 업무 수행 중 다른 사용자의 주목 요청이 있는 경우 업무동작중주목(task busy attending)을 한다.여기서 업무동작중주목(task busy attending)이란 또다른 유저인터페이스와 상호작용을 준비하기 위한동작이다. 한편, 업무동작중주목(task busy attending)에 의해 로봇이 사용자와 대화 준비가 끝나면 업무동작중단대화(task busy interrupt dialog)를 수행한다. 업무동작중단대화(task busy interrupt dialog)에서는 이전사용자가 입력한 명령을 수행하고 있는 것을 감안하여 대화하는 것으로서, \"죄송합니다. 다른 명령을 수행하고있습니다.\"등의 대화를 할 수 있다. 한편, 로봇에 미리 저장된 우선순위에 따라 현재 사용자의 명령을 우선적으로 수행하게 할 수 있다.(s10,s20,s70,s72,s73)도 3b는 본 발명의 일실시예에 의한 로봇에게 명령 전달 후 업무 수행 개시전에 다른 사용자에 의해 주목 요청 [0074]이 들어올 경우의 로봇의 동작을 설명하기 위한 흐름도이다.도 3b에 도시한 바와 같이, 임의의 인터럽트는 로봇의 리더 에이전트(16)가 업무를 수행하기 전에 발생할 수 있 [0075]다. 즉, 사용자에 의해 주목 요청을 받은 후 대화의 진행 도중 또는 대화가 끝난 후 업무 수행 개시 전에 임의의 사용자에 의해 주목 요청이 발생하는 경우이다. 이러한 경우 사용자인터페이스동작중단대화(User InterfaceBusy Interrupt Dialog)를 수행함으로서 먼저 대화를 요청한 선사용자와의 관계를 고려하여 대화를 수행할 수있다.(s10,s20,s52,s53)도 3c는 본 발명의 일실시예에 의한 로봇의 사용자와 대화동작을 설명하기 위한 제어흐름도이다. [0076]또한, 도 3c는 도 3a 및 도 3b를 합성한 흐름도로서, 도 3a 및 도 3b와 같은 블록에 대해서는 동일한 부호를 병 [0077]기한다.본 발명의 일실시예에 의한 로봇은 전원이 인가되면 초기화(initialization)를 수행한다. 즉, 상술한 로봇의 시 [0078]스템을 리셋하여 초기화를 시킨다.(s10) 다음으로, 로봇의 리더 에이전트(16)는 상호작용 에이전트(13)를 부동상태(idle state)로 천이시킴으로서 사용 [0079]자의 명령을 대기한다.(s20) 다음으로, 대화관리자(3)는 부동상태에서 임의의 사용자 인터페이스 요소(User Interface Component)가 발생하 [0080]여 로봇의 주목(attending)요청이 있는지 확인한다. 즉, 사용자 인터페이스 요소 즉, 특정 주목을 요구하는 단어(예를 들면, \"이리 와\", \"컴온\", \"주목\", \"로봇\"등)나 손뼉 소리, 접촉, 무선 조종(remote control), 호출버튼(call button)의 누름 등이 발생한 것으로 확인되면 그 정보를 상호작용 에이전트(13)에 전달한다.(s30)다음으로, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목(user interface attending)을 [0081]하게 된다. 여기서 로봇이 사용자에게 주목(attending)을 하는 것은 적절한 거리에서 그 사람과 마주 대면하는것과 같은 사회적 규범이라고 할 수 있다. 또한, 주목은 주목에 대한 사용자의 요구에 즉시 자극되기 시작한다.이는 로봇 주도의 업무(task)의 시작을 방지해주며, 동시에 다수의 사용자들이 로봇의 주목을 요구할 때 결정이우유부단한 상황을 예방해준다.(s40)다음으로, 로봇은 사용자에게 주목함으로서 대화 준비가 완료되면 사용자와 컬앤컴(call and come) 대화를 수행 [0082]한다. 예를 들면, 사용자가 로봇에게 \"이리와\"라고 명령을 하고 로봇이 \"예, 주인님\"이라 대답을 한 후, 사용자가 \"나한테 컵을 가져와\"라고 하면 로봇이 \"예, 주인님\"이라고 대답하는 방식으로 대화를 수행하게 되는것이다.(s50)다음으로, 어느 사용자와 대화의 진행 도중 또는 대화가 끝난 후 업무 수행 개시 전에 임의의 사용자에 의해 주 [0083]목 요청이 발생하는지 여부 즉, 사용자 인터페이스가 추가로 발생하는지 확인한다.(s51)다음으로, 사용자 인터페이스가 추가로 발생한 것으로 확인되면 사용자인터페이스주목(user interface [0084]attending)을 하고, 사용자인터페이스동작중단대화(User Interface Busy Interrupt Dialog)를 수행함으로서 먼저 대화를 요청한 선사용자와의 관계를 고려하여 대화를 수행할 수 있다. 예를 들면, \"다른 사용자가 먼저 대화를 시도하고 있습니다.\"등의 대화를 할 수 있다.(s52,s53)다음으로, 상호작용 에이전트(13)은 부동상태로 다시 천이된다.(s60) [0085]공개특허 10-2010-0067274-9-다음으로, 상호작용 에이전트(13)는 부동상태(idle state)에서 동작상태(busy state)로 천이된다. 여기서 동작 [0086]상태(busy state)는 로봇의 주목을 받는 임의의 비대화 상태를 표현한다. 또한, 동작상태는 상호작용 에이전트(13)가 부동상태(idle state)일 경우 리더 에이전트(16)에 의해서만 천이 될 수 있다.(s70)다음으로, 로봇은 업무 수행 중 다른 사용자의 주목 요청 즉, 사용자 인터페이스가 있는지 확인하며, 주목 요청 [0087]이 있는 경우 업무동작중주목(task busy attending)을 한다. 여기서 업무동작중주목(task busy attending)이란또다른 유저인터페이스와 상호작용을 준비하기 위한 동작이다.(s71,s72) 다음으로, 업무동작중주목(task busy attending)에 의해 로봇이 사용자와 대화 준비가 끝나면 업무동작중단대 [0088]화(task busy interrupt dialog)를 수행한다. 업무동작중단대화(task busy interrupt dialog)는 이전 사용자가입력한 명령을 수행하고 있는 것을 감안하여 대화하는 것으로서, \"죄송합니다. 다른 명령을 수행하고 있습니다.\"등의 대화를 할 수 있다.(s73)한편, s71단계에서 임의의 사용자 인터페이스가 발생하지 않는 것으로 확인되면 동작상태에서 사용자와 업무에 [0089]대해 상호작용을 하기 위한 대화를 하기 위해 업무상 주목(task attending)을 하게 된다.(s80)다음으로, 로봇의 업무상 주목으로 대화준비가 되면, 사용자가 지시한 작업의 수행과정에서 필요한 업무특정대 [0090]화(Task-Specific-dialog)를 하게되면 지시받은 업무를 수행함으로서 행동을 종료하게 된다.(s90)한편, 로봇이 대화 또는 업무 수행 중 다른 인터럽트가 들어오면 리더 에이전트(16)는 상호작용 에이전트(13)의 [0091]상태를 확인하고, 확인된 상태 정보를 대화관리자(3)에 전송함으로서 로봇이 컬앤컴 대화를 수행할 것인지, 사용자인터페이스동작중단대화를 수행할 것인지, 업무동작중단대화를 수행할 것인지, 업무특정대화를 수행할 것인지 결정할 수 있다.도면의 간단한 설명도 1은 본 발명의 일실시예에 의한 지능형 로봇의 판단시스템의 개략적인 구성도 [0092]도 2a는 본 발명의 일실시예에 의한 로봇과 사용자의 초기 인터페이스에 관한 동작을 설명하기 위한 흐름도 [0093]도 2b는 본 발명의 일실시예에 의한 로봇과 사용자의 초기 대화에 관한 동작을 설명하기 위한 흐름도 [0094]도 2c는 본 발명의 일실시예에 의한 로봇이 업무 수행 중 사용자와 대화하는 동작을 설명하기 위한 흐름도 [0095]도 2d는 본 발명의 일실시예에 의한 로봇의 사용자와 대화동작을 설명하기 위한 제어흐름도 [0096]도 3a는 본 발명의 일실시예에 의한 로봇이 업무 수행중 다른 사용자에 의해 주목 요청이 들어올 경우의 로봇의 [0097]동작을 설명하기 위한 흐름도도 3b는 본 발명의 일실시예에 의한 로봇에게 명령 전달 후 업무 수행 개시전에 다른 사용자에 의해 주목 요청 [0098]이 들어올 경우의 로봇의 동작을 설명하기 위한 흐름도도 3c는 본 발명의 일실시예에 의한 로봇의 사용자와 대화동작을 설명하기 위한 제어흐름도 [0099]*도면의 주요부분에 대한 부호 설명* [0100]10 : 대화시스템 20 : 작업계획시스템 [0101]13 : 상호작용에이전트 16 : 리더에이전트 [0102]19 : 액션 에이전트 [0103]공개특허 10-2010-0067274-10-도면 도면1 도면2a 도면2b공개특허 10-2010-0067274-11- 도면2c 도면2d공개특허 10-2010-0067274-12- 도면3a 도면3b공개특허 10-2010-0067274-13- 도면3c공개특허 10-2010-0067274-14-"}
{"patent_id": "10-2008-0125755", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 대화시스템과 작업계획시스템을 포함하는 판단시스템을 구비함으로서 다차원적인 인식, 사고 및 행동 을 수행할 수 있는 로봇 및 그 제어방법에 관한 것이다. 이를 위해 본 발명의 일실시예에 의한 로봇은 지능형 로봇의 대화 진행을 관장하는 대화관리자를 포함하는 대화 시스템;과 상기 지능형 로봇이 상기 대화에 따라 수행해야 할 작업의 목표, 계획 및 행동을 관리하며 리더 에이 전트, 액션 에이전트 및 상호작용 에이전트를 포함하는 작업계획시스템;을 포함하는 판단시스템을 구비하므로 관 심(concern)의 분리를 지원하고, 이를 통해 개발의 편의를 고려할 수 있다. 또한, 본 발명의 일실시예에 의한 로봇의 판단시스템은 작업의 우선순위, 사용자의 인터페이스 및 로봇 본연의 임무 등 수많은 경우의 수를 고려한 메커니즘을 구비하고 있으므로 다차원적인 인식, 사고 및 행동을 수행할 수 있다."}
{"patent_id": "10-2008-0125755", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 지능형 로봇 및 그 제어방법에 관한 것으로서, 보다 상세하게는 대화시스템과 작업계획시스템을 포함 하는 판단시스템을 구비하는 지능형 로봇 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2008-0125755", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "오늘날 일반적인 로봇의 대화시스템은 휴머노이드 서비스 로봇 뿐만 아니라 가전이나 휴대폰 등 인공지능 에이 전트들이 존재하며 어디든지 임베딩 될 수 있는 시스템에 주로 쓰이고 있으며, 로봇의 작업계획시스템은 사람과 의 상호작용이나 대화가 필요없는 산업용 로봇 등에 널리 쓰이고 있다. 한편, 상술한 로봇의 대화시스템 및 작업계획시스템은 각각 복잡한 구성요소들을 가지고 있으며, 독립적으로도 훌륭한 모달리티를 지니고 있고, 인공지능적으로 작동이 가능하기 때문에 가정이나 사무실에서 사용자와 대화를 하면서 서비스를 제공하는데 필요한 판단시스템의 설계에 관한 연구는 주먹구구식으로 이루어지고 있다. 실제적으로 독립적인 시스템인 로봇의 대화시스템과 작업계획시스템을 결합하여 판단시스템을 제작하다 보면 대 화시스템이 주가 되어 작업계획시스템을 제어할 수도 있고, 반대로 작업계획시스템이 주가 되어 대화시스템을 제어할 수도 있다. 즉, 일을 하다가 대화를 할 수도 있고, 대화를 하다가 다른 일을 수행할 수도 있고, 대화 를 하던 도중에 다른 센서입력을 받을 수도 있고, 대화없이 임의의 스케쥴된 일을 수행해야 할 경우도 있으므로 판단시스템 설계 시 수많은 경우의 수를 고려하여 설계를 하여야 한다. 예를 들면, 하나의 두뇌의 일부분이 대 화도 담당하고, 두뇌의 다른 부분이 주로 인간의 행동을 계획 및 실행하면 조화롭게 되지만 판단 시스템의 경우 작업의 우선순위, 사용자의 즉각적인 입력, 로봇 본연의 임무 등을 소홀히 하지 않으면서 수많은 경우의 수를 고려하는 좋은 메카니즘을 구현하지 못하면 시스템 자체가 매우 복잡해지거나 조악해지기 쉽고, 좋은 성능을 기 대하기 어렵게 된다."}
{"patent_id": "10-2008-0125755", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용 과제 해결수단 본 발명의 일측면에 의하면 로봇의 작업계획시스템과 대화시스템 중 어느 하나의 시스템의 기능도 축소하지 않 으면서 결합된 판단시스템의 설계 메카니즘을 제시하고자 한다. 또한, 본 발명의 다른 측면에 의하면 1차원적인 입출력의 개수가 다차원적인 인식, 사고, 행동의 종류별 입출력 의 개수로 증가될 수 있는 다차원의 FSM(Finite State Machine)으로 설계된 작업계획시스템을 제시하고자 한다. 이를 위한 본 발명의 일실시예에 의한 지능형 로봇은 지능형 로봇의 대화 진행을 관장하는 대화관리자를 포함하 는 대화시스템;과 상기 지능형 로봇이 상기 대화에 따라 수행해야 할 작업의 목표, 계획 및 행동을 관리하며 리 더 에이전트, 액션 에이전트 및 상호작용 에이전트를 포함하는 작업계획시스템;을 포함하는 것이 바람직하다. 상기 리더 에이전트는 상위 수준의 목표를 유지하면서 다른 에이전트를 통합 및 조정하는 것이 바람직하다. 상기 액션 에이전트는 하드웨어와 관련된 센싱 및 구동을 제어하는 것이 바람직하다. 상기 상호작용 에이전트는 상기 대화관리자 상태를 모니터링하여 상기 작업계획시스템의 작업의 목표, 계획 및 행동에 반영하는 것이 바람직하다. 상기 판단시스템은 상황인식시스템을 더 포함하며, 상기 상황인식시스템은 대화상황이나 작업수행상황 또는 센 서입력상황을 종합하여 필요한 정보를 상기 대화시스템 또는 작업계획시스템에 전송하는 것이 바람직하다. 상기 판단시스템은 데이타베이스를 더 포함하며, 상기 데이타베이스는 상기 지능형 로봇에 발생하는 정보를 저 장하는 것이 바람직하다. 상기 대화시스템과 상기 작업계획시스템은 동종 또는 이종의 통신프로토콜을 통해 결합되는 것이 바람직하다. 상기 대화관리자는 화자의 대화 입력에 대한 의미 이해 및 종합적 상황 판단을 하여 대답을 생성하는 것이 바람 직하다. 그리고, 본 발명의 일실시예에 의한 지능형 로봇의 제어방법은 지능형 로봇의 대화 진행을 관장하는 대화관리자 를 포함하는 대화시스템과 상기 지능형 로봇이 상기 대화에 따라 수행해야 할 작업의 목표, 계획 및 행동을 관 리하며 리더 에이전트, 액션 에이전트 및 상호작용 에이전트를 포함하는 작업계획시스템;을 포함하는 지능형 로 봇의 제어방법에 있어서, 상기 상호작용 에이전트를 부동상태(idle state)로 천이시키는 단계;와 상기 대화관리 자가 사용자 인터페이스를 감지하는 단계;와 상기 사용자 인터페이스가 감지되면 상기 로봇은 사용자인터페이스 주목(user interface attending)을 수행하는 단계;와 상기 사용자인터페이스주목(user interface attending)이 수행되면 상기 대화관리자는 상기 사용자와 컬앤컴(call and come)대화를 수행하는 단계;를 포함하는 것이 바 람직하다. 상기 컬앤컴(call and come)대화를 수행하면 상기 상호작용 에이전트를 동작상태(busy state)로 천이시키는 단 계;를 더 포함하는 것이 바람직하다. 상기 상호작용 에이전트를 동작상태로 천이시키기 전에 사용자 인터페이스가 추가로 발생하는지 감지하는 단 계;를 더 포함하는 것이 바람직하다. 상기 사용자 인터페이스가 추가로 발생하면 사용자인터페이스동작중단대화(user interface busy interrupt dialog)를 수행하는 단계;를 더 포함하는 것이 바람직하다. 상기 상호작용 에이전트가 동작상태(busy state)로 천이되면 사용자 인터페이스가 추가로 발생하는지 감지하는 단계;를 더 포함하는 것이 바람직하다. 상기 사용자 인터페이스가 추가로 발생한 것으로 확인되면 업무동작중주목(task busy attending)을 수행하는 단 계;를 더 포함하는 것이 바람직하다. 상기 업무동작중주목(task busy attending)이 수행되면 업무동작중단대화(task busy interrupt dialog)를 수행 하는 단계;를 더 포함하는 것이 바람직하다. 상기 상호작용 에이전트가 동작상태(busy state)로 천이되면 업무상주목(task attending)을 수행하는 단계;를 더 포함하는 것이 바람직하다. 상기 업무상주목(task attending)이 수행되면 업무특정대화(task-specific-dialog)를 수행하는 단계;를 더 포 함하는 것이 바람직하다. 한편, 상술한 본 발명의 일실시예에 의한 지능형 로봇의 판단시스템은 3가지의 멀티 에이전트 시스템을 가짐으 로서 관심(concern)의 분리를 지원하고, 이를 통해 개발의 편의를 용이하게 한다. 발명의 실시를 위한 구체적인 내용 이하에서는 첨부도면을 참조하여 본 발명에 대해 상세히 설명한다. 도 1은 본 발명의 일실시예에 의한 지능형 로봇의 판단시스템의 개략적인 구성도이다. 도 1에 도시한 바와 같이, 본 발명의 일실시예에 의한 판단시스템은 도메인(domain)에 독립적인 대화가 가능 한 대화시스템과, 복수개의 에이전트를 구비하여 관심의 분리가 가능하며 개발의 편의성을 용이하게 하는 작업계획시스템과, 지능형 로봇에 관련된 배경정보나 과거정보 등을 저장하고 있는 데이터베이스와, 로 봇의 주변 상황이나 센서입력상황 등을 인식하는 상황인식부를 포함할 수 있다. 대화시스템은 컴포넌트(component) 간에 메시지-패싱(message-passing) 통신방식을 사용하여 통신할 수 있 는 아키텍쳐이며, 음성 인식(speech recognition), 음성 이해(spoken language understanding), 발화(language generation)등의 기능을 할 수 있으며, 그 기능 수행과정에 대해서는 구체적으로 후술한다. 인식서버는 외부의 음성을 인식하는 서버로서 사용자와 상호작용 시 입력부분이 된다. 또한, 문장 인식 즉, 텍스트의 인식도 가능하며 인식된 음성 또는 텍스트에 관한 정보를 파싱부에 전송한다.파싱부(parsing,2)는 인식된 음성 또는 텍스트의 각각의 단어를 구분해준다. 예를 들어, \"bring me the cup\"이 라는 음성 또는 텍스트가 입력되면 \"bring\", \"me\", \"the cup\"로 단어를 구분함으로서, 동작과 관련된 명령어 \"bring\"과 대상과 관련된 \"me\"와 타켓인 \"cup\"를 분리하여 의미적 요소를 추출하고, 그 의미를 이해하게 된다. 대화관리자(dialog manager,3)는 대화 테이블을 형성함으로서 대화 진행을 종합적으로 관장하며, 화자에 의해 들어온 입력에 대한 의미 이해 및 종합적인 상황 판단을 하여 텍스트 대답까지 생성하게 된다. 언어발생부(language generation,4)는 대화관리자에서 발생한 텍스트의 단어들을 조합하여 문장을 생성한다. 이 때, 사용자의 설정에 따라 한국어 또는 영어 등의 언어종류 선택이 가능하다. 음성합성부(synthesis theta,5)는 언어발생부에서 발생한 텍스트 즉, 문장을 음성으로 합성하게 되며, 텍스 트 입출력부는 상술한 구성 없이 바로 허브를 통해 대화관리자로 텍스트를 전송할 때 사용된다. 한편, 허브는 상술한 모든 구성간에 통신을 가능하게 해주는 중앙서버를 의미한다. 한편, 상술한 대화시스템은 올림푸스 시스템(Olympus System)으로서 CMU LTI의 Carbonell 및 Rudnicky 교수에 의해 개발되어 사용되는 기술로서 공지기술이다. 한편, 작업계획시스템은 복수개의 에이전트 즉, 상호작용 에이전트(interaction agent, 13), 리더 에이전트 (leader agent, 16), 액션 에이전트(action agent, 19)를 도입하여 작업 수행 및 실행을 행하는 메커니즘으로 서 그 구체적인 동작에 대해 살펴본다. 상호작용 에이전트는 대화시스템의 대화관리자의 상태를 계속 모니터링하여 반영하게 되며, 대화관 리자로부터 인터럽트를 받기도 한다. 또한, 대화관리자로부터 전송된 정보(information)와 목표(goal)을 해석하고. 리더 에이전트가 상위 수준의 목표에 해당하는 행동을 개시시킬 수 있도록 한다. 리더 에이전트는 상호작용 에이전트에서 해석된 상위 수준의 목표(high-level-goal)을 유지하면서 다른 에이전트들을 통합 및 조정한다. 액션 에이전트는 로봇의 하드웨어와 관련된 센싱(sensing)과 구동(actuation)에 관련된 업무(task)들을 담 당한다. 한편, 본 발명의 일실시예에 의한 작업계획시스템은 상술한 것과 같이 멀티 에이전트 시스템(multi agent system)으로 구성되므로 관심(concern)의 분리를 지원하고, 이를 통해 개발의 편의를 용이하게 할 수 있다. 예 를 들어, 하나의 에이전트를 테스트 목적의 간단한 기본 기능(harness)을 지닌 에이전트 또는 프로그램 등으로 대체함으로서 단독으로 테스트를 가능하게 할 수도 있다. 한편, 데이터베이스는 로봇이 동작하는데 필요한 프로그램 데이터 및 미리 정해지는 다양한 설정값들을 저 장하며, 웹으로부터 필요한 정보를 제공받는 웹부와, 짧은 기간 동안 정보를 저장할 수 있는 STM(Short Term Memory,26)과, 긴 시간 동안 정보를 저장할 수 있는 LTM(Long Term Memory,29)을 포함할 수 있다. 한편, 상황인식부는 매우 복잡한 대화 상황이나 작업수행 상황 또는 센서입력상황 등을 종합하여 가장 적합 한 상황을 인식하고, 그 정보를 대화시스템과 작업계획시스템에 전송한다. 예를 들어, \"bring me the cup\"라는 명령을 사용자가 로봇에 음성 또는 텍스트로 입력했을 때, 상황인식부는 사용자의 명령과 외부 상 황 즉, 계절 등을 인식하여 여름에는 찬물을 가져오고, 겨울에는 뜨거운 물을 가져오는 등 가장 적합한 상황에 따른 행동 정보를 전송하게 된다. 한편, 각 에이전트간에 통신방법에 대해 간단히 설명한다. 첫째로, 작업계획시스템과 대화관리자간에는 동종 또는 이종의 통신프로토콜을 통해 결합될 수 있다. 이 때, 이종 프로토콜로 결합될 경우에는 미들웨어를 두어 서로간의 통신이 원활하게 할 수 있다. 또한, 작업계획 시스템과 대화관리자는 서로간에 비동기적으로 메시지를 보내며 반응을 하게 된다. 예를 들면, 작업계획 시스템은 업무 수행 중 대화관리자가 대화를 개시하도록 통신할 수 있으며, 대화관리자는 작업계획시 스템이 사용자와 상호작용을 하며 업무 수행을 할 때 인터럽트할 수 있다. 둘째로, 대화관리자로부터 상호작용 에이전트간의 통신을 알아보면, 대화관리자에서 발생하는 이벤트 들은 상호작용 에이전트로 지속적으로 전달되어야 한다. 이 때, 대화관리자를 통한 주목 요청 뿐만 아니 라 상술한 여러 가지 사용자인터페이스 등에 의한 주목 요청(attending request)에 대해서도 동일한 방식으로 다루어져야 한다. 예를 들어, 로봇이 자신의 이름을 부르는 주목 요청이나 접촉 혹은 손뼉을 치는 등의 주목 요청에 대해서도 동일하게 반응해야 한다. 또한, 대화가 끝나면 대화종료신호도 전송이 되어야 한다. 셋째로, 대화관리자로부터 작업계획시스템으로의 통신을 알아보면, 대화 중에 사용자에 의해 요구되는 목표(goals)는 리더 에이전트에 전송이 된다. 또한, 목표(goal)는 다른 모달리티를 통해 제시되더라도 동일 한 방법으로 전송이 되어야 한다. 넷째로, 상호작용 에이전트로부터 대화관리자로의 통신을 알아보면, 대화관리자는 시스템의 전체의 상태에 대해 알지 못한다. 따라서, 상호작용 에이전트가 FSM(Finite State Machine)의 새로운 상태(stat e)로 진입할 때 대화관리자에게새로운 상태와 관련된 모든 정보를 전달해야 한다. 다섯번째로, 작업계획시스템으로부터 대화관리자로의 통신을 알아보면, 작업계획시스템은 대화와 관련있는 로봇의 일시적 상태를 모두 전송해야 한다. 예를 들어, 즉시 실행을 필요로 하는 임의의 업무가 리더 에이전트의 큐(queue)에 있는지 여부, 대화 도중에 배터리가 방전되어 충전 스테이션으로 돌아오기 위해 대 화를 중단해야 하는 상태에 있는지 여부 등에 관한 정보를 전송해야 한다. 도 2a는 본 발명의 일실시예에 의한 로봇과 사용자의 초기 인터페이스에 관한 동작을 설명하기 위한 흐름도이다. 도 2a에 도시한 바와 같이, 본 발명의 일실시예에 의한 로봇에 전원이 인가되면 초기화를 수행한다. 즉, 상술한 로봇의 시스템을 리셋하여 초기화를 시킨다.(s10) 이 때, 로봇의 상호작용 에이전트는 부동상태(idle state)로 천이되어 사용자의 명령을 대기한다.(s20) 또한, 부동상태에서 임의의 사용자 인터페이스 요소(User Interface Component)등은 로봇의 주목(attending)요청을 낼 수 있으며, 사용자 인터페이스 요소들은 복수개가 존재할 수 있다. 예를 들면, 특정 주목을 의미하는 단어(예를 들면, \"이리 와\", \"컴온\", \"주목\", \"로봇\"등)나 손뼉 소리, 접촉, 무선 조종(remote control), 호출 버튼(call button) 등이 사용자 인터페이스 요소가 될 수 있다. 한편, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목(user interface attending)을 하 게 된다. 여기서 로봇이 사용자에게 주목(attending)을 하는 것은 적절한 거리에서 그 사람과 마주 대면하는 것 과 같은 사회적 규범이라고 할 수 있다. 또한, 주목은 주목에 대한 사용자의 요구에 즉시 자극되기 시작한다. 이는 로봇 주도의 업무(task)의 시작을 방지해주며, 동시에 다수의 사용자들이 로봇의 주목을 요구할 때 결정이 우유부단한 상황을 예방해준다. 만약, 사용자 인터페이스 요소에 의한 주목이 실패하면 상호작용 에이전트 는 부동 상태로 돌아간다.(s40) 도 2b는 본 발명의 일실시예에 의한 로봇과 사용자의 초기 대화에 관한 동작을 설명하기 위한 흐름도이다. 도 2a에서 설명한 것과 같이, 본 발명의 일실시예에 의한 로봇은 초기화를 수행 후 부동상태(idle state)로 천 이되며, 상술한 것처럼 \"로봇\"과 같은 사용자의 음성 호출 등의 사용자 인터페이스 요소에 의해 로봇의 주목 요 청이 입력되면 사용자 주목(user interface attending)을 수행함으로서 대화 준비를 완료하게 된 다.(s10,s20,s40) 또한, 로봇은 사용자에게 주목함으로서 대화 준비가 완료되면 사용자와 컬앤컴(call and come) 대화를 수행한 다. 예를 들면, 사용자가 로봇에게 \"이리와\"라고 명령을 하고 로봇이 \"예, 주인님\"이라 대답을 한 후, 사용자가 \"나한테 컵을 가져와\"라고 하면 로봇이 \"예, 주인님\"이라고 대답하는 방식으로 대화를 수행하게 되는 것이다. 이 때, 대화관리자는 컬앤컴 대화가 끝난 후 또는 대화 도중 작업계획시스템에 목표(goal)를 제시할 수 도 있으며, 제시된 목표는 리더 에이전트의 큐(queue)에 저장된다. 대화가 종료되면 로봇은 사용자의 명령 에 의해 큐(queue)에 저장된 업무를 수행하며, 대화관리자가 대화의 완료를 나타내는 신호를 보내면 로봇은 다시 부동상태(idle state)로 천이한다.(s50) 도 2c는 본 발명의 일실시예에 의한 로봇이 업무 수행 중 사용자와 대화하는 동작을 설명하기 위한 흐름도이다. 도 2a 및 도 2b에 설명한 것처럼, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목을 한 후 컬앤컴 대화를 수행한 후 상호작용 에이전트는 부동상태(idle state)에서 동작상태(busy state)로 천이 된다. 여기서 동작상태(busy state)는 로봇의 주목을 받는 임의의 비대화 상태를 표현한다. 또한, 동작상태는 상호작용 에이전트가 부동상태(idle state)일 경우 리더 에이전트에 의해서만 천이 될 수 있 다.(s10,s20,s60) 그리고, 동작상태에서 사용자와 업무에 대해 상호작용을 하기위해 업무상 주목(task attending)을 하게 된다. 또한, 로봇의 업무상 주목으로 대화준비가 되면, 사용자가 지시한 작업의 수행과정에서 필요한 업무특정대화(Task-Specific-dialog)를 할 수 있다.(s70,s80) 예를 들어, 컬앤컴(call and come)대화에서 전달된 업무가 \"컵을 나에게 가져와\"였다면 업무특정대화(Task- Specific-dialog)에서는 \"여기 가져왔습니다\", \"더 시킬일 없습니까?\"등의 대화를 관장하게 된다. 즉, 로봇이 수행해야 할 하나의 목표(goal)는 사람과 상호작용을 필요로 하므로 리더 에이전트는 물품의 전 달, 도움 요청, 발음을 명확히 해달라는 요청 등 어떤 특정한 업무를 위한 대화 즉, 업무특정대화(Task- Specific-dialog)를 시작할 수 있다. 그리고, 상호작용 에이전트는 업무가 완료되면 동작상태에서 부동상태 로 천이하게 된다. 도 2d는 본 발명의 일실시예에 의한 로봇의 사용자와 대화동작을 설명하기 위한 제어흐름도이다. 또한, 도 2d는 도 2a 내지 도 2c를 합성한 흐름도로서, 도 2a 내지 도 2c와같은 블록에 대해서는 동일한 부호를 병기한다. 본 발명의 일실시예에 의한 로봇에 전원이 인가되면 초기화(initialization)를 수행한다. 즉, 상술한 로봇의 시 스템을 리셋하여 초기화를 시킨다.(s10) 다음으로, 로봇의 리더 에이전트는 상호작용 에이전트를 부동상태(idle state)로 천이시킴으로서 사용 자의 명령을 대기한다.(s20) 다음으로, 대화관리자는 부동상태에서 임의의 사용자 인터페이스 요소(User Interface Component)가 발생하 여 로봇의 주목(attending)요청이 있는지 확인한다. 즉, 사용자 인터페이스 요소 즉, 특정 주목을 요구하는 단 어(예를 들면, \"이리 와\", \"컴온\", \"주목\", \"로봇\"등)나 손뼉 소리, 접촉, 무선 조종(remote control), 호출 버튼(call button)의 누름 등이 발생한 것으로 확인되면 그 정보를 상호작용 에이전트에 전달한다. 한편, 대화 관리자에서 발생하는 이벤트들은 상호작용 에이전트에 지속적으로 전달된다.(s30) 다음으로, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목(user interface attending)을 하게 된다. 여기서 로봇이 사용자에게 주목(attending)을 하는 것은 적절한 거리에서 그 사람과 마주 대면하는 것과 같은 사회적 규범이라고 할 수 있다. 또한, 주목은 주목에 대한 사용자의 요구에 즉시 자극되기 시작한다. 이는 로봇 주도의 업무(task)의 시작을 방지해주며, 동시에 다수의 사용자들이 로봇의 주목을 요구할 때 결정이 우유부단한 상황을 예방해준다.(s40) 다음으로, 로봇은 사용자에게 주목함으로서 대화 준비가 완료되면 사용자와 컬앤컴(call and come) 대화를 수행 한다. 예를 들면, 사용자가 로봇에게 \"이리와\"라고 명령을 하고 로봇이 \"예, 주인님\"이라 대답을 한 후, 사용자 가 \"나한테 컵을 가져와\"라고 하면 로봇이 \"예, 주인님\"이라고 대답하는 방식으로 대화를 수행하게 되는 것이다.(s50) 다음으로, 상호작용 에이전트는 부동상태(idle state)로 천이된다.(s60) 다음으로, 상호작용 에이전트는 부동상태(idle state)에서 동작상태(busy state)로 천이된다. 여기서 동작 상태(busy state)는 로봇의 주목을 받는 임의의 비대화 상태를 표현한다. 또한, 동작상태는 상호작용 에이전트 가 부동상태(idle state)일 경우 리더 에이전트에 의해서만 천이 될 수 있다.(s70) 다음으로, 동작상태에서 사용자와 업무에 대해 상호작용을 하기위해 업무상 주목(task attending)을 하게 된 다.(s80) 다음으로, 로봇의 업무상 주목으로 대화준비가 되면, 사용자가 지시한 작업의 수행과정에서 필요한 업무특정대 화(Task-Specific-dialog)를 할 수 있다. 예를 들어, 컬앤컴(call and come)대화에서 전달된 업무가 \"컵을 나에게 가져와\"였다면 업무특정대화(Task- Specific-dialog)에서는 \"여기 가져왔습니다\", \"더 시킬일 없습니까?\"등의 대화를 관장하게 된다. 또다른 예로 컬앤컴 대화에서 전달된 업무가 \"우리 딸 영이에게 점심을 줘\"였다면 업무 특정대화에서는 \"영이님 점심 가지고 왔습니다\", \"영이님 점심 드실 시간입니다\", \"영이님 점심 다 드시면 제가 치워드리겠습니다\" 등의 대화를 관장 하게 된다.(s90) 도 3a는 본 발명의 일실시예에 의한 로봇이 업무 수행중 다른 사용자에 의해 주목 요청이 들어올 경우의 로봇의 동작을 설명하기 위한 흐름도이다. 도 2d에 설명한 것처럼, 사용자 인터페이스 요소(user interface component)가 있는 것으로 확인되면 로봇은 사 용자인터페이스주목(user interface attending)으로 대화준비를 완료한 후 컬앤컴(call and come)대화를 수행 하고, 상호작용 에이전트는 동작 상태(busy state)로 천이되며 다시 부동상태(idle state)로 돌아올 때 큐 (queue)에 저장되어 있는 업무를 수행해야 한다. 이 때, 어떤 다른 사용자가 로봇의 주목을 요청한다면 다른 사 용자와의 대화는 본래의 주목 요청에 의한 대화 즉, 컬앤컴대화(call and come dialog)와 달라야만 한다. 따라 서, 로봇은 업무 수행 중 다른 사용자의 주목 요청이 있는 경우 업무동작중주목(task busy attending)을 한다. 여기서 업무동작중주목(task busy attending)이란 또다른 유저인터페이스와 상호작용을 준비하기 위한 동작이다. 한편, 업무동작중주목(task busy attending)에 의해 로봇이 사용자와 대화 준비가 끝나면 업무동작중 단대화(task busy interrupt dialog)를 수행한다. 업무동작중단대화(task busy interrupt dialog)에서는 이전 사용자가 입력한 명령을 수행하고 있는 것을 감안하여 대화하는 것으로서, \"죄송합니다. 다른 명령을 수행하고 있습니다.\"등의 대화를 할 수 있다. 한편, 로봇에 미리 저장된 우선순위에 따라 현재 사용자의 명령을 우선적으 로 수행하게 할 수 있다.(s10,s20,s70,s72,s73) 도 3b는 본 발명의 일실시예에 의한 로봇에게 명령 전달 후 업무 수행 개시전에 다른 사용자에 의해 주목 요청 이 들어올 경우의 로봇의 동작을 설명하기 위한 흐름도이다. 도 3b에 도시한 바와 같이, 임의의 인터럽트는 로봇의 리더 에이전트가 업무를 수행하기 전에 발생할 수 있 다. 즉, 사용자에 의해 주목 요청을 받은 후 대화의 진행 도중 또는 대화가 끝난 후 업무 수행 개시 전에 임의 의 사용자에 의해 주목 요청이 발생하는 경우이다. 이러한 경우 사용자인터페이스동작중단대화(User Interface Busy Interrupt Dialog)를 수행함으로서 먼저 대화를 요청한 선사용자와의 관계를 고려하여 대화를 수행할 수 있다.(s10,s20,s52,s53) 도 3c는 본 발명의 일실시예에 의한 로봇의 사용자와 대화동작을 설명하기 위한 제어흐름도이다. 또한, 도 3c는 도 3a 및 도 3b를 합성한 흐름도로서, 도 3a 및 도 3b와 같은 블록에 대해서는 동일한 부호를 병 기한다. 본 발명의 일실시예에 의한 로봇은 전원이 인가되면 초기화(initialization)를 수행한다. 즉, 상술한 로봇의 시 스템을 리셋하여 초기화를 시킨다.(s10) 다음으로, 로봇의 리더 에이전트는 상호작용 에이전트를 부동상태(idle state)로 천이시킴으로서 사용 자의 명령을 대기한다.(s20) 다음으로, 대화관리자는 부동상태에서 임의의 사용자 인터페이스 요소(User Interface Component)가 발생하 여 로봇의 주목(attending)요청이 있는지 확인한다. 즉, 사용자 인터페이스 요소 즉, 특정 주목을 요구하는 단 어(예를 들면, \"이리 와\", \"컴온\", \"주목\", \"로봇\"등)나 손뼉 소리, 접촉, 무선 조종(remote control), 호출 버튼(call button)의 누름 등이 발생한 것으로 확인되면 그 정보를 상호작용 에이전트에 전달한다.(s30) 다음으로, 사용자 인터페이스 요소가 있는 것으로 확인되면 사용자인터페이스주목(user interface attending)을 하게 된다. 여기서 로봇이 사용자에게 주목(attending)을 하는 것은 적절한 거리에서 그 사람과 마주 대면하는 것과 같은 사회적 규범이라고 할 수 있다. 또한, 주목은 주목에 대한 사용자의 요구에 즉시 자극되기 시작한다. 이는 로봇 주도의 업무(task)의 시작을 방지해주며, 동시에 다수의 사용자들이 로봇의 주목을 요구할 때 결정이 우유부단한 상황을 예방해준다.(s40) 다음으로, 로봇은 사용자에게 주목함으로서 대화 준비가 완료되면 사용자와 컬앤컴(call and come) 대화를 수행 한다. 예를 들면, 사용자가 로봇에게 \"이리와\"라고 명령을 하고 로봇이 \"예, 주인님\"이라 대답을 한 후, 사용자 가 \"나한테 컵을 가져와\"라고 하면 로봇이 \"예, 주인님\"이라고 대답하는 방식으로 대화를 수행하게 되는 것이다.(s50) 다음으로, 어느 사용자와 대화의 진행 도중 또는 대화가 끝난 후 업무 수행 개시 전에 임의의 사용자에 의해 주 목 요청이 발생하는지 여부 즉, 사용자 인터페이스가 추가로 발생하는지 확인한다.(s51) 다음으로, 사용자 인터페이스가 추가로 발생한 것으로 확인되면 사용자인터페이스주목(user interface attending)을 하고, 사용자인터페이스동작중단대화(User Interface Busy Interrupt Dialog)를 수행함으로서 먼 저 대화를 요청한 선사용자와의 관계를 고려하여 대화를 수행할 수 있다. 예를 들면, \"다른 사용자가 먼저 대화 를 시도하고 있습니다.\"등의 대화를 할 수 있다.(s52,s53) 다음으로, 상호작용 에이전트은 부동상태로 다시 천이된다.(s60) 다음으로, 상호작용 에이전트는 부동상태(idle state)에서 동작상태(busy state)로 천이된다. 여기서 동작 상태(busy state)는 로봇의 주목을 받는 임의의 비대화 상태를 표현한다. 또한, 동작상태는 상호작용 에이전트 가 부동상태(idle state)일 경우 리더 에이전트에 의해서만 천이 될 수 있다.(s70) 다음으로, 로봇은 업무 수행 중 다른 사용자의 주목 요청 즉, 사용자 인터페이스가 있는지 확인하며, 주목 요청 이 있는 경우 업무동작중주목(task busy attending)을 한다. 여기서 업무동작중주목(task busy attending)이란 또다른 유저인터페이스와 상호작용을 준비하기 위한 동작이다.(s71,s72) 다음으로, 업무동작중주목(task busy attending)에 의해 로봇이 사용자와 대화 준비가 끝나면 업무동작중단대 화(task busy interrupt dialog)를 수행한다. 업무동작중단대화(task busy interrupt dialog)는 이전 사용자가 입력한 명령을 수행하고 있는 것을 감안하여 대화하는 것으로서, \"죄송합니다. 다른 명령을 수행하고 있습니 다.\"등의 대화를 할 수 있다.(s73) 한편, s71단계에서 임의의 사용자 인터페이스가 발생하지 않는 것으로 확인되면 동작상태에서 사용자와 업무에 대해 상호작용을 하기 위한 대화를 하기 위해 업무상 주목(task attending)을 하게 된다.(s80) 다음으로, 로봇의 업무상 주목으로 대화준비가 되면, 사용자가 지시한 작업의 수행과정에서 필요한 업무특정대 화(Task-Specific-dialog)를 하게되면 지시받은 업무를 수행함으로서 행동을 종료하게 된다.(s90) 한편, 로봇이 대화 또는 업무 수행 중 다른 인터럽트가 들어오면 리더 에이전트는 상호작용 에이전트의 상태를 확인하고, 확인된 상태 정보를 대화관리자에 전송함으로서 로봇이 컬앤컴 대화를 수행할 것인지, 사 용자인터페이스동작중단대화를 수행할 것인지, 업무동작중단대화를 수행할 것인지, 업무특정대화를 수행할 것인 지 결정할 수 있다."}
