{"patent_id": "10-2023-0037340", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0142821", "출원번호": "10-2023-0037340", "발명의 명칭": "인공지능 모델 학습 방법, 인공지능 모델을 이용한 보행 이상탐지 방법 및 이를 수행하는 프", "출원인": "경상국립대학교산학협력단", "발명자": "김진현"}}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의하여, 마커(Maker)를 구비하지 않은 보행자가 보행하고 있는 다수 개의 학습영상이학습 데이터셋으로 획득되는 학습 데이터셋 획득단계;상기 적어도 하나의 프로세서에 의하여, 각 학습영상으로부터 다수 개의 관절 포인트가 추출되는 학습영상 관절포인트 추출단계; 및상기 적어도 하나의 프로세서에 의하여, 학습영상별 다수 개의 관절 포인트가 이용되어 인공지능 모델을 학습시키고, 보행 이상탐지를 위한 인공지능 모델이 생성되는 모델 학습단계;를 포함하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 프로세서에 의하여, 학습 정확도를 향상시킬 수 있도록 각 학습영상이 전처리되는 학습영상전처리단계;를 더 포함하는 것을 특징으로 하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 다수 개의 학습영상은,정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상과 비정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상을 포함하는 것을 특징으로 하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 다수 개의 관절 포인트는,보행자의 오른 무릎의 각도, 왼 무릎의 각도, 오른 엉덩이의 각도, 왼 엉덩이의 각도 및 코-어깨의 각도 중 적어도 하나를 포함하는 것을 특징으로 하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 인공지능 모델은,시계열 데이터 처리가 가능한 장단기 메모리(Long Short-Term Memory; LSTM)와 비지도 학습이 가능한 오토인코더(Autoencoder)가 결합된 LSTM-Autoencoder 모델인 것을 특징으로 하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 모델 학습단계는,정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상으로부터 추출된 상기 다수 개의 관절 포인트가 학습되면,관절 포인트별 손실값이 추출되는 손실값 추출단계; 및관절 포인트별 손실값을 평균한 평균값이 연산되고, 관절 포인트별 평균값이 보행 이상여부를 구분하는 임계값으로 설정되는 임계값 설정단계;를 포함하는 것을 특징으로 하는 인공지능 모델 학습 방법.공개특허 10-2024-0142821-3-청구항 7 적어도 하나의 프로세서에 의하여, 마커(Maker)를 구비하지 않은 보행자가 보행하고 있는 다수 개의 학습영상이학습 데이터셋으로 획득되는 학습 데이터셋 획득단계;상기 적어도 하나의 프로세서에 의하여, 각 학습영상으로부터 다수 개의 관절 포인트가 추출되는 학습영상 관절포인트 추출단계;상기 적어도 하나의 프로세서에 의하여, 학습영상별 다수 개의 관절 포인트가 이용되어 인공지능 모델을 학습시키고, 보행 이상탐지를 위한 인공지능 모델이 생성되는 모델 학습단계;상기 적어도 하나의 프로세서에 의하여, 마커(Maker)를 구비하지 않은 피검사자가 보행하고 있는 보행영상이 획득되는 보행영상 획득단계;상기 적어도 하나의 프로세서에 의하여, 상기 보행영상으로부터 다수 개의 관절 포인트가 추출되는 보행영상 관절 포인트 추출단계; 및상기 적어도 하나의 프로세서에 의하여, 상기 모델 학습단계로부터 생성된 인공지능 모델에 상기 보행영상의 다수 개의 관절 포인트가 입력됨으로써, 피검사자의 보행 이상여부가 출력되는 보행 이상탐지단계;를 포함하는 인공지능 모델을 이용한 보행 이상탐지 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 적어도 하나의 프로세서에 의하여, 학습 정확도를 향상시킬 수 있도록 각 학습영상이 전처리되는 학습영상전처리단계; 및상기 적어도 하나의 프로세서에 의하여, 이상탐지 정확도를 향상시킬 수 있도록 상기 보행영상이 전처리되는 보행영상 전처리단계;를 더 포함하는 것을 특징으로 하는 인공지능 모델을 이용한 보행 이상탐지 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 다수 개의 학습영상은, 정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상과 비정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상을 포함하고,상기 보행영상은,촬영부를 포함하는 피검사자 단말을 통해서 피검사자의 좌측면 또는 우측면이 촬영된 것을 특징으로 하는 인공지능 모델을 이용한 보행 이상탐지 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 학습영상 관절 포인트는,보행자의 오른 무릎의 각도, 왼 무릎의 각도, 오른 엉덩이의 각도, 왼 엉덩이의 각도 및 코-어깨의 각도 중 적어도 하나를 포함하고,상기 보행영상 관절 포인트는,피검사자의 오른 무릎의 각도, 왼 무릎의 각도, 오른 엉덩이의 각도, 왼 엉덩이의 각도 및 코-어깨의 각도 중적어도 하나를 포함하는 것을 특징으로 하는 인공지능 모델을 이용한 보행 이상탐지 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,공개특허 10-2024-0142821-4-상기 인공지능 모델은,시계열 데이터 처리가 가능한 장단기 메모리(Long Short-Term Memory; LSTM)와 비지도 학습이 가능한 오토인코더(Autoencoder)가 결합된 LSTM-Autoencoder 모델인 것을 특징으로 하는 인공지능 모델을 이용한 보행 이상탐지방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 모델 학습단계는,정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상으로부터 추출된 상기 다수 개의 관절 포인트가 학습되면,관절 포인트별 손실값이 추출되는 손실값 추출단계; 및관절 포인트별 손실값을 평균한 평균값이 연산되고, 각 평균값이 보행 이상여부를 구분하는 관절 포인트별 임계값으로 설정되는 임계값 설정단계;를 포함하는 것을 특징으로 하는 인공지능 모델을 이용한 보행 이상탐지방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 보행 이상탐지단계는,상기 보행영상의 다수 개의 관절 포인트에 대한 관절 포인트별 손실값과 상기 임계값 설정단계로부터 설정된 관절 포인트별 임계값과 비교되고, 관절 포인트별 손실값이 임계값보다 큰 경우가 하나라도 존재하는 경우 피검사자의 보행이 이상한 것으로 판단되고,관절 포인트별 손실값이 임계값보다 모두 작은 경우 피검사자의 보행이 정상인 것으로 판단되는 것을 특징으로하는 인공지능 모델을 이용한 보행 이상탐지 방법."}
{"patent_id": "10-2023-0037340", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 내지 제13항 중 어느 한 항의 인공지능 모델 학습 방법 또는 인공지능 모델을 이용한 보행 이상탐지 방법을 수행하는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체."}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 모델 학습 방법, 인공지능 모델을 이용한 보행 이상탐지 방법 및 이를 수행하는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체에 관한 것으로, 보다 구체적으로 마커(Maker)를 구비하지 않은 보행자가 보행하고 있는 다수 개의 학습영상이 학습 데이터셋으로 획득되는 학습 데이터셋 획득단계, 각 학습영상으로부터 (뒷면에 계속)"}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델 학습 방법, 인공지능 모델을 이용한 보행 이상탐지 방법 및 이를 수행하는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체에 관한 것이다."}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술은 자율주행, 항공, 농업 등 다양한 분야에서 활용되고 있다. 특히 의료계에서는 축적된 빅 데이터(Big data)를 기반으로 의사의 판단을 도울 수 있는 인공지능 기술개발이 한창이다. 이러한 인공지능은 저렴한 비용으로 환자에 대한 즉각적인 기초 진단 및 위급성 분석을 할 수 있어 효과적인 진료 방법이 될 것으 로 예상되고 있다. 그중 정형외과에서는 근골격계 질환 및 질환의 중증도를 판단하는데 유용한 보행 특징을 분석하기 위해 보행 이 미지 및 동영상을 활용하고 있다. 이와 관련하여 관련문헌 1은 근골격계 이상예측장치 및 어플리케이션에 관한 것으로, 2차원 보행영상을 획득한 후 기계학습모델에 입력함으로써 이상보행에 속하는지 여부를 판단할 수 있는 기술이다. 다만, 보행영상은 보행자의 촬영환경, 촬영방식에 따라 보행자를 객체로써 정확하게 인식하기 어려울 수 있다. 관련문헌 2는 근골격계 진단을 위한 동작 획득 방법 및 장치에 관한 것으로, 사전에 계측된 사람의 신체정보를 이용하여 착용형 다중 센서와 깊이 영상을 기반으로 근골격계 진단을 위한 동작을 획득할 수 있다. 다만, 이 영상은 보행자가 착용형 다중 센서를 반드시 착용해야만 획득할 수 있다. 정형외과 등 특정 기관에 방문해야만 이 러한 시스템을 사용하여 근골격계 진단을 받을 수 있다. 따라서 피검사자의 신체에 어떠한 마커도 부착되지 않은 일반적인 상황에서도 피검사자의 보행 이상여부를 탐지"}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "하고, 더 나아가 근골격계 질환 및 질환의 중증도 등을 정확하게 판단할 수 있는 기술이 본 기술분야에서 절실 히 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허문헌 제10-2251925호 (특허문헌 0002) 대한민국 등록특허문헌 제10-2020-0087027호"}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위한 것으로 신체에 어떠한 마커도 부착되지 않은 일반적인 상황에서 도 피검사자의 보행 이상여부를 종래보다 정확하게 탐지할 수 있도록 학습 데이터셋 내 학습영상별 다수 개의 관절 포인트가 이용되어 인공지능 모델을 학습시키고, 생성된 인공지능 모델을 이용하여 피검사자의 보행 이상 여부가 탐지되는 인공지능 모델 학습 방법, 인공지능 모델을 이용한 보행 이상탐지 방법 및 이를 수행하는 프로 그램이 기록된 컴퓨터 판독이 가능한 기록매체를 얻고자 하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 본 발명의 기재로부터 당해 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있다."}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여, 본 발명의 인공지능 모델 학습 방법은 적어도 하나의 프로세서에 의하여, 마커 (Maker)를 구비하지 않은 보행자가 보행하고 있는 다수 개의 학습영상이 학습 데이터셋으로 획득되는 학습 데이 터셋 획득단계; 상기 적어도 하나의 프로세서에 의하여, 각 학습영상으로부터 다수 개의 관절 포인트가 추출되 는 학습영상 관절 포인트 추출단계; 및 상기 적어도 하나의 프로세서에 의하여, 학습영상별 다수 개의 관절 포 인트가 이용되어 인공지능 모델을 학습시키고, 보행 이상탐지를 위한 인공지능 모델이 생성되는 모델 학습단 계;를 제공한다. 또한 상기 목적을 달성하기 위하여, 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법은 적어도 하나의 프 로세서에 의하여, 마커(Maker)를 구비하지 않은 보행자가 보행하고 있는 다수 개의 학습영상이 학습 데이터셋으 로 획득되는 학습 데이터셋 획득단계; 상기 적어도 하나의 프로세서에 의하여, 각 학습영상으로부터 다수 개의 관절 포인트가 추출되는 학습영상 관절 포인트 추출단계; 상기 적어도 하나의 프로세서에 의하여, 학습영상별 다수 개의 관절 포인트가 이용되어 인공지능 모델을 학습시키고, 보행 이상탐지를 위한 인공지능 모델이 생성되 는 모델 학습단계; 상기 적어도 하나의 프로세서에 의하여, 마커(Maker)를 구비하지 않은 피검사자가 보행하고 있는 보행영상이 획득되는 보행영상 획득단계; 상기 적어도 하나의 프로세서에 의하여, 상기 보행영상으로부터 다수 개의 관절 포인트가 추출되는 보행영상 관절 포인트 추출단계; 및 상기 적어도 하나의 프로세서에 의하여, 상기 모델 학습단계로부터 생성된 인공지능 모델에 상기 보행영상의 다수 개의 관절 포인트가 입력됨으로써, 피 검사자의 보행 이상여부가 출력되는 보행 이상탐지단계;를 제공한다. 또한 상기 목적을 달성하기 위하여 본 발명의 인공지능 모델 학습 방법 또는 인공지능 모델을 이용한 보행 이상 탐지 방법을 수행하는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체에 관한 것이다."}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같이 본 발명에 의하면 학습 데이터셋 내 학습영상별 다수 개의 관절 포인트가 이용되어 인공지능 모델 을 학습시키고, 학습된 인공지능 모델을 이용하여 피검사자의 보행 이상여부가 탐지됨으로써, 신체에 어떠한 마커도 부착되지 않은 일반적인 상황에서도 피검사자의 보행 이상여부를 탐지할 수 있고, 더 나아가 근골격계 질 환 및 질환의 중증도 등을 객관적으로 정확하게 판단하는데 보조적인 역할을 할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 상세한 설명 및 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가 지는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 다르게 정의되지 않는 한 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반 적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 본 발명에 따른 실시예를 첨부한 도면을 참조하여 상세히 설명하기로 한다. 도 1은 본 발명의 인공지능 모델 학습 방법 흐름도이다. 도 2는 본 발명의 일실시예에 따른 학습영상 전처리단계(S200)를 포함하는 인공지 능 모델 학습 방법 흐름도이다. 도 3은 프레임 불균형(a), 옷(b), 배경(c)으로 인한 객체 인식 오류를 표시한 도면이다. 도 4는 배경으로 인한 객체 인식 오류가 발생한 프레임(a)과 본 발명의 일실시예에 따른 전처리단계 (S200, S600)로부터 배경 처리된 프레임(b)을 표시한 도면이다. 도 5는 본 발명의 일실시예에 따른 다수 개의 관절 포인트를 표시한 도면이다. 도 6은 본 발명의 일실시예에 따른 LSTM-Autoencoder 모델의 구조도이다. 도 7 은 본 발명의 일실시예에 따른 LSTM-Autoencoder 모델 layer를 표시한 도면이다. 도 8은 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법 흐름도이다. 도 9는 본 발명의 일실시예에 따른 학습영상 전처리단계(S200) 및 보행영상 전처리단계(S600)를 포함하는 인공지능 모델을 이용한 보행 이상탐지방법 흐름도이다. 도 10은 본 발명의 일실시예에 따른 보행자 및 피검사자의 목 위의 신체부위가 프레임 밖으로 벗어난 경우(a)와 보행자 및 피검사자가 오른쪽으로 걸어갈 때 팔 또는 다리가 프레임 밖으로 벗어난 경우(b)를 표시한 도면이다. 도 11은 본 발명의 일실시예에 따른 경계박스 도출단계(S910)로부터 경계박스가 표시된 프레임(a)과 좌표값 도 출단계(S920)로부터 도출된 제1 꼭지점과 제2 꼭지점에 대한 좌표값을 표시한 도면이다. 도 12는 본 발명의 일 실시예에 따른 이상적인(Ideal) 촬영 가이드(a)와 최대(Maximum) 촬영 가이드(b)를 표시한 도면이다. 우선, 본 발명은 인공지능 모델 학습 방법 또는 인공지능 모델을 이용한 보행 이상탐지 방법을 수행하는 프로그 램이 기록된 컴퓨터 장치로 읽을 수 있는 기록매체를 포함한다. 예컨대, CD, DVD, 하드디스크, 블루 레이 디스크, USB, 메모리 카드, ROM 등일 수 있다. 그리고 본 발명의 인공지능 모델 학습 방법 또는 인공지능 모델을 이용한 보행 이상탐지 방법은 컴퓨터 장치 내 적어도 하나의 프로세서가 상기 기록매체 를 읽음으로써 구현될 수 있다. 인공지능 모델 학습 방법 도 1을 보면, 본 발명의 인공지능 모델 학습 방법은 적어도 하나의 프로세서에 의하여, 마커(Maker)를 구 비하지 않은 보행자가 보행하고 있는 다수 개의 학습영상이 학습 데이터셋으로 획득되는 학습 데이터셋 획득단 계(S100), 상기 적어도 하나의 프로세서에 의하여, 각 학습영상으로부터 다수 개의 관절 포인트가 추출되 는 학습영상 관절 포인트 추출단계(S300) 및 상기 적어도 하나의 프로세서에 의하여, 학습영상별 다수 개 의 관절 포인트가 이용되어 인공지능 모델을 학습시키고, 보행 이상탐지를 위한 인공지능 모델이 생성되는 모델 학습단계(S400)를 포함한다. 본 발명에서 언급하는 보행자는 학습 데이터셋을 구축하기 위한 불특정 다수의 정상 보행자 및 비정상 보행자이 다. 그리고 학습영상은 불특정 다수의 정상 보행자 및 비정상 보행자가 보행하고 있는 영상이다. 또한, 본 발명에서 언급하는 다수 개의 학습영상은 마커(Maker)를 구비하지 않은 정상 보행자 및 비정상 보행자 로부터 획득한 마커리스(Makerless)기반 영상이다. 일반적으로, 보행자의 신체일부에 센서의 일종인 별도의 마 커(Maker)와 이를 인식하기 위한 또 다른 센서를 포함하는 시스템으로 보행자의 보행을 추적할 수 있다. 그러나 정상 보행자 및 비정상 보행자는 다수 개의 마커(Maker)를 착용해야하는 불편함이 있고, 해당 시스템이 구비된 기관에 방문하여 사용해야만 하는 번거로움이 있다. 이를 해결하기 위해서 상기 학습 데이터셋 획득단계(S100) 는 카메라 또는 카메라가 내장된 장치, 예컨대 스마트폰을 통해서 정상 보행자 및 비정상 보행자가 보행하는 동 작이 촬영된 학습영상이 획득될 수 있다. 또한, 상기 다수 개의 학습영상은 정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상과 비정상 보행자의 좌 측면 또는 우측면이 촬영된 학습영상을 포함하는 것을 특징으로 한다. 상술한 바와 같이 상기 학습영상은 일반 적인 촬영장치를 통해서 획득한 2차원 영상이기 때문에, 보행자의 정면 또는 후면이 촬영된 영상으로는 보행자 의 보행 동작을 정확하게 파악하는데 어려움이 있다. 즉, 2차원 영상인 학습영상으로부터 보행 이상탐지여부, 더 나아가 근골격계 질환을 보다 효율적이고 정확하게 판단하기 위해서 상기 학습 데이터셋 획득단계(S100)는 보행자의 정면 또는 후면이 촬영된 영상이 아닌, 우측면 또는 좌측면이 촬영된 영상이 획득되는 것이 가장 바람 직하다. 다음으로, 본 발명의 인공지능 모델 학습 방법은, 상기 적어도 하나의 프로세서에 의하여, 학습 정확도를 향상시킬 수 있도록 각 학습영상이 전처리되는 학습영상 전처리단계(S200)를 더 포함하는 것을 특징으로 한다. 상술한 바와 같이 상기 학습영상은 일반적인 촬영장치를 통해서 비전문가가 촬영하는 것이기 때문에 각 학습영 상 내 보행자를 정확하게 인식하지 못하는 문제가 발생할 수 있다. 도 3의 (a)와 같은 영상의 프레임으로부터 보행자의 신체 중 일부가 벗어난 프레임 불균형 문제, 도 3의 (b)와 같은 신체보다 큰 사이즈의 옷을 착용함으 로써 보행자의 신체형상이 정확하게 파악되지 못하는 옷 문제, 도 3의 (c)와 같은 촬영환경에 따라 보행자 외 다양한 집기 등이 촬영되어 보행자가 정확하게 파악되지 못하는 배경 문제가 발생할 수 있다. 특히나, 본 발명 은 배경 문제를 정보 처리 방식을 통해서 해결하고자 한다. 한편, 배경 문제를 해결하기 위해서 도 2의 일실시예를 보면, 상기 학습영상 전처리 단계(S200)는 학습영상 프 레임 추출단계(S210), 보행자 탐지단계(S220), 보행자 이진화 단계(S230), 보행자 면적 연산단계(S240) 및 학습 영상 배경 처리단계(S250)를 포함하는 것을 특징으로 한다.우선, 학습영상 프레임 추출단계(S210)는 상기 학습영상으로부터 다수 개의 프레임이 추출될 수 있다. 상기 학 습영상은 1개의 프레임으로 형성된 이미지형식이 아닌, 다수 개의 프레임으로 형성된 영상형식이다. 즉, 프레임 별로 보행자의 모습이 상이하기 때문에, 상기 학습영상 프레임 추출단계(S210)는 이를 파악하고자 상기 학습영 상이 다수 개의 프레임으로 분리 및 추출되는 것이다. 다음으로, 상기 보행자 탐지단계(S220)는 시맨틱 분할(Semantic Segmentation) 기법이 이용되어 각 프레임에서 보행자가 탐지될 수 있다. 상기 시맨틱 분할(Semantic Segmentation) 기법은 상기 학습영상의 각 프레임을 다수 개의 픽셀 집합으로 나누어, 객체와 객체 사이의 경계를 찾는 기법이다. 상기 보행자 탐지단계(S220)는 가장 바 람직하게 ResNet-101이 Backbone으로 사용된 DeeplabV3 모델을 기반으로 시맨틱 분할 기법이 이용되어 객체와 객체 외 배경이 구분될 수 있다. 즉, 상기 보행자 탐지단계(S220)는 객체와 객체 외 배경을 구분하는 과정이다. 다음으로, 상기 보행자 이진화 단계(S230)는 탐지된 보행자가 이진화될 수 있다. 상기 학습영상 내 사물이 없고 온전히 보행자만 있다면, 시맨틱 분할 기법만으로도 충분히 보행자가 탐지될 수 있다. 그러나 촬영환경으로 인 해 상기 학습영상 내 사물이 있다면, 상기 보행자 탐지단계(S220)로부터 시맨틱 분할 기법이 이용되어 구분된 객체에 보행자와 보행자가 아닌 사물이 포함될 수 있다. 따라서 상기 보행자 이진화 단계(S230)는 객체 중에서 보행자와 보행자 외 사물을 구분하기 위함이다. 본 발명의 일실시예에 따르면, 상기 보행자 이진화 단계(S230) 는 상기 객체 중 보행자만이 흰색으로 이진화될 수 있다. 다음으로, 상기 보행자 면적 연산단계(S240)는 윤곽선 검출 기법이 이용되어 보행자가 포함된 윤곽선 영역이 지정되고, 프레임별 윤곽선 영역에 대한 면적이 연산될 수 있다. 상술한 바와 같이 프레임별로 보행자의 동작이 상이함으로 보행자의 영역이 프레임별로 상이할 수 있다. 상기 보행자 면적 연산단계(S240)는 상기 보행자 이진 화 단계(S230)로부터 이진화된 영역을 대상으로 윤곽선 검출 기법이 이용되어 윤곽선 영역이 하나의 선으로 지 정될 수 있다. 그리고 상기 보행자 면적 연산단계(S240)는 각 프레임에 대한 상기 윤곽선 영역을 대상으로 면적 이 연산될 수 있다. 다음으로, 상기 학습영상 배경 처리단계(S250)는 각 프레임에서 최대 윤곽선 영역을 제외한 나머지 부분인 배경 이 단색으로 처리될 수 있다. 그러면 상기 학습영상 관절 포인트 추출단계(S300)는 상기 최대 윤곽선 영역을 객 체로 인식하는 것을 특징으로 한다. 윤곽선 영역은 프레임별로 존재하고, 각 윤곽선 영역은 서로 다른 면적을 가지고 있다. 상기 학습영상 배경 처리단계(S250)는 그 중 최대 윤곽선 영역을 대상으로 한다. 이는, 보행자의 신체가 상기 윤곽선 영역 내 모두 포함될 수 있도록 영역에 마진(Margin)을 두기 위함이다. 도 4의 (a)를 보면, 임의의 프레임은 전처리 전 배경으로 인해서 객체 인식 오류가 발생한 것을 확인할 수 있다. 도 4의 (b)를 보면, 임의의 프레임은 전처리 후 보행자와 보행자 외 배경이 정확하게 구분될 수 있고, 배 경이 검은색으로 이진화될 수 있다. 이에 따라, 상기 학습영상 관절 포인트 추출단계(S300)로부터 배경으로 인 한 객체 인식 오류가 발생하지 않는 것을 확인할 수 있다. 다음으로, 상기 학습영상 관절 포인트 추출단계(S300)는 가장 바람직하게, Google에서 개발된 MediaPipe 시스템 이 이용되어 전처리된 각 학습영상 내 프레임별 다수 개의 관절 포인트가 각각 추출될 수 있다. MediaPipe 시스 템에 따르면, 종래 OpenPose 시스템 보다 더 많은 관절 포인트를 추출할 수 있는 현저한 효과가 있다. 도 5의 일실시예를 보면, 상기 다수 개의 관절 포인트는, 보행자의 오른 무릎의 각도, 왼 무릎의 각도, 오른 엉덩이의 각도, 왼 엉덩이의 각도 및 코-어깨(12-0-11)의 각도 중 적어도 하나를 포함하는 것을 특징으 로 한다. 이때, 모델 학습단계(S400)는 전처리된 각 학습영상 내 프레임별 다수 개의 관절 포인트가 대상이 되고, 관절 포인트의 종류별 하이퍼 파라미터를 달리하여 인공지능 모델을 학습시킬 수 있다. 예컨대, 오른 엉덩이의 각도 의 경우 에포크(Epoch) 100, 배치 사이즈(Batch_size) 64, 학습률(Learning_Rate) 0.0001의 하이퍼 파라미 터로 학습될 수 있고, 오른 무릎의 각도 경우 에포크 (Epoch) 100, 배치 사이즈(Batch_size) 32, 학습률 (Learning_Rate) 0.0001의 하이퍼 파라미터로 학습될 수 있다. 도 6 내지 도 7의 일실시예를 보면, 본 발명에서 언급하는 인공지능 모델은 시계열 데이터 처리가 가능한 장단 기 메모리(Long Short-Term Memory; LSTM)와 비지도 학습이 가능한 오토인코더(Autoencoder)가 결합된 LSTM- Autoencoder 모델인 것을 특징으로 한다. 일반적으로, 장단기 메모리(LSTM)는 순환적인 구조를 가지는 순환 신경망 네트워크(RNN) 모델의 단점인 학습이 지속될수록 발생하는 기울기 소멸 문제(Vanishing Gradient)를 극복하기 위해 만들어진 딥러닝 신경망 알고리즘 모델이다. 순환 신경망 네트워크(RNN) 모델에 비해 비교적 긴 시간의 정보를 기억하여 시계열 데이터 처리가 용이하다는 장점이 있다. 본 발명의 학습영상 역시 시간에 대한 다수 개의 프레임을 구비함으로, 시계열 데이터 중 하나이다. 도 6의 일실시예를 보면, 상기 인공지능 모델은 다수 개의 LSTM을 포함함으로써, 시계열 데이터인 학습영상의 길이가 길더라도 기울기 소멸 문제(Vanishing Gradient)를 최소화하여 용이하게 처리할 수 있는 현 저한 효과가 있다. 또한, 오토인코더(Autoencoder)는 입력과 출력을 동일한 층으로 쌓고 정답값이 없는 상태에서 스스로 학습을 하 는 비지도 학습이 가능한 모델이다. 도 6 내지 도 7의 일실시예를 보면, 상기 오토인코더(Autoencoder)는 입력 과 출력이 동일한 인코딩(Encoding) LSTM 층과 디코딩(Decoding) LSTM 층을 포함할 수 있다. 이에 따라, 상기 모델 학습단계(S400)는 시계열 데이터인 각 학습영상을 비지도 학습시킬 수 있는 현저한 효과가 있다. 예컨대, 오른 무릎의 각도를 학습시키기 위해서 임의의 학습영상 내 프레임이 64 배치 사이즈로 입력되면, 인코딩(Encoding) LSTM 층은 64 배치 사이즈에서 32 배치 사이즈로 압축시키는 인코딩(Encoding)을 수행하고, 디코딩(Decoding) LSTM 층은 32 배치 사이즈에서 다시 본래의 형태인 64 배치 사이즈로 복원시키는 디코딩 (Decoding)을 수행할 수 있다. 또한, 오른 엉덩이의 각도를 학습시키기 위해서 동일한 학습영상이 32 배치 사이즈로 입력되면, 인코딩(Encoding) LSTM 층은 32 배치 사이즈에서 16 배치 사이즈로 압축시키는 인코딩 (Encoding)을 수행하고, 디코딩(Decoding) LSTM 층은 16 배치 사이즈에서 다시 본래의 형태인 32 배치 사이즈로 복원시키는 디코딩(Decoding)을 수행할 수 있다. 다음으로, 상기 모델 학습단계(S400)는 정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상으로부터 추출된 상기 다수 개의 관절 포인트가 학습되면, 관절 포인트별 손실값이 추출되는 손실값 추출단계(S410) 및 관절 포 인트별 손실값을 평균한 평균값이 연산되고, 관절 포인트별 평균값이 보행 이상여부를 구분하는 임계값으로 설 정되는 임계값 설정단계(S420)를 포함하는 것을 특징으로 한다. 예컨대, 상기 손실값 추출단계(S410)는 다수 개의 학습영상을 대상으로 보행자의 오른 무릎의 각도를 각각 학습함으로써, 상기 인공지능 모델로부터 오른 무릎의 각도에 대한 손실값(L1...Ln)(n은 1 이상의 양의 정수)이 추출될 수 있다. 그리고 상기 임계값 설정단계(S420)는 손실값 L1 내지 손실값 Ln을 평균한 평균값이 오 른 무릎에서의 보행 이상여부를 구분하는 임계값으로 설정될 수 있다. 또한, 상기 손실값 추출단계(S410)는 다 수 개의 학습영상을 대상으로 보행자의 오른 엉덩이의 각도를 각각 학습함으로써, 상기 인공지능 모델로부 터 오른 엉덩이의 각도에 대한 손실값(L1...Lm)(m은 1 이상의 양의 정수)이 추출될 수 있다. 그리고 상기 임 계값 설정단계(S420)는 손실값 L1 내지 손실값 Lm을 평균한 평균값이 오른 엉덩이에서의 보행 이상여부를 구 분하는 임계값으로 설정될 수 있다. 따라서 본 발명에 의하면, 마커(Maker)를 구비하지 않은 보행자가 보행하고 있는 다수 개의 학습영상을 이용하 여, 보행 이상탐지 정확도가 향상된 인공지능 모델을 생성할 수 있는 현저한 효과가 있다. 인공지능 모델을 이용한 보행 이상탐지 방법 도 8을 보면, 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법은 학습 데이터셋 획득단계(S100), 학습영 상 관절 포인트 추출단계(S300), 모델 학습단계(S400), 보행영상 획득단계(S500), 보행영상 관절 포인트 추출단 계(S700), 보행 이상탐지단계(S800)를 포함한다. 상기 학습 데이터셋 획득단계(S100)는 적어도 하나의 프로세서에 의하여, 마커(Maker)를 구비하지 않은 보 행자가 보행하고 있는 다수 개의 학습영상이 학습 데이터셋으로 획득된다. 상기 학습영상 관절 포인트 추출단계 (S300)는 상기 적어도 하나의 프로세서에 의하여, 각 학습영상으로부터 다수 개의 관절 포인트가 추출된다. 상기 모델 학습단계(S400)는 상기 적어도 하나의 프로세서에 의하여, 학습영상별 다수 개의 관 절 포인트가 이용되어 인공지능 모델을 학습시키고, 보행 이상탐지를 위한 인공지능 모델이 생성된다. 즉, 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법의 학습 데이터셋 획득단계(S100), 학습영상 관절 포인트 추 출단계(S300) 및 모델 학습단계(S400)는 상술한 인공지능 모델 학습 방법과 동일하다. 여기서, 상기 다수 개의 학습영상은, 정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상과 비정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상을 포함할 수 있다. 또한, 본 발명은 상기 적어도 하나의 프로세서에 의하여, 학습 정확도를 향상시킬 수 있도록 각 학습영상 이 전처리되는 학습영상 전처리단계(S200)를 더 포함하는 것을 특징으로 한다. 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법의 상기 학습영상 전처리단계(S200)는 상술한 인공지능 모델 학습 방법과 동일하다. 또한, 상기 학습영상 관절 포인트는, 보행자의 오른 무릎의 각도, 왼 무릎의 각도, 오른 엉덩이의 각도 , 왼 엉덩이의 각도 및 코-어깨의 각도(12-0-11) 중 적어도 하나를 포함할 수 있다. 또한, 상기 모델 학습단계(S400)는 정상 보행자의 좌측면 또는 우측면이 촬영된 학습영상으로부터 추출된 상기 다수 개의 관절 포인트가 학습되면, 관절 포인트별 손실값이 추출되는 손실값 추출단계(S410) 및 관절 포인트별 손실값을 평균한 평균값이 연산되고, 관절 포인트별 평균값이 보행 이상여부를 구분하는 임계값으로 설정되는 임계값 설정단계(S420)를 포함하는 것을 특징으로 한다. 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법 의 상기 손실값 추출단계(S410) 및 임계값 설정단계(S420)는 상술한 인공지능 모델 학습 방법과 동일하다. 다음으로, 상기 보행영상 획득단계(S500)는 상기 적어도 하나의 프로세서에 의하여, 마커(Maker)를 구비하 지 않은 피검사자가 보행하고 있는 보행영상이 획득된다. 본 발명에서 언급하는 보행영상은 마커(Maker)를 구비하지 않은 피검사자로부터 획득한 마커리스(Makerless)기 반 영상이다. 일반적으로, 피검사자의 신체일부에 센서의 일종인 별도의 마커(Maker)와 이를 인식하기 위한 또 다른 센서를 포함하는 시스템으로 피검사자의 보행을 추적할 수 있다. 그러나 피검사자는 다수 개의 마커 (Maker)를 착용해야하는 불편함이 있다. 이를 해결하기 위해서 상기 보행영상 획득단계(S500)는 카메라 또는 카 메라가 내장된 장치, 예컨대 스마트폰을 통해서 피검사자가 보행하는 동작이 촬영된 보행영상이 획득될 수 있다. 또한, 상기 보행영상은 촬영부를 포함하는 피검사자 단말을 통해서 피검사자의 좌측면 또는 우측면이 촬영 된 것을 특징으로 한다. 본 발명은 피검사자의 보행 이상탐지를 목적으로 한다. 상술한 바와 같이 상기 보행영 상은 촬영장치를 통해서 획득한 2차원 영상이기 때문에, 피검사자의 정면 또는 후면이 촬영된 영상으로는 피검 사자의 보행 동작을 정확하게 파악하는데 어려움이 있다. 즉, 2차원 영상인 보행영상으로부터 피검사자의 보행 이상탐지, 더 나아가 근골격계 질환을 보다 효율적이고 정확하게 판단하기 위해서 상기 보행영상 획득단계 (S500)는 피검사자의 정면 또는 후면이 촬영된 영상이 아닌, 우측면 또는 좌측면이 촬영된 영상이 획득되는 것 이 가장 바람직하다. 이때, 본 발명의 상기 인공지능 모델을 이용한 보행 이상탐지 방법은 상기 적어도 하나의 프로세서에 의하 여, 이상탐지 정확도를 향상시킬 수 있도록 상기 보행영상이 전처리되는 보행영상 전처리단계(S600)를 더 포함 할 수 있다. 즉, 상기 보행영상 전처리단계(S600)는 상기 보행영상 관절 포인트 추출단계(S700)로부터 발생될 수 있는 인식 오류를 최소화하기 위함이다. 도 3의 (a)와 같은 영상의 프레임으로부터 피검사자의 신체 중 일부가 벗어난 프 레임 불균형 문제, 도 3의 (b)와 같은 피검사자 신체보다 큰 사이즈의 옷을 착용함으로써 피검사자의 신체형상 이 정확하게 파악되지 못하는 옷 문제, 도 3의 (c)와 같은 촬영환경에 따라 피검사자 외 다양한 집기 등이 촬영 되어 피검시자가 정확하게 파악되지 못하는 배경 문제가 발생할 수 있다. 특히나, 본 발명은 프레임 불균형 문 제 및 배경 문제를 정보 처리 방식을 통해서 해결하고자 한다. 한편, 배경 문제를 해결하기 위해서 도 9의 일실시예를 보면, 상기 보행영상 전처리 단계(S600)는 보행영상 프 레임 추출단계(S610), 피검사자 탐지단계(S620), 피검사자 이진화 단계(S630), 피검사자 면적 연산단계(S640) 및 보행영상 배경 처리단계(S650)를 포함하는 것을 특징으로 한다. 우선, 보행영상 프레임 추출단계(S610)는 상기 보행영상으로부터 다수 개의 프레임이 추출될 수 있다. 상기 보 행영상은 1개의 프레임으로 형성된 이미지형식이 아닌, 다수 개의 프레임으로 형성된 영상형식이다. 즉, 프레임 별로 피검사자의 모습이 상이하기 때문에, 상기 보행영상 프레임 추출단계(S610)는 이를 파악하고자 상기 학습 영상이 다수 개의 프레임으로 분리 및 추출되는 것이다. 다음으로, 상기 피검시자 탐지단계(S620)는 시맨틱 분할(Semantic Segmentation) 기법이 이용되어 각 프레임에 서 피검사자가 탐지될 수 있다. 상기 시맨틱 분할(Semantic Segmentation) 기법은 상기 보행영상의 각 프레임을 다수 개의 픽셀 집합으로 나누어, 객체와 객체 사이의 경계를 찾는 기법이다. 상기 피검사자 탐지단계(S620)는 가장 바람직하게 ResNet-101이 Backbone으로 사용된 DeeplabV3 모델을 기반으로 시맨틱 분할 기법이 이용되어 객체와 객체 외 배경이 구분될 수 있다. 즉, 상기 피검사자 탐지단계(S620)는 객체와 객체 외 배경을 구분하는 과정이다. 다음으로, 상기 피검사자 이진화 단계(S630)는 탐지된 보행자가 이진화될 수 있다. 상기 보행영상 내 사물이 없고 온전히 보행자만 있다면, 시맨틱 분할 기법만으로도 충분히 보행자가 탐지될 수 있다. 그러나 촬영환경으 로 인해 상기 보행영상 내 사물이 있다면, 상기 피검사자 탐지단계(S620)로부터 시맨틱 분할 기법이 이용되어 구분된 객체에 피검사자와 피검사자가 아닌 사물이 포함될 수 있다. 따라서 상기 피검사자 이진화 단계(S630)는 객체 중에서 피검사자와 피검사자 외 사물을 구분하기 위함이다. 본 발명의 일실시예에 따르면, 상기 피검시자 이진화 단계(S630)는 상기 객체 중 피검사자만이 흰색으로 이진화될 수 있다. 다음으로, 상기 피검사자 면적 연산단계(S640)는 윤곽선 검출 기법이 이용되어 피검사자가 포함된 윤곽선 영 역이 지정되고, 프레임별 윤곽선 영역에 대한 면적이 연산될 수 있다. 상술한 바와 같이 프레임별로 피검사자의 동작이 상이함으로 피검사자의 영역이 프레임별로 상이할 수 있다. 상기 피검사자 면적 연산단계(S640)는 상기 피검사자 이진화 단계(S630)로부터 이진화된 영역을 대상으로 윤곽선 검출 기법이 이용되어 윤곽선 영역이 하나 의 선으로 지정될 수 있다. 그리고 상기 피검사자 면적 연산단계(S640)는 각 프레임에 대한 상기 윤곽선 영역을 대상으로 면적이 연산될 수 있다. 다음으로, 상기 보행영상 배경 처리단계(S650)는 각 프레임에서 최대 윤곽선 영역을 제외한 나머지 부분인 배경 이 단색으로 처리될 수 있다. 그러면 상기 보행영상 관절 포인트 추출단계(S700)는 상기 최대 윤곽선 영역을 객 체로 인식하는 것을 특징으로 한다. 윤곽선 영역은 프레임별로 존재하고, 각 윤곽선 영역은 서로 다른 면적을 가지고 있다. 상기 보행영상 배경 처리단계(S650)는 그 중 최대 윤곽선 영역을 대상으로 한다. 이는, 보행자의 신체가 상기 윤곽선 영역 내 모두 포함될 수 있도록 영역에 마진(Margin)을 두기 위함이다. 도 4의 (a)를 보면, 임의의 프레임은 전처리 전 배경으로 인해서 객체 인식 오류가 발생한 것을 확인할 수 있다. 도 4의 (b)를 보면, 임의의 프레임은 전처리 후 피검사자와 피검사자 외 배경이 정확하게 구분될 수 있고, 배경이 검은색으로 이진화될 수 있다. 이에 따라, 상기 보행영상 관절 포인트 추출단계(S700)로부터 배경 으로 인한 객체 인식 오류가 발생하지 않는 것을 확인할 수 있다. 다음으로, 상기 보행영상 관절 포인트 추출단계(S700)는 상기 적어도 하나의 프로세서에 의하여, 상기 보 행영상으로부터 다수 개의 관절 포인트가 추출된다. 상기 보행영상 관절 포인트 추출단계(S700)는 가장 바람직하게, Google에서 개발된 MediaPipe 시스템이 이용되 어 전처리된 각 보행영상 내 프레임별 다수 개의 관절 포인트가 각각 추출될 수 있다. MediaPipe 시스템에 따르 면, 종래 OpenPose 시스템 보다 더 많은 관절 포인트를 추출할 수 있는 현저한 효과가 있다. 도 5의 일실시예를 보면, 상기 다수 개의 관절 포인트는, 피검사자의 오른 무릎의 각도, 왼 무릎의 각도, 오른 엉덩이의 각도, 왼 엉덩이의 각도 및 코-어깨의 각도(12-0-11) 중 적어도 하나를 포함하는 것을 특징으로 한다. 다음으로, 보행 이상탐지단계(S800)는 상기 적어도 하나의 프로세서에 의하여, 상기 모델 학습단계(S400) 로부터 생성된 인공지능 모델에 상기 보행영상의 다수 개의 관절 포인트가 입력됨으로써, 피검사자의 보행 이상 여부가 출력된다. 도 6 내지 도 7의 일실시예를 보면, 본 발명에서 언급하는 인공지능 모델은 시계열 데이터 처리가 가능한 장단 기 메모리(Long Short-Term Memory; LSTM)와 비지도 학습이 가능한 오토인코더(Autoencoder)가 결합된 LSTM- Autoencoder 모델인 것을 특징으로 한다. 일반적으로, 장단기 메모리(LSTM)는 순환적인 구조를 가지는 순환 신경망 네트워크(RNN) 모델의 단점인 학습이 지속될수록 발생하는 기울기 소멸 문제(Vanishing Gradient)를 극복하기 위해 만들어진 딥러닝 신경망 알고리즘 모델이다. 순환 신경망 네트워크(RNN) 모델에 비해 비교적 긴 시간의 정보를 기억하여 시계열 데이터 처리가 용 이하다는 장점이 있다. 본 발명의 보행영상 역시 시간에 대한 다수 개의 프레임을 구비함으로, 시계열 데이터 중 하나이다. 도 6의 일실시예를 보면, 상기 인공지능 모델은 다수 개의 LSTM을 포함함으로써, 시계열 데이터인 보행영상의 길이가 길더라도 기울기 소멸 문제(Vanishing Gradient)를 최소화하여 용이하게 처리할 수 있는 현 저한 효과가 있다. 또한, 오토인코더(Autoencoder)는 입력과 출력을 동일한 층으로 쌓고 정답값이 없는 상태에서 스스로 학습을 하 는 비지도 학습이 가능한 모델이다. 도 6 내지 도 7의 일실시예를 보면, 상기 오토인코더(Autoencoder)는 입력 과 출력이 동일한 인코딩(Encoding) LSTM 층과 디코딩(Decoding) LSTM 층을 포함할 수 있다. 보행 이상여부에 있어서, 상기 보행 이상탐지단계(S800)는, 상기 보행영상의 다수 개의 관절 포인트에 대한 관 절 포인트별 손실값과 상기 임계값 설정단계(S420)로부터 설정된 관절 포인트별 임계값과 비교되고, 관절 포인 트별 손실값이 임계값보다 큰 경우가 하나라도 존재하는 경우 피검사자의 보행이 이상한 것으로 판단되고, 관절포인트별 손실값이 임계값보다 모두 작은 경우 피검사자의 보행이 정상인 것으로 판단되는 것을 특징으로 한다. 따라서 본 발명에 의하면, 신체에 어떠한 마커(Maker)도 부착되지 않은 일반적인 상황에서도 피검사자의 보행 이상여부를 탐지할 수 있고, 더 나아가 근골격계 질환 및 질환의 중증도 등을 객관적으로 정확하게 판단하는데 보조적인 역할을 할 수 있는 효과가 있다. 한편, 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법은 상기 적어도 하나의 프로세서에 의하여, 보행영상의 각 프레임에 피검사자의 전신이 포함될 수 있도록 피검사자 단말에 보행영상의 촬영 가이드가 제공되는 촬영 가이드 제공단계(S900)를 더 포함하는 것을 특징으로 한다. 프레임 불균형 문제를 해결하기 위해서, 상기 촬영 가이드 제공단계(S900)는 경계박스 도출단계(S910), 좌표값 도출단계(S920), 프레임 평균값 연산단계(S930), 학습영상 평균값 연산단계(S940) 및 조건경계박스 선택단계 (S950)를 포함할 수 있다. 본 발명에서 언급하는 프레임 불균형은 목, 다리 등 보행자의 일부 신체 부위가 프레임(F)을 벗어나는 경우를 말한다. 도 10의 (a)를 보면, 목 위에 신체부위가 프레임(F) 밖으로 벗어남으로써, 경계박스(B) 역시 프레임(F) 밖으로 벗어난 것을 확인할 수 있다. 도 10의 (b)를 보면, 역시나, 팔 또는 다리가 프레임(F) 밖으로 벗어남으 로써, 경계박스(B) 역시 프레임(F) 밖으로 벗어난 것을 확인할 수 있다. 이때, 상기 학습 데이터셋 획득단계(S100)는 촬영 가이드를 제공할 수 있도록 각 프레임에 보행자의 전신이 포 함된 다수 개의 학습영상이 획득될 수 있다. 상기 학습 데이터셋 획득단계(S100)는 보행자의 신체 일부가 벗어 난 프레임을 포함하는 학습영상이 아닌, 각 프레임에 보행자의 전신이 포함된 학습영상이 획득되는 것이 가장 바람직하다. 이는, 향후 촬영장치를 통해서 보행영상을 촬영할 임의의 피검사자에게 촬영 가이드를 제공하기 위 함이다. 다음으로, 상기 경계박스 도출단계(S910)는 YOLO 알고리즘이 이용되어 다수 개의 학습영상 내 각 프레임마다 보행자 중심의 경계박스가 도출될 수 있다. 본 발명에서 언급하는 YOLO(You Only Look Once) 알고리즘은 각 프 레임을 다수 개의 조각으로 분할해서 해석하지 않고 하나의 프레임을 전체적으로 한 번에 처리할 수 있어 신속 한 객체 분류가 가능한 효과가 있다. 상기 경계박스 도출단계(S910)는 YOLO 알고리즘이 이용되어 분류된 보행자 를 중심으로 경계박스가 도출될 수 있다. 상기 경계박스(B)는 도 11의 (a)와 같다. 다음으로, 상기 좌표값 도출단계(S920)는 프레임(F)별 경계박스(B)에서 대각선으로 마주보는 제1 꼭지점(P1)과 제2 꼭지점(P2)에 대한 좌표값이 각각 도출될 수 있다. 도 11의 (b)의 일실시예를 보면, 상기 제1 꼭지점(P1)은 좌측 상단의 꼭지점인 (x,y)일 수 있고, 상기 제2 꼭지점(P2)은 우측 하단의 꼭지점인 (x+w, y+h)일 수 있다. 즉, 상기 좌표값 도출단계(S920)는 4개의 꼭지점이 모두 연산되지 않고 2개의 꼭지점(P1, P2)만이 연산됨으로써, w*h 크기의 경계박스(B)가 확인될 수 있어 연산량을 줄이고 연산속도를 높일 수 있는 현저한 효 과가 있다. 다음으로, 상기 프레임 평균값 연산단계(S930)는 프레임별 경계박스(B)의 제1 꼭지점(P1)을 평균한 제1 프레임 평균값(AVGF1)과 제2 꼭지점(P2)을 평균한 제2 프레임 평균값(AVGF2)이 연산될 수 있다. 예컨대, 임의의 학습영 상은 프레임 F1 내지 F5로 이루어져 있을 수 있다. 그러면, 제1 프레임 평균값(AVGF1)은 프레임 F1의 제1 꼭지 점(P1_1), 프레임 F2의 제1 꼭지점(P1_2), 프레임 F3의 제1 꼭지점(P1_3), 프레임 F4의 제1 꼭지점(P1_4), 프 레임 F5의 제1 꼭지점(P1_5)을 평균한 값이다. 그리고 제2 프레임 평균값(AVGF2)은 프레임 F1의 제2 꼭지점 (P2_1), 프레임 F2의 제2 꼭지점(P2_2), 프레임 F3의 제2 꼭지점(P2_3), 프레임 F4의 제2 꼭지점(P2_4), 프레 임 F5의 제2 꼭지점(P2_5)을 평균한 값이다. 만약, 20개의 학습영상이 있다면, 각 학습영상에 대한 연산이 상술 한 바와 같이 반복될 수 있다. 다음으로, 상기 학습영상 평균값 연산단계(S940)는 학습영상별 제1 프레임 평균값(AVGF1)을 평균한 제1 학습영 상 평균값(AVGV1)과 제2 프레임 평균값(AVGF2)을 평균한 제2 학습영상 평균값(AVGV2)이 연산될 수 있다. 예컨대, 상기 학습영상 V1 내지 V20이 있다면, 상기 제1 학습영상 평균값(AVGV1)은 학습영상 V1에 대한 제1 프 레임 평균값(AVGF1_1) 내지 학습영상 V20에 대한 제1 프레임 평균값(AVGF1_20)을 평균한 값이다. 그리고 상기 제2 학습영상 평균값(AVGV2)은 학습영상 V1에 대한 제2 프레임 평균값(AVGF2_1) 내지 학습영상 V20에 대한 제2 프레임 평균값(AVGF2_20)을 평균한 값이다. 즉, 상기 프레임 평균값 연산단계(S930) 및 상기 학습영상 평균값 연산단계(S940)로부터 촬영 가이드를 제공하기 위해서 획득된 학습영상에 대하여 평균한 경계박스(B)의 크기가 연산될 수 있다. 이때, 상기 촬영 가이드 제공단계(S900)는, 상기 제1 학습영상 평균값(AVGV1)과 상기 제2 학습영상 평균값 (AVGV2)으로 형성된 경계박스가 이상적인(Ideal) 촬영 가이드(G_Ideal)로 제공되는 것을 특징으로 한다. 도 12 의 (a)는 상기 이상적인(Ideal) 촬영 가이드(G_Ideal)이고, 해당 가이드 내 보행자가 촬영되는 것이 가장 바람 직하다. 또한, 상기 촬영 가이드 제공단계(S900)는, 다수 개의 경계박스(B) 중 기 설정된 조건에 만족하는 조건경계박 스가 선택되는 조건경계박스 선택단계(S950)를 더 포함하고, 상기 조건경계박스의 제1 꼭지점과 제2 꼭지점 중 에서 최소값을 갖는 제1 꼭지점과 최대값을 갖는 제2 꼭지점으로 형성된 조건경계박스가 최대(Maximum) 촬영 가 이드(G_Maximum)로 제공되는 것을 특징으로 한다. 본 발명에서 언급하는 기 설정된 조건은 3가지가 있다. 제1 조건은 임의의 경계박스(B)의 제1 꼭지점 (x,y)의 x 좌표값이 제1 학습영상 평균값(AVGV1)의 x 좌표값 보다 작은 경우이다. 제2 조건은 임의의 경계박스(B)의 제2 꼭지점 (x+w, y+h)의 x+w 좌표값이 제2 학습영상 평균값(AVGV2)의 x 좌표값 보다 큰 경우이다. 제3 조건은 임의 의 경계박스(B)의 제2 꼭지점(x+w, y+h)의 y+h 좌표값이 제2 학습영상 평균값(AVGV2)의 y 좌표값 보다 큰 경우 이다. 상술한 3가지 조건은 다수 개의 경계박스(B) 중에서 촬영 가이드를 제공하기 위해서 획득된 학습영상에 대해서 평균한 경계박스(B)보다 크기가 큰 경계박스를 선택하기 위한 조건이다. 상술한 3가지 조건을 통해서 선택된 상기 조건경계박스의 제1 꼭지점(P1)과 제2 꼭지점(P2) 중에서 최소값을 갖 는 제1 꼭지점(P1)과 최대값을 갖는 제2 꼭지점(P2)으로 형성된 조건경계박스가 최대(Maximum) 촬영 가이드 (G_Maximum)로 제공되는 것을 특징으로 한다. 상기 최대(Maximum) 촬영 가이드(G_Maximum)는 프레임 내에서 촬 영을 허용할 수 있는 영역이다. 도 12의 (b)는 상기 최대(Maximum) 촬영 가이드(G_Maximum)이고, 해당 가이드 내 보행자가 촬영되는 것이 가장 바람직하다. 따라서 상기 보행영상은 일반적인 촬영장치가 이용되어 이상적인(Ideal) 촬영 가이드(G_Ideal) 내 피검사자가 위치되어 촬영되는 것이 가장 바람직하고, 그렇지 못한 경우 최대(Maximum) 촬영 가이드(G_Maximum) 내 피검사 자가 위치되어 촬영되는 것이 허용될 수 있다. 따라서 본 발명에 의하면 피검사자 단말에 촬영 가이드가 제공됨으로써, 객체 인식 오류가 발생하지 않도록 미연에 예방할 수 있는 효과가 있다. 실시예들은 하드웨어, 소프트웨어, 펌웨어, 미들웨어, 마이크로코드, 하드웨어 기술 언어, 또는 이들의 임의의 조합에 의해 구현될 수 있다. 소프트웨어, 펌웨어, 미들웨어 또는 마이크로코드로 구현되는 경우, 필요한 작업 을 수행하는 프로그램 코드 또는 코드 세그먼트들은 컴퓨터 판독 가능 저장 매체에 저장되고 하나 이상의 프로 세서에 의해 실행될 수 있다. 그리고 본 명세서에 설명된 주제의 양태들은 컴퓨터에 의해 실행되는 프로그램 모듈 또는 컴포넌트와 같은 컴퓨 터 실행 가능 명령어들의 일반적인 맥락에서 설명될 수 있다. 일반적으로, 프로그램 모듈 또는 컴포넌트들은 특 정 작업을 수행하거나 특정 데이터 형식을 구현하는 루틴, 프로그램, 객체, 데이터 구조를 포함한다. 본 명세서 에 설명된 주제의 양태들은 통신 네트워크를 통해 링크되는 원격 처리 디바이스들에 의해 작업들이 수행되는 분 산 컴퓨팅 환경들에서 실시될 수도 있다. 분산 컴퓨팅 환경에서, 프로그램 모듈들은 메모리 저장 디바이스들을 포함하는 로컬 및 원격 컴퓨터 저장 매체에 둘 다에 위치할 수 있다."}
{"patent_id": "10-2023-0037340", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 으로 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달 성될 수 있다. 그러므로 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2023-0037340", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 인공지능 모델 학습 방법 흐름도이다. 도 2는 본 발명의 일실시예에 따른 학습영상 전처리단계를 포함하는 인공지능 모델 학습 방법 흐름도이다. 도 3은 프레임 불균형(a), 옷(b), 배경(c)으로 인한 객체 인식 오류를 표시한 도면이다. 도 4는 배경으로 인한 객체 인식 오류가 발생한 프레임(a)과 본 발명의 일실시예에 따른 전처리단계로부터 배경 처리된 프레임(b)을 표시한 도면이다. 도 5는 본 발명의 일실시예에 따른 다수 개의 관절 포인트를 표시한 도면이다. 도 6은 본 발명의 일실시예에 따른 LSTM-Autoencoder 모델의 구조도이다. 도 7은 본 발명의 일실시예에 따른 LSTM-Autoencoder 모델 layer를 표시한 도면이다. 도 8은 본 발명의 인공지능 모델을 이용한 보행 이상탐지 방법 흐름도이다. 도 9는 본 발명의 일실시예에 따른 학습영상 전처리단계 및 보행영상 전처리단계를 포함하는 인공지능 모델을 이용한 보행 이상탐지 방법 흐름도이다. 도 10은 본 발명의 일실시예에 따른 보행자 및 피검사자의 목 위의 신체부위가 프레임 밖으로 벗어난 경우(a)와 보행자 및 피검사자가 오른쪽으로 걸어갈 때 팔 또는 다리가 프레임 밖으로 벗어난 경우(b)를 표시한 도면이다. 도 11은 본 발명의 일실시예에 따른 경계박스 도출단계로부터 경계박스가 표시된 프레임(a)과 좌표값 도출단계 로부터 도출된 제1 꼭지점과 제2 꼭지점에 대한 좌표값을 표시한 도면이다. 도 12는 본 발명의 일실시예에 따른 이상적인(Ideal) 촬영 가이드(a)와 최대(Maximum) 촬영 가이드(b)를 표시한 도면이다."}
