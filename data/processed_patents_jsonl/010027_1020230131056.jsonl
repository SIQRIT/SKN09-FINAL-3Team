{"patent_id": "10-2023-0131056", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0019537", "출원번호": "10-2023-0131056", "발명의 명칭": "미러 디스플레이를 통해 가상 오브젝트를 제공하는 디스플레이 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "장용석"}}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "미러(mirror) 디스플레이;상기 미러 디스플레이에 비친 오브젝트를 촬영 가능한 뎁스(depth) 카메라; 및상기 뎁스 카메라를 통해 상기 오브젝트를 포함하는 이미지를 획득하여 상기 오브젝트의 뎁스 정보를 획득하고,상기 오브젝트의 뎁스 정보에 기초하여 상기 오브젝트의 스켈레톤(skeleton) 정보를 획득하고,상기 획득된 스켈레톤 정보에 기초하여 상기 오브젝트의 형상 정보를 획득하고,상기 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하여 상기 가상 오브젝트를 상기 오브젝트에 정합시켜 상기 미러 디스플레이를 통해 제공하는 하나 이상의 프로세서;를 포함하는 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 오브젝트의 스켈레톤 정보는,상기 오브젝트에 포함된 복수의 부위 별 스켈레톤을 포함하며,상기 하나 이상의 프로세서는,상기 복수의 부위 별 스켈레톤을 기준으로 대칭 구조에 따른 상기 복수의 부위 각각의 형상을 식별하고,상기 복수의 부위 각각의 형상을 포함하는 상기 오브젝트의 상기 형상 정보를 획득하는, 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 하나 이상의 프로세서는,상기 이미지를 신경망 모델에 입력하여 상기 이미지에 포함된 상기 오브젝트의 형상 정보를 획득하며,상기 신경망 모델은,상기 오브젝트를 포함하는 상기 이미지가 입력되면, 상기 오브젝트의 뎁스 정보로부터 상기 오브젝트에 대한 복수의 시점(view point) 각각에 대응되는 뎁스 정보를 포함하는 상기 오브젝트의 형상 정보를 출력하도록 학습된모델인, 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 하나 이상의 프로세서는,상기 오브젝트의 형상 정보 및 상기 가상 오브젝트의 형상 정보에 기초하여 상기 가상 오브젝트의 일부를 상기오브젝트의 전면에 위치시키고, 상기 가상 오브젝트의 나머지를 상기 오브젝트의 후면에 위치시켜 상기 가상 오브젝트를 디스플레이하는, 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 하나 이상의 프로세서는,상기 오브젝트의 형상 정보 및 상기 가상 오브젝트의 형상 정보에 기초하여 상기 미러 디스플레이 상에서 상기공개특허 10-2025-0019537-3-가상 오브젝트의 일부가 상기 오브젝트에 접촉되도록 상기 가상 오브젝트를 디스플레이하는, 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,통신 인터페이스;를 더 포함하며,상기 하나 이상의 프로세서는,상기 오브젝트가 착용한 웨어러블 디바이스(wearable device)와 통신하도록 상기 통신 인터페이스를 제어하며,상기 미러 디스플레이 상에서 상기 가상 오브젝트의 일부와 상기 오브젝트 간의 접촉이 식별되면, 상기 오브젝트 상에서 상기 가상 오브젝트의 일부가 접촉된 영역에 촉각 피드백을 제공하도록 상기 웨어러블 디바이스를 제어하는, 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,통신 인터페이스;를 더 포함하며,상기 하나 이상의 프로세서는,상기 통신 인터페이스를 통해 외부 장치로부터 상기 가상 오브젝트의 형상 정보를 수신하며,상기 외부 장치로 상기 오브젝트의 형상 정보를 전송하도록 상기 통신 인터페이스를 제어하는, 디스플레이장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 하나 이상의 프로세서는,상기 가상 오브젝트에 대한 사용자의 입력이 식별되면, 상기 입력에 기초하여 상기 가상 오브젝트와 인터렉션(interaction)을 수행하고, 상기 사용자의 입력에 따른 상기 오브젝트의 변경된 형상 정보를 상기 외부 장치로 전송하며,상기 사용자의 입력은,상기 가상 오브젝트의 일부에 대한 터치 입력을 포함하는, 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 하나 이상의 프로세서는,상기 오브젝트에 대한 타 사용자의 입력에 따라 상기 외부 장치로부터 상기 가상 오브젝트의 변경된 형상 정보가 수신되면, 상기 변경된 형상 정보에 따라 상기 가상 오브젝트를 상기 오브젝트에 재정합시키며,상기 가상 오브젝트는, 상기 외부 장치에 구비된 미러 디스플레이에 비친 상기 타 사용자에 대응되며,상기 오브젝트는, 상기 사용자에 대응되는, 디스플레이 장치."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 하나 이상의 프로세서는,사용자의 입력에 기초하여 상기 미러 디스플레이 상에서 상기 가상 오브젝트의 위치, 시점, 크기 또는 비율 중적어도 하나를 조정하는, 디스플레이 장치.공개특허 10-2025-0019537-4-청구항 11 미러 디스플레이를 포함하는 디스플레이 장치의 제어 방법에 있어서,상기 미러 디스플레이에 비친 오브젝트를 촬영한 이미지를 획득하여 상기 오브젝트의 뎁스 정보를 획득하는 단계;상기 오브젝트의 뎁스 정보에 기초하여 상기 오브젝트의 스켈레톤 정보를 획득하는 단계;상기 획득된 스켈레톤 정보에 기초하여 상기 오브젝트의 형상 정보를 획득하는 단계; 및상기 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하여 상기 가상 오브젝트를 상기 오브젝트에 정합시켜 상기 미러 디스플레이를 통해 제공하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 오브젝트의 스켈레톤 정보는,상기 오브젝트에 포함된 복수의 부위 별 스켈레톤을 포함하며,상기 형상 정보를 획득하는 단계는,상기 복수의 부위 별 스켈레톤을 기준으로 대칭 구조에 따른 상기 복수의 부위 각각의 형상을 식별하는 단계;및상기 복수의 부위 각각의 형상을 포함하는 상기 오브젝트의 상기 형상 정보를 획득하는 단계;를 포함하는, 제어방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 형상 정보를 획득하는 단계는,상기 이미지를 신경망 모델에 입력하여 상기 이미지에 포함된 상기 오브젝트의 형상 정보를 획득하는 단계;를포함하며,상기 신경망 모델은,상기 오브젝트를 포함하는 상기 이미지가 입력되면, 상기 오브젝트의 뎁스 정보로부터 상기 오브젝트에 대한 복수의 시점(view point) 각각에 대응되는 뎁스 정보를 포함하는 상기 오브젝트의 형상 정보를 출력하도록 학습된모델인, 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 제공하는 단계는,상기 오브젝트의 형상 정보 및 상기 가상 오브젝트의 형상 정보에 기초하여 상기 가상 오브젝트의 일부를 상기오브젝트의 전면에 위치시키고, 상기 가상 오브젝트의 나머지를 상기 오브젝트의 후면에 위치시켜 상기 가상 오브젝트를 디스플레이하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 제공하는 단계는,상기 오브젝트의 형상 정보 및 상기 가상 오브젝트의 형상 정보에 기초하여 상기 미러 디스플레이 상에서 상기가상 오브젝트의 일부가 상기 오브젝트에 접촉되도록 상기 가상 오브젝트를 디스플레이하는 단계;를 포함하는,제어 방법.공개특허 10-2025-0019537-5-청구항 16 제15항에 있어서,상기 제어 방법은,상기 미러 디스플레이 상에서 상기 가상 오브젝트의 일부와 상기 오브젝트 간의 접촉이 식별되면, 상기 오브젝트 상에서 상기 가상 오브젝트의 일부가 접촉된 영역에 촉각 피드백을 제공하도록 오브젝트가 착용한 웨어러블디바이스(wearable device)를 제어하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 제어 방법은,외부 장치로부터 상기 가상 오브젝트의 형상 정보를 수신하는 단계; 및상기 외부 장치로 상기 오브젝트의 형상 정보를 전송하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 제어 방법은,상기 가상 오브젝트에 대한 사용자의 입력이 식별되면, 상기 입력에 기초하여 상기 가상 오브젝트와 인터렉션(interaction)을 수행하는 단계;를 더 포함하며,상기 전송하는 단계는,상기 사용자의 입력에 따른 상기 오브젝트의 변경된 형상 정보를 상기 외부 장치로 전송하는 단계;를 포함하고,상기 사용자의 입력은,상기 가상 오브젝트의 일부에 대한 터치 입력을 포함하는, 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 제공하는 단계는,상기 오브젝트에 대한 타 사용자의 입력에 따라 상기 외부 장치로부터 상기 가상 오브젝트의 변경된 형상 정보가 수신되면, 상기 변경된 형상 정보에 따라 상기 가상 오브젝트를 상기 오브젝트에 재정합시키는 단계;를 포함하며,상기 가상 오브젝트는, 상기 외부 장치에 구비된 미러 디스플레이에 비친 상기 타 사용자에 대응되며,상기 오브젝트는, 상기 사용자에 대응되는, 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 제어 방법은,사용자의 입력에 기초하여 상기 미러 디스플레이 상에서 상기 가상 오브젝트의 위치, 시점, 크기 또는 비율 중적어도 하나를 조정하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0131056", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디스플레이 장치가 개시된다. 디스플레이 장치는 미러(mirror) 디스플레이, 미러 디스플레이에 비친 오브젝트를 촬영 가능한 뎁스(depth) 카메라, 뎁스 카메라를 통해 오브젝트를 포함하는 이미지를 획득하여 오브젝트의 뎁스 정보를 획득하고, 오브젝트의 뎁스 정보에 기초하여 오브젝트의 스켈레톤(skeleton) 정보를 획득하고, 획득된 스 켈레톤 정보에 기초하여 오브젝트의 형상 정보를 획득하고, 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보 에 기초하여 가상 오브젝트를 오브젝트에 정합시켜 미러 디스플레이를 통해 제공하는 하나 이상의 프로세서를 포 함한다."}
{"patent_id": "10-2023-0131056", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디스플레이 장치 및 그 제어 방법에 관한 것으로, 더욱 상세하게는, 미러 디스플레이를 통해 가상 오 브젝트를 제공하는 디스플레이 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2023-0131056", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술의 발달에 힘입어 다양한 종류의 전자 장치가 개발되어 보급되고 있다. 특히, 최근에는 TV를 비롯한 다양한 유형의 전자 장치들이 일반 가정에서 사용되고 있다. 이들 전자 장치들은 사용자의 요구에 따라 점차 다 양한 기능을 구비하게 되었다. 일 예로, 미러 기능 및 디스플레이 기능을 모두 제공하는 미러 디스플레이를 통해 다양한 종류의 서비스를 제공 받을 수 있게 되었다. 예를 들어, 미러 디스플레이는 사용자를 비추면서 동시에, 사용자가 상호 작용 가능한 가 상의 오브젝트를 디스플레이할 수 있다. 다만, 종래의 미러 디스플레이는 사용자의 형상을 고려하여 가상의 오브젝트를 사실적으로(Realistic) 디스플레 이하지는 못하였다. 예를 들어, 가상의 오브젝트가 사용자에 대응되는 거울 상과 중첩되거나, 관통하는 등, 가 상의 오브젝트가 사용자와 동일한 공간에 위치하여 미러 디스플레이에 비친 상처럼 느껴지는 효과를 사용자에게 제공하기에는 한계가 있었다. 미러 디스플레이에 비친 사용자에 대응되는 거울 상을 3D로 식별하고 가상 오브젝트가 미러 디스플레이 비친 상 처럼 느껴지는 효과를 제공하는 방법에 대한 요구가 있었다."}
{"patent_id": "10-2023-0131056", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 디스플레이 장치는, 미러(mirror) 디스플레이, 상기 미러 디스플레이에 비친 오브젝트를 촬영 가능한 뎁스(depth) 카메라, 및 상기 뎁스 카메라를 통해 상기 오브젝트를 포함하는 이미지를 획득하여 상기 오브젝트의 뎁스 정보를 획득하고, 상기 오브젝트의 뎁스 정보에 기초하여 상기 오브젝트의 스켈레톤(skeleton) 정보를 획득하고, 상기 획득된 스켈레톤 정보에 기초하여 상기 오브젝트의 형상 정보를 획득하고, 상기 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하여 상기 가상 오브젝트를 상기 오브젝트에 정합시켜 상기 미러 디스플레이를 통해 제공하는 하나 이상의 프로세서를 포 함한다. 본 개시의 일 실시 예에 따른 미러 디스플레이를 포함하는 디스플레이 장치의 제어 방법은, 상기 미러 디스플레 이에 비친 오브젝트를 촬영한 이미지를 획득하여 상기 오브젝트의 뎁스 정보를 획득하는 단계, 상기 오브젝트의 뎁스 정보에 기초하여 상기 오브젝트의 스켈레톤 정보를 획득하는 단계, 상기 획득된 스켈레톤 정보에 기초하여 상기 오브젝트의 형상 정보를 획득하는 단계 및 상기 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기 초하여 상기 가상 오브젝트를 상기 오브젝트에 정합시켜 상기 미러 디스플레이를 통해 제공하는 단계를 포함한 다. 본 개시의 상술한 목적을 달성하기 위한 일 실시 예에 따르면 미러 디스플레이를 포함하는 디스플레이 장치의 제어 방법을 실행하는 프로그램을 포함하는 컴퓨터 판독 가능 기록매체에 있어서, 디스플레이 장치의 제어 방법 은, 상기 미러 디스플레이에 비친 오브젝트를 촬영한 이미지를 획득하여 상기 오브젝트의 뎁스 정보를 획득하는 단계, 상기 오브젝트의 뎁스 정보에 기초하여 상기 오브젝트의 스켈레톤 정보를 획득하는 단계, 상기 획득된 스 켈레톤 정보에 기초하여 상기 오브젝트의 형상 정보를 획득하는 단계 및 상기 오브젝트의 형상 정보와 가상 오 브젝트의 형상 정보에 기초하여 상기 가상 오브젝트를 상기 오브젝트에 정합시켜 상기 미러 디스플레이를 통해 제공하는 단계를 포함한다."}
{"patent_id": "10-2023-0131056", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 미러 디스플레이의 특성을 나타내는 도면이다. 본 개시의 일 실시 예에 따른 디스플레이 장치는 거울이 필요한 다양한 장소에 설치되어 거울 기능을 제공 하면서 정보를 전달할 수 있는 다양한 유형의 미러 디스플레이 장치로 구현될 수 있다. 여기서, 미러 디스플레 이(Mirror Display)'는 거울을 의미하는 '미러(Mirror)'와 정보를 시각적으로 표현하는 작업을 의미하는 '디스플레이(Display)'의 합성어이다. 도 1에 도시된 바와 같이 디스플레이 장치는 미러 디스플레이를 포함하며, 미러 디스플레이는 스위처블 미러(Switchable mirror), 디스플레이 패널를 포함할 수 있다. 예를 들어, 영상을 디스플레이하는 디스플레이 패널, 디스플레이 패널의 전면에 배치되어 반사율을 조정 가능한 스위처블 미러를 포함할 수 있다. 일 예에 따라 스위처블 미러는 입사(入射) 광량의 일부를 반사하고, 다른 일부를 투과하는 금속 박막 또는 유전체 다층막을 증착한 유리판 혹은 투명 플라스틱판으로 구현되어 미러(mirror) 기능을 제공할 수 있다. 일 예에 따라 디스플레이 패널는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함할 수 있다. 예를 들어, 디스플레이 레이어는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형 태의 디스플레이로 구현될 수 있다. 본 개시에서는 설명의 편의를 위해 도 1에 도시된 바와 같이 사용자의 위치를 디스플레이 장치의 전면 으로 정의하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 디스플레이 장치의 구성을 나타내는 블록도이다. 도 2에 따르면 디스플레이 장치는 미러 디스플레이, 뎁스(Depth) 카메라, 메모리 및 하나 이상의 프로세서를 포함한다. 미러 디스플레이는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함하는 디스 플레이로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디 스플레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형태의 디스플레이 로 구현될 수 있다. 미러 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같 은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 일 예에 따라 미러 디스플레이 의 전면에는 터치 필름, 터치 시트, 터치 패드 등의 형태를 가지고 터치(touch) 동작을 감지하는 터치 센 서가 배치되어 다양한 유형의 터치 입력을 감지할 수 있도록 구현될 수 있다. 예를 들어, 미러 디스플레이(11 0)는 사용자 손에 의한 터치 입력, 스타일러스 펜과 같은 입력 장치에 의한 터치 입력, 특정 정전 물질에 의한 터치 입력 등 다양한 유형의 터치 입력을 감지할 수 있다. 여기서, 입력 장치는 전자 펜, 스타일러스 펜, S-펜 등 다양한 용어로 지칭될 수 있는 펜 형의 입력 장치로 구현될 수 있다. 일 예에 따라 미러 디스플레이는 평면(flat) 디스플레이, 커브드(curved) 디스플레이, 폴딩(folding) 또는/및 롤링(rolling) 가능한 플렉서블 디 스플레이 등으로 구현될 수 있다. 한편, 미러 디스플레이는 미러 기능 및 디스플레이 기능을 제공하는 디스플레이로 구현될 수 있다. 예를 들어, 미러 디스플레이는 기존의 일반적인 디스플레이 패널에 하프 미러(또는 미러 필름)가 추가된 형태로 구현될 수 있다. 도 3a 및 도 3b에 도시된 디스플레이는 미러 디스플레이의 일 구현 예시인 하프 미러를 포함하는 LCD를 도시한 것으로, 액정 디스플레이라고도 불리우는 LCD는 백라이트에서 빛을 만들면 그 빛이 액정의 분자들 사이로 투과되면서 원하는 영상을 얻는 원리로 작동하게 된다. 도 3 및 도 4는 본 개시의 일 예에 따른 스위처블 미러의 동작을 설명하기 위한 도면이다. 본 개시의 일 예에 따른 스위처블 미러는 편광판(polarizer), 상부 글래스, 하부 글래스, 반사 편광판 (reflective polarizer)을 포함하는 형태로 구현될 수 있다. 일 예에 따라 상부 글래스 및 하부 글래스 사이에서 LC(liquid crystal) 레이어가 형성될 수 있다. LC(liquid crystal)는 액체와 결정의 중간 상태에 있어 막대 모양 분자(액정 분자)가 고체 결정과 유사하게 한 방향으로 정렬된 구조를 가질 수 있다. 일 예에 따라 편광판(polarizer)은 편광된 빛을 투과시키도록 구현될 수 있다. 일 예에 따라 상부 글래스 및 하 부 글래스는 TCO(transparent Conductive Oxide) 글래스로 구현될 수 있으나 이에 한정되는 것은 아니다.도 3은 전압 OFF 시의 스위처블 미러를 도시한 것으로, 전압 OFF 시에 액정 분자는 수직 상태를 유지하고, 입사한 편광은 그대로 LC(liquid crystal) 레이어(111-3)를 투과하여 반사 편광판(reflective polarizer)(111- 5)의 반사축으로 반사될 수 있다. 이에 따라 스위처블 미러는 미러 상태로 유지될 수 있다. 예를 들어, 전기의 미인가 시에 입사한 편광이 반사 편광판의 반사축으로 반사되므로 스위처블 미러의 미 러 기능(이하, 미러(Mirror) 상태)이 제공 가능하며, 도 4에 도시된 바와 같이 전기의 인가 시에는 입사한 편광 이 90도 회전하여 반사 편광판(reflective polarizer)(111-5)의 반사축을 투과하므로 스위처블 미러의 투 명한 상태(이하, 클리어(clear) 상태)로 유지될 수 있다. 그 밖에 구현 예에 따라 편광판을 보호해 주는 역할을 하는 보호 필름, 편광판에서 빛을 분류하는 역할을 하는 필름 등을 더 포함할 수도 있다. 도 2로 돌아와서, 뎁스 카메라는 기 설정된 이벤트에 따라 턴 온 되어 촬영을 수행할 수 있다. 뎁스 카메 라는 ToF(Time of Flight) 카메라 센서를 포함할 수 있다. ToF 카메라 센서는, 신호(예를 들어, 근적외선, 초음파, 레이저 등)를 조사하고, 조사된 신호가 피사체에 의해 반사되어 ToF 카메라 센서가 수신하기까지의 시간을 측정하여 ToF 카메라 센서와 피사체 간의 거리(또는, 깊이 (Depth))를 측정하는 센서일 수 있다. 일 예에 따라 하나 이상의 프로세서는 ToF 카메라 센서와 피사체 간 의 거리에 기초하여 피사체의 뎁스 정보를 획득할 수 있다. ToF 카메라 센서는 일 예시이며, 이에 한정되지 않고 뎁스 카메라는 라이다(Lidar) 센서, 레이더(Radar) 센서, 초음파 센서, 적외선 센서 등을 포함할 수도 있음은 물론이다. 디스플레이 장치는 뎁스 카메라 외에도, 다양한 유형의 카메라를 포함할 수 있음은 물론이다. 일 예 에 따른 카메라는 촬상된 영상을 전기적인 신호로 변환하고 변환된 신호에 기초하여 영상 데이터를 생성할 수 있다. 예를 들어, 카메라는 피사체를 반도체 광학소자(CCD; Charge Coupled Device)를 통해 전기적인 영상 신호 로 변환하고, 변환된 영상 신호를 증폭 및 디지털 신호로 변환한 후 신호 처리할 수 있다. 예를 들어, 카메라는 일반(또는, 기본) 카메라, RGB 카메라 및 초광각 카메라 중 적어도 하나를 포함할 수 있다. 하나 이상의 프로세서는 디스플레이 장치의 동작을 전반적으로 제어한다. 구체적으로, 하나 이상의 프로세서는 디스플레이 장치의 각 구성과 연결되어 디스플레이 장치의 동작을 전반적으로 제어 할 수 있다. 예를 들어, 하나 이상의 프로세서는 미러 디스플레이 및 메모리와 전기적으로 연결되어 디스플 레이 장치의 전반적인 동작을 제어할 수 있다. 하나 이상의 프로세서는 뎁스 카메라를 통해 ToF 카메라 센서와 피사체 간의 거리를 식별하며, 식별된 거리에 기초하여 피사체의 뎁스 정보를 획득할 수 있다. 일 예에 따른 피사체는, 디스플레이 장치의 전면에 위치하는 사용자를 포함할 수 있다. 예를 들어, 디스플레이 장치는 미러 기능을 통해 디스플레이 장치의 전면에 위치하는 사물(또는, 사 용자)의 상을 비추며, 뎁스 카메라를 통해 사물을 피사체로 하여 영상을 획득할 수 있다. 일 예에 따른 영 상은, 뎁스 카메라와 피사체 간의 거리를 포함하며, 하나 이상의 프로세서는 영상에 기초하여 피사체 의 뎁스 정보를 획득할 수 있다. 이하에서는, 설명의 편의를 위해 피사체를 오브젝트(Object)로 통칭하도록 한 다. 메모리는 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따라 디스플레이 장치에 임베디드된 메모리 형태로 구현되거나, 디스플 레이 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 디스플레이 장치의 구동 을 위한 데이터의 경우 디스플레이 장치에 임베디드된 메모리에 저장되고, 디스플레이 장치의 확장 기능을 위한 데이터의 경우 디스플레이 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 디스플레 이 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 또 한, 디스플레이 장치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital),MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구 현될 수 있다. 일 예에 따라 메모리는 디스플레이 장치를 제어하기 위한 적어도 하나의 인스트럭션(instruction) 또 는 인스트럭션들을 포함하는 컴퓨터 프로그램을 저장할 수 있다. 일 예에 따라 메모리는 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB), 외부 서버(예 를 들어 웹 하드) 등으로부터 수신된 영상, 즉 입력 영상을 저장할 수 있다. 또는 메모리는 디스플레이 장 치에 구비된 뎁스 카메라를 통해 획득된 영상(또는, 뎁스 정보)을 저장할 수 있다. 여기서, 영상은 2D 동영상이 될 수 있으나 이에 한정되는 것은 아니다. 일 예에 따라, 메모리는 화질 처리에 필요한 다양한 정보, 예를 들어 Noise Reduction, Detail Enhancement, Tone Mapping, Contrast Enhancement, Color Enhancement 또는 Frame rate Conversion 중 적어 도 하나를 수행하기 위한 정보, 알고리즘, 화질 파라미터 등을 저장할 수 있다. 또한, 메모리는 영상 처리 에 의해 생성된 중간 영상, 깊이 정보를 기초로 생성된 영상을 저장할 수도 있다. 일 실시 예에 따르면, 메모리는 본 개시에 따른 다양한 동작들에서 생성되는 데이터를 저장하는 단일 메모 리로 구현될 수 있다. 다만, 다른 실시 예에 따르면, 메모리는 상이한 타입의 데이터를 각각 저장하거나, 상이한 단계에서 생성되는 데이터를 각각 저장하는 복수의 메모리를 포함하도록 구현될 수도 있다. 또한, 메모리는 디스플레이 장치를 구동/제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션 을 저장할 수 있다. 그 밖에, 메모리는 사용자 센싱 모듈, 통신 제어 모듈, 음성 인식 모듈, 모션 인식 모 듈, 광 수신 모듈, 디스플레이 제어 모듈, 오디오 제어 모듈, 외부 입력 제어 모듈, 전원 제어 모듈, 음성 데이 터베이스(DB), 또는 모션 데이터베이스(DB)을 포함할 수 있다. 상술한 실시 예에서는 다양한 데이터가 프로세서의 외부 메모리에 저장되는 것으로 설명하였으나, 상 술한 데이터 중 적어도 일부는 디스플레이 장치 또는 프로세서 중 적어도 하나의 구현 예에 따라 프 로세서 내부 메모리에 저장될 수도 있다. 하나 이상의 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 하나 이상의 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션(instruction)을 실행함으로써, 다양한 실시 예에 따른 디스플레이 장치의 동작을 수행할 수 있다. 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), NPU (Neural Processing Unit), 하드웨어 가속기 또는 머신 러닝 가속기 중 하나 이상을 포함할 수 있다. 하나 이상의 프로 세서는 전자 장치의 다른 구성요소 중 하나 또는 임의의 조합을 제어할 수 있으며, 통신에 관한 동작 또는 데이터 처리를 수행할 수 있다. 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 프로그램 또는 명령 어(instruction)을 실행할 수 있다. 예를 들어, 하나 이상의 프로세서는 메모리에 저장된 하나 이상의 명령어를 실행함으로써, 본 개시의 하나 이상의 실시 예에 따른 방법을 수행할 수 있다. 본 개시의 하나 이상의 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의해 수행될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 하나 이상의 실시 예에 따른 방 법에 의해 제 1 동작, 제 2 동작, 제 3 동작이 수행될 때, 제 1 동작, 제 2 동작, 및 제 3 동작 모두 제 1 프로 세서에 의해 수행될 수도 있고, 제 1 동작 및 제 2 동작은 제 1 프로세서(예를 들어, 범용 프로세서)에 의해 수 행되고 제 3 동작은 제 2 프로세서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 하나 이상의 프로세서는 하나의 코어를 포함하는 단일 코어 프로세서(single core processor)로 구현될 수 도 있고, 복수의 코어(예를 들어, 동종 멀티 코어 또는 이종 멀티 코어)를 포함하는 하나 이상의 멀티 코어 프 로세서(multicore processor)로 구현될 수도 있다. 하나 이상의 프로세서가 멀티 코어 프로세서로 구현되 는 경우, 멀티 코어 프로세서에 포함된 복수의 코어 각각은 캐시 메모리, 온 칩(On-chip) 메모리와 같은 프로세 서 내부 메모리를 포함할 수 있으며, 복수의 코어에 의해 공유되는 공통 캐시가 멀티 코어 프로세서에 포함될 수 있다. 또한, 멀티 코어 프로세서에 포함된 복수의 코어 각각(또는 복수의 코어 중 일부)은 독립적으로 본 개 시의 하나 이상의 실시 예에 따른 방법을 구현하기 위한 프로그램 명령을 판독하여 수행할 수도 있고, 복수의 코어 전체(또는 일부)가 연계되어 본 개시의 하나 이상의 실시 예에 따른 방법을 구현하기 위한 프로그램 명령 을 판독하여 수행할 수도 있다.본 개시의 하나 이상의 실시 예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 멀티 코어 프로세 서에 포함된 복수의 코어 중 하나의 코어에 의해 수행될 수도 있고, 복수의 코어에 의해 수행될 수도 있다. 예 를 들어, 하나 이상의 실시 예에 따른 방법에 의해 제 1 동작, 제 2 동작, 및 제 3 동작이 수행될 때, 제 1 동 작, 제2 동작, 및 제3 동작 모두 멀티 코어 프로세서에 포함된 제 1 코어에 의해 수행될 수도 있고, 제 1 동작 및 제 2 동작은 멀티 코어 프로세서에 포함된 제 1 코어에 의해 수행되고 제 3 동작은 멀티 코어 프로세서에 포 함된 제 2 코어에 의해 수행될 수도 있다. 본 개시의 실시 예들에서, 프로세서는 하나 이상의 프로세서 및 기타 전자 부품들이 집적된 시스템 온 칩(SoC), 단일 코어 프로세서, 멀티 코어 프로세서, 또는 단일 코어 프로세서 또는 멀티 코어 프로세서에 포함된 코어를 의미할 수 있으며, 여기서 코어는 CPU, GPU, APU, MIC, DSP, NPU, 하드웨어 가속기 또는 기계 학습 가속기 등으 로 구현될 수 있으나, 본 개시의 실시 예들이 이에 한정되는 것은 아니다. 하나 이상의 프로세서는 입력 영상에서 뎁스 정보를 획득할 수 있다. 여기서, 입력 영상은 뎁스 카메라 로부터 수신될 수도 있고, 외부 장치로부터 수신될 수도 있다. 입력 영상은 정지 영상, 복수의 연속된 정 지 영상(또는 프레임), 또는 동영상을 포함할 수 있다. 예를 들어, 입력 영상은 2D 영상이 될 수 있다. 여기서, 뎁스 정보는 뎁스 맵 형태가 될 수 있다. 뎁스 맵(Depth map)이란 영상의 각 영역 별 뎁스 정보를 포함하고 있 는 테이블을 의미한다. 영역은 픽셀 단위로 구분될 수도 있고, 픽셀 단위보다 큰 기설정된 영역으로 정의될 수 도 있다. 일 예에 따라 뎁스 맵은 0~255까지의 그레이 스케일(grayscale) 값 중 127 또는 128을 기준 값 즉, 0 (또는 포컬 플레인)으로 하여 127 또는 128 보다 작은 값을 - 값으로 나타내고, 큰 값을 + 값으로 나타내는 형 태가 될 수 있다. 포컬 플레인의 기준값은 0~255 사이에서 임의로 선택할 수 있다. 여기서, - 값은 침강을 의미 하며, + 값은 돌출을 의미한다. 다만, 이는 일 예일 뿐이며, 뎁스 맵은 다양한 기준에 따라 다양한 값으로 뎁스 를 표현할 수 있다. 일 예에 따라 프로세서는 입력 영상을 영상 처리한 후, 영상 처리된 영상에 기초하여 뎁스 정보를 획득할 수 있다. 여기서, 영상 처리는 영상 개선(image enhancement), 영상 복원(image restoration), 영상 변환 (image transformation), 영상 분석(image analysis), 영상 인식(image understanding), 영상 압축(image compression), 영상 디코딩(image decoding) 또는 스케일링(scaling) 중 적어도 하나를 포함하는 디지털 영상 처리가 될 수 있다. 일 예에 따라 하나 이상의 프로세서는 입력 영상에 대한 뎁스 정보를 획득하기 전에 다양한 전처리를 수행 할 수 있으나, 이하에서는 설명의 편의를 위하여 입력 영상과 전처리된 영상을 구분하지 않고, 이미지라고 명명 하도록 한다. 본 개시의 일 예에 따른 하나 이상의 프로세서는 뎁스 카메라를 통해 오브젝트를 포함하는 이미지를 획득 하고, 획득된 이미지를 통해 오브젝트의 형상 정보를 획득할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 오브젝트 및 가상 오브젝트를 제공하는 디스플레이 장치를 설명하기 위한 도면이다. 도 5를 참조하면, 본 개시의 일 예에 따른 디스플레이 장치는 미러 기능과 디스플레이 기능을 제공할 수 있다. 일 예에 따라 디스플레이 장치는 미러 기능을 통해 디스플레이 장치의 전면에 위치하는 사용자를 비 추어 오브젝트를 제공하고, 디스플레이 기능을 통해 가상 오브젝트를 디스플레이할 수 있다. 일 예에 따라 오브젝트는 디스플레이 장치와 동일한 공간에 위치하여(예를 들어, 미러 디스플레이(11 0)의 전면에 위치하여) 미러 디스플레이가 비추는 물건(Thing) 또는 사용자에 대응되며, 가상 오브젝트 는 디스플레이 장치와 상이한 공간에 위치하는 물건 또는 사용자, 또는 실존하지 않는 그래픽 오브젝트 (Graphic Object)에 대응될 수 있다. 본 개시의 일 예에 따라 뎁스 카메라를 통해 획득된 이미지는 2D 이미지이고, 하나 이상의 프로세서 가 2D 이미지에 기초하여 오브젝트를 2D 오브젝트로만 식별한다면, 디스플레이 장치는 오브젝트와 가상 오브젝트 간의 상호 작용을 제공할 수 없다. 여기서, 상호 작용은, 오브젝트의 형상과 가상 오브젝트의 형상에 따라 오브젝트와 가상 오브젝트 간에 충돌(또는, 접촉)이 발생하는지 여부, 오브젝트와 가상 오브젝트 중 어느 하나가 나머지 하나에 오 버랩되는지 여부 또는, 오브젝트와 디스플레이 장치 간의 제1 거리와 가상 오브젝트와 디스플레이장치 간의 제2 거리에 따른 오브젝트와 가상 오브젝트의 배치 관계(또는, 정렬 순서) 등을 포함할 수 있다. 예를 들어, 하나 이상의 프로세서가 오브젝트를 2D 오브젝트로만 식별한다면, 뎁스 카메라를 통한 시점(view point) 외에 다른 시점에서 오브젝트의 뎁스 정보를 고려한 오브젝트와 가상 오브젝트 간의 상호 작용(interaction)을 제공하지 못하는 문제가 있다. 예를 들어, 하나 이상의 프로세서가 뎁스 카메라를 통한 시점(view point) 외에 다른 시점에서 오브 젝트의 형상(또는, 표면(surface))을 식별하고, 오브젝트의 형상에 따른 오브젝트와 가상 오브젝트 의 충돌(또는, 접촉) 발생 여부를 식별하고, 충돌 발생에 따른 피드백(예를 들어, 진동) 등을 제공하지 못하 는 문제가 있다. 본 개시의 일 예에 따른 하나 이상의 프로세서는 뎁스 카메라를 통해 오브젝트를 포함하는 이미지 를 획득하며, 이미지를 통해 오브젝트의 형상 정보를 획득할 수 있다. 일 예에 따른 하나 이상의 프로세서 는 오브젝트의 형상 정보를 이용하여 가상 오브젝트 간의 상호 작용을 적절히 제공할 수 있다. 여기 서, 오브젝트의 형상 정보는, 오브젝트의 표면(surface) 정보를 포함할 수 있다. 본 개시의 일 예에 따른 하나 이상의 프로세서는 뎁스 카메라를 통해 미러 디스플레이에 비친 오브젝트를 촬영한 이미지를 획득하고, 이미지에 기초하여 오브젝트의 뎁스 정보를 획득할 수 있다. 일 예에 따른 하나 이상의 프로세서는 뎁스 정보에 기초하여 오브젝트의 스켈레톤(Skeleton) 정보를 획 득하고, 스켈레톤 정보에 기초하여 오브젝트의 형상 정보를 획득할 수 있다. 여기서, 오브젝트의 형상 정보는, 오브젝트를 3D 오브젝트로 표현 가능한, 오브젝트에 대한 복수의 시 점(view point) 각각에 대응되는 뎁스 정보를 포함할 수 있다. 일 예에 따른 하나 이상의 프로세서는 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하 여 가상 오브젝트를 오브젝트에 정합시켜 미러 디스플레이를 통해 제공할 수 있다. 일 예로, 하나 이상의 프로세서는 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하여 가상 오브젝트의 일부가 오브젝트에 닿았는지(또는, 충돌하였는지, 접촉하였는지) 여부를 판단하고, 가상 오브젝트의 일부가 오브젝트에 닿도록 가상 오브젝트를 렌더링할 수 있다. 즉, 하나 이상의 프로세서는 가상 오브젝트가 오브젝트에 겹치지 않도록(가상 오브젝트가 오브젝 트에 겹쳐지지 않도록), 오브젝트의 형상 정보에 따라 가상 오브젝트의 일부가 오브젝트에 접촉하 도록 가상 오브젝트를 렌더링할 수 있다. 예를 들어, 하나 이상의 프로세서는 가상 오브젝트를 디스플레이 장치와 동일한 공간에 위치하여 미러 디스플레이가 비추는 상처럼 디스플레이할 수 있다. 이하에서는, 설명의 편의를 위해, 하나 이상의 프로세서가 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하여 가상 오브젝트를 렌더링하는 구성을 가상 오브젝트를 오브젝트에 정합(adjust, align)시키는 구성으로 명명하도록 한다. 도 6은 본 개시의 일 실시 예에 따른 뎁스 정보를 설명하기 위한 도면이다. 종래에 따르면 뎁스 카메라를 통해 획득된 이미지는 2D 이미지이고, 하나 이상의 프로세서는 2D 이미 지에 기초하여 뎁스 카메라의 시점(view point)에 대응되는 뎁스 정보만 획득 가능하며, 오브젝트 에 대한 복수의 시점 각각에 대응되는 뎁스 정보를 포함하는 오브젝트의 형상 정보는 획득할 수 없었다. 본 개시의 일 실시 예에 따른 하나 이상의 프로세서는 뎁스 카메라를 통해 획득된 이미지에 기초하여 오브젝트의 뎁스 정보를 획득할 수 있다. 일 예에 따른 하나 이상의 프로세서는 뎁스 정보에 기초하여 오브젝트의 스켈레톤 정보를 획득 할 수 있다. 일 예에 따른 하나 이상의 프로세서는 오브젝트의 형상을 스켈레톤(뼈대, 골격)을 기준으로 한 대칭 구 조(또는, 원통형)로 예측(estimate)하여 오브젝트의 형상 정보를 획득할 수 있다. 일 예로, 하나 이상의 프로세서는 뎁스 정보에 기초하여 오브젝트를 복수의 부위로 구분하고, 복수 의 부위 별 스켈레톤을 식별할 수 있다. 예를 들어, 하나 이상의 프로세서는 복수의 부위 각각의 중심축을스켈레톤으로 식별할 수 있다. 이어서, 하나 이상의 프로세서는 복수의 부위 별 스켈레톤을 기준으로 대칭 구조(또는, 원통형)에 따른 복수의 부위 각각의 형상을 식별(또는, 예측)할 수 있다. 일 예에 따른 하나 이상의 프로세서는 복수의 부위 각각의 형상을 포함하는 오브젝트의 형상 정보 를 획득할 수 있다. 도 6을 참조하면, 하나 이상의 프로세서는 팔 부위의 뎁스 정보에 기초하여 스켈레톤 정보를 획득 하고, 스켈레톤을 기준으로 하기 수학식 1에 따른 대칭 구조에 따른 팔 부위의 형상을 식별할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0131056", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, (x, y, z)는 뎁스 카메라의 시점 외에 다른 시점(예를 들어, 음영 영역(shadow area))에서 오브젝 트의 뎁스 정보(또는, 오브젝트의 음영 영역(shadow area)의 뎁스 정보), ((x0 내지 xn), (y0 내지 yn), (z0 내지 zn))은 이미지에 기초하여 획득된 오브젝트의 뎁스 정보를 의미함. 도 7은 본 개시의 일 실시 예에 따른 스켈레톤 정보에 기초하여 형상 정보를 획득하는 디스플레이 장치를 설명 하기 위한 도면이다. 도 7을 참조하면, 본 개시의 일 예에 따른 하나 이상의 프로세서는 오브젝트를 포함하는 이미지 또는 뎁스 정보를 제1 신경망 모델에 입력하여 스켈레톤 정보를 획득할 수 있다. 일 예에 따라 스켈레톤 정 보는, 오브젝트에 포함된 복수의 부위 별 스켈레톤을 포함할 수 있다. 일 예에 따른 하나 이상의 프로세서는 제1 신경망 모델로부터 획득된 스켈레톤 정보에 포함된 복수의 부위 별 스켈레톤을 기준으로 대칭 구조에 따른 복수의 부위 각각의 형상을 식별할 수 있다. 일 예에 따른 하나 이상의 프로세서는 복수의 부위 각각의 형상을 포함하는 오브젝트의 형상 정보 를 획득할 수 있다. 일 예에 따른 제1 신경망 모델은, 복수의 샘플 이미지 및 복수의 샘플 이미지 각각에 대응되는 스켈레톤 정보를 이용하여, 이미지가 입력되면 이미지에 대응되는 스켈레톤 정보를 출력하도록 학습된 모델일 수 있다. 일 예로, 제1 신경망 모델은, 이미지가 입력되면, 이미지에 포함된 오브젝트를 식별하고, 오브젝트에 포함된 복 수의 부위를 식별하며, 복수의 부위 별 스켈레톤을 식별하도록 학습된 모델일 수 있다. 도 8은 본 개시의 일 실시 예에 따른 형상 정보를 획득하는 신경망 모델을 설명하기 위한 도면이다. 본 개시의 일 예에 따른 하나 이상의 프로세서는 뎁스 카메라를 통해 획득된 이미지를 제2 신경망 모 델에 입력하여 이미지에 포함된 오브젝트의 형상 정보를 획득할 수도 있다. 본 개시의 일 예에 따른 제2 신경망 모델은 GAN(Generative Adversarial Networks) 기반의 모델일 수 있다. GAN은 가상의 데이터 샘플을 생성하는 생성기(G, generator)와 입력된 데이터 샘플이 실제 데이터인지 여부를 판별하는 판별기(D, discriminator)로 구성된다. GAN은 생성기와 판별기 간의 적대적 트레이닝(adversarial training)을 통해 구축되는 기계 학습 모델을 의미한다. 생성기(G)(이하, 제2 신경망 모델)는 자신이 생성한(또 는, 예측한) 형상 정보(즉, 복수의 시점 각각에 대응되는 뎁스 정보)가 오브젝트의 실제 형상과의 차이 (Loss)가 최소화되도록 학습하는 모델이다. 판별기(D)는 오브젝트의 형상 정보와 오브젝트의 실제 형 상 간의 차이 값을 식별하는 모델이다. 다만, 이는 일 예시이며, 제2 신경망 모델은 NeRF(Neural radiance Fields) 기반의 모델일 수도 있다. 일 예에 따른 NeRF 기반의 모델은, 오브젝트를 촬영하여 획득한 이미지에 기초하여 새로운 시점(즉, 뎁스 카 메라의 시점 외에 다른 시점)에서의 오브젝트를 포함하는 이미지를 생성하는(View synthesis) 모델일 수 있다. 예를 들어, 디스플레이 장치는 적어도 하나 이상의 뎁스 카메라를 포함하며, 적어도 하나 이상의 뎁 스 카메라를 통해 오브젝트를 피사체로하는 적어도 하나 이상의 2D 이미지가 수신되면, NeRF 기반의 모 델은 적어도 하나 이상의 2D 이미지에 기초하여 새로운 시점에서의 오브젝트를 포함하는 이미지 또는, 오브젝트에 대응되는 3D 오브젝트를 생성할 수 있다. 일 예에 따른 NeRF 기반의 모델은, 물체(또는, 피사체)의 위치 정보(spatial location)인 (x, y, z)와 물체를 바라보는 방향(viewing direction)(예를 들어, 뎁스 카메라의 시점)인 (θ, Φ)를 포함하는 5차원 데이터 가 입력되면, RGB 값과 물체의 밀도(density)를 예측하는 완전 연결 계층(fully-connected network, FC)을 학 습한 모델일 수 있다. 여기서 물체의 밀도는 투명도의 역수로, 밀도가 커지면 물체가 불투명해지고(배치 관계 (또는, 정렬 순서)에 따라 물체의 뒤에 위치하는 다른 물체가 보이지 않음), 밀도가 작아지면 물체가 투명해질 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 디스플레이 장치의 하나 이상의 프로세서와 메모리를 통해 동작된다. 하나 이상의 프로세서는 CPU(Central Processing Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit) 중 적어도 하나를 포함할 수 있으나 전술한 프로세서의 예시에 한정되지 않는다. CPU는 일반 연산뿐만 아니라 인공지능 연산을 수행할 수 있는 범용 프로세서로서, 다계층 캐시(Cache) 구조를 통해 복잡한 프로그램을 효율적으로 실행할 수 있다. CPU는 순차적인 계산을 통해 이전 계산 결과와 다음 계산 결과의 유기적인 연계가 가능하도록 하는 직렬 처리 방식에 유리하다. 범용 프로세서는 전술한 CPU로 명시한 경 우를 제외하고 전술한 예에 한정되지 않는다. GPU는 그래픽 처리에 이용되는 부동 소수점 연산 등과 같은 대량 연산을 위한 프로세서로서, 코어를 대량으로 집적하여 대규모 연산을 병렬로 수행할 수 있다. 특히, GPU는 CPU에 비해 컨볼루션(Convolution) 연산 등과 같 은 병렬 처리 방식에 유리할 수 있다. 또한, GPU는 CPU의 기능을 보완하기 위한 보조 프로세서(co-processor)로 이용될 수 있다. 대량 연산을 위한 프로세서는 전술한 GPU로 명시한 경우를 제외하고 전술한 예에 한정되지 않 는다. NPU는 인공 신경망을 이용한 인공지능 연산에 특화된 프로세서로서, 인공 신경망을 구성하는 각 레이어를 하드 웨어(예로, 실리콘)로 구현할 수 있다. 이때, NPU는 업체의 요구 사양에 따라 특화되어 설계되므로, CPU나 GPU 에 비해 자유도가 낮으나, 업체가 요구하기 위한 인공지능 연산을 효율적으로 처리할 수 있다. 한편, 인공지능 연산에 특화된 프로세서로, NPU 는 TPU(Tensor Processing Unit), IPU(Intelligence Processing Unit), VPU(Vision processing unit) 등과 같은 다양한 형태로 구현 될 수 있다. 인공 지능 프로세서는 전술한 NPU로 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 또한, 하나 이상의 프로세서는 SoC(System on Chip)으로 구현될 수 있다. 이때, SoC에는 하나 또는 복수의 프로세서 이외에 메모리, 및 프로세서와 메모리 사이의 데이터 통신을 위한 버스(Bus)등과 같은 네트워크 인터 페이스를 더 포함할 수 있다. 디스플레이 장치에 포함된 SoC(System on Chip)에 복수의 프로세서가 포함된 경우, 디스플레이 장치 는 복수의 프로세서 중 일부 프로세서를 이용하여 인공지능과 관련된 연산(예를 들어, 인공지능 모델의 학습 (learning)이나 추론(inference)에 관련된 연산)을 수행할 수 있다. 예를 들어, 디스플레이 장치는 복수의 프로세서 중 컨볼루션 연산, 행렬 곱 연산 등과 같은 인공지능 연산에 특화된 GPU, NPU, VPU, TPU, 하드웨어 가 속기 중 적어도 하나를 이용하여 인공지능과 관련된 연산을 수행할 수 있다. 다만, 이는 일 실시예에 불과할 뿐, CPU 등과 범용 프로세서를 이용하여 인공지능과 관련된 연산을 처리할 수 있음은 물론이다. 또한, 디스플레이 장치는 하나의 프로세서에 포함된 멀티 코어(예를 들어, 듀얼 코어, 쿼드 코어 등)를 이 용하여 인공지능과 관련된 기능에 대한 연산을 수행할 수 있다. 특히, 디스플레이 장치는 프로세서에 포함 된 멀티 코어를 이용하여 병렬적으로 컨볼루션 연산, 행렬 곱 연산 등과 같은 인공 지능 연산을 수행할 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데 이터를 처리하도록 제어한다. 기정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 다수의 학습 데이터들에 학습 알고리즘을 적용함으로써, 원하는 특성 의 기정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 적어도 하나의 레이어는 적어도 하나의 가중치 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 적어도 하나의 정의된 연산을 통해 레이 어의 연산을 수행한다. 신경망의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network), GAN (Generative Adversarial Networks), NeRF 및 심 층 Q-네트워크 (Deep Q-Networks), Transformer가 있으며, 본 개시에서의 신경망은 명시한 경우를 제외하고 전 술한 예에 한정되지 않는다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)을 훈련시켜 소정의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘은 명시한 경우를 제외하고 전술 한 예에 한정되지 않는다. 도 9는 본 개시의 일 실시 예에 따른 외부 장치와 통신하는 디스플레이 장치를 설명하기 위한 도면이다. 본 개시의 일 예에 따른 디스플레이 장치는 통신 인터페이스를 더 포함할 수 있고, 디스플레이 장치 는 통신 인터페이스를 통해 타 디스플레이 장치(이하, 외부 장치(100'))와 통신할 수 있다. 통신 인터페이스는 디스플레이 장치의 구현 예에 따라 다양한 인터페이스로 구현될 수 있음은 물론이다. 예를 들어 통신 인터페이스는 블루투스(Bluetooth), AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 지그 비(Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜 (Coaxial) 등과 같은 통신 방식을 통해 외부 장치(100'), 외부 저장 매체(예를 들어, USB 메모리), 외부 서버 (예를 들어 웹 하드) 등과 통신을 수행할 수 있다. 일 예에 따라 통신 인터페이스는 타 전자 장치, 외부 서버 및/또는 원격 제어 장치 등과 통신을 수행할 수 있다. 특히, 일 예에 따라 하나 이상의 프로세서는 오브젝트의 형상 정보를 외부 장치(100')로 전송할 수 있 고, 외부 장치(100')로부터 가상 오브젝트의 형상 정보를 수신할 수 있다. 일 예로, 외부 장치(100')는 외부 장치(100')와 동일한 공간에 위치하여 외부 장치(100')에 구비된 미러 디스플 레이(110')가 비추는 사용자의 형상 정보를 획득할 수 있다. 이어서, 외부 장치(100')는 사용자(또는, 물체 (thing) 등)의 형상 정보를 디스플레이 장치로 전송할 수 있다. 설명의 편의를 위해, 외부 장치(100')에 구비된 미러 디스플레이(110')가 비추는 사용자를 가상 오브젝트로 통칭하도록 한다. 하나 이상의 프로세서는 외부 장치(100')로부터 수신된 가상 오브젝트의 형상 정보에 기초하여 가상 오 브젝트를 디스플레이하도록 미러 디스플레이를 제어할 수 있다. 일 예에 따른 하나 이상의 프로세서는 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하 여 가상 오브젝트를 오브젝트에 정합시켜 디스플레이할 수 있다. 일 예로, 하나 이상의 프로세서는 오브젝트의 형상 정보에 기초하여 오브젝트와 디스플레이 장치 간의 제1 거리를 식별할 수 있다. 하나 이상의 프로세서는 가상 오브젝트의 형상 정보에 기초하 여 가상 오브젝트와 디스플레이 장치 간의 제2 거리를 식별할 수 있다. 일 예에 따른 하나 이상의 프로세서는 제1 거리와 제2 거리에 기초하여 오브젝트와 가상 오브젝트 중 어느 하나를 나머지 하나보다 뒤에 위치시킬 수 있다. 일 예로, 하나 이상의 프로세서는 가상 오브젝트에 포함된 복수의 부위 중 적어도 하나의 부위(또는, 가상 오브젝트의 일부)를 오브젝트 보다 전면에 위치시킬 수 있고, 나머지 부위(또는, 가상 오브젝트 의 나머지)를 오브젝트 보다 후면에 위치시킬 수 있다. 한편, 하나 이상의 프로세서는 오브젝트의 형상 정보를 외부 장치(100')로 전송하며, 외부 장치(100') 는 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하여 오브젝트를 가상 오브젝트에 정 합시켜 미러 디스플레이(110')를 통해 제공할 수 있음은 물론이다. 본 개시의 일 예에 따른 하나 이상의 프로세서는 오브젝트의 형상 정보 및 가상 오브젝트의 형상 정 보에 기초하여 미러 디스플레이 상에서 가상 오브젝트의 일부가 오브젝트에 접촉되도록 가상 오브젝트를 디스플레이할 수 있다. 예를 들어, 하나 이상의 프로세서는 오브젝트 및 가상 오브젝트 각각을 2D 오브젝트가 아닌, 3D 오 브젝트로 식별하며, 오브젝트와 가상 오브젝트가 중첩되는 것이 아닌(또는, 가상 오브젝트가 오브젝트 를 통과 또는, 관통하도록 디스플레이하는 것이 아닌), 오브젝트의 표면 정보에 따라 가상 오브젝트의 일부가 오브젝트에 접촉되도록 가상 오브젝트를 디스플레이할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 오브젝트에 정합된 가상 오브젝트를 설명하기 위한 도면이다. 도 10을 참조하면, 하나 이상의 프로세서는 미러 디스플레이가 비추는 오브젝트에 가상 오브젝트 를 조정없이 그대로 덮어 씌워 디스플레이하지 않고, 오브젝트의 형상 정보와 외부 장치(100')로부터 수 신된 가상 오브젝트의 형상 정보에 기초하여 가상 오브젝트를 오브젝트에 정합하여(또는, 조정하여) 디스플레이할 수 있다. 예를 들어, 하나 이상의 프로세서는 오브젝트의 형상 정보에 포함된 오브젝트에 대한 복수의 시점 각각에 대응되는 뎁스 정보에 기초하여 오브젝트에 대응되는 3D 오브젝트를 획득할 수 있다. 3D 오브젝트는, 오브젝트의 자세(Pose) 정보도 포함할 수 있다. 일 예에 따라 하나 이상의 프로세서는 가상 오브젝트의 형상 정보에 기초하여 가상 오브젝트에 대응 되는 3D 오브젝트를 획득할 수 있다. 일 예에 따라 하나 이상의 프로세서는 뎁스 카메라에 따른 시점 외에, 새로운 시점(또는, 뎁스 카메 라를 통한 뎁스 정보의 미 획득 영역)에서 오브젝트의 자세와 가상 오브젝트의 자세에 따라 접촉이 발생하는지 여부를 식별할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 피드백을 제공하는 디스플레이 장치를 설명하기 위한 도면이다. 본 개시의 일 예에 따른 하나 이상의 프로세서는 통신 인터페이스를 통해 웨어러블 디바이스(wearable device)와 통신할 수 있다. 여기서, 웨어러블 디바이스란, 플렉서블(flexible) 재질(예를 들어, 실리 콘 고무, 섬유 등)로 이루어져, 사용자가 착용 또는 사용자의 신체 일부와 접촉 가능한 장치를 의미한다. 예를 들어, 사람이나 동물이 신체에 착용할 수 있는 시계, 의복(예를 들어, 진동 슈트(suit)), 신발, 장갑, 안경, 모 자, 장신구(예를 들어, 반지) 등과 같은 다양한 유형의 장치가 웨어러블 디바이스에 포함될 수 있다. 다만, 이는 예시에 불과하며, 이에 한정되지 않음은 물론이다. 본 개시의 일 예에 따른 하나 이상의 프로세서는 미러 디스플레이 상에서 가상 오브젝트의 일부와 오브젝트 간의 접촉이 식별되면, 오브젝트 상에서 가상 오브젝트의 일부가 접촉된 영역에 촉각 피드백 이 제공되도록 웨어러블 디바이스를 제어할 수 있다. 예를 들어, 도 11에 도시된 바와 같이, 사용자(즉, 오브젝트)가 어깨 부위에 웨어러블 디바이스를 착용 중이며, 가상 오브젝트로 표현되는 타 사용자의 움직임에 따라 외부 장치(100')로부터 가상 오브젝트의 변경된 형상 정보가 수신되면, 가상 오브젝트의 변경된 형상 정보에 따라 가상 오브젝트를 오브젝트에 재정합할 수 있다. 일 예에 따라, 가상 오브젝트의 일부가 오브젝트의 어깨 부위에 접촉되면, 하나 이상 의 프로세서는 사용자의 어깨 부위에 피드백(예를 들어, 진동)을 제공하도록 웨어러블 디바이스로 제 어 신호를 전송할 수 있다. 일 예에 따라 외부 장치(100')의 사용자(즉, 디스플레이 장치의 사용자와 다른 사용자)의 자세가 변경되면, 외부 장치(100')의 뎁스 카메라(120')는 자세가 변경된 사용자를 포함하는 이미지를 획득할 수 있고, 사용자(이하, 가상 오브젝트)의 변경된 형상 정보를 획득할 수 있다. 일 예에 따라 외부 장치(100')는 변경된 형상 정보를 디스플레이 장치로 전송하며, 하나 이상의 프로세서 는 변경된 형상 정보에 따라 가상 오브젝트를 오브젝트에 재정합시킬 수 있다. 일 예에 따라 실시간 또는 기설정된 시간 간격으로, 가상 오브젝트의 변경된 형상 정보에 따라 가상 오브젝 트를 오브젝트에 재정합시키므로, 디스플레이 장치는 디스플레이 장치의 사용자에게 외부 장치 (100')의 사용자(즉, 타 사용자)가 동일한 공간에 위치하며, 타 사용자가 디스플레이 장치의 미러 디스플 레이에 비치는 효과를 제공할 수 있다. 또한, 디스플레이 장치는 스피커를 더 포함하며, 외부 장치(100')에 구비된 마이크는 타 사용자의 음성, 외부 장치(100')가 위치하는 공간에서 발생한 소리 등을 획득하여 디스플레이 장치로 전송하며, 디스플레이 장치는 외부 장치(100')로부터 수신된 음성 및 소리를 출력할 수 있다. 또한, 디스플레이 장치는 마이크를 더 포함하며, 디스플레이 장치에 구비된 마이크는 사용자의 음성, 디스플레이 장치가 위치 하는 공간에서 발생한 소리 등을 획득하여 외부 장치(100')로 전송하며, 외부 장치(100')는 디스플레이 장치 로부터 수신된 음성 및 소리를 출력할 수 있다. 도 12는 본 개시의 일 실시 예에 따른 외부 장치와 통신하는 디스플레이 장치를 설명하기 위한 도면이다. 본 개시의 일 예에 따라 디스플레이 장치 및 외부 장치(100')는 외부 서버를 통해 상호 통신할 수도 있다. 일 예에 따라 하나 이상의 프로세서는 가상 오브젝트에 대한 사용자의 입력이 식별되면, 가상 오브젝트 와 인터렉션을 수행할 수 있다. 예를 들어, 사용자의 자세가 변경되어, 미러 디스플레이에 비치는 오브젝트가 가상 오브젝트를 터치 하거나, 오브젝트와 가상 오브젝트 간의 접촉이 식별되면, 가상 오브젝트와 인터렉션을 수행할 수 있 다. 예를 들어, 가상 오브젝트가 그래픽 오브젝트이면, 하나 이상의 프로세서는 그래픽 오브젝트에 대응되 는 동작(또는, 기능)을 실행시킬 수 있다. 예를 들어, 가상 오브젝트가 외부 장치(100')의 사용자에 대응되면, 하나 이상의 프로세서는 외부 장치 (100')의 사용자가 착용하는 웨어러블 디바이스가 촉각 피드백을 제공하도록 제어하는 신호를 외부 장치(100') 로 전송하며, 외부 장치(100')는 수신된 신호에 따라 외부 장치(100')의 사용자가 착용하는 웨어러블 디바이스 를 제어할 수 있다. 예를 들어, 하나 이상의 프로세서는 가상 오브젝트에 대한 사용자의 입력에 따라 미러 디스플레이 상에서 가상 오브젝트의 위치, 시점, 크기 또는 비율 중 적어도 하나를 조정할 수 있다. 일 예로, 사용자의 입력이 가상 오브젝트를 회전시키는 입력이면, 하나 이상의 프로세서는 가상 오브젝 트의 형상 정보에 기초하여 가상 오브젝트의 시점을 변경(또는, 가상 오브젝트를 회전)할 수 있다. 일 예로, 사용자의 입력이 가상 오브젝트의 정렬 순서를 변경시키는 입력이면, 하나 이상의 프로세서는 사용자의 입력에 따라 가상 오브젝트를 오브젝트의 전면 또는 후면에 위치시킬 수 있다. 일 예로, 사용자의 입력이 가상 오브젝트의 크기를 변경시키는 입력(예를 들어, 크기를 축소시키는 핀치 (Pinch), 크기를 확대시키는 스프레드(Spread) 등)이면, 하나 이상의 프로세서는 사용자의 입력에 따라 가 상 오브젝트의 크기를 변경시킬 수 있다. 여기서, 사용자의 입력은, 미러 디스플레이에 대한 터치 입력(즉, 미러 디스플레이와 물리적인 접촉 이 있는 입력), 사용자의 변경된 자세에 대응되는 미러 디스플레이에 비친 오브젝트를 통한 입력(즉, 미러 디스플레이와 물리적인 접촉이 없는 입력) 등을 포함할 수 있다. 예를 들어, 하나 이상의 프로세서 는 미러 디스플레이에 비친 오브젝트에서 손 부위(예를 들어, 엄지와 검지 등)를 식별하고, 식별 된 손 부위의 자세(pose), 위치, 형상 등에 기초하여 입력을 식별할 수 있다. 도 13은 본 개시의 일 실시 예에 따른 디스플레이 장치의 제어 방법을 설명하기 위한 흐름도이다. 일 예에 따른 제어 방법은 미러 디스플레이에 비친 오브젝트를 촬영한 이미지를 획득하여 오브젝트의 뎁스 정보 를 획득한다(S1310). 오브젝트의 뎁스 정보에 기초하여 오브젝트의 스켈레톤 정보를 획득한다(S1320). 획득된 스켈레톤 정보에 기초하여 오브젝트의 형상 정보를 획득한다(S1330). 오브젝트의 형상 정보와 가상 오브젝트의 형상 정보에 기초하여 가상 오브젝트를 오브젝트에 정합시켜 미러 디 스플레이를 통해 제공한다(S1340). 일 예에 따른 오브젝트의 스켈레톤 정보는, 오브젝트에 포함된 복수의 부위 별 스켈레톤을 포함하며, 형상 정보 를 획득하는 S1330 단계는, 복수의 부위 별 스켈레톤을 기준으로 대칭 구조에 따른 복수의 부위 각각의 형상을 식별하는 단계 및 복수의 부위 각각의 형상을 포함하는 오브젝트의 형상 정보를 획득하는 단계를 포함할 수 있 다.본 개시의 일 예에 따른 형상 정보를 획득하는 S1330 단계는, 이미지를 신경망 모델에 입력하여 이미지에 포함 된 오브젝트의 형상 정보를 획득하는 단계를 포함하며, 신경망 모델은, 오브젝트를 포함하는 이미지가 입력되면, 오브젝트의 뎁스 정보로부터 오브젝트에 대한 복수의 시점(view point) 각각에 대응되는 뎁스 정보를 포함하는 오브젝트의 형상 정보를 출력하도록 학습된 모델일 수 있다. 본 개시의 일 예에 따른 제공하는 S1340 단계는, 오브젝트의 형상 정보 및 가상 오브젝트의 형상 정보에 기초하 여 가상 오브젝트의 일부를 오브젝트의 전면에 위치시키고, 가상 오브젝트의 나머지를 오브젝트의 후면에 위치 시켜 가상 오브젝트를 디스플레이하는 단계를 포함할 수 있다. 본 개시의 일 예에 따른 제공하는 S1340 단계는, 오브젝트의 형상 정보 및 가상 오브젝트의 형상 정보에 기초하 여 미러 디스플레이 상에서 가상 오브젝트의 일부가 오브젝트에 접촉되도록 가상 오브젝트를 디스플레이하는 단 계를 포함할 수 있다. 본 개시의 제어 방법은, 미러 디스플레이 상에서 가상 오브젝트의 일부와 오브젝트 간의 접촉이 식별되면, 오브 젝트 상에서 가상 오브젝트의 일부가 접촉된 영역에 촉각 피드백을 제공하도록 오브젝트가 착용한 웨어러블 디 바이스(wearable device)를 제어하는 단계를 더 포함할 수 있다. 본 개시의 제어 방법은, 외부 장치로부터 가상 오브젝트의 형상 정보를 수신하는 단계 및 외부 장치로 오브젝트 의 형상 정보를 전송하는 단계를 더 포함할 수 있다. 본 개시의 제어 방법은, 가상 오브젝트에 대한 사용자의 입력이 식별되면, 입력에 기초하여 가상 오브젝트와 인 터렉션(interaction)을 수행하는 단계를 더 포함하며, 전송하는 단계는, 사용자의 입력에 따른 오브젝트의 변경 된 형상 정보를 외부 장치로 전송하는 단계를 포함하고, 사용자의 입력은, 가상 오브젝트의 일부에 대한 터치 입력을 포함할 수 있다. 본 개시의 일 예에 따른 제공하는 S1340 단계는, 오브젝트에 대한 타 사용자의 입력에 따라 외부 장치로부터 가 상 오브젝트의 변경된 형상 정보가 수신되면, 변경된 형상 정보에 따라 가상 오브젝트를 오브젝트에 재정합시키 는 단계를 포함하며, 가상 오브젝트는, 외부 장치에 구비된 미러 디스플레이에 비친 타 사용자에 대응되며, 오 브젝트는, 사용자에 대응될 수 있다. 본 개시의 일 예에 따른 제어 방법은, 사용자의 입력에 기초하여 미러 디스플레이 상에서 가상 오브젝트의 위치, 시점, 크기 또는 비율 중 적어도 하나를 조정하는 단계를 더 포함할 수 있다. 다만, 본 개시의 다양한 실시 예들은 디스플레이 장치 뿐 아니라, 미러 기능과 디스플레이 기능을 포함하는 다 양한 유형의 전자 장치에 적용될 수 있음은 물론이다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트 웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 디스플레이 장치의 프로세싱 동작을 수행하기 위한 컴퓨 터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프 로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 디스플레이 장치에서의 처리 동작을 특정 기 기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2023-0131056", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다.부호의 설명 100: 디스플레이 장치 110: 미러 디스플레이 120: 뎁스 카메라 130: 메모리 140: 하나 이상의 프로세서"}
{"patent_id": "10-2023-0131056", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 미러 디스플레이의 특성을 나타내는 도면이다. 도 2는 본 개시의 일 실시 예에 따른 디스플레이 장치의 구성을 나타내는 블록도이다. 도 3 및 도 4는 본 개시의 일 예에 따른 스위처블 미러의 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 오브젝트 및 가상 오브젝트를 제공하는 디스플레이 장치를 설명하기 위한 도면이다.도 6은 본 개시의 일 실시 예에 따른 뎁스 정보를 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시 예에 따른 스켈레톤 정보에 기초하여 형상 정보를 획득하는 디스플레이 장치를 설명 하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 형상 정보를 획득하는 신경망 모델을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 외부 장치와 통신하는 디스플레이 장치를 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 오브젝트에 정합된 가상 오브젝트를 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시 예에 따른 피드백을 제공하는 디스플레이 장치를 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시 예에 따른 외부 장치와 통신하는 디스플레이 장치를 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시 예에 따른 디스플레이 장치의 제어 방법을 설명하기 위한 흐름도이다."}
