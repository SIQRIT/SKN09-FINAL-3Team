{"patent_id": "10-2023-0130660", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0144505", "출원번호": "10-2023-0130660", "발명의 명칭": "딥러닝 모델 기반의 데이터 생성 방법, 트레이닝 방법 및 장치", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "왕 하이펑"}}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥러닝 모델 기반의 데이터 생성 방법으로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있고, 상기 데이터 생성방법은, 사용자로부터의 입력 데이터에 기반하여, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계; 상기 딥러닝 모델의 제1 출력을 획득하되, 상기 딥러닝 모델에 응답하여 상기 초기 입력을 기반으로 생성한 회신을 결정하기 위해서는 상기 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 상기 제1 출력은 상기 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 초기 입력을 기반으로 결정되고 상기 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 단계; 상기 제1 기능 컴포넌트가 상기 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하는 단계; 적어도 상기 초기 입력 및 상기 제1 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하는단계; 및 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하는 단계를 포함하는 것을특징으로 하는 딥러닝 모델 기반의 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 기능 컴포넌트는 외부 기억 장치이고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목인 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 방법은, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 임의의 하나의 데이터 세트 사이의 유사도가 제2 임계값보다 낮다고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이터 세트 그룹에 등록하는 단계를 더 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 방법은, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 제2 데이터 세트 사공개특허 10-2023-0144505-3-이의 유사도가 제3 임계값보다 높다고 결정하며 상기 제1 데이터 세트와 상기 제2 데이터 세트가 서로 충돌된다고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이터 세트 그룹에 등록하고, 상기 제1 데이터 세트 그룹에서 상기 제2 데이터 세트를 삭제하는 단계를 더 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 상기 세트 중 과거 입력 데이터 항목 및 과거 회신 항목과대응되는 등록 시간 항목을 더 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기입력 데이터와의 유사도가 제1 임계값보다 높고 타임스탬프가 최신인 과거 입력 데이터 항목에 대응되는 과거회신 항목인 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 방법은, 상기 등록 시간 항목에 기반하여, 상기 외부 기억 장치에서 시효가 지난 데이터 세트를 삭제하는 단계를 더 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계는, 상기 입력 데이터에 기반하여, 외부 기억 장치에서 상기 입력 데이터와의 유사도가 제1 임계값보다 높은 과거입력 데이터 항목에 대응되는 과거 회신 항목을 획득하는 단계; 및 상기 입력 데이터 및 상기 과거 회신 항목에 기반하여, 상기 초기 입력을 결정하는 단계를 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 초기 입력은 상기 입력 데이터의 컨텍스트 정보를 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계는, 외부 기억 장치에서 상기 입력 데이터 및 상기 컨텍스트 정보와의 유사도가 제4 임계값에 부합되는 적어도 한쌍의 과거 입력 데이터 항목과 과거 회신 항목을 획득하는 단계; 및 상기 입력 데이터, 상기 컨텍스트 정보 및 상기 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목에 기반하여, 상기 딥러닝 모델에 사용되는 상기 초기 입력을 결정하는 단계를 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에공개특허 10-2023-0144505-4-대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 외부 서치 엔진인 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델인 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스인 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항 내지 제11항 중 어느 한 항에 있어서, 적어도 상기 초기 입력 및 상기 제1 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하는단계는, 상기 초기 입력, 상기 제1 중간 결과 및 상기 제1 중간 문의에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하는 단계를 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항 내지 제11항 중 어느 한 항에 있어서, 상기 제2 출력은 상기 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않고, 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하는 단계는, 상기 제2 출력을 상기 초기 입력에 대한 상기 회신으로 하는 단계를 포함하는 것을 특징으로 하는 데이터 생성방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항 내지 제11항 중 어느 한 항에 있어서, 상기 제2 출력은 제2 기능 컴포넌트를 호출하기 위한 제2 토큰 및 상기 제2 입력을 기반으로 얻어지고 상기 제2기능 컴포넌트에 의해 인식될 수 있는 제2 중간 문의를 포함하고, 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하는 단계는, 상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 단계; 및상기 딥러닝 모델의 제N 출력에 제N 기능 컴포넌트를 호출하기 위한 제N 토큰 및 제N 입력을 기반으로 얻어지고상기 제N 기능 컴포넌트에 의해 인식될 수 있는 제N 중간 문의가 포함되는 것에 응답하여, 제N+1 출력에 상기딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰이 포함되지 않다고 결정될 때까지 상기 제N 출력과 대응되는 기능 호출 작업을 수행하고, 상기 제N+1 출력을 상기 초기 입력에 대한 상기 회신으로 하되, N은 2보다 큰 정수인 단계를 포함하며,상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 단계는,상기 제2 기능 컴포넌트가 상기 제2 중간 문의에 기반하여 결정한 제2 중간 결과를 획득하는 단계;공개특허 10-2023-0144505-5-적어도 상기 제2 입력 및 상기 제2 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제3 입력을 결정하는단계; 및 상기 딥러닝 모델의 제3 출력을 획득하는 단계를 포함하는 것을 특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 제2 기능 컴포넌트 및 제N 기능 컴포넌트는 각각,외부 서치 엔진; 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델; 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스; 및 외부 기억 장치를 포함하는 기능 컴포넌트 그룹 중 하나이되, 상기 외부 기억 장치에는 상기 사용자와 관련된제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을특징으로 하는 데이터 생성 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "딥러닝 모델의 트레이닝 방법으로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성하고, 상기 트레이닝 방법은, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하되, 상기 제1 샘플 초기 입력은 상기 딥러닝 모델과 구별되는 제1 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하며, 상기 제1 샘플 출력은 상기 제1 기설정된 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 제1 기설정된 기능 컴포넌트에 의해 인식될 수 있는 제1 샘플 중간 입력을 포함하는 단계; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하되, 상기 제2 샘플 초기 입력은 상기 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하지 않으며,상기 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않는단계; 상기 딥러닝 모델을 이용하여 상기 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력을 획득하는 단계; 상기 제1 샘플 출력과 상기 제1 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하는 단계; 상기 딥러닝 모델을 이용하여 상기 제2 샘플 초기 입력을 처리함으로써, 제2 예측 출력을 획득하는 단계; 및 상기 제2 샘플 출력과 상기 제2 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하는 단계를포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 트레이닝 방법은, 제3 샘플 초기 입력, 샘플 서치 문의, 복수의 샘플 서치 결과, 및 상기 딥러닝 모델이 상기 제3 샘플 초기 입력에 대한 제3 샘플 회신을 포함하는 제3 샘플 데이터를 획득하되, 상기 샘플 서치 문의는 상기 딥러닝 모델이 상기 제3 샘플 초기 입력을 기반으로 생성한 샘플 중간 입력이고, 상기 샘플 중간 입력은 상기 딥러닝 모델과 구별되는 검색 모델에 의해 인식될 수 있으며, 상기 복수의 샘플 서치 결과는 상기 검색 모델이 상기 샘플 서치문의에 기반하여 출력한 결과인 단계; 상기 복수의 샘플 서치 결과 각자와 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결과에 대하여 배열 작업을 수행하는 단계; 및 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델을 트레이닝하는 단계를 더 포함하는 것을 특징공개특허 10-2023-0144505-6-으로 하는 딥러닝 모델의 트레이닝 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 복수의 샘플 서치 결과 각자와 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결과에 대하여 배열 작업을 수행하는 단계는, 상기 복수의 샘플 서치 결과에서 현재 일치도가 가장 높은 제1 샘플 서치 결과를 선별하는 단계; 상기 제3 샘플 회신과 상기 제1 샘플 서치 결과 사이의 중합 내용을 삭제하여, 상기 제3 샘플 회신을 업데이트하는 단계; 및 상기 복수의 샘플 서치 결과의 나머지 부분 각자와 업데이트된 상기 제3 샘플 회신 사이의 일치도에 기반하여,상기 복수의 샘플 서치 결과 중 모든 샘플 서치 결과에 대한 배열을 완성할 때까지 상기 나머지 부분에 대하여상기 배열 작업을 반복하는 단계를 포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항 또는 제21항에 있어서, 상기 검색 모델은 배열 서브 모델 및 소환 서브 모델을 포함하고, 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델을 트레이닝하는 단계는, 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델의 배열 서브 모델을 트레이닝하는 단계; 및 트레이닝된 상기 배열 서브 모델을 교사 모델로 하여, 상기 소환 서브 모델을 트레이닝하는 단계를 포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제19항 내지 제21항 중 어느 한 항에 있어서, 상기 방법은, 제4 샘플 초기 입력, 외부 기억 장치에 의해 인식될 수 있는 제4 샘플 중간 입력, 샘플 기억 결과 및 제4 샘플회신을 포함하는 제4 샘플 데이터를 획득하되, 상기 제4 샘플 중간 입력은 상기 제4 샘플 초기 입력을 기반으로결정된 것인 단계; 외부 기억 장치가 상기 제4 샘플 중간 입력을 기반으로 결정한 예측 기억 결과를 획득하는 단계; 상기 예측 기억 결과와 상기 샘플 기억 결과의 비교에 기반하여, 상기 외부 기억 장치의 파라미터를 조정하는단계; 적어도 상기 제4 샘플 초기 입력 및 상기 샘플 기억 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제4 샘플타겟 입력을 결정하는 단계; 상기 딥러닝 모델을 이용하여 상기 제4 샘플 타겟 입력을 처리함으로써, 제4 예측 회신을 획득하는 단계; 및 상기 제4 샘플 회신과 상기 제4 예측 회신의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하는 단계를더 포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "딥러닝 모델 기반의 데이터 생성 장치로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있고, 상기 데이터 생성장치는, 사용자로부터의 입력 데이터에 기반하여, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하도록 구성되는 제1결정 유닛; 상기 딥러닝 모델의 제1 출력을 획득하도록 구성되되, 상기 딥러닝 모델에 응답하여 상기 초기 입력을 기반으로공개특허 10-2023-0144505-7-생성한 회신을 결정하기 위해서는 상기 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 상기 제1출력은 상기 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 초기 입력을 기반으로 결정되고 상기 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 제1 획득 유닛; 상기 제1 기능 컴포넌트가 상기 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하도록 구성되는 제2 획득 유닛; 적어도 상기 초기 입력 및 상기 제1 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하도록 구성되는 제2 결정 유닛; 및 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하도록 구성되는 제3 획득유닛을 포함하는 것을 특징으로 하는 딥러닝 모델 기반의 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서, 상기 제1 기능 컴포넌트는 외부 기억 장치이고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목인 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제25항에 있어서, 상기 장치는, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 임의의 하나의 데이터 세트 사이의 유사도가 제2 임계값보다 낮다고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이터 세트 그룹에 등록하도록 구성되는 제1 등록 유닛을 더 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제25항에 있어서, 상기 장치는, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 제2 데이터 세트 사이의 유사도가 제3 임계값보다 높다고 결정하며 상기 제1 데이터 세트와 상기 제2 데이터 세트가 서로 충돌된다고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이터 세트 그룹에 등록하고, 상기 제1 데이터 세트 그룹에서 상기 제2 데이터 세트를 삭제하도록 구성되는 제2 등록 유닛을 더 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제25항에 있어서, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 상기 세트 중 과거 입력 데이터 항목 및 과거 회신 항목과대응되는 등록 시간 항목을 더 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서, 공개특허 10-2023-0144505-8-상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기입력 데이터와의 유사도가 제1 임계값보다 높고 타임스탬프가 최신인 과거 입력 데이터 항목에 대응되는 과거회신 항목인 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제29항에 있어서, 상기 장치는, 상기 등록 시간 항목에 기반하여, 상기 외부 기억 장치에서 시효가 지난 데이터 세트를 삭제하도록 구성되는 삭제 유닛을 더 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제24항에 있어서, 상기 제1 결정 유닛은, 상기 입력 데이터에 기반하여, 외부 기억 장치에서 상기 입력 데이터와의 유사도가 제1 임계값보다 높은 과거입력 데이터 항목에 대응되는 과거 회신 항목을 획득하도록 구성되는 제1 획득 서브 유닛; 및 상기 입력 데이터 및 상기 과거 회신 항목에 기반하여, 상기 초기 입력을 결정하도록 구성되는 제1 결정 서브유닛을 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제24항에 있어서, 상기 초기 입력은 상기 입력 데이터의 컨텍스트 정보를 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제33항에 있어서, 상기 제1 결정 유닛은, 외부 기억 장치에서 상기 입력 데이터 및 상기 컨텍스트 정보와의 유사도가 제4 임계값에 부합되는 적어도 한쌍의 과거 입력 데이터 항목과 과거 회신 항목을 획득하도록 구성되는 제2 획득 서브 유닛; 및 상기 입력 데이터, 상기 컨텍스트 정보 및 상기 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목에 기반하여, 상기 딥러닝 모델에 사용되는 상기 초기 입력을 결정하도록 구성되는 제2 결정 서브 유닛을 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제32항 내지 제34항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 외부 서치 엔진인 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제32항 내지 제34항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델인 것을 특징으로 하는 데이터 생성 장치.공개특허 10-2023-0144505-9-청구항 37 제32항 내지 제34항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스인 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제24항 내지 제34항 중 어느 한 항에 있어서, 상기 제2 결정 유닛은, 상기 초기 입력, 상기 제1 중간 결과 및 상기 제1 중간 문의에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하도록 구성되는 제3 결정 서브 유닛을 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제24항 내지 제34항 중 어느 한 항에 있어서, 상기 제2 출력은 상기 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않고, 상기 제3 획득 유닛은, 상기 제2 출력을 상기 초기 입력에 대한 상기 회신으로 하도록 구성되는 회신 서브 유닛을 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제24항 내지 제34항 중 어느 한 항에 있어서, 상기 제2 출력은 제2 기능 컴포넌트를 호출하기 위한 제2 토큰 및 상기 제2 입력을 기반으로 얻어지고 상기 제2기능 컴포넌트에 의해 인식될 수 있는 제2 중간 문의를 포함하고, 상기 제3 획득 유닛은, 상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하도록 구성되는 제3 획득 서브 유닛; 및상기 딥러닝 모델의 제N 출력에 제N 기능 컴포넌트를 호출하기 위한 제N 토큰 및 제N 입력을 기반으로 얻어지고상기 제N 기능 컴포넌트에 의해 인식될 수 있는 제N 중간 문의가 포함되는 것에 응답하여, 제N+1 출력에 상기딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰이 포함되지 않다고 결정될 때까지 상기 제N 출력과 대응되는 기능 호출 작업을 수행하고, 상기 제N+1 출력을 상기 초기 입력에 대한 상기 회신으로 하되, N은 2보다 큰 정수이도록 구성되는 호출 서브 유닛을 포함하며,상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 것은, 상기 제2 기능 컴포넌트가 상기 제2 중간 문의에 기반하여 결정한 제2 중간 결과를 획득하는 것; 적어도 상기 제2 입력 및 상기 제2 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제3 입력을 결정하는것; 및 상기 딥러닝 모델의 제3 출력을 획득하는 것을 포함하는 것을 특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제40항에 있어서, 상기 제2 기능 컴포넌트 및 제N 기능 컴포넌트는 각각, 외부 서치 엔진; 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델; 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스; 및 공개특허 10-2023-0144505-10-외부 기억 장치를 포함하는 기능 컴포넌트 그룹 중 하나이되, 상기 외부 기억 장치에는 상기 사용자와 관련된제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을특징으로 하는 데이터 생성 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "딥러닝 모델의 트레이닝 장치로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성하고, 상기 트레이닝 장치는, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하도록 구성되되, 상기 제1 샘플 초기입력은 상기 딥러닝 모델과 구별되는 제1 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하며, 상기 제1샘플 출력은 상기 제1 기설정된 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 제1 기설정된 기능 컴포넌트에 의해 인식될 수 있는 제1 샘플 중간 입력을 포함하는 제4 획득 유닛; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하도록 구성되되, 상기 제2 샘플 초기입력은 상기 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하지않으며, 상기 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지않는 제5 획득 유닛; 상기 딥러닝 모델을 이용하여 상기 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력을 획득하도록 구성되는제1 처리 유닛; 상기 제1 샘플 출력과 상기 제1 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하도록 구성되는 제1 파라미터 조정 유닛; 상기 딥러닝 모델을 이용하여 상기 제2 샘플 초기 입력을 처리함으로써, 제2 예측 출력을 획득하도록 구성되는제2 처리 유닛; 및 상기 제2 샘플 출력과 상기 제2 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하도록 구성되는 제2 파라미터 조정 유닛을 포함하는 것을 특징으로 하는 트레이닝 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "제42항에 있어서, 상기 트레이닝 장치는, 제3 샘플 초기 입력, 샘플 서치 문의, 복수의 샘플 서치 결과, 및 상기 딥러닝 모델이 상기 제3 샘플 초기 입력에 대한 제3 샘플 회신을 포함하는 제3 샘플 데이터를 획득하도록 구성되되, 상기 샘플 서치 문의는 상기 딥러닝 모델이 상기 제3 샘플 초기 입력을 기반으로 생성한 샘플 중간 입력이고, 상기 샘플 중간 입력은 상기 딥러닝 모델과 구별되는 검색 모델에 의해 인식될 수 있으며, 상기 복수의 샘플 서치 결과는 상기 검색 모델이 상기샘플 서치 문의에 기반하여 출력한 결과인 제6 획득 유닛; 상기 복수의 샘플 서치 결과 각자와 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결과에 대하여 배열 작업을 수행하도록 구성되는 배열 유닛; 및 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델을 트레이닝하도록 구성되는 트레이닝 유닛을더 포함하는 것을 특징으로 하는 트레이닝 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제43항에 있어서, 상기 배열 유닛은, 상기 복수의 샘플 서치 결과에서 현재 일치도가 가장 높은 제1 샘플 서치 결과를 선별하도록 구성되는 선별 서브 유닛; 상기 제3 샘플 회신과 상기 제1 샘플 서치 결과 사이의 중합 내용을 삭제하여, 상기 제3 샘플 회신을 업데이트공개특허 10-2023-0144505-11-하도록 구성되는 삭제 서브 유닛; 및 상기 복수의 샘플 서치 결과의 나머지 부분 각자와 업데이트된 상기 제3 샘플 회신 사이의 일치도에 기반하여,상기 복수의 샘플 서치 결과 중 모든 샘플 서치 결과에 대한 배열을 완성할 때까지 상기 나머지 부분에 대하여상기 배열 작업을 반복하도록 구성되는 배열 서브 유닛을 포함하는 것을 특징으로 하는 트레이닝 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제43항 또는 제44항에 있어서, 상기 검색 모델은 배열 서브 모델 및 소환 서브 모델을 포함하고, 상기 트레이닝 유닛은, 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델의 배열 서브 모델을 트레이닝하도록 구성되는제1 트레이닝 서브 유닛; 및 트레이닝된 상기 배열 서브 모델을 교사 모델로 하여, 상기 소환 서브 모델을 트레이닝하도록 구성되는 제2 트레이닝 서브 유닛을 포함하는 것을 특징으로 하는 트레이닝 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제42항 내지 제44항 중 어느 한 항에 있어서, 상기 트레이닝 장치는, 제4 샘플 초기 입력, 외부 기억 장치에 의해 인식될 수 있는 제4 샘플 중간 입력, 샘플 기억 결과 및 제4 샘플회신을 포함하는 제4 샘플 데이터를 획득하도록 구성되되, 상기 제4 샘플 중간 입력은 상기 제4 샘플 초기 입력을 기반으로 결정된 것인 제7 획득 유닛; 외부 기억 장치가 상기 제4 샘플 중간 입력을 기반으로 결정한 예측 기억 결과를 획득하도록 구성되는 제8 획득유닛; 상기 예측 기억 결과와 상기 샘플 기억 결과의 비교에 기반하여, 상기 외부 기억 장치의 파라미터를 조정하도록구성되는 제3 파라미터 조정 유닛; 적어도 상기 제4 샘플 초기 입력 및 상기 샘플 기억 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제4 샘플타겟 입력을 결정하도록 구성되는 제3 결정 유닛; 상기 딥러닝 모델을 이용하여 상기 제4 샘플 타겟 입력을 처리함으로써, 제4 예측 회신을 획득하도록 구성되는제3 처리 유닛; 및 상기 제4 샘플 회신과 상기 제4 예측 회신의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하도록 구성되는 제4 파라미터 조정 유닛을 더 포함하는 것을 특징으로 하는 트레이닝 장치."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "전자 기기로서, 상기 전자 기기는, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행될 수 있는 명령이 저장되며, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제23항 중 어느 한 항에 따른방법을 수행할 수 있도록 하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2023-0130660", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제23항 중 어느 한 항에 따른 방법을 수행하도록 하는 것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체.공개특허 10-2023-0144505-12-청구항 49 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 명령을 포함하고, 상기 명령이 적어도 하나의 프로세서에 의해 실행될 경우 제1항 내지제23항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 인공 지능"}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로, 특히 자연 언어 처리 및 딥러닝 등 기술분야에 관한, 딥러닝 모 델이 사용자 입력 데이터에 기반하여 생성한 회신 데이터의 품질을 향상할 수 있는 딥러닝 모델 기반의 데이터 생성 방법, 트레이닝 방법 및 장치를 제공한다. 데이터 생성 방법은, 사용자 입력 데이터에 기반하여 딥러닝 모 (뒷면에 계속) 대 표 도 - 도2"}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2023-0144505 델의 초기 입력을 결정하는 단계; 모델의 제1 출력을 획득하되, 모델에 응답하여 초기 입력을 기반으로 생성한 회신을 결정하기 위해서는 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 제1 출력은 제1 기능 컴포넌트 를 호출하기 위한 제1 토큰 및 초기 입력을 기반으로 결정되고 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중 간 문의를 포함하는 단계; 제1 기능 컴포넌트가 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하는 단 계; 초기 입력 및 제1 중간 결과에 기반하여 모델에 사용되는 제2 입력을 결정하는 단계; 및 모델의 제2 출력을 획득하여 초기 입력에 대한 회신을 생성하는 단계를 포함한다. CPC특허분류 G06N 3/08 (2023.01) 발명자 톈 하오 중국 100085 베이징 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층 쑨 위 중국 100085 베이징 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층위 톈 중국 100085 베이징 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층 훙 더우 중국 100085 베이징 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 딥러닝 모델 기반의 데이터 생성 방법으로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있고, 상기 데이터 생성 방법은, 사용자로부터의 입력 데이터에 기반하여, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계; 상기 딥러닝 모델의 제1 출력을 획득하되, 상기 딥러닝 모델에 응답하여 상기 초기 입력을 기반으로 생성한 회 신을 결정하기 위해서는 상기 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 상기 제1 출력은 상 기 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 초기 입력을 기반으로 결정되고 상기 제1 기능 컴포넌 트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 단계; 상기 제1 기능 컴포넌트가 상기 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하는 단계; 적어도 상기 초기 입력 및 상기 제1 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하는 단계; 및 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하는 단계를 포함하는 것을 특징으로 하는 딥러닝 모델 기반의 데이터 생성 방법. 청구항 2 제1항에 있어서, 상기 제1 기능 컴포넌트는 외부 기억 장치이고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세 트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상 기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 3 제2항에 있어서, 상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기 입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목인 것을 특징 으로 하는 데이터 생성 방법. 청구항 4 제2항에 있어서, 상기 방법은, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 임의의 하나의 데이 터 세트 사이의 유사도가 제2 임계값보다 낮다고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이 터 세트 그룹에 등록하는 단계를 더 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 5 제2항에 있어서, 상기 방법은, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 제2 데이터 세트 사이의 유사도가 제3 임계값보다 높다고 결정하며 상기 제1 데이터 세트와 상기 제2 데이터 세트가 서로 충돌된다 고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이터 세트 그룹에 등록하고, 상기 제1 데이터 세 트 그룹에서 상기 제2 데이터 세트를 삭제하는 단계를 더 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 6 제2항에 있어서, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 상기 세트 중 과거 입력 데이터 항목 및 과거 회신 항목과 대응되는 등록 시간 항목을 더 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 7 제6항에 있어서, 상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기 입력 데이터와의 유사도가 제1 임계값보다 높고 타임스탬프가 최신인 과거 입력 데이터 항목에 대응되는 과거 회신 항목인 것을 특징으로 하는 데이터 생성 방법. 청구항 8 제6항에 있어서, 상기 방법은, 상기 등록 시간 항목에 기반하여, 상기 외부 기억 장치에서 시효가 지난 데이터 세트를 삭제하는 단계를 더 포 함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 9 제1항에 있어서, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계는, 상기 입력 데이터에 기반하여, 외부 기억 장치에서 상기 입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목을 획득하는 단계; 및 상기 입력 데이터 및 상기 과거 회신 항목에 기반하여, 상기 초기 입력을 결정하는 단계를 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 10 제1항에 있어서, 상기 초기 입력은 상기 입력 데이터의 컨텍스트 정보를 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 11 제10항에 있어서, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계는, 외부 기억 장치에서 상기 입력 데이터 및 상기 컨텍스트 정보와의 유사도가 제4 임계값에 부합되는 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목을 획득하는 단계; 및 상기 입력 데이터, 상기 컨텍스트 정보 및 상기 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목에 기 반하여, 상기 딥러닝 모델에 사용되는 상기 초기 입력을 결정하는 단계를 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 12 제9항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 외부 서치 엔진인 것을 특징으로 하는 데이터 생성 방법. 청구항 13 제9항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델인 것을 특징으로 하는 데 이터 생성 방법. 청구항 14 제9항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인 터페이스인 것을 특징으로 하는 데이터 생성 방법. 청구항 15 제1항 내지 제11항 중 어느 한 항에 있어서, 적어도 상기 초기 입력 및 상기 제1 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하는 단계는, 상기 초기 입력, 상기 제1 중간 결과 및 상기 제1 중간 문의에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입 력을 결정하는 단계를 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 16 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 제2 출력은 상기 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함 하지 않고, 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하는 단계는, 상기 제2 출력을 상기 초기 입력에 대한 상기 회신으로 하는 단계를 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 17 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 제2 출력은 제2 기능 컴포넌트를 호출하기 위한 제2 토큰 및 상기 제2 입력을 기반으로 얻어지고 상기 제2 기능 컴포넌트에 의해 인식될 수 있는 제2 중간 문의를 포함하고, 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하는 단계는, 상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 단계; 및 상기 딥러닝 모델의 제N 출력에 제N 기능 컴포넌트를 호출하기 위한 제N 토큰 및 제N 입력을 기반으로 얻어지고 상기 제N 기능 컴포넌트에 의해 인식될 수 있는 제N 중간 문의가 포함되는 것에 응답하여, 제N+1 출력에 상기 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰이 포함되지 않다고 결정될 때 까지 상기 제N 출력과 대응되는 기능 호출 작업을 수행하고, 상기 제N+1 출력을 상기 초기 입력에 대한 상기 회 신으로 하되, N은 2보다 큰 정수인 단계를 포함하며, 상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 단계는, 상기 제2 기능 컴포넌트가 상기 제2 중간 문의에 기반하여 결정한 제2 중간 결과를 획득하는 단계;적어도 상기 제2 입력 및 상기 제2 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제3 입력을 결정하는 단계; 및 상기 딥러닝 모델의 제3 출력을 획득하는 단계를 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 18 제17항에 있어서, 상기 제2 기능 컴포넌트 및 제N 기능 컴포넌트는 각각, 외부 서치 엔진; 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델; 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스; 및 외부 기억 장치를 포함하는 기능 컴포넌트 그룹 중 하나이되, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이 터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 방법. 청구항 19 딥러닝 모델의 트레이닝 방법으로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성하고, 상기 트레이닝 방법은, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하되, 상기 제1 샘플 초기 입력은 상 기 딥러닝 모델과 구별되는 제1 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하며, 상기 제1 샘플 출력 은 상기 제1 기설정된 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 제1 기설정된 기능 컴포넌트에 의해 인 식될 수 있는 제1 샘플 중간 입력을 포함하는 단계; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하되, 상기 제2 샘플 초기 입력은 상 기 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하지 않으며, 상기 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않는 단계; 상기 딥러닝 모델을 이용하여 상기 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력을 획득하는 단계; 상기 제1 샘플 출력과 상기 제1 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하는 단계; 상기 딥러닝 모델을 이용하여 상기 제2 샘플 초기 입력을 처리함으로써, 제2 예측 출력을 획득하는 단계; 및 상기 제2 샘플 출력과 상기 제2 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하는 단계를 포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법. 청구항 20 제19항에 있어서, 상기 트레이닝 방법은, 제3 샘플 초기 입력, 샘플 서치 문의, 복수의 샘플 서치 결과, 및 상기 딥러닝 모델이 상기 제3 샘플 초기 입력 에 대한 제3 샘플 회신을 포함하는 제3 샘플 데이터를 획득하되, 상기 샘플 서치 문의는 상기 딥러닝 모델이 상 기 제3 샘플 초기 입력을 기반으로 생성한 샘플 중간 입력이고, 상기 샘플 중간 입력은 상기 딥러닝 모델과 구 별되는 검색 모델에 의해 인식될 수 있으며, 상기 복수의 샘플 서치 결과는 상기 검색 모델이 상기 샘플 서치 문의에 기반하여 출력한 결과인 단계; 상기 복수의 샘플 서치 결과 각자와 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결 과에 대하여 배열 작업을 수행하는 단계; 및 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델을 트레이닝하는 단계를 더 포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법. 청구항 21 제20항에 있어서, 상기 복수의 샘플 서치 결과 각자와 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결 과에 대하여 배열 작업을 수행하는 단계는, 상기 복수의 샘플 서치 결과에서 현재 일치도가 가장 높은 제1 샘플 서치 결과를 선별하는 단계; 상기 제3 샘플 회신과 상기 제1 샘플 서치 결과 사이의 중합 내용을 삭제하여, 상기 제3 샘플 회신을 업데이트 하는 단계; 및 상기 복수의 샘플 서치 결과의 나머지 부분 각자와 업데이트된 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결과 중 모든 샘플 서치 결과에 대한 배열을 완성할 때까지 상기 나머지 부분에 대하여 상기 배열 작업을 반복하는 단계를 포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법. 청구항 22 제20항 또는 제21항에 있어서, 상기 검색 모델은 배열 서브 모델 및 소환 서브 모델을 포함하고, 배열된 상기 복수의 샘플 서치 결과에 기반하 여, 상기 검색 모델을 트레이닝하는 단계는, 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델의 배열 서브 모델을 트레이닝하는 단계; 및 트레이닝된 상기 배열 서브 모델을 교사 모델로 하여, 상기 소환 서브 모델을 트레이닝하는 단계를 포함하는 것 을 특징으로 하는 딥러닝 모델의 트레이닝 방법. 청구항 23 제19항 내지 제21항 중 어느 한 항에 있어서, 상기 방법은, 제4 샘플 초기 입력, 외부 기억 장치에 의해 인식될 수 있는 제4 샘플 중간 입력, 샘플 기억 결과 및 제4 샘플 회신을 포함하는 제4 샘플 데이터를 획득하되, 상기 제4 샘플 중간 입력은 상기 제4 샘플 초기 입력을 기반으로 결정된 것인 단계; 외부 기억 장치가 상기 제4 샘플 중간 입력을 기반으로 결정한 예측 기억 결과를 획득하는 단계; 상기 예측 기억 결과와 상기 샘플 기억 결과의 비교에 기반하여, 상기 외부 기억 장치의 파라미터를 조정하는 단계; 적어도 상기 제4 샘플 초기 입력 및 상기 샘플 기억 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제4 샘플 타겟 입력을 결정하는 단계; 상기 딥러닝 모델을 이용하여 상기 제4 샘플 타겟 입력을 처리함으로써, 제4 예측 회신을 획득하는 단계; 및 상기 제4 샘플 회신과 상기 제4 예측 회신의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하는 단계를 더 포함하는 것을 특징으로 하는 딥러닝 모델의 트레이닝 방법. 청구항 24 딥러닝 모델 기반의 데이터 생성 장치로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있고, 상기 데이터 생성 장치는, 사용자로부터의 입력 데이터에 기반하여, 상기 딥러닝 모델에 사용되는 초기 입력을 결정하도록 구성되는 제1 결정 유닛; 상기 딥러닝 모델의 제1 출력을 획득하도록 구성되되, 상기 딥러닝 모델에 응답하여 상기 초기 입력을 기반으로생성한 회신을 결정하기 위해서는 상기 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 상기 제1 출력은 상기 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 초기 입력을 기반으로 결정되고 상기 제1 기 능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 제1 획득 유닛; 상기 제1 기능 컴포넌트가 상기 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하도록 구성되는 제2 획 득 유닛; 적어도 상기 초기 입력 및 상기 제1 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입력을 결정하도 록 구성되는 제2 결정 유닛; 및 상기 딥러닝 모델의 제2 출력을 획득하여, 상기 초기 입력에 대한 상기 회신을 생성하도록 구성되는 제3 획득 유닛을 포함하는 것을 특징으로 하는 딥러닝 모델 기반의 데이터 생성 장치. 청구항 25 제24항에 있어서, 상기 제1 기능 컴포넌트는 외부 기억 장치이고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세 트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상 기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 26 제25항에 있어서, 상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기 입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목인 것을 특징 으로 하는 데이터 생성 장치. 청구항 27 제25항에 있어서, 상기 장치는, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 임의의 하나의 데이 터 세트 사이의 유사도가 제2 임계값보다 낮다고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이 터 세트 그룹에 등록하도록 구성되는 제1 등록 유닛을 더 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 28 제25항에 있어서, 상기 장치는, 상기 입력 데이터 및 상기 회신에 기반한 제1 데이터 세트와 상기 제1 데이터 세트 그룹 중 제2 데이터 세트 사 이의 유사도가 제3 임계값보다 높다고 결정하며 상기 제1 데이터 세트와 상기 제2 데이터 세트가 서로 충돌된다 고 결정한 것에 응답하여, 상기 제1 데이터 세트를 상기 제1 데이터 세트 그룹에 등록하고, 상기 제1 데이터 세 트 그룹에서 상기 제2 데이터 세트를 삭제하도록 구성되는 제2 등록 유닛을 더 포함하는 것을 특징으로 하는 데 이터 생성 장치. 청구항 29 제25항에 있어서, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 상기 세트 중 과거 입력 데이터 항목 및 과거 회신 항목과 대응되는 등록 시간 항목을 더 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 30 제29항에 있어서, 상기 제1 중간 문의는 상기 입력 데이터에 기반하고, 상기 제1 중간 결과는 상기 제1 데이터 세트 그룹 중 상기 입력 데이터와의 유사도가 제1 임계값보다 높고 타임스탬프가 최신인 과거 입력 데이터 항목에 대응되는 과거 회신 항목인 것을 특징으로 하는 데이터 생성 장치. 청구항 31 제29항에 있어서, 상기 장치는, 상기 등록 시간 항목에 기반하여, 상기 외부 기억 장치에서 시효가 지난 데이터 세트를 삭제하도록 구성되는 삭 제 유닛을 더 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 32 제24항에 있어서, 상기 제1 결정 유닛은, 상기 입력 데이터에 기반하여, 외부 기억 장치에서 상기 입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목을 획득하도록 구성되는 제1 획득 서브 유닛; 및 상기 입력 데이터 및 상기 과거 회신 항목에 기반하여, 상기 초기 입력을 결정하도록 구성되는 제1 결정 서브 유닛을 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 33 제24항에 있어서, 상기 초기 입력은 상기 입력 데이터의 컨텍스트 정보를 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 34 제33항에 있어서, 상기 제1 결정 유닛은, 외부 기억 장치에서 상기 입력 데이터 및 상기 컨텍스트 정보와의 유사도가 제4 임계값에 부합되는 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목을 획득하도록 구성되는 제2 획득 서브 유닛; 및 상기 입력 데이터, 상기 컨텍스트 정보 및 상기 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목에 기 반하여, 상기 딥러닝 모델에 사용되는 상기 초기 입력을 결정하도록 구성되는 제2 결정 서브 유닛을 포함하고, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 35 제32항 내지 제34항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 외부 서치 엔진인 것을 특징으로 하는 데이터 생성 장치. 청구항 36 제32항 내지 제34항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델인 것을 특징으로 하는 데 이터 생성 장치.청구항 37 제32항 내지 제34항 중 어느 한 항에 있어서, 상기 제1 기능 컴포넌트는 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인 터페이스인 것을 특징으로 하는 데이터 생성 장치. 청구항 38 제24항 내지 제34항 중 어느 한 항에 있어서, 상기 제2 결정 유닛은, 상기 초기 입력, 상기 제1 중간 결과 및 상기 제1 중간 문의에 기반하여, 상기 딥러닝 모델에 사용되는 제2 입 력을 결정하도록 구성되는 제3 결정 서브 유닛을 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 39 제24항 내지 제34항 중 어느 한 항에 있어서, 상기 제2 출력은 상기 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함 하지 않고, 상기 제3 획득 유닛은, 상기 제2 출력을 상기 초기 입력에 대한 상기 회신으로 하도록 구성되는 회신 서브 유닛을 포함하는 것을 특징 으로 하는 데이터 생성 장치. 청구항 40 제24항 내지 제34항 중 어느 한 항에 있어서, 상기 제2 출력은 제2 기능 컴포넌트를 호출하기 위한 제2 토큰 및 상기 제2 입력을 기반으로 얻어지고 상기 제2 기능 컴포넌트에 의해 인식될 수 있는 제2 중간 문의를 포함하고, 상기 제3 획득 유닛은, 상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하도록 구성되는 제3 획득 서브 유닛; 및 상기 딥러닝 모델의 제N 출력에 제N 기능 컴포넌트를 호출하기 위한 제N 토큰 및 제N 입력을 기반으로 얻어지고 상기 제N 기능 컴포넌트에 의해 인식될 수 있는 제N 중간 문의가 포함되는 것에 응답하여, 제N+1 출력에 상기 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰이 포함되지 않다고 결정될 때 까지 상기 제N 출력과 대응되는 기능 호출 작업을 수행하고, 상기 제N+1 출력을 상기 초기 입력에 대한 상기 회 신으로 하되, N은 2보다 큰 정수이도록 구성되는 호출 서브 유닛을 포함하며, 상기 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 것은, 상기 제2 기능 컴포넌트가 상기 제2 중간 문의에 기반하여 결정한 제2 중간 결과를 획득하는 것; 적어도 상기 제2 입력 및 상기 제2 중간 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제3 입력을 결정하는 것; 및 상기 딥러닝 모델의 제3 출력을 획득하는 것을 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 41 제40항에 있어서, 상기 제2 기능 컴포넌트 및 제N 기능 컴포넌트는 각각, 외부 서치 엔진; 상기 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델; 상기 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스; 및 외부 기억 장치를 포함하는 기능 컴포넌트 그룹 중 하나이되, 상기 외부 기억 장치에는 상기 사용자와 관련된 제1 데이터 세트 그룹이 저장되며, 상기 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이 터 항목 및 상기 딥러닝 모델이 상기 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함하는 것을 특징으로 하는 데이터 생성 장치. 청구항 42 딥러닝 모델의 트레이닝 장치로서, 상기 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성하고, 상기 트레이닝 장치는, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하도록 구성되되, 상기 제1 샘플 초기 입력은 상기 딥러닝 모델과 구별되는 제1 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하며, 상기 제1 샘플 출력은 상기 제1 기설정된 기능 컴포넌트를 호출하기 위한 제1 토큰 및 상기 제1 기설정된 기능 컴포넌트 에 의해 인식될 수 있는 제1 샘플 중간 입력을 포함하는 제4 획득 유닛; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하도록 구성되되, 상기 제2 샘플 초기 입력은 상기 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하는 의도 표현을 포함하지 않으며, 상기 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않는 제5 획득 유닛; 상기 딥러닝 모델을 이용하여 상기 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력을 획득하도록 구성되는 제1 처리 유닛; 상기 제1 샘플 출력과 상기 제1 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하도록 구성 되는 제1 파라미터 조정 유닛; 상기 딥러닝 모델을 이용하여 상기 제2 샘플 초기 입력을 처리함으로써, 제2 예측 출력을 획득하도록 구성되는 제2 처리 유닛; 및 상기 제2 샘플 출력과 상기 제2 예측 출력의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하도록 구성 되는 제2 파라미터 조정 유닛을 포함하는 것을 특징으로 하는 트레이닝 장치. 청구항 43 제42항에 있어서, 상기 트레이닝 장치는, 제3 샘플 초기 입력, 샘플 서치 문의, 복수의 샘플 서치 결과, 및 상기 딥러닝 모델이 상기 제3 샘플 초기 입력 에 대한 제3 샘플 회신을 포함하는 제3 샘플 데이터를 획득하도록 구성되되, 상기 샘플 서치 문의는 상기 딥러 닝 모델이 상기 제3 샘플 초기 입력을 기반으로 생성한 샘플 중간 입력이고, 상기 샘플 중간 입력은 상기 딥러 닝 모델과 구별되는 검색 모델에 의해 인식될 수 있으며, 상기 복수의 샘플 서치 결과는 상기 검색 모델이 상기 샘플 서치 문의에 기반하여 출력한 결과인 제6 획득 유닛; 상기 복수의 샘플 서치 결과 각자와 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결 과에 대하여 배열 작업을 수행하도록 구성되는 배열 유닛; 및 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델을 트레이닝하도록 구성되는 트레이닝 유닛을 더 포함하는 것을 특징으로 하는 트레이닝 장치. 청구항 44 제43항에 있어서, 상기 배열 유닛은, 상기 복수의 샘플 서치 결과에서 현재 일치도가 가장 높은 제1 샘플 서치 결과를 선별하도록 구성되는 선별 서 브 유닛; 상기 제3 샘플 회신과 상기 제1 샘플 서치 결과 사이의 중합 내용을 삭제하여, 상기 제3 샘플 회신을 업데이트하도록 구성되는 삭제 서브 유닛; 및 상기 복수의 샘플 서치 결과의 나머지 부분 각자와 업데이트된 상기 제3 샘플 회신 사이의 일치도에 기반하여, 상기 복수의 샘플 서치 결과 중 모든 샘플 서치 결과에 대한 배열을 완성할 때까지 상기 나머지 부분에 대하여 상기 배열 작업을 반복하도록 구성되는 배열 서브 유닛을 포함하는 것을 특징으로 하는 트레이닝 장치. 청구항 45 제43항 또는 제44항에 있어서, 상기 검색 모델은 배열 서브 모델 및 소환 서브 모델을 포함하고, 상기 트레이닝 유닛은, 배열된 상기 복수의 샘플 서치 결과에 기반하여, 상기 검색 모델의 배열 서브 모델을 트레이닝하도록 구성되는 제1 트레이닝 서브 유닛; 및 트레이닝된 상기 배열 서브 모델을 교사 모델로 하여, 상기 소환 서브 모델을 트레이닝하도록 구성되는 제2 트 레이닝 서브 유닛을 포함하는 것을 특징으로 하는 트레이닝 장치. 청구항 46 제42항 내지 제44항 중 어느 한 항에 있어서, 상기 트레이닝 장치는, 제4 샘플 초기 입력, 외부 기억 장치에 의해 인식될 수 있는 제4 샘플 중간 입력, 샘플 기억 결과 및 제4 샘플 회신을 포함하는 제4 샘플 데이터를 획득하도록 구성되되, 상기 제4 샘플 중간 입력은 상기 제4 샘플 초기 입력 을 기반으로 결정된 것인 제7 획득 유닛; 외부 기억 장치가 상기 제4 샘플 중간 입력을 기반으로 결정한 예측 기억 결과를 획득하도록 구성되는 제8 획득 유닛; 상기 예측 기억 결과와 상기 샘플 기억 결과의 비교에 기반하여, 상기 외부 기억 장치의 파라미터를 조정하도록 구성되는 제3 파라미터 조정 유닛; 적어도 상기 제4 샘플 초기 입력 및 상기 샘플 기억 결과에 기반하여, 상기 딥러닝 모델에 사용되는 제4 샘플 타겟 입력을 결정하도록 구성되는 제3 결정 유닛; 상기 딥러닝 모델을 이용하여 상기 제4 샘플 타겟 입력을 처리함으로써, 제4 예측 회신을 획득하도록 구성되는 제3 처리 유닛; 및 상기 제4 샘플 회신과 상기 제4 예측 회신의 비교에 기반하여, 상기 딥러닝 모델의 파라미터를 조정하도록 구성 되는 제4 파라미터 조정 유닛을 더 포함하는 것을 특징으로 하는 트레이닝 장치. 청구항 47 전자 기기로서, 상기 전자 기기는, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행될 수 있는 명령이 저장되며, 상기 명령은 상기 적어 도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제23항 중 어느 한 항에 따른 방법을 수행할 수 있도록 하는 것을 특징으로 하는 전자 기기. 청구항 48 컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제23항 중 어느 한 항에 따른 방법을 수행하도록 하는 것을 특징 으로 하는 비일시적 컴퓨터 판독 가능 저장 매체.청구항 49 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 명령을 포함하고, 상기 명령이 적어도 하나의 프로세서에 의해 실행될 경우 제1항 내지 제23항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램. 발명의 설명 기 술 분 야"}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 3, "content": "본 발명은 인공 지능 기술분야에 관한 것으로, 특히 자연 언어 처리 및 딥러닝 등 기술분야에 관한 것이며, 구 체적으로 딥러닝 모델 기반의 데이터 생성 방법, 딥러닝 모델의 트레이닝 방법, 딥러닝 모델 기반의 데이터 생 성 장치, 딥러닝 모델의 트레이닝 장치, 전자 기기 및 컴퓨터 판독 가능 저장 매체에 관한 것이다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능은 컴퓨터가 인간의 일부 사고 과정 및 지능 행동(예를 들어 학습, 추리, 사고, 계획 등)을 시뮬레이 션하도록 하는 학문으로서, 하드웨어 방면의 기술과 소프트웨어 방면의 기술을 모두 가지고 있다. 인공 지능 하 드웨어 기술은 일반적으로 예를 들어 센서, 전용 인공 지능 칩, 클라우드 컴퓨팅, 분산 저장, 빅데이터 처리 등 기술을 포함하고; 인공 지능 소프트웨어 기술은 주로 자연 언어 처리 기술, 컴퓨터 비전 기술, 음성 인식 기술 및 머신 러닝/딥러닝, 빅데이터 처리 기술, 지식 그래프 기술 등 방향을 포함한다. 이 부분에서 설명되는 방법이 반드시 이전에 구상되었거나 사용된 방법인 것은 아니고, 달리 명시되지 않는 한, 이 부분에서 설명되는 임의의 방법이 이 부분에 포함된다고 선행기술로 간주되어서는 안된다. 유사하게, 달리 명시되지 않는 한, 이 부분에서 언급되는 문제는 임의의 선행기술에서 인정된 것을 간주되어서는 안된다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 딥러닝 모델 기반의 데이터 생성 방법, 딥러닝 모델의 트레이닝 방법, 딥러닝 모델 기반의 데이터 생 성 장치, 딥러닝 모델의 트레이닝 장치, 전자 기기 및 컴퓨터 판독 가능 저장 매체를 제공한다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양태에 따르면, 딥러닝 모델 기반의 데이터 생성 방법을 제공한다. 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있다. 데이터 생성 방법은, 사용자로부터의 입력 데이터에 기반하 여, 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계; 딥러닝 모델의 제1 출력을 획득하되, 딥러닝 모델에 응답하여 초기 입력을 기반으로 생성한 회신을 결정하기 위해서는 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 제1 출력은 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 초기 입력을 기반으로 결정되고 제 1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 단계; 제1 기능 컴포넌트가 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하는 단계; 적어도 초기 입력 및 제1 중간 결과에 기반하여, 딥러닝 모델 에 사용되는 제2 입력을 결정하는 단계; 및 딥러닝 모델의 제2 출력을 획득하여, 초기 입력에 대한 회신을 생성 하는 단계를 포함한다. 본 발명의 다른 양태에 따르면, 딥러닝 모델의 트레이닝 방법을 제공한다. 딥러닝 모델은 사용자의 입력 데이터 에 기반하여 회신 데이터를 생성한다. 트레이닝 방법은, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하되, 제1 샘플 초기 입력은 딥러닝 모델과 구별되는 제1 기설정된 기능 컴포넌트를 호출하 기 위한 의도 표현을 포함하며, 여기서, 제1 샘플 출력은 제1 기설정된 기능 컴포넌트를 호출하기 위한 제1 토 큰 및 제1 기설정된 기능 컴포넌트에 의해 인식될 수 있는 제1 샘플 중간 입력을 포함하는 단계; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하되, 제2 샘플 초기 입력은 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 의도 표현을 포함하지 않으며, 여기서, 제2 샘플 출력 은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않는 단계; 딥러닝 모델을 이 용하여 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력을 획득하는 단계; 제1 샘플 출력과 제1 예측 출력의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하는 단계; 딥러닝 모델을 이용하여 제2 샘플 초기 입력을 처리함으로써, 제2 예측 출력을 획득하는 단계; 및 제2 샘플 출력과 제2 예측 출력의 비교에 기반하여, 딥러닝 모 델의 파라미터를 조정하는 단계를 포함한다. 본 발명의 또 다른 양태에 따르면, 딥러닝 모델 기반의 데이터 생성 장치를 제공한다. 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있다. 데이터 생성 장치는, 사용자로부터의 입력 데이터에 기 반하여, 딥러닝 모델에 사용되는 초기 입력을 결정하도록 구성되는 제1 결정 유닛; 딥러닝 모델의 제1 출력을 획득하도록 구성되되, 딥러닝 모델에 응답하여 초기 입력을 기반으로 생성한 회신을 결정하기 위해서는 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 제1 출력은 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 초기 입력을 기반으로 결정되고 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 제1 획 득 유닛; 제1 기능 컴포넌트가 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하도록 구성되는 제2 획 득 유닛; 적어도 초기 입력 및 제1 중간 결과에 기반하여, 딥러닝 모델에 사용되는 제2 입력을 결정하도록 구성 되는 제2 결정 유닛; 및 딥러닝 모델의 제2 출력을 획득하여, 초기 입력에 대한 회신을 생성하도록 구성되는 제 3 획득 유닛을 포함한다. 본 발명의 또 다른 양태에 따르면, 딥러닝 모델의 트레이닝 장치를 제공한다. 딥러닝 모델은 사용자의 입력 데 이터에 기반하여 회신 데이터를 생성한다. 트레이닝 장치는, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하도록 구성되되, 제1 샘플 초기 입력은 딥러닝 모델과 구별되는 제1 기설정된 기능 컴 포넌트를 호출하기 위한 의도 표현을 포함하며, 여기서, 제1 샘플 출력은 제1 기설정된 기능 컴포넌트를 호출하 기 위한 제1 토큰 및 제1 기설정된 기능 컴포넌트에 의해 인식될 수 있는 제1 샘플 중간 입력을 포함하는 제4 획득 유닛; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하도록 구성되되, 제2 샘 플 초기 입력은 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 의도 표현을 포함하지 않으며, 여기서, 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰 을 포함하지 않는 제5 획득 유닛; 딥러닝 모델을 이용하여 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력 을 획득하도록 구성되는 제1 처리 유닛; 제1 샘플 출력과 제1 예측 출력의 비교에 기반하여, 딥러닝 모델의 파 라미터를 조정하도록 구성되는 제1 파라미터 조정 유닛; 딥러닝 모델을 이용하여 제2 샘플 초기 입력을 처리함 으로써, 제2 예측 출력을 획득하도록 구성되는 제2 처리 유닛; 및 제2 샘플 출력과 제2 예측 출력의 비교에 기 반하여, 딥러닝 모델의 파라미터를 조정하도록 구성되는 제2 파라미터 조정 유닛을 포함한다. 본 발명의 하나 이상의 실시예에 따르면, 본 발명은 딥러닝 모델을 이용하여 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하는지 여부를 결정하고, 제1 기능 컴포넌트를 호출해야 한다고 결정할 경우 딥러닝 모델 을 이용하여 상기 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 생성하며, 나아가 제1 중간 문의 를 이용하여 제1 기능 컴포넌트를 호출하여 제1 중간 결과를 얻고, 최종적으로 딥러닝 모델을 이용하여 제1 중 간 결과에 기반하여 사용자의 초기 입력에 대한 결과를 생성한다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 방식을 통해, 자체적으로 이해 및 생성 등 임무를 수행할 수 있는 딥러닝 모델에 대하여, 능력 강화를 더 구현함으로써, 최종적으로 생성된 회신의 품질을 향상시킨다. 이 밖에, 딥러닝 모델을 이용하여 외부 기능 컴포 넌트에 의해 인식될 수 있는 중간 문의를 직접 생성하는 것을 통해, 중간 문의 및 획득한 중간 결과가 사용자의 초기 입력 중의 잠재적 의도에 더 부합되도록 함으로써, 모델이 사용자의 요구를 만족하는 회신을 출력할 수 있 도록 한다. 이해해야 할 것은, 이 부분에서 설명되는 내용은 본 발명의 실시예의 핵심 또는 중요한 특징을 식별하기 위한 것이 아니며, 본 발명의 범위를 한정하려는 것도 아니다. 본 발명의 다른 특징은 아래의 명세서에 의해 쉽게 이 해될 것이다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래 도면을 결부하여 본 발명의 예시적 실시예를 설명하되, 여기에는 이해를 돕기 위한 본 발명의 실시예의 다"}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "양한 세부사항들이 포함되지만, 이들은 단지 예시적인 것으로 간주되어야 한다. 따라서, 본 기술분야의 통상의 기술자는 본 발명의 범위 및 정신을 벗어나지 않는 전제 하에 여기서 설명된 실시예에 대해 다양한 변형 및 수 정을 진행할 수 있음을 이해해야 할 것이다. 마찬가지로, 명확 및 간략을 위해, 아래의 설명에서 공지 기능 및 구조에 대한 설명을 생략한다. 본 발명에서, 달리 설명되지 않는 한, 용어 \"제1\", \"제2\" 등은 다양한 요소를 설명하기 위한 것이고 이러한 요 소의 위치 관계, 시간 순서적 관계 또는 중요성 관계 등을 한정하려는 것이 아니며, 이러한 용어는 단지 하나의 요소를 다른 요소와 구별하기 위한 것이다. 일부 예시에서, 제1 요소 및 제2 요소는 상기 요소의 동일한 구현예 를 가리킬 수 있고, 일부 상황에서, 문맥상 이들은 상이한 구현예를 가리킬 수도 있다. 본 발명 중 다양한 예시에 대한 설명에서 사용되는 용어는 단지 특정 예시를 설명하기 위한 것일 뿐, 한정하려 는 것이 아니다. 문맥상 다른 명확한 표명이 없는 한, 요소의 수량을 특별히 한정하지 않으면, 해당 요소는 하 나일 수 있고 복수일 수도 있다. 이 밖에, 본 발명에서 사용되는 용어 \"및/또는\"은 열거된 항목 중 어느 하나 및 모든 가능한 조합 방식을 포함한다. 관련 기술에서, 지능화 시스템은 사용자의 입력 데이터에 기반하여 대응되는 회신 내용을 생성할 수 있다. 그러 나, 현재 지능화 시스템은 사용자의 입력 데이터에 대한 처리 능력이 비교적 약하고, 생성되는 회신 내용의 품질이 좋지 않다. 상기 문제를 해결하기 위해, 본 발명은 딥러닝 모델을 이용하여 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하는지 여부를 결정하고, 제1 기능 컴포넌트를 호출해야 한다고 결정할 경우, 딥러닝 모델을 이용하여 상기 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 생성하며, 나아가 제1 중간 문의를 이용하여 제1 기능 컴포넌트를 호출하여 제1 중간 결과를 얻고, 최종적으로 딥러닝 모델을 이용하여 제1 중간 결과에 기 반하여 사용자의 초기 입력에 대한 결과를 생성한다. 상기 방식을 통해, 자체적으로 이해 및 생성 등 임무를 수행할 수 있는 딥러닝 모델에 대하여, 능력 강화를 더 구현함으로써, 최종적으로 생성된 회신의 품질을 향상시킨다. 이 밖에, 딥러닝 모델을 이용하여 외부 기능 컴포 넌트에 의해 인식될 수 있는 중간 문의를 직접 생성하는 것을 통해, 중간 문의 및 획득한 중간 결과가 사용자의 초기 입력 중의 잠재적 의도에 더 부합되도록 함으로써, 모델이 사용자의 요구를 만족하는 회신을 출력할 수 있 도록 한다. 아래 도면을 결합하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 발명의 실시예에 따른 본문에서 설명되는 다양한 방법 및 장치가 구현될 수 있는 예시적 시스템(10 0)의 모식도를 도시한다. 도 1을 참조하면, 상기 시스템은 하나 이상의 클라이언트 기기(101, 102, 103, 104, 105 및 106), 서버 및 하나 이상의 클라이언트 기기를 서버에 커플링하는 하나 이상의 통신 네 트워크를 포함한다. 클라이언트 기기(101, 102, 103, 104, 105 및 106)는 하나 이상의 애플리케이션 프로 그램을 실행하도록 구성될 수 있다. 본 발명의 실시예에서, 서버는 본 발명의 데이터 생성 방법 또는 딥러닝 모델의 트레이닝 방법의 하나 이 상의 서비스 또는 소프트웨어 애플리케이션을 실행할 수 있도록 작동될 수 있다. 하나의 예시적 실시예에서, 서 버에는 지능화 시스템을 지원하는 딥러닝 모델이 구성될 수 있다. 일부 실시예에서, 서버는 다른 서비스 또는 소프트웨어 애플리케이션을 더 제공할 수 있고, 이러한 서비스 또는 소프트웨어 애플리케이션은 비가상 환경 및 가상 환경을 포함할 수 있다. 일부 실시예에서, 이러한 서비스 는 web 기반 서비스 또는 클라우드 서비스로 제공될 수 있고, 예를 들어 서비스형 소프트웨어(SaaS) 모델에서 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 사용자에게 제공될 수 있다. 도 1에 도시된 구성에서, 서버는 서버에 의해 실행되는 기능을 구현하는 하나 이상의 컴포넌트를 포 함할 수 있다. 이러한 컴포넌트는 하나 이상의 프로세서에 의해 실행될 수 있는 소프트웨어 컴포넌트, 하드웨어 컴포넌트 또는 이들의 조합을 포함할 수 있다. 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)를 조작 하는 사용자는 하나 이상의 클라이언트 애플리케이션 프로그램을 순차적으로 이용하여 서버와 인터랙션함 으로써, 이러한 컴포넌트에서 제공되는 서비스를 이용할 수 있다. 이해해야 할 것은, 시스템은 다양하게 구성될 수 있고, 이는 시스템과 상이할 수 있다. 따라서, 도 1은 본문에서 설명되는 다양한 방법을 구현하는 시스 템의 하나의 예시로서, 이를 한정하려는 것이 아니다. 사용자는 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)를 사용하여 지능화 시스템에 입력할 수 있다. 클라이언트 기기는 클라이언트 기기의 사용자가 클라이언트 기기와 인터랙션할 수 있도록 하는 인터페이스를 제 공할 수 있다. 클라이언트 기기는 상기 인터페이스를 통해 사용자에게 정보를 출력할 수도 있고, 예를 들어, 사 용자에게 지능화 시스템이 사용자 입력에 대하여 생성한 회신을 출력할 수 있다. 도 1에서는 단지 6 가지의 클"}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "라이언트 기기를 설명하였지만, 본 기술분야의 통상의 기술자라면, 본 발명은 임의의 수량의 클라이언트 기기를 지원할 수 있음을 이해할 수 있을 것이다. 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)는 예를 들어 휴대용 핸드헬드 기기, 범용 컴퓨터(예를 들면 개인 컴퓨터 및 랩톱), 워크 스테이션 컴퓨터, 웨어러블 기기, 스마트 스크린 기기, 셀프 서비스 단말 기 기, 서빙 로봇, 게임 시스템, 신 클라이언트, 다양한 메시지 송수신 기기, 센서 또는 다른 감지 기기 등과 같은 다양한 타입의 컴퓨터 기기를 포함할 수 있다. 이러한 컴퓨터 기기는, 예를 들어 MICROSOFT Windows, APPLE iOS, UNIX 유사 운영 체제, Linux 또는 Linux 유사 운영 체제(예를 들어 GOOGLE Chrome OS)와 같은 다양한 타 입 및 버전의 소프트웨어 애플리케이션 프로그램과 운영 체제를 실행하거나; 예를 들어 MICROSOFT Windows Mobile OS, iOS, Windows Phone, Android와 같은 다양한 모바일 운영 체제를 포함할 수 있다. 휴대용 핸드헬드 기기는 셀룰러 전화, 스마트 전화, 태블릿, 개인 휴대 정보 단말기(PDA) 등을 포함할 수 있다. 웨어러블 기기는 헤드 마운트 디스플레이(예를 들어 스마트 안경) 및 다른 기기를 포함할 수 있다. 게임 시스템은 다양한 휴대용 게임 기기, 인터넷을 지원하는 게임 기기 등을 포함할 수 있다. 클라이언트 기기는 예를 들어 다양한 Internet관련 애플리케이션 프로그램, 통신 애플리케이션 프로그램(예를 들어 이메일 애플리케이션 프로그램), 단문 메 시지 서비스(SMS) 애플리케이션 프로그램과 같은 다양한 상이한 애플리케이션 프로그램을 실행할 수 있고, 다양 한 통신 프로토콜을 사용할 수 있다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "네트워크는 본 기술분야의 통상의 기술자에게 숙지된 임의의 타입의 네트워크일 수 있고, 다양한 프로토콜 중 어느 하나(TCP/IP, SNA, IPX 등을 포함하지만 이에 한정되지 않음)를 사용하여 데이터 통신을 지원할 수 있 다. 단지 예시로서, 하나 이상의 네트워크는 근거리 통신망(LAN), 이더넷 기반 네트워크, 토큰 링, 광역 통신망(WAN), 인터넷, 가상 네트워크, 가상 사설 통신망(VPN), 인트라넷, 엑스트라넷, 블록체인 네트워크, 공중 교환 전화망(PSTN), 적외선 네트워크, 무선 네트워크(예를 들어 블루투스, WiFi) 및/또는 상술한 네트워크 및/ 또는 다른 네트워크의 임의의 조합일 수 있다. 서버는 하나 이상의 범용 컴퓨터, 전용 서버 컴퓨터(예를 들어 PC(개인 컴퓨터) 서버, UNIX 서버, 미들 엔 드 서버), 블레이드 서버, 대형 컴퓨터, 서버 클러스터 또는 임의의 다른 적절한 배치 및/또는 조합을 포함할 수 있다. 서버는 가상 운영 체제를 실행하는 하나 이상의 가상 기계를 포함하거나, 가상화의 다른 컴퓨팅 아키텍처(예를 들어, 서버의 가상 저장 기기를 유지하기 위해 가상화될 수 있는 논리적 저장 장치의 하나 이상 의 플렉시블 풀)와 관련될 수 있다. 다양한 실시예에서, 서버는 아래에 설명되는 기능을 제공하는 하나 이 상의 서비스 또는 소프트웨어 애플리케이션을 실행할 수 있다. 서버 중 컴퓨팅 유닛은 상기 임의의 운영 체제 및 임의의 상업적으로 사용 가능한 서버 운영 체제를 포함 하는 하나 이상의 운영 체제를 실행할 수 있다. 서버는 또한 HTTP서버, FTP서버, CGI서버, JAVA서버, 데이 터베이스 서버 등을 포함하는 다양한 부가적 서버 애플리케이션 프로그램 및/또는 중간층 애플리케이션 프로그 램 중 어느 하나를 실행할 수 있다. 일부 실시형태에서, 서버는 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 사용자로부터 수신 되는 데이터 피드 및/또는 이벤트 업데이트를 분석하고 병합하기 위해 하나 이상의 애플리케이션 프로그램을 포 함할 수 있다. 서버는 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 하나 이상의 디스플레이 기기를 통해 데이터 피드 및/또는 실시간 이벤트를 디스플레이하기 위해 하나 이상의 애플리케이션 프로그램을 더 포함할 수 있다. 일부 실시형태에서, 서버는 분산형 시스템인 서버, 또는 블록체인을 결합한 서버일 수 있다. 서버는 클라우드 서버이거나, 인공 지능 기술을 갖는 스마트 클라우드 컴퓨팅 서버 또는 스마트 클라우드 호스트일 수 도 있다. 클라우드 서버는 기존의 물리적 호스트 및 가상 전용 서버(VPS, Virtual Private Server) 서비스에서 관리가 어렵고 비즈니스 확장성이 약한 단점을 해결하기 위한 클라우드 컴퓨팅 서비스 시스템의 호스트 제품이 다. 시스템은 하나 이상의 데이터 베이스를 더 포함할 수 있다. 일부 실시예에서, 이러한 데이터 베이스 는 데이터 및 다른 정보를 저장할 수 있다. 예를 들어, 데이터 베이스 중 하나 이상은 예를 들어 오디오 파일 및 비디오 파일과 같은 정보를 저장할 수 있다. 데이터 베이스는 다양한 위치에 체류될 수 있다. 예 를 들어, 서버에 의해 사용되는 데이터 베이스는 서버 로컬이거나, 서버에서 떨어질 수 있으며 네트워크 또는 전용 연결을 통해 서버와 통신할 수 있다. 데이터 베이스는 상이한 타입일 수 있다. 일부 실시예에서, 서버에 의해 사용되는 데이터 베이스는 관계형 데이터 베이스일 수 있다. 이러한 데이터 베이스 중 하나 이상은 명령에 응답하여 데이터 베이스로부터의 데이터를 저장, 업데이트 및 검색할 수 있다. 일부 실시예에서, 데이터 베이스 중 하나 이상은 애플리케이션 프로그램에 의해 사용되어 애플리케이션 프 로그램 데이터를 저장할 수도 있다. 애플리케이션 프로그램에 의해 사용되는 데이터 베이스는 예를 들어 키 값 저장소, 객체 저장소 또는 파일 시스템이 지원하는 통상적인 저장소와 같은 상이한 타입의 데이터 베이스일 수 있다. 도 1의 시스템은, 본 발명의 설명에 따른 다양한 방법 및 장치를 응용할 수 있도록 다양한 형태로 구성 및 작동될 수 있다. 본 발명의 일 양태에 따르면, 딥러닝 모델 기반의 데이터 생성 방법을 제공한다. 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있다. 도 2에 도시된 바와 같이, 데이터 생성 방법은, 사용자로부 터의 입력 데이터에 기반하여, 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계 S201; 딥러닝 모델의 제1 출 력을 획득하되, 딥러닝 모델에 응답하여 초기 입력을 기반으로 생성한 회신을 결정하기 위해서는 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 제1 출력은 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 초기 입력을 기반으로 결정되고 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 단계 S202; 제1 기능 컴포넌트가 제1 중간 문의에 기반하여 결정한 제1 중간 결과를 획득하는 단계 S203; 적어도 초기 입력 및 제1 중간 결과에 기반하여, 딥러닝 모델에 사용되는 제2 입력을 결정하는 단계 S204; 및 딥러닝 모델의 제2 출력을 획득하여, 초기 입력에 대한 회신을 생성하는 단계 S205를 포함한다. 이로써, 상기 방식을 통해, 자체적으로 이해 및 생성 등 임무를 수행할 수 있는 딥러닝 모델에 대하여, 능력 강 화를 더 구현함으로써, 최종적으로 생성된 회신의 품질을 향상시킨다. 이 밖에, 딥러닝 모델을 이용하여 외부 기능 컴포넌트에 의해 인식될 수 있는 중간 문의를 직접 생성하는 것을 통해, 중간 문의 및 획득한 중간 결과가 사용자의 초기 입력 중의 잠재적 의도에 더 부합되도록 함으로써, 모델이 사용자의 요구를 만족하는 회신을 출 력할 수 있도록 한다. 본 발명에서, 딥러닝 모델은 이해 생성 통합 상호 작용 대형 모델(이해 생성 대형 모델 또는 통일 대형 모델이 라고도 함)이라고도 할 수 있다. 이해 생성 대형 모델은 엔드 투 엔드 특성을 가지며, 이해 생성 대형 모델을 제외한 다른 기능 컴포넌트 또는 다른 입력에 의존하지 않고, 사용자의 입력 데이터를 기반으로 회신 데이터를 직접 생성할 수 있다. 다시 말해, 이해 생성 대형 모델 자체가 생성 기능을 구비한다. 또한, 이해 생성 대형 모 델이 구성하는 시스템은 지능화 시스템이라고도 할 수 있다. 지능화 시스템에는, 사용자로부터의 입력 데이터를 수신하고 최종적으로 생성된 회신을 사용자에게 제공하는 인터랙션 모듈을 더 포함할 수 있다. 사용자와 지능화 시스템 사이의 회화에서, 지능화 시스템은 이에 구성된 이해 생성 대형 모델을 이용하여 사용자와 여러 차례 대 화할 수 있다. 이해 생성 대형 모델은 엔코더(Encoder) 및 디코더(Decoder)를 갖는 N층 Transformer 네트워크 구조, 또는 통합 사전 트레이닝 언어 모델(Unified pre-trained Language Model, UniLM) 네트워크 구조를 사용할 수 있다. 이해 할 수 있는 것은, 이해 생성 대형 모델은 Transformer 네트워크 구조에 기반한 다른 신경 네트워크 모델일 수도 있고, 여기서 한정하지 않는다. 이해 생성 대형 모델의 입력 및 출력은 모두 토큰(token)에 의해 구성된다. 각 각의 토큰은 아래에서 설명될 바와 같이 하나의 단일 단어, 문자, 단어, 특수 부호와 대응되거나, 일부 외부 기 능 컴포넌트와 대응될 수 있다. 이해할 수 있는 것은, 본 발명에서 설명되는 데이터 생성 방법에 사용되는 딥러닝 모델은 본 발명의 아래에서 설명할 딥러닝 모델의 트레이닝 방법을 통해 트레이닝하여 얻어질 수 있는 것이다. 단계 S201 이전에, 먼저 사용자의 입력 데이터를 획득할 수 있다. 사용자의 입력 데이터는 예를 들어 사용자가 지능화 시스템에 대한 입력일 수 있고, 예를 들어 텍스트 입력, 음성 입력, 이미지 입력 등을 포함할 수 있다. 이해할 수 있는 것은, 사용자의 입력 데이터는 다른 데이터 형태를 구비할 수 있으나, 여기서 한정하지 않는다. 사용자의 입력 데이터는 사실류의 문제일 수 있고, 특정 업무를 수행하라는 지시일 수도 있으며, 잡담 내용일 수도 있다. 상이한 타입의 사용자 입력에 대하여, 지능화 시스템은 모두 적합한 회신을 생성할 수 있다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 외부 기억 장치일 수 있고, 외부 기억 장치에는 사용자와 관련된 제1 데이터 세트 그룹이 저장될 수 있다. 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데 이터 항목 및 딥러닝 모델이 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함할 수 있다. 이해할 수 있는 것은, 과거 입력 데이터 항목 및 대응되는 과거 회신 항목은 예를 들어 사용자와 지능화 시스템의 과거 회화에서 생성된 대화를 포함할 수 있고, 사용자와 지능화 시스템의 현재 회화에서 생성되는 대화를 포함할 수 도 있다. 이로써, 외부 기억 장치를 설치하여 사용자와 지능화 시스템의 장기간의 과거 대화를 저장하는 것을 통해, 지능화 시스템의 기억력을 향상시키고, 사용자 입력과 관련되는 과거 대화를 획득하는 것을 통해, 딥러닝 모델이 과거 대화를 참조하여 사용자 맞춤성이 더 강하고, 내용이 더 풍부하고 구체적인 회신을 생성하도록 함 으로써, 회신 품질을 향상시키고, 대화의 지능성을 향상시키며, 사용자 체험을 강화시킨다. 일부 실시예에 따르면, 제1 데이터 세트 그룹 중 각각의 데이터 세트는 상기 세트 중 과거 입력 데이터 항목 및 과거 회신 항목과 대응되는 등록 시간 항목(또는 타임스탬프)을 더 포함할 수 있다. 이로써, 등록 시간 항목을 설치하는 것을 통해, 외부 기억 장치 중의 과거 대화를 조회 및 삭제할 경우, 과거 대화의 등록 시간에 따라 더 풍부한 동작을 구현할 수 있으며, 기억의 시효성을 향상시킨다. 일부 실시예에서, 제1 데이터 세트 그룹 중 각각의 데이터 세트는 상기 세트 중 과거 입력 데이터 항목 및 과거 회신 항목과 대응되는 주제 항목을 더 포함할 수 있다. 하나의 예시적 실시예에서, 기억을 획득할 경우, 현재 대화와 동일한 주제를 갖는 과거 대화를 직접 획득하거나, 주제 항목을 유사도 계산의 의거로 할 수 있으므로, 더 효과적인 과거 대화를 효율적으로 획득할 수 있다. 이로써, 주제 항목을 설치하는 것을 통해, 구체적인 기억을 추상적인 기억으로 전환하여, 외부 기억 장치 중의 과거 대화를 조회 및 삭제할 경우, 과거 대화의 주제에 따라 더 풍부한 동작을 구현할 수 있다. 하나의 예시적 실시예에서, 외부 기억 장치 중의 데이터 세트는 표 1에 도시된 바와 같을 수 있다. 표 1 과거 입력 데이터 항목 과거 회신 항목 등록 시간 항목 주제 항목 XX중학교의 부지 면적은 얼마입 니까？XX중학교 부지 150무 20XX-8-2 10:00사실류 문답 짱중징(仲景)은 몇년생입니까？짱중징(仲景) 서기 150년 출 생20XX-8-2 10:01사실류 문답 동물들이 같이 줄을 서는데, 고 양이 앞에 4명, 돼지 뒤에 6명 있고, 고양이는 돼지 앞에 있되 둘이 붙어있다면, 총 몇 명의 동물이 줄을 서나요?고양이 앞에 4개, 고양이까 지 합치면 4+1=5개, 돼지 뒤 에 6개, 돼지까지 6+1=7개로 총 5+7=12개의 동물이 줄을 서 있다.20XX-8-2 10:02수학 추리 문제 일부 실시예에 따르면, 제1 중간 문의는 입력 데이터에 기반할 수 있다. 제1 중간 문의는 사용자의 입력 데이터 와 일치할 수 있고, 사용자의 입력 데이터 및 컨텍스트 정보를 포함할 수 있으며, 딥러닝 모델이 입력 데이터에 기반하여 결정된 초기 입력을 개작하여 얻은 것일 수도 있다. 컨텍스트 정보는 획득한 사용자의 입력 데이터 전 에, 사용자와 지능화 시스템에서 발생한 여러 차례의 대화를 포함할 수 있다. 일부 실시예에 따르면, 제1 중간 결과는 제1 데이터 세트 그룹 중 입력 데이터와의 유사도가 제1 임계값보다 높 은 과거 입력 데이터 항목에 대응되는 과거 회신 항목일 수 있다. 이로써, 외부 기억 장치에서 현재의 사용자 입력과 관련되는 과거 회신 항목을 획득하여 제1 중간 결과를 얻는 것을 통해, 딥러닝 모델이 사용자와 지능화 시스템의 과거 대화를 참조하여 사용자의 현재 입력에 대하여 회신을 생성할 수 있도록 함으로써, 지능화 시스 템이 최종적으로 출력하는 회신의 품질을 향상시킨다. 일부 실시예에서, 제1 중간 결과는 입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목 자체 를 더 포함할 수 있다. 일부 실시예에서, 밀집 벡터 유사도를 계산하는 방식을 통해 사용자의 입력 데이터와 관련된 과거 대화 정보를 얻을 수 있다. 밀집 벡터 유사도는 다음과 같이 표시할 수 있다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, eq, ec, emq, emr는 각각 사용자의 입력 데이터 q, 컨텍스트 정보 c, 외부 기억 장치 중의 과거 입력 데 이터 항목 mq 및 과거 회신 항목 mr의 밀집 벡터를 나타내고, 트레이닝된 임베딩 모델을 통해 얻을 수 있다. cont는 두 부분의 내용 조합을 나타내고, 신경 네트워크(예를 들어, 다층 감지기)를 조립, 합계, 이용하여 처리 하는 등 방식을 사용하여 구현할 수 있으며; sim은 유사도 함수를 나타낸다. 이해할 수 있는 것은, 상기 유사도 계산 과정은 신경 네트워크 방식을 통해 구현할 수 있다. 사용자의 입력 데 이터(또는 사용자의 입력 데이터와 컨텍스트 정보 양자, 또는 사용자의 입력 데이터에 기반하여 얻은 제1 중간 문의)와 외부 기억 장치 중 각각의 과거 입력 데이터 항목(또는 과거 입력 데이터 항목과 대응되는 과거 회신 항목 양자)의 유사도를 계산하고, 유사도 s가 기설정된 제1 임계값 δ보다 큰 하나 이상의 데이터 세트 중의 과 거 회신 항목(선택 가능하게, 과거 입력 데이터 항목)을 이해 생성 대형 모델에 리턴할 수 있다. 일부 실시예에 서, 예를 들어 Top K 등 다른 방식을 통해 유사도에 기반하여 리턴할 과거 회신 항목을 결정할 수도 있고, 여기 서 한정하지 않는다. 일부 실시예에서, 외부 기억 장치는 아래에서 설명할 바와 같이 이해 생성 대형 모델과 연합 최적화하여 얻은 것일 수 있다. 일부 실시예에 따르면, 제1 중간 문의는 입력 데이터에 기반할 수 있고, 제1 중간 결과는 제1 데이터 세트 그룹 중 입력 데이터와의 유사도가 제1 임계값보다 높고 타임스탬프가 최신인 과거 입력 데이터 항목에 대응되는 과 거 회신 항목일 수 있다. 이로써, 입력 데이터와 관련된 복수의 과거 회신 항목을 얻을 경우 타임스탬프가 최신 인 과거 회신 항목을 리턴하는 것을 통해, 딥러닝 모델이 최신 관련 기억에 기반하여 회신을 생성하도록 함으로써, 기억의 시효성을 충분히 이용한다. 일부 실시예에서, 제1 데이터 세트 그룹 중 입력 데이터와의 유사도가 제1 임계값보다 높고 타임스탬프가 최신 인 과거 입력 데이터 항목 자체를 딥러닝 모델에 리턴할 수도 있다. 일부 실시예에서, 도 3에 도시된 바와 같이, 사용자와 지능화 시스템은 과거에 두 차례의 애완용 베베를 데리고 놀러 가는 대화가 있었다. 지능화 시스템은 예를 들어 위에서 설명된 바와 같이, 이해 생성 대형 모델이 배치되고 사용자와 대화 인터랙션할 수 있는 시스템일 수 있다. 현재 대화에서, 지능화 시스템은 \"최근에 베베를 데리고 가서 저번에 만났던 친구들이랑 놀고 싶다\"는 사용자 입력을 획득하고, 상기 사용자 입 력을 기반으로 외부 기억 장치에서 기억을 획득함으로써, 타임스탬프가 20XX0812인 과거 입력 데이터 항목 \"제가 요즘 베베를 펫랜드에 데려가려고 하는데 추천해주실 곳이 있나요?\"와 대응되는 과거 회신 항목 \"XX랜드 산책도 할 수 있고 반려동물 놀이기구도 많이 있습니다\", 및 타임스탬프가 20XX0817인 과거 입력 데이터 항목 \"내일은 베베와 함께 교외로 나가 신선한 공기를 마시고 싶다\"와 대응되는 과거 회신 항목 \"YY파크는 좋은 선 택입니다\"를 조회할 수 있다. 나아가, 타임스탬프가 최신인 과거 대화를 딥러닝 모델에 리턴하고, 딥러닝 모델 이 상기 과거 대화에 기반하여 회신 \"YY공원에 가실 건가요? 많은 친구들을 만날 수 있습니다\"를 생성할 수 있 다. 이해할 수 있는 것은, 지능화 시스템은 획득한 두 개의 과거 대화를 모두 모델에 제공하여, 모델이 회신을 생성하는 데 사용할 수 있다. 상기 실시예를 통해 볼 수 있다시피, 외부 기억 장치를 사용하는 것을 통해, 사용자와 지능화 시스템의 이전 회 화에서(예를 들어, 일주일 전, 한 달 전 또는 그 이전) 생성된 과거 대화를 기록할 수 있고, 지능화 시스템의 기억력을 향상시키며, 사용자의 현재 입력에 대하여 회신을 생성할 경우 관련된 과거 대화를 참고하여, 사용자 맞춤성이 더 강하고, 내용이 더 풍부하고 구체적인 회신을 생성할 수 있으므로, 회신 품질을 향상시키고, 대화 의 지능성을 향상시키며, 사용자 체험을 강화시킨다. 상기 실시예는 외부 기억 장치의 조회 작업을 설명하였고, 아래 외부 기억 장치 중 데이터 세트의 추가 및 삭제 등 작업에 대하여 설명한다. 도 4는 예시적 실시예에 따른 외부 기억 장치에서 데이터 세트를 추가하고 데 이터 세트를 삭제하는 등 작업의 모식도를 도시한다. 지능화 시스템은 예를 들어 위에서 설명된 바와 같이, 이해 생성 대형 모델이 배치되고 사용자와 대화 인터랙션할 수 있는 시스템일 수 있다. 주의해야 할 것은, 외부 기억 장치의 조회 작업은 딥러닝 모델을 이용하여 사용자의 입력 데이터에 대한 회신 데이터를 생성 하는 과정에서 수행되는 것이며, 추가 및 삭제 등 작업은 딥러닝 모델이 회신 데이터를 생성한 후에 수행되는 것이다. 일부 실시예에 따르면, 데이터 생성 방법은 입력 데이터 및 회신에 기반한 제1 데이터 세트와 제1 데이터 세트 그룹 중 임의의 하나의 데이터 세트 사이의 유사도가 제2 임계값보다 낮다고 결정한 것에 응답하여, 제1 데이터 세트를 제1 데이터 세트 그룹에 등록하는 단계를 더 포함할 수 있다. 일부 실시예에서, 제t-1 차례의 사용자 입력 데이터 ut-1 및 딥러닝 모델의 회신 데이터 rt-1에 대하여, 제1 데이 터 세트 mt-1 = (ut-1, rt-1)와 외부 기억 장치 M 중 임의의 하나의 데이터 세트의 유사도가 모두 기설정된 제2 임 계값보다 낮으면, 외부 기억 장치 M에 mt-1 = (ut-1, rt-1)을 추가한다. 일부 실시예에 따르면, 데이터 생성 방법은 입력 데이터 및 회신에 기반한 제1 데이터 세트와 제1 데이터 세트 그룹 중 제2 데이터 세트 사이의 유사도가 제3 임계값보다 높다고 결정하며 제1 데이터 세트와 제2 데이터 세트 가 서로 충돌된다고 결정한 것에 응답하여, 제1 데이터 세트를 제1 데이터 세트 그룹에 등록하고, 제1 데이터 세트 그룹에서 제2 데이터 세트를 삭제하는 단계를 더 포함할 수 있다. 일부 실시예에서, 제t-1 차례의 사용자 입력 데이터 ut-1 및 딥러닝 모델의 회신 데이터 rt-1에 대하여, 제1 데이 터 세트 mt-1 = (ut-1, rt-1)와 외부 기억 장치 M 중 제2 데이터 세트 mi∈M의 유사도가 제3 임계값보다 높고, mt-1 과 mi 일관성이 충돌되는 것으로 판단되면, M에서 mi를 삭제하고 mt-1을 보충한다. 하나의 예시적 실시예에서, mt- 1과 mi의 일관성 판단(예를 들어, 충돌 검출)은 신경 네트워크를 이용하여 양자의 의미 벡터에 기반하여 수행될 수 있고, 다른 방식으로 구현될 수도 있으며, 여기서 한정하지 않는다. 이로써, 상기 방식을 통해, 외부 기억 장치에서 데이터 세트를 추가 및 삭제하는 것을 구현하고, 외부 기억 장 치 중 데이터 세트에 대한 작업의 유연성을 향상시키며, 외부 기억 장치 중 데이터 세트의 시효성 및 내용의 정 확성을 향상시킨다. 일부 실시예에서, 도 4에 도시된 바와 같이, 딥러닝 모델이 사용자 입력에 대하여 회신을 생성한 후, 현재 대화 (사용자 입력 및 모델이 생성한 회신을 포함함)를 외부 기억 장치에 추가할 수 있고; 현재 대화 내용과 외부 기 억 장치 중의 과거 대화가 충돌될 경우, 외부 기억 장치 중의 과거 대화를 삭제할 수 있다. 일부 실시예에 따르면, 데이터 생성 방법은 등록 시간 항목에 기반하여, 외부 기억 장치에서 시효가 지난 데이 터 세트를 삭제하는 단계를 더 포함할 수 있다. 일부 예시적 실시예에서, 데이터 세트의 보존 시간을 설정하여, 상기 시간을 초과하는 데이터 세트를 삭제할 수 있고; 데이터 세트의 내용에 따라 정기적 또는 비정기적으로 시 효성 검증을 수행하여, 검증에 통과하지 못한 데이터 세트를 삭제할 수도 있으며; 다른 방식을 통해 외부 기억 장치에서 시효가 지난 데이터 세트를 삭제하는 것을 구현할 수도 있다. 이로써, 상기 방식을 통해, 외부 기억 장치 중의 데이터 세트가 모두 시효가 지나지 않은 것을 보장할 수 있고, 기억의 시효성을 향상시킨다. 일부 실시예에서, 지능화 시스템은 딥러닝 모델을 구축하는 초기 입력 단계에서(즉, 딥러닝 모델을 이용하여 초 기 입력을 처리하기 전에), 외부 기억 장치 중 사용자의 현재 차례의 입력 데이터와 대응되는 과거 대화 정보를 직접 획득하고, 과거 대화 정보에 기반하여 딥러닝 모델의 초기 입력을 결정할 수 있다. 일부 실시예에 따르면, 도 5에 도시된 바와 같이, 딥러닝 모델에 사용되는 초기 입력을 결정하는 단계 S201은, 입력 데이터에 기반하여, 외부 기억 장치에서 입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목을 획득하는 단계 S501; 및 입력 데이터 및 과거 회신 항목에 기반하여, 초기 입력을 결정하는 단계 S502를 포함할 수 있다. 이해할 수 있는 것은, 단계 S501의 작업은 위에서 제1 중간 결과 를 획득하는 것에 대한 설명을 참조할 수 있고, 여기서 더 이상 설명하지 않는다. 이로써, 딥러닝 모델이 회신 을 생성할 때마다 외부 기억 장치에서 획득한 과거 대화 정보를 참고할 수 있음을 보장할 수 있다. 일부 실시예에서, 사용자의 입력 데이터와 과거 회신 항목을 직접 조립하여, 딥러닝 모델의 초기 입력을 얻을 수 있고; 다른 방식을 사용하여 사용자의 입력 데이터 및 과거 회신 항목을 처리함으로써, 딥러닝 모델의 초기 입력을 얻을 수도 있으며, 여기서 한정하지 않는다. 아래 일부 예시적 실시예를 결합하여 딥러닝 모델 및 지능화 시스템의 기억력이 강화된 효과를 더 설명한다. 하 나의 예시적 실시예에서, 도 6에 도시된 바와 같이, 외부 기억 장치의 대화 시스템을 구비하지 않으면 장 기 기억을 형성할 수 없으므로, 사용자가 과거 대화에 관한 내용을 문의할 경우, 상기 시스템은 기계적으로 회 신할 수 밖에 없다. 본 발명에서 설명되는 외부 기억 장치를 구비하는 지능화 시스템은 사용자 입력에 대 하여, 외부 기억 장치에서 대응되는 과거 대화를 획득함으로써, 사용자 요구를 만족시키는 회신을 생성할 수 있고, 딥러닝 모델 및 지능화 시스템의 기억력에 대한 강화를 나타냈다. 일부 실시예에서, 제1 기능 컴포넌트는 예를 들어 외부 서치 엔진, 검색 모델, 애플리케이션 프로그래밍 인터페 이스 등등과 같은 다른 기능 컴포넌트일 수도 있다. 이러한 상이한 기능 컴포넌트는 각자 대응되는 토큰(toke n)을 구비한다. 단계 S202에서, 딥러닝 모델은 외부의 기능 컴포넌트 호출 여부(및/또는 어느 기능 컴포넌트를 호출하겠는 가)에 대해 결정하고, 결정 결과는 딥러닝 모델이 출력한 결과에 호출된 외부 기능 컴포넌트에 대응 되는 토큰이 포함되는지 여부(및/또는 결과에 구체적으로 어느 기능 컴포넌트에 대응되는 토큰을 포함하는 지) 에 나타난다. 주의해야 할 것은, 외부 서치 엔진, 검색 모델, 애플리케이션 프로그래밍 인터페이스와 같은 외부 기능 컴포넌트는 컨텍스트 정보 및/또는 외부 기억 장치를 전제로 할 필요가 없고, 다시 말해, 이러한 외부 기 능 컴포넌트는 모두 딥러닝 모델에 의해 단독적으로 호출되어 사용할 수 있다. 일부 실시예에서, Transformer 네트워크 구조 기반의 딥러닝 모델이 예측을 수행할 경우, 모델은 먼저 초기 입 력을 수신하여 첫번째 출력 토큰(token_1)을 생성한다. 나아가 모델은 token_1을 수신하여, 두번째 출력 토큰 (token_2)을 생성한다. 모델이 출력한 token_n이 모델 출력 완료를 가리킬 때까지 딥러닝 모델에 대한 순환 호 출을 반복한다. 모델이 출력한 각각의 토큰은 특정 외부 기능 컴포넌트와 대응되어, 외부 기능 컴포넌트 호출 여부에 대한 결정 결과를 나타낼 수 있고; 특정 마크업(markup) 형태로서, 특정 외부 기능 컴포넌트에 의해 인 식될 수 있는 중간 문의를 생성할 수도 있으며; 구체적인 단일 문자, 문자 부호 또는 단어로서, 사용자 입력에 대한 회신을 생성할 수도 있고; 또한 현재 내용 생성이 완료되었음을 가리키는 특수 부호일 수도 있다. 이로써, 모델을 이용하여 자동 결정을 수행함으로써, 다음에 수행할 임무(예를 들어, 외부 기능 컴포넌트를 호출하거나 회신을 생성함)를 결정하는 것을 구현한다. 도 7은 예시적 실시예에 따른 딥러닝 모델이 초기 입력을 기반으로 회신을 생성하는 모식도를 도시한다. 이해 생성 대형 모델(즉, 딥러닝 모델)의 구조는 UniLM일 수 있다. 먼저 사용자의 입력 데이터(선택 가능하게, 컨텍스트 정보)에 기반한 모델의 초기 입력을 딥러닝 모델에 입력하여, 모델이 출력한 첫번째 토큰을 얻고, 대응되는 내용은 <api1>이다. 상기 토큰은 호출이 필요한 기능 컴포넌트(API 1)에 대한 모델의 결정을 나타냈다. 모델은 계속하여 출력하여, API 1에 의해 인식될 수 있는 제1 중간 문의(input_1)를 생성할 수 있다. 상기 과정 은 사용자의 입력 데이터에 대하여 개작함으로써, API 1에 의해 인식될 수 있고 API 1로부터 희망하는 결과를 획득할 수 있는 호출 정보를 얻을 수 있는 것으로 이해할 수도 있다. input_1을 출력한 후, 모델은 마크업 </api1>과 대응되는 토큰을 출력하여, API 1에 대한 제1 중간 문의가 생성 완료되었음을 나타낼 수 있다. 제1 출력은 완전한 <api1>input_1</api1>을 포함할 수 있다. 일부 실시예에서, API 1과 대응되는 제1 중간 문의(input_1)는 딥러닝 모델을 순환 호출하는 것을 통해 한 글자 씩 생성되는 것일 수 있고, 즉, 매번 사용자의 입력 데이터, 및 input_1에서 생성된 부분을 모델에 입력하여, input_1 중 다음 단일 문자, 문자 부호 또는 마크업(markup)을 획득한다. input_1은 딥러닝 모델이 출력한 단일 토큰에 대하여 디코딩하는 것을 통해 얻은 것일 수도 있다. input_1은 또한 다른 방식을 통해 모델이 출력한 토 큰에 따라 얻은 것일 수 있으며, 여기서 한정하지 않는다. 제1 중간 문의(input_1)를 얻은 후, input_1을 이용하여 API 1을 호출함으로써, 제1 중간 결과 <api1- r>result_1</api1-r>를 획득할 수 있다. 나아가, 사용자의 입력 데이터와 제1 중간 결과를 조합하여 딥러닝 모 델에 사용되는 제2 입력을 얻음으로써, 모델이 출력하는 다음 토큰을 획득할 수 있다. 일부 실시예에서, 제2 입 력을 결정할 경우, 제1 중간 문의(또는 완전한 제1 출력)를 병합할 수도 있고, 도 7 중 제1 출력 <api1>input_1</api1> 하부의 점선 화살표 및 제1 중간 결과 <api1-r>result_1</api1-r> 좌측의 점선 블록에 도시된 바와 같다. 상기 점선 블록은 제1 중간 문의(input_1)일 수 있고, 완전한 제1 출력 <api1>input_1</api1>일 수도 있다. 하나의 예시적 실시예에서, 제2 입력은 모델의 초기 입력, 제1 출력 및 제1 중간 결과의 조립이다. 일부 실시예에 따르면, 적어도 초기 입력 및 제1 중간 결과에 기반하여, 딥러닝 모델에 사용되는 제2 입력을 결 정하는 단계 S204는 초기 입력, 제1 중간 결과 및 제1 중간 문의에 기반하여, 딥러닝 모델에 사용되는 제2 입력 을 결정하는 단계를 포함할 수 있다. 이로써, 제1 중간 문의를 딥러닝 모델이 제2 출력을 생성하는 참고 요소로 하는 것을 통해, 모델 결정의 정확성을 더 향상할 수 있고, 최종적으로 생성된 회신의 품질을 향상할 수 있다. 딥러닝 모델이 제2 입력을 기반으로 생성한 제2 토큰에 대응되는 내용은 <api2>이고, 상기 토큰은 호출이 필요 한 기능 컴포넌트(API 2)에 대한 모델의 결정을 나타냈다. 모델은 계속하여 제2 중간 문의(input_2) 및 마크업 </api2>와 대응되는 토큰을 출력할 수 있다. 나아가, input_2를 이용하여 API 2를 호출함으써, 제2 중간 결과 <api2-r>result_2</api2-r>를 획득하고, 사용자의 입력 데이터, 제2 중간 결과(선택 가능하게, 제2 중간 문의) 를 조합하여 딥러닝 모델에 사용되는 제3 입력을 얻을 수 있다. 하나의 예시적 실시예에서, 제3 입력은 모델의 초기 입력, 제1 출력, 제1 중간 결과, 제2 출력 및 제2 중간 결과의 조립이다. 딥러닝 모델이 제3 입력을 기반으로 생성한 제3 토큰은 임의의 하나의 외부 기능 컴포넌트와 대응되지 않을 수 있으므로, 상기 제3 토큰은 모델의 초기 입력에 대한(사용자의 입력 데이터에 대한 것으로 이해할 수도 있음) 회신을 생성하도록 모델을 지시할 수 있다. 일부 실시예에서, 제3 토큰은 회신 중의 첫번째 단일 문자, 문자 부 호 또는 단어일 수 있고, 의미 정보를 구비하지 않는 다음 토큰부터 회신을 생성하도록 모델을 지시하는 특수 부호일 수도 있다. 그 후, 모델은 한 글자씩 회신을 생성하고, 최종적으로 회신 생성이 완료되었음을 가리키는 특수 부호를 생성한다. 주의해야 할 것은, 상이한 외부 기능 컴포넌트의 호출은 독립적이고, 기설정된 선후 순서적 관계가 없으며, 모 델이 출력한 토큰에 의해 어느 외부 기능 컴포넌트를 호출할지 결정된다. 따라서, 일부 예시적 실시예에서, 모 델은 동일한 기능 컴포넌트를 여러 차례 호출할 것을 결정하거나, 사용자 입력에 대한 이해에 따라, 특정 논리 적 순서에 따라 복수의 기능 컴포넌트를 호출하여 특정 임무를 수행할 수 있다. 이로써, 이해 생성 대형 모델이 상이한 의미의 토큰을 출력하도록 하는 것을 통해, 모델이 사용자 입력(선택 가 능하게, 컨텍스트 정보)에 대한 이해에 기반하여 수행해야 할 임무(예를 들어, 특정 외부 기능 컴포넌트를 호출 하거나 회신을 직접 생성함) 및 수행 순서를 자동적으로 결정할 수 있도록 함으로써, 단일 딥러닝 모델을 이용 한 자동화 이해, 추리, 결정, 생성을 구현하고, 시스템의 지능성을 향상시킨다. 일부 실시예에서, UniLM 모델은 하나의 입력만 구비한다. 따라서, 단계 S204에서, 조립 등 수단을 통해 초기 입 력과 제1 중간 결과를 조합하여, 사용자 딥러닝 모델의 제2 입력을 얻을 수 있다. 일부 실시예에서, 엔코더 및 디코더를 갖는 N층 Transformer 네트워크 구조를 사용하는 것에 대하여, 엔코더의 입력은 모델의 초기 입력일 수 있고, 엔코더의 출력은 초기 입력에 대한 코딩 결과일 수 있으며; 디코더의 두출력은 각각 엔코더가 출력한 초기 입력에 대한 코딩 결과 및 모델이 생성한 모든 토큰이고, 디코더의 출력은 예측한 다음 토큰이다. 따라서, 단계 S204에서, 제1 중간 결과 및 초기 입력에 대한 코딩 결과를 각각 디코더의 두 출력으로 할 수 있다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 외부 서치 엔진일 수 있다. 외부 서치 엔진은 범용 서치 엔진일 수 있고, 분야 맞춤형 지식 엔진 또는 전문 지식 창고일 수도 있으며, 또는 사유화 데이터 베이스로서, 상이한 타 입의 지식을 획득하고 실시간으로 지식을 업데이트할 수 있다. 딥러닝 모델이 생성한 제1 중간 문의는 예를 들어 서치형으로서, 외부 서치 엔진을 이용하여 상기 서치형에 기 반하여 서치함으로써, 하나 이상의 서치 결과를 얻을 수 있다. 일부 실시예에서, 서치 엔진이 리턴한 하나 이상 의 서치 결과를 직접 제1 중간 결과로 할 수 있고, 이러한 서치 결과를 처리하여, 제1 중간 결과를 얻을 수도 있다. 그 후, 딥러닝 모델의 초기 입력(예를 들어, 사용자의 입력 데이터, 및 선택 가능하게, 컨텍스트 정보) 및 제1 중간 결과(예를 들어, 하나 이상의 서치 결과)에 기반하여 딥러닝 모델의 처리에 사용되는 제2 입력을 결정할 수 있다. 제2 입력에 대하여, 딥러닝 모델은 아래에 설명될 바와 같이, 제2 기능 컴포넌트를 더 호출해 야 하는 것을 결정할 수 있고, 다른 기능 컴포넌트를 호출할 필요 없이 초기 입력에 대한 회신을 직접 생성하는 것을 결정할 수도 있다. 일부 실시예에서, 조립 등 방식을 통해 초기 입력과 제1 중간 결과를 조합하여, 제2 입력을 얻을 수 있고; 먼저 내용 추출, 개작, 의미 벡터 계산 또는 다른 방식을 통해 각각의 서치 결과를 처리한 다음, 조립 등 방식을 통 해 초기 입력과 처리된 서치 결과를 조합하여, 제2 입력을 얻을 수도 있으며, 여기서 한정하지 않는다. 일부 실시예에서, 트레이닝을 통해, 데이터를 파라미터 방식으로 모델에 완전히 내재화하고, 이러한 모델을 이 용하여 사용자 입력에 대한 회신을 직접 생성할 수 있다. 이러한 메커니즘에서, 인기 없는 사실류 정보에 대하 여, 트레이닝 데이터의 빈도가 낮고, 모델의 학습이 불충분하여, \"망각\" 또는 \"기억 오류\"의 상황이 존재할 수 있다. 이로써, 외부 서치 엔진에서 서치 결과를 획득하는 것을 통해, 다양한 정확한 지식, 정보 및 시효성 데이터를 정확하고 적시적으로 상층 이해 생성 대형 모델에 전달하도록 함으로써, 이해 생성 대형 모델이 서치된 명시적 정보와 모델에 내재화된 지식을 결합하여 사용자의 요구를 만족시키는 회신을 함께 완성하도록 한다. 이 밖에, 이해 생성 대형모델은 제2 입력에 포함된 하나 이상의 서치 결과에 따라 최후의 회신을 생성하고, 서치된 정보 에 대한 정합 가공을 구현함으로써, 사용자 의도에 더 적합한 회신을 출력할 수 있고, 회신 데이터의 품질을 향 상시킨다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델이다. 검색 모 델은 엔드 투 엔드의 Transformer 구조 기반의 대형 모델일 수 있고, 여기서 소환 모델 및 배열 모델을 더 포함 할 수 있다. 검색 모델은 단일 신경 네트워크 모델(예를 들어, 엔드 투 엔드의 Transformer 구조 기반의 대형 모델)에 의해 구현될 수도 있다. 딥러닝 모델과 검색 모델의 연합 트레이닝은 아래에서 설명한다. 딥러닝 모델이 생성한 제1 중간 문의는 예를 들어 검색 쿼리(query)일 수 있고, 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델을 이용하여 검색함으로써, 하나 이상의 검색 결과를 얻을 수 있다. 이해할 수 있는 것은, 검색 결과에 대한 처리는 위에서 서치 엔진이 리턴한 서치 결과에 대한 처리를 참고할 수 있고, 여기서 더 이상 설명하지 않는다. 이로써, 외부 검색 모델의 사용을 통해, 한 방면으로 외부 서치 엔진의 상술한 장점을 구현할 수 있고, 다른 한 방면으로 외부 검색 모델과 이해 생성 대형 모델은 연합 최적화로서, 양자는 협력할 수 있으므로, 외부 검색 모 델은 이해 생성 대형 모델에 회신이 생성한 내용을 더 정확하고, 더 적합하게 제공할 수 있고, 이해 생성 대형 모델은 검색 결과를 더 잘 정합 가공함으로써, 사용자 의도에 더 적합하고 품질이 더 높은 회신을 생성할 수 있 다. 따라서, 외부 서치 엔진 또는 외부 검색 모델의 사용을 통해, 딥러닝 모델 및 지능화 시스템에 대한 지식 강화를 구현할 수 있다. 아래 일부 예시적 실시예를 결합하여 딥러닝 모델 및 지능화 시스템에 대한 지식 강화 효과를 더 설명한다. 하 나의 예시적 실시예에서, 도 8에 도시된 바와 같이, 지식이 강화되지 않은 대화 시스템에 내재화된 지식이 제한되므로, 지적인 질문을 받았을 때 정확한 답변을 할 수 없다. 이 밖에, 대화 시스템은 지식을 실시간 으로 업데이트할 수 없으므로, 출력하는 결과가 시간이 지나거나 잘못된 것일 수 있다. 본 발명에서 설명되는 지식이 강화된 지능화 시스템은 사용자 입력에 대하여, 외부 서치 엔진/검색 모델에서 검색함으로써, 정확한 지식 내용을 획득하고, 지식의 정확도를 향상시킨다. 사용자가 제출한 \"삼국시대 위나라 주공의 아들이쓴 유명한 시는 무엇입니까?\"라는 질문에 대하여, 서치 엔진/검색 모델은 두 개의 관련 결과를 리턴하였고, 그 중 하나는 삼국시대 위나라의 주공은 조조이고, 그는 아들 조비와 조식이 있다는 것을 설명하였 고, 다른 하나는 조조의 아들 조식의 시 '칠보시'가 유명하다는 것을 설명하였다. 딥러닝 모델은 자체의 내재화 된 지식을 결합하고, 외부에서 획득한 이 두개의 서치 결과를 융합한 후, 정확한 회신을 제시하였다. 이 밖에, 외부 서치 엔진 및 검색 모델 배후의 데이터 베이스, 지식 창고, 자원 창고는 실시간으로 업데이트되 므로, 서치 또는 검색을 통해 얻은 지식은 더 강한 시효성을 갖는다. 이로써, 딥러닝 모델 및 지능화 시스템에 대한 지식 강화를 나타냈다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스(Application Programming Interface, API)이다. 상이한 API는 각자 대응되는 마크업 (markup) 형태를 구비하고, 상기 API를 호출하기 위한 해당 토큰을 구비한다. 딥러닝 모델 예측 시, 모델이 특 정 API와 대응되는 토큰/마크업을 출력하면, 지능화 시스템은 해당 API를 촉발해야 함을 알고 있다. 그 후, 모 델은 계속하여 해당 API에 의해 인식될 수 있는 중간 문의(즉, 해당 API의 입력에 사용되고, 개작된 조회 query 라고 할 수도 있음)를 출력한다. 나아가, 중간 문의를 이용하여 해당 API를 호출하여 획득한 중간 결과에 기반 하여 딥러닝 모델에 다시 입력할 제2 입력을 결정함으로써, 모델이 계속하여 예측하도록 할 수 있다. 제2 입력 에 대하여, 딥러닝 모델의 결책은 제2 기능 컴포넌트(서치 엔진, 검색 모델, 또는 다른 API)를 더 호출해야 할 수 있고, 다른 기능 컴포넌트를 호출할 필요 없이 초기 입력에 대한 회신을 직접 생성할 수도 있다. 위에서 설명된 바와 같이, 모델이 한 차례의 회신을 생성하는 과정에서, 전부의 API(또는 전부의 외부 기능 모 듈)를 호출할 수 있고, 일부 API만 호출할 수도 있으며, 이러한 API의 호출 순서 및 호출 횟수는 모두 모델에 의해 결정된다. 일부 실시예에서, 지능화 시스템에서 사용되는 API는 과학 계산기, 테이블 처리 도구, 스마트홈 제어 등을 포함 할 수 있다. 이로써, 다양한 임무를 수행할 수 있는 API를 호출하는 것을 통해, 지능화 시스템에 대한 능력 확 장을 구현한다. 과학 계산기 등 외부 기능 컴포넌트의 사용을 통해, 딥러닝 모델의 논리 계산 능력이 떨어지는 문제를 해결하고, 지능화 시스템의 전체적인 논리 추리 능력을 향상시킨다. 키워드와 API 호출 명령의 영사표를 이용하여 API에 대해 호출하는 방식에 비해, 딥러닝 모델을 이용하면 해당 API에 의해 인식될 수 있는 중간 문 의를 직접 생성할 수 있고, 중간 문의 및 획득한 중간 결과가 사용자의 초기 입력 중의 잠재적 의도에 더 부합 되도록 함으로써, 최종 생성된 회신의 품질을 향상시키며, 시스템의 지능성을 강화시킨다. 이 밖에, 이해 생성 대형 모델과 API의 결합을 통해, 지능화 시스템이 자동화 작업 수행 능력을 구비하도록 할 수 있고, 딥러닝 모 델 및 지능화 시스템에 대한 능력 확장을 구현한다. 아래 일부 예시적 실시예를 결합하여 딥러닝 모델 및 지능화 시스템의 능력 확장 효과를 더 설명한다. 하나의 예시적 실시예에서, 도 9에 도시된 바와 같이, 확장 능력(예를 들어, 외부 API의 호출 능력)을 구비하지 않는 대화 시스템이 완성할 수 있는 임무는 제한되고, 날씨 조회, 수학 계산 등과 같이 외부 기능 컴포넌트를 호출해야만 완성할 수 있는 임무를 처리할 수 없다. 본 발명에서 설명되는 능력이 확장된 지능화 시스템은 사용자 입력에 대하여, 호출해야 할 API를 결정하고, 나아가 해당 API를 호출하며 리턴한 결과를 처 리하는 것을 통해 사용자 요구를 만족시키는 회신을 생성할 수 있고, 딥러닝 모델 및 지능화 시스템에 대한 능 력 확장을 나타냈다. 일부 실시예에 따르면, 제2 출력은 제2 기능 컴포넌트를 호출하기 위한 제2 토큰 및 제2 입력을 기반으로 얻어 지고 제2 기능 컴포넌트에 의해 인식될 수 있는 제2 중간 문의를 포함할 수 있다. 이해할 수 있는 것은, 제2 기 능 컴포넌트는 제1 기능 컴포넌트와 동일할 수 있고(즉, 동일한 기능 컴포넌트를 여러 차례 호출함), 제1 기능 컴포넌트와 상이할 수도 있으며, 여기서 한정하지 않는다. 일부 실시예에 따르면, 도 10에 도시된 바와 같이, 딥러닝 모델의 제2 출력을 획득하여, 초기 입력에 대한 회신 을 생성하는 단계 S205는, 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 단계 S1001; 및 딥러닝 모델 의 제N 출력에 제N 기능 컴포넌트를 호출하기 위한 제N 토큰 및 제N 입력을 기반으로 얻어지고 제N 기능 컴포넌 트에 의해 인식될 수 있는 제N 중간 문의가 포함되는 것에 응답하여, 제N+1 출력에 딥러닝 모델과 구별되는 임 의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰이 포함되지 않다고 결정될 때까지 제N 출력과 대응되는 기능 호출 작업을 수행하고, 제N+1 출력을 초기 입력에 대한 회신으로 하되, 여기서, N은 2보다 큰 정수인 단계 S1002를 포함할 수 있으며, 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 단계 S1001은, 제2 기능 컴 포넌트가 제2 중간 문의에 기반하여 결정한 제2 중간 결과를 획득하는 단계; 적어도 제2 입력 및 제2 중간 결과 에 기반하여, 딥러닝 모델에 사용되는 제3 입력을 결정하는 단계; 및 딥러닝 모델의 제3 출력을 획득하는 단계를 포함한다. 이로써, 상기 방식을 통해, 딥러닝 모델은 모델이 외부 기능 컴포넌트에 대하여 호출할 필요가 없다고 결정할 때까지 기능 컴포넌트 호출을 여러 차례 수행할 수 있다. 일부 실시예에 따르면, 제2 기능 컴포넌트 및 제N 기능 컴포넌트는 각각, 외부 서치 엔진; 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델; 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스; 및 외부 기억 장치를 포함하는 기능 컴포넌트 그룹 중 하나일 수 있고, 외부 기억 장치에는 사용자 와 관련된 제1 데이터 세트 그룹이 저장되며, 여기서, 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 딥러닝 모델이 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함한다. 일부 실시예에 따르면, 제2 출력은 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않을 수 있다. 딥러닝 모델의 제2 출력을 획득하여, 초기 입력에 대한 회신을 생성하는 단계 S205는, 제2 출력을 초기 입력에 대한 회신으로 하는 단계를 포함할 수 있다. 이로써, 모델이 생성한 제2 출력 에 임의의 하나의 기능 컴포넌트와 대응되는 토큰이 포함되지 않을 경우, 모델이 출력한 초기 입력에 대한 최종 회신을 획득할 수 있다. 아래 일부 예시적 실시예를 결합하여 딥러닝 모델 및 지능화 시스템의 다양한 능력이 강화된 효과를 더 설명한 다. 하나의 예시적 실시예에서, 도 11에 도시된 바와 같이, 능력이 강화되지 않은 대화 시스템이 모델에 내재화된 지식에 기반하여 생성한 회신 내용은 간단하고, 사용자 입력에서 설명되는 임무를 완성할 수 없으므로, 사용자 요구를 만족시킬 수 없다. 본 발명에서 설명되는 능력이 강화된 지능화 시스템은 사용 자 입력이 나타내는 의도를 정확히 이해할 수 있고, 나아가 외부 기억 장치, 서치 엔진/검색 모델, API 등 외부 컴포넌트를 이용하여 과거 기억 조회, 문장 생성, API를 호출하여 이메일 발송 등 다양한 임 무를 정확히 완성할 수 있으며, 정확한 논리로 상술한 임무를 완성할 수 있다. 이 밖에, 문장 생성 시, 모델은 외부 서치 엔진/검색 모델을 이용하여 획득한 디스플레이 정보를 문장 소재로 할 수 있고, 내재화된 지식을 이용하여 획득한 이러한 소재를 선택, 통합, 윤색하고, 시작, 끝 및 과도 단락을 생성하여 하나의 완전한 문장으로 결합할 수 있다. 도 11에 도시된 바와 같이, 지능화 시스템이 생성한 문장에서, \"X시는 경치가 아름다운 도시입니다\"와 \"X시를 여행할 기회가 있다면 반드시 이 도시를 좋아하게 될 것입니다\"는 두 단락은 모델에 내재화된 지식에 따라 생성된 내용일 수 있고, 중간의 여행 계절, 음식 및 가는 방식에 관한 세 단락의 내용은 세 편의 검색 결과에서 유래한 것이며, 검색 결과의 기초상에서 윤색 보정하여 생성된 것이다. 이로써, 상기 방식을 통해, 높은 품질의 회신 내용을 생성할 수 있다. 하나의 예시적 실시예에서, 도 12에 도시된 바와 같이, 능력이 강화되지 않은 대화 시스템은 사용자와의 과거 대화를 획득할 수 없으므로, 사용자 입력에서 설명되는 임무를 완성할 수 없고, 사용자 요구를 만족시킬 수 없다. 비교해 보면, 본 발명에서 설명되는 능력이 강화된 지능화 시스템은 사용자 입력이 나타내는 의 도를 정확히 이해할 수 있고, 나아가 외부 기억 장치, API, 서치 엔진/검색 모델 등 외부 컴 포넌트를 이용하여 과거 기억 조회, API를 호출하여 플레이 뮤직, 가사 조회 등 다양한 임무를 정확하게 완성할 수 있으며, 정확한 논리로 상술한 임무를 완성할 수 있다. 이로써, 딥러닝 모델 및 지능화 시스템에 대한 다양 한 능력 강화를 나타냈다. 단계 S201로 돌아가, 일부 실시예에 따르면, 초기 입력은 입력 데이터의 컨텍스트 정보를 포함할 수 있다. 컨텍 스트 정보는 획득한 사용자의 입력 데이터 전에, 사용자와 지능화 시스템에서 발생한 여러 차례의 대화를 포함 할 수 있다. 일부 실시예에서, 컨텍스트 정보는 사용자와 지능화 시스템의 현재 회화에서, 사용자와 지능화 시스템의 여러 차례 대화를 포함하지만, 사용자와 지능화 시스템의 과거 회화에서 전송한 대화를 포함하지 않는다. 다시 말해, 사용자가 지능화 시스템의 애플리케이션 또는 서비스를 종료한 후, 컨텍스트 정보는 삭제되고; 사용자가 지능화 시스템의 애플리케이션 또는 서비스를 다시 시작하면, 컨텍스트 정보는 다시 기록된다. 이 밖에, 딥러닝 모델의 입력 길이가 제한되므로, 컨텍스트 정보는 일반적으로 기설정된 인코딩 가능한 최대 길 이를 구비하고, 기억력이 제한된다. 따라서, 사용자와 지능화 시스템이 여러 차례 또는 긴 내용의 대화를 진행 한 후, 컨텍스트 정보 중의 일부 내용이 포기될 수 있다. 일부 실시예에 따르면, 외부 기억 장치에서 과거 대화 정보를 획득할 경우, 사용자의 입력 데이터의 기초상에서, 컨텍스트 정보를 참고로 사용할 수도 있다. 이 밖에, 과거 회신 항목을 획득하는 외에도, 대응되는 과거 입력 데이터 항목을 획득할 수도 있다. 도 13에 도시된 바와 같이, 딥러닝 모델에 사용되는 초기 입력을결정하는 단계 S201은, 외부 기억 장치에서 입력 데이터 및 컨텍스트 정보와의 유사도가 제4 임계값에 부합되는 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목을 획득하는 단계 S1301; 및 입력 데이터, 컨텍스트 정 보 및 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목에 기반하여, 딥러닝 모델에 사용되는 초기 입력 을 결정하는 단계 S1302를 포함할 수 있다. 이로써, 사용자의 입력 데이터 및 컨텍스트 정보를 사용하여 유사도 를 계산하는 것을 통해, 외부 기억 장치에서 더 효과적인 과거 대화 정보를 획득할 수 있도록 하며; 입력 데이 터, 컨텍스트 정보, 및 대응되는 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목을 이용하는 것을 통 해, 딥러닝 모델이 생성한 회신의 품질을 더 향상할 수 있다. 일부 실시예에서, 다른 외부 기능 컴포넌트에 대하여, 상응한 제1 중간 문의를 생성할 경우, 사용자의 입력 데 이터 및 컨텍스트 정보를 참고로 사용할 수도 있다. 이해할 수 있는 것은, 본 발명의 방법을 수행할 경우, 요구에 따라 제1 임계값, 제2 임계값, 제3 임계값 및 제4 임계값을 설정할 수 있다. 이러한 기설정된 임계값은 동일할 수 있고, 상이할 수도 있으며, 여기서 한정하지 않 는다. 지능화 시스템 및 이에 배치된 이해 생성 대형 모델은 풍부한 형태로 생성된 회신을 나타낼 수 있고, 사용자와 인터랙션하여 사용자 체험을 향상할 수 있다. 일부 실시예에서, 대화 시스템은 단일 서치 결과에 따라 최종 회신을 생성하므로, 답안이 불완전하거나 답안 오 류의 상황이 나타날 수 있다. 도 14에 도시된 바와 같이, 본 발명의 지능화 시스템은 서치 또는 검색 후 온라인 계산을 통해 답안을 집약적으로 보여주는 방법을 구현할 수 있다(단일 답안 집합 및 여러 답안 집합이 모두 구 현될 수 있음). 일부 실시예에서, 도 15에 도시된 바와 같이, 검색된 내용을 중합하여 보여주는 외에, 지능화 시스템은 자체적 으로 예를 들면 시, 소설, 우편물, 총결산 보고서, 작문, 마케팅 문안 등 답안을 생성할 수도 있고, 그 외에도 학과와 관련된 수학적 추리와 상식적 추리를 할 수 있다. 이러한 결과에 대하여, 지능화 시스템은 구조적으로 보여줄 수 있다. 일부 실시예에서, 지능화 시스템은 사용자와 여러 차례의 해명, 능동적 안내, 심층 토픽 질의응답 및 명령 실행 을 통해, 인터랙션 표현을 구현한다. 일부 예시적 실시예에서, 도 16 중의 A부분에 도시된 바와 같이, 지능화 시스템은 사용자에게 대화의 주제와 내용을 적극적으로 설명하여, 사용자의 기대에 보다 부합하는 내용을 생성 할 수 있으며; 도 16 중의 B부분에 도시된 바와 같이, 지능화 시스템은 사용자에 대하여 능동적 안내를 통해, 사용자의 구체적인 요구를 발굴할 수 있다. 본 발명의 또 다른 양태에 따르면, 딥러닝 모델의 트레이닝 방법을 제공한다. 딥러닝 모델은 사용자의 입력 데 이터에 기반하여 회신 데이터를 생성한다. 도 17에 도시된 바와 같이, 트레이닝 방법은, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하되, 제1 샘플 초기 입력은 딥러닝 모델과 구별되는 제1 기 설정된 기능 컴포넌트를 호출하기 위한 의도 표현을 포함하고, 여기서, 제1 샘플 출력은 제1 기설정된 기능 컴 포넌트를 호출하기 위한 제1 토큰 및 제1 기설정된 기능 컴포넌트에 의해 인식될 수 있는 제1 샘플 중간 입력을 포함하는 단계 S1701; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하되, 제2 샘플 초기 입력은 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 의도 표현을 포함 하지 않으며, 여기서, 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포 함하지 않는 단계 S1702; 딥러닝 모델을 이용하여 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력을 획득하 는 단계 S1703; 제1 샘플 출력과 제1 예측 출력의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하는 단계 S1704; 딥러닝 모델을 이용하여 제2 샘플 초기 입력을 처리함으로써, 제2 예측 출력을 획득하는 단계 S1705; 및 제2 샘플 출력과 제2 예측 출력의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하는 단계 S1706을 포함한다. 이로써, 상기 방식을 통해 딥러닝 모델을 트레이닝하여, 트레이닝된 딥러닝 모델이 특정 기설정된 기능 컴포넌 트를 호출해야 할 경우 해당 기설정된 기능 컴포넌트에 대응되는 토큰 및 해당 기설정된 기능 컴포넌트에 의해 인식될 수 있는 중간 문의를 출력하도록 하고, 임의의 하나의 기능 컴포넌트를 호출할 필요가 없을 경우 임의의 하나의 기설정된 기능 컴포넌트와 대응되는 토큰 및 중간 입력을 포함하지 않는 출력 내용을 생성하여, 모델이 이해, 결정 및 생성 등 임무를 수행할 수 있는 능력을 갖도록 하며, 외부 기능 컴포넌트를 이용하여 딥러닝 모 델에 대한 능력을 강화시켜, 생성된 회신 데이터의 품질을 향상시킨다. 일부 실시예에서, 단계 S1701 전에, 먼저 이해 생성 대형 모델에 대하여 언어 텍스트 및 선험적 지식의 혼합 트 레이닝을 수행할 수 있다. 이해 생성 대형 모델은 대량 텍스트 데이터(예를 들어, 인터넷 데이터), 지식 그래프, 약한 감독 데이터에서 트 레이닝할 수 있다. 이 밖에, 인공적으로 총괄한 지식을 모델에 추가하는 것도 특히 중요하다. 인공적으로 총괄 한 선험적 지식은 모델을 도와 더 잘 언어를 이해하고, 언어를 생성하며, 결정을 내림으로써, 모델이 사람과 효 율적이고 원활하게 인터랙션할 수 있도록 한다. 구체적인 단계는 하기와 같다. 1) 인터넷 상의 텍스트 데이터를 수집하고, 이에 대하여 저품질 및 소음 제거 처리를 수행하여, 빅데이터 중의 무효, 중복된 정보를 제거한다. 2) 선험적 지식 융합 단계는, 주로 3 가지 지식을 포함한다. A, 인터넷에 기반하여 구축된 대량의 지식 그래프: <실체-속성-속성값> 또는 <실체-관계-실체2>를 포함하고; 예 를 들어 <스타A-키-172>, <스타A-부부-스타B>이다. B, 고품질 수동 사전 표시 데이터: 분류 및 라벨링 데이터와 같은 다양한 작업을 수동으로 표시하여 'XX가 새로 운 남자 농구 의장으로 선출됨'은 <XX가 새로운 남자 농구 의장으로 선출됨> - '스포츠' 또는 Q&A 데이터: <초 콜릿을 장기간 먹으면 당뇨병에 걸릴 수 있습니까? - '아니오'>로 표시된다. C, 업무 지식: 의료, 안전, 교통, 금융, 에너지 산업의 사전과 같은 산업 구조화 지식. 3) 도 18에 도시된 바와 같이, 지식 융합 기술에서, 위의 세 가지 유형의 구조화된 지식은 언어 템플릿 을 통해 자연 언어 설명 형태(즉, 자연 언어 형태의 데이터)으로 변환된 다음, 인터넷 텍스트 데이 터와 혼합하여 학습한다. 하나의 예시적 실시예에서, 구조화 지식 <스타A-부부-스타B>는 언어화 템플릿을 통해 '스타A의 마누라는 스타B'와 같은 자연어 형식의 데이터로 변환할 수 있다. 혼합 학습 방법을 통해 모델은 자연 언어를 더 잘 이해하여 기본 대화 및 인터랙션 능력을 가질 수 있다. 일부 실시예에서, 단계 S1701에서 획득한 제1 샘플 데이터 및 단계 S1702에서 획득한 제2 샘플 데이터에 대하여, 제1 샘플 초기 입력 및 제2 샘플 초기 입력은 진실된 사용자 데이터 또는 만들어진 데이터일 수 있고, 입력 데이터(선택 가능하게, 컨텍스트 정보)를 포함할 수 있다. 제1 샘플 초기 입력은 딥러닝 모델과 구별되는 제1 기설정된 기능 컴포넌트를 호출하기 위한 의도 표현을 포함하고, 다시 말해, 제1 샘플 초기 입력에서 설명 되는 내용은 모델이 제1 기설정된 기능 컴포넌트를 호출하길 필요로 하거나 희망한다. 제2 샘플 초기 입력은 딥 러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 의도 표현을 포함하지 않고, 다 시 말해, 제2 샘플 초기 입력에서 설명되는 내용은 모델이 임의의 하나의 기설정된 기능 컴포넌트를 호출할 필 요가 없거나 희망하지 않는다. 제1 샘플 출력 및 제2 샘플 출력은 딥러닝 모델이 출력하길 희망하는 결과, 즉 진리값(ground truth)일 수 있다. 일부 실시예에서, 제1 샘플 출력에 포함되는 제1 토큰은 대응되는 제1 기설정된 기능 컴포넌트와 대응됨으로써, 트레이닝된 딥러닝 모델이 해당 토큰을 통해 호출해야 할 제1 기설정된 기능 컴포넌트를 지시할 수 있도록 한다. 일부 실시예에서, 모델이 출력한 제1 토큰은 해당 제1 기설정된 기능 컴포넌트와 대응되는 마크업 (markup)형태로 코딩될 수 있고, API 호출 결과를 문자 부호열로 변환하여, 트레이닝된 모델이 텍스트 처리 방 식으로 결정, 정보 생성 호출 및 결과 이해 호출을 수행할 수 있도록 한다. 일부 실시예에서, 제1 샘플 출력에 포함되는 제1 샘플 중간 입력은 외부 제1 기설정된 기능 컴포넌트에 의해 처 리됨으로써, 해당 제1 기설정된 기능 컴포넌트가 리턴한 결과를 획득할 수 있다. 제1 기설정된 기능 컴포넌트가 외부 기억 장치일 경우, 제1 샘플 중간 입력은 외부 기억 장치에 의해 유사도를 계산할 수 있는 사용자의 입력 데이터(선택 가능하게, 컨텍스트 정보)일 수 있다. 제1 기설정된 기능 컴포넌트가 서치 엔진일 경우, 제1 샘플 중간 입력은 서치 엔진에 의해 인식될 수 있는 서치식일 수 있다. 제1 기설정된 기능 컴포넌트가 검색 모델일 경우, 제1 샘플 중간 입력은 검색 모델에 의해 처리될 수 있는 쿼리일 수 있다. 제1 기설정된 기능 컴포넌트가 특정 API일 경우, 제1 샘플 중간 입력은 해당 API와 대응되는 마크업(markup)형태로 코딩될 수 있다. 상기 방식 을 통해, 트레이닝된 모델이 이러한 기설정된 기능 컴포넌트에 의해 인식될 수 있는 중간 입력을 출력할 수 있 는 능력을 갖도록 한다. 일부 실시예에서, 단계 S1703에서 획득한 딥러닝 모델이 출력한 제1 예측 출력은 제1 샘플 출력과 비슷할 수 있 고, 완전히 상이할 수도 있지만, 딥러닝 모델 트레이닝에 대한 타겟은, 트레이닝된 모델이 생성한 제1 예측 출 력이 제1 기설정된 기능 컴포넌트를 호출하기 위한 토큰 및 제1 기설정된 기능 컴포넌트에 의해 인식될 수 있고 제1 샘플 중간 입력의 기능 또는 의미와 일치한 예측 중간 입력을 포함하도록 하는 것이다. 일부 실시예에서, 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하 지 않으므로, 제2 샘플 출력은 응당 딥러닝 모델이 제2 샘플 초기 입력에 대한 회신이다. 단계 S1705에서 획득 한 딥러닝 모델이 출력한 제2 예측 출력은 제2 샘플 출력과 비슷할 수 있고, 완전히 상이할 수도 있지만, 딥러 닝 모델 트레이닝에 대한 타겟은, 트레이닝된 모델이 생성한 제2 예측 출력에 임의의 하나의 기설정된 기능 컴 포넌트를 호출하기 위한 토큰이 포함되지 않고, 제2 샘플 초기 입력에 대한 고품질 회신 데이터를 포함하도록 하는 것이다. 일부 실시예에서, 단계 S1704 및 단계 S1706에서, 요구에 따라 상응하는 손실 함수를 결정하고, 샘플 출력 및 예측 출력의 차이를 설명하는 손실값을 계산하며, 손실값에 기반하여 딥러닝 모델의 파라미터를 조정할 수 있다. 일부 실시예에서, 제1 샘플 데이터는 제1 샘플 타겟 입력 및 제1 샘플 회신을 더 포함할 수 있다. 제1 샘플 타 겟 입력은 제1 샘플 초기 입력 및 제1 샘플 중간 입력을 기반으로 제1 기설정된 기능 컴포넌트에서 획득한 제1 샘플 중간 결과를 포함한다. 일부 실시예에서, 제1 샘플 타겟 입력은 제1 샘플 중간 입력을 더 포함할 수 있다. 제1 샘플 회신은 제1 샘플 중간 결과를 이용하여 만들어진 제1 샘플 초기 입력에 대한 진실된(ground truth) 회 신이다. 트레이닝 방법은, 딥러닝 모델을 이용하여 제1 샘플 타겟 입력을 처리함으로써, 제1 예측 회신을 획득 하는 단계; 및 제1 샘플 회신과 제1 예측 회신의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하는 단계를 더 포함할 수 있다. 이로써, 상기 방식을 통해, 트레이닝된 딥러닝 모델이 외부 기능 컴포넌트에서 획득한 결과와 모델에 내재화된 지식을 결합하여 함께 사용자 요구에 대한 만족 및 회신을 완성하도록 함으로써, 최종적으로 높은 품질의 회신 내용을 얻을 수 있다. 일부 실시예에 따르면, 도 19에 도시된 바와 같이, 트레이닝 방법은, 제3 샘플 초기 입력, 샘플 서치 문의, 복 수의 샘플 서치 결과, 및 딥러닝 모델이 제3 샘플 초기 입력에 대한 제3 샘플 회신을 포함하는 제3 샘플 데이터 를 획득하되, 샘플 서치 문의는 딥러닝 모델이 제3 샘플 초기 입력을 기반으로 생성한 샘플 중간 입력이고, 샘 플 중간 입력은 딥러닝 모델과 구별되는 검색 모델에 의해 인식될 수 있으며, 여기서, 복수의 샘플 서치 결과는 검색 모델이 샘플 서치 문의에 기반하여 출력한 결과인 단계 S1907; 복수의 샘플 서치 결과 각자와 제3 샘플 회 신 사이의 일치도에 기반하여, 복수의 샘플 서치 결과에 대하여 배열 작업을 수행하는 단계 S1908; 및 배열된 복수의 샘플 서치 결과에 기반하여, 검색 모델을 트레이닝하는 단계 S1909를 더 포함할 수 있다. 이해할 수 있 는 것은, 도 19 중의 단계 S1901~단계 S1906의 작업은 각각 도 17 중의 단계 S1701~단계 S1706의 작업과 유사하 며, 여기서 더 이상 설명하지 않는다. 이로써, 제3 샘플 데이터 중 복수의 샘플 서치 결과의 배열 결과를 결정하는 것을 통해, 나아가 해당 배열 결과 를 감독으로 이용하여 검색 모델을 트레이닝하며, 이해 생성 대형 모델 및 검색 모델의 연합 최적화를 구현함으 로써, 양자가 협동할 수 있도록 하고, 외부 검색 모델이 더 정확하고 회신 생성에 더 적합한 내용을 이해 생성 대형 모델에 제공하도록 함으로써, 이해 생성 대형 모델이 사용자 의도에 더 적합하고 더 높은 품질의 회신을 생성하도록 한다. 일부 실시예에서, 제3 샘플 데이터에 포함되는 샘플 서치 문의는 예를 들어 검색 query일 수 있고, 복수의 샘플 서치 결과는 예를 들어 검색 모델에 사용되는 검색 창고에서 제3 샘플 초기 입력의 요구에 부합되고 제3 샘플 초기 입력에 대한 제3 샘플 회신을 통합하여 생성한 복수의 내용일 수 있으며, 제3 샘플 회신은 인공적으로 복 수의 샘플 서치 결과를 참조하여 선택, 보정, 윤색 등 단계를 수행하여 얻은 내용일 수 있다. 일부 실시예에서, 도 17 중의 단계 S1701, 단계 S1703~단계 S1704의 방식을 참조하여 제3 샘플 데이터를 이용하여 딥러닝 모델을 트레이닝하여, 딥러닝 모델이 상기 선택, 보정, 윤색 등 단계를 자동적으로 수행하는 능력을 갖도록 할 수 있다. 일부 실시예에서, 단계 S1908에서, 복수의 샘플 서치 결과와 제3 샘플 회신 사이의 내용 일치도를 계산할 수 있 고, 예를 들어 의미 벡터에 기반하여 유사도를 계산할 수 있다. 일부 실시예에 따르면, 도 20에 도시된 바와 같이, 복수의 샘플 서치 결과 각자와 제3 샘플 회신 사이의 일치도 에 기반하여, 복수의 샘플 서치 결과에 대하여 배열 작업을 수행하는 단계 S1908은, 복수의 샘플 서치 결과에서 현재 일치도가 가장 높은 제1 샘플 서치 결과를 선별하는 단계 S2001; 제3 샘플 회신과 제1 샘플 서치 결과 사 이의 중합 내용을 삭제하여, 제3 샘플 회신을 업데이트하는 단계 S2002; 및 복수의 샘플 서치 결과의 나머지 부 분 각자와 업데이트된 제3 샘플 회신 사이의 일치도에 기반하여, 복수의 샘플 서치 결과 중 모든 샘플 서치 결과에 대한 배열을 완성할 때까지 나머지 부분에 대하여 배열 작업을 반복하는 단계 S2003을 포함할 수 있다. 이로써, 상기 방식을 통해, 제3 샘플 회신을 생성하기 위한 복수의 샘플 서치 결과에 대한 배열을 구현함으로써, 이해 생성 대형 모델과 검색 모델의 연합 최적화를 구현할 수 있다. 일부 실시예에 따르면, 검색 모델은 배열 서브 모델 및 소환 서브 모델을 포함할 수 있다. 배열된 복수의 샘플 서치 결과에 기반하여, 검색 모델을 트레이닝하는 단계 S1909는, 배열된 복수의 샘플 서치 결과에 기반하여, 검 색 모델의 배열 서브 모델을 트레이닝하는 단계; 및 트레이닝된 배열 서브 모델을 교사 모델로 하여, 소환 서브 모델을 트레이닝하는 단계를 포함할 수 있다. 이로써, 상기 방식을 통해, 이해 생성 대형 모델, 검색 모델 중의 배열 서브 모델 및 소환 서브 모델 삼자간의 연합 최적화를 구현한다. 일부 실시예에서, 배열 서브 모델은 엔드 투 엔드의 서치를 위한 정렬 모델(Cross-Encoder)이다. 정렬 모델의 입력에는 쿼리(query, q)와 문서(passage, p)가 포함되며, 출력은 둘의 유사도 sim(q, p)이다. 목록 방법 손실 (listwise loss)을 감독으로 사용하여 정렬 모델 출력의 배열 결과와 복수의 샘플 서치 결과에 대해 생성된 배 열 결과가 유사하거나 일치하도록 할 수 있다. 일부 실시예에서, 소환 서브 모델은 이중 타워 모델(Bi-Encoder)일 수 있다. 여기서, 하나의 타워는 쿼리 q의 고유 벡터를 생성하는 데 사용되고, 다른 타워는 문서 p의 고유 벡터를 생성하는 데 사용되다. 이 두 고유 벡터 에 따라, 둘 사이의 유사성을 계산할 수 있다. 배열 모델이 트레이닝된 후, 모델 증류의 방식을 통해, 배열 모 델을 교사 모델로서 소환 모델에 대하여 트레이닝 샘플을 구축하고, 소환 모델의 최적화 타겟이 배열 모델과 일 치하도록 하며, 나아가 이해 생성 대형 모델과 검색 모델의 연합 최적화를 구현한다. 하나의 예시적 실시예에서, KL-산도를 교사 모델인 배열 모델을 사용하여 소환 모델을 트레이닝하기 위한 감독으로 사용할 수 있다. 일부 실시예에서, 연합 트레이닝을 수행하기 전에, 엔드 투 엔드의 검색 모델에 대하여 단독적으로 트레이닝할 수 있다. 하나의 예시적 실시예에서, 소환 서브 모델 및 배열 서브 모델에 대하여 연합 트레이닝을 수행할 수 있다. 일부 실시예에 따르면, 도 21에 도시된 바와 같이, 트레이닝 방법은, 제4 샘플 초기 입력, 외부 기억 장치에 의 해 인식될 수 있는 제4 샘플 중간 입력, 샘플 기억 결과 및 제4 샘플 회신을 포함하는 제4 샘플 데이터를 획득 하되, 제4 샘플 중간 입력은 제4 샘플 초기 입력을 기반으로 결정된 것인 단계 S2107; 외부 기억 장치가 제4 샘 플 중간 입력을 기반으로 결정한 예측 기억 결과를 획득하는 단계 S2108; 예측 기억 결과와 샘플 기억 결과의 비교에 기반하여, 외부 기억 장치의 파라미터를 조정하는 단계 S2109; 적어도 제4 샘플 초기 입력 및 샘플 기억 결과에 기반하여, 딥러닝 모델에 사용되는 제4 샘플 타겟 입력을 결정하는 단계 S2110; 딥러닝 모델을 이용하여 제4 샘플 타겟 입력을 처리함으로써, 제4 예측 회신을 획득하는 단계 S2111; 및 제4 샘플 회신과 제4 예측 회신 의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하는 단계 S2112를 더 포함할 수 있다. 이해할 수 있는 것 은, 도 21 중의 단계 S2101~단계 S2106의 작업은 각각 도 17 중의 단계 S1701~단계 S1706의 작업과 비슷하고, 여기서 더 이상 설명하지 않는다. 이로써, 외부 기억 장치와 이해 생성 대형 모델의 연합 트레이닝을 구현한다. 이해할 수 있는 것은, 상기 방식을 통해 얻은 외부 기억 장치는 외부 기능 컴포넌트로서 위에서 설명된 데이터 생성 방법에서 사용되어, 외부 기억을 획득할 수 있다. 일부 실시예에서, 기억 조회 및 이해 생성 대형 모델을 연합 트레이닝하는 트레이닝 타겟은 기억 강화된 회신 생성 확률을 최대화 하는 것이다."}
{"patent_id": "10-2023-0130660", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, M은 외부 기억 장치이고, ct는 외부 기억 장치와 대응되는 샘플 중간 입력으로서, 샘플 초기 입력 및 컨텍스트 정보를 포함할 수 있으며, mi은 조회된 과거 대화(즉, 데이터 세트)이고, r은 딥러닝 모델이 생성한 회신이다. 상응하게, 은 기억 조회 과정이고, 은 기억 강화된 회신 생성 과정이다. 해당 트레이닝 타겟에 기반하여 외부 기억 장치와 이해 생성 대형 모델을 연합 최적화함으로써, 연합 최적화된 외부 기억 장치가 사용자 입력과의 관련성이 높고, 회신 생성에 도움되는 과거 대화를 제공할 수 있도록 함으로 써, 연합 최적화된 이해 생성 대형 모델은 획득한 과거 대화에 기반하여 사용자 입력에 대하여 높은 품질의 회 신 내용을 생성할 수 있다. 일부 실시예에서, 위에서 설명된 바와 같이, 밀집 벡터 유사도를 계산하는 방식을 통해 외부 기억 장치에서 사 용자 입력과 관련되는 과거 대화 정보를 획득할 수 있고, 구체적으로 신경 네트워크를 이용하여 구현할 수 있다. 단계 S2109에서, 밀집 벡터 유사도 계산에 사용되는 신경 네트워크의 파라미터를 조정하여, 제4 샘플 초 기 입력을 기반으로 결정된 제4 샘플 중간 입력과 샘플 기억 결과의 유사도를 향상함으로써, 최적화된 신경 네 트워크(외부 기억 장치)가 제4 샘플 중간 입력에 대하여 샘플 기억 결과를 리턴할 수 있도록 한다. 이해할 수 있는 것은, 단계 S2112에서 딥러닝 모델에 대한 파라미터 조정은 도 17 중의 단계 S1704 또는 단계 S1706을 참 조할 수 있고, 여기서 더 이상 설명하지 않는다. 본 발명의 또 다른 양태에 따르면, 딥러닝 모델 기반의 데이터 생성 장치를 제공한다. 딥러닝 모델은 사용자의 입력 데이터에 기반하여 회신 데이터를 생성할 수 있다. 도 22에 도시된 바와 같이, 데이터 생성 장치는 사용자로부터의 입력 데이터에 기반하여, 딥러닝 모델에 사용되는 초기 입력을 결정하도록 구성되는 제1 결정 유닛; 딥러닝 모델의 제1 출력을 획득하도록 구성되되, 딥러닝 모델에 응답하여 초기 입력을 기반으로 생 성한 회신을 결정하기 위해서는 딥러닝 모델과 구별되는 제1 기능 컴포넌트를 호출해야 하며, 제1 출력은 제1 기능 컴포넌트를 호출하기 위한 제1 토큰 및 초기 입력을 기반으로 결정되고 제1 기능 컴포넌트에 의해 인식될 수 있는 제1 중간 문의를 포함하는 제1 획득 유닛; 제1 기능 컴포넌트가 제1 중간 문의에 기반하여 결정 한 제1 중간 결과를 획득하도록 구성되는 제2 획득 유닛; 적어도 초기 입력 및 제1 중간 결과에 기반하여, 딥러닝 모델에 사용되는 제2 입력을 결정하도록 구성되는 제2 결정 유닛; 및 딥러닝 모델의 제 2 출력을 획득하여, 초기 입력에 대한 회신을 생성하도록 구성되는 제3 획득 유닛을 포함한다. 이해할 수 있는 것은, 장치 중 유닛~유닛의 작업은 각각 도 2 중의 단계(S201)~단계(S205)의 작업과 유사하며, 여기서 더 이상 설명하지 않는다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 외부 기억 장치일 수 있고, 외부 기억 장치에는 사용자와 관련된 제1 데이터 세트 그룹이 더 저장될 수 있다. 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 딥러닝 모델이 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함할 수 있다. 일부 실시예에 따르면, 제1 데이터 세트 그룹 중 각각의 데이터 세트는 상기 세트 중 과거 입력 데이터 항목 및 과거 회신 항목과 대응되는 등록 시간 항목을 더 포함할 수 있다. 일부 실시예에 따르면, 제1 중간 문의는 입력 데이터에 기반할 수 있다. 제1 중간 결과는 제1 데이터 세트 그룹 중 입력 데이터와의 유사도가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목일 수 있 다. 일부 실시예에 따르면, 제1 중간 문의는 입력 데이터에 기반할 수 있다. 제1 중간 결과는 제1 데이터 세트 그룹 중 입력 데이터와의 유사도가 제1 임계값보다 높고 타임스탬프가 최신인 과거 입력 데이터 항목에 대응되는 과 거 회신 항목일 수 있다. 일부 실시예에 따르면, 데이터 생성 장치는 입력 데이터 및 회신에 기반한 제1 데이터 세트와 제1 데이터 세트 그룹 중 임의의 하나의 데이터 세트 사이의 유사도가 제2 임계값보다 낮다고 결정한 것에 응답하여, 제1 데이터 세트를 제1 데이터 세트 그룹에 등록하도록 구성되는 제1 등록 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 데이터 생성 장치는 입력 데이터 및 회신에 기반한 제1 데이터 세트와 제1 데이터 세트 그룹 중 제2 데이터 세트 사이의 유사도가 제3 임계값보다 높다고 결정하며 제1 데이터 세트와 제2 데이터 세트 가 서로 충돌된다고 결정한 것에 응답하여, 제1 데이터 세트를 제1 데이터 세트 그룹에 등록하고, 제1 데이터 세트 그룹에서 제2 데이터 세트를 삭제하도록 구성되는 제2 등록 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 데이터 생성 장치는 등록 시간 항목에 기반하여, 외부 기억 장치에서 시효가 지난 데이 터 세트를 삭제하도록 구성되는 삭제 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 제1 결정 유닛은 입력 데이터에 기반하여, 외부 기억 장치에서 입력 데이터와의 유사도 가 제1 임계값보다 높은 과거 입력 데이터 항목에 대응되는 과거 회신 항목을 획득하도록 구성되는 제1 획득 서 브 유닛; 및 입력 데이터 및 과거 회신 항목에 기반하여, 초기 입력을 결정하도록 구성되는 제1 결정 서브 유닛 을 포함할 수 있다. 외부 기억 장치에는 사용자와 관련된 제1 데이터 세트 그룹이 저장될 수 있다. 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 딥러닝 모델이 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함할 수 있다. 일부 실시예에 따르면, 제2 결정 유닛은 초기 입력, 제1 중간 결과 및 제1 중간 문의에 기반하여, 딥러닝 모델 에 사용되는 제2 입력을 결정하도록 구성되는 제3 결정 서브 유닛을 포함할 수 있다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 외부 서치 엔진일 수 있다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델일 수 있다. 일부 실시예에 따르면, 제1 기능 컴포넌트는 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스일 수 있다. 일부 실시예에 따르면, 제2 출력은 제2 기능 컴포넌트를 호출하기 위한 제2 토큰 및 제2 입력을 기반으로 얻어 지고 제2 기능 컴포넌트에 의해 인식될 수 있는 제2 중간 문의를 포함할 수 있다. 제3 획득 유닛은, 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하도록 구성되는 제3 획득 서브 유닛; 및 딥러닝 모델의 제N 출력에 제N 기능 컴포넌트를 호출하기 위한 제N 토큰 및 제N 입력을 기반으로 얻어지고 제N 기능 컴포넌트에 의해 인식될 수 있는 제N 중간 문의가 포함되는 것에 응답하여, 제N+1 출력에 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰이 포함되지 않다고 결정될 때까지 제N 출력과 대응되는 기능 호출 작업을 수행하고, 제N+1 출력을 초기 입력에 대한 회신으로 하되, N은 2보다 큰 정수이도록 구성되는 호출 서브 유닛을 포함할 수 있으며, 제2 출력에 대하여 대응되는 기능 호출 작업을 수행하는 단계는, 제2 기능 컴포넌트가 제2 중간 문의에 기반하여 결정한 제2 중간 결과를 획득하는 단계; 적어도 제2 입력 및 제2 중간 결과에 기반하여, 딥러닝 모델에 사용되는 제3 입력을 결정하는 단계; 및 딥러닝 모델의 제3 출력을 획득하는 단계를 포함한다. 일부 실시예에 따르면, 제2 기능 컴포넌트 및 제N 기능 컴포넌트는 각각, 외부 서치 엔진; 딥러닝 모델과 연합 트레이닝을 거쳐 얻은 검색 모델; 딥러닝 모델에 의해 호출될 수 있는 적어도 하나의 애플리케이션 프로그래밍 인터페이스; 및 외부 기억 장치 중 하나를 포함할 수 있고, 외부 기억 장치에는 사용자와 관련된 제1 데이터 세 트 그룹이 저장되며, 여기서, 제1 데이터 세트 그룹 중 각각의 데이터 세트는 적어도 과거 입력 데이터 항목 및 딥러닝 모델이 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함한다. 일부 실시예에 따르면, 제2 출력은 딥러닝 모델과 구별되는 임의의 하나의 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않을 수 있다. 제3 획득 유닛은 제2 출력을 초기 입력에 대한 회신으로 하도록 구성되는 회신 서브 유닛을 포함할 수 있다. 일부 실시예에 따르면, 초기 입력은 입력 데이터의 컨텍스트 정보를 포함할 수 있다. 일부 실시예에 따르면, 제1 결정 유닛은 외부 기억 장치에서 입력 데이터 및 컨텍스트 정보와의 유사도가 제4 임계값에 부합되는 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목을 획득하도록 구성되는 제2 획득 서브 유닛; 및 입력 데이터, 컨텍스트 정보 및 적어도 한 쌍의 과거 입력 데이터 항목과 과거 회신 항목에 기반 하여, 딥러닝 모델에 사용되는 초기 입력을 결정하도록 구성되는 제2 결정 서브 유닛을 포함할 수 있다. 외부 기억 장치에는 사용자와 관련된 제1 데이터 세트 그룹이 저장될 수 있다. 제1 데이터 세트 그룹 중 각각의 데이 터 세트는 적어도 과거 입력 데이터 항목 및 딥러닝 모델이 과거 입력 데이터 항목에 대하여 생성한 과거 회신 항목을 포함할 수 있다. 본 발명의 또 다른 양태에 따르면, 딥러닝 모델의 트레이닝 장치를 제공한다. 딥러닝 모델은 사용자의 입력 데 이터에 기반하여 회신 데이터를 생성한다. 도 23에 도시된 바와 같이, 트레이닝 장치는, 제1 샘플 초기 입력 및 제1 샘플 출력을 포함하는 제1 샘플 데이터를 획득하도록 구성되되, 제1 샘플 초기 입력은 딥러닝 모델 과 구별되는 제1 기설정된 기능 컴포넌트를 호출하기 위한 의도 표현을 포함하고, 여기서, 제1 샘플 출력은 1 기설정된 기능 컴포넌트를 호출하기 위한 제1 토큰 및 제1 기설정된 기능 컴포넌트에 의해 인식될 수 있는 제1 샘플 중간 입력을 포함하는 제4 획득 유닛; 제2 샘플 초기 입력 및 제2 샘플 출력을 포함하는 제2 샘플 데이터를 획득하도록 구성되되, 제2 샘플 초기 입력은 딥러닝 모델과 구별되는 임의의 하나의 기설정된 기능 컴 포넌트를 호출하기 위한 의도 표현을 포함하지 않으며, 여기서, 제2 샘플 출력은 임의의 하나의 기설정된 기능 컴포넌트를 호출하기 위한 해당 토큰을 포함하지 않는 제5 획득 유닛; 딥러닝 모델을 이용하여 제1 샘플 초기 입력을 처리함으로써, 제1 예측 출력을 획득하도록 구성되는 제1 처리 유닛; 제1 샘플 출력과 제1 예측 출력의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하도록 구성되는 제1 파라미터 조정 유닛; 딥러닝 모델을 이용하여 제2 샘플 초기 입력을 처리함으로써, 제2 예측 출력을 획득하도록 구성되는 제2 처리 유닛; 및 제2 샘플 출력과 제2 예측 출력의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하도록 구성 되는 제2 파라미터 조정 유닛을 포함한다. 이해할 수 있는 것은, 장치 중의 유닛~유닛(236 0)의 작업은 각각 도 17 중의 단계 S1701~단계 S1706의 작업과 유사하며, 여기서 더 이상 설명하지 않는다. 일부 실시예에 따르면, 트레이닝 장치는, 제3 샘플 초기 입력, 샘플 서치 문의, 복수의 샘플 서치 결과, 및 딥 러닝 모델이 제3 샘플 초기 입력에 대한 제3 샘플 회신을 포함하는 제3 샘플 데이터를 획득하도록 구성되되, 샘플 서치 문의는 딥러닝 모델이 제3 샘플 초기 입력을 기반으로 생성한 샘플 중간 입력이고, 샘플 중간 입력은 딥러닝 모델과 구별되는 검색 모델에 의해 인식될 수 있으며, 여기서, 복수의 샘플 서치 결과는 검색 모델이 샘 플 서치 문의에 기반하여 출력한 결과인 제6 획득 유닛; 복수의 샘플 서치 결과 각자와 제3 샘플 회신 사이의 일치도에 기반하여, 복수의 샘플 서치 결과에 대하여 배열 작업을 수행하도록 구성되는 배열 유닛; 및 배열된 복수의 샘플 서치 결과에 기반하여, 검색 모델을 트레이닝하도록 구성되는 트레이닝 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 배열 유닛은, 복수의 샘플 서치 결과에서 현재 일치도가 가장 높은 제1 샘플 서치 결과 를 선별하도록 구성되는 선별 서브 유닛; 제3 샘플 회신과 제1 샘플 서치 결과 사이의 중합 내용을 삭제하여, 제3 샘플 회신을 업데이트하도록 구성되는 삭제 서브 유닛; 및 복수의 샘플 서치 결과의 나머지 부분 각자와 업 데이트된 제3 샘플 회신 사이의 일치도에 기반하여, 복수의 샘플 서치 결과 중 모든 샘플 서치 결과에 대한 배 열을 완성할 때까지 나머지 부분에 대하여 배열 작업을 반복하도록 구성되는 배열 서브 유닛을 포함할 수 있다. 일부 실시예에 따르면, 검색 모델은 배열 서브 모델 및 소환 서브 모델을 포함할 수 있다. 트레이닝 유닛은, 배 열된 복수의 샘플 서치 결과에 기반하여, 검색 모델의 배열 서브 모델을 트레이닝하도록 구성되는 제1 트레이닝 서브 유닛; 및 트레이닝된 배열 서브 모델을 교사 모델로 하여, 소환 서브 모델을 트레이닝하도록 구성되는 제2 트레이닝 서브 유닛을 포함할 수 있다. 일부 실시예에 따르면, 트레이닝 장치는, 제4 샘플 초기 입력, 외부 기억 장치에 의해 인식될 수 있는 제4 샘플 중간 입력, 샘플 기억 결과 및 제4 샘플 회신을 포함하는 제4 샘플 데이터를 획득하도록 구성되되, 제4 샘플 중 간 입력은 제4 샘플 초기 입력을 기반으로 결정된 것인 제7 획득 유닛; 외부 기억 장치가 제4 샘플 중간 입력을 기반으로 결정한 예측 기억 결과를 획득하도록 구성되는 제8 획득 유닛; 예측 기억 결과와 샘플 기억 결과의 비 교에 기반하여, 외부 기억 장치의 파라미터를 조정하도록 구성되는 제3 파라미터 조정 유닛; 적어도 제4 샘플 초기 입력 및 샘플 기억 결과에 기반하여, 딥러닝 모델에 사용되는 제4 샘플 타겟 입력을 결정하도록 구성되는 제3 결정 유닛; 딥러닝 모델을 이용하여 제4 샘플 타겟 입력을 처리함으로써, 제4 예측 회신을 획득하도록 구성 되는 제3 처리 유닛; 및 제4 샘플 회신과 제4 예측 회신의 비교에 기반하여, 딥러닝 모델의 파라미터를 조정하 도록 구성되는 제4 파라미터 조정 유닛을 더 포함할 수 있다. 본 발명의 기술적 해결수단에서, 관련되는 사용자 개인 정보의 수집, 저장, 사용, 가공, 전송, 제공 및 공개 등 처리는 모두 관련 법규의 규정에 부합되고, 공서양속을 위반하지 않는다. 본 발명의 실시예에 따르면, 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한다. 도 24를 참조하면, 본 발명의 서버 또는 클라이언트로 사용될 수 있는 전자 기기의 구조 블록도를 설명하 고, 이는 본 발명의 각 양태의 하드웨어 기기의 예시에 적용될 수 있다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴 퓨터, 워크스테이션, 개인 정보 단말기, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적절한 컴퓨터와 같은 다 양한 형태의 디지털 전자인 컴퓨터를 의미한다. 전자 기기는 개인 디지털 처리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 의미할 수도 있다. 본문에서 나타낸 부 재, 이들의 연결과 관계, 및 이들의 기능은 단지 예시적인 것으로, 본문에서 설명되거나 및/또는 요구된 본 발 명의 구현을 한정하지 않는다. 도 24에 도시된 바와 같이, 전자 기기는 판독 전용 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저 장 유닛으로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 따라, 다양하고 적절한 동 작 및 처리를 수행할 수 있는 컴퓨팅 유닛을 포함한다. RAM에는, 전자 기기의 작동에 필요한 다양한 프로그램 및 데이터가 더 저장될 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연결된다. 입/출력 (I/O) 인터페이스 역시 버스에 연결된다. 전자 기기 중의 복수의 부재는 입력 유닛, 출력 유닛, 저장 유닛 및 통신 유닛(240 9)을 포함하는 I/O 인터페이스에 연결된다. 입력 유닛은 전자 기기에 정보를 입력할 수 있는 임의의 타입의 기기일 수 있고, 입력 유닛은 입력된 숫자 또는 문자 정보를 수신할 수 있으며, 전자 기기 의 사용자 설정 및/또는 기능 제어와 관련된 키 신호 입력을 생성할 수 있고, 마우스, 키보드, 터치 스크린, 트 랙 패드, 트랙 볼, 조이스틱, 마이크 및/또는 리모컨을 포함할 수 있지만 이에 한정되지 않는다. 출력 유닛 은 정보를 나타낼 수 있는 임의의 타입의 기기일 수 있고, 디스플레이, 스피커, 비디오/오디오 출력 단말 기, 진동기 및/또는 프린터를 포함할 수 있지만 이에 한정되지 않는다. 저장 유닛은 자기 디스크, 광 디 스크를 포함할 수 있지만 이에 한정되지 않는다. 통신 유닛은 전자 기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신망을 통해 다른 기기와 정보/데이터를 교환하도록 허용하고, 모뎀, 랜 카드, 적외선 통신 기기, 무선 통신 트랜시버 및/또는 칩셋을 포함하지만 이에 한정되지 않으며, 예를 들어 블루투스 TM 기기, 802.11 기기, WiFi 기기, WiMax 기기, 셀룰러 통신 기기 및/또는 유사물이다. 컴퓨팅 유닛은 다양한 처리 및 컴퓨팅 기능이 구비되는 범용 및/또는 전용 처리 컴포넌트일 수 있다. 컴 퓨팅 유닛의 일부 예시는 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 다양한 전용 인공 지능(AI) 컴퓨 팅 칩, 다양한 머신 러닝 모델 알고리즘을 실행하는 컴퓨팅 유닛, 디지털 신호 프로세서(DSP), 및 임의의 적절 한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만 이에 한정되지 않는다. 컴퓨팅 유닛은 예를 들어 데이터 생성 방법 또는 딥러닝 모델의 트레이닝 방법과 같은, 위에서 설명된 각 방법 및 처리를 수행한다. 예를 들어, 일부 실시예에서, 데이터 생성 방법 또는 딥러닝 모델의 트레이닝 방법은 컴퓨터 소프트웨어 프로그 램으로 구현될 수 있고, 이는 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함된다. 일부 실시 예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛에 의해 전자 기기에 로 딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴퓨팅 유닛에 의해 실행될 경우, 위에서 설명된 데이터 생성 방법 또는 딥러닝 모델의 트레이닝 방법 중 하나 이상의 단계를 수행할 수 있다. 대 안적으로, 다른 실시예에서, 컴퓨팅 유닛은 다른 임의의 적절한 방식을 통해(예를 들어, 펌웨어를 이용) 데이터 생성 방법 또는 딥러닝 모델의 트레이닝 방법을 구현하도록 구성될 수 있다. 본문에서 이상 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그램 가능 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스템 온 칩의 시스템 (SOC), 복합 프로그램 가능 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있다. 이러한 다양한 실시형태는 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있고, 상기 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데이터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치 에 전송할 수 있다. 본 발명의 방법을 구현하는 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합으로 편집할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 다른 프로그램 가능 데이터 처리 장치의 프로세서 또는 제어기에 제공될 수 있으며, 프로그램 코드는 프로세서 또는 제어기에 의해 실행될 경우, 흐름도 및/또는 블록 도에 지정된 기능/작동이 구현되도록 할 수 있다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적으로 기 계에서 실행되거나, 독립형 소프트웨어 패키지로서 부분적으로 기계에서 실행되고 부분적으로 원격 기계에서 실 행되거나 완전히 원격 기계 또는 서버에서 실행될 수 있다. 본 발명의 컨텍스트에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기에 의해 또는 명령 실행 시 스템, 장치 또는 기기와 결합하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있는 타입의 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 보다 구체적인 예는 하나 이상의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메모리(ROM), 소거 가능 프로그램 가능 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, CD-ROM, 광학 저 장 기기, 자기 저장 기기 또는 상술한 내용의 임의의 적절한 조합을 포함한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기서 설명된 시스템 및 기술을 실시할 수 있고, 상기 컴 퓨터는 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시 장치) 모니 터); 및 키보드 및 지향 장치(예를 들어, 마우스 또는 트랙 볼)를 구비하며, 사용자는 상기 키보드 및 상기 지 향 장치를 통해 컴퓨터에 입력을 제공한다. 다른 타입의 장치는 또한 사용자와의 인터랙션을 제공할 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 감지 피드백(예를 들어, 시각 피드백, 청각 피드백, 또 는 촉각 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력)로 사용자로부터의 입력을 수 신할 수 있다. 여기서 설명된 시스템 및 기술을 백그라운드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버), 또는 미 들웨어 부재를 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프론트 엔드 부재를 포함하는 컴퓨팅 시스 템(예를 들어, 그래픽 사용자 인터페이스 또는 웹 브라우저를 구비하는 사용자 컴퓨터이고, 사용자는 상기 그래 픽 사용자 인터페이스 또는 웹 브라우저를 통해 여기서 설명된 시스템 및 기술의 실시형태와 인터랙션할 수 있음), 또는 이러한 백그라운드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임의의 조합을 포함하는 컴퓨팅 시스템에서 실시할 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신 네트워크의 예시로 근거리 통신망(LAN), 광역 통신망(WAN), 인터 넷, 블록체인 네트워크를 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고 일반적으로 통신 네트워크를 통해 서로 인터랙션한다. 대응되는 컴퓨터에서 실행되고 또한 서로 클라이언트- 서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트와 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있고, 분산형 시스템 서버, 또는 블록체인을 결합한 서버일 수도 있다. 위에서 설명한 다양한 형태의 프로세스를 사용하여 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본 발명에 기재된 각 단계는 동시에 수행될 수 있거나 순차적으로 수행될 수 있거나 상이한 순서로 수행될 수 있고, 본 발명에서 공개된 기술적 해결수단이 이루고자 하는 결과를 구현할 수만 있으면, 본문은 여 기서 한정하지 않는다. 비록 도면을 참조하여 본 발명의 실시예 또는 예시를 설명하였으나, 상술한 방법, 시스템 및 기기는 예시적인 실시예 또는 예시일 뿐이며, 본 발명의 범위는 이러한 실시예 또는 예시에 한정되지 않고, 등록된 특허청구범위 및 이와 동등한 범위에 의해서만 한정된다는 것을 이해하여야 한다. 실시예 또는 예시의 여러 요소는 생략되거 나 동등한 요소로 대체될 수 있다. 또한, 각 단계는 본 발명에 설명된 것과 다른 순서로 수행될 수 있다. 나아 가, 실시예 또는 예시의 여러 요소들은 다양한 방식으로 조합될 수 있다. 중요한 것은 기술의 발전에 따라, 여 기에 설명된 많은 요소들은 본 발명의 이후에 발명된 동등 요소로 대체될 수 있다는 것이다."}
{"patent_id": "10-2023-0130660", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 실시예를 예시적으로 나타내고 명세서의 일부분을 구성하며, 명세서의 문자 설명과 함께 실시예의 예시 적 실시형태를 설명한다. 도시된 실시예는 단지 예시적인 목적일 뿐, 청구항의 범위를 한정하려는 것이 아니다. 모든 도면에서, 동일한 도면 부호는 유사하지만 반드시 동일한 것은 아닌 요소를 가리킨다. 도 1은 본 발명의 실시예에 따른 본문에서 설명되는 다양한 방법이 구현될 수 있는 예시적 시스템의 모식도를 도시한다. 도 2는 본 발명의 실시예에 따른 데이터 생성 방법의 흐름도를 도시한다. 도 3은 본 발명의 실시예에 따른 외부 기억 장치에서 기억을 조회하는 모식도를 도시한다. 도 4는 본 발명의 실시예에 따른 외부 기억 장치에서 기억을 추가 및 삭제하는 모식도를 도시한다. 도 5는 본 발명의 실시예에 따른 딥러닝 모델에 사용되는 초기 입력 결정을 구현할 수 있는 흐름도를 도시한다. 도 6은 본 발명의 실시예에 따른 기억력이 강화된 모식도를 도시한다. 도 7은 본 발명의 실시예에 따른 딥러닝 모델이 초기 입력을 기반으로 회신을 생성하는 모식도를 도시한다. 도 8은 본 발명의 실시예에 따른 지식이 강화된 모식도를 도시한다. 도 9는 본 발명의 실시예에 따른 능력이 확장된 모식도를 도시한다. 도 10은 본 발명의 실시예에 따른 초기 입력에 대한 회신 생성을 구현할 수 있는 흐름도를 도시한다. 도 11은 본 발명의 실시예에 따른 다양한 능력을 강화하는 모식도를 도시한다. 도 12는 본 발명의 실시예에 따른 다양한 능력을 강화하는 모식도를 도시한다. 도 13은 본 발명의 실시예에 따른 딥러닝 모델에 사용되는 초기 입력 결정을 구현할 수 있는 흐름도를 도시한다. 도 14는 본 발명의 실시예에 따른 답안을 집약적으로 보여주는 것을 구현할 수 있는 모식도를 도시한다. 도 15는 본 발명의 실시예에 따른 답안을 구조화하여 보여주는 것을 구현할 수 있는 모식도를 도시한다. 도 16은 본 발명의 실시예에 따른 상호적으로 보여주는 것을 구현할 수 있는 모식도를 도시한다. 도 17은 본 발명의 실시예에 따른 딥러닝 모델의 트레이닝 방법의 흐름도를 도시한다. 도 18은 본 발명의 실시예에 따른 지식 융합 기술의 모식도를 도시한다. 도 19는 본 발명의 실시예에 따른 딥러닝 모델의 트레이닝 방법의 흐름도를 도시한다. 도 20은 본 발명의 실시예에 따른 복수의 샘플 서치 결과에 대하여 배열 작업을 수행하는 흐름도를 도시한다. 도 21은 본 발명의 실시예에 따른 딥러닝 모델의 트레이닝 방법의 흐름도를 도시한다. 도 22는 본 발명의 실시예에 따른 데이터 생성 장치의 구조 블록도를 도시한다. 도 23은 본 발명의 실시예에 따른 딥러닝 모델의 트레이닝 장치의 구조 블록도를 도시한다. 도 24는 본 발명의 실시예를 구현할 수 있는 예시적인 전자 기기의 구조 블록도를 도시한다."}
