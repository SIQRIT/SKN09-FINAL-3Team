{"patent_id": "10-2020-0006220", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0092875", "출원번호": "10-2020-0006220", "발명의 명칭": "로봇과 카메라 간 좌표값 보정 장치 및 보정 방법", "출원인": "한국기술교육대학교 산학협력단", "발명자": "조재수"}}
{"patent_id": "10-2020-0006220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수개의 QR 코드부를 구비하고, 3 차원의 작업 영역에서 움직이며 물건을 그랩하는 로봇;상기 로봇을 촬영하여 복수개의 3차원 위치를 감지하고, 상기 복수개의 QR 코드부를 리딩하여 상기 복수개의 3차원 위치의 변경된 좌표값을 출력하는 카메라; 및상기 변경된 좌표값을 인가받아 동차 변환 행렬을 산출하고, 이를 이용하여 상기 감지된 복수개의 3차원 위치를1차 보정하고, 상기 1차 보정된 복수개의 3차원 위치에서 측정된 최대 오차의 크기에 따라 인공 지능 모델을 이용하여 상기 1차 보정된 복수개의 3차원 위치를 2차 보정하는 제어부;를 포함하는 것을 특징으로 하는,로봇과 카메라 간 좌표값 보정 장치."}
{"patent_id": "10-2020-0006220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "복수개의 QR 코드부를 구비하고, 3 차원의 작업 영역에서 움직이며 물건을 그랩하는 로봇;상기 로봇을 촬영하여 복수개의 3차원 위치를 감지하고, 상기 복수개의 QR 코드부를 리딩하여 상기 복수개의 3차원 위치의 변경된 좌표값을 출력하는 카메라; 및상기 변경된 좌표값을 인가받아 동차 변환 행렬을 산출하고, 이를 이용하여 상기 감지된 복수개의 3차원 위치를1차 보정하고, 상기 1차 보정된 복수개의 3차원 위치에서 측정된 최대 오차의 크기에 따라 인공 지능 모델을 이용하여 상기 1차 보정된 복수개의 3차원 위치를 2차 보정하는 제어부;를 포함하고,상기 로봇은 상기 작업 영역에서 상기 제어부의 명령에 응답하여 6 자유도로 움직이는 로봇 암; 상기 로봇 암의 일측에 장착되어 상기 작업 영역에서 상기 제어부의 명령에 응답하여 물건을 그랩하는 동작을하는 그리퍼; 및 상기 복수개의 QR 코드부를 구비하고, 상기 로봇 암과 상기 그리퍼 사이에 장착되어 상기 그리퍼를 수용하는 그리퍼 어댑터;를 포함하며, 상기 카메라는상기 로봇의 상기 작업 영역에서 상기 카메라 및 상기 로봇의 복수개의 3차원 위치를 감지하여 복수개의 카메라로봇 좌표값 쌍을 출력하는 카메라 센서; 및 상기 로봇에 구비된 상기 복수개의 QR 코드부를 리딩하여, 각 QR 코드부 내 QR 코드를 통해 상기 작업 영역에서상기 로봇 암의 이동 및 상기 그리퍼의 회전으로 변경된 상기 복수개의 3차원 위치의 변경된 좌표값을 감지하는QR 감지기; 를 포함하는 것을 특징으로 하는, 로봇과 카메라 간 좌표값 보정 장치."}
{"patent_id": "10-2020-0006220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "공개특허 10-2021-0092875-3-(a) 카메라 센서가 로봇의 작업 영역에서 카메라 및 로봇의 N개의 3차원 위치를 감지하여 카메라 로봇 좌표값쌍을 출력하는 단계; (b) 제어부가 상기 N개 중에서 T개의 카메라 로봇 좌표값 쌍을 이용하여 동차 변환 행렬을 산출하는 단계; (c) 제어부가 상기 산출된 동차 변환 행렬을 이용하여 상기 감지된 3차원 위치에 대한 카메라 좌표계 값을 로봇좌표계 값으로 변환하여 상기 카메라 로봇 좌표값 쌍을 1차 보정하는 단계; (d) 상기 제어부가 상기 1차 보정된 카메라 로봇 좌표값 쌍에서 측정된 최대 오차가 소정 값보다 큰지 여부를판단하는 단계; 및(e) 상기 최대 오차가 상기 소정 값보다 큰 경우, 상기 제어부가 인공 지능 모델을 이용하여 상기 카메라 로봇좌표값 쌍을 2차 보정하는 단계; 를 포함하고, 상기 (a) 단계는상기 카메라에 내장된 QR 감지기가 상기 로봇에 장착된 그리퍼 어댑터에 부착된 QR 코드부를 리딩하는 단계; 및상기 QR 감지기가 상기 리딩된 QR 코드부 내 QR 코드를 통해 상기 작업 영역에서 상기 로봇의 변경된 3차원 위치를 소정의 오차 범위 내에서 감지하는 단계; 를 포함하는 것을 특징으로 하는,로봇과 카메라 간 좌표값 보정 방법."}
{"patent_id": "10-2020-0006220", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "(a) 카메라 센서가 로봇의 작업 영역에서 카메라 및 로봇의 N개의 3차원 위치를 감지하여 카메라 로봇 좌표값쌍을 출력하는 단계; (b) 제어부가 상기 N개 중에서 T개의 카메라 로봇 좌표값 쌍을 이용하여 동차 변환 행렬을 산출하는 단계; (c) 제어부가 상기 산출된 동차 변환 행렬을 이용하여 상기 감지된 3차원 위치에 대한 카메라 좌표계 값을 로봇좌표계 값으로 변환하여 상기 카메라 로봇 좌표값 쌍을 1차 보정하는 단계; (d) 상기 제어부가 상기 1차 보정된 카메라 로봇 좌표값 쌍에서 측정된 최대 오차가 소정 값보다 큰지 여부를판단하는 단계; 및(e) 상기 최대 오차가 상기 소정 값보다 큰 경우, 상기 제어부가 인공 지능 모델을 이용하여 상기 카메라 로봇좌표값 쌍을 2차 보정하는 단계; 를 포함하고, 상기 (b) 단계는상기 제어부가 상기 T개의 카메라 로봇 좌표값 쌍을 이용하여 상기 산출된 동차 변환 행렬의 추정 오차를 산출하는 단계;상기 제어부가 상기 산출된 추정 오차를 특정값과 비교하여, 상기 특정값 이하일 경우에는 상기 산출된 동차 변환 행렬을 확정하는 단계; 및상기 추정 오차가 상기 특정값 초과일 경우에는, 상기 제어부가 상기 T개의 카메라 로봇 좌표값 쌍 중 오차가큰 좌표값 쌍을 외곽선으로 간주하고, 추가적인 개수의 카메라 로봇 좌표값 쌍을 구하여 상기 산출된 동차 변환행렬을 업데이트하는 단계; 를 포함하는 것을 특징으로 하는,로봇과 카메라 간 좌표값 보정 방법.공개특허 10-2021-0092875-4-청구항 5 (a) 카메라 센서가 로봇의 작업 영역에서 카메라 및 로봇의 N개의 3차원 위치를 감지하여 카메라 로봇 좌표값쌍을 출력하는 단계; (b) 제어부가 상기 N개 중에서 T개의 카메라 로봇 좌표값 쌍을 이용하여 동차 변환 행렬을 산출하는 단계; (c) 제어부가 상기 산출된 동차 변환 행렬을 이용하여 상기 감지된 3차원 위치에 대한 카메라 좌표계 값을 로봇좌표계 값으로 변환하여 상기 카메라 로봇 좌표값 쌍을 1차 보정하는 단계; (d) 상기 제어부가 상기 1차 보정된 카메라 로봇 좌표값 쌍에서 측정된 최대 오차가 소정 값보다 큰지 여부를판단하는 단계; 및(e) 상기 최대 오차가 상기 소정 값보다 큰 경우, 상기 제어부가 인공 지능 모델을 이용하여 상기 카메라 로봇좌표값 쌍을 2차 보정하는 단계; 를 포함하고, 상기 (e) 단계는상기 제어부가 상기 인공 지능 모델의 딥 러닝 기법을 활용해 반복적으로 수행되는 기계 학습을 하는 단계; 및상기 기계 학습을 통해 획득된 카메라 로봇 좌표값 쌍의 정정값을 실측값에 반영하여 상기 1차 보정이 불가능한에러에 대하여 상기 2차 보정을 수행하는 단계; 를 포함하는 것을 특징으로 하는,로봇과 카메라 간 좌표값 보정 방법."}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 로봇과 카메라 간 좌표값 보정 장치 및 보정 방법을 공개한다. 이 장치는 복수개의 QR 코드부를 구비 하고, 3 차원의 작업 영역에서 움직이며 물건을 그랩하는 로봇; 상기 로봇을 촬영하여 복수개의 3차원 위치를 감 지하고, 상기 복수개의 QR 코드부를 리딩하여 상기 복수개의 3차원 위치의 변경된 좌표값을 출력하는 카메라; 및 (뒷면에 계속)"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 좌표값 보정 장치 및 보정 방법에 관한 것으로, 특히 3차원 카메라 좌표를 로봇 좌표로 변환하는 좌 표값을 보정하는 알고리즘에 동차 변환 행렬 및 인공지능의 딥러닝 기법을 이용하여 좌표 변환 중에 발생할 수 있는 다양한 오차를 최소화할 수 있는 로봇과 카메라 간 좌표값 보정 장치 및 보정 방법에 관한 것이다."}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 전기적 또는 자기적인 작용을 이용하여 인간의 동작과 닮은 운동을 행하는 기계장치를 로봇이라고 한다. 초기의 로봇은 생산 현장에서의 작업 자동화 및 무인화 등을 목적으로 한 매니퓰레이터(manipulator)나 반송 로 봇 등의 산업용 로봇으로 인간을 대신하여 위험한 작업이나 단순한 반복 작업, 큰 힘을 필요로 하는 작업을 수 행하였으나, 최근에는 인간과 유사한 관절 체계를 가지고 인간의 작업 및 생활 공간에서 인간과 공존하며 다양 한 서비스를 제공하는 인간형 로봇(humanoid robot)의 연구 개발이 활발하게 진행되고 있다. 이러한 인간형 로봇은 전기적, 기계적 메카니즘에 의해서 팔이나 손의 동작에 가깝게 운동할 수 있도록 만들어 진 매니퓰레이터를 이용하여 작업을 수행한다. 현재 사용되고 있는 대부분의 매니퓰레이터는 여러 개의 링크(link)들이 서로 연결되어 구성된다. 각 링크들의 연결 부위를 관절(joint)이라 하는데 매니퓰레이터는 이러한 링크와 관절들 사이의 기하학적인 관 계에 따라 운동 특성이 결정된다. 이 기하학적인 관계를 수학적으로 표현한 것이 기구학(Kinematics)이며, 대부분의 매니퓰레이터는 이러한 기구 학적 특성(kinematics characteristic)을 가지고 작업을 수행하기 위한 방향(목표 위치)으로 그리퍼(예컨대, 엔 드 이펙터)를 이동시킨다. 또한, 카메라를 부착한 로봇 시스템의 보정은 크게 로봇 베이스와 그리퍼의 보정, 카메라의 보정, 로봇 베이스 또는 그리퍼와 카메라의 보정(hand/eye calibration)으로 분류된다. 이 중에서 그리퍼와 카메라 간의 보정은 로봇으로 물건을 그랩(grap) 등의 동작을 수행하기 위해 물건이 놓여진 3차원 위치를 카메라로 촬영하고, 카메라 좌표계 값을 로봇 좌표계 값으로 변환하는 과정이 필수적이다. 그런데, 종래에 산업 현장에서 사용 중인 로봇과 카메라의 보정 방법은 일반적으로 티치 팬던트(teach pendan t)라고 불리는 별도의 조작기를 이용하였다. 티치 팬던트라고 불리는 별도의 조작기를 이용하여 알고 있는 대상의 위치에 로봇의 핸드를 교시하여 여러 번의 반복 과정을 통해서 카메라와 로봇의 핸드 사이에 변환 관계를 추정할 수 있다. 티치 팬던트를 이용하는 경우에는 작업자에게 교시 메뉴 및 프로그래밍 언어에 대한 이해와 공간적인 감각, 로 봇 시스템 및 기구학적 해석 능력 등이 요구되어 작업자가 운용하기 위해서는 많은 시간이 소요되고 조작이 번 거로운 문제가 발생한다. 또한, 로봇의 핸드를 직접 교시하는 경우, 작업자는 로봇의 바로 옆이나 로봇의 인근에서 로봇의 핸드를 직접 교시하여야 하므로 로봇의 오작동에 따라 작업자의 안정상 문제가 발생할 수 있으며, 인간의 판단을 통한 교시 방법이므로 정밀도가 떨어질 수 있다. 그 외에도 카메라 자체의 좌표값 보정도 별도로 수행되어야 하는 과정이 존재하므로, 작업자가 카메라에 관한 사전 지식 없이 카메라 내/외부 파라미터를 구하기에 어려움을 가지고 있어 상당한 불편함과 시간 소요가 있었 다. 한편, 현재 산업 현장에서 작업 환경 개선 및 생산성 향상을 목적으로 로봇의 사용이 증가하는 추세이고, 특히 단순 반복 작업이나 인간이 직접 수행하기 힘들고 위험한 작업에 로봇의 사용이 급증하고 있다. 이와 같은 로봇은 용접이나 조립 등의 할당된 작업을 수행하기 위해서 툴 끝단(Tool Center Point: TCP)이 작업 대상물의 위치로 이동되어야 한다. 하지만, 로봇은 정형화된 환경에서 반복 작업을 수행하기 때문에 작업 대 상물의 위치를 알 수가 없으며, 이러한 이유로 작업 대상물을 고정된 위치로 이동시킨 후에 로봇이 작업 위치로 이동하여 할당된 작업을 수행해야 한다. 그러나, 이러한 경우 로봇과 작업 대상물과의 위치 관계가 고정적이기 때문에 작업물의 위치가 고정적으로 설정 되지 않는 환경에서는 로봇의 사용과 성능이 제한되는 문제점이 있다. 이러한 문제점을 해결하기 위한 방법으로, 종래에는 도 1에 도시된 바와 같이 3차원 위치를 정확히 알고 있는 기준점으로 사용자가 수동 조작하여 로봇을 이동시킨 후 거리 감지 센서(LVS, LRF, Lidar, Stereo 카메라, RGB- D 카메라 등)가 지정된 자세로 그 기준점을 센싱하게 했다. 또는, 거리감지 센서를 이용하여 로봇 주위에 배치된 측정 지그 상의 다수 기준점(point)의 위치를 측정하고 측 정된 각 점의 위치 정보를 이용하여 로봇 기준 좌표계와 거리 감지 센서 기준 좌표계 간의 위치 관계를 조정하 였는데, 이러한 조정 작업을 좌표값 보정(Calibration)이라 한다. 그러나, 작업 중 로봇의 충돌 또는 진동, 사용자의 조정 등에 의해 로봇 기준 좌표계와 거리 감지 센서 기준 좌 표계 간의 위치 관계가 달라지는 경우가 빈번하게 발생하며, 이를 보정하기 위해서는 빈번하게 좌표값 보정을 수행해야만 하는 한계가 있었다. 하지만, 종래의 좌표값 보정 방법은 3차원 위치를 정확히 알고 있는 기준점으로 사용자가 로봇을 이동시키거나, 여러 자세에서 거리 감지 센서로 기준점의 위치를 반복 측정하여야 하므로 로봇의 정밀한 조작이 요구되며, 이 로 인해 좌표값 보정에 소요되는 시간이 증가되어 비효율적이라는 문제점이 있다. 또한, 3차원 위치를 정확히 알고 있는 기준점을 지정된 자세로 센싱하여 좌표값을 보정하는 종래의 방법은 다양 한 자세로 좌표값 보정을 할 수 없으므로 측정 시 로봇이 취할 수 있는 자세가 매우 제한되며, 경우에 따라서는 측정이 불가능한 문제점이 있다. 한편, 인공 지능(Artificial Intelligence, AI)은 인간의 뇌와 뉴런 신경망을 모방해 언젠가는 컴퓨터나 로봇들 이 인간처럼 사고하고 행동하게 하는 것이다. 예를 들어, 우리는 사진만으로 개와 고양이를 아주 쉽게 구분할 수 있지만 컴퓨터는 구분하지 못한다. 이를 위해 “머신 러닝(Machine Learning, ML)” 기법이 고안되었는데, 이 기법은 많은 데이터를 컴퓨터에 입력 하고 비슷한 것끼리 분류하도록 하는 기술로서, 저장된 개 사진과 비슷한 사진이 입력되면, 이를 개 사진이라고 컴퓨터가 분류하도록 하는 것이다. 데이터를 어떻게 분류할 것인가에 따라, 의사결정 나무(Decision Tree)나 베이지안 망(Bayesian network), 서포 트 벡터 머신(support vector machine, SVM), 그리고 인공 신경망(Artificial neural network) 등 많은 머신 러닝 알고리즘이 등장했다. 그 중에 인공 신경망 알고리즘에서 파생된 딥 러닝(Deep Learning, DL)은 인공 신경망을 이용하여 데이터를 군 집화하거나 분류하는데 사용하는 기술이다. 머신 러닝과 인지 과학에서의 인공 신경망은 생물학의 신경망(동물의 중추 신경계)에서 영감을 얻은 통계학적 학습 알고리즘이다. 인공 신경망은 시냅스(synapse)의 결합으로 네트워크를 형성한 인공 뉴런(node)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 가리킨다. 인공 신경망을 이용하는 딥 러닝의 핵심은 분류를 통한 예측이다. 수많은 데이터 속에서 패턴을 발견해 인간이 사물을 구분하듯 컴퓨터가 데이터를 나눈다. 이 같은 분별 방식은 지도자(감독자/교사)의 신호(정답) 입력에 의해서 문제에 최적화되어 가는 지도(감독/교사) 학습과 지도자의 교사 신호를 필요로 하지 않는 비지도(감독/교사) 학습이 있다. 일반적으로 입력으로부터 값을 계산하는 뉴런 시스템의 상호 연결로 표현되고 적응성이 있어 패턴 인식과 같은 기계 학습을 수행할 수 있다. 데이터로부터 학습하는 다른 기계 학습과 같이, 신경망은 일반적으로 규칙 기반 프로그래밍으로 풀기 어려운 컴 퓨터 비전(vision) 또는 음성 인식과 같은 다양한 범위의 문제를 푸는 데 이용된다. 즉, 어떠한 데이터가 있을 때 이를 컴퓨터가 인지할 수 있는 형태(예를 들어 이미지의 경우 픽셀정보를 열 벡터 로 표현하는 툴)로 표현하고 이를 학습에 적용하기 위해 많은 연구가 진행되고 있으며, 이러한 노력의 결과로 심층 신경망(deep neural networks), 합성 곱 신경망(convolutional neural network), 순환 신경망(Recurrent neural network)와 같은 다양한 딥 러닝 기법들이 컴퓨터 비젼, 음성 인식, 자연어 처리, 음성/신호 처리 등의 분야에 적용되어 우수한 성능의 응용 프로그램들이 개발되고 있다. 그런데, 종래에 카메라로 측정된 카메라 좌표를 로봇 좌표로 변환하는 방법들은 저가의 3차원 카메라로 측정됨 에 따라 카메라 렌즈의 왜곡 현상 또는 영상 측정 중에 발생하는 오류로 인하여 카메라 로봇 좌표계 변환시 실 측값 데이터와 추정값 간에 상당히 큰 오차가 발생하는 문제점이 있었다. 이에 본 발명자는 카메라로 측정된 카메라 좌표를 로봇 좌표로 변환하는 과정에서 카메라 렌즈의 왜곡 현상 또 는 영상 측정 중에 발생하는 오류로 인한 실측값 데이터와 추정값 간의 큰 오차를, 동차 변환 행렬 및 인공지능 의 딥러닝 기법을 이용하여 최소화할 수 있는 소프트웨어 고장 시간 예측 방법을 발명하기에 이르렀다. 선행기술문헌 특허문헌 (특허문헌 0001) US 9014853 B2"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 저가의 3차원 카메라로 측정된 3차원 카메라 좌표를 로봇 좌표로 변환하는 좌표값을 보정하는 알고리즘에, 동차 변환 행렬 및 인공지능의 딥러닝 기법을 이용하여 좌표 변환 중에 발생할 수 있는 다양한 오 차를 최소화할 수 있는 로봇과 카메라 간 좌표값 보정 장치를 제공하는 것이다. 본 발명의 다른 목적은 상기 목적을 달성하기 위한 좌표값 보정 장치의 로봇과 카메라 간 좌표값 보정 방법을 제공하는데 있다."}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 로봇과 카메라 간 좌표값 보정 장치는 복수개의 QR 코드부를 구비하고, 3 차원의 작업 영역에서 움직이며 물건을 그랩하는 로봇; 상기 로봇을 촬영하여 복수개의 3차원 위치를 감지하고, 상기 복수개의 QR 코드부를 리딩하여 상기 복수개의 3차원 위치의 변경된 좌표값을 출력하는 카메라; 및 상기 변경된 좌표값을 인가받아 동차 변환 행렬을 산출하고, 이를 이용하여 상기 감지된 복수개의 3차원 위치를 1차 보정하고, 상기 1차 보정된 복수개의 3차원 위치에서 측정된 최대 오차의 크기에 따라 인공 지능 모델을 이용하 여 상기 1차 보정된 복수개의 3차원 위치를 2차 보정하는 제어부; 를 포함하는 것을 특징으로 한다. 상기 목적을 달성하기 위한 본 발명의 로봇과 카메라 간 좌표값 보정 장치는 복수개의 QR 코드부를 구비하고, 3 차원의 작업 영역에서 움직이며 물건을 그랩하는 로봇; 상기 로봇을 촬영하여 복수개의 3차원 위치를 감지하고, 상기 복수개의 QR 코드부를 리딩하여 상기 복수개의 3차원 위치의 변경된 좌표값을 출력하는 카메라; 및 상기 변경된 좌표값을 인가받아 동차 변환 행렬을 산출하고, 이를 이용하여 상기 감지된 복수개의 3차원 위치를 1차 보정하고, 상기 1차 보정된 복수개의 3차원 위치에서 측정된 최대 오차의 크기에 따라 인공 지능 모델을 이용하 여 상기 1차 보정된 복수개의 3차원 위치를 2차 보정하는 제어부; 를 포함하고, 상기 로봇은 상기 작업 영역에 서 상기 제어부의 명령에 응답하여 6 자유도로 움직이는 로봇 암; 상기 로봇 암의 일측에 장착되어 상기 작업 영역에서 상기 제어부의 명령에 응답하여 물건을 그랩하는 동작을 하는 그리퍼; 및 상기 복수개의 QR 코드부를 구비하고, 상기 로봇 암과 상기 그리퍼 사이에 장착되어 상기 그리퍼를 수용하는 그리퍼 어댑터; 를 포함하며, 상기 카메라는 상기 로봇의 상기 작업 영역에서 상기 카메라 및 상기 로봇의 복수개의 3차원 위치를 감지하여 복수개의 카메라 로봇 좌표값 쌍을 출력하는 카메라 센서; 및 상기 로봇에 구비된 상기 복수개의 QR 코드부를 리딩하여, 각 QR 코드부 내 QR 코드를 통해 상기 작업 영역에서 상기 로봇 암의 이동 및 상기 그리퍼의 회전으 로 변경된 상기 복수개의 3차원 위치의 변경된 좌표값을 감지하는 QR 감지기; 를 포함하는 것을 특징으로 한다. 상기 다른 목적을 달성하기 위한 본 발명의 로봇과 카메라 간 좌표값 보정 방법은 (a) 카메라 센서가 로봇의 작 업 영역에서 카메라 및 로봇의 N개의 3차원 위치를 감지하여 카메라 로봇 좌표값 쌍을 출력하는 단계; (b) 제어 부가 상기 N개 중에서 T개의 카메라 로봇 좌표값 쌍을 이용하여 동차 변환 행렬을 산출하는 단계; (c) 제어부가 상기 산출된 동차 변환 행렬을 이용하여 상기 감지된 3차원 위치에 대한 카메라 좌표계 값을 로봇 좌표계 값으 로 변환하여 상기 카메라 로봇 좌표값 쌍을 1차 보정하는 단계; (d) 상기 제어부가 상기 1차 보정된 카메라 로 봇 좌표값 쌍에서 측정된 최대 오차가 소정 값보다 큰지 여부를 판단하는 단계; 및 (e) 상기 최대 오차가 상기 소정 값보다 큰 경우, 상기 제어부가 인공 지능 모델을 이용하여 상기 카메라 로봇 좌표값 쌍을 2차 보정하는 단계; 를 포함하는 것을 특징으로 한다. 상기 다른 목적을 달성하기 위한 본 발명의 로봇과 카메라 간 좌표값 보정 방법은 (a) 카메라 센서가 로봇의 작 업 영역에서 카메라 및 로봇의 N개의 3차원 위치를 감지하여 카메라 로봇 좌표값 쌍을 출력하는 단계; (b) 제어 부가 상기 N개 중에서 T개의 카메라 로봇 좌표값 쌍을 이용하여 동차 변환 행렬을 산출하는 단계; (c) 제어부가 상기 산출된 동차 변환 행렬을 이용하여 상기 감지된 3차원 위치에 대한 카메라 좌표계 값을 로봇 좌표계 값으 로 변환하여 상기 카메라 로봇 좌표값 쌍을 1차 보정하는 단계; (d) 상기 제어부가 상기 1차 보정된 카메라 로 봇 좌표값 쌍에서 측정된 최대 오차가 소정 값보다 큰지 여부를 판단하는 단계; 및 (e) 상기 최대 오차가 상기 소정 값보다 큰 경우, 상기 제어부가 인공 지능 모델을 이용하여 상기 카메라 로봇 좌표값 쌍을 2차 보정하는 단계; 를 포함하고, 상기 (b) 단계는 상기 제어부가 상기 T개의 카메라 로봇 좌표값 쌍을 이용하여 상기 산출된 동차 변환 행렬의 추정 오차를 산출하는 단계; 상기 제어부가 상기 산출된 추정 오차를 특정값과 비교하여, 상 기 특정값 이하일 경우에는 상기 산출된 동차 변환 행렬을 확정하는 단계; 및 상기 추정 오차가 상기 특정값 초 과일 경우에는, 상기 제어부가 상기 T개의 카메라 로봇 좌표값 쌍 중 오차가 큰 좌표값 쌍을 외곽선으로 간주하 고, 추가적인 개수의 카메라 로봇 좌표값 쌍을 구하여 상기 산출된 동차 변환 행렬을 업데이트하는 단계; 를 포 함하는 것을 특징으로 한다. 상기 다른 목적을 달성하기 위한 본 발명의 로봇과 카메라 간 좌표값 보정 방법은 (a) 카메라 센서가 로봇의 작 업 영역에서 카메라 및 로봇의 N개의 3차원 위치를 감지하여 카메라 로봇 좌표값 쌍을 출력하는 단계; (b) 제어 부가 상기 N개 중에서 T개의 카메라 로봇 좌표값 쌍을 이용하여 동차 변환 행렬을 산출하는 단계; (c) 제어부가 상기 산출된 동차 변환 행렬을 이용하여 상기 감지된 3차원 위치에 대한 카메라 좌표계 값을 로봇 좌표계 값으 로 변환하여 상기 카메라 로봇 좌표값 쌍을 1차 보정하는 단계; (d) 상기 제어부가 상기 1차 보정된 카메라 로봇 좌표값 쌍에서 측정된 최대 오차가 소정 값보다 큰지 여부를 판단하는 단계; 및 (e) 상기 최대 오차가 상기 소정 값보다 큰 경우, 상기 제어부가 인공 지능 모델을 이용하여 상기 카메라 로봇 좌표값 쌍을 2차 보정하는 단계; 를 포함하고, 상기 (e) 단계는 상기 제어부가 상기 인공 지능 모델의 딥 러닝 기법을 활용해 반복적으로 수행되는 기계 학습을 하는 단계; 및 상기 기계 학습을 통해 획득된 카메라 로봇 좌표값 쌍의 정정값을 실측값 에 반영하여 상기 1차 보정이 불가능한 에러에 대하여 상기 2차 보정을 수행하는 단계; 를 포함하는 것을 특징 으로 한다. 기타 실시예의 구체적인 사항은 \""}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의할 경우, 종래에 카메라로 측정된 카메라 좌표를 로봇 좌표로 변환하는 과정에서 저가의 3차원 카 메라로 측정됨에 따라 발생하는 카메라 렌즈의 왜곡 현상 또는 영상 측정 중에 발생하는 오류로 인한 실측값 데 이터와 추정값 간의 큰 오차가 현저하게 감소된다."}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "\" 및 첨부 \"도면\"에 포함되어 있다. 본 발명의 이점 및/또는 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 각종 실시예를 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 각 실시예의 구성만으로 한정되는 것이 아니라 서로 다른 다양한 형태로 도 구현될 수도 있으며, 단지 본 명세서에서 개시한 각각의 실시예는 본 발명의 게시가 완전하도록 하며, 본 발 명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것 이며, 본 발명은 청구범위의 각 청구항의 범주에 의해 정의될 뿐임을 알아야 한다."}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "발명의 효과 본 발명에 의할 경우, 종래에 카메라로 측정된 카메라 좌표를 로봇 좌표로 변환하는 과정에서 저가의 3차원 카 메라로 측정됨에 따라 발생하는 카메라 렌즈의 왜곡 현상 또는 영상 측정 중에 발생하는 오류로 인한 실측값 데 이터와 추정값 간의 큰 오차가 현저하게 감소된다."}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "도면의 간단한 설명 도 1은 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 장치의 사시도이다. 도 2는 도 1에 도시된 본 발명의 보정 장치 내 그리퍼 어댑터의 평면도 및 QR 코드부의 확대도이다. 도 3은 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법에서 보정 수단을 설명하기 위한 구성도 이다. 도 4는 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법의 동작을 설명하기 위한 순서도이다. 도 5는 본 도 4에 도시된 보정 방법 중 단계(S300)의 세부 동작을 설명하기 위한 순서도이다. 도 6은 도 4에 도시된 보정 방법 중 단계(S600)에서 오차를 측정하는 실험 장치에 대한 사진이다. 도 7은 도 4에 도시된 보정 방법 중 단계(S500)에서 동차 변환 행렬만을 이용하여 1차 보정한 후 실측값 데이터 와 추정값 간 최대 오차를 관측한 결과 영상이다. 도 8은 도 4에 도시된 보정 방법 중 단계(S500)에서 실측값 데이터와 추정값 간 최대 오차를 동차 변환 행렬만 을 이용한 경우(a)와 단계(S750)에서 동차 변환 행렬 및 인공 지능 모델을 이용한 경우(b)를 비교한 결과 영상 이다."}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "발명을 실시하기 위한 구체적인 내용 이하, 첨부한 도면을 참고로 하여 본 발명의 바람직한 실시예에 대하여 상세히 설명하면 다음과 같다. 본 발명을 상세하게 설명하기 전에, 본 명세서에서 사용된 용어나 단어는 통상적이거나 사전적인 의미로 무조건 한정하여 해석되어서는 아니되며, 본 발명의 발명자가 자신의 발명을 가장 최선의 방법으로 설명하기 위해서 각 종 용어의 개념을 적절하게 정의하여 사용할 수 있다. 더 나아가 이들 용어나 단어는 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야 함을 알아야 한 다. 즉, 본 명세서에서 사용된 용어는 본 발명의 바람직한 실시예를 설명하기 위해서 사용되는 것일 뿐이고, 본 발 명의 내용을 구체적으로 한정하려는 의도로 사용된 것이 아니다. 이들 용어는 본 발명의 여러 가지 가능성을 고려하여 정의된 용어임을 알아야 한다. 또한, 본 명세서에 있어서, 단수의 표현은 문맥상 명확하게 다른 의미로 지시하지 않는 이상, 복수의 표현을 포 함할 수 있다. 또한, 유사하게 복수로 표현되어 있다고 하더라도 단수의 의미를 포함할 수 있음을 알아야 한다. 본 명세서의 전체에 걸쳐서 어떤 구성 요소가 다른 구성 요소를 \"포함\"한다고 기재하는 경우에는, 특별히 반대 되는 의미의 기재가 없는 한 임의의 다른 구성 요소를 제외하는 것이 아니라 임의의 다른 구성 요소를 더 포함 할 수도 있다는 것을 의미할 수 있다. 더 나아가서, 어떤 구성 요소가 다른 구성 요소의 \"내부에 존재하거나, 연결되어 설치된다\"고 기재한 경우에는, 이 구성 요소가 다른 구성 요소와 직접적으로 연결되어 있거나 접촉하여 설치되어 있을 수 있다. 또한, 일정한 거리를 두고 이격되어 설치되어 있을 수도 있으며, 일정한 거리를 두고 이격되어 설치되어 있는 경우에 대해서는 해당 구성 요소를 다른 구성 요소에 고정 내지 연결시키기 위한 제 3의 구성 요소 또는 수단이 존재할 수 있다. 한편, 상기 제 3의 구성 요소 또는 수단에 대한 설명은 생략될 수도 있음을 알아야 한다. 반면에, 어떤 구성 요소가 다른 구성 요소에 \"직접 연결\"되어 있다거나, 또는 \"직접 접속\"되어 있다고 기재되는 경우에는, 제 3의 구성 요소 또는 수단이 존재하지 않는 것으로 이해하여야 한다. 마찬가지로, 각 구성 요소 간의 관계를 설명하는 다른 표현들, 즉 \" ~ 사이에\"와 \"바로 ~ 사이에\", 또는 \" ~ 에 이웃하는\"과 \" ~ 에 직접 이웃하는\" 등도 마찬가지의 취지를 가지고 있는 것으로 해석되어야 한다. 또한, 본 명세서에 있어서 \"일면\", \"타면\", \"일측\", \"타측\", \"제 1\", \"제 2\" 등의 용어는, 하나의 구성 요소에 대해서 이 하나의 구성 요소가 다른 구성 요소로부터 명확하게 구별될 수 있도록 하기 위해서 사용된다. 하지만, 이와 같은 용어에 의해서 해당 구성 요소의 의미가 제한적으로 사용되는 것은 아님을 알아야 한다. 또한, 본 명세서에서 \"상\", \"하\", \"좌\", \"우\" 등의 위치와 관련된 용어는, 사용된다면, 해당 구성 요소에 대해 서 해당 도면에서의 상대적인 위치를 나타내고 있는 것으로 이해하여야 한다. 또한, 이들의 위치에 대해서 절대적인 위치를 특정하지 않는 이상은, 이들 위치 관련 용어가 절대적인 위치를 언급하고 있는 것으로 이해하여서는 아니된다. 더욱이, 본 발명의 명세서에서는, \"…부\", \"…기\", \"모듈\", \"장치\" 등의 용어는, 사용된다면, 하나 이상의 기능 이나 동작을 처리할 수 있는 단위를 의미한다. 이는 하드웨어 또는 소프트웨어, 또는 하드웨어와 소프트웨어의 결합으로 구현될 수 있음을 알아야 한다. 본 명세서에 첨부된 도면에서 본 발명을 구성하는 각 구성 요소의 크기, 위치, 결합 관계 등은 본 발명의 사상 을 충분히 명확하게 전달할 수 있도록 하기 위해서 또는 설명의 편의를 위해서 일부 과장 또는 축소되거나 생략 되어 기술되어 있을 수 있고, 따라서 그 비례나 축척은 엄밀하지 않을 수 있다. 또한, 이하에서, 본 발명을 설명함에 있어서, 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 구성, 예 를 들어, 종래 기술을 포함하는 공지 기술에 대한 상세한 설명은 생략될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 장치의 사시도로서, 로봇, 카메라 및 제어부를 구비한다. 로봇은 로봇 암, 그리퍼 및 그리퍼 어댑터를 구비하고, 그리퍼 어댑터는 4개의 QR 코 드부(131 내지 134)를 구비한다. 또한, 카메라는 카메라 센서 및 QR 감지기(미도시)를 구비한다. 도 2는 도 1에 도시된 본 발명의 보정 장치 내 그리퍼 어댑터의 평면도 및 QR 코드부의 확대도이다. 도 1 및 도 2를 참조하여 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 장치의 각 구성요소들의 구조 및 기능을 개략적으로 설명하면 다음과 같다. 로봇은 3 차원의 작업 영역에서 제어부의 명령에 응답하여 6 자유도로 움직이는 로봇 암과, 로 봇 암의 일측에 장착되어 작업 영역에서 제어부의 명령에 응답하여 소정의 물건을 그랩(grap)하는 등 의 동작을 하는 그리퍼를 구비한다. 그리퍼는 작업 영역에서 소정의 물건을 그랩하기 위해 손가락 부분이 2 개 이상으로 구성되고, 손가락 부 분은 유압에 의해 열리고 닫힌다. 또한, 원반 형상의 그리퍼 어댑터(Gripper adapter, 130)가 외주면 중 동서남북 방향에 4 개의 QR 코드부(131 내지 134)를 구비하면서, 로봇 암과 그리퍼 사이에 장착되어 그리퍼를 용이하게 수용한다. 카메라에 내장된 카메라 센서는 로봇의 작업 영역에서 카메라 및 로봇의 복수개의 3 차원 위치를 감지하여 복수개의 카메라 로봇 좌표값 쌍을 출력한다. 또한, QR 감지기가 카메라 내부에 장착되어, 로봇에 장착된 그리퍼 어댑터에 부착된 4개의 QR 코드부(131 내지 134)를 리딩함으로써, QR 코드부 내 QR 코드를 통해 작업 영역에서 로봇 암의 이동 및 그리퍼의 회전으로 변경된 로봇의 3차원 위치를 감지한다. 제어부는 변경된 복수개의 카메라 로봇 좌표값 쌍을 통해 산출된 동차 변환 행렬을 이용하여 감지된 복수 개의 카메라 로봇 좌표값 쌍을 1차 보정하고, 1차 보정된 카메라 로봇 좌표값 쌍에서 측정된 최대 오차의 크기 에 따라 인공 지능 모델을 이용하여 1차 보정된 카메라 로봇 좌표값 쌍을 2차 보정한다. 도 3은 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법에서 보정 수단을 설명하기 위한 구성도 이다. 도 4는 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법의 동작을 설명하기 위한 순서도이다. 도 1 내지 도 4를 참조하여 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법의 동작을 개략적으 로 설명하면 다음과 같다. 먼저, 카메라 센서가 로봇의 작업 영역에서 카메라 및 로봇의 N개의 3차원 위치를 감지하 여(S100) 카메라 로봇 좌표값 쌍을 출력한다(S200). 제어부가 상기 N개 중에서 T개의 카메라 로봇 좌표값 쌍을 이용하여 동차 변환 행렬을 산출한다(S300). 제어부가 상기 산출된 동차 변환 행렬을 이용하여 상기 감지된 3차원 위치에 대한 카메라 좌표계 값을 로 봇 좌표계 값으로 변환하여(S400) 상기 카메라 로봇 좌표값 쌍을 1차 보정한다(S500). 제어부가 상기 1차 보정된 카메라 로봇 좌표값 쌍으로부터 최대 오차를 측정하고(S600), 측정된 최대 오차 가 소정 값보다 큰지 여부를 판단한다(S700). 최대 오차가 상기 소정 값보다 큰 경우, 상기 제어부가 인공 지능 모델을 이용하여 상기 카메라 로봇 좌표 값 쌍을 2차 보정한다(S750). 도 5는 본 도 4에 도시된 보정 방법 중 단계(S300)의 세부 동작을 설명하기 위한 순서도이다. 도 6은 도 4에 도시된 보정 방법 중 단계(S600)에서 오차를 측정하는 실험 장치에 대한 사진으로서, 측정된 실 측값(a)과 카메라 좌표의 영상(b)을 포함한다. 도 7은 도 4에 도시된 보정 방법 중 단계(S500)에서 동차 변환 행렬만을 이용하여 1차 보정한 후 실측값 데이터 와 추정값 간 최대 오차를 관측한 결과 영상이다. 도 8은 도 4에 도시된 보정 방법 중 단계(S500)에서 실측값 데이터와 추정값 간 최대 오차를 동차 변환 행렬만 을 이용한 경우(a)와 단계(S750)에서 동차 변환 행렬 및 인공 지능 모델을 이용한 경우(b)를 비교한 결과 영상 이다. 도 1 내지 도 8을 참조하여 본 발명의 일 실시예에 따른 비선형 회귀 모형 기반 소프트웨어 고장 시간의 보정 장치의 유기적인 동작을 상세하게 설명하면 다음과 같다. 카메라 센서는 3차원 센서로서, 로봇으로 하여금 물건을 그랩(grap) 등의 동작을 수행하게 하기 위해 물건이 놓여진 작업 영역의 3차원 위치를 카메라로 촬영하여 감지한다. 제어부는 3차원 카메라 센서에서 감지된 3차원 위치에 대해 아래의 수학식 1과 같은 동차 변환 행렬 (Homogeneous Transform Matrix) 'H'를 이용하여 카메라 좌표계 값을 로봇 좌표계 값으로 변환한다.[수학식 1]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기에서, '동차 변환 행렬'이란 기준 좌표계에 대한 대상체의 위치 및 자세를 동시에 나타내는 변환을 위한 연 산자로서, 두 좌표계 사이의 관계를 의미한다. 두 좌표계 중에서 (Xr, Yr, Zr)는 로봇 좌표값이고, (Xc, Yc, Zc)는 카메라(영상) 좌표값이다. 예를 들어, 작업 영역상에서 총 12개의 위치에 대한 로봇 좌표점과 카메라 좌표점 쌍을 획득한다고 가정한다. 즉, 동차 변환 행렬 H에서 3 X 4 행렬의 벡터값은 미지수 a1 ~ a12 이 되고, 4 행의 벡터값은 [0 0 0 1] 이 되어, 아래의 수학식 2와 같이 표현될 수 있다. [수학식 2]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기에서, 벡터 Xr, Yr, Zr은 로봇의 좌표값이고, 벡터 Xc, Yc, Zc는 카메라 좌표값을 나타낸다. 수학식 2에서 우항의 벡터곱을 풀어 쓰면 아래의 수학식 3과 같이 표현된다. [수학식 3] = ------------------------ ① = ------------------------ ② = -------------------------③ 만일, 총 12개의 위치에 대한 로봇 좌표점과 카메라 좌표점 쌍 중 4개의 위치에 대한 좌표점 쌍의 정확한 실측 값을 알고 있다면, 로봇 좌표점과 카메라 좌표점 간의 상관 관계는 아래의 수학식 4와 같이 표현될 수 있다. [수학식 4]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 2에서 동차 변환 행렬 H의 미지의 벡터값(a1 ~ a12) 중 미지의 벡터값(a1 ~ a4)를 먼저 구하기 위하여 수 학식 3의 ① 식에 수학식 4를 대입하면, 아래의 수학식 5와 같이 표현될 수 있다. [수학식 5] ="}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "="}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "="}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "="}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "상기 수학식 5를 벡터의 곱 형태로 정리하면, 아래의 수학식 6과 같이 표현될 수 있다. [수학식 6]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "상기 수학식 6에서 좌항의 벡터를 B 행렬, 좌항의 벡터의 곱을 (A a) 행렬로 정의하여 간소화하면, 아래의 수학 식 7과 같이 표현될 수 있다. [수학식 7]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "상기 수학식 7의 좌항 및 우항에 벡터 A의 전치 행렬(AT)을 곱하면, 아래의 수학식 8과 같이 표현될 수 있다. 이때, 전치 행렬(Transpose Matrix)이란 행렬을 구성하고 있는 벡터의 행과 열을 뒤바꾼 행렬을 의미한다 [수학식 8]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "상기 수학식 8의 좌항 및 우항에 벡터 (AT A)의 역 행렬인 (AT A)-1을 곱하면, 아래의 수학식 9와 같이 표현되어, 최종적으로 a 행렬이 산출된다. 이때, 역 행렬(Inverse Matrix)이란 소정의 행렬에 곱한 결과가 항등행렬이 나오는 행렬을 의미한다 [수학식 9]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "즉, 수학식 6에서 우항의 a 행렬을 구성하는 미지의 벡터값(a1 ~ a4)을 구할 수 있게 된다. 마찬가지로, 동일한 방법으로 수학식 3의 ②식에 수학식 4를 대입하여 상기 계산 과정을 반복하면, 수학식 2에 서 동차 변환 행렬 H의 미지의 벡터값(a5 ~ a8)을 구할 수 있다. 또한, 동일한 방법으로 수학식 3의 ③식에 수학식 4를 대입하여 상기 계산 과정을 반복하면, 수학식 2에서 동차 변환 행렬 H의 미지의 벡터값(a9 ~ a12)을 구할 수 있다. 이와 같이, 로봇의 작업 영역 상에서 총 12개의 로봇 좌표점과 카메라 좌표점 쌍 중 4개의 좌표점 쌍을 먼 저 산출한 후에, 동일한 방식으로 나머지 8개의 좌표점 쌍을 산출하게 된다.따라서, 동차 변환 행렬 H는 일반적으로 위치 및 자세 정보를 동시에 포함하고 있으며, 연산의 편의상 아래의 수학식 10과 같이 결과적으로 4개의 부행렬로 구성된 44 행렬로 산출된다. [수학식 10]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "여기에서, 벡터 Ry(β)는 좌표 변환에서 y축을 기준으로 β 각도만큼 회전하는 회전 변환 행렬로서, 아래의 수학 식 11과 같이 표현될 수 있다. [수학식 11]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "또한, 벡터 Rz(γ)는 좌표 변환에서 z축을 기준으로 γ 각도만큼 회전하는 회전 변환 행렬로서, 아래의 수학식 12와 같이 표현될 수 있다. [수학식 12]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "또한, 벡터 t는 두 좌표계의 원점간의 이동벡터로 두 좌표계의 원점 사이의 오프셋 행렬로서, 아래의 수학식 12 와 같이 표현될 수 있다. [수학식 12]"}
{"patent_id": "10-2020-0006220", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 19, "content": "도 4 및 도 5에 도시된 본 발명의 로봇과 카메라 간 좌표값 보정 방법을 이용하여 동차 변환 행렬을 산출하는 세부적인 과정은 다음과 같다. 카메라 센서는 작업 영역상의 N개(예를 들어, 12개)의 카메라 및 로봇의 위치에 대한 카메라 로봇 좌표값 쌍을 획득한다. 제어부는 카메라 센서가 획득한 N개의 위치에 대한 카메라 로봇 좌표값 쌍 중에서 먼저 T개(예를 들 어, 4개)의 좌표쌍을 인가받아 이에 대한 동차 변환 행렬의 추정 오차를 산출한다(S310). 제어부는 산출된 추정 오차를 특정값과 비교하여(S320), 특정값 이하일 경우에는 수학식 10과 같이 산출 된 동차 변환 행렬을 확정한다(S340). 반면, 추정 오차가 특정값 초과일 경우에는(S330), 제어부가 T개의 카메라 로봇 좌표값 쌍 중 오차가 큰 좌표값 쌍을 외곽선(outlier)으로 간주하고(S331), 추가적인 (N-T)개(예를 들어, 8개)의 카메라 로봇 좌표값 쌍 을 구하여(S332) 산출된 동차 변환 행렬을 업데이트한다(S333). 이때, 상기 알고리즘은 자동 QR 코드 인식 프로그램으로 오차가 특정 범위 이내(예를 들어, 1 pixel)로 구현되 어야 한다. 즉, 카메라에 내장된 QR 감지기가 로봇 암과 그리퍼 사이에 장착된 원반 형상의 그리퍼 어댑터 의 외주면 중 동서남북 방향에 부착된 4 개의 QR 코드부(131 내지 134)를 리딩한다. QR 감지기는 로봇 암의 이동 및 그리퍼의 회전으로 변경된 그리퍼의 3차원 위치를 자동 QR 코 드 인식 프로그램을 이용하여 특정 오차 범위(예를 들어, 1 pixel) 내에서 감지한다. 도 6(a) 와 같이 구성된 카메라 로봇 간 좌표계 변환 오차 측정 실험 장치에서는, 저가의 TOF(Time-of-Flight) 3차원 카메라와 카메라 로봇 간 좌표값 보정 방법을 이용하여 레이저 범위 파인더 스폿을 측정한 결과, 카 메라의 좌표 영상이 도 6(b)와 같이 생성되었다. 또한, 시야각(Field Of View, FOV)이 60 cm x 70 cm x 100 cm 인 실험 환경에서, 수학식 10에 기재된 동차 변 환 행렬을 이용하여 카메라 로봇 좌표계 변환의 최대 오차를 측정한 결과, 도 7에서 보는 바와 같이, 실측값 (Ground Truth) 데이터와 추정값 간에 약 28 mm의 최대 오차가 관측됨을 알 수 있다. 이와 같은 오차는 TOF 3차원 카메라 렌즈의 왜곡 현상 또는 저가의 3차원 카메라 센서에 의한 3차원 영상 측정 중에 발생하는 오류에 기인한다. 여기에서, TOF(Time-of-Flight) 3차원 카메라는 거리 또는 깊이를 측정할 수 있는 3 차원 카메라의 한 종 류로서, \"비행 시간\"으로부터 거리를 측정한다. 즉, 거리(D) = 비행속도(V) * 비행시간(T)인데, 이때 비행속도는 광의 속도가 되고, 물체의 거리는 D/2가 된다. 광원은 주로 레이저나 적외선을 사용한다. 카메라의 광원으로부터 레이저나 적외선이 발사되는데, 그 파형이 펄스 형태가 될 수도 있고 싸인파 형태 가 될 수도 있다. 또한, '시야각'이란 센서를 상하 좌우로 움직였을 때 얻을 수 있는 최대한의 범위로서, 이 값이 커지면 한 화 면에 표현해야 할 정보량이 많아지므로 피사체의 크기는 줄어들게 되고, 반대로 값이 작아지면 피사체가 확대되 는 효과를 가지게 된다. 한편, 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법은 동차 변환 행렬로 보정이 불가능한 좌 표값 변환 과정상 에러에 대하여 인공 지능(AI) 모델을 이용하여 2차적으로 보정한다. 즉, 도 4에서 보는 바와 같이, 수학식 10에 기재된 동차 변환 행렬을 이용하여 변환해 보정한 카메라 로봇 좌표 값 쌍에서 관측된 최대 오차를 제어부가 소정 값보다 큰지 여부를 판단한다. 만일, 관측된 최대 오차가 소정 값보다 큰 경우, 제어부가 인공 지능 모델의 딥 러닝 기법을 활용해 반복 적으로 수행되는 기계 학습을 한다. 이를 통해 획득된 카메라 로봇 좌표값 쌍의 정정값을 실측값에 반영하여 동차 변환 행렬로 보정이 불가능한 좌 표값 변환 과정상 에러에 대하여 2차적 보정을 수행하게 된다. 이와 같이 동차 변환 행렬 및 인공 지능 모델을 모두 이용할 경우, 관측된 최대 오차가 약 5.9 mm로서, 도 6에 서 비교한 바와 같이, 관측된 최대 오차가 약 28 mm인 동차 변환 행렬만을 이용할 때보다 실측값 데이터와 추정 값 간 최대 오차가 약 4.7배 현저하게 감소된 것이 관측됨을 알 수 있다. 이와 같이, 본 발명은 저가의 3차원 카메라로 측정된 3차원 카메라 좌표를 로봇 좌표로 변환하는 좌표값을 보정 하는 알고리즘에 동차 변환 행렬 및 인공지능의 딥러닝 기법을 이용하여 좌표 변환 중에 발생할 수 있는 다양한 오차를 최소화할 수 있는 로봇과 카메라 간 좌표값 보정 장치 및 보정 방법을 제공한다. 이를 통하여, 종래에 카메라로 측정된 카메라 좌표를 로봇 좌표로 변환하는 과정에서 저가의 3차원 카메라로 측 정됨에 따라 발생하는 카메라 렌즈의 왜곡 현상 또는 영상 측정 중에 발생하는 오류로 인한 실측값 데이터와 추 정값 간의 큰 오차가 현저하게 감소된다. 이상, 일부 예를 들어서 본 발명의 바람직한 여러 가지 실시예에 대해서 설명하였지만, 본 \"발명을 실시하기 위 한 구체적인 내용\" 항목에 기재된 여러 가지 다양한 실시예에 관한 설명은 예시적인 것에 불과한 것이며, 본 발 명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 이상의 설명으로부터 본 발명을 다양하게 변형하여 실시 하거나 본 발명과 균등한 실시를 행할 수 있다는 점을 잘 이해하고 있을 것이다. 또한, 본 발명은 다른 다양한 형태로 구현될 수 있기 때문에 본 발명은 상술한 설명에 의해서 한정되는 것이 아 니며, 이상의 설명은 본 발명의 개시 내용이 완전해지도록 하기 위한 것으로 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이며, 본 발명은 청구범 위의 각 청구항에 의해서 정의될 뿐임을 알아야 한다.부호의 설명 100: 로봇 110: 로봇 암 120: 그리퍼 130: 그리퍼 어댑터 131 내지 134: 4개의 QR 코드부 200: 카메라 210: 카메라 센서 300: 제어부"}
{"patent_id": "10-2020-0006220", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 장치의 사시도이다. 도 2는 도 1에 도시된 본 발명의 보정 장치 내 그리퍼 어댑터의 평면도 및 QR 코드부의 확대도이다. 도 3은 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법에서 보정 수단을 설명하기 위한 구성도 이다. 도 4는 본 발명의 일 실시예에 따른 로봇과 카메라 간 좌표값 보정 방법의 동작을 설명하기 위한 순서도이다. 도 5는 본 도 4에 도시된 보정 방법 중 단계(S300)의 세부 동작을 설명하기 위한 순서도이다. 도 6은 도 4에 도시된 보정 방법 중 단계(S600)에서 오차를 측정하는 실험 장치에 대한 사진이다. 도 7은 도 4에 도시된 보정 방법 중 단계(S500)에서 동차 변환 행렬만을 이용하여 1차 보정한 후 실측값 데이터 와 추정값 간 최대 오차를 관측한 결과 영상이다. 도 8은 도 4에 도시된 보정 방법 중 단계(S500)에서 실측값 데이터와 추정값 간 최대 오차를 동차 변환 행렬만 을 이용한 경우(a)와 단계(S750)에서 동차 변환 행렬 및 인공 지능 모델을 이용한 경우(b)를 비교한 결과 영상 이다."}
