{"patent_id": "10-2017-0140317", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0046471", "출원번호": "10-2017-0140317", "발명의 명칭": "의료 영상 처리 방법 및 그에 따른 의료 영상 처리 장치", "출원인": "삼성전자주식회사", "발명자": "이동재"}}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의료 영상을 획득하는 단계; 상기 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서, 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신경망을 획득하는 단계; 및 상기 제1 인공 배양 신경망을 통하여, 상기 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인제1 시점과 다른 적어도 하나의 시점 각각에서의 상기 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득하는 단계를 포함하는 것을 특징으로 하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적어도 하나의 제2 의료 영상 각각은 상기 제1 시점과 다른 적어도 하나의 시점 각각에서 상기 제1 의료 영상에 포함되는 병변의 변화 상태를 예측하여 획득한 인공 의료 영상인 것을 특징으로 하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제1 인공 배양 신경망은 상기 복수개의 실제 의료 영상들 각각에 포함되는 상기 병변의 시간에 따른 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및 상기 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를예측하고, 예측된 결과를 포함하는 인공 의료 영상을 출력하는 심층 신경망인 것을 특징으로 하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 병변의 상태는 상기 병변의 발생 시기, 상기 병변의 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및상기 병변으로 인한 추가 질병의 특성, 상기 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를포함하는 것을 특징으로 하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 적어도 하나의 제2 의료 영상에 근거하여 상기 제1 인공 배양 신경망을 학습하여, 상기 제1 인공 배양 신경망을 형성하는 복수개의 노드들의 가중치 값들을 조절하는 단계; 및 상기 조절된 가중치 값들을 포함하는 제2 인공 배양 신경망을 획득하는 단계를 더 포함하는 것을 특징으로 하는의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제2 인공 배양 신경망을 통하여 피검사자의 대상체를 스캔하여 획득한 제3 의료 영상을 분석하고, 상기 분석의 결과로 상기 피검사자의 대상체에 대응되는 진단 정보를 획득하는 단계를 더 포함하는 것을 특징으로 하는의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 진단 정보는 공개특허 10-2019-0046471-3-상기 대상체에 발생한 질병의 종류, 상기 질병의 특성, 상기 질병의 시간에 따른 변화 또는 발전 가능성, 상기질병으로 인하여 발생 가능한 추가 질병의 종류, 상기 추가 질병의 특성, 상기 추가 질병의 변화 또는 발전 상태 중 적어도 하나를 포함하는 것을 특징으로 하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 적어도 하나의 제2 의료 영상을 포함하는 화면을 디스플레이하는 단계를 더 포함하는 것을 특징으로 하는의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 적어도 하나의 제2 의료 영상은 병변을 포함하는 대상체를 나타내는 엑스선 영상인 것을 특징으로 하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 적어도 하나의 제2 의료 영상은 상기 제1 시점과 다른 적어도 하나의 시점 각각에서의 상기 병변의 상태를 나타내는 병변 영상인 것을 특징으로하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의료 영상을 획득하는 데이터 획득부; 및 상기 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서 시간에 따른 병변의 변화를 예측하기 위한제1 인공 배양 신경망을 획득하고, 상기 제1 인공 배양 신경망을 통하여 상기 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에서의 상기 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득하는 제어부를 포함하는 것을 특징으로 하는의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 적어도 하나의 제2 의료 영상 각각은 상기 제1 시점과 다른 적어도 하나의 시점 각각에서 상기 제1 의료 영상에 포함되는 병변의 변화 상태를 예측하여 획득한 인공 의료 영상인 것을 특징으로 하는 의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 제1 인공 배양 신경망은 상기 복수개의 실제 의료 영상들 각각에 포함되는 상기 병변의 시간에 따른 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및 상기 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를예측하고, 예측된 결과를 포함하는 인공 의료 영상을 출력하는 심층 신경망인 것을 특징으로 하는 의료 영상 처리 방법."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 병변의 상태는 상기 병변의 발생 시기, 상기 병변의 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및상기 추가 질병의 특성, 상기 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를 포함하는 것을특징으로 하는 의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 제어부는 공개특허 10-2019-0046471-4-상기 적어도 하나의 제2 의료 영상에 근거하여 상기 제1 인공 배양 신경망을 학습하여, 상기 제1 인공 배양 신경망을 형성하는 복수개의 노드들의 가중치 값들을 조절하고, 상기 조절된 가중치 값들을 포함하는 제2 인공 배양 신경망을 획득하는 것을 특징으로 하는 의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제어부는 상기 제2 인공 배양 신경망을 통하여 피검사자의 대상체를 스캔하여 획득한 제3 의료 영상을 분석하고, 상기 분석의 결과로 상기 피검사자의 상기 대상체에 대응되는 진단 정보를 획득하는 것을 특징으로 하는 의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 진단 정보는 상기 대상체에 발생한 질병의 종류, 상기 질병의 특성, 상기 질병의 시간에 따른 변화 또는 발전 가능성, 상기질병으로 인하여 발생 가능한 추가 질병의 종류, 상기 추가 질병의 특성, 상기 추가 질병의 변화 또는 발전 가능성 중 적어도 하나를 포함하는 것을 특징으로 하는 의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 적어도 하나의 제2 의료 영상은 병변을 포함하는 대상체를 나타내는 엑스선 영상 또는 상기 제1 시점과 다른 적어도 하나의 시점 각각에서의 상기 병변의 상태를 나타내는 병변 영상인 것을 특징으로 하는 의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 적어도 하나의 제2 의료 영상을 포함하는 화면을 디스플레이하는 디스플레이를 더 포함하는 것을 특징으로하는 의료 영상 처리 장치."}
{"patent_id": "10-2017-0140317", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터에 의해서 실행 가능한 명령어들을 포함하는 프로그램을 기록한 기록 매체에 있어서, 상기 프로그램은 복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의료 영상을 획득하는 단계; 상기 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서, 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신경망을 획득하는 단계; 및 상기 제1 인공 배양 신경망을 통하여, 상기 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인제1 시점과 다른 적어도 하나의 시점 각각에서의 상기 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득하는 단계를 포함하는 방법을 실행하기 위한 명령어들을 포함하는 프로그램인것을 특징으로 하는 기록 매체."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시예에 따른 의료 영상 처리 방법은 복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의료 영상을 획득하는 단계; 상기 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서, 시간에 따른 병변 의 변화를 예측하기 위한 제1 인공 배양 신경망을 획득하는 단계; 및 상기 제1 인공 배양 신경망을 통하여, 상기 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에 서의 상기 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득하는 단계를 포함한다. 본 개시의 실시예에 따른 의료 영상 처리 방법에 따르면, 의사 등의 사용자는 실제 의료 영상이 획득 된 시점에서의 병변의 상태 이외에, 후속되는 시점에서의 병변의 발전 양상을 인공적으로 획득되는 제2 의료 영 상을 통하여 용이하게 예측 또는 파악할 수 있다."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 실시예들은 의료 영상 장치로부터 획득된 의료 영상을 분석하여 추가적인 영상 또는 정보를 획득하기 위한 의료 영상 처리 방법 및 그에 따른 의료 영상 처리 장치에 대한 것이다."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "의료 영상 장치는 대상체의 내부 구조를 영상으로 획득하기 위한 장비이다. 의료 영상 장치는 비침습 검사 장치 로서, 신체 내의 구조적 세부사항, 내부 조직 및 유체의 흐름 등을 촬영 및 처리하여 사용자에게 보여준다. 의 사 등의 사용자는 의료 영상 장치에서 출력되는 의료 영상을 이용하여 환자의 건강 상태 및 질병을 진단할 수 있다.의료 영상 장치로는 대상체로 엑스선을 조사하고 대상체를 통과한 엑스선을 감지하여 영상을 이미징하는 엑스레 이(X-ray) 장치, 자기 공명 영상을 제공하기 위한 자기 공명 영상(MRI: magnetic resonance imaging) 장치, 컴 퓨터 단층 촬영(CT: Computed Tomography) 장치, 및 초음파(Ultrasound) 진단 장치 등이 있다. 최근에는 캐드(CAD: Computer Aided Detection) 시스템, 기계 학습, 등과 같은 영상 처리 기술의 발전으로 인하 여, 의료 영상 장치가 획득된 의료 영상을 컴퓨터로 분석하여, 대상체에 이상이 발생한 부위인 비정상 (abnormal) 영역을 검출하거나 분석한 결과를 생성할 수 있다. 이렇게 생성된 분석 결과는 의사의 판독 및 환자 의 진단을 용이하게 할 수 있다. 구체적으로 이러한 의료 영상의 처리를 위하여, 인공지능(Artificial Intelligence, AI)을 이용한 정보 처리를 수행하는 캐드 시스템이 개발되고 있다. 여기서, 인공 지능을 이용한 정보 처리를 수행하는 캐드 시스템을 '인 공지능 시스템'이라 호칭할 수 있을 것이다. 인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 규칙 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 규칙 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분 야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 인공 지능 시스템에 있어서, 전술한 시각적 이해 및 추론 예측 분야를 의료 영상의 처리에 적용하면, 보다 빠르 고 정확하게 의료 영상을 분석함으로써, 의사 등의 사용자가 의료 영상을 통하여 환자를 진단하는데 도움이 될 것이다."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시예는 소정 시점에서 이미징된 실제 의료 영상에서 병변이 포함 또는 검출된 경우, 검출된 병변의 시간에 따른 변화를 예측할 수 있는 적어도 하나의 의료 영상을 획득하기 위한 의료 영상 처리 방법 및 그에 따 른 의료 영상 처리 장치의 제공을 목적으로 한다. 또한, 본 개시의 실시예는 병변을 포함하는 복수개의 실제 의료 영상을 학습한 심층 신경망을 통하여, 환자의 질병을 정확하게 진단하는데 이용되는 정보를 획득하기 위한 의료 영상 처리 방법 및 그에 따른 의료 영상 처리 장치의 제공을 목적으로 한다."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시예에 따른 의료 영상 처리 방법은 복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의 료 영상을 획득하는 단계; 상기 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서, 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신경망을 획득하는 단계; 및 상기 제1 인공 배양 신경망을 통하여, 상기 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에서의 상기 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득하는 단계를 포함한다. 또한, 상기 적어도 하나의 제2 의료 영상 각각은 상기 제1 시점과 다른 적어도 하나의 시점 각각에서 상기 제1 의료 영상에 포함되는 병변의 변화 상태를 예측하여 획득한 인공 의료 영상이 될 수 있다. 또한, 상기 제1 인공 배양 신경망은 상기 복수개의 실제 의료 영상들 각각에 포함되는 상기 병변의 시간에 따른 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및 상기 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를 예측하고, 예측된 결과를 포함하는 인공 의료 영상을 출력하는 심층 신경망이 될 수 있다. 또한, 상기 병변의 상태는 상기 병변의 발생 시기, 상기 병변의 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및 상기 병변으로 인한 추가 질병의 특성, 상기 병변으로 인한 추가 질병의 발전 또는 변 화 형태 중 적어도 하나를 포함할 수 있다. 본 개시의 실시예에 따른 의료 영상 처리 방법은 상기 적어도 하나의 제2 의료 영상에 근거하여 상기 제1 인공 배양 신경망을 학습하여, 상기 제1 인공 배양 신경망을 형성하는 복수개의 노드들의 가중치 값들을 조절하는 단 계; 및 상기 조절된 가중치 값들을 포함하는 제2 인공 배양 신경망을 획득하는 단계를 더 포함할 수 있다. 또한, 본 개시의 실시예에 따른 의료 영상 처리 방법은 상기 제2 인공 배양 신경망을 통하여 피검사자의 대상체 를 스캔하여 획득한 제3 의료 영상을 분석하고, 상기 분석의 결과로 상기 피검사자의 대상체에 대응되는 진단 정보를 획득하는 단계를 더 포함할 수 있다. 또한, 상기 진단 정보는 상기 대상체에 발생한 질병의 종류, 상기 질병의 특성, 상기 질병의 시간에 따른 변화 또는 발전 가능성, 상기 질병으로 인하여 발생 가능한 추가 질병의 종류, 상기 추가 질병의 특성, 상기 추가 질 병의 변화 또는 발전 상태 중 적어도 하나를 포함할 수 있다. 또한, 본 개시의 실시예에 따른 의료 영상 처리 방법은 상기 적어도 하나의 제2 의료 영상을 포함하는 화면을 디스플레이하는 단계를 더 포함할 수 있다. 또한, 상기 적어도 하나의 제2 의료 영상은 병변을 포함하는 대상체를 나타내는 엑스선 영상이 될 수 있다. 또한, 상기 적어도 하나의 제2 의료 영상은 상기 제1 시점과 다른 적어도 하나의 시점 각각에서의 상기 병변의 상태를 나타내는 병변 영상이 될 수 있다. 본 개시의 실시예에 따른 의료 영상 처리 장치는 복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의 료 영상을 획득하는 데이터 획득부; 및 상기 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서 시 간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신경망을 획득하고, 상기 제1 인공 배양 신경망을 통하 여 상기 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하나의 시 점 각각에서의 상기 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득하 는 제어부를 포함할 수 있다. 또한, 상기 적어도 하나의 제2 의료 영상 각각은 상기 제1 시점과 다른 적어도 하나의 시점 각각에서 상기 제1 의료 영상에 포함되는 병변의 변화 상태를 예측하여 획득한 인공 의료 영상이 될 수 있다. 또한, 상기 제1 인공 배양 신경망은 상기 복수개의 실제 의료 영상들 각각에 포함되는 상기 병변의 시간에 따른 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및 상기 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를 예측하고, 예측된 결과를 포함하는 인공 의료 영상을 출력하는 심층 신경망이 될 수 있다. 또한, 상기 병변의 상태는 상기 병변의 발생 시기, 상기 병변의 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및 상기 추가 질병의 특성, 상기 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어 도 하나를 포함할 수 있다. 또한, 상기 제어부는 상기 적어도 하나의 제2 의료 영상에 근거하여 상기 제1 인공 배양 신경망을 학습하여, 상 기 제1 인공 배양 신경망을 형성하는 복수개의 노드들의 가중치 값들을 조절하고, 상기 조절된 가중치 값들을 포함하는 제2 인공 배양 신경망을 획득할 수 있다. 또한, 상기 제어부는 상기 제2 인공 배양 신경망을 통하여 피검사자의 대상체를 스캔하여 획득한 제3 의료 영상 을 분석하고, 상기 분석의 결과로 상기 피검사자의 상기 대상체에 대응되는 진단 정보를 획득할 수 있다. 또한, 상기 진단 정보는 상기 대상체에 발생한 질병의 종류, 상기 질병의 특성, 상기 질병의 시간에 따른 변화 또는 발전 가능성, 상기 질병으로 인하여 발생 가능한 추가 질병의 종류, 상기 추가 질병의 특성, 상기 추가 질 병의 변화 또는 발전 가능성 중 적어도 하나를 포함할 수 있다. 또한, 상기 적어도 하나의 제2 의료 영상은 병변을 포함하는 대상체를 나타내는 엑스선 영상 또는 상기 제1 시 점과 다른 적어도 하나의 시점 각각에서의 상기 병변의 상태를 나타내는 병변 영상이 될 수 있다. 또한, 본 개시의 실시예에 따른 의료 영상 처리 장치는 상기 적어도 하나의 제2 의료 영상을 포함하는 화면을 디스플레이하는 디스플레이를 더 포함할 수 있다. 또한, 본 개시의 실시예에 따른 기록 매체는 퓨터에 의해서 실행 가능한 명령어들을 포함하는 프로그램을 기록 한 기록 매체이다. 여기서, 상기 프로그램은 복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의료 영 상을 획득하는 단계; 상기 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서, 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신경망을 획득하는 단계; 및 상기 제1 인공 배양 신경망을 통하여, 상기 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에 서의 상기 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득하는 단계를 포함하는 방법을 실행하기 위한 명령어들을 포함하는 프로그램이다."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 따른 의료 영상 처리 방법 및 그에 따른 의료 영상 처리 장치에 있어서, 의사 등의 사용자 는 실제 의료 영상이 획득된 시점에서의 병변의 상태 이외에, 후속되는 시점에서의 병변의 발전 양상을 인공적 으로 획득되는 제2 의료 영상을 통하여 용이하게 예측 또는 파악할 수 있다. 또한, 본 개시의 실시예에 따른 의료 영상 처리 방법 및 그에 따른 의료 영상 처리 장치는 인공적으로 획득된 복수의 제2 의료 영상을 이용하여 심층 신경망을 학습함으로써, 학습 데이터의 다양성을 증가시킬 수 있으며, 학습 데이터의 한계성을 극복할 수 있다. 또한, 본 개시의 실시예에 따른 의료 영상 처리 방법 및 그에 따른 의료 영상 처리 장치는 인공적으로 획득된 복수의 제2 의료 영상을 이용하여 심층 신경망을 학습함으로써, 심층 신경망의 정확도를 개선 및 증가시킬 수 있다. 그에 따라서, 후속하여 획득되는 검사 영상의 진단 정보의 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서는 본 발명의 권리범위를 명확히 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 실시할 수 있도록, 본 발명의 원리를 설명하고, 실시예들을 개시한다. 개시된 실시예들은 다양한 형태 로 구현될 수 있다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부'(part, portion)라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시 예들에 따라 복수의 '부'가 하나의 요소(unit, element)로 구현되거나, 하나의 '부'가 복수의 요소들을 포함하 는 것도 가능하다. 이하 첨부된 도면들을 참고하여 본 발명의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 영상은 자기 공명 영상(MRI) 장치, 컴퓨터 단층 촬영(CT) 장치, 초음파 촬영 장치, 또는 엑스선 장치 등의 의료 영상 장치에 의해 획득된 의료 영상을 포함할 수 있다. 본 명세서에서 '대상체(object)'는 촬영의 대상이 되는 것으로서, 사람, 동물, 또는 그 일부를 포함할 수 있다. 예를 들어, 대상체는 신체의 일부(장기 또는 기관 등; organ) 또는 팬텀(phantom) 등을 포함할 수 있다. 전술한 의료 영상 장치 중 빠르고 간편하게 의료 영상을 획득할 수 있는 장치로는 엑스선 장치를 예로 들 수 있 으며, 이하에서 도 1을 참조하여 상세히 설명하도록 한다. 도 1은 일 실시예에 따른 엑스선 장치의 구성을 도시하는 외관도이다. 도 1에서는 고정식 엑스선 장치를 예로 들어 설명한다. 도 1을 참조하면, 엑스선 장치는 엑스선을 발생시켜 조사하는 엑스선 조사부, 엑스선 조사부로부터 조사되어 대상체를 투과한 엑스선을 검출하는 엑스선 디텍터, 및 사용자로부터 명령을 입력 받고 정보를 제공하는 워크스테이션을 포함한다. 또한, 엑스선 장치는 입력된 명령에 따라 엑스선 장치를 제 어하는 제어부 및 외부 장치와 통신하는 통신부를 포함할 수 있다. 제어부 및 통신부의 구성요소 중 일부 또는 전부는 워크스테이션에 포함되거나 워크스테이션 과 별도로 마련될 수 있다. 엑스선 조사부는 엑스선을 발생시키는 엑스선 소스와, 엑스선 소스에서 발생되는 엑스선의 조사영역을 조 절하는 콜리메이터(collimator)를 구비할 수 있다. 엑스선 장치가 배치되는 검사실 천장에는 가이드 레일이 설치될 수 있고, 가이드 레일을 따라 이 동하는 이동 캐리지에 엑스선 조사부를 연결하여 대상체(P)에 대응되는 위치로 엑스선 조사부를 이동시킬 수 있고, 이동 캐리지와 엑스선 조사부는 절첩 가능한 포스트 프레임을 통해 연결되어 엑스선 조사부의 높이를 조절할 수 있다. 워크스테이션에는 사용자의 명령을 입력 받는 입력부 및 정보를 표시하는 디스플레이가 마련될 수 있다. 입력부는 촬영 프로토콜, 촬영 조건, 촬영 타이밍, 엑스선 조사부의 위치 제어 등을 위한 명령을 입 력 받을 수 있다. 입력부는 키보드, 마우스, 터치스크린, 음성 인식기, 등을 포함할 수 있다. 디스플레이는 사용자의 입력을 가이드 하기 위한 화면, 엑스선 영상, 엑스선 장치의 상태를 나타내는 화면 등을 표시할 수 있다. 제어부는 사용자로부터 입력된 명령에 따라 엑스선 조사부의 촬영 타이밍, 촬영 조건 등을 제어할 수 있고, 엑스선 디텍터로부터 수신된 이미지 데이터를 이용하여 의료 이미지를 생성할 수 있다. 또한, 제어 부는 촬영 프로토콜 및 대상체(P)의 위치에 따라 엑스선 조사부나 엑스선 디텍터가 장착된 장착 부(14, 24)의 위치 또는 자세를 제어할 수도 있다. 제어부는 전술한 동작 및 후술하는 동작을 수행하는 프로그램이 저장된 메모리 및 저장된 프로그램을 실행 하는 프로세서를 포함할 수 있다. 제어부는 단일 프로세서를 포함할 수도 있고, 복수의 프로세서를 포함할 수도 있는바, 후자의 경우에는 복수의 프로세서가 하나의 칩 상에 집적될 수도 있고, 물리적으로 분리될 수도 있다. 엑스선 장치는 통신부를 통해 외부 장치 (예를 들면, 외부의 서버, 의료 장치 및 휴 대용 단말(153; 스마트폰, 태브릿 PC, 웨어러블 장치 등)) 와 연결되어 데이터를 송신하거나 수신할 수 있다. 통신부는 외부 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으며, 예를 들어 근거 리 통신 모듈, 유선 통신 모듈 및 무선 통신 모듈 중 적어도 하나를 포함할 수 있다. 또한, 통신부가 외부 장치로부터 제어 신호를 수신하고, 수신된 제어 신호를 제어부에 전달하여 제어 부로 하여금 수신된 제어 신호에 따라 엑스선 장치를 제어하도록 하는 것도 가능하다. 또한, 제어부는 통신부를 통해 외부 장치에 제어 신호를 송신함으로써, 외부 장치를 제어부의 제어 신호에 따라 제어하는 것도 가능하다. 예를 들어, 외부 장치는 통신부를 통해 수신된 제어부의 제어 신호에 따라 외부 장치의 데이터를 처리할 수 있다. 또한, 통신부는 엑스선 장치의 구성요소들 간에 통신을 가능하게 하는 내부 통신 모듈을 더 포함할 수도 있다. 외부 장치에는 엑스선 장치를 제어할 수 있는 프로그램이 설치될 수 있는 바, 이 프로그램은 제어부의 동작 중 일부 또는 전부를 수행하는 명령어를 포함할 수 있다. 프로그램은 휴대용 단말에 미리 설치될 수도 있고, 휴대용 단말의 사용자가 어플리케이션을 제공하는 서버로부터 프로그램을 다운로딩하여 설치하는 것도 가능하다. 어플리케이션을 제공하는 서버에는 해당 프로그 램이 저장된 기록매체가 포함될 수 있다. 한편, 엑스선 디텍터는 스탠드나 테이블에 고정된 고정형 엑스선 디텍터로 구현될 수도 있고, 장 착부(14, 24)에 착탈 가능하게 장착되거나, 임의의 위치에서 사용 가능한 휴대용 엑스선 디텍터(portable x-ray detector)로 구현될 수도 있다. 휴대용 엑스선 디텍터는 데이터 전송 방식과 전원 공급 방식에 따라 유선 타입 또는 무선 타입으로 구현될 수 있다. 엑스선 디텍터는 엑스선 장치의 구성 요소로 포함될 수도 있고, 포함되지 않을 수도 있다. 후자의 경 우, 엑스선 디텍터는 사용자에 의해 엑스선 장치에 등록될 수 있다. 또한, 두 경우 모두 엑스선 디텍 터는 통신부를 통해 제어부와 연결되어 제어 신호를 수신하거나 이미지 데이터를 송신할 수 있 다. 엑스선 조사부의 일 측면에는 사용자에게 정보를 제공하고 사용자로부터 명령을 입력 받는 서브 유저 인터 페이스가 마련될 수 있고, 워크 스테이션의 입력부 및 디스플레이가 수행하는 기능 중 일부 또는 전부가 서브 유저 인터페이스에서 수행될 수 있다. 제어부 및 통신부의 구성 요소 중 전부 또는 일부가 워크스테이션과 별도로 마련되는 경우에는 엑스선 조사부에 마련된 서브 유저인터페이스에 포함될 수 있다. 도 1은 검사실의 천장에 연결된 고정식 엑스선 장치에 대해 도시하고 있지만, 엑스선 장치는 C-암(arm) 타 입 엑스선 장치, 모바일 엑스선 장치 등 당업자에게 자명한 범위 내에서 다양한 구조의 엑스선 장치를 포함할 수 있다. 의료 영상의 판독, 또는 의료 영상을 이용한 진단의 용이성 향상을 위하여, 의료 영상 처리 장치는 의료 영상 장치에서 획득된 의료 영상을 분석하고 그에 따른 결과를 이용할 수 있다. 여기서, 의료 영상은 환자의 대상체 내부를 나타내는 모든 영상이 될 수 있다. 또한, '의료 영상'은 대상체를 시각적으로 표현하는 영상뿐만 아니라 영상을 생성하기 위해서 획득되는 데이터를 지칭할 수도 있을 것이다. 이하에서는, 의료 영상 장치를 이용하여 환자의 대상체를 직접 스캔하여 획득된 의료 영상을 '실제 의료 영상' 이라 칭하고, 의료 영상 장치를 이용하여 환자의 대상체를 직접 이미징 하지 않고 획득된 의료 영상을 '인공 의 료 영상(Artificial medical image)'라 칭하겠다. 의료 영상 처리 장치는 i) 의료 영상을 이용하여 소정 정보를 획득하거나, ii) 의료 영상을 분석하여 진단 정보 를 획득하거나, iii) 의료 영상에 근거하여 진단에 이용되는 모든 영상 또는 정보를 가공, 생성, 수정, 갱신 또 는 디스플레이할 수 있는 전자 장치를 의미할 수 있다. 구체적으로, 의료 영상 처리 장치는 캐드(CAD: Computer Aided Detection) 시스템, 또는 기계 학습, 등과 같은 영상 처리 기술을 이용하여, 의료 영상 장치에서 획득된 의료 영상을 컴퓨터로 분석하고, 그 결과를 이용할 수 있다. 이하에서는, 도 1의 엑스선 장치와 같은 의료 영상 장치에서 소정 시점에서 이미징된 의료 영상에서 병변이 포 함 또는 검출된 경우, 검출된 병변의 시간에 따른 변화를 예측할 수 있는 적어도 하나의 의료 영상을 획득할 수 있는 본 개시의 실시예에 따른 의료 영상 처리 방법 및 그에 따른 의료 영상 처리 장치를 첨부된 도면들을 참조 하여 상세히 설명한다. 본 개시의 실시예에 따른 의료 영상 처리 장치는 의료 영상을 처리하여 진단에 이용되는 추가적인 정보를 획득 할 수 있는 모든 전자 장치를 포함할 수 있다. 여기서, 의료 영상의 처리는 의료 영상을 분석, 가공, 의료 영상 의 분석 결과 생성되는 데이터를 생성, 분석, 디스플레이 하는 모든 동작을 포함할 수 있다. 또한, 본 개시의 실시예에 따른 의료 영상 처리 장치는 다양한 형태로 존재할 수 있다. 예를 들어, 본 개시의 실시예에 따른 의료 영상 처리 장치는 의료 영상 장치, 예를 들어, 도 1의 엑스선 장치, CT 장치, MRI 시 스템 또는 초음파 진단 장치의 워크 스테이션(예를 들어, 엑스선 장치의 워크 스테이션) 또는 콘솔 (console) 상에 형성될 수 있다. 또 다른 예로, 본 개시의 실시예에 따른 의료 영상 처리 장치는 의료 영상 장치, 예를 들어, 도 1의 엑스선 장 치, CT 장치, MRI 시스템 또는 초음파 진단 장치와 구별되는 독립된 별도의 장치 또는 서버 상에 형성될 수 있다. 여기서, 의료 영상 장치와 구별되는 독립된 별도의 장치 또는 서버를 '외부 장치'라 지칭할 수 있다. 예를 들어, 외부 장치로는 도 1에서 도시된 서버, 의료 장치, 및 휴대용 단말(1530 등이 될 수 있으 며, 의료 영상 장치와 유무선의 통신 네트워크를 통하여 실제 의료 영상을 수신할 수 있다. 예를 들어, 본 개시 의 실시예에 따른 의료 영상 처리 장치는 분석용 워크 스테이션, 외부의 의료 장치, PACS(Picture Archiving Communications System) 서버, PACS 뷰어, 외부 의료 서버, 또는 병원 서버 상에 형성될 수 있다. 도 2는 본 개시의 실시예에 따른 의료 영상 처리 장치를 나타내는 블록도이다. 도 2를 참조하면, 본 개시의 실시예에 따른 의료 영상 처리 장치는 데이터 획득부 및 제어부를 포함할 수 있다. 데이터 획득부는 복수의 환자들에 대응하며 병변을 포함하는 복수개의 실제 의료 영상을 획득한다. 여기서, 여기서, 복수개의 실제 의료 영상들 각각은 병변을 포함하는 의료 영상이 되며, 심층 신경망을 학습하 기 위해 이용되는 데이터들이다. 따라서, 복수개의 실제 의료 영상들 각각은 다양한 형태, 상태, 및 진행 정도 등을 갖는 병변들을 포함하며, 다양한 연령, 성별, 가족력 등을 갖는 환자들을 의료 영상 촬영하여 획득된 영상 들이 될 수 있다. 여기서, 병변은 건강한 신체의 세포, 조직, 장기, 및 구성 물질 중 적어도 하나를 포함하는 신체 부위가 아닌 모든 비정상적인 신체 부위를 지칭할 수 있다. 따라서, 병변은 질병 발생 직전 단계의 신체 부위, 질병이 발생 한 신체 부위 등을 모두 포함할 수 있다. 여기서, 데이터 획득부는 다양한 방법으로 복수개의 실제 의료 영상을 획득할 수 있다. 예를 들어, 의료 영상 처리 장치가 의료 영상 장치(예를 들어, 엑스선 장치)의 내부에 형성되는 경우, 의료 영상 처리 장치는 자체적으로 의료 영상 촬영을 수행하여 의료 영상을 획득할 수 있을 것이다. 또 다른 예로, 의료 영상 처리 장치과 의료 영상 장치와 독립적인 장치로 형성되는 경우, 의료 영상 장치로부터 유무선의 통신 네트워크를 통하여 의료 영상을 수신할 수 있을 것이다. 이 경우, 데이터 획득부는 내부적으로 통신부(예 를 들어, 이하의 도 3에서 설명할 통신부)(도 2에서는 미도시 됨)를 포함하고, 내부적으로 구비되는 통신 부(미도시)를 통하여 복수개의 실제 의료 영상을 수신할 수 있다. 제어부는 데이터 획득부에서 획득한 복수개의 실제 의료 영상들에 근거하여 심층 신경망(DNN: Deep Neural Network)을 학습한다. 그리고, 학습의 결과 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신 경망을 획득한다. 그리고, 제1 인공 배양 신경망을 통하여 복수개의 실제 의료 영상에 포함되는 제1 의료 영상 의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에서의 제1 의료 영상에 포함되는 병변의 상태를 나타 내는 적어도 하나의 제2 의료 영상을 획득한다. 여기서, 설명의 편의상 '제1 의료 영상'을 단수의 개념으로 기 재하였으나, 제1 의료 영상은 복수개의 서로 다른 의료 영상들을 포함할 수 있다. 즉, 제어부는 제1 인공 배양 신경망을 통하여 복수개의 실제 의료 영상에 포함되는 적어도 하나의 제1 의료 영상들 각각에 대응되는 적 어도 하나의 제2 의료 영상을 생성할 수 있다. 여기서, 실제 의료 영상, 및 제2 의료 영상은 대상체의 내부를 나타내는 영상으로, 엑스선 영상, 단층 영상, 자 기 공명 영상, 초음파 영상 등이 포함될 수 있다. 또한, 복수개의 실제 의료 영상들은 병변의 다양한 형태들을 파악할 수 있는 영상들로, 서로 다른 진행 정도, 형태 등을 갖는 병변을 갖는 복수의 환자들에 대한 의료 영상촬영을 수행하여 획득된 영상들이 될 수 있다. 그리고, 심층 신경망(Deep Neural Network)은 인공 지능(AI) 기술에 따른 추론 및 예측을 위한 연산을 수행한다. 구체적으로, 심층 신경망(DNN) 연산은 컨볼루션 신경망(CNN: Convolution Neural Network) 연산 등 을 포함할 수 있다. 즉, 제어부는 예시된 신경망을 통하여 데이터 인식 모델을 구현하고, 구현된 데이터 인식 모델을 학습 데이터를 이용하여 학습시킬 수 있다. 그리고, 학습된 데이터 인식 모델을 이용하여 입력되는 데이터인 의료 영상을 분석 또는 분류하여, 의료 영상에서 이미징한 대상체 내에 어떠한 이상이 발생하였는지 여부를 분석 및 분류할 수 있다. 구체적으로, 제1 인공 배양 신경망은 복수개의 실제 의료 영상들 각각에 포함되는 소정 병변의 위중 정도, 소정 병변이 소정 질병에 해당할 가능성, 소정 병변의 시간에 따른 발전 또는 변화 형태, 소정 병변으로 인한 추가 질병의 발병 가능성, 및 소정 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를 예측하고, 예 측된 결과를 포함하는 인공 의료 영상을 출력하기 위한 연산을 수행할 수 있다. 또한, 제2 의료 영상이 나타내는 병변의 상태는 병변의 발생 시기, 병변의 발전 또는 변화 형태, 상기 병변으로 인한 추가 질병의 발병 가능성, 및 병변으로 인한 추가 질병의 발전 또는 변화 형태 중 적어도 하나를 포함할 수 있다. 제1 의료 영상에 포함되는 병변인 현재 발생한 병변이 폐암 0기로 판단되는 경우를 예로 들자. 이 경우, 제2 의 료 영상은 폐암 0기인 병변의 시간에 따른 변화 또는 발전 양상, 시간에 따라 변화된 상태, 시간에 따른 전이 여부 또는 전이 정도(또는, 상태) 등을 나타내는 적어도 하나의 영상으로, 심층 신경망을 이용한 연산을 수행하여 획득된 인공 의료 영상이 될 수 있다. 또한, 제2 의료 영상은 현재 발생한 병반인 폐암 0 기의 병변이 후속 시점에서 다른 장기로 전이될 가능성이 높 은 경우, 현재 발생한 병반인 폐암 0 기 병변으로 인하여 후속되는 소정 시점, 예를 들어, 현재 시점으로부터 3 년 뒤에 발생 가능한 전이암, 예를 들어, 뇌전이암 등에 대한 정보를 나타내는 영상이 될 수 있다. 이 경우, 제 2 영상은 현재시점으로부터 3년 뒤에 발생 가능성이 높은 것으로 판단되는 뇌전이암의 위치, 형태, 특성 등을 나타내는 영상 또는 데이터를 포함할 수 있을 것이다. 또한, 제어부는 복수개의 실제 의료 영상들을 학습하여 시간에 따른 병변의 변화를 예측하기 위해서, 인공 지능 기술에 따른 기계 학습 이외의 기계 학습 기술을 이용할 수도 있을 것이다. 구체적으로, 기계 학습은 컴퓨 터 연산을 통하여 의료 영상에 포함되는 병변을 검출하고 병변의 특성을 분석하여 후속 시점에서의 병변의 변화 를 예측하기 위한 연산 기술로, CAD 연산, 데이터 기반의 통계적인 기계 학습(Statistical learning) 등이 이용 될 수 있다. 따라서, 제어부는 CAD 연산 또는 데이터 기반의 통계적인 기계 학습(Statistical learning) 등의 기계 학 습을 통하여, 복수개의 실제 의료 영상들을 학습하여 시간에 따른 병변의 변화를 예측할 수 있다. 그리고, 예측 결과를 이용하여 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하 나의 시점 각각에서의 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득 할 수 있을 것이다. 여기서, 적어도 하나의 제2 의료 영상 각각은 제1 시점과 다른 적어도 하나의 시점 각각에 서 제1 의료 영상에 포함되는 소정 병변의 변화 상태를 예측하여 획득한 인공 의료 영상이 될 수 있다. 즉, 제2 의료 영상은 대상체를 의료 영상 촬영하여 병변을 이미징한 영상이 아니라, 제1 인공 배양 신경망을 통한 연산 결과 인공적으로 생성된 의료 영상이 된다. 또한, 제어부는 내부적으로 메모리, 예를 들어, ROM, RAM 등 및 전술한 동작을 수행하기 위한 명령어들을 수행하는 적어도 하나의 프로세서를 포함할 수 있다. 그리고, 제어부에 포함되는 적어도 하나의 프로세서 는 전술한 동작들을 수행하기 위한 명령어들을 실행시키도록 동작할 수 있다. 본 개시의 실시예에 따른 의료 영상 처리 장치는 의료 영상에서 확인되는 환자의 병변(lesion) 정보들을 기반하 여, 병변의 변화 및 진행상황 등을 AI(Artificial Intelligence) 기술을 이용하여 병변을 인공 배양 (Artificial Intelligence lesion culture)할 수 있다. 즉, 실제 의료 영상이 획득된 시점과 다른 적어도 하나 의 시점에서 병변의 상태를 알 수 있도록, 인공 지능 기술을 통하여 병변을 배양하는 것이다. 여기서, 인공 배 양된 병변을 포함하는 영상이 전술한 제2 의료 영상이 될 수 있다. 그에 따라서, 의사 등의 사용자는 실제 의료 영상이 획득된 시점에서의 병변의 상태 이외에, 후속되는 시점에서의 병변의 발전 양상(또는 상태)을 제2 의료 영상을 통하여 용이하게 예측 또는 파악할 수 있게 된다. 또한, 제어부는 적어도 하나의 제2 의료 영상에 근거하여 제1 인공 배양 신경망을 학습하여, 제1 인공 배 양 신경망을 형성하는 복수개의 노드들의 가중치 값들을 조절하고, 조절된 가중치 값들을 포함하는 제2 인공 배 양 신경망을 획득할 수 있다. 즉, 제2 인공 배양 신경망은 제1 인공 배양 신경망을 수정 또는 갱신하여 획득되 는 신경망이 될 수 있다. 또한, 제어부는 제2 인공 배양 신경망을 통하여 피검사자의 대상체를 스캔하여 획득한 제3 의료 영상을 분 석하고, 상기 분석의 결과로 피검사자의 대상체에 대응되는 진단 정보를 획득할 수 있다. 여기서, 진단 정보는 대상체에 발생한 질병의 종류, 질병의 특성, 질병의 시간에 따른 변화 또는 발전 가능성, 질병으로 인하여 발생 가능한 추가 질병의 종류, 추가 질병의 특성, 추가 질병의 변화 또는 발전 가능성 중 적어도 하나를 포함할 수 있다. 제1 및 제2 인공 배양 신경망과 같은 심층 신경망은 이하에서 도 5를 참조하여 상세히 설명한다. 도 3은 본 개시의 실시예에 따른 의료 영상 처리 장치를 나타내는 블록도이다. 도 3에 도시된 의료 영상 처리 장치의 데이터 획득부 및 제어부는 각각 도 2에 도시된 의료 영상 처리 장치의 데이터 획 득부 및 제어부에 동일 대응될 수 있으므로, 도 2에서와 중복되는 상세 설명은 생략한다. 도 3에 도시된 의료 영상 처리 장치는 도 2에 도시된 의료 영상 처리 장치에 비하여, 통신부, 심층 신경망 프로세서, 메모리, 디스플레이, 사용자 인터페이스 중 적어도 하나를 더 포함 할 수 있다. 도 2에 도시된 의료 영상 처리 장치에서는, 제어부가 심층 신경망을 통한 연산, 예를 들어, 학습 (learning)을 수행하였다. 이러한 의료 영상 처리 장치에 비하여, 도 3에 도시된 의료 영상 처리 장치 는 심층 신경망을 통한 연산을 별도의 프로세서(미도시)에서 수행할 수 있다. 구체적으로, 심층 신경망을 통한 연산을 수행하는 적어도 하나의 프로세서를 심층 신경망(Deep Neural Network) 프로세서라 칭할 수 있다. 심층 신경망 프로세서는 신경망(Neural Network)을 기반으로 하는 연산을 수행할 수 있다. 구체적으로, 심 층 신경망(DNN) 연산은 컨볼루션 신경망(CNN: Convolution Neural Network) 연산 등을 포함할 수 있다. 구체적으로, 심층 신경망 프로세서는 데이터 획득부에서 획득한 복수개의 실제 의료 영상들에 근거하 여 심층 신경망을 학습한다. 그리고, 학습의 결과 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신 경망을 획득한다. 그리고, 제1 인공 배양 신경망을 통하여 복수개의 실제 의료 영상에 포함되는 제1 의료 영상 의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에서의 제1 의료 영상에 포함되는 병변의 상태를 나타 내는 적어도 하나의 제2 의료 영상을 획득한다. 여기서, 제1 시점과 다른 적어도 하나의 시점은 사용자에 의해서 설정되거나, 제어부 또는 심층 신경망 프 로세서에 의해서 설정될 수 있을 것이다. 여기서, 심층 신경망 프로세서는 도 3에서 도시된 바와 같이 제어부와 구별되는 구비될 수 있다. 또 는, 심층 신경망 프로세서는 제어부에 포함되는 적어도 하나의 프로세서 중 적어도 하나가 될 수 있 다. 즉, 심층 신경망 프로세서는 제어부에 포함되는 형태로 구비될 수도 있을 것이다. 심층 신경망 프로세서의 구체적인 구성은 이하에서 도 4a 내지 도 4c를 참조하여 상세히 설명하도록 한다. 또한, 제어 부(220 또는 320) 및/또는 심층 신경망 프로세서에서 수행되는 심층 신경망 연산 동작은 이하에서 도 5 내 지 도 10을 참조하여 상세히 설명한다. 통신부는 유무선의 통신 네트워크를 통하여 전자 장치(미도시)와 데이터를 송수신할 수 있다. 구체적으로, 통신부는 제어부의 제어에 따라서 데이터의 송수신을 수행할 수 있다. 여기서, 통신부는 도 1에 도시된 통신부에 대응될 수 있다. 또한, 통신부와 유무선의 통신 네트워크로 연결되는 전자 장치(미 도시)는 도 1에 도시된 서버, 의료 장치, 또는 휴대용 단말이 될 수 있다. 또한, 전자 장치(미 도시)는 의료 영상 처리 장치와 독립적으로 형성되는 의료 영상 장치, 예를 들어, 도 1의 엑스선 장치 등 이 될 수 있다. 구체적으로, 통신부는 외부의 전자 장치(미도시)가 의료 영상 장치인 경우, 의료 영상 장치에서 획득된 실 제 의료 영상을 수신할 수 있다. 또한, 통신부는 외부의 전자 장치(미도시)로 적어도 하나의 제2 의료 영 상을 전송할 수 있다. 또한, 통신부는 제어부 또는 심층 신경망 프로세서에서 생성한 정보, 데 이터 및 영상 중 적어도 하나를 외부의 전자 장치(미도시)로 전송할 수 있다. 메모리는 의료 영상 처리 장치가 동작하기 위해서 필요한 적어도 하나의 프로그램 또는 적어도 하나 의 프로그램이 실행되기 위해서 필요한 적어도 하나의 명령어를 포함할 수 있다. 또한, 메모리는 전술한동작들을 수행하기 위한 적어도 하나의 프로세서들을 포함할 수 있다. 또한, 메모리는 의료 영상, 의료 영상과 관련된 정보, 환자에 대한 정보, 및 피검사자에 대한 정보 중 적 어도 하나를 저장할 수 있다. 또한, 메모리는 제어부 또는 심층 신경망 프로세서에서 생성한 정 보, 데이터 및 영상 중 적어도 하나를 저장할 수 있다. 또한, 메모리는 외부의 전자 장치(미도시)로부터 수신되는 영상, 데이터 및 정보 중 적어도 하나를 저장할 수 있을 것이다. 디스플레이는 의료 영상, 사용자 인터페이스 화면, 사용자 정보, 영상 처리 정보 등을 디스플레이 할 수 있다. 구체적으로, 디스플레이는 제어부의 제어에 따라서 생성된 사용자 인터페이스 화면을 디스플레 이 할 수 있다. 여기서, 사용자 인터페이스 화면은 의료 영상, 의료 영상과 관련된 정보, 및/또는 제어부 또는 심층 신경망 프로세서에서 생성한 정보 등을 포함할 수 있다. 본 개시의 실시예에서, 디스플레이는 실제 의료 영상, 제2 의료 영상, 및 진단 정보 중 적어도 하나를 포 함하는 사용자 인터페이스 화면을 디스플레이 할 수 잇다. 사용자 인터페이스는 사용자로부터 소정 데이터 또는 소정 명령을 입력받을 수 있다. 사용자 인터페이스 는 도 1의 서브 유저 인터페이스 및 입력부 중 적어도 하나에 대응될 수 있다. 또한, 사용자 인 터페이스는 디스플레이와 일체로 형성되는 터치 스크린으로 형성될 수 있다. 또 다른 예로, 사용자 인터페이스는 포인터, 마우스, 키보드 등의 사용자 입력 장치를 포함할 수 있다. 도 4a는 본 개시의 실시예에 따른 의료 영상 처리 장치 내에 포함되는 심층 신경망 프로세서를 나타내는 블록도 이다. 도 4a에 도시된 심층 신경망 프로세서는 도 3에 도시된 심층 신경망 프로세서와 동일 대응되므 로, 도 3에서와 중복되는 설명은 생략한다. 도 4a를 참조하면, 일부 실시예에 따른 심층 신경망 프로세서는 데이터 학습부 및 데이터 인식부 를 포함할 수 있다. 데이터 학습부는 전술한 심층 신경망을 통한 연산을 수행하기 위한 기준을 학습할 수 있다. 구체적으로, 데이터 학습부는 시간에 따른 병변의 변화를 예측하기 위하여 어떤 데이터를 이용할지, 데이터를 이용하여 상황을 어떻게 판단할 지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 데이터를 획득하 고, 획득된 데이터를 후술할 데이터 인식 모델에 적용함으로써, 상황 판단을 위한 기준을 학습할 수 있다. 여기 서, 데이터 학습부가 학습에 이용하는 데이터는 데이터 획득부에서 획득된 복수개의 실제 의료 영상 들이 될 수 있다. 데이터 인식부는 데이터에 기초한 상황을 판단할 수 있다. 데이터 인식부는 학습된 데이터 인식 모델, 예를 들어, 제1 인공 배양 신경망을 이용하여, 소정의 데이터로부터 상황을 인식할 수 있다. 구체적으로, 데이터 인식부는 학습에 의한 기 설정된 기준에 따라 소정의 데이터를 획득하고, 획득된 데이 터를 입력 값으로 하여 데이터 인식 모델을 이용함으로써, 소정의 데이터에 기초한 소정의 상황을 판단할 수 있 다. 또한, 획득된 데이터를 입력 값으로 하여 데이터 인식 모델에 의해 출력된 결과 값은, 데이터 인식 모델을 갱신하는데 이용될 수 있다. 본 개시의 실시예에서 데이터 인식부가 구축하는 데이터 인식 모델, 예를 들어, 심층 신경망을 학습 하여 생성한 제1 인공 배양 신경망 또는 제1 인공 배양 신경망을 학습하여 생성한 제2 인공 배양 신경망 등은 복수개의 실제 의료 영상들을 학습하여 복수개의 실제 의료 영상들 각각에 포함되는 병변의 시간에 따른 변화 특성을 추론하도록 모델링될 수 있다. 즉, 데이터 인식부가 구축하는 데이터 인식 모델은 소정 병변의 시 간에 따른 발전 또는 변화 형태, 발전 또는 변화되는 병변의 특성, 및/또는 소정 병변의 발전 또는 변화로 인하 여 발생하는 추가 질병의 형태 또는 특성 등을 추론한다. 구체적으로, 데이터 인식부는 제1 인공 배양 신경망을 통하여, 복수개의 실제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에서, 상기 제1 의료 영상에 포함되는 병변 의 상태를 나타내는 적어도 하나의 제2 의료 영상을 출력할 수 있다. 여기서, 데이터 인식 모델인 제1 인공 배 양 신경망으로 입력되는 데이터는 복수개의 실제 의료 영상에 포함되는 제1 의료 영상이 될 수 있으며, 제1 인 경 배양 신경망으로 출력되는 적어도 하나의 제2 의료 영상이 될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전 자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능 (AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 제어부에 포함되거나 독립적으로 형성되는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프 로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 학습부 및 데이터 인식부는 하나의 전자 장치인 의료 영상 처리 장치에 탑재될 수 도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식 부 중 하나는 의료 영상 처리 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부는 유선 또는 무선으로 상호 연여, 데이터 학습부가 구축한 모델 정보 를 데이터 인식부로 제공할 수도 있고, 데이터 인식부로 입력된 데이터가 추가 학습 데이터로서 데이 터 학습부로 제공될 수도 있다. 한편, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하 는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가 능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프 트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플 리케이션에 의해 제공될 수 있다. 도 4b는 심층 신경망 프로세서 내에 포함되는 데이터 학습부를 나타내는 블록도이다. 도 4b를 참조하면, 일부 실시예에 따른 데이터 학습부는 전처리부(410-2), 학습 데이터 선택부(410-3), 모 델 학습부(410-4) 및 모델 평가부(410-5)를 포함할 수 있다. 전처리부(410-2)는 상황 판단을 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 본 개시의 실시예에서, 전처리부(410-2)는 후술할 모델 학습부(410-4)가 상황 판단을 위한 학습을 위하여 획득된 데이터인 복수개의 실제 의료 영상들을 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부(410-3)는 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 데이터 는 모델 학습부(410-4)에 제공될 수 있다. 학습 데이터 선택부(410-3)는 상황 판단을 위한 기 설정된 기준에 따 라, 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부(410-3)는 후술 할 모델 학습부(410-4)에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 모델 학습부(410-4)는 학습 데이터에 기초하여 상황을 어떻게 판단할 지에 관한 기준을 학습할 수 있다. 또한, 모델 학습부(410-4)는 상황 판단을 위하여 어떤 학습 데이터를 이용해야 하는 지에 대한 기준을 학습할 수도 있 다. 본 개시의 실시예에서, 모델 학습부(410-4)는 복수개의 실제 의료 영상들을 학습하고, 학습된 데이터에 기초하 여 병변의 변화를 예측하는데 필요한 기준을 학습할 수 있다. 구체적으로, 모델 학습부(410-4)는 환자의 연령, 환자가 갖는 병변의 종류, 조직 특성, 또는 진행 정도(또는 진행 단계, 진행 병기 등), 환자가 갖는 병변이 존 재하는 신체 부위 등에 따라서 복수개의 실제 의료 영상들 각각에 포함되는 병변을 분류하고, 분류된 병변들의 특성을 학습하여 분류된 병변들 각각의 시간에 따른 진행 상태, 양상, 및 특성 등을 예측하는데 필요한 기준을 학습할 수 있다. 또한, 모델 학습부(410-4)는 상황 판단에 이용되는 데이터 인식 모델을 학습 데이터를 이용하여 학습시킬 수 있 다. 이 경우, 데이터 인식 모델은 미리 구축된 모델일 수 있다. 예를 들어, 데이터 인식 모델은 기본 학습 데이 터(예를 들어, 샘플 의료 영상 등)을 입력 받아 미리 구축된 모델일 수 있다. 데이터 인식 모델은, 인식 모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 데이터 인식 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 데이터 인식 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 또한, 데이터 인식 모델이 학습되면, 모델 학습부(410-4)는 학습된 데이터 인식 모델을 저장할 수 있다. 이 경 우, 모델 학습부(410-4)는 학습된 데이터 인식 모델을 데이터 인식부를 포함하는 전자 장치의 메모리에 저 장할 수 있다. 또는, 모델 학습부(410-4)는 학습된 데이터 인식 모델을 후술할 데이터 인식부를 포함하는 전자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부(410-4)는 학습된 데이터 인식 모델을 전자 장치와 유선 또는 무선 네트워크로 연결되는 서버의 메모리에 저장할 수도 있다. 이 경우, 학습된 데이터 인식 모델인 제1 인공 배양 신경망이 저장되는 메모리는, 예를 들면, 전자 장치의 적어 도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/ 또는 프로그램을 저장할 수도 있다. 프로그램은, 예를 들면, 커널, 미들웨어, 어플리케이션 프로그래밍 인터페 이스(API) 및/또는 어플리케이션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 모델 평가부(410-5)는 데이터 인식 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 인식 결과가 소정 기준인 소정의 정확도 또는 소정의 신뢰도를 만족하지 못하는 경우, 모델 학습부(410-4)로 하여금 다시 학 습하도록 할 수 있다. 이 경우, 평가 데이터는 데이터 인식 모델을 평가하기 위한 기 설정된 데이터일 수 있다. 예를 들어, 모델 평가부(410-5)는 평가 데이터에 대한 학습된 데이터 인식 모델의 인식 결과 중에서, 인식 결과 가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 데이터 인식 모델이 총 1000개의 평가 데이터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 인식 결과를 출력하는 경우, 모델 평 가부(410-5)는 학습된 데이터 인식 모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 데이터 인식 모델이 복수 개가 존재하는 경우, 모델 평가부(410-5)는 각각의 학습된 동영상 인식 모델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 데이터 인식 모델로서 결정할 수 있다. 한편, 데이터 학습부 내의 전처리부(410-2), 학습 데이터 선택부(410-3), 모델 학습부(410-4) 및 모델 평 가부(410-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 또한, 전처리부(410-2), 학습 데이터 선택부(410-3), 모델 학습부(410-4) 및 모델 평가부(410-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 전처리부(410-2), 학습 데이터 선택부(410-3), 모델 학습부(410-4) 및 모델 평가부(410-5) 중 일부는 전자 장치에 포함되고, 나머 지 일부는 서버에 포함될 수 있다. 도 4c는 심층 신경망 프로세서 내에 포함되는 데이터 인식부를 나타내는 블록도이다. 도 4c를 참조하면, 일부 실시예에 따른 데이터 인식부는 데이터 획득부(420-1), 전처리부(420-2), 인식 데 이터 선택부(420-3), 인식 결과 제공부(420-4) 및 모델 갱신부(420-5)를 포함할 수 있다. 데이터 획득부(420-1)는 상황 판단에 필요한 데이터를 획득할 수 있으며, 전처리부(420-2)는 상황 판단을 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리부(420-2)는 후술할 인식 결과 제공부(420-4)가 상황 판단을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 인식 데이터 선택부(420-3)는 전처리된 데이터 중에서 상황 판단에 필요한 데이터를 선택할 수 있다. 선택된 데 이터는 인식 결과 제공부(420-4)에게 제공될 수 있다. 인식 데이터 선택부(420-3)는 상황 판단을 위한 기 설정 된 기준에 따라, 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 인식 데이터 선택부(420- 3)는 후술할 모델 학습부(410-4)에 의한 학습에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 인식 결과 제공부(420-4)는 선택된 데이터를 데이터 인식 모델에 적용하여 상황을 판단할 수 있다. 인식 결과 제공부(420-4)는 데이터의 인식 목적에 따른 인식 결과를 제공할 수 있다. 본 개시의 실시예에서, 데이터 획득부(420-1)는 데이터 인식 모델인 제1 인공 배양 신경망으로 입력된 복수개의 실제 의료 영상들 중 적어도 하나, 예를 들어, 제1 의료 영상을 수신할 수 있다. 그리고 전처리부(420-2)는 수 신된 제1 의료 영상을 전처리할 수 있다. 계속하여, 인식 데이터 선택부(420-3)는 전처리된 데이터인 제1 의료 영상을 선택할 수 있다. 그리고, 인식 결과 제공부(420-4)는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적 어도 하나의 시점 각각에서, 제1 의료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 생성하여 제공할 수 있다. 예를 들어, 제1 의료 영상이 제1 시점에 획득된 실제 의료 영상인 경우, 제1 의료 영상은 제1 시점에서의 해당 병변의 상태를 이미징하고 있다. 제1 인공 배양 신경망은 시간에 따른 병변의 변화를 예측하는 데이터 인식 모 델이므로, 실제 의료 영상이 획득된 시점인 제1 시점과 다른 적어도 하나의 시점들, 예를 들어, 제1 시점으로 1 개월 및 3개월 경과 후의 시점들 각각에서 해당 병변의 상태를 나타내는 2개의 의료 영상을 생성할 수 있다. 모델 갱신부(420-5)는 인식 결과 제공부(420-4)에 의해 제공되는 인식 결과에 대한 평가에 기초하여, 데이터 인 식 모델이 갱신되도록 할 수 있다. 예를 들어, 모델 갱신부(420-5)는 인식 결과 제공부(420-4)에 의해 제공되는 인식 결과를 모델 학습부(410-4)에게 제공함으로써, 모델 학습부(410-4)가 데이터 인식 모델을 갱신하도록 할 수 있다. 본 개시의 실시예에서, 모델 갱신부(420-5)는 실제 의료 영상이 추가적으로 획득될 때마다, 데이터 인식 모델인 제1 인공 배양 신경망을 학습하여, 제1 인공 배양 신경망이 갱신되도록 할 수 있다. 또한, 모델 갱신부(420- 5)는 제1 인공 배양 신경망을 통한 연산을 수행하여 획득한 적어도 하나의 제2 의료 영상으로 제1 인공 배양 신 경망을 학습하여, 제1 인공 배양 신경망을 수정 또는 갱신하여 제2 인공 배양 신경망을 획득할 수도 있을 것이다. 한편, 데이터 인식부 내의 데이터 획득부(420-1), 전처리부(420-2), 인식 데이터 선택부(420-3), 인식 결 과 제공부(420-4) 및 모델 갱신부(420-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 또한, 데이터 획득부(420-1), 전처리부(420-2), 인식 데이터 선택부(420-3), 인식 결과 제공부(420-4) 및 모델 갱신부(420-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(420-1), 전처리부(420-2), 인식 데이터 선택부(420-3), 인식 결과 제공부(420-4) 및 모델 갱신부(420-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 이하에서는 도 5 내지 도 10을 참조하여, 심층 신경망을 통한 연산 동작을 상세히 설명한다. 또한, 심층 신경망 을 통한 연산 동작을 설명하는데 있어서, 도 3에 도시된 의료 영상 처리 장치를 예를 들어 참조하도록 하 겠다. 도 5는 본 개시의 실시예에 따른 학습 동작을 설명하기 위한 도면이다. 본 개시의 실시예에 따른 의료 영상 처리 장치는 심층 신경망을 통한 연산을 수행한다. 구체적으로, 의료 영상 처리 장치(200 또는 300)는 제어부(220 또는 320) 또는 심층 신경망 프로세서를 통하여 심층 신경망 을 학습할 수 있다. 그리고, 학습된 심층 신경망을 통한 추론 연산을 수행할 수 있다. 이하에서는, 심층 신경망 프로세서가 심층 신경망을 통한 연산을 수행하는 경우를 예로 들어 설명한다. 도 5를 참조하면, 의료 영상 처리 장치는 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서, 시간에 따른 병변의 변화를 예측하기 위한 심층 신경망인 제1 인공 배양 신경망을 획득할 수 있다. 제1 인 공 배양 신경망은 복수개의 실제 의료 영상들에 근거하여 훈련된 심층 신경망이므로, 이하에서는, 520 블록에 도시된 신경망을 '심층 신경망'이라 칭할 수도 있으며, '제1 인공 배양 신경망'이라 칭할 수도 있을 것이다. 도 5를 참조하면, 심층 신경망 프로세서는, 입력 계층, 숨은 계층(hidden layer) 및 출력 계층을 포함하는 심층 신경망을 통한 연산을 수행할 수 있다. 여기서, 숨은 충은 복수개의 계층들, 예를 들어, 숨은 제1 계 층(hidden layer1), 숨은 제2 계층(hidden layer2), 및 숨은 제3 계층(hidden layer3),을 포함할 수 있다. 도 5를 참조하면, 심층 신경망은 입력 계층, 숨은 계층(hidden layer) 및 출력 계층을 포 함한다. 심층 신경망는 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습하여, 시간에 따른 병변의 변화 를 예측하기 위한 제1 인공 배양 신경망을 구축할 수 있다. 구체적으로, 심층 신경망은 입력 데이터인 복수개의 실제 의료 영상에 포함되는 정보를 분석하여 복수개의 실제 의료 영상들 각각에 포함되는 병변을 분석하여 병변의 특성을 나타내는 정보를 획득할 수 있다. 그리고, 획득된 정보를 학습하여 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신경망을 구축할 수 있다. 예를 들어, 심층 신경망은 입력 데이터가 엑스선 영상일 때, 엑스선 영상에 포함되는 영상 객체 인 대상체를 분석한 결과 데이터를 출력 데이터로써 출력할 수 있다. 심층 신경망는 복수개의 실제 의료 영상들 각각을 학습하나, 도 5에서는 복수개의 실제 의료 영상 중 하나인 엑스선 영상을 학습하는 경우를 예로 들어 도시하였다. 심층 신경망을 형성하는 복수개의 계층들은 데이터를 수신하는 복수개의 노드(node)(예를 들어, 531)들을 포함할 수 있다. 그리고, 인접한 두 개의 계층들은 도시된 바와 같이 복수개의 엣지(edge)(예를 들어, 536)들로연결된다. 각각의 노드들은 대응되는 가중치값을 가지고 있어서, 심층 신경망은 입력된 신호와 가중치 값 을 연산, 예를 들어, 곱하기 연산한 값에 근거하여, 출력 데이터를 획득할 수 있다. 도 5에 도시된 실시예를 참조하면, 입력 계층은 대상체인 흉부를 촬영하여 획득한 엑스선 영상를 입 력 받는다. 여기서, 엑스선 영상은 우측 가슴에 병변이 발생한 대상체를 소정 시점인 제1 시점에서 촬영하여 획득한 영상이 될 수 있다. 또한, 도 5를 참조하면 심층 신경망은 예시적으로 입력 계층과 제1 숨은 계층(HIDDEN LAYER1) 간에 형성되는 제1 계층(Layer 1), 제1 숨은 계층(HIDDEN LAYER1)과 제2 숨은 계층(HIDDEN LAYER2) 간에 형성 되는 제2 계층(Layer 2), 및 제2 숨은 계층(HIDDEN LAYER2)과 제3 숨은 계층(HIDDEN LAYER3) 간에 형성되 는 제3 계층(Layer 3), 및 제3 숨은 계층(HIDDEN LAYER3)과 출력 계층(OUTPUT LAYER 간에 형성되는 제4 계층(Layer 4)으로 형성될 수 있다. 심층 신경망의 입력 계층에 포함되는 복수개의 노드들은 엑스선 영상에 대응되는 복수개의 데이 터들을 수신한다. 여기서, 복수개의 데이터들은 엑스선 영상은 분할하는 필터 처리를 하여 생성된 복수개 의 부분 영상들이 될 수 있다. 그리고, 숨은 계층에 포함되는 복수개의 계층들에서의 연산을 통하여, 출력 계층에서는 엑스선 영상 에 대응되는 출력 데이터(570, 580)를 출력할 수 있다. 도시된 예시에서, 심층 신경망는 입력된 엑스 선 영상에 포함되는 병변의 특성을 분석한 결과를 획득하기 위한 연산을 수행하므로, 출력 계층은 입 력된 엑스선 영상에서 검출된 병변을 표시한 영상 및/또는 검출된 병변을 분석한 데이터 를 포함할 수 있다. 여기서, 데이터는 검출된 병변의 특성을 나타내는 정보로, 병변의 종류, 심 각도, 질병의 진행 정도, 크기, 위치 등을 포함할 수 있다. 또한, 데이터는 환자 별로 분류되어 획득될 수 도 있다. 예를 들어, 환자의 성별, 나이, 가족력 등에 따라서 분류되어 획득될 수 있다. 또한, 심층 신경망을 통하여 출력된 출력 데이터의 정확도를 높이기 위해서, 출력 계층에서 입력 계 층 방향으로 학습(learning)을 수행하며 출력 데이터의 정확도가 높아지도록 가중치값들을 수정할 수 있다. 따라서, 심층 신경망는 복수개의 서로 다른 실제 의료 영상들을 이용하여 심층 학습(Deep learnin g)을 수행하여 엑스선 영상에 포함되는 병변의 특성을 검출하는 방향으로, 각 노드들의 가중치값을 수정할 수 있다. 계속하여, 심층 신경망은 복수개의 실제 의료 영상들을 학습하여 획득된 병변 특성에 근거하여, 병변의 시 간에 따른 변화를 예측하기 위한 연산을 자동으로 수행할 수 있는 제1 인공 배양 신경망으로 갱신될 수 있다. 그에 따라서, 심층 심경망, 예를 들어, 제1 인공 배양 신경망은 복수개의 실제 의료 영상에 포함되는 제1 시점에서 획득된 제1 의료 영상을 입력받고, 제1 의료 영상에 포함되는 병변의 변화를 예측한 결과인 제1 시점 과 다른 적어도 하나의 시점 각각에서 병변의 변화된 상태를 나타내는 적어도 하나의 제2 의료 영상을 출력할 수 있다. 또한, 심층 신경망은 복수개의 실제 의료 영상들 각각에 대응되는 적어도 하나의 제2 의료 영상 을 생성할 수 있다. 또한, 심층 신경망, 구체적으로, 제1 인공 배양 신경망은 생성된 복수개의 제2 의료 영상들 각각을 학습하 여, 출력되는 데이터의 정확도가 높아지는 방향으로 심층 신경망을 학습할 수 있다. 즉, 심층 신경망(52 0)는 인공 의료 영상인 복수개의 제2 의료 영상들 각각을 이용한 학습을 통하여 심층 신경망을 형성하는 복수개의 노드들에 대응되는 가중치 값들을 조절 또는 수정하여, 갱신된 심층 신경망인 제2 인공 배양 신 경망을 구축할 수 있다. 심층 신경망이 수행하는 추론 연산의 정확도를 높이기 위해서는, 다양한 학습 데이터들이 요구된다. 즉, 다양한 학습 데이터를 학습하여 심층 신경망을 훈련시켜야, 새로운 입력 데이터에 대한 추론 결과의 정확 도가 높아질 수 있다. 전술한 바와 같이, 개시된 실시예에서는 심층 신경망을 통하여, 실제 환자들로부터 획득된 실제 의료 영상 을 학습함에 따라서 실제 의료 영상이 획득된 시점과 다른 다양한 시점들에서의 병변의 상태를 나타내는 복수의 제2 의료 영상을 획득할 수 있다. 그리고, 획득된 복수의 제2 의료 영상을 이용하여 다시 심층 신경망을 학습시킴으로써, 학습 데이터의 다양성을 증가시킬 수 있다. 예를 들어, 실제 의료 영상이 1000장인 경우, 실제 의료 영상들 각각에서 4개의 서로 다른 시점들에서 병변의 진행 상태를 나타내는 4개의 제2 의료 영상을 획득할 경우, 총 4000장의 서로 다른 인공 의료 영상들을 획득할 수 있게 된다. 그리고, 4000장의 서로 다른 인공 의료 영상들을 이용하여 심층 신경망을 학습 및 훈련시킬 경우, 심층 신경망 연산의 정확도를 더욱더 높아질 수 있다. 그에 따라서, 의료 영상 데이터 베이스의 한계성을 극복하여 학습 데이터를 다양화시키고 학습 데이터의 양을 증가시킴으로써, 보다 정확도 높은 심층 신경망을 구축할 수 있게 되는 효과가 있다. 또한, 적어도 하나의 제2 의료 영상을 참조하여, 의사 등의 사용자는 실제 촬영된 병변의 시간에 따른 변화를 용이하게 파악할 수 있다. 즉, 해당 병변의 발생, 발전, 및/또는 변화 가능성을 용이하게 파악 및 예측할 수 있 다. 도 6은 본 개시의 실시예에 따른 의료 영상 처리 장치에서 이용되는 의료 영상들을 나타내는 도면이다. 도 5에서는 심층 신경망의 학습에 이용되는 실제 의료 영상이 대상체를 전체적으로 나타내는 의료 영상인 경우를 예로 들어 도시하였다. 또한, 심층 신경망의 학습에 이용되는 실제 의료 영상은 도 6에 도시된 바와 같은 복수개의 병변 영상 이 될 수 있다. 구체적으로, 복수개의 병변 영상 각각은 실제 의료 영상에서 병변이 발생한 부분만이 추출된 영상을 나타낸다. 심층 신경망은 복수개의 병변 영상을 학습할 경우, 복수개의 병변 영상 각각의 추출 동작을 생 략하고, 바로 복수개의 병변 영상 각각의 특성을 분석 및 파악할 수 있을 것이다. 도 7은 본 개시의 실시예에 따른 제2 의료 영상의 생성 동작을 설명하기 위한 일 도면이다. 도 7을 참조하면, 본 개시의 실시예에 따른 의료 영상 처리 장치는 도 6에서 설명한 병변 영상을 실 제 의료 영상으로 입력받고, 병변 영상에 대응되는 적어도 하나의 제2 의료 영상들인 적어도 하나의 인공 병변 영상(721, 722, 723, 724)를 획득할 수 있다. 구체적으로, 의료 영상 처리 장치는 제1 시점에서 병변을 이미징한 실제 의료 영상인 제1 병변 영상 을 심층 신경망으로 입력하고, 심층 신경망을 통한 연산 결과 제1 시점과 다른 복수개의 시점들에 대 응되는 복수개의 인공 병변 영상(721, 722, 723, 724)을 획득할 수 있다. 예를 들어, 제1 병변 영상이 현 재 시점에서 대상체를 의료 영상 촬영하여 획득된 초기 병변 영상인 경우, 병변이 후속되는 시간에서의 진행 상 태들을 나타내는 4개의 인공 병변 영상(721, 722, 723, 724)을 획득할 수 있다. 구체적으로, 심층 신경망 에서 출력되는 인공 의료 영상은 병변 영상에 포함되는 병변이 1기로 진행된 경우를 나타내는 배양 병변 1기 영상, 병변이 2기로 진행된 경우를 나타내는 배양 병변 2기 영상, 병변이 3기로 진행된 경우를 나타내는 배양 병변 3기 영상, 및 병변이 4기로 진행된 경우를 나타내는 배양 병변 4 기 영상을 포함할 수 있다. 따라서, 본 개시의 실시예에 따른 의료 영상 장치는 현재 시점에서 검출된 병변의 후속하는 시점들에서의 병변의 변화 상태를 심층 신경망에서 출력되는 복수개의 인공 병변 영상(721, 722, 723, 724)을 통하여 용 이하고 정확하게 파악 및 예측할 수 있다. 도 8a는 본 개시의 실시예에서 생성된 제2 의료 영상들을의 일 예를 나타내는 도면이다. 또한, 의료 영상 처리 장치에서 이용되는 심층 신경망은 대상체를 전체적으로 나타내는 실제 의료 영 상으로 입력받고, 실제 의료 영상에 대응되는 적어도 하나의 제2 의료 영상들인 적어도 하나의 인공 의료 영상(821, 822, 823, 824)를 획득할 수 있다. 도 8a 에 도시된 예에 있어서, 심층 신경망에서 출력되 는 적어도 하나의 인공 의료 영상은 병변 1기 영상, 병변 2기 영상, 병변 3기 영상 및 병변 4기 영상를 포함할 수 있다. 도 8b는 본 개시의 실시예에서 생성된 제2 의료 영상의 다른 예를 나타내는 도면이다. 도 8b 를 참조하면, 도 8a 에서 설명한 제2 의료 영상은 의료 영상에 도 6에서 설명한 인공 병변 영상들에 포함되는 인공 병변을 부가함으로써 획득될 수도 있을 것이다. 여기서, 의료 영상는 병변이 발생하지 않은 일반 의료 영상이 될 수 있다. 또는, 의료 영상는 도 8a에서 설명한 실제 의료 영상이 될 수도 있을 것이다. 예를 들어, 의료 영상에 1기의 병변을 중첩 또는 부가하여, 병변 1기 영상를 생성할 수 있을 것이다. 도 9는 본 개시의 실시예에 따른 제2 의료 영상의 생성 동작을 설명하기 위한 일 도면이다. 도 9를 참조하면, 의료 영상 처리 장치는 심층 신경망을 통한 연산을 통하여, 복수개의 실제 병변 영 상들 각각에 대응되는 복수개의 인공 병변 영상(910, 920, 930, 940)을 생성할 수 있다. 예를 들어, 의료 영상 처리 장치는 심층 신경망을 통한 연산을 수행하여, 제1 시점에서 획득한 실제 병변 영상을 심층 신경망인 제1 인공 배양 신경망에 입력하고, 심층 신경망을 통한 연산을 수행 하여, 실제 병변 영상에 포함되는 병변의 제1 시점과 다른 적어도 하나의 시점에서 상태 또는 특성을 나타 내는 적어도 하나의 인공 병변 영상(911, 921, 931, 941)을 출력할 수 있다. 여기서, 제1 시점에서의 해당 병변 이 병변 0 기에 대응할 때, 심층 신경망에서 출력되는 4개의 인공 병변 영상들(911, 921, 931, 941) 각각 은 병변 1기에서의 해당 병변을 나타내 영상, 병변 2기에서의 해당 병변을 나타내는 영상, 병변 3기 에서의 해당 병변을 나타내는 영상 및 병변 4기에서의 해당 병변을 나타내는 영상이 될 수 있다. 또 한, 심층 신경망을 해당 병변의 시간에 따른 발전 양상 또는 변화 상태의 특성을 나타내는 정보를 출력할 수도 있을 것이다. 도 10은 본 개시의 실시예에 따른 진단 정보의 생성 동작을 설명하기 위한 도면이다. 심층 신경망이 수행하는 추론 연산의 정확도를 높이기 위해서는, 다양한 학습 데이터들이 요구된다. 즉, 다양한 학습 데이터를 학습하여 심층 신경망을 훈련시켜야, 새로운 입력 데이터에 대한 추론 결과의 정확 도가 높아질 수 있다. 그에 따라서, 본 개시의 실시예에 따른 의료 영상 처리 장치는 제1 인공 배양 신경망을 통하여 획득된 복 수개의 제2 의료 영상을 학습할 수 있다. 또한, 제1 인공 배양 신경망을 통하여 의료 영상 처리 장치의 데 이터 획득부가 획득한 복수개의 실제 의료 영상을 학습할 수 있다. 즉, 의료 영상 처리 장치는 제1 인공 배양 신경망의 연산 정확도를 향상시키기 위해서 복수개의 실제 의료 영상의 학습에 추가하여, 더 많은 입 력 데이터에 기초한 학습을 수행할 수 있다. 그리고, 학습의 결과에 근거하여 상기 제1 인공 배양 신경망을 형 성하는 복수개의 노드들의 가중치 값들을 조절함으로써, 제1 인공 배양 신경망을 갱신할 수 있다. 여기서, 갱신 된 제1 인공 배양 신경망을 제2 인공 배양 신경망이라 칭할 수 있다. 인공적으로 생성된 의료 영상인 복수개의 제2 의료 영상들을 이용하여, 제1 인공 배양 신경망을 학습하면, 제1 인공 배양 신경망의 연산 정확도를 향상시킬 수 있다. 따라서, 제2 인공 배양 신경망은 소정 병변의 특성, 시간 에 따른 변화 양상 및 형태, 시간에 따른 소정 병변의 특성 등을 더욱 정확하게 추론할 수 있다. 도 10을 참조하면, 의료 영상 처리 장치는 적어도 하나의 제2 의료 영상을 소정 병변의 시간에 따른 변화 상태을 추론하기 위해서 심층 신경망을 학습하기 위한 학습 데이터 베이스로 이용할 수 있다. 도 10에서는 학습에 이용되는 복수개의 실제 의료 영상을 '질병 영상'이라 표시하고, 학습에 이용되는 인공 의료 영상을 '인 공 배양 학습 DB'라고 표시하였다. 그에 따라서, 의료 영상 처리 장치는 질병 영상 및 인공 배양 학습 데 이터 베이스를 이용하여 심층 신경망을 학습할 수 있다. 일반적인 심층 신경망을 학습하기 위해서는 실제 의료 영상이 이용되므로 학습 데이터 베이스의 한계성이 존재 한다. 그러나, 본 개시의 실시예에서는 자체적으로 획득하는 인공 의료 영상을 학습 데이터 베이스에 포함시킴 으로써, 학습 데이터 베이스의 범위를 확대함으로써 학습 데이터 베이스의 한계성을 극복할 수 있다. 그에 따라 서, 심층 신경망의 연산 정확도를 증가시킬 수 있게 된다. 본 개시의 실시예에 따른 의료 영상 처리 장치는 제2 인공 배양 신경망을 통하여 피검사자의 대상체를 스 캔하여 획득한 제3 의료 영상을 분석하고, 상기 분석의 결과로 피검사자의 대상체에 대응되는 진단 정보를 획득 할 수 있다. 여기서, 제3 의료 영상은 도 10에 도시된 검사 영상을 나타낸다. 구체적으로 도 10을 참조하면, 의료 영상 처리 장치는 실제 의료 영상 및 인공 의료 영상을 학습하 여 구축한 데이터 인식 모델인 제2 인공 배양 신경망에 검사 영상을 입력하여 연산을 수행할 수 있다. 의 료 영상 처리 장치는 검사 영상의 진단에 필요한 진단 정보를 획득할 수 있다. 여기서, 진단 정보는 대상체에 발생한 질병의 종류, 질병의 특성, 질병의 시간에 따른 변화 또는 발전 가능성, 질병으로 인하여 발생 가능한 추가 질병의 종류, 추가 질병의 특성, 추가 질병의 변화 또는 발전 가능성 중 적 어도 하나를 포함할 수 있다. 도 10에서는 생성되는 진단 정보로, 진단 영상을 예로 들어 도시하였다. 구체적으로, 진단 영상은 검사 영상을 분석하여, 검사 영상에서 이미징된 대상체에 존재하는 비정상 부위를 검출하고, 검출 된 비정상 부위의 특성을 분석한 결과를 진단 영상 내에 표시할 수 있다. 여기서, 비정상 부위는 정상이 아닌 모든 신체 부위를 지칭하는 것으로, 병변 또는 병변 가능성이 존재하는 모든 신체 부위를 포함할 수 있다. 예를 들어, 진단 영상 내에 5개의 비정상 부위들(1061, 1062, 1063, 1064, 1065)이 검출된 경우, 비정상 부위들(1061, 1062, 1063, 1064, 1065) 각각에 대응되는 분석 정보를 해당 비정상 부위에 표시할 수 있다. 예를 들어, 검출된 일 비정상 부위를 분석한 결과, 비정상 부위가 결절(nodule)일 가능성이 높은 경우, 결절일 가능성인 'Nodule: 89%' 및 검출된 비정상 부위를 확대한 영상을 도시된 바와 같이 진단 영 상 상에 중첩하여 표시할 수 있다. 또한, 또 다른 비정상 부위가 결핵일 가능성이 높은 경우, 결핵 일 가능성인 'TB: 75%' 및 검출된 비정상 부위를 확대한 영상를 도시된 바와 같이 진단 영상 상에 중첩하여 표시할 수 있다. 또한, 의료 영상 처리 장치의 디스플레이는 제어부의 제어에 따라서 제2 인공 배양 신경망의 연 산 결과 출력되는 진단 정보, 예를 들어, 진단 영상를 디스플레이 할 수 있다. 또한, 의료 영상 처리 장치의 제어부는 제2 인공 배양 신경망의 연산 결과 출력되는 진단 정보, 예를 들어, 진단 영상를 통신부를 통하여 외부의 전자 장치(미도시)로 전송할 수 있다. 예를 들어, 통신 부를 통하여 연결되는 외부의 전자 장치가 PACS 서버(미도시) 또는 PACS 뷰어(미도시)인 경우, 제어부 는 획득된 진단 정보가 PACS 뷰어로 전송되도록 제어할 수 있다. 그에 따라서, 의사는 PACS 뷰어(미도시) 를 통하여 디스플레이되는 진단 정보를 이용하여, 대상체를 더욱 용이하고 빠르고 진단할 수 있을 것이다. 전술한 바와 같이, 본 개시의 실시예에 따른 의료 영상 처리 장치는 심층 신경망을 통한 연산의 결과 병변을 인공적으로 배양하여 시간에 따른 변화를 학습 및/또는 예측함으로써, 피검사자의 대상체에 발병한 병변 또는 질병을 더욱 정확하게 진단 및 예측할 수 있다. 도 11은 본 개시의 일 실시예에 따른 의료 영상 처리 방법을 나타내는 플로우차트이다. 본 개시의 실시예에 따른 의료 영상 처리 방법은 전술한 본 개시의 실시예에 따른 의료 영상 처리 장치 (200 또는 300)를 통하여 수행될 수 있다. 따라서, 의료 영상 처리 방법의 각 단계 동작은 의료 영상 처 리 장치(200 또는 300)의 각 구성을 통하여 수행될 수 있으며, 의료 영상 처리 방법은 전술한 의료 영상 처리 장치(200 또는 300)와 동일한 구성상 특징을 포함할 수 있다. 따라서, 의료 영상 처리 방법을 설명 하는데 있어서, 도 1 내지 도 10에서와 중복되는 설명은 생략한다. 이하에서는, 도 3에서 설명한 의료 영상 처리 장치를 참조하여, 의료 영상 처리 방법을 설명한다. 도 11을 참조하면, 본 개시의 실시예에 따른 의료 영상 처리 방법은 복수의 환자들에 대응하며 병변을 포 함하는 복수개의 실제 의료 영상을 획득한다(S1110). S1110 단계는 데이터 획득부에서 수행될 수 있다. 계속하여, S1110 단계에서 획득된 복수개의 실제 의료 영상들에 근거하여 심층 신경망을 학습해서, 시간에 따른 병변의 변화를 예측하기 위한 제1 인공 배양 신경망을 획득할 수 있다(S1120). S1120 단계는 제어부에서 수행될 수 있다. 또는, S1120 단계는 심층 신경망 프로세서에서 자체적으로 수행될 수 있다. 또는, S1120 단계는 제어부의 제어에 따라서 심층 신경망 프로세서에서 수행될 수 있다. 계속하여, 본 개시의 실시예에 따른 의료 영상 처리 방법은 제1 인공 배양 신경망을 통하여, 복수개의 실 제 의료 영상에 포함되는 제1 의료 영상의 획득 시점인 제1 시점과 다른 적어도 하나의 시점 각각에서의 제1 의 료 영상에 포함되는 병변의 상태를 나타내는 적어도 하나의 제2 의료 영상을 획득한다(S1130). S1130 단계는 제 어부에서 수행될 수 있다. 또는, S1130 단계는 심층 신경망 프로세서에서 자체적으로 수행될 수 있다. 또는, S1130 단계는 제어부의 제어에 따라서 심층 신경망 프로세서에서 수행될 수 있다. 도 12는 본 개시의 다른 실시예에 따른 의료 영상 처리 방법을 나타내는 플로우차트이다. 도 12에 도시된 의료 영상 처리 방법에 있어서 S1210, S1220 및 S1230 단계의 동작은 각각 도 11에 도시된 의료 영상 처리 방 법에 있어서 S1110, S1120 및 S1130 단계의 동작에 대응될 수 있다. 그러므로, 의료 영상 처리 방법 을 설명하는데 있어서, 의료 영상 처리 방법 및 도 1 내지 도 10에서와 중복되는 설명은 생략한다. 의료 영상 처리 방법은 의료 영상 처리 방법에 비하여 S1240 단계 및 S1250 단계를 더 포함할 수 있다. 도 12를 참조하면, 의료 영상 처리 방법은 S1230 단계에 후속하여, 적어도 하나의 제2 의료 영상을 학습 하여 제2 인공 배양 신경망을 구축할 수 있다(S1240). 여기서, S1240 단계는 제어부에서 수행될 수 있다. 또는, S1240 단계는 심층 신경망 프로세서에서 자체적으로 수행될 수 있다. 또는, S1240 단계는 제어부 의 제어에 따라서 심층 신경망 프로세서에서 수행될 수 있다. 구체적으로, 의료 영상 처리 방법은 적어도 하나의 제2 의료 영상에 근거하여 제1 인공 배양 신경망을 학 습하여, 제1 인공 배양 신경망을 형성하는 복수개의 노드들의 가중치 값들을 조절할 수 있다(S1241). 그리고, 조절된 가중치 값들을 포함하는 제2 인공 배양 신경망을 획득할 수 있다(S1241). 즉, 제2 인공 배양 신경망은 제1 인공 배양 신경망을 수정 또는 갱신하여 획득되는 신경망이 될 수 있다. 계속하여, 의료 영상 처리 방법은 제2 인공 배양 신경망을 통하여 피검사자의 대상체에 대응되는 진단 정 보를 획득할 수 있다(S1250). 여기서, S1250 단계는 제어부에서 수행될 수 있다. 또는, S1250 단계는 심층 신경망 프로세서에서 자체적으로 수행될 수 있다. 또는, S1250 단계는 제어부의 제어에 따라서 심층 신경망 프로세서에서 수행될 수 있다. 구체적으로, 구축된 제2 인공 배양 신경망을 통하여 피검사자의 대상체를 스캔하여 획득한 제3 의료 영상, 예를 들어, 검사 영상을 분석하고, 상기 분석의 결과로 피검사자의 대상체에 대응되는 진단 정보, 예를 들어, 진단 영상을 획득할 수 있다(S1250). 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어 및 데이터를 저장하는 컴퓨터로 읽을 수 있는 기록 매체의 형태로 구현될 수 있다. 상기 명령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실 행되었을 때, 소정의 프로그램 모듈을 생성하여 소정의 동작을 수행할 수 있다. 또한, 상기 명령어는 프로세서 에 의해 실행되었을 때, 개시된 실시예들의 소정의 동작들을 수행할 수 있다."}
{"patent_id": "10-2017-0140317", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 발명이 속하는 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 발명이 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2017-0140317", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 엑스선 장치의 구성을 도시하는 외관도이다. 도 2는 본 개시의 실시예에 따른 의료 영상 처리 장치를 나타내는 블록도이다. 도 3은 본 개시의 실시예에 따른 의료 영상 처리 장치를 나타내는 블록도이다. 도 4a는 본 개시의 실시예에 따른 의료 영상 처리 장치 내에 포함되는 심층 신경망 프로세서를 나타내는 블록도 이다. 도 4b는 심층 신경망 프로세서 내에 포함되는 데이터 학습부를 나타내는 블록도이다. 도 4c는 심층 신경망 프로세서 내에 포함되는 데이터 인식부를 나타내는 블록도이다. 도 5는 본 개시의 실시예에 따른 학습 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 실시예에 따른 의료 영상 처리 장치에서 이용되는 의료 영상들을 나타내는 도면이다. 도 7은 본 개시의 실시예에 따른 제2 의료 영상의 생성 동작을 설명하기 위한 일 도면이다. 도 8a는 본 개시의 실시예에서 생성된 제2 의료 영상들을의 일 예를 나타내는 도면이다. 도 8b는 본 개시의 실시예에서 생성된 제2 의료 영상의 다른 예를 나타내는 도면이다. 도 9는 본 개시의 실시예에 따른 제2 의료 영상의 생성 동작을 설명하기 위한 일 도면이다. 도 10은 본 개시의 실시예에 따른 진단 정보의 생성 동작을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시예에 따른 의료 영상 처리 방법을 나타내는 플로우차트이다. 도 12는 본 개시의 다른 실시예에 따른 의료 영상 처리 방법을 나타내는 플로우차트이다."}
