{"patent_id": "10-2025-0035537", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0047938", "출원번호": "10-2025-0035537", "발명의 명칭": "정보 예측 방법 및 자율주행 모델의 훈련 방법, 장치, 컴퓨터 프로그램", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "공, 시"}}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "정보 예측 방법으로서, 차량 내의 센서가 수집한 영상 데이터 및 상기 차량의 운전 데이터를 포함하는 감지 데이터를 취득하며; 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻으며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것을 포함하는 정보 예측 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 영상 토큰 시퀀스는 상기 영상 데이터의 이산적인 특징이며; 상기 정보 예측 방법은, 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1특징 벡터를 얻는 것을 또한 포함하며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기예측 토큰 시퀀스 및 상기 제어 정보를 생성하는 것을 포함하는, 정보 예측 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 운전 데이터는 상기 차량의 주행 파라미터 및 상기 차량의 네비게이션 데이터를 포함하며; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻는 것은, 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는제2 특징 벡터를 얻으며; 다층 퍼셉트론을 이용하여 상기 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를얻는 것을 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 정보 예측 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함하며; 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는제2 특징 벡터를 얻는 것은, 상기 적어도 2개의 목표 지점의 위치에 기초하여, 상기 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스공개특허 10-2025-0047938-3-크 영상을 생성하며; 상기 제2 컨볼루션 네트워크를 이용하여 상기 마스크 영상을 부호화하여, 상기 제2 특징 벡터를 얻는 것을 포함하는, 정보 예측 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻는 것은, 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻으며; 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻는 것을 포함하는 정보 예측 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻으며; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻으며; 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 제어 정보를 얻는 것을, 포함하는 정보 예측 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "자율주행 모델의 훈련 방법으로서, 상기 자율주행 모델은 부호화 층 및 생성 모델을 포함하며; 상기 부호화 층은 시퀀스 부호화 네트워크 및 운전데이터 부호화 네트워크를 포함하며; 상기 자율주행 모델의 훈련 방법은, 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻으며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하며; 상기 예측 토큰 시퀀스와 상기 영상 토큰 시퀀스에 따라, 상기 자율주행 모델을 훈련하는 것을 포함하는 자율주행 모델의 훈련 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 샘플 감지 데이터는 실제 제어 정보를 또한 포함하며; 상기 자율주행 모델의 훈련 방법은 공개특허 10-2025-0047938-4-상기 실제 제어 정보와 상기 예측 제어 정보 사이의 차이에 따라, 상기 자율주행 모델을 훈련하는 것을 또한 포함하는 자율주행 모델의 훈련 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항 또는 제8항에 있어서,상기 자율주행 모델을 훈련하는 것은, 상기 자율주행 모델 중 상기 시퀀스 부호화 네트워크 이외의 기타 모델 구조를 훈련하는 것을, 포함하는 자율주행 모델의 훈련 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 부호화 층은 제1 컨볼루션 네트워크를 또한 포함하며; 상기 자율주행 모델의 훈련 방법은, 상기 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는제1 특징 벡터를 얻는 것을 또한 포함하며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하는 것은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기예측 토큰 시퀀스 및 상기 예측 제어 정보를 생성하는 것을, 포함하는 자율주행 모델의 훈련 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항 또는 제10항에 있어서, 상기 운전 데이터는 차량의 과거 주행 파라미터 및 상기 차량의 과거 네비게이션 데이터를 포함하며; 상기 운전 데이터 부호화 네트워크는 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포함하며; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻는 것은, 상기 제2 컨볼루션 네트워크를 이용하여 상기 과거 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를표현하는 제2 특징 벡터를 얻으며; 상기 다층 퍼셉트론을 이용하여 상기 과거 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻는 것을, 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 자율주행 모델의 훈련 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함하며; 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻는 것은 상기 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻으며; 공개특허 10-2025-0047938-5-상기 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻는 것을,포함하며,상기 시퀀스 부호화 네트워크는 벡터 양자화의 압축 기술에 기초하여 상기 영상 데이터를 처리하는, 자율주행 모델의 훈련 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제7항에 있어서, 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하는 것은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻으며; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻으며; 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 얻는 것을, 포함하며, 상기 생성 모델은 자기 회귀 모델을 포함하는, 자율주행 모델의 훈련 방법."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "정보 예측 장치로서, 차량 내의 센서가 수집한 영상 데이터 및 상기 차량의 운전 데이터를 포함하는 감지 데이터를 취득하기 위해 사용되는 데이터 취득 모듈; 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용되는 제1 부호화 모듈; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용되는 제2 부호화 모듈; 및 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하기 위해 사용되는 생성 모듈, 을 포함하는 정보 예측 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 영상 토큰 시퀀스는 상기 영상 데이터의 이산적인 특징이며; 상기 정보 예측 장치는, 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻기 위해 사용되는 특징 추출 모듈을 또한 포함하며; 상기 생성 모듈은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 제어 정보를 생성하기 위해 사용되는 정보 예측 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항 또는 제15항에 있어서, 상기 운전 데이터는 상기 차량의 주행 파라미터 및 상기 차량의 네비게이션 데이터를 포함하며; 상기 제2 부호화 모듈은, 공개특허 10-2025-0047938-6-제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는제2 특징 벡터를 얻기 위해 사용되는 제1 부호화 서브 모듈; 및 다층 퍼셉트론을 이용하여 상기 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를얻기 위해 사용되는 제2 부호화 서브 모듈을, 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 정보 예측 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함하며; 상기 제1 부호화 서브 모듈은, 상기 적어도 2개의 목표 지점의 위치에 기초하여, 상기 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스크 영상을 생성하기 위해 사용되는 영상 생성 유닛; 및 상기 제2 컨볼루션 네트워크를 이용하여 상기 마스크 영상을 부호화하여, 상기 제2 특징 벡터를 얻기 위해 사용되는 영상 부호화 유닛을, 포함하는 정보 예측 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서, 상기 제1 부호화 모듈은, 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻기 위해 사용되는 제3 부호화 서브모듈; 및 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻기 위해 사용되는 양자화 서브 모듈을, 포함하는, 정보 예측 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서, 상기 생성 모듈은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용되는 태그 추가 서브 모듈; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻기 위해 사용되는시퀀스 획득 서브 모듈; 및 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 제어 정보를 얻기 위해 사용되는 생성 서브 모듈을, 포함하는 정보 예측 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "자율주행 모델의 훈련 장치로서, 상기 자율주행 모델은 부호화 층 및 생성 모델을 포함하며; 상기 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함하며; 공개특허 10-2025-0047938-7-상기 자율주행 모델의 훈련 장치는, 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용되는 제1 부호화 모듈; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용되는 제2 부호화 모듈; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하기 위해 사용되는 생성 모듈; 및 상기 예측 토큰 시퀀스와 상기 영상 토큰 시퀀스에 따라, 상기 자율주행 모델을 훈련하기 위해 사용되는 훈련모듈을 포함하는 자율주행 모델의 훈련 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 샘플 감지 데이터는 실제 제어 정보를 또한 포함하며; 상기 훈련 모듈은 또한 상기 실제 제어 정보와 상기 예측 제어 정보 사이의 차이에 따라, 상기 자율주행 모델을 훈련하기 위해 사용되는, 자율주행 모델의 훈련 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항 또는 제21항에 있어서, 상기 훈련 모듈은, 상기 자율주행 모델 중 상기 시퀀스 부호화 네트워크 이외의 기타 모델 구조를 훈련하기 위해 사용되는, 자율주행 모델의 훈련 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20항에 있어서, 상기 부호화 층은 제1 컨볼루션 네트워크를 또한 포함하며; 상기 자율주행 모델의 훈련 장치는, 상기 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는제1 특징 벡터를 얻기 위해 사용되는 특징 추출 모듈을 또한 포함하며; 상기 생성 모듈은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 생성하기 위해 사용되는, 자율주행 모델의 훈련장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제20항 또는 제21항에 있어서, 상기 운전 데이터는 차량의 과거 주행 파라미터 및 상기 차량의 과거 네비게이션 데이터를 포함하며; 상기 운전 데이터 부호화 네트워크는 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포함하며; 상기 제2 부호화 모듈은, 상기 제2 컨볼루션 네트워크를 이용하여 상기 과거 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를공개특허 10-2025-0047938-8-표현하는 제2 특징 벡터를 얻기 위해 사용되는 제1 부호화 서브 모듈; 및 상기 다층 퍼셉트론을 이용하여 상기 과거 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻기 위해 사용되는 제2 부호화 서브 모듈을, 포함하며,상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 자율주행 모델의 훈련 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제20항에 있어서, 상기 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함하며; 상기 제1 부호화 모듈은, 상기 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻기 위해 사용되는 제3 부호화서브 모듈; 및 상기 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻기 위해 사용되는 양자화 서브 모듈을 포함하며, 상기 시퀀스 부호화 네트워크는 벡터 양자화의 압축 기술에 기초하여 상기 영상 데이터를 처리하는, 자율주행 모델의 훈련 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제20항에 있어서, 상기 생성 모듈은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용되는 태그 추가 서브 모듈; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻기 위해 사용되는시퀀스 획득 서브 모듈; 및 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 얻기 위해 사용되는 생성 서브 모듈을 포함하며,상기 생성 모델은 자기 회귀 모델을 포함하는, 자율주행 모델의 훈련 장치."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "전자 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통시 연결된 메모리를 포함하며, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 상기 명령어가 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서를 제1항, 제2항, 및 제4항 내지 제6항 중어느 하나의 정보 예측 방법을 실행 가능하게 하는 전자 기기."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "전자 기기로서, 적어도 하나의 프로세서; 및 공개특허 10-2025-0047938-9-상기 적어도 하나의 프로세서와 통시 연결된 메모리를 포함하며, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 상기 명령어가 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서를 제7항, 제8항, 제10항, 제12항 및 제13항중 어느 하나의 자율주행 모델의 훈련 방법을 실행 가능하게 하는 전자 기기."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "컴퓨터 명령어가 저장되어 있는 비순간 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령어는 상기 컴퓨터로 하여금 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방법 또는 제7항, 제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 실행하기 위해사용되는 비순간 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 판독 가능 저장 매체 및 전자 기기 중 적어도 하나에 저장되며, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 때 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방법 또는 제7항,제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 구현하는 컴퓨터 프로그램."}
{"patent_id": "10-2025-0035537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제27항의 전자 기기를 포함하는 자율주행 차량."}
{"patent_id": "10-2025-0035537", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 정보 예측 방법, 자율주행 모델의 훈련 방법, 장치, 기기, 매체, 프로그램, 및 자율주행 차량을 제공 하고, 인공 지능"}
{"patent_id": "10-2025-0035537", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로서, 특히 컴퓨터 비전 및 딥러닝 등 기술 분야에 관한 것이며, 자율주 행 등 장면에 적용 가능하다. 정보 예측 방법의 구체적인 실현 방안은, 차량 내의 센서가 수집한 영상 데이터 및 차량의 운전 데이터를 포함하는 감지 데이터를 취득하며; 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영 상 토큰 시퀀스를 얻으며; 운전 데이터를 부호화하여, 운전 데이터에 대응하는 운전 특징을 얻으며; 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량 에 대한 제어 정보를 생성한다. 대 표 도 - 도2"}
{"patent_id": "10-2025-0035537", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2025-0047938 CPC특허분류 G06N 3/045 (2023.01) G06N 3/0475 (2023.01) G06N 3/09 (2023.01) G06V 10/454 (2023.08) G06V 10/774 (2023.08) G06V 10/82 (2022.01) G06V 20/58 (2022.01) 발명자 탄, 샤오 중국, 베이징 100085, 하이디안 디스트릭트 샹디 10번가, 넘버 10, 바이두 캠퍼스 2층 딩, 에루이 중국, 베이징 100085, 하이디안 디스트릭트 샹디 10번가, 넘버 10, 바이두 캠퍼스 2층 왕, 징동 중국, 베이징 100085, 하이디안 디스트릭트 샹디 10번가, 넘버 10, 바이두 캠퍼스 2층우, 티안 중국, 베이징 100085, 하이디안 디스트릭트 샹디 10번가, 넘버 10, 바이두 캠퍼스 2층 왕, 하이펑 중국, 베이징 100085, 하이디안 디스트릭트 샹디 10번가, 넘버 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 정보 예측 방법으로서, 차량 내의 센서가 수집한 영상 데이터 및 상기 차량의 운전 데이터를 포함하는 감지 데이터를 취득하며; 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻으며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하 는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것을 포함하는 정보 예측 방법. 청구항 2 제1항에 있어서, 상기 영상 토큰 시퀀스는 상기 영상 데이터의 이산적인 특징이며; 상기 정보 예측 방법은, 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻는 것을 또한 포함하며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하 는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 제어 정보를 생성하는 것을 포함하는, 정보 예측 방법. 청구항 3 제1항 또는 제2항에 있어서, 상기 운전 데이터는 상기 차량의 주행 파라미터 및 상기 차량의 네비게이션 데이터를 포함하며; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻는 것은, 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻으며; 다층 퍼셉트론을 이용하여 상기 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻는 것을 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 정보 예측 방법. 청구항 4 제3항에 있어서, 상기 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함하며; 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻는 것은, 상기 적어도 2개의 목표 지점의 위치에 기초하여, 상기 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스크 영상을 생성하며; 상기 제2 컨볼루션 네트워크를 이용하여 상기 마스크 영상을 부호화하여, 상기 제2 특징 벡터를 얻는 것을 포함 하는, 정보 예측 방법. 청구항 5 제1항에 있어서, 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻는 것은, 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻으며; 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻는 것을 포함하 는 정보 예측 방법. 청구항 6 제1항에 있어서, 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하 는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그 를 추가하여, 태그된 토큰 시퀀스를 얻으며; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻으며; 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 제 어 정보를 얻는 것을, 포함하는 정보 예측 방법. 청구항 7 자율주행 모델의 훈련 방법으로서, 상기 자율주행 모델은 부호화 층 및 생성 모델을 포함하며; 상기 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함하며; 상기 자율주행 모델의 훈련 방법은, 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터 에 대응하는 영상 토큰 시퀀스를 얻으며; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운 전 데이터에 대응하는 운전 특징을 얻으며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대 응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하며; 상기 예측 토큰 시퀀스와 상기 영상 토큰 시퀀스에 따라, 상기 자율주행 모델을 훈련하는 것을 포함하는 자율주행 모델의 훈련 방법. 청구항 8 제7항에 있어서, 상기 샘플 감지 데이터는 실제 제어 정보를 또한 포함하며; 상기 자율주행 모델의 훈련 방법은 상기 실제 제어 정보와 상기 예측 제어 정보 사이의 차이에 따라, 상기 자율주행 모델을 훈련하는 것을 또한 포 함하는 자율주행 모델의 훈련 방법. 청구항 9 제7항 또는 제8항에 있어서, 상기 자율주행 모델을 훈련하는 것은, 상기 자율주행 모델 중 상기 시퀀스 부호화 네트워크 이외의 기타 모델 구조를 훈련하는 것을, 포함하는 자율주행 모델의 훈련 방법. 청구항 10 제7항에 있어서, 상기 부호화 층은 제1 컨볼루션 네트워크를 또한 포함하며; 상기 자율주행 모델의 훈련 방법은, 상기 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻는 것을 또한 포함하며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대 응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하는 것은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 생성하는 것을, 포함하는 자율주행 모델의 훈련 방법. 청구항 11 제7항 또는 제10항에 있어서, 상기 운전 데이터는 차량의 과거 주행 파라미터 및 상기 차량의 과거 네비게이션 데이터를 포함하며; 상기 운전 데이터 부호화 네트워크는 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포함하며; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운 전 데이터에 대응하는 운전 특징을 얻는 것은, 상기 제2 컨볼루션 네트워크를 이용하여 상기 과거 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻으며; 상기 다층 퍼셉트론을 이용하여 상기 과거 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특 징 벡터를 얻는 것을, 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 자율주행 모델의 훈련 방법. 청구항 12 제7항에 있어서, 상기 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함하며; 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터 에 대응하는 영상 토큰 시퀀스를 얻는 것은 상기 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻으며; 상기 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻는 것을, 포함하며, 상기 시퀀스 부호화 네트워크는 벡터 양자화의 압축 기술에 기초하여 상기 영상 데이터를 처리하는, 자율주행 모델의 훈련 방법. 청구항 13 제7항에 있어서, 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대 응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하는 것은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그 를 추가하여, 태그된 토큰 시퀀스를 얻으며; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻으며; 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 예 측 제어 정보를 얻는 것을, 포함하며, 상기 생성 모델은 자기 회귀 모델을 포함하는, 자율주행 모델의 훈련 방법. 청구항 14 정보 예측 장치로서, 차량 내의 센서가 수집한 영상 데이터 및 상기 차량의 운전 데이터를 포함하는 감지 데이터를 취득하기 위해 사 용되는 데이터 취득 모듈; 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용되는 제1 부 호화 모듈; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용되는 제2 부호화 모 듈; 및 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하 는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하기 위해 사용되는 생성 모듈, 을 포함하는 정보 예측 장치. 청구항 15 제14항에 있어서, 상기 영상 토큰 시퀀스는 상기 영상 데이터의 이산적인 특징이며; 상기 정보 예측 장치는, 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영 상 특징을 표현하는 제1 특징 벡터를 얻기 위해 사용되는 특징 추출 모듈을 또한 포함하며; 상기 생성 모듈은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델 을 이용하여 상기 예측 토큰 시퀀스 및 상기 제어 정보를 생성하기 위해 사용되는 정보 예측 장치. 청구항 16 제14항 또는 제15항에 있어서, 상기 운전 데이터는 상기 차량의 주행 파라미터 및 상기 차량의 네비게이션 데이터를 포함하며; 상기 제2 부호화 모듈은, 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻기 위해 사용되는 제1 부호화 서브 모듈; 및 다층 퍼셉트론을 이용하여 상기 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻기 위해 사용되는 제2 부호화 서브 모듈을, 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 정보 예측 장치. 청구항 17 제16항에 있어서, 상기 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함하며; 상기 제1 부호화 서브 모듈은, 상기 적어도 2개의 목표 지점의 위치에 기초하여, 상기 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스 크 영상을 생성하기 위해 사용되는 영상 생성 유닛; 및 상기 제2 컨볼루션 네트워크를 이용하여 상기 마스크 영상을 부호화하여, 상기 제2 특징 벡터를 얻기 위해 사용 되는 영상 부호화 유닛을, 포함하는 정보 예측 장치. 청구항 18 제14항에 있어서, 상기 제1 부호화 모듈은, 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻기 위해 사용되는 제3 부호화 서브 모듈; 및 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻기 위해 사용되 는 양자화 서브 모듈을, 포함하는, 정보 예측 장치. 청구항 19 제14항에 있어서, 상기 생성 모듈은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그 를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용되는 태그 추가 서브 모듈; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻기 위해 사용되는 시퀀스 획득 서브 모듈; 및 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 제 어 정보를 얻기 위해 사용되는 생성 서브 모듈을, 포함하는 정보 예측 장치. 청구항 20 자율주행 모델의 훈련 장치로서, 상기 자율주행 모델은 부호화 층 및 생성 모델을 포함하며; 상기 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함하며; 상기 자율주행 모델의 훈련 장치는, 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터 에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용되는 제1 부호화 모듈; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운 전 데이터에 대응하는 운전 특징을 얻기 위해 사용되는 제2 부호화 모듈; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대 응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하기 위해 사용되는 생성 모듈; 및 상기 예측 토큰 시퀀스와 상기 영상 토큰 시퀀스에 따라, 상기 자율주행 모델을 훈련하기 위해 사용되는 훈련 모듈을 포함하는 자율주행 모델의 훈련 장치. 청구항 21 제20항에 있어서, 상기 샘플 감지 데이터는 실제 제어 정보를 또한 포함하며; 상기 훈련 모듈은 또한 상기 실제 제어 정보와 상기 예측 제어 정보 사이의 차이에 따라, 상기 자율주행 모델을 훈련하기 위해 사용되 는, 자율주행 모델의 훈련 장치. 청구항 22 제20항 또는 제21항에 있어서, 상기 훈련 모듈은, 상기 자율주행 모델 중 상기 시퀀스 부호화 네트워크 이외의 기타 모델 구조를 훈련하기 위해 사용되는, 자율주행 모델의 훈련 장치. 청구항 23 제20항에 있어서, 상기 부호화 층은 제1 컨볼루션 네트워크를 또한 포함하며; 상기 자율주행 모델의 훈련 장치는, 상기 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻기 위해 사용되는 특징 추출 모듈을 또한 포함하며; 상기 생성 모듈은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델 을 이용하여 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 생성하기 위해 사용되는, 자율주행 모델의 훈련 장치. 청구항 24 제20항 또는 제21항에 있어서, 상기 운전 데이터는 차량의 과거 주행 파라미터 및 상기 차량의 과거 네비게이션 데이터를 포함하며; 상기 운전 데이터 부호화 네트워크는 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포함하며; 상기 제2 부호화 모듈은, 상기 제2 컨볼루션 네트워크를 이용하여 상기 과거 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를표현하는 제2 특징 벡터를 얻기 위해 사용되는 제1 부호화 서브 모듈; 및 상기 다층 퍼셉트론을 이용하여 상기 과거 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특 징 벡터를 얻기 위해 사용되는 제2 부호화 서브 모듈을, 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 자율주행 모델의 훈련 장치. 청구항 25 제20항에 있어서, 상기 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함하며; 상기 제1 부호화 모듈은, 상기 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻기 위해 사용되는 제3 부호화 서브 모듈; 및 상기 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻기 위해 사 용되는 양자화 서브 모듈을 포함하며, 상기 시퀀스 부호화 네트워크는 벡터 양자화의 압축 기술에 기초하여 상기 영상 데이터를 처리하는, 자율주행 모델의 훈련 장치. 청구항 26 제20항에 있어서, 상기 생성 모듈은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그 를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용되는 태그 추가 서브 모듈; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻기 위해 사용되는 시퀀스 획득 서브 모듈; 및 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 예 측 제어 정보를 얻기 위해 사용되는 생성 서브 모듈을 포함하며, 상기 생성 모델은 자기 회귀 모델을 포함하는, 자율주행 모델의 훈련 장치. 청구항 27 전자 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통시 연결된 메모리를 포함하며, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 상기 명령어가 상기 적어 도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서를 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방법을 실행 가능하게 하는 전자 기기. 청구항 28 전자 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통시 연결된 메모리를 포함하며, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 상기 명령어가 상기 적어 도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서를 제7항, 제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 실행 가능하게 하는 전자 기기. 청구항 29 컴퓨터 명령어가 저장되어 있는 비순간 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령어는 상기 컴퓨터로 하여금 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방 법 또는 제7항, 제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 실행하기 위해 사용되는 비순간 컴퓨터 판독 가능 저장 매체. 청구항 30 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 판독 가능 저장 매체 및 전자 기기 중 적어도 하나에 저장되며, 상기 컴퓨터 프로그램 이 프로세서에 의해 실행될 때 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방법 또는 제7항, 제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 구현하는 컴퓨터 프로그램. 청구항 31 제27항의 전자 기기를 포함하는 자율주행 차량. 발명의 설명 기 술 분 야 본 개시는 인공 지능 기술 분야에 관한 것으로서, 특히 컴퓨터 비전 및 딥러닝 등 기술 분야에 관한 것이며, 자 율주행 등 장면에 적용 가능하다."}
{"patent_id": "10-2025-0035537", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능 및 자율주행 기술의 빠른 발전에 따라, 엔드 투 엔드(end-to-end) 자율주행 시스템은 간소화된 시스 템 아키텍처, 감소된 오류 누적 및 전역 최적화 능력 등으로 주목받고 있다. 예를 들어, 자율주행 시스템은 감지 데이터의 분석을 통해, 차량에 대한 제어 신호를 예측할 수 있다. 차량은 예측된 제어 신호에 따라 제동 시스템을 제어하여, 차량의 자동 주행을 실현한다. 이 자율주행 시스템의 설정을 통해, 어느 정도 편리한 이동의 요구를 충족할 수 있다. 본 개시는 대규모의 정확한 라벨링 데이터에 의존하지 않고 제어 정보 예측을 실현 가능한 정보 예측 방법, 자 율주행 모델의 훈련 방법, 장치, 기기, 매체, 프로그램 제품, 및 자율주행 차량을 제공하는 것을 목적으로 한다. 본 개시의 제1 측면에 따라, 차량 내의 센서가 수집한 영상 데이터 및 차량의 운전 데이터를 포함하는 감지 데 이터를 취득하며; 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 운전 데이터 를 부호화하여, 운전 데이터에 대응하는 운전 특징을 얻으며; 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 제어 정보를 생성하는 것을 포 함하는 정보 예측 방법을 제공한다. 본 개시의 제2 측면에 따라, 자율주행 모델의 훈련 방법을 제공한다. 자율주행 모델은 부호화 층 및 생성 모델 을 포함하며; 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함한다. 훈련 방법은, 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 운전 데이터 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 운전 데이터를 부 호화하여, 운전 데이터에 대응하는 운전 특징을 얻으며; 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델 을 이용하여 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하며; 예측 토큰 시퀀스와 영상 토큰 시퀀스에 따라, 자율주행 모델을 훈련하는 것을 포함한다. 본 개시의 제3 측면에 따라, 차량 내의 센서가 수집한 영상 데이터 및 차량의 운전 데이터를 포함하는 감지 데 이터를 취득하기 위해 사용되는 데이터 취득 모듈; 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토 큰 시퀀스를 얻기 위해 사용되는 제1 부호화 모듈; 운전 데이터를 부호화하여, 운전 데이터에 대응하는 운전 특 징을 얻기 위해 사용되는 제2 부호화 모듈; 및 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하 여 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 제어 정보를 생성하기 위해 사용되는 생성 모듈, 을 포함하는 정보 예측 장치을 제공한다. 본 개시의 제4 측면에 따라, 자율주행 모델의 훈련 장치를 제공한다. 자율주행 모델은 부호화 층 및 생성 모델 을 포함하며; 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함한다. 훈련 장치는, 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용되는 제1 부호화 모듈; 운전 데이터 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용되는 제2 부호화 모듈; 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대응하는 예측 토 큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하기 위해 사용되는 생성 모듈; 및 예측 토큰 시퀀스와 영상 토큰 시퀀스에 따라, 자율주행 모델을 훈련하기 위해 사용되는 훈련 모듈을 포함한다. 본 개시의 제5 측면에 따라, 적어도 하나의 프로세서; 및 적어도 하나의 프로세서와 통시 연결된 메모리를 포함 하며, 메모리는 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 명령어가 적어도 하나의 프로 세서에 의해 실행되어, 적어도 하나의 프로세서를 본 개시가 제공한 정보 예측 방법을 실행 가능하게 하는 전자 기기를 제공한다. 본 개시의 제6 측면에 따라, 적어도 하나의 프로세서; 및 적어도 하나의 프로세서와 통시 연결된 메모리를 포함 하며, 메모리는 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 명령어가 적어도 하나의 프로 세서에 의해 실행되어, 적어도 하나의 프로세서를 본 개시가 제공한 자율주행 모델의 훈련 방법을 실행 가능하 게 하는 전자 기기를 제공한다. 본 개시의 제7 측면에 따라, 컴퓨터 명령어가 저장되어 있는 비순간 컴퓨터 판독 가능 저장 매체를 제공하며, 컴퓨터 명령어는 컴퓨터로 하여금 본 개시가 제공한 정보 예측 방법 또는 자율주행 모델의 훈련 방법을 실행하 기 위해 사용된다. 본 개시의 제8 측면에 따라, 컴퓨터 프로그램/명령어가 포함되고, 상기 컴퓨터 프로그램/명령어가 판독 가능 저 장 매체 및 전자 기기 중 적어도 하나에 저장되며, 상기 컴퓨터 프로그램/명령어가 프로세서에 의해 실행될 때 본 개시가 제공한 정보 예측 방법 또는 자율주행 모델의 훈련 방법을 구현하는 컴퓨터 프로그램 제품을 제공한 다. 본 개시의 제9 측면에 따라, 본 개시의 제5 측면에 제공한 전자 기기를 포함하는 자율주행 차량을 제공한다. 이 부분에서 설명한 내용은 본 개시의 실시예의 핵심 또는 중요한 특징들을 표시하기 위한 것이 아니며, 본 개 시의 범위를 한정하는 데 사용하지 않는다는 것을 이해해야 한다. 본 개시의 기타 특징은 아래의 명세서를 통해 쉽게 이해할 수 있게 될 것이다."}
{"patent_id": "10-2025-0035537", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 예시적인 실시예를 상세히 설명하기로 한다. 이해를 돕기 위하여 그 중에는 본 개시의 실시예의 다양한 세부사항이 포함되어 있으며, 이들을 단지 예시적인 것으로 간주해야 한다."}
{"patent_id": "10-2025-0035537", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라서, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 개시의 범위 및 사상을 벗어나는 것이 없 이 여기서 설명된 실시예에 대해 다양한 변경 및 수정을 진행할 수 있음을 인식해야 한다. 마찬가지로, 명확하 고 간결하기 위하여, 아래 설명 중에는 공지 기능 또는 구성에 대한 설명은 생략하도록 한다. 엔드 투 엔드 자율주행 시스템이 직면한 주요 도전 중 하나는 견고한 환경 감지 및 표현을 어떻게 구축할 것인 지에 있다. 예를 들어, 보조 감지 태스크(Task)를 도입하여 견고한 환경 감지 및 표현을 구축하는 능력을 향상 시킬 수 있다. 구체적으로, 현재의 자율주행 시스템은 일반적으로 다중 태스크 보조 계획에 의존하며, 보조 감 독 신호를 도입하여 환경 표현을 개선한다. 그러나, 이러한 방법은 통상적으로 비용이 많이 들고 얻기 어려운 정확한 감지 라벨링이 필요하다. 즉, 라벨링 데이터를 보조 감독 신호로 사용하기 위해, 정확하게 라벨링된 감 지 데이터가 필요하다. 따라서, 시간과 인력이 많이 드는 문제가 있으며, 이는 자율주행 모델의 배치 비용, 확 장 가능성 및 실용성을 어느 정도 제한한다. 종래 기술에서 존재하는 문제를 해결하기 위해, 본 개시는 정보 예측 방법, 자율주행 모델의 훈련 방법, 장치, 기기, 매체, 프로그램 제품 및 자율주행 차량을 제공한다. 이하, 먼저 도 1을 결합하여 본 개시가 제공한 방법 및 장치의 적용 장면을 설명한다. 도 1은 본 개시의 실시예에 따른 정보 예측 방법, 자율주행 모델의 훈련 방법, 및 장치의 적용 장면 개략도이다. 도 1에 도시된 바와 같이, 본 실시예의 적용 장면은 차량 및 서버를 포함할 수 있다. 여기서, 차량에서 자율주행 시스템이 통합될 수 있고, 서버는 예를 들어 지능형 운전 시스템의 작동에 지원을 제공하기 위한 백그라운드 관리 서버일 수 있다. 일 실시예에서, 차량은 예를 들어 자율주행 시스템과 통시 연결된 다양한 유형의 센서, 예를 들어, 시각형 카메라 및 레이더형 거리 측정센서 등이 통합될 수도 있다. 여기서, 시각형 카메라는 예를 들어 단안 카메라, 쌍안 입체 시각 카메라, 파노라마 시각 카메라 및 적외선 카메라 등을 포함할 수 있다. 레이더형 거리 측정센서 는 예를 들어 레이저 레이더, 밀리미터파 레이더, 초음파 레이더 등을 포함할 수 있다. 자율주행 시스템은 예를 들어 다양한 유형의 센서가 수집한 데이터를 처리하여, 차량의 환경 정보 및 차량에 대한 제어 정보 을 결정하여, 차량이 제어 정보에 따라 주행하도록 할 수 있다. 일 실시예에서, 서버는 예를 들어 자율주행 시스템에 자율주행 모델을 제공할 수 있다. 자율주행 시 스템은 이 자율주행 모델에 의해 센서가 수집한 영상 데이터를 처리하고, 차량의 현재 운전 데이터와 결합 하여, 차량에 대한 제어 정보를 예측하여, 차량이 이 제어 정보에 따라 자동 주행할 수 있도록 한다. 예를 들어, 자율주행 모델은 제어 정보의 예측을 주요 태스크으로 하고 영상의 생성 태스크를 보조 태스크으로 하여, 영상 토큰 시퀀스 및 예측된 제어 정보를 동기화하여 출력할 수 있고, 이 출력된 영상 토큰 시퀀스를 복 호화함으로써, 영상을 생성할 수 있다. 일 실시예에서, 서버는 라벨링 데이터와 결합하여 자율주행 모델을 훈련하여, 자율주행 모델이 제어 정보를 예측하는 능력을 갖도록 할 수 있다. 보조 태스크를 수행하기 위하여, 서버는 영상 데이터를 이용 하여 자율주행 모델에 대해 자기 감독 훈련을 수행하여, 자율주행 모델이 영상을 생성하는 능력을 갖도록하고, 이 보조 태스크에 의존하여 자율주행 모델이 주요 태스크를 수행하는 정확도를 향상하도록 할 수 있 다. 일 실시예에서, 차량 내의 자율주행 시스템은 센서가 수집한 데이터를 서버에 송신하여, 서버에 의해 영상 생성 및 제어 정보의 예측을 수행할 수 있다. 그후, 서버에 의해 예측한 제어 정보를 자율주행 시스템에 전송하고, 자율주행 시스템에 의해 이 제어 정보에 따라 차량의 이동을 제어한다. 설명해야 할 것은, 본 개시가 제공한 정보 예측 방법은 차량 또는 차량 내의 자율주행 시스템에 의해 수행할 수 있고, 서버에 의해 수행할 수도 있다. 따라서, 본 개시가 제공한 정보 예측 장치는 차량 또는 차량이 포함 하는 자율주행 시스템에 설치될 수 있고, 서버에 설치될 수도 있다. 본 개시가 제공한 자율주행 모델의 훈 련 방법은 서버에 의해 수행할 수 있다. 따라서, 본 개시가 제공한 자율주행 모델의 훈련 장치는 서버 에 설치될 수 있다. 이해해야 할 것은, 도 1에서의 차량 및 서버의 수량 및 유형은 예시일 뿐이다. 실현 요구에 따라, 임 의의 수량 및 유형의 차량 및 서버를 갖을 수 있다. 이하 도 2~도 6을 결합하여 본 개시가 제공한 정보 예측 방법을 자세하게 설명할 것이다. 도 2는 본 개시의 실시예에 따른 정보 예측 방법의 흐름 개략도이다. 도 2에 도시된 바와 같이, 본 실시예의 정보 예측 방법은 동작 S210~동작 S240을 포함할 수 있다. 동작 S210에서, 감지 데이터를 취득한다. 이 감지 데이터는 차량 내의 센서가 수집한 영상 데이터 및 차량의 운 전 데이터를 적어도 포함한다. 본 개시의 실시예에 따라, 감지 데이터는 정보 예측 방법을 수행하는 과정에서 실시간으로 취득될 수 있다. 차 량의 운전 데이터는 현재 시각의 네비게이션 데이터, 현재 시각의 속도, 현재 시각의 차량에 대한 제어 정보 등 중의 하나 또는 복수를 포함할 수 있다. 여기서, 제어 정보는 가속 페달을 밟은 각도, 브레이크를 밟은 각도, 스티어링 휠 조향 및 스티어링 휠 회전 각도 등 중의 하나 또는 복수를 포함할 수 있다. 이 운전 데이터는 예를 들어 차량 내의 차량 제어 시스템에 의해 취득할 수 있고, 차량 내의 자율주행 시스템에 의해 취득할 수도 있으 며, 본 개시는 이에 대해 제한하지 않는다. 센서가 수집한 영상 데이터는 예를 들어 차량 내의 카메라가 수집한 현재 시각의 환경 영상 등을 포함할 수 있다. 일 실시예에서, 취득된 감지 데이터는 현재 시각에서 수집된 영상 데이터 및 운전 데이터외에도, 예를 들어 과 거 시각(예를 들어 하나 또는 복수의 과거 시각일 수 있음)에서 수집된 영상 데이터 및 운전 데이터를 포함할 수 있다. 과거 시각의 영상 데이터 및 현재 시각의 영상 데이터는 영상 데이터 시퀀스를 구성할 수 있다. 과거 시각의 운전 데이터 및 현재 시각의 운전 데이터는 운전 데이터 시퀀스를 구성할 수 있다. 동작 S220에서, 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻는다. 본 개시의 실시예에 따라, 예를 들어 먼저 환경 영상을 블록화 처리한 후, 블로화된 각 영상 블록을 부호화하여, 하나의 token(토큰)을 얻을 수 있다. 블로화된 복수의 영상 블록을 부호화함으로써, 하나의 token 시퀀스, 즉, 영상 토큰 시퀀스를 얻을 수 있다. 예를 들어, 2차원 컨볼루션 층을 이용하여 각 영상 블록을 부호 화하여, 하나의 token을 얻을 수 있다. 영상 데이터 시퀀스를 취득한 경우, 영상 데이터 시퀀스 중의 각 영상 데이터를 부호화하여 하나의 token 시퀀 스를 얻고, 합쳐서 복수의 token 시퀀스를 얻을 수 있다. 그후 영상 데이터가 수집된 순서에 따라, 복수의 token 시퀀스를 이어맞춰, 영상 데이터 시퀀스에 대응하는 영상 토큰 시퀀스를 얻는다. 동작 S230에서, 운전 데이터를 부호화하여, 운전 데이터에 대응하는 운전 특징을 얻는다. 예를 들어, 운전 데이터는 일련의 숫자로 나타낼 수 있고, 이 숫자는 차량의 속도, 네비게이션 경로에서의 목표 지점의 2차원 좌표, 차량 가속 페달을 밟은 각도 등을 포함할 수 있다. 예를 들어 임베디드 층을 사용하여 운전 데이터를 부호화하여, 운전 데이터를 하나의 벡터로 매핑하여, 운전 특징을 얻도록 할 수 있다. 운전 데이터 시퀀스를 취득한 경우, 먼저 운전 데이터 시퀀스의 각 시각의 운전 데이터를 부호화하여, 하나의 특징을 얻을 수 있다. 운전 데이터 시퀀스에 대해 합쳐서 복수의 특징을 얻는다. 그후 운전 데이터가 수집된 순 서에 따라, 이 복수의 특징을 이어맞춰, 운전 데이터 시퀀스에 대응하는 운전 특징을 얻는다. 동작 S240에서, 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대응하 는 예측 토큰 시퀀스 및 차량에 대한 제어 정보를 생성한다. 예를 들어, 운전 특징과 영상 토큰 시퀀스를 이어맞춰 입력 특징을 얻고, 이 입력 특징을 생성 모델에 입력하여, 예측 토큰 시퀀스 및 제어 정보를 얻을 수 있다. 여기서, 제어 정보는 차량의 제어 신호로 이해될 수 있고, 가속 페달을 밟은 각도, 브레이크를 밟은 각도, 스티어링 휠 조향 및 스티어링 휠 회전 각도 등의 정보 중의 적어도 하나를 포함할 수 있다. 본 실시예에서, 생성 모델은 다중 태스크를 수행하는 모델이고, 수행되는 다중 태스크는 영상 생성 태스크 및 제어 정보 예측 태스크를 포함한다. 영상 생성 태스크는 영상 재구성 태스크일 수 있고, 영상 예측 태스크일 수 도 있다. 또한, 이 영상 생성 태스크는 제어 정보 예측 태스크에 대해 보조 태스크가다. 예를 들어, 생성 모델은 변분 오토 부호기(VAEs, Variational Auto Encoders), 디퓨전 모델 (Diffusion Models) 또는 자기 회귀 모델 등일 수 있다. 여기서, 자기 회귀 모델은 예를 들어 트랜스포머(Transformer) 아 키텍처에 기초하는 모델일 수 있고, 본 개시는 이에 대해 제한하지 않는다. 일 실시예에서, 영상 토큰 시퀀스를 t시각의 영상 데이터에 대응하는 시퀀스 Xt=(xt,1, xt,2, …, xt,n)로 설정하고, 생성 모델이 생성하는 예측 토큰 시퀀스는 예를 들어 예측된 t 시각의 영상 데이터에 대응하는 시퀀 스 Xt'=(xt,1', xt,2', …, xt,n')일 수 있으며, 예측된 t+1 시각의 영상 데이터에 대응하는 시퀀스 Xt+1=(xt+1,1, xt+1,2, …, xt+1,n)일 수도 있다. 제어 정보를 얻은 후, 차량 내의 자율주행 시스템은 예를 들어 이 제어 정보에 따라 주행 파라미터를 결정하고, 이 주행 파라미터에 따라 차량 주행을 제어할 수 있다. 본 개시의 실시예에서, 영상의 토큰 시퀀스를 예측하는 보조 태스크를 도입함으로써 차량에 대한 제어 정보의 예측을 수행한다. 이럼으로써, 제어 정보의 예측 과정에서 견고한 환경 감지 및 표현을 구축 가능하도록 할 수 있다. 또한, 보조 태스크는 수집된 영상을 감독 신호로 구현할 수 있기 때문에, 정확한 감지의 라벨링에 의존하 지 않고, 보조 태스크를 실현하는 난이도를 효과적으로 줄여, 제어 정보 예측 태스크의 광범위한 배포에 유리하 여, 이 제어 정보 예측 태스크의 확장 가능성 및 실용성을 향상할 수 있다. 도 3은 본 개시의 실시예에 따른 정보 예측 방법을 실현하는 원리도이다. 일 실시예에서, 영상 데이터를 영상 토큰 시퀀스로 부호화하는 과정에서, 영상의 중간 크기의 입도의 일부 정보 를 손실할 수 있다. 예를 들어, 2개의 token에 대응하는 영상 블록 사이의 관련 정보를 손실하거나, 교통 신호 등 등과 같은 작은 물체가 제어 정보의 예측 정확도에 미친 영향을 손실한다. 제어 정보의 예측 정확도를 더욱 확보하여, 보조 태스크가 주요 태스크(제어 정보 예측)의 완성를 보다 잘 보조하도록 하기 위해, 본 실시예는 영상 데이터를 부호화하여 영상 토큰 시퀀스를 얻으면서, 영상 데이터의 영상 특징을 추출하고, 즉, 영상 데이 터 단위로 특징 추출하고, 추출한 특징도 생성 모델의 입력 데이터의 일부로 할 수도 있다. 도 3에 도시된 바와 같이, 실시예에서, 시퀀스 부호화 네트워크를 이용하여 영상 데이터를 부호 화하여, 영상 토큰 시퀀스를 얻을 수 있다. 본 실시예는 제1 컨볼루션 네트워크를 이용하여 영 상 데이터의 영상 특징을 추출하여, 영상 특징을 표현하는 제1 특징 벡터를 얻을 수도 있다. 본 실시 예는 또한 운전 데이터 부호화 네트워크를 이용하여 운전 데이터를 부호화하여, 운전 특징(30 5)을 얻는다. 운전 특징, 제1 특징 벡터 및 영상 토큰 시퀀스를 얻은 후, 생성 모델을 이용하여, 이러한 특징에 기초하여 보조 태스크 및 주요 태스크를 수행하고, 즉 예측된 토큰 시퀀스 및 차량에 대한 제어 정 보를 생성할 수 있다. 구체적으로, 운전 특징, 제1 특징 벡터 및 영상 토큰 시퀀스를 이어 맞춘 후 입력 특징으로, 생성 모델에 입력하고, 생성 모델에 의해 예측된 토큰 시퀀스 및 제어 정보를 출력할 수 있다. 일 실시예에서, 생성 모델은 자기 회귀 모델일 수 있다. 태스크를 수행할 때, 먼저 운전 특징 및 제1 특징 벡터를 이어맞춘 후 생성 모델에 입력하여, 생성 모델에 의해 토큰 시퀀스 중의 첫 번째 token을 예측하고, 그후 운전 특징, 제1 특징 벡터 및 이 영상 토큰 시퀀스 중의 첫 번째 영상 토큰을 이어맞춘 후 생성 모델에 입력하여, 생성 모델에 의해 토큰 시퀀스 중의 두 번째 token을 예 측할 수 있다. 이와 같이, 토큰 시퀀스를 생성할 수 있다. 마지막으로, 운전 특징, 제1 특징 벡터 및 이 영상 토큰 시퀀스를 이어맞춘 후 생성 모델에 입력하여, 생성 모델에 의해 제어 정보를 예측한다. 일 실시예에서, 생성 모델이 단일token을 예측할 때, 생성하는 데이터가 확률 벡터이고, 이 확률 벡터는 복수의 token 중 각 token의 확률을 포함한다. 본 실시예는 확률 벡터 중 가장 높은 확률에 대응하는 token을 예측한 token으로 할 수 있다. 영상 블록에 대응하는 token을 식각성 단어로 이해할 수 있다. 그렇게 하면, 확 률 벡터가 포함하는 확률 값의 수는 미리 설정된 식각성 단어의 수로 이해할 수 있다. 일 실시예에서, 운전 데이터 부호화 네트워크는 예를 들어 임베디드 층의 구성을 이용할 수 있다. 본 실시 예는 또한 임의의 시퀀스화되지 않은 네트워크로 제1 컨볼루션 네트워크를 대체할 수 있다. 여기서, 제1 컨볼루션 네트워크는 예를 들어 VGG, ResNet, MobileNet 등 네트워크 아키텍처를 이용할 수 있고, 예를 들 어 경량 컨볼루션 네트워크 아키텍처 등을 이용할 수 있으며, 본 개시는 이에 대해 제한하지 않는다. 여기서, 이 제1 컨볼루션 네트워크의 역할은 영상 데이터를 영상 특징으로 매핑하는 것이다. 예를 들어, 원본 영상의 1/2m의 공간 해상도의 영상 특징을 전개한 후 제1 특징 벡터를 얻을 수 있다. 일 실시예에서, 운전 데이터는 예를 들어 적어도 차량의 주행 파라미터 및 차량의 네비게이션 데이터의 두 부분 의 데이터를 포함할 수 있다. 본 실시예는 상이한 네트워크를 이용하여 운전 데이터 중의 상이한 부분의 데이터 를 부호화할 수 있어, 부호화된 운전 특징의 표현 능력을 향상하기에 유리하도록 한다. 이는 상이한 유형의 데 이터에 대해, 상이한 유형의 부호화 원리를 이용하면, 부호화하는 정확도를 향상할 수 있기 때문이다. 예를 들어, 네비게이션 데이터는 네비게이션 지도일 수 있다. 즉, 네비게이션 데이터는 영상 모드의 데이터일 수 있다. 본 실시예는 컨볼루션 네트워크를 이용하여 네비게이션 데이터를 부호화하여, 네비게이션 데이터를 표 현하는 제2 특징 벡터를 얻을 수 있다. 예를 들어, 주행 파라미터는 차량의 속도, 스칼라 가속도, 회전 각도 등 의 파라미터 중의 적어도 하나를 포함할 수 있다. 본 실시예는 완전 연결 층 또는 다층 퍼셉트론(Multi-layer Perceptron)을 이용하여 주행 파라미터를 부호화하여, 주행 파라미터를 표현하는 제3 특징 벡터를 얻을 수 있다. 따라서, 상술한 운전 특징은 본 실시예의 제2 특징 벡터 및 제3 특징 벡터를 포함한다. 도 4는 본 개시의 실시예에 따른 네비게이션 데이터를 부호화하는 원리 개략도이다. 도 4에 도시된 바와 같이, 일 실시예에서, 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함할 수 있다. 이 위치는 예를 들어2차원 좌표로 나타내, 목표 지점의 차량이 위치하는 도로 평면 상의 위치를 나타낸다. 예를 들어, 이 적어도 2개의 목표 지점은 2개이며, 하나는 차량의 현재 위치에 대 응하는 목표 지점이고, 다른 하나의 목표 지점은 네비게이션 경로 상의 차량의 다음 경유점으로 한다. 이 적어 도 2개의 목표 지점은 복수일 수도 있고, 네비게이션 경로 전체 또는 네비게이션 경로 상의 차량에 가까운 하나 의 서브 경로를 나타내도록 한다. 바꾸어 말하면, 실시예에서, 네비게이션 지도에서 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치만을 네비게이션 데이터로 추출할 수 있다. 그렇게 하면, 네비게이션 지도에서 네비게이션 경로 이외의 기타 정보가 예측 태스크에 대한 간섭을 감소할 수 있어, 제어 정보의 예측 정확도를 향상하기에 유리하 다. 예를 들어, 실시예에서, 네비게이션 데이터를 얻은 후, 이 적어도 2개의 목표 지점의 위치에 기초하 여, 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스크 영상을 생성할 수 있다. 마스크 영상으로 전환함으로써, 컨볼루션 네트워크를 이용하여 네비게이션 경로의 특징을 추출하기에 유리하다. 마스크 영상 을 얻은 후, 컨볼루션 네트워크를 이용하여 이 마스크 영상을 부호화하여, 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻을 수 있다. 여기서, 마스크 영상를 부호화하는 컨볼루션 네트워크는 예를 들어 ResNet 계열 네트워크, VGG 계열 네트워크 등일 수 있고, 본 개시는 이에 대해 제한하지 않는다. 본 실시예는 마스크 영상을 컨볼루션 네트 워크에 입력하여, 컨볼루션 네트워크에 의해 텐서 형태의 영상 특징을 출력할 수 있다. 영상 특징을 전개 함으로써 제2 특징 벡터를 얻을 수 있다. 도 5는 본 개시의 실시예에 따른 영상 데이터를 부호화하여 영상 토큰 시퀀스를 얻는 원리 개략도이다. 일 실시예에서, 영상 데이터를 부호화하여 영상 토큰 시퀀스를 얻는 과정에서, 예를 들어, 예측 태스크에서 확 률의 계산에 유리하기 위하여, 또한 양자화 처리를 수행하여, 얻은 영상 토큰 시퀀스를 이산화하게 할 수 있다. 예를 들어, 실시예에서, 생성 모델의 계산 효율을 향상하기에 유리하게 하기 위하여, 먼저 부호기 (Encoder)를 이용하여 영상 데이터를 부호화하여, 영상 데이터의 화소 값을 보다 효율적인 표현 공간 에 매핑하여, 정보를 압축하는 목적을 달성할 수 있다. 부호기를 이용하여 부호화함으로써, 부호화 특징 시퀀스를 얻을 수 있다. 그후, 양자화기를 이용하여 부호화 특징 시퀀스를 양자화 처리하여, 부 호화 특징 시퀀스의 연속적인 표현을 정수 값에 매핑하게 하여, 이산화 표현을 진행한다. 양자화 처리를 통해, 영상 토큰 시퀀스를 얻는다. 일 실시예에서, 부호기에 입력되는 것은 영상을 화소 분할하여 얻는 일련의 화소일 수 있다. 부호기 는 예를 들어 2차원 컨볼루션 층의 구성을 이용할 수 있다. 예를 들어, 화소에 대한 부호기의 처리는 함수 로 나타낼 수 있고, 이하의 수식을 이용하여 부호화 특징 시퀀스 (f 502)를 얻을 수 있다. 설명해야 할 것은, 실제 처리 과정에서, 입력 함수 의 변수는 영상 I를 블로화하여 얻는 화소 시퀀스이다. 수식 일 실시예에서, 양자화기는 예를 들어 하나의 코드북 을 미리 학습한 양자화 층일 수 있으며, 코드북은 K개의 벡터를 포함하고, K는 미리 설정된 식각성 단어의 수이고, C는 각 미리 설정된 식각성 단어의 임베딩 차원이다. 이 양자화기는 양자화 함수 에 의하여 부호화 특징 시퀀스(f 502)를 양자화 처리할 수 있다. 여기서, 예를 들어, 영상 I 중의 i번째 행 j번째 열의 화소에 대응하는 부호화 특징 에 대해, 이하의 수식을 이용하여 양자화 처리하여, 이 부호화 특징 에 대응하는 양자화된 특징 을 얻어, 하나의 영상 토큰으로 할 수 있다. 그렇게 하면, 각 부호화 특징을 가장 가까운 코드북 e에 포함되는 어느 벡터 에 매핑할 수 있다. 즉, 이다. 여기서, 는 코드북 e의 k번째 벡터를 나타낸다. 수식 일 실시예에서, 영상 데이터를 부호화하여, 영상 토큰 시퀀스를 얻는 스텝은 예를 들어 데이터 압축 기술인 벡 터 양자화(Vector Quantization, VQ)로 실현할 수 있다. 예를 들어, 사전 훈련된 벡터 양자화 생성 네트워크 (Vector Quantized Generative Adversarial Network, VQGAN) 또는 벡터 양자화 변분 오토 부호기(Vector Quantized Variational Auto Encoder, VQVAE) 중의 부호기를 이용하여 영상 데이터를 부호화하여, 영상 데이터 를VQ 공간 중의 이산화 벡터 표현에 매핑하도록 할 수 있고, 본 개시는 이에 대해 제한하지 않는다. 일 실시예에서, 이하의 수식을 이용하여 t 시각의 영상 를 부호화하여, 이산적인 영상 token 시퀀스를 얻 을 수 있다. 수식 여기서, 부호기 및 양자화기의 부호화 네트워크 를 포함하며, 이 부호화 네트워크는 예를 들어 16배 공간의 다운샘플링 속도를 갖는다. 여기서, , h, w는 각각 영상 I의 화소의 높이 및 너비이다. 그렇게 하면, 부호화 네트워크의 처리를 통해, 영상 데이터 I의 비트 압축비는 이다. 여기서, 3은 각 화소의 채널 수이고, 8은 각 화소가 차지하는 비트 수이다. 도 6은 본 개시의 다른 실시예에 따른 정보 예측 방법을 실현하는 원리도이다. 본 개시의 실시예에 따라, 생성 모델을 이용하여 예측 태스크를 수행할 때, 생성 모델에 입력하는 시퀀스에 태 그를 추가하여, 생성 모델에 대해 보조 태스크 및 주요 태스크를 수행하도록 프롬프트하는 역할을 할 수 있다. 예를 들어, 보조 태스크는 입력된 영상 토큰 시퀀스에 대해 재생성하는 태스크가면, 즉, 입력된 영상 토큰 시퀀 스는 t 시각의 영상 데이터를 표현하면, 보조 태스크는 t 시각의 영상 데이터를 표현하는 token 시퀀스를 예측 하는 태스크일 수 있다. 상술한 실시예에 의해 얻은 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하여, 생 성 모델을 이 시작 태그에 기초하여 t 시각의 영상 데이터를 표현하는 token 시퀀스 중의 첫 번째token을 예측 하도록 할 수 있다. 여기서, 시작 태그는 예를 들어 <c> 등의 미리 정의된 태그일 수 있고, 본 개시는 이에 대 해 제한하지 않는다. 예를 들어, 또한, 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 생성 모델에 영상 토큰 시퀀스가 이 미 모두 입력되었고, 주요 태스크의 실행, 즉 차량에 대한 제어 정보의 예측을 시작 가능함을 프롬프트할 수 있 다. 여기서, 쿼리 태그는 예를 들어 <a> 등의 미리 정의된 태그일 수 있고, 본 개시는 이에 대해 제한하지 않는 다. 일 실시예에서, 영상 토큰 시퀀스의 헤드 위치 및 꼬리 위치 모두에 태그를 추가하여, 태그된 토큰 시퀀스를 얻 을 수 있다. 그후, 예를 들어 상술한 실시예에 얻은 운전 특징과 태그된 토큰 시퀀스를 이어맞춰, 생성 모델의 입력 시퀀스를 얻을 수 있다. 그후, 입력 시퀀스를 생성 모델에 입력하면, 생성 모델에 의해 예측 토큰 시퀀스 (즉 t 시각의 영상 데이터를 표현하는 token 시퀀스) 및 제어 정보를 생성할 수 있다. 일 실시예에서, 보조 태스크 및 주요 태스크를 수행할 때, 예를 들어 또한 상술한 실시예에서 얻은 영상 특징을 표현하는 제1 특징 벡터를 동시에 고려할 수 있다. 일 실시예에서, 운전 데이터는 상술한 주행 파라미터 및 네비게이션 데이터를 포함할 수 있다. 제2 컨볼루션 네 트워크를 이용하여 네비게이션 데이터를 부호화하고, MLP를 이용하여 주행 파라미터를 부호화할 수 있다. 예를 들어, 도 6에 도시된 바와 같이, 실시예에서, 취득된 감지 데이터는 영상 데이터 및 운전 데이 터를 포함한다. 자율주행 모델에 의해 감지 데이터를 처리하여, 예측 토큰 시퀀스 및 차량에 대한 제어 정보를 생성할 수 있다. 여기서, 자율주행 모델은 부호화 층 및 생성 모델을 포함할 수 있다. 여기서, 부호화 층은 영상 데이터 , 주행 파라미터 및 네비게이션 데이터를 각각 부호화하기 위한 네트워크를 포함할 수 있다. 일 실시예에서, 부호화 층은, 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스 를 얻기 위한 시퀀스 부호화 네트워크를 포함한다. 일 실시예에서, 부호화 층은 운전 데이터 부호화 네트워크를 또한 포함할 수 있다. 이 운전 데이터 부호화 네트 워크는 운전 데이터를 부호화하여, 운전 특징을 얻기 위해 사용된다. 일 실시예에서, 운전 데이터는 주행 파라 미터 및 네비게이션 데이터를 포함할 수 있다. 운전 데이터 부호화 네트워크는 다층 퍼셉트론 MLP 및 제2 컨볼루션 네트워크를 포함할 수 있다. 다층 퍼셉트론 MLP는 주행 파라미터를 부호화하여, 제3 특징 벡터를 얻기 위해 사용된다. 제2 컨볼루션 네트워크는 네비게이션 데이터(60 3)를 부호화하여, 제2 특징 벡터를 얻기 위해 사용된다. 예를 들어, 주행 파라미터는 t 시각의 속도 를 포함하는 것을 예로 하여, 다층 퍼셉트론 MLP는 예를 들 어 이하의 수식을 이용하여 주행 파라미터를 부호화하여, 제3 특징 벡터 를 얻을 수 있다. 여기서, 는 다층 퍼셉트론이 이용하는 함수이다. 수식 예를 들어, 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함하는 것으로 설정 한다. 상술한 실시예를 이용하여 설명된 원리를 예로 하여, 제2 컨볼루션 네트워크는 이하의 수식 을 이용하여 제2 특징 벡터 를 얻을 수 있다. 여기서, 는 적어도 2개의 목표 지점의 위치에 기초하여, 생성되는 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스크 영상이다. 는 제2 컨볼루션 네트워크 가 이용하는 함수이다. 수식 일 실시예에서, 부호화 층은, 또한, 영상 데이터의 영상 특징을 추출하여, 이 영상 특징을 표현하는 제1 특징 벡터를 얻기 위한 제1 컨볼루션 네트워크를 포함할 수 있다. 이 제1 컨볼루션 네트워크는 비 양자화 갈래로서, 영상 데이터에서 운전에 관련한 정보를 추출기 위해 사용될 수 있다. 예를 들어, 제1 컨볼루션 네트워크는 경량 컨볼루션 네트워크 를 이용하여, 영상 데이터의 공간 해상도의 영상 특징을 취득할 수 있다. 이 영상 특징은 전개되고 제어 정보를 예측할 때 고려되는 프롬프트 정보로 할 수 있다. 예를 들어, t 시각의 영상 데이터 에 대해, 제1 컨볼루션 네트워크는 이하의 수식을 이용하여 제1 특징 벡터 를 얻을 수 있다. 여기서, , 는 공간 해상도에서의 영상 특징의 화소 높이및 화소 너비이다. 수식 일 실시예에서, 감지 데이터 부호화하는 과정에서, 학습 가능한 위치 정보를 결합할 수도 있다. 이 학습 가능한 위치 정보는 Transformer 아키텍처에 입력할 때token에 대해 추가하는 위치 태그와 유사하다. 일 실시예에서, 감지 데이터에 대한 부호화가 완료후, 예를 들어 부호화하여 얻은 각 벡터, 시퀀스에 기초하여, 생성 모델의 입력 시퀀스를 얻을 수 있다. 예를 들어, 또한, 먼저 영상 토큰 시퀀스의 헤드 위치에 시작 태그<c>를 추가하고, 영상 토큰 시퀀스(60 4)의 꼬리 위치에 쿼리 태그<a>를 추가하여, 태그된 토큰 시퀀스를 얻으며, 그후에, 얻은 벡터, 시퀀스를 순서대로 순차적으로 생성 모델에 입력할 수 있다. 여기서, t 시각은 현재 시각으 로 이해될 수 있다. 일 실시예에서, 생성 모델은 예를 들어 자기 회귀 모델을 이용할 수 있다. 이는 자기 회귀 모델은 다양한 프롬프트를 받아들이는 유연성을 갖고, 계열 모델(예를 들어 생성형 사전 훈련 모델GPT 등)은 확장 가능성을 갖 기 때문이다. 본 실시예에서, 먼저 를 입력 시퀀스로 생성 모델에 입력하고, 생성 모델 에 의해 입력 시퀀스를 기초로 예측하여 예측 토큰 시퀀스 중의 첫 번째 token의 확률 벡터를 얻을 수 있 다. 본 실시예는 이 확률 벡터 중의 최대 확률 값에 대응하는 token을 예측 토큰 시퀀스 중의 첫 번째 token으 로 할 수 있다. 그후, 본 실시예는 및 중의 첫 번째 영상 토큰을 입력 시퀀스로 생성 모 델에 입력하고, 생성 모델에 의해 예측하여 예측 토큰 시퀀스 중의 두 번째 token의 확률 벡터를 얻 을 수 있다. 본 실시예는 이 확률 벡터 중의 최대 확률 값에 대응하는 token을 예측 토큰 시퀀스 중의 두 번째 token으로 할 수 있다. 이와 같이, 및 중 마지막 하나의 영상 토큰 이외의 모든 영상 토 큰을 생성 모델에 입력하여, 예측 토큰 시퀀스 중의 마지막 하나의 token을 얻을 수 있다. 마지막으로, 본 실시예는 를 입력 시퀀스로 생성 모델에 입력하여, 생성 모델에 의해 예측하여 차량 에 대한 t+1 시각의 제어 정보를 얻을 수 있다. 본 개시의 실시예에 의해, 자율주행 모델을 통해, 제어 정보의 엔드 투 엔드 예측을 실현할 수 있다. 또한, 영 상 생성 태스크를 보조 태스크으로 주요 태스크의 실시를 안내하기 때문에, 복잡한 감지 태스크 및 비싼 감지 라벨링에 의존할 필요가 없고, 엔드 투 엔드의 자율주행 기술에 대해 저비용이고 확장 가능한 해결 방안을 제공 할 수 있다. 본 개시의 실시예의 정보 예측 방법의 실시를 용이하게 하기 위해, 본 개시는 또한 자율주행 모델의 훈련 방법 을 제공한다. 이하 도 7을 결합하여 이 훈련 방법을 자세하게 설명할 것이다. 도 7은 본 개시의 실시예에 따른 자율주행 모델의 훈련 방법의 흐름 개략도이다. 도 7에 도시된 바와 같이, 본 실시예의 자율주행 모델의 훈련 방법은 동작 S710~동작 S740을 포함할 수 있 다. 여기서, 자율주행 모델은 부호화 층 및 생성 모델을 포함할 수 있다. 여기서, 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함할 수 있다. 동작 S710에서, 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 영상 데 이터에 대응하는 영상 토큰 시퀀스를 얻는다. 본 개시의 실시예에 따라, 샘플 감지 데이터는 과거 시각에서 수집된 영상 데이터, 영상 데이터가 수집되는 시 각에서의 차량의 운전 데이터를 포함한다. 시퀀스 부호화 네트워크는 예를 들어 영상에 대해 블록화 처리를 수핸하는 구성 및 2차원 컨볼루션 층을 포함하 고, 상술한 동작 S220에 설명된 원리와 유사한 원리를 통해, 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 영상 토큰 시퀀스를 얻을 수 있다. 일 실시예에서, 시퀀스 부호화 네트워크는 벡터 양자화 압축 기술을 이용하 여 영상 데이터를 부호화할 수 있다. 동작 S720에서, 운전 데이터 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 운 전 데이터에 대응하는 운전 특징을 얻는다. 본 개시의 실시예에 따라, 이 동작 S720의 실현 원리는 상술한 동작 S220의 실현 원리와 유사하고, 여기에서는 더 이상 설명하지 않을 것이다. 운전 데이터 부호화 네트워크는 임베디드 층의 구성을 이용할 수 있고, 상술한 실시예에 도시된 바와 같이, MLP 및 컨볼루션 네트워크를 포함할 수도 있다. 동작 S730에서, 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대 응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성한다. 본 개시의 실시예에 따라, 이 동작 S730의 실현 원리는 상술한 동작 S230의 실현 원리와 유사하다. 설명해야 할 것은, 생성 모델이 자기 회귀 모델인 경우, 생성 모델이 생성하는 것은 예측 토큰 시퀀스 중의 token에 일대일 로 대응하는 일련의 확률 벡터이다. 본 실시예는 확률 벡터 중 최대 확률 값에 대응하는 token을, 예측 토큰 시 퀀스 중 이 확률 벡터가 대응하는 token로 할 수 있다. 동작 S740에서, 예측 토큰 시퀀스와 영상 토큰 시퀀스에 따라, 자율주행 모델을 훈련한다. 예를 들어, 본 실시예는 예측 토큰 시퀀스와 영상 토큰 시퀀스 사이의 차이에 따라, 자율주행 모델의 손실 값을 결정할 수 있다. 그후 이 손실 값을 최소화하는 것을 목표로 하여, 자율주행 모델을 훈련한다. 일 실시예에서, 생성 모델이 생성하는 것은 일련의 확률 벡터인 경우, 본 실시예는 i번째 확률 벡터 중 영상 토 큰 시퀀스 중의 i번째 영상 토큰에 대응하는 확률 값에 따라, 자율주행 모델의 손실 값을 결정할 수 있다. 예를 들어 분류 손실 함수를 이용하여 이 손실 값을 계산할 수 있다. 예를 들어, 생성 모델이 자기 회귀 모델인 실시예에 대해, 자기 회귀 모델링의 원리는, 일련의 이산적인 태그가 주어진 경우, i번째 이산적인 태그의 생성 확률은 이 i번째 이산적인 태그 앞에 위치한 모든 태그 시퀀스에 달 린다. 이를 고려하여, 교차 엔트로피 손실 함수를 이용하는 것을 예로, 본 실시예는 이하의 수식을 이용하여 확률 벡터에 기초하여 자율주행 모델의 손실 값 을 결정할 수 있다. 여기서, 는 t 시각의 영상에 대해 생성하는 i번째 확률 벡터 중 i번째 영상 토큰에 대한 확률 값이다. 수식 설명해야 할 것은, 이 확률 값 은 t 시각의 운전 데이터 등과도 관련하고, 수식에 반영되지 않는다. n은 영상 토큰 시퀀스 중의 영상 토큰의 개수이다. 본 실시예에 의해, 감독 신호로 되는 것은 샘플 감지 데이터 중의 영상 데이터 자체이므로, 정확한 감지 라벨링 데이터가 필요없고, 따라서 자율주행 모델의 자기 감독 훈련을 실현할 수 있다. 일 실시예에서, 자율주행 모델을 훈련할 때, 예를 들어 자율주행 모델 중의 시퀀스 부호화 네트워크가 포함하는 네트워크 파라미터를 조정하지 않아도 되고, 따라서 감독 신호인 영상 토큰 시퀀스의 안정성을 향상하는 데 편 리하고, 자율주행 모델의 훈련 정확도 및 훈련 효율을 향상하기에 유리하다. 일 실시예에서, 샘플 감지 데이터는 예를 들어 t 시각의 감지 데이터외에도, t 시각 이전의 여러 시각의 감지 데이터를 포함할 수 있다. 각 시각의 감지 데이터에 대해서, 모두 유사한 방식을 이용하여 영상 토큰 시퀀스 및 운전 특징을 얻을 수 있다. 생성 모델이 예측하여 예측 토큰 시퀀스 및 t+1 시각의 제어 정보를 얻을 때, 이 t 시각 이전의 여러 시각의 감지 데이터를 동시에 고려허여, 예측 정확도를 향상할 수 있다. 예를 들어, 샘플 감지 데이터는 과거 시각 중 제1 시각~제T 시각의 감지 데이터를 포함하면, 자율주행 모델을 훈련하는 과정에서, 먼저 제1 시각의 감지 데이터에 따라, 제1 시각의 영상 데이터에 대응하는 예측 토큰 시퀀 스를 예측할 수 있고, 이 예측 토큰 시퀀스에 따라, 하나의 손실 값을 얻을 수 있다. 그후, 제1 시각의 감지 데 이터 및 제2 시각의 감지 데이터에 따라, 제2 시각의 영상 데이터에 대응하는 예측 토큰 시퀀스를 예측하고, 이 예측 토큰 시퀀스에 따라, 하나의 손실 값을 얻을 수 있다. 이와 같이, T개의 손실 값을 얻을 수 있다. 본 실시 예는 T개의 손실 값의 합을, 자율주행 모델이 토큰 시퀀스를 생성하는 손실 값으로 할 수 있다. 이 손실 값을 최소화하는 것을 목표로 하여, 자율주행 모델을 훈련한다. 일 실시예에서, 자율주행 모델이 수행하는 주요 태스크(제어 정보 예측)에 감독 신호를 추가할 수도 있다. 예를 들어, 샘플 감지 데이터는 실제 제어 정보를 또한 포함할 수 있다. 구체적으로, 샘플 감지 데이터는 t 시각의 감지 데이터를 포함하면, 이 t 시각의 감지 데이터는 t+1 시각의 실제 제어 정보를 나타내는 라벨을 가질 수 있다. 본 실시예는 자율주행 모델을 훈련할 때, 실제 제어 정보와 예측 제어 정보 사이의 차이를 또한 고려할 수 있다. 예를 들어, 회귀 손실 함수를 이용하여 자율주행 모델이 예측 제어 정보를 생성하는 손실 값을 결정할 수 있다. 예를 들어, 실제 제어 정보를 , 를 예측 제어 정보로 설정하고, 본 실시예는 이하의 수 식을 이용하여 예측 제어 정보를 생성하는 손실 값 을 계산할 수 있다. 설명해야 할 것은, 예측 제 어 정보 는 t 시각의 운전 데이터 등과도 관련되고, 또한 t 시각 이전의 영상 데이터 및 운전 데이터 등과 관련될 수 있으며, 여기서 표현식에는 반영되지 않는다. 회귀 손실 함수는 예를 들어 L1 손실 함수, L2 손 실 함수 등을 포함할 수 있고, 본 개시는 이에 대해 제한하지 않는다. 수식 예를 들어, 샘플 감지 데이터는 과거 시각 중 제1 시각~제T 시각의 감지 데이터를 포함하면, 자율주행 모델을 훈련하는 과정에서, 먼저 제1 시각의 감지 데이터에 따라, 제2 시각의 제어 정보를 예측할 수 있고, 이 예측한 제어 정보와 제2 시각의 실제 제어 정보에 따라, 제어 정보를 생성하는 하나의 손실 값을 얻을 수 있다. 그후, 제1 시각의 감지 데이터 및 제2 시각의 감지 데이터에 따라, 제3 시각의 제어 정보를 예측하고, 이 예측한 제어 정보와 제3 시각의 실제 제어 정보에 따라, 제어 정보를 생성하는 하나의 손실 값을 얻을 수 있다. 이와 같이, T개의 손실 값을 얻을 수 있다. 본 실시예는 T개의 손실 값의 합을, 자율주행 모델이 제어 정보를 생성하는 손 실 값으로 할 수 있다. 이 손실 값을 최소화하는 것을 목표로 하여, 자율주행 모델을 훈련한다. 일 실시예에서, 자율주행 모델에 의해 제어 정보를 생성하는 손실 값 및 예측 토큰 시퀀스를 생성하는 손실 값 을 동시에 고려할 수 있다. 예를 들어, 두 부분의 손실 값의 가중 합을 자율주행 모델의 총 손실 값으로 할 수 있다. 이 총 손실 값을 최소화하는 것을 목표로 하여, 자율주행 모델을 훈련한다. 여기서, 가중 시 이용되는 가 중치는 실제 필요에 따라 설정할 수 있다. 예를 들어, 예측 토큰 시퀀스를 생성하는 태스크는 보조 태스크인 것 을 고려하면, 손실 값 에 작은 가중치를 할당할 수 있고, 본 개시는 이에 대해 제한하지 않는다. 일 실시예에서, 상술한 부호화 층은 제1 컨볼루션 네트워크를 또한 포함할 수 있다. 이 제1 컨볼루션 네트워크 는 상술한 실시예에서의 제1 컨볼루션 네트워크와 유사하다. 본 실시예는 제1 컨볼루션 네트워크를 이용하 여 영상 데이터의 영상 특징을 추출하여, 영상 특징을 표현하는 제1 특징 벡터를 얻을 수 있다. 그후, 운전 특 징, 제1 특징 벡터 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 예측 토큰 시퀀스 및 예측 제어 정 보를 생성한다. 일 실시예에서, 운전 데이터는 차량의 과거 주행 파라미터 및 차량의 과거 네비게이션 데이터를 포함할 수 있다. 운전 데이터 부호화 네트워크는 상술한 실시예에서의 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포 함할 수 있다. 제2 컨볼루션 네트워크를 이용하여 과거 네비게이션 데이터를 부호화하여, 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻을 수 있다. 다층 퍼셉트론을 이용하여 과거 주행 파라미터를 부호화하여, 주행 파 라미터를 표현하는 제3 특징 벡터를 얻을 수 있다. 상술한 운전 특징은 이 제2 특징 벡터 및 제3 특징 벡터를 포함한다. 일 실시예에서, 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함한다. 시퀀스 부호화 네트워크는 상술한 실시예에 설명된 원리와 유사한 원리를 이용하여, 영상 데이터를 부호화하여, 영상 토큰 시퀀스를 얻을 수 있다. 일 실시예에서, 생성 모델이 예측 토큰 시퀀스 및 예측 제어 정보를 생성하는 원리는 상술한 실시예에서 설명된 원리와 유사하고, 여기에서는 더 이상 설명하지 않을 것이다. 일 실시예에서, 자율주행 모델의 훈련 방법은, 2개의 태스크를 통해 자율주행 모델을 훈련할 수 있다. 하나의 태스크는 다음의 token의 자기 회귀 생성 태스크(즉 예측 토큰 시퀀스를 생성하는 태스크), 다른 하나는 플래너 (Planner)(예를 들어 브레이크, 가속 페달, 스티어링 휠 등)의 동작 예측(즉 제어 정보를 예측하는 태스크)이다. 상이한 출력 헤드를 제외하고, 이 2개의 태스크는 대부분의 네트워크 파라미터를 공유한다. 그렇 게 하면, 생성 태스크를 위해 공유 파라미터를 최적화할 때, 모델은 입력 token 사이의 의존 관계를 잘 학습하 여, 좋은 환경 표현을 구축하고, 동작 예측 태스크의 실시에 유리하다. 본 개시가 제공한 정보 예측 방법에 기초하여, 본 개시는 정보 예측 장치를 또한 제공한다. 이하 도 8을 결합하 여 이 장치를 자세하게 설명할 것이다. 도 8은 본 개시의 실시예에 따른 정보 예측 장치의 구성 블록도이다. 도 8에 도시된 바와 같이, 본 실시예의 정보 예측 장치는 데이터 취득 모듈, 제1 부호화 모듈, 제2 부호화 모듈 및 제1 생성 모듈을 포함할 수 있다. 데이터 취득 모듈은 감지 데이터를 취득하기 위해 사용되고, 이 감지 데이터는 차량 내의 센서가 수집한 영상 데이터 및 차량의 운전 데이터를 포함한다. 일 실시예에서, 데이터 취득 모듈은 전문에 설명된 동작 S210을 수행기 위해 사용될 수 있고, 여기에서는 더 이상 설명하지 않을 것이다. 제1 부호화 모듈은 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사 용된다. 일 실시예에서, 제1 부호화 모듈은 전문에 설명된 동작 S220을 수행하기 위해 사용될 수 있고, 여 기에서는 더 이상 설명하지 않을 것이다. 제2 부호화 모듈은 운전 데이터를 부호화하여, 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용된다. 일 실시예에서, 제2 부호화 모듈은 전문에 설명된 동작 S230을 수행하기 위해 사용될 수 있고, 여기에서는 더 이상 설명하지 않을 것이다. 제1 생성 모듈은 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 제어 정보를 생성하기 위해 사용된다. 일 실시예에서, 제1 생성 모 듈은 전문에 설명된 동작 S240을 수행하기 위해 사용될 수 있고, 여기에서는 더 이상 설명하지 않을 것이다. 본 개시의 실시예에 따라, 영상 토큰 시퀀스는 영상 데이터의 이산적인 특징이다. 상술한 정보 예측 장치 는, 제1 컨볼루션 네트워크를 이용하여 영상 데이터의 영상 특징을 추출하여, 영상 특징을 표현하는 제1 특징 벡터를 얻기 위한 제1 특징 추출 모듈을 또한 포함할 수 있다. 구체적으로, 상술한 제1 생성 모듈은 운전 특징, 제1 특징 벡터 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 예측 토큰 시퀀스 및 제어 정보를 생성하기 위해 사용될 수 있다. 본 개시의 실시예에 따라, 상술한 운전 데이터는 차량의 주행 파라미터 및 차량의 네비게이션 데이터를 포함한 다. 상술한 제2 부호화 모듈은 제1 부호화 서브 모듈 및 제2 부호화 서브 모듈을 포함할 수 있다. 제1 부 호화 서브 모듈은 제2 컨볼루션 네트워크를 이용하여 네비게이션 데이터를 부호화하여, 네비게이션 데이터를 표 현하는 제2 특징 벡터를 얻기 위해 사용된다. 제2 부호화 서브 모듈은 다층 퍼셉트론을 이용하여 주행 파라미터 를 부호화하여, 주행 파라미터를 표현하는 제3 특징 벡터를 얻기 위해 사용된다. 여기서, 운전 특징은 제2 특징 벡터 및 제3 특징 벡터를 포함한다. 본 개시의 실시예에 따라, 상술한 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함할 수 있다. 상술한 제1 부호화 서브 모듈은 영상 생성 유닛 및 영상 부호화 유닛을 포함할 수 있다. 영상 생성 유닛은 적어도 2개의 목표 지점의 위치에 기초하여, 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마 스크 영상을 생성하기 위해 사용된다. 영상 부호화 유닛은 제2 컨볼루션 네트워크를 이용하여 마스크 영상을 부 호화하여, 제2 특징 벡터를 얻기 위해 사용된다. 본 개시의 실시예에 따라, 상술한 제1 부호화 모듈은 제3 부호화 서브 모듈 및 제1 양자화 서브 모듈을 포 함할 수 있다. 제3 부호화 서브 모듈은 부호기를 이용하여 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻 기 위해 사용된다. 제1 양자화 서브 모듈은 양자화기를 이용하여 부호화 특징 시퀀스를 양자화 처리하여, 영상 토큰 시퀀스를 얻기 위해 사용된다. 본 개시의 실시예에 따라, 상술한 제1 생성 모듈은 제1 태그 추가 서브 모듈, 제1 시퀀스 획득 서브 모듈 및 제 1 생성 서브 모듈을 포함할 수 있다. 제1 태그 추가 서브 모듈은 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용된다. 제1 시퀀스 획득 서브 모듈은 운전 특징 및 태그된 토큰 시퀀스에 기초하여, 생성 모델의 입력 시퀀스를 얻기 위해 사용된다. 제1 생성 서브 모듈은 입력 시퀀스를 생성 모델에 입력하여, 생성 모델이 생성하는 예측 토큰 시퀀스 및 제어 정보를 얻기 위해 사용된다. 본 개시가 제공한 자율주행 모델의 훈련 방법에 기초하여, 본 개시는 자율주행 모델의 훈련 장치를 또한 제공한 다. 이하 도 9를 결합하여 이 장치를 자세하게 설명할 것이다. 도 9는 본 개시의 실시예에 따른 자율주행 모델의 훈련 장치의 구성 블록도이다. 도 9에 도시된 바와 같이, 본 실시예의 자율주행 모델의 훈련 장치는 제3 부호화 모듈, 제4 부호화 모듈, 제2 생성 모듈 및 훈련 모듈을 포함할 수 있다. 여기서, 자율주행 모델은 부호화 층 및 생성 모델을 포함하고, 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함한다. 제3 부호화 모듈은 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용된다. 일 실시예에서, 제3 부호화 모듈은 전문 에 설명된 동작 S710을 수행하기 위해 사용될 수 있고, 여기에서는 더 이상 설명하지 않을 것이다. 제4 부호화 모듈은 운전 데이터 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 운전 데이터를 부호화 하여, 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용된다. 일 실시예에서, 제4 부호화 모듈은 전문 에 설명된 동작 S720을 수행하기 위해 사용될 수 있고, 여기에서는 더 이상 설명하지 않을 것이다. 제2 생성 모듈은 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하기 위해 사용된다. 일 실시예에서, 제2 생 성 모듈은 전문에 설명된 동작 S730을 수행하기 위해 사용될 수 있고, 여기에서는 더 이상 설명하지 않을 것이다. 훈련 모듈은 예측 토큰 시퀀스와 영상 토큰 시퀀스에 따라, 자율주행 모델을 훈련하기 위해 사용된다. 일 실시예에서, 훈련 모듈은 전문에 설명된 동작 S740을 수행하기 위해 사용될 수 있고, 여기에서는 더 이상 설명하지 않을 것이다. 본 개시의 실시예에 따라, 샘플 감지 데이터는 실제 제어 정보를 또한 포함한다. 상술한 훈련 모듈은 또한 실제 제어 정보와 예측 제어 정보 사이의 차이에 따라, 자율주행 모델을 훈련하기 위해 사용될 수 있다. 본 개시의 실시예에 따라, 상술한 훈련 모듈은 구체적으로 자율주행 모델 중 시퀀스 부호화 네트워크 이외 의 기타 모델 구조를 훈련하기 위해 사용된다. 본 개시의 실시예에 따라, 부호화 층은 제1 컨볼루션 네트워크를 또한 포함한다. 상술한 자율주행 모델의 훈련 장치는, 제1 컨볼루션 네트워크를 이용하여 영상 데이터의 영상 특징을 추출하여, 영상 특징을 표현하는 제1 특징 벡터를 얻기 위한 제2 특징 추출 모듈을 또한 포함할 수 있다. 구체적으로, 상술한 제2 생성 모듈 은 운전 특징, 제1 특징 벡터 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 예측 토큰 시퀀스 및 예측 제어 정보를 생성하기 위해 사용된다. 본 개시의 실시예에 따라, 상술한 운전 데이터는 차량의 과거 주행 파라미터 및 차량의 과거 네비게이션 데이터 를 포함하고, 운전 데이터 부호화 네트워크는 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포함한다. 상술한 제4 부호화 모듈은 제4 부호화 서브 모듈 및 제5 부호화 서브 모듈을 포함할 수 있다. 제4 부호화 서브 모듈은 제2 컨볼루션 네트워크를 이용하여 과거 네비게이션 데이터를 부호화하여, 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻기 위해 사용된다. 제5 부호화 서브 모듈은 다층 퍼셉트론을 이용하여 과거 주행 파라미터를 부 호화하여, 주행 파라미터를 표현하는 제3 특징 벡터를 얻기 위해 사용된다. 상술한 운전 특징은 제2 특징 벡터 및 제3 특징 벡터를 포함한다. 본 개시의 실시예에 따라, 상술한 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함한다. 상술한 제3 부호 화 모듈은 제6 부호화 서브 모듈 및 제2 양자화 서브 모듈을 포함할 수 있다. 제6 부호화 서브 모듈은 부 호기를 이용하여 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻기 위해 사용된다. 제2 양자화 서브 모듈 은 양자화기를 이용하여 부호화 특징 시퀀스를 양자화 처리하여, 영상 토큰 시퀀스를 얻기 위해 사용된다. 여기 서, 시퀀스 부호화 네트워크는 벡터 양자화의 압축 기술에 기초하여 상기 영상 데이터를 처리한다. 본 개시의 실시예에 따라, 상술한 제2 생성 모듈은 제2 태그 추가 서브 모듈, 제2 시퀀스 획득 서브 모듈 및 제2 생성 서브 모듈을 포함할 수 있다. 제2 태그 추가 서브 모듈은 영상 토큰 시퀀스의 헤드 위치에 시작 태 그를 추가하고, 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용 된다. 제2 시퀀스 획득 서브 모듈은 운전 특징 및 태그된 토큰 시퀀스에 기초하여, 생성 모델의 입력 시퀀스를 얻기 위해 사용된다. 제2 생성 서브 모듈은 입력 시퀀스를 생성 모델에 입력하여, 생성 모델이 생성하는 예측 토큰 시퀀스 및 예측 제어 정보를 얻기 위해 사용된다. 여기서, 생성 모델은 자기 회귀 모델을 포함한다. 설명해야 할 것은, 본 개시의 기술 방안에서, 언급된 사용자 개인 정보의 수집, 저장, 사용, 가공, 전송, 제공, 공개 및 적용과 관련된 처리는 관련 법률 및 규정에 부합하고 필요한 기밀 조치를 취했으며 공서 양속을 위반하 지 않는다. 본 개시의 기술 방안에서, 사용자의 개인 정보를 취득 또는 수집하기 전에 사용자의 허가 또는 동의를 얻었다. 본 개시의 실시예에 따르면, 본 개시는 또한 전자 기기와 판독 가능 저장 매체와 컴퓨터 프로그램 제품을 제공 한다. 도 10은 본 개시의 실시예의 정보 예측 방법 또는 자율주행 모델의 훈련 방법을 실현할 수 있는 전자 기기 의 블록도를 예시적으로 도시하는 것이다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크 스테이션, 개인 휴대 정보 단말기, 서버, 블레이드 서버, 메인 프레임 컴퓨터 및 다른 적합한 컴퓨터 등 다양한 형태의 디 지털 컴퓨터를 의미한다. 전자 기기는 개인 디지털 프로세서, 셀룰러 전화, 스마트 폰, 웨어러블 디바이스 및 다른 유형의 컴퓨팅 장치 등 다양한 형태의 이동 장치를 의미할 수도 있다. 본 문장에 개시되는 부품, 이들의 연결과 관계 및 이들의 기능은 오직 예시일 뿐이고, 본 문장에서 설명 및/또는 요구되는 본 개시의 실현을 제한 하는 것은 아니다. 도 10에 도시된 바와 같이, 전자 기기에는 리드 온리 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛으로부터 랜덤 액세스 메모리(RAM)로 로딩되는 컴퓨터 프로그램에 근거하여 여러가지 적 합한 동작과 처리를 실행할 수 있는 컴퓨팅 유닛이 포함된다. RAM에는, 전자 기기의 동작에 필요한 다양한 프로그램 및 데이터가 더 저장 될 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스 를 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스에 연결된다. 전자 기기에서의 복수의 부품은 I/O 인터페이스에 연결되며, 상기 부품에는, 예를 들면 키보드, 마 우스 등과 같은 입력 유닛, 예를 들면 다양한 유형의 디스플레이, 스피커 등과 같은 출력 유닛, 예 를 들면 디스크, 광 디스크 등과 같은 저장 유닛; 및 예를 들면 네트워크 카드, 모뎀(modem), 무선통신 송수신기 등과 같은 통신 유닛이 포함된다. 통신 유닛은 전자 기기가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 텔레콤 네트워크를 통해 기타 기기와 정보/데이터를 교환할 수 있도록 허용한다. 컴퓨팅 유닛은 처리 능력과 컴퓨팅 능력을 갖는 다양한 범용 및/또는 전용 처리 컴포넌트일 수 있다. 컴 퓨팅 유닛의 일부 예시에는, 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공지능(AI) 컴 퓨팅 칩, 머신 러닝 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 프로세서(DSP) 및 임의의 적합 한 프로세서, 컨트롤러, 마이크로 컨트롤러 등이 포함되지만 이에 한정되는 것은 아니다. 컴퓨팅 유닛은, 예를 들면, 정보 예측 방법 또는 자율주행 모델의 훈련 방법과 같은 위에서 설명된 각 방법과 처리를 실행한다. 예를 들면, 일부 실시예에서, 정보 예측 방법 또는 자율주행 모델의 훈련 방법은 컴퓨터 소프트웨어 프로그램으 로 구현되어, 저장 유닛과 같은 기계 판독가능 매체에 유형적으로 포함될 수 있다. 일부 실시예에서, 컴 퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 거쳐 전자 기기에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되어 컴퓨팅 유닛에 의해 실행될 경우, 위에서 설명 한 정보 예측 방법 또는 자율주행 모델의 훈련 방법의 하나 이상의 단계를 실행할 수 있다. 선택적으로, 기타 실시예에서, 컴퓨팅 유닛은 기타 임의의 적합한 방식(예를 들면, 펌웨어를 이용함)을 통해 정보 예측 방 법 또는 자율주행 모델의 훈련 방법을 실행하도록 구성될 수 있다. 본 문에서 상기 설명한 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 현장 프로그래밍 가능 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스템 온 칩 시스템 (SOC), 복잡 프로그래밍 가능 로직 디바이스(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합 에서 실현될 수 있다. 상기 다양한 실시형태는 다음과 같은 내용을 포함할 수 있다. 하나 이상의 컴퓨터 프로그 램에서 실시되고, 상기 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그래밍 가능 프로세서를 포함하는 프 로그래밍 가능 시스템에서 실행 및/또는 해석될 수 있다. 상기 프로그래밍 가능 프로세서는 전용 또는 범용 프 로그래밍 가능 프로세서일 수 있으며, 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부 터 데이터 및 명령어를 수신하며, 또한 상기 저장 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장 치에 데이터 및 명령어를 전송할 수 있다. 본 발명의 방법을 실시하기 위한 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합을 적용하여 작성 할 수 있다. 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 시 흐름도 및/또는 블록도에서 규정된 기 능/동작이 실시되도록, 이러한 프로그램 코드를 범용 컴퓨터, 전용 컴퓨터 또는 기타 프로그래밍 가능 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공할 수 있다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적 으로 기계에서 실행되거나, 개별적인 소프트웨어 패키지(Software Package)로서 부분적으로 기계에서 실행되며, 부분적으로 원격 기계에서 실행되거나, 완전히 원격 기계 또는 서버에서 실행될 수 있다. 본 발명의 문맥에서, 기계 판독가능 매체는 유형적인 매체일 수 있다. 상기 기계 판독가능 매체에는, 명령어 실 행 시스템, 장치 또는 기기에 사용되거나 또는 명령어 실행 시스템, 장치 또는 기기와 결합하여 사용되도록 제 공되는 프로그램이 포함되거나 저장될 수 있다. 기계 판독가능 매체는 기계 판독가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독가능 매체에는, 전자, 자성, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적합한 조합이 포함될 수 있지만 이에 한정되는 것은 아니다. 기계 판독가능 저장 매체의 더 구체적인 예시에는 하나 이상의 와이어에 의한 전기적인 연결, 휴대용 컴퓨터 디스크, 하드디스크, 랜덤 액세스 메모리(RAM), 리드 온리 메모리(ROM), 소거 가능 및 프로그램 가능 리드 온리 메모리 (EPROM 또는 플래시 메모리), 광섬유，휴대용 콤팩트 디스크 리드 온리 메모리(CD-ROM), 광학 저장 장치, 자기 저장 장치 또는 상기 내용의 임의의 적합한 조합이 포함될 수 있다. 사용자와의 인터랙션을 제공하기 위해, 여기에서 설명하는 시스템과 기술을 컴퓨터에서 실행할 수 있다. 상기 컴퓨터는 사용자에게 정보를 표시하기 위한 디스플레이 장치(예를 들면, CRT(음극선관) 또는 LCD(액정 디스플레 이) 모니터) 및 키보드, 포인팅 장치(예를 들면, 마우스 또는 트랙 볼)를 포함한다. 사용자는 상기 키보드 및 포인팅 장치를 통해 입력을 컴퓨터에 제공한다. 기타 종류의 장치는 사용자와의 인터랙션을 제공하기 위해 사용 될 수도 있다. 예를 들면, 사용자에게 제공하는 피드백은 임의의 형태의 센싱 피드백(예를 들면, 시각 피드백, 청각 피드백 또는 촉각 피드백)일 수 있으며, 또한 사용자로부터의 입력은 임의의 형태(소리 입력, 음성 입력 또는 촉각 입력을 포함)로 수신될 수 있다. 여기에서 설명하는 시스템 및 기술을 백그라운드 부품을 포함하는 컴퓨팅 시스템(예를 들면, 데이터 서버), 또 는 미들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들면, 애플리케이션 서버), 또는 프론트 부품을 포함하는 컴 퓨팅 시스템(예를 들면, 그래픽 유저 인터페이스 또는 웹 브라우저를 구비하는 사용자 컴퓨터, 사용자는 상기 그래픽 유저 인터페이스 또는 웹 브라우저를 통해 여기에서 설명하는 시스템 및 기술의 실시형태와 인터랙션을 진행할 수 있음), 또는 상기 백그라운드 부품, 미들웨어 부품 또는 프론트 부품의 임의의 조합을 포함하는 컴퓨 팅 시스템에서 실행할 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들면, 통신 네트워크)을 통 해 시스템의 부품을 서로 연결할 수 있다. 통신 네트워크의 예시는 근거리 통신망(LAN), 광대역 통신망(WAN) 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함한다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있으며, 통신망을 통해 인터랙션을 진행한다. 해당 컴퓨터에서 실행되고, 또한 서로 클라이언트-서버 관계를 갖는 컴퓨 터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 여기서, 서버는 클라우드 컴퓨팅 서버 또는 클라우 드 호스트라고 칭할 수도 있는 클라우드 서버일 수 있으며, 클라우드 컴퓨팅 서비스 체계에서의 호스트 제품으 로서, 기존의 물리적 호스트와 가상 사설 서버 서비스(\"Virtual Private Server\", 또는 \"VPS\"으로 약칭)에 존재 하는 관리 난이도가 크고, 트랜잭션 확장성이 약한 결함을 해결하였다. 서버는 분산 시스템의 서버, 또는 블록 체인을 결합한 서버일 수도 있다. 본 개시가 제공한 정보 예측 방법을 실시하는 전자 기기에 기초하여, 본 개시는 자율주행 차량을 또한 제공한다. 이 자율주행 차량은 정보 예측 방법을 실시하기 위한 전자 기기를 포함한다. 일 실시예에서, 이 자율주행 차량은 영상 데이터를 수집하기 위한 센서를 또한 포함할 수 있다. 전자 기기는 이 영상 데이터와 자율주행 차량의 운전 데이터에 기초하여, 다음 시각의 제어 정보를 예측하여, 이 제어 정보에 기초하여 자율주행 차량의 주행을 제어할 수 있다. 상기의 다양한 형태의 프로세스를 이용하여, 단계를 다시 순서 배열, 추가 또는 삭제할 수 있음을 이해해야 한 다. 예를 들면, 본 발명에 기재된 각 단계는 병행하여 실행할 수 있고, 순서대로 실행할 수도 있으며, 서로 다 른 순서로 실행할 수도 있는데, 본 발명에 의해 개시되는 기술방안이 기대하는 결과를 실현할 수만 있다면, 이 에 대해 제한하지 않는다. 상기 구체적인 실시형태는 본 발명의 보호 범위에 대해 제한하지 않는다. 당업자는 설계 요구와 기타 요인에 따 라 다양한 수정, 조합, 서브 조합 및 대체를 진행할 수 있음을 이해해야 한다. 본 발명의 사상 및 원칙 내에서 진행되는 수정, 균등한 교체 및 개선 등은 모두 본 발명의 보호 범위에 포함되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2025-0035537", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 해결 수단을 더 잘 이해하기 위한 것이며, 본 개시에 대해 한정하지 않는다. 여기서, 도 1은 본 개시의 실시예에 따른 정보 예측 방법, 자율주행 모델의 훈련 방법, 및 장치의 적용 장면 개략도이고; 도 2는 본 개시의 실시예에 따른 정보 예측 방법의 흐름 개략도이고; 도 3은 본 개시의 실시예에 따른 정보 예측 방법을 실현하는 원리도 이고; 도 4는 본 개시의 실시예에 따른 네비게이션 데이터를 부호화하는 원리 개략도이고; 도 5는 본 개시의 실시예에 따른 영상 데이터를 부호화하여 영상 토큰 시퀀스를 얻는 원리 개략도이고; 도 6은 본 개시의 다른 실시예에 따른 정보 예측 방법을 실현하는 원리도이고; 도 7은 본 개시의 실시예에 따른 자율주행 모델의 훈련 방법의 흐름 개략도이고; 도 8은 본 개시의 실시예에 따른 정보 예측 장치의 구성 블록도 이고; 도 9는 본 개시의 실시예에 따른 자율주행 모델의 훈련 장치의 구성 블록도이고; 도 10은 본 개시의 실시예의 정보 예측 방법 또는 자율주행 모델의 훈련 방법을 실시하기 위한 전자 기기의 블 록도이다."}
