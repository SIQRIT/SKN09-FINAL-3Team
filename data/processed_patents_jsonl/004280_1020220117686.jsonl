{"patent_id": "10-2022-0117686", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0039306", "출원번호": "10-2022-0117686", "발명의 명칭": "랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 및 이를 이용한 변", "출원인": "한국과학기술원", "발명자": "예종철"}}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법에 있어서, 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후서버로 전송하는 단계; 및 상기 서버에서 수신된 상기 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위해 사용하는 단계를 포함하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 다중 작업 학습을 수행하는 상기 비전 변환기 모델을 클라이언트 측의 모델인 헤드 및 테일 부분과 서버 측의모델인 본체 부분으로 분리하고 직접적인 데이터의 공유 없이 분산 학습 방식으로 학습하는 것을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단계는, 상기 순열 모듈을 이용하여 상기 클라이언트 측에서 상기 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞어 전송하는 것을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 클라이언트 측에서 상기 서버 측으로 전송하는 데이터는 패치 순열이 랜덤하게 치환되어 원본 데이터를 식별할 수 없는 표상 특징 데이터를 보내도록 하는 것을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 서버 측에서 취합(aggregate)하여 분배하는 모델 가중치의 일부만을 공유하도록 하여 전체 데이터를 역순으로 복원하는 것이 불가능한 것을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 서버의 상기 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코공개특허 10-2024-0039306-3-딩된 특징을 상기 클라이언트로 다시 전송하는 단계를 더 포함하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 클라이언트는 저장된 키로 순열을 반전시키고 반환된 상기 특징을 작업별로 테일 부분에 전달하여 최종 출력을 산출하는 단계를 더 포함하고, 상기 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단계는, 상기 순열 모듈을 이용하여 상기 클라이언트 측에서 상기 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 상기 키를 저장하는 것을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 인코딩된 특징을 상기 클라이언트로 다시 전송하는 단계는, 상기 순열 모듈을 사용하여 순방향 전파의 반대인 상기 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행되는 것을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법에 있어서, 순열 모듈을 이용하여 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 키를 저장한 후,상기 클라이언트에서 서버로 패치 특징을 전송하는 단계; 상기 서버의 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된특징을 상기 클라이언트로 다시 전송하는 단계; 및 상기 클라이언트는 저장된 상기 키로 순열을 반전시키고 반환된 상기 특징을 작업별로 테일 부분에 전달하여 최종 출력을 산출하는 단계를 포함하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 인코딩된 특징을 상기 클라이언트로 다시 전송하는 단계는, 상기 순열 모듈을 사용하여 순방향 전파의 반대인 상기 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행되는 것을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 클라이언트에서 서버로 패치 특징을 전송하는 단계는, 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후서버로 전송하는 것공개특허 10-2024-0039306-4-을 특징으로 하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 서버에서 수신된 상기 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위해 사용하는 단계를 더 포함하는, 다중 작업 비전 변환 방법."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 장치에 있어서, 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후서버로 전송하는 헤드부; 및 상기 서버에서 수신된 상기 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위해 사용하는 특징 저장부를 포함하는, 다중 작업 비전 변환 장치."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 다중 작업 학습을 수행하는 상기 비전 변환기 모델을 클라이언트 측의 모델인 헤드 및 테일 부분과 서버 측의모델인 본체 부분으로 분리하고 직접적인 데이터의 공유 없이 분산 학습 방식으로 학습하는 것을 특징으로 하는, 다중 작업 비전 변환 장치."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 헤드부는, 상기 순열 모듈을 이용하여 상기 클라이언트 측에서 상기 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞어 전송하는 것을 특징으로 하는, 다중 작업 비전 변환 장치."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 클라이언트 측에서 상기 서버 측으로 전송하는 데이터는 패치 순열이 랜덤하게 치환되어 원본 데이터를 식별할 수 없는 표상 특징 데이터를 보내도록 하는 것을 특징으로 하는, 다중 작업 비전 변환 장치."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 서버 측에서 취합(aggregate)하여 분배하는 모델 가중치의 일부만을 공유하도록 하여 전체 데이터를 역순으로 복원하는 것이 불가능한 것을 특징으로 하는, 다중 작업 비전 변환 장치.공개특허 10-2024-0039306-5-청구항 18 제13항에 있어서,상기 서버의 상기 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된 특징을 상기 클라이언트로 다시 전송하는 본체부를 더 포함하는, 다중 작업 비전 변환 장치."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 클라이언트는 저장된 키로 순열을 반전시키고 반환된 상기 특징을 작업별로 테일 부분에 전달하여 최종 출력을 산출하는 테일부를 더 포함하고, 상기 헤드부는, 상기 순열 모듈을 이용하여 상기 클라이언트 측에서 상기 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 상기 키를 저장하는 것을 특징으로 하는, 다중 작업 비전 변환 장치."}
{"patent_id": "10-2022-0117686", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,상기 본체부는, 상기 순열 모듈을 사용하여 순방향 전파의 반대인 상기 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행되는 것을 특징으로 하는, 다중 작업 비전 변환 장치."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 및 이를 이용한 변환 방법이 제시된다. 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법 은, 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단계; 및 상기 서버에서 수신된 상기 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위해 사용하는 단계를 포함하여 이루어질 수 있다."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 실시예들은 개인정보 보호를 위한 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 및 이를 이용한 변환 방법에 관한 것이다. 본 연구는 보건복지부의 재원으로 한국보건산업진흥원의 융합 형 의사과학자 양성 사업 지원에 의하여 이루어진 것임."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI)은 다양한 데이터 과학 분야를 혁신할 수 있는 잠재력 덕분에 전례 없는 인기를 얻고 있다. 특히, 심층 신경망은 의료 영상의 다양한 응용 분야에서 전문가 수준의 성능을 달성했다. AI 모델이 견고성과 함께 정확한 의사 결정 지원을 제공할 수 있도록 하려면 엄청난 양의 데이터가 필수적이다. 그러나 일부 기관의 자발적 참여에서 수집된 데이터는 강력한 성과를 보장하기 위한 양을 완전히 충족할 수 없 다. 대규모 공공 데이터셋의 경우에도 제한된 지리적 지역 및 인종과 같은 환자 인구 통계에서 비롯된 정량화 할 수 없는 편견이 불가피하게 포함되어 실제 애플리케이션에서 성능 불안정성을 초래할 수 있다. 특히, COVID-19와 같이 새롭게 등장하는 질병의 경우, 충분한 다양성을 가진 크고 잘 큐레이션된 데이터셋을 즉시 구 축하기 어렵기 때문에 이러한 제한은 악화될 수 있다. 따라서 의료 이미징에 AI를 성공적으로 적용하기 위해서는 여러 기관 간의 협업 능력이 중요하지만, 환자 데이 터 공유를 위한 엄격한 규정과 윤리적 제약은 다중 기관 협업의 또 다른 장애물이다. 미국 HIPAA(Health Insurance Portability and Accountability Act) 및 유럽 일반 데이터 보호 규정(GDPR)과 같은 몇 가지 공식 규정 및 지침은 환자 데이터의 저장 및 공유와 관련된 엄격한 규정을 명시하고 있다. 따라서 에지 장치(edge device)에서 학습 과제를 분산 방식으로 수행하는 분산 학습(distributed learning) 방 법을 건강관리 연구에 효과적으로 활용할 수 있다. 구체적으로, 분산 학습은 공유 없이 소스 장치에 상주하는 데이터로 모델 교육을 가능하게 하기 위해 도입되었다. 연합 학습(Federated Learning, FL)은 분산 클라이언트 가 교육 데이터를 공유하지 않고도 공유 모델을 공동으로 학습할 수 있도록 하는 이러한 방법 중 하나이다. 그 러나 병렬 연산을 위해 클라이언트 측 연산 리소스에 크게 의존하고 그래디언트(gradient) 반전 공격으로 프라 이버시 보호 문제에서 완전히 자유롭지 않다는 점에서 여전히 몇 가지 한계를 가지고 있다. 클라이언트와 서버 사이의 부분으로 네트워크를 분할하는 또 다른 분산 학습 방법인 분할 학습(Split Learning, SL)은 에지 장치에 낮은 연산 부하를 두는 유망한 방법이다. 그러나 클라이언트와 서버 사이의 통신 오버헤드가 높다는 단점이 있 고 개인 데이터는 기능 하이재킹 및 모델 반전을 통한 악의적인 공격에 의해 복구될 수 있기 때문에 프라이버시 보호에도 한계가 있다. 또한, 분할 학습(SL)은 연합 학습(FL)에 비해 상당히 느린 수렴을 보여주며 클라이언트 간의 데이터 분포가 크게 치우쳐 있을 때 최적의 성능을 보이지 않는다. 비전 변환기(Vision Transformer, ViT)의 모듈식 분해 구조에서 영감을 받아, 비전 변환기(ViT) 아키텍처를 사 용하는 분산 다중 작업 협업을 위해 연합 분할 작업-불가론적 학습(Federated Split Task-Agnostic learning, FESTA)라는 새로운 분산 학습 방법이 최근 제안되었다. 서버 측의 공유 작업-agnostic 비전 변환기(ViT) 본체 와 클라이언트 측의 다중 작업 특정 컨볼루션 신경망(Convolutional Neural Network, CNN) 헤드 및 테일을 갖 춘 FESTA 프레임워크는 연합 학습(FL)과 분할 학습(SL)의 장점을 균형 있게 조정하여 분산 다중 작업 협업 설정 에서 개별 작업의 성능을 수준별로 향상시킬 수 있었다. 데이터 중앙 집중식으로 학습된 단일 작업 전문 모델 보다 훨씬 우수하다. 그럼에도 불구하고 FESTA 프레임워크에는 몇 가지 중요한 한계가 있다. 첫째, 모델이 네트워크의 헤드와 테일 부분뿐만 아니라 특징과 gradient를 지속적으로 공유해야 하기 때문에 통신 오버헤드가 분할 학습(SL)과 연합 학습(FL)보다 높아 실질적인 구현에 어려움이 있을 수 있다. 둘째, 원래의 FESTA에서 큰 크기의 헤드와 테일 부분은 공유 본체의 역할을 줄이는 경향이 있어 비전 변환기(ViT)의 다중 작업 학습(Multi-Task Learning, MTL) 잠재력에도 불구하고 단일 작업 학습에 비해 작은 개선을 가져온다는 것을 발견했다. 마지막으로, FESTA 프레 임워크는 분할 학습(SL)에서 동일한 방식으로 외부 악의적인 공격자나 \"honest but curious\" 서버에 의해 서버 본체에 전송된 특징을 장악하여 원본 데이터로 되돌릴 수 있기 때문에 프라이버시 문제에서 자유롭지 못했다. 선행기술문헌 비특허문헌 (비특허문헌 0001) H. Chen, Y. Wang, T. Guo, C. Xu, Y. Deng, Z. Liu, S. Ma, C. Xu, C. Xu, and W. Gao, \"Pre-trained image processing transformer,\" arXiv preprint arXiv:2012.00364, 2020."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예들은 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 및 이를 이용한 변환 방법 에 관하여 기술하며, 보다 구체적으로 랜덤으로 순열 치환하는 간단한 패치 임베더를 채택하여 프라이버시를 희 생하지 않고 다중 작업 학습 성능을 향상시키는 기술을 제공한다. 실시예들은 분산 학습 방식과 다중 작업 학습을 비전 변환기 모델을 활용하여 통합함과 동시에, 랜덤 패치 순열 치환 모듈이라는 기술을 적용하여 기존 방식에서 불가능하였던 개인정보 보호가 가능하고, 동시에 통신량 또한 절반 수준으로 감소시킬 수 있는 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 및 이를 이용한 변환 방법을 제공하는데 있다."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법 은, 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단계; 및 상기 서버에서 수신된 상기 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위해 사용하는 단계를 포함하여 이루어질 수 있다. 다중 작업 학습을 수행하는 상기 비전 변환기 모델을 클라이언트 측의 모델인 헤드 및 테일 부분과 서버 측의 모델인 본체 부분으로 분리하고 직접적인 데이터의 공유 없이 분산 학습 방식으로 학습할 수 있다. 상기 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단계는, 상기 순열 모듈을 이용하여 상 기 클라이언트 측에서 상기 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞어 전송할 수 있다. 상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 클라이언트 측에서 상기 서버 측으로 전송하는 데이터는 패치 순열이 랜덤하게 치환되어 원본 데이터를 식별할 수 없는 표상 특징 데이터를 보내도록 할 수 있다. 상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 서버 측에서 취합(aggregate)하여 분배하는 모델 가중치 의 일부만을 공유하도록 하여 전체 데이터를 역순으로 복원하는 것이 불가능할 수 있다. 상기 서버의 상기 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코 딩된 특징을 상기 클라이언트로 다시 전송하는 단계를 더 포함할 수 있다. 상기 클라이언트는 저장된 키로 순열을 반전시키고 반환된 상기 특징을 작업별로 테일 부분에 전달하여 최종 출 력을 산출하는 단계를 더 포함하고, 상기 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단 계는, 상기 순열 모듈을 이용하여 상기 클라이언트 측에서 상기 서버로 패치 특징을 전송하기 이전에 패치 순열 을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 상기 키를 저장할 수 있다. 상기 인코딩된 특징을 상기 클라이언트로 다시 전송하는 단계는, 상기 순열 모듈을 사용하여 순방향 전파의 반 대인 상기 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행될 수 있다. 다른 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방 법은, 순열 모듈을 이용하여 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 키를 저장 한 후, 상기 클라이언트에서 서버로 패치 특징을 전송하는 단계; 상기 서버의 비전 변환기 모델의 본체 부분에 서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된 특징을 상기 클라이언트로 다시 전송하는 단계; 및 상기 클라이언트는 저장된 상기 키로 순열을 반전시키고 반환된 상기 특징을 작업별로 테일 부분에 전 달하여 최종 출력을 산출하는 단계를 포함하여 이루어질 수 있다. 상기 인코딩된 특징을 상기 클라이언트로 다시 전송하는 단계는, 상기 순열 모듈을 사용하여 순방향 전파의 반 대인 상기 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행될 수 있다. 상기 클라이언트에서 서버로 패치 특징을 전송하는 단계는, 작업 비특이 패치 임베더를 이용하여 각 클라이언트 에 대한 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송할 수 있다. 상기 서버에서 수신된 상기 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위 해 사용하는 단계를 더 포함할 수 있다. 또 다른 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 장치는, 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비하여 순열 모듈을 통과 시킨 후 서버로 전송하는 헤드부; 및 상기 서버에서 수신된 상기 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위해 사용하는 특징 저장부를 포함할 수 있다. 다중 작업 학습을 수행하는 상기 비전 변환기 모델을 클라이언트 측의 모델인 헤드 및 테일 부분과 서버 측의 모델인 본체 부분으로 분리하고 직접적인 데이터의 공유 없이 분산 학습 방식으로 학습할 수 있다. 상기 헤드부는, 상기 순열 모듈을 이용하여 상기 클라이언트 측에서 상기 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞어 전송할 수 있다. 상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 클라이언트 측에서 상기 서버 측으로 전송하는 데이터는 패치 순열이 랜덤하게 치환되어 원본 데이터를 식별할 수 없는 표상 특징 데이터를 보내도록 할 수 있다. 상기 순열 모듈은, 랜덤 패치 순열 치환 모듈로, 상기 서버 측에서 취합(aggregate)하여 분배하는 모델 가중치 의 일부만을 공유하도록 하여 전체 데이터를 역순으로 복원하는 것이 불가능할 수 있다. 상기 서버의 상기 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코 딩된 특징을 상기 클라이언트로 다시 전송하는 본체부를 더 포함할 수 있다. 상기 클라이언트는 저장된 키로 순열을 반전시키고 반환된 상기 특징을 작업별로 테일 부분에 전달하여 최종 출 력을 산출하는 테일부를 더 포함하고, 상기 헤드부는, 상기 순열 모듈을 이용하여 상기 클라이언트 측에서 상기서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 상 기 키를 저장할 수 있다. 상기 본체부는, 상기 순열 모듈을 사용하여 순방향 전파의 반대인 상기 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행될 수 있다."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들에 따르면 분산 학습 방식과 다중 작업 학습을 비전 변환기 모델을 활용하여 통합함과 동시에, 랜덤 패 치 순열 치환 모듈이라는 기술을 적용하여 기존 방식에서 불가능하였던 개인정보 보호가 가능하고, 동시에 통신 량 또한 절반 수준으로 감소시킬 수 있는 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 및 이를 이용한 변환 방법을 제공할 수 있다. 실시예들에 따르면 기존 분산 학습 방식에 비하여 효과적인 개인정보 보호를 통한 플랫폼의 효과적인 보급이 가 능하다. 또한, 실시예들에 따르면 다중 작업 분산 학습 플랫폼의 폭넓은 보급 및 다양한 모달리티에 적용을 통한 개별 작업 특화 인공지능 모델들의 성능 향상이 가능하다. 또한, 실시예들에 따르면 효율적인 서버-클라이언트 통신을 통한 분산 학습 과정에서의 통신량 및 비용, 시간을 감소시킬 수 있다."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 실시예들을 설명한다. 그러나, 기술되는 실시예들은 여러 가지 다른 형태로 변 형될 수 있으며, 본 발명의 범위가 이하 설명되는 실시예들에 의하여 한정되는 것은 아니다. 또한, 여러 실시"}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예들은 당해 기술분야에서 평균적인 지식을 가진 자에게 본 발명을 더욱 완전하게 설명하기 위해서 제공되는 것 이다. 도면에서 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 인공지능 모델들이 의료 영상 분야에서 뛰어난 성능을 보임에 따라 관련 제품들이 다양하게 출시되고 있으나, 이는 중앙화된 학습 방식으로 일부 데이터에 대해서만 학습된 모델로 우수한 일반화 성능을 보장하지 못하는 경 우가 많고, 우수한 일반화 성능을 확보하기 위해서는 다수의 데이터가 필수적이라는 문제가 있다. 이에 연합 학습 등의 분산 학습 방식이 개발되었으나, 개인정보 보호가 불완전하여 여전히 개인정보를 복원할 수 있다는 위험성이 있으며, 통신량이 많아 실제적인 적용이 어렵다. 또한, 분산 학습 방식에서 다중 학습을 활용하여 성능 향상을 가능하게 한 기존의 기술은 통신량이 특히 늘어나는 한계점 있었다. 아래의 실시예들은 기존 분산 학습 방식들에서 문제가 되던 공격자 및 서버에 의한 개인정보 복원을 통한 프라 이버시 침해 문제를 해결하고, 다중 학습 방식의 이점을 최대로 살려 다중 학습 프레임워크를 통한 성능 향상을 극대화하며, 서버-클라이언트간의 통신량 또한 줄일 수 있는 방식을 제공하고자 한다. 실시예들은 패치 순열 치환 불변성이라는 비전 변환기 모델 고유의 특성을 활용하여, 클라이언트 측에서 서버로 표상 특징을 전송하기 전에 패치 순열을 랜덤하게 섞어 전송하는 방식으로 개인정보를 보호한다. 이 방식으로 는 서버에 표상 특징을 저장하여도 유출의 우려가 없기 때문에, 처음에 모든 표상 특징을 저장하고 학습을 진행 하는 방식으로 통신량을 감소시킬 수 있으며, 동시에 비전 변환기 모델을 헤드, 변환기(본체), 테일(tail)로 분 리하여 변환기 자체는 공유되게 함으로써 다중 학습 방식의 이점을 살려 개별 작업에 비하여 성능을 향상시키도 록 한다. 실시예들에 따르면 기존 분산 학습 방식에 비하여 효과적인 개인정보 보호를 통한 플랫폼의 효과적인 보급을 기 대할 수 있다. 결과적으로, 다중 작업 분산 학습 플랫폼의 폭넓게 보급하고 및 다양한 모달리티에 적용하여 개 별 작업 특화 인공지능 모델들의 성능 향상을 기대해볼 수 있으며, 동시에 효율적인 서버-클라이언트 통신을 통 해 실제 분산 학습 과정에서의 통신량 및 비용, 시간 감소 또한 기대해 볼 수 있다. 본 실시예에서는 랜덤 패치 순열을 가진 비전 변환기(Vision Transformer, ViT)를 사용하는 다중 작업 분산 학 습을 제시한다. FESTA(federated split task-agnostic)에서처럼 CNN 기반 헤드를 사용하는 대신, 본 실시예에 따른 p-FESTA는 랜덤으로 순열하는 간단한 패치 임베더를 채택하여 프라이버시를 희생하지 않고 다중 태스킹 학 습 성능을 향상시킬 수 있다. 실험 결과, 제안된 방법이 다중 작업 협업, 커뮤니케이션 효율성 및 개인 정보 보호의 이점을 크게 향상시켜 의료 영상 분야의 실제 다중 작업 분산 학습을 조명한다는 것을 확인할 수 있다. 보다 구체적으로, 본 실시예들은 순수 비전 변환기(Vision Transformer, ViT)를 치환하는 연합 분할 작업-비특 이적 학습(Federated Split Task-Agnostic learning, FESTA)인 p-FESTA 프레임워크를 도입하여 프라이버시 보 호로 통신 효율적인 다중 작업 학습(Multi-Task Learning, MTL)을 강화한다. p-FESTA의 전체적인 구성은 FESTA와 비슷하지만, CNN 기반 헤드를 사용하는 대신 p-FESTA는 vanilla 비전 변환기(ViT)와 같은 단순한 작업 비특이 패치 임베더를 채택하여 변환기(transformer) 아키텍처 내에서 자기주의를 기울여 다중 작업 학습(MTL) 성능을 향상시킨다. 프라이버시 보호를 위해 외부 공격자나 \"honest but curious\" 서버가 개인 정보를 포함하 는 원래 데이터로 특징을 되돌리는 것을 방지하기 위해 모든 패치 특징의 순서를 랜덤으로 바꾸는 순열 모듈을 도입한다. 새로운 아키텍처 변경은 p-FESTA에 몇 가지 독특한 이점을 제공한다. 첫째, 전체 학습 프로세스에서 사용할 기 능을 저장하여 통신 오버헤드를 크게 줄였다. 또한, 헤드는 작은 역할을 하고, 다중 작업 본체는 heavy lifting을 함으로써 다중 작업 학습(MTL)의 장점이 강화된다. 또한, 비전 변환기(ViT)의 고유 속성을 사용하는 단순하지만 효과적인 순열 모듈로 데이터 프라이버시 보호도 강화된다. 먼저, 비전 변환기(ViT)에 대해 설명한다. 자연어 처리(Natural Language Processing, NLP)에서의 성공적인 적용에서 영감을 얻은 정교한 주의 메커니즘을 갖춘 최근 도입된 딥러닝 모델인 비전 변환기(ViT)는 많은 비전 작업에서 인상적인 성능을 보여주었다. 비전 변환기(ViT)의 다중 헤드 자기 주의는 큐를 인코딩하기 위해 이미지의 일련의 패치에 유연하게 주의를 기울일 수 있어 모델이 occlusion, 공간 순열 및 적대적 섭동과 같은 방해에 견고할 수 있으며, 따라서 모델이 CNN 기 반 모델보다 인간처럼 더 형태 편향(shape-biased)될 수 있다. 또한, 비전 변환기(ViT)의 모듈식 설계는 간단하여 이미지 패치를 임베딩에 투영하는 헤드, 임베딩을 인코딩하 는 transformer 본체, 작업별 출력을 생성하는 테일 등 구성 요소를 쉽게 분해할 수 있음을 암시한다. 이 쉽게 분해할 수 있는 설계는 다중 작업 학습(MTL) 애플리케이션에서 가능성을 제공한다. 다중 작업 학습(MTL)의 동 기는 개별 작업에 대한 데이터 수가 제한된 데이터 부족 문제를 완화하려는 시도에서 비롯된다는 것을 기억해야 한다. 다중 작업 학습(MTL)은 데이터 효율성을 개선하고, 공유 표현을 통해 과적합을 줄이며, 보조 지식을 활 용하여 더 빠른 수렴을 할 수 있는 장점을 제공할 수 있다. 특히, transformer 기반 모델이 있는 다중 작업 학습(MTL)은 자연어 처리(NLP)에서 밀접하게 관련된 작업의 성 능을 향상시키기 위한 인기 있는 접근 방식으로 등장했다. 이 접근 방식에서 공유 transformer는 문장 분류 및 단어 예측과 같은 여러 관련 작업을 동시에 학습하고 작업별 모듈이 각 작업에 대한 결과를 산출한다. 다중 작 업 학습(MTL) 전략으로 학습된 모델은 일반적으로 광범위한 작업에서 향상된 성능을 보여준다. 언어에서처럼 잘 연구되지는 않았지만, 비전 변환기(ViT)의 분해 가능한 설계는 시각적 transformer 모델에 다중 작업 학습 (MTL)을 적용하는 것을 가능하게 했다. 초기 접근 방식(비특허문헌 1)에서, 비전 변환기(ViT)는 작업 전반에 걸쳐 작업별 헤드, 테일 및 공유 transformer 구조로 나뉘었고, 관련 작업 간에 transformer 모델을 공유함으로 써 더 적은 학습 단계로 유사한 일반화 성능을 달성할 수 있었다. 도 1은 기존 FESTA의 구조를 나타내는 도면이고, 도 2는 기존 FESTA의 학습 방법을 설명하기 위한 도면이다. 도 1 및 도 2에 도시된 바와 같이, 기존 FESTA(Federated Split Task-Agnostic) 프레임워크의 주요 동기는 연 합 학습(FL)과 분할 학습(SL) 방식의 뚜렷한 장점을 최대한 활용하고 다양한 작업을 수행하는 클라이언트 간의 협업으로 개별 작업의 성과를 향상시키는 프레임워크를 제공하는 것이다. 가 서로 다른 작업을 가진 클라이언트 집합의 그룹이라 한다. 여기서, K는 작업 수를 나타내 고, 클라이언트 집합 Ck는 k번째 작업, 에 대해 서로 다른 데이터 소스 를 가진 하나 이상의 클라이언트를 포함한다. k번째 작업에 대한 각 클라이언트 집합의 클라이언트는 헤드 (head) Hc 및 테일(tail) Tc에 대한 자체 작업별 모델 아키텍처를 가지고 있으며, 서버 측 transformer 본체(body) B는 공유된다. 학습을 위해 서버와 각 클라이언트는 랜덤 초기화 또는 사전 학습된 파라미터로부터 각 서브 네트워크 의 가중치를 초기화한다. 학습 라운드 의 경우, 개별 클라이언트는 로컬 학습 데이터 을 사용하여 작업별 헤드 Hc에 포워드 패스를 수행하고, 중간 특징 를 서버로 전송 한다. . 그런 다음, transformer 본체 B는 모든 클라이언트로부터 중간 특징을 수신하 고 포워드 패스와 병렬로 특징 를 얻어 각 클라이언트 c로 보낸다. . 특징 를 사 용하면 클라이언트의 작업별 테일이 출력 및 포워드 패스가 완료된다. 역전파는 테일, 본체, 헤드 순서로 정확히 반대 방향으로 진행된다. 첫째, 테일에서 손실은 로 계산되며, 여기서 는 목표 y와 추정 사이의 c 작업별 손실을 나타낸다. 그런 다음, 체인 규칙을 사 용하여 테일, 본체에서 헤드까지 역순으로 전달된다. 다중 작업 본체 업데이트의 경우 헤드와 테일을 고정하여 최적화가 수행된다. 작업별 헤드 및 테일 업데이트의 경우 transformer 본체를 수정하여 최적화 문제를 해결한다. 또한, 서버는 \"UnifyingRounds\"마다 FedAvg 에서와 같이 동일한 작업에 참여하는 클라이언트 간에 헤드 및 테일 파라미터를 집계, 평균하여 분산한다. 이전 연구에서, 다중 작업 학습(MTL)과 함께 FESTA는 데이터 거버넌스(data governance) 및 소유권 문제를 해결 하는 동시에 transformer 본체의 큰 가중치를 전송할 필요가 없는 동시에 클라이언트의 개별 성능을 공동으로 향상시키는 것으로 나타났다. FESTA 프레임워크에는 여전히 몇 가지 단점이 있다. 첫째, 분할 학습(SL)처럼 서버와 클라이언트 간에 특징과 gradient를 지속적으로 교환해야 하지만, 연합 학습(FL)처럼 헤드와 테일 가중치도 클라이언트 간에 집계해야 하기 때문에 통신비가 더 높을 수 있다. 이에 따라 총 통신비가 분할 학습(SL)보다 높을 수밖에 없고, 망 규모 에 따라 연합 학습(FL)보다 더 높을 수밖에 없다. 둘째, transformer 본체가 없는 연구에서 알 수 있듯이 CNN 헤드와 테일 자체는 이미 강력한 표현 능력을 가지고 있어 헤드와 테일 사이의 transformer 본체의 역할을 줄일 수 있다. 셋째, 클라이언트에서 서버로 전송되는 특징에 대한 모델 반전 공격으로부터 프라이버시 보호 방법이 없기 때문에 프라이버시 보호 문제가 발생할 수 있다.일 실시예에 따라 제안된 p-FESTA는 이러한 단점을 완화하기 위해 고안된 프레임워크이다. 도 3은 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치의 구조를 설 명하기 위한 도면이고, 도 4는 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치의 학습 방법을 설명하기 위한 도면이다. 도 3 및 도 4에 도시된 바와 같이, p-FESTA의 전체적인 구성은 헤드 H(310, 410), 본체 B(320, 420), 테일 T(330, 430) 등으로 네트워크를 분해하는 FESTA와 유사하지만, 기존 FESTA와 달리 각 작업에 맞춘 CNN 헤드를 사용하지 않는다. 작업에서 중요한 역할을 할 수 있을 정도로 CNN 헤드가 강력하면 이 추가 모듈로 개선할 여 지가 거의 없기 때문에 공유 transformer가 중요한 구성 요소가 되는 것을 방해한다. 대신, 일 실시예에 따르 면 vanilla 비전 변환기(ViT)와 같은 단순하고 작업 비특이 패치 임베더(task non-specific patch embedder)를 채택하여 transformer 아키텍처 내에서 자기주의(self-attention)를 강제하여 heavy lift를 수행한다. vanilla 비전 변환기(ViT)에서 패치 임베딩을 사용하면 원래 이미지를 얻기 위해 패치 임베더를 뒤집으려는 외 부 공격자가 발생할 수 있다. 이를 해결하기 위해, 여기서는 외부 공격자 또는 \"honest but curious\" 서버가 개인 정보를 포함하는 원래 데이터로 특징을 되돌리는 것을 방지하기 위해, 도 3에 도시된 바와 같이, 새로운 순열 모듈(permutation module)(340, 440)을 제안한다. 특히, 이 순열 모듈(340, 440)은 모든 패치 특징을 서 버로 보내기 전에 임의로 순서를 섞고 클라이언트 측에서 순열을 반대로 하기 위해 키(permutation key)를 저장 한다. 그런 다음, 서버의 transformer 본체 B(320, 420)는 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된 특징을 클라이언트로 다시 전송한다. 마지막으로, 클라이언트는 저장된 키로 순열을 반전시키고 반환 된 특징을 작업별 테일 Tk(330, 430)에 전달하여 최종 출력을 산출한다. 역전파는 순방향 전파에 동일한 순열 모듈(340, 440)이 사용되는 정반대의 방식으로 수행된다. 순열 모듈(340, 440)의 가용성은 다중 헤드 자기주의, 피드포워드 네트워크(feedforward network) 및 계층 정규 화와 같이 transformer 본체를 구성하는 모든 구성 요소가 근본적으로 \"순열 불가변성(permutation equivariant)\"인, 비전 변환기(ViT)의 흥미로운 특성 때문이다. 이들은 패치 기반 방식으로 독립적으로 처리되 며 패치의 순서가 결과에 영향을 미치지 않으므로 성능 저하 없이 transformer 본체를 학습할 수 있다. 또한, 패치 순서가 완전히 뒤엉키기 때문에 악의적인 공격자가 원본 이미지를 성공적으로 되돌리는 것은 불가능하다. 순열 모듈(340, 440)이 악의적인 공격자로부터 프라이버시 보호를 제공하는 방법에 대해서는 아래에서 자세히 설명한다. 연합 학습(FL)의 경우, 모델 업데이트가 원래 데이터보다 덜 정보적이라고 간주할 때, 모델 업데이트의 연합 집 계, 평균화 및 분산의 일시적이고 집중적인 특성에 의해 프라이버시가 개선된다. 그러나 최근 연구는 이러한 로컬 모델 업데이트만으로 개인 데이터가 충실하게 발견될 수 있다는 잘못된 보안의식에 의문을 제기하고 있다. 구체적으로, 글로벌 모델 W에 대한 액세스와 클라이언트의 모델 업데이트 에 대한 액세스가 주어지면 공 격자는 클라이언트의 모델 업데이트와 일치하는 gradient를 생성하기 전에 이전의 입력 이미지를 최적화할 수 있다. 그러나 전체 모델의 테일 부분만 서버에 의해 집계되고 클라이언트에 분산되기 때문에 제안된 p-FESTA 방법에서는 이러한 유형의 공격이 불가능하다. 예를 들어, COVID-19 분류의 경우 작업별 테일은 간단한 선형 분류기로서, 프라이버시가 있는 원본 데이터를 발견할 수 없다. 분할 학습(SL)은 다른 방식으로 프라이버시를 보호한다. 이름에서 알 수 있듯이 분할 학습(SL)은 전체 모델을 클라이언트 측 서브 네트워크와 서버 측 서브 네트워크로 분할하고 서버와 클라이언트 간에 모델을 전송하지 않 는다. 대신, 특징과 gradient가 서버와 클라이언트 사이에서 왔다 갔다 전송되며 악의적인 공격자의 먹이가 될 수 있다. 클라이언트가 서버에 중간 특징 f를 보낼 때 공격자는 특징을 탈취할 수 있으며, 나머지 분할 학습(SL) 모델을 실행하는 대신 인코더 , 디코더 G, 판별기 D의 세 가지 구성 요소를 자체 데이터로 학습한다. D는 탈취된 특 징 f와 로 인코딩된 특징 를 구별하도록 학습되어 가 f와 동일한 특징 공간에 있도록 한다. 동시에 G는 최소한의 오류만으로 를 이미지로 디코딩하는 방법을 학습한다. 그런 다음, 잘 학습된 G를 사용하여 탈취된 특징 f를 원본 데이터로 충실하게 디코딩할 수도 있다. 도 5는 일 실시예에 따른 프라이버시를 강화하기 위한 순열 모듈을 나타내는 도면이다. 또한, 도 6은 일 실시 예에 따른 각 클라이언트의 각 데이터에 대한 서로 다른 순열 패턴을 나타내는 도면이다. 특징 공간 탈취는 일 실시예에 따른 p-FESTA에서도 가능하다. 일 실시예에 따른 모델의 헤드 부분은 비교적 단 순하며 공격자의 쉬운 먹잇감이 될 수 있다. 이것이 도 7에 도시된 바와 같이, 프라이버시를 보호하기 위한 새 로운 순열 모듈을 도입하는 이유이다. 순열 모듈은 모든 패치 특징의 순서를 임의로 섞는다. 구현에서 각 클 라이언트의 각 데이터의 순열은 도 8에 도시된 바와 같이, 규칙성 없이 모두 달라서 모든 데이터에 대해 수많은 패턴이 발생한다. 이러한 랜덤 순열로 악의적인 공격자 또는 서버가 개인 데이터를 발견하기 위해 패치 특징을 탈취하더라도 학습 가능한 알 수 없는 변수인 위치 임베딩 파라미터는 패치의 원래 순서에 대한 정보가 없으므 로 추론할 수 없다. 또한, 공격자가 알 수 없는 추가된 위치 임베딩이 반전을 위해 먼저 감산되어야 하므로 패 치 특징을 이미지 패치에 역행하는 것은 불가능하다. 이는 공격자가 다른 \"알 수 없는(unknown)\" 것을 추론하 기 위해 \"알 수 없는\" 것을 이미 알고 있어야 한다는 모순을 만들어 반전 공격을 미확정 문제의 한 종류로 만든 다. 아래에서는 일 실시예에 따른 p-FESTA의 학습 프로세스를 설명한다. p-FESTA의 학습 프로세스는 원래의 FESTA와 유사하지만 여러 면에서 다르다. 작업 비특이 패치 임베더 H는 각 작업 k에 대한 작업별 헤드 Hk 대신 처음에 각 클라이언트 c에 대한 패치 임베딩 hc를 준비하여 순열 모듈을 통 과한 후 서버로 전송한다. 그런 다음, 서버는 수신된 패치 임베딩 hc를 측면에 저장하고 모델의 본체 B와 테일 Tk 부분을 업데이트하기 위해 학습 프로세스의 나머지 기간 동안 사용한다. 결과적으로, 중간 특징 hc를 보내거 나 헤드 H를 업데이트하기 위한 통신이 더 이상 필요하지 않기 때문에, 원래의 FESTA에 비해 전반적인 통신 비 용을 크게 줄일 수 있다. 모델의 헤드 부분인 패치 임베더는 이 구성에서 업데이트 할 수 없다. 그러나 패치 임베더의 파라미터를 수정 해도 이미지 패치를 동일한 벡터 공간에 임베딩할 수 있는 간단한 구조 덕분에 성능 저하가 발생하지 않는다. 학습할 수 있게 하면 작업 간의 임베딩 불일치가 발생하여 성능이 다소 저하된다. 제안된 p-FESTA의 자세한 프 로세스는 다음의 [표 1]의 알고리즘 1에 설명되어 있다.[표 1]"}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 7은 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변 환 방법을 나타내는 흐름도이다. 도 7을 참조하면, 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법은, 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단계(S110), 및 서버에서 수신된 패치 임베딩을 저장하고 비전 변환기 모 델의 본체 및 테일 부분을 업데이트하기 위해 사용하는 단계(S120)를 포함하여 이루어질 수 있다. 또한, 서버의 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된 특징을 클라이언트로 다시 전송하는 단계(S130)를 더 포함할 수 있다. 또한, 클라이언트는 저장된 키로 순열을 반전시키고 반환된 특징을 작업별로 테일 부분에 전달하여 최종 출력을 산출하는 단계(S140)를 더 포함할 수 있다. 여기서, 패치 임베딩을 준비하여 순열 모듈을 통과시킨 후 서버로 전송하는 단계는, 순열 모듈을 이용하여 클라이언트 측에서 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 키를 저장할 수 있다. 아래에서 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법을 보다 상세히 설명한다. 도 8은 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 나타내는 블록도이다. 도 8을 참조하면, 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 는 헤드부 및 특징 저장부를 포함할 수 있다. 실시예에 따라 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치는 본체부 및 테일부를 더 포함할 수 있다. 실시예들은 다중 작업 학습을 수행하는 비전 변환기 모델을 클라이언트 측의 모델인 헤드 및 테일 부분과 서버 측의 모델인 본체 부분으로 분리하고 직접적인 데이터의 공유 없이 분산 학습 방식으로 학습할 수 있다. 단계(S110)에서, 헤드부는 작업 비특이 패치 임베더를 이용하여 각 클라이언트에 대한 패치 임베딩을 준비 하여 순열 모듈을 통과시킨 후 서버로 전송할 수 있다. 헤드부는 순열 모듈을 이용하여 클라이언트 측에 서 서버로 패치 특징을 전송하기 이전에 패치 순열을 랜덤하게 섞어 전송할 수 있다. 이 때, 헤드부는 패 치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키기 위해 키를 저장할 수 있다. 여기서, 순열 모듈은 랜덤 패치 순열 치환 모듈로, 클라이언트 측에서 서버 측으로 전송하는 데이터는 패치 순 열이 랜덤하게 치환되어 원본 데이터를 식별할 수 없는 표상 특징 데이터를 보내도록 할 수 있다. 또한, 순열 모듈은 랜덤 패치 순열 치환 모듈로, 서버 측에서 취합(aggregate)하여 분배하는 모델 가중치의 일부만을 공유 하도록 하여 전체 데이터를 역순으로 복원하는 것이 불가능할 수 있다. 단계(S120)에서, 특징 저장부는 서버에서 수신된 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테 일 부분을 업데이트하기 위해 사용할 수 있다. 단계(S130)에서, 본체부, 즉 서버의 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된 특징을 클라이언트로 다시 전송할 수 있다. 본체부는 순열 모듈을 사용하여 순 방향 전파의 반대인 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행될 수 있다. 단계(S140)에서, 클라이언트는 저장된 키로 순열을 반전시키고, 테일부는 반환된 특징을 작업별로 테일 부 분에 전달하여 최종 출력을 산출할 수 있다. 도 9는 다른 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법을 나타내는 흐름도이다. 도 9를 참조하면, 다른 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 를 이용한 변환 방법은, 순열 모듈을 이용하여 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반전시키 기 위해 키를 저장한 후, 클라이언트에서 서버로 패치 특징을 전송하는 단계(S210), 서버의 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된 특징을 클라이언트로 다시 전송하 는 단계(S220), 및 클라이언트는 저장된 키로 순열을 반전시키고 반환된 특징을 작업별로 테일 부분에 전달하여최종 출력을 산출하는 단계(S230)를 포함하여 이루어질 수 있다. 다른 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방 법은 앞에서 설명한 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치 를 이용한 변환 방법의 구성에 포함되거나 포함할 수 있어 중복되는 설명은 생략하기로 한다. 단계(S210)에서, 헤드부는 순열 모듈을 이용하여 패치 순열을 랜덤하게 섞고 클라이언트 측에서 순열을 반 전시키기 위해 키를 저장한 후, 클라이언트에서 서버로 패치 특징을 전송할 수 있다. 한편, 특징 저장부는 서버에서 수신된 패치 임베딩을 저장하고 비전 변환기 모델의 본체 및 테일 부분을 업데이트하기 위해 사용할 수 있다. 단계(S220)에서, 본체부는 서버의 비전 변환기 모델의 본체 부분에서 순열 치환된 패치 특징으로 포워드 패스를 수행하고 인코딩된 특징을 클라이언트로 다시 전송할 수 있다. 즉, 순열 모듈을 사용하여 순방향 전파 의 반대인 비전 변환기 모델의 테일, 본체 및 헤드 순서로 역전파가 진행될 수 있다. 단계(S230)에서, 테일부는 클라이언트는 저장된 키로 순열을 반전시키고 반환된 특징을 작업별로 테일 부 분에 전달하여 최종 출력을 산출할 수 있다. 실시예들은 다중 작업 학습을 수행하는 비전 변환기 모델을 클라이언트(접속자) 측의 모델과 서버 측의 모델로 분리하고 직접적인 데이터 공유 없이 분산 학습 방식으로 학습하는 방식을 사용한다. 위 과정에서 클라이언트 측에서 나온 표상 특징(feature representation) 및 클라이언트 모델 가중치가 서버 측 으로 전송되어야 하는데, 기존 분산 학습 방식을 활용할 경우에는 이 과정에서 서버로 전송되는 데이터를 외부 의 공격자가 해킹하거나, 혹은 서버 자체에서 이 데이터를 활용하여 개인정보를 복원하고자 할 경우 민감한 정 보를 식별 가능한 수준까지 복원 가능하였다. 그러나, 실시예들은 위 과정에 추가적으로 랜덤 패치 순열 치환 모듈을 적용하여, 서버 측으로 전송하는 데이터 는 패치 순열이 랜덤하게 치환되어 원본 데이터를 식별할 수 없는 표상 특징 데이터를 보내도록 한다. 또한, 서버 측에서 취합(aggregate)하여 분배(distribute)하는 모델 가중치 또한 일부만을 공유하도록 함으로써 전체 데이터를 역순으로 복원하는 것을 불가능하게 하였다. 이러한 두 가지 방식을 통하여 실시예들은 기존 분산 학 습 방식보다 개인 정보를 더 효과적으로 보호할 수 있다. 이와 같은 랜덤 패치 순열 치환 방식은 패치 순열 치 환 불변(patch permuation invariance)이라는 비전 변환기 모델의 특성을 활용한 것이다. 또한, 실시예들은 다중 학습 방식의 이점을 살려, 여러 작업을 수행하는 클라이언트 간에 모델 학습에 유용한 표상 특징 및 그래디언트(gradient)가 공유되도록 함으로써 단일 작업 모델에 비하여 최종 학습된 모델의 성능 을 향상시킬 수 있다. 실시예들은 기존 방식에 비하여 간단한 헤드(head) 모델을 사용하고 클라이언트 간에 같 은 헤드를 활용하는 방식으로 같은 표상 공간에서 학습되게 하고, 공유 트랜스포머 모듈이 대부분의 작업을 하 게 함으로써 다중 학습 방식의 이점이 극대화되도록 설계하였다. 그리고, 기존 다중 작업 분산 학습 방식에서 문제가 되었던 서버와 클라이언트 간의 지나치게 많은 통신량의 문 제에 대해, 실시예들은 학습 시작 시 표상 특징 데이터를 서버 측에 저장하고, 이를 학습 내내 활용하도록 함으 로써 통신량을 절반 수준으로 줄여 적은 비용을 학습이 가능하도록 하였다. 이는 랜덤 패치 순열 치환 모듈을 통하여 개인정보가 보호된 데이터를 서버 측으로 보내기 때문에 가능한 방식이며, 서버 측에 표상 특징이 저장 되더라도 서버가 이를 복원할 수 없다는 점을 효과적으로 활용한 방식이다. 위와 같은 개인정보 보호 다중 작업 분산 학습 기술은 의료 영상뿐만 아니라 다양한 분야에 적용할 수 있다. 비전 변환기 모델의 특성을 활용하여 랜덤 패치 치환으로 개인정보 보호를 하는 기술은, 비전 변환기 모델을 적 용할 수 있는 영상(imaging) 분야라면 모달리티에 관계 없이 적용이 가능하며, 인공지능 모델을 통하여 수행하 고자 하는 작업 또한 분류/분할/정량화 등 작업 종류에 관계없이 다양한 작업에 적용할 수 있다는 폭넓은 범용 성이 있다. 실시예들에 따르면, 개인정보 보호가 무엇보다 중요한 의료영상 분야에서 가장 효과적으로 적용될 수 있을 것으 로 기대된다. 연구에서 실험을 수행한 X-ray 영상 이외에도 모달리티에 관계없이 \"영상\" 정보이기만 하면 적용 할 수 있다는 장점으로 인하여 CT, MRI, PET 등 다양한 의료영상 모달리티에서 응용 가능하며, 다중 작업 학습 모델의 유연성으로 인하여 각 클라이언트가 서로 다른 작업을 수행하고 싶은 상황에서도 효과적으로 본 기술을적용할 수 있다는 장점이 있다. 또한, 의료 영상 분야 이외에도 스마트폰 등의 모바일 기기의 데이터를 활용한 분산 학습 환경 등에서도 효과적으로 적용될 수 있는데, 개인 스마트폰 등에 있는 영상 정보 또한 개인정보 보 호가 중요한 데이터이기 때문이다. 실시예들은 비전 변환기 모델을 기반으로 개발되었으나, 비전 변환기 모델에서 각각의 이미지 패치(patch)를 다 루는 방식이 자연어 처리를 위한 변환기 모델이 단어(word)를 다루는 방식과 거의 동일하며, 그 외의 구조도 유 사하다는 점을 고려하면, 본 기술을 자연어 처리 분야의 분산 학습 및 다중 작업 학습 모델에도 활용할 수 있을 것으로 기대된다. 실시예에서 패치 순열을 랜덤하게 섞어 개인정보를 보호한 방식과 유사하게 자연어 모델에서 도 단어의 순서를 랜덤하게 섞어 전체적인 개인정보에 대한 보호 효과를 기대할 수 있다. 이상과 같이, 실시예들은 분산 방식인 연합 학습 및 분할 학습 방식의 장점을 융합함과 동시에 다중 작업 학습 을 통하여 비전 변환기 모델의 성능 향상이 가능하도록 하였다. 또한, 실시예들은 기존 분산 학습 방식에서 문 제가 되던 공격자에 의한 민감한 개인정보 복원 문제를 랜덤 패치 순열 치환 방식을 통하여 불가능하게 함으로 써, 다른 개인정보 보호 방식을 활용하지 않아도 근본적으로 민감한 개인정보의 복원이 불가능하도록 하였는데 이는 비전 변환기 자체의 고유의 특성인 패치 순열 치환 불변성을 활용한 것이다. 이를 통하여 서버 측에 순열 치환된 데이터를 저장해놓고 학습할 수 있게 함으로써, 분산 학습 과정에서 전체적인 통신량을 절반 수준으로 감소시킬 수 있다. 이에 따라, 실시예들은 기존의 분산 학습 방식에 비하여 다중 학습 방식을 통한 성능 향상의 폭이 크고, 개인정 보 보호가 강화되었으며, 동시에 통신량 또한 절반 수준으로 크게 감소하였다. 이와 같은 향상은 비전 변환기 고유의 특성을 최대한으로 활용함으로써 얻은 효과이다. 따라서 실시예들은 기존 특허 방식들에 비하여 향상된 개인정보 보호를 제공하며, 의료 영상 인공지능 및 기타 영상 인공지능 분야에 폭넓게 적용 가능하다. 실시예들에 따른 기술이 가장 먼저 활용될 수 있는 의료 영상 인공지능 분야는 최근 몇 년간 시장 규모가 급격 하게 성장하고 있는 분야로, X-ray, CT, MRI 등 다양한 모달리티에 대해 인공지능 모델을 활용한 상품들이 출시 되고 있다. 그러나, 이와 같은 기존의 제품들은 단일 작업에 대하여 데이터를 중앙에서 취합하여 학습시키는 방식으로 개발된 제품들이기 때문에, 충분한 데이터가 모이기 어려운 세부 작업 등에 대해서는 제품이 출시되기 어렵고, 소수의 기관 데이터를 활용하여 학습된 모델이기 때문에 우수한 일반화 성능을 보이지 못하는 경우가 많다는 문제점이 있다. 실시예들은 이와 같은 기존 시장 제품들의 단점을 없애주는 기술로, 제품 개발에 필요 한 데이터의 직접적인 공유 및 중앙 취합 없이 모델을 학습하면서도 환자 개인정보를 보호할 수 있는 학습 프레 임워크를 제공할 수 있으며, 작업 종류에 관계 없이 폭넓게 활용하며 다중 작업 학습의 이점을 살려 성능을 더 욱 향상시킬 수 있다는 장점이 있다. 때문에, 의료인공지능 모델을 개발하는 회사 등에서 유용하게 활용될 수 있어 해당 회사들을 대상으로 개발 플랫폼 제품을 제공하는 방식으로 판매할 수 있으며, 연구 목적으로도 유용 하게 활용이 가능하기 때문에 병원, 대학 등의 연구 기관에도 연구용으로 플랫폼 판매를 기대해 볼 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0117686", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2022-0117686", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 기존 FESTA의 구조를 나타내는 도면이다. 도 2는 기존 FESTA의 학습 방법을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치의 구조를 설 명하기 위한 도면이다. 도 4는 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치의 학습 방법 을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 프라이버시를 강화하기 위한 순열 모듈을 나타내는 도면이다. 도 6은 일 실시예에 따른 각 클라이언트의 각 데이터에 대한 서로 다른 순열 패턴을 나타내는 도면이다. 도 7은 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변 환 방법을 나타내는 흐름도이다. 도 8은 일 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 나타내는 블록도이다. 도 9는 다른 실시예에 따른 랜덤 패치 순열 치환을 통한 분산 학습 기반의 다중 작업 비전 변환 장치를 이용한 변환 방법을 나타내는 흐름도이다."}
