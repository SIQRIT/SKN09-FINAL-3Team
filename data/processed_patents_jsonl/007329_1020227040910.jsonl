{"patent_id": "10-2022-7040910", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0005900", "출원번호": "10-2022-7040910", "발명의 명칭": "개인 다중 모드 인공 지능 플랫폼을 제공하기 위한 시스템 및 방법", "출원인": "트리플블라인드, 인코퍼레이티드", "발명자": "스톰 그렉"}}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법에 있어서,신경망(neural network)을 제1 클라이언트(client) 측 네트워크, 제2 클라이언트 측 네트워크 및 서버(server)측 네트워크로 분할하는 단계;상기 제1 클라이언트 측 네트워크를 제1 클라이언트에 발송하는 단계-여기서, 상기 제1 클라이언트 측 네트워크는 상기 제1 클라이언트로부터의 제1 데이터를 처리하도록 구성되고, 상기 제1 데이터는 제1 유형을 갖고 상기제1 클라이언트 측 네트워크는 적어도 하나의 제1 클라이언트 측 레이어(layer)를 포함함-;상기 제2 클라이언트 측 네트워크를 제2 클라이언트에 발송하는 단계-여기서, 상기 제2 클라이언트 측 네트워크는 상기 제2 클라이언트로부터의 제2 데이터를 처리하도록 구성되고, 상기 제2 데이터는 제2 유형을 갖고 상기제2 클라이언트 측 네트워크는 적어도 하나의 제2 클라이언트 측 레이어를 포함하고, 상기 제1 유형 및 상기 제2 유형이 공통 연관(common association)을 가짐-;상기 제1 클라이언트로부터의 제1 데이터에 대해 상기 제1 클라이언트 측 네트워크를 훈련시키고 제1 활성화(activation)들을 생성하는 단계;상기 제1 클라이언트 측 네트워크로부터 상기 서버 측 네트워크로 상기 제1 활성화들을 송신하는 단계;상기 제2 클라이언트로부터의 제2 데이터에 대해 상기 제2 클라이언트 측 네트워크를 훈련시키고 제2 활성화들을 생성하는 단계;상기 제2 클라이언트 측 네트워크로부터 상기 서버 측 네트워크로 상기 제2 활성화들을 송신하는 단계;그라디언트(gradient)들을 생성하기 위해 상기 제1 활성화들 및 상기 제2 활성화들에 기초하여 상기 서버 측 네트워크의 적어도 하나의 서버 측 레이어를 훈련시키는 단계; 및상기 서버 측 네트워크로부터 상기 제1 클라이언트 측 네트워크 및 상기 제2 클라이언트 측 네트워크로 상기 그라디언트들을 송신하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 공통 연관은 디바이스, 사람, 소비자, 환자, 비즈니스, 개념, 의학적 상태, 사람들의 그룹, 프로세스, 제품 및/또는 서비스 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 서버 측 네트워크는 글로벌 머신 러닝 모델(global machine learning model)을 포함하는,방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 신경망은 가중치(weight)들, 바이어스(bias) 및 하이퍼파라미터(hyperparameter)들을 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 적어도 하나의 제1 클라이언트 측 레이어 및 상기 적어도 하나의 제2 클라이언트 측 레이어는 동일한 수의 레이어들 또는 상이한 수의 레이어들을 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 절단 레이어(cut layer)는 상기 서버 측 네트워크와 상기 제1 클라이언트 측 네트워크 및 상기공개특허 10-2023-0005900-3-제2 클라이언트측 네트워크 사이에 존재하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제1 유형은 텍스트 데이터(text data)를 포함하고, 상기 제2 유형은 이미지 데이터(imagedata)를 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제1 클라이언트 측 네트워크 및 상기 제2 클라이언트 측 네트워크는 독립적이고 독립적으로 동작하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 제1 유형은 표 형식의(tabular) 데이터를 포함하고, 상기 제2 유형은 이미지 데이터를 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "시스템에 있어서,프로세서(processor); 및명령어(instructions)를 저장하는 컴퓨터 판독가능(computer-readable) 저장 디바이스를 포함하고, 상기 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금:신경망을 제1 클라이언트 측 네트워크, 제2 클라이언트 측 네트워크 및 서버 측 네트워크로 분할하는 것;상기 제1 클라이언트 측 네트워크를 제1 클라이언트에 발송하는 것-여기서, 상기 제1 클라이언트 측 네트워크는상기 제1 클라이언트로부터의 제1 데이터를 처리하도록 구성되고, 상기 제1 데이터는 제1 유형을 갖고, 상기 제1 클라이언트 측 네트워크는 적어도 하나의 제1 클라이언트 측 레이어를 포함함-;상기 제2 클라이언트 측 네트워크를 제2 클라이언트에 발송하는 것-여기서, 상기 제2 클라이언트 측 네트워크는상기 제2 클라이언트로부터의 제2 데이터를 처리하도록 구성되고, 상기 제2 데이터는 제2 유형을 갖고, 상기 제2 클라이언트 측 네트워크는 적어도 하나의 제2 클라이언트 측 레이어를 포함하며, 상기 제1 유형 및 제2 유형은 공통 연관을 가짐-; 상기 서버 측 네트워크에서, 상기 제1 클라이언트로부터의 제1 데이터에 대한 상기 제1 클라이언트 측 네트워크의 훈련으로부터 제1 활성화들을 수신하는 것;상기 서버 측 네트워크에서, 상기 제2 클라이언트로부터의 제2 데이터에 대한 상기 제2 클라이언트 측 네트워크의 훈련으로부터 제2 활성화들을 수신하는 것;그라디언트들을 생성하기 위해 상기 제1 활성화들 및 상기 제2 활성화들에 기초하여 상기 서버 측 네트워크의적어도 하나의 서버 측 레이어를 훈련시키는 것; 및상기 서버 측 네트워크로부터 상기 제1 클라이언트 측 네트워크 및 상기 제2 클라이언트 측 네트워크로 상기 그라디언트들을 송신하는 것을 포함하는 동작들을 수행하게 하는, 시스템."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 공통 연관은 디바이스, 사람, 소비자, 환자, 비즈니스, 개념, 의학적 상태, 사람들의 그룹, 프로세스, 제품 및 /또는 서비스 중 적어도 하나를 포함하는, 시스템."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 서버 측 네트워크는 글로벌 머신 러닝 모델을 포함하는, 시스템."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 신경망은 가중치들, 바이어스 및 하이퍼파라미터들을 포함하는, 시스템.공개특허 10-2023-0005900-4-청구항 14 제10항에 있어서, 상기 적어도 하나의 제1 클라이언트 측 레이어 및 상기 적어도 하나의 제2 클라이언트 측 레이어는 동일한 수의 레이어들 또는 상이한 수의 레이어들을 포함하는, 시스템."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서, 절단 레이어는 상기 서버 측 네트워크와 상기 제1 클라이언트 측 네트워크 및 상기 제2 클라이언트 측 네트워크 사이에 존재하는, 시스템."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서, 상기 제1 유형 및 상기 제2 유형은 상이한 유형들의 데이터인, 시스템."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서, 상기 제1 유형은 표 형식의 데이터 또는 시계열 데이터를 포함하고, 상기 제2 유형은 이미지데이터를 포함하는, 시스템."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "방법에 있어서,신경망을 제1 클라이언트 측 네트워크, 제2 클라이언트 측 네트워크 및 서버 측 네트워크로 분할하는 단계;상기 제1 클라이언트 측 네트워크를 제1 클라이언트에 발송하는 단계-여기서, 상기 제1 클라이언트 측 네트워크는 상기 제1 클라이언트로부터의 제1 데이터를 처리하도록 구성되고, 상기 제1 데이터는 제1 유형을 갖고 상기제1 클라이언트 측 네트워크는 적어도 하나의 제1 클라이언트 측 레이어를 포함함-;상기 제2 클라이언트 측 네트워크를 제2 클라이언트에 발송하는 단계-여기서, 상기 제2 클라이언트 측 네트워크는 상기 제2 클라이언트로부터의 제2 데이터를 처리하도록 구성되고, 상기 제2 데이터는 제2 유형을 갖고 상기제2 클라이언트 측 네트워크는 적어도 하나의 제2 클라이언트 측 레이어를 포함하고, 상기 제1 유형 및 상기 제2 유형이 공통 연관을 가짐-;상기 서버 측 네트워크에서, 상기 제1 클라이언트로부터의 제1 데이터에 대한 상기 제1 클라이언트 측 네트워크의 훈련으로부터 제1 활성화들을 수신하는 단계;상기 서버 측 네트워크에서, 상기 제2 클라이언트로부터의 제2 데이터에 대한 상기 제2 클라이언트 측 네트워크의 훈련으로부터 제2 활성화들을 수신하는 단계;그라디언트들을 생성하기 위해 상기 제1 활성화들 및 상기 제2 활성화들에 기초하여 상기 서버 측 네트워크의적어도 하나의 서버 측 레이어를 훈련시키는 단계; 및상기 서버 측 네트워크로부터 상기 제1 클라이언트 측 네트워크 및 상기 제2 클라이언트 측 네트워크로 상기 그라디언트들을 송신하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 제1 유형 및 상기 제2 유형은 상이한 유형들의 데이터인, 방법."}
{"patent_id": "10-2022-7040910", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서, 상기 제1 유형은 표 형식의 데이터 또는 시계열 데이터를 포함하고, 상기 제2 유형은 이미지데이터를 포함하는, 방법."}
{"patent_id": "10-2022-7040910", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "개인 다중 모드 인공 지능 플랫폼을 제공하기 위한 시스템 및 방법이 개시된다. 방법은 신경망을 제1 클라이언트 측 네트워크, 제2 클라이언트 측 네트워크 및 서버 측 네트워크로 분할하고 제1 클라이언트 측 네트워크를 제1 클라이언트에 발송하는 단계를 포함한다. 제1 클라이언트 측 네트워크는 제1 클라이언트로부터의 제1 데이터를 처리하고, 제1 데이터는 제1 유형을 갖는다. 본 방법은 제2 클라이언트 측 네트워크를 제2 클라이언트에 발송하 는 단계를 포함한다. 제2 클라이언트 측 네트워크는 제2 클라이언트로부터의 제2 데이터를 처리하고, 제2 데이터 는 제2 유형을 갖는다. 제1 유형과 제2 유형은 공통 연관을 갖는다. 순방향 및 역전파는 클라이언트 측 네트워크 들과 다른 클라이언트 측 네트워크들의 이질적인 데이터 유형들과 서버 측 네트워크 사이에서 발생하여 신경망을 훈련시킨다."}
{"patent_id": "10-2022-7040910", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "우선권 주장 본 출원은 2020년 5월 6일에 출원된 미국 가출원 번호 63/020,930(문서 번호 213-0104P)에 대한 우선권을 주장 하며, 그 내용은 본 명세서에 참조로 포함된다. 본 출원은 2019년 12월 13일에 출원된 미국 가출원 번호 제 62/948,105호에 대한 우선권을 주장하는 2020년 3월 24일자로 출원된 미국 출원 번호 16/828,085(문서 번호 213-0100)의 일부 계속출원이며, 그 내용은 본 명세서에 참조로 포함된다. 본 출원은 2019년 12월 13일에 출원 된 미국 가출원 번호 제62/948,105호에 대한 우선권을 주장하는 2020년 3월 24일에 출원된 미국 출원 번호 16/828,216(문서 번호 213-0101)의 일부 계속출원이며, 그 내용은 본 명세서에 참조로 포함된다. 본 출원은 2019년 12월 13일에 출원된 미국 가출원 번호 제62/948,105호에 대한 우선권을 주장하는 현재 2021년 2월 16일 자로 등록된 미국 특허 번호 제10,924,460호인, 2020년 3월 24일에 출원된 미국 출원 번호 제16/828,354(213- 0102)의 계속출원인, 2021년 2월 16일에 출원된 미국 출원 번호 제17/176,530(213-0102-CON)호의 일부 계속출 원이며, 이는 이제 그 내용이 참조로 본 명세서에 포함된다. 본 출원은 2019년 12월 13일에 출원된 미국 가출원 번호 제62/948,105호에 대한 우선권을 주장하는 2020년 3월 24일에 출원된 미국 출원 번호 제16/828,420(문서 번호 213-0103)호의 일부 계속출원이며, 그 내용은 본 명세서에 참조로 포함된다. 기술 분야 본 개시는 일반적으로 신경망들 훈련에 관한 것으로 다양한 소스들로부터의 훈련 데이터가 발견 가능하지 않도 록 보호하는 방식으로 신경망들 또는 다른 훈련된 모델들을 훈련 및 전개하기 위한 새로운 기술들을 소개한다."}
{"patent_id": "10-2022-7040910", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "신경망들 훈련에 대한 기존 접근법들이 존재하며 연합 훈련 접근법(federated training approach) 또는 중앙 집 중식 훈련 접근법(centralized training approach)을 사용한다. 신경망들 훈련에 대한 기존 접근법 각각은 다른 클라이언트들로부터 받은 데이터를 기반으로 한다. 이 맥락에서 데이터를 공유하는 프로세스로 인해 데이터가 누출되거나 발견 가능하게 될 수 있다. 예를 들어, 의료 맥락에서 딥 러닝 또는 머신 러닝은 진단들에 의미가 있는 훈련된 모델들에서 충분한 정확도를 생성하기 위해 대규모 데이터세트들을 요구할 수 있다. 이러한 데이터는 여러 환자들 또는 환자 범주들에 대한 X-선들 또는 MRI들에 대한 데이터가 포함할 수 있다. 이러한 모델들을 훈련하는 한 가지 접근법은 원시 데이터 를 풀링한 다음 분석가가 풀링된 데이터의 중앙 저장소에 액세스하여 대규모 데이터세트에 대해 머신 러닝을 수 행할 수 있다는 것이다. 그러나 이 접근법에는 윤리적 이슈들과 프라이버시 이슈들뿐만 아니라 단일 지점 실패 및 보관 요구 사항들과 같은 기타 이슈들이 있다."}
{"patent_id": "10-2022-7040910", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "도입 본 개시의 특정 양태 및 실시양태가 아래에 제공된다. 이들 양태 및 실시예 중 일부는 독립적으로 적용될 수 있 고 이들 중 일부는 당업자에게 명백한 바와 같이 조합하여 적용될 수 있다. 다음 설명에서, 설명의 목적으로, 애플리케이션의 실시예에 대한 완전한 이해를 제공하기 위해 특정 세부사항이 제시된다. 그러나, 이러한 특정 세부사항 없이 다양한 실시예가 실시될 수 있음이 명백할 것이다. 도면 및 설명은 제한하려는 의도가 아니다. 이어지는 설명은 예시적인 실시예만을 제공하며, 본 개시의 범위, 적용 가능성 또는 구성을 제한하도록 의도되 지 않는다. 오히려, 예시적인 실시예의 다음 설명은 예시적인 실시예를 구현하기 위한 가능한 설명을 당업자에 게 제공할 것이다. 첨부된 특허청구범위에 기술된 적용의 사상 및 범위를 벗어나지 않으면서 요소의 기능 및 배 열에 다양한 변경이 이루어질 수 있음을 이해해야 한다. 간단한 설명 당업계에서 필요한 것은 모델이 훈련된 데이터를 비공개로 유지하는 신경망 모델을 훈련하기 위해 알려진 접근 법들을 결합하는 방법 및 시스템이다. 이전 접근법을 사용하면 훈련 데이터가 누출되거나 훈련 프로세스의 일부 로 발견될 수 있다. 본 명세서에 개시된 개선된 접근법은 또한 보관 문제와 같은 다른 문제를 처리하고 실패 문 제의 단일-포인트를 제거할 수 있다. 본 개시는 먼저 알려진 접근법을 논의한 다음 새로운 접근법을 소개한다. 일 양태에서, 특정 플랫폼은 신경망 모델의 연합 개발 또는 훈련을 가능하게 하기 위해 사용된다. 이러한 방식 으로 모델을 훈련하기 위한 개시된 플랫폼의 사용은 본 명세서의 다른 실시예로서 개시된다. 또 다른 실시예에 서, 데이터는 서버와 하나 이상의 클라이언트 디바이스 사이에서 전달될 때 암호화된다. 다양한 유형의 연합 러 닝(도 1에 도시), 분할 러닝(도 2에 도시) 및 분할 러닝 피어-투-피어(도 3에 도시)가 본 명세서에 개시되어 있 다. 본 개시는 기존 접근법에 대한 몇 가지 새로운 개선 사항을 제공한다. 일반적인 연합 러닝은 클라이언트 데이터를 사용한 훈련을 위해 서버에서 클라이언트 디바이스로 전체 모델을 전달하는 작업 포함한다. 이 프로세스는 교육 목적으로 각각의 데이터가 있는 여러 클라이언트를 사용하는 것을 포함할 수 있다. 이 접근법은 일반적으로 전체 모델이 데이터와 함께 제1 클라이언트에 발송된 다음 제1 클라이 언트에서 훈련된 후 전체 모델이 \"평균화\"를 위해 서버로 다시 수신되는 선형 및 반복 방식으로 수행된다. 그런 다음 전체 업데이트된 모델이 추가 처리를 위해 데이터와 함께 제2 클라이언트로 발송된다. 그런 다음 업데이트 된 모델은 추가 \"평균화\" 등을 위해 서버로 다시 발송된다. 분할 러닝 접근법에서는 모델이 분할되고 일부가 각 클라이언트에 발송되지만 여전히 비효율적인 선형 및 대화형 훈련 프로세스가 존재한다. 분할 러닝 피어-투-피 어 접근법은 피어 클라이언트가 선형 프로세스에서 데이터를 공유하므로 선형적으로 수행된다. 데이터의 프라이 버시를 유지하기 위한 개선과 훈련 프로세스의 효율성이 필요하다. 본 개시는 연합 러닝 및 분할 러닝에 대한 2가지 주요 개선점을 설명한다. 첫 번째는 클라이언트 측 처리가 다 른 클라이언트와 병렬로 및 독립적으로 발생하는 연합 분할 학습 접근법(도 4 내지 5 참조)이다. 두 번째로 개 시된 접근법(도 6 내지 10에 도시됨)은 상이한 클라이언트로부터 상이한 유형의 데이터를 처리하기 위한 다중 모드 인공 지능(MMAI) 훈련 접근법에 관한 것이다. 위에서 언급한 바와 같이, 연합 분할 러닝 접근법은 위의 전형적인 연합 러닝 접근법의 변형으로서 개시된다. 이와 관련하여 방법은 서버에서 신경망을 제1 부분 및 제2 부분으로 분할하는 단계, 및 제2 부분을 개별적으로 제1 클라이언트 및 제2 클라이언트에 발송하는 단계를 포함한다. 클라이언트는 데이터(MRI, 환자 데이터, 고객 을 위한 은행 데이터 등)를 가질 수 있으며 각각은 신경망의 일부(절단 레이어까지 네트워크의 특정 수의 레이 어)를 수신할 수 있다. 이 방법은 임계값이 충족될 때까지 다음 동작을 수행하는 것을 포함한다: 데이터 SA1 및 SA2를 생성하기 위해 제1 클라이언트 및 제2 클라이언트에서 제2 부분에 대한 순방향 단계를 동시에 수 행하는 단계(도 1 내지 4 참조); 제1 클라이언트 및 제2 클라이언트로부터 SA1 및 SA2를 서버로 송신하는 단계; 서버에서 제1 클라이언트 및 제2 클라이언트에 대한 손실 값을 계산하는 단계; 서버에서 제1 클 라이언트와 제2 클라이언트에 걸친 평균 손실을 계산하는 단계; 서버에서 평균 손실을 사용하여 역전파를 수행하고 그라디언트를 계산하는 단계; 및 서버로부터 그라디언트를 제1 클라이언트와 제2 클라이언트로 발 송하는 단계. 이 접근법은 클라이언트 측(또는 \"데이터 서버\" 측)의 처리가 서로 독립적이고 병렬로 동작하도록 하여 연합 러닝 접근법 및 분할 러닝 접근법보다 향상된 기능을 제공한다. 이 접근법은 또한 분할 러닝 피어-투 -피어 접근법과도 상이하다. 독립적인 데이터 서버는 최종 훈련 모델을 얻기 위해 네트워크 요구 사항에 따라 데이터를 집계, 평균화 또는 처리하는 서버 측에 그들의 활성화를 발송한다.본 개시의 다른 양태는 다중 상이한 모드의 데이터 또는 데이터 유형이 훈련에 사용될 수 있는 인공 지능 모델 을 개발하는 데 있어서의 개선에 관한 것이다. 예를 들어 클라이언트마다 데이터 유형이 다를 수 있다. 한 클라 이언트는 X-선 또는 MRI 이미지를 가지고 있고 다른 클라이언트는 환자의 건강 상태를 설명하는 텍스트를 가지 고 있을 수 있다. 이와 관련하여, 방법은 신경망을 제1 클라이언트측 네트워크, 제2 클라이언트측 네트워크 및 서버측 네트워크로 분할하고, 제1 클라이언트측 네트워크를 제1 클라이언트에 발송하는 단계를 포함할 수 있다. 제1 클라이언트 측 네트워크는 제1 클라이언트로부터의 제1 데이터를 처리하도록 구성되며, 제1 데이터는 제1 유형을 갖는다. 제1 클라이언트측 네트워크는 적어도 하나의 제1 클라이언트측 레이어를 포함할 수 있다. 이 방 법은 제2 클라이언트 측 네트워크를 제2 클라이언트에 발송하는 단계를 포함한다. 제2 클라이언트측 네트워크는 제2 클라이언트로부터의 제2 데이터를 처리하도록 구성되며, 제2 데이터는 제2 유형을 갖는다. 제2 클라이언트 측 네트워크는 적어도 하나의 제2 클라이언트 측 레이어를 포함할 수 있으며, 여기서 제1 유형 및 제2 유형은 공통 연관을 갖는다. 방법은 서버 측 네트워크에서, 제1 클라이언트로부터의 제1 데이터에 대한 제1 클라이언트 측 네트워크의 훈련 으로부터 제1 활성화를 수신하는 단계, 서버 측 네트워크에서, 제2 클라이언트로부터의 제2 데이터에 대한 제2 클라이언트 측 네트워크의 훈련으로부터 제2 활성화를 수신하는 단계, 그라디언트를 생성하기 위해 제1 활성화 및 제2 활성화에 기초하여 서버 측 네트워크의 적어도 하나의 서버 측 레이어를 훈련하는 단계, 및 서버 측 네 트워크에서 제1 클라이언트 측 네트워크 및 제2 클라이언트 측 네트워크로 그라디언트를 발송하는 단계를 더 포 함할 수 있다. 이러한 방식으로 단일 환자 또는 단일 유형 또는 환자 범주와 같은 공통 관계를 갖는 여러 유형 의 데이터를 사용하여 모델이 학습될 수 있다."}
{"patent_id": "10-2022-7040910", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이 요약은 청구된 요지의 핵심 또는 필수 피쳐를 식별하도록 의도되지 않았으며, 청구된 요지의 범위를 결정하 기 위해 단독으로 사용되도록 의도되지 않는다. 주제는 이 특허의 전체 명세서, 일부 또는 모든 도면 및 각 청 구범위의 적절한 부분을 참조하여 이해되어야 한다. 전술한 내용은 다른 피쳐 및 실시예와 함께 다음 명세서, 청구범위 및 첨부 도면을 참조하면 더욱 명확해질 것 이다. 상세한 설명 신경망들 훈련에 대한 개선된 접근법을 가능하게 할 새로운 시스템, 플랫폼, 컴퓨팅 환경, 클라우드 환경, 시장, 또는 시스템의 임의의 다른 특성화가 본 명세서에 개시된다. 하나의 양태에서, 접근법은 알려진 접근법들 의 피쳐들을 결합하지만 다양한 클라이언트 디바이스들로부터 모델을 훈련하는 데 사용되는 데이터에 대한 프라 이버시를 유지하는 훈련 프로세스를 제공하는 연합-분할 러닝 접근법이라고 한다. 이 개시는 먼저 연합 러닝 접 근법을 더 자세히 논의하고, 분할 러닝 접근법과 분할 러닝 피어-투-피어 접근법에 이어 새로운 연합 분할 러닝 접근법을 소개한다. 또한 다양한 유형들의 데이터에 대한 다중 모드 인공 지능(MMAI) 러닝 접근법도 소개된다. 새로운 연합 분할 러닝 접근법과 MMAI 접근법은 위에서 언급한 모델들을 포함한 여러 모델들을 기반으로 한다. 애플리케이션은 이러한 제1 접근법들을 더 자세히 검토한 다음 두 가지 새로운 러닝 기술들을 소개한다. 연합 러닝 도 1은 연합 러닝 접근법을 예시한다. 이것은 현재 주요 회사들에 의해 사용되는 접근법이다. 이 접근법의 단점은 병렬이 아니라 한 번에 하나의 데이터 공급자에게 \"선형\"으로 진행된다는 것이다. 도시된 신경망의 예는 연합 러닝 접근법을 사용하여 훈련되는 완전 연결된 피드 포워드 신경망(feed forward neural network)이다. 이 경우의 훈련 프로세스는 모델을 생성하고 선형으로 개별의 클라이언트들(106, 108, 110)과 모델(106A, 108A 및 110A)을 공유하는 서버를 포함한다. 클라이언트들은 차례대로 모델을 수신할 때 개별의 모델 (106A, 108A, 110A)을 따로 훈련시키고 도시된 바와 같이 훈련된 모델 데이터를 개별 서버로 다시 발송한 다. 서버는 모델들을 평균화하고 업데이트된 가중치들을 갖는 새로운 모델(일명 훈련된 모델)을 생성 한다. 서버는 새로운 모델 또는 가중치들을 선형 방식으로 개별의 클라이언트들(106, 108, 110)에 발송한 다. 프로세스는 여러 번 반복되거나 특정 정확도가 달성될 때까지 반복된다. 각각의 반복에서, 서버는 훈련된 모델 B를 생성하기 위해 모든 참여 모델들을 평균화한다. 따라서, 서버는 임의의 시점에서 완전히 훈련된 모델을 갖는다. \"글로벌 모델\"이라는 용어는 훈련 프로세스의 결과인 모델 을 지칭한다. 글로벌 모델은 추론 작업에 사용되는 훈련된 개체이다. 추론 작업은 환자가 암이나 부러진 뼈 또 는 기타 의학적 상태에 있는지 여부를 분류하기 위해 의료 이미지를 평가하는 것일 수 있다. 사용되는 이 접근법의 예, 전자 시계와 같은 디바이스들 또는 모바일 디바이스, 예를 들어 야간에 충전하고, Wi-Fi 네트워크에 연결된 디바이스는 신경망 모델들을 훈련하는 데 사용되는 그의 프로세서를 가질 수 있다. 따 라서, 클라이언트 1은 애플 와치(Apple watch)가 될 수 있고, 클라이언트 2는 다른 사람의 아이폰 (iPhone)이 될 수 있으며, 기타 등등이 가능하다. 애플(Apple)에서 제공하는 시리(Siri) 음성 처리 서비스를 모 델로 들 수 있다. 모든 디바이스는 동일한 모델을 훈련하고 있으며 유일한 차이점은 개별 클라이언트가 로컬 데 이터에 대해 훈련한다는 것이다. 모델 또는 데이터는 서버로 다시 송신되고 서버는 모델을 함께 평균화한 다. 단점은 클라이언트 1과 같은 개별 클라이언트들이 속아서 모델을 훈련하는 데 사용되는 데이터에 대한 무언가를 공유할 수 있다는 것이다. 이것은 프라이버시 데이터의 누출이 될 것이며 위에서 설명한 이슈를 제기 할 것이다. 연합 러닝 접근법의 문제는 전체 모델이 클라이언트로부터 클라이언트로 전달되기 때문에 모델 프라 이버시가 없다는 것이다. 각 클라이언트가 전체 모델을 처리하기 때문에 높은 계산 비용이 발생하고 전체 모델 이 여러 번 송신되기 때문에 많은 통신 오버헤드가 발생한다. 재구성 공격은 훈련 데이터를 또한 취약하게 만들 수 있다. 분할 러닝 도 2는 분할 러닝 중앙 집중식 접근법을 예시한다. 모델(신경망)은 두 부분들로 분할된다: 한 부분(206A, 208A, 210A)은 개별 클라이언트 측(206, 208, 210)에 상주하고 모델에 대한 입력 레이어 및 선택적으로 절단 레 이어(cut layer)까지의 다른 레이어들을 포함하며, 그리고 다른 부분(B)은 서버 측에 상주하고 종종 출력 레이어를 포함한다. 분할 레이어(S)는 A와 B가 분할된 레이어(절단 레이어)를 지칭한다. 도 2에서 SA는 A로부터 B로 발송된 분할 레이어 또는 데이터를 나타내고 SB는 B로부터 A로 발송된 분할 레이어를 나타낸다. 일례에서, B와 클라이언트 1 사이의 신경망은 전체 신경망을 완성하기 위한 데이터 SB1(206C) 및 SA1(206B)의 통신을 갖는 B 부분에 A1 부분(206A)을 더한 것이다. 이 모델에서 훈련 프로세스는 다음과 같 다. 서버는 A와 B를 생성하고 개별 모델 A(206A, 208A, 210A)를 개별 클라이언트(206, 208, 210)에 발송 한다. 모든 클라이언트에 대해, 동작들은 일부 조건들이 발생할 때까지 클라이언트들 그룹에서 선형 또는 반복 방식으로 다음을 반복하는 것을 포함한다. 개별 클라이언트(206, 208, 210)는 차례로 서버로부터 가장 최 근의 모델 A를 다운로드한다(이 단계는 도 2와 도 3에 도시된 접근법이 다르다는 점에 유의). 클라이언트들 (206, 208, 210)은 개별 차례에서 모델 A에 대해 순방향 단계를 수행하고 A의 출력(즉, S에서만 활성화 또는 SA1(206B), SA2(208B), SAN(210B))을 필수 레이블들에 더해 서버로 발송한다. 서버는 개별 클라이언 트(206, 208, 210)로부터 수신된 SA들을 사용하여 B에 대한 순방향 단계를 수행한다. 서버는 손실 함수 (loss function)를 계산하고 서버는 역전파(backpropagation)를 수행하고 S 레이어에서 그라디언트 (gradient)들을 계산한다. 서버는 S만의 그라디언트(즉, SB1(206C), SB2(208C), SBN(210C))를 개별 클라 이언트(206, 208, 210)에 발송한다. 이 프로세스는 클라이언트에 대해 먼저 동작들이 발생하고 클라이언트 가 그 다음 클라이언트에 대해 발생하도록 서로 다른 클라이언트들에 걸쳐 선형으로 수행된다. 클라 이언트(206, 208, 210)는 서버로부터 수신된 SB 그라디언트들을 사용하여 역전파를 수행하고 클라이언트 (206, 208, 210)는 업데이트된 A(SA1(206B), SA2(208B), SAN(210B))를 서버와 공유한다. 도 2의 수평축은 클라이언트로부터 클라이언트로 라운드 로빈(round-robin) 방식으로 처리가 발생하는 시간이다. 일례에서, 클라이언트 1 상의 네트워크 A1(206A)은 컨볼루션(convolution) 레이어 및 활성화 레이어를 포함할 수 있다. 데이터를 처리한 클라이언트 1은 해당 레이어의 결과(SA1(206B))를 위에서 설명한 대로 역전파 등을 계산하는 서버에 있는 네트워크의 다음 레이어로 발송한다. B 네트워크는 (라운드 로빈 방식으로) 반 복적으로 다른 클라이언트들(206, 208, 210)로부터의 다른 데이터를 처리한다. 그것은 궁극적으로 네트워크의 평균 반영(averaged reflection)에 도달한다. 그것은 절대 동시에 모든 클라이언트들(206, 208, 210)의 모든 데이터에 대해 네트워크를 훈련하지 않는다. 그것은 데이터를 더 빠르게 처리할 수 있고 B가 구축될 때 데이터 전체에서 평균화된다는 이점이 있다. 최종 알고리즘은 모든 데이터를 확인하지 못했다. 모델 B는 모든 데이터에 대해 훈련된 적이 없기 때문에 그것의 데이터를 공개하도록 속여질 수 없다. 피어-투-피어 환경에서의 분할 러닝 도 3은 분할 러닝 피어-투-피어 접근법을 예시한다. 모델(신경망)은 두 부분들로 나뉜다: 한 부분(A)은 클라이 언트 측에 상주하고 입력 레이어를 포함하고, 다른 부분(B)은 서버 측에 상주하고 종종 출력 레이어를 포함한다. 도 3에서, 클라이언트 측 부분(A)은 클라이언트에서 A1(306A), 클라이언트에서 A2(308A), 클라이언트에서 AN(310A)으로 개별로 도시되어 있다. 분할 레이어(S)는 A와 B가 분할된 레이어를 지칭한다. 도 3에서 SA는 A로부터 B로 발송되는 분할 레이어를 나타내고 SB는 B로부터 A로 발송되는 분할 레이어를 나타낸다. 일례에서, B와 클라이언트 1 사이의 신경망은 전체 신경망을 완성하기 위해 데이터 SB1(306C) 및 SA1(306B)의 통신과 함께 B 부분에 A1 부분(306A)을 더한 것이다. 이 모델에서 훈련 프로세스는 다음과 같다. 서버는 A와 B를 생성하고 A를 클라이언트(306, 308, 310)에. 모든 클라이언트에 대해, 프로세스는 일부 조 건들이 발생할 때까지 다음을 반복하는 것을 포함한다. 첫째, 프로세스는 이전 클라이언트로부터 가장 최근 A 를 다운로드하는 것을 포함한다. 이 단계는 다른 도면들에 도시된 접근 법과 다르다는 것을 유의한다. 그 다음, 프로세스는 A에 대한 순방향 단 계를 수행하고 A의 출력(즉, S에서만 활성화들)을 필요한 레이블들에 추가하여 서버로 발송하는 것을 포함 한다. 서버는 개별 클라이언트(306, 308, 310)로부터 수신된 SA를 사용하여 B에 대한 순방향 단계를 수행 한다. 서버는 손실 함수를 계산하고 역전파를 수행하고 S에서 그라디언트들을 계산한다. 서버는 S만 의 그라디언트들(즉, SB)을 개별 클라이언트(306, 308, 310)에 발송한다. 클라이언트는 서버로부터 수신된 SB 그라디언트들을 사용하여 역전파를 한다. 클라이언트는 업데이트된 A를 서버와 공유한다. 피어-투-피어 접근법은 일반적으로 마지막 훈련된 클라이언트로부터, 또는 더 광범위하게는, 이전에 훈련된 클 라이언트로부터 직접 다운로드함으로써 개별 클라이언트가 그것들의 A 모델을 업데이트하는 것을 포함한다. 이 와 관련하여, 클라이언트들을 훈련시키는 프로세스는 클라이언트가 순차적으로 훈련되는 라운드 로빈 방식으로 발생할 수 있다. 예를 들어, 클라이언트 1이 먼저 훈련되면, 클라이언트 2가 서버 또는 다른 신 뢰할 수 있는 서버로부터 클라이언트 측 모델 A2를 업데이트하기보다는 피어-투-피어 모델에서, 클라이언트 2는 클라이언트 1로부터 클라이언트 측 모델 A1을 다운로드함으로써 클라이언트 모델 A2를 업데이트 한다. 이전에 훈련된 모델은 마지막으로 훈련된 클라이언트 모델일 수 있거나 일부 기준에 기초하여 이전에 훈 련된 일부 다른 클라이언트로부터의 모델일 수 있다. 예를 들어, 클라이언트 1 및 클라이언트 2는 개 별 모델들을 훈련시킬 수 있다. 클라이언트 3은 클라이언트 측 모델 업데이트가 필요하고 클라이언트 1과 클라이언트 2 사이에서 다운로드할 클라이언트 측 모델을 결정하기 위한 알고리즘 또는 프로세스 를 구현할 수 있다. 아래 개시 내용은 여기서 적용될 수 있는 다중 모델 인공 지능 훈련 프로세스를 구현한다는 것에 유의한다. 클라이언트 1이 이미지들을 처리하고 그 모델 A1이 이미지 처리에 포커스를 맞추고, 클라 이언트 2가 텍스트를 처리하고 그 모델 A2가 텍스트 처리에 포커스를 맞추고, 클라이언트 3이 이미지 들을 처리한다면, 알고리즘 또는 프로세스는, 피어-투-피어 환경에서, 클라이언트 측 모델 A1을 업데이트로서 클라이언트 3에 다운로드하게 할 수 있다. 일 시나리오에서, 신경망의 적절한 훈련을 달성하기 위해 분할 러닝으로부터의 정보가 충분하지 않다. 이 모델 에서는 A 및 B가 단순히 적층 (A 및 B)되어 일반 텍스트로 서버에서 집계되는 것이 좋은 훈련 접근법일 수 있다고 가정한다. 연합 분할 러닝 도 4는 본 명세서에 개시된 훈련 신경망들에 대한 개선을 예시한다. 이 개선은 연합 분할 러닝 접근법으로 특징 지어질 수 있으며 위에서 설명한 접근법들의 일부 결함을 다룬다. 도 4는 병렬 처리 접근법을 소개한다. 병렬 및 독립 처리로 인해 위에서 설명한 다른 모델들보다 빠른 속도로 모델 훈련이 발생한다. 연합 분할 러닝 접근법은 위에서 설명한 라운드 로빈 처리를 수행하지 않는다. 서버는 네트워크 정의 코드 (network definition code)들에 삽입된 사용자 파라미터인 \"분할 레이어(split layer)\"에서 네트워크를 분할한 다. 네트워크의 \"상단 부분(top portion)\"은 서버에서 유지되고 \"하단 부분(bottom portion)\"은 개별 데 이터 제공자들 또는 클라이언트들(406, 408, 410)로 발송된다(클라이언트들 및 데이터 제공자들이라는 용어는 여기서 상호 교환 가능하게 사용됨). 훈련은 데이터에 가장 가까운 레이어인 가장 낮은 네트워크 레이어에서 시 작된다. 각 레이어는 데이터(제1 레이어로부터) 또는 이전 레이어의 출력(다른 모든 레이어들)을 판독한다. 레이어들은 임의의 유효한 네트워크 아키텍처 커맨드(컨볼루션들, 드롭아웃(dropout)들, 배치 정규화, 플랫화된 레이어들 등) 및 활성화 함수(relu, tanh 등)에 기초하여 출력(활성화 함수에서 가져오기 때문에 \"활성화 (activation)들\"이라고 한다)을 계산할 수 있다. 데이터 측(406, 408, 410)의 마지막 레이어가 적절한 활성화들 (즉, 출력)을 계산하면 해당 출력은 \"분할의 다른 측\"에 있는 제1 레이어-서버 측의 제1 레이어로 발송된 다. 다음 접근법은 이전과 같이 모델을 분할하는 것을 포함한다. A 모델은 두 부분으로 분할된다: (A)는 클라이언트 측에서 입력 레이어를 포함하고 (B)는 서버 측에서 종종 출력 레이어를 포함한다. (S)는 분할 레이어이다. 클라이언트들 또는 데이터 제공자들(406, 408, 410)은 독립적으로 실행되고 응답이 있으면 응답을 다시 발송한다. 서버의 코드는 데이터를 처리하고 그 출력을 SB(406C, 408C, 410C)로 모든 클라이언트에 동일하게 다시 발 송한다. 예시적인 훈련 프로세스는 다음과 같다. 서버는 A 및 B를 생성하고 부분 A(406A, 408A, 410A)를 클라이언 트들(406, 408, 410)에 발송한다. 다음 단계들은 조건(예를 들어, 정확도)이 충족될 때까지 반복된다. 모든 클 라이언트들(406, 408, 410)은 A에 대한 순방향 단계를 동시에 수행한다. 이 시점까지, 클라이언트들(406, 408, 410)에 대한 모든 계산들은 독립적인 서버들에서 수행되고 있으며 한 데이터 서버로부터 다른 서버로의 종속성 이 없다. 이 접근법은 본 명세서에 공개된 혁신들 중 하나를 강조한다. 클라이언트들/데이터 제공자들(406, 408, 410)에 의한 이러한 모든 계산들은 동시에 병렬로 모두 동작할 수 있다. 이것은 위에서 논의한 선형 또는 \"라운드 로빈\" 방식과 대조된다. 클라이언트들(406, 408, 410)은 각각 신경망의 A 부분(406A, 408A, 410A)을 실행하고 A(즉, SA(406B, 408B, 410B))의 개별 출력을 생성하고 출력을 서버로 발송한다. 서버는 3개의 다른 '버전들'의 활성화들 (SA1, SA2, SA3 각각에서 하나씩)을 수신한다. 이 시점에서, 서버는 그러한 활성화들을 \"적절하게\" 처리하 는데, 이는 서버가 경우에 따라 상이한 동작들을 수행함을 의미할 수 있다. 예를 들어, 서버는 각각 의 클라이언트(406, 408, 410)에 대한 손실 값을 계산하고 서버는 모든 클라이언트들에 대한 평균 손실을 계산한다. 서버는 평균 손실을 사용하여 역전파를 수행하고 S에서 그라디언트들을 계산한다. 서버는 S(즉, SB(406C, 408C, 410C))에서 그라디언트들을 모든 클라이언트들(406, 408, 410)에 발송한다. 다시 말해서, 서버 측에서의 훈련은 위에서 설명된 것과 매우 유사하게 진행된다. 서버 측의 제1 레 이어가 \"완료\"되면(데이터 제공자들(406, 408, 410)로부터 수신된 것을 평균화하거나 집계함으로써) 네트워크의 \"상단\"에 도달할 때까지 순방향 전파가 발생한다. 본 개시에 설명된 추가 혁신은 데이터 제공자들(406, 408, 410)로부터 오는 활성화 들 및 이들이 평균화, 집계 또는 기타 처리되는 방법을 관리하는 것이다. 시스템이 모 델의 상단에 도달하면, 서버는 역전파에 필요한 그라디언트들을 계산하고, 도 4에 도시된 바와 같이 분할 네트워크들을 통해 하향으로 다시 발송한다. 전술한 바와 같이, 서버에 의한 활성화들의 처리 및 관리는 상이한 인자(factor)들에 따라 변할 수 있다. 예를 들어, 3개의 데이터 제공자들(406, 408, 410) 모두가 동일한 데이터(X-선들)를 제공하는 경우를 가정한다. 이 경우, 데이터는 수평으로 결합되며 개념적으로 데이터가 한 파일 위에 다른 파일 위에 \"적층\"됨을 의미할 수 있다. 이 경우, 발생하는 활성화들은 평균이 될 가능성이 크다. 그러면 \"각 활성화의 평균\"이 네트워크의 \"상반 부\"로 순방향 발송된다. 다른 경우에, 데이터는 \"수직으로\" 적층될 수 있으므로, 클라이언트 1은 데이터의 처음 40개 컬럼(colum n)들((예를 들어, 혈액 검사)을 갖고, 클라이언트 2는 데이터의 다음 60개 컬럼들(예를 들어, 나이, 체중 등과 같은 데이터를 포함하는 전자 건강 기록)을 갖고 및 클라이언트 3은 데이터의 마지막 100개 컬럼들 (예를 들어, 보험 정보-이전 청구 등)을 갖는다. 이 예에서, 세 개의 클라이언트들은 200개 컬럼들의 결합된 \" 기록\"을(페이지 전체에 걸쳐 수직으로 집계됨) 설정하는 것으로 간주될 수 있다. 이 경우, 활성화들은 \"수직으 로 결합\"되어 서버 네트워크로 순방향 발송된다. 데이터 결합에 대한 이 접근법 및 기타 접근법들이 구현될 수 있다. 아래에서 더 자세히 설명하는 다중 모델 인공 지능 모델은 수직으로 활성화들을 결합하는 것과 관련하여 방금 설명한 개념을 기반으로 한다는 것을 유의한다. 이 개념에 대한 자세한 내용은 아래에서 제공될 것이다. 위에서 언급한 바와 같이, 클라이언트들(406, 408, 410)은 이 실시예에서 병렬로 실행된다. 이렇게 하면 모든 처리가 병렬로 수행되므로 모델을 훈련하는 데 걸리는 시간이 줄어든다. 또한, 이 데이터는 특정 플랫폼을 통해 전달된다. 위에 통합된 애플리케이션들은 본 명세서에 공개된 데이터를 전달하는데 사용할 수 있는 특정 플랫폼 의 예시들을 제공한다. 이것은 아래에서 더 논의될 것이다. 연합 분할 러닝의 글로벌 모델은 다음과 같이 집계될 수 있다. 훈련이 완료되면, 시스템은 추론 작업에 사용될 글로벌 모델을 집계하기 위해 다음 접근법을 사용한다. 제1 접근법에서 서버는 모델들 중 하나인 Ai를 선택하여 해당 모델 B와 통합하여 글로벌 모델을 형성한다. Ai의 선택은 다음 방법들 중 하나를 사용하여 달성될 수 있다. 예를 들어, 서버가 임의의 클라이언트(406, 408, 410)의 모델(Ai)을 무작위로 선택하는 경우 무작위 선택 이 사용될 수 있다. 이 무작위 선택은 현재 온라인에서 사용 가능한 클라이언트들, 각 클라이언트가 처리하는 데이터 유형들(텍스트 데이터, 이미지 데이터, 시간 데이터) 또는 두 독립체들 간의 송신 속도 또는 네트워크 지연과 같은 다른 인자들의 영향을 받을 수 있다. 그런 다음 서버는 Ai와 B 부분들을 모두 적층하여 글로벌 모 델을 생성한다.다른 예에서, 가중 클라이언트 선택이 사용될 수 있다. 이 선택 기준에 대해, 서버는 각각의 클라이언트에 게 그들의 데이터, 계산 능력들, 및 그들이 훈련 프로세스 동안 소유하고 기여하는 다른 가치 있는 자산에 기초 하여 그들의 중요성을 반영하는 가중치(즉, 수치 값)를 할당한다. 예를 들어, 특정 모델 세트(예를 들어, 특정 언어에 대한 데이터, 이미지 유형과 관련된 데이터, 환자 세트와 관련된 데이터 또는 특정 국가 또는 지역의 데 이터)는 모델 개발에서 많은 가중치를 받을 수 있다. 따라서, 국가가 선택되면, 해당 국가의 클라이언트 디바이 스들이 다른 국가들의 클라이언트들보다 더 많은 가중치를 둘 수 있다. 예를 들어, 일본 기반 클라이언트 디바 이스들은 모델 데이터의 80%에 사용될 수 있다. 호주는 10%가 될 수 있고 캐나다는 나머지 10%가 될 수 있다. 또 다른 예로, 독감이나 COVID의 발병과 관련된 특정 클리닉의 데이터에 더 많은 가중치를 둘 수 있다. 또 다른 예에서, 데이터 유형도 더 많은 가중치를 둘 수 있다. 모델의 70%는 이미지 데이터가 사용되는 반면, 20%는 텍 스트 데이터, 10%는 시간 데이터가 사용될 수 있다. 또 다른 모델은 정확도 기반 선택일 수 있다. 이 경우, 서버는 각각의 클라이언트 모델 Ai로부터 생성된 정확도를 테스트한 다음 \"최고\" 정확도를 생성하는 모델을 선택할 수 있다. \"최고\"는 이해 관계자들에 의해 머 신 러닝 접근법 등을 통해 식별될 수 있다. 이들은 모두 제1 접근법의 모델들이다. 제2 접근법은 모든 클라이언트들의 모델들 Ai {1, N}을 평균화하여 글로벌 모델을 집계하는 경우일 수 있다. 각 클라이언트는 먼저 동형 암호화(homomorphic encryption)를 사용하여 자신의 모델을 암호화한 다음 암호화된 Ai' 데이터를 서버로 발송한다. 서버는 모든 암호화된 모델들을 추가하고, 추가 결과들을 해독한 다 음, 평균을 계산한다. 그런 다음 평균화된 A를 B와 함께 적층하여 글로벌 모델을 생성한다. 한 가지 접근법은 디폴트 접근법일 수 있으며 선택적 접근법들도 제공될 수 있다. 해독화 프로세스들 및 평균화 프로세스는 또한, 예를 들어, 클라이언트 측에서 발생하는 하나의 프로세스와 글로벌 모델을 달성하기 위해 서버에 의해 수 행되는 다른 프로세스로 서로 상이한 서버들 간에 확산될 수 있다. 접근법들은 모델의 개발을 통해 다양할 수 있다. 예를 들어, 모델은 디폴트 접근법을 사용하여 훈련이 시작된 다음 가중치 접근법이 사용되어 모델 훈련을 완료하도록 훈련이 조정될 수 있다. 방법의 예가 도 5에 도시되어 있고, 서버에서 신경망을 제1 부분과 제2 부분으로 분할하는 단계, 제2 부분 을 개별적으로 제1 클라이언트 및 제2 클라이언트에 발송하는 단계 및 임계치가 충족될 때까지 다음 동작 들을 수행하는 단계를 포함할 수 있다: 데이터 SA1 및 SA2를 생성하기 위해 제1 클라이언트 및 제2 클라이언트에서 제2 부분에 대한 순방향 단계를 동시에 수행하는 단계; 제1 클라이언트 및 제2 클라이언트로부터 SA1 및 SA2를 서버로 송신하는 단계; 서버에서 제1 클라이언트 및 제2 클라이언트에 대한 손실 값을 계산하는 단계; 서버에서 제1 클라이언트와 제2 클라이언트에 걸친 평균 손실을 계산하는 단계; 서버에서 평균 손실을 사용하여 역전파를 수행하고 그라디언트들을 계산하는 단계; 및 서버로부터 제1 클라이언트 및 제2 클라이언트로 그라디언트를 발송하는 단계. 위의 동작들을 수행하는 컴퓨팅 디바이스 또는 디바이스들은 또한 실행될 때 프로세서가 이러한 동작들을 수행 하게 하는 명령어들을 저장하는 컴퓨터 판독가능 저장 디바이스로 다루어질 수 있다. 동작들은 임의의 순서로 수행될 수 있으며 방법은 하나 이상의 동작들을 포함할 수 있다. 본 개시의 다른 양태에서, 위에 통합된 특허 애플리케이션들에 설명된 플랫폼들은 임의의 연합 모델들에서 데이 터를 전후로 통신하기 위한 기초를 제공할 수 있다. 예를 들어, 클라이언트들의 각각은 및/또는 서버는 플랫폼 또는 본 명세서에 통합된 애플리케이션에서 참조되는 플랫폼 버전들 중 하나에 로그온해야 될 수도 있다. 따라 서, 이러한 애플리케이션들에 개시된 바와 같이 구성된 플랫폼 또는 교환을 통해 이 기능을 전달하는 것도 본 개시의 양태로서 다루어진다. 다른 양태에서, 고객은 전파될 필요가 있는 가중치들을 나타내는 SA, SB 라인들(벡터들 및 숫자들)을 선택할 수 있다. 클라이언트가 데이터에 대해 서버가 알지 못하는 상태에서 데이터를 잠그기를 원하면, 해당 데이터를 동 형 암호화할 수 있다. 암호화 프로세스(임의의 암호화 프로세스를 포함할 수 있음)는 위에서 설명한 모든 접근 법에서 사용될 수 있다. 상기 통합된 특허 애플리케이션들은 클라이언트 디바이스들 및/또는 서버들이 본 명세서에 개시된 연합 분할 러 닝 접근법을 수행하기 위해 로그인할 수 있거나 로그인이 요구될 수 있는 예시적인 플랫폼들을 제공한다. 일 양태에서, 본 명세서에 개시된 단계들은 \"시스템\"에 의해 실행될 수 있음에 유의한다. 시스템은 서버와 하나 이상의 클라이언트들을 함께 포함하거나, 서버에서 수행하는 기능일 수 있다. 시스템은 또한 본 명세서에 개시 된 클라이언트 기반 기능들을 수행하는 특정 지리적 영역의 클라이언트들 또는 클라이언트들 그룹들과 같은 클 라이언트들 또는 클라이언트들의 그룹일 수 있다. 일 양태에서, \"서버\"는 또한 서버 측 상의 컴퓨팅 디바이스 (물리적 또는 가상) 및 클라이언트 측 상의 컴퓨팅 디바이스(물리적 또는 가상)일 수 있다. 일례에서, 서버는 클라이언트 측에 있을 수 있고 개별 클라이언트 측 모델 Ai의 역전파 출력을 수신할 수 있고 훈련 라운드에서 클라이언트 측 글로벌 모델을 동기화할 수 있다. 따라서, 서버 측 시스템 및 클라이언트 측 시스템 각각은 본 명세서에 개시된 동작들 중 임의의 하나 이상을 수 행할 수 있다. 본 명세서에 공개된 임의의 디바이스의 관점에서 발생하는 단계들을 설명하는 청구항들이 포함될 수 있다. 예를 들어, 데이터의 송신, 계산 및 수신 단계들은 어떤 실시예가 다루어지는지에 따라 서버 디바이스, 클라이언트 디바이스 또는 클라이언트 디바이스들의 그룹의 관점으로부터 청구될 수 있다. 개별 컴포 넌트 또는 디바이스의 관점에서 이러한 모든 통신은 해당 디바이스에 포커스를 둔 특정 실시예의 범위 내에 포 함될 수 있다. 다른 양태에서, 시스템은 참조로 포함된 특허 애플리케이션들에 개시된 플랫폼을 포함할 수 있으며 또한 위에 개시된 개념과 협력하여 단계들을 수행할 수 있다. 따라서, 본 명세서에 설명된 연합 분할 러닝 프로세스를 제 공하는 데 사용되는 플랫폼은 또한 본 개시의 실시예이며 본 명세서에 설명된 대로 데이터의 프라이버시를 유지 하는 방식으로 모델들을 훈련하기 위한 해당 플랫폼의 사용과 관련하여 단계들이 나열될 수 있다. 일반적으로 신경망의 훈련은 유사한 데이터 유형들에 대해 수행된다. 예를 들어, 환자 이미지나 신장을 수신하 여 암을 식별하도록 훈련된 신경망은 암이 있는 것과 그렇지 않은 신장들의 이미지들에 대해 훈련된다. 다음은 본 명세서에 개시된 연합 분할 러닝 접근법들을 사용하여, 신경망을 훈련하기 위해 다른 유형들의 훈련 데이터 를 함께 사용하는 훈련에 대한 새로운 접근법에 대해 설명된다. 다중 모델 인공 지능 접근법 위에서 언급한 바와 같이, MMAI 혁신은 연합 분할 러닝의 예에서 설명된 \"수직 집계(vertical aggregation)\" 아 이디어를 기반으로 한다. 예는 동일한 유형의 데이터-이미지들(적층용) 또는 수직으로 결합되는 표 형식의 데이 터를 제공하는 세 개의 클라이언트들(406, 408, 410) 모두와 관련된다. 발명가들이 수직 집계 개념을 고려하고 있을 때, 이것이다른 유형들의 데이터로 수행될 수 있음을 깨달았다. 예를 들어, 클라이언트 1은 이미지들을 제공할 수 있고, 클라이언트 2는 혈액 검사를 제공할 수 있으며, 클라이언트 3은 의사들에게 텍스트 메모들을 제공할 수 있다. 중요한 차이점은 이러한 모든 데이터 유형들에는 서로 다른 네트워크 아키텍처들이 필요하다는 것이다. 이 경우, 시스템의 개발자들은 하나의 네트워크를 정의한 다음 서버가 그것을 \"분할\"하도록 할 수 없다. 따라서, 솔루션의 일부는 사용자들이 각 데이터 공급자에 대해 \"분할 전\" 네트워크를 정의한 다음, 서버 에서 네트워크 및 집계 기술을 정의하도록 하는 것이다. 이 접근법은 도 6 내지 10에 예시되어 있다. 도 6은 다중 모드 인공 지능(MMAI) 플랫폼 또는 머신 러닝(ML) 플랫폼을 예시한다. MMAI 접근법은 다른 접 근법들의 계산 요구 사항들 및 통신 오버헤드를 감소시킨다. 또한, 훈련 속도가 훨씬 빠르고 프로세스는, 모델 도 개인적으로 유지된다는 사실을 포함하여, 데이터에서 훨씬 더 높은 프라이버시를 유지한다. MMAI 플랫폼은 하나의 대형 AI 모델의 여러 데이터 유형들에 AI/ML 기술들을 적용한다. 일반적으로, 정확 한 결과들을 산출하려면 데이터 유형들에 따라 다양한 AI 네트워크 아키텍처들이 필요하다. 예를 들어, 이미지 에는 일반적으로 특수 필터들(컨볼루션들)이 필요한 반면, 텍스트 또는 음성에는 다른 \"시계열과 같은\" 처리가 필요하며, 표 형식 데이터는 종종 ML 또는 피드 순방향 아키텍처들에서 가장 잘 작동한다. 이슈는 이미지들이 모든 픽셀들을 함께 살펴보고 다양한 방식들로 \"컨볼루션\"할 때 가장 잘 이해되는 반면, 음성은 특정 사운드 전 후(즉, 시계열 데이터와 유사한 방식으로)의 맥락에서 가장 잘 이해된다는 것 등이다. 이러한 처리 방식의 차이 들로 인해, 오늘날 \"최첨단\" 시스템들은 일반적으로 하나의 데이터 유형(즉, 이미지들, 텍스트, 음성, 표 형식 등)을 처리한다. 대부분의 AI 연구자들은 \"차세대\" 정확도의 브레이크스루(breakthrough)들이 자신들의 모델들에 더 많은 고유 데이터를 추가함으로써 달성될 수 있음을 인식한다. 이는 본질적으로 모델에 더 많은 데이터를 제공하여 사례들 에서 흥미로운 차이점들을 발견할 수 있는 더 많은 맥락을 제공하는 것과 같다. 이러한 개념의 예는 심전도 (ECG) 데이터를 검사하여 심방세동(A-fib)을 진단하는 모델이다. 이 모델은 심전도 데이터만으로도 일정 수준의정확도에 도달할 수 있지만 연구자들이 심전도 데이터에 나이, 성별, 키 및 체중을 추가하면 모델이 훨씬 더 정 확해진다. 정확도의 증가는 \"동등한\" 심전도들과 같이 모델이 어떻게 보일지 모델이 더 잘 이해하는 데 도움이 될 수 있는 네 가지 추가 데이터 유형들 때문이다. 네 가지 항목들 또는 데이터의 특성들을 추가하면 데이터를 더 세분화할 수 있다. 도 6에 도시된 MMAI 플랫폼은 개인 데이터의 훈련 및 보호를 개선하기 위해 신세대 암호화 도구세트를 소 개한다. MMAI 플랫폼은 AI/ML 모델들을 훈련하고 데이터를 확장하는데 일반적으로 사용되는 것보다 더 많 은 데이터를 모델에 제공한다. 이 접근법은 다양한 데이터 유형들(예를 들어, 이미지들 및 표 형식 데이터)을 결합하여 상당한 양의 데이터를 추가한다. 도 6은 웰스 파고(Wells Fargo) 은행으로 도시된 데이터의 제1 외부 소스를 예시한다. 웰스 파고 데이터 (602a)는 암호화되고(602b), 암호화된 데이터(602c) 패키지는 개인 AI 기반시설로 송신된다. 데이터의 제2 외부 소스는 시티은행(Citibank)으로 도시된다. 시티은행 데이터(604a)는 암호화(604b)되고 암호화된 데이 터(604c) 패키지는 개인 AI 기반시설로 송신된다. 데이터의 제3 외부 소스는 뱅크 오브 아메리카 (Bank of America)로 도시된다. 뱅크 오브 아메리카 데이터(606a)는 암호화되고(606b) 암호화된 데이터(606c) 패키지는 개인 AI 기반시설로 송신된다. AI 기반시설은 이질적인 소스들(602, 604, 606)으로부터의 모든 데이터를 개인적으로 탐색, 선택 및 전처리하는 제1 모듈을 포함한다. 이 예에서, 모든 소스들 은 은행들로 식별되지만 서로 다른 구조들을 가지며, 개별 데이터도 이질적일 수 있다. 물론, 데이터의 모든 외 부 소스들(602, 604, 606)이 동일한 유형, 즉 은행들일 필요는 없다. 은행들의 사용은 단지 예일뿐이다. 외부 소스들(602, 604, 606)은, 예를 들어 병원, 클리닉, 대학 등이 될 수 있다. 기본 개념은 데이터 유형들이 다양 한 외부 소스들(602, 604, 606)과 다를 수 있다는 것이다. 개인 AI 기반시설은 훈련을 위해 수신하는 모든 데이터(602c, 604c, 606c)로부터 관련 피쳐들을 개인적으 로 탐색, 선택 및 전처리하는 컴포넌트를 포함할 수 있다. 피쳐는 개인 AI 기반시설에서 컴포넌트의 처리로부터 발생할 수 있는 데이터의 서브세트를 나타낸다. 동작들(614, 616)에서, AI 기반시설은 선 택된 데이터에 대한 새로운 딥 및 통계 모델들을 개인적으로 훈련하고 동작에서 이미지들, 비디오, 텍스트 및/또는 기타 데이터 유형들을 포함할 수 있는 임의의 개인적이고 민감한 데이터에 대해 예측할 것이다. AI 기반시설은 그 다음 동작에서 제시되는 새로운 모델들에 대한 액세스를 판매하거나 허가할 수 있 다. 도 7은 분할 러닝 기술에 대한 또 다른 변형을 예시한다. 이 접근법은 데이터의 이질적인 유형들에 기초한 훈련을 위한 블라인드 상관 프로세스를 사용함으로써 모델들의 훈련을 개선하기 위해 낮은 컴퓨팅 요구사항들 및 낮은 통신 오버헤드를 제공한다. 위의 A-fib 모델 예를 기반으로, 모델에 대한 더 많은 데이터의 또 다른 소 스는 모델이 고려하는 각 사례에 대한 흉부 X-선을 포함하는 것이다. 불행히도, X-선 영상의 일반적인 처리는 표 형식의 심전도 데이터의 일반적인 처리와 일치하지 않다. 약간의 마이너한 엔지니어링을 추가하면, 위에서 설명한 분할 연합 러닝 도구를 사용하여 이 비호환성 문제를 해결할 수 있다. 즉, 다른 데이터 유형들이 기존 파이프라인에서 처리할 수 있도록 도구에 새 명령어들이 제공될 수 있다. 이 경우에 네트워크 아키텍처의 \"자동\" 분할보다는 아이디어에 대한 이러한 변형을 통해 네트워크 설계자(즉, 알고리즘을 개발하는 데이터 과학자)가 각 데이터 유형에 대해 원하는 특정 네트워크 컴포넌트를 지정할 수 있 다. 각 데이터 유형에는 해당 데이터 유형과 관련된 네트워크 아키텍처 레이어들이 필요하다(즉 이미지들에 대 한 컨볼루션 레이어들, 음성에 대한 순환 레이어들/장기 단기 메모리 레이어, 표 형식 데이터에 대한 피드 순방 향 레이어들 등). 문제의 데이터 유형에 고유한 이러한 이질적인 레이어들은 \"데이터 서버\" 측에서 실행되도록 지정된다(거의 그 자체로 독립 네트워크들과 유사). 각 \"독립 네트워크\"(데이터 유형별)의 마지막 레이어는 활 성화들을 \"분할을 통해\" \"서버 측\"으로 발송한다. 알고리즘 서버 측은 들어오는 활성화들(데이터 서버 측으로부 터)을 적절하게 처리하는 하나의 일관된 \"네트워크\"를 가진다. 어떤 면들에서 이 접근법은 (데이터 서버 측에서) \"네트워크들의 앙상블\"이 알고리즘 서버 측에서 하나의 최종 네트워크로 집계되는 것과 유사하다(궁극 적으로 네트워크들의 \"앙상블\"로부터 최종 \"답변\"을 생성함). 분할 러닝은 협력 딥 러닝 기술로, 딥 러닝 네트워크 또는 신경망(NN)은 위에서 논의된 바와 같이 클라이언트 측 네트워크 A와 서버 측 네트워크 B의 두 부분으로 분할될 수 있다. NN에는 가중치, 편향, 하이퍼파라미터들을 포함한다. 도 7에서, 데이터가 상주하는 클라이언트들(702, 704, 706)은 네트워크의 클라이언트측 부분에만 커 미팅(committing)하고 서버는 네트워크의 서버측 부분에만 커밋한다. 클라이언트 측과 서버 측 부분은 집 합적으로 전체 네트워크 NN을 형성한다.네트워크의 훈련은 일련의 분산된 훈련 프로세스들에 의해 수행된다. 순방향 전파와 역전파는 다음과 같이 일어 날 수 있다. 원시 데이터를 사용하여 클라이언트(클라이언트로 가정)는 절단 레이어 또는 분할 레이어라고 부를 수 있는 네트워크의 특정 레이어까지 클라이언트 측 네트워크(702A)를 훈련하고, 절단 레이어의 활성화들 을 서버로 발송한다. 서버는 클라이언트로부터 수신한 활성화들로 NN의 나머지 레이어들을 훈련 시킨다. 이것은 단일 순방향 전파 단계를 완료한다. 유사한 프로세스가 제2 클라이언트 및 그의 클라이언 트 측 네트워크(704A) 및 서버로 송신되는 그의 데이터 및 생성된 활성화들에 대해 병렬로 발생한다. 추가 유사한 프로세스가 제3 클라이언트 및 그의 클라이언트 측 네트워크(706A) 및 서버로 송신되는 그의 데이터 및 생성된 활성화들에 병렬로 발생한다. 다음으로, 서버는 절단 레이어까지 역전파를 수행하고 활성화들의 그라디언트들을 개별 클라이언트들(702, 704, 706)로 발송한다. 그라디언트들을 사용하여 각각의 개별 클라이언트(702, 704, 706)는 나머지 네트워크 (702A, 704A, 706A)에서 역전파를 수행한다. 이것은 클라이언트(702, 704, 706)와 서버 사이의 역전파의 단일 패스를 완료한다. 순방향 전파 및 역전파의 이 프로세스는 네트워크가 모든 이용 가능한 클라이언트들(702, 704, 706)로 훈련되고 그 수렴에 도달할 때까지 계속된다. 분할 러닝에서 아키텍처 구성들은 메인 서버에 직접 액세스하는 신뢰 할 수 있는 당사자에 의해 수행되는 것으로 가정한다. 이 승인된 당사자는 러닝의 시작에서 ML 모델(애플리케이 션 기반) 및 네트워크 분할(절단 레이어 찾기)을 선택한다. 전술한 바와 같이, 본 개시에 도입된 개념은 각각 상이한 유형의 데이터를 제공하지만 또한 상이한 유형들의 데 이터가 공통 연관을 갖는 클라이언트들(702, 704, 706)에 관한 것이다. 따라서, 머신 러닝 모델의 선택은 클라 이언트 측에서 처리되는 데이터의 유형들을 기반으로 할 수 있으며, 절단 레이어를 찾는 프로세스는 데이터의 유형들 또는 서로 상이한 데이터의 유형들의 이질성에 따라 달라질 수 있다. 예를 들어, 클라이언트들(702, 704, 706)에 걸쳐 광범위하게 이질적인 데이터 유형들에 대해, 절단 레이어는 클라이언트 측 네트워크들(702A, 704A, 706A)에 더 많거나 더 적은 레이어들을 갖도록 선택될 수 있다. 다른 양태에서, 절단 레이어 또는 분할 레이어 이전의 레이어들의 수는 클라이언트들에 따라 다를 수 있다. 클라이언트는 이미지들을 처리할 수 있고 절단 레이어 전에 8개의 레이어들을 필요로 하는 반면, 클라이언트는 텍스트를 처리할 수 있고 절단 레이어 전에 4개의 레이어만 필요로 할 수 있다. 이와 관련하여, 절단 레이어의 벡터들, 활성화들 또는 활성화 레이어가 서로 다른 유형들의 데이터를 갖는 서로 다른 클라이언트들(702, 704, 706)에 걸쳐 일관되는 한, 클라 이언트측 네트워크들(702A, 704A, 706A)의 레이어들 수가 동일할 필요는 없다. 다중 클라이언트들(702, 704, 706)과의 러닝 프로세스의 동기화는 중앙 집중식 모드 또는 피어-투-피어 모드에 서 수행될 수 있다. 중앙 집중식 모드에서, 클라이언트(702, 704, 706)는 서버로 훈련을 시작하기 전에, 마지막으로 훈련된 클라이언트가 업로드한 업데이트된 클라이언트 측 모델을 유지하는 신뢰할 수 있는 제3자 서 버로부터 모델 파라미터들을 다운로드하여 클라이언트 측 모델(702A, 704A, 706A)을 업데이트한다. 반면에, 피어-투-피어 모드에서, 클라이언트(702, 704, 706)는 마지막으로 훈련된 클라이언트에서 직접 다운로 드하여 클라이언트 측 모델을 업데이트한다. 위에서 언급했듯이, 이전에 훈련된 모델들은 해당 모델을 업데이트 해야 하는 현재 클라이언트와 데이터 유형 유사성을 가질 수 있다. 예를 들어, 유사성은 이미지들, 텍스트 데이 터, 음성 데이터, 비디오 데이터, 시간 데이터 등인 데이터에 기초할 수 있다. 따라서, 피어에서 다운로드하는 데 사용할 이전에 훈련된 클라이언트 모델을 지능적으로 선택할 수 있다. 서버에 의한 처리는 또한 일부 경우들에 서버 측의 일부 처리와 클라이언트 측의 연합 서버에서의 다른 처리 사이에서 분할될 수 있다. 위에서 소개된 바와 같이, 클라이언트 1, 클라이언트 2 및 클라이언트 3은 상이한 데이터 유형 들을 가질 수 있다. 서버는 네트워크의 두 부분들을 생성하고 한 부분(702A, 704A, 706A)을 모든 클라이언 트들(702, 704, 706)에 발송한다. 시스템은 정확성 조건 또는 예를 들어 모든 클라이언트들이 데이터를 그들이 가지고 있는 네트워크의 일부로 발송하고 출력을 서버로 발송하는 다른 조건이 충족될 때까지 특정 단계를 반복한다. 서버는 각 클라이언트에 대한 손실 값과 모든 클라이언트들에 걸친 평균 손실을 계산한다. 서버 는 역전파 동안 계산하는 그라디언트들의 가중 평균을 사용하여 자신의 모델을 업데이트할 수 있고 그라디 언트들을 다시 모든 클라이언트들(702, 704, 706)로 발송한다. 클라이언트들(702, 704, 706)은 서버로부터 그라디언트들을 수신하고 각 클라이언트(702, 704, 706)는 클라이언트 측 네트워크(702A, 704A, 706A)에서 역전 파를 수행하고 각 클라이언트 측 네트워크(702A, 704A, 706A)에 대한 개별 그라디언트들을 계산한다. 클라이언 트측 네트워크들(702A, 704A, 706A)로부터의 개별 그라디언트들은 클라이언트측 업데이트들의 평균화를 전도하 고 글로벌 결과들을 모든 클라이언트들(702, 704, 706)에 다시 발송하는 서버로 다시 송신될 수 있다.서버 기능은 또한 각각이 상이한 동작들(각각 상이한 영역들에 위치하는, 하나의 서버에 의한 모델 업데이 트 및 다른 서버에 의한 로컬 클라이언트 업데이트들의 평균화와 같은)을 수행하는 여러 서버들로 분할될 수 있 다는 점에 유의한다. 도 7의 경우, 클라이언트들(702, 704, 706)은 모두 AI 모델을 개발하기 위해 일반적으로 처리되거나 처리될 수 없는 이질적인 유형들의 데이터를 처리한다. 예의 목적들로, 위의 A-fib 모델이 프로세스를 예시하는데 사용될 수 있다. 클라이언트 1은 심전도 데이터 를 가질 수 있고, 클라이언트 2는 X-선 데이터를 가질 수 있고, 클라이언트 3은 유전 데이터를 가질 수 있다. 예를 들어, 클라이언트 1은 병원일 수 있고, 클라이언트 2는 의료 진단들 영상 회사일 수 있으며 클라이언트 3은 도 6에 묘사된 방식으로 은행 또는 금융 기관일 수 있다. 클라이언트들 중 하나는 검진들을 위해 매주 병원을 방문하는 것과 관련하여 환자에 대한 점진적 정보와 같은 시간 기반 데이터를 가질 수도 있다. 도 7에 도시된 접근법은 사용자가 분할 또는 절단 레이어 이전에 또는 블라인드 역상관(decorrelation) 블록 에 도시된 바와 같이 \"정확한\" 처리와 함께 상이한 데이터 유형들을 가져오도록 하는 새로운 사용자 명령 어들을 시스템이 구현할 수 있는 방법을 예시한다. 모델의 각 부분들은 독립적일 수 있으며, 독립적으로 동작한 다. 일 양태에서, 블라인드 상관 블록에 의해 수행된 처리는 서버로 전송되는 활성화 레이어 또는 활 성화들을 초래할 것이다. 이 접근법은 클라이언트들(702, 704, 706) 사이의 데이터 유형의 차이들을 추가하여 위에서 설명된 접근법과 유사하다. 서버는 다수의 방법들 중 하나로 이러한 활성화 레이어들을 결합할 것이다. 서버는 그것들을 평균화 할 수 있지만(또한 위에서 설명됨), 그것들을 하나의 긴 활성화 레이어로 이을 수도 있다(concatenation) . 다 른 양태에서, 서버는 활성화 레이어들의 원하는 조합을 달성하기 위해 임의의 수학적 함수를 적용할 수 있 다. 그런 다음 서버는 임의의 적절한 네트워크 아키텍처를 사용하여 결합된 활성화 레이어들을 추가로 처 리할 수 있다. 일 양태에서, 클라이언트 측의 서버는 그라디언트들을 수신하고 다양한 클라이언트들(702, 704, 706)의 글로벌 모델을 생성하기 위해 그라디언트들을 평균화하고 이음 또는 추가 처리를 위해 글로벌 모델을 서 버에 발송할 수 있다. 도 6 및 7에 도시된 아이디어는 분할 연합 러닝 도구 세트의 확장 및 애플리케이션을 나타내고 이질적인 데이터 유형을 슈퍼세트 AI 모델로 함께 가져오기 위한 기성 도구들의 플랫폼을 제공한다. 처리는 모두 개인적으로 수 행될 수 있으며 위에서 참조한 통합 특허 애플리케이션들에 설명된 대로 제안이 시장에 포함될 수도 있다. 시스템은 상이한 데이터 유형들을 결합할 수 있을 뿐만 아니라, 시스템은 또한 상이한 AI/ML 기술들을 결합할 수 있다. 예를 들어, 클라이언트 1은 CNN(컨볼루션 신경망)일 수 있고, 클라이언트 2는 ML 루틴(즉, XGBoost)일 수 있으며, 클라이언트 3도 다른 기술을 적용할 수 있다. 이와 관련하여 서로 상이한 AI/ML 기 술들은 상이하지만 절단 레이어의 결과 데이터가 일관되고 적절하게 구성되어 있으면, 순방향 전파와 역전파가 발생할 수 있고 모델들은 훈련될 수 있다. 당업자가 MMAI 접근법이 어떻게 작동하는지 이해하는 것을 돕기 위해 다음은 3개의 데이터 제공자들(702, 704, 706)로부터 오는 데이터 유형별 실제 커맨드들의 예이다. 이 코드는 파이썬 넘버링 규칙을 사용하므로 builder0(데이터 공급자 1의 표 형식 데이터)으로 시작한다. 이 예에서 builder1은 CT 스캔 또는 이미지 데이터용이다. 커맨드들은 X-선, MRI 및/또는 기타 사진에 대해 유사하다. Builder2(데이터 제공자로부 터)는 텍스트 데이터이다. \"장기/단기 메모리\"의 줄임말인 \"lstm\" 커맨드에 유의한다. \"서버\" 빌더 커맨드들은 분할 반대 측의 \"상단\"에서 나머지 세 개를 집계하는 네트워크를 정의한다. builder0 = tb.NetworkBuilder() builder0.add_dense_layer(100, 120) builder0.add_relu() builder0.add_dense_layer(120, 160) builder0.add_relu() builder0.add_dropout(0.25) builder0.add_dense_layer(160, 200) builder0.add_relu() builder0.add_split() builder1 = tb.NetworkBuilder() builder1.add_conv2d_layer(1, 32, 3, 1) builder1.add_batchnorm2d builder1.add_relu() builder1.add_max_pool2d_layer(2, 2) builder1.add_conv2d_layer(32, 64, 3, 1) builder1.add_batchnorm2d builder1.add_relu() builder1.add_max_pool2d_layer(2, 2) builder1.add_flatten_layer() builder1.add_split() builder2 = tb.NetworkBuilder() builder2.add_lstm_layer(39, 100, batch_first=True) builder2.add_dense_layer(100, 39) builder2.add_split() server_builder = tb.NetworkBuilder() server_builder.add_dense_layer(60000, 8000), server_builder.add_relu() server_builder.add_dense_layer(8000, 1000), server_builder.add_relu() server_builder.add_dense_layer(1000, 128), server_builder.add_relu() server_builder.add_dense_layer(128, 1) 도 8은 클라이언트들의 관점에서 MMAI 개념을 제공하기 위한 예시적인 방법을 예시한다. 방법은 제1 데이 터 소스로부터 데이터의 제1 세트를 수신하는 단계, 제1 데이터 유형을 갖는 제1 데이터 세트, 제1 데이터 세트에 대해 제1 클라이언트측 네트워크를 훈련하고 제1 활성화들을 생성하는 단계, 제2 데이터 소스로부 터 제2 데이터 세트를 수신하는 단계, 제2 데이터 유형을 갖는 제2 데이터 세트 및 제2 데이터 세트에 대 해 제2 클라이언트측 네트워크를 훈련하고 제2 활성화들을 생성하는 단계를 포함한다. 방법은 제1 활성화들 및 제2 활성화들을 서버 측 네트워크로 송신하는 단계-여기서, 서버 측 네트워크는 그라디 언트들을 생성하기 위해 제1 활성화들 및 제2 활성화들에 기초하여 훈련됨-, 및 제1 클라이언트 측 네트워크 및 제2 클라이언트 측 네트워크에서의 그라디언트를 수신하는 단계를 더 포함할 수 있다. 제1 데 이터 유형 및 제2 데이터 유형은 하나는 이미지 기반이고 다른 하나는 음성에서와 같이 텍스트 또는 시간 기반 인 것과 같이 서로 상이한 데이터 유형들일 수 있다. 도 9는 서버와 하나 이상의 클라이언트들(702, 704, 706)의 관점에서 예시적인 방법을 예시한다. 방 법은 신경망을 제1 클라이언트 측 네트워크, 제2 클라이언트 측 네트워크 및 서버 측 네트워크로 분할하는 단계, 제1 클라이언트측 네트워크를 제1 클라이언트로 발송하는 단계-여기서 제1 클라이언트 측 네트워크는 제1 클라이언트로부터의 제1 데이터를 처리하도록 구성되고, 제1 데이터는 제1 유형을 갖고 제1 클라이언트 측 네트워크는 적어도 하나의 제1 클라이언트 측 레이어를 포함함-, 및 제2 클라이언트 측 네트워크를 제2 클라이 언트로 발송하는 단계를 포함하고, 제2 클라이언트 측 네트워크는 제2 클라이언트로부터의 제2 데이터를 처리하 도록 구성되고, 제2 데이터는 제2 유형을 갖고, 제2 클라이언트 측 네트워크는 적어도 하나의 제2 클라이언트 측 레이어를 포함할 수 있고, 여기서 제1 유형 및 제2 유형은 공통 연관을 갖는다. 방법은 제1 클라이언트로부터의 제1 데이터에 대해 제1 클라이언트 측 네트워크를 훈련시키고 제1 활성화들을 생성하는 단계, 제1 클라이언트 측 네트워크로부터 서버 측 네트워크로 제1 활성화들을 송신하는 단계 , 제2 클라이언트로부터의 제2 데이터에 대해 제2 클라이언트 측 네트워크를 훈련시키고, 제2 활성화들을 생성하는 단계, 제2 클라이언트 측 네트워크로부터 서버 측 네트워크로 제2 활성화들을 송신하고, 그 라디언트들을 생성하기 위해 제1 활성화들 및 제2 활성화들에 기초하여 서버 측 네트워크의 적어도 하나의 서버 측 레이어를 훈련시키는 단계 및 서버 측 네트워크로부터 제1 클라이언트 측 네트워크 및 제2 클라이언트 측 네트워크로 그라디언트들을 송신하는 단계를 더 포함할 수 있다. 데이터의 이질적인 유형들 사이의 공통 연관은 디바이스, 사람, 소비자, 환자, 비즈니스, 개념, 의학적 상태, 사람들의 그룹, 프로세스, 제품 중 및/또는 서비스 중 적어도 하나를 포함할 수 있다. 임의의 개념, 디바이스 또는 사람은 상이한 클라이언트들로부터 제공되고 절단 또는 분할 레이어까지 상이한 독립적인 클라이언트 측 네트워크들에 의해 처리되는 데이터의 다양한 이질적인 유형들에 대한 공통 연관 또는 주제가 될 수 있다. 서버 측 네트워크는 글로벌 머신 러닝 모델을 포함할 수 있다. 신경망은 가중치들, 바이어스 및 하이퍼파라미터들을 포함할 수 있다. 하이퍼파라미터들은 일반적으로 토폴로지 파라미터 또는 신경망의 크기와 같이 러닝 프로세스 를 제어하는 데 값이 사용되는 파라미터와 관련된다. 예를 들어, 러닝 레이트, 미니 배치 크기, 클라이언트 측 레이어들의 수 또는 상이한 데이터 유형들에 영향을 미치거나 관련될 수 있는 프로세스 제어와 관련된 임의의 파라미터가 하이퍼파라미터를 나타낼 수 있다. 적어도 하나의 제1 클라이언트 측 레이어 및 적어도 하나의 제2 클라이언트 측 레이어 각각은 동일한 수의 레이 어들 또는 상이한 수의 레이어들을 포함할 수 있다. 독립적으로 동작하기 때문에, 클라이언트 측 네트워크들은 데이터를 처리하여 추가 훈련을 위해 서버 측 네트워크에 전달할 적절한 형식의 활성화들 또는 벡터들을 생성하 는 한 상이한 수의 레이어들을 가질 수 있다. 절단 레이어는 서버 측 네트워크와 제1 클라이언트 측 네트워크 및 제2 클라이언트 측 네트워크 사이에 존재할 수 있다. 도 10은 서버의 관점에서 예시적인 방법을 예시한다. 방법은 신경망을 제1 클라이언트 측 네트워크, 제2 클라이언트 측 네트워크 및 서버 측 네트워크로 분할하는 단계, 제1 클라이언트 측 네트워크를 제1 클라이언트에 발송하는 단계-여기서 제1 클라이언트 측 네트워크는 제1 클라이언트로부터의 제1 데이터를 처리 하도록 구성되고, 제1 데이터는 제1 유형을 갖고 여기서 제1 클라이언트 측 네트워크는 적어도 하나의 제1 클라 이언트 측 레이어를 포함함-, 제2 클라이언트 측 네트워크를 제2 클라이언트에 발송하는 단계를 포함하고, 여기서 제2 클라이언트 측 네트워크는 제2 클라이언트로부터의 제2 데이터를 처리하도록 구성되고, 제2 데이터는 제2 유형을 갖고 여기서 제2 클라이언트 측 네트워크는 적어도 하나의 제2 클라이언트 측 레이어 를 포함할 수 있으며, 여기서 제1 유형 및 제2 유형은 공통 연관을 갖는다. 방법은, 서버 측 네트워크에서, 제1 클라이언트로부터의 제1 데이터에 대한 제1 클라이언트 측 네트워크의 훈련 으로부터 제1 활성화들을 수신하는 단계, 서버측 네트워크에서, 제2 클라이언트로부터의 제2 데이터에 대 한 제2 클라이언트 측 네트워크의 훈련으로부터 제2 활성화들을 수신하는 단계, 그라디언트들을 생성하기 위해 제1 활성화들 및 제2 활성화들에 기초하여 서버 측 네트워크의 적어도 하나의 서버 측 레이어를 훈련시키 는 단계, 및 서버 측 네트워크로부터 제1 클라이언트 측 네트워크 및 제2 클라이언트 측 네트워크로 그라 디언트들을 송신하는 단계를 더 포함할 수 있다. 각각의 경우에, 훈련의 관점에서 서버의 프로세스의 일부는 서버에 의해 수행될 수 있고 다양한 클라 이언트들에 대한 값들의 평균화와 같은 다른 부분들은 클라이언트 사이트, 별도의 위치 또는 여러 클라이언트들 에 걸쳐 있을 수 있는 상이한 서버(미도시됨)에 의해 수행될 수 있음을 유의한다. 이 접근법은 시스템이 블라인드 상관 관계에서 신경망을 분할할 때 시스템은 결과로 훈련된 모델을 취하는 것을 더 어렵게 만들고, 이를 깨고 훈련 추론 공격을 적용할 수 있게 하는 새로운 방식으로 연합 분할 러닝 도 구 세트의 사용을 가능하게 한다. 시스템은 신경망을 반으로(또는 두 부분들로) 나눌 수 있고, 위에서 설명한 방식으로, 신경망 부분들(702A, 704A, 706A)에서 교환되는 모든 것은 활성화 레이어 숫자들이라고도 묘사된 스 트링 또는 숫자들의 어레이이다. 이것들은 단지 숫자들 또는 문자들의 어레이이기 때문에, 제1 신경망 부분 (702A)에서 일어나는 일은 제2 신경망 부분(704A)에서 일어나는 것과 상이할 수 있다. 예를 들어, 제1 신경망부분(702A)은 2 레이어 깊이일 수 있고 제2 신경망 부분(704A)은 90 레이어 깊이일 수 있다. 각 출력이 신경망 의 상단 부분으로 송신하기에 적절하게 구성된 일련의 숫자들로 해석되는 한, 순방향 전파 및 역전파가 작 동할 수 있고 훈련이 달성될 수 있다. 이러한 이해는 신경망의 상이한 부분들(702A, 704A, 706A)에 걸쳐 처리되 는 상이한 유형의 데이터가 모델들()을 훈련시키기 위해 적절하게 수신되고 처리될 수 있다는 본 명세서에 개시 된 새로운 개념을 위한 길을 열어준다. 시스템이 상이한 클라이언트들 각각에 대해 상이한 하반부(702A, 704A, 706A)를 생성할 수 있는 경우, 클라이언트들(702, 704, 706)은 동일한 유형의 데이터(예를 들어 텍스트와 이미 지들 사이)를 생성하거나 처리할 필요가 없으나, 적절하게 포맷된 신경망 부분들(702A, 704A, 706A)은 이질적인 데이터를 처리하고, 서버로 발송될 수 있는 구조화된 출력을 생성할 수 있다. 일례에서, 클라이언트 1은 사람의 심전도를 제공할 수 있고, 클라이언트 2는 심장의 흉부 X-선을 제 공할 수 있고, 클라이언트 3은 환자의 혈액에서 가장 흥미로운 4개의 단백질들의 유전적 프로파일을 제공 할 수 있다. 신경망 부분들(702A, 704A, 706A)이 출력을 위한 올바른 벡터 구조까지 상이한 개별 데이터 유형들 을 처리할 수 있고, 이질적인 유형들의 데이터를 서버에 제공할 수 있다면, 서버는 상이하고 이질적 인 유형들의 데이터를 활용할 수 있는 진단을 내리는데 사용될 모델을 훈련하기 위해 모든 정보를 결합하는 적 절한 신경망으로 구성될 수 있다. 일 양태에서, 신경망 부분들(702A, 704A, 706A)이 각각 상이한 유형의 데이터를 처리하는 동안, 데이터와 연관 된 일부 상관 인자가 있다. 위의 예에서 모든 데이터는 일반적으로 동일한 사람과 관련될 수 있지만, 일부 데이 터는 심전도와 관련되고 다른 데이터는 유전적 프로파일과 관련되어 있지만, 모두 동일한 사람에 대한 것이다. 따라서, 본 개시의 한 양태는 데이터가 공통 연관을 갖는다는 것이다. 다른 양태에서, 데이터는 동일한 사람과 관련되지 않을 수 있지만 공통 연관은 연령, 성별, 인종, 프로젝트, 개념, 날씨, 주식 시장 또는 기타 요인과 관련될 수 있다. 예를 들어, 모든 데이터는 30 내지 35세 사이의 여성과 관련될 수 있다. 따라서 공통 연관은 그것을 어떻게 적용하느냐에 약간의 유연성을 가진다. 다른 예에서, 데이터는 제트 엔진 스트림의 카메라로부터의 이미지들일 수 있고, 데이터의 다른 스트림은 센서 데이터일 수 있고, 다른 데이터는 비행기로부터의 비행 특성일 수 있고, 공통 연관은 비행기일 수 있다. 또 다 른 양태에서 공통 연관은 한 소비자의 한 유형의 데이터는 구매 습관들, 다른 유형의 데이터는 웹서핑 패턴들, 다른 유형의 데이터는 사용자가 발송하는 이메일들, 또 다른 유형의 데이터는 시리로부터의 오디오 또는 다른 음성 처리 도구들, 및 또 다른 유형의 데이터는 소비자가 자주 방문하는 물리적 상점 또는 사용자의 현재 위치 와 같은 다른 유형의 데이터일 수 있다. 서버의 출력은 이질적인 유형들의 입력에 대한 분석을 기반으로 사용자 에게 제공할 광고일 수 있다. 따라서 공통 연관은 이질적인 유형들의 데이터가 개념과 연관될 수 있는 임의의 개념과 연관될 수 있다. 도 11은 본 명세서에 개시된 임의의 시스템들과 관련하여 사용될 수 있는 예시적인 컴퓨터 디바이스를 예시한다. 이 예에서, 도 11은 버스와 같은 연결을 사용하여 서로 전기적으로 통신하는 컴포넌트들을 포 함하는 컴퓨팅 시스템을 예시한다. 시스템은 처리 유닛(CPU 또는 프로세서) 및 시스템 메모 리를 포함하는 다양한 시스템 컴포넌트들, 예를 들어 판독 전용 메모리(ROM) 및 랜덤 액세스 메모 리(RAM)를 프로세서에 결합하는 시스템 연결을 포함한다. 시스템은 프로세서와 직접 연결되거나, 근접하거나 그 일부로서 통합된 고속 메모리 캐시를 포함할 수 있다. 시스템은 프로세 서에 의한 빠른 액세스를 위해 메모리 및/또는 저장 디바이스로부터 캐시로 데이터를 복사할 수 있다. 이러한 방식으로, 캐시는 데이터를 기다리는 동안 프로세서 지연을 피하는 성능 향상을 제공할 수 있다. 이들 및 다른 모듈들은 다양한 액션들을 수행하도록 프로세서를 제어하거나 제어하도록 구성될 수 있다. 다른 시스템 메모리도 사용 가능할 수 있다. 메모리는 상이한 성능 특성들을 갖는 다수의 상이한 유형들의 메모리를 포함할 수 있다. 프로세서는 스토리지 디바이스에 저장된 서비스 (모듈) 1, 서비스(모듈) 2 및 서비스(모듈) 3과 같은 임의의 범용 프로세서 및 하드웨어 또 는 소프트웨어 서비스 또는 모듈을 포함할 수 있으며, 소프트웨어 명령어들이 실제 프로세서 디자인에 통합되는 특수 목적 프로세서와 프로세서를 제어하도록 구성된다. 프로세서는 다중 코어들 또는 프로세서들, 버스, 메모리 제어기, 캐시 등을 포함하는 완전히 자체 완비된 컴퓨팅 시스템일 수 있다. 다중 코어 프로세서는 대칭 또는 비대칭일 수 있다. 디바이스와의 사용자 상호작용을 가능하게 하기 위해, 입력 디바이스는 음성용 마이크, 제스처 또 는 그래픽 입력용 터치 감지 스크린, 키보드, 마우스, 모션 입력, 음성과 같은 임의의 수의 입력 메커니즘들을 나타낼 수 있다. 출력 디바이스는 또한 당업자들에게 공지된 다수의 출력 메커니즘들 중 하나 이상일 수 있다. 일부 예들에서, 다중 모드 시스템들은 사용자가 디바이스와 통신하기 위해 여러 유형들의 입력을제공할 수 있게 할 수 있다. 통신들 인터페이스는 일반적으로 사용자 입력 및 시스템 출력을 통제하고 관 리할 수 있다. 특정 하드웨어 배열에서 동작하는 데 제한이 없으므로 여기의 기본 피쳐들은 개발될 때 개선된 하드웨어 또는 펌웨어 배열들로 쉽게 대체될 수 있다. 저장 디바이스는 비휘발성 메모리이고 자기 카세트들, 플래시 메모리 카드들, 고체 상태 메모리 디바이스 들, 디지털 다목적 디스크들, 카트리지들, 랜덤 액세스 메모리들(RAM들), 판독 전용 메모리(ROM), 및 이들의 하이브리드들 같이 컴퓨터에 의해 액세스 가능한 데이터를 저장할 수 있는 하드 디스크 또는 다른 유 형들의 컴퓨터 판독가능 매체일 수 있다. 저장 디바이스는 프로세서를 제어하기 위한 서비스들 또는 모듈들(1132, 1134, 1136)을 포함할 수 있다. 다른 하드웨어 또는 소프트웨어 모듈들이 고려된다. 저장 디바이스는 시스템 연결에 연결될 수 있다. 일 양태에서, 특정 기능을 수행하는 하드웨어 모듈은 기능을 수행하기 위해 프로세서, 연결 , 출력 디바이스 등과 같은 필요한 하드웨어 컴포넌트들과 관련하여 컴퓨터 판독가능 매체에 저장 된 소프트웨어 컴포넌트를 포함할 수 있다. 일부 경우에, 이러한 컴퓨팅 디바이스 또는 장치는 프로세서, 마이크로프로세서, 마이크로컴퓨터, 또는 위에 개 시된 방법의 단계를 수행하도록 구성된 디바이스의 다른 컴포넌트를 포함할 수 있다. 일부 예들에서, 그러한 컴 퓨팅 디바이스 또는 장치는 RF 신호들을 송신 및 수신하기 위한 하나 이상의 안테나들을 포함할 수도 있다. 일 부 예들에서, 그러한 컴퓨팅 디바이스 또는 장치는 이전에 설명된 바와 같이 RF 신호들을 송신, 수신, 변조 및 복조하기 위한 안테나 및 모뎀을 포함할 수도 있다. 컴퓨팅 디바이스의 컴포넌트들은 회로부로 구현될 수 있다. 예를 들어, 컴포넌트들은 하나 이상의 프로그래밍 가능한 전자 회로들(예를 들어, 마이크로프로세서, 그래픽 처리 장치(GPU), 디지털 신호 프로세서(DSP), 중앙 처리 장치(CPU) 및/또는 기타 적절한 전자 회로)을 포함할 수 있는 전자 회로 또는 다른 전자 하드웨어를 포함 할 수 있고 및/또는 이를 사용하여 구현될 수 있고 및/또는 본 명세서에 설명된 다양한 동작을 수행하기 위해 컴퓨터 소프트웨어, 펌웨어, 또는 이들의 임의의 조합을 포함 및/또는 사용하여 구현될 수 있다. 컴퓨팅 디바이 스는 디스플레이(출력 디바이스의 예로 또는 출력 디바이스에 추가하여), 데이터를 통신 및/또는 수신하도록 구 성된 네트워크 인터페이스, 이들의 임의의 조합, 및/또는 다른 컴포넌트(들)를 더 포함할 수 있다. 네트워크 인 터페이스는 인터넷 프로토콜(IP) 기반 데이터 또는 다른 유형의 데이터를 통신 및/또는 수신하도록 구성될 수 있다. 위에서 논의된 방법은 논리적 흐름도로서 예시되며, 그 동작은 하드웨어, 컴퓨터 명령어, 또는 이들의 조합으로 구현될 수 있는 동작들의 시퀀스를 나타낸다. 컴퓨터 명령어의 맥락에서, 동작은 하나 이상의 프로세서에 의해 실행될 때 인용된 동작을 수행하는 하나 이상의 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 실행가능 명령어를 나타낸다. 일반적으로, 컴퓨터 실행가능 명령어는 특정 기능을 수행하거나 특정 데이터 유형을 구현하는 루틴, 프로그램, 오브젝트, 컴포넌트, 데이터 구조 등을 포함한다. 동작이 설명되는 순서는 제한으로 해석되지 않으며 설명된 동작의 임의의 수는 프로세스를 구현하기 위해 임의의 순서로 및/또는 병렬로 결합될 수 있다. 추가적으로, 본 명세서에 개시된 방법은 실행 가능한 명령어로 구성된 하나 이상의 컴퓨터 시스템의 제어하에 수행될 수 있고 하드웨어에 의해 하나 이상의 프로세서에서 집합적으로 실행되는 코드(예를 들어, 실행 가능한 명령어, 하나 이상의 컴퓨터 프로그램 또는 하나 이상의 애플리케이션)로 구현될 수 있고, 또는 이들의 조합이 가능하다. 위에서 언급된 바와 같이, 코드는 예를 들어 하나 이상의 프로세서에 의해 실행가능한 복수의 명령어 를 포함하는 컴퓨터 프로그램의 형태로 컴퓨터 판독가능 또는 머신 판독가능 저장 매체에 저장될 수 있다. 컴퓨 터 판독가능 또는 머신 판독가능 저장 매체는 비일시적일 수 있다. \"컴퓨터 판독가능 매체\"라는 용어는 휴대용 또는 비휴대용 저장 디바이스, 광학 저장 디바이스, 및 명령어(들) 및/또는 데이터를 저장, 포함 또는 운반할 수 있는 다양한 기타 매체를 포함하지만 이에 제한되지 않는다. 컴퓨 터 판독가능 매체는 데이터가 저장될 수 있고 무선으로 또는 유선 연결을 통해 전파하는 반송파 및/또는 일시적 인 전자 신호를 포함하지 않는 비일시적 매체를 포함할 수 있다. 비일시적 매체의 예는 자기 디스크 또는 테이 프, 콤팩트 디스크(CD) 또는 디지털 다목적 디스크(DVD)와 같은 광학 저장 매체, 플래시 메모리, 메모리 또는 메모리 디바이스를 포함할 수 있지만 이에 제한되지 않는다. 컴퓨터 판독가능 매체에는 코드 및/또는 머신 실행 가능 명령어가 저장되어 있을 수 있으며, 이는 절차, 기능, 서브프로그램, 프로그램, 루틴, 서브루틴, 모듈, 소 프트웨어 패키지, 클래스 또는 명령어, 데이터 구조 또는 프로그램 명령문의 조합을 나타낼 수 있다. 코드 세그 먼트는 정보, 데이터, 인수, 파라미터 또는 메모리 내용을 전달 및/또는 수신하여 다른 코드 세그먼트 또는 하 드웨어 회로에 연결될 수 있다. 정보, 인수, 파라미터, 데이터 등은 메모리 공유, 메시지 전달, 토큰 전달, 네트워크 전송 등을 포함하는 임의의 적절한 수단을 통해 전달, 포워딩 또는 송신될 수 있다. 일부 실시예에서, 컴퓨터 판독가능 저장 디바이스, 매체, 및 메모리는 비트 스트림 등을 포함하는 케이블 또는 무선 신호를 포함할 수 있다. 그러나 언급된 경우 비일시적 컴퓨터 판독가능 저장 매체는 에너지, 캐리어 신호, 전자기파 및 신호 자체와 같은 매체를 명시적으로 제외한다. 특정 세부사항은 본 명세서에 제공된 실시예 및 예의 완전한 이해를 제공하기 위해 위의 설명에서 제공된다. 그 러나, 이들 특정 세부사항 없이 실시예가 실시될 수 있다는 것이 당업자에 의해 이해될 것이다. 설명의 명확성 을 위해, 일부 경우에 본 기술은 디바이스, 디바이스 컴포넌트, 소프트웨어로 구현된 방법의 단계 또는 루틴, 또는 하드웨어와 소프트웨어의 조합을 포함하는 개별 기능 블록을 포함하는 것으로 제시될 수 있다. 도면에 도 시되거나 본 명세서에 설명된 것 이외의 추가 컴포넌트가 사용될 수 있다. 예를 들어, 회로, 시스템, 네트워크, 프로세스 및 기타 구성 요소는 실시예를 불필요한 세부 사항으로 모호하게 하지 않기 위해 블록도 형태의 컴포 넌트로 도시될 수 있다. 다른 예에서, 잘 알려진 회로, 프로세스, 알고리즘, 구조 및 기술은 실시예를 모호하게 하는 것을 피하기 위해 불필요한 세부사항 없이 도시될 수 있다. 개별 실시예는 순서도, 흐름도, 데이터 흐름도, 구조도, 또는 블록도로서 도시된 프로세스 또는 방법으로서 위 에서 설명될 수 있다. 순서도에서는 동작들을 순차적 프로세스로 설명할 수 있지만 많은 동작들이 병렬로 또는 동시에 수행될 수 있다. 또한, 동작들의 순서는 재배열될 수 있다. 프로세스는 동작들이 완료되면 종료되지만 도면에 포함되지 않은 추가 단계가 존재할 수 있다. 프로세스는 방법, 함수, 절차, 서브루틴, 서브프로그램 등 에 대응할 수 있다. 프로세스가 기능에 해당할 때 해당 종료는 호출 함수 또는 메인 함수에 대한 함수의 반환에 대응할 수 있다. 전술한 예에 따른 프로세스 및 방법은 컴퓨터 판독가능 매체로부터 저장되거나 달리 이용가능한 컴퓨터 실행가 능 명령어를 사용하여 구현될 수 있다. 이러한 명령어는 예를 들어 범용 컴퓨터, 특수 목적 컴퓨터 또는 처리 디바이스가 특정 기능 또는 기능 그룹을 수행하도록 하거나 구성하는 명령어 및 데이터를 포함할 수 있다. 사용 된 컴퓨터 리소스의 일부는 네트워크를 통해 액세스 가능할 수 있다. 컴퓨터 실행 가능한 명령어는 예를 들어 바이너리, 어셈블리 언어, 펌웨어, 소스 코드와 같은 중간 형식 명령어일 수 있다. 설명된 예에 따른 방법 동안 생성된 정보, 사용된 정보 및/또는 명령어를 저장하는 데 사용될 수 있는 컴퓨터 판독가능 매체의 예시는 자기 또는 광 디스크, 플래시 메모리, 비휘발성 메모리가 제공되는 USB 디바이스, 네트워크 저장 디바이스 등을 포함 한다. 본 개시에 따른 프로세스 및 방법을 구현하는 디바이스는 하드웨어, 소프트웨어, 펌웨어, 미들웨어, 마이크로코 드, 하드웨어 기술 언어, 또는 이들의 임의의 조합을 포함할 수 있으며, 다양한 폼 팩터를 사용할 수 있다. 소 프트웨어, 펌웨어, 미들웨어 또는 마이크로코드로 구현될 때, 필요한 작업을 수행하기 위한 프로그램 코드 또는 코드 세그먼트(예를 들어, 컴퓨터 프로그램 제품)는 컴퓨터 판독가능 또는 머신 판독가능 매체에 저장될 수 있 다. 프로세서(들)는 필요한 작업을 수행할 수 있다. 폼 팩터의 일반적인 예는 랩톱, 스마트폰, 휴대폰, 태블릿 장치 또는 기타 소형 폼 팩터 개인용 컴퓨터, PDA, 랙마운트 장치, 독립형 디바이스 등을 포함한다. 본 명세서 에 설명된 기능은 또한 주변기기 또는 추가 카드로 구현될 수 있다. 이러한 기능은 또한 추가 예로서 단일 디바 이스에서 실행되는 상이한 칩 또는 상이한 프로세스 사이의 회로 기판 상에서 구현될 수 있다. 명령어, 이러한 명령어를 전달하기 위한 매체, 이를 실행하기 위한 컴퓨팅 리소스, 및 이러한 컴퓨팅 리소스를 지원하기 위한 다른 구조는 본 개시에 설명된 기능을 제공하기 위한 예시적인 수단이다. 전술한 설명에서, 애플리케이션의 양태는 그의 특정 실시예를 참조하여 설명되지만, 당업자는 애플리케이션이 이에 제한되지 않는다는 것을 인식할 것이다. 따라서, 본 출원의 예시적인 실시예가 본 명세서에서 상세히 설명 되었지만, 본 발명의 개념은 달리 다양하게 구현 및 사용될 수 있으며, 첨부된 청구범위는 선행 기술에 의해 제 한되는 경우를 제외하고는 이러한 변형을 포함하는 것으로 해석되어야 함을 이해해야 한다. 전술한 애플리케이 션의 다양한 피쳐 및 양태는 개별적으로 또는 공동으로 사용될 수 있다. 또한, 실시예는 명세서의 보다 넓은 사 상 및 범위를 벗어나지 않고 본 명세서에 설명된 것 이상의 환경 및 애플리케이션에서 활용될 수 있다. 따라서 명세서 및 도면은 제한적인 것이 아니라 예시적인 것으로 간주되어야 한다. 설명을 위해 특정 순서로 방법이 설 명되었다. 대안적인 실시예에서, 방법은 설명된 것과 다른 순서로 수행될 수 있음을 이해해야 한다. 통상의 기술을 가진 사람은 보다 작음(\"<\") 및 보다 큼(\">\") 기호 또는 본 명세서에 사용된 용어는 본 설명의 범위를 벗어나지 않고 각각 이하(\" \") 및 이상(\" \") 기호로 대체될 수 있다는 것을 이해해야 한다.컴포넌트가 특정 동작을 수행하도록 \"구성된\" 것으로 설명되는 경우, 그러한 구성은 예를 들어 동작을 수행하기 위해 전자 회로 또는 기타 하드웨어를 설계함으로써, 동작을 수행하기 위해 프로그래밍 가능한 전자 회로(예를 들어, 마이크로프로세서 또는 기타 적절한 전자 회로)를 프로그래밍함으로써, 또는 이들의 임의의 조합을 통해 달성될 수 있다. \"결합된\"이라는 문구는 다른 컴포넌트에 직접 또는 간접적으로 물리적으로 연결된 임의의 컴포넌트 및/또는 다 른 컴포넌트와 직접 또는 간접적으로 통신하는(예를 들어, 유선 또는 무선 연결 및/또는 기타 적절한 통신 인터 페이스를 통해 다른 컴포넌트에 연결된) 임의의 컴포넌트를 지칭한다. 세트의 \"적어도 하나\" 및/또는 \"하나 이상\"을 인용하는 청구 언어 또는 기타 언어는 세트의 하나의 맴버 또는 세트의 다중 맴버들(임의의 조합으로)이 청구를 충족함을 나타낸다. 예를 들어, \"A와 B 중 적어도 하나\" 또는 \"A 또는 B 중 적어도 하나\"를 인용하는 클레임 언어는 A, B 또는 A와 B를 의미한다. 다른 예에서, \"A, B, 및 C 중 적어도 하나\" 또는 \"A, B, 또는 C 중 적어도 하나\"를 인용하는 클레임 언어는 A, B, C, 또는 A 및 B, 또는 A 와 C, 또는 B와 C, 또는 A와 B와 C를 의미한다. 세트의 \"적어도 하나\" 및/또는 세트의 \"하나 이상\"이라는 언어 는 세트에 나열된 항목으로 세트를 제한하지 않는다. 예를 들어, \"A와 B 중 적어도 하나\" 또는 \"A 또는 B 중 적 어도 하나\"를 인용하는 클레임 언어는 A, B 또는 A 및 B를 의미할 수 있으며, A 및 B의 세트에 나열되지 않은 항목을 추가로 포함할 수 있다. 첨부된 청구항의 범위 내에서 양태를 설명하기 위해 다양한 예 및 기타 정보가 사용되었지만, 통상의 기술자가 광범위한 구현예를 유도하기 위해 이러한 예를 사용할 수 있기 때문에 이러한 예의 특정 피쳐 또는 배열에 기초 하여 청구범위의 제한이 암시되어서는 안 된다. 또한 일부 주제가 구조적 피쳐 및/또는 방법 단계의 예에 특정 한 언어로 설명되었을 수 있지만, 첨부된 청구범위에 정의된 주제는 이러한 설명된 피쳐 또는 작용에 반드시 제 한되지 않는다는 것을 이해해야 한다. 예를 들어, 이러한 기능은 본 명세서에서 식별된 것과 다른 컴포넌트에서 다르게 배포되거나 수행될 수 있다. 오히려, 설명된 피쳐 및 단계는 첨부된 청구범위 내에서 시스템 및 방법의 컴포넌트의 예로서 개시된다. 세트의 \"적어도 하나\"를 인용하는 클레임 언어는 세트의 한 맴버 또는 세트의 여러 맴버들이 클레임을 충족함을 나타낸다. 예를 들어, \"A와 B 중 적어도 하나\"를 인용하는 클레임 언어는 A, B 또는 A와 B를 의미한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면9a 도면10 도면10a 도면11"}
{"patent_id": "10-2022-7040910", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 전술한 및 기타 이점 및 피쳐가 획득될 수 있는 방식을 설명하기 위해, 위에서 간략하게 설명된 원리 의 보다 특정한 설명은 첨부된 도면에 예시된 특정 실시예를 참조하여 제공될 것이다. 이들 도면은 본 개시의 예시적인 실시예만을 도시하고 따라서 그 범위를 제한하는 것으로 간주되어서는 안 된다는 것을 이해하고, 본 명세서의 원리는 다음과 같은 첨부 도면을 사용하여 추가로 구체적이고 세부적으로 설명되고 설명된다: 도 1은 연합 러닝 모델 훈련 접근법을 예시한다; 도 2는 분할 러닝 중앙 집중식 모델 훈련 접근법을 예시한다; 도 3은 분할 러닝 피어-투-피어(peer-to-peer) 접근법을 예시한다; 도 4는 연합 분할 러닝 접근법(federated split learning approach)을 예시한다; 도 5는 블라인드 러닝과 관련된 실시예를 예시한다; 도 7은 블라인드 상관관계가 다중 클라이언트들에 걸쳐 어떻게 작동하는지를 예시한다; 도 8은 방법 실시예를 예시한다; 도 9 내지 9a는 방법 실시예를 예시한다; 도 10 내지 도 10a는 방법 실시예를 예시한다; 및 도 11은 시스템 실시예를 예시한다."}
