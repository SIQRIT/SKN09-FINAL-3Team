{"patent_id": "10-2022-0177026", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0094611", "출원번호": "10-2022-0177026", "발명의 명칭": "카메라 단일 영상을 이용한 동적객체 검출장치 및 이를 이용한 방법", "출원인": "(주)테슬라시스템", "발명자": "오광만"}}
{"patent_id": "10-2022-0177026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오 카메라로부터 영상을 획득하는 영상분리부;상기 영상분리부로부터 입력된 영상에 존재하는 객체들의 상대적인 거리를 검출하여 깊이 정보를 컬러에 매핑하여 표시한 깊이 맵 영상을 생성하는 거리 검출부;CNN 딥러닝 기반의 인공지능을 이용하여 상기 영상에 존재하는 객체만을 부분적으로 분리하여 하나의 박스로 표시하는 객체 추출부; 및상기 박스에 표시된 객체의 종류와 위치를 추정하는 동적객체 인식부로 이루어지는 카메라 단일 영상을 이용한동적객체 검출장치."}
{"patent_id": "10-2022-0177026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 거리 검출부는 상기 영상분리부로부터 입력된 영상에서 특징 맵을 생성하고 소프트맥스 함수를 이용한 선형 퍼셉트론을 적용하여 영상내 개별 픽셀에 대한 유사성을 분석하는 변형모듈;상기 특징 맵을 추출하기 위해 영상의 크기를 점진적으로 업샘플링하는 픽셀-레벨모듈 및상기 픽셀-레벨 모듈(210)과 상기 변형 모듈(220)의 출력을 결합하여 상기 픽셀의 깊이를 예측하는 깊이추정모듈로 이루어지는 카메라 단일 영상을 이용한 동적객체 검출장치."}
{"patent_id": "10-2022-0177026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 객체 추출부는 상기 영상분리부로부터 입력된 영상에 존재하는 객체의 위치를 결정하는 객체 검출부 및상기 객체 검출부에서 추정되는 복수의 박스에서 객체가 포함되는 확률을 계산하여 최종적으로 객체가 포함되는박스를 결정하는 영역 검출부를 포함하는 카메라 단일 영상을 이용한 동적객체 검출장치."}
{"patent_id": "10-2022-0177026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 동적객체 인식부는 상기 거리 검출부에서 생성된 깊이 맵 영상과 상기 객체 추출부에서 객체를 포함하는박스를 결합한 영상을 생성하고, 객체의 크기 및 중심점을 생성하는 객체중심 감지부 및상기 중심점의 상대적인 위치와 이동 속도를 추적하는 객체 인지부를 포함하는 카메라 단일 영상을 이용한 동적객체 검출장치."}
{"patent_id": "10-2022-0177026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 박스를 결합한 영상은 3차원의 객체 중심의 컬러 PCD 영상인 것을 특징으로 하는 카메라 단일 영상을 이용한 동적객체 검출장치."}
{"patent_id": "10-2022-0177026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항중 어느 한 항에 기재된 카메라 단일 영상을 이용한 동적객체 검출장치를 이용하여 동적객체를추적하는 방법으로서, 비디오 영상 프레임으로부터 하나의 영상을 분리하는 제1 단계; 공개특허 10-2024-0094611-3-상기 영상으로부터 거리 정보를 포함하는 깊이 맵 영상을 생성하는 제2-1 단계; 상기 제1 단계에서 상기 영상에 포함되는 객체를 추출하여 하나의 박스로 표시하는 제2-2 단계; 상기 깊이 맵 영상에 박스를 결합하여 객체만을 포함하는 PCD 영상을 생성하는 제3 단계; 및상기 PCD 영상으로부터 객체의 종류 및 크기를 검출하고, 객체의 중심점을 추정하고 상기 중심점의 움직임을 추정하는 제4 단계로 이루어지는 카메라 영상을 이용한 동적객체의 검출방법."}
{"patent_id": "10-2022-0177026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제4 단계 이후, 제1 단계를 반복하여 상기 객체의 움직임을 반복적으로 추적하여 변경된 위치 및 이동 속도를 추정하는 제5 단계를 포함하는 카메라 영상을 이용한 동적객체의 검출방법."}
{"patent_id": "10-2022-0177026", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 카메라 단일 영상을 이용한 동적객체 검출장치 및 이를 이용한 검출방법에 관한 것으로, 보다 상세하 게는 비디오 카메라로부터 영상을 획득한 영상 분리부, 입력된 영상에 존재하는 객체들의 상대적인 깊이를 검출 하고 깊이 정보를 컬러에 매핑하여 표시한 깊이 맵 영상을 생성하는 거리 검출부, CNN 딥러닝 기반의 인공지능을 이용하여 상기 영상에 존재하는 객체만을 부분적으로 분리하여 하나의 박스로 표시하는 객체 추출부 및 객체 박 스에 표시된 객체의 종류와 위치를 추정하는 동적객체 인식부로 이루어지는 동적객체 검출장치 및 이를 이용한 검출방법에 관한 것이다."}
{"patent_id": "10-2022-0177026", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 카메라 단일 영상을 이용한 동적객체 검출장치 및 이를 이용한 방법에 관한 것으로, 보다 상세하게는 비디오 카메라로부터 획득한 영상에 존재하는 객체들의 깊이를 검출하여 깊이 정보를 컬러에 매핑하여 표시한 깊이 맵 영상을 생성하고 영상에 존재하는 객체의 종류와 크기를 검출하고, 객체의 움직임을 추적하는 것을 특 징으로 하는 카메라 단일 영상 기반의 동적객체 검출장치 및 이를 이용한 검출방법에 관한 것이다."}
{"patent_id": "10-2022-0177026", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율주행의 핵심 기술은 주변환경을 인지하는 것인데, 도로위에 위치하는 다양한 객체(예로, 자동차, 사람 등) 의 위치와 종류를 검출하는 것이 무엇보다도 중요하다. 특히, 움직이는 객체(이하 '동적객체'라 함)에 대해서는 객체의 위치, 크기뿐만 아니라, 이동방향, 이동 속도를 탐지하여 자율자동차의 운행 방향, 속도 및 제어에 활용 된다. 이러한 동적객체를 검출하기 위해서는 자율자동차에 다양한 센서들이 구비되는데, 센서 데이터의 특징에 따라 크게 카메라 센서, 라이다(Lidar) 센서 또는 레이더(Radar) 센서로 나누어진다. 여기서, 카메라 센서는 가격이 저렴하고, 소형화가 가능하며, 가시광선을 이용한 객체 식별이 쉽지만 영상만으 로는 객체의 위치 특히 거리정보를 획득하기가 어렵다. 이를 보완하는 수단으로 라이다 센서를 활용하는데, 라이다 센서는 송신단에서 레이저를 주사하고 주사된 레이 저의 반사되는 빛을 수신단에서 수신하여 도착 시간을 측정하여 객체의 거리정보를 획득할 수 있고 주야간에도 객체 검출 성능이 우수하다. 송신단에서 레이저를 반시시키는 거울의 각도를 360도 회전하면서 수직으로(Z-축) 반복하게 되면 센서주변의 수만개의 포인트에 대한 3차원 거리정보를 알 수 있다. 하지만 센서시스템이 레이저 반사 거울 회전을 위한 기구물을 포함하므로 인해 가격이 비싸고 소형화가 어려운 문제점이 있다. 특히 국내의 경우, 자율자동차에 독립적으로 모든 정보를 센싱하고 인지 및 판단하는 자율독립주행보다는 자율 자동차들 간에 협력하거나 자율자동차가-엣지 인프라시스템이 정보를 공유하는 방식인 자율협력주행기술을 정부 차원에서 추진하고 있어 인프라 구축비용을 고려할 때 고가의 라이다를 대처할 수 있는 저가의 센서 솔루션 즉 카메라 영상을 통해 객체의 종류 및 위치정보를 검출하는 기술이 필요한 실정하다. 2018년도에 CVPR(computer vision and Pattern Recognition)에 발표된 논문에서는 카메라 영상에서 거리정보를 추출하는 기술에 대한 소개가 있었고, 그 뒤에 발표된 다수의 논문에서 깊이 정보 추출 성능이 매우 좋아지면서 카메라가 라이다를 대체할 수 있는 가능성이 매우 높아지고 있다. 한편, 딥러닝 기술의 발전에 따라 양안(스테레오) 영상뿐만 아니라 단안(monocular) 영상에서의 각 pixel들의 depth estimation 기술이 개발되어 왔고, 이를 자율주행을 비롯한, 로봇과 스마트폰에서의 AR/VR, 드론 등에 접 목하기 위해서는 경량화된 딥러닝 기반 기술이 요구된다. 또한, 양안(stereo)에 비해서 단안(monocular)영상에서 객체에 대해 깊이를 정확히 추정하기가 매우 어렵다. 사람의 경우는 2개의 영상(좌우 눈)과 객체가 이루는 삼각형에 삼각법을 적용하여 객체와의 거리를 측정하고 있 으며 다양한 조명 환경에서의 질감(texture)이나 시점(perspective), 객체에 대한 상대적 크기 등의 정보와 장면 내 전체적 모양과 레이아웃 등의 전반적인 컨텍스트를 적절히 활용하여 자연스럽게 활용하고 있다. 하지만 컴퓨터를 활용한 비전기술로는 객체와의 거리를 추출하는 것은 매우 어려운 문제로 여겨지고 있다. 특허문헌 1에는 라이다를 이용하여 3차원의 포인트 클라우드를 생성하고, 포인트 클라우드 내에 포함되는 객체 까지의 거리 영상 및 밝기(intensity) 영상을 재구성하여 컬러 영상을 생성하고 이를 기반으로 하는 자율주행을 위한 객체 영상 생성 장치에 관한 것이나, 3차원의 영상을 위해 고가의 라이다 센서를 이용하는 점에서 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허공보 제10-2315483호"}
{"patent_id": "10-2022-0177026", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위하여, 본 발명에서는 고가의 라이다 센서를 이용하지 않고 카메라로부터 획득 된 단안 영상으로부터 3차원의 동적객체의 위치 및 종류를 검출하는 동적객체 검출장치 및 이를 이용한 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2022-0177026", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치는 비디오 카 메라로부터 영상을 획득하는 영상분리부, 영상분리부로부터 입력된 영상에 존재하는 객체들의 상대적 인 거리를 검출하여 깊이 정보를 컬러에 매핑하여 표시한 깊이 맵 영상을 생성하는 거리 검출부, 딥러닝 기반의 인공지능을 이용하여 상기 영상에 존재하는 객체만을 부분적으로 분리하여 하나의 박스로 표시하는 객체 추출부 및 박스에 표시된 객체의 종류와 위치를 인식하는 동적객체 인식부로 이루어지는 것을 특징으 로 한다. 또한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치에서, 상기 거리 검출부는 상기 영상분 리부로부터 입력된 영상에서 특징 맵을 생성하고 소프트맥스 함수를 이용한 선형 퍼셉트론을 적용하여 영 상내 개별 픽셀에 대한 유사성을 분석하는 변형모듈, 특징 맵을 추출하기 위해 영상의 크기를 점진적으로 업샘플링하는 픽셀-레벨모듈 및 픽셀-레벨 모듈과 상기 변형 모듈의 출력을 결합하여 상기 픽셀 의 깊이를 예측하는 깊이추정모듈로 이루어지는 것을 특징으로 한다. 또한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치에서, 객체 추출부는 상기 영상분리부 로부터 입력된 영상에 존재하는 객체의 위치를 결정하는 객체 검출부 및 객체 검출부에서 추정 되는 복수의 박스에서 객체가 포함되는 확률을 계산하여 최종적으로 객체가 포함되는 박스를 결정하는 영역 검 출부를 포함하는 것을 특징으로 한다. 또한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치에서, 동적객체 인식부는 상기 거리 검 출부에서 생성된 깊이 맵 영상과 상기 객체 추출부에서 객체를 포함하는 박스를 결합한 영상을 생성 하고, 객체의 크기 및 중심점을 생성하는 객체중심 감지부 및 중심점의 상대적인 위치와 이동 속도를 추적 하는 객체 인지부를 포함하는 것을 특징으로 한다. 또한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치에서, 박스를 결합한 영상은 3차원의 객체 중심의 컬러 PCD 영상인 것을 특징으로 한다. 또한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치를 이용하여 동적객체를 추적하는 방법은 비 디오 영상 프레임으로부터 하나의 영상을 분리하는 제1 단계, 상기 영상으로부터 거리 정보를 포함하는 깊이 맵 (depth map) 영상을 생성하는 제2-1 단계, 제1 단계에서 상기 영상에 포함되는 객체를 추출하여 하나의 박스로 표시하는 제2-2 단계, 깊이 맵 영상에 박스를 결합하여 객체만을 포함하는 PCD 영상을 생성하는 제3 단계 및 PCD 영상으로부터 객체의 종류 및 크기를 검출하고, 객체의 중심점을 추정하고 상기 중심점의 움직임을 추정하는 제4 단계를 포함하는 것을 특징으로 한다. 또한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치를 이용하여 동적객체를 추적하는 방법에서, 제4단계 이후, 제1 단계를 반복하여 객체의 움직임을 반복적으로 추적하여 변경된 위치 및 이동 속도를 추정하 는 제5 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0177026", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이, 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치 및 이를 이용한 방 법에 의하면, 고가의 라이다를 이용하지 않고 카메라 영상만으로 객체의 거리 정보를 획득할 수 있다는 장점이 있다. 또한 본 발명에 따른 카메라 단일 영상을 이용한 동적객체 검출장치 및 이를 이용한 방법에 의하면, 동적객체의 중심점을 추정하고 이들 중심점의 이동을 추적하므로 동적객체의 종류, 위치 및 이동 속도를 실시간으로 쉽게 파악하여 자율주행에 효과적으로 대응할 수 있다는 이점이 있다."}
{"patent_id": "10-2022-0177026", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작 원리를 상세하게 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 어떤 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하, 본 발명에 바람직한 일실시예에 따른 카메라 단일 영상을 이용한 동적객체 검출장치 및 이를 이용한 방법 을 첨부한 도면들을 참고하면서 설명하기로 한다. 도 1은 본 발명의 바람직한 일실시예에 따른 카메라 단일 영상을 이용한 동적객체 검출장치의 기능 블럭도이다. 도 1에 도시된 와 같이, 동적객체 검출장치은 영상분리부, 거리 검출부, 객체 추출부 및 동 적객체 인식부로 구성된다.먼저 영상분리부는 컬러 비디오 카메라로부터 획득된 실시간 비디오 신호를 하나의 영상프레임 단위로 분 리한다. 일반적으로 비디오 신호는 초당 30 개 이상의 영상프레임으로 구성되나, 프로세서의 성능이나 동적객체 의 움직임에 따라 선택적으로 영상을 분리할 수 있으므로 초당 분리하는 영상프레임의 수는 한정하지 않는다. 거리 검출부는 영상분리부로부터 입력된 영상 내에 존재하는 객체들의 상대적인 깊이(거리)를 검출하 고, 깊이 정보를 컬러에 매핑하여 표시한 깊이 맵(Depth map) 영상을 생성하는 기능을 수행한다. 객체 추출부는 딥러닝 기반의 인공지능을 이용하여 영상 내의 객체만을 부분적으로 분리하여 하나의 박스 로 표시하는 기능을 수행한다. 마지막으로 동적객체 인식부는 거리 검출부로부터 획득한 깊이 맵 영상과 객체 추출부에서 검출 한 객체를 포함하는 박스를 서로 결합하여 거리정보를 포함하는 객체를 분리하고, 객체의 움직임을 추적하여 객 체의 위치 및 이동 속도를 인식하는 기능을 수행한다. 이하 도면들을 참조하여 각각의 기능 수단을 자세히 설명하고자 한다. 도 2는 본 발명의 바람직한 일실시예에 따른 거리 검출부의 기능 블럭도이고, 도 3은 본 발명의 바람직한 일실시예에 따른 거리 검출부에 의해 생성된 깊이 맵 영상을 예시한 도면이다. 레이더 또는 라이다 센서를 이용하면 3차원 거리정보를 쉽게 획득하여 영상내 객체의 거리 측정이 가능하지만 영상만으로는 거리 측정이 불가능하여 픽셀 수준에서 동적객체의 종류를 판단하고 원근감을 통해 거리정보를 추 정하여 라이다 센서를 사용하지 않고도 라이다와 유사한 성능을 발휘할 필요가 있다. 거리 검출부는 코넬 대학에서 개발된 기존의 공개된 빈스포머(BinsFormer) 프로그램을 이용하는데, 먼저 영상분리부로부터 획득한 2차원 영상을 구성하는 픽셀 하나 하나의 깊이를 추정할 수 있디. 이렇게 추정한 깊이를 가지고 주변 사물 즉 동적객체의 원근을 표현하는 깊이 맵을 만들 수 있다. 도 2를 참조하면, 거리 검출부는 변형모듈, 픽셀-레벨모듈 및 깊이추정모듈을 이용하여 영 상분리부로부터 획득된 영상에서 객체들의 깊이를 추정한다. 변형모듈은 영상에서 특징 맵을 생성하고 소프트맥스 함수를 이용한 선형 퍼셉트론을 적용하여 영상내 개 별 픽셀에 대한 유사성을 분석한다. 픽셀-레벨모듈은 특징 맵 세트를 추출하기 위해 영상의 크기를 점진적으로 CNN을 통해 업샘플링한다. 깊이추정모듈에서는 픽셀레벨 모듈과 변형 모듈의 출력을 집계하여 픽셀의 깊이를 예측한다. 도 3(a)는 입력영상을 나타내고 있고, 도 3(b)는 거리 검출부에 의해 생성된 깊이 맵의 영상을 나타내고 있다. 도 3(b)를 참조하면, 영상 내의 객체, 즉, 자동차 및 도로의 원근에 따른 색상의 차이를 명확하게 표현하고 있 고, 객체와 배경에 따른 깊이 정보 차이도 충분히 구분이 가능하다. 특히 주목할 점은 거리 검출부는 영상 내에서 거리 정보를 추정하는 것이므로 도로에 표시된 차선의 정보는 도로의 거리정보와 일치하므로 표시되지 않고, 멀리 위치하는 배경 정보는 희석되는 특징이 있는데 이는 사람이 운전 중에 보는 시야의 특징과도 유사하 다. 도 4는 본 발명의 바람직한 일실시예에 따른 객체 추출부의 기능 블럭도이고, 도 5는 본 발명의 바람직한 일실시예에 따른 객체 추출부에 의해 추출된 객체를 예시한 영상이다. 도 4를 참조하면, 객체 추출부는 영상 내에서 움직이는 객체가 존재하는 위치를 결정하는 것으로, 객체 검 출부 및 영역 검출부로 이루어진다. 객체 검출부는 하나의 영상에서 객체가 위치할 가능성이 있는 하나의 박스를 생성하고 영상의 크기를 필터 를 통해 재구성하면서 객체가 위치할 영역을 특정하는 것을 특징으로 한다. 영역 검출부는 객체 검출부에서 추정되는 복수의 박스에서 객체가 포함되는 확률을 계산하여 최종적 으로 객체가 포함되는 박스를 결정하게 된다. 이러한 일련의 과정을 위해 본 발명에서는 영상을 그리드 시스템 으로 분할되는 객체 감지 알고리즘 중 하나인 파이토치(Pytorch) 딥러닝 프레임워크에서 수행되는 YOLOv5를 사 용하였다. YOLO는 별도의 전처리 과정없이 하나의 영상을 CNN(컨볼루션 신경망)을 통해 가능하고 별도의 다른 분류기 기반의 접근 방식과 달리 손실함수에 대해 직접 대응해 훈련하여 처리시간 측면에서 실시간 객체 검출이가능하다는 장점이 있다. 이러한 YOLOv5는 오픈소스이므로 자세한 동작 및 설명은 생략한다. 도 5에 도시된 바와 같이, 도 5(a)는 입력 영상을 나타내고 있고, 도 5(b) 및 (c)는 입력 영상 내에서 객체로 추정되는 영역을 선정하여 하나의 박스로 표현한 예시를 나타내고 있다. 특히, 입력 영상에서 배경을 나타내는 영역의 객체(예로 도로, 집, 나무 등)들은 학습 과정에서 객체로 선정되지 않도록 가중치를 조정할 수 있으므로 배제가 가능하다. 도 6은 본 발명의 바람직한 일실시예에 따른 거리 검출부 및 객체 추출부에 의해 생성된 또다른 영상을 나타내 고 있다. 도 6(a)를 참조하면, 거리 검출부에 의해 수행된 객체 즉, 도로상에서 자동차와 사람들에 대한 깊이를 검 출하여 깊이 정보를 컬러에 매핑하여 표시한 깊이 맵 영상이다. 도 6(b)는 객체 추출부에 의해 수행된 객체를 분리하여 하나의 박스로 표현한 영상으로, 특히 객체를 제외 한 나머지 배경정보를 검은색으로 표시하여 객체의 위치를 명확하게 특정할 수 있다. 도 7은 본 발명의 바람직한 일실시예에 따른 3차원 영상의 PCD(Point Cloud Data)를 예시한 영상이고, 도 8은 본 발명의 바람직한 일실시예에 따른 동적객체 인식부의 기능 블럭도이다. 또한, 도 9는 동적객체 인식부 에서 추정한 3차원 동적객체들을 예시한 영상이고, 도 7을 참조하면, 거리 검출부를 통한 깊이 맵 영상과 객체 추출부에서 추출된 객체가 위치하는 박스 를 서로 결합하여 라이다가 제공하는 형태의 3차원 영상인 객체 중심의 컬러 PCD(Point Cloud Data) 영상이다. 이러한 PCD 영상에는 객체 추출부에서 추정된 개별 객체에 대한 깊이 정보를 포함하는데, 이들 정보들은 객체의 종류와 위치를 추정하는 동적객체 인식부의 입력으로 제공된다. 도 8에 도시된 동적객체 인식부는 동적객체를 지정하고, 해당 객체를 하나의 박스로 표현하여 객체의 종류 와 위치를 추정하는 기능을 수행한다. 이러한 박스로 표현된 객체는 다양한 크기, 모양, 가로세로의 비율의 차이가 크다. 예를 들면, 교통 영역에서 자전거는 평면 가까이에 있고, 버스와 리무진은 길쭉하며, 보행자는 키가 크다. 또한, 이들 객체의 이동에 따른 형태의 변화로 인해 추정하기 어려운 문제점이 있다. 이를 위한 다양한 방법이 소개되어 있지만 본 발명에서는 객체의 중심을 감지하고 이 중심의 이동 방향 및 속도를 감지하는 CenterPoint 알고리즘을 채용한다. 이러한 중심점 이동은 도로에서 차량이 회전할 때 축의 방향도 이동하므로 인해 각도 등 의 정보를 더 필요하지만 중심점의 경우는 축의 변화없이 하나의 점 만을 추적하므로 객체를 정확히 감지할 수 있다. CenterPoint 알고리즘은 PCD로부터 3차원 객체를 감지하는 객체중심 감지부 및 이들 객체의 움직임을 추적 하는 객체 인지부으로 이루어진다. 먼저, 객체중심 감지부는 키포인트(Key point) 탐지 수단을 통해 객체의 중심점을 탐지하고, 탐지된 각 중 심에 대해 중심 위치의 포인트에서 크기, 방향 및 속도와 같은 다른 모든 객체 특성으로 회귀한다. 객체 인지부는 객체의 종류와 크기를 검출하고, 부가적으로 객체중심 감지부에서 지정한 중심점의 이 동을 추적하는 기능을 수행한다. 이러한 중심점의 변화는 공간과 시간의 경로로 표현이 가능하고, 연속적인 영 상을 통해 상대적 위치를 통해 이동 속도의 예측이 가능하다. 도 9에 도시된 바와 같이, 동적객체 인식부에서 최종적으로 생성한 3차원 객체들을 추정한 영상이다. 이 영상이외에 시간적으로 연속되는 영상을 통해 추정된 객체의 움직임을 이전 영상과 대비하여 실시간 추적이 가 능하므로 별도의 라이다에 의한 PCD 영상 없이도 단일 영상을 반복하여 객체 추적을 통해 자율 주행이 가능하다. 도 10은 본 발명에 따른 바람직한 일실시예로 동적객체 검출장치를 이용하여 동적객체를 검출하는 방법을 설명 한 순서도이다. 도 10를 참조하면, 비디오 영상 프레임으로부터 하나의 영상을 분리하는 제1 단계; 영상으로부터 거리 정보를 포함하는 깊이 맵(depth map)을 생성하는 제2-1 단계, 제1 단계에서 영상에 포함되는 객체를 추출하여 하나의 박스로 표시하는 제2-2 단계, 깊이 맵 영상에 박스를 결합하여 객체만을 포함하는 PCD 영상을 생성하는 제3 단 계 및 PCD 영상으로부터 객체의 종류 및 크기를 검출하고, 객체의 중심점을 추정하고 상기 중심점의 움직임을추정하는 제4 단계로 이루어진다. 또한, 제4 단계 이후 제1 단계를 반복하여 객체의 움직임을 반복적으로 추적 하여 변경된 위치 및 이동 속도를 추정하는 제5 단계로 이루어진다. 지금까지 본 발명에 대해 구체적인 실시예들을 참고하여 설명하였다. 그러나, 본 발명이 속한 분야에서 통상의 지식을 가진 자라면 상기 내용을 바탕으로 본 발명의 범주내에서 다양한 응용 및 변형을 수행하는 것이 가능할 것이다."}
{"patent_id": "10-2022-0177026", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 바람직한 일실시예에 따른 카메라 단일 영상을 이용한 동적객체 검출장치의 기능 블럭도이다. 도 2는 본 발명의 바람직한 일실시예에 따른 거리 검출부의 기능 블럭도이다. 도 3은 본 발명의 바람직한 일실시예에 따른 거리 검출부에 의해 생성된 깊이 맵 영상을 예시한 도면이다. 도 4는 본 발명의 바람직한 일실시예에 따른 객체 추출부의 기능 블럭도이다. 도 5는 본 발명의 바람직한 일실시예에 따른 객체 추출부에 의해 추출된 객체를 예시한 영상이다. 도 6은 본 발명의 바람직한 일실시예에 따른 거리 검출부 및 객체 추출부에 의해 생성된 또다른 영상을 나타내 고 있다. 도 7은 본 발명의 바람직한 일실시예에 따른 3차원 영상의 PCD를 예시한 영상이다. 도 8은 본 발명의 바람직한 일실시예에 따른 동적객체 인식부의 기능 블럭도이다. 도 9는 동적객체 인식부에서 추정한 3차원 동적객체들을 예시한 영상이다. 도 10은 본 발명에 따른 바람직한 일실시예로 동적객체 검출장치를 이용하여 동적객체를 검출하는 방법을 설명 한 순서도이다."}
