{"patent_id": "10-2022-0171665", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0086905", "출원번호": "10-2022-0171665", "발명의 명칭": "특정인을 추적하는 로봇시스템", "출원인": "주식회사에이로봇", "발명자": "엄윤설"}}
{"patent_id": "10-2022-0171665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "특정인을 추적하는 로봇시스템에 있어서,로봇의 헤드에 설치되며 주변 사물을 촬영하는 카메라,인공지능모델을 이용하여 상기 카메라에 의해 촬영된 영상으로부터 사람의 얼굴 영역을 인식하는 얼굴인식부,상기 인식된 각각의 사람에 대하여 무작위로 식별 ID를 할당하고, 복수의 식별 ID 중에서 임의로 선택된 하나의식별 ID에 해당하는 얼굴 영역을 특정인의 얼굴영역으로 지정하는 특정인 지정부,상기 지정된 특정인의 얼굴영역을 추적하며, 실시간으로 특정인의 얼굴영역에 대한 좌표를 획득하는 얼굴 좌표획득부,상기 특정인의 얼굴영역에 대한 좌표를 이용하여 상기 로봇의 헤드가 특정인의 얼굴과 대향되는 위치로 이동하기 위한 목표 좌표 및 표정 ID값을 생성하는 헤드 제어부,상기 목표 좌표를 기반으로 상기 로봇의 헤드를 상하로 움직이게 하는 틸팅 모터 또는 상기 로봇의 헤드를 좌우로 움직이게 하는 패닝 모터의 회전 각도값을 산출하고, 산출된 회전 각도값을 이용하여 모터를 제어하는 모터제어부, 그리고빔 프로젝터의 구동을 제어하는 제어신호를 생성하여 상기 표정 ID값에 대응하는 이미지 프레임을 출력시키는화면 제어부를 포함하는 로봇시스템."}
{"patent_id": "10-2022-0171665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 로봇이 수행해야 하는 모션을 복수개 설정하고, 설정된 복수개의 모션 중에서 선택된 하나의 모션을 수행하도록 하는 제어 신호를 출력하며, 상기 모션에 대응하는 표정 ID값을 생성하는 모션 제어부를 더 포함하는 로봇시스템."}
{"patent_id": "10-2022-0171665", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 빔 프로젝터는,로봇의 헤드에 내장되어 설치되며, 얼굴 이미지 또는 표정 이미지를 출력하는 로봇시스템."}
{"patent_id": "10-2022-0171665", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 특정인을 추적하는 로봇시스템에 대한 것이다. 본 발명에 따른 로봇시스템은 로봇의 헤드에 설치되며 주변 사물을 촬영하는 카메라, 인공지능모델을 이용하여 상기 카메라에 의해 촬영된 영상으로부터 사람의 얼굴 영역을 인식하는 얼굴인식부, 상기 인식된 각각의 사람에 대하여 무작위로 식별 ID를 할당하고, 복수의 식별 ID (뒷면에 계속)"}
{"patent_id": "10-2022-0171665", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 특정인을 추적하는 로봇시스템에 관한 것으로서, 더욱 상세하게는 특정인의 얼굴 위치 좌표를 이용하 여 로봇의 머리 또는 몸의 방향을 제어하고, 특정인의 얼굴 표정에 대응하여 적절한 얼굴 표정을 빔 프로젝터를 통해 출력시켜 특정인과 로봇이 서로 상호작용하는 로봇시스템에 관한 것이다."}
{"patent_id": "10-2022-0171665", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전 세계 많은 기업들이 로봇 개발에 투자하면서 최첨단 기능을 선보이는 다양한 로봇들이 등장하고 있다. 애완 견을 대신하는 로봇부터 어린이들에게 언어를 교육하는 로봇까지 매우 다양하다. 최근 과학 전문 잡지 'NewScientist'는 다양한 사람의 얼굴로 사람과 대화가 가능한 최첨단 '비서 로봇'이 개발 됐다고 보도되었다.'비서 로봇'은 사람의 얼굴을 그대로 형상화하며, 다양한 얼굴 이미지와 표정을 실시간으로 출력하고 있다. 이 는 로봇이 주위 사람들의 말과 행동을 인식하고 어느 정도의 상호작용과 커뮤니케이션이 가능하다는 것을 보여 주는 예로서 많은 사람들의 이목을 집중시키고 있다. '비서 로봇'은 프로젝터 기술을 이용하여 얼굴을 통해 다양한 얼굴 이미지 및 표정을 출력시킨다. 자세히는 로 봇의 얼굴 안쪽면에서 반투명의 얼굴 앞면을 향하여 다양한 얼굴의 형태와 표정을 투사하여 이미지를 만들어내 는 것이다. 따라서, 사용자는 자신의 얼굴이나 친구의 얼굴을 로봇의 얼굴에 투사하거나, 로봇의 머리에 부탁된 카메라를 통해 상대의 얼굴 표정을 인식하여 사람의 감정에 대한 반응을 표현할 수 있다. 그러나 종래의 프로젝터는 로봇의 몸체에 내장되어 있어 특정인을 추적할 경우에는 로봇 전체의 움직임을 제어 해야 하므로 특정인과의 자연스러운 아이 컨텍이 불가능하고, 특정인의 추적하는데 한계가 발생될 수 있다. 본 발명의 배경이 되는 기술은 대한민국 공개특허공보 제10-2019-0103146호(2019.09.04. 공개)에 개시되어 있다."}
{"patent_id": "10-2022-0171665", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는, 특정인의 얼굴 위치 좌표를 이용하여 로봇의 머리 또는 몸의 방향을 제어하고, 특정인의 얼굴 표정에 대응하여 적절한 얼굴 표정을 빔 프로젝터를 통해 출력시키는 로봇시스템을 제 공하는데 목적이 있다."}
{"patent_id": "10-2022-0171665", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 특정인을 추적하는 로봇시스템은 로봇의 헤드에 설치되며 주변 사물을 촬영하는 카메라, 인공지 능모델을 이용하여 상기 카메라에 의해 촬영된 영상으로부터 사람의 얼굴 영역을 인식하는 얼굴인식부, 상기 인 식된 각각의 사람에 대하여 무작위로 식별 ID를 할당하고, 복수의 식별 ID 중에서 임의로 선택된 하나의 식별 ID에 해당하는 얼굴 영역을 특정인의 얼굴영역으로 지정하는 특정인 지정부, 상기 지정된 특정인의 얼굴영역을 추적하며, 실시간으로 특정인의 얼굴영역에 대한 좌표를 획득하는 얼굴 좌표 획득부, 상기 특정인의 얼굴영역에 대한 좌표를 이용하여 상기 로봇의 헤드가 특정인의 얼굴과 대향되는 위치로 이동하기 위한 목표 좌표 및 표정 ID값을 생성하는 헤드 제어부, 상기 목표 좌표를 기반으로 상기 로봇의 헤드를 상하로 움직이게 하는 틸팅 모터 또는 상기 로봇의 헤드를 좌우로 움직이게 하는 패닝 모터의 회전 각도값을 산출하고, 산출된 회전 각도값을 이 용하여 모터를 제어하는 모터 제어부, 그리고 빔 프로젝터의 구동을 제어하는 제어신호를 생성하여 상기 표정 ID값에 대응하는 이미지 프레임을 출력시키는 화면 제어부를 포함한다. 또한, 상기 로봇이 수행해야 하는 모션을 복수개 설정하고, 설정된 복수개의 모션 중에서 선택된 하나의 모션을 수행하도록 하는 제어 신호를 출력하며, 상기 모션에 대응하는 표정 ID값을 생성하는 모션 제어부를 더 포함한 다. 또한, 상기 빔 프로젝터는, 로봇의 헤드에 내장되어 설치되며, 얼굴 이미지 또는 표정 이미지를 출력할 수 있다."}
{"patent_id": "10-2022-0171665", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이와 같이 본 발명에 따르면, 얼굴 표정을 출력시키는 빔 프로젝터가 로봇의 머리 부분에 설치됨으로써 필요에 따라 로봇의 머리 부분과 몸체 부분을 분리하여 제어가능 하므로 모션을 수행중인 상황에서도 얼굴 추적 상태에 따라 즉각적으로 얼굴 표정을 변환할 수 있다. 또한, 본 발명에 따르면, 다양한 모션을 수행하는 동시에 특정인 추적을 통해 특정인과의 아이 컨택을 시도하고, 추적상태에 대응하여 즉각적으로 얼굴 표정을 바꿀 수 있으므로 실제 대화하는 듯한 효과를 도모할 수 있다."}
{"patent_id": "10-2022-0171665", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하기로 한다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시되어 있을 수 있다. 또한 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서, 이는 사용자, 운용자의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대한 정의는 본 명세서 전반에 걸친 내용을 토대로 내 려져야 할 것이다. 먼저, 도 1을 통해 본 발명의 실시예에 따른 특정인을 추적하는 로봇시스템에 대하여 설명한다. 도 1은 본 발명의 실시예에 따른 로봇시스템을 설명하기 위한 구성도이다. 도 1에 도시된 바와 같이, 본 발명의 실시예에 따른 로봇시스템은 카메라, 얼굴인식부, 특정인 지정부, 얼굴좌표 획득부, 헤드 제어부, 모터 제어부, 모션 제어부, 화면 제어부 및 제어부를 포함한다. 먼저, 카메라는 로봇의 머리에 설치된 상태에서 전방을 촬영한다. 그리고, 얼굴인식부는 카메라를 통해 촬영된 영상을 이용하여 사람의 얼굴 영역을 인식한다. 즉, 얼 굴인식부는 얼굴을 인식할 수 있는 딥러닝 기반의 인공지능모델을 구축한 다음, 구축된 인공지능모델에 수 신된 영상을 입력하여 사람의 얼굴에 해당하는 영역을 인식한다. 특정인 지정부는 인식된 사람의 얼굴 영역에 식별 ID를 할당한다. 이때, 특정인 지정부는 식별 ID는 무작위로 할당한다. 그리고, 특정인 지정부는 사람의 얼굴 영역으로부터 특징점을 획득하고, 획득한 특징 점과 할당된 식별 ID를 매칭하여 수집한다. 그 다음, 특정인 지정부는 복수의 식별 ID 중에서 선택된 식별 ID를 특정인의 ID로 설정한다. 얼굴좌표 획득부는 특정인으로 설정된 ID와 특징점을 이용하여 실시간으로 특정인의 얼굴영역에 대한 좌표 를 획득한다. 이때, 좌표는 로봇이 위치하는 곳을 기준점으로 하여 3차원 상에 위치하고 있는 얼굴영역 좌표를 나타낸다. 헤드 제어부는 획득한 특정인의 얼굴 영역 좌표를 이용하여 로봇의 헤드가 특정인의 얼굴과 대향되는 위치 로 이동하기 위한 목표 좌표 및 표정 ID값을 생성한다. 모터 제어부는 생성된 목표 좌표를 이용하여 특정인 사이의 거리값과 특정인의 움직임 정보를 획득한다. 그리고, 모터 제어부는 획득한 거리값 및 움직임 정보를 이용하여 모터의 회전을 제어하는 각도값을 산출 한다. 이때, 모터는 틸팅모터와 패닝모터를 포함하며, 모터 제어부는 특정인과의 거리값을 이용하여 틸딩 모터의 회전 각도값을 산출하고, 특정인의 움직임 정보를 이용하여 패닝모터의 회전 각도값을 산출한다. 모션 제어부는 로봇으로 하여금 모션을 수행하게 한다. 모션은 어떤 몸놀림이나 동작을 나타내는 것으로서, 모션 제어부는 로봇이 행할 수 있는 모션을 기 설정한다. 그 다음, 모션 제어부는 기 설정 된 복수의 모션들 중에서 선택된 모션을 수행하도록 제어신호를 출력한다. 또한, 모션 제어부는 모션에 매 칭되는 표정 ID값을 생성한다. 화면 제어부는 빔 프로젝트를 통해 출력할 수 있는 로봇의 얼굴이미지 또는 표정이미지를 수집한다. 이때 수집되는 얼굴이미지 또는 표정이미지에는 고유의 표정 ID값이 부여되므로, 화면 제어부는 얼굴이미지 또 는 표정이미지와 부여된 표정 ID값을 매칭하여 저장한다. 그 다음, 화면 제어부는 기 저장된 얼굴이미지 또는 표정이미지 중에서 헤드 제어부 또는 모션 제어 부로부터 수신된 표정 ID값과 매칭되는 이미지를 추출하고, 추출된 이미지가 빔 프로젝터를 통해 출력되도 록 제어신호를 생성한다.마지막으로, 제어부는 로봇으로 하여금 특정 모션을 수행하게 하거나, 음성을 출력시킨다. 이하에서는 도 2 내지 도 4를 이용하여 로봇시스템을 이용하여 특정인을 추적하는 방법에 대해 더욱 구체적으로 설명한다. 도 2는 본 발명의 실시예에 따른 로봇시스템을 이용하여 특정인을 추적하는 방법을 설명하기 위한 순서도이다. 도 2에 도시된 바와 같이, 본 발명의 실시예에 따른 로봇의 헤드 부분 일측에 설치된 카메라는 실시간으로 주변환경을 촬영한다. 그 다음, 카메라는 촬영된 영상을 얼굴인식부에 전달한다(S210). 그 다음 얼굴인식부는 전달받은 영상에 포함된 사람의 얼굴 영역을 인식한다(S220) 부연하자면, 얼굴인식부는 딥러닝 기반의 인공지능모델을 구축한다. 그리고, 얼굴인식부는 영상을 이용하여 사람의 얼굴을 인식하고, 인식된 얼굴 영역을 좌표값을 출력하도록 인공지능모델을 학습시킨다. 학습이 완료되면, 얼굴인식부는 카메라로부터 전달받은 영상을 인공지능 모델에 입력하여 영상에 포함된 모든 사람의 얼굴 영역 및 그에 대응하는 좌표값을 추출한다. 추출된 얼굴 영역 및 그에 대응하는 좌표값은 특정인 지정부에 전달된다. 그러면, 특정인 지정부는 전달받은 얼굴 영역마다 식별 ID를 할당하고, 현재시점에서 추적해야 하는 하나 의 얼굴 영역을 선택한다(S230). 이를 다시 설명하면, 특정인 지정부는 인식된 사람 얼굴 영역마다 무작위로 식별 ID를 할당한 다음, 할당 된 식별 ID 중에서 어느 하나의 사람 얼굴 영역을 특정인으로 지정한다. 그리고, 특정인 지정부는 지정된 특정인의 식별 ID 및 얼굴 영역에 대한 최초의 좌표값을 후술되는 얼굴 좌표 획득부에 전달한다. 본 발명의 실시예에 따른 따른 로봇시스템은 인식된 복수의 사람 중에서 어느 하나의 사람을 특정인으로 설정하였으나, 이에 한정하지 않고, 복수의 사람 중에서 사용자로부터 수신된 정보와 매칭되는 사람을 특정인으 로 설정할 수도 있다. 부연하자면, 사용자는 단말기를 이용하여 특정인의 얼굴 또는 신체에 나타나는 특징에 대 한 정보를 입력하고, 입력된 정보는 무선 또는 유선을 통해 로봇시스템에 전달된다. 그러면 로봇시스템 은 전달받은 특정인의 얼굴 또는 신체에 나타나는 특징에 대한 정보를 이용하여 매칭되는 사람을 추출하고, 추출된 사람을 특정인으로 설정한다. S230단계에서 특정인에 대한 설정이 완료되면, 얼굴 좌표 획득부는 특정인의 얼굴영역에 대한 좌표를 실시 간으로 획득한다(S240). 얼굴 좌표 획득부는 선택된 특정인의 ID를 이용하여 현재 시점에서의 특정인의 얼굴 영역에 대한 좌표값을 획득한다. 부연하자면, 얼굴 좌표 획득부는 특정인의 ID와 얼굴영역에 포함된 특징값을 이용하여 특정인의 얼굴 영역을 실시간 추적한다. 그리고, 얼굴 좌표 획득부는 추적하여 획득한 특정인의 얼굴영역에 대한 좌 표값을 헤드 제어부 및 모터 제어부에 각각 전달한다. 그러면, 헤드 제어부는 특정인의 얼굴과 대향되는 위치로 이동하기 위한 목표 좌표 및 표정 ID값을 생성한 다(S250). 먼저, 헤드 제어부는 얼굴 영역 크기를 이용하여 로봇과 사람과의 거리값을 획득한다. 이를 다시 설명하면, 카메라와 사람간의 거리에 따라 인식된 얼굴 영역의 크기는 각각 상이하게 나타난다. 따라서, 헤드 제어부는 특정인의 얼굴 영역에 대한 좌표값을 이용하여 카메라와 특정인 간의 거리값을 획득한 다. 그 다음, 헤드 제어부는 최초에 특정인 얼굴에 대한 좌표값과 현재 시점에서 획득한 좌표값을 이용하여 좌 우 방향으로 이동여부를 판단하고, 이동된 것으로 판단되면 좌측 또는 우측으로 이동된 거리값을 획득한다. 그 다음, 헤드 제어부는 특정인 간의 거리값과 좌측 또는 우측으로 이동된 거리값을 이용하여 목표 좌표를 생성한다. 또한, 헤드 제어부는 특정인과 대향되는 위치에 이동되었을 때 로봇의 표정에 대한 표정 ID값을 생성한다. 여기서 표정 ID값은 로봇의 얼굴을 통해 출력되는 얼굴이미지 또는 표정이미지를 나타낸다. 헤드 제어부는 기본적으로 셋팅된 표정에 대응하는 표정 ID값을 생성할 수도 있고, 특정인의 표정에 대응되는 표정 ID값일 수 도 있다.헤드 제어부는 생성된 목표 좌표값과 표정 ID값을 모터 제어부 및 화면 제어부에 각각 전달한다. S250 단계가 완료되면, 모터 제어부는 전달받은 목표 좌표값을 이용하여 틸팅 모터 및 패닝 모터의 회전 각도값을 산출하고, 산출된 회전 값도값을 이용하여 틸팅 모터 및 패닝 모터를 제어한다(S260). 여기서 틸팅 모터는 로봇의 헤드를 상하로 움직이게 하는 모터이고, 패닝 모터는 로봇의 헤드를 좌우로 움직이 게 하는 모터이다. 따라서, 모터 제어부는 수신된 목표 좌표값을 이용하여 로봇의 헤드를 상하 또는 좌우로 회전하여 특정인 과 마주볼 수 있도록 한다. 그리고, 특정인과 대향되는 위치에 위치한 것으로 판단되면, 모터 제어부는 화 면 제어부에 표정 출력 신호를 송신한다. 그러면, 화면 제어부는 전달받은 표정 ID값에 대응하는 이미지 프레임을 출력하기 위해 빔 프로젝터를 구 동시킨다(S270). 이하에서는 도 3을 이용하여 S270단계에 대해 더욱 상세하게 설명한다. 도 3은 도 2에 도시된 S270단계를 설명하기 위한 순서도이다. 도 3에 도시된 바와 같이, 본 발명의 실시예에 따른 화면 제어부는 얼굴이미지 또는 표정이미지를 수집한 다(S271). 화면 제어부는 빔 프로젝터를 통해 출력되는 얼굴 이미지 또는 표정이미지를 수집한다. 이때, 수집된 얼굴 이미지 또는 표정이미지에는 임의의 표정 ID 값이 부여된다. 그 다음, 화면 제어부는 수신된 표정 ID값에 대응하는 이미지를 추출하고, 추출된 이미지의 출력 순서를 설정한다(S272). 부연하자면, 화면 제어부는 헤드 제어부 또는 모션 제어부로부터 표정 ID값을 전달받는다. 이때, 화면 제어부는 전달받은 순서대로 표정 ID값에 대응되는 이미지를 추출하고, 추출된 순서대로 출력 순서를 설정한다. 다만, 헤드 제어부와 모션 제어부로부터 동시간에 표정 ID값을 수신할 경우, 화면 제어부는 헤 드 제어부로부터 수신된 표정 ID값에 우선순위를 부여한다. 즉, 화면제어부는 헤드 제어부로부 터 수신된 표정 ID값에 대응하는 이미지를 먼저 출력하고, 그 다음, 모션 제어부로부터 전달받은 표정 ID 값에 대응하는 이미지를 출력한다. 이는 모션을 수행 중인 상황에서도 특정인을 추적하는 상태에 따라 로봇의 표정을 즉각적으로 변환시키시 위함이다. S272단계가 완료되면, 화면 제어부는 빔 프로젝트의 구동을 제어하는 제어신호를 생성한다(S730). 도 4는 본 발명의 실시예에 따른 로봇의 얼굴을 통해 이미지가 출력된 상태를 나타낸다. 빔 프로젝터는 로봇의 얼굴 내부에 설치된다. 따라서, 빔 프로젝트는 화면 제어부로부터 수신된 제어신호 에 따라 이미지를 출력하며, 출력된 이미지는 도 4에 도시된 바와 같이, 로봇의 얼굴에 비춰지게 된다. 본 발명의 실시예에 따른 로봇시스템은 특정인을 추적하고, 추적된 특정인과 아이 컨택이 발생되었을 경우, 로봇의 얼굴에 표정을 출력시키거나 모션을 수행한다. 그러나, 추적하던 특정인에 대해 더 이상의 추적이 불가능하다고 판단될 경우, 자세하게는 기 설정된 시간동안 특정인의 얼굴 영역에 대해 좌표를 획득하지 못하면, 얼굴 좌표 획득부는 특정인 추적 중단 신호를 생성하 고, 생성된 추적 중단 신호는 제어부에 전달된다. 그러면, 제어부는 수신된 추적 중단 신호에 따라 \"안녕히 가세요\"라는 인사말을 출력하고, 추적이 중단된 특정인에 대한 재추적 요청 신호를 생성하여 얼굴 좌표 획득부에 전달한다. 그러면, 얼굴 좌표 획득부는 특정인의 ID값 및 특정인에 대한 특징값을 이용하여 특정인을 재추적한다. 이때, 재추적한 결과 특정인의 얼굴 영역에 대한 좌표를 다시 획득하면, 제어부는\"안녕하세요\"라는 인사말 을 출력한다. 반면에 재추적한 결과 특정인의 얼굴 영역에 대한 좌표를 다시 획득하지 못하면, 제어부는 다른 특정인을 지정하는 신호를 출력한다. 이와 같이 본 발명에 따른 로봇시스템은 얼굴 표정을 출력시키는 빔 프로젝터가 로봇의 머리 부분에 설치됨으로 써 필요에 따라 로봇의 머리 부분과 몸체 부분을 분리하여 제어가능 하므로 모션을 수행중인 상황에서도 얼굴 추적 상태에 따라 즉각적으로 얼굴 표정을 변환할 수 있다. 또한, 본 발명에 따른 로봇시스템은 다양한 모션을 수행하는 동시에 특정인 추적을 통해 특정인과의 아이 컨택 을 시도하고, 추적상태에 대응하여 즉각적으로 얼굴 표정을 바꿀 수 있으므로 실제 대화하는 듯한 효과를 도모 할 수 있다. 본 발명은 도면에 도시된 실시예를 참고로 하여 설명되었으나 이는 예시적인 것에 불과하며, 당해 기술이 속하 는 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서 본 발명의 진정한 기술적 보호범위는 아래의 특허청구범위의 기술적 사상에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2022-0171665", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 로봇시스템을 설명하기 위한 구성도이다. 도 2는 본 발명의 실시예에 따른 로봇시스템을 이용하여 특정인을 추적하는 방법을 설명하기 위한 순서도이다. 도 3은 도 2에 도시된 S270단계를 설명하기 위한 순서도이다. 도 4는 본 발명의 실시예에 따른 로봇의 얼굴을 통해 이미지가 출력된 상태를 나타낸다."}
