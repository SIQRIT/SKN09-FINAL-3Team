{"patent_id": "10-2021-0120094", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0037147", "출원번호": "10-2021-0120094", "발명의 명칭": "비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치 및 이를 이용한 방법", "출원인": "한국전자통신연구원", "발명자": "김호원"}}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "센서를 기반으로 사용자의 시선 및 헤딩 동작을 모니터링하는 단계; 상기 시선 및 헤딩 동작을 조합한 응시 기반 헤딩 정보를 기반으로 상기 시선에 상응하는 위치에 사용자 인터페이스를 출력하는 단계; 및상기 사용자 인터페이스에서 선택된 사용자 명령을 인식하는 단계를 포함하는 것을 특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 사용자 인터페이스가 출력되는 위치는 디스플레이 영역 내에서 상기 시선이 고정되는 위치에 상응하게 가변하는 것을 특징으로 하는 사용자 명령 인식방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서, 상기 사용자 인터페이스는 상기 사용자에 상응하는 고유 명령셋을 제공하는 것을 특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서, 상기 응시 기반 헤딩 정보는상기 시선이 고정된 상태에서 상기 헤딩 동작에 의해 입력되는 방향 정보에 상응하는 것을 특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서, 상기 모니터링하는 단계는상기 사용자에 상응하는 헤딩 특성을 고려하여 상기 응시 기반 헤딩 정보를 감지하는 것을 특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서, 상기 헤딩 특성은 머리 회전 각도, 머리 회전 속도, 머리 회전 유지 시간, 머리 회전 복귀 시간 및 머리 회전에 따른 동공의 위치와 모양 중 적어도 하나를 포함하는 것을 특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 공개특허 10-2023-0037147-3-상기 사용자에 상응하는 복수의 응시 기반 헤딩 동작들을 획득하고, 상기 복수의 응시 기반 헤딩 동작들을 기반으로 추출된 상기 헤딩 특성을 사용자 식별정보와 매칭하여 상기 사용자를 등록하는 단계를 더 포함하는 것을특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 사용자를 등록하는 단계는상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 동작 유도 메시지를 출력하는 단계; 및상기 동작 유도 메시지를 통해 의도한 제1 움직임 및 상기 복수의 응시 기반 헤딩 동작들에 상응하는 제2 움직임 간의 차이를 고려하여 상기 헤딩 특성을 보정하는 단계를 포함하는 것을 특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 상기 헤딩 특성을 보정하는 단계는상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 시선 응시점의 위치를 이동시키면서 상기 헤딩 특성을 보정하는 것을 특징으로 하는 사용자 명령 인식 방법."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "센서를 기반으로 사용자의 시선 및 헤딩 동작을 모니터링하고, 상기 시선 및 헤딩 동작을 조합한 응시 기반 헤딩 정보를 기반으로 상기 시선에 상응하는 위치에 사용자 인터페이스를 출력하고, 상기 사용자 인터페이스에서선택된 사용자 명령을 인식하는 프로세서; 및상기 사용자 인터페이스를 저장하는 메모리를 포함하는 것을 특징으로 하는 사용자 명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 사용자 인터페이스가 출력되는 위치는 디스플레이 영역 내에서 상기 시선이 고정되는 위치에 상응하게 가변하는 것을 특징으로 하는 사용자 명령 인식장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 10에 있어서,상기 사용자 인터페이스는 상기 사용자에 상응하는 고유 명령셋을 제공하는 것을 특징으로 하는 사용자 명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 10에 있어서,상기 응시 기반 헤딩 정보는상기 시선이 고정된 상태에서 상기 헤딩 동작에 의해 입력되는 방향 정보에 상응하는 것을 특징으로 하는 사용자 명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서,공개특허 10-2023-0037147-4-상기 프로세서는상기 사용자에 상응하는 헤딩 특성을 고려하여 상기 응시 기반 헤딩 정보를 감지하는 것을 특징으로 하는 사용자 명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 14에 있어서,상기 헤딩 특성은 머리 회전 각도, 머리 회전 속도, 머리 회전 유지 시간, 머리 회전 복귀 시간 및 머리 회전에 따른 동공의 위치와 모양 중 적어도 하나를 포함하는 것을 특징으로 하는 사용자 명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 프로세서는상기 사용자에 상응하는 복수의 응시 기반 헤딩 동작들을 획득하고, 상기 복수의 응시 기반 헤딩 동작들을 기반으로 추출된 상기 헤딩 특성을 사용자 식별정보와 매칭하여 상기 사용자를 등록하는 것을 특징으로 하는 사용자명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서,상기 프로세서는상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 동작 유도 메시지를 출력하고, 상기 동작 유도 메시지를통해 의도한 제1 움직임 및 상기 복수의 응시 기반 헤딩 동작들에 상응하는 제2 움직임 간의 차이를 고려하여상기 헤딩 특성을 보정하는 것을 특징으로 하는 사용자 명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 17에 있어서,상기 프로세서는상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 시선 응시점의 위치를 이동시키면서 상기 헤딩 특성을 보정하는 것을 특징으로 하는 사용자 명령 인식 장치."}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치 및 이를 이용한 방법이 개시된다. 본 발명의 일실 시예에 따른 사용자 명령 인식 방법은 센서를 기반으로 사용자의 시선 및 헤딩 동작을 모니터링하는 단계; 상기 시선 및 헤딩 동작을 조합한 응시 기반 헤딩 정보를 기반으로 상기 시선에 상응하는 위치에 사용자 인터페이스를 출력하는 단계; 및 상기 사용자 인터페이스에서 선택된 사용자 명령을 인식하는 단계를 포함한다."}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 기술에 관한 것으로, 특히 사용자가 별도의 접촉없이 시선과 헤딩 동작 만으로 원하는 위치에 사용자 인터페이스를 출력시켜 사용자 명령을 시스템에 전달 할 수 있는 기술에 관한 것이다."}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "연산기능을 포함한 시스템이 사용자의 명령을 인식하는 방법은 키보드/마우스/버튼/터치 등을 이용한 접촉기반 방법과, 사용자를 촬영한 카메라 영상분석에 기반한 시선(응시)추적, 손/바디 제스처 인식, 음성인식을 통한 비 접촉기반 방법 등이 있다. 제스처를 통한 방법은 제스처를 인식하기 위한 공간이 요구되고, 사용자가 본연의 목적을 위해 손이나 몸을 사 용할 수 없는 상황에서는 이용하기 어렵다는 단점이 있다. 예를 들어, 사용자가 요가와 같은 전신 운동 중이거 나, 산업현장에서 도구를 들고 있거나 작업 중인 경우가 이에 해당된다. 또한, 제스처를 통한 방법은, 제스처 명령을 위해 사용자의 의도적 노력이 많이 요구되는 UX(User Experience) 관점에서의 이슈, 명령동작의 복잡성에 따른 인식률의 이슈, 시스템이 일반적인 사용자의 동작으로부터 사용자 명령을 시작하기 위한 동작과 명령과 무관한 동작에 대한 구분이 어려운 이슈 등이 존재하기도 한다. 시선추적을 통한 방법은, 주로 마우스를 통한 커서조작을 대체하여 사용자의 명령을 입력 받는 용도로 활용된다. 예를 들어, 스크린 앞에 있는 사용자의 시선방향을 카메라로 인식하고, 사용자가 스크린 상의 어느 위치를 보고 있는지를 시스템이 인식함으로써 사용자 명령을 인식한다. 이러한 경우, 정밀한 시선추적을 위해서 사용자의 안구 특성에 따른 캘리브레이션(calibration)이 요구되고, 정밀한 시선추적 결과를 이용하기 위해서는 캘리브레이션이 수행되는 공간 이내로 사용자의 움직임이 상당히 제한된다는 한계를 가지고 있다. 또한, 시선추적을 통한 방법은, 시선방향을 명령입력 수단으로 사용하기 때문에 운전중인 사용자가 전방의 대형 HUD(Head Up Display) 통해 명령을 내릴 경우, 운전자의 전방주시를 방해할 가능성이 높다. 이와 유사하게, HMD(Head Mounted Display)나 AR(Augmented Reality) 글래스를 이용하는 경우에도 사용자는 사용자에게 제시된 스크린 상의 특정 버튼을 누르기 위해 시선방향을 해당 버튼 위치로 이동시켜야 하며, 이러한 사용자명령 입력 방식이 콘텐츠를 보거나 하는 사용자 본연의 목적을 방해하는 방향으로 UX가 전개되는 이슈가 있다. 산업현장의 긴급정지 버튼을 예로 들면, 사용자가 버튼 근처에 없거나 작업 반경을 넓게 사용해야 하는 상황에 서 긴급하게 기계의 기능을 정지시켜야 할 경우, 종래의 물리적 버튼은 한계를 가지며, 작업 중 종래의 제스처 를 통한 방법으로 명령을 내리거나 종래의 시선추적을 통한 방법으로 명령을 내리기에도 한계성을 지니게 된다. 선행기술문헌 특허문헌 (특허문헌 0001) 미국 공개 특허 제10-2020-0285379호, 2020년 9월 10일 공개(명칭: SYSTEM FOR GAZE INTERACTION)"}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 사용자의 본연의 목적을 위한 몸의 사용이나 전방주시 요구 등의 상황을 방해하지 않으면서도, 사용자의 시선이 머무는 곳에 사용자 명령을 입력하기 위한 인터페이스를 출력함으로써 시스템에게 사용자 명령을 전달하는 것이다. 또한, 본 발명의 목적은 최소한의 움직임으로 실시간 사용자 명령을 인터랙티브하게 시스템에 전달하는 것이다. 또한, 본 발명의 목적은 종래의 사용자 명령 전달 체계를 대체하거나 보완 혹은 보조하는 방식으로, 사용자의 얼굴영상을 분석하는 인공지능(AI)을 통해 사용자가 시스템에 실시간 명령을 전달할 필요가 있는 다양한 분야에 활용하기 위한 기술을 제공하는 것이다. 또한, 본 발명의 목적은 접촉기반 입력이나 비접촉 기반 입력이 사용되는 다양한 환경에서 자연스러운 사용자 경험(UX)을 통해 인식되는 다양한 사용자 명령을 인터랙티브하게 시스템에 전달하는 것이다."}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명에 따른 사용자 명령 인식 방법은, 센서를 기반으로 사용자의 시선 및 헤 딩 동작을 모니터링하는 단계; 상기 시선 및 헤딩 동작을 조합한 응시 기반 헤딩 정보를 기반으로 상기 시선에 상응하는 위치에 사용자 인터페이스를 출력하는 단계; 및 상기 사용자 인터페이스에서 선택된 사용자 명령을 인 식하는 단계를 포함한다. 이 때, 사용자 인터페이스가 출력되는 위치는 디스플레이 영역 내에서 상기 시선이 고정되는 위치에 상응하게 가변할 수 있다. 이 때, 사용자 인터페이스는 상기 사용자에 상응하는 고유 명령셋을 제공할 수 있다. 이 때, 응시 기반 헤딩 정보는 상기 시선이 고정된 상태에서 상기 헤딩 동작에 의해 입력되는 방향 정보에 상응 할 수 있다.이 때, 모니터링하는 단계는 상기 사용자에 상응하는 헤딩 특성을 고려하여 상기 응시 기반 헤딩 정보를 감지할 수 있다. 이 때, 헤딩 특성은 머리 회전 각도, 머리 회전 속도, 머리 회전 유지 시간, 머리 회전 복귀 시간 및 머리 회전 에 따른 동공의 위치와 모양 중 적어도 하나를 포함할 수 있다. 이 때, 사용자에 상응하는 복수의 응시 기반 헤딩 동작들을 획득하고, 상기 복수의 응시 기반 헤딩 동작들을 기 반으로 추출된 상기 헤딩 특성을 사용자 식별정보와 매칭하여 상기 사용자를 등록하는 단계를 더 포함할 수 있 다. 이 때, 사용자를 등록하는 단계는 상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 동작 유도 메시지를 출 력하는 단계; 및 상기 동작 유도 메시지를 통해 의도한 제1 움직임 및 상기 복수의 응시 기반 헤딩 동작들에 상 응하는 제2 움직임 간의 차이를 고려하여 상기 헤딩 특성을 보정하는 단계를 포함할 수 있다. 이 때, 헤딩 특성을 보정하는 단계는 상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 시선 응시점의 위치 를 이동시키면서 상기 헤딩 특성을 보정할 수 있다. 또한, 본 발명의 일실시예에 따른 사용자 명령 인식 장치는, 센서를 기반으로 사용자의 시선 및 헤딩 동작을 모 니터링하고, 상기 시선 및 헤딩 동작을 조합한 응시 기반 헤딩 정보를 기반으로 상기 시선에 상응하는 위치에 사용자 인터페이스를 출력하고, 상기 사용자 인터페이스에서 선택된 사용자 명령을 인식하는 프로세서; 및 상기 사용자 인터페이스를 저장하는 메모리를 포함한다. 이 때, 사용자 인터페이스가 출력되는 위치는 디스플레이 영역 내에서 상기 시선이 고정되는 위치에 상응하게 가변할 수 있다. 이 때, 사용자 인터페이스는 상기 사용자에 상응하는 고유 명령셋을 제공할 수 있다. 이 때, 응시 기반 헤딩 정보는 상기 시선이 고정된 상태에서 상기 헤딩 동작에 의해 입력되는 방향 정보에 상응 할 수 있다. 이 때, 프로세서는 상기 사용자에 상응하는 헤딩 특성을 고려하여 상기 응시 기반 헤딩 정보를 감지할 수 있다. 이 때, 헤딩 특성은 머리 회전 각도, 머리 회전 속도, 머리 회전 유지 시간, 머리 회전 복귀 시간 및 머리 회전 에 따른 동공의 위치와 모양 중 적어도 하나를 포함할 수 있다. 이 때, 프로세서는 상기 사용자에 상응하는 복수의 응시 기반 헤딩 동작들을 획득하고, 상기 복수의 응시 기반 헤딩 동작들을 기반으로 추출된 상기 헤딩 특성을 사용자 식별정보와 매칭하여 상기 사용자를 등록할 수 있다. 이 때, 프로세서는 상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 동작 유도 메시지를 출력하고, 상기 동 작 유도 메시지를 통해 의도한 제1 움직임 및 상기 복수의 응시 기반 헤딩 동작들에 상응하는 제2 움직임 간의 차이를 고려하여 상기 헤딩 특성을 보정할 수 있다. 이 때, 프로세서는 상기 복수의 응시 기반 헤딩 동작들을 유도하기 위한 시선 응시점의 위치를 이동시키면서 상 기 헤딩 특성을 보정할 수 있다."}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사용자의 본연의 목적을 위한 몸의 사용이나 전방주시 요구 등의 상황을 방해하지 않으면서 도, 사용자의 시선이 머무는 곳에 사용자 명령을 입력하기 위한 인터페이스를 출력함으로써 시스템에게 사용자 명령을 전달할 수 있다. 또한, 본 발명은 최소한의 움직임으로 실시간 사용자 명령을 인터랙티브하게 시스템에 전달할 수 있다. 또한, 본 발명은 종래의 사용자 명령 전달 체계를 대체하거나 보완 혹은 보조하는 방식으로, 사용자의 얼굴영상 을 분석하는 인공지능(AI)을 통해 사용자가 시스템에 실시간 명령을 전달할 필요가 있는 다양한 분야에 활용하 기 위한 기술을 제공할 수 있다. 또한, 본 발명은 접촉기반 입력이나 비접촉 기반 입력이 사용되는 다양한 환경에서 자연스러운 사용자 경험(U X)을 통해 인식되는 다양한 사용자 명령을 인터랙티브하게 시스템에 전달할 수 있다."}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명을 첨부된 도면을 참조하여 상세히 설명하면 다음과 같다. 여기서, 반복되는 설명, 본 발명의 요지를 불 필요하게 흐릴 수 있는 공지 기능, 및 구성에 대한 상세한 설명은 생략한다. 본 발명의 실시형태는 당 업계에서 평균적인 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위해서 제공되는 것이다. 따라서, 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 이하, 본 발명에 따른 바람직한 실시예를 첨부된 도면을 참조하여 상세하게 설명한다."}
{"patent_id": "10-2021-0120094", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명은 컴퓨터, 태블릿, 핸드폰, 로봇, 차량, 엘리베이터, 산업현장, 병원 등에 장착된 카메라 또는 영상 센 서 등을 통해 사용자의 얼굴 및 머리를 촬영하고, 촬영한 영상으로부터 사용자의 신원, 시선 응시방향, 헤드 포 즈 등을 실시간으로 식별함으로써 사용자의 자유로운 움직임이 요구되거나, 사용자가 본연의 작업을 위해 시선 방향을 유지해야 하거나, 손을 사용하여(키보드, 마우스, 터치, 버튼 입력, 손 제스처 등) 시스템에게 명령을 전달하기 어려운 환경이나, 음성을 통해 명령전달이 어려운 환경(시끄러운 환경, 정숙함이 요구되는 환경, 소음 통제가 어려운 환경 등)에서 비접촉 기반으로 사용자의 명령을 시스템에 인터랙티브하게 실시간 인식할 수 있는 사용자 명령 인식 기술에 관한 것이다. 종래의 비접촉 사용자 명령 전달 방식은 시스템에 명령을 전달하기 위해 사용자가 행하고 있는 행위 본연의 목 적에 반하는 동작이나 시선방향을 요구하지만, 본 발명은 사용자가 행하고 있는 본연의 행위 중에 자연스러운 UX(User Experience)를 기반으로 사용자 명령을 시스템에 전달할 수 있다는 차이점이 있다. 본 발명을 통해, 1) 키보드, 마우스, 터치, 버튼 입력 혹은 바디 제스처 등을 통해 시스템이 사용자의 명령을 입력받는 다양한 산업분야와 생활분야, 2) 운전 중 전방주시와 같이 본연의 목적에 위배되지 않는 방향으로 종 래의 사용자 명령 전달 체계를 대체하거나 보완 및 보조하는 경우, 3) 얼굴 영상분석 기반 AI를 이용하여 사용 자가 시스템에 실시간 명령을 전달할 필요가 있는 다양한 분야에서 활용될 수 있는 기술을 제안하고자 한다. 도 1은 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 시스템을 나타낸 도 면이다. 도 1을 참조하면, 차량 내 운전자를 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 시스템의 사용자로 예시한 상황을 나타낼 수 있다. 이 때, 도 1에는 사용자 명령 인식 장치에 해당하는 모듈이 명시적으로 도시되어 있지 않지만, 사용자를 모니터링하는 카메라 및 디스플레이 영역과 연동되어 동작할 수 있도록 자동차에 사용자 명령 인식 장치가 내장된 형태라 가정할 수 있다.카메라는 사용자의 머리와 눈을 촬영할 수 있는 위치에 설치되어 사용자의 시선과 헤딩 동 작을 모니터링 할 수 있다. 이 때, AR 글래스와 같은 착용형 디바이스의 경우에는 내부에 장착된 카메라를 통해 시선을 모니터링하고, 별도 의 모션 센서등을 이용하여 헤딩 동작을 모니터링 할 수도 있다. 이 때, 본 발명에서는 실시간 모니터링을 통해 검출되는 시선과 헤딩 동작을 조합하여 사용자 명령을 수신할 수 있다. 예를 들어, 시선이 한 곳에 고정된 상태에서 감지되는 헤딩 동작을 기반으로 사용자 명령을 인식할 수 있다. 이를 종래의 방식과 비교하면, 사용자가 정해진 위치를 응시하는 것이 아니라 본원의 목적에 맞게 시선을 둔 상 태로 사용자 명령을 전달할 수 있다. 즉, 종래의 시선추적 기반의 사용자 명령 인식 방법은 디스플레이에 표출되는 특정 위치를 사용자가 응시해야만 사용자 명령이 전달되기 때문에 도 1과 같이 운전을 하는 상황에서 사용자가 전방을 주시하기 어려워 사고의 위 험이 증가할 수 있다. 하지만, 본 발명에 따르면 사용자가 안전운전을 위해 시선은 전방을 주시하면서도 간단한 헤딩 동작 만으로도 원하는 명령을 시스템에 전달할 수 있다. 디스플레이 영역은 사용자 명령을 인터랙티브하게 수신할 수 있도록 사용자의 요구에 따라 사용자의 시선이 위치하는 곳에 사용자 인터페이스를 출력할 수 있다. 예를 들어, 도 1과 같이 차량의 앞 유리에 구비된 HUD(Head Up Display)를 통해 사용자가 주행 중 시선 을 두는 곳에 사용자 명령을 위한 사용자 인터페이스를 표출할 수 있다. 이 때, 사용자 인터페이스를 통해 사용자에 의해 설정된 고유 명령셋이 제공될 수 있다. 예를 들어, 고유 명령셋은 사용자에 의해 설정된 형태나 사용자에 의해 정의된 순서 혹은 시나리오에 상응하게 표출될 수 있다. 이렇게 사용자에 상응하는 고유 명령셋이 표출되면, 사용자 인터페이스를 호출했을 때의 시선을 유지하면서 고개를 좌, 우 혹은 위, 아래 등으로 헤딩하여 시스템에 사용자 명령을 전달할 수 있다. 이 때, 인식된 사용자 명령에 대해 하부 명령셋을 표출하거나, 인식된 사용자 명령을 수행할 수도 있다. 도 1과 같이 본 발명에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 시스템을 차량에 적용함으 로써 차량 사고의 위험성을 감소시킬 수 있다. 예를 들어, 운전자가 운전 중에 차량의 좌우 사이드 미러를 응시하거나 차량 내부 센터페시아를 조작하는 경우, 전방주시에 소홀하여 사고가 발생할 가능성이 있다. 이 때, 본 발명의 구성을 적용하면, 운전자가 전방을 주시 하면서 고개를 위로 올렸다 내리는 등 사전에 정의된 헤딩 동작만 수행하여도, 차량의 사이드미러에 장착된 카 메라의 영상을 정면 디스플레이에 표시하거나 센터페시아 상의 버튼을 직접 조작할 수 있게 된다. 또는, 차량에 음성명령을 위한 시스템이 구비된 경우, 본 발명의 구성을 적용하여 간단한 헤딩 동작만으로 오디오음을 소거한 뒤 음성명령을 수행할 수도 있다. 이 경우, 운전자는 사용자 명령을 전달하는 동안에 전방주시와 자동차 핸들링을 유지하면서도 원하는 방향의 후 방영상을 HUD를 통해 확인하면서 차선 변경을 등을 진행할 수 있다. 상기의 예시 설명에서 HUD를 통한 GUI는 필 수사항은 아니며 사용자의 명령셋 사전 설정에 의해 HUD상의 GUI 디스플레이 없이도 빠른 전개가 가능하다. 다른 예를 들어, 사용자가 TV에 표시되는 콘텐츠를 보면서 스쿼트나 요가와 같은 운동을 하는 홈 트레이닝 같은 운동 분야에서의 상황을 가정해볼 수 있다. 운동 중 콘텐츠의 속도를 조정하거나 다음 운동으로 전환하거나, 옵 션을 설정하는 등의 사용자 명령을 입력해야하는 상황이 발생할 수 있다. 이 때, 본 발명의 구성을 적용하면, 사용자가 TV나 사용자 전방에 장착된 카메라를 통해 TV에 오버레이되어 표시되는 GUI 명령셋에 따라 응시 기반 의 헤딩(시선 방향과 헤딩 동작의 조합)을 수행함으로써 운동의 흐름을 깨지 않으면서도 사용자 명령을 콘텐츠 에 전달할 수 있다. 또 다른 예를 들어, 산업 현장에서 위급상황이 발생하는 경우에 긴급하게 장치나 시스템을 멈출 수 있는 기능의 버튼이 존재하지만, 위급상황 발생 시 사용자가 해당 버튼을 누를 수 없는 상태나 위치일 수 있다. 이 때, 본발명의 구성을 적용하면, 원거리에서도 장치나 시스템을 제어할 수 있다. 즉, 위급상황 발생 시 사용자는 현장 에 설치된 카메라를 통해 응시 기반의 헤딩을 수행함으로써 시스템을 비접촉 기반의 사용자 명령을 인식하기 위 한 대기 모드로 전환할 수 있다. 이 후, 시스템이 대기 모드로 전환되면, 계속해서 카메라 응시를 유지하면서 사전에 정의된 헤딩동작을 수행함으로써 시스템을 긴급정지시킬 수 있다. 이 때, 시스템은 카메라를 통해 명령 을 전달하는 사용자가 긴급 멈춤 권한이 있는 사용자인지 여부를 식별한 뒤 동작할 수 있다. 또한, 시스템은 원 거리에서도 쉽게 식별할 수 있는 조명(조명색 변화 또는 특정위치 조명 점등 등)이나 소리 등을 이용하여 사용 자에게 비접촉 기반의 사용자 명령을 인식하였거나 또는 인식하기 위한 대기 모드로 전환되었음을 확인시켜줌으 로써 사용자에게 명령 수신 상태를 피드백해줄 수 있다. 또 다른 예를 들어, 병원분야에서는 의사가 수술 중 수술과정에 방해를 받지않으면서 시스템에게 상황에 따른 명령을 모니터나 AR 글래스 등에 장착된 카메라를 통해 인터랙티브하게 요청할 수도 있다. 또는, 몸을 움직일 수 없는 환자의 경우, 베드에 누워서 간단히 헤딩 동작만으로 간호사를 호출하거나 응급콜을 요청하는 등의 명 령을 시스템에 전달할 수도 있다. 또 다른 예를 들어, 피아노와 같이 두 손을 계속 사용해야하는 악기 연주 중 응시 기반 헤딩 동작을 통해 손을 사용하지 않고 악보를 넘길 수도 있다. 이 때, 악보 주변에 장착되어 연주자의 얼굴을 모니터링하는 카메라 혹 은 악보를 출력하는 태블릿에 구비된 태블릿 카메라 등을 이용하여 사용자의 비접촉 응시 및 헤딩 기반 사용자 명령을 인식할 수 있다. 또 다른 예를 들어, 접촉에 의한 바이러스 전염 상황에서 엘리베이터 등의 버튼 조작 역시 본 발명에 의한 응시 기반 헤딩을 통해 비접촉으로 수행할 수도 있다. 이와 같이 본 발명은 기존의 시선추적을 통한 명령과는 상이한 방식으로 동작하되, 시선유지와 헤딩의 조합을 통해 사용자에 의한 명령 동작을 명확하게 구분할 수 있다. 이하에서는, 사용자가 카메라의 시야 내에서 자유롭게 움직이면서 본연의 활동을 유지하는 과정에서, 사용자의 활동에 방해가 되지 않는 최소한의 움직임을 통해 사용자가 원하는 수준의 명령을 인터랙티브하게 인식할 수 있 는 비접촉 응시 기반 헤딩 동정보를 이용한 사용자 명령 인식 기술에 대해 상세하게 설명하도록 한다. 도 2는 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 방법을 나타낸 동작 흐름도이다. 도 2를 참조하면, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 방법은 센서를 기반으로 사용자의 시선 및 헤딩 동작을 모니터링한다(S210). 예를 들어, 카메라와 같은 영상 센서 또는 움직임을 감지할 수 있는 모션 센서 등을 기반으로 사용자의 시선 및 헤딩 동작을 모니터링할 수 있다. 따라서, 센서는 사용자의 시선과 헤딩 동작을 모니터링할 수 있는 위치에 설치될 수 있다. 예를 들어, 본 발명의 구성을 차량 주행 시 적용하는 경우, 운전석에 앉은 운전자의 얼굴을 촬영할 수 있는 위 치에 카메라가 구비될 수 있다. 다른 예를 들어, 본 발명의 구성을 악기 연주 시 적용하는 경우, 악기를 연주하는 연주자의 얼굴을 촬영할 수 있도록 악보 주변에 카메라가 구비될 수도 있다. 만약, AR 글래스와 같이 사용자가 직접 착용하는 착용형 디바이스를 활용하는 경우에는 대부분의 디바이스에 장 착되어 사용자의 눈을 직접 촬영할 수 있는 카메라를 통해 사용자의 시선을 모니터링 할 수 있다. 이 때, 디바 이스에 장착된 자이로센서와 같이 직접적인 사용자의 헤드포즈 움직임 정보를 수신할 수 있는 센서를 사용하거 나, inside-out 방식으로 디바이스에 장착되어 외부를 볼 수 있는 한대 혹은 여러 대의 카메라를 통해 SLAM 방 식으로 얻어지는 디바이스의 헤드포즈 정보를 이용하여 사용자의 헤딩 정보를 수신할 수 있다. 또한, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 방법은 시선 및 헤딩 동작을 조합한 응시 기반 헤딩 정보를 기반으로 시선에 상응하는 위치에 사용자 인터페이스를 출력한다(S220). 이 때, 사용자 인터페이스가 출력되는 위치는 디스플레이 영역 내에서 시선이 고정되는 위치에 상응하게 가변할 수 있다. 예를 들어, 도 3은 운전자가 운전 중에 사용자 인터페이스를 호출한 일 예를 나타내고 있다. 일반적으로는 운전 중에는 정면을 주시해야하지만, 우회전을 하거나 우측 차선으로 차선을 변경하는 경우에는 도 3에 도시된 것처 럼 정면이 아닌 우측을 주시하는 경우가 발생할 수 있다. 이러한 경우, 사용자의 시선이 자연스럽게 디스 플레이 영역 중 오른쪽에 위치하게 되고, 응시 기반 헤딩 정보를 기반으로 제공되는 사용자 인터페이스 는 사용자의 정면이 아닌 오른쪽에 출력될 수 있다. 즉, 사용자가 사용자 인터페이스를 호출하기 위 해서 다시 정면을 주시하거나 하는 행동을 하지 않아도, 현재 시선을 두고 있는 위치에 사용자 인터페이스 를 출력함으로써 사용자의 시선이 현재 목적에 맞지 않게 이동해야하는 불편함을 감소시킬 수 있다. 다른 예를 들어, 도 4 내지 도 5는 HMD를 통해 보여지는 디스플레이 영역에 사용자 인터페이스 를 제공하는 일 예를 나타낸다. 이 때, HMD의 경우, 도 4에 도시된 것처럼, 직접적으로 사용자의 헤드포즈를 감지할 수 있는 움직임 센서 또는 자이로 센서를 통해 사용자의 헤딩 동작을 검출할 수 있다. 또한, HMD에 장착되어 사용자의 눈을 직 접 촬영할 수 있는 카메라를 통해 사용자의 시선을 모니터링함으로써 사용자에게 보여지는 디스플레이 영 역 중 사용자가 시선을 두고 있는 위치에 사용자 명령을 위한 사용자 인터페이스를 출력할 수 있다. 또 다른 예를 들어, 도 6은 사용자가 TV에 표시되는 콘텐츠를 시청하면서 홈 트레이닝할 때 사용자 인터페이스 를 제공하는 일 예를 나타낸다. 도 6을 참조하면, 사용자는 TV에 표시되는 콘텐츠를 따라 홈 트레이닝을 수행하면서 사용자 명령을 입력하기 위 해 디스플레이 영역 중 한 곳을 응시하면서 응시 기반 헤딩 동작을 수행할 수 있다. 이 때, TV에 구비된 카메라를 통해 응시 기반 헤딩 동작이 감지되면, 디스플레이 영역 중 사용자의 시선이 위치하는 곳에 사용자 인터페이스를 제공할 수 있다. 이 때, 출력되는 사용자 인터페이스는 사용자의 시선 에 따라 사용자가 시청하고 있는 콘텐츠와 오버레이되어 표시될 수 있다. 이 때, 응시 기반 헤딩 정보는 시선이 고정된 상태에서 인식되는 헤딩 동작에 상응할 수 있으며, 이러한 응시 기반 헤딩 정보가 감지되는지 여부를 고려하여 사용자 인터페이스의 호출 여부를 판단할 수 있다. 예를 들어, 사용자에 상응하게 기등록된 응시 기반 헤딩 정보가 인식되는 경우, 사용자가 시스템으로 사용자 명 령을 전달하기 위한 모션을 취한 것으로 판단하고 사용자 인터페이스를 호출하여 보여줄 수 있다. 만약, 사용자의 시선과 헤딩 동작이 감지되었더라도, 사용자의 시선이 어느 한 점에 고정되지 않은 경우에는 응 시 기반 헤딩 정보로 인식되지 않아 사용자 인터페이스가 출력되지 않을 수 있다. 즉, 본 발명에서 시선은, 디스플레이 영역에 출력되는 사용자 인터페이스의 위치를 결정하거나, 다양하게 감지 되는 사용자의 헤딩 동작으로부터 명령 시작, 명령 상태 유지 및 명령 입력 등의 유효성을 판단하기 위해 사용 될 수 있다. 따라서, 본 발명에 따르면 시선추적을 통한 사용자 명령 입력방식에서 거리나 사용자 움직임에 대한 민감성을 해소할 수 있다. 예를 들어, 사용자가 카메라에서 멀어지더라도 사용자의 시선과 헤딩 동작을 모니터링 할 수만 있다면, 사용자 활동을 방해하지 않으면서도 사용자 명령을 인식할 수 있다. 이 때, 사용자 명령 수신모드를 호출하기 위한 응시 기반 헤딩 명령을 등록하는 과정은 추후 사용자 등록 과정 에서 상세하게 설명하도록 한다. 이 때, 사용자 인터페이스는 사용자에 상응하는 고유 명령셋을 제공할 수 있다. 예를 들어, 사용자에 상응하는 고유 명령셋은, 사용자가 다양한 환경에서 자연스러운 사용자 경험(UX)을 통해 인식한 정보를 바탕으로 자신이 선호하는 형태로 커스텀하게 설정한 명령셋일 수 있다. 이렇게 사용자에 상응하 게 설정된 고유 명령셋은 마우스를 이용하거나 터치 입력을 통해 사용하는 명령셋처럼 자유도가 높은 형태로 제 공됨으로써 보다 다양한 사용자 명령을 가능하게 할 수 있다. 도 10 내지 도 14는, 사용자 명령과 방향표시자를 포함하는 고유 명령셋의 일 예를 나타낸 것으로, 이하에서는 도 10 내지 도 14를 기반으로 사용자에 의해 선택된 사용자 명령을 피드백하는 시나리오 예시를 설명하도록 한 다. 도 10 내지 도 12는 시선을 고정한 상태에서 상하좌우의 방향으로 헤딩 동작을 수행하여 사용자 명령을 선택할 수 있는 형태의 고유 명령셋을 나타낸다. 또한, 도 13 내지 도 14는 시선을 고정한 상태에서 좌측 또는 우측으로 헤딩 동작을 수행하되, 헤딩 상태로 회 전을 유지할 경우에 해당 방향에 연속적으로 배치된 번호에 상응하는 명령을 선택할 수 있는 형태의 명령셋을 나타낸다. 예를 들어, 컴퓨터를 통해 문서작업을 하는 상황과 같이 카메라와 사용자 간의 거리가 일정하게 근접하고, 광량 과 안정적 전원공급 및 연산 능력이 보장되는 경우에는 보다 정교한 헤딩방향 인지를 통해 보다 많은 수의 명령 을 동시에 표출할 수 있는 고유 명령셋을 제공하여 사용자 명령을 선택할 수 있도록 할 수 있다. 반대로, 공장이나 트레이닝 시설 등 원거리 명령이 요구되는 경우에는 좌/우 선택 등의 단순한 명령체계를 사용 하는 고유 명령셋을 제공하는 등 시스템의 운용환경에 따라 다양한 고유 명령셋을 조합하여 선택적으로 사용할 수 있다. 이 때, 도 10 내지 도 14에 도시된 것처럼, 고유 명령셋에 등록된 명령 중 현재 선택된 명령이 무엇인지를 사용 자가 알 수 있도록 강조되게 표시하여 보여줄 수 있다. 이 때, 도 10 내지 도 14에 도시한 고유 명령셋은 설명을 위한 일실시예에 해당하는 것으로 도시된 형태에 한정 되지 않고, 다양하게 설정될 수 있다. 이 때, 사용자가 시선을 고정한 상태에서도 고유 명령셋의 구성을 쉽게 파악할 수 있도록, 시선이 위치하는 응 시점이 고유 명령셋의 중심이 되도록 사용자 인터페이스를 출력할 수 있다. 또한, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 방법은 사용자 인터 페이스에서 선택된 사용자 명령을 인식한다(S230). 예를 들어, 사용자 인터페이스를 통해 고유 명령셋이 표출된 상태에서 사용자로부터 감지되는 응시 기반 헤딩 정보에 상응하게 사용자 인터페이스를 제어하여 사용자 명령을 선택할 수 있다. 즉, 응시 기반 헤딩 정보는 시 선이 고정된 상태에서 헤딩 동작에 의해 입력되는 방향 정보에 해당하기 때문에 시선이 위치하는 응시점을 기준 으로 헤딩 동작에 의해 입력되는 방향 정보에 위치하는 명령을 선택할 수 있다. 예를 들어, 헤딩 동작에 의해 입력되는 방향 정보는 적게는 2방향에서 최대 8방향으로 분류될 수 있다. 이렇게 분류되는 방향 정보는 사용자의 기호에 따라 설정되거나 또는 시스템이 적용되는 환경을 고려하여 설정 및 변경이 가능하다. 이 때, 사용자에 상응하는 헤딩 특성을 고려하여 응시 기반 헤딩 정보를 감지할 수 있다. 이 때, 헤딩 특성은 머리 회전 각도, 머리 회전 속도, 머리 회전 유지 시간, 머리 회전 복귀 시간 및 머리 회전 에 따른 동공의 위치와 모양 중 적어도 하나를 포함할 수 있다. 즉, 동일한 헤딩 동작도 사람마다 다른 움직임을 보일 수 있으므로, 사용자들 각각의 헤딩 특성을 사전에 등록 해두었다가 응시 기반 헤딩 정보에 의해 선택되는 사용자 명령을 인식할 때 사용할 수 있다. 예를 들어, 고유 명령셋에 표시되는 복수개의 명령들 중 헤딩 특성을 고려하여 인식된 응시 기반 헤딩 정보의 방향에 위치하는 사용자 명령을 선택할 수 있다. 만약, 고유 명령셋이 도 10과 같은 형태라고 가정하면, 헤딩 특성을 고려하여 인식된 응시 기반 헤딩 정보의 방 향이 오른쪽인지 왼쪽인지를 인식하고, 인식된 방향에 위치하는 사용자 명령을 선택할 수 있다. 다른 예를 들어, 고유 명령셋이 도 11 내지 도 12와 같은 형태라고 가정하면, 헤딩 특성을 고려하여 인식된 응 시 기반 헤딩 정보의 방향이 위, 아래, 좌, 우 중 어느 방향인지를 인식하고, 인식된 방향에 위치하는 사용자 명령을 선택할 수 있다. 또 다른 예를 들어, 고유 명령셋이 도 13과 같은 형태라고 가정하면, 헤딩 특성을 고려하여 인식된 응시 기반 헤딩 정보의 방향이 오른쪽인지 왼쪽인지를 먼저 파악한 후 헤딩 방향으로 머리 회전이 유지되는 시간을 고려하 여 연속적으로 배치된 번호들 중 하나의 번호에 상응하게 사용자 명령을 선택할 수 있다. 즉, 도 13에 도시되 고유 명령셋에서 1번에 해당하는 사용자 명령을 선택하려는 경우에는 왼쪽으로 헤딩 동작을 수행하여 1번이 선택될 때까지 헤딩 상태를 유지할 수 있다. 이 후, 1번이 선택되면 헤딩 동작을 멈추고 얼굴을정면으로 복귀시킴으로써 최종적으로 1번에 해당하는 사용자 명령을 선택할 수 있다. 도 13과 유사한 방식으로 도 14에 도시된 고유 명령셋을 이용하여 사용자 명령을 선택할 수도 있다. 즉, 응시 기반 헤딩 정보의 방향이 오른쪽인지 왼쪽인지를 먼저 인식하고, 인식된 방향으로 헤딩 상태가 유지됨에 따라 번호들이 회전하면서 선택 대상이 변경될 수 있다. 이 때, 사용자가 헤딩 동작을 멈추고 얼굴을 정면으로 복귀 시킨 시점에 선택된 번호의 사용자 명령을 선택할 수 있다. 또한, 도 2에는 도시하지 아니하였으나, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용 자 명령 인식 방법은 모니터링 중인 사용자가 등록된 사용자인지 여부를 식별할 수 있다. 만약, 사용자가 시스템으로 사용자 명령을 전달할 있는 등록된 사용자인 경우, 헤딩 특성 별 명령 처리 기준을 바탕으로 사용자 명령의 수행 유무를 결정할 수 있다. 예를 들어, 본 발명의 일실시예에 따른 사용자 명령 인식 과정은, 도 15에 도시된 것처럼 오프라인 프로세스와 온라인 프로세스로 구성될 수 있는데, 도 2에 도시된 단계들은 온라인 프로세스의 단계(S1508)에 해당할 수 있 다. 이 때, 단계(S1508)은 상술한 여러 예시들과 같이 사용자에 의해 활성화되어 수행될 수 있으며, 경우에 따라서 는 시스템이 사용자에게 특정 판단을 요청하는 경우에 활성화될 수도 있다. 시스템에 의해 활성화되는 경우, EXTERNAL TRIGGER INFO를 입력으로 받을 수 있다. 예를 들어, 자율주행 시스템의 자율주행 레벨이 3 이상이면, 운전자는 더 이상 직접 운전할 필요가 없다. 하지 만, 자율주행 시스템이 판단하기 모호한 도로상황에 대해서는 시스템이 운전자의 개입이나 판단을 요구할 수 있 다. 만약, 운전자가 즉시 수동운전으로 전환이 어려운 상황이라면, 본 발명의 일실시예에 따른 사용자 명령 인 식 방법을 적용할 수 있다. 긴급상황이 발생한 경우, 시스템은 HUD와 사운드를 등을 통해 사용자를 호출할 수 있으며, 사용자가 판단해 주 기를 원하는 상황을 HUD에 실시간 표출할 수 있다. 이 경우, 사용자는 시스템의 요청 상황을 판단한 후, 운전자 세가 아닌 (혹은 즉시 운전자세로 복귀가 어려운) 상태에서도 GUI 창에 표시된 고유 명령셋에 기반한 응시 기반 헤딩 명령을 통해 사용자 명령을 전달할 수 있다. 이 때, 시스템은 차량의 주운전자를 식별하고, 식별된 운전자의 명령을 우선하여 입력받을 수 있다. 이러한 시 나리오는 자율주행 기능이 미완성인 상태로, 자율주행 레벨이 3 이상인 차량에서의 사고발생을 방지하거나, 사 고발생 시 시스템의 잘못과 사용자 과실 유무를 판단할 수 있는 블랙박스의 역할도 수행할 수 있다. 또한, 도 2에는 도시하지 아니하였으나, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용 자 명령 인식 방법은 사용자에 상응하는 복수의 응시 기반 헤딩 동작들을 획득하고, 복수의 응시 기반 헤딩 동 작들을 기반으로 추출된 헤딩 특성을 사용자 식별정보와 매칭하여 사용자를 등록한다. 예를 들어, 사용자 등록 과정은 도 15에 도시된 오프라인 프로세스의 단계(S1502)에 해당할 수 있다. 즉, 신규 사용자(NEW USER)는 도 15에 도시된 단계(S1502)를 통해 사용자 등록을 진행할 수 있는데, 이 과정에서 사용자의 헤딩 특성을 등록하는 과정이 동시에 진행될 수 있다. 이 때, 사용자를 식별하기 위한 사용자 식별정보와 헤딩 특성을 사용자 ID 별로 데이터베이스에 등록할 수 있으며, 온라인 프로세스 수행 시 데이터베이스에 등록된 데이터를 호출하여 사용할 수 있다. 이 때, 사용자 등록을 위한 사용자 인식, 헤드 모션 또는 헤딩 포즈 검출, 시선 검출 등의 기술은 컴퓨터 비전 및 인공지능 분야의 종래 기술을 통해 다양하게 구현될 수 있다. 도 7 내지 도 8을 참조하여, 사용자 등록 과정을 설명하면 다음과 같다. 먼저, 사용자는 디스플레이 영역에 표출되는 응시점에 시선 을 둔 상태에서 상하좌우의 헤 딩 방향(742~745)으로 헤딩 동작을 수행할 수 있다. 이 때, 카메라를 통해 사용자의 헤딩 동작 을 촬영하여 도 8에 도시된 것과 같은 헤딩 방향 별 얼굴영상(801~805)을 획득하고, 이를 기반으로 사용자 등록 과 사용자 별 헤딩 특성의 보정을 수행할 수 있다. 이 때, 복수의 응시 기반 헤딩 동작들을 유도하기 위한 동작 유도 메시지를 출력할 수 있다. 이 때, 동작 유도 메시지를 통해 의도한 제1 움직임 및 복수의 응시 기반 헤딩 동작들에 상응하는 제2 움직임 간의 차이를 고려하여 헤딩 특성을 보정할 수 있다. 예를 들어, 도 7에 도시된 사용자 인터페이스에 표출되는 응시점과 헤딩방향(742~745)을 랜덤하게 제 시하는 방식으로 동작 유도 메시지를 출력할 수 있다. 만약, 오른쪽 방향으로 헤딩 후 복귀하라는 동작 유도 메 시지를 출력한 경우, 사용자가 오른쪽 방향으로 헤딩 동작을 수행하는 동안에 머리 회전 각도, 머리 회전 속도, 머리 회전 유지 시간, 머리 회전 복귀 시간 및 머리 회전에 따른 동공의 위치와 모양 등을 획득하고, 이를 기반 으로 오른쪽 방향 헤딩 동작에 대해 사용자 고유의 헤딩 특성을 보정할 수 있다. 이 때, 복수의 응시 기반 헤딩 동작들을 유도하기 위한 시선 응시점의 위치를 이동시키면서 헤딩 특성을 보정할 수 있다. 즉, 시스템이 사용자 명령을 받는 응시 기반 헤딩 명령의 특성이나 시나리오를 고려하여 동작 유도 메시지를 통 해 사용자에게 요구하는 동작이 다양화될 수 있다. 예를 들어, 디스플레이 영역이 넓은 경우, 디스플레이 영역에서 시선 응시점의 위치를 이동시키면서 응시 기반 헤딩 동작들을 획득하고, 이를 기반으로 헤딩 특성을 보정할 수 있다. 또한, 도 2에는 도시하지 아니하였으나, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용 자 명령 인식 방법은 사용자 인터페이스를 호출하기 위한 응시 기반 헤딩 명령, 고유 명령셋에서 사용자 명령을 선택하기 위한 응시 기반 헤딩 명령 및 고유 명령셋에서 선택된 사용자 명령의 실행 승인을 위한 응시 기반 헤 딩 명령 등을 포함하는 응시 기반 헤딩 명령을 등록할 수 있다. 예를 들어, 응시 기반 헤딩 명령을 등록하는 과정은 도 15에 도시된 오프라인 프로세스 중 단계(S1504)에 해당 할 수 있다. 이 때, 사용자 인터페이스를 호출하기 위한 응시 기반 헤딩 명령은, 시스템에게 사용자 명령을 수신할 수 있는 모드로의 전환을 지시하는 명령에 상응하는 것으로, 사용자의 요구나 시스템 적용 환경에 따라 다양하거나 또는 간소하게 구성될 수 있다. 예를 들어, 운전자 A가 운전 중 고개를 위로 드는 상황이 별로 없다면, 운전 중 시선이 고정된 상태에서 위쪽으 로 헤딩 동작을 수행하는 행동을 사용자 인터페이스를 호출하기 위한 응시 기반 헤딩 명령으로 등록할 수 있다. 다른 예를 들어, 운전자 B에 대해서는, 운전 중 시선이 고정된 상태에서 고개를 상하로 끄덕이는 헤딩 동작을 수행하는 행동을 사용자 인터페이스를 호출하기 위한 응시 기반 헤딩 명령으로 등록할 수도 있다. 즉, 사용자가 평소에 자주 취하지 않는 동작을 사용자 인터페이스를 호출하기 위한 응시 기반 헤딩 명령으로 등 록함으로써 시스템이 사용자 인터페이스를 호출하기 위한 명령과 의미없는 동작을 효과적으로 구별할 수 있도록 할 수 있다. 또한, 고유 명령셋에서 사용자 명령을 선택하기 위한 응시 기반 헤딩 명령을 등록할 수 있다. 예를 들어, 고유 명령셋이 도 10과 같은 형태라고 가정할 수 있다. 이 때, 사용자의 시선이 고유 명령셋의 중심 을 응시한 상태에서 오른쪽이나 왼쪽으로 헤딩한 후 복귀하는 경우, 헤딩 방향에 위치하는 명령이 선택되도록 응시 기반 헤딩 명령을 등록할 수 있다. 또한, 고유 명령셋에서 선택된 사용자 명령의 실행 승인을 위한 응시 기반 헤딩 명령을 등록함으로써 사용자로 부터 명령 실행을 위한 최종 승인을 받을 수 있다. 즉, 시스템은 사용자를 통해 선택된 사용자 명령을 사용자에게 한번 더 확인받고 실행할 수 있다. 예를 들어, 도 10에 도시된 것처럼 Command A에 해당하는 사용자 명령이 인식된 상태에서, 사용자가 시선을 유 지한 채로 고개를 끄덕거리는 헤딩 동작을 수행한다면 Command A 실행을 위한 최종 승인이 완료된 것으로 판단 하고 Command A를 실행할 수 있다. 이 때, 사용자 명령의 종류에 따라 최종 승인 절차 없이 바로 사용자 명령을 실행할 수도 있다. 예를 들어, 공장 및 현장 등의 환경에서 긴급성을 요구하는 사용자 명령의 경우, 사용자 명령이 인식됨과 동시 에 명령을 실행할 수도 있다. 즉, 공장 근로자 C가 시스템의 긴급 멈춤 명령을 위한 사용자 인터페이스를 호출 하고, 카메라를 응시한 채로 좌우로 헤딩하는 동작만을 수행함으로써 최종 승인 절차를 생략하고 긴급 멈춤 명 령이 실행될 수 있도록 설정할 수 있다. 이 때, 시스템은 공장 근로자 C가 긴급 멈춤 명령을 실행할 자격이 있는지를 여부를 판단한 후 자격이 있는 사용자일 경우에 긴급 멈춤 명령을 수행할 수 있다. 이와 같은 응시 기반 헤딩 명령은 사용자의 선호도 또는 시스템 운영 환경을 고려한 형태로 설정되어 등록될 수 있으며, 상기에서 제시된 예시에 한정되지 않는다. 이렇게 등록된 응시 기반 헤딩 명령들은 사용자 ID 별로 저장될 수 있으며, 도 15에 도시된 온라인 프로세스 수 행 시 호출되어 사용될 수 있다. 또한, 도 2에는 도시하지 아니하였으나, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용 자 명령 인식 방법은 카메라를 통해 실시간으로 사용자의 신원확인 정보를 획득하고, 데이터베이스에 기등록된 사용자 정보와 신원확인 정보를 비교하여 사용자를 식별하고, 식별된 사용자가 실제 사용자인지 라이브니스 (LIVENESS)를 확인할 수 있다. 예를 들어, 본 발명의 구성이 적용된 운전 주행 시스템의 경우, 운전석에 앉은 사용자 A가 본 발명에 따른 사용 자 명령 인식 시스템을 통해 운전할 수 있는 권한을 가진 사용자 A가 맞는지 확인하는 절차를 진행할 수 있다. 이 때, 도 15에 도시된 DB에 등록된 사용자 정보와 카메라를 통해 실시간으로 입력되는 사용자의 신원확 인 정보를 대조하여 사용자 A를 식별할 수 있다. 이 때, 사용자의 라이브니스(Liveness)를 확인할 수 있다. 즉, 카메라를 통해 입력된 사용자 영상이 사진이나 동영상 혹은 또 다른 Fake 기술을 통해 입력된 영상이 아니라 실시간으로 실제 사용자를 촬영하여 생성된 사용 자 영상인지 여부를 확인할 수 있다. 예를 들어, 본 발명의 구성이 적용된 운전 주행 시스템의 경우, HUD를 기반으로 표출되는 GUI를 통해 사용자에 게 임의의 방향에 대한 명령선택을 일정 시간 내에 수행하도록 요청하는 방식으로 사용자의 라이브니스를 확인 할 수 있다. 보다 높은 수준의 사용자 식별 또는 확인이 필요한 경우, 사용자 등록 과정에서 사용자에 상응하게 등록된 헤딩 특성을 대조하여 사용자 및 사용자의 라이브니스를 확인할 수도 있다. 이 때, 사용자가 사전에 등록된 사용자이고, 라이브니스도 확인되면, 사용자로부터 사용자 명령을 인식할 수 있 도록 사용자에 상응하게 기등록된 데이터를 불러올 수 있다. 예를 들어, 도 15에 도시된 단계(S1506)이 완료되면, 단계(S1508)에서 사용자 명령 인식 과정(S1508)을 수행할 수 있도록 데이터베이스에서 사용자에 상응하게 기등록된 데이터를 검색하여 시스템에 로딩할 수 있다. 이 때, 사용자에 상응하게 기등록된 데이터는, 도 15에 도시된 단계(S1504)를 통해 등록된 응시 기반 헤딩 명령 에 관한 정보일 수 있다. 이와 같은 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 방법을 이용함으로써 사용자의 본연의 목적 을 위한 몸의 사용이나 전방주시 요구 등의 상황을 방해하지 않으면서도, 사용자의 시선이 머무는 곳에 사용자 명령을 입력하기 위한 인터페이스를 출력함으로써 시스템에게 사용자 명령을 전달할 수 있다. 또한, 최소한의 움직임으로 실시간 사용자 명령을 인터랙티브하게 시스템에 전달할 수 있다. 또한, 종래의 사용자 명령 전달 체계를 대체하거나 보완 혹은 보조하는 방식으로, 사용자의 얼굴영상을 분석하 는 인공지능(AI)을 통해 사용자가 시스템에 실시간 명령을 전달할 필요가 있는 다양한 분야에 활용하기 위한 기 술을 제공할 수 있다. 또한, 접촉기반 입력이나 비접촉 기반 입력이 사용되는 다양한 환경에서 자연스러운 사용자 경험(UX)을 통해 인 식되는 다양한 사용자 명령을 인터랙티브하게 시스템에 전달할 수 있다. 도 9는 본 발명의 일실시예에 따른 사용자 명령 인식 과정 중 응시 기반 헤딩 명령을 처리하는 과정을 상세하게 나타낸 동작 흐름도이다. 도 9를 참조하면, 사용자 명령 인식 과정 중 응시 기반 헤딩 명령을 처리하는 과정은 먼저 사용자가 오프라인 프로세스를 통해 등록한 고유 명령셋을 DB로부터 입력 받아 카메라를 통해 촬영된 영상 상의 사용자 ID와 시선 및 헤딩 동작을 동시에 모니터링 할 수 있다(S910). 이 후, 모니터링 결과를 기반으로 DB에 저장된 사용자가 DB에 사전 등록된 응시 기반 헤딩 명령을 통 해 사용자 인터페이스를 호출했는지 여부를 판단할 수 있다(S915). 단계(S915)의 판단결과 사용자 인터페이스를 호출했으면, 사용자가 사전에 정의한 최상위 명령셋을 디스플레이 할 수 있다(S920). 예를 들어, HUD와 같은 디스플레이 장치 상에서 사용자의 시선 위치를 중심으로 사용자 인터페이스에 포함된 고 유 명령셋을 디스플레이할 수 있다. 이와 동시에, 시스템은 사용자가 GUI로 표출된 고유 명령셋에 포함된 명령들 중 어떤 명령의 방향으로 응시 기 반 헤딩 명령을 수행했는지 모니터링 할 수 있다(S930). 이 때, 사용자의 응시 기반 헤딩 명령을 수행할 때에 어떤 헤딩 특성을 보였는지 모니터링 할 수 있다. 이 후, 고유 명령셋에서 응시 기반 헤딩 정보에 상응하는 방향으로 매칭되는 사용자 명령을 인식하여 명령을 수 행할 수 있다(S940). 이 때, 모니터링된 사용자의 헤딩 특성과 사전 정의된 헤딩 특성 별 명령 처리 기준을 바탕으로 인식된 사용자 명령의 수행유무를 판단할 수 있다. 이 때, 사용자가 해당 명령을 수행할 수 있는 사용자인지 유무를 함께 판단할 수 있다. 이 후, 인식된 사용자 명령이 하부 명령셋을 포함하고 있고, 사용자가 초기 응시점을 계속 응시하고 있는지 여 부를 판단하고(S945), 사용자가 초기 응시점을 계속 응시하고 있으면 하부 명령셋을 디스플레이한 뒤 단계 (S920) 및 단계(S930)을 활성화하여 실행할 수 있다. 만약, 단계(S945)의 판단결과 사용자가 더 이상 초기 응시점을 응시하고 있지 않으면, 고유 명령셋의 디스플레 이를 중지하고 단계(S910)을 통해 모니터링을 수행할 수 있다. 또한, 단계(S915)의 판단결과 사용자 인터페이스를 호출하지 않았으면, 단계(S910)으로 돌아가 지속적으로 사용 자 인터페이스가 호출되었는지 여부를 판단할 수 있다. 상기와 같은 플로우를 통해 상시로 사용자의 시선과 헤딩 동작을 모니터링 할 수 있으며, 사용자에 의한 응시 기반 헤딩 명령을 인터랙티브하게 실시간 수신하여 처리할 수 있다. 도 16은 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치를 나타낸 도 면이다. 도 16을 참조하면, 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치는 도 16에 도시된 것과 같이 컴퓨터로 읽을 수 있는 기록매체와 같은 컴퓨터 시스템에 상응하게 구현될 수 있다. 도 16에 도시된 바와 같이, 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서 , 메모리, 사용자 입력 장치, 사용자 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있 다. 프로세서는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로세싱 인스트럭션들을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 다양한 형태의 휘발성 또는 비휘발성 저 장 매체일 수 있다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 따라서, 본 발명의 실시예는 컴퓨터로 구현된 방법이나 컴퓨터에서 실행 가능한 명령어들이 기록된 비일시적인 컴퓨터에서 읽을 수 있는 매체로 구현될 수 있다. 컴퓨터에서 읽을 수 있는 명령어들이 프로세서에 의해서 수 행될 때, 컴퓨터에서 읽을 수 있는 명령어들은 본 발명의 적어도 한 가지 측면에 따른 방법을 수행할 수 있다. 이하에서는 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치 관점에서 상세하게 설명하도록 한다. 프로세서는 센서를 기반으로 사용자의 시선 및 헤딩 동작을 모니터링한다. 이 때, 사용자에 상응하는 헤딩 특성을 고려하여 응시 기반 헤딩 정보를 감지할 수 있다. 이 때, 응시 기반 헤딩 정보는 시선이 고정된 상태에서 헤딩 동작에 의해 입력되는 방향 정보에 상응할 수 있다. 이 때, 헤딩 특성은 머리 회전 각도, 머리 회전 속도, 머리 회전 유지 시간, 머리 회전 복귀 시간 및 머리 회전 에 따른 동공의 위치와 모양 중 적어도 하나를 포함할 수 있다. 또한, 프로세서는 시선 및 헤딩 동작을 조합한 응시 기반 헤딩 정보를 기반으로 시선에 상응하는 위치에 사용자 인터페이스를 출력한다. 이 때, 사용자 인터페이스가 출력되는 위치는 디스플레이 영역 내에서 시선이 고정되는 위치에 상응하게 가변할 수 있다. 이 때, 사용자 인터페이스는 사용자에 상응하는 고유 명령셋을 제공할 수 있다. 또한, 프로세서는 사용자 인터페이스에서 선택된 사용자 명령을 인식한다. 또한, 프로세서는 사용자에 상응하는 복수의 응시 기반 헤딩 동작들을 획득하고, 복수의 응시 기반 헤딩 동작들을 기반으로 추출된 헤딩 특성을 사용자 식별정보와 매칭하여 사용자를 등록한다. 이 때, 복수의 응시 기반 헤딩 동작들을 유도하기 위한 동작 유도 메시지를 출력할 수 있다. 이 때, 동작 유도 메시지를 통해 의도한 제1 움직임 및 복수의 응시 기반 헤딩 동작들에 상응하는 제2 움직임 간의 차이를 고려하여 헤딩 특성을 보정할 수 있다. 이 때, 복수의 응시 기반 헤딩 동작들을 유도하기 위한 시선 응시점의 위치를 이동시키면서 헤딩 특성을 보정할 수 있다. 메모리는 사용자 인터페이스를 저장한다. 또한, 메모리는 상술한 바와 같이 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용 자 명령 인식 과정에서 발생하는 다양한 정보를 저장한다. 실시예에 따라, 메모리는 도 16과 같은 컴퓨터 시스템에 상응하는 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치와 독립적으로 구성되어 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식을 위한 기능을 지원할 수 있다. 이 때, 메모리는 별도의 대용량 스토리지로 동작할 수 있고, 동작 수행을 위한 제어 기능을 포함할 수도 있다. 한편, 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치는 메모리가 탑재되어 그 장치 내에서 정보 를 저장할 수 있다. 일 구현예의 경우, 메모리는 컴퓨터로 판독 가능한 매체이다. 일 구현 예에서, 메모리는 휘 발성 메모리 유닛일 수 있으며, 다른 구현예의 경우, 메모리는 비휘발성 메모리 유닛일 수도 있다. 일 구현예의 경우, 저장장치는 컴퓨터로 판독 가능한 매체이다. 다양한 서로 다른 구현 예에서, 저장장치는 예컨대 하드디스 크 장치, 광학디스크 장치, 혹은 어떤 다른 대용량 저장장치를 포함할 수도 있다. 이와 같은 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치를 통해 사용자의 본연의 목적을 위한 몸의 사용이나 전방주시 요구 등의 상황을 방해하지 않으면서도, 사용자의 시선이 머무는 곳에 사용자 명령을 입력하기 위한 인터페이스를 출력함으로써 시스템에게 사용자 명령을 전달할 수 있다. 또한, 최소한의 움직임으로 실시간 사용자 명령을 인터랙티브하게 시스템에 전달할 수 있다. 또한, 종래의 사용자 명령 전달 체계를 대체하거나 보완 혹은 보조하는 방식으로, 사용자의 얼굴영상을 분석하 는 인공지능(AI)을 통해 사용자가 시스템에 실시간 명령을 전달할 필요가 있는 다양한 분야에 활용하기 위한 기 술을 제공할 수 있다. 또한, 접촉기반 입력이나 비접촉 기반 입력이 사용되는 다양한 환경에서 자연스러운 사용자 경험(UX)을 통해 인 식되는 다양한 사용자 명령을 인터랙티브하게 시스템에 전달할 수 있다. 이상에서와 같이 본 발명에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치 및 이를 이용한 방법은 상기한 바와 같이 설명된 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시예 들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있 다. 부호의 설명100, 700: 사용자 101, 310, 410, 610, 710: 시선 102, 711: 헤딩 동작 120, 630, 720: 카메라 130, 320, 420, 620, 730: 디스플레이 영역 131, 321, 421, 621, 740: 사용자 인터페이스 400: HMD 741: 응시점 742~745: 헤딩 방향 1600: 컴퓨터 시스템 1610: 프로세서 1620: 버스 1630: 메모리 1631: 롬 1632: 램 1640: 사용자 입력 장치 1650: 사용자 출력 장치 1660: 스토리지 1670: 네트워크 인터페이스 1680: 네트워크"}
{"patent_id": "10-2021-0120094", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 시스템을 나타낸 도 면이다. 도 2는 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 방법을 나타낸 동작 흐름도이다. 도 3 내지 도 6은 본 발명에 따라 사용자 인터페이스가 출력되는 일 예를 나타낸 도면이다. 도 7 내지 도 8은 본 발명에 따른 사용자 등록 과정의 일 예를 나타낸 도면이다. 도 9는 본 발명의 일실시예에 따른 사용자 명령 인식 과정 중 응시 기반 헤딩 명령을 처리하는 과정을 상세하게 나타낸 동작 흐름도이다. 도 10 내지 도 14는 본 발명에 따른 고유 명령셋의 일 예를 나타낸 도면이다. 도 15는 본 발명에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 시스템 구조의 일실시예를 나 타낸 도면이다. 도 16은 본 발명의 일실시예에 따른 비접촉 응시 기반 헤딩 정보를 이용한 사용자 명령 인식 장치를 나타낸 도 면이다."}
