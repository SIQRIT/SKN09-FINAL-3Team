{"patent_id": "10-2024-0114877", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0038601", "출원번호": "10-2024-0114877", "발명의 명칭": "사후 신뢰도를 정량화하는 방법", "출원인": "수퍼소닉 이매진", "발명자": "창, 보"}}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터-구현 방법에 있어서,혼합 모델을 사용하여 입력 데이터 샘플 세트에 대한 인공 지능(AI) 모델의 계층의 출력의 사후 신뢰도를 정량화하는 단계,클래스 분포에 추정된 사전 유병률을 제공하는 단계, 및 상기 사전 유병률에 기초하여 정량화된 사후 신뢰도를 교정하는 단계를 포함하고, 상기 AI 모델은, 분류기 모델인, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 계층은, 상기 모델의 숨겨진 계층, 상기 모델의 중간 계층, 상기 모델의 출력 계층 이외의 계층, 및 상기 모델의 출력 계층에 앞서는 계층중 적어도 하나인, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 정량화된 사후 신뢰도를 상기 모델의 출력 계층으로 사용하는 단계, 및/또는 상기 정량화된 사후 신뢰도를 사용하여 입력 데이터 샘플의 클래스 확률을 예측하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,정량화된 사후 신뢰도 함수는, 상기 혼합 모델을 사용하여 입력 데이터 샘플 세트에 대한 상기 모델의 계층의 출력의 사후 신뢰도를 정량화하공개특허 10-2025-0038601-3-여 획득되고, 및/또는 상기 정량화된 사후 신뢰도는, 정량화된 사후 신뢰도 함수인, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 사전 유병률은, 입력 데이터 샘플 세트와 연관된 지리적 지역 및/또는 인구 집단의 함수로 결정되는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 정량화된 사후 신뢰도는, 교정되고, 모델 판별력은, 선택적으로 반복 프로세서에서 최적화되고, 상기 정량화된 사후 신뢰도를 교정하는 단계는, 상기 반복 프로세스의 이전 반복에서 예측된 클래스 확률 및 교정된 확률 사이의 거리를 최소화하는 단계를 포함하고, 및/또는 상기 모델 판별력을 최적화하는 단계는, 서로 다른 클래스에서 비롯된 데이터 분포 쌍 사이의 거리를 최대화하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 베이지안 규칙은, 상기 정량화된 사후 신뢰도 및/또는 상기 입력 데이터 샘플의 상기 클래스 확률을 교정하는 데 사용되고, 및/또는 상기 혼합 모델은, 확률적 혼합 모델 및/또는 가우스 혼합 모델인, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2025-0038601-4-제1항에 있어서,상기 계층의 상기 사후 신뢰도를 정량화하는 단계는, 상기 계층의 상기 출력의 확률 분포를 정량화하는 단계, 및/또는 상기 모델의 가능한 각 출력 클래스에 대한 상기 계층의 상기 출력의 평균 및 공분산 통계를 기록하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 모델은, 머신 러닝 모델과 신경망 중 적어도 하나이고, 및/또는 상기 모델은, 적어도 하나의 숨겨진 계층과 출력 계층을 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 모델은, 분류 작업을 수행하도록 구성된 초기 출력 계층을 포함하는 제1 초기 모델이고, 및/또는 상기 초기 출력 계층은, K-클래스 소프트맥스 규칙을 수행하도록 구성되며, K는, 최소 둘(2)인, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 제1 초기 모델의 상기 초기 출력 계층을 상기 정량화된 사후 신뢰도로 대체하여 제1 수정 모델을 획득하는단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "입력 샘플의 클래스 확률을 예측하는 컴퓨터-구현 방법에 있어서,공개특허 10-2025-0038601-5-제11항에 따른 상기 제1 수정 모델을 사용하여 상기 입력 샘플에 대한 클래스 확률을 예측하는 단계를 포함하고, 선택적으로 상기 방법은, 상기 입력 샘플의 함수로 사전 유병률을 선택하는 단계, 제11항에 따른 상기 제1 수정 모델을 사용하여 상기 사전 유병률에 기초하여 상기 입력 샘플에 대한 교정된 클래스 확률을 예측하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "인공 지능(AI) 알고리즘을 위한 훈련 레이블을 생성하는 방법에 있어서,클래스 확률 세트를 획득하기 위해 제1항 내지 제12항 중 어느 한 항의 방법을 상기 입력 데이터 샘플에 적용하는 단계, 상기 클래스 확률 세트에 기초하여 상기 훈련 레이블을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "인공 지능(AI) 모델을 훈련하는 방법에 있어서,훈련 레이블을 생성하기 위해 제13항의 방법을 수행하는 단계, 상기 훈련 레이블을 사용하여 감독된 방식으로 제1 초기 인공 지능(AI) 모델을 훈련시키는 단계를 포함하고, 상기 방법은, 선택적으로, 훈련된 제1 인공 지능(AI) 모델의 마지막 계층을 상기 정량화된 사후 신뢰도로 대체하여 제2 인공 지능(AI) 모델을 획득하는 단계, 입력 데이터 샘플 세트에 대한 예측 클래스 확률을 획득하기 위해 상기 제2 인공 지능(AI) 모델을 실행하는 단계, 상기 입력 데이터 샘플 세트에 상기 예측 클래스 확률로 다시 레이블링하는 단계, 다시 레이블링된 입력 데이터 샘플 세트를 기반으로 제3 인공 지능(AI) 모델을 훈련시키는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-0114877", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨팅 장치에 있어서,하나 이상의 프로세서, 및 컴퓨터-실행 명령들을 저장하는 적어도 하나의 메모리공개특허 10-2025-0038601-6-를 포함하고, 상기 컴퓨터-실행 명령들이, 상기 프로세서에 의해 실행될 때, 상기 컴퓨팅 장치로 하여금, 제1항 내지 12항 중 어느 하나에 따른 방법을 수행하게 하는, 컴퓨팅 장치."}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 컴퓨터-구현 방법에 관한 것으로, 이 방법은: 혼합 모델을 사용하여 입력 데이터 샘플 세트에 대한 인 공 지능(AI) 모델의 계층의 출력에 대한 사후 신뢰도를 정량화하는 단계 - AI 모델은 분류기 모델이며, 클래스 분포에 대해 추정된 사전 유병률을 미리 제공함 -, 및 사전 유병률에 기초하여 정량화된 사후 신뢰도를 교정하는 단계를 포함한다."}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사후 신뢰도를 정량화하는 방법에 관한 것이다."}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(artificial intelligence)(AI)은 학습(learning) 및 문제 해결(problem-solving)과 같이 일반적으로 인간의 지능과 연관된 작업들(tasks)을 수행하는 기계의 능력이다. AI 알고리즘이나 모델은, 예를 들어 컴퓨터 비전 분야에서 다양하게 활용될 수 있다. 좀 더 구체적인 예로 의료 이미징 분야(medical imaging)의 이미지 인식(image recognition) 또는 분류(classification)를 들 수 있다. 예를 들어, AI 모델은 유방 병변 악성 확률(breast lesion malignancy probability), 바이라즈(BI-RADS)(유방 이미징 보고 및 데이터 시스템(Breast Imaging Reporting and Data System)) 병변 분류 확률(lesion classification probability), 간 병변 분류 확률(liver lesion classification probability), 갑상선의 TI- RADS(갑상선 이미징 보고 및 데이터 시스템(Thyroid Imaging Reporting & Data System)) 분류 확률 (classification probability) 등을 예측할 수 있다. AI의 일부는 머신 러닝(Machine learning)을 포함하고, 이는 인간이 개발한 알고리즘에 명시적으로 지시할 필요 없이, 기계가 '자체' 알고리즘을 '발견'하여 문제를 해결하도록 도와주는 기술이다. 이러한 알고리즘 또는 신경 망(neural network)을 일반적으로 모델이라고도 한다. 딥 러닝(Deep learning)은 인공 신경망(artificial neural networks)과 표현 학습(representation learning)에 기초하는 광범위한 머신 러닝 방법(machine learning methods)의 일부이다. 딥 러닝에서 '딥'이라는 형용사는 네트워크에서 여러 계층을 사용한다는 의미이다. 사용되는 방법이 감독(supervised), 반감독(semi-supervised) 또는 비감독(unsupervised) 중 하나가 될 수 있다. 예시적인 감독 학습 작업(supervised learning tasks)은 분 류와 회귀(regression)를 포함한다. '딥 러닝'에서 '딥'이라는 단어는 데이터가 변환되는 계층의 수를 의미한다. 예를 들어, 다계층 네트워크 (multilayer network)는 입력 계층(input layer), 하나 또는 여러 개의 숨겨진 계층(hidden layers), 출력 계 층(output layer)으로 구성될 수 있다. 굿펠로우(Goodfellow) 등은 딥 러닝의 수학적 및 개념적 배경, 업계에서 사용되는 딥 러닝 기술, 연구 관점 등 딥 러닝의 광범위한 주제에 대한 소개(딥 러닝, 케임브리치, MA, MIT 프레스, 2016)를 제공한다(굿펠로우 (Goodfellow), 이안(Ian), 요슈아 벤지오(Yoshua Bengio), 아론 쿠르빌(Aaron Courville) 참조). 예를 들어 분류 작업의 경우, 분류 모델의 출력 계층은 예측의 인공 확률(artificial probability)을 예측하기 위해 일반적으로 소프트맥스 로지스틱 함수(softmax logistic function)에 의존할 수 있다. 따라서, 분류 모델 은 확률과 함께 예측 클래스(estimated class)를 출력할 수 있다. 예를 들어, 의료 영역에서 모델은 의료 이미 지를 수신하고 검출된 유방 병변의 바이라즈 레벨(BI-RADS level)과 그 확률을 분류할 수 있다. 그러나, 의사, 물리학자 또는 방사선 전문의와 같이 검사하는 사람에게는 이 예측 클래스(estimated class)의 확률을 해석하는 방법이 불분명하게 보일 수 있다. 특히, 확률을 해석할 때, 확률이 AI 모델의 순수한 신뢰도인지, 아니면 특정 사용 사례와 관련된 상황적 불확실 성이 고려되어야 하는지 여부가 불분명할 수 있다. 예를 들어, 특정 사용 사례(예: 선별 검사(instance screening) 또는 진단(diagnostics))에 따라 배경 인구가 다를 수 있는 상황으로 인해 맥락적 불확실성이 발생될 수 있다. 또 다른 예로, 특정 사용 사례에 따라, 검사 대상 환자(patient to be examined)가 병변 병력 (lesion history), 인종(ethnicity) 등에 따라 특정 그룹에 속할 수 있는 상황으로 인해 맥락적 불확실성이 발 생될 수 있다. 위와 같이, 단점 및 연관된 불리한 점을 해결할 필요가 있다."}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "컴퓨터-구현 방법(computer-implemented method)은: 혼합 모델(mixture model)을 사용하여 입력 데이터 샘플 세트에 대한 인공 지능(AI) 모델의 계층의 출력의 사후 신뢰도(posterior confidence)를 정량화하는 (quantifying) 단계이고, AI 모델은 분류기 모델(classifier model)이다. 이 방법은: 클래스 분포(class distribution)에 추정된 사전 유병률(assumed prevalence prior)을 제공하는 (providing) 단계, 및 사전 유병률(prevalence prior)에 기초하여 정량화된 사후 신뢰도(quantified posterior confidence)를 교정하 는(calibrating) 단계를 더 포함한다. 즉, 이 방법은: 입력 데이터를 분류하도록 구성된 인공 지능(AI) 모델을 제공하는(providing) 단계, 및 혼합 모 델(mixture model)을 사용하여 입력 데이터 샘플 세트에 대한 모델의 계층의 출력에 대한 사후 신뢰도를 정량화 하는(quantifying) 단계를 포함할 수 있다. 이러한 방법을 제공함으로써, 새로운 훈련 데이터(training data) 없이도 AI 모델에 대해 보다 의미 있는 클래 스 확률(class probability)을 교정할 수 있게 된다. 특히, 출력 확률(즉, 본 개시 내용에 따른 정량화된 사후 신뢰도)은 기존의 소프트맥스(softmax) 기반 인공 로지스틱 확률보다 더 잘 교정될 수 있다. 기존의 AI 모델(예: 심층 신경망)은 입력 데이터를 분류하는 등 예측의 인공 확률을 예측하기 위해 소프트맥스 로지스틱 함수(softmax logistic function)에 의존한다. 이 확률은, 예를 들어 인코딩된 피처가 헤테로스케다스 틱인 경우 최적이 아니다. 또한 클래스의 사전 확률을 알지 못한다. 이와 대조적으로, 본 개시에 따르면, 예를 들어 가우스 혼합 기반 파라메트릭 모델을 사용하여 사후 신뢰도를 정량화할 수 있다. 그런 다음, 네트워크의 확률 예측을 더 잘 교정하기 위해 베이지안 프레임워크(Bayesian framework)에서 고려될 수 있다. 이는 다시 재훈련 없이 기존 네트워크에서 수행될 수 있다. 즉, 초기 모델을 재훈련할 필요가 없다. 위에서 설 명한 대로, 출력 계층을 교체하는 것으로 충분하다. 따라서, 이 방법은 모델 훈련이 필요한 기존 방식에 비해 계산 비용이 훨씬 저렴하다. 기존 AI 모델을 사용할 경우, AI 모델에 의해 결정된 예측 클래스의 확률을 해석하는 방법이 불분명할 수 있다. 이러한 결함(deficiency)은 적어도 부분적으로는 AI 모델 훈련에 사용되는 훈련 데이터의 제한으로 인한 것일 수 있다. 예를 들어, 의료 영역에서 훈련 데이터는 의료 이미지와 각각의 분류 레이블로 구성될 수 있다. 주석 작성자(예: 의사, 물리학자, 방사선사 또는 기타 전문가)가 각 이미지에 클래스로 주석을 달아서 생성할 수 있 다. 그러나, 이러한 주석은 일반적으로 문맥상의 불확실성에 대한 임의의 신뢰도나 확률 정보를 포함하지 않는 다. 이 결함은, 의료 분야에서 일반적으로 많은 훈련 데이터를 확보하기 어렵기 때문에, 더욱 심각하다. 보다 구체적인 예로, 단일 주석 작성자(single annotator)는 상기 선택된 레벨에 확률이나 신뢰도를 추가하지 않고도 바이라즈 레벨(BI-RADS level)로 의료 이미지에 주석을 달 수 있다. 결과적으로, 하나의 특정 바이라즈 레벨(BI-RADS level)은 100%의 확률로 올바른 출력으로 주석이 달릴 수 있고, 한편 다른 가능한 바이라즈 레벨 (BI-RADS level)은 0%의 확률로 올바른 출력으로 주석이 달릴 수 있다. 따라서, 훈련 데이터는 훈련 레이블에 모호함이 없도록 구성된다. 따라서, 결과 훈련 데이터(resulting training data)는 일반적으로 훈련된 AI 모델 의 신뢰도를 과대평가하는 결과를 초래한다. 즉, 기존의 훈련된 모델의 확률이 너무 높은 경우가 많다. 기존의 소프트맥스 함수(softmax function)는 주로 레이블에 신뢰도 정보가 존재하지 않기 때문에 이러한 결함 을 극복할 수 없다. 또한, 소프트맥스 함수는 일반적으로 단편적인 선형 결정 경계(piecewise linear decision boundary)로 인해 지나치게 단순화되어 있다. 예를 들어, 소프트맥스는 본 개시의 AI 모델과 달리 인코딩된 특징의 헤테로세스틱 가우시안(heteroscedastic gaussians)의 혼합 분포(mixture distribution)를 AI 모델의 계 층에서 적절하게 고려하지 않는다. 특히, 본 공개의 AI 모델은 모델에 내재된 데이터(예: 신경망)를 더 잘 활용 할 수 있으며, 이는 예측 클래스에 대한 보다 현실적인 신뢰도 또는 확률로 이어질 수 있다. 추가적인 장점으로, 본 개시의 AI 모델은 소프트맥스 함수를 사용하는 종래의 AI 모델보다 계산적으로 훨씬 더 비싸지 않다. 클래스 분포는 알려진 또는 미리 결정된 클래스 분포일 수 있다. 따라서, 각각의 사전 데이터는 외부 장치로부 터 방법(예: 방법이 실행 중인 시스템)에 제공될 수 있거나, 데이터가 시스템에 저장될 수 있다. 따라서 클래스 분포는 \"사전 분포(prior distribution)\"라고도 할 수 있다. 사전 분포 또는 클래스 분포는 모든 클래스 레이블 의 분포일 수 있다(예: 클래스 레이블 Y). 따라서, 알려진 클래스 분포는 모델을 교정하고 모델의 정확도를 높이기 위해 선행으로 사용될 수 있다. 한 가지 예로, 클래스 분포는 특정 지역의 인구에 대한 클래스의 분포(예: 바이라즈 레벨(Bi-Rads levels))와 관련될 수 있다. 예를 들어, 베이지안 규칙은 정량화된 사후 신뢰도 및/또는 입력 데이터 샘플의 클래스 확률을 교정하기 위해 사용될 수 있다. 따라서 교정을 통해 모델이 실제 특성에 더 잘 적응할 수 있으므로 모델 출력의 정확도를 향상시킬 수 있다. 특히, 추정된 사전 유병률에 기초하는 교정은 다음과 같은 기술적 이점이 있을 수 있다: 정확도 향상(Improved Accuracy): 추정된 사전 유병률(즉, 실제 클래스 분포 데이터)을 통합함으로써, AI 모델 의 예측은 타겟 집단 내 다양한 클래스의 실제 유병률과 더 잘 일치하도록 조정될 수 있다. 이는 보다 정확하고 신뢰할 수 있는 예측으로 이어진다. 일반화 개선(Better Generalization): 사전 유병률로 모델을 교정하면 실제 데이터에 더 잘 일반화할 수 있어, 훈련 데이터에 과적합할 가능성을 줄일 수 있다. 견고성 개선선(Enhanced Robustness): 이 모델은, 각 클래스의 예상 유병률을 고려하기 때문에, 입력 데이터 분 포의 변화에 더욱 강력해진다. 편향성 완화(Bias Mitigation): 사전 유병률을 사용하는 것은, 모델의 출력을 알려진 클래스 분포와 일치시켜 훈련 데이터에 있을 수 있는 편향을 완화하는 데 도움이 될 수 있다. 인공 지능(AI) 모델을 제공하는 동작은, 응답으로 클래스 확률을 예측하는 AI 모델에 입력 데이터 세트(set of input data)를 입력하는 것을 포함할 수 있다. 클래스 확률은 미리 정의된 복수의 가능한 클래스 중에서 예측될 수 있다. 본 개시에 따른 '계층의 출력'은 복수의 출력, 예를 들어 각 입력에 대해 각각의 출력으로 구성될 수 있다. 예 를 들어, 계층에 뉴런이 하나만 있는 경우, 입력당 출력은 단일 값(예: 스칼라)일 수 있다. 계층에 복수의 뉴런 이 있는 경우, 입력당 출력은 각각의 차원 수를 가진 벡터일 수 있다. 계층의 출력의 사후 신뢰도를 정량화하는 것은 계층의 출력의 모델링을 포함하거나 의미할 수 있다. 본 개시의 계층은 미리 정의된 계층일 수 있다. 본 개시의 방법은 사후 신뢰도를 정량화하는 방법일 수 있다. 입력 데이터 세트는 복수의 샘플을 포함할 수 있다. 샘플은 예를 들어 이미지일 수 있으며, 보다 구체적인 예로 인체의 내부 조직을 표현한 의료용 이미지를 예로 들어 설명할 수 있다. 다양한 분류 작업, 즉 클래스 확률의 다양한 유형이 예측될 수 있다. 한 가지 예는 환자 조직의 병변 특성을 분 류하는 것을 포함한다. 예를 들어, 이 방법은 유방 병변 악성 확률, 바이라즈(BI-RADS)(유방 이미징 보고 및 데 이터 시스템) 병변 분류 확률, 간 병변 분류 확률 등을 예측할 수 있다. 그러나, 본 공개는 특정 종류의 분류 작업이나 기술 분야에 국한되지 않는다는 점에 유의하기 바란다. 예를 들 어 음파(sound wave)의 특성을 분류하는 등 완전히 다른 작업과 기술 분야도 가능하다. 계층은 다음 중 하나 이상일 수 있다: 모델의 숨겨진 계층(hidden layer), 예를 들어 모델의 마지막 숨겨진 계층(last hidden layer), 모델의 중간 계층(intermediate layer), 모델의 출력 계층(output layer) 이외의 계층, 그리고 모델의 출력 계층에 앞서는(preceding) 계층, 예를 들어 모델의 출력 계층에 앞서는 마지막 계층과 같은 계층. 즉, AI 모델은 적어도 하나의 숨겨진, 즉 중간 계층을 포함할 수 있다. 예를 들어, 모델은 선택적 입력 계층, 하나 또는 여러 개의 숨겨진 또는 중간 계층, 출력 계층을 포함할 수 있 다. \"계층의 출력\"을 언급할 때는, 출력 계층을 제외한 모델의 모든 계층을 지칭할 수 있다. 이 방법은 정량화된 사후 신뢰도를 모델의 출력 계층으로 사용하는(using) 단계를 더 포함할 수 있다. 정량화된 사후 신뢰도는 수학적 함수로 표현되거나 수학적 함수로 구성될 수 있다. 이 함수는 모델의 초기 출력 계층(initial output layer)을 대체하는 '새로운' 또는 대체 출력 계층(replacing output layer)으로 사용될 수 있다. 따라서 \"새로운\" 또는 대체 출력 계층은 마지막 숨겨진 계층의 출력을 입력으로 수신할 수 있으며 이 를 기반으로 모델의 출력을 계산한다. 정량화된 사후 신뢰도는 계층의 출력을 수신하고 처리하도록 구성될 수 있다. 이 방법은 정량화된 사후 신뢰도를 사용하여 입력 데이터 샘플의 클래스 확률을 예측하는(estimating) 단계를 더 포함할 수 있다. 정량화된 사후 신뢰도 함수는 혼합 모델을 사용하여 입력 데이터 샘플 세트에 대한 모델의 계층의 출력의 사후 신뢰도를 정량화하여 획득될 수 있다. 정량화된 사후 신뢰도는 정량화된 사후 신뢰도 함수일 수 있다. 따라서, '정량화된 사후 신뢰도'는 예를 들어 입력에 기초하여 출력을 계산할 수 있는 수학적 함수일 수 있다. 방법은: 클래스 분포(class distribution)에 추정된 사전 유병률(assumed prevalence prior)을 제공하는(providing) 단 계, 및 사전 유병률에 기초하여 입력 데이터 샘플의 클래스 확률을 교정하는(calibrating) 단계를 더 포함한다. 클래스 분포는 알려진 또는 미리 결정된 클래스 분포일 수 있다. 이에 따라, 각각의 사전 데이터는 외부 장치로 부터 해당 방법(예: 방법이 실행 중인 시스템)에 제공될 수 있거나, 또는 데이터가 시스템에 저장될 수 있다. 따라서, 알려진 클래스 분포는 모델을 교정하고 모델의 정확도를 높이기 위해 선행으로 사용될 수 있다. 사전 유병률은 입력 데이터 샘플 세트와 연관된 지리적 지역 및/또는 인구 집단의 함수로 결정될 수 있다. 예를 들어, 입력 샘플은 특정 인구 및/또는 특정 지역과 연관될 수 있다(예: 출신 지역). 한 가지 예로, 이 방법은 의료 영역, 특히 유방암 진단을 위해 바이라즈(BI-RADS)(유방 이미징 보고 및 데이터 시스템) 분류를 사용하는 유방암 진단(breast cancer diagnosis)에 적용될 수 있다. 바이라즈 레벨(BI-RADS level)은 0에서 6까지이며, 각 레벨은 암의 가능성을 나타내며, 레벨이 높을수록 악성일 가능성이 높음을 나타 낸다. 예시적인 시나리오에서, 특정 지역의 과거 환자 데이터는 해당 지역의 환자 집단에서 바이라즈 레벨(BI-RADS level)의 분포를 보여준다. 이 분포는 환자 집단에 대한 사전 유병률을 반영할 수 있다. AI 모델은 바이라즈 레 벨(BI-RADS level)로 분류하기 위해, 예를 들어 초음파 이미지(또는 위에서 설명한 다른 유형의 이미지)를 처리 하고, 각 분류에 대한 초기 사후 신뢰도를 제공할 수 있다. 벨의따라서 이 예시 시나리오에서, 알려진 바이라즈 레벨(BI-RADS level)의 분포(위에 나열된 바와 같이)를 사전 유병률로 사용할 수 있다. 초기 사후 신뢰도는 사 전 유병률을 사용하여 교정될 수 있다. 교정(calibration)은 AI 모델의 예측이 환자 집단에서 서로 다른 바이라즈 레벨(BI-RADS level)의 실제 유병률 을 반영하도록 조정되는 것을 보장한다. 예를 들어, 초기 예측에서 비정상적으로 높은 수의 바이라즈(BI-RADS) 5 사례가 도시되면, 교정 프로세스는 예상 유병률에 더 일치하게 이러한 예측을 조정할 것이다. 모델의 출력을실제 분포와 일치시키면, 가긍정적 판단(false positives)(예: 바이라즈(BI-RADS) 2 사례를 불필요하게 바이라 즈(BI-RADS) 4로 분류)과 가긍정적 판단(false negatives)(예: 바이라즈(BI-RADS) 5 사례를 누락)의 가능성을 줄여, 보다 정확한 모델 출력을 얻을 수 있다. 정량화된 사후 신뢰도가 교정되고 (예: 동시에 또는 준동시적으로) 모델 판별력(model discrimination power)이 최적화될 수 있으며, 선택적으로 반복적인 프로세스를 통해 최적화할 수 있다. 즉, 정량화된 사후 신뢰도를 교정하는 동시에, 모델 판별력이 최적화될 수 있다. 모델 판별의 교정 및 동시 최적화는 반복적으로 수행될 수 있다. 따라서, 모델은, 예를 들어 (a) 확률 교정(probability calibration)에 대한 충실도와 (b) 모델 판별력의 최적 화라는 두 가지 상충되는 측면의 균형을 맞추어, 개선될 수 있다. 확률 교정에 대한 충실도 (a)는 모델의 예측 확률이 실제 사후 확률을 반영하도록 정확하게 교정되는지, 특히 예를 들어 타겟 집단에서 알려진 분포(즉, 사전 유병률)를 고려하는지 보장한다. 예를 들어, 모델이 특정 지역 의 타겟 집단에서 예를 들어 바이라즈 레벨(BI-RADS level)의 실제 분포와 일치하는 확률을 예측하는 것이 바람 직할 수 있다. 예를 들어, 해당 타겟 집단에서 레벨 3이 일반적이라면, 모델은 이를 예측에 반영해야 한다. 모델 판별(model discrimination)의 최적화 (b)는 서로 다른 클래스(예: 서로 다른 바이라즈 레벨(BI-RADS level))를 명확하게 구분하는 모델의 능력을 향상시켜, 예측을 더욱 뚜렷하고 신뢰할 수 있게 만든다. 예를 들 어, 레벨 2와 레벨 3을 혼동하지 않도록 하는 등 모델에서 레벨을 명확하게 구분하는 것이 바람직할 수 있다. 정량화된 사후 신뢰도를 교정하는 것은 반복 프로세스에서 예측된 클래스 확률(예: 현재 반복 k+1에서)과 이전 반복 k에서 교정된 확률(예: 교정된 클래스 확률) 사이의 거리를 최소화하는 것으로 구성될 수 있다. 모델 판별력을 최적화하는 것은 서로 다른 클래스에서 비롯된 임의의 데이터 분포 쌍 간의 거리를 최대화하는 것을 포함할 수 있다. 여기서 데이터 분포는 단일 클래스에서 발생하는 데이터의 분포를 의미할 수 있다. 즉, 이 \"데이터 분포\"는 모델에 공급되는 입력 데이터, 즉 각 입력 데이터가 모델에 공급될 때(예: 사후 신뢰도 정 량화) 단일 클래스와 관련된 (예: 마지막 숨겨진) 계층(Z)의 출력 데이터의 분포를 나타낼 수 있다. 다시 말해, 데이터 분포는 클래스가 주어진 계층(z)의 출력 분포일 수 있다. 따라서 이 데이터 분포는 다른 클래스 간의 ' 사전 분포'와 다를 수 있다. 따라서 서로 다른 클래스에서 비롯된 한 쌍의 데이터 분포는 두 개의 데이터 분포 를 나타낼 수 있으며, 두 데이터 분포 각각은 서로 다른 클래스를 나타낸다. 예를 들어, 거리를 최소화하는 것은 단계 (k+1)에서 교정된 예측(예: 예측) 확률과 사전 단계 k에서 교정된 확 률 사이의 거리를 최소화하는 제1 발산(first divergence)(D)를 기반으로 할 수 있다. 특히, 제1 발산(D)는 예측 확률을 이전 반복에서 교정된 확률에 가깝게 유지하는 것을 목표로 할 수 있다(위에 서 설명한 확률 교정에 대한 충실도의 측면 (a)도 참조). 따라서 교정 프로세스가 초기 예측에서 너무 많이 벗 어나지 않도록 보장할 수 있다. 다른 예에서, 거리를 최대화하는 것은 서로 다른 클래스에서 오는 분포 쌍 사이의 거리를 최대화하는 제2 발산 (Dij)를 기반으로 할 수 있다. 즉, 제2 항(second term)은 서로 다른 클래스 간의 분리를 최대화하도록 구성될 수 있다. 베이지안 규칙은 정량화된 사후 신뢰도 및/또는 입력 데이터 샘플의 클래스 확률을 교정하는 데 사용될 수 있다. 혼합 모델(mixture model)은 가우스 혼합 모델(Gaussian mixture model)과 같은 확률적 혼합 모델 (probabilistic mixture model)일 수 있다. 일반적으로 '혼합 모델(mixture model)'이라는 용어는 여러 클래스가 존재하며 따라서 단일 가우스 분포가 아니 라는 것을 가리킬 수 있다. 계층의 사후 신뢰도를 정량화하는 것은: 계층의 출력의 확률 분포(예: 한 클래스에 대한 데이터 분포 또는 여러 클래스 또는 모든 클래스에 대한 데이터 분포)를 정량화하는 것 및/또는 모델의 가능한 각 출력 클래스에 대한 계층의 출력의 평균(mean) 및 공분산 통계(covariance statistics)를 기 록하는 것을 포함할 수 있다. 모델은 머신 러닝 모델과 신경망 중 적어도 하나일 수 있다. 이 모델은, 컨볼루션 신경망(CNN)과 같은, 예를 들 어 신경망과 같은, 딥 러닝 모델일 수도 있고 이를 포함할 수도 있다. 모델은 하나 이상의 숨겨진 계층과 출력 계층을 포함할 수 있다. 예를 들어, 적어도 하나의 숨겨진 계층은 모델 의 출력 계층에 출력이 입력되는 모델의 마지막 또는 종료 계층(z)일 수 있다. 모델은 분류 작업을 수행하도록 구성된 초기 출력 계층을 포함하는 제1 초기 모델일 수 있다. 즉, 제1 모델, 즉 초기 모델은 마지막 계층을 대체하여 수정될 수 있다. 이렇게 수정 모델은, 아래 도면의 맥락 에서 자세히 설명하는 대로, 예를 들어 이미징 및/또는 분류 시스템과 같은, 최종 제품에 사용될 수 있다. 예를 들어, 초기 출력 계층은 K-클래스 소프트맥스 규칙을 수행하도록 구성될 수 있다. K는 2 이상이어야 한다. 즉, 초기 출력 계층은 소프트맥스 로지스틱 함수이거나, 이를 수행할 수 있거나 포함할 수 있다. 이 방법은 제1 초기 모델의 초기 출력 계층을 정량화된 사후 신뢰도로 대체하여 제1 수정 모델(first modified model)을 획득하는 단계를 더 포함할 수 있다. 따라서, 제1 수정 모델은, 예를 들어 K-클래스 소프트맥스 규칙을 더 이상 사용하지 않을 수 있다. 유리하게도, 초기 모델을 재훈련할 필요가 없다. 위에서 설명한 대로 출력 계층을 교체하는 것으로 충분하하다. 따라서, 이 방법은 모델 훈련이 필요한 기존 방식에 비해 계산 비용이 훨씬 저렴하다. 본 개시는 제1 수정 모델을 사용하여 입력 샘플의 클래스 확률을 예측하는 것을 포함하는 입력 샘플의 클래스 확률을 예측하는 컴퓨터-구현 방법과 더 관련될 수 있다. 이 방법은 선택적으로 (예를 들어 클래스 확률 예측 동작 전에) 제1 수정 모델에 입력 샘플을 공급하는 동작을 포함할 수 있다. 클래스 확률을 예측하는 컴퓨터-구현 방법은 위에서 설명한 대로 분류 시스템에서 사용되거나 분류 시스템에 의 해 수행될 수 있다. 분류 시스템은 예를 들어 의료 이미징 기기의 일부이거나 이와 연관되어 있을 수 있다. 입 력 샘플은 예를 들어 의료 이미지일 수 있다. 다양한 분류 작업, 즉 클래스 확률의 다양한 유형이 예측될 수 있다. 한 가지 예는 환자 조직의 병변 특성을 분류하는 것을 포함한다. 예를 들어, 이 방법은 유방 병변 악성 확률, 바이라즈(BI-RADS)(유방 이미징 보고 및 데이터 시스템) 병변 분류 확률, 간 병변 분류 확률 등을 예측할 수 있다. 그러나, 본 공개는 특정 종류의 분류 작업이나 기술 분야로 제한되지 않는다는 점에 유의하시기 바란다. 또한 음파의 특성을 분류하는 등 다른 작업과 기술 분야가 가능하다. 이 방법은 입력 샘플의 함수로서 사전 유병률을 선택하는(selecting) 단계 및 제1 수정 모델을 사용하여 사전 유병률에 기초하여 입력 샘플에 대한 교정된 클래스 확률을 예측하는 단계를 더 포함할 수 있다. 본 개시는 인공 지능(AI) 알고리즘을 위한 훈련 레이블(training labels)을 생성하는 방법과 더 관련될 수 있으 며, 이는, 각각의 클래스 확률 세트를 획득하기 위해 위에서 설명한 방법 중 하나를 입력 데이터 샘플 세트에 적용하는 (applying) 단계, 및 클래스 확률 세트에 기초하여 훈련 레이블을 생성하는(generating) 단계를 더 포함한다. 따라서, 훈련 데이터 세트는 입력 데이터 세트와 연관된 레이블을 포함할 수 있다. 따라서, 아래에 자세히 설명된 대로 다른 모델은 훈련될 수 있다. 본 개시는 인공 지능(AI) 모델을 훈련하는 방법과 더 관련될 수 있으며, 이는, 훈련 레이블을 생성하기 위해 위에서 설명된 바와 같은 방법을 수행하는(performing) 단계, 훈련 레이블을 사용하여 감독된 방식으로 제1 초기 인공 지능(AI) 모델(first initial artificial intelligence (AI) model)을 훈련시키는(training) 단계를 포함한다. 제1 초기 인공 지능(AI) 모델은 위에서 언급한 제1 초기 인공 지능(AI) 모델 또는 임의의 다른 모델일 수 있다. 예를 들어, 입력 데이터 세트는 훈련 중에 입력으로 사용되고 훈련 레이블 세트는 타겟 출력(target output)으 로 사용될 수 있다.따라서, 제1 초기 인공 지능(AI) 모델은 훈련 데이터세트에서 처음부터 훈련(예: 처음부터 훈련)될 수 있다. 제 1 초기 인공 지능(AI) 모델은 모든 종류의 분류 모델이 될 수 있다. 예를 들어, K-클래스 소프트맥스 규칙과 같 은 기존 출력 계층(conventional output layer)을 포함할 수 있다. 이 방법은 훈련된 제1 인공 지능(AI) 모델의 마지막 계층을 정량화된 사후 신뢰도로 대체하여 제2 인공 지능 (AI) 모델(trained first artificial intelligence (AI) model)을 획득하는(obtaining) 단계, 입력 데이터 샘플 세트에 대한 예측 클래스 확률(estimated class probabilities)을 획득하기 위해 제2 인공 지 능(AI) 모델을 실행하는(running) 단계, 입력 데이터 샘플 세트에 예측 클래스 확률로 다시 레이블링하는(re-labelling) 단계, 다시 레이블링된 입력 데이터 샘플 세트를 기반으로 제3 인공 지능(AI) 모델을 훈련시키는 단계를 더 포함할 수 있다. 이 방법은 한 번 또는 여러 번 반복될 수 있다. 따라서, 이 방법은 훈련 단계에서, 훈련과 확률을 동시에 유리 하게 교정하기 위해, 추가로 반복적으로 적용될 수 있다. 예를 들어, 이 방법은 훈련된 제3 인공 지능(AI) 모델의 마지막 계층을 정량화된 사후 신뢰도로 대체하여 제4 인공 지능(AI) 모델을 획득하는(obtaining) 단계, 입력 데이터 샘플 세트에 대한 예측 클래스 확률을 획득하기 위해 제4 인공 지능(AI) 모델을 실행하는(running) 단계, 입력 데이터 샘플 세트에 예측 클래스 확률로 다시 레이블링하는(re-labelling) 단계, 다시 레이블링된 지정된 입력 데이터 샘플 세트를 기반으로 제5 인공 지능(AI) 모델을 훈련시키는 단계를 더 포 함할 수 있다. 이러한 방식으로, 훈련 데이터 세트와 훈련된 모델은 실제 분류 문제를 더 정확하게 표현하기 위해 연속적으로 개선될 수 있다. 본 개시는 또한 컴퓨팅 장치(computing device)와 관련될 수 있으며, 이는, 하나 이상의 프로세서(processor), 및 컴퓨터-실행 명령들(computer-executable instructions)을 저장하는 적어도 하나의 메모리를 포함하고, 컴퓨터- 실행 명령들(computer-executable instructions)이, 프로세서에 의해 실행될 때, 컴퓨팅 장치로 하여금, 위에 서 설명된 임의의 하나의 방법을을 수행하게 한다. 본 개시는 또한, 컴퓨팅 장치(computing device)와 더 관련되며, 이는, 적어도 하나의 프로세서(processor) 및 컴퓨터-실행 명령을 저장하는 적어도 하나의 메모리(memory), 및 분류기 모델인 인공 지능(AI) 모델을 포함한다. 프로세서에 의해 실행되는 컴퓨터-실행 명령들은 혼합 모델을 사용하여 입력 데이터 샘플 세트에 대 한 모델의 계층의 출력에 대한 사후 신뢰도를 정량화하는 것을 포함한다. 컴퓨팅 장치는 디스플레이 장치와 연결되도록 구성될 수 있으며, 예를 들어 이미지 및 연관된 예측 클래스가 디 스플레이 장치에 표시될 수 있다. 컴퓨팅 장치는 하나 또는 다수의 입력 샘플을 획득하고 컴퓨팅 장치에 이를 제공하도록 구성된 입력 장치와 연 관되도록 구성될 수 있다. 프로세서(또는 처리 유닛(processing unit))는 계산 작업(computational tasks)을 수행하는 역할을 담당할 수 있는 전자 장치의 구성요소일 수 있다. 처리 유닛은 중앙 처리 장치(Central Processing Unit)(CPU), 그래픽 처 리 장치(Graphics Processing Unit)(GPU), 디지털 신호 프로세서(Digital Signal Processor)(DSP), 필드 프로 그래머블 게이트 어레이(Field-Programmable Gate Array)(FPGA), 및/또는 애플리케이션 특정 집적 회로 (Application-Specific Integrated Circuit)(ASIC)를 포함할 수 있다. 본 개시에 따른 방법은 가상 서버 (virtual server)에서 실행될 수도 있다. 본 개시는 또한 입력 샘플을 분루하는 시스템과 관련될 수 있으며, 이 시스템은 본 개시의 임의의 실시예에 따 른 방법을 수행하는 수단을 포함한다. 예를 들어, 시스템은 위에서 설명한 대로 컴퓨팅 장치로 구성되거나 컴퓨 팅 장치일 수 있다.본 개시는 또한 본 개시의 임의의 실시예에 따른 방법을 수행하기 위한 수단을 포함하는 이미징 시스템(예컨대, 초음파 이미징)에 관한 것일 수도 있다. 본 개시는 또한, 프로그램(program)이 컴퓨터에 의해 실행될 때, 컴퓨터가 본 개시의 임의의 예에 따른 방법을 수행하게 하는 명령들(instructions)을 포함하는 컴퓨터 프로그램(computer program)에 관한 것일 수 있다. 본 개시는 또한, 컴퓨터에 의해 실행될 때, 컴퓨터가 본 개시의 임의의 예에 따른 방법을 수행하게 하는 명령들 (instructions)을 포함하는 컴퓨터 판독가능 매체(computer-readable medium)에 관한 것일 수 있다. 달리 모순되는 경우를 제외하고 위에서 설명한 요소와 사양 내의 요소의 조합을 만들 수 있다. 전술한 일반 설명과 다음 세부 설명은 모두 예시적이고 설명적일 뿐이며 설명 목적으로 제공되며 청구된 대로 공개를 제한하지 않는다는 것을 이해해야 한다. 본 명세서에 포함되어 그 일부를 구성하는 첨부 도면들은 개시의 예시들 및 설명과 함께 설명하고, 그 원리들을 뒷받침하고 설명하는 역할을 한다."}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "참조(reference)는 이제 첨부 도면들에서 도시되는 예들인 본 개시의 예들로 상세히 이루어질 것이다. 가능하면 도면 전체에 동일한 참조 번호가 사용되어 동일하거나 유사한 파트를 참조한다. 도 1은 본 개시의 실시예에 따른 사후 신뢰도를 정량화하는 방법을 개략적으로 도시한다. 이 방법은 복수의 동 작을 포함할 수 있다. 예를 들어, 하나 또는 여러 개의 동작이 각각의 소프트웨어 모듈에 의해 구현될 수 있다. 선택적 동작 S1에서, 인공 지능(AI) 모델이 제공될 수 있다. 이 모델은 입력 데이터를 분류하도록 구성될 수 있 다. 도 2는 인공 지능(AI) 모델(artificial intelligence (AI) model)의 예를 보여준다. 선택적 동작 S2에서, 입력 데이터 세트가 AI 모델에 입력될 수 있다. 이에 응답하여, AI 모델은 각 샘플에 대해 각각의 클래스 확률을 예측할 수 있다. 다양한 분류 작업이 수행될 수 있으며, 즉 클래스 확률의 다양한 유형이 예측될 수 있다. 한 가지 예는 환자 조 직의 병변 특성을 분류하는 것(classifying)을 포함한다. 예를 들어, 이 방법은 유방 병변 악성 확률, 바이라즈 (BI-RADS)(유방 이미징 보고 및 데이터 시스템) 병변 분류 확률, 간 병변 분류 확률 등을 예측할 수 있다. 샘플은, 예를 들어 이미지, 특히 의료 이미지일 수 있다. 예를 들어 이미지는해, 예를 들어 의료 이미징 시스템 과 같은, 이미징 시스템에 의해 제공할 수 있다. 이미지는 이미징 시스템에서 스캔한 매질(medium)과 연관될 수 있다. 예를 들어, 이미징 시스템은 유방 촬영(mammography), 단층 합성(tomosynthesis), 자기 공명 이미징 (magnetic resonance imaging)(MRI), 단일 광자 방출 컴퓨터 단층 촬영(single-photon emission computerized tomography)(SPECT) 스캔, 양전자 방출 단층 촬영(positron emission tomography)(PET) 스캔, 광간섭 단층 촬 영(optical coherence tomography)(OCCT), 광학 단층 촬영(optical tomography)(OCT), X-선 검사(X-ray exam) 및 초음파 이미징(ultrasound imaging) 중 하나 이상을 포함할 수 있다. 예시적인 초음파 시스템이 도 7에 도시 된다. 일반적으로, 이미지는 도 1의 방법을 수행하는 제1 시스템에 의해 획득될 수도 있고, 이미지는 제2 시스템에 의해 준비되거나 획득되고, 측시 또는 제2 페이스에서 제1 시스템에 제공될 수도 있다. 전달(transfer)은 4G/5G, WIFI, LAN, WAN, 지점 간 등 유선 또는 무선 네트워크를 통해 이루어질 수 있다. 실시예들에서, 연결은 포인트대포인트 통신들, 연결 지향 통신(connection-oriented communication)들, 비연결 통신(connectionless communication)들 등을 설비하도록 동작 가능하다. 동작 S3에서, 모델의 계층(예: 숨겨진 계층) 출력에 대한 사후 신뢰도는 혼합 모델을 사용하여 입력 데이터 샘 플 세트에 대해 정량화된다. 혼합 모델(mixture model)은 확률적 혼합 모델(probabilistic mixture model) 및/ 또는 가우스 혼합 모델(Gaussian mixture model)일 수 있다. 동작 S3은 모델의 가능한 각 출력 클래스에 대한 계층의 출력의 평균(mean) 및 공분산 통계(covariance statistics)를 기록하는 것(recording)을 포함할 수 있 다. 동작 S4에서, 클래스 분포에 대해 추정된 사전 유병률이 제공될 수 있다. 동작 S5에서, 입력 데이터 샘플의 정량화된 사후 신뢰도 및/또는 클래스 확률은 사전 유병률에 기초하여 교정될 수 있다. 클래스 분포는 알려진 또는 미리 결정된 클래스 분포일 수 있다. 이에 따라, 각각의 사전 데이터는 외부 장치로 부터 해당 방법(예: 방법이 실행 중인 시스템)에 제공될 수 있거나, 또는 데이터가 시스템에 저장될 수 있다. 따라서, 알려진 클래스 분포는 모델을 교정하고 모델의 정확도를 높이기 위해 선행으로 사용될 수 있다. 한 가 지 예로, 클래스 분포는 특정 지역의 인구에 대한 클래스의 분포(예: 바이라즈 레벨(Bi-Rads levels))와 관련될 수 있다. 예를 들어, 베이지안 규칙은 정량화된 사후 신뢰도 및/또는 입력 데이터 샘플의 클래스 확률을 교정하 기 위해 사용될 수 있다. 따라서 클래스 분포는 \"사전 분포(prior distribution)\"라고도 할 수 있다. 사전 분 포 또는 클래스 분포는 모든 클래스 레이블의 분포일 수 있다(예: 클래스 레이블 Y). 따라서, 교정을 통해 모델이 실제 특성에 더 잘 적응할 수 있으므로 모델 출력의 정확도를 향상시킬 수 있다. 설명된 교정 기법의 추가적인 장점과 예시적인 시나리오는 도 4의 맥락에서 설명된다. 선택적 동작 S6에서, 정량화된(그리고 선택적으로 교정된) 사후 신뢰도를 사용하여 입력 데이터 샘플의 클래스 확률이 예측될 수 있다. 예를 들어, 상기 클래스 확률은 사용자에게 출력(예: 표시)될 수 있다. 도 2는 본 개시의 실시예에 따른 초기 AI 모델과 제1 수정 AI 모델을 개략적으로 도시한다. 모델은 분류 작업을 수행하도록 구성된 초기 출력 계층을 포함하는 제1 초기 모델일 수 있다. 모델은 머신 러닝 모델(machine learning model)과 신경망(neural network) 중 적어도 하나일 수 있다. 이 모델은, 컨볼루션 신경망(CNN)과 같은, 예를 들어 신경망과 같은, 딥 러닝 모델일 수도 있고 이를 포함할 수 도 있다. 예를 들어, 모델은 선택적 입력 계층(input layer), 하나 또는 여러 개의 숨겨진(hidden) 또는 중간 계층 (intermediate layers), 및 초기 출력 계층(initial output layer)을 포함할 수 있다. 예를 들어, 초기 출력 계층은 K-클래스 소프트맥스 규칙을 수행하도록 구성될 수 있다. K는 2 이상이어야 한다. 즉, 초기 출력 계층은 소프트맥스 로지스틱 함수이거나, 이를 수행할 수 있거나 포함할 수 있다. 본 개시에 따른 계층은 예를 들어 숨겨진 계층 중 어느 하나일 수 있다. 하나의 예에서, 계층은 모델의 출 력 계층에 출력이 입력되는 모델(도 3 참조)의 마지막 또는 종료 숨겨진 계층(z)일 수 있다. 수정 모델(modified model)(200')과 관련하여, 제1 초기 모델(first initial model)은 출력 계층을 대체하여 수정될 수 있다. 이 수정 모델(200')은 최종 제품, 예를 들어 도 7에 도시된 시스템과 연관되어 사용될 수 있다. 수정된 출력 계층(modified output layer)은 모델의 종결 숨겨진 계층(202a)의 데이터를 처리하기 위해 정 량화된 사후 신뢰도 함수(quantified posterior confidence function)를 포함하거나 사용한다(예컨대, 도 3 참 조). 즉, '정량화된 사후 신뢰도'는 예를 들어 입력에 기초하여 출력을 계산할 수 있는 수학적 함수일 수 있다. 따라 서, 정량화된 사후 신뢰도는 모델(200')의 출력 계층으로 사용될 수 있다. 결과적으로, 제1 수정 모델(first modified model)(200')은 더 이상 소프트맥스 로지스틱 함수을 사용하지 않는다. 다시 말해, 정량화된 사후 신뢰도는 수학적 함수로 표현되거나 수학적 함수로 구성될 수 있다. 이 함수는 모델 의 초기 출력 계층(initial output layer)을 대체하는 '새로운' 또는 대체 출력 계층(replacing output layer)으로 사용될 수 있다. 따라서 \"새로운\" 또는 대체 출력 계층(replacing output layer)은 마 지막 숨겨진 계층(last hidden layer)의 출력을 입력으로 수신할 수 있으며 이를 기반으로 모델(200')의 출력을 계산한다. 이 출력은 모델(200')에 제공되고 모델 계층을 통해 전달되는 입력 샘플의 예측 클래스 확률 을 구성할 수 있다. 유리하게도, 초기 모델을 재훈련할 필요가 없다. 위에서 설명한 대로, 출력 계층(203, 204)를 교체하는 것으로 충분하다. 따라서, 이 방법은 모델 훈련이 필요한 기존 방식에 비해 계산 비용이 훨씬 저렴하다. 결과적으로, 모델(200')은 본 개시에 따른 입력 샘플의 클래스 확률을 예측하는 컴퓨터-구현 방법(computer- implemented method)을 수행하도록 구성될 수 있다. 클래스 확률을 예측하는 컴퓨터-구현 방법은 위에서 설명한 대로 분류 시스템에서 사용되거나 분류 시스템에 의 해 수행될 수 있다. 분류 시스템은 예를 들어 의료 이미징 기기의 일부이거나 이와 연관되어 있을 수 있다. 입 력 샘플은 예를 들어 의료 이미지일 수 있다. 다양한 분류 작업이 수행될 수 있으며, 즉 클래스 확률의 다양한 유형이 예측될 수 있다. 한 가지 예는 환자 조직의 병변 특성을 분류하는 것(classifying)을 포함한다. 예를 들 어, 이 방법은 유방 병변 악성 확률, 바이라즈(BI-RADS)(유방 이미징 보고 및 데이터 시스템) 병변 분류 확률, 간 병변 분류 확률 등을 예측할 수 있다. 그러나, 본 공개는 특정 종류의 분류 작업이나 기술 분야로 제한되지 않는다는 점에 유의하시기 바란다. 예를 들어 음파(sound wave)의 특성을 분류하는 등 완전히 다른 작업과 기술 분야도 가능하다. 도 3은 기존 출력 계층과 예제에 따른 출력을 개략적으로 도시한다. 출력 계층은 마지막 숨겨진 계층(202a)의 출력을 수신하여 처리한다. 예에서, 출력 계층는 K-클래스 소프트맥스 로지스틱 함수이며, 여기서 K=2이다. 즉, 출력 계층는 두 클래스 A와 B의 확률(p)을 다음과 같이 예측하는 이중 분류기로 구성된다( 및 참조):"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": ", 여기서 x는 모델에 공급되는 입력 벡터(input vector)이다, z는 마지막 숨겨진 계층(202a)의 출력 벡터이고, 및 w는 마지막 숨겨진 계층(202a)의 출력에 부여된 가중치이다. 일반적으로, K-클래스 소프트맥스 로지스틱 함수는 예를 들어 식과 같이 정의될 수 있다: , 이고, 및 이다. 그러나, 소프트맥스 함수에는 몇 가지 단점이 있다. 소프트맥스 확률은 인코딩된 피처()의 분포를 무시한다. 또 한, 소프트맥스 확률은 클래스의 사전 확률을 무시한다. 또한, 도 4에 자세히 나와 있는 것처럼 소프트맥스 확률은 차선책 선형 결정 경계에 따라 조정된다. 또한, 적어도 일부 경우에는 소프트맥스 확률이 임의적인 것으로 보이다. 도 4는 예에 따른 소프트맥스 로지스틱 함수의 두 가지 클래스 분포와 단점을 개략적으로 보여준다. 이 예 에서는 부분적으로 겹칠 수 있는 두 개의 클래스 분포(class distributions)(401 및 402)가 표시된다. 분포는 가우스 분포일 수 있다. 소프트맥스 함수는 선형 경계(linear boundary)로 개략적으로 표현될 수 있는데, 이는 소프트맥스가 차선 책 선형 결정 경계에 따라 조정되기 때문이다. 따라서, 소프트맥스는 인코딩된 피처()의 분포를 고려하지 않는 다. 예를 들어, 헤테로스케다스틱 기능(heteroskedastic features)의 분류는 차선책이다. 이러한 맥락에서 도 4의 예에서도 볼 수 있듯이, 두 개의 헤테로스케다스틱 가우시안 경계는 선형 경계가 아닌 이차 경계(quadratic boundary)로 이어진다. 따라서, 소프트맥스는 현실 세계에서 클래스 사전 확률 을 고려하지 않는다. 이는 예측 확률이 편향될 수 있음을 의미한다. 이러한 단점을 극복하기 위해, 소프트맥스 로지스틱 함수를 포함하는 모델의 초기 출력 계층은 본 개시에 따라 정량화된 사후 신뢰도 함수를 포함하는 수정된 출력 계층으로 유리하게 대체될 수 있다. 이 정량화된 사후 신뢰도 함수는 다음과 같이 결정될 수 있다: 기존의 소프트맥스 규칙으로 훈련된 기존 AI 모델이 주어지면, 모델은 훈련 데이터(즉, 입력 데이터 세트)를 통 해 실행되고 각 클래스(C)에 대해 의 평균 및 공분산 통계를 기록하며, 예를 들어 식 및 로: ,"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 는 평균 통계이고, C는 클래스이고(이 예에서는 클래스 A와 B가 두 개 있다), 은 공분산 통계이다. 클래스()에 속하는 입력의 가능성은 가우스 함수로 모델링할 수 있으며, 예를 들어 식 및 로:"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": ", 여기서 은 트레이닝 레이블, 즉 주석이 달린 클래스의 레이블이고, 는 정규 분포(예: 다변량 정규 분포)이고, 은 다변량 정규 분포와 연관된 파라미터 세트이다. 균일한 유병률 가정 하에서, 사후 신뢰도는 다음에 의해 결정될 수 있으며, 예를 들어 식은,"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이다. 앞서 언급했듯이, 입력 데이터 샘플의 정량화된 사후 신뢰도 및/또는 클래스 확률은 사전 유병률에 기초하여 교 정될 수 있다. 사전 유병률 이 주어지면 입력이 클래스 A에 속할 사후 확률은 예를 들 어 식와 같이 표현될 수 있으며,"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이다. 따라서, x가 클래스(C)에서 나올 확률은 p(x|C)로 표시된다. 이것은 클래스(C)에 대응하는 가우스 분포일 수 있 다. x가 주어진 클래스 C의 사후 신뢰도는: Pr(C|x) 일 수 있다. 이는 가우시안 혼합에서 파생될 수 있다. 클래스 분포는 알려진 또는 미리 결정된 클래스 분포일 수 있다. 따라서, 각각의 사전 데이터는 외부 장치로부 터 방법(예: 방법이 실행 중인 시스템)에 제공될 수 있거나, 데이터가 시스템에 저장될 수 있다. 따라서 클래스 분포는 \"사전 분포(prior distribution)\"라고도 할 수 있다. 사전 분포 또는 클래스 분포는 모든 클래스 레이 블의 분포일 수 있다. 결과적으로, 알려진 클래스 분포는 모델을 교정하고 모델의 정확도를 높이기 위해 선행으로 사용될 수 있다. 한 가지 예로, 클래스 분포는 특정 지역의 인구에 대한 클래스의 분포(예: 바이라즈 레벨(Bi-Rads levels))와 관련 될 수 있다. 예를 들어, 베이지안 규칙은 정량화된 사후 신뢰도 및/또는 입력 데이터 샘플의 클래스 확률을 교 정하기 위해 사용될 수 있다. 따라서 교정을 통해 모델이 실제 특성에 더 잘 적응할 수 있으므로 모델 출력의 정확도를 향상시킬 수 있다. 특히, 추정된 사전 유병률에 기초하는 교정은 다음과 같은 기술적 이점이 있을 수 있다: 정확도 향상(Improved Accuracy): 추정된 사전 유병률(즉, 실제 클래스 분포 데이터)을 통합함으로써, AI 모델 의 예측은 타겟 집단 내 다양한 클래스의 실제 유병률과 더 잘 일치하도록 조정될 수 있다. 이는 보다 정확하고 신뢰할 수 있는 예측으로 이어진다. 일반화 개선(Better Generalization): 사전 유병률로 모델을 교정하면 실제 데이터에 더 잘 일반화할 수 있어, 훈련 데이터에 과적합할 가능성을 줄일 수 있다. 견고성 개선선(Enhanced Robustness): 이 모델은, 각 클래스의 예상 유병률을 고려하기 때문에, 입력 데이터 분 포의 변화에 더욱 강력해진다. 편향성 완화(Bias Mitigation): 사전 유병률을 사용하는 것은, 모델의 출력을 알려진 클래스 분포와 일치시켜 훈련 데이터에 있을 수 있는 편향을 완화하는 데 도움이 될 수 있다. 한 가지 예로, 이 방법은 의료 영역, 특히 유방암 진단을 위해 바이라즈(BI-RADS)(유방 이미징 보고 및 데이터 시스템) 분류를 사용하는 유방암 진단(breast cancer diagnosis)에 적용될 수 있다. 바이라즈 레벨(BI-RADS level)은 0에서 6까지이며, 각 레벨은 암의 가능성을 나타내며, 레벨이 높을수록 악성일 가능성이 높음을 나타 낸다. 예시적인 시나리오에서, 특정 지역의 과거 환자 데이터는 해당 지역의 환자 집단에서 바이라즈 레벨(BI-RADS level)의 분포를 보여준다. 예를 들어 다음과 같이 분포할 수 있다: - 바이라즈(BI-RADS) 0: 5% - 바이라즈(BI-RADS) 1: 50% - 바이라즈(BI-RADS) 2: 20% - 바이라즈(BI-RADS) 3: 15% - 바이라즈(BI-RADS) 4: 7% - 바이라즈(BI-RADS) 5: 2% - 바이라즈(BI-RADS) 6: 1% 이 예시적인 분포는 환자 집단에 대한 사전의 유병률을 반영할 수 있다. AI 모델은 바이라즈 레벨(BI-RADS level)로 분류하기 위해, 예를 들어 초음파 이미지(또는 위에서 설명한 다른 유형의 이미지)를 처리하고, 각 분류에 대한 초기 사후 신뢰도를 제공할 수 있다. 이 예시 시나리오에서, 알려 진 바이라즈 레벨(BI-RADS level)의 분포(위에 나열된 바와 같이)는 사전 유병률로 사용된다. 초기 사후 신뢰도는 사전 유병률을 사용하여 교정될 수 있다. 이는 베이지안 방법을 사용하여 이루어질 수 있는 데, 사전 분포(알려진 바이라즈(BI-RADS) 분포)는 교정된 사후 신뢰도를 획득하기 위해 초기 사후 신뢰도와 결 합된다. 교정(calibration)은 AI 모델의 예측이 환자 집단에서 서로 다른 바이라즈 레벨(BI-RADS level)의 실제 유병률 을 반영하도록 조정되는 것을 보장한다. 예를 들어, 초기 예측에서 비정상적으로 높은 수의 바이라즈(BI-RADS) 5 사례가 도시되면, 교정 프로세스는 예상 유병률에 더 일치하게 이러한 예측을 조정할 것이다. 모델의 출력을 실제 분포와 일치시키면, 가긍정적 판단(false positives)(예: 바이라즈(BI-RADS) 2 사례를 불필요하게 바이라 즈(BI-RADS) 4로 분류)과 가긍정적 판단(false negatives)(예: 바이라즈(BI-RADS) 5 사례를 누락)의 가능성을 줄여, 보다 정확한 모델 출력을 얻을 수 있다. 도 5는 본 개시의 실시예들에 따른 선행 유병률에 기초하여 모델의 정량화된 사후 신뢰도(예컨대, 입력 데이터 샘플의 클래스 확률)를 교정하는 반복적 방법(iterative method)을 개략적으로 도시한다. 특히, 도 5의 예 시적인 방법은 판별력을 최적화하면서 모델 교정의 방법을 개략적으로 보여준다. 단순화를 위해, 예시에서는 모델(200')의 일부, 즉 마지막 숨겨진 계층(202a)과 그 예측 확률(A, B)만 보여줄 것이다. 이 모델은 일반적으로 도 2의 AI 모델(200')과 대응할 수 있다. 따라서, 출력 계층(예컨대, 소프트맥스 로지스틱 함수)은 본 개시에 따라 정량화된 사후 신뢰도 함수를 포함하는 수정된 출력 계층으로 대체될 수 있다. 도 5에 개략적으로 표시된 바와 같이, 출력 계층은, 예를 들어 파라메트릭(parametric)(및/또는 가우시안 (gaussian)) 혼합 모델과 같은, 혼합 모델에 기초될 수 있다. 특히, 위에서 설명한 바와 같이 정량화된 사후 신 뢰도 함수를 획득하기 위해 혼합 모델을 사용하여 사후 신뢰도가 정량화될 수 있다. 도 5의 예시적인 방법에서, 교정은 모델 판별력 최적화와 동시에 또는 준동시적으로 수행될 수 있다. 즉, 모델 (특히 출력 계층에서)은 (a) 확률 교정에 대한 충실도, 및 (b) 모델 판별의 최적화(즉, 다른 클래스 간) 사이에 서 경쟁하여 균형을 맞추고 개선할 수 있다. 즉, 모델은, 예를 들어 (a) 확률 교정(probability calibration)에 대한 충실도와 (b) 모델 판별력의 최적화라 는 두 가지 상충되는 측면의 균형을 맞추어, 개선될 수 있다. 확률 교정에 대한 충실도 (a)는 모델의 예측 확률이 실제 사후 확률을 반영하도록 정확하게 교정되는지, 특히 예를 들어 타겟 집단에서 알려진 분포(즉, 사전 유 병률)를 고려하는지 보장한다. 예를 들어, 모델이 특정 지역의 타겟 집단에서 예를 들어 바이라즈 레벨(BI-RADS level)의 실제 분포와 일치하는 확률을 예측하는 것이 바람직할 수 있다. 예를 들어, 해당 타겟 집단에서 레벨 3이 일반적이라면, 모델은 이를 예측에 반영해야 한다. 모델 판별의 최적화 (b)는 서로 다른 클래스(예: 서로 다른 바이라즈 레벨(BI-RADS level))를 명확하게 구분하 는 모델의 능력을 향상시켜, 예측을 더욱 뚜렷하고 신뢰할 수 있게 만든다. 예를 들어, 레벨 2와 레벨 3을 혼동 하지 않도록 하는 등 모델에서 레벨을 명확하게 구분하는 것이 바람직할 수 있다. 따라서, 이러한 균형 조정 및 개선 프로세스(refinement process를 통해 모델에 더 많은 유연성을 제공할 수 있 다. 또한, 확률 교정과 모델 분류 능력 향상이라는 두 가지 목표를 동시에 해결할 수 있다. 모델 판별의 교정 및 동시 최적화는 반복적으로 수행될 수 있다. 도 5는 이러한 맥락에서 예시적인 반복 k와 k+1을 보여 주지만, 이 방법은 두 개 이상의 반복으로 구성될 수 있다. 특히, 모델 출력 계층은, 정확한 확률 예측치를 유지하는(교정) 것과 서로 다른 클래스를 구별하는 능력(판별)을 향상시키는 것의, 두 가지 중요한 목 표에 균형을 맞추기 위해, 이 균형 조정 및 개선 프로세스에서 반복적으로 조정될 수 있다. 모델(200')의 단계 k에서 교정된 확률(즉, 교정된 정량화된 사후 신뢰도)은 다음과 같다(식 참조):"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "k+1 단계에서 모델의 최적화된 교정 확률은(식 참조):"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "일 수 있다. 반복적인 확률 교정과 모델 판별의 동시 최적화는, 예를 들어 식를 기반으로 할 수 있다:"}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "i와 j는 서로 다른 두 클래스 Ci와 Cj의 인덱스를 나타낸다. 가중치 wij는 Ci와 Cj 사이의 모델 판별을 최적화하 는 데 중요성을 제공한다. 선택적으로, 가중치 wij는 다른 단계 k에서 다를 수 있다. D와 Dij는 모두 발산 (divergence)을 나타낸다. 발산은 하나의 데이터 분포에서 다른 데이터 분포로의 분리를 설정하는 거리 메트릭 (distance metric)으로 이해될 수 있다. 특히, 이 발산은 두 데이터 분포가 서로 얼마나 다른지 측정하는 방법 으로 이해될 수 있다. 예는(다른 것들 중에서): 쿨백-라이블러(Kullback-Leibler)(KL) 발산, 헬리거 거리 (Helliger distance), 바타차르야 거리(Bhattacharyya distance) 및 바서스타인 거리(Wasserstein distance)를 포함한다. 단계 (k+1)의 최적화는 두 개의 항으로 구성된다: 제1 발산(first divergence)(D)(또는 제1 항)은 단계 (k+1)에서 교정된 예측 확률과 이전 단계 k에서 교정된 확 률 사이의 거리를 최소화한다. 특히, 제1 발산(D)는 예측 확률을 이전 반복에서 교정된 확률에 가깝게 유지하는 것을 목표로 할 수 있다(위에 서 설명한 확률 교정에 대한 충실도의 측면 (a)도 참조). 따라서 교정 프로세스가 초기 예측에서 너무 많이 벗어나지 않도록 보장할 수 있다. 제2 발산(second divergences)(Dij)(또는 발산(Dij)의 제2 항)은 서로 다른 클래스에서 오는 데이터 분포의 임의 의 쌍 사이의 거리를 최대화한다(또한, 위에서 설명한 모델 판별 최적화의 측면 (b) 참조). 즉, 제2 항(second term)은 서로 다른 클래스 간의 분리를 최대화하도록 구성된다. 여기서 데이터 분포는 단일 클래스에서 발생하 는 데이터의 분포를 의미할 수 있다. 즉, 이 \"데이터 분포\"는 모델에 공급되는 입력 데이터, 즉 각 입력 데이터 가 모델에 공급될 때(예: 사후 신뢰도 정량화) 단일 클래스와 관련된 (예: 마지막 숨겨진) 계층 z의 출력 데이 터의 분포를 나타낼 수 있다. 따라서 이 데이터 분포는 다른 클래스 간의 '사전 분포'와 다를 수 있다. 특히, 데이터 분포는 클래스가 주어졌을 때 z의 분포일 수 있다. 사전 분포 또는 클래스 분포는 모든 클래스 레이블의 분포일 수 있으며, 즉 y일 수 있다. 가중치(wij)는 다양한 차이의 가중치로 작용할 수 있으며, (a) 확률 교정에 대한 충실도와 (b) 서로 다른 클래스 간의 판별 능력 극대화 사이의 균형을 제공한다. 따라서, 가중치는 두 항의 중요도를 조정할 수 있으며, 따라서, 측면 (a) 및 (b)의 중요도를 조정할 수 있다. 특히 이전에 교정된 확률에 가깝게 유지하는 것(충실도, (a))과 클래스를 더 구별할 수 있게 만드는 것(판별력, (b)) 중 어느 쪽에 더 중점을 둘지 균형을 맞출 수 있다. 전반적으로 큰 가중치는 클래스 판별력에 더 중점을 두고, 전반적으로 작은 가중치는 확률 교정 충실도에 중점을 둔다. 또한, 상이한 가중치(wij)는 서로 다른 클래 스 쌍 간의 판별력 향상에 초점을 맞추도록 모델의 균형을 맞춘다. 예를 들어, 레벨 2와 레벨 3 예측 간의 구분 이 매우 정확해야 하는 경우, 더 높은 가중치 W23가 그 항에 할당될 수 있다. 따라서, 확률을 반복적으로 교정하는 동시에 판별력도 극대화될 수 있다. 예를 들어, 지역별 클래스 분포(즉, '사전 분포')에 더 잘 일치하도록 확률을 조정하면, 모델이 다양한 바이라즈 레벨(BI-RADS level)을 더 잘 구 분할 수 있게 된다. 이 이중 목표(dual objective)는 예측의 정확성을 유지하는 동시에 모델의 클래스 간 구분 능력을 향상시키는 데 도움이 된다. 도 6은 본 개시의 실시예에 따른 모델 훈련의 반복적 방법을 개략적으로 도시한 도면이다. 단순화를 위해, 이 예시에서는 관련 모델의 일부, 즉 도 3의 예시에서 사용된 것과 유사한, 마지막 숨겨진 계층 (202a)과 예측 확률 A, B만 보여준다. 동작(O1)에서, 소프트맥스 로지스틱 함수(softmax logistic function)를 갖는 출력 계층을 갖는 종래의 인공 지능 모델(conventional AI model)이 제공될 수 있다(또한 도 2 참조). 동작(O2)에서, 출력 계층은 본 개시에 따라 정량화된 사후 신뢰도 함수를 포함하는 수정된 출력 계층으로 대체될 수 있다(또한, 도 2의 수정 모델(200') 참조). 상기 수정된 AI 모델은 입력 데이터 샘플 세트가 공급될 수 있으며, 각각의 클래스 확률 세트를 출력할 수 있다. 또한, 훈련 레이블(training labels)은 클래스 확률 세트에 기초하여 생성될 수 있다. 동작(O3)에서, 인공 지능(AI) 모델(즉, 종래의 소프트맥스 로지스틱 함수를 포함하는)은 훈련 레이블을 사 용하여 감독된 방식으로 훈련될 수 있다. 예를 들어, 모델은 동작(O3)에서 훈련된 모델과 일치하거나 이에 대응할 수 있다. 동작(O4)에서, 훈련된 제1 인공 지능(AI) 모델의 마지막 계층(동작(O3) 참조)을 정량화된 사후 신뢰도 함수로 대체하여 제2 인공 지능(AI) 모델이 획득될 수 있다. 제2 인공 지능(AI) 모델은 입력 데이터 샘플 세트에 대한 예측 클래스 확률을 획득하기 위해 실행될 수 있다. 입력 데이터 샘플 세트는 예측 클래스 확률로 다시 레이블 링될 수 있다. 동작(O5)에서, 제3 인공 지능(AI) 모델(third artificial intelligence (AI) model)은 다시 레이블링링된 입력 데이터 샘플 세트에 기초하여 감독된 방식으로 훈련될 수 있다. 예를 들어, 모델은 모델 또는 모델에 대응할 수 있으며, 이는 동작(O5)에서 (재-)훈련((re-)trained)될 수 있다. 이러한 방식으로, 훈련 데이터 세트의 레이블과 훈련된 모델은 실제 분류 문제를 더 정확하게 표현하기 위해 연 속적으로 개선될 수 있다. 특히, 소프트맥스 함수가 있는 기존 출력 계층을 포함하는 기존 AI 모델은 개선될 수 있다."}
{"patent_id": "10-2024-0114877", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "이 방법은 한 번 또는 여러 번 반복될 수 있다. 요약하면, 본 개시에 따른 방법은 다음 동작 중 하나 또는 여러 개를 포함할 수 있다: 1. 예를 들어 다변량 가우스(multivariate Gaussian)와 같은 파라메트릭 확률 모델(parametric probabilistic model)에 의해 주어진 클래스의 네트워크 마지막 계층의 출력을 모델링한다; 2. 클래스 분포에 사전 유병률을 가정한다; 3. 베이지안 규칙에 따라 교정된 확률을 공식화한다; 4. 선택적으로, 모델 훈련을 감독하기 위해 교정된 확률을 재사용한다. 도 7은 본 개시내용의 예에 따른 초음파 시스템(ultrasound system)의 개략도를 도시한다. 초음파 시스템은 예를 들어, 본 개시의 방법을 수행하도록 구성될 수 있다. 그러나, 본 개시에 따른 임의의 한 방법은 외부 시스템에 의해 (적어도 부분적으로) 수행될 수도 있다. 초음파 이미징 시스템(ultrasound imaging system)은, - 프로브(probe), - 프로브에 의해 수신된 신호에 기초하여 이미지(예를 들어, 환자의 의료 이미지)를 처리하기 위한 처리 유닛 (processing unit), - 처리 유닛에 연결된 제어 패널(control panel) - 제어 패널은 적어도 버튼(buttons) 및 터치 패드 (touch pad)를 포함함 -, 및 - 이미지를 시각화하기 위한 디스플레이(display)를 포함할 수 있다. 프로브는 케이블 및/또는 무선 연결(들)에 의해 처리 유닛에 연관될 수 있고, 초음파(W)를 매질 (M)로 항출할 수 있고 매질(M)로부터 초음파(W)를 수신할 수 있으며, 상기 수신된 초음파는 매질(M) 내의 확산 하는 입자에 상기 방출된 초음파의 반사에 따른 것 또는 결과이다. 디스플레이 스크린(display screen)은 처리 유닛에서 처리된 이미지를 시각화하기 위한 스크린일 수 있 다. 이미지는, 예를 들어 잠재적 병변을 포함하는 조직과 같은, 환자의 의료 이미지일 수 있다. 디스플레이(5 0)는 본 개시에 따른 인공 지능 모델의 출력, 예를 들어 예측 클래스 및 선택적으로 예측 클래스의 확률을 더 나타낼 수 있다. 한 가지 예로, 클래스는 유방 병변의 바이라즈 레벨(BI-RADS level)일 수 있다. 다른 예에서, 클래스는 갑상선, 즉 목에 있는 샘의 타이라즈 레벨(TI-RADS level)(갑상선 이미징 보고 및 데이터 시스템 (Thyroid Imaging Reporting & Data System)) 일 수 있으며, 또한 이미지에 사용된 스케일 및/또는 처리를 위 한 구성 정보 또는 터치 패드에 대한 도움말 정보 또는 상황에 맞는 제스처 도움말과 같은 기타 정보를 시 각화할 수 있다. 처리 유닛은 본 개시에 따른 방법을 수행하도록 구성될 수 있으며, 예를 들어, 본 개시의 AI 모델을 수행하 도록 구성될 수 있다. 처리 유닛은 또한 외부 장치에서 본 개시 방법의 적어도 부분적인 수행을 위해 외부 장치 로 데이터를 전송할 수도 있다. 외부 장치의 예로는 서버, 컴퓨터, 전용 워크스테이션 , 전자 제어 장치에서 획 득한 이미지를 표시하는 장치 또는 기타 외부 장치가 있다. 따라서, 본 개시에 따른 방법은 처리 유닛 또는 외 부 장치 중 적어도 하나에 의해 수행될 수 있다. 또한, 획득된 데이터에 기초하여 이미지 데이터를 구축하는 프 로세스, 즉 초음파 이미지 데이터를 컴파일하는 프로세스는 본 개시의 AI 모델을 수행하는 것과 동일한 처리 장 치에 의해 수행되거나 (적어도 부분적으로는) 다른 처리 장치에 의해 수행될 수 있다. 추가 예에 따르면, 시스템(system 10)은 적어도 하나의 처리 유닛(또는 프로세서) 및 메모리를 포함할 수 있다. 예에서, 프로세서 및 메모리 유닛은 시스템에 통합될 수 있거나 컴퓨터 또는 통신 가능하게 연결된 컴퓨 터일 수 있다. 컴퓨팅 장치의 정확한 구성 및 유형에 따라, 메모리(저장, 초음파 데이터를 평가하거나 본 명세 서에 기술된 방법을 달리 수행하기 위한 명령)는 휘발성(예: RAM), 비휘발성(예: RAM, 플래시 메모리 등) 또는 이 둘의 일부 조합일 수 있다. 또한, 시스템은 자기 또는 광 디스크 또는 테이프를 포함하지만 이에 국한되 지 않는 저장 장치들(이동식(removable) 및/또는 비-이동식(non-removable))을 포함할 수도 있다. 유사하게, 시 스템은 또한 키보드, 마우스, 펜, 음성 입력 등과 같은 입력 장치(들) 및/또는 디스플레이, 스피커, 프린터등과 같은 출력 장치(들)을 포함할 수 있다. 또한, 4G/5G, 와이파이, LAN, WAN, 포인트-대-포인트(point to point) 등과 같은 하나 이상의 통신 연결이 환경에 포함될 수 있다. 실시예들에서, 연결은 포인트대포인트 통신 들, 연결 지향 통신(connection-oriented communication)들, 비연결 통신(connectionless communication)들 등 을 설비하도록 동작 가능하다. 시스템은 전형적으로 일부 형태의 컴퓨터 판독가능 매체(computer readable media)를 포함할 수 있다. 통신 매체는 컴퓨터 판독가능 명령들, 데이터 구조들, 프로그램 모듈들, 또는 반송파 또는 기타 전송 메커니즘 과 같은 변조된 데이터 신호의 기타 데이터를 구현하고 임의의 정보 전달 매체를 포함한다. \"변조된 데이터 신 호(modulated data signal)\"라는 용어는 신호의 정보를 인코딩하는 방식으로 설정되거나 변경된 특성 중 하나 이상을 갖는 신호를 의미한다. 예를 들어, 통신 매체는 유선 네트워크 또는 직접 유선 연결과 같은 유선 매체와 음향, RF, 적외선, 마이크로파 및 기타 무선 매체와 같은 무선 매체를 포함하지만 이에 국한되지 않는다. 위의 것 중 어느 하나의 조합도 컴퓨터 판독가능 매체의 범위에 포함되어야 한다. 시스템은 하나 이상의 원격 컴퓨터에 대한 논리적 연결을 사용하여 네트워크 환경에서 작동하는 단일 컴퓨 터일 수 있다. 원격 컴퓨터는 개인용 컴퓨터, 서버, 라우터, 네트워크 PC, 피어 장치 또는 기타 공통 네트워크 노드일 수 있으며 일반적으로 위에서 설명된 요소들의 대부분 또는 모두와 언급되지 않은 요소들을 포함한다. 논리적 연결들에는 사용 가능한 통신 매체에서 지원하는 모든 방법이 포함될 수 있다. 첨구항을 포함한, 설명 전체에서 \"포함하는(comprising a)\"이라는 용어는 달리 명시되지 않는 한 \"적어도 하나 를 포함하는(comprising at least one)\"과 동의어로 이해되어야 한다. 또한, 청구항을 포함하는, 설명에 명시된 모든 범위는 달리 명시되지 않는 한 최종 가치를 포함하는 것으로 이해되어야 한다. 설명된 요소에 대한 특정 값은 당업자의 기술 중 하나에 알려진 허용된 제조 또는 산업 허용 오차 범위 내에 있는 것으로 이해되어야 하 며, \"실질적으로(substantially)\" 및/또는 \"대략(approximately)\" 및/또는 \"일반적으로(generally)\"라는 용어 를 사용하는 것은, 그러한 허용된 범위 내에 속하는 것으로 이해되어야 한다. \"기록하다\" 및 \"수신하다\" 용어들은 다르게 나타내지 않는 한 본 개시 전반에 걸쳐 동의어로 사용될 수 있다. 비록 여기에 본 개시는 특정 예들을 참조하여 설명되긴 하지만, 이 예들을 단지 본 개시의 원리들 및 적용들을 예시하는 것임을 이해해야 한다. 상세한 설명 및 예는 예시적인 것으로만 간주되며, 공개의 실제 범위는 다음 청구항에 의해 표시된다. 여기에서 특허 문서 또는 선행 기술로 확인된 기타 사항에 대한 참조는 문서 또는 기타 문제가 알려졌거나 문서 에 포함된 정보가 청구항의 우선권에 일반적인 일반 지식의 일부였다는 것을 인정하는 것으로 간주되지 않는다."}
{"patent_id": "10-2024-0114877", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시예에 따른 사후 신뢰도를 정량화하는 방법을 개략적으로 도시한다. 도 2는 본 개시의 실시예에 따른 초기 AI 모델과 제1 수정 AI 모델을 개략적으로 도시한다. 도 3은 기존 출력 계층과 예제에 따른 출력을 개략적으로 도시한다. 도 4는 두 가지 클래스 분포와 소프트맥스 로지스틱 함수의 단점을 예시를 통해 개략적으로 도시한다. 도 5는 본 개시의 실시예들에 따른 선행 유병률에 기초하여 모델의 정량화된 사후 신뢰도(예컨대, 입력 데이터 샘플의 클래스 확률)를 교정하는 반복적 방법을 개략적으로 도시한다. 도 6은 본 개시의 실시예에 따른 모델 훈련의 반복적 방법을 개략적으로 도시한다. 도 7은 본 개시내용의 예에 따른 초음파 시스템(ultrasound system)의 개략도를 도시한다."}
