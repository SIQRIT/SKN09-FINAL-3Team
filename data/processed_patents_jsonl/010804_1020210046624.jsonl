{"patent_id": "10-2021-0046624", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0140297", "출원번호": "10-2021-0046624", "발명의 명칭": "건설기계를 위한 센서 퓨전 시스템 및 센싱 방법", "출원인": "현대두산인프라코어", "발명자": "이희진"}}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "센서 퓨전 시스템에 있어서,두 개의 렌즈를 구비하고 입체 영상을 촬영하여 영상 데이터 및 제1 점군 데이터(point cloud data)를 생성하는스테레오 카메라;각각 제2 점군 데이터 및 제3 점군 데이터를 생성하는 2대의 라이다(LiDAR) 센서; 및상기 스테레오 카메라 및 상기 2대의 라이다 센서로부터 획득한 상기 영상 데이터, 상기 제1 점군 데이터, 상기제2 점군 데이터 및 상기 제3 점군 데이터에 기초하여 주변에 대한 점군 데이터 및 객체 정보를 검출하는 센싱퓨전부를 포함하는, 센서 퓨전 시스템."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 스테레오 카메라는 제1 측정 영역에 대한 상기 영상 데이터 및 상기 제1 점군 데이터를 생성하고,상기 2대의 라이다 센서 중 제1 라이다 센서는 수평면을 기준으로 제1 미리 설정된 각도만큼 상향된 방향의 제2측정 영역을 센싱하여 상기 제2 측정 영역에 대한 상기 제2 점군 데이터를 생성하고,제2 라이다 센서는 상기 수평면을 기준으로 제2 미리 설정된 각도만큼 하향된 방향의 제3 측정 영역을 센싱하여상기 제3 측정 영역에 대한 상기 제3 점군 데이터를 생성하는, 센서 퓨전 시스템."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 센싱퓨전부는,서로 상이한 좌표계를 가지는 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 하나의통일된 좌표계의 데이터로 변환하고,변환된 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 통합하여 상기 제2 측정 영역과 상기 제3 측정 영역이통합된 제4 측정 영역에 대한 제4 점군 데이터를 획득하고,변환된 상기 제1 점군 데이터 및 상기 제4 점군 데이터를 통합하여, 상기 제1 측정 영역과 상기 제4 측정 영역을 포함하는 제5 측정 영역에 대한 제5 점군 데이터를 획득하고,상기 제5 측정 영역에 대해서 건설 기계가 요구하는 그리드(grid)에 맞추어 등간격으로 그리딩을 수행하여 상기제5 점군 데이터를 가공함으로써 균등한 간격 및 밀도를 가지는 제6 점군 데이터를 획득하는, 센서 퓨전시스템."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 센싱퓨전부는,상기 제2 측정 영역과 상기 제3 측정 영역 중에 중복된 영역에서는 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 보간(interpolation) 처리하여 상기 제4 점군 데이터를 획득하는, 센서 퓨전 시스템.공개특허 10-2022-0140297-3-청구항 5 제 4 항에 있어서, 상기 센싱퓨전부는,상기 제1 측정 영역과 상기 제4 측정 영역에 기초하여 직사각형 형태의 상기 제5 측정 영역을 설정하고,상기 제5 측정 영역중에서 상기 제1 측정 영역과 상기 제4 측정 영역이 겹치는 영역은 해당 영역의 상기 제1 점군 데이터와 상기 제4 점군 데이터를 보간 처리하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하고,상기 제5 측정 영역중에서 상기 제1 측정 영역에만 포함되는 영역은 해당 영역의 상기 제1 점군 데이터를 그대로 사용하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하고,상기 제5 측정 영역중에서 상기 제4 측정 영역에만 포함되는 영역은 해당 영역의 상기 제4 점군 데이터를 그대로 사용하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하고, 상기 제5 측정영역중에서 상기 제1 측정 영역 및 상기 제4 측정 영역 모두에 포함되지 않는 영역은 해당 영역주변부의 상기 제1 점군 데이터 및 상기 제4 점군 데이터를 외삽(extrapolation) 처리하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하는, 센서 퓨전 시스템."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 외삽 처리는 머신러닝 기법을 적용하여 수행하는, 센서 퓨전 시스템."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 3 항에 있어서, 상기 센싱퓨전부는,상기 영상 데이터를 전처리하고,전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하고,검출된 상기 객체에 대해 상기 제6 점군 데이터를 이용하여 위치 좌표, 거리 정보를 획득하는, 센서 퓨전 시스템."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 센싱퓨전부는,머신러닝 기법을 적용하여 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하되, 상기 머신러닝을 수행하는 인공지능을 학습시키기 위하여 덤프트럭의 덤프베드 형상 및 사람, 차량을 포함하는장애물에 대한 이미지 정보를 학습 데이터로 제공하는, 센서 퓨전 시스템."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "영상 데이터 및 제1 점군 데이터를 출력하는 스테레오 카메라 및 제2 점군 데이터 및 제3 점군 데이터를 출력하는 2대의 라이다(LiDAR) 센서가 구비된 센서 퓨전 시스템에서의 측정 영역에 대한 객체 검출 및 점군 데이터를생성하는 센싱 방법에 있어서,상기 영상 데이터, 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 획득하는 동작;상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터에 기초하여 상기 측정 영역에 대한 제6점군 데이터를 획득하는 동작; 상기 영상 데이터를 전처리하는 동작;공개특허 10-2022-0140297-4-전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하는 동작; 및검출된 상기 객체의 위치 좌표 및 거리 정보를 상기 제6 점군 데이터를 이용하여 획득하는 동작을 포함하는, 센싱 방법."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 영상 데이터 및 상기 제1 점군 데이터는 제1 측정 영역에 대해 획득되고,상기 제2 점군 데이터는 수평면을 기준으로 제1 미리 설정된 각도만큼 상향된 방향의 제2 측정 영역을 제1 라이다 센서로 센싱하여 획득되고,상기 제3 점군 데이터는 상기 수평면을 기준으로 제2 미리 설정된 각도만큼 하향된 방향의 제3 측정 영역을 제2라이다 센서로 센싱하여 획득되는, 센싱 방법."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 측정 영역에 대한 제6 점군 데이터를 획득하는 동작은,서로 상이한 좌표계를 가지는 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 하나의통일된 좌표계의 데이터로 변환하는 동작;변환된 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 통합하여 상기 제2 측정 영역과 상기 제3 측정 영역이통합된 제4 측정 영역에 대한 제4 점군 데이터를 획득하는 동작;변환된 상기 제1 점군 데이터 및 상기 제4 점군 데이터를 통합하여, 상기 제1 측정 영역과 상기 제4 측정 영역을 포함하는 제5 측정 영역에 대한 제5 점군 데이터를 획득하는 동작;상기 제5 측정 영역에 대해서 건설 기계가 요구하는 그리드(grid)에 맞추어 등간격으로 그리딩을 수행하여 상기제5 점군 데이터를 가공함으로써 균등한 간격 및 밀도를 가지는 제6 점군 데이터를 획득하는 동작을 포함하는,센싱 방법."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 제4 점군 데이터를 획득하는 동작은,상기 제2 측정 영역과 상기 제3 측정 영역 중에 중복된 영역에서는 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 보간(interpolation) 처리하여 상기 제4 점군 데이터를 획득하는, 센싱 방법."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 제5 점군 데이터를 획득하는 동작은,상기 제1 측정 영역과 상기 제4 측정 영역에 기초하여 직사각형 형태의 상기 제5 측정 영역을 설정하는 동작;상기 제5 측정 영역중에서 상기 제1 측정 영역과 상기 제4 측정 영역이 겹치는 영역은 해당 영역의 상기 제1 점군 데이터와 상기 제4 점군 데이터를 보간 처리하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하는 동작;상기 제5 측정 영역중에서 상기 제1 측정 영역에만 포함되는 영역은 해당 영역의 상기 제1 점군 데이터를 그대공개특허 10-2022-0140297-5-로 사용하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하는 동작;상기 제5 측정 영역중에서 상기 제4 측정 영역에만 포함되는 영역은 해당 영역의 상기 제4 점군 데이터를 그대로 사용하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하는 동작; 및 상기 제5 측정영역중에서 상기 제1 측정 영역 및 상기 제4 측정 영역 모두에 포함되지 않는 영역은 해당 영역주변부의 상기 제1 점군 데이터 및 상기 제4 점군 데이터를 외삽(extrapolation) 처리하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하는 동작을 포함하는, 센싱 방법."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 외삽 처리는 머신러닝 기법을 적용하여 수행하는, 센싱 방법."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9 항에 있어서,상기 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하는 동작은,머신러닝 기법을 적용하여 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하는 동작을 포함하되, 상기 머신러닝을 수행하는 인공지능을 학습시키기 위하여 덤프트럭의 덤프베드 형상 및 사람, 차량을 포함하는장애물에 대한 이미지 정보를 학습 데이터로 제공하는, 센싱 방법."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "건설기계에 있어서,제1항 내지 제8항에 따른 센서 퓨전 시스템에 기초하여 주변 환경을 센싱하는, 건설기계."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 프로그램에 있어서,프로세서에 의해 실행될 때, 제9항 내지 제15항 중 어느 하나의 방법에 따른 동작을 수행하는 컴퓨터 프로그램."}
{"patent_id": "10-2021-0046624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터 판독가능 저장매체에 있어서,프로세서에 의해 실행될 때, 제9항 내지 제15항 중 어느 하나의 방법에 따른 동작을 수행하는 프로그램이 저장된 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시 예들은 건설기계에서 사용되는 센서 퓨전 시스템 및 센서 퓨전 시스템을 이용한 센싱 방법 및 센 서 퓨전 시스템이 구비된 건설기계에 관한 것으로, 센서 퓨전 시스템은 두 개의 렌즈를 구비하고 입체 영상을 촬 영하여 영상 데이터 및 제1 점군 데이터(point cloud data)를 생성하는 스테레오 카메라, 각각 제2 점군 데이터 및 제3 점군 데이터를 생성하는 2대의 라이다(LiDAR) 센서 및 상기 스테레오 카메라 및 상기 2대의 라이다 센서 로부터 획득한 상기 영상 데이터, 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터에 기초 하여 주변에 대한 점군 데이터 및 객체 정보를 검출하는 센싱퓨전부를 포함할 수 있다."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 다양한 실시 예들은 건설기계에서 사용되는 센서 퓨전 시스템 및 센서 퓨전 시스템을 이용한 센싱 방 법 및 센서 퓨전 시스템이 구비된 건설기계에 관한 것이다."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "굴착기는 주로 토사를 굴착하는 장비로서, 토사 적재, 건물 기초 작업, 택지 조성 작업 및 화물 적재 등과 같은 다양한 작업을 할 수 있다. 그리고 휠로더는 토목공사 현장이나 광산에서 흙이나 모래, 골재 등을 옮기는 작업 을 할 수 있다. 굴착기 또는 휠로더와 같은 건설기계는 작업자에 의해 조작되는 것이 일반적이나, 최근에는 제 어 및 센싱 기술의 발달에 따라 작업자 없이 무인 운전이 가능한 건설기계에 대한 개발이 이루어지고 있다. 건설기계, 예를 들어 굴착기의 무인 운전이 가능하기 위해서는 전방의 지형, 버켓 내부의 적재물 형상, 협업 덤 프트럭의 덤프베드 위치, 덤프베드의 적재물 형상 및 장비 전방 장애물을 검출하는 등의 주변 작업 환경, 작업 공간 및 객체에 대한 정보를 얻기 위한 센싱 작업이 필요하다. 건설기계는 탑재한 복수의 센서 장치들을 이용하 여, 이러한 센싱 작업을 수행할 수 있으나, 종래의 센서는 단일 센서 기반으로 동작하여 특정 상황에서는 센서 가 작동 불능이 되거나 원하는 정보를 제공할 수 없는 상황이 발생할 수 있다. 예를 들면, 카메라 기반의 센서 를 생각해 보면, 입체데이터를 검출할 수 없기 때문에 장애물 검출 정도의 기능은 사용할 수 있으나, 지형 데이 터는 취득할 수 없어 건설기계의 자율 작업을 지원하기 위한 충분한 센싱 기능을 제공할 수 없다는 문제가 있다."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해소하고자 복수 개의 센서가 결합되어 주변 환경을 인지하는 센서 퓨전 시스템을 제안하고자 한다. 본 개시에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 다양한 실시 예에 따른 센서 퓨전 시스템은 두 개의 렌즈를 구비하고 입체 영상을 촬영하여 영상 데 이터 및 제1 점군 데이터(point cloud data)를 생성하는 스테레오 카메라, 각각 제2 점군 데이터 및 제3 점군 데이터를 생성하는 2대의 라이다(LiDAR) 센서 및 상기 스테레오 카메라 및 상기 2대의 라이다 센서로부터 획득 한 상기 영상 데이터, 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터에 기초하여 주변 에 대한 점군 데이터 및 객체 정보를 검출하는 센싱퓨전부를 포함할 수 있다. 본 개시의 다양한 실시 예에 따른 영상 데이터 및 제1 점군 데이터를 출력하는 스테레오 카메라 및 제2 점군 데 이터 및 제3 점군 데이터를 출력하는 2대의 라이다(LiDAR) 센서가 구비된 센서 퓨전 시스템에서의 측정 영역에 대한 객체 검출 및 점군 데이터를 생성하는 센싱 방법은 상기 영상 데이터, 상기 제1 점군 데이터, 상기 제2 점 군 데이터 및 상기 제3 점군 데이터를 획득하는 동작, 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제 3 점군 데이터에 기초하여 상기 측정 영역에 대한 제6 점군 데이터를 획득하는 동작, 상기 영상 데이터를 전처 리하는 동작, 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하는 동작 및 검출된 상기 객체의 위치 좌 표 및 거리 정보를 상기 제6 점군 데이터를 이용하여 획득하는 동작을 포함할 수 있다."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예들에 따른 건설기계에 구비되는 센서 퓨전 시스템은 자율작업과 장애물 검출을 동시에 가능하 게 하며, 지형 검출 시의 해상도를 비약적으로 향상시킬 수 있다. 본 개시의 실시 예들에 따른 건설기계는 센서 퓨전 시스템의 구비로 주변 환경에 대한 인식력이 비약적으로 높 아짐에 따라 자율작업의 정확도 향상, 작업효율 향상을 기대할 수 있다. 본 개시의 실시 예들에 따른 건설기계는 구비되는 센서 퓨전 시스템에 기초하여 장애물과의 거리를 정확하게 파 악할 수 있어 능동안전 대응이 가능할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시물의 이점 및 특징, 그리고 그것들을 달성하는 장치 및 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시물은 이하에서 개시되는 실시 예들에 한정되는 것 이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시 예들은 본 개시물의 개시가 완전하도록 하며,"}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 개시물이 속하는 기술분야에서 통상의 지식을 가진 자에게 개시물의 범주를 완전하게 알려주기 위해 제공되 는 것이며, 본 개시물은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 하나의 구성 요소가 다른 구성 요소와 \"연결된(connected to)\" 또는 \"커플링된(coupled to)\" 이라고 지칭되는 것은, 다른 구성 요소와 직접 연결 또는 커플링된 경우 또는 중간에 다른 구성 요소를 개재한 경우를 모두 포함 한다. 반면, 하나의 구성 요소가 다른 구성 요소와 \"직접 연결된(directly connected to)\" 또는 \"직접 커플링된 (directly coupled to)\"으로 지칭되는 것은 중간에 다른 구성 요소를 개재하지 않은 것을 나타낸다. \"및/또는\" 은 언급된 아이템들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서 사용된 용어는 실시 예들을 설명하기 위한 것이며 본 개시물을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성 요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 비록 제 1, 제 2 등이 다양한 구성 요소들을 서술하기 위해서 사용되나, 이들 구성 요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성 요소를 다른 구성 요소와 구별하기 위하여 사용하 는 것이다. 따라서, 이하에서 언급되는 제 1 구성 요소는 본 개시물의 기술적 사상 내에서 제2 구성 요소 일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시물이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또 는 과도하게 해석되지 않는다. 본 실시 예에서 사용되는 '부' 또는 '모듈'이라는 용어는 소프트웨어 또는 FPGA또는 ASIC과 같은 하드웨어 구성 요소를 의미하며, '부' 또는 '모듈'은 어떤 역할들을 수행한다. 그렇지만 '부' 또는 '모듈'은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '부' 또는 '모듈'은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '부' 또는 '모듈'은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성 요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수 들을 포함할 수 있다. 구성요소들과 '부' 또는 '모듈'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '부' 또는 '모듈'들로 결합되거나 추가적인 구성요소들과 '부' 또는 '모듈'들로 더 분리될 수 있다. 본 개시물의 몇몇 실시 예들과 관련하여 설명되는 방법 또는 알고리즘의 단계는 프로세서에 의해 실행되는 하드 웨어, 소프트웨어 모듈, 또는 그 2 개의 결합으로 직접 구현될 수 있다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 디스크, 착탈형 디스크, CD-ROM, 또는 당업 계에 알려진 임의의 다른 형태의 기록 매체에 상주할 수도 있다. 예시적인 기록 매체는 프로세서에 커플링되며, 그 프로세서는 기록 매체로부터 정보를 판독할 수 있고 저장 매체에 정보를 기입할 수 있다. 다른 방법으로, 기 록 매체는 프로세서와 일체형일 수도 있다. 프로세서 및 기록 매체는 주문형 집적회로(ASIC) 내에 상주할 수도 있다. ASIC는 사용자 단말기 내에 상주할 수도 있다. 도 1은 본 개시의 다양한 실시 예에 따른 자율 작업 시스템을 도시한 도면이다. 도 1을 참조하면, 다양한 실시 예에 따른 자율 작업 시스템은 관제센터와 적어도 하나의 건설 기계 (또는 자율 작업 건설 기계)(120 내지 150)를 포함할 수 있다. 다양한 실시 예에 따르면, 건설 기계(120 내지 150)는 토목공사나 건축공사 현장에서 작업을 수행하는 기계를 지칭하는 것으로, 도 1을 통해 도시된 바와 같이, 믹서트럭(mixer truck) , 덤프 트럭(dump truck), 도저(dozer), 굴착기(excavator)를 포함할 수 있다. 그러나, 이는 예시적일 뿐, 건설 기계는 굴삭기 (drilling machine), 크레인(crane), 휠로더(wheel loader), 스크레이퍼(scraper) 등과 같은 다양한 기계를 포 함할 수 있다. 일 실시 예에 따르면, 건설 기계(120 내지 150)는 관제센터로부터 수신하는 작업 지시에 따라, 운전자에 의해 작업을 수행할 수 있다. 다른 일 실시 예에 따르면, 건설 기계(120 내지 150)는 운전자없이 자율적으로 작 업을 수행할 수 있다. 작업 지시는 해당 건설 기계가 작업을 해야 하는 작업 영역, 작업 영역에서 수행해야 하 는 작업 등과 관련된 정보를 포함할 수 있다. 예를 들어, 건설 기계(120 내지 150)는 작업 지시에 따라 사용자 의 조작없이 또는 사용자의 조작에 기초하여 작업 영역으로 이동하여 작업을 수행할 수 있다. 건설 기계(120 내지 150)는 다양한 센서를 구비할 수 있으며, 센서를 통해 획득되는 정보에 기초하여 건설 기계 의 상태 및/또는 건설 기계의 주변 환경을 감지하고, 감지 결과를 작업 수행에 고려할 수 있다. 다양한 실시 예에 따르면, 관제센터는 작업 현장에 투입되는 적어도 하나의 건설 기계(120 내지 150)를 관 리하는 시스템일 수 있다. 일 실시 예에 따르면, 관제센터는 적어도 하나의 건설 기계(120 내지 150)로 작 업을 지시할 수 있다. 예를 들어, 관제센터는 작업 영역 및 해당 작업 영역에서 수행해야 하는 작업을 정 의한 작업 지시를 생성하고, 이를 적어도 하나의 건설 기계(120 내지 150)로 전송할 수 있다. 도 2는 본 개시의 다양한 실시 예에 따른 센서 퓨전(sensor fusion) 시스템을 구비한 굴착기를 도시한 도 면이다. 이하 설명에서, 굴착기는 건설 기계의 일 예로 설명하나 본 개시가 굴착기로 한정하는 것은 아니다. 또한, 도 2를 통해 설명되는 굴착기는 도 1에 도시된 굴착기일 수 있다. 도 2를 참조하면, 굴착기는 이동 역할을 하는 하부체, 하부체에 탑재되어 360도 회전하는 상부 체 및 상부체의 전방에 결합된 프론트 작업 장치로 구성될 수 있다. 그러나, 이는 예시적일 뿐, 본 개시의 실시 예가 이에 한정되는 것이 아니다. 예컨대, 전술한 굴착기의 구성요소 외에 하나 이상의 다 른 구성 요소(예: 하부체의 후방에 결합된 플레이드 등)가 추가될 수도 있다. 다양한 실시 예에 따르면, 상부체는 운전자가 탑승하여 조작할 수 있는 운전실이 내장되고 동력발생 장치(예: 엔진)가 장착될 수 있는 내부공간(미도시)이 구비될 수 있다. 운전실은 작업 영역과 가까운 부분 에 구비될 수 있다. 작업 영역은 굴착기가 작업을 하는 공간으로서, 굴착기 전방에 위치한다. 예를 들어, 탑승한 운전자가 확보된 시야 아래에서 작업을 진행하고, 프론트 작업 장치가 장착되는 위치를 고려 하여 운전실은, 도 2에서와 같이 작업 영역과 근접하면서 상부체에서 일측으로 편향된 곳에 위치할 수 있다. 다양한 실시 예에 따르면, 프론트 작업 장치는 상부체의 상면에 장착되고, 토지 굴착이나 하중이 큰 물체의 운반 등의 작업을 진행하기 위한 장치일 수 있다. 일 실시 예에 따르면, 프론트 작업 장치는 상부체에 회전 가능하게 결합되는 붐, 붐을 회전시키는 붐 실린더, 붐의 선단부에 회전 가능하게 결합되는 암, 암을 회전시키는 암 실린더, 암의 선단부에 회전 가능하게 결합되 는 버켓, 버켓을 회전시키는 버켓 실린더를 포함할 수 있다. 굴착기의 작업시에는 붐(23 1)의 일단과 암의 일단 그리고 버켓의 일단에서 각각 개별적으로 회전 운동하여 버켓이 도달할 수 있는 영역을 최대화할 수 있다. 전술한 프론트 작업 장치는 많은 문서에서 공지되어 있는 바, 이에 대 한 상세한 설명을 생략한다. 다양한 실시 예에 따르면, 하부체는 상부체의 하면에 결합될 수 있다. 하부체는 바퀴를 사용하 는 휠 타입 또는 무한궤도를 사용하는 크롤러 타입으로 형성된 주행체를 포함할 수 있다. 주행체는 동력발생 장 치에 의해 발생되는 동력을 구동력으로 하여 굴착기의 전후좌우 움직임을 구현할 수 있다. 일 실시 예에 따르면, 하부체와 상부체는 센터 조인트(center joint)에 의해 회전 가능하게 결합될 수 있다. 다양한 실시 예에 따르면, 굴착기는 굴착기의 상태와 관련된 정보 및/또는 주변 환경과 관련된 정보 를 수집하기 위한 센서 퓨전 시스템을 구비할 수 있다. 도 2의 예에서 센서 퓨전 시스템의 센싱 장치는 굴 착기의 붐에 구비되는 것으로 도시되어 있으나, 이는 하나의 실시 예이며 센서 퓨전 시스템의 센싱 장치는 그 사용 용도 및 측정하고자 하는 주변 환경 등에 따라 굴착기의 다양한 위치에 구비될 수 있 다. 일 실시 예에 따라, 센서 퓨전 시스템의 센싱 장치는 굴착기 또는 휠로더의 전방과 버켓, 그리고 협업 트럭의 덤프베드를 가장 측정하기 유리한 위치에 설치될 수 있다. 예를 들면, 굴착기의 경우에는 붐 하단 의 측면 또는 운전실 상단 등에 센서 퓨전 시스템의 센싱 장치가 설치될 수 있다. 도 2의 예에서는 센서 퓨전 시스템을 구비한 굴착기에 대하여 설명하였으나 센서 퓨전 시스템은 임의의 건설 기 계에 구비될 수 있다. 다양한 실시 예에 따라, 구비된 센서 퓨전 시스템은 건설 기계(예: 굴착기) 전방 인지기능을 담당할 수 있어, 전방 지형 검출을 통해 자동화/무인화 작업을 가능하게 하며, 실시간으로 관제센터에 현재 지형을 업데이 트하여 도면에 반영할 수 있도록 할 수 있다. 또한 작업 중에는 버켓 적재물의 형상을 검출하여 현재 작업량 또 는 작업 효율을 파악하여 작업 계획 수립/수정을 위한 정보로 사용하도록 할 수 있다. 그리고 협업 덤프트럭의 덤프베드 위치인식 및 덤프베드 적재물의 형상 검출을 가능하게 하여 자동 상차 기능을 구현할 수 있다. 그리고 카메라 영상정보를 기반으로 장애물의 검출과 종류 분류를 구현하고 센서 퓨전 정보를 기반으로 장애물과의 정 확한 거리를 파악하여 자동 정지, 회피와 같은 능동 안전기능 구현이 가능하도록 할 수 있다. 도 3은 본 개시의 다양한 실시 예에 따른 건설 기계를 개념적으로 나타낸 도면이다. 도 3을 참조하면, 건설 기계는 프로세서, 통신 장치, 저장 장치, 센서 장치 및 작업 제어 장치를 포함할 수 있다. 그러나, 이는 예시적일 뿐, 본 개시의 실시 예가 이에 한정되는 것이 아니다. 예컨대, 전술한 건설 기계의 구성요소 중 적어도 하나가 생략되거나 또는 하나 이상의 다른 구성 요소(예: 입력 장치, 출력 장치 등)가 건설 기계의 구성으로 추가될 수도 있다. 다양한 실시 예에 따르면, 프로세서는 건설 기계의 전반적인 동작을 제어하도록 구성될 수 있다. 일 실시 예에 따르면, 프로세서는, 저장 장치에 저장된 소프트웨어(예를 들어, 프로그램)를 실행하여, 프로세서에 연결된 구성 요소(예를 들어, 통신 장치, 저장 장치, 센서 장치 또는 작업 제 어 장치) 중 적어도 하나의 구성 요소를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 예를 들어, 데이터 처리 또는 연산의 적어도 일부로서, 프로세서는 다른 구성 요소로부터 수신된 명 령 또는 데이터를 저장 장치에 저장하고, 저장 장치에 저장된 명령 또는 데이터를 처리하고, 결과 데 이터를 저장 장치에 저장할 수 있다. 프로세서는 메인 프로세서 및 메인 프로세서와 독립적으로 또는 함께 운영 가능한 보조 프로세서로 구성될 수 있다. 일 실시 예에 따르면, 프로세서는 전술한 구성 요소 (예를 들어, 통신 장치, 저장 장치, 센서 장치 또는 작업 제어 장치)와 CAN(Controller Area Network) 통신을 수행할 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 다양한 실시 예에 따르면, 통신 장치는 무선 통신 기술을 이용하여 외부 장치와 데이터를 송수신할 수 있 다. 외부 장치는 관제 센터 및 다른 건설 기계(120 내지 150)를 포함할 수 있다. 예컨대, 통신 장치 는 외부 장치로부터 작업 지시를 수신하고, 외부 장치로 작업과 관련된 정보(예: 작업 결과)를 전송할 수 있다. 이때, 통신 장치가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블 루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA),ZigBee, NFC(Near Field Communication) 등이 있다. 또한, 통신 장치는 또한, 건설 기계의 위치를 인지할 수 있는 적어도 하나의 측위 장치를 포함할 수 있다. 다양한 실시 예에 따르면, 저장 장치는 건설 기계의 적어도 하나의 구성요소(예를 들어, 프로세서 , 통신 장치, 센서 장치 또는 작업 제어 장치)에 의해 사용되는 다양한 데이터를 저장할 수 있다. 일 실시 예에 따르면, 저장 장치는 건설 기계의 제원(예: 모델명, 고유번호, 기본 사양), 맵 데이터 등을 저장할 수 있다. 예를 들어, 저장 장치는 비휘발성 메모리 장치 및 휘발성 메모리 장치 중 적어도 하나를 포함할 수 있다. 다양한 실시 예에 따르면, 센서 장치는 다양한 센서들을 이용하여 건설 기계의 상태, 건설 기계(30 0)의 작업 영역 또는 건설 기계 주변의 장애물 중 적어도 하나와 관련된 정보를 수집할 수 있다. 센서 장 치는 이후 상세하게 설명한 센서 퓨전 시스템을 포함할 수 있다. 다양한 실시 예에 따르면, 작업 제어 장치는 건설 기계의 작업을 제어할 수 있다. 예를 들어, 작업 제어 장치는 작업 계획 수립부 및 구동 제어부를 포함할 수 있다. 다양한 실시 예에 따르면, 작업 제어 장치는 관제 센터 및/또는 건설 기계로부터 작업 지시를 수신할 수 있다. 일 실시 예에 따르면, 작업 지시는 작업 영역 및 해당 작업 영역에서 수행되어야 하는 작업 종류(또는 작업 내 용)를 포함할 수 있다. 작업 종류는 건설 기계에 의해 수행될 수 있는 굴삭(digging) 작업, 호파기 (trench) 작업, 평탄화 (grading) 작업, 파쇄(breaking) 작업, 굴삭한 토사를 상차시키는 덤핑(dumping) 작업, 상부체를 회전시키는 스윙(swing) 작업, 건설 기계의 위치를 변경하는 이동(moving) 작업 등을 포함 할 수 있다. 또한, 작업 영역은 작업 현장의 일부분으로, 적어도 하나의 작업이 수행되어야 하는 영역(예: 굴삭 영역, 평탄화 영역 등)일 수 있다. 추가적으로, 작업 지시는 작업 현장으로부터 벗어나 대기하고 있는 건설 기 계를 작업 현장으로 안내하는 이동 경로를 포함할 수 있다. 이러한 경우, 건설 기계는 이동 경로에 기초하여 대기 장소를 출발하여 작업 현장으로 이동할 수 있다. 또한, 작업 제어 장치(또는 작업 계획 수립부)는, 작업 계획의 일부로, 작업 영역에서 건설 기계 가 수행하고자 하는 작업의 처리 순서를 결정할 수 있다. 예를 들어, 작업 현장 내의 복수의 작업 영역에 대한 작업을 지시받은 경우, 작업 제어 장치(또는 작업 계획 수립부)는 우선 순위로 처리해야하는 작 업 영역과 차순위로 처리해야하는 작업 영역을 결정할 수 있다. 다른 예로, 하나의 작업 영역에서 복수의 작업 을 지시받은 경우, 작업 제어 장치(또는 작업 계획 수립부)는 작업 영역에서 우선순위로 처리할 작업 과 차순위로 처리할 작업을 계획할 수 있다. 그러나, 이는 예시적일 뿐, 본 개시가 이에 한정되는 것은 아니다. 예컨대, 작업 계획의 적어도 일부, 예를 들어, 작업의 처리 순서는 관제 센터에 의해 지정되어 건설 기계 로 제공될 수도 있다. 다양한 실시 예에 따르면, 작업 제어 장치(또는 작업 계획 수립부)는, 작업 계획에 기초하여, 작업 처리를 위한 작업 경로를 획득 결정할 수 있다. 작업 경로는 작업 영역(또는 작업 처리 지점)으로 건설 기계 가 이동해야 하는 경로를 나타낼 수 있다. 다양한 실시 예에 따르면, 작업 제어 장치(또는 구동 제어부)는 작업 경로에 기초하여, 건설 기계 의 운동 궤적을 결정할 수 있다. 운동 궤적은 작업 경로를 따라 이동하기 위한 건설 기계의 움직임을 의미할 수 있다. 일 실시 예에 따르면, 작업 제어 장치(또는 구동 제어부)는 작업 경로에 포함된 중 간점들 가운데 건설 기계와 가까운 중간점을 운동 궤적의 일부로 결정할 수 있다. 다양한 실시 예에 따르면, 작업 제어 장치(또는 구동 제어부)는 운동 궤적에 기초하여 건설 기계 의 조향 정보를 획득할 수 있다. 조향 정보는 조향 속도, 조향 각도 등을 포함할 수 있다. 예를 들어, 작 업 제어 장치(또는 구동 제어부)는 센서 장치(예: 관성 센서)를 통해 획득된 센서 정보(예: 건 설 기계의 상태와 관련된 정보) 또는 통신 장치(예: RTK GNSS 모듈)를 통해 획득되는 정보(예: 상기 건설 기계의 위치 및/또는 방향과 관련된 정보) 중 적어도 하나에 기초하여 건설 기계(예: 하부체 )의 위치 및 방향을 결정할 수 있으며, 이를 결정된 중간점의 위치 및 방향과 비교하여 조향 정보를 획득 할 수 있다. 다양한 실시 예에 따르면, 작업 제어 장치(또는 구동 제어부)는 조향 정보에 기초하여 건설 기계 를 제어하기 위한 제어 정보를 결정할 수 있다. 일 실시 예에 따르면, 작업 제어 장치(또는 구동 제 어부)는 건설 기계의 제원에 기초하여 조향 정보를 구동 제어 값으로 변환할 수 있다. 예를 들어, 작업 제어 장치(또는 구동 제어부)는 건설 기계의 제원에 기초하여, 조향 정보를 건설 기계 의 주행체에 대한 속도 제어 값 및 방향 제어 값으로 변환할 수 있다. 또한, 작업 제어 장치(또는 구동 제 어부)는 변환된 제어 값에 따라 건설 기계가 구동되도록 좌측 및 우측 주행체(예: 바퀴, 무한궤도 트 랙)를 제어할 수 있다. 전술한 실시 예에서는 프로세서와 작업 제어 장치가 서로 분리된 구성으로 설명하였으나, 이는 예시 적일 뿐, 본 개시가 이에 한정되는 것이 아니다. 예를 들어, 작업 제어 장치와 프로세서는 하나의 구 성으로 설계될 수 있다. 또한, 전술한 프로세서의 구성 중 적어도 일부는 굴착기와 분리된 구성으로 설계 될 수 있다. 예를 들어, 프로세서의 구성 중 적어도 일부는 외부 장치의 구성으로 구성될 수도 있다. 이하에서는 센서 장치의 일부가 될 수 있는 센서 퓨전 시스템에 대하여 좀 더 상세히 설명한다. 도 4는 본 개시의 다양한 실시 예에 따른 센서 퓨전 시스템의 구성을 도시한 도면이다. 도 4를 참조하면, 센서 퓨전 시스템은 두 개의 렌즈를 구비한 스테레오 카메라, 2대의 라이다(LiDAR) 센서 (420, 430) 및 센싱퓨전부로 구성될 수 있다. 스테레오 카메라는 입체 영상을 찍을 수 있는 카메라로, 좌우로 일정 간격으로 떨어져 있는 두 개의 렌즈 를 이용하여 인간의 눈을 모사하여 원근감에 의해 입체적으로 보일 수 있는 입체 영상을 찍을 수 있는 카메라이 다. 스테레오 카메라를 입체 영상을 촬영하여 영상 데이터 및 점군 데이터(point cloud data)를 생성할 수 있다. 라이다 센서는 점군 데이터만을 생성할 수 있다. 점군 데이터는 신호를 보내서 돌아오는 시간에 기초하여 신호 가 반사되어 온 점까지의 거리 정보를 포함하고 있는 데이터일 수 있다. 즉, 점군 데이터의 각 점은 신호를 반 사하는 물체가 있는 곳이 될 수 있으며 해당 점까지의 거리 정보가 함께 포함될 수 있다. 일 실시 예에 따라, 각 라이다 센서는 스테레오 카메라의 렌즈 아래 부분에 설치되어 스테레오 카메라 와 거의 동일한 센싱 방향을 가지도록 할 수 있다. 또한, 일 실시 예에 따라, 1대의 라이다 센서는 센싱 방향이 수평을 기준으로 특정 각도만큼 하향되도록 설치되고, 나머지 1대의 라이다 센서는 센싱 방향이 수평을 기준으로 특정 각도만큼 상향되도록 설치할 수 있다. 예를 들면, 1대의 라이다 센서의 센싱 방향은 수평을 기준 으로 25도만큼 하향되도록 설치되고, 나머지 1대의 라이다 센서의 센싱 방향은 수평을 기준으로 25도만큼 상향 되도록 설치될 수 있다. 이렇게 설치함으로써 2대의 라이다 센서가 측정하는 측정 영역이 상부와 하부로 나누어 질 수 있다. 이때 2대의 라이다 센서가 측정하는 각 측정 영역이 일부 겹치도록 상향 각도 및 하향 각도를 조정 할 수 있는데, 이론적으로는 겹치지 않도록 해도 무방하나 실제로는 사각 영역의 발생을 없애기 위하여 일부 겹 치도록 설치하는 것이 좋을 수 있다. 2대의 라이다 센서의 센싱 방향을 상부와 하부로 나누어 설치하는 이유는 현재 출시되는 대부분의 라이다 센서 가 수평 측정범위는 120도 이상으로 매우 넓은 반면에 수직 측정범위는 30도 미만으로 매우 좁기 때문이다. 대 부분의 상용 라이다 센서는 자율주행 차량에 설치될 목적으로 출시되기 때문에 위와 같은 넓은 수평 측정범위와 좁은 수직 측정범위를 가질 수 있다. 그런데 건설기계의 자율작업 환경에 적용하기 위해서는 수직 측정범위를 현재의 상용 라이다 센서가 제공하는 범위 이상으로 확장하여야 하기 때문에 2대의 라이다 센서를 이용하여 수 직 측정범위를 확장하는 것을 제안한다. 일 실시 예에 따라, 스테레오 카메라와 2대의 라이다 센서로 구성되는 센서 퓨전 시스템의 센싱 장치는 브라켓 에 설치될 수 있으며, 이 경우 브라켓은 스테레오 카메라와 라이다 센서의 각도를 미세 조정할 수 있는 장치를 구비할 수 있고, 관제센터 또는 운전자의 제어에 따라, 스테레오 카메라와 라이다 센서의 각도를 조정할 수 있다. 센싱퓨전부는 센싱 퓨전 시스템의 센싱 장치들(410, 420, 430)으로부터 획득한 데이터를 기초로 객체 검출 정보 및 점군 데이터(point cloud data, PCD)를 출력할 수 있다. 센싱퓨전부는 적어도 하나의 프로세서로 구현될 수 있으며, 적어도 하나의 프로세서를 이용하여 프로그램 또는 알고리즘을 실현함으로써 센싱 장치들 (410, 420, 430)로부터 획득한 센싱 정보를 처리하여 정밀하고 정확한 센싱 데이터를 생성할 수 있다. 일 실시 예에 따라, 센싱퓨전부는 도 3에 도시된 프로세서에 구현될 수도 있으나 다른 일 실시 예에 따라, 프 로세서와 상이한 별도의 적어도 하나의 프로세서로 구현될 수도 있다. 도 5는 본 발명의 다양한 실시 예들에 따른 센싱퓨전부의 동작을 도시한 흐름도이다. 도 5를 참조하면, 동작 S510에서, 센싱퓨전부는 연결될 복수의 센싱 장치들(410, 420, 430)로부터 센싱 데 이터를 획득할 수 있다. 다양한 실시 예들에 따르면, 센싱퓨전부는 센서 퓨전 시스템의 스테레오 카메라 로부터 영상 데이터와 각 지점의 점군 데이터(PCD)를 획득할 수 있다. 점군 데이터는 입체 데이터일 수 있 다. 센싱퓨전부는 획득한 점군 데이터를 저장 장치 또는 별도의 저장 장치 또는 적어도 하나의 프로 세서 내부에 일시적으로 저장할 수 있다. 또한, 센싱퓨전부는 2대의 라이더 센서(420, 430)로부터도 각 지점의 점군 데이터를 획득할 수 있다. 센싱 퓨전부는 2대의 라이더 센서(420, 430)로부터 획득한 점군 데이터도 저장 장치 또는 별도의 저장 장 치 또는 적어도 하나의 프로세서 내부에 일시적으로 저장할 수 있다. 이후 PCD 정보를 처리하는 동작(S520, S530)과 영상 데이터를 처리하는 동작 (S540, S550, S560, S570)은 서로 독립적으로 수행될 수 있으나, 일 실시 예에 따라, 순차적으로 실행되거나 또는 다른 실시 예에 따라 동시에 실 행될 수도 있다. 다양한 실시 예들에 따르면, 동작 S520에서, 센싱퓨전부는 센서 장치들에서 획득한 PCD 데이터를 합성할 수 있다. 다양한 실시 예들에 따르면, 센싱퓨전부는 스테레오 카메라 및 라이더 센서(420, 430) 각각 에서 획득한 PCD 데이터를 합성하여 센서 퓨전 시스템의 FOV(field of view)를 생성하고, 각 점군 데이터의 합 성을 통해 FOV의 각 점에 대한 점군 데이터를 생성하고, 동작 S530에서 점군 데이터 정보를 출력할 수 있다. 출력된 점군 데이터 정보는 통신 장치를 통해 관제 센터로 전달되거나 건설 기계의 운용에 사용 될 수 있다. 도 6은 본 발명의 다양한 실시 예들에 따른 센싱퓨전부의 PCD 데이터 합성 동작을 도시한 흐름도이다. 도 6은 도 5의 동작 S520의 일 실시 예일 수 있다. 도 6을 참조하면, 동작 S610에서, 센싱퓨전부는 각 점군 데이터에 대한 좌표계 변환 및 통일 동작을 수행 할 수 있다. 각 측정 장치로부터 획득한 점군 데이터는 각 장치의 측정원점으로부터 측정된 데이터이므로 서로 다른 좌표계를 가질 수 있다. 따라서, 각각의 장치에서 측정된 점군 데이터를 합성하기 위해서는 해당 데이터들 이 동일한 좌표계를 갖도록 변환하고 통일해 줄 필요가 있다. 일 실시 예에 따라, 센싱 퓨전 시스템 전체에 대 한 좌표계 원점을 설정하고, 이 원점을 기준으로 각 장치의 좌표계 원점의 상대적 좌표를 구하고, 구한 상대적 좌표를 각 측정값에 반영하여 각 장치에서 획득한 데이터의 좌표계를 통일할 수 있다. 이때 퓨전 시스템 전체에 대한 좌표계 원점은 건설 기계가 사용하는 좌표계의 원점일 수 있다. 다양한 실시 예들에 따르면, 동작 S620에서, 센싱퓨전부는 2대의 라이다 센서(420, 430)로부터 획득한 점 군 데이터를 통합할 수 있다. 일 실시 예에 따라 제1 라이다 센서의 센싱 방향은 수평면 기준 상향으로 일 정 각도 올라간 방향이고, 제2 라이다 센서의 센싱 방향은 수평면 기준 하향으로 일정 각도 내려간 방향일 수 있다. 즉, 제1 라이다 센서는 상부 측정 영역에 대한 점군 데이터를 제공할 수 있고, 제2 라이다 센서 는 하부 측정 영역에 대한 점군 데이터를 제공할 수 있다. 이 2대의 라이다 센서(420, 430)가 제공하는 점 군 데이터의 데이터 형식 및 스케일은 동일할 수 있기 때문에 동작 S610에 따라 좌표계가 통일된 상태에서는 2 대의 라이다 센서(420, 430)를 그대로 합치면 라이다 센서 전체의 점군 데이터를 바로 획득할 수 있다. 다만, 설치 시에 제1 라이다 센서와 제2 라이다 센서가 비뚤어짐 없이 설치되어 있다는 보장이 없기 때문에 제1 라이다 센서에서 획득한 점군 데이터와 제2 라이다 센서에서 획득한 점군 데이터를 통합 하였을 때에 최종적으로 확보되는 측정 영역이 정확히 사각형이 되지 않을 수 있다. 이러한 경우, 측정되지 않 는 점들이 있을 수 있기 때문에 상술한 바와 같이 제1 라이다 센서에 의한 측정 영역과 제2 라이다 센서 에 의한 측정 영역을 일부 겹치도록 설정될 수 있다. 이 경우, 제1 라이다 센서의 점군 데이터와 제2 라이다 센서의 점군 데이터를 통합하는 경우 일부 중복되는 구간이 있을 수 있으며, 센싱퓨전부는 중 복되는 구간에서는 2대의 라이다 센서(420, 430)의 점군 데이터를 보간(interpolation) 처리하여 해당 구간에 대한 점군 데이터를 결정할 수 있다. 또한, 제1 라이다 센서와 제2 라이다 센서가 비뚤어짐을 가지고 설치된 경우에, 최종 통합된 측정 영 역이 사각형 형상이 아닌 사다리꼴과 흡사한 형태가 될 수 있다. 이때, 센싱퓨전부는 합성된 측정 영역에 서 획득할 수 있는 가장 큰 직사각형 형태로 측정 영역을 수정(trim)하여 최종적인 점군 데이터의 측정 영역을 결정할 수 있다. 다양한 실시 예들에 따르면, 동작 S630에서, 센싱퓨전부는 스테레오 카메라로부터 획득한 점군 데이 터와 라이다 센서들의 통합된 점군 데이터를 통합할 수 있다.도 7은 스테레오 카메라 점군 데이터와 라이더 센서 통합 점군 데이터를 통합하는 예를 설명하 기 위한 도면이다. 도 7을 참조하면, 센싱퓨전부는 스테레오 카메라 점군 데이터와 라이더 센서 통합 점군 데이터 의 겹치는 영역에서는 획득한 점군 데이터(710, 720)에 기초하여 보간을 수행하여 점군 데이터를 통 합할 수 있다. 그리고 겹치지 않는 영역에서는 해당 영역에 존재하는 하나의 점군 데이터를 그대로 이용할 수 있다. 그리고 아무 데이터도 없는 모서리 영역(731 내지 734)의 외삽(extrapolation)을 수행하여 주변부의 점군 데이터의 추이로부터 추정치를 결정하여 해당 영역의 점군 데이터를 결정할 수 있다. 일 실시 예에 따라 주변부 의 점군 데이터의 추이로부터 아무 데이터가 없는 모서리 영역(731 내지 734)의 점군 데이터를 추정하는 외삽은 머신러닝(machine learning) 기법을 적용하여 수행할 수 있다. 일 실시 예에 따라 머신 러닝을 수행하는 인공지능을 학습시키기 위하여 외삽을 위한 학습 자료가 제공될 수 있 다. 이때의 학습 자료는 라이더 센서들의 통합 점군 데이터 및 스테레오 카메라의 점군 데이터를 통합한 경우에 발생되는 빈공간 영역에 대한 다양한 실제로 측정된 점군 데이터의 샘플일 수 있다. 인공 지능은 제공된 점군 데이터의 샘플에 기초하여 빈공간 영역에 대한 점군 데이터를 추정하여 제공할 수 있다. 여기서 학습 데이터는 비주기적으로 갱신이 필요한 경우에만 시스템 내부의 저장 장치에 업데이트 될 수 있다. 이러한 통합의 결과로 스테레오 카메라 점군 데이터와 라이더 센서 통합 점군 데이터의 겹치는 영역은 높은 정밀도로 센싱된 영역이 될 수 있고, 그 주변 영역은 낮은 정밀도로 센싱된 영역으로 볼 수 있다. 이후 동작 S640에서 점군 데이터에 대한 그리딩 및 샘플링이 수행될 수 있다. 도 7의 예에서 보간을 적용한 영 역, 외삽을 적용한 영역(731 내지 734) 및 라이더의 통합 점군 데이터 또는 스테레오 카메라 점군 데이터 만을 적용한 영역 각각에서의 점군 데이터의 간격 및 밀도가 상이할 수 있다. 따라서, 센싱퓨전부는 전체 측정 영역에 대하여 건설 기계가 요구하는 그리드(grid)에 맞추어 등간격으로 그리딩(griding)을 수행하여 모든 측정 영역에 대해 균등한 간격 및 밀도를 가지도록 점군 데이터를 가공할 수 있다. 추가적으로 센싱퓨전부는 필요한 경우 빠른 처리 또는 실시간 처리를 위해 1/n으로 다운 샘플링을 수행할 수 있고, 최종 처리 완료된 점군 데이터는 시간 정보와 함께 규격화될 수 있다. 다시 도 5를 참조하면, 센싱퓨전부는 스테레오 카메라로부터 획득한 영상 데이터에 대해 전처리를 수 행할 수 있다. 일 실시 예에 따라, 센싱퓨전부는 감마 보정, 밝기 보정, 대비 보정, 선명도 보정, 노이즈 제거와 같은 전처리를 수행할 수 있다. 다양한 실시 예들에 따르면, 동작 S550에서, 센싱퓨전부는 전처리된 영상으로부터 객체을 인식하고 분류할 수 있다. 일 실시 예에 따라, 센싱퓨전부는 머신러닝 기법을 적용하여 객체를 인식하고 분류할 수 있다. 머신 러닝을 위하여, 덤프트럭의 덤프베드 형상, 다양한 상대 위치에 따른 버켓의 형상, 사람 및 작업 시 충돌 이 예상되는 차량 등과 같은 장애물에 대한 이미지 정보를 포함하는 학습 데이터가 제공될 수 있다. 센싱퓨전부 는 머신러닝 기법을 적용하여 학습 데이터에서 제공하는 객체들과 비교하여 일치율이 높은 객체를 찾고 분 류할 수 있다. 다양한 실시 예들에 따르면, 동작 S560에서, 센싱퓨전부는 검출된 객체에 대한 트래킹을 수행할 수 있다. 일 실시 예에 따라, 센싱퓨전부는 영상 상에서 검출된 객체의 위치 좌표를 획득하고, 동작 S520에서 획득 한 점군 데이터에 기초하여 해당 좌표에 대한 정확한 거리 정보를 획득할 수 있다. 또한 복수의 영상에서의 해 당 객체의 움직임을 트래킹하여 해당 객체의 속도를 획득할 수 있다. 센싱퓨전부는 검출된 객체에 대해, 종류, 위치 좌표, 정확한 거리, 속도 정보를 획득할 수 있다. 다양한 실시 예들에 따르면, 동작 S570에서, 센싱퓨전부는 검출된 객체의 종류, 위치 좌표, 거리 정보, 추 가적으로 속도 정보를 시간 정보와 함께 규격화하여 객체 검출 정보로 영상과 함께 출력할 수 있다. 출력된 영상 정보 및 객체 검출 정보는 통신 장치를 통해 관제센터로 전달되거나 건설 기계의 계기판에 표시될 수 있고, 자동 제어되는 건설 기계인 경우 제어를 위한 기초 데이터로 사용될 수 있다."}
{"patent_id": "10-2021-0046624", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상술 설명한 내용을 요약하면 다음과 같이 정리될 수 있다. 다양한 실시 예들에 따르면, 센서 퓨전 시스템은 두 개의 렌즈를 구비하고 입체 영상을 촬영하여 영상 데이터 및 제1 점군 데이터(point cloud data)를 생성하는 스테레오 카메라, 각각 제2 점군 데이터 및 제3 점군 데이터 를 생성하는 2대의 라이다(LiDAR) 센서 및 상기 스테레오 카메라 및 상기 2대의 라이다 센서로부터 획득한 상기영상 데이터, 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터에 기초하여 주변에 대한 점군 데이터 및 객체 정보를 검출하는 센싱퓨전부를 포함할 수 있다. 다양한 실시 예들에 따르면, 상기 스테레오 카메라는 제1 측정 영역에 대한 상기 영상 데이터 및 상기 제1 점군 데이터를 생성하고, 상기 2대의 라이다 센서 중 제1 라이다 센서는 수평면을 기준으로 제1 미리 설정된 각도만 큼 상향된 방향의 제2 측정 영역을 센싱하여 상기 제2 측정 영역에 대한 상기 제2 점군 데이터를 생성하고, 제2 라이다 센서는 상기 수평면을 기준으로 제2 미리 설정된 각도만큼 하향된 방향의 제3 측정 영역을 센싱하여 상 기 제3 측정 영역에 대한 상기 제3 점군 데이터를 생성할 수 있다. 다양한 실시 예들에 따르면, 상기 센싱퓨전부는 서로 상이한 좌표계를 가지는 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 하나의 통일된 좌표계의 데이터로 변환하고, 변환된 상기 제2 점군 데 이터 및 상기 제3 점군 데이터를 통합하여 상기 제2 측정 영역과 상기 제3 측정 영역이 통합된 제4 측정 영역에 대한 제4 점군 데이터를 획득하고, 변환된 상기 제1 점군 데이터 및 상기 제4 점군 데이터를 통합하여, 상기 제 1 측정 영역과 상기 제4 측정 영역을 포함하는 제5 측정 영역에 대한 제5 점군 데이터를 획득하고, 상기 제5 측 정 영역에 대해서 건설 기계가 요구하는 그리드(grid)에 맞추어 등간격으로 그리딩을 수행하여 상기 제5 점군 데이터를 가공함으로써 균등한 간격 및 밀도를 가지는 제6 점군 데이터를 획득할 수 있다. 다양한 실시 예들에 따르면, 상기 센싱퓨전부는 상기 제2 측정 영역과 상기 제3 측정 영역 중에 중복된 영역에 서는 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 보간(interpolation) 처리하여 상기 제4 점군 데이터를 획득할 수 있다. 다양한 실시 예들에 따르면, 상기 센싱퓨전부는 상기 제1 측정 영역과 상기 제4 측정 영역에 기초하여 직사각형 형태의 상기 제5 측정 영역을 설정하고, 상기 제5 측정 영역중에서 상기 제1 측정 영역과 상기 제4 측정 영역이 겹치는 영역은 해당 영역의 상기 제1 점군 데이터와 상기 제4 점군 데이터를 보간 처리하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하고, 상기 제5 측정 영역중에서 상기 제1 측정 영역에만 포함되는 영역은 해당 영 역의 상기 제1 점군 데이터를 그대로 사용하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하고, 상기 제5 측정 영역중에서 상기 제4 측정 영역에만 포함되는 영역은 해당 영역의 상기 제4 점군 데이터를 그대로 사용하 여 해당 영역에 대한 상기 제5 점군 데이터를 획득하고, 상기 제5 측정영역중에서 상기 제1 측정 영역 및 상기 제4 측정 영역 모두에 포함되지 않는 영역은 해당 영역 주변부의 상기 제1 점군 데이터 및 상기 제4 점군 데이 터를 외삽(extrapolation) 처리하여 해당 영역에 대한 상기 제5 점군 데이터를 획득할 수 있다. 다양한 실시 예들에 따르면, 상기 외삽 처리는 머신러닝 기법을 적용하여 수행할 수 있다. 다양한 실시 예들에 따르면, 상기 센싱퓨전부는 상기 영상 데이터를 전처리하고, 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하고, 검출된 상기 객체에 대해 상기 제6 점군 데이터를 이용하여 위치 좌표, 거리 정보를 획득할 수 있다. 다양한 실시 예들에 따르면, 상기 센싱퓨전부는 머신러닝 기법을 적용하여 전처리된 상기 영상 데이터로부터 객 체를 검출하고 분류하되, 상기 머신러닝을 수행하는 인공지능을 학습시키기 위하여 덤프트럭의 덤프베드 형상 및 사람, 차량을 포함하는 장애물에 대한 이미지 정보를 학습 데이터로 제공할 수 있다. 다양한 실시 예들에 따르면, 영상 데이터 및 제1 점군 데이터를 출력하는 스테레오 카메라 및 제2 점군 데이터 및 제3 점군 데이터를 출력하는 2대의 라이다(LiDAR) 센서가 구비된 센서 퓨전 시스템에서의 측정 영역에 대한 객체 검출 및 점군 데이터를 생성하는 센싱 방법은 상기 영상 데이터, 상기 제1 점군 데이터, 상기 제2 점군 데 이터 및 상기 제3 점군 데이터를 획득하는 동작, 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점 군 데이터에 기초하여 상기 측정 영역에 대한 제6 점군 데이터를 획득하는 동작, 상기 영상 데이터를 전처리하 는 동작, 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하는 동작 및 검출된 상기 객체의 위치 좌표 및 거리 정보를 상기 제6 점군 데이터를 이용하여 획득하는 동작을 포함할 수 있다. 다양한 실시 예들에 따르면, 상기 영상 데이터 및 상기 제1 점군 데이터는 제1 측정 영역에 대해 획득되고, 상 기 제2 점군 데이터는 수평면을 기준으로 제1 미리 설정된 각도만큼 상향된 방향의 제2 측정 영역을 제1 라이다 센서로 센싱하여 획득되고, 상기 제3 점군 데이터는 상기 수평면을 기준으로 제2 미리 설정된 각도만큼 하향된 방향의 제3 측정 영역을 제2 라이다 센서로 센싱하여 획득될 수 있다. 다양한 실시 예들에 따르면, 상기 측정 영역에 대한 제6 점군 데이터를 획득하는 동작은 서로 상이한 좌표계를 가지는 상기 제1 점군 데이터, 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 하나의 통일된 좌표계의 데이터로 변환하는 동작, 변환된 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 통합하여 상기 제2 측정 영역과 상기 제3 측정 영역이 통합된 제4 측정 영역에 대한 제4 점군 데이터를 획득하는 동작, 변환된 상기 제1 점군 데이터 및 상기 제4 점군 데이터를 통합하여, 상기 제1 측정 영역과 상기 제4 측정 영역을 포함하는 제5 측정 영역에 대한 제5 점군 데이터를 획득하는 동작, 상기 제5 측정 영역에 대해서 건설 기계가 요구하는 그리드 (grid)에 맞추어 등간격으로 그리딩을 수행하여 상기 제5 점군 데이터를 가공함으로써 균등한 간격 및 밀도를 가지는 제6 점군 데이터를 획득하는 동작을 포함할 수 있다. 다양한 실시 예들에 따르면, 상기 제4 점군 데이터를 획득하는 동작은 상기 제2 측정 영역과 상기 제3 측정 영 역 중에 중복된 영역에서는 상기 제2 점군 데이터 및 상기 제3 점군 데이터를 보간(interpolation) 처리하여 상 기 제4 점군 데이터를 획득할 수 있다. 다양한 실시 예들에 따르면, 상기 제5 점군 데이터를 획득하는 동작은 상기 제1 측정 영역과 상기 제4 측정 영 역에 기초하여 직사각형 형태의 상기 제5 측정 영역을 설정하는 동작, 상기 제5 측정 영역중에서 상기 제1 측정 영역과 상기 제4 측정 영역이 겹치는 영역은 해당 영역의 상기 제1 점군 데이터와 상기 제4 점군 데이터를 보간 처리하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하는 동작, 상기 제5 측정 영역중에서 상기 제1 측정 영역에만 포함되는 영역은 해당 영역의 상기 제1 점군 데이터를 그대로 사용하여 해당 영역에 대한 상기 제5 점 군 데이터를 획득하는 동작, 상기 제5 측정 영역중에서 상기 제4 측정 영역에만 포함되는 영역은 해당 영역의 상기 제4 점군 데이터를 그대로 사용하여 해당 영역에 대한 상기 제5 점군 데이터를 획득하는 동작 및 상기 제5 측정영역중에서 상기 제1 측정 영역 및 상기 제4 측정 영역 모두에 포함되지 않는 영역은 해당 영역 주변부의 상기 제1 점군 데이터 및 상기 제4 점군 데이터를 외삽(extrapolation) 처리하여 해당 영역에 대한 상기 제5 점 군 데이터를 획득하는 동작을 포함할 수 있다. 다양한 실시 예들에 따르면, 상기 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하는 동작은 머신러닝 기법을 적용하여 전처리된 상기 영상 데이터로부터 객체를 검출하고 분류하는 동작을 포함하되, 상기 머신러닝 을 수행하는 인공지능을 학습시키기 위하여 덤프트럭의 덤프베드 형상 및 사람, 차량을 포함하는 장애물에 대한 이미지 정보를 학습 데이터로 제공할 수 있다. 다양한 실시 예들에 따르면, 건설기계는 상술한 센서 퓨전 시스템에 기초하여 주변 환경을 센싱할 수 있다. 다양한 실시 예들에 따르면, 컴퓨터 프로그램은 프로세서에 의해 실행될 때, 상술한 방법 중 어느 하나의 방법 에 따른 동작을 수행할 수 있다. 다양한 실시 예들에 따르면, 컴퓨터 판독가능 저장매체는 프로세서에 의해 실행될 때, 상술한 방법 중 어느 하 나의 방법에 따른 동작을 수행하는 프로그램이 저장될 수 있다. 상술한 바처럼 본 개시에서 제안하는 센서 퓨전 시스템은 객체 검출에 있어서 정밀도를 높일 수 있어 장애물 검 출의 정확도를 높일 수 있고, 지형 검출 시의 해상도를 비약적으로 향상시킬 수 있으며, 이를 구비한 건설 기계 의 자율 작업을 가능하도록 할 수 있다. 본 개시의 실시 예들에 따른 건설 기계의 동작 방법 또는 센서 퓨전 시스템의 동작은 컴퓨터로 판독 가능 한 저장 매체에 저장되어 적어도 하나의 프로세서(예: 프로세서)에 의해 실행될 수 있는 명령어들로 구현 될 수 있다. 저장 매체는, 직접 및/또는 간접적이든, 원시 상태, 포맷화된 상태, 조직화된 상태 또는 임의의 다른 액세스 가 능한 상태이든 관계없이, 관계형 데이터베이스, 비관계형 데이터베이스, 인-메모리(in-memory) 데이터베이스, 또는 데이터를 저장할 수 있고 저장 제어기를 통해 이러한 데이터에 대한 액세스를 허용할 수 있는 다른 적절한 데이터베이스와 같이 분산형을 포함하는 데이터베이스를 포함할 수 있다. 또한, 저장 매체는, 1차 저장 장치 (storage), 2차 저장 장치, 3차 저장 장치, 오프라인 저장 장치, 휘발성 저장 장치, 비휘발성 저장 장치, 반도 체 저장 장치, 자기 저장 장치, 광학 저장 장치, 플래시 저장 장치, 하드 디스크 드라이브 저장 장치, 플로피 디스크 드라이브, 자기 테이프, 또는 다른 적절한 데이터 저장 매체와 같은 임의의 타입의 저장 장치를 포함할 수 있다. 본 개시는 도면에 도시된 실시 예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 개시의 진정한 기술적 보호 범위는 첨부된 등록청구범위의 기술적 사상에 의해 정해져야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2021-0046624", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 다양한 실시 예에 따른 자율 작업 시스템을 도시한 도면이다. 도 2는 본 개시의 다양한 실시 예에 따른 센서 퓨전(sensor fusion) 시스템을 구비한 굴착기를 도시한 도면이다. 도 3은 본 개시의 다양한 실시 예에 따른 건설 기계를 개념적으로 나타낸 도면이다. 도 4는 본 개시의 다양한 실시 예에 따른 센서 퓨전 시스템의 구성을 도시한 도면이다. 도 5는 본 발명의 다양한 실시 예들에 따른 센싱퓨전부의 동작을 도시한 흐름도이다. 도 6은 본 발명의 다양한 실시 예들에 따른 센싱퓨전부의 PCD 데이터 합성 동작을 도시한 흐름도이다. 도 7은 스테레오 카메라 점군 데이터와 라이더 센서 통합 점군 데이터를 통합하는 예를 설명하 기 위한 도면이다."}
