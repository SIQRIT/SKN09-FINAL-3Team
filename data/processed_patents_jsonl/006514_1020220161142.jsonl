{"patent_id": "10-2022-0161142", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0078717", "출원번호": "10-2022-0161142", "발명의 명칭": "다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 및 방법", "출원인": "주식회사 인공지능연구원", "발명자": "황대원"}}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다시점 카메라에 의해 촬영된 다관절 객체의 다시점 이미지로부터 3차원 객체 정보를 생성하는 객체의 입체영상캡쳐 장치에 있어서, 외부장치 또는 메모리로부터 동일 객체에 대해 다른 시점에서 촬영한 복수의 다시점 이미지를 입력받는 이미지입력부; 입력된 다시점 이미지 각각에서 배경을 제거하여 각 시점의 객체 영역 이미지를 추출하는 객체 영역 추출부; 입력된 다시점 이미지에서 구한 각 시점별 2차원 관절 위치 정보와 카메라 파라미터 정보를 이용하여 3차원 관절정보를 결정하고, 3차원 관절정보에 3차원 메쉬 모델을 피팅시켜 3차원 메쉬 정보를 생성하는 3차원 메쉬 생성부; 및 객체 영역 이미지의 각 시점에 따라 3차원 메쉬를 해당 시점의 객체 영역 이미지에 투영시키고, 3차원 메쉬의각 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출하여 텍스쳐 이미지를 생성하는 텍스쳐 생성부; 를 포함하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 3차원 메쉬 생성부는 : 입력된 이미지에서 관절을 찾도록 학습된 심층 신경망을 포함하며, 입력된 다시점 이미지 각각으로부터 2차원관절 위치 정보를 산출하는 2차원 관절 위치 결정부; 복수의 2차원 관절 위치 정보에 대해 각각의 다시점 이미지를 촬영한 카메라들의 파라미터를 이용하여 각 관절의 3차원 위치를 결정하는 3차원 관절 위치 결정부; 및 3차원 관절 위치 정보를 이용하여 3차원 객체 생성 모델을 피팅하여 3차원 부피감을 표현하는 3차원 메쉬 정보를 결정하는 3차원 메쉬 정보 결정부; 를 포함하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 3차원 관절 위치 결정부는, 동일한 관절을 포함하는 복수의 다시점 이미지에서의 2차원 관절 위치 정보와, 각각의 다시점 이미지를 촬영한카메라들의 외부 파라미터에 삼각측량법을 적용하여 관절의 3차원 위치를 결정하는, 객체의 입체영상 캡쳐장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서, 상기 3차원 메쉬 정보 결정부는, 3차원 관절 위치 정보를 입력받아서 3차원 객체 생성 모델에서 구한 관절, 자세 및 형상의 오차를 최소화하도록3차원 메쉬 파라미터 정보를 결정하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0078717-3-청구항 2에 있어서, 상기 3차원 메쉬 생성부는 : 카메라 보정 객체를 촬영한 이미지와 보정 객체의 위치 정보로부터 각각의 카메라에 대해 카메라의 회전 및 병진에 대한 외부 파라미터를 결정하는 카메라 파라미터 결정부; 를 더 포함하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서, 상기 텍스쳐 생성부는 : 3차원 메쉬의 각 버텍스를 각 시점별 객체 영역 이미지에 매핑시키고, 각 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출하여 각 시점별 텍스쳐 이미지를 생성하는 시점별 텍스쳐 생성부; 및 각 시점의 텍스쳐 이미지들을 결합하여 하나의 텍스쳐 이미지를 생성하는 텍스쳐 병합부; 를 포함하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 시점별 텍스쳐 생성부는 : 3차원 메쉬 정보를 2차원 평면에 투영시켜 2차원 메쉬 맵인 UV맵을 생성하는 UV맵 생성부;를 포함하여, 객체 영역 이미지의 시점에 맞추어 3차원 메쉬의 각 버텍스를 객체 영역 이미지에 매핑시키고, 각 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출하고, 추출된 색상 정보를 2차원 UV맵에 적용하여 각 시점의텍스쳐 이미지를 생성하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 6에 있어서, 상기 텍스쳐 병합부는, 각 시점의 텍스쳐 이미지들에서 색상 정보가 중복되는 버텍스에는 중복되는 색상 정보 값들을 평균하고, 색상정보가 없는 버텍스에는 인접 버텍스의 색상정보를 이용하여 색상 정보를 보충하여 텍스쳐 이미지를 생성하는,객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서, 상기 객체 영역 추출부는, 객체 영역을 추출하도록 학습된 심층 신경망을 포함하여, 입력된 다시점 이미지에서 배경 영역을 제외하고 객체영역을 추출하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 1에 있어서, 상기 객체의 입체영상 캡쳐 장치는 : 동일한 초점거리를 가지고 객체로부터 동일한 거리에 배치되는 복수의 카메라를 포함하며, 동시에 서로 다른 시점에서 동일 객체를 촬영하여 복수의 다시점 이미지를 생성하는 다시점 카메라; 를 더 포함하는, 객체의 입체영상 캡쳐 장치."}
{"patent_id": "10-2022-0161142", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다시점 카메라에 의해 촬영된 다관절 객체의 다시점 이미지로부터 3차원 객체 정보를 생성하는 객체의 입체영상 캡쳐 장치에 관한 기술이 개시된다. 객체의 입체영상 캡쳐 장치는 이미지 입력부와, 객체 영역 추출부와, 3차원 메쉬 생성부와, 텍스쳐 생성부를 포함한다. 이미지 입력부는 동일 객체에 대해 다른 시점에서 촬영한 복수의 다 (뒷면에 계속)"}
{"patent_id": "10-2022-0161142", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 처리 기술, 특히 객체에 대한 다시점 이미지로부터 3차원 메쉬와 텍스쳐 이미지를 생성하는 방 법에 관한 영상 처리 기술이 개시된다."}
{"patent_id": "10-2022-0161142", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술의 발달에 따라, 영상 분야에서도 종래 2차원 이미지 위주에서 점차 3차원 이미지의 사용이 증가 하고 있다. 이에 따라 캐릭터, 배경 등의 콘텐츠 요소인 3D 에셋(assets)의 요구가 증가하고 있다. 따라서 게임 엔진, 메타버스와 같은 3차원 시뮬레이션 환경 등에서 사용되는 3D 에셋을 쉽고 정확하게 생성하는 입체영상 캡 쳐 장치 및 방법의 개발이 필요하다. 종래의 3차원 이미지 추출 또는 생성 방법은 우선 다시점 카메라 영상들에서 각 매치되는 포인트들의 깊이 (depth)를 계산하여 객체의 표면을 구성하는 포인트 클라우드(point cloud)를 생성한다. 그리고 이로부터 3D 메 쉬 모델을 생성하고 메쉬를 스무딩 처리한 후 텍스쳐(texture)를 입히는 과정을 통해서 3차원 이미지를 생성한 다. 카메라 2D영상에서 각 매칭점들의 깊이를 계산하여 직접 메쉬 모델을 산출하므로, 많은 수(100대)의 다시점 영상(카메라)이 필요하다. 2022년 02월 08일 공고된 등록특허 제 10-2358464호는 인공지능 기술을 이용하여 영상 정보로부터 3D 캐릭터 애 니메이션을 자동으로 생성하는 3D 이미지 변환장치 및 이를 포함하는 3D 이미지 변환시스템에 관한 것이다. 3D 이미지 변환장치는, 2D 영상을 사용자 단말기로부터 수신하는 통신부와, 상기 2D 영상을 기학습된 제1 인공신경 망에 적용하여 상기 2D 영상 내 인간 형상의 제1 객체의 주요관절의 위치를 상기 2차원 좌표로 출력하는 2D 이 미지 분석모듈과, 상기 제1 객체를 3D 이미지로 변환하기 위해, 상기 2차원 좌표를 기학습된 제2 인공신경망에 적용하여 상기 주요관절의 위치를 3차원 좌표로 출력하는 3D 이미지 분석모듈과, 3D 이미지의 깊이 보정을 위해, 기설정된 호모그래피 행렬을 이용하여 상기 3차원 좌표를 상기 제1 객체가 위치한 공간 상의 공간좌표로 변환하는 깊이 분석모듈과, 상기 공간좌표에 대응하는 각 골격 포인트를 연결하여 골격형상으로 구현된 3D 골격 이미지를 생성하는 3D 이미지 생성모듈을 포함하는 구성을 개시하고 있다. 다만, 3차원 관절 정보를 이용하여 3차원 메쉬를 생성하고, 텍스쳐를 병합하여 3차원 입체 영상을 캡쳐하는 장 치 및 방법에 대해서는 아직 구체적으로 개시되어 있지 않다."}
{"patent_id": "10-2022-0161142", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은, 상대적으로 적은 카메라 만으로 객체의 3차원 영상을 캡쳐할 수 있는 다시점 카메라 기반 다관절 객체의 입체영상 캡쳐장치 및 방법을 제공하는 것이다. 본 발명의 다른 목적은, 3차원 관절 위치를 이용하여 보다 정확한 3차원 메쉬의 생성이 가능한 객체의 입체영상 캡쳐장치 및 방법을 제공하는 것이다. 본 발명의 또 다른 목적은, 객체 표면의 세부적 표현이 가능한 텍스쳐 이미지 생성이 가능한 객체의 입체영상 캡쳐장치 및 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0161142", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제안된 발명의 일 양상에 따르면, 다시점 카메라에 의해 촬영된 다관절 객체의 다시점 이미지로부터 3차원 객체 정보를 생성하는 객체의 입체영상 캡쳐 장치는, 이미지 입력부, 객체 영역 추출부, 3차원 메쉬 생성부, 및 텍스 쳐 생성부를 포함한다. 이미지 입력부는 외부장치 또는 메모리로부터 동일 객체에 대해 다른 시점에서 촬영한 복수의 다시점 이미지를 입력받는다. 객체 영역 추출부는 입력된 다시점 이미지 각각에서 배경을 제거하여 각 시점의 객체 영역 이미지 를 추출한다. 3차원 메쉬 생성부는 입력된 다시점 이미지에서 구한 각 시점별 2차원 관절 위치 정보와 카메라 파라미터 정보를 이용하여 3차원 관절 정보를 결정하고, 3차원 관절 정보에 3차원 메쉬 모델을 피팅시켜 3차원 메쉬 정보를 생성한다. 텍스쳐 생성부는 객체 영역 이미지의 각 시점에 따라 3차원 메쉬를 해당 시점의 객체 영역 이미지에 투영시키고, 3차원 메쉬의 각 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출하여 텍 스쳐 이미지를 생성한다. 추가적인 양상에 따르면, 3차원 메쉬 생성부는, 2차원 관절 위치 결정부, 3차원 관절 위치 결정부, 및 3차원 메 쉬 정보 결정부를 포함한다. 2차원 관절 위치 결정부는 입력된 이미지에서 관절을 찾도록 학습된 심층 신경망을 포함하며, 입력된 다시점 이 미지 각각으로부터 2차원 관절 위치 정보를 산출한다. 3차원 관절 위치 결정부는 복수의 2차원 관절 위치 정보 에 대해 각각의 다시점 이미지를 촬영한 카메라들의 파라미터를 이용하여 각 관절의 3차원 위치를 결정한다. 3 차원 메쉬 정보 결정부는 3차원 관절 위치 정보를 이용하여 3차원 객체 생성 모델을 피팅하여 3차원 부피감을 표현하는 3차원 메쉬 정보를 결정한다. 추가적인 양상에 따르면, 3차원 관절 위치 결정부는, 동일한 관절을 포함하는 복수의 다시점 이미지에서의 2차 원 관절 위치 정보와, 각각의 다시점 이미지를 촬영한 카메라들의 외부 파라미터에 삼각측량법을 적용하여 관절 의 3차원 위치를 결정한다. 추가적인 양상에 따르면, 3차원 메쉬 정보 결정부는, 3차원 관절 위치 정보를 입력받아서 3차원 객체 생성 모델 에서 구한 관절, 자세 및 형상의 오차를 최소화하도록 3차원 메쉬 파라미터 정보를 결정한다. 추가적인 양상에 따르면, 3차원 메쉬 생성부는, 카메라 보정 객체를 촬영한 이미지와 보정 객체의 위치 정보로 부터 각각의 카메라에 대해 카메라의 회전 및 병진에 대한 외부 파라미터를 결정하는 카메라 파라미터 결정부를 더 포함한다. 추가적인 양상에 따르면, 텍스쳐 생성부는 시점별 텍스쳐 생성부와 텍스쳐 병합부를 포함한다. 시점별 텍스쳐 생성부는 3차원 메쉬의 각 버텍스를 각 시점별 객체 영역 이미지에 매핑시키고, 각 버텍스에 매 핑되는 객체 영역의 이미지에서 색상 정보를 추출하여 각 시점별 텍스쳐 이미지를 생성한다. 텍스쳐 병합부는 각 시점의 텍스쳐 이미지들을 결합하여 하나의 텍스쳐 이미지를 생성한다. 추가적인 양상에 따르면, 시점별 텍스쳐 생성부는 3차원 메쉬 정보를 2차원 평면에 투영시켜 2차원 메쉬 맵인 UV맵을 생성하는 UV맵 생성부를 포함하여, 객체 영역 이미지의 시점에 맞추어 3차원 메쉬의 각 버텍스를 객체 영역 이미지에 매핑시키고, 각 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출하고, 추출된 색상 정보를 2차원 UV맵에 적용하여 각 시점의 텍스쳐 이미지를 생성한다. 추가적인 양상에 따르면, 텍스쳐 병합부는, 각 시점의 텍스쳐 이미지들에서 색상 정보가 중복되는 버텍스에는 중복되는 색상 정보 값들을 평균하고, 색상 정보가 없는 버텍스에는 인접 버텍스의 색상정보를 이용하여 색상 정보를 보충하여 텍스쳐 이미지를 생성한다. 추가적인 양상에 따르면, 객체 영역 추출부는, 객체 영역을 추출하도록 학습된 심층 신경망을 포함하여, 입력된 다시점 이미지에서 배경 영역을 제외하고 객체 영역을 추출한다. 추가적인 양상에 따르면, 객체의 입체영상 캡쳐 장치는, 동일한 초점거리를 가지고 객체로부터 동일한 거리에 배치되는 복수의 카메라를 포함하며, 동시에 서로 다른 시점에서 동일 객체를 촬영하여 복수의 다시점 이미지를 생성하는 다시점 카메라를 더 포함한다."}
{"patent_id": "10-2022-0161142", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "제안된 발명에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 및 방법은, 다시점 이미지에서 관절 점을 추출하여 3차원 메쉬를 생성하므로 상대적으로 적은 카메라 만으로 객체의 3차원 입체 영상을 캡쳐할 수 있다. 나아가 제안된 발명은, 카메라 외부 파라미터를 이용하여 구한 3차원 관절 위치를 이용하여 3차원 메쉬를 생성 하므로 보다 정확한 3차원 메쉬를 생성할 수 있다. 나아가 제안된 발명은, 3차원 메쉬를 객체 영역에 투영시켜 얻은 텍스쳐 이미지를 이용하여 객체 표면의 세부적 인 표현을 할 수 있다."}
{"patent_id": "10-2022-0161142", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한, 그리고 추가적인 양상들은 첨부된 도면을 참조하여 설명하는 실시예들을 통해 구체화된다. 각 실시예들 의 구성 요소들은 다른 언급이나 상호간에 모순이 없는 한 실시예 내에서 또는 타 실시예의 구성 요소들과 다양 한 조합이 가능한 것으로 이해된다. 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개 념을 적절하게 정의할 수 있다는 원칙에 입각하여 본 명세서 및 청구범위에 사용된 용어는 기재 내용 혹은 제안 된 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 본 명세서에서 모듈 또는 부분은, 컴퓨터 또는 프로세서에서 실행할 수 있도록 메모리에 저장된 프로그램 명령어의 집합이거나, 이러한 명령들을 수행할 수 있 도록 ASIC, FPGA 등의 전자 부품 또는 회로의 집합을 이용하여 구현할 수 있다. 또한, 각 모듈 또는 부분의 동 작은 하나 또는 복수의 프로세서 또는 장치에 의해 수행될 수 있다. 동일·유사한 기능을 수행하는 구성요소에 대해서 앞에서 설명된 경우, 중복되는 설명을 생략할 수 있다. 설명이 생략된 구성요소에 대해서는, 앞에서 설 명된 동일·유사한 기능을 수행하는 구성요소에 대한 설명을 참조할 수 있다. 이하 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치의 구성을 나타내는 구성도이다. 제안된 발명의 일 양상에 따르면, 다시점 카메라에 의해 촬영된 다관절 객체의 다시점 이미지로부터 3차원 객체 정보를 생성하는 객체의 입체영상 캡쳐 장치는, 이미지 입력부, 객체 영역 추출부, 3차원 메쉬 생성부, 및 텍스쳐 생성부를 포함한다. 이미지 입력부는 외부장치 또는 메모리로부터 다시점 이미지를 입력받는다. 다시점 이미지는 동일 객체를 다른 위치(시점)에서 촬영한 복수의 이미지이다. 움직이는 객체에 대해서는 보다 정밀한 스캔을 위해서, 복수의 카메라를 이용하여 같은 시각에 촬영한 다시점 이미지를 사용하는 것이 바람직하다. 입력된 다시점 이미지는 객 체 영역 추출부와 3차원 메쉬 생성부로 전달된다. 객체의 입체영상 캡쳐 장치는 다시점 카메라(미도시)를 더 포함할 수 있다. 다시점 카메라는 동일 객체 주 위에 배치되는 복수의 카메라로 구성된다. 다시점 카메라를 이용하면, 동시에 서로 다른 시점에서 동일 객체를 촬영하여 복수의 다시점 이미지를 생성할 수 있고, 모든 방향에서 촬영된 다시점 이미지를 이용하여 객체의 입 체적인 정보를 생성할 수 있다. 정밀한 측정과 간편한 계산을 위해, 다시점 카메라에 사용되는 복수의 카메라들 은 스캔하려는 객체로부터 동일한 거리에 균일한 간격으로 배치되고, 동일한 초점거리를 가지도록 하는 것이 바 람직하다. 객체 영역 추출부는 입력된 다시점 이미지 각각에서 배경을 제거하여 각 시점의 객체 영역 이미지를 추출 (Segmentation)한다. 추출된 객체 영역 이미지는 텍스쳐 생성부로 전달되어 텍스쳐 추출에 사용된다. 객체 영역 추출부는, 객체 영역을 추출하도록 학습된 심층 신경망을 포함하여, 입력된 다시점 이미지에서 배경 영역을 제외하고 객체 영역을 추출한다. 심층 신경망으로는 합성곱 신경망(Convolutional Neural Network; CNN)을 비롯한 다양한 신경망을 사용할 수 있다. 3차원 메쉬 생성부는 다시점 이미지를 이용하여 3차원 메쉬 정보를 생성한다. 이를 위해, 3차원 메쉬 생성 부는 우선 입력된 다시점 이미지에서 각 시점별 2차원 관절 위치 정보를 결정한다. 그리고 시점별 2차원관절 위치 정보와 카메라의 회전 및 병진 위치에 대한 외부 파라미터 정보를 이용하여 3차원 관절정보를 결정하 한다. 그리고, 3차원 관절정보를 이용하여 3차원 메쉬 모델을 피팅시켜 3차원 메쉬 정보를 생성한다. 텍스쳐 생성부는 객체영역 추출부에서 추출된 객체 영역 이미지와, 3차원 메쉬 생성부에서 생성 된 3차원 메쉬의 정보를 이용하여 텍스쳐 이미지를 생성한다. 텍스쳐 이미지를 생성하기 위해, 텍스쳐 생성부 는 객체 영역 이미지의 각 시점에 따라 3차원 메쉬를 해당 시점의 객체 영역 이미지에 투영시키고, 3차원 메쉬의 각 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출한다. 추출된 색상정보를 시점별로 병합 하여 3차원용 텍스쳐를 생성할 수 있다. 도 2는 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 중 3차원 메쉬 생성부의 구성을 나타내는 구성도이다. 추가적인 양상에 따르면, 3차원 메쉬 생성부는, 2차원 관절 위치 결정부, 3차원 관절 위치 결정부 , 및 3차원 메쉬 정보 결정부를 포함한다. 2차원 관절 위치 결정부는 입력된 이미지에서 관절(Joint)을 찾도록 학습된 심층 신경망을 포함하며, 입력 된 다시점 이미지 각각으로부터 2차원 관절 위치 정보를 산출한다. 이미지로부터 2차원 관절점(Joint)의 위치 정보를 구하는 방법으로는 OpenPose 알고리즘을 사용할 수 있다. OpenPose 알고리즘에서는 딥러닝 합성곱 신경망을 이용하여 25개의 2차원 관절 정보를 추출할 수 있다. OpenPose 신경망 구조는 첫번째 특징맵을 생성하는 컨볼루션층(Convolution Layer)들과 풀링층(Pooling Laye r)들로 이루어진 신경망과, 특징맵(Feature Map)을 입력받아 관절의 '위치'를 결정하도록 학습된 컨볼루션층들 로 구성된 제1 가지(Branch)와 관절의 '방향'을 결정하도록 학습된 컨볼루션층들로 구성된 제2 가지로 구성된다. 제1 가지와 제2 가지의 신경망은 25개의 관절에 대하여 순차적으로 생성된다. 즉, 첫번째 관절의 위 치와 방향이 결정된 경우, 그 출력을 이용하여 특징맵을 형성하고, 다음 관절에 대해 제1 가지의 신경망과 제2 가지의 신경망을 통과시는 과정을 반복한다. 3차원 관절 위치 결정부는 복수의 2차원 관절 위치 정보에 대해 각각의 다시점 이미지를 촬영한 카메라들 의 외부 파라미터를 이용하여 각 관절의 3차원 위치를 결정한다. 각각의 시점에서 얻은 2차원 관절 위치 정보는 각 시점의 이미지를 촬영한 카메라의 회전 및 병진 정보를 이용하여 3차원 상의 절대 좌표로 변환할 수 있다. 카메라의 외부(회전 및 병진) 파라미터는 카메라 보정 과정에서 결정할 수 있다. 3차원 관절 위치 결정부는, 동일한 관절을 포함하는 복수의 다시점 이미지에서의 2차원 관절 위치 정보와, 각각의 다시점 이미지를 촬영한 카메라들의 외부 파라미터에 삼각측량법(triangulation)을 적용하여 관절의 3차 원 위치를 결정할 수 있다. 3차원 메쉬 정보 결정부는 3차원 관절 위치 정보를 이용하여 3차원 객체 생성 모델을 피팅하여 3차원 부피 감을 표현하는 3차원 메쉬 정보를 결정한다. 3차원 메쉬 정보 결정부는, 3차원 관절 위치 정보에 맞추어 3차원 객체 생성 모델의 파라미터를 결정한다. 즉, 3차원 관절 위치 정보를 입력받아서 3차원 객체 생성 모델에서 구한 관절, 자세 및 형상의 오차를 최소화하 도록 3차원 메쉬 파라미터 정보를 결정할 수 있다. 3차원 객체 생성 모델로는 SMPL(Skinned Multi-Person Linear model)을 사용할 수 있다. SMPL은 관절점 기반 메쉬 모델(mesh model) 중에서 특히, 3차원 인체를 생성하는 모델 중 하나이다. SMPL은 매개변수 기반의 3차원 휴먼 메쉬 모델로, 자세(Pose)와 형상(Shape) 파라미터를 입력하면, 메쉬 모델이 생성된다. 관절점(joint)으로 부터 각 관절(뻐대; bone)의 길이를 결정할 수 있고, 볼륨 정도를 통해 통통하거나 마른 정도를 반영하여 3차원 인물 메쉬 모델을 적은 데이터로 생성할 수 있다. SMPL에서 메쉬 M은 미분 가능한 함수 M(β, θ)으로 표현된다. 형상(Shape) 파라미터 β ∈ R10 는 PCA(Principal Component Analysis) 공간에서 얻어지는 10개의 계수로 기술된다. 자세(Pose) 파라미터 θ ∈ RJ ×D 는 신체를 구성하는 관절들의 3차원 회전으로 기술된다. 여기서 J와 D는 각각 SMPL 인체 템플릿을 구성하는 주요 관절의 개수와 3차원 회전 표현의 차원을 나타낸다. SMPL 모델의 정점의 수 N은 6890이다. SMPL 모델을 최적화 시키기 위한 목적함수(Objective Function)는 관절기반 데이터(joint-based data), 세가지 포즈 정보(pose priors) 및 모양 정보(shape prior)의 합으로 구성할 수 있다. 관절기반 데이터는 3차원 관절위치와 SMPL 모델의 관절 위치에 대한 3차원 거리로 구할 수 있다. 다시점 이미지와 카메라 파라미터 정보로부터 결정된 3차원 관절 정보를 이용하여 SMPL 모델을 피팅하므로, 2차 원 관절 정보를 이용하여 SMPL 모델을 피팅하는 경우보다 실제 인체의 자세와 형상을 더욱 정확히 반영할 수 있 어서 보다 정확한 3차원 메쉬를 생성할 수 있다. 이상에서 객체 생성 모델로 인체의 자세를 재구성하는 SMPL에 대해서 주로 설명하였으나, 다양한 객체에 대해서 적합한 모델을 사용할 수 있다. 예를 들어, 동물에 대해서는 SMAL(Skinned Multi-Animal Linear model) 모델을 사용할 수 있다. 추가적인 양상에 따르면, 3차원 메쉬 생성부는, 카메라 보정 객체를 촬영한 이미지와 보정 객체의 위치 정 보로부터 각각의 카메라에 대해 카메라의 회전 및 병진에 대한 외부 파라미터를 결정하는 카메라 파라미터 결정 부를 더 포함한다. 촬영되는 객체의 위치에 보정 이미지를 배치하고, 카메라들로부터 보정 이미지를 촬영 하고, 보정 이미지의 위치정보를 이용하여 카메라의 외부 파라미터를 결정할 수 있다. 카메라의 외부 파라미터 는 회전 파라미터와 병진 파라미터로 구성된다. 카메라가 고정된 경우에는 미리 결정되어 저장된 카메라의 외부 파라미터를 이용하여 3차원 관절 위치를 결정할 수 있다. 도 3은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치에서 3차원 관절 위치를 결정에 사용되는 카메라 좌표계를 나타내는 개념도이다. 이미지 A는 객체 P를 카메라 OA 시점에서 촬영한 것이고, 이미지 B는 카메라 OB의 시점에서 객체 P'을 촬영한 이 미지이다. 이미지 A에서 객체 P는 p위치에 촬영되고, 카메라 OB는 e 위치에 촬영된다. 이미지 B에서 객체 P'은 p'위치에 촬영되고, 카메라 OA는 e' 위치에 촬영된다. OA 카메라와 OB 카메라가 동일한 객체를 촬영한 경우 P의 위치는 P'과 같아지며, 두 카메라 좌표계의 관계는 다음 수학식 1과 같다. [수학식 1] P' = [R] P + [t] 여기에서, [R]은 3×3 회전 행렬이고, [t]는 3×1 병진 벡터이며, 공지된 카메라 보정 과정을 통해서 구할 수 있다. 도 4는 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 중 텍스쳐 생성부의 구성을 나 타내는 구성도이다. 추가적인 양상에 따르면, 텍스쳐 생성부는 시점별 텍스쳐 생성부와 텍스쳐 병합부를 포함한다. 시점별 텍스쳐 생성부는 3차원 메쉬의 각 버텍스를 각 시점별 객체 영역 이미지에 매핑시키고, 각 버텍스 (vertex)에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출하여 각 시점별 텍스쳐 이미지를 생성한다. 시점별 텍스쳐 생성부는 3차원 메쉬 정보를 2차원 평면에 투영시켜 2차원 메쉬 맵인 UV맵을 생성하는 UV맵 생성부를 포함한다. 시점별 텍스쳐 생성부는 객체 영역 이미지의 시점에 맞추어 3차원 메쉬의 각 버텍스를 배경이 제거된 객체 영역 이미지에 매핑시키고, 각 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추 출한다. 추출된 색상 정보를 2차원 UV맵에 적용하여 각 시점의 텍스쳐 이미지를 생성할 수 있다. 카메라의 시점 에 따라 객체에서 촬영되는 영역이 다르므로, 텍스쳐 이미지는 시점에 따라 다르게 생성된다. 텍스쳐 병합부는 각 시점의 텍스쳐 이미지들을 결합하여 각 시점의 모든 방향의 텍스쳐가 결합된 하나의 텍스쳐 이미지를 생성한다. 텍스쳐 병합부는, 각 시점의 텍스쳐 이미지들에서 색상 정보가 중복되는 버텍 스에는 중복되는 색상 정보 값들을 평균하여 텍스쳐 이미지를 생성한다. 색상 정보가 없는 버텍스에는 이미지 인페인팅(inpainting) 기술을 사용하여 색상 정보를 보강하여 텍스쳐 이미지를 생성한다. 이미지 인페인팅 기술 은 인접 버텍스의 색상정보를 이용하여 색상 정보를 보충할 수 있다. 색상 정보가 없는 빈 공간에 색상 정보를 보강하는 이미지 인페인팅(inpainting) 방법으로는, 구멍의 경계를 기반으로 조금씩 채우는 확산 기반 방법 외 에도, 유사한 패턴을 찾아 빈 공간을 채우는 패치기반 방법이 있으며, 딥러닝을 이용하는 합성곱 신경망을 이용 하는 방법, 생성적 적대 네트워크를 이용하는 방법 등을 사용할 수 있다. 도 5는 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 중 텍스쳐 생성부에서 텍스쳐를 생성하는 방법을 설명하는 개념도이다. 도 5(a)는 인체를 정면 시점에서 촬영한 이미지이다. 붉은 색으로 표시한 점은 3차원 메쉬의 일부 버텍스를 나 타낸다. 도 5(b)는 3차원 메쉬를 2차원 UV맵으로 나타낸 이미지이다. 붉은 색으로 표시한 점은 도 5(a)의 붉은 색으로 표시한 점에 대응한다. 도 5(b)의 UV맵에서 아래쪽 몸통의 붉은 점들은 중앙부에 위치한다. 도 5(c)는 정면 시점의 객체 영역 이미지에서 추출한 색상을 이용한 정면 시점의 텍스쳐 이미지이다. 몸통(주황색)의 중앙 부위만 색이 나타나 있다. 도 5(d)는 인체를 측면 시점에서 촬영한 이미지이다. 붉은 색으로 표시한 점은 3차원 메쉬의 일부 버텍스를 나 타낸다. 도 5(e)는 3차원 메쉬를 2차원 UV맵으로 나타낸 이미지이다. 붉은 색으로 표시한 점은 도 5(d)의 붉은 색으로 표시한 점에 대응한다. 도 5(e)의 UV맵에서 아래쪽 몸통의 붉은 점들은 오른쪽에 위치한다. 도 5(f)는 측면 시점의 객체 영역 이미지에서 추출한 색상을 이용한 측면 시점의 텍스쳐 이미지이다. 몸통(주황색)의 오른 쪽 부위만 색이 나타나 있다. 도 5(g)는 도 5(c)와 도 5(f)를 병합하여 생성한 텍스쳐 이미지이다. 중복되는 부분은 색상 평균으로, 비어 있 는 부분은 인접한 색상 정보를 이용하여 채울 수 있다. 도 6은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 방법을 나타내는 순서도이다. 다관절 객체의 입체영상을 캡쳐하는 방법은, 입체영상 캡쳐장치에 의해 수행된다. 입체영상 캡쳐 장치는 컴퓨터 장치에 의해 수행되는 하나 이상의 모듈로 구성될 수 있다. 컴퓨터 장치는 하나 이상의 프로세서와 프로 세서가 수행하는 명령어가 저장된 메모리를 포함한다. 다관절 객체의 입체영상을 캡쳐하는 방법은, 우선 다시점 이미지를 입력받는 단계(S610)를 포함한다. 다시점 이 미지는 외부의 다시점 카메라로부터 직접 입력되거나, 메모리 등의 저장장치에 저장된 이미지를 입력받을 수 있 다. 입력된 이미지를 이용하여 객체 세그멘테이션 단계(S630)와 메쉬정보 생성 단계(S650)를 수행한다. 다시점 이미지를 촬영하기 위한 다시점 카메라는 동일한 초점거리를 가지고 객체로부터 동일한 거리에 균등하게 배치되 는 복수의 카메라를 포함할 수 있다. 다시점 카메라를 이용하여 동시에 다른 시점에서 동일 객체를 촬영하셔 다 시점 이미지를 생성할 수 있다. 객체 세그멘테이션 단계(S630)에서는 입력된 다시점 이미지 각각에서 배경영역을 제거하고 객체 영역 이미지를 추출한다. 객체 영역 이미지 추출은 인공신경망을 사용할 수 있다. 인공신경망은 합성곱 신경망(CNN)과 같은 심 층 신경망을 사용할 수 있다. 메쉬 정보 생성단계(S650)에서는 입력된 다시점 이미지에서 구한 각 시점별 2차원 관절 위치 정보와 카메라 파 라미터 정보를 이용하여 3차원 관절 정보를 결정하고, 3차원 관절 정보에 3차원 메쉬 모델을 피팅시켜 3차원 메 쉬 정보를 생성한다. 시점별 텍스쳐 이미지 추출단계(S670)에서는 3차원 메쉬 정보를 2차원 평면에 투영시켜 2차원 메쉬 맵인 UV맵을 생성할 수 있다. 객체 영역 이미지의 각 시점에 따라 3차원 메쉬를 해당 시점의 객체 영역 이미지에 투영시키고, 3차원 메쉬의 버텍스에 매핑되는 객체 영역의 이미지에서 색상 정보를 추출하여 시점별 텍스쳐 이 미지를 생성한다. 텍스쳐 이미지 병합단계(S690)에서는 각 시점의 텍스쳐 이미지들을 결합하여 하나의 텍스쳐 이미지를 생성한다. 각 시점의 텍스쳐 이미지들에서 색상 정보가 중복되는 버텍스에는 중복되는 색상 정보 값들을 평균하고, 색상 정보가 없는 버텍스에는 인접 버텍스의 색상정보를 이용하여 색상 정보를 보충하여 텍스쳐 이미지를 생성한다. 도 7은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 방법 중 3차원 메쉬를 성성하는 단계 를 나타내는 순서도이다. 메쉬 정보 생성 단계(S650)는 2차원 관절 위치정보 결정 단계(S730)와, 3차원 관절 위지 결정 단계(S750)와 3차 원 메쉬 생성 단계(S770)를 포함한다. 2차원 관절 위치 결정 단계(S730)에서는 입력받은 다시점 이미지(S710)에서 2차원 관절 위치를 결정한다. 이미 지로부터 2차원 관절점(Joint)의 위치 정보를 구하는 방법으로는 OpenPose 알고리즘을 사용할 수 있다. OpenPose 알고리즘에서는 딥러닝 합성곱 신경망을 이용하여 25개의 2차원 관절 정보를 추출할 수 있다. 3차원 관절 위지 결정 단계(S750)에서는 2차원 관절 위치 정보(S730)와 카메라 파라미터 정보(S740)를 이용하여 3차원 관절의 위치를 결정한다. 카메라 파라미터 정보는 카메라 캘리브레이션 단계(S720)를 통해 구할 수 있다. 동일한 관절을 포함하는 복수의 다시점 이미지에서의 2차원 관절 위치 정보와, 각각의 다시점 이미지를 촬영한 카메라들의 외부 파라미터에 삼각측량법을 적용하여 관절의 3차원 위치를 결정할 수 있다. 3차원 메쉬 생성 단계(S770)에서는 3차원 관절 위치 정보를 입력받아서 3차원 객체 생성 모델에서 구한 관절, 자세 및 형상의 오차를 최소화하도록 학습된 3차원 객체 생성 모델 이용하여 3차원 부피감을 표현하는 3차원 메 쉬 파라미터 정보를 결정한다. 본 발명의 일 실시예에 따르면, 다시점 이미지에서 관절점을 추출하므로 종래기술보다 상대적으로 적은 카메라 만으로도 객체의 3차원 입체 영상을 캡쳐할 수 있으며, 카메라의 외부 파라미터를 이용한 3차원 관절 위치를 이 용하여 보다 정확한 3차원 메쉬를 생성할 수 있다. 표면의 세부적인 표현은 3차원 메쉬를 배경을 제거한 객체 영역 이미지에 투영시켜 얻는 텍스쳐 이미지를 이용한다. 이렇게 얻은 데이터는 게임 엔진, 3차원 시뮬레이션 환경(메타버스) 등의 3차원 에셋(assets)으로 활용할 수 있다. 이상에서 본 발명을 첨부된 도면을 참조하는 실시예들을 통해 설명하였지만 이에 한정되는 것은 아니며, 이들로 부터 당업자라면 자명하게 도출할 수 있는 다양한 변형예들을 포괄하도록 해석되어야 한다. 특허청구범위는 이 러한 변형예들을 포괄하도록 의도되었다."}
{"patent_id": "10-2022-0161142", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치의 구성을 나타내는 구성도이다. 도 2는 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 중 3차원 메쉬 생성부의 구성을 나타내는 구성도이다. 도 3은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치에서 3차원 관절 위치를 결정에 사용되는 카메라 좌표계를 나타내는 개념도이다. 도 4는 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 중 텍스쳐 생성부의 구성을 나 타내는 구성도이다. 도 5는 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 장치 중 텍스쳐 생성부에서 텍스쳐를 생성하는 방법을 설명하는 개념도이다. 도 6은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 방법을 나타내는 순서도이다. 도 7은 일 실시예에 따른 다시점 카메라 기반 다관절 객체의 입체영상캡쳐 방법 중 3차원 메쉬를 성성하는 단계 를 나타내는 순서도이다."}
