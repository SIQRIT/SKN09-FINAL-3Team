{"patent_id": "10-2023-0049241", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0153056", "출원번호": "10-2023-0049241", "발명의 명칭": "종단간 음성 데이터 비유창성 보정 시스템 및 방법", "출원인": "주식회사 바이칼에이아이", "발명자": "윤기현"}}
{"patent_id": "10-2023-0049241", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터에 의해 수행되는 방법에 있어서,사용자의 음성 데이터를 수신하는 단계;상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력하는 단계; 및상기 비유창성 음성 정보를 기반으로 상기 음성 데이터의 유창성을 보정하는 단계를 포함하되,상기 비유창성 음성 정보를 기반으로 상기 음성 데이터의 유창성을 보정하는 단계는,상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간을 삭제하는 단계; 및상기 비유창성 음성 구간이 삭제된 부분 음성 데이터를 결합하는 단계를 포함하는,종단간 음성 데이터 비유창성 보정 방법."}
{"patent_id": "10-2023-0049241", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력하는 단계는,상기 음성 데이터에서의 상기 비유창성 음성 구간의 시작 시간 및 길이 정보를 포함하는 비유창성 음성 정보를출력하는 것인,종단간 음성 데이터 비유창성 보정 방법."}
{"patent_id": "10-2023-0049241", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력하는 단계는,상기 음성 데이터에서의 반복 이벤트, 수정 이벤트, 주저 이벤트, 간투사 이벤트, 무의미어 이벤트, 첨가 이벤트, 대용어 이벤트 및 비운율적발성 이벤트에 대응하는 비유창성 음성 정보를 출력하는 것인,종단간 음성 데이터 비유창성 보정 방법."}
{"patent_id": "10-2023-0049241", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간을 삭제하는 단계는,상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 복수의 비유창성 음성 구간을 모두 삭제하는 것인,종단간 음성 데이터 비유창성 보정 방법."}
{"patent_id": "10-2023-0049241", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2024-0153056-3-상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간을 삭제하는 단계는,상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 복수의 비유창성 이벤트 각각의 가중치에 기초하여 비유창성 음성 구간 중 일부를 삭제하는 것인,종단간 음성 데이터 비유창성 보정 방법."}
{"patent_id": "10-2023-0049241", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간을 삭제하는 단계는,상기 음성 데이터에 대한 유창성 테스트 결과에 기초하여 결정된 각 비유창성 이벤트별 가중치를 적용하여 상기음성 데이터에서 비유창성 음성 구간 중 일부를 삭제하는 것인,종단간 음성 데이터 비유창성 보정 방법."}
{"patent_id": "10-2023-0049241", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "사용자의 음성 데이터를 수신하는 통신부,상기 음성 데이터의 유창성을 보정하기 위한 프로그램이 저장된 메모리 및상기 메모리에 저장된 프로그램을 실행시키는 프로세서를 포함하되,상기 프로세서는 상기 프로그램을 실행시킴에 따라, 상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력하고, 상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간을 삭제한 후, 비유창성 음성 구간이 삭제된 음성 데이터를 결합하여 상기 음성 데이터의 유창성을 보정하는 것인,종단간 음성 데이터 비유창성 보정 시스템."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "종단간 음성 데이터 비유창성 보정 방법이 제공된다. 상기 방법은 사용자의 음성 데이터를 수신하는 단계; 상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력하는 단계; 및 상기 비유 창성 음성 정보를 기반으로 상기 음성 데이터의 유창성을 보정하는 단계를 포함하되, 상기 비유창성 음성 정보를 기반으로 상기 음성 데이터의 유창성을 보정하는 단계는, 상기 음성 데이터에서 상기 비유창성 음성 정보에 포함 된 비유창성 음성 구간을 삭제하는 단계; 및 상기 비유창성 음성 구간이 삭제된 부분 음성 데이터를 결합하는 단 계를 포함한다."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 종단간 음성 데이터 비유창성 보정 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자연 발화는 보고 읽기와는 달리 여러가지 이유(말버릇, 실수, 발화의 난이도 등)로 비유창성 요소가 발화에 포 함될 수 있다. 이러한 비유창성 요소를 자연 발화 음성에서 구별하여 제거하면 발화자가 원래 의도했던 말글이 된다고 볼 수 있다. 뿐만 아니라, 비유창성 구간을 구분하고 제거하여 학습 데이터로 구성한다면 음성 인식 모델의 성능 또한 더욱 향상될 수 있다. 이러한 이유로, 사람의 발화로부터 유창성을 분석하고 보정하는 기술이 필요한 실정이다. 선행기술문헌 특허문헌"}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "(특허문헌 0001) 공개특허공보 제10-2022-0109604호(2022.08.05) 발명의 내용"}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 음성 데이터를 대상으로 비유창성 요소 구간을 판단하여, 비유창성 요소 구 간이 제거된 유창한 음성만이 출력되도록 하는, 종단간 음성 데이터 비유창성 보정 시스템 및 방법을 제공하는 것이다. 다만, 본 발명이 해결하고자 하는 과제는 상기된 바와 같은 과제로 한정되지 않으며, 또다른 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 제1 측면에 따른 종단간 음성 데이터 비유창성 보정 방법은 사용자의 음성 데이터를 수신하는 단계; 상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력하는 단계; 및 상기 비유창성 음성 정보를 기반으로 상기 음성 데이터의 유창성을 보정하는 단계를 포함한다. 이때, 상기 비유창성 음성 정보를 기반으로 상기 음성 데이터의 유창성을 보정하는 단계는, 상기 음 성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간을 삭제하는 단계; 및 상기 비유창성 음성 구간이 삭제된 부분 음성 데이터를 결합하는 단계를 포함한다. 본 발명의 일부 실시예에 있어서, 상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음 성 정보를 출력하는 단계는, 상기 음성 데이터에서의 상기 비유창성 음성 구간의 시작 시간 및 길이 정보를 포 함하는 비유창성 음성 정보를 출력할 수 있다. 본 발명의 일부 실시예에 있어서, 상기 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음 성 정보를 출력하는 단계는, 상기 음성 데이터에서의 반복 이벤트, 수정 이벤트, 주저 이벤트, 간투사 이벤트, 무의미어 이벤트, 첨가 이벤트, 대용어 이벤트 및 비운율적발성 이벤트에 대응하는 비유창성 음성 정보를 출력 할 수 있다. 본 발명의 일부 실시예에 있어서, 상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간 을 삭제하는 단계는, 상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 복수의 비유창성 음성 구간을 모 두 삭제할 수 있다. 본 발명의 일부 실시예에 있어서, 상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간 을 삭제하는 단계는, 상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 복수의 비유창성 이벤트 각각의 가중치에 기초하여 비유창성 음성 구간 중 일부를 삭제할 수 있다. 본 발명의 일부 실시예에 있어서, 상기 음성 데이터에서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간 을 삭제하는 단계는, 상기 음성 데이터에 대한 유창성 테스트 결과에 기초하여 결정된 각 비유창성 이벤트별 가 중치를 적용하여 상기 음성 데이터에서 비유창성 음성 구간 중 일부를 삭제할 수 있다. 또한, 본 발명의 제2 측면에 따른 종단간 음성 데이터 비유창성 보정 시스템은 사용자의 음성 데이터를 수신하 는 통신부, 상기 음성 데이터의 유창성을 보정하기 위한 프로그램이 저장된 메모리 및 상기 메모리에 저장된 프 로그램을 실행시키는 프로세서를 포함한다. 이때, 상기 프로세서는 상기 프로그램을 실행시킴에 따라, 상기 음 성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력하고, 상기 음성 데이터에 서 상기 비유창성 음성 정보에 포함된 비유창성 음성 구간을 삭제한 후, 비유창성 음성 구간이 삭제된 음성 데 이터를 결합하여 상기 음성 데이터의 유창성을 보정한다. 상술한 과제를 해결하기 위한 본 발명의 다른 면에 따른 컴퓨터 프로그램은, 하드웨어인 컴퓨터와 결합되어 상 기 종단간 음성 데이터 비유창성 보정 방법을 위한 프로그램을 실행하며, 컴퓨터 판독가능 기록매체에 저장된다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 본 발명에 의하면, 입력된 음성 데이터에 대하여 자동으로 비유창성 요소가 제거된 유창한 음성 데이터 를 출력할 수 있다. 이를 통해 청자는 유창성이 보정된 음성 데이터를 제공받아 더욱 정확하고 빠른 의도 파악이 가능하며, 발화자는 보정된 음성 데이터를 확인하여 자신의 발화에서 비유창성 요소가 무엇인지를 직관적으 로 확인할 수 있고 비유창성 요소가 제거된 음성 데이터를 통해 더욱 명료한 발화가 가능하도록 훈련할 수 있다."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 도 1은 본 발명의 일 실시예에 따른 종단간 음성 데이터 비유창성 보정 시스템의 블록도이다. 본 발명의 일 실시예에 따른 종단간 음성 데이터 비유창성 보정 시스템은 입력부, 통신부, 표시 부, 메모리 및 프로세서를 포함한다. 입력부는 종단간 음성 데이터 비유창성 보정 시스템의 사용자 입력에 대응하여 입력데이터를 발생시 킨다. 일 예로, 사용자 입력은 음성 데이터의 입력, 음성 데이터에 대한 선택 입력, 선택된 음성 데이터에 상응 하는 비유창성 음성 정보 확인 입력, 유창성 테스트 결과 확인 입력, 복수의 음성 데이터를 대상으로 하는 발화 변화 시점 정보에 대한 확인 입력 등일 수 있다. 입력부는 적어도 하나의 입력수단을 포함한다. 입력부 는 마이크(mike), 키보드(key board), 키패드(key pad), 돔 스위치(dome switch), 터치패널(touch panel), 터치 키(touch key), 마우스(mouse), 메뉴 버튼(menu button) 등을 포함할 수 있다.통신부는 사용자의 음성 데이터를 수신하며, 그밖에 데이터를 송수신하기 위해 서버나 사용자 단말 등 외 부장치와의 통신을 수행한다. 이와 같은 통신부는 유선 통신 모듈 및 무선 통신 모듈을 모두 포함할 수 있 다. 유선 통신 모듈은 전력선 통신 장치, 전화선 통신 장치, 케이블 홈(MoCA), 이더넷(Ethernet), IEEE1294, 통 합 유선 홈 네트워크 및 RS-485 제어 장치로 구현될 수 있다. 또한, 무선 통신 모듈은 WLAN(wireless LAN), Bluetooth, HDR WPAN, UWB, ZigBee, Impulse Radio, 60GHz WPAN, Binary-CDMA, 무선 USB 기술 및 무선 HDMI 기술, 그밖에 5G(5th generation communication), LTE-A(long term evolution-advanced), LTE(long term evolution), Wi-Fi(wireless fidelity) 등의 기능을 구현하기 위한 모듈로 구성될 수 있다. 표시부는 종단간 음성 데이터 비유창성 보정 시스템의 동작에 따른 표시 데이터를 표시한다. 일 예로 표시부는 음성 데이터의 전사 결과, 음성 데이터에 대한 비유창성 음성 정보, 음성 데이터의 보정 결과, 유창성 테스트 결과 등을 표시할 수 있다. 표시부는 액정 디스플레이(LCD; liquid crystal display), 발 광 다이오드(LED; light emitting diode) 디스플레이, 유기 발광 다이오드(OLED; organic LED) 디스플레이, 마 이크로 전자기계 시스템(MEMS; micro electro mechanical systems) 디스플레이 및 전자 종이(electronic paper) 디스플레이를 포함한다. 표시부는 입력부와 결합되어 터치 스크린(touch screen)으로 구현될 수 있다. 메모리는 음성 데이터의 유창성을 보정하기 위한 프로그램들을 저장한다. 여기에서, 메모리는 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 비휘발성 저장장치 및 휘발성 저장장치를 통칭하는 것이다. 예를 들어, 메모리는 콤팩트 플래시(compact flash; CF) 카드, SD(secure digital) 카드, 메모리 스틱(memory stick), 솔리드 스테이트 드라이브(solid-state drive; SSD) 및 마이크로(micro) SD 카드 등과 같은 낸드 플래 시 메모리(NAND flash memory), 하드 디스크 드라이브(hard disk drive; HDD) 등과 같은 마그네틱 컴퓨터 기억 장치 및 CD-ROM, DVD-ROM 등과 같은 광학 디스크 드라이브(optical disc drive) 등을 포함할 수 있다. 프로세서는 프로그램 등 소프트웨어를 실행하여 종단간 음성 데이터 비유창성 보정 시스템의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연 산을 수행할 수 있다. 이하에서는 도 2 내지 도 6을 참조하여 본 발명의 일 실시예에 따른 종단간 음성 데이터 비유창성 보정 시스템 에 의해 수행되는 방법을 설명하도록 한다. 도 2는 본 발명의 일 실시예에 따른 종단간 음성 데이터 비유창성 보정 방법의 순서도이다. 도 3은 본 발명의 일 실시예에서 보정된 음성 데이터를 출력하는 과정을 설명하기 위한 도면이다. 먼저, 사용자의 음성 데이터를 수신한다(S110). 이때, 음성 데이터는 하나의 문장을 기본 단위로 할 수 있으나 반드시 이에 한정되는 것은 아니며 복수 개의 문장으로 이루어진 문단 단위로 구성될 수도 있다. 다음으로, 수신한 음성 데이터를 미리 학습된 비유창성 식별 모델에 입력하여 비유창성 음성 정보를 출력한다 (S120). 이때, 본 발명의 일 실시예는 비유창성 식별 모델이 사용자의 음성 데이터를 직접 입력받는 End-to-End 구조로 구성되어 있다. 비유창성 식별 모델이 출력하는 비유창성 음성 정보는 비유창성 음성 구간의 시작 시간 및 길이 정보를 포함할 수 있다. 여기에서 비유창성 음성 구간은 음성 데이터에서 식별된 비유창성 이벤트에 상응하는 구간을 의미한다. 그리고 본 발명의 일 실시예에서의 비유창성 이벤트는 반복(repetition) 이벤트, 수정(revision) 이 벤트, 주저(hesitation) 이벤트, 간투사(filler) 이벤트, 무의미어 이벤트, 첨가(insertion) 이벤트, 대용어 이벤트 및 비운율적발성 이벤트를 포함할 수 있다. 다음으로, 비유창성 음성 정보를 기반으로 음성 데이터의 유창성을 보정한다(S130). 일 실시예로, 비유창성 식별 모델을 통해 비유창성 음성 정보가 출력되면, 음성 데이터에서 비유창성 음성 정보 에 포함된 비유창성 음성 구간을 삭제한다(S131). 그 다음, 비유창성 음성 구간이 삭제된 부분 음성 데이터를 결합하여 보정된 음성 데이터를 출력한다(S132). 아래 표 1은 비유창성 식별 모델이 음성 데이터를 입력받아 비유창성 음성 정보를 출력하고, 비유창성 음성 정 보에 기초하여 음성 데이터를 보정한 결과를 나타낸 것이다. - 입력: 나는 어어어어제 뭐냐 라면 아니 우동을 끓여어어 (...) 먹었어 - 출력: 나는 어제 우동을 끓여 먹었어 표 1 구간 1 2 3 4 5 6 7 8 9 10 입력 나는어어어어제뭐냐라면 아 니우동을끓여어어 먹었어 비유창성 식별 모델반복 삽입수정 연장주저 비유창성 음성 구간 삭제삭제 삭제삭제 삭제삭제 출력 나는 어제 우동을 끓여 먹었어 위 표 1의 예시와 같이, 본 발명의 일 실시예는 입력된 음성 데이터에서 비유창성 음성 정보에 포함된 복수의 비유창성 음성 구간을 모두 삭제하여 보정된 음성 데이터를 출력할 수 있다.다른 실시예로, 본 발명의 일 실시 예는 입력된 음성 데이터에서 비유창성 음성 정보에 포함된 복수의 비유창성 이벤트 각각의 가중치에 기초하여 비유창성 음성 구간 중 일부를 삭제하여 보정된 음성 데이터를 출력할 수 있다. 즉, 비유창성 음성 구간을 전부 삭제할 경우 가장 완벽한 보정된 음성 데이터가 출력되는 것이나, 일부 비유창성 음성 구간만을 삭제하는 것을 통해 비유창성 식별 모델의 학습 데이터로 활용하거나, 또는 모두 삭제하는 결과보다도 더 자연스러운 보정 결 과가 획득될 수도 있으므로, 이를 고려하여 일부 비유창성 음성 구간만을 삭제할 수도 있다. 이 경우, 복수의 비유창성 이벤트 각각에는 가중치가 설정되는데 일 예로 관리자에 의한 초기 기본 가중치가 설 정될 수 있다. 이때, 초기 기본 가중치는 비유창성 이벤트 중 의미를 포함하는 단어가 존재하는 경우 해당 비유 창성 이벤트에 가중치를 부여하는 등 다양한 조건에 따라 설정될 수 있다. 다른 일 예로, 음성 데이터에 포함된 비유창성 음성 구간 중 사용자에 의해 제거되길 희망하는 음성 구간에 상 응하는 비유창성 이벤트에 가중치를 부여할 수도 있다. 이처럼 타 비유창성 이벤트 대비 가중치가 높게 부여된 비유창성 이벤트 중 상위 N개에 상응하는 비유창성 음성 구간은 음성 데이터에서 삭제 보정될 수 있다. 또 다른 일 예로, 본 발명의 일 실시예는 음성 데이터를 대상으로 유창성 테스트 결과를 산출하고, 유창성 테스 트 결과에 기초하여 비유창성 이벤트의 가중치를 결정할 수도 있다. 예를 들어, 음성 데이터는 하나의 문장이라 가정하면, 제1 내지 제N 문장에 대하여 각각 유창성 테스트 결과를 산출한다. 여기에서 제1 문장의 유창성 테스트 결과는 '하' 등급, 제2 문장의 유창성 테스트 결과는 '중' 등급, 제3 문장의 유창성 테스트 결과는 '상' 등급이라 한다면, '하' 등급은 비유창성 이벤트가 상대적으로 많고, '상' 등급은 비유창성 이벤트가 상대적으로 적은 결과에 해당한다. 이때, '상' 등급의 유창성 테스트 결과를 갖는 제3 문장(음성 데이터)의 경우에는 소수의 비유창성 이벤트를 삭 제하는 것을 통해 유창성이 명확히 상승되는 것이 보장되므로 가장 높은 가중치를 부여한다. 반면, '하' 등급의 유창성 테스트 결과를 갖는 제1 문장(음성 데이터)의 경우에는 다수의 비유창성 이벤트를 전 부 삭제해야만 유창성이 상승될 수 있으며, 어느 비유창성 이벤트를 삭제하는 경우 유창성이 명확히 상승되는지 불분명하므로 가장 낮은 가중치를 부여한다. 이후, 제1 내지 제N 문장에 대한 비유창성 이벤트 및 이들에 적용된 가중치를 종합 적용(예를 들어 평균화)하여, 비유창성 이벤트별 가중치를 결정할 수 있다. 이하에서는 전술한 예시에서의 유창성 테스트 결과를 산출하는 구체적인 방법에 대해 설명하도록 한다. 도 4는 본 발명의 일 실시예에서의 유창성 테스트 결과를 생성하는 과정을 설명하기 위한 도면이다. 먼저, 사용자의 음성 데이터를 수신하고(S210), 수신한 음성 데이터를 전사한다(S220). 일 실시예로, 본 발명에서의 음성 데이터는 사용자와 적어도 하나의 타인 간의 1:1 또는 1:다 대화를 통해 획득 한 것일 수 있다. 이때, 소정의 사람일 수 있으며, 인공지능 기반의 AI 챗봇일 수도 있다. 다음으로, 전사된 음성 데이터를 대상으로 유창성 테스트 결과를 생성한다(S130). 도 5는 본 발명의 일 실시예에서 유창성 테스트 결과를 생성하는 상세 과정을 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시예에서 비유창성 반영도를 산출하는 과정을 설명하기 위한 도면이다. 일 실시예로, 유창성 테스트 결과를 생성하기 위해, 본 발명은 전사된 음성 데이터에서의 서로 다른 낱말 수 (NDW: Number of Different Word)를 산출하고(S232), 전사된 음성 데이터에서의 모든 단어 수(NTW: Number of Total Word)를 산출한다(S233). 여기에서 모든 단어 수는 중복되는 단어를 포함하여 모든 단어 수를 카운팅한다. 이때, 본 발명의 일 실시예는 서로 다른 낱말 수 및 모든 단어 수를 산출하기 위하여 전사된 음성 데이터를 대 상으로 형태소 분석을 수행하는 과정을 사전 수행할 수 있다(S231). 이후, 서로 다른 낱말 수 및 모든 단어 수에 기초하여 어휘 다양도(TTR: Type-Token Ratio)를 산출하며(S234), 이때 어휘 다양도는 식 1과 같이 서로 다른 낱말 수를 모든 단어 수로 나눈 결과값으로 산출될 수도 있다. [식 1]"}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그 다음, 전사된 음성 데이터에서의 어휘 다양도 및 비유창성 반영도를 기반으로 유창성 테스트 결과를 산출한 다(S235). 이때, 어휘 다양도와 비유창성 반영도는 점수로 산출된다. 간단한 일 예로, 유창성 테스트 결과는 식 2와 같이 나타낼 수 있다. [식 2]"}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "더욱 구체적으로 S235 단계에서 비유창성 반영도를 산출하기 위해, 먼저 전사된 음성 데이터에서 소정의 비유창 성 이벤트를 식별한다(S2351). 그 다음, 기 설정된 최대 점수에서 식별된 비유창성 이벤트만큼 차감하여 비유창성 반영도를 산출할 수 있다 (S2352). 이때, 전체 음성의 길이가 긴 경우 비유창성 반영도가 소정의 임계치 이하로 낮아지지 않도록 소정의 상수 등을 계산식의 분모에 추가할 수 있다. 소정의 상수는 전체 음성의 길이에 기초하여 결정될 수 있다. 결과적으로 유창성 테스트 결과 및 비유창성 반영도는 다음 식 3, 식 4와 같이 나타낼 수 있다. [식 3]"}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[식 4]"}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이때, 식 3에서의 df score는 비유창성 반영도를 나타내고, ttr은 어휘 다양도를 나타낸다. 또한, eDF와 eTTR은 비유창성 반영도와 어휘 다양도의 가중치, 즉 반영 비율을 나타낸다. 일 예로 비유창성 반영도의 반영비율은 70%, 어휘 다양도의 반영 비율은 30%로 설정할 수 있으며, 이는 전체 모집단의 특성 정보에 기반하여 결정될 수 있다. 또한, 식 4에서 F1 count, F2 count는 개별 비유창성 이벤트를 나타내며, eF1, eF2는 이들의 가중치를 의미한다. 이때, 본 발명의 일 실시예는 기 수행된 인구통계적 분석 결과를 기반으로 식별 대상인 비유창성 이 벤트에 대하여 각각의 가중치를 설정할 수 있다. 예를 들어, 음성 데이터에서 반복이 1번 발생하면 반복 점수를 감점시키게 되며, 이때 1점 또는 3점을 감점시킬 수 있다. 더욱 상세하게는, 계산 시점에 100마디의 음성 데이터를 한 경우 반복이 1번 발생하면 1점을 감점할 수도 있고, 3점을 감점할 수도 있으며, 1~3점의 계수 적용 여부는 전체 모집단의 특성 정보를 고려하여 결정될 수 있다(가장 기본적으로는 모집단의 평균과 비교하여 결정할 수 있다).또 다른 예로, 전체 모집단이 인수분해, 1차방정식, 2차방정식, 타원별로 서로 다른 점수치를 가지고 있을 때, 전체적으로 점수가 나올 수 있도록 하기 위해서 각 비유창성 이벤트(특징)별로 점수를 감점시킬 계수를 찾아내 고, 그 결과 인수분해는 1점, 1차방정식은 0.5점, 1차방정식 = 1.5점, 2차방정식 = 2점, 타원 = 3점과 같은 방 식으로 계수를 적용할 수 있다. 또한, 300마디의 음성 데이터를 한 경우 각각 감점을 시킬 때, 각 계수별로 1/3을 적용하면 된다. 뿐만 아니라, 본 발명의 일 실시예는 식 3인 유창성 테스트 결과를 산출함에 있어서 사용자의 음성 속도 정보를 측정하고, 음성 속도 정보에 대한 가중치를 더 반영할 수도 있다. 이때, 음성 속도는 음성 데이터의 구간 평균 으로 산출하여 적용할 수 있다. 또는, 서로 다른 낱말 수에 상응하는 개별 구간에서의 각 속도를 합산 및 평균 화하여 어휘 다양도 부분에 가중치로 적용하고, 비유창성 이벤트 식별 구간에서의 각 속도를 합산 및 평균화하 여 비유창성 반영도 부분에 기중치로 적용할 수도 있다. 도 7은 본 발명의 일 실시예에서 유창성 테스트 결과의 변화시점 정보를 제공하는 과정을 설명하기 위한 도면이 다. 일 실시예로, 본 발명은 일상 대화에서 주기적이고 반복적인 유창성을 측정하여 유창성이 떨어지는 지점을 파악 할 수 있다. 즉, 사용자의 복수의 음성 데이터를 대상으로 각각의 유창성 테스트 결과를 생성할 수 있다. 이를 위해, 전술한 S210 내지 S230 단계를 소정의 충분한 음성 데이터만큼 입력될 때까지 반복 수행하여(S236), 각 음성 데이터에 상응하는 유창성 테스트 결과를 생성할 수 있다. 소정의 음성 데이터 양만큼의 복수의 유창성 테스트 결과가 생성되고 나면, 각각의 유창성 테스트 결과 중 소정 등급(또는 점수) 이하의 유창성 테스트 결과에 상응하는 유창성 변화 시점 정보를 생성한다(S237, S238). 소정 등급 이하를 갖는 유창성 테스트 결과는 유창성이 급격히 떨어지는 지점을 의미하므로 해당 음성 데이터에 상응 하는 구간을 유창성 변화 시점 정보로 생성하여 사용자에게 제공한다(S239). 이를 통해, 사용자는 유창성 변화 시점 정보를 제공받음으로써 자신이 어떤 주제의 발화를 하는 도중 어떠한 구 간에서 유창성이 좋지 않았는지를 직관적으로 확인할 수 있다. 도 8은 본 발명의 일 실시예에서 담화 주제를 추천하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예는 사용자의 대화 주제를 보다 다양하게 만들도록 담화 주제를 추천할 수 있으며, 이를 통 해 보다 유창성이 더욱 향상되도록 할 수 있다. 즉, 복수의 음성 데이터를 대상으로 생성된 유창성 테스트 결과에 기초하여 다음 음성 데이터를 위한 담화 주제 를 추천 제시할 수 있다. 구체적으로, 전술한 유창성 테스트 결과가 생성되면 이는 사용자에게 제공됨과 동시에 DB 상에 저장된다. 이러 한 유창성 테스트 결과가 저장된 DB를 독출하여 유창성 테스트 결과에 상응하는 담화 유형 통계 및 담화 분포 정보를 생성할 수 있다(S310, S320). 그리고 담화 유형 통계 및 담화 분포 정보에 기초하여 사용자 맞춤형 담화 주제를 생성하고(S330) 이를 사용자 단말 등을 통해 제공할 수 있다(S340). 이와 같이 대화 주제를 다양하게 했을 때의 유창성 테스트 결과를 다시 산출하고 그 결과를 사용자에게 제공할 수 있으며, 이를 통해 보다 다양한 대화 주제에서의 유창성 테스트 결과를 확인할 수 있다는 장점이 있다. 또한, 사용자로 하여금 담화 유형 통계 및 담화 분포 정보에 기초한 담화 주제를 추천함으로써 보다 다양한 주 제에서의 유창성있는 대화가 가능하도록 지원할 수 있다. 이때, 본 발명의 일 실시예는 다음과 같은 예시의 맞춤형 담화 주제를 추천할 수 있다. - 이야기 담화(예: 흥부 놀부 이야기) - 절차적 담화(예: 라면 끓이는 방법, 제주도 여행 준비하기) - 일화적 담화(예: 서술기억에 의존하는 이야기, 딸과 함께 있었던 재미난 기억) - 대화적 담화(예: 대화를 진행하는 과정의 담화) - 설명적 담화(예: 개념이나 이론, 논리 등을 설명하기) 그밖에 본 발명의 일 실시예는 복수의 사용자 간의 음성 데이터를 기반으로 담화 주제를 추천할 수도 있다. 일 실시예로, 제1 사용자의 음성 데이터를 기반으로 제1 담화 유형 통계 및 제1 담화 분포 정보를 생성한다. 또 한, 제2 사용자의 음성 데이터를 기반으로 제2 담화 유형 통계 및 제2 담화 분포 정보를 생성한다. 그 다음, 제1 담화 유형 통계 및 제1 담화 분포 정보와 제2 담화 유형 통계 및 제2 담화 분포 정보에 기초하여 각 음성 데이터 간의 매칭도와 비매칭도를 산출한다. 그 다음, 상위 N개의 매칭도를 갖는 음성 데이터의 담화 주제를 제1 사용자에게 추천 제공할 수 있다. 또한, 상 위 M개의 비매칭도를 갖는 제2 사용자의 음성 데이터의 담화 주제를 제1 사용자에게 추천할 수 있다. 결과적으 로, 제1 사용자는 N개+M개의 담화 주제를 실시간으로 또는 소정의 시간이 경과한 후(예를 들어, 소정의 음성 데 이터가 누적된 후) 추천 제공받을 수 있다. 또 다른 실시예로, 본 발명은 제1 음성 데이터 구간에서의 제1 음성 데이터를 수신하여 제1 유창성 테스트 결과 를 산출한다. 이후 제1 음성 데이터와 동일한 주제인 제2 음성 데이터 구간에서의 제2 음성 데이터를 수신하여 제2 유창성 테스트 결과를 산출한다. 그리고, 제1 음성 데이터 구간에서의 제1 음성 데이터를 기반으로 제2 음 성 데이터 구간에서의 제2 예상 유창성 테스트 결과를 생성한다. 이후, 제2 유창성 테스트 결과와 제2 예상 유창성 테스트 결과를 비교하고, 비교 결과 제2 유창성 테스트 결과 가 제2 예상 유창성 테스트 결과보다 더 우수한 경우, 실제 사용자의 발화가 예상치보다 더욱 우수한 것이므로, 이후 제3 음성 데이터에 상응하는 제3 음성 데이터 구간의 길이를 더욱 증가시킬 수 있다. 즉, 제1 및 제2 음성 데이터가 1개의 문구 단위나, 1개의 문장 단위인 경우, 제3 음성 데이터는 2개의 문구 단위, 2개의 문장 단위 등으로 그 단위를 더욱 증가시킬 수 있다. 반대로, 비교 결과 제2 유창성 테스트 결과가 제2 예상 유창성 테스트 결과보다 더 열악한 경우, 실제 사용자의 발화가 예상치보다 더욱 열악한 것이므로, 이후 제3 음성 데이터에 상응하는 제3 음성 데이터 구간의 길이를 감 소시킬 수 있다. 이는 더욱 짧은 구간 동안 유창성 테스트 결과를 확인하여 보다 정밀하고 세부적인 피드백을 제공하기 위함이다. 이러한 단계는 동일 주제에 대한 대화가 완료될 때까지 또는 소정의 시간, 소정의 대화 길이를 만족할 때까지 반복 수행될 수 있다. 대화가 완료되면 해당 주제에 대한 평균 음성 데이터 구간 길이를 산출하고, 이를 DB상에 저장할 수 있다. 복수 의 사용자에 대한 평균 음성 데이터 구간 길이의 비교를 통해 개별 사용자의 유창성 정도의 비교 분석이 가능하 며, 전체 사용자의 평균치 이하의 사용자에게는 상위 등급의 사용자의 유창성 테스트 결과 및 상응하는 음성 데 이터를 제공하여 개별 훈련이 가능하도록 지원할 수 있다. 한편, 상술한 설명에서, 단계 S110 내지 S340은 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 한편, 기타 생략된 내용이라 하더라도 도 1의 내용은 도 2 내지 도 8의 내용과 상호 적용된다. 이상에서 전술한 본 발명의 일 실시예는, 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 어플리케 이션)으로 구현되어 매체에 저장될 수 있다. 상기 전술한 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, Ruby, 기계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하 는 필요한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들 을 상기 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있 다. 또한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하 는지 등에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다."}
{"patent_id": "10-2023-0049241", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2023-0049241", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 종단간 음성 데이터 비유창성 보정 시스템의 블록도이다. 도 2는 본 발명의 일 실시예에 따른 종단간 음성 데이터 비유창성 보정 방법의 순서도이다. 도 3은 본 발명의 일 실시예에서 보정된 음성 데이터를 출력하는 과정을 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에서의 유창성 테스트 결과를 생성하는 과정을 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에서 유창성 테스트 결과를 생성하는 상세 과정을 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시예에서 비유창성 반영도를 산출하는 과정을 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시예에서 유창성 테스트 결과의 변화시점 정보를 제공하는 과정을 설명하기 위한 도면이 다. 도 8은 본 발명의 일 실시예에서 담화 주제를 추천하는 과정을 설명하기 위한 도면이다."}
