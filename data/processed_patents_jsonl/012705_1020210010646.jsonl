{"patent_id": "10-2021-0010646", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0107697", "출원번호": "10-2021-0010646", "발명의 명칭": "컨텐츠 유형 분류 방법 및 그 장치", "출원인": "(주)아몬드미디어", "발명자": "박효준"}}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 의해 수행되는 방법에 있어서,컨텐츠에 포함된 컨텐츠 항목을 추출하는 단계;상기 컨텐츠 항목을 분석하여, 상기 컨텐츠 항목의 유형 관련도를 산출하되, 상기 유형 관련도는 상기 컨텐츠항목에 대응되도록 미리 결정된 복수의 유형 정보 각각과 상기 컨텐츠 항목 사이의 관련성을 나타내는 수치들의집합인, 단계; 및상기 유형 관련도를 이용하여, 상기 컨텐츠의 유형을 분류하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 추출하는 단계는,상기 컨텐츠에 포함된 이미지 내부의 텍스트 정보를 추출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 추출하는 단계는,상기 컨텐츠에 포함된 동영상의 음성 정보를 추출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 음성 정보를 추출하는 단계는,상기 음성 정보가 비언어 음성인 경우, 상기 음성 정보를 이미지화 하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 음성 정보를 이미지화 하는 단계는,상기 음성 정보에 대응되는 스펙트로그램을 생성하는 단계; 및상기 스펙트로그램을 라돈 변환하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3 항에 있어서,공개특허 10-2022-0107697-3-상기 음성 정보를 추출하는 단계는,상기 음성 정보가 언어 음성인 경우, 상기 음성 정보에 대응되는 텍스트 정보를 추출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 추출하는 단계는,상기 컨텐츠에 포함된 동영상의 적어도 하나의 스크린샷을 추출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 적어도 하나의 스크린샷을 추출하는 단계는,제1 스크린샷 및 제2 스크린샷을 추출하는 단계; 및상기 제1 스크린샷 및 상기 제2 스크린샷의 차이에 기초하여, 모션 정보를 추출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 제2 스크린샷을 추출하는 단계는,상기 제1 스크린샷과 상기 제2 스크린샷의 차이에 기초하여 생성된 복수의 모션 벡터들의 크기 합이 기준치 이상인 경우, 상기 제2 스크린샷을 추출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서,상기 제2 스크린샷을 추출하는 단계는,상기 제1 스크린샷과 상기 제2 스크린샷의 차이에 기초하여 생성된 복수의 모션 벡터들 중 크기가 기준 크기 이상인 모션 벡터의 개수가 기준 개수 이상인 경우, 상기 제2 스크린샷을 추출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8 항에 있어서,상기 모션 정보를 추출하는 단계는,상기 제1 스크린샷에 포함된 제1 포인트 및 상기 제1 포인트에 대응되는 상기 제2 스크린샷에 포함된 제2 포인트의 위치 차이에 기초하여, 모션 벡터를 생성하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1 항에 있어서,상기 복수의 유형 정보는 폭력물 유형 정보, 음란물 유형 정보, 정치물 유형 정보 및 표절물 유형 정보를 포함하는,공개특허 10-2022-0107697-4-컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1 항에 있어서,상기 유형 관련도를 산출하는 단계는,학습된 제1 인공 신경망에 상기 컨텐츠 항목을 입력하여, 상기 컨텐츠 항목의 상기 유형 관련도를 출력하는 제1모델을 이용하여, 상기 유형 관련도를 산출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1 항에 있어서,상기 분류하는 단계는,상기 컨텐츠에서 추출된 제1 컨텐츠 항목의 제1 유형 관련도 및 상기 컨텐츠에서 추출된 제2 컨텐츠 항목의 제2유형 관련도를 이용하여, 상기 컨텐츠의 최종 유형 관련도를 산출하되, 상기 최종 유형 관련도는 복수의 유형정보 각각과 상기 컨텐츠 사이의 관련성을 나타내는 수치들의 집합인, 단계; 및상기 최종 유형 관련도에 포함된 수치가 기준 수치 이상인 유형 정보에 대응되는 유형을 상기 컨텐츠의 유형으로 결정하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 최종 유형 관련도를 산출하는 단계는,학습된 제2 인공 신경망에 상기 제1 유형 관련도 및 상기 제2 유형 관련도를 입력하여, 상기 최종 유형 관련도를 출력하는 제2 모델을 이용하여, 상기 최종 유형 관련도를 산출하는 단계를 포함하는,컨텐츠 유형 분류 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "인공 신경망을 가지는 컴퓨팅 장치에서 수행되는 방법에 있어서,컨텐츠에서 추출된 제1 컨텐츠 항목의 제1 유형 관련도 및 상기 컨텐츠에서 추출된 제2 컨텐츠 항목의 제2 유형관련도를 상기 인공 신경망에 입력하여, 상기 컨텐츠의 최종 유형 관련도를 출력하도록 상기 인공 신경망을 학습시키는 단계를 포함하되,상기 제1 유형 관련도는 복수의 유형 정보 각각과 상기 제1 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합이고, 상기 제2 유형 관련도는 복수의 유형 정보 각각과 상기 제2 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합이고, 상기 최종 유형 관련도는 복수의 유형 정보 각각과 상기 컨텐츠 사이의 관련성을 나타내는 수치들의 집합이고,상기 인공 신경망을 학습시키는 단계는,상기 제1 컨텐츠 항목의 종류에 기초하여 결정된 제1 가중치를 상기 제1 유형 관련도에 부여하고, 상기 제2 컨텐츠 항목의 종류에 기초하여 결정된 제2 가중치를 상기 제2 유형 관련도에 부여하는 단계를 포함하는,컨텐츠 유형 분류 학습 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 제1 컨텐츠 항목은 이미지 정보이고, 상기 제2 컨텐츠 항목은 모션 정보 또는 텍스트 정보인 경우, 상기공개특허 10-2022-0107697-5-제1 가중치는 상기 제2 가중치보다 큰,컨텐츠 유형 분류 학습 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16 항에 있어서,상기 인공 신경망을 학습시키는 단계는,복수의 유형 정보 각각과 상기 컨텐츠에서 추출된 컨텐츠 항목 사이의 관련성을 나타내는 수치들 중 적어도 하나에, 다른 수치들에 부여되는 가중치와 상이한 가중치를 부여하는 단계를 포함하는,컨텐츠 유형 분류 학습 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서,상기 컨텐츠 항목이 음성 정보인 경우, 상기 음성 정보와 음란물 유형 정보의 관련성을 나타내는 수치에 부여되는 제3 가중치는, 상기 음란물 유형 정보가 아닌 유형 정보와 상기 음성 정보의 관련성을 나타내는 수치에 부여되는 제4 가중치보다 큰,컨텐츠 유형 분류 학습 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18 항에 있어서,상기 컨텐츠 항목이 이미지 정보인 경우, 상기 이미지 정보와 음란물 유형 정보의 관련성을 나타내는 수치에 부여되는 제5 가중치는, 상기 음란물 유형 정보가 아닌 유형 정보와 상기 이미지 정보의 관련성을 나타내는 수치에 부여되는 제6 가중치보다 큰,컨텐츠 유형 분류 학습 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제16 항에 있어서,상기 제1 컨텐츠 항목 및 상기 제2 컨텐츠 항목은 텍스트 정보이고, 상기 제1 컨텐츠 항목의 길이가 상기 제2컨텐츠 항목의 길이보다 긴 경우, 상기 제1 가중치는 상기 제2 가중치보다 큰,컨텐츠 유형 분류 학습 방법."}
{"patent_id": "10-2021-0010646", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "프로세서;네트워크 인터페이스;메모리; 및상기 메모리에 로드(load)되고, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되,상기 컴퓨터 프로그램은,컨텐츠에 포함된 컨텐츠 항목을 추출하는 인스트럭션(instruction);상기 컨텐츠 항목을 분석하여, 상기 컨텐츠 항목의 유형 관련도를 산출하되, 상기 유형 관련도는 상기 컨텐츠항목에 대응되도록 미리 결정된 복수의 유형 정보 각각과 상기 컨텐츠 항목 사이의 관련성을 나타내는 수치들의집합인, 인스트럭션; 및상기 유형 관련도를 이용하여, 상기 컨텐츠의 유형을 분류하는 인스트럭션을 포함하는,컨텐츠 유형 분류 장치.공개특허 10-2022-0107697-6-"}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 컨텐츠 유형 분류 방법 및 그 장치에 관한 것이다. 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 방 법은, 컴퓨팅 장치에 의해 수행되는 방법에 있어서, 컨텐츠에 포함된 컨텐츠 항목을 추출하는 단계, 상기 컨텐츠 항목을 분석하여, 상기 컨텐츠 항목의 유형 관련도를 산출하되, 상기 유형 관련도는 상기 컨텐츠 항목에 대응되 도록 미리 결정된 복수의 유형 정보 각각과 상기 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합인, 단계 및 상기 유형 관련도를 이용하여, 상기 컨텐츠의 유형을 분류하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컨텐츠 유형 분류 방법 및 그 장치에 관한 것이다. 보다 구체적으로는, 컨텐츠에서 추출된 컨텐츠 항 목과 미리 결정된 복수의 유형 정보 각각과의 관련성을 분석하여, 컨텐츠의 유형을 분류하는 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "개인이 다양한 컨텐츠를 직접 생산하고, 생산된 컨텐츠를 공유하는 다양한 플랫폼 서비스가 제공되고 있다. 이 러한 플랫폼 서비스의 운영자에게 있어서, 플랫폼 서비스의 사용자가 공유하는 컨텐츠의 유형을 분류하는 것은 중요한 문제이다. 컨텐츠의 유형을 분류하는 종래의 기술들 중 하나는, 컨텐츠에 포함된 태그(tag) 정보를 이용하는 방식이다. 다 만, 이러한 태그 정보를 이용하는 방식은, 컨텐츠를 생산한 플랫폼 서비스의 사용자가 컨텐츠의 실제 내용과 무 관한 태그 정보를 컨텐츠에 포함시킴으로써, 컨텐츠의 실제 내용과 무관하게 컨텐츠의 유형이 분류될 수 있다. 따라서, 컨텐츠의 실제 내용에 기초하여 컨텐츠를 자동적으로 분류하는 기술이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-0850774호 \"컨텐츠 분류 방법 및 그 방법을 수행할 수 있는 컨텐츠 재생 장 치\""}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 몇몇 실시예를 통해 해결하고자 하는 기술적 과제는, 컨텐츠를 자동적으로 분류하는 장치 및 그 장치 에서 수행되는 방법을 제공하는 것이다. 본 발명의 몇몇 실시예를 통해 해결하고자 하는 다른 기술적 과제는, 컨텐츠의 내용을 기초로 컨텐츠를 자동적 으로 분류하는 장치 및 그 장치에서 수행되는 방법을 제공하는 것이다. 본 발명의 몇몇 실시예를 통해 해결하고자 하는 또 다른 기술적 과제는, 컨텐츠에 복수의 컨텐츠 항목이 포함된 경우, 복수의 컨텐츠 항목을 기초로 컨텐츠를 자동적으로 분류하는 장치 및 그 장치에서 수행되는 방법을 제공 하는 것이다. 본 발명의 몇몇 실시예를 통해 해결하고자 하는 또 다른 기술적 과제는, 컨텐츠에 포함된 컨텐츠 항목을 추출하 는 장치 및 그 장치에서 수행되는 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 본 발명의 기술 분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한, 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 방법은, 컴퓨팅 장치에 의해 수행되는 방법에 있어서, 컨텐츠에 포함된 컨텐츠 항목을 추출하는 단계, 상기 컨텐츠 항목을 분석하여, 상기 컨텐츠 항목의 유형 관련도를 산출하되, 상기 유형 관련도는 상기 컨텐츠 항목에 대응되도록 미리 결정된 복수 의 유형 정보 각각과 상기 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합인, 단계 및 상기 유형 관련도 를 이용하여, 상기 컨텐츠의 유형을 분류하는 단계를 포함할 수 있다. 일 실시예에서, 상기 추출하는 단계는, 상기 컨텐츠에 포함된 이미지 내부의 텍스트 정보를 추출하는 단계를 포 함하거나 상기 컨텐츠에 포함된 동영상의 음성 정보를 추출하는 단계를 포함하거나 상기 컨텐츠에 포함된 동영상의 적어도 하나의 스크린샷을 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 음성 정보를 추출하는 단계는, 상기 음성 정보가 비언어 음성인 경우, 상기 음성 정보를 이미지화 하는 단계를 포함하거나 상기 음성 정보가 언어 음성인 경우, 상기 음성 정보에 대응되는 텍스트 정보 를 추출하는 단계를 포함할 수 있다. 여기서, 상기 음성 정보를 이미지화 하는 단계는, 상기 음성 정보에 대응 되는 스펙트로그램을 생성하는 단계 및 상기 스펙트로그램을 라돈 변환하는 단계를 포함할 수 있다. 일 실시예에서, 상기 적어도 하나의 스크린샷을 추출하는 단계는, 제1 스크린샷 및 제2 스크린샷을 추출하는 단 계 및 상기 제1 스크린샷 및 상기 제2 스크린샷의 차이에 기초하여, 모션 정보를 추출하는 단계를 포함할 수 있 다. 여기서, 상기 제2 스크린샷을 추출하는 단계는, 상기 제1 스크린샷과 상기 제2 스크린샷의 차이에 기초하여 생성된 복수의 모션 벡터들의 크기 합이 기준치 이상인 경우, 상기 제2 스크린샷을 추출하는 단계를 포함하거나 상기 제1 스크린샷과 상기 제2 스크린샷의 차이에 기초하여 생성된 복수의 모션 벡터들 중 크기가 기준 크기 이 상인 모션 벡터의 개수가 기준 개수 이상인 경우, 상기 제2 스크린샷을 추출하는 단계를 포함할 수 있다. 또한, 상기 모션 정보를 추출하는 단계는, 상기 제1 스크린샷에 포함된 제1 포인트 및 상기 제1 포인트에 대응되는 상 기 제2 스크린샷에 포함된 제2 포인트의 위치 차이에 기초하여, 모션 벡터를 생성하는 단계를 포함할 수 있다. 일 실시예에서, 상기 복수의 유형 정보는 폭력물 유형 정보, 음란물 유형 정보, 정치물 유형 정보 및 표절물 유 형 정보를 포함할 수 있다. 일 실시예에서, 상기 유형 관련도를 산출하는 단계는, 학습된 제1 인공 신경망에 상기 컨텐츠 항목을 입력하여, 상기 컨텐츠 항목의 상기 유형 관련도를 출력하는 제1 모델을 이용하여, 상기 유형 관련도를 산출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 분류하는 단계는, 상기 컨텐츠에서 추출된 제1 컨텐츠 항목의 제1 유형 관련도 및 상기 컨 텐츠에서 추출된 제2 컨텐츠 항목의 제2 유형 관련도를 이용하여, 상기 컨텐츠의 최종 유형 관련도를 산출하되, 상기 최종 유형 관련도는 복수의 유형 정보 각각과 상기 컨텐츠 사이의 관련성을 나타내는 수치들의 집합인, 단 계 및 상기 최종 유형 관련도에 포함된 수치가 기준 수치 이상인 유형 정보에 대응되는 유형을 상기 컨텐츠의 유형으로 결정하는 단계를 포함할 수 있다. 여기서, 상기 최종 유형 관련도를 산출하는 단계는, 학습된 제2 인 공 신경망에 상기 제1 유형 관련도 및 상기 제2 유형 관련도를 입력하여, 상기 최종 유형 관련도를 출력하는 제 2 모델을 이용하여, 상기 최종 유형 관련도를 산출하는 단계를 포함할 수 있다. 본 발명의 다른 실시예에 따른 컨텐츠 유형 분류 학습 방법은, 인공 신경망을 가지는 컴퓨팅 장치에서 수행되는 방법에 있어서, 컨텐츠에서 추출된 제1 컨텐츠 항목의 제1 유형 관련도 및 상기 컨텐츠에서 추출된 제2 컨텐츠 항목의 제2 유형 관련도를 상기 인공 신경망에 입력하여, 상기 컨텐츠의 최종 유형 관련도를 출력하도록 상기 인공 신경망을 학습시키는 단계를 포함하되, 상기 제1 유형 관련도는 복수의 유형 정보 각각과 상기 제1 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합이고, 상기 제2 유형 관련도는 복수의 유형 정보 각각과 상기 제2 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합이고, 상기 최종 유형 관련도는 복수의 유형 정보 각각과 상기 컨텐츠 사이의 관련성을 나타내는 수치들의 집합이고, 상기 인공 신경망을 학습시키는 단계는, 상기 제1 컨텐츠 항목의 종류에 기초하여 결정된 제1 가중치를 상기 제1 유형 관련도에 부여하고, 상기 제2 컨텐츠 항목 의 종류에 기초하여 결정된 제2 가중치를 상기 제2 유형 관련도에 부여하는 단계를 포함할 수 있다. 다른 실시예에서, 상기 제1 컨텐츠 항목은 이미지 정보이고, 상기 제2 컨텐츠 항목은 모션 정보 또는 텍스트 정 보인 경우, 상기 제1 가중치는 상기 제2 가중치보다 클 수 있다. 다른 실시예에서, 상기 인공 신경망을 학습시키는 단계는, 복수의 유형 정보 각각과 상기 컨텐츠에서 추출된 컨 텐츠 항목 사이의 관련성을 나타내는 수치들 중 적어도 하나에 다른 수치들에 부여되는 가중치와 상이한 가중치 를 부여하는 단계를 포함할 수 있다. 여기서, 상기 컨텐츠 항목이 음성 정보인 경우, 상기 음성 정보와 음란물 유형 정보의 관련성을 나타내는 수치에 부여되는 제3 가중치는, 상기 음란물 유형 정보 이외의 유형 정보와 상 기 음성 정보의 관련성을 나타내는 수치에 부여되는 제4 가중치보다 클 수 있다. 또한, 상기 컨텐츠 항목이 이 미지 정보인 경우, 상기 이미지 정보와 음란물 유형 정보의 관련성을 나타내는 수치에 부여되는 제5 가중치는, 상기 음란물 유형 정보 이외의 유형 정보와 상기 이미지 정보의 관련성을 나타내는 수치에 부여되는 제6 가중치 보다 클 수 있다. 다른 실시예에서, 상기 제1 컨텐츠 항목 및 상기 제2 컨텐츠 항목은 텍스트 정보이고, 상기 제1 컨텐츠 항목의 길이가 상기 제2 컨텐츠 항목의 길이보다 긴 경우, 상기 제1 가중치는 상기 제2 가중치보다 클 수 있다. 본 발명의 또 다른 실시예에 따른 컨텐츠 유형 분류 장치는, 프로세서, 네트워크 인터페이스, 메모리 및 상기 메모리에 로드(load)되고, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되, 상기 컴퓨터 프로그램 은, 컨텐츠에 포함된 컨텐츠 항목을 추출하는 인스트럭션(instruction), 상기 컨텐츠 항목을 분석하여, 상기 컨 텐츠 항목의 유형 관련도를 산출하되, 상기 유형 관련도는 상기 컨텐츠 항목에 대응되도록 미리 결정된 복수의 유형 정보 각각과 상기 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합인, 인스트럭션 및 상기 유형 관련 도를 이용하여, 상기 컨텐츠의 유형을 분류하는 인스트럭션을 포함할 수 있다."}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명한다. 본 발명의 이점 및 특징, 그리고 그것들 을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러 나 본 발명의 기술적 사상은 이하의 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으"}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "며, 단지 이하의 실시예들은 본 발명의 기술적 사상을 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명의 기술적 사상은 청구 항의 범주에 의해 정의될 뿐이다. 각 도면의 구성 요소들에 참조부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면상에 표 시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관 련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상 세한 설명은 생략한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있다. 또 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니 다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다.또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성 요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성 요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구 성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는 (comprising)\"은 언급된 구성 요소, 단계, 동 작 및/또는 소자는 하나 이상의 다른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 이하, 본 발명의 다양한 실시예들에 대하여 첨부된 도면에 따라 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 장치가 적용될 수 있는 예시적인 환경을 도시한다. 도 1에 도시된 컨텐츠 유형 분류 장치가 적용될 수 있는 예시적인 환경은 본 발명의 목적을 달성하기 위한 바람직한 실시예를 도시하고 있을 뿐이며, 필요에 따라 일부 구성 요소가 추가되거나 삭제될 수 있다. 또한, 도 1에 도시된 예시적인 환경의 구성 요소들은 기능적으로 구분되는 기능 요소들을 나타낸 것으로서, 복수의 구성 요소가 실제 물리적 환경에서는 서로 통합되는 형태로 구현될 수도 있음에 유의해야 한다. 이하, 도 1에 도시된 각 구성 요소에 대해 보다 구체적으로 설명하기로 한다. 사용자는 사용자 장치를 이용하여 컨텐츠를 생성할 수 있다. 이때, 사용자는 생성한 컨텐츠를 다 른 사용자들과 공유하기 위해 컨텐츠 공유 플랫폼 서비스에 업로드할 수 있다. 예를 들어, 제1 사용자는 제1 사 용자 장치(100a)를 이용하여 컨텐츠를 컨텐츠 공유 플랫폼 서비스에 업로드할 수 있고, 제2 사용자는 제2 사용자 장치(100b)를 이용하여 컨텐츠를 컨텐츠 공유 플랫폼 서비스에 업로드할 수도 있다. 또한, 제1 사용 자는 제2 사용자가 업로드한 컨텐츠를 컨텐츠 공유 플랫폼 서비스에서 열람할 수 있으며, 제2 사용자는 제1 사용자가 업로드한 컨텐츠를 컨텐츠 공유 플랫폼 서비스에서 열람할 수도 있다. 상술한 컨텐츠 공유 플랫폼 서비스를 복수의 사용자들에게 제공하기 위한 컴퓨팅 장치(미도시)가 도 1에 도시된 예시적인 환경에 추가될 수 도 있으나, 본 발명의 논지를 흐리지 않기 위해 보다 구체적인 설명은 생략하기로 한다. 사용자 장치는 컨텐츠를 데이터 저장소에 전송할 수 있다. 또한, 사용자 장치는 컨텐츠(1 0)를 컨텐츠 유형 분류 장치에 전송할 수도 있다. 여기서, 사용자 장치는, 노트북, 데스크톱(desktop), 랩 탑(laptop) 등이 될 수 있으나, 이에 국한되는 것은 아니며 컴퓨팅 기능이 구비된 모든 종류의 장치를 포함할 수 있다. 데이터 저장소는 사용자 장치가 전송한 컨텐츠를 수신할 수 있다. 이때, 데이터 저장소는 사용자 장치가 전송한 컨텐츠를 저장할 수 있다. 데이터 저장소는 추후 명세서의 기재에 의해 구체화될 컨텐츠 유형 분류 정보를 컨텐츠 유형 분류 장 치로부터 수신할 수 있다. 이때, 데이터 저장소는 컨텐츠에 대응되는 컨텐츠 분류 정보를 컨 텐츠와 함께 저장할 수 있다. 컨텐츠 공유 플랫폼 서비스를 제공하기 위한 컴퓨팅 장치(미도시)는 데이터 저장소에 저장된 컨텐츠 분류 정보를 이용하여, 폭력물 컨텐츠, 음란물 컨텐츠, 정치물 컨텐츠 및 표절물 컨텐츠 중 어느 하나로 분류된 컨텐츠를 서비스에서 삭제할 수 있다. 또한, 폭력물 컨텐츠, 음란물 컨텐츠, 정치물 컨텐츠 및 표절물 컨텐 츠 중 어느 하나로 분류된 컨텐츠를 업로드한 사용자의 계정에 페널티를 부여할 수도 있다. 상술한 예시들 은 컨텐츠 공유 플랫폼 서비스에서 컨텐츠 분류 정보를 이용할 수 있는 실례들이며, 이외에도 컨텐츠 공유 플랫폼 서비스를 운영하기 위해 컨텐츠 분류 정보가 다양하게 이용될 수 있음은 자명하다. 컨텐츠 유형 분류 장치는 사용자 장치로부터 컨텐츠를 수신할 수 있다. 또한, 컨텐츠 유형 분류 장치는 컨텐츠에 포함된 컨텐츠 항목을 추출할 수 있다. 여기서, 컨텐츠 항목은 컨텐츠를 구성하는 항 목들을 의미하는 것으로써, 예를 들어, 이미지 정보, 텍스트 정보, 동영상 정보 및 음성 정보 등을 포함할 수 있다. 컨텐츠 유형 분류 장치는 컨텐츠에 포함된 적어도 하나의 컨텐츠 항목을 분석하여, 컨텐츠 항목에 대 응되는 적어도 하나의 유형 관련도를 산출할 수 있다. 여기서, 유형 관련도는 컨텐츠 항목에 대응되도록 미리 결정된 복수의 유형 정보 각각과의 관련성을 나타내는 수치들을 의미할 수 있다. 또한, 컨텐츠 유형 분류 장치 는 적어도 하나의 유형 관련도를 이용하여, 컨텐츠의 유형을 분류하고, 컨텐츠 분류 정보를 생성할 수있다. 컨텐츠 유형 분류 장치는 생성한 컨텐츠 분류 정보를 데이터 저장소에 전송할 수 있다. 이외에 컨텐츠 유형 분류 장치가 컨텐츠의 유형 분류를 수행하는 구체적인 방법에 관해서는 추후 명세서의 기재를 통해 구체화될 것이다. 컨텐츠 유형 분류 장치는 하나 이상의 컴퓨팅 장치로 구현될 수 있다. 예를 들어, 컨텐츠 유형 분류 장치 의 모든 기능은 단일 컴퓨팅 장치에서 구현될 수 있다. 다른 예로써, 컨텐츠 유형 분류 장치의 제1 기능은 제1 컴퓨팅 장치에서 구현되고, 제2 기능은 제2 컴퓨팅 장치에서 구현될 수도 있다. 여기서, 컴퓨팅 장 치는, 노트북, 데스크톱(desktop), 랩탑(laptop) 등이 될 수 있으나, 이에 국한되는 것은 아니며 컴퓨팅 기능이 구비된 모든 종류의 장치를 포함할 수 있다. 다만, 컨텐츠 유형 분류 장치가 다양한 컨텐츠를 수집하 고, 그 유형을 분류해야 되는 환경이라면, 컨텐츠 유형 분류 장치는 고성능의 서버급 컴퓨팅 장치로 구현 되는 것이 바람직할 수 있다. 상술한 컴퓨팅 장치의 일 예에 대해서는 추후 도 15를 참조하여 설명하기로 한다. 몇몇 실시예에서, 컨텐츠 유형 분류 장치는 도 1의 다른 구성과 네트워크를 통해 통신할 수 있다. 네트워 크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 이동 통신망(mobile radio communication network), Wibro(Wireless Broadband Internet) 등과 같은 모든 종류의 유/무선 네트워크 로 구현될 수 있다. 지금까지 도 1을 참조하여 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 장치가 적용될 수 있는 예시적인 환경에 대하여 설명하였다. 이하에서는, 도 2 내지 도 14를 참조하여 본 발명의 다른 실시예에 따른 컨텐츠 유 형 분류 방법에 대해 구체적으로 설명하기로 한다. 도 2 내지 도 7에 도시된 방법들의 각 단계는 컴퓨팅 장치에 의해 수행될 수 있다. 다시 말하면, 방법들의 각 단계는 컴퓨팅 장치의 프로세서에 의해 실행되는 하나 이상의 인스트럭션들로 구현될 수 있다. 방법들에 포함되 는 모든 단계는 하나의 물리적인 컴퓨팅 장치에 의하여 실행될 수도 있을 것이나, 방법의 제1 단계들은 제1 컴 퓨팅 장치에 의하여 수행되고, 방법의 제2 단계들은 제2 컴퓨팅 장치에 의하여 수행될 수도 있다. 이하에서는, 방법들의 각 단계가 도 1에 예시된 컨텐츠 유형 분류 장치에 의해 수행되는 것을 가정하여 설명을 이어가 도록 한다. 다만, 설명의 편의상, 방법들에 포함되는 각 단계의 동작 주체는 그 기재가 생략될 수도 있다. 또한, 도 2 내지 도 7에 도시된 방법들은 본 발명의 목적을 달성하기 위한 바람직한 실시예일 뿐이며, 필요에 따라 일부 단계가 추가되거나 삭제될 수 있음은 물론이다. 도 2를 참조하면 단계 S100에서, 컨텐츠에 포함된 컨텐츠 항목이 추출된다. 컨텐츠 항목에 대한 보다 구체적인 설명을 위해 도 8을 참조하면, 컨텐츠가 이미지 정보, 텍스트 정보, 동영상 정보 및 음성 정보 등을 포함할 수 있음이 이해될 수 있다. 컨텐츠에 포함된 이미지 정보, 텍스트 정보, 동영상 정보 및 음성 정보는 그 자체로 분석되어, 추후 설명될 유형 관련도가 산출될 수 있다. 또한, 각 정보 를 가공 변형하여 추출된 정보로부터 유형 관련도가 산출될 수도 있다. 이하, 도 3 내지 도 4를 참조하여, 컨텐 츠 항목의 추출 동작을 보다 구체적으로 설명하기로 한다. 도 3을 참조하면 컨텐츠에 이미지가 포함된 경우(S111), 단계 S113에서 이미지 정보가 추출된다. 예를 들어, html로 작성된 웹페이지의 이미지 태그를 이용하여, 이미지 정보를 추출하는 기술이 적용될 수 있다. 이외에도 컨텐츠에 포함된 이미지 정보를 추출하기 위한 공지된 모든 기술이 본 실시예에 적용될 수 있다. 다음으로, 이미지 내부에 텍스트가 포함된 경우(S115), 단계 S117에서 이미지 내부의 텍스트 정보가 추출된다. 예를 들어, 이미지 내부의 경계(Contour)를 식별하는 알고리즘 등이 이미지 내부의 텍스트 정보를 추출하기 위 해 이용될 수 있다. 이외에도 이미지 내부의 텍스트 정보를 추출하기 위한 공지된 모든 기술이 본 실시예에 적 용될 수 있다. 정리하면, 컨텐츠에 이미지가 포함된 경우, 이미지 정보가 추출될 수 있다. 또한, 그 이미지 내부에 텍스트가 포함된 경우, 이미지 내부의 텍스트 정보가 추출될 수도 있다. 컨텐츠에 텍스트가 포함된 경우(S131), 단계 S133에서 텍스트 정보가 추출된다. 예를 들어, html로 작성된 웹페 이지의 텍스트 관련 태그를 이용하여, 텍스트 정보를 추출하는 기술이 적용될 수 있다. 다른 예를 들어, 컨텐츠 의 스크린샷을 생성하고, 앞서 단계 S117에서 설명된 이미지 내부의 텍스트 정보를 추출하는 알고리즘 등이 생 성된 스크린샷에 적용됨으로써, 텍스트 정보가 추출될 수도 있다. 이외에도 컨텐츠에 포함된 텍스트 정보를 추 출하기 위한 공지된 모든 기술이 본 실시예에 적용될 수 있다.도 4를 참조하면 컨텐츠에 동영상이 포함된 경우(S151), 단계 S153에서 동영상의 스크린샷이 추출된다. 여기서, 스크린샷이란 동영상을 특정 시점에서 캡쳐한 이미지 정보를 의미한다. 이와 관련된 보다 구체적인 설명을 위해 도 5를 참조하여 설명하기로 한다. 도 5를 참조하면 단계 S153a에서, 제1 스크린샷이 추출된다. 동영상으로부터 추출된 제1 스크린샷은 앞서 단계 S113에서 추출된 이미지 정보와 마찬가지로 취급되어, 추후 유형 관련도가 산출될 수 있다. 다음으로, 단계 S153b에서 제2 스크린샷이 추출된다. 즉, 제1 스크린샷 외에도 적어도 하나의 다른 스크린샷이 추출될 수도 있다. 이때, 동영상으로부터 추출되는 다른 스크린샷들도 제1 스크린샷과 마찬가지로 취급되어, 추 후 유형 관련도가 산출될 수 있음은 자명하다. 단계 S153b와 관련된 몇몇 실시예에서, 제1 스크린샷과 제2 스크린샷의 차이에 기초하여 생성된 복수의 모션 벡 터들의 크기 합이 기준치 이상인 경우, 제2 스크린샷을 추출할 수 있다. 또한, 단계 S153b와 관련된 다른 몇몇 실시예에서, 제1 스크린샷과 제2 스크린샷의 차이에 기초하여 생성된 복수의 모션 벡터들 중 크기가 기준 크기 이상인 모션 벡터의 개수가 기준 개수 이상인 경우, 제2 스크린샷을 추출할 수도 있다. 상술한 실시예들을 보다 구체적으로 설명하기 위해 도 9를 참조하여 설명하기로 한다. 도 9의 (a)가 제1 스크린샷(11a)이고, 도 9의 (b)가 제2 스크린샷(11b)이라면, 도 9의 (c)는 제2 스크린샷 (11b) 및 제1 스크린샷(11a)의 차이에 기초하여 생성되는 벡터들을 나타내는 도면이다. 이때, 제1 스크린샷 (11a)에 포함된 제1 포인트(1a)는 제2 스크린샷(11b)에 포함된 제2 포인트(1b)로 동영상의 시점 이동에 따라 그 위치가 이동했음이 확인될 수 있다. 이때, 제1 포인트(1a)와 제2 포인트(1b)의 위치 차이에 기초하여 생성된 모 션 벡터(1c)는 도 9의 (c)에서 확인될 수 있다. 이처럼 제1 스크린샷(11a)의 포인트들과 제2 스크린샷(11b)의 대응되는 포인트들의 위치 차이에 기초하여, 모션 벡터들이 생성될 수 있다. 이때 상술한 바와 같이, 생성되는 모션 벡터들의 스칼라 크기 합이 기준치 이상일 경우의 스크린샷이 제2 스크 린샷으로 추출될 수 있다. 모션 벡터들의 스칼라 크기 합이 기준치 이상인 스크린샷은, 제1 스크린샷으로부터 도출할 수 있는 이미지 정보와 다른 이미지 정보를 포함할 가능성이 높은 스크린샷이므로, 제2 스크린샷으로 추 출됨이 타당하다. 또한, 생성되는 모션 벡터들 중 그 크기가 기준 크기 이상인 모션 벡터의 개수가 기준 개수 이상인 스크린샷은, 마찬가지로 제1 스크린샷으로부터 도출할 수 있는 이미지 정보와 다른 이미지 정보를 포함할 가능성이 높은 스 크린샷이므로, 제2 스크린샷으로 추출됨이 타당하다. 즉, 제1 스크린샷과 비교할 때 많은 이미지 변형이 생겨서 상술한 조건들을 만족하는 경우, 제2 스크린샷이 추 출될 수 있다. 정리하면, 동영상 정보는 시점에 따라 각기 다른 이미지 정보를 포함하므로, 추출되는 스크린샷 의 수가 증가할수록 스크린샷을 분석하여 산출되는 유형 관련도의 개수가 증가하므로, 동영상 정보에 대응되는 유형 관련도가 정확하게 산출될 수 있을 것이다. 다만, 추출되는 스크린샷의 수가 증가할수록 추출되는 스크린 샷을 관리하기 위한 많은 컴퓨팅 자원이 소비되는 문제가 있다. 따라서, 제1 스크린샷과의 차이에서 발생하는 상술한 실시예들의 조건을 만족한 경우 비로소 제2 스크린샷을 추출함으로써, 동영상 정보의 이미지 정보 중 유 의미한 스크린샷을 추출할 수 있다. 또한, 이에 따라 컴퓨팅 로드를 감소시킬 수도 있다. 다시 도 5를 참조하여 설명하기로 한다. 다음으로 단계 S153c에서, 모션 정보가 추출된다. 본 단계에 관한 설명은 앞서 도 9의 (c)를 참조하여 설명된 내용이 참조될 수 있을 것이다. 본 실시예에 따르면, 동영상으로부터 스크린샷뿐만 아니라 적어도 둘 이상의 스 크린샷에 기초하여 생성되는 모션 정보가 추출될 수도 있다. 다시 도 4를 참조하여 설명하기로 한다. 도 4를 참조하면 컨텐츠에 동영상이 포함된 경우(S151), 단계 S155에서 동영상의 음성 정보가 추출된다. 여기서, 음성 정보는 동영상의 비언어 음성 정보 및 동영상의 언어 음성 정보를 포함할 수 있으며, 이와 관련된 보다 구체적인 설명은 추후 단계 S161 내지 S169의 단계들의 설명을 참조하면 이해될 수 있을 것이다. 다음으로 컨텐츠에 음성이 포함된 경우(S161), 단계 S163에서 음성 정보가 추출된다. 이때, 음성 정보가 언어 음성인 경우(S165), 단계 S167에서 음성 정보에 대응되는 텍스트 정보가 추출된다. 예를 들어, 언어 음성 정보 에 대응되는 텍스트 정보를 추출하기 위해, STT(Speech To Text) 알고리즘이 적용될 수 있다. 이외에도 언어 음 성 정보에 대응되는 텍스트 정보를 추출하기 위한 공지된 모든 기술이 본 실시예에 적용될 수 있다. 만약, 음성 정보가 비언어 음성인 경우(S165), 단계 S169에서 음성 정보가 이미지화 된다. 이와 관련된 보다 구 체적인 설명을 위해 도 6을 참조하여 설명하기로 한다.도 6을 참조하면 단계 S169a에서, 음성 정보에 대응되는 스펙트로그램이 생성된다. 여기서, 스펙트로그램은 소 리나 파동을 시각화하여 파악하기 위한 도구로써, 파형과 스펙트럼의 특징이 조합되어 있는 그래프를 의미한다. 보다 구체적인 설명을 위해 도 10을 참조하면, 예시적인 음성 정보에 대응되는 예시적인 스펙트로그램이 도시된 것이 확인될 수 있다. 이때, 스펙트로그램은 시간, 주파수 및 진폭으로 표현된다. 다만, 도 10의 3 차원 스펙트로그램에 한정되는 것은 아니고 진폭은 칼라바(Color Bar)의 색으로 표현함으로써, 시간 및 주파수에 의해 2차원 스펙트로그램으로 특정 음성 정보를 표현할 수도 있다. 여기서, 음성 정보를 스펙트로 그램으로 변환하기 위한 모든 공지 기술이 본 실시예에 적용될 수 있음을 유의해야 한다. 다시 도 6을 참조하여 설명하기로 한다. 다음으로 단계 S169b에서 스펙트로그램이 라돈 변환된다. 여기서, 라돈 변환은 라돈 공간에서 물체를 회전하며 사영(Projection)한 값을 의미한다. 보다 구체적인 설명을 위해 도 11 및 수학식 1을 참조하기로 한다. 수학식 1"}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, , , 및 는 도 11을 참조하면 그 의미를 알 수 있다. 즉, 를 라돈 변환하면, 가 생성된다. 라돈 변환은 라돈 축 방향으로 물체를 사영한 값을 의미하는데, 이러한 라돈 축의 및 각각의 값을 달리하면서 물체를 사영한다. 라돈 변환의 보다 구체적인 설명은 본 발명의 요지를 흐리지 않기 위해 생략하기로 한다. 도 12를 참조하면, 비언어 음성 정보를 라돈 변환한 예시들이 확인될 수 있다. 예를 들어, 도 12의 (a)는 일상 대화 소리를 라돈 변환한 예시이고, 도 12의 (b)는 음악 소리를 라돈 변환한 예시이고, 도 12의 (c)는 과격한 소리를 라돈 변환한 예시이다. 즉, 도 12를 참조하면 음성 정보의 특성에 따라 라돈 변환된 이미지가 서로 다른 패턴을 형성하는 것이 확인될 수 있다. 이러한 서로 다른 패턴을 가진 이미지 정보를 이용함으로써, 후술될 유 형 관련도가 산출될 수 있다. 비언어 음성 정보를 라돈 변환하는 보다 구체적인 예시들은, \"Automatic extraction of pornographic contents using radon transform based audio features, Myung Jong Kim et a l.\"을 참조하면 보다 명확히 이해될 수 있을 것이다. 다시 도 2를 참조하여 설명하기로 한다. 도 2를 참조하면 단계 S200에서 컨텐츠 항목의 유형 관련도가 산출된다. 여기서, 유형 관련도란 컨텐츠 항목에 대응되도록 미리 결정된 복수의 유형 정보 각각과 컨텐츠 항목 사이의 관련성을 나타내는 수치들의 집합을 의미 한다. 구체적인 예를 들어, 컨텐츠 항목이 이미지 정보인 경우, 이미지 정보에 대응되도록 미리 결정된 복수의 유형 정보는 폭력물 유형 정보, 음란물 유형 정보, 표절물 유형 정보 및 정치물 유형 정보를 포함할 수 있다. 이때, 이미지 정보와 각각의 유형 정보들의 관련성이 분석됨으로써, 수치들이 산출될 수 있다. 단계 S200과 관련된 몇몇 실시예에서, 컨텐츠 항목마다 대응되는 복수의 유형 정보가 다르게 설정될 수 있다. 상술한 예와 다른 예를 들어, 비언어 음성 정보는 폭력물 유형 정보, 음란물 유형 정보 및 표절물 유형 정보를 포함할 수 있다. 비언어 음성 정보는 정치물 유형 정보와는 관련성이 낮을 수 있으므로 비언어 음성 정보에 대 응되는 유형 정보에서 정치물 유형 정보를 제외함으로써, 유형 관련도 산출에 의해 발생될 수 있는 컴퓨팅 로드 를 낮출 수 있다. 단계 S200과 관련된 다른 몇몇 실시예에서, 학습된 제1 인공 신경망에 컨텐츠 항목을 입력하여, 컨텐츠 항목의 유형 관련도를 출력하는 제1 모델을 이용함으로써, 유형 관련도가 산출될 수 있다. 본 실시예는 유형 관련도를 산출하기 위해, 이미지 정보, 모션 정보 및 텍스트 정보 중 적어도 하나가 이용될 수 있다. 여기서, 비언어 음 성으로부터 얻을 수 있는 라돈 변환 이미지 정보 및 동영상으로부터 얻을 수 있는 스크린샷은 이미지 정보와 마 찬가지로 취급될 수 있다. 또한, 이미지 내의 텍스트 정보 및 언어 음성으로부터 얻을 수 있는 텍스트 정보는 텍스트 정보와 마찬가지로 취급될 수 있다. 상술한 정보들을 입력 데이터로 하여, 특정 주제와의 관련도를 산출 할 수 있는 공지된 모든 인공 지능 기술이 여기에 적용될 수 있다. 예를 들어, 모션 정보를 이용하여, 음란물 유형 정보를 검출하는 동작은, \"Video pornography detection through deep learning techniques and motion information, Mauricio Perez et al.\"가 참조될 수 있다.본 실시예에 따라 이미지 정보, 모션 정보 및 텍스트 정보 중 적어도 하나를 입력하여, 폭력물 유형 정보, 음란 물 유형 정보, 표절물 유형 정보 및 정치물 유형 정보 중 적어도 하나와의 관련성이 산출될 수 있다. 다음으로 단계 S300에서, 적어도 하나의 유형 관련도를 이용하여, 컨텐츠의 유형이 분류된다. 보다 구체적인 설 명을 위해 도 7을 참조하여 설명하기로 한다. 도 7을 참조하면 단계 S310에서, 최종 유형 관련도가 산출된다. 여기서, 최종 유형 관련도는 복수의 유형 관련 도를 이용하여 산출되는 것으로써, 복수의 유형 정보 각각과 컨텐츠 사이의 관련성을 나타내는 수치들의 집합을 의미한다. 단계 S310과 관련된 몇몇 실시예에서, 학습된 제2 인공 신경망에 복수의 유형 관련도를 입력하여, 최종 유형 관 련도를 출력하는 제2 모델을 이용함으로써, 최종 유형 관련도가 산출될 수 있다. 본 실시예는 최종 유형 관련도 를 산출하기 위해, 이미지 정보, 모션 정보 및 텍스트 정보 중 적어도 둘로부터 산출된 복수의 유형 관련도가 이용될 수 있다. 차원이 동일한 수치 정보들을 입력 데이터로 하여, 입력 데이터와 동일한 차원의 수치 정보들 을 출력하는 공지된 모든 인공 지능 기술이 여기에 적용될 수 있다. 보다 구체적인 설명을 위해 도 13을 참조하 여 설명하기로 한다. 도 13에는 제1 유형 관련도, 제2 유형 관련도 및 제3 유형 관련도의 실례가 도시된다. 이때, 제1 유형 관련도, 제2 유형 관련도 및 제3 유형 관련도는 각각 복수의 유형 정보 각각과의 관련성을 나 타내는 수치들(41a, 41b, 41c, 41d, 42a, 42b, 42c, 42d, 43a, 43b, 43c 및 43d)을 포함할 수 있다. 예를 들어, 제1 유형 정보와 관련된 수치들(41a, 42a, 43a), 제2 유형 정보와 관련된 수치들(41b, 42b, 43b), 제3 유형 정보와 관련된 수치들(41c, 42c, 43c) 및 제4 유형 정보와 관련된 수치들(41d, 42d, 43d)이 확인될 수 있 다. 도 13을 참조하면 상술한 제1 유형 관련도, 제2 유형 관련도 및 제3 유형 관련도에 대응되는 각각 의 가중치(44, 45, 46)가 부여되어, 최종 유형 관련도가 산출됨을 이해할 수 있다. 즉, 인공 지능 기술을 이용함으로써, 각각의 유형 관련도에 최적의 가중치(44, 45, 46)가 결정될 수 있음을 이해할 수 있다. 예를 들 어, 가중치(44, 45, 46)를 도출하기 위해 앙상블 기계 학습에 관한 기술이 이용될 수 있을 것이다. 단계 S310과 관련된 몇몇 실시예에서, 유형 관련도에 부여되는 가중치는 유형 관련도 산출의 근거가 되는 컨텐 츠 항목의 종류에 기초하여 결정될 수 있다. 예를 들어, 컨텐츠 항목이 이미지 정보인 경우, 이미지 정보는 컨 텐츠를 열람하는 사용자가 다른 컨텐츠 항목보다 직접적으로 인식할 수 있는 항목이므로, 이미지 정보로부터 산 출되는 유형 관련도에 보다 높은 가중치를 부여하여, 최종 유형 관련도를 산출하는 것이 타당하다. 도 13을 참조하여 구체적으로 설명하면, 도 13의 제1 유형 관련도는 이미지 정보에 기초하여 산출된 유형 관련도라 가정하고, 제2 유형 관련도 및 제3 유형 관련도는 각각 모션 정보 또는 텍스트 정보에 기초하 여 산출된 유형 관련도라 가정하면, 제1 가중치가 다른 가중치(45, 46) 보다 높게 설정될 수 있다. 보다 구체적인 예를 들어 설명하면, 이미지 정보로부터 산출된 유형 관련도는, 이미지 정보와 음란물 유형 정보 의 관련성을 나타내는 수치를 포함하고, 그 수치에 높은 가중치가 부여되어 최종 유형 관련도가 산출된다. 이에 따라, 음란물 유형 정보와 높은 관련성을 갖는 이미지 정보를 포함하는 컨텐츠를 보다 직접적으로 음란물 유형 으로 분류할 수 있다. 다른 예를 들어 설명하면, 이미지 정보로부터 산출된 유형 관련도는, 이미지 정보와 폭력 물 유형 정보의 관련성을 나타내는 수치를 포함하고, 그 수치에 높은 가중치가 부여되어 최종 유형 관련도가 산 출된다. 이에 따라, 폭력물 유형 정보와 높은 관련성을 갖는 이미지 정보를 포함하는 컨텐츠를 보다 직접적으로 폭력물 유형으로 분류할 수도 있다. 본 실시예와 같이 컨텐츠 항목의 종류에 기초하여 유형 관련도에 부여되는 가중치를 조절하기 위해서, 벌점 회 귀(Penalized regression)와 관련된 인공 지능 분야의 공지된 기술들이 적용될 수 있다. 예를 들어, 컨텐츠 항 목이 이미지 정보인 경우, 이미지 정보로부터 산출되는 유형 관련도에 대해서는 패널티 함수를 적용하지 않음으 로써, 이미지 정보 이외의 컨텐츠 항목들로부터 산출되는 유형 관련도에 부여되는 가중치보다 이미지 정보로부 터 산출되는 유형 관련도에 부여되는 가중치가 높게 형성될 수 있다. 단계 S310과 관련된 다른 몇몇 실시예에서, 복수의 유형 정보 각각과 컨텐츠 항목 사이의 관련성을 나타내는 수 치들 중 적어도 하나에 다른 수치들에 부여되는 가중치와 상이한 가중치가 부여될 수도 있다. 보다 구체적인 설명을 위해 도 13 및 도 14를 참조하여 설명하기로 한다. 도 14에는 도 13에 도시된 제1 가중치 를 보다 구체화한 실례가 도시된다. 도 13에 도시된 제1 유형 관련도는 제1 컨텐츠 항목과 제1 유형 정보와의 관련성을 나타내는 수치(41a), 제1 컨텐츠 항목과 제2 유형 정보와의 관련성을 나타내는 수치 (41b), 제 1 컨텐츠 항목과 제3 유형 정보와의 관련성을 나타내는 수치(41c) 및 제1 컨텐츠 항목과 제4 유형 정보와의 관 련성을 나타내는 수치들을 포함한다. 이때 최종 유형 관련도를 산출하기 위해서, 각각의 관련도를 나타내는 수 치들 중 적어도 하나에 다른 수치들에 부여되는 가중치와 상이한 가중치가 부여될 수 있다. 즉, w11(44a), w12(44b), w13(44c) 및 w14(44d) 중 적어도 하나가 다른 것들과 상이할 수 있다. 예를 들어, 음란물 유형의 컨텐츠를 보다 민감하게 식별하기 위해서, 컨텐츠 항목과 음란물 유형 정보의 관련성 을 나타내는 수치에 부여되는 가중치는 컨텐츠 항목과 음란물 이외의 유형 정보(e.g. 폭력물 유형 정보, 정치물 유형 정보 및 표절물 유형 정보)의 관련성을 나타내는 수치에 부여되는 가중치 보다 높게 설정될 수 있다. 본 실시예와 같이 유형 정보의 종류에 기초하여 유형 관련도에 부여되는 가중치를 조절하기 위해서, 상술한 벌 점 회귀(Penalized regression)와 관련된 인공 지능 분야의 공지된 기술들이 적용될 수 있다. 예를 들어, 유형 정보가 음란물 유형 정보인 경우, 유형 관련도에 포함된 음란물 유형 정보와 관련된 수치에 대해서 패널티 함수 를 적용하지 않음으로써, 음란물 유형 정보 이외의 유형 정보들과 관련된 수치에 부여되는 가중치보다 음란물 유형 정보와 관련된 수치에 부여되는 가중치가 높게 형성될 수 있다. 이에 따라, 컨텐츠에 포함된 음란물을 보 다 민감하게 식별할 수 있다. 단계 S310과 관련된 또 다른 몇몇 실시예에서, 복수의 컨텐츠 항목이 모두 텍스트 정보일 경우 텍스트 정보의 길이에 대응되도록 가중치가 결정될 수도 있다. 도 13을 참조하여 예를 들면, 제1 컨텐츠 항목의 길이가 제2 컨 텐츠 항목의 길이보다 긴 경우, 제1 컨텐츠 항목으로부터 산출된 제1 유형 관련도에 부여되는 제1 가중치 가 제2 컨텐츠 항목으로부터 산출된 제2 유형 관련도에 부여되는 제2 가중치 보다 클 수 있다. 본 실시예에 따르면, 텍스트 정보의 경우 텍스트 정보의 길이가 길수록 높은 추가 가중치가 부여됨으로써, 긴 텍스 트 정보를 포함하는 컨텐츠를 통해서 컨텐츠의 유형을 보다 직접적으로 분류할 수 있다. 다음으로 단계 S320에서 최종 유형 관련도에 포함된 수치가 기준 수치 이상인 유형 정보에 대응되는 유형이 컨 텐츠의 유형으로 결정된다. 예를 들어, 기준 수치가 0.5인 경우, 도 13에 도시된 최종 유형 관련도를 갖는 컨텐츠는 수치가 0.5 이상인 제1 유형 정보와 관련된 컨텐츠이면서, 제2 유형 정보와 관련된 컨텐츠로 결정될 수 있다. 지금까지 도 2 내지 도 14를 참조하여 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 방법을 설명하였다. 상술 한 방법에 따르면, 컨텐츠에 포함된 적어도 하나의 컨텐츠 항목에 기초하여, 컨텐츠의 유형이 분류될 수 있다. 이하, 도 15를 참조하여 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 장치를 구현할 수 있는 예시적인 컴퓨팅 장치를 보다 구체적으로 설명하기로 한다. 컴퓨팅 장치는 하나 이상의 프로세서, 버스, 통신 인터페이스, 프로세서에 의하 여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리와, 컴퓨터 프로그램을 저장하는 스토 리지를 포함할 수 있다. 다만, 도 15에는 본 발명의 실시예와 관련 있는 구성 요소들 만이 도시되어"}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "있다. 따라서, 본 발명이 속한 기술분야의 통상의 기술자라면 도 15에 도시된 구성 요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서 는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 실시예들에 따른 방법 을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드 할 수 있다. 메모리는 RAM 과 같은 휘발성 메모리로 구현될 수 있을 것이나, 본 발명의 기술적 범위가 이에 한정되는 것은 아니다. 버스는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(Address Bus), 데이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다.몇몇 실시예들에 따르면, 통신 인터페이스는 생략될 수도 있다. 스토리지는 상기 하나 이상의 프로그램과 각종 데이터를 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드 될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이 상의 인스트럭션들을 실행함으로써, 본 발명의 다양한 실시예에 따른 방법/동작들을 수행할 수 있다. 위와 같은 경우, 컴퓨팅 장치를 통해 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 장치가 구현될 수 있 다. 지금까지 도 1 내지 도 15를 참조하여 본 발명의 다양한 실시예들 및 그 실시예들에 따른 효과들을 언급하였다. 본 발명의 기술적 사상에 따른 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효 과들은 명세서의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다. 지금까지 도 1 내지 도 15를 참조하여 설명된 본 발명의 기술적 사상은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨 터가 읽을 수 있는 코드로 구현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매체(CD, DVD, 블루레이 디스크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨 터 구비 형 하드 디스크)일 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인터넷 등의 네트워크를 통하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상기 다른 컴퓨팅 장치에서 사용될 수 있다. 이상에서, 본 발명의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명 되었다고 해서, 본 발명의 기술적 사상이 반드시 이러한 실시예에 한정되는 것은 아니다. 즉, 본 발명의 목적 범위 안에서라면, 그 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 도면에서 동작들이 특정한 순서로 도시되어 있지만, 반드시 동작들이 도시된 특정한 순서로 또는 순차적 순서로 실행 되어야만 하거나 또는 모든 도시 된 동작들이 실행 되어야만 원하는 결과를 얻을 수 있는 것으로 이해되어 서는 안 된다. 특정 상황에서는, 멀티태스킹 및 병렬 처리가 유리할 수도 있다. 더욱이, 위에 설명한 실시예들 에서 다양한 구성들의 분리는 그러한 분리가 반드시 필요한 것으로 이해되어서는 안 되고, 설명된 프로그램 컴 포넌트들 및 시스템들은 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패 키지 될 수 있음을 이해하여야 한다."}
{"patent_id": "10-2021-0010646", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 본 발명이 다른 구체적인 형태로도 실시될 수 있다는 것을 이해할 수 있다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로 이해해야만 한다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명에 의해 정의되는 기술적 사상의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2021-0010646", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 컨텐츠 유형 분류 장치가 적용될 수 있는 예시적인 환경을 도시한다. 도 2는 본 발명의 다른 실시예에 따른 컨텐츠 유형 분류 방법을 나타내는 예시적인 순서도이다. 도 3 및 도 4는 도 2를 참조하여 설명된 컨텐츠 항목을 추출하는 동작을 보다 구체적으로 설명하기 위한 예시적 인 순서도이다. 도 5는 도 4를 참조하여 설명된 스크린샷을 추출하는 동작을 보다 구체적으로 설명하기 위한 예시적인 순서도이 다. 도 6은 도 4를 참조하여 설명된 비언어 음성 정보를 이미지화 하는 동작을 보다 구체적으로 설명하기 위한 예시 적인 순서도이다. 도 7은 도 2를 참조하여 설명된 컨텐츠 유형을 분류하는 동작을 보다 구체적으로 설명하기 위한 예시적인 순서 도이다. 도 8은 본 발명의 몇몇 실시예에서 참조될 수 있는 컨텐츠의 실례이다. 도 9는 도 5를 참조하여 설명된 스크린샷을 추출하는 동작을 부연 설명하기 위한 예시적인 도면이다. 도 10은 도 6을 참조하여 설명된 비언어 음성 정보를 이미지화 하는 동작을 부연 설명하기 위한 스펙트로그램의 실례이다. 도 11은 도 6을 참조하여 설명된 라돈 변환 동작을 부연 설명하기 위한 도면이다. 도 12는 본 발명의 몇몇 실시예에서 참조될 수 있는 이미지화 된 비언어 음성 정보의 실례이다. 도 13은 본 발명의 몇몇 실시예에서 참조될 수 있는 복수의 유형 관련도에 기초하여 최종 유형 관련도를 산출하 는 동작을 구체적으로 설명하기 위한 예시적인 도면이다. 도 14는 본 발명의 몇몇 실시예에서 참조될 수 있는 가중치를 구체적으로 설명하기 위한 예시적인 도면이다. 도 15는 본 발명의 일 실시예에 따른 장치를 구현할 수 있는 예시적인 하드웨어 구성도이다."}
