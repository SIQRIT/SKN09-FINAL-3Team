{"patent_id": "10-2020-0065298", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0147691", "출원번호": "10-2020-0065298", "발명의 명칭": "반려동물을 모니터링하기 위한 모니터링 장치 및 서버", "출원인": "삼성전자주식회사", "발명자": "이정환"}}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,통신 인터페이스; 메모리; 및모니터링 장치에 의해 촬영된 복수의 이미지를 상기 통신 인터페이스를 통해 상기 모니터링 장치로부터 수신하고,상기 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판단하고, 상기 이벤트가 발생한 것으로 판단된 경우, 상기 복수의 이미지 중 상기 이벤트가 발생한 것으로 판단된 시점을기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단하고,상기 판단된 이미지에 기초하여 상기 이벤트에 대응되는 클립 영상을 생성하여 상기 메모리에 저장하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 이미지 중 상기 적어도 하나의 이미지에서 상기 반려동물의 위치를 판단하고,상기 판단된 반려동물의 위치가 기설정된 제1 관심 영역 내인 경우, 상기 적어도 하나의 이미지를 분석하여 상기 반려동물과 관련된 이벤트가 발생했는지를 판단하는, 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 이미지 중 상기 적어도 하나의 이미지에서 상기 반려동물의 위치를 판단하고,상기 판단된 반려동물의 위치가 기설정된 제2 관심 영역 내인 경우, 상기 기설정된 제2 관심 영역에 대응되는상기 반려동물과 관련된 이벤트가 발생한 것으로 판단하는, 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는,상기 클립 영상 및 상기 이벤트에 대응되는 메시지를 상기 통신 인터페이스를 통해 사용자 단말 장치로 전송하는, 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는,상기 통신 인터페이스를 통해 사용자 단말 장치로부터 문의 메시지가 수신되면, 기설정된 복수의 이벤트 중 상기 문의 메시지에 대응되는 이벤트를 판단하고, 공개특허 10-2021-0147691-3-상기 판단된 이벤트에 대응되는 적어도 하나의 클립 영상이 상기 메모리에 저장되어 있는 경우, 상기 저장된 클립 영상 및 상기 판단된 이벤트가 발생했음을 나타내는 응답 메시지를 상기 통신 인터페이스를 통해 상기 사용자 단말 장치로 전송하는, 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 판단된 이벤트에 대응되는 적어도 하나의 클립 영상이 상기 메모리에 저장되어 있지 않은 경우, 상기 판단된 이벤트가 발생하지 않았음을 나타내는 응답 메시지를 상기 통신 인터페이스를 통해 상기 사용자 단말 장치로전송하는, 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,기설정된 복수의 이벤트 중 적어도 하나의 이벤트의 발생 시간 및 발생 횟수 중 적어도 하나에 기초하여 상기적어도 하나의 이벤트에 대한 히스토리 정보를 생성하고,상기 생성된 히스토리 정보를 상기 통신 인터페이스를 통해 사용자 단말 장치로 전송하는, 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 생성된 히스토리 정보에 기초하여 상기 반려동물의 상태를 판단하고, 상기 판단된 반려동물의 상태에 대응되는 메시지를 상기 통신 인터페이스를 통해 상기 사용자 단말 장치로 전송하는, 전자 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "반려동물 모니터링 장치에 있어서,이미지 센서;메모리; 및상기 이미지 센서를 통해 촬영된 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판단하고, 상기 이벤트가 발생한 것으로 판단된 경우, 상기 복수의 이미지 중 상기 이벤트가 발생한 것으로 판단된 시점을기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단하고,상기 판단된 이미지에 기초하여 상기 이벤트에 대응되는 클립 영상을 생성하여 상기 메모리에 저장하는, 프로세서;를 포함하는, 반려동물 모니터링 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는,상기 복수의 이미지 중 상기 적어도 하나의 이미지에서 상기 반려동물의 위치를 판단하고,상기 판단된 반려동물의 위치가 기설정된 제1 관심 영역 내인 경우, 상기 적어도 하나의 이미지를 분석하여 상기 반려동물과 관련된 이벤트가 발생했는지를 판단하는, 반려동물 모니터링 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2021-0147691-4-제9항에 있어서,상기 프로세서는,상기 복수의 이미지 중 상기 적어도 하나의 이미지에서 상기 반려동물의 위치를 판단하고,상기 판단된 반려동물의 위치가 기설정된 제2 관심 영역 내인 경우, 상기 기설정된 제2 관심 영역에 대응되는상기 반려동물과 관련된 이벤트가 발생한 것으로 판단하는, 반려동물 모니터링 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,통신 인터페이스;를 더 포함하고,상기 프로세서는,상기 클립 영상을 상기 통신 인터페이스를 통해 외부 전자 장치로 전송하는, 반려동물 모니터링 장치."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 장치의 제어 방법에 있어서,복수의 이미지를 수신하는 단계;상기 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판단하는 단계;상기 이벤트가 발생한 것으로 판단된 경우, 상기 복수의 이미지 중 상기 이벤트가 발생한 것으로 판단된 시점을기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단하는 단계; 및상기 판단된 이미지에 기초하여 상기 이벤트에 대응되는 클립 영상을 생성하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 반려동물과 관련된 이벤트가 발생했는지 판단하는 단계는,상기 복수의 이미지 중 상기 적어도 하나의 이미지에서 상기 반려동물의 위치를 판단하고,상기 판단된 반려동물의 위치가 기설정된 제1 관심 영역 내인 경우, 상기 적어도 하나의 이미지를 분석하여 상기 반려동물과 관련된 이벤트가 발생했는지를 판단하는, 제어 방법."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 반려동물과 관련된 이벤트가 발생했는지 판단하는 단계는,상기 복수의 이미지 중 상기 적어도 하나의 이미지에서 상기 반려동물의 위치를 판단하고,상기 판단된 반려동물의 위치가 기설정된 제2 관심 영역 내인 경우, 상기 기설정된 제2 관심 영역에 대응되는상기 반려동물과 관련된 이벤트가 발생한 것으로 판단하는, 제어 방법."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 클립 영상 및 상기 이벤트에 대응되는 메시지를 사용자 단말 장치로 전송하는 단계;를 더 포함하는, 제어방법."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,사용자 단말 장치로부터 문의 메시지가 수신되면, 기설정된 복수의 이벤트 중 상기 문의 메시지에 대응되는 이공개특허 10-2021-0147691-5-벤트를 판단하는 단계; 및상기 판단된 이벤트에 대응되는 적어도 하나의 클립 영상이 상기 메모리에 저장되어 있는 경우, 상기 저장된 클립 영상 및 상기 판단된 이벤트가 발생했음을 나타내는 응답 메시지를 상기 사용자 단말 장치로 전송하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 판단된 이벤트에 대응되는 적어도 하나의 클립 영상이 상기 메모리에 저장되어 있지 않은 경우, 상기 판단된 이벤트가 발생하지 않았음을 나타내는 응답 메시지를 상기 통신 인터페이스를 통해 상기 사용자 단말 장치로전송하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,기설정된 복수의 이벤트 중 적어도 하나의 이벤트의 발생 시간 및 발생 횟수 중 적어도 하나에 기초하여 상기적어도 하나의 이벤트에 대한 히스토리 정보를 생성하는 단계; 및상기 생성된 히스토리 정보를 사용자 단말 장치로 전송하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0065298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 생성된 히스토리 정보에 기초하여 상기 반려동물의 상태를 판단하는 단계; 및상기 판단된 반려동물의 상태에 대응되는 메시지를 상기 사용자 단말 장치로 전송하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는, 통신 인터페이스, 메모리, 모니터링 장치에 의해 촬영된 복수의 이미지 를 통신 인터페이스를 통해 모니터링 장치로부터 수신하고, 복수의 이미지 중 적어도 하나에 기초하여 반려동물 과 관련된 이벤트가 발생했는지 판단하고, 이벤트가 발생한 것으로 판단된 경우, 복수의 이미지 중 이벤트가 발 생한 것으로 판단된 시점을 기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단하고, 판단 된 이미지에 기초하여 이벤트에 대응되는 클립 영상을 생성하여 메모리에 저장하는 프로세서를 포함한다."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 반려동물을 촬영한 이미지를 기반으로 다양한 정보를 생성하여 제공하는 모니터링 장치 및 서버에 관한 것이다. 보다 상세하게는, 반려동물을 촬영한 이미지를 기반으로 이벤트의 발생 여부를 판단하고, 판단된 이벤트와 관련된 클립 영상을 제공하는 모니터링 장치 및 서버에 관한 것이다."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래 이용되던 펫 모니터링 장치는, 반려동물이 돌아다니는 곳을 촬영하여 반려동물에 대한 영상을 실시간으로 제공할 수 있었다. 일반적으로, 카메라를 통해 촬영된 이미지가 서버를 통해 사용자의 단말 장치/모바일 기기 등으로 제공되었다. 다만, 단순히 실시간으로 촬영된 복수의 이미지 중 적어도 일부를 단말 장치/모바일 기기 등을 통해 제공받는 것만으로는, 사용자가 반려동물의 상태를 명확히 파악하기 어려웠다."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 반려동물을 촬영하여 획득된 이미지들을 바탕으로 반려동물과 관련하여 발생한 이벤트가 무엇인지 판단할 수 있는 모니터링 시스템 및 전자 장치를 개시한다. 또한, 본 개시는, 발생한 이벤트에 대한 클립 영상 및/또는 히스토리 정보를 제공하는 모니터링 장치, 전자 장 치 및 사용자 단말 장치를 제공한다."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는, 통신 인터페이스, 메모리, 모니터링 장치에 의해 촬영된 복수의 이 미지를 상기 통신 인터페이스를 통해 상기 모니터링 장치로부터 수신하고, 상기 복수의 이미지 중 적어도 하나 에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판단하고, 상기 이벤트가 발생한 것으로 판단된 경우, 상 기 복수의 이미지 중 상기 이벤트가 발생한 것으로 판단된 시점을 기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단하고, 상기 판단된 이미지에 기초하여 상기 이벤트에 대응되는 클립 영상을 생성하 여 상기 메모리에 저장하는 프로세서를 포함한다. 본 개시의 일 실시 예에 따른 반려동물 모니터링 장치는, 이미지 센서, 메모리, 상기 이미지 센서를 통해 촬영 된 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판단하고, 상기 이벤트가 발생한 것으로 판단된 경우, 상기 복수의 이미지 중 상기 이벤트가 발생한 것으로 판단된 시점을 기준으로 기설 정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단하고, 상기 판단된 이미지에 기초하여 상기 이벤트 에 대응되는 클립 영상을 생성하여 상기 메모리에 저장하는, 프로세서를 포함한다. 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 복수의 이미지를 수신하는 단계, 상기 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판단하는 단계, 상기 이벤트가 발생한 것으 로 판단된 경우, 상기 복수의 이미지 중 상기 이벤트가 발생한 것으로 판단된 시점을 기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단하는 단계, 상기 판단된 이미지에 기초하여 상기 이벤트에 대 응되는 클립 영상을 생성하는 단계를 포함한다."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전자 장치, 모니터링 장치 및 사용자 단말 장치는 반려동물과 관련된 이벤트를 자동으로 분석하여 사 용자에게 클립 영상을 제공한다는 효과가 있다. 특히, 본 개시에 따른 전자 장치 및/또는 모니터링 장치는, 반려동물의 위치를 기반으로 이벤트의 발생 여부를 효과적으로 판단할 수 있으며, 사용자 단말 장치를 통해, 판단된 이벤트와 관련된 다양한 정보를 제공한다는 장 점이 있다."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다. 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또 는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소를 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 도 1은, 본 개시에 따라 전자 장치, 모니터링 장치 및 사용자 단말 장치를 포함하는 시스템의 동작을 개략적으로 설명하기 위한 도면이다. 다만, 도 1과 달리, 본 시스템에 포함된 모니터링 장치의 수 및/또 는 사용자 단말 장치의 수는 복수 개일 수도 있다. 일 예로, 전자 장치는 서버로 구현되고, 모니터링 장치는 이미지 센서를 구비한 촬영 장치로 구현되 며, 사용자 단말 장치는 스마트폰으로 구현될 수 있다. 도 1을 참조하면, 모니터링 장치는 반려동물인 고양이가 위치한 장소를 촬영하여 복수의 이미지를 획득 할 수 있다. 이때, 모니터링 장치는 비젼 센서를 통해 복수의 RGB 이미지를 획득할 수 있다. 여기서, 모니 터링 장치는 뎁스 센서를 추가로 이용하여 복수의 뎁스 이미지를 획득할 수도 있다.모니터링 장치는 촬영된 복수의 이미지를 분석하여 고양이와 관련된 적어도 하나의 이벤트가 발생했는 지 여부를 판단할 수 있다. 또한, 모니터링 장치는 발생한 이벤트가 무엇인지도 판단할 수 있다. 예를 들어, 고양이가 밥그릇에 담긴 사료를 먹는 경우, 모니터링 장치는 밥그릇과 관련된 '식 사' 이벤트가 발생한 것으로 판단할 수 있다. 예를 들어, 고양이가 캣 타워 상에서 이동하는 경우, 모니 터링 장치는 캣 타워와 관련된 '캣 타워 놀이' 이벤트가 발생한 것으로 판단할 수 있다. 이렇듯 특정한 이벤트가 발생한 것으로 판단된 경우, 모니터링 장치는 상술한 복수의 이미지 중 해당 이벤 트가 발생한 시점을 기준으로 기설정된 시간 범위 내에 촬영된 적어도 하나의 이미지(: RGB 이미지)를 포함하는 클립 영상을 생성할 수 있다. 그리고, 모니터링 장치는 생성된 클립 영상을 서버로 구현된 전자 장치(10 0)를 통해 사용자 단말 장치로 전송할 수 있다. 그 결과, 사용자 단말 장치는 발생한 이벤트에 대한 클립 영상을 사용자에게 제공할 수 있다. 한편, 복수의 이미지를 분석하는 과정은 서버로 구현된 전자 장치를 통해 수행될 수도 있다. 구체적으로, 모니터링 장치는 촬영된 복수의 이미지를 전자 장치로 전송할 수 있다. 이때, 모니터링 장치는 순차적으로 촬영된 복수의 이미지를 전자 장치에 실시간으로 전송할 수도 있다. 여기서, 전자 장치는 모니터링 장치로부터 수신된 복수의 이미지를 분석하여 고양이와 관련된 이 벤트가 발생했는지 여부를 판단할 수 있다. 그리고, 특정한 이벤트가 발생한 것으로 판단된 경우, 전자 장치는 상술한 복수의 이미지 중 해당 이벤트 가 발생한 시점을 기준으로 기설정된 시간 범위 내에 촬영된 적어도 하나의 이미지(: RGB 이미지)를 포함하는 클립 영상을 생성할 수 있다. 그리고, 전자 장치는 생성된 클립 영상을 사용자 단말 장치로 전송할 수 있다. 그 결과, 사용자 단말 장치는 발생한 이벤트에 대한 클립 영상을 사용자에게 제공할 수 있다. 이렇듯, 복수의 이미지를 분석하는 과정은 모니터링 장치 및/또는 전자 장치를 통해 수행될 수 있는 바, 이하 도 2 내지 도 4를 통해서는, 전자 장치가 복수의 이미지를 분석하는 경우를 전제로 다양한 동작 을 설명한다. 도 2는, 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 전자 장치는 서버로 구현될 수 있다. 도 2를 참조하면, 전자 장치는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 전자 장치가 모니터링 장치 및 사용자 단말 장치 등 다양한 외부 전자 장치와 통신을 수행하여 신호/데이터를 주고받기 위한 구성이다. 이를 위해 통신 인터페이스는 회로를 포 함할 수 있다. 전자 장치는 애플리케이션 서버로 동작할 수 있다. 이 경우, 전자 장치는 서버에 등록된 다양한 기기 (가령, 가전 기기 및 IoT 기기 등)를 통신 인터페이스를 통해 제어하고 관리할 수 있다. 구체적으로, 전자 장치는 사용자 계정 별로 적어도 하나의 모니터링 장치 및 적어도 하나의 사용자 단말 장치를 등록할 수 있다. 일 예로, 사용자 단말 장치는 별도의 서버로부터 전자 장치의 애플리케이션을 다운받아 설치할 수 있 다. 그리고, 사용자 단말 장치에서 제공된 애플리케이션의 실행 화면을 통해 사용자 계정이 입력되면, 사 용자 단말 장치는 전자 장치가 제공하는 웹 주소 내지는 서버에 접속할 수 있다. 그 결과, 사용자 단 말 장치는 전자 장치에 연결될 수 있다. 여기서, 사용자 단말 장치는 Wifi-direct 또는 블루투스 통신 등을 이용하여 모니터링 장치와 연결될 수 있다. 이때, 사용자 단말 장치를 통해 제공되는 애플리케이션의 실행 화면 상에서 특정한 액세스 포인트(Access Point, AP)를 선택하는 사용자 명령이 수신되면, 사용자 단말 장치는 액세스 포인트에 대한 정보를 모니터 링 장치로 전송할 수 있다. 이때, 액세스 포인트는, 모니터링 장치가 위치한 장소(: 반려동물의 위치 한 장소)의 와이파이 액세스 포인트일 수 있다.이 경우, 모니터링 장치는 해당 액세스 포인트를 통해 전자 장치의 웹 주소 내지는 서버에 접속할 수 있다. 이때, 모니터링 장치는 연결된 사용자 단말 장치에 대한 정보를 전자 장치로 전송할 수도 있다. 그리고, 전자 장치는 사용자 단말 장치의 사용자 계정에 모니터링 장치를 등록할 수 있다. 그 결과, 전자 장치는 사용자 계정에 등록된 모니터링 장치 및 사용자 단말 장치와 통신을 수행 할 수 있게 된다. 또한, 사용자 단말 장치는 전자 장치를 통해 모니터링 장치를 원격 제어할 수 있게 된다. 다만, 사용자 계정에 모니터링 장치 및 사용자 단말 장치가 등록되는 과정은 상술한 예에 한정되지 않으며, 이밖에 종래의 기술 상식에 따른 다양한 방식을 이용할 수 있음은 물론이다. 통신 인터페이스는 TCP/IP(Transmission Control Protocol/Internet Protocol), UDP(User Datagram Protocol), HTTP(Hyper Text Transfer Protocol), HTTPS(Secure Hyper Text Transfer Protocol), FTP(File Transfer Protocol), SFTP(Secure File Transfer Protocol), MQTT(Message Queuing Telemetry Transport) 등 의 통신 규약(프로토콜)을 이용하여 하나 이상의 외부 전자 장치와 다양한 정보를 송수신할 수 있다. 이를 위해, 통신 인터페이스는 유선 통신 및/또는 무선 통신을 통해 구현된 네트워크를 기반으로, 외부 전 자 장치와 연결될 수 있다. 이때, 통신 인터페이스는 외부 전자 장치와 직접적으로 연결될 수도 있지만, 네트워크를 제공하는 하나 이상의 외부 서버(ex. ISP(Internet Service Provider))를 통해서 외부 전자 장치와 연결될 수도 있다. 네트워크는 영역 또는 규모에 따라 개인 통신망(PAN; Personal Area Network), 근거리 통신망(LAN; Local Area Network), 광역 통신망(WAN; Wide Area Network) 등일 수 있으며, 네트워크의 개방성에 따라 인트라넷 (Intranet), 엑스트라넷(Extranet), 또는 인터넷(Internet) 등일 수 있다. 여기에서, 무선 통신은 LTE(long-term evolution), LTE-A(LTE Advance), 5G(5th Generation) 이동통신, CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), GSM(Global System for Mobile Communications), DMA(Time Division Multiple Access), WiFi(Wi-Fi), WiFi Direct, Bluetooth, NFC(near field communication), Zigbee 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 유선 통신은 이더넷(Ethernet), 광 네트워크(optical network), USB(Universal Serial Bus), 선더볼트(ThunderBolt) 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 여기서, 통신 인터페이스는 상술한 유무선 통신 방식에 따른 네트워크 인터페이스(Network Interface) 또 는 네트워크 칩을 포함할 수 있다. 한편, 통신 방식은 상술한 예에 한정되지 아니하고, 기술의 발전에 따라 새 롭게 등장하는 통신 방식을 포함할 수 있다. 메모리는 전자 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 적어도 하나의 인스트럭션 또는 데이터를 저장하기 위한 구성이다. 프 로세서는 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써 후술할 다양한 실시 예들에 따 른 동작을 수행할 수 있다. 메모리는 ROM, 플래시 메모리 등의 비휘발성 메모리를 포함할 수 있으며, DRAM 등으로 구성된 휘발성 메모 리를 포함할 수 있다. 또한, 메모리는 하드 디스크, SSD(Solid state drive) 등으로 구성된 스토리지를 포 함할 수도 있다. 프로세서는 전자 장치에 포함된 각 구성을 전반적으로 제어하기 위한 구성으로, CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit)와 같은 인공 지능 전용 프로세서 등으로 구현될 수 있다. 또한, 프로세서는 SRAM 등의 휘발성 메모리를 포함할 수 있다. 한편, 메모리에는 적어도 하나의 인공지능 모델이 저장될 수 있다. 예를 들어, 이미지에 포함된 반려동물이나 인간 등 다양한 객체를 인식하도록 훈련된 인공지능 모델, 적어도 하 나의 이미지를 이용하여 반려동물과 관련된 이벤트가 발생했는지 여부 및 발생한 이벤트가 무엇인지 판단하도록 훈련된 인공지능 모델 등이 데이터 형태로 메모리에 저장될 수 있다.저장된 인공지능 모델의 기능은 프로세서 및 메모리를 통해 수행될 수 있다. 이를 위해, 프로세서 는 하나 또는 복수의 프로세서로 구성될 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데 이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전 용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 다수의 학습 데이터들에 학습 알골지즘을 적용함으로써, 원하는 특성의 기정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도 형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치 (weight values)를 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치의 연산을 통해 신경망 연 산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의해 최 적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공지능 모델의 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있다. 예를 들어, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크(Deep Q-Networks) 등이 있으며, 다만 본 개시에서의 신경망이 전술한 예에 한정되 지는 않는다. 도 2를 참조하면, 프로세서는 이벤트 검출 모듈 및 클립 영상 생성 모듈을 이용하여 후술할 다 양한 동작을 수행할 수 있다. 이벤트 검출 모듈은 복수의 이미지를 기반으로 반려동물과 관련된 이벤트가 발생했는지 판단하기 위한 모 듈이다. 클립 영상 생성 모듈은, 이벤트가 발생한 경우, 발생한 이벤트와 관련된 클립 영상을 생성하기 위한 모듈 이다. 한편, 프로세서는 상술한 모듈들 외에도 사용자 단말 장치와 주고받는 메시지를 생성/관리하기 위한 메신저 모듈, 발생한 이벤트에 대한 히스토리 정보를 생성/관리하기 위한 이벤트 히스토리 모듈 및 반려동물과 관련된 적어도 하나의 다른 외부 장치를 제어하기 위한 외부 장치 제어 모듈 중 적어도 하나를 더 이용할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는 모니터링 장치에 의해 촬영된 복수의 이미지를 통신 인터페 이스를 통해 모니터링 장치로부터 수신할 수 있다. 이때, 프로세서는, 통신 인터페이스를 통해 모니터링 장치로부터, 모니터링 장치에 입력된 사운드에 대한 데이터를 함께 수신할 수 있다. 그리고, 프로세서는 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판 단할 수 있다. 이때, 프로세서는 이벤트 검출 모듈을 이용할 수 있다. 구체적으로, 이벤트 검출 모듈은 실시간으로 수신되는 복수의 이미지 각각을 분석하여 적어도 하나의 이벤 트가 발생했는지 판단하고, 또한 발생한 이벤트가 무엇인지 판단할 수 있다. 이를 위해, 메모리에는 반려동물과 관련된 기설정된 복수의 이벤트에 대한 정보가 저장되어 있을 수 있다. 여기서, 기설정된 복수의 이벤트는, 식사(: 사료 먹기), 물 마시기, 배변, 수면, 캣 타워 놀이, 공 놀이, 안전 구역 이탈 등 반려동물과 관련된 다양한 이벤트에 해당할 수 있으며, 전술한 예에 한정되는 것은 아니다. 이벤트 검출 모듈은, 적어도 하나의 인공지능 모델을 이용하여 적어도 하나의 이벤트의 발생 여부를 판단 할 수 있다.예를 들어, 메모리에는, 적어도 하나의 이미지가 입력되면, 입력된 적어도 하나의 이미지를 기반으로 반려 동물과 관련하여 발생한 이벤트가 무엇인지 판단하도록 훈련된 인공지능 모델 'A'가 저장되어 있을 수 있다. 인공지능 모델 'A'는, 적어도 하나의 이미지가 입력되면, 기설정된 복수의 이벤트 중 (발생한) 적어도 하나의 이벤트에 대한 정보(ex. 발생한 이벤트가 무엇인지)를 출력하도록 설계된 분류기 형태로 구현될 수 있다. 본 분 류기는, 아무런 이벤트도 발생하지 않았음을 나타내는 정보를 출력할 수도 있다. 이때, 이벤트 검출 모듈은 수신된 복수의 이미지를 인공지능 모델 'A'에 입력한 결과, 발생한 이벤트에 대 한 정보를 획득할 수 있다. 한편, 이벤트 검출 모듈은 수신된 복수의 이미지 중 일부만을 인공지능 모델 'A'에 입력하여, 발생한 이벤 트를 판단할 수도 있다. 예를 들어, 이벤트 검출 모듈은 복수의 이미지 중 적어도 하나의 이미지에서 반려동물의 위치를 판단할 수 있다. 그리고, 판단된 반려동물의 위치가 기설정된 제1 관심 영역 내인 경우, 이벤트 검출 모듈은 해당 이미지를 분석하여 반려동물과 관련된 이벤트가 발생했는지 판단할 수 있다. 구체적으로, 이벤트 검출 모듈은, 반려 동물의 위치가 기설정된 제1 관심 영역 내인 적어도 하나의 이미지만을 상술한 인공지능 모델 'A'에 입력할 수 있다. 관련하여, 도 3a 내지 도 3b는, 본 개시의 일 실시 예에 따라, 반려동물의 위치를 판단하고, 판단된 위치를 기 반으로 이미지를 분석하여 발생한 이벤트를 판단하는 전자 장치의 동작을 설명하기 위한 도면들이다. 도 3a에는, 수신된 복수의 이미지 중 연속하여 촬영된 두 이미지(301, 302)가 도시되었다. 도 3a를 참조하면, 이벤트 검출 모듈은 이미지들(301, 302) 각각에 포함된 고양이 및 밥그릇을 인 식할 수 있다. 구체적인 예로, 이벤트 검출 모듈은 이미지들(301, 302)을 객체를 인식하도록 훈련된 별도 의 인공지능 모델 'B'에 각각 입력한 결과, 각 이미지 내에서 고양이 및 밥그릇을 인식할 수 있다. 한편, 도 3a를 참조하면, 이벤트 검출 모듈은 밥 그릇에 근접한 영역(ex. 밥 그릇으로부터 기설정된 거리 내의 영역)을 제1 관심 영역(11')으로 식별할 수 있다. 다만, 제1 관심 영역(11')은 입력된 사용자 명령에 따라 기설정된 영역일 수도 있는바, 관련된 실시 예는 도 11을 통해 후술한다. 그리고, 이벤트 검출 모듈은, 이미지들(301, 302) 각각을 기반으로, 고양이가 제1 관심 영역(11') 내에 위치하는지 판단할 수 있다. 그리고, 도 3a를 참조하면, 이미지에서 고양이의 위치가 제1 관심 영역(11') 밖이기 때문에, 이벤트 검 출 모듈은 이미지를 인공지능 모델 'A'에 입력하지 않을 수 있다. 반면, 이미지에서는 고양이의 위치가 제1 관심 영역(11') 내이기 때문에, 이벤트 검출 모듈은 이 미지를 인공지능 모델 'A'에 입력할 수 있다. 도 3b를 참조하면, 이벤트 검출 모듈은, 고양이의 위치가 제1 관심 영역(11') 내인 이미지들(302, 303, 304)을 분석하여, '식사' 이벤트가 발생한 것으로 판단할 수 있다. 구체적으로, 이벤트 검출 모듈은 해당 이미지들(302, 303, 304)을 인공지능 모델 'A'에 입력한 결과, 고양이의 '식사' 이벤트가 발생한 것으로 판 단할 수 있다. 다만, 비록 고양이가 제1 관심 영역(11') 내에 들어가기는 했으나 사료를 먹지는 않은 경우라면, 이벤트 검 출 모듈은 '식사' 이벤트가 발생한 것으로 판단하지 않을 수 있다. 한편, 이벤트 검출 모듈은, 판단된 반려동물의 위치만을 이용하여 발생한 이벤트를 판단할 수도 있다. 구체적으로, 이벤트 검출 모듈은, 복수의 이미지 중 적어도 하나의 이미지에서 반려동물의 위치를 판단하 고, 판단된 반려동물의 위치가 기설정된 제2 관심 영역 내인 경우, 기설정된 제2 관심 영역에 대응되는 반려동 물과 관련된 이벤트가 발생한 것으로 판단할 수도 있다. 관련하여, 도 4는, 반려동물의 위치를 판단하고, 판단된 위치를 기반으로 발생한 이벤트를 판단하는 전자 장치 의 동작 예를 설명하기 위한 도면이다. 도 4는, '안전 구역'에 해당하는 기설정된 제2 관심 영역이 기설정된 상황을 가정한다. 이때, 제2 관심 영역은 입력된 사용자 명령에 따라 기설정된 것일 수 있다. 또는, 제2 관심 영역은 일정 기간 동안의 고양이의 이동 경로에 따라 기설정된 것일 수 있다. 예를 들어, 프로세서는 일정 기간 동안 고양이의 이동 경로를 추적하여 메모리에 저장할 수 있다. 그리 고, 프로세서는 고양이의 지난 이동 경로를 포함하는 적어도 하나의 영역을 제2 관심 영역으로 설 정할 수 있다. 이때, 프로세서는 고양이가 기설정된 횟수 이상 지나간 이력이 있는 위치만을 포함하는 영역을 제2 관심 영역으로 설정할 수도 있으나 이밖에도 다양한 방식이 가능하다. 도 4를 참조하면, 이미지에서, 고양이는 제2 관심 영역 내에 있으므로, 이벤트 검출 모듈은 '안전구역 이탈' 이벤트가 발생하지 않은 것으로 식별할 수 있다. 반면, 이미지에서, 고양이는 제2 관심 영역 밖에 있으므로, 이벤트 검출 모듈은 '안전 구역 이탈' 이벤트가 발생한 것으로 판단할 수 있다. 상술한 과정들을 통해 적어도 하나의 이벤트가 발생한 것으로 판단된 경우, 프로세서는 발생한 이벤트에 대한 클립 영상을 생성할 수 있다. 구체적으로, 프로세서는 (수신된) 복수의 이미지 중 이벤트가 발생한 것으로 판단된 시점을 기준으로 기설 정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단할 수 있다. 그리고, 프로세서는 판단된 이미 지에 기초하여 이벤트에 대응되는 클립 영상을 생성할 수 있다. 관련하여, 도 5는, 본 개시의 일 실시 예에 따라, 이벤트가 발생한 시점을 기반으로 클립 영상을 생성하는 전자 장치의 동작을 설명하기 위한 도면이다. 도 5는, 이벤트 검출 모듈이 고양이의 위치를 기반으로 이미지들(503, 504, 505, ...)을 분석하여 '식사' 이벤트가 발생했음을 식별한 경우를 가정한다. 이 경우, 프로세서는, 해당 이미지들(503, 504, 505, ...) 중 '식사' 이벤트가 시작되는 시점에 촬영된 이 미지를 식별할 수 있다. 도 5를 참조하면, 프로세서는 고양이가 사료를 먹기 시작하는 시점에 촬영된 이미 지를 '식사' 이벤트가 시작되는 시점에 촬영된 이미지로 식별할 수 있다. 그리고, 프로세서는 클립 영상 생성 모듈을 제어하여 클립 영상을 생성할 수 있다. 구체적으로, 도 5를 참조하면, 클립 영상 생성 모듈은 해당 이미지가 촬영된 시점 또는 해당 이미지 가 촬영된 시점으로부터 일정 시간 이전의 시점을 이벤트가 발생한 시점(T0)으로 판단할 수 있다. 여기서, 일정 시간은, 복수의 이미지의 촬영 간격(프레임 간격)을 기반으로 설정될 수 있으나 이에 한정되지 않는다. 그리고, 클립 영상 생성 모듈은, 이벤트가 발생한 시점(T0)으로부터 기설정된 시간 동안(T0 ~ T0+T1) 촬영 된 이미지들을 포함하는 클립 영상을 생성할 수 있다. 여기서, 프로세서는 모니터링 장치에 입력된 사운드 중 클립 영상에 포함된 이미지들이 촬영된 시간 구간(T0 ~ T0+T1) 동안에 모니터링 장치에 입력된 사운드를 클립 영상에 대응되는 사운드로 식별할 수 있다. 여기서, 기설정된 시간(ex. T1)은, 발생한 이벤트에 따라 달리 설정될 수 있다. 예를 들어, '식사' 이벤트의 클 립 영상의 시간 길이는 '30초'로 기설정되고, '배변' 이벤트의 클립 영상의 시간 길이는 '20초'로 기설정될 수 있다. 한편, 클립 영상 생성 모듈은, 도 5와 달리, 이벤트가 발생한 것으로 판단된 시점(T0)보다 일정 시간(T2) 이전의 특정 시점('T0-T2')으로부터 'T0+T1' 시점까지 촬영된 이미지들을 이용하여 클립 영상을 생성할 수도 있 다. 한편, 기설정된 시간은 사용자 명령에 따라 설정된 것일 수도 있다. 예를 들어, 사용자 단말 장치를 통해 입력된 사용자 명령에 따라 클립 영상의 시간 길이가 '30초'로 설정 된 경우를 가정할 수 있다. 이때, 사용자 단말 장치로부터 사용자 명령에 대한 정보를 수신한 프로세서 는, 기설정된 시간을 '30초'로 설정할 수 있다. 이 경우, 클립 영상 생성 모듈은 이벤트 발생 시점으 로부터 30초 동안 촬영된 이미지들을 포함하는 30초 길이의 클립 영상을 생성할 수 있다. 한편, 클립 영상 생성 모듈은, 이미지들(503, 504, 505, ...)을 분석하여 '식사'가 종료된 시점을 식별할 수도 있다. 이 경우, 클립 영상 생성 모듈은 '식사'가 시작된 시점부터 '식사'가 종료된 시점까지 촬영된 이미지들을 포함하는 클립 영상을 생성할 수도 있다. 프로세서는 클립 영상을 메모리에 저장할 수 있다. 이때, 프로세서는, 클립 영상에 대응되는 사 운드에 대한 데이터도 클립 영상과 함께 저장할 수 있다. 여기서, 프로세서는, 분석을 위해 메모리에 임시로 저장되었던 복수의 이미지는 삭제할 수 있다. 즉, 프로세서는 복수의 이미지 중 클립 영상에 포함되는 이미지만을 메모리에 남기고, 나머지 이미지들은 삭제할 수 있다. 또는, 프로세서는 복수의 이미지들을 삭제하지 않은 채, 클립 영상과 별도로 메모리에 저장해둘 수도 있다. 클립 영상은, 대응되는 이벤트에 대한 정보와 함께 메모리에 저장될 수 있다. 여기서, 이벤트에 대한 정보 는, 이벤트의 내용(ex. 식사, 배변, 캣 타워 놀이 등), 이벤트의 이벤트의 발생 시점, 이벤트의 종료 시점, 이 벤트의 발생 위치, 이벤트의 지속 시간 등에 대한 정보를 포함할 수 있다. 모니터링 장치가 복수 개인 경우, 이 벤트에 대한 정보는, 이벤트의 발생을 감지한 모니터링 장치에 대한 식별 번호를 포함할 수도 있다. 프로세서는, 클립 영상을 사용자 단말 장치로 전송할 수 있다. 이때, 사용자 단말 장치는 클립 영상을 재생하여 사용자에게 제공할 수 있다. 프로세서는, 통신 인터페이스를 통해, 발생한 이벤트에 대응되는 메시지를 사용자 단말 장치로 전송할 수 있다. 구체적으로, 프로세서는 메신저 모듈을 이용하여 통신 인터페이스를 통해 사용자 단말 장치 와 메시지를 주고받을 수 있다. 이때, 사용자 단말 장치는, 메신저 모듈과 메시지를 송수신하고, 송수신된 메시지를 사용자에게 제공하기 위한 메신저 애플리케이션을 이용할 수 있다. 메신저 모듈은 발생한 이벤트에 대한 정보를 이용하여 이벤트와 관련된 메시지를 생성할 수 있다. 그리고, 메신저 모듈은 생성된 메시지를 사용자 단말 장치로 전송할 수 있다. 이때, 메신저 모듈은 발생 한 이벤트에 대응되는 클립 영상을, 생성된 메시지와 함께 사용자 단말 장치로 전송할 수도 있다. 이벤트와 관련된 메시지는, 이벤트가 발생했음을 알리는 메시지, 이벤트의 발생 시점을 알리는 메시지, 이벤트 의 발생 횟수를 알리는 메시지 등 다양할 수 있다. 이하 도 6a 내지 도 6b, 도 7a 내지 도 7c 및 도 8을 통해, 전자 장치 및 사용자 단말 장치가 사용자 단말 장치에 저장된 메신저 애플리케이션의 실행 화면을 통해 메시지 및 클립 영상을 제공하는 예들을 설 명한다. 도 6a 내지 도 6b는, 본 개시의 일 실시 예에 따라, 발생한 이벤트에 대한 클립 영상 및 메시지를 제공하는 전 자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면들이다. 도 6a는 반려동물인 고양이의 '식사' 이벤트가 발생한 결과, 전자 장치가 '식사' 이벤트에 대응되는 클립 영상을 생성한 상황을 가정한다. 이 경우, 메신저 모듈은 '식사' 이벤트가 발생했음을 알리는 메시지(: 야옹이는 밥 먹고 있다냥~)를 생성 할 수 있다. 메신저 모듈은, 반려동물의 종류(ex. 고양이)에 따라, '야옹이는 ~다냥'과 같이 마치 반려동 물이 직접 말하는 것과 같은 어투의 메시지를 생성할 수 있다. 여기서, 메시지는 이벤트의 종류(ex. 식사, 배변 등) 및 반려동물의 종류(ex. 고양이, 강아지 등) 중 적어도 하 나에 따라 기설정된 것일 수 있다. 예를 들어, '고양이'의 '식사' 이벤트에 대하여 '야옹이는 밥 먹고 있다냥 ~'이라는 메시지가 매칭되어 메모리에 기저장되어 있을 수 있다. 또는, 메신저 모듈은 발생한 이벤트의 종류 및 반려동물의 종류를 기반으로, 메시지를 직접 생성할 수도 있다. 이 경우, 메신저 모듈은 대화 생성 기능을 갖춘 적어도 하나의 인공지능 모델을 이용할 수도 있다. 그리고, 메신저 모듈은 생성된 메시지를 클립 영상과 함께 사용자 단말 장치로 전송할 수 있다. 그 결과, 사용자 단말 장치는 도 6a와 같이 메신저 애플리케이션의 실행 화면을 통해 해당 메시지 및 클립 영상에 대한 링크를 제공할 수 있다. 이때, 사용자가 터치 등을 통해 클립 영상에 대한 링크를 선택하면, 전자 장치는 해당 링크의 웹 주 소를 통해 사용자 단말 장치로 '식사' 이벤트에 대한 클립 영상을 전송 또는 스트리밍할 수 있다. 한편, 전자 장치는 '식사' 이벤트가 발생한 경우, '식사' 이벤트에 대한 알림 또는 푸시를 사용자 단말 장 치로 전송할 수도 있다. 이 경우, 사용자 단말 장치는 사용자에게 시각적 또는 청각적으로 '식사' 이벤트에 대한 알람을 제공할 수 있다. 그리고, 알람을 접한 사용자가 메신저 애플리케이션을 통해 전자 장치의 웹 주소(: 사용자 단말 장치(30 0)에 대하여 할당된 웹 주소일 수 있음)에 접속한 결과, 전자 장치는 사용자 단말 장치로 메시지 및 클립 영상에 대한 링크를 제공할 수도 있다. 도 6b는 반려동물인 고양이의 '안전구역 이탈' 이벤트가 발생한 결과, 전자 장치가 '안전구역 이탈' 이벤 트에 대응되는 클립 영상을 생성한 상황을 가정한다. 이 경우, 메신저 모듈은 '안전구역 이탈' 이벤트가 발생했음을 알리는 메시지(: 오늘은 여기를 탐험하고 있다냥!)를 생성할 수 있다. 그리고, 메신저 모듈은 생성된 메시지를 클립 영상과 함께 사용자 단말 장치로 전송할 수 있다. 그 결과, 사용자 단말 장치는 도 6b와 같이 메신저 애플리케이션의 실행 화면을 통해 해당 메시지 및 클립 영상에 대한 링크를 제공할 수 있다. 한편, 프로세서는, 통신 인터페이스를 통해 사용자 단말 장치로부터 문의 메시지가 수신되면, 기설정된 복수의 이벤트 중 문의 메시지에 대응되는 이벤트를 판단할 수 있다. 그리고, 프로세서는 판단된 문의 메시지에 대한 응답 메시지를 사용자 단말 장치로 전송할 수 있다. 관련하여, 도 7a 내지 도 7c는, 본 개시의 일 실시 예에 따라, 사용자의 문의 메시지를 기반으로, 발생한 이벤 트에 대한 클립 영상 및/또는 메시지를 제공하는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면 들이다. 도 7a를 참조하면, 사용자 단말 장치는 메신저 애플리케이션의 실행 화면을 통해 사용자 입력 UI(User Interface. 350)를 제공할 수 있다. 사용자 입력 UI는 '밥 먹었어?'(350-1), '필요한 거 있어?'(350-2), '뭐해?'(350-3) 등과 같은 항목들을 제공할 수 있다. 여기서, 사용자 명령에 따라 적어도 하나의 항목이 선택되면, 선택된 항목에 대응되는 메시지 가 사용자 단말 장치로부터 전자 장치로 전송될 수 있다. 다만, 완성된 문장에 대응되는 적어도 하나의 항목이 사용자 입력 UI를 통해 선택되는 도 7a와 달리, 사용 자 입력 UI는 단순한 키패드 등의 형태로 구현될 수도 있다. 이 경우, 사용자는 전송될 메시지에 대응되는 텍스트를 사용자 입력 UI를 통해 직접 작성할 수 있게 된다. 도 7a에서는 사용자 입력 UI 내 항목들 중 '밥 먹었어?'(350-1)가 선택된 경우를 가정한다. 이 경우, 사용자 단말 장치는 '밥 먹었어?'라는 내용의 메시지를 전자 장치로 전송할 수 있다. 그리고, 프로세서는 '밥 먹었어?'라는 내용의 메시지에 대응되는 이벤트가 '식사' 이벤트라는 점을 식별할 수 있다. 구체적으로, '밥 먹었어?'라는 내용의 메시지가 '식사' 이벤트에 매칭되도록 기설정되어 있던 결과, 프로세서 는 해당 메시지에 대응되는 이벤트가 '식사' 이벤트인 것으로 판단할 수 있다. 또는, 프로세서는 자연어 이해 모듈을 이용하여 '밥 먹었어?'라는 메시지의 의미를 추론하고, 기설정된 복 수의 이벤트 중 추론된 의미와 가장 연관성이 높은 '식사' 이벤트를 식별할 수도 있다. 그리고, 프로세서는 '식사' 이벤트가 발생했는지 여부를 판단할 수 있다. 구체적으로, 프로세서는 메 시지가 수신된 시점으로부터 기설정된 시간 이내(ex. 5시간)에 '식사' 이벤트가 발생했는지 판단할 수 있 다. 이때, 프로세서는 적어도 하나의 이벤트에 대한 히스토리 정보를 이용하여 이벤트의 발생 여부를 판단할 수 있다. 히스토리 정보는, 이벤트 히스토리 모듈을 통해 생성된 것일 수 있다. 이벤트 히스토리 모듈은, 적어 도 하나의 이벤트의 발생/종료 시간 및 발생 횟수 중 적어도 하나에 기초하여 해당 이벤트에 대한 히스토리 정 보를 생성하고, 이를 메모리에 저장할 수 있다. 예를 들어, '식사' 이벤트에 대한 히스토리 정보는, 각 '식사'의 시작/종료 시점, '식사'에 걸리는 시간, 일별 '식사' 횟수 등에 대한 정보를 포함할 수 있다. 추가적인 예로, '식사' 이벤트에 대한 히스토리 정보는, 예를 들어, 평균적인 일별 '식사' 횟수에 대한 오늘자 '식사' 횟수의 비율에 대한 정보를 포함할 수도 있다. 예를 들어, '이동' 이벤트에 대한 히스토리 정보는, 반려동물이 '이동'하는 동안의 이동 경로에 대한 정보를 포 함할 수 있다. 히스토리 정보는 수치 정보, 텍스트, 그래프, 차트 등 다양한 형태로 구축될 수 있다. 만약 현재로부터 기설정된 시간 이내에 '식사' 이벤트가 발생했었던 경우라면, 상술한 클립 영상 생성 모듈 의 동작에 따라 생성된 '식사' 이벤트에 대한 클립 영상이 이미 메모리에 기저장되어 있을 수 있다. 이때, 프로세서는, '식사' 이벤트에 대한 히스토리 정보를 기반으로, 기설정된 시간 이내에 '식사' 이벤트 가 발생했다는 점을 식별할 수 있다. 또는, 프로세서는, '식사' 이벤트에 대한 클립 영상이 메모리에 저장되어 있으면, '식사' 이벤트가 발생한 것으로 식별할 수 있다. 이 경우, 프로세서는 저장된 클립 영상 및 '식사' 이벤트가 발생했음을 나타내는 응답 메시지를 통신 인터 페이스를 통해 사용자 단말 장치로 전송할 수 있다. 그 결과, 사용자 단말 장치는 도 7b와 같이 '식사' 이벤트의 발생을 알리는 응답 메시지 및 클립 영 상에 대한 링크를 제공할 수 있다. 반면, 현재로부터 기설정된 시간 이내에 '식사' 이벤트가 발생하지 않았던 경우라면, '식사' 이벤트에 대응되는 적어도 하나의 클립 영상이 메모리에 저장되어 있지 않을 수 있다. 이 경우, 프로세서는, '식사' 이벤트에 대한 히스토리 정보를 기반으로, 기설정된 시간 이내에 '식사' 이 벤트가 발생하지 않았다는 점을 식별할 수 있다. 또는, 프로세서는, '식사' 이벤트에 대한 클립 영상이 메 모리에 저장되어 있지 않으면, '식사' 이벤트가 발생하지 않은 것으로 식별할 수 있다. 이 경우, 프로세서는 '식사' 이벤트가 발생하지 않았음을 나타내는 응답 메시지를 통신 인터페이스 를 통해 사용자 단말 장치로 전송할 수 있다. 그 결과, 사용자 단말 장치는 도 7c와 같이 '식사' 이벤트가 발생하지 않았음을 알리는 응답 메시지 를 제공할 수 있다. 한편, 도 7a에서, 항목(350-2)이 선택됨에 따라 '필요한 거 있어?'라는 메시지가 전자 장치로 전송된 경우, 전자 장치는 적어도 하나의 이벤트에 대한 히스토리 정보를 기반으로 반려동물의 상태를 판단할 수 있다. 예를 들어, 히스토리 정보에 따라 오늘의 '식사' 횟수 또는 '식사' 시간이 평소보다 적은 것으로 판단되는 경우, 프로세서는 반려동물의 상태가 '배고픔'인 것으로 판단할 수 있다. 이때, 프로세서는 반려동물에게 사료를 줄 수 있는 펫시터 또는 가족의 연락처 등을 담은 메시지를 사용자 단말 장치로 전송할 수 있다. 예를 들어, 히스토리 정보에 따라 오늘의 '놀이' 횟수 또는 '놀이' 시간이 평소보다 적은 것으로 판단되는 경우, 프로세서는 반려동물의 상태가 '심심함'인 것으로 판단할 수 있다. 이때, 프로세서는 원격 레이저 놀이를 추천하는 메시지를 사용자 단말 장치로 전송할 수 있다. 여기 서, 프로세서는 사용자 단말 장치를 통해 입력된 사용자 명령을 사용자 단말 장치로부터 수신하 고, 수신된 사용자 명령에 따라 모니터링 장치 또는 다른 외부 장치를 제어하여 반려동물을 위한 레이저 놀이의 시작/종료 등을 제어할 수 있다. 이때, 전자 장치는 외부 장치 제어 모듈을 이용할 수 있으며, 관련된 구체적인 설명은 도 12를 통해 후술한다. 한편, 도 7a에서, 항목(350-3)이 선택됨에 따라 '뭐 해?'라는 메시지가 전자 장치로 전송된 경우, 전자 장 치는 모니터링 장치를 통해 실시간으로 촬영되어 전자 장치로 수신되는 실시간 영상(: 복수의 이미지)을 사용자 단말 장치로 제공할 수 있다. 구체적으로, 전자 장치는 실시간 영상에 대한 링크가 포함된 메시지를 사용자 단말 장치로 전송할 수 있다. 만약 현재 진행 중인 이벤트가 있다면, 전자 장치는 실시간 영상에 대한 링크와 함께 현재 진행 중 인 이벤트에 대한 정보를 포함하는 메시지(ex. 밥 먹고 있다냥~)를 사용자 단말 장치로 전송할 수도 있다. 그리고, 사용자 단말 장치 상에서 해당 링크가 선택됨에 따라, 전자 장치는 실시간 영상을 사용자 단 말 장치로 스트리밍할 수 있다. 관련된 보다 상세한 예는 도 9a 내지 도 9b를 통해 후술한다. 한편, 반려동물의 상태가 '식욕 부진', '움직임 저하' 등 기설정된 이상(abnormal) 상태인 경우, 프로세서(13 0)는 사용자 단말 장치로부터 문의 메시지가 수신되지 않더라도, 반려동물의 상태에 대응되는 메시지를 사 용자 단말 장치로 전송할 수 있다. 도 8은, 본 개시의 일 실시 예에 따라, 발생한 이벤트에 대한 정보를 기반으로 생성된 히스토리 정보를 제공하 는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면이다. 도 8은, 최근 며칠 간 반려동물의 '식사' 시간 및/또는 '식사' 횟수가 이전에 비해 매우 적어진 경우를 가정한 다. 이 경우, 프로세서는 '식사'에 대한 히스토리 정보를 기반으로, 반려동물의 상태가 '식욕 부진'인 것으로 판단할 수 있다. 이때, 프로세서는 '식욕 부진' 상태를 알리는 메시지 및 지난 1~2주 간의 '식사' 히스토리 정보에 대 한 링크를 사용자 단말 장치로 전송할 수 있다. 그리고, 사용자 단말 장치 상에서 링크가 선택되면, 사용자 단말 장치는 전자 장치로부터 수신된 '식사'에 대한 통계 정보를 사용자에게 제공할 수 있다. 한편, 비록 도 8에서는 도시되지 않았으나, 반려동물의 상태가 '식욕 부진' 또는 '움직임 저하'인 경우, 프로세 서는 동물병원의 연락처 또는 주소에 대한 정보를 담은 메시지를 사용자 단말 장치로 전송할 수도 있 다. 상술한 도 6a 내지 도 6b, 도 7a 내지 도 7c, 도 8 등을 통해 설명한 실시 예들을 통해, 본 개시의 전자 장치 및 사용자 단말 장치는, 사용자가 마치 반려동물과 직접 대화하듯 반려동물에 대한 정보를 요청/수 신할 수 있도록 하는 사용자 경험을 제공한다는 효과가 있다. 또한, 본 개시의 전자 장치 및 사용자 단말 장치는, 사용자가 직접 요청보지 않아도, 모니터링 장치 로부터 실시간으로 수신되는 영상을 기반으로, 반려동물의 히스토리 정보 및/또는 상태에 대한 정보를 사 용자에게 선제적으로 제공할 수도 있다는 장점이 있다. 이하 도 9a 내지 도 9b 및 도 10을 통해서는, 반려동물의 모니터링과 관련하여 다양한 서비스를 제공하기 위한 통합 애플리케이션이 사용자 단말 장치에 저장된 상황을 전제로, 전자 장치 및 사용자 단말 장치 의 다양한 동작을 설명한다. 도 9a는, 본 개시의 일 실시 예에 따라, 실시간 영상 및/또는 이벤트 별 클립 영상을 제공하는 전자 장치 및 사 용자 단말 장치의 동작을 설명하기 위한 도면이다. 도 9a를 참조하면, 전자 장치가 사용자 단말 장치에 제공하는 통합 애플리케이션 'PET MONITORING'(: 가명)의 실행화면 상에는, 실시간 영상을 제공하기 위한 UI, 복수의 이벤트에 대한 클립 영상을 제공하기 위한 UI, 복수의 메뉴 항목을 제공하기 위한 UI가 각각 디스플레이될 수 있다. 터치 등으로 입력되는 사용자 명령에 따라 UI 내의 재생 항목(912')이 선택되면, 사용자 단말 장치는, 모니터링 장치를 통해 촬영되어 전자 장치를 통해 스트리밍되는 반려동물에 대한 실시 간 영상을 UI를 통해 재생할 수 있다. 도 9a의 UI는 'Video Event Card'의 형태로, 최근에 일어난 복수의 이벤트들 각각에 대한 정보(먹었어요, 마셨어요, 볼 일 봤어요, 위험 구역에 갔어요) 및 복수의 이벤트 각각에 대한 클립 영상에 대한 링크를 제공할 수 있다."}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다만, 도 9a와 달리, UI는 적어도 하나의 이벤트의 지속 시간에 대한 정보를 제공하는 'Track Card' 형태, 이벤트들에 대한 정보를 요약하여 제공하는 'Summary Card' 형태, 또는 반려동물에 대한 유용한 정보를 제공하 는 'Tip Card' 형태 등 다양한 형태로 사용자에게 정보를 제공할 수 있다. UI는 설정 항목(916-1), 메신저 항목(916-2), 히스토리 항목(916-3) 등을 포함할 수 있다. 사용자 명령에 따라 설정 항목(916-1)이 선택되면, 사용자 단말 장치는 반려동물의 모니터링 및 클립 영상 의 제공에 대한 다양한 조건을 설정할 수 있게 하는 세부 설정 UI를 제공할 수 있다. 예를 들어, 세부 설정 UI는, 사용자로 하여금, 이벤트 별로 생성될 클립 영상의 시간 길이, 생성된 클립 영상의 보관 기간, 각 장치(전자 장치, 모니터링 장치, 사용자 단말 장치) 마다 최대로 저장할 수 있는 클립 영상의 용량/수, 연결된 모니터링 장치의 식별/등록 번호, 모니터링 장치의 촬영 시간, 적어도 하나의 이벤트와 관련된 관심 영역의 위치, 사용자 단말 장치를 통해 알람을 제공받을 이벤트의 종류, 이 벤트 별 히스토리 정보의 보관 기간 등 다양한 요소를 설정하도록 하는 UI일 수 있다. 메신저 항목(916-2)이 선택되는 경우, 전자 장치 및 사용자 단말 장치는, 앞서 도 6a 내지 도 6b, 도 7a 내지 도 7c, 도 8 등을 통해 설명한 메신저 애플리케이션의 실행화면을 제공할 수 있다. 여기서, 메신저 애 플리케이션은, 통합 애플리케이션이 제공하는 다양한 서비스들 중 하나의 서비스일 수 있다. 히스토리 항목(916-3)이 선택되는 경우, 전자 장치는 적어도 하나의 이벤트에 대한 히스토리 정보를 사용 자 단말 장치로 전송할 수 있다. 그 결과, 사용자 단말 장치는 텍스트, 그래프 등 다양한 형태로 히 스토리 정보를 사용자에게 제공할 수 있다. 관련하여, 도 10을 통해 구체적인 예를 후술한다. 도 9b는, 본 개시의 일 실시 예에 따라, 적어도 하나의 펫 관련 외부 장치를 제어하기 위한 사용자 인터페이스 를 제공하는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면이다. 도 9b는, 도 9a에서 재생 항목(912')이 선택됨에 따라 실시간 영상이 UI를 통해 재생되고 있는 상황을 가 정한다. 도 9b를 참조하면, 실시간 영상이 재생되는 동안, 도 9a에서 제공되던 UI는 외부 장치들을 제어하기 위한 UI로 갈음될 수 있다. UI는, 'Beammice' 기능 및 '레이저' 출력 기능을 각각 ON/OFF하기 위한 UI 항목을 제공할 수 있다. 본 기 능들에 대해서는 도 12를 통해 후술한다. UI는, 모니터링 장치 또는 다른 스피커 장치 등의 음성 출력을 제어하기 위한 UI 항목(: sound)도 제 공할 수 있다. 예를 들어, 'sound' 항목의 'ON'을 선택하는 사용자 명령이 입력되어 전자 장치로 전송된 경우, 프로세서 는 모니터링 장치 상에 기녹음된 사용자(: 반려동물의 보호자)의 음성을 출력하도록 모니터링 장치 를 원격 제어할 수 있다. 이때, 프로세서는 외부 장치 제어 모듈 및 통신 인터페이스를 이 용할 수 있다. UI는 모니터링 장치 또는 다른 마이크 장치 등이 반려동물이 위치한 장소에서 발생하는 사운드를 녹 음하도록 제어하기 위한 UI 항목(: record)도 제공할 수 있다. 예를 들어, 'record' 항목의 'ON'을 선택하는 사용자 명령이 입력되어 전자 장치로 전송된 경우, 프로세서 는 모니터링 장치가 자체 구비한 마이크를 통해 사운드를 녹음하도록 모니터링 장치를 원격 제 어할 수 있다. 이때, 녹음된 사운드에 대한 데이터는 모니터링 장치 또는 전자 장치에 저장될 수 있으며, 사용자 단 말 장치를 통해 입력된 사용자 명령에 따라 사용자 단말 장치로 전송/스트리밍될 수 있다. UI는 실시간 영상이 재생되는 동안 반려동물이 위치한 장소에서 발생하는 사운드도 함께 듣기 위한 UI 항 목(: Microphone)도 제공할 수 있다. 예를 들어, 'microphone' 항목의 'ON'을 선택하는 사용자 명령이 입력되어 전자 장치로 전송된 경우, 프로 세서는 모니터링 장치가 자체 구비한 마이크를 통해 사운드를 실시간으로 입력받고, 입력된 사운드에 대한 데이터를 전자 장치로 전송하도록 모니터링 장치를 원격 제어할 수 있다. 그리고, 프로세서는 모니터링 장치로부터 실시간으로 수신되는 사운드에 대한 데이터를 사용자 단말 장치로 스트리밍할 수 있다. 그 결과, 사용자 단말 장치는 UI를 통해 실시간 영상을 제공함과동시에, 자체 구비된 스피커를 통해 실시간 사운드를 제공할 수 있다. 이렇듯 상술한 도 9b의 실시 예에 따른 전자 장치는, 모니터링 장치 및 사용자 단말 장치를 이 용하여, 사용자가 단순히 반려동물을 실시간으로 관찰하는 것에 그치지 않고 반려동물을 실시간으로 관리/감독 하거나 반려동물과 놀아줄 수도 있도록 하는 다양한 서비스를 제공할 수 있다. 도 10은, 본 개시의 일 실시 예에 따라, 히스토리 정보를 제공하는 전자 장치 및 사용자 단말 장치의 동작을 설 명하기 위한 도면이다. 도 10에서 사용자 단말 장치가 제공하는 실행 화면은, 도 9a 또는 도 9b에 도시된 통합 애플리케이션의 실 행 화면에서 히스토리 항목(916-3)이 선택됨에 따라 사용자 단말 장치가 제공하는 통합 애플리케이션의 다 른 실행화면일 수 있다. 도 10을 참조하면, 전자 장치는 사용자 단말 장치를 통해, 현재 진행 중인 이벤트에 대한 히스토리 정보를 제공하는 UI, 오늘 발생한 이벤트 전체의 타임라인을 제공하는 UI, 오늘의 이동 거리에 대 한 정보를 제공하는 UI등을 제공할 수 있다. 일 예로, UI는 '기록'(1012-1) 항목 및 '전체 보기'(1012-2) 항목을 제공할 수 있다. 도 10과 같이 '기 록'(1012-1) 항목이 선택된 상태에서, UI는 현재 진행 중인 이벤트의 지속 시간(ex. 수면 42분)이 표시될 수 있다. 반면, '전체 보기'(1012-2) 항목이 선택된 상태에서, UI는 최근의 기설정된 시간(ex. 일주일) 동안의 '수 면' 시간에 대한 정보를 통계 수치, 그래프 또는 차트 등의 형태로 제공할 수 있다. UI에서, '이전 활동 더 보기'(1014') 항목이 선택되면, 현재 표시된 이벤트들(식사, 공놀이, 수면)에 대 한 타임라인에 더하여, 이전에 발생한 적어도 하나의 이벤트에 대한 타임라인이 더 제공될 수 있다. UI가 제공하는 칼로리 소모량 및 UI가 제공하는 이동거리는, 프로세서를 통해 획득된 것일 수 있다. 구체적으로, 프로세서는 모니터링 장치로부터 수신된 복수의 이미지 각각을 통해 반려동물을 인식할 수 있으며, 인식된 반려동물의 이동 거리를 측정할 수 있다. 또는, 프로세서는 통신 인터페이스를 통해 반려동물에 부착된 가속도 센서 또는 GPS 장치 등과 통신 을 수행함으로써, 반려동물의 이동 거리를 측정할 수도 있다. 또한, 프로세서는 반려동물의 이동 거리 내지는 움직임을 기반으로 반려동물의 칼로리 소모량을 추론할 수 도 있다. 이를 위해, 프로세서는 반려동물의 이동거리에 따라 칼로리 소모량이 매핑된 기저장된 테이블을 이용하거나, 또는 인식된 반려동물의 움직임에 따라 칼로리 소모량을 추론하도록 훈련된 적어도 하나의 인공지 능 모델을 이용할 수 있다. 한편, 도 10에서 제시된 UI들은 일부 예일 뿐, 전자 장치는 이밖에도 다양한 방식 또는 다양한 내용을 담 은 히스토리 정보를 사용자 단말 장치를 통해 제공할 수 있다. 한편, 앞서 도 3a 내지 도 3b 및 도 4를 통해 설명하였듯, 이벤트 검출 모듈은 기설정된 다양한 관심 영역 들을 이용하여 반려동물과 관련된 적어도 하나의 이벤트가 발생했는지 판단할 수 있다. 관련하여, 도 11은, 입력된 사용자 명령을 기반으로 적어도 하나의 관심 영역을 설정하는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면이다. 전자 장치는 모니터링 장치가 촬영한 이미지 내에서 적어도 하나의 관심 영역을 설정하도록 하는 UI 를 사용자 단말 장치에 제공할 수 있다. 그 결과, 도 11을 참조하면, 사용자 단말 장치는 이미지로부터 '식사' 이벤트와 관련된 '고양이 밥 그릇'을 선택하도록 하는 UI를 제공할 수 있다. 이때, 이미지 상에서 고양이 밥그릇을 포함하는 일 영역을 선택하는 사용자 명령이 입력되면, 사용자 명 령에 대한 정보가 사용자 단말 장치에서 전자 장치로 전송될 수 있다. 그리고, 전자 장치는 사용자 명령을 기반으로 이미지를 통해 나타난 장소 중 '식사' 이벤트에 대응 되는 관심 영역을 설정할 수 있다. 구체적으로, 전자 장치는 '식사' 이벤트에 대응되는 관심 영역이 사용자 명령에 따라 선택된 영역을 포함하도록 설정할 수 있다. 한편, 도 12는, 본 개시의 일 실시 예에 따라 반려동물을 위한 레이저 놀이를 제공하는 모니터링 장치의 동작을 설명하기 위한 도면이다. 사용자 단말 장치를 통해 입력된 사용자 명령을 기반으로, 전자 장치는 모니터링 장치가 레이저 놀이를 시작하도록 제어할 수 있다. 여기서, 레이저 놀이는, 도 9b에 도시된 사용자 단말 장치의 실행 화면 상에서 Beammice 기능 및 Laser 기 능이 'ON'된 경우를 전제로 시작될 수 있다. 다만, 레이저 놀이를 활성화하는 조건은 이밖에도 다양할 수 있으 며, 레이저 놀이를 활성화시키기 위한 사용자 명령의 입력 방식 역시 도 9b의 경우에만 한정되는 것은 아니다. 도 12를 참조하면, 레이저 놀이가 활성화됨에 따라, 모니터링 장치는 특정 지점에 레이저를 출력할 수 있다. 이를 위해, 모니터링 장치는 광 출력 인터페이스를 포함할 수 있다. 그리고, 모니터링 장치는 레이저가 도달하는 지점이 특정 지점으로부터 계속해서 변경되도록 레이저 를 출력하는 방향을 변경할 수 있다. 이 경우, 고양이와 같은 반려동물은 계속해서 레이저의 도달 지점을 따라 가는 등 흥미를 느낄 수 있다. 여기서, 모니터링 장치는 촬영되는 복수의 이미지(RGB 이미지/뎁스 이미지)를 기반으로 반려동물(고양이) 의 위치를 판단하고, 판단된 위치에 따라 레이저의 출력 방향을 변경할 수도 있다. 예를 들어, 모니터링 장치 는 현재 고양이가 위치한 지점으로부터 기설정된 거리(ex. 1m) 내에 레이저가 도달하도록 레이저의 출력 방향을 제어할 수 있다. 그리고, 도 12를 참조하면, 모니터링 장치는 레이터의 최종 도달 지점이 보상 장치 상에 위치하도록 레이터의 출력을 제어할 수 있다. 보상 장치는, 모니터링 장치가 출력한 레이저가 보상 장치에 도달한 상태에서 고양이가 특정 부 분(250-1)을 터치한 경우, 사료 내지는 간식 등의 보상을 제공하도록 설계된 장치이다. 보상 장치는 보상 장치에 구비된 조도 센서를 통해 보상 장치에 레이저가 도달했는지 여부를 판 단할 수 있다. 또는, 보상 장치는, 모니터링 장치가 출력한 레이저가 보상 장치에 도달했다는 것을 알리는 정 보가 모니터링 장치 또는 모니터링 장치를 제어하는 전자 장치로부터 수신되는 경우, 레이저가 도달한 것으로 판단할 수도 있다. 이를 위해, 보상 장치는 와이파이, LTE, 5G 이동통신, 블루투스 통신 등 다양한 방식으로 전자 장치 및/또는 모니터링 장치와 연결될 수 있다. 보상 장치는, 특정 부분(250-1)에 형성된 버튼, 터치 센서 또는 조도 센서를 통해, 고양이의 터치를 감지 할 수 있다. 구체적으로, 보상 장치는 버튼의 눌림, 터치 센서에 대한 터치, 조도 센서에 수신되는 광량의 감소 중 적어도 하나를 감지하여 고양이의 터치를 감지할 수 있다. 모니터링 장치는 복수의 이미지를 기반으로 반려동물을 추적한 결과, 정지/약이동/강이동 등 반려동물의 상태를 판단할 수 있다. 그리고, 모니터링 장치는, 레이저 놀이 중, 판단된 상태에 따라 레이저의 출력 방 향이 변경되는 속도를 달리 제어할 수 있다. 사용자 단말 장치 등을 통해 입력된 사용자 명령에 따라, 레이저 놀이의 난이도가 설정될 수도 있다. 설정 된 난이도에 따라, 모니터링 장치는 레이저의 출력 방향이 변경되는 속도 등을 제어할 수도 있다. 레이저 놀이 중, 모니터링 장치를 통해 실시간으로 촬영된 영상(복수의 이미지: RGB 이미지)이 전자 장치 를 거쳐 사용자 단말 장치로 스트리밍 될 수 있다. 실시간 스트리밍 중, 사용자 단말 장치를 통해 레이저의 도달 지점을 실시간으로 선택하는 사용자 명령이 입력될 수도 있다. 이 경우, 해당 사용자 명령이 사용자 단말 장치로부터 전자 장치로 전송된 결과, 전자 장치는 사용자 명령에 따라 실시간으로 선택된 도달 지점에 레이저를 출력하도록 모니터링 장치(20 0)를 제어할 수 있다. 또한, 모니터링 장치 또는 전자 장치는, '레이저 놀이'에 대응되는 클립 영상을 생성하여 모니터링 장치 또는 전자 장치에 저장할 수도 있다.도 13은, 본 개시의 일 실시 예에 따른 모니터링 장치의 구성을 설명하기 위한 블록도이다. 도 13을 참조하면, 모니터링 장치는 이미지 센서, 메모리 및 프로세서를 포함한다. 이미지 센서는 반려동물이 위치한 장소를 촬영하여 복수의 이미지를 획득하기 위한 구성이다. 이미지 센서 는 비젼 센서, 뎁스 센서, TOF 센서 중 적어도 하나를 포함할 수 있다. 구체적으로, 이미지 센서는 비젼 센서를 통해 복수의 RGB 이미지를 획득할 수 있다. 또한, 이미지 센서 는 뎁스 센서를 이용하여 복수의 뎁스 이미지를 획득할 수도 있다. 모니터링 장치는 이미지 센서를 통해 촬영된 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 적어도 하나의 이벤트가 발생했는지 판단할 수 있다. 이때, 모니터링 장치의 프로세서는 이벤트 검출 모듈을 이용할 수 있으며, 이벤트 검출 모듈 은 앞서 설명한 전자 장치의 이벤트 검출 모듈의 다양한 실시 예에 대응되는 동작을 수행할 수 있다. 이벤트가 발생한 것으로 판단된 경우, 프로세서는 복수의 이미지 중 이벤트가 발생한 것으로 판단된 시점 을 기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단할 수 있다. 그리고, 프로세서 는 판단된 이미지에 기초하여 이벤트에 대응되는 클립 영상을 생성하여 메모리에 저장할 수도 있다. 이때, 프로세서는 클립 영상 생성 모듈을 이용할 수 있으며, 클립 영상 생성 모듈은 앞서 설명 한 전자 장치의 클립 영상 생성 모듈의 다양한 실시 예에 대응되는 동작을 수행할 수 있다. 통신 인터페이스는 모니터링 장치가 전자 장치 및 사용자 단말 장치와 직접적/간접적으로 통신을 수행하기 위한 구성이다. 프로세서는, 통신 인터페이스를 통해, 생성된 클립 영상을 전자 장치 및/또는 사용자 단말 장치 로 전송할 수 있다. 또한, 프로세서는, 통신 인터페이스를 통해, 실시간으로 촬영된 복수의 이미지를 전자 장치 및/ 또는 사용자 단말 장치로 전송할 수 있다. 마이크는 사운드를 입력받기 위해 회로를 포함할 수 있다. 프로세서는, 마이크를 통해 입력된 사운드를 전자 장치 및/또는 사용자 단말 장치로 전송 할 수 있다. 구체적으로, 프로세서는 이미지 센서를 통해 실시간으로 촬영된 복수의 이미지와 함께 마이크에 실시간으로 입력된 사운드에 대한 데이터 역시 전자 장치 및/또는 사용자 단말 장치로 전송할 수 있 다. 또한, 프로세서는 클립 영상을 전자 장치 및/또는 사용자 단말 장치로 전송하는 경우, 클립 영 상에 포함된 이미지들이 촬영된 시간 구간 동안 마이크에 입력된 사운드에 대한 데이터도 함께 전송할 수 있다. 오디오 출력 인터페이스는 오디오 신호를 출력하기 위한 구성이다. 일 예로, 오디오 출력 인터페이스(26 0)는 스피커로 구현될 수 있다. 일 실시 예로, 프로세서는 메모리에 기저장된 사용자 음성에 대한 데이터를 기반으로 사용자 음성을 출력하도록 오디오 출력 인터페이스를 제어할 수 있다. 일 실시 예로, 사용자 단말 장치에 사용자 음성이 입력되는 경우, 입력된 사용자 음성에 대한 데이터가 사 용자 단말 장치로부터 전자 장치를 거쳐 모니터링 장치로 수신될 수 있다. 이 경우, 프로세서 는 수신된 데이터를 기반으로 사용자 음성을 출력하도록 오디오 출력 인터페이스를 제어할 수도 있다. 광 출력 인터페이스는 상술한 도 12의 레이저 놀이를 위해 레이저를 출력한다. 구체적으로, 광 출력 인터 페이스는 적외선 영역 및/또는 가시광선 영역의 광을 출력할 수 있다. 이를 위해, 광 출력 인터페이스는 다이오드와 같은 발광 소자를 포함할 수 있다. 또한, 광 출력 인터페이 스는 출력된 광의 진행 방향을 조정하기 위한 렌즈 및/또는 출력된 광의 출력량이나 파장을 조정하기 위한필터를 포함할 수도 있으나 이밖에도 다양한 방식으로 구현될 수 있다. 광 출력 인터페이스의 레이저 출력 방향 및 이미지 센서의 촬영 방향을 제어하기 위해, 모니터링 장 치는 반려동물이 위치한 장소에 구비된 벽 상에서 회전 가능한 헤드 형태로 벽에 부착될 수 있다. 이때, 모니터링 장치는 프로세서의 제어에 따라 Pan - Tilt 동작을 수행할 수 있으며, 그 결과 이미 지 센서 및 광 출력 인터페이스의 방향이 변경될 수 있다. 또는, 모니터링 장치가 바라보는 방향은 고정된 상태에서, 광 출력 인터페이스가 프로세서의 제 어에 따라 모니터링 장치 상에서 회전 가능하도록 구현될 수도 있다. 한편, 모니터링 장치에 이벤트 검출 모듈 및 클립 영상 생성 모듈이 포함되는 경우, 전자 장치 에는 이벤트 검출 모듈 및 클립 영상 생성 모듈이 구비되지 않을 수 있다. 반대로, 전자 장치에 이벤트 검출 모듈 및 클립 영상 생성 모듈이 구비되는 경우, 모니터링 장 치에는 이벤트 검출 모듈 및 클립 영상 생성 모듈이 구비되지 않을 수 있다. 다만, 이밖에도 다양한 실시 예가 가능하다. 일 예로, 모니터링 장치에 포함된 이벤트 검출 모듈 및 전자 장치에 포함된 이벤트 검출 모듈 이 모두 존재할 수 있다. 여기서, 모니터링 장치의 이벤트 검출 모듈은 반려동물의 위치를 기반으로 적어도 하나의 이미지를 식별할 수 있다(ex. 도 3a에서 이미지 식별). 그리고, 모니터링 장치는 이미지를 포함한 기설정 된 시간 내의 이미지들(ex. 도 3b의 302, 303, 304, ...)을 전자 장치로 전송할 수 있다. 이 경우, 전자 장치의 이벤트 검출 모듈은 해당 이미지들(302, 303, 304, ...)을 분석한 결과, '식사' 이벤트가 발생했음을 판단할 수 있다. 한편, 도 14는, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도이다. 이때, 전자 장치는 서버 장치로 구현될 수 있다. 본 제어 방법은, 모니터링 장치로부터 복수의 이미지를 수신할 수 있다(S1410). 이때, 복수의 이미지는 모니터 링 장치를 통해 반려동물이 위치한 장소를 촬영한 복수의 이미지일 수 있다. 그리고, 본 제어 방법은, 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판 단할 수 있다(S1420). 일 예로, 본 제어 방법은, 복수의 이미지를 분석하여 반려동물과 관련된 이벤트가 발생했는지 판단할 수 있다. 이 경우, 본 제어 방법은 복수의 이미지가 입력되면 발생한 이벤트에 대한 정보를 출력하도록 훈련된 인공지능 모델을 이용할 수 있다. 일 예로, 본 제어 방법은, 복수의 이미지 중 적어도 하나의 이미지에서 반려동물의 위치를 판단할 수 있다. 여 기서, 판단된 반려동물의 위치가 기설정된 제1 관심 영역 내인 경우, 적어도 하나의 이미지를 분석하여 반려동 물과 관련된 이벤트가 발생했는지를 판단할 수 있다. 이때, 적어도 하나의 이미지를 상술한 인공지능 모델에 입력할 수 있다. 일 예로, 복수의 이미지 중 적어도 하나의 이미지에서 반려동물의 위치를 판단하고, 판단된 반려동물의 위치가 기설정된 제2 관심 영역 내인 경우, 기설정된 제2 관심 영역에 대응되는 반려동물과 관련된 이벤트가 발생한 것으로 판단할 수도 있다. 본 제어 방법은, 이벤트가 발생한 것으로 판단된 경우, 복수의 이미지 중 이벤트가 발생한 것으로 판단된 시점 을 기준으로 기설정된 시간 범위 내에서 촬영된 적어도 하나의 이미지를 판단할 수 있다(S1430). 그리고, 판단된 이미지에 기초하여 이벤트에 대응되는 클립 영상을 생성할 수 있다(S1440). 본 제어 방법은, 클립 영상 및 이벤트에 대응되는 메시지를 사용자 단말 장치로 전송할 수 있다. 한편, 사용자 단말 장치로부터 문의 메시지가 수신되면, 기설정된 복수의 이벤트 중 문의 메시지에 대응되는 이 벤트를 판단할 수도 있다. 이 경우, 판단된 이벤트에 대응되는 적어도 하나의 클립 영상이 메모리에 저장되어 있는 경우, 저장된 클립 영 상 및 판단된 이벤트가 발생했음을 나타내는 응답 메시지를 사용자 단말 장치로 전송할 수도 있다. 반면, 판단된 이벤트에 대응되는 적어도 하나의 클립 영상이 메모리에 저장되어 있지 않은 경우, 판단된 이벤트 가 발생하지 않았음을 나타내는 응답 메시지를 통신 인터페이스를 통해 사용자 단말 장치로 전송할 수 있다. 한편, 본 제어 방법은, 기설정된 복수의 이벤트 중 적어도 하나의 이벤트의 발생 시간 및 발생 횟수 중 적어도 하나에 기초하여 적어도 하나의 이벤트에 대한 히스토리 정보를 생성할 수도 있다. 이 경우, 생성된 히스토리 정보를 사용자 단말 장치로 전송할 수 있다. 또한, 본 제어 방법은, 생성된 히스토리 정보에 기초하여 반려동물의 상태를 판단할 수 있다. 이 경우, 판단된 반려동물의 상태에 대응되는 메시지를 사용자 단말 장치로 전송할 수 있다. 상술한 도 14의 제어 방법 중 적어도 일부는, 도 2의 전자 장치를 통해 수행될 수 있다. 도 15는, 본 개시의 일 실시 예에 따른 모니터링 장치의 제어 방법을 설명하기 위한 순서도이다. 본 제어 방법은, 이미지 센서를 통해 복수의 이미지를 획득할 수 있다(S1510). 이때, 복수의 이미지는 반려동물 이 위치한 장소가 촬영된 것일 수 있다. 그리고, 본 제어 방법은, 복수의 이미지 중 적어도 하나에 기초하여 반려동물과 관련된 이벤트가 발생했는지 판 단할 수 있다(S1520). 이벤트가 발생한 것으로 판단된 경우, 복수의 이미지 중 이벤트가 발생한 것으로 판단된 시점을 기준으로 기설 정된 시간 범위 내에 촬영된 적어도 하나의 이미지를 판단할 수 있다(S1530). 그리고, 판단된 이미지에 기초하 여 이벤트에 대응되는 클립 영상을 생성할 수 있다(S1540). 이때, 생성된 클립 영상을 서버로 구현된 전자 장치 및/또는 사용자 단말 장치로 전송할 수 있다. 상술한 도 14의 제어 방법 중 적어도 일부는, 도 13의 모니터링 장치를 통해 수행될 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(Programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processor), 제어기 (controller), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessor), 기타 기능 수행을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구 현에 의하면 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 전자 장치에서의 처리동작을 수행하기 위한 컴퓨터 명령 어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의 해 실행되었을 때 상술한 다양한 실시 예에 따른 전자 장치의 처리 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2020-0065298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해돼서는 안 될 것이다. 부호의 설명100: 전자 장치 200: 모니터링 장치 300: 사용자 단말 장치"}
{"patent_id": "10-2020-0065298", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은, 본 개시에 따라 전자 장치, 모니터링 장치 및 사용자 단말 장치를 포함하는 시스템의 동작을 개략적으 로 설명하기 위한 도면, 도 2는, 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도, 도 3a 내지 도 3b는, 본 개시의 일 실시 예에 따라, 반려동물의 위치를 판단하고, 판단된 위치를 기반으로 이미 지를 분석하여 발생한 이벤트를 판단하는 전자 장치의 동작을 설명하기 위한 도면들, 도 4는, 본 개시의 일 실시 예에 따라, 반려동물의 위치를 판단하고, 판단된 위치를 기반으로 발생한 이벤트를 판단하는 전자 장치의 동작을 설명하기 위한 도면, 도 5는, 본 개시의 일 실시 예에 따라, 이벤트가 발생한 시점을 기반으로 클립 영상을 생성하는 전자 장치의 동 작을 설명하기 위한 도면, 도 6a 내지 도 6b는, 본 개시의 일 실시 예에 따라, 발생한 이벤트에 대한 클립 영상 및 메시지를 제공하는 전 자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면들, 도 7a 내지 도 7c는, 본 개시의 일 실시 예에 따라, 사용자의 문의 메시지를 기반으로, 발생한 이벤트에 대한 클립 영상 및/또는 메시지를 제공하는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면들, 도 8은, 본 개시의 일 실시 예에 따라, 발생한 이벤트에 대한 정보를 기반으로 생성된 히스토리 정보를 제공하 는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면, 도 9a는, 본 개시의 일 실시 예에 따라, 실시간 영상 및/또는 이벤트 별 클립 영상을 제공하는 전자 장치 및 사 용자 단말 장치의 동작을 설명하기 위한 도면, 도 9b는, 본 개시의 일 실시 예에 따라, 적어도 하나의 펫 관련 외부 장치를 제어하기 위한 사용자 인터페이스 를 제공하는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면, 도 10은, 본 개시의 일 실시 예에 따라, 히스토리 정보를 제공하는 전자 장치 및 사용자 단말 장치의 동작을 설 명하기 위한 도면,도 11은, 본 개시의 일 실시 예에 따라, 입력된 사용자 명령을 기반으로 적어도 하나의 관심 영역을 설정하는 전자 장치 및 사용자 단말 장치의 동작을 설명하기 위한 도면, 도 12는, 본 개시의 일 실시 예에 따라 반려동물을 위한 레이저 놀이를 제공하는 모니터링 장치의 동작을 설명 하기 위한 도면, 도 13은, 본 개시의 일 실시 예에 따른 모니터링 장치의 구성을 설명하기 위한 블록도, 도 14는, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도, 그리고 도 15는, 본 개시의 일 실시 예에 따른 모니터링 장치의 제어 방법을 설명하기 위한 순서도이다."}
