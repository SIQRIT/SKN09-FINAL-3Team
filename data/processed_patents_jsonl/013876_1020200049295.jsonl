{"patent_id": "10-2020-0049295", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0131020", "출원번호": "10-2020-0049295", "발명의 명칭": "비지도 학습 기법을 이용한 영상데이터의 정합 방법 및 장치", "출원인": "재단법인대구경북과학기술원", "발명자": "박상현"}}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 영상데이터 및 제2 영상데이터를 획득하는 단계; 상기 제1 영상데이터와 상기 제2 영상데이터를 기반으로 복수의 레벨에 대응되는 변위맵을 추정하는 단계; 상기 변위맵을 기반으로 상기 제1 영상데이터를 변환하여 복수의 제1 변환 영상데이터를 생성하는 단계;상기 제1 영상데이터로부터 추출된 제1 특징맵으로 복수의 제1 변환특징맵을 생성하는 단계; 쌍(pair)을 이루는 상기 복수의 제1 변환특징맵과 상기 제2 영상데이터로부터 추출된 제2 특징맵을 이용하여 학습을 수행하는 단계; 및상기 학습의 수행결과를 기반으로 복수의 영상데이터를 정합하는 단계;를 포함하는 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 영상데이터는 복수의 위상을 갖는 동영상데이터, 상기 제2 영상데이터는 정지영상데이터인 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 변위맵을 추정하는 단계는, 상기 복수의 레벨을 갖는 인코더와 디코더를 포함하는 네트워크를 이용하여 상기 복수의 위상 각각에 대응되는변위맵을 추정하는 단계인 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제1 변환 영상데이터를 생성하는 단계는, 상기 제1 영상데이터에 상기 변위맵을 각각 적용하여 복수의 제1 변환 영상데이터를 생성하는 단계인 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 제1 변환특징맵을 생성하는 단계는, 상기 제1 영상데이터를 이용하여 제1 특징맵을 추출하는 단계; 및상기 제1 특징맵에 상기 변위맵을 각각 적용하여 복수의 제1 변환특징맵을 생성하는 단계; 를 포함하는 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 학습을 수행하는 단계는, 공개특허 10-2021-0131020-3-쌍(pair)을 이루는 상기 복수의 제1 변환 영상데이터와 상기 제2 영상데이터의 차이값이 최소가 될 때까지 학습하는 단계; 및상기 복수의 제1 변환특징맵과 상기 제2 특징맵의 차이값이 최소가 될 때까지 학습하는 단계;를 포함하는 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 학습을 수행하는 단계는, 상기 복수의 레벨에 대응되는 변위맵에 대한 손실 함수, 상기 복수의 제1 변환 영상데이터와 상기 제2 영상데이터 사이의 손실 함수 및 상기 복수의 제1 변환특징맵과 상기 제2 특징맵 사이의 손실 함수를 고려하여 최종 손실 함수를 정의하는 단계;를 포함하는 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 제1 특징맵 및 상기 제2 특징맵은 상기 제1 영상데이터와 상기 제2 영상데이터 각각에서 확인되는 혈관,분기점 및 특징점 중 적어도 하나를 포함하는 것을 특징으로 하는 영상데이터 정합 방법."}
{"patent_id": "10-2020-0049295", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 영상획득장치에서 획득된 제1 영상데이터 및 제2 영상데이터를 기반으로 복수의 레벨에 따른 변위맵을 추정하는 변위맵추정기;상기 제1 영상데이터로부터 제1 특징맵을 추출하고, 상기 제2 영상데이터로부터 제2 특징맵을 추출하는 특징추출기;상기 변위맵을 기반으로 상기 제1 영상데이터를 변환하여 복수의 제1 변환 영상데이터를 생성하고, 상기 제1 특징맵을 변환하여 복수의 제1 변환특징맵을 생성하는 공간변환기; 및쌍(pair)을 이루는 상기 복수의 제1 변환특징맵과 상기 제2 특징맵을 이용하여 학습을 수행하고, 상기 학습의수행결과를 기반으로 복수의 영상데이터를 정합하는 손실확인기;를 포함하는 것을 특징으로 하는 영상데이터 정합 장치."}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 비지도 학습 기법을 이용한 영상데이터의 정합 방법 및 장치에 관한 것으로, 제1 영상데이터 및 제2 영상데이터를 획득하는 단계, 제1 영상데이터와 제2 영상데이터를 기반으로 복수의 레벨에 대응되는 변위맵을 추 정하는 단계, 변위맵을 기반으로 제1 영상데이터를 변환하여 복수의 제1 변환 영상데이터를 생성하는 단계, 제1 영상데이터로부터 추출된 제1 특징맵으로 복수의 제1 변환특징맵을 생성하는 단계, 쌍(pair)을 이루는 복수의 제 1 변환특징맵과 제2 영상데이터로부터 추출된 제2 특징맵을 이용하여 학습을 수행하는 단계 및 학습의 수행결과 를 기반으로 복수의 영상데이터를 정합하는 단계를 포함하며 다른 실시 예로도 적용이 가능하다."}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비지도 학습 기법을 이용하여 복수의 영상데이터를 정합하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 딥러닝(deep learning) 알고리즘을 적용하여 빅데이터를 처리하는 다양한 기법들이 개발되고 있으며, 이를 적용한 성공사례도 점점 증가하고 있다. 특히, X-ray, 초음파, CT(computed tomography), MRI(magnetic resonance imaging), PET(positron emission tomography), 광각안저카메라(ultra-widefield fundus imaging) 등의 진단기기들로부터 획득된 의료영상데이터를 인공지능 알고리즘에 적용하여 의사의 의사결정에 도움을 주는 방법이 개발되고 있다. 이 중에서도 최근에는 안구의 상태를 진단하기 위해 광각안저카메라에서 획득된 멀티 위 상(multi-phase) 초광각(ultra-widefield) 망막 영상을 이용한다. 이와 같은 멀티 위상 초광각 망막 영상의 분석을 위해서는 위상에 따라 변화되는 영상의 특성을 파악하는 것이 중요한데 이를 위해서는 각각의 영상에서 발생되는 왜곡 및 위치가 보정되어야 한다. 이를 위해, 딥러닝 기법을 이용하여 영상간 왜곡과 위치 변화를 보정하는 정합 기법에 대한 연구가 진행되고 있다. 그러나 이러한 연구는 영상의 종류가 유사한 경우를 가정하여 진행되고 있으므로, 동영상데이터와 정지영상데이터와 같이 서로 다른종류의 영상을 정합하고자 할 때에는 영상간 왜곡 및 위치 변화가 효율적이지 못한 문제가 발생한다. 또한, 이를 위해 혈관 및 분기점 검출기, SIFT 및 에지기반 해리스 코너 검출기를 이용하여 연관성을 찾고, 가 장 가까운 포인트 또는 스플라인 기반 방법을 이용하여 영상 정합을 수행하였다. 그러나, 이러한 방식은 정합하 고자 하는 영상 사이의 강력한 연관성을 찾기 용이하지 않은 문제점이 존재한다."}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이러한 종래의 문제점을 해결하기 위한 본 발명의 실시 예들은 서로 다른 종류의 영상데이터를 복수의 인코더와 디코더를 갖는 네트워크 구조에 적용하여 위상별 변위맵을 추정함으로써 딥러닝 기반 정합 기법을 이용하여 멀 티 위상을 갖는 동영상데이터와 정지영상데이터의 정합을 수행할 수 있는 비지도 학습 기법을 이용한 영상데이 터의 정합 방법 및 장치를 제공하는 것이다. 아울러, 본 발명의 실시 예들은 서로 다른 종류의 영상데이터에서 추출된 혈관, 분기점 및 특징점을 포함하는 특징맵을 이용하여 복수의 영상데이터 정합 시의 손실율을 고려하면서 복수의 영상데이터를 정합할 수 있는 비 지도 학습 기법을 이용한 영상데이터의 정합 방법 및 장치를 제공하는 것이다."}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 비지도 학습 기법을 이용한 영상데이터의 정합 방법은, 제1 영상데이터 및 제2 영상 데이터를 획득하는 단계, 상기 제1 영상데이터와 상기 제2 영상데이터를 기반으로 복수의 레벨에 대응되는 변위 맵을 추정하는 단계, 상기 변위맵을 기반으로 상기 제1 영상데이터를 변환하여 복수의 제1 변환 영상데이터를 생성하는 단계, 상기 제1 영상데이터로부터 추출된 제1 특징맵으로 복수의 제1 변환특징맵을 생성하는 단계, 쌍 (pair)을 이루는 상기 복수의 제1 변환특징맵과 상기 제2 영상데이터로부터 추출된 제2 특징맵을 이용하여 학습 을 수행하는 단계 및 상기 학습의 수행결과를 기반으로 복수의 영상데이터를 정합하는 단계를 포함하는 것을 특 징으로 한다. 또한, 제1 영상데이터는 복수의 위상을 갖는 동영상데이터, 상기 제2 영상데이터는 정지영상데이터인 것을 특징 으로 한다. 또한, 변위맵을 추정하는 단계는, 상기 복수의 레벨을 갖는 인코더와 디코더를 포함하는 네트워크를 이용하여 상기 복수의 위상 각각에 대응되는 변위맵을 추정하는 단계인 것을 특징으로 한다. 또한, 제1 변환 영상데이터를 생성하는 단계는, 상기 제1 영상데이터에 상기 변위맵을 각각 적용하여 복수의 제 1 변환 영상데이터를 생성하는 단계인 것을 특징으로 한다. 또한, 제1 변환특징맵을 생성하는 단계는, 상기 제1 영상데이터를 이용하여 제1 특징맵을 추출하는 단계 및 상 기 제1 특징맵에 상기 변위맵을 각각 적용하여 복수의 제1 변환특징맵을 생성하는 단계를 포함하는 것을 특징으 로 한다. 또한, 학습을 수행하는 단계는, 쌍(pair)을 이루는 상기 복수의 제1 변환 영상데이터와 상기 제2 영상데이터의 차이값이 최소가 될 때까지 학습하는 단계 및 상기 복수의 제1 변환특징맵과 상기 제2 특징맵의 차이값이 최소 가 될 때까지 학습하는 단계를 포함하는 것을 특징으로 한다. 또한, 학습을 수행하는 단계는, 상기 복수의 레벨에 대응되는 변위맵에 대한 손실 함수, 상기 복수의 제1 변환 영상데이터와 상기 제2 영상데이터 사이의 손실 함수 및 상기 복수의 제1 변환특징맵과 상기 제2 특징맵 사이의 손실 함수를 고려하여 최종 손실 함수를 정의하는 단계를 포함하는 것을 특징으로 한다. 또한, 제1 특징맵 및 상기 제2 특징맵은 상기 제1 영상데이터와 상기 제2 영상데이터 각각에서 확인되는 혈관, 분기점 및 특징점 중 적어도 하나를 포함하는 것을 특징으로 한다. 아울러, 본 발명의 실시 예에 따른 비지도 학습 기법을 이용한 영상데이터의 정합 장치는, 적어도 하나의 영상 획득장치에서 획득된 제1 영상데이터 및 제2 영상데이터를 기반으로 복수의 레벨에 따른 변위맵을 추정하는 변 위맵추정기, 상기 제1 영상데이터로부터 제1 특징맵을 추출하고, 상기 제2 영상데이터로부터 제2 특징맵을 추출 하는 특징추출기, 상기 변위맵을 기반으로 상기 제1 영상데이터를 변환하여 복수의 제1 변환 영상데이터를 생성 하고, 상기 제1 특징맵을 변환하여 복수의 제1 변환특징맵을 생성하는 공간변환기 및 쌍(pair)을 이루는 상기복수의 제1 변환특징맵과 상기 제2 특징맵을 이용하여 학습을 수행하고, 상기 학습의 수행결과를 기반으로 복수 의 영상데이터를 정합하는 손실확인기를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 발명에 따른 비지도 학습 기법을 이용한 영상데이터의 정합 방법 및 장치는, 서로 다른 종 류의 영상데이터를 복수의 인코더와 디코더를 갖는 네트워크 구조에 적용하여 위상별 변위맵을 추정함으로써 딥 러닝 기반 정합 기법을 이용하여 멀티 위상을 갖는 동영상데이터와 정지영상데이터의 정합을 수행할 수 있는 효 과가 있다. 또한, 본 발명에 따른 비지도 학습 기법을 이용한 영상데이터의 정합 방법 및 장치는, 서로 다른 종류의 영상데 이터에서 추출된 혈관, 분기점 및 특징점을 포함하는 특징맵을 이용하여 복수의 영상데이터 정합 시의 손실율을 고려함으로써, 복수의 영상데이터의 밝기 분포가 상이하더라도 복수의 영상데이터의 정합 일치도를 향상시킬 수 있고, 다양한 종류의 영상데이터의 정합에 적용할 수 있는 효과가 있다."}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 바람직한 실시 형태를 첨부된 도면을 참조하여 상세하게 설명한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 발명의 예시적인 실시형태를 설명하고자 하는 것이며, 본 발명이 실시될 수 있 는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략할 수 있고, 명세서 전체를 통하여 동일 또는 유사한 구성 요소에 대해서는 동일한 참조 부 호를 사용할 수 있다. 본 발명의 일 실시 예에서, “또는”, “적어도 하나” 등의 표현은 함께 나열된 단어들 중 하나를 나타내거나, 또는 둘 이상의 조합을 나타낼 수 있다. 예를 들어, “A 또는 B”, “A 및 B 중 적어도 하나”는 A 또는 B 중 하나만을 포함할 수 있고, A와 B를 모두 포함할 수도 있다. 도 1은 본 발명의 실시 예에 따른 영상데이터의 정합 시스템을 나타낸 도면이다. 도 1을 참조하면, 본 발명에 따른 정합 시스템은 영상획득장치 및 정합 장치를 포함하고, 영상획 득장치는 제1 영상획득장치, 제2 영상획득장치를 포함하며, 정합 장치는 변위맵추정기 , 공간변환기, 손실확인기 및 특징추출기를 포함한다. 영상획득장치는 멀티 위상(multi-phase) 초광각(ultra-widefield) 망막 영상데이터를 획득하는 광각안저카 메라일 수 있다. 이때, 제1 영상획득장치는 광각안저카메라에서 동영상데이터인 제1 영상데이터(M; moving image data)를 획득하는 이미지 센서로, 획득된 제1 영상데이터를 변위맵추정기 및 특징추출기로 제 공한다. 아울러, 제2 영상획득장치는 광각안저카메라에서 정지영상데이터인 제2 영상데이터(F; fixed image data)를 획득하는 이미지 센서로, 획득된 제2 영상데이터를 변위맵추정기 및 특징추출기로 제 공한다. 아울러, 본 발명의 실시 예에서는 영상획득장치가 서로 다른 제1 영상획득장치와 제2 영상획득장치 를 포함하는 것을 예로 설명하고 있으나, 이는 설명의 편의를 위한 것이다. 즉, 제1 영상획득장치와 제2 영상획득장치는 하나의 이미지 센서로 구성되되, 영상획득장치를 이용하는 사용자에 의해 동영상 데이터 획득 시 특정 시점에 동영상데이터를 캡쳐하여 정지영상데이터를 획득할 수 있다. 또한, 본 발명의 실시 예에서는 설명의 편의를 위해 광각안저카메라를 예로 설명하고 있으나, 반드시 이에 한정되는 것은 아니며, X- ray, 초음파, CT(computed tomography), MRI(magnetic resonance imaging), PET(positron emissiontomography) 등과 같이 동영상데이터와 정지영상데이터를 획득할 수 있는 의료영상획득장치에 변경적용이 가능 하다. 정합 장치는 제1 영상획득장치와 제2 영상획득장치에서 제공된 제1 영상데이터(M)와 제2 영상데 이터(F)의 정합을 수행한다. 이를 위해, 정합 장치는 변위맵추정기, 공간변환기, 손실확인기 및 특징추출기를 포함할 수 있고, 정합 장치는 컴퓨터, 태블릿 PC(personal computer) 등의 장치일 수 있다. 변위맵추정기는 복수의 인코더 및 디코더를 포함하여 구현된 네트워크 예컨대, U-Net을 이용할 수 있다. 변위맵추정기는 네트워크를 이용하여 멀티 위상을 갖는 제1 영상데이터(M)와 제2 영상데이터(F)의 변위맵 을 추정한다. 변위맵추정기의 동작은 하기의 도 2를 이용하여 구체적으로 설명하기로 한다. 도 2는 본 발 명의 실시 예에 따른 변위맵을 추정하는 네트워크의 구조를 나타내는 도면이다. 도 2를 참조하면, 제1 영상획득장치에서 획득된 제1 영상데이터(M) 및 제2 영상데이터(F)는 변위맵추정기 에 구현된 네트워크에 적용되어 디코더의 각 레벨에서 제1 영상데이터(M)가 갖는 멀티 위상별로 제1 영상 데이터(M) 및 제2 영상데이터(F)를 기반으로 하는 위상별 변위맵(displacement map)( 내지 )을 추정한다. 이때, 변위맵은 제1 영상데이터(M)와 제2 영상데이터(F) 사이의 변위를 매칭하기 위해 추정된다. 이를 위해, 제 1 영상데이터(M)와 제2 영상데이터(F)는 인코딩 블록을 위한 채널과 역순으로 디코딩 블록을 위한 채널을 형성 하는 6개의 인코더와 디코더를 통과한다. 이때, 인코더와 디코더의 개수는 6개로 한정되지 않음을 명확히 하는 바이다. 아울러, 변위맵추정기에서 추정된 변위맵( 내지 )은 공간변환기 및 손실확인기로 제공된다. 보다 구체적으로, 디코더의 각 레벨에서의 특징맵은 다른 해상도들과 함께 변위를 추정하기 위해서 컨벌루션 블 록에 포함된 LeakyReLU 활성화 기능을 가진 3X3 컨벌루션을 통과한다. 4X4커널사이즈와 2X2스트라이드를 포함한 컨벌루션 레이어는 인코딩 블록내에서 풀링없이 사용되고, 디코딩 블록에서 X2 업샘플링이 사용된다. 저해상도 의 변위맵(예컨대, 또는 )은 선형 보간에 의해 제2 영상데이터(F)의 크기로 업샘플링된다. 공간변환기는 경사하강법(gradient-descent)을 사용하는 최적화에서 손실 함수와 관련된 매개 변수를 차별 화한다. 이를 위해, 공간변환기는 쌍선형(bilinear) 보간을 이용하여 이미지의 픽셀 사이의 값을 계산한다. 그리고 공간변환기는 변위맵추정기에서 추정된 복수의 변위맵( 내지 )을 이용하여 복수의 제1 변환 영상데이터(M 내지 M( )를 생성한다. 보다 구체적으로, 공간변환기는 제1 영상데 이터(M)에 복수의 변위맵( 내지 )을 각각 적용하여 복수의 제1 변환 영상데이터(M 내지 M( )를 생 성하고, 이를 손실확인기로 제공한다. 제1 변환 영상데이터 생성 시 공간변환기는 제1 변환 영상데이 터(M 내지 M( 각각의 픽셀 값들을 샘플링한다. 이때, 공간변환기는 선형 보간을 이용하여 불연속 이미지를 연속 그리드로 변환할 수 있다. 아울러, 공간변환기는 특징추출기로부터 제공된 제1 특징맵 (Mv)에 복수의 변위맵( 내지 )을 각각 적용하여 복수의 제1 변환특징맵(Mv 내지 Mv( )를 생성한다. 손실확인기는 제2 영상획득장치에서 수신된 제2 영상데이터(F)와 변위맵추정기로부터 제공된 제 1 변환 영상데이터(M 내지 M( )를 비교하여 차이가 최소화가 될 때까지 학습을 수행한다. 이를 위해, 손 실확인기는 제2 영상데이터(F)와 제1 변환 영상데이터(M 내지 M( )의 쌍(pair)을 생성하여 비교할 수 있다. 또한, 손실확인기는 특징추출기로부터 제공된 제2 특징맵(Fv)과 공간변환기로부터 제 공된 복수의 제1 변환특징맵(Mv 내지 Mv( )을 비교하여 차이가 최소화될 때까지 학습을 수행한다. 이를 위해, 손실확인기는 제2 특징맵(Fv)과 제1 변환특징맵(Mv 내지 Mv( )의 쌍(pair)을 생성하여 비교 할 수 있다. 이를 통해, 손실확인기는 영상데이터 정합 시에 손실율을 최소로 할 수 있는 영상데이터를 선 택하여 영상데이터를 정합할 수 있다. 아울러, 특징추출기는 제1 영상획득장치에서 획득된 제1 영상데이터(M)를 이용하여 적어도 하나의 제 1 특징맵(Mv)를 추출한다. 또한, 특징추출기는 제2 영상획득장치에서 획득된 제2 영상데이터(F)를 이 용하여 제2 특징맵(Fv)를 추출한다. 이때, 제1 특징맵(Mv)은 제1 영상데이터(M)에서 확인되는 혈관, 분기점 및특징점 중 적어도 하나를 포함할 수 있고, 제2 특징맵(Fv)는 제2 영상데이터(F)에서 확인되는 혈관, 분기점 및 특징점 중 적어도 하나를 포함할 수 있다. 이를 위해, 특징추출기는 프랜지 필터(frangi filter), 혈관 및 분기점 검출기, SIFT 및 에지기반 해리스 코너 검출기 등을 포함하는 다양한 특징추출기를 적용할 수 있다. 보다 구체적으로, 손실확인기는 제1 영상데이터(M)을 기반으로 생성된 제1 변환 영상데이터(M( ))와 제2 영상데이터(F) 사이의 유사성 손실(Lsim)을 이용하여 손실 함수를 정의한다. 이때, 유사성 손실(Lsim)은 제1 변 환 영상데이터(M ))와 제2 영상데이터(F)의 일부 영역의 음의 상호상관(CC; cross-correlation)으로써 정의되 고 이는 하기의 수학식 1과 같다. 수학식 1"}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "(단, 와 는 n*n 패치의 평균 밝기를 나타내고, pi는 p주위의 n*n패치를 반복하는 횟수를 의미한다.) 이때, 상호상관값이 높아질수록 정렬이 좋아지며, 손실 함수는 Lsim(F, M( ))=-CC(F, M( ))의 형식으로 사용된 다. 또한, 다른 특성을 갖는 제1 변환 영상데이터(M( ))와 제2 영상데이터(F)를 매치하기 위하여 제1 변환특징 맵(Mv( ))과 제2 특징맵(Fv) 사이의 상호상관도 손실 함수에 추가된다. 변위맵추정기에 의해 추정된 변위맵( )은 제1 변환특징맵(Mv( ))을 생성하기 위해 제1 특징맵(Mv)에 적용 된다. 이때, 제1 변환특징맵(Mv( ))과 제2 특징맵(Fv) 사이의 상호상관은 Lvessel(Fv, Mv( )) = -CC(Fv, Mv( ))로 계산된다. 아울러, 손실확인기는 하기의 수학식 2와 같이 Lsim과 Lvessel과 함께 평탄화 손실인 Lsmooth를 이용하여 변위맵( 내지 )에 대한 손실 함수를 정의하고 변형 필드의 기울기를 기반으로 부자연스러운 변위를 정규화 한다. 수학식 2"}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "마지막으로, 손실확인기는 하기의 수학식 3을 이용하여 최종 손실값을 산출한다. 수학식 3"}
{"patent_id": "10-2020-0049295", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(단, λ는 정규화 변수이다.) 이와 같이, 손실확인기는 최종적으로 산출된 최종 손실값이 가장 작을 때까지 반복적으로 학습을 수행한다. 그리고, 손실확인기에서 최종 손실값이 0에 가장 가깝게 산출되면 정합 장치는 학습이 완 료된 것으로 확인하고, 학습 완료 시점에 입력된 제1 영상데이터와 제2 영상데이터를 정합한다. 도 3은 본 발명의 실시 예에 따른 영상데이터의 정합 방법을 설명하기 위한 순서도이다. 도 3을 참조하면, 301단계에서 정합 장치는 제1 영상획득장치와 제2 영상획득장치에서 획득된 제1 영상데이터와 제2 영상데이터를 수신한다. 303단계에서 정합 장치에 포함된 변위맵추정기는 복수 의 인코더와 디코더로 구현된 네트워크를 이용하여 멀티 위상을 갖는 제1 영상데이터(M)와 제2 영상데이터(F)를 기반으로 하는 변위맵(displacement map)( 내지 ))을 추정한다. 305단계에서 정합 장치에 포함된 공간변환기는 제1 영상데이터(M)에 복수의 변위맵( 내지 )을 각각 적용하여 복수의 제1 변환 영상데이터(M 내지 M( )를 생성한다. 307단계에서 특징추출기는 제 1 영상데이터(M)를 이용하여 제1 특징맵(Mv)을 추출한다. 이때, 제1 특징맵(Mv)은 제1 영상데이터(M)에서 확인 되는 혈관, 분기점 및 특징점 중 적어도 하나를 포함할 수 있다. 309단계에서 정합 장치에 포함된 공간변환기는 특징추출기에서 추출된 제1 특징맵(Mv)에 복수의 변위맵( 내지 )을 각각 적용하여 복수의 제1 변환특징맵(Mv 내지 Mv( )를 생성한다. 이어서, 311 단계에서 특징추출기는 제2 영상데이터(F)를 이용하여 제2 특징맵(Fv)를 추출한다. 이때, 제2 특징맵(Fv) 는 제2 영상데이터(F)에서 확인되는 혈관, 분기점 및 특징점 중 적어도 하나를 포함할 수 있다. 이어서, 313단계에서 정합 장치의 손실확인기는 학습을 수행하고 315단계를 수행한다. 315단계에서 정합 장치는 학습이 완료됨이 확인되면 317단계를 수행하여 영상데이터를 정합하고, 학습이 완료됨이 확인 되지 않으면 313단계로 회귀하여 학습이 완료될 때까지 반복적으로 학습을 수행한다. 보다 구체적으로, 손실확인기는 제2 영상획득장치에서 수신된 제2 영상데이터(F)와 변위맵추정기 로부터 제공된 제1 변환 영상데이터(M 내지 M( )를 비교하여 차이가 최소화가 될 때까지 학습을 수 행한다. 또한, 손실확인기는 특징추출기로부터 제공된 제2 특징맵(Fv)과 공간변환기로부터 제공 된 복수의 제1 변환특징맵(Mv 내지 Mv( )을 비교하여 차이가 최소화될 때까지 학습을 수행한다. 이는 상 기의 수학식 1 내지 수학식 3에서 설명하였으므로 구체적인 설명을 생략하기로 한다. 손실확인기에서 정의 된 변위맵( 내지 )에 대한 손실 함수, 제1 변환 영상데이터(M( ))와 제2 영상데이터(F) 사이의 손실 함수 및 제1 변환특징맵(Mv( ))과 제2 특징맵(Fv) 사이의 손실 함수를 고려하여 산출된 최종 손실값이 0에 가장 가 까워지면 정합 장치는 학습이 완료된 것으로 확인하고, 학습 완료 시점에 입력된 제1 영상데이터와 제2 영 상데이터를 정합한다. 도 4는 본 발명의 실시 예에 따른 영상데이터의 정합 방법 및 다른 방법으로 영상데이터를 정합한 결과를 나타 낸 도면이다. 도 4를 참조하면, 도 4는 본 발명의 정합 방법과 이전의 affine정합, B-spline, SIFT-RANSAC, VoxelMorph를 이 용하였을 때 확인되는 평균 리콜, 정밀도, DSC(dice similarity coefficient), 거리 점수를 나타낸 표이며, 이 동(moving)은 동영상데이터와 정지영상데이터 사이의 정확도 점수를 나타낸다. 도 4를 참조하면, affine 변환의 경우, 변환 전과 변환 후의 거리가 크게 변화가 없으며, affine+b-spline의 경 우, 밝기 분포 차이가 커서 매칭이 실패한 경우가 많다. 아울러, VoxelMorph는 DSC와 거리 점수에서 보다 나은 성능을 달성하였으나, 대응 사이의 거리에 대한 개선은 상대적으로 낮음을 확인할 수 있다. 반면, 본 발명의 정합 방법은 최고의 성능을 달성하였음을 확인할 수 있다. 예컨대, 분기점 사이의 거리가 감소 한 것은 본 발명의 정합 방법의 결과가 자연 변위 맵을 획득하였음을 나타내고, 디코더의 멀티 레벨에서 변위 추정이 수행되었을 때 DSC가 2%의 성능이 향상되었고, VoxelMorph와 비교한 거리의 오차가 1정도 향상되었음을 확인할 수 있다. 또한, 혈관에 의해 계산된 손실이 사용될 때 DSC가 3%의 성능이 향상되었고, 거리의 오차가 2정도 향상되었음을 확인할 수 있다. 상기의 도 4는 당뇨병성 망막증 환자 30명에 대한 3900*3076크기의 영상데이터를 이용하여 실험을 진행한 결과 이다. 이때, 획득한 영상데이터는 1) 당뇨병성 망막증 환자 30명으로부터 3900*3076크기를 갖는 30쌍의 초기 위 상 및 후기 위상 UWF FA(fluorescein angiography)이미지, 2) 다른 망막 혈관 질환이 있는 34명의 환자로부터 4000*4000크기를 갖는 5 내지 10개의 멀티 위상 UWF FA 이미지를 포함한다. 1)과 2)의 이미지들의 크기를 동일하게 조정하고 [0, 1]의 밝기 범위를 조정하기 위해 히스토그램 이퀄라이제이 션을 수행하였다. 정합 정확도를 측정하기 위해 이미지의 쌍으로부터 혈관과 분기점을 추출하였다. 혈관 추출을 위해, 프랜지 필터링에 의해 획득된 혈관 지수의 임계값을 계산하고 수동으로 오류를 수정하여 이진 분할을 수 행하였다. 그리고 분기점에도 수동으로 주석을 달았다. 본 명세서와 도면에 개시된 본 발명의 실시 예들은 본 발명의 기술 내용을 쉽게 설명하고 본 발명의 이해를 돕 기 위해 특정 예를 제시한 것일 뿐이며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 따라서 본 발명의 범 위는 여기에 개시된 실시 예들 이외에도 본 발명의 기술적 사상을 바탕으로 도출되는 모든 변경 또는 변형된 형 태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2020-0049295", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 영상데이터의 정합 시스템을 나타낸 도면이다. 도 2는 본 발명의 실시 예에 따른 변위맵을 추정하는 네트워크의 구조를 나타내는 도면이다. 도 3은 본 발명의 실시 예에 따른 영상데이터의 정합 방법을 설명하기 위한 순서도이다. 도 4는 본 발명의 실시 예에 따른 영상데이터의 정합 방법 및 다른 방법으로 영상데이터를 정합한 결과를 나타 낸 도면이다."}
