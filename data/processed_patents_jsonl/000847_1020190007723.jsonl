{"patent_id": "10-2019-0007723", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0040165", "출원번호": "10-2019-0007723", "발명의 명칭": "분산처리용 인공신경망 연산 가속화 장치, 이를 이용한 인공신경망 가속화 시스템, 및 그 인", "출원인": "주식회사 디퍼아이", "발명자": "이상헌"}}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력 뉴런들이 계층적으로 구성되어 형성된 인공 신경망 연산을 처리하기 위한 가속화 장치에 있어서, 상기 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 저장하는 외부 메인 메모리;상기 외부 메인 메모리에 저장된 시냅스 가중치와 입력데이터 중 상기 인공 신경망 연산을 구성하는 각각의 사이클마다 필요한 시냅스 가중치와 입력데이터를 저장하는 내부 버퍼 메모리;상기 외부 메인 메모리 및 내부 버퍼 메모리와 데이터를 직접 송수신 하기 위한 DMA모듈;상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 인공 신경망 연산을 수행하고 연산 결과를 상기 외부 메인 메모리에 저장하는 일련의 순차적인 과정을 인공 신경망 연산을 구성하는 각각의 사이클마다 반복적으로 처리하는 신경망 연산장치; 상기 외부 메인 메모리와 내부 버퍼 메모리에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 저장시키는 동작과 상기 신경망 연산장치의 동작을 제어하기 위한 CPU; 및상기 입력 뉴런들에 대한 입력데이터와 시냅스 가중치, 및 상기 신경망 연산장치에서 수행한 연산결과를 집적회로의 종류에 관계없이 물리적으로 연결되는 다른 가속화 장치와 송수신할 수 있는 범용 통신중개블록;을 구비하는 것을 특징으로 하는 분산처리용 인공신경망 연산 가속화 장치"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 범용 통신중개블럭은, 물리적으로 연결되는 가속화 장치를 구성하는 집적회로의 종류가 SoC(System on Chip)또는 FPGA(FieldProgrammable Gate Array)일 경우 모두 통신중개가 가능하게 형성되며, 송신용 집적회로와 연결된 버스 마스터인터페이스로부터 인가되는 신호들 중 수신용 집적회로의 구성요소를 지정하는 어드레스와 버스 ID신호의 폭을리맵핑하기 위한 리맵핑 블럭;을 구비하는 것을 특징으로 하는 분산처리용 인공신경망 연산 가속화 장치"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "입력 뉴런들에 대한 입력데이터가 복수개의 깊이를 갖는 인공 신경망 연산을 처리하기 위한 가속화 시스템에 있어서,상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저장된 플래시 메모리와 연결되며 호스트용 통신중개블록을 상기 복수개의 깊이 갯수 이상으로 구비하는 호스트 가속화 장치; 및상기 호스트 가속화 장치의 호스트용 통신중개블럭에 물리적으로 연결되는 슬레이브용 통신중개블록을 각각 하나 이상 구비하며, 상기 복수개의 깊이 갯수에 일대일 대응되게 형성되는 복수개의 슬레이브 가속화 장치;를 구비하고,상기 호스트 가속화 장치는, 상기 복수개의 깊이 각각에 관련되는 슬레이브 가속화 장치에 시냅스 가중치와 입력데이터를 병렬방식으로 분산시켜 인공 신경망 연산을 처리하게 하고, 상기 슬레이브 가속화 장치의 중간연산결과를 취합하여 최종 연산을수행하는 것을 특징으로 하는 인공신경망 가속화 시스템"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2020-0040165-3-입력 뉴런들이 복수개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템에 있어서,상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저장된 플래시 메모리와 연결되며 호스트용 통신중개블록을 송수신용으로 한 쌍 이상 구비하는 호스트 가속화 장치; 및상기 호스트 가속화 장치와 전체적으로 파이프라인 형태가 되게 순차적으로 연결되기 위하여 슬레이브용 통신중개블록을 송수신용으로 한 쌍 이상 구비하는 복수개의 슬레이브 가속화 장치;를 구비하고,상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치에 상기 인공 신경망 연산을 구성하는 입력 뉴런들에 대한 시냅스 가중치와 입력데이터를 순차적으로 분산시켜 인공 신경망 연산을 처리하게 하는 것을 특징으로 하는인공신경망 가속화 시스템"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3 또는 청구항 4에 있어서, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, SoC방식 및 FPGA방식 중 어느 한 가지 방식의 집적회로로 구성될 수 있으며,집적회로의 종류에 관계없이 상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록을 통해 상호간에 서로 송수신이 가능하고,상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록은 각각,송신용 집적회로와 연결된 버스 마스터 인터페이스로부터 인가되는 신호들 중 수신용 집적회로의 구성요소를 지정하는 어드레스와 버스 ID신호의 폭을 리맵핑하기 위한 리맵핑 블럭;을 구비하는 것을 특징으로 하는 인공신경망 가속화 시스템"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각,입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 저장하는 외부 메인 메모리;상기 외부 메인 메모리에 저장된 시냅스 가중치와 입력데이터 중 인공 신경망 연산을 구성하는 각각의 사이클마다 필요한 시냅스 가중치와 입력데이터를 저장하는 내부 버퍼 메모리;상기 외부 메인 메모리 및 내부 버퍼 메모리와 데이터를 직접 송수신 하기 위한 DMA모듈;상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 인공 신경망 연산을 수행하고 연산 결과를 상기 외부 메인 메모리에 저장하는 일련의 순차적인 과정을 인공 신경망 연산을 구성하는 각각의 사이클마다 반복적으로 처리하는 신경망 연산장치; 및 상기 외부 메인 메모리와 내부 버퍼 메모리에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 저장시키는 동작과 상기 신경망 연산장치의 동작을 제어하기 위한 CPU;를 더 구비하는 것을 특징으로 하는 인공신경망 가속화시스템"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "입력 뉴런들에 대한 입력데이터가 복수(M)개의 깊이와 복수(N)개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템에 있어서,상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저장된 플래시 메모리와 연결되며 호스트용 통신중개블록을 상기 복수(N)개의 계층 수 이상으로 구비하는 호스트 가속화 장치; 및상기 호스트 가속화 장치의 호스트용 통신중개블럭과 연결되거나 다른 가속화 장치와 연결되기 위한 슬레이브용통신중개블록을 하나 이상 구비하고, 상기 복수(M)개의 깊이 및 복수(N)개의 계층에 필요한 신경망 연산 사이클수(M×N)와 일대일 대응되게 형성되는 복수개의 슬레이브 가속화 장치;를 구비하는 것을 특징으로 하는 인공신공개특허 10-2020-0040165-4-경망 가속화 시스템"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, SoC방식 및 FPGA방식 중 어느 한 가지 방식의 집적회로로 구성될 수 있으며,집적회로의 종류에 관계없이 상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록을 통해 상호간에 서로 송수신이 가능하고,상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록은, 각각 송신용 집적회로와 연결된 버스 마스터인터페이스로부터 인가되는 신호들 중 수신용 집적회로의 구성요소를 지정하는 어드레스와 버스 ID신호의 폭을리맵핑하기 위한 리맵핑 블럭;을 구비하는 것을 특징으로 하는 인공신경망 가속화 시스템"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각,입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 저장하는 외부 메인 메모리;상기 외부 메인 메모리에 저장된 시냅스 가중치와 입력데이터 중 인공 신경망 연산을 구성하는 각각의 사이클마다 필요한 시냅스 가중치와 입력데이터를 저장하는 내부 버퍼 메모리;상기 외부 메인 메모리 및 내부 버퍼 메모리와 데이터를 직접 송수신 하기 위한 DMA모듈;상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 인공 신경망 연산을 수행하고 연산 결과를 상기 외부 메인 메모리에 저장하는 일련의 순차적인 과정을 인공 신경망 연산을 구성하는 각각의 사이클마다 반복적으로 처리하는 신경망 연산장치; 및 상기 외부 메인 메모리와 내부 버퍼 메모리에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 저장시키는 동작과 상기 신경망 연산장치의 동작을 제어하기 위한 CPU;를 더 구비하는 것을 특징으로 하는 인공신경망 가속화시스템"}
{"patent_id": "10-2019-0007723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "단일의 집적회로로 구성되는 분산처리용 인공신경망 연산 가속화 장치를 이용해 입력층과 N개의 은닉층을 포함하여 계층구조를 갖는 인공신경망 처리를 가속화 하는 방법에 있어서,상기 가속화 장치에 전원이 인가되면 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 외부 메인 메모리에 저장하는 단계(a1);데이터 입력장치를 통해 입력되는 최초 입력데이터를 DMA모듈을 거쳐 외부 메인 메모리에 저장하는 단계(a2);상기 외부 메인 메모리에 저장된 입력데이터와 상기 입력데이터에 대응되는 시냅스 가중치를 인공신경망의 입력층을 구성하는 각각의 사이클에 필요한 만큼 내부 버퍼 메모리에 저장하는 단계(a3);신경망 연산장치가 상기 인공신경망을 구성하는 각각의 사이클에 대응되어 상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 층 전체에 대한 연산이 완료될 때 까지 인공 신경망 연산을 수행하고 그연산 결과를 다음층의 입력데이터로 사용하기 위해 외부 메인 메모리에 저장하는 단계(a4);은닉층에 대한 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치와 입력 데이터를 각각의 사이클에필요한 만큼 상기 외부 메인 메모리로부터 읽어 내부 버퍼 메모리에 저장한 다음 상기 a4단계를 수행하는 과정을 N개의 은닉층에 대하여 반복적으로 수행하는 단계(a5);를 포함하는 것을 특징으로 하는 인공신경망 가속화방법"}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 분산처리용 인공신경망 연산 가속화 장치, 이를 이용한 인공신경망 가속화 시스템, 및 그 인공신경망 의 가속화 방법에 관한 것으로서, 본 발명에 따른 분산처리용 인공신경망 연산 가속화 장치는, 입력 뉴런들이 계 층적으로 구성되어 형성된 인공 신경망 연산을 처리하기 위한 가속화 장치에 있어서, 상기 입력 뉴런들에 대한 (뒷면에 계속)"}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "분산처리용 인공신경망 연산 가속화 장치, 이를 이용한 인공신경망 가속화 시스템, 및 그 인공신경망의 가속화 방법에 관한 것으로서, 더욱 상세하게는, 인공 신경망의 연산에 필요한 입력 뉴런들에 대한 데이터와 시냅스 가 중치를 범용 통신중개블럭을 구비한 복수개의 분산처리용 인공신경망 연산 가속화 장치에 분산하여 처리함으로 써 GPGPU와 같은 고전력 고비용의 하드웨어를 사용하지 않더라도 인공신경망 연산에 필요한 성능을 만족시킬 수 있을 뿐만 아니라 목표 성능에 맞게 인공신경망을 유연하게 설계할 수 있는 분산처리용 인공신경망 연산 가속화 장치, 이를 이용한 인공신경망 가속화 시스템, 및 그 인공신경망의 가속화 방법에 관한 것이다."}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술이 발달하면서 다양한 산업분야에 인공지능 기술이 도입되고 있다. 이와 같은 인공지능 기술은 이면에 다수의 신호를 입력으로 받아 하나의 신호를 출력하는 퍼셉트론 알고리즘을 기원으로 하여 뉴런 네트워크로 구성된 인공 신경망기술로 진화해온 딥 러닝(Deep Learning; 심층학습) 기술이 중요한 역할을 담당하고 있다. 여기서, 상기 딥 러닝 기술과 같은 인공 신경망 기술을 수행하기 위해서는 입력 뉴런 들에 대한 수많은 가중치 와 연산을 필요로 하기 때문에 종래기술에 따른 인공신경망 관련 가속화 기술의 경우에는 GPU(Graphics Processing Unit; 그래픽 처리 장치)의 자원을 이용해 그래픽 작업 이외의 범용작업을 할 수 있는 GPGPU(General-Purpose computing on Graphics Processing Unit ; 범용 그래픽 처리 장치)와 같은 고가의 하드 웨어를 사용하지 않으면 요구되는 연산 성능을 만족하기에는 어려움이 있는 문제점이 있었다. 뿐만 아니라, 상기 GPGPU를 동작시키기 위해서는 높은 전력을 필요로 하기 때문에 IoT(Internet Of Things; 사 물인터넷)와 같은 저전력을 필요로 하는 분야에 적용하기에는 어려움이 있으며, 딥 러닝 기술로 빅데이터를 처 리하기 위하여 대규모 컴퓨터 시스템이 설치되는 데이터센터의 경우에는 인공 신경망 기술을 구현하는데 필요한 가속화 장치를 GPGPU로 구성하면서 대규모 전력을 필요로 하기 때문에 초기 구축비용 뿐만 아니라 유지보수에 소요되는 비용이 기하급수적으로 늘어나는 심각한 문제점이 있었다. 따라서, 인공신경망 관련 가속화 기술을 구현하는 경우에 GPGPU와 같은 고가의 하드웨어를 필요로 하지 않으면 서도 연산 성능을 만족시킬 수 있으며 나아가 전력소모를 줄일 수 있는 현실적이고도 적용이 가능한 기술이 절 실히 요구되고 있는 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 KR 10-2011-0027916호(공개일 2011.03.17.)"}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 문제점을 해결하기 위하여 안출된 것으로서, 본 발명은, 인공 신경망의 연산에 필요한 입력 뉴 런들에 대한 데이터와 시냅스 가중치를 범용 통신중개블럭을 구비한 복수개의 분산처리용 인공신경망 연산 가속 화 장치에 분산하여 처리함으로써 GPGPU와 같은 고전력 고비용의 하드웨어를 사용하지 않더라도 인공신경망 연 산에 필요한 성능을 만족시킬 수 있을 뿐만 아니라 목표 성능에 맞게 인공신경망을 유연하게 설계할 수 있는 분 산처리용 인공신경망 연산 가속화 장치, 이를 이용한 인공신경망 가속화 시스템, 및 그 인공신경망의 가속화 방 법을 제공하는데 있다."}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치는, 입력 뉴런들이 계층적으로 구성되어 형성 된 인공 신경망 연산을 처리하기 위한 가속화 장치에 있어서, 상기 입력 뉴런들에 대한 입력데이터와 시냅스 가 중치를 저장하는 외부 메인 메모리; 상기 외부 메인 메모리에 저장된 시냅스 가중치와 입력데이터 중 상기 인공 신경망 연산을 구성하는 각각의 사이클마다 필요한 시냅스 가중치와 입력데이터를 저장하는 내부 버퍼 메모리; 상기 외부 메인 메모리 및 내부 버퍼 메모리와 데이터를 직접 송수신 하기 위한 DMA모듈; 상기 내부 버퍼 메모 리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 인공 신경망 연산을 수행하고 연산 결과를 상기 외부 메인 메모리에 저장하는 일련의 순차적인 과정을 인공 신경망 연산을 구성하는 각각의 사이클마다 반복적으로 처리하 는 신경망 연산장치; 상기 외부 메인 메모리와 내부 버퍼 메모리에 입력 뉴런들에 대한 입력데이터와 시냅스 가 중치를 저장시키는 동작과 상기 신경망 연산장치의 동작을 제어하기 위한 CPU; 및 상기 입력 뉴런들에 대한 입 력데이터와 시냅스 가중치, 및 상기 신경망 연산장치에서 수행한 연산결과를 집적회로의 종류에 관계없이 물리 적으로 연결되는 다른 가속화 장치와 송수신할 수 있는 범용 통신중개블록;을 구비할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치는, 센서인터페이스 또는 Peripheral로 구성 되는 데이터 입력장치;를 더 구비할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치는, 상기 인공 신경망 연산을 수행하는 과정 에 필요한 전체 시냅스 가중치가 저장되는 외부 플래시 메모리;를 더 구비할 수 있다. 상기 범용 통신중개블럭은, 물리적으로 연결되는 가속화 장치를 구성하는 집적회로의 종류가 SoC(System on Chip)또는 FPGA(Field Programmable Gate Array)일 경우 모두 통신중개가 가능하게 형성될 수 있다. 상기 범용 통신중개블럭은, 송신용 집적회로와 연결된 상기 버스 마스터 인터페이스로부터 인가되는 신호들 중 수신용 집적회로의 구성요소를 지정하는 어드레스와 버스 ID신호의 폭을 리맵핑하기 위한 리맵핑 블럭;을 구비 할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망 가속화 시스템은, 입력 뉴런들에 대한 입력데이터가 복수개의 깊이를 갖는 인공 신경망 연산을 처리하기 위한 가속화 시스템에 있어서, 상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저장된 플래시 메모리와 연결되며 호스트용 통신중개블 록을 상기 복수개의 깊이 갯수 이상으로 구비하는 호스트 가속화 장치; 및 상기 호스트 가속화 장치의 호스트용 통신중개블럭에 물리적으로 연결되는 슬레이브용 통신중개블록을 각각 하나 이상 구비하며, 상기 복수개의 깊이 갯수에 일대일 대응되게 형성되는 복수개의 슬레이브 가속화 장치;를 구비하고, 상기 호스트 가속화 장치는, 상 기 복수개의 깊이 각각에 관련되는 슬레이브 가속화 장치에 시냅스 가중치와 입력데이터를 병렬방식으로 분산시 켜 인공 신경망 연산을 처리하게 하고, 상기 슬레이브 가속화 장치의 중간연산결과를 취합하여 최종 연산을 수 행할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망 가속화 시스템은, 입력 뉴런들이 복수개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템에 있어서, 상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저장된 플래시 메모리와 연결되며 호스트용 통신중개블록을 송수신 용으로 한 쌍 이상 구비하는 호스트 가속화 장치; 및 상기 호스트 가속화 장치와 전체적으로 파이프라인 형태가 되게 순차적으로 연결되기 위하여 슬레이브용 통신중개블록을 송수신용으로 한 쌍 이상 구비하는 복수개의 슬레 이브 가속화 장치;를 구비하고, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치에 상기 인공 신경망 연 산을 구성하는 입력 뉴런들에 대한 시냅스 가중치와 입력데이터를 순차적으로 분산시켜 인공 신경망 연산을 처 리하게 할 수 있다. 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, SoC방식 및 FPGA방식 중 어느 한 가지 방식의 집적회로로 구성될 수 있으며, 집적회로의 종류에 관계없이 상기 호스트용 통신중개블록과 상기 슬레이브용 통 신중개블록을 통해 상호간에 서로 송수신이 가능할 수 있다. 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, 입력 뉴런들에 대한 입력데이터와 시냅스 가중 치를 저장하는 외부 메인 메모리; 상기 외부 메인 메모리에 저장된 시냅스 가중치와 입력데이터 중 인공 신경망 연산을 구성하는 각각의 사이클마다 필요한 시냅스 가중치와 입력데이터를 저장하는 내부 버퍼 메모리; 상기 외 부 메인 메모리 및 내부 버퍼 메모리와 데이터를 직접 송수신 하기 위한 DMA모듈; 상기 내부 버퍼 메모리에 저 장된 시냅스 가중치와 입력데이터를 읽어들여 인공 신경망 연산을 수행하고 연산 결과를 상기 외부 메인 메모리 에 저장하는 일련의 순차적인 과정을 인공 신경망 연산을 구성하는 각각의 사이클마다 반복적으로 처리하는 신경망 연산장치; 및 상기 외부 메인 메모리와 내부 버퍼 메모리에 입력 뉴런들에 대한 입력데이터와 시냅스 가중 치를 저장시키는 동작과 상기 신경망 연산장치의 동작을 제어하기 위한 CPU;를 더 구비할 수 있다. 상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록은 각각, 버스 마스터 인터페이스와 버스 슬레이브 인터페이스를 동시에 구비하여 마스터와 슬레이브로 동작이 가능하며, 송신용 집적회로와 연결된 상기 버스 마 스터 인터페이스로부터 인가되는 신호들 중 수신용 집적회로의 구성요소를 지정하는 어드레스와 버스 ID신호의 폭을 리맵핑하기 위한 리맵핑 블럭;을 구비할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망 가속화 시스템은, 입력 뉴런들에 대한 입력데이터가 복수(M)개의 깊이와 복수(N)개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템에 있어서, 상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저장된 플래시 메모리와 연결되며 호스트용 통신중개블록을 상기 복수(N)개의 계층 수 이상으로 구비하는 호스트 가속화 장치; 및 상기 호스트 가속화 장치의 호스트용 통신중개블럭과 연결되거나 다른 가속화 장치와 연결되기 위한 슬레이브용 통신 중개블록을 하나 이상 구비하고, 상기 복수(M)개의 깊이 및 복수(N)개의 계층에 필요한 신경망 연산 사이클 수 (M×N)와 일대일 대응되게 형성되는 복수개의 슬레이브 가속화 장치;를 구비할 수 있다. 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, SoC방식 및 FPGA방식 중 어느 한 가지 방식의 집적회로로 구성될 수 있으며, 집적회로의 종류에 관계없이 상기 호스트용 통신중개블록과 상기 슬레이브용 통 신중개블록을 통해 상호간에 서로 송수신이 가능할 수 있다. 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, 입력 뉴런들에 대한 입력데이터와 시냅스 가중 치를 저장하는 외부 메인 메모리; 상기 외부 메인 메모리에 저장된 시냅스 가중치와 입력데이터 중 인공 신경망 연산을 구성하는 각각의 사이클마다 필요한 시냅스 가중치와 입력데이터를 저장하는 내부 버퍼 메모리; 상기 외 부 메인 메모리 및 내부 버퍼 메모리와 데이터를 직접 송수신 하기 위한 DMA모듈; 상기 내부 버퍼 메모리에 저 장된 시냅스 가중치와 입력데이터를 읽어들여 인공 신경망 연산을 수행하고 연산 결과를 상기 외부 메인 메모리 에 저장하는 일련의 순차적인 과정을 인공 신경망 연산을 구성하는 각각의 사이클마다 반복적으로 처리하는 신 경망 연산장치; 및 상기 외부 메인 메모리와 내부 버퍼 메모리에 입력 뉴런들에 대한 입력데이터와 시냅스 가중 치를 저장시키는 동작과 상기 신경망 연산장치의 동작을 제어하기 위한 CPU;를 더 구비할 수 있다. 상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록은 각각, 송신용 집적회로와 연결된 상기 버스 마 스터 인터페이스로부터 인가되는 신호들 중 수신용 집적회로의 구성요소를 지정하는 어드레스와 버스 ID신호의 폭을 리맵핑하기 위한 리맵핑 블럭;을 구비할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망 가속화 시스템은, 하나 이상의 인공신경망 가속화 시스템에 의해 복수개의 인공신경망으로 구성되는 복합 인공신경망 가속화 시스템에 있어서, 입력 뉴런들에 대한 입력데이터와 시냅시스 가중치를 상기 복수개의 인공신경망을 구성하는 각각의 인 공신경망 단위로 나누어 분산하여 처리할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 단일 의 집적회로로 구성되는 분산처리용 인공신경망 연산 가속화 장치를 이용해 입력층과 N개의 은닉층을 포함하여 계층구조를 갖는 인공신경망 처리를 가속화 하는 방법에 있어서, 상기 가속화 장치에 전원이 인가되면 외부 플 래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 외부 메인 메모리에 저장하는 단계(a1); 데이터 입력장치를 통해 입력되는 최초 입력데이터를 DMA모듈을 거쳐 외부 메인 메모리에 저장하는 단계(a2); 상기 외부 메인 메모리에 저장된 입력데이터와 상기 입력데이터에 대응되는 시냅스 가중치 를 인공신경망의 입력층을 구성하는 각각의 사이클에 필요한 만큼 내부 버퍼 메모리에 저장하는 단계(a3); 신경 망 연산장치가 상기 인공신경망을 구성하는 각각의 사이클에 대응되어 상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 층 전체에 대한 연산이 완료될 때 까지 인공 신경망 연산을 수행하고 그 연산 결과를 다음층의 입력데이터로 사용하기 위해 외부 메인 메모리에 저장하는 단계(a4); 은닉층에 대한 인공 신경 망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치와 입력 데이터를 각각의 사이클에 필요한 만큼 상기 외부 메 인 메모리로부터 읽어 내부 버퍼 메모리에 저장한 다음 상기 a4단계를 수행하는 과정을 N개의 은닉층에 대하여 반복적으로 수행하는 단계(a5);를 포함할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 단일 의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치를 포함하여 입력 뉴런들에 대한 입력데이터가 M개의 깊이를 갖는 인공신경망 처리를 가속화 하는 방법에 있어서, 상기 단일의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치에 전원이 인가되면 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대 한 시냅스 가중치 전체를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(b1); 상기 호스트 가속 화 장치가 범용 통신중개블록을 통해 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 시냅스 가중치 중 상기 M개의 깊이에 대응되는 각각의 시냅스 가중치를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모 리에 병렬방식으로 순차적으로 전달하여 저장하는 단계(b2); 상기 복수개의 슬레이브 가속화 장치의 각 외부 메 인 메모리에 저장된 시냅스 가중치 중 인공신경망의 입력층을 구성하는 각각의 사이클에 필요한 시냅스 가중치 를 상기 각 슬레이브 가속화 장치의 내부 버퍼 메모리에 저장하는 단계(b3); 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 최초 입력데이터를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(b4); 상기 호스트 가속화 장치가 범용 통신중개블록을 통해 상기 호스트 가속화 장치의 외부 메인 메모리 에 저장된 입력데이터 중 상기 M개의 깊이에 대응되는 각각의 입력데이터를 상기 복수개의 슬레이브 가속화 장 치의 각 외부 메인 메모리에 병렬방식으로 순차적으로 전달하여 저장하는 단계(b5); 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장된 입력데이터를 상기 인공신경망을 구성하는 각각의 사이클에 필요한 만큼 상 기 각각의 슬레이브 가속화 장치 내부 버퍼 메모리에 저장하는 단계(b6); 상기 슬레이브 가속화 장치 각각의 신 경망 연산장치가 상기 인공신경망을 구성하는 각각의 사이클에 대응되어 상기 슬레이브 가속화 장치 각각의 내 부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 층 전체에 대한 연산이 완료될 때 까지 인공 신경망 연산을 수행하고 그 연산 결과를 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장하는 단계 (b7); 상기 호스트 가속화 장치가 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장된 중간연산결과 를 수신하여 상기 호스트 가속화 장치의 외부 메인 메모리에 순차적으로 저장한 다음 취합하여 층 전체에 대한 최종연산을 수행하고 최종연산결과를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(b8); 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 최종연산결과를 다음층의 연산을 위한 입력데이터로 사용하기 위하여 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 M개의 깊이에 대응되게 병렬방식으로 순 차적으로 전달하여 저장하는 단계(b9); 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 저장된 시냅스 가중치 중 다음층을 구성하는 각각의 사이클에 필요한 시냅스 가중치를 상기 각 슬레이브 가속화 장치의 내부 버퍼 메모리에 저장하는 단계(b10); 및 입력 데이터에 대한 모든 계층의 연산이 완료 될 때까지 상기 b6 단계 내지 b10 단계를 반복적으로 수행하는 단계(b11);를 포함할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 단일 의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치를 포함하여 입력 뉴런들에 대한 입력데이터가 M개의 깊이를 갖는 인공신경망 처리를 가속화 하는 방법에 있어서, 상기 단일의 호스트 가속화 장치와 복수개의 슬레 이브 가속화 장치에 전원이 인가되면 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대 한 시냅스 가중치 전체를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(c1); 상기 호스트 가속 화 장치가 범용 통신중개블록을 통해 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 시냅스 가중치 중 상기 M개의 깊이에 대응되는 각각의 시냅스 가중치를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모 리에 병렬방식으로 순차적으로 전달하여 저장하는 단계(c2); 상기 복수개의 슬레이브 가속화 장치의 각 외부 메 인 메모리에 저장된 시냅스 가중치 중 인공신경망의 입력층을 구성하는 각각의 사이클에 필요한 시냅스 가중치 를 상기 각 슬레이브 가속화 장치의 내부 버퍼 메모리에 저장하는 단계(c3); 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 최초 입력데이터를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(c4); 상기 호스트 가속화 장치가 외부 메인 메모리에 저장된 입력데이터와 시냅스 가중치 중 신경망의 입 력층을 구성하는 사이클에 필요한 만큼 내부 버퍼 메모리에 저장하고 신경망 연산장치를 이용해 입력층에 대한 신경망 연산을 수행하고 그 연산결과를 다음층의 입력데이터로 사용하기 위해 외부 메인 메모리에 저장하는 단 계(c5); 상기 호스트 가속화 장치가 범용 통신중개블록을 통해 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 입력데이터 중 상기 M개의 깊이에 대응되는 각각의 입력데이터를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 병렬방식으로 순차적으로 전달하여 저장하는 단계(c6); 상기 슬레이브 가속화 장치 각각 의 외부 메인 메모리에 저장된 입력데이터와 그에 해당하는 시냅스 가중치를 상기 인공신경망을 구성하는 각각 의 사이클에 필요한 만큼 상기 각각의 슬레이브 가속화 장치 내부 버퍼 메모리에 저장하는 단계(c7); 상기 슬레 이브 가속화 장치 각각의 신경망 연산장치가 상기 인공신경망을 구성하는 각각의 사이클에 대응되어 상기 슬레 이브 가속화 장치 각각의 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 반복적으로 읽어들여 인공 신경망을 구성하는 계층 전체에 대한 연산이 완료될 때 까지 인공 신경망 연산을 반복적으로 수행하고 그 연산 결과를 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장하는 단계(c8); 및 상기 호스트 가속화 장치 가 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장된 중간연산결과를 수신하여 상기 호스트 가속화 장치의 외부 메인 메모리에 순차적으로 저장한 다음 취합하여 신경망 전체에 대한 최종연산을 수행하고 최종연산결과를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(c9);를 포함할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 단일 의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치의 연결구조가 전체적으로 파이프라인 형태가 되게 순 차적으로 배치되어 입력 뉴런들에 대한 입력데이터가 입력층과 N개의 은닉층을 포함하는 계층구조를 갖는 인공 신경망 처리를 가속화 하는 방법에 있어서, 상기 단일의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치 에 전원이 인가되면 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(d1); 상기 호스트 가속화 장치가 범용 통 신중개블록을 통해 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 시냅스 가중치 중 상기 N개의 계층에 대응되는 각각의 시냅스 가중치를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 순차적으로 전 달하여 저장하는 단계(d2); 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 입력층의 입력 데이터를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(d3); 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 입력층의 입력데이터와 시냅스 가중치를 내부 버퍼 메모리에 저장하는 단계(d4); 상기 호 스트 가속화 장치의 신경망연산 장치에 의해 상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽 어들여 입력층에 대한 신경망 연산을 수행하고 상기 외부 메인 메모리에 연산결과를 저장하는 단계(d5); 다음층 에 해당하는 슬레이브 가속화 장치의 외부 메인 메모리에 연산결과를 입력데이터로 저장한 다음, 상기 슬레이브 가속화 장치의 내부 버퍼 메모리에 해당층에 대응되는 입력데이터와 시냅스 가중치를 저장하는 단계(d6); 상기 슬레이브 가속화 장치의 신견망연산장치에 의해 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어 들여 해당층에 대한 신경망 연산을 수행하고 연산결과를 외부 메인 메모리에 저장하는 단계(d7); N개의 은닉층 에 대하여 상기 d6 내지 d7단계를 반복적으로 수행하고 최종 연산 결과는 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하거나 주변장치에 전달하는 단계(d8);를 포함할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 단일 의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치를 포함하여 입력 뉴런들에 대한 입력데이터가 M개의 깊이와 N개의 계층으로 구성되는 인공신경망 처리를 가속화 하는 방법에 있어서, 상기 단일의 호스트 가속화 장 치와 복수개의 슬레이브 가속화 장치에 전원이 인가되면 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(e1); 상기 호스트 가속화 장치가 범용 통신중개블록을 통해 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 시냅스 가중치 중 상기 N개의 계층에 대응되는 각각의 시냅스 가중치 전체를 각 계층을 구성하는 M개의 깊이 중 각 계층의 첫번째 깊이에 대응하는 N개의 슬레이브 가속화 장치 각각의 외부 메인 메모리에 순차적으로 전달하 면, 전달받은 N개의 슬레이브 가속화 장치와 연결된 다른 깊이에 대응하는 슬레이브 가속화 장치 전체에 해당 시냅스 가중치가 각각 저장되는 단계(e2); 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 입력층의 입력데이터를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(e3); 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 입력층의 입력데이터는 입력층의 첫번째 깊이에 대응되는 슬레이브 가속화 장치의 외부 메인 메모리에 일차적으로 해당층의 전체 입력데이터가 저장된 다음, 입력층을 구성하는 깊이에 대 응하는 M개의 슬레이브 가속화 장치 외부 메인 메모리에 해당되는 입력데이터가 각각 분산되어 순차적으로 저장 되는 단계(e4); 상기 입력층을 구성하는 M개의 슬레이브 가속화 장치 내부 버퍼 메모리에 해당층의 입력데이터 와 시냅스 가중치를 저장하는 단계(e5); 상기 입력층을 구성하는 M개의 슬레이브 가속화 장치의 신경망연산 장 치에 의해 신경망 연산을 수행하고 자신의 외부 메인 메모리에 연산결과를 저장하는 단계(e6); 상기 M개의 슬레 이브 가속화 장치에 저장된 연산결과를 입력층의 첫번째 깊이에 해당하는 슬레이브 가속화 장치에 전달하여 해 당층의 최종 연산을 수행하고 그 최종연산결과를 다음층의 첫번째 깊이에 해당하는 슬레이브 가속화장치에 해당 층의 입력데이터로 전달하는 단계(e7); 다음층의 첫번째 깊이에 대응되는 슬레이브 가속화 장치의 외부 메인 메 모리에 일차적으로 해당층의 전체 입력데이터가 저장된 다음 해당층을 구성하는 M개의 슬레이브 가속화 장치 외 부 메인 메모리에 해당되는 입력데이터가 각각 분산되어 순차적으로 저장하는 단계(e8); 및 N번째 계층의 연산 이 완료될때까지 e5 단계 내지 e8 단계에서와 동일한 과정을 반복수행하고, 최종 연산결과는 상기 호스트 가속 화 장치에 전달하는 단계(e9);를 구비할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 입력 뉴런들에 대한 입력데이터가 복수개의 깊이를 갖는 인공신경망의 가속화 방법에 있어서, 상기 복수개의 깊이에 대응되는 각각의 가속화장치에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 분산하여 처리할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 입력 뉴런들이 복수개의 계층구조로 구성되는 인공신경망의 가속화 방법에 있어서, 상기 복수개의 계층에 대응되는각각의 가속화장치에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 분산하여 처리할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 입력 뉴런들에 대한 입력데이터가 복수개의 깊이와 복수개의 계층구조로 구성되는 인공신경망의 가속화 방법에 있어 서, 복수개의 계층을 각각 구성하는 복수개의 깊이에 대응되는 각각의 가속화장치에 입력 뉴런들에 대한 입력데 이터와 시냅스 가중치를 분산하여 처리할 수 있다. 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 이용한 인공신경망의 가속화 방법은, 하나 이상의 인공신경망 가속화 방법에 의해 복수개의 인공신경망으로 구성되는 복합 인공신경망의 가속화 방법에 있 어서, 입력 뉴런들에 대한 입력데이터와 시냅시스 가중치를 상기 복수개의 인공신경망을 구성하는 각각의 인공 신경망 단위로 나누어 분산하여 처리할 수 있다."}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이, 본 발명은, 인공 신경망의 연산에 필요한 입력 뉴런들에 대한 데이터와 시냅스 가 중치를 집적회로의 종류에 관계없이 통신중개가 가능한 범용 통신중개블럭을 구비한 복수개의 분산처리용 인공 신경망 연산 가속화 장치에 분산하여 처리함으로써 GPGPU와 같은 고전력 고비용의 하드웨어를 사용하지 않더라 도 인공신경망 연산에 필요한 성능을 만족시킬 수 있을 뿐만 아니라 목표 성능에 맞게 인공신경망을 유연하게 설계할 수 있는 인공신경망 연산 가속화 장치, 가속화 시스템, 및 그 가속화 방법을 제공하는 효과가 있다. 또한, 본 발명은, 저전력/저비용의 집적회로로 구성되는 다수의 가속화 장치를 연결하여 신경망 연산을 수행하 게 함으로써 종래기술에 따라 단일의 하드웨어로 구현되는 고가의 GPGPU를 사용하는 것에 비해 제조비용을 절감 할 수 있으며 저전력을 필요로 하는 분야에 적용할 수 있는 효과가 있다. 또한, 본 발명은, 집적회로의 종류에 관계없이 통신중개가 가능한 범용 통신중개블럭을 가속화 장치에 구현함으 로써 동일한 기종이나 이기종으로 구성된 집적회로로 구현되는 가속화 시스템에 추가적인 기능을 유연하게 적용 할 수 있어 사용자의 다양한 요구에 능동적으로 대처할 수 있는 효과가 있다. 또한, 본 발명은, 다중 가속화 장치를 이용하여 인공 신경망을 분산 병렬 처리함으로써 목표성능에 맞게 유연하 게 가속화장치를 확장하거나 축소할 수 있는 효과가 있다. 또한, 본 발명은, 인공신경망을 구성하는 뉴런들에 대한 입력데이터와 시냅스 가중치를 입력데이터를 구성하는 깊이, 계층구조, 신경망 네트워크 또는 이들의 조합 단위로 나누어 각각의 가속화장치에서 연산이 가능하게 함 으로서 하드웨어로 구현하는 경우에 메모리 및 주변장치를 최적화할 수 있어 결과적으로 제품의 개발단가를 낮 출 수 있는 효과가 있다. 또한, 본 발명은, 다양한 종류의 집적회로를 이용해 가속화 시스템을 구현함으로써 미래에 적용될 다양한 형태 의 인공신경망 구조에서도 능동적으로 활용이 가능한 효과가 있다."}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 한편, 본 발명에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 발명에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하기로 한다. 도 1은 본 발명의 실시예가 적용된 입력층과 은닉층과 출력층을 포함하는 인경신경망 모델을 개략적으로 나타내 는 개념도이다. 도면에 도시된 바와 같이, 도 1의 인공신경망 모델은 입력층(Input Layer), 복수개의 은닉층(Hidden Layer), 출 력층(Ouput Layer)을 포함하는 계층구조로 구성되어 있다. 여기서, 각 층의 원은 뉴런(Neuron)이라 부르며, 각 뉴런에서 다음 층의 뉴런으로 연결된 화살표는 시냅스 (Synapse)라 하여 뉴런 간 연결을 의미한다. 예를 들어, x1은 입력층의 뉴런 중 하나를 나타내고, a1은 은닉층-1의 뉴런 중 하나를 나타낸다. 한편, 도 1의 신경망 모델을 수학적으로 표현하기 위해 A는 연산결과, W는 가중치(Weight), X는 입력(Input), 그리고 B는 편향(Bias) 이라 할 때, 아래의 [수학식 1]로 각각 표현될 수 있다.[수학식 1]"}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, [수학식 1]을 행렬의 내적을 이용하여 수식으로 간소화하여 표현하면 아래의 [수학식 2]로 표현될 수 있 다. [수학식 2]"}
{"patent_id": "10-2019-0007723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 2는 도 1에 도시된 인공신경망을 확장한 심층 신경망을 개략적으로 나타내는 도면이다. 도 2에 도시된 바와 같이, 은닉층이 2개 이상인 인공신경망을 심층신경망이라 한다. 본 발명의 실시예에 적용된 인공신경망은 영상분야에 주로 적용되는 심층 신경망으로 구성되며, 일반적으로는 입력 뉴런들에 대한 데이터가 영상의 특징을 활용하는 벡터 형태의 다차원(N-Tensor)에 해당하는 특징맵으로 간 소화하여 표현될 수 있다. 즉, 도면에 도시된 바와 같이, 본 발명의 실시예에서, 각각의 층을 구성하는 특징맵은 Width, Height, Depth 로 이루어진 차원으로 표현할 수 있으며, 이때, Depth는 Width와 Height로 이루어진 차원을 확장한 것을 나타내는 것으로 본 명세서에서는 '깊이'라는 용어로 확장된 차원을 Depth로 수치화 하여 나타낼 수 있다. 보다 구체적으로는,'깊이'는 본 발명의 실시예가 적용된 컨볼루션 신경망(ConvNet; Convolutional Neural Network)에서 차원의 확장을 다룰 때 사용하며, 일반 신경망에서는, 예를 들어 영상을 표현할 때 영상의 형태가 일반적인 RGB(Red, Green, Blue)인 경우 224×224×3(가로,세로,컬러 채널)로 표현되고 이는 컨볼루션 신경망의 가로, 세로, 깊이에 각각 대응되며, 깊이 대신 채널이란 용어로 사용될 수 있다. 즉, 본 발명의 실시예에 따른 컨볼루션 신경망은 입력이 영상 일때 각각의 레이어가 가로, 세로, 깊이의 3개 차 원을 갖게 되며, 여기서, 깊이는 전체 신경망의 깊이가 아니라 입력 뉴런들에 대한 데이터에 해당하는 액티베이 션 볼륨(Activation Volume)에서의 3번째 차원을 이야기 할 수 있다. 또한, 도 2에 도시된 각각의 계층 사이에 표시된 화살표는 각 층의 연산결과를 인접한 다음 층의 입력으로 전달 하는 것을 간소화하여 표현한 것이다. 여기서, Layer N은 전결합층(Fully Connected Layer)을 표현한 것으로 이전 층의 차원을 1차원으로 재구성한 입 력에 대한 출력으로 [input, output]의 차원으로 표현할 수 있고, 출력층(Output Layer)의 출력은 최종 연산결 과로 사용될 수 있다. 도 3은 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치의 집적회로 구성을 개략적으로 나타 내는 블럭도이다. 도 3의 가속화 장치는, 본 발명의 핵심 아이디어인 인공신경망의 분산처리를 구현하기 위한 장치로서, 입력 뉴 런들이 계층적으로 구성되어 형성된 인공 신경망의 입력데이터와 시냅스 가중치에 대한 연산을 분산하여 처리할 수 있으며, 후술하는 범용 통신중개블럭을 구비하여 집적회로의 종류에 상관없이 연결이 가능하기 때문에 FPGA 또는 SoC 방식의 다양한 집적회로를 상호간에 서로 연결할 수 있어 요구되는 성능에 따라 유연한 설계가 가능하다. 도면을 참조하여 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치를 상세하게 설명하면 다음 과 같다. 도면에 도시된 바와 같이, 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치는, 플래쉬 메 모리, 외부 메인 메모리, 내부 버퍼 메모리, DMA모듈, 신경망 연산장치, CPU, 데이터 입력장치, 및 통신중개블럭을 구비할 수 있다.보다 상세하게는, 상기 플래쉬 메모리는, SD(Secure Digital)카드와 같은 비휘발성 메모리로 구성되며, 본 발명의 실시예에 따른 인공신경망 연산에 필요한 시냅스 가중치 전체가 저장되어 가속화 장치에 전원이 인가되 면 CPU의 동작제어신호에 의해 상기 DMA모듈을 거쳐 상기 외부 메인 메모리에 전달될 수 있다. 또한, 상기 외부 메인 메모리는, 본 발명의 실시예에 따른 인공신경망 연산을 수행하기 위하여 상기 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 운영체제의 관리하에 저장할 수 있는 범용 저장 수단으로서, DDR- SDRAM(Dual Data Rate SDRAM)과 같은 휘발성 메모리로 구성되어 가속화장치에 전원이 인가되는 경우에만 사용할 수 있으며, 본 명세서에서 '외부 메모리'라고 기재되는 경우에는 외부 메인 메모리를 가리킬 수 있다. 한편, 도면에 도시된 바와 같이, 상기 플래쉬 메모리와 상기 외부 메인 메모리에 데이터를 쓰거나 읽기 위한 제어로직을 갖는 메모리 인터페이스를 구비할 수 있다. 또한, 상기 내부 버퍼 메모리는, 상기 외부 메인 메모리에 저장된 시냅스 가중치와 입력데이터 중 상기 인공 신경망 연산을 구성하는 각각의 사이클마다 필요한 시냅스 가중치와 입력데이터를 버퍼와 같이 임시로 저 장하기 위한 수단으로 사용되며, 구성되는 저장용량에 따라 상기 외부 메인 메모리에 저장된 입력데이터와 시냅스 가중치 중 전체 또는 일부를 저장할 수 있다. 또한, 상기 DMA모듈은, 상기 외부 메인 메모리 및 내부 버퍼 메모리와 데이터를 직접 송수신 하기 위한 구성으로서, 주변장치들이 메모리에 직접 접근하여 쓰기 또는 읽기 기능을 수행할 수 있는 DMA(Direct Memory Access)기능을 지원할 수 있다. 여기서, 본 발명의 실시예에 적용된 상기 DMA모듈을 더욱 구체적으로 설명하면, 예를 들어, 후술하는 CPU와 같은 중앙처리장치가 상대적으로 처리속도가 느린 주변장치와 데이터를 읽고/쓰기가 완료될 때 까지 다른 동작을 하지 못하고 대기하는 것을 회피하여 하드웨어 연산자원활용을 높이려는 목적으로 데이터의 일고/ 쓰기를 대신하는 것을 목적으로 사용될 수 있다. 특히, 본 발명의 실시예에서는, 앞서 상술한 바와 같이, '1) 외부 플래쉬 메모리에 저장된 가중치를 외부 메인 메모리에 저장 2) 외부 메인 메모리에 저장된 가중치 및 입력 데이터를 내부 버퍼 메모리에 저장 3)외부 메인 메모리에 저장된 연산결과를 후술하는 범용통신중개블럭과 같은 주변장치 인터페이스를 통해 다른 가속화 장치로 전달 4)후술하는 신경망 연산장치의 연산결과를 외부 메인 메모리에 저장 5)후술하는 데이터 입력장치와 같은 주변장치의 입력데이터를 외부 메인 메모리에 저장 6)후술한 범용통신중개블럭을 기반으로 하는 가속화 장치의 외부 메인 메모리에 저장된 연산결과를 다 른 가속화 장치의 외부 메인 메모리에 입력데이터로 전달하여 저장 ' 과 같은 목적으로 사용될 수 있다. 또한, 상기 신경망 연산장치는, 상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들 여 인공 신경망 연산을 수행한 다음 연산 결과를 상기 외부 메인 메모리에 저장하는 일련의 순차적인 과정 을 인공 신경망 연산을 구성하는 각각의 사이클마다 반복적으로 처리할 수 있다. 또한, 상기 CPU는, 상기 외부 메인 메모리와 내부 버퍼 메모리에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 저장시키는 동작과 상기 신경망 연산장치의 동작을 제어하는 것을 포함하여, 가속화장치의 중앙처리장치로 동작할 수 있다. 또한, 상기 데이터 입력장치는, 센서인터페이스 또는 Peripheral로 구성되는 데이터 입력수단으로서, 본 발 명의 실시예에서와 같이 입력데이터가 영상일 경우에 (영상)센서인터페이스를 이용하여 카메라로부터 영상 데이 터를 입력받아 상기 외부 메인 메모리에 저장하는 역할을 수행할 수 있다. 또한, 상기 범용 통신중개블록은, 상기 입력 뉴런들에 대한 입력데이터와 시냅스 가중치, 및 상기 신경망 연산장치에서 수행한 연산결과를 집적회로의 종류에 관계없이 물리적으로 연결되는 다른 가속화 장치와 송 수신할 수 있다. 이때, 상기 범용 통신중개블록은, 다른 가속화 장치와 어드레스, 데이터, 그리고, 제어신호를 송수신하는 역할을 수행할 수 있으며, 물리적으로 연결되는 가속화 장치를 구성하는 집적회로의 종류가 SoC(System on Chip)또는 FPGA(Field Programmable Gate Array)일 경우 모두 통신중개가 가능하게 형성될 수 있다. 한편, 본 발명의 실시예에 따르면, 가속화 장치의 집적회로 상의 각 요소간 통신을 위한 버스프로토콜은 업 계 표준인 AMBA(Advanced Microcontroller Bus Architecture)인 것이 바람직하며, 이에 따라, 상기 범용 통신 중개블록은 AXI(Advanced Extensible Interface) 또는 AHB(Advanced High Performance Bus) 신호를 받아 가속화 장치간의 통신 입출력 인터페이스 신호로 전환하는 기능을 수행할 수 있다. 도 4를 참조하여 본 발명의 실시예에 따른 가속화 장치에 구비된 범용 통신중개블록를 더욱 상세하게 설명하면 다음과 같다. 도 4는 도 3에 도시된 가속화 장치를 구성하는 범용 통신중개블럭의 세부구성을 나타내는 도면이다. 도면에 도시된 바와 같이, 본 발명의 실시예에 따른 가속화 장치를 구성하는 범용 통신중개블럭은, 리맵핑 블럭, 버스제어신호 매칭블럭, 모니터 블럭, 및 송수신 인터페이스에 해당하는 송신모듈과 수신모듈을 구비할 수 있다. 본 발명의 실시예에 따르면, 물리적으로 연결되는 복수개의 가속화 장치는 범용 통신중개블럭을 통해 버스 제어신호(Bus Control Signal: Bus ID, Burst, Size, R/W...), 버스 어드레스 신호(Bus Address Signal), 버스 데이터 신호(Bus Data Signal)가 송수신 되고, 프로세서에서 생성된 메시지와 인터럽트 신호가 전달될 수 있다. 여기서, 상기 리맵핑 블럭은, 가속화 장치의 송신용 집적회로와 연결된 버스 마스터 인터페이스로부터 인 가되는 신호들 중 수신용 집적회로의 구성요소를 지정하는 어드레스와 버스 ID신호의 폭을 약속에 따라 리맵핑 하는 역할을 수행할 수 있다. 보다 상세하게 설명하면, 각각의 가속화 장치를 구성하는 집적회로가 적용하고 있는 내부 구성요소들의 어드레 스는 서로 다른데, 이러한 차이점을 감안하지 않고 임의의 가속화장치(송신측)가 외부의 다른 장치(수신측)의 특정 영역의 어드레스에 있는 기능블록에 접근하고자 하면, 어드레스의 충돌로 인해 목표 영역으로 접근할 수 없게 될 것은 당연하다. 예를 들어, DDR, Flash, CPU 및 Video Codec에 할당된 고유의 어드레스는 각각의 가속 화장치에서 서로 다르다. 따라서 정상적인 통신을 위해서는 미리 어드레스의 리맵핑에 대한 약속이 있어야 할 것이다. 또한, 상기 리맵핑블럭은, 버스 마스터 인터페이스로부터 인가되는 버스 ID 신호와 이웃하는 장치(수신 측)의 버스 ID 신호의 폭(Width)을 일치시키는 버스 ID 리맵핑을 수행할 수 있다. 여기서, AXI 버스 표준은 어드레스 채널과 데이터 채널이 독립적으로 분리되어 있기 때문에, 수치적인 액세스 방식으로는 어드레스와 데이터의 연결이 불가능하므로, 버스 ID를 이용하여 어드레스-데이터 짝을 맞추게 된다. 이러한 버스 ID의 이용으로 인해 버스 층의 구성마다 버스 ID 폭(Bus ID width)이 다를 수 있는데, 서로 다른 칩은 각기 다른 버스 시스템으로 구성되어 있으며, 이러한 버스 구성의 차이는 버스 ID 폭의 차이로 귀결된다. 따라서 서로 다른 칩의 버스 간 통신을 위해서는 버스 ID 폭을 일치시켜 야 하는데, 여기서 일치시킨다는 의미는 필요에 따라 버스 ID 폭을 확장하거나 축소하는 것을 의미하며, 어드레 스 리맵핑과 마찬가지로, 버스 ID 폭은 서로 약속이 되어 있어야 할 것다. 따라서, 어드레스와 버스 ID신호의 폭을 일치시키는 리맵핑을 수행할 때 참조하는 리맵핑 약속테이블이 리맵핑 블록에 포함되어 있는 것이 바람직하다. 또한, 본 발명의 실시예에서, 상기 버스제어신호 매칭블럭은, 버스 마스터 인터페이스로부터 인가되는 신 호 중 버스제어신호(Bus Control Signal)의 패턴을 분석하여 바로 이전에 인가된 버스제어신호와 이어지는 순서 로 인가되는 버스제어신호가 동일할 경우, 이전의 버스제어신호를 재사용하도록 할 수 있으며, 이로 인해, 버스 제어신호가 동일할 경우에 재사용하게 함으로써 가속화 장치 사이의 통신 인터페이스의 I/O 핀 사용률을 극대화 하여 결과적으로 통신 속도를 최대한으로 향상시킬 수 있다. 게다가, 본 발명의 실시예에 따르면, 상기 모니터 블럭은, 프로세서 인터페이스로부터 인가되는 메시지 (Message)와 인터럽트 인터페이스로부터 인가되는 모든 인터럽트 신호(Interrupt)를 모니터 할 수 있으며, 이를 이용해 가속화 장치 사이에서 어드레스 신호 및 데이터를 전달할 때 메시지와 인터럽트 신호를 포함하여 전달함 으로써 인터럽트 신호와 프로세서의 메시지가 최우선으로 전송되게 할 수 있어 통신 효율을 극대화 할 수 있다. 도 2 내지 도 4를 참조하여, 단일의 집적회로로 구성되는 분산처리용 인공신경망 연산 가속화 장치를 이용해 입 력층과 N개의 은닉층을 포함하여 계층구조를 갖는 도 2에 도시된 인공신경망 모델에 대한 신경망 처리를 가속화 하는 방법을 설명하면 다음과 같다. 먼저, 가속화 장치에 전원이 인가되면, CPU의 제어신호에 의해 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 외부 메인 메모리에 저장하는 단계(a1)를 수행한 다. 다음으로, 데이터 입력장치를 통해 입력되는 최초 입력데이터를 외부 메인 메모리에 저장하는 단계(a 2)를 수행한다. 여기서, 본 발명의 실시예에서와 같이 입력데이터가 영상인 경우에 카메라로부터 입력받은 영상 데이터는 DMA모듈을 거쳐 저장되게 할 수 있다. 다음으로, 상기 외부 메인 메모리에 저장된 입력데이터와 상기 입력데이터에 대응되는 시냅스 가중치를 인 공신경망의 입력층을 구성하는 각각의 사이클에 필요한 만큼 내부 버퍼 메모리에 저장하는 단계(a3)를 수행할 수 있다. 이때, 인공신경망의 크기에 따라 가중치 및 입력데이터는 전체 또는 일부가 저장될 수 있다. 다음으로, 신경망 연산장치가 상기 인공신경망을 구성하는 각각의 사이클에 대응되어 상기 내부 버퍼 메모 리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 층 전체에 대한 연산이 완료될 때 까지 인공 신경망 연산을 수행하고 그 연산 결과를 다음층의 입력데이터로 사용하기 위해 외부 메인 메모리에 저장하는 단계 (a4)를 수행할 수 있다. 여기서, 연산에 필요한 가중치 및 입력데이터가 내부 메모리에 저장되면 CPU는 연산 시작명령어를 신경망 연산장치에 전달하고, 신경망 연산장치는 가중치 및 입력데이터를 버스를 통하지 않고 직접적으로 내부 버퍼 메모리에서 읽어와 연산을 수행할 수 있다. 이때, 신경망의 입력 데이터 및 가중치 전체를 내부 메모 리에 저장할 수 없는 경우에는 일부를 내부 메모리에 저장하고 연산하는 과정을 층전체에 대한 연산이 완료 될까지 반복할 수 있다. 다음으로, 입력층에 대한 연산결과가 외부 메인 메모리에 저장되면, 은닉층에 대한 인공 신경망 연산을 위 한 입력 뉴런들에 대한 시냅스 가중치와 입력 데이터를 각각의 사이클에 필요한 만큼 상기 외부 메인 메모리 로부터 읽어 내부 버퍼 메모리에 저장한 다음 상기 a4단계를 수행하는 과정을 N개의 은닉층에 대하여 반복 적으로 수행(a5)할 수 있다. 도 5는 본 발명의 실시예에 따라 입력데이터가 복수개의 깊이를 갖는 인공 신경망 연산을 처리하기 위한 가속화 시스템의 다중 집적회로 구성을 개략적으로 나타내는 블럭도이다. 도 5에 도시된 바와 같이, 본 발명의 실시예에 따른 입력 뉴런들에 대한 입력데이터가 복수개의 깊이를 갖는 인 공 신경망 연산을 처리하기 위한 가속화 시스템은, 단일의 호스트 가속화 장치, 및 복수개의 슬레이 브 가속화 장치를 구비할 수 있다. 보다 상세하게는, 상기 호스트 가속화 장치는, 상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저 장된 플래시 메모리와 연결되며, 호스트용 통신중개블록을 상기 복수개의 깊이 갯수 이상으로 구비할 수 있다. 또한, 상기 슬레이브 가속화 장치는, 상기 호스트 가속화 장치의 호스트용 통신중개블럭에 물리 적으로 연결되는 슬레이브용 통신중개블록을 각각 하나 이상 구비하며, 상기 복수개의 깊이 갯수에 일대일 대응되게 복수개 형성될 수 있다. 이때, 상기 호스트 가속화 장치는, 상기 복수개의 깊이 각각에 관련되는 슬레이브 가속화 장치에 시 냅스 가중치와 입력데이터를 병렬방식으로 분산시켜 인공 신경망 연산을 처리하게 하고, 상기 슬레이브 가속화 장치의 중간연산결과를 취합하여 최종 연산을 수행할 수 있다. 본 발명의 실시예에서, 상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록은, 도 4에서 상 술한 범용 통신중개블록과 동일한 구성을 갖는 것이 바람직하며, 이에 대한 상세한 설명은 생락하기로 한 다. 또한, 본 발명의 실시예에서, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, SoC방 식 및 FPGA방식 중 어느 한 가지 방식의 집적회로로 구성될 수 있으며, 집적회로의 종류에 관계없이 상기 호스 트용 통신중개블록과 상기 슬레이브용 통신중개블록(2020을 통해 상호간에 서로 송수신이 가능할 수 있다. 게다가, 도면에 도시된 바와 같이, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, 외부 메인 메모리(211,221), 내부 버퍼 메모리(212,222), DMA모듈(213, 223), 신경망 연산장치(214,224), 및 CPU(215, 225)를 구비할 수 있으며, 도 3에 도시된 구성과 동일한 구성에 대한 상세한 설명은 생략하기로 한다. 다음으로, 도 6과 도 7을 참조하여, 도 5에 도시된 가속화 시스템의 실시예들을 설명하기로 한다. 도 6은 도 5에 도시된 가속화 시스템의 일실시예에 따른 인공신경망을 개략적으로 나타내는 도면으로서, 입력데 이터를 구성하는 특징맵의 차원을 A,B,C 세 개의 깊이로 분산하여 처리하는 인공 신경망 모델을 도식화 한 것이다. 도 6에 도시된 인공신경망 모델을 도 5에 도시된 가속화 시스템으로 구현하는 과정을 설명하면 다음과 같다. 먼저, 단일의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치에 전원이 인가되어, 모든 가속화 장치가 연산을 위한 준비상태가 완료되면, 호스트 가속화 장치와 연결된 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(b1)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치가 범용 통신중개블록(201,202)을 통해 상기 호스트 가속화 장치 의 외부 메인 메모리에 저장된 시냅스 가중치 중 A,B,C 세 개의 깊이에 대응되는 각각의 시냅스 가중치를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 병렬방식으로 순차적으로 전달하여 저 장하는 단계(b2)를 수행할 수 있다. 다음으로, 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 저장된 시냅스 가중치 중 인공신경망의 입력층을 구성하는 각각의 사이클에 필요한 시냅스 가중치를 상기 각 슬레이브 가속화 장치 의 내부 버퍼 메모리에 저장하는 단계(b3)를 수행할 수 있다. 다음으로, 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 최초 입력데이터를 상 기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(b4)를 수행할 수 있으며, 본 발명의 실 시예에서는 영상데이터일 경우에 센서인페이스를 통해 입력을 받으며, 다른 주변장치로부터 Peripheral을 통해 입력받을 수 있다. 다음으로, 상기 호스트 가속화 장치가 범용 통신중개블록(201,202)을 통해 상기 호스트 가속화 장치 의 외부 메인 메모리에 저장된 입력데이터 중 상기 A,B,C 세 개의 깊이에 대응되는 각각의 입력데이터를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 병렬방식으로 순차적으로 전달하여 저 장하는 단계(b5)를 수행할 수 있다. 다음으로, 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장된 입력데이터를 상기 인공신 경망을 구성하는 각각의 사이클에 필요한 만큼 상기 각각의 슬레이브 가속화 장치 내부 버퍼 메모리 에 저장하는 단계(b6)를 수행할 수 있다. 다음으로, 상기 슬레이브 가속화 장치 각각의 신경망 연산장치가 상기 인공신경망을 구성하는 각각의 사이클에 대응되어 상기 슬레이브 가속화 장치 각각의 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 층 전체에 대한 연산이 완료될 때 까지 인공 신경망 연산을 수행하고 그 연산 결과를 상 기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장하는 단계(b7)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치가 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장된 중간연산결과를 수신하여 상기 호스트 가속화 장치의 외부 메인 메모리에 순차적으로 저장한 다음 취합하여 층 전체에 대한 최종연산을 수행하고 최종연산결과를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(b8)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 최종연산결과를 다음층의 연산을 위한 입력데이터로 사용하기 위하여 상기 세 개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 세 개의 깊이에 대응되게 병렬방식으로 순차적으로 전달하여 저장하는 단계(b9)를 수행할 수 있다. 다음으로, 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 저장된 시냅스 가중치 중 다음층을 구 성하는 각각의 사이클에 필요한 시냅스 가중치를 상기 각 슬레이브 가속화 장치의 내부 버퍼 메모리에 저장하는 단계(b10)를 수행할 수 있다. 마지막으로, 입력 데이터에 대한 모든 계층의 연산이 완료 될 때까지 상기 b6 단계 내지 b10 단계를 반복적으 로 수행하는 단계(b11)를 수행할 수 있다.도 7은 도 5에 도시된 가속화 시스템의 다른 실시예에 따른 인공신경망을 개략적으로 나타내는 도면이다. 도 7은 도 5에 도시된 가속화 시스템의 다른 실시예에 따른 인공신경망을 개략적으로 나타내는 도면으로서, 입 력데이터를 구성하는 특징맵의 차원을 논리적으로 입력층과 출력층을 제외화고 독립적으로 A,B 두 개의 깊이로 분산하여 병렬처리하는 AlexNet 에 해당하는 인공 신경망 모델을 도식화 한 것이다. 이와 같이, 인공신경망이 독립적으로 분리되면 각 입력층과 출력층을 제외한 나머지 출력층에 대한 중간 연산 결과를 매층의 연산마다 호스트 가속화 장치로 전송하고 취합 및 후처리를 할 필요가 없기 때문에, 도 6에 도시 된 모델과 비교했을 때, 가속화장치사이의 데이터 전송시간을 회피할 수 있어 최적의 분산처리 방법을 제공할 수 있다. 도 7에 도시된 인공신경망 모델을 도 5에 도시된 가속화 시스템으로 구현하는 과정을 설명하면 다음과 같다. 먼저, 단일의 호스트 가속화 장치와 A,B 두 개의 슬레이브 가속화 장치에 전원이 인가되면 외부 플래 시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(c1)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치가 범용 통신중개블록(201,202)을 통해 상기 호스트 가속화 장치 의 외부 메인 메모리에 저장된 시냅스 가중치 중 상기 두 개의 깊이에 대응되는 각각의 시냅스 가중치를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 병렬방식으로 순차적으로 전달하여 저 장하는 단계(c2)를 수행할 수 있다. 다음으로, 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 저장된 시냅스 가중치 중 인공신경망의 입력층을 구성하는 각각의 사이클에 필요한 시냅스 가중치를 상기 각 슬레이브 가속화 장치 의 내부 버퍼 메모리에 저장하는 단계(c3)를 수행할 수 있다. 다음으로, 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 최초 입력데이터를 상 기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(c4)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치가 외부 메인 메모리에 저장된 입력데이터와 시냅스 가중치 중 신 경망의 입력층을 구성하는 사이클에 필요한 만큼 내부 버퍼 메모리에 저장하고, 신경망 연산장치를 이용해 입력층에 대한 신경망 연산을 수행한 다음 그 연산결과를 다음층의 입력데이터로 사용하기 위해 외부 메 인 메모리에 저장하는 단계(c5)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치가 범용 통신중개블록(201,202)을 통해 상기 호스트 가속화 장치 의 외부 메인 메모리에 저장된 입력데이터(연산결과) 중 상기 복수개의 깊이에 대응되는 각각의 입력데이 터(연산결과)를 상기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 병렬방식으로 순차적 으로 전달하여 저장하는 단계(c6)를 수행할 수 있다. 다음으로, 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장된 입력데이터(입력층의 연산 결과)와 그에 해당하는 시냅스 가중치를 상기 인공신경망을 구성하는 각각의 사이클에 필요한 만큼 상기 각각의 슬레이브 가속화 장치 내부 버퍼 메모리에 저장하는 단계(c7)를 수행할 수 있다. 다음으로, 상기 슬레이브 가속화 장치 각각의 신경망 연산장치가 상기 인공신경망을 구성하는 각각의 사이클에 대응되어 상기 슬레이브 가속화 장치 각각의 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 반복적으로 읽어들여 인공신경망을 구성하는 계층 전체에 대한 연산이 완료될 때 까지 인공 신경 망 연산을 반복적으로 수행하고 그 연산 결과를 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리(22 1)에 저장하는 단계(c8)를 수행할 수 있다. 마지막으로, 상기 호스트 가속화 장치가 상기 슬레이브 가속화 장치 각각의 외부 메인 메모리에 저장된 중간연산결과를 수신하여 상기 호스트 가속화 장치의 외부 메인 메모리에 순차적으로 저장한 다음 취합하여 신경망 전체에 대한 최종연산을 수행하고 최종연산결과를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(c9);를 수행할 수 있다. 이와 같이, 본 발명은, 입력 뉴런들에 대한 입력데이터가 복수개의 깊이를 갖는 인공신경망의 가속화 방법에 있 어서, 상기 복수개의 깊이에 대응되는 각각의 가속화장치에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 분산하여 처리할 수 있다. 도 8은 본 발명의 실시예에 따라 입력 뉴런들이 복수개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템의 다중 집적회로 구성을 개략적으로 나타내는 블럭도이다. 도면에 도시된 바와 같이, 본 발명의 실시예에 따른 입력 뉴런들이 복수개의 계층으로 구성되는 인공 신경망 연 산을 처리하기 위한 가속화 시스템은, 호스트 가속화 장치, 및 복수개의 슬레이브 가속화 장치 을 구비할 수 있다. 보다 상세하게는, 상기 호스트 가속화 장치는, 상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저 장된 플래시 메모리와 연결되며 호스트용 통신중개블록을 송수신용으로 한 쌍 이상 구비할 수 있다. 또한, 상기 슬레이브 가속화 장치는, 상기 호스트 가속화 장치와 전체적으로 파이프라인 형태가 되게 순차적으로 연결되기 위하여 슬레이브용 통신중개블록을 송수신용으로 한 쌍 이상 구비하며 복수개 형성될 수 있다. 따라서, 본 발명의 실시예에 따른 입력 뉴런들이 복수개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위 한 가속화 시스템은, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치에 상기 인공 신경 망 연산을 구성하는 입력 뉴런들에 대한 시냅스 가중치와 입력데이터를 순차적으로 분산시켜 인공 신경망 연산 을 처리하게 할 수 있다. 또한, 본 발명의 실시예에서, 상기 호스트용 통신중개블록과 상기 슬레이브용 통신중개블록은, 도 4 에서 상술한 범용 통신중개블록과 동일한 구성을 갖는 것이 바람직하며, 이에 대한 상세한 설명은 생락하 기로 한다. 또한, 본 발명의 실시예에서, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, SoC방 식 및 FPGA방식 중 어느 한 가지 방식의 집적회로로 구성될 수 있으며, 집적회로의 종류에 관계없이 상기 호스 트용 통신중개블록과 상기 슬레이브용 통신중개블록을 통해 상호간에 서로 송수신이 가능할 수 있다. 게다가, 도면에 도시된 바와 같이, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, 외부 메인 메모리(311,321), 내부 버퍼 메모리(312,322), DMA모듈(313, 323), 신경망 연산장치(314,324), 및 CPU(315, 325)를 구비할 수 있으며, 도 3에 도시된 구성과 동일한 구성에 대한 상세한 설명은 생략하기로 한다. 도 9는 도 8에 도시된 가속화 시스템의 실시예에 따른 인공신경망 모델을 개략적으로 나타내는 도면이다. 도 9에 도시된 인공신경망 모델을 도 8에 도시된 가속화 시스템으로 구현하는 과정을 설명하기 위하여 도 8에서 상술한 인공신경망 시스템을 이용하여 단일의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치의 연결구조 가 전체적으로 파이프라인 형태가 되게 순차적으로 배치할 수 있다. 먼저, 본 발명의 실시예에 따라 계층구조를 갖는 인공신경망 처리를 가속화 하는 방법은, 단일의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치에 전원이 인가되면 외부 플래시 메모리에 저장된 인공 신 경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 상기 호스트 가속화 장치의 외부 메인 메모리 에 저장하는 단계(d1)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치가 범용 통신중개블록(301,302)을 통해 상기 호스트 가속화 장치 의 외부 메인 메모리에 저장된 시냅스 가중치 중 상기 N개의 계층에 대응되는 각각의 시냅스 가중치를 상 기 복수개의 슬레이브 가속화 장치의 각 외부 메인 메모리에 순차적으로 전달하여 저장하는 단계(d 2)를 수행할 수 있다. 다음으로, 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 입력층의 입력데이터 를 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(d3)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 입력층의 입력데이터와 시냅스 가 중치를 내부 버퍼 메모리에 저장하는 단계(d4)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치의 신경망연산 장치에 의해 상기 내부 버퍼 메모리에 저장된 시냅스 가중치와 입력데이터를 읽어들여 입력층에 대한 신경망 연산을 수행하고 상기 외부 메인 메모리에 연산결과를 저장하는 단계(d5)를 수행할 수 있다. 다음으로, 다음층에 해당하는 슬레이브 가속화 장치의 외부 메인 메모리에 연산결과를 입력데이터로 저장한 다음, 상기 슬레이브 가속화 장치의 내부 버퍼 메모리에 해당층에 대응되는 입력데이터와 시 냅스 가중치를 저장하는 단계(d6)를 수행할 수 있다.다음으로, 상기 슬레이브 가속화 장치의 신견망연산장치에 의해 내부 버퍼 메모리에 저장된 시 냅스 가중치와 입력데이터를 읽어들여 해당층에 대한 신경망 연산을 수행하고 연산결과를 외부 메인 메모리 에 저장하는 단계(d7)를 수행할 수 있다. 다음으로, N개의 은닉층에 대하여 상기 d6 내지 d7단계를 반복적으로 수행하고 최종 연산 결과는 상기 호스트 가속화 장치의 외부 메인 메모리에 저장하거나 주변장치에 전달하는 단계(d8)를 수행할 수 있다. 한편, 본 발명의 실시예에 따르면, N개의 계층을 갖는 신경망을 분산하여 처리하는 경우에는 N개층을 슬레이브 의 수로 나누거나 각 계층의 연산량에 비례하여 슬레이브에 독립적으로 할 당할 수 있다. 이와 같이, 계층별로 분산하여 각각의 층별로 가속화장치가 할당이 되면 파이프라인화가 가능하여 연속적인 스 트림 입력에 대해 연산의 효율성이 높아지는 효과가 있다. 따라서, 본 발명은, 입력 뉴런들이 복수개의 계층구조로 구성되는 인공신경망의 가속화 방법에 있어서, 상기 복 수개의 계층에 대응되는 각각의 가속화장치에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 분산하여 처리 하는 방법을 제공할 수 있다. 도 10은 복수(M)개의 깊이와 복수(N)개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템 의 다중 집적회로 구성을 개략적으로 나타내는 블럭도이다. 도면에 도시된 바와 같이, 본 발명의 실시예에 따라 입력 뉴런들에 대한 입력데이터가 복수(M)개의 깊이와 복수 (N)개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템은, 호스트 가속화 장치와 복 수개의 슬레이브 가속화 장치을 포함할 수 있다. 보다 상세하게는, 상기 호스트 가속화 장치는 상기 인공 신경망 연산에 필요한 전체 시냅스 가중치가 저장 된 플래시 메모리(미도시)와 연결되며 호스트용 통신중개블록(미도시)을 상기 복수(N)개의 계층 수 이상으로 구 비할 수 있다. 또한, 상기 슬레이브 가속화 장치는, 상기 호스트 가속화 장치의 호스트용 통신중개블럭과 연결되거 나 다른 가속화 장치와 연결되기 위한 슬레이브용 통신중개블록을 하나 이상 구비하고, 상기 복수(M)개의 깊이 및 복수(N)개의 계층에 필요한 신경망 연산 사이클 수(M×N)와 일대일 대응되는 복수개로 형성될 수 있다. 또한, 본 발명의 실시예에서, 상기 호스트용 통신중개블록)과 상기 슬레이브용 통신중개블록은, 도 4에서 상술한 범용 통신중개블록과 동일한 구성을 갖는 것이 바람직하며, 이에 대한 상세한 설명은 생락하기로 한다. 또한, 본 발명의 실시예에서, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, SoC방 식 및 FPGA방식 중 어느 한 가지 방식의 집적회로로 구성될 수 있으며, 집적회로의 종류에 관계없이 상기 호스 트용 통신중개블록과 상기 슬레이브용 통신중개블록을 통해 상호간에 서로 송수신이 가능할 수 있다. 게다가, 도면에 도시된 바와 같이, 상기 호스트 가속화 장치와 상기 슬레이브 가속화 장치는 각각, 외부 메인 메모리, 내부 버퍼 메모리, DMA모듈, 신경망 연산장치, 및 CPU를 구비할 수 있으며, 도 3에 도시된 구성과 동일한 구성에 대한 상세한 설명은 생략하기로 한다. 도면에 도시된 바와 같이, 인공 신경망의 입력뉴런들에 대한 데이터의 깊이와 계층수가 많을 경우에 단일 또는 소수의 가속화 장치로는 요구되는 목표성능을 만족시키기 어려울 수 있다. 이와 같은 경우에는, 앞서 상술한 도 5 내지 도 9의 깊이 분산방법과 계층분산방법을 동시에 적용하여 본 발명 에 따른 가속화 장치로 최대한 분산시켜 독립적으로 연산하게 함으로써 연산 성능을 높일 수 있다. 이때, 도면에 도시된 바와 같이, 상기 호스트 가속화 장치는, 인공신경망 연산을 위한 가중치와 입력데이 터를 각각의 계층을 구성하는 슬레이브 가속화 장치의 상위 입력단에 전달하고, 모든 연산이 완료되면 최 종 연산 결과를 슬레이브 가속화 장치의 마지막 계층에서 전달 받는다. 도면을 참조하면, 슬레이브 가속화 장치의 L은 할당된 계층을 의미하고 이것의 수를 1~N으로 표현할 수 있 으며, D는 할당된 깊이(또는 Depth)을 의미하고 이것의 수를 1~M으로 표현할 수 있다. 도 11은 도 10에 도시된 가속화 시스템의 실시예에 따른 인공신경망 모델을 개략적으로 나타내는 도면이다. 도 11을 참조하여 도 10의 가속화 시스템을 설명하면, 입력층의 A-1, A-2, A-3의 연산을 위해 슬레이브 가속화 장치는 Slave(L1,D1)~ Slave(L1,DM) 방향으로 할당될 수 있으며, 다른 계층도 이와 동일한 방식으로 할당될 수 있다. 한편, 가속화장치의 연산능력과 수에 따라 각각의 슬레이브 가속화장치는 가변적으로 할당될 수 있다. 도 11에 도시된 인공신경망 모델을 도 10에 도시된 가속화 시스템으로 구현하는 과정을 설명하면 다음과 같다. 먼저, 단일의 호스트 가속화 장치와 복수개의 슬레이브 가속화 장치에 전원이 인가되면 외부 플래시 메모리에 저장된 인공 신경망 연산을 위한 입력 뉴런들에 대한 시냅스 가중치 전체를 상기 호스트 가속화 장치 의 외부 메인 메모리에 저장하는 단계(e1)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치가 범용 통신중개블록을 통해 상기 호스트 가속화 장치의 외부 메인 메 모리에 저장된 시냅스 가중치 중 상기 N개의 계층에 대응되는 각각의 시냅스 가중치 전체를 각 계층을 구성하는 M개의 깊이 중 각 계층의 첫번째 깊이에 대응하는 N개의 슬레이브 가속화 장치(420L1D1, 420L2D1, 420LND1) 각 각의 외부 메인 메모리에 순차적으로 전달하면, 전달받은 N개의 슬레이브 가속화 장치와 연결된 다른 깊이에 대 응하는 슬레이브 가속화 장치 전체에 해당 시냅스 가중치가 각각 저장되는 단계(e2)를 수행할 수 있다. 다음으로, 상기 단일의 호스트 가속화 장치가 데이터 입력장치를 통해 입력되는 입력층의 입력데이터를 상 기 호스트 가속화 장치의 외부 메인 메모리에 저장하는 단계(e3)를 수행할 수 있다. 다음으로, 상기 호스트 가속화 장치의 외부 메인 메모리에 저장된 입력층의 입력데이터는 입력층의 첫번째 깊이에 대응되는 슬레이브 가속화 장치(420L1D1)의 외부 메인 메모리에 일차적으로 해당층의 전체 입력데 이터가 저장된 다음, 입력층을 구성하는 깊이에 대응하는 M개의 슬레이브 가속화 장치 외부 메인 메모리에 해당 되는 입력데이터가 각각 분산되어 순차적으로 저장되는 단계(e4)를 수행할 수 있다. 다음으로, 상기 입력층을 구성하는 M개의 슬레이브 가속화 장치 내부 버퍼 메모리에 해당층의 입력데이터 와 시냅스 가중치를 저장하는 단계(e5)를 수행할 수 있다. 다음으로, 상기 입력층을 구성하는 M개의 슬레이브 가속화 장치의 신경망연산 장치에 의해 신경망 연산을 수행 하고 자신의 외부 메인 메모리에 연산결과를 저장하는 단계(e6)를 수행할 수 있다. 다음으로,상기 M개의 슬레이브 가속화 장치에 저장된 연산결과를 입력층의 첫번째 깊이에 해당하는 슬레이브 가 속화 장치(420L1D1)에 전달하여 해당층의 최종 연산을 수행하고 그 최종연산결과를 다음층의 첫번째 깊이에 해 당하는 슬레이브 가속화장치(420L2D1)에 해당층의 입력데이터로 전달하는 단계(e7)를 수행할 수 있다. 다음층의 첫번째 깊이에 대응되는 슬레이브 가속화 장치의 외부 메인 메모리에 일차적으로 해당층의 전체 입력 데이터가 저장된 다음 해당층을 구성하는 M개의 슬레이브 가속화 장치 외부 메인 메모리에 해당되는 입력데이터 가 각각 분산되어 순차적으로 저장하는 단계(e8);를 수행할 수 있다. N번째 계층의 연산이 완료될때까지 e5 단계 내지 e8 단계에서와 동일한 과정을 반복수행하고, 최종 연산결과는 상기 호스트 가속화 장치에 전달하는 단계(e9)를 수해할 수 있다. 이와 같이, 본 발명은 입력 뉴런들에 대한 입력데이터가 복수개의 깊이와 복수개의 계층구조로 구성되는 인공신 경망의 가속화 방법에 있어서, 복수개의 계층을 각각 구성하는 복수개의 깊이에 대응되는 각각의 가속화장치에 입력 뉴런들에 대한 입력데이터와 시냅스 가중치를 분산하여 처리하는 방법을 제공할 수 있다. 도 12는 본 발명의 실시예에 따라 복수개의 인공신경망으로 구성되는 복합 인공신경망 모델을 개략적으로 나타 내는 도면이다. 도면에 도시된 바와 같이, 본 발명의 실시예에서는, 복합 인공신경망 모델의 세가지 예를 나타내고 있다. 먼저, 본 발명의 실시예에 따른 인공신경망 모델의 제 1실시예는, 물체 검출(Object Detection)을 위한 제 1 복 합 인공신경망이다. 여기서, 상기 제 1 복합 인공신경망은, 개념적으로는 입력 영상으로부터 물체의 특징을 추출하는 신경망 과 입력영상에서의 물체의 위치를 검출하는 신경망을 포함하여 구성될 수 있다. 다음으로, 본 발명의 실시예에 따른 인공신경망 모델의 제 2실시예는, 영상에서 사람 또는 물체에 대한 상황을 문장(Word)으로 표현하는 영상 캡션(Image Captioning)을 위한 제 2 복합 인공 신경망이다. 여기서, 상기 제 2 복합 인공신경망은, 영상에서 물체가 어떤 것인지를 분류 하는 신경망과 이미지를 설명하기 위해 분류된 물체에 캡션을 생성하는 신경망을 포함하여 구성될 수 있다. 이때, 상기 영상 캡션을 위한 제 2 복합 인공 신경망은 영상 데이터를 처리하기 때문에 인공신경망의 크기 가 일반적인 신경망의 크기에 비해 상대적으로 상당히 큰 편에 속한다. 따라서, 연산 성능을 높이기 위해서는 상기 제 2 복합 인공 신경망을 두개의 인공신경망(521,522) 단위로 나눈 다음, 각각의 인공신경망에 대하여 앞서 상술한 깊이, 계층, 및 깊이와 계층에 대응되게 분산하여 가속화 장치에 할당할 수 있다. 특히, 상기 이미지를 설명하기 위해 분류된 물체에 캡션을 생성하는 신경망의 경우에 시계열 순으로 메모 리 셀이 순차적으로 연결될 수 있기 때문에 도 8에 도시된 계층구조를 기반으로 하는 인공 신경망 가속화 시스 템을 활용하여 분산처리 하는 것이 바람직하다. 한편, 본 발명의 복합 인공신경망 모델의 제 3실시예에 따른 복합 인공신경망은, 비디오 또는 스트림 영상 처럼 시계열로 정렬이 가능한 입력 데이터에 대해서, 합성곱 신경망(Convolutional Neural Network)을 시 간축으로 확장한 3차원 합성곱 신경망(3-dimentional Convolutional Neural Network)을 통해 특징을 추출 하고, 특징들 간의 상관관계와 시간적 연속성을 판단하여 제스처 및 행동을 인지하는 인공신경망을 포함할 수 있다. 이때, 상기 3차원 합성곱 신경망의 경우처럼 연속된 영상 데이터를 처리하는 연산량이 많은 신경망은 내부 신경 망을 앞서 상술한 깊이, 계층, 및 시계열을 기준으로 나누어 분산 처리할 수 있다. 이와 같이, 본 발명의 실시예에 따라 하나 이상의 인공신경망 가속화 시스템에 의해 복수개의 인공신경망으로 구성되는 복합 인공신경망 가속화 시스템은, 입력 뉴런들에 대한 입력데이터와 시냅시스 가중치를 상기 복수개 의 인공신경망을 구성하는 각각의 인공신경망 단위로 나누어 분산하여 처리할 수 있다. 상기와 같이, 본 발명은, 인공 신경망의 연산에 필요한 입력 뉴런들에 대한 데이터와 시냅스 가중치를 집적회로 의 종류에 관계없이 통신중개가 가능한 범용 통신중개블럭을 구비한 복수개의 분산처리용 인공신경망 연산 가속 화 장치에 분산하여 처리함으로써 GPGPU와 같은 고전력 고비용의 하드웨어를 사용하지 않더라도 인공신경망 연 산에 필요한 성능을 만족시킬 수 있을 뿐만 아니라 목표 성능에 맞게 인공신경망을 유연하게 설계할 수 있는 인 공신경망 연산 가속화 장치, 가속화 시스템, 및 그 가속화 방법을 제공하는 효과가 있다. 또한, 본 발명은, 저전력/저비용의 집적회로로 구성되는 다수의 가속화 장치를 연결하여 신경망 연산을 수행하 게 함으로써 종래기술에 따라 단일의 하드웨어로 구현되는 고가의 GPGPU를 사용하는 것에 비해 제조비용을 절감 할 수 있으며 저전력을 필요로 하는 분야에 적용할 수 있는 효과가 있다. 또한, 본 발명은, 집적회로의 종류에 관계없이 통신중개가 가능한 범용 통신중개블럭을 가속화 장치에 구현함으 로써 동일한 기종이나 이기종으로 구성된 집적회로로 구현되는 가속화 시스템에 추가적인 기능을 유연하게 적용 할 수 있어 사용자의 다양한 요구에 능동적으로 대처할 수 있는 효과가 있다. 또한, 본 발명은, 다중 가속화 장치를 이용하여 인공 신경망을 분산 병렬 처리함으로써 목표성능에 맞게 유연하 게 가속화장치를 확장하거나 축소할 수 있는 효과가 있다. 또한, 본 발명은, 인공신경망을 구성하는 뉴런들에 대한 입력데이터와 시냅스 가중치를 입력데이터를 구성하는 깊이, 계층구조, 신경망 네트워크 또는 이들의 조합 단위로 나누어 각각의 가속화 장치에서 연산이 가능하게 함 으로써 하드웨어로 구현하는 경우에 메모리 및 주변장치를 최적화할 수 있어 결과적으로 제품의 개발단가를 낮 출 수 있는 효과가 있다. 또한, 본 발명은, 다양한 종류의 집적회로를 이용해 가속화 시스템을 구현함으로써 미래에 적용될 다양한 형태 의 인공신경망 구조에서도 능동적으로 활용이 가능한 효과가 있다. 지금까지 본 발명에 대해서 상세히 설명하였으나, 그 과정에서 언급한 실시예는 예시적인 것일 뿐이며, 한정적 인 것이 아님을 분명히 하고, 본 발명은 이하의 특허청구범위에 의해 제공되는 본 발명의 기술적 사상이나 분야 를 벗어나지 않는 범위내에서, 균등하게 대처될 수 있는 정도의 구성요소 변경은 본 발명의 범위에 속한다 할 것이다. 부호의 설명1 : 플래쉬 메모리 10 : 가속화 장치 11, 211,221, 311, 321, 421 : 외부 메인 메모리 12, 212, 222, 312, 322, 422 : 내부 버퍼 메모리 13, 213, 223, 313, 323, 423 : DMA모듈 14, 214, 224, 314, 324, 424 : 신경망 연산장치 15, 215, 225, 315, 325, 425 : CPU 16 : 데이터 입력장치 100 : 범용 통신중개블럭 101 : 송신모듈(인터페이스) 102 : 수신모듈(인터페이스) 110 : 리맵핑 블럭 120 : 버스제어신호 매칭블럭 130 : 모니터 블럭 200, 300, 400 : 가속화 시스템 201, 301, 401 : 호스트용 중개블럭 202, 302, 402 : 슬레이브용 통신중개블럭 210, 310, 410 : 호스트 가속화 장치 220, 320, 420 : 슬레이브 가속화 장치 510, 520, 530 : 복합 인공 신경망 511,512,521,522,531,532 : 인공신경망도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2019-0007723", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예가 적용된 입력층과 은닉층을 포함하는 인경신경망을 개략적으로 나타내는 개념도이다. 도 2는 도 1에 도시된 인공신경망을 확장한 심층 신경망을 개략적으로 나타내는 도면이다. 도 3은 본 발명의 실시예에 따른 분산처리용 인공신경망 연산 가속화 장치의 집적회로 구성을 개략적으로 나타 내는 블럭도이다. 도 4는 도 3에 도시된 가속화 장치를 구성하는 범용 통신중개블럭의 세부구성을 나타내는 도면이다. 도 5는 본 발명의 실시예에 따라 입력데이터가 복수개의 깊이를 갖는 인공 신경망 연산을 처리하기 위한 가속화 시스템의 다중 집적회로 구성을 개략적으로 나타내는 블럭도이다. 도 6은 도 5에 도시된 가속화 시스템의 일실시예에 따른 인공신경망 모델을 개략적으로 나타내는 도면이다. 도 7은 도 5에 도시된 가속화 시스템의 다른 실시예에 따른 인공신경망 모델을 개략적으로 나타내는 도면이다. 도 8은 본 발명의 실시예에 따라 입력 뉴런들이 복수개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한가속화 시스템의 다중 집적회로 구성을 개략적으로 나타내는 블럭도이다. 도 9는 도 8에 도시된 가속화 시스템의 실시예에 따른 인공신경망 모델을 개략적으로 나타내는 도면이다. 도 10은 복수(M)개의 깊이와 복수(N)개의 계층으로 구성되는 인공 신경망 연산을 처리하기 위한 가속화 시스템 의 다중 집적회로 구성을 개략적으로 나타내는 블럭도이다. 도 11은 도 10에 도시된 가속화 시스템의 실시예에 따른 인공신경망 모델을 개략적으로 나타내는 도면이다. 도 12는 본 발명의 실시예에 따라 복수개의 인공신경망으로 구성되는 복합 인공신경망 모델을 개략적으로 나타 내는 도면이다."}
