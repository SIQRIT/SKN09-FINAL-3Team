{"patent_id": "10-2021-0154410", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0068530", "출원번호": "10-2021-0154410", "발명의 명칭": "협동 로봇 지능제어를 위한 모니터링 제어 시스템", "출원인": "주식회사 소이넷", "발명자": "김용호"}}
{"patent_id": "10-2021-0154410", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "협동 로봇에 의해 수행되는 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점 중 적어도 하나에 관한정보를 3D 센서;를 통해 실시간 획득하고, 상기 3D 센서를 통해 획득(비전 정보)된 상기 협동 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점 중 적어도 하나의 유형에 관한 정보에 기초하여 상기 협동 로봇의 위치, 상태 및 동작 중 적어도 하나에 대한 제어가 가능한 컨트롤 박스; 및상기 컨트롤 박스와 통신 네트워크;를 통해 유선 또는 무선으로 연결되며, 상기 협동 로봇의 위치, 상태 및 동작 중 적어도 하나의 획득된 정보 및 미리 학습된 패턴에 따라 설정된 작업 환경 내에서의 상기 협동 로봇의 위치, 상태 및 동작 중 적어도 하나에 대한 제어를 유지관리할 수 있는 스마트 티칭펜던트;를 포함하여,3D 비전 일체형 협동 로봇의 모니터링 제어 플랫폼의 구현이 가능하며, 이를 통해 작업자 등과의 충돌 회피 모션을 포함한 작업을 스스로 인지하고 모션을 생성하는 행동지능을 가지는 것을 특징으로 하는 협동 로봇 지능제어를 위한 모니터링 제어 시스템."}
{"patent_id": "10-2021-0154410", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 컨트롤 박스는,상기 3D 센서를 통해 실시간 모니터링되는 협동 로봇의 위치, 상태 및 동작 중 적어도 하나의 정보를 기반으로미리 설정된 3D 좌표계 상에서의 상기 협동 로봇의 전체 또는 특정 부위의 자세를 추론할 수 있는 비전 프로세스;를 포함하는 것을 특징으로 하는 협동 로봇 지능제어를 위한 모니터링 제어 시스템."}
{"patent_id": "10-2021-0154410", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 협동 로봇 지능제어를 위한 모니터링 제어 시스템은,작업자의 직접 교시(teaching) 또는 미리 설정된 워크플로우에 따라 작업을 수행하는 상기 협동 로봇이 설정된동작을 수행하는 동안, 상기 협동 로봇의 전체 또는 특정 부위의 위치, 자세 및 동작 중 적어도 하나를 실시간모니터링할 수 있는 RGB 카메라;를 더 포함하되,상기 컨트롤 박스는,상기 비전 프로세스를 통해, 상기 RGB카메라를 통해 모니터링 되는 실시간 이미지(동영상) 정보를 3차원 포인트클라우드 기반을 통해 3차원 모델로 생성할 수 있는 것을 특징으로 하는,협동 로봇 지능제어를 위한 모니터링 제어 시스템."}
{"patent_id": "10-2021-0154410", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 스마트 티칭펜던트(teaching pendent)는,상기 협동 로봇의 설정된 단부의 위치 정보(x, y, z 위치와 회전 x, 회전 y, 회전 z)를 미리 지정하는 동시에,상기 협동 로봇의 설정된 단부가 설정된 워크플로우에 따라 지정된 교시위치에 도달하면 다음 작업으로 진행하기 위한 조건을 비교하고 상기 조건이 만족이 될 시, 작업자가 지정한 다음 작업으로 반복 동작 작업을 수행할공개특허 10-2023-0068530-3-수 있도록 하도록 하되,작업자가 상기 협동 로봇에 워크플로우 정보를 직접 교시할 수 있는 인터페이스를 가지는 로봇 인터페이스 앱;및상기 협동 로봇이 위치한 작업 환경 내에서 획득 가능한 비전 정보와 정합 가능하도록 지원하는 비전 인터페이스 앱;을 포함하는 것을 특징으로 하는 협동 로봇 지능제어를 위한 모니터링 제어 시스템."}
{"patent_id": "10-2021-0154410", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 컨트롤 박스는,상기 협동 로봇을 제어하여 상기 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 상기 협동 로봇 동작이 수행되는 작업 환경에 관한 정보를 획득하는 작업 환경 측정부;상기 협동 로봇을 제어하여 상기 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 상기 협동 로봇 동작에 관한 작업 정보를 획득하는 작업 정보 수신부; 및획득한 상기 작업 환경에 관한 정보 및 상기 협동 로봇 동작에 관한 작업 정보에 기초하여 상기 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 상기 협동 로봇이 동작을 수행하도록 상기 협동 로봇을 제어하는 로봇 동작제어부;를 포함하되,상기 작업 환경 측정부는,작업자가 상기 협동 로봇을 직접 움직여서 위치와 움직임을 알려주는 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 상기 협동 로봇을 동작시키면서 상기 협동 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점을 포함하는 상기 작업 환경에 관한 정보를 획득하고,상기 작업 정보 수신부는,작업자가 상기 협동 로봇을 직접 움직여서 위치와 움직임을 알려주는 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 상기 로봇을 동작시키면서 상기 협동 로봇의 동작에 기초하여 생성되는 상기 협동 로봇 동작의특성을 포함하는 상기 협동 로봇 동작에 관한 작업 정보를 획득하는 것을 특징으로 하는,협동 로봇 지능제어를 위한 모니터링 제어 시스템."}
{"patent_id": "10-2021-0154410", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 작업 환경 측정부는,상기 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 상기 협동 로봇이 동작을 수행하는 동안, 설정된3D 센서 또는 RGB 카메라에 의해 상기 작업 환경에 관한 정보를 획득하는 것을 특징으로 하는,협동 로봇 지능제어를 위한 모니터링 제어 시스템."}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 협동 로봇 모니터링 제어 시스템에 관한 것으로서, 보다 상세하게는 3D비전(3D센서) 기술, RGB 카메라 영상정보 등을 통해 획득되는 협동 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점과 작업 환경에 대 한 실시간 모니터링이 가능한 동시에, 작업자 등 사용자의 편의성이 개선된 스마트 티칭펜던트(teaching pendent)를 통해 모니터링 및 제어의 대상이 되는 협동 로봇의 관절의 움직임 상태 등에 대한 분석을 기반으로 협동 로봇의 지능제어가 가능한 공정인식 및 자동모션생성 알고리즘을 활용하는 협동 로봇 지능제어를 위한 모니 터링 제어 시스템에 관한 것이다."}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 협동 로봇 모니터링 제어 시스템에 관한 것으로서, 보다 상세하게는 3D비전(3D센서) 기술, RGB 카메 라 영상정보 등을 통해 획득되는 협동 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점과 작업 환경에 대한 실시간 모니터링이 가능한 동시에, 작업자 등 사용자의 편의성이 개선된 스마트 티칭펜던트(teaching pendent)를 통해 협동 로봇의 동작 등에 대한 제어나 학습이 가능한 협동 로봇 지능제어를 위한 모니터링 제어시스템에 관한 것이다. 또한 본 발명은 제어의 대상이 되는 협동 로봇의 관절의 움직임 상태 등에 대한 분석을 기반으로 협동 로봇의 지능제어가 가능한 공정인식 및 자동모션생성 알고리즘을 활용하는 협동 로봇 지능제어를 위한 모니터링 제어 시스템에 관한 것이기도 하다."}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사람과 근접한 곳에서 작동하는 로봇으로 통상적으로 정의되는 협동 로봇은 IoT와 같은 정보통신기술과 로봇 공 학, 인공지능 기술과 센싱 기술 등의 발전에 따라 사람과 같은 공간에서 일할 수 있는 협동 로봇이 산업 전방에 걸쳐 확대되고 있다. 이러한 협동 로봇은 작업자가 필요에 따라 직접 교시하여 사용할 수 있고, 다양한 작업에 대해 작업자 등을 보 조하는 수단으로써 적업 효율을 증대시킬 수 있는 동시에, 장기적으로 고정비를 절감할 수 있는 수단으로써도 최근 주목 받고 있디고 하다. 그러나 작업자와 충돌하는 등의 일이 발생할 위험성을 내포하고 있는 바, 충격량이 크지 않은 소형 중심으로 협동 로봇이 개발되어 활용되는 제약 사항(충격량을 줄이기 위한 주된 목적)이 있고, 사전 교시된 위치 기반의 작업만 수행되는 제약 사항 등과 같은 지속적인 한계가 지적되어 왔다. 또한 이와 함께 SI(System Integration)에 의존적인 자동화 및 제어 관련 시스템의 한계와 작업 진행을 위해 JIG 등 주변 장치의 설계 및 설치가 사전적으로 요구되는 한계점 역시 지속적으로 개선되어야 할 문제점으로 지 적되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2021-0118380호(2021년 9월 30일 공개)"}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 전술한 문제점 해결을 위해 개발된 기술로, AI(인공지능) 기반 3D 비전 시스템과 로봇제어가 연동되 는 자동모션생성 기술을 통합하여 작업을 스스로 인지하고 모션을 생성하는 협동 로봇 기술을 제공함에 있다."}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 본 발명의 목적 달성을 위해, 협동 로봇에 의해 수행되는 로봇 동작의 시작점, 이동 경로 상의 경유 지 점 및 도착점 중 적어도 하나에 관한 정보를 3D 센서;를 통해 실시간 획득하고, 상기 3D 센서를 통해 획득(비전 정보)된 상기 협동 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점 중 적어도 하나의 유형에 관한 정 보에 기초하여 상기 협동 로봇의 위치, 상태 및 동작 중 적어도 하나에 대한 제어가 가능한 컨트롤 박스; 및 상 기 컨트롤 박스와 통신 네트워크;를 통해 유선 또는 무선으로 연결되며, 상기 협동 로봇의 위치, 상태 및 동작 중 적어도 하나의 획득된 정보 및 미리 학습된 패턴에 따라 설정된 작업 환경 내에서의 상기 협동 로봇의 위치, 상태 및 동작 중 적어도 하나에 대한 제어를 유지관리할 수 있는 스마트 티칭펜던트;를 포함하여, 3D 비전 일체 형 협동 로봇의 모니터링 제어 플랫폼의 구현이 가능하며, 이를 통해 작업자 등과의 충돌 회피 모션을 포함한 작업을 스스로 인지하고 모션을 생성하는 행동지능을 가지는 것을 특징으로 하는 협동 로봇 지능제어를 위한 모 니터링 제어 시스템이 제공될 수 있다. 또한 본 발명에 따른 상기 컨트롤 박스는,상기 3D 센서를 통해 실시간 모니터링되는 협동 로봇의 위치, 상태 및 동작 중 적어도 하나의 정보를 기반으로 미리 설정된 3D 좌표계 상에서의 상기 협동 로봇의 전체 또는 특정 부위의 자세를 추론할 수 있는 비전 프로세스;를 더 포함하는 것을 특징으로 하는 협동 로봇 지능제어를 위한 모 니터링 제어 시스템의 형태로도 제공될 수 있다. 또한 본 발명에 따른 상기 협동 로봇 지능제어를 위한 모니터링 제어 시스템은, 작업자의 직접 교시(teaching) 또는 미리 설정된 워크플로우에 따라 작업을 수행하는 상기 협동 로봇이 설정된 동작을 수행하는 동안, 상기 협 동 로봇의 전체 또는 특정 부위의 위치, 자세 및 동작 중 적어도 하나를 실시간 모니터링할 수 있는 RGB 카메라;를 더 포함하되, 상기 컨트롤 박스는, 상기 비전 프로세스를 통해, 상기 RGB카메라를 통해 모니터링 되 는 실시간 이미지(동영상) 정보를 3차원 포인트 클라우드 기반을 통해 3차원 모델로 생성할 수 있는 것을 특징 으로 하는, 협동 로봇 지능제어를 위한 모니터링 제어 시스템의 형태로도 제공이 가능하다. 또한 상기 스마트 티칭펜던트(teaching pendent)는, 상기 협동 로봇의 설정된 단부의 위치 정보(x, y, z 위치와 회전 x, 회전 y, 회전 z)를 미리 지정하는 동시에, 상기 협동 로봇의 설정된 단부가 설정된 워크플로우에 따라 지정된 교시위치에 도달하면 다음 작업으로 진행하기 위한 조건을 비교하고 상기 조건이 만족이 될 시, 작업자 가 지정한 다음 작업으로 반복 동작 작업을 수행할 수 있도록 하도록 하되, 작업자가 상기 협동 로봇에 워크플 로우 정보를 직접 교시할 수 있는 인터페이스를 가지는 로봇 인터페이스 앱; 및 상기 협동 로봇이 위치한 작업 환경 내에서 획득 가능한 비전 정보와 정합 가능하도록 지원하는 비전 인터페이스 앱;을 포함하는 것을 특징으 로 하는 협동 로봇 지능제어를 위한 모니터링 제어 시스템의 구성을 통해서도 전술한 본 발명의 목적 달성이 가 능하게 된다. 또한 상기 컨트롤 박스는, 상기 협동 로봇을 제어하여 상기 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 상기 협동 로봇 동작이 수행되는 작업 환경에 관한 정보를 획득하는 작업 환경 측정부; 상기 협동 로봇을 제어 하여 상기 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 상기 협동 로봇 동작에 관한 작업 정보를 획득하 는 작업 정보 수신부; 및 획득한 상기 작업 환경에 관한 정보 및 상기 협동 로봇 동작에 관한 작업 정보에 기초 하여 상기 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 상기 협동 로봇이 동작을 수행하도록 상기 로봇을 제어하는 로봇 동작 제어부를 포함하되, 상기 작업 환경 측정부는, 작업자가 상기 협동 로봇을 직접 움직여서 위치와 움직임을 알려주는 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 상기 협동 로봇을 동작시키 면서 상기 협동 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점을 포함하는 상기 작업 환경에 관한 정보를 획득하고, 상기 작업 정보 수신부는,작업자가 상기 협동 로봇을 직접 움직여서 위치와 움직임을 알려주 는 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 상기 로봇을 동작시키면서 상기 협동 로봇의 동작에 기초하여 생성되는 상기 협동 로봇 동작의 특성을 포함하는 상기 협동 로봇 동작에 관한 작업 정보를 획득하는 것을 특징으로 하는, 협동 로봇 지능제어를 위한 모니터링 제어 시스템의 구성을 통한 본 발명의 목적 달성도 고려될 수 있다. 이와 함께 본 발명에 따른 상기 작업 환경 측정부는, 상기 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 상기 협동 로봇이 동작을 수행하는 동안, 설정된 3D 센서 또는 RGB 카메라에 의해 상기 작업 환경에 관한 정보를 획득하는 것을 특징으로 하는, 협동 로봇 지능제어를 위한 모니터링 제어 시스템의 형태로도 제공이 가 능하게 된다."}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 목적 및 해결 수단에 의할 경우, 3D 비전 일체형 협동 로봇의 모니터링 제어 플랫폼의 구현이 가능하며, 이를 통해 작업자 등과의 충돌 회피 모션을 포함한 작업을 스스로 인지하고 모션을 생성하는 행동지 능을 가지는 협동 로봇 기술을 제공할 수 있게 된다. 다만, 본 발명에 따른 효과는 이상에서 예시된 내용에 의해 제한되지 않으며, 더욱 다양한 효과들이 본 명세서 내에 포함되어 해석되어야 한다."}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명을 설명하기로 한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 따라서 여기에서 설명하는 실시예로 한정되는 것은 아니다. 그리고 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유 사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉, 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연 결\"되어 있는 경우뿐 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 구비할 수 있다는 것을 의미한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하에서는 도 1 내지 도 3을 참조하여, 본 발명에 따른 협동 로봇 지능제어를 위한 모니터링 제어 시스템(10 0)에 대해 기술하기로 한다. 도 1은 본 발명의 일 실시예에 따른 딥러닝 기반 3D 작업의 인식이 가능한 협동 로봇 지능제어를 위한 모니터링 제어 시스템의 구성을 개략적으로 표현한 도면이다. 또한 도 2는 본 발명의 일 실시예에 따른 클라우드를 기반으로 적어도 하나 이상의 협동 로봇에 대한 학습 데이터 제공 및 RGB카메라 등을 기반으로 획득되는 작업 정보 등을 기반으로 협업 로봇의 지능제어를 수행하는 모식도를 나타내고 있는 도면이다. 도 3은 본 발명에 일 실시예에 따른 협동 로봇 지능제어를 위한 모니터링 제어 시스템을 통해 복수개의 작업 대상물을 3D 차원 에서 추적하여 작업 대응할 수 있는 개념을 나타내고 있는 도면이다. 본 발명에 따른 협동 로봇 지능제어를 위한 모니터링 제어 시스템은 내외부 3D센서(비전센서 등) 및/또는 RGB 카메라 등과 연결된 컨트롤 박스 및 스마트 티칭팬던트(130, (teaching pendent))를 포함할 수 있다. 이를 통해 협동 로봇 지능제어를 위한 모니터링 제어 시스템은 3D 비전 일체형 협동 로봇의 모니터링 제어 플랫폼의 구현이 가능하며, 이를 통해 작업자 등과의 충돌 회피 모션을 포함한 작업을 스스로 인지하고 모션을 생성하는 행동지능을 제공할 수 있게 된다. 또한 비전 프로세서 및 로봇 제어기의 동기화(도 3 참 조)를 통해 실시간으로 고속으로 이동하는 다양한 3D 형상과 모양을 가지는 작업 대상물을 추적 및 특정할 수 있는 기술적 특징 역시 가지고 있다. 본 발명에 따른 컨트롤 박스는 협동 로봇(1, 2, n)에 의해 수행되는 로봇 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점 중 적어도 하나에 관한 정보를 3D 센서 및/또는 카메라(12, RGB 카메라, 다중 RGB-D 카메라 등이 될 수 있다)를 통해 실시간 획득할 수 있다. 또한 본 발명에 따른 컨트롤 박스는 3D 센서 및/또는 카메라를 통해 획득(비전 정보 등)되는 협동 로봇(1, 2, n) 동작의 시작점, 이동 경로 상의 경유 지점 및 도착점 중 적어도 하나의 유형에 관한 정보에 기초하여 협동 로봇((1, 2, n)의 위치, 상태 및 동작 중 적어도 하나에 대한 실시간 모니터링 및 제어가 가능한 독립된 장치 또는 PC나 서버, 통신 가능한 IT디바이스 내에서 구동되는 모듈이 될 수도 있다(도 2 및 도 3 참조). 이를 위해 본 발명에 따른 컨트롤 박스는 3D 센서를 통해 실시간 모니터링되는 협동 로봇(1, 2, n)의 위치, 상태 및 동작 중 적어도 하나의 정보를 기반으로 미리 설정된 3D 좌표계 상에서의 협동 로봇(1, 2, n)의전체 또는 특정 부위(일 예로 로봇 손가락 등의 단부나 팁, 팔꿈치 등이 될 수 있다)의 자세를 추론할 수 있는 비전 프로세스를 포함할 수 있다. 본 발명에 따른 비전 프로세스는 3D 센서 및/또는 카메라를 통해 획득된 실시간 이미지의 픽셀을 미리 결정된 좌표 시스템에 매핑하는 기능을 수행할 수 있다. 이 경우 타겟은 특징 패턴에 인레이드된(inlaid) 3D 코드와 같은 좌표 시스템(예를 들어, 일련의 체커보드의 X-Y-Z축 배열)을 정의하는 특징 또는 패턴 좌표 시 스템을 정의하는 구별되는 기점(distinctive fiducial)을 포함할 수 있다. 즉 일 예로 본 발명에 따른 비전 프 로세스는 협동 로봇(1, 2, n)의 작업 대상이 되는 작업물 또는 작업 환경 등의 특징을 비전 센서나 카메라 를 통해 획득하고, 획득된 이미지의 픽셀에 매핑을 통해 시스템이 타겟으로 교정되는 과정을 수행할 수 있다. 이 경우 교정 타겟의 전부 또는 일부의 이미지를 획득하는데 사용되는 적어도 하나의 3D 센서 및/또는 카메 라의 경우 타겟의 특징(예를 들어, 타겟의 평면을 따른 x 및 y, z(높이) 및 x-y 평면에서 z축을 중심으로 하는 회전 θ) 또는 다른(예를 들어, 글로벌) 좌표 시스템에 의해 특정될 수 있게 된다. 또한 본 발명에 따른 비전 프로세서는 내장된 교정 애플리케이션을 포함할 수 있으며, 이를 통해 3D 센서 및/또는 별도의 카메라를 통해 획득된 타겟의 이미지로부터 하나 이상의 3D 센서 및/또는 별도의 카메라의 상대 위치를 추론할 수 있으며, 타겟의 기점은 개별 시야 내의 타겟에 대해 3D 센서 및/또는 별도의 카메라를 배향시키는데도 사용될 수 있다. 또한 본 발명에 따른 비전 프로세스는 3D 센서 및/또는 카메라를 통해 촬영되는 깊이 및 RGB 이미 지를 이용하여 깊이 카메라의 좌표계를 따르는 포인트 클라우드를 각 3D 센서 및/또는 카메라에서 획득 하도록 할 수도 있다. 본 발명에 따른 카메라는 3D 센서와 일체형 또는 하나의 모듈로써 전술한 기능을 수행할 있으며, 이와 함께 작업자의 직접 교시(teaching) 또는 미리 설정된 워크플로우에 따라 작업을 수행하는 협동 로봇이 설정 된 동작을 수행하는 동안, 협동 로봇의 전체 또는 특정 부위의 위치, 자세 및 동작 중 적어도 하나를 실시간 모니터링할 수 있는 RGB 카메라일 수 있다. 이 경우 컨트롤 박스는, 비전 프로세스를 통해, 카메라 를 통해 모니터링(획득) 되는 실시간 이미지(동영상, 스틸 이미지 등) 정보를 3차원 포인트 클라우드 기반 을 통해 3차원 모델로 생성할 수도 있게 된다. 또한 본 발명에 따른 3D 센서 및/또는 카메라는 미리 설정된 협동 로봇(1, 2, n)의 전체 또는 설정된 일부 (일 예로 특정한 회전, 굽힘 등의 동작이 가능한 관절이나 단부 등)를 이미지 기반으로 센싱(일종의 키넥티센서)할 수 있으며, 이를 통해 획득된 로봇 관절의 움직임이나 동작 등에 대한 데이터 역시 컨트롤 박스 로 전달되어 가공, 처리될 수 있다. 이에 의해, 본 발명에 따른 협동 로봇 지능제어를 위한 모니터링 제어 시스템은 3D 센서 데이터, RGB 카메 라 데이터 및 전술한 로봇 관절 데이터를 활용하여 영상 속 겹쳐진 시편을 Instance Segmentation하여 분할 및 3D 좌표계 상의 자세를 추론할 수 있게 되는 기술적 특징 역시 가지게 된다. 이를 위해 본 발명에 따른 비전 프 로세서는 기공지된 적어도 하나 이상 또는 하나 이상의 AI(인공지능) 기반의 추론 모델을 통합하여 3D 작 업물의 인식 및 작업모션에 대한 알고리즘에 대한 구현 역시 가능하게 된다(도 4, 딥러닝 알고리즘 연산 프로세 싱 개념도 참조). 도 4에 도시된 바와 같이, 본 발명에 따른 시스템, 보다 구체적으로는 로봇 제어기는 AI(인공지능)을 기반으로 3차원 작업물을 실시간으로 정확하게 인식할 수 있게 되며, 이러한 작업물의 상태 및 정보 등을 기초 로 협동 로봇의 자세나 동작, 위치 등에 정보를 자동으로 생성하는 알고리즘 역시 포함할 수 있다. 또한 도 2에서 도시된 바와 같이, 본 발명에 따른 시스템은 경량화 및 최적화되어 있는 AI(인공지능) 기반 의 추론 모델을 통해 복수개의 협동 로봇(1, 2, n)과의 데이터 통신(일 예로 협동 로봇 설정된 내부 또는 외 측, 이격된 작업 공간에 설치된 3D 센서 및/또는 카메라를 통해 작업물 등에 대한 영상 이미지를 전달 (실시간)받을 수 있는 동시에, 획득된 영상 이미지 정보를 기반으로 분석된 영상 인식 결과 데이터를 협동 로봇 (1, 2, n)들에게 실시간 전송함으로써 협동 로봇들의 작업물 특성 및 워크플로우에 따른 작업을 빠르고 정확 하게 진행하도록 지원할 수 있게 된다. 또한 본 발명에 따른 시스템은 별도의 클라우드 학습 서버 등과 연동하여 새로운 작업물 처리나 대응 등이 필요한 상황에 맞춰 학습 데이터를 협동 로봇(1, 2, n)에 전송하거나 컨트롤 박스에 전달하여 협동 로봇의 작업물 대응 능력을 고도화 시킬 수 있게 되며, 이와 동시에 작업자의 개입을 최소화할 수 있게 된다. 이 경우 채택될 수 있는 학습모델의 경우 Detectron2으로 segmentation 된 결과를 MaskRCNN에서 받아 classification하는 방식 등이 고려될 수 있다. 또한 전술한 본 발명의 목적 달성을 위해, 본 발명에 따른 시스템은 협동 로봇이 설치 및 운영되는 작 업 공간(현장)의 공간 형상 정보, 협동 로봇의 관절 데이터 및 작업물(pick & place 대상물)의 라벨 데이터 정보를 미리 저정하거나 외부의 별도 서버 등을 통해 입력받을 수 있다. 또한 본 발명에 따른 다른 실시예에 의할 경우, 컨트롤 박스는, 작업 환경 측정부, 작업 정보 수신부 및 로봇 동작 제어부를 포함할 수 있다. 이 경우 상기 작업 환경 측정부는, 협동 로봇을 제어하여 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 협동 로봇 동작이 수행되는 작업 환경에 관한 정보를 획득하는 것을 주요한 기능으로 하는 모듈을 지칭 한다. 본 발명에 따른 작업 환경 측정부는, 작업자가 협동 로봇을 직접 움직여서 위치와 움직임을 알려주는 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 협동 로봇을 동작시키면서 협동 로봇 동작의 시 작점, 이동 경로 상의 경유 지점 및 도착점을 포함하는 상기 작업 환경에 관한 정보를 획득할 수도 있다. 또한 상기 작업 환경 측정부는, 상기 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 상기 협동 로봇이 동작을 수행하는 동안, 설정된 3D 센서 또는 카메라에 의해 상기 작업 환경에 관한 정보를 획득할 수도 있다. 상기 작업 정보 수신부는, 협동 로봇을 제어하여 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 협동 로봇 동작에 관한 작업 정보를 획득하는 것을 주요 기능으로 하는 모듈을 지칭한다. 이 경우 작업 정보 수신 부는, 작업자가 협동 로봇을 직접 움직여서 위치와 움직임을 알려주는 직접 교시에 의해 상기 작업 유형 및 워크플로우에 따라 협동 로봇을 동작시키면서 협동 로봇의 동작에 기초하여 생성되는 상기 협동 로봇 동작의 특성에 대한 정보를 모니터링하는 기능을 추가적으로 포함할 수 있다. 상기 로봇 동작 제어부는, 획득한 상기 작업 환경에 관한 정보 및 협동 로봇 동작에 관한 작업 정보에 기초 하여 협동 로봇 동작의 작업 유형 및 워크플로우에 따라 상기 협동 로봇이 동작을 수행하도록 로봇을 제 어하는 기능을 수행하는 모듈을 지칭한다. 본 발명에 따른 스마트 티칭펜던트(130, teaching pendent)는 컨트롤 박스와 통신 네트워크를 통해 유선 및/또는 무선으로 연결되며, 협동 로봇의 위치, 상태 및 동작 중 적어도 하나의 획득된 정보 및 미리 학습된 패턴에 따라 설정된 작업 환경 내에서의 협동 로봇의 위치, 상태 및 동작 중 적어도 하나에 대한 제 어를 유지관리할 수 있는 모듈로써, 별도 자체적인 독립 장비로 제공되거나, 디스플레이 화면을 가지는 PC, 태 블릿 등 IT디바이스의 내부에서 구동 가능한 모듈(프로그램 내지 알고리즘)의 형태로 제공될 수 있다. 또한 본 발명에 따른 스마트 티칭펜던트는 적어도 하나의 협동 로봇의 설정된 단부의 위치 정보(x, y, z 위치와 회전 x, 회전 y, 회전 z)를 미리 지정하는 동시에, 협동 로봇의 설정된 단부가 설정된 워크플로우 에 따라 지정된 교시위치에 도달하면 다음 작업으로 진행하기 위한 조건을 비교하고 상기 조건이 만족이 될 시, 작업자가 지정한 다음 작업으로 반복 동작 작업을 수행할 수 있도록 모니터링 및 제어가 가능하다. 또한 이와 함께(또는 별도로) 작업자 등은 스마트 티칭펜던트를 통해 협동 로봇에 워크플로우 정보를 직접 교시할 수 있는 인터페이스를 가지는 로봇 인터페이스 앱(App, 설정된 디스플레이 화면을 통해 입출력이 가능)과 협동 로봇이 위치한 작업 환경 내에서 획득 가능한 비전 정보(3D 센서 및/또는 카메라를 통해 획득)와 정 합 가능하도록 지원하는 비전 인터페이스 앱(App)을 포함할 수 있다."}
{"patent_id": "10-2021-0154410", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 후술하는 청구범위에 의하여 나타내어지며, 청구범위의 의미 및 범위 그리고 그 균등 개념으 로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다.부호의 설명 1: 협동 로봇(n) 100: 협동 로봇 지능제어를 위한 모니터링 제어 시스템 110: 컨트롤 박스 111: 비전 프로세스 113: 로봇 제어기 130: 스마트 티칭펜던트 150: 유선 및/또는 무선 네트워크"}
{"patent_id": "10-2021-0154410", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 딥러닝 기반 3D 작업의 인식이 가능한 협동 로봇 지능제어를 위한 모니터링 제어 시스템의 구성을 개략적으로 표현한 도면이다. 도 2는 본 발명의 일 실시예에 따른 클라우드를 기반으로 적어도 하나 이상의 협동 로봇에 대한 학습 데이터 제공 및 RGB카메라 등을 기반으로 획득되는 작업 정보 등을 기반으로 협업 로봇의 지능제어를 수행하는 모식도를 나타내고 있는 도면이다. 도 3은 본 발명에 일 실시예에 따른 협동 로봇 지능제어를 위한 모니터링 제어 시스템을 통해 복수개의 작업 대 상물을 3D 차원에서 추적하여 작업 대응할 수 있는 개념을 나타내고 있는 도면이다. 도 4는 딥러닝 기반의 알고리즘 연산 고속화를 위한 프로세싱 개념도를 나타내고 있다."}
