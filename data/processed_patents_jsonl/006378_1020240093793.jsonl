{"patent_id": "10-2024-0093793", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0037344", "출원번호": "10-2024-0093793", "발명의 명칭": "전자 장치에 의해 수행되는 방법, 전자 장치 및 저장 매체", "출원인": "삼성전자주식회사", "발명자": "지화 리우"}}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 의해 수행되는 방법에 있어서,비디오의 프레임 이미지 및 상기 프레임 이미지에 대응하는 관성 측정 유닛의 데이터를 획득하는 단계; 및상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈(Position&Pose), 스파스 맵(sparse map) 및 고밀도 맵을 획득하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는,상기 프레임 이미지가 키 프레임인 경우,상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈, 3차원 랜드마크 포인트(Three-Dimensional Landmark Point), 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 획득하는 단계;상기 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 3차원 랜드마크포인트, 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 전역 최적화를 수행하는 단계;최적화된 3차원 랜드마크 포인트로부터 상기 프레임 이미지에 대응하는 스파스 맵을 생성하는 단계; 및상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지에 기초하여 신경망을통해 상기 고밀도 맵을 얻는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는,상기 프레임 이미지가 비 키 프레임인 경우,상기 프레임 이미지 및 상기 프레임 이미지에 대응하는 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임이미지의 상기 카메라 위치와 포즈를 획득하는 단계; 및상기 프레임 이미지 이전의 이전 키 프레임에 대응하는 상기 스파스 맵과 상기 고밀도 맵을 상기 프레임 이미지에 대응하는 상기 스파스 맵과 상기 고밀도 맵으로 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2025-0037344-3-제2항에 있어서, 상기 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 상기 3차원 랜드마크 포인트, 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 전역 최적화를 수행하는 단계는,상기 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈 및 상기 3차원 랜드마크 포인트를 기반으로강건 커널(robust kernel) 함수 기반의 재투영 오차 함수를 구성하는 단계;상기 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈와 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 상기 관성 측정 유닛의 오차 함수를 구성하는 단계; 및상기 강건 커널 함수 기반의 재투영 오차 함수 및 상기 관성 측정 유닛의 오차 함수로 구성된 전역 최적화 타겟함수를 최소화하여, 상기 적어도 하나의 키 프레임에 대응하는 최적화된 카메라 위치와 포즈, 최적화된 3차원랜드마크 포인트 및 상기 관성 측정 유닛의 최적화된 속도 및 상기 관성 측정 유닛의 최적회된 편차를 획득하는단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 강건 커널 함수는,후버(Huber) 커널 함수를 포함하는방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는,상기 프레임 이미지가 비 키 프레임인 경우,상기 프레임 이미지에 대응하는 깊이 맵을 결정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프레임 이미지에 대응하는 상기 깊이 맵을 결정하는 단계는,상기 프레임 이미지 중 왼쪽 눈 이미지와 오른쪽 눈 이미지에 대해 스테레오 매칭을 수행하여 상기 프레임 이미지에 대응하는 양안 시차 맵을 획득하는 단계; 및상기 양안 시차 맵을 변환하여 상기 프레임 이미지에 대응하는 깊이 맵을 획득하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2025-0037344-4-제7항에 있어서,상기 프레임 이미지 중 상기 왼쪽 눈 이미지와 상기 오른쪽 눈 이미지에 대해 스테레오 매칭을 수행하여 상기프레임 이미지에 대응하는 상기 양안 시차 맵을 획득하는 단계는,상기 프레임 이미지 이전의 이전 키 프레임에 대응하는 고밀도 맵과 상기 프레임 이미지의 상기 왼쪽 눈 이미지및 상기 오른쪽 눈 이미지에 따라 스테레오 매칭을 수행하여 상기 양안 시차 맵을 얻는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항에 있어서, 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로, 상기 신경망을 통해 상기 고밀도 맵을 획득하는 단계는,상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로 상기 신경망을 훈련하여, 양안 비디오에 대응하는 장면의 암시적 고밀도 맵 표현을 획득하는 단계; 및상기 획득한 암시적 고밀도 맵 표현에 상기 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 입력하여상기 고밀도 맵 및 상기 고밀도 맵 내 각 3차원 랜드마크 포인트의 신뢰도를 획득하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로 상기 신경망을 훈련하여, 상기 양안 비디오에 대응하는 장면의 상기 암시적 고밀도 맵 표현을 획득하는 단계는,상기 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 기반으로, 렌더링된 컬러 이미지와 렌더링된 깊이 맵을 획득하는 단계;상기 렌더링된 컬러 이미지 및 상기 프레임 이미지의 컬러 이미지를 기반으로 제1 손실 함수를 결정하는 단계;상기 렌더링된 깊이 맵 및 상기 깊이 맵을 기반으로 제2 손실 함수를 결정하는 단계;상기 깊이 맵 및 상기 프레임 이미지의 컬러 이미지를 기반으로 제3 손실 함수를 결정하는 단계; 및제1 손실 함수, 제2 손실 함수 및 제3 손실 함수의 가중치 합을 기반으로 상기 신경망을 훈련하여 상기 장면의암시적 고밀도 맵 표현을 획득하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는,상기 프레임 이미지가 키 프레임인 경우,상기 고밀도 맵과 상기 고밀도 맵 내의 각 3차원 랜드마크 포인트의 신뢰도를 기반으로 상기 스파스 맵을 업데이트하는 단계공개특허 10-2025-0037344-5-를 더 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 스파스 맵을 업데이트하는 단계는, 상기 스파스 맵 내 하나의 3차원 랜드마크 포인트에 대해, 상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 신뢰도에 따라, 상기 하나의 3차원 랜드마크 포인트의 제1 가중치 및상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가중치를 결정하는 단계;결정된 상기 제1 가중치 및 상기 제2 가중치에 기초하여, 상기 하나의 3차원 랜드마크 포인트와 상기 고밀도 맵중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트를 융합하여, 상기 하나의 3차원 랜드마크 포인트를 업데이트하는 단계; 및상기 스파스 맵 내 각 3차원 랜드마크 포인트에 대해 상기 제1 가중치와 상기 제2 가중치를 결정하는 단계와 상기 하나의 3차원 랜드마크 포인트를 업데이트하는 단계를 수행하여 상기 스파스 맵을 업데이트하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터 판독가능 기록매체에 있어서,명령들을 저장하고,상기 명령들은, 하나 이상의 프로세서에 의하여 실행되는 경우, 제1항 내지 제12항의 방법을 수행하도록 하는컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "전자 장치에 있어서,하나 이상의 프로세서, 및명령들을 저장하는 메모리를 포함하고,상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 장치로 하여금,비디오의 프레임 이미지 및 상기 프레임 이미지에 대응하는 관성 측정 유닛의 데이터를 획득하는 단계; 및상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈(Position&Pose), 스파스 맵(sparse map) 및 고밀도 맵을 획득하는 단계를 수행하도록 하는 전자 장치."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계공개특허 10-2025-0037344-6-에서,상기 프레임 이미지가 키 프레임인 경우,상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈, 3차원 랜드마크 포인트(Three-Dimensional Landmark Point), 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 획득하는 단계;상기 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 3차원 랜드마크포인트, 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 전역 최적화를 수행하는 단계;최적화된 3차원 랜드마크 포인트로부터 상기 프레임 이미지에 대응하는 스파스 맵을 생성하는 단계; 및상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지에 기초하여 신경망을통해 상기 고밀도 맵을 얻는 단계를 수행하도록 하는 전자 장치."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계에서,상기 프레임 이미지가 비 키 프레임인 경우,상기 프레임 이미지 및 상기 프레임 이미지에 대응하는 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임이미지의 상기 카메라 위치와 포즈를 획득하는 단계; 및상기 프레임 이미지 이전의 이전 키 프레임에 대응하는 상기 스파스 맵과 상기 고밀도 맵을 상기 프레임 이미지에 대응하는 상기 스파스 맵과 상기 고밀도 맵으로 결정하는 단계를 수행하도록 하는 전자 장치."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우,상기 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 상기 3차원 랜드마크 포인트, 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 전역 최적화를 수행하는 단계에서,상기 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈 및 상기 3차원 랜드마크 포인트를 기반으로강건 커널(robust kernel) 함수 기반의 재투영 오차 함수를 구성하는 단계;상기 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈와 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 상기 관성 측정 유닛의 오차 함수를 구성하는 단계; 및상기 강건 커널 함수 기반의 재투영 오차 함수 및 상기 관성 측정 유닛의 오차 함수로 구성된 전역 최적화 타겟함수를 최소화하여, 상기 적어도 하나의 키 프레임에 대응하는 최적화된 카메라 위치와 포즈, 최적화된 3차원랜드마크 포인트 및 상기 관성 측정 유닛의 최적화된 속도 및 상기 관성 측정 유닛의 최적회된 편차를 획득하는단계공개특허 10-2025-0037344-7-를 수행하도록 하는 전자 장치."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계에서,상기 프레임 이미지가 비 키 프레임인 경우,상기 프레임 이미지 중 왼쪽 눈 이미지와 오른쪽 눈 이미지에 대해 스테레오 매칭을 수행하여 상기 프레임 이미지에 대응하는 양안 시차 맵을 획득하는 단계; 및상기 양안 시차 맵을 변환하여 상기 프레임 이미지에 대응하는 깊이 맵을 획득하는 단계를 수행하도록 하는 전자 장치."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로, 상기 신경망을 통해 상기 고밀도 맵을 획득하는 단계는,상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로 상기 신경망을 훈련하여, 양안 비디오에 대응하는 장면의 암시적 고밀도 맵 표현을 획득하는 단계; 및상기 획득한 암시적 고밀도 맵 표현에 상기 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 입력하여상기 고밀도 맵 및 상기 고밀도 맵 내 각 3차원 랜드마크 포인트의 신뢰도를 획득하는 단계를 수행하도록 하는 전자 장치."}
{"patent_id": "10-2024-0093793", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항에 있어서,상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는,상기 프레임 이미지가 키 프레임인 경우,상기 스파스 맵 내 하나의 3차원 랜드마크 포인트에 대해, 상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 신뢰도에 따라, 상기 하나의 3차원 랜드마크 포인트의 제1 가중치 및상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가중치를 결정하는 단계;결정된 상기 제1 가중치 및 상기 제2 가중치에 기초하여, 상기 하나의 3차원 랜드마크 포인트와 상기 고밀도 맵중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트를 융합하여, 상기 하나의 3차원 랜드마크 포인트를 업데이트하는 단계; 및상기 스파스 맵 내 각 3차원 랜드마크 포인트에 대해 상기 제1 가중치와 상기 제2 가중치를 결정하는 단계와 상기 하나의 3차원 랜드마크 포인트를 업데이트하는 단계를 수행하여 상기 스파스 맵을 업데이트하는 단계공개특허 10-2025-0037344-8-를 수행하도록 하는 전자 장치."}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 비디오의 프레임 이미지 및 상기 프레임 이미지에 대응하는 관성 측정 유닛의 데이터를 획득하고, 상 기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈(Position&Pose), 스파스 맵(sparse map) 및 고밀도 맵을 획득하는 전자 장치에 의해 수행되는 방법, 전자 장치 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하의 일 실시 예들은 위치 측정 및 매핑과 관련된 전자 장치에 의해 수행되는 방법, 전자 장치 및 저장 매체 에 관한 것이다."}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(AR; augmented reality)/가상 현실(VR; virtual reality) 분야에서 가장 일반적으로 사용되는 하드 웨어는 이미지 센서와 관성 측정 장치(IMU; inertial measurement unit) 센서가 있다. 이미지 센서는 현실 세계 의 이미지 정보를 실시간으로 수집할 수 있고, IMU 센서는 고주파 각속도 및 가속도 정보를 수집할 수 있다. 이 러한 정보를 기반으로 기존의 동시 위치 측정 및 매핑(SLAM; simultaneous localization and mapping) 기술은 일반적으로 장면의 특징점을 먼저 추출하고, 데이터 연관을 통해 위치를 측정한 후 스파스 맵(sparse map)을 구 축하며, 사전 훈련 모델 없이도 새로운 장면에 빠르게 적용할 수 있다. 그러나 SLAM 기술은 실시간 카메라 위치와 포즈(position&pose)를 얻기 위해 장면의 구조와 세부 사항을 인식할 수 없는 스파스 맵만 얻을 수 있으므로 특정 AR 인터랙션 영역에서는 현실과 가상의 상호 작용이 불가능하다. 예를 들어 실제 물체 뒤에 가상 물체를 배치하면 가상-현실 폐색(occlusion) 기능을 구현할 수 없다."}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 전자 장치에 의해 수행되는 방법, 전자 장치 및 저장 매체를 제공하는 것을 목적으로 한다. 본 개시의 일 실시 예에 따른 전자 장치에 의해 수행되는 방법은, 비디오의 프레임 이미지 및 상기 프레임 이미 지에 대응하는 관성 측정 유닛의 데이터를 획득하는 단계; 및 상기 프레임 이미지 및 상기 관성 측정 유닛의 데 이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈(Position&Pose), 스파스 맵(sparse map) 및 고밀도 맵을 획득하는 단계를 포함할 수 있다. 이때, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는, 상기 프레임 이미지가 키 프레임인 경우, 상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반 으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈, 3차원 랜드마크 포인트(Three-Dimensional Landmark Point), 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 획득하는 단계; 상기 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 3차원 랜드마크 포인트, 상기 관성 측 정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 전역 최적화를 수행하는 단계; 최적화된 3차원 랜드 마크 포인트로부터 상기 프레임 이미지에 대응하는 스파스 맵을 생성하는 단계; 및 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지에 기초하여 신경망을 통해 상기 고밀도 맵을 얻 는 단계를 포함할 수 있다. 이때, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는, 상기 프레임 이미지가 비 키 프레임인 경우, 상기 프레임 이미지 및 상기 프레임 이미지에 대응하는 상 기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지의 상기 카메라 위치와 포즈를 획득하는 단계; 및 상기 프레임 이미지 이전의 이전 키 프레임에 대응하는 상기 스파스 맵과 상기 고밀도 맵을 상기 프레임 이미지 에 대응하는 상기 스파스 맵과 상기 고밀도 맵으로 결정하는 단계를 포함할 수 있다. 이때, 상기 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 상기 3차 원 랜드마크 포인트, 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 전역 최적화를 수 행하는 단계는, 상기 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈 및 상기 3차원 랜드마크 포 인트를 기반으로 강건 커널(robust kernel) 함수 기반의 재투영 오차 함수를 구성하는 단계; 상기 적어도 하나 의 키 프레임에 대응하는 상기 카메라 위치와 포즈와 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 상기 관성 측정 유닛의 오차 함수를 구성하는 단계; 및 상기 강건 커널 함수 기반의 재투영 오차 함수 및 상기 관성 측정 유닛의 오차 함수로 구성된 전역 최적화 타겟 함수를 최소화하여, 상기 적어도 하나의 키 프레임에 대응하는 최적화된 카메라 위치와 포즈, 최적화된 3차원 랜드마크 포인트 및 상기 관성 측정 유닛 의 최적화된 속도 및 상기 관성 측정 유닛의 최적회된 편차를 획득하는 단계를 포함할 수 있다. 이때, 상기 강건 커널 함수는, 후버(Huber) 커널 함수를 포함할 수 있다. 이때, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는, 상기 프레임 이미지가 비 키 프레임인 경우, 상기 프레임 이미지에 대응하는 깊이 맵을 결정하는 단계 를 더 포함할 수 있다. 이때, 상기 프레임 이미지에 대응하는 상기 깊이 맵을 결정하는 단계는, 상기 프레임 이미지 중 왼쪽 눈 이미지 와 오른쪽 눈 이미지에 대해 스테레오 매칭을 수행하여 상기 프레임 이미지에 대응하는 양안 시차 맵을 획득하 는 단계; 및 상기 양안 시차 맵을 변환하여 상기 프레임 이미지에 대응하는 깊이 맵을 획득하는 단계를 포함할 수 있다. 이때, 상기 프레임 이미지 중 상기 왼쪽 눈 이미지와 상기 오른쪽 눈 이미지에 대해 스테레오 매칭을 수행하여 상기 프레임 이미지에 대응하는 상기 양안 시차 맵을 획득하는 단계는, 상기 프레임 이미지 이전의 이전 키 프 레임에 대응하는 고밀도 맵과 상기 프레임 이미지의 상기 왼쪽 눈 이미지 및 상기 오른쪽 눈 이미지에 따라 스 테레오 매칭을 수행하여 상기 양안 시차 맵을 얻는 단계를 포함할 수 있다. 이때, 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로, 상기 신경망을 통해 상기 고밀도 맵을 획득하는 단계는, 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응 하는 깊이 맵 및 상기 프레임 이미지를 기반으로 상기 신경망을 훈련하여, 양안 비디오에 대응하는 장면의 암시 적 고밀도 맵 표현을 획득하는 단계; 및 상기 획득한 암시적 고밀도 맵 표현에 상기 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 입력하여 상기 고밀도 맵 및 상기 고밀도 맵 내 각 3차원 랜드마크 포인트의 신 뢰도를 획득하는 단계를 포함할 수 있다. 이때, 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로 상 기 신경망을 훈련하여, 상기 양안 비디오에 대응하는 장면의 상기 암시적 고밀도 맵 표현을 획득하는 단계는, 상기 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 기반으로, 렌더링된 컬러 이미지와 렌더링된 깊 이 맵을 획득하는 단계; 상기 렌더링된 컬러 이미지 및 상기 프레임 이미지의 컬러 이미지를 기반으로 제1 손실 함수를 결정하는 단계; 상기 렌더링된 깊이 맵 및 상기 깊이 맵을 기반으로 제2 손실 함수를 결정하는 단계; 상 기 깊이 맵 및 상기 프레임 이미지의 컬러 이미지를 기반으로 제3 손실 함수를 결정하는 단계; 및 제1 손실 함 수, 제2 손실 함수 및 제3 손실 함수의 가중치 합을 기반으로 상기 신경망을 훈련하여 상기 장면의 암시적 고밀 도 맵 표현을 획득하는 단계를 포함할 수 있다. 이때, 상기 프레임 이미지에 대응하는 상기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는, 상기 프레임 이미지가 키 프레임인 경우, 상기 고밀도 맵과 상기 고밀도 맵 내의 각 3차원 랜드마크 포 인트의 신뢰도를 기반으로 상기 스파스 맵을 업데이트하는 단계를 더 포함할 수 있다. 이때, 상기 스파스 맵을 업데이트하는 단계는, 상기 스파스 맵 내 하나의 3차원 랜드마크 포인트에 대해, 상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 신뢰도에 따라, 상기 하 나의 3차원 랜드마크 포인트의 제1 가중치 및 상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하 는 3차원 랜드마크 포인트의 제2 가중치를 결정하는 단계; 결정된 상기 제1 가중치 및 상기 제2 가중치에 기초 하여, 상기 하나의 3차원 랜드마크 포인트와 상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트를 융합하여, 상기 하나의 3차원 랜드마크 포인트를 업데이트하는 단계; 및 상기 스파스 맵 내 각 3차원 랜드마크 포인트에 대해 상기 제1 가중치와 상기 제2 가중치를 결정하는 단계와 상기 하나의 3 차원 랜드마크 포인트를 업데이트하는 단계를 수행하여 상기 스파스 맵을 업데이트하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 컴퓨터 판독가능 기록매체는, 명령들을 저장하고, 상기 명령들은, 하나 이상의 프 로세서에 의하여 실행되는 경우, 비디오의 프레임 이미지 및 상기 프레임 이미지에 대응하는 관성 측정 유닛의 데이터를 획득하는 단계; 및 상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이 미지에 대응하는 카메라 위치와 포즈(Position&Pose), 스파스 맵(sparse map) 및 고밀도 맵을 획득하는 단계를 수행하도록 할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치는, 하나 이상의 프로세서, 및 명령들을 저장하는 메모리를 포함하고, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 장치로 하여금, 비디오의 프레임 이 미지 및 상기 프레임 이미지에 대응하는 관성 측정 유닛의 데이터를 획득하는 단계; 및 상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈(Position&Pose), 스파스 맵(sparse map) 및 고밀도 맵을 획득하는 단계를 수행하도록 할 수 있다. 이때, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상 기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계에서, 상기 프레임 이미지가 키 프 레임인 경우, 상기 프레임 이미지 및 상기 관성 측정 유닛의 데이터를 기반으로 상기 프레임 이미지에 대응하는 카메라 위치와 포즈, 3차원 랜드마크 포인트(Three-Dimensional Landmark Point), 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 획득하는 단계; 상기 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 3차원 랜드마크 포인트, 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유 닛의 편차를 기반으로 전역 최적화를 수행하는 단계; 최적화된 3차원 랜드마크 포인트로부터 상기 프레임 이미 지에 대응하는 스파스 맵을 생성하는 단계; 및 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지에 기초하여 신경망을 통해 상기 고밀도 맵을 얻는 단계를 수행하도록 할 수 있다. 이때, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상 기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계에서, 상기 프레임 이미지가 비 키 프레임인 경우, 상기 프레임 이미지 및 상기 프레임 이미지에 대응하는 상기 관성 측정 유닛의 데이터를 기반으 로 상기 프레임 이미지의 상기 카메라 위치와 포즈를 획득하는 단계; 및 상기 프레임 이미지 이전의 이전 키 프 레임에 대응하는 상기 스파스 맵과 상기 고밀도 맵을 상기 프레임 이미지에 대응하는 상기 스파스 맵과 상기 고 밀도 맵으로 결정하는 단계를 수행하도록 할 수 있다. 이때, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지를 포함하는 적 어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈, 상기 3차원 랜드마크 포인트, 상기 관성 측정 유 닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 전역 최적화를 수행하는 단계에서, 상기 적어도 하나의 키 프레임에 대응하는 상기 카메라 위치와 포즈 및 상기 3차원 랜드마크 포인트를 기반으로 강건 커널(robust kernel) 함수 기반의 재투영 오차 함수를 구성하는 단계; 상기 적어도 하나의 키 프레임에 대응하는 상기 카메 라 위치와 포즈와 상기 관성 측정 유닛의 속도 및 상기 관성 측정 유닛의 편차를 기반으로 상기 관성 측정 유닛 의 오차 함수를 구성하는 단계; 및 상기 강건 커널 함수 기반의 재투영 오차 함수 및 상기 관성 측정 유닛의 오 차 함수로 구성된 전역 최적화 타겟 함수를 최소화하여, 상기 적어도 하나의 키 프레임에 대응하는 최적화된 카 메라 위치와 포즈, 최적화된 3차원 랜드마크 포인트 및 상기 관성 측정 유닛의 최적화된 속도 및 상기 관성 측 정 유닛의 최적회된 편차를 획득하는 단계를 수행하도록 할 수 있다. 이때, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상 기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계에서, 상기 프레임 이미지가 비 키 프레임인 경우, 상기 프레임 이미지 중 왼쪽 눈 이미지와 오른쪽 눈 이미지에 대해 스테레오 매칭을 수행하여 상기 프레임 이미지에 대응하는 양안 시차 맵을 획득하는 단계; 및 상기 양안 시차 맵을 변환하여 상기 프레임 이미지에 대응하는 깊이 맵을 획득하는 단계를 수행하도록 할 수 있다. 이때, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 전역 최적화의 결과, 상기 프 레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기반으로, 상기 신경망을 통해 상기 고밀도 맵을 획 득하는 단계는, 상기 전역 최적화의 결과, 상기 프레임 이미지에 대응하는 깊이 맵 및 상기 프레임 이미지를 기 반으로 상기 신경망을 훈련하여, 양안 비디오에 대응하는 장면의 암시적 고밀도 맵 표현을 획득하는 단계; 및 상기 획득한 암시적 고밀도 맵 표현에 상기 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 입력하여 상기 고밀도 맵 및 상기 고밀도 맵 내 각 3차원 랜드마크 포인트의 신뢰도를 획득하는 단계를 수행하도록 할 수 있다. 이때, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프레임 이미지에 대응하는 상 기 카메라 위치와 포즈, 상기 스파스 맵 및 상기 고밀도 맵을 획득하는 단계는, 상기 프레임 이미지가 키 프레 임인 경우, 상기 스파스 맵 내 하나의 3차원 랜드마크 포인트에 대해, 상기 고밀도 맵 중 상기 하나의 3차원 랜 드마크 포인트에 대응하는 3차원 랜드마크 포인트의 신뢰도에 따라, 상기 하나의 3차원 랜드마크 포인트의 제1 가중치 및 상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가 중치를 결정하는 단계; 결정된 상기 제1 가중치 및 상기 제2 가중치에 기초하여, 상기 하나의 3차원 랜드마크 포인트와 상기 고밀도 맵 중 상기 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트를융합하여, 상기 하나의 3차원 랜드마크 포인트를 업데이트하는 단계; 및 상기 스파스 맵 내 각 3차원 랜드마크 포인트에 대해 상기 제1 가중치와 상기 제2 가중치를 결정하는 단계와 상기 하나의 3차원 랜드마크 포인트를 업 데이트하는 단계를 수행하여 상기 스파스 맵을 업데이트하는 단계를 수행하도록 할 수 있다."}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면을 참조하여 실시예들을 상세하게 설명한다. 그러나, 실시예들에는 다양한 변경이 가해 질 수 있어서 특허출원의 권리 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 실시예들에 대한 모든 변경, 균등물 내지 대체물이 권리 범위에 포함되는 것으로 이해되어야 한다. 실시예에서 사용한 용어는 단지 설명을 목적으로 사용된 것으로, 한정하려는 의도로 해석되어서는 안된다. 단 수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 개시에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조부호를 부여 하고 이에 대한 중복되는 설명은 생략하기로 한다. 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적 인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 실시 예의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 어느 하나의 실시 예에 포함된 구성요소와, 공통적인 기능을 포함하는 구성요소는, 다른 실시 예에서 동일한 명 칭을 사용하여 설명하기로 한다. 반대되는 기재가 없는 이상, 어느 하나의 실시 예에 기재한 설명은 다른 실시 예에도 적용될 수 있으며, 중복되는 범위에서 구체적인 설명은 생략하기로 한다. 본 개시의 실시예에서 제공하는 장치 또는 전자 장치 중 적어도 일부 기능은 인공 지능(AI; artificial intelligence) 모델을 통해 구현될 수 있고, 예를 들어 AI 모델을 통해 장치 또는 전자 장치의 복수의 모듈 중 적어도 하나의 모듈을 구현할 수 있다. AI와 관련된 기능은 비휘발성 메모리, 휘발성 메모리 및 프로세서에 의 해 수행될 수 있다. 해당 프로세서는 하나 이상의 프로세서를 포함할 수 있다. 이때, 해당 하나 이상의 프로세서는 범용 프로세서 (예, 중앙 처리 장치(CPU; central processing unit), 응용 프로세서(AP; application processor) 등) 또는 순 수 그래픽 처리 유닛(예, 그래픽 처리 유닛(GPU; graphics processing unit), 비전 처리 유닛(VPU; vision processing unit)), 및/또는 AI 전용 프로세서(예, 신경 처리 유닛(NPU; neural processing unit))일 수 있다.해당 하나 이상의 프로세서는 비휘발성 메모리 및 휘발성 메모리에 저장된 사전 정의된 동작 규칙 또는 인공 지 능(AI; artificial intelligence) 모델에 따라 입력 데이터의 처리를 제어한다. 훈련 또는 학습을 통해 사전 정 의된 동작 규칙 또는 인공 지능 모델을 제공한다. 여기서, 학습에 의한 제공은 복수의 학습 데이터에 학습 알고리즘을 적용하여 사전 정의된 동작 규칙 또는 원하 는 특성을 갖는 AI 모델을 얻는 것을 의미한다. 이러한 학습은 실시예에 따른 AI가 수행되는 장치 또는 전자 장 치 자체에서 수행될 수 있고, 및/또는 별도의 서버/장치/시스템에 의해 구현될 수 있다. AI 모델은 복수의 신경망 레이어로 구성될 수 있다. 각 레이어는 복수의 가중치 값을 가지며, 각 레이어는 해당 레이어의 입력 데이터(예, 이전 레이어의 계산 결과 및/또는 AI 모델의 입력 데이터)와 현재 레이어의 복수의 가중치 값 사이를 계산하여 신경망 계산을 수행한다. 신경망의 예시로, 컨볼루션 신경망(CNN; convolutional neural network), 심층 신경망(DNN; deep neural network), 순환 신경망(RNN; recurrent neural network), 제 한된 볼츠만 머신(RBM; restricted boltzmann machine), 심층 신뢰망(DBN; deep belief network), 양방향 순환 심층 신경망(BRDNN; bidirectional recurrent deep neural network), 생성 대응 네트워크(GAN; generative adversarial network) 및 심층 Q 네트워크를 포함하나 이에 제한되지 않는다. 학습 알고리즘은 복수의 학습 데이터를 이용하여 소정의 타겟 장치(예, 로봇)를 훈련시켜 타겟 장치를 결정 또 는 예측하도록 유도, 허용 또는 제어하는 방법이다. 해당 학습 알고리즘의 예시는 지도 학습(supervised learning), 비지도 학습, 반 지도 학습 또는 강화 학습을 포함하나 이에 국한되지는 않는다. 본 개시에서 제공하는 방법은 음성, 언어, 이미지, 비디오 또는 데이터 인텔리전스 등 기술 분야 중 하나 또는 여러 분야와 관련될 수 있다. 선택적으로, 음성 또는 언어 분야와 관련하여, 본 개시에 따른 전자 장치에 의해 수행되는 방법에서, 음성 신호 는 음성 입력 장치(예를 들어, 마이크)를 통해 아날로그 신호로 수신될 수 있고, 자동 음성 인식(ASR; automatic speech recognition) 모델을 사용하여 음성 부분을 컴퓨터가 읽을 수 있는 텍스트로 변환한다. 자연 어 이해(NLU; natural language understanding) 모델을 이용하여 변환된 텍스트를 해석함으로써 사용자의 발화 의도를 얻을 수 있다. ASR 모델 또는 NLU 모델은 인공 지능 모델일 수 있다. 인공지능 모델은 인공지능 모델 처 리를 위해 지정된 하드웨어 아키텍처로 설계된 인공지능 전용 프로세서에 의해 처리될 수 있다. 언어 이해는 자 연어 처리, 기계 번역, 대화 시스템, 질의응답 또는 음성 인식/합성 등 인간의 언어/텍스트를 인식하고 적용/처 리하는 기술이다. 선택적으로, 이미지 또는 비디오 분야와 관련하여, 본 개시에 따른 전자 장치에 의해 수행되는 방법에서, 이미 지 데이터를 인공 지능 모델의 입력 데이터로 사용하여 출력 데이터를 얻을 수 있다. 본 개시의 방법은 인간의 시야각과 같은 것을 인식하고 처리하는 기술인 시야각적 이해를 위한 인공지능 기술 분야와 관련될 수 있으며, 예를 들어, 대상 인식, 대상 추적, 이미지 검색, 사람 인식, 장면 인식, 3차원 재구성/포지셔닝 또는 이미지 향 상을 포함할 수 있다. 선택적으로, 데이터 지능 처리 분야와 관련하여, 본 개시에 따른 전자 장치에 의해 수행되는 방법에서, 추론 또 는 예측 단계에서, 실시간 입력 데이터를 이용하여 예측을 수행하기 위해 인공지능 모델을 사용할 수 있다. 전 자 장치의 프로세서는 데이터에 대한 전처리 작업을 수행하여 인공지능 모델의 입력으로 사용하기에 적합한 형 태로 변환할 수 있다. 추론 예측은 정보를 판단하여 논리적 추론 및 예측을 수행하는 기술로, 예를 들어 지식 기반 추론, 최적화 예측, 선호도 기반의 계획 또는 추천을 포함한다. 본 개시에서, AI 모델은 훈련을 통해 얻을 수 있다. 여기서 '훈련을 통해 얻는' 것은 훈련 알고리즘을 통해 여 러 훈련 데이터로 기본 인공지능 모델을 훈련시켜 미리 정의된 운영 규칙 또는 필요한 특징(또는 목표)을 실행 하도록 구성된 인공지능 모델을 훈련시키는 것을 의미한다. AI 모델은 복수의 신경망 레이어를 포함할 수 있다. 복수의 신경 네트워크 레이어 각각은 복수의 가중치 값을 포함하고, 신경 네트워크 계산은 이전 레이어의 계산 결과와 복수의 가중치 값 간의 계산으로 수행된다. 배경 기술 부분에서 설명한 것과 같이, 현재 가상 및 실제 폐색 기능을 달성하기 위해 카메라 위치와 포즈와 고 밀도 맵을 얻을 수 있는 일부 알고리즘이 존재하나, 이러한 알고리즘으로 얻은 카메라 위치와 포즈와 고밀도 맵 의 정확도는 낮은 편이며, 심지어 CPU 또는 터미널에서의 실시간 실행이 불가능하다. 예를 들어, ORB 특징 및 NeRF 실현 매핑을 갖는 실시간 단안 시야각 SLAM(Real-time Monocular Visual SLAM with ORB Features and NeRF-realized Mapping，Orbeez-SLAM) 알고리즘은 기존 SLAM(simultaneouslocalization and mapping) 알고리즘을 바탕으로 NeRF(neural radiance fields) 네트워크와 결합하여 카메라 위치와 포즈와 고밀도 맵을 실시간으로 출력할 수 있다. 해당 알고리즘은 기존의 SLAM을 활용하여 실시간 카메 라 위치와 포즈와 스파스 맵을 출력하고, 이러한 데이터와 해당 RGB 이미지를 입력으로 취하고, NeRF 방식을 사 용하여 다층 퍼셉트론(MLP; multilayer perceptron) 네트워크의 구조를 학습하여 3차원 장면의 암시적 표현을 학습할 수 있도록 한다. 이런 경우, 해당 3차원 장면의 암시적 표현을 기반으로, 하나의 시야각이 주어지면 NeRF 네트워크는 해당 시야각 하에서의 RGB 이미지를 출력할 수 있다. 그러나, 차별적 반복 최적화 영감 디자인 -SLAM(Differentiable Recurrent Optimization-Inspired Design-SLAM, Orbeez-SLAM) 알고리즘은 심층 융합 없 이 텔레포트 SLAM 알고리즘과 NeRF 네트워크를 단순히 추가한 것일 뿐이다. 구체적으로, Orbeez-SLAM 알고리즘 은 NeRF 네트워크가 얻은 고밀도 맵을 SLAM 알고리즘의 위치와 포즈 계산 및 스파스 맵 재구성에 적용하지 않는 다. 또 예를 들어, NeRF-SLAM 알고리즘은 딥러닝 기반의 SLAM 알고리즘인 Droid-SLAM과 NeRF 네트워크를 엔드투엔드 딥 프레임워크로 통합하고, 해당 NeRF-SLAM 알고리즘은 Dorid-SLAM에서 얻은 고밀도 깊이 맵의 출력을 활용하여 NeRF 네트워크를 감독한다. 구체적으로, NeRF-SLAM 알고리즘은 입력된 단안 비디오 스트림을 기반으로, 해당 NeRF-SLAM 알고리즘은 컨볼루션 게이트 순환 유닛(GRU)을 통해 광학 스트림과 광학 스트림의 신뢰도를 구한 다 음, 헤시안(Hessian) 행렬을 구성하고 제곱근법(즉, Cholesky)을 통해 분해하여 상대 위치 및 포즈와 위치와 포 즈의 신뢰도를 구한다. 그런 다음, NeRF-SLAM 알고리즘은 이렇게 얻은 데이터를 훈련을 위해 NeRF 네트워크에 입력하고, 해당 NeRF 네트워크는 RGB 이미지 및 깊이를 이용하여 감독한다. NeRF-SLAM 알고리즘은 카메라 위치 와 포즈와 고밀도 암시적 맵을 모두 출력할 수 있지만, NeRF-SLAM 알고리즘은 딥러닝 기반의 SLAM 알고리즘인 Droid-SLAM과 NeRF 네트워크를 엔드투엔드 심도 프레임워크로 통합하기 때문에 CPU나 단말에서 실시간으로 실행 할 수 없다. 종래의 SLAM 알고리즘으로 얻은 카메라 위치와 포즈, 암시적 고밀도 맵 표현, 고밀도 맵 및/또는 스파스 맵의 정확도를 더욱 향상시키기 위해, 본 개시의 일부 실시예는 종래의 SLAM 알고리즘, 양안 깊이 추정 및 NeRF 방법 을 심층 융합하는 아이디어를 제안한다. 이하에서는, 본 개시의 일 실시 예에 따른 전자 장치에 의해 수행되는 방법, 전자 장치 및 저장 매체를 첨부된 도 1 내지 도 5를 참조하여 상세히 설명한다. 이하 구현 방법은 상호 참고, 참조 또는 결합될 수 있으며, 상이 한 구현 방법 중 동일한 용어, 유사한 기능 및 유사한 구현 단계 등에 대해서는 반복 설명하지 않는다. 도 1은 일 실시예에 따른 전자 장치에 의해 수행되는 개략적인 방법을 도시한 흐름도이다. 도 1을 참조하면, 110단계에서, 전자 장치는 비디오 내 프레임 이미지 및 해당 프레임 이미지에 대응하는 관성 측정 장치(IMU; inertial measurement unit)의 데이터(IMU 데이터 스트림 등으로도 칭함)를 획득할 수 있다. 여기서 비디오는 양안 카메라 등을 이용하여 하나의 장면을 촬영하여 얻어지는 양안 비디오일 수 있다. 본 개시 에서는 양안 비디오는 또한 양안 비디오 스트림, 입체 비디오 스트림, 입체 비디오 등으로도 불릴 수 있다. 또 한, 본 개시에서 프레임 이미지는 좌안 이미지 및 우안 이미지를 포함할 수 있다. 120단계에서, 전자 장치는 프레임 이미지 및 IMU의 데이터에 기초하여, 프레임 이미지에 대응하는 카메라 위치 와 포즈, 스파스 맵 및 고밀도 맵을 획득할 수 있다. 본 개시의 실시예에서, 프레임 이미지는 키 프레임 또는 비 키 프레임(일반 프레임 등이라고도 함)일 수 있다. 본 개시의 실시예에서, SLAM 관련 기술과 관련된 임의의 공지된 키 프레임 선택 방법 및 향후 등장할 키 프레임 선택 방법을 사용하여 양안 비디오에서 키 프레임 및 비 키 프레임을 결정할 수 있고, 본 개시는 이에 대해 제 한하지 않는다. 이하, 도 2를 참조하여 프레임 이미지가 각각 키 프레임 및 비 키 프레임인 경우, 프레임 이미지 및 프레임 이 미지에 대응하는 IMU의 데이터에 기반하여 프레임 이미지에 대응하는 카메라 위치와 포즈, 스파스 맵 및 고밀도 맵을 얻는 과정에 대해 설명한다. 도 2는 일 실시예에 따른 전자 장치에 의해 수행되는 상세한 방법을 도시한 흐름도이다. 도 3은 일 실시예에 따른 전자 장치에 의해 수행되는 방법에 대응하는 시스템을 도시한 예시도이다. 구체적으로, 도 1 및 도 2에 도시된 방법은 도 3에 도시된 전자 장치에 의해 실행될 수 있으며, 해당 전자 장치는 주로 4개의 주요 모듈, 즉 추적 모듈, 스파스 맵 모듈, 양안 깊이 추정 모듈 및 신 경 고밀도 맵 모듈을 포함할 수 있고, 이들은 서로 다른 스레드에 의해 실행될 수 있다.먼저, 110단계에서, 전자 장치는 비디오의 프레임 이미지와 프레임 이미지에 대응하는 IMU의 데이터를 획 득한다. 도 3에 도시된 바와 같이, 비디오의 프레임 이미지와 IMU의 데이터가 도 3의 전자 장치로 입력된 다. 110단계는 도 1을 참조하여 상세히 설명하였으므로, 여기서 더는 반복하지 않는다. 210단계에서, 전자 장치는 프레임 이미지가 키 프레임인지 또는 비 키 프레임인지 여부를 결정할 수 있다. 전자 장치는 프레임 이미지가 키 프레임인 경우, 220단계 내지 224단계를 실행할 수 있다. 즉, 프레임 이 미지가 키 프레임인 경우, 도 1의 120단계는 220단계 내지 224단계를 포함할 수 있다. 먼저, 220단계에서, 전자 장치는 프레임 이미지 및 프레임 이미지에 대응하는 IMU의 데이터에 기초하여 프 레임 이미지에 대응하는 카메라 위치와 포즈, 3차원 랜드마크 포인트(Three-Dimensional Landmark Point) 및 IMU의 속도 및 IMU의 편차를 획득할 수 있다. 본 개시에서, 프레임 이미지에 대응하는 3차원 랜드마크 포인트는 해당 프레임 이미지로부터 관측 가능한 3차원 랜드마크 포인트를 의미할 수 있다. 또한, 본 개시에서 3차원 랜 드마크 포인트는 3차원 포인트(Three-Dimensional Point) 등으로 지칭될 수 있다. 도 3에 도시된 바와 같이, 비디오의 프레임 이미지와 프레임 이미지에 대응하는 IMU의 데이터는 추적 모듈(31 0)로 입력된다. 추적 모듈은 특징점 검출 및 매칭 모듈, IMU 사전 통합 모듈, 특징 재식별 모듈 , 슬라이딩 윈도우 기반의 BA(Bundle Adjustment) 모듈을 포함할 수 있다. 구체적으로, 특징점 검출 및 매칭 모듈은 입력된 비디오의 프레임 이미지에서 특징점 검출을 수행한 후, 프레임 이미지의 좌안 이미 지와 우안 이미지에서 검출된 특징점을 매칭할 수 있다. IMU 사전 통합 모듈은 프레임 이미지에 대응하는 IMU 데이터에 대해 사전 통합 작업을 수행하며, 이에 따라 IMU 속도 및 편차를 획득할 수 있다. 특징 재식별 모 듈은 새로 검출된 특징점이 전역의 스파스 맵의 점인지 여부를 식별하고, 새로 추출된 특징점이 스파스 맵 의 점인 경우 스파스 맵과 연관시키고, 그렇지 않은 경우 스파스 맵과 연관시키는 작업을 수행하지 않을 수 있 다. 해당 작업은 알고리즘의 정확도를 효과적으로 향상시킬 수 있으며, 본 개시에서, 스파스 맵은 전역적으로 일관된 맵으로서, 후속 설명에서 설명하는 스파스 맵 모듈에서 최적화되거나 및/또는 업데이트될 수 있다. 그 후, 슬라이딩 윈도우 기반의 BA 모듈은 시간 영역 내의 연속 비디오 프레임, 3차원 랜드마크 포인트 및 이 기간 내의 IMU의 데이터에 대해 BA 최적화를 수행하여, 시간 영역이 일관된 카메라 위치와 포즈를 획득할 수 있다. 여기서, 연속 비디오 프레임은 키 프레임 및/또는 비 키 프레임을 포함할 수 있다. 그리고, 3차원 랜드마 크 포인트는 스파스 맵의 랜드마크 포인트뿐만 아니라 프레임 이미지에 대해 삼각화하여 얻은 3차원 랜드마크 포인트를 포함할 수 있다. 추적 모듈은 상술한 프로세스에 따라 양안 비디오의 각 프레임에 대해 작업을 수행하여 각 프레임에 대한 카메라 위치와 포즈를 획득함으로써, 양안 비디오에 대한 프레임 주파수의 카메라 위치와 포즈를 획득할 수 있다. 이런 경우, IMU 사전 통합 모듈의 출력 결과와 윈도우 기반의 BA 모듈 에 의해 출력된 프레임 주파수의 카메라 위치와 포즈(예를 들어, 30Hz의 6 자유도(DoF) 카메라 위치와 포 즈)를 기반으로, IMU 주파수의 카메라 위치와 포즈(예를 들어, 1 KHz에서 6-DoF 카메라 위치와 포즈)를 획득할 수 있다. 예를 들어, IMU 주파수의 카메라 위치와 포즈는 보간 방법을 통해 획득될 수 있으나, 본 개시는 이에 대해 제한하지 않으며, 다른 방법을 사용할 수도 있다. 또한, 추적 모듈은 또한 각각의 프레임으로부터 관찰된 새로운 3차원 랜드마크 포인트(구체적으로, 랜드마 크 포인트의 3차원 좌표)를 획득할 수 있고(예를 들어, 동시에 획득할 수 있음), 추적된 특징점의 수에 따라 키 프레임을 결정할 수 있다. 예를 들어, 추적 모듈은 하나의 프레임 내 추적된 특징점의 수가 소정의 임계값 보다 작으면(이때, 해당 임계값은 설정 가능함), 해당 하나의 프레임을 키 프레임으로 결정할 수 있고, 그렇지 않는 경우 해당 하나의 프레임을 비 키 프레임으로 결정할 수 있다. 즉, 추적 모듈은 양안 비디오 내의 각 프레임을 키 프레임 및 비 키 프레임으로 결정(또는 선택)할 수 있다. 설명을 통해 추적 모듈은 각 프레임의 카메라 위치와 포즈, 관측 가능한 3차원 랜드마크 포인트, IMU의 속 도 및 IMU의 편차를 결정할 수 있다. 상술한 추적 모듈은 기존의 SLAM 알고리즘 내 추적 알고리즘을 채택 할 수 있다. 예를 들어, Oriented FAST and Rotated BRIEF-SLAM(ORB-SLAM), Open Keyframe-based Visual- Inertial SLAM(OKVIS) 등이 있고, 이에 대해 본 개시는 관련 내용에 대해 중복 설명하지 않는다. 222단계에서, 전자 장치는 프레임 이미지를 포함하는 적어도 하나의 키 프레임에 대응하는 카메라 위치와 포즈, 3차원 랜드마크 포인트, IMU 속도 및 편차에 기초하여 전역 최적화를 수행할 수 있다. 도 3에 도시된 바 와 같이, 스파스 맵 모듈의 전역 최적화 모듈은 프레임 이미지를 포함하는 적어도 하나의 키 프레임 에 대응하는 카메라 위치와 포즈, 3차원 랜드마크 포인트(즉, 현재 스파스 맵의 3차원 랜드마크 포인트), 및 IMU의 속도 및 IMU의 편차를 사용하여 전역 최적화를 수행할 수 있다. 그 결과 전역 최적화 모듈은 적 어도 하나의 키 프레임에 대응하는 최적화된 3차원 랜드마크 포인트, 최적화된 카메라 위치와 포즈 및 최적화된IMU의 속도 및 최적화된 IMU의 편차를 획득할 수 있다. 이때, 현재 입력된 프레임 이미지에 대응하는 스파스 맵 은 최적화된 3차원 랜드마크 포인트에 기초하여 생성될 수 있다. 구체적으로, 222단계는 적어도 하나의 키 프레임에 대응하는 카메라 위치와 포즈 및 3차원 랜드마크 포인트를 기반으로 강건 커널(robust kernel) 함수 기반의 재투영 오차 함수를 구성하고, 적어도 하나의 키 프레임에 대 응하는 카메라 위치와 포즈와 IMU의 속도 및 IMU의 편차를 기반으로 IMU 오차 함수를 구성하고, 강건 커널 함수 기반의 재투영 오차 함수 및 IMU 오차 함수로 구성된 전역 최적화 타겟 함수를 최소화하여, 적어도 하나의 키 프레임에 대응하는 최적화된 카메라 위치와 포즈, 최적화된 3D 랜드마크 포인트 및 최적화된 IMU의 속도 및 최 적화된 IMU의 편차를 획득할 수 있다. 이때, 120단계에서 획득한 프레임 이미지에 대응하는 스파스 맵은 최적화 된 3차원 랜드마크 포인트에 따라 생성될 수 있다. 구체적으로, 전자 장치는 아래 <수학식 1> 같이, 적어도 하나의 키 프레임에 대응하는 카메라 위치와 포즈 및 3차원 랜드마크 포인트에 기초하여, 강건 커널 함수 기반의 재투영 오차 함수를 구성할 수 있다: [수학식 1]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, E1는 재투영 오차 함수를 나타내고, km는 적어도 하나의 키 프레임의 개수를 나타내고, k1는 제1 키 프 레임을 나타내고, Vi는 I 번째 키 프레임에서 새로 생성된 3차원 랜드마크 포인트의 인덱스 세트(예, I 번째 키 프레임 중 새로 나타날 수 있는 3차원 랜드마크 포인트의 인덱스 집합)를 나타내고, Eij는 I 번째 키프레임에서 j 번째 3차원 랜드마크 포인트의 재투영 오차를 나타내고, Ti는 i 번째 키 프레임에 대응하는 카메라 위치와 포 즈를 나타내고, Tsj는 sj번째 키 프레임에 대응하는 카메라 위치와 포즈를 나타내고, Xj는 j 번째 3차원 랜드마 크 포인트의 3차원 좌표를 나타낼 수 있다. 본 개시의 예시적 실시예에서, 재투영 오차 함수를 구성할 때, 본 개시는 안정성을 향상시키기 위해 강건 커널 함수를 사용하고, 구성된 재투영 오차 함수는 강건 커널 함수(예, Huber 함수)에 기반할 수 있고, 구체적인 계 산 과정은 아래 <수학식 2>와 같고, <수학식 3>은 후버 함수의 정의이다. 이때, b는 0보다 큰 실수로 설정될 수 있는 하이퍼 파라미터이다. 예를 들어 1로 설정될 수 있다. [수학식 2]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[수학식 3]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, zk는 k 번째 키 프레임의 측정(즉, k 번째 키 프레임의 특징점)을 나타내고, 은 Mahalanobis 거리 함수를 나타내고, 는 정보 행렬을 나타낸다. 본 개시의 실시예에서 후버 커널 함수를 사용하여 모든 특징점 의 재투영 오차에 작용함으로써, 최적화에 대한 이상점의 영향을 줄일 수 있다. 또는, 본 개시는 아래 <수학식 4>와 같이, 적어도 하나의 키 프레임에 대응하는 카메라 위치와 포즈와 IMU의 속 도 및 IMU의 편차를 기반으로 IMU 오차 함수를 구성할 수 있다. [수학식 4]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, E2는 IMU 오차 함수를 나타내고, 는 i 번째 키 프레임과 i+1번째 키 프레임의 IMU 오차를 나타내 고, Mi와 Mi+1은 각각 i 번째 키 프레임에 대응하는 IMU 속도와 편차 및 i+1번째 키 프레임에 대응하는 IMU 속도 와 편차를 나타내고, Ti와 Ti+1는 각각 i 번째 키 프레임에 대응하는 카메라 위치와 포즈 및 i+1번째 키 프레임 에 대응하는 카메라 위치와 포즈를 나타낸다. 그런 다음, 본 개시는 아래 <수학식 5>와 같이 강건 커널 함수에 기반한 재투영 오차 함수와 IMU 오차 함수로 전역 최적화 타겟 함수를 구성할 수 있다. [수학식 5]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "<수학식 5>에 도시된 전역 최적화 타겟 함수의 최적화량은 적어도 하나의 키 프레임(현재 프레임 이미지 포함) 에 대응하는 카메라 위치와 포즈, IMU의 속도, IMU의 편차 및 3차원 랜드마크 포인트를 포함하며, 이런 경우 전 역 최적화 타겟 함수의 최소화를 통해 <수학식 5>의 해를 구하고, 이를 통해 적어도 하나의 키 프레임에 대응하 는 최적화된 카메라 위치와 포즈 및 최적화된 3차원 랜드마크 포인트를 획득할 수 있다. 또한, 현재의 프레임의 이미지에 대응하는 스파스 맵(예, 이 때의 전역 스파스 맵)은 최적화된 3차원 랜드마크 포인트에 따라 생성될 수 있다. 도 2를 다시 참조하면, 224단계에서, 전자 장치는 전역 최적화 결과, 프레임 이미지에 대응하는 깊이 맵 및 프레임 이미지를 기반으로 신경망을 통해 고밀도 맵을 획득할 수 있다. 224단계를 수행하기 전, 전자 장치는 프레임 이미지에 대응하는 깊이 맵을 결정할 수도 있다. 예를 들어, 전자 장치는 먼저 프레임 이미지에서 좌안 이미지와 우안 이미지의 스테레오 매칭을 수행하여 프레임 이미지에 대응하는 양안 시차 맵을 획득할 수 있다. 여기서 해당 양안 시차 맵은 프레임 이미지의 해상 도와 동일한 해상도를 갖을 수 있다. 양안 비디오의 임의의 키 프레임에 대해, 해당 키 프레임에 대응하는 깊이 맵을 결정할 때, 양안 깊이 추정 모 듈은 해당 키 프레임에서 좌안 이미지와 우안 이미지에 대해 직접 스테레오 매칭을 수행함으로써 해 당 키 프레임에 대응하는 양안 시차 맵을 얻을 수 있다. 예를 들어, 양안 깊이 추정 모듈은 양안 깊 이 추정 네트워크를 통해 스테레오 매칭을 수행하여 양안 시차 맵을 획득한 후, 획득한 양안 시차 맵 의 변환(후술 예정)을 수행하여 프레임 이미지에 대응하는 깊이 맵을 획득할 수 있다. 그러나, 본 개시는 이에 한정되지 않으며, 프레임 이미지에서 좌안 이미지와 우안 이미지의 스테레오 매칭을 수 행하여 프레임 이미지에 대응하는 양안 시차 맵을 획득하는 단계는, 프레임 이미지 이전의 이전 키 프레임에 대 응하는 고밀도 맵과 프레임 이미지의 왼쪽 눈 이미지 및 오른쪽 눈 이미지에 따라 스테레오 매칭을 수행하여 양 안 시차 맵을 얻는 단계를 포함할 수 있다. 구체적으로, 도 3에 도시된 바와 같이, 프레임 이미지 이전의 이전 키 프레임에 대응하는 고밀도 맵을 양안 깊이 추정 모듈로 피드백하고, 그런 다음 양안 깊이 추정 모듈 은 해당 이전 키 프레임에 대응하는 고밀도 맵과 현재 프레임 이미지 내의 좌안 이미지 및 우안 이미지를 기반으로 스테레오 매칭을 수행하여 현재 프레임 이미지에 대응하는 양안 시차 맵을 획득할 수 있다. 여기서, 이전 키 프레임에 대응하는 고밀도 맵은 해당 이전 키 프레임을 후술할 신경 고밀도 맵 모듈을 통 해 얻어지는 암시적 고밀도 맵 표현에 입력하여 획득되어질 수 있다. 그런 다음, 해당 양안 시차 맵은 후 술할 변환 작업을 통해 보다 정확한 장면 구조 정보를 갖는 깊이 맵으로 변환도리 수 있다. 이후 해당 깊이 맵 은 신경 고밀도 맵 모듈에 입력되어 신경 고밀도 맵 모듈이 획득한 고밀도 맵이 보다 정확한 깊이 정보를 갖도록 할 수 있다. 구체적으로, 전자 장치는 아래 <수학식 6>을 통해 양안 시차 맵을 변환하여 대응하는 깊이 맵을 획득할 수 있다. [수학식 6] z=lf/d 여기서, z는 깊이를 나타내고, l은 양안 비디오를 얻는데 사용되는 양안 카메라의 광학 중심 사이의 거리를 나 타내며, d는 시차를 나타내고, f는 양안 카메라의 초점 거리를 나타낸다. 본 개시에서, 222단계 및 프레임 이미지에 대응하는 깊이 맵을 획득하는 단계의 실행 순서는 특별히 제한되지 않으며, 실행 순서는 상호 교환될 수 있다. 이상, 프레임 이미지에 대응하는 깊이 맵을 얻는 과정을 설명한 것이며, 224단계는 아래에서 자세히 설명한다. 구체적으로, 224단계는 전역 최적화의 결과, 프레임 이미지에 대응하는 깊이 맵 및 프레임 이미지를 기반으로 신경망을 훈련하여, 양안 비디오에 대응하는 장면의 암시적 고밀도 맵 표현을 획득하는 단계, 획득한 암시적 고 밀도 맵 표현에 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 입력하여 고밀도 맵 및 고밀도 맵 내 각 3차원 랜드마크 포인트의 신뢰도를 획득하는 단계를 포함할 수 있다. 도 3에 도시된 바와 같이, 현재 입력된 프레임 이미지에 대해, 스파스 맵 모듈은 해당 프레임 이미지의 최 적화된 카메라 위치와 포즈뿐만 아니라 해당 프레임 이미지(즉, 해당 프레임 이미지의 컬러 이미지)을 신경 고 밀도 맵 모듈에 입력할 수 있다. 이에 따라 양안 깊이 추정 모듈은 해당 프레임 이미지에 대응하는 깊이 맵을 신경 고밀도 맵 모듈에 입력할 수 있다. 이런 경우, 신경 고밀도 맵 모듈의 신경망(이하 신경 방사장 NeRF라 함)은 수신된 이러한 정보를 기반으로 온라인 상에서 양안 비디오에 대응하는 장면을 학습 하여 네트워크에 암묵적으로 해당 장면을 표현함으로써 해당 장면의 암시적 고밀도 맵 표현을 얻을 수 있다. 이 하, 도 4를 참조하여 신경 방사장 NeRF의 훈련 과정에 대해 설명한다. 도 4는 일 실시예에 따른 신경 방사장에 의한 학습 방법을 도시한 예시도이다. 도 4를 참조하면, 본 개시의 학습 방법은 먼저 현재 입력된 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈를 기반으로 렌더링된 컬러 이미지와 렌더링된 깊이 맵을 획득한다. 구체적으로, 광선 샘플러 는 프레임 이미지에 대응하는 최적화된 카메라 위치와 포즈의 위치 정보와 시야각 정보를 인코 딩하여, 위치 정보에 대응하는 해시 인코딩 결과와 시야각 정보에 대응하는 방향 인코딩 결과를 얻고, 이후 이 러한 인코딩 결과를 암시적 맵 네트워크(즉, NeRF 네트워크)에 입력하여 렌더링을 수행함으로써 렌더링된 컬러 이미지와 렌더링된 깊이 맵을 획득할 수 있다. 그리고, 본 개시의 학습 방법은 렌더링된 컬러 이미지와 프레임 이미지의 컬러 이미지에 기초하여 제 1 손실 함수를 결정한다. 구체적으로, 제1 손실 함수는 RGB 손실( )을 나타낼 수 있다. RGB 손 실은 렌더링된 컬러 이미지와 프레임 이미지의 컬러 이미지 사이의 L-1 표준(norm)일 수 있고, 아래의 <수학식 7>과 같이 표현될 수 있다. [수학식 7]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, I는 프레임 이미지의 컬러 이미지를 나타내고, 는 렌더링된 컬러 이미지를 나타낸다. 즉 카메라 위치와 포즈 T와 에 대응하는 렌더링된 컬러 이미지를 나타내고, 는 암시적 맵 네트워크(즉, NeRF 네트워크)의 파라미터를 나타낸다. 그리고, 본 개시의 학습 방법은 렌더링된 깊이 맵과 프레임 이미지의 대응하는 깊이 맵에 기초하여 제2 손실 함수를 결정할 수 있다. 구체적으로, 제2 손실 함수는 깊이 손실( )을 나낼 수 있다.깊이 손실은 렌더링된 깊이 맵과 프레임 이미지의 양안 깊이 추정 모듈에 의해 추정된 깊이 맵 사이의 L-1 표준(norm)일 수 있고, 아래의 <수학식 8>과 같이 표현될 수 있다. [수학식 8]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 은 양안 깊이 추정 모듈에 의해 추정된 프레임 이미지에 대응하는 깊이 맵을 나 타낸다. 즉 카메라 위치와 포즈 T와 에 대응하는 프레임 이미지에 대응하는 깊이 맵을 나타내고, 은 양안 깊이 추정 모듈의 깊이 추정 네트워크의 파라미터를 나타낸다. 은 렌더링된 깊이 맵, 즉 카메라 위치와 포즈 T와 에 대응하는 렌더링된 깊이 맵을 나타낸다. 그리고, 본 개시의 학습 방법은 프레임 이미지에 대응하는 깊이 맵과 프레임 이미지의 컬러 이미지를 기반으로 제3 손실 함수를 결정할 수 있다. 구체적으로, 제3 손실 함수는 다른 이미지의 변환 후 대응 포인트의 RGB 차이 값을 계산하기 위한 기하학적 변환 손실( )을 나타낼 수 있다. 예를 들어, 기하학 적 변환 손실은 m 번째 프레임 이미지의 픽셀 포인트 qm=(u,v)를 n 번째 프레임 이미지로 변환할 때(이때, u와 v는 각각 m 번째 프레임 이미지의 수평 좌표 및 수직 좌표를 나타냄), 양안 깊이 추정 모듈에 의해 추 정된 깊이 맵과 두 프레임 이미지의 상대적 위치와 포즈를 기반으로 픽셀 포인트qm의 3차원 좌표를 계산한 후, 해당 픽셀 포인트를 n 번째 프레임 이미지에 투영하여 기하학적 변환 후의 프레임(Iwarp)을 획득할 수 있다. 본 개시에서, 아래 <수학식 9>에 따라 제3 손실 함수를 계산할 수 있다. [수학식 9]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "그런 다음, 본 개시의 학습 방법은 제1 손실 함수, 제2 손실 함수 및 제3 손실 함수의 가중치 합에 기초하여 신 경망을 훈련(예, 온라인 학습)하여, 양안 비디오에 해당하는 장면의 암시적 고밀도 맵 표현을 획득할 수 있다. 예를 들어, 본 개시의 학습 방법은 아래 <수학식 10>에 따라 제1 손실 함수, 제2 손실 함수 및 제3 손실 함수의 가중 합을 수행하여 NeRF 네트워크의 훈련을 위한 총 손실 함수 를 획득할 수 있다. [수학식 10]"}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서, 과 는 하이퍼 파라미터이다. 상술한, 본 개시의 전자 장치는 총 손실 함수 최소화를 이용하여, NeRF 네트워크의 네트워크 파라미터를 구할 수 있고, 이에 따라 양안 비디오에 대응하는 장면의 암시적 고밀도 맵 표현을 구할 수 있다. 또한, 본 개 시의 전자 장치는 현재 프레임 이미지의 카메라 위치 및 포즈가 암시적 고밀도 맵 표현에 입력되면, 해당 프레임 이미지에 대응하는 고밀도 맵과 해당 고밀도 맵 내의 각 3차원 랜드마크 포인트의 신뢰도를 구할 수 있 다. 또한, 앞서 설명한 바와 같이, 전자 장치는 해당 프레임에 대응하는 고밀도 맵을 양안 깊이 추정 모듈 에 피드백할 수 있다. 이때, 양안 깊이 추정 모듈은 고밀도 맵을 다음 키 프레임에서 좌안 이미지와 우안 이미지를 결합하여 스테레오 매칭을 수행하여 다음 키 프레임에 대응하는 양안 시차 맵을 획득할 수 있다. 신경 고밀도 맵 모듈은 양안 시차 맵을 수신하여 깊이 맵으로 변환할 수 있다. 양안 깊이 추정 모듈 과 신경 고밀도 맵 모듈은 교대로 반복적으로 업데이트하여 시스템 및 모델의 정확도를 향상시킬 수 있다. 이와 같이, 본 개시의 전자 장치는 현재 프레임 이미지가 키 프레임일 때 해당 프레임 이미지에 대응하는 카메라 위치와 포즈, 스파스 맵 및 고밀도 맵을 획득할 수 있다.또한, 본 개시의 예시적 실시예에서, 프레임 이미지가 키 프레임인 경우, 120단계는, 획득한 고밀도 맵과 해당 고밀도 맵 내 각 3차원 랜드마크 포인트의 신뢰도를 기반으로 획득한 스파스 맵을 업데이트하는 단계를 더 포함 할 수 있다. 예를 들어, 전자 장치는 신경망 최적화가 수렴하여 장면의 암시적 고밀도 맵 표현을 획득하는 경우, 현재 프레임 이미지 및 해당 암시적 고밀도 맵 표현을 기반으로 프레임 이미지에 대응하는 고밀도 맵 및 해당 고밀도 맵 내 각 3차원 랜드마크 포인트의 신뢰도를 획득하는 경우, 프레임 이미지에 대응하는 획득한 스 파스 맵을 업데이트하여 하나의 전역적으로 일관된 스파스 맵을 유지할 수 있다. 구체적으로, 스파스 맵을 업데이트하는 단계는, 스파스 맵 내 하나의 3차원 랜드마크 포인트에 대해, 고밀도 맵 중 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 신뢰도에 따라, 하나의 3차원 랜드마크 포인트의 제1 가중치 및 고밀도 맵 중 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가중치를 결정하는 단계 및 결정된 제1 가중치 및 제2 가중치에 기초하여, 하나의 3차원 랜드마크 포인트와 고 밀도 맵 중 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트를 융합하여, 업데이트된 하나의 3 차원 랜드마크 포인트를 획득하는 단계를 통해서 스파스 맵의 각 3차원 랜드마크 포인트에 대해 업데이트를 실 행할 수 있다. 예를 들어, 고밀도 맵에서의 스파스 맵 중 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가중치는 대응하는 3차원 랜드마크 포인트의 신뢰도에 정비례할 수 있다. 구체적으로, 전자 장치는 고밀도 맵에서의 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인 트의 신뢰도가 높은 경우, 고밀도 맵에서의 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가중치를 더 큰 값으로 결정하고, 스파스 맵에서의 하나의 3차원 랜드마크 포인트의 제1 가중치를 더 작은 값으로 결정할 수 있다. 전자 장치는 고밀도 맵에서의 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 신뢰도 가 낮은 경우, 고밀도 맵에서의 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가중치 를 더 작은 값으로 결정하고, 스파스 맵에서의 하나의 3차원 랜드마크 포인트의 제1 가중치를 더 큰 값으로 결 정할 수 있다. 다른 예로서, 전자 장치는 신뢰도와 소정의 임계값 간의 비교 결과에 따라 스파스 맵의 하 나의 3차원 랜드마크 포인트의 제1 가중치와 고밀도 맵에서 하나의 3차원 랜드마크 포인트에 대응하는 3차원 랜 드마크 포인트의 제2 가중치를 결정할 수 있다. 본 개시는 이에 대해 제한하지 않는다. 전자 장치는 스파스 맵에서 하나의 3차원 랜드마크 포인트의 제1 가중치와 고밀도 맵에서 하나의 3차원 랜 드마크 포인트에 대응하는 3차원 랜드마크 포인트의 제2 가중치를 결정한 후, 결정된 제1 가중치 및 제2 가중치 에 따라 스파스 맵에서 하나의 3차원 랜드마크 포인트와 고밀도 맵에서 하나의 3차원 랜드마크 포인트에 대응하 는 3차원 랜드마크 포인트에 가중치를 부여하고 합산하여, 스파스 맵 중 해당 하나의 3차원 랜드마크 포인트 해 당 결과로 업데이트할 수 있다. 그후, 전자 장치는 스파스 맵의 각 3차원 랜드마크 포인트를 비슷한 방식으로 업데이트할 수 있다. 이렇게 업데이트된 스파스 맵은 프레임 이미지가 키 프레임일 때의 최종 스파스 맵으로 사용될 수 있다. 이상, 프레임 이미지가 키 프레임인 경우의 프로세스에 대해 설명하였으며, 프레임 이미지가 비 키 프레임(즉, 일반 프레임)인 경우, 230단계 및 232단계를 실행할 수 있다. 다시 말해, 프레임 이미지가 비 키 프레임인 경우, 120단계는 230단계 및 232단계를 포함할 수 있다. 구체적으로, 230단계에서, 전자 장치는 프레임 이미지와 프레임 이미지에 대응하는 IMU의 데이터를 기반으 로 프레임 이미지에 대응하는 카메라 위치와 포즈를 획득할 수 있다. 도 3에 도시된 바와 같이, 추적 모듈(31 0)은 프레임 이미지 및 프레임 이미지에 대응하는 관성 측정 유닛의 데이터에 기초하여, 특징점 검출 및 매칭, IMU 사전 통합, 특징 재식별 및 슬라이딩 윈도우 기반의 BA 최적화를 순차적으로 수행하여 해당 비 키 프레임에 대응하는 카메라 위치와 포즈를 획득할 수 있다. 해당 과정은 프레임 이미지가 키 프레임일 때 수행되는 220단 계와 동일하므로 여기서 더는 반복하지 않는다. 232단계에서, 전자 장치는 프레임 이미지 이전의 이전 키 프레임에 대응하는 스파스 맵과 고밀도 맵을 프 레임 이미지에 대응하는 스파스 맵과 고밀도 맵으로 결정할 수 있다. 구체적으로, 본 개시의 예시적 실시예에서, 비 키 프레임은 키 프레임과 달리 추적 모듈에서 카메라 위치 와 포즈 추정만을 수행하고 다른 모듈의 계산에는 참여하지 않으므로, 비 키 프레임인 프레임 이미지에 대해서 는, 프레임 이미지 이전의 이전 키 프레임에 대응하는 스파스 맵과 고밀도 맵을 해당 프레임 이미지에 대응하는스파스 맵과 고밀도 맵으로 결정할 수 있다. 예를 들어, 전자 장치는 현재 프레임 이미지가 제10 프레임이 고, 해당 프레임 이미지 이전의 이전 키 프레임이 제8 프레임인 경우, 220단계 내지 224를 통해 얻은 제8 프레 임에 대응하는 스파스 맵 및 고밀도 맵을 해당 프레임 이미지에 대응하는 스파스 맵 및 고밀도 맵으로 결정할 수 있다. 입체 비디오의 모든 프레임이 처리될 때까지 키 프레임과 비 키 프레임은 상술한 방법에 따라 처리될 수 있다. 본 개시의 실시예는 또한 프로세서를 포함하는 전자 장치를 제공하며, 선택적으로, 적어도 하나의 프로세서에 결합된 적어도 하나의 트랜시버 및/또는 적어도 하나의 메모리를 더 포함할 수 있고, 적어도 하나의 프로세서는 본 개시의 임의의 선택적 실시예에서 제공되는 방법의 단계를 수행하도록 구성될 수 있다. 도 5는 본 개시의 실시예가 적용되는 전자 장치의 구조를 도시한 예시도이다. 도 5를 참조하면, 전자 장치는 프로세서 및 메모리를 포함한다. 이때, 프로세서는, 예를 들어 버스를 통해 메모리에 연결된다. 선택적으로, 전자 장치는 트랜시버를 더 포함할 수 있다. 트랜시버는 데이터 송신 및/또는 데이터 수신과 같은 전자 장치와 다른 전자 장치 간의 데이터 상호 작용을 위해 사용될 수 있다. 실제 응용에서 프로세서, 메모리 및 트랜시버는 하나로 제한되지 않으며, 해당 전자 장치의 구조는 본 개시의 실시예에 대한 제한을 구성하지 않는다는 점에 유의해야 한다. 선택적으로, 해당 전자 장치는 제1 네트워크 노드, 제2 네트워크 노드 또는 제3 네트워크 노드일 수 있다. 프로세서는 CPU(central processing unit), 범용 프로세서, DSP(digital signal processor), 주문형 집적 회로(ASIC; application-specific integrated circuit), 필드 프로그램 가능 게이트 어레이(FPGA; field- programmable gate array) 또는 기타 프로그램 가능 논리 장치, 트랜지스터 논리 장치, 하드웨어 구성 요소, 또 는 이들의 임의의 조합일 수 있다. 이는 본 개시에서 설명된 다양한 예시적 논리 블록, 모듈 및 회로를 구현하 거나 실행할 수 있다. 프로세서는 또한, 예를 들어, 하나 이상의 마이크로프로세서 조합, DSP와 마이크로 프로세서의 조합 등을 포함하는 컴퓨팅 기능을 실현하는 조합일 수 있다. 버스는 구성요소들 사이에서 정보를 전달하기 위한 경로를 포함할 수 있다. 버스는 PCI(peripheral component interconnect) 버스 또는 EISA(extended industry standard architecture) 버스일 수 있다. 버스 는 어드레스 버스, 데이터 버스, 제어 버스 등으로 구분될 수 있다. 예시의 편의를 위해, 도 4에는 굵은 선 하나만 도시하였으나, 버스가 하나 또는 한 종류만 있는 것은 아니다. 메모리는 읽기 전용 메모리(ROM; read-only memory) 또는 정적 정보 및 명령을 저장할 수 있는 다른 유형 의 정적 저장 장치, 랜덤 액세스 메모리(RAM; random access memory) 또는 정보 및 명령을 저장할 수 있는 다른 유형의 동적 저장 장치일 수 있고, EEPROM(electrically erasable programmable read-only memory), CD-ROM 또 는 기타 광 디스크 스토리지, 광 디스크 스토리지(압축 광 디스크, 레이저 디스크, 광 디스크, 디지털 다목적 디스크, 블루 레이 디스크 등 포함), 디스크 저장 매체, 기타 자기 저장 장치 또는 컴퓨터 프로그램을 운반하거 나 저장하는데 사용할 수 있고 컴퓨터에서 읽을 수 있는 기타 모든 매체일 수도 있으며, 여기서 이에 대해 제한 하지는 않는다. 메모리는 본 개시의 실시예를 실행하기 위한 컴퓨터 프로그램 및 명령어를 저장하는데 사용되며 프로세서 에 의해 제어된다. 프로세서는 메모리에 저장된 컴퓨터 프로그램 또는 명령어를 실행하여 전술 한 방법 실시예에 도시된 단계를 실현하도록 구성될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 저장할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 저장될 수 있다. 소프트웨어는 네트워크로 연결된 컴 퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이 상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다."}
{"patent_id": "10-2024-0093793", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2024-0093793", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 전자 장치에 의해 수행되는 개략적인 방법을 도시한 흐름도이다. 도 2는 일 실시예에 따른 전자 장치에 의해 수행되는 상세한 방법을 도시한 흐름도이다. 도 3은 일 실시예에 따른 전자 장치에 의해 수행되는 방법에 대응하는 시스템을 도시한 예시도이다. 도 4는 일 실시예에 따른 신경 방사장에 의한 학습 방법을 도시한 예시도이다. 도 5는 본 개시의 실시예가 적용되는 전자 장치의 구조를 도시한 예시도이다."}
