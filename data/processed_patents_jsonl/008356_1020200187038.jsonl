{"patent_id": "10-2020-0187038", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0095483", "출원번호": "10-2020-0187038", "발명의 명칭": "AR 빔 프로젝트를 구비하는 실시간 의상 교체 콘텐츠 제공 시스템", "출원인": "제이에스씨", "발명자": "조지은"}}
{"patent_id": "10-2020-0187038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 캐릭터 의상을 그릴 수 있는 캐릭터 의상 그리기 기능이 포함된 전용 어플리케이션이 설치되어 있는 사용자 단말;상기 사용자 단말로부터 상기 전용 어플리케이션의 캐릭터 의상 그리기 기능을 통해 사용자가 그린 사용자 그림데이터를 수신하면, 수신한 사용자 그림 데이터에 대하여 인공지능 기반 3D 캐릭터 의상 모델을 생성하고, 생성된 3D 캐릭터 의상 모델을 AR 빔 프로젝트에 제공하는 생성 서버; 및실사물로 구성된 콘텐츠의 프로젝션 영역에 AR(Augmented Reality) 화면을 조사하되, 상기 생성 서버로부터 수신한 3D 캐릭터 의상 모델을 적용한 AR 화면을 조사하기 위한 AR 빔 프로젝트를 포함하는 실시간 의상 교체 콘텐츠 제공 시스템."}
{"patent_id": "10-2020-0187038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 생성 서버는 인공지능 기반 3D 캐릭터 의상 모델을 생성하기 위한 학습 데이터 구축 단계 및 상기 사용자단말로부터 입력된 사용자 그림 데이터를 활용한 3D 의상 생성을 위한 준비 단계를 통해 3D 캐릭터 의상 모델을생성하는 것을 특징으로 하는 실시간 의상 교체 콘텐츠 제공 시스템."}
{"patent_id": "10-2020-0187038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 생성 서버는 상기 학습 데이터 구축 단계에서,캐릭터 모델에 착장 가능한 기본 의상 모델로 구성된 모델링 학습 데이터, 기본 의상 모델로 구성된 각 의상에대한 모델 데이터의 질감, 색상, UV 맵으로 구성된 질감 학습 데이터 및 콘텐츠 내에서 실시간으로 애니메이션을 지원할 수 있는 리깅 학습 데이터를 구축하는 과정인 기본 의상 데이터 구축 과정;콘텐츠 내용에 특화된 의상 데이터 구축 과정;콘텐츠 내 특화 의상에 대한 대표의상을 정의하는 과정; 및각 대표의상의 변형 영역을 지정해 의상을 변형시켜서 학습 모델을 확장시키는 학습모델 확장 과정을 수행하는것을 특징으로 하는 실시간 의상 교체 콘텐츠 제공 시스템."}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 실시간 의상 교체 콘텐츠 제공 시스템에 관한 것으로서, 사용자 캐릭터 의상을 그릴 수 있는 캐릭터 의상 그리기 기능이 포함된 전용 어플리케이션이 설치되어 있는 사용자 단말, 상기 사용자 단말로부터 상기 전용 어플리케이션의 캐릭터 의상 그리기 기능을 통해 사용자가 그린 사용자 그림 데이터를 수신하면, 수신한 사용자 (뒷면에 계속)"}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 의상 교체 콘텐츠 제공 기술에 관한 것으로서, 더욱 상세하게는 AR(Augmented Reality) 영상을 프로 젝션하는 AR 빔 프로젝트를 구비하는 의상 교체 콘텐츠 제공 기술에 관한 것이다."}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "AR(Augmented Reality, 증강현실)은 사용자가 눈으로 보는 현실세계와 부가정보를 갖는 가상세계를 합쳐 하나의 영상으로 보여주는 가상현실의 하나이다. 현실세계를 가상세계로 보완해주는 개념인 AR은 컴퓨터 그래픽으로 만 들어진 가상환경을 사용하지만 주역은 현실환경이다. 컴퓨터 그래픽은 현실환경에 필요한 정보를 추가 제공하는 역할을 하며, 사용자가 보고 있는 실사 영상에 3차원 가상영상을 겹침(overlap)으로써 현실환경과 가상화면과의구분이 모호해지도록 한다. 가상현실은 자신(객체)과 배경, 환경 모두 현실이 아닌 가상의 이미지를 사용하는데 반해, 증강현실(AR)은 현실 의 이미지나 배경에 3차원 가상 이미지를 겹쳐서 하나의 영상으로 보여주는 기술이다. 또한, 증강현실은 혼합 현실(Mixed Reality, MR)이라고도 하는데, 비행기 제조사인 보잉사에서 1990경 비행기 조립 과정에 가상의 이미지를 첨가하면서 증강현실이 처음으로 세상에 소개됐다. 증강현실과 가상현실(Virtual Reality, VR)은 서로 비슷한 듯 하지만 그 주체가 허상이냐 실상이냐에 따라 명확 히 구분된다. 예를 들어, 가상현실 격투 게임은 나를 대신하는 캐릭터가 가상의 공간에서 가상의 적과 대결하지 만, 증강현실 격투 게임은 현실의 내가 현실의 공간에서 가상의 적과 대결을 벌이는 형태가 된다. 따라서, 증강 현실이 가상현실에 비해 현실감이 뛰어나다는 특징이 있다. 이 밖에 가상현실은 일반적으로 영화나 영상 분야 등 특수 환경에서만 사용되지만 증강현실은 현재 일반인들에 게도 널리 활용될 만큼 대중화된 상태다. 예를 들어, 인터넷을 통한 지도 검색, 위치 검색 등도 넓은 의미에서는 증강현실에 포함된다. 일반적으로, 유아 및 어린이는 동화책을 보거나 놀이기구로서 퍼즐 맞추기나 블럭쌓기를 하며 성장한다. 이처럼, 아동에게 동화책 또는 놀이기구는 다양한 정보와 지식을 자연스럽게 습득하게 하는 중요한 매체로, 동 화책이나 퍼즐 또는 블럭은 아동의 정서, 상상력, 창의력 발달에 도움을 주면서 그 교육적인 내용을 통해 사회, 언어, 인지 발달 등에 고른 영향을 미친다. 2015년 국민독서실태조사 보고서에 의하면, 성장 과정에서 책을 매개로 한 소통(책 읽기, 책 놀이, 독서대화 등)은 독서에 대한 친밀감을 키우고 독서습관을 기르는데 중요한 역할을 한다고 한다. 이처럼 최근 연구 결과에 의하면, 독서량이 많은 아이는 학업성적은 물론, 사고력과 창의력이 높다는 사실이 밝 혀졌다. 그리고, 디지털 매체의 발달로 급변하는 독서환경 및 독서인구 감소에 따른 대응이 요구되는 상황이다. 이에 정부는 독서문화진흥기본계획을 수립하여, 독서진흥 및 독서문화 확산을 위한 사업을 추진하고 있으나, 국 민이 체감하기에는 미흡한 실정이며, 독서 콘텐츠의 지속적 확충이 요구된다. 이처럼, 유아용 시장이 틈새시장에서 핵심(엔젤)시장으로 부상함에 따라 모바일 키즈를 겨냥한 학습용 게임형 모바일 에듀테인먼트 콘텐츠 소비시장이 성장하고 있다. 그리고, 가상현실(VR)이 미래 산업을 이끌 블루오션으로 떠오르면서 게임, 의료, 교육, 전시 등 다양한 분야에 적용사례가 증가하고 있으나, 킬러 콘텐츠 발굴이 필요한 실정이다. 최근 아날로그와 디지털 정보를 결합한 증강현실 기반의 차세대 전자책의 일종인 디지로그 북(Digilog Book) 기 술이 주목을 받고 있다. 이는 종이로 인쇄된 실사물을 손으로 만지고 느끼면서 자연마커를 통해 다양한 증강현 실 기반의 멀티미디어 효과를 제공한다. 또한 사용자와의 손쉬운 인터렉션을 통해 다양한 방향으로 이야기를 전개해나가는 흥미로운 특징들을 가지고 있 다. 아날로그와 디지털 정보를 결합하기 위해 다양한 연구들이 진행되고 있지만, 그 중 프로젝션 방식으로 실사 물 위에 디지털 정보를 그대로 투사하여 실사물 위에서 다양한 멀티미디어 콘텐츠가 동작되는 효과를 얻을 수 있다. 이는 실사물을 보면서 실감 있는 부가 정보를 체험할 수 있어 몰입도를 높일 수 있는 장점을 가진다. 그러나, 프로젝션 방식은 실사물을 프로젝션 영역에 정확히 위치시켜야만 실사물에 인쇄된 정보와 투사된 디지 털 정보가 조화되어 실감나는 콘텐츠를 제공할 수 있는데, 유아나 아이들은 실사물을 프로젝션 영역에 정확히 위치시키는 것이 쉽지 않은 문제가 있다. 기존의 2D 이미지 기반의 3D 캐릭터 생성 기술은 클라우드 검색 등을 통해 데이터베이스에서 사용자가 그린 이 미지와 가장 비슷한 데이터를 골라 변형하여 사용하거나, 또는 3D 모델을 미리 만든 후 사용자가 색칠한 옷의 텍스처만 가지고 와서 3D 모델에 적용하는 형태로 서비스 되고 있어서, 엄밀히 말하면 사용자의 의도와 완전히 일치하지는 않는 다른 캐릭터의 옷을 제공하고 있다고 할 수 있다. 선행기술문헌 특허문헌(특허문헌 0001) 대한민국 공개특허 10-2020-0137766"}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 인공지능 기술을 활용하여 사용자가 입력한 2D 원화를 그대로 3D 모델로 생성하여 콘텐츠에 실시간으로 적용할 수 있는 실시간 의상 교체 콘텐츠 제공 시스 템을 제공하는데 그 목적이 있다. 또한, 본 발명은 AR 프로젝션 기술을 이용하여 디지털 정보를 투사하는 AR 빔 프로젝터의 프로젝션 영역(투사 영역)에 아날로그 정보가 인쇄된 투사물을 정확히 위치시킬 수 있는 AR 빔 프로젝터가 설치되는 책상을 제공하 는데 그 다른 목적이 있다. 본 발명의 목적은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이와 같은 목적을 달성하기 위한 본 발명은 실시간 의상 교체 콘텐츠 제공 시스템에 관한 것으로서, 사용자 캐 릭터 의상을 그릴 수 있는 캐릭터 의상 그리기 기능이 포함된 전용 어플리케이션이 설치되어 있는 사용자 단말, 상기 사용자 단말로부터 상기 전용 어플리케이션의 캐릭터 의상 그리기 기능을 통해 사용자가 그린 사용자 그림 데이터를 수신하면, 수신한 사용자 그림 데이터에 대하여 인공지능 기반 3D 캐릭터 의상 모델을 생성하고, 생성 된 3D 캐릭터 의상 모델을 AR 빔 프로젝트에 제공하는 생성 서버 및 실사물로 구성된 콘텐츠의 프로젝션 영역에 AR(Augmented Reality) 화면을 조사하되, 상기 생성 서버로부터 수신한 3D 캐릭터 의상 모델을 적용한 AR 화면 을 조사하기 위한 AR 빔 프로젝트를 포함한다. 상기 생성 서버는 인공지능 기반 3D 캐릭터 의상 모델을 생성하기 위한 학습 데이터 구축 단계 및 상기 사용자 단말로부터 입력된 사용자 그림 데이터를 활용한 3D 의상 생성을 위한 준비 단계를 통해 3D 캐릭터 의상 모델을 생성할 수 있다. 상기 생성 서버는 상기 학습 데이터 구축 단계에서, 캐릭터 모델에 착장 가능한 기본 의상 모델로 구성된 모델 링 학습 데이터, 기본 의상 모델로 구성된 각 의상에 대한 모델 데이터의 질감, 색상, UV 맵으로 구성된 질감 학습 데이터 및 콘텐츠 내에서 실시간으로 애니메이션을 지원할 수 있는 리깅 학습 데이터를 구축하는 과정인 기본 의상 데이터 구축 과정, 콘텐츠 내용에 특화된 의상 데이터 구축 과정, 콘텐츠 내 특화 의상에 대한 대표 의상을 정의하는 과정 및 각 대표의상의 변형 영역을 지정해 의상을 변형시켜서 학습 모델을 확장시키는 학습모 델 확장 과정을 수행할 수 있다."}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 사용자가 직접 입력한 2D 원화를 그대로 3D 모델로 생성하여 AR 콘텐츠에 실시간으로 적용함 으로써, 사용자의 흥미를 증가시킬 수 있으며, AR 콘텐츠 관련 교육 기능을 증대시킬 수 있는 효과가 있다. 또한, 본 발명의 AR 빔 프로젝터가 설치되는 책상은 삽입홈에 실사물을 넣으면 실사물이 AR 빔 프로젝터의 프로 젝션 영역에 정확하게 위치되므로, 유아나 아이들도 실사물을 정확한 곳에 용이하게 위치시킬 수 있는 이점이 있다."}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시된 실시 예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되 어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시에서 제안하고자 하는 실시 예는 이하에서 개시 되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 당해"}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 실시 예들의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시 예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 개시된 실시 예들의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 명세서의 상세한 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아 닌, 그 용어가 가지는 의미와 본 명세서의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 \"부\"라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미하며, \"부\"는 어떤 역할들을 수 행한다. 그렇지만 \"부\"는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\"는 어드레싱할 수 있는 저 장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\"는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태 스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들을 포함한다. 구성요소들과 \"부\"들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\"들 로 결합되거나 추가적인 구성요소들과 \"부\"들로 더 분리될 수 있다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부 여하고 이에 대한 중복되는 설명은 생략하기로 한다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체 적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 본 발명은 인공지능 기술을 활용하여 사용자가 입력한 2D 원화 그대로의 3D 모델을 생성하여 콘텐츠에 실시간으 로 적용하는 기술이며, 인공지능 모델 생성을 위한 학습 데이터베이스 생성 방법과 실시간 콘텐츠 서비스를 위 한 콘텐츠 서비스 플랫폼을 제안한다. 도 1 및 도 2는 본 발명의 일 실시예에 따른 실시간 의상 교체 콘텐츠 제공 시스템의 구성을 개략적으로 나타낸 도면이다. 도 1 및 도 2를 참조하면, 본 발명의 실시간 의상 교체 콘텐츠 제공 시스템은 생성 서버, 사용자 단말 , AR 빔 프로젝터(B)를 포함한다. 사용자 단말은 사용자 캐릭터 의상을 그릴 수 있는 캐릭터 의상 그리기 기능이 포함된 전용 어플리케이션 이 설치되어 있는 단말이다. 예를 들어, 사용자 단말은 이동통신망에 접속하여 통신이 가능하고 전용 어플 리케이션을 설치할 수 있는 단말로서, 스마트폰, 태블릿 PC 등을 포함할 수 있다. 생성 서버는 사용자 단말로부터 전용 어플리케이션의 캐릭터 의상 그리기 기능을 통해 사용자가 그린 사용자 그림 데이터를 수신하면, 수신한 사용자 그림 데이터에 대하여 인공지능 기반 3D 캐릭터 의상 모델을 생 성하고, 생성된 3D 캐릭터 의상 모델을 AR 빔 프로젝트(B)에 제공한다. AR 빔 프로젝트(B)는 실사물로 구성된 콘텐츠의 프로젝션 영역에 AR(Augmented Reality) 화면을 조사하되, 생성 서버로부터 수신한 3D 캐릭터 의상 모델을 적용한 AR 화면을 조사하는 역할을 한다. 도 2에서 보는 바와 같이, 본 발명에서 콘텐츠는 그림이 그려진 실사물로 구현되며, 예를 들어 콘텐츠는 스토리 북, AR 핑거스토리 북 등으로 구현될 수 있다. 생성 서버는 인공지능 기반 3D 캐릭터 의상 모델을 생성하기 위한 학습 데이터 구축 단계 및 사용자 단말 로부터 입력된 사용자 그림 데이터를 활용한 3D 의상 생성을 위한 준비 단계를 통해 3D 캐릭터 의상 모델 을 생성할 수 있다. 생성 서버는 학습 데이터 구축 단계에서, 캐릭터 모델에 착장 가능한 기본 의상 모델로 구성된 모델링 학 습 데이터, 기본 의상 모델로 구성된 각 의상에 대한 모델 데이터의 질감, 색상, UV 맵으로 구성된 질감 학습 데이터 및 콘텐츠 내에서 실시간으로 애니메이션을 지원할 수 있는 리깅 학습 데이터를 구축하는 과정인 기본 의상 데이터 구축 과정, 콘텐츠 내용에 특화된 의상 데이터 구축 과정, 콘텐츠 내 특화 의상에 대한 대표의상을 정의하는 과정 및 각 대표의상의 변형 영역을 지정해 의상을 변형시켜서 학습 모델을 확장시키는 학습모델 확장 과정을 수행할 수 있다. 도 8은 본 발명의 일 실시예에 따른 사용자 단말 화면예이다. 도 8을 참조하면, 사용자 단말에서는 전용 어플리케이션(앱)을 통해 캐릭터 의상 그리기 기능을 제공한다. 전용 앱에서는 사용자가 사용자 단말을 통해 입력한 사용자 그림을 입력으로 받는다. 그리고, 사용자 그림 을 밑색과 무늬로 구분하여 생성 서버에 전달한다(Step1). 도 9는 본 발명에서 사용자 단말에서 제공 서버로 전달되는 데이터를 예시한 것이다. 도 9를 참조하면, 본 발명에서 사용자 그림을 입력으로 받는 앱으로 사용자가 그린 의상을 인공지능 기술을 이 용하여 3D 모델을 추론하여 만들어야 하기 때문에 원피스의 원형 질감에 해당되는 드레스 밑색 레이어와 무늬 레이어를 분리하여 생성 서버로 전송한다. 다음, 생성 서버는 사용자와 사용자가 그린 사용자 그림을 식별하기 위한 식별번호 정보를 요청한다 (Step2). 예를 들어, 사용자 단말에서는 유저(User) ID(이름), 템플릿(Template) ID(Format index), 이미 지1(드레스 밑색), 이미지2(드레스 무늬) 등의 데이터를 생성 서버에 전송한다. 다음, 생성 서버는 사용자 단말에 요청 결과(Result)와 토근 ID(token ID)를 포함하는 식별번호를 부 여한다(Step3). 생성 서버는 사용자 단말로부터 전달된 이미지를 바탕으로 인공지능 기술 기반 3D 캐릭터 의상 모델 을 생성한다(Step4). 생성 서버는 인공지능 기반 3D 캐릭터 의상 모델을 생성하기 위하여, 학습 데이터를 구축 단계, 사용자 단 말로부터 입력된 사용자 그림 이미지를 활용한 3D 의상 생성을 위한 준비 단계를 통해 3D 캐릭터 의상 모 델을 생성한다. 생성 서버는 학습 데이터 구축 단계에서 1) 기본 의상 데이터 구축, 2) 콘텐츠 내용에 특화된 의상 데이터 구축, 3) 콘텐츠 내 특화 의상에 대한 대표의상 정의, 4) 학습모델 확장 과정을 수행한다. 먼저, 1) 학습 데이터 중에서 기본 의상 데이터 구축 과정은 다음과 같다. 인공지능 기술 기반 3D 의상 모델링 기술을 활용한 실시간 콘텐츠 서비스를 위해서는 응용 서비스에 적합한 학 습 데이터 셋을 필요로 하여 캐릭터 모델이 착장 가능한 기본 의상 모델들로 구성된 모델링 학습 데이터를 구축 한다. 그리고, 기본 의상 모델로 구성된 각 의상에 대한 모델데이터의 질감, 색상, UV맵으로 구성된 질감 학습 데이터 를 구축한다. 그리고, 콘텐츠 내에서 실시간으로 애니메이션 움직임을 지원할 수 있는 리깅 학습 데이터를 구축한다. 다음, 2) 콘텐츠 내용에 특화된 의상 데이터 구축 과정은 다음과 같다. 사용자가 그린 의상 이미지를 보다 정확하게 3D로 재현하기 위해 특정 캐릭터가 주로 입고 등장하는 의상에 대 해 별도의 학습 데이터를 구축한다. 예를 들어 “이상한 나라의 앨리스”의 앨리스 의상인 드레스 등의 학습 데이터를 구축한다. 도 10 내지 도 13은 본 발명에서 인공지능 3D 캐릭터 의상 모델 생성을 위한 학습 데이터 구축 과정을 예시한 것이다. 도 10에서 반팔, 긴팔의 여성 상의와 반바지, 긴바지의 여성 하의 등의 여성모델과 착장가능한 학습 데이터가 예시되어 있다. 도 11에서 각 의상에 대한 모델의 질감과 UV맵이 예시되어 있다. 도 12에서 애니메이션 지원을 위한 리깅 데이터가 예시되어 있다. 도 13에서 콘텐츠 내 캐릭터 착장에 필요한 옷 카테고리 학습 데이터가 예시되어 있다. 다음, 3) 콘텐츠 내 특화 의상에 대한 대표의상 정의 과정은 다음과 같다. 콘텐츠 내 캐릭터에 적용하기 위한 학습 데이터는 사용자 그림의 다양성을 커버할 수 있도록 의상 카테고리별 대표 의상 모델을 정의하여 데이터베이스를 확보한다. 도 14는 본 발명에서 대표의상 모델 정의를 예시한 것이다. 도 14에서 민소매 원피스에 대한 대표의상 모델을 정의하기 위하여, 네크라인 형태, 허리라인, 치마 밑단, 치마 폭, 치마길이/ 그외 등 다양한 구성요소 데이터 중에서 대표의상 모델을 정의한다. 도 15 및 도 16은 본 발명에서 대표의상 모델 정의에 따른 제작 예시도이다. 다음, 4) 학습모델 확장 과정에서 학습데이터의 확장을 위해 각 대표의상의 변형 영역을 지정해 컨트롤 포인트 (Control Points)를 움직여 의상을 변형을 주는 형태로 학습모델을 확장시킨다. 도 17은 본 발명에서 대표의상 의 로컬 변형 수행 과정을 예시한 것이다. 그리고, 생성 서버는 사용자 그림 앱의 입력 이미지를 활용한 3D 의상 생성을 위한 준비 단계에서, 콘텐츠 내에 사용될 캐릭터의 모델의 UV 텍스처 맵에서 의상에 해당하는 부분의 텍스처를 지운 후, 별도의 템플릿으로 인덱스 처리하여 사용자의 이미지를 변형해서 처리할 수 있도록 한다. 도 18은 본 발명의 일 실시예에 따른 캐릭터 모델 예시도이고, 도 19 내지 도 21은 본 발명에서 캐릭터의 UV 텍 스처 맵 예시도이다. 도 19는 도 18의 캐릭터 모델에 대한 UV 텍스처 맵을 예시한 것이다. 그리고, 도 20은 UV 텍스처 맵 중 의상에 해당하는 영역을 별도의 템플릿으로 만들고 영역별로 그레이스케일을 다르게 지정하여 인덱스로 활용할 수 있도록 한 예시이다. 도 21은 캐릭터의 UV 텍스처 맵에서 의상 부분이 빠진 텍스처 맵을 도시한 것이다. 사용자 단말에서는 콘텐츠 플레이를 담당하는 AR 빔 프로젝트(B)로 사용자 ID와 식별 번호를 전송한다. 본 발명에서 사용자 단말은 사용자가 자기가 그린 그림을 기초로 3D 모델 생성이 완료되면, 바로 확인할 수 있도록 생성 서버로부터 부여받은 식별번호를 AR 빔 프로젝트(B)로 전달한다(Step5). 예를 들어, 사용자 단말은 유저 ID, 토근 ID를 AR 빔 프로젝트(B)로 전달할 수 있다. 다음, AR 빔 프로젝트(B)에서는 전달받은 식별번호에 해당하는 의상이 제작 완료되었는지 생성 서버에 요 청을 보내 진행상황을 확인한다(Step6). 예를 들어, AR 빔 프로젝트(B)는 Inquiry(진행상황)과 토근 ID를 생성서버에 전송할 수 있다. 3D 의상 모델 생성이 완료되면, 생성 서버는 생성된 3D 의상 모델을 AR 빔 프로젝트(B)에 제공한다 (Step7). 이때, 생성 서버에서는 사용자 그림에 맞는 3D 모델의 메쉬(mesh)를 생성하고, 리깅 정보가 담긴 캐릭터 모델을 AR 빔 프로젝트(B)에 전달하며, 새롭게 생성된 캐릭터 메쉬에 맞는 UV맵을 자동으로 생성하여 콘 텐츠에 함께 전달한다. 예를 들어, 생성 서버는 이미지(texture), 생성 모델링(Fbx), 캐릭터 모델 이미지 등을 포함하는 3D 의상 모델 정보를 AR 빔 프로젝트(B)에 전송할 수 있다. AR 빔 프로젝트(B)에서는 콘텐츠에 새롭게 생성된 의상을 실시간 적용하여 플레이한다. 예를 들어, 생성 서버 로부터 전달받은 인공지능 캐릭터 모델을 콘텐츠에 적용하여 실시간으로 AR 핑거 스토리(Finger Story) 콘 텐츠를 플레이할 수 있다. 도 22 및 도 23은 본 발명의 일 실시예에 따른 최종 출력 이미지를 예시한 것이다. 본 발명의 일 실시예에서 AR 빔 프로젝터를 정해진 위치에 고정시키고, 실사물인 콘텐츠를 수납할 수 있는 공간 등 본 발명의 실시간 의상 교체 콘텐츠 제공 시스템을 최적으로 구현하도록 하기 위한 전용 책상을 제안하고자 한다. 이하에서는 본 발명에 의한 AR 빔 프로젝터가 설치되는 책상의 실시 예를 첨부된 도면을 참조하여 상세히 설명 한다. 도 3 내지 도 5은 본 발명의 일 실시예에 따른 AR 빔 프로젝터가 설치되는 책상을 보인 도면이다. 그리고, 도 6는 본 발명의 일 실시예에 따른 AR 빔 프로젝터가 설치되는 책상에서 후방패널의 위치를 조절하는 모습을 보인 도면이다. 도 7는 본 발명의 일 실시예에 따른 AR 빔 프로젝터가 설치되는 책상의 삽입홈에서 탑커버를 빼내는 모습을 보 인 도면이다. 본 발명에 의한 AR 빔 프로젝터가 설치되는 책상은 다리부와, 상기 다리부의 상단에 설치되는 상판(2 0)을 포함하여 구성된다. 상기 상판은 상면에 고정부가 설치되고, 일정 깊이의 삽입홈이 형성되며, 수납홀이 형성된다. 상기 고정부는 상판의 상면에 프로젝션 영역(투사영역)을 형성하는 AR 빔 프로젝터(B)의 설치위치를 설 정하는 것으로서, 상기 삽입홈에 가까워지거나 멀어지는 방향으로 이동가능하게 설치된다. 이러한 고정부 는 한 쌍의 측방패널(21a)과, 상기 측방패널 (21a)의 후방 측면에 연결되는 후방패널 (21b)으로 구성된다. 상기 측방패널(21a)은 상판의 상면 후방측에 설치되는 AR 빔 프로젝터(B)의 하단 양측면에 밀착된다. 이러 한 측방패널(21a)의 전방 끝부분에는 AR 빔 프로젝터가 전방으로 움직이는 것을 막는 전방패널(21c)이 설치된다. 그리고, 측방패널(21a)에는 다수의 통기홀(21d)이 형성되어, AR 빔 프로젝터에서 발생되는 열을 외부로 배출시 키고, AR 빔 프로젝터의 스피커를 통해 나오는 사운드를 음질 저하 없이 사용자에게 전달한다. 상기 후방패널(21b)은 양단이 상기 측방패널(21a)에 볼팅되어 고정되고, AR 빔 프로젝터(B)의 하단 후면에 밀착 된다. 따라서, 측방패널(21a)과 전방패널(21c)이 AR 빔 프로젝터(B)가 측방과 전방으로 이동하는 것을 막고, 후방패널 (21b)이 AR 빔 프로젝터(B)가 후방으로 이동하는 것을 막음으로써, AR 빔 프로젝터(B)의 설치 위치가 견고하게 유지된다. 한편, AR 빔 프로젝터(B)는 AR(Augmented Reality) 화면을 실사물(A)에 조사하여 실사물(A)에 디지털 정보를 제 공하는 프로젝션 영역(Projection area)을 전방 일정거리 라인에서부터 형성하는데, 이 프로젝션 영역의 시작라 인은 AR 빔 프로젝터(B)의 기종에 따라 달라질 수 있다. 이렇게 AR 빔 프로젝터(B)의 프로젝션 영역 시작 라인이 기종마다 다르기 때문에 AR 빔 프로젝터(B)의 설치위치 를 앞뒤로 조금씩 조정하는 것이 필요하다. 본 발명에서는 AR 빔 프로젝터(B)의 설치위치를 조정하기 위해 상판 에 장공을 형성하고, 이 장공 내에서 이동하는 핸드스크류를 후방패널(21b)과 체결하도록 하였 다. 부연하면, 상기 장공은 AR 빔 프로젝터(B)를 향하는 쪽, 즉 전후방향으로 길게 상판에 형성되는데, 핸 드스크류가 상판 밑에서 장공을 따라 이동한 후 특정 위치에서 후방패널(21b)과 체결된다. 이렇게후방패널(21b)을 전후방향으로 이동시켜 AR 빔 프로젝터(B)가 원하는 곳에 위치되면 핸드스크류를 후방패널 (21b)에 체결하여 후방패널(21b)의 위치를 고정시킨다. 상기 삽입홈은 문자나 그림과 같은 아날로그 정보가 인쇄된 보드나 종이와 같은 실사물(A)이 삽입되는 곳이 다. 이러한 삽입홈은 그 깊이가 실사물(A)의 두께와 동일하거나 비슷하게 형성되어 실사물(A) 한 장이 삽입 홈 내에 삽입된다. 그리고, 삽입홈의 일측단에는 삽입홈과 연결되면서 삽입홈보다 더 깊은 누름홈(22a)이 형성된다. 따라서 실사물(A)을 삽입홈에 삽입하였을 때 실사물(A)의 일측단은 누름홈(22a) 위쪽에 위치된다. 실사물(A)의 일측단이 누름홈(22a) 위쪽에 위치되므로, 실사물(A)의 일측단을 누름홈(22a) 안쪽으로 누르면 실 사물(A)의 타측단이 위쪽으로 들어 올려지게 되어 타측단을 잡고 삽입홈에서 실사물(A)을 쉽게 빼낼 수 있 다. 그리고, AR 빔 프로젝터(B)를 사용하지 않아서 삽입홈에 실사물(A)을 삽입하지 않을 때에는 삽입홈 내 에 탑커버(C)를 설치하여 삽입홈에 이물질이 들어가는 것을 막는다. 상기 수납홀은 상판의 상면에 형성되는 것으로, 다수의 실사물(A)이 저장된다. 수납홀 내에 실사물 (A)이 꽂히면 실사물의 상부 일부분이 수납홀 밖으로 돌출된다. 한편, 상판의 아래에는 다수의 서랍이 구비되어 있다. 상기 서랍은 용도별로 분할되어 있다. 즉 도면에서 가장 왼쪽에 있는 서랍에는 알파벳 블록을 저장하고, 그 오른쪽 옆에 있는 서랍에는 한글 블록을 저장하며, 다시 그 오른쪽 옆에 있는 서랍에는 숫자 블록을 저장한다. 마지막으로 가장 오른쪽에 있는 서랍에는 실사물(A)을 저장한다. 이렇게 용도가 다른 각각의 서랍이 상판 의 아래쪽에 슬라이딩 가능하게 구비되어 있다. 그리고, 서랍의 하부에는 다수의 실사물이 안착되는 거치대가 구비되어 있다. 상기 거치대는 실사물(A)을 수납하는 가장 오른쪽 서랍의 하측에 구비된다. 더불어 거치대는 다수의 실 사물(A)을 꽂아놓는 수납홀의 하측에 위치된다. 따라서, 책상의 오른쪽 부분은 실사물(A)을 꽂아놓는 수납 홀과 실사물(A)을 수납하는 서랍 및 실사물(A)을 안착시키는 거치대가 위아래로 형성되므로 실사물(A) 의 정리를 좀 더 용이하게 할 수 있다. 이상 본 발명을 몇 가지 바람직한 실시 예를 사용하여 설명하였으나, 이들 실시 예는 예시적인 것이며 한정적인"}
{"patent_id": "10-2020-0187038", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "것이 아니다. 본 발명이 속하는 기술분야에서 통상의 지식을 지닌 자라면 본 발명의 사상과 첨부된 특허청구범 위에 제시된 권리범위에서 벗어나지 않으면서 다양한 변화와 수정을 가할 수 있음을 이해할 것이다."}
{"patent_id": "10-2020-0187038", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 본 발명의 일 실시예에 따른 실시간 의상 교체 콘텐츠 제공 시스템의 구성을 개략적으로 나타낸 도면이다. 도 3 내지 도 5은 본 발명의 일 실시예에 따른 AR 빔 프로젝터가 설치되는 책상을 보인 도면이다. 도 6는 본 발명의 일 실시예에 따른 AR 빔 프로젝터가 설치되는 책상에서 후방패널의 위치를 조절하는 모습을 보인 도면이다.도 7는 본 발명의 일 실시예에 따른 AR 빔 프로젝터가 설치되는 책상의 삽입홈에서 탑커버를 빼내는 모습을 보 인 도면이다. 도 8은 본 발명의 일 실시예에 따른 사용자 단말 화면예이다. 도 9는 본 발명에서 사용자 단말에서 제공 서버로 전달되는 데이터를 예시한 것이다. 도 10 내지 도 13은 본 발명에서 인공지능 3D 캐릭터 의상 모델 생성을 위한 학습 데이터 구축 과정을 예시한 것이다. 도 14는 본 발명에서 대표의상 모델 정의를 예시한 것이다. 도 15 및 도 16은 본 발명에서 대표의상 모델 정의에 따른 제작 예시도이다. 도 17은 본 발명에서 대표의상의 로컬 변형 수행 과정을 예시한 것이다. 도 18은 본 발명의 일 실시예에 따른 캐릭터 모델 예시도이다. 도 19 내지 도 21은 본 발명에서 캐릭터의 UV 텍스처 맵 예시도이다. 도 22 및 도 23은 본 발명의 일 실시예에 따른 최종 출력 이미지를 예시한 것이다."}
