{"patent_id": "10-2023-0056956", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0160697", "출원번호": "10-2023-0056956", "발명의 명칭": "머신러닝을 이용한 만화 이미지 변환 시스템 및 방법과 이를 위한 컴퓨터 프로그램", "출원인": "주식회사 닉컴퍼니", "발명자": "박재홍"}}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 이미지 데이터를 입력받고, 상기 이미지 데이터의 얼굴 영역을 인식하여 상기 이미지 데이터로부터배경 이미지 및 얼굴 이미지를 각각 생성하도록 구성된 얼굴 추출부; 및 머신러닝 기반의 변환 모델을 이용하여 상기 배경 이미지를 만화화한 제1 변환 이미지 및 상기 얼굴 이미지를만화화한 제2 변환 이미지를 각각 생성하고, 상기 제1 변환 이미지 및 상기 제2 변환 이미지를 결합하여 상기이미지 데이터에 상응하는 만화 이미지를 생성하도록 구성된 이미지 변환부를 포함하는 만화 이미지 변환 시스템."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 이미지 변환부는, 상기 배경 이미지를 머신러닝 기반의 제1 변환 모델에 대한 입력값으로 이용하여 상기 제1 변환 이미지를 생성하도록 구성된 배경 변환부; 상기 얼굴 이미지를 머신러닝 기반의 제2 변환 모델에 대한 입력값으로 이용하여 상기 제2 변환 이미지를 생성하도록 구성된 얼굴 변환부; 및 상기 제1 변환 이미지 및 상기 제2 변환 이미지를 결합하도록 구성된 후처리부를 포함하되, 상기 제1 변환 모델 및 상기 제2 변환 모델은 적어도 부분적으로 서로 상이한 학습 이미지를 이용하여 학습된것인 만화 이미지 변환 시스템."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 변환 모델 및 상기 제2 변환 모델 각각은, 무작위 생성 데이터와 미리 설정된 학습용 그림 이미지 사이의 유사도에 대한 판별 결과를 이용하여 미리 학습된 것인 만화 이미지 변환 시스템."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 동영상 데이터를 입력받고, 상기 동영상 데이터로부터 서로 상이한 복수 개의 이미지 데이터를 추출하도록 구성된 이미지 추출부를 더 포함하는 만화 이미지 변환 시스템."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 이미지 추출부는, 상기 동영상 데이터가 나타내는 밝기 정보, 색상 정보 및 색 공간 정보 중 하나 이상의변화를 탐지함으로써 서로 상이한 복수 개의 장면에 상응하는 상기 복수 개의 이미지 데이터를 추출하도록 더구성된 만화 이미지 변환 시스템. 공개특허 10-2024-0160697-3-청구항 6 제1항에 있어서, 상기 얼굴 추출부는, 컨볼루션 신경망을 이용하여 상기 이미지 데이터의 각 픽셀을 분류함으로써 상기 이미지데이터의 얼굴 영역을 인식하도록 더 구성된 만화 이미지 변환 시스템."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "만화 이미지 변환 시스템이 하나 이상의 이미지 데이터를 수신하는 단계; 상기 만화 이미지 변환 시스템이, 상기 이미지 데이터의 얼굴 영역을 인식하여 상기 이미지 데이터로부터 배경이미지 및 얼굴 이미지를 각각 생성하는 단계; 상기 만화 이미지 변환 시스템이, 머신러닝 기반의 변환 모델을 이용하여 상기 배경 이미지를 만화화한 제1 변환 이미지 및 상기 얼굴 이미지를 만화화한 제2 변환 이미지를 각각 생성하는 단계; 및상기 만화 이미지 변환 시스템이, 상기 제1 변환 이미지 및 상기 제2 변환 이미지를 결합하여 상기 이미지 데이터에 상응하는 만화 이미지를 생성하는 단계를 포함하는 만화 이미지 변환 방법."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 변환 이미지 및 상기 제2 변환 이미지를 각각 생성하는 단계는, 상기 만화 이미지 변환 시스템이, 상기 배경 이미지를 머신러닝 기반의 제1 변환 모델에 대한 입력값으로 이용하여 상기 제1 변환 이미지를 생성하는 단계; 및 상기 만화 이미지 변환 시스템이, 상기 얼굴 이미지를 머신러닝 기반의 제2 변환 모델에 대한 입력값으로 이용하여 상기 제2 변환 이미지를 생성하는 단계를 포함하되,상기 제1 변환 모델 및 상기 제2 변환 모델은 적어도 부분적으로 서로 상이한 학습 이미지를 이용하여 학습된것인 만화 이미지 변환 방법."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 이미지 데이터를 수신하는 단계는, 상기 만화 이미지 변환 시스템이 동영상 데이터를 수신하는 단계; 및 상기 만화 이미지 변환 시스템이, 상기 동영상 데이터로부터 서로 상이한 장면에 상응하는 복수 개의 이미지 데이터를 추출하는 단계를 포함하는 만화 이미지 변환 방법."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어와 결합되어 청구항 제7항 내지 제9항 중 어느 한 항에 따른 만화 이미지 변환 방법을 실행하도록 컴퓨터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0056956", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2024-0160697-4-실행 가능한 명령어가 저장된 메모리; 외부 시스템과 통신 가능하게 구성된 통신 모듈; 및 상기 메모리 및 상기 통신 모듈과 통신 가능하게 연결된 프로세서를 포함하는 컴퓨팅 장치에 있어서, 상기 프로세서는, 상기 명령어를 실행함으로써, 하나 이상의 이미지 데이터를 수신하고, 상기 이미지 데이터의 얼굴 영역을 인식하여 상기 이미지 데이터로부터 배경 이미지 및 얼굴 이미지를 각각 생성하고, 머신러닝 기반의 변환 모델을 이용하여 상기 배경 이미지를 만화화한 제1 변환 이미지 및 상기 얼굴 이미지를만화화한 제2 변환 이미지를 각각 생성하고, 상기 제1 변환 이미지 및 상기 제2 변환 이미지를 결합하여 상기 이미지 데이터에 상응하는 만화 이미지를 생성하도록 구성된 컴퓨팅 장치."}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "만화 이미지 변환 시스템은, 하나 이상의 이미지 데이터를 입력받고, 상기 이미지 데이터의 얼굴 영역을 인식하 여 상기 이미지 데이터로부터 배경 이미지 및 얼굴 이미지를 각각 생성하도록 구성된 얼굴 추출부; 및 머신러닝 기반의 변환 모델을 이용하여 상기 배경 이미지를 만화화한 제1 변환 이미지 및 상기 얼굴 이미지를 만화화한 제 (뒷면에 계속)"}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예들은 만화 이미지 변환 시스템 및 방법과 이를 위한 컴퓨터 프로그램에 관한 것이다. 보다 상세하게는, 실시예들은 동영상, 사진 등으로부터 추출된 실사 이미지 데이터를 머신러닝 기반의 변환 모델을 활용하여 만화 이미지로 변환하는 기술에 대한 것이다."}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "원작의 작품성이 검증된 웹소설, 웹툰 등이 드라마로 제작되거나 또는 영화화되는 경우가 점점 증가하고 있다. 또한 최근 웹툰 시장의 비약적인 확장으로 웹툰이 주류 컨텐츠로 부상하면서, 기존의 제작 방식과 반대로 원작 의 작품성이 탄탄한 인기 드라마 등 컨텐츠를 원작으로 하여 이를 웹툰으로 제작하는 경우도 등장하였다. 현재 이러한 웹툰의 제작 방식은, 인기 드라마의 콘티를 바탕으로 같은 소재를 다른 내용으로 각색하거나, 또는 기존 드라마의 스핀오프(오리지널 작품에서 새롭게 파생되어 나온 작품), 프리퀄(오리지널 작품의 속편) 등에 해당하는 웹툰을 직접 그림으로써 컨텐츠를 제작하는 방식으로 이루어진다. 이러한 각색, 스핀오프, 프리퀄 등 은 기존 드라마를 재미있게 시청한 팬층이 쉽게 유입될 수 있는 장점을 갖는다. 그러나, 원작이 존재하는 경우에도 원작의 스토리만 채용하고 그림 작가가 직접 그림을 그려서 웹툰을 제작하는 데에는 많은 비용과 시간이 소요된다. 최근 웹툰을 서비스하는 플랫폼이 증가하고 글로벌 웹툰 시장이 성장하면 서 웹툰 컨텐츠의 수요가 폭발적으로 증가하고 있으나, 그림 작가가 직접 그림을 그리는 기존의 방식으로는 이 러한 수요를 충족시킬 수 없는 한계를 갖는다. 웹툰 등 만화 이미지의 제작을 보조하기 위한 종래의 기술로, 공개특허공보 제10-2009-0050910호는 영화와 같은 동영상이나 사진 등을 입력으로 하여 영상들을 만화 영상과 같이 렌더링하는 카투닝(cartooning) 작업과 만화책 처럼 보이게 하는 양식화(stylization) 작업, 그리고 말풍선 등 만화적 요소를 배치하는 작업을 통해 수작업을 최소화하고 디지털 만화책을 제작할 수 있는 디지털 만화책 제작 방법 및 장치를 개시한다. 그러나, 공개특허공보 제10-2009-0050910호에 개시된 것을 비롯한 종래 기술은 실사 이미지의 외곽선과 색상 등 을 간략화하여 만화적 느낌이 나도록 하는 것에 불과하므로, 사람이 실제로 그린 만화와 비교하면 결과물에 큰 차이가 있다. 또한, 실사 이미지를 단순화, 추상화하는 종래의 방법으로는 특정 작가의 그림체가 반영된 만화 이미지를 생성하는 것은 불가능하므로, 실제 웹툰과 품질면에서 큰 차이를 갖는다. 선행기술문헌 특허문헌"}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "(특허문헌 0001) 공개특허공보 제10-2009-0050910호 발명의 내용"}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 머신러닝 기반의 변환 모델을 활용한 로봇 프로세스 자동화(Robot Process Automation; RPA) 방식으로 동영상 등 입력 데이터를 웹툰 이미지 데이터로 변환함으로써, 웹툰 제작 시간과 비 용을 혁신적으로 줄이고 늘어난 웹툰 컨텐츠 수요에 맞춘 컨텐츠 공급을 가능하도록 하는 만화 이미지 변환 시 스템 및 방법과 이를 위한 컴퓨터 프로그램을 제공할 수 있다."}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따른 만화 이미지 변환 시스템은, 하나 이상의 이미지 데이터를 입력받고, 상기 이미지 데 이터의 얼굴 영역을 인식하여 상기 이미지 데이터로부터 배경 이미지 및 얼굴 이미지를 각각 생성하도록 구성된 얼굴 추출부; 및 머신러닝 기반의 변환 모델을 이용하여 상기 배경 이미지를 만화화한 제1 변환 이미지 및 상기 얼굴 이미지를 만화화한 제2 변환 이미지를 각각 생성하고, 상기 제1 변환 이미지 및 상기 제2 변환 이미지를 결합하여 상기 이미지 데이터에 상응하는 만화 이미지를 생성하도록 구성된 이미지 변환부를 포함한다. 일 실시예에서, 상기 이미지 변환부는, 상기 배경 이미지를 머신러닝 기반의 제1 변환 모델에 대한 입력값으로 이용하여 상기 제1 변환 이미지를 생성하도록 구성된 배경 변환부; 상기 얼굴 이미지를 머신러닝 기반의 제2 변 환 모델에 대한 입력값으로 이용하여 상기 제2 변환 이미지를 생성하도록 구성된 얼굴 변환부; 및 상기 제1 변 환 이미지 및 상기 제2 변환 이미지를 결합하도록 구성된 후처리부를 포함한다. 이때, 상기 제1 변환 모델 및 상기 제2 변환 모델은 적어도 부분적으로 서로 상이한 학습 이미지를 이용하여 학습된다. 일 실시예에서, 상기 제1 변환 모델 및 상기 제2 변환 모델 각각은, 무작위 생성 데이터와 미리 설정된 학습용 그림 이미지 사이의 유사도에 대한 판별 결과를 이용하여 미리 학습된다. 일 실시예에 따른 만화 이미지 변환 시스템은, 동영상 데이터를 입력받고, 상기 동영상 데이터로부터 서로 상이 한 복수 개의 이미지 데이터를 추출하도록 구성된 이미지 추출부를 더 포함한다. 일 실시예에서, 상기 이미지 추출부는, 상기 동영상 데이터가 나타내는 밝기 정보, 색상 정보 및 색 공간 정보 중 하나 이상의 변화를 탐지함으로써 서로 상이한 복수 개의 장면에 상응하는 상기 복수 개의 이미지 데이터를 추출하도록 더 구성된다. 일 실시예에서, 상기 얼굴 추출부는, 컨볼루션 신경망(Convolution Neural Network)을 이용하여 상기 이미지 데 이터의 각 픽셀을 분류함으로써 상기 이미지 데이터의 얼굴 영역을 인식하도록 더 구성된다. 본 발명의 일 측면에 따른 만화 이미지 변환 방법은, 만화 이미지 변환 시스템이 하나 이상의 이미지 데이터를 수신하는 단계; 상기 만화 이미지 변환 시스템이, 상기 이미지 데이터의 얼굴 영역을 인식하여 상기 이미지 데 이터로부터 배경 이미지 및 얼굴 이미지를 각각 생성하는 단계; 상기 만화 이미지 변환 시스템이, 머신러닝 기 반의 변환 모델을 이용하여 상기 배경 이미지를 만화화한 제1 변환 이미지 및 상기 얼굴 이미지를 만화화한 제2 변환 이미지를 각각 생성하는 단계; 및 상기 만화 이미지 변환 시스템이, 상기 제1 변환 이미지 및 상기 제2 변 환 이미지를 결합하여 상기 이미지 데이터에 상응하는 만화 이미지를 생성하는 단계를 포함한다. 일 실시예에서, 상기 제1 변환 이미지 및 상기 제2 변환 이미지를 각각 생성하는 단계는, 상기 만화 이미지 변 환 시스템이, 상기 배경 이미지를 머신러닝 기반의 제1 변환 모델에 대한 입력값으로 이용하여 상기 제1 변환 이미지를 생성하는 단계; 및 상기 만화 이미지 변환 시스템이, 상기 얼굴 이미지를 머신러닝 기반의 제2 변환 모델에 대한 입력값으로 이용하여 상기 제2 변환 이미지를 생성하는 단계를 포함한다. 이때, 상기 제1 변환 모 델 및 상기 제2 변환 모델은 적어도 부분적으로 서로 상이한 학습 이미지를 이용하여 학습된 것이다. 일 실시예에서, 상기 이미지 데이터를 수신하는 단계는, 상기 만화 이미지 변환 시스템이 동영상 데이터를 수신 하는 단계; 및 상기 만화 이미지 변환 시스템이, 상기 동영상 데이터로부터 서로 상이한 장면에 상응하는 복수 개의 이미지 데이터를 추출하는 단계를 포함한다. 본 발명의 일 측면에 컴퓨터 프로그램은, 하드웨어와 결합되어 전술한 실시예들에 따른 만화 이미지 변환 방법 을 실행하기 위한 것으로서 컴퓨터로 판독 가능한 기록매체에 저장될 수 있다. 본 발명의 일 측면에 따른 컴퓨팅 장치는, 실행 가능한 명령어가 저장된 메모리; 외부 시스템과 통신 가능하게 구성된 통신 모듈; 및 상기 메모리 및 상기 통신 모듈과 통신 가능하게 연결된 프로세서를 포함한다. 상기 프로세서는, 상기 명령어를 실행함으로써, 하나 이상의 이미지 데이터를 수신하고, 상기 이미지 데이터의 얼굴 영역을 인식하여 상기 이미지 데이터로부터 배경 이미지 및 얼굴 이미지를 각각 생성하고, 머신러닝 기반 의 변환 모델을 이용하여 상기 배경 이미지를 만화화한 제1 변환 이미지 및 상기 얼굴 이미지를 만화화한 제2 변환 이미지를 각각 생성하고, 상기 제1 변환 이미지 및 상기 제2 변환 이미지를 결합하여 상기 이미지 데이터 에 상응하는 만화 이미지를 생성하도록 구성된다."}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 측면에 따른 만화 이미지 변환 시스템 및 방법을 이용하면, 머신러닝 기반의 변환 모델을 활용한 로봇 프로세스 자동화(Robot Process Automation; RPA) 방식으로 동영상 등 입력 데이터를 만화 이미지 데이터 로 변환함으로써, 웹툰 제작 시간과 비용을 혁신적으로 줄이고 늘어난 웹툰 컨텐츠 수요에 맞춘 컨텐츠 공급이 가능한 이점이 있다. 또한, 본 발명의 일 측면에 따른 만화 이미지 변환 시스템 및 방법은 특정 작가의 그림체 특징이 학습된 변환 모델을 이용하여 마치 동일 작가가 그린 것과 같은 자연스러운 웹툰 이미지를 생성할 수 있고, 입력 이미지 데 이터에서 얼굴 이미지에는 배경 이미지와 상이한 변환 모델을 적용함으로써, 여러 장면에 등장하는 동일 인물이 만화 이미지 상에서 동일하게 보이도록 할 수 있는 이점이 있다. 나아가, 본 발명의 일 측면에 따른 만화 이미지 변환 시스템 및 방법에 의하면 드라마, 영화 등 기존 컨텐츠의 동영상 데이터로부터 영상 장면의 전환 정도에 따라 만화화할 이미지 프레임을 자동으로 추출함으로써, 만화 컷 으로 사용할 수 없는 중복 프레임을 사람이 직접 제거하지 않고 자동으로 제거하여 효율적인 이미지 변환이 가 능한 이점이 있다."}
{"patent_id": "10-2023-0056956", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 도면을 참조하여 본 발명의 실시예들에 대하여 상세히 살펴본다. 도 1은 일 실시예에 따른 만화 이미지 변환 시스템의 개략적인 블록도이다. 도 1을 참조하면, 본 실시예에 따른 만화 이미지 변환 시스템은 동영상, 사진 등의 입력 데이터로부터 이미지 데이터를 추출하고, 추출된 이미지 데이터를 머신러닝 기반의 변환 모델을 이용하여 만화 이미지로 변환하는 기능을 한다. 일 실시예에서, 만화 이미지 변환 시스템은 특정 작가의 그림체 특징이 학습된 변환 모델을 이용하여 만화 이미지 데이터를 생성할 수도 있다. 이와 같이 생성된 만화 이미지 데이터는 웹툰 등 만화화된 이미지를 필요로 하는 컨텐츠에 활용될 수 있다. 일 실시예에서, 만화 이미지 변환 시스템은 사용자 장치와 통신하며 동작하며, 사용자 장치로부터 만 화화를 위한 입력 데이터를 수신하고, 수신한 입력 데이터로부터 변환된 만화 이미지 데이터를사용자 장치에 제공할 수 있다. 사용자는 사용자 장치를 이용하여 만화 이미지 데이터에 대한 컷 분 할, 말풍선 삽입 또는 편집 등과 같이 만화 이미지를 웹툰 등 컨텐츠에 필요한 형태로 가공하기 위한 추가적인 이미지 처리를 수행할 수도 있다. 이상의 동작을 위하여, 만화 이미지 변환 시스템은 사용자 장치를 이용하여 접속할 수 있는 서버의 형태 로 구현될 수 있다. 예를 들어, 만화 이미지 변환 시스템은 사용자 장치 상에서 실행되는 애플리케이션 (또는, 앱(app))의 동작을 가능하게 하는 애플리케이션 서비스 서버(application service server)일 수 있다. 또는, 만화 이미지 변환 시스템은 사용자 장치 상에서 실행되는 웹 브라우저(web browser)에 의하여 접근 가능한 웹 페이지(web page)를 제공하는 웹 서버(web server)일 수도 있다. 사용자는 스마트폰(smartphone) 등 이동 통신 단말기, 개인용 컴퓨터(personal computer), 노트북(notebook) 컴퓨터, PDA(personal digital assistant), 태블릿(tablet) 컴퓨터, IPTV(Internet Protocol Television) 등을 위한 셋톱박스(set-top box), 인공지능(Artificial Intelligence; AI) 스피커, 또는 네트워크 서버 등 임의의 컴퓨팅 장치인 사용자 장치에서 유선 및/또는 무선 네트워크를 통하여 만화 이미지 변환 시스템에 접속하 고 만화화가 필요한 데이터를 만화 이미지 변환 시스템에 업로드하는 방식으로 이미지 변환 서비스를 이용할 수 있다. 또 다른 실시예에서, 만화 이미지 변환 시스템은 사용자 장치로부터 수신된 요청에 따라 별도의 외부 서 버(미도시)로부터 입력 데이터를 수신하도록 구성될 수도 있다. 예컨대, 만화 이미지 변환 시스템은 영 화, 드라마 등 동영상이나 사진을 포함하는 컨텐츠를 제공하는 미디어 서버로부터 입력 데이터를 수신할 수도 있다. 이를 위하여, 만화 이미지 변환 시스템은 유선 및/또는 무선 네트워크를 통하여 사용자 장치 및/또는 다 른 서버와 정보를 송수신하도록 구성될 수 있다. 유선 및/또는 무선 네트워크를 통한 통신 방법은 객체와 객체 가 네트워킹 할 수 있는 모든 통신 방법을 포함할 수 있으며, 유선 통신, 무선 통신, 3G, 4G, 혹은 그 이외의 방법으로 제한되지 않는다. 예를 들어, 유선 및/또는 무선 네트워크는 LAN(Local Area Network), MAN(Metropolitan Area Network), GSM(Global System for Mobile Network), EDGE(Enhanced Data GSM Environment), HSDPA(High Speed Downlink Packet Access), W-CDMA(Wideband Code Division Multiple Access), CDMA(Code Division Multiple Access), TDMA(Time Division Multiple Access), 블루투스 (Bluetooth), 지그비(Zigbee), 와이-파이(Wi-Fi), VoIP(Voice over Internet Protocol), LTE Advanced, IEEE802.16m, WirelessMAN-Advanced, HSPA+, 3GPP Long Term Evolution (LTE), Mobile WiMAX (IEEE 802.16e), UMB (formerly EV-DO Rev. C), Flash-OFDM, iBurst and MBWA (IEEE 802.20) systems, HIPERMAN, Beam- Division Multiple Access (BDMA), Wi-MAX(World Interoperability for Microwave Access) 및 초음파 활용 통 신으로 이루어진 군으로부터 선택되는 하나 이상의 통신 방법에 의한 통신 네트워크를 지칭할 수 있으나, 이에 한정되는 것은 아니다. 한편 다른 실시예에서는, 네트워크를 통한 통신을 경유할 필요 없이 만화 이미지 변환 시스템 자체가 사용자 가 사용하는 스마트폰, PC 등 컴퓨팅 장치의 형태로 구현될 수도 있으며, 이 경우 도 1에 도시된 사용자 장치 는 생략될 수 있다. 일 실시예에서, 만화 이미지 변환 시스템은 얼굴 추출부 및 이미지 변환부를 포함한다. 또한 일 실 시예에서, 만화 이미지 변환 시스템은 이미지 추출부를 더 포함할 수 있다. 나아가 일 실시예에서, 이미 지 변환부는 배경 변환부, 얼굴 변환부 및 후처리부를 포함할 수 있다. 본 명세서에 기재된 장치들은 전적으로 하드웨어이거나, 또는 부분적으로 하드웨어이고 부분적으로 소프트웨어 인 측면을 가질 수 있다. 예컨대, 사용자 장치 및 만화 이미지 변환 시스템은 특정 형식 및 내용의 데이 터를 전자통신 방식으로 주고받기 위한 장치 및 이에 관련된 소프트웨어를 통칭할 수 있다. 본 명세서에서 \"부 (unit)\", \"모듈(module)\", \"서버\", \"시스템\", \"플랫폼\", \"장치\" 또는 \"단말\" 등의 용어는 하드웨어 및 해당 하 드웨어에 의해 구동되는 소프트웨어의 조합을 지칭하는 것으로 의도된다. 예를 들어, 여기서 하드웨어는 CPU 또 는 다른 프로세서(processor)를 포함하는 데이터 처리 기기일 수 있다. 또한, 하드웨어에 의해 구동되는 소프트 웨어는 실행중인 프로세스, 객체(object), 실행파일(executable), 실행 스레드(thread of execution), 프로그 램(program) 등을 지칭할 수 있다. 또한, 본 명세서에서 만화 이미지 변환 시스템을 구성하는 각각의 부(21-23, 231-233)는 반드시 물리적으로 구분되는 별개의 구성요소를 지칭하는 것으로 의도되지 않는다. 즉, 도 1에서 만화 이미지 변환 시스템의 각부(21-23, 231-233)는 서로 구분되는 별개의 블록으로 도시되었으나, 이는 만화 이미지 변환 시스템을 이에 의해 실행되는 동작에 의해 기능적으로 구분한 것이다. 실시예에 따라서는 전술한 각 부(21-23, 231-233) 중 일 부 또는 전부가 동일한 하나의 장치 내에 집적화될 수 있으며, 또는 하나 이상의 부가 다른 부와 물리적으로 구 분되는 별개의 장치로 구현될 수도 있다. 예컨대, 만화 이미지 변환 시스템의 각 부(21-23, 231-233)는 분산 컴퓨팅 환경 하에서 서로 통신 가능하게 연결된 컴포넌트들일 수도 있다. 이미지 추출부는, 동영상 형태의 입력 데이터를 수신하고 이로부터 만화 이미지로 변환될 복수 개의 이미지 데이터를 추출할 수 있다. 예를 들어, 이미지 추출부는 동영상 데이터가 나타내는 강도, 밝기 및/또 는 색 공간의 정보 변화를 탐지함으로써 동영상 데이터 중에서 서로 상이한 장면을 나타내는 이미지 데이터들을 추출할 수 있다. 그러나, 실시예에 따라서는 입력 데이터 자체가 연속적인 동영상이 아니라 분절된 이미지 데이터들로 구성될 수도 있으며, 이 경우 이미지 추출부는 생략될 수 있다. 얼굴 추출부는, 입력 데이터에 해당하는 이미지 데이터 또는 입력 데이터로부터 이미지 추출부 에 추출된 이미지 데이터를 입력받고, 이미지 데이터의 얼굴 영역을 인식하여 배경과 얼굴 부분을 분리할 수 있다. 즉, 얼굴 추출부는 입력된 이미지 데이터로부터 배경 이미지 및 얼굴 이미지를 각각 생성할 수 있 다. 일 실시예에서, 얼굴 추출부는 이미지 데이터로부터 얼굴 영역을 인식하기 위하여 컨볼루션 신경망 (Convolution Neural Network; CNN)을 이용하여 이미지 데이터의 각 픽셀을 분류하는 방법을 사용할 수도 있으 며, 이에 대해서는 상세히 후술한다. 이미지 변환부는, 머신러닝 기반의 변환 모델을 이용하여 얼굴 이미지와 배경 이미지를 각각 만화 형태로 변환하고, 얼굴 이미지와 배경 이미지로부터 각각 변환된 만화 형태의 이미지들을 결합하여 최종 출력될 만화 이미지 데이터를 생성할 수 있다. 구체적으로, 이미지 변환부의 배경 변환부는 미리 학습된 제1 변환 모델을 이용하여 배경 이미지를 만 화화한 제1 변환 이미지를 생성할 수 있다. 또한, 이미지 변환부의 얼굴 변환부는 미리 학습된 제2 변 환 모델을 이용하여 얼굴 이미지를 만화화한 제2 변환 이미지를 생성할 수 있다. 후처리부는, 배경 변환부 와 얼굴 변환부 각각에 의하여 생성된 변환 이미지들을 결합하여 만화 이미지 데이터를 생성할 수 있다. 이때, 배경 변환부의 제1 변환 모델과 얼굴 변환부의 제2 변환 모델은 적어도 부분적으로 서로 상이 한 학습 이미지를 이용하여 학습된 것일 수 있다. 예컨대, 제1 변환 모델은 특정 그림체가 적용된 배경 이미지 를 학습 데이터로 이용하여 학습된 것이며, 제2 변환 모델은 특정 그림체가 적용된 얼굴 이미지를 학습 데이터 로 이용하여 학습된 것일 수 있다. 이처럼 배경과 얼굴 이미지에 다른 변환 모델을 적용함으로써, 배경에 변화 가 있는 여러 장면에서도 장면에 등장하는 동일 인물이 만화 이미지 상에서 동일하게 보이도록 하여 이미지 품 질을 향상시키는 역할을 한다. 일 실시예에서, 이미지 변환부에 의한 변환 과정에는, 생성적 적대 신경망(Generative Adversarial Networks; GAN) 기반의 변환 모델이 이용될 수도 있다. 즉, 제1 변환 모델 및 상기 제2 변환 모델 각각은 GAN 알고리즘에 기반한 것으로서, 무작위 생성 데이터와 미리 설정된 학습용 그림 이미지 사이의 유사도에 대한 판 별 결과를 이용하여 학습될 수 있다. 이와 같이 학습된 제1 및 제2 변환 모델에 각각 배경 이미지 및 얼굴 이미 지를 입력값으로 입력하면, 각 변환 모델은 입력값을 학습된 그림체 특징을 나타내는 만화 이미지 데이터로 변 환할 수 있다. GAN 알고리즘의 구체적인 동작에 대해서는 도 8을 참조하여 상세히 후술한다. 도 2은 일 실시예에 따른 만화 이미지 변환 시스템의 하드웨어 구성을 나타내는 개략적인 블록도이다. 도 2을 참조하면, 실시예들에 따른 만화 이미지 변환 시스템은 하드웨어를 포함하는 컴퓨팅 장치의 형태로 구현되며, 메모리, 프로세서, 통신부 그리고 입출력부를 포함할 수 있다. 메모리는 비-일시적인 컴퓨터 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM, SSD, 플래시 메모리, 디스크 드라 이브 등과 같은 비소멸성 대용량 저장 장치는 메모리와는 구분되는 별도의 영구 저장 장치로서 상술한 장 치나 서버에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드(일례로 보안 모듈이나 특정 서비스의 제공을 위해 설치된 애플리케이션 등을 위한 코드)가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메모리와 는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기 록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신부를 통해 메모리 에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 애플리케이션의 설치 파일을 배포하는 파일 배포 시스템(일례로, 애플리케이션 스토어 서비스 서버)이 네트워크를 통해 제공하는 파일들에 의해 설치되는 컴퓨터 프로그램에 기반하여 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신부에 의해 프로세서로 제공될 수 있다. 예를 들어 프 로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도록 구성 될 수 있다. 통신부는 네트워크를 통해 만화 이미지 변환 시스템이 사용자 장치, 서비스 서버 및/또는 학습 서버 등과 통신하기 위한 기능을 제공할 수 있다. 또한, 통신부는 만화 이미지 변환 시스템이 유선 및/또는 무선 네트워크를 통해 다른 하나 이상의 장치와 통신하기 위한 기능을 제공할 수 있다. 즉, 통신부는 메모 리를 참조하는 프로세서에 의하여 그 기능이 제어됨으로써, 도 1을 참조하여 전술한 각 기능 모듈을 실현하는 부분이다. 입출력부는 외부 입력/출력장치(미도시)와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 외부 입력장 치는 키보드, 마우스, 마이크로폰, 카메라 등의 장치를, 그리고 외부 출력 장치는 디스플레이, 스피커, 햅틱 피 드백 장치(haptic feedback device) 등과 같은 장치를 포함할 수 있다. 다른 예로 입출력부는 터치스크린 과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와의 인터페이스를 위한 수단일 수도 있다. 또한, 다른 실시예들에서 만화 이미지 변환 시스템은 적용되는 장치의 성질에 따라서 도 2에 도시된 구성요소들 보다 더 많은 하드웨어 구성요소들을 포함할 수도 있다. 예를 들어, 만화 이미지 변환 시스템이 사용자가 사용 하는 단말 장치에 적용되는 경우 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), GPS(Global Positioning System) 모듈, 카메라, 각종 센서, 데이터베이스 등과 같은 다른 구성 요소들을 더 포함할 수도 있다. 보다 구체적인 예로, 단말 장치가 스마트폰인 경우, 일반적으로 스마트폰이 포 함하고 있는 가속도 센서나 자이로 센서, 카메라 모듈, 각종 물리적인 버튼, 터치패널을 이용한 버튼, 입출력 포트, 진동을 위한 진동기 등의 다양한 구성요소들이 더 포함되도록 구현될 수 있다. 이하에서 도 3 내지 도 8을 참조하여 후술하는 만화 이미지 변환 방법은, 도 2를 참조하여 전술한 하드웨어 구성을 포함하는 컴퓨팅 장치 형태로 구현된 만화 이미지 변환 시스템에 의하여 수행될 수 있다. 일 예로, 만화 이미지 변환 방법은 사용자 장치 및/또는 서버에 기초하여 동작하는 애플리케이션, 소프트웨어 및 그 밖의 프로그램 중 적어도 어느 하나에 기초한 서비스의 형태로 사용자에게 제공될 수 있다. 일 실시예에서, 프로세서는 메모리에 저장된 명령어를 실행함으로써, 하나 이상의 이미지 데이터를 수신하고, 이미지 데이터의 얼굴 영역을 인식하여 이미지 데이터로부터 배경 이미지 및 얼굴 이미지를 각각 생 성할 수 있다. 또한 프로세서는, 머신러닝 기반의 변환 모델을 이용하여 배경 이미지를 만화화한 제1 변환 이미지 및 얼 굴 이미지를 만화화한 제2 변환 이미지를 각각 생성하고, 제1 변환 이미지 및 제2 변환 이미지를 결합하여 이미 지 데이터에 상응하는 만화 이미지를 생성할 수 있다. 도 3은 일 실시예에 따른 만화 이미지 변환 방법의 각 단계를 나타내는 순서도이다. 설명의 편의를 위하여, 도 1 및 도 3을 참조하여 본 실시예에 따른 만화 이미지 변환 방법에 대하여 설명한다. 먼저, 만화 이미지 변환 시스템의 이미지 추출부는 입력 데이터로 동영상 데이터를 입력받고(S1), 동영상 데이터로부터 서로 중복되지 않는 복수 개의 이미지 데이터를 추출할 수 있다(S2). 예를 들어, 이 미지 데이터는 동영상의 서로 상이한 프레임(frame)에 해당되는 것일 수 있다. 이때 추출되는 이미지 데이터는 동영상의 서로 상이한 장면을 나타낼 수 있으며, 만화 컷으로 사용할 수 없는 중복 프레임을 자동으로 제거함으 로써 효율적인 이미지 변환이 가능하다. 일 실시예에서, 이미지 추출부는 동영상의 각 프레임에 해당하는 이미지들에서 밝기 정보, 색상 정보 및/또 는 색 공간 정보의 변화가 미리 설정된 임계값 이상인 이미지들을 이미지 데이터로 추출할 수 있다. 예를 들어, 이미지 추출부는 이미지의 밝기 및/또는 색상 변화를 임계값과 비교하여 페이드인/아웃과 같이 변화가 임계값 이상으로 크게 나타내는 프레임을 이미지 데이터로 추출할 수 있다. 더 구체적으로는, 이미지 추 출부는 동영상의 각 프레임의 이미지 내 모든 픽셀에 대한 색상값(예컨대, R, G, B)의 평균값을 산출하고, 픽셀들의 평균 색상값을 나타내는 수치의 변화가 임계값 이상인 프레임을 이미지 데이터로 추출할 수도 있다. 또는, 이미지 추출부는 동영상의 각 프레임의 이미지의 색 공간을 프레임의 색 공간을 RGB에서 색조(hue), 포화도(saturation) 및 휘도(luminance)로 변환하고, 색조, 포화도 및 휘도로 구성되는 색 공간 정보의 프레임 간의 변화량을 계산하여 변화량이 미리 설정된 임계값 이상인 프레임을 이미지 데이터로 추출할 수 있다. 이상 과 같이 색 공간 정보를 통하여 이미지 데이터를 추출할 경우 컨텐츠 인식을 통하여 컨텐츠 내용의 변화가 이루 어지는 프레임을 추출할 수 있다. 도 4a 및 4b는 일 실시예에 따른 만화 이미지 변환 방법을 적용하기 위한 예시적인 입력 이미지 데이터를 나타 내는 이미지로서, 도 4a는 원본 동영상 데이터의 정지 화면의 일 예를 나타낸 것이며, 도 4b는 도 4a에 정지 화 면으로 도시된 동영상 데이터로부터 추출된 서로 상이한 장면들의 이미지 데이터의 예시를 나타낸 것이다. 일 실시예에서, 이미지 데이터의 추출에는 영상의 전환점을 찾아주는 공지된 파이썬(Python) 라이브러리인 PySceneDetect가 사용될 수도 있으나, 이미지 데이터의 추출 방법은 이에 한정되는 것은 아니다. 또한 일 실시 예에서, 입력 데이터 자체가 동영상 데이터가 아닌 분절된 이미지들일 경우, 전술한 이미지 데이터 추출 과정은 생략될 수도 있다. 다시 도 1 및 도 3을 참조하면, 만화 이미지 변환 시스템의 얼굴 추출부는 입력된 이미지 데이터에서 사 람의 얼굴 영역을 인식하고(S3), 인식된 영역을 기반으로 이미지 데이터를 배경 이미지와 얼굴 이미지로 분리할 수 있다(S4). 본 명세서에서 얼굴 이미지란, 만화화될 이미지에서 적어도 하나의 등장 인물의 얼굴을 포함하는 이미지를 의미 하며, 얼굴 외의 부분이 이미지 상에서 반드시 배제되어야 한다는 의미로 의도되지 않는다. 예를 들어, 등장 인 물의 얼굴을 포함하되 해당 인물의 다른 신체 일부를 포함하는 이미지라도 본 명세서의 얼굴 이미지에 해당될 수 있다. 또한 본 명세서에서 배경 이미지란, 만화화될 이미지에서 장면의 중심이 되는 하나 이상의 등장 인물의 얼굴 부 분을 포함하거나 포함하지 않는 사물, 사람, 풍경 등으로 구성된 이미지를 지칭하며, 반드시 사람의 얼굴 형상 을 포함하지 않는다는 의미로 의도되지 않는다. 예를 들어, 동영상의 특정 장면에서 인물의 얼굴 영역을 별도의 얼굴 이미지로 분리하되, 해당 인물의 얼굴을 포함하는 해당 장면의 이미지 전체가 본 명세서의 배경 이미지에 해당될 수 있다. 또는, 동영상의 특정 장면에서 중심 인물에 해당하는 하나 또는 복수의 사람의 얼굴 영역을 얼 굴 이미지로 분리하였을 경우, 해당 중심 인물을 얼굴 영역을 제외한 다른 부분은 설령 중심 인물이 아닌 하나 이상의 보조 인물의 얼굴을 포함하더라도 배경 이미지에 해당될 수 있다. 일 실시예에서는, 얼굴 이미지 중 얼굴 영역으로 검출된 부분 외의 배경 영역은 단색(예컨대, 흰색)으로 처리하 여 얼굴 이미지가 형성될 수도 있다. 마찬가지로, 배경 이미지에서는 별도의 얼굴 이미지로 분리된 영역은 단색 으로 처리하여 배경 이미지가 형성될 수도 있으나, 이에 한정되는 것은 아니며, 배경 이미지는 얼굴 영역을 원 본 그대로 포함할 수도 있다. 일 실시예에서, 배경 이미지와 얼굴 이미지의 분리는 이미지 세그멘테이션(image segmentation) 기법을 사용하 여 수행될 수 있다. 이미지 세그멘테이션 기법은 이미지를 픽셀 단위의 복수 개의 세그먼트(segment)로 분할하 는 기술로, 도 5a는 사람이 포함된 원본 이미지 데이터를 나타내고, 도 5b는 도 5a의 이미지의 각 픽셀들에 대 해 해당 픽셀이 구성하는 객체에 대한 분류 결과를 숫자 1 내지 4의 라벨(label)로 표시한 것을 나타낸다. 도 5b에 도시된 것과 같이 이미지의 각 영역에 대한 분류 결과를 얻기 위하여, 일 실시예에서 얼굴 추출부 는 컨볼루션 신경망(CNN)에 기초한 인간 파싱(human parsing) 세그멘테이션을 이용할 수 있다. 컨볼루션 신경망 (CNN)에 기초한 영역 구분을 위하여, 얼굴 추출부는 이미지 데이터로부터 추출된 특징값을 컨볼루션 신경망 (CNN)에 입력하여 특징 지도를 얻고 이를 병합하여 이미지 데이터에 대한 파싱 결과를 획득하도록 구성될 수 있 다. 컨볼루션 신경망(CNN)을 통한 인간 파싱 알고리즘에 대해서는 통상의 기술자에게 잘 알려져 있으므로, 발명 의 요지를 명확하게 하기 위하여 이에 대해서는 자세한 설명을 생략한다. 도 6은 도 5a를 원본 이미지 데이터로 하여 이미지의 각 픽셀들이 나타내는 객체를 컨볼루션 신경망(CNN)에 의 해 분류함으로써 이미지의 사람 부분을 신체 각 부위별로 분류한 결과를 나타낸 것이다. 흑백 이미지의 한계로 인하여 도 6의 분류 결과에서는 각 영역의 색상을 통해 분류 결과를 확인할 수 있으나, 세그멘테이션된 이미지 의 각 영역을 표시하는 방식은 이에 의해 제한되지 않는다. 일 실시예에서, 얼굴 추출부는 이미지에서 하나 이상의 주요 인물의 얼굴을 포함하는 영역은 얼굴 이미지로 분리하고 나머지 영역을 배경 이미지로 하되, 주요 인물인지 여부는 해당 프레임의 이미지 내에서 인물의 얼굴 이 차지하는 비율 또는 인물의 얼굴에 카메라의 초점이 맞추어져 있는지 여부 등을 기준으로 결정할 수 있다. 예를 들어, 얼굴 추출부는 이미지 내에 인물의 얼굴이 포함되어 있더라도 이미지의 전체 픽셀들 중 해당 인 물의 얼굴을 구성하는 픽셀들의 비율이 미리 설정된 문턱값 미만일 경우, 해당 인물은 장면의 주요 인물이 아닌 것으로 결정할 수 있다. 장면의 주요 인물이 아닌 것으로 결정될 경우, 해당 인물의 얼굴 영역은 얼굴 이미지로 분리되지 않으며, 해당 인물의 얼굴이 포함된 영역은 배경 이미지의 일부를 구성한다. 이는 영화나 드라마의 각 장면에서 중요하지 않은 보조 인물 또는 사람의 눈으로 식별 불가능할 정도로 얼굴이 작게 나와 있는 인물에 대 해서는 얼굴 이미지를 별도로 생성하지 않음으로써 변환 모델의 연산 부하를 줄이기 위한 것이다. 또 다른 예로, 얼굴 추출부는 이미지 내에 인물의 얼굴이 포함되어 있더라도 해당 장면에서 카메라의 초점 이 인물의 얼굴에 맞추어져 있지 않아 인물의 얼굴이 흐리게 표현(소위, 아웃포커스)된 경우, 흐리게 표현된 얼 굴에 대해서는 이를 얼굴 이미지로 분리하지 않고 배경 이미지에 포함시킬 수 있다. 영화나 드라마를 촬영함에 있어서 각 장면의 주요 인물에 카메라의 초점을 맞춤에 따라 카메라로부터 초점 거리 밖에 위치하는 인물들은 의도적으로 흐리게 표현하는 경우가 있는데, 이처럼 의도적으로 흐리게 촬영된 인물의 경우 얼굴 변환을 위한 별도의 변환 모델을 적용하지 않고 배경으로 취급함으로써 변환 모델의 연산 부하를 줄일 수 있다. 본 실시예에 있어서, 특정 인물의 얼굴에 카메라의 초점이 맞은 것인지 여부는, 해당 프레임의 이미지의 픽셀들 을 세그멘테이션한 결과에서 세그멘테이션된 얼굴 영역의 픽셀들의 특성값을 이용하여 결정될 수 있다. 예컨대, 초점이 맞지 않은 픽셀은 주변 픽셀과의 경계, 즉, 에지가 뚜렷하지 않을 수 있으므로, 세그멘테이션된 얼굴 영 역의 에지를 검출하고 에지가 분명하지 않은 얼굴 영역은 아웃포커스된 얼굴 이미지로 결정할 수 있다. 이때 에 지가 분명하지 않다는 것은, 검출된 에지의 두께가 미리 설정된 값 이상이거나, 또는 에지 안팎의 픽셀들을 비 교했을 때 픽셀들의 밝기 및/또는 색상 값의 대비가 미리 설정된 값 미만인 경우를 의미할 수 있다. 또 다른 실시예에서는, 얼굴 영역을 검출하기 위한 컨볼루션 신경망(CNN) 자체가 초점이 맞지 않는 픽셀을 분류 하도록 학습되어, 얼굴 영역의 검출과 동시에 해당 얼굴 영역이 초점이 맞은 얼굴 이미지인지 여부를 분류하도 록 구성될 수도 있다. 이상에서 설명한, 이미지에서 얼굴이 차지하는 비율 또는 얼굴에 초점이 맞추어져 있는지 여부를 기준으로 얼굴 이미지 추출 여부를 결정하는 방식은 복합적으로 수행될 수도 있다. 예컨대, 이미지에서 얼굴이 차지하는 비율 이 미리 설정된 문턱값 미만인 동시에 초점이 맞지 않은 얼굴 영역은 얼굴 이미지 추출 대상에서 제외하도록 얼 굴 추출부가 구성될 수도 있다. 다시 도 1 및 도 3을 참조하면, 만화 이미지 변환 시스템의 이미지 변환부는 배경 이미지를 미리 학습된 제1 변환 모델에 대한 입력값으로 이용하여 동영상의 배경 부분을 만화화한 제1 변환 이미지를 생성하고(S5-1), 얼굴 이미지를 미리 학습된 제2 변환 모델에 대한 입력값으로 이용하여 동영상의 등장 인물의 얼굴 부분을 만화 화한 제2 변환 이미지를 생성할 수 있다(S5-2). 다음으로, 이미지 변환부는 각각의 변환 모델을 통해 변환 된 제1 변환 이미지와 제2 변환 이미지를 결합하여(S6), 결합된 이미지를 입력 이미지 데이터에 상응하는 만화 화된 이미지로 출력할 수 있다(S7). 머신러닝 기반의 변환 모델을 통한 이상의 변환 과정에 대하여, 이하에서 도 7 및 도 8을 참조하여 더 상세히 설명한다. 도 7은 일 실시예에 따른 만화 이미지 변환 방법에 의한 이미지 변환 과정을 설명하기 위한 개념도이다. 도 7을 참조하면, 배경 변환부는 미리 설정된 그림체 특징을 갖는 이미지 데이터셋을 학습 데이터로 이용 하여 학습된 제1 변환 모델을 포함한다. 예컨대, 제1 변환 모델은 특정 웹툰 작가의 그림 이미지들을 학습 데이 터셋으로 이용하여 학습된 것일 수 있다. 이때, 제1 변환 모델을 학습시키기 위한 이미지들은 인물의 얼굴 보다 는 배경 이미지들로 구성될 수도 있으나, 이에 한정되는 것은 아니다. 한편, 얼굴 변환부는 미리 설정된 그림체 특징을 갖는 이미지 데이터셋을 학습 데이터로 이용하여 학습된 제2 변환 모델을 포함한다. 제2 변환 모델을 학습시키기 위한 학습 데이터셋은 특정 웹툰 작가의 그림 이미지들 로 구성될 수 있으며, 이때 웹툰 작가는 제1 변환 모델을 학습시키기 위한 학습 데이터셋의 이미지들을 그린 작 가와 동일하거나 또는 상이할 수 있다. 또한, 제2 변환 모델을 학습시키기 위한 이미지들은 인물의 얼굴 이미지 들로 구성될 수도 있다. 이는, 등장 인물의 얼굴의 경우 상이한 여러 장면에서도 동일인이라는 점을 알아볼 수 있어야 하므로, 배경 부분에 대한 변환 모델과는 상이한 모델을 얼굴 영역만을 대상으로 적용함으로써 이미지 품질을 향상시키기 위한 것이다. 배경 변환부는 배경 이미지를 전처리한 특징값들을 제1 변환 모델에 입력함으로써, 배경 이미지(11 0)가 만화화된 제1 변환 이미지를 생성한다. 또한, 얼굴 변환부는 얼굴 이미지를 전처리한 특징 값들을 제2 변환 모델에 입력함으로써, 얼굴 이미지가 만화화된 제2 변환 이미지를 생성한다. 이미지 처리부의 후처리부는, 이상과 같이 생성된 제1 변환 이미지 및 제2 변환 이미지를 서로 결합함으로써 하나의 만화 이미지를 생성할 수 있다. 예를 들어, 후처리부는 제2 변환 이미지에서 얼굴에 해당하는 영역을 추출하고, 추출된 얼굴 영역 이 미지를 제1 변환 이미지의 해당하는 부분에 덮어쓰는 방식으로 만화 이미지를 생성할 수 있다. 또는, 제2 변환 이미지가 얼굴 외의 영역을 전혀 포함하지 않거나 또는 얼굴 외의 영역이 투명하게 처리된 이미 지일 경우, 후처리부는 제2 변환 이미지 전체를 제1 변환 이미지 상에 배치하는 방식으로 만화 이미지를 생성할 수도 있다. 도 8은 일 실시예에 따른 만화 이미지 변환 방법에서 생성적 적대 신경망(GAN) 기반의 변환 모델에 의한 변환 과정을 설명하기 위한 개념도로서, 도 8에 도시된 변환 과정은 제1 변환 모델에 의한 변환 과정 및 제2 변환 모 델에 의한 변환 과정 모두에 적용될 수 있다. 도 8을 참조하면, 본 발명의 실시예들에 따른 변환 모델은 두 개의 신경망인 생성자(generator)와 판별자 를 사용하여 만화화된 이미지를 생성하도록 구성된다. 생성자는 무작위 노이즈 벡터(random noise vector)를 입력으로 하여 이미지 데이터를 생성하며, 판별자는 이미지 생성데이터와 실제데이터(즉, 학습용 그림 이미지)를 각각 입력받고, 생성데이터와 실제데이터 간의 유사도를 토대로 생성데 이터와 실제데이터의 일치 여부를 나타내는 판별 결과를 생성할 수 있다. 상기 변환 모델에서 생성자와 판별자는 서로 경쟁하며, 생성자는 판별자가 가짜(즉, 실제 데이터와 일치하지 않는 것)로 판별하기 어려운 생성데이터를 생성하도록 학습된다. 또한, 판별자 는 생성자가 생성한 생성데이터를 실제데이터와 구분할 수 있도록 학습된다. 이와 같이 생 성자와 판별자가 서로 경쟁하면서 각각의 신경망의 파라미터들이 학습을 통해 업데이트됨으로써, 생 성자는 실제데이터와 구분하기 어려울 정도의 고품질 생성데이터를 생성하도록 학습된다. 이상과 같이 생성적 적대 신경망(GAN) 알고리즘의 원리를 변환 모델에 적용하여, 특정 작가의 그림 이미지들을 실제데이터로 입력할 경우 해당 그림 이미지들의 그림체 특징이 입력 이미지에 반영된 생성데이터를 생성하도록 변환 모델을 학습시킬 수 있다. 이상에서 설명한 실시예들에 따른 만화 이미지 변환 시스템 및 방법에 의하면, 동영상이나 사진 등으로부터 추 출된 실사 이미지들을 변환 모델에 입력할 경우 입력 이미지들은 자동으로 미리 설정된 그림체 특징이 반영된 그림 이미지로 변환되므로, 이를 통해 기존의 원작 드라마나 영화 등이 존재하는 컨텐츠의 각 장면을 쉽게 만화 이미지로 변환할 수 있다. 이와 같이 생성된 만화 이미지를 컷 분할이나 말풍선 삽입 등 추가 가공을 거쳐 웹툰 형태의 파일로 생성함으로써, 웹툰 제작에 소요되는 시간과 비용을 줄이고 실제 촬영된 영상이나 사진을 기반으 로 하는 원작 컨텐츠를 쉽게 웹툰 컨텐츠로 변환할 수 있다. 이상에서 설명한 실시예들에 따른 만화 이미지 변환 방법에 의한 동작은 적어도 부분적으로 컴퓨터 프로그램으 로 구현되고 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다. 실시예들에 따른 방법에 의한 동작을 구현하기 위한 프로그램이 기록되고 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터에 의하여 읽혀질 수 있는 데이터가 저장되 는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이 프, 플로피디스크, 광 데이터 저장장치 등이 있다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 또한, 본 실시예를 구현하기 위한 기능적인 프로그램, 코드 및 코드 세그먼트(segment)들은 본 실시예가 속하는 기술 분 야의 통상의 기술자에 의해 용이하게 이해될 수 있을 것이다. 이상에서 살펴본 본 발명은 도면에 도시된 실시예들을 참고로 하여 설명하였으나 이는 예시적인 것에 불과하며 당해 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 실시예의 변형이 가능하다는 점을 이해할 것이다. 그러나, 이와 같은 변형은 본 발명의 기술적 보호범위 내에 있다고 보아야 한다."}
{"patent_id": "10-2023-0056956", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 만화 이미지 변환 시스템의 개략적인 블록도이다. 도 2는 일 실시예에 따른 만화 이미지 변환 시스템의 하드웨어 구성을 나타내는 개략적인 블록도이다. 도 3은 일 실시예에 따른 만화 이미지 변환 방법의 각 단계를 나타내는 순서도이다. 도 4a 및 4b는 일 실시예에 따른 만화 이미지 변환 방법을 적용하기 위한 예시적인 입력 이미지 데이터를 나타 내는 이미지이다. 도 5a 및 5b는 일 실시예에 따른 만화 이미지 변환 방법에 의해 얼굴 영역을 추출하기 위한 이미지 세그멘테이 션(image segmentation) 과정을 설명하기 위한 예시적인 이미지이다. 도 6은 일 실시예에 따른 만화 이미지 변환 방법에 의해 얼굴 영역을 추출하기 위한 이미지 세그멘테이션 과정 을 설명하기 위한 또 다른 예시적인 이미지이다. 도 7은 일 실시예에 따른 만화 이미지 변환 방법에 의한 이미지 변환 과정을 설명하기 위한 개념도이다. 도 8은 일 실시예에 따른 만화 이미지 변환 방법에서 머신러닝 기반의 변환 모델에 의한 변환 과정을 설명하기 위한 개념도이다."}
