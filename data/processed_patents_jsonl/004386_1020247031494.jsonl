{"patent_id": "10-2024-7031494", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0155273", "출원번호": "10-2024-7031494", "발명의 명칭": "결정론적 스트리밍 프로세서들의 다이-투-다이 고밀도 패키징", "출원인": "그록, 인크.", "발명자": "에이비티에스, 데니스, 찰스"}}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "집적 회로에 있어서,제1 다이(die); 및상기 제1 다이로 다이-투-다이(die-to-die, D2D) 구조를 형성하는 D2D 구성에서의 D2D 인터페이스 회로(interface circuit)를 통해 상기 제1 다이에 연결된 제2 다이를 포함하고,상기 D2D 인터페이스는 제1 방향 또는 상기 제1 방향과 직교하는 제2 방향을 따라 상기 제1 다이와 상기 제2 다이 간에 데이터를 스트리밍(stream)하기 위해 상기 제1 다이의 제1 복수의 슈퍼레인들을 상기 제2 다이의 제2복수의 슈퍼레인(superlane)들과 연결하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 D2D 인터페이스 회로는, 복수의 양방향 인터페이스 슬라이스들(bidirectional interface slices)을 포함하고,한 쌍의 상기 양방향 인터페이스 슬라이스들은, 상기 제2 다이의 상기 제2 복수의 슈퍼레인들의 해당 슈퍼레인에 연결되는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 D2D 인터페이스 회로는, 상기 제1 다이의 상기 제1 복수의 슈퍼레인들의 해당 서브세트(subset)에 연결된D2D 코어(core) 인터페이스 회로를 포함하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 D2D 인터페이스 회로는 복수의 D2D 인터페이스 뱅크(bank)들을 포함하고,상기 복수의 D2D 인터페이스 뱅크들 각각은 상기 제1 복수의 슈퍼레인들의 클러스터(cluster)에 상기 제2 복수의 슈퍼레인들의 클러스터를 연결하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0155273-3-제4항에 있어서,상기 제1 방향을 따른 상기 복수의 D2D 인터페이스 뱅크들 각각의 크기는, 상기 제1 방향을 따른 상기 제2 복수의 슈퍼레인들의 클러스터의 크기와 매칭하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 복수의 D2D 인터페이스 뱅크들 각각은, 복수의 D2D 인터페이스 매크로(macros)를 포함하고, 그리고상기 복수의 D2D 매크로 각각은, 복수의 양방향 인터페이스 슬라이스들의 각자의 양방향 인터페이스 슬라이스를포함하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 D2D 구조는, 상기 D2D 구성으로 상기 제1 다이 및 상기 제2 다이와 연결되고, 제1 디멘션(dimension) 및제2 디멘션 중 적어도 하나를 가로지르는(span across) 하나 더 다이들을 더 포함하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 D2D 구조는, 상기 D2D 구조의 복수의 다이들을 가로질러 모델-병렬화(model-parallelism)를 위해 단일 코어 프로세서로 기능하도록 구성되는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 D2D 구조의 복수의 다이들은, D2D 폴디드 메시(folded mesh) 구성 또는 D2D 토러스(torus) 구성으로 연결되는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 제1 다이 및 상기 제2 다이로 상기 D2D 구조를 형성하는 상기 D2D 구성으로 제2 D2D 인터페이스 회로를 통해 상기 제2 다이에 연결된 제3 다이를 더 포함하고,상기 제2 D2D 인터페이스는 상기 제1 방향 또는 상기 제2 방향을 따라 상기 제2 다이와 상기 제3 다이 간에 데이터를 스트리밍하기 위해 상기 제2 다이의 상기 제2 복수의 슈퍼레인들을 상기 제3 다이의 제3 복수의 슈퍼레공개특허 10-2024-0155273-4-인들에 연결하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제1 다이, 상기 제2 다이 및 상기 제3 다이로 상기 D2D 구조를 형성하는 상기 D2D 구성으로 제3 D2D 인터페이스 회로를 통해 상기 제3 다이에 연결된 제4 다이를 더 포함하고,상기 제3 D2D 인터페이스는 상기 제1 방향 또는 상기 제2 방향을 따라 상기 제3 다이와 상기 제4 다이 간에 데이터를 스트리밍하기 위해 상기 제3 다이의 상기 제3 복수의 슈퍼레인들을 상기 제4 다이의 제4 복수의 슈퍼레인들에 연결하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 D2D 구조를 형성하는 상기 제1 다이, 상기 제2 다이, 상기 제3 다이 및 상기 제4 다이는, D2D 폴디드 메시구성으로 상호 연결되는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 D2D 폴디드 메시 구성으로 연결된 상기 제1 다이, 상기 제2 다이, 상기 제3 다이 및 상기 제4 다이는, 상기 D2D 폴디드 메시 구성을 가로질러 모델-병렬화를 위해 단일 코어 프로세서로 작동하도록 구성되는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서,상기 제1 다이는 상기 제1 복수의 슈퍼레인들을 통해 적어도 부분적으로 연결된 제1 복수의 기능 유닛들(functional units)을 갖는 제1 텐서 스트리밍 프로세서(tensor streaming processor, TSP)를 포함하고; 그리고상기 제2 다이는 상기 제2 복수의 슈퍼레인들을 통해 적어도 부분적으로 연결된 제2 복수의 기능 유닛들을 갖는제2 TSP, 고-대역폭 메모리, 및 상기 D2D 인터페이스 회로를 포함하는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,상기 제2 다이는, 상기 D2D 구조를 형성하는 백투백(back-to-back, B2B) 구성 또는 페이스-투-페이스(face-to-공개특허 10-2024-0155273-5-face, F2F) 구성으로 상기 제1 다이에 연결되는,집적 회로."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴파일러(compiler)에 의해, 제1 다이 및 제2 다이를 가로질러 복수의 프로세싱 유닛들에 의한 실행을 위해 복수의 인스트럭션(instruction)들의 발행을 개시하는 단계; 및상기 컴파일러에 의해, 상기 복수의 인스트럭션들의 실행을 위해 제1 방향 또는 상기 제1 방향과 직교하는 제2방향을 따라 다이-투-다이(D2D) 인터페이스 회로를 통해 상기 제1 다이의 제1 복수의 슈퍼레인들과 상기 제2 다이의 제2 복수의 슈퍼레인들 간에 데이터의 스트리밍을 개시하는 단계를 포함하고,상기 제2 다이는, 상기 제1 다이로 D2D 구조를 형성하는 D2D 구성으로 상기 D2D 인터페이스 회로를 통해 상기제1 다이에 연결되는,방법."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 컴파일러에 의해, 상기 제1 방향과 상기 제2 방향 중 적어도 하나에 따라 복수의 다이들을 가로질러 데이터의 스트리밍을 개시하는 단계를 더 포함하고,상기 복수의 다이들은, 복수의 D2D 인터페이스 회로들을 통해 상기 D2D 구성으로 연결되고 상기 D2D 구조를 형성하는,방법."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,컴파일러에 의해, 상기 D2D 구조의 상기 복수의 다이들을 가로질러 모델-병렬화를 위해 단일 코어 프로세서로기능하도록 상기 D2D 구조를 형성하는 상기 복수의 다이들을 구성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "저장된 컴퓨터 실행 가능 인스트럭션들(instructions)을 포함하는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서,적어도 하나의 컴퓨터 프로세서 상에서 작동하는 컴파일러에 의해 실행되는 경우에 상기 적어도 하나의 컴퓨터프로세서로 하여금:제1 다이와 제2 다이를 가로질러 복수의 프로세싱 유닛들에 의한 실행을 위해 복수의 인스트럭션들의 발행을 개시하고; 그리고상기 복수의 인스트럭션들의 실행을 위해 제1 방향 또는 상기 제1 방향과 직교하는 제2 방향을 따라 다이-투-다이(D2D) 인터페이스 회로를 통해 상기 제1 다이의 제1 복수의 슈퍼레인들과 상기 제2 다이의 제2 복수의 슈퍼레공개특허 10-2024-0155273-6-인들 간에 데이터의 스트리밍을 개시하게 하고,상기 제2 다이는 상기 제1 다이로 D2D 구조를 형성하는 D2D 구성에서의 상기 D2D 인터페이스 회로를 통해 상기제1 다이에 연결되는,비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7031494", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 인스트럭션들은, 추가로 상기 컴퓨터 프로세서로 하여금:상기 제1 방향과 상기 제2 방향 중 적어도 하나를 따라 복수의 다이들을 가로질러 데이터의 스트리밍을 개시하고; 그리고상기 D2D 구조의 상기 복수의 다이들을 가로질러 모델-병렬화를 위해 단일 코어 프로세서로 기능하는 상기 D2D구조를 형성하는 상기 복수의 다이들을 구성하게 하며,상기 복수의 다이들은 복수의 D2D 인터페이스 회로들을 통해 상기 D2D 구성으로 연결되고 상기 D2D 구조를 형성하는,비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7031494", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예들은 다이-투-다이(die-to-die, D2D) 구성으로 연결된 다수의 다이(die)들을 가진 집적 회로에 관한 것이다(direct to). 상기 집적 회로는 제1 다이 및 상기 제1 다이로 D2D 구조를 형성하는 D2D 구성에서의 D2D 인터 페이스 회로를 통해 상기 제1 다이에 연결된 제2 다이를 포함할 수 있다. 상기 D2D 인터페이스는 제1 방향 또는 상기 제1 방향과 직교하는 제2 방향을 따라 상기 제1 다이와 상기 제2 다이 간에 데이터를 스트리밍(stream)하기 위해 상기 제2 다이의 제2 복수의 슈퍼레인들과 상기 제1 다이의 제1 복수의 슈퍼레인(superlane)들을 연결할 수 있다."}
{"patent_id": "10-2024-7031494", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2022년 02월 22일에 출원된 미국 임시 특허 출원(Provisional Patent Application) 번호 63/312,781 에 대한 우선권 및 이익을 주장하며, 이는 그 전체가 여기에 참조로 포함된다. 본 개시는 일반적으로 다수의 다이들을 갖는 프로세서 아키텍처, 보다 구체적으로는 결정론적 스트리밍 프로세 서들(deterministic streaming processors)의 다이-투-다이 고밀도 패키징(die-to-die dense packaging)에 관 한 것이다."}
{"patent_id": "10-2024-7031494", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "지난 10년 동안, 데이터 센터 오퍼레이터(operator)들은 창고-규모의 컴퓨터들에 멀티코어 프로세서 시스템들을 설치해 왔다. 많은 것이 효율적인 원격 메모리 액세스를 위해 데이터 네트워크 컨트롤러들을 사용하는, 이 시 스템들은 매우 다양한 형태와 기능으로 수십 내지 수천 개의 프로세싱 코어들을 가지고, 강력한 그래픽 프로세 싱 유닛들(graphical processing units, GPU들), 텐서 프로세싱 유닛들(tensor processing units, TPU들), 필 드 프로그래머블 게이트 어레이들(field programmable gate arrays, FPGA들)에 사용된다. 이러한 시스템들은 커머스에서 광범위한 사용을 위해 심층 신경망(deep neural network), 예를 들어, 추천 알고리즘들을 위한 컨볼 루션 신경망들(convolutional neural networks, CNN들), 제품 검색을 위한 컴퓨터 비전 및 이미지 분류; 및 사 용자 인터페이스들에서의 자연어 프로세싱(natural language processing)을 위한 순환 신경망들(recurrent neural networks, RNN들) 트레이닝 및 추론 (트레이닝된 신경망의 애플리케이션) 성능을 가속화하기 위해 자주 사용된다. 수백만 명의 소비자들과 수십억 건의 거래들에 사용되는 경우, 많은 것이 매우 많은 수의 벡터 및 행렬 계산들을 포함하는, 이 모델들의 높은 계산 요구 사항들은 아키텍처 혁신의 부활(resurgence)을 위한 기폭 제(catalyst)가 되었다. 기존의 칩 멀티프로세서(chip multiprocessor, CMP)에서, 프로세싱 코어들은 모든 프로세싱 코어들 간에 데이터 를 교환하도록 온-칩 네트워크를 사용하여 상호 연결된다. 이 단순 로드-스토어 모델(load-store model)에서, 범용 데이터 레지스터 세트가 주 메모리(main memory) 시스템들과 프로세서 코어들 간의 중간 스토리지 (storage)로 사용되고, 이는 데이터에 대해 작동하는, 산술 논리 유닛들(arithmetic logic units, ALU들)을 포 함할 수 있다. 인스트럭션(instruction)들은 각 코어로 디스패치(dispatch)되고 로컬(local) 정수(integer) 또는 부동소수점(floating-point) 프로세싱 모듈들에 의해 실행되는 동안, 중간 결과들은 범용 레지스터들에 저 장된다. 이 로드-스토어 아키텍처는 레지스터들과 주 메모리 간에 계산된 결과들 및 ('피연산자들(operands)'로도 지칭되는) 데이터를 이동시킨다. 인스트럭션 실행은 자주 여러 단계들: 1) 인스트럭션 페치(instruction fetch), 2) 인스트럭션 디코드(decode), 3) ALU들 상에서의 실행, 4) 메모리 읽기, 및 5) 레지스터들에서의 결 과들을 업데이트하는 메모리 쓰기에 걸쳐 수행된다. 그러나, CMP들에 대한 워크로드(workload)들은 규모와 복잡성 모두 계속 증가하여, 전통적인 CMP 아키텍처들에 대해 심한 확장성, 성능 및 사용성 요구 사항들을 제시하고 있다. 이 수요들을 효율적으로 관리하는 것은 프로 그램 실행 내내 거의 최고 성능 수준(levels)에서 사용되는, 벡터 및 행렬 계산들을 위해 충분한(abundant) 온- 칩(on-chip)의 ALU들을 필요로 한다. 안타깝게도, 추가된 ALU들 및 다른 구성 요소들로부터의 하드웨어 복잡성 은 많은 이 아키텍처들 내에서의 스케줄링 어려움들을 크게 증가시켰다. 결국, 이는 런타임 스톨들(runtime stalls)을 방지하기 어렵기 때문에 시스템 성능을 저해한다. 더구나, 캐시들(caches), 브랜치 예측기들(branch predictors), 프리페처들(prefetchers)과 같은 아키텍처 개선 사항들은 성능을 향상시키는 것에서 큰 도움을 주 는 반면, 최악의(worst-case) 성능을 제한하지는 않는다."}
{"patent_id": "10-2024-7031494", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시예들은 각각 기능 슬라이스 아키텍처를 갖는 하나 이상의 결정론적(deterministic) 프로세서들 (예를 들어, 텐서 스트리밍 프로세서들(tensor streaming processors, TSP들) 또는 인공 지능(artificial intelligence) 프로세서들)을 갖는 집적 회로(integrated circuit)에 관한 것이다. 일부 실시예들에서, 각 결 정론적 프로세서는 머신 러닝 모델(machine learning model)을 프로세싱(process)하도록 구성된다. 각 결정론 적 프로세서는 복수의 기능 슬라이스들(functional slices)로 조직된 복수의 기능 유닛들로 나누어진다. 각 기 능 슬라이스는 상기 결정론적 프로세서 내에서 특정 기능들을 수행하도록 구성되며, 이는 피연산자(operand) 데 이터를 저장하기 위한 메모리 기능 슬라이스들(MEM들), 수신된 피연산자 데이터에 대한 연산(operation)들(예를 들어, 벡터 프로세싱, 행렬 처리(matrix manipulation))을 수행하기 위한 산술(arithmetic) 기능 슬라이스들, 및/또는 그 유사한 것을 포함할 수 있다. 상기 결정론적 프로세서의 기능 유닛들은 해당 인스트럭션에서 나타 내는(indicate) 방향으로 제1(예를 들어, 시간적(temporal)) 디멘션(dimension)을 가로질러 피연산자 데이터를 스트리밍하고, 제2(예를 들어, 공간적(spatial)) 디멘션을 가로지르는 인스트럭션들을 수신하도록 구성된다. 상기 결정론적 프로세서를 위한 컴파일러(compiler)는 프로세서의 하드웨어 구성을 인식하고, 해당 데이터와 인 스트럭션들이 미리 결정된 시간에 각 계산 요소에서 교차되도록 데이터 및 인스트럭션 흐름들의 타이밍을 구성 한다. 상기 결정론적 프로세서의 각 기능 슬라이스는 단일 인스트럭션 다중 데이터(Single Instruction Multiple Data, SIMD) 방식으로 데이터 레인(lanes) 세트 상에서 작동할 수 있다. 상기 데이터 레인 세트는 여 기에서 \"슈퍼레인(superlane)\"으로 지칭될 수 있으며 프로세서 칩 상에서의 모든 기능 슬라이스들의 단면 (cross-section)을 나타낸다. 본 개시의 실시예들은 집적 회로에 관한 것이다. 상기 집적 회로는 타일(tile) 구조를 형성하는 제1 다이 및 상기 제1 다이에 연결된 제2 다이를 포함한다. 상기 제1 다이는 제1 디멘션을 따라 제1 시프트(shift) 양만큼, 및 상기 제1 디멘션에 직교하는 제2 디멘션을 따라 제2 시프트 양만큼 상기 제2 다이에 관하여 시프트된다. 상 기 타일 구조는 상기 타일 구조의 상기 제1 다이 및 상기 제2 다이를 가로질러 모델-병렬화(model- parallelism)를 위한 단일 코어 프로세서로 작동(operate)하도록 구성된다. 본 개시의 실시예들은 추가로 타일 구조들의 어레이를 포함하는 집적 회로에 관한 것이다. 상기 어레이에서의 각 타일 구조는 제1 다이, 및 페이스-투-페이스(face-to-face, F2F)으로 상기 제1 다이에 연결된 제2 다이를 포 함한다. 상기 제1 다이는 상기 제1 다이와 상기 제2 다이 간에 오프셋 정렬(offset alignment)을 형성하는 제1 디멘션을 따라 제1 시프트 양만큼, 및 상기 제1 디멘션에 직교하는 제2 디멘션을 따라 제2 시프트 양만큼 제2 다이에 관하여 시프트된다. 일부 구성들에서, 상기 제1 시프트 양은 상기 제1 디멘션을 따라 상기 제1 다이(또 는 상기 제2 다이)의 제1 크기의 50%까지일 수 있고, 및/또는 상기 제2 시프트 양은 상기 제1 디멘션을 따라 상 기 제1 다이(또는 상기 제2 다이)의 제2 크기의 50%까지일 수 있다. 상기 타일 구조들의 어레이는 상기 타일 구조들을 가로질러 모델-병렬화를 위해 단일 코어 프로세서로 작동하도록 구성된다. 본 개시의 실시예들은 추가로 스택된(stacked) 타일 구조들을 포함하는 집적 회로에 관한 것이다. 상기 집적 회로는 타일-투-타일(tile-to-tile, T2T) 브릿지(bridge)의 제1 사이드(side)에 커플링(couple)된 제1 복수의 타일 구조들, 및 상기 제1 사이드의 맞은편에 상기 T2T 브릿지의 제2 사이드에 커플링된 제2 복수의 타일 구조 들을 포함한다. 상기 제1 및 제2 복수들에서의 각 타일 구조는 F2F 구성으로 연결된 제1 다이 및 제2 다이를포함한다. 상기 제1 다이는 제1 디멘션을 따라 제1 시프트(shift) 양만큼, 및 상기 제1 디멘션에 직교하는 제2 디멘션을 따라 제2 시프트 양만큼 상기 제2 다이에 관하여 시프트된다. 상기 집적 회로는 상기 제1 사이드에 커플링된 제1 스택의 고대역폭 메모리들(high bandwidth memories, HBM들), 상기 제2 사이드에 커플링된 제2 스 택의 HBM들, 및 상기 제1 스택의 HBM들 및 상기 제1 복수의 타일 구조들의 외부 표면들에 커플링된 히트 싱크 (heat sink)를 더 포함한다. 일부 실시예들에서, 상기 집적 회로는 타일 구조들의 직육면체(cuboid) 구조를 포 함한다. 상기 직육면체 구조의 타일 구조들은 상기 타일 구조들을 가로질러 모델-병렬화를 위해 단일 코어 프 로세서로 작동(operate)하도록 구성된다. 본 개시의 실시예들은 추가로 집적 회로의 하나 이상의 결정론적 스트리밍 프로세서(예를 들어, 텐서 스트리밍 프로세서(tensor streaming processor))를 사용하여 계산(computing)하는 프로세스(또는 방법)와 관련된다 (relate to). 상기 프로세스는, 상기 집적 회로의 하나 이상의 타일 구조들의 복수의 다이들을 가로질러 프로 세싱 유닛들(예를 들어, 하나 이상의 기능 슬라이스들의 계산 요소들)에 의한 실행을 위해 인스트럭션들의 발행 을 개시하는 단계, 상기 인스트럭션들의 실행을 위해 상기 하나 이상의 타일 구조들의 상기 복수의 다이들을 가 로질러 상기 프로세싱 유닛들을 통한 데이터의 스트리밍을 개시하는 단계, 및 상기 하나 이상의 타일 구조들의 하나 이상의 메모리 슬라이스들로 결과 데이터를 반환하는 단계를 포함한다. 본 개시의 실시예들은 추가로 저장된 컴퓨터 실행 가능한 인스트럭션들을 포함하는 비일시적 컴퓨터 판독 가능 저장 매체와 관련되고, 이는 적어도 하나의 컴퓨터 프로세서 상에서 작동하는 컴파일러(compiler)에 의해 실행 되는 경우에 상기 적어도 하나의 컴퓨터 프로세서로 하여금: 집적 회로의 하나 이상의 타일 구조들의 복수의 다 이들을 가로질러 프로세싱 유닛들(예를 들어, 하나 이상의 기능 슬라이스들의 계산 요소들(computational elements))에 의한 실행을 위해 인스트럭션들의 발행을 개시하고, 상기 인스트럭션들의 실행을 위해 상기 하나 이상의 타일 구조들의 복수의 다이들을 가로질러 상기 프로세싱 유닛들을 통해 데이터의 스트리밍을 개시하며, 그리고 상기 하나 이상의 타일 구조들의 하나 이상의 메모리 슬라이스들로 결과 데이터를 반환하는 것을 개시하 게 한다. 본 개시의 실시예들은 추가로 결정론적 스트리밍 프로세서들(예를 들어, 텐서 스트리밍 프로세서들)의 다이-투- 다이(die-to-die, D2D) 고밀도 패키징으로 구현된 집적 회로와 관련된다. 상기 집적 회로는 D2D 구성으로 연결 된 다수의 다이들을 포함하며, 그리고 각 다이는 각각의(respective) 결정론적 스트리밍 프로세서를 포함한다. 상기 집적 회로는 제1 다이 및 상기 제1 다이로 D2D 구조를 형성하는 상기 D2D 구성에서의 D2D 인터페이스 회로 를 통해 상기 제1 다이에 연결된 제2 다이를 포함할 수 있다. 상기 D2D 인터페이스는 제1 방향 또는 상기 제1 방향에 직교하는 제2 방향을 따라 상기 제1 다이와 상기 제2 다이 간에 데이터를 스트리밍하기 위해 상기 제2 다이의 제2 복수의 슈퍼레인들(즉, 제2 스트리밍 데이터 레인 그룹)과 상기 제1 다이의 제1 복수의 슈퍼레인들 (즉, 제1 스트리밍 데이터 레인 그룹)을 연결할 수 있다. 상기 D2D 구조는 상기 D2D 구조의 상기 제1 다이와 상기 제2 다이를 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구성된다. 본 개시의 실시예들은 추가로 집적 회로의 하나 이상의 결정론적 스트리밍 프로세서들(예를 들어, 텐서 스트리 밍 프로세서들)을 사용하여 계산하는 프로세스(또는 방법)와 관련된다. (예를 들어, 컴파일러에 의해 수행되는) 프로세스는: 제1 다이 및 제2 다이를 가로질러 복수의 프로세싱 유닛들(예를 들어, 하나 이상의 기능 슬라이스들의 계산 요소들)에 의한 실행을 위해 복수의 인스트럭션들의 발행을 개시하는 단계; 및 상기 복수의 인스트럭션들의 실행을 위해 제1 방향 또는 상기 제1 방향에 직교하는 제2 방향을 따라 상기 D2D 인터페이스 회 로를 통해 상기 제1 다이의 제1 복수의 슈퍼레인들과 상기 제2 다이의 제2 복수의 슈퍼레인들 간에 데이터의 스 트리밍을 개시하는 단계를 포함하고, 상기 제2 다이는 상기 제1 다이로 D2D 구조를 형성하는 D2D 구성에서의 D2D 인터페이스 회로를 통해 상기 제1 다이에 연결된다. 본 개시의 실시예들은 추가로 저장된 컴퓨터 실행 가능한 인스트럭션들을 포함하는 비일시적 컴퓨터 판독 가능 저장 매체와 관련되고, 이는 적어도 하나의 컴퓨터 프로세서 상에서 작동하는 컴파일러에 의해 실행되는 경우에 상기 적어도 하나의 컴퓨터 프로세서로 하여금: 제1 다이와 상기 제1 다이로 D2D 구조를 형성하는 D2D 구성에서 의 상기 D2D 인터페이스 회로를 통해 상기 제1 다이에 연결되는 제2 다이를 가로질러 복수의 프로세싱 유닛들 (예를 들어, 하나 이상의 기능 슬라이스들의 계산요소들)에 의한 실행을 위해 복수의 인스트럭션들의 발행을 개 시하고; 그리고 상기 복수의 인스트럭션들의 실행을 위해 제1 방향 또는 상기 제1 방향과 직교하는 제2 방향을 따라 D2D 인터페이스 회로를 통해 상기 제1 다이의 제1 복수의 슈퍼레인들과 상기 제2 다이의 제2 복수의 슈퍼 레인들 사이에서 데이터의 스트리밍을 개시하게 한다."}
{"patent_id": "10-2024-7031494", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "도면들(도들) 및 다음의 설명은 단지 예시로서 바람직한 실시예들과 관련된다. 다음의 논의로부터, 여기에 개 시된 구조들 및 방법들의 대안적인 실시예들은 청구된 것의 원리들에서 벗어나지 않고도 이용(employ)될 수 있 는 실행 가능한 대안들로 쉽게 인식될 것임을 주목해야 한다. 참조는 이제 여러 실시예들에 대해 상세히 이루어질 것이며, 이의 예들은 첨부된 도면들에 예시된다. 실행 가 능한 곳 어디든 유사하거나 같은(like) 참조 번호들이 도면들에 사용될 수 있으며 유사하거나 같은 기능을 나타 낼 수 있음을 주목한다. 도면들은 단지 예시의 목적들을 위해 개시된 시스템(또는 방법)의 실시예들을 묘사한 다. 당업자는 다음의 설명으로부터 여기에 예시된 구조들 및 방법들의 대안적인 실시예들이 여기에 설명된 원 리들을 벗어나지 않고도 이용될 수 있음을 쉽게 인식할 것이다. 소개 개요 개시된 것은 하나 이상의 결정론적 프로세서들(deterministic processors)(예를 들어, 텐서 스트리밍 프로세서 들(tensor streaming processors, TSP들) 또는 인공 지능(artificial intelligence) 프로세서들)을 갖는 집적 회로를 포함하는 구성들이다. 각 결정론적 프로세서는 기능 슬라이스 아키텍처(functional slice architecture)를 가질 수 있다. 일부 실시예들에서, 각 결정론적 프로세서는 머신러닝 모델(machine learning model)을 처리하도록 구성된다. 각 결정론적 프로세서는 복수의 기능 유닛들로 나뉘어진다. 기능 유닛들은 복 수의 기능 슬라이스들로 조직(organize)된다. 각 기능 슬라이스는 결정론적 프로세서 내에서 특정 기능들 (functions)을 수행하도록 구성된다. 결정론적 프로세서는 피연산자(operand) 데이터를 저장하기 위한 메모리 기능 슬라이스들(memory functional slices)(MEM들), 수신된 피연산자 데이터에 대한 연산(operation)들(예를 들어, 벡터 프로세싱(vector processing), 행렬 조작(matrix manipulation))을 수행하기 위한 산술 (arithmetic) 기능 슬라이스들, 및/또는 그 유사한 것을 포함할 수 있다. 결정론적 프로세서의 기능 유닛들은 해당 인스트럭션에서 나타낸 방향으로 제1(예를 들어, 시간적) 디멘션(dimension)을 가로질러 피연산자 데이터 를 스트리밍(stream)하고, 제2(예를 들어, 공간적) 디멘션을 가로질러 인스트럭션들을 수신하도록 구성된다. 결정론적 프로세서를 위한 컴파일러(compiler)는 프로세서의 하드웨어 구성을 인식하고, 해당 데이터와 인스트 럭션들이 각 계산 요소에서 미리 결정된 시간에 교차되도록 데이터 및 인스트럭션 흐름들의 타이밍을 설정 (configure)한다. 결정론적 프로세서의 각 기능 슬라이스는 단일 인스트럭션 다중 데이터(Single Instruction Multiple Data, SIMD) 방식으로 데이터 레인(data lanes) 세트 상에서 작동(operate)할 수 있다. 데이터 레인 세트는 여기에서 \"슈퍼레인(superlane)\"로 지칭될 수 있으며 프로세서 칩 상에서의 모든 기능 슬라이스들의 단 면(cross-section)을 나타낸다. 개시된 실시예들은 기능 슬라이싱 아키텍처를 갖는 결정론적 스트리밍 프로세서에 관한 것이다. 일부 실시예들 에서, 결정론적 스트리밍 프로세서는 기능 슬라이싱 아키텍처를 갖는 텐서 스트리밍 프로세서(TSP)를 포함(comprise)할 수 있고, 이는 하드웨어 가속 머신 러닝(machine learning, ML) 애플리케이션들을 위해 사용될 수 있다. 결정론적 스트리밍 프로세서(예를 들어, TSP)는 복수의 \"계산 요소들(computational elements)\"을 포함 (comprise)하며, 각 계산 요소들은 프로세서 내에서의 기능 유닛에 대응한다. 프로세서 아키텍처의 온-칩 메모 리 및 네트워크-온-칩(network-on-chip, NoC)은 피연산자들 및 결과들의 저장을 둘 다 제공하기 위해 융합되며, 프로세서의 기능 유닛들로(to)/로부터(from) 피연산자 및/또는 결과 데이터를 전송하기 위한 전달자(conduit) 역할을 할 수 있다. 결정론적 스트리밍 프로세서의 계산 요소들은 다른 기능들(예를 들어, 메모리, 산술 연산 (arithmetic operation) 등)로 나뉘어지고, 다중-디멘션의 데이터(예를 들어, 텐서들(tensors))에 대해 작동하 는 기능 슬라이스들로 조직된다. 예를 들어, 각 기능 슬라이스는 기능 슬라이스를 형성하기 위해, 수평 및 수 직 모두, 서로 경계를 이루는(border)(또는 인접하는(abut)) 계산 요소들로부터 구성(compose)된다. 계산 요소 들의 수와 각 계산 요소의 계산 세분성(computation granularity)은 구축된 기본 기술을 활용하도록 선택될 수 있다. 메모리(예를 들어, 정적-랜덤 액세스 메모리(static random-access memory, SRAM))의 계산 요소들의 수 (N)와 단어 세분성(M)을 합하는 것은 머신의 벡터 길이(vector length, VL)를 산출한다. 일부 실시예들에서, 결정론적 스트리밍 프로세서의 각 기능 슬라이스는 독립적으로 기능하며, 인스트럭션 제어 유닛(instruction control unit, ICU)으로부터 인스트럭션들(instructions)을 수신한다. ICU는 기능 슬라이스 의 제1 계산 요소에 인스트럭션들을 패스(pass)할 수 있으며, 그런 후에 이는 기능 슬라이스를 따라 프로세서의 제1 시간적 디멘션에서 기능 슬라이스의 나머지 계산 요소들로 전파된다. 반면, 저장 및/또는 프로세싱을 위한 데이터 피연산자들은 제1 시간적 디멘션에 수직인 프로세서의 제2 공간적 디멘션에서, 결정론적 스트리밍 프로 세서의 다른 기능 슬라이스들 간에 패스될 수 있다. 이와 같이, 결정론적 스트리밍 프로세서의 데이터 흐름 및 인스트럭션 흐름은 서로 분리된다. 일부 실시예들에서, 결정론적 스트리밍 프로세서를 위한 컴파일러는 결정론적 스트리밍 프로세서의 하드웨어 구 성을 인식하고, 해당 데이터 및 인스트럭션들이 미리 결정된 시간적 관계(예를 들어, 동일한 클록 사이클(clock cycle) 동안, 미리 결정된 지연으로 분리되는 등)를 갖는 각 계산 요소에서 수신되도록 데이터 및 인스트럭션 흐름들의 타이밍을 동기화한다. 일부 실시예들에서, 미리 결정된 시간적 관계는 결정론적 스트리밍 프로세서의 하드웨어, 인스트럭션의 유형 및/또는 그 유사한 것에 기초할 수 있다. 데이터와 인스트럭션들 간에 시간적 관 계는 컴파일러가 알고 있기 때문에, 계산 요소에 의해 수신된 피연산자 데이터는 데이터가 무엇을 위해 사용될 것인지를 나타내는 임의의 메타데이터를 포함하지 않는다. 대신, 각 계산 요소는 인스트럭션들을 수신하고, 미 리 결정된 타이밍에 기초하여, 해당 데이터에 대한 인스트럭션을 수행한다. 이는 결정론적 스트리밍 프로세서 를 통해 보다 효율적으로 흐르도록 데이터와 인스트럭션들을 허용한다. 본 개시의 실시예들은 집적 회로에 관한 것이다. 집적 회로는 타일(tile) 구조를 형성하는 제1 다이 및 제1 다 이에 연결된 제2 다이를 포함한다. 제1 다이는 제1 디멘션을 따라 제1 시프트(shift) 양만큼, 및 제1 디멘션에 직교하는 제2 디멘션을 따라 제2 시프트 양만큼 제2 다이에 관하여 시프트된다. 타일 구조는 타일 구조의 제1 및 제2 다이들을 가로질러 모델-병렬화(model-parallelism)를 위해 단일 코어 프로세서(single core processor)로 작동하도록 구성된다. 본 개시의 실시예들은 추가로 타일 구조들의 어레이를 포함(comprise)하는 집적 회로에 관한 것이다. 어레이에 서의 각 타일 구조는 제1 다이, 및 페이스-투-페이스(face-to-face, F2F)로 제1 다이에 연결된 제2다이를 포함 한다. 제1 다이는 제1 다이와 제2 다이 간에 오프셋 정렬(offset alignment)을 형성하는 제1 디멘션을 따라 제 1 시프트 양만큼, 및 제1 디멘션에 직교하는 제2 디멘션을 따라 제2 시프트 양만큼 제2 다이에 관하여 시프트된 다. 타일 구조들의 어레이는 타일 구조들을 가로질러 모델-병렬화를 위해 단일 코어 프로세서로 작동하도록 구 성된다. 본 개시의 실시예들은 추가로 스택(stack)된 타일 구조들을 포함하는 집적 회로에 관한 것이다. 집적 회로는 타일-투-타일(tile-to-tile, T2T) 브릿지(bridge)의 제1 사이드(side)에 커플링(couple)된 제1 복수의 타일 구 조들, 및 제1 사이드의 반대편에 있는 T2T 브릿지의 제2 사이드에 커플링된 제2 복수의 타일 구조들을 포함한다. 제1 및 제2 복수들에서의 각 타일 구조는 F2F 구성으로 연결된 제1 다이 및 제2 다이를 포함한다. 제1 다이는 제1 디멘션을 따라 제1 시프트(shift) 양만큼, 및 제1 디멘션에 직교하는 제2 디멘션을 따라 제2 시 프트 양만큼 제2 다이에 관하여 시프트된다. 집적 회로는 제1 사이드에 커플링된 제1 스택의 고대역폭 메모리 들(high bandwidth memories, HBM들), 제2 사이드에 커플링된 제2 스택의 HBM들, 및 제1 복수의 타일 구조들과 제1 스택의 HBM들의 외부 표면들에 커플링된 히트 싱크(heat sink)를 더 포함한다. (예를 들어, 직육면체(cuboid) 구조로 스택된) 스택 타일 구조들은 타일 구조들을 가로질러 모델-병렬화를 위한 단일 코어 프로세서 로 작동하도록 구성된다. 텐서 스트리밍 프로세서의 아키텍처의 개요 본 개시의 실시예들에 따르면, 프로세서 플레인(plane)은, 예를 들어, 캘리포니아, 마운틴 뷰(Mountain View, California)의 GROQ, INC.로부터 상업적으로 이용 가능할 수 있기 때문에, TSP를 포함(comprise)한다. 여기에 설명된 많은 실시예들은 바람직한 프로세서들로 TSP를 사용하긴 하지만, 다른 결정론적 프로세서들은 상용 애플 리케이션들에서 사용될 수 있음이 이해된다. 도면(도) 1a는 일부 실시예들에 따른, TSP에서의 기능 슬라이스들 의 배열을 보여준다. 특정 코어 아키텍처의 요소들은 GPU 및 가속기들(accelerators)과 TSP를 구별한다. 기존의 칩 멀티프로세서 (chip multiprocessor, CMP)에서, 각 “계산 요소(computational element)”는 코어들 간에 데이터를 교환하도 록 온-칩 네트워크를 사용하여 상호 연결되는 독립적인 코어이다. 인스트럭션 실행은 여러 단계들: (i) 인스트 럭션 페치(instruction fetch, IF), (ii) 인스트럭션 디코딩(instruction decode, ID), (iii) 산술 논리 장치 들(Arithmetic Logic Units, ALU들) 상에서의 실행(EX), (iv) 메모리 액세스(MEM), (v) 범용 레지스터들 (general-purpose registers, GPRs)에서의 결과들을 업데이트하는 라이트백(writeback, WB)에 걸쳐 수행된다. 기존의 멀티코어와 대조적으로, 각 계산 요소가 기능 유닛들의 이질적인(heterogeneous) 집합이지만 글로벌하게 동질(homogeneous)한 경우, TSP는 로컬 기능적 동질성을 갖지만 칩-전체의(chip-wide)(글로벌) 이질성을 갖도록 이를 반전시킨다. 보다 구체적으로, TSP는 코어들의 동질의 2-디멘션의 메시(homogeneous two-dimensional mesh)를 도 1a에서 보여지는 기능적으로 슬라이스된 마이크로아키텍처로 재조직한다. 이 접근법에서, 각 계산 요소는 특정 기능을 구현하고 2-디멘션의 온-칩 메시의 Y-디멘션에서 특정 \"기능 슬라이스(functional slice)\" 에 수직으로 스택된다. 도 1a의 탑(top)에서 기능 슬라이스 라벨들에 의해 보여지는 것처럼, TSP는 그의 각각 의(respective) 기능들: (예를 들어, 인스트럭션 제어 유닛(instruction control unit, ICU)을 통한) 인스트럭 션 제어 및 디스패치(dispatch), 메모리(MEM), 정수(INT) 산술(arithmetic), 부동 소수점 유닛(float point unit, FPU) 산술, 및 네트워크(NET) 인터페이스별로 기존의 멀티코어의 기본 요소들을 분해(disaggregate)한다. 2-디멘션의 온-칩 메시의 각 로우(row)는 모든 기능 슬라이스들의 단면(cross section)을 포함(contain)한다. 이 조직에서, 각 기능 슬라이스는 온-칩 역할에 특정된 일련의 인스트럭션들에 의해 독립적으로 제어된다. 예 를 들어, MEM 기능 슬라이스들은 Read(읽기) 및 Write(쓰기)를 지원하지만, Add(추가) 또는 Mui(무이)를 필수적 으로 지원하지 않으며, 이는 전형적으로 선형 회귀 알고리즘(linear regression algorithm)과 같은, 일부 전형 적인 머신 러닝(ML) 알고리즘들을 위한 산술 기능 슬라이스들(예를 들어, 벡터 실행 모듈(vector execution module, VXM) 및 행렬 실행 모듈(matrix execution module, MXM) 기능 슬라이스들)에서 수행된다. 모든 기능 슬라이스의 계산 요소들은 동일한 인스트럭션 스트림(stream)- 단일 인스트럭션 다중 데이터(Single Instruction Multiple Data, SIMD) 인스트럭션들을 실행한다. 따라서, 공통 인스트럭션 디코드(decode) 및 디 스패치(dispatch) 로직은 자체 계산 요소(예를 들어, ICU)로 추출(factor out)될 수 있고 일반 인스트럭션 실행 파이프라인을 두개의 영역들: (i) 인스트럭션 페치, 디코드, 및 파셀링(parceling)과 (ii) 피연산자(operand) 읽기, 실행, 및 라이트백으로 분해(decompose)할 수 있다. 이 접근법은 그의 피연산자들 검색하고 결과들을 저 장(deposit)하는 기능 유닛들로부터 메모리 서브시스템을 디커플링(decouple)한다. 일부 실시예들에서, 각 기능 슬라이스는, 예를 들어, 320-요소 최대 벡터 길이의 16개의 요소들을 생산하는 각 계산 요소를 갖는, 각 기능 슬라이스의 계산 요소들에 걸쳐(span)있는 20-단계 벡터 파이프라인을 구현한다. 이 조직은 자연스럽게 데이터 흐름이 다른 기능 유형들을 지나(pass over)가기 때문에 수평 디멘션에서의 데이 터 흐름과 수직 디멘션에서의 인스트럭션 흐름을 분해한다. 이 프로세서 조직(organization)과 함께, 인스트럭 션 실행은 상이한 계산 요소들에 의해 수행되는데: (수직으로 흐르는) 디스패치(dispatch)된 인스트럭션이, 디 스패치된 인스트럭션이 작동하는, (수평으로 흐르는) 피연산자 데이터와 교차하기 때문에, ICU에서 인스트럭션 페칭(fetching) 및 디코딩(decoding)이 수행되고, 기능 슬라이스의 각 계산 요소에서 피연산자 디코드(operand decode), 실행 및 라이트백(writeback)이 수행된다. 도면들에서 보여지는 예시들과 관련하여 사용된 '수직 (vertical)' 및 '수평(horizontal)' 또는 '북쪽(north)', '남쪽(south)', '동쪽(east)' 및 '서쪽(west)'에 대 한 참조(reference)는 오로지 독자(reader)를 돕도록 의도된 추상화(abstraction)들이며 기술적 한계들로 유추 해서는 안 되는 점이 이해될 것이다. 도 1b는 일부 실시예들에 따른, 예시적인 TSP를 예시한다. TSP은 머신 러닝 애플리케이션들(예를 들 어, 트레이닝 또는 추론)을 위해 입력 데이터에 (예를 들어, 트레이닝된 또는 트레이닝 중인) 가중치 세트들 (weight sets)을 곱하고 더하기 위해 최적화된 메모리 및 산술 유닛들을 포함할 수 있다. 예를 들어, TSP(10 0)는 벡터들(즉, 1-디멘션 어레이들의 값들)에 대한 연산(operation)들을 수행하기 위해 VXM을 포함한다. 시스템의 다른 요소들은 프로세싱 속도를 최적화하기 위해 VXM의 양사이드에 대칭으로 배열된다. 예를 들 어, VXM은 MEM들(111 내지 112), 데이터의 라우팅, 데이터 도메인 및 프레젠테이션(presentation) 컨트롤 러들(또는 수치 해석 모듈들(numerical interpretation modules, NIM들))(115 내지 116)을 제어하기 위한 SXM 들(113 내지 114), 및 MXM들(117 내지 118)에 인접해 있다. 예를 들어, ICU는 블록들(110 내지 118)을 가로질러 데이터의 흐름 및 연산들의 실행을 제어한다. TSP는 칩-투-칩(chip-to-chip, C2C) 회로들(123 내지 124) 및 외부 통신 회로(예를 들어, PCIe)와 같은 통신 회로들을 더 포함할 수 있다. 예를 들어, TSP는 부팅 연산(boot operation)들, 클록 리셋들, 및 다른 저-수준(low level) 셋업 연산들을 제어하도 록 칩 제어 유닛(chip control unit, CCU)을 더 포함할 수 있다. 도 1c는 일부 실시예들에 따른, TSP의 로우(row) 내에서의 조직 및 데이터 흐름을 예시한다. 도 1c에서 보여지는 것처럼, TSP의 2-디멘션의 온-칩 메시의 각 로우(row)는 모든 기능 슬라이스들, 예를 들어, 정수 (INT) 및 부동 소수점(FP) 숫자들(예를 들어, INT8 및 FP16) 둘 다에 대해 구성된 MXM들의 N x N 어레이(예를 들어, N = 320), S MEM 기능 슬라이스들(S = 44), 레인당 V 벡터 ALU들(예를 들어, V = 16)을 가진 VXM 기능 슬라이스들, 및 SXM 기능 슬라이스들의 단면(cross section)을 포함(contain)한다. 이 조직에서, 각 기능 슬라 이스는 ICU들의 해당 어레이에서 페치된 그의 온-칩 역할에 특정된 일련의 인스트럭션들에 의해 독립적으로 제 어된다(예를 들어, 총 I = 144개의 ICU). 개념적으로, 기능 슬라이스들은 고정되고 데이터는 그때-계산 요소들을 가로질러 흐르고 있다. 데이터가 특정 기능 슬라이스를 통해 흐르기 때문에, 각 기능 슬라이스는 선 택적으로 (예를 들어, MXM 및 VXM의 경우) 데이터 피연산자를 가로채고 결과를 계산하거나, (예를 들어, SXM 및 MEM의 경우) 네트워크 상에서 데이터 전송 레인들 간에 데이터를 이동시킬 수 있다. 인스트럭션들은 ICU들로부 터 기능 슬라이스들로 북쪽으로 흐르는 반면, (피연산자들 및 결과들) 데이터는 주로 기능 슬라이스들 간에 동 쪽(east) 및 서쪽(west)으로 흐른다. 임의의 벡터 내에서의 레인-간의 데이터 이동은 온-칩 네트워크 기능 슬 라이스를 사용한다. \"동-서-남-북\" 방향성은 여기에서 논의의 용이성 및 상대성을 위해 제공되는 점이 주목된다. 게다가, “동-서- 남-북” 방향성은 여기에서 설명된 것처럼 프로세싱 흐름의 설명을 위한 참조로 사용되며 특정 방향의 라벨과 관련하여 제한될 의도가 없다. 예를 들어, 북-남은 동-서로 바꾸어질 수 있고(reorient) 현재 동-서로 설명한 원리들은 바꿔진 북-남에 적용할 수 있다. 언급된 참조에 따른 설명에 제한될 의도가 없는 방향성의 또 다른 예로, 방향성은 북-남은 상-하이고 동서는 우-좌이도록 참조될 수 있으며 원리들은 이에 따라 적용할 수 있다. 일 실시예에서, 320 레인들은 온-칩 메시에서의 각 계산 요소가 SIMD 방식으로, 예를 들어, 16-레인들에 대해 작동하는 TSP 상에서 오버레이(overlay)된다. 16-레인 유닛은 여기에서 \"슈퍼레인(superlane)\"으로 지칭 될 수 있으며 칩 상에 모든 기능 슬라이스들의 단면을 나타낸다. 이와 같이, 슈퍼레인은, 예를 들어, 16 요소 들의 아키텍처의 최소 벡터 길이(minVL)를 나타낼 수 있다. 마찬가지로, 기능 슬라이스를 형성하는 20 타일들 의 수직 구성은, 예를 들어, 20 x 16 = 320 기능 유닛들의 최대 벡터 길이(maxVL)를 생산할 수 있다. 144 독립 적인 온-칩 ICU들 각각은 클록 사이클(clock cycle)당 하나 이상의 인스트럭션들을 발행할 수 있다. 컴파일러 는, 예를 들어, ICU들 및 기능 슬라이스들에 의한 실행을 위해 어셈블된 프로그램(assembled program)을 생성하여, 각 인스트럭션 큐(queue)에서의 프로그램 순서의 명시적 제어를 갖는다. 예를 들어, 동쪽으로 32 스 트림들 및 서쪽으로 32 스트림들을 가진, 피연산자들 또는 결과들 온-칩을 이동시키기 위해 64 레인당 로직의 스트림들이 있다. 220MB의 글로벌하게 공유된 SRAM은 레인당 32바이트의 스트림 대역폭과 모델 파라미터에 대 한 저-레이턴시(low-latency) 액세스를 전달(deliver)할 수 있다. MEM은, 예를 들어, SRAM 및 온-칩 네트워크 전송 지연들을 포함하는 30 클록 사이클들 내에서 320 x 320 어레이(즉, 320 레인들 x 320 기능 유닛들)에, 예 를 들어, 100,000 이상의 가중치들을 읽을 수 있고 MXM은 이를 설치할 수 있다. 도 1b 및 도1c에서 보여지는 것처럼, 온-칩 네트워크는 X-Y-X 디멘션 순서 라우팅과 함께 계산 요소들의 X-딤 (dim) 메시와 Y-딤(dim) 메시로 구현된다. 각 인스트럭션은 제1 홉(hop) 방향(동쪽 또는 서쪽)을 지정하고, 그 래서 메모리 인스트럭션 시멘틱들(semantics)은 주소와 데이터 흐름 방향 둘 다를 갖는다(도 1c 참조). 스트림 들은 MEM(111/112)을 통해 X-디멘션으로 라우팅되고 데이터 요소들을 수직으로 이동시키도록 SXM(113/114)의 퍼 뮤터(permuter) 및 레인-시프터(lane-shifter)들을 사용하여 Y-디멘션으로 라우팅된다. SXM(113/114)의 퍼뮤 터는 배열들의 순서가 중요(matter)한 경우에 세트에서 가능한 배열들의 수를 결정하는 수학적 기법인 퍼뮤테이 션 기능(permutation function)을 구현한다. 공통의 수학적 문제들은 특정 순서를 가진 아이템 세트로부터 몇가지 항목들만 선택하는 것을 수반(involve)한다. MEM(111/112) 및 SXM(113/114)은 스트림 데이터가, 각각(respectively), X 및 Y 디멘션들로 흐르기 때문에 스 트림 데이터의 결정론적 라우팅을 제공한다. TSP 아키텍처와 함께, 기능 슬라이스들은 생산자-소비자 방 식(fashion)으로 데이터의 스트림들과 상호 작용한다. 즉, 기능 슬라이스들은 스트림들로부터 피연산자들을 소 모하고 어셈블리 라인 오퍼레이터(assembly line operator)(기능 슬라이스) 및 컨베이어 벨트(conveyor belt) (스트림)같은, (아마도 다른) 스트림에 결과들을 생산한다. 개념적으로, 도 1c에서 보여지는 것처럼 기능 슬라이스들은 고정되고, 데이터는 계산 요소들을 가로질러 흐르고 있다. 데이터가 기능 슬라이스를 통해 흐르기 때문에, (계산 요소가 산술 논리 장치(ALU)를 포함한다면) 각 계 산 요소는 선택적으로 데이터 피연산자들을 가로채고 결과를 계산하거나, 계산 요소가 스위칭 요소를 포함한다 면 네트워크 상에서 레인들 간에 데이터를 이동시킬 수 있다. 스트림들은 프로그래밍 추상화(programming abstraction)를 제공하며, 데이터가 기능 슬라이스들 간에 흐르는 것을 통한 전달자(conduit)이다. GPR들과는 달리, 기능 슬라이스들은 칩을 가로질러 (수평으로) 동쪽 또는 서 쪽으로 흐르는 병렬 데이터 스트림들에 대해 작동한다. 피연산자들을 전달하는 수평으로 흐르는 스트림들은 기 능 슬라이스 상에서의 계산 요소에서 계산을 수행하도록 수직으로(북쪽으로) 흐르는 인스트럭션들(도 1c를 참조)을 가로챈다. 컴파일러는 칩의 아키텍처 상태를 정확하게 유지 관리하고 인스트럭션들이 정확하게 스트림 피연산자(들)을 올바르게 가로채는 것을 보장하기 위해 그 지식을 사용한다. 스트림들은 칩-전체의 스트리밍 레지스터 파일(chip-wide streaming register file)에 의해 하드웨어에 구현된 다. 스트림들은 아키텍처적으로 볼 수 있으며 기능 슬라이스들 간에 피연산자들 및 결과들을 전송한다. 공통 의 소프트웨어 패턴은, 이어서 다운스트림(downstream) 산술 기능 슬라이스에 의해 소모되고 작동되는 하나 이 상의 MEM 기능 슬라이스들로부터 읽기 피연산자 데이터를 수반한다. 그런 후 연산의 결과들은 메모리에 다시 쓰일 수 있거나 후속 계산 요소들로 패스될 수 있도록 또 다른 스트림으로 생산된다. 예를 들어, Z=X+Y 연산 (operation)은 4개의 인스트럭션들을 요구할 수 있다: Read(읽기) S1, X 및 Read S2, Y는 두 개의 MEM 기능 슬 라이스들 상에서 실행되고 Add(추가) S1, S2, S3을 수행하도록 ALU 기능 슬라이스로 향해 안쪽으로 디렉팅 (direct)된다. 마지막으로, 결과는 Write(쓰기) S3, Z를 통해 메모리에 다시 저장된다. 스트림들은 각 기능 슬라이스에 의해 SIMD 방식으로 연산되는, N-요소들의 집합을 나타낸다. 예로서, TSP 아키텍처는 하드웨어-소프트웨어 인터페이스 상에서 여러 의도적인 트레이드오프들(tradeoffs)로 이루어지고, 스케줄링(scheduling)과 관련된 복잡성을 컴파일러로 밀어 넣는다. 특히, 인스트럭션들을 정확하 게 스케쥴링하는 것은 하드웨어를 정확하고 효율적으로 사용하도록 컴파일러에 속한다. 때때로 이는 알고리즘 또는 메타-연산이 하드웨어에서 실현될 수 있는 여러 수단들 중 하나를 선택하는 것을 수반할 수 있다. 다중- 발행 실행 유닛들에 대한 동적 인스트럭션 스케줄링의 제어 복잡성을 제거하는 것은 ICU가, 예를 들어, 칩 영역 의 3%보다 적게 차지하여(account for), 상대적으로 작아지게 한다. 컴파일러는, 예를 들어, 온-칩 메시에서의 각 계산 요소가 SIMD 방식으로 16-레인들에서 작동하는 TSP 아키텍처 에 오버레이된 320-레인 프로그래밍 추상화에 액세스한다. 16-레인 유닛은 칩 상에 모든 기능 슬라이스들의 단 면 또는 계산의 최소 단위(granularity)인 '슈퍼레인'으로 지칭될 수 있다. 이와 같이, 슈퍼레인은 16 요소들 의 아키텍처의 최소 벡터 길이(minVL)를 나타낸다. 마찬가지로, 기능 슬라이스를 형성하는 20 타일들의 수직 구성은, 20x16=320 요소들의 최대 벡터 길이(maxVL)를 생산한다. 컴파일러는, 예를 들어, 온-칩의 144 독립적인 인스트럭션 큐들(즉, ICU들): (a) 두 독립적인 2-디멘션의 MAC (곱셈-누적) 어레이들을 포함하는 서쪽을 향한 MXM에 대한 6; (b) 벡터들의 요소들을 재배열하여 슈퍼레인-내 (intra-superlane) 및 레인-간(inter-lane) 스위칭을 위해 서쪽을 향한 SXM에 대한 14; (c) 정적 랜덤-액세스 메모리(static random-access memory, SRAM)의 44 병렬 기능 슬라이스들을 포함하는 서쪽을 향한 MEM에 대한 44; (d) 레인당 16 벡터 ALU들을 포함하는 VXM에 대한 16; (e) SRAM의 44 병렬 기능 슬라이스들을 포함하는-동 쪽을 향한 MEM에 대한 44; (f) 동쪽을 향한 SXM에 대한 14; 및 (g) 두 독립적인 2-디멘션의 MAC 어레이들을 포 함하는 동쪽으로 향한 MXM에 대한 여섯에 액세스하고, 각 인스트럭션 큐는 사이클당 하나 이상의 인스트럭션들 을 발행할 수 있고 컴파일러는 각 인스트럭션 큐에서 프로그램 순서를 명시적으로 제어한다. 컴파일러는, 예를 들어, 레인당 64 논리 스트림들에 액세스한다. 예를 들어, 32 로직의 스트림들은 32 스트림 들을 가진 온-칩의 피연산자 또는 결과들을 동쪽으로 이동시키고 32 스트림들을 가진 온-칩의 피연산자 또는 결 과들을 서쪽으로 이동시키기 위해 레인당 16 minVL 상에서 작동하는 것을 필요로 한다.컴파일러는, 예를 들어, 레인당 32바이트(bytes)의 스트림 대역폭 및 모델 파라미터들에 대해 저-레이턴시 액세 스를 전달(deliver)하는 220메가바이트(Mbytes)의 글로벌하게 공유된 SRAM에 액세스한다. 예를 들어, MEM은 SRAM 및 온-칩의 네트워크 전송 지연을 포함하는 40회 보다 더 적은 작동 사이클들로 모든 네 개의 320x320 어 레이들에 400K 가중치들을 읽고 MXM은 이를 설치할 수 있다. 스트림들은 식별자(0, ...,31) 및 방향 둘 다에 의해 지정된다. 예를 들어, 인(in)은 스트림 28을 안쪽으 로 지정하고, 아웃(out)는 스트림 24를 칩의 바깥쪽 가장자리를 향하게 지정한다. 스트림의 방향은 (칩 분 기 쪽으로) 안쪽 또는 (칩의 바깥쪽 가장자리를 향하는) 바깥쪽으로 지정될 수 있거나, 방향은 도 1c에서 보여 지는 것처럼, 동쪽 또는 서쪽으로 지정될 수 있다. 도 1c에서 보여지는 것처럼, 슈퍼레인의 구성 요소들은 공간적으로 조직된다. TSP의 인스트럭션 세트 아키텍처 (instruction set architecture, ISA)는 다른 기능 영역들을 포괄하는(spanning) 인스트럭션들을 정의한다. MEM 기능 슬라이스들에 의해 제시되는 분할된 글로벌 주소 공간(partitioned global address space, PGAS)은 SRAM으로부터 주소가 지정(address)된 벡터들을 위한 메모리 시맨틱들(semantics)을 제공하고, 벡터들(them)을 연산하도록 의도된 기능 슬라이스를 향한 데이터흐름의 방향과 함께 아키텍처적으로 보이는 스트림으로 로드한 다. 제1 기능 영역(즉, ICU)은 IFetch 인스트럭션(들)을 가진 명시적 인스트럭션 페칭을 제공하고, 슬라이스-간 동 기화는 참여하는 기능 슬라이스들 중에서 칩-전체의 배리어 동기화(barrier synchronization)를 수행하도록 Sync 및 Notify 인스트럭션들을 사용한다. 반복된-NOP(no-op) 인스트럭션은 인스트럭션-간 지연의 정밀한 사이 클-바이-사이클(cycle-by-cycle) 제어를 허용한다. 예를 들어, 컴파일러는 N 사이클들이 연산들(them)(예를 들 어, OpA NOP(N) OpB)을 분리하도록 중간 NOP를 사용하여 두 개의 연산들(A 및 B)을 스케줄링하는 경우에 사이클 -정확도 제어를 갖는다. 제2 기능 영역(즉, VXM)은 포인트-와이즈(point-wise) 산술 연산들을 위해 각 레인에서의 4x4 메시의 ALU들로 구성된다. 제3 기능 영역(즉, MXM)은 예를 들어, INT8 또는 FP16 데이터 타입들에 대해 연산하는 네 개의 독립적인 2-디멘 션의 MAC 어레이들로 구성된다. 온-칩의 데이터 이동은 벡터들의 요소들을 재배열하여 슈퍼레인-내(intra-superlane) 및 레인-간(inter-lane) 스위칭을 위한 제4 기능 영역(즉, SXM)을 사용한다. SXM은 도 1a에서의 코어들 간에 통신하는 NET 인터페이스 와 유사(analogous)하다. MEM과 SXM은 함께 온-칩 네트워크의 X-Y 디멘션들을 형성하도록 나란히(in tandem) 작업(work)한다. 제5 기능 영역(즉, 온-칩 MEM 모듈의 동반구 및 서반구)은 SRAM의 44 병렬 MEM 기능 슬라이스들로 구성되며, 각 각의 동 또는 서 방향으로 32 스트림들을 완전히 활용하는 데 필요한 메모리 액세스 동시성을 제공한다. 각 기 능 슬라이스는 16-바이트(byte) 메모리 단어들의 13-비트(bits)의 물리적 주소 지정하는 것을 제공하며, 총 220 메가바이트(Mbytes)의 온-칩 SRAM에 대하여, 각 바이트를 레인에 매핑한다. 추가적인 제6 기능 영역은 한 쌍의 TSP 칩 간에 320-바이트(byte) 벡터들을 교환하기 위한 Send 및 Receive 프 리미티브(primitive)들을 제공하도록 구성된 C2C 모듈들을 포함한다. 하나의 가능한 TSP 구현은, 예를 들어, 대규모 시스템들을 위한 TSP들의 고-래딕스(high-radix) 상호 연결 네트워크들을 지원하기 위해 유연하게 분할 (partition)될 수 있는 오프-칩 핀 대역폭의 16 x 4 x 30Gbps x 2 방향들 = 3.84Tb/s(초당 테라바이트(Tera- bytes per second))의 총 오프-칩 대역폭에 대해 각각 30Gbps에서 연산하는 총 16 x 4 개의 링크들을 갖는다. 주변의 컴포넌트 인터커넥트 익스프레스(peripheral component interconnect express, PCIe) Gen4에 대한 호스 트 인터페이스(host interface)는 또한 이 모듈에서 핸들링(handle)될 수 있다. 호스트 인터페이스는 TSP 메모 리에 모델을 설치(emplace)하기 위한 경량의(lightweight) 직접 메모리 액세스(direct memory access, DMA) 엔 진을 제공하며 모델 실행을 부트스트랩(bootstrap)하기 위한 진입점(entry point)을 제공한다. 예를 들어, 호 스트 인터페이스는 또한 호스트에 인터럽트를 패스(pass)하기 위한 일반적인 메커니즘을 제공하며, 이는 멀티- 비트 메모리 오류가 관찰되는 경우에 필요할 수 있다."}
{"patent_id": "10-2024-7031494", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 1은 일부 실시예들에 따른, 각 기능 슬라이스에 대한 예시적인 인스트럭션들의 요약을 제공한다."}
{"patent_id": "10-2024-7031494", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 1각 기능 슬라이스에 대한 인스트럭션들의 요약 인스트럭션 설명 ICUNOP N Ifetch Sync Notify Config Repeat n, dN 사이클에서의 지연을 위해 N 번 반복될 수 있는 비-연산(No-operation) 스트림들 또는 로컬 메모리로부터의 페치(fetch) 인스트럭션들 배리어(barrier) 통지를 기다리기 위해 인스트럭션 페치 큐의 헤드에서 대기(park) 인스트럭션 흐름으로 하여금 재개하게 하는 보류중인 배리어 연산들을 해제 저-전력 모드(low-power mode)를 구성 반복들 간에 d 사이클들을 가진, 이전 인스트럭션을 n번 반복 MEMRead a,s Write a,s Gather s, map Scatter s, map주소a에서 벡터를 스트림 s로 로드 스트림 s 레지스터 컨텐츠를 주 메모리 주소 a로 저장 스트림 s로 넣어진(put) 맵(map)에 의해 포인팅(point)된 주소들을 간접적으로 읽기 map 스트림에서의 주소로 스트림 s를 간접적으로 저장 VXMUnary Operation Binary Operationtype Conversions ReLU TanH Exp RSqrt1 개의 결과(z)를 생산하는, 1개의 피연산자(x)에 대한 z = op x 포인트- 와이즈(point-wise) 연산(예를 들어, mask, negate) 1 개의 결과(z)를 생산하는, 2개의 피연산자들(x 및 y)로 = x op y 포인트-와이 즈(point-wise) 연산(예를 들어, add, mul, sub) 고정 소수점(fixed point)을 부동 소수점(floating point)으로 변환하고, 그 반 대로 변환 정류된 선형 유닛(rectified linear unit) 활성화 함수 max(0, x) 쌍곡선 탄젠트-활성화 함수 지수 ex 역수 제곱근 MXMLW IW ABC ACC스트림들로부터 가중치 버퍼로 가중치들(LW)을 로드 스트림들 또는 LW 버퍼로부터의 가중치들(IW)을 320x320 어레이에 설치 도착하는 활성화들을 개시하고 조정하기 위한 활성화 버퍼 제어(Activation buffer control, ABC) MXM로부터 INT32 또는 FP32 결과를 누적(ACC) SXM시프트 up/down N 퍼뮤트 map Distribute map Rotate stream Transpose sg16N개의 레인들에 의해 스트림들을 위/아래로 레인-시프트(lane-shift)하고, 북/ 남 시프트된 벡터들 사이에서 선택 320개의 입력들 출력들을 바이젝티브 퍼뮤트함(bijective permute) 슈퍼레인(16개의 레인들) 내에서 데이터를 재배열 또는 복제 모든 가능한 회전들과 함께 n2(n=3 또는 n=4) 출력 스트림들을 생성하도록 nxn 입력 데이터를 회전 서로 바뀐 로우와 컬럼들을 가진 16 출력 스트림들을 생산하는 16x16 요소들을 바꿈 C2CDeskewSend Receive독립 동기(plesiochronous) 링크들을 가로질러 skew를 관리 320-바이트 벡터를 전송 320-바이트 벡터 수신, 주 메모리에 배치 다른 기능 슬라이스들 상에서 수행되는 일련의 인스트럭션들은 중간 결과들을 메모리에 다시 쓸 필요 없이 더 복잡한 액션들(actions)을 만들도록 연쇄될 수 있다. 이는 최대 대역폭과 최저 레이턴시(latency)에서 스트림 들의 효율적인 프로세싱을 허용한다. 머신 러닝 알고리즘들은 전형적으로 특정된 데이터 유형(예를 들어, INT8, FP16 등)의 계수(coefficient)들을 가진 벡터들에 대해 연산한다. 이 벡터들은 기본 데이터에 대한 추상화로 해석될 수 있으며, 그 요소들은 SIMD 방식으로 동일한 연산에 의해 프로세싱될 수 있다. TSP는 때때로 랭크-2 텐서들로 조직된, 벡터들에 대해 연산 하며, 더 높은 등급의 텐서들을 랭크-2 텐서들로 변형(transform)시키도록 그래프-하락(graph-lowering) 컴파일러를 의존한다. TSP의 프로그래밍 모델은 각 기능 슬라이스가 하나 이상의 스트림들의 소비자 및 생산자 역할을 하는 생산자-소 비자 모델이다. 벡터가 주 메모리로부터 읽히는 경우, 벡터는 스트림 식별자(0, ..., 31) 및 방향: 동쪽, 또는 서쪽이 주어진다. 일단 벡터가 스트림 레지스터로 읽히면 벡터(it)는 스트림이고 다음의 의미에서 주어진 방향 으로 \"흐르는 것(flowing)\" 이다: (공간 좌표가 흐름의 방향으로 증가하는) 좌표들(x0, x1, x2)에서 공간적으로 인접한 기능 슬라이스들을 고려해볼 때, 그런 후에 주어진 시간(ti)에서, 기능 슬라이스(x1)에서 스트림(s1)을 나타내는 벡터는 그 기능 슬라이스에 의한 피연산자들로 액세스될 수 있다. 유사하게, x0와 x2에서 기능 슬라이 스들은 동일한 스트림 레지스터에 대한 다른 스트림 값들에 액세스할 것이다. 다음 사이클(ti+1)에서, 값(s1)은 x2에서 기능 슬라이스로 전파하거나, 그렇지 않으면 값(s1)은 사이클(t)에서 x1에서의 기능 슬라이스에 의해 생 산된 결과(r1)로 덮어씌워진다(overwrite). 유사하게, 시간(ti)에서의 좌표(x0)에서 기능 슬라이스에 의해 소모 되도록 존재했던 스트림 값(s0)은 다음 사이클(ti+1)에서 x1에서의 기능 슬라이스로 (시간(ti)에서의 값을 덮어쓰 는 x0없이) 이용가능할 것이다. 스트림 피연산자들은 피연산자들(them)을 소모하고 결과 스트림을 생산하는 기 능 슬라이스를 향해 움직(steer)인다. 스트림들은 칩을 가로질러 끊임없이 흐르며, 기능 슬라이스들이 서로 통 신하는 방법으로 서브(serving as)한다. TSP 프로그래밍 모델에서, 인스트럭션은 주어진 컴파일러-스케줄링된 시간(t)에서 기능 슬라이스 상에 발행되고, (예를 들어, 320-요소들까지의) 스트림-공급된 피연산자 벡터들에 대한 SIMD 연산으로 실행되며, 결 과 스트림들 상에서 동일한 길이의 벡터들을 생산한다. 예를 들어, 마이크로-아키텍처 수준에서, 320-요소 SIMD 인스트럭션은 기능 슬라이스에서의 계산 요소들의 수직 스택을 가로질러 파이프라인으로 수송된다 (pipeline). 즉, 스케줄링된 시간(t)에서, 인스트럭션은, 예를 들어, 피연산자/결과 벡터들의 제1 16-요소 슈 퍼레인에 대응하는, 기능 슬라이스의 가장-아래쪽(bottom-most) 계산 요소에 발행될 수 있다. 이후 연산 사이 클에서, 인스트럭션은 기능 슬라이스에서의 북쪽으로 다음 계산 요소에 전파될 수 있고, 이는 결과적으로 피연 산자 벡터들의 다음 16-요소 슈퍼레인 상에 인스트럭션을 실행한다. 이 프로세스는 프로세스가, 예를 들어, 기 능 슬라이스에서의 모든 20-계산 요소들을 횡단(traverse)할 때까지 사이클-바이-사이클(cycle-by-cycle)을 계 속한다. 정확한 시간에서 일치하는 피연산자들과 인스트럭션들에 대한 필요성에 따라, 위에서 설명한 수직 인 스트럭션 파이프라인으로 수송되는 것(pipelining)의 조합은 SIMD 피연산자와 결과 데이터의 공간적 “스태거 (stagger)”를 초래한다. 다수의 다이 프로세서들을 위한 타일 구조들 본 개시의 실시예들은 다수의 다이 장치들의 구현을 위한 타일 구조들과 관련된다(relate to). 타일 구조는 제 2 프로세싱 유닛 어레이를 갖는 제2 다이와 페이스-투-페이스(face-to-face, F2F) 구성으로 연결된 제1 다이 상 에 제1 프로세싱 유닛 어레이를 포함할 수 있다. 타일 구조는 다수의 프로세서들 또는, 일부 실시예들에서, GROQ, INC으로부터 상업적으로 이용 가능한 TSP와 같은 다중-다이 단일 프로세서를 갖는 다양한 다수의 다이 장 치들을 구현하기 위해 하나 이상의 다른 타일 구조들(즉, 다른 다이)과의 연결을 허용하는 특정 인터페이스들을 더 포함할 수 있다. 여기에 제시된 타일 구조는 임의의 인터포저(interposer) 기반 인터페이스(예를 들어, 실 리콘-기반 인터포저)를 활용하는 것 없이 다수의 타일들의 효율적인 커플링을 허용한다. 일부 다른 실시예들에 서, 여기에 제시된 타일 구조는 F2F 구성, 페이스-투-백(Face-to-Back, F2B) 구성 또는 백-투-백(Back-to- Back, B2B) 구성으로 연결된 한 쌍의 인공 지능(artificial intelligence, Al) 프로세서를 포함한다. 도 2a는 일부 실시예들에 따른, 예시적인 타일 구조를 예시한다. 타일 구조는 타일 구조를 형 성하는 다이와 다이에 연결된 다이를 포함한다. 도 2a에 도시(show)되는 것처럼, 타일 구조 내 다이들(202, 204)은 스택된, 오프셋 구성으로 배치(position)된다. 다이는 타일 구조 아 래에서 바깥으로 확장(extend)한 바텀 확장(bottom extension)을 가진 바텀 다이(bottom die)이고 \"셀프 (shelf)\"으로 지칭(refer to)될 수 있지만, 다이는 다이의 하나의 가장자리(edge)를 넘어(over) 바 깥으로 확장한 탑 확장(top extension)을 갖는 탑 다이(top die)이고 “렛지(ledge)”로 지칭될 수 있다. 다이 는 타일 구조를 형성하는 F2F 구성으로 다이에 연결된다. 타일 구조를 형성하는 F2F 구성 에 대한 세부 사항들은 도 3과 함께 아래에서 설명된다. (즉, 렛지를 형성하는 다이의 일부를 가진) 다이는 (즉, 셀프를 형성하는 다이의 일부를 가진) 다이에 대하여 제1 디멘션(예를 들어, x 디멘션 또는 수평 디멘션)에 따라 제1 시프트 양만큼 및 제1 디멘션에 직교하는 제2 디멘션(예를 들어, y 디멘션 또는 수직 디멘션)에 따라 제2 시프트 양만큼 시프트될 수 있다. 제1 시프트 양은 제2 시프트 양과 같거나 다를 수 있다. 다이는 제1 복수의 기능 유닛들(즉, 기능 슬라이스들)을 갖는 제1 TSP를 포함(comprise)할 수 있고, 다이는 제2 복수의 기능 유닛들(즉, 기능 슬라 이스들)을 갖는 제2 TSP, 메모리 장치(예를 들어, HBM), 인터페이스 칩(interface chip), 일부 다른 칩, 또는 이의 일부 조합: 중 하나를 포함할 수 있다. 바람직한 실시예에서, 타일 구조는 각 다이(202, 204) 상에 프로세싱 유닛들(즉, 기능 슬라이스들)을 가진 단일 스트리밍 프로세서(즉, 단일 코어 TSP)를 형성한다. 다른 실시예들에서, 타일 구조는 복수의 다수의 코어 장치들 또는 다른 회로들을 포함할 수 있다. 도 2a에서 도시되는 타일 구조 및 렛지/셀프 구성은 추가 타일 구조들이 타일 구조에 전기적으로 연결할 수 있 게 한다. 도 2b는 일부 실시예들에 따른, 타일 구조의 예시적인 다이를 예시한다. 다이는 프로세싱 유닛 들 및 예를 들어, TSP(예를 들어, TSP)의 인터페이스 회로를 포함할 수 있다. 프로세싱 유닛들(20 6)은 복수의 TSP의 기능 슬라이스들을 포함할 수 있다. 하나 이상의 실시예들에서, 타일 구조의 다이 는 다이와 동일한 구조를 가지며, 다이를 갖는 단일 코어 TSP를 형성한다. 다시 말하자면, 타 일 구조는 단일 코어 TSP를 포함할 수 있다. 하나 이상의 다른 실시예들에서, 다이는 HBM, 인터페이 스 칩, 일부 다른 칩, 또는 이의 일부 조합을 포함한다. 다이의 인터페이스 회로는 다이-투-다이(D2D) 핀들의 제1 세트, D2D 핀들의 제2 세트, 타일-투- 타일(T2T) 핀들의 제1 세트, 및 T2T 핀들의 제2 세트를 포함할 수 있다. D2D 핀들의 제1 세트 를 포함하는 제1 D2D 상호 연결 영역(area) 및 D2D 핀들의 제2 세트를 포함하는 제2 D2D 상호 연결 영역은 타일 구조를 형성하기 위해 (도 3에서 더 도시되는 것처럼) F2F 구성으로 다이와의 연결을 위한 다이 의 인터페이스 영역들을 나타낸다. 하나 이상의 실시예들에서, 제1 및 제2 D2D 상호 연결 영역들은 다이 의 해당 연결 회로들(예를 들어, D2D 핀들)과 초음파로 본딩(bond)된 D2D 핀들(208, 210)의 적어도 하나의 서브세트를 통해 다이에 커플링(couple)된다. 하나 이상의 다른 실시예들에서, 제1 및 제2 D2D 상호 연결 영역들은 D2D 핀들(208, 210)의 적어도 하나의 서브세트가 다이의 해당 연결 회로들(예를 들어, D2D 핀 들)과 물리적 접촉으로 배치되는 곳에서 전기적 연결들을 형성하여 다이에 커플링된다. 다이의 렛지 존(ledge zone)(및 유사하게 다이의 셀프 존)은 타일 구조를 하나 이상의 다른 타 일 구조들과 연결하기 위해 사용된 T2T 핀들(212, 214)의 제1 및 제2 세트들을 포함할 수 있다. T2T 핀들(212, 214) 주변의 영역들은 타일 구조와 또 다른 타일 구조가 그의 해당 T2T 핀들이 정렬되는 곳마다 전기적인 연결을 형성하여 서로 상호 연결할 수 있게 하도록 렛지 존(또는 유사하게 다이와 동일한 구조의 다이 에 대한 셀프 존)을 형성할 수 있다. T2T 핀들(212, 214)은 인접한 타일 구조의 해당 T2T 핀들과 임의의 필요한 다이-투-간격(예를 들어, 대략 0.1mm 내지 0.5mm)에 맞춰 조정(align with)하도록 충분히 멀리 간격을 둘(space) 수 있다. 다이의 렛지 존(및 유사하게 다이의 셀프 존)은 하나의 영역이 다이의 '사 이드(side)' 가장자리를 따라 있고 다른 영역이 다이의 '탑(top)' 가장자리(또는 다이의 '바텀 (bottom)' 가장자리)를 따라 있도록 두개의 영역들로 분기(bifurcate)된다. 따라서, 타일 구조는 밀접하 게 커플링된 3-구조 장치를 형성하도록 다이의 두개의 렛지 영역들을 사용하여 한 쌍의 타일 구조에 커플 링할 수 있다. 유사하게, 타일 구조의 다이는 다이의 셀프 영역들 내 해당 T2T 핀들을 사용하 여 또 다른 쌍의 타일 구조에 커플링할 수 있다. 도 2c는 일부 실시예들에 따른, T2T 브릿지를 갖는 예시적인 타일 구조를 예시한다. 일부 실시 예에 따라 타일 구조는 타일 구조와 동일한 구성을 가진다. 하나 이상의 실시예에서, 타일 구조의 렛지 및/또는 셀프 다이는 인접한 타일 구조로부터 패스된 데이터의 저장을 위해 공유된 메모리(예를 들어, HBM)에 T2T 브릿지를 통한 직접 T2T 연결을 형성한다. T2T 브릿지는 타일 구조의 하나의 사이 드에 따라, 예를 들어, 타일 구조의 셀프(즉, 바텀 다이)의 위에 가용 공간 상에 배치될 수 있다. 대체적 으로(도 2c에 미도시), T2T 브릿지는 타일 구조의 일부 다른 사이드에 따라(예를 들어, 타일 구조 의 바텀 사이드에 따라) 배치될 수 있다. T2T 브릿지는 인접한 타일 구조와의 연결을 위해 T2T 핀들 을 포함할 수 있다. T2T 브릿지는 인접한 타일 구조의 하나의 다이 또는 양 다이와의 연결을 위해 T2T 브릿지의 한 사이드 또는 양 사이드에 T2T 핀들을 갖는 연결 패드들을 포함할 수 있다. 일부 실시예들에서, T2T 브릿지는 타일 구조의 하나의 다이로부터의 전력(power)을 인접한 타일 구조 의 또 다른 다이에 대하여 전달(delivery)하기 위해 이용된다. 이러한 경우, 미러 이미징(mirror imaging)은, 예를 들어, 파워 서플라이(power supply) VDD 및 VSS 연결의 구현을 위해 타일 구조의 렛지와 셀프 다이들 간에 필요할 수 있다. T2T 브릿지의 T2T 핀들은 T2T 브릿지 다이의 가장자리들에 근접한 존에 바람직하게 배치된다. 예를 들어, T2T 브릿지 다이의 가장자리에 따른 영역은 T2T 핀들의 제1 서브세트를 포 함할 수 있고, T2T 브릿지 다이의 탑 또는 바텀 중 하나에 따른 영역은 T2T 핀들의 제2 서브세트를 포함 (contain)할 수 있다. T2T 핀들은 또 다른 타일 구조 또는 다이의 핀들에 연결되는 경우에 그렇게 함으로 써 형성된 낮은 옴(ohmic) 연결로 인해 고속 데이터 전송을 가능하게 하는 전기적 연결을 형성할 수 있다. 도 2c에서 더 도시되는 것처럼, 하나 이상의 실시예들에서, 적어도 하나의 입출력(inputoutput, IO) 다이 는 하나 이상의 호스트 컴퓨터들, 하나 이상의 센서들(예를 들어, 카메라 또는 다른 이미징 장치), 메모리 장치 (예를 들어, HBM 구조), 또는 일부 다른 외부 장치와 같은 하나 이상의 외부 장치들과의 연결을 용이하게 하기 위해 타일 구조의 하나 이상의 사이드들에 따라 배치된다. IO 다이는 상호 연결 핀들이 타일 구조의 해당 T2T 핀들과 짝을 이루도록(mate with) 배치되는 곳에서 상호 연결 핀 존을 포함할 수 있다(도 2c에 미도시). 일부 경우에, IO 다이는 외부 장치들에 의해 부과된 제약들로 인해 타일 구조의 셀프 또는 렛지에 위치한 핀들에 직접 커플링할 수 없을 수 있다. 이러한 상황에서, T2T 브릿지는 IO 다이를 타 일 구조에 커플링하도록 사용될 수 있다. 인접한 타일 구조들의 밀접하게 배치한 다이들은 연결된 타일 구조들의 탑(및/또는 바텀) 사이드들로부터의 열 기(heat)의 제거를 위해 향상된 열 전도성(thermal conductivity)을 제공할 수 있음을 주목해야 한다. 여기에 제시된 F2F 타일 구성은 인접한 타일 구조들의 다이들 간에 사실상 갭(gap)이 없음을 보장하기 위해 선호되는 접근법을 나타낸다. 좋고(good) 균일한 열 전도를 가지는 것은, 예를 들어, 타일 구조의 탑 사이드에서의 쿨링 시스템을 사용하여 효율적인 쿨링(cooling) 및 열기의 제거를 용이하게 한다. 타일 구조들의 쿨링(cooling)에 대한 더 많은 세부 사항들은 도 8b와 함께 아래에 제공된다. 도 2d는 일부 실시예들에 따른, 메모리 장치와 커플링된 예시적인(example) 타일 구조를 예시한다. 타일 구조는 다이(예를 들어, 탑 다이 또는 렛지) 및 다이(예를 들어, 바텀 다이 또는 셀프)를 포함할 수 있다. 타일 구조는 타일 구조의 일 실시예일 수 있고, 즉, 다이는 F2F 구성으로 다 이에 연결될 수 있다. 일부 실시예들에서, 다이(및/또는 다이)의 T2T 핀들의 적어도 하나의 서브 세트는 하나 이상의 관통- 실리콘 비아(through-silicon via, TSV) 커넥터들을 포함한다. TSV 커넥터들은 타일 구조가 (예를 들어, 도 4에 도시된 수평 연결에 추가로) F2F 구성, F2B 구성 또는 B2B 구성으로 또 다른 타일 구조와 수직으로(예를 들어, z 디멘션에 따라) 연결되게 할 수 있다. 하나 이상의 실시예들에서, (F2F 구성, F2B 구성 또는 B2B 구성으로) 타일 구조에 커플링된 다른 타일 구조는 TSP, 메모리 장치(예를 들어, HBM 장치), 인터페이 스 장치, 일부 다른 장치, 또는 이의 조합을 포함할 수 있다. 도 2d에서 도시되는 것처럼, 일부 실시예들에서, 메모리 장치(예를 들어, HBM 장치)는 타일 구조의 위에 배치되고 TSV 커넥터들을 통해 다이(즉, 렛지)에 연결된다. 다른 실시예들(도 2d에 미도시)에 서, 브릿지 다이는 타일 구조의 다이(즉, 렛지) 또는 다이(즉, 셀프) 중 하나에 배치된 핀들로 부터의 연결을 인접한 타일 구조 또는 타일 구조의 위에 스택된 또 다른 장치(예를 들어, HBM 장치) 중 하나에 제공할 수 있다. 브릿지 다이를 사용하여 집적 회로에서의 HBM 장치들과 타일 구조들을 스택하는 것에 대한 더 많은 세부 사항들은 도 7a 내지 도 7b 및 도 8a 내지 도 8b와 함께 아래에 설명된다. 도 3은 일부 실시예들에 따른, 타일 구조 내에서의 예시적인 데이터 흐름을 예시한다. 타일 구조는 타일 구조의 일 실시예일 수 있다. 타일 구조는 F2F 구성으로 연결된 한 쌍의 다이(305A, 305B)를 포함한다. (예를 들어, 도 3에 도시되는 것처럼, 해당 D2D 핀들(310A, 310B)의 일부로서) 각 다이(305A, 305B)에 통합된 인스트럭션 제어 유닛(Instruction Control Unit, ICU)은 각 다이(305A, 305B)에서의 하나 이 상의 프로세싱 유닛들(예를 들어, 하나 이상의 기능 슬라이스들(functional slices)의 계산 요소들)에 의한 실 행을 위해 인스트럭션들을 발행할 수 있다. ICU에 의해 인스트럭션들이 발행되면, 데이터 흐름은 각 다이 (305A, 305B) 내 프로세싱 유닛들을 통해 개시되고, 결과 데이터는 타일 구조의 각 다이(305A, 305B)의 해 당 D2D 핀들(315A, 315B)에 반환된다(도 3에 \"데이터 반환\"으로 도시됨). 타일 구조의 사이드 뷰(side view)에 의해 도시되는 것처럼, 결과 데이터는 D2D 핀들(310A, 310B)을 통해 타일 구조 내에서 하나 의 다이로부터 또 다른 다이로 패스(pass)될 수 있으므로, 타일 구조의 한 쌍의 다이(305A, 305B) 간에 고 속 데이터 통신이 제공된다. 도 4는 일부 실시예들에 따른, 다양한 다수의 다이 프로세서 아키텍처들의 구현을 위한 타일 구조들의 2-디멘션 의(dimensional) 어레이들의 예들을 예시한다. 일 실시예에서, 집적 회로는 타일 구조(예를 들어, 일 실 시예의 타일 구조)를 형성하는 F2F 구성으로 연결된 한 쌍의 다이로 구성(compose)된 결정론적 스트리밍프로세서를 나타낸다. 둘 이상의 타일 구조들을 수평으로 연결하여, 다양한 다수의 다이 프로세서들이 구현될 수 있다. 도 4에서 도시되는 것처럼, 집적 회로는 타일 구조들의 1x2 어레이로 수평 연결된 한 쌍의 타일 구조를 포 함한다. 이 경우, 제1 타일 구조의 탑 다이는 (예를 들어, 해당 T2T 핀들을 통해) 제2 타일 구조의 바텀 다이 에 연결될 수 있고, 제1 타일 구조의 바텀 다이는 (예를 들어, 해당 T2T 핀들을 통해) 제2 타일 구조의 탑 다이 에 연결될 수 있다. 이는 제2 타일 구조가 제1 타일 구조의 사용 가능한 다이 영역들에 맞출(fit) 수 있도록 각 타일 구조에서 서로에 대하여 탑 및 바텀 다이들을 시프트(shift)시켜 가능해진다. 도 4에서 더 도시되는 것처럼 다른 다수의 다이 프로세서들을 구현하기 위해, 동일한 프로세스는 x 및 y 디멘션들 둘 다에서 여러 번 반복될 수 있다. 도 4에서 도시되는 것처럼, 예를 들어, 네 개의 타일 구조들은 집적 회로를 형성하는 타 일 구조들의 2x2 어레이에 수평으로 연결될 수 있고; 여섯 개의 타일 구조들은 집적 회로를 형성하는 타일 구조들의 2x3 어레이에 수평으로 연결될 수 있으며; 및 여덟 개의 타일 구조들은 집적 회로를 형성하는 타 일 구조들의 2x4 어레이에 수평으로 연결될 수 있다. 타일 구조들의 각 어레이(즉, 각 집적 회로(405, 410, 415, 420, 425))는 타일 구조들의 다이들을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구 성될 수 있다. 도 4는 TSP 장치와 같이 확장 가능한(extendable) 결정론적 스트리밍 프로세서 아키텍처들을 예시하도록 의도된 다. 다른 실시예들에서, 결정론적 스트리밍 프로세서 아키텍처들은 다수의 코어들을 포함(comprise)할 수 있으 며, 도 4에 도시되지 않은 타일 구조들을 연결하기 위한 다양한 다른 변형들은 타일 구조들의 수직 및 수평 연 결의 조합 등, 예를 들어 서로의 위에(on top of) 타일 구조들의 수직 연결이 가능하다. 일부 실시예들에서, 집적 회로는 \"싱글 코어(single core)\" 집적 회로로 지칭될 수 있다. 유사하게, 집적 회로들(410, 415, 420, 425)은, 각각(respectively), \"듀얼 코어(dual core)\" 집적 회로, \"쿼드-코어(quad-core)\" 집적 회로, \" 헥사-코어(hexa-core)\" 집적 회로 및 \"옥토-코어(octo-core)\" 집적 회로로 지칭될 수 있다. 용어 “코어”의 사용은 하나 또는 다수의 프로세서 코어들로 제한되지 않음을 주목해야 한다. 오히려, \"코어\"의 사용은 단순히 결정론적 스트리밍 프로세서에 포함된 동일한 구성(예를 들어, 타일 구조의 구성)의 타일 구조들의 수를 의미(denote)할 수 있다. 도 5a는 일부 실시예들에 따른, 타일 구조에 연결된 예시적인 한 쌍의 다이(505A, 505B)를 예시한다. 다 이(505A)는 다이(505A)와 다이(505B) 간에 오프셋 정렬을 형성하는 제1 디멘션(예를 들어, x 디멘션)을 따라 제 1 시프트 양만큼 및 제1 디멘션에 직교하는 제2 디멘션(예를 들어, y 디멘션)을 따라 제2 시프트 양만큼 다이 (505B)에 대해 시프트될 수 있다. 타일 구조는 다이들(505A, 505B)을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 작동(operate)하도록 구성될 수 있다. 타일 구조는 타일 구조의 일 실시예일 수 있 다. 타일 구조 내 각 다이(505A 및 505B)는 기판 상에 (예를 들어, 기능/메모리 슬라이스들의 일부로서) 계산 요소들의 어레이를 가지는 TSP를 포함할 수 있다. 대안적으로, TSP 대신에, 다이들(505A, 505B) 중 하나는 메 모리 장치(예를 들어, HBM), 인터페이스 장치(예를 들어, 브릿지 다이), 또는 일부 다른 장치를 포함(compris e)할 수 있다. 복수의 D2D 핀들(510A, 510B)은 각 다이(505A, 505B)에 배치될 수 있다. 각 다이(505A, 505 B)는 네 개의 사분면들(quadrants)로 나누어질 수 있고, 각 다이(505A, 505B)에서의 각 사분면은 인접한 다이에 서의 해당 쌍의 D2D 핀(510A, 510B)과의 직접 고속 연결을 위해 D2D 핀들(510A, 510B)의 부분을 포함할 수 있음 이 관찰될 수 있다. 도 5a에서 도시되는 것처럼, 다이(505A)의 우측 하부 사분면(lower right quadrant)은, 예를 들어, 다이(505A)의 D2D 핀들(510A)의 해당 부분들의 위에 다이(505A)의 D2D 핀들(510B)의 부분들을 배치 시켜 다이(505B)의 좌측 상부 사분면(upper left quadrant)과 연결되므로(또는 그 반대로), 다이(505A)와 다이 (505B) 간에 고속 데이터 통신이 제공된다. 도 5a에 예시된 한 쌍의 다이(505A, 505B)의 직접 연결은 두 개보다 많은 다이들 간에 F2F 연결들을 달성하기 위해 확장될 수 있다. 도 5b는 일부 실시예들에 따른, 타일 구조의 구성을 사용하여 상호 연결된 다수의 다이들(예를 들어, 13개의 다이들)을 갖는 집적 회로를 예시한다. 도 5b에서 도시되는 것처럼, 다이 A의 각 사분면은, 다이(525), 다이(525), 다이(525), 및 다이(525)의 해당 사분면과, (도 5a에서 도시 되는 것처럼) D2D 핀들의 해당 부분들을 통해 연결될 수 있다. 따라서, D2D 핀들을 통한 고속 데이터 통신이 다이(530A) 및 다이들(525, 525, 525, 및 525) 각각 간에 구축(establish)될 수 있다. 유사하게, 다이(530B)의 각 사분면은, 다이(525), 다이(525), 다이(525), 및 다이(525)의 해당 사분면과, (도 5a에서 도시되는 것처럼) D2D 핀들의 해당 부분들을 통해 연결될 수 있다. 따라서, D2D 핀들을 통한 고속 데이터 통신은 다이(530B) 및 다이들(525, 525, 525, 및 525) 각각 간에 구축(establish)될 수 있다. 더구나, 다이(530C)의 각 사분면은 다이(525), 다이(525), 다이(525), 및 다이(525)의 해당 사분면과, (도 5a에서 도시되는 것처럼) D2D 핀들의 해당 부분들을 통해 연결될 수 있다. 따라서, D2D 핀들을 통한 고속 데이터 통신은 다이(530C) 및 다이들(525, 525, 525, 및 525) 각각 간에 구축 (establish)된다. 마지막으로, 다이(530D)의 각 사분면은 다이(525), 다이(525), 다이(525), 및 다 이(525)의 해당 사분면과, (도 5a에서 도시되는 것처럼) D2D 핀들의 해당 부분들을 통해 연결된다. 따라서, D2D 핀들을 통한 고속 데이터 통신은 다이(530D) 및 다이들(525, 525, 525, 및 525) 각각 간에 구 축(establish)된다. 따라서, 도 5b에서의 집적 회로는 고속 데이터 통신을 위해 해당 D2D 핀들을 통해 상 호 연결된 13개의 다이들의 일례를 포함한다. 각 다이(530A, 530B, 530C, 530D)는 TSP, 메모리 장치(예를 들어, HBM 장치), 인터페이스 장치(예를 들어, 브릿지 다이), 또는 일부 다른 장치일 수 있다. 인터페이스 장 치(예를 들어, 브릿지 다이)로 구현되는 경우에 각 다이(530A, 530B, 530C, 530D)는 (예를 들어, 각각의 (respective) 다이(530A, 530B, 530C, 530D)의 하나 이상의 사분면들을 통해) 집적 회로를 호스트 컴퓨터, HBM 장치, 또는 일부 다른 장치에 인터페이스(interface)하도록 사용될 수 있음을 주목해야 한다. 도 6a는 일부 실시예들에 따른, 타일 구조로 연결된 예시적인 한 쌍의 다이들을 예시한다. 다이(605A)는 다이(605A)와 다이(605B) 간에 오프셋 정렬을 형성하는 제1 디멘션(예를 들어, x 디멘션)을 따라 제1 시프트 양 만큼 및 제1 디멘션에 직교하는 제2 디멘션(예를 들어, y 디멘션)을 따라 제2 시프트 양만큼 다이(605B)에 대해 시프트될 수 있다. 타일 구조는 다이들(605A, 605B)을 가로질러 모델-병렬화를 위한 단일 코어 프로세서 로 작동하도록 구성될 수 있다. 타일 구조는 타일 구조의 일 실시예일 수 있다. 타일 구조에서의 각 다이(605A 및 605B)는 기판 상에 (예를 들어, 기능/메모리 슬라이스들의 일부로서) 계 산 요소들의 어레이를 가지는 TSP를 포함할 수 있다. 대안적으로, TSP 대신에, 다이들(605A, 605B) 중 하나는 메모리 장치(예를 들어, HBM), 인터페이스 장치(예를 들어, 브릿지 다이), 또는 일부 다른 장치를 포함 (comprise)할 수 있다. 복수의 D2D 핀들(610A, 610B)은 각 다이(605A, 605B)에 배치될 수 있다. 유사하게, 도 5a에서의 타일 구조의 경우와 마찬가지로, 타일 구조에서의 다이(605A)와 다이(605B) 간에 직접 연결은, 예를 들어, 다이(605A)의 D2D 핀들(610A)의 해당 부분의 위에 다이(605B)의 D2D 핀들(610B)의 부분을 배치하여(또는 그 반대로) 달성된다. 도 5a를 다시 참조하면, 도 5a에서의 각 다이(505A, 505B)는 동일한 크기의 네 개의 사분면들로 나뉘어질 수 있 고, 다이(505A, 505B)에서의 각 사분면은 인접한 다이에서의 510A, 510B 핀들의 해당 부분과의 직접 연결을 위 해 균일한 크기의 D2D 핀들(510A, 510B)의 해당 부분을 이용함(exploit)이 관찰될 수 있다. 그러나, 도 5a에서 의 타일 구조와 달리, 도 6a에서의 타일 구조는 타일 구조의 경우보다 D2D 핀들(610A, 610B)의 더 긴 부분들을 통해 한 쌍의 다이를 연결하여 형성된다. 따라서, 도 6a에서 도시되는 것처럼, D2D 핀들 (610A, 610B)을 통한 다이(605A)의 우측 하단 사분면과 다이(610A)의 좌측 상단 사분면 간에 직접 연결은 타일 구조보다 더 길다. 그러나, 각 다이(605A, 605B)에서의 D2D 핀 영역의 나머지 부분들은 보다 작은데, 이 는 형성될 수 있는 가능한 연결들이 보다 적은 것을 의미하고, D2D 핀들(610A, 610B)의 영역의 이 부분들을 통 해 각 다이(605A, 605B)와 해당 인접 다이(도 6a에 미도시) 간에 연결은 타일 구조보다 더 작음이 도 6a에 서 관찰될 수 있다. 이러한 영역들에서 더 적은 D2D 핀들이 있기 때문에, 각 핀은 다수의 신호들이 각 핀 연결 을 통해 라우팅될 수 있도록 멀티플렉싱(multiplex)될 수 있다. 도 6b는 일부 실시예들에 따른, 타일 구조의 구성을 사용하여 상호 연결된 다수의 다이들(예를 들어, 다섯 개의 다이들)을 갖는 예시적인 집적 회로를 예시한다. 도 6b에서 도시되는 것처럼, 다이는 다이들 (625 및 625)과 해당 더 큰 영역에서 해당 D2D 핀들을 통해 직접 연결된다. 도 6b에서 추가로 도시되는 것처럼, 다이는 다이들(625 및 625)과 더 작은 영역에서 해당 D2D 핀들을 통해 직접 연결된다. 따 라서, 집적 회로는 다이와 다이들(625, 625, 625, 및 625) 각각 간에 직접 고속 데이터 통신을 제공할 수 있다. 각 쌍의 다이 간의 통신 대역폭은 균일하지 않지만, 다이와 다이(625)(또는 다이(625)) 간에 통신 대역폭은 다이와 다이(625)(또는 다이(625)) 간에 대역폭(that)보다 더 크다. 도 6b에서의 집적 회로의 구현을 위해 적용된 도 6a에서의 타일 구조는, 더 높은 데이터 통신 대역폭 이 두 쌍의 다이 간에(예를 들어, 다이와 다이(625) 간에 및 다이와 다이(625) 간에) 필요해지 는 경우에 적합할 수 있다. 하나 이상의 실시예들에서, 다이(625)(또는 도 6b에서의 일부 다른 다이)는 도 6b에서의 다른 다이들과 다를 수 있으며, 즉, 다이(625)는 집적 회로를 도 5b에서의 집적 회로와 연결하기 위해 적절한 인터페이스(예를 들어, PCI 슬롯들)를 갖는 컴퓨터 장치(예를 들어, 인쇄 회로 기판)일 수 있다. 또한, 다이는 TSP, 메모리 장치(예를 들어, HBM 장치), 인터페이스 장치(예를 들어, 브릿지 다이), 또는 일부 다른 장치일 수 있다. 인터페이스 장치(예를 들어, 브릿지 다이)로 구현되는 경우에 다이(63 0)는 (예를 들어, 하나 이상의 사분면들을 통해) 집적 회로를 호스트 컴퓨터, HBM 장치, 또는 일부 다른 장치에 인터페이스(interface)하도록 사용될 수 있음을 주목해야 한다. 도 7a는 일부 실시예들에 따른, T2T 브릿지를 통해 상호 연결된 다수의 타일 구조들(예를 들어, 여덟 개의 타일 구조들)을 포함하는 집적 회로의 예시적인 탑 뷰(top view) 및 바텀 뷰(bottom view)를 예시한다. 집적 회로는 제1 디멘션(예를 들어, x 디멘션), 제1 디멘션에 직교하는 제2 디멘션(예를 들어, y 디멘션) 및 제 1 및 제2 디멘션들에 직교하는 제3 디멘션(예를 들어, z 디멘션)을 가로지르는(span across) 타일 구조들(710A 내지 710H)의 어레이를 포함한다. 어레이에서의 타일 구조들은 T2T 브릿지를 통해 집적 회로에 상호 연결된다. 타일 구조들(710A, 710B, 710C, 710D)은 서로에 대해 두 사이드들에 인접하고 (예를 들어, x 및 y 디멘션들을 가로질러) 동일한 2D 평면에 배치되며, T2T 브릿지는 제3 디멘션(예를 들어, z 디멘션)에 오버 레이(overlay)된다. 유사하게, 타일 구조들(710E, 710F, 710G, 710H)은 서로에 대하여 두 사이드들에 인접하고 동일한 2D 평면(예를 들어, x 및 y 디멘션들을 가로질러)에 배치되며, 그리고 T2T 브릿지는 제3 디멘션(예 를 들어, z 디멘션)에 오버레이(overlay)된다. 타일 구조들(710A 내지 710H)의 적어도 하나의 서브 세트는 타 일 구조들(710A 내지 710H)의 복수의 다이들을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구성될 수 있다. 각 타일 구조(710A 내지 710H)는 타일 구조와 동일한 구성을 가질 수 있다. 따라서, 각 타일 구조(710A 내지 710H)는 제1 다이 및 F2F 구성으로 제1 다이에 연결된 제2 다이를 포함할 수 있다. 제1 다이는 제1 다이 와 제2 다이 간에 오프셋 정렬을 형성하는 제1 디멘션을 따라 제1 시프트 양만큼, 제2 디멘션을 따라 제2 시프 트 양만큼 제2 다이에 대해 시프트될 수 있다. 각 타일 구조(710A 내지 710H)에서의 제1 다이는 TSP를 포함할 수 있고, 각 타일 구조(710A 내지 710H)에서의 제2 다이들은 또 다른 TSP, 메모리 장치(예를 들어, HBM 장치), 인터페이스 장치, 일부 다른 장치, 또는 이의 일부 조합을 포함할 수 있다. 집적 회로의 탑 뷰(705A)는 T2T 브릿지의 제1 사이드(예를 들어, 탑 사이드)를 통해 상호 연결된 타 일 구조들(710A, 710B, 710C, 710D)을 예시한다. 유사하게, 집적 회로의 바텀 뷰(705B)는 제1 사이드에 반대되는 T2T 브릿지의 제2 사이드(예를 들어, 바텀 사이드)을 통해 상호 연결된 타일 구조들(710E, 710F, 710G, 710H)을 예시한다. T2T 브릿지는 브릿지 다이의 양 사이드에 T2T 핀들(예를 들어, 상호 연결 패드들)을 갖는 브릿지 다이로 구현된다. T2T 브릿지의 제1 사이드 상에 T2T 핀들의 적어도 하나의 서브세트는 타일 구조들(710A, 710B, 710C, 710D)의 해당 T2T 핀들과 정렬된다. 유사하게, T2T 브릿지의 제2 사이드 상에 T2T 핀들의 적어도 하나의 서브세트는 타일 구조들(710E, 710F, 710G, 710H)의 해당 T2T 핀들과 정렬된다. 따 라서, 집적 회로는 효과적으로 타일 구조들의 두 개의 수평 레이어(horizontal layer)들-T2T 브릿지 를 통해 수직 디멘션(예를 들어, z 디멘션)을 따라 상호 연결된 타일 구조들(710A, 710B, 710C, 710D)의 제1 수 평 레이어 및 타일 구조들(710E, 710F, 710G, 710H)의 제2 수평 레이어를 포함한다. 도 7b는 일부 실시예들에 따른, T2T 브릿지를 통해 상호 연결된 다수의 타일 구조들(예를 들어, 32개의 타일 구 조들)을 포함하는 집적 회로의 예시적인 탑 뷰 및 바텀 뷰를 예시한다. 집적 회로는 제1 디멘션(예 를 들어, x 디멘션), 제1 디멘션에 직교하는 제2 디멘션(예를 들어, y 디멘션), 및 제1 및 제2 디멘션들에 직교 하는 제3 디멘션(예를 들어, z 디멘션)을 가로지르는 타일 구조들(TS1 내지 TS32)의 어레이를 포함한다. 어레 이에서의 타일 구조들은 T2T 브릿지를 통해 집적 회로에 상호 연결된다. 타일 구조들(TS1 내지 TS32)의 어레이에서의 타일 구조들의 적어도 일 부분들은 타일 구조들(TS1 내지 TS32)의 복수의 다이들을 가로 질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구성될 수 있다. 각 타일 구조(TS1 내지 TS32)는 타일 구조와 동일한 구성을 가질 수 있다. 따라서, 각 타일 구조(TS1 내 지 TS32)는 제1 다이 및 F2F 구성으로 제1 다이에 연결된 제2 다이를 포함할 수 있다. 제1 다이는 제1 다이와 제2 다이 간에 오프셋 정렬을 형성하는 제1 디멘션을 따라 제1 시프트 양만큼, 제2 디멘션을 따라 제2 시프트 양만큼 제2 다이에 대해 시프트될 수 있다. 각 타일 구조(TS1 내지 TS32)에서의 제1 다이는 TSP를 포함할 수 있고, 각 타일 구조(TS1 내지 TS32)에서의 제2 다이는 또 다른 TSP, 메모리 장치(예를 들어, HBM 장치), 인터페 이스 장치, 일부 다른 장치, 또는 이의 일부 조합을 포함할 수 있다. 집적 회로의 탑 뷰(725A)는 T2T 브릿지의 제1 사이드(예를 들어, 탑 사이드)를 통해 상호 연결된 타 일 구조들(TS1 내지 TS16)을 예시한다. 유사하게, 집적 회로의 바텀 뷰(725B)는 제1 사이드에 반대되는 T2T 브릿지의 제2 사이드(예를 들어, 바텀 사이드)를 통해 상호 연결된 타일 구조들(TS17 내지 TS32)을 예 시한다. T2T 브릿지는 브릿지 다이의 양 사이드에 T2T 핀들(예를 들어, T2T 상호 연결 패드들)을 갖는 브릿지 다이로 구현된다. T2T 브릿지의 제1 사이드 상에 T2T 핀들의 적어도 하나의 서브세트는 타일 구조들 (TS1 내지 TS16)의 해당 T2T 핀들과 정렬된다. 유사하게, T2T 브릿지의 제2 사이드 상에 T2T 핀들의 적어 도 하나의 서브세트는 타일 구조들(TS17 내지 TS32)의 해당 T2T 핀들과 정렬된다. 따라서, 집적 회로는 효과적으로 타일 구조들의 두 개의 수평 레이어(horizontal layer)들-T2T 브릿지를 통해 수직 디멘션(예를 들어, z 디멘션)을 따라 상호 연결된 타일 구조들(TS1 내지 TS16)의 제1 수평 레이어 및 타일 구조들(TS17 내지 TS32)의 제2 수평 레이어를 포함한다. 도 8a는 일부 실시예들에 따른, T2T 브릿지를 통해 상호 연결된 HBM들의 스택들(stacks) 및 다수의 타일 구조들 을 포함하는 집적 회로의 예시적인 사이드 뷰(side view)를 예시한다. 집적 회로는 (예를 들어, 도 7a에서 탑 뷰(705A)에 의해 도시되는 구성으로) T2T 브릿지의 제1 사이드(예를 들어, 탑 사이드)를 통해 상호 연결된 타일 구조들(805A, 805B)(및 도 8a에 도시되지 않은 적어도 두 개 더 타일 구조들)을 포함한다. 집적 회로는 (예를 들어, 도 7a에서 바텀 뷰(705B)에 의해 도시되는 구성으로) T2T 브릿지의 제2 사 이드(예를 들어, 바텀 사이드)를 통해 상호 연결된 타일 구조들(805C, 805D)(및 도 8a에 도시되지 않은 적어도 두 개 더 타일 구조들)을 더 포함한다. T2T 브릿지는 T2T 브릿지 또는 T2T 브릿지의 일 실시예 일 수 있다. 집적 회로에서의 각 타일 구조는 타일 구조와 동일한 구성을 가질 수 있다. 집적 회로의 각 타 일 구조에서의 제1 다이는 TSP를 포함할 수 있고, 집적 회로의 각 타일 구조에서의 제2 다이는 또 다른 TSP, 메모리 장치(예를 들어, HBM 장치), 인터페이스 장치, 일부 다른 장치, 또는 이의 일부 조합을 포함할 수 있다. T2T 브릿지의 탑 사이드를 통해 연결된 타일 구조들의 수는 4N이고, T2T 브릿지의 바텀 사이 드를 통해 연결된 타일 구조들의 수는 4N이며, N은 정수이다. 따라서, 집적 회로에서의 타일 구조들의 총 수는 8N(예를 들어, N = 1, 2, 3, 또는 4)일 수 있다. 집적 회로는 T2T 브릿지의 제1 사이드에, 예를 들어, 타일 구조(805A)와 타일 구조(805B) 간에 공간 적으로, 배치된 메모리 장치들의 제1 스택(815A)(예를 들어, HBM 장치들의 스택)을 더 포함한다. HBM 스택 (815A)은 (예를 들어, TSV 커넥터들을 통해) F2B 구성으로 또는 B2B 구성으로 서로의 위에 스택된 하나 이상의 HBM들을 포함할 수 있다. 집적 회로는 T2T 브릿지의 제2 사이드에, 예를 들어, 타일 구조(805C)와 타일 구조(805D) 간에 공간적으로, 배치되는 메모리 장치들의 제2 스택(815B)(예를 들어, HBM 장치들의 스택)을 더 포함한다. HBM 스택(815B)은 (예를 들어, TSV 커넥터들을 통해) F2B 구성 또는 B2B 구성으로 서로의 탑에 스택된 하나 이상의 HBM들을 포함(comprise)할 수 있다. HBM 스택들(815A, 815B)과 마찬가지로 집적 회로 에서의 타일 구조들은 타일 구조들 및 HBM들의 복수의 다이들을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능할 수 있다. 도 8b는 일부 실시예에 따른, 히트 싱크와 T2T 브릿지를 통해 상호 연결된 HBM들의 스택들 및 다수의 타일 구조 들을 포함하는 집적 회로의 예시적인 사이드 뷰를 예시한다. 집적 회로는 (예를 들어, 도 7a에서 탑 뷰(705A)에 의해 도시(show)되는 구성으로) T2T 브릿지의 제1 사이드(예를 들어, 탑 사이드)를 통해 상호 연결된 타일 구조들(825A, 825B)(및 도 8b에 도시(show)되지 않은 적어도 두 개 더 타일 구조들)을 포함한다. 집적 회로는 (예를 들어, 도 7a에서 탑 뷰(705B)에 의해 도시(show)되는 구성으로) T2T 브릿지의 제2 사이드(예를 들어, 바텀 사이드)를 통해 상호 연결된 타일 구조들(825C, 825D)(및 도 8b에 도시(show)되지 않은 적어도 두 개 더 타일 구조들)을 더 포함한다. T2T 브릿지는 T2T 브릿지 또는 T2T 브릿지의 일 실시예일 수 있다. 집적 회로에서의 각 타일 구조는 타일 구조와 동일한 구성을 가질 수 있다. 집 적 회로의 각 타일 구조에서의 제1 다이는 TSP를 포함할 수 있고, 집적 회로의 각 타일 구조에서의 제2 다이는 또 다른 TSP, 메모리 장치(예를 들어, HBM 장치), 인터페이스 장치, 일부 다른 장치, 또는 이의 일 부 조합을 포함할 수 있다. 집적 회로는 T2T 브릿지의 제1 사이드에, 예를 들어, 타일 구조(825A)와 타일 구조(825B) 간에 공간 적으로, 배치되는 메모리 장치들(예를 들어, HBM 장치들의 스택)의 제1 스택(835A)을 더 포함한다. HBM 스택 (835A)은 (예를 들어, TSV 커넥터들을 통해) F2B 구성 또는 B2B 구성으로 서로의 위에 스택된 하나 이상의 HBM 들을 포함(comprise)할 수 있다. 집적 회로는 T2T 브릿지의 제2 사이드에, 예를 들어, 타일 구조 (825C)와 타일 구조(825D) 간에 공간적으로, 배치되는 메모리 장치들의 제2 스택(835B)(예를 들어, HBM 장치들 의 스택)을 더 포함한다. HBM 스택(835B)은 (예를 들어, TSV 커넥터들을 통해) F2B 구성 또는 B2B 구성으로 서 로의 위에 스택된 하나 이상의 HBM들을 포함(comprise)할 수 있다. HBM 스택들(835A, 835B)에 따른 집적 회로 에서의 타일 구조들은 타일 구조들 및 HBM들의 복수의 다이들을 가로질러 모델-병렬화를 위한 단일 코어프로세서로 기능할 수 있다. 집적 회로는 HBM 스택(835A) 및 타일 구조들(825A, 825B)(및 T2T 브릿지의 제1 사이드에 커플링된 임의의 추가 타일 구조들)의 외부 표면들에 커플링된 히트 싱크를 더 포함한다. 히트 싱크는 HBM 스 택들(835A, 835B) 및 타일 구조들(825A 내지 825D)(및 T2T 브릿지의 제1 및 제2 사이드들에 커플링된 임 의의 추가 타일 구조들)로부터 열기(heat)를 방출하도록 구성될 수 있다. 하나 이상의 실시예들에서, 히트 싱 크는, 예를 들어, 기판 위에 형성된 메탈 레이어(metal layer)를 포함하는, 히트 싱크 다이로 구현된다. 하나 이상의 다른 실시예들에서, 히트 싱크는 타일 구조들 간에 갭(gap)들을 채우는 열 필러(thermal filler)로 구현될 수 있다. 예를 들어, 히트 싱크의 열 필러는 타일 구조(825A)와 타일 구조(825B)(및 T2T 브릿지의 제1 사이드에 커플링된 임의의 추가 타일 구조들) 간에 갭들을 채울 수 있다. 히트 싱크 의 열 필러는 예를 들어 실리콘(그래핀 기반) 필러 또는 실리콘과 접촉하는 구리 냉각 플레이트(cold plate) 상에 배치된 그래핀 튜브일 수 있다. 집적 회로는, 예를 들어, HBM 스택(835B) 및 타일 구조들(825C, 825D)(및 T2T 브릿지의 제2 사이드 에 커플링된 임의의 추가 타일 구조들)의 외부 표면들에 커플링된 파워 서플라이 레이어(power supply layer)를 더 포함할 수 있다. 파워 서플라이 레이어는 집적 회로에서의 실리콘의 하부 레이어 (lower layer)들(예를 들어, HBM 스택(835B)의 하부 다이들, 타일 구조들(825C, 825D)의 하부 다이들 및 T2T 브릿지의 제2 사이드에 커플링된 임의의 추가 타일 구조들)에 대하여 파워 서플라이 네트워크들을 제공하 기 위한 C4 범프(bump)들의 어레이를 포함할 수 있다. 집적 회로에서의 다른 다이들(즉, 실리콘의 상부 레이어(upper layer)들)은 TSV 커넥터들을 통한 전력 전송(power delivery)을 포함할 수 있다. 도 9는 일부 실시예들에 따른, 타일 구조들의 직육면체(cuboid) 구조로 구현된 예시적인 집적 회로를 예시 (illustrate)한다. 직육면체 구조는 상호 연결된 타일 구조들의 3-디멘션의 어레이, 즉, 세개의 공간적인 디멘션들(예를 들어, 각각(respectively), x 디멘션, y 디멘션 및 z 디멘션)을 가로지르는(span across) N x M x K 타일 구조 어레이를 나타내며, 여기서 N, M 및 K는 (예를 들어, 5보다 작은) 정수들이다. 직육면체 구조 에서의 타일 구조들 각각은 타일 구조의 구성을 가질 수 있다. 직육면체 구조의 타일 구조들은 타일 구조들을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 작동(operate)하도록 구성될 수 있다. 도 9에서 도시되는 것처럼, 직육면체 구조는 수직으로(예를 들어, z 디멘션을 따라) 상호 연결된 타일 구 조들의 복수의 수평 레이어들을 포함한다. 타일 구조들의 각 수평 레이어는 제1 디멘션(예를 들어, x 디멘션) 과 제2 디멘션(예를 들어, y 디멘션)을 가로지르는 타일 구조들의 2-디멘션의 어레이(예를 들어, N x M 어레 이)이 포함한다. 각 수평 레이어에서의 한 쌍의 인접한 타일 구조는 (예를 들어, 도 4에서 도시되는 것처럼) 각 타일 구조에서의 한 쌍의 다이 간에 형성된 오프셋 정렬을 통해 상호 연결될 수 있다. 타일 구조들의 한 쌍 의 인접한 수평 레이어는 수직 디멘션(예를 들어, z 디멘션)을 따라 인접한 수평 레이어들에서의 해당 타일 구 조들을 커플링하여 수직 디멘션(예를 들어, z 디멘션)을 따라 연결된다. 수직 디멘션(예를 들어, z 디멘션)을 따라 연결된 타일 구조들의 수평 레이어들의 수는 K이다(예를 들어, 도 9의 실시예에서 K = 4). 일 실시예에서, 인접한 수평 레이어들에서의 해당 타일 구조들은 TSV 커넥터들을 통해 B2B 구성으로 수직 디멘션 (예를 들어, z 디멘션)을 따라 서로 커플링된다. 또 다른 실시예에서, 인접한 수평 레이어들에서의 해당 타일 구조들은 TSV 커넥터들을 통해 F2B 구성으로 수직 디멘션(예를 들어, z 디멘션)을 따라 서로 커플링된다. 아직 또 다른 실시예에서, 인접한 수평 레이어들에서의 해당 타일 구조들은 (도 7a 내지 도 7b에서 도시되는 것처럼) T2T 브릿지를 통해 수직 디멘션(예를 들어, z 디멘션)을 따라 커플링된다. 일부 실시예들에서, 직육면체 구조 에서의 두 개의 인접한 수평 레이어들은 B2B 구성으로 그 타일 구조들을 연결하여 상호 커플링되지만, 직 육면체 구조에서의 또 다른 두 개의 인접한 수평 레이어들은 F2B 구성으로 그 타일 구조들을 연결하여 상 호 커플링된다. 직육면체 구조는 (도 9에 미도시된) 복수의 히트싱크들을 더 포함할 수 있다. 직육면체 구조에서의 각 히트 싱크는 직육면체 구조 내 적어도 하나의 타일 구조에 직접 연결될 수 있으며, 적어도 하나의 타일 구조로부터 열기(heat)를 방출하도록 구성될 수 있다. 각 히트 싱크는, 예를 들어, 실리콘 (그래핀 기반) 필러, 실리콘과 접촉하는 구리 냉각 플레이트(cold plate) 상에 배치된 그래핀 튜브, 기판 상에 메탈 레이어, 일부 다른 유형의 히트 싱크, 또는 이의 조합으로 구현될 수 있다. 하나 이상의 실시예들에서, 각 히트 싱크는 타일 구조들의 두 개의 인접한 수평 레이어들 사이에 배치되고 타일 구조들의 두 개의 인접한 수평 레이어들로 부터 열기를 방출하도록 구성된다. 추가적으로, 한 쌍의 히트 싱크는 (예를 들어, 수직 또는 z 디멘션에 대하 여) 직육면체 구조의 탑 표면 및 직육면체 구조의 바텀 표면에 배치될 수 있으며, 직육면체 구조에서의 타일 구조들의 외부 수평 레이어들로부터 열기를 방출하도록 구성될 수 있다. 일부 실시예들에서, 직육면체 구조의 다이들에서 수행되는 데이터 연산(operation)들을 제어하는 컴파일러 는, 예를 들어, 최대 정의된 클록 레이트(clock rate)의 50%에서 직육면체 구조의 다이들의 수를 2배로 실 행(run)하여, 특정 실리콘-투-트레이드오프(silicon-to-power tradeoff)를 제공하도록 구성될 수 있다. 추가적 으로, 또는 대안적으로, 컴파일러는 다이들 및 타일 구조들의 로컬 히팅(local heating)을 최적화하고 열기 생 성에 스태거(stagger)하도록 유틸리제이션(utilization)을 직육면체 구조 내에서의 리소스들에 매핑(map) 할 수 있다. 하나 이상의 실시예들에서, 직육면체 구조에서의 타일 구조들의 각 다이들은 다른 크기일 수 있고 및/또는 다른 기능들을 수행할 수 있다. 직육면체 구조의 크기와 기능의 다이-당 세분성(per-die granularity)은 직육면체 구조에서 실리콘-투-파워 트레이드오프(silicon-to-power tradeoff)를 최적화하 기 위해 컴파일러에 의해 이용(exploit)될 수 있다. 일부 실시예들에서, 하나 이상의 직육면체 구조들은 랙에 하우징(house)되고, 데이터 센터에 활용될 수 있 다. 데이터 센터는 수천 개의 이러한 랙들을 포함(contain)할 수 있다. 랙 내 각 정육면체 구조는 해당 모델(예를 들어, 머신 러닝 모델)을 실행(run)하는 단일 코어 결정론적 스트리밍 프로세서(예를 들어, TSP)로 작동하도록 구성될 수 있다. 따라서, 다수의 모델들은 랙 내 다수의 직육면체 구조들을 가로질러 비동기 적으로(asynchronously) 실행될 수 있다. 랙은 랙 내 각 직육면체 구조의 작동(operation)들을 (예를 들 어, 중앙 컨트롤러에서 실행되는 컴파일러를 통해) 제어하는 중앙 컨트롤러를 더 포함할 수 있다. 데이터 센터 가 전체 랙에 대한 임계 전력 예산(threshold power budget)을 갖춘(feature)다면, 각 직육면체(cuboid) 구조 는 랙 내 모든 직육면체 구조들에(among) 전력(power)을 할당하도록 개별적으로(individually) 관리 될 수 있다. 유리하게(advantageously), 임계 전력 예산이 초과되는 것을 막도록 관리되는 전력이 있을 뿐만 아니라, 랙 내 각 직육면체 구조를 가로질러 서비스 품질(quality of service, QoS)도 유지된다. 타일 구조들을 갖는 집적 회로에 대한 예시적인 프로세스 흐름 도 10은 일부 실시예들에 따른, 하나 이상의 타일 구조들의 복수의 다이들을 가로질러 모델-병렬화로 데이터 프 로세싱을 위해 집적 회로를 사용하는 방법을 예시하는 흐름도이다. 집적 회로는 적어도 하나의 컴퓨터 프로세서(예를 들어, 결정론적 스트리밍 프로세서) 및 컴퓨터 실행 인스트럭션들을 저장하기 위한 비일시적 컴 퓨터 판독 가능 저장 매체(non-transitory computer-readable storage medium)를 더 포함할 수 있다. 결정론 적 스트리밍 프로세서는 TSP일 수 있다. 하나 이상의 실시예들에서, 집적 회로는 단일 코어 결정론적 스트리밍 프로세서로 작동할 수 있는 한 쌍의 다이를 갖는 하나의 타일 구조를 포함한다. 이러한 경우, 집적 회로는, 예 를 들어, 타일 구조, 타일 구조, 타일 구조, 또는 타일 구조의 일 실시예일 수 있다. 하 나 이상의 다른 실시예들에서, 집적 회로는 단일 코어 결정론적 스트리밍 프로세서로 작동할 수 있는 타일 구조 들의 2-디멘션의 어레이를 포함한다. 이러한 경우, 집적 회로는, 예를 들어, 집적 회로들(410, 415, 420, 425, 520, 620) 중 하나의 일 실시예일 수 있다. 하나 이상의 다른 실시예들에서, 집적 회로는 단일 코어 결정론적 스트리밍 프로세서로 작동할 수 있는 타일 구조들의 3-디멘션의 어레이를 포함한다. 이러한 경우, 집적 회로는, 예를 들어, 집적 회로들(700, 800, 820) 또는 직육면체 구조 중 하나의 일 실시예일 수 있다. 방법의 작동(operation)들은 적어도 하나의 컴퓨터 프로세서 및/또는 집적 회로와 분리된 호스트 서버에 서 작동하는 컴파일러에 의해 개시될 수 있다. 컴파일러는 결정론적 스트리밍 프로세서에 대한 모델(예를 들어, 머신 러닝 모델)을 그 입력으로 활용할 수 있고 전체로서 집적 회로와 결정론적 스트리밍 프로세서의 작 동을 구성하기 위한 인스트럭션들을 출력으로 활용할 수 있다. 집적 회로는 집적 회로의 하나 이상의 타일 구 조들의 복수의 다이들을 가로질러 프로세싱 유닛들(예를 들어, 하나 이상의 기능 슬라이스들의 계산 요소들)에 의해 실행을 위한 인스트럭션들의 발행을 개시한다. 집적 회로는 인스트럭션들의 실행을 위해 하나 이상 의 타일 구조들의 복수의 다이들을 가로질러 프로세싱 유닛들을 통해 데이터의 스트리밍을 개시한다. 집 적 회로는 하나 이상의 타일 구조들의 하나 이상의 메모리 슬라이스들로 결과 데이터를 반환하는 것을 개시한다 . 결정론적 스트리밍 프로세서들의 다이-투-다이 구조들 본 개시의 실시예들은 추가로 결정론적 스트리밍 프로세서(예를 들어, TSP들)의 다이-투-다이(die-to-die, D2D) 고밀도 패키징과 관련된다. D2D 구조로 연결된 각 결정론적 스트리밍 프로세서(예를 들어, TSP)는 차세대 인공 지능/머신러닝 알고리즘들을 실행(run)하는 데 적합한 확장된 확장 가능 컴퓨팅 아키텍처(extended scalable compute architecture)를 갖춘다(feature). D2D 구조의 각 결정론적 스트리밍 프로세서는 공간적인 파이프라인 프로세싱으로 SIMD 연산(operation)들(예를 들어, 256바이트(byte) SIMD 연산들)을 지원하고, 슈퍼레인당 S(예를 들어, S = 64)개의 동시 스트림들을 스트리밍하며, 예를 들어, 130TB/s 이상의 메모리 대역폭을 특징 (feature)으로 할 수 있다. D2D 구조에서의 각 결정론적 스트리밍 프로세서는 민감하지 않는 스트라이드 (stride)이며 대규모 동시성(예를 들어, 1.5TB/s의 HBM 대역폭)을 특징으로 하는 결정론적 고-대역폭 메모리 (HBM)를 더 지원할 수 있다. D2D 구조에서의 각 결정론적 스트리밍 프로세서는 닷 프로덕트(dot product) 계산 들이 융합된 각각 256 x 256을 지원하는 네 개의 MXM 엔진들을 포함하고, FP16(16-비트 부동 소수점) 밀도가 더 블(double)로 되며, INT4(4-비트 정수) 연산들에 대한 추가 지원을 특징으로 할 수 있다. D2D 구조에서의 각 결정론적 스트리밍 프로세서는 프로그래머블(programmable) 고성능 VXM들, 예를 들어, 8192 벡터 ALU들, 개선된 데이터 이동 및 데이터 재구성을 위해 더블된 퍼뮤터들을 갖는 SXM들, 및 인스트럭션 병렬화(parallelism)를 달 성하기 위한 다수의 인스트럭션 큐들을 가진 ICU들을 더 포함할 수 있다. D2D 구조에서의 각 결정론적 스트리 밍 프로세서는 확장 가능한(extensible) 네트워크 확장성과 다수의 D2D 토폴로지들을 지원할 수 있다. 도 11은 일부 실시예들에 따른, D2D 구성으로 연결된 두 개의 결정론적 스트리밍 프로세서들(또는 다이들)을 갖 는 예시적인 다이-투-다이(D2D) 구조를 예시(illustrate)한다. D2D 구조는 D2D 인터페이스를 통 해 두 개의 다이들을 가로질러 슈퍼레인들의 확장을 제공한다. D2D 구조는 제1 결정론적 스트리밍 프로 세서(또는 제1 TSP 코어)를 갖는 다이 및 제2 결정론적 스트리밍 프로세서(또는 제2 TSP 코어)를 갖는 다 이를 포함한다. 다이는 D2D 인터페이스를 통해 다이에 연결되어, D2D 구조를 형성할 수 있다. D2D 인터페이스는, 예를 들어, 2GHz에서 네 개의 스트림들을 지원할 수 있다. D2D 구 조는 다이들(1105 및 1110)을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구성된다. 일 실시예에서, D2D 인터페이스는 다이들(1105 및 1110) 간에 16 슈퍼레인들의 매핑을 위한 인터페이스를 나타낸다. 이러한 경우, D2D 인터페이스는 2TB/sec까지의 스트리밍 레이트를 지원할 수 있다. 또 다른 실시예에서, D2D 인터페이스는 다이들(1105 및 1110) 간에 24 슈퍼레인들의 매핑을 위한 인터페이스를 나 타낸다. 이러한 경우, D2D 인터페이스는 3TB/sec까지의 스트리밍 레이트(rate)를 달성할 수 있다. 수평 방향(예를 들어, x 방향)을 따른 D2D 구조의 크기는, 예를 들어, 65mm 또는 85mm일 수 있고; 수직 방향 (예를 들어, y 방향)을 따른 D2D 구조의 크기는, 예를 들어, 65mm 또는 85mm일 수 있다. D2D 구조 는, 예를 들어, 2 페타플롭스(PetaFlops)(부동 소수점 연산들)를 달성하기 위한 FP16 데이터 포맷 (format), 4 페타옵스(PetaOps)를 달성하기 위한 INT8 데이터 포맷, 및 8 페타옵스를 달성하기 위한 INT4 데이 터 포맷을 지원할 수 있다. D2D 구조는, 예를 들어, 480메가바이트(MBytes)의 SRAM을 포함할 수도 있다. D2D 구조의 각 다이(1105, 1110)(예를 들어, 각 TSP 코어)는, 예를 들어, 각각의(respective) 다이 (1105, 1110)의 로컬 DRAM에 1.6 TB/s의 스트림 대역폭을 제공하는 결정론적 HBM을 포함할 수 있다. 각 다이 (1105, 1110)는 예를 들어 64-바이트(byte) 워드 크기를 지원하도록 설계(design)될 수 있다. D2D 구조(110 0)는 예측 가능하고 확장 가능한 낮은 레이턴시(latency) 상호 연결 네트워크들(예를 들어, 온-칩(on-chip) 및 오프-칩(off-chip))을 지원할 수 있다. D2D 구조는 추가로 동적 전력 범위(dynamic power range)를 활 용하기 위해 에너지-비례성(energy-proportionality)을 지원할 수 있다. 도 12는 일부 실시예들에 따른, 다수의 다이들을 가로질러 확장된 슈퍼레인들을 갖는 예시적인 D2D 구조 를 예시한다. D2D 구조는 수평 방향(예를 들어, x 방향)을 따라 다수의 다이들을 가로질러 슈퍼레인들의 확장을 제공할 수 있다. D2D 구조는 (예를 들어, x 방향을 따라 D2D 구조의 가능한 확장 (extension)을 위한) D2D 인터페이스를 갖는 다이, D2D 인터페이스, 다이, D2D 인 터페이스, ..., D2D 인터페이스(1210N-1), 및 (예를 들어, x 방향을 따라 D2D 구조의 가능한 확장 (extension)을 위한) D2D 인터페이스(1210N)를 갖는 다이(1205N)를 포함하며, 여기서 N≥3이다. D2D 인터페이 스는 다이의 슈퍼레인들에 다이의 슈퍼레인들의 매핑을 제공할 수 있고, D2D 인터페이스 는 다이의 슈퍼레인들과 다이의 슈퍼레인들의 매핑 등을 제공할 수 있다. 일반적으로, D2D 인터페이스(1210i)는 다이(1205i+1)의 슈퍼레인들에 다이(1205i)의 슈퍼레인들의 매핑을 제공할 수 있고, 여 기서 i =1, 2, ..., N-1이다. D2D 구조는 수직 방향(예를 들어, y 방향)을 따른 추가 다이들의 고밀도(dense) 패키징을 지원할 수 있다. 추가적으로 또는 대안적으로, D2D 구조는 D2D 구조의 하나 이상의 다이들의 기판 상에 고밀 도 패키징을 지원할 수 있다. D2D 구조는 고속 SRAM 메모리 용량의 확장을 지원할 수 있으며 다수의 다 이들을 가로질러 매우 효율적인 모델-병렬화를 위한 경로(path)를 제공한다. D2D 구조의 임의의 D2D 인 터페이스를 가로지르는 레이턴시는 단지, 예를 들어, 18 클록 사이클들(또는 9ns)일 수 있는 반면, 매 클록 사이클마다 각 방향으로 S 스트림들(예를 들어, S = 4)을 전송할 수 있다. D2D 구조의 임의의 D2D 인터페 이스의 비트 오류율(bit error rate, BER)은 1O-20보다 적을 수 있고, 이는 와이어(wire)처럼 신뢰할 수 있고 강 건한 D2D 구조의 D2D 인터페이스를 만들 수 있다. D2D 구조는 다이들(12051, 12052, ..., 1205N) 을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구성된다. 도 13a은 일부 실시예들에 따른, D2D 구성으로 연결된 세 개의 다이들을 갖는 예시적인 D2D 구조를 예시 한다. D2D 구조는 세 개의 다이들을 가로질러(즉, 세 개의 결정론적 스트리밍 프로세서들 또는 TSP 코어 들을 가로질러) 슈퍼레인들의 확장을 제공한다. D2D 구조는 그의 슈퍼레인들의 확장을 위해 D2D 구성으 로 연결된 다이들(1305, 1310, 1315)을 포함한다. D2D 인터페이스는 다이의 슈퍼레인들을 다이 의 슈퍼레인들에 매핑하고, D2D 인터페이스는 다이의 슈퍼레인들을 다이의 슈퍼레인들 에 매핑한다. D2D 구조는 N=3에 대한 D2D 구조의 일 실시예일 수 있다. 수평 방향(예를 들어, x 방향)을 따른 D2D 구조의 크기는, 예를 들어, 95mm일 수 있고, 수직 방향(예를 들어, y 방향)을 따른 D2D 구조의 크기는, 예를 들어, 95mm일 수 있다. D2D 구조는, 예를 들어, 3 페타플롭스(PetaFlops)를 달성하기 위한 FP16 데이터 포맷(format), 6 페타옵스(PetaOps)를 달성하기 위한 INT8 데이터 포맷, 및 12 페타 옵스를 달성하기 위한 INT4 데이터 포맷을 지원할 수 있다. D2D 구조는, 예를 들어, 720메가바이트 (MBytes)의 SRAM을 포함할 수도 있다. D2D 구조는 다이들(1305, 1310, 1315)을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구성된다. 도 13b는 일부 실시예들에 따른, D2D 폴디드 메시(folded mesh) 구성으로 연결된 다이들을 갖는 예시적인 D2D 구조를 예시한다. 도 13b는 초기에 수평 방향(예를 들어, x 방향)을 따라 확장된 슈퍼레인들을 가진 네 개의 다이들(13350, 13351, 13352 및 13353)을 갖는 D2D 구조를 도시(show)한다. 각 다이(13350, 13351, 13352 및 13353)는 각각의(respective) 결정론적 스트리밍 프로세서 또는 TSP 코어를 포함한다. D2D 인터페이스 는 수평 방향(예를 들어, x 방향)을 따라 다이의 슈퍼레인들에 다이의 슈퍼레인들을 매핑 하고; D2D 인터페이스는 수평 방향(예를 들어, x 방향)을 따라 다이의 슈퍼레인들에 다이 의 슈퍼레인들을 매핑하며; 그리고 D2D 인터페이스는 수평 방향(예를 들어, x 방향)을 따라 다이 의 슈퍼레인들에 다이의 슈퍼레인들을 매핑한다. D2D 구조는 N=4에 대한 D2D 구조의 일 실 시예일 수 있다. 수평 방향(예를 들어, x 방향)을 따른 D2D 구조의 크기는, 예를 들어, 120mm일 수 있고, 그리고 수직 방향(예를 들어, y 방향)을 따른 D2D 구조의 크기는, 예를 들어, 55mm일 수 있다. D2D 구조는 D2D 폴디드(folded) 메시 구성(예를 들어, 라딕스(radix)-4 메시)을 가진 D2D 구조로 변환될 수 있다. D2D 인터페이스는 수직 방향(예를 들어, y 방향)을 따라 다이의 슈퍼레인들에 다이의 슈퍼레인들을 매핑하고; D2D 인터페이스는 수직 방향(예를 들어, y 방향)을 따라 다이 의 슈퍼레인들에 다이의 슈퍼레인들을 매핑하며; 그리고 D2D 인터페이스는 수직 방향(예를 들어, y 방향)을 따라 다이의 슈퍼레인들에 다이의 슈퍼레인들을 매핑한다. D2D 구조와 비교해 보면, D2D 구조는 더 작은 전체 크기를 가지는 반면 동일한 스트리밍 대역폭을 달성할 수 있다. 수평 방향(예를 들어, x 방향)을 따른 D2D 구조의 크기는, 예를 들어, 55mm일 수 있고, 수직 방향(예를 들어, y 방향)을 따른 D2D 구조의 크기는, 예를 들어, 55mm일 수 있다. D2D 구조와 마찬가지로, D2D 구조는 다이들(13350, 13351, 13352, 13353)을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기 능하도록 구성된다. 도 13c는 일부 실시예들에 따른, D2D 토러스(torus) 구성으로 연결된 다이들을 갖는 예시적인 D2D 구조를 예시한다. 도 13c에서 도시되는 것처럼, D2D 폴디드 메시 구성(예를 들어, 라딕스-4 메시 구성)을 갖는 D2D 구 조는 D2D 구조를 형성하기 위해 사용될 수 있다. D2D 구조의 D2D 토러스 구성(예를 들어, 라딕스-8 토러스 구성)은 D2D 인터페이스들을 통해 수평 방향(예를 들어, x 방향)을 따라 두 개의 D2D 폴 디드 메시 구성들(예를 들어, 두 개의 라딕스-4 메시 구성들)을 연결하여 만들어질 수 있다. D2D 구조는 제1 D2D 폴디드 메시 구성(예를 들어, 제1 라딕스-4 메시 구성)으로 연결된 다이들(13650, 13651, 13652, 13653) 및 제2 D2D 폴디드 메시 구성(예를 들어, 제2 라딕스-4 메시 구성)으로 연결된 다이들(13654, 13655, 13656, 13657)을 포함한다. 제1 D2D 폴디드 메시 구성은 D2D 토러스 구성(예를 들어, 라딕스-8 토러스 구성)으로 연결 된 여덟 개의 다이들로 D2D 구조를 형성하는 D2D 인터페이스들을 통해 제2 D2D 폴디드 메시 구성에연결된다. 수평 방향(예를 들어, x 방향)을 따른 D2D 구조의 크기는, 예를 들어, 85mm일 수 있고, 수직 방향(예를 들어, y 방향)을 따른 D2D 구조의 크기는, 예를 들어, 85mm일 수 있다. D2D 구조는 다 이들(13650, 13651, 13652, 13653, 13654, 13655, 13656, 13657)을 가로질러 모델-병렬화를 위한 단일 코어 프로 세서로 기능하도록 구성된다. 도 14는 일부 실시예들에 따른, 한 쌍의 다이 간에 슈퍼레인들의 D2D 매핑을 위한 예시적인 D2D 매핑 구조 를 예시한다. D2D 매핑 구조는 제1 다이(즉, 제1 결정론적 스트리밍 프로세서 또는 제1 TSP 코 어)의 슈퍼레인들과 제2 다이(즉, 제2 결정론적 스트리밍 프로세서 또는 제2 TSP 코어)의 슈퍼레인들 간에 연결 을 제공한다. D2D 매핑 구조는 (제1 다이의 일부일 수 있는) 슈퍼 셀들의 어레이, D2D 인터페이스 및 (제2 다이의 일부일 수 있는) 슈퍼레인들을 포함한다. 비록 도 14에서 D2D 매핑 구조가 16 슈퍼레인들을 매핑하는 것을 예시하고 있지만, D2D 매핑 구조는 일부 다른 수의 슈퍼레인들(예를 들어, 20 슈퍼레인들 또는 24 슈퍼레인들)의 매핑을 지원하도록 확장될 수 있음을 이해해야 한다. 슈퍼 셀들의 어레이는 N 슈퍼 셀들(예를 들어, N = 4)의 2-디멘션의 어레이로 구현될 수 있다. 슈퍼 셀 들의 어레이에서의 각 슈퍼 셀은 D2D 인터페이스를 통해 스트리밍하는 데이터를 저장하기 위한 온- 칩 스트림 레지스터들을 포함할 수 있다. 슈퍼 셀들의 어레이는, 예를 들어, 대략 수백 TB/sec의 스트리 밍 대역폭을 제공할 수 있다. 슈퍼 셀들의 어레이는 제1 다이의 슈퍼레인들에 직접 연결된다(도 14에 미 도시). D2D 인터페이스는 제1 다이의 슈퍼 셀들의 어레이를 제2 다이의 슈퍼레인들과 연결 하므로, 한 쌍의 다이를 가로질러 슈퍼레인들의 확장을 제공한다. D2D 인터페이스는 다수의 D2D 인터페 이스 뱅크들을 포함하고, 각 D2D 인터페이스 뱅크는 슈퍼레인들의 해당 서브세트에 매핑을 제공한다. 각 D2D 인터페이스 뱅크는 해당 슈퍼레인들에 물리적 연결들을 제공하기 위해 D2D 코어 인터페이스, D2D 물리 계층(physical layer, PHY) 제어 회로, 및 양방향(bidirectional) 인터페이 스 슬라이스들을 포함한다. 각 쌍의 양방향 인터페이스 슬라이스들은 해당 슈퍼레인에 연결 될 수 있다. 각 슈퍼 레인 및 D2D 인터페이스의 해당 부분은 각 방향(예를 들어, x 축을 따라)으로 256비트 (bits)를 스트리밍(stream)할 수 있고, 매 클록 사이클마다 슈퍼 레인당 S 스트림들(예를 들어, S = 4)을 포함 한다. D2D 인터페이스는, 예를 들어, 9 테라바이트/초(TBytes/sec)의 총 대역폭에 대해 TSP 코어의 각 반구 상에 4.6TB/sec까지 지원할 수 있다. D2D 인터페이스는 물리적 및 데이터 스트리밍 대칭을 허용하 기 위해 TSP 코어의 반구들 둘 다에 배치될 수 있다. 도 14에 예시된 D2D 인터페이스는 제1 다이의 17 슈퍼레인들(즉, 슈퍼 셀들의 17 로우들)을 제2 다 이의 16 슈퍼레인들에 매핑할 수 있다. 논리적으로, 각 슈퍼레인은, 예를 들어, 각 방향 4 x 128 비트(bits) = 512비트(bits)에 대해, S = 4 스트림들을 내보낸다(export). 각 인터페이스 슬라이스는 임의의 방향으로 동시에 256 비트(bits)의 스트리밍을 지원할 수 있으며, 각 인터페이스 슬라이스는 복수 의 D2D 인터페이스 매크로(macros) 중 각각의(respective) D2D 인터페이스 매크로의 일부이다. 다수의 D2D 인 터페이스 매크로(macros)는 D2D 인터페이스 뱅크를 형성한다. 도 14의 예시적인(illustrative) 실시예에 서, 8개의 D2D 인터페이스 매크로는 하나의 D2D 인터페이스 뱅크를 형성한다. 각 슈퍼레인은, 예 를 들어, 한 쌍의 256-비트(bit) 양방향 인터페이스 슬라이스에 직접 매핑될 수 있으며, 슈퍼레인들 은 S 슈퍼레인들(예를 들어, S = 4 슈퍼레인들)의 클러스터(cluster)로 그룹화된다. 하나의 D2D 인터페이스 뱅크를 형성하는 여덟 개의 D2D 인터페이스 매크로(macros)는 S 슈퍼레인들(예를 들어, S = 4 슈퍼레인들)의 클러스터와 매칭(match)된 피치이고 거의 동일한 높이이다. D2D 인터페이스를 갖는 D2D 매핑 구조는 다수의 다이들을 D2D 구성으로 스택하는 경우에 페이스-투 -페이스(face-to-face, F2F) 및 백-투-백(back-to-back, B2B) 다이 방향(orientation) 둘 다를 허용한다. D2D 매핑 구조는, 예를 들어, 라딕스(radix)-4 메시 구성 및 라딕스-8 토러스 구성을 가지는 시스템-인-패키 지(system-in-package)로 3-디멘션의 패키징을 가능하게 한다. D2D 매핑 구조는 또한 시스템-인 패키지 내에서 효율적인 모델 병렬화를 허용하고, 이는 가장 가까운-이웃 통신 패턴들을 활용할 수 있다. D2D 매핑 구 조는 D2D 구성, 예를 들어, 대략 수백 TB/sec의 온-칩 스트림 레지스터 대역폭, 대략 수십 TB/sec의 D2D 스트리밍 대역폭, 및 대략 TB/sec의 오프-칩 네트워크 대역폭으로 연결된 각 다이에 선호되는 통신 계층 (hierarchy)을 제공한다. 도 15a는 일부 실시예들에 따른, 제1 수의 슈퍼레인들(예를 들어, 16 슈퍼레인들) 및 D2D 인터페이스들을 갖는 예시적인 다이를 예시한다. 다이는 다이와 실질적으로 동일한 구조를 가지는 한개의 다이또는 두 개의 다이들(도 15a에 미도시)의 슈퍼레인들에 다이의 슈퍼레인들을 매핑하기 위해 다이의 반구들 둘 다에 배치된 도 14의 D2D 매핑 구조를 포함한다. 다이는, 예를 들어, 16(+1) 슈퍼레인 들, PCIe, 및 12 C2C 모듈들을 포함한다. 다이의 D2D 인터페이스들은, 예를 들어, 반구들 둘 다에 배치 된 총 여덟 개의 D2D 인터페이스 뱅크들(네 개의 동쪽 D2D 인터페이스 뱅크들, 및 네 개의 서쪽 D2D 인터페이스 뱅크들), 및 반구당 32 인터페이스 슬라이스들을 포함한다. 다이는 각 방향에서 인터페이스 슬라이스당 512Gb/s의 스트리밍 대역폭, 반구당 2TB/s의 송신 대역폭, 및 반구당 2TB/s의 수신 대역폭을 제공할 수 있다. 다이는, 예를 들어, 256MB SRAM을 더 포함할 수 있다. 다이의 영역(area)은, 예를 들어, 468mm2이 다. 도 15b는 일부 실시예들에 따른, 제2 수의 슈퍼레인들(예를 들어, 20 슈퍼레인들) 및 D2D 인터페이스들을 갖는 예시적인 다이를 예시한다. 다이는 다이와 실질적으로 동일한 구조를 가지는 한개의 다이 또는 두 개의 다이들(도 15b에 미도시)의 슈퍼레인들에 다이의 슈퍼레인들을 매핑하기 위해 다이의 반구들 둘 다에 배치된 도 14의 D2D 매핑 구조를 포함한다. 다이는, 예를 들어, 20(+1) 슈퍼레인 들, PCIe, 및 12 C2C 모듈들을 포함한다. 다이의 D2D 인터페이스들은, 예를 들어, 반구들 둘 다에 배치 된 총 10개의 D2D 인터페이스 뱅크들(다섯 개의 동쪽 D2D 인터페이스 뱅크들, 및 다섯 개의 서쪽 D2D 인터페이 스 뱅크들), 및 반구당 40개의 인터페이스 슬라이스들을 포함한다. 다이는 각 방향에서 인터페이스 슬라 이스당 512Gb/s의 스트리밍 대역폭, 반구당 2.5TB/s의 송신 대역폭, 및 반구당 2.5TB/s의 수신 대역폭을 제공할 수 있다. 다이는, 예를 들어, 250MB의 SRAM을 더 포함할 수 있다. 다이의 영역은, 예를 들어, 530mm2이다. 다이와 비교해 보면, 다이의 영역은 다이의 영역보다 약 20% 더 넓은 반면, 다 이은 다이보다 57%까지의 더 나은 성능(즉, 더 높은 대역폭)을 달성할 수 있다. 도 15c는 일부 실시예들에 따른, 제3 수의 슈퍼레인들(예를 들어, 24 슈퍼레인들) 및 D2D 인터페이스들을 갖는 예시적인 다이를 예시한다. 다이는 다이와 실질적으로 동일한 구조를 가지는 또 다른 다이 (도 15c에 미도시)의 슈퍼레인들에 다이의 슈퍼레인들을 매핑하기 위해 다이의 반구들 둘 다에 배 치된 도 14의 D2D 매핑 구조를 포함한다. 다이는, 예를 들어, 24(+1) 슈퍼레인들, PCIe, 및 12 C2C 모듈들을 포함한다. 다이의 D2D 인터페이스는, 예를 들어, 반구들 둘 다에 배치된 총 12개의 D2D 인 터페이스 뱅크들(여섯 개의 동쪽 D2D 인터페이스 뱅크들, 및 여섯 개의 서쪽 D2D 인터페이스 뱅크들), 및 반구 당 48개의 인터페이스 슬라이스들을 포함한다. 다이는 각 방향에서 인터페이스 슬라이스당 512Gb/s의 스 트리밍 대역폭, 반구당 3TB/s의 송신 대역폭, 및 반구당 3TB/s의 수신 대역폭을 제공할 수 있다. 다이는, 예를 들어, 240MB의 SRAM을 더 포함할 수 있다. 다이의 영역은, 예를 들어, 616mm2이다. 다이와 비교해 보면, 다이의 영역은 다이의 영역보다 약 50% 더 넓은 반면, 다이는 다 이보다 225%까지의 더 나은 성능(즉, 더 높은 대역폭)을 달성할 수 있다. 다이는 또한 작동 효율성을 위해 상대적으로 낮은 공급 전압(supply voltage) 및 낮은 클록 주파수를 지 원할 수 있다. 선택적으로, 다이는 다이의 각 코너(corner)에 배치된 두 개의 32b 채널 저-전력 이중 데이터 레이트(Low-Power Double Data Rate, LPDDR) 메모리를 포함할 수 있다. 일부 실시예들에서(도 15c에 미도시), C2C 모듈들의 수는 추가 LPDDR 채널들을 위한 자리(room)를 만들기 위해 (예를 들어, 12 C2C 모 듈들에서 9 C2C 모듈들로) 줄일 수 있다. 다이는, 예를 들어, 칩당 240 메가바이트(MBytes)를 프로세싱 하면서, (전력-효율을 달성하기 위해) 750MHz에서 약 1 팝스(Pops), 또는 1.8GHz에서 약 1피플롭스(PFlops)를 수행할 수 있다. LPDDR의 한 채널은, 예를 들어, 34GB/sec의 대역폭을 가지며, 이는 단일 스트림 직렬화 대역 폭(예를 들어, 16B/cycle)과 짝을 이룬다(mate up with)-스트림당 32GB/sec의 대역폭은 LPDDR 채널의 34GB/sec 대역폭으로 바꿀(translate) 수 있음. 본 개시의 실시예들은 D2D 인터페이싱(interfacing)을 사용하여 \"네트워크-인-패키지(network-in-package)\"를 구축하는 새로운 접근법에 관한 것이다. 여기에 제시된 패키징 방식(packaging scheme)은 다수의 다이를 “나 란히(side by side)”한 또는 다이들을 “폴딩”하여 다이들을 “수직으로 스택”한 멀티-칩(multi-chip) 모듈 을 구축하는 것을 허용한다. 이 패키징 방식은 스트림들이 동쪽 방향 또는 서쪽 방향 중 하나로 하나의 칩(즉, 다이)에서 다음 칩으로 자동으로 흐르기 때문에 다수의 칩들(또는 다이들)을 가로질러 “스트리밍(streaming)” 프로그래밍 모델을 확장(extend)한다. 다이의 East/West 가장자리에서의 D2D 인터페이스 배치의 물리적 대칭은 다이를 “가장자리 대칭(edge symmetric)”으로 취급(treat)할 수 있으며, 인접한 다이 위에 “스택”하기 위해 다이를 거꾸로 “플리핑(flipping)”을 허용한다. 가장자리-대칭(edge-symmetry)은 인접한 다이들이 \"페이스- 투-페이스(face-to-face)\" 또는 \"백-투-백(back-to-back)\" 스택되게 한다. 가장자리 대칭은 달리 수평 다이들의 패키징을 가능하게 하며, 예를 들어, 네 개의 TSP 코어들을 단일 45x45mm 패키지에 포함하도록 “폴디드 메 시(folded mesh)”를 생성하는 것과 같은, 패키지 내에서의 “TSP들의 네트워크”를 구축하는 것을 허용한다. D2D 패키지(또는 D2D 구조)는, 예를 들어, \"유효한\" (전파) 비트가 설정되는 경우, 각 D2D 인터페이스 매크로를 가로질러 S 스트림들(예를 들어, S = 4 스트림들)을 패스(pass)하는 것으로 간소화된 제어를 갖는 단일 \"기능 유닛(functional unit)\"으로 작동한다. 여기에 제시된 패키징 방식은 활성화들이, 예를 들어, 제한된 제어/인 스트럭션 오버헤드로 테라바이트/초(TBytes/sec)보다 많은 대역폭을 달성하기 위해, 소수의(a handful of) 사이 클들 레이턴시 만을 갖는 매우 효율적으로 다수의 칩들을 가로질러 스트리밍되게 한다. 여기에 제시된 패키징 방식은, 각각(respectively), D2D 패키지 내 두 개 또는 세 개의 다이들(또는 TSP 칩들)에 연결된다면 MXM들이, 예를 들어, 256x512 또는 256x768 크기일 수 있기 때문에 \"비대칭(asymmetric)\"으로 D2D 패키지 내 다수의 칩 들(즉, 다수의 TSP 코어들)을 가로질러 MXM들을 취급하는 것을 더 허용한다. 여기에 제시된 패키징 방식은 다 이들(또는 TSP 칩들) 간에 동기 스트리밍을 더 허용하며, 이는 결정론적 고정-레이턴시 스트리밍 모델을 진정으 로 확장(extend)한다. 다이-투-다이 고밀도 패키징을 갖는 집적 회로에 대한 예시적인 프로세스 흐름 도 16은 일부 실시예들에 따른, D2D 구조로 연결된 복수의 다이들을 가로질러 모델-병렬화로 데이터 프로세싱을 위해 집적 회로를 사용하는 방법을 예시하는 흐름도(flowchart)이다. 집적 회로는 적어도 하나의 컴퓨터 프로세서(예를 들어, 결정론적 스트리밍 프로세서) 및 컴퓨터 실행 가능한 인스트럭션들을 저장하기 위한 비일 시적 컴퓨터 판독 가능 저장 매체(non-transitory computer-readable storage medium)를 더 포함할 수 있다. D2D 구조에서의 각 다이는 결정론적 스트리밍 프로세서를 포함할 수 있다. 결정론적 스트리밍 프로세서는 TSP 일 수 있다. 복수의 다이들을 갖는 D2D 구조는 단일 코어 결정론적 스트리밍 프로세서로 작동하도록 구성될 수 있다. 방법의 작동들은 (예를 들어, 집적 회로의 일부로서) 적어도 하나의 컴퓨터 프로세서 및/또는 (예를 들어, 집적 회로와 분리된) 호스트 서버에서 작동하는 컴파일러에 의해 개시될 수 있다. 컴파일러는 결정론적 스트리밍 프로세서들에 대한 모델(예를 들어, 머신 러닝 모델)을 그 입력으로 활용할 수 있고 D2D 구조에 연결 된 복수의 다이들을 갖는 집적 회로의 작동을 구성하기 위한 인스트럭션들을 출력으로 활용할 수 있다. 집적회로는 (예를 들어, 컴파일러를 통해) 제1 다이 및 제2 다이를 가로질러 복수의 프로세싱 유닛들에 의한 실 행을 위해 복수의 인스트럭션(instruction)들의 발행을 개시하고, 제2 다이는 제1 다이로 D2D 구조를 형 성하는 D2D 구성에서의 D2D 인터페이스 회로를 통해 제1 다이에 연결된다. 집적회로는 (예를 들어, 컴파일러를 통해) 복수의 인스트럭션들의 실행을 위해 제1 방향 또는 제1 방향과 직교하는 제2 방향을 따라 D2D 인터페이스 회로를 통해 제1 다이의 제1 복수의 슈퍼레인들과 제2 다이의 제2 복수의 슈퍼레인들 간에 데이터의 스트리밍 (streaming)을 개시한다. 집적 회로는 (예를 들어, 컴파일러를 통해) 제1 방향 및 제2 방향 중 적어도 하나를 따라 복수의 다이들을 가로 질러 데이터의 스트리밍을 개시할 수 있고, 복수의 다이들은 복수의 D2D 인터페이스 회로들을 통해 D2D 구성으 로 연결되고, 그리고 D2D 구조를 형성할 수 있다. 집적 회로는 D2D 구조의 복수의 다이들을 가로질러 모델-병 렬화를 위한 단일 코어 프로세서로 기능하도록 D2D 구조를 형성하는 복수의 다이들을 (예를 들어, 컴파일러를 통해) 구성할 수 있다. 일부 실시예들에서, D2D 인터페이스 회로는 복수의 양방향 인터페이스 슬라이스들을 포함하고, 그리고 한 쌍의 양방향 인터페이스 슬라이스는 제2 다이의 제2 복수의 슈퍼레인들의 해당 슈퍼레인들에 연결된다. D2D 인터페 이스 회로는 제1 다이의 제1 복수의 슈퍼레인들의 해당 서브세트에 연결된 D2D 코어 인터페이스 회로를 더 포함 한다. 일부 실시예들에서, D2D 인터페이스 회로는 복수의 D2D 인터페이스 뱅크들을 포함하며, 복수의 D2D 인터페이스 뱅크들 각각은 제1 복수의 슈퍼레인들의 클러스터(cluster)를 제2 복수의 슈퍼레인들의 클러스터에 연결한다. 제1 방향을 따른 D2D 인터페이스의 복수의 D2D 인터페이스 뱅크들 각각의 크기는, 제1 방향을 따른 제2 복수의 슈퍼레인들의 클러스터의 크기와 매칭(match)한다. D2D 인터페이스의 복수의 D2D 인터페이스 뱅크들 각각은 복 수의 D2D 인터페이스 매크로(macros)를 포함하고, 그리고 복수의 D2D 매크로 각각은 복수의 양방향 인터페이스 슬라이스들의 각각의(respective) 양방향 인터페이스 슬라이스를 포함한다. D2D 구조는, D2D 구성으로 제1 및 제2 다이들과 연결되고, 제1 디멘션(dimension)과 제2 디멘션 중 적어도 하나 를 가로지르는(span across) 하나 더 다이들을 더 포함할 수 있다. D2D 구조는 D2D 구조의 복수의 다이들을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 기능하도록 구성될 수 있다. D2D 구조의 복수의 다이들은 D2D 폴디드 메시(folded mesh) 구성 또는 D2D 토러스(torus) 구성으로 연결될 수 있다. 집적 회로는, 제1 및 제2 다이들로 D2D 구조를 형성하는 D2D 구성에서의 제2 D2D 인터페이스 회로를 통해 제2 다이에 연결된 제3 다이를 더 포함할 수 있고, 제2 D2D 인터페이스는 제1 방향 또는 제2 방향을 따라 제2 다이 와 제3 다이 간에 데이터를 스트리밍하기 위해 제2 다이의 제2 복수의 슈퍼레인들을 제3 다이의 제3 복수의 슈 퍼레인들에 연결한다. 집적 회로는 제1, 제2 및 제3 다이들로 D2D 구조를 형성하는 D2D 구성에서의 제3 D2D 인 터페이스 회로를 통해 제3 다이에 연결된 제4 다이를 더 포함하고, 제3 D2D 인터페이스는 제1 방향 또는 제2 방 향을 따라 제3 다이와 제4 다이 간에 데이터를 스트리밍하기 위해 제3 다이의 제3 복수의 슈퍼레인들을 제4 다 이의 제4 복수의 슈퍼레인들에 연결할 수 있다. D2D 구조를 형성하는 제1, 제2, 제3 및 제4 다이들은 D2D 폴디 드 메시 구성으로 상호 연결될 수 있다. D2D 폴디드 메시 구성으로 연결된 제1, 제2, 제3 및 제4 다이들은 D2D 폴디드 메시 구성을 가로질러 모델-병렬화를 위한 단일 코어 프로세서로 작동하도록 구성된다. 제1 다이는 제1 복수의 슈퍼레인들을 통해 적어도 부분적으로 연결된 제1 복수의 기능 유닛들(functional units)을 가지는 제1 TSP를 포함하고, 제2 다이는 제2 복수의 슈퍼레인들을 통해 적어도 부분적으로 연결된 제2 복수의 기능 유닛들을 가지는 제2 TSP, 고-대역폭 메모리, 및 D2D 인터페이스 회로를 포함할 수 있다. 제2 다 이는 D2D 구조를 형성하는 백투백(back-to-back) 구성 또는 페이스-투-페이스(face-to-face) 구성으로 제1 다이 에 연결될 수 있다. 예시적인 컴퓨터 시스템 아키텍처 도 17a는 일부 실시예들에 따른, 청구된 개시들의 실시예들을 가능하게 하는 데 적합한 예시적인 컴퓨터 시스템 의 추상도(abstract diagram)이다. 도 17a에서, 컴퓨터 시스템의 구조는 전형적으로 버스 서브시스템을 통해 주변 장치들과 통신하는 적어도 하나의 컴퓨터를 포함한다. 전형적으로, 컴퓨터는 프로세서(예를 들어, 마이크로프로세서, 그래 픽 처리 장치(graphics processing unit), 또는 디지털 신호 프로세서), 또는 ASIC 또는 FPGA와 같은, 전자 프 로세싱 등가물들을 포함한다. 전형적으로, 주변 장치들은 메모리 서브시스템 및 파일 스토리지 서브시스 템을 포함하는 스토리지 서브시스템, 유저 인터페이스 입력 장치들, 유저 인터페이스 출력 장치들, 및/또는 네트워크 인터페이스 서브시스템을 포함한다. 입력 및 출력 장치들은 컴퓨터 시 스템과 직접의 및 원격의 유저 상호 작용을 가능하게 한다. 컴퓨터 시스템은 적어도 하나의 출력 장치 및/또는 네트워크 인터페이스 서브시스템을 사용하여 중요한 사후-프로세스 활동을 가능하게 한다. 컴퓨터 시스템은 서버, 클라이언트, 워크스테이션, 메인프레임, 개인용 컴퓨터(personal computer, PC), 태블릿 PC, 셋톱박스(set-top box, STB), 개인용 디지털 어시스턴트(personal digital assistant, PDA), 셀룰러폰 (cellular telephone), 스마트폰, 웹 어플라이언스(web appliance), 랙-장착된(rack-mounted) '블레이드', 키 오스크, 텔레비전, 게임 스테이션, 네트워크 라우터, 스위치 또는 브릿지, 또는 이 머신에 의해 취해질 액션 (action)들을 지정하는 인스트럭션들을 갖는 임의의 데이터 프로세싱 머신으로 구조화(structure)될 수 있다. 여기에서 사용되는 것처럼, 용어 '서버'는 전형적으로 프로세스들을 수행하고, 데이터 및 정보를 또 다른 컴퓨 터 또는 프로세서로 전송하는 컴퓨터 또는 프로세서를 지칭한다. 전형적으로 컴퓨터 시스템은 적어도 하나의 운영 체제(operating system) 프로그램, 예를 들어, 마이크로소프트 윈도우들(MICROSOFT WINDOWS), 애플 매코스(APPLE MACOS) 및 아이오에스(IOS), 구글 안드로이드(GOOGLE ANDROID), 리눅스(Linux) 및/또는 유닉스(Unix)로 부분적으로 구조화된다. 컴퓨터 시스템은 전형적으로 기본 입력/출력 시스템(Basic Input/Output System, BIOS) 및 프로세서 펌웨어를 포함한다. 운영 체제, BIOS 및 펌 웨어는 프로세서에 연결된 임의의 서브시스템들 및 인터페이스들을 구조화하고 제어하도록 프로세서에 의해 사 용된다. 이러한 운영체제들을 가능하게 하는 예시적인 프로세서들은 인텔에서의 펜티엄(Pentium), 아이타니엄 (Itanium), 제온(Xeon) 프로세서들; AMD(어드밴스드 마이크로 디바이스들(ADVANCED MICRO DEVICES))에서의 옵 테론(Opteron) 및 애슬론(Athlon) 프로세서들; 아마존(AMAZON)에서의 그래비톤(Graviton) 프로세서, IBM에서의 파워(POWER) 프로세서, 오라클(ORACLE)에서의 스팍(SPARC) 프로세서, ARM 홀딩스에서의 ARM 프로세서를 포함한 다. 본 개시의 임의의 실시예는 프로그램들로 구조화된 전자 디지털 논리 컴퓨터 또는 전자적으로 프로그래머블 장 치 중 하나로 제한되지 않는다. 예를 들어, 청구된 실시예들은 광학 컴퓨터, 양자 컴퓨터, 아날로그 컴퓨터, 또는 그 유사한 것을 사용할 수 있다. 게다가, 단일 컴퓨터 시스템 또는 단일 머신 만을 의미(signify)하는 경우, 이러한 용어들의 단수형 사용은 프로세스들을 개별적으로 또는 공동으로 사용하는 컴퓨터 시스템들 또는 머 신들의 임의의 구조를 의미할 수도 있다. 컴퓨터들 및 네트워크들의 끊임없이-변화하는 특성(ever-changing nature)으로 인해, 도 17a에 묘사된 컴퓨터 시스템의 설명은 단지 예로 의도된다. 컴퓨터 시스템 의 많은 다른 구조들은 도 17a에 묘사된 컴퓨터 시스템보다 더 많은 구성요소들을 가진다. 네트워크 인터페이스 서브시스템은 통신 네트워크에 대한 인터페이스를 포함하는, 외부 네트워크들 에 대한 인터페이스를 제공하고, 그리고 통신 네트워크를 통해 다른 컴퓨터 시스템들 또는 머신들 내 해 당 인터페이스 장치들에 커플링된다. 통신 네트워크는 많은 상호 연결된 컴퓨터 시스템들, 머신들 및 물 리적 통신 연결들('링크들'로 의미됨)을 포함(comprise)할 수 있다. 이 통신 링크들은 와이어라인(wireline) 링크들, 광 링크들, (예를 들어, 와이파이(WiFi) 또는 블루투스(Bluetooth) 프로토콜들을 사용하는) 무선 링크 들, 또는 정보의 통신을 위한 임의의 다른 물리 장치들일 수 있다. 통신 네트워크는 임의의 적절한 컴퓨 터 네트워크, 예를 들어 인터넷(Internet)과 같은 광역(wide area) 네트워크, 및/또는 이더넷(Ethernet)과 같은 로컬-투-광역(local-to-wide area) 네트워크일 수 있다. 예를 들어 가상 사설망(virtual private network)으 로 이용가능한, 통신 네트워크는 유선 및/또는 무선이며, 그리고 많은 통신 네트워크들은 암호화(encryption) 및 암호 해독(decryption) 프로세스들을 사용한다. 통신 네트워크는 하나 이상의 통신 인터페이스들을 사용하 고, 이는 다른 시스템들로부터 데이터를 수신하고, 다른 시스템들로 데이터를 송신한다. 통신 인터페이스들의 실시예들은 전형적으로 이더넷 카드, 모뎀(예를 들어, 전화, 위성, 케이블, 또는 통합 서비스 디지털 네트워크 (Integrated Services Digital Network, ISDN)), (비동기식) 디지털 가입자 회선(digital subscriber line, DSL) 유닛, 파이어와이어(Firewire) 인터페이스, 범용 직렬 버스(universal serial bus, USB) 인터페이스, 및 그 유사한 것을 포함한다. 통신 알고리즘들('프로토콜들')은 하이퍼텍스트 전송 프로토콜(Hypertext Transfer Protocol, HTTP), 전송 제어 프로토콜/인터넷 프로토콜(Transmission Control Protocol/Internet Protocol, TCP/IP), 실시간 전송 프로토콜/실시간 스트리밍 프로토콜(Real-time Transport Protocol/Real Time Streaming Protocol, RTP/RTSP), 망간 패킷 교환(Internetwork Packet Exchange, IPX) 프로토콜 및/또는 사용자 데이터그 램 프로토콜(User Datagram Protocol, UDP)과 같은, 하나 이상의 통신 언어들을 사용하여 지정될 수 있다. 유저 인터페이스 입력 장치들은 알파숫자(alphanumeric) 키보드, 키패드, 마우스와 같은 포인팅 (pointing) 장치들, 트랙볼(trackball), 토글 스위치(toggle switch), 터치패드, 스타일러스(stylus), 그래픽 태블릿, 바코드 리더와 같은 광학 스캐너(optical scanner), 디스플레이 장치를 위한 터치스크린 전자 장치들, 음성 인식 시스템들 또는 마이크들과 같은 오디오 입력 장치들, 시선 인식, 뇌파 패턴 인식, 광학 문자 인식 시 스템들, 및 다른 유형의 입력 장치들을 포함할 수 있다. 이러한 장치들은 유선 또는 무선으로 컴퓨터 시스템에 연결된다. 전형적으로, 용어 '입력 장치'는 용어는 데이터 및 정보를 컴퓨터 시스템 또는 통신 네트워크 로 전송하는 모든 가능한 유형의 장치들 및 프로세스들을 의미한다. 유저 인터페이스 입력 장치들은 전 형적으로 유저가 일부 유형의 유저 인터페이스 출력 장치들, 예를 들어, 디스플레이 서브시스템에 나타나는 오 브젝트(object)들, 아이콘들, 텍스트 및 그 유사한 것을 선택하는 것을 가능하게 한다. 유저 인터페이스 출력 장치들은 디스플레이 서브시스템, 프린터, 팩스 머신, 또는 오디오 및 햅틱 (haptic) 장치들과 같은 비-시각적 통신 장비를 포함할 수 있다. 디스플레이 서브시스템은 CRT, LCD와 같은 플 랫-패널(flat-panel) 장치, 이미지 투사 장치, 또는 가상 현실 시스템과 같은 시각적 자극(stimuli)을 만들기 위한 일부 다른 장치를 포함할 수 있다. 디스플레이 서브시스템은 예를 들어 오디오 출력, 아로마 생성, 또는 촉각(tactile)/햅틱 출력(예를 들어, 진동(vibrations) 및 포스(forces)) 장치들을 통해 비시각적 자극을 제공 할 수도 있다. 전형적으로, 용어 '출력 장치'는 유저에게 컴퓨터 시스템 밖으로 또는 또 다른 머신 또는 컴퓨터 시스템으로 데이터 및 정보를 전송하기 위한 모든 가능한 유형의 장치들 및 프로세스들을 의미한다. 이 러한 장치들은 유선 또는 무선으로 컴퓨터 시스템에 연결된다. 일부 장치들, 예를 들어, 유저의 손에 진동과 포스(forces)를 생성하며 손의 위치와 움직임을 측정하는 센서들을 또한 통합하는 햅틱 장치들은 컴퓨터 안으로 및 밖으로 데이터와 정보를 전송하는 점을 주목한다. 인체공학(ergonomics) 및 기호학(semiotics)의 과학들의 기술적 애플리케이션들은 위의 어느 입력 또는 출력 장치들을 사용하는 회로들의 설계 및 제조와 관련된 임의의 상호작용들과 같이, 여기에 개시된 임의의 프로세스들 및 컴퓨터들과의 사용자 상호작용들(user interactions) 의 효율성을 개선하도록 사용된다. 메모리 서브시스템은 전형적으로 프로그램 실행 중 인스트럭션들 및 데이터의 저장을 위한 주(main) RAM(또는 다른 휘발성 스토리지 장치) 및 고정 인스트럭션들이 저장되는 ROM을 포함하는 여러 메모 리들을 포함한다. 파일 스토리지 서브시스템은 프로그램 및 데이터 파일들을 위한 영구 스토리지를 제공 하며, 하드 디스크 드라이브, 관련 이동식 매체들(removable media)과 함께 플로피 디스크 드라이브, CD-ROM 드라이브, 광 드라이브, USB 드라이브와 같은 플래시 메모리, 또는 이동식 미디어 카트리지들을 포함할 수 있다. 컴퓨터 시스템이 광학 문자 인식을 수행하는 입력 장치를 포함한다면, (종이와 같은) 물리적 오브젝트에 인쇄된 텍스트 및 기호들은 프로그램 및 데이터 파일들을 저장을 위한 디바이스(device)로 사용될 수 있다. 일 부 실시예들에 의해 사용되는 데이터베이스들 및 모듈들은 파일 스토리지 서브시스템에 의해 저장될 수 있다. 버스 서브시스템은 컴퓨터 시스템의 다양한 구성요소들과 서브시스템들 간에 데이터 및 정보를 전 송하기 위한 장치를 제공한다. 비록 버스 서브시스템은 단일 버스로 묘사되긴 하지만, 버스 서브시스템 의 대안적인 실시예들은 다수의 버스들을 사용할 수 있다. 예를 들어, RAM을 사용하는 주 메모리는 DMA 시스템 들을 사용하여 파일 저장 시스템들과 직접 통신할 수 있다. 도 17b는 일부 실시예들에 따른, 청구된 개시들의 실시예들을 가능하게 하는 데 적합한 컴퓨터 시스템의 또 다 른 추상도이다. 도 17b는 (예를 들어, 버스 서브시스템을 통해) 파일 스토리지 서브시스템 및/또 는 네트워크 인터페이스 서브시스템과 연관된 비-일시적, 프로세서 판독 가능 데이터 및 정보 저장 매체 와 같은 메모리를 묘사하며, 그리고 회로 설계를 지정하는 데이터 구조를 포함할 수 있다. 메모리(174 0)는 하드 디스크, 플로피 디스크, CD-ROM, 광학 매체, 이동식 미디어 카트리지, 또는 광학 문자 인식 시스템에 의해 프로세싱될 수 있는 (종이와 같은) 물리적 오브젝트 상에 텍스트 및 기호들과 같은, 휘발성 또는 비휘발성 형태로 컴퓨터 판독 가능 데이터를 저장하는 임의의 다른 매체일 수 있다. 이러한 메모리에서 프로세서 안으로 밖으로 전송되는 프로그램은 (전기 펄스로서 네트워크, 커넥터, 와이어, 또는 회로 트레이스(trace)와 같은) 매 체를 통해; 또는 음향(acoustic) 신호로서, 또는 적외선보다 더 긴 전자기 스펙트럼에서의 파장들을 가진 전자 기 방사선으로서 우주(space) 또는 대기와 같은 매체를 통해 전파되는 물리적인 신호로 변환될 수 있다. 추가 예시적인 컴퓨팅 시스템 도 18은 일부 실시예에 따라 프로세서(또는 컨트롤러)에서 컴퓨터 판독 가능 매체로부터 인스트럭션들을 읽고 인스트럭션들(them)을 실행시킬 수 있는 예시적인 컴퓨팅 머신의 구성요소들을 예시하는 블록도이다. 여기에 설명된 컴퓨터는 도 18에 도시된 단일 컴퓨팅 머신, 가상 머신, 도 18에 도시된 컴퓨팅 머신들의 다수의 노드들 을 포함하는 분산 컴퓨팅 시스템, 또는 컴퓨팅 장치들의 임의의 다른 적합한 배열들을 포함할 수 있다. 여기에 설명된 컴퓨터는 설명된 기능들을 실행하도록 이전 도면들에서 설명된 어느 요소들에 의해 사용될 수 있다. 예로서, 도 18은 컴퓨터 판독 가능한 매체에 저장될 수 있는 인스트럭션들(예를 들어, 소프트웨어, 프로그램 코 드, 또는 머신 코드)이 머신으로 하여금 여기에서 논의되는 프로세스들 중 임의의 하나 이상을 수행하게 하는 컴퓨터 시스템의 예시적인 형태에서의 컴퓨팅 머신의 도식적 표현을 묘사한다. 일부 실시예에서, 컴퓨팅 머신은 독립형(standalone) 장치로 작동하거나 다른 머신들에 연결(예를 들어, 네트워크 연결)될 수 있다. 네 트워크 연결된 배포에서, 머신은 서버클라이언트 네트워크 환경 내 클라이언트 머신 또는 서버 머신의 용량에서, 또는 피어-투-피어(또는 분산) 네트워크 환경 내 피어 머신으로 작동할 수 있다. 도 18에 설명된 컴퓨팅 머신의 구조는 상기 도면들에서 도시되는 임의의 소프트웨어, 하드웨어 또는 조합된 구 성 요소들을 대응할 수 있다. 예로서, 컴퓨팅 머신은 캘리포니아 마운틴 뷰의 GROQ, INC.에 의해 설계되고 제 조된 텐서 스트리밍 프로세서, 개인용 컴퓨터(PC), 태블릿 PC, 셋톱박스(STB), 개인용 디지털 어시스턴트(PDA), 셀룰러폰, 스마트폰, 웹 어플라이언스, 네트워크 라우터, 사물 인터넷(internet of things, loT) 장치, 스위치 또는 브릿지, 또는 이 머신에 의해 취해질 액션들을 지정하는 인스트럭션들을 실행할 수 있는 임의의 머 신일 수 있다. 더욱이, 단일 머신만이 예시되는 반면, 용어 \"머신(machine)\"은 여기에서 논의되는 방법론들 중 임의의 하나 이상을 수행하도록 개별적으로 또는 공동으로 인스트럭션들을 실행하는 머신들의 임의의 집 합(collection)을 포함하는 것으로 간주되어야 한다. 예시적인 컴퓨터 시스템은 하나 이상의 프로세서들(일반적으로, 프로세서(예를 들어, 중앙 처리 장 치(central processing unit, CPU), 그래픽 처리 장치(graphics processing unit, GPU), 디지털 신호 프로세서 (digital signal processor, DSP), 하나 이상의 애플리케이션 특정 집적 회로들(application specific integrated circuits, ASIC들), 하나 이상의 라디오-주파수 집적 회로들(radio-frequency integrated circuits, RFIC들) 또는 이들의 임의의 조합), 주 메모리, 및 정적(static) 메모리를 포함하며, 이는 버스를 통해 서로 통신하도록 구성된다. 컴퓨터 시스템은 그래픽 디스플레이 유닛(예 를 들어, 플라즈마 디스플레이 패널(plasma display panel, PDP), 액정 디스플레이(liquid crystal display, LCD), 프로젝터, 또는 음극선관(cathode ray tube, CRT))을 더 포함할 수 있다. 컴퓨터 시스템은 또한 알파숫자(alphanumeric) 입력 장치(예를 들어, 키보드), 커서 제어 장치(예를 들어, 마우스, 트랙볼(trackball), 조이스틱(joystick), 모션 센서, 또는 다른 포인팅 기구), 스토리지 유닛, 신호 생성 장 치(예를 들어, 스피커), 및 네트워크 인터페이스 장치를 포함할 수 있으며, 이는 또한 버스 를 통해 통신하도록 구성된다. 스토리지 유닛은 여기에 설명된 방법론(methodology)들 또는 기능들 중 임의의 하나 이상을 구현(embod y)하는 인스트럭션들이 저장된 컴퓨터 판독 가능 매체를 포함한다. 인스트럭션들은 또한 주 메모리 내에 또는 프로세서 내에(예를 들어, 프로세서의 캐시 메모리 내에), 완전히 또는 적어도 부분적으로, 존재(reside)할 수 있다. 따라서, 컴퓨터 시스템에 의해 이를 실행하는 동안, 주 메모리 및 프로세서는 또한 컴퓨터 판독 가능 매체들을 구성할 수 있다. 인스트럭션들은 네트워크 인터페이스 장치를 통해 네트워크를 거쳐 송신 또는 수신될 수 있다. 컴퓨터 판독 가능 매체는 예시적인 실시예에서 단일 매체로 도시되지만, 용어 \"컴퓨터 판독 가능 매체 (computer-readable medium)\"는 인스트럭션들(예를 들어, 인스트럭션들)을 저장할 수 있는 단일 매체 또 는 다수의 매체들(예를 들어, 중앙 집중식 또는 분산 데이터베이스, 또는 관련 캐시들 및 서버들)을 포함하는 것으로 간주되어야 한다. 컴퓨터 판독 가능 매체는 머신으로 하여금 여기에 개시된 방법론들 중 임의의 하나 이상을 수행하게 하고 머신에 의한 실행을 위해 인스트럭션들(예를 들어, 인스트럭션들)을 저장할 수 있는 임의의 매체를 포함할 수 있다. 컴퓨터 판독 가능 매체는 고체 메모리들, 광학 매체들, 및 자기 매체들의 형태로 데이터 저장소(repository)들을 포함할 수 있지만, 이에 제한되지 않는다. 컴퓨터 판독 가능 매체는 신호(signal) 또는 반송파(carrier wave)와 같은 일시적인 매체를 포함하지 않다. 추가 고려 사항들 개시된 구성들은, 예를 들어, 프로세서의 기능들을 특수한 기능 유닛들로 분리하고, 각 기능 유닛에 데이터 및 인스트럭션들의 타이밍을 구성하여, 보다 효율적인 데이터 흐름을 포함하는, 베네핏(benefit)들 및 이점 (advantage)들을 가질 수 있게 되며, 그 결과 각 유닛은 수신된 데이터와 인스트럭션들 간에 알려진 타이밍에 기초하여 수신된 데이터를 작동하는 것이 가능하게 된다. 프로세서를 위한 컴파일러는 하드웨어를 인식하기 때 문에, 인스트럭션들과 데이터 피연산자들이 프로세서의 다른 타일들로 전송되는 방법(how)과 시기(when)를 나타 내는 프로세서를 위한 명시적인 계획을 구성할 수 있다. 수신된 인스트럭션들과 데이터의 타이밍을 고려하여 데이터는 불필요한 메타데이터 없이 프로세서의 타일들 간에 전송될 수 있고, 전송의 효율을 증가시킨다. 추가 로, 데이터 및 인스트럭션들의 전송을 분리하여, 인스트럭션들은 수신된 데이터 피연산자들과는 별도로 반복 (iterate)되고 루프(loop)될 수 있다. 추가로, 프로세서의 각 계산 요소는 특정 기능(예를 들어, MEM, VXM, MXM, SXM)에 전용되기 때문에, 계산 요소 들에 의해 프로세싱될 필요가 있는 인스트럭션들의 양이 줄어들 수 있다. 예를 들어, (예를 들어, MXM 기능 슬 라이스에서의) 특정 계산 요소들은 임의의 수신된 데이터에 대해 제한된 작동 세트(set of operations)를 수행 하도록 구성될 수 있다. 이와 같이, 이러한 계산 요소들은 명시적인 인스트럭션들을 수신하는 것 없이 또는 간 헐적이거나 제한된 인스트럭션들만을 수신하여 작동할 수 있고, 프로세서의 작동을 잠재적으로 간소화할 수 있 다. 예를 들어, 메모리에서 읽은 데이터 피연산자는 데이터가 데이터 레인을 가로질러 전송되기 때문에 다수의 기능 슬라이스들에 의해 가로채질 수 있고, 보다 효율적인 방식으로 데이터에 대해 수행될 다수의 작동들을 허 용할 수 있다. 작동 시, 호스트 컴퓨터는 실제로 데이터를 전송하도록 DMA 엔진을 프로그래밍하며, 다시 이 모든 것은 런타임 레이어에 의해 조정된다. 구체적으로, IDU는 매 코어 클록 사이클마다(예를 들어, 공칭 900Mhz) PCIe-Gen4 32 바이트(bytes)에서 320-바이트 벡터들을 전송한다. 따라서, 320-요소 벡터는 10 사이클들의 기간(period)에 걸 쳐 도착하고 MEM을 향해 이동하는 다수의 스트림들에 배치된다. 들어오는 스트림들은 S24 내지 31(상위 여덟 개의 스트림들) 상에서 흐르며, 이로부터 MEM은 그 벡터를 SRAM에 커밋(commit)하기 위해 \"쓰기(write)\"를 수행 한다. 그러므로, PCI-Receive는 (i) PCI 인터페이스로부터 데이터를 수신하는 것, 및 (ii) 벡터를 MEM의 지정 된 기능 슬라이스에 쓰는 것으로 구성된다. 개시의 실시예들의 전술한 설명은 예시(illustration)의 목적으로 제시되었다; 설명(it)은 개시된 정확한 형태 로 개시를 제한하거나 철저하게(exhaustive) 하도록 의도되지 않는다. 관련 기술 분야의 당업자(Persons skilled in the relevant art)는 상기 개시(above disclosure)에 비추어 많은 수정들 및 변경들이 가능하다는 것을 이해할 수 있다. 이 설명의 일부 부분들은 정보 상에 동작(operation)들의 알고리즘들 및 기호적 표현들(symbolic representations)의 관점에서 본 개시의 실시예들을 설명한다. 이 알고리즘 설명들 및 표현들은 데이터 프로세 싱 분야에 숙련된 당업자들에 의해 그 작업의 내용을 해당 기술 분야에 다른 당업자에게 효과적으로 전달하기 위해 사용된다. 이 동작(operation)들은, 기능적으로, 계산적으로, 또는 논리적으로 설명되는 반면, 컴퓨터 프 로그램들 또는 이에 상응하는 전기 회로들, 마이크로코드, 또는 그 유사한 것에 의해 구현되는 것으로 이해된다. 더구나, 일반성의 상실(loss of generality) 없이 동작(operation)들의 이러한 배열들을 모듈들로 지칭하는 것이 때때로 편리한 것 또한 입증되었다. 설명된 동작(operation)들 및 그들의 관련된 모듈들은 소프 트웨어, 펌웨어, 하드웨어, 또는 이의 임의의 조합들에서 구현(embody)될 수 있다. 여기에 설명된 어느 단계들, 동작(operation)들, 또는 프로세스들은 단독으로 또는 다른 장치들과의 조합으로, 하나 이상의 하드웨어 또는 소프트웨어 모듈들로 수행되거나 구현될 수 있다. 일 실시예에서, 소프트웨어 모듈 은 컴퓨터 프로그램 코드를 포함(contain)하는 컴퓨터 판독 가능 매체를 포함(comprise)하는 컴퓨터 프로그램 제품(product)으로 구현되고, 이는 설명된 단계들, 동작들, 또는 프로세스들의 일부 또는 전부를 수행하기 위해 컴퓨터 프로세서에 의해 실행될 수 있다. 본 개시의 실시예들은 또한 여기에 동작들을 수행하기 위한 장치와 관련될 수 있다. 이 장치는 요구되는 목적 들을 위해 특별히 구성될 수 있고, 및/또는 컴퓨터에 저장된 컴퓨터 프로그램에 의해 선택적으로 활성화 (activate)되거나 재구성된 범용 컴퓨팅 장치(general-purpose computing device)를 포함(comprise)할 수 있다. 이러한 컴퓨터 프로그램은 컴퓨터 시스템 버스에 커플링(couple)된, 비일시적(non-transitory)이고 유형 의(tangible) 컴퓨터 판독 가능 저장 매체, 또는 전자 인스트럭션들을 저장하는 데 적합한 임의의 유형의 매체 들(media)에 저장될 수 있다. 더구나, 명세서에서 언급된 임의의 컴퓨팅 시스템들은 단일 프로세서를 포함하거 나 증가된 컴퓨팅 능력(increased computing capability)을 위해 다중 프로세서 설계들을 이용(employ)하는 아 키텍처들일 수 있다. 본 개시의 일부 실시예들은 추가로 프로세서(예를 들어, 텐서 스트리밍 프로세서 또는 인공 지능 프로세서), 적 어도 하나의 컴퓨터 프로세서(예를 들어, 호스트 서버), 및 비일시적 컴퓨터 판독 가능 저장 매체를 포함하는 시스템과 관련될 수 있다. 저장 매체는 컴퓨터 실행가능 인스트럭션들을 저장할 수 있고, 이는 적어도 하나의 컴퓨터 프로세서에서 동작하는 컴파일러에 의해 실행되는 경우, 적어도 하나의 컴퓨터 프로세서로 하여금 여기 에 설명된 동작들 및 기법들을 수행하기 위해 동작 가능(operable)하게 할 수 있다. 마지막으로, 본 명세서에 사용된 언어는 주로 가독성 및 설명적 목적들(instructional purposes)을 위해 선택되 었고, 또한 발명 대상(inventive subject matter)을 기술(delineate)하거나 국한(circumscribe)하기 위해 선택 되지 않았다. 따라서 본 개시의 범위는 이러한 상세 설명에 의한 것이 아니라, 오히려 여기에 기초한 출원 (application)을 발행(issue)하는 임의의 청구항들(claims)에 의해 제한(limit)됨이 의도된다. 따라서, 실시 예들의 개시는 예시적이지, 본 개시의 범위를 제한하지 않음이 의도되고, 이는 다음의 청구항들에서 제시된다.도면 도면1a 도면1b 도면1c 도면2a 도면2b 도면2c 도면2d 도면3 도면4 도면5a 도면5b 도면6a 도면6b 도면7a 도면7b 도면8a 도면8b 도면9 도면10 도면11 도면12 도면13a 도면13b 도면13c 도면14 도면15a 도면15b 도면15c 도면16 도면17a 도면17b 도면18"}
{"patent_id": "10-2024-7031494", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면(도) 1a는 일부 실시예들에 따른, 텐서 스트리밍 프로세서(tensor streaming processor, TSP)에서의 기능 슬라이스들의 배열을 예시(illustrate)한다. 도 1b는 일부 실시예들에 따른, 예시적인(example) TSP 아키텍처를 예시한다. 도 1c는 일부 실시예들에 따른, TSP의 로우(row) 내에서의 조직 및 데이터 흐름을 예시한다. 도 2a는 일부 실시예들에 따른, 예시적인 타일 구조를 예시한다. 도 2b는 일부 실시예들에 따른, 도 2a에서의 타일 구조의 예시적인 다이를 예시한다. 도 2c는 일부 실시예들에 따른, 타일-투-타일(tile-to-tile, T2T) 브릿지를 갖는 예시적인 타일 구조를 예시한 다. 도 2d는 일부 실시예들에 따른, 고대역폭 메모리(high bandwidth memory, HBM)를 갖는 예시적인 타일 구조를 예 시한다. 도 3은 일부 실시예들에 따른, 타일 구조 내에서의 예시적인 데이터 흐름을 예시한다. 도 4는 일부 실시예들에 따른, 다양한 다수의 다이 프로세서 아키텍처들의 구현을 위한 타일 구조들의 2-디멘션 의(dimensional) 어레이들의 예들을 예시한다. 도 5a는 일부 실시예들에 따른, 타일 구조로 연결된 한 쌍의 다이들의 예를 예시한다. 도 5b는 일부 실시예들에 따른, 도 5a에서의 타일 구조의 구성을 사용하여 상호 연결된 다수의 다이들을 가진 집적 회로를 예시한다. 도 6a는 일부 실시예들에 따른, 타일 구조로 연결된 한 쌍의 다이의 또 다른 예를 예시한다. 도 6b는 일부 실시예들에 따른, 도 6a에서의 타일 구조의 구성을 사용하여 상호 연결된 다수의 다이들을 갖는 예시적인 집적 회로를 예시한다. 도 7a는 일부 실시예들에 따른, T2T 브릿지를 통해 상호 연결된 다수의 타일 구조들을 포함(comprise)하는 집적 회로의 예시적인 탑 뷰(top view) 및 바텀 뷰(bottom view)를 예시한다. 도 7b는 일부 실시예들에 따른, T2T 브릿지를 통해 상호 연결된 다수의 타일 구조들을 포함(comprise)하는 집적 회로의 또 다른 예시적인 탑뷰 및 바텀 뷰를 예시한다. 도 8a는 일부 실시예들에 따른, T2T 브릿지를 통해 상호 연결된 스택들(stacks)의 HBM들 및 타일 구조들을 포함 하는 예시적인 집적 회로를 예시한다. 도 8b는 일부 실시예들에 따른, 히트 싱크를 갖는 T2T 브릿지를 통해 상호 연결된 스택들의 HBM들 및 타일 구조 들을 포함하는 예시적인 집적 회로를 예시한다. 도 9는 일부 실시예들에 따른, 타일 구조들의 직육면체(cuboid) 구조로 구현된 예시적인 집적 회로를 예시한다. 도 10은 일부 실시예들에 따른, 하나 이상의 타일 구조들의 복수의 다이들을 가로질러 모델-병렬화로 데이터 프 로세싱을 위해 집적 회로를 사용하는 방법을 예시하는 흐름도이다. 도 11은 일부 실시예들에 따른, D2D 구성으로 연결된 두 개의 결정론적 스트리밍 프로세서들(또는 다이들)을 갖 는 예시적인 다이-투-다이(D2D) 구조를 예시한다. 도 12는 일부 실시예들에 따른, 다수의 다이들을 가로질러 확장된 슈퍼레인들을 갖는 예시적인 D2D 구조를 예시 한다. 도 13a은 일부 실시예들에 따른, D2D 구성으로 연결된 세 개의 다이들을 갖는 예시적인 D2D 구조를 예시한다. 도 13b는 일부 실시예들에 따른, D2D 폴디드 메시(folded mesh) 구성으로 연결된 다이들을 갖는 예시적인 D2D 구조를 예시한다. 도 13c는 일부 실시예들에 따른, D2D 토러스(torus) 구성으로 연결된 다이들을 갖는 예시적인 D2D 구조를 예시 한다. 도 14는 일부 실시예들에 따른, 한 쌍의 다이들 간에 슈퍼레인들의 D2D 매핑을 위한 예시적인 D2D 매핑 구조를예시한다. 도 15a는 일부 실시예들에 따른, 제1 수의 슈퍼레인들 및 D2D 인터페이스들을 갖는 예시적인 다이를 예시한다. 도 15b는 일부 실시예들에 따른, 제2 수의 슈퍼레인들 및 D2D 인터페이스들을 갖는 예시적인 다이를 예시한다. 도 15c는 일부 실시예들에 따른, 제3 수의 슈퍼레인들 및 D2D 인터페이스들을 갖는 예시적인 다이를 예시한다. 도 16은 일부 실시예들에 따른, 다이-투-다이 구조로 연결된 복수의 다이들을 가로질러 모델-병렬화로 데이터 프로세싱을 위해 집적 회로를 사용하는 방법을 예시하는 흐름도이다. 도 17a는 일부 실시예들에 따른, 상업에서의 사용을 위해 청구된 개시들의 실시예들을 가능하게 하는 데 적합한 예시적인 컴퓨터 시스템의 추상도(abstract diagram)이다. 도 17b는 일부 실시예들에 따른, 상업에서의 사용을 위해 청구된 개시들의 실시예들을 가능하게 하는 데 적합한 예시적인 컴퓨터 시스템의 또 다른 추상도이다. 도 18은 일부 실시예들에 따른, 상업에서의 사용을 위해 추가 예시적인 컴퓨팅 머신(computing machine)을 예시 한다. 도면들은 단지 예시의 목적들을 위해 본 개시의 실시예들을 묘사한다. 당업자(one skilled in the art)는 다음 의 설명으로부터 여기에 예시된 구조들 및 방법들의 대안적인 실시예들이 여기에 설명된 개시의, 논한(touted) 이익들(benefits), 또는 원리들(principles)에서 벗어나지 않고도 사용될 수 있음을 쉽게 인식할 것이다."}
