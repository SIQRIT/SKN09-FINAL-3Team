{"patent_id": "10-2023-0065577", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0168046", "출원번호": "10-2023-0065577", "발명의 명칭": "상호 작용이 가능한 혼합 현실 기반의 가상 훈련 방법 및 상기 방법을 수행하는 컴퓨팅 장치", "출원인": "한국전자통신연구원", "발명자": "이소연"}}
{"patent_id": "10-2023-0065577", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "혼합 현실 기반의 가상 훈련 시스템을 이용하여 훈련 콘텐츠를 플레이 중인 훈련자의 관측 데이터에 기초하여상기 훈련자의 자세 정보를 추정하는 단계;상기 추정된 훈련자의 자세 정보를 딥러닝 기반의 행동 인식 모델에 적용함으로써 상기 훈련자의 행동 정보를식별하는 단계;상기 훈련자의 자세 정보 및 행동 정보를 딥러닝 기반의 대응 행동 결정 모델에 적용함으로써 상기 가상 훈련시스템 내에서 상기 논플레이어 캐릭터(Non-Player Character, NPC)의 대응 행동을 결정하는 단계;상기 논플레이어 캐릭터의 대응 행동을 딥러닝 기반의 자율 모션 생성 모델에 적용함으로써 상기 논플레이어 캐릭터의 자율 모션을 생성하는 단계; 및상기 생성된 논플레이어 캐릭터의 자율 모션을 상기 훈련 콘텐츠 내에 렌더링하여 실감 가시화하는 단계를 포함하는 가상 훈련 방법."}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 혼합 현실 기반의 가상 훈련 방법 및 컴퓨팅 장치를 개시한다. 상세하게, 가상 훈련 방법은 기존의 가상 훈련 기술에 관한 한계점을 극복할 수 있는 인공 지능 기반의 논플레이 어 캐릭터를 이용한 광역 공간에서 훈련자의 반응과 상황 정보에 따라 극사실적 상호 작용이 가능한 혼합 현실 기반의 가상 훈련을 제공하기 위해 필요한 기술적 요소와 이의 연계하는 방법은 제안한다."}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상 훈련 방법에 관한 것으로, 보다 구체적으로는 크리티컬 미션(Critical Mission) 분야에 필수적 인 극한 상황의 모의와 반복학습을 수행하는 혼합 현실 기반의 가상 훈련 방법에 관한 것이다."}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "제4차 산업 혁명의 주요 키워드 중에서 하나인 융합은 여러 버티컬 산업들과 ICT(Information and Communication Technology) 기술 간의 융합을 의미한다. 버티컬 산업들과 접목된 ICT 기술은 가상 현실에서 시 작하여 혼합 현실에 이르기까지 발전되었으며, 최근에는 실제 현장에서 모의하기 어려운 상황을 가상화하여 훈 련에 적용하고자 하는 니즈를 증폭시키고 있다. 이러한, 수요는 크리티컬 미션 분야에서 강조되고 있으며, 이 는 평상시에도 실전과 같은 훈련이 필요한 군대, 위험한 화재 상황에 대처해야 하는 소방, 예측하기 어려운 재 난 재해 등에 대비할 필요가 있는 각 지자체 대응 그룹 등의 수요가 높아지고 있다. 따라서, 버티컬 산업들과 접목된 ICT 기술은 다양한 가상 훈련 시스템이 도입되어 왔으나, 여러 문제가 인식되 고 있다. 대부분의 가상 훈련 시스템은 VR 디바이스를 통해 가시화되는 시각적 콘텐츠 개발에 의존하여, 사용자 인터랙션의 제한, 다양한 상황 연출의 한계, 훈련 교관을 대체할 디지털 휴먼 기술 부재, 이동성 지원 부족 등 훈련자들이 요구하는 높은 수준의 몰입감과 현장감을 만족시키지 못하고 있다. 특히나, 훈련자의 행위에 의한 결과가 치명적인 결과를 초래할 수 있는 교전 상황과 같이 인터랙션이 주요한 경 우에는 이에 대응하는 NPC(Non-user Player Character)의 역할이 매우 중요하다. 군대의 병사를 대상으로 수행 되는 가상 훈련 시스템의 경우에 NPC는 대항군의 역할을 해야 하며, 경찰/소방훈련 시스템의 경우에는 사건 및 사고를 일으키는 사람, 또는 요구조자의 역할을 해야 한다. 그러나 대부분의 훈련자는 NPC를 실제 사람과 같이 판단하고 행동하고 의사소통 할 수 있는 존재로 기대하나, 이러한 NPC를 생성하는 기술은 현재 기술 수준으로는 불가능하다. 따라서, 기존의 가상 훈련과 관련된 기술 한계를 극복하고, 앞서 언급된 기술적 요구사항을 만족시키기 위해 주 요 분야별로 기술 발전의 깊이를 심화함과 동시에, 개별적으로 발전 및 진화하고 있는 기술들을 조합함으로써 몰입감과 현장감을 확보할 수 있는 가상 융합 기술이 요구되고 있다."}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 기존의 가상 훈련 기술에서 나타나는 한계점을 극복하기 위한 상호 작용이 가능한 혼합 현실 기반의 가상 훈련 방법을 제공한다. 본 발명은 광역 공간 내에서 훈련자의 반응 정보 및 상황 정보에 따라 상호 작용이 가능한 인공 지능 기반의 논 플레이어 캐릭터(AI NPC: Artificial Intelligence Non Player Character) 기반의 혼합 현실 기반의 가상 훈련 방법을 제공한다."}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른 가상 훈련 방법은 혼합 현실 기반의 가상 훈련 시스템을 이용하여 훈련 콘텐츠를 플 레이 중인 훈련자의 관측 데이터에 기초하여 상기 훈련자의 자세 정보를 추정하는 단계; 상기 추정된 훈련자의 자세 정보를 딥러닝 기반의 행동 인식 모델에 적용함으로써 상기 훈련자의 행동 정보를 식별하는 단계; 상기 훈 련자의 자세 정보 및 행동 정보를 딥러닝 기반의 대응 행동 결정 모델에 적용함으로써 상기 가상 훈련 시스템 내에서 상기 논플레이어 캐릭터(Non-Player Character, NPC)의 대응 행동을 결정하는 단계; 상기 논플레이어 캐 릭터의 대응 행동을 딥러닝 기반의 자율 모션 생성 모델에 적용함으로써 상기 논플레이어 캐릭터의 자율 모션을 생성하는 단계; 및 상기 생성된 논플레이어 캐릭터의 자율 모션을 상기 훈련 콘텐츠 내에 렌더링하여 실감 가시 화하는 단계를 포함할 수 있다. 상기 훈련자의 자세 정보를 추정하는 단계는 상기 훈련자의 신체에 장착된 다중 센서들을 이용하여 상기 훈련 콘텐츠를 플레이 중인 훈련자의 움직임에 따른 관측 데이터를 수집하는 단계; 상기 수집된 관측 데이터를 기반 으로 상기 훈련자의 자세를 추정하는 단계; 및 상기 추정된 훈련자의 자세에 대응하는 3D 스켈레톤(3D Skeleton)을 생성하는 단계를 포함할 수 있다. 상기 훈련자의 행동 정보를 식별하는 단계는 상기 추정된 훈련자의 자세에 대응하는 3D 스켈레톤을 상기 딥러닝 기반의 행동 인식 모델에 입력함으로써 상기 훈련자가 수행하는 행동의 종류를 구분할 수 있다. 상기 논플레이어 캐릭터의 대응 행동을 결정하는 단계는 상기 훈련자의 자세 정보 및 행동 정보를 기반으로, 상 기 훈련 공간 내에서 상기 확인된 논플레이어 캐릭터가 위치하고 있는 공간의 지형 정보, 타 에이전트의 상태 정보 및 상기 가상 훈련에 관한 상황 정보 중 적어도 하나를 이용함으로써 상기 논플레이어 캐릭터의 행동 정책 을 결정하고, 상기 결정된 논플레이어 캐릭터의 행동 정책을 딥러닝 기반의 대응 행동 결정 모델에 적용함으로 써 상기 훈련자와 상호 작용이 가능한 논플레이어 캐릭터의 대응 행동을 결정할 수 있다. 상기 논플레이어 캐릭터의 자율 모션을 생성하는 단계는 상기 논플레이어 캐릭터의 대응 행동이 적용된 자율 모 션 생성 모델에, 상기 대응 행동에 적용 가능한 행동 조건을 추가적으로 반영함으로써 상기 논플레이어 캐릭터 의 자율 모션을 생성할 수 있다. 상기 생성된 논플레이어 캐릭터의 자율 모션을 상기 훈련 콘텐츠 내에 렌더링하여 실감 가시화하는 단계는 상기 훈련 콘텐츠에서 논플레이어 캐릭터 그래픽만 추출하여 뉴럴 렌더링에 대응하는 심층학습을 적용함으로써 실제 사람과 구분하기 어려운 수준의 외형으로 변화시킬 수 있다. 상기 논플레이어 캐릭터의 자율 모션이 렌더링되어 가시화된 훈련 콘텐츠를 플레이하는 과정에서 상기 훈련자 및 논플레이어 캐릭터의 반응 정보를 수집하는 단계; 및 상기 수집된 훈련자 및 논플레이어 캐릭터의 반응 정보 를 이용하여 훈련 분석을 수행하는 단계를 더 포함할 수 있다. 본 발명의 일실시예에 따른 컴퓨팅 장치는 하나 이상의 프로세서; 및 상기 프로세서에 의해 실행되는 프로그램 을 로드(load)하거나 저장하는 메모리를 포함하되, 상기 프로그램은 혼합 현실 기반의 가상 훈련 시스템을 이용 하여 훈련 콘텐츠를 플레이 중인 훈련자의 관측 데이터에 기초하여 상기 훈련자의 자세 정보를 추정하는 동작, 상기 추정된 훈련자의 자세 정보를 딥러닝 기반의 행동 인식 모델에 적용함으로써 상기 훈련자의 행동 정보를 식별하는 동작, 상기 훈련자의 자세 정보 및 행동 정보를 딥러닝 기반의 대응 행동 결정 모델에 적용함으로써 상기 가상 훈련 시스템 내에서 상기 논플레이어 캐릭터(Non-Player Character, NPC)의 대응 행동을 결정하는 동 작, 상기 논플레이어 캐릭터의 대응 행동을 딥러닝 기반의 자율 모션 생성 모델에 적용함으로써 상기 논플레이 어 캐릭터의 자율 모션을 생성하는 동작 및 상기 생성된 논플레이어 캐릭터의 자율 모션을 상기 훈련 콘텐츠 내 에 렌더링하여 실감 가시화하는 동작을 수행하도록 하는 인스트럭션들을 포함할 수 있다. 상기 프로세서는 상기 훈련자의 신체에 장착된 다중 센서들을 이용하여 상기 훈련 콘텐츠를 플레이 중인 훈련자 의 움직임에 따른 관측 데이터를 수집하고, 상기 수집된 관측 데이터를 기반으로 추정된 상기 훈련자의 자세를 대응하는 3D 스켈레톤(3D Skeleton)을 생성하며, 상기 추정된 훈련자의 자세에 대응하는 3D 스켈레톤을 상기 딥 러닝 기반의 행동 인식 모델에 입력함으로써 상기 훈련자가 수행하는 행동의 종류를 구분할 수 있다. 상기 프로세서는 상기 훈련자의 자세 정보 및 행동 정보를 기반으로, 상기 훈련 공간 내에서 상기 확인된 논플 레이어 캐릭터가 위치하고 있는 공간의 지형 정보, 타 에이전트의 상태 정보 및 상기 가상 훈련에 관한 상황 정 보 중 적어도 하나를 이용함으로써 상기 논플레이어 캐릭터의 행동 정책을 결정하고, 상기 결정된 논플레이어 캐릭터의 행동 정책을 딥러닝 기반의 대응 행동 결정 모델에 적용함으로써 상기 훈련자와 상호 작용이 가능한 논플레이어 캐릭터의 대응 행동을 결정할 수 있다. 상기 프로세서는 상기 논플레이어 캐릭터의 대응 행동이 적용된 자율 모션 생성 모델에, 상기 대응 행동에 적용 가능한 행동 조건을 추가적으로 반영함으로써 상기 논플레이어 캐릭터의 자율 모션을 생성할 수 있다."}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일실시예에 의하면, 실제 공간과 가상 공간이 혼합된 혼합 현실 기반 콘텐츠를 플레이하는 훈련자의 반응 정보 및 상황 정보에 따라 인공 지능 기반 논플레이어 캐릭터의 대응 정책과 모션 방식을 생성함으로써, 극사실적인 상호 작용이 가능한 혼합 현실 기반 가상 훈련을 수행할 수 있다. 본 발명의 일실시예에 의하면, 극사실적인 상호 작용이 가능한 혼합 현실 기반 가상 훈련을 통해 국방, 치안, 소방 등 훈련자의 현장 대응력에 따라 파급력이 달라질 수 있는 분야에서 가상 훈련의 효과를 높이는데 기여할 수 있다."}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명의 일실시예에 따른 컴퓨팅 장치의 구성도를 도시한 도면이다. 도 1에 도시된 바와 같이, 컴퓨팅 장치는 하나 이상의 프로세서, 프로세서에 의하여 수행되는 프로그램을 로드(load)하거나 저장하는 메모리를 포함할 수 있다. 도 1의 컴퓨팅 장치에 포함된"}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "구성 요소는 일례에 불과하고, 본 발명이 속한 기술분야의 통상의 기술자라면 도 1에 도시된 구성 요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit), DSP(Digital Signal Processor) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또한, 프로세서는 본 발명의 다양한 실시예 들에 따른 방법/동작을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있 다. 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 컴퓨팅 장치에 포함된 구성요소(예: 프로세서)에 의해 사용되는 다양한 데이터, 명령 및 정보 중 하나 또는 둘 이상의 조합을 저장한다. 메모리는 휘발성 메모리 및/또는 비휘발성 메모리를 포 함할 수 있다. 프로그램은 본 발명의 다양한 실시예들에 따른 방법/동작들이 구현된 하나 이상의 동작(action)들을 포함 할 수 있으며, 메모리에 소프트웨어 형태로 저장될 수 있다. 여기서, 동작은 프로그램에서 실현되는 명령어에 대응한다. 예를 들어, 프로그램은 혼합 현실 기반의 가상 훈련을 위한 훈련 콘텐츠를 플레이 중인 훈련자의 관측 데이터에 기초하여 상기 훈련자의 자세 정보를 추정하는 동작, 상기 추정된 훈련자의 자세 정 보를 딥러닝 기반의 행동 인식 모델에 적용함으로써 상기 훈련자의 행동 정보를 식별하는 동작, 상기 훈련자의 자세 정보 및 행동 정보를 딥러닝 기반의 대응 행동 결정 모델에 적용함으로써 상기 훈련 콘텐츠 내에서 상기 논플레이어 캐릭터(Non-Player Character, NPC)의 대응 행동을 결정하는 동작, 상기 논플레이어 캐릭터의 대응 행동을 딥러닝 기반의 자율 모션 생성 모델에 적용함으로써 상기 논플레이어 캐릭터의 자율 모션을 생성하는 동 작 및 상기 생성된 논플레이어 캐릭터의 자율 모션을 상기 훈련 콘텐츠 내에 렌더링하여 가시화하는 동작을 수 행하도록 하는 인스트럭션들을 포함할 수 있다. 프로그램이 메모리에 로드 되면, 프로세서는 프로그램을 구현하기 위한 복수의 동작들을 실행시킴으로써 본 발명의 다양한 실시예들에 따른 방법/동작들을 수행할 수 있다. 프로그램의 실행 화면은 디스플레이을 통해 표시될 수 있다. 도 1의 경우, 디스플레이는 컴퓨 팅 장치와 연결되는 별도의 장치로 표현되나, 스마트폰, 태블릿 등 사용자가 휴대할 수 있는 단말기와 같 은 컴퓨팅 장치의 경우 디스플레이가 컴퓨팅 장치의 구성 요소로 될 수 있다. 디스플레이(14 0)에 표현되는 화면은 프로그램에 정보를 입력하기 전이나 프로그램의 실행 결과일 수 있다. 도 2는 본 발명의 일실시예에 따른 훈련 콘텐츠의 공간을 구성하기 위해 동적 장면 그래프를 생성하는 과정을 설명하기 위해 도시한 도면이다. 도 2를 참고하면, 컴퓨팅 장치의 프로세서는 혼합 현실 기반의 가상 훈련이 이루어지는 가상의 훈련 공간을 구축할 수 있다. 보다 구체적으로 프로세서는 기존의 가상 현실과는 달리 실제 공간을 대상으로 가 상 공간에 대응하는 훈련 콘텐츠를 접목시키는 혼합 현실 방식으로 훈련 공간을 구현할 수 있다. 여기서, 훈련 콘텐츠는 객체, 이벤트, 캐릭터 표현 등을 포함할 수 있으나 이는 하나의 예시일 뿐 상기의 예에 한정되지 않는 다. 혼합 현실을 구성하는 실제 공간과 가상 공간이 이질감 없이 서로 연동하기 위해서는 실제 공간에서 이루어진 변화가 즉각적으로 가상 공간에도 적용되어야 한다. 일례로, 실제 공간에서 문이 열린다거나, 의자 움직임 등 의 이벤트가 발생하면, 프로세서는 발생된 이벤트를 즉각적으로 혼합 현실 기반의 훈련 공간에도 동일하게 반영하여야 한다. 이를 위해, 프로세서는 훈련자의 훈련이 실제로 이루어지는 훈련 공간을 스캔 장치를 이용하여 스캔 할 수 있다. 프로세서는 이러한 스캔을 통해 훈련 공간에 대한 디지털 트윈화를 수행함으로써 훈련 공간 을 구성하는 요소들에 대한 데이터 베이스를 구성할 수 있다. 여기서, 스캔 장치는 휴대형 스캔 장치, 로 봇형 스캔 장치 또는 드론형 스캔 장치 등 다양한 형태의 스캔 장치들을 포함할 수 있으며, 프로세서는 다 양한 형태의 스캔 장치들 중 훈련 공간의 특성에 따라 하나 이상의 스캔 장치를 선택하여 훈련 공간에 대한 스 캔을 수행할 수 있다. 보다 구체적으로 프로세서는 단계(S1)와 같이, 스캔 장치를 통해 훈련 공간에 대한 관측 데이터를 수 집할 수 있다. 이때, 수집되는 관측 데이터는 훈련 공간에 대한 RGB 영상 또는 깊이 정보 등이 포함될 수 있다. 프로세서는 단계(S2)와 같이, 수집된 관측 데이터를 기반으로 훈련 공간에 대한 구조물 및 객체들에 대해 3D 모델을 생성할 수 있으며, 단계(S3)와 같이 생성된 3D 모델을 기반으로 구조물 및 객체들에 대한 위치 및 상 태를 식별하여 훈련 공간에 대응하는 동적 장면 그래프를 생성할 수 있다. 도 3은 본 발명의 일실시예에 따른 훈련자와 논플레이어 캐릭터 간의 상호 작용에 따른 가상 훈련 방법을 설명 하기 위해 도시한 도면이다. 도 3을 참고하면, 게임 형태의 훈련 콘텐츠를 통해 가상 훈련이 진행되는 경우, 컴퓨팅 장치의 프로세서 는 훈련자의 신체에 부착된 복수의 센서들을 통해 입력되는 데이터를 이용하여 훈련자의 상태를 인식하고, 인식된 훈련자의 상태에 대응하여 결정된 논플레이어 캐릭터의 반응에 기반하여 극사실적인 상호 작용이 가능한 혼합 현실 기반의 가상 훈련을 제공할 수 있다. 보다 자세하게, 프로세서는 훈련자의 신체에 장착된 스캔 장치를 통해 관측 데이터를 수집할 수 있다. 이때, 관측 데이터는 훈련자가 착용한 VR 디바이스를 통해 재생되는 훈련 콘텐츠를 플레이하는 훈련자의 실제 공간에서의 움직임을 나타낼 수 있다. 프로세서는 관측 데이터를 기반으로 게임 형태의 훈련 콘텐츠를 통해 플레이 중인 훈련자의 자세 정보를 추정할 수 있다. 보다 구체적으로 프로세서는 훈련자의 신체에 장착된 스캔 장치, 즉, 복수의 모션 센서들을 이용하여 수집된 훈련 콘텐츠를 플레이 중인 훈련자의 움직임에 따른 관측 데이터를 기반으로 훈 련자의 자세를 추정하고, 추정된 훈련자의 자세에 대응하는 3D 스켈레톤(3D Skeleton)을 생성할 수 있다. 프로세서는 추정된 훈련자의 자세 정보를 딥러닝 기반의 행동 인식 모델에 적용함으로써 훈련자의 행동 정 보를 식별할 수 있다. 보다 구체적으로 프로세서는 추정된 훈련자의 자세에 대응하는 3D 스켈레톤을 다양한 딥러닝 기반의 행동 인식 모델에 입력함으로써 훈련자가 수행하는 행동의 종류를 구분할 수 있다. 이와 같은 훈련자의 자세 정보 및 행동 정보는 실제/가상 공간 동기화부로 전달되어 훈련 콘텐츠 내에 저 장될 수 있으며, 이를 기반으로 논플레이어 캐릭터의 행동 정책에 대한 탐색이 수행될 수 있다. 여기서, 논플레이어 캐릭터의 행동 정책에 대한 탐색은 훈련자의 자세 정보 및 행동 정보를 기반으로, 훈련 공간 내에서 확인된 논플레이어 캐릭터가 위치하고 있는 공간의 지형 정보, 타 에이전트의 상태 정보 및 가상 훈련에 관한 상황 정보 중 적어도 하나의 추가 정보를 이용함으로 결정될 수 있다. 논플레이어 캐릭터(NPC)의 행동 정책이 도출되면, 프로세서는 결정된 논플레이어 캐릭터의 행동 정책을 딥 러닝 기반의 대응 행동 결정 모델에 적용함으로써 훈련자와 상호 작용이 가능한 논플레이어 캐릭터의 대응 행동 을 결정할 수 있다. 즉, 프로세서는 논플레이어 캐릭터의 대응 행동, 즉 논플레이어 캐릭터가 어떤 행동을 어떻게 할 지를 결정할 수 있다. 이후 프로세서는 논플레이어 캐릭터의 대응 행동을 딥러닝 기반의 자율 모션 생성 모델에 적용함으로써 논 플레이어 캐릭터의 자율 모션을 생성할 수 있다. 이때, 프로세서는 논플레이어 캐릭터의 대응 행동이 적용된 자율 모션 생성 모델에, 해당 대응 행동에 적용 가능한 행동 조건을 추가적으로 반영함으로써 해 당 대응 행동에 보다 적합한 논플레이어 캐릭터의 자율 모션을 생성할 수 있다. 논플레이어 캐릭터의 자율 모션이 생성되면, 프로세서는 생성된 논플레이어 캐릭터의 자율 모션을 훈련 콘 텐츠 내에 렌더링할 수 있다. 이때, 프로세서는 논플레이어 캐릭터의 자율 모션 종류에 따라, 신체적 제약 조건이나 부자연스러움을 최소화하기 위해 모션 정제를 수행할 수 있다. 컴퓨터 그래픽으로 표현된 논플레이어 캐릭터의 렌더링 결과가 애니메이션 캐릭터와 같이 인위적이면 사실감이 낮아진 경우, 심층 학습을 통해 품질을 향상시킬 수 있다. 따라서, 프로세서는 품질이 낮은 논플레이어 캐릭터의 렌더링 결과를 딥러닝 기반의 실감 가시화 모델에 적용함으로써 논플레이어 캐릭터를 실감나게 가시화할 수 있다. 보다 구체적으로 프로세서는 유니티, 언리얼과 같은 게임 엔진으로 만들어진 훈련 콘텐츠 내의 논플레이어 캐릭터에 뉴럴 렌더링 방법을 적용함으로 써 사람의 눈으로 분간하기 어려울 정도로 실사와 같은 결과물로 생성할 수 있다. 프로세서는 실제/가상 공간 동기화부를 통해 훈련자와 논플레이어 캐릭터를 연동하여 훈련 콘텐츠의 훈련 공간 내에서 동기화할 수 있다. 이를 위해 프로세서는 훈련자의 관측 데이터에 포함된 영상 정보 (RGB) 및 깊이 영상(Depth)을 기반으로 훈련자의 주변에 위치하는 객체를 식별 및 추적하는 기능을 수행할 수 있다. 이와 같은 객체의 식별 및 추적 기능을 기반으로, 프로세서는 실시간으로 3차원 동적 장면 그래프를 구축 하고, 갱신함으로써 혼합 현실 기반의 훈련 콘텐츠를 생성할 수 있다. 이와 같이 생성된 훈련 콘텐츠는 훈련자가 장착하고 있는 HMD(Head Mounted Display) 또는 글래스 타입의 디스 플레이에 가시화됨과 동시에 훈련자의 햅틱 반응을 생성할 수 있다. 가상 훈련이 진행되는 동안 발생되는 훈련 결과 데이터인 훈련자 및 논플레이어 캐릭터의 반응 정보는 데이터 베이스화되어 저장될 수 있으며, 프로세서는 저장된 훈련자 및 논플레이어 캐릭터의 반응 정보를 전 문적인 훈련 분석을 위한 기본 데이터로 활용할 수 있다. 한편, 본 발명에 따른 방법은 컴퓨터에서 실행될 수 있는 프로그램으로 작성되어 마그네틱 저장매체, 광학적 판 독매체, 디지털 저장매체 등 다양한 기록 매체로도 구현될 수 있다.본 명세서에 설명된 각종 기술들의 구현들은 디지털 전자 회로조직으로, 또는 컴퓨터 하드웨어, 펌웨어, 소프트 웨어로, 또는 그들의 조합들로 구현될 수 있다. 구현들은 데이터 처리 장치, 예를 들어 프로그램가능 프로세서, 컴퓨터, 또는 다수의 컴퓨터들의 동작에 의한 처리를 위해, 또는 이 동작을 제어하기 위해, 컴퓨터 프로그램 제 품, 즉 정보 캐리어, 예를 들어 기계 판독가능 저장 장치(컴퓨터 판독가능 매체) 또는 전파 신호에서 유형적으 로 구체화된 컴퓨터 프로그램으로서 구현될 수 있다. 상술한 컴퓨터 프로그램(들)과 같은 컴퓨터 프로그램은 컴 파일된 또는 인터프리트된 언어들을 포함하는 임의의 형태의 프로그래밍 언어로 기록될 수 있고, 독립형 프로그 램으로서 또는 모듈, 구성요소, 서브루틴, 또는 컴퓨팅 환경에서의 사용에 적절한 다른 유닛으로서 포함하는 임 의의 형태로 전개될 수 있다. 컴퓨터 프로그램은 하나의 사이트에서 하나의 컴퓨터 또는 다수의 컴퓨터들 상에 서 처리되도록 또는 다수의 사이트들에 걸쳐 분배되고 통신 네트워크에 의해 상호 연결되도록 전개될 수 있다. 컴퓨터 프로그램의 처리에 적절한 프로세서들은 예로서, 범용 및 특수 목적 마이크로프로세서들 둘 다, 및 임의 의 종류의 디지털 컴퓨터의 임의의 하나 이상의 프로세서들을 포함한다. 일반적으로, 프로세서는 판독 전용 메 모리 또는 랜덤 액세스 메모리 또는 둘 다로부터 명령어들 및 데이터를 수신할 것이다. 컴퓨터의 요소들은 명령 어들을 실행하는 적어도 하나의 프로세서 및 명령어들 및 데이터를 저장하는 하나 이상의 메모리 장치들을 포함 할 수 있다. 일반적으로, 컴퓨터는 데이터를 저장하는 하나 이상의 대량 저장 장치들, 예를 들어 자기, 자기-광 디스크들, 또는 광 디스크들을 포함할 수 있거나, 이것들로부터 데이터를 수신하거나 이것들에 데이터를 송신하 거나 또는 양쪽으로 되도록 결합될 수도 있다. 컴퓨터 프로그램 명령어들 및 데이터를 구체화하는데 적절한 정 보 캐리어들은 예로서 반도체 메모리 장치들, 예를 들어, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD-ROM(Compact Disk Read Only Memory), DVD(Digital Video Disk)와 같은 광 기 록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체(Magneto-Optical Media), 롬 (ROM, Read Only Memory), 램(RAM, Random Access Memory), 플래시 메모리, EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM) 등을 포함한다. 프로세서 및 메모리는 특수 목적 논리 회로조직에 의해 보충되거나, 이에 포함될 수 있다. 또한, 컴퓨터 판독가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용매체일 수 있고, 컴퓨터 저장매체 및 전송매체를 모두 포함할 수 있다. 본 명세서는 다수의 특정한 구현물의 세부사항들을 포함하지만, 이들은 어떠한 발명이나 청구 가능한 것의 범위 에 대해서도 제한적인 것으로서 이해되어서는 안되며, 오히려 특정한 발명의 특정한 실시형태에 특유할 수 있는 특징들에 대한 설명으로서 이해되어야 한다. 개별적인 실시형태의 문맥에서 본 명세서에 기술된 특정한 특징들 은 단일 실시형태에서 조합하여 구현될 수도 있다. 반대로, 단일 실시형태의 문맥에서 기술한 다양한 특징들 역 시 개별적으로 혹은 어떠한 적절한 하위 조합으로도 복수의 실시형태에서 구현 가능하다. 나아가, 특징들이 특 정한 조합으로 동작하고 초기에 그와 같이 청구된 바와 같이 묘사될 수 있지만, 청구된 조합으로부터의 하나 이 상의 특징들은 일부 경우에 그 조합으로부터 배제될 수 있으며, 그 청구된 조합은 하위 조합이나 하위 조합의 변형물로 변경될 수 있다. 마찬가지로, 특정한 순서로 도면에서 동작들을 묘사하고 있지만, 이는 바람직한 결과를 얻기 위하여 도시된 그 특정한 순서나 순차적인 순서대로 그러한 동작들을 수행하여야 한다거나 모든 도시된 동작들이 수행되어야 하는 것으로 이해되어서는 안 된다. 특정한 경우, 멀티태스킹과 병렬 프로세싱이 유리할 수 있다. 또한, 상술한 실시 형태의 다양한 장치 컴포넌트의 분리는 그러한 분리를 모든 실시형태에서 요구하는 것으로 이해되어서는 안되며, 설명한 프로그램 컴포넌트와 장치들은 일반적으로 단일의 소프트웨어 제품으로 함께 통합되거나 다중 소프트웨어 제품에 패키징 될 수 있다는 점을 이해하여야 한다. 한편, 본 명세서와 도면에 개시된 본 발명의 실시 예들은 이해를 돕기 위해 특정 예를 제시한 것에 지나지 않으 며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 여기에 개시된 실시 예들 이외에도 본 발명의 기술적 사상"}
{"patent_id": "10-2023-0065577", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자 에게 자명한 것이다."}
{"patent_id": "10-2023-0065577", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 상호 작용이 가능한 혼합 현실의 가상 훈련을 수행하는 전반적인 동작을 설 명하기 위해 도시한 도면이다. 도 2는 본 발명의 일실시예에 따른 훈련 콘텐츠의 공간을 구성하기 위해 동작 장면 그래프를 생성하는 과정을 설명하기 위해 도시한 도면이다. 도 3은 본 발명의 일실시예에 따른 훈련자와 논플레이어 캐릭터 간의 상호 작용에 따른 가상 훈련을 학습하는 과정을 설명하기 위해 도시한 도면이다."}
