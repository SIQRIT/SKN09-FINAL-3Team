{"patent_id": "10-2024-0117069", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0137507", "출원번호": "10-2024-0117069", "발명의 명칭": "음성 인식 방법, 딥러닝 모델의 트레이닝 방법, 장치 및 기기", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "푸 샤오인"}}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 인식 방법으로서,인식할 음성의 제1 음성 특징을 획득하되, 상기 제1 음성 특징은 상기 인식할 음성 중의 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 단계;제1 디코더를 이용하여 상기 제1 음성 특징을 디코딩하여 상기 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하되, 상기 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계;제1 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하되, 상기 제1 선험적 정보는상기 복수의 제1 디코딩 결과를 포함하고, 상기 제2 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 단어레벨 오디오 특징을 포함하는 단계; 및제2 디코더를 이용하여 상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하되, 상기 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계를 포함하는 음성 인식방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,제1 선험적 정보에 기반하여 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계는,상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 주의력 모듈의 조회 특징으로사용하고, 상기 제1 음성 특징을 상기 주의력 모듈의 키 특징 및 값 특징으로 사용하여, 상기 주의력 모듈에 의해 출력되는 상기 단어에 대응되는 제1 단어 레벨 오디오 특징을 획득하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,제1 선험적 정보에 기반하여 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계는,제2 인코더를 이용하여 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩을 수행하여 강화된 제2 음성 특징을 획득하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,제2 디코더를 이용하여 상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하는 단계는,상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에의해 출력되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함하고, 상기 순방향 디코더 및 상기 역방향 디코더는모두 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징으로 사용하고, 상기 제2 음성 특징을 입력된 키 특징 및 값 특징으로 사용하도록 구성되며, 상기 순방향 디코더는 입력된 특징을왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성되고, 상기 역방향 디코더는 입력된 특징을 오른쪽에서 왼쪽공개특허 10-2024-0137507-3-으로 시간적으로 마스킹하도록 구성되는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계는,상기 순방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 순방향 디코딩 특징 및 상기 역방향디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 상기 복수의 단어에 대응되는 복수의 융합 특징을 획득하는 단계; 및상기 복수의 융합 특징에 기반하여, 상기 복수의 제2 디코딩 결과를 획득하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제N 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제N+1 디코딩 결과를 획득하되, N은 2보다 크거나 같은 정수인 단계를 더 포함하는음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,제2 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제3 음성 특징을 추출하되, 상기 제2 선험적 정보는상기 복수의 제2 디코딩 결과를 포함하고, 상기 제3 음성 특징은 상기 복수의 단어에 대응되는 복수의 제2 단어레벨 오디오 특징을 포함하는 단계; 및상기 제2 디코더를 이용하여 상기 제3 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제3 디코딩결과를 획득하되, 상기 제3 디코딩 결과는 대응하는 단어의 제3 인식 결과를 지시하는 단계를 더 포함하는 음성인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,인식할 음성의 제1 음성 특징을 획득하는 단계는,상기 인식할 음성의 원래 음성 특징을 획득하는 단계;상기 원래 음성 특징에 기반하여 상기 인식할 음성 중의 복수의 스파이크를 결정하는 단계; 및상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을획득하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 복수의 음성 세그먼트 특징은 상기 원래 음성 특징에 대한 스트리밍 절단에 의해 순차적으로 획득된 것이고, 제1 디코더를 이용하여 상기 제1 음성 특징을 디코딩하는 단계는,상기 제1 디코더를 이용하여 상기 복수의 음성 세그먼트 특징에 대해 순차적으로 스트리밍 디코딩을 수행하는단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,공개특허 10-2024-0137507-4-인식할 음성의 제1 음성 특징을 획득하는 단계는,현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하되, 상기 이력 특징 추상 정보는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 상기 이전 음성 세그먼트 특징에 대해 주의력 모델링을 수행함으로써 획득된 것인 단계; 및제1 인코더를 이용하고 상기 이력 특징 추상 정보를 결합하여 상기 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,제1 인코더를 이용하고 상기 이력 특징 추상 정보를 결합하여 상기 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계는,상기 현재 획득된 음성 세그먼트 특징을 상기 제1 인코더의 조회 특징으로 사용하고, 상기 이력 특징 추상 정보와 상기 현재 획득된 음성 세그먼트 특징의 스플라이싱 결과를 상기 제1 인코더의 키 특징 및 값 특징으로 사용하여, 상기 제1 인코더에 의해 출력되는 상기 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계를 포함하는음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을획득하는 단계는,기설정된 시간 길이를 기반으로 상기 원래 음성 특징을 절단하고, 상기 복수의 스파이크 중 각 스파이크가 위치하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을획득하는 단계는,상기 복수의 스파이크를 기반으로 상기 원래 음성 특징을 절단하고, 인접한 2개의 스파이크 사이마다의 음성 세그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 제2 디코더는 음성 빅모델인 음성 인식 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법으로서,상기 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 상기 트레이닝 방법은,샘플 음성 및 상기 샘플 음성 중의 복수의 단어의 실제 인식 결과를 획득하는 단계;상기 샘플 음성의 제1 샘플 음성 특징을 획득하되, 상기 제1 샘플 음성 특징은 상기 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하는 단계;제1 디코더를 이용하여 상기 제1 샘플 음성 특징을 디코딩하여 상기 샘플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩 결과를 획득하되, 상기 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하공개특허 10-2024-0137507-5-는 단계;제1 샘플 선험적 정보에 기반하여 상기 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하되, 상기 제1샘플 선험적 정보는 상기 복수의 제1 샘플 디코딩 결과를 포함하고, 상기 제2 샘플 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단계;제2 디코더를 이용하여 상기 제2 샘플 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 샘플디코딩 결과를 획득하되, 상기 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계; 및상기 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 상기 딥러닝 모델의 파라미터를 조정하여 트레이닝된 딥러닝 모델을 획득하는 단계를 포함하는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "음성 인식 장치로서,인식할 음성의 제1 음성 특징을 획득하도록 구성되되, 상기 제1 음성 특징은 상기 인식할 음성 중의 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈;상기 제1 음성 특징을 디코딩하여 상기 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하도록 구성되되, 상기 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더;제1 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하도록 구성되되, 상기 제1 선험적 정보는 상기 복수의 제1 디코딩 결과를 포함하고, 상기 제2 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모듈; 및상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하도록구성되되, 상기 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더를 포함하는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 단어 레벨 특징 추출 모듈은 주의력 모듈을 포함하고,상기 주의력 모듈은 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 주의력 모듈의 조회 특징으로서 수신하고, 상기 제1 음성 특징을 상기 주의력 모듈의 키 특징 및 값 특징으로서 수신하여, 상기 단어에 대응되는 제1 단어 레벨 오디오 특징으로 출력하도록 구성되는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 단어 레벨 특징 추출 모듈은,상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩을 수행하여, 강화된 제2음성 특징을 획득하도록 구성되는 제2 인코더를 포함하는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항 내지 제19항 중 어느 한 항에 있어서,상기 제2 디코더는 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으로서 수신하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로서 수신하여, 상기 단어에 대응되는 제2 디코딩 결과를 출력하도록 구성되는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함하고, 상기 순방향 디코더 및 상기 역방향 디코더는공개특허 10-2024-0137507-6-모두 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징으로서 수신하고,상기 제2 음성 특징을 입력된 키 특징 및 값 특징으로서 수신하도록 구성되며, 상기 순방향 디코더는 입력된 특징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성되고, 상기 역방향 디코더는 입력된 특징을 오른쪽에서왼쪽으로 시간적으로 마스킹하도록 구성되는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 제2 디코더는,상기 순방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 순방향 디코딩 특징 및 상기 역방향디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 상기 복수의 단어에 대응되는 복수의 융합 특징을 획득하고;상기 복수의 융합 특징에 기반하여, 상기 복수의 제2 디코딩 결과를 획득하도록 구성되는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20항에 있어서,상기 제2 디코더는,상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제N 디코딩 결과를 상기 제2 디코더의 조회 특징으로서 수신하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로서 수신하여, 상기 단어에 대응되는 제N+1 디코딩 결과를 출력하도록 구성되되, N은 2보다 크거나 같은 정수인 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제17항 내지 제19항 중 어느 한 항에 있어서,상기 단어 레벨 특징 추출 모듈은 제2 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제3 음성 특징을추출하도록 구성되되, 상기 제2 선험적 정보는 상기 복수의 제2 디코딩 결과를 포함하고, 상기 제3 음성 특징은상기 복수의 단어에 대응되는 복수의 제2 단어 레벨 오디오 특징을 포함하며,상기 제2 디코더는 상기 제3 음성 특징을 디코딩하여, 상기 복수의 단어에 대응되는 복수의 제3 디코딩 결과를획득하도록 구성되되, 상기 제3 디코딩 결과는 대응하는 단어의 제3 인식 결과를 지시하는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제17항 내지 제19항 중 어느 한 항에 있어서,상기 음성 특징 인코딩 모듈은,상기 인식할 음성의 원래 음성 특징을 획득하고; 상기 원래 음성 특징에 기반하여 상기 인식할 음성 중의 복수의 스파이크를 결정하며;상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을획득하도록 구성되는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서,상기 복수의 음성 세그먼트 특징은 상기 원래 음성 특징에 대한 스트리밍 절단에 의해 순차적으로 획득된 것이고, 상기 제1 디코더는 상기 복수의 음성 세그먼트 특징에 대해 순차적으로 스트리밍 디코딩을 수행하도록 구성되는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서,공개특허 10-2024-0137507-7-상기 음성 특징 인코딩 모듈은,현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하도록 구성되되, 상기 이력 특징 추상 정보는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 상기 이전 음성 세그먼트 특징에 대해 주의력 모델링을 수행함으로써 획득된 것이고;상기 음성 특징 인코딩 모듈은,상기 이력 특징 추상 정보를 결합하여 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 출력하도록 구성되는 제1 인코더를 포함하는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서,상기 제1 인코더는 상기 현재 획득된 음성 세그먼트 특징을 상기 제1 인코더의 조회 특징으로서 수신하고, 상기이력 특징 추상 정보와 상기 현재 획득된 음성 세그먼트 특징의 스플라이싱 결과를 상기 제1 인코더의 키 특징및 값 특징으로서 수신하여 상기 대응하는 강화된 음성 세그먼트 특징을 출력하도록 구성되는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제25항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을획득하는 단계는,기설정된 시간 길이를 기반으로 상기 원래 음성 특징을 절단하고, 상기 복수의 스파이크 중 각 스파이크가 위치하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제25항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을획득하는 단계는,상기 복수의 스파이크를 기반으로 상기 원래 음성 특징을 절단하고, 인접한 2개의 스파이크 사이마다의 음성 세그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제17항 내지 제19항 중 어느 한 항에 있어서,상기 제2 디코더는 음성 빅모델인 음성 인식 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치로서,상기 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 상기 트레이닝 장치는,샘플 음성 및 상기 샘플 음성 중의 복수의 단어의 실제 인식 결과를 획득하도록 구성되는 획득 모듈; 상기 샘플 음성의 제1 샘플 음성 특징을 획득하도록 구성되되, 상기 제1 샘플 음성 특징은 상기 샘플 음성 중의복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈; 상기 제1 샘플 음성 특징을 디코딩하여 상기 샘플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩결과를 획득하도록 구성되되, 상기 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더; 제1 샘플 선험적 정보에 기반하여 상기 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하도록공개특허 10-2024-0137507-8-구성되되, 상기 제1 샘플 선험적 정보는 상기 복수의 제1 샘플 디코딩 결과를 포함하고, 상기 제2 샘플 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모듈; 상기 제2 샘플 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 샘플 디코딩 결과를 획득하도록 구성되되, 상기 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더; 및상기 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 상기 딥러닝 모델의 파라미터를 조정하여 트레이닝된 딥러닝 모델을 획득하도록 구성되는 파라미터 조정 모듈을 포함하는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "전자 기기로서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되;상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적어도하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 제1항 내지 제16항 중 어느 한 항에 따른 방법을 수행할 수 있도록 하는 전자 기기."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제16항 중 어느 한 항에 따른 방법을 수행하도록 하기 위한 것인비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-0117069", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은 명령을 포함하고, 상기 명령이 적어도 하나의 프로세서에 의해 실행될 경우 제1항 내지제16항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램."}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능"}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로, 특히 음성 인식 및 딥러닝 등 기술분야에 관한 음성 인식 방법, 딥 러닝 모델의 트레이닝 방법, 장치 및 기기를 제공한다. 상기 음성 인식 방법은 인식할 음성의 제1 음성 특징을 획득하되, 제1 음성 특징은 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 단계; 제1 (뒷면에 계속) 대 표 도 - 도2"}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2024-0137507 디코더를 이용하여 제1 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하되, 제 1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계; 제1 선험적 정보에 기반하여, 제1 음성 특징 으로부터 제2 음성 특징을 추출하되, 제1 선험적 정보는 복수의 제1 디코딩 결과를 포함하고, 제2 음성 특징은 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단계; 및 제2 디코더를 이용하여 제2 음 성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하되, 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계를 포함한다. CPC특허분류 G10L 17/04 (2013.01) G10L 19/0018 (2013.01) G10L 19/008 (2020.08) 발명자 성 펀펀 중국 100085 베이징 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층 왕 하이펑 중국 100085 베이징 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층자 레이 중국 100085 베이징 하이디안 디스트릭트 샹디 10 번가 넘버 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 음성 인식 방법으로서, 인식할 음성의 제1 음성 특징을 획득하되, 상기 제1 음성 특징은 상기 인식할 음성 중의 복수의 음성 세그먼트 에 대응되는 복수의 음성 세그먼트 특징을 포함하는 단계; 제1 디코더를 이용하여 상기 제1 음성 특징을 디코딩하여 상기 인식할 음성 중의 복수의 단어에 대응되는 복수 의 제1 디코딩 결과를 획득하되, 상기 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계; 제1 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하되, 상기 제1 선험적 정보는 상기 복수의 제1 디코딩 결과를 포함하고, 상기 제2 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단계; 및 제2 디코더를 이용하여 상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과 를 획득하되, 상기 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계를 포함하는 음성 인식 방법. 청구항 2 제1항에 있어서, 제1 선험적 정보에 기반하여 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계는, 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 주의력 모듈의 조회 특징으로 사용하고, 상기 제1 음성 특징을 상기 주의력 모듈의 키 특징 및 값 특징으로 사용하여, 상기 주의력 모듈에 의 해 출력되는 상기 단어에 대응되는 제1 단어 레벨 오디오 특징을 획득하는 단계를 포함하는 음성 인식 방법. 청구항 3 제2항에 있어서, 제1 선험적 정보에 기반하여 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계는, 제2 인코더를 이용하여 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩 을 수행하여 강화된 제2 음성 특징을 획득하는 단계를 포함하는 음성 인식 방법. 청구항 4 제1항 내지 제3항 중 어느 한 항에 있어서, 제2 디코더를 이용하여 상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과 를 획득하는 단계는, 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으 로 사용하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계를 포함하는 음성 인식 방법. 청구항 5 제4항에 있어서, 상기 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함하고, 상기 순방향 디코더 및 상기 역방향 디코더는 모두 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징으로 사용하고, 상 기 제2 음성 특징을 입력된 키 특징 및 값 특징으로 사용하도록 구성되며, 상기 순방향 디코더는 입력된 특징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성되고, 상기 역방향 디코더는 입력된 특징을 오른쪽에서 왼쪽으로 시간적으로 마스킹하도록 구성되는 음성 인식 방법. 청구항 6 제5항에 있어서, 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하 고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력 되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계는, 상기 순방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 순방향 디코딩 특징 및 상기 역방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 상기 복수의 단어 에 대응되는 복수의 융합 특징을 획득하는 단계; 및 상기 복수의 융합 특징에 기반하여, 상기 복수의 제2 디코딩 결과를 획득하는 단계를 포함하는 음성 인식 방법. 청구항 7 제4항에 있어서, 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제N 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하 고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력 되는 상기 단어에 대응되는 제N+1 디코딩 결과를 획득하되, N은 2보다 크거나 같은 정수인 단계를 더 포함하는 음성 인식 방법. 청구항 8 제1항 내지 제3항 중 어느 한 항에 있어서, 제2 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제3 음성 특징을 추출하되, 상기 제2 선험적 정보는 상기 복수의 제2 디코딩 결과를 포함하고, 상기 제3 음성 특징은 상기 복수의 단어에 대응되는 복수의 제2 단어 레벨 오디오 특징을 포함하는 단계; 및 상기 제2 디코더를 이용하여 상기 제3 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제3 디코딩 결과를 획득하되, 상기 제3 디코딩 결과는 대응하는 단어의 제3 인식 결과를 지시하는 단계를 더 포함하는 음성 인식 방법. 청구항 9 제1항 내지 제3항 중 어느 한 항에 있어서, 인식할 음성의 제1 음성 특징을 획득하는 단계는, 상기 인식할 음성의 원래 음성 특징을 획득하는 단계; 상기 원래 음성 특징에 기반하여 상기 인식할 음성 중의 복수의 스파이크를 결정하는 단계; 및 상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계를 포함하는 음성 인식 방법. 청구항 10 제9항에 있어서, 상기 복수의 음성 세그먼트 특징은 상기 원래 음성 특징에 대한 스트리밍 절단에 의해 순차적으로 획득된 것이 고, 제1 디코더를 이용하여 상기 제1 음성 특징을 디코딩하는 단계는, 상기 제1 디코더를 이용하여 상기 복수의 음성 세그먼트 특징에 대해 순차적으로 스트리밍 디코딩을 수행하는 단계를 포함하는 음성 인식 방법. 청구항 11 제10항에 있어서,인식할 음성의 제1 음성 특징을 획득하는 단계는, 현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하되, 상기 이력 특징 추상 정보 는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 상기 이전 음성 세그먼트 특징에 대해 주 의력 모델링을 수행함으로써 획득된 것인 단계; 및 제1 인코더를 이용하고 상기 이력 특징 추상 정보를 결합하여 상기 현재 획득된 음성 세그먼트 특징을 인코딩하 여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계를 포함하는 음성 인식 방법. 청구항 12 제11항에 있어서, 제1 인코더를 이용하고 상기 이력 특징 추상 정보를 결합하여 상기 현재 획득된 음성 세그먼트 특징을 인코딩하 여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계는, 상기 현재 획득된 음성 세그먼트 특징을 상기 제1 인코더의 조회 특징으로 사용하고, 상기 이력 특징 추상 정보 와 상기 현재 획득된 음성 세그먼트 특징의 스플라이싱 결과를 상기 제1 인코더의 키 특징 및 값 특징으로 사용 하여, 상기 제1 인코더에 의해 출력되는 상기 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계를 포함하는 음성 인식 방법. 청구항 13 제9항에 있어서, 상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는, 기설정된 시간 길이를 기반으로 상기 원래 음성 특징을 절단하고, 상기 복수의 스파이크 중 각 스파이크가 위치 하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계 를 포함하는 음성 인식 방법. 청구항 14 제9항에 있어서, 상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는, 상기 복수의 스파이크를 기반으로 상기 원래 음성 특징을 절단하고, 인접한 2개의 스파이크 사이마다의 음성 세 그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 방 법. 청구항 15 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제2 디코더는 음성 빅모델인 음성 인식 방법. 청구항 16 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법으로서, 상기 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 상기 트레이닝 방법은, 샘플 음성 및 상기 샘플 음성 중의 복수의 단어의 실제 인식 결과를 획득하는 단계; 상기 샘플 음성의 제1 샘플 음성 특징을 획득하되, 상기 제1 샘플 음성 특징은 상기 샘플 음성 중의 복수의 샘 플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하는 단계; 제1 디코더를 이용하여 상기 제1 샘플 음성 특징을 디코딩하여 상기 샘플 음성 중의 복수의 단어에 대응되는 복 수의 제1 샘플 디코딩 결과를 획득하되, 상기 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계; 제1 샘플 선험적 정보에 기반하여 상기 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하되, 상기 제1 샘플 선험적 정보는 상기 복수의 제1 샘플 디코딩 결과를 포함하고, 상기 제2 샘플 음성 특징은 상기 복수의 단 어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단계; 제2 디코더를 이용하여 상기 제2 샘플 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 샘플 디코딩 결과를 획득하되, 상기 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계; 및 상기 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 상기 딥러닝 모델의 파라미터 를 조정하여 트레이닝된 딥러닝 모델을 획득하는 단계를 포함하는 음성 인식에 사용되는 딥러닝 모델의 트레이 닝 방법. 청구항 17 음성 인식 장치로서, 인식할 음성의 제1 음성 특징을 획득하도록 구성되되, 상기 제1 음성 특징은 상기 인식할 음성 중의 복수의 음 성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈; 상기 제1 음성 특징을 디코딩하여 상기 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획 득하도록 구성되되, 상기 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더; 제1 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하도록 구성되되, 상기 제1 선 험적 정보는 상기 복수의 제1 디코딩 결과를 포함하고, 상기 제2 음성 특징은 상기 복수의 단어에 대응되는 복 수의 제1 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모듈; 및 상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하도록 구성되되, 상기 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더를 포함하는 음성 인 식 장치. 청구항 18 제17항에 있어서, 상기 단어 레벨 특징 추출 모듈은 주의력 모듈을 포함하고, 상기 주의력 모듈은 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 주의 력 모듈의 조회 특징으로서 수신하고, 상기 제1 음성 특징을 상기 주의력 모듈의 키 특징 및 값 특징으로서 수 신하여, 상기 단어에 대응되는 제1 단어 레벨 오디오 특징으로 출력하도록 구성되는 음성 인식 장치. 청구항 19 제18항에 있어서, 상기 단어 레벨 특징 추출 모듈은, 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩을 수행하여, 강화된 제2 음성 특징을 획득하도록 구성되는 제2 인코더를 포함하는 음성 인식 장치. 청구항 20 제17항 내지 제19항 중 어느 한 항에 있어서, 상기 제2 디코더는 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 제2 디 코더의 조회 특징으로서 수신하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로서 수신하 여, 상기 단어에 대응되는 제2 디코딩 결과를 출력하도록 구성되는 음성 인식 장치. 청구항 21 제20항에 있어서, 상기 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함하고, 상기 순방향 디코더 및 상기 역방향 디코더는모두 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징으로서 수신하고, 상기 제2 음성 특징을 입력된 키 특징 및 값 특징으로서 수신하도록 구성되며, 상기 순방향 디코더는 입력된 특 징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성되고, 상기 역방향 디코더는 입력된 특징을 오른쪽에서 왼쪽으로 시간적으로 마스킹하도록 구성되는 음성 인식 장치. 청구항 22 제21항에 있어서, 상기 제2 디코더는, 상기 순방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 순방향 디코딩 특징 및 상기 역방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 상기 복수의 단어 에 대응되는 복수의 융합 특징을 획득하고; 상기 복수의 융합 특징에 기반하여, 상기 복수의 제2 디코딩 결과를 획득하도록 구성되는 음성 인식 장치. 청구항 23 제20항에 있어서, 상기 제2 디코더는, 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제N 디코딩 결과를 상기 제2 디코더의 조회 특징으로서 수신 하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로서 수신하여, 상기 단어에 대응되는 제 N+1 디코딩 결과를 출력하도록 구성되되, N은 2보다 크거나 같은 정수인 음성 인식 장치. 청구항 24 제17항 내지 제19항 중 어느 한 항에 있어서, 상기 단어 레벨 특징 추출 모듈은 제2 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제3 음성 특징을 추출하도록 구성되되, 상기 제2 선험적 정보는 상기 복수의 제2 디코딩 결과를 포함하고, 상기 제3 음성 특징은 상기 복수의 단어에 대응되는 복수의 제2 단어 레벨 오디오 특징을 포함하며, 상기 제2 디코더는 상기 제3 음성 특징을 디코딩하여, 상기 복수의 단어에 대응되는 복수의 제3 디코딩 결과를 획득하도록 구성되되, 상기 제3 디코딩 결과는 대응하는 단어의 제3 인식 결과를 지시하는 음성 인식 장치. 청구항 25 제17항 내지 제19항 중 어느 한 항에 있어서, 상기 음성 특징 인코딩 모듈은, 상기 인식할 음성의 원래 음성 특징을 획득하고; 상기 원래 음성 특징에 기반하여 상기 인식할 음성 중의 복수의 스파이크를 결정하며; 상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하도록 구성되는 음성 인식 장치. 청구항 26 제25항에 있어서, 상기 복수의 음성 세그먼트 특징은 상기 원래 음성 특징에 대한 스트리밍 절단에 의해 순차적으로 획득된 것이 고, 상기 제1 디코더는 상기 복수의 음성 세그먼트 특징에 대해 순차적으로 스트리밍 디코딩을 수행하도록 구성 되는 음성 인식 장치. 청구항 27 제26항에 있어서,상기 음성 특징 인코딩 모듈은, 현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하도록 구성되되, 상기 이력 특 징 추상 정보는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 상기 이전 음성 세그먼트 특 징에 대해 주의력 모델링을 수행함으로써 획득된 것이고; 상기 음성 특징 인코딩 모듈은, 상기 이력 특징 추상 정보를 결합하여 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세 그먼트 특징을 출력하도록 구성되는 제1 인코더를 포함하는 음성 인식 장치. 청구항 28 제27항에 있어서, 상기 제1 인코더는 상기 현재 획득된 음성 세그먼트 특징을 상기 제1 인코더의 조회 특징으로서 수신하고, 상기 이력 특징 추상 정보와 상기 현재 획득된 음성 세그먼트 특징의 스플라이싱 결과를 상기 제1 인코더의 키 특징 및 값 특징으로서 수신하여 상기 대응하는 강화된 음성 세그먼트 특징을 출력하도록 구성되는 음성 인식 장치. 청구항 29 제25항에 있어서, 상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는, 기설정된 시간 길이를 기반으로 상기 원래 음성 특징을 절단하고, 상기 복수의 스파이크 중 각 스파이크가 위치 하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계 를 포함하는 음성 인식 장치. 청구항 30 제25항에 있어서, 상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는, 상기 복수의 스파이크를 기반으로 상기 원래 음성 특징을 절단하고, 인접한 2개의 스파이크 사이마다의 음성 세 그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 장 치. 청구항 31 제17항 내지 제19항 중 어느 한 항에 있어서, 상기 제2 디코더는 음성 빅모델인 음성 인식 장치. 청구항 32 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치로서, 상기 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 상기 트레이닝 장치는, 샘플 음성 및 상기 샘플 음성 중의 복수의 단어의 실제 인식 결과를 획득하도록 구성되는 획득 모듈; 상기 샘플 음성의 제1 샘플 음성 특징을 획득하도록 구성되되, 상기 제1 샘플 음성 특징은 상기 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈; 상기 제1 샘플 음성 특징을 디코딩하여 상기 샘플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩 결과를 획득하도록 구성되되, 상기 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디 코더; 제1 샘플 선험적 정보에 기반하여 상기 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하도록구성되되, 상기 제1 샘플 선험적 정보는 상기 복수의 제1 샘플 디코딩 결과를 포함하고, 상기 제2 샘플 음성 특 징은 상기 복수의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모 듈; 상기 제2 샘플 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 샘플 디코딩 결과를 획득하도 록 구성되되, 상기 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더; 및 상기 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 상기 딥러닝 모델의 파라미터 를 조정하여 트레이닝된 딥러닝 모델을 획득하도록 구성되는 파라미터 조정 모듈을 포함하는 음성 인식에 사용 되는 딥러닝 모델의 트레이닝 장치. 청구항 33 전자 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되; 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 제1항 내지 제16항 중 어느 한 항에 따른 방 법을 수행할 수 있도록 하는 전자 기기. 청구항 34 컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제16항 중 어느 한 항에 따른 방법을 수행하도록 하기 위한 것인 비일시적 컴퓨터 판독 가능 저장 매체. 청구항 35 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 명령을 포함하고, 상기 명령이 적어도 하나의 프로세서에 의해 실행될 경우 제1항 내지 제16항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램. 발명의 설명 기 술 분 야"}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 3, "content": "본 발명은 인공지능 기술분야에 관한 것으로, 특히 음성 인식 및 딥러닝 등 기술분야에 관한 것이고, 구체적으 로 음성 인식 방법, 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법, 음성 인식 장치, 음성 인식에 사용되 는 딥러닝 모델의 트레이닝 장치, 전자 기기, 컴퓨터 판독 가능 저장 매체 및 컴퓨터 프로그램 제품에 관한 것 이다."}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능은 컴퓨터가 인간의 특정 사고 과정과 지능적인 행동(예를 들어, 학습, 추론, 사고, 계획 등)을 시뮬레 이션하도록 하는 학과를 연구하는 것으로, 하드웨어 수준의 기술과 소프트웨어 수준의 기술을 모두 갖추고 있다. 인공지능 하드웨어 기술에는 일반적으로 센서, 전용 인공지능 칩, 클라우드 컴퓨팅, 분산 스토리지, 빅데 이터 처리 등의 기술이 포함되며; 인공지능 소프트웨어 기술에는 주로 자연 언어 처리 기술, 컴퓨터 비전 기술, 음성 인식 기술 및 기계 학습/딥러닝, 빅데이터 처리 기술, 지식 그래프 기술 등 여러 방향이 포함된다. 자동 음성 인식(Auto Speech Recognition, ASR)은 입력된 음성 신호를 컴퓨터를 통해 대응하는 텍스트로 자동으 로 변환하는 기술이다. 음성 인식 분야에서 딥러닝 기술에 대한 심층적인 연구에 따라, 특히 엔드 투 엔드 음성 인식 기술의 도입으로 모델 모델링의 복잡성을 줄이면서 음성 인식의 정확도가 크게 향상되었다. 다양한 스마트 기기가 지속적으로 대중화됨에 따라 대규모 어휘 온라인 음성 인식 시스템이 음성 전사, 지능형 고객 서비스, 자동차 내비게이션 및 스마트 홈과 같은 다양한 장면에서 널리 응용되고 있다. 이러한 음성 인식 작업에서 사용 자는 일반적으로 음성 입력이 완료된 후 시스템으로부터 빠르고 정확한 응답과 피드백을 얻기를 원하며, 따라서음성 인식 모델의 정확성과 실시간 속도에 대한 요구 사항이 매우 높다. 이 부분에서 설명된 방법은 반드시 이전에 구상되었거나 사용된 방법이 아닐 수도 있다. 달리 명시되지 않는 한, 이 부분에 설명된 방법이 단지 이 부분에 포함되어 있다는 이유만으로 선행 기술이라고 가정해서는 안된다. 마찬가지로, 달리 명시되지 않는 한, 이 부분에 언급된 문제는 선행 기술에서 공인되는 것으로 간주되어서는 안 된다."}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 음성 인식 방법, 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법, 음성 인식 장치, 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치, 전자 기기, 컴퓨터 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 제 공한다."}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양태에 따르면, 인식할 음성의 제1 음성 특징을 획득하되, 제1 음성 특징은 인식할 음성 중의 복 수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 단계; 제1 디코더를 이용하여 제1 음성 특징을 디코딩하여 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하되, 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계; 제1 선험적 정보에 기반하여, 제1 음성 특징으로부터 제2 음성 특징을 추출하되, 제1 선험적 정보는 복수의 제1 디코딩 결과를 포함하고, 제2 음성 특징은 복수의 단 어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단계; 및 제2 디코더를 이용하여 제2 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하되, 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계를 포함하는 음성 인식 방법을 제공한다. 본 발명의 다른 양태에 따르면, 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법을 제공하며, 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 트레이닝 방법은, 샘플 음성 및 샘플 음성 중의 복수의 단어의 실제 인 식 결과를 획득하는 단계; 샘플 음성의 제1 샘플 음성 특징을 획득하되, 제1 샘플 음성 특징은 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하는 단계; 제1 디코더를 이용하 여 제1 샘플 음성 특징을 디코딩하여 샘플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩 결과를 획득하되, 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계; 제1 샘플 선험적 정보에 기반하여 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하되, 제1 샘플 선험적 정보는 복수의 제1 샘 플 디코딩 결과를 포함하고, 제2 샘플 음성 특징은 복수의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단계; 제2 디코더를 이용하여 제2 샘플 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수 의 제2 샘플 디코딩 결과를 획득하되, 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계; 및 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 딥러닝 모델의 파라미터 를 조정하여 트레이닝된 딥러닝 모델을 획득하는 단계를 포함한다. 본 발명의 다른 양태에 따르면, 인식할 음성의 제1 음성 특징을 획득하도록 구성되되, 제1 음성 특징은 인식할 음성 중의 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈; 제 1 음성 특징을 디코딩하여, 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하도록 구 성되되, 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더; 제1 선험적 정보에 기반하 여, 제1 음성 특징으로부터 제2 음성 특징을 추출하도록 구성되되, 제1 선험적 정보는 복수의 제1 디코딩 결과 를 포함하고, 제2 음성 특징은 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단어 레 벨 특징 추출 모듈; 및 제2 음성 특징을 디코딩하여, 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하 도록 구성되되, 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더를 포함하는 음성 인 식 장치를 제공한다. 본 발명의 다른 양태에 따르면, 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치를 제공하며, 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 트레이닝 장치는, 샘플 음성 및 샘플 음성 중의 복수의 단어의 실제 인 식 결과를 획득하도록 구성되는 획득 모듈; 샘플 음성의 제1 샘플 음성 특징을 획득하도록 구성되되, 제1 샘플 음성 특징은 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하 는 음성 특징 인코딩 모듈; 제1 샘플 음성 특징을 디코딩하여, 샘플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩 결과를 획득하도록 구성되되, 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더; 제1 샘플 선험적 정보에 기반하여 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하 도록 구성되되, 제1 샘플 선험적 정보는 복수의 제1 샘플 디코딩 결과를 포함하고, 제2 샘플 음성 특징은 복수 의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모듈; 제2 샘플 음성 특징을 디코딩하여, 복수의 단어에 대응되는 복수의 제2 샘플 디코딩 결과를 획득하도록 구성되되, 제2 샘 플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더; 및 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 딥러닝 모델의 파라미터를 조정하여 트레이닝된 딥러닝 모델을 획 득하도록 구성되는 파라미터 조정 모듈을 포함한다. 본 발명의 다른 양태에 따르면, 적어도 하나의 프로세서; 및 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되; 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 이러한 명령은 적어도 하 나의 프로세서에 의해 실행되어 적어도 하나의 프로세서가 상기 방법을 수행할 수 있도록 하는 전자 기기를 제 공한다. 본 발명의 다른 양태에 따르면, 컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체를 제공하며, 여기 서 컴퓨터 명령은 컴퓨터가 상기 방법을 수행하도록 하기 위한 것이다. 본 발명의 다른 양태에 따르면, 컴퓨터 프로그램을 포함한 컴퓨터 프로그램 제품을 제공하며, 여기서 컴퓨터 프 로그램이 프로세서에 의해 실행될 경우 상기 방법을 구현한다."}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 하나 이상의 실시예에 따르면, 본 발명은 복수의 음성 세그먼트 특징을 포함하는 인식할 음성의 제1 음성 특징을 획득하고 이를 디코딩하여 인식할 음성의 초기 인식 결과를 획득하며, 나아가 초기 인식 결과를 이 용하여 제1 음성 특징으로부터 단어 레벨의 오디오 특징을 추출하고, 단어 레벨의 오디오 특징을 디코딩하여 최 종 인식 결과를 획득하는 것이다. 인식할 음성의 초기 인식 결과를 선험적으로 하여, 프레임 레벨 오디오 정보 중 상이한 길이를 갖는 음성 특징 정보로부터 단어 레벨의 길이가 같고 통일된 오디오 특징 표현을 추출하고, 단어 레벨의 오디오 특징을 디코딩 하여 최종 인식 결과를 획득함으로써, 기존의 음성 프레이밍의 특징 표현 길이가 일치하지 않은 난제를 해결하 고 음성 인식의 정밀도를 향상시키며 컴퓨팅 효율을 향상시킨다. 이해해야 할 것은, 본 부분에서 설명된 내용은 본 발명의 실시예의 핵심 또는 중요한 특징을 식별하려는 의도가 아니며, 본 발명의 범위를 한정하려는 것도 아니다. 본 발명의 다른 특징은 아래 명세서로부터 쉽게 이해될 것 이다."}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 도면을 결부하여 본 발명의 예시적인 실시예를 설명하되, 여기에는 이해를 돕기 위한 본 발명의 실시예의 다양한 세부사항들이 포함되지만, 이들은 단지 예시적인 것으로 이해되어야 한다. 따라서, 당업자는 본 발명의 범위를 벗어나지 않으면서 여기서 설명된 실시예에 대해 다양한 변형 및 수정을 진행할 수 있음을 이해해야 한 다. 마찬가지로, 명확성 및 간략함을 위해, 아래의 설명에서 공지 기능 및 구조에 대한 설명을 생략한다. 본 발명에서, 달리 설명되지 않는 한, 용어 \"제1\", \"제2\" 등을 사용하여 다양한 요소를 설명하는 것은 이러한 요소의 위치 관계, 시간 순서 관계 또는 중요성 관계를 한정하려는 의도가 아니며, 이러한 용어는 단지 하나의 요소를 다른 요소와 구분하기 위한 것이다. 일부 예시에서, 제1 요소와 제2 요소는 상기 요소의 동일한 예를 지 칭할 수 있고, 일부 경우 문맥적인 설명에 기반하여 상이한 예를 지칭할 수도 있다. 본 발명에서 다양한 상기 예시에 대한 설명에 사용되는 용어는 단지 특정 예시를 설명하기 위한 목적일 뿐 제한 하려는 의도가 아니다. 문맥상 다른 명확한 설명이 없고, 요소의 개수를 특별히 한정하지 않는 한, 상기 요소는 하나 이상일 수 있다. 이 밖에, 본 발명에 사용되는 용어 \"및/또는\"은 나열된 항목 중 어느 하나 및 전부 가능 한 조합 방식을 포함한다. 관련 기술에서, 일부 음성 인식 방법에서는 오디오 특징 표현 학습 시 프레이밍의 음성 특징을 사용하여 표현 학습하는데, 음성 중에 포함된 내용 정보가 말하는 사람의 말하는 속도, 억양, 어조 등에 따라 지속적으로 변화 하고, 말하는 사람이 상이함에 따라 동일한 내용에 대한 표현이 모두 상이하므로 이러한 특징 표현 방식은 프레 이밍의 음성 특징의 표현 길이가 일치하지 않게 하여, 음성 인식의 정확도에 영향을 미치며, 획득된 특징 표현 에 대량의 중복 특징이 존재하여 컴퓨팅 효율이 낮아진다. 상술한 문제를 해결하기 위해, 본 발명은 복수의 음성 세그먼트 특징을 포함하는 인식할 음성의 제1 음성 특징 을 획득하고 이를 디코딩하여 인식할 음성의 초기 인식 결과를 획득하며, 나아가 초기 인식 결과를 이용하여 제 1 음성 특징으로부터 단어 레벨의 오디오 특징을 추출하고, 단어 레벨의 오디오 특징을 디코딩하여 최종 인식 결과를 획득한다. 인식할 음성의 초기 인식 결과를 선험적으로 하여, 프레임 레벨 오디오 정보 중 상이한 길이 를 갖는 음성 특징 정보로부터 단어 레벨의 길이가 같고 통일된 오디오 특징 표현을 추출하고, 단어 레벨의 오 디오 특징을 디코딩하여 최종 인식 결과를 획득함으로써, 기존의 음성 프레이밍의 특징 표현 길이가 일치하지 않은 난제를 해결하고 음성 인식의 정밀도를 향상시키며 컴퓨팅 효율을 향상시킨다. 아래에 도면을 결부하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 발명의 실시예에 따라 본문에 설명된 다양한 방법 및 장치가 구현될 수 있는 예시적인 시스템의 모식도를 도시한다. 도 1을 참조하면, 상기 시스템은 하나 이상의 클라이언트 기기(101, 102, 103, 104, 105 및 106), 서버 및 하나 이상의 클라이언트 기기를 서버에 연결하는 하나 이상의 통신 네트워크 를 포함한다. 클라이언트 기기(101, 102, 103, 104, 105 및 106)는 하나 이상의 응용 프로그램을 실행하도 록 구성될 수 있다. 본 발명의 실시예에서, 서버는 본 발명의 음성 인식 방법 및/또는 음성 인식에 사용되는 딥러닝 모델의 트 레이닝 방법을 수행할 수 있도록 하는 하나 이상의 서비스 또는 소프트웨어 애플리케이션을 실행할 수 있다. 예 시적인 일 실시예에서, 서버에는 완전한 음성 인식 시스템, 또는 음성 빅모델과 같은 음성 인식 시스템 중의 일 부 구성요소가 배치될 수 있다. 일부 실시예에서, 서버는 또한 비가상 환경 및 가상 환경을 포함할 수 있는 다른 서비스 또는 소프트웨어 애플리케이션을 제공할 수 있다. 일부 실시예에서, 이러한 서비스는 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 사용자에게 서비스로서의 소프트웨어(SaaS) 모델에서와 같이 web 기반 서비스 또는 클라우드 서 비스로서 제공될 수 있다. 도 1에 도시된 구성에서, 서버는 서버에 의해 실행되는 기능을 구현하는 하나 이상의 구성요소를 포 함할 수 있다. 이러한 구성요소에는 하나 이상의 프로세서에 의해 실행 가능한 소프트웨어 구성요소, 하드웨어구성요소 또는 이들의 조합이 포함될 수 있다. 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)를 조작 하는 사용자는 하나 이상의 클라이언트 애플리케이션을 순차적으로 이용하여 서버와 상호작용함으로써 이 들 구성요소에 의해 제공되는 서비스를 활용할 수 있다. 시스템과 상이할 수 있는 다양한 시스템 구성이 가능하다는 것을 이해해야 한다. 따라서, 도 1은 본 명세서에 설명된 다양한 방법을 구현하기 위한 시스템의 일 예시이며 제한하려는 의도는 아니다. 사용자는 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)를 사용하여 인식할 음성을 입력할 수 있다. 클라이언트 기기는 클라이언트 기기의 사용자가 클라이언트 기기와 상호작용할 수 있도록 하는 인터페이스를 제 공할 수 있다. 클라이언트 기기는 상기 인터페이스를 통해 사용자에게 정보를 출력할 수도 있으며, 예를 들어 사용자에게 음성 인식 결과를 출력할 수 있다. 도 1은 단지 6종의 클라이언트 기기를 도시하고 있지만, 당업자 는 본 발명이 임의의 개수의 클라이언트 기기를 지원할 수 있다는 것을 이해할 수 있을 것이다. 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)는 휴대용 핸드헬드 기기, 범용 컴퓨터(예를 들어, 개인 용 컴퓨터 및 랩톱 컴퓨터), 워크스테이션 컴퓨터, 웨어러블 기기, 스마트 스크린 기기, 셀프 서비스 단말 기기, 서비스 로봇, 게임 시스템, 씬 클라이언트, 다양한 메시지 송수신 기기, 센서 또는 기타 감지 기기와 같 은 다양한 유형의 컴퓨터 기기를 포함할 수 있다. 이러한 컴퓨터 기기는 MICROSOFT Windows, APPLE iOS, UNIX 유사 운영 체제, Linux 또는 Linux 유사 운영 체제(예를 들어, GOOGLE Chrome OS)와 같은 다양한 유형 및 버전 의 소프트웨어 애플리케이션 및 운영 체제를 실행할 수 있거나 MICROSOFT Windows Mobile OS, iOS, Windows Phone, Android와 같은 다양한 모바일 운영 체제를 포함할 수 있다. 휴대용 핸드헬드 기기는 셀룰러 폰, 스마트 폰, 태블릿 PC, 개인 휴대 정보 단말기(PDA) 등을 포함할 수 있다. 웨어러블 기기는 헤드 마운트 디스플레이(예 를 들어, 스마트 안경) 및 다른 기기를 포함할 수 있다. 게임 시스템은 다양한 휴대용 게임 기기, 인터넷 기반 게임 기기 등을 포함할 수 있다. 클라이언트 기기는 다양한 인터넷 관련 애플리케이션 프로그램, 통신 애플리케 이션 프로그램(예를 들어, 이메일 애플리케이션 프로그램), 단문 메시지 서비스(SMS) 애플리케이션 프로그램과 같은 다양한 애플리케이션 프로그램을 실행할 수 있으며 다양한 통신 프로토콜을 사용할 수 있다. 네트워크는 다양한 이용 가능한 프로토콜 중 어느 하나(TCP/IP, SNA, IPX 등을 포함하지만 이에 제한되지 않음)를 사용하여 데이터 통신을 지원할 수 있는 당업자에게 잘 알려진 임의의 유형의 네트워크일 수 있다. 단 지 예시로서, 하나 이상의 네트워크는 근거리 통신망(LAN), 이더넷 기반 네트워크, 토큰 링, 광역 통신망 (WAN), 인터넷, 가상 네트워크, 가상 사설망(VPN), 인트라넷, 엑스트라넷, 블록체인 네트워크, 공중 교환 전화 망(PSTN), 적외선 네트워크, 무선 네트워크(예를 들어, 블루투스, WIFI) 및/또는 이러한 네트워크 및/또는 기타 네트워크의 임의의 조합일 수 있다. 서버는 하나 이상의 범용 컴퓨터, 전용 서버 컴퓨터(예를 들어, PC(개인용 컴퓨터) 서버, UNIX 서버, 중급 서버), 블레이드 서버, 메인프레임 컴퓨터, 서버 클러스터, 또는 임의의 다른 적절한 배치 및/또는 조합을 포함 할 수 있다. 서버는 가상 운영 체제를 실행하는 하나 이상의 가상 머신, 또는 가상화에 관한 다른 컴퓨팅 아키텍처(예를 들어, 서버의 가상 저장 기기를 유지하기 위해 가상화될 수 있는 논리적 저장 기기의 하나 이상 의 플렉시블 풀)를 포함할 수 있다. 다양한 실시예에서, 서버는 아래에 설명된 기능을 제공하는 하나 이상 의 서비스 또는 소프트웨어 애플리케이션을 실행할 수 있다. 서버 중의 컴퓨팅 유닛은 위에서 설명한 임의의 운영 체제뿐만 아니라 임의의 상업적으로 이용 가능한 서 버 운영 체제를 포함하는 하나 이상의 운영 체제를 실행할 수 있다. 서버는 또한 HTTP서버, FTP서버, CGI 서버, JAVA서버, 데이터베이스 서버 등을 포함하는 다양한 부가적 서버 애플리케이션 프로그램 및/또는 중간 계 층 애플리케이션 프로그램 중 어느 하나를 실행할 수 있다. 일부 실시형태에서, 서버는 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 사용자로부터 수신 된 데이터 피드 및/또는 이벤트 업데이트를 분석하고 합병하기 위한 하나 이상의 애플리케이션 프로그램을 포함 할 수 있다. 서버는 또한 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 하나 이상의 디스플 레이 기기를 통해 데이터 피드 및/또는 실시간 이벤트를 표시하는 하나 이상의 애플리케이션 프로그램을 포함할 수 있다. 일부 실시형태에서, 서버는 분산 시스템의 서버일 수도 있고, 블록체인과 결합된 서버일 수도 있다. 서버 는 클라우드 서버일 수도 있고, 인공지능 기술이 적용된 지능형 클라우드 컴퓨팅 서버 또는 지능형 클라우 드 호스트일 수도 있다. 클라우드 서버는 기존의 물리적 호스트와 가상사설서버(VPS) 서비스의 관리가 어렵고 사업 확장성이 취약한 결함을 해결하기 위한 클라우드 컴퓨팅 서비스 시스템 중의 호스트 제품이다.시스템은 하나 이상의 데이터베이스를 더 포함할 수 있다. 일부 실시예에서, 이러한 데이터베이스는 데이터 및 기타 정보를 저장하는 데 사용될 수 있다. 예를 들어, 데이터베이스 중 하나 이상은 오디오 파 일 및 비디오 파일과 같은 정보를 저장하는 데 사용될 수 있다. 데이터베이스는 다양한 위치에 상주할 수 있다. 예를 들어, 서버에 의해 사용되는 데이터베이스는 서버에 로컬되거나 서버로부터 멀리 떨 어져 있을 수 있고 네트워크 기반 또는 전용 연결을 통해 서버와 통신할 수도 있다. 데이터베이스는 상이한 유형일 수 있다. 일부 실시예에서, 서버에 의해 사용되는 데이터베이스는 예를 들어 관계형 데이터 베이스일 수 있다. 이러한 데이터베이스 중 하나 이상은 명령에 응답하여 데이터베이스와 데이터베이스로부터의 데이터를 저장, 업데이트 및 검색할 수 있다. 일부 실시예에서, 데이터베이스 중 하나 이상은 또한 애플리케이션 프로그램 데이터를 저장하기 위해 애플 리케이션 프로그램에 의해 사용될 수도 있다. 애플리케이션 프로그램에서 사용하는 데이터베이스는 키-값 저장 소, 객체 저장소 또는 파일 시스템이 지원하는 일반 저장소와 같은 다양한 유형의 데이터베이스일 수 있다. 도 1의 시스템은 다양한 방식으로 구성 및 작동되어 본 발명에 따라 설명된 다양한 방법 및 장치가 적용될 수 있도록 한다. 본 발명의 일 양태에 따르면, 음성 인식 방법을 제공한다. 도 2에 도시된 바와 같이, 음성 인식 방법은, 인식할 음성의 제1 음성 특징을 획득하되, 제1 음성 특징은 인식할 음성 중의 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 단계(S201); 제1 디코더를 이용하여 제1 음성 특징을 디코딩하여 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하되, 제1 디코딩 결과는 대응하는 단어의 제1 인 식 결과를 지시하는 단계(S202); 제1 선험적 정보에 기반하여, 제1 음성 특징으로부터 제2 음성 특징을 추출하 되, 제1 선험적 정보는 복수의 제1 디코딩 결과를 포함하고, 제2 음성 특징은 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단계(S203); 및 제2 디코더를 이용하여 제2 음성 특징을 디코딩하여 복 수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하되, 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과 를 지시하는 단계(S204)를 포함한다. 이로써, 인식할 음성의 초기 인식 결과를 선험적으로 하여, 프레임 레벨 오디오 정보 중 상이한 길이를 갖는 음 성 특징 정보로부터 단어 레벨의 길이가 같고 통일된 오디오 특징 표현을 추출하고, 단어 레벨의 오디오 특징을 디코딩하여 최종 인식 결과를 획득함으로써, 기존의 음성 프레이밍의 특징 표현 길이가 일치하지 않은 난제를 해결하고 음성 인식의 정밀도를 향상시키며 컴퓨팅 효율을 향상시킨다. 기술적인 구상을 간편하게 설명하기 위해, 본 발명의 실시예의 인식할 음성에는 복수의 단어에 대응되는 음성 내용이 포함된다. 단계(S201)에서, 기존의 다양한 음성 특징 추출 방법을 이용하여 인식할 음성의 제1 음성 특 징을 획득할 수 있다. 복수의 음성 세그먼트는 고정된 길이로 인식할 음성을 절취하여 획득된 것일 수 있고, 다 른 절취 방식으로 획득된 것일 수도 있으며; 복수의 음성 세그먼트 특징은 복수의 음성 세그먼트와 일대일로 대 응될 수 있고, 동일한 음성 세그먼트가 복수의 음성 세그먼트 특징에 대응할 수도 있으며(아래에서 소개될 것임), 이에 한정되지 않는다. 일부 실시예에 따르면, 도 3에 도시된 바와 같이, 인식할 음성의 제1 음성 특징을 획득하는 단계(S201)는, 인식 할 음성의 원래 음성 특징을 획득하는 단계(S301); 원래 음성 특징에 기반하여 인식할 음성 중의 복수의 스파이 크를 결정하는 단계(S302); 및 원래 음성 특징을 절단하여 복수의 스파이크에 일대일로 대응되는 복수의 음성 세그먼트 특징을 획득하는 단계(S303)를 포함할 수 있다. 스파이크 신호는 일반적으로 인식할 음성 중 각 단어와 대응 관계를 가지므로, 먼저 인식할 음성의 스파이크 신 호를 획득하고, 스파이크 신호에 따라 복수의 스파이크에 일대일로 대응되는 복수의 음성 세그먼트 특징을 획득 하여, 제1 디코더가 스파이크 정보의 구동 하에 제1 음성 특징을 디코딩할 수 있도록 함으로써 정확한 초기 인 식 결과를 획득한다. 단계(S301)에서, 인식할 음성에 포함되는 복수의 음성 프레임에 대해 음성 특징 추출을 수행하여 복수의 음성 프레임 특징을 포함하는 원래 음성 특징을 획득할 수 있다. 단계(S302)에서, 인과 관계 Conformer(Causal Conformer) 모델링 기반의 이진값 CTC(Connectionist Temporal Classification) 모듈을 이용하여 원래 음성 특징을 처리하여, CTC 스파이크 정보를 획득함으로써 인식할 음성 중의 복수의 스파이크를 결정할 수 있다. 이해할 수 있는 것은, 또한 다른 방식을 통해 인식할 음성 중의 복수 의 스파이크를 결정할 수 있으며 이에 한정되지 않는다.단계(S303)에서, 원래 음성 특징에 대한 절단은 복수의 음성 프레임에 대응하는 복수의 음성 프레임 특징을 복 수의 그룹의 음성 프레임 특징으로 절단하는 것일 수 있고, 각 그룹의 음성 프레임/음성 프레임 특징은 하나의 음성 세그먼트/음성 세그먼트 특징을 구성한다. 일부 실시예에 따르면, 원래 음성 특징을 절단하여 복수의 스파이크에 일대일로 대응되는 복수의 음성 세그먼트 특징을 획득하는 단계(S303)는, 기설정된 시간 길이를 기반으로 원래 음성 특징을 절단하고, 복수의 스파이크 중 각 스파이크가 위치하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특 징으로 사용하는 단계를 포함할 수 있다. 이로써, 상기 방식을 통해 각 스파이크에 대응되는 음성 세그먼트 특 징이 동일한 길이를 갖도록 한다. 유의해야 할 것은, 이러한 방식에서 하나의 음성 세그먼트에 하나 이상의 스 파이크가 포함되면, 상기 음성 세그먼트의 음성 세그먼트 특징은 동시에 이러한 스파이크 중 각 스파이크에 대 응되는 음성 세그먼트로 사용된다. 이해할 수 있는 것은, 요구에 따라 기설정된 시간 길이를 설정할 수 있다. 도 4에 설명된 실시예에서 기설정된 시간 길이(d)는 5개의 음성 프레임이다. 일부 실시예에 따르면, 원래 음성 특징을 절단하여 복수의 스파이크에 일대일로 대응되는 복수의 음성 세그먼트 특징을 획득하는 단계(S303)는, 복수의 스파이크를 기반으로 원래 음성 특징을 절단하고, 인접한 2개의 스파이 크 사이마다의 음성 세그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함할 수 있다. 이로써, 상기 방식을 통해 각 스파이크에 대응되는 음성 세그먼트 특징에 인접한 2개의 스파이 크 사이에 구성된 음성 세그먼트의 완전한 음성 정보가 포함되도록 한다. 일부 실시예에서, 원래 음성 특징을 사용(CTC 모듈 또는 초기 음성 인식)하기 이전에 원래 음성 특징에 대해 샘 플링(예를 들어, 컨볼루션 다운샘플링)을 수행할 수 있다 일부 실시예에 따르면, 복수의 음성 세그먼트 특징은 원래 음성 특징에 대해 스트리밍 절단을 수행하여 순차적 으로 획득된 것일 수 있다. 단계(S202)에서, 제1 디코더를 이용하여 제1 음성 특징을 디코딩하는 단계는, 제1 디코더를 이용하여 복수의 음성 세그먼트 특징에 대해 스트리밍 디코딩을 수행하는 단계를 포함할 수 있다. 이 로써, 원래 음성 특징에 대해 스트리밍 절취를 수행하고 제1 음성 특징에 대해 스트리밍 디코딩을 수행함으로써 인식할 음성에 대한 초기 인식 결과를 빠르게 획득할 수 있도록 한다. 일부 실시예에 따르면, 이력 특징 추상 기반의 방식을 이용하여 음성 세그먼트 특징에 대해 추가 인코딩을 수행 하여, 음성 세그먼트 특징의 설명 기능을 강화함으로써 음성 세그먼트 특징을 디코딩한 후 얻은 초기 인식 결과 의 정확성을 향상시킬 수 있다. 도 3에 도시된 바와 같이, 인식할 음성의 제1 음성 특징을 획득하는 단계(S20 1)는, 현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하되, 이력 특징 추상 정 보는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 이전 음성 세그먼트 특징에 대해 주의력 모델링을 수행함으로써 획득된 것인 단계(S304); 및 제1 인코더를 이용하고 이력 특징 추상 정보를 결합하여 현 재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계(S305)를 더 포함할 수 있다. 일부 실시예에서, 현재 획득된 음성 세그먼트 특징에 대응되는 이력 특징 추상 정보는 복수의 이전 음성 세그먼 트 특징 각각에 대응되는 이력 특징 추상 정보를 포함하고, 각 이전 음성 세그먼트 특징의 이력 특징 추상 정보 는 상기 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 상기 이전 음성 세그먼트 특징에 대 해 주의력 모델링을 수행하여 획득된 것이다. 예시적인 일 실시예에서, 상기 제1 디코딩 결과를 조회 특징(Q)으 로 사용하고, 상기 이전 음성 세그먼트 특징을 키 특징(K) 및 값 특징(V)으로 사용하여 주의력 메커니즘 컴퓨팅 을 수행하여, 상기 이전 음성 세그먼트 특징의 이력 특징 추상 정보를 획득할 수 있다. 주의력 메커니즘의 컴퓨 팅 과정은 하기와 같이 표시될 수 있다."}
{"patent_id": "10-2024-0117069", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, dk는 특징의 차원이다. 이해할 수 있는 것은, 본 발명의 조회 특징, 키 특징 및 값 특징을 기반으로 수 행된 다른 특징 획득 및 주의력 메커니즘 컴퓨팅은 모두 상기 공식을 참조할 수 있다. 유의해야 할 것은, 상기 방식을 통해 얻은 특징의 수는 조회 특징에 포함되는 특징 수와 동일하다. 일부 실시예에 따르면, 제1 인코더를 이용하고 이력 특징 추상 정보를 결합하여 현재 획득된 음성 세그먼트 특 징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계(S305)는, 현재 획득된 음성 세그먼트 특 징을 제1 인코더의 조회 특징(Q)으로 사용하고, 이력 특징 추상 정보와 현재 획득된 음성 세그먼트 특징의 스플 라이싱 결과를 제1 인코더의 키 특징(K) 및 값 특징(V)으로 사용하여, 제1 인코더에 의해 출력되는 대응하는 강 화된 음성 세그먼트 특징을 획득하는 단계를 포함할 수 있다. 이로써, 상기 방식을 통해, 더 많은 음성 특징 중의 시간적 관계와 언어 관계를 충분히 발굴하여 모델의 이력 추상 기능을 현저하게 향상시키며, 강화된 음성 세그먼트 특징의 디코딩 결과의 정확성을 향상시킬 수 있다. 일부 실시예에서, 제1 인코더 및 제1 디코더는 공통으로 이력 특징 추상 기반의 Conformer 스트리밍 다단계 절 단 주의력(Streaming Multi-Layer Truncated Attention, SMLTA) 모델을 구성할 수 있다. 도 4에 도시된 바와 같이, Conformer SMLTA 모델은 주로 2개의 부분을 포함하는 데, 하나는 스트리밍 절단의 Conformer 인코더 (Streaming Truncated Conformer Encoder), 즉 제1 인코더이고, 다른 하나는 Transformer 디코더 (Transformer Decoder), 즉 제1 디코더이다. 스트리밍 절단의 Conformer 인코더는 N개의 적층된 Conformer 모듈을 포함하고, 각 Conformer 모듈은 피드포워드 모듈, 다중 헤드 셀프 주의력 모듈, 컨 볼루션 모듈 및 피드포워드 모듈을 포함한다. Conformer 모듈은 음성 세그먼트 특징을 계층별로 인코 딩하여 대응하는 암시적 특징(즉, 강화된 음성 세그먼트 특징)을 획득한다. Transformer 디코더는 M개의 적층된 Transformer 모듈을 포함하고, 스트리밍 주의력 메커니즘을 통해 인코더가 출력한 암시적 특징을 선별하여 초기 인식 결과를 지시하는 제1 디코딩 결과를 출력한다. 도 4는 또한 이력 특징 추상 기반의 Conformer SMLTA 원리를 도시한다. 입력된 원래 음성 특징은 우선 동 일한 길이를 갖는 음성 세그먼트 특징으로 분할되고, 다음으로 스트리밍 Conformer 인코더는 각 음성 세그먼트 특징에 대해 특징 인코딩을 수행한다. Transformer 디코더는 이진값 CTC 모델의 스파이크 정보에 따라 각 오디오 세그먼트에 포함된 스파이크 수를 통계하고 스파이크 수에 따라 현재 세그먼트의 인식 결과를 디코딩하 여 출력한다. 마지막에 현재 세그먼트의 디코딩 결과에 따라 Conformer 인코더의 각 계층의 암시적 특징에 대해 상관성 주의력 모델링을 수행하여 대응하는 음성 세그먼트에 포함된 이력 특징 추상을 획득하고, 각 계층의 추 상에서 얻은 이력 특징 추상 정보와 현재 획득된 음성 세그먼트 특징을 스플라이싱하여 다음 세그먼트의 컴퓨팅 에 사용한다. 일부 실시예에 따르면, 도 5에 도시된 바와 같이, 제1 선험적 정보에 기반하여 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계(S203)는, 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 주의 력 모듈의 조회 특징(Q)으로 사용하고, 제1 음성 특징을 주의력 모듈의 키 특징(K) 및 값 특징(V)으로 사용하여, 주의력 모듈에 의해 출력되는 상기 단어에 대응되는 제1 단어 레벨 오디오 특징을 획득하는 단계 (S501)를 포함할 수 있다. 이로써, 복수의 단어 각각에 대응되는 제1 디코딩 결과를 조회 특징(Q)으로 사용하고, 제1 음성 특징을 키 특징 (K) 및 값 특징(V)으로 사용하여, 인식할 음성에 대한 초기 인식 결과를 선험적 정보로서 효과적으로 이용할 수 있도록 함으로써 각 단어에 대응되는 단어 레벨 오디오 특징을 획득한다. 일부 실시예에서, 주의력 모듈에 의해 출력되는 제1 단어 레벨 오디오 특징은 대응하는 Q, K 및 V를 상술한 주 의력 메커니즘의 공식에 대입하여 계산될 수 있다. 일부 실시예에 따르면, 도 5에 도시된 바와 같이, 제1 선험적 정보에 기반하여 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계(S203)는, 제2 인코더를 이용하여 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩을 수행하여 강화된 제2 음성 특징을 획득하는 단계(S502)를 포함할 수 있다. 이로써, 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩을 수행하여, 제1 인 코더가 스트리밍 인식을 충족해야 하므로 전역적 특징 정보를 인코딩할 수 없는 단점을 효과적으로 보완하여 길 이가 같고 통일된 특징 표현의 설명 기능을 현저하게 향상시킨다. 일부 실시예에서, 제2 인코더는 Conformer 인코더일 수 있고, N층의 적층된 Conformer 모듈을 포함할 수 있다. Conformer 모듈이 주의력 모델과 컨볼루션 모델을 동시에 융합하였으므로 오디오 특징 중 장거리 관계와 국부적 관계에 대한 효과적인 모델링을 동시에 수행할 수 있어 모델의 설명 기능을 크게 향상시킨다. 이해할 수 있는 것은, 또한 주의력 메커니즘, Conformer 인코더를 제외한 방식을 통해 제1 선험적 정보에 기반 하여 제1 음성 특징으로부터 제2 음성 특징을 추출하는 것을 구현할 수 있으며, 이에 한정되지 않는다. 일부 실시예에 따르면, 제2 디코더를 이용하여 제2 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하는 단계(S204)는, 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과 를 제2 디코더의 조회 특징(Q)으로 사용하고, 제2 음성 특징을 제2 디코더의 키 특징(K) 및 값 특징(V)으로 사 용하여, 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계를 포함할 수 있다. 이로써, 복수의 단어 각각에 대응되는 제1 디코딩 결과를 조회 특징(Q)으로 사용하고, 제2 음성 특징을 키 특징 (K) 및 값 특징(V)으로 사용하여, 인식할 음성에 대한 초기 인식 결과를 선험적 정보로서 효과적으로 이용할 수 있도록 함으로써 각 단어에 대응되는 제2 디코딩 결과를 획득한다. 이 밖에, 기존의 인코더-디코더(Encoder-Decoder) 구조 또는 Decoder-Only 구조는 디코딩 시 캐시(Cache) 로딩 문제에 직면하게 된다. GPU의 컴퓨팅 속도는 크게 향상되었지만 컴퓨터 하드웨어 리소스의 발전으로 인해 디코 더가 컴퓨팅 중에 모델 파라미터를 캐시에 로딩하는 속도는 크게 향상되지 않았으며 음성 인식 모델의 디코딩 효율성을 심각하게 제한한다. 또한, Encoder-Decoder 구조의 음성 인식 모델이든 Decoder-Only 구조의 음성 인 식 모델이든 디코딩 시 모두 이전 순간의 디코딩 결과에 의존하여야만 다음 순간의 컴퓨팅을 수행할 수 있으며, 이러한 재귀적 컴퓨팅 방식은 모델이 캐시에 반복적으로 로딩되어 일정한 컴퓨팅 지연을 초래한다. 특히 음성 빅모델 파라미터가 증가함에 따라 캐시 로딩으로 인한 컴퓨팅 지연 문제가 더욱 두드러져 온라인 디코딩의 실시 간 디코딩 요구 사항을 충족할 수 없다. 획득한 복수의 단어 각각에 대응되는 제1 디코딩 결과를 제2 디코더의 조회 특징으로 사용함으로써 단 한 번의 병렬 계산만으로 최종 인식 결과를 얻을 수 있도록 하므로, 빅모델이 직면하는 캐시 로딩 문제를 효과적으로 해결할 수 있다. 일부 실시예에 따르면, 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함할 수 있고, 순방향 디코더 및 역 방향 디코더는 모두 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징(Q)으로 사용하고, 제2 음성 특징을 입력된 키 특징(K) 및 값 특징(V)으로 사용하도록 구성될 수 있으며, 순방향 디코더 는 입력된 특징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성될 수 있고, 역방향 디코더는 입력된 특징 을 오른쪽에서 왼쪽으로 시간적으로 마스킹하도록 구성될 수 있다. 이로써, 입력 특징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하는 순방향 디코더와, 입력 특징을 오른쪽에서 왼 쪽으로 시간적으로 마스킹하는 역방향 디코더를 설정하여 2개의 상이한 방향의 언어 모델링이 가능해지도록 함 으로써 언어 문맥에 대한 동시 모델링이 구현되어 모델의 예측 기능이 더 향상된다. 일부 실시예에서, 순방향 디코더는 왼쪽에서 오른쪽으로(Left-Right)의 Transformer 디코더로 지칭될 수도 있고, 역방향 디코더는 오른쪽에서 왼쪽으로(Right-Left)의 Transformer 디코더로 지칭될 수도 있다. 순방향 디 코더와 역방향 디코더에는 K개의 적층된 시간적으로 마스킹되는 Transformer 모듈이 포함될수 있다. 일부 실시예에 따르면, 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 제2 디코더의 조회 특 징(Q)으로 사용하고, 제2 음성 특징을 제2 디코더의 키 특징(K) 및 값 특징(V)으로 사용하여, 제2 디코더에 의 해 출력되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계는, 순방향 디코더에 의해 출력되는 복수의 단어에 대응되는 복수의 순방향 디코딩 특징 및 역방향 디코더에 의해 출력되는 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 복수의 단어에 대응되는 복수의 융합 특징을 획득하는 단계; 및 복수의 융합 특 징에 기반하여, 복수의 제2 디코딩 결과를 획득하는 단계를 포함할 수 있다. 일부 실시예에서, 순방향 디코딩 특징과 역방향 디코딩 특징을 직접 가하여 대응하는 융합 특징을 획득할 수 있 다. 융합 특징에 대해 Softmax 등 처리를 수행하여 최종 인식 결과를 획득할 수 있다. 제2 디코딩 결과를 획득한 후, 제2 디코딩 결과를 다시 인식 결과의 선험적 정보로 사용하여 단어 레벨 오디오 특징을 다시 추출하거나 제2 디코더를 다시 이용하여 디코딩을 수행할 수 있다. 일부 실시예에 따르면, 도 6에 도시된 바와 같이, 음성 인식 방법은, 복수의 단어 중 각 단어에 대해, 상기 단 어의 제N 디코딩 결과를 제2 디코더의 조회 특징(Q)으로 사용하고, 제2 음성 특징을 제2 디코더의 키 특징(K) 및 값 특징(V)으로 사용하여, 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제N+1 디코딩 결과를 획득하되, 여기서 N은 2보다 크거나 같은 정수인 단계(S605)를 더 포함할 수 있다. 이해할 수 있는 것은, 도 6 중의 단계(S601) 내지 단계(S604)의 동작은 도 2 중의 단계(S201) 내지 단계(S204)의 동작과 유사하므로 여기서 반복 서술하지 않는다. 이로써, 제2 디코더를 이용하여 다중 반복 디코딩을 수행함으로써 음성 인식의 정확도를 향상시킬 수 있다. 일부 실시예에 따르면, 도 7에 도시된 바와 같이, 음성 인식 방법은, 제2 선험적 정보에 기반하여, 제1 음성 특 징으로부터 제3 음성 특징을 추출하되, 제2 선험적 정보는 복수의 제2 디코딩 결과를 포함하고, 제3 음성 특징 은 복수의 단어에 대응되는 복수의 제2 단어 레벨 오디오 특징을 포함하는 단계(S705); 및 제2 디코더를 이용하 여 제3 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제3 디코딩 결과를 획득하되, 제3 디코딩 결과 는 대응하는 단어의 제3 인식 결과를 지시하는 단계(S706)를 더 포함할 수 있다. 이로써, 제2 디코딩 결과를 다시 인식 결과의 선험적으로 하여 단어 레벨 오디오 특징을 다시 추출함으로써 제2 디코더를 이용하여 새로운 단어 레벨 오디오 특징을 디코딩하여 음성 인식의 정확도를 더욱 향상시킬 수 있다. 이해할 수 있는 것은, 도 7 중의 단계(S701) 내지 단계(S704)의 동작은 도 2 중의 단계(S201) 내지 단계(S204) 의 동작과 유사하므로 여기서 반복 서술하지 않는다. 일부 실시예에 따르면, 제2 디코더는 음성 빅모델일 수 있다. 제2 디코더의 모델 규모는 수십억 개의 파라미터 에 달할 수 있으며, 이를 통해 음성에 포함된 언어 정보를 충분히 발굴할 수 있어 모델의 모델링 기능을 크게 향상시킨다. 일부 예시적인 실시예에서, 제2 디코더로 사용되는 음성 빅모델의 파라미터 양은 2B일 수도 있고 다른 10억 레벨 이상의 파라미터 양일 수도 있다. 일부 실시예에서, 제1 디코더(또는 제1 인코더와 제1 디코더로 구성된 모델)의 모델 규모는 예를 들어 수백 메 가바이트일 수 있다. 그 기능은 인식할 음성의 초기 인식 결과를 스트리밍 출력하는 것이므로 대규모 파라미터 가 필요하지 않다. 일부 실시예에서, 도 8에 도시된 바와 같이, 제1 인코더(SMLTA2 Encoder), 제1 디코더(SMLTA2 Decoder), 주의력 모듈(Attention Module), 제2 인코더(Conformer Encoder) 및 제2 디코더(순 방향 디코더(Left-Right Transformer Decoder)와 역방향 디코더(Right-Left Transformer Decoder)를 포함함)는 공통으로 엔드 투 엔드의 음성 빅모델을 구성할 수 있다. 본 발명의 다른 양태에 따르면, 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법을 제공한다. 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함한다. 도 9에 도시된 바와 같이, 트레이닝 방법은, 샘플 음성 및 샘플 음성 중 의 복수의 단어의 실제 인식 결과를 획득하는 단계(S901); 샘플 음성의 제1 샘플 음성 특징을 획득하되, 제1 샘 플 음성 특징은 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함 하는 단계(S902); 제1 디코더를 이용하여 제1 샘플 음성 특징을 디코딩하여 샘플 음성 중의 복수의 단어에 대응 되는 복수의 제1 샘플 디코딩 결과를 획득하되, 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시 하는 단계(S903); 제1 샘플 선험적 정보에 기반하여 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하 되, 제1 샘플 선험적 정보는 복수의 제1 샘플 디코딩 결과를 포함하고, 제2 샘플 음성 특징은 복수의 단어에 대 응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단계(S904); 제2 디코더를 이용하여 제2 샘플 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제2 샘플 디코딩 결과를 획득하되, 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계(S905); 및 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과를 기반으로 딥러닝 모델의 파라미터를 조정하여 트레이닝된 딥러닝 모델을 획득하는 단계(S906) 를 포함한다. 이해할 수 있는 것은, 도 9 중의 단계(S902) 내지 단계(S905)의 동작은 도 2 중의 단계(S201) 내 지 단계(S204)의 동작과 유사하므로 여기서 반복 서술하지 않는다. 이로써, 상기 방식을 통해, 트레이닝된 딥러닝 모델이 인식할 음성의 초기 인식 결과를 선험적으로 하여, 프레 임 레벨 오디오 정보 중 상이한 길이를 갖는 음성 특징 정보로부터 단어 레벨의 길이가 같고 통일된 오디오 특 징 표현을 추출하고, 단어 레벨의 오디오 특징을 디코딩하여 최종 인식 결과를 획득할 수 있도록 함으로써, 기 존의 음성 프레이밍의 특징 표현 길이가 일치하지 않은 난제를 해결하고 음성 인식의 정밀도를 향상시키며 컴퓨 팅 효율을 향상시킨다. 일부 실시예에서, 딥러닝 모델은 또한 제1 인코더, 제2 인코더, 주의력 모듈과 같이 상술한 음성 인식 방법과 관련된 다른 모듈을 더 포함할 수 있다. 딥러닝 모델 중 각 모듈에 대한 동작은 상술한 음성 인식 방법에서 대 응하는 모듈의 동작을 참조할 수도 있다. 일부 실시예에서, 단계(S906)에서, 실제 인식 결과 및 제2 인식 결과에 기반하여 제1 손실값을 결정하고, 제1 손실값에 기반하여 딥러닝 모델의 파라미터를 조정할 수 있다. 일부 실시예에서, 또한 실제 인식 결과 및 제1 인식 결과에 기반하여 제2 손실값을 결정하고, 제1 손실값 및 제2 손실값에 기반하여 딥러닝 모델의 파라미터를 조정할 수 있다. 일부 실시예에서, 제2 손실값은 제1 디코더(및 제1 인코더)의 파라미터를 조정할 수 있고, 제1 손실값은 제2 디코더(및 주의력 모듈, 제2 인코더)의 파라미터를 조정할 수 있으며, 엔드 투 엔드로 딥러닝 모 델의 파라미터를 조정할 수도 있다. 이 밖에, 딥러닝 모델 중의 일부 모듈은 독립적인 트레이닝 또는 사전 트레이닝을 미리 수행할 수 있다. 이해할 수 있는 것은, 또한 다른 방식을 사용하여 딥러닝 모델의 파라미터를 조정 할 수도 있으며 이에 한정되지 않는다. 이해할 수 있는 것은, 상기 트레이닝 방법에 따라 트레이닝하여 얻은 딥러닝 모델을 이용하여 상술한 음성 인식 방법을 수행할 수 있다. 본 발명의 다른 양태에 따르면, 음성 인식 장치를 제공한다. 도 10에 도시된 바와 같이, 장치는, 인식할 음성의 제1 음성 특징을 획득하도록 구성되되, 제1 음성 특징은 인식할 음성 중의 복수의 음성 세그먼트에 대응 되는 복수의 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈; 제1 음성 특징을 디코딩하여, 인식 할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하도록 구성되되, 제1 디코딩 결과는 대응 하는 단어의 제1 인식 결과를 지시하는 제1 디코더; 제1 선험적 정보에 기반하여, 제1 음성 특징으로부터 제2 음성 특징을 추출하도록 구성되되, 제1 선험적 정보는 복수의 제1 디코딩 결과를 포함하고, 제2 음성 특징 은 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모듈; 및 제2 음성 특징을 디코딩하여, 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하도록 구성되되, 제2 디 코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더를 포함한다. 이해할 수 있는 것은, 장치 중의 모듈 내지 모듈의 동작은 도 2 중의 단계(S201) 내지 단계(S204)의 동작과 유사하 므로 여기서 반복 서술하지 않는다. 일부 실시예에 따르면, 음성 특징 인코딩 모듈은 인식할 음성의 원래 음성 특징을 획득하고; 원래 음성 특징에 기반하여 인식할 음성 중의 복수의 스파이크를 결정하며; 원래 음성 특징을 절단하여 복수의 스파이크에 일대일로 대응되는 복수의 음성 세그먼트 특징을 획득하도록 구성될 수 있다. 일부 실시예에 따르면, 원래 음성 특징을 절단하여 복수의 스파이크에 일대일로 대응되는 복수의 음성 세그먼트 특징을 획득하는 단계는, 기설정된 시간 길이를 기반으로 원래 음성 특징을 절단하고, 복수의 스파이크 중 각 스파이크가 위치하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함할 수 있다. 일부 실시예에 따르면, 원래 음성 특징을 절단하여 복수의 스파이크에 일대일로 대응되는 복수의 음성 세그먼트 특징을 획득하는 단계는, 복수의 스파이크를 기반으로 원래 음성 특징을 절단하고, 인접한 2개의 스파이크 사이 마다의 음성 세그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함할 수 있다. 일부 실시예에 따르면, 복수의 음성 세그먼트 특징은 원래 음성 특징에 대해 스트리밍 절단을 수행하여 순차적 으로 획득된 것일 수 있고, 제1 디코더는 복수의 음성 세그먼트 특징에 대해 순차적으로 스트리밍 디코딩을 수 행하도록 구성될 수 있다. 일부 실시예에 따르면, 음성 특징 인코딩 모듈은, 현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하도록 구성되되, 이력 특징 추상 정보는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결 과를 이용하여 이전 음성 세그먼트 특징에 대해 주의력 모델링을 수행함으로써 획득된 것일 수 있다. 음성 특징 인코딩 모듈은 이력 특징 추상 정보를 결합하여 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 획득하도록 구성되는 제1 인코더를 포함할 수 있다. 일부 실시예에 따르면, 제1 인코더는 현재 획득된 음성 세그먼트 특징을 제1 인코더의 조회 특징으로서 수신하 고, 이력 특징 추상 정보와 현재 획득된 음성 세그먼트 특징의 스플라이싱 결과를 제1 인코더의 키 특징 및 값 특징으로서 수신하여 대응하는 강화된 음성 세그먼트 특징을 출력하도록 구성될 수 있다. 일부 실시예에 따르면, 단어 레벨 특징 추출 모듈은 주의력 모듈을 포함할 수 있고, 상기 주의력 모듈은 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 주의력 모듈의 조회 특징으로서 수신하고, 제1 음성 특징을 주의력 모듈의 키 특징 및 값 특징으로서 수신하여 상기 단어에 대응하는 제1 단어 레벨 오디 오 특징을 출력하도록 구성된다. 일부 실시예에 따르면, 단어 레벨 특징 추출 모듈은, 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특 징에 대해 전역적 인코딩을 수행하여 강화된 제2 음성 특징을 획득하도록 구성되는 제2 인코더를 포함할 수 있 다. 일부 실시예에 따르면, 제2 디코더는 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 제2 디코더의 조회 특징으로서 수신하고, 제2 음성 특징을 제2 디코더의 키 특징 및 값 특징으로서 수신하여 상기 단어에 대응되는 제2 디코딩 결과를 출력하도록 구성될 수 있다. 일부 실시예에 따르면, 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함할 수 있고, 순방향 디코더 및 역 방향 디코더는 모두 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징으로서 수신하고, 제2 음성 특징을 입력된 키 특징 및 값 특징으로서 수신하도록 구성될 수 있으며, 순방향 디코더는 입력된 특징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성되고, 역방향 디코더는 입력된 특징을 오른쪽 에서 왼쪽으로 시간적으로 마스킹하도록 구성된다. 일부 실시예에 따르면, 제2 디코더는 순방향 디코더에 의해 출력되는 복수의 단어에 대응되는 복수의 순방향 디 코딩 특징 및 역방향 디코더에 의해 출력되는 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 복수의 단어에 대응되는 복수의 융합 특징을 획득하고; 복수의 융합 특징에 기반하여, 복수의 제2 디코딩 결과 를 획득하도록 구성될 수 있다. 일부 실시예에 따르면, 제2 디코더는 복수의 단어 중 각 단어에 대해, 상기 단어의 제N 디코딩 결과를 제2 디코 더의 조회 특징으로서 수신하고, 제2 음성 특징으로 제2 디코더의 키 특징 및 값 특징으로서 수신하여 상기 단 어에 대응되는 제N+1 디코딩 결과를 출력하도록 구성되되, 여기서 N은 2보다 크거나 같은 정수일 수 있다. 일부 실시예에 따르면, 단어 레벨 특징 추출 모듈은 제2 선험적 정보에 기반하여, 제1 음성 특징으로부터 제3 음성 특징을 추출하도록 구성되되, 제2 선험적 정보는 복수의 제2 디코딩 결과를 포함하고, 제3 음성 특징은 복 수의 단어에 대응되는 복수의 제2 단어 레벨 오디오 특징을 포함할 수 있다. 제2 디코더는 제3 음성 특징을 디 코딩하여 복수의 단어에 대응되는 복수의 제3 디코딩 결과를 획득하도록 구성되되, 제3 디코딩 결과는 대응하는 단어의 제3 인식 결과를 지시할 수 있다. 일부 실시예에 따르면, 제2 디코더는 음성 빅모델일 수 있다. 본 발명의 다른 양태에 따르면, 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치를 제공한다. 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함한다. 도 11에 도시된 바와 같이, 트레이닝 장치는, 샘플 음성 및 샘플 음성 중의 복수의 단어의 실제 인식 결과를 획득하도록 구성되는 획득 모듈; 샘플 음성의 제1 샘플 음성 특징을 획득하도록 구성되되, 제1 샘플 음성 특징은 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복 수의 샘플 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈; 제1 샘플 음성 특징을 디코딩하여, 샘 플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩 결과를 획득하도록 구성되되, 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더; 제1 샘플 선험적 정보에 기반하여 제1 샘 플 음성 특징으로부터 제2 샘플 음성 특징을 추출하도록 구성되되, 제1 샘플 선험적 정보는 복수의 제1 샘플 디 코딩 결과를 포함하고, 제2 샘플 음성 특징은 복수의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징 을 포함하는 단어 레벨 특징 추출 모듈; 제2 샘플 음성 특징을 디코딩하여, 복수의 단어에 대응되는 복수 의 제2 샘플 디코딩 결과를 획득하도록 구성되되, 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지 시하는 제2 디코더; 및 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 딥러 닝 모델의 파라미터를 조정하여 트레이닝된 딥러닝 모델을 획득하도록 구성되는 파라미터 조정 모듈을 포 함한다. 이해할 수 있는 것은, 장치 중의 모듈 내지 모듈의 동작은 도 9 중의 단계(S901) 내 지 단계(S906)의 동작과 유사하므로 여기서 반복 서술하지 않는다. 본 발명의 기술적 해결수단에서, 관련된 사용자 개인 정보의 수집, 저장, 사용, 가공, 전송, 제공 및 공개와 같 은 처리는 모두 관련 법률법규의 규정에 부합되며 공서양속을 위배하지 않는다. 본 발명의 실시예에 따르면, 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한다. 도 12를 참조하면, 본 발명의 각 양태의 하드웨어 기기에 적용될 수 있는 예시로서, 본 발명의 서버 또는 클라 이언트로 사용될 수 있는 전자 기기의 구조 블록도를 설명한다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨 터, 운영 플랫폼, 개인 정보 단말기, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형태의 디지털 전자의 컴퓨터 기기를 의미한다. 전자 기기는 개인 디지털 처리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 의미할 수도 있다. 본문에 표시된 부재, 이들의 연결과 관계, 및 이들의 기능은 단지 예시적인 것으로, 본문에 설명되거나 및/또는 요구된 본 발명의 구 현을 한정하지 않는다. 도 12에 도시된 바와 같이, 전자 기기는 판독 전용 메모리(ROM)에 저장된 컴퓨터 프로그램 또는 저 장 유닛로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 따라 다양하고 적절한 동작 및 처리를 수행할 수 있는 컴퓨팅 유닛을 포함한다. RAM에는 또한 전자 기기의 조작에 필요한 다양한 프로그램 및 데이터가 저장될 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연결된다. 입/출력(I/O) 인터페이스 역시 버스에 연결된다. 입력 유닛, 출력 유닛, 저장 유닛 및 통신 유닛을 포함하는 전자 기기 중의 복 수의 부재는 I/O 인터페이스 연결된다. 입력 유닛은 전자 기기에 정보를 입력할 수 있는 임 의의 유형의 기기일 수 있으며, 입력 유닛은 입력된 숫자 또는 문자 정보를 수신할 수 있고, 전자 기기의 사용자 설정 및 기능 제어와 관련된 키 신호 입력을 발생할 수 있으며, 마우스, 키보드, 터치스크린, 트랙패드, 트랙볼, 조이스틱, 마이크 및/또는 리모컨을 포함할 수 있지만 이에 한정되지 않는다. 출력 유닛은 정보 를 나타낼 수 있는 임의의 유형의 기기일 수 있으며, 디스플레이, 스피커, 비디오/오디오 출력 단말기, 진동기 및/또는 프린터를 포함할 수 있지만 이에 한정되지 않는다. 저장 유닛은 자기 디스크 및 광 디스크를 포 함할 수 있지만 이에 한정되지 않는다. 통신 유닛은 전자 기기가 인터넷 등의 컴퓨터 네트워크 및/ 또는 다양한 통신망을 통해 다른 기기와 정보/데이터를 교환하도록 허용하며, 모뎀, 네트워크 카드, 적외선 통 신 기기, 무선 통신 트랜시버 및/또는 블루투스 기기, 802.11 기기, WiFi 기기, WiMax 기기, 셀룰러 통신 기기 및/또는 유사물과 같은 칩셋을 포함할 수 있지만 이에 한정되지 않는다. 컴퓨팅 유닛은 처리 및 컴퓨팅 기능을 갖는 일반 및/또는 전용 처리 구성요소일 수 있다. 컴퓨팅 유닛 의 일 예는 중앙처리유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공 지능(AI) 컴퓨팅 칩, 기계 학 습 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 처리 프로세서(DSP) 및 적절한 프로세서, 컨트 롤러, 마이크로컨트롤러 등을 포함하지만 이에 한정되지 않는다. 컴퓨팅 유닛은 음성 인식 방법 및/또는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법과 같이 상술한 다양한 방법 및 처리를 수행한다. 예를 들어, 일부 실시예에서, 음성 인식 방법 및/또는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법은 저장 유 닛과 같은 기계 판독 가능 매체에 유형적으로 포함되는 컴퓨터 소프트웨어 프로그램으로 구현될 수 있다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 통해 전자 기기 에 로드되거나 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되어 컴퓨팅 유닛에 의해 실행될 경우, 상술한 음성 인식 방법 및/또는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법 중 하나 이상의 단계를 수행할 수 있다. 대안적으로, 다른 실시예에서, 컴퓨팅 유닛은 임의의 다른 적절한 방식 (예를 들어, 펌웨어에 의해)으로 음성 인식 방법 및/또는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법을 수행하도록 구성될 수 있다. 본문의 이상에서 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 현 장 프로그래머블 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 특수표준제품(ASSP), 시스템 온 칩(SOC), 복합 프로그래머블 논리 기기(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있 다. 이러한 다양한 실시형태는 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있고, 상기 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그래머블 프로세서를 포함하는 프로그래머블 시스템에서 실행되거나 및/ 또는 해석될 수 있으며, 상기 프로그래머블 프로세서는 전용 또는 범용 프로그래머블 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데 이터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치에 전송할 수 있다. 본 발명의 방법을 구현하는 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합으로 편집할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 다른 프로그래머블 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 경우, 흐름도 및/또는 블록도에 지정된 기능/동작이 구현될 수 있도록 한다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적으로 기계에 서 실행되거나, 독립형 소프트웨어 패키지로서 일부는 기계에서 실행되며, 일부는 원격 기계에서 실행되거나 완 전히 원격 기계 또는 서버에서 실행될 수 있다. 본 발명의 컨텍스트에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기에 의해 또는 명령 실행 시 스템, 장치 또는 기기와 결합하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있는 유형 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절 한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 보다 구체적인 예는 하나 이상 의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메모 리(ROM), 소거 가능 프로그래머블 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 휴대용 컴팩트 디스크 판독 전용 메모리(CD-ROM), 광학 저장 기기, 자기 저장 기기 또는 상술한 내용의 임의의 적절한 조합을 포함한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기서 설명된 시스템 및 기술을 구현할 수 있고, 상기 컴 퓨터는 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시 장치) 모니 터); 및 키보드 및 지향 장치(예를 들어, 마우스 또는 트랙 볼)를 구비하며, 사용자는 상기 키보드 및 상기 지 향 장치를 통해 컴퓨터에 입력을 제공한다. 다른 유형의 장치는 또한 사용자와의 인터랙션을 제공할 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피드백, 또 는 촉각 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력)로 사용자로부터의 입력을 수 신할 수 있다. 여기서 설명된 시스템 및 기술은 백그라운드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버로 사용 됨), 또는 미들웨어 부재를 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프론트 엔드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 그래픽 사용자 인터페이스 또는 웹 브라우저를 구비하는 사용자 컴퓨터이고, 사용자 는 상기 그래픽 사용자 인터페이스 또는 웹 브라우저를 통해 여기서 설명된 시스템 및 기술의 실시형태와 인터 랙션할 수 있음), 또는 이러한 백그라운드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임의의 조합을 포함 하는 컴퓨팅 시스템에서 구현될 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워 크)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신 네트워크의 예시로 근거리 통신망(LAN), 광역 통신망 (WAN), 인터넷 및 블록체인 네트워크가 포함된다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고 일반적으로 통신 네트워크를 통해 서로 인터랙션한다. 대응하는 컴퓨터에서 실행되고 또한 서로 클라이언트- 서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있고 분산형 시스템의 서버, 또는 블록체인을 결합한 서버일 수도 있다. 위에서 설명한 다양한 형태의 프로세스를 사용하여 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본 발명에 기재된 각 단계는 병렬로 수행될 수 있거나 순차적으로 수행될 수 있거나 상이한 순서로 수행될 수 있고, 본 발명에서 공개된 기술적 해결수단이 이루고자 하는 결과를 구현할 수만 있으면, 본문은 여 기서 한정하지 않는다. 본 발명의 실시예 또는 예시는 도면을 참조하여 설명되었지만, 상기 방법, 시스템 및 기기는 단지 예시적인 실 시예 또는 예시이며, 본 발명의 범위는 이러한 실시예 또는 예시에 의해 한정되는 것이 아니라 부여된 청구범위 및 동등 범위에 의해서만 한정되는 것을 이해해야 할 것이다. 실시예 또는 예시 중의 다양한 요소는 생략되거나 다른 동등 요소에 의해 대체될 수 있다. 이 밖에, 본 발명에 설명된 것과 다른 순서로 각 단계를 수행할 수 있 다. 또한, 다양한 방식으로 실시예 또는 예시 중의 다양한 요소를 조합할 수 있다. 중요한 것은, 기술의 발전과 더불어, 여기서 설명된 많은 요소는 본 발명 이후에 나타나는 동등한 요소에 의해 교체될 수 있다는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2024-0117069", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은 실시예를 예시적으로 도시하고 명세서의 일부를 구성하며, 명세서의 문자 설명과 함께 실시예의 예시적 인 실시형태를 설명하기 위한 것이다. 도시된 실시예는 단지 예시 목적일 뿐 청구 범위를 제한하지 않는다. 모 든 도면에서 동일한 도면 부호는 유사하지만 반드시 동일하지는 않은 요소를 지칭한다. 도 1은 본 발명의 실시예를 따라 본문에 설명된 다양한 방법이 구현될 수 있는 예시적인 시스템의 모식도를 도 시한다. 도 2는 본 발명의 실시예를 따른 음성 인식 방법의 흐름도를 도시한다. 도 3은 본 발명의 실시예를 따른 인식할 음성의 제1 음성 특징을 획득하는 흐름도를 도시한다. 도 4는 본 발명의 실시예를 따른 이력 특징 추상 기반의 Conformer 스트리밍 다단계 절단 주의력 모델의 모식도 를 도시한다. 도 5는 본 발명의 실시예를 따른 제1 음성 특징으로부터 제2 음성 특징을 추출하는 흐름도를 도시한다. 도 6은 본 발명의 실시예를 따른 음성 인식 방법의 흐름도를 도시한다. 도 7은 본 발명의 실시예를 따른 음성 인식 방법의 흐름도를 도시한다. 도 8은 본 발명의 실시예를 따른 엔드 투 엔드의 음성 빅모델의 모식도를 도시한다. 도 9는 본 발명의 실시예를 따른 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법의 흐름도를 도시한다.도 10은 본 발명의 실시예를 따른 음성 인식 장치의 구조 블록도를 도시한다. 도 11은 본 발명의 실시예를 따른 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치의 구조 블록도를 도시한 다. 도 12는 본 발명의 실시예를 구현할 수 있는 예시적인 전자 기기의 구조 블록도를 도시한다."}
