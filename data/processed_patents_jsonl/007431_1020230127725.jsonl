{"patent_id": "10-2023-0127725", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0045008", "출원번호": "10-2023-0127725", "발명의 명칭": "AI 기반 의료관련 3D 형상 데이터 제공 서버 및 방법", "출원인": "정진혁", "발명자": "정진혁"}}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이; 및신체 대상에 대한 제1 3D 형상 데이터에 실시간 의료 데이터를 반영한 제2 3D 형상 데이터를 생성하여 제공하기위한 프로세서;를 포함하고,상기 프로세서는,상기 신체 대상에 대한 복수의 제1 3D 형상 데이터를 생성하여 저장하고,상기 신체 대상에 대한 식별정보를 포함하는 실시간 의료 데이터를 수신하면, 상기 복수의 제1 3D 형상 데이터로부터 상기 식별정보와 매칭되는 제1 3D 형상 데이터를 추출하고, 및사전 학습된 제1 인공지능 모델을 기초로 상기 제1 3D 형상 데이터에 상기 실시간 의료 데이터를 반영하여 제23D 형상 데이터 생성하여 상기 디스플레이를 통해 출력하는, AI 기반 의료관련 3D 형상 데이터 제공 서버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 실시간 의료 데이터가 건강 검진 데이터를 포함하는 경우,상기 프로세서는,상기 사전 학습된 제1 인공지능 모델을 기초로 상기 제1 3D 형상 데이터로부터 상기 건강 검진 데이터의 항목에매칭되는 신체 대상의 형상에 변화가 있는지 여부를 파악하고, 및 상기 신체 대상의 형상에 변화가 있는 경우, 상기 제1 3D 형상 데이터에 신체 대상의 변화를 반영하여 상기 제23D 형상 데이터 생성하는, AI 기반 의료관련 3D 형상 데이터 제공 서버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 신체 대상은, 신체 장기 및 신체 기관을 포함하고, 상기 프로세서는,상기 제2 3D 형상 데이터를 생성할 때, 변화된 상기 신체 장기 또는 상기 신체 기관의 형상이 반영된 3D 형상이미지 및 안내 메시지를 포함하는 상기 제2 3D 형상 데이터를 생성하는, AI 기반 의료관련 3D 형상 데이터 제공 서버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 실시간 의료 데이터가 건강 측정 데이터를 포함하는 경우,상기 프로세서는,상기 사전 학습된 제1 인공지능 모델을 기초로 상기 제1 3D 형상 데이터에 상기 건강 측정 데이터의 항목에 매칭되는 신체 대상의 변화를 반영하여 제2 3D 형상 데이터 생성하는, AI 기반 의료관련 3D 형상 데이터 제공 서공개특허 10-2025-0045008-3-버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 건강 측정 데이터는 신체 체형 스캔 데이터, 신체 사이즈, 체중, 골격근량, 체지방량, 체수분, 단백질, 무기질, BMI 체질량지수, 체지방률, 복부지방률 및 기초대사량을 비롯한 사용자의 건강 측정 데이터를 포함하고,상기 프로세서는,상기 제1 인공지능 모델을 이용하여 상기 제1 3D 형상 데이터의 3D 형상 이미지에 상기 건강 측정 데이터를 기초로 파악된 사용자의 변화된 신체 형상(body shape)을 반영하여 상기 제2 3D 형상 데이터를 생성하는, AI 기반의료관련 3D 형상 데이터 제공 서버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 실시간 의료 데이터가 사용자의 의료 관련 직무에 대한 경력, 자격증, 학위 및 교육 이수 정보를 포함하는사용자 정보를 포함하는 경우,상기 프로세서는,상기 사전 학습된 제1 인공지능 모델을 이용하여 상기 사용자 정보를 기초한 사용자 학습 레벨을 결정하고 상기제1 3D 형상 데이터를 상기 사용자 학습 레벨에 따라 차별화된 학습 커리큘럼에 대응되는 상기 제2 3D 형상 데이터로 생성하는, AI 기반 의료관련 3D 형상 데이터 제공 서버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 프로세서는,상기 제2 3D 형상 데이터의 3D 형상 이미지를 생성할 때, 정상 사이즈 3D 형상 이미지, 확대 사이즈 3D 형상 이미지, 축소 사이즈 3D 형상 이미지, 사전 설정된 방향별의 3D 형상 이미지 및 변화가 발생된 신체 대상의 인접한 신체 대상의 3D 형상 이미지 중 적어도 하나 이상을 포함하는 상기 3D 형상 이미지를 생성하는, AI 기반 의료관련 3D 형상 데이터 제공 서버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 프로세서는,상기 신체 대상에 대한 3D 스캔 데이터, 측량 데이터 및 형상 데이터를 제2 인공지능 모델을 입력하여 사전 설정된 형상 기준에 따라 출력되는 상기 제1 3D 형상 데이터를 획득하는, AI 기반 의료관련 3D 형상 데이터 제공서버."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "3D 형상 데이터 제공 서버에 의해 수행되는 방법에 있어서,신체 대상에 대한 복수의 제1 3D 형상 데이터를 생성하여 저장하는 단계;공개특허 10-2025-0045008-4-상기 신체 대상에 대한 식별정보를 포함하는 실시간 의료 데이터를 수신하는 단계;상기 복수의 제1 3D 형상 데이터로부터 상기 식별정보와 매칭되는 제1 3D 형상 데이터를 추출하는 단계; 및사전 학습된 제1 인공지능 모델을 기초로 상기 제1 3D 형상 데이터에 상기 실시간 의료 데이터를 반영하여 제23D 형상 데이터 생성하여 출력하는 단계를 포함하는, AI 기반 의료관련 3D 형상 데이터 제공 방법."}
{"patent_id": "10-2023-0127725", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "AI 기반 의료관련 3D 형상 데이터 제공 서버 및 방법이 개시된다. 본 발명의 일 실시예에 따른 3D 형상 데이터 제공 서버는, 신체 대상에 대한 복수의 제1 3D 형상 데이터를 생성하여 저장하고, 신체 대상에 대한 식별정보를 포함하는 실시간 의료 데이터를 수신하면, 복수의 제1 3D 형상 데이터로부터 식별정보와 매칭되는 제1 3D 형상 데이터를 추출하고, 및 사전 학습된 제1 인공지능 모델을 기초로 제1 3D 형상 데이터에 실시간 의료 데이터를 반 영하여 제2 3D 형상 데이터 생성하여 상기 디스플레이를 통해 출력한다."}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시되는 실시예들은 AI 기반 의료관련 3D 형상 데이터 제공 서버 및 방법과 관련된다."}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "3D 스캔 영상은 3D 스캐너를 이용하여 스캔 대상인 물체의 형상 정보를 획득하고 디지털화 하여 획득할 수 있다. 이러한 3D 스캔 영상은 자동차 분야, 건축 분야, 피규어 제작 등 다양한 분야에서 다양한 목적으로 사용 하게 되었다. 관련 분야 운용자는 3D 스캔 영상의 활용 범위를 보다 확장하여 사용자들의 편의를 향상시키기 위한 방안을 모 색하게 되었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-1747172호 (2017. 06. 08.)"}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은 의료 분야에서 발생하는 각종 실시간 의료 데이터를 기초로 파악되는 변화를 3D 형상 데이터 로 가시화하여 제공하기 위한 AI 기반 의료관련 3D 형상 데이터 제공 서버 및 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 AI 기반 의료관련 3D 형상 데이터 제공 서버는, 디스플레이; 및 신체 대상에 대한 제1 3D 형 상 데이터에 실시간 의료 데이터를 반영한 제2 3D 형상 데이터를 생성하여 제공하기 위한 프로세서;를 포함하고, 상기 프로세서는, 상기 신체 대상에 대한 복수의 제1 3D 형상 데이터를 생성하여 저장하고, 상기 신 체 대상에 대한 식별정보를 포함하는 실시간 의료 데이터를 수신하면, 상기 복수의 제1 3D 형상 데이터로부터 상기 식별정보와 매칭되는 제1 3D 형상 데이터를 추출하고, 및 사전 학습된 제1 인공지능 모델을 기초로 상기 제1 3D 형상 데이터에 상기 실시간 의료 데이터를 반영하여 제2 3D 형상 데이터 생성하여 상기 디스플레이를 통 해 출력한다. 상기 실시간 의료 데이터가 건강 검진 데이터를 포함하는 경우, 상기 프로세서는, 상기 사전 학습된 제1 인공지 능 모델을 기초로 상기 제1 3D 형상 데이터로부터 상기 건강 검진 데이터의 항목에 매칭되는 신체 대상의 형상 에 변화가 있는지 여부를 파악하고, 및 상기 신체 대상의 형상에 변화가 있는 경우, 상기 제1 3D 형상 데이터에신체 대상의 변화를 반영하여 상기 제2 3D 형상 데이터 생성할 수 있다. 상기 신체 대상은, 신체 장기 및 신체 기관을 포함하고, 상기 프로세서는, 상기 제2 3D 형상 데이터를 생성할 때, 변화된 상기 신체 장기 또는 상기 신체 기관의 형상이 반영된 3D 형상 이미지 및 안내 메시지를 포함하는 상기 제2 3D 형상 데이터를 생성할 수 있다. 상기 실시간 의료 데이터가 건강 측정 데이터를 포함하는 경우, 상기 프로세서는, 상기 사전 학습된 제1 인공지 능 모델을 기초로 상기 제1 3D 형상 데이터에 상기 건강 측정 데이터의 항목에 매칭되는 신체 대상의 변화를 반 영하여 제2 3D 형상 데이터 생성할 수 있다. 상기 건강 측정 데이터는 신체 체형 스캔 데이터, 신체 사이즈, 체중, 골격근량, 체지방량, 체수분, 단백질, 무 기질, BMI 체질량지수, 체지방률, 복부지방률 및 기초대사량을 비롯한 사용자의 건강 측정 데이터를 포함할 수 있다. 상기 프로세서는, 상기 제1 인공지능 모델을 이용하여 상기 제1 3D 형상 데이터의 3D 형상 이미지에 상기 건강 측정 데이터를 기초로 파악된 사용자의 변화된 신체 형상(body shape)을 반영하여 상기 제2 3D 형상 데이 터를 생성할 수 있다. 상기 실시간 의료 데이터가 사용자의 의료 관련 직무에 대한 경력, 자격증, 학위 및 교육 이수 정보를 포함하는 사용자 정보를 포함하는 경우, 상기 프로세서는, 상기 사전 학습된 제1 인공지능 모델을 이용하여 상기 사용자 정보를 기초한 사용자 학습 레벨을 결정하고 상기 제1 3D 형상 데이터를 상기 사용자 학습 레벨에 따라 차별화 된 학습 커리큘럼에 대응되는 상기 제2 3D 형상 데이터로 생성할 수 있다. 상기 프로세서는, 상기 제2 3D 형상 데이터의 3D 형상 이미지를 생성할 때, 정상 사이즈 3D 형상 이미지, 확대 사이즈 3D 형상 이미지, 축소 사이즈 3D 형상 이미지, 사전 설정된 방향별의 3D 형상 이미지 및 변화가 발생된 신체 대상의 인접한 신체 대상의 3D 형상 이미지 중 적어도 하나 이상을 포함하는 상기 3D 형상 이미지를 생성 할 수 있다. 상기 프로세서는, 상기 신체 대상에 대한 3D 스캔 데이터, 측량 데이터 및 형상 데이터를 제2 인공지능 모델을 입력하여 사전 설정된 형상 기준에 따라 출력되는 상기 제1 3D 형상 데이터를 획득할 수 있다. 다른 실시예에 따른 AI 기반 의료관련 3D 형상 데이터 제공 방법은, 3D 형상 데이터 제공 서버에 의해 수행되는 방법에 있어서, 신체 대상에 대한 복수의 제1 3D 형상 데이터를 생성하여 저장하는 단계; 상기 신체 대상에 대 한 식별정보를 포함하는 실시간 의료 데이터를 수신하는 단계; 상기 복수의 제1 3D 형상 데이터로부터 상기 식 별정보와 매칭되는 제1 3D 형상 데이터를 추출하는 단계; 및 사전 학습된 제1 인공지능 모델을 기초로 상기 제1 3D 형상 데이터에 상기 실시간 의료 데이터를 반영하여 제2 3D 형상 데이터 생성하여 출력하는 단계를 포함한다. 이 외에도, 개시되는 실시예를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시되는 실시예들에 따르면, 사용자의 외형 및 내형을 3D 형상 데이터로 생성한 후, 건강 검진 데이터, 건강 측정 데이터 및 사용자 정보를 비롯한 실시간 의료 데이터를 기초로 파악되는 변화된 형상을 3D 형상 데이터에 반영하여 제공할 수 있다는 효과를 기대할 수 있다. 또한, 개시되는 실시예들에 따르면, 사용자가 자신의 변화되는 신체 내형 및 외형을 직관적으로 확인할 수 있으 며, 이를 통해 자신의 건강 상태에 대해 신속하게 파악하고 보다 체계적인 건강 관리를 수행할 수 있다는 효과 를 기대할 수 있다."}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 도 1은 일 실시예에 따른 3D 형상 데이터 제공 서버를 설명하기 위한 블록도이다. 이하에서는, 일 실시예에 따른 3D 형상 데이터 제공 방법을 설명하기 위한 예시도인 도 2 내지 도 6을 참고하여 설명하기로 한다. 도 1을 참고하면, 3D 형상 데이터 제공 서버는 프로세서, 메모리, 통신부 및 디스플레이 를 포함한다. 도 1에 도시된 구성요소들은 본 개시에 따른 3D 형상 데이터 제공 서버를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 3D 형상 데이터 제공 서버는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 도 1에 도시된 구성요소들은 통신 네트워크(미도시)를 통해 서로 간에 통신 가능하게 연결될 수 있다. 몇몇 실 시예들에서, 통신 네트워크는 인터넷, 하나 이상의 로컬 영역 네트워크(local area networks), 광역 네트워크 (wire area networks), 셀룰러 네트워크, 모바일 네트워크, 그 밖에 다른 종류의 네트워크들, 또는 이러한 네트 워크들의 조합을 포함할 수 있다. 프로세서는 신체 대상에 대한 제1 3D 형상 데이터에 실시간 의료 데이터를 반영한 제2 3D 형상 데이터를 생성하여 제공하기 위한 구성일 수 있다. 도 2를 참고하면, 제1 3D 형상 데이터는 신체 대상을 내시경을 비롯한 3D 스캐너(미도시)를 통해 스캔하여 획득한 3D 스캔 데이터의 포인트 클라우드를 최적화하여 생성된 데이터일 수 있다. 이때, 제1 3D 형상 데이터는 3D 형상 이미지뿐만 아니라 스캔된 신체 대상과 관련된 각종 정보(예를 들어, 신체 대상명 등)를 추가로 포함할 수 있다. 이에 대한 상세 설명은 후술하기로 한다. 상기 신체 대상은 위, 창자, 간, 콩팥 및 이자를 비롯한 내장의 여러 기관을 포함하는 신체 장기, 및 치아 및 잇몸을 비롯한 신체 기관을 포함할 수 있으며, 이에 한정되지 않고, 신체 외형을 추가로 포함할 수 있다. 구체적으로, 프로세서는 신체 대상에 대한 복수의 제1 3D 형상 데이터를 생성하여 저장할 수 있다. 이때, 프로세서는 복수의 사용자 각자의 신체 대상에 대해 획득된 복수의 제1 3D 형상 데이터를 메모리에 저장할 수 있다. 상기 복수의 제1 3D 형상 데이터는 각각을 식별할 수 있는 식별정보를 포함할 수 있다. 도 3을 참고하면, 프로세서는 신체 대상에 대한 식별정보를 포함하는 실시간 의료 데이터를 수신하면, 복 수의 제1 3D 형상 데이터로부터 식별정보와 매칭되는 제1 3D 형상 데이터를 추출할 수 있다. 상기 식별정보는 상술한 제1 3D 형상 데이터에 부여된 식별정보를 의미할 수 있다. 프로세서는 사전 학습된 제1 인공지능 모델을 기초로 제1 3D 형상 데이터에 실시간 의료 데이터를 반영하 여 제2 3D 형상 데이터 생성하여 디스플레이를 통해 출력할 수 있다. 상기 실시간 의료 데이터는 건강 검진 데이터, 건강 측정 데이터 및 사용자 정보를 포함할 수 있다. 이하에서는, 실시간 의료 데이터의 종류에 따라 제2 3D 형상 데이터를 생성하는 방법을 구체적으로 설명하기로 한다.일 예로, 실시간 의료 데이터가 건강 검진 데이터를 포함하는 경우, 프로세서는 사전 학습된 제1 인공지능 모델을 기초로 제1 3D 형상 데이터로부터 건강 검진 데이터의 항목에 매칭되는 신체 대상의 형상에 변화가 있는 지 여부를 파악할 수 있다. 신체 대상의 형상에 변화가 있는 경우, 프로세서는 제1 3D 형상 데이터에 신체 대상의 변화를 반영하여 제2 3D 형상 데이터 생성할 수 있다. 상기 신체 대상은, 신체 장기 및 신체 기관을 포 함할 수 있다. 상기 건강 검진 데이터는 의료 기관에서의 검진을 통해 획득된 데이터를 의미할 수 있다. 예를 들어, 건강 검진 데이터는 시각, 청각, 고혈압, 빈혈증 및 당뇨 등의 일반건강검진 항목과 위암, 대장암, 간암, 폐암 및 유방암 등의 암 검진 항목 등에 따라 검진된 결과를 포함할 수 있다. 상기 건강 검진 데이터는 동영상 및 정지영상을 포함하는 이미지, 수치 및 문자 형태 중 적어도 하나 이상을 포함하는 형태일 수 있다. 프로세서는 제2 3D 형상 데이터를 생성할 때, 변화된 신체 장기 또는 신체 기관의 형상이 반영된 3D 형상 이미지 및 안내 메시지를 포함하는 제2 3D 형상 데이터를 생성할 수 있다. 상기 안내 메시지는 신체 대상의 변 화된 형상과 관련된 설명을 위한 메시지로, 예를 들어, 질환명 및 질환에 대한 설명 등을 포함할 수 있다. 이때, 안내 메시지는 질환을 개선하기 위한 방법(운동, 식이, 처방 등)을 추가로 포함할 수 있다. 도 4를 참고하면, 프로세서는 제1 3D 형상 데이터의 3D 형상 이미지(a)에서 건강 검진 데이터를 기초로 특 정 신체 장기의 변화된 부분을 인식하면, 변화된 부분을 반영한 제2 3D 형상 이미지와 안내 메시지(예측되는 질 환명(예를 들어, 심혈관 질환))을 포함하여 제2 3D 형상 데이터(b)를 생성할 수 있다. 이를 위해, 제1 인공지능 모델은 각종 질환과 관련된 이미지 및 이와 매칭되는 질환명을 기초로 사전 학습할 수 있다. 일 예로, 실시간 의료 데이터가 이미지를 포함하는 경우, 프로세서는 제1 3D 형상 데이터의 3D 형상 이미 지와 이미지 형태의 실시간 의료 데이터를 비교하여, 변화된 부분을 파악할 수 있다. 다른 예로, 실시간 의료 데이터가 문자 형태인 경우, 프로세서는 사전 학습 된 제1 인공지능 모델을 이용 하여 실시간 의료 데이터(예를 들어, 건강 검진 데이터, 건강 측정 데이터 및 사용자 정보 등)를 기초한 신체 대상의 형상의 변화를 예측할 수 있다. 이를 위해, 제1 인공지능 모델은 문자 형태의 실시간 의료 데이터별 형 상 변화를 예측 및 출력하는 학습 절차를 사전에 수행할 수 있다. 도 5를 참고하면, 프로세서는 제2 3D 형상 데이터를 생성할 때, (a-1) 및 (b-1)과 같이 신체 장기의 변화 된 부분이 반영된 제2 3D 형상 이미지 및 안내 메시지를 생성하는 것 뿐만 아니라, 신체 대상 중 변화된 부분의 위치(D1의 위치, D2의 위치)를 포함하는 이미지도 추가로 포함하여 생성할 수 있다. 예를 들어, 프로세서 는 신체 장기 중 질환이 발생한 영역을 가시적으로 상세하게 확인할 수 있는 3D 이미지와 신체 장기 중 해당 질 환의 세부위치((a-2)의 D1의 위치, (b-2)의 D2의 위치)를 확인할 수 있는 3D 이미지를 생성하는 것이다. 다른 예로, 실시간 의료 데이터가 건강 측정 데이터를 포함하는 경우, 프로세서는 사전 학습된 제1 인공지 능 모델을 기초로 제1 3D 형상 데이터에 건강 측정 데이터의 항목에 매칭되는 신체 대상의 변화를 반영하여 제2 3D 형상 데이터 생성할 수 있다. 상기 건강 측정 데이터는 의료 기관이 아니더라도 체성분 검사 항목에 따라 측정되거나, 또는 신체 외형이 스캔 된 데이터를 포함할 수 있다. 예를 들어, 건강 측정 데이터는 신체 체형 스캔 데이터, 신체 사이즈, 체중, 골격 근량, 체지방량, 체수분, 단백질, 무기질, BMI 체질량지수, 체지방률, 복부지방률 및 기초대사량을 비롯한 사용 자의 건강 측정 데이터를 포함할 수 있다. 프로세서는 제1 인공지능 모델을 이용하여 제1 3D 형상 데이터의 3D 형상 이미지에 건강 측정 데이터를 기 초로 파악된 사용자의 변화된 신체 형상(body shape)을 반영하여 제2 3D 형상 데이터를 생성할 수 있다. 이를 위해, 제1 인공지능 모델은 건강 측정 데이터를 기초로 신체의 형상 변화를 예측할 수 있도록 사전 학습될 수 있다. 도 6을 참고하면, 프로세서는 제1 3D 형상 데이터의 3D 형상 이미지(a)에 변화된 신체의 형상(예를 들어, P1, P4: 복부비만, P2: 하체비만, P3: 전체 비만 등)을 반영한 제2 3D 형상 데이터를 생성할 수 있다. 다른 예로, 실시간 의료 데이터가 사용자의 의료 관련 직무에 대한 경력, 자격증, 학위 및 교육 이수 정보를 포 함하는 사용자 정보를 포함할 수 있다. 이때, 프로세서는 사전 학습된 제1 인공지능 모델을 이용하여 사용 자 정보를 기초한 사용자 학습 레벨을 결정하고 제1 3D 형상 데이터를 사용자 학습 레벨에 따라 차별화된 학습 커리큘럼에 대응되는 제2 3D 형상 데이터로 생성할 수 있다. 이를 위해, 제1 인공지능 모델은 사용자 정보를 기 초로 사용자 학습 레벨을 결정하고, 사용자 학습 레벨에 따라 사전 매칭된 학습 커리큘럼에 대응되는 제2 3D 형상 데이터를 출력할 수 있도록 사전 학습될 수 있다. 예를 들어, 사용자가 의사를 비롯한 의료계 종사자이고, 사용자 레벨(1레벨 ~ 5레벨)이 초급(1레벨)인 경우, 프로세서는 제1 3D 형상 데이터에 각 질환을 식별할 수 있도록 하는 3D 형상 이미지 및 안내 메시지를 반영하여 제2 3D 형상 데이터를 생성할 수 있다. 또한, 사용 자가 의사를 비롯한 의료계 종사자이고, 사용자 레벨(1레벨 ~ 5레벨)이 고급(2레벨)인 경우, 프로세서는 제1 3D 형상 데이터에 특정 질환을 식별할 수 있도록 하는 3D 형상 이미지, 상기 특정 질환과 관련된 다양한 수 술법을 확인할 수 있도록 하는 3D 형상 이미지 및 안내 메시지를 포함하여 제2 3D 형상 데이터를 생성할 수 있 다. 상술한 예시는 일 예로, 사용자 학습 레벨별 학습 커리큘럼의 차별은 운용자의 필요에 따라 생성, 추가 및 변경 될 수 있다. 상술한 제1 인공지능 모델은 실시간 의료 데이터의 종류에 따라 각각 별도로 구현될 수도 있다. 프로세서는 제2 3D 형상 데이터의 3D 형상 이미지를 생성할 때, 정상 사이즈 3D 형상 이미지, 확대 사이즈 3D 형상 이미지, 축소 사이즈 3D 형상 이미지, 사전 설정된 방향별의 3D 형상 이미지 및 변화가 발생된 신체 대 상의 인접한 신체 대상의 3D 형상 이미지 중 적어도 하나 이상을 포함하는 3D 형상 이미지를 생성할 수 있다. 이때, 3D 형상 이미지는 단일 프레임 또는 다수의 프레임을 포함하는 동영상일 수 있다. 만약, 3D 형상 이미지 가 동영상일 경우, 프로세서는 동영상을 재생할 시간(동영상의 길이)을 사전에 설정할 수 있다. 도 2를 참고하면, 프로세서는 신체 대상에 대한 3D 스캔 데이터, 측량 데이터 및 형상 데이터를 제2 인공 지능 모델을 입력하여 사전 설정된 형상 기준에 따라 출력되는 제1 3D 형상 데이터를 획득할 수 있다. 구체적으로, 프로세서는 내시경을 비롯한 3D 스캐너를 통한 3D 스캐닝을 통해 3D 스캔 데이터를 획득할 수 있다. 이때, 프로세서는 포인트 클라우드 데이터를 획득할 수 있다. 프로세서는 포인트 클라우드 최 적화 수행하여 삼각형의 메쉬 데이터 형태인 제1 3D 형상 데이터를 획득할 수 있다. 예를 들어, 제1 3D 형상 데 이터는 사용자의 신체 장기 및 신체 기관의 3D 형상 이미지를 포함하거나, 또는 사용자의 신체 외형의 3D 형상 이미지를 포함할 수 있다. 이때, 프로세서는 사전 학습 시 3D 스캔 데이터 뿐만 아니라, 측정 데이터 및 다양한 형상 데이터를 추가 입력 데이터로 학습된 제2 인공지능 모델을 통해, 보다 완성도 있는 제1 3D 형상 데 이터를 획득할 수 있다. 상기 측정 데이터는 데이터 기반 측정 데이터 및 임의 수치 데이터를 포함할 수 있다. 상기 다양한 형상 데이터는 동영상 및 정지영상을 포함하는 신체 대상 관련 이미지를 의미할 수 있다. 개시되는 프로세서는 제1 3D 형상 데이터를 생성할 때, 3D 스캔 데이터 뿐만 아니라, 측정 데이터(예를 들어, 신체 사이즈 등) 및 다양한 형상 데이터(예를 들어, 신체 각 기관의 형상 이미지)를 반영하여, 보다 명확한 제1 3D 형상 데이터를 획득할 수 있다. 한편, 프로세서는 제2 3D 형상 데이터를 제공할 때, 가상현실(virtual reality, VR), 증강현실(augmented reality, AR) 또는 확장현실(eXtended reality, XR)을 적용하여, 고객(운용자를 비롯한 사용자)의 목적에 맞게 보다 실감나는 제2 3D 형상 데이터를 제공할 수 있다. 예를 들어, 프로세서는 사용자 학습 레벨에 따라 차 별화된 학습 커리큘럼에 대응되는 제2 3D 형상 데이터로 생성할 때, 질환에 대한 수술 교육 영상을 생성하는 경 우, 상술한 가상현실, 증강현실 또는 확장현실 기술을 적용할 수 있다. 본 개시의 프로세서는 하나 이상의 코어로 구성될 수 있으며, 컴퓨팅 장치의 중앙 처리 장치(central processing unit), 범용 그래픽 처리 장치 (general purpose graphics processing unit), 텐서 처리 장치 (tensor processing unit) 등의 데이터 분석, 딥러닝을 위한 프로세서를 포함할 수 있다. 프로세서는 메모 리에 저장된 컴퓨터 프로그램을 판독하여 본 개시에 따른 기계 학습을 위한 데이터 처리를 수행할 수 있다. 본 개시에 따라 프로세서는 신경망의 학습을 위한 연산을 수행할 수 있다. 프로세서는 딥러닝 (deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파 (backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망의 학습을 위한 계산을 수행할 수 있다. 상기 뉴럴 네트워크 모델은 딥 뉴럴 네트워크일 수 있다. 본 개시에서, 신경망, 네트워크 함수, 뉴럴 네트워크 (neural network)는 동일 한 의미로 사용될 수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경 망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트 워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(예를 들어, 어떤 물체가 사진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감 정이 무엇인지 등)를 파악할 수 있다. 딥 뉴럴 네트워크는 컨벌루셔널 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), 제한 볼츠만 머신(RBM:restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크 등을 포함할 수 있다. 컨벌루셔널 뉴럴 네트워크는 딥 뉴럴 네트워크의 일종으로서, 컨벌루셔널 레이어를 포함하는 신경망을 포함한다. 컨벌루셔널 뉴럴 네트워크는, 최소 한의 전처리(preprocess)를 사용하도록 설계된 다계층 퍼셉트론 (multilayer perceptrons)의 한 종류이다. CNN은 하나 또는 여러 개의 컨벌루셔널 레이어와 이와 결합된 인공 신경망 계층들로 구성될 수 있다. CNN은 가중치와 풀링 레이어(pooling layer)들을 추가로 활용할 수 있다. 이 러한 구조 덕분에 CNN은 2차원 구 조의 입력 데이터를 충분히 활용할 수 있다. 컨벌루셔널 뉴럴 네트워크는 이 미지에서 오브젝트를 인식하기 위하여 사용될 수 있다. 컨벌루셔널 뉴럴 네트워크는, 이미지 데이터를 차원을 가진 행렬로 나타내어 처리할 수 있다. 예를 들어 RGB(red-green-blue)로 인코딩 된 이미지 데이터의 경우, R, G, B 색상별로 각각 2 차원(예를 들어, 2 차원 이미지 인 경우) 행렬로 나타내 질 수 있다. 즉, 이미지 데이터 의 각 픽셀의 색상 값이 행렬의 성분이 될 수 있으며 행렬의 크기는 이미지의 크기와 같을 수 있다. 따라서, 이 미지 데이터는 3개의 2차원 행렬로(3차원의 데이터 어레이)로 나타내질 수 있다. 컨벌루셔널 뉴럴 네트워크에서, 컨벌루셔널 필터를 이동해가며 컨벌루셔널 필터와 이미지의 각 위치에서의 행렬 성분끼리 곱하는 것으로 컨벌루셔널 과정(컨벌루셔널 레이어의 입출력)을 수행할 수 있다. 컨벌루셔널 필터는 n*n 형태의 행렬로 구성될 수 있다. 컨벌루셔널 필터는, 일반적으로 이미지의 전체 픽셀의 수보다 작은 고정된 형태의 필터로 구성될 수 있다. 즉, m*m 이미지를 컨벌루셔널 레이어(예를 들어, 컨벌루셔널 필터의 사이즈가 n*n인 컨벌루셔널 레이어)입력시키는 경우, 이미지의 각 픽셀을 포함하는 n*n 픽셀을 나타내는 행렬이 컨벌루셔 널 필터와 성분 곱 (즉, 행렬의 각 성분끼리의 곱) 될 수 있다. 컨벌루셔널 필터와의 곱에 의하여 이 미지에서 컨벌루셔널 필터와 매칭되는 성분이 추출될 수 있다. 예를 들어, 이미지에서 상하 직선 성분을 추출하기 위한 3*3 컨벌루셔널 필터는 [[0,1,0], [0,1,0], [0,1,0]] 와 같이 구성될 수 있다. 이미지에서 상하 직선 성분을 추 출하기 위한 3*3 컨벌루셔널 필터가 입력 이미지에 적용되면 이미지에서 컨벌 루셔널 필터와 매칭되는 상하 직 선 성분이 추출되어 출력될 수 있다. 컨벌루셔널 레이어는 이미지를 나타낸 각각의 채널에 대한 각각의 행렬(즉, R, G, B 코딩 이미 지의 경우, R, G, B 색상)에 컨벌루셔널 필터를 적용할 수 있다. 컨벌루셔널 레이 어는 입력 이미지에 컨벌루셔널 필터를 적용하여 입력 이미지에서 컨벌루셔널 필터 와 매칭되는 피쳐를 추출할 수 있다. 컨벌루셔널 필터의 필터 값(즉, 행렬의 각 성 분의 값)은 컨벌루셔널 뉴럴 네트워크의 학습 과정에서 역전파에 의하여 업데이트 될 수 있다. 컨벌루셔널 레이어의 출력에는, 서브샘플링 레이어가 연결되어 컨벌 루셔널 레이어의 출력을 단순화하여 메모리 사용량과 연산량을 줄일 수 있다. 예를 들어, 2*2 맥스 풀링 필터를 가지는 풀링 레이어에 컨벌루셔널 레이어의 출력을 입 력시키는 경우, 이미지의 각 픽셀에서 2*2 패치마다 각 패치에 포함되는 최대값을 출력하여 이미지를 압축할 수 있다. 전술한 풀링은 패치에서 최소값을 출력하거나, 패치의 평균값을 출력하는 방식일 수도 있으며 임의의 풀링 방식이 본 개시에 포함될 수 있다 컨벌루셔널 뉴럴 네트워크는, 하나 이상의 컨벌루셔널 레이어, 서브 샘플링 레이어를 포함할 수 있다. 컨벌루셔 널 뉴럴 네트워크는 컨벌루셔널 과정과 서브샘플링 과정(예를 들어, 전술한 맥스 풀링 등)을 반복적으로 수행하 여 이미지에서 피쳐를 추출할 수 있다. 반복적인 컨벌루션널 과정과 서브샘플링 과정을 통해 뉴럴 네트워크는 이미지의 글로벌 피쳐를 추출할 수 있다. 컨벌루셔널 레이어 또는 서브샘플링 레이어의 출력은 풀 커넥티드 레이어(fully connected layer)에 입력될 수 있다. 풀 커넥티드 레이어는 하나의 레이어에 있는 모든 뉴런과 이웃한 레이어에 있는 모든 뉴런이 연결되는 레 이어이 다. 풀 커넥티드 레이어는 뉴럴 네트워크에서 각 레이어의 모든 노드가 다른 레이 어의 모든 노드에 연 결된 구조를 의미할 수 있다. 프로세서의 CPU, GPGPU, 및 TPU 중 적어도 하나가 네트워크 함수의 학습을 처리할 수 있다. 예를 들어, CPU와 GPGPU가 함께 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 개시의 일 실시예에서 복수의 컴퓨팅 장치의 프로세서를 함께 사용하여 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 개시의 일 실시예에 따른 컴퓨팅 장치에서 수행되는 컴퓨터 프 로그램은, CPU, GPGPU 또는 TPU 실행가능 프로그램일 수 있다. 메모리는 3D 형상 데이터 제공 방법을 제공하기 위한 컴퓨터 프로그램을 저장할 수 있으며, 저장된 컴퓨터 프로그램은 프로세서에 의해 판독되어 구동될 수 있다. 메모리는 프로세서가 생성하거나 결정한 임의의 형태의 정보 및 통신부가 수신한 임의의 형태의 정보를 저장할 수 있다.메모리는 3D 형상 데이터 제공 서버의 다양한 기능을 지원하는 데이터와, 프로세서의 동작을 위 한 프로그램을 저장할 수 있고, 입/출력되는 데이터들을 저장할 있고, 3D 형상 데이터 제공 서버에서 구동 되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 3D 형상 데이터 제공 서버 의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통 신을 통해 외부 서버로부터 다운로드 될 수 있다. 상술한 메모리는 후술하는 컴퓨팅 장치의 컴퓨터 판독 가능 저장 매체일 수 있다. 이러한, 메모리 는 플래시 메모리 타입(Flash memory type), 하드디스크 타입(Hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(Multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(Random access memory; RAM), SRAM(Static random access memory), 롬(Read-only memory; ROM), EEPROM(Electrically erasable programmable read-only memory), PROM(Programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 타 입의 저장매체를 포함할 수 있다. 또한, 메모리는 본 장치와는 분리되어 있으나, 유선 또는 무선으로 연결된 데 이터베이스가 될 수도 있다. 통신부는 외부 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으며, 예를 들어, 방송 수신 모듈, 유선통신 모듈, 무선통신 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 이러한, 통신부는 후술하는 컴퓨팅 장치의 네트워크 통신 인터페이스일 수 있다. 디스플레이는 프로세서의 제어에 따라, 제1 및 제2 3D 형상 데이터를 출력할 수 있다. 이 외에도, 디 스플레이는 3D 형상 데이터 제공 서버와 관련된 각종 정보를 시각적으로 출력하여 운용자를 비롯한 사용자가 확인할 수 있도록 할 수 있다. 한편, 디스플레이는 프로세서의 제어에 따라, 제1 및 제2 3D 형상 데이터를 출력할 때, 운용자에 의해서 표시 방식의 니즈에 따라 출력할 수 있다. 이를 위해, 프로세서 는 운용자에 의해서 사전 설정된 표시 방식에 따라, 제1 및 제2 3D 형상 데이터를 비롯한 각종 정보를 가 공하여 디스플레이를 통해 출력할 수 있다. 도 7은 일 실시예에 따른 3D 형상 데이터 제공 방법을 설명하기 위한 흐름도이다. 도 7에 도시된 방법은 예를 들어, 전술한 3D 형상 데이터 제공 서버에 의해 수행될 수 있다. 도시된 흐름도에서는 상기 방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가 되어 수행될 수 있다. 후술하는 3D 형상 데이터 제공 방법은 상술한 도 1 내지 도 6을 통해 개시한 3D 형상 데이터 제공 서버의 동작을 동일하게 구현할 수 있으나, 설명의 편의를 위해 중복되는 설명은 생략하기로 한다. 1100 단계에서, 3D 형상 데이터 제공 서버는 프로세서를 통해 신체 대상에 대한 복수의 제1 3D 형상 데이터를 생성하여 저장할 수 있다. 1200 단계에서, 3D 형상 데이터 제공 서버는 프로세서를 통해 신체 대상에 대한 식별정보를 포함하는 실시간 의료 데이터를 수신할 수 있다. 1300 단계에서, 3D 형상 데이터 제공 서버는 프로세서를 통해 복수의 제1 3D 형상 데이터로부터 식별 정보와 매칭되는 제1 3D 형상 데이터를 추출할 수 있다. 1400 단계에서, 3D 형상 데이터 제공 서버는 프로세서를 통해 사전 학습된 제1 인공지능 모델을 기초 로 제1 3D 형상 데이터에 실시간 의료 데이터를 반영하여 제2 3D 형상 데이터 생성하여 출력할 수 있다. 도 8은 일 실시예에 따른 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도이다. 도시된 실시예에 서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 컴퓨팅 장치는 일 실시예에 따른 3D 형상 데이터 제공 서버에 포함된 하나 이상의 컴포넌트일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다. 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다."}
{"patent_id": "10-2023-0127725", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서 본 발명의 대표적인 실시예들을 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후술하는 청구 범위뿐만 아니라 이 청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2023-0127725", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 3D 형상 데이터 제공 서버를 설명하기 위한 블록도 도 2 내지 도 6은 일 실시예에 따른 3D 형상 데이터 제공 방법을 설명하기 위한 예시도 도 7은 일 실시예에 따른 3D 형상 데이터 제공 방법을 설명하기 위한 흐름도도 8은 일 실시예에 따른 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도"}
