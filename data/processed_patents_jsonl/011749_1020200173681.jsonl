{"patent_id": "10-2020-0173681", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0013290", "출원번호": "10-2020-0173681", "발명의 명칭": "오토포커스를 보상하는 방법 및 오토포커스를 보상하는 전자 장치", "출원인": "삼성전자주식회사", "발명자": "진경환"}}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 오토포커스를 보상하는 방법에 있어서,입력 이미지로부터 생성된 복수의 파티션 블록 중 현재 파티션 블록에 대응되는 점확산함수(point spreadfunction, PSF)를 획득하는 단계;상기 현재 파티션 블록에 포함된 블러(blur)를 제거하기 위해, 상기 점확산함수를 이용하여 상기 현재 파티션블록을 필터링하는 단계;상기 필터링된 현재 파티션 블록에 포함된 오버슈트(overshoot)를 제거하기 위해, 상기 필터링된 현재 파티션블록 내에 포함된 샘플들을 임계값에 기초하여 후처리하는 단계; 및상기 후처리된 현재 파티션 블록을 포함하는 출력 이미지를 생성하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 현재 파티션 블록에 대응되는 점확산함수는, 기 설정된 점확산함수 또는 인공 신경망(artificial neuralnetwork)을 통해 계산된 점확산함수인, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 획득된 점확산함수를 이용하여, 상기 현재 파티션 블록을 필터링하는 단계는,상기 획득된 점확산함수로부터 위너 필터(Wiener filter)를 획득하는 단계; 및상기 획득된 위너 필터를 이용하여, 상기 현재 파티션 블록을 필터링하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 위너 필터는 공간 도메인(spatial domain) 상의 위너 필터인, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 공간 도메인 상의 위너 필터는,푸리에 도메인(Fourier domain) 상의 위너 필터를 푸리에 역변환(Fourier inverse transform)하고, 상기 푸리에 역변환된 위너 필터의 계수에서 기 설정된 강도(intensity) 이하의 값은 제거함으로써 획득되는, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 위너 필터를 획득하는 단계는, 푸리에 도메인(Fourier domain) 상의 위너 필터 및 공간 도메인(spatialdomain) 상의 위너 필터를 획득하는 단계를 포함하고,상기 획득된 위너 필터를 이용하여, 상기 현재 파티션 블록을 필터링하는 단계는,상기 획득된 푸리에 도메인 상의 위너 필터 또는 공간 도메인 상의 위너 필터를 선택하는 단계; 및상기 선택된 위너 필터를 이용하여, 상기 현재 파티션 블록을 필터링하는 단계를 포함하는, 방법.공개특허 10-2022-0013290-3-청구항 7 제3항에 있어서,상기 위너 필터는, 1차원 방향성 필터 또는 2차원 방향성 필터인, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서, 상기 위너 필터(Wiener filter)가 1차원 방향성 필터인 경우,상기 획득된 점확산함수로부터 위너 필터를 획득하는 단계는, 룩업 테이블(lookup table)을 이용해 상기 위너필터의 필터 계수를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 임계값은, 샘플의 비트 깊이(bit-depth) 에 기초하여 결정되는, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 임계값은, 현재 샘플이 포함된 일정 영역의 샘플들의 표준편차에 기초하여 결정되는, 방법."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "오토포커스를 보상하는 전자 장치에 있어서,입력 이미지를 획득하는 카메라부;출력 이미지를 출력하는 디스플레이부;적어도 하나의 명령어(instruction)를 포함하는 프로그램을 저장하는 저장부; 및상기 저장부에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,상기 입력 이미지로부터 생성된 복수의 파티션 블록 중 현재 파티션 블록에 대응되는 점확산함수(point spreadfunction, PSF)를 획득하고,상기 현재 파티션 블록에 포함된 블러(blur)를 제거하기 위해, 상기 점확산함수를 이용하여 상기 현재 파티션블록을 필터링하고,상기 필터링된 현재 파티션 블록에 포함된 오버슈트(overshoot)를 제거하기 위해, 상기 필터링된 현재 파티션블록 내에 포함된 샘플들을 임계값에 기초하여 후처리하고,상기 후처리된 현재 파티션 블록을 포함하는 출력 이미지를 생성하는, 전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 현재 파티션 블록에 대응되는 점확산함수는, 기 설정된 점확산함수 또는 인공 신경망(artificial neuralnetwork)을 통해 계산된 점확산함수인, 전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여,상기 획득된 점확산함수로부터 위너 필터(Wiener filter)를 획득하고,상기 획득된 위너 필터를 이용하여, 상기 현재 파티션 블록을 필터링하는, 전자 장치.공개특허 10-2022-0013290-4-청구항 14 제13항에 있어서,상기 위너 필터는 공간 도메인(spatial domain) 상의 위너 필터인, 전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 공간 도메인 상의 위너 필터는,푸리에 도메인(Fourier domain) 상의 위너 필터를 푸리에 역변환(Fourier inverse transform)하고, 상기 푸리에 역변환된 위너 필터의 계수에서 기 설정된 강도(intensity) 이하의 값은 제거함으로써 획득되는, 전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여,푸리에 도메인(Fourier domain) 상의 위너 필터 및 공간 도메인(spatial domain) 상의 위너 필터를 획득하고,상기 획득된 푸리에 도메인 상의 위너 필터 또는 공간 도메인 상의 위너 필터를 선택하고,상기 선택된 위너 필터를 이용하여, 상기 현재 파티션 블록을 필터링하는, 전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 위너 필터는, 1차원 방향성 필터 또는 2차원 방향성 필터인, 전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서, 상기 위너 필터(Wiener filter)가 1차원 방향성 필터인 경우,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여,룩업 테이블(lookup table)을 이용해, 상기 획득된 점확산함수로부터 상기 위너 필터의 필터 계수를 획득하는,전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 임계값은,샘플의 비트 깊이(bit-depth), 및 현재 샘플이 포함된 일정 영역의 샘플들의 표준편차 중 적어도 하나에 기초하여 결정되는, 전자 장치."}
{"patent_id": "10-2020-0173681", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "오토포커스를 보상하는 방법 및 오토포커스를 보상하는 전자 장치가 제공된다. 방법은, 입력 이미지로부터 생성 된 복수의 파티션 블록 중 현재 파티션 블록에 대응되는 점확산함수(point spread function, PSF)를 획득하는 단 계, 상기 현재 파티션 블록에 포함된 블러(blur)를 제거하기 위해 상기 점확산함수를 이용하여 상기 현재 파티션 블록을 필터링하는 단계, 상기 필터링된 현재 파티션 블록에 포함된 오버슈트(overshoot)를 제거하기 위해 상기 필터링된 현재 파티션 블록 내에 포함된 샘플들을 임계값에 기초하여 후처리하는 단계, 및 상기 후처리된 현재 파티션 블록을 포함하는 출력 이미지를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 오토포커스를 보상하는 방법, 오토포커스를 보상하는 전자 장치, 및 상기 오토포커스를 보상하는 방 법을 수행하기 위한 프로그램 코드들을 저장하는 컴퓨터 판독가능 저장매체에 관한 것이다."}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털 촬영 장치는 광학 신호를 전기 신호로 변환하는 촬상 소자를 구비한다. 촬상 소자에서 감지된 신호를 이 용하여, 현재 촬상 소자에 생성된 상을 표시하는 라이브뷰(live-view) 화면이 사용자에게 제공될 수 있다. 카메 라, 캠코더 등의 디지털 촬영 장치에 있어서 선명한 정지 영상 또는 동영상을 촬영하기 위해서는 피사체에 정확하게 초점을 맞추는 것이 필요하다. 따라서, 피사체를 촬영하는 촬영 장치에는 피사체에 자동적으로 핀트를 맞 추는 오토포커스(Auto-Focus, AF) 기능이 넓게 탑재되고 있다. 촬영 장치에 AF 기능을 탑재함으로써, 초심자라 도 간편하게, 피사체에 초점이 맞은 고화질의 촬영 화상을 취득할 수 있다. 일반적으로 촬영 장치가 광학 AF 기능을 구현하기 위해서 액츄에이터(actuator)를 사용하고 있다. 이러한 액츄 에이터 사용을 위해서는 일정 크기 이상의 촬영 장치가 필요하고 따라서 휴대폰용 카메라의 부피 감소에 어려움 을 줄 수 있다. 그러므로, 휴대폰용 카메라 등에서 부피를 감소시키면서, 광학 AF 기능을 대체할 수 있는 방안 이 요구된다. 액츄에이터를 사용하지 않는 경우, 렌즈는 고정되어 있고, 카메라로부터 물체까지의 거리에 따라 서 획득한 영상의 블러(blur) 정도가 다를 수 있다. 따라서, 이미지에 따라 블러 정도를 예측하고, 예측된 블러 정도로부터 추정된 점확산함수(point spread function, PSF)를 이용하여 이미지를 복원하는 기술이 요구된다. 이 때, 잘못 추정된 점확산함수를 사용하여 영 상의 블러를 제거할 경우, 블러의 제거에 한계가 있을 뿐만 아니라, 컬러 디펙트(color defect)나 링 현상(ring effect) 등의 결함(artifact)이 발생될 수도 있다. 따라서, 다양한 영상에 따라 적절한 점확산함수를 추정하고, 오토포커스를 보상하는 것이 요구된다."}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 이미지를 구성하는 영역들의 블러 레벨에 따라 이미지의 블러를 제거하여 이미지를 복 원하는 방법 및 전자 장치를 제공할 수 있다. 본 개시의 일 실시예는, 디컨볼루션(deconvolution) 필터링 동작에서 발생한 오버슈트(overshoot)를 보정하기 위한 후처리 동작을 수행함으로써, 이미지의 해상도를 유지하면서도 링 현상(ring effect) 등의 결함(artifac t)을 경감시킬 수 있는 방법 및 전자 장치를 제공할 수 있다. 본 개시의 일 실시예는, 공간 도메인(spatial domain)에서 디컨볼루션 필터링함으로써, 프로세서의 연산 로드 (load)를 줄일 수 있고, 연산 수행 시간을 가속화할 수 있는 방법 및 전자 장치를 제공할 수 있다."}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 오토포커스를 보상하는 방법은, 입력 이미지로 부터 생성된 복수의 파티션 블록 중 현재 파티션 블록에 대응되는 점확산함수(point spread function, PSF)를 획득하는 단계, 상기 현재 파티션 블록에 포함된 블러(blur)를 제거하기 위해 상기 점확산함수를 이용하여 상기 현재 파티션 블록을 필터링하는 단계, 상기 필터링된 현재 파티션 블록에 포함된 오버슈트(overshoot)를 제거하 기 위해 상기 필터링된 현재 파티션 블록 내에 포함된 샘플들을 임계값에 기초하여 후처리하는 단계, 및 상기 후처리된 현재 파티션 블록을 포함하는 출력 이미지를 생성하는 단계를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 오토포커스를 보상하는 전자 장치는, 입력 이 미지를 획득하는 카메라부, 출력 이미지를 출력하는 디스플레이부, 적어도 하나의 명령어(instruction)를 포함 하는 프로그램을 저장하는 저장부, 및 상기 저장부에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 입력 이미지로부터 생성된 복수의 파티션 블 록 중 현재 파티션 블록에 대응되는 점확산함수(point spread function, PSF)를 획득하고, 상기 현재 파티션 블 록에 포함된 블러(blur)를 제거하기 위해 상기 점확산함수를 이용하여 상기 현재 파티션 블록을 필터링하고, 상 기 필터링된 현재 파티션 블록에 포함된 오버슈트(overshoot)를 제거하기 위해, 상기 필터링된 현재 파티션 블 록 내에 포함된 샘플들을 임계값에 기초하여 후처리하고, 상기 후처리된 현재 파티션 블록을 포함하는 출력 이 미지를 생성할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 컴퓨터로 읽을 수 있는 기록매체는, 개시된 방법의 실 시예들 중에서 적어도 하나를 컴퓨터에서 실행시키기 위한 프로그램이 저장된 것일 수 있다."}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라 질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적 합한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하 도록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용 될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C 를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로 세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있 는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 오토포커스(auto-focus, AF)를 보상하는 방법의 개요도이다. 전자 장치는 입력 영상 또는 입력 이미지를 획득하고, 출력 영상 또는 출력 이미지를 출력하는 장치일 수 있다. 전자 장치는 예를 들어, 스마트 폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기 (mobile phone), 영상 전화기, 전자책 리더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 워크스테이션(workstation), 서버, PDA(personal digital assistant), PMP(portable multimedia player), MP3 플레이어, 모바일 의료기기, 카메라 (camera), 웨어러블 장치(wearable device), 가전기기 및 기타 모바일 또는 비모바일 컴퓨팅 장치 중 적어도 하 나로 구성될 수 있다. 그러나, 전자 장치가 전술한 예시로 한정되는 것은 아니며, 전자 장치는 영상 또는 이미 지를 획득하고 처리하여 출력하는 모든 종류의 기기를 포함할 수 있다. 본 개시에서 '오토포커스의 보상(auto-focus compensation)'은 주어진 이미지의 포커스를 개선하는 것을 의미할 수 있다. 일 실시예에서, 카메라의 센서 크기 증대에 따라 근거리 촬영 시 이미지의 외곽에 초점이 잡히지 않는 열화 현상(번짐, 블러(blur))이 일어날 수 있다. 예를 들어, 열화 현상은 이미지의 중심부로부터 방사형으로 발 생될 수 있다. 오토포커스의 보상은, 이러한 열화 현상에 대한 사전 정보를 이용하여 열화된 이미지를 재구성 또는 복구하는 동작을 의미할 수 있다. 도 1을 참조하면, 전자 장치는 내장된 카메라부를 통해 입력 이미지를 획득할 수 있다. 일 실시예에서, 획 득된 입력 이미지로부터 복수의 파티션 블록(partition block)이 생성될 수 있다. 복수의 파티션 블록 은 각각 입력 이미지의 적어도 일부에 해당할 수 있다. 일 실시예에서, 특정 파티션 블록은 이웃하는 파티 션 블록과 접할 수 있다. 다른 실시예에서, 특정 파티션 블록과 이웃하는 파티션 블록은 적어도 일부가 오버랩 (overlap)될 수도 있다. 본 개시의 일 실시예에 따른 전자 장치는 입력 이미지로부터 생성된 복수의 파티션 블록 중 현재 파티션 블 록에 대응되는 점확산함수(point spread function, PSF)를 획득할 수 있다. 점확산함수(PSF)는 열화 현상 에 대한 함수 또는 이미징 시스템의 광학 전달 함수를 의미할 수 있다. 점확산함수(PSF)는 점 소스(point source)에 대한 이미징 시스템의 임펄스 응답을 나타낸다. 점확산함수(PSF)는 단일 점 개체(point object)를 나 타내는 이미지의 확장된 형태로 볼 수 있다. 점 개체의 퍼짐(spread) 또는 블러(blur) 정도는 이미징 시스템의 품질에 대한 척도가 될 수 있다. 공간 불변 시스템(space-invariant system)에서 점확산함수(PSF)는 이미지의 전체 영역에서 동일할 수도 있다. 특정 이미징 시스템으로 촬영된 물체의 이미지는 물체의 실제 이미지와 해당이미징 시스템의 점확산함수(PSF)의 컨볼루션(convolution)의 결과로 볼 수 있다. 일 실시예에서, 전자 장치는 획득된 점확산함수(PSF)를 이용하여, 현재 파티션 블록을 필터링할 수 있다. 예를 들어, 필터링 동작에는 디컨볼루션 필터(deconvolution filter)가 이용될 수 있다. 물체의 촬영된 이 미지는 물체의 실제 이미지와 점확산함수(PSF)의 컨볼루션 값으로 나타낼 수 있으므로, 이론적으로, 획득된(촬 영된) 입력 이미지를 점확산함수(PSF)로 디컨볼루션(deconvolution)할 경우, 물체의 실제 이미지가 획득될 수 있다. 촬영된 입력 이미지는 블러(blur)를 포함하는 것으로 가정한다. 따라서, 점확산함수(PSF)를 이용 하여 입력 이미지의 복수의 파티션 블록들을 필터링할 경우, 복수의 파티션 블록들에 포함된 블러를 제거할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 필터링된 현재 파티션 블록 내에 포함된 샘플(sample)들을 임계 값(threshold)에 기초하여 후처리할 수 있다. 일 실시예에서, 디컨볼루션 필터링 동작을 수행할 경우, 필터링된 이미지에서는, 포함된 객체의 가장자리 또는 포함된 글씨의 가장자리 부분의 밝기가 과도하게 강화되는 오버슈트(overshoot)가 발생할 수 있다. 이러한 오버 슈트가 발생한 위치에서의 샘플은, 입력 이미지에서와 필터링 이후에서의 값의 차이가 크다. 따라서, 특정 샘플의 입력 이미지에서의 값과 필터링 이후에서의 값의 차이 δ에 대한 임계값이 설정되고, 전 자 장치가 설정된 임계값에 기초하여 필터링된 이미지를 후처리할 경우, 필터링된 파티션 블록에 포 함된 오버슈트(overshoot)를 제거할 수 있고, 이미지의 해상도를 유지하면서도 링 현상(ring effect) 등의 결함 (artifact)을 경감시킬 수 있다. 이후, 전자 장치는 후처리된 샘플들을 포함하는 복수의 파티션 블록들을 융합함으로써, 후처리된 파 티션 블록들을 포함하는 출력 이미지를 생성할 수 있다. 출력 이미지는 오토포커스가 보상된 입력 이미 지에 대응될 수 있다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 블록도이다. 도 2를 참조하면, 전자 장치는 카메라부, 프로세서, 저장부, 및 디스플레이부를 포함할 수 있다. 도 2에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니다. 도 2에 도 시된 구성 요소보다 많은 구성 요소들에 의해 전자 장치가 구현될 수도 있고, 도 2에 도시된 구성 요소보 다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 카메라부는 디지털 촬영 장치를 포함할 수 있다. 일 실시예에서, 카메라부는 입력 영상 또는 입력 이미지를 획득할 수 있다. 일 실시예에서, 카메라부는 액츄에이터(actuator)를 포함할 수 있고, 전자 장 치의 저장부는, 액츄에이터를 사용하는 광학 오토포커스 기능을 구현하기 위한 명령어들을 포함할 수도 있다. 디스플레이부는 출력 영상 또는 출력 이미지를 외부로 출력할 수 있다. 디스플레이부는 시각적 이 미지를 외부로 표시하여 출력할 수 있다. 일 실시예에서, 디스플레이부는 패널(panel)을 포함할 수 있다. 디스플레이부는 예를 들어, 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이 (thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉시 블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나로 구성될 수 있다. 다만 디스플레이부는 전술한 예시로 한정되는 것은 아니 며, 영상 또는 이미지를 출력하여 표시하는 모든 종류의 디스플레이를 포함할 수 있다. 저장부는 전자 장치의 동작을 제어하기 위해 후술할 프로세서에 의해 실행될 프로그램을 저 장할 수 있다. 저장부는 전자 장치의 동작을 제어하기 위한 적어도 하나의 명령어들(instruction s)을 포함하는 프로그램을 저장할 수 있다. 저장부에는 프로세서가 판독할 수 있는 명령어들 및 프 로그램 코드(program code)가 저장될 수 있다. 일 실시예에서, 프로세서는 저장부에 저장된 프로그 램의 명령어들 또는 코드들을 실행하도록 구현될 수 있다. 저장부는 전자 장치로 입력되거나 전자 장치로부터 출력되는 데이터를 저장할 수 있다. 저장부는 예를 들어, 플래시 저장부(flash memory), 하드디스크(hard disk), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 저장부(예를 들어, SD 또는 XD 저장부 등), 램(RAM, Random Access Memory), SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 저장부, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장 매체를 포함할 수 있다. 다만 저장부는 전술한 예시로한정되는 것은 아니며, 데이터가 저장될 수 있는 모든 종류의 저장 매체를 포함할 수 있다. 저장부에 저장된 프로그램들은 기능에 따라 복수 개의 모듈들로 분류할 수 있다. 예를 들어, 저장부 는, 점확산함수(PSF) 획득 모듈, 필터링 모듈, 및 후처리 모듈을 포함할 수 있다. 일 실시예에서, 저장부는 인공 신경망(artificial neural network, ANN) 또는 데이터베이스(database, DB) 를 더 포함할 수 있다. 프로세서는, 전자 장치의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서는 저장부 에 저장된 프로그램들을 실행함으로써, 카메라부, 디스플레이부, 및 저장부 등을 전반 적으로 제어할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서는, 저장부에 저장된 적어도 하나의 명령어들을 실행함으로써, 카메라부를 통해 입 력 영상 또는 입력 이미지를 획득할 수 있다. 프로세서는, 저장부에 저장된 적어도 하나의 명령어들을 실행함으로써, 입력 이미지로부터 복수의 파티션 블록을 생성할 수 있다. 복수의 파티션 블록은 각각 입력 이미지의 적어도 일부에 해당할 수 있다. 일 실시예에서, 특정 파티션 블록은 이웃하는 파티션 블록과 접할 수도 있고, 특정 파티션 블록과 이웃하는 파티션 블록은 적어도 일부가 오버랩될 수도 있다. 복수의 파티션 블록에는 각각 복수의 샘플(sample)들이 포함될 수 있다. 입력 이미지에 포함된 모든 샘플들(픽셀값, pixel value)은 적어도 하나의 파티션 블록에 포함될 수 있다. 프로세서는, 저장부에 저장된 프로그램들 중 점확산함수(PSF) 획득 모듈을 구성하는 적어도 하나의 명령어들을 실행함으로써, 입력 이미지로부터 생성된 복수의 파티션 블록 중 현재 파티션 블록에 대응되 는 점확산함수(point spread function, PSF)를 획득할 수 있다. 현재 파티션 블록에 대응되는 점확산함수(PSF) 는, 현재 파티션 블록에 포함된 점 개체(point object)들에 적용되는 이미징 임펄스 응답을 나타낼 수 있다. 즉, 현재 파티션 블록에 대응되는 점확산함수(PSF)는 현재 파티션 블록의 블러(blur) 정도를 나타낼 수 있다. 예를 들어, 근거리 촬영의 경우, 이미지의 중심에서 외곽으로 갈수록 블러(blur) 정도 또는 열화 정도가 증가할 수 있다. 파티션 블록별로 이미지 중심으로부터 각 파티션 블록까지의 거리가 다르며, 현재 파티션 블록에 대응 하는 점확산함수(PSF)는 이미지 중심으로부터 현재 파티션 블록까지의 거리에 따라 결정되므로, 파티션 블록별 로 대응하는 점확산함수(PSF)가 달라질 수 있다. 일 실시예에서, 현재 파티션 블록에 대응하는 점확산함수(PS F)는 현재 파티션 블록 내의 모든 샘플에 적용될 수 있다. 일 실시예에서, 입력 이미지로부터 생성된 복수의 파티션 블록 중 현재 파티션 블록에 대응되는 점확산함수는, 기 설정된 점확산함수(PSF)거나, 인공 신경망(artificial neural network)을 통해 계산된 점확산함수(PSF)일 수 있다. 프로세서는, 저장부에 저장된 프로그램들 중 필터링 모듈을 구성하는 적어도 하나의 명령어 들을 실행함으로써, 현재 파티션 블록에 포함된 블러(blur)를 제거하기 위해, 현재 파티션 블록에 대응하도록 획득된 점확산함수(PSF)를 이용하여 현재 파티션 블록을 필터링할 수 있다. 일 실시예에서, 필터링 동작에는 디 컨볼루션 필터(deconvolution filter)가 적용될 수 있다. 물체의 촬영된 이미지는 물체의 실제 이미지와 점확산 함수(PSF)의 컨볼루션된 결과로 나타낼 수 있으므로, 획득된 입력 이미지의 복수의 파티션 블록을 대응되는 점 확산함수(PSF)들로 디컨볼루션(deconvolution)할 경우, 물체의 실제 이미지를 획득할 수 있다. 따라서, 획득된 점확산함수(PSF)를 이용하여 파티션 블록을 필터링하는 동작을 통해, 파티션 블록에 포함된 블러(blur)를 제거 할 수 있다. 일 실시예에서, 획득된 점확산함수(PSF)를 이용하여, 파티션 블록을 필터링하는 동작은, 획득된 점확산함수 (PSF)로부터 위너 필터(Wiener filter)를 획득하고, 획득된 위너 필터를 이용하여 파티션 블록을 필터링하는 동 작을 포함할 수 있다. 디컨볼루션 필터는 위너 필터의 형태일 수 있다. 예를 들어, 주파수 도메인 상의 위너 필 터(W(f))는 다음의 수학식 1과 같이 정의될 수 있다.수학식 1"}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, f는 주파수 도메인에서의 좌표 성분이고, H(f)는 주파수 도메인 상의 점확산함수(PSF)며, H*(f)는 H (f)의 켤레(conjugate) 함수이다. N(f)는 노이즈 대 신호의 비율로서, 노이즈의 파워 스펙트럼을 실제 이미지의 파워 스펙트럼으로 나눈 값으로 정의될 수 있다. W(f)를 해당 점확산함수 H(f)에 대응되는 파티션 블록에 적용하여, W(f)와 해당 파티션 블록 내의 샘플들의 주 파수 성분들을 곱하면, 해당 파티션 블록 내의 필터링된 샘플들의 주파수 성분이 생성될 수 있다. 해당 파티션 블록 내의 필터링된 샘플들의 주파수 성분을 공간 도메인으로 변환(transformation)하면 해당 파티션 블록 내의 필터링된 샘플들이 획득될 수 있다. 해당 파티션 블록 내의 샘플들이 필터링되면, 블러(blur)가 제거된 샘플들 을 획득할 수 있다. 이러한 과정을 파티션 블록 내의 모든 샘플들에 대하여 반복하면, 해당 파티션 블록에 포함 된 블러(blur)가 모두 제거될 수 있다. 일 실시예에서, 위너 필터(Wiener filter)는 공간 도메인(spatial domain) 상의 위너 필터일 수도 있다. 공간 도메인 상의 위너 필터는, 푸리에 도메인(주파수 도메인) 상의 위너 필터를 푸리에 역변환(Fourier inverse transform, IFT)하고, 푸리에 역변환된 위너 필터의 계수에서 기 설정된 강도(intensity) 이하의 값은 제거함으 로써 생성될 수 있다. 예를 들어, 공간 도메인 상의 Wiener 필터(c(x))는 다음의 수학식 2와 같이 정의될 수 있 다. 수학식 2"}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, x는 공간 도메인에서의 좌표 성분이고, w(x)는 주파수 도메인 상의 위너 필터 W(f)를 푸리에 역변환 ( )한 공간 도메인 상의 함수이다. 기 설정된 강도(intensity)로서, 예를 들어, 전체 강도 대비 약 99%가 c(x)에 포함되도록 가 설정될 수 있다. c(x)를 해당 점확산함수 H(f)에 대응되는 파티션 블록의 블록 영상과 공간 도메인 상에서 컨볼루션 계산하면, 해당 파티션 블록 내의 샘플들이 필터링된 결과, 즉 블러(blur)가 제거된 샘플들을 획득할 수 있다. 이러한 과 정을 파티션 블록 내의 모든 샘플들에 대하여 반복하면, 해당 파티션 블록에 포함된 블러(blur)가 모두 제거될 수 있다. 일 실시예에서, 프로세서는 저장부에 저장된 적어도 하나의 명령어를 실행함으로써, 푸리에 도메인 (Fourier domain) 상의 위너 필터 및 공간 도메인(spatial domain) 상의 위너 필터 중 적어도 하나를 획득하고, 획득된 푸리에 도메인 상의 위너 필터 또는 공간 도메인 상의 위너 필터를 선택하고, 선택된 위너 필 터를 이용하여 파티션 블록을 필터링할 수 있다. 일 실시예에서, 전자 장치는 입력 이미지로부터 생성된 복수의 파티션 블록들에 포함된 블러를 제거하기 위해, 푸리에 도메인 상의 위너 필터를 이용하여 복수의 파티 션 블록들을 필터링하거나, 공간 도메인 상의 위너 필터를 이용하여 복수의 파티션 블록들을 필터링하거나, 또 는 복수의 파티션 블록들 중 일부 파티션 블록들은 푸리에 도메인 상의 위너 필터를 이용하여 필터링하고 다른 일부 파티션 블록들은 공간 도메인 상의 위너 필터를 이용하여 필터링할 수 있다. 일 실시예에서, 공간 도메인 상의 위너 필터는 주파수 도메인(푸리에 도메인) 상의 위너 필터에 비해 프로세서 에 발생시키는 연산 로드(load)가 적고, 연산 속도가 빠를 수 있다. 따라서, 일 실시예에서, 필터링 동작 에서 연산에 할당되는 컴퓨팅 리소스(computing resource)를 줄이기 위해, 공간 도메인 상의 위너 필터만을 이 용하거나, 전자 장치의 연산 로드(load)에 기초하여 푸리에 도메인(주파수 도메인) 상의 위너 필터 또는공간 도메인 상의 위너 필터를 선택적으로 이용할 수 있다. 예를 들어, 프로세서에 걸리는 연산 로드 (load)가 과다한 경우, 필터링 동작에 대응되는 연산 로드를 줄이기 위해 공간 도메인 상의 위너 필터를 이용하 여 필터링 동작을 수행할 수 있다. 일 실시예에서, 위너 필터(Wiener filter)는 1차원 방향성 필터이거나 2차원 방향성 필터일 수 있다. 위너 필터 의 차원은 필터 생성시 이용되는 점확산함수(PSF) H(f)의 차원에 따라 결정될 수 있다. 위너 필터(W(f) 또는 c(x))가 1차원 방향성 필터인 경우, 전술한 수학식 1에서 f는 u 또는 v로 표시되고, 수학식 2에서 x는 x 또는 y 로 표시될 수 있다. 위너 필터(W(f) 또는 c(x))가 2차원 방향성 필터인 경우, 전술한 수학식 1에서 f 대신 u,v 로 표시되고, 수학식 2에서 x 대신 x,y로 표시될 수 있다. 일 실시예에서, 프로세서가 획득된 점확산함수(PSF)를 이용하여 파티션 블록을 필터링하는 동작은, 룩업 테이블(lookup table)을 더 이용해 파티션 블록을 필터링하는 동작을 포함할 수 있다. 예를 들어, 위너 필터가 1차원 방향성 필터인 경우, 획득된 점확산함수로부터 위너 필터를 획득하는 동작은, 룩업 테이블을 이용해 위너 필터의 필터 계수를 획득하는 동작을 포함할 수 있다. 룩업 테이블(lookup table) 또는 순람표는 배열이나 연관 배열로 이루어진 데이터 구조로써, 연산 동작을 보다 단순한 배열 색인화 동작으로 대체하는데 이용될 수 있다. 일 실시예에서, 룩업 테이블에는 위너 필터의 필터 계수(filter coefficient)가 저장되어 있을 수 있다. 즉, 룩업 테이블을 이용하여 미리 저장된 위너 필터를 불 러올 수 있다. 룩업 테이블에 기 저장된 위너 필터의 필터 계수를 이용하는 경우, 전술한 수학식 1 또는 수학식 2를 계산하지 않고도, 점확산함수로부터 위너 필터를 획득할 수 있다. 일 실시예에서, 룩업 테이블을 이용해 획 득한 위너 필터를 이용해 파티션 블록을 필터링할 수 있다. 룩업 테이블을 이용할 경우, 푸리에 도메인 상의 위 너 필터 또는 공간 도메인 상의 위너 필터를 획득하기 위하여 직접적인 수학식 1 또는 수학식 2의 연산을 수행 하지 않을 수 있고, 프로세서의 처리 속도가 더욱 가속화될 수 있다. 따라서, 전체적인 오토포커스 조절 방법의 연산 로드를 줄이고, 연산 속도를 증가시킬 수 있다. 한편, 룩업 테이블을 이용해 위너 필터를 획득하고, 획득된 위너 필터를 이용해 복수의 파티션 블록을 필터링하는 동작은, 방향성 필터가 1차원일 때 및 2차원일 때 모두 적용될 수 있으나, 프로세서의 연산 속도를 증가시키고 룩업 테이블 자체의 용량을 감소 시키기 위해서는, 방향성 필터가 1차원일 때 수행하는 것이 보다 효과적일 수 있다. 프로세서는, 저장부에 저장된 프로그램들 중 후처리 모듈을 구성하는 적어도 하나의 명령어 들을 실행함으로써, 필터링된 파티션 블록에 포함된 오버슈트(overshoot)를 제거하기 위해, 필터링된 파티션 블 록 내에 포함된 샘플들을 임계값에 기초하여 후처리할 수 있다. 일 실시예에서, 디컨볼루션 필터링 동작을 수행할 경우, 필터링된 이미지 내에 포함된 객체의 가장자리 또는 글 씨의 가장자리 부분의 밝기가 과도하게 강화되는 오버슈트(overshoot) 현상이 발생할 수 있다. 이러한 오버슈트 가 발생한 위치에서의 샘플은, 입력 이미지에서의 값과 필터링된 이미지에서의 값의 차이가 크다. 따라서, 특정 샘플의 입력 이미지에서의 값과 필터링된 이미지에서의 값의 차이 δ에 대한 임계값을 결정하고, 결정된 임계값 에 기초하여 필터링된 이미지를 후처리할 경우, 필터링된 이미지에 포함된 오버슈트(overshoot)를 제거할 수 있 다. 이 경우, 이미지의 해상도를 유지하면서도 링 현상(ring effect) 등의 결함(artifact)을 경감시킬 수 있다. 예를 들어, 특정 샘플의 오리지널 값 O(x,y)와 디컨볼루션 필터링된 샘플값 D(x,y)의 차이 δ가 결정된 임계값 (TH)보다 클 경우, 결정된 임계값(TH) 내로 δ를 조정할 수 있다. 여기서, (x,y)는 이미지 상에서의 샘플의 좌 표(coordinates)를 의미한다. 이러한 동작은 아래의 표 1과 같은 Pseudo 코드로 표현될 수 있다. 표 1 δ = D(x,y) - O(x,y) if (δ < -TH) D(x,y) = O(x,y) - TH else if (δ > TH) D(x,y) = O(x,y) + TH else D(x,y) = D(x,y) 일 실시예에서, 프로세서는, 저장부에 저장된 적어도 하나의 명령어를 실행함으로써, 파티션 블록 내에 포함된 샘플들을 후처리하기 위한 임계값을 결정할 수 있다.일 실시예에서, 임계값(TH)은 샘플의 비트 깊이(bit-depth)에 기초하여 결정될 수 있다. 예를 들어, 샘플의 비 트 깊이가 N 비트인 경우, 임계값(TH)은 2(N-M)으로 결정될 수 있다. 여기서, M은 N보다 작거나 같은 임의의 정수 일 수 있다. 예를 들어, 이미지의 비트 깊이가 8 비트이고, M이 5로 결정된 경우, 임계값(TH)은 8이 될 수 있다. 일 실시예에서, 임계값(TH)은 특정 샘플이 포함된 일정 영역으로부터, 해당 영역에 포함된 샘플들의 표준편차 (σ)에 기초하여 결정될 수도 있다. 이러한 경우에 대해서는 후술할 도 7 및 도 8에서 구체적으로 설명하도록 한다. 이후, 프로세서는 저장부에 저장된 적어도 하나의 명령어를 실행함으로써, 후처리된 샘플들을 포함 하는 파티션 블록들을 융합함으로써, 오토포커스가 보상된 출력 이미지를 획득할 수 있다. 일 실시예에서, 전자 장치는 디스플레이부를 제어함으로써, 오토포커스가 보상된 출력 이미지를 출력할 수 있다. 도 3은 본 개시의 일 실시예에 따른 카메라부의 블록도이다. 도 3를 참조하면, 카메라부는 렌즈 어셈블리, 플래쉬, 이미지 센서, 이미지 스태빌라 이저, 메모리(예: 버퍼 메모리), 또는 이미지 시그널 프로세서를 포함할 수 있다. 렌즈 어셈 블리는 이미지 촬영의 대상인 피사체로부터 방출되는 빛을 수집할 수 있다. 렌즈 어셈블리는 하나 또는 그 이상의 렌즈들을 포함할 수 있다. 일 실시예에 따르면, 카메라부는 복수의 렌즈 어셈블리 들을 포함할 수 있다. 이런 경우, 카메라부는, 예를 들면, 듀얼 카메라, 360도 카메라, 또는 구형 카메라 (spherical camera)를 형성할 수 있다. 복수의 렌즈 어셈블리들 중 일부는 동일한 렌즈 속성(예: 화각, 초점 거리, 자동 초점, f 넘버(f number), 또는 광학 줌)을 갖거나, 또는 적어도 하나의 렌즈 어셈블리는 다른 렌즈 어셈블리의 렌즈 속성들과 다른 하나 이상의 렌즈 속성들을 가질 수 있다. 렌즈 어셈블리는, 예를 들면, 광각 렌즈 또는 망원 렌즈를 포함할 수 있다. 플래쉬는 피사체로부터 방출 또는 반사되는 빛을 강화하기 위하여 사용되는 빛을 방출할 수 있다. 일 실 시예에 따르면, 플래쉬는 하나 이상의 발광 다이오드들(예: RGB(red-green-blue) LED, white LED, infrared LED, 또는 ultraviolet LED), 또는 제논 램프(xenon lamp)를 포함할 수 있다. 이미지 센서는 피사체로부터 방출 또는 반사되어 렌즈 어셈블리를 통해 전달된 빛을 전기적인 신호로 변환함으로써, 상 기 피사체에 대응하는 이미지를 획득할 수 있다. 일 실시예에 따르면, 이미지 센서는, 예를 들면, RGB 센 서, BW(black and white) 센서, IR 센서, 또는 UV 센서와 같이 속성이 다른 이미지 센서들 중 선택된 하나의 이 미지 센서, 동일한 속성을 갖는 복수의 이미지 센서들, 또는 다른 속성을 갖는 복수의 이미지 센서들을 포함할 수 있다. 이미지 센서에 포함된 각각의 이미지 센서는, 예를 들면, CCD(charged coupled device) 센서 또는 CMOS(complementary metal oxide semiconductor) 센서를 이용하여 구현될 수 있다. 이미지 스태빌라이저는 카메라부 또는 이를 포함하는 전자 장치의 움직임에 반응하여, 렌즈 어셈블리에 포함된 적어도 하나의 렌즈 또는 이미지 센서를 특정한 방향으로 움직이거나 이미지 센 서의 동작 특성을 제어(예: 리드 아웃(read-out) 타이밍을 조정 등)할 수 있다. 이는 촬영되는 이미지에 대한 상기 움직임에 의한 부정적인 영향의 적어도 일부를 보상하게 해 준다. 일 실시예에 따르면, 이미지 스태 빌라이저는 카메라부의 내부 또는 외부에 배치된 자이로 센서(미도시) 또는 가속도 센서(미도시)를 이용하여 카메라부 또는 전자 장치의 움직임을 감지할 수 있다. 이미지 스태빌라이저는, 예 를 들면, 광학식 이미지 스태빌라이저로 구현될 수 있다. 메모리는 이미지 센서를 통하여 획득된 이미지의 적어도 일부를 다음 이미지 처리 작업을 위하여 적어도 일시 저장할 수 있다. 예를 들어, 셔터에 따른 이미지 획득이 지연되거나, 또는 복수의 이미지들이 고속으로 획득되는 경우, 획득된 원본 이미지(예: 베이어 패턴의(Bayer-patterned) 이미지 또는 높은 해상도의 이미지)는 메모리에 저장이 되고, 그에 대응하는 사 본 이미지(예: 낮은 해상도의 이미지)는 디스플레이부를 통하여 프리뷰될 수 있다. 이후, 지정된 조건이 만족되면(예: 사용자 입력 또는 시스템 명령) 메모리에 저장되었던 원본 이미지의 적어도 일부가, 예를 들면, 이미지 시그널 프로세서에 의해 획득되어 처리될 수 있다. 일 실시예에 따르면, 메모리는 저 장부의 적어도 일부로, 또는 이와는 독립적으로 운영되는 별도의 메모리로 구성될 수 있다. 이미지 시그널 프로세서는 이미지 센서를 통하여 획득된 이미지 또는 메모리에 저장된 이미 지에 대하여 하나 이상의 이미지 처리들을 수행할 수 있다. 상기 하나 이상의 이미지 처리들은, 예를 들면, 깊 이 지도(depth map) 생성, 3차원 모델링, 파노라마 생성, 특징점 추출, 이미지 합성, 또는 이미지 보상(예: 노 이즈 감소, 해상도 조정, 밝기 조정, 블러링(blurring), 샤프닝(sharpening), 또는 소프트닝(softening)을 포함할 수 있다. 추가적으로 또는 대체적으로, 이미지 시그널 프로세서는 카메라부에 포함된 구성 요 소들 중 적어도 하나(예: 이미지 센서)에 대한 제어(예: 노출 시간 제어, 또는 리드 아웃 타이밍 제어 등)를 수행할 수 있다. 이미지 시그널 프로세서에 의해 처리된 이미지는 추가 처리를 위하여 메모리 에 다시 저장 되거나 카메라부의 외부 구성 요소(예를 들어, 프로세서, 저장부, 또는 디스플레이부)로 제공될 수 있다. 일 실시예에 따르면, 이미지 시그널 프로세서는 프로세서 의 적어도 일부로 구성되거나, 프로세서와 독립적으로 운영되는 별도의 프로세서로 구성될 수 있다. 이미 지 시그널 프로세서가 프로세서와 별도의 프로세서로 구성된 경우, 이미지 시그널 프로세서 에 의해 처리된 적어도 하나의 이미지는 프로세서에 의하여 그대로 또는 추가의 이미지 처리를 거친 후 디스플레이부를 통해 표시될 수 있다. 일 실시예에서, 전자 장치는 각각 다른 속성 또는 기능을 가진 복수의 카메라부들을 포함할 수 있 다. 이런 경우, 예를 들면, 상기 복수의 카메라부들 중 적어도 하나는 광각 카메라이고, 적어도 다른 하 나는 망원 카메라일 수 있다. 유사하게, 상기 복수의 카메라부들 중 적어도 하나는 전면 카메라이고, 적 어도 다른 하나는 후면 카메라일 수 있다. 도 4는 본 개시의 일 실시예에 따른 오토포커스를 보상하는 방법의 흐름도이다. 본 개시의 일 실시예에 따른 오토포커스를 보상하는 방법은, 입력 이미지로부터 복수의 파티션 블록을 생성할 수 있다. 복수의 파티션 블록은 각각 입력 이미지의 적어도 일부에 해당할 수 있다. 일 실시예에서, 특정 파티 션 블록은 이웃하는 파티션 블록과 접할 수도 있고, 특정 파티션 블록과 이웃하는 파티션 블록은 적어도 일부가 오버랩될 수 있다. 복수의 파티션 블록에는 복수의 샘플(sample)들이 포함될 수 있다. 입력 이미지에 포함된 모 든 샘플은 각각 적어도 하나의 파티션 블록에 포함될 수 있다. 단계 S410에서, 입력 이미지로부터 생성된 복수의 파티션 블록 중 현재 파티션 블록에 대응되는 점확산함수 (point spread function, PSF)를 획득할 수 있다. 특정 파티션 블록에 대응되는 점확산함수(PSF)는, 해당 파티 션 블록에 포함된 점 개체(point object)들에 적용되는 이미징 임펄스 응답을 나타낼 수 있다. 파티션 블록에 대응되는 점확산함수(PSF)를 획득하는 동작은, 파티션 블록 별로 기 설정된 점확산함수(PSF)를 획득하거나, 인 공 신경망(artificial neural network)을 통해 계산된 점확산함수(PSF)를 획득하는 동작을 포함할 수 있다. 단계 S420에서, 파티션 블록에 포함된 블러(blur)를 제거하기 위해, 획득된 점확산함수를 이용하여 파티션 블록 을 필터링할 수 있다. 예를 들어, 현재 파티션 블록에 포함된 블러를 제거하기 위해, 현재 파티션 블록에 대응 하도록 획득된 점확산함수를 이용하여 현재 파티션 블록을 필터링할 수 있다. 일 실시예에서, 필터링 동작에는 디컨볼루션 필터(deconvolution filter)가 적용될 수 있고, 디컨볼루션 필터는 주파수 도메인 상의 위너 필터의 형태이거나 또는 공간 도메인 상의 위너 필터의 형태일 수 있다. 일 실시예에서, 필터링 동작에서 연산에 할당 되는 컴퓨팅 리소스(computing resource)를 줄이기 위해, 공간 도메인 상의 위너 필터만을 이용하거나, 전자 장 치의 연산 로드(load)에 기초하여 푸리에 도메인(주파수 도메인) 상의 위너 필터 또는 공간 도메인 상의 위너 필터를 선택적으로 이용할 수도 있다. 일 실시예에서, 위너 필터(Wiener filter)는 필터 생성시 이용되는 점확 산함수 H(f)의 차원에 따라 결정된, 1차원 방향성 필터이거나 2차원 방향성 필터일 수 있다. 일 실시예에서, 획 득된 점확산함수(PSF)를 이용하여 파티션 블록을 필터링하는 동작은, 룩업 테이블(lookup table)을 이용해 점확 산함수로부터 위너 필터를 획득하고, 획득된 위너 필터를 이용해 파티션 블록을 필터링하는 동작을 더 포함할 수도 있다. 단계 S430에서, 필터링된 파티션 블록에 포함된 오버슈트(overshoot)를 제거하기 위해, 필터링된 현재 파티션 블록 내에 포함된 샘플들을 임계값에 기초하여 후처리할 수 있다. 일 실시예에서, 디컨볼루션 필터를 이용하여 촬영된 이미지에 필터링 동작을 수행할 경우, 필터링된 이미지 내에 포함된 객체의 가장자리 또는 글씨의 가장 자리 부분의 밝기가 과도하게 강화되는 오버슈트(overshoot) 현상이 발생할 수 있다. 일 실시예에서, 오버슈트 를 제거하면서도, 이미지의 해상도를 유지하기 위해, 샘플들을 결정된 임계값에 기초하여 후처리할 수 있다. 예 를 들어, 임계값은, 샘플의 비트 깊이(bit-depth)에 기초하여 결정되거나, 현재 샘플이 포함된 일정 영역의 샘 플들의 표준편차(σ)에 기초하여 결정될 수 있다. 단계 S440에서, 후처리된 파티션 블록을 포함하는 출력 이미지를 생성할 수 있다. 일 실시예에서, 후처리된 샘 플들을 포함하는 파티션 블록들을 융합함으로써, 오토포커스가 보상된 출력 이미지를 획득할 수 있다. 도 5는 본 개시의 일 실시예에 따른 현재 파티션 블록에 대응되는 점확산함수(PSF)를 이용하여, 현재 파티션 블록을 필터링하는 동작을 설명하기 위한 도면이다.도 5를 참조하면, 입력 이미지로부터 복수의 파티션 블록을 생성할 수 있다. 복수의 파티션 블록은 사각 그리드(grid)의 형태를 가질 수 있다. 복수의 파티션 블록들 중 현재 파티션 블록은 입력 이미 지의 적어도 일부를 포함할 수 있고, 입력 이미지의 모든 샘플은 적어도 하나의 파티션 블록에 포함될 수 있다. 복수의 점확산함수(PSF)들은 복수의 파티션 블록에 대응될 수 있다. 일 실시예에서, 점확산함수 (PSF)들과 파티션 블록들은 1대1 대응될 수 있다. 일 실시예에서, 하나의 점확산함수(PSF)에 복 수의 파티션 블록들이 대응될 수도 있다. 도 5를 참조하면, 예를 들어 입력 이미지가 25개의 파티션 블록들로 분할된 경우, 점확산함수 또한 복수의 파티션 블록들에 대응되도록 25개가 생성될 수 있다. 특정 점확산함수는 대응되는 파티션 블 록 내의 모든 샘플에 적용될 수 있다. 예를 들어, 제1 파티션 블록에 제1 점확산함수가 대응되 는 경우, 제1 파티션 블록 내에 위치한 모든 샘플에는 제1 점확산함수가 적용될 수 있다. 따라서, 복수의 파티션 블록에 대응되는 점확산함수들을 이용하여, 복수의 파티션 블록을 필터 링할 수 있고, 필터링된 복수의 파티션 블록들로부터, 필터링된 이미지를 획득할 수 있다. 도 6은 본 개시의 일 실시예에 따른 파티션 블록에 대응되는 점확산함수(PSF)를 설명하기 위한 도면이다. 도 6을 참조하면, 근거리 촬영 시, 초점(F)의 주위로 방사형의 블러(blur)가 형성될 수 있고, 초점(F)으로부터 의 거리가 멀수록, 블러의 정도가 심해질 수 있다. 예를 들어, 초점으로부터 좌측 상단의 제1 지점(60a)에서는 이미지 개체(image object)가 좌측 상단으로 그림자가 지듯이 블러가 형성되는 것을 볼 수 있고, 초점으로부터 우측 상단의 제2 지점(60b)에서는 이미지 개체가 우측 상단으로 그림자가 지듯이 블러가 형성되는 것을 볼 수 있다. 또한, 초점으로부터 우측 하단의 제3 지점(60c)에서는 이미지 개체가 좌측 상단으로 그림자가 지듯이 블 러가 형성되는 것을 볼 수 있고, 초점으로부터 좌측 하단의 제4 지점(60d)에서는 이미지 개체가 좌측 하단으로 그림자가 지듯이 블러가 형성되는 것을 볼 수 있다. 제3 지점(60c) 및 제4 지점(60d)을 참조하면, 초점(F)으로부터의 직선 거리가 보다 먼 제4 지점(60d)의 경우가, 제3 지점(60c)의 경우에 비해 블러가 크게 일어난 것을 볼 수 있다. 이와 같이, 초점(F)으로부터의 거리 및 방향에 따라 블러의 정도가 다르게 형성되므로, 촬영된 이미지에 포함된 블러를 제거하기 위해 필터링 동작에서 이용되는 점확산함수(PSF) 또한, 초점(F)으로부터의 거리 및 방향에 따 라 다르게 설정될 수 있다. 도 7은 본 개시의 일 실시예에 따른 후처리 동작에서 임계값을 결정하는 동작을 설명하기 위한 도면이다. 도 7을 참조하면, 일 실시예에서 임계값은, 후처리 동작을 수행하고자 하는 현재 샘플이 포함된 일정 영역 에 포함된 샘플들의 표준편차(σ)에 기초하여 결정될 수 있다. 예를 들어, 영역이 MxN 개의 픽셀들을 가지고, 영역에 포함된 M*N 개의 샘플들의 값에 대한 표준편차가 σ일 수 있다. 이 경우, 표준편차 σ를 임 계값(TH)으로 결정할 수 있다. 일 실시예에서, 영역 내에 포함된 샘플들에 대한 표준편차(σ)에, 스케일 인자(α)와 오프셋 인자(β)를 적 용한 값 'α*σ + β'를 임계값(TH)로 설정할 수도 있다. 일 실시예에서, 특정 샘플이 포함된 일정 영역 내에 포함된 샘플들에 대한 표준편차(σ), 및 특정 샘플 의 오리지널 값 O(x,y)와 필터링 동작 이후의 값 D(x,y)의 차이(δ)에 기초하여 임계값(TH)을 결정할 수도 있다. 예를 들어, 표준편차(σ) 및 차이(δ)에 대해 가중치를 적용한 가중합 'w*σ+(1-w)*δ'을 임계값(TH)으로 결정할 수도 있다. 여기서 가중치(w)는 0과 1사이의 임의의 값을 가질 수 있다. 도 8은 본 개시의 일 실시예에 따른 후처리 동작에서 임계값을 결정하는 다른 동작을 설명하기 위한 도면이다. 도 8을 참조하면, 일 실시예에서 임계값은, 후처리 동작을 수행하고자 하는 현재 샘플이 포함된 일정 영역 에 포함된 샘플들 중 일부 샘플의 표준편차(σ)에 기초하여 결정될 수 있다. 예를 들어, 현재 샘플이 포함된 일정 영역의 네 개의 코너 샘플들(83a, 83b, 83c, 83d)만을 이용해 표준편차(σ)를 계산한 후, 계산 된 표준편차(σ)를 임계값(TH)으로 결정할 수도 있다. 일 실시예에서, 후처리 동작을 위한 임계값은, 샘플의 비트 깊이(bit-depth), 및 현재 샘플이 포함된 일정 영역 에 포함된 샘플들의 표준편차에 기초하여 결정될 수도 있다. 예를 들어, 일 실시예에서, 임계값 결정 동작은 아래의 표 2와 같은 Pseudo 코드로 표현될 수도 있다. 표 2 δ = D(x, y) - O(x, y) TH2 = (1 << (bit_depth - M)) Avg = (A + B + C + D) >> 2 σ = (abs(A - Avg) + abs(B - Avg) + abs(C - Avg) + abs(D - Avg)) >> 2 if (σ < abs(δ)) TH1 = (w*σ+(1-w)*δ) else TH1 = σ if (TH1 > TH2) TH = TH2 else TH = TH1 if (δ < -TH) D(x, y) = O(x, y) - TH else if (δ > TH) D(x, y) = O(x, y) + TH else D(x, y) = D(x, y) 여기서, O(x,y)는 특정 샘플의 오리지널 값이고, D(x,y)는 특정 샘플의 디컨볼루션 필터링 동작 이후의 값이고, bit_depth는 샘플의 비트 깊이이고, M은 샘플의 비트 깊이보다 작거나 같은 임의의 정수이고, A, B, C, 및 D는 특정 샘플이 포함된 일정 영역의 네 개의 코너 샘플들(83a, 83b, 83c, 83d)의 값이고, w는 0과 1사이의 임의의 값을 가지는 가중치일 수 있다. 표 2를 참조하면, 특정 샘플(x, y)의 오리지널 값 O(x, y)와 디컨볼루션 필터링된 샘플값 D(x, y)의 차이 δ를 계산할 수 있다. 제2 임계값(TH2)은, 샘플의 비트 깊이(bit_depth)에 기초하여 결정될 수 있다. 예를 들어, 샘플의 비트 깊이가 N 비트인 경우, bit_depth 는 N이 될 수 있고, M은 N보다 작거나 같은 임의의 정수일 수 있다. 이 때, 제2 임계 값(TH2)은 2(N-M)으로 결정될 수 있다. 제1 임계값(TH1)은, 현재 샘플(x, y)이 포함된 일정 영역에 포함된 샘플들(A, B, C, D)의 표준편차에 기초하여 결정될 수 있다. 예를 들어, 샘플들(A, B, C, D)의 평균값(Avg)을 계산하고, 그로부터 샘플들(A, B, C, D)의 표 준편차(σ)를 계산할 수 있다. 표 2를 참조하면, 표준편차 σ가 앞서 구한 차이값 δ의 절대치보다 작을 경우, 제1 임계값(TH1)은 표준편차 σ 및 차이값 δ에 대해 가중치를 적용한 가중합 'w*σ+(1-w)*δ'으로 결정될 수 있다. 그 밖의 경우, 즉, 표준편차 σ가 차이값 δ의 절대치보다 크거나 같을 경우, 제1 임계값(TH1)은 표준편 차 σ로 결정될 수 있다. 이후, 후처리 동작을 위한 최종 임계값(TH)은, 샘플의 비트 깊이(bit_depth)에 기초하여 결정된 제2 임계값 (TH2) 및 적어도 하나의 샘플들의 표준편차(σ)에 기초하여 결정된 제1 임계값(TH1)으로부터 결정될 수 있다. 표 2를 참조하면, 일 실시예에서, 제1 임계값(TH1)이 제2 임계값(TH2)보다 큰 경우 최종 임계값(TH)은 제2 임계 값(TH2)으로 결정될 수 있고, 그 밖의 경우 최종 임계값(TH)은 제1 임계값(TH1)으로 결정될 수 있다. 결정된 최종 임계값(TH)은 샘플의 후처리 동작에 이용될 수 있다. 예를 들어, 샘플(x, y)의 오리지널 값 O(x, y)와 디컨볼루션 필터링된 샘플값 D(x, y)의 차이 δ를 결정된 최종 임계값(TH) 내로 조정할 수 있다. 한편, 임계값의 결정은 전술한 방법들로 한정되는 것은 아니며, 샘플들의 분산값, 평균값, 최대값 등을 이용해 결정될 수도 있다. 도 9 및 도 10은 본 개시의 일 실시예에 따른 오토포커스를 보상하는 방법을 적용하여 입력 이미지의 오토포커 스를 보상한 결과를 도시한 도면이다.도 9는 촬영된 이미지의 우측단을 확대한 모습을 나타낸다. 도 9를 참조하면, 입력 이미지의 제1 부분(90a) 및 제2 부분(90b)에 포함된 우측 방향 블러가, 출력 이미지의 제1 부분(95a) 및 제2 부분(95b)에서 각각 제 거된 것을 볼 수 있다. 도 10은 촬영된 이미지의 좌측 상단을 확대한 모습을 나타낸다. 도 10을 참조하면, 입력 이미지의 제1 부 분(100a), 제2 부분(100b), 제3 부분(100c), 및 제4 부분(100d)에 포함된 좌측 상측 방향 블러가, 출력 이미지 의 제1 부분(105a), 제2 부분(105b), 제3 부분(105c), 및 제4 부분(105d)들에서 각각 제거된 것을 볼 수 있다. 이와 같이, 본 개시의 일 실시예에 따르면, 촬영된 이미지를 구성하는 영역들의 블러 레벨에 따라 촬영된 이미 지의 블러를 제거하여 실제 이미지를 복원할 수 있다. 또한, 디컨볼루션(deconvolution) 필터링 동작에서 발생 한 오버슈트(overshoot)를 보정하기 위한 후처리 동작을 수행함으로써, 이미지의 해상도를 유지하면서도 링 현 상(ring effect) 등의 결함(artifact)을 경감시킬 수 있다. 본 개시의 일 실시예에 따른 오토포커스를 보상하는 방법 또는 오토포커스를 보상하는 전자 장치에 있어서, 파 티션 블록을 필터링하는 동작 또는 필터링된 파티션 블록 내에 포함된 샘플들을 임계값에 기초하여 후처리하는 동작은, Y채널에 대하여만 수행될 수도 있고, YUV 채널들 또는 RGB 채널들에 대해 모두 수행될 수도 있다. 본 개시의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의 의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령 어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령 어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2020-0173681", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2020-0173681", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 오토포커스(auto-focus, AF)를 보상하는 방법의 개요도이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 블록도이다.도 3은 본 개시의 일 실시예에 따른 카메라부의 블록도이다. 도 4는 본 개시의 일 실시예에 따른 오토포커스를 보상하는 방법의 흐름도이다. 도 5는 본 개시의 일 실시예에 따른 현재 파티션 블록에 대응되는 점확산함수(PSF)를 이용하여, 현재 파티션 블 록을 필터링하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 현재 파티션 블록에 대응되는 점확산함수(PSF)를 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 후처리 동작에서 임계값을 결정하는 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 후처리 동작에서 임계값을 결정하는 다른 동작을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시예에 따른 오토포커스를 보상하는 방법을 적용하여 입력 이미지의 오토포커스를 보상 한 결과를 도시한 도면이다. 도 10은 본 개시의 일 실시예에 따른 오토포커스를 보상하는 방법을 적용하여 입력 이미지의 오토포커스를 보상 한 다른 결과를 도시한 도면이다."}
