{"patent_id": "10-2023-0119413", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0037063", "출원번호": "10-2023-0119413", "발명의 명칭": "인공지능 기반의 인간 아바타 제공 장치", "출원인": "왕 보준", "발명자": "왕 보준"}}
{"patent_id": "10-2023-0119413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터 아바타 설정값을 입력받는 사용자 인터페이스부;상기 입력받은 아바타 설정값을 3D 모델링 기술에 적용하여 아바타 이미지를 생성하는 아바타 이미지 생성부;상기 사용자의 음성을 입력받는 음성 입력부;상기 입력받은 음성을 분석하는 음성 분석부;상기 음성 분석부의 분석 결과를 이용하여 상기 음성과 대응하는 텍스트를 생성하는 텍스트 생성부;상기 생성된 텍스트를 음성신호로 변환하는 음성 변환부; 및상기 아바타 이미지에 상기 변환된 음성신호를 결합하는 아바타 통합부;를 포함하는 것을 특징으로 하는 인공지능 기반의 인간 아바타 제공 장치."}
{"patent_id": "10-2023-0119413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 음성 변환부는, 상기 텍스트를 상기 사용자의 음성에 따른 음성신호로 변환하는 것을 특징으로 하는 인공지능 기반의 인간 아바타 제공 장치."}
{"patent_id": "10-2023-0119413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 사용자 인터페이스부는 상기 사용자로부터 주석이 달린 텍스트를 더 입력받으며,상기 음성 변환부는 상기 주석이 달린 텍스트를 상기 음성신호로 변환하는 것을 특징으로 하는 인공지능 기반의인간 아바타 제공 장치."}
{"patent_id": "10-2023-0119413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 텍스트 생성부는, Llama 시리즈, ChatGPT 시리즈, ChatGLM 시리즈, Falcon 시리즈, 및 OpenLLM 시리즈 중어느 하나를 적용하여 상기 음성과 대응하는 텍스트를 생성하는 것을 특징으로 하는 인공지능 기반의 인간 아바타 제공 장치."}
{"patent_id": "10-2023-0119413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 음성 변환부는, Tacotron 시리즈, WaveNet 시리즈 및 Transformer TTS 시리즈 중 어느 하나를 적용하여상기 텍스트를 음성신호로 변환하는 것을 특징으로 하는 인공지능 기반의 인간 아바타 제공 장치."}
{"patent_id": "10-2023-0119413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0037063-3-제 1 항에 있어서,상기 아바타 통합부는, 텍스트 데이터를 처리하는 텍스트 모달(Modal), 음성 데이터를 처리하는 음성 모달, 및이미지 데이터를 처리하는 이미지 모달을 상기 아바타 이미지에 결합하여 멀티모달(MultiMadal)을 형성하는 멀티모달부;를 포함하는 것을 특징으로 하는 인공지능 기반의 인간 아바타 제공 장치."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 인간 아바타 제공 장치가 개시된다. 본 발명의 실시 예에 따른 인공지능 기반의 인간 아바타 제 공 장치는, 사용자로부터 아바타 설정값을 입력받는 사용자 인터페이스부, 입력받은 아바타 설정값을 3D 모델링 기술에 적용하여 아바타 이미지를 생성하는 아바타 이미지 생성부, 사용자의 음성을 입력받는 음성 입력부, 입력 받은 음성을 분석하는 음성 분석부, 음성 분석부의 분석 결과를 이용하여 음성과 대응하는 텍스트를 생성하는 텍 스트 생성부, 생성된 텍스트를 음성신호로 변환하는 음성 변환부 및 아바타 이미지에 변환된 음성신호를 결합하 는 아바타 통합부를 포함한다."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 인간 아바타 제공 장치에 관한 것으로서, 보다 상세하게는, 사용자의 실제 음성으로 대화가 가능한 인공지능 기반의 인간 아바타 제공 장치에 관한 것이다."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트폰의 사용이 일반화되고, 소셜 네트워크 서비스(Social Network Service : SNS)가 확대되면서, 사람들은 온라인 상에서 다른 사람들과 채팅, 음성 채팅, 파일 공유, 블로그 이용 등을 통해 관계를 맺게 되었다. 소셜 네트워크 서비스의 가상 공간에서 사용자가 자신을 표현할 수 있도록 하기 위하여 아바타가 등장하였다. 아바타(Avatar)는 컴퓨터 사용자가 스스로를 묘사한 것으로, 초기에는 컴퓨터 게임에서 많이 사용하였으며, 2차 원 혹은 3차원 모형 형태로 사용자를 표현한다. 아바타는 가상의 공간에서 사용자가 스스로의 모습을 부여한 물체라고 볼 수 있다. 아바타는 사용자의 사진과 같이 단순한 형태일 수도 있고, 사용자의 관심사항, 외모, 신원 등을 표현할 수 있는 그래픽 객체일 수도 있으 며, 애니메이션으로 구현될 수도 있다. 사용자는 소셜 네트워크 서비스를 통해 여러 활동을 하면서 자신의 익명 성 유지를 위해 아바타를 사용할 수도 있다. 현재 서비스되고 있는 아바타 시스템은 사용자를 제대로 표현하기에는 부족함이 있다. 즉, 대부분의 아바타 시 스템에서는 미리 저장되어 있는 아이템들을 아바타에 적용시키는 것이어서, 아무리 다양한 종류의 아이템들이 제공된다 하더라도 모든 사용자들의 개인 취향을 만족시킬 수는 없는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내공개특허공보 제10-2015-0006487호(2015. 01. 16. 공개)"}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제점을 해결하기 위하여 본 발명이 이루고자 하는 기술적 과제는, 사용자의 실제 음성을 아바타에 연 결하고, 인공지능에 의해 상호 작용이 가능한 인공지능 기반의 인간 아바타 제공 장치를 제시하는 데 있다. 본 발명의 해결과제는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 해결과제들은 아래의 기 재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 기술적 과제를 해결하기 위한 수단으로서, 본 발명의 실시 예에 따른 인공지능 기반의 인간 아바타 제공 장치는, 사용자로부터 아바타 설정값을 입력받는 사용자 인터페이스부, 입력받은 아바타 설정값을 3D 모델링 기 술에 적용하여 아바타 이미지를 생성하는 아바타 이미지 생성부, 사용자의 음성을 입력받는 음성 입력부, 입력받은 음성을 분석하는 음성 분석부, 음성 분석부의 분석 결과를 이용하여 음성과 대응하는 텍스트를 생성하는 텍스트 생성부, 생성된 텍스트를 음성신호로 변환하는 음성 변환부 및 아바타 이미지에 변환된 음성신호를 결합 하는 아바타 통합부를 포함한다. 바람직하게, 음성 변환부는, 텍스트를 사용자의 음성에 따른 음성신호로 변환할 수 있다. 또한 바람직하게, 사용자 인터페이스부는 사용자로부터 주석이 달린 텍스트를 더 입력받으며, 음성 변환부는 주 석이 달린 텍스트를 음성신호로 변환할 수 있다. 또한 바람직하게, 텍스트 생성부는, Llama 시리즈, ChatGPT 시리즈, ChatGLM 시리즈, Falcon 시리즈, 및 OpenLLM 시리즈 중 어느 하나를 적용하여 음성과 대응하는 텍스트를 생성할 수 있다. 또한 바람직하게, 음성 변환부는, Tacotron 시리즈, WaveNet 시리즈 및 Transformer TTS 시리즈 중 어느 하나 를 적용하여 텍스트를 음성신호로 변환할 수 있다. 또한 바람직하게, 아바타 통합부는, 텍스트 데이터를 처리하는 텍스트 모달(Modal), 음성 데이터를 처리하는 음 성 모달, 및 이미지 데이터를 처리하는 이미지 모달을 아바타 이미지에 결합하여 멀티모달(MultiMadal)을 형성 하는 멀티모달부를 포함할 수 있다."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사용자가 원하는 선호도에 따라 생성된 아바타를 제공하고, 멀티모달 표현이 가능한 아바타 에 의해 매끄럽고 자연스러운 소통이 가능한 아바타의 구현이 가능한 인공지능 기반의 인간 아바타 제공 장치를 제공하는 효과가 있다."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이상의 본 발명의 목적들, 다른 목적들, 특징들 및 이점들은 첨부된 도면과 관련된 이하의 바람직한 실시 예들 을 통해서 쉽게 이해될 것이다. 그러나 본 발명은 여기서 설명되는 실시 예들에 한정되지 않고 다른 형태로 구 체화될 수도 있다. 오히려, 여기서 소개되는 실시 예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당업자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 명세서에서, 어떤 구성요소가 다른 구성요소 상에 있다고 언급되는 경우에 그것은 다른 구성요소 상에 직접 형성될 수 있거나 또는 그들 사이에 제 3의 구성요소가 개재될 수도 있다는 것을 의미한다. 또한, 도면들에 있 어서, 구성요소들의 두께는 기술적 내용의 효과적인 설명을 위해 과장된 것이다. 또한, 제1 엘리먼트 (또는 구성요소)가 제2 엘리먼트(또는 구성요소) 상(ON)에서 동작 또는 실행된다고 언급될 때, 제1 엘리먼트(또는 구성요소)는 제2 엘리먼트(또는 구성요소)가 동작 또는 실행되는 환경에서 동작 또는 실 행되거나 또는 제2 엘리먼트(또는 구성요소)와 직접 또는 간접적으로 상호 작용을 통해서 동작 또는 실행되는 것으로 이해되어야 할 것이다. 어떤 엘리먼트, 구성요소, 장치, 또는 시스템이 프로그램 또는 소프트웨어로 이루어진 구성요소를 포함한다고 언급되는 경우, 명시적인 언급이 없더라도, 그 엘리먼트, 구성요소, 장치, 또는 시스템은 그 프로그램 또는 소 프트웨어가 실행 또는 동작하는데 필요한 하드웨어(예를 들면, 메모리, CPU 등)나 다른 프로그램 또는 소프트웨 어(예를 들면 운영체제나 하드웨어를 구동하는데 필요한 드라이버 등)를 포함하는 것으로 이해되어야 할 것이다.또한, 어떤 엘리먼트(또는 구성요소)가 구현됨에 있어서 특별한 언급이 없다면, 그 엘리먼트(또는 구성요소)는 소프트웨어, 하드웨어, 또는 소프트웨어 및 하드웨어 어떤 형태로도 구현될 수 있는 것으로 이해되어야 할 것이다. 또한, 본 명세서에서 사용된 용어는 실시 예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '포함한다(comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요소는 하나 이상의 다른 구성요소의 존 재 또는 추가를 배제하지 않는다. 도 1은 본 발명의 바람직한 실시예에 따른 인공지능 기반의 인간 아바타 제공 장치를 도시한 블록도이다. 도 1을 참조하면, 본 발명의 바람직한 실시예에 따른 인공지능 기반의 인간 아바타 제공 장치(이하, '인간 아바 타 제공장치'라 한다)는 사용자 인터페이스부, 아바타 이미지 생성부, 음성 입력부, 음성 분석부, 텍스트 생성부, 음성 변환부, 아바타 통합부, 저장부 및 제어부를 포함 한다. 사용자 인터페이스부는 인간 아바타 제공장치와 사용자 간의 인터페이스를 지원한다. 즉, 사용자 인 터페이스부는 사용자로부터 소정 입력신호 혹은 조작신호를 입력받을 수 있고, 인간 아바타 제공장치(10 0)에서 사용자에게 전달하고자 하는 정보를 제공할 수도 있다. 예를 들면, 사용자 인터페이스부는 사용자 가 원하는 아바타를 생성하기 위해 아바타 설정값 및 주석이 달린 텍스트를 더 입력받을 수 있다. 인간 아바타 제공장치는 사용자 단말장치일 수도 있고, 사용자 단말장치와 통신이 가능한 서버일 수도 있 다. 인간 아바타 제공장치가 사용자 단말장치일 경우에는 사용자 인터페이스부는 사용자로부터 직접 데이터를 입력받을 수 있고, 인간 아바타 제공장치가 서버일 경우에는 사용자 단말장치와의 통신을 통해 사용자가 입력한 데이터를 전송받을 수 있다. 아바타 이미지 생성부는 사용자 인터페이스부를 통해 입력받은 아바타 설정값을 3D 모델링 기술에 적 용하여 아바타 이미지를 생성한다. 3D 모델링 기술을 이용하여 생성된 아바타는 확대, 축소, 회전이 가능하고, 3차원 공간에서 자유자재로 이동이 가능하도록 구현될 수 있다. 음성 입력부는 사용자의 음성을 입력받는다. 인간 아바타 제공장치가 사용자 단말장치일 경우, 음성 입력부는 사용자의 음성을 입력받기 위해 마이크(미도시)와 같은 하드웨어와 연결될 수 있다. 사람마다 제각각 다른 음성을 가지고 있음에 따라, 음성은 사용자를 식별하기 용이한 요소가 될 수 있다. 그런 데, 아바타에 기계음이 적용될 경우 실제 사용자의 음성과는 차이가 많음에 따라, 아바타는 사용자와는 매우 다 른 존재로 느껴지는 상황이었다. 하지만, 본 발명에서는 음성 입력부를 통해 사용자의 음성을 입력받아 이 를 아바타의 음성으로 적용함으로써, 아바타가 실제 사용자와 동일한 음성을 갖도록 구성한다. 음성 분석부는 음성 입력부를 통해 입력받은 음성을 분석하다. 음성 분석부는 동일 사용자로부 터 이전에 입력받은 음성이 있을 경우, 현재 입력받은 음성과 이전에 입력받은 음성의 동일 여부에 대하여도 판 단할 수 있다. 새롭게 입력된 음성과 이전 음성이 동일한 경우에는 별다른 조치를 취할 필요가 없지만, 두 음성 이 서로 다른 경우에는 사용자에게 현재 입력한 음성이 정당한지 확인을 요청할 필요가 있다. 음성 분석부에서는 위스퍼(Whisper)를 사용할 수 있다. 위스퍼는 트랜스포머(Transformer) 구조를 기반으 로 하는 오픈 소스 음성 인식 아키텍처로, 다국어 및 다중 작업 데이터에 대해 ASR 모델 트레이닝이 된 것으로, 시끄러운 환경에서도 음성을 구별하고, 다양한 억양이나 전문 용어에 대한 이해가 가능하다. 위스퍼 아키텍처는 인코더-디코더 변환기로 구현되는 간단한 종단 간 접근 방식으로, 입력 오디오는 30초 단위 로 분할되어 로그-맬(Log-Mel) 스펙트로그램으로 변환되어 다음 인코더로 전달된다. 여기서, 디코더는 단일 모 델이 언어 식별, 구분 수준 타임 스탬프, 다국어 음성 전사 및 영어 음성 번역과 같은 작업을 수행하도록 지시 하는 특수 토큰과 혼합된 해당 텍스트 캡션을 예측하도록 훈련된다. 트랜스포터 모델은 입력 시퀀스의 글로벌 의존성을 포착하기 위해 셀프 어텐션 메커니즘(Self-attention)을 사 용하는 딥러닝 모델의 일종이다. 이러한 유형의 글로벌 의존성은 자연어를 이해하고 처리하는데 중요하다. 이에, 위스퍼에서는 음성 인식 작업에 필수적인 가변길이의 입력 시퀀스를 처리할 수 있는 특수 트랜스포머 구 조를 사용한다.다만, 본 실시예에서는 위스퍼 모델의 일부 언어나 교육 데이터에서 발생 빈도가 낮은 콘텐츠에 대한 인식률이 낮게 나타나는 단점을 해소하기 위해, 주식이 달린 음성 데이터를 사용하여 모델을 자동으로 미세 조정하는 기 능을 제공한다. 이에 의해, 특정 언어 또는 명사의 인식 정확도를 향상시킬 수 있게 되었다. 이러한 미세 조정 방식은 Maas(Model as a Service)의 유형에 속한다. MaaS에서는 사용자가 자신의 필요에 따라 미세 조정이 가능하도록 모델을 맞춤화하여 성능을 향상시킬 수 있고, 모델의 인식 정확도를 향상시킬 수 있으 며, 사용자의 특정 요구에 맞게 모델을 더 잘 조정할 수 있게 된다. 텍스트 생성부는 음성 분석부의 분석 결과를 이용하여 음성과 대응하는 텍스트를 생성한다. 텍스트 생성부는 Llama 시리즈, ChatGPT 시리즈, ChatGLM 시리즈, Falcon 시리즈, 및 OpenLLM 시리즈 중 어느 하 나를 적용할 수 있는데, 이 모델들은 모두 트랜스포터 구조를 기반으로 하는 것이어서 일관성 있고 자연스러운 텍스트의 생성이 가능하다. 본 실시예에서는, 텍스트 생성을 위해 사용되는 모델로 Llama 시리즈, ChatGPT 시리 즈, ChatGLM 시리즈, Falcon 시리즈, 및 OpenLLM 시리즈를 예시하였으나, 이는 반드시 여기에 한정되지 않는다. 즉, Llama 시리즈, ChatGPT 시리즈, ChatGLM 시리즈, Falcon 시리즈, 및 OpenLLM 시리즈와 유사한 기능 혹은 호출 가능한 API(Application Programming Interface)를 가진 모델이라면 모두 적용할 수 있다. Llama 및 ChatGPT는 GPT(Generative Pretrained Transformer) 모델을 기반으로 하며, 대량의 텍스트 데이터를 기반으로 한 다음 특정 작업에 대해 미세 조정이 가능하다. ChatGLM 및 Falcon은 GLM(Generalized Language"}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "Model)을 기반으로 대화 생성 및 요약 생성과 같은 더 복잡한 작업의 처리가 가능하다. 또한, OpenLLM은 다양한 작업 모델을 선택할 수 있는 오픈 소스 언어 모델이다. 텍스트 생성부에 의해 생성되는 텍스트는 사용자가 음성으로 입력한 내용을 그대로 텍스트로 변환한 것일 수 있고, 사용자가 음성으로 질문한 내용에 대한 답변일 수도 있다. 음성 변환부는 텍스트 생성부에 의해 생성된 텍스트를 음성신호로 변환한다. 음성 변환부는 TTS(Text-to-Speech) 기술을 적용하여 텍스트를 음성신호로 변환할 수 있다. TTS는 두가지 주요 음성 합성 기술인 전통적인 연결 TTS 와 AI 기반의 생성 TTS를 사용할 수 있다. 전통적인 연결 TTS는 연결 TTS와 매개변수 TTS가 있다. 연결 TTS는 가장 초기의 TTS 기술 중 하나로, 사전 녹음 된 음성 세그먼트(단어, 음절, 음소 등)를 연결하여 음성을 생성하는 것이다. 매개변수 TTS는 모델을 사용하여 음성을 생성하고, 모델 매개변수는 훈련 데이터로부터 학습된다. 매개변수 TTS는 포먼트(formant) 합성, 관절 합성, 및 HMM 기반 합성을 포함한다. 딥러닝 기술의 발달로 인해 새로운 TTS 기술인 뉴럴(Neural) TTS가 등장하였다. 뉴럴 TTS는 텍스트에서 직접 음 성을 생성하기 위해 심층 학습 모델(예를 들면, sequence-to-sequence model)을 사용한다. 이는, 연결 TTS 및 매개변수 TTS의 장점을 결합하여 높은 품질을 보장하면서 새로운 음성의 생성이 가능하다. 뉴럴 TTS는 Tacotron 시리즈, WaveNet 시리즈 및 Transformer TTS 시리즈 를 포함하며, 이들 중 하나를 선택적으로 적용할 수 있다. 본 실시예에서는, 뉴럴 TTS로 Tacotron 시리즈, WaveNet 시리즈 및 Transformer TTS 시리즈를 선택 적용함을 예시하였지만, 이는 반드시 여기에 한정되지는 않는다. 즉, Tacotron 시리즈, WaveNet 시리즈 및 Transformer TTS 시리즈와 유사한 기능 혹은 호출 가능한 API를 가진 모델이라면 모두 적용할 수 있다. 음성 변환부는 텍스트를 음성신호로 변환할 때, 사용자의 음성을 적용하도록 한다. 즉, 음성 변환부 에 의해 변환된 신호는 사용자의 음성과 동일한 음성신호이다. 또한, 음성 변환부는 사용자 인터페이스부 를 통해 사용자로부터 입력받은 주석이 달린 텍스트를 음성신호로 변환할 수 있다. 아바타 통합부는 아바타 이미지 생성부에 의해 생성된 아바타 이미지에 사용자의 음성으로 변환된 음 성신호를 결합한다. 이에 의해, 사용자의 음성으로 대화가 가능한 3D 아바타가 사용자게에 제공될 수 있다. 또한, 아바타 통합부는 MMF(Multi-Modal Fusion) 아키텍처를 기반으로 아바타의 상호 작용 방식을 구현한 다. 이를 위해, 아바타 통합부는 멀티모달부를 포함한다. 멀티모달부는 서로 다른 모달의 데이터를 서로 연결하여 통합하는 것으로, 텍스트 데이터를 처리하는 텍스 트 모달, 음성 데이터를 처리하는 음성 모달, 및 이미지 데이터를 처리하는 이미지 모달을 아바타 이미지에 결 합하여 멀티 모달을 형성한다. 멀티모달부의 동작에 의해, 서로 다른 모달 데이터 간의 상관 관계와 상호 보완성으로 풍부한 상호 작용 경험을 제공할 수 있다. 저장부는 본 인간 아바타 제공장치의 동작에 필요한 모든 정보를 저장한다. 예를 들면, 저장부 는 아바타 이미지 생성부에서 아바타 이미지를 생성하는데 필요한 세부 정보들을 저장한다. 또한, 저장부 는 사용자로부터 입력받은 음성을 저장할 수 있다. 제어부는 본 인간 아바타 제공장치의 전반적인 동작을 제어한다. 즉, 제어부는 사용자 인터페이 스부, 아바타 이미지 생성부, 음성 입력부, 음성 분석부, 텍스트 생성부, 음성 변환 부, 아바타 통합부 및 저장부들 간의 신호 입출력을 제어한다. 도 2는 본 발명의 바람직한 실시예에 따른 인공지능 기반의 인간 아바타 제공 방법을 설명하기 위한 흐름도이다. 여기에서는 도 1 내지 도 2를 참조하여 본 발명의 바람직한 실시예에 따른 인공지능 기반의 인간 아바타 제공 방법을 설명한다. 사용자는 아바타를 생성하기 위해 아바타 설정값을 입력한다. 아바타 설정값은 아바타 이미지를 생성하기 위해 아바타 각 부분에 대한 선택 및 설정을 포함한다. 사용자가 입력하는 아바타 설정값은 사용자 인터페이스부 를 통해 입력된다(S210). 아바타 이미지 생성부에서는 사용자 인터페이스부를 통해 입력된 사용자에 의해 설정된 아바타 설정 값을 이용하여 아바타 이미지를 생성한다(S220). 사용자는 자신의 아바타에 등록하기 위해 자신의 음성을 입력한다. 혹은, 아바타가 기생성되어 있는 상태일 경 우, 아바타와의 대화를 위한 음성을 입력할 수 있다(S230). 음성 분석부에서는 사용자가 입력한 음성을 분석한다(S240). 이때, 음성 분석부는 사용자가 입력한 음성을 분석하여 사용자가 입력한 내용을 파악할 수 있다. 텍스트 생성부에서는 사용자가 입력한 음성을 텍스트로 생성한다(S250). 이때, 텍스트는 한가지 언어에 제 한되지 않고 다양하게 적용될 수 있으며, 특히 두 가지 이상의 언어가 혼재되어 있는 경우에 해당 언어에 대한 텍스트로 변환한다. 이후, 텍스트 생성부에 의해 생성된 텍스트는 음성 변환부에 의해 이전에 사용자가 입력한 음성에 대 한 음성신호로 변환된다(S260). 즉, 사용자가 아바타와 대화를 시도하거나 혹은 질문을 하였을 때 사용자의 음 성으로 답변을 제공할 수 있다. 아바타 통합부는 음성 변환부에 의해 생성된 음성신호를 아바타 이미지에 결합한다. 이를 통해, 사용 자의 음성으로 말하는 아바타가 제공된다(S270). 이러한 동작에 의해, 사용자가 원하는 바에 따라 맞춤형 외모, 목소리 및 성격 등을 갖는 아바타를 제공할 수 있다. 이러한 아바타는 컴퓨터 게임, SNS와 같은 개인을 위해서도 적용이 가능하고, 박물관과 같은 공공시설에 서도 자연스럽게 소통이 가능할 수 있다."}
{"patent_id": "10-2023-0119413", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 발명이 속하는 기술분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고서 다른 구 체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면 에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상기 상세한 설명보다 는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2023-0119413", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 바람직한 실시예에 따른 인공지능 기반의 인간 아바타 제공 장치를 도시한 블록도, 그리고, 도 2는 본 발명의 바람직한 실시예에 따른 인공지능 기반의 인간 아바타 제공 방법을 설명하기 위한 흐름도이다."}
