{"patent_id": "10-2018-0124282", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0043660", "출원번호": "10-2018-0124282", "발명의 명칭": "음성 합성 방법 및 음성 합성 장치", "출원인": "주식회사 케이티", "발명자": "김태환"}}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서에 의하여 음성을 합성하는 방법에 있어서,얼굴 이미지를 입력 받는 단계;상기 얼굴 이미지로부터 얼굴 특징 모델을 이용하여 얼굴 특징을 추출하는 단계;생성 모델(Generative model) 알고리즘을 이용하는 목소리 모델을 통해 상기 얼굴 특징에 대응되는 목소리를 생성하는 단계; 및상기 목소리와 입력되는 텍스트를 조합하여 텍스트 음성을 합성하는 단계; 를 포함하는 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 얼굴 특징 모델은제1 고차원 얼굴 이미지 벡터를 저차원 얼굴 이미지 벡터로 압축하는 제1 압축 단계;제1 고차원 목소리 벡터를 저차원 목소리 벡터로 압축하는 제2 압축 단계;상기 저차원 얼굴 이미지 벡터를 제2 고차원 얼굴 이미지 벡터로 복원하는 제1 복원 단계; 및상기 저차원 목소리 벡터를 제2 고차원 목소리 벡터로 복원하는 제2 복원 단계; 를 통해 학습되는 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 제1 압축 단계, 상기 제2 압축 단계, 상기 제1 복원 단계 및 상기 제2 복원 단계는상기 복원된 제2 고차원 얼굴 이미지 벡터가 상기 제1 고차원 얼굴 이미지 벡터와 소정 크기 이상의 유사도를가지고, 상기 복원된 제2 고차원 목소리 벡터가 상기 제1 고차원 목소리 벡터와 소정 크기 이상의 유사도를 가질 때까지 반복되는 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서, 상기 저차원 얼굴 이미지 벡터와 상기 저차원 목소리 벡터는 저차원 특징을 공유하며,상기 저차원 특징의 공유는 상기 제1 압축 단계에서 추출되는 얼굴 특징과 상기 제2 압축 단계에서 생성되는 목소리 특징을 맵핑함으로써 이루어지는 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 제1 복원 단계는 공유되는 상기 저차원 얼굴 이미지 벡터 및 저차원 목소리 벡터를 이용하여 상기 제2 고차원 얼굴 이미지로 복원하는 단계이고,상기 제2 복원 단계는 공유되는 상기 저차원 얼굴 이미지 벡터 및 저차원 목소리 벡터를 이용하여 상기 제2 고차원 목소리로 복원하는 단계인 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3 항에 있어서, 상기 제1 압축 단계, 상기 제2 압축 단계, 상기 제1 복원 단계 및 상기 제2 복원 단계는오토-인코더(Auto-encoder) 알고리즘을 사용하여 수행되는 것을 특징으로 하는 음성 합성 방법.공개특허 10-2020-0043660-3-청구항 7 제1 항에 있어서, 상기 얼굴 이미지는촬영부를 통해 촬영된 얼굴에 대한 이미지 데이터인 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서, 상기 얼굴 특징 모델과 상기 목소리 모델 중 하나 이상은상기 프로세서가 포함된 음성 합성 장치의 외부에서 생성되어 상기 음성 합성 장치에 저장되는 것을 특징으로하는 음성 합성 방법."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "얼굴을 촬영하여 얼굴 이미지를 생성하는 촬영부;적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램의 제어에 따라 동작하는 프로세서;를 포함하고,상기 프로세서는 상기 얼굴 이미지를 입력 받고, 상기 얼굴 이미지로부터 얼굴 특징 모델을 이용하여 얼굴 특징을 추출하며, 생성 모델 알고리즘을 이용하는 목소리 모델을 통해 상기 얼굴 특징에 대응되는 목소리를 생성하고, 상기 목소리와 입력되는 텍스트를 조합하여 텍스트 음성을 합성하는 것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2018-0124282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 얼굴 특징 모델과 상기 목소리 모델은외부의 장치에서 학습되어 생성된 후 상기 음성 합성 장치의 내부에 저장되는 것을 특징으로 하는 음성 합성 장치."}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 입력되는 얼굴 이미지의 특징에 대응되는 음성을 합성하기 위한 음성 방법 및 음성 합성 장치에 관한 것으로서, 본 발명의 실시예에 따른 음성 합성 방법은 얼굴 이미지를 입력 받는 단계; 상기 얼굴 이미지로부터 얼굴 특징을 추출하는 단계; 목소리 모델을 이용하여 상기 얼굴 특징에 대응되는 목소리를 생성하는 단계; 및 상 기 목소리와 입력되는 텍스트를 조합하여 텍스트 음성을 합성하는 단계; 를 포함하고, 상기 목소리 모델은 생성 모델(Generative model)을 통해 상기 목소리를 생성할 수 있다."}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 합성 방법 및 음성 합성 장치에 관한 것으로서, 보다 상세하게는 입력되는 얼굴 이미지의 특징 에 대응되는 음성을 합성하기 위한 음성 방법 및 음성 합성 장치에 관한 것이다."}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 통신 기술과 전자 장치 기술의 발달과 함께, 사용자 간의 관계를 온라인으로 형성하기 위한 다양한 방법들 이 제시되고 있다. 특히, 사용자가 온라인 상에서 자신을 표현하기 위하여 아바타와 같은 사이버상의 캐릭터를 이용하는 경우가 많다. 사용자의 개성을 나타내기 위하여 아바타는 다양한 형태로 표현될 수 있고, 다양한 방법 으로 치장될 수 도 있다. 사람 형상의 아바타의 경우, 실제 사용자의 얼굴을 촬영하고, 그 특징을 활용하여 생성함으로써 더욱 사용자가 실감나게 몰입할 수 있는 환경을 조성하는 경우가 있다. 최근에는 아바타를 이용한 보다 다양한 활동을 제공하기 위한 많은 연구가 진행되고 있고, 단지 형상과 모양을 가진 상태로 움직이는 것뿐 아니라 상호 작용을 위해 아바타가 음성을 발성토록 하는 음성 합성 서비스가 제공 되기도 한다. 그러나 종래의 음성 합성 서비스는 성우나 유명인들의 음성 데이터를 이용함으로써 사용자에게 익숙한 목소리로 텍스트를 읽어주는 음성 합성 기술을 이용한다. 하지만 이러한 음성합성 시스템의 경우 성우나 유명인의 목소리 를 사용한다는 점에서 고비용이 발생하게 되고 이미 생성되어 저장된 목소리를 사용할 수 있을 뿐, 실제 사용자 의 목소리 특징을 살릴 수 없다. 따라서, 얼굴 이미지에 대응하여 출력되는 목소리가 사용자의 실제 목소리와 어울리지 않아 부자연스러워 지고,"}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "목소리에 대한 몰입감이 감소하게 되는 문제점이 있다.발명의 내용"}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예에 따른 음성 합성 방법 및 음성 합성 장치는 입력되는 얼굴 이미지의 특징을 이용하여 목소리 를 생성함으로써, 입력되는 얼굴 이미지에 어울리고 자연스러운 목소리로 음성을 출력할 수 있도록 하는 것에 그 목적이 있다. 본 발명의 실시예에 따른 음성 합성 방법 및 음성 합성 장치는 입력되는 얼굴 이미지의 특징을 이용하여 목소리 를 생성함으로써, 성우나 유명인의 목소리를 데이터베이스로 활용하지 않아도 되게 함으로써, 음성 합성 서비스 에 제공되는 비용을 절감시키는 것에 다른 목적이 있다."}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 과제를 해결하기 위해 본 발명의 일 실시예에 따른 음성 합성 방법은 프로세서에 의하여 음성을 합성하 는 방법에 있어서, 얼굴 이미지를 입력 받는 단계; 상기 얼굴 이미지로부터 얼굴 특징 모델을 이용하여 얼굴 특 징을 추출하는 단계; 생성 모델(Generative model) 알고리즘을 이용하는 목소리 모델을 통해 상기 얼굴 특징에 대응되는 목소리를 생성하는 단계; 및 상기 목소리와 입력되는 텍스트를 조합하여 텍스트 음성을 합성하는 단계; 를 포함할 수 있다. 상기 얼굴 특징 모델은 제1 고차원 얼굴 이미지 벡터를 저차원 얼굴 이미지 벡터로 압축하는 제1 압축 단계; 제 1 고차원 목소리 벡터를 저차원 목소리 벡터로 압축하는 제2 압축 단계; 상기 저차원 얼굴 이미지 벡터를 제2 고차원 얼굴 이미지 벡터로 복원하는 제1 복원 단계; 및 상기 저차원 목소리 벡터를 제2 고차원 목소리 벡터로 복원하는 제2 복원 단계; 를 통해 학습될 수 있다. 상기 제1 압축 단계, 상기 제2 압축 단계, 상기 제1 복원 단계 및 상기 제2 복원 단계는 상기 복원된 제2 고차 원 얼굴 이미지 벡터가 상기 제1 고차원 얼굴 이미지 벡터와 소정 크기 이상의 유사도를 가지고, 상기 복원된 제2 고차원 목소리 벡터가 상기 제1 고차원 목소리 벡터와 소정 크기 이상의 유사도를 가질 때까지 반복될 수 있다. 상기 저차원 얼굴 이미지 벡터와 상기 저차원 목소리 벡터는 저차원 특징을 공유하며, 상기 저차원 특징의 공유 는 상기 제1 압축 단계에서 추출되는 얼굴 특징과 상기 제2 압축 단계에서 생성되는 목소리 특징을 맵핑함으로 써 이루어질 수 있다. 상기 제1 복원 단계는 공유되는 상기 저차원 얼굴 이미지 벡터 및 저차원 목소리 벡터를 이용하여 상기 제2 고 차원 얼굴 이미지로 복원하는 단계이고, 상기 제2 복원 단계는 공유되는 상기 저차원 얼굴 이미지 벡터 및 저차 원 목소리 벡터를 이용하여 상기 제2 고차원 목소리로 복원하는 단계일 수 있다. 상기 제1 압축 단계, 상기 제2 압축 단계, 상기 제1 복원 단계 및 상기 제2 복원 단계는 오토-인코더(Auto- encoder) 알고리즘을 사용하여 수행될 수 있다. 상기 얼굴 이미지는 촬영부를 통해 촬영된 얼굴에 대한 이미지 데이터일 수 있다. 상기 얼굴 특징 모델과 상기 목소리 모델 중 하나 이상은 상기 프로세서가 포함된 음성 합성 장치의 외부에서 생성되어 상기 음성 합성 장치에 저장될 수 있다. 상기한 과제를 해결하기 위한 본 발명의 다른 실시예에 다른 음성 합성 장치는 얼굴을 촬영하여 얼굴 이미지를 생성하는 촬영부; 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램의 제어에 따라 동 작하는 프로세서;를 포함하고, 상기 프로세서는 상기 얼굴 이미지를 입력 받고, 상기 얼굴 이미지로부터 얼굴 특징 모델을 이용하여 얼굴 특징을 추출하며, 생성 모델 알고리즘을 이용하는 목소리 모델을 통해 상기 얼굴 특 징에 대응되는 목소리를 생성하고, 상기 목소리와 입력되는 텍스트를 조합하여 텍스트 음성을 합성할 수 있다. 상기 얼굴 특징 모델과 상기 목소리 모델은 외부의 장치에서 학습되어 생성된 후 상기 음성 합성 장치의 내부에 저장될 수 있다."}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 입력되는 얼굴 이미지의 특징을 이용하여 목소리를 생성함으로써, 입력되는 얼굴 이미지에 어울리고 자연스러운 목소리로 음성을 출력할 수 있다. 본 발명은 얼굴 이미지의 특징을 이용하여 목소리를 생성함으로써, 성우나 유명인의 목소리를 데이터베이스로 활용하지 않아도 되게 함으로써, 음성 합성 서비스에 제공되는 비용을 절감시키는 효과가 있다. 다만, 본 발명의 일 실시예에 따라 달성할 수 있는 효과는 이상에서 언급한 것들로 제한되지 않으며, 언급하지"}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고, 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대 해 한정하려는 것이 아니며, 본 발명은 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체 물을 포함하는 것으로 이해되어야 한다. 본 발명을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제 1, 제 2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 사람의 성대에서 발생된 소리는 혀, 구개(입천장), 입술 등으로 이루어진 성도를 지남으로써 외부로 표현되는 목소리로 만들어 진다. 이러한 목소리는 성대의 특징뿐만 아니라 흔히 구강구조라고 불리는 성도의 특징에도 많 은 영향을 받게 된다. 이러한 이유 때문에 특정 사람의 성대모사를 하기 위해서 특정 입 모양을 하는 모습을 흔히 볼 수 있다. 본 발 명에서는 얼굴 이미지를 이용하여 가상 아바타(Avatar)를 만들 때 사용자의 특징을 살릴 수 있는 목소리를 함께 생성해주어 획일화된 목소리가 아닌 본인의 아바타와 어울리는 목소리를 만들어줄 수 있는 방법 및 장치를 개시 한다. 도 1은 본 발명의 일 실시예에 따른 음성 합성 장치를 설명하기 위한 도면이다. 도 1의 음성 합성 장치는 촬영부, 디스플레이, 메모리, 프로세서, 통신부 및 음성출력부를 포함할 수 있 다. 음성 합성 장치는 입력된 이미지로부터 얼굴 특징을 추출하고 얼굴 특징에 대응하여 목소리를 생성하고 음 성을 합성하기 위한 장치로서, 웹/모바일 사이트 또는 전용 어플리케이션의 제어 하에 서비스 화면 구성, 데이 터 입력, 데이터 송수신, 데이터 저장 등 서비스 전반의 동작을 수행할 수 있다. 음성 합성 장치는 촬영부 를 포함하며, 입력된 이미지로부터 그래픽 처리가 가능한 스마트폰 뿐만 아니라, 데스크탑 컴퓨터, 노트북 컴퓨터, PDA, 웹 패드, 테블릿 PC 등의 다양한 장치를 포함할 수 있다. 촬영부는 대상 객체를 촬영할 수 있다. 촬영부는 음성 합성 장치에 내장된 카메라 또는 별도의 장치로 연결된 외부의 카메라를 포함할 수 있으며, 사진이나 영상의 형태로 사람의 얼굴을 촬영함으로써 얼굴 이미지 데이터를 생성할 수 있다. 디스플레이는 후술하는 프로세서의 처리에 따라, 데이터를 사용자에게 시각적으로 표시할 수 있다. 메모리는 적어도 하나의 프로그램이 저장될 수 있다. 또한, 후술할 얼굴 특징 모델 또는 목소리 모델과 관 련된 파일이 저장될 수 있고, 프로세서의 요청에 따라 저장된 데이터를 제공할 수 있다. 프로세서는 입력되는 이미지 데이터로부터 대상 객체를 인식하기 위한 연산을 처리할 수 있다. 통신부는 프로세서의 제어에 따라 외부의 장치와 무선 또는 유선으로 데이터를 송신하거나 수신하기 위한 구성이다. 음성출력부는 프로세서의 제어에 따라 합성된 음성을 음성 합성 장치의 외부로 출력 하기 위한 구성이다. 보다 상세하게, 프로세서는 촬영부를 통해 입력되는 얼굴 특징 모델을 이용하여 얼굴 이미지로부터 얼굴 특징을 추출할 수 있다. 이후, 목소리 모델을 이용하여 얼굴 특징에 대응되는 목소리를 생성할 수 있다. 이후, 목소리와 입력되는 텍스트를 조합하여 텍스트 음성을 합성할 수 있다. 여기서, 얼굴 특징 모델과 목소리 모델은 음성 합성 장치가 음성을 합성하는 과정에서 요구되는 연산량을 감소시키기 위하여, 음성 합성 장치의 외부에서 미리 생성되어 음성 합성 장치의 메모리에 저장 된 상태일 수 있다. 즉, 음성 합성 장치는 외부에서 학습되어 생성된 얼굴 특징 모델과 목소리 모델을 저장하고, 해당 모델들 에 포함되는 가중치 값을 이용하여 얼굴 특징을 분석하고 목소리를 생성함으로써 적은 연산량으로도 음성을 합 성할 수 있게 된다. 따라서, 데스크탑 PC나 대형 컴퓨터에 비하여 비교적 연산 처리 성능이 낮은 스마트폰이나 노트북 컴퓨터, 태블릿 PC 등에서도 음성 합성을 원활히 수행할 수 있는 효과가 있다. 음성 합성에 사용되는 얼굴 특징 모델과 목소리 모델을 생성하는 방법에 대해선 후술하기로 한다. 도 2는 본 발명의 다른 실시예에 따른 음성 합성 방법을 설명하기 위한 도면이다. 도 2를 참조하면, 음성 합성 방법은 얼굴 이미지를 입력 받는 단계(S100), 얼굴 특징을 추출하는 단계(S110), 목소리를 생성하는 단계(S120) 및 텍스트 음성을 합성하는 단계(S130)를 포함할 수 있다. 도 2를 설명함에 있어, 도 1과 중복되는 구성 또는 효과에 대한 설명은 생략하기로 한다. 얼굴 이미지를 입력 받는 단계(S100)는 음성 합성 장치의 촬영부 또는 외부에서 입력되는 얼굴 이미지를 입력받 는 단계일 수 있다. 상기 얼굴 이미지는 적어도 한 명의 사람의 얼굴을 촬영한 이미지에 대한 데이터를 포함할 수 있다. 얼굴 특징을 추출하는 단계(S110)는 입력된 얼굴 이미지로부터 얼굴 특징을 추출하는 단계로서, 얼굴 특징 모델 을 이용하여 수행될 수 있다. 이 때, 얼굴 특징 모델은 다른 장치를 통해 이미 생성되어 음성 합성 장치에 저장 된 상태일 수 있다. 음성 합성 장치는 얼굴 특징 모델에 포함되는 다양한 가중치 값들을 적용하여 입력되는 얼 굴 이미지로부터 얼굴 특징을 추출할 수 있다. 목소리를 생성하는 단계(S120)는 추출된 얼굴 특징으로부터 목소리를 생성하는 단계로서, 목소리 모델을 이용하 여 수행될 수 있다. 목소리를 생성하는 단계(S120)를 통해 생성된 목소리는 얼굴 특징에 대응되는 음색을 가질 수 있다. 즉, 목소리 파형이나 주파수와 관련된 목소리 특징은 얼굴 특징에 대응하여 다양하게 생성될 수 있다. 목소리 모델은 다른 장치를 통해 이미 생성되어 음성 합성 장치에 저장된 상태일 수 있다. 음성 합성 장치는 목 소리 모델에 포함되는 다양한 가중치 값들을 적용하여 추출된 얼굴 특징에 대응되는 목소리를 생성할 수 있다. 텍스트 음성을 합성하는 단계(S130)는 목소리를 생성 하는 단계(S120)를 통해 생성된 목소리와 입력되는 텍스트 를 조합하여 해당 텍스트를 발음하는 텍스트 음성을 합성하는 단계일 수 있다. 텍스트 음성을 합성함에 있어서, 상기한 방법으로 생성된 목소리와 텍스트에 대해서 TTS(Text to Speech) 프로그램이 사용될 수 있다. 도 3은 도 2의 음성 합성 방법에 사용되는 모델들의 학습 방법을 설명하기 위한 도면이다. 본 발명에서는 얼굴 이미지로부터 얼굴 특징을 추출하기 위한 얼굴 특징 모델과 추출된 얼굴 특징으로부터 목소 리를 생성하기 위한 목소리 모델이 사용될 수 있다. 이러한 모델들은 여러 층의 인공 신경망(Artificial neural network)을 사용하는 딥러닝(Deep learning) 학습 방법을 통해 이루어질 수 있다. 딥러닝을 통한 모델 생성은 많은 그래픽 연산을 요구하므로, 그래픽 연산 처리 속도가 우수한 다른 장치에서 수 행됨이 바람직하다. 얼굴 특징 모델을 생성하기 위해선 얼굴 이미지로부터 얼굴의 특징을 추출하고, 목소리로부 터 목소리의 특징을 추출할 수 있어야 한다. 이러한 특징의 추출과 관련하여 또한, 본 발명에서는 인공지능 알 고리즘 중 오토인코더(Auto-Encoder)를 사용할 수 있다. 오토인코더의 경우, 부호화(Encoding)와 복호화(Decoding)의 구조를 통해 고차원 입력 데이터를 저차원의 공간에서 표현할 수 있게 된다. 이러한 구조는 고차 원 입력 데이터 중에서 입력 데이터를 가장 잘 표현할 수 있는 특징들만 추출해서 저차원 데이터로 압축할 수 있다. 상기한 방법을 통해 얼굴 특징 모델이 학습되어 생성되는 과정을 보다 상세히 설명하면 다음과 같다. 얼굴 특징 모델은 제1 고차원 얼굴 이미지 벡터를 저차원 얼굴 이미지 벡터로 압축하는 제1 압축 단 계, 제1 고차원 목소리 벡터를 저차원 목소리 벡터로 압축하는 제2 압축 단계, 저차원 얼굴 이미지 벡터를 제2 고차원 얼굴 이미지 벡터로 복원하는 제1 복원 단계, 저차원 목소리 벡터를 제2 고 차원 목소리 벡터로 복원하는 제2 복원 단계를 따를 수 있다. 여기서, 제1 고차원 얼굴 이미지 벡터는 원본의 얼굴 이미지에 대한 벡터값을 의미할 수 있고, 제2 고차원 얼굴 이미지 벡터는 저차원 얼굴 이미지 벡터에 기초하여 복원된 고차원 얼굴 이미지 벡터를 의미할 수 있다. 이러한 학습의 초기 단계에서 복원된 제2 고차원 얼굴 이미지 벡터는 사람의 얼굴 형상을 제대로 갖추지 못하여 기존의 제1 고차원 얼굴 이미지 벡터와 많은 차이를 보일 수 있다. 그러나, 복원된 제2 고 차원 얼굴 이미지 벡터를 제1 고차원 얼굴 이미지 벡터와 비교하여 유사도가 낮은 제2 고차원 얼굴 이미지 벡터로 복원하는 방법을 회피하고, 유사도가 높은 제2 고차원 얼굴 이미지 벡터로 복원하는 방법을 반복 학습 시킴으로써 제2 고차원 얼굴 이미지 벡터는 제1 고차원 얼굴 이미지 벡터와 유사도 가 증가하게 된다. 이러한 과정을 통해서 기존의 제1 고차원 얼굴 이미지 벡터에서 주요 얼굴 특징만 찾아내어 저차원 얼굴 이미지 벡터로 압축하는 제1 압축 단계와 저차원 얼굴 이미지 벡터를 유사도가 높은 제2 고차원 얼굴 이미지 벡터로 복원하는 제1 복원 단계를 수행하는 얼굴 특징 모델이 생성될 수 있다. 또한, 얼굴 특징 모델은 제1 고차원 목소리 벡터를 저차원 목소리 벡터로 압축하는 제2 압축 단계와 다시 저차원 목소리 벡터를 제2 고차원 목소리 벡터로 복원하는 제2 복원 단계를 수행할 수 있다. 여 기서, 제1 고차원 목소리 벡터는 원본의 목소리에 대한 벡터값을 의미할 수 있고, 제2 고차원 목소리 벡터 는 저차원 목소리 벡터에 기초하여 복원된 고차원 목소리 벡터를 의미할 수 있다. 이러한 학습의 초 기 단계에서 복원된 제2 고차원 목소리 벡터는 잡음 위주의 소리로서 기존의 제1 고차원 목소리 벡터(22 0)와 많은 차이를 보일 수 있다. 그러나, 복원된 제2 고차원 목소리 벡터를 제1 고차원 목소리 벡터 와 비교하여 유사도가 낮은 제2 고차원 목소리 벡터로 복원하는 방법을 회피하고, 유사도가 높은 제2 고차 원 목소리 벡터로 복원하는 방법을 반복 학습 시킴으로써 제2 고차원 목소리 벡터는 제1 고차원 목소 리 벡터와 유사도가 증가하게 된다. 즉, 고차원의 얼굴 특징과 목소리 특징을 저차원으로 압축하고, 압축된 저차원의 얼굴 특징과 목소리 특징을 다 시 복원하는 단계를 반복 학습함으로써 복원된 특징과 원래의 특징의 유사도를 향상시킬 수 있게 된다. 상기 얼굴 특징 모델에 대한 학습 단계는 복원된 목소리 또는 얼굴 특징이 원래의 목소리 또는 얼굴 특징과 소 정 크기 이상의 유사도를 가지게 될 때까지 반복 수행될 수 있다. 여기에서, 복원된 특징과 원래 특징 간의 유 사도는 80% 이상이 그 기준으로서 예시될 될 수 있다. 또한, 상기한 과정에서 얼굴 특징과 목소리 특징을 저차원으로 압축할 때, 압축된 저차원 얼굴 이미지 벡터와 저차원 목소리 벡터의 저차원 특징을 공유시킬 수 있다. 도 3에 도시된 바와 같이, 고차원 벡터(210, 220)를 저차원 벡터로 변환하고, 저차원 벡터를 고차원 벡터(240, 250)로 변환하는 과정에 있어서, 저차원 벡터를 공유할 수 있다. 저차원 벡터를 통해 목소리 특징과 얼굴 특징의 저차원 특징이 공유될 수 있다. 보다 상세하게, 상기 제1 압축 단계에서 추출되는 얼굴 특징과 상기 제2 압축 단계에서 생성되는 목소리 특징을 맵핑함으로써 저차원 특 징의 공유가 이루어질 수 있다. 즉, 저차원 특징 공간에서 공유되는 내용은 얼굴 특징 벡터와 목소리 특징 벡터 를 하나의 벡터로 표현하였을 때, 동일한 벡터를 가지는 것을 의미할 수 있다. 그리고 제1 복원 단계와 제2 복원 단계가 수행될 때, 공유된 저차원 특징을 기초로 하여 복원이 수행될 수 있다. 보다 상세하게, 제1 복원 단계는 공유되는 상기 저차원 얼굴 이미지 벡터 및 저차원 목소리 벡터를 이용 하여 상기 제2 고차원 얼굴 이미지로 복원하는 단계이고, 제2 복원 단계는 공유되는 상기 저차원 얼굴 이미지 벡터 및 저차원 목소리 벡터를 이용하여 상기 제2 고차원 목소리로 복원하는 단계일 수 있다. 따라서, 저차원 벡터의 저차원 특징을 공유하도록 함으로써, 학습이 진행되는 과정에서 저차원의 얼굴 이 미지 특징 벡터를 통해 고차원의 얼굴을 복원하는 것뿐 아니라, 고차원의 목소리도 복원할 수 있게 된다. 또한, 저차원의 목소리 특징 벡터를 통해 고차원의 목소리를 복원하는 것뿐 아니라, 고차원의 얼굴도 복원할 수 있게 된다. 목소리 모델은 생성 모델(Generative model) 알고리즘을 이용하여 얼굴 특징으로부터 목소리를 생성하는 모델일 수 있다. 보다 상세하게, 딥 러닝 학습 방법 중 이미지 데이터를 학습하여 새로운 이미지를 만들어내거나 손상 된 이미지를 복구시키는 등의 다양한 이미지 처리 기술에 사용되는 생성 모델(Generative model)을 이용하여 목 소리 모델을 생성할 수 있다. 생성 모델을 사용하여 목소리를 생성하는 경우, 기 생성된 목소리의 유형에 한정되지 않고, 얼굴 특징과 목소리 특징에 대응되는 새로운 목소리를 생성할 수 있게 된다. 따라서, 다양한 얼굴 이미지로부터 추출되는 얼굴 특징 과 목소리 특징에 대응하여 기존에 없던 목소리가 생성될 수 있다. 예를 들어, 음성 합성 장치의 사용자가 자신 의 얼굴을 촬영하여 목소리를 생성하고자 하는 경우, 이미 녹음되어 저장된 성우나 유명 배우의 목소리에 한정 되지 않고 사용자의 얼굴에 대응되는 목소리가 생성될 수 있게 된다."}
{"patent_id": "10-2018-0124282", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정 적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2018-0124282", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 음성 합성 장치를 설명하기 위한 도면이다. 도 2는 본 발명의 다른 실시예에 따른 음성 합성 방법을 설명하기 위한 도면이다. 도 3은 도 2의 음성 합성 방법에 사용되는 모델들의 학습 방법을 설명하기 위한 도면이다."}
