{"patent_id": "10-2022-0047364", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0148535", "출원번호": "10-2022-0047364", "발명의 명칭": "멀티 에이전트 강화학습 시스템 및 그 동작 방법", "출원인": "한국과학기술원", "발명자": "김주영"}}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "멀티 에이전트 강화학습 심층 신경망 학습에 필요한 가중치들을 초기화하여 저장하고, PCIe 인터페이스로부터학습 샘플들을 제공 받는 가중치 메모리; 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희소성 벡터, 가중치 희소 인덱스, 실제 연산량을 포함하는희소 데이터를 생성하고, 생성된 희소 데이터를 행방향 가중치 희소성 데이터 메모리에 저장하는 가중치 희소데이터 생성 유닛; 상기 가중치 메모리로부터 가중치를 불러와 상기 생성된 희소 데이터의 형태에 따라 가중치 값들을 압축하여,실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하는 가중치 데이터 압축 유닛; 가중치 그룹화, 순방향 전파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망 학습의 전 과정을 제어하는 명령 스케줄러; 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정에서 레이어 내 병렬처리를 수행하는희소성 병렬처리 아키텍처; 상기 희소성 병렬처리 아키텍처의 하나의 레이어의 연산이 끝나면 각각의 희소성 병렬처리 아키텍처의 결과를합치는 축적기; 및 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나눠주는 연산량 분배기 를 포함하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,한 번의 에포크 동안 상기 가중치 희소 데이터 생성 유닛을 통해 상기 희소 데이터를 생성하고, 생성된 희소 데이터의 형태에 따라 상기 가중치 데이터 압축 유닛을 통해 가중치 값들을 압축하여, 실제 연산량및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하고, 상기 명령 스케줄러의 제어에 따라 상기 축적기를 통해 각각의 희소성 병렬처리 아키텍처의 결과를 합치고, 상기 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 각각의 코어에 나눠주는 연산 방식을 반복하고,상기 연산 결과에 따른 가중치를 업데이트하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 가중치 희소 데이터 생성 유닛은, 가중치 그룹화를 위해 희소성을 생성하고자 하는 레이어에 대해 각각의 입력채널 가중치 그룹행렬과 출력채널가중치 그룹행렬을 생성하고, 생성된 입력채널 가중치 그룹행렬의 열과 출력채널 가중치 그룹행렬의 행에 있는 그룹 개의 데이터에서 최댓값인덱스를 찾고 각각의 최댓값 인덱스를 저장한 후에 비교하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,공개특허 10-2023-0148535-3-상기 가중치 희소 데이터 생성 유닛은, 상기 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스를 비교하여, 최댓값 인덱스가 일치할 경우, 희소성 벡터의 요소를 1로 생성하고, 최댓값 인덱스가 일치하지 않을 경우, 희소성 벡터의 요소를 0으로 생성하며, 상기 최댓값 인덱스가 일치하는 위치와 일치하는 개수를 저장하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 가중치 희소 데이터 생성 유닛은, 상기 입력채널 가중치 그룹행렬과 상기 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스 중 최댓값 인덱스의 값은 1이고 나머지는 0인 입력채널 가중치 선택 행렬과 출력채널 가중치 선택 행렬을 생성하고, 상기 입력채널 가중치 선택 행렬과 상기 출력채널 가중치 선택 행렬을 곱하여 희소성을 생성하고자 하는 레이어와 동일한 크기의 가중치 마스크 행렬을 생성하고, 가중치 마스크 행렬의 값이 1인 경우, 해당 가중치를 연산에 이용하며, 가중치 마스크 행렬의 값이 0인 경우, 해당 가중치는 에포크에서 사용되지 않는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 연산량 분배기는, 상기 가중치 희소 데이터 생성 유닛에서 생성된 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬에 대해각각의 코어가 모두 동일한 개수의 가중치 그룹행렬 열을 가질 경우 연산량이 일정하게 수렴할 것을 예측하여연산량을 스케쥴링하고, 연산량을 예측한 후 해당 연산량에 따라 레이어의 입력과 가중치를 압축하여 희소성 병렬처리 아키텍처에 전달하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 희소성 병렬처리 아키텍처는, 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 상기 가중치 희소 데이터 생성 유닛에서 생성된 가중치 마스크 행렬에 따라 서로 다른 벡터 프로세싱 유닛에 분배하고, 상기 가중치 마스크 행렬의 열 마다 실제 연산량에차이가 존재하므로, 벡터 프로세싱 유닛을 통해 상기 벡터 프로세싱 유닛 간의 고정된 연결을 최소화하여 연산량을 분배하도록 하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 희소성 병렬처리 아키텍처는, 상기 벡터 프로세싱 유닛은 복수의 가중치 마스크 행렬의 열을 병렬처리하고, 입력 메모리로부터 입력 데이터가 브로드캐스팅 되고 가중치 메모리로부터 각각의 가중치가 유니캐스트 되면 상공개특허 10-2023-0148535-4-기 벡터 프로세싱 유닛은 해당 가중치와 곱할 입력을 결정하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 희소성 병렬처리 아키텍처는, 상기 연산량 분배기를 통해 제공되는 연산량을 이용하여 생성된 입력 선택 신호를 이용하여 상기 벡터 프로세싱유닛을 통해 해당 가중치와 곱할 입력을 결정하고, 각각의 가중치 마스크 행렬의 열이 갖는 최댓값 인덱스에 따라 입력 선택 신호가 변경되어 복수의 가중치 마스크 행렬의 열에 대하여 동시에 연산을 수행하고, 희소성을 가진 레이어와 희소성을 갖지 않은 레이어 모두에 대하여 연산을 수행하는 멀티 에이전트 강화학습 가속 시스템."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "가중치 메모리가 PCIe 인터페이스로부터 학습 샘플들을 제공 받아 멀티 에이전트 강화학습 심층 신경망 학습에필요한 가중치 값들을 초기화하여 저장하는 단계; 가중치 희소 데이터 생성 유닛을 통해 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희소성 벡터, 가중치희소 인덱스, 실제 연산량을 포함하는 희소 데이터를 생성하고, 생성된 희소 데이터를 행방향 가중치 희소성 데이터 메모리에 저장하는 단계; 가중치 데이터 압축 유닛을 통해 상기 가중치 메모리로부터 가중치를 불러와 상기 생성된 희소 데이터의 형태에따라 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하는단계; 명령 스케줄러를 통해 가중치 그룹화, 순방향 전파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망학습의 전 과정을 제어하는 단계; 희소성 병렬처리 아키텍처가 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정에서 레이어 내 병렬처리를 수행하는 단계; 상기 희소성 병렬처리 아키텍처의 하나의 레이어의 연산이 끝나면 축적기를 통해 각각의 희소성 병렬처리 아키텍처의 결과를 합치는 단계; 및 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나눠주는 단계를 포함하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,한 번의 에포크 동안 상기 가중치 희소 데이터 생성 유닛을 통해 상기 희소 데이터를 생성하고, 생성된 희소 데이터의 형태에 따라 상기 가중치 데이터 압축 유닛을 통해 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하고, 상기 명령 스케줄러의 제어에 따라 상기 축적기를 통해각각의 희소성 병렬처리 아키텍처의 결과를 합치고, 상기 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 각각의 코어에 나눠주는 연산 방식을 반복하고, 상기 연산 결과에 따른 가중치를 업데이트하는 단계를 더 포함하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 가중치 희소 데이터 생성 유닛을 통해 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희소성 벡터,가중치 희소 인덱스, 실제 연산량을 포함하는 희소 데이터를 생성하고, 생성된 희소 데이터를 행방향 가중치 희공개특허 10-2023-0148535-5-소성 데이터 메모리에 저장하는 단계는, 가중치 그룹화를 위해 희소성을 생성하고자 하는 레이어에 대해 각각의 입력채널 가중치 그룹행렬과 출력채널가중치 그룹행렬을 생성하고, 생성된 입력채널 가중치 그룹행렬의 열과 출력채널 가중치 그룹행렬의 행에 있는 그룹 개의 데이터에서 최댓값인덱스를 찾고 각각의 최댓값 인덱스를 저장한 후에 비교하는멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스를 비교하여, 최댓값 인덱스가 일치할 경우, 희소성 벡터의 요소를 1로 생성하고, 최댓값 인덱스가 일치하지 않을 경우, 희소성 벡터의 요소를 0으로 생성하며, 상기 최댓값 인덱스가 일치하는 위치와 일치하는 개수를 저장하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 입력채널 가중치 그룹행렬과 상기 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스 중 최댓값 인덱스의 값은 1이고 나머지는 0인 입력채널 가중치 선택 행렬과 출력채널 가중치 선택 행렬을 생성하고, 입력채널 가중치 선택 행렬과 상기 출력채널 가중치 선택 행렬을 곱하여 희소성을 생성하고자 하는 레이어와 동일한 크기의 가중치 마스크 행렬을 생성하고, 가중치 마스크 행렬의 값이 1인 경우, 해당 가중치를 연산에 이용하며, 가중치 마스크 행렬의 값이 0인 경우, 해당 가중치는 에포크에서 사용되지 않는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나눠주는 단계는, 상기 가중치 희소 데이터 생성 유닛에서 생성된 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬에 대해각각의 코어가 모두 동일한 개수의 가중치 그룹행렬 열을 가질 경우 연산량이 일정하게 수렴할 것을 예측하여연산량을 스케쥴링하고, 연산량을 예측한 후 해당 연산량에 따라 레이어의 입력과 가중치를 압축하여 희소성 병렬처리 아키텍처에 전달하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서, 상기 희소성 병렬처리 아키텍처가 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정에서 레이어 내 병렬처리를 수행하는 단계는, 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 상기 가중치 희소 데이터 생성 유닛에서 생성된 가중치 마스크 행렬에 따라 서로 다른 벡터 프로세싱 유닛에 분배하고, 상기 가중치 마스크 행렬의 열 마다 실제 연산량에차이가 존재하므로, 벡터 프로세싱 유닛을 통해 상기 벡터 프로세싱 유닛 간의 고정된 연결을 최소화하여 연산공개특허 10-2023-0148535-6-량을 분배하도록 하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 벡터 프로세싱 유닛을 통해 복수의 가중치 마스크 행렬의 열을 병렬처리하고, 입력 메모리로부터 입력 데이터가 브로드캐스팅 되고 가중치 메모리로부터 각각의 가중치가 유니캐스트 되면 상기 벡터 프로세싱 유닛은 해당 가중치와 곱할 입력을 결정하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 연산량 분배기를 통해 제공되는 연산량을 이용하여 생성된 입력 선택 신호를 이용하여 상기 벡터 프로세싱유닛을 통해 해당 가중치와 곱할 입력을 결정하고, 각각의 가중치 마스크 행렬의 열이 갖는 최댓값 인덱스에 따라 입력 선택 신호가 변경되어 복수의 가중치 마스크 행렬의 열에 대하여 동시에 연산을 수행하고, 희소성을 가진 레이어와 희소성을 갖지 않은 레이어 모두에 대하여 연산을 수행하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "멀티 에이전트 강화학습 가속 시스템에 의해 수행되는 개인 맞춤형 수면 패턴 제공 방법을 실행시키기 위해 컴퓨터 판독 가능한 저장 매체에 저장된 프로그램에 있어서, 가중치 메모리가 PCIe 인터페이스로부터 학습 샘플들을 제공 받아 멀티 에이전트 강화학습 심층 신경망 학습에필요한 가중치 값들을 초기화하여 저장하는 단계; 가중치 희소 데이터 생성 유닛을 통해 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희소성 벡터, 가중치희소 인덱스, 실제 연산량을 포함하는 희소 데이터를 생성하고, 생성된 희소 데이터를 행방향 가중치 희소성 데이터 메모리에 저장하는 단계; 가중치 데이터 압축 유닛을 통해 상기 가중치 메모리로부터 가중치를 불러와 상기 생성된 희소 데이터의 형태에따라 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하는단계; 명령 스케줄러를 통해 가중치 그룹화, 순방향 전파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망학습의 전 과정을 제어하는 단계; 희소성 병렬처리 아키텍처가 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정에서 레이어 내 병렬처리를 수행하는 단계; 상기 희소성 병렬처리 아키텍처의 하나의 레이어의 연산이 끝나면 축적기를 통해 각각의 희소성 병렬처리 아키텍처의 결과를 합치는 단계; 및 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나눠주는 단계를 포함하는 컴퓨터 판독 가능한 저장 매체에 저장된 프로그램."}
{"patent_id": "10-2022-0047364", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,멀티 에이전트 강화학습 심층 신경망 학습의 정확도를 유지하기 위해 가중치 그룹화 방식을 이용하고, 가중치그룹행렬의 학습을 통해 에포크 별로 가중치를 선택하여 멀티 에이전트 강화학습 심층 신경망 학습을 수행하고, 공개특허 10-2023-0148535-7-가중치 그룹화 방식의 희소 데이터 인코딩을 통해 희소 데이터를 생성하는 시간을 단축하여 메모리 공간을 감소시키며, 그룹 수에 제한되는 희소 데이터의 종류를 이용하여, 해당 인덱스의 데이터 유무에 따라 부적중의 경우에만 새로운 희소 데이터를 생성하고, 생성된 희소 데이터를 저장할 경우 서로 다른 종류의 희소 데이터만 저장하고, 이외의 희소 데이터는 반복되므로 인덱스 포인터만 저장함으로써 반복되는 데이터에 대한 저장 공간을 감소시키는 컴퓨터 판독 가능한 저장 매체에 저장된 프로그램."}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "멀티 에이전트 강화학습 시스템 및 그 동작방법 및 장치가 제시된다. 본 발명에서 제안하는 멀티 에이전트 강화 학습 시스템은 멀티 에이전트 강화학습 심층 신경망 학습에 필요한 가중치들을 초기화하여 저장하고, PCIe 인터 페이스로부터 학습 샘플들을 제공 받는 가중치 메모리, 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희소 (뒷면에 계속)"}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티 에이전트 강화학습 시스템 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "강화학습은 인공지능의 한 갈래로서, 지도학습과 함께 큰 관심을 받고 있다. 강화학습은 타 인공지능 기술과 다 르게 에이전트가 환경과 상호작용하며 보상을 극대화할 수 있는 정책을 찾는 것을 목표로 한다. 강화학습에 심 층 신경망을 접목한 심층 강화학습은 게임, 로보틱스, 산업 제어 시스템 등 다양한 분야에서 뛰어난 성능을 보 이며 주목을 받고 있다. 최근에는 기존 강화학습을 여러개의 에이전트로 확장시킨 멀티 에이전트 강화학습이 에 이전트가 한 개인 경우에 비해 더 높은 정확도를 보여주며 더 큰 AI 시스템 구축에 중심이 되고 있다. 하지만 멀티 에이전트 강화학습은 학습 안정성을 위해 모든 에이전트가 동일한 네트워크 가중치를 이용하면서 반복적인 연산을 요구하며, 이는 곧 하드웨어에서 많은 전력 소비를 초래한다. 더하여, 최근 심층신경망이 점점 깊어짐에 따라 가치지기(Pruning), 양자화(Quantization)과 같은 네트워크 압축 알고리즘이 등장하였다. 특히 가지치기 기법은 중요도가 낮은 학습 파라미터를 0으로 하여 네트워크 모델 크기를 줄이는 기법으로, 0의 값을 가지는 가중치에 대하여 연산을 생략할 수 있고 메모리 공간을 줄일 수 있다는 하드웨어 측면의 장점이 있 다. 하지만 대부분의 가지치기 기법은 지도학습을 대상으로 연구가 이루어지고 있어 동일한 가지치기 기법을 심 층 강화학습에 적용한 사례는 부족하다. 특히 강화학습의 경우 현재의 값이 미래의 에이전트의 상태에 영향을 미치는 롱 텀 결정 문제(long term decision problem)을 다루기 때문에 모델의 학습 초기에 제거된 가중치가 이 후에 어떤 정확도에 어떤 영향을 줄지 알 수 없다. 또한, 멀티 에이전트 강화학습의 가중치를 제거하게 되면 모 든 에이전트의 가중치를 제거하기 때문에 더 많은 오류를 초래할 수 있다. 선행기술문헌 비특허문헌 (비특허문헌 0001) [1] J. Lee, S. Kim, S. Kim, W. Jo, and H.-J. Yoo, \"Gst: Group-sparse training for accelerating deep reinforcement learning,\" arXiv preprint arXiv: 2101.09650, 2021. (비특허문헌 0002) [2] X. Wang, M. Kan, S. Shan, and X. Chen, \"Fully learnable group convolution for acceleration of deep neural networks,\" in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 9049-9058."}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 희소성 처리를 통한 멀티 에이전트 강화학습 가속 시스템 및 그 동작 방법을 제공하는데 있다. 본 발명에서는 멀티 에이전트 강화학습의 특징에 맞추어 정확도를 보장할 수 있는 가 중치 가지치기 알고리즘을 분석하고, 이를 효과적으로 지원할 수 있는 온칩 인코딩 유닛, 희소 가중치 연사량 분배 유닛, 벡터 프로세싱을 통한 희소성 병렬처리 아키텍처를 포함하는 가속 시스템 및 그 동작 방법을 제안한 다. 또한, 수천 개의 코어가 집약되어 있어 연산 시 엄청난 열과 전력 소모가 발생하는 GPU가 아닌, FPGA를 이용하여 높은 처리량과 전력효율을 가지며 초기 단계부터 딥러닝 모델에 적합하도록 회로를 구성하는 가속 플랫 폼을 제안한다."}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에 있어서, 본 발명에서 제안하는 멀티 에이전트 강화학습 시스템은 멀티 에이전트 강화학습 심층 신경 망 학습에 필요한 가중치들을 초기화하여 저장하고, PCIe 인터페이스로부터 학습 샘플들을 제공 받는 가중치 메 모리, 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희소성 벡터, 가중치 희소 인덱스, 실제 연산량을 포 함하는 희소 데이터를 가중치 희소 데이터 생성 유닛에서 생성하고, 생성된 희소 데이터를 행방향 가중치 희소 성 데이터 메모리에 저장 후, 상기 가중치 메모리로부터 가중치를 불러와 상기 생성된 희소 데이터의 형태에 따 라 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하는 가 중치 데이터 압축 유닛, 가중치 그룹화, 순방향 전파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망 학습의 전 과정을 제어하는 명령 스케줄러, 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정에서 레이어 내 병렬처리를 수행하는 희소성 병렬처리 아키텍처, 상기 희소성 병렬처리 아키텍처의 하나 의 레이어의 연산이 끝나면 각각의 희소성 병렬처리 아키텍처의 결과를 합치는 축적기 및 다음 레이어의 연산량 을 예측하여 다음 레이어 입력을 각각의 코어에 나눠주는 연산량 분배기를 포함한다. 본 발명의 실시예에 따르면, 한 번의 에포크 동안 상기 가중치 희소 데이터 생성 유닛을 통해 상기 희소 데이터 를 생성하고, 생성된 희소 데이터의 형태에 따라 상기 가중치 데이터 압축 유닛을 통해 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하고, 상기 명령 스케줄러 의 제어에 따라 상기 축적기를 통해 각각의 희소성 병렬처리 아키텍처의 결과를 합치고, 상기 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 각각의 코어에 나눠주는 연산 방식을 반복하고, 상기 연산 결과에 따른 가중치를 업데이트한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 가중치 그룹화를 위해 희소성을 생성하고자 하는 레 이어에 대해 각각의 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬을 생성하고, 생성된 입력채널 가중 치 그룹행렬의 열과 출력채널 가중치 그룹행렬의 행에 있는 그룹 개의 데이터에서 최댓값 인덱스를 찾고 각각의 최댓값 인덱스를 저장한 후에 비교한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 상기 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스를 비교하여, 최댓값 인덱스가 일치할 경우, 희소성 벡터의 요소를 1로 생성하고, 최댓값 인덱스가 일치하지 않을 경우, 희소성 벡터의 요소를 0으로 생성하며, 상기 최댓값 인덱스가 일치하는 위치와 일치하는 개수를 저장한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 상기 입력채널 가중치 그룹행렬과 상기 출력채널 가 중치 그룹행렬 각각의 행 및 열에 있는 그룹 개의 데이터에 대하여 최댓값 인덱스의 값은 1이고 나머지는 0인 입력채널 가중치 선택 행렬과 출력채널 가중치 선택 행렬을 생성하고, 상기 입력채널 가중치 선택 행렬과 상기 출력채널 가중치 선택 행렬을 곱하여 희소성을 생성하고자 하는 레이어와 동일한 크기의 가중치 마스크 행렬을 생성하고, 가중치 마스크 행렬의 값이 1인 경우, 해당 가중치를 연산에 이용하며, 가중치 마스크 행렬의 값이 0 인 경우, 해당 가중치는 에포크에서 사용되지 않는다. 본 발명의 실시예에 따른 연산량 분배기는 상기 가중치 희소 데이터 생성 유닛에서 생성된 입력채널 가중치 그 룹행렬과 출력채널 가중치 그룹행렬에 대해 각각의 코어가 모두 동일한 개수의 가중치 그룹행렬 열을 가질 경우 연산량이 일정하게 수렴할 것을 예측하여 연산량을 스케쥴링하고, 연산량을 예측한 후 해당 연산량에 따라 레이 어의 입력과 가중치를 압축하여 희소성 병렬처리 아키텍처에 전달한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 상기 가중치 희소 데이터 생성 유닛에서 생성된 가중치 마스크 행렬에 따라 서로 다른 벡터 프로세싱 유닛에 분배하 고, 상기 가중치 마스크 행렬의 열 마다 실제 연산량에 차이가 존재하므로, 벡터 프로세싱 유닛을 통해 상기 벡 터 프로세싱 유닛 간의 고정된 연결을 최소화하여 연산량을 분배하도록 한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 상기 벡터 프로세싱 유닛은 복수의 가중치 마스크 행렬의 열을 병렬처리하고, 입력 메모리로부터 최대 4개의 입력 데이터가 브로드캐스팅 되고 가중치 메모리로부터 각각 의 가중치가 유니캐스트 되면 상기 벡터 프로세싱 유닛은 입력 데이터들 중 해당 가중치와 곱할 입력을 결정한 다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 상기 연산량 분배기를 통해 제공되는 연산량을 이용하여 생성된 입력 선택 신호를 이용하여 상기 벡터 프로세싱 유닛을 통해 해당 가중치와 곱할 입력을 결정하고, 각각 의 가중치 마스크 행렬의 열이 갖는 최댓값 인덱스에 따라 입력 선택 신호가 변경되어 복수의 가중치 마스크 행 렬의 열에 대하여 동시에 연산을 수행하고, 희소성을 가진 레이어와 희소성을 갖지 않은 레이어 모두에 대하여 연산을 수행한다. 또 다른 일 측면에 있어서, 본 발명에서 제안하는 멀티 에이전트 강화학습 시스템의 동작 방법은 가중치 메모리 가 PCIe 인터페이스로부터 학습 샘플들을 제공 받아 멀티 에이전트 강화학습 심층 신경망 학습에 필요한 가중치 값들을 초기화하여 저장하는 단계, 가중치 희소 데이터 생성 유닛을 통해 에포크가 시작할 때 가중치 그룹화 방 식을 이용하여 희소성 벡터, 가중치 희소 인덱스, 실제 연산량을 포함하는 희소 데이터를 생성하고, 생성된 희 소 데이터를 행방향 가중치 희소성 데이터 메모리에 저장하는 단계, 가중치 데이터 압축 유닛을 통해 상기 가중 치 메모리로부터 가중치를 불러와 상기 생성된 희소 데이터의 형태에 따라 가중치 값들을 압축하여, 실제 연산 량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하는 단계, 명령 스케줄러를 통해 가중치 그룹 화, 순방향 전파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망 학습의 전 과정을 제어하는 단계, 희소성 병렬처리 아키텍처가 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정에서 레 이어 내 병렬처리를 수행하는 단계, 상기 희소성 병렬처리 아키텍처의 하나의 레이어의 연산이 끝나면 축적기를 통해 각각의 희소성 병렬처리 아키텍처의 결과를 합치는 단계 및 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나눠주는 단계를 포함한다."}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따르면 희소성 처리를 통한 멀티 에이전트 강화학습 가속 시스템 및 그 동작 방법을 통해 멀티 에이전트 강화학습의 특징에 맞추어 정확도를 보장할 수 있는 가중치 가지치기 알고리즘을 분석하고, 온칩 인코딩 유닛, 희소 가중치 연사량 분배 유닛, 벡터 프로세싱을 통한 희소성 병렬처리 아키텍처를 포함하는 가속 시스템을 통해 이를 효과적으로 지원할 수 있다. 또한, 수천 개의 코어가 집약되어 있어 연산 시 엄청난 열과 전력 소모가 발생하는 GPU가 아닌 FPGA를 이용하여 가속 플랫폼을 개발함으로써 높은 처리량과 전력효율을 가지 며 초기 단계부터 딥러닝 모델에 적합하도록 회로를 구성할 수 있다."}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시 예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 멀티 에이전트 강화학습 가속 시스템의 구성을 나타내는 도면이다. 제안하는 멀티 에이전트 강화학습 가속 시스템은 가중치 메모리, 가중치 희소 데이터 생성 유닛, 행 방향 가중치 희소성 데이터 메모리, 가중치 데이터 압축 유닛, 희소성 병렬처리 아키텍처, 명령 스케줄러, 축적기 연산량 분배기를 포함한다. 본 발명의 실시예에 따른 가중치 메모리는 멀티 에이전트 강화학습 심층 신경망 학습에 필요한 가중치들을 초기화하여 저장하고, 호스트 CPU를 통해 PCIe 인터페이스로부터 학습 샘플들을 제공 받는다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 에포크가 시작할 때 가중치 그룹화 방식을 이용 하여 희소성 벡터, 가중치 희소 인덱스, 실제 연산량을 포함하는 희소 데이터를 생성하고, 생성된 희소 데이터 를 행방향 가중치 희소성 데이터 메모리에 저장한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 가중치 그룹화를 위해 희소성을 생성하고자 하 는 레이어에 대해 각각의 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬을 생성한다. 이후, 생성된 입 력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스를 저장한 후에 비교한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 상기 입력채널 가중치 그룹행렬과 출력채널 가 중치 그룹행렬 각각의 최댓값 인덱스를 비교하여, 최댓값 인덱스가 일치할 경우, 희소성 벡터의 요소를 1로 생 성하여 최댓값 인덱스가 일치하는 위치와 일치하는 개수를 저장한다. 반면에, 최댓값 인덱스가 일치하지 않을 경우, 희소성 벡터의 요소를 0으로 생성한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 상기 입력채널 가중치 그룹행렬과 상기 출력채 널 가중치 그룹행렬 각각의 최댓값 인덱스 중 최댓값 인덱스의 값은 1이고 나머지는 0인 입력채널 가중치 선택 행렬과 출력채널 가중치 선택 행렬을 생성한다. 이후, 입력채널 가중치 선택 행렬과 출력채널 가중치 선택 행렬을 곱하여 희소성을 생성하고자 하는 레이어와 동일한 크기의 가중치 마스크 행렬을 생성한다. 이때, 가중치 마스크 행렬의 값이 1인 경우, 해당 가중치를 연 산에 이용하고, 가중치 마스크 행렬의 값이 0인 경우, 해당 가중치는 에포크에서 사용되지 않는다. 본 발명의 실시예에 따른 가중치 데이터 압축 유닛은 상기 가중치 메모리로부터 가중치를 불러와 상기 생 성된 희소 데이터의 형태에 따라 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬 처리 아키텍처로 전송한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정(예를 들어, 전파, 역전파, 가중치 업데이트)에서 레이어 내 병렬처리를 수행한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 상기 가중치 희소 데이터 생성 유닛에서 생성된 가중치 마스크 행렬에 따라 서로 다른 프로세싱 유닛에 분 배한다. 상기 가중치 마스크 행렬의 열 마다 실제 연산량에 차이가 존재하므로, 벡터 프로세싱 유닛을 통해 상 기 벡터 프로세싱 유닛 간의 고정된 연결을 최소화하여 연산량을 분배하도록 한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 상기 벡터 프로세싱 유닛은 복수의 가중치 마스크 행렬의 열을 병렬처리 한다. 이때, 입력 메모리로부터 입력 데이터가 브로드캐스팅 되고 가중치 메모리로부터 각각의 가중치가 유니캐스트 되면 상기 벡터 프로세싱 유닛은 해당 가중치와 곱할 입력을 결정한다. 본 발명의 실시예에 따른 명령 스케줄러는 가중치 그룹화, 순방향 전파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망 학습의 전 과정을 제어한다. 본 발명의 실시예에 따른 축적기는 상기 희소성 병렬처리 아키텍처의 하나의 레이어의 연산이 끝나면 각각 의 희소성 병렬처리 아키텍처의 결과를 합친다. 본 발명의 실시예에 따른 연산량 분배기는 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나눠준다. 상술된 바와 같이, 본 발명의 실시예에 따른 멀티 에이전트 강화학습 가속 시스템은 한 번의 에포크 동안 상기 가중치 희소 데이터 생성 유닛을 통해 상기 희소 데이터를 생성하고, 생성된 희소 데이터의 형태에 따라 상기 가중치 데이터 압축 유닛을 통해 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송한다. 그리고, 명령 스케줄러의 제어에 따라 상기 축적기를 통 해 각각의 희소성 병렬처리 아키텍처의 결과를 합치고, 연산량 분배기를 통해 다음 레이어의 연산량을 예 측하여 각각의 코어에 나눠주는 연산 방식을 반복하고, 상기 연산 결과에 따른 가중치를 업데이트한다. 다시 말 해, 한 번의 에포크 동안 위의 연산 방식을 반복하고 가중치 업데이트를 진행하면 다시 가중치 희소 데이터 생 성 유닛에서 새로운 가중치에 대한 희소 데이터를 생성한다. 본 발명의 실시예에 따른 연산량 분배기는 상기 가중치 희소 데이터 생성 유닛에서 생성된 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬에 대해 각각의 코어가 모두 동일한 개수의 가중치 그룹행렬 열을 가질 경우 연산량이 일정하게 수렴할 것을 예측하여 연산량을 스케쥴링한다. 연산량을 예측한 후 해당 연산량에 따라 레이어의 입력과 가중치를 압축하여 희소성 병렬처리 아키텍처에 전달한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 상기 연산량 분배기를 통해 제공되는 연산량을 이용하여 생성된 입력 선택 신호를 이용하여 상기 벡터 프로세싱 유닛을 통해 해당 가중치와 곱할 입력을 결정 한다. 본 발명의 실시예에 따른 고대역 메모리 컨트롤러는 고대역 메모리 내의 인덱스 목록과 워크로드(다 시 말해, 연산량)를 읽어냄으로써 선택 신호를 생성하도록 한다. 이후, 각각의 가중치 마스크 행렬의 열이 갖는 최댓값 인덱스에 따라 입력 선택 신호가 변경되어 복수의 가중치 마스크 행렬의 열에 대하여 동시에 연산을 수행하고, 희소성을 가진 레이어와 희소성을 갖지 않은 레이어 모두 에 대하여 연산을 수행한다. 도 2 내지 도 9를 참조하여 본 발명의 실시예에 따른 멀티 에이전트 강화학습 가속 시스템의 각각의 구성에 대하여 더욱 상세히 설명한다. 도 2는 본 발명의 일 실시예에 따른 가중치 그룹화 방식의 희소 데이터 온칩 인코딩 유닛에 대해 설명하기 위한 도면이다. 도 2(a)는 본 발명의 실시예에 따른 가중치 그룹행렬 IG, OG의 그룹별 최댓값 확인을 나타내는 도면이고, 도 2(b)는 본 발명의 실시예에 따른 이진화를 통한 가중치 선택 행렬 IS, OS 생성을 나타내는 도면이고, 도 2(c)는 본 발명의 실시예에 따른 가중치 선택 행렬의 곱셈을 통한 가중치 마스크 행렬 생성을 나타내는 도면이다. 도 2는 가중치 그룹행렬이 어떻게 희소성을 생성하는지를 자세히 보여준다. G는 그룹 수, M은 입력 벡터, N은 출력 벡터라고 할 때 1 × M의 입력 벡터를 1 × N의 출력 벡터로 변환하는 M × N 크기의 계층에 대해서, 각각 M × G, G × N로 설정된 입력 그룹화(IG) 행렬과 출력 그룹화(OG) 행렬을 작성하며 둘 다 랜덤으로 초기화된다. 먼저, IG 행렬의 각 행에 존재하는 그룹 개수의 데이터에 대하여 최댓값을 찾는다. 다시 말해, IG의 한 행과 OG 의 한 열에 그룹 개수에 해당하는 데이터가 있어 이 그룹 개 중 한 개의 데이터만 뽑는다. 그런 다음 도 2의 네 모 박스와 같이, 최대 위치에 1을 할당하고 나머지 위치에 0을 할당하여 각 행을 2진화하여 입력 선택(IS) 행렬 을 생성한다. 마찬가지로 OG 행렬의 각 열에 대한 최댓값을 찾고 출력 선택(OS) 행렬을 생성한다. 마지막으로, 마스크 행렬 M은, IS 행렬과 OS 행렬을 곱해, 그 사이즈를 계층 크기 M×N과 같게 하여 생성한다. 가중치 그룹행렬은 가중치 마스크 행렬(마스크에 해당하는 비트가 1인 가중치)을 참조하여 마스크되지 않은 가 중치만 사용함으로써 많은 희소성을 생성한다. 다시 말해, 마스크되지 않은 가중치만 읽고 코어로 전송함으로써 마스크된 가중치로 불필요한 계산을 건너뛴다. 또한, 각 그룹행렬의 값은 대응하는 선택 행렬의 오차에 근거하여 학습 된다. 가중치 마스크 행렬은 가중치 그 룹 행렬이 반복될 때마다 새로 생성된다. 마스크 행렬의 행을 나타낼 때 비트 벡터라는 용어를 사용한다. 가중치 그룹화 알고리즘은 가중치 그룹행렬을 학습하고 각 반복에서 마스크할 대상을 결정하기 때문에 다른 프 루닝 방식보다 유연성이 높아진다. 또한 그룹 수를 통해 희소성 수준을 조정할 수 있다. 가장 중요한 것은, 가 중치 그룹화는 모든 반복을 변경하는 마스크 행렬이 구조화되지 않은 프루닝의 동등한 형태이기 때문에 모델의 정확성을 보장한다는 것이다. 가중치 그룹의 또 다른 장점은 원래 가중치 값을 유지한다는 점이다. 마스크된 가 중치는 0으로 설정되어 있지 않기 때문에 다음 반복에서 사용할 수 있다. 이러한 유연성을 활용하여 하드웨어에서 효율적인 희소 데이터 생성과 희소 행렬 벡터 곱셈을 제안한다. 도 3은 본 발명의 일 실시예에 따른 온칩 인코딩 유닛의 가중치 희소성 데이터 생성 과정을 설명하기 위한 도면 이다. 도 3에 도시된 가중치 그룹화 방식에서는 희소성을 생성하고자 하는 레이어에 대해 각각 입력채널 가중치 그룹 행렬과 출력채널 가중치 그룹행렬을 생성한다. 생성된 입력채널 가중치 그룹행렬의 최댓값 인덱스와 출력 채널 가중치 그룹행렬 최댓값 인덱스를 찾는다. 각각의 가중치 그룹행렬의 크기는 그룹 수×채널 크기로, 각각의 그룹별로 최댓값을 찾은 후에 최댓값 인덱스의 값은 1이고 나머지는 0 인 가중치 선택 행렬을 생성한다. 입력채널 가중치 선택 행렬과 출력채널 가중치 선택 행렬을 곱하면 희소성을 생성하고자 하는 레이어와 동일한 크기의 가중치 마스크 행렬이 생성된다. 가중치 행렬 마스크의 값이 1인 경우 해당 가중치를 연산에 이용하며, 0인 경우에는 해당 위치에 있는 가중치가 에포크에서 사용되지 않는다. 이를 통해 생성된 희소성 데이터는 행 방향 가중치 희소성 데이터 메모리에 저장된다. 도 4는 본 발명의 일 실시예에 따른 온칩 인코딩 유닛의 희소성 데이터 생성 시간 단축에 대해 설명하기 위한 도면이다. 본 발명에서는 가중치 그룹화 방식을 이용할 때 더욱 효과적으로 희소 데이터를 생성할 수 있는 온칩 인코딩 유 닛을 제안한다. 본 발명은 생성될 수 있는 희소 데이터의 종류가 그룹 수와 같거나 그보다 작은 값으로 제한되 어 있다는 가중치 그룹화의 특징으로부터 기인하였다. 가중치 선택 행렬을 생성할 때 그룹 개수 중에 반드시 한 개의 최댓값을 고르게 되고, 이 최댓값 인덱스가 동일하면 생성되는 희소 데이터가 동일하기 때문에 동일한 희 소 데이터가 생성되는 과정을 생략할 수 있다. 본 발명의 실시예에 따른 온칩 인코딩 유닛에서는 각 채널별 그룹행렬의 최댓값 인덱스를 저장한 후에 이를 비 교한다. 비교할 때 최댓값 인덱스가 일치하면 희소성 벡터의 요소를 1로 그렇지 않으면 0으로 하고 인덱스가 일 치하는 위치와 일치한 개수를 저장한다. 최댓값 인덱스가 일치하는 위치는 가중치 희소 인덱스로 가중치 데이터 압축 유닛에서 실제 연산할 가중치를 불러올 때 주소값으로 사용되며 실제 연산량은 희소성 병렬처리 아키텍처 에서 높은 하드웨어 이용량을 달성하기 위해 사용된다. 입력채널 가중치 그룹행렬의 한 최댓값 인덱스에 대해 위의 희소성 데이터를 모두 생성하면 해당 인덱스의 데이터 유무 상태는 변하게 된다. 입력채널 가중치 그룹행 렬의 다른 최댓값 인덱스에 대해서도 위 과정을 반복하며, 만일 데이터가 이미 존재하는 경우(다시 말해, 인덱 스 적중하는 경우) 생성 과정을 생략할 수 있다. 도 4를 참조하면, 온칩 인코딩 유닛을 어떻게 하드웨어에 구현하는지를 나타내고 있다. 사이클마다 입력 그룹화 (IG) 행렬 행의 최댓값 인덱스를 받는다. 사이클 1, 2에서는 인덱스 1, 2의 비트 벡터가 희소성 데이터 메모리 에 아직 생성되지 않았기 때문에 비교기를 사용하여 사이클별로 비트 벡터를 새로 생성한다. 그런 다음 희소 데 이터 튜플 {비트 벡터, 0이 아닌 인덱스, 연산량}를 희소성 데이터 메모리에 저장하고 최댓값 인덱스를 인덱스 목록에 추가한다. 사이클 3에서는 희소 데이터 메모리에 최대 인덱스 1이 존재하므로 희소 데이터 인코더는 튜 플을 업데이트하지 않고 인덱스 목록에 최대 인덱스를 저장한다. 사이클 4, 5에서는 각각 인덱스 3, 0에 대해 희소성 데이터 메모리 업데이트가 이루어진다. 이 시점에서 희소성 데이터 메모리는 G개(그룹 수)의 다른 행에 대해 가능한 모든 비트 벡터를 저장하고 완전한 마스크 행렬을 만든다. 따라서 사이클 6부터 희소 데이터 인코 더는 항상 희소성 데이터 메모리에서 인덱스에 히트(hit)한다. 본 발명의 실시예에 따른 온칩 인코딩 유닛의 비트 벡터 및 기타 행 단위 정보 캐싱 덕분에, 희소 데이터 인코 더는 사이클과 온칩 메모리 공간을 모두 절약한다. 온칩 인코딩 유닛이 없는 기준선의 경우 비트 벡터를 계산하 고 사이클마다 희소성 데이터 튜플을 메모리에 저장한다. 희소 데이터 인코더는 필수 데이터만 온칩 메모리에 저장하고 필수 데이터를 인덱스 목록에서 참조함으로써 장황한 계산 및 메모리 footprint를 대체한다. 또한 희소 데이터 인코더는 간단한 수정으로 훈련을 위한 희소 데이터 튜플을 생성할 수 있다. 역방향 전파는 전치 행렬을 사용하기 때문에 출력 그룹화(OG) 행렬을 IG 행렬로 간주하기 때문에 OG 행렬의 최댓값 인덱스와 IG 행렬의 최댓값 인덱스를 하나씩 비교하여 비트 벡터를 생성한다. 전치 행렬의 행에 대한 비트 벡터가 생성되 면 예측과 마찬가지로 0이 아닌 인덱스와 연산량으로 희소성 데이터 메모리를 업데이트한다. 학습을 위한 희소데이터 튜플 생성은 시스템에 오버헤드가 없도록 예측 계산과 병렬로 작동할 수 있다. 도 5는 본 발명의 일 실시예에 따른 온칩 인코딩 유닛의 행 방향 가중치 희소성 데이터 메모리를 종래기술과 비 교하기 위한 도면이다. 본 발명의 실시예에 따른 가중치 그룹화 방식의 온칩 인코딩 유닛은 알고리즘, 하드웨어 관점에서 모두 장점이 존재한다. 첫 번째로, 알고리즘 관점에서 가중치 그룹화 방식은 멀티 에이전트 강화학습의 정확도를 유지할 수 있는 희소성 생성 방식이다. 다시 말해, 실제 가중치의 값을 0으로 보내는 것이 아니라 가중치 그룹행렬의 학습 을 통해 에포크 별로 가중치를 선택하기 때문에 기존의 희소성 생성 방식에 비해 훨씬 더 융통성 있는 방식으로 학습이 가능하다. 두 번째로, 하드웨어 측면에서 가중치 그룹화 방식의 희소 데이터 인코딩은 희소 데이터를 생성하는 시간을 단 축할 수 있으며 이를 저장하는 메모리 공간도 감소시킬 수 있다. 희소 데이터의 종류가 그룹 수에 제한되어 있 다는 점을 이용하여, 해당 인덱스의 데이터 유무를 보고 부적중의 경우에만 새로운 데이터를 생성하게 된다. 또 한, 생성된 희소 데이터를 저장할 때 서로 다른 종류의 희소 데이터만 저장하여 최대 그룹 개수와 일치하게 되 고, 이외의 데이터는 반복되므로 인덱스 포인터만 저장함으로써 반복되는 데이터에 대한 저장 공간을 줄일 수 있다. 이와 같이 본 발명의 실시예에 따르면, 희소 데이터 생성에 필요한 시간과 메모리를 줄임으로써, 모델의 학습 시간 동안 변화하는 가중치에 대해 희소 데이터를 모두 온칩에서 생성하여 외부 메모리 접근을 제거할 수 있다. 도 6은 본 발명의 일 실시예에 따른 열 방향 희소 가중치 연산량 분배기를 설명하기 위한 도면이다. 도 6(a)는 본 발명의 실시예에 따른 희소성 벡터 요소를 설명하기 위한 도면이고, 도 6(b)는 본 발명의 실시예 에 따른 열 방향 희소 가중치 연산량 분배 유닛(도 1에 도시된 연산량 분배기)을 통한 연산량을 예측과정 을 설명하기 위한 도면이다. 본 발명의 실시예에 따른 연산량 분배 유닛 역시 입력채널 가중치 그룹행렬과 출력채널 그룹행렬의 최대 인덱스 값이 일치해야 희소성 벡터의 요소를 1로 만든다는 점을 이용한다. 두 그룹행렬의 최댓값 인덱스가 일치할 확률 이 곧 평균 희소성이 되고, 가중치 마스크 행렬의 한 열(다시 말해, 희소성 벡터)마다 존재하는 1의 개수는 열 의 크기를 그룹 수로 나눈 것에 수렴하게 된다. 도 6은 두 개의 간단한 부하(다시 말해, 연산량) 분배 방식을 나타내고 있다. 첫 번째 방식은 임계값을 사용하 는 것이다. 이와 같은 방식은 희소성 처리를 위한 대부분의 하드웨어에서 활용하는 방식으로 연산량을 예측하기 위한 추가적인 로직이 필요하다. 가중치 매트릭스에서 마스킹되지 않은 요소의 수(즉, 총 연산량)를 모두 더한 후 코어 수로 나누어 임계값을 설정한다. 그런 다음 마스크되지 않은 요소를 할당된 요소의 수가 임계값보다 커 질 때까지 각 코어 요소에 행별로 분포시킨다. 두 번째 방식은 전체 행렬의 행을 코어 수로 균등하게 분할하여 각 코어에 연산량을 할당한다. 비트 벡터를 설 정하려면 IG 행렬 각 행의 최댓값 인덱스와 OG 각 열의 최댓값 인덱스가 일치해야 하므로 그 확률은 1/G로 평균 희소성으로 해석할 수 있다. 따라서 할당자가 행을 코어에 균등하게 배분하면 각 코어의 연산량은 시간이 지남 에 따라 총 연산량의 1/(C×G)로 수렴된다. 여기서 C는 코어 수이다. 이러한 연산량 분배 방식은 단순하지만 제 안하는 멀티 에이전트 강화학습 가속 시스템에서 더욱 효과적이다. 연산량을 제안하는 가속 시스템에서는 온칩 인코딩 유닛이 이미 행 단위로 희소 데이터 튜플을 생성하기 때문에 이를 행 단위로 분배하는 것에는 추가 로직 이 필요하지 않다. 또한, 이러한 방식은 단일 레이어를 행 방향으로 여러 코어에 연산량을 분산하기 때문에 레 이어 내 병렬 처리를 바로 활용할 수 있다. 도 7은 본 발명의 일 실시예에 따른 희소 가중치 행렬 곱셈에 대해 설명하기 위한 도면이다. 도 6을 참조하여 설명된 바와 같이, 열 방향 희소 가중치 연산량 분배 유닛에서는 가중치 행렬에 대해 각각의 코어가 모두 동일한 개수의 가중치 행렬 열을 가지면 연산량이 일정하게 수렴할 것이라고 예측하고 연산을 스케 쥴링한다. 연산량을 예측한 후에 이 연산량에 맞게 레이어의 입력과 가중치를 압축하여 희소성 병렬처리 아키텍 처에 전달한다. 이와 같이, 본 발명의 실시예에 따른 열 방향 희소 가중치 연산량 분배 유닛을 사용하면 추가적인 하드웨어 모듈 없이 간단하게 연산량을 스케쥴링 할 수 있다는 장점이 있다. 도 8은 본 발명의 일 실시예에 따른 벡터 프로세싱 유닛을 포함하는 희소성 병렬처리 아키텍처를 설명하기 위한 도면이다. 도 8(a)는 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처를 나타내는 도면이고, 도 8(b)는 본 발명의 실시 예에 따른 벡터 프로세싱 유닛을 나타내는 도면이다. 도 8을 참조하여, 희소성 처리를 포함하는 멀티 에이전트 강화학습의 예측 및 학습의 전 과정을 효율적으로 지 원하는 희소성 병렬처리 아키텍처를 더욱 상세히 설명한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 열 방향 연산량 분배기와 가중치 데이터 압축 유닛으로부 터 희소성을 고려하여 실제 연산할 데이터만 받아 각각 입력 메모리와 가중치 메모리에 저장하고 있다. 희소성 을 고려한 모델의 학습에서 각각의 가중치는 마스크 행렬에 따라 서로 다른 프로세싱 유닛에 분배되어야 하며, 가중치 행렬의 열 마다 실제 연산량에 차이가 존재하게 된다. 따라서 본 발명에서는 기존의 2d 어레이 프로세서 와는 달리 벡터 형태의 프로세싱 유닛을 사용하여 유닛간의 고정된 연결을 최소화하고, 더욱 효율적으로 연산량 을 분배하였다. 도 8을 참조하면, 본 발명의 일 실시예에 따른 벡터 프로세싱 유닛을 포함하는 희소성 병렬처리 아키텍처는 코 어 컨트롤러, 입력 메모리, 가중치 메모리, 희소 데이터 메모리, N개의 밀집/희소 벡터 프로세싱 유닛(Vector Processing Units; VPU)로 구성된 학습 그룹 코어의 아키텍처를 나타내고 있다. 활성화 및 가중치 메모리에는 방향 희소 가중치 연산량 분배 유닛 연산량에서 배포된 활성화 및 패킹 가중치 데이터가 저장된다. 연산량 희소 데이터 메모리는 각 코어에서 실제로 연산해야 할, 즉 마스킹 되지 않은 가중치와 희소 데이터 인코더로부터 받 은 희소 데이터 튜플을 가리키는 인덱스를 각 가중치의 열 별로 저장한다. 본 발명의 실시예에 따르면, 코어 컨 트롤러는 4개의 16비트 입력 데이터가 VPU에 브로드캐스트되며 4사이클 동안 가중치 메모리에서 가중치를 불러 온다. 학습 그룹 코어의 주요 기능은 동시에 서로 다른 연산량을 가진 최대 4개의 행을 처리할 수 있다는 것이다. 여러 행의 가중치는 이미 가중치 압축 유닛에 의해 패킹되어 로드되기 때문에 각 VPU는 브로드캐스트된 4개 의 활성화 중에서 적절한 활성화만 선택하면 된다. 이를 위해 코어 컨트롤러는 희소 데이터 메모리 내의 인덱스 목록과 연산량을 읽어냄으로써 입력 선택 신호를 생성한다. VPU의 입력 선택 신호 행렬은 연산량 번호에 따라 이루어진다. VPU의 WL0 번호는 Activation0을 선택하고 VPU의 WL1 번호는 Activation1을 선택한다. 최대 4개의 행을 VPU에 패킹하여 MAC(multiply-and-accumulate)를 병행함으로써 코어는 높은 처리량과 사용률을 달성할 수 있다. 본 발명의 실시예에 따른 각 VPU는 FP16 곱셈기, FP16 덧셈기, 4-to-1 곱셈기를 포함한다. 입력 메모리로부터 4 개의 활성화를 입력으로 수신하면서 가중치 값을 저장할 수 있어 다중 행 처리가 완료될 때까지 일정하게 유지 된다. 각 VPU에는 4개의 개별 누적 레지스터가 있으며, 각각은 행 인덱스에 대응하여 개별적으로 누적될 수 있 다. 네트워크 차원과 선택 신호 생성의 이동량을 고려하여 VPU 수, N을 264개로 선택한다. 이 구성에서 학습 그 룹 코어는 밀집, 희소 계층에 대해 각각 평균 86.96과 96.89%의 높은 컴퓨팅 사용률을 나타낸다. 도 9는 본 발명의 일 실시예에 따른 벡터 프로세싱 유닛을 통해 입력 선택 신호를 생성하는 과정을 설명하기 위 한 도면이다. 본 발명의 실시예에 따른 벡터 프로세싱 유닛은 최대 4개의 가중치 행렬의 열을 처리할 수 있다. 예를 들어, 입 력 메모리로부터 16비트 입력 4개가 브로드캐스팅 되고 가중치 메모리로부터 각각의 가중치가 유니캐스트 되면 벡터 프로세싱 유닛은 해당 가중치와 어떤 입력을 곱할 것인지 결정한다. 이는 열 방향 연산량 분배기에서 제공 한 연산량을 이용해 생성된 입력 선택 신호를 이용하여 진행된다. 최대 그룹 개수에 해당하는 연산량이 있고, 각각의 가중치 행렬의 열이 어떤 최댓값 인덱스를 가지는지에 따라 입력 선택 신호는 바뀌게 된다. 이를 통해 최대 4개의 연산량, 다시 말해 4개의 열에 대하여 동시에 연산을 진행할 수 있으며, 희소성을 가진 레이어와 그 렇지 않은 레이어 모두에 대해 높은 하드웨어 이용량으로 연산을 진행할 수 있다. 도 10은 본 발명의 일 실시예에 따른 멀티 에이전트 강화학습 가속 시스템의 동작 방법을 설명하기 위한 흐름도 이다. 제안하는 멀티 에이전트 강화학습 가속 시스템의 동작 방법은 가중치 메모리가 PCIe 인터페이스로부터 학습 샘 플들을 제공 받아 멀티 에이전트 강화학습 심층 신경망 학습에 필요한 가중치 값들을 초기화하여 저장하는 단계 , 가중치 희소 데이터 생성 유닛을 통해 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희소성 벡터, 가중치 희소 인덱스, 실제 연산량을 포함하는 희소 데이터를 생성하고, 생성된 희소 데이터를 행방향 가 중치 희소성 데이터 메모리에 저장하는 단계, 가중치 데이터 압축 유닛을 통해 상기 가중치 메모리로부터 가중치를 불러와 상기 생성된 희소 데이터의 형태에 따라 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키텍처로 전송하는 단계, 명령 스케줄러를 통해 가중치 그룹화, 순방향 전 파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망 학습의 전 과정을 제어하는 단계, 희소성 병렬처리 아키텍처가 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정(예를 들어, 전 파, 역전파, 가중치 업데이트)에서 레이어 내 병렬처리를 수행하는 단계, 상기 희소성 병렬처리 아키텍처 의 하나의 레이어의 연산이 끝나면 축적기를 통해 각각의 희소성 병렬처리 아키텍처의 결과를 합치는 단계 및 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나눠주는 단계를 포함한다. 단계에서, 가중치 메모리가 PCIe 인터페이스로부터 학습 샘플들을 제공 받아 멀티 에이전트 강화학습 심 층 신경망 학습에 필요한 가중치 값들을 초기화하여 저장한다. 단계에서, 가중치 희소 데이터 생성 유닛을 통해 에포크가 시작할 때 가중치 그룹화 방식을 이용하여 희 소성 벡터, 가중치 희소 인덱스, 실제 연산량을 포함하는 희소 데이터를 생성하고, 생성된 희소 데이터를 행방 향 가중치 희소성 데이터 메모리에 저장한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 가중치 그룹화를 위해 희소성을 생성하고자 하는 레 이어에 대해 각각의 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬을 생성한다. 이후, 생성된 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스를 저장한 후에 비교한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 상기 입력채널 가중치 그룹행렬과 출력채널 가중치 그룹행렬 각각의 최댓값 인덱스를 비교하여, 최댓값 인덱스가 일치할 경우, 희소성 벡터의 요소를 1로 생성하여 최댓값 인덱스가 일치하는 위치와 일치하는 개수를 저장한다. 반면에, 최댓값 인덱스가 일치하지 않을 경우, 희 소성 벡터의 요소를 0으로 생성한다. 본 발명의 실시예에 따른 가중치 희소 데이터 생성 유닛은 상기 입력채널 가중치 그룹행렬과 상기 출력채널 가 중치 그룹행렬 각각의 최댓값 인덱스 중 최댓값 인덱스의 값은 1이고 나머지는 0인 입력채널 가중치 선택 행렬 과 출력채널 가중치 선택 행렬을 생성한다. 이후, 입력채널 가중치 선택 행렬과 출력채널 가중치 선택 행렬을 곱하여 희소성을 생성하고자 하는 레이어와 동일한 크기의 가중치 마스크 행렬을 생성한다. 이때, 가중치 마스크 행렬의 값이 1인 경우, 해당 가중치를 연 산에 이용하고, 가중치 마스크 행렬의 값이 0인 경우, 해당 가중치는 에포크에서 사용되지 않는다. 단계에서, 가중치 데이터 압축 유닛을 통해 상기 가중치 메모리로부터 가중치를 불러와 상기 생성된 희소 데이터의 형태에 따라 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬처리 아키 텍처로 전송한다. 단계에서, 명령 스케줄러를 통해 가중치 그룹화, 순방향 전파, 역방향 전파 및 가중치 업데이트 작업을 포함하는 신경망 학습의 전 과정을 제어한다. 단계에서, 희소성 병렬처리 아키텍처가 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경망 학습의 전 과정에서 레이어 내 병렬처리를 수행한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 신경 망 학습의 전 과정에서 레이어 내 병렬처리를 수행한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 실제 연산량 및 가중치 희소 인덱스만을 입력 받아 상기 가중치 희소 데이터 생성 유닛에서 생성된 가중치 마스크 행렬에 따라 서로 다른 프로세싱 유닛에 분배한다. 상 기 가중치 마스크 행렬의 열 마다 실제 연산량에 차이가 존재하므로, 벡터 프로세싱 유닛을 통해 상기 벡터 프 로세싱 유닛 간의 고정된 연결을 최소화하여 연산량을 분배하도록 한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 상기 벡터 프로세싱 유닛은 복수의 가중치 마스크 행렬의 열을 병렬처리한다. 이때, 입력 메모리로부터 입력 데이터가 브로드캐스팅 되고 가중치 메모리로부터 각각의 가 중치가 유니캐스트 되면 상기 벡터 프로세싱 유닛은 해당 가중치와 곱할 입력을 결정한다. 단계에서, 상기 희소성 병렬처리 아키텍처의 하나의 레이어의 연산이 끝나면 축적기를 통해 각각의 희소 성 병렬처리 아키텍처의 결과를 합친다. 단계에서, 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 다음 레이어 입력을 각각의 코어에 나 눠준다. 상술된 바와 같이, 본 발명의 실시예에 따른 멀티 에이전트 강화학습 가속 시스템은 한 번의 에포크 동안 상기 가중치 희소 데이터 생성 유닛을 통해 상기 희소 데이터를 생성하고, 생성된 희소 데이터의 형태에 따라 상기 가중치 데이터 압축 유닛을 통해 가중치 값들을 압축하여, 실제 연산량 및 가중치 희소 인덱스만을 희소성 병렬 처리 아키텍처로 전송한다. 그리고, 명령 스케줄러의 제어에 따라 상기 축적기를 통해 각각의 희소성 병렬처리 아키텍처의 결과를 합치고, 연산량 분배기를 통해 다음 레이어의 연산량을 예측하여 각각의 코어에 나눠주는 연 산 방식을 반복하고, 상기 연산 결과에 따른 가중치를 업데이트한다. 본 발명의 실시예에 따른 연산량 분배기는 상기 가중치 희소 데이터 생성 유닛에서 생성된 입력채널 가중치 그 룹행렬과 출력채널 가중치 그룹행렬에 대해 각각의 코어가 모두 동일한 개수의 가중치 그룹행렬 열을 가질 경우 연산량이 일정하게 수렴할 것을 예측하여 연산량을 스케쥴링한다. 연산량을 예측한 후 해당 연산량에 따라 레이 어의 입력과 가중치를 압축하여 희소성 병렬처리 아키텍처에 전달한다. 본 발명의 실시예에 따른 희소성 병렬처리 아키텍처는 상기 연산량 분배기를 통해 제공되는 연산량을 이용하여 생성된 입력 선택 신호를 이용하여 상기 벡터 프로세싱 유닛을 통해 해당 가중치와 곱할 입력을 결정한다. 이후, 각각의 가중치 마스크 행렬의 열이 갖는 최댓값 인덱스에 따라 입력 선택 신호가 변경되어 복수의 가중치 마스크 행렬의 열에 대하여 동시에 연산을 수행하고, 희소성을 가진 레이어와 희소성을 갖지 않은 레이어 모두 에 대하여 연산을 수행한다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로"}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크 로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이 터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0047364", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형 태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성 될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2022-0047364", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 멀티 에이전트 강화학습 가속 시스템의 구성을 나타내는 도면이다. 도 2는 본 발명의 일 실시예에 따른 가중치 그룹화 방식의 희소 데이터 온칩 인코딩 유닛에 대해 설명하기 위한 도면이다. 도 3은 본 발명의 일 실시예에 따른 온칩 인코딩 유닛의 가중치 희소성 데이터 생성 과정을 설명하기 위한 도면 이다. 도 4는 본 발명의 일 실시예에 따른 온칩 인코딩 유닛의 희소성 데이터 생성 시간 단축에 대해 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 온칩 인코딩 유닛의 행 방향 가중치 희소성 데이터 메모리를 종래기술과 비 교하기 위한 도면이다. 도 6은 본 발명의 일 실시예에 따른 열 방향 희소 가중치 연산량 분배기를 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시예에 따른 희소 가중치 행렬 곱셈에 대해 설명하기 위한 도면이다. 도 8은 본 발명의 일 실시예에 따른 벡터 프로세싱 유닛을 포함하는 희소성 병렬처리 아키텍처를 설명하기 위한 도면이다. 도 9는 본 발명의 일 실시예에 따른 벡터 프로세싱 유닛을 통해 입력 선택 신호를 생성하는 과정을 설명하기 위 한 도면이다. 도 10은 본 발명의 일 실시예에 따른 멀티 에이전트 강화학습 가속 시스템의 동작 방법을 설명하기 위한 흐름도 이다."}
