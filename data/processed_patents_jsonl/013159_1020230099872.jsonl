{"patent_id": "10-2023-0099872", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0018783", "출원번호": "10-2023-0099872", "발명의 명칭": "객체 클래스에 따른 데이터 증강을 수행하는 전자 장치 및 그 동작 방법", "출원인": "서울여자대학교 산학협력단", "발명자": "홍헬렌"}}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체 클래스에 따른 데이터 증강을 수행하는 전자 장치로서,제1 데이터 증강 방법을 수행하는 제1 모델;제2 데이터 증강 방법을 수행하는 제2 모델;객체 클래스에 따라 전체 객체에 대한 상기 제1 데이터 증강 방법을 적용할 제1 객체의 비율과, 전체 객체에 대한 상기 제2 데이터 증강 방법을 적용할 제2 객체의 비율을 결정하는 비율 결정부; 및상기 객체를 상기 비율에 따라 제1 객체 및 제 2 객체로 분류하는 배치 분류부; 를 포함하며,상기 배치 분류부는 각 객체 클래스마다 결정된 상기 비율에 따라 상기 트레이닝 배치를 분류하고, 분류된 상기트레이닝 배치를 상기 제1 모델 및 상기 제2 모델에 입력하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 비율 결정부는 상기 객체 클래스의 클래스 불균형을 고려하여 상기 비율을 결정하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 비율 결정부는 상기 객체 클래스가 메이저 클래스인지 또는 마이너 클래스인지 여부에 따라 상기 비율을결정하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 비율 결정부는 상기 객체의 이미지 종류에 따라 상기 비율을 결정하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 비율 결정부가 결정한 상기 메이저 클래스에 대한 트레이닝 배치의 비율과 상기 마이너 클래스에 대한 트레이닝 배치의 비율은 상이한 것을 특징으로 하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 제1 데이터 증강 방법은 MixUp 방법이고, 상기 제2 데이터 증강 방법은 AugMix 방법인 것을 특징으로 하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치.공개특허 10-2025-0018783-3-청구항 7 제6 항에 있어서,상기 객체의 이미지가 국소 간 병변인 경우, 상기 메이저 클래스에서 제1 데이터 증강 방법을 적용한 비율이 상기 마이너 클래스에서 제1 데이터 증강 방법을 적용한 비율보다 작은 것을 특징으로 하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 제1 객체의 이미지, 상기 제2 객체의 이미지, 상기 제1 객체의 증강된 이미지 및 상기 제2 객체의 증강된이미지를 입력 받아 국소 간 병변을 판단하는 제3 모델을 더 포함하는, 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "프로세서와, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 저장하는 메모리를 포함하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법으로서,객체 클래스에 따라 전체 객체에 대한 상기 제1 데이터 증강 방법을 적용할 제1 객체의 비율과, 전체 객체에 대한 상기 제2 데이터 증강 방법을 적용할 제2 객체의 비율을 결정하는 비율결정단계;각 객체 클래스마다 결정된 상기 비율에 따라 상기 객체를 제1 객체 및 제 2 객체로 분류하는 분류단계; 분류된 상기 트레이닝 배치를 상기 제1 모델 및 상기 제2 모델에 입력하는 입력단계; 및분류된 객체에 대해 제1 모델에 의해 제1 데이터 증강 방법을 수행하고, 제2 모델에 의해 제2 데이터 증강 방법을 수행하는 증강단계를 포함하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 비율결정단계는 상기 객체 클래스의 클래스 불균형을 고려하여 상기 비율을 결정하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 비율결정단계는 상기 객체 클래스가 메이저 클래스인지 또는 마이너 클래스인지 여부에 따라 상기 비율을결정하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 비율결정단계는 상기 객체의 이미지 종류에 따라 상기 비율을 결정하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,공개특허 10-2025-0018783-4-상기 비율결정단계는 결정한 상기 메이저 클래스에 대한 트레이닝 배치의 비율과 상기 마이너 클래스에 대한 트레이닝 배치의 비율은 상이한 것을 특징으로 하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 제1 데이터 증강 방법은 MixUp 방법이고, 상기 제2 데이터 증강 방법은 AugMix 방법인 것을 특징으로 하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 객체의 이미지가 국소 간 병변인 경우, 상기 메이저 클래스에서 제1 데이터 증강 방법을 적용한 비율이 상기 마이너 클래스에서 제1 데이터 증강 방법을 적용한 비율보다 작은 것을 특징으로 하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 제1 객체의 이미지, 상기 제2 객체의 이미지, 상기 제1 객체의 증강된 이미지 및 상기 제2 객체의 증강된이미지를 입력 받아 국소 간 병변을 판단하는 판단단계를 더 포함하는, 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치로서, 제1 데이터 증강 방법을 수행하는 제1 모 델; 제2 데이터 증강 방법을 수행하는 제2 모델; 객체 클래스에 따라 전체 객체에 대한 상기 제1 데이터 증강 방 법을 적용할 제1 객체의 비율과, 전체 객체에 대한 상기 제2 데이터 증강 방법을 적용할 제2 객체의 비율을 결정 하는 비율 결정부; 및 상기 객체를 상기 비율에 따라 제1 객체 및 제 2 객체로 분류하는 배치 분류부; 를 포함하 며, 상기 배치 분류부는 각 객체 클래스마다 결정된 상기 비율에 따라 상기 트레이닝 배치를 분류하고, 분류된 상기 트레이닝 배치를 상기 제1 모델 및 상기 제2 모델에 입력할 수 있다."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 데이터 증강을 수행하는 전자 장치 및 그 동작 방법에 관한 것으로, 특히 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래에는 객체의 데이터량이 많은 메이저 클래스(Major class)와 데이터량이 적은 마이너 클래스(Minor class) 를 구분하지 않고 객체에 대해 동일한 데이터 증강 방법을 적용하였다. 도 1에 도시된 바와 같이, 간 병변을 판단하기 위해 간(liver) 이미지의 객체에 대해 MixUp 데이터 증강 방법만 적용하였을 경우, 메이저 클래스와 마이너 클래스 사이에 데이터량이 부족한 영역(a)에 데이터가 증강(b)됨을 확인할 수 있다. 그러나, 이는 메이저 클래스인 물혹(Cyst)와 전이암(Metastasis)에 대해서만 데이터가 증강되 고, 마이너 클래스인 혈관종(Hemagioma)의 데이터는 거의 증강되지 않아 클래스에 따라 불균형이 발생하며, 데 이터 증강을 통해 불균형이 더 심화됨을 알 수 있다. 또한, 도 2에 도시된 바와 같이, 객체에 대해 AugMix 데이터 증강 방법만 적용하였을 경우, 여러 가지 클래스가 뒤섞여서 데이터가 튀는 형상을 없애 전체적인 데이터들이 안정적으로 분류되도록 데이터가 증강됨을 확인할 수 있다. AugMix는 각 클래스의 데이터를 안정적으로 확장시키기 때문에 마이너 클래스인 혈관종의 특이도 개선에 특히 도움이 됨을 확인할 수 있다. 다시 말해, 이미지 데이터를 분류할 때 모든 데이터 세트 크기가 동일할 수 없어 데이터 증강 방법의 효과가 클 래스 별로 다르게 나타나기 때문에 클래스에 상관없이 일관된 형태의 데이터 증강을 적용할 경우 특정 클래스로 의 편향(bias)가 발생할 우려가 있다. 따라서, 각 클래스 별로 적합한 데이터 증강을 수행할 필요가 있다. 또한, 종래 특허문헌과 같이 복수의 데이터 증강 방법을 적용하더라도 복수의 데이터 증강 방법을 결한한 기초 에 의하여 데이터를 증강한다고 할 뿐 각 클래스마다 어떻게 복수의 데이터 증강 방법을 적용할 것인지도 불확실하다는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 10-2022-0003968 A"}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에 개시된 실시예는 객체 클래스에 따라 결정된 상이한 비율의 트레이닝 배치에 복수의 데이터 증강 방 식을 적용하는, 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치 및 그 동작 방법을 제공하는데 그 목적 이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 발명에 따른 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치는, 제1 데이터 증강 방법을 수행하는 제1 모델; 제2 데이터 증강 방법을 수행하는 제2 모델; 객체 클래스에 따라 전체 객체에 대한 상기 제1 데이터 증강 방법을 적용할 제1 객체의 비율과, 전체 객체에 대한 상기 제2 데이터 증강 방법을 적용할 제2 객체의 비율을 결정하는 비율 결정부; 및 상기 객체를 상기 비율에 따라 제1 객체 및 제 2 객체로 분류하는 배치 분류부; 를 포함하며, 상기 배치 분류부는 각 객체 클래스마다 결정된 상기 비율에 따라 상기 트레이닝 배치를 분류하고, 분류된 상기 트레이닝 배치를 상기 제1 모델 및 상기 제2 모델에 입력할 수 있다. 상술한 기술적 과제를 달성하기 위한 본 발명에 따른 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법은, 프로세서와, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 저장하는 메모리를 포함하는 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법으로서, 객체 클래스에 따라 전체 객체에 대한 상 기 제1 데이터 증강 방법을 적용할 제1 객체의 비율과, 전체 객체에 대한 상기 제2 데이터 증강 방법을 적용할 제2 객체의 비율을 결정하는 비율결정단계; 각 객체 클래스마다 결정된 상기 비율에 따라 상기 객체를 제1 객체 및 제 2 객체로 분류하는 분류단계; 분류된 상기 트레이닝 배치를 상기 제1 모델 및 상기 제2 모델에 입력하는 입력단계; 및 분류된 객체에 대해 제1 모델에 의해 제1 데이터 증강 방법을 수행하고, 제2 모델에 의해 제2 데 이터 증강 방법을 수행하는 증강단계를 포함할 수 있다. 이 외에도, 본 발명을 구현하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 더 제공될 수 있다. 이 외에도, 본 발명을 구현하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 전술한 과제 해결 수단에 의하면, 메이저 클래스와 마이너 클래스에 따라 각각 상이한 데이터 증강 방법을 적용함으로써 각 클래스에 더 효율적인 데이터 증강 방법을 적용하여 클래스 별 성능을 최적으로 개선하 는 효과를 제공한다. 또한, 본 발명의 전술한 과제 해결 수단에 의하면, 각 클래스의 트레이닝 배치에 대해 상이한 비율로 데이터 증 강 방식을 적용함으로써 클래스 별 데이터량 불균형을 최소화하여 이미지 기반 분류 효율을 향상시키는 효과를 제공한다."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 발명이 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 ‘부, 모듈, 부재, 블록’이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으 며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 발명의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 발명에 따른 장치'는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들 이 모두 포함된다. 예를 들어, 본 발명에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 발명에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 발명에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN: Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 발명의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련데이터로서 입력데이터와 출력데이터가 같이 제공됨으로써 문제(입력데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출력데 이터 없이 입력데이터만 제공되어 문제(입력데이터)의 해답(출력데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴 럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과(output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 발명의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 3은 본 발명에 따른 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 구성을 간략하게 도시한 블록 도이다. 이하, 도 4 내지 도 7을 참조하여 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치를 구체적으로 설명하기로 한다. 도 3에 도시된 바와 같이, 본 발명에 따른 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치는, 제1 데이터 증강 방법을 수행하는 제1 모델, 제2 데이터 증강 방법을 수행하는 제2 모델, 객체 클래스에 따라 전체 객체에 대한 상기 제1 데이터 증강 방법을 적용할 제1 객체의 비율과, 전체 객체에 대한 상기 제2 데 이터 증강 방법을 적용할 제2 객체의 비율을 결정하는 비율 결정부 및 상기 객체를 상기 비율에 따라 제1 객체 및 제 2 객체로 분류하는 트레이닝 배치 분류부를 포함할 수 있다. 또한, 일 실시예에 따른 배치 분류부는 각 객체 클래스마다 결정된 상기 비율에 따라 상기 트레이닝 배치 를 분류하고, 분류된 상기 트레이닝 배치를 상기 제1 모델 및 상기 제2 모델에 입력할 수 있 다. 훈련 이미지(Training image) 또는 테스트 이미지(Test image)를 입력 받으면, 이는 트레이닝 배치에 객체 로서 저장될 수 있다. 트레이닝 배치에 대해 비율 결정부가 제1 모델로 입력될 트레이닝 배치 와, 제2 모델로 입력될 트레이닝 배치의 비율을 결정할 수 있다.예를 들어, 비율 결정부가 전체의 75%의 트레이닝 배치는 제1 모델로, 전체의 25%의 트레이닝 배치는 제2 모델로 입력하기로 결정하고, 배치 분류부가 결정된 비율에 따라 트레이닝 배치를 분류할 수 있다. 본 발명의 실시예에 따른 비율 결정부는 상기 객체 클래스의 클래스 불균형을 고려하여 상기 비율을 결정 할 수 있다. 전체 객체를 클래스의 불균형에 따라 분류한 후 분류된 객체에 따라 상이한 데이터 증강 방법을 적 용하여 클래스에 따른 불균형을 최소화하도록 데이터를 증강할 수 있다. 일 실시예로서, 비율 결정부는 상기 객체 클래스가 메이저 클래스인지 또는 마이너 클래스인지 여부에 따 라 상기 비율을 결정할 수 있다. 예를 들어, 트레이닝 배치에 있는 객체의 데이터량을 고려하여 메이저 클래스 또는 마이너 클래스로 구분 하고, 메이저 클래스에 포함된 객체와 마이너 클래스에 포함된 객체에 상이한 데이터 증강 방법을 적용할 수 있 다. 또는, 메이저 클래스에 포함된 객체에 제1 비율을 적용하여 트레이닝 배치를 분류하고, 마이너 클래스에 포 함된 객체에 제2 비율을 적용하여 트레이닝 배치를 분류할 수 있다. 그리고 각 클래스에서 분류된 트레이 닝 배치에 각각 상이한 데이터 증강 방법을 적용할 수 있다. 이때, 비율 결정부가 결정한 상기 메이저 클래스에 대한 트레이닝 배치의 비율과 상기 마이너 클래스 에 대한 트레이닝 배치의 비율은 상이할 수 있다. 도 4는 객체가 간 병변에 대한 이미지일 경우를 가정하여 결정된 비율에 따라 배치 분류부가 트레이닝 배 치를 분류한 것으로, 도 4에 도시된 바와 같이, 트레이닝 배치에는 메이저 클래스인 물혹(Cyst, 11)과, 메이저 클래스인 전이암(Metastasis, 13), 마이너 클래스인 혈관종(Hemangioma, 15)이 입력될 수 있다. 또한, 배치 분류부는 결정된 비율에 따라 물혹, 전이암, 혈관종 내의 객체를 분류할 수 있다. 이때, 제1 데이터 증강 방법은 MixUp 방법이고, 제2 데이터 증강 방법은 AugMix 방법일 수 있다. 메이저 클래스 에 속한 전체 트레이닝 배치에서 MixUp 방법이 적용되는 트레이닝 배치의 비율을 rM이라 하고, 마이너 클래스에 속한 전체 트레이닝 배치에서 MixUp 방법이 적용되는 트레이닝 배치의 비율을 rm이라 정의한 다. 메이저 클래스에 속한 전체 트레이닝 배치에서 AugMix 방법이 적용되는 트레이닝 배치의 비율은 1- rM, 마이너 클래스에 속한 전체 트레이닝 배치에서 AugMix 방법이 적용되는 트레이닝 배치의 비율은 1- rm이 된다. 따라서, 배치 분류부는 메이저 클래스인 물혹, 전이암에서 rM의 비율을 적용하여 산출된 개수만큼 의 트레이닝 배치와, 1-rM 비율을 적용하여 산출된 개수만큼의 트레이닝 배치를 분류할 수 있다. rM 비율로 산출 된 트레이닝 배치에는 MixUp 방법을 적용하고, 1-rM 비울로 산출된 트레이닝 배치에는 AugMix 방법을 적용하도 록 제1 모델 또는 제2 모델에 입력할 수 있다. 또한, 배치 분류부는 마이너 클래스인 혈관종에서 rm의 비율을 적용하여 산출된 개수만큼의 트레이닝 배치와, 1-rm비율을 적용하여 산출된 개수만큼의 트레이닝 배치를 분류할 수 있다. rm 비율로 산출된 트레이닝 배치에는 MixUp 방법을 적용하고, 1-rm 비율로 산출된 트레이닝 배치에는 AugMix 방법을 적용하도록 제1 모델 또는 제2 모델에 입력할 수 있다. rm와 rM의 값은 상이하며, 메이저 클래스인지 마이너 클래스인지 여부에 따라 다르게 결정될 수 있다. 일 실시예로서, 상기 객체의 이미지가 국소 간 병변인 경우, 상기 메이저 클래스에서 MixUp 방법을 적용한 비율 은 0.5이고, 상기 마이너 클래스에서 MixUp 방법을 적용한 비율은 0.75일 수 있다. Mixup 방법은 서로 다른 클래스에 속하는 영상을 선형조합하여 각 클래스 사이 영역의 데이터 포인트를 정의함 으로써 각 클래스를 구분 짓는 특징을 이용하여 데이터 증강을 수행하는 기법이며, AugMix 방법은 자기 영상을 transformation을 한 것을 자기 영상과 선형조합하여 해당 클래스에 해당하는 데이터 포인트를 정의하고, 해당 클래스에 해당하는 특징을 이용하여 데이터 증강을 수행하는 기법이다. 본 발명에 따른 전자 장치는 두 데이터 증강 기법을 클래스 별로 다른 비율로 혼합하여 각 클래스 별 성능 을 최적 개선할 수 있으며, 마이너 클래스일수록 MixUp 방법의 적용 비율을 늘려 데이터가 부족한 영역의 데이 터 증강에 집중하도록 할 수 있다. 또한, 비율 결정부는 상기 객체의 이미지 종류에 따라 상기 비율을 결정할 수 있다. 예를 들어, 객체가 간 병변 이미지 또는 영상일 경우, 상기 메이저 클래스에서 MixUp 방법을 적용한 비율은 0.5 이고, 상기 마이너 클래스에서 MixUp 방법을 적용한 비율은 0.75일 수 있다. 그러나, 다른 객체일 경우, 본 발명에 따른 비율 결정부는 메이저 클래스와 마이너 클래스 간의 데이터량 차이를 고려하여 MixUp 방법의 적용 비율을 상이하게 산출할 수 있다. 따라서, 상기 제1 객체의 이미지, 상기 제2 객체의 이미지, 제1 모델로 부터 출력된 상기 제1 객체의 증강 된 이미지, 및 제2 모델로부터 출력된 상기 제2 객체의 증강된 이미지를 입력 받아 국소 간 병변을 판단하 는 제3 모델을 더 포함할 수 있다. 일 실시예로서, 제3 모델은 간 병변이 있으면 양성, 간 병변이 없으면 음성으로 객체를 판단하여 출력할 수 있다. 도 5는 데이터 증강 방법에 따라 측정한 데이터 증강 효율을 나타낸 것으로, 데이터 증강 효율을 확인하기 위하 여 정확도(Accuracy), Class-Normalized Accuracy(CNA), F1 score, 민감도(Sensitivity), 특이도 (Specificity)를 즉정한 결과를 도시한 것이다. 특히, CNA는 클래스 별 Accuracy를 측정하여(Accuracy(M)) 클래스 별 Accuracy를 클래스 크기(M)로 나눈 것이다. Accuracy를 측정하는 경우에는, 크기가 작은 마이너 클래스의 경우 비중이 작아 증강된 데이터가 틀려도 Accuracy가 감소하지 않았다. 반면, CNA에서 클래스 크기(M)로 나눠주게 되면, 크기가 작아도 다른 클래스에 비 해 비중이 커지게 되어 크기가 작은 마이너 클래스의 영향력이 커지게 된다. 다시 말해, CNA는 마이너 클래스에서 오류가 발생할 경우 패널티를 크게 가져갈 수 있으며 클래스 불균형 (imbalance)을 반영한 파라미터이다. 또한, F1 score도 클래스 별로 점수를 내서 평균을 내기 때문에 클래스 불균형이 반영된 파라미터이다. 따라서, Accurancy보다 CNA 와 F1 score가 높게 산출되는 것이 마이너 클래스에서의 증강 효율까지 정확히 반영 된 데이터 증강 방법이다. 도 5에 도시된 바와 같이, 전체 트레이닝 배치에 Affine, MixUp, AugMix 방법을 각각 적용하여 데이터 증강을 수행할 경우, Accuracy는 높게 나오더라도 CNA, F1 score는 낮게 나오는 것을 확인할 수 있다. 반면, 본 발명에 따른 전자 장치를 이용하여 복수의 데이터 증강 기법을 클래스 별로 다른 비율로 혼합하 여 데이터 증강하는 CDDA(Class Dependent Data Augmentation) 방법을 적용한 경우, rM은 50%, rm은 75%으로 혼합했을 때 Accuracy는 Affine, MixUp, AugMix 방법보다 낮더라도 CNA와 F1 score는 더 높은 것을 확인할 수 있다. 또한, 도 5에 도시된 바와 같이, Cyst와 Metastasis와 같은 메이저 클래스의 경우, 종래의 Affine, MixUp, AugMix 방법을 수행하더라도 비교적 민감도(Sens), 특이도(Spec)가 모두 높게 나타나나, Hemangioma와 같은 마 이너 클래스의 경우, Sens가 낮게 나타난다. 특히, MixUp 방법을 이용할 경우, 메이저 클래스인 전이암에서 데이터 증강이 되어 Sens가 가장 잘 개선되는 바, 전체적인 Accuracy는 가장 높게 나타나지만, 마이너 클래스인 혈관종에서는 오히려 떨어진 Sens 값을 확인 할 수 있다. 또한, AugMix 방법을 이용할 경우, 메이저 클래스인 물혹, 전이암의 Sens는 떨어지지만, 마이너 클래스인 혈관 종의 Sens는 올라갔음을 확인할 수 있다. 다시 말해, AugMix 방법은 마이너 클래스의 데이터 증강에 효율적이고, MixUp 방법은 메이저 클래스의 데이터 증강에 효율적이며, 이를 고려하여 본 발명에 따른 전자 장치에 의해 수행되는 CDDA 방법은, rM은 50%, rm 은 75% 비율로 메이저 클래스와 마이너 클래스를 구분하여 MixUp 방법을 적용하고, 1-rM은 50%, 1-rm은 25% 비 율로 메이저 클래스와 마이너 클래스를 구분하여 AugMix 방법을 적용할 수 있다. 따라서, 트레이닝 배치의 메이저 클래스와 마이너 클래스 여부, 객체의 종류를 고려하여 결정된 비율에 따라 트 레이닝 배치를 분류하고 분류된 트레이닝 배치에 각각 상이한 데이터 증강 방법을 적용함으로써 최적의 데이터 증강 방법을 적용할 수 있다. 도 6은 본 발명에 따른 전자 장치에 의해 수행되는 CDDA 방법을 rM은 50%, rm은 75% 비율로 적용한 경우의 데이터량 변화를 도시한 것으로, 도 6(a)에 도시된 바와 같이 MixUp 방법에 의해 증강된 데이터는 물혹과 전이 암의 경계영역의 데이터들, 전이암과 혈관종의 경계성 영역의 데이터들을 추가 생성하고 있음을 확인할 수 있다. 특히, 마이너 클래스인 혈관종의 데이터가 눈에 띄게 증가하였음을 확인할 수 있다. 또한, 도 6(b)에 도 시된 바와 같이, AugMix 방법에 의해 증강된 데이터는 클래스가 뒤섞인 데이터들이 아직 남아있기는 하나 데이 터가 지나치게 튀는 형상이 없이 안정적으로 분류되서 분포가 되어 있으며, 마이너 클래스에서도 비교적 안정적 으로 증강되어 안정적인 데이터 증강이 수행됨을 확인할 수 있다. 따라서, 본 발명에 따른 전자 장치는 객체를 분류(classification) 할 수 있는 태스크에서 메이저 클래스 와 마이너 클래스를 구분하여 클래스 특성에 따라 데이터 증강 방법을 적용할 수 있다. 상술한 방법에서는 MixUp 방법과 AugMix 방법으로 한정한 실시예로 서술하였으나, 다른 데이터 증강 방법도 클 래스에 따라 구분하여 적용할 수 있다. 또한, 클래스에 따라 데이터 증강 방법을 달리 적용하는 것 뿐만 아니라 클래스에 따라 다른 비율로 트레이닝 배치를 분류하여 각각 상이한 데이터 증강 방법을 적용함으로써 하나의 데이터 증강 방법을 적용하여 부족한 부 분을 추가적으로 보완하여 최적의 데이터 증강을 수행할 수 있다. 상술한 방법에서는 rM=50%, rm=75%로 일 실시예에 따른 수치로 서술하였으나, 간 병변 영상 외에 영상 분류가 가능한 객체의 경우 그 객체의 종류에 따라 상이한 수치의 비율로 데이터 증강 방법을 적용할 수 있다. 따라서, 본 발명에 따른 전자 장치는 각 데이터 증강 방법의 효과가 클래스 별로 상이하게 나타나도록 두 데이터 증강 방법을 클래스 별로 다른 비율로 혼합하여 각 클래스 별 성능을 최적 개선할 수 있다. 이때, 두 가지 데이터 증강 방법을 적용한 것은 예시적인 실시예로서 두 가지 이상의 데이터 증강 방법을 적용 할 수도 있다. 도 7은 본 발명에 따른 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법을 도시한 플로우 차 트이다. 도 7에 도시된 바와 같이, 본 발명에 따른 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법은, 프로세서와, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 저장하는 메모리를 포함하는 객체 클래 스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법일 수 있다. 상기 동작 방법은 객체 클래스에 따라 전체 객체에 대한 상기 제1 데이터 증강 방법을 적용할 제1 객체의 비율 과, 전체 객체에 대한 상기 제2 데이터 증강 방법을 적용할 제2 객체의 비율을 결정하는 단계(S710), 각 객체 클래스마다 결정된 상기 비율에 따라 상기 객체를 제1 객체 및 제 2 객체로 분류하는 트레이닝 배치하는 단계 (S720), 분류된 상기 트레이닝 배치를 상기 제1 모델 및 상기 제2 모델에 입력하는 단계(S730), 및 분류된 객체에 대해 제1 모델에 의해 제1 데이터 증강 방법을 수행하고, 제2 모델에 의해 제2 데이 터 증강 방법을 수행하는 단계(S740)를 포함할 수 있다. 일 실시예로서, 단계(S710)는 상기 객체 클래스의 클래스 불균형을 고려하여 상기 비율을 결정할 수 있다. 구체적으로, 단계(S710)는 상기 객체 클래스가 메이저 클래스인지 또는 마이너 클래스인지 여부에 따라 상기 비 율을 결정할 수 있다. 또한, 단계(S710)는 상기 객체의 이미지 종류에 따라 상기 비율을 결정할 수 있다. 일 실시예로서, 단계(S710)에서 결정한 상기 메이저 클래스에 대한 트레이닝 배치의 비율과 상기 마이너 클래스 에 대한 트레이닝 배치의 비율은 상이할 수 있다. 예를 들어, 상기 객체의 이미지가 국소 간 병변인 경우, 상기 제1 데이터 증강 방법은 MixUp 방법이고, 상기 제 2 데이터 증강 방법은 AugMix 방법을 적용할 수 있으며, 상기 메이저 클래스에서 제1 데이터 증강 방법을 적용 한 비율(rM)은 0.5, 상기 마이너 클래스에서 제1 데이터 증강 방법을 적용한 비율(rm)은 0.75로 rM이 rm보다 작 을 수 있다. 이는 예시적인 실시예로서, 국소 간 병변을 판단하기 위해 국소 간 병변 영상에 대한 데이터 증강을 수행할 경우의 방법과 비율이며, 객체의 종류가 달라질 경우 그 방법과 비율도 달라질 수 있다. 더하여, 본 발명에 따른 전자 장치의 동작 방법은 제1 객체의 이미지, 상기 제2 객체의 이미지, 상기 제1 객체의 증강된 이미지 및 상기 제2 객체의 증강된 이미지를 입력 받아 국소 간 병변을 판단하는 판단단계를 더 포함할 수 있다. 학습에 사용될 데이터를 데이터 증강 방법을 이용하여 그 수를 늘리고 국소 간 병변을 판단하 는 제3 모델의 학습 효율을 높일 수 있다. 한편, 도 8은 본 발명의 일 실시예에 따른 컴퓨팅 장치를 도시한 것이다. 도 8에 도시된 바와 같이, 본 발명에 따른 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치는 컴퓨터에 의해 실행 가능한 명령어를 저장 하는 기록매체의 형태로 구현될 수 있다. 명령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽 을 수 있는 기록매체로 구현될 수 있다. 본 발명에 따른 전자 장치는 컴퓨팅 장치에 대응될 수 있으며, 컴퓨팅 장치는 적어도 하나의 프로세서 , 프로그램을 포함하는 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함할 수 있다. 또한, 컴 퓨팅 장치는 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다."}
{"patent_id": "10-2023-0099872", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2023-0099872", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 데이터에 대해 동일한 데이터 증강 방법을 적용했을 때 데이터량 변화를 도시한 것이다. 도 3은 본 발명의 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 구성을 간략하게 도시한 블록도이다. 도 4는 본 발명의 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치를 이용한 트레이닝 배치를 간략하게 도시한 개념도이다. 도 5는 본 발명의 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 비율에 따라 측정한 데이터 증강 효 율을 나타낸 것이다. 도 6은 본 발명의 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 데이터 증강 방법을 적용했을 때 데 이터량 변화를 도시한 것이다. 도 7은 본 발명의 객체 클래스에 따른 데이터 증강을 수행하는 전자 장치의 동작 방법을 도시한 플로우 차트이 다. 도 8은 본 발명의 일 실시예에 따른 컴퓨팅 장치를 도시한 것이다."}
