{"patent_id": "10-2022-0075187", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0064535", "출원번호": "10-2022-0075187", "발명의 명칭": "글로벌 모델의 방향성을 따르는 로컬 모델 연합 학습 시스템, 방법, 컴퓨터 판독 가능한 기록", "출원인": "한국과학기술원", "발명자": "이기훈"}}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "글로벌 모델의 글로벌 파라미터를 각 클라이언트 장치에 전송하고, 각 클라이언트 장치로부터 학습된 로컬 파라미터를 수신하여 상기 글로벌 모델을 업데이트하는 중앙 서버; 및글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 손실 함수(lossfunction)에 가해 상기 로컬 모델을 학습시킴으로써 학습된 로컬 파라미터를 상기 중앙 서버에 전송하는 복수의클라이언트 장치를 포함하는, 연합 학습 시스템."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 클라이언트 장치는, 상기 글로벌 파라미터를 유지한 채 동작하는 글로벌 모델; 및 자신이 보유한 데이터를 사용해 상기 글로벌 파라미터를 갱신한 로컬 파라미터를 생성하는 로컬 모델을 저장하는, 연합 학습 시스템."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 로컬 모델의 손실 함수는, 자신이 보유한 데이터의 정답값과 상기 로컬 모델의 예측값의 차이가 작아지도록 하는 제1 손실 함수; 및 상기글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 차이가 작아지도록 하는 제2 손실 함수를 포함하는, 연합 학습 시스템."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제2 손실 함수는, 학습할 데이터의 출력 클래스 중 FALSE에 해당하는 클래스에 대한 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 손실을 포함하고, 학습할 데이터의 출력 클래스 중 TRUE에 해당하는 클래스에 대한 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 손실은 0으로 설정하는, 연합 학습 시스템."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제1 손실 함수는, 클라이언트 장치가 보유한 데이터의 정답값과 상기 로컬 모델의 예측값에 대한 크로스 엔트로피 함수를 포함하고, 상기 제2 손실 함수는, 상기 글로벌 모델의 예측값과, 로컬 모델의 예측값의 확률에 대한 크로스 엔트로피 함수를 포함하는, 연합 학습 시스템.공개특허 10-2023-0064535-3-청구항 6 제5항에 있어서,상기 로컬 모델의 손실 함수는, 상기 글로벌 모델의 반영 정도를 나타내는 가중치를 상기 제2 손실 함수에 가한 값과 상기 제1 손실 함수의 합으로 구성되는, 연합 학습 시스템."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 가중치는,0 보다 크거나 같고 1보다 작거나 같은 범위의 실수값으로 설정되는, 연합 학습 시스템."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 예측값은, 글로벌 모델 또는 로컬 모델의 출력값에 logit 함수 및 softmax 함수를 통과시켜 출력되는 확률값으로 구성된,연합 학습 시스템."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "중앙 서버 및 복수의 클라이언트 장치가 수행하는 연합 학습 방법에 있어서, 중앙 서버가 글로벌 모델의 글로벌 파라미터를 각 클라이언트 장치에 전송하는 단계;복수의 클라이언트 장치 각각이 글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 손실 함수(loss function)에 가해 상기 로컬 모델을 학습시킴으로써 학습된 로컬 파라미터를 상기 중앙 서버에 전송하는 단계; 및 중앙 서버가 각 클라이언트 장치로부터 학습된 로컬 파라미터를 수신하여 상기 글로벌 모델을 업데이트하는 단계를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 복수의 클라이언트 장치는, 상기 글로벌 파라미터를 유지한 채 동작하는 글로벌 모델; 및 클라이언트 장치가 보유한 데이터를 사용해 상기글로벌 파라미터를 갱신한 로컬 파라미터를 생성하는 로컬 모델을 저장하는, 연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 로컬 모델의 손실 함수는, 자신이 보유한 데이터의 정답값과 상기 로컬 모델의 예측값의 차이가 작아지도록 하는 제1 손실 함수; 및 상기글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 차이가 작아지도록 하는 제2 손실 함수를 포함하는, 공개특허 10-2023-0064535-4-연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제2 손실 함수는, 학습할 데이터의 출력 클래스 중 FALSE에 해당하는 클래스에 대한 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 손실을 포함하고, 학습할 데이터의 출력 클래스 중 TRUE에 해당하는 클래스에 대한 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 손실은 0으로 설정하는, 연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 제1 손실 함수는, 자신이 보유한 데이터의 정답값과 상기 로컬 모델의 예측값에 대한 크로스 엔트로피 함수를 포함하고, 상기 제2 손실 함수는, 소프트맥스 함수를 이용한 상기 글로벌 모델의 예측값의 확률과, 소프트맥스 함수를 이용한 로컬 모델의 예측값의 확률에 대한 크로스 엔트로피 함수를 포함하는, 연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 로컬 모델의 손실 함수는, 상기 글로벌 모델의 반영 정도를 나타내는 가중치를 상기 제2 손실 함수에 가한 값과 상기 제1 손실 함수의 합으로 구성되는, 연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 가중치는,0 보다 크거나 같고 1보다 작거나 같은 범위의 실수값으로 설정되는, 연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 예측값은, 글로벌 모델 또는 로컬 모델의 출력값에 logit 함수 및 softmax 함수를 통과시켜 출력되는 확률값으로 구성된,연합 학습 방법."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서,글로벌 모델의 글로벌 파라미터를 획득하는 단계;글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 손실 함수(loss공개특허 10-2023-0064535-5-function)에 가해 상기 로컬 모델을 학습하는 단계; 및학습된 로컬 파라미터를 중앙 서버에 전송하는 단계의 연합 학습 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하는, 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2022-0075187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서,글로벌 모델의 글로벌 파라미터를 획득하는 단계;글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 손실 함수(lossfunction)에 가해 상기 로컬 모델을 학습하는 단계; 및학습된 로컬 파라미터를 중앙 서버에 전송하는 단계의 연합 학습 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 연합 학습 시스템은 글로벌 모델의 글로벌 파라미터를 각 클라이언트 장치에 전송하 고, 각 클라이언트 장치로부터 학습된 로컬 파라미터를 수신하여 상기 글로벌 모델을 업데이트하는 중앙 서버; 및 글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실을 손실 함수에 가해 상기 로 컬 모델을 학습시킴으로써 학습된 로컬 파라미터를 상기 중앙 서버에 전송하는 복수의 클라이언트 장치를 포함할 수 있다."}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 글로벌 모델의 방향성을 따르는 로컬 모델 연합 학습 시스템, 방법, 컴퓨터 판독 가능한 기록 매체 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 클라우드 및 빅데이터 기술의 발전으로 다양한 서비스에 인공 지능(Artificial Intelligence; AI) 기술이 적용되고 있다. 이러한 인공 지능 기술을 서비스에 적용하기 위해서는 많은 양의 데이터를 바탕으로 인공 지능 모델을 학습하는 절차가 선행되어야 한다. 인공 지능 모델의 학습에는 대규모 계산을 수행하기 위해 상당한 컴퓨터 리소스가 필요하다. 일 예로, 클라우드 컴퓨팅 서비스는 복잡한 하드웨어 및 소프트웨어 설치 없이 인공 지능 모델을 학습할 수 있도록 클라우드 컴퓨 팅 인프라를 제공하는 서비스이다. 클라우드 컴퓨팅은 리소스의 중앙 집중화를 기반으로 하기 때문에 필요한 모 든 데이터를 클라우드 메모리에 저장하고 모델 학습에 활용해야 한다. 데이터 중앙 집중화는 효율성 극대화라는 관점에서 많은 이점을 제공하지만, 사용자 개인 데이터의 유출 위험이 있으며 데이터 전송이 수반됨에 따라 상 당한 네트워크 비용이 발생한다. 최근 이러한 문제를 극복하기 위해 연합 학습(Federated Learning)이 활발히 연구되고 있다. 연합 학습이란 기 존처럼 사용자 개인 데이터를 중앙에 모아서 학습하는 것이 아니라, 여러 클라이언트 장치가 보유한 개별 데이 터를 기초로 각 클라이언트 장치가 직접 학습한 모델을 중앙으로 취합하는 형식의 학습 방법이다. 이러한 연합 학습은 사용자 개인 데이터를 중앙으로 수집하는 것이 아니기 때문에 사생활 침해 소지가 적고, 갱신된 모델의 파라미터만을 전송할 수 있기에 네트워크 비용이 절감될 수 있다. 한편, 일반적으로 연합 학습에 사용되는 각 클라이언트 장치의 실제 데이터셋은 수, 종류, 분포 등이 서로 상이 한 경우가 대부분이다. 이러한 경우, 각 클라이언트 장치는 자신이 보유한 데이터만으로 학습하기 때문에, 개별 적으로 학습된 파라미터들은 학습 방향성에 대한 기준이 없는 상태로 값이 갱신될 수 있다. 때문에, 도 1(a)를 참조하면, 각 클라이언트 장치가 개별적으로 생성한 각 로컬 파라미터는 모델이 예측값을 도 출하는 방향에 대한 편차가 발생할 가능성이 높고, 중앙 서버가 이러한 로컬 파라미터들을 취합하여 글로벌 모 델을 업데이트하는 경우, 글로벌 모델 역시도 학습 방향성을 잃게 되는 포게팅(ex. catastrophic forgetting) 문제가 발생할 수 있다. 한편, 상술한 도 1(a)의 내용은 발명자가 본원의 개시 내용을 도출하는 과정에서 보유하거나 습득한 것으로서, 반드시 본 출원 전에 일반 공중에 공개된 공지 기술이라고 할 수는 없다. 선행기술문헌특허문헌 (특허문헌 0001) 대한민국 공개특허공보 제10-2021-0132500호 (2021년11월04일 공개) : 연합 학습 시스템 및 방 법"}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 연합 학습에 사용되는 각 클라이언트 장치의 데이터 불균형으로 인해 다양한 문제가 야기될 수 있다는 점에 착안하여, 도 1(b)와 같이, 각 클라이언트 장치의 로컬 모델들이 글로벌 모델을 기준으로 학습의 방향성을 따라 파라미터를 학습하도록 하는 연합 학습 시스템, 방법, 컴퓨터 판독 가능한 기록 매체 및 컴퓨터 프로그램을 제공하는 것이다. 다만, 본 발명이 해결하고자 하는 과제는 이상에서 언급한 바로 제한되지 않으며, 언급되지는 않았으나 아래의"}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있는 목적을 포함할 수 있다."}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 연합 학습 시스템은 글로벌 모델의 글로벌 파라미터를 각 클라이언트 장치에 전송 하고, 각 클라이언트 장치로부터 학습된 로컬 파라미터를 수신하여 상기 글로벌 모델을 업데이트하는 중앙 서버; 및 글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 손실 함수 (loss function)에 가해 상기 로컬 모델을 학습시킴으로써 학습된 로컬 파라미터를 상기 중앙 서버에 전송하는 복수의 클라이언트 장치를 포함할 수 있다. 또한, 상기 복수의 클라이언트 장치는 상기 글로벌 파라미터를 유지한 채 동작하는 글로벌 모델; 및 자신이 보 유한 데이터를 사용해 상기 글로벌 파라미터를 갱신한 로컬 파라미터를 생성하는 로컬 모델을 저장할 수 있다. 또한, 상기 로컬 모델의 손실 함수는 자신이 보유한 데이터의 정답값과 상기 로컬 모델의 예측값의 차이가 작아 지도록 하는 제1 손실 함수; 및 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 차이가 작아지도록 하 는 제2 손실 함수를 포함할 수 있다. 또한, 상기 제2 손실 함수는 학습할 데이터의 출력 클래스 중 FALSE에 해당하는 클래스에 대한 상기 글로벌 모 델의 예측값과 상기 로컬 모델의 예측값의 손실을 포함하고, 학습할 데이터의 출력 클래스 중 TRUE에 해당하는 클래스에 대한 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 손실은 0으로 설정할 수 있다. 또한, 상기 제1 손실 함수는 클라이언트 장치가 보유한 데이터의 정답값과 상기 로컬 모델의 예측값에 대한 크 로스 엔트로피 함수를 포함하고, 상기 제2 손실 함수는 상기 글로벌 모델의 예측값과, 로컬 모델의 예측값의 확 률에 대한 크로스 엔트로피 함수를 포함할 수 있다. 또한, 상기 로컬 모델의 손실 함수는 상기 글로벌 모델의 반영 정도를 나타내는 가중치를 상기 제2 손실 함수에 가한 값과 상기 제1 손실 함수의 합으로 구성될 수 있다. 또한, 상기 가중치는 0 보다 크거나 같고 1보다 작거나 같은 범위의 실수값으로 설정될 수 있다. 또한, 상기 예측값은 글로벌 모델 또는 로컬 모델의 출력값에 logit 함수 및 softmax 함수를 통과시켜 출력되는 확률값으로 구성될 수 있다. 일 실시예에 따른 중앙 서버 및 복수의 클라이언트 장치가 수행하는 연합 학습 방법은 중앙 서버가 글로벌 모델 의 글로벌 파라미터를 각 클라이언트 장치에 전송하는 단계; 복수의 클라이언트 장치 각각이 글로벌 모델의 예 측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 손실 함수(loss function)에 가해 상기 로컬 모델을 학습시킴으로써 학습된 로컬 파라미터를 상기 중앙 서버에 전송하는 단계; 및 중앙 서버가 각 클라 이언트 장치로부터 학습된 로컬 파라미터를 수신하여 상기 글로벌 모델을 업데이트하는 단계를 포함할 수 있다. 또한, 상기 복수의 클라이언트 장치는 상기 글로벌 파라미터를 유지한 채 동작하는 글로벌 모델; 및 자신이 보 유한 데이터를 사용해 상기 글로벌 파라미터를 갱신한 로컬 파라미터를 생성하는 로컬 모델을 저장할 수 있다.또한, 상기 로컬 모델의 손실 함수는 자신이 보유한 데이터의 정답값과 상기 로컬 모델의 예측값의 차이가 작아 지도록 하는 제1 손실 함수; 및 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 차이가 작아지도록 하 는 제2 손실 함수를 포함할 수 있다. 또한, 상기 제2 손실 함수는 학습할 데이터의 출력 클래스 중 FALSE에 해당하는 클래스에 대한 상기 글로벌 모 델의 예측값과 상기 로컬 모델의 예측값의 손실을 포함하고, 학습할 데이터의 출력 클래스 중 TRUE에 해당하는 클래스에 대한 상기 글로벌 모델의 예측값과 상기 로컬 모델의 예측값의 손실은 0으로 설정할 수 있다. 또한, 상기 제1 손실 함수는 클라이언트 장치가 보유한 데이터의 정답값과 상기 로컬 모델의 예측값에 대한 크 로스 엔트로피 함수를 포함하고, 상기 제2 손실 함수는 상기 글로벌 모델의 예측값과, 로컬 모델의 예측값의 확 률에 대한 크로스 엔트로피 함수를 포함할 수 있다. 또한, 상기 로컬 모델의 손실 함수는 상기 글로벌 모델의 반영 정도를 나타내는 가중치를 상기 제2 손실 함수에 가한 값과 상기 제1 손실 함수의 합으로 구성될 수 있다. 또한, 상기 가중치는 0 보다 크거나 같고 1보다 작거나 같은 범위의 실수값으로 설정될 수 있다. 또한, 상기 예측값은 글로벌 모델 또는 로컬 모델의 출력값에 logit 함수 및 softmax 함수를 통과시켜 출력되는 확률값으로 구성될 수 있다. 일 실시예에 따른 컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서, 글로벌 모델의 글로벌 파 라미터를 획득하는 단계; 글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실(los s)을 손실 함수(loss function)에 가해 상기 로컬 모델을 학습하는 단계; 및 학습된 로컬 파라미터를 중앙 서버 에 전송하는 단계의 연합 학습 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함할 수 있다. 일 실시예에 따른 컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서, 글로벌 모델의 글로벌 파라미터를 획득하는 단계; 글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이에 대한 손실 (loss)을 손실 함수(loss function)에 가해 상기 로컬 모델을 학습하는 단계; 및 학습된 로컬 파라미터를 중앙 서버에 전송하는 단계의 연합 학습 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함할 수 있다."}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 글로벌 모델의 예측값과 클라이언트 장치가 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 로컬 모델의 학습에 사용되는 손실 함수(loss function)에 반영하여, 각 클라이언트 장치의 로컬 모델들이 글로벌 모델을 기준으로 학습의 방향성을 따르도록 하여 포게팅 문제를 방지할 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 다 양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명의 범주 는 청구항에 의해 정의될 뿐이다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명은 실제로 필요한 경우 외에 는 생략될 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기능을 고려하여 정의된 용어들로서 이 는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도면에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다른 구현들에서는 상세한 설명 의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다. 또한 본 발명의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 본 발명의 기능 블록 중 하나 이상은 동일 기능을 실행하는 다양한 하 드웨어 및 소프트웨어 구성의 조합일 수 있다. 또한 어떤 구성 요소들을 포함한다는 표현은 개방형의 표현으로서 해당 구성 요소들이 존재하는 것을 단순히 지 칭할 뿐이며, 추가적인 구성 요소들을 배제하는 것으로 이해되어서는 안 된다. 나아가 어떤 구성 요소가 다른 구성 요소에 연결되어 있다거나 접속되어 있다고 언급될 때에는, 그 다른 구성 요소에 직접적으로 연결 또는 접속되어 있을 수도 있지만, 중간에 다른 구성 요소가 존재할 수도 있다고 이해되 어야 한다. 또한 '제1, 제2' 등과 같은 표현은 복수의 구성을 구분하기 위한 용도로만 사용된 표현으로써, 구성들 사이의 순서나 기타 특징들을 한정하지 않는다. 이하 사용되는 '…부', '…기' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하 드웨어나 소프트웨어, 또는, 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 도 1은 연합 학습 과정에서 발생 가능한 문제점을 설명하기 위한 예시도이다. 일반적으로 연합 학습에 사용되는 각 클라이언트 장치의 실제 데이터셋은 수, 종류, 분포 등이 서로 상이 한 경우가 대부분이다. 이러한 경우, 각 클라이언트 장치는 자신이 보유한 데이터만으로 학습하기 때문에, 개별적으로 학습된 파라미터들은 학습 방향성에 대한 기준이 없는 상태로 값이 갱신될 수 있다. 때문에, 도 1(a)를 참조하면, 각 클라이언트 장치가 개별적으로 생성한 각 로컬 파라미터는 모델이 예측값 을 도출하는 방향에 대한 편차가 발생할 가능성이 높고, 중앙 서버가 이러한 로컬 파라미터들을 취합하여 글로벌 모델을 업데이트하는 경우, 글로벌 모델 역시도 학습 방향성을 잃게 되는 포게팅(ex. catastrophic forgetting) 문제가 발생할 수 있다. 이에 따라, 본 문서의 실시예는 도 1(b)와 같이, 각 클라이언트 장치의 로컬 모델들이 글로벌 모델을 기준 으로 학습의 방향성을 따라 파라미터를 학습하도록 하는 방안을 제시하고자 한다. 도 2는 본 발명의 일 실시예에 따른 연합 학습 시스템의 구성도이다. 도 2를 참조하면, 일 실시예에 따른 연합 학습 시스템은 중앙 서버 및 복수의 클라이언트 장치를 포함할 수 있다. 중앙 서버 및 클라이언트 장치는 메모리 및 프로세서를 포함하는 컴퓨팅 장치로서, 메모리에 저장된 명령어와 프로세서의 연산에 의해 전반적인 동작이 수행될 수 있다. 중앙 서버 및 클라이언트 장치는 연합 학습(Federated Learning)을 수행하기 위해 동일한 구조로 설 계된 인공지능 신경망 모델을 저장할 수 있다. 이하, 본 문서의 실시예에 따라 연합 학습에 사용되는 인공지능 신경망 모델을 '연합 학습 모델'로 지칭하기로 한다. 또한, '연합 학습 모델'이 저장된 장치를 구분하여 설명이 필요한 경우, 중앙 서버에 저장된 연합 학습 모델을 '글로벌 모델', 클라이언트 장치에 저장된 연합 학습 모델을 '로컬 모델'로 구분하여 지칭하 기로 한다. 또한, '글로벌 모델'에 적용된 파라미터를 '글로벌 파라미터', '로컬 모델'에 적용된 파라미터를 ' 로컬 파라미터'로 구분하여 지칭하기로 한다. 도 3은 본 발명의 일 실시예에 따라 연합 학습 시스템을 구성하는 중앙 서버 및 클라이언트 장치(20 0)가 연합 학습 모델을 학습시키는 개괄적인 동작의 예시도이다. 먼저, 중앙 서버는 글로벌 모델에 설정되어 있는 글로벌 파라미터 값을 각 클라이언트 장치에 전송할 수 있다. 다음으로, 각 클라이언트 장치는 자신이 보유한 데이터(D1, D2, ..., Dn)를 사용해 로컬 모델을 학습시키 고, 학습된 로컬 모델의 로컬 파라미터를 중앙 서버에 전송할 수 있다. 이후, 중앙 서버는 각 클라이언트 장치가 학습한 로컬 모델의 파라미터를 취합하여 글로벌 모델의 파 라미터를 업데이트 할 수 있다. 이처럼, 중앙 서버가 클라이언트 장치에 파라미터를 전송하여 새롭게 학습된 파라미터를 취합한 후 모델을 업데이트하는 일련의 과정을 연합 학습의 한 라운드로 이해할 수 있다. 연합 학습의 라운드는 설계에 따 라 복수의 라운드로 진행될 수 있으며, 최종 라운드가 진행된 이후 업데이트된 글로벌 모델의 파라미터가 최종 적인 연합 학습 모델의 파라미터로 결정될 수 있다. 이때 중앙 서버는 소정의 방식(ex. FedAvg, FedSGD, FedMA 등)에 따라, 연합 학습의 라운드 마다 복수의 클라이언트 장치 중 일부 클라이언트 장치를 선별하여 글로벌 파라미터를 전송할 수 있다. 이때 중앙 서버는 소정의 방식(ex. FedAvg, FedSGD, FedMA 등)에 따라, 클라이언트 장치로부터 취합 된 로컬 파라미터를 조합하여 글로벌 모델의 파라미터를 업데이트할 수 있다. 한편, 연합 학습에서 각 클라이언트 장치가 보유한 데이터의 수, 종류, 분포 등이 서로 상이한 경우 포게 팅 문제가 발생할 수 있다. 이러한 점을 해결하기 위해, 본 문서의 실시예에 따른 연합 학습 시스템은 각 클라이언트 장치 단에서, 글로벌 모델의 예측값과 로컬 모델의 예측값의 차이에 대한 손실을 손실 함수에 가해 로컬 모델을 학습시키는 방안을 제시한다. 도 4는 본 문서의 실시예에 따른 각 클라이언트 장치가 로컬 모델을 학습시키는 동작을 구체화한 예시도이 다. 도 4는 연합 학습 모델이 출력한 값을 출력 벡터(ex. logit 함수) 및 확률 벡터(ex. softmax 함수)로 변환 된 확률값을 모델의 예측값으로 구성한 것을 예시하고 있다. 한편, 도 4에 도시된 모델 출력값의 변환 구성은 예시일 뿐, 본 문서의 실시예가 이러한 구성에 한정되는 것은 아니다. 도 4를 참조하면, 클라이언트 장치는 글로벌 모델의 학습 방향을 기준으로 로컬 모델을 학습시키기 위해, 글로벌 모델 및 로컬 모델을 각각 저장할 수 있다. 클라이언트 장치는 중앙 서버로부터 수신한 글로벌 파라미터를 유지한 채 동작하는 글로벌 모델을 저 장할 수 있다. 클라이언트 장치는 자신이 보유한 데이터를 사용해 중앙 서버로부터 수신한 글로벌 파라미터를 갱신 하여 새로운 로컬 파라미터를 생성하는 로컬 모델을 저장할 수 있다. 일 예로, 로컬 모델의 학습에 사용되는 손실 함수는 클라이언트 장치가 보유한 데이터 자체를 학습하기 위 한 제1 손실 함수와, 글로벌 모델의 학습 방향성을 유지하기 위한 제2 손실 함수로 구성될 수 있다. 제1 손실 함수는 클라이언트 장치가 보유한 데이터의 정답값과 로컬 모델의 예측값의 차이가 작아지도록 하는 제1 손실을 포함할 수 있다. 예를 들어, 제1 손실 함수는 클라이언트 장치가 보유한 데이터의 정답값 과 상기 로컬 모델의 예측값에 대한 크로스 엔트로피 함수로 구성될 수 있다. 제2 손실 함수는 글로벌 모델의 예측값과 로컬 모델의 예측값의 차이가 작아지도록 하는 제2 손실을 포함할 수 있다. 예를 들어, 제2 손실 함수는 글로벌 모델의 예측값과, 로컬 모델의 예측값에 대한 크로스 엔트로피 함수 로 구성될 수 있다. 이때 제2 손실 함수는 학습할 데이터의 정답 클래스를 제외한 나머지 클래스에 대한 손실만을 고려하는 방향으 로 학습되도록 구성될 수 있다. 예를 들어, 도 4를 참조할 때, 학습할 데이터의 출력 클래스는 '0, 1, 2, 3, 4, 5, 6, 7, 8, 9'로 10가지인 환경에서, 정답 클래스가 '3'인 'Sample x'를 학습할 차례라고 가정한다. 이 경우, 제2 손실 함수는 TRUE에 해당하는 클래스인 '3'를 제외하고, FALSE에 해당하는 클래스인 '0, 1, 2, 4, 5, 6, 7, 8, 9' 에 해당하는 클래스에 대해서만 글로벌 모델의 예측값과 로컬 모델의 예측값의 손실을 최소화하는 방 향으로 학습하도록 구성될 수 있다. 이를 위해, 제2 손실 함수는 학습할 데이터의 출력 클래스 중 TRUE에 해당하는 클래스에 대한 글로벌 모델의 예 측값과 로컬 모델의 예측값의 손실은 '0' 으로 설정되고, 학습할 데이터의 출력 클래스 중 FALSE에 해당하는 클 래스에 대한 글로벌 모델의 예측값과 로컬 모델의 예측값에 대해서는 크로스 엔트로피 함수로 구성되도록 할 수 있다. 이 경우, 제2 손실 함수 는 소프트맥스를 이용한 글로벌 모델의 예측 확률 과, 소프트맥스를 이용 한 로컬 모델의 예측 확률 에 크로스 엔트로피를 적용하여 아래 수학식 1과 같이 표현할 수 있다. 수학식 1 에서 대문자 'C'는 클래스의 개수, 소문자 'c'는 학습할 데이터의 클래스를 의미하며, 클래스 'c'가 정답 'y'에 해당하는 경우는 크로스 엔프로피 값이 반영되지 않도록 시그마 함수가 구성될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 로컬 모델의 손실 함수는 '손실 함수 = 제1 손실 함수 + 제2 손실 함수x가중치' 로 구성할 수 있다. 즉, 로컬 모델의 손실 함수는 글로벌 모델의 반영 정도를 나타내는 가중치를 제2 손실 함수에 가한 값과 제1 손실 함수의 합으로 구성될 수 있다. 이때, 가중치는 0 보다 크거나 같고, 1보다 작거나 같은 실수값으로 설정될 수 있다. 여기서, 가중치를 1에 가깝게 설정할수록 로컬 파라미터는 글로벌 모델의 학습 방향을 따를 수 있고, 가 중치를 0에 가깝게 설정할수록 로컬 파라미터는 클라이언트 장치가 가진 데이터의 방향성을 따르도록 학습 될 수 있다. 도 5는 본 발명의 일 실시예에 따른 연합 학습 방법의 흐름도이다. 도 5에 따른 연합 학습 방법의 각 단계는 도 1 내지 도 4를 통해 설명된 연합 학습 시스템의 중앙 서버 와 클라이언트 장치에 의해 수행될 수 있으며, 각 단계를 설명하면 다음과 같다. S1010 단계에서, 중앙 서버는 글로벌 모델의 글로벌 파라미터를 각 클라이언트 장치에 전송할 수 있 다. S1020 단계에서, 각 클라이언트 장치는 글로벌 모델의 예측값과 자신이 보유한 로컬 모델의 예측값의 차이 에 대한 손실을 손실 함수에 가해 상기 로컬 모델을 학습시킴으로써 학습된 로컬 파라미터를 상기 중앙 서버 에 전송할 수 있다. S1030 단계에서, 중앙 서버는 각 클라이언트 장치로부터 학습된 로컬 파라미터를 수신하여 상기 글로 벌 모델을 업데이트할 수 있다. 한편, 도 5에 도시된 단계 외에도, 상술한 도 1 내지 도 4과 함께 설명된 내용을 수행하는 실시예들을 다양하게 구성함에 따라, 도 5에 도시된 단계에 더하여 적용 가능한 동작을 수행하는 새로운 단계가 부가될 수 있다. 한 편, 추가적인 단계의 구성 및 각 단계의 주체인 구성 요소들이 해당 단계를 실시하기 위한 동작은 도 1 내지 도 4에서 설명하였으므로 중복된 설명은 생략한다. 도 6은 본 발명의 일 실시예에 따른 연합 학습 시스템에 의해 생성된 연합 학습 모델(FedNTD)과 기존의 연 합 학습 알고리즘에 의해 생성된 연합 학습 모델을 복수의 클라이언트 장치에서 동일한 데이터셋을 적용하 여 측정한 정확도의 비교표이다. 도 6을 참조하면, 's'는 각 클라이언트 장치가 가지는 데이터의 불균형도를 설정하는 변수이다. 도 6에 도 시된 변수에 따라 설정된 다양한 환경에서 본 발명 실시예(FedNTD)의 정확도는 기존의 알고리즘에 의해 생성된 연합 학습 모델의 정확도에 비해 크게 향상되었음을 확인할 수 있다. 상술한 실시예에 의하면, 글로벌 모델의 예측값과 클라이언트 장치가 보유한 로컬 모델의 예측값의 차이에 대한 손실(loss)을 로컬 모델의 학습에 사용되는 손실 함수(loss function)에 반영하여, 각 클라이언트 장치 의 로컬 모델들이 글로벌 모델을 기준으로 학습의 방향성을 따르도록 하여 포게팅 문제를 방지할 수 있다.상술한 본 발명의 실시예들은 다양한 수단을 통해 구현될 수 있다. 예를 들어, 본 발명의 실시예들은 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 프로세서, 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 실시예들에 따른 방법은 이상에서 설명된 기능 또는 동작 을 수행하는 모듈, 절차 또는 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드 등이 기록된 컴퓨터 프로그램 은 컴퓨터 판독 가능 기록 매체 또는 메모리 유닛에 저장되어 프로세서에 의해 구동될 수 있다. 메모리 유닛은 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 프로세서와 데이터를 주고받을 수 있다. 또한 본 발명에 첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행될 수도 있다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능 한 데이터 프로세싱 장비의 인코딩 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 인코딩 프로세서를 통해 수행되는 그 인스트럭션들이 블록도의 각 블록 또는 흐름도의 각 단계 에서 설명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방법으로 기 능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가 능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메 모리에 저장된 인스트럭션들은 블록도의 각 블록 또는 흐름도의 각 단계에서 설명된 기능을 수행하는 인스트럭 션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데 이터 프로세싱 장비 상에서 일련의 동작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또 는 기타 프로그램 가능한 데이터 프로세싱 장비를 수행하는 인스트럭션들은 블록도의 각 블록 및 흐름도의 각 단계에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 더불어 각 블록 또는 각 단계는 특정된 논리적 기능을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또한, 몇 가지 대체 실시예들에서는 블록들 또는 단계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 또는 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들 또는 단계 들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다."}
{"patent_id": "10-2022-0075187", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이와 같이, 본 발명이 속하는 기술분야의 당업자는 본 발명이 그 기술적 사상이나 필수적 특징을 변경하지 않고 서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범위는 상세한 설명보 다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 등가개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0075187", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 연합 학습 과정에서 발생 가능한 문제점을 설명하기 위한 예시도이다. 도 2는 본 발명의 일 실시예에 따른 연합 학습 시스템의 구성도이다. 도 3은 본 발명의 일 실시예에 따라 연합 학습 시스템을 구성하는 중앙 서버 및 클라이언트 장치가 연합 학습 모델을 학습시키는 개괄적인 동작의 예시도이다. 도 4는 본 문서의 실시예에 따른 각 클라이언트 장치가 로컬 모델을 학습시키는 동작을 구체화한 예시도이 다. 도 5는 본 발명의 일 실시예에 따른 연합 학습 방법의 흐름도이다. 도 6은 본 발명의 일 실시예에 따른 연합 학습 시스템에 의해 생성된 연합 학습 모델(FedNTD)과 기존의 연합 학 습 알고리즘에 의해 생성된 연합 학습 모델을 복수의 클라이언트 장치에서 동일한 데이터셋을 적용하여 측정한 정확도의 비교표이다."}
