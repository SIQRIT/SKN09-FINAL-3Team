{"patent_id": "10-2022-0053253", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0153626", "출원번호": "10-2022-0053253", "발명의 명칭": "오토 포커스 조절 방법 및 이를 이용한 카메라 장치", "출원인": "한화비전 주식회사", "발명자": "김대봉"}}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서와, 상기 프로세서에 의해 실행 가능한 인스트럭션들을 저장하는 메모리를 포함하는 카메라 장치는, 피사체의 영상을 캡쳐하는 이미지 센서;상기 캡쳐된 영상에 포함된 객체를 식별하는 객체 식별부;상기 식별된 객체가 상기 캡쳐된 영상 내에서 차지하는 비율에 기초하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출하는 거리 산출부; 및상기 산출된 거리에 대응되는 렌즈의 포커스 위치를 적어도 포함하는 포커스 범위 내에서 상기 렌즈를 이동시키면서, 기준값이 가장 큰 최적 포커스 위치를 탐색하는 제어부(controller)를 포함하는, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 기준값은 콘트라스트 데이터 또는 에지 데이터인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 카메라 장치의 사양 정보를 저장하는 저장부를 더 포함하고,상기 거리 산출부는상기 사양 정보에 포함된 세로 방향 화각을 취득하고,상기 취득된 세로 방향 화각, 상기 객체의 크기비율 및 상기 객체의 물리적인 크기를 이용하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출하되,상기 객체의 크기비율은, 상기 캡쳐된 영상의 세로 방향 크기에 대한, 상기 객체의 전체 또는 상기 객체의 부분이 갖는 세로 방향 크기의 비율인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 객체는 사람이고 상기 객체의 부분은 얼굴인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 객체는 자동차이고 상기 객체의 부분은 차량 번호판인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서, 상기 제어부는상기 저장부에 저장된 상기 사양 정보에 포함되는 로커스 데이터를 판독하고, 상기 로커스 데이터를 참조하여상기 산출된 거리로부터 상기 포커스 범위를 결정하되,상기 로커스 데이터는 특정 줌 배율에서 피사체와의 거리에 따른 포커스 위치로 표현되는, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2023-0153626-3-제1항에 있어서,상기 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 선택된 객체는 상기 복수의 객체 중에서 상기 캡쳐된 영상의 중심에 가장 가까운 객체인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 복수의 객체는 객체 종류가 상이한 2이상의 객체를 포함하고,상기 선택된 객체는 상기 2이상의 객체 중에서 전체 또는 부분의 크기가 정형화된 객체인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 객체의 식별은 딥러닝 기반의 사물 탐지 알고리즘에 의해 이루어지고, 그 식별 결과 상기 객체의 식별에대한 정확도가 얻어지는데,상기 선택된 객체는 상기 복수의 객체 중에서 상기 정확도가 보다 높은 객체인, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 제어부는상기 캡쳐된 영상 내에 윈도우를 설정하고, 상기 설정된 윈도우 내에서 상기 최적 포커스 위치를 탐색하는데,상기 설정되는 윈도우는 상기 선택된 객체를 중심으로 설정되는, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 객체의 식별은 딥러닝 기반의 사물 탐지 알고리즘에 의해 이루어지고, 그 식별 결과 상기 객체의 식별에대한 정확도가 얻어지는데,상기 정확도가 높을수록 상기 포커스 범위는 좁게 설정되고, 상기 정확도가 낮을수록 상기 포커스 범위는 넓게설정되는, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 제어부는 상기 캡쳐된 영상 내에 윈도우를 설정하고, 상기 설정된 윈도우 내에서 상기 최적 포커스 위치를탐색하는데,상기 식별된 객체의 움직임이 있는 경우에, 상기 객체의 움직임을 고려하여 상기 윈도우를 설정하는, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 객체의 움직임이 상기 이미지 센서로부터 가까워지거나 멀어지는 움직임이면 상기 윈도우의 크기를 변경하는, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,공개특허 10-2023-0153626-4-상기 객체의 움직임이 상기 캡쳐된 영상 내에서 다른 위치로 이동하는 움직임이면 상기 움직임에 따른 예측된위치에 상기 윈도우를 이동하여 설정하는, 카메라 장치."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "프로세서와, 상기 프로세서에 의해 실행 가능한 인스트럭션들을 저장하는 메모리를 포함하는 카메라 장치에서,프로세서의 제어에 따라 인스트럭션들에 의해 수행되는 오토 포커스 조절 방법은,피사체의 영상을 캡쳐하는 단계;상기 캡쳐된 영상에 포함된 객체를 식별하는 단계;상기 식별된 객체가 상기 캡쳐된 영상 내에서 차지하는 비율에 기초하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출하는 단계;상기 산출된 거리에 대응되는 렌즈의 포커스 위치를 적어도 포함하는 포커스 범위 내에서 상기 렌즈를 이동시키는 단계; 및상기 렌즈의 이동 중에 기준값이 가장 큰 최적 포커스 위치를 탐색하는 단계를 포함하는, 오토 포커스 조절 방법."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 카메라 장치의 사양 정보에 포함된 세로 방향 화각을 취득하는 단계; 및상기 취득된 세로 방향 화각, 상기 객체의 크기비율 및 상기 객체의 물리적인 크기를 이용하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출하는 단계를 더 포함하되,상기 객체의 크기비율은, 상기 캡쳐된 영상의 세로 방향 크기에 대한, 상기 객체의 전체 또는 상기 객체의 부분이 갖는 세로 방향 크기의 비율인, 오토 포커스 조절 방법."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체이고, 상기 선택된 객체는 상기 복수의객체 중에서 상기 캡쳐된 영상의 중심에 가장 가까운 객체인, 오토 포커스 조절 방법."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서,상기 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체이고, 상기 복수의 객체는 객체 종류가상이한 2이상의 객체를 포함하며, 상기 선택된 객체는 상기 2이상의 객체 중에서 전체 또는 부분의 크기가 정형화된 객체인, 오토 포커스 조절 방법."}
{"patent_id": "10-2022-0053253", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항에 있어서,상기 객체의 식별은 딥러닝 기반의 사물 탐지 알고리즘에 의해 이루어지고, 그 식별 결과 상기 객체의 식별에대한 정확도가 얻어지는데,상기 캡쳐된 영상에 포함된 복수의 객체 중에서, 상기 정확도가 보다 높은 객체가 상기 식별된 객체로선택되는, 오토 포커스 조절 방법."}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "프로세서와, 상기 프로세서에 의해 실행 가능한 인스트럭션들을 저장하는 메모리를 포함하는 카메라 장치는, 피 사체의 영상을 캡쳐하는 이미지 센서와, 상기 캡쳐된 영상에 포함된 객체를 식별하는 객체 식별부와, 상기 식별 된 객체가 상기 캡쳐된 영상 내에서 차지하는 비율에 기초하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출하는 거리 산출부와, 상기 산출된 거리에 대응되는 렌즈의 포커스 위치를 적어도 포함하는 포커스 범위 내에 서 상기 렌즈를 이동시키면서, 기준값이 가장 큰 최적 포커스 위치를 탐색하는 제어부를 포함한다."}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 오토 포커스 조절 기술에 관한 것으로, 더욱 상세하게는, 렌즈와 피사체 간의 거리를 추정함으로써 신속한 오토 포커스 조절이 가능한 오토 포커스 조절 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털카메라나 디지털 비디오 카메라 등으로 대표되는 전자기기에는 예를 들면 CCD(Charge Coupled Device)나 CMOS(Complementary Metal-Oxide Semiconductor) 이미지 센서 등의 촬상 장치가 탑재된다. 촬상 장치는 자동으 로 초점 조정을 하는 오토 포커스(AF) 기능을 가진다. 자동 초점에서는 렌즈를 구동함으로써 초점이 적절하게 조정되고, 이렇게 초점이 조정된(focused) 화상을 취득하는 것이 가능하게 된다. 그러나 종래의 자동 초점에서는 대상이 되는 피사체에 의해 반드시 사용자가 희망하는 부분에 자동으로 초점 조 정이 되지 못한다. 이 경우, 촬영 시에 사용자가 초점 조정을 위한 조작을 하지 않으면 안 되기 때문에 사용자 는 촬영 자체에 전념하여 촬영할 수 없게 된다. 뿐만 아니라 이러한 오토 포커스 기능을 사용하기 위해서는 렌즈의 위치를 가변함으로써 렌즈와 이미지센서 간 의 거리를 조정하고 피사체의 이미지의 포커싱을 수행해야 하므로, 최적의 포커스 위치를 찾기 위한 시간 지연 이 발생하게 된다. 도 1에 도시된 바와 같이, 종래 기술에 따른 카메라는 렌즈와, 상기 렌즈를 투과한 피사체의 이미지가 촬상 되는 이미지 센서와, 상기 이미지 센서에 촬상된 이미지에 대한 정보를 처리하여 상기 이미지의 포커싱 정도를 나타내는 선명도를 생성하는 이미지 처리부와, 상기 이미지 처리부의 선명도에 따라 상기 렌즈 의 적절한 위치를 산출하는 제어부와, 상기 제어부에서 산출한 위치로 상기 렌즈를 이동시키기 위 한 렌즈구동 수단을 포함한다. 구체적으로, 제어부는 사용자의 카메라 조작 등에 의하여 오토 포커스 명령이 입력되면, 렌즈를 이미지 센서와 가장 가까운 위치(피사체와 가장 먼 위치)인 최원거리위치 또는 이미지 센서와 가장 먼 위치(피사체와 가장 가까운 위치)인 최근거리위치 중 어느 한 지점인 초기위치로 렌즈를 이동시켜 렌즈의 위치를 초기한 다. 그 후에 제어부는 렌즈를 일정한 간격으로 이동시키면서 각 렌즈위치에서의 선명도(예: 콘트라스 트 데이터)를 계산하고, 그 값 중 최대 선명도를 갖는 렌즈의 위치를 결정한다. 이후에, 제어부는 다시 렌즈를 상기 최대 선명도를 갖는 지점 인근으로 렌즈를 이동시키고, 상기 최대 선명도를 갖는 지점 인근의 소정 범위에서 상기 렌즈를 짧게 이동시키면서 각 렌즈위치에서의 선명도를 계산하고, 그 값 중 최대 선명도를 갖는 지점을 최종적으로 결정한다. 마지막으로, 제어부는 상기 렌즈를 상기 최대 선명도를 갖는 지점으로 이동시킨 후 오토 포커싱을 완료한 다. 이와 같이, 종래의 오토 포커스 기능은, 렌즈의 위치가 가변되는 영역 모두에 대하여 선명도를 계산하여야 하므 로 오토 포커싱에 소요되는 시간이 길어지게 되고, 이러한 소요 시간을 줄이기 위해 신속한 오토 포커싱을 수행 하는 경우에는 그 정확도가 낮아진다는 문제가 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 일본 특허공개공보 2009-31760호 (2009.2.12 공개)"}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는, 인공 지능 딥러닝 기반의 사물 검출 기술을 통해, 콘트라스트 기반의 오토 포커스 성능을 향상시키고자 하는 것이다. 본 발명이 이루고자 하는 다른 기술적 과제는, 검출된 객체 정보 및 렌즈/센서 정보를 활용하여 피사체와 렌즈 간의 거리를 추정함으로써 오토 포커스 속도를 향상시키고자 하는 것이다.본 발명이 이루고자 하는 또다른 기술적 과제는, 오토 포커싱 동작 중에 객체 검출 정보를 활용하여 오토 포커 스 성능을 한층 더 향상시키고자 하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위한 본 발명의 일 실시예에 따른 카메라 장치는, 프로세서와, 상기 프로세서에 의해 실행 가능한 인스트럭션들을 저장하는 메모리로 구성되며, 피사체의 영상을 캡쳐하는 이미지 센서; 상기 캡쳐된 영상에 포함된 객체를 식별하는 객체 식별부; 상기 식별된 객체가 상기 캡쳐된 영상 내에서 차지하는 비 율에 기초하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출하는 거리 산출부; 및 상기 산출된 거리에 대응되는 렌즈의 포커스 위치를 적어도 포함하는 포커스 범위 내에서 상기 렌즈를 이동시키면서, 기준값이 가장 큰 최적 포커스 위치를 탐색하는 제어부(controller)를 포함한다. 상기 기준값은 콘트라스트 데이터 또는 에지 데이터이다. 상기 카메라 장치는, 상기 카메라 장치의 사양 정보를 저장하는 저장부를 더 포함하고, 상기 거리 산출부는, 상기 사양 정보에 포함된 세로 방향 화각을 취득하고, 상기 취득된 세로 방향 화각, 상기 객체의 크기비율 및 상기 객체의 물리적인 크기를 이용하여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출하되, 상기 객체의 크기비율은, 상기 캡쳐된 영상의 세로 방향 크기에 대한, 상기 객체의 전체 또는 상기 객체의 부분이 갖는 세로 방향 크기의 비율이다. 상기 객체는 사람이고 상기 객체의 부분은 얼굴이다. 상기 객체는 자동차이고 상기 객체의 부분은 차량 번호판이다. 상기 제어부는, 상기 저장부에 저장된 상기 사양 정보에 포함되는 로커스(locus) 데이터를 판독하고, 상기 로커 스 데이터를 참조하여 상기 산출된 거리로부터 상기 포커스 범위를 결정하되, 상기 로커스 데이터는 특정 줌 배 율에서 피사체와의 거리에 따른 포커스 위치로 표현된다. 상기 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체이다. 상기 선택된 객체는 상기 복수의 객체 중에서 상기 캡쳐된 영상의 중심에 가장 가까운 객체이다. 상기 복수의 객체는 객체 종류가 상이한 2이상의 객체를 포함하고, 상기 선택된 객체는 상기 2이상의 객체 중에 서 전체 또는 부분의 크기가 정형화된 객체이다. 상기 객체의 식별은 딥러닝 기반의 사물 탐지 알고리즘에 의해 이루어지고, 그 식별 결과 상기 객체의 식별에 대한 정확도가 얻어지는데, 상기 선택된 객체는 상기 복수의 객체 중에서 상기 정확도가 보다 높은 객체이다. 상기 제어부는, 상기 캡쳐된 영상 내에 윈도우를 설정하고, 상기 설정된 윈도우 내에서 상기 최적 포커스 위치 를 탐색하는데, 상기 설정되는 윈도우는 상기 선택된 객체를 중심으로 설정된다. 상기 객체의 식별은 딥러닝 기반의 사물 탐지 알고리즘에 의해 이루어지고, 그 식별 결과 상기 객체의 식별에 대한 정확도가 얻어지는데, 상기 정확도가 높을수록 상기 포커스 범위는 좁게 설정되고, 상기 정확도가 낮을수 록 상기 포커스 범위는 넓게 설정된다. 상기 제어부는 상기 캡쳐된 영상 내에 윈도우를 설정하고, 상기 설정된 윈도우 내에서 상기 최적 포커스 위치를 탐색하는데, 상기 식별된 객체의 움직임이 있는 경우에, 상기 객체의 움직임을 고려하여 상기 윈도우를 설정한 다. 상기 객체의 움직임이 상기 이미지 센서로부터 가까워지거나 멀어지는 움직임이면 상기 윈도우의 크기를 변경한 다. 상기 객체의 움직임이 상기 캡쳐된 영상 내에서 다른 위치로 이동하는 움직임이면 상기 움직임에 따른 예측된 위치에 상기 윈도우를 이동하여 설정한다. 상기 기술적 과제를 달성하기 위한 본 발명의 일 실시예에 따른 카메라 장치는, 프로세서와, 상기 프로세서에 의해 실행 가능한 인스트럭션들을 저장하는 메모리를 포함하며, 상기 카메라 장치에서, 프로세서의 제어에 따라인스트럭션들에 의해 수행되는 오토 포커스 조절 방법은, 피사체의 영상을 캡쳐하는 단계; 상기 캡쳐된 영상에 포함된 객체를 식별하는 단계; 상기 식별된 객체가 상기 캡쳐된 영상 내에서 차지하는 비율에 기초하여 상기 카 메라 장치와 상기 식별된 객체와의 거리를 산출하는 단계; 상기 산출된 거리에 대응되는 렌즈의 포커스 위치를 적어도 포함하는 포커스 범위 내에서 상기 렌즈를 이동시키는 단계; 및 상기 렌즈의 이동 중에 기준값이 가장 큰 최적 포커스 위치를 탐색하는 단계를 포함한다. 상기 오토 포커스 조절 방법은, 상기 카메라 장치의 사양 정보에 포함된 세로 방향 화각을 취득하는 단계; 및 상기 취득된 세로 방향 화각, 상기 객체의 크기비율 및 상기 객체의 물리적인 크기를 이용하여 상기 카메라 장 치와 상기 식별된 객체와의 거리를 산출하는 단계를 더 포함하되, 상기 객체의 크기비율은, 상기 캡쳐된 영상의 세로 방향 크기에 대한, 상기 객체의 전체 또는 상기 객체의 부분이 갖는 세로 방향 크기의 비율이다. 상기 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체이고, 상기 선택된 객체는 상기 복수의 객체 중에서 상기 캡쳐된 영상의 중심에 가장 가까운 객체이다. 상기 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체이고, 상기 복수의 객체는 객체 종류가 상이한 2이상의 객체를 포함하며, 상기 선택된 객체는 상기 2이상의 객체 중에서 전체 또는 부분의 크기가 정형 화된 객체이다. 상기 객체의 식별은 딥러닝 기반의 사물 탐지 알고리즘에 의해 이루어지고, 그 식별 결과 상기 객체의 식별에 대한 정확도가 얻어지는데, 상기 캡쳐된 영상에 포함된 복수의 객체 중에서, 상기 정확도가 보다 높은 객체가 상기 식별된 객체로 선택된다."}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 콘트라스트 오토 포커스 기술에서, 오토 포커스의 검색 범위를 좁혀서 오토 포커스 소요 시 간을 감소시킴과 동시에, 포커스의 부정확으로 인한 성능 저하를 감소시킬 수 있다. 또한, 본 발명에 따르면, 카메라의 설정에 사용자가 검색 범위를 선택할 수 있도록 GUI를 제공하여 사용자 편의 성을 향상시킬 수 있다. 또한, 본 발명에 따른 오토 포커스 향상 기술에 레이저와 같은 거리 측정 장치를 추가함으로써 보다 신속하고 정확한 오토 포커싱이 가능해진다."}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 이하 첨부된 도면들을 참조하여 본 발명의 일 실시예를 상세히 설명한다. 도 2는 본 발명의 일 실시예에 따른 카메라 장치의 구성을 도시한 블록도이다. 카메라 장치는 렌즈 , 이미지 센서, 이미지 처리부, 렌즈 구동부, 객체 식별부, AI 장치, 제어부 , 거리 산출부 및 저장부를 포함하여 구성될 수 있다. 제어부(controller, 150)는 카메라 장치의 다른 구성요소들의 동작을 제어하는 컨트롤러 역할을 하며, 일 반적으로 CPU(central processing unit), 마이크로프로세서(microprocessor) 등으로 구현될 수 있다. 또한, 저 장부는 제어부에서 수행된 결과를 저장하거나 제어부의 동작을 위해 필요한 데이터를 저장하는 저장 매체로서, 휘발성 메모리 또는 비휘발성 메모리로 구현될 수 있다. 렌즈는 셔터(미도시 됨)에 의해 열리거나 닫힐 수 있고, 상기 셔터가 열린 상태에서 피사체에서 반사된 광 을 유입한다. 렌즈는 포커스 조절을 위해 렌즈 구동부에 의해 소정 범위 내에서 이동(전진 또는 후진)할 수 있다. 렌즈 구동부는 일반적으로, 회전 모터, 리니어 모터 또는 다른 형태의 다양한 액츄에이 터(actuator)로 구현될 수 있다. 이미지 센서는 상기 셔터의 개방 상태에서 렌즈로 입력되는 광을 포착하여 전기적 신호로 출력하는 방식으로 영상을 캡쳐한다. 이러한 영상은 아날로그 신호 또는 디지털 신호로 표시될 수 있지만 최근에는 디지 털 신호로 표시되는 것이 일반적이다. 상기 디지털 신호는 이미지 처리부 내지 ISP(image signal processor)에 의해 전처리 된 후 제어부에 제공되며, 저장부에 일시적 또는 영구적으로 저장된다. 객체 식별부는 상기 캡쳐된 영상에 포함된 객체를 식별한다. 상기 객체(object)란 영상 내에 포함되는 사 람, 사물과 같이 배경과 구별될 수 있고 독립적인 움직임을 갖는 대상을 의미한다. 이러한 객체의 식별은 AI 장 치에 의한 딥러닝 알고리즘에 의해 이루어질 수 있다. AI 장치에 대한 보다 자세한 설명은 도 8a 및 도 8b를 참조하여 후술하기로 한다. 객체 식별부에 의해 식별된 객체는 일반적으로 객체 ID, 객체 종류, 객체 확률, 객체 크기 등에 의해 정의될 수 있다. 상기 객체 ID란 객체의 동일성 여부를 나타내는 임의의 식별자이고, 객체의 종류는 사람, 동물, 자동차 등과 같은 사람이 구별 가능한 분류(class)를 나타낸다. 또한, 객체 확률은 해당 객체가 바르게 식별되었을 정확도를 나타내는 수치이다. 예를 들어, 특정 객체의 종류가 사람 이고 객체 확률이 80%라고 하면, 해당 객체가 사람일 확률이 80%임을 의미한다. 거리 산출부는 상기 식별된 객체가 상기 캡쳐된 영상 내에서 차지하는 비율에 기초하여 상기 카메라 장치 와 상기 식별된 객체와의 거리를 산출한다. 물론, 거리 산출부는 레이저 기반의 거리 측정기와 같이 직접 적으로 상기 식별된 객체와의 거리를 측정할 수도 있다. 이하, 본 발명에서는 영상 내에서 객체가 차지하는 비 율과 같은 영상 분석만으로 거리를 산출하는 것으로 하여 설명하기로 한다. 도 3a 내지 도 3c는 카메라 장치에 의해 촬영된 영상만으로 특정 객체와의 거리를 산출하는 예들을 보여주 는 도면들이다. 이 중에서, 도 3a는 영상 내에 포함된 객체, 예를 들어 사람 전체의 크기를 기준으로 카메라 장 치와 상기 사람 간의 거리를 산출하는 예를 보여준다. 도 3a에서, 산출하고자 하는 값은 카메라 장치와 사람 간의 거리(D)이다. 여기서, 카메라 장치의 세로 방향 화각은 θ로 표시되고 상기 화각(θ)에 따른 카메라 장치에 의해 촬영 가능한 세로 방향 크기는 V로 표시된다. 또한, 전술한 객체 식별부에 의해 사람이라는 객체의 크기는 박스 형태로 표시될 수 있 는데, 이러한 객체의 세로 방향 크기를 H로 정의할 수 있다.이러한 카메라 장치의 화각(θ)은 카메라 장치의 사양 정보로부터 얻어질 수 있는데, 상기 사양 정보 는 저장부에 미리 저장되어 있을 수 있다. 이 때, 상기 촬영 가능한 세로 방향 크기(V)와 객체의 세로 방향 크기(H)(객체가 사람인 경우 사람의 키)의 비 율은, 이미지 센서에 의해 캡쳐된 영상의 세로 방향 크기에 대한 상기 영상 내에서의 객체의 크기가 갖는 비율과 동일하다고 볼 수 있다. 따라서, 영상의 세로 방향 크기를 100으로 가정하고, 이에 대한 객체의 크기가 갖는 비율을 P(%)라고 하면 수학식 1과 같은 관계가 성립한다. 수학식 1"}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "또한, 상기 거리(D)와 촬영 가능한 세로 방향 크기(V) 간에는 다음의 수학식 2가 만족된다. 여기서, θ는 카메 라 장치의 세로 방향 화각, 보다 정확히는 특정 배율에서의 세로 방향 화각을 의미한다. 수학식 2"}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "따라서, 수학식 1 및 수학식 2를 결합하면 최종적으로 구하고자 하는 거리(D)는 다음의 수학식 3과 같이 산출된 다. 수학식 3"}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3에서 화각(θ)는 카메라 장치의 사양에서 알 수 있고, 객체의 크기 비율(P)는 이미지 센서에 의해 캡쳐된 영상을 확인하면 간단히 알 수 있다. 예를 들어, 캡쳐된 영상의 세로 픽셀 개수가 1080개이고, 그 안에서 특정 객체가 차지하는 세로 방향의 픽셀 개수가 216개이면, 객체의 크기 비율(P)은 20이 될 것이다. 또한, 상기 화각(θ)을 30°라고 가정하면, 사람의 키에 해당하는 H는 대략 1m~2m라고 볼 수 있으므로, D의 최 소값은 9.25m이고 D의 최대값은 18.5m가 될 것이다. 이와 같이 단순한 계산을 통해서도 객체와의 거리가 전체의 거리범위(0~infinity)가 아니라 일정 범위 내로 축 소되었으므로 이를 기준점으로 하여 최적 포커스 위치를 탐색한다면 오토 포커스 동작의 시간이 분명히 감소될 것이다. 또한, 객체의 위치 및 렌즈 왜곡 정보 등을 추가적으로 반영하여 보다 정확한 계산을 할 수도 있고, 화각이 바 뀌는 줌 카메라인 경우에는 각 배율에 따라 객체 크기별 거리값을 테이블로 저장하여 신속히 상기 거리를 산출 할 수도 있을 것이다. 다만, 이러한 거리 산출은 오토 포커스 작동시 포커스 검색 범위를 좁히는 정도로도 충분 하므로 그 정확도가 완전하지 않더라도 충분히 활용 가능하다. 도 3a에서는 사람의 키와 같은 객체 전체의 크기를 기준으로 카메라 장치와 객체간의 거리(D)를 산출 하였다. 그러나, 전술한 바와 같이 사람의 키는 상당히 다양한 범위를 가지며 동일한 사람이라도 자세에 따라 달라질 수 있으므로, 도 3b에서는 객체가 갖는 부분, 예를 들어, 사람의 얼굴의 세로 방향 크기(Ha)를 기준 으로 전술한 수학식 3을 적용하여 상기 거리(D)를 산출할 수 있다. 특히, 사람의 얼굴은 눈, 코, 입과 같이 얼굴의 특징점들이 분명하고 그 크기의 편차가 작기 때문에 보다 정확한 결과를 얻을 수 있다. 한편, 사람의 얼굴보다도 보다 정형화된 크기를 갖는 객체의 부분을 이용한다면 상기 거리(D) 산출을 정확성을 보다 높일 수 있다. 도 3c에 도시된 바와 같이, 차량의 번호판은 국가별 법규에 따라 가로 및 세로 방향으 로 정형화된 크기를 갖는다. 따라서, 차량의 번호판의 세로 방향 크기(Hb)를 기준으로 전술한 수학식 3을 적용하여 상기 거리(D)를 산출할 수 있다. 이 경우에는 다른 실시예들에 비해 보다 상기 산출된 거리(D)의 정확 성이 보다 높아질 것이다. 다시 도 2를 참조하면, 제어부는 상기 거리 산출부에서 산출된 거리(D)에 대응되는 렌즈의 포커 스 위치를 적어도 포함하는 포커스 범위 내에서 상기 렌즈를 이동시키도록 렌즈 구동부를 구동한다. 그리 고, 상기 포커스 범위 내에서 기준값이 가장 큰 최적 포커스 위치를 탐색한다. 도 4는 이와 같이 상기 기준값이 가장 큰 최적 포커스 위치(Fo)를 찾는 과정을 보여주는 도면이다. 제어부는 렌즈의 포커스 위치가 이 동하는 동안 지속적으로 상기 기준값의 변화를 체크한다. 처음에는 상대적으로 큰 스텝으로 이동하면서 일단 피 크치가 발생되는 지점(피크점)이 포함된 피크 구간을 먼저 찾는다. 상기 피크 구간이 찾아지면 그 피크 구간 내 에서 미세 이동을 하면서 최종적인 피크점(k)을 발견할 수 있으며, 이러한 피크점(k)에서의 포커스 위치가 최적 포커스 위치(Fo)로 설정된다. 마지막으로, 제어부는 렌즈 구동부를 구동하여 렌즈가 상기 최적 포커스 위치(Fo)로 이동하게 함으로써 오토 포커싱 동작이 완료된다. 상기 기준값으로는 일반적으로 콘트라스트(contrast) 데이터 내지 에지 데이터를 이용할 수 있다. 이러한 콘트 라스트 데이터는 관심 영역 내의 픽셀과 주변 픽셀과의 차이값의 합(SAD: Sum of Absolute Difference)으로 정 의될 수 있으며, 이 값이 클수록 에지 데이터 또는 영상의 디테일(detail)이 많다는 의미이다. 일반적으로 에지 데이터는 포커스가 정확할수록 보다 높은 값을 갖는다. 이와 같이, 상기 산출된 거리(D)는 렌즈의 포커스 위치와 대응관계를 갖는다. 도 5는 특정 배율에서의 포 커스 위치의 변화를 보여주는 로커스 데이터의 그래프이다. 이러한 로커스 데이터는 카메라 장치의 사양 정보로서 저장부에 미리 저장되어 있을 수 있다. 여기서, 가로축은 카메라 장치의 줌 배율이고 세로 축은 카메라 장치의 포커스 위치이다. 도 5에는, 무한(Inf) 거리에서의 로커스 데이터(실선)와 1.5m 거리에서의 로커스 데이터(점선)만을 예시적으로 보여준다. 예를 들어, 줌 배율이 1597인 위치에서, 1.5m 거리에서 포커스 위치는 대략 300 정도이고, 상기 줌 배율 위치에서 무한 거리에서의 포커스 위치는 대략 500 정도이다. 만약, 일반적인 오토 포커싱 기능이라면 지 근 거리로부터 무한 거리까지, 즉 0에서 500 범위(N) 내에서 최적의 포커스 위치를 탐색하여야 할 것이다. 반면 에, 본 발명에서 제시한 바와 같이 예를 들어, 산출된 거리(D)가 1.5m라는 것을 산출하면, 상기 산출된 포커스 위치(b)를 적어도 포함하는 축소된 마진 범위, 즉 포커스 범위(M) 내에서만 최적의 포커스 위치를 탐색하면 되 므로 오토 포커싱 동작에 소요되는 시간이 감소되어 신속한 오토 포커싱이 가능해진다. 이상에서, 영상 내의 객체를 기준으로 거리(D)를 산출하고 이를 이용하여 최적의 포커스 위치를 찾는 과정에 대 해 설명하였다. 그러나, 영상 내에는 하나의 객체만 존재하기 보다는 복수의 객체가 존재하는 경우가 많다. 따 라서, 캡쳐된 영상 내에서 거리(D) 산출의 기준이 되는 객체는 복수의 객체 중에서 선택된 일부 또는 하나의 객 체인 것이 바람직하다. 복수의 객체 중에 하나의 객체를 선택하는 일 실시예로서, 상기 선택된 객체는 상기 복수의 객체 중에서 상기 캡쳐된 영상의 중심에 가장 가까운 객체일 수 있다. 도 6은 복수의 객체 중에서 영상의 중심에 가까운 객체를 기준으로 거리(D)를 산출하는 예를 보여주는 도면이다. 카메라가 단순히 영상의 중심을 기준으로 오토 포커스를 수행한다면, 영상의 중심(pc)에 아무런 객체가 존재하 지 않는 경우에는 오토 포커스를 통해 오히려 사물들에 포커스가 맞지 않아서 흐린 영상이 얻어질 수 가 있다. 만약, 도 2와 같이 객체 식별부를 구비한 카메라 장치라면 복수의 객체 중에 선택된 객체(po)를 기준 으로 상기 거리(D)를 산출하는 것이 나을 것이다. 다만, 영상 내의 복수의 객체 중에서 객체를 선택하는 기준을 결정할 필요가 있다. 일반적으로 사용자는 본인이 촬영하고자 하는 대상을 영상의 중심에 두는 경우가 대부분이 기 때문에, 일 실시예에서는 복수의 객체들 중에서 영상의 중심(pc)에 가장 근접한 객체(po)를 선택한다. 그런데, 도 6에서는 복수의 객체들이 모두 사람이지만, 영상 내에 사람과 다른 사물이 혼재되어 있을 수도 있다. 즉, 영상 내의 복수의 객체가 객체의 종류가 상이한 2이상의 객체를 포함할 경우에 객체를 선택하는 기준 을 다르게 정할 수도 있다. 예를 들어, 도 3c와 같은 정형화된 크기를 갖는 부분(예: 번호판)을 갖는 객체와 그 렇지 않은 객체가 혼재되어 있는 영상에서는 해당 영상의 중심에서의 근접 여부 보다 앞서, 정형화된 크기의 부 분을 갖는 객체를 기준으로 상기 거리(D)를 산출할 수도 있다.또 다른 실시예로서, 객체 확률이 높은 객체를 기준으로 상기 거리(D)를 산출하는 것도 가능하다. 전술한 바와 같이 객체 식별부는 딥러닝 기반의 사물 탐지 알고리즘에 의해 객체를 식별하고 그 결과 객체 의 식별에 대한 정확도, 즉 객체 확률을 얻을 수 있다. 이 때, 영상 내의 복수의 객체들 중에서 상기 객체 확률 내지 정확도가 가장 높은 객체를 기준으로 상기 거리(D)를 산출할 수 있다. 이는 객체의 종류를 오판했을 때 상 기 거리(D) 산출이 완전히 잘못되어 신속히 오토 포커싱 동작에 오히려 장애가 되는 것을 방지하기 위함이다. 도 7a 및 도 7b는 제어부가 콘트라스트 데이터로부터 최대 선명도를 갖는 렌즈의 위치를 결정할 때 사 용되는 AF 윈도우의 설정 방법을 예시하는 도면들이다. 전술한 도 6이 거리 산출부에 의해 거리(D)를 산출 할 기준으로서 객체를 선택하는 과정에 이용된다면, 도 7a 및 7b는 이와 달리 그 이후 제어부에서 수행되 는 콘트라스트 데이터 기반의 최적 포커스 위치 탐색 과정에 이용되므로 서로 구별된다. 일반적으로 과도한 연산을 방지하기 위해, 최적 포커스 탐색은 영상 전체가 아니라 영상 내에 설정된 AF 윈도우 내에서 수행된다. 즉, 제어부는 상기 AF 윈도우 내에서 최적 포커스 위치를 탐색하기 위해 콘트라스트 데 이터를 연산한다. 이러한 AF 윈도우 설정이 어떻게 되는가에 따라 당연히 최적 포커스 위치 탐색의 정확성이 달 라질 수 있다. 예를 들어, 도 7a와 같이 단순히 영상의 중심(pc)에 AF 윈도우를 설정한다면, 여기에는 2개의 객 체가 함께 포함될 수 있고 가까운 위치의 객체보다 먼 위치의 객체의 에지 데이터가 더 많은 경우에는 최적 포 커스 위치가 잘못 판단될 수가 있다. 전술한 바와 같이 객체 식별부는 딥러닝 기반의 사물 탐지 알고리즘에 의해 객체를 식별하고 그 크기 정보 도 이미 알고 있는 상황이므로, 각각의 객체가 자치하는 영역(31, 32)을 AF 윈도우로 설정하거나 이 중에서 하 나의 객체의 영역을 AF 윈도우로 설정할 수 있다. 이러한 객체 기반의 AF 윈도우 설정은 오토 포커스의 정 확성 및 신속성을 높이는 데에 도움을 준다. 한편, 전술한 바와 같이, 제어부는 거리 산출부에 의해 산출된 거리(D)를 기초로 포커스 위치를 결정 하였더라도, 어느 정도의 마진을 포함하여 상기 포커스 위치를 포함하는 포커스 범위를 설정하고, 이 포커스 범 위 내에서 최적 포커스 위치를 탐색한다. 그런데, 이러한 포커스 범위의 크기, 즉 마진의 크기는 크게 잡을수록 정확성이 높지만 오토 포커스 속도가 느리고, 작게 잡을수록 오토 포커스 속도는 빠르지만 정확성은 낮아지는 트레이드 오프가 발생한다. 따라서, 본 발명의 일 실시예에 있어서, 상기 마진의 크기 결정에 객체 식별부에서 얻어진 객체의 정확도, 즉 객체 확률을 이용한다. 상기 정확도가 높을수록 상기 포커스 범위는 좁게(마진이 작게) 설정되고, 상기 정확 도가 낮을수록 상기 포커스 범위는 넓게(마진이 크게) 설정되는 것이 바람직하다. 이러한 가변 마진은 딥러닝 기반의 사물 탐지 알고리즘에 따른 객체 확률에 따라 변경되기 때문에 영상 내의 객체들의 상황에 따라 적절히 조절될 수 있게 된다. 한편, 지금까지는 현재 캡쳐된 영상 내에서 오토 포커스를 설정하는 실시예들을 설명하였다. 그러나, 영상 내의 객체가 일정 이상의 속도로 이동하는 상황이라면 아무리 오토 포커싱을 신속히 수행한다고 하더라도 상기 객체 의 이동 속도만큼의 응답 성능을 가지기는 어렵다. 따라서, 이를 고려하여 본 발명의 실시예에서는, 이동하는 객체의 이동 속도에 따라 이동된 예측 위치에서 AF 윈도우를 설정하는 방법을 제시하고자 한다. 일단, 제어부는 상기 캡쳐된 영상 내에 AF 윈도우를 설정하고, 상기 설정된 AF 윈도우 내에서 상기 최적 포커스 위치를 탐색한다. 만약, 상기 식별된 객체의 움직임이 일정 임계치 이상인 것으로 객체 식별부에 의해 식별된 경우에는, 제어부는 상기 객체의 움직임을 고려하여 상기 AF 윈도우를 설정한다. 일 실시예에 있어서, 제어부는 상기 객체의 움직임이 상기 이미지 센서로부터 가까워지거나 멀어지는 움직임(원근 움직임)이면 상기 AF 윈도우의 크기를 변경하여 설정한다. 상기 객체가 이미지 센서와 가까워 지는 움직임을 갖는다면 상기 AF 윈도우의 크기는 미리 크게 변경될 수 있고, 상기 객체가 이미지 센서와 멀어지는 움직임을 갖는다면 상기 AF 윈도우의 크기는 미리 크게 변경될 수 있다. 또한, 다른 실시예에 있어서, 상기 객체의 움직임이 상기 캡쳐된 영상 내에서 다른 위치로 이동하는 움직임(2차 원 움직임)이면, 제어부는 상기 움직임에 따른 예측된 위치에 상기 AF 윈도우를 미리 이동하여 설정할 수 있다. 물론, 상기 객체가 원근 움직임과 2차원 움직임이 복합된 경우라면 제어부은 두 가지를 함께 고려하 여 AF 윈도우의 크기 및 위치를 함께 변경할 수 있을 것이다. 도 8a는 도 2의 AI 장치(artificial intelligence device, 20)의 블록도이고, 도 8b는 상기 AI 장치가 이 용하는 DNN(Deep Neural Network) 모델의 예시이다. AI 장치는 AI 처리를 수행할 수 있는 AI 모듈을 포함하는 통신 장치, AI 모듈을 포함하는 서버 등을 포함한 다. 또한, AI 장치는 도 1에 도시된 통신 장치의 적어도 일부로 포함된다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함한다. 인공지능 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등 다양한 전자 장치로 구현된다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망(neural network)을 학습한다. 특히, AI 프 로세서는 차량 관련 데이터를 인식하기 위한 신경망을 학습한다. 여기서, 차량 관련 데이터를 인식하기 위 한 신경망은 컴퓨터 상에서 인간의 뇌 구조를 모사(simulation)하도록 설계될 수 있으며, 인간 신경망의 뉴런을 모사하는 가중치를 갖는 복수의 네트워크 노드를 포함한다. 복수의 네트워크 노드는 각각의 연결 관계에 따라 데이터를 교환하여 뉴런이 시냅스를 통해 신호를 주고받는 뉴런의 시냅스 활동을 모사한다. 여기서, 신경망은 신경망 모델로부터 개발된 딥 러닝 모델을 포함한다. 딥 러닝 모델에서 복수의 네트워크 노드는 서로 다른 계층 에 위치하여 컨볼루션(convolution) 연결 관계에 따라 데이터를 교환한다. 신경망 모델의 예로는 심층 신경망 (DNN), 컨볼루션 심층 신경망(CNN), 순환 신경망(RNN), 제한적 볼츠만 기계(RBM), 심층 신념망(DBN)과 같은 다 양한 심층 학습 기술이 있다. Deep Q-Networks는 컴퓨터 비전, 음성 인식, 자연어 처리, 음성/신호 처리 등의 분야에 적용될 수 있다. 한편, 상기와 같은 기능을 수행하는 프로세서는 범용 프로세서(예: CPU)일 수 있으나, 인공지능 학습을 위한 AI 전용 프로세서(예: GPU)일 수도 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장한다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시 메모리, 하드디스크 드라이브(HDD), 솔리드 스테이트 드라이브(SDD) 등으로 구현된다. 메모리는 AI 프로세서에 의해 액세스되고, AI 프로세서 에 의한 데이터 읽기/쓰기/편집/삭제/갱신이 수행된다. 또한, 메모리는 본 발명의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예: 딥 러닝 모델)을 저장한다. 한편, 인공지능 처리부는 데이터 분류/인식을 위한 신경망 학습을 위한 데이터 학습부를 포함한다. 데 이터 학습부는 데이터 분류/인식을 결정하기 위해 어떤 트레이닝 데이터를 사용할 것인지, 트레이닝 데이터 를 이용하여 데이터를 어떻게 분류하고 인식하는지에 대한 기준을 학습한다. 데이터 학습부는 학습에 사용 할 학습 데이터를 획득하고 획득한 학습 데이터를 딥 러닝 모델에 적용하여 딥 러닝 모델을 학습한다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 장치에 탑재된다. 예를 들어, 데이터 학습부는 인공지능 전용 하드웨어 칩 형태로 제작된다. (AI) 또는 범용 프로세서(CPU) 또는 전용 그래픽 프 로세서(GPU)의 일부로 제작되어 AI 장치에 탑재된다. 또한, 데이터 학습부는 소프트웨어로 구현된다. 기준 치수. 소프트웨어 모듈(또는 명령어를 포함하는 프로그램 모듈)로 구현되는 경우, 상기 소프트웨어 모듈은 컴퓨터 판독 가능 매체에 저장된다. 이 경우, 적어도 하나의 소프트웨어 모듈은 운영체제(OS) 또는 애플리케이 션에 의해 제공된다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함한다. 학습 데이터 획득부는 데이터 분류 및 인식을 위한 신경망 모델에 대해 요청된 학습 데이터를 획득한다. 예 를 들어, 학습 데이터 획득부는 신경망 모델에 학습 데이터로 입력하기 위한 차량 데이터 및/또는 샘플 데 이터를 획득한다. 모델 학습부는 획득한 트레이닝 데이터를 이용하여 신경망 모델이 소정의 데이터를 어떻게 분류하는지 판단 하는 기준을 갖도록 학습한다. 이 경우, 모델 학습부는 학습 데이터의 적어도 일부를 판단 기준으로 하여 감독 학습(supervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또는, 모델 학습부는 비지도 학 습을 통해 신경망 모델을 학습시켜 감독 없이 학습 데이터를 사용하여 자가 학습하여 기준을 발견한다. 또한, 모델 학습부는 학습 기반의 상황 판단 결과가 정확한지 피드백을 이용하여 강화 학습을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 오차 역전파(back-propagation) 방법 또는 그래디언트 디센트 (gradient decent) 방법을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 학습부는 학습된 신경망 모델을 메모리에 저장한다. 모델 학습부는 학습 된 신경망 모델을 인공지능 장치와 유무선 네트워크로 연결된 서버의 메모리에 저장한다. 데이터 학습부는 학습 데이터 전처리기(미도시) 및 학습 데이터 선택부(미도시)를 더 포함하여 인식 모델의 분석 결과를 향상시키거나 생성에 필요한 자원 또는 시간을 절약한다. 학습 데이터 전처리기는 획득된 데이터가 상황을 결정하기 위한 학습에 사용될 수 있도록 획득된 데이터를 전처 리한다. 예를 들어, 학습 데이터 전처리부는 획득된 데이터를 미리 설정된 포맷으로 처리하여 모델 학습부 가 학습을 위해 획득한 학습 데이터를 영상 인식에 사용할 수 있도록 한다. 또한, 학습 데이터 선택부는 학습 데이터 획득부에 의해 획득된 학습 데이터 또는 전처리기에 의해 전처리 된 학습 데이터로부터 학습에 필요한 데이터를 선택한다. 선택된 학습 데이터는 모델 학습부로 제공된다. 예를 들어, 학습 데이터 선택부는 차량 카메라를 통해 획득한 영상 중 특정 영역을 검출하여 특정 영역에 포함 된 객체에 대한 데이터만을 학습 데이터로 선택한다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위해 모델 평가부(미도시)를 더 포함한다. 모델 평가부는 평가 데이터를 신경망 모델에 입력하고, 평가 데이터로부터 출력된 분석 결과가 소정의 기준을 만족하지 않는 경우 모델 학습부가 신경망 모델을 재학습시키도록 한다. 이 경우, 평가 데이터는 인식 모델 을 평가하기 위한 미리 정의된 데이터일 수 있다. 예를 들어, 모델 평가부는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중 분석 결과가 부정확한 평가 데이터의 개수 또는 비율이 기설정된 기준을 초과하는 경우 해 당 모델을 소정 기준을 만족하지 않는 것으로 평가한다. 통신부는 AI 처리부에 의한 AI 처리 결과를 외 부의 통신 장치로 전송한다. 도 8b를 참조하면, 심층신경망(DNN)은 입력 계층과 출력 계층 사이에 여러 개의 은닉 계층을 포함하는 인공신경 망(ANN)이다. 심층 신경망은 일반적인 인공 신경망에서와 같이 복잡한 비선형 관계를 모델링할 수 있다. 예를 들어, 객체 식별 모델을 위한 심층 신경망 구조에서 각 객체는 기본 이미지 요소의 계층적 구성으로 표현 된다. 이 경우, 추가 레이어는 점차적으로 모이는 하위 레이어의 특성을 통합할 수 있다. 심층 신경망의 이러한 기능을 통해 유사하게 수행되는 인공 신경망보다 더 적은 수의 단위(노드)로 더 복잡한 데이터를 모델링할 수 있다. 은닉 계층이 증가함으로써 충분히 심화된 인공신경망을 학습 모델로 사용하는 머신 러닝 패러다임을 딥러닝 (deep learning)이라고 한다. 또한 딥 러닝에 사용되는 충분히 깊은 인공 신경망을 일반적으로 DNN(Deep Neural Network)이라고 한다. 본 발명에서 객체 식별부에 의한 객체 데이터 생성 모델을 학습시키는 데 필요한 평가 데이터는 DNN의 입 력 계층에 입력될 수 있고, 데이터가 은닉 계층들을 통과하는 동안 출력 계층을 통해 사용자가 사용할 수 있는 의미 있는 평가 데이터가 생성된다. 이와 같이, 신경망 모델을 통과하여 학습된 평가 데이터는 그 정확도가 확 률에 의해 표시될 수 있으며, 상기 확률이 높을수록 평가된 결과의 정확도가 높다는 것을 의미한다. 도 9는 도 2의 카메라 장치를 실현하는 컴퓨팅 장치의 하드웨어 구성을 예시하는 도면이다. 컴퓨팅 장치은 버스, 프로세서, 메모리, 스토리지, 입출력 인터페이스 및 네트 워크 인터페이스를 가진다. 버스는 프로세서, 메모리, 스토리지, 입출력 인터페이스 및 네트워크 인터페이스가 서로 데이터를 송수신하기 위한 데이터 전송로이다. 단, 프로세서 등을 서로 접속하는 방법은 버스 연결로 제한되지 않는다. 프로세서은 CPU (Central Processing Unit)나 GPU (Graphics Processing Unit) 등의 연산 처리 장치이다. 메모리은 RAM (Random Access Memory)나 ROM (Read Only Memory) 등의 메모리이다. 스토리지은 하드 디스크, SSD (Solid State Drive), 또는 메모리 카드 등의 저장 장치이다. 또한 스토리지은 RAM 나 ROM 등의 메모리일 수 있다. 입출력 인터페이스은 컴퓨팅 장치과 입출력 디바이스를 접속하기 위한 인터페이스이다. 예를 들면 입 출력 인터페이스에는 키보드나 마우스 등이 접속된다. 네트워크 인터페이스은 컴퓨팅 장치을 외부 장치와 통신 가능하게 접속하여 전송 패킷을 송수신하기 위한 인터페이스이다. 네트워크 인터페이스은 유선 회선과 접속하기 위한 네트워크 인터페이스라도 좋고 무선 회선과 접속하기 위한 네트워크 인터페이스라도 좋다. 예를 들면, 컴퓨팅 장치은 네트워크를 통 해 다른 컴퓨팅 장치(200-1)와 접속될 수 있다. 스토리지는 컴퓨팅 장치의 각 기능을 구현하는 프로그램 모듈을 기억하고 있다. 프로세서은 이 들 각 프로그램 모듈을 실행함으로써, 그 프로그램 모듈에 대응하는 각 기능을 구현한다. 여기서 프로세서(23 0)은 상기 각 모듈을 실행할 때, 이 모듈들을 메모리상으로 읽어낸 후 실행할 수 있다. 다만, 컴퓨팅 장치의 하드웨어 구성은 도 9에 나타낸 구성으로 제한되지 않는다. 예를 들면 각 프로그램 모듈은 메모리에 저장되어도 좋다. 이 경우, 컴퓨팅 장치은 스토리지을 구비하지 않아도 된다. 이와 같이, 카메라 장치는 적어도, 프로세서와 상기 프로세서에 의해 실행 가능한 인스트럭션들 (instructions)을 저장하는 메모리를 포함한다. 특히, 도 2의 카메라 장치는 상기 카메라 장치 에 포함된 다양한 기능 블록들 내지 단계들을 포함하는 인스트럭션들이 상기 프로세서에 의해 수행됨으로 써 동작된다. 도 10은 본 발명의 일 실시예에 따른 카메라 장치에서의 오토 포커스 조절 방법을 개략적으로 도시한 흐름 도이다. 먼저, 이미지 센서는 피사체의 영상을 캡쳐한다(S51) 다음으로, 객체 식별부는 딥러닝 기반의 사물 탐지 알고리즘에 의해, 캡쳐된 영상에 포함된 객체를 식별한 다(S52). 거리 산출부는 상기 식별된 객체가 상기 캡쳐된 영상 내에서 차지하는 비율에 기초하여 상기 카메라 장치 와 상기 식별된 객체와의 거리를 산출한다(S53). 제어부는 상기 산출된 거리에 대응되는 렌즈의 포커스 위치를 적어도 포함하는 포커스 범위 내에서 상기 렌즈를 이동시킨다(S54). 마지막으로, 제어부는 상기 렌즈의 이동 중에 기준값이 가장 큰 최적 포커스 위치를 탐색한다(S55). 상기 단계 S53에서, 거리 산출부는 보다 구체적으로, 상기 카메라 장치의 사양 정보에 포함된 세로 방향 화각을 취득하고, 상기 취득된 세로 방향 화각, 상기 객체의 크기비율 및 상기 객체의 물리적인 크기를 이용하 여 상기 카메라 장치와 상기 식별된 객체와의 거리를 산출한다. 이 때, 상기 객체의 크기비율은, 상기 캡쳐된 영상의 세로 방향 크기에 대한, 상기 객체의 전체 또는 상기 객체의 부분이 갖는 세로 방향 크기의 비율일 수 있다. 여기서, 상기 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체이고, 상기 선택된 객체는 상 기 복수의 객체 중에서 상기 캡쳐된 영상의 중심에 가장 가까운 객체일 수 있다. 또는, 객체는 상기 캡쳐된 영상에 포함된 복수의 객체 중에서 선택된 객체이고, 상기 복수의 객체는 객체 종류 가 상이한 2이상의 객체를 포함하며, 상기 선택된 객체는 상기 2이상의 객체 중에서 전체 또는 부분의 크기가 정형화된 객체일 수 있다. 또는, 상기 객체의 식별은 딥러닝 기반의 사물 탐지 알고리즘에 의해 이루어지고, 그 식별 결과 상기 객체의 식 별에 대한 정확도가 얻어질 수 있으며, 상기 캡쳐된 영상에 포함된 복수의 객체 중에서, 상기 정확도가 보다 높 은 객체가 상기 식별된 객체로 선택될 수 있다."}
{"patent_id": "10-2022-0053253", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있 다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적 이 아닌 것으로 이해해야 한다."}
{"patent_id": "10-2022-0053253", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래 기술에 따른 오토 포커스 기능을 갖는 카메라의 블록도이다. 도 2는 본 발명의 일 실시예에 따른 카메라 장치의 구성을 도시한 블록도이다. 도 3a 내지 도 3c는 카메라 장치에 의해 촬영된 영상만으로 특정 객체와의 거리를 산출하는 예들을 보여주는 도 면들이다. 도 4는 기준값이 가장 큰 최적 포커스 위치를 찾는 과정을 보여주는 도면이다. 도 5는 특정 배율에서의 포커스 위치의 변화를 보여주는 로커스 데이터의 그래프이다. 도 6은 복수의 객체 중에서 영상의 중심에 가까운 객체를 기준으로 거리를 산출하는 예를 보여주는 도면이다. 도 7a 및 도 7b는 제어부가 콘트라스트 데이터로부터 최대 선명도를 갖는 렌즈의 위치를 결정할 때 사용되는 AF 윈도우의 설정 방법을 예시하는 도면들이다. 도 8a는 도 2의 AI 장치의 블록도이고, 도 8b는 상기 AI 장치가 이용하는 DNN 모델의 예시이다. 도 9는 도 2의 카메라 장치를 실현하는 컴퓨팅 장치의 하드웨어 구성을 예시하는 도면이다. 도 10은 본 발명의 일 실시예에 따른 카메라 장치에서의 오토 포커스 조절 방법을 개략적으로 도시한 흐름도이 다."}
