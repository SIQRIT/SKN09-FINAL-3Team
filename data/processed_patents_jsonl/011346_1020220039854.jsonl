{"patent_id": "10-2022-0039854", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0142021", "출원번호": "10-2022-0039854", "발명의 명칭": "비 참조 영상 기반의 영상 품질 평가 방법", "출원인": "주식회사 이노와이어리스", "발명자": "홍성만"}}
{"patent_id": "10-2022-0039854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상의 한 프레임에 대해 RGB 값을 추출하는 (a) 과정;상기 추출한 RGB 값을 1번 CNN에 주어 출력을 획득하는 (b) 과정;상기 추출된 RGB 값을 n번(n ≥ 2 이상의 정수) CNN에 제공하여 출력을 획득하는 (c) 과정;(a) ~ (c) 과정을 모든 프레임에 대해 반복하고 모든 CNN의 출력을 병합하는 (d) 과정;시간 차원의 학습을 위해 병합된 출력 값을 RNN에 전달한 후 시간 차원을 1로 줄인 RNN의 출력을 획득하는 (e)과정 및출력 값이 1개의 차원이 되도록 RNN의 최종 출력에 회귀 알고리즘을 적용한 후 이 값을 비디오 품질 값으로 예측하는 (f) 과정을 포함하여 이루어진 비 참조 영상 기반의 영상 품질 평가 방법."}
{"patent_id": "10-2022-0039854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,1번 CNN의 일부 컨볼루션 계층은 학습이 불가능하도록 하는 반면에 나머지는 학습이 가능하도록 설정하는 것을특징으로 하는 비 참조 영상 기반의 영상 품질 평가 방법."}
{"patent_id": "10-2022-0039854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,1번 CNN의 일부 컨볼루션 계층은 복수의 ImageNet 학습 데이터로 사전 학습되어 계수가 고정되어 있고, 1번 CNN의 나머지 컨볼루션 계층은 상기 사전 학습된 계수에서 학습을 시작하지만 추가 학습이 가능하도록 된 것을 특징으로 하는 비 참조 영상 기반의 영상 품질 평가 방법."}
{"patent_id": "10-2022-0039854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 n은 2이고,2번 CNN의 일부 컨볼루션 계층은 1번 CNN과는 다른 복수의 이미지 학습 데이터로 사전 학습되어 계수가 고정되어 있고, 2번 CNN의 나머지 컨볼루션 계층은 상기 사전 학습된 계수에서 학습을 시작하지만 추가 학습이 가능하도록 된 것을 특징으로 하는 비 참조 영상 기반의 영상 품질 평가 방법."}
{"patent_id": "10-2022-0039854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,학습 과정에서 오차 역전파법(backpropagation)을 사용하는 것을 특징으로 하는 비 참조 영상 기반의 영상 품질평가 방법."}
{"patent_id": "10-2022-0039854", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1 내지 5 중 어느 한 항에 있어서,RNN에서 시간 개념을 담당하는 프레임 수 차원을 제외한 나머지 데이터는 전역 평균 풀링(global averagepooling)을 통해 전체 필터 수의 차원으로 변경하여 1차원 RNN으로 동작할 수 있도록 한 것을 특징으로 하는 비참조 영상 기반의 영상 품질 평가 방법."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 학습 범위 설정이 가능한 복수의 합성곱 신경망(CNN)과 순환 신경망(RNN)으로 구성된 인공지능을 이용 하여 원본 영상 없이 수신한 영상의 품질을 평가하는 비 참조 영상 기반의 영상 품질 평가 방법에 관한 것이다. 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법은 영상의 한 프레임에 대해 RGB 값을 추출하는 (a) 과정; 상기 추출한 RGB 값을 1번 CNN에 주어 출력을 획득하는 (b) 과정; 상기 추출된 RGB 값을 n번(n ≥ 2 이상의 정수) CNN에 제공하여 출력을 획득하는 (c) 과정; (a) ~ (c) 과정을 모든 프레임에 대해 반복하고 모든 CNN의 출 력을 병합하는 (d) 과정; 시간 차원의 학습을 위해 병합된 출력 값을 RNN에 전달한 후 시간 차원을 1로 줄인 RNN 의 출력을 획득하는 (e) 과정 및 출력 값이 1개의 차원이 되도록 RNN의 최종 출력에 회귀 알고리즘을 적용한 후 이 값을 비디오 품질 값으로 예측하는 (f) 과정을 포함하여 이루어진다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비 참조 영상 기반의 영상 품질 평가 방법에 관한 것으로, 특히 학습 범위 설정이 가능한 복수의 합 성곱 신경망(CNN)과 순환 신경망(RNN)으로 구성된 인공지능을 이용하여 원본 영상 없이 수신한 영상의 품질을 평가하는 비 참조 영상 기반의 영상 품질 평가 방법에 관한 것이다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "배경기술", "item": 1, "content": "도 1은 무선 통신 환경에서 늘어나는 영상 트래픽 수요를 보인 그래프이다. 도 1에 도시한 바와 같이, 최근 5세 대 이동통신 시스템의 도입 및 그에 따른 5세대 가입자 수의 증가와 원격 근무 수요의 증가 등으로 인해 영상에 대한 네트워크 트래픽의 수요가 증가하고 있다. 그러나 이에 반해 사용자가 느끼는 수신 영상에 대한 품질을 원본 영상 없이 비 참조 방식으로 평가하는 방법으 로는 아직까지 대부분 사람이 직접 수작업으로 설계한 알고리즘이 알려져 있다. 즉 영상의 BPS(Bit Per Second), 밝기 및 흐림의 정도 등 약 10개 내외의 KPI(Key Performance Indicator)를 SVM(Support Vector Machine) 등의 알고리즘의 입력으로 사용하여 평가하는데, 이는 인간이 영상에 대한 품질을 평가하는 방법이 매 우 고차원적이라는 것을 감안할 때 제대로 동작하기 어려운 문제가 있다. 구체적으로 종래 수신한 영상 데이터의 품질을 평가하는 방식은 크게 세가지로 구분될 수 있다. a. 원본 영상과 수신 영상을 모두 획득한 후 수학적인 알고리즘을 통해 지연 시간 등을 계산하여 수신한 영상 데이터의 품질을 평가한다(전 참조 방식). b. 원본 영상에 대한 일부 정보와 수신 영상을 획득한 후 수학적인 알고리즘을 통해 색 공간의 변화 정도 등을 계산하여 수신한 영상 데이터의 품질을 평가한다(축소 참조 방식). c. 수신 영상만으로 수신한 영상 데이터의 품질을 평가한다(비 참조 방식). 전술한 전 참조 방식의 경우에 원본 영상과 수신 영상을 활용할 수 있으므로 수신 영상의 품질을 구하는 알고리 즘의 설계가 쉬우며 대체적으로 비 참조 방식보다 수신 영상의 예측 품질과 실제 사람이 느꼈던 품질 간의 오차 가 적다. 반면에, 실제 통신 환경에서 수신기가 원본 영상을 가지고 있는 경우가 극히 드물어서 대부분의 실제 환경에서 적용이 불가능하다(하기 선행기술 1 참조). 전술한 축소 참조 방식의 경우에 원본 영상을 모두 가지고 있지 않고 일부 정보만 가지고 있어도 수신 영상에 대한 품질 예측이 가능하다는 장점이 있는 반면에,실제 환경에서 적용하려면 추가적인 정보 처리 및 정보 전송 이 필요한 부담이 있어서 실제 환경에 적용하는데 장애물이 된다. 마지막으로 비 참조 방식의 경우에는 수신 영상 만으로 품질 예측이 가능하다는 장점이 있는 반면에 수신 영상 만으로 수신한 영상 데이터의 품질을 판단하는 알고리즘의 설계가 매우 어렵다는 단점이 있다. 이에 따라 대부 분의 비 참조 방식은 BPS, 밝기 및 흐림 등의 수십개의 KPI를 활용하여 수신 영상의 품질을 예측하는 알고리즘 으로 설계되고 있으나 알고리즘이 상대적으로 단순하기 때문에 대체적으로 전 참조 방식에 비해 수신 영상의 예 측 품질과 실제 사람이 느꼈던 품질 간의 오차가 크다는 문제점이 있었다(하기 선행기술 2 참조). 선행기술문헌 선행기술 1: 10-2020-0044652호 공개특허공보(발명의 명칭: 영상의 주관적 품질을 평가하는 방법 및 장치) 선행기술 2: 10-1279705호 등록특허공보(발명의 명칭: 영상 프레임 내의 블러 측정 방법과 이를 이용하여 영상 프레임의 화질 측정 장치 및 방법)"}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위해 안출된 것으로서, 학습 범위 설정이 가능한 복수의 합성곱 신경망 (CNN)과 순환 신경망(RNN)으로 구성된 인공지능을 이용하여 원본 영상 없이 수신한 영상의 품질을 평가하는 비 참조 영상 기반의 영상 품질 평가 방법을 제공함을 목적으로 한다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위한 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법은 영상의 한 프레임에 대해 RGB 값을 추출하는 (a) 과정; 상기 추출한 RGB 값을 1번 CNN에 주어 출력을 획득하는 (b) 과정; 상기 추출된 RGB 값을 n번(n ≥ 2 이상의 정수) CNN에 제공하여 출력을 획득하는 (c) 과정; (a) ~ (c) 과정을 모든 프레임에 대해 반복하고 모든 CNN의 출력을 병합하는 (d) 과정; 시간 차원의 학습을 위해 병합된 출력 값을 RNN에 전달한 후 시간 차원을 1로 줄인 RNN의 출력을 획득하는 (e) 과정 및 출력 값이 1개의 차원이 되도록 RNN의 최종 출력 에 회귀 알고리즘을 적용한 후 이 값을 비디오 품질 값으로 예측하는 (f) 과정을 포함하여 이루어진다. 전술한 구성에서, 1번 CNN의 일부 컨볼루션 계층은 학습이 불가능하도록 하는 반면에 나머지는 학습이 가능하도 록 설정한다. 1번 CNN의 일부 컨볼루션 계층은 복수의 ImageNet 학습 데이터로 사전 학습되어 계수가 고정되어 있고, 1번 CNN 의 나머지 컨볼루션 계층은 상기 사전 학습된 계수에서 학습을 시작하지만 추가 학습이 가능하다. 상기 n은 2이고, 2번 CNN의 일부 컨볼루션 계층은 1번 CNN과는 다른 복수의 이미지 학습 데이터로 사전 학습되 어 계수가 고정되어 있고, 2번 CNN의 나머지 컨볼루션 계층은 상기 사전 학습된 계수에서 학습을 시작하지만 추 가 학습이 가능하다. 학습 과정에서 오차 역전파법(backpropagation)을 사용한다. RNN에서 시간 개념을 담당하는 프레임 수 차원을 제외한 나머지 데이터는 전역 평균 풀링(global average pooling)을 통해 전체 필터 수의 차원으로 변경하여 1차원 RNN으로 동작한다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에 따르면, 종래 KPI를 사용하는 방식이나 사람이 수학적으 로 고안한 품질 평가 알고리즘 대신에 학습 범위 설정이 가능한 복수의 컨볼루션 신경망을 AI 구조 설계에 반영 함으로써 영상 그 자체만을 요구하는 진정한 비 참조 영상 품질 모니터링 시스템을 AI로 구현함과 동시에 사람 에 의한 MOS(Mean Opinion Score) 값과 AI의 예측 값의 상관도를 증가시킬 수가 있고, 이에 따라 언택트 시대의 도래에 따라 급증하는 영상 수요에 맞춰 소비자의 만족도를 크게 증진시킬 수가 있다. 한편, 낮은 MOS 값은 촬영 환경의 장애와도 상관관계가 있는데, 본 발명의 방법은 영상 그 자체만을 활용하여 영상의 MOS 값을 측정하는 시스템이기 때문에 향후 자율 주행 시스템 등에서 카메라 촬영 환경에 장애가 있는지 를 높은 정확도로 실시간으로 검출하는데 도움을 줄 수 있고, 결과적으로 자율주행 시스템 등에서 카메라가 먼 지나 나무조각 등에 가려져 있을 때 이를 제대로 파악하지 못하여 초래될 수 있는 큰 인명사고를 미연에 방지할 수가 있다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법의 바람직한 실시예에 대해 상세하게 설명한다. 잘 알려진 바와 같이, 인공신경망은 인간의 주관을 개재함이 없이 데이터 만으로 학습이 될 뿐만 아니라 입력 특성으로 영상의 원본 그 자체를 사용한다는 점에서 수십 개 내외의 KPI를 사용하는 방식보다 더욱 더 고차원적 으로 동작할 수 있다. 도 2는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법의 개요를 설명하기 위한 도이다. 도 2에 도시한 바 와 같이 본 발명의 방법에 따르면, 인공신경망이 영상의 픽셀 값만으로 유의미한 특성을 충분히 추출할 수 있도 록 복수의 합성곱 신경망을 사용하고 시간의 개념을 학습할 수 있도록 순환 신경망을 사용하되, 인공지능 학습 시 측정(예측)의 정확도를 높이기 위하여 합성곱 신경망과 순환 신경망 이 동시에 학습되도록 한다. 또한 BPS, 밝기, 흐림 등의 수십개의 KPI를 기반으로 동작하는 알고리즘 대신 수신 영상의 픽셀 값 만을 입력으 로 받아 동작하도록 한다. 만약 KPI를 사용하는 경우 사용하는 KPI가 20개라면 알고리즘의 입력 값은 (20 x 영상의 길이)가 되지만, 픽셀 값을 사용하는 경우 \"채널 수 x 영상의 가로 폭(너비) x 영상의 세로 폭(높이) x 영상의 길이\"가 입력 값이 되 어 훨씬 고차원적이면서도 KPI 등의 어떤 추가 정보도 요구하지 않는 진정한 비 참조 영상 품질 평가 알고리즘 이 설계될 수 있다. 기존 학습 과정의 어려움은 AI 구조의 개선으로 달성한다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 3은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법을 요약하여 설명하기 위한 모식도이다. 도 3에 도 시한 바와 같이 본 발명의 방법에 따르면, 복수의 학습 범위 설정이 가능한 합성곱 신경망(CNN; Convolutional Neural Network)과 순환 신경망(RNN: Recurrent Neural Network)을 사용하되 이들을 한꺼번에 학습시킨다. 영 상과 사람이 매긴 품질 값이 정답지로 존재하는 학습 데이터를 수십만개 이상 대량으로 확보하기 힘들어서 상기 와 같이 픽셀 값을 사용하는 방식으로 동작하는 AI의 학습 과정에는 과적합(over-fitting)이 발생할 우려가 있 다. 이에 따라, 예를 들어 이미지 데이터베이스인 ImageNet에 있는 수백만장의 이미지에 대해 CNN을 사전 학습 시키되, ImageNet에 대한 과적합을 추가적으로 방지하기 위해 CNN의 일부 컨볼루션 계층(Convolution Layer)에 대해서만 선택적으로 학습이 가능하도록 한다. 이를 통해 ImageNet과 영상 데이터 모두에 대해 과적합을 방지할 수 있다. 또한 선택적으로 학습 가능한 CNN이 복수가 되도록 ImageNet 이외의 여러 이미지 학습 데이터를 사용할 수 있도록 함으로써 이미지 기반 학습 데이 터 셋의 증가로 인한 일반화 효과를 더욱 배가시킬 수가 있다. 도 4는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법을 설명하기 위한 흐름도이다. 도 4에 도시한 바와 같이 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법은, 예를 들어 CNN의 수를 2라고 할 때, 영상의 한 프 레임에 대해 RGB 값을 추출하는 (a) 과정, 상기 추출한 RGB 값을 1번 CNN에 주어 출력을 획득(이때 1번 CNN에 존재하는 컨볼루션 계층 중 일부는 학습이 불가능하도록 하는 반면에 일부는 학습이 가능하도록 설정한다. 이와 같이 CNN의 일부 컨볼루션 계층만 학습이 가능하기 때문에 이미지에 대해 사전 학습된 CNN이 이미지나 영상 데 이터의 어느 하나에만 과적합(overfitting)되는 것이 방지되면서도 영상 데이터에 대해 CNN이 추가 학습을 할 수 있게 된다.)하는 (b) 과정, 상기 추출된 RGB 값을 2번 CNN에 제공하여 출력을 획득하는 (c) 과정, (a) ~ (c) 과정을 모든 프레임에 대해 반복하고 두 CNN의 출력을 병합하는 (d) 과정, 시간 차원의 학습을 위해 병합된 출 력 값을 RNN에 전달한 후 시간 차원을 1로 줄인 RNN의 출력을 획득하는 (e) 과정 및 출력 값이 1개의 차원이 되 도록 RNN의 최종 출력에 회귀 알고리즘을 적용한 후 이 값을 비디오 품질 값으로 예측하는 (f) 과정을 포함하여 이루어질 수 있다. 본 발명의 방법에서는 학습 과정에서 오차 역전파법(backpropagation)을 사용하여 학습되게 된다. 이하에서는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법의 각 과정에 대해 구체적으로 설명한다. (a) 과정: 영상의 한 프레임에 대해 RGB값 추출 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에 따른 비 참조 영상 품질 평가 인공신경망은 수신 영상 이외에 다른 정보들을 요구하지 않음, 즉 수신 영상 외의 다른 정보의 필요 등 다른 선결 조건을 요구하지 않음으로써 안정적으로 비 참조 방식의 영상 품질 평가가 가능하도록 하고 있다. 또한 수신 영상 이외의 다른 정보 가 필요하지 않아 정보의 계산 등의 시간이 추가적으로 필요하지 않은 장점이 있다. 그러나 기계가 영상을 이해하기 위해서는 수학적으로 영상이 표현될 필요가 있기 때문에 영상의 각 프레임에 대 해 RGB 값으로 변환하는 과정이 요구된다. 도 5는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 영상을 프레임별로 디코딩하는 과정을 예시적 으로 보인 도이다. 도 5에 도시한 바와 같이, 예를 들어, 영상이 30fps(frame per second)으로 이루어지고 8초 의 재생 길이를 갖고 있다면 240개의 프레임을 갖는 영상이 된다. 또한, 예를 들어 영상의 높이가 540 픽셀이고 너비가 960 픽셀이라면 하나의 프레임은 3 x 540 x 960으로 표현되는 행렬이 되며, 이때 앞의 3은 RGB 색공간을 의미한다. 만약 RGB 값이 8비트로 표현된다면 각 RGB 값은 0~255로 표현될 수 있는데, 최대값을 255로 하고 최 소값을 0으로 하여 정규화하는 경우 0~1로 표현될 수 있으며 각 단계는 1/255의 해상도를 갖게 된다. 또한 영상 은 \"프레임 수 x 3(R, G, B 색공간의 수) x 높이 픽셀 수 x 너비 픽셀 수의 행렬(형태)로 표현되게 된다. (b) 과정: (a) 과정에서 추출된 RGB 값을 1번 CNN(학습 범위의 설정이 가능한)에 제공하여 출력을 획득 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 제안하는 CNN은 영상과 사람이 매긴 품질 값이 정답지 로 존재하는 학습 데이터를 수십만개 이상 대량으로 확보하기 힘들어서 영상만으로만 인공신경망의 학습을 진행 하게 되는 경우 실제 예측시 학습 과정만큼의 성능이 발휘하지 않는 과적합 현상이 발생되는 것을 피하기 위해 이미지로 사전 학습된 CNN이다. 이때 1번 CNN은 수백만장의 ImageNet 학습 데이터로 사전 학습이 된 CNN일 수 있다. 여기에서, CNN의 모든 컨볼루션 계층을 아예 학습시키지 않게 되면 영상과 품질 값 사이에 담긴 패턴을 학습하 지 못하는 문제가 있다. 반면에, CNN의 모든 컨볼루션 계층을 학습시키면 학습용 영상 데이터의 수가 수십만개 이하인 경우 영상 데이터에만 과적합, 즉 이미지에 대해 학습한 일반적인 패턴을 상실하고, 영상 데이터에 존재 하는 패턴에만 과도하게 학습되는 과적합 현상이 발생함으로써 오히려 CNN을 학습시키지 않는 경우보다 못한 일 반화 성능을 보일 가능성이 있다. 따라서 ImageNet과 영상 데이터 모두에 과적합이 되지 않도록 하기 위해 CNN 을 구성하는 일부 컨볼루션 계층은 ImageNet으로부터 사전 학습된 계수를 고정함으로써 학습이 되지 않도록 하 고, 나머지 컨볼루션 계층은 사전 학습된 계수에서 학습을 시작하지만 추가 학습이 가능하도록 설정한다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 6은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 CNN의 동작을 요약하여 설명하기 위한 모식도 이다. 예를 들어 CNN 구조로 잘 알려진 Resnet50의 경우 하나의 CNN에 총 48개의 컨볼루션 계층이 있는데, 본 발명의 방법에서는 예를 들어 39개의 컨볼루션 계층은 학습이 불가능하도록 설정하고 9개의 컨볼루션 계층만 학습이 가 능하도록 설정함으로써 ImageNet과 영상 데이터 모두에 과적합이 발생되지 않도록 할 수 있다. 또한 도 6에 도 시한 바와 같이, 한 프레임 당 3(R, G, B 색공간) x 높이 픽셀 수 x 너비 픽셀 수의 길이를 갖는 데이터가 1번 CNN의 입력이라면 1번 CNN의 출력은 필터 수(CNN의 최종 컨볼루션 계층의 필터 수) x 높이 픽셀 수 x 너비 픽셀 수로 바뀌게 된다. 이는 CNN의 일반적인 입출력 데이터의 형태로, 3이라는 RGB 색공간의 수가 CNN의 필터 수로 바뀌어서 표현되기 때문이다. (c) 과정: (a) 과정에서 추출된 RGB 값을 2번 CNN(학습 범위의 설정이 가능한)에 제공하여 출력을 획득 이 과정에서의 CNN을 (b) 과정과 같이 수백만장의 ImageNet 학습 데이터로 사전 학습이 된 CNN으로 가정하면 ImageNet으로만 학습된 패턴에 과적합될 우려가 있기 때문에 본 발명의 방법에서는 복수의 CNN의 사용을 제안한 다. 예를 들어, 2번 CNN은 1번 CNN과 다른 수 만장 이상의 이미지 학습 데이터로 사전 학습된 신경망으로 가정 한다. 이 경우 2번 CNN도 이미지 데이터와 영상 데이터 모두에 과적합이 되지 않도록 하기 위해 CNN의 일부 컨 볼루션 계층은 사전 학습된 계수를 고정하고, 나머지 컨볼루션 계층은 사전 학습된 계수에서 학습을 시작하지만 추가 학습이 가능하도록 설정한다. 한 프레임 당 3(R, G, B 색공간) x 높이 픽셀 수 x 너비 픽셀 수의 길이를 갖는 데이터가 2번 CNN의 입력이라면 2번 CNN의 출력은 필터 수(CNN의 최종 컨볼루션 계층의 필터 수) x 높이 픽셀 수 x 너비 픽셀수로 바뀌게 된다. (d) 과정: (a) 내지 (c) 과정을 모든 프레임에 대해 반복 수행한 후 두 CNN의 출력을 병합 구체적으로 (a) 과정 내지 (c) 과정을 반복하면 그 출력에 프레임 수의 차원이 추가됨으로써 결과적으로 2개의 프레임 수 x 필터 수 x 높이 픽셀 수 x 너비 픽셀 수를 갖는 데이터가 출력된다. 두 CNN에서 사용되는 이미지의 높이 픽셀 수 및 너비 픽셀 수가 동일하다고 가정할 때 (d) 과정을 거치면 프레임 수 x 전체 필터 수(복수의CNN의 필터 수를 모두 합친 값) x 높이 픽셀 수 x 너비 픽셀 수를 갖는 데이터가 출력된다. (e) 과정: (d) 과정의 출력 값을 시간 차원의 학습을 위해 RNN에 전달한 후 시간 차원을 1로 줄인 RNN의 출력 획득"}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 7은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 RNN의 동작을 요약하여 설명하기 위한 모식도 이다. 도 7에 도시한 바와 같이, 본 발명의 방법에서는 (d) 과정의 출력인 프레임 수 x 전체 필터 수(복수의 CNN의 필터 수를 모두 합친 값) x 높이 픽셀 수 x 너비 픽셀 수의 길이를 갖는 데이터에 대해 시간 개념이 학습 되도록 하기 위해 RNN을 사용한다. 이때 RNN에서 시간 개념을 담당하는 프레임 수 차원을 제외한 나머지 데이터 는 전역 평균 풀링(global average pooling)을 통해 전체 필터 수의 차원으로 변경하여 1차원 RNN으로 동작할 수 있도록 한다. 이후 RNN이 모든 프레임 수만큼의 데이터를 입력 받은 이후의 출력인 전체 필터 수의 차원을 갖는 데이터를 RNN의 출력으로 획득한다(RNN을 거치면서 프레임 수 차원의 데이터가 제거된다). (f) 과정: RNN의 최종 출력에 출력 값이 1개의 차원이 되도록 회귀 알고리즘을 적용"}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 8은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 회귀 계층(Regression layer)의 동작을 요약하 여 설명하기 위한 모식도이다. 도 8에 도시한 바와 같이, 본 발명의 방법에서는 (e) 과정의 출력 값인 전체 필 터 수에서 1의 차원(MOS 값)이 되도록 회귀 알고리즘을 적용한다. 구체적으로는 ReLU(Rectified Linear Unit) 레이어를 통해 회귀 알고리즘이 적용되나 다른 활성화 함수(activation function) 등이 사용될 수도 있다. 만약 신경망이 학습이 완료된 신경망이라면 전술한 과정을 통해 수신 영상을 신경망에 입력으로 주어 영상의 품 질 값인 MOS 값을 얻을 수 있게 된다."}
{"patent_id": "10-2022-0039854", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 6, "content": "도 9는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법을 보다 구체적으로 요약하여 정리한 모식도이다. 도 9에 도시한 바와 같이, 본 발명의 방법에서는 먼저, 미리 CNN을 이미지 데이터에 의해 학습시켜 준비하는데, 이 과정에서 예를 들어 수백만장의 이미지 학습 데이터가 존재하는 ImageNet의 데이터 셋이 사용될 수 있다. 다음으로, 학습하고자 하는 영상 데이터를 준비한다. 마지막으로 준비된 이미지에 의해 학습된 CNN의 컨볼루션 계층 중에서 일부를 선별하여 해당 컨볼루션 계층은 재학습이 가능하도록 구성하는 반면에 나머지 컨볼루션 계층은 재학습이 불가능하도록 하여 이미 학습된 컨볼루 션 계층의 특성이 학습이 진행되어도 변경되지 않도록 한다. 도 10은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 CNN의 학습 범위를 설정하는 예를 설명하기 위한 도이다. 보통 학습하고자 하는 영상 데이터 셋보다는 이미지 데이터 셋이 상대적으로 더 큰 수로 존재하므로 본 발명의 방법에서는 영상 데이터 셋 이외에 이미지 데이터 셋도 활용함으로써 학습 데이터가 적은 한계를 극복하고 있는 데, 이를 전이 학습(transfer learning)이라고 한다. 이 과정에서 도 10에 도시한 바와 같이, 이미지 데이터와 이미지 데이터에 대한 정답 레이블로 미리 CNN을 학습시킨 후 일부 컨볼루션 계층만을 선별하여 영상 데이터를 학습하는 과정에서 계수가 변경되도록 한다. 만약 영상 데이터 셋을 학습하는 과정에서 모든 컨볼루션 계층이 학습 가능하도록 할 경우 인공신경망이 영상 데이터에만 과적합될 우려가 존재하기 때문이다. 한편, CNN을 한 개만 사용하게 되면 비록 ImageNet에 과적합이 되지는 않지만 ImageNet에만 의존적인 인공신경 망이 발생할 수 있다. 이를 방지하기 위해 본 발명의 방법에서는 학습 범위 설정이 가능한 컨볼루션 신경망을 복수로 확장하고 있는데, 도 11은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 복수의 CNN을 사용 하여 과적합을 방지하는 예를 설명하기 위한 도이다. 도 11에 도시한 바와 같이, 본 발명의 방법에 따르면 학습 범위 설정이 가능한 CNN이 복수로 존재하고 각 CNN은 서로 다른 이미지 데이터 셋에 기반하여 사전 학습된 모습을 보여준다. 이를 통해 본 발명의 방법에 따른 인공 신경망은 보다 더 일반화가 가능하고 다양한 이미지 데이터 셋의 모든 패턴을 활용할 수 있게 된다. 이상, 첨부한 도면을 참조하여 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법의 바람직한 실시예에 대하 여 상세히 설명하였으나 이는 예시에 불과한 것이며, 본 발명의 기술적 사상의 범주 내에서 다양한 변형과 변경 이 가능할 것이다. 따라서, 본 발명의 권리범위는 이하의 청구범위의 기재에 의하여 정해져야 할 것이다. 예를 들어 CNN을 3개 또는 그 이상으로 구성할 수도 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2022-0039854", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 무선 통신 환경에서 늘어나는 영상 트래픽 수요를 보인 그래프. 도 2는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법의 개요를 설명하기 위한 도."}
{"patent_id": "10-2022-0039854", "section": "도면", "subsection": "도면설명", "item": 2, "content": "도 3은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법을 요약하여 설명하기 위한 모식도. 도 4는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법을 설명하기 위한 흐름도. 도 5는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 영상을 프레임별로 디코딩하는 과정을 예시적 으로 보인 도."}
{"patent_id": "10-2022-0039854", "section": "도면", "subsection": "도면설명", "item": 3, "content": "도 6은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 CNN의 동작을 요약하여 설명하기 위한 모식도."}
{"patent_id": "10-2022-0039854", "section": "도면", "subsection": "도면설명", "item": 4, "content": "도 7은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 RNN의 동작을 요약하여 설명하기 위한 모식도."}
{"patent_id": "10-2022-0039854", "section": "도면", "subsection": "도면설명", "item": 5, "content": "도 8은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 회귀 계층(Regression layer)의 동작을 요약하 여 설명하기 위한 모식도."}
{"patent_id": "10-2022-0039854", "section": "도면", "subsection": "도면설명", "item": 6, "content": "도 9는 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법을 보다 구체적으로 요약하여 정리한 모식도. 도 10은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 CNN의 학습 범위를 설정하는 예를 설명하기 위한 도.도 11은 본 발명의 비 참조 영상 기반의 영상 품질 평가 방법에서 복수의 CNN을 사용하여 과적합을 방지하는 예 를 설명하기 위한 도."}
