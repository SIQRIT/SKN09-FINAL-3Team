{"patent_id": "10-2019-0151602", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0063106", "출원번호": "10-2019-0151602", "발명의 명칭": "자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화", "출원인": "군산대학교산학협력단", "발명자": "이덕진"}}
{"patent_id": "10-2019-0151602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 센서융합모델이 다중센서 데이터를 융합하여 상태 메모리 기반 상태 변수를 생성하는 단계;(b) 인공신경망 강화학습 모델이 상태 메모리 기반 상태 변수를 입력 받아 자율이동체의 모션 제어를 위한 행동값으로 출력하는 단계 및(c) 출력된 행동값을 운영환경에서 속도 제어 명령으로 변환하여 할당하는 단계를 포함하는 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법."}
{"patent_id": "10-2019-0151602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 센서융합모델은 다중센서 및 상태융합부를 포함하며,상기 (a) 단계는,상기 다중센서가 소정의 범위의 물체를 센싱하여 상태 데이터를 생성하는 단계 및상기 상태융합부가 상기 상태 데이터를 전달받아 융합하여 상태 메모리 기반 상태 변수로 재구성하는 단계를 포함하는 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반에이전트의 작동방법."}
{"patent_id": "10-2019-0151602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 다중센서는 깊이센서 및 거리센서를 포함하는 것을 특징으로 하는 자율이동체의 충돌회피 및 자율주행을위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법."}
{"patent_id": "10-2019-0151602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 인공신경망 강화학습 모델은 다중 계층 구조의 인공신경망을 포함하며,상기 (b) 단계는,상기 인공신경망이 상태 메모리 기반 상태 변수를 입력 받아 행동값을 출력하는 것을 특징으로 하는 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법."}
{"patent_id": "10-2019-0151602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 (b) 단계는,상기 인공신경망에서 행동값으로 출력 시 보상값을 계산하며, 계산된 보상값을 이용하여 상기 인공신경망에 입력되는 상태 메모리 기반 상태 변수를 업데이트하여 행동값으로 출력하는 것을 특징으로 하는 자율이동체의 충공개특허 10-2021-0063106-3-돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법."}
{"patent_id": "10-2019-0151602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 운영환경은 속도값 변환부 및 프로그래밍 언어부를 포함하며,상기 (c) 단계는,상기 속도값 변환부에서 상기 출력된 행동값을 자율이동체의 모션 제어를 위한 속도 명령값으로 변환하는 단계및상기 프로그래밍 언어부에서 상기 속도 명령값을 전달받아 속도 제어 명령으로 할당하는 단계를 포함하는 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의작동방법."}
{"patent_id": "10-2019-0151602", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항 내지 제 6 항 중 어느 한 항의 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법에 있어서,상기 할당된 속도 제어 명령은,자율이동체를 제어하는 운영시스템에 전달되어 상기 운영시스템이 자율이동체를 GPS 음영 지역이나 위치 인식이불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 할 수 있도록 제어할 수 있는 것을 특징으로 하는 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반에이전트의 작동방법에 의한 자율이동체의 주행방법."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 자율이동체를 GPS 음영 지역이나 위치 인식이 불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 수행할 수 있도록 할 수 있는 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법과 상기 에이전트를 탑재한 자율이동체의 주행방법을 개시한다."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기 반 에이전트의 작동방법과 상기 에이전트를 탑재한 자율이동체의 주행방법에 관한 것으로서, 특히 자율이동체를 GPS 음영 지역이나 위치 인식이 불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 수행할 수 있도록 할 수 있는 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법과 상기 에이전 트를 탑재한 자율이동체의 주행방법에 관한 것이다."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어 다양한 IT 기술이 가전제품, 자동차, 로봇 등에 접목되면서 인공지능 구글, 테슬라 등 IT 선도기업을 중심으로 자율주행자동차(Self-Driving Car) 등의 인공지능 및 충돌회피가 가능한 기술 개발이 활발히 진행되고 있다. 이러한 자율주행자동차의 알고리즘은 GPS와 같이 위치 인식을 기반으로 하거나, 환경인식을 기반한 지도 (Mapping) 정보를 이용하여 자율주행 및 충돌회피 기능을 구현하고 있다. 특히, GPS(Global Positioning System)는 위성에서 보내는 신호를 기반으로 하기 때문에 핸드폰, 네비게이션 등 과 같은 현대의 위치 인식 기술이 필수로 요구되는 IT 제품 등에 필수적으로 탑재되고 있고, 더불어 로봇, 자율 주행자동차 등에서도 GPS 기반으로 위치 인식을 하여 자율주행 및 충돌회피를 하는 기술을 활발히 쓰고 있다. 그러나, 상기 GPS(Global Positioning System)는 많은 곳에서 유용하게 쓰이지만 지하나 터널, 밀폐된 공간 등 의 위성 신호가 낮거나 수신할 수 없는 곳에서는 작동이 더디거나 아예 작동 불능이 될 수 있는 단점이 있다. 이 때문에, GPS 음영지역 등의 위치인식이 불가한 환경에서도 장애물의 충돌회피 및 자율주행이 가능한 자율이 동체의 기술이 항시 요구되고 있는 실정이다."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기 문제점을 해결하기 위하여 자율이동체를 GPS 음영 지역이나 위치 인식이 불가능한 실내 또는 실 외 환경에서도 장애물 충돌회피 및 자율주행을 수행할 수 있도록 할 수 있는 상태 메모리 기반 인공신경망을 이 용하는 강화학습 기반 에이전트의 작동방법과 상기 에이전트를 탑재한 자율이동체의 주행방법을 제공하는 데 목 적이 있다."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 본 발명의 실시 예에 따른 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모 리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법은 (a) 센서융합모델이 다중센서 데이터를 융합하여 상태 메모리 기반 상태 변수를 생성하는 단계; (b) 인공신경망 강화학습 모델이 상태 메모리 기반 상 태 변수를 입력 받아 자율이동체의 모션 제어를 위한 행동값으로 출력하는 단계 및 (c) 출력된 행동값을 운영환 경에서 속도 제어 명령으로 변환하여 할당하는 단계를 포함할 수 있다. 여기서, 상기 센서융합모델은 다중센서 및 상태융합부를 포함하며, 상기 (a) 단계는 상기 다중센서가 소정의 범 위의 물체를 센싱하여 상태 데이터를 생성하는 단계 및 상기 상태융합부가 상기 상태 데이터를 전달받아 융합하 여 상태 메모리 기반 상태 변수로 재구성하는 단계를 포함할 수 있다. 또한, 상기 다중센서는 깊이센서 및 거리센서를 포함할 수 있다. 또한, 상기 인공신경망 강화학습 모델은 다중 계층 구조의 인공신경망을 포함하며, 상기 (b) 단계는 상기 인공 신경망이 상태 메모리 기반 상태 변수를 입력 받아 행동값을 출력할 수 있다. 또한, 상기 (b) 단계는 상기 인공신경망에서 행동값으로 출력 시 보상값을 계산하며, 계산된 보상값을 이용하여 상기 인공신경망에 입력되는 상태 메모리 기반 상태 변수를 업데이트하여 행동값으로 출력할 수 있다. 또한, 상기 운영환경은 속도값 변환부 및 프로그래밍 언어부를 포함하며, 상기 (c) 단계는 상기 속도값 변환부 에서 상기 출력된 행동값을 자율이동체의 모션 제어를 위한 속도 명령값으로 변환하는 단계 및 상기 프로그래밍 언어부에서 상기 속도 명령값을 전달받아 속도 제어 명령으로 할당하는 단계를 포함할 수 있다. 한편, 본 발명의 실시 예에 따른 에이전트를 탑재한 자율이동체의 주행은 상기 할당된 속도 제어 명령이 자율이 동체를 제어하는 운영시스템에 전달되어 상기 운영시스템이 자율이동체를 GPS 음영 지역이나 위치 인식이 불가 능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 할 수 있도록 제어가 이루어질 수 있다."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따른 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하 는 강화학습 기반 에이전트는 장애물과의 충돌회피 및 자율주행이 가능하도록 사람의 지능과 같은 인공지능 에 이전트 기능을 수행할 수 있는 장점이 있다. 또한, 본 발명의 에이전트를 탑재할 시, GPS 음영 지역이나 위치 인식이 어려운 내부 또는 외부 환경에서도 작 동할 수 있는 장점이 있다. 또한, 스스로 훈련(Training)을 할 수 있어 성능이 갈수록 향상될 수 있는 장점이 있다. 또한, 오픈소스 알고리즘을 기반으로 에이전트가 구성되어 저렴한 비용으로 제공될 수 있는 장점이 있다."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조한 본 발명의 설명은 특정한 실시 형태에 대해 한정되지 않으며, 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있다. 또한, 이하에서 설명하는 내용은 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 이하의 설명에서 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용되는 용어로서, 그 자체에 의미가 한정되지 아니하며, 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 명세서 전체에 걸쳐 사용되는 동일한 참조번호는 동일한 구성요소를 나타낸다. 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 이하에서 기재되는 \"포함하다\", \"구비하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것으로 해석되어야 하며, 하나 또는 그 이 상의 다른 특징들이나, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하, 본 발명의 실시예를 첨부한 도 1 내지 도 8을 참조하여 상세히 설명하기로 한다. 도 1은 본 발명의 실시 예에 따른 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 구성도이 며, 도 2는 도 1의 에이전트가 자율이동체의 탑재되었을 때 작동을 도시한 블록도이다. 먼저, 본 발명의 실시 예에 따른 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트에 의해 속도 제어 명령을 할당 받아 동작하는 자율이동체는 GPS 음영 지역이 나 위치 인식이 불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 수행할 수 있는 특징이 있 다. 이와 관련하여, 도 1 내지 도 2를 참조하여 살펴보면 본 발명의 실시 예에 따른 자율이동체의 충돌회피 및 자율 주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트는 센서융합모델, 인공신 경망 기반 강화학습모델, 운영환경을 포함할 수 있다. 구체적으로, 센서융합모델은 다중센서 데이터를 융합하여 상태 메모리 기반 상태 변수를 생성할 수 있다. 이를 위해, 센서융합모델은 다중센서 및 상태융합부를 포함할 수 있다. 다중센서는 주변의 물체를 감지하여 각기 상태 데이터를 생성할 수 있다. 이때, 다중센서는 소정의 범위 내에서 사각지대 없이 범위 측정을 하기 위하여, 적어도 2개의 센서를 포함할 수 있다. 이는, 1개의 센서 만으로는 소정의 범위를 측정할 시 사각지대가 생길 수 있는데, 이러한 것을 방지하기 위함으로 1개의 센서가 측정할 수 없는 부분을 다른 1개가 보완함으로써 소정의 범위 내에 사각지대가 생기지 않을 수 있다. 여기서, 2개의 센서는 깊이센서 및 거리센서일 수 있으며, 거리센서의 경우 소정의 주파수를 발 산하여 거리를 감지하는 초음파센서 또는 적외선 센서 등으로 형성될 수 있다. 또한, 초음파센서 또는 적외선 센서 등으로 형성되는 거리센서는 후술하는 보상값에 사용될 수 있다. 또한, 상기에서는 2개의 센서를 예시하였지만, 범위 측정에 더 정확하고 용이하게 사용될 수 있는 것이면 더 추 가되도록 구성될 수 있다. 다중센서의 보다 자세한 설명은 도 3 내지 도 5를 참조하여 본 발명의 구체적인 구성을 설명할 때에 후술 하기로 한다. 또한, 이해가 쉽도록 깊이센서 및 거리센서가 구비되는 것을 바탕으로 설명하기로 한다. (거리센서의 경우, 초음파센서가 구비되는 것을 바탕으로 설명하기로 한다) 상태융합부는 다중센서의 각 상태 데이터를 전달받을 수 있다. 또한, 상태융합부는 전달받은 상 태 데이터를 융합하여 상태 메모리 기반 상태 변수로 재구성할 수 있다. 여기서, 상태 데이터는 본 발명의 에이 전트의 상황을 나타내며 에이전트가 결정을 내리거나 조치를 취할 수 있는 소스(source)이다. 이에 따라, 에이 전트가 하나의 결정을 내릴 수 있도록 다중센서로부터 전달되는 다수의 상태 데이터를 상태융합부에 서 하나의 상태 메모리 기반 상태 변수로 융합하도록 재구성할 수 있다. 상기의 다중센서 및 상태융합부를 포함하는 센서융합모델은 상태 메모리 기반 상태 변수를 생성 하여 인공신경망 기반 강화학습모델에 전달할 수 있다. 인공신경망 기반 강화학습모델은 센서융합모델로부터 전달받은 상태 메모리 기반 상태 변수를 기반으 로 자율이동체의 모션 제어를 위한 행동값을 출력할 수 있다. 이를 위해, 인공신경망 기반 강화학습모델은 다중 구조 계층의 인공신경망을 포함할 수 있다. 구체적으로, 인공신경망은 상술한 바와 같이 다중 구조 계층으로 형성될 수 있다. 이는, 수없이 많은 상태 변수가 발생함에 따라 기존의 방법으로는 처리가 불가능하기 때문에 다중 구조 계층의 인공신경망을 통해 수많은 상태 변수를 처리하고자 함이다. 다중 구조 계층의 인공신경망에 대한 구체적인 설명은 도 3 내지 도 5를 참조하여 본 발명의 구체적인 구 성을 설명할 때에 후술하기로 한다. 인공신경망의 다중 계층 구조를 통과하면서 처리된 상태 메모리 기반 상태 변수는 행동값으로 출력될 수 있다. 여기서, 행동값은 자율이동체의 모션, 행동 등을 제어를 하는 값으로서 출력 시 운영환경에 의해 속도 제 어 명령으로 변환되어 자율이동체의 모터 등에 전달될 수 있다. 이때, 행동값은 자율이동체의 단순 충돌회피 및 자율주행 성능을 발휘하도록 운영환경으로 바로 출력될 수 있겠으나, 보다 충돌회피 및 자율주행 성능이 향상되도록 훈련되어 질수도 있다. 이를 위해, 인공신경망 기반 강화학습모델은 행동값의 출력 시 보상값을 계산하도록 알고리즘이 형성될 수 있다. 여기서, 인공신경망 기반 강화학습모델은 계산된 보상값을 이용하여 인공신경망에 입력되는 상 태 메모리 기반 상태 변수를 업데이트 할 수 있다. 즉, 인공신경망 기반 강화학습모델은 행동값 출력시마다 보상값을 항시 업데이트함으로써 본 발명의 에이 전트가 탑재되는 자율이동체는 충돌회피 및 자율주행 성능이 업데이트 되어 우수한 성능을 발휘할 수 있다. 여기서, 보상값은 상술한 바와 같이 계산될 때 거리센서인 초음파센서가 관여할 수 있다. 보상값이 업데이트되어 출력되는 행동값은 상술한 바와 같이 운영환경으로 전달되어 속도 명령값으로 변환 되고, 자율이동체에 속도 제어 명령으로 할당될 수 있다. 운영환경은 상기 작동을 위해 속도값 변환부 및 프로그래밍 언어부를 포함할 수 있다. 속도값 변환부는 단순 행동값 또는 보상값에 의해 업데이트되어 출력되는 행동값을 자율이동체의 모 션 제어를 위한 속도 명령값으로 변환할 수 있다. 이는, 자율이동체의 모션 제어 시 바퀴, 관절 등에 연결된 모 터의 속도 변화에 의해 자율이동체가 자율주행 또는 충돌회피 등을 할 수 있기 때문이다. 즉, 자율이동체는 구 비되는 각 바퀴 등의 속도가 제어되어 충돌회피 및 자율주행을 할 수 있다. 프로그래밍 언어부는 속도값 변환부에서 변환된 속도 명령값을 속도 제어 명령으로 할당할 수 있다. 여기서, 프로그래밍 언어부는 파이썬 및 C 언어를 포함할 수 있으며, 본 발명의 에이전트가 자율이동체의 탑재시 운영시스템과 연동될 수 있다.운영시스템의 경우 자율이동체의 모션, 행동을 전반적으로 담당하는 시스템으로서 프로그래밍 언어부(32 0)로부터 속도 제어 명령을 할당받으면 모터에 속도 제어를 위한 명령으로 할당하여 자율이동체의 모션이 이루 어질 수 있다. 상기의 센서융합모델, 인공신경망 기반 강화학습모델, 운영환경을 포함하는 본 발명의 실시 예 에 따른 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트는 자율이동체에 탑재됨으로써, 자율이동체가 GPS 음영 지역이나 위치 인식이 불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 할 수 있다. 이하, 도 3 내지 5를 참조하여 본 발명의 실시 예에 따른 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메 모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 구체적인 구성을 살펴보기로 한다. 도 3은 도 1의 다중센서의 데이터가 상태 메모리 기반 상태 변수로 변환되는 과정을 도시한 알고리즘이며, 도 4 는 도 1의 인공신경망의 다중 구조 계층을 도시한 도면이고, 도 5는 도 1의 에이전트를 이용하여 장애물 탐지 및 행동값을 출력하는 방식을 도시한 자율이동체의 작동 예시도이다. 상술한 본 발명을 도 3 내지 도 5를 참조하여 보다 구체적으로 설명하면 다음과 같다. 본 발명의 에이전트 작동은 먼저, 센서융합모델에서 수행될 수 있다. 구체적으로, 사람의 감각에 해당하는 다중센서의 감각 데이터 즉, 깊이센서의 깊이 맵 이미지(Depth map image) 및 초음파센서의 측 정 값(Ultrasonic Sensors Data)이 입력된다. 여기서, 깊이센서의 경우 맵 이미지가 0.5m 내지 5.5m까지 작동할 수 있다. 즉, 0m 에서 0.5m 사이는 사각 지대로 형성될 수 있는데, 이를, 거리 센서(초음파센서)를 융합시킴으로써 사각지대를 해소하였다. 초음파센서 는 0m 내지 1.5m의 근거리를 측정할 수 있도록 형성되어 깊이센서와 중첩되도록 측정할 수 있다. 또한, 깊이센서는 처리 시간을 줄이기 위해 이미지를 80x60 픽셀 크기로 조정할 수 있다. 이때, 80x60 픽 셀 크기로 조정된 깊이 맵 이미지는 융합과정 전에 80개의 평면 벡터를 포함하는 상태 데이터로 변환될 수 있다. 또한, 변환된 80개의 평면 벡터 중 40 내지 80개 항목은 초음파센서가 담당할 수 있다. 이는, 초음파센서 가 깊이 맵 이미지에서 40 픽셀의 면적을 추정할 수 있기 때문에 깊이센서와 초음파센서를 동시 에 이용하여 보다 효율적으로 처리시간을 줄이기 위함이다. 즉, 0m 내지 0.5m의 범위에서는 거리 센서인 초음파센서의 측정 값으로 80개의 평면 벡터로 변환하며, 0.5m 내지 5.5m의 반경에서는 깊이센서의 이미지를 사용하여 40개의 평면 벡터, 초음파센서의 측정 값을 사용하여 40개의 평면 벡터를 변환할 수 있다. 한편, 상태 데이터를 구성하는 80개의 평면 벡터는 각각 0 내지 255의 스칼라 값을 형성할 수 있으며, 각 상태 데이터는 융합되어 하나의 상태 메모리 기반 상태 변수로 재설정될 수 있다. 상태 데이터가 융합된 하나의 상태 메모리 기반 상태 변수는 인공신경망 기반 강화학습모델의 다중 구조 계층의 인공신경망을 통과하여 3개의 벡터로 구성되는 행동값을 출력할 수 있다. 여기서, 인공신경망이 다중 구조 계층으로 이루어지는 것은 상태 수의 증가에 따른 경우의 수가 현저히 증 가하기 때문이다. 이는 상술한 바와 같이 이미징 아웃에서 상태는 각각 80개의 평면 벡터가 포함되고, 80개의 평면 벡터는 각각 0 내지 255의 스칼라를 형성할 수 있는데, 이는 25580라는 경우의 수를 수반한다. 따라서, 상태 값에 대한 단순한 계산을 실질적으로 불가능하며, 다중 구조 계층으로 이루어진 인공신경망 을 통해 보다 수월하게 경우의 수들을 계산하여 행동값으로 출력할 수 있다. 이하, 도 4를 참조하여 다중 구조 계층의 인공신경망을 구체적으로 살펴보면, 다중 구조 계층의 인공신경 망은 서로 연결된 네트워크를 형성하는 하나의 입력층, 두개의 히든층, 하나의 출력층으로 구성될 수 있다. 입력층에는 상태의 80개의 벡터가 입력될 수 있다. 또한, 2개의 히든층 중 제1 히든층은 150개의 신경으로 구성 되며, 선형의 신경 활성화 함수를 형성할 수 있다. 또한, 2개의 히든층 중 제2 히든층은 100개의 신경으로 구성 되며, ReLU(Rectified Linear Unit) 신경 활성화 함수를 형성할 수 있다. 또한, 출력층은 선형 신경 활성화 함수를 형성할 수 있으며, 제2 히든층을 통과한 벡터가 하나의 행동 벡터 즉, 행동 값(y)으로 출력될 수 있다. 여기서, 출력된 행동 값은 3개의 제1 내지 제3 방향 벡터(L, C, R)를 포함할 수 있다. 구체적으로, 3개의 방향 벡터 중 제1 방향 벡터(L)은 좌방향 벡터일 수 있다. 또한, 3개의 방향 벡터 중 제2 방 향 벡터(C)는 중심방향 벡터일 수 있다. 또한, 3개의 방향 벡터 중 제3 방향 벡터(R)는 우방향 벡터일 수 있다. 여기서, 제1 내지 제3 방향 벡터(L, C, R)는 각각 3개의 길이 벡터(좌방향 : L1, L2, L3, 중심방향 : C1, C2, C3, 우방향 : R1, R2, R3)를 포함할 수 있다. 초음파센서가 측정할 수 있는 범위인 0 내지 1.5m의 범위로 예를 들면, 3개의 길이 벡터 중 하나인 제1 길이 벡 터(L1, C1, R1)는 0 내지 0.4m 일 수 있다. 또한, 3개의 길이 벡터 중 또 다른 하나인 제2 길이 벡터(L2, C2, R 2)는 0.41m 내지 0.95m 일 수 있다. 또한, 3개의 길이 벡터 중 마지막 하나인 제3 길이 벡터(L3, C3, R3)는 0.96m 내지 1.5m일 수 있다. (이의 범위는 예시적인 것으로서 한정되는 것은 아니다.) 즉, 3개의 방향 벡터가 3개의 길이 벡터를 각각 포함함으로써, 도 6에 도시된 바와 같이 장애물을 탐지할 수 있 는 총 9개의 탐지 벡터가 형성될 수 있다. 여기서, 9개의 탐지 벡터는 장애물이 탐지되면 1로 표시되고, 탐지되지 않으면 0으로 표시된다. 예를 들어, 도 5을 참조하면 우방향 벡터인 제3 방향 벡터(R)의 제2 내지 제3 길이 벡터(R2 내지 R3)에서 장애물 이 감지되면 제2 내지 제3 길이 벡터(R2 내지 R3)는 하기와 같이 1로 표시될 수 있다. L(좌방향) : [0, 0, 0], C(중심방향) : [0, 0, 0], R(우방향) : [0, 1, 1] 이와 같이 장애물이 탐지 벡터에 감지되면, 속도값 변환부에서 자율이동체가 상기 탐지 벡터를 피하 도록 모터를 제어하는 속도 명령값으로 변환되고, 속도 명령값은 프로그래밍 언어부에서 속도 제어 명령으 로 할당되어 자율이동체를 제어하는 운영시스템에 전달됨으로써 자율이동체가 장애물을 회피 기동할 수 있다. 한편, 본 발명의 인공신경망 기반 강화학습모델은 받는 보상에 기초하여 행동값을 출력하도록 형성될 수 있다. 즉, 행동값 출력시 보상값을 상태 메모리 기반 상태 변수에 더하게 되고 이에 따른 행동값을 출력하도록 형성될 수 있다. 예를 들어, 0.1m 마다 10의 행동값이 주어지고, 상기 제3 방향 벡터(R)의 제2 내지 제3 길이 벡터의 0.71m 내지 0.8m에서 장애물이 감지된 것으로 가정하면, 1.5m의 범위에서는 제1 내지 제3 방향 벡터(L, C, R)는 각각 150의 행동값이 주어지게 되고[150, 150, 150], 제3 방향 벡터의 0.71m 내지 0.8m에 걸쳐 장애물이 감지됨에 따라 -80 의 행동값을 받게 되어 제1 내지 제3 방향 벡터의 값은 [150, 150, 70]이 될 수 있다. 이에 따라, 자율이동체는 [150, 150, 70]의 행동값만큼의 속도가 제어되어 방향이 전환된다. 이때, 본 발명의 에이전트는 시간이 지남에 따라 초기 행동값인 [150, 150, 150]을 맞추려고 제3 방향 벡터에 80의 보상값을 주 어 자율이동체의 모션제어가 이루어지게 할 수 있다. 즉, 본 발명의 에이전트는 시간이 지남에 따라 보상을 최대화하기 위해 앞으로 나아갈 수 있는 동기 부여를 제 공받을 수 있다. 여기서, 초음파센서의 측정 값이 보상값에 사용될 수 있으며, 초음파센서를 기반으로 행동값이 형성될수록 높은 보상을 받을 수 있다. 예를 들어, 0.71m 내지 0.8m 보다 가까이 형성되었을 때, 즉 0.7m 또는 그 이하(0.69m…0m)에 근접할수록 행동 값은 -80보다 높은 -90 … -150을 형성함으로, 보상값은 초기 행동값인 150을 보상하기 위해 높게 책정될 수 있 다. 이에 따라 에이전트는 높은 보상을 받게 된다. 상기의 방식을 통해, 본 발명의 에이전트는 현 상황에서 취할 수 있는 최선의 조치를 취하도록 학습되며, 자율 이동체를 GPS 음영 지역이나 위치 인식이 불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 수행할 수 있도록 할 수 있다.이하, 도 6 내지 도 8을 참조하여 본 발명의 실시 예에 따른 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법에 대하여 설명하기로 한다. 도 6은 본 발명의 실시 예에 따른 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법 을 도시한 흐름도이며, 도 7은 도 6의 상태 메모리 기반 상태 변수 생성 단계의 세부 작동 흐름도이고, 도 8은 도 6의 속도 제어 명령으로 변환하여 할당하는 단계의 세부 작동 흐름도이다. 도 6 내지 도 8을 참조하면, 본 발명의 실시 예에 따른 자율이동체의 충돌회피 및 자율주행을 위하여 상태 메모 리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법은 센서융합모델이 다중센서 데이터를 융합 하여 상태 메모리 기반 상태 변수를 생성하는 단계(S10), 인공신경망 강화학습 모델이 상태 메모리 기반 상태 변수를 입력받아 자율이동체의 모션 제어를 위한 행동값으로 출력하는 단계(S20) 및 출력된 행동값을 운영환경 에서 속도 제어 명령으로 변환하여 할당하는 단계(S30)를 포함할 수 있다. 구체적으로, 센서융합모델은 다중센서 및 상태융합부를 포함하며, 센서융합모델이 다중센서 데 이터를 융합하여 상태 메모리 기반 상태 변수를 생성하는 단계(S10)는 다중센서가 소정의 범위의 물체를 센싱하 여 상태 데이터를 생성하는 단계(S12) 및 상태융합부가 상태 데이터를 전달받아 융합하여 상태 메모리 기반 상 태 변수로 재구성하는 단계(S14)를 포함할 수 있다. 여기서, 다중센서는 깊이센서 및 거리센서를 포함하며, 거리센서는 적외선 또는 초음파센 서를 포함할 수 있다. 또한, 인공신경망 강화학습 모델은 다중 계층 구조의 인경신경망을 포함하며, 상기 인공신경망 강화 학습 모델이 상태 메모리 기반 상태 변수를 입력받아 자율이동체의 모션 제어를 위한 행동값으로 출력하는 단계 (S20)는 인공신경망을 통해 수행될 수 있다. 즉, 인공신경망이 상태 메모리 기반 상태 변수를 입력 받아 행동값을 출력할 수 있다. 이때, 인공신경망에서 행동값 출력 시 보상값을 계산하며, 계산된 보상값을 이용하여 인공신경망에 입력되는 상 태 메모리 기반 상태 변수를 업데이트하여 행동값으로 출력할 수 있다. 이러한 강화학습을 통해 본 발명의 에이 전트는 현 상황에서 취할 수 있는 최선의 조치를 취하도록 학습되며, 자율이동체를 GPS 음영 지역이나 위치 인식이 불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 수행할 수 있도록 할 수 있다. 또한, 운영환경은 속도값 변환부 및 프로그래밍 언어부를 포함하며, 상기 출력된 행동값을 운영 환경에서 속도 제어 명령으로 변환하여 할당하는 단계(S30)는 속도값 변환부에서 출력된 행동값을 자율이동체의 모션 제어를 위한 속도 명령값으로 변환하는 단계(S32) 및 프로그래밍 언어부에서 속도 명령값을 전달받아 속도 제어 명령으로 할당하는 단계(S34)를 포함할 수 있다. 여기서 할당된 속도 제어 명령은 자율이동체를 제어하는 운영시스템에 전달되어 상기 운영시스템이 자율이동체 를 GPS 음영 지역이나 위치 인식이 불가능한 실내 또는 실외 환경에서도 장애물 충돌회피 및 자율주행을 할 수 있도록 제어할 수 있다."}
{"patent_id": "10-2019-0151602", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상으로 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지 식을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고 다른 구체적인 형태로 실시할 수 있 다는 것을 이해할 수 있을 것이다. 따라서 이상에서 기술한 실시예는 모든 면에서 예시적인 것이며 한정적이 아 닌 것이다."}
{"patent_id": "10-2019-0151602", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 구성도이 다. 도 2는 도 1의 에이전트가 자율이동체의 탑재되었을 때 작동을 도시한 블록도이다. 도 3은 도 1의 다중센서의 데이터가 상태 메모리 기반 상태 변수로 변환되는 과정을 도시한 알고리즘이다. 도 4는 도 1의 인공신경망의 다중 구조 계층을 도시한 도면이다. 도 5는 도 1의 에이전트를 이용하여 장애물 탐지 및 행동값을 출력하는 방식을 도시한 자율이동체의 작동 예시 도이다. 도 6은 본 발명의 실시 예에 따른 상태 메모리 기반 인공신경망을 이용하는 강화학습 기반 에이전트의 작동방법 을 도시한 흐름도이다. 도 7은 도 6의 상태 메모리 기반 상태 변수 생성 단계의 세부 작동 흐름도이다. 도 8은 도 6의 속도 제어 명령으로 변환하여 할당하는 단계의 세부 작동 흐름도이다."}
