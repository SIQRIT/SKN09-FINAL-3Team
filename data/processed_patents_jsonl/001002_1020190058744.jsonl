{"patent_id": "10-2019-0058744", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0133484", "출원번호": "10-2019-0058744", "발명의 명칭": "분산 병렬 기반 인공지능 예측 모델 관제 장치 및 방법", "출원인": "주식회사 에이젠글로벌", "발명자": "강정석"}}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 플랫폼에 적용되고, 학습 서버 클러스터와 통신하는 분산 병렬 기반 인공지능 예측 모델 관제 장치에있어서,학습 작업을 수신하고, 상기 학습 작업으로부터 학습 속성 정보를 추출하여, 상기 추출된 학습 속성 정보를 기반으로 상기 학습 작업의 처리 작업량을 예측하는 학습 실행 스케줄링부;상기 학습 실행 스케줄링부가 다수의 학습 작업을 수신하면, 상기 다수의 학습 작업에 대한 병렬화 처리를 수행하는 병렬 실행 관리부;상기 예측된 학습 작업의 처리 작업량을 고려하여, 상기 학습 작업을 할당할 상기 학습 서버를 결정하는 분산실행 관리부;상기 학습 서버로 할당된 학습 작업의 실제 처리 작업량을 계산하고, 상기 실제 처리 작업량을 기초로 과금 정보를 생성하는 학습 작업 자원 관리부; 및상기 학습 서버 클러스터로부터 다수의 학습 서버의 최적화 타입 및 유휴 용량을 수집하여, 서버 상태 정보를생성하는 클러스터 관리부를 포함하는 분산 병렬 기반 인공지능 예측 모델 관제 장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 학습 실행 스케줄링부는,병렬화 처리된 각각의 학습 작업에 대한 처리 작업량을 예측하는 분산 병렬 기반 인공지능 예측 모델 관제장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 학습 실행 스케줄링부는,상기 추출된 학습 속성 정보에 포함되는, 상기 학습 작업의 타입 정보 및 처리 용량을 기반으로 상기 학습 작업의 처리 작업량을 예측하는 분산 병렬 기반 인공지능 예측 모델 관제 장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 학습 실행 스케줄링부는,상기 학습 작업의 타입 정보를 이용하여 상기 학습 작업의 작업 타입을 예측하고,상기 학습 작업의 처리 용량을 이용하여 상기 학습 작업이 수행될 상기 학습 서버에 포함된 워커의 개수를 예측하는 분산 병렬 기반 인공지능 예측 모델 관제 장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,공개특허 10-2020-0133484-3-상기 분산 실행 관리부는,상기 클러스터 관리부로부터 상기 서버 상태 정보를 수신하여, 상기 서버 상태 정보에 포함되는, 상기 학습 서버의 최적화 타입 및 유휴 용량을 모니터링하는 분산 병렬 기반 인공지능 예측 모델 관제 장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4항에 있어서,상기 분산 실행 관리부는,예측된 작업 타입을 기초로, 상기 학습 작업의 작업 타입에 최적화된 상기 학습 서버를 선별하고,상기 선별된 학습 서버의 포함된 유휴 워커의 개수를 계산하는 분산 병렬 기반 인공지능 예측 모델 관제 장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 분산 실행 관리부는,예측된 워커의 개수와 상기 계산된 유휴 워커의 개수를 비교하여 상기 학습 작업을 할당할 상기 학습 서버를 결정하는 분산 병렬 기반 인공지능 예측 모델 관제 장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 분산 실행 관리부는,상기 계산된 유휴 워커의 개수가 상기 예측된 워커의 개수보다 적으면, 상기 학습 작업을 할당할 상기 학습 서버의 결정을 대기하고, 상기 학습 작업의 할당을 상기 선별된 학습 서버에 예약하는 분산 병렬 기반 인공지능 예측 모델 관제 장치."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능 플랫폼에 적용되고, 학습 서버 클러스터와 통신하는 분산 병렬 기반 인공지능 예측 모델 관제 방법에있어서,학습 작업을 수신하고, 상기 학습 작업으로부터 학습 속성 정보를 추출하여, 상기 추출된 학습 속성 정보를 기반으로 상기 학습 작업의 처리 작업량을 예측하는 단계;상기 예측된 학습 작업의 처리 작업량을 고려하여, 상기 학습 작업을 할당할 상기 학습 서버를 결정하는 단계;및상기 학습 서버로 할당된 학습 작업의 실제 처리 작업량을 계산하고, 상기 실제 처리 작업량을 기초로 과금 정보를 생성하는 단계를 포함하는 분산 병렬 기반 인공지능 예측 모델 관제 방법."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 예측하는 단계는,다수의 학습 작업을 수신하면, 상기 다수의 학습 작업에 대한 병렬화 처리를 수행하는 단계 및공개특허 10-2020-0133484-4-상기 병렬화 처리된 각각의 학습 작업에 대한 처리 작업량을 예측하는 단계를 더 포함하는 분산 병렬 기반 인공지능 예측 모델 관제 방법."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9항에 있어서,상기 예측하는 단계는,상기 추출된 학습 속성 정보에 포함되는, 학습 작업의 타입 정보를 이용하여 상기 학습 작업의 작업 타입을 예측하는 단계; 및상기 추출된 학습 속성 정보에 포함되는, 학습 작업의 처리 용량을 이용하여 상기 학습 작업이 수행될 상기 학습 서버에 포함된 워커의 개수를 예측하는 단계를 더 포함하는 분산 병렬 기반 인공지능 예측 모델 관제 방법."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 결정하는 단계는,서버 상태 정보를 수신하여, 상기 서버 상태 정보에 포함되는, 상기 학습 서버의 최적화 타입 및 유휴 용량을모니터링하는 단계;예측된 작업 타입을 기초로, 상기 학습 작업의 작업 타입에 최적화된 상기 학습 서버를 선별하는 단계;상기 학습 서버의 유휴 용량을 이용하여 선별된 학습 서버의 포함된 유휴 워커의 개수를 계산하는 단계; 및예측된 워커의 개수와 상기 계산된 유휴 워커의 개수를 비교하여 상기 학습 작업을 할당할 상기 학습 서버를 결정하는 단계를 더 포함하는 분산 병렬 기반 인공지능 예측 모델 관제 방법."}
{"patent_id": "10-2019-0058744", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 결정하는 단계는,상기 계산된 유휴 워커의 개수가 상기 결정된 워커의 개수보다 적으면, 상기 학습 작업을 할당할 상기 학습 서버의 결정을 대기하고, 상기 학습 작업의 할당을 선별된 학습 서버에 예약하는 단계를 더 포함하는 분산 병렬기반 인공지능 예측 모델 관제 방법."}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 분산 병렬 기반 인공지능 예측 모델 관제 장치 및 방법은, 인공지능 플랫폼에 적용되고, 학습 서버 클 러스터와 통신하는 분산 병렬 기반 인공지능 예측 모델 관제 장치에 있어서, 학습 작업을 수신하고, 상기 학습 작업으로부터 학습 속성 정보를 추출하여, 상기 추출된 학습 속성 정보를 기반으로 상기 학습 작업의 처리 작업 (뒷면에 계속)"}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 분산 병렬 기반 인공지능 예측 모델 관제 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기계 학습 또는 머신 러닝(Machine Learning)은 인공 지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고 리즘과 기술을 개발하는 분야를 통칭한다. 기본적으로 기계 학습을 통해 컴퓨터가 특정 문제에 대한 올바른 답을 도출할 수 있도록 학습 데이터를 통해 문 제와 답 사이의 연관 관계를 스스로 학습할 수 있으며, 학습 데이터와 같은 다양한 정보들을 조합해 자신의 관 점으로 새로운 명제를 추론하거나 미래를 예측할 수 있다.그런데, 상기와 같은 기술은 다음과 같은 문제가 있다. 최근 정보 처리 기술이 발달함에 따라, 컴퓨터는 기계 학습에 있어서 대용량의 학습 데이터를 처리해야 하며, 이 과정은 순차적으로 진행되어 복잡하고 오랜 시간이 소요는 단점이 있다. 이에 따라, 많은 작업량을 짧은 시간에 처리하기 위하여, 컴퓨터의 하드웨어 성능을 향상시키는 방법 또는 컴퓨 터를 효율적으로 구동시키기 위한 소프트웨어를 개발하는 방법 등이 연구가 필요하다."}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은 상기와 같은 문제를 해결하기 위해 제안된 것으로서, 다수의 독립적인 데이터를 분산하여 병렬 처리할 수 있는 분산 병렬 기반 인공지능 예측 모델 관제 장치 및 방법을 제공하고자 한다. 또한, 본 발명의 실시예들은 순차적으로 데이터를 처리하는 방법보다 데이터를 짧은 시간 내에 처리할 수 있는 분산 병렬 기반 인공지능 예측 모델 관제 장치 및 방법을 제공하고자 한다."}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 분산 병렬 기반 인공지능 예측 모델 관제 장치는 인공지능 플랫폼에 적용되고, 학 습 서버 클러스터와 통신하는 분산 병렬 기반 인공지능 예측 모델 관제 장치에 있어서, 학습 작업을 수신하고, 상기 학습 작업으로부터 학습 속성 정보를 추출하여, 상기 추출된 학습 속성 정보를 기반으로 상기 학습 작업의 처리 작업량을 예측하는 학습 실행 스케줄링부; 상기 학습 실행 스케줄링부가 다수의 학습 작업을 수신하면, 상 기 다수의 학습 작업에 대한 병렬화 처리를 수행하는 병렬 실행 관리부; 상기 예측된 학습 작업의 처리 작업량 을 고려하여, 상기 학습 작업을 할당할 상기 학습 서버를 결정하는 분산 실행 관리부; 상기 학습 서버로 할당된 학습 작업의 실제 처리 작업량을 계산하고, 상기 실제 처리 작업량을 기초로 과금 정보를 생성하는 학습 작업 자원 관리부; 및 상기 학습 서버 클러스터로부터 다수의 학습 서버의 최적화 타입 및 유휴 용량을 수집하여, 서 버 상태 정보를 생성하는 클러스터 관리부를 포함할 수 있다. 또한, 상기 학습 실행 스케줄링부는 병렬화 처리된 각각의 학습 작업에 대한 처리 작업량을 예측한다. 또한, 상기 학습 실행 스케줄링부는 상기 추출된 학습 속성 정보에 포함되는, 상기 학습 작업의 타입 정보 및 처리 용량을 기반으로 상기 학습 작업의 처리 작업량을 예측할 수 있다. 또한, 상기 학습 실행 스케줄링부는 상기 학습 작업의 타입 정보를 이용하여 상기 학습 작업의 작업 타입을 예 측하고, 상기 학습 작업의 처리 용량을 이용하여 상기 학습 작업이 수행될 상기 학습 서버에 포함된 워커의 개 수를 예측한다. 또한, 상기 분산 실행 관리부는 상기 클러스터 관리부로부터 상기 서버 상태 정보를 수신하여, 상기 서버 상태 정보에 포함되는, 상기 학습 서버의 최적화 타입 및 유휴 용량을 모니터링할 수 있다. 또한, 상기 분산 실행 관리부는 예측된 작업 타입을 기초로, 상기 학습 작업의 작업 타입에 최적화된 상기 학습 서버를 선별하고, 상기 선별된 학습 서버의 포함된 유휴 워커의 개수를 계산한다. 또한, 상기 분산 실행 관리부는 예측된 워커의 개수와 상기 계산된 유휴 워커의 개수를 비교하여 상기 학습 작 업을 할당할 상기 학습 서버를 결정할 수 있다. 또한, 상기 분산 실행 관리부는 상기 계산된 유휴 워커의 개수가 상기 예측된 워커의 개수보다 적으면, 상기 학 습 작업을 할당할 상기 학습 서버의 결정을 대기하고, 상기 학습 작업의 할당을 상기 선별된 학습 서버에 예약 한다. 또한, 본 발명의 일 실시예에 따른 분산 병렬 기반 인공지능 예측 모델 관제 방법은 인공지능 플랫폼에 적용되 고, 학습 서버 클러스터와 통신하는 분산 병렬 기반 인공지능 예측 모델 관제 방법에 있어서, 학습 작업을 수신 하고, 상기 학습 작업으로부터 학습 속성 정보를 추출하여, 상기 추출된 학습 속성 정보를 기반으로 상기 학습 작업의 처리 작업량을 예측하는 단계; 상기 예측된 학습 작업의 처리 작업량을 고려하여, 상기 학습 작업을 할 당할 상기 학습 서버를 결정하는 단계; 및 상기 학습 서버로 할당된 학습 작업의 실제 처리 작업량을 계산하고, 상기 실제 처리 작업량을 기초로 과금 정보를 생성하는 단계를 포함할 수 있다.또한, 상기 예측하는 단계는 다수의 학습 작업을 수신하면, 상기 다수의 학습 작업에 대한 병렬화 처리를 수행 하는 단계 및 상기 병렬화 처리된 각각의 학습 작업에 대한 처리 작업량을 예측하는 단계를 더 포함한다. 또한, 상기 예측하는 단계는 상기 추출된 학습 속성 정보에 포함되는, 학습 작업의 타입 정보를 이용하여 상기 학습 작업의 작업 타입을 예측하는 단계 및 상기 추출된 학습 속성 정보에 포함되는, 학습 작업의 처리 용량을 이용하여 상기 학습 작업이 수행될 상기 학습 서버에 포함된 워커의 개수를 예측하는 단계를 더 포함할 수 있다. 또한, 상기 결정하는 단계는 서버 상태 정보를 수신하여, 상기 서버 상태 정보에 포함되는, 상기 학습 서버의 최적화 타입 및 유휴 용량을 모니터링하는 단계; 예측된 작업 타입을 기초로, 상기 학습 작업의 작업 타입에 최 적화된 상기 학습 서버를 선별하는 단계; 상기 학습 서버의 유휴 용량을 이용하여 선별된 학습 서버의 포함된 유휴 워커의 개수를 계산하는 단계; 및 예측된 워커의 개수와 상기 계산된 유휴 워커의 개수를 비교하여 상기 학습 작업을 할당할 상기 학습 서버를 결정하는 단계를 더 포함한다. 또한, 상기 결정하는 단계는 상기 계산된 유휴 워커의 개수가 상기 결정된 워커의 개수보다 적으면, 상기 학습 작업을 할당할 상기 학습 서버의 결정을 대기하고, 상기 학습 작업의 할당을 선별된 학습 서버에 예약하는 단계 를 더 포함할 수 있다."}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들에 따른 분산 병렬 기반 인공지능 예측 모델 관제 장치 및 방법은 다수의 독립적인 데이터를 분산하여 병렬 처리할 수 있다. 또한, 본 발명의 실시예들은 순차적으로 데이터를 처리하는 방법보다 데이터를 짧은 시간 내에 처리할 수 있다."}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 다른 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술 되는 실 시 예를 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예는 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2019-0058744", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 만일 정의되지 않더라도, 여기서 사용되는 모든 용어들(기술 혹은 과학 용어들을 포함)은 이 발명이 속한 종래 기술에서 보편적 기술에 의해 일반적으로 수용되는 것과 동일한 의미를 가진다. 일반적인 사전들에 의해 정의된 용어들은 관련된 기술 그리고/혹은 본 출원의 본문에 의미하는 것과 동일한 의미를 갖는 것으로 해석될 수 있고, 그리고 여기서 명확하게 정의된 표현이 아니더라도 개념화되거나 혹은 과도하게 형식적으로 해석되지 않 을 것이다. 본 명세서에서 사용된 용어는 실시 예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '포함한다' 및/또는 이 동사의 다양한 활용형들 예를 들어, '포함', '포함하는', '포함하고', '포함하며' 등은 언급된 조성, 성분, 구성요소, 단계, 동작 및/또는 소자는 하나 이상의 다른 조성, 성분, 구성요소, 단계, 동작 및/또 는 소자의 존재 또는 추가를 배제하지 않는다. 본 명세서에서 '및/또는' 이라는 용어는 나열된 구성들 각각 또 는 이들의 다양한 조합을 가리킨다. 한편, 본 명세서 전체에서 사용되는 '~부', '~기', '~블록', '~모듈' 등의 용어는 적어도 하나의 기능이나 동작 을 처리하는 단위를 의미할 수 있다. 예를 들어 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미 할 수 있다. 그렇지만 '~부', '~기', '~블록', '~모듈' 등이 소프트웨어 또는 하드웨어에 한정되는 의미는 아니 다. '~부', '~기', '~블록', '~모듈'은 어드레싱 할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부', '~기', '~블록', '~모듈'은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로 시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터 베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부', '~기', '~블록', '~모 듈'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부', '~기', '~블록', '~모듈'들로 결합되거나 추 가적인 구성요소들과 '~부', '~기', '~블록', '~모듈'들로 더 분리될 수 있다. 도 1은 본 발명의 실시예들에 따른 분산 병렬 기반 인공지능 예측 모델 관제 장치를 설명하기 위한 개념도이다. 도 1을 참조하면, 인공지능 플랫폼은 분산 병렬 기반 인공지능 예측 모델 관제 장치 및 학습 서버 클러 스터를 포함한다. 분산 병렬 기반 인공지능 예측 모델 관제 장치는 인공지능 플랫폼을 효율적으로 운영하기 위한 장치로, 학습 서버 클러스터와 연동하여 다수의 예측 모델을 병렬적으로 생성하고 관리할 수 있다. 또한, 분산 병렬 기반 인공지능 예측 모델 관제 장치는 사용자로부터 기계 학습 실행요청을 수신하여 처리 하며, 동시에 다수의 실행요청을 수신하여도 하나의 인공지능 플랫폼에서 요청된 다수의 실행요청을 효율적 으로 분산하여 처리할 수 있다. 학습 서버 클러스터는 학습 데이터를 기초로 기계 학습 알고리즘을 통해 소정의 목적 변수를 예측하는 예측 모델을 생성할 수 있다. 도 1에 도시된 바와 같이, 분산 병렬 기반 인공지능 예측 모델 관제 장치는 학습 실행 스케줄링부, 병 렬 실행 관리부, 분산 실행 관리부, 학습 작업 자원 관리부 및 클러스터 관리부를 포함한 다. 학습 실행 스케줄링부는 인공지능 플랫폼으로부터 기계 학습 실행요청 시에 학습 서버가 학습 작업을 수행함에 있어 필요한 작업량을 예측할 수 있다. 병렬 실행 관리부는 인공지능 플랫폼으로부터 다수의 기계 학습 실행요청 시에 다수의 학습 작업을 병렬적 으로 나열하여 관리할 수 있다. 분산 실행 관리부는 예측된 작업량을 기반으로 학습 작업을 학습 서버에 할당할 수 있다. 학습 작업 자원 관리부는 학습 서버가 학습 작업을 수행함에 있어 실제 작업량을 계산한다. 클러스터 관리부는 학습 서버 클러스터에 포함된 다수의 학습 서버를 관리할 수 있다. 학습 서버 클러스터는 다수의 기계 학습 알고리즘 각각의 특성이 상이하기 때문에, 각 기계 학습 알고리즘 에 사용될 특징을 서로 다르게 사용할 수 있다. 즉, 다수의 기계 학습 알고리즘의 특성을 기초로, 각각의 예측 모델의 학습에 사용될 각각의 학습 서버(제 1 학 습 서버, 제 2 학습 서버, ..., 제 n 학습서버)를 포함하고, 각각의 학습 서버를 기초로 각각의 예측 모델을 생 성할 수 있다. 도 2는 본 발명의 일 실시예에 따른 학습 작업을 처리하는 분산 병렬 기반 인공지능 예측 모델 관제 장치를 설 명하기 위한 개념도이다. 도 2를 참조하면, 학습 실행 스케줄링부는 인공지능 플랫폼으로부터 학습 작업을 수신하고, 학습 작업 으로부터 학습 속성 정보를 추출하여, 추출된 학습 속성 정보를 기반으로 학습 작업의 처리 작업량을 예측한다. 분산 실행 관리부는 예측된 학습 작업의 처리 작업량을 고려하여, 학습 작업을 할당할 학습 서버를 결정한 다. 학습 작업 자원 관리부는 학습 서버로 할당된 학습 작업의 실제 처리 작업량을 계산하고, 상기 실제 처리 작업량을 기초로 과금 정보를 생성한다. 예를 들어, 인공지능 플랫폼으로부터 학습 실행 스케줄링부가 기계 학습 실행 요청과 함께 제 1 학습 작업 을 수신하면, 학습 실행 스케줄링부는 제 1 학습 작업의 제 1 처리 작업량을 예측하고, 분산 실행 관리부 는 예측된 제 1 학습 작업의 제 1 처리 작업량을 기반으로 제 1 학습 작업을 제 1 학습 서버에 할당하 며, 학습 작업 자원 관리부는 할당된 학습 작업의 제 1 실제 처리 작업량을 계산하여, 제 1 실제 처리 작 업량을 기초로 과금 정보를 생성한다. 또한, 상기 학습 속성 정보는 학습 작업의 타입 정보 및 학습 작업의 처리 용량을 포함하며, 상기 학습 작업의 타입 정보는 롱 타입, 숏 타입, 비교분석 타입 및 GPU 타입을 포함할 수 있다. 구체적으로, 롱 타입은 해당 학습 작업을 처리하는데 걸리는 시간이 기 설정된 시간보다 크거나 같은 타입이며, 숏 타입은 해당 학습 작업을 처리하는 데 걸리는 시간이 기 설정된 시간보다 작은 타입일 수 있다. 또한, 비교분석 타입은 해당 학습 작업을 처리하는데 걸리는 시간과 관계없이, 다양한 데이터들을 기 설정된 데 이터와 비교 분석하여 대용량 데이터의 알려지지 않은 속성을 발견하거나 규칙적으로 발현되는 패턴을 찾아내는 목적을 가진 타입이며, GPU 타입은 해당 학습 작업을 처리하는데 걸리는 시간과 관계없이, 이미지 프로세싱, 렌 더링 및 과학 연산 등 고성능 연산 처리를 필요로 하는 타입이다. 도 3은 본 발명의 다른 실시예에 따른 다수의 학습 작업을 병렬 분산 처리하는 분산 병렬 기반 인공지능 예측 모델 관제 장치를 설명하기 위한 개념도이고, 도 4는 본 발명의 다수의 학습 서버를 포함하는 클러스터에서 각 각의 학습 서버가 특정 작업 타입으로 그룹화되는 것을 설명하기 위한 개념도이고, 도 5는 본 발명의 학습 작업 의 작업 타입에 따라 학습 서버를 선별하는 방법을 설명하기 위한 개념도이고, 도 6은 본 발명의 학습 작업을 할당할 학습 서버를 결정하는 방법을 설명하기 위한 개념도이다. 도 3에 도시된 바와 같이, 병렬 실행 관리부는 학습 실행 스케줄링부가 인공지능 플랫폼으로부터 다수의 학습 작업을 수신하면, 상기 다수의 학습 작업에 대한 병렬화 처리를 수행한다. 이때, 학습 실행 스케줄링부는 병렬 실행 관리부로부터 병렬화 처리된 각각의 학습 작업에 대한 처리 작업량을 예측할 수 있다. 예를 들어, 학습 작업이 4개(제 1 학습 작업, 제 2 학습 작업, 제 3 학습 작업, 제 4 학습 작업)가 있다고 가정 한다(실제로는 n 개의 학습 작업을 수행할 수 있지만 설명의 편의상 4개의 학습 작업을 기준으로 설명한다). 이 때, 학습 실행 스케줄링부가 4개(제 1 처리 작업량, 제 2 처리 작업량, 제 3 처리 작업량, 제 4 처리 작업 량)의 처리 작업량을 예측하였다면, 분산 실행 관리부는 예측된 4개의 학습 작업의 처리 작업량을 고려하 여, 4개의 학습 작업을 할당할 학습 서버를 결정한다. 또한, 학습 실행 스케줄링부는 4개의 학습 작업으로부터 각각 학습 속성 정보를 추출하고, 추출된 학습 속 성 정보에 포함되는, 해당 학습 작업의 타입 정보 및 처리 용량을 기반으로 해당 학습 작업의 처리 작업량을 예 측한다. 이때, 분산 실행 관리부는 학습 서버 클러스터에 포함된 제 1 학습 서버, 제 2 학습 서버, 제 3 학습 서버 및 제 4 학습 서버의 최적화 타입 및 유휴 용량을 모니터링하고, 4개의 학습 작업의 작업 타입을 각각 고려하여, 해당 학습 작업의 작업 타입에 최적화된 학습 서버에 4개의 학습 작업을 할당할 수 있다.또한, 학습 작업 자원 관리부는 할당된 4개의 학습 작업의 실제 처리 작업량을 계산하되, 제 1 학습 작업 에 의해 생성된 제 1 실제 처리 작업량, 제 2 학습 작업에 의해 생성된 제 2 실제 처리 작업량, 제 3 학습 작업 에 의해 생성된 제 3 실체 처리 작업량, 제 4 학습 작업에 의해 생성된 제 4 실체 처리 작업량을 생성할 수 있 다. 더하여, 학습 작업 자원 관리부는 생성된 4개의 실제 처리 작업량을 기초로 과금 정보를 생성할 수 있다. 또한, 과금 정보는 생성된 실제 처리 작업량을 기초로 생성하는 것이 바람직하나, 학습 작업의 처리 시간, 이용 한 학습 서버의 개수, 학습 작업의 작업 타입을 더 고려할 수 있다. 도 4를 참조하면, 클러스터 관리부는 학습 서버 클러스터에 포함된 n개의 학습 서버를 롱 타입에 최적 화된 제 1 학습 서버(21a), 숏 타입에 최적화된 제 2 학습 서버(22a), GPU 타입에 최적화된 제 3 학습 서버 (23a) 및 비교분석 타입에 최적화된 제 4 학습 서버(24a)로 그룹화 할 수 있다. 또한, 클러스터 관리부는 학습 서버 클러스터로부터 다수의 학습 서버의 최적화 타입 및 유휴 용량을 수집하여, 서버 상태 정보를 생성할 수 있다. 본 발명에서 하나의 학습 서버가 하나의 최적화 타입을 가지도록 그룹화하는 것이 바람직하나, n개의 학습 서버 중 적어도 2개 이상의 학습 서버가 하나의 최적화 타입을 가지도록 그룹화할 수 있다. 예를 들어, 학습 서버가 4개(제 1 학습 서버, 제 2 학습 서버, 제 3 학습 서버, 제 4 학습 서버)가 있다고 가정 하였을 때, 클러스터 관리부는 제 1 학습 서버(21a)를 작업 타입이 롱 타입인 학습 작업에 최적화된 서버 로 설정하고, 제 2 학습 서버(22a)를 작업 타입이 숏 타입인 학습 작업에 최적화된 서버로 설정하고, 제 3 학습 서버(23a)를 작업 타입이 GPU 타입인 학습 작업에 최적화된 서버로 설정하고, 제 4 학습 서버(24a)를 작업 타입 이 비교분석 타입인 학습 작업에 최적화된 서버로 설정할 수 있다. 도 5에 도시된 바와 같이, 학습 실행 스케줄링부는 학습 작업의 타입 정보를 이용하여 학습 작업의 작업 타입을 예측할 수 있다. 또한, 분산 실행 관리부는 예측된 학습 타입을 기초로, 학습 작업의 작업 타입에 최적화된 학습 서버를 선 별한다. 예를 들어, 학습 작업이 3개(제 1 학습 작업, 제 2 학습 작업, 제 3 학습작업)가 있고, 학습 서버가 3개(제 1 학습 서버, 제 2 학습 서버, 제 3 학습 서버)가 있다고 가정하였을 때, 분산 실행 관리부는 롱 타입의 학 습 작업에 최적화된 서버인 제 1 학습 서버(21a)를 제 1 학습 작업이 수행될 학습 서버로 선별하고, 숏 타입의 학습 작업에 최적화된 서버인 제 2 학습 서버(22a)를 제 2 학습 작업이 수행될 학습 서버로 선별하고, GPU 타입 의 학습 작업에 최적화된 서버인 제 3 학습 서버(24a)를 제 3 학습 작업이 수행될 학습 서버로 선별할 수 있다. 도 6에 도시된 바와 같이, 학습 서버 클러스터에 포함된 n 개의 학습 서버는 학습 작업이 수행될 적어도 하 나의 워커를 더 포함할 수 있다. 또한, 학습 실행 스케줄링부는 학습 작업의 처리 용량을 이용하여 학습 작업이 수행될 학습 서버에 포함된 워커의 개수를 예측할 수 있다. 또한, 도 4에 도시된 바와 같이, 분산 실행 관리부는 클러스터 관리부로부터 서버 상태 정보를 수신 하여, 상기 서버 상태 정보에 포함되는, 학습 서버의 최적화 타입 및 유휴 용량을 모니터링한다. 더하여, 분산 실행 관리부는 학습 서버의 유휴 용량을 이용하여 선별된 학습 서버의 포함된 유휴 워커 (20b)의 개수를 계산할 수 있다. 또한, 분산 실행 관리부는 예측된 워커의 개수와 계산된 유휴 워커(20b)의 개수를 비교하고 학습 작업을 할당할 학습 서버를 결정할 수 있다. 예를 들어, 도 5 내지 도 6을 참조하여 설명하면, 학습 작업이 3개(제 1 학습 작업, 제 2 학습 작업, 제 3 학습 작업)가 있고, 학습 서버가 3개(제 1 학습 서버, 제 2 학습 서버, 제 3 학습 서버)가 있다고 가정한다. 학습 실 행 스케줄링부는 제 1 학습 작업으로부터 학습 속성 정보를 추출하여, 제 1 학습 작업의 작업 타입이 롱 타입이고 제 1 학습 작업이 수행될 워커의 개수가 2개임을 예측한다(제 1 처리 작업량 예측). 이후, 분산 실행 관리부는 클러스터 관리부로부터 서버 상태 정보를 수신하여, 상기 서버 상태 정보로부터 롱 타입의 학습 작업에 최적화된 서버인 제 1 학습 서버(21a)를 선별하고, 제 1 학습 서버(21a)에 작업을 수행 중인 1개의수행 워커(20a)와 작업을 수행하고 있지 않은 2개의 유휴 워커(20b)를 모니터링할 수 있다. 다음으로, 분산 실 행 관리부는 롱 타입의 작업 타입에 최적화된 제 1 학습 서버(21a)의 포함된 유휴 워커(20b)가 2개 있음을 계산하고, 예측된 2개의 워커의 개수와 계산된 2개의 유휴 워커(20b)의 개수를 비교하여, 계산된 유휴 워커 (20b)의 개수가 예측된 워커의 개수보다 같거나 크면, 제 1 학습 작업을 선별된 제 1 학습 서버(21a)에 할당하 도록 결정한다. 다른 예로, 학습 실행 스케줄링부는 제 3 학습 작업으로부터 학습 속성 정보를 추출하여, 제 2 학습 작업 의 작업 타입이 숏 타입이고 제 2 학습 작업이 수행될 워커의 개수가 1개임을 예측한다(제 2 처리 작업량 예 측). 이후, 분산 실행 관리부는 클러스터 관리부로부터 서버 상태 정보를 수신하여, 상기 서버 상태 정보로부터 숏 타입의 학습 작업에 최적화된 서버인 제 2 학습 서버(22a)를 선별하고, 제 2 학습 서버(22a)에 작업을 수행 중인 3개의 수행 워커(20a)를 모니터링할 수 있다. 다음으로, 분산 실행 관리부는 숏 타입의 작업 타입에 최적화된 제 2 학습 서버(22a)의 포함된 유휴 워커(20b)가 0개 있음을 계산하고, 예측된 2개의 워 커의 개수와 계산된 0개의 유휴 워커(20b)의 개수를 비교하여, 계산된 유휴 워커(20b)의 개수가 예측된 워커의 개수보다 적으면, 제 2 학습 작업을 할당할 학습 서버의 결정을 대기하고, 제 2 학습 작업의 할당을 선별된 제 2 학습 서버(22a)에 예약한다. 도 7은 본 발명의 일 실시예에 따른 학습 작업을 처리하는 분산 병렬 기반 인공지능 예측 인공지능 모델 관제 방법을 설명하기 위한 흐름도이고, 도 8은 본 발명의 다수의 학습 작업에 대한 처리 작업량을 예측하는 방법을 설명하기 위한 흐름도이고, 도 9는 본 발명의 다수의 학습 작업을 할당할 학습 서버를 결정하는 방법을 설명하 기 위한 흐름도이고, 도 10은 본 발명의 유휴 워커의 개수가 부족할 경우에, 학습 작업의 할당을 예약하는 방법 을 설명하기 위한 흐름도이다. 도 7 내지 도 10에 따른 분산 병렬 기반 인공지능 예측 모델 관제 방법의 각 단계는 도 1 내지 도 6을 통해 설 명된 분산 병렬 기반 인공지능 예측 모델 관제 장치에 의해 수행될 수 있으며, 각 단계를 설명하면 다음과 같다. 우선, 도 7을 참조하면, 학습 실행 스케줄링부는 학습 작업을 수신하고, 학습 작업으로부터 학습 속성 정 보를 추출하여, 추출된 학습 속성 정보를 기반으로 학습 작업의 처리 작업량을 예측한다(S100). 이후, 분산 실 행 관리부는 예측된 학습 작업의 처리 작업량을 고려하여, 학습 작업을 할당할 학습 서버를 결정한다 (S110). 다음으로, 학습 서버로 할당된 학습 작업의 실제 처리 작업량을 계산하고, 실제 처리 작업량을 기초로 과금 정보를 생성한다(S120). 도 8에 도시된 바와 같이, 예측하는 단계(S100)에서 학습 실행 스케줄링부가 다수의 학습 작업을 수신하면, 병렬 실행 관리부는 다수의 학습 작업에 대한 병렬화 처리를 수행하고(S110), 병렬화 처리된 각 각의 학습 작업에 대한 처리 작업량을 예측한다(S120). 또한, 학습 실행 스케줄링부는 각각의 학습 작업으로부터 학습 속성 정보를 추출한다(S130). 이때, 학습 실행 스케줄링부는 추출된 학습 속성 정보에 포함되는, 학습 작업의 타입 정보를 이용하여 각각의 학습 작 업의 작업 타입을 예측한다(S140). 다음으로, 추출된 학습 속성 정보에 포함되는, 학습 작업의 처리 용량을 이용하여 학습 작업이 수행될 학습 서 버에 포함된 워커의 개수를 예측한다(S150). 도 9 내지 도 10을 참조하면, 결정하는 단계(S200)에서 분산 실행 관리부는 클러스터 관리부로부터 서버 상태 정보를 수신하여, 서버 상태 정보에 포함되는, 학습 서버의 최적화 타입 및 유휴 용량을 모니터링한 다(S210). 이후, 예측된 학습 작업의 작업 타입을 기초로, 학습 작업의 작업 타입에 최적화된 학습 서버를 선별 한다(S220). 이후, 분산 실행 관리부는 학습 서버의 유휴 용량을 이용하여 선별된 학습 서버의 포함된 유휴 워커(22b) 의 개수를 계산한다(S230). 다음으로, 분산 실행 관리부는 예측된 워커의 개수와 계산된 유휴 워커(22b)의 개수를 비교하여 학습 작업을 할당할 학습 서버를 결정한다(S240). 또한, 계산된 유휴 워커(22b)의 개수가 예측된 워커의 개수보다 적으면, 분산 실행 관리부는 학습 작업을 할당할 학습 서버의 결정을 대기하고, 학습 작업의 할당을 선별된 학습 서버에 예약한다(S250). 이에 따라, 본 발명은 분산 병렬 기반 인공지능 예측 모델 관제 장치를 이용하여 다수의 학습 작업을 병렬 적으로 처리할 수 있어 다수의 예측 모델을 동시에 생성하고, 관리할 수 있는 효과가 있다. 이상의 상세한 설명은 본 발명을 예시하는 것이다. 또한, 전술한 내용은 본 발명의 바람직한 실시 형태를 나타내어 설명하는 것이며, 본 발명은 다양한 다른 조합, 변경 및 환경에서 사용할 수 있다. 즉 본 명세서에 개시된 발명의 개념의 범위, 저술한 개시 내용과 균등한 범 위 및/또는 당 업계의 기술 또는 지식의 범위 내에서 변경 또는 수정이 가능하다. 저술한 실시 예는 본 발명의 기술적 사상을 구현하기 위한 최선의 상태를 설명하는 것이며, 본 발명의 구체적인 적용 분야 및 용도에서 요구 되는 다양한 변경도 가능하다. 따라서 이상의 발명의 상세한 설명은 개시된 실시 상태로 본 발명을 제한하려는 의도가 아니다. 또한 첨부된 청구범위는 다른 실시 상태도 포함하는 것으로 해석되어야 한다."}
{"patent_id": "10-2019-0058744", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예들에 따른 분산 병렬 기반 인공지능 예측 모델 관제 장치를 설명하기 위한 개념도이다. 도 2는 본 발명의 일 실시예에 따른 학습 작업을 처리하는 분산 병렬 기반 인공지능 예측 모델 관제 장치를 설 명하기 위한 개념도이다. 도 3은 본 발명의 다른 실시예에 따른 다수의 학습 작업을 병렬 분산 처리하는 분산 병렬 기반 인공지능 예측 모델 관제 장치를 설명하기 위한 개념도이다. 도 4는 본 발명의 다수의 학습 서버를 포함하는 클러스터에서 각각의 학습 서버가 특정 작업 타입으로 그룹화되 는 것을 설명하기 위한 개념도이다. 도 5는 본 발명의 학습 작업의 작업 타입에 따라 학습 서버를 선별하는 방법을 설명하기 위한 개념도이다. 도 6은 본 발명의 학습 작업을 할당할 학습 서버를 결정하는 방법을 설명하기 위한 개념도이다. 도 7은 본 발명의 일 실시예에 따른 학습 작업을 처리하는 분산 병렬 기반 인공지능 예측 모델 관제 방법을 설 명하기 위한 흐름도이다. 도 8은 본 발명의 다수의 학습 작업에 대한 처리 작업량을 예측하는 방법을 설명하기 위한 흐름도이다. 도 9는 본 발명의 다수의 학습 작업을 할당할 학습 서버를 결정하는 방법을 설명하기 위한 흐름도이다. 도 10은 본 발명의 유휴 워커의 개수가 부족할 경우에, 학습 작업의 할당을 예약하는 방법을 설명하기 위한 흐 름도이다."}
