{"patent_id": "10-2023-0112759", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0154421", "출원번호": "10-2023-0112759", "발명의 명칭": "비디오 이미지 입력에 대한 깊이맵을 추정하는 방법, 장치 및 컴퓨터 판독 가능 매체", "출원인": "한국전자통신연구원", "발명자": "김준수"}}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장치에 의해 수행되는, 프레임에 대한 깊이 맵을 추출하는 방법에 있어서, 상기 방법은:영상을 구성하는 복수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출하는 단계;상기 복수의 프레임 중 제2 프레임에 대한 제1 특징 데이터와 상기 제1 프레임에 대한 제1 특징 데이터 간의유사도에 기초하여, 상기 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특징 데이터를 획득하는 단계; 상기 멀티 스케일 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징데이터에 기초하여, 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하는 단계; 및상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 이용하여 상기 제1 프레임에 대한 깊이 맵을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2 프레임은, 상기 복수의 프레임 중 상기 제1 프레임에 대한 깊이 맵을 추출하기 전에 깊이 맵이 추출된프레임인, 방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,깊이 값 후보 별로 상기 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀 및 상기 제2 프레임에 대한 제1 특징데이터의 특정 픽셀 간의 상기 유사도가 산출되는, 방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 멀티 스케일 특징 데이터를 획득하는 단계는,상기 깊이 값 후보 별로 산출된 유사도 및 상기 깊이 값 후보 각각에 대응되는 특징 벡터 간의 곱 연산을 수행하는 단계;상기 곱 연산 결과를 합산하는 단계; 및상기 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀에 대해 상기 합산된 곱 연산 결과를 합산하여 상기 멀티스케일 특징 데이터를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 깊이 값 후보 각각에 대응되는 특징 벡터는, 미리 설정되거나 전체 네트워크의 학습 과정에서 학습되는,방법.공개특허 10-2024-0154421-3-청구항 6 제1항에 있어서,상기 제2 프레임의 깊이 맵은, i) 상기 제2 프레임에 대해 깊이 맵 추출 알고리즘을 적용하여 획득되거나, ii) 상기 제2 프레임에 대한 제1 특징 데이터 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여 획득되는, 방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 프레임과 연관된 제2 특징 데이터를 획득하는 단계는,상기 멀티 스케일 특징 데이터를 멀티 스케일 특징 압축 모듈에 입력하여 압축된 특징 데이터를 획득하는 단계;및상기 압축된 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터를 인공지능 모델에 입력하여 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 인공지능 모델은, 컨볼루션(convolution) 레이어 기반의 LSTM(long-short term memory)를 포함하는,방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제1 프레임에 대한 깊이 맵을 획득하는 단계는,인코딩된 상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 연결(concatenation)한 후 디코더(decoder)에 입력하여 상기 제1 프레임에 대한 깊이 맵을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "프레임에 대한 깊이 맵을 추출하는 장치에 있어서, 상기 장치는:하나 이상의 메모리; 및하나 이상의 프로세서를 포함하고,상기 하나 이상의 프로세서는,영상을 구성하는 복수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출하고;상기 복수의 프레임 중 제2 프레임에 대한 제1 특징 데이터와 상기 제1 프레임에 대한 제1 특징 데이터 간의유사도에 기초하여, 상기 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특징 데이터를 획득하고; 상기 멀티 스케일 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징데이터에 기초하여, 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하고; 및상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 이용하여 상기 제1 프레임에 대공개특허 10-2024-0154421-4-한 깊이 맵을 획득하도록 설정되는, 장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제2 프레임은, 상기 복수의 프레임 중 상기 제1 프레임에 대한 깊이 맵을 추출하기 전에 깊이 맵이 추출된프레임인, 장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,깊이 값 후보 별로 상기 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀 및 상기 제2 프레임에 대한 제1 특징데이터의 특정 픽셀 간의 상기 유사도가 산출되는, 장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 깊이 값 후보 별로 산출된 유사도 및 상기 깊이 값 후보 각각에 대응되는 특징 벡터 간의 곱 연산을 수행하고;상기 곱 연산 결과를 합산하고; 및상기 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀에 대해 상기 합산된 곱 연산 결과를 합산하여 상기 멀티스케일 특징 데이터를 획득하도록 설정되는, 장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 깊이 값 후보 각각에 대응되는 특징 벡터는, 미리 설정되거나 전체 네트워크의 학습 과정에서 학습되는,장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 제2 프레임의 깊이 맵은, i) 상기 제2 프레임에 대해 깊이 맵 추출 알고리즘을 적용하여 획득되거나, ii) 상기 제2 프레임에 대한 제1 특징 데이터 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여 획득되는, 장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 하나 이상의 프로세서는,상기 멀티 스케일 특징 데이터를 멀티 스케일 특징 압축 모듈에 입력하여 압축된 특징 데이터를 획득하고; 및공개특허 10-2024-0154421-5-상기 압축된 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터를 인공지능 모델에 입력하여 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하도록 설정되는, 장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 인공지능 모델은, 컨볼루션(convolution) 레이어 기반의 LSTM(long-short term memory)를 포함하는,장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 하나 이상의 프로세서는,인코딩된 상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 연결(concatenation)한 후 디코더(decoder)에 입력하여 상기 제1 프레임에 대한 깊이 맵을 획득하는 단계를 포함하는, 장치."}
{"patent_id": "10-2023-0112759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "하나 이상의 명령을 저장하는 하나 이상의 비-일시적(non-transitory) 컴퓨터 판독가능 매체로서,상기 하나 이상의 명령은 하나 이상의 프로세서에 의해서 실행되어, 프레임에 대한 깊이 맵을 추출하는 장치가: 영상을 구성하는 복수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출하고;상기 복수의 프레임 중 제2 프레임에 대한 제1 특징 데이터와 상기 제1 프레임에 대한 제1 특징 데이터 간의유사도에 기초하여, 상기 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특징 데이터를 획득하고; 상기 멀티 스케일 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징데이터에 기초하여, 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하고; 및상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 이용하여 상기 제1 프레임에 대한 깊이 맵을 획득하도록 제어되는, 컴퓨터 판독가능 매체."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "프레임에 대한 깊이 맵을 추출하는 방법 및 장치가 개시된다. 본 개시의 일 실시예에 따른, 장치에 의해 수행되 는 프레임에 대한 깊이 맵을 추출하는 방법은, 영상을 구성하는 복수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출하는 단계; 상기 복수의 프레임 중 제2 프레임에 대한 제1 특징 데이터와 상기 제1 프레임에 대한 제1 특징 데이터 간의 유사도에 기초하여, 상기 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특징 데 이터를 획득하는 단계; 상기 멀티 스케일 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여, 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하는 단계; 및 상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 이용하여 상기 제1 프레임에 대한 깊 이 맵을 획득하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 깊이맵 추정 방법에 관한 것으로서, 더욱 상세하게는 다시점(multi-view)의 비디오 이미지 입력에 대 한 깊이맵을 추정하는 방법, 장치 및 컴퓨터 판독 가능 매체에 관한 것이다."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 딥 러닝 기반 멀티-뷰 스테레오 접근 방식이 비디오 깊이 추정 분야에 도입 및 적용됨에 따라 깊이맵 추정 성능이 향상되었다. 일 예로, 4D 코스트(cost) 부피 생성의 계산 복잡성을 완화하기 위하여, 단안(monocular) 깊이 추정 아키텍처를 활용하는 기하학적 정보의 효율적인 획득을 위한 어텐션 기반 기술이 도입되었다. 또 다른 예로, 효율성, 정확성, 및 사용성 모두를 달성하기 위하여 딥러닝 기반 영상 깊이 추정을 위한 종단 간 (end-to-end) 프레임 워크를 활용하는 기술이 도입되었다. 또 다른 예로, 순차적 프레임 간의 시공간적 일관성(spatio-temporal)을 향상시키기 위하여, 비디오 깊이 추정 작업에 순환 신경망을 적용하는 기술 역시 도입되었다. 다만, 종래 기술에 의할 경우, 구조화되지 않은 카메라 시점을 포함하는 비디오 콘텐츠에서 일관된 깊이 맵을 효율적으로 생성할 수 없다는 문제점이 존재하였다."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는 다시점 비디오 이미지 입력에 대한 깊이맵을 추정하는 방법, 장치 및 컴퓨터 판독 가 능 매체를 제공함에 있다. 본 개시의 기술적 과제는 종단 간 방식에 기초한 비디오 깊이 추정 네트워크 및 기하(geometry)-시간(temporal) 결합(coupling) 모듈을 활용하는 방법, 장치 및 시스템을 제공함에 있다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예로, 장치에 의해 수행되는, 프레임에 대한 깊이 맵을 추출하는 방법은, 영상을 구성하는 복 수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출하는 단계; 상기 복수의 프레임 중 제2 프레임에 대 한 제1 특징 데이터와 상기 제1 프레임에 대한 제1 특징 데이터 간의 유사도에 기초하여, 상기 제1 프레임에 대 한 제1 특징 데이터로부터 멀티 스케일 특징 데이터를 획득하는 단계; 상기 멀티 스케일 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여, 상기 제1 프레임과 연 관된 제2 특징 데이터를 획득하는 단계; 및 상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특 징 데이터를 이용하여 상기 제1 프레임에 대한 깊이 맵을 획득하는 단계를 포함할 수 있다. 그리고, 상기 제2 프레임은, 상기 복수의 프레임 중 상기 제1 프레임에 대한 깊이 맵을 추출하기 전에 깊이 맵 이 추출된 프레임일 수 있다. 그리고, 깊이 값 후보 별로 상기 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀 및 상기 제2 프레임에 대한 제1 특징 데이터의 특정 픽셀 간의 상기 유사도가 산출될 수 있다. 그리고, 상기 멀티 스케일 특징 데이터를 획득하는 단계는, 상기 깊이 값 후보 별로 산출된 유사도 및 상기 깊 이 값 후보 각각에 대응되는 특징 벡터 간의 곱 연산을 수행하는 단계; 상기 곱 연산 결과를 합산하는 단계; 및 상기 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀에 대해 상기 합산된 곱 연산 결과를 합산하여 상기 멀티 스케일 특징 데이터를 획득하는 단계를 포함할 수 있다. 그리고, 상기 깊이 값 후보 각각에 대응되는 특징 벡터는, 미리 설정되거나 전체 네트워크의 학습 과정에서 학 습될 수 있다. 그리고, 상기 제2 프레임의 깊이 맵은, i) 상기 제2 프레임에 대해 깊이 맵 추출 알고리즘을 적용하여 획득되거 나, ii) 상기 제2 프레임에 대한 제1 특징 데이터 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여 획득될 수 있다. 그리고, 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하는 단계는, 상기 멀티 스케일 특징 데이터를 멀티 스케일 특징 압축 모듈에 입력하여 압축된 특징 데이터를 획득하는 단계; 및 상기 압축된 특징 데이터, 상기 제 2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터를 인공지능 모델에 입력하여 상 기 제1 프레임과 연관된 제2 특징 데이터를 획득하는 단계를 포함할 수 있다. 그리고, 상기 인공지능 모델은, 컨볼루션(convolution) 레이어 기반의 LSTM(long-short term memory)를 포함할 수 있다. 그리고, 상기 제1 프레임에 대한 깊이 맵을 획득하는 단계는, 인코딩된 상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 연결(concatenation)한 후 디코더(decoder)에 입력하여 상기 제1 프레 임에 대한 깊이 맵을 획득하는 단계를 포함할 수 있다. 그리고, 본 개시의 일 실시예로, 프레임에 대한 깊이 맵을 추출하는 장치는, 하나 이상의 메모리; 및 하나 이상 의 프로세서를 포함하고, 상기 하나 이상의 프로세서는, 영상을 구성하는 복수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출하고; 상기 복수의 프레임 중 제2 프레임에 대한 제1 특징 데이터와 상기 제1 프레임에 대한 제1 특징 데이터 간의 유사도에 기초하여, 상기 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특 징 데이터를 획득하고; 상기 멀티 스케일 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여, 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하고; 및 상기 멀 티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 이용하여 상기 제1 프레임에 대한 깊이 맵을 획득하도록 설정될 수 있다. 그리고, 상기 적어도 하나의 프로세서는, 상기 깊이 값 후보 별로 산출된 유사도 및 상기 깊이 값 후보 각각에 대응되는 특징 벡터 간의 곱 연산을 수행하고; 상기 곱 연산 결과를 합산하고; 및 상기 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀에 대해 상기 합산된 곱 연산 결과를 합산하여 상기 멀티 스케일 특징 데이터를 획득하 도록 설정될 수 있다. 그리고, 상기 하나 이상의 프로세서는, 상기 멀티 스케일 특징 데이터를 멀티 스케일 특징 압축 모듈에 입력하 여 압축된 특징 데이터를 획득하고; 및 상기 압축된 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프 레임의 깊이 맵과 연관된 제2 특징 데이터를 인공지능 모델에 입력하여 상기 제1 프레임과 연관된 제2 특징 데 이터를 획득하도록 설정될 수 있다. 그리고, 상기 하나 이상의 프로세서는, 인코딩된 상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 연결(concatenation)한 후 디코더(decoder)에 입력하여 상기 제1 프레임에 대한 깊이 맵을 획득하는 단계를 포함할 수 있다. 본 개시의 일 실시예로, 하나 이상의 명령을 저장하는 하나 이상의 비-일시적(non-transitory) 컴퓨터 판독가능 매체로서, 상기 하나 이상의 명령은 하나 이상의 프로세서에 의해서 실행되어, 프레임에 대한 깊이 맵을 추출하 는 장치는, 영상을 구성하는 복수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출하고; 상기 복수의 프레임 중 제2 프레임에 대한 제1 특징 데이터와 상기 제1 프레임에 대한 제1 특징 데이터 간의 유사도에 기초 하여, 상기 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특징 데이터를 획득하고; 상기 멀티 스케일 특징 데이터, 상기 제2 프레임의 깊이 맵, 및 상기 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여, 상기 제1 프레임과 연관된 제2 특징 데이터를 획득하고; 및 상기 멀티 스케일 특징 데이터 및 상기 제1 프레임과 연관된 제2 특징 데이터를 이용하여 상기 제1 프레임에 대한 깊이 맵을 획득하도록 제어될 수 있 다."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예에 의해, 다시점 비디오 이미지 입력에 대한 깊이맵을 추정하는 방법, 장치 및 컴퓨터 판독 가능 매체가 제공될 수 있다. 본 개시의 다양한 실시예에 의해, 종단 간 방식에 기초한 비디오 깊이 추정 네트워크 및 geometry-temporal coupling 모듈을 활용하는 방법, 장치 및 시스템을 제공함에 있다. 본 개시의 다양한 실시예에 의해, 에피폴라 어텐션(epipolar Attention)을 사용하여 멀티 스케일 기하학적 특징 이 효율적으로 생성되고, 멀티 스케일 특징 압축을 통해 다음 모듈에 대한 효과적인 입력 텐서(input tensor)를 획득하기 위한 압축 동작이 수행될 수 있다. 본 개시의 다양한 실시예에 의해, 의사-깊이(pseudo-depth) 안내가 있는 시간적 일관성 모듈로 컨벌루션 LSTM을 적용함으로써 인접한 순차 프레임 간의 시간적 일관성이 향상될 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나, 이는 본 개시를 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어 야 한다. 도면에서 유사한 기준부호는 여러 측면에 걸쳐서 동일하거나 유사한 기능을 지칭한다. 도면에서의 요 소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 후술하는 예시적 실시예들에 대한 상세한 설명은, 특정 실시예를 예시로서 도시하는 첨부 도면을 기준한다. 이들 실시예는 당업자가 실시예를 실시할 수 있기에 충분하도록 상세히 설명된다. 다양한 실시예들은 서로 다르지만 상호 배타적일 필요는 없음이 이해되어 야 한다. 예를 들어, 여기에 기재되어 있는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 개시의 정신 및 범위를 벗어나지 않으면서 다른 실시예로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소 의 위치 또는 배치는 실시예의 정신 및 범위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로서 취하려는 것이 아니며, 예시적 실시예들의 범위는, 적절하게 설명된 다면, 그 청구항들이 주장하는 것과 균등한 모든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 본 개시에서 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으 로만 사용된다. 예를 들어, 본 개시의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재 된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 개시의 어떤 구성 요소가 다른 구성 요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성 요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있으나, 중간에 다른 구성 요소가 존재할 수 도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다거나 \"직접 접 속되어\"있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 개시의 실시예에 나타나는 구성부들은 서로 다른 특징적인 기능들을 나타내기 위해 독립적으로 도시되는 것으로, 각 구성부들이 분리된 하드웨어나 하나의 소프트웨어 구성단위로 이루어짐을 의미하지 않는다. 즉, 각 구 성부는 설명의 편의상 각각의 구성부로 나열하여 포함한 것으로 각 구성부 중 적어도 두개의 구성부가 합쳐져 하나의 구성부로 이루어지거나, 하나의 구성부가 복수 개의 구성부로 나뉘어져 기능을 수행할 수 있고 이러한 각 구성부의 통합된 실시예 및 분리된 실시예도 본 개시의 본질에서 벗어나지 않는 한 본 개시의 권리범위에 포 함된다. 본 개시에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 즉, 본개시에서 특정 구성을 \"포함\"한다고 기술하는 내용은 해당 구성 이외의 구성을 배제하는 것이 아니며, 추가적인 구성이 본 개시의 실시 또는 본 개시의 기술적 사상의 범위에 포함될 수 있음을 의미한다. 본 개시의 일부의 구성 요소는 본 개시에서 본질적인 기능을 수행하는 필수적인 구성 요소는 아니고 단지 성능 을 향상시키기 위한 선택적 구성 요소일 수 있다. 본 개시는 단지 성능 향상을 위해 사용되는 구성 요소를 제외 한 본 개시의 본질을 구현하는데 필수적인 구성부만을 포함하여 구현될 수 있고, 단지 성능 향상을 위해 사용되 는 선택적 구성 요소를 제외한 필수 구성 요소만을 포함한 구조도 본 개시의 권리범위에 포함된다. 이하, 도면을 기준하여 본 개시의 실시 형태에 대하여 구체적으로 설명한다. 본 명세서의 실시예를 설명함에 있 어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 명세서의 요지를 흐릴 수 있다고 판단되는 경우에 는 그 상세한 설명은 생략하고, 도면상의 동일한 구성요소에 대해서는 동일한 기준부호를 사용하고 동일한 구성 요소에 대해서 중복된 설명은 생략한다. 본 개시에서 제안하는 시스템 및/또는 방법/장치(이하 '시스템'으로 간단히 표현함)는 비디오 이미지 입력에 대 한 깊이 맵을 추정하는 기술에 관한 것이다. 즉, 본 개시는 움직이는 카메라로 촬영한 비디오 영상에 기초하여 프레임 별로 깊이 맵을 추출하는 방법에 관한 것이다. 비디오 영상의 각 프레임에 대한 깊이 맵을 추출하는 방법은 개별 프레임에 포함된 단안 깊이 정보를 활용하는 방법 및 인접 프레임과의 대응점 정보를 이용하는 멀티 뷰 기반 깊이 맵 추출 방법 등을 포함할 수 있다. 멀티 뷰 기반 깊이 맵 추출 방법은 보다 정확하게 깊이 맵을 추출할 수 있으나, 처리해야할 데이터의 크기가 클 뿐만 아니라 4-D(dimension) 비용(cost) 볼륨 형성에 따라 부담이 클 수 있다. 단안 깊이 정보를 활용하는 방법 은 처리 속도는 빠르나 프레임 간 깊이 스케일의 일관성이 떨어지는 현상이 자주 발생한다는 문제점이 존재한다. 상술된 문제점을 해결하기 위하여, i) epipolar 어텐션을 이용하여 깊이 맵을 추출하는 방법 및 ii) RNN(recurrent neural network)에 기초한 프레임 간 정보 전파 방식으로 깊이 맵을 추출하는 방법 등이 도입되 었다. 본 개시는 i) 및 ii) 방법을 하나의 종단 간 학습 가능한 모델로 통합하여 보다 효율적으로 깊이 맵을 추출하는 방법에 관한 것이다. 뿐만 아니라, 본 개시에 따르면, 멀티스케일 특징 압축 및 유사 깊이 가이던스(guidance) 모듈을 이용하여 깊이 맵을 추출하는 성능을 높일 수 있다. 본 개시는 시간적 일관성(temporal consistency) 및 추론 속도(inference speed)를 개선하고 학습 절차의 비효 율성을 해결하기 위한 비디오 이미지 입력에 대한 깊이맵을 추정하는 기술(즉, CMVDE (End-to-End Temporal Consistent Multi-view Video Depth Estimation) 기술)에 관한 것이다. 여기서, CMVDE는 의사 깊이 안내 (pseudo depth-guided) 컨벌루션 (convolutional) LSTM (long-short term memory)을 사용하는 효율적인 epipolar Attention 기반 기하학적 일관성(geometric consistency) 모듈 및 시간 적 일관성(temporal consistency) 모듈이 결합된 종단 간 네트워크를 의미한다. 즉, CMVDE는 단일 단계 학습 절차를 허용하는 딥 러닝 기반의 기하학적-시간적 일관된 다시점 비디오 깊이 추정 네트워크를 의미한다. CMVDE가 적용될 경우, 평면 스윕(plane sweep) 방법에 기초한 종래의 일관된 비디오 깊이 추정 모델에 비해 더 빠른 추론 속도가 도출될 수 있다. 그리고, 본 개시는 XR(eXtended Reality), 메타버스(Metaverse)와 같은 차세대 서비스를 포함한 실제 상황에 유 용하게 적용될 수 있다. 본 개시의 CMVDE(이하, '네트워크')에서는 추론 과정에서 정확한 기하학적 정보가 요구되는 불편함을 해결하기 위해 기하학적 안내로 의사-깊이(pseudo-depth) 맵이 사용될 수 있다. 본 개시는 epipolar Attention 모듈 및 시간적 모듈(Temporal module)을 종단 간 방식으로 결합하여 비디오 깊 이 추정 일관성을 향상시킬 수 있다. 본 개시에 따른 네트워크는 로우-레벨 및 하이-레벨 특징 맵을 함께 융합 하기 위한 새로운 멀티 스케일 특징 압축 모듈을 포함할 수 있다. 여기서, 네트워크의 시간적 일관성 모듈은 평면 스윕 알고리즘에 의해 생성되지는 않지만 다중 보기 신호를 효 과적으로 학습될 수 있다.또한, 본 개시에 따른 네트워크는 의사 깊이 유도 컨벌루션 LSTM을 사용하여 시간 일관성 모듈을 추가함으로써 깊이 추정 프레임워크를 확장할 수 있다. 이에 따라, 프레임 선택 기술 없이 은닉 상태 전파가 생성될 수 있다. 도 1은 본 개시의 일 실시예에 따른, 장치에 의해 수행되는 비디오 이미지 입력에 대한 깊이 맵을 추정하는 방 법을 설명하기 위한 순서도이다. 본 개시를 설명함에 있어서, 장치는 스마트 폰, 데스크 탑, 태블릿 PC, 노트북, 서버 장치, 웨어러블 장치 등을 포함할 수 있다. 다만, 이는 일 실시예에 불과하며, 장치는 다양한 유형의 전자 장치로 구현될 수 있다. 또한, 도 1을 참조하여 설명하는 비디오 이미지 입력에 대한 깊이 맵을 추정하는 방법은 컴퓨터 판독 가능 매체 에 의해 수행/제어될 수 있다. 장치는 영상을 구성하는 복수의 프레임 중 제1 프레임에 대한 제1 특징 데이터를 추출할 수 있다(S110). 여기서, 제1 프레임(또는, 기준 프레임(reference frame))은 깊이 맵을 추정/획득하고자 하는 프레임을 의미한 다. 구체적으로, 도 2a를 기준하면, 장치는 제1 프레임(또는, 제1 프레임의 이미지)으로부터 제1 프레임에 대 한 제1 특징 데이터(또는, 제1 특징 맵)을 획득할 수 있다. 한편, 영상을 구성하는 복수의 프레임 각각에서 추출된 제1 특징 데이터는 멀티 스케일 특징 데이터의 모음으로 구성될 수 있다. 이 때, 각 스케일 별로 제1 특징 데이터 추출 및 관련 연산이 수행될 수 있다. 장치는 복수의 프레임 중 제2 프레임에 대한 제1 특징 데이터와 제1 프레임에 대한 제1 특징 데이터 간의 유사 도에 기초하여, 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특징 데이터를 획득할 수 있다(S120). 여기서, 제2 프레임(또는, 소스 프레임)은 영상을 구성하는 복수의 프레임 중 (제1 특징 데이터의 깊이 맵을 추 출하기 전에) 미리 깊이 맵을 추출한 프레임을 의미할 수 있다. 즉, 제2 프레임은 제1 프레임에 대한 깊이 맵을 추출하기 전에 깊이 맵이 추출된 프레임을 의미하며, 하나 이상일 수 있다. 일 예로, 도 2b를 기준하면, 장치는 제2 프레임에 대한 제1 특징 데이터(즉, 소스 프레임(또는, 이미지)의 제1 특징 데이터)와 제1 프레임에 대한 제1 특징 데이터(즉, 기준 프레임(또는, 이미지)의 제1 특징 데이 터) 간의 유사도에 기초하여 제1 프레임에 대한 제1 특징 데이터로부터 멀티 스케일 특징 데이터를 획득할 수 있다. 즉, 장치는 상기 유사도에 기초하여 제1 프레임에 대한 제1 특징 데이터를 변형할 수 있 다. 구체적으로, 장치는 깊이 값 후보 별로 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀(예로, (x, y)) 및 제2 프레임에 대한 제1 특징 데이터의 특정 픽셀 간의 유사도(즉, 어텐션 스코어(attention score))를 획 득할 수 있다. 예로, 장치는 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀(x, y)에서의 특징 벡터( )(24 5)를 추출할 수 있다. 그리고, 장치는 제2 프레임에 대한 제2 특징 데이터의 특정 픽셀(x, y) 지점에서 깊이 값 후보 별로 특징 벡터를 산출할 수 있다. 예로, 장치는 특징 픽셀 지점에서 깊이가 dj인 (backward-) 워프된(warped) 특징 벡터( ) 및 깊이가 di인(backward-) 워프된(warped) 특징 벡터( ) 를 추출할 수 있다. 본 개시를 설명함에 있어서, 호모그래픽 워핑(homographic) 워핑(warping)은 특징 이미지(예로, 제1 프레임의 이미지)의 픽셀들을 특정 깊이 값(예로, d)로 역투영(un-projection)한 뒤 다른 이미지(예로, 제2 프레임의 이 미지) 시점으로 재투영하는 동작을 의미할 수 있다. 그리고, 장치는 각 깊이 샘플 di 별로 유사도(즉, 어텐션 스코어)(Ai,x,y)를 수학식 1 및 2를 이용하여 산출할 수 있다. 수학식 1에서 Sim은 길이 C인 두 벡터의 유사도를 산출하는 함수를 의미하며 코사인 유사도가 사용될 수 있다.수학식 1"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 개시를 설명함에 있어서, 깊이 샘플은 각 픽셀에서 가능 여부를 검토할 깊이 값의 모음(예로, [d0, d1, d2, ..., dN-1]을 의미할 수 있다. 그리고, 장치는 epipolar attention 기반 깊이 인코딩(depth encoding) 가중합을 더함으로써 멀티 스케일 특징 데이터를 획득(즉, 제1 프레임의 제1 특징 데이터를 변형)할 수 있다. 구체적으로, 장치는 깊이 값 후보 별로 산출된 유사도 및 깊이 값 후보 각각에 대응되는 특징 벡터 간의 곱 연 산을 수행할 수 있다. 장치는 곱 연산을 수행한 결과를 합산할 수 있다. 그리고, 장치는 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀에 대해 합산된 곱 연산 결과를 합산하여 멀티 스케일 특징 데이터를 획득할 수 있다. 일 예로, 도 2c를 참조하면, 장치는 각 깊이 값 후보(즉, 깊이 샘플)(d0, d1, 쪋 dN-1) 별로 산출된 유사도(또는, 어텐션 스코어)(A0,x,y, A1,x,y, ... AN-1,x,y) 및 깊이 값 후보 각각에 대응되는 특징 벡터(즉, 깊이 값 후보 각각에 대응되는 깊이 임베딩) 간의 곱 연산을 수행할 수 있다. 그리고, 장치는 제1 프레임에 대한 제1 특징 데이터의 특정 픽셀에 대해 상기 합산된 곱 연산 결과를 합산하여 멀티 스케일 특징 데이터를 획득(즉, 제1 프레임에 대 한 제1 특징 데이터를 변형)할 수 있다. 여기서, 깊이 값 후보 각각에 대응되는 특징 벡터는 미리 설정(또는, 정의)되거나, 전체 네트워크(즉, 후술할 일관성 모듈(geometric consistency module, GCM), 시간적 일관성 모듈(Temporal consistency module, TCM) 및 멀티-스케일 특징 디코더(multi-scale feature decoder)의 전체 네트워크)의 학습 과정에서 학습될 수 있다. 구체적으로, 특징 벡터를 전체 네트워크(예로, 깊이 추정 모델)을 구성하는 파라미터의 하나로 간주될 수 있으며, 이를 통해 해당 모델의 학습이 수행될 수 있다. 예로, 장치는 각 픽셀/깊이에 대응되는 데이터에 기초하여 각 깊이 값 후보 각각에 대응되는 특징 벡터를 획득 할 수 있다. 장치는 멀티 스케일 특징 데이터, 제2 프레임의 깊이 맵, 및 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여, 제1 프레임과 연관된 제2 특징 데이터를 획득할 수 있다(S130). 여기서, 제2 프레임의 깊이 맵은, 제2 프레임에 대해 별도의 깊이 맵 추출 알고리즘(예로, 유사 깊이 맵 생성 알고리즘)을 적용하여 획득되거나, ii) 제2 프레임에 대한 제1 특징 데이터 및 제2 프레임의 깊이 맵과 연관된 제2 특징 데이터에 기초하여 획득될 수 있다. 즉, 장치는 제2 프레임에 대해 별도의 깊이 맵 추출 알고리즘을 적용하여 제2 프레임의 깊이 맵을 획득하거나, 도 1에서 설명하는 방식에 따라 제2 프레임의 깊이 맵을 획득할 수 있다. 구체적으로, 장치는 멀티 스케일 특징 데이터를 멀티 스케일 특징 압축 모듈에 입력하여 압축된 특징 데이터를 획득할 수 있다. 장치는 압축된 특징 데이터, 제2 프레임의 깊이 맵, 및 제2 프레임의 깊이 맵과 연관된 제2 특 징 데이터를 인공지능 모델에 입력하여 제1 프레임과 연관된 제2 특징 데이터(예로, 도 3의 현재 프레임(즉, 제 1 프레임)과 연관된 셀 상태(CT), 현재 프레임의 은닉 상태와 연관된 특징 맵(HT))를 획득할 수 있다. 여기서, 인공지능 모델은 컨볼루션 레이어 기반의 LSTM(long-short term memory)를 포함할 수 있다. 장치는 멀티 스케일 특징 데이터 및 제1 프레임과 연관된 제2 특징 데이터를 이용하여 제1 프레임에 대한 깊이 맵을 획득할 수 있다(S140).구체적으로, 장치는 인코딩된 멀티 스케일 특징 데이터 및 제1 프레임과 연관된 제2 특징 데이터를 연결 (concatenation)한 후 이를 디코더(decoder)에 입력하여 상기 제1 프레임에 대한 깊이 맵을 획득할 수 있다. 도 3은 본 개시의 일 실시예에 따른, CMVDE의 전체적인 구조를 나타내는 도면이다. 도 3에 도시된 바와 같이, CMVDE는 기하학적 일관성 모듈(geometric consistency module, GCM), 시간적 일 관성 모듈(Temporal consistency module, TCM) 및 멀티-스케일 특징 디코더(multi-scale feature decoder)를 포함할 수 있다. TCM은 기준 프레임(reference frame)에 앞서는 소스 프레임(source frame)에 대해 추출된 깊이 맵이 있는 것으로 가정할 수 있다. 예로, 소스 프레임에 대해 추출된 깊이 맵이 존재하는 경우는 앞선 단계에서 깊이 맵을 추출하였거나, ground-truth 값이 존재하거나, 또는 유사 깊이 값이 주어진 경우 등을 포함할 수 있다. TCM에 포함된 ConvoLSTM 모듈은 상기 깊이 맵을 이용하여 기준 프레임의 카메라 시점으로 소스 프레임의 은 닉 상태의 특징 맵을 워핑(warping)시킨 HT-1 및 CT-1을 출력할 수 있다. 여기서, CT-1은 소스 프레임에 대한 깊이 맵을 산출하는 과정에서 도출될 수 있다. ConvoLSTM 모듈은 HT-1, CT-1, 및 GCM에서 출력된 T가 입력될 때 HT 및 CT를 출력할 수 있다. 즉, TCM은 이전 프레임에서 깊이 맵을 추출하면서 같이 산출된 은닉 상태 및 셀 상태를 기준함으로써 깊이 특징 관련 일관성을 증진할 수 있다. 멀티-스케일 특징 디코더는 GCM에서 출력된 최종 멀티-스케일 기준 특징 및 TCM에서 출력된 현재 프레임의 은닉 상태 특징맵을 디코더에 입력하여 최종 깊이 맵을 획득할 수 있다. 사전 학습된 인코더 모델(예로, ResNet-18 등)(즉, 특징 추출기(feature extractor))은 멀티 스케일 이미 지 특징(예로, FT, FT-1, 및 FT-2)을 생성할 수 있다. EAM(Epipolar Attention Module)은 타겟 시점 프레임에서만 기하학적 특징을 생성할 수 있다. 멀티-스케일 특징 압축 모듈(70-1, 70-2)은 로우-레벨(low level)에서 하이-레벨까지 다양한 공간 특징을 고려 하면서 멀티스케일 특징의 채널과 해상도를 줄여 압축된 특징 맵 FT 및 FT-1을 생성할 수 있다. TCM은 멀티 스케일 특징 압축을 통해 압축된 현재 특징 맵 및 이전 은닉 상태, 의사-깊이(pseudo-depth) 맵 을 고려하여 새로운 은닉 상태를 생성할 수 있다. 멀티-스케일 특징 디코더에 멀티 스케일 타겟 시점 특징 및 은닉 상태가 입력될 수 있다. 마지막으로 멀티- 스케일 특징 디코더의 출력 깊이 특징이 회귀(regressed)되고, 이는 4x로 업스케일링하여 최종 깊이 맵이 생성될 수 있다. 구체적으로, 어텐션 메커니즘이 단안 추정 백본(backbone) 네트워크에 통합되므로 GCM은 4D 코스트 부피를 생성하는 기존의 멀티 시점 깊이 추정 모듈과 다르게 구성될 수 있다. GCM은 계산량을 감소시킬 수 있으며, TCM의 추가를 허용할 수 있다. GCM은 입력 이미지 시퀀스 간의 기하학적 정보를 포함하는 특정 맵(feature map)을 생성할 수 있다. GCM의 출력 특징 맵은 기하학적 특징으로 표현될 수 있다. 단일 시점에 대한 특징 맵에 대해 멀티 시점 기하학 정보를 추가하기 위하여, GCM에 포함된 EAM(Epipolar Attention Module)이 사용될 수 있다. EAM 은 2D 컨볼루션 네트워크로 구성될 수 있으며, 기존 4D 코스트 볼륨 (cost volume) 생성 방식에 비해 순차적인 프레임 간의 기하학적 정보를 효율적으로 획득할 수 있다. GCM은 인코더(예로, ResNet-18 등)를 이용하여 입력된 이미지(예로, 소스 이미지(40-1, 40-2) 및 기준 이미지 등의 멀티 스케일 특징 맵(예로, FT, FT-1 , FT-2)을 추출할 수 있다. 특징 맵은 원래(original) 입력 이미지의 1/8, 1/16 및 1/32 해상도로 세 가지 다른 스케일에서 획득될 수 있다. 멀티 스케일 특징 추출의 특징 맵은 EAM에 활용될 수 있다. 본 개시를 설명함에 있어서, 기준 이미지(IT)는 현재 깊이 값을 추출하는 이미지를 의미하며, 소스 이미지 (IT-1, IT-2)(40-1, 40-2)는 이전에 깊이를 추출했던 이미지를 의미할 수 있다. EAM은 기하학적 정보를 획득하고 깊이를 효율적으로 추론하는 데 사용될 수 있다. EAM은 기준 프레임(즉, 기준 이미지의 프레임)의 픽셀과 소스 프레임(즉, 소스 이미지(40-1, 40-2)의 프레임)의 에피폴라 라인 픽셀 간 의 기하학적 관계를 나타낼 수 있다. EAM에서 키(key), 쿼리(query) 및 값(value)은 완전히 연결된 단일 레이어(fully-connected layer)인 학습 가 능한 임베더(embedder)에 의해 개별적으로 임베딩될 수 있다. 예로, 키는 기준 시점 특징 맵의 임베딩을 의미하며, 쿼리는 소스 시점 특징 맵의 임베딩을 의미하며, 값은 최 소 깊이 값과 최대 깊이 값 사이에서 역균일하게(inverse-uniformly) 샘플링된 Nd 깊이 가설(depth hypothesis) 값의 임베딩을 의미할 수 있다. 상술한 바와 같이, EAM은 2D 컨벌루션 네트워크로만 구성되어 있는 바, 평면 스윕(plane sweep) 알고리즘 기반 의 시간적 일관된 비디오 추정 모델에 의존하는 이전 모델에 비해 속도가 향상될 수 있다. 입력된 순차 프레임 간의 기하학적 일관성을 고려하기 위하여, EAM은 기하학적 지식을 포함하는 각 스케일 i 어 텐션 스코어 맵을 생성할 수 있다. 기준 시점에서 기하학적 특징 생성 과정은 수학식 3 및 수학식 4와 같을 수 있다. 수학식 3"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3 및/또는 수학식 4에서, E는 표준 인코더(예로, ResNet-18 등) 특징 추출기를 의미하고, G는 학습 가능 한 선형 임베더를 의미할 수 있다. 도 4에 도시된 바와 같이, 각 깊이 값에 대해 소스 프레임을 기준 시점으로 워핑(warping)되고, 워핑된 소스 시 점 특징 맵 및 기준 시점 특징 맵 간에 어텐션 스코어 맵 이 산출될 수 있다. 그리고, 스케일 i의 기준 시점 특징 맵( )은 어텐션 스코어 맵 , 이미지 특징 맵(E( ) 및 출력 선형 임베딩(G(E( ))을 합산하여 획득될 수 있다. 두 시점에 걸쳐 Attention 알고리즘이 적용될 경우, 프레임 간 의 기하학적 일관성이 향상될 수 있다. 멀티 스케일 특징 맵을 TCM에 공급하기 전에, GCM의 멀티 스케일 특징 압축기(Multi-scale Feature Compressor, MFC)는 네트워크 매개변수의 수와 계산 비용이 증가하지 않도록 멀티 스케일 특징 맵을 압축할 수 있다. MFC는 다양한 해상도와 채널을 포함하는 특징 맵을 압축하고 연결할 수 있다. 인코더 출력에 많은 수의 채널이 있는 경우, MFC에 의한 압축 동작을 통해 느린 추론 속도와 잠재적인 성능 저하를 방지할 수 있다. 도 5는 본 개시의 일 실시예에 따른, MFC의 전체 구조를 나타낸다. 공간 특징(spatial feature)이 다양한 해상도 크기로 널리 분포되어 있기 때문에, MFC는 확장된 2D CNN을 사용 하여 기하학적 정보를 추출하여 수용 필드(receptive field)를 확장할 수 있다.규모가 더 큰 특징 맵의 경우, MFC는 더 큰 팽창(dilation) 매개변수 값을 적용할 수 있다. 그리고, MFC는 평균 2D 풀링(Pooling) 알고리즘을 적용하여 확장된 컨볼루션의 출력 크기를 조정하고 모든 압축된 특징 맵을 연결할 수 있다. MFC를 사용하여 로우-레벨 및 하이-레벨 특징에 걸쳐 다양한 공간 정보를 융합하여 특징 표현의 품질을 향상시 킬 수 있다. TCM은 입력된 순차 프레임 간의 시간적 일관성 정보를 계산하고, 이를 멀티-시점 기하 특징 맵에 통합하여 깊이 추정 정확도를 향상시킬 수 있다. 연속 프레임(예로, IT-2, IT-1, IT)의 시간적 일관성을 향상시키기 위하여, TCM의 백-본(back-bone)으로서 ConvLSTM(Convolutional LSTM)이 사용될 수 있다. ConvLSTM 모듈을 통합하는 기존 비디오 깊이 추정 네트워크는 일반적으로 대상 프레임 정보에서만 파생된 특징 맵에 의존하였다. 대조적으로, 본 개시에 따른 TCM은 3개의 순차적 프레임의 멀티 시점 기하적 특징을 캡처 하는 특징 맵을 활용함으로써 기하학적 특징이 보다 효율적으로 반영될 수 있다. 또한, 네트워크 파이프라인에 종단 간 아키텍처를 채택함으로써, 단일 단계 학습을 가능하게 하고 학습 효율성 이 향상될 수 있다. TCM은 기존 비디오 깊이 추정 방법에서 사용되는 프레임 선택 기술이 필요하지 않으므로 전체 데이터 준비 프로세스가 단순화될 수 있다. 일 예로, TCM의 상세한 구조는 도 6와 같을 수 있다. 도 6에 도시된 각 파라 미터 관계는 수학식 5 내지 수학식 8과 같이 구현될 수 있다. 수학식 5"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 6"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 7 수학식 8"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "수학식 5에서 시간 T에서의 카메라 투영(projection) 행렬 PT는 세계(world)에서 카메라 좌표로의 변환에 기초 할 수 있다. 행렬 KT 및 [RT | tT]는 각각 타겟 시점에서 카메라 고유(intrinsic) 파라미터 및 상대 카메라 포즈 를 나타낼 수 있다. 그리고, 이전 시간에 입력된 은닉 상태(hidden state)(HT-1)가 다음 hidden state(HT)로 변환되므로, 수학식 6에 제시된 바와 같이 이는 입력 특징 맵의 카메라 좌표로 워핑될 수 있다. 이전 은닉 상태(HT-1)는 깊이 맵 안내(DT- 1)를 사용하여 입력 특징 맵 좌표로 워핑될 수 있다. 워핑된 은닉 상태( )는 압축된 특징 맵( )과 연결될 수 있다. 마지막으로 은닉 상태 전파 프로세스는 수학식 7와 8에 제시된 대로 다음 은닉 상태를 생성할 수 있다. 셀의 각 출력은 식 수학식 7에서 ConvLSTM의 게이트 값을 나타낼 수 있다. TCM에서 의사-깊이(pseudo-depth) 안내(guided) 은닉 상태 워핑이 수행될 수 있다. 이전 은닉 상태의 좌표계를 현재 특징 맵과 정렬하면 좌표계 불일치로 인한 노이즈를 효과적으로 완화할 수 있 으므로 깊이 추정의 정확도와 시간적 일관성이 향상될 수 있다. 이를 위해 TCM은 깊이 맵을 활용하여 은닉 상태에 처리할 수 있다. 구체적으로, TCM은 이전 은닉 상태 와 현재 특징 맵 간의 관계를 정의하여 일관성 정보를 포함하는 다음 은닉 상태를 계산할 수 있다. TCM은 좌표계를 변환하기 위해 두 시간 인스턴스 사이의 호모그래피(homography) 행렬을 활용할 수 있다. 기하 프라이얼스(geometric priors)는 수학식 9과 같이 호모그래피 워핑 표현식의 d 값으로 지정될 수 있다. 수학식 9"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "TCM이 포함된 네트워크는 실제 상황에 초점을 맞추기 때문에 은닉 상태 워핑에 사용되는 깊이 맵은 훈련 단 계와 테스트 단계에서 각각 다를 수 있다. 학습 중에 은닉 상태는 이전과 같이 정확한 기하학적 안내를 제공하는 실측 깊이 맵을 사용하여 워핑될 수 있다. 반대로 의사 깊이 맵은 테스트 중에 사용될 수 있다. 실측 깊이 맵이 존재하지 않는 경우와 같은 실제 시 나리오에서 상당한 이점이 제공될 수 있다. 입력 비디오 콘텐츠의 절대 깊이 스케일은 실측 깊이 맵으로 훈련되기 때문에 예측된 깊이 맵은 내재된 상대 깊 이 스케일이 있는 의사 깊이 맵을 사용하는 동안 불변일 수 있다. 따라서 실제 상황에 적용하기 위해서는 유사 깊이 맵을 기하 프라이얼스(geometric priors)으로 활용하는 것이 적합할 수 있다. 의사 깊이 맵은 단안 깊이 추정 모델에 의해 생성될 수 있다. 최종 깊이 맵은 멀티 스케일 특징 디코더에서 은닉 상태 HT와 기준 이미지 특징 맵을 결합하여 획득될 수 있다. 멀티 스케일 특징 디코더는 3개의 블록으로 구성될 수 있다. 일 예로, 멀티 스케일 특징 디코더에 포함된 3개의 블록은 도 7과 같다. 일 예로, 출력 깊이 특징 맵은 원 본 입력 영상 해상도의 1/4 크기일 수 있다.그 후, 멀티 스케일 특징 디코더는 깊이 회귀 방법(depth regression method)을 사용하여 깊이 맵을 산출할 수 있다. 멀티 스케일 디코더를 통해 산출된 최종 깊이 특징 맵에 소프트 맥스 함수를 적용하여 깊이 확률 맵이 획득될 수 있다. Nk 깊이 가설 평면이 있는 픽셀 당 최종 깊이 기대치는 수학식 10과 같다. 수학식 10"}
{"patent_id": "10-2023-0112759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 10, "content": "도 8은 본 개시의 실시예에 따른 장치를 예시하는 블록도이다. 도 8을 기준하면, 장치는 본 개시에서 설명된 영상을 구성하는 복수의 프레임에 대한 깊이 맵을 추출하는 방법을 실행하는 장치를 나타낼 수 있다. 예로, 장치는 움직이는 카메라로 촬영한 비디오 영상에 기초하여 프레임 별로 깊이 맵을 추출할 수 있다. 장치는 프로세서, 메모리, 송수신부, 입력 인터페이스 장치 및 출력 인터페이스 장치 중 적어도 하나를 포함할 수 있다. 각각의 구성 요소들은 공통 버스(bus)에 의해 연결되어 서로 통 신을 수행할 수 있다. 또한, 각각의 구성 요소들은 공통 버스가 아니라, 프로세서를 중심으로 개별 인터페이스 또는 개별 버스를 통하여 연결될 수도 있다. 프로세서는 AP(Application Processor), CPU(Central Processing Unit), GPU(Graphic Processing Unit) 등과 같은 다양한 종류들로 구현될 수 있으며, 메모리에 저장된 명령을 실행하는 임의의 반도체 장 치일 수 있다. 프로세서는 메모리에 저장된 프로그램 명령(program command)을 실행할 수 있다. 프로 세서는 상술한 도 1 내지 도 7를 토대로 설명한 움직이는 카메라로 촬영한 비디오 영상에 기초하여 프레임 별로 깊이 맵을 추출하는 방법을 수행할 수 있다. 프로세서는 움직이는 카메라로 촬영한 비디오 영상에 기초하여 프레임 별로 깊이 맵을 추출하기 위한 하나 이상의 모듈을 포함할 수 있다. 그리고/또는, 프로세서는 하나 이상의 모듈들에 대한 적어도 하나의 기능을 구현하기 위한 프로그램 명령 을 메모리에 저장하여, 도 1 내지 도 7에 기반하여 설명된 동작이 수행되도록 제어할 수 있다. 즉, 도 1 내지 도 7에 따른 각 동작 및/또는 기능은 하나 이상의 프로세서에 의해 실행될 수 있다. 메모리는 다양한 형태의 휘발성 또는 비 휘발성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(read-only memory) 및 RAM(random access memory)을 포함할 수 있다. 본 개시의 실시예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는 이미 알려진 다양한 수단을 통해 프로세서 와 연결될 수 있다. 예를 들어, 메모리는 영상을 구성하는 복수의 프레임 각각에 대한 제1/제2 특징 데이터 및 깊이 맵을 저장 할 수 있다. 송수신부는 프로세서에서 처리된/처리될 데이터를 외부 장치 및/또는 외부 시스템과 송수신하는 기능 을 수행할 수 있다. 예를 들어, 송수신부는 다른 단말 장치와 데이터 교환 등에 활용될 수 있다. 입력 인터페이스 장치는 데이터를 프로세서로 제공하도록 구성된다. 출력 인터페이스 장치는 프로세서로부터의 데이터를 출력하도록 구성된다. 본 개시의 예시적 실시예들에서 설명된 구성요소는, 하드웨어 요소에 의해 구현될 수 있다. 예를 들어, 상기 하 드웨어 요소는, 디지털 신호 프로세서(DSP), 프로세서, 컨트롤러, 주문형 집적 회로(ASIC), FPGA와 같은 프로그 래머블 로직 요소, GPU, 기타 전자 장치, 또는 이들의 조합 중 적어도 하나를 포함할 수 있다. 본 개시의 예시 적 실시예들에서 설명된 기능 또는 과정 중 적어도 일부는 소프트웨어로 구현될 수 있으며, 소프트웨어는 기록 매체에 기록될 수 있다. 예시적 실시예들에서 설명하는 구성요소, 기능 및 프로세스는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 본 개시의 일 실시예에 따른 방법은 컴퓨터에 의해 수행될 수 있는 프로그램으로 구현될 수 있으며, 상기 컴퓨 터 프로그램은 자기 저장 매체, 광 판독 매체, 디지털 저장 매체 등과 같은 다양한 기록 매체에 기록될 수 있다. 본 개시에서 설명한 다양한 기술들은, 디지털 전자 회로 또는 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 또는 이들 의 조합으로 구현될 수 있다. 상기 기술들은 컴퓨터 프로그램 제품, 즉, 정보 매체에 유형적으로 구현되는 컴퓨 터 프로그램 또는 컴퓨터 프로그램(예를 들어, 기계 판독 가능 저장 장치(예: 컴퓨터 판독 가능 매체) 또는 데 이터 처리 장치), 데이터 처리 장치에 의해 처리되거나 데이터 처리 장치(예를 들어, 프로그램 가능한 프로세서, 컴퓨터 또는 복수의 컴퓨터들)의 동작을 하기 위해 전파된 신호로 구현되는 컴퓨터 프로그램으로 구 현될 수 있다. 컴퓨터 프로그램(들)은 컴파일된 언어나 해석된 언어를 포함한 모든 형태의 프로그래밍 언어로 작성될 수 있으 며, 독립 실행형 프로그램 또는 모듈, 구성 요소, 서브루틴 또는 컴퓨팅 환경에서 사용하기에 적합한 기타 단위 를 포함하는 모든 형태로 배포될 수 있다. 컴퓨터 프로그램은 하나의 컴퓨터, 또는 한 사이트 또는 여러 사이트 에 분산되어 있고 통신 네트워크로 상호 연결되어 있는 복수 컴퓨터들에 의해 수행될 수 있다. 컴퓨터 프로그램의 실행에 적합한 프로세서의 예로, 범용 및 특수 목적 마이크로프로세서, 및 디지털 컴퓨터의 하나 이상의 프로세서가 포함된다. 일반적으로 프로세서는 읽기 전용 메모리나 랜덤 액세스 메모리 또는 둘 모 두에서 명령과 데이터를 수신한다. 컴퓨터의 구성 요소는 명령을 실행하기 위한 적어도 하나의 프로세서, 및 명 령 및 데이터를 저장하기 위한 하나 이상의 메모리 장치를 포함할 수 있다. 또한, 컴퓨터는 데이터 저장을 위한 하나 이상의 대용량 저장 장치, 예를 들어, 자기, 광자기 디스크 또는 광 디스크를 포함하거나, 상기 대용량 저 장 장치에 연결되어 데이터를 수신 및/또는 전송을 수행할 수 있다. 컴퓨터 프로그램 명령 및 데이터를 구현하 기에 적합한 정보 매체의 예로는, 반도체 메모리 장치(예를 들어, 하드 디스크, 플로피 디스크 및 자기 테이프 와 같은 자기 매체), 컴팩트 디스크 읽기 전용 메모리(CD- ROM), 디지털 비디오 디스크(DVD) 등과 같은 광학 매 체, 플롭티컬 디스크와 같은 광자기 매체, 및 ROM(Read Only Memory), RAM(Random Access Memory), 플래시 메 모리, EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM) 및 기타 알려진 컴퓨터 판독 가능 매체가 포함된다. 프로세서와 메모리는 특수 목적 논리 회로에 의해 보완되거나 통합될 수 있 다. 프로세서는 운영 체제(OS) 및 OS에서 실행되는 하나 이상의 소프트웨어 애플리케이션을 실행할 수 있다. 프로세 서 장치는 또한 소프트웨어 실행에 응답하여 데이터를/에 액세스, 저장, 조작, 처리 및 생성할 수 있다. 단순화 를 위해 프로세서 장치는 단수로 설명되었으나, 해당 기술 분야의 통상의 지식을 가진자는, 프로세서 장치가 복 수의 처리 요소들 및/또는 다양한 타입의 처리 요소들을 포함할 수 있음을 이해할 수 있다. 예를 들어, 프로세 서 장치는 복수 프로세서들 또는 프로세서(processor)와 제어부(controller)를 포함할 수 있다. 또한, 병렬 프 로세서들과 같이 상이한 처리 구조를 구성할 수도 있다. 또한, 컴퓨터가 읽을 수 있는 매체는 컴퓨터가 접근할 수 있는 모든 매체를 의미하며, 컴퓨터 저장매체와 전송매체를 모두 포함할 수 있다. 본 개시는 다양한 상세 구현 예들의 세부 설명을 포함하나, 그 세부 사항이 본 개시에서 제안하는 발명 또는 청 구 범위를 제한하는 것은 아니고, 특정한 예시적 실시예의 특징을 설명하는 것으로 이해되어야 한다. 본 개시에서 예시적 실시예들에서 개별적으로 설명된 특징들은 단일 예시적 실시예에 의해 구현될 수 있다. 반 대로, 본 개시에서 단일 예시적 실시예에 대해 설명된 다양한 특징들은 복수의 예시적 실시예들의 조합 또는 적 절한 하위 조합에 의해 구현될 수도 있다. 나아가, 본 개시에서, 상기 특징들은 특정 조합에 의해 동작할 수 있 고, 최초 상기 조합이 청구된 것처럼 기술될 수 있으나, 경우에 따라, 하나 이상의 특징이 청구된 조합에서 제 외되거나, 청구된 조합이 하위 조합 또는 하위 조합의 수정 형태로 변경될 수 있다. 마찬가지로, 도면에 특정 순서로 동작이 설명되어 있다 하더라도, 목표된 결과를 획득하기 위해, 동작들을 특정 순번 또는 순서로 실행하는 것이 필요하거나, 모든 동작들의 수행이 필요한 것으로 이해되어서는 안 된다. 특정한 경우에는 멀티태스킹과 병렬 처리가 유용할 수 있다. 또한, 모든 실시예들의 예시적 실시예들에서 다양한 장 치 구성요소들이 반드시 분리되어야 하는 것으로 이해되어서는 안 되며, 전술한 프로그램 구성요소 및 장치는 단일 소프트웨어 제품 또는 여러 소프트웨어 제품에 패키징될 수 있다. 본 명세서에 개시된 예시적 실시예들은 단지 예시적인 것이며 본 개시의 범위를 제한하려는 것이 아니다. 해당 기술 분야의 통상의 지식을 가진자는, 청구범위 및 그 균등물의 사상 및 범위를 벗어나지 않으면서 예시적 실시 예들에 대한 다양한 수정이 이루어질 수 있음을 인식할 수 있을 것이다. 따라서, 본 개시는 이하의 특허청구범위 내에 속하는 모든 다른 교체, 수정 및 변경을 포함한다고 할 것이다."}
{"patent_id": "10-2023-0112759", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른, 비디오 이미지 입력에 대한 깊이맵을 추정하는 설명하기 위한 순서도이다. 도 2a는 본 개시의 일 실시예에 따른, 제1 프레임에 대한 제1 특징 데이터를 추출하는 과정을 설명하기 위한 도 면이다. 도 2b는 본 개시의 일 실시예에 따른, 제1 프레임 및 제2 프레임 각각에 대한 제1 특징 데이터 간의 유사도를 산출하는 방법을 설명하기 위한 도면이다. 도 2c는 본 개시의 일 실시예에 따른, 멀티 스케일 특징 데이터를 획득하는 과정을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시예에 따른, CMVDE의 전체적인 구조를 나타내는 도면이다. 도 4는 본 개시의 일 실시예에 따른, epipolar 어텐션 알고리즘을 시각화한 도면이다. 도 5는 본 개시의 일 실시예에 따른, MFC의 전체 구조를 예시하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른, TCM의 구조 및 동작을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른, 멀티 스케일 특징 디코더의 구조 및 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 실시예에 따른 장치를 예시하는 블록도이다."}
