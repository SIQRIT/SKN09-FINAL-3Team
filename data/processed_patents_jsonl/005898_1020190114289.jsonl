{"patent_id": "10-2019-0114289", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0113692", "출원번호": "10-2019-0114289", "발명의 명칭": "군집 로봇을 이용하여 사용자의 위치를 추적하는 방법, 태그장치 및 이를 구현하는 로봇", "출원인": "엘지전자 주식회사", "발명자": "김정식"}}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "태그장치로부터 제1프로토콜에 기반한 신호를 수신하여 테그장치의 위치를 측정하는 측위 모듈; 상기 태그장치로부터 제2프로토콜에 기반한 신호를 수신하는 블루투스 모듈;주변에 배치된 장애물을 센싱하는 장애물 센서;상기 태그장치의 위치정보를 누적하여 저장하고, 상기 저장된 태그장치의 위치정보에 대응하는 이동 경로를 생성하며, 상기 태그장치로부터 전달된 상기 태그장치 주변의 군집로봇의 위치 추정 정보를 이용하여 상기 태그장치의 위치정보를 수정하는 제어부; 및상기 이동 경로를 따라 이동하는 이동부를 포함하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 측위 모듈 또는 상기 블루투스 모듈은 상기 위치 추정 정보를 수신하며, 상기 위치 추정 정보는 상기 태그장치의 움직임 정보, 상기 군집로봇의 위치 정보, 또는 상기 군집로봇이 상기제2프로토콜로 전송한 신호의 세기 정보 중 어느 하나 이상을 포함하는, 군집 로봇을 이용하여 사용자의 위치를추적하는 로봇."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제어부는 상기 태그장치의 움직임 정보를 추적하여 상기 로봇의 움직임을 제어하는, 군집 로봇을 이용하여사용자의 위치를 추적하는 로봇."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제어부는 상기 태그장치의 움직임 정보를 수신하고 상기 태그장치와의 거리를 일정 거리 이하로 유지하도록 상기 이동부를 제어하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 제어부는 상기 군집로봇의 위치 정보 또는 상기 세기 정보 중 어느 하나 이상을 이용하여 상기 태그 장치의 위치를 계산하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 공개특허 10-2019-0113692-3-상기 제1프로토콜은 UWB(Ultra-Wideband)이며, 상기 측위 모듈은 UWB 신호를 송수신하는 칩 및 UWB 필터를 포함하며 상기 측위 모듈은 상기 로봇에 두 개 이상 배치되며, 상기 UWB 필터는 상기 태그장치의 움직임 정보를 반영하여 상기 태그 장치의 위치를 추정하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제2프로토콜은 블루투스(Bluetooth)이며, 상기 블루투스 모듈은 블루투스 신호를 송수신하는 칩 및 블루투스 필터를 포함하며 상기 블루투스 모듈은 상기 군집로봇에 대한 상기 태그장치의 위치정보를 계산하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1프로토콜에 기반한 신호를 제1로봇에게 송신하는 측위 모듈; 제2프로토콜에 기반한 신호를 상기 제2로봇으로부터 수신하고 상기 제2프로토콜에 기반하여 상기 제1로봇에게신호를 송신하는 블루투스 모듈; 상기 블루투스 모듈이 상기 제2로봇으로부터 수신한 위치 정보 또는 상기 제2로봇이 상기 제2프로토콜로 전송한신호의 세기 정보를 상기 측위 모듈 또는 상기 블루투스 모듈을 제어하여 상기 제1로봇에게 송신하는 태그 제어부를 포함하는, 태그 장치."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 태그장치의 움직임을 센싱하는 움직임 감지 센서; 상기 움직임 감지 센서가 센싱한 값을 필터링하는 태그 필터를 더 포함하며, 상기 태그제어부는 상기 태그필터에서 산출된 상기 태그장치의 움직임 정보를 상기 측위 모듈 또는 상기 블루투스 모듈을 제어하여 상기 제1로봇에게 송신하는, 태그 장치."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 태그장치는 조작 신호를 수신하는 조작부를 더 포함하며, 상기 태그제어부는 상기 조작부의 조작에 따라 상기 태그장치의 움직임 정보의 송신을 제어하는, 태그 장치."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "측위 모듈이 태그장치로부터 제1프로토콜에 기반한 신호를 수신하여 상기 테그장치의 위치를 측정하는 단계; 블루투스 모듈이 상기 태그장치로부터 제2프로토콜에 기반한 신호를 수신하는 단계; 제어부가 상기 태그장치의 위치정보를 누적하여 저장하고, 상기 저장된 태그장치의 위치정보에 대응하는 이동공개특허 10-2019-0113692-4-경로를 생성하는 단계; 상기 제어부가 상기 태그장치로부터 전달된 상기 태그장치 주변의 군집로봇의 위치 추정 정보를 이용하여 상기태그장치의 위치정보를 수정하는 단계; 및이동부가 상기 이동 경로를 따라 로봇을 이동시키는 단계를 포함하는, 군집 로봇을 이용하여 사용자의 위치를추적하는 방법."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 측위 모듈 또는 상기 블루투스 모듈이 상기 위치 추정 정보를 수신하는 단계를 더 포함하며, 상기 위치 추정 정보는 상기 태그장치의 움직임 정보, 상기 군집로봇의 위치 정보, 또는 상기 군집로봇이 상기제2프로토콜로 전송한 신호의 세기 정보 중 어느 하나 이상을 포함하는, 군집 로봇을 이용하여 사용자의 위치를추적하는 방법."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 제어부는 상기 태그장치의 움직임 정보를 추적하여 상기 로봇의 움직임을 제어하는 단계를 더 포함하는,군집 로봇을 이용하여 사용자의 위치를 추적하는 방법."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 제어부는 상기 태그장치의 움직임 정보를 수신하고 상기 태그장치와의 거리를 일정 거리 이하로 유지하도록 상기 이동부를 제어하는 단계를 더 포함하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 방법."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서, 상기 제어부는 상기 군집로봇의 위치 정보 또는 상기 세기 정보 중 어느 하나 이상을 이용하여 상기 태그 장치의 위치를 계산하는 단계를 더 포함하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 방법."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 제1프로토콜은 UWB(Ultra-Wideband)이며, 상기 측위 모듈은 UWB 신호를 송수신하는 칩 및 UWB 필터를 포함하며 상기 측위 모듈은 상기 로봇에 두 개 이상 배치되며, 상기 UWB 필터는 상기 태그장치의 움직임 정보를 반영하여 상기 태그 장치의 위치를 추정하는 단계를 더 포함하는, 군집 로봇을 이용하여 사용자의 위치를 추적하는 방법."}
{"patent_id": "10-2019-0114289", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2019-0113692-5-제11항에 있어서, 상기 제2프로토콜은 블루투스(Bluetooth)이며, 상기 블루투스 모듈은 블루투스 신호를 송수신하는 칩 및 블루투스 필터를 포함하며 상기 블루투스 모듈은 상기 군집로봇에 대한 상기 태그장치의 위치정보를 계산하는 단계를 더 포함하는, 군집로봇을 이용하여 사용자의 위치를 추적하는 방법."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 군집 로봇을 이용하여 사용자의 위치를 추적하는 방법, 태그장치 및 이를 구현하는 로봇에 관한 것으 로, 본 발명의 일 실시예에 의한 로봇은 태그장치의 위치정보를 누적하여 저장하고, 저장된 태그장치의 위치정보 에 대응하는 이동 경로를 생성하며, 태그장치로부터 전달된 태그장치 주변의 군집로봇의 위치 추정 정보를 이용 하여 태그장치의 위치정보를 수정하는 제어부를 포함한다."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 군집 로봇을 이용하여 사용자의 위치를 추적하는 방법, 태그장치 및 이를 구현하는 로봇에 관한 기술 이다."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "대형 마트, 백화점, 공항, 골프장 등 인적, 물적 교류가 활발하게 발생하는 공간에서 다양한 사람들이 다양한 물건을 소지하고 이동한다. 이 경우, 사용자의 편의를 제공하기 위해 물건을 이동시킴에 있어서 카트와 같은 장 치가 사용자를 추종하여 이동하며 사용자를 보조할 수 있다. 또한, 대형 공간에서 사용자에게 소정의 정보를 제공하기 위한 장치가 사용자를 추종하여 이동하며 사용자에게 정보를 제공할 수 있다. 이들 로봇들이 사용자를 보조하거나 정보를 제공하기 위해서는 사용자를 추종하여 이동하는 것이 필요하다. 이 를 위해 로봇은 사용자의 위치를 확인하는 과정이 필요하다. 그런데, 사용자의 위치를 추적하는 과정에서 신호의 왜곡이나 측정 오류의 문제가 발생할 수 있으므로, 로봇이 사용자의 위치를 추적함에 있어서 정확도를 높이는 기술이 필요하다."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서에서는 전술한 문제점을 해결하기 위한 것으로, 카트로봇 또는 배송 로봇과 같은 로봇들이 사용자의 위치를 추적하여 사용자를 추종하여 자율적으로 이동하는 메커니즘을 제공하고자 한다. 또한, 본 명세서에서는 로봇이 사용자의 위치를 직접 추적하는 것에 장애가 발생한 경우 다른 로봇들이 생성한 정보를 이용하여 사용자의 위치를 추적하는 방안을 제공하고자 한다. 또한, 본 명세서에서는 로봇이 사용자가 소지한 태그장치의 움직임에 대응하여 일정 범위내에서 움직여서 로봇 을 직관적으로 확인하는 방안을 제시하고자 한다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 의한 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇은 태그장치의 위치정보를 누 적하여 저장하고, 저장된 태그장치의 위치정보에 대응하는 이동 경로를 생성하며, 태그장치로부터 전달된 태그 장치 주변의 군집로봇의 위치 추정 정보를 이용하여 태그장치의 위치정보를 수정하는 제어부를 포함한다. 본 발명의 일 실시예에 의한 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇의 측위 모듈 또는 블루투스 모듈은 위치 추정 정보를 수신하며, 위치 추정 정보는 태그장치의 움직임 정보, 군집로봇의 위치 정보, 또는 군 집로봇이 제2프로토콜로 전송한 신호의 세기 정보 중 어느 하나 이상을 포함한다. 본 발명의 일 실시예에 의한 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇의 제어부는 태그장치의 움직 임 정보를 추적하여 로봇의 움직임을 제어한다. 본 발명의 일 실시예에 의한 군집 로봇을 이용하여 사용자의 위치를 추적하는 로봇의 제어부는 제어부는 군집로 봇의 위치 정보 또는 세기 정보 중 어느 하나 이상을 이용하여 태그 장치의 위치를 계산한다. 본 발명의 일 실시예에 의한 태그장치는 제1프로토콜에 기반한 신호를 제1로봇에게 송신하는 측위 모듈과 제2프 로토콜에 기반한 신호를 제2로봇으로부터 수신하고 제2프로토콜에 기반하여 제1로봇에게 신호를 송신하는 블루 투스 모듈과 블루투스 모듈이 제2로봇으로부터 수신한 위치 정보 또는 제2로봇이 제2프로토콜로 전송한 신호의 세기 정보를 측위 모듈 또는 블루투스 모듈을 제어하여 제1로봇에게 송신하는 태그 제어부를 포함한다. 본 발명의 일 실시예에 의한 군집 로봇을 이용하여 사용자의 위치를 추적하는 방법은 측위 모듈이 태그장치로부 터 제1프로토콜에 기반한 신호를 수신하여 테그장치의 위치를 측정하는 단계와, 블루투스 모듈이 태그장치로부 터 제2프로토콜에 기반한 신호를 수신하는 단계와, 제어부가 태그장치의 위치정보를 누적하여 저장하고, 저장된 태그장치의 위치정보에 대응하는 이동 경로를 생성하는 단계와, 제어부가 태그장치로부터 전달된 태그장치 주변 의 군집로봇의 위치 추정 정보를 이용하여 태그장치의 위치정보를 수정하는 단계와, 이동부가 이동 경로를 따라 로봇을 이동시키는 단계를 포함한다."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들을 적용할 경우, 카트로봇 또는 배송 로봇과 같은 로봇들이 사용자의 위치를 추적하여 사용 자를 추종하여 자율적으로 이동할 수 있다. 본 발명의 실시예들을 적용할 경우, 로봇이 사용자의 위치를 추적하는 과정에서의 오차를 제거하고 다른 로봇들 이 생성한 정보를 이용하여 위치 추적의 정확도를 높이고자 한다 본 발명의 실시예들을 적용할 경우, 로봇의 움직임을 선택적으로 태그장치의 움직임에 연동시켜 사용자가 로봇 을 직관적으로 확인할 수 있도록 한다."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 전술한 효과에 한정되지 않으며, 본 발명의 당업자들은 본 발명의 구성에서 본 발명의 다양한 효과를 쉽게 도출할 수 있다."}
{"patent_id": "10-2019-0114289", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서설명하는 실시예에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 또한, 본 발명의 일부 실시예들을 예시적인 도 면을 참조하여 상세하게 설명한다. 각 도면의 구성요소들에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가질 수 있다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에 는 그 상세한 설명은 생략할 수 있다. 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질, 차례, 순서 또는 개수 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 다른 구성 요소가 \"개재\"되거나, 각 구성 요소가 다른 구성 요소를 통해 \"연결\", \"결합\" 또는 \"접 속\"될 수도 있다고 이해되어야 할 것이다. 또한, 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요 소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘 어져서 구현될 수도 있다. 이하, 본 명세서에서 사용자를 추종하며 자율적으로 이동하거나 사용자의 제어에 따라 전기적 에너지에 기반하 여 이동하는 장치들은 스마트 카트로봇, 카트로봇 혹은 줄여서 카트, 또는 배송 로봇 등으로 다양하게 지칭한다. 본 명세서에서는 이들을 모두 로봇으로 통칭하며, 이들 로봇은 사용자의 위치를 추적하여 사용자를 추종하는 모드로 동작한다. 로봇은 대형 마트나 백화점 등 매장 내에서 사용할 수 있다. 또는 공항이나 항만과 같이 여행객들이 많이 이동 하는 공간 내에서 사용자들이 로봇을 사용할 수 있다. 그리고 로봇은 골프장과 같은 레저 공간에서도 사용될 수 있다. 또한, 로봇은 사용자의 위치를 추적하여 사용자를 따르면서 소정의 보관 공간을 제공할 수 있다. 로봇은 사용자 가 밀거나 당기는 등의 제어에 따라 전기적 동력을 이용하여 이동할 수 있다. 그 결과, 사용자는 로봇을 전혀 조정할 필요 없이 이동시킬 수 있다. 또한 사용자는 매우 작은 힘으로 로봇을 이동시킬 수 있다. 도 1 및 도 2는 본 발명의 일 실시예에 의한 로봇의 외관을 보여준다. 도 1은 핸들 어셈블리와 이동부 (190a, 190b)가 외부에서 식별 가능하게 배치된 로봇의 실시예이다. 도 2는 이동부가 로봇의 하단부의 커 버 내부에 배치되어 외부에서 쉽게 확인할 수 없는 로봇의 실시예이다. 도 2의 로봇은 별도의 핸들 어셈블 리가 없는 대신, 로봇의 외부 케이스에서 압력을 센싱하는 포스센서가 배치되어 사용자가 로봇 을 밀 경우 로봇이 미는 힘에 따라 이동할 수 있다. 도 1, 2에서 로봇는 수납부와 제어모듈을 포함한다. 또한, 두 실시예의 로봇들 모두 태그장치 와통신하여 태그장치의 위치를 파악할 수 있다. 도 1의 실시예의 로봇은 핸들 어셈블리, 이동부(190a, 190b)를 포함한다. 수납부는 사용자에 의해 사 물이 수납되거나 적재되는 공간이다. 핸들 어셈블리는 사용자가 카트로봇를 수동으로 이동을 제어하 거나, 반자동으로 이동을 제어할 수 있도록 한다. 도 1의 핸들 어셈블리를 이용하여 사용자는 로봇를 전후로 밀거나 방향을 변경할 수 있다. 이 경우, 핸들 어셈블리에 가해진 힘의 크기나 좌우 힘의 차이에 따라 로봇는 전기적 에너지를 이용하여 반자 동으로 주행할 수 있도록 한다. 로봇의 내부에 배치되는 제어모듈는 로봇의 이동을 제어한다. 특히, 제어모듈는 사용자를 추종 할 수 있도록 로봇의 자율 주행을 제어한다. 또한, 제어모듈은 사용자가 작은 힘으로 로봇을 밀거나 당길 때 사용자의 힘을 보조하여 로봇이 주행하는 반자율 주행(파워 어시스트)을 제어한다. 제어모듈은 이동부를 제어할 수 있다. 이동부는 제어부가 생성한 이동 경로를 따라 로봇을 이동시킨다. 이동부는 이동부를 구성하는 바퀴를 회전시킴으로써 로봇을 이동시킬 수 있다. 이동부에 의해 로봇이 이동할 경우 휠의 회전속도와 회전한 횟수, 방향 등의 정보가 산출된다. 제어부 는 이동 과정에서 산출된 정보를 이용하여 로봇의 위치를 확인할 수 있다. 제어부가 생성한 이 동 경로는 로봇의 좌측 바퀴와 우측 바퀴에 인가하는 각속도를 포함한다. 또한 로봇의 여러 영역에 사용자의 추종을 위한 사용자 위치를 추적하는 측위모듈이 배치될 수 있다. 또한 로봇의 여러 영역에는 주변의 장애물을 센싱하기 위한 장애물 센서가 배치될 수 있다. 측위모듈은 특정한 신호를 출력하는 (태그장치를 감지할 수 있다. 본 발명의 실시예에 의한 로봇은 도 1 또는 도 2와 다른 형상을 가질 수 있으며, 도 1 또는 도 2의 형상에 의해 본 발명의 로봇이 한정되지 않는다. 도 3을 참조한다. 도 3의 로봇은 카트 로봇, 배송 로봇 등을 일 실시예로 한다. 주요 구성요소로 태그장치로부 터 제1프로토콜에 기반한 신호를 수신하여 테그장치의 위치를 측정하는 측위 모듈, 태그장치로부터 제2프로토콜에 기반한 신호를 수신하는 블루투스 모듈, 로봇의 주변에 배치된 장애물을 센싱하는 장애물 센서, 태그장치의 위치정보를 누적하여 저장하고, 저장된 태그장치의 위치정보에 대응하는 이동 경로 를 생성하며, 태그장치로부터 전달된 태그장치 주변의 군집로봇의 위치 추정 정보를 이용하여 태그장 치의 위치정보를 수정하는 제어부, 이동 경로를 따라 이동하는 이동부를 포함한다. 수정이란 도 3은 도 1 또는 도 2의 로봇을 구성하는 제어모듈을 구성하는 논리적 구성요소들인 측위모듈, 포스센서, 장애물 센서, 인터페이스부, 제어부, 카메라 센서, 통신부를 도시한 도면이다. 도 2의 실시예에서 포스센서는 선택적으로 배치된다. 장애물 센서는 로봇의 주변에 배치된 장애물을 센싱한다. 장애물 센서는 사람, 벽, 사물, 고정물 또 는 설치물(installed object) 등과 로봇과의 거리를 센싱할 수 있다. 측위모듈는 자율 주행을 지원하는 로봇에 필수 구성요소이다. 그러나 반자율 주행(파워 어시스트) 주행 만 을 지원하는 로봇의 경우 측위모듈는 선택적으로 배치될 수 있다. 측위모듈는 (태그장치를 소지하는 사용자의 위치를 추적할 수 있으며, 로봇의 상단 또는 측면 등에 배치될 수 있다. 그러나 이들 센서들의 위치는 실시예에 따라 다양하게 변경될 수 있으며 본 발명이 이에 한정되지 않는다. 그리고 센서들의 위치와 무관하게 제어모듈은 센서들을 제어하거나 센서들이 센싱한 정 보를 활용한다. 즉, 센서들은 물리적 위치에 상관없이 논리적으로 제어모듈의 구성요소이다. 측위모듈는 앵커(anchor)를 포함한다. 태그장치로부터 신호를 수신하여 태그장치의 위치를 측정 한다. 측위모듈가 UWB(Ultra-wideband)를 이용할 경우, 사용자는 측위모듈에게 소정의 신호를 송신하 는 태그장치를 소지할 수 있다. 그리고 측위모듈는 태그장치의 위치로 사용자의 위치를 확인할 수 있다. 일 실시예로 사용자는 손목에 부착하는 밴드 형태의 태그장치를 소지할 수 있다. 측위모듈는 로봇에 하나 이상 배치될 수 있다. 일 실시예로 두 개의 측위모듈가 로봇에 배치될 경우 로봇은 태그장치의 후보 위치를 2개 계산할 수 있다. 이 경우, 로봇은 2 개 중에서 이전 위치와 근접한 것을 선택하여 태그장치 의 위치를 확인할 수 있다. 3개의 측위모듈가 로봇에 배치될 경우 로봇은 태그장치의 위치를 계산할 수 있다. 또한, 도 1의 핸들 어셈블리 또는 도 2의 로봇의 상부에는 사용자에게 소정의 정보를 출력하는 인터 페이스부가 배치될 수 있다. 인터페이스부 역시 제어모듈의 제어를 받는 구성요소가 될 수 있 다. 그리고 핸들 어셈블리는 사용자가 로봇을 밀거나 당기는 힘을 센싱하는 포스 센서를 포함한다. 물론 도 2의 실시예에서 로봇의 외부 케이스에 사용자가 미는 힘을 감지할 수 있도록 포스 센서가 배치될 수 있다. 포스 센서는 도 1의 핸들 어셈블리의 조작에 의해 힘의 변화가 발생하는 영역 또는 도 2의 외부 케이 스에 가해진 힘을 센싱할 수 있는 영역에 배치될 수 있다. 포스 센서는 로봇의 외부 또는 내부 에 배치될 수 있다. 포스 센서의 위치나 구성은 다양하게 적용될 수 있으며 본 발명의 실시예들은 특정한 포스 센서에 한정되지 않는다. 도 1의 실시예에서 포스센서는 핸들 어셈블리에 배치되거나 핸들 어셈블리에 연결된 로봇 의 외부 또는 내부에 배치된다. 도 2의 실시예에서 포스센서는 외부 케이스의 안쪽에 배치된다. 포스센서는 사용자가 핸들 어셈블리 또는 외부 케이스에 힘을 가할 경우, 힘의 크기나 힘의 변 화 등을 센싱한다. 포스 센서는 홀 센서, 마그네틱 타입 센서, 버튼식 센서 등 다양한 센서를 포함한다. 포스 센서는 좌측 포스센서와 우측 포스센서로 각각 핸들 어셈블리 또는 로봇 내부 또는 외부 케이스에 배치될 수 있다. 장애물 센서는 로봇의 주변에 배치된 장애물을 센싱한다. 장애물 센서는 거리를 측정하거나 영상을 취득하 여 영상 내에서 장애물을 확인하는 센서를 포함한다. 거리 측정을 위한 장애물 센서는 적외선 센서나 초음 파 센서, 라이다 센서 등을 일 실시예로 한다. 또한 장애물 센서는 뎁스 센서 혹은 RGB 센서를 포함한다. RGB 센서의 경우 영상 내에서 장애물과 설치물 을 감지할 수 있다. 뎁스 센서는 영상 내에서 각 지점 별 뎁스 정보를 산출한다. 또한 장애물 센서는 TOF(Time of Flight) 센서를 포함한다. 제어부는 태그장치의 위치정보를 누적하여 저장하고, 저장된 태그장치의 위치정보에 대응하는 이동 경로를 생성한다. 누적하여 위치정보를 저장하기 위해서 제어부는 태그장치 및 로봇의 위치정보를 일정 한 기준점을 기반으로 하는 절대위치정보(절대좌표)로 저장할 수 있다. 또는 제어부는 장애물 센서와 카메라 센서를 이용하여 로봇의 이동을 제어할 수 있다. 제어부 는 포스 센서가 센싱한 힘의 변화 또는 크기에 따라, 이동부의 이동 방향 또는 이동 속도를 제어한다. 또는 제어부는 이동 속도를 제어하기 위해 이동부의 모터에 더 많은 전기에너지가 제공되도록 이동부를 제어할 수 있다. 또한, 제어부는 장애물 센서가 센싱한 값을 이용하여 로봇 주변에 배치된 설치물을 검출한다. 제어부 는 로봇의 측면 및 전면에 배치된 장애물 센서를 이용하여 설치물을 확인할 수 있다. 카메라 센서는 로봇 주변의 사물/사람/설치물 등의 영상을 촬영할 수 있다. 카메라 센서는 로봇(10 0)의 하단부 또는 측면 또는 전방부 등에 배치될 수 있다. 장애물 센서 또는 카메라 센서는 로봇의 하단 또는 중간 또는 측면 등 다양한 위치에 배치되어 다양한 방향의 사물을 센싱하거나 촬영할 수 있다. 예를 들어 도 1, 2의 155에서 지시되는 영역에 로봇의 전/좌/우/후방의 장애물을 센싱하기 위해 다수의 장애물 센서들이 배치될 수 있다. 장애물 센서는 로봇의 하단에 동일한 높이에 배치될 수 있다. 또는 장애물 센서는 로봇의 하단에 둘 이상의 높이가 다른 영역에 배치될 수 있다. 또한 전면/양측면과 같 이 로봇가 이동하는 방향으로 장애물 센서가 배치될 수 있다. 또는 로봇가 후진할 경우, 전면 및 후 면, 양측면에 장애물 센서가 배치될 수 있다. 마찬가지로 카메라 센서 역시 영상 획득의 목적에 따라 장애물 센서들이 배치된 다양한 위치에 배치 될 수 있다. 예를 들어, 카메라 센서가 전방의 이미지 정보를 취득할 경우 로봇의 전방에 배치될 수 있다. 또는 카메라 센서가 하방의 이미지 정보를 취득할 경우 로봇의 하방에 배치될 수 있다. 블루투스 모듈은 통신부를 구성하며 블루투스(Bluethooth) 프로토콜에 따라 신호를 송수신할 수 있다. 블루투스 모듈은 측위모듈가 사용자의 위치를 추정하는 과정에서 정확도를 높이기 위한 기능을 제공한다. 즉, 사용자의 위치 추적은 로봇에 부착된 다수의 측위모듈에 의한 UWB RTLS(Real-Time Location System)를 통하여 이루어진다. 반면 태그장치와측위모듈 사이에서 신호 끊김이나 품질 열화(위치가 튀는 현상)가 발생할 수 있다. 이 경우, 다른 사용자가 보유하는 다른 태그장치와 상호작용중인 다수의 로봇들과의 관계에서 자체 로케이션 정 보를 생성할 수 있다. 또한, 블루투스 모듈을 이용하여 BLE RSSI(Received Signal Strength Indicator) 정보를 이용하여 사용자가 소지하는 태그장치의 위치를 강건하게 추종할 수 있다. 전술한 로봇은 이동부의 동작이나 이전에 이동한 궤적 등에서 오도메트리(odometry) 정보를 산출할 수 있다. 또는 로봇은 SLAM 과정에서 로봇의 위치 정보를 산출할 수 있다. 또한, 제어부는 측위모듈와 태그장치 사이에서 수신된 패킷을 이용하여 태그장치의 방위와 거리를 산출할 수 있다. 물론, 제어부 내에 혹은 제어모듈 내에 별도의 측위모듈 용 MCU(Micro Control Unit)가 배치될 수도 있다. 또한, 제어모듈은 선택적으로 관성 센서(Inertia Measurement Unit, 관성 센서 또는 관성 측정 센 서)를 더 포함할 수 있다. 이는 자이로 센서와 가속도 센서를 포함하며 로봇이 이동하는 과정에서 발새아 는 관성을 센싱한다. 로봇의 제어부는 인공지능 모듈을 이용하여 상황인식(Context Awareness)을 수행할 수 있다. 마찬가지로, 센싱된 값들, 사용자의 제어, 또는 다른 카트로봇들이나 서버로부터 수신된 정보 등을 인공지능 모듈의 입력값 으로 하여 제어부는 로봇의 상황을 인식할 수 있다. 특히 로봇이 수신된 군집 로봇들의 위치 정 보를 이용하여 사용자의 위치를 추적할 것인지, 아니면 독자적으로 사용자가 보유한 태그 모듈의 위치를 추적할 것인지와 같은 상황의 인식에서 제어부의 인공지능 모듈이 판단 기능을 제공할 수 있다. 또한, 카트로봇의 제어부는 인공지능 모듈을 이용하여 입력된 데이터들을 판독할 수 있다. 전술한 인공지능모듈은 추론 엔진(inference engine), 뉴럴 네트워크(neural network), 확률모델(probability model)을 포함할 수 있다. 그리고 인공지능 모듈은 다양한 데이터에 기반한 지도학습(supervised learning) 또 는 비지도학습(unsupervised learning)을 수행할 수 있다. 또한, 인공지능모듈은 사용자의 음성을 인식하여 이로부터 정보를 추출하기 위해 자연어 처리(natural language processing)을 수행할 수 있다. 또한, 카트로봇의 제어부는 음성 인식(Voice Recognition), TTS(Text To Speech) 기능을 제공한다. 도 4는 본 발명의 일 실시예에 의한 태그장치의 구성을 보여주는 도면이다. 태그장치은 사용자에 의해 착 용되거나 사용자가 휴대하는 태그를 일 실시예로 한다. 태그장치의 주요 구성요소로는 제1프로토콜(일 실시예로 UWB)에 기반한 신호를 제1로봇(추종 로봇)에게 송 신하는 측위 모듈, 제2프로토콜(일 실시예러 블루투스)에 기반한 신호를 제2로봇(군집로봇)으로부터 수신 하고 제2프로토콜에 기반하여 제1로봇에게 신호를 송신하는 블루투스 모듈, 블루투스 모듈이 제2로봇 으로부터 수신한 위치 정보 또는 제2로봇이 제2프로토콜로 전송한 신호의 세기 정보를 측위 모듈 또는 블 루투스 모듈을 제어하여 제1로봇에게 송신하는 태그 제어부가 있다. 또한, 태그장치는 태그장치의 움직임을 센싱하는 움직임 감지 센서(532, 534, 536), 그리고 움직임 감지 센서가 센싱한 값을 필터링하는 태그 필터를 더 포함할 수 있다. 이 경우, 태그제어부는 태그필터 에서 산출된 태그장치의 움직임 정보를 측위 모듈 또는 블루투스 모듈을 제어하여 제1로봇 에게 송신한다. 보다 상세히 살펴본다. 측위 모듈은 로봇의 측위모듈와 패킷을 송수신한다. 예를 들어, 로봇의 측위모듈가 UWB 모듈이 며, 측위 모듈 역시 UWB 모듈인 경우, 측위 모듈은 UWB 패킷을 로봇에게 송신한다. 측위모듈는 이를 수신하며 로봇의 제어부는 수신한 패킷을 이용하여 태그장치의 방위와 거리를 산출할 수 있다. 블루투스 모듈은 로봇의 블루투스 모듈로부터 로봇의 위치 정보, 예를 들어 로컬라이제이션 정보 (localization data)를 수신한다. 이는 로봇이 이동부의 동작이나 이전에 이동한 궤적 등에서 산출된 오도메트리(odometry) 정보를 포함할 수 있다. 또는 로봇의 SLAM(Simultaneous localization and mapping) 과정에서 산출된 로봇의 위치 정보를 포함할 수 있 다. 또한, 태그장치의 블루투스 모듈과 로봇의 블루투스 모듈 간의 블루투스 통신으로 각 로봇 들과의 블루투스 통신 과정에서의 신호의 특성인 RSSI를 수집할 수 있다. 한편, 태그장치은 태그장치의 물리적 변화를 센싱하는 가속도 센서, 자이로 센서, 지자기 센서와 이들 센서들이 센싱한 값을 이용하여 (태그장치를 소지한 사용자의 자세나 움직임을 필터링하 는 태그 필터를 포함한다. 가속도 센서, 자이로 센서, 지자기 센서를 통칭하여 움직임 감 지 센서라 지시한다. 그리고 태그 제어부는 태그장치의 구성요소들을 제어한다. 가속도 센서, 자이로 센서는 일 체로 하나의 IMU(Inertia Measurement Unit, 관성 센서 또는 관성 측정 센서) 센서를 구성할 수 있다. 조작부는 사용자가 (태그장치를 이용하여 로봇을 조종하는 모드로 사용할 수 있도록 한다. 조작부 는 버튼 형태인 것을 일 실시예로 한다. 또는 조작부는 터치 입력을 수신하는 것을 일 실시예로 한다. 즉, 조작부는 사용자로부터 조작 신호를 수신한다. 조작부가 사용자에 의해 조작될 경우, 예를 들어 버튼이 눌려지거나 사용자가 터치하는 경우에 태그 제어 부는 (태그장치를 추종하는 로봇에게 조종 모드가 활성화되었음을 알린다. 이후 로봇은 태그장치 의 움직임을 반영하여 이동하거나 움직일 수 있다. 태그제어부는 조작부이 조작에 따라 태그장 치의 움직임 정보의 송신을 제어한다. 도 5는 본 발명의 일 실시예에 의한 태그장치와 추종 로봇, 그리고 군집 로봇 사이의 정보를 송수신하는 프로세 스에 대해 살펴본다. 추종 로봇(100a)은 제1태그장치(500a)의 위치를 확인하여 제1(태그장치(500a)를 추종하는 로봇이다. 군집로봇 (100b)은 제1태그장치(500a)와 페어링된 상태에서 로봇의 위치 정보를 전송한다. 제1태그장치(500a)에는 통상 하나의 추종 로봇(100a)이 배치된다. 또는 다수의 추종로봇들이 하나의 제1(태그장치(500a)를 추종할 수 있다. 또한, 군집로봇(100b)은 제1(태그장치(500a)를 추종하지 않고 제2태그장치를 추종할 수 있다. 군집로봇(100b)은 제1(태그장치(500a)를 추종하지 않으나 제1태그장치(500a)에게 위치 정보를 전송한다. 또는 군집로봇(100b)은 어느 태그장치도 추종하지 않을 수 있다. 따라서, 추종 로봇과 군집로봇은 태그장치를 기준으로 구분되며, 어느 하나의 태그장치에 대해 추종하는 로봇이 다른 태그장치에 대하여 군집로봇으로 동작할 수 있다. 도 5에서 제1태그장치(500a)은 추종 로봇(100a)에게 측위를 위한 패킷을 송신한다(S11). 그리고 추종로봇(100 a)은 수신한 패킷을 이용하여 제1태그장치(500a)의 위치를 계산한다(S12). 한편 추종로봇(100a)이 제1태그장치(500a)의 위치를 추정함에 있어 정확도를 높이기 위해 추종 로봇(100a)이 아 니며 제1태그장치(500a)와 일정 거리 내에 위치하는 군집 로봇(100b)은 자신의 위치 정보를 전송한다(S13). 제1 태그장치(500a)은 S13 과정에서 하나 이상의 군집로봇(100b)으로부터 각각의 군집 로봇(100b)들의 위치 정보를 수신한다. 특히 S13의 정보 전송은 블루투스 통신을 이용할 수 있으며, 이 경우, 제1송신로봇(500a)은 군집로봇(100b)과의 블루투스 통신 과정에서 BLE RSSI를 확인할 수 있다. 따라서, 제1태그장치(500a)은 태그장치의 움직임 정보와 각 군집로봇(100b)과의 거리 정보를 추종 로봇(100a)에 게 송신한다(S14). 이를 수신한 추종 로봇(100a)은 수신한 정보를 이용하여 태그장치의 위치를 계산한다(S15). S12는 제1태그장치 (500a)가 측위를 위해 송신하는 패킷에 기반하여 위치를 계산하는 것으로, 예를 들어 UWB 통신에 기반할 수 있 다. 그런데 S12 과정에서 제1태그장치(500a)와 추종로봇(100a) 사이에 장애물이 배치될 경우, 추종로봇(100a)은 잘못된 위치를 계산할 수 있다. 따라서, 추종로봇(100a)은 S15와 같이 다른 로봇들의 위치 정보를 수신하고 이를 반영하여 제1태그장치(500a)의 위치 계산의 정확도를 높일 수 있다. 도 5를 정리하면, 로봇, 특히 추종로봇(100a)의 측위 모듈 또는 블루투스 모듈은 위치 추정 정 보를 수신한다. 이때, 위치 추정 정보는 태그장치(500a)의 움직임 정보, 군집로봇(100b)의 위치 정보, 또는 군 집로봇(100b)이 블루투스로 전송한 신호의 세기 정보 중 어느 하나 이상을 포함한다. 도 6은 본 발명의 일 실시예에 의한 추종로봇과 군집로봇의 구성을 보여준다. 제1태그장치(500a)의 추종 로봇은 제1로봇(100a)이다. 제2태그장치(500b)의 추종 로봇은 제2로봇(100b)이다. 제3태그장치(500c)의 추종 로봇은 제 3로봇(100c)이다. 제4태그장치(500d)의 추종 로봇은 제4로봇(100d)이다. 제5태그장치(500e)의 추종 로봇은 제5 로봇(100e)이다. 제1(태그장치(500a)를 기준으로 군집로봇은 100b~100e이다. 제2태그장치(500b)을 기준으로 군집로봇은 100a, 100c~100e이다. 제3태그장치(500c)을 기준으로 군집로봇은 100a, 100b, 100d, 100e이다. 제4태그장치(500d)을 기준으로 군집로봇은 100a~100c, 100e이다. 제5태그장치(500d)을 기준으로 군집로봇은 100a~100d이다. 도 6의 구성에서 제1태그장치(500a)와 제1로봇(100a)이 UWB 송수신할 수 있으며, 제1로봇(100a)은 UWB 패킷을 제1태그장치(500a)로부터 수신하여 제1태그장치(500a)의 위치를 계산한다. 한편, 이 과저에서 제1태그장치(500a)와 제1로봇(100a) 사이에 장애물이 배치될 수 있다. 그러나 제1태그장 치(500a)은 다수의 군집로봇(100b~100e)로부터 블루투스 통신에 기반하여 군집 로봇들의 위치 정보를 수신한다. 또한 제1태그장치(500a)가 군집로봇(100b~100e)으로부터 수신한 블루투스 통신 패킷의 RSSI를 이용하여 군집로 봇(100b~100e)과 제1태그장치(500a) 사이의 거리를 산출할 수 있다. 그리고, 추가적으로 제1태그장치(500a)은 움직일 수 있으며 움직임 정보 역시 산출할 수 있다. 그리고 제1태그장치(500a)은 움직임 정보와 군집로봇(100b~100e)들의 정보를 추종 로봇인 제1로봇(100a)에게 전 송한다. 이 경우, 전송 방식은 UWB 송수신 또는 블루투스 송수신을 일 실시예로 한다. 제1로봇(100a)은 수신한 정보들을 이용하여 제1태그장치(500a)의 위치를 계산할 수 있다. 따라서, 제1로봇 (100a)이 제1태그장치(500a)로부터 UWB 패킷을 수신하지 못하거나 장애물로 인해 신호가 왜곡되는 경우라도 제1 태그장치(500a)가 송신하는 움직임 정보와 군집로봇(100b~100e)들의 정보에 기반하여 제1태그장치(500a)의 위치 를 계산할 수 있다. 도 6에서 태그장치(500a)는 블루투스에 기반한 통신을 수행할 군집로봇(100b~100e)을 선택할 수 있다. 예를 들 어, 태그장치(500a)는 가장 근접한 로봇들을 우선적으로 군집로봇으로 선택할 수 있다. 이는 블루투스 신호의 세기(RSSI)를 이용할 수 있다. 또는 태그장치(500a)는 각 로봇들이 전송한 위치 정보를 이용하여 근접한 로봇들 혹은 다양한 각도로 분산된 로봇들을 선택할 수 있다. 도 7은 도 6의 과정을 보다 상세히 설명한 도면이다. 도 7은 태그장치(500a)와 군집로봇(100b~100e), 그리고 추 종 로봇(100a) 간의 상호 작용을 보여준다. 도 7에서 태그장치(500a)의 측위 모듈의 일 실시예로 UWB 모듈 이 제시된다. 또한, 로봇의 측위모듈 역시 UWB 칩과 UWB 필터를 포함한다. 그리고 로봇의 블루투스 모듈(29 0)는 블루투스 칩(BT 칩)과 블루투스 필터를 포함한다. 군집 로봇(100b~100e)들은 이동 과정에서 SLAM을 수행하여 SLAM 정보를 산출할 수 있다. 또한 군집 로봇 (100b~100e)들은 로봇의 이동부를 통해 오도메트리(odometry) 정보를 산출할 수 있다. SLAM 정보 및 오도 메트리 정보는 로봇의 제어부에 의해 위치 정보(Localization data)로 취합된다(S21, S22). 이후 취합된 데이터는 태그장치(500a)로 전송된다. 태그장치(500a)와 다수의 군집 로봇(100b~100e)은 일정한 거 리 내에서 블루투스 통신으로 페어링된다. 따라서, 군집 로봇(100b~100e)은 페어링된 블루투스 통신을 통해 각 로봇들의 위치 정보(Localization data)를 태그장치(500a)에게 전송한다(S23b~S23e). 태그장치(500a)의 BLE 모듈은 군집 로봇들의 위치 정보(Localization data)를 수신한다(S23b~S23e). 군집 로봇들의 위치 정보는 UWB 모듈을 통해 추종 로봇(100a)에게 전송된다. 또는 군집 로봇들의 위치 정보는 BLE 모듈을 통해 추종 로봇(100a)에게 전송될 수 있다. 한편, 가속도 센서, 자이로 센서, 지자기 센서 역시 태그장치(500a)의 움직임과 자세의 변화 등 을 추정하고 자세/움직임 정보를 필터에게 제공한다. 가속도 센서, 자이로 센서, 지자기 센서 등이 센싱한 값은 태그 필터에서 좌표 변환 등의 프로세스를 수행한 후 태그장치의 자세와 움직임을 산출한다. 그리고 BLE 모듈은 군집 로봇들의 위치 정보 뿐만 아니라 위치 정보를 수신하는 과정에서의 신호의 세기에 대한 정보를 산출할 수 있다. 즉, 태그 제어부는 태그 필터에서 산출된 태그장치의 움직임 정보와, BLE 모듈이 수신한 다른 군집 로봇들의 위치 정보, 그리고 BLE 모듈이 수신한 정보의 신호의 세기(RSSI)를 통한 거리 정보를 취합 하여 추종 로봇(100a)에게 UWB 모듈 또는 BLE 모듈을 통해 전송한다(S25). 태그필터와 UWB 모듈 사이에서 스위치기 배치될 수 있으며, 태그장치(500a)가 움직이지 않은 경우에 태그 제어부는 군집 로봇들의 위치 정보뿐만 아니라 위치 정보를 수신하는 과정에서의 신호의 세기에 대한 정보만을 추종 로봇(100a)에게 전송할 수 있다. 수신된 정보가 블루투스 통신을 통해 수신된 경우 해당 정보는 추종 로봇(100a)의 BT 칩 및 BT 필터 를 통해 제어부 내의 로컬라이제이션 필터(Localization filter)로 입력된다(S26b). 이때, BT 필터 는 위치 추정 모델을 포함할 수 있다. 그 결과 로컬라이제이션 필터에게 위치 정보를 제공할 수 있다. 수신된 정보가 UWB 통신을 통해 수신된 경우 해당 정보는 추종 로봇(100a)의 UWB 칩 및 UWB 필터를 통해 제어부 내의 로컬라이제이션 필터(Localization filter)로 입력된다(S26u). 이때, UWB 필터 는 위치 추정 모델을 포함할 수 있다. 그 결과 로컬라이제이션 필터에게 위치 정보를 제공할 수 있다.또한, 측위 모듈은 태그장치(500a)의 UWB 패킷의 수신 과정에서 태그장치(500a)의 속도나 위치 정보를 산 출할 수 있으며, 이를 로컬라이제이션 필터에게 전달한다. 또한, 정보 수신 과정에서 로봇의 움직임이 발생했는지를 센싱하는 관성 센서 역시 센싱한 값을 로컬라이 제이션 필터로 전달한다(S27). 이후, 제어부의 로컬라이제이션 필터가 태그장치(500a)의 위치 정보와 속도 정보를 생성하여 위치 제 어기로 위치/속도 정보를 제공한다(S28). 위치 제어기가 로봇의 위치를 이동시키는 제어 정보를 생성 하여 이동부를 구성하는 모터로 제어 정보를 제공한다(S29). 도 8은 본 발명의 일 실시예에 의한 블루투스 필터의 세부 구성과 동작 과정을 보여준다. BT 필터는 BT RTLS(Bluetooth Real Time Location System)(297a)을 포함한다. BT RTLS(297a)는 다른 로봇 들에 대한 사용자의 절대 위치를 계산한다. 초기 추정부(297b)는 초기 추정값을 위치 추정 모델(297c)에게 제공한다. 위치 추정 모델(297c)은 BT RTLS(297a)가 계산하여 산출한 위치값을 이용하여 로봇을 기준으로 하는 태그장치의 위치를 계산한다. 이는 최 적값을 추정할 때까지 BT 필터는 계속 반복적으로 계산할 수 있다. 그리고 Limit(297d)은 위치 추정의 민감도를 조종하기 위한 필터 (평균값 혹은 경계값 적용)가 되며, 외부에서 이 필터를 사용할 것인지 여부를 스위칭하여 제어할 수 있다. 즉, 블루투스를 프로토콜로 이용하는 블루투스 모듈은 블루투스 신호를 송수신하는 칩 및 블루투스 필터를 포함한다. 그리고 블루투스 모듈은 군집로봇에 대한 태그장치(500a)의 위치정보를 계산한다. 또는, 블루투스 모듈은 데이터를 수신한 후, 제어부가 군집로봇들의 위치 정보와 블루투스 신호 세기 에 대한 정보를 이용하여 태그장치(500a)의 위치정보를 계산할 수 있다. 그리고 블루투스 모듈과 태그장치(500a) 사이의 신호의 세기 정보(RSSI) 역시 제어부가 태그장치 (500a)의 위치정보를 계산하는데 사용할 수 있다. 도 9는 본 발명의 일 실시예에 의한 UWB 필터의 세부 구성과 동작 과정을 보여준다. UWB 위치 측위(UWB RTLS)(217a)는 UWB 위치 측정 알고리즘으로 로봇을 기준으로 사용자 위치를 계산한다. 초기 추정부(217b)는 초 기 추정값을 동적 모델(217e)에게 제공한다. 동적 모델(217e)은 태그장치의 움직임에 대한 기본적인 동역학 모 델을 제공한다. 태그장치이 전송한 자세/움직임 추정값을 적용한다. 위치 추정 모델(217c)는 UWB 위치 측정 알고리즘으로 계산된 위치값을 이용하여 동적모델을 업데이트한다. 그리 고 최적값을 추정할 때까지 UWB 필터는 계속 반복적으로 위치를 계산한다. Limit(297d)는 위치 추정의 민 감도를 조종하기 위한 필터(평균값 혹은 경계값 적용)가 되며, 외부에서 이 필터를 사용할 것인지 여부를 스위 칭하여 제어할 수 있다. UWB 필터는 선택적으로 카메라 센서가 촬영한 정보를 이용할 수 있다. 카메라 센서는 스테레오 카메라, 뎁스 카메라 등을 일 실시예로 한다. UWB 필터는 UWB 위치 측위 시 카메라 센서가 촬영한 이 미지를 반영하여 위치 오차값을 보상할 수 있다. 즉, UWB를 프로토콜로 이용하여 통신하는 측위 모듈은 UWB 신호를 송수신하는 칩 및 UWB 필터를 포함한다. 그리고 이러한 측위 모듈은 로봇(100a)에 2개 이상, 바람직하게는 3개 이상 배치된다. 그리고 UWB 필 터는 태그장치(500a)의 움직임 정보를 반영하여 태그장치(500a)의 위치를 추정한다. 도 10은 본 발명의 일 실시예에 의한 태그 필터가 동작하는 과정을 보여준다. 태그 필터는 가속도 센서와 지자기 센서가 센싱한 값의 좌표계를 변환한다(S31). 또한, 자이로 센서의 값 역시 좌표계를 변환한다(S32). S31의 변환된 좌표는 비용 함수에 입력된 후 비용함수 계산결과 로 최적화 필터에 입력된다. 한편, S32의 변환된 값 및 비용함수 계산 결과를 취합하고(s) 여기에 대해 최적화 필터에서 산출된 값과 연산한 후 역산(1/s) 하여 좌표계 변환을 수행한다(S33). 그 결과 태그장치의 움직임에 대한 정보, 즉 x/y/z 축을 기준으로 하는 움직임 정보(roll, pitch, yaw)가 산출된다. 한편, 측정 단위 당 가속도(acceleration in earth frame)는 로봇(100a)의 위치추정모델(217c 또는 297c)에게 전달된다(S34). 그리고 위치추정모델(217c 또는 297c)은 UWB RTLS(217a) 또는 BT RTLS(297a)로부터 제공된 정 보를 이용하여 태그장치(500a)의 위치와 움직이는 속도를 계산할 수 있다. 도 11 및 도 12는 본 발명의 일 시시예에 의한 사용자가 태그장치를 제어할 경우 추종 로봇이 이에 대응하여 동 작하는 과정을 보여준다. 추종 로봇(100a)이 태그장치(500a)의 위치를 놓치거나 추종 로봇(100a)이 장애물에 둘 러싸여 움직일 수 없는 경우에 도 11 또는 도 12와 같이 (태그장치(500a)를 이용하여 추종 로봇(100a)을 조정할 수 있다. 태그장치(500a)은 평상시에는 사용자가 휴대 또는 착용한다. 추종 로봇(100a)은 태그장치(500a)에 대한 위치 측 정을 통해 (태그장치(500a)를 소지하는 사용자의 위치를 획득할 수 있다. 또한, 사용자는 태그에 부착된 버튼과 같은 조작부를 조작하여 로봇을 조종할 수 있다. 조종 모드의 일 실시예로 추종 로봇(100a)은 태그장치(500a)의 움직임을 반영하여 이동할 수 있다. 예를 들어 도 11과 같이 사용자가 (태그장치(500a)를 좌우로 흔들면 추종로봇(100a) 역시 태그장치(500a)의 좌우 이동에 대응하여 움직인다. 도 12와 같이 사용자가 (태그장치(500a)를 원으로 그리듯 움직이면 추종로봇(100a) 역시 태그장치(500a)의 원형 이동에 대응하여 움직인다. 도 11 및 도 12의 실시예는 로봇(100a)의 제어부가 UWB 필터를 이용하여 태그장치(500a)의 자세나 움 직임을 확인하고, 태그장치(500a)와 추종 로봇(100a) 사이의 거리나 태그장치(500a)의 방향 정보를 확인한다. 그리고 제어부는 태그장치(500a)의 움직임 대로 로봇이 움직이도록 로봇(100a)을 제어한다. 이를 통해 사 용자는 태그장치(500a)와 동일한 방식으로 움직이는 추종 로봇(100a)을 직관적으로 식별하여 조종할 수 있다. 태그장치(500a)의 조작부(예를 들어 버튼)의 조작이 트리거링되면 로봇(100a)과 태그장치(500a) 과의 거리 와 방위값을 유지하도록 제어부는 로봇의 위치를 제어한다. 그리고 제어부는 태그장치(500a)의 앞뒤/ 좌우/상하 움직임에 대응하여 거리/방위값이 유지되도록 로봇의 이동을 제어할 수 있다. 또한, 태그장치(500a)에 내장된 센서들(532, 534, 536)이 생성한 데이터가 태그장치(500a)의 회전을 지시할 경 우, 제어부는 이러한 회전에 대응하여 로봇을 회전시킬 수 있다. 도 11 및 도 12에서 추종 로봇(100a)의 제어부는 태그장치(500a)의 움직임 정보를 추적하여 추종 로봇 (100a)의 움직임을 제어한다. 보다 상세히, 추종 로봇(100a)의 제어부는 태그장치(500a)의 움직임 정보를 수신하고 태그장치(500a)와의 거리를 일정 거리 이하로 유지하도록 이동부를 제어한다. 도 13은 본 발명의 일 실시예에 의한 추종 로봇이 태그장치의 상대 위치를 추종하는 과정을 보여준다. 도 13에 서 태그장치(500a)와 추종 로봇(100a)이 배치된다. 추종 로봇(100a)은 사용자가 소지 중인 (태그장치(500a)를 추종한다. 또한, 추종 로봇(100a)외에도 최소한 2개 이상의 군집 로봇(100b, 100c, 100d)과 태그장치(500a)은 블루투스로 페어링될 수 있다. 이는 군집로봇(100b, 100c, 100d)과 태그장치(500a) 사이의 거리에 따라 자동으로 페어링되 어 일정 수 이상 동시 연결을 수행할 수 있다. 예를 들어 태그장치(500a)는 다수의 군집 로봇들이 전송하는 블루투스 패킷의 신호의 세기나 신호 품질(BLE RSSI의 SNR등 신호 품질)을 이용하여 최대 N 개의 기기들과 커넥션을 유지할 수 있다. 그리고 태그장치(500a)는 BLE RSSI 정보를 추종로봇(100a)에게 제공하거나 혹은 직접 다수의 군집 로봇들의 위치와 BLE RSSI 에 기반하여 태그장치(500a)의 위치를 추정할 수 있다. 물론, 추종 로봇(100a) 역시 다수의 군집 로봇들의 위치와 태그장치(500a)가 수신한 블루투스 패킷의 RSSI 등에 기반하여 태그장치(500a)의 위치를 추정할 수 있다. 이는, 추종 로봇(100a)의 제어부는 추종 로봇(100a)의 좌표를 (0, 0)이라고 설정하고, 각 군집로봇의 좌표 및 태그장치(500a)의 좌표를 미지수(x_i, y_i)로 설정한다. 그리고 추종 로봇(100a)의 제어부는 거리 측정값을 이용하여 모든 미지수에 대한 추정치를 계산하여 태그 장치(500a)의 위치 추정지를 산출하고, 이를 이용하여 태그장치(500a)를 추적한다. 즉, 추종 로봇(100a)의 제어부는 다수의 군집로봇(100b~100d)의 위치 정보 또는 블루투스 RSSI 정보(세기 정보) 중 어느 하나 이상을 이용하여 태그장치(500a)의 위치를 계산할 수 있다. 도 14는 본 발명의 일 실시예에 의한 거리 정보의 배열을 좌표 배열로 변환하는 과정을 보여준다. 추종 로봇 (100a)의 제어부는 각 군집로봇의 좌표 및 태그장치(500a)의 좌표를 미지수(x_i, y_i)로 하여 41과 같이 거리 정보를 배열한다. 그리고 이 값을 필터에 입력하여 좌표 배열을 산출한다. 여기서 필터는 LSF(Least Square Filter), RF(Regression Filter), 칼만 필터(Kalman Filter 혹은 딥뉴럴네트워크(Deep Neural Network) 등이 될 수 있다. 전술한 실시예를 적용할 경우, 사용자를 추적하여 이동하는 트래킹 로봇(Tracking Robot)이 사용자의 위치 추적 을 위해 UWB RTLS 기술을 사용하며, 이 과정에서 사용자 위치 추적의 정확도를 높이기 위해 블루투스 통신을 이 용한다. 이는 별도의 UWB 앵커를 로봇이 주행하는 환경에 설치할 필요가 없이 다른 로봇들을 일종의 앵커로 사용한다. 그리고 이러한 구성은 UWB 앵커의 설치 비용을 감소시키며 로봇과 태그장치 사이의 장애물로 인한 위치 측정의 오류를 제거한다. 그 결과 신호 품질 문제를 제거하여 사용자의 위치 추적의 신뢰성을 높인다. 본 발명의 실시예는 사용자를 추적하여 이동하는 배송 로봇, 카트로봇 등과 같은 트래킹 로봇에 적용하여 사용 자의 위치 추적의 정확도를 높일 수 있다. 한편, 추종 로봇(100a)은 SLAM을 수행하거나 태그 장치의 위치를 추적하는 과정에서 정확도가 높은 위치 정보를 산출할 수 있다. 또한 추종 로봇(100a)은 군집 로봇들의 위치 정보 또는 위치를 추정하는데 필요한 신호의 세기 정보들을 저장할 수 있다. 그리고 저장된 정보들을 인공지능 모듈을 이용하여 학습하여 반복적으로 위치 추정의 정확도를 높일 수 있다. 이를 위해, 제어부는 인공지능부를 포함한다. 이는 일종의 러닝 프로세서(learning processor)이며, 로봇 이 누적하여 저장된 위치 정보 및 센서가 획득한 정보, 그리고 위치 추정의 정확도에 대한 수치값을 처리 할 수 있다. 인공 지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미하며, 머신 러닝(기계 학습, Machine Learning)은 인공 지능 분야에서 다루는 다양한 문제를 정의하고 그것을 해결하는 방법론을 연구하는 분야를 의미한다. 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작업에 대한 성능을 높이는 알고리 즘으로 정의하기도 한다. 인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로써, 시냅스의 결합으로 네트워 크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층(Hidden Layer)를 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하는 시냅 스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함숫값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망의 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수 는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키 는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화 하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 인공 신경망 중에서 복수의 은닉층을 포함하는 심층 신경망(DNN: Deep Neural Network)으로 구현되는 머신 러닝 을 딥 러닝(심층 학습, Deep Learning)이라 부르기도 하며, 딥 러닝은 머신 러닝의 일부이다. 이하에서, 머신 러닝은 딥 러닝을 포함하는 의미로 사용된다. 로봇의 제어부를 구성하는 하위 구성요소인 인공지능부가 전술한 인공지능 기능을 수행할 수 있다. 이 경우, 로봇의 통신부는 유무선 통신 기술을 이용하여 다른 AI 기능을 제공하는 로봇이나 또는 도 15에서 살펴볼 AI 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 예컨대, 통신부는 외부 장치 들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 이때, 통신부가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블 루투스(Bluetooth TM), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 인터페이스부는 다양한 종류의 데이터를 획득할 수 있다. 이때, 인터페이스부는 영상 신호 입력을 위한 카메라, 오디오 신호를 수신하기 위한 마이크로폰, 사용자로 부터 정보를 입력 받기 위한 사용자 입력부 등을 포함할 수 있다. 여기서, 장애물 센서, 카메라 센서 또는 마이크로폰이 획득한 정보들은 센싱 데이터 또는 센서 정보등 지칭한다. 인터페이스부 및 각종 센서들(220, 260)과 이동부의 휠 인코더 등은 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때 사용될 입력 데이터 등을 획득할 수 있다. 전술한 구성요소들은 가 공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 제어부 또는 인공지능부는 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 인공지능부는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학습된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데이터에 대하여 결과 값 을 추론해 내는데 사용될 수 있고, 추론된 값은 로봇이 어떠한 동작을 수행하기 위한 판단의 기초로 이용 될 수 있다. 이때, 인공지능부는 AI 서버의 러닝 프로세서과 함께 AI 프로세싱을 수행할 수 있다. 이때, 인공지능부는 로봇에 통합되거나 구현된 메모리를 포함할 수 있다. 또는, 인공지능부는 별도의 메모 리 또는 로봇에 결합된 외부 메모리 또는 외부 장치에서 유지되는 메모리를 사용하여 구현될 수도 있다. 로봇은 다양한 센서들을 이용하여 로봇의 내부 정보, 로봇의 주변 환경 정보 및 사용자 정보 중 적어도 하나를 획득할 수 있다. 이때, 로봇에 포함되는 센서에는 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센서 , RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다 센서, 장애물 센서 , 카메라 센서, 레이더 등이 있다. 또한, 앞서 살펴본 인터페이스부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시킬 수 있다. 이때, 인터페이스부는 시각 정보를 출력하는 디스플레이부, 청각 정보를 출력하는 스피커, 촉각 정보를 출 력하는 햅틱 모듈 등이 포함될 수 있다. 로봇에 내장된 메모리는 로봇의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 예컨대, 로봇 에 내장된 각종 센서들이나 인터페이스부 등이 획득한 입력 데이터, 학습 데이터, 학습 모델, 학습 히스토리 등을 저장할 수 있다. 제어부는 데이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하여, 로봇의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 제어부는 로봇의 구성 요소 들을 제어하여 결정된 동작을 수행할 수 있다. 이를 위해, 제어부는 인공지능부 또는 메모리의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동작을 실행하도록 로봇의 구 성 요소들을 제어할 수 있다. 이때, 제어부는 결정된 동작을 수행하기 위하여 외부 장치의 연계가 필요한 경우, 해당 외부 장치를 제어 하기 위한 제어 신호를 생성하고, 생성한 제어 신호를 해당 외부 장치에 전송할 수 있다. 제어부는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요구 사항 을 결정할 수 있다. 이때, 제어부는 음성 입력을 문자열로 변환하기 위한 STT(Speech To Text) 엔진 또는 자연어의 의도 정보 를 획득하기 위한 자연어 처리(NLP: Natural Language Processing) 엔진 중에서 적어도 하나 이상을 이용하여, 사용자 입력에 상응하는 의도 정보를 획득할 수 있다. 이때, STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 적어도 일부가 머신 러닝 알고리즘에 따라 학습된 인 공 신경망으로 구성될 수 있다. 그리고, STT 엔진 또는 NLP 엔진 중에서 적어도 하나 이상은 인공지능부에 의해 학습된 것이나, AI 서버의 러닝 프로세서에 의해 학습된 것이거나, 또는 이들의 분산 처리에 의해 학 습된 것일 수 있다. 제어부는 로봇의 동작 내용이나 동작에 대한 사용자의 피드백 등을 포함하는 이력 정보를 수집하여 메모리 또는 인공지능부에 저장하거나, AI 서버 등의 외부 장치에 전송할 수 있다. 수집된 이력 정보는 학 습 모델을 갱신하는데 이용될 수 있다. 제어부는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 로봇의 구성 요소들 중 적어도 일 부를 제어할 수 있다. 나아가, 제어부는 는 응용 프로그램의 구동을 위하여, 로봇에 포함된 구성 요 소들 중 둘 이상을 서로 조합하여 동작시킬 수 있다. 또는 로봇과 통신하는 별도의 인공지능 서버(AI server)가 배치되고 로봇이 제공하는 정보를 처리할 수 있다. 도 15는 본 발명의 일 실시예에 의한 AI 서버의 구성을 보여준다. 인공 지능 서버, 즉 AI 서버는 머신 러닝 알고리즘을 이용하여 인공 신경망을 학습시키거나 학습된 인공 신경망을 이용하는 장치를 의미할 수 있다. 여기서, AI 서버는 복수의 서버들로 구성되어 분산 처리를 수 행할 수도 있고, 5G 네트워크로 정의될 수 있다. 이때, AI 서버는 AI 장치의 일부의 구성으로 포함되 어, AI 프로세싱 중 적어도 일부를 함께 수행할 수도 있다. AI 서버는 통신부, 메모리, 러닝 프로세서 및 프로세서 등을 포함할 수 있다. AI 서버의 통신부는 로봇등의 외부 장치와 데이터를 송수신할 수 있다. AI 서버의 메모리는 모델 저장부를 포함할 수 있다. 모델 저장부는 러닝 프로세서을 통하여 학습 중인 또는 학습된 모델(또는 인공 신경망, 231a)을 저장할 수 있다. AI 서버의 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망(731a)을 학습시킬 수 있다. 학습 모 델은 인공 신경망의 AI 서버에 탑재된 상태에서 이용되거나, 로봇등의 외부 장치에 탑재되어 이용될 수도 있다. 학습 모델은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 학습 모델의 일부 또는 전부가 소프트웨어로 구현되는 경우 학습 모델을 구성하는 하나 이상의 명령어(instruction)는 메모리 에 저장될 수 있다. 프로세서는 학습 모델을 이용하여 새로운 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기 초한 응답이나 제어 명령을 생성할 수 있다. 본 발명의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명되었다고 해서, 본 발명이 반드시 이러한 실시예에 한정되는 것은 아니며, 본 발명의 목적 범위 내에서 모든 구성 요소들 이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 또한, 그 모든 구성 요소들이 각각 하나의 독립적인 하드웨어로 구현될 수 있지만, 각 구성 요소들의 그 일부 또는 전부가 선택적으로 조합되어 하나 또는 복수 개 의 하드웨어에서 조합된 일부 또는 전부의 기능을 수행하는 프로그램 모듈을 갖는 컴퓨터 프로그램으로서 구현 될 수도 있다. 그 컴퓨터 프로그램을 구성하는 코드들 및 코드 세그먼트들은 본 발명의 기술 분야의 당업자에 의해 용이하게 추론될 수 있을 것이다. 이러한 컴퓨터 프로그램은 컴퓨터가 읽을 수 있는 저장매체(Computer Readable Media)에 저장되어 컴퓨터에 의하여 읽혀지고 실행됨으로써, 본 발명의 실시예를 구현할 수 있다. 컴 퓨터 프로그램의 저장매체로서는 자기 기록매체, 광 기록매체, 반도체 기록소자를 포함하는 저장매체를 포함한다. 또한 본 발명의 실시예를 구현하는 컴퓨터 프로그램은 외부의 장치를 통하여 실시간으로 전송되는 프로그램 모듈을 포함한다. 이상에서는 본 발명의 실시예를 중심으로 설명하였지만, 통상의 기술자의 수준에서 다양한 변경이나 변형을 가 할 수 있다. 따라서, 이러한 변경과 변형이 본 발명의 범위를 벗어나지 않는 한 본 발명의 범주 내에 포함되는 것으로 이해할 수 있을 것이다."}
{"patent_id": "10-2019-0114289", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 본 발명의 일 실시예에 의한 로봇의 외관을 보여준다. 도 3은 본 발명의 일 실시예에 의한 제어모듈의 구성을 보여준다. 도 4는 본 발명의 일 실시예에 의한 태그장치의 구성을 보여준다. 도 5는 본 발명의 일 실시예에 의한 태그장치와 추종 로봇, 그리고 군집 로봇 사이의 정보를 송수신하는 프로세 스를 보여준다. 도 6은 본 발명의 일 실시예에 의한 추종로봇과 군집로봇의 구성을 보여준다. 도 7은 도 6의 과정을 보다 상세히 설명한 도면이다. 도 8은 본 발명의 일 실시예에 의한 블루투스 필터의 세부 구성과 동작 과정을 보여준다. 도 9는 본 발명의 일 실시예에 의한 UWB 필터의 세부 구성과 동작 과정을 보여준다. 도 10은 본 발명의 일 실시예에 의한 태그 필터가 동작하는 과정을 보여준다. 도 11 및 도 12는 본 발명의 일 시시예에 의한 사용자가 태그장치를 제어할 경우 추종 로봇이 이에 대응하여 동 작하는 과정을 보여준다. 도 13은 본 발명의 일 실시예에 의한 추종 로봇이 태그장치의 상대 위치를 추종하는 과정을 보여준다. 도 14는 본 발명의 일 실시예에 의한 거리 정보의 배열을 좌표 배열로 변환하는 과정을 보여준다. 도 15는 본 발명의 일 실시예에 의한 AI 서버의 구성을 보여준다."}
