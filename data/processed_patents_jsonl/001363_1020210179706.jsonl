{"patent_id": "10-2021-0179706", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0090712", "출원번호": "10-2021-0179706", "발명의 명칭": "인공지능 기반의 의료 영상 가공 장치 및 방법", "출원인": "고려대학교 산학협력단", "발명자": "안경식"}}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 의료 영상 가공 방법에 있어서,대상자의 소정 부위를 촬영한 의료 영상 데이터를 수신하는 단계;상기 의료 영상 데이터를 상기 부위를 이루는 조직 유형에 따라 복수의 영역으로 분할하는 단계;상기 복수의 영역 각각에 대한 영상 출력 설정을 구분하여 적용하는 영상 가공을 수행하는 단계; 및상기 영상 가공이 적용된 출력 영상 데이터를 표시하는 단계,를 포함하는 것인, 의료 영상 가공 방법."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 분할하는 단계는,상기 의료 영상 데이터를 이루는 각 픽셀의 하운스 필드 유닛 값을 추출하는 단계를 포함하는 것인, 의료 영상가공 방법."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 분할하는 단계는,상기 하운스 필드 유닛 값에 기초하여 상기 복수의 영역을 구획하고, 상기 복수의 영역 각각에 대응하는 상기조직 유형을 식별하도록 인공지능 기반의 학습을 통해 미리 구축되는 분할 모델에 기초하여 상기 의료 영상 데이터를 상기 복수의 영역으로 분할하는 것인, 의료 영상 가공 방법."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 영상 가공을 수행하는 단계에서 상기 영상 출력 설정은 상기 복수의 영역 각각이 상기 출력 영상 데이터상에서 나머지 영역 대비 상대적으로 용이하게 식별되도록 상기 조직 유형에 대응하여 미리 결정되는 상기 하운스 필드 유닛 값과 연계되는 것인, 의료 영상 가공 방법."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 영상 출력 설정은 상기 하운스 필드 유닛 값에 대응하는 윈도우 레벨 설정 및 윈도우 너비 설정 중 적어도하나를 포함하는 것인, 의료 영상 가공 방법."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 영상 가공을 수행하는 단계는,상기 복수의 영역 중 상호 인접한 두 영역에 대하여 결정된 상기 하운스 필드 유닛 값 간의 차이가 미리 설정된임계 범위 이내이면, 상기 두 영역에 대한 경계 영역이 강조되도록 하는 영상 가공을 적용하는 것인, 의료 영상가공 방법.공개특허 10-2023-0090712-3-청구항 7 제4항에 있어서,상기 표시하는 단계는,상기 영상 가공이 상기 복수의 영역 각각에 대하여 적용된 출력 영상 데이터를 한 화면에 출력하는 단계;상기 복수의 영역 중 적어도 하나를 선택하는 사용자 입력을 수신하는 단계; 및상기 수신된 사용자 입력에 기초하여 상기 출력 영상 데이터를 갱신하는 단계,를 포함하는 것인, 의료 영상 가공 방법."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공지능 기반의 의료 영상 가공 장치에 있어서,대상자의 소정 부위를 촬영한 의료 영상 데이터를 수신하는 데이터 수신부;상기 의료 영상 데이터를 상기 부위를 이루는 조직 유형에 따라 복수의 영역으로 분할하는 데이터 분할부;상기 복수의 영역 각각에 대한 영상 출력 설정을 구분하여 적용하는 영상 가공을 수행하는 데이터 가공부; 및상기 영상 가공이 적용된 출력 영상 데이터를 표시하는 데이터 출력부,를 포함하는 것인, 의료 영상 가공 장치."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 데이터 분할부는,상기 의료 영상 데이터를 이루는 각 픽셀의 하운스 필드 유닛 값을 추출하는 것인, 의료 영상 가공 장치."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 데이터 분할부는,상기 하운스 필드 유닛 값에 기초하여 상기 복수의 영역을 구획하고, 상기 복수의 영역 각각에 대응하는 상기조직 유형을 식별하도록 인공지능 기반의 학습을 통해 미리 구축되는 분할 모델에 기초하여 상기 의료 영상 데이터를 상기 복수의 영역으로 분할하는 것인, 의료 영상 가공 장치."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 영상 출력 설정은 상기 하운스 필드 유닛 값에 대응하는 윈도우 레벨 설정 및 윈도우 너비 설정 중 적어도하나를 포함하는 것인, 의료 영상 가공 장치."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 데이터 출력부는,상기 영상 가공이 상기 복수의 영역 각각에 대하여 적용된 출력 영상 데이터를 한 화면에 출력하되,상기 복수의 영역 중 적어도 하나를 선택하는 사용자 입력을 수신하고 상기 사용자 입력에 기초하여 상기 출력영상 데이터를 갱신하는 것인, 의료 영상 가공 장치."}
{"patent_id": "10-2021-0179706", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제7항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있공개특허 10-2023-0090712-4-는 기록매체."}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 의료 영상 가공 장치 및 방법이 개시되며, 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 가공 방법은 대상자의 소정 부위를 촬영한 의료 영상 데이터를 수신하는 단계, 상기 의료 영상 데이터를 상기 부 위를 이루는 조직 유형에 따라 복수의 영역으로 분할하는 단계, 상기 복수의 영역 각각에 대한 영상 출력 설정을 구분하여 적용하는 영상 가공을 수행하는 단계 및 상기 영상 가공이 적용된 출력 영상 데이터를 표시하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 인공지능 기반의 의료 영상 가공 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재는 CT 등의 의료 영상을 확인할 때 사용자가 직접 윈도우 레벨 값을 조정해 특정 조직에 최적화된 수치로 각각 보아야 한다. 예를 들어, 흉부 영상의 경우 폐 윈도우 값, 종격동 윈도우 값, 뼈 윈도우 값을 바꿔가며 영상을 판독하고 복부 의 경우도 연부조직 윈도우 값, 뼈 윈도우값을 조절해가며 영상을 보게 된다. 또한 골절을 확인하기 위해 일반적인 사지 혹은 척수 영상에서 윈도우 값을 조정하면 디스크나 신경 등의 연부 조직 정보를 얻을 수 있지만 전문가의 부재 혹은 시간 부족으로 많은 영상 정보들이 버려지고 있으며, 의료 영 상에 반영된 각각의 조직을 인식하고, 해당 조직에 대응하여 최적화된 윈도우 설정을 자동으로 적용하는 기술은 아직 도입된바 없다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-1971625호에 개시되어 있다."}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 대상자의 소정 부위를 촬영한 의료 영상 데이터 를 수신하여 조직 유형에 따라 복수의 영역으로 분할하고 복수의 영역 각각에 대한 영상 출력 설정을 구분하여 표시하는 인공지능 기반의 의료 영상 가공 방법 및 장치를 제공하는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 수단으로서, 본원의 일 실시예에 따른 의료 영상 가공 방법은 대상자의 소 정 부위를 촬영한 의료 영상 데이터를 수신하는 단계, 상기 의료 영상 데이터를 상기 부위를 이루는 조직 유형 에 따라 복수의 영역으로 분할하는 단계, 상기 복수의 영역 각각에 대한 영상 출력 설정을 구분하여 적용하는 영상 가공을 수행하는 단계 및 상기 영상 가공이 적용된 출력 영상 데이터를 표시하는 단계를 포함할 수 있다. 또한, 상기 분할하는 단계는, 상기 의료 영상 데이터를 이루는 각 픽셀의 하운스 필드 유닛 값을 추출하는 단계 를 포함할 수 있다. 또한, 상기 분할하는 단계는, 상기 하운스 필드 유닛 값에 기초하여 상기 복수의 영역을 구획하고, 상기 복수의 영역 각각에 대응하는 상기 조직 유형을 식별하도록 인공지능 기반의 학습을 통해 미리 구축되는 분할 모델에 기초하여 상기 의료 영상 데이터를 상기 복수의 영역으로 분할할 수 있다. 또한, 상기 영상 가공을 수행하는 단계에서 상기 영상 출력 설정은 상기 복수의 영역 각각이 상기 출력 영상 데 이터 상에서 나머지 영역 대비 상대적으로 용이하게 식별되도록 상기 조직 유형에 대응하여 미리 결정되는 상기 하운스 필드 유닛 값과 연계할 수 있다. 또한, 상기 영상 출력 설정은 상기 하운스 필드 유닛 값에 대응하는 윈도우 레벨 설정 및 윈도우 너비 설정 중 적어도 하나를 포함할 수 있다. 또한, 상기 표시하는 단계는, 상기 영상 가공이 상기 복수의 영역 각각에 대하여 적용된 출력 영상 데이터를 한 화면에 출력하는 단계, 상기 복수의 영역 중 적어도 하나를 선택하는 사용자 입력을 수신하는 단계 및 상기 수 신된 사용자 입력에 기초하여 상기 출력 영상 데이터를 갱신하는 단계를 포함할 수 있다.또한, 상기 영상 가공을 수행하는 단계는, 상기 복수의 영역 중 상호 인접한 두 영역에 대하여 결정된 상기 하 운스 필드 유닛 값 간의 차이가 미리 설정된 임계 범위 이내이면, 상기 두 영역에 대한 경계 영역이 강조되도록 하는 영상 가공을 적용할 수 있다. 한편, 본원의 일 실시예에 따른 의료 영상 가공 장치는 대상자의 소정 부위를 촬영한 의료 영상 데이터를 수신 하는 데이터 수신부, 상기 의료 영상 데이터를 상기 부위를 이루는 조직 유형에 따라 복수의 영역으로 분할하는 데이터 분할부, 상기 복수의 영역 각각에 대한 영상 출력 설정을 구분하여 적용하는 영상 가공을 수행하는 데이 터 가공부 및 상기 영상 가공이 적용된 출력 영상 데이터를 표시하는 데이터 출력부를 포함할 수 있다. 또한, 상기 데이터 분할부는 상기 의료 영상 데이터를 이루는 각 픽셀의 하운스 필드 유닛 값을 추출할 수 있다. 또한, 상기 데이터 분할부는, 상기 하운스 필드 유닛 값에 기초하여 상기 복수의 영역을 구획하고, 상기 복수의 영역 각각에 대응하는 상기 조직 유형을 식별하도록 인공지능 기반의 학습을 통해 미리 구축되는 분할 모델에 기초하여 상기 의료 영상 데이터를 상기 복수의 영역으로 분할할 수 있다. 또한, 상기 영상 출력 설정은 상기 하운스 필드 유닛 값에 대응하는 윈도우 레벨 설정 및 윈도우 너비 설정 중 적어도 하나를 포함할 수 있다. 또한, 상기 데이터 출력부는 상기 영상 가공이 상기 복수의 영역 각각에 대하여 적용된 출력 영상 데이터를 한 화면에 출력하되, 상기 복수의 영역 중 적어도 하나를 선택하는 사용자 입력을 수신하고 상기 사용자 입력에 기 초하여 상기 출력 영상 데이터를 갱신할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 인공지능 기반의 의료 영상 가공 방법 및 장치를 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 의료 영상에서 해당 위치가 어떤 조직인지 파악하여 그 조직을 가장 잘 나타내는 최적화된 윈도우 값으로 영상을 구성하여 표시할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 자동으로 조직을 인식하고 해당 조직에 최적화된 윈도우 값으로 합성 된 영상을 보여줌으로써 윈도우 값을 조절해야하는 불편함을 없애고 불필요한 시간과 노력을 줄여 빠르게 의료 영상 판독을 할 수 있다. 전술한 본원이 과제 해결 수단에 의하면, 디스크나 신경, 근육 등 하운스 필드 유닛 값이 비슷한 연부조직 내 여러 조직들의 대조도를 극대화하여 표시함으로써 영상의학 전문가의 부재 또는 시간이 부족한 일차 진료 혹은 응급 진료 현장에서 진단 정확도를 높이고 오진율을 낮출 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\" 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 인공지능 기반의 의료 영상 가공 방법 및 장치에 관한 것이다. 도 1은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 가공 장치의 개략적인 구성도이다. 도 1을 참조하면, 본원에서 개시하는 인공지능 기반의 의료 영상 가공 장치(이하, '의료 영상 가공 장치 '라 한다.)는 데이터 수신부, 데이터 분할부, 데이터 가공부 및 데이터 출력부를 포 함할 수 있다. 데이터 수신부는 대상자의 소정 부위를 촬영한 의료 영상 데이터를 수신할 수 있다. 예를 들면, 대상자의 소정 부위는 두부, 흉부, 복부, 혈관, 심장 중 어느 한 부위 일 수 있으나, 이에 한정되지는 않으며, 대상자의 질환, 증상 등을 고려하여 대상자의 신체를 이루는 다양한 부위로 결정될 수 있음은 물론이다. 본원의 일 실시예에 따르면, 의료 영상 가공 장치는 자기공명영상(Magnetic Resonance Imaging, MRI) 스 캐너, 초음파 영상 촬영 장치, 컴퓨터 단층촬영(Computerized Tomography, CT) 스캐너 등의 의료 영상 촬영 디 바이스(미도시)와 연동될 수 있다. 예시적으로, 의료 영상 가공 장치는 의료 영상 촬영 디바이스에 탑재되 거나 설치되는 형태로 의료 영상 촬영 디바이스와 일체로 구비되거나 본원의 구현예에 따라서는 의료 영상 촬영 디바이스와 독립적인 디바이스로 마련되어 의료 영상 촬영 디바이스로부터 의료 영상 데이터를 수신하여 가공하 도록 동작하는 것일 수 있다. 이와 관련하여, 의료 영상 촬영 디바이스(미도시)의 유형에 따라 의료 영상 가공 장치로 제공되는 의료 영 상 데이터는 X-선 영상, 자기공명영상(MRI) 영상, CT이미지, 초음파 영상 등에 해당할 수 있다. 또한, 의료 영상 가공 장치에 의해 후술하는 영상 가공이 적용된 출력 영상 데이터는 의료 영상 가공 장치 와 연동하는 사용자 단말(미도시)을 통해 출력(표시)되는 것일 수 있다. 사용자 단말(미도시)은 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 의료 영상 가공 장치, 의료 영상 촬영 디바이스(미도시) 및 사용자 단말(미도시) 상호간은 네트워크를 통 해 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조 를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 데이터 분할부는 수신한 의료 영상 데이터를 대상자의 소정 부위를 이루는 조직 유형에 따라 복수의 영역 으로 분할할 수 있다. 데이터 분할부는 의료 영상 데이터를 이루는 각 픽셀의 하운스 필드 유닛 값을 추출할 수 있다. 이와 관련하여, 하운스 필드 유닛(Hounsfield Units)이란, CT를 이용한 의료 영상을 렌더링할 때 사용하는 단위 로, 이 단위를 통해 CT로 촬영한 영상에서 어떤 물체가 있는지 찾을 수 있다. 하운스 필드 유닛은 물을 0으로 기준값으로 삼고, 범위는 약 -1000 내지 3000의 값을 가져 12bits의 데이터로 표현할 수 있다. 데이터 분할부는 의료 영상 데이터를 이루는 각 픽셀 값을 하운스 필드 유닛 값으로 변환할 수 있다. 엑스 선의 흡수 정도를 컴퓨터 단층 촬영한 수치인 하운스 필드 유닛 값은 물이 0, 공기가 -1000, 밀도가 큰 뼈가 +1000이며, 그 밖의 다른 물질들은 각각 엑스선의 감쇄 정도에 따라 -1000에서 +1000사이의 값을 가지게 된다. 한편, 본원의 실시예에 관한 설명에서 조직 유형은 뼈 조직, 연조직, 지방 조직, 근육 조직 등을 포함할 수 있 다. 또한, 데이터 분할부는 인공지능 기반 학습을 통해 구축되는 분할 모델을 통해 각 영역의 해당 조직을 가 장 잘 표시해주는 하운스 필드 유닛 값을 미리 결정 할 수 있다. 예를 들어, 폐는 -500, 지방은 -100 내지 -50, 근육은 10 내지 40, 연조직은 100 내지 300, 뼈(해면골)는 300 내지 400, 피질골은 1800 내지 1900의 범위를 만족하는 하운스 필드 유닛 값으로 각 조직의 유형에 대응하여 미 리 결정 될 수 있다. 구체적으로, 데이터 분할부는 의료 영상 데이터의 각 픽셀 별 하운스 필드 유닛 값에 기초하여 의료 영상 데이터를 조직 유형에 따라 복수의 영역을 구획하고, 복수의 영역 각각에 대응하는 조직 유형을 식별하도록 인 공지능 기반의 학습을 통해 미리 구축되는 분할 모델에 기초하여 수신한 의료 영상 데이터를 분할할 수 있다. 다른 예로, 데이터 분할부는 의료 영상 데이터의 각 픽셀 별 색상 정보(예를 들면, 그레이 레벨, RGB 데이 터 등)에 기초하여 의료 영상 데이터를 이루는 각각의 영역을 구획하고, 구획된 각각의 영역에 대응하는 조직의 유형을 파악하도록 미리 학습되는 인공지능 기반의 분할 모델을 이용하여 의료 영상 데이터를 분할하는 것일 수 있다. 여기서, 인공지능 기반의 학습을 통해 구축되는 분할 모델은 예를 들어 CNN(Convolutional Neural Network)과 같이 영상 분석에 적합한 딥러닝 모델로 구현될 수 있다. 인공 지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미하며, 머신 러닝(기계 학습, Machine Learning)은 인공 지능 분야에서 다루는 다 양한 문제를 정의하고 그것을 해결하는 방법론을 연구하는 분야를 의미한다. 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작업에 대한 성능을 높이는 알고리즘으로 정의하기도 한다. 다른 예로, 인공지능 기반의 학습을 통해 구축되는 분할 모델은 미리 정의된 클래스(객체 유형)로 입력된 이미 지(의료 영상 데이터)의 각 픽셀에 대한 분류 범주를 결정하도록 학습되는 의미론적 영역 분할(Semantic Segmentation) 기반의 모델일 수 있다. 이와 관련하여, 본원의 일 실시예에 따른 의미론적 영역 분할 기반의 분 할 모델은 영역 분할을 위한 클래스로서 전술한 각각의 조직 유형을 고려하는 모델일 수 있다. 한편, 인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로써, 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층(Hidden Layer)를 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하는 시냅 스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함수값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망의 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수 는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키 는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화 하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 데이터 가공부는 분할된 복수의 영역 각각에 대한 영상 출력 설정을 구분하여 적용하는 영상 가공을 수행 할 수 있다. 도 2는 조직 유형에 따라 최적화된 윈도우 값을 설정하여 출력한 결과를 예시적으로 나타낸 도면이다. 도 2를 참조하면, 본원의 실시예에 관한 설명에서 \"영상 출력 설정\"은 구획된 복수의 영역 각각이 출력 영상 데 이터 상에서 나머지 영역 대비 상대적으로 용이하게 식별되도록 조직 유형에 대응하여 미리 결정되는 하운스 필 드 유닛 값과 연계될 수 있다. 또한 영상 출력 설정은 구체적으로 하운스 필드 유닛 값에 대응하는 윈도우 레벨 설정 및 윈도우 너비 설정 중 적어도 하나를 포함할 수 있다. 윈도우 너비란 흑백의 여러 단계인 농도범위로 표현 할 수 있는 CT Number들의 범위이며, 윈도우 레벨은 농도범 위의 중앙 값이다. 윈도우 너비는 영상의 대조도에 직접적인 영향을 미칠 수 있다. 즉, 윈도우 너비는 흑백으로 표시되는 CT수의 범위를 나타내는 것으로 윈도우 너비가 작을수록 표시되는 CT Number의 폭이 좁고, 윈도우 너비가 클수록 CT Number의 폭은 넓어진다. 또한, 윈도우 너비가 좁으면 흑백이 뚜렷한 상으로 되고 넓으면 흑과 백의 중간 농도인 다양한 상으로 될 수 있 다. 구체적으로, 윈도우 너비를 넓게 설정하면 표시되는 농도범위가 커져 영상의 대조도가 나빠지고 밀도범위도 커 져 영상의 분해능이 저하될 수 있다. 반면에 윈도우 너비를 좁게 설정하면 표시되는 농도 범위가 작아져서 영상 의 대조도가 좋아지고 밀도범위가 작아져 분해능이 향상된다. 또한 반음영이 감소되어 흡수치가 적은 조직을 영 상화하기 용이하다. 윈도우 레벨은 선감약계수, 흡수치, 농도와 직접적인 관련이 있는 것으로, 공기와 같이 선감약계수가 적은 조직 을 관찰할 때는 윈도우 레벨을 낮게 설정하고, 뼈과 같은 선감약계수가 큰 조직(X선 흡수치가 높은 물질)을 관 찰 할 때는 윈도우 레벨을 높게 설정할 수 있다. 이와 관련하여, 전술한 도 2에 도시된 폐 CT 이미지를 참조하여 분할된 복수의 영역 각각이 나머지 영역 대비 상대적으로 용이하게 식별되도록 미리 결정되는 하운스 필드 유닛 값 및 이에 대응하는 윈도우 설정을 적용하는 본원에서 개시하는 가공 프로세스를 보다 구체적으로 설명하면, 데이터 가공부는 도 2의 (a)와 같이 종래 의 soft tissue setting에 따른 윈도우 설정을 적용하는 경우 출력 영상 데이터 상에서 잘 식별(예를 들면, 밝 게 표시)되는 연조직 영역에 대하여는 국부적으로 soft tissue setting에 대응하는 하운스 필드 유닛 값에 따른 윈도우 설정을 적용하고, 도 2의 (b)와 같이 종래의 lung tissue setting에 따른 윈도우 설정을 적용하는 경우 출력 영상 데이터 상에서 잘 식별되는 폐조직 영역에 대하여 국부적으로 lung tissue setting에 대응하는 하운 스 필드 유닛 값에 따른 윈도우 설정을 적용하고, 도 2의 (c)와 같이 종래의 bone setting에 따른 윈도우 설정 을 적용하는 경우 출력 영상 데이터 상에서 잘 식별되는 뼈 영역에 대하여 국부적으로 bone setting에 대응하는 하운스 필드 유닛 값에 따른 윈도우 설정을 적용하는 등 공간적으로 구획된 복수의 영역에 대하여 서로 다른 윈 도우 설정을 적용하는 가공을 의미할 수 있다. 도 3은 복수의 영역 중 상호 인접한 두 영역의 하운스 필드 유닛 값 간의 차이가 미리 설정된 임계 범위 이내일 경우 두 영역에 대한 경계 영역이 강조되도록 출력한 결과를 예시적으로 나타낸 도면이다. 도 3을 참조하면, 복수의 영역 중 상호 인접한 두 영역에 대하여 결정된 하운스 필드 유닛 값 간의 차이가 미리 설정된 임계 범위 이내이면, 두 영역에 대한 경계 영역이 강조되도록 하는 영상 가공을 적용할 수 있다. 예를 들어, 데이터 가공부는 디스크나 신경, 근육 등 하운스 필드 유닛 값이 비슷한 연부조직 내 여러 조 직은 color mapping 또는 경계선을 오버레이 함으로써 대조도를 극대화하여 디스플레이하도록 영상을 가공 할 수 있다. 이와 관련하여, 전술한 도 3에 도시된 상호 인접한 두 영역의 하운스 필드 유닛 값 간의 차이가 미리 설정된 임 계 범위 이내일 경우 두 영역에 대한 경계 영역을 강조하는 영상 가공 프로세스를 보다 구체적으로 설명하면, 데이터 가공부는 도 3의 (a) 및 (b)와 같이 각 영역을 구분하는 분할 알고리즘을 통해 뼈 영역에 대응하는 윈도우 값과 디스크에 대응하는 윈도우 값을 조정함으로써 하나의 이미지에서 뼈와 디스크를 구분하여 영상으로 출력할 수 있고, 도 3의 (c)와 같이 각 영역의 경계를 구분하는 분할 알고리즘을 통해 근육이나, 신경, 디스크 등의 연부조직에 해당되어 하운스 유닛 필드 값의 차이가 크지 않은 조직은 color mapping 또는 경계선을 오버 레이하는 등 상호 인접한 두 영역에 대하여 서로 다른 윈도우 설정을 적용하거나 color mapping 또는 경계선 오 버레이를 적용하는 가공을 의미할 수 있다. 데이터 출력부는 데이터 가공부에 의한 영상 가공이 적용된 출력 영상 데이터를 표시할 수 있다. 도 4는 복수의 영역 각각에 대하여 적용된 출력 영상 데이터를 한 화면에 출력한 결과를 예시적으로 나타낸 도 면이다. 도 4는 참조하면, 의료 영상 가공 장치는 조직을 인식하고 해당 조직들에 최적화된 윈도우 값을 적용하고 하나로 합성된 영상을 출력할 수 있다. 구체적으로, 데이터 출력부는 입력된 의료 영상 데이터에 대하여 제1유형 조직에 대응하는 영상 출력 설정 이 적용된 영상인 제1윈도우 영상을 기반으로 하여, 해당 의료 영상 데이터에 대하여 제2유형 조직에 대응하는 영상 출력 설정이 적용된 영상인 제2윈도우 영상의 일부분을 전술한 제1윈도우 영상 내에서 제2유형 조직에 해 당하는 것으로 식별된 영역에 오버레이 하는 방식으로 제1유형 조직과 제2유형 조직이 모두 용이하게 식별되도 록 합성된 영상인 출력 영상 데이터를 생성할 수 있다. 보다 구체적으로 이해를 돕기 위해 예시하면, 데이터 출력부는 수신된 의료 영상 데이터에 대하여 연부조 직에 대응하는 영상 출력 설정이 적용된 윈도우 영상(제1윈도우 영상)을 바탕으로 하여 해당 의료 영상 데이터 에서 뼈 부위로 식별된 영역에 대하여 뼈 조직에 대응하는 영상 출력 설정이 적용된 윈도우 영상(제2윈도우 영 상)을 국부적으로 오버레이 하는 방식으로 연부조직 대응 설정과 뼈 조직 대응 설정이 종합 적용된 출력 영상 데이터를 생성할 수 있다. 또 다른 예로, 데이터 출력부는 수신된 의료 영상 데이터에 대하여 연부조직에 대응하는 영상 출력 설정이 적용된 윈도우 영상(제1윈도우 영상)을 바탕으로 하여 해당 의료 영상 데이터에서 폐 부위로 식별된 영역에 대 하여 폐 조직에 대응하는 영상 출력 설정이 적용된 윈도우 영상(제2윈도우 영상)을 국부적으로 오버레이 하는 방식으로 연부조직 대응 설정과 폐 조직 대응 설정이 종합 적용된 출력 영상 데이터를 생성할 수 있다. 또한, 본원의 일 실시예에 따르면, 데이터 출력부는 제1유형 조직에 대응하는 윈도우 영상과 제2유형 조직 에 대응하는 윈도우 영상이 합성된 상태의 영상에 대하여 제3유형 조직에 대응하는 윈도우 영상을 추가로 오버 레이 할 수도 있다. 예시적으로, 데이터 출력부는, 연부조직과 뼈 조직에 따른 윈도우 영상이 하나로 합성 된 영상에 폐 조직에 대응하는 윈도우 영상을 추가로 오버레이함으로써 연부조직, 뼈 조직, 폐 조직이 모두 용 이하게 식별될 수 있는 형태로 합성된 영상을 생성할 수 있다. 또한, 본원의 다른 실시예에 따르면, 데이터 출력부는 제1윈도우 영상으로부터 제1유형 조직에 해당하는 것으로 식별된 부분과 제2윈도우 영상으로부터 제2유형 조직에 해당하는 것으로 식별된 부분을 각각의 조직 유 형에 대응하는 영상 출력 설정이 적용된 상태로 개별 추출한 후, 개별 추출된 영상이 한 화면에 출력될 수 있도 록 공간적으로 병합하는 방식으로 출력 영상 데이터를 생성 및 출력할 수 있다. 또한, 데이터 출력부는 영상 가공이 복수의 영역 각각에 대하여 적용된 출력 영상 데이터를 한 화면에 출 력한 후, 복수의 영역 중 적어도 하나를 선택하는 사용자 입력을 수신할 수 있다. 또한, 데이터 출력부는 수신된 사용자 입력에 기초하여 기 생성된 출력 영상 데이터를 갱신할 수 있다. 구체적으로, 데이터 출력부는 입력된 사용자 입력에 따라 선택된 영역에 포함되는 부위의 조직 유형에 대 응하는 영상 출력 설정을 출력 영상 데이터에 대하여 적용할 수 있다. 달리 말해, 데이터 출력부는 도 4에 도시된 바와 같이 촬영 대상 부위를 이루는 각각의 조직 유형에 따라 분할(구획)되고, 조직 유형에 대응하는 부 분이 모두 용이하게 식별되도록 영상 출력 설정(예를 들면, 윈도우 설정 등)이 분할(구획)된 영역 별로 개별적 으로 적용된 상태로 출력되는 출력 영상 데이터에 대하여 특정 조직 유형 또는 특정 조직 유형에 해당하는 영역 을 선택하는 사용자 입력을 사용자가 인가하면, 선택된 조직 유형에 대응하는 영상 출력 설정이 전체적으로 적 용되도록 출력 영상 데이터를 갱신할 수 있다. 예를 들어, 데이터 출력부는 연부 조직, 뼈 조직 및 폐 조직을 포함하도록 촬영된 의료 영상 데이터에 대 한 가공(증강)을 통해 연부 조직, 뼈 조직 및 폐 조직 각각에 대하여 영상 가공이 적용된 출력 영상 데이터에 대하여 사용자가 뼈 조직을 선택하는 사용자 입력을 인가하면, 출력 영상 데이터에 대하여 뼈 조직에 부합하는 영역이 나머지 영역(예를 들면, 연부 조직, 폐 조직 등) 대비 상대적으로 용이하게 식별되도록 결정되는 영상 출력 설정을 적용할 수 있다. 한편, 출력 영상 데이터에 대하여 특정 조직을 선택하는 사용자 입력은 본원의 일 실시예에 따르면, 토글 선택 입력, 체크 박스 기반 선택 방식, 스크롤 방식 등에 기반하여 인가되는 것일 수 있으나, 이에만 한정되는 것은 아니다. 또한, 본원의 일 실시예에 따르면, 데이터 출력부는 선택된 영역에 대한 영상 출력 설정을 변경하는 사용 자 입력을 추가로 수신하여 선택된 영역에 대하여 국부적으로 적용되는 영상 출력 설정값(예를 들면, 윈도우 너 비, 윈도우 레벨 등)을 소정의 값으로 세밀하게 가변하도록 동작할 수도 있다. 즉, 의료 영상 가공 장치는 복수의 영역들을 한 화면에 동시에 디스플레이하되 명암, 밝기 등을 고려한 사 용자의 선호도에 따라 인가되는 사용자 입력에 기초하여 출력 영상 데이터를 갱신할 수 있다. 상기와 같은 구성에 의하여, 사용자가 선호하는 영상의 출력을 사용자가 임의대로 설정할 수 있을 뿐 아니라, 한 화면에 디스플레이된 복수의 영역들을 기준으로 참고하여 보다 정확히 사용자의 선호에 맞는 영상의 출력을 선택하고 설정할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 5는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 가공 방법에 대한 동작 흐름도이다. 도 5를 참조하면, 단계 S501에서 데이터 수신부는 대상자의 소정 부위를 촬영한 의료 영상 데이터를 수신 할 수 있다. 다음으로, 단계 S502에서 데이터 분할부는 의료 영상 데이터를 부위를 이루는 조직 유형에 따라 복수의 영 역으로 분할할 수 있다. 또한, 단계 S502에서 데이터 분할부는 의료 영상 데이터를 이루는 각 픽셀의 하운스 필드 유닛 값을 추출 할 수 있다. 또한, 단계 S502에서 데이터 분할부는 하운스 필드 유닛 값에 기초하여 복수의 영역을 구획하고, 복수의 영역 각각에 대응하는 조직 유형을 식별하도록 인공지능 기반의 학습을 통해 미리 구축되는 분할 모델에 기초하 여 의료 영상 데이터를 복수의 영역으로 분할할 수 있다. 다음으로, 단계 S503에서 데이터 가공부는 복수의 영역 각가에 대한 영상 출력 설정을 구분하여 적용하는 영상 가공을 할 수 있다. 또한, 단계 S503에서 데이터 가공부의 영상 출력 설정은 복수의 영역 각각이 출력 영상 데이터 상에서 나 머지 영역 대비 상대적으로 용이하게 식별되도록 조직 유형에 대응하여 미리 결정되는 하운스 필드 유닛 값과 연계될 수 있다. 또한, 영상 출력 설정은 하운스 필드 유닛 값에 대응하는 윈도우 레벨 설정 및 윈도우 너비 설정 중 적어도 하 나를 포함할 수 있다. 또한, 단계 S503에서 데이터 가공부는 복수의 영역 중 상호 인접한 두 영역에 대하여 결정된 하운스 필드 유닛 값 간의 차이가 미리 설정된 임계 범위 이내이면, 두 영역에 대한 경계 영역이 강조되도록 하는 영상 가공 을 적용할 수 있다. 다음으로, S504단계에서 데이터 출력부는 영상 가공이 적용된 출력 영상 데이터를 표시할 수 있다. 또한, S504단계에서 데이터 출력부는 영상 가공이 복수의 영역 각각에 대하여 적용된 출력 영상 데이터를 한 화면에 출력하고, 복수의 영역 중 적어도 하나를 선택하는 제1사용자 입력 및 해당 영역에 대한 영상 출력 설정을 변경하는 제2사용자 입력을 수신하고, 제1사용자 입력 및 제2사용자 입력에 기초하여 출력 영상 데이터 를 갱신할 수 있다. 본원의 일 실시예에 따르면, 단계 S504에서 데이터 출력부는 의료 영상 데이터에 대하여 제1유형 조직에 대응하는 영상 출력 설정이 적용된 영상인 제1윈도우 영상을 기반으로 하여, 의료 영상 데이터에 대하여 제2유 형 조직에 대응하는 영상 출력 설정이 적용된 영상인 제2윈도우 영상의 일부분을 전술한 제1윈도우 영상 내에서제2유형 조직에 해당하는 것으로 식별된 영역에 오버레이 하는 방식으로 출력 영상 데이터를 생성할 수 있다. 다른 예로, 단계 S504에서 데이터 출력부는 제1윈도우 영상으로부터 제1유형 조직에 해당하는 것으로 식별 된 부분과 제2윈도우 영상으로부터 제2유형 조직에 해당하는 것으로 식별된 부분을 각각의 조직 유형에 대응하 는 영상 출력 설정이 적용된 상태로 개별 추출한 후, 개별 추출된 영상이 한 화면에 출력될 수 있도록 공간적으 로 병합하는 방식으로 출력 영상 데이터를 생성 및 출력할 수 있다. 상술한 설명에서, 단계 S501 내지 S504는 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있 다. 본원의 일 실시 예에 따른 인공지능 기반의 의료 영상 가공 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있 는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프 로그램명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프 로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이 프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 전술한 본원의 설명은 예시를 위한"}
{"patent_id": "10-2021-0179706", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명 되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들 도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2021-0179706", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 가공 장치의 개략적인 구성도이다. 도 2는 조직 유형에 따라 최적화된 윈도우 값을 설정하여 출력한 결과를 예시적으로 나타낸 도면이다. 도 3은 복수의 영역 중 상호 인접한 두 영역의 하운스 필드 유닛 값 간의 차이가 미리 설정된 임계 범위 이내일 경우 두 영역에 대한 경계 영역이 강조되도록 출력한 결과를 예시적으로 나타낸 도면이다. 도 4는 복수의 영역 각각에 대하여 윈도우 값이 적용된 출력 영상 데이터를 한 화면에 출력한 결과를 예시적으 로 나타낸 도면이다. 도 5는 본원의 일 실시예에 따른 인공지능 기반의 의료 영상 가공 방법에 대한 동작 흐름도이다."}
