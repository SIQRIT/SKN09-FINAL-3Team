{"patent_id": "10-2019-0136894", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0051516", "출원번호": "10-2019-0136894", "발명의 명칭": "촉매의 활성도를 예측하는 방법 및 전자 장치", "출원인": "한국과학기술연구원", "발명자": "김동훈"}}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 제1 소재를 구성하는 적어도 하나의 제1 원자에 관련된 제1 정보 및 흡착물을 구성하는 적어도 하나의 제2 원자에 관련된 제2 정보를 사용자로부터 수신하는 단계;상기 전자 장치가 상기 수신된 제1 정보 및 제2 정보를 흡착 에너지를 추정하는 학습 모델에 적용하는 단계; 및상기 전자 장치가 상기 학습 모델로부터 출력된 흡착 에너지를 출력하는 단계;를 포함하고,상기 학습 모델은상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 제1 원자, 상기 제2 원자 및 이들의 결합을 그래프로 모델링하고, 상기 모델링된 그래프를 벡터로 변환하고, 변환된 벡터를 이용하여 흡착 에너지를 추정하도록 학습된 것인, 방법."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 학습 모델은,상기 적어도 하나의 제1 원자 및 상기 적어도 하나의 제2 원자 중에서 적어도 하나를 노드로 모델링하고, 상기 적어도 하나의 제1 원자 사이의 결합, 상기 적어도 하나의 제2 원자 사이의 결합, 상기 적어도 하나의 제1원자와 상기 적어도 하나의 제2 원자 사이의 결합 중에서 적어도 하나를 엣지로 모델링함으로써, 상기 그래프를모델링하도록 학습된 것인, 방법."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 학습 모델은, 상기 제1 정보에 기초하여, 상기 제1 소재의 구조를 제1 그래프로 모델링하고,상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 제1 소재의 표면의 구조 및 상기 흡착물의 구조를 제2 그래프로 모델링하도록 학습된 것인, 방법."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 학습 모델은,상기 제1 소재의 최외곽층을 구성하는 제3 원자들과, 상기 최외곽층의 바로 아래층을 구성하는 제4 원자들에 기초하여 상기 제1 소재의 표면의 구조를 제2 그래프로 모델링하도록 학습된 것인, 방법."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2021-0051516-3-제1 항에 있어서,상기 제1 정보는 상기 제1 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(meltingpoint), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나를 포함하고,상기 제2 정보는 상기 제2 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(meltingpoint), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나를 포함하는,방법."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 방법은, 상기 전자 장치가 상기 적어도 하나의 제1 원자 사이의 결합 거리, 상기 적어도 하나의 제2 원자 사이의 결합거리, 상기 적어도 하나의 제1 원자와 상기 적어도 하나의 제2 원자 사이의 결합 거리 중에서 적어도 하나에 관련된, 제3 정보를 수신하는 단계; 및상기 전자 장치가 상기 수신된 제3 정보를 상기 학습 모델에 적용하는 단계를 더 포함하고,상기 학습 모델은, 상기 제3 정보에 기초하여 상기 그래프를 모델링하도록 학습된 것인, 방법."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 제1 정보 및 상기 제2 정보를 수신하는 단계는,상기 전자 장치가 적어도 하나의 노드 엘리먼트 및 적어도 하나의 엣지 엘리먼트를 그래픽 인터페이스로 제공하는 단계;상기 전자 장치가 상기 적어도 하나의 노드 엘리먼트를 배열하는 제1 사용자 입력을 수신하는 단계;상기 전자 장치가 상기 노드 엘리먼트를 연결하도록 적어도 하나의 엣지 엘리먼트를 배열하는 제2 사용자 입력을 수신하는 단계;상기 전자 장치가 상기 노드 엘리먼트에 상기 제1 정보 및 상기 제2 정보 중에서 적어도 하나를 입력하는 제3사용자 입력을 수신하는 단계; 및상기 전자 장치가 상기 적어도 하나의 제1 원자 사이의 결합 거리, 상기 적어도 하나의 제2 원자 사이의 결합거리, 상기 적어도 하나의 제1 원자와 상기 적어도 하나의 제2 원자 사이의 결합 거리 중에서 적어도 하나에 관련된 정보를 상기 엣지 엘리먼트에 입력하는 제4 사용자 입력을 수신하는 단계;를 포함하고,상기 학습 모델은,상기 제1 사용자 입력, 상기 제2 사용자 입력, 상기 제3 사용자 입력 및 상기 제4 사용자 입력 중에서 적어도하나에 기초하여 상기 그래프를 모델링하도록 학습된 것인, 방법."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 소재를 구성하는 적어도 하나의 제1 원자에 관련된 제1 정보 및 흡착물을 구성하는 적어도 하나의 제2 원자공개특허 10-2021-0051516-4-에 관련된 제2 정보를 사용자로부터 수신하는, 사용자 입력부;상기 수신된 제1 정보 및 제2 정보를 흡착 에너지를 추정하는 학습 모델에 적용하는 프로세서; 및상기 학습 모델로부터 출력된 흡착 에너지를 출력하는 출력부;를 포함하고,상기 학습 모델은,상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 제1 원자, 상기 제2 원자 및 이들의 결합을 그래프로 모델링하고, 상기 모델링된 그래프를 벡터로 변환하고, 변환된 벡터를 이용하여 흡착 에너지를 추정하도록 학습된 것인, 전자 장치."}
{"patent_id": "10-2019-0136894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항 내지 제7 항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 비 일시적인 기록매체."}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 촉매의 활성도를 예측하는 방법의 일 실시예는, 전자 장치가 제1 소재를 구성하는 적어도 하나의 제 1 원자에 관련된 제1 정보 및 흡착물을 구성하는 적어도 하나의 제2 원자에 관련된 제2 정보를 사용자로부터 수 신하는 단계, 상기 수신된 제1 정보 및 제2 정보를 흡착 에너지를 추정하는 학습 모델에 적용하는 단계 및 상기 학습 모델로부터 출력된 흡착 에너지를 출력하는 단계;를 포함하고, 상기 학습 모델은 상기 제1 정보 및 상기 제 2 정보에 기초하여, 상기 제1 원자, 상기 제2 원자 및 이들의 결합을 그래프로 모델링하고, 상기 모델링된 그래 프를 벡터로 변환하고, 변환된 벡터를 이용하여 흡착 에너지를 추정하도록 학습된 것 일 수 있다."}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 촉매의 활성도를 예측하는 방법 및 전자 장치에 관한 것이다."}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "촉매는 화학 반응에 참여하여 화학 반응의 속도를 증가 또는 감소시키고, 반응 전후는 원래대로 존재하는 물질 을 의미한다. 촉매는 활성화 에너지를 조절하기 때문에, 화학 반응을 제어하는데 빈번하게 이용된다. 하나의 화학 반응에는 여러 종류의 촉매가 이용될 수 있다. 화학 반응에 가장 적합한 촉매를 결정하기 위해서는 촉매 의 활성도와 안정성을 검토할 필요가 존재한다. 도 1을 참조하면, 질소(N2)와 수소(3H2)를 이용하여 암모니아(2NH3)를 생성할 때, 촉매의 종류에 대응하여 활성 화 에너지가 결정된다. 촉매의 활성화 에너지는 촉매와 흡착물 사이의 흡착 에너지에 의해서 결정되기 때문에, 촉매와 흡착물 사이의 흡착 에너지를 계산함으로써 촉매의 활성도가 예측할 수 있다. 일반적으로 흡착 에너지 는 DFT(Density Functional Theory, 제일원리계산법 중 밀도 범함수 이론)를 이용하여 계산될 수 있다. 하지만, DFT를 이용하여 화학 반응의 반응 단계 및 경로마다 흡착 에너지를 연산하기에는 시간 및 비용이 과다 한 문제점이 존재한다. 따라서, 촉매와 흡착물 사이의 흡착 에너지를 빠르고 정확하게 예측할 수 있는 방법이 요구되고 있다."}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 촉매의 활성도를 예측하는 방법 및 전자 장치를 제공하고자 한다. 본 실시예가 이루고자 하는 기술 적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 이하의 실시예들로부터 또 다른 기술적 과제들 이 유추될 수 있다."}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된 방법은, 전자 장치가 제1 소재를 구성하는 적어 도 하나의 제1 원자에 관련된 제1 정보 및 흡착물을 구성하는 적어도 하나의 제2 원자에 관련된 제2 정보를 사 용자로부터 수신하는 단계, 상기 전자 장치가 상기 수신된 제1 정보 및 제2 정보를 흡착 에너지를 추정하는 학 습 모델에 적용하는 단계 및 상기 전자 장치가 상기 학습 모델로부터 출력된 흡착 에너지를 출력하는 단계;를 포함하고, 상기 학습 모델은 상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 제1 원자, 상기 제2 원자 및 이 들의 결합을 그래프로 모델링하고, 상기 모델링된 그래프를 벡터로 변환하고, 변환된 벡터를 이용하여 흡착 에너지를 추정하도록 학습된 것일 수 있다. 또한, 상기 학습 모델은, 상기 적어도 하나의 제1 원자 및 상기 적어도 하나의 제2 원자 중에서 적어도 하나를 노드로 모델링하고, 상기 적어도 하나의 제1 원자 사이의 결합, 상기 적어도 하나의 제2 원자 사이의 결합, 상 기 적어도 하나의 제1 원자와 상기 적어도 하나의 제2 원자 사이의 결합 중에서 적어도 하나를 엣지로 모델링함 으로써, 상기 그래프를 모델링하도록 학습된 것일 수 있다. 또한, 상기 학습 모델은, 상기 제1 정보에 기초하여, 상기 제1 소재의 구조를 제1 그래프로 모델링하고, 상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 제1 소재의 표면의 구조 및 상기 흡착물의 구조를 제2 그래프로 모델링하도록 학습된 것일 수 있다. 또한, 상기 학습 모델은, 상기 제1 소재의 최외곽층을 구성하는 제3 원자들과, 상기 최외곽층의 바로 아래층을 구성하는 제4 원자들에 기초하여 상기 제1 소재의 표면의 구조를 제2 그래프로 모델링하도록 학습된 것일 수 있 다. 또한, 상기 제1 정보는 상기 제1 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도 (electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀 도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나를 포함하고, 상기 제2 정보는 상기 제2 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도 (electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀 도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나를 포함하는 것일 수 있다. 또한, 상기 방법은, 상기 전자 장치가 상기 적어도 하나의 제1 원자 사이의 결합 거리, 상기 적어도 하나의 제2 원자 사이의 결합 거리, 상기 적어도 하나의 제1 원자와 상기 적어도 하나의 제2 원자 사이의 결합 거리 중에서 적어도 하나에 관련된, 제3 정보를 수신하는 단계; 및 상기 전자 장치가 상기 수신된 제3 정보를 상기 학습 모 델에 적용하는 단계를 더 포함하고, 상기 학습 모델은, 상기 제3 정보에 기초하여 상기 그래프를 모델링하도록 학습된 것일 수 있다. 또한, 상기 제1 정보 및 상기 제2 정보를 수신하는 단계는, 상기 전자 장치가 적어도 하나의 노드 엘리먼트 및 적어도 하나의 엣지 엘리먼트를 그래픽 인터페이스로 제공하는 단계, 상기 전자 장치가 상기 적어도 하나의 노 드 엘리먼트를 배열하는 제1 사용자 입력을 수신하는 단계, 상기 전자 장치가 상기 노드 엘리먼트를 연결하도록 적어도 하나의 엣지 엘리먼트를 배열하는 제2 사용자 입력을 수신하는 단계, 상기 전자 장치가 상기 노드 엘리 먼트에 상기 제1 정보 및 상기 제2 정보 중에서 적어도 하나를 입력하는 제3 사용자 입력을 수신하는 단계 및 상기 전자 장치가 상기 적어도 하나의 제1 원자 사이의 결합 거리, 상기 적어도 하나의 제2 원자 사이의 결합 거리, 상기 적어도 하나의 제1 원자와 상기 적어도 하나의 제2 원자 사이의 결합 거리 중에서 적어도 하나에 관 련된 정보를 상기 엣지 엘리먼트에 입력하는 제4 사용자 입력을 수신하는 단계를 포함하고, 상기 학습 모델은, 상기 제1 사용자 입력, 상기 제2 사용자 입력, 상기 제3 사용자 입력 및 상기 제4 사용자 입력 중에서 적어도 하나에 기초하여 상기 그래프를 모델링하도록 학습된 것일 수 있다. 한편, 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된 전자 장치는, 제1 소재를 구성하는 적어 도 하나의 제1 원자에 관련된 제1 정보 및 흡착물을 구성하는 적어도 하나의 제2 원자에 관한 제2 정보를 사용 자로부터 수신하는, 사용자 입력부, 상기 수신된 제1 정보 및 제2 정보를 흡착 에너지를 추정하는 학습 모델에 적용하는 프로세서 및 상기 학습 모델로부터 출력된 흡착 에너지를 출력하는 출력부를 포함하고, 상기 학습 모 델은, 상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 제1 원자, 상기 제2 원자 및 이들의 결합을 그래프로 모델링하고, 상기 모델링된 그래프를 벡터로 변환하고, 변환된 벡터를 이용하여 흡착 에너지를 추정하도록 학습 된 것 일 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 컴퓨터로 읽을 수 있는 기록매체는 개시된 방법의 실 시예들 중에서 적어도 하나를 컴퓨터에서 실행시키기 위한 프로그램을 기록한 것일 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 기록매체에 저장된 어플리케이션은 개시된 방법의 실 시예들 중에서 적어도 하나의 기능을 실행시키기 위한 것일 수 있다."}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 본 명세서에서 사용되는 “제1” 또는 “제2” 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 사용될 수 있다. 예를 들면, 본 명세서에서는 촉 매를 구성하는 적어도 하나의 원자들을 제1 원자로 기재하고, 흡착물을 구성하는 적어도 하나의 원자들을 제2 원자로 기재하였으나, 이는 촉매를 구성하는 원자와 흡착물을 구성하는 원자를 구분하기 위하여 사용한 것일 뿐 이므로, 이에 의해서 한정되어서는 안 된다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 2는 촉매의 활성도를 예측하는 방법의 예시를 설명하는 도면이다. 이하에서는, 촉매의 활성도에 관련된 정보들 중에서, 촉매와 흡착물 사이의 흡착 에너지(adsorption energy)를 예측하여 출력하는 방법이 예시로서 설명되지만, 이에 한정되는 것은 아니다. 이하에 기술될, 흡착 에너지를 예 측하여 출력하는 방법이 유추 적용됨으로써, 촉매의 형성 에너지(Formation energy), 밴드 갭(Band gap), 푸아 송 비율(Poisson ratio), 탄성 계수(Shear moduli), 체적 탄성 계수(Bulk moduli)과 같은 촉매의 활성도에 관 련된 정보가 예측될 수 있다. 도 2를 참조하면, 전자 장치는 사용자로부터 촉매에 관련된 정보 및 흡착물에 관련된 정보를 수신할 수 있 다. 전자 장치는 수신된 정보를 인공지능 신경망에 적용할 수 있다. 전자 장치는 학습 모델로부터 출 력된 촉매의 활성도에 관련된 정보를 출력할 수 있다. 일 실시예에 따르면, 전자 장치는 인공지능 신경망을 포함하는 모바일 장치(예를 들면, 스마트폰, 태블릿PC 등), 범용 컴퓨터(PC, Personal Computer), 서버(Server)와 같은 연산 장치를 포함할 수 있다. 또한, 전자 장 치는 인공지능 신경망을 포함하는 서버와 네트워크를 통해서 데이터를 송수신 할 수 있는 모바일 장치(예를 들면, 스마트폰, 태블릿PC 등), 범용 컴퓨터(PC, Personal Computer)와 같은 연산 장치를 포함할 수 있다. 인공지능 신경망은 학습 데이터로서 입력된 복수의 텍스트 데이터 및 이미지 데이터를 소정의 기준에 의해 학습 함으로써 생성된 것일 수 있다. 인공지능 신경망은 적어도 하나의 기능을 수행하도록 학습된 복수개의 학습 모 델(trained model)을 포함할 수 있다. 인공지능 신경망은 전자 장치로부터 수신된 데이터에 대응하여, 학 습된 기능을 수행함으로써 결과 데이터를 생성하고, 결과 데이터를 전자 장치로 출력할 수 있다. 예를 들 면, 인공지능 신경망은 전자 장치로부터 수신된 사용자로부터 촉매에 관련된 정보 및 흡착물에 관련된 정보 에 기초하여 촉매의 활성도에 관련된 데이터를 생성하고, 전자 장치로 출력할 수 있다. 일 실시예에 따르면, 인공지능 신경망은 프로세서의 형태로 존재할 수 있다. 프로세서는 범용적으로 이용되는 적어도 하나의 프로세서 (예를 들면, CPU, Application processor) 및 인공지능 신경망의 기능을 수행하기 위하 여 제작된 적어도 하나의 프로세서 중에서 적어도 하나를 포함할 수 있다.일 실시예에 따르면, 인공지능 신경망은 소프트웨어 모듈의 형태로 존재할 수 있다. 범용 프로세서 또는 인공 지능 신경망의 기능을 수행하기 위하여 제작된 프로세서는 명령어를 실행함으로써 소프트웨어 모듈 형태의 인공 지능 신경망을 이용할 수 있다. 일 실시예에 따르면, 인공지능 신경망은 서버에 포함될 수 있다. 전자 장치는 사용자로부터 수신한 입력 데이터를 서버로 전송할 수 있다. 서버는 전자 장치로부터 수신된 데이터를 인공지능 신경망에 적용하고, 인공지능 신경망으로부터 출력된 데이터를 전자 장치로 전송할 수 있다. 일 실시예에 따르면, 인공지능 신경망은 전자 장치에 포함될 수 있다. 전자 장치는 내부 메모리에 인 공지능 신경망을 구성하는 데이터를 저장하고 이용할 수 있다. 예를 들면, 전자 장치는 서버로부터 인공지 능 신경망을 구성하는 데이터를 수신함으로써, 인공지능 신경망을 내부 메모리에 저장하고 이용할 수 있다. 또 한, 전자 장치는 서버로부터 인공지능 신경망을 갱신하는 데이터를 수신할 수 있다. 개시된 실시예에 따르면, 전자 장치는 화학 반응의 각 반응 단계 및 경로마다 촉매의 활성도에 관련된 정보 를 빠르고 정확하게 획득할 수 있다. 도 3은 일 실시예에 따른, 전자 장치가 촉매의 활성도를 예측하는 방법의 순서도이다. 단계 310을 참조하면, 전자 장치는 사용자 입력부를 통해서, 촉매의 후보 물질인 제1 소재에 관련된 제1 정 보 및 흡착물에 관한 제2 정보를 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 활성도를 예측할 제1 소재를 구성하는 적어도 하나의 제1 원자에 관련된 제1 정보를 수신할 수 있다. 제1 원자는 복수의 다른 원자 일 수 있다. 예를 들면, 제1 원자는 니켈(Ni) 및 루 테늄(Ru)과 같이 다른 종류의 복수개의 원자일 수 있다. 전자 장치는 제1 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도 (electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀 도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge)중에서 적어도 하나에 대한 값을 제1 정보로서 사용자로부터 수신할 수 있다. 구체적으로, 전자 장치는 니켈(Ni)의 족 번호인 10, 전기 음성도인 1.91, 원자량인 6.59(cm3/mol), 전자 친 화력인 1.16(eV), 원자량인 58.69(g/mol)을 제1 정보로서 사용자로부터 수신할 수 있다. 또한, 전자 장치는 루테늄(Ru)의 족 번호인 8, 전기 음성도인 2.2, 원자량인 8.22(cm3/mol), 전자 친화력인 1.05(eV), 원자량인 101.07(g/mol)을 제1 정보로서 사용자로부터 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 흡착물을 구성하는 적어도 하나의 제2 원자에 관련된 제2 정보를 수신할 수 있다. 제2 원자는 복수의 다른 원자 일 수 있다. 예를 들면, 제2 원자는 질소(N) 및 수소(H)와 같이 다른 종류의 복수개의 원자일 수 있다. 전자 장치는 제2 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도 (electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀 도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나에 대한 값을 제2 정보로서 사용자로부터 수신할 수 있다. 구체적으로, 전자 장치는 질소(N)의 족 번호인 15, 전기 음성도인 3.04, 원자량인 17.3(cm3/mol), 전자 친 화력인 0(eV), 원자량인 14.01(g/mol)을 제2 정보로서 사용자로부터 수신할 수 있다. 또한, 전자 장치는 원자 사이의 결합(bond)에 관련된 제3 정보를 사용자로부터 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 적어도 하나의 제1 원자 사이의 결합 거리에 관련된 정보를 수신할 수 있 다. 예를 들면, 전자 장치는 니켈(Ni)과 루테늄(Ru)사이의 결합 거리인 2.9(Å)을 제3 정보로서 사용자로 부터 수신할 수 있다. 다른 일 실시예에 따르면, 전자 장치는 적어도 하나의 제2 원자 사이의 결합 거리에 관련된 정보를 수신할 수 있다. 예를 들면, 전자 장치는 질소(N)와 수소(H)사이의 결합 거리인 2(Å)을 제3 정보로서 사용자로부터 수신할 수 있다. 다른 예를 들면, 전자 장치는 질소(N)와 질소(N)사이의 결합 거리인 1.0975(Å)을 제 3 정보로서 사용자로부터 수신할 수 있다. 다른 일 실시예에 따르면, 전자 장치는 적어도 하나의 제1 원자와 적어도 하나의 제2 원자 사이의 결합 거 리 중에서 적어도 하나에 관련된 정보를 수신할 수 있다. 예를 들면, 전자 장치는 니켈(Ni)와 질소(N)사이 의 결합 거리인 2.04(Å)을 제3 정보로서 사용자로부터 수신할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 정보, 제2 정보 및 제3 정보 중에서 적어도 하나를 그래픽 인터페이 스를 통해서 사용자로부터 수신할 수 있다. 구체적인 내용은 도 4를 참조하여 아래에서 설명한다. 단계 350을 참조하면, 전자 장치의 프로세서는 사용자로부터 수신된 제1 정보, 제2 정보 및 제3 정보 중에 서 적어도 하나를 학습 모델에 적용할 수 있다. 전자 장치의 프로세서는 제1 정보, 제2 정보 및 제3 정보 중에서 적어도 하나에 대해서 전처리를 수행하고, 학습 모델에 적용할 수 있다. 예를 들면, 전자 장치의 프로세서는 제1 정보, 제2 정보 및 제3 정보 중에서 적어도 하나를 그래프로 모델링하는 전처리를 수행 할 수 있다. 구체적인 내용은 도 5를 참조하여 아래에서 설 명한다. 또는, 학습 모델이 제1 정보, 제2 정보 및 제3 정보 중에서 적어도 하나에 대해서 전처리를 수행할 수 있다. 학습 모델은 제1 정보 및 제2 정보에 기초하여 촉매의 활성도에 관련된 정보를 출력하도록 학습된 인공지능 신 경망일 수 있다. 예를 들면, 학습 모델은 제1 소재를 구성하는 적어도 하나의 제1 원자에 관련된 제1 정보, 흡 착물을 구성하는 적어도 하나의 제2 원자에 관련된 제2 정보 및 원자들 사이의 결합 거리에 관한 제3 정보를 컨 벌루션 연산함으로써 흡착 에너지를 예측하도록 학습된 인공지능 신경망일 수 있다. 학습 모델은 흡착 에너지 외에도, 촉매의 형성 에너지(Formation energy), 밴드 갭(Band gap), 푸아송 비율(Poisson ratio), 탄성 계수 (Shear moduli), 체적 탄성 계수(Bulk moduli)과 같은 촉매의 활성도에 관련된 정보를 예측하도록 학습된 인공 지능 신경망일 수 있다. 학습 모델은 예측한 촉매의 활성도에 관련된 정보를 전자 장치로 출력할 수 있다. 일 실시예에 따르면, 학습 모델은 전자 장치에 포함될 수 있다. 예를 들면, 학습 모델은 프로세서의 형태 로 전자 장치에 포함되거나, 소프트웨어 모듈의 형태로 전자 장치의 메모리 또는 데이터 스토리지에 저 장될 수 있다. 전자 장치의 프로세서는 제1 정보, 제2 정보 및 제3 정보 중에서 적어도 하나를 전자 장치 에 포함된 학습 모델로 적용할 수 있다. 학습 모델은 촉매의 활성도에 관련된 정보를 전자 장치의 프 로세서로 출력할 수 있다. 일 실시예에 따르면, 학습 모델은 전자 장치가 네트워크를 통해서 데이터를 송수신 하는 서버에 포함될 수 있다. 예를 들면, 학습 모델은 프로세서의 형태로 서버에 포함되거나, 소프트웨어 모듈의 형태로 서버의 메모 리 또는 데이터 스토리지에 저장될 수 있다. 전자 장치의 프로세서는 서버로 제1 정보, 제2 정보 및 제3 정보 중에서 적어도 하나를 송신하고, 서버로부터 출력되는 촉매의 활성도에 관련된 정보를 수신하도록 전 자 장치의 통신부를 제어할 수 있다. 단계 390을 참조하면, 전자 장치는 학습 모델로부터 출력된 촉매의 활성도에 관련된 정보를 출력할 수 있다. 예를 들면, 전자 장치는 디스플레이부를 이용하여 학습 모델로부터 출력된 흡착 에너지 값을 출력할 수 있다. 또한, 전자 장치는 촉매의 형성 에너지(Formation energy), 밴드 갭(Band gap), 푸아송 비율 (Poisson ratio), 탄성 계수(Shear moduli), 체적 탄성 계수(Bulk moduli)와 같은 촉매의 활성도에 관련된 정 보를 출력할 수 있다. 도 4는 일 실시예에 따른, 전자 장치가 그래프를 사용자가 모델링하도록 제공하는 그래픽 인터페이스를 도시한 것이다. 전자 장치는 소재(material)의 구조(structure), 흡착물의 구조 및 이들의 결합에 대응하는 그래프를 사용 자가 모델링하도록 그래픽 인터페이스를 제공할 수 있다. 그래픽 인터페이스는 노드 엘리먼트(411, 413, 431) 와 엣지 엘리먼트(451, 453, 455)를 포함할 수 있다. 그래픽 인터페이스는 노드 엘리먼트(411, 413, 431) 및 엣지 엘리먼트(451, 453, 455)가 배열될 수 있는 소정의 빈(blank) 영역을 포함할 수 있다. 그래픽 인터페이스 는 사용자가 노드 엘리먼트(411, 413, 431) 및 엣지 엘리먼트(451, 453, 455)를 선택하기 위한 팔레트 (palette)를 포함할 수 있다. 전자 장치는 사용자로부터 노드 엘리먼트(411, 413, 431)를 배열하는 제1 사용자 입력을 수신할 수 있다. 노드 엘리먼트(411, 413, 431)는 소재(예를 들면, NiRu)를 구성하는 제1 원자(예를 들면, 니켈(Ni)과 루테늄 (Ru)) 및 흡착물(예를 들면 N2)을 구성하는 제2 원자(예를 들면, 질소(N)) 중에서 적어도 하나에 대응될 수 있 다. 사용자는 팔레트로부터 적어도 하나의 노드 엘리먼트(411, 413, 431)를 선택하여 드래그 함으로써 빈 영역 에 배열할 수 있다. 예를 들면, 전자 장치는 제1 원자인 니켈(Ni)에 대응하는 노드 엘리먼트를 배열하는 제1 사용자 입력 을 수신할 수 있다. 또한, 전자 장치는 제1 원자인 루테늄(Ru)에 대응하는 노드 엘리먼트를 배열하는 제1 사용자 입력을 수신할 수 있다. 또한, 전자 장치는 제2 원자인 질소(N)에 대응하는 노드 엘리먼트(43 1)를 배열하는 제1 사용자 입력을 수신할 수 있다. 전자 장치는 노드 엘리먼트를 연결하도록 적어도 하나의 엣지 엘리먼트를 배열하는 제2 사용자 입력을 수신 할 수 있다. 엣지 엘리먼트는 원자들 사이의 결합에 대응될 수 있다. 사용자는 팔레트로부터 적어도 하나의 엣 지 엘리먼트(451, 453, 455)를 선택하여 드래그 함으로써 빈 영역에 배열할 수 있다. 예를 들면, 전자 장치는 제1 원자인 니켈(Ni)와 루테늄(Ru)를 연결하는 엣지 엘리먼트를 배열하는 제2 사용자 입력을 수신할 수 있다. 또한, 전자 장치는 제1 원자인 니켈(Ni)과 제2 원자인 질소(N)를 연결하는 엣지 엘리먼트를 배열하는 제2 사용자 입력을 수신할 수 있다. 또한, 전자 장치는 제2 원자인 질소 (N)와 질소(N)를 연결하는 엣지 엘리먼트를 배열하는 제2 사용자 입력을 수신할 수 있다. 전자 장치는 배열된 적어도 하나의 노트 엘리먼트에 관련된 정보를 입력하는 제3 사용자 입력을 수신할 수 있다. 제3 사용자 입력은 제1 원자에 관련된 제1 정보 및 제2 원자에 관련된 제2 정보 중에서 적어도 하나를 입력하는 것을 포함할 수 있다. 예를 들면, 전자 장치는 니켈(Ni)의 족 번호인 10, 전기 음성도인 1.91, 원자량인 6.59(cm3/mol), 전자 친 화력인 1.16(eV), 원자량인 58.69(g/mol)을 입력하는 제3 사용자 입력을 수신할 수 있다. 또한, 전자 장치(1 0)는 루테늄(Ru)의 족 번호인 8, 전기 음성도인 2.2, 원자량인 8.22(cm3/mol), 전자 친화력인 1.05(eV), 원자량 인 101.07(g/mol)을 입력하는 제3 사용자 입력을 수신할 수 있다. 또한, 전자 장치는 질소(N)의 족 번호인 15, 전기 음성도인 3.04, 원자량인 17.3(cm3/mol), 전자 친화력인 0(eV), 원자량인 14.01(g/mol)을 입력하는 제 3 사용자 입력을 수신할 수 있다. 전자 장치는 배열된 적어도 하나의 엣지 엘리먼트에 관련된 정보를 입력하는 제4 사용자 입력을 수신할 수 있다. 제4 사용자 입력은 적어도 하나의 제1 원자 사이의 결합 거리, 적어도 하나의 제2 원자 사이의 결합 거 리, 적어도 하나의 제1 원자와 적어도 하나의 제2 원자 사이의 결합 거리 중에서 적어도 하나에 관련된 제3 정 보를 입력하는 것을 포함할 수 있다. 예를 들면, 전자 장치는 니켈(Ni)과 루테늄(Ru)사이의 결합 거리인 2.9(Å)을 입력하는 제4 사용자 입력을 수신할 수 있다. 또한, 전자 장치는 질소(N)와 질소(N)사이의 결합 거리인 1.09(Å)을 입력하는 제4 사용 자 입력을 수신할 수 있다. 또한, 전자 장치는 니켈(Ni)와 질소(N)사이의 결합 거리인 2.04(Å)을 입력하 는 제4 사용자 입력을 수신할 수 있다. 도 5는 일 실시예에 따른, 전자 장치가 소재 및 흡착물의 구조(structure)에 관련된 정보를 그래프로 모델링하 는 것을 도시한 것이다. 소재는 적어도 하나의 제1 원자로 구성될 수 있다. 예를 들면, 소재는 단원자 금속(구체적으로, 백 금(Pt), 티타늄(Ti) 등)일 수 있다. 또는 소재는 2개 이상의 원자가 화합된 금속 화합물(구체적으로, NiRu, HfRe, YAg, TiRh, NbAu, TiRu, TiIr 등)일 수 있다. 또한, 2원자 금속 화합물(Binary intermetallics) 은 2가지 종류의 원자가 서로 균일하게 배열된 OI(Ordered intermetallics) 구조로 구성되거나, CS(Core- shell) 구조로 구성될 수 있다. 이하에서는 설명의 편의를 위해서, OI구조로 구성된 2원자 금속 화합물을 예시로서 설명한다. 단원자 금속, CS 구조의 2원자 금속 화합물 및 3개 이상의 원자로 구성된 금속 화합물에도 유사하게 적용될 수 있다. 도 5를 참조하면, 전자 장치의 프로세서는 사용자로부터 수신된 정보에 기초하여, 제1 소재를 구성하는 적 어도 하나의 원자에 관련된 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 정보 및 원자들의 결합 (bond)에 관련된 정보를 그래프로 모델링할 수 있다. 서버의 프로세서 및 인공지능 신경망도 유사하게 모 델링을 수행할 수 있다. 이하에서는, 전자 장치의 프로세서가 모델링을 수행하는 것으로 설명한다. 일 실시예에 따르면, 프로세서는 제1 소재를 구성하는 적어도 하나의 원자를 노드(node)로 모델링할 수 있다. 또한, 프로세서는 흡착물을 구성하는 적어도 하나의 원자 중에서 적어도 하나를 노드(node)로 모델링할 수 있다. 예를 들면, 제1 소재는 2가지 종류의 원자들(511, 513)이 OI 구조로 구성될 수 있다. 프로세서는 제1 원자 를 그래프의 제1 노드로 모델링하고, 제2 원자를 그래프의 제2 노드로 모델링 할 수 있다. 일 실시예에 따르면, 프로세서는 제1 소재를 구성하는 원자들 사이의 결합, 흡착물을 구성하는 원자들 사이의 결합 및 제1 소재를 구성하는 원자와 흡착물을 구성하는 원자 사이의 결합 중에서 적어도 하나를 엣지(edge)로 모델링 할 수 있다. 엣지는 노드들의 사이를 연결하는 선을 의미한다. 예를 들면, 프로세서는 제1 원자와 제2 원자 사이의 결합을 제1 노드과 제2 노드를 연결하는 제1 엣지로 모델링 할 수 있다. 즉, 프로세서는 제1 원자를 제1 노드로 모델링하고, 제1 원자의 주변에 위치된 제2 원자를 제2 노드으로 모델링하고, 제1 원자과 제2 원자 사이의 결합을 제1 노드과 제2 노드 을 연결하는 제1 엣지로 모델링함으로써, 제1 소재에 대응하는 그래프를 모델링 할 수 있다. 프로세서는 노드 및 엣지가 소정의 데이터를 포함하도록 그래프를 모델링 할 수 있다. 예를 들면, 프로세서는 제1 노드가 제1 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge)에 관련된 데이터 중에서 적어도 하나의 데이터를 포함하도록 그래프를 모델링 할 수 있다. 제1 노드에 포함된 데이터 는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 또한, 프로세서는 제2 노드가 제2 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge)에 관련된 데이터 중에서 적어도 하나의 데이터를 포함하도록 그래프를 모델링 할 수 있다. 제2 노드에 포함된 데이터 는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 또한, 프로세서는 제1 엣지가 제1 원자와 제2 원자가 결합되었는지 여부를 나타내는 데이터 및 제1 원자와 제2 원자 사이의 결합 거리에 관한 데이터를 포함할 수 있다. 제1 엣지에 포함된 데 이터는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예를 들면, 수학식 1이 만족되는 경우, 프로세서는 제1 원자와 제2 원자가 결합되었다고 식별될 수 있다. 수학식 1"}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, ri는 제1 원자의 반지름이고, rj는 제2 원자의 반지름이고, d(i,j)는 제1 원자와 제2 원자 사이의 거리이 고, Δ는 허용 오차를 의미한다. 사용자는 제1 원자 및 제2 원자의 반지름과 제1 원자와 제2 원자 사이의 거리 에 기초하여 허용 오차 값을 설정할 수 있다. 예를 들면, 사용자는 허용 오차 값을 1.5Å로 설정할 수 있다. 또한, 제1 엣지에 포함된 데이터는 수학식 2와 같이 나타낼 수 있다. 수학식 2"}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, u(i,j)k는 제1 원자와 제2 원자 사이에 연결된 k번째 엣지를 의미한다. 또한, d(i,j)k는 k번째 엣지로 연 결된 제1 원자와 제2 원자 사이의 거리를 의미한다. μn은 n번째 항에 종속된 정규화용 변수이고, σ는 표준편 차를 의미한다. 일 실시예에 따르면, 프로세서는 제1 소재의 구조를 제1 그래프로 모델링하고, 제1 소재의 표면의 구조 및 흡착 물의 구조를 제2 그래프로 모델링 할 수 있다. 전자 장치의 프로세서가 제1 그래프를 모델링 하는 방법은 도 5를 참조하여 구체적으로 설명한다. 전자 장치의 프로세서가 제2 그래프를 모델링 하는 방법은 도 6을 참조하여 구체적으로 설명한다. 도 6은 일 실시예에 따른, 전자 장치가 소재 및 흡착물의 구조에 관련된 정보를 그래프로 모델링하는 것을 도시 한 것이다. 도 5에서 설명한 것과 같이, 설명의 편의를 위해서 OI구조로 구성된 2원자 금속 화합물을 예시로서 설명한다. 단원자 금속, CS구조의 2원자 금속 화합물 및 3개 이상의 원자로 구성된 금속 화합물에도 유사하게 적용될 수 있다. 또한, 전자 장치의 프로세서가 모델링을 수행하는 것으로 설명한다. 서버의 프로세서 및 인공지능 신 경망도 유사하게 모델링을 수행할 수 있다. 도 6를 참조하면, 프로세서는 제1 소재의 덩어리 구조(bulk structure)를 제1 그래프로 모델링할 수 있다. 프로세서는 제1 소재의 소정의 영역을 제1 그래프로 모델링 할 수 있다. 제1 소재의 최외곽층 및 최외곽층으로부터 소정의 범위 내의 층은 흡착물에 의해서 제1 소재를 구성하는 원자들 사 이의 결합 거리에 영향이 존재할 수 있다. 따라서, 소정의 영역은 제1 소재의의 최외곽층으로 부터 소정의 범위 외의 층(layer)에 해당될 수 있다. 예를 들면, 소정의 영역은 제1 소재의 최외곽 층의 아래에 위치한 3개의 층 외의 층에 해당될 수 있다. 즉, 프로세서는 흡착물에 의해서 제1 소재를 구 성하는 원자들 사이의 결합 거리에 영향이 존재하는 소정의 범위를 제외한 영역을 소정의 영역으로 식별할 수 있다. 프로세서는 소정의 영역내에 포함된 제1 원자을 제1 노드(631a)로 모델링 할 수 있다. 예를 들면, 프로세서는 니켈(Ni)을 제1 노드(631a)로 모델링 할 수 있다. 프로세서는 제2 원자를 제2 노드(633a)로 모델링 할 수 있다. 예를 들면, 프로세서는 루테늄(Ru)을 제2 노 드(633a)로 모델링 할 수 있다. 프로세서는 제1 원자와 제2 원자 사이의 결합을 엣지(639a)로 모델링 할 수 있다. 예를 들면, 프로 세서는 니켈(Ni)과 루테늄(Ru)사이의 결합을 엣지(639a)로 모델링 할 수 있다. 또한, 프로세서는 노드 및 엣지가 소정의 데이터를 포함하도록 그래프를 모델링 할 수 있다. 일 실시예에 따르면, 프로세서는 제1 노드(631a)에 포함된 데이터(631b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예를 들면, 프로세서는 니켈(Ni)의 족 번호인 10, 전기 음성도인 1.91, 원자량인 6.59(cm3/mol), 전자 친화력인 1.16(eV), 원자량인 58.69(g/mol)을 벡터 형식으로 변환하여 제1 노드의 데이터 (631b)로 모델링 할 수 있다. 구체적인 내용은 도 8을 참조하여 아래에서 설명한다. 또한, 프로세서는 제2 노드(633a)에 포함된 데이터(633b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예를 들면, 프로세서는 루테늄(Ru)의 족 번호인 8, 전기 음성도인 2.2, 원자량인 8.22(cm3/mol), 전자 친 화력인 1.05(eV), 원자량인 101.07(g/mol)을 벡터 형식으로 변환하여 제2 노드의 데이터(633b)로 모델링 할 수 있다. 구체적인 내용은 도 9을 참조하여 아래에서 설명한다.또한, 프로세서는 엣지(639a)에 포함된 데이터(639b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예 를 들면, 프로세서는 니켈(Ni)과 루테늄(Ru)사이의 결합 거리인 2.9(Å)을 벡터 형식으로 변환하여 엣지의 데이 터(639b)로 모델링 할 수 있다. 구체적인 내용은 도 11을 참조하여 아래에서 설명한다. 도 7은 일 실시예에 따른, 전자 장치가 소재 및 흡착물의 구조에 관련된 정보를 그래프로 모델링하는 것을 도시 한 것이다. 설명의 편의를 위해서 OI구조로 구성된 2원자 금속 화합물을 예시로서 설명한다. 단원자 금속, CS구조의 2원자 금속 화합물 및 3개 이상의 원자로 구성된 금속 화합물에도 유사하게 적용될 수 있다. 또한, 전자 장치의 프로세서가 모델링을 수행하는 것으로 설명한다. 서버의 프로세서 및 인공지능 신 경망도 유사하게 모델링을 수행할 수 있다. 도 7를 참조하면, 프로세서는 제1 소재의 표면의 구조(surface structure) 및 흡착물의 구조를 제2 그래프로 모델링할 수 있다. 프로세서는 제1 소재의 소정의 영역 및 흡착물을 제2 그래프로 모델링 할 수 있다. 제1 소재 의 최외곽층 및 최외곽층으로부터 소정의 범위 내의 층(layer)은 흡착물에 의해서 제1 소재를 구성하는 원자들 사이의 결합 거리에 영향이 존재할 수 있다. 따라서, 제1 소재의 표면의 구조에 관련된 소정의 영역은 제1 소재의의 최외곽층으로부터 소정의 범위 내의 층(layer)에 해당될 수 있다. 예를 들면, 소정의 영역은 제1 소재의 최외곽층 및 최외곽층의 바로 아래에 위치한 층에 해당될 수 있다. 즉, 프로세서는 흡착물에 의해서 제1 소재를 구성하는 원자들 사이의 결합 거리에 영향이 존재하는 소정의 범위를 소정의 영역으로 식별할 수 있다. 프로세서는 소정의 영역내에 포함된 제1 원자을 제1 노드(731a)로 모델링 할 수 있다. 예를 들면, 프 로세서는 니켈(Ni)을 제1 노드(731a)로 모델링 할 수 있다. 프로세서는 제2 원자을 제2 노드(733a)로 모델링 할 수 있다. 예를 들면, 프로세서는 루테늄(Ru)을 제2 노 드(733a)로 모델링 할 수 있다. 프로세서는 제1 원자에 결합된 흡착물의 제3 원자를 제3 노드(735a)로 모델링 할 수 있다. 예를 들면, 프로세서는 니켈(Ni)에 결합된 질소(N)를 제3 노드(735a)로 모델링 할 수 있다. 프로세서는 제3 원자에 결합된 제4 원자를 제4 노드(737a)로 모델링 할 수 있다. 예를 들면, 프로세 서는 질소(N)에 결합된 질소(N)를 제4 노드(737a)로 모델링 할 수 있다. 프로세서는 제1 원자와 제2 원자 사이의 결합을 엣지(739a)로 모델링 할 수 있다. 예를 들면, 프로세 서는 니켈(Ni)과 루테늄(Ru)사이의 결합을 엣지(739a)로 모델링 할 수 있다. 프로세서는 제1 원자와 제3 원자 사이의 결합을 엣지로 모델링 할 수 있다. 예를 들면, 프로세서는 니켈(Ni)와 질소(N)사이의 결합을 엣지로 모델링 할 수 있다. 프로세서는 제3 원자와 제4 원자 사이의 결합을 엣지로 모델링 할 수 있다. 예를 들면, 프로세서는 질소(N)와 질소(N)사이의 결합을 엣지로 모델링 할 수 있다. 또한, 프로세서는 노드 및 엣지가 소정의 데이터를 포함하도록 그래프를 모델링 할 수 있다. 예를 들면, 프로세서는 제1 노드(731a)에 포함된 데이터(731b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예를 들면, 프로세서는 니켈(Ni)의 족 번호인 10, 전기 음성도인 1.91, 원자량인 6.59(cm3/mol), 전자 친 화력인 1.16(eV), 원자량인 58.69(g/mol)을 벡터 형식으로 변환하여 제1 노드의 데이터(731b)로 모델링 할 수 있다. 구체적인 내용은 도 8을 참조하여 아래에서 설명한다. 또한, 프로세서는 제2 노드(733a)에 포함된 데이터(733b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예를 들면, 프로세서는 루테늄(Ru)의 족 번호인 8, 전기 음성도인 2.2, 원자량인 8.22(cm3/mol), 전자 친 화력인 1.05(eV), 원자량인 101.07(g/mol)을 벡터 형식으로 변환하여 제2 노드의 데이터(733b)로 모델링 할 수 있다. 구체적인 내용은 도 9을 참조하여 아래에서 설명한다. 또한, 프로세서는 제3 노드(735a)에 포함된 데이터(735b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예를 들면, 프로세서는 질소(N)의 족 번호인 15, 전기 음성도인 3.04, 원자량인 17.3(cm3/mol), 전자 친화력인 0(eV), 원자량인 14.01(g/mol)을 벡터 형식으로 변환하여 제3 노드의 데이터(735b)로 모델링 할 수 있다. 구체적인 내용은 도 10을 참조하여 아래에서 설명한다. 또한, 프로세서는 제4 노드(737a)에 포함된 데이터(737b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예를 들면, 프로세서는 질소(N)의 족 번호인 15, 전기 음성도인 3.04, 원자량인 17.3(cm3/mol), 전자 친 화력인 0(eV), 원자량인 14.01(g/mol)을 벡터 형식으로 변환하여 제4 노드의 데이터(737b)로 모델링 할 수 있다. 구체적인 내용은 도 10을 참조하여 아래에서 설명한다. 또한, 프로세서는 엣지(739a)에 포함된 데이터(739b)는 벡터 형식(vector-type)의 데이터를 포함할 수 있다. 예 를 들면, 프로세서는 니켈(Ni)과 루테늄(Ru)사이의 결합 거리인 2.9(Å)을 벡터 형식으로 변환하여 엣지의 데이 터(739b)로 모델링 할 수 있다. 구체적인 내용은 도 11을 참조하여 아래에서 설명한다. 도 8 내지 도 10은 일 실시예에 따른, 전자 장치가 원자에 관련된 정보를 벡터 형식으로 변환하는 것을 나 타낸 것이다. 구체적으로, 도 8은 전자 장치가 니켈(Ni)에 관련된 정보를 벡터 형식으로 변환하는 것을 나타낸 것이고, 도 9는 전자 장치가 루테늄(Ru)에 관련된 정보를 벡터 형식으로 변환하는 것을 나타낸 것이고, 도 8은 전자 장치가 질소(N)에 관련된 정보를 벡터 형식으로 변환하는 것을 나타낸 것이다. 이하에서는, 전자 장치의 프로세서가 원자에 관련된 정보를 벡터 형식으로 변환하는 것으로 설명한다. 서 버의 프로세서 및 인공지능 신경망도 유사하게 원자에 관련된 정보를 벡터 형식으로 변환을 수행할 수 있다. 프로세서는 원자에 관련된 정보들의 각각을 소정 개수의 인덱스를 포함하는 이진 벡터(binary vector)로 변환할 수 있다. 프로세서는 원자에 관련된 정보들의 각각의 특징에 기초하여, 인덱스의 개수를 설정할 수 있다. 또는 사용자의 입력에 기초하여 인덱스의 개수를 설정할 수 있다. 예를 들면, 프로세서는 주기율표 상의 족의 종류 에 기초하여, 원자의 족 번호를 나타내는 인덱스를 18개로 설정할 수 있다. 일 실시예에 따르면, 프로세서는 원자에 관련된 정보에 포함된 값에 대해서 하한값과 상한값을 설정할 수 있다. 프로세서는 원자에 관련된 정보들의 각각의 특징에 기초하여 하한값 및 상한값을 설정할 수 있다. 예를 들면, 프로세서는 원자의 족 번호의 하한값을 1로 설정하고, 상한값을 18로 설정할 수 있다. 또한, 프로세서는 원자 의 전기 음성도의 하한값을 1.2로 설정하고, 상한 값을 3.2로 설정할 수 있다. 또한, 프로세서는 원자의 원자 량의 하한값을 6.5(cm3/mol)로 설정하고, 상한값을 18(cm3/mol)로 설정할 수 있다. 또한, 프로세서는 원자의 전자 친화력의 하한값을 -0.8(eV)로 설정하고, 상한값을 2.4(eV)로 설정할 수 있다. 또한, 프로세서는 원자의 원자량의 하한값을 1(g/mol)로 설정하고, 상한값을 240(g/mol)로 설정할 수 있다. 일 실시예에 따르면, 프로세서는 설정된 하한값 및 상한값에 기초하여 인덱스에 대응되는 값을 설정할 수 있다. 프로세서는 하한값 및 상한값 사이의 범위내에서 인덱스를 구분할 소정의 간격을 설정할 수 있다. 프로세서는 선형 함수, 지수형 함수, log형 함수를 이용하여 소정의 간격을 설정할 수 있다. 예를 들면, 프로세서는 각 인 덱스가 원자의 전기 음성도를 1.2 내지 3.2의 범위 내에서 0.2 간격 내의 값을 나타내도록 설정할 수 있다. 도 8을 참조하면, 프로세서는 니켈(Ni)에 관련된 정보를 이진 벡터로 변환하고, 노드에 저장할 수 있다. 예를 들면, 프로세서는 니켈(Ni)의 족 번호 값인 10을 18개의 인덱스 중에서 10번째의 인덱스에만 1의 값이 저 장된 제1 이진 벡터로 변환할 수 있다. 프로세서는 니켈(Ni)의 전기 음성도 값인 1.91을 10개의 인덱스 중에서 4번째의 인덱스에만 1의 값이 저장된 제2 이진 벡터로 변환할 수 있다. 프로세서는 니켈(Ni)의 원 자량 값인 6.59(cm3/mol)를 10개의 인덱스 중에서 1번째의 인덱스에만 1의 값이 저장된 제3 이진 벡터로 변환할 수 있다. 프로세서는 니켈(Ni)의 전자 친화력 값인 1.16(eV)를 10개의 인덱스 중에서 7번째의 인덱스에 만 1의 값이 저장된 제4 이진 벡터로 변환할 수 있다. 프로세서는 니켈(Ni)의 원자량 값인 58.69(g/mol) 를 10개의 인덱스 중에서 3번째의 인덱스에만 1의 값이 저장된 제5 이진 벡터로 변환할 수 있다. 도 9를 참조하면, 프로세서는 루테늄(Ru)에 관련된 정보를 이진 벡터로 변환하고, 노드에 저장 할 수 있다. 예를 들면, 프로세서는 루테늄(Ru)의 족 번호 값인 8을 18개의 인덱스 중에서 8번째의 인덱스에만 1의 값이 저 장된 제1 이진 벡터로 변환할 수 있다. 프로세서는 루테늄(Ru)의 전기 음성도 값인 2.2을 10개의 인덱스중에서 6번째의 인덱스에만 1의 값이 저장된 제2 이진 벡터로 변환할 수 있다. 프로세서는 루테늄(Ru)의 원자량 값인 8.22(cm3/mol)를 10개의 인덱스 중에서 2번째의 인덱스에만 1의 값이 저장된 제3 이진 벡터로 변환할 수 있다. 프로세서는 루테늄(Ru)의 전자 친화력 값인 1.05(eV)를 10개의 인덱스 중에서 6번째의 인덱스 에만 1의 값이 저장된 제4 이진 벡터로 변환할 수 있다. 프로세서는 루테늄(Ru)의 원자량 값인 101.07(g/mol)를 10개의 인덱스 중에서 5번째의 인덱스에만 1의 값이 저장된 제5 이진 벡터로 변환할 수 있다. 도 10을 참조하면, 프로세서는 질소(N)에 관련된 정보를 이진 벡터로 변환하고, 노드에 저장 할 수 있다. 예를 들면, 프로세서는 질소(N)의 족 번호 값인 15을 18개의 인덱스 중에서 15번째의 인덱스에만 1의 값이 저장 된 제1 이진 벡터로 변환할 수 있다. 프로세서는 질소(N)의 전기 음성도 값인 3.04를 10개의 인덱스 중 에서 10번째의 인덱스에만 1의 값이 저장된 제2 이진 벡터로 변환할 수 있다. 프로세서는 질소(N)의 원 자량 값인 17.3(cm3/mol)를 10개의 인덱스 중에서 10번째의 인덱스에만 1의 값이 저장된 제3 이진 벡터로 변환할 수 있다. 프로세서는 질소(N)의 전자 친화력 값인 0(eV)를 10개의 인덱스 중에서 3번째의 인덱스에만 1 의 값이 저장된 제4 이진 벡터로 변환할 수 있다. 프로세서는 질소(N)의 원자량 값인 14.03(g/mol) 를 10개의 인덱스 중에서 1번째의 인덱스에만 1의 값이 저장된 제5 이진 벡터로 변환할 수 있다. 프로세서는 변환된 이진 벡터를 접합(concatenation)하여 노드에 저장할 수 있다. 각 노드에 저장된 이진 벡터 들은 접합 순서가 동일하다. 예를 들면, 이진 벡터들은 원자의 족 번호 값이 변환된 제1 이진 벡터, 원자의 전 기 음성도 값이 변환된 제2 이진 벡터, 원자의 원자량 값이 변환된 제3 이진 벡터, 원자의 전자 친화력 값이 변 환된 제4 이진 벡터, 원자의 원자량 값이 변환된 제5 이진 벡터 순으로 접합된 것 일 수 있다. 도 11은 일 실시예에 따른, 전자 장치가 원자들 사이의 결합 거리에 관련된 정보를 벡터 형식으로 변환하는 것을 나타낸 것이다. 이하에서는, 전자 장치의 프로세서가 원자들 사이의 결합 거리에 관련된 정보를 벡터 형식으로 변환하는 것으로 설명한다. 서버의 프로세서 및 인공지능 신경망도 유사하게 원자들 사이의 결합 거리에 관련된 정보 를 벡터 형식으로 변환을 수행할 수 있다. 프로세서는 제1 원자와 제2 원자 사이의 결합 거리에 관련된 정보를 소정 개수의 인덱스를 포함하 는 이진 벡터로 변환하고, 엣지에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 제1 원자와 제2 원자 사이의 결합 거리에 대해서 하한값과 상한값 을 설정할 수 있다. 예를 들면, 프로세서는 결합 거리의 하한값을 2.2(Å)로 설정하고, 상한값을 4.2(Å) 로 설정할 수 있다. 일 실시예에 따르면, 프로세서는 설정된 하한값 및 상한값에 기초하여 인덱스에 대응되는 값을 설정할 수 있다. 프로세서는 하한값 및 상한값 사이의 범위내에서 인덱스를 구분할 소정의 간격을 설정할 수 있다. 프로세서는 선형 함수, 지수형 함수, log형 함수를 이용하여 소정의 간격을 설정할 수 있다. 예를 들면, 프로세서는 각 인 덱스가 2.2(Å) 내지 4.2(Å)의 범위 내에서 0.2(Å) 간격 내의 값을 나타내도록 설정할 수 있다. 도 11을 참조하면, 프로세서는 제1 원자인 니켈(Ni)과 제2 원자인 루테늄(Ru)사이의 결합 거리인 2.9(Å)를 10개의 인덱스 중에서 4번째의 인덱스에만 1의 값이 저장된 이진 벡터으로 변환할 수 있다. 모델링된 그래프의 엣지에 저장된 이진 벡터의 하한값, 상한값, 인덱스 수 및 각 인덱스가 나타내는 값은 모두 동일할 수 있다. 도 12는 일 실시예에 따른, 촉매의 활성도에 관련된 정보를 출력하는 학습 모델을 도시화 한 것이다. 도 12을 참조하면, 학습 모델은 제1 소재를 구성하는 적어도 하나의 원자에 관련된 제1 정보, 흡착물을 구성하 는 적어도 하나의 원자에 관련된 제2 정보 및 원자들의 결합(bond)에 관한 제3 정보에 기초하여, 촉매의 활성도 에 관련된 정보를 출력하도록 학습된 인공지능 신경망일 수 있다. 예를 들면, 학습 모델은 제1 정보, 제2 정보 및 제3 정보에 대해서 컨벌루션 연산을 수행함으로써 흡착 에너지 를 예측하고, 출력하도록 학습된 인공지능 신경망일 수 있다. 학습 모델은 흡착 에너지 외에도, 촉매의 형성 에너지(Formation energy), 밴드 갭(Band gap), 푸아송 비율 (Poisson ratio), 탄성 계수(Shear moduli), 체적 탄성 계수(Bulk moduli)과 같은 촉매의 활성도에 관련된 정 보를 예측하고 출력하도록 학습된 인공지능 신경망일 수 있다. 학습 모델에서 출력되는 정보는 학습 데이터에 의해서 결정될 수 있다. 일 실시예에 따르면, 학습 모델은 학습 데이터를 학습함으로써 획득한 특징 벡터와 촉매의 활성도에 관련 된 정보의 상관 관계에 기초하여, 전자 장치의 프로세서로부터 입력된 제1 정보, 제2 정보 및 제3 정보 중 에서 적어도 하나로부터 촉매의 활성도에 관련된 정보를 획득하도록 학습된 인공지능 신경망일 수 있다. 일 실시예에 따르면, 학습 모델은 획득된 촉매의 활성도에 관련된 정보 및 전자 장치의 프로세서로부 터 입력된 제1 정보, 제2 정보 및 제3 정보 중에서 적어도 하나를 학습 데이터로서 이용하도록 학습된 인공지능 신경망일 수 있다. 일 실시예에 따르면, 학습 모델은 전자 장치의 프로세서로부터 전처리가 수행된, 제1 소재를 구성하 는 적어도 하나의 원자에 관련된 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 정보 및 원자들의 결합 (bond)에 관련된 정보를 수신할 수 있다. 예를 들면, 학습 모델은 도 5 내지 도 11을 참조하여 위에서 설명한 것과 같이, 모델링 된 그래프를 입력 받을 수 있다. 다른 예를 들면, 학습 모델은 도 4를 참조하여 위에서 설명한 것과 같이, 그래픽 유저 인 터페이스를 통해서 수신된 모델링 된 그래프를 입력 받을 수 있다. 일 실시예에 따르면, 학습 모델은 전자 장치의 프로세서로부터 수신된, 제1 정보, 제2 정보 및 제3 정보에 대해서 전처리를 수행할 수 있다. 예를 들면, 학습 모델은 도 5 내지 도 11을 참조하여 위에서 설명한 것과 같이, 제1 소재를 구성하는 적 어도 하나의 원자에 관련된 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 정보 및 원자들의 결합 (bond)에 관련된 정보를 그래프로 모델링 할 수 있다. 일 실시예에 따르면, 학습 모델은 모델링 된 그래프로부터 입력 레이어(input layer)를 생성할 수 있다. 학습 모델은 그래프의 노드에 포함된 벡터 형식의 데이터와 엣지에 포함된 벡터 형식의 데이터를 이용하 여 입력 레이어를 생성할 수 있다. 예를 들면, 학습 모델은 제1 소재의 덩어리 구조(bulk structure)를 나타내는 제1 그래프의 노드들 에 포함된 벡터 데이터와 제1 그래프의 엣지에 포함된 벡터 데이터로부터 제1 입력 레이어을 생성 할 수 있다. 또한, 학습 모델은 제1 소재의 표면의 구조(surface structure) 및 흡착물의 구조를 나타내 는 제2 그래프의 노드들에 포함된 벡터 데이터와, 제2 그래프의 엣지에 포함된 벡터 데이터로부터 제2 입력 레이어를 생성할 수 있다. 구체적으로, 학습 모델은 수학식 3과 같이 벡터 데이터를 접합(concatenation)함으로써 입력 레이어를 생 성할 수 있다. 수학식 3"}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 vi는 제1 원자의 벡터 데이터를 의미하고, vj는 제2 원자의 벡터 데이터를 의미하고, u(i,j)k는 제1 원자와 제2 원자 사이에 연결된 k번째 엣지를 의미하고, t는 컨벌루션 레이어의 수를 의미하고, f는 컨벌루션 필터의 수를 의미하고, 는 접합을 의미한다. 일 실시예에 따르면, 학습 모델은 CNN(Convolution Neural Network)기술을 이용하여, 입력 레이어에 대 해서 컨벌루션(convolution) 연산을 수행하고, 풀링(pooling) 연산을 수행함으로써, 특징 벡터를 생성할 수 있 다. 컨벌루션 연산과 풀링 연산은 복수회 뱐복적으로 수행될 수 있다. 또한, 특징 벡터의 차원을 줄이기 위한 flatten함수 연산이 수행될 수 있다. 학습 모델은 제1 입력 레이어와 제2 입력 레이어에 대해서 독립적으로 컨벌루션 연산과 풀링 연산을 수행할 수 있다. 학습 모델은 제1 입력 레이어에 대해서 컨벌루션 연산을 수행하고, 풀링 연산을 수행함으로써 제1 특징 벡터를 생성할 수 있다. 학습 모델은 제2 입력 레이어에 대 해서 컨벌루션 연산을 수행하고, 풀링 연산을 수행함으로써 제2 특징 벡터를 생성할 수 있다. 예를 들면, 학습 모델은 수학식 4와 같이 컨벌루션 연산을 수행할 수 있다. 수학식 4"}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, vi는 제1 원자의 벡터 데이터를 의미하고, vj는 제2 원자의 벡터 데이터를 의미하고, t는 컨벌루션 레이 어의 수를 의미하고, f는 컨벌루션 필터의 수를 의미하고, 는 엘리먼트 와이즈(element-wise) 곱셈을 의미 하고, σ는 시그모이드 함수(sigmoid function)을 의미하고, g는 exponential linear units(ELUs)를 의미한다. 또한, 학습 모델은 수학식 5와 같이 원자 벡터의 정규화 된 합으로 풀링 연산을 수행할 수 있다. 수학식 5"}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "vi는 컨벌루션된 벡터 데이터를 의미하고, t는 컨벌루션 레이어의 수를 의미하고, f는 컨벌루션 필터의 수를 의 미한다. 학습 모델은 컨벌루션(convolution) 연산을 수행하고, 풀링(pooling) 연산을 수행함으로써 생성된, 특징 벡터로부터 촉매의 활성도에 관련된 정보를 획득할 수 있다. 학습 모델은 획득된 촉매의 활성도에 관련된 정보를 전자 장치의 프로세서로 출력할 수 있다. 일 실시예에 따르면, 학습 모델은 학습 데이터를 학습함으로써 획득한 제3 특징 벡터와 촉매의 활성도에 관련된 정보의 상관 관계에 기초하여, 제1 특징 벡터 및 제2 특징 벡터로부터 촉매의 활성도에 관련된 정보 를 획득할 수 있다. 학습 모델은 학습 데이터들로부터 학습 데이터들의 각각에 대응하는 특징 벡터들을 획득할 수 있다. 학 습 데이터는 촉매를 구성하는 적어도 하나의 원자에 관련된 제1 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 제2 정보 및 원자들의 결합(bond)에 관한 제3 정보 및 촉매의 활성도에 관련된 제4 정보를 포함할 수 있 다. 학습 모델은 제1 정보, 제2 정보 및 제3 정보에 대해서 위에서 설명한 바와 같이 컨벌루션 연산 및 풀링 연산을 수행함으로써 특징 벡터를 획득할 수 있다. 학습 모델은 촉매의 활성도에 관련된 제4 정보를 제1 정보, 제2 정보 및 제3 정보와 함께 컨벌루션 연산 및 풀링 연산을 수행할 수 있다. 학습 모델은 특징 벡터와 제4 정보의 상관 관계를 획득할 수 있다. 예를 들면, 학습 모델은 특징 벡터와 제4 정보의 상관 관계를 선형 관계, 지수 관계 및 log 관계 중의 적어도 하나로 획득할 수 있다. 학습 모델은 특징 벡터와 제4 정보의 상관 관계를 나타내는 함수를 획득할 수 있다. 학습 모델은 획득된 상관 관계에 제1 특징 벡터 및 제2 특징 벡터를 적용함으로써, 촉매의 활성도에 관련 된 정보를 획득할 수 있다. 일 실시예에 따르면, 학습 모델은 FCN (fully connected network) 을 통해서, 획득된 제1 특징 벡 터 및 제2 특징 벡터를 소정의 값으로 변환할 수 있다. 변환된 값은 흡착 에너지, 촉매의 형성 에너지 (Formation energy), 밴드 갭(Band gap), 푸아송 비율(Poisson ratio), 탄성 계수(Shear moduli), 체적 탄성계수(Bulk moduli)과 같은 촉매의 활성도에 관련된 값이다. 학습 모델은 변환된 값을 학습 데이터를 학 습함으로써 획득한 상관 관계에 적용함으로써, 촉매의 활성도에 관련된 정보를 획득할 수 있다. 학습 모델 은 특징 벡터가 변환된 소정의 값을 상관 관계를 나타내는 함수에 적용함으로써, 촉매의 활성도에 관련된 정보를 획득할 수 있다. 일 실시예에 따르면, 학습 모델은 제1 특징 벡터와 제2 특징 벡터 각각을 FCN을 통해 서 흡착 에너지 기여도로 변환할 수 있다. 학습 모델은 흡착 에너지 기여도를 이용하여 흡착 에너지를 예 측할 수 있다. 예를 들면, 학습 모델은 제1 특징 벡터를 FCN을 통해서 흡착 에너지에 대한 덩어리 구조의 기여도 값인 Vbulk로 변환할 수 있다. 학습 모델은 제2 특징 벡터을 FCN을 통해서 흡착 에너지에 대 한 표면 구조의 기여도 값인 Vsurface로 변환할 수 있다. 학습 모델은 학습 데이터를 학습함으로써 획득한 흡착에너지와 기여도의 상관 관계를 나타내는 함수에 Vbulk와 Vsurface를 적용함으로써, 흡착 에너지를 예측할 수 있다. 일 실시예에 따르면, 학습 모델은 제1 특징 벡터와 제2 특징 벡터를 접합(concatenation)함 으로써 제4 특징 벡터를 생성할 수 있다. 학습 모델은 FCN을 통해서 제4 특징 벡터를 소정의 값으 로 변환할 수 있다. 학습 모델은 제4 특징 벡터가 변환된 소정의 값을 학습 데이터를 학습함으로써 획득 한 상관 관계에 적용함으로써, 흡착 에너지를 예측할 수 있다. 학습 모델은 흡착 에너지 대신/함께 촉매의 형성 에너지(Formation energy), 밴드 갭(Band gap), 푸아송 비율(Poisson ratio), 탄성 계수(Shear moduli), 체적 탄성 계수(Bulk moduli)를 촉매를 구성하는 적어도 하나 의 원자에 관련된 제1 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 제2 정보 및 원자들의 결합(bon d)에 관한 제3 정보과 함께 학습할 수 있다. 학습 모델은 학습한 촉매의 활성도에 관련된 정보의 유형과 동일한 유형의 정보를 출력할 수 있다. 예를 들면, 학습 모델은 밴드 갭(Band gap)에 대한 정보가 포함된 학습 데이터를 학습한 경우, 학습 모델 은 전자 장치의 프로세서로부터 입력된 제1 소재를 구성하는 적어도 하나의 원자에 관련된 제1 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 제2 정보 및 원자들의 결합(bond)에 관한 제3 정보에 대응되는 밴드 갭에 대한 정보를 출력할 수 있다. 즉, 학습 모델에서 출력되는 정보는 학습 데이터에 의해서 결정될 수 있다. 개시된 학습 모델은 입력 레이어로서, 소재를 구성하는 원자에 관련된 기초적인 정보(예를 들면, 원자의 족 번 호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경 (covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge))로부터 흡착 에너지와 같이 많은 시간과 연산 자원이 필요한 촉매의 활성도에 관련 된 정보를 빠르고 정확하게 획득할 수 있다. 특히, 개시된 학습 모델은 소재를 구성하는 원자의 d오비탈에 관련된 정보(예를 들면, d-band filing, d-band center, d-band width, d-band skewness, d-band kurtosis)와 같이 DFT연산이 필요한 정보를 이용하지 않기 때 문에, 촉매의 활성도에 관련된 정보를 빠르게 획득할 수 있다. 도 13 내지 도 19는 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출 된 흡착 에너지의 유사도를 나타낸 그래프이다. 학습 모델은 학습 데이터로서 465개의 촉매 물질과 5가지의 흡 착물 및 이들의 2699개의 결합 에너지에 관련된 정보가 학습된 것이다. 학습 데이터는 질소 전기 환원을 이용 한 암모니아 생성하는 공정에 이용되는 촉매 물질과 공정 중간에 생성되는 흡착물에 대한 정보를 포함한다. 학습 데이터에 포함된 촉매 물질에 관련된 정보는 주기율표상의 제4주기, 제5 주기 및 제6 주기에 해당되는 물 질들 중에서, 제3 족 내지 제12 족에 해당되는 물질에 관련된 정보다. 촉매에 관한 물질에 관련된 정보는 OI(Ordered intermetallics) 구조로 구성된 물질 172개와 CS(Core-shell) 구조로 구성된 물질 263개를 포함한 다. 학습 데이터에 포함된 흡착물에 관련된 정보는 H, N2, N2H, NH, NH2에 관련된 정보를 포함한다. 학습 데이터에 포함된 결합 에너지에 관련된 정보는 465개의 촉매 물질을 구성하는 원자들의 결합 에너지에 대 한 정보, 촉매 물질을 구성하는 원자와 흡착물을 구성하는 원자 사이의 결합 에너지에 대한 정보 및 흡착물을 구성하는 원자들의 결합 에너지에 대한 정보를 포함한다. 결합 에너지에 대한 정보는 -7eV 내지 1eV 사이의 결 합 에너지에 대한 정보를 포함한다. 학습 데이터는 촉매 물질에 관련된 정보, 흡착물에 관련된 정보 및 이들의 결합 에너지에 관련된 정보가 도 5 내지 도 7과 같이 그래프로 모델링된 데이터를 포함할 수 있다. 또한, 학습 데이터는 도 8 내지 도 10과 같이 벡터로 변환된 데이터를 포함할 수 있다. 도 13 및 도 14는 학습 데이터에 포함된 모든 소재 및 흡착물에 대해서 학습 모델을 이용하여 획득한 촉매의 활 성도에 관련된 정보와 DFT 연산을 이용하여 산출된 촉매의 활성도에 관련된 정보의 유사도를 나타낸 그래프이다. 그래프의 점선으로 표현된 사선과 일치하는 실험 결과가 많을 수록, 학습 모델을 이용하여 획득한 흡착 에너지와 DFT 연산을 이용하여 산출한 흡착 에너지가 동일한 결과가 존재하는 것을 의미한다. 구체적으로 도 13은 학습 데이터로서 소재의 덩어리 구조(bulk structure)가 모델링된 제1 그래프만을 학습한 제1 학습 모델이 획득한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 유사도를 나타낸 그래프이다. 또한, 도 14는 학습 데이터로서 소재의 덩어리 구조가 모델링된 제1 그래프 및 소재의 표면 구조 가 모델링된 제2 그래프를 함께 학습한 제2 학습 모델이 획득한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡 착 에너지의 유사도를 나타낸 그래프이다. 제2 그래프는 소재의 최외곽층을 구성하는 원자들과 최외곽층의 바로 아래층을 구성하는 원자들 및 흡착물을 구성하는 원자들의 결합이 모델링 된 것이다. 도 13을 참조하면, DFT 연산을 이용하여 산출한 흡착 에너지는 -7eV 내지 1eV에 골고루 분포되어 있지만, 제1 학습 모델이 획득한 흡착 에너지는 -2eV 내지 -3eV에 분포되어 있다. 즉, 흡착 에너지가 -2eV 내지 -3eV에 해 당하는 제1 학습 모델로부터 획득한 흡착 에너지가 DFT 연산을 이용하여 산출된 흡착 에너지와 유사할 뿐, 다른 범위의 흡착 에너지에 대해서는 유사하지 않음을 알 수 있다. 도 14를 참조하면, DFT 연산을 이용하여 산출한 흡착 에너지에 대한 제1 학습 모델이 획득한 흡착 에너지를 나 타내는 점들은 대부분 사선 그래프에 일치함을 알 수 있다. 도 13 및 도 14를 비교하면, 제2 학습 모델이 제1 학습 모델보다 흡착 에너지를 정확하게 획득함을 알 수 있다. 즉, 소재의 덩어리 구조가 모델링된 제1 그래프 및 소재의 표면 구조가 모델링된 제2 그래프를 함께 학습한 학 습 모델이 흡착 에너지를 정확하게 획득할 수 있다. 도 15 내지 도 18은 학습 데이터로서 소재의 덩어리 구조가 모델링된 제1 그래프 및 소재의 표면 구조가 모델링 된 제2 그래프를 함께 학습한 제2 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지 의 유사도를 나타낸 그래프들이다. 도 15는 일 실시예에 따른, 학습 데이터에 포함된 모든 소재와 N2에 대해서 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 유사도를 나타낸 그래프이고, 도 16는 일 실시예에 따른, 학습 데이터에 포함된 모든 소재와 N2H에 대해서 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하 여 산출된 흡착 에너지의 유사도를 나타낸 그래프이고, 도 17은 일 실시예에 따른, 학습 데이터에 포함된 모든 소재와 NH에 대해서 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 유 사도를 나타낸 그래프이고, 도 18은 일 실시예에 따른, 학습 데이터에 포함된 모든 소재와 NH2에 대해서 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 유사도를 나타낸 그래프이다. 도 15를 참조하면, DFT 연산을 이용하여 산출한 흡착 에너지에 대한 제1 학습 모델이 획득한 흡착 에너지를 나 타내는 점들은 대부분 -1eV 내지 1eV 범위 내에서 사선 그래프에 일치함을 알 수 있다. 도 16를 참조하면, DFT 연산을 이용하여 산출한 흡착 에너지에 대한 제1 학습 모델이 획득한 흡착 에너지를 나 타내는 점들은 대부분 -7eV 내지 0eV 범위 내에서 사선 그래프에 일치함을 알 수 있다. 도 17을 참조하면, DFT 연산을 이용하여 산출한 흡착 에너지에 대한 제1 학습 모델이 획득한 흡착 에너지를 나 타내는 점들은 대부분 -7eV 내지 -1eV 범위 내에서 사선 그래프에 일치함을 알 수 있다. 도 18을 참조하면, DFT 연산을 이용하여 산출한 흡착 에너지에 대한 제1 학습 모델이 획득한 흡착 에너지를 나 타내는 점들은 대부분 -5eV 내지 -1eV 범위 내에서 사선 그래프에 일치함을 알 수 있다. 도 15 내지 도 18을 참조하면, 소재의 덩어리 구조가 모델링된 제1 그래프 및 소재의 표면 구조가 모델링된 제2 그래프를 함께 학습한 학습 모델가 예측한 흡착 에너지는 DFT 연산을 이용하여 산출된 흡착 에너지와 거의 유사 함을 알 수 있다. 도 19는 학습 데이터로서 소재의 덩어리 구조가 모델링된 제1 그래프 및 소재의 표면 구조가 모델링된 제2 그래 프를 함께 학습한 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 유사도를 평균 절대 편차(Mean absolute error, MAE)를 이용하여 나타낸 그래프이다. 도 19를 참조하면, 흡착물 H에 대해서, 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에 너지의 편차는 0.28eV이다. 또한, 흡착물 N2에 대해서, 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 편차 는 0.18eV이다. 또한, 흡착물 N2H에 대해서, 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 편 차는 0.23eV이다. 또한, 흡착물 NH에 대해서, 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 편차 는 0.29eV이다. 또한, 흡착물 NH2에 대해서, 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지의 편 차는 0.26eV이다. 흡착물 전체에 대해서, 학습 모델이 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너지는 -7eV 내 지 1eV사이의 흡착 에너지 범위에 대해서 0.24eV의 편차가 존재한다. 도 19를 참조하면, 소재의 덩어리 구조가 모델링된 제1 그래프 및 소재의 표면 구조가 모델링된 제2 그래프를 함께 학습한 학습 모델이 예측한 흡착 에너지는 DFT 연산을 이용하여 산출된 흡착 에너지와 거의 유사함을 알 수 있다. 도 20은 일 실시예에 따른, 전자 장치의 블록도이다. 도 20을 참조하면, 일부 실시예에 따른 전자 장치는, 사용자 입력부, 출력부, 프로세서, 통신 부 및 메모리를 포함할 수 있다. 그러나, 도 10에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니다. 도 10에 도시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 도 10에 도시된 구성 요소보다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 사용자 입력부는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 터치스크린, 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 사용자 입력부는 도 2 내지 도 12를 참조하여 설명한 실시예들을 전자 장치가 수행하기 위해 필요한 사 용자 입력을 수신할 수 있다. 예를 들면, 사용자 입력부는 사용자로부터 소재를 구성하는 적어도 하나의 제1 원자에 관련된 정보를 수신 할 수 있다. 또한, 사용자 입력부는 흡착물을 구성하는 적어도 하나의 제2 원자에 관련된 정보를 수신할 수 있다. 또한, 사용자 입력부는 적어도 하나의 제1 원자 사이의 결합 거리, 적어도 하나의 제2 원자 사이 의 결합 거리, 적어도 하나의 제1 원자와 적어도 하나의 제2 원자 사이의 결합 거리 중에서 적어도 하나에 관련 된 정보를 사용자로부터 수신할 수 있다. 중복되는 내용은 생략한다. 다른 예를 들면, 사용자 입력부는 촉매로 이용될 소재(material)의 구조(structure), 흡착물의 구조 및 이 들의 결합에 대응하는 그래프를 사용자가 모델링하도록 그래픽 인터페이스를 제공할 수 있다. 그래픽 인터페이 스는 노드 엘리먼트와 엣지 엘리먼트를 포함할 수 있다. 사용자 입력부는 사용자로부터 노드 엘리먼트 (411, 413, 431)를 배열하는 사용자 입력을 수신할 수 있다. 사용자 입력부는 사용자로부터 노드 엘리먼트 를 연결하도록 적어도 하나의 엣지 엘리먼트를 배열하는 사용자 입력을 수신할 수 있다. 사용자 입력부는 배열된 적어도 하나의 노트 엘리먼트에 관련된 정보를 입력하는 사용자 입력을 수신할 수 있다. 사용자 입력부 는 배열된 적어도 하나의 엣지 엘리먼트에 관련된 정보를 입력하는 사용자 입력을 수신할 수 있다. 중복되 는 내용은 생략한다. 출력부는 전자 장치에서 처리되는 정보를 출력한다. 출력부는 촉매로 이용될 소재의 활성도에 관련 된 정보를 출력하는 디스플레이부(12-1)를 포함할 수 있다. 예를 들면 디스플레이부(12-1)은 소재의 흡착 에너 지, 형성 에너지(Formation energy), 밴드 갭(Band gap), 푸아송 비율(Poisson ratio), 탄성 계수(Shear moduli), 체적 탄성 계수(Bulk moduli)과 같은 활성도에 관련된 정보를 출력할 수 있다. 프로세서는 범용적으로 이용되는 적어도 하나의 프로세서일 수 있다. 또한, 프로세서는 촉매로 이용될 소재의 활성도에 관련된 정보를 획득하기 위한 특수 목적으로 제작된 프로세서 일 수 있다. 또한, 프로세서 는 인공지능 신경망의 기능을 수행하기 위해서 제작된 적어도 하나의 프로세서를 포함할 수 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메모리 에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 출력부, 통신부, 메모리 등을 전반 적으로 제어할 수 있다. 예를 들면, 프로세서는 촉매로 이용될 소재를 구성하는 적어도 하나의 원자에 관련 된 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 정보 및 원자들 사이의 결합에 관련된 정보 중에서 적어도 하나를 수신하도록 사용자 입력부 및 통신부 중에서 적어도 하나를 제어할 수 있다. 프로세서 는 인공지능 신경망으로 출력된 촉매로 이용될 소재의 활성도에 관련된 정보를 출력하도록 디스플레이부 (12-1)를 제어할 수 있다. 프로세서는 사용자로부터 수신된 정보를 인공지능 신경망에 적용할 수 있다. 예를 들면, 프로세서는 촉매로 이용될 소재를 구성하는 적어도 하나의 원자에 관련된 정보, 흡착물을 구성하는 적어도 하나의 원자에 관련된 정보 및 원자들 사이의 결합에 관련된 정보를 인공지능 신경망에 적용할 수 있다. 프로세서는 사용자로부터 수신된 정보에 대해서 전처리를 수행한 후, 인공지능 신경망에 적용할 수 있다. 예를 들면, 프로세서는 촉매로 이용될 소재를 구성하는 적어도 하나의 원자에 관련된 정보, 흡착물을 구성 하는 적어도 하나의 원자에 관련된 정보 및 원자들 사이의 결합에 관련된 정보를 그래프로 모델링한 후, 인공지 능 신경망에 적용할 수 있다. 프로세서는 도 2 내지 도 12를 참조하여 위에서 설명한 인공지능 신경망의 기능을 수행할 수 있다. 프로세 서는 인공지능 신경망의 기능을 수행하기 위해서 제작된 적어도 하나의 프로세서를 포함할 수 있다. 프로세 서는 메모리에 저장된 일련의 명령어를 실행함으로써 소프트웨어 모듈 형태로 존재하는 인공지능 신경 망의 기능을 수행할 수 있다. 프로세서는 서버에 저장된 인공지능 신경망의 기능을 수행하기 위해서 통신부를 제어할 수 있다. 프로세서는 인공지능 신경망의 기능을 수행하기 위해서 서버로 데이터를 송신하도록 통신부를 제어 할 수 있다. 프로세서는 서버에 저장된 인공지능 신경망으로부터 출력된 데이터를 수신하도록 통신부 를 제어할 수 있다. 프로세서는 인공지능 신경망을 갱신하기 위한 데이터를 서버로부터 수신하도 록 통신부를 제어할 수 있다. 프로세서는 인공지능 신경망이 새로운 학습 데이터를 학습하도록 일련의 명령어를 실행할 수 있다. 통신부는, 전자 장치가 다른 장치(미도시) 및 서버와 통신을 하게 하는 하나 이상의 구성요소를 포 함할 수 있다. 다른 장치(미도시)는 전자 장치와 같은 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 메모리는 램(RAM, Random Access Memory) SRAM(Static Random Access Memory)과 같이 일시적으로 데이터를 저장하는 메모리 및 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 롬 (ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크과 같이 비일시적으로 데이터를 저 장하는 데이터 스토리지 중에서 적어도 하나의 타입의 저장매체를 포함할 수 있다. 도 21은 일 실시예에 따른, 인공지능 신경망의 블록도이다. 도 21은 전자 장치의 프로세서가 인공지능 신경망을 수행하는 것으로 설명한다. 인공지능 신경망은 전 자 장치의 프로세서에 포함될 수 있으나, 이에 한정되지 않는다. 이하, 프로세서에 인공지능 신경 망이 포함된 것을 전제로 설명하나, 인공지능 신경망이 소프트웨어 모듈로 존재하는 경우, 서버에 포함된 경우도 유추 적용될 수 있음은 자명하다 도 21을 참조하면, 프로세서에 포함된 인공지능 신경망은 데이터 학습 모델(13-1) 및 데이터 인식 모델(13- 2)를 포함할 수 있다. 데이터 학습 모델(13-1)은 촉매로 이용될 소재의 활성도에 관련된 정보를 예측하기 위한 기준을 학습할 수 있다. 예를 들면, 데이터 학습 모델(13-1)은 입력된 데이터를 그래프로 모델링하는 기준을 학습할 수 있다. 구체적으 로, 데이터 학습 모델(13-1)은 촉매로 이용될 소재의 활성도를 구성하는 적어도 하나의 제1 원자에 관련된 제1 정보, 흡착물을 구성하는 적어도 하나의 제2 원자에 관련된 제2 정보 중에서 적어도 하나를 노드로 모델링하는 기준을 학습할 수 있다. 데이터 학습 모델(13-1)은 적어도 하나의 제1 원자 사이의 결합, 적어도 하나의 제2 원 자 사이의 결합, 제1 원자 및 제2 원자 사이의 결합에 관한 제3 정보를 엣지로 모델링하는 기준을 학습할 수 있 다. 또한, 데이터 학습 모델(13-1)은 촉매로 이용될 소재의 구조를 제1 그래프로 모델링하고, 소재의 표면 구 조 및 흡착물의 구조를 제2 그래프로 모델링하는 기준을 학습할 수 있다. 또한, 데이터 학습 모델(13-1)은 소재 의 최외곽층을 구성하는 제3 원자들과, 최외곽층의 바로 아래층을 구성하는 제4 원자들에 기초하여 촉매로 이용 될 소재의 표면의 구조를 제2 그래프로 모델링하는 기준을 학습 할 수 있다. 다른 예를 들면, 데이터 학습 모델(13-1)은 그래프로 모델링된 데이터를 벡터 형식 데이터로 변환하는 기준을 학습할 수 있다. 구체적으로, 데이터 학습 모델(13-1)은 제1 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나를 벡터 형식 데이터로 변환하는 기준을 학습할 수 있다. 데이터 학습 모델(13-1)은 제2 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경 (covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나를 중에서 적어도 하나를 벡터 형식 데이터로 변환하는 기준을 학습할 수 있다. 또 다른 예를 들면, 데이터 학습 모델(13-1)은 변환된 데이터로부터 특징 벡터를 획득하는 기준을 학습할 수 있 다. 구체적으로, 데이터 학습 모델(13-1)은 컨벌루션 연산, 풀링 연산 및 FCN(Full Connected Network) 기술을 이용하여 특징벡터를 획득하는 기준을 학습할 수 있다. 또 다른 예를 들면, 데이터 학습 모델(13-1)은 특징 벡터로부터 촉매로 이용될 소재의 활성도에 관련된 정보를 예측하는 기준을 학습할 수 있다. 구체적으로, 데이터 학습 모델(13-1)은 FCN(Full Connected Network) 기술 을 이용하여 특징벡터로부터 소재의 활성도에 관련된 정보를 예측하는 기준을 학습할 수 있다. 데이터 인식 모델(13-2)은 학습된 데이터 인식 모델을 이용하여, 촉매로 이용될 소재의 활성도에 관련된 정보를 예측할 수 있다. 예를 들면, 데이터 인식 모델(13-2)은 입력된 데이터를 그래프로 모델링 할 수 있다. 구체적으로, 데이터 인식 모델(13-2)은 촉매로 이용될 소재의 활성도를 구성하는 적어도 하나의 제1 원자에 관련된 제1 정보, 흡착물을 구성하는 적어도 하나의 제2 원자에 관련된 제2 정보 중에서 적어도 하나를 노드로 모델링할 수 있다. 데이터 인식 모델(13-2)은 적어도 하나의 제1 원자 사이의 결합, 적어도 하나의 제2 원자 사이의 결합, 제1 원자 및 제 2 원자 사이의 결합에 관한 제3 정보를 엣지로 모델링할 수 있다. 또한, 데이터 인식 모델(13-2)은 촉매로 이 용될 소재의 구조를 제1 그래프로 모델링하고, 소재의 표면 구조 및 흡착물의 구조를 제2 그래프로 모델링할 수 있다. 또한, 데이터 인식 모델(13-2)은 소재의 최외곽층을 구성하는 제3 원자들과, 최외곽층의 바로 아래층을 구성하는 제4 원자들에 기초하여 촉매로 이용될 소재의 표면의 구조를 제2 그래프로 모델링 할 수 있다. 다른 예를 들면, 데이터 인식 모델(13-2)은 그래프로 모델링된 데이터를 벡터 형식 데이터로 변환할 수 있다. 구체적으로, 데이터 인식 모델(13-2)은 제1 원자의 족 번호(group number), 주기 번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨(atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하 나를 벡터 형식 데이터로 변환할 수 있다. 데이터 인식 모델(13-2)은 제2 원자의 족 번호(group number), 주기번호(period number), 전기 음성도(electronegativity), 1차 이온화 에너지(the 1st ionization energy), 전자 친화력 (electron affinity), 밀도(density), 원자량(atomic weight), 공유 반경(covalent radius), 원자 볼륨 (atomic volume), 융점(melting point), 비등점(boiling point), 유효 핵 충전량 (effective nuclear charge) 중에서 적어도 하나를 중에서 적어도 하나를 벡터 형식 데이터로 변환할 수 있다. 또 다른 예를 들면, 데이터 인식 모델(13-2)은 변환된 데이터로부터 특징 벡터를 획득할 수 있다. 구체적으로, 데이터 인식 모델(13-2)은 컨벌루션 연산, 풀링 연산 및 FCN(Full Connected Network) 기술을 이용하여 특징벡 터를 획득할 수 있다. 또 다른 예를 들면, 데이터 인식 모델(13-2)은 특징 벡터로부터 촉매로 이용될 소재의 활성도에 관련된 정보를 예측할 수 있다. 구체적으로, 데이터 인식 모델(13-2)은 FCN(Full Connected Network) 기술을 이용하여 특징벡 터로부터 소재의 활성도에 관련된 정보를 예측하는 기준을 학습할 수 있다. 데이터 학습 모델(13-1) 및 데이터 인식 모델(13-2) 중에서 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습 모델(13-1) 및 데이터 인식 모델(13-2) 중에서 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또 는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 이 경우, 데이터 학습 모델(13-1) 및 데이터 인식 모델(13-2)은 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습 모델(13-1) 및 데이터 인식 모델(13-2) 중 하나는 전자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 데이터 학습 모델(13-1)은 데이터 학 습 모델(13-1)이 구축한 모델 정보를 데이터 인식 모델(13-2)로 제공할 수도 있다. 데이터 인식 모델(13-2)은 데이터 인식 모델(13-2)로 입력된 데이터를 추가 학습 데이터로서 데이터 학습 모델(13-1)로 제공할 수도 있다. 한편, 데이터 학습 모델(13-1) 및 데이터 인식 모델(13-2) 중에서 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 학습 모델(13-1) 및 데이터 인식 모델(13-2) 중에서 적어도 하나가 소프트웨어 모듈(또는, 인스터 력션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머 지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 22는 일 실시예에 따른, 전자 장치와 연동하는 서버의 블록도이다. 도 12을 참조하면, 일부 실시예에 따른 서버는 통신부, DB 및 프로세서를 포함할 수 있다. 통신부는 서버가 전자 장치와 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있다. DB는 촉매로 이용될 소재의 활성도에 관련된 정보를 예측하기 위한 데이터 및 프로그램을 저장할 수 있다. 프로세서는 통상적으로 서버의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 서버의 DB에 저장된 프로그램들을 실행함으로써, DB 및 통신부 등을 전반적으로 제어할 수 있다. 프로세서 는 DB에 저장된 프로그램들을 실행함으로써, 도 2 내지 도 12에서의 전자 장치의 동작의 일부를 수 행할 수 있다. 한편, 전자 장치 및 서버는 데이터 인식 모델의 학습 및 데이터 인식을 위한 작업을 효과적으로 분배하 여 수행할 수 있으며, 이를 통하여, 사용자의 의도에 부합하는 서비스를 제공하기 위하여 데이터 처리를 효율적 으로 수행할 수 있다. 일부 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기 록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매 체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매 체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데 이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발 성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈을 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다."}
{"patent_id": "10-2019-0136894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2019-0136894", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 촉매를 이용하여 N2를 전기 환원함으로써 암모니아(NH3)를 생성하는 동안의 반응 단계와 반응 경로를 나 타낸 도면이다. 도 2는 촉매의 활성도를 예측하는 방법의 예시를 설명하는 도면이다. 도 3은 일 실시예에 따른, 전자 장치가 촉매의 활성도를 예측하는 방법의 순서도이다. 도 4는 일 실시예에 따른, 전자 장치가 그래프를 사용자가 모델링하도록 제공하는 그래픽 인터페이스를 도시한 것이다. 도 5는 일 실시예에 따른, 전자 장치가 소재 및 흡착물의 구조에 관련된 정보를 그래프로 모델링하는 것을 도시 한 것이다. 도 6은 일 실시예에 따른, 전자 장치가 소재 및 흡착물의 구조에 관련된 정보를 그래프로 모델링하는 것을 도시 한 것이다. 도 7은 일 실시예에 따른, 전자 장치가 소재 및 흡착물의 구조에 관련된 정보를 그래프로 모델링하는 것을 도시 한 것이다. 도 8은 일 실시예에 따른, 전자 장치가 원자에 관련된 정보를 벡터 형식으로 변환하는 것을 나타낸 것이다. 도 9는 일 실시예에 따른, 전자 장치가 원자에 관련된 정보를 벡터 형식으로 변환하는 것을 나타낸 것이다. 도 10은 일 실시예에 따른, 전자 장치가 원자에 관련된 정보를 벡터 형식으로 변환하는 것을 나타낸 것이다. 도 11은 일 실시예에 따른, 전자 장치가 원자들 사이의 결합 거리에 관련된 정보를 벡터 형식으로 변환하는 것 을 나타낸 것이다. 도 12는 일 실시예에 따른, 전자 장치가 원자들 사이의 결합 거리에 관련된 정보를 벡터 형식으로 변환하는 것 을 나타낸 것이다. 도 13은 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너 지의 유사도를 나타낸 그래프이다. 도 14는 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너 지의 유사도를 나타낸 그래프이다. 도 15는 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너 지의 유사도를 나타낸 그래프이다. 도 16는 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너 지의 유사도를 나타낸 그래프이다. 도 17은 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너 지의 유사도를 나타낸 그래프이다. 도 18은 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너 지의 유사도를 나타낸 그래프이다. 도 19는 일 실시예에 따른, 학습 모델을 이용하여 예측한 흡착 에너지와 DFT 연산을 이용하여 산출된 흡착 에너 지의 유사도를 나타낸 그래프이다. 도 20은 일 실시예에 따른, 전자 장치의 블록도이다. 도 21은 일 실시예에 따른, 인공지능 신경망의 블록도이다. 도 22는 일 실시예에 따른, 전자 장치와 연동하는 서버의 블록도이다."}
