{"patent_id": "10-2020-0161200", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0073282", "출원번호": "10-2020-0161200", "발명의 명칭": "자율주행 판매를 위한 제스처 인식을 지원하는 AI 기반 자율주행 로봇 시스템", "출원인": "한국기술교육대학교 산학협력단", "발명자": "김덕수"}}
{"patent_id": "10-2020-0161200", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자율주행 로봇 시스템에 있어서,상기 시스템은모바일 로봇과 상기 모바일 로봇을 원격에서 제어하는 컴퓨팅 서버부를 포함하며,상기 모바일 로봇은주변의 영상을 취득하는 영상 취득부;상기 모바일 로봇의 위치 예측을 위해 복수의 센서를 포함하는 센서부;상기 센서부로부터 획득한 복수의 센서 데이터를 가공하고 판단하는 제어부;상기 제어부로부터 가공된 상기 센서 데이터 및 상기 영상 취득부로부터 획득한 영상 데이터를 원격지의 상기컴퓨팅 서버부에 송신하거나, 상기 컴퓨팅 서버부로부터 상기 모바일 로봇의 제어에 관련된 로봇 제어 데이터를수신하는 통신부;상기 모바일 로봇의 동작을 제어하는 구동부; 및상기 영상 데이터로부터 AI를 이용하여, 객체를 인식하고, 자동으로 물건을 판매하는 자동판매 모듈을 포함하는AI 기반 자율주행 로봇 시스템."}
{"patent_id": "10-2020-0161200", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 컴퓨팅 서버부는 상기 모바일 로봇의 상기 통신부를 통해 수신한 상기 영상 데이터로부터 특정한 객체 및 객체의 특정 제스처를인식하는 제스처 인식 모듈;상기 모바일 로봇으로부터 획득한 복수의 센서 데이터를 이용하여 상기 모바일 로봇의 이동경로를 제어할 수 있도록 목적지 좌표(waypoint)를 연산하고, 연산한 상기 목적지 좌표에 따라, 상기 모바일 로봇이 일정한 경로를순회할 수 있도록 제어하는 경로 순회 제어 모듈;상기 목적지 좌표에 따라, 상기 모바일 로봇의 항해(navigation)을 제어하는 항해 모듈; 및상기 모바일 로봇과의 데이터 송신 및 수신을 제어하는 서버통신부를 더 포함하는 AI기반 자율주행 로봇시스템."}
{"patent_id": "10-2020-0161200", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 제스처 인식 모듈은 상기 영상 데이터를 신경망 학습시키는 학습부;상기 학습부로부터 학습된 결과를 바탕으로 객체 및 객체의 제스처를 판단하는 AI 처리부를포함하는 AI기반 자율주행 로봇 시스템"}
{"patent_id": "10-2020-0161200", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 AI 처리부는 상기 객체를 개별 클래스로 인식하기 위한 신경망으로 Mask R-CNN을 사용하며, 상기 개별 클래스로는 사람과 백그라운드로 이루어진 바이너리 클래시피케이션을 사용하여, 상기 사람 클래스로 인식된 경우공개특허 10-2022-0073282-3-에만 상기 영상 데이터의 상기 사람 객체의 영역에 마스크(Mask) 처리하는 것을 특징으로 하는 AI기반 자율주행로봇 시스템"}
{"patent_id": "10-2020-0161200", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 학습부는 상기 객체의 제스처를 판단하기 위해, 상기 마스크 처리된 상기 영상데이터를 기반으로 Resnet기반 모델 학습을 이용하는 것을 특징으로 하며, 상기 Resnet 기반 모델의 학습을 시키기 위해, 다양한 제스처의 사람 이미지를 생성하는 데이터셋 생성 프로그램을 이용하는 것을 특징으로 하는 AI기반 자율주행 로봇 시스템."}
{"patent_id": "10-2020-0161200", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 AI 기반 자율주행 로봇 시스템은 모바일 로봇과 모바일 로봇을 원격에서 제어하는 컴퓨팅 서버부를 포함하며, 모바일 로봇은 주변의 영상을 취득하여, 상기 영상에서 객체와 객체의 제스처를 컴퓨 팅 서버부의 AI 처리부를 통해 인식하고, 인식된 제스처에 따라 모바일 로봇을 이동하거나 자동으로 물건을 판매 할 수 있는 것을 특징으로 한다."}
{"patent_id": "10-2020-0161200", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI(Artificial Intelligence)룰 이용하여, 사용자의 특정한 제스처를 구매를 위한 의사표시라고 인식 하여, 사용자에게 물건을 판매할 수 있는 자율주행과 자동 판매가 가능한 모바일 로봇과 상기 모바일 로봇과 통 신하며 원격에서 제어할 수 있는 컴퓨터 서버를 포함한 AI 기반의 자율주행 로봇 시스템에 관한 것이다."}
{"patent_id": "10-2020-0161200", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇 기술과 인공지능 기술, 그리고 자율주행 기술이 발전하면서, 점점 로봇이 제조업에서 단순히 특정한 형상 의 물품을 제조하는 데서 벗어나 사용자들에게 서비스를 제공하는 형태로 발전하고 있다. 다만 현재로서는 상업적 서비스가 가능한 로봇의 기술 수준은 상점에서 물품을 배달하거나, 사용자에게 미리 정 해진 수준의 서비스 행위(예를 들어 설겆이를 한다거나, 물건을 들어 옮기는)를 하는 정도에 머물러 있는 실정 이다. 따라서, 전술한 로봇 활용의 한계점을 극복하기 위하여, 사용자의 의사를 확인하고, 확인된 의사에 따라, 로봇 이 스스로 경로를 찾아 이동하며, 이후 사용자가 필요한 물품을 구매할 수 있는 자동판매가 특정한 지역안에서 자율적인 주행을 통해 가능한 모바일 로봇이나 모바일 로봇 시스템에 대한 연구가 필요하게 되었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개 특허 제10-2019-0088854호(2019년07월23일 공개) (특허문헌 0002) 대한민국 공개 특허 제10-2019-0130214호(2019년11월22일 공개)"}
{"patent_id": "10-2020-0161200", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 사용자 및 사용자의 특정한 제스처를 인식하고, 상기 사용자가 위치한 목표 위치로 자율주행 을 하며, 상기 사용자에게 특정한 서비스(예를 들어 물건 판매)를 제공할 수 있는 AI 기반 자율주행 로봇 시스 템을 제공하는 데 있다. 본 발명의 또다른 목적은 상기 AI 기반 자율주행 로봇 시스템에서 상기 사용자의 제스처를 인식할 때, AI 처리 부를 활용하며, 상기 AI 처리부가 Mask R-CNN과 같은 인공지능 알고리즘을 사용하여, 처리 속도와 정확도 모두 를 높게 하여, 모바일 로봇과 같이 순간적인 이동이 잦은 환경에 적합하도록 하는 데 있다. 본 발명의 또다른 목적은 상기 AI 기반 자율주행 로봇 시스템의 모바일 로봇의 주행시, 단순히 GPS 등의 위치 항법 기반의 방식이 아닌 다양한 센서부로부터 획득한 정보를 이용하여, 자신의 위치를 추정하면서 동시에 이동 을 위한 지도를 작성할 수 있는 특징을 제공하는데 있다."}
{"patent_id": "10-2020-0161200", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 AI 기반 자율주행 로봇 시스템은, 모바일 로봇과 상기 모바일 로봇을 원격에서 제 어하는 컴퓨팅 서버부를 포함하며, 상기 모바일 로봇은 주변의 영상을 취득하는 영상 취득부; 상기 모바일 로봇의 위치 예측을 위해 복수의 센서를 포함하는 센서부; 상기 센서부로부터 획득한 복수의 센서 데이터를 가공하고 판단하는 제어부; 상기 제어부로부 터 가공된 상기 센서 데이터 및 상기 영상 취득부로부터 획득한 영상 데이터를 원격지의 상기 컴퓨팅 서버부에 송신하거나, 상기 컴퓨팅 서버부로부터 상기 모바일 로봇의 제어에 관련된 로봇 제어 데이터를 수신하는 통신부; 상기 모바일 로봇의 동작을 제어하는 구동부; 및 상기 영상 데이터로부터 AI를 이용하여, 객체를 인식 하고, 자동으로 물건을 판매하는 자동판매 모듈을 포함한다. 본 발명의 일 실시예에 따른 상기 컴퓨팅 서버부는 상기 모바일 로봇의 상기 통신부를 통해 수신한 상기 영상 데이터로부터 특정한 객체 및 객체의 특정 제스처를 인식하는 제스처 인식 모듈; 상기 모바일 로봇으로부터 획 득한 복수의 센서 데이터를 이용하여 상기 모바일 로봇의 이동경로를 제어할 수 있도록 목적지 좌표(waypoint) 를 연산하고, 연산한 상기 목적지 좌표에 따라, 상기 모바일 로봇이 일정한 경로를 순회할 수 있도록 제어하는 경로 순회 제어 모듈; 상기 목적지 좌표에 따라, 상기 모바일 로봇의 항해(navigation)을 제어하는 항해 모듈; 및 상기 모바일 로봇과의 데이터 송신 및 수신을 제어하는 서버통신부를 더 포함한다. 본 발명의 일 실시예에 따르면, 상기 제스처 인식 모듈은 상기 영상 데이터를 신경망 학습시키는 학습부 및 상 기 학습부로부터 학습된 결과를 바탕으로 객체 및 객체의 제스처를 판단하는 AI 처리부를 포함한다. 본 발명의 일 실시예에 따르면, 상기 AI 처리부는 상기 객체를 개별 클래스로 인식하기 위한 신경망으로 Mask R-CNN을 사용하며, 상기 개별 클래스로는 사람과 백그라운드로 이루어진 바이너리 클래시피케이션을 사용하여, 상기 사람 클래스로 인식된 경우에만 상기 영상 데이터의 상기 사람 객체의 영역에 마스크(Mask) 처리하는 것을 특징으로 한다. 본 발명의 일 실시예에 따르면, 상기 학습부는 상기 객체의 제스처를 판단하기 위해, 상기 마스크 처리된 상기 영상데이터를 기반으로 Resnet 기반 모델 학습을 이용하는 것을 특징으로 하며, 상기 Resnet 기반 모델의 학습 을 시키기 위해, 다양한 제스처의 사람 이미지를 생성하는 데이터셋 생성 프로그램을 이용하는 것을 특징으로 한다. 본 발명의 일 실시예에 따르면, 상기 항해 모듈은 상기 목적지 좌표로, 이동하는 경우, 상기 획득한 복수의 센 서 데이터를 이용하는 SLAM(Simultaneous Localization and Mapping) 방식을 사용하는 것을 특징으로 한다. 본 발명의 일 실시예에 따르면, 상기 경로 순회 제어 모듈은 사용자의 객체의 제스처로 결정되거나 또는 사용자 가 지정한 단수 또는 복수의 목적지 좌표를 기반으로 이동하되, 상기 복수의 목적지 좌표중 최종 목적지 좌표에 도달하면, 상기 모바일 로봇의 이동경로를 반대로(reverse) 설정하여 이동하며, 상기 제스처 인식 모듈에서 상 기 특정 제스처를 인식하는 경우, 정지하는 것을 특징으로 한다. 본 발명의 일 실시예에 따르면, 상기 경로 순회 제어 모듈에서 상기 사용자가 목적지 좌표(waypoint)를 지정하 는 경우, 시각화를 위해, Rviz 방식을 사용하며, 상기 Rviz 방식에서 사용하는 데이터의 형태는 목적지 좌표 뿐 아니라, 상기 모바일 로봇의 자세 정보를 포함하도록 한다. 본 발명의 일 실시예에 따르면, 상기 항해 모듈은, 상대적으로 원거리까지의 항해를 위한 글로벌 플래너(Global planner)와 상기 글로벌 플래너보다 가까운 근거리의 항해를 위한 로컬 플래너(Local planner)를 포함한다. 본 발명의 일 실시예에 따르면,상기 글로벌 플래너는 Dijkstra 알고리즘 또는 A*알고리즘을 사용하고, 상기 로 컬 플래너의 경우에는 Dynamic Window Approach 방식을 사용하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0161200", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 AI 기반 자율주행 로봇 시스템은 사용자 및 사용자의 특정한 제스처를 인식하고, 상기 사용자가 위치 한 목표 위치로 자율주행을 하며, 상기 사용자에게 물건 판매와 같은 특정한 서비스를 제공하여 로봇의 서비스 능력을 향상시키는 데 있다. 본 발명은 사용자의 제스처를 인식할 때, AI 처리부를 활용하는데, 상기 AI 처리부가 Mask R-CNN과 같은 인공지 능 알고리즘을 사용하여, 처리 속도와 정확도 모두를 높게 하여, 자동 판매와 같은 기능을 제공하는 모바일 로 봇과 같이 순간적인 이동이 잦은 환경에 적합하다. 본 발명은 모바일 로봇의 주행시, 단순히 GPS 등의 위치 항법 기반의 방식이 아닌 다양한 센서부로부터 획득한 정보를 이용하여, 자신의 위치를 추정하면서 동시에 이동을 위한 지도를 작성하고, 목적지로 이동시에 상대적으 로 원거리를 이동하는 동작 방법과 근거리를 이동하는 동작 방법을 이원화하여, 결과적으로 빠른 속도로 제스처 를 취하는 사용자에게 접근할 수 있는 효과를 제공한다."}
{"patent_id": "10-2020-0161200", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명의 구체적인 실시예를 상세하게 설명한다. 다만, 본 발명의 사상은 제시되 는 실시예에 제한되지 아니하고, 본 발명의 사상을 이해하는 당업자는 동일한 사상의 범위 내에서 다른 구성요 소를 추가, 변경, 삭제 등을 통하여, 퇴보적인 다른 발명이나 본 발명 사상의 범위 내에 포함되는 다른 실시예 를 용이하게 제안할 수 있을 것이나, 이 또한 본원 발명 사상 범위 내에 포함된다고 할 것이다. 또한, 각 실시 예의 도면에 나타나는 동일한 사상의 범위 내의 기능이 동일한 구성요소는 동일한 참조부호를 사용하여 설명한 다. 도 1 및 도 5는 각각 본 발명의 일 실시예에 따른 모바일 로봇의 전체적인 구성을 나타낸 블록도와, 상기 모바일 로봇의 예시적 설계도를 도시한 것이다. 상기 모바일 로봇은 주변의 영상을 취득하는 영상 취득부, 상기 모바일 로봇의 위치 예측을 위해 복수의 센서를 포함하는 센서부, 상기 센서부로부터 획득한 복수의 센서 데이터를 가공하고 판단하 는 제어부, 상기 제어부로부터 가공된 상기 센서 데이터 및 상기 영상 취득부로부터 획득한 영상 데이터를 원격지의 후술되는 상기 컴퓨팅 서버부에 송신하거나, 상기 컴퓨팅 서버부로부터 상기 모 바일 로봇의 제어에 관련된 로봇 제어 데이터를 수신하는 통신부를 포함한다. 또한, 상기 모바일 로봇은 상기 모바일 로봇의 동작을 제어하여, 로모바일 로봇을 이동시키는 구동부 ; 및 상기 영상 데이터로부터 AI를 이용하여, 객체를 인식하고, 자동으로 물건을 판매하는 자동판매 모듈 을 포함한다. 구체적으로, 상기 모바일 로봇이란 기본적인 자율주행이 가능하도록 이동가능한 로봇을 의미한다. 또한 상기 센서부의 경우 복수의 센서들을 포함할 수 있는데, 상기 복수의 센서들이랑 IMU(관성측정장 치), 바퀴의 회전수 등을 측정할 수 있는 엔코더를 포함할 수 있으며 각각 센서 데이터를 출력하여, 후술될 컴 퓨팅 서버부에서 목적지 좌표의 연산 등에 활용될 수 있다. 또한, 상기 제어부는 후술되는 컴퓨팅 서버부와의 통신을 하는 상기 통신부를 제어하거나, 상기 컴퓨팅 서버부로부터 수신된 목적지 좌표나 다른 로봇 제어 데이터를 통해 상술한 구동부를 제어하는 기능을 수행한다. 또한 상기 통신부는 상기 센서부로부터 획득한 상기 센서 데이터나 상기 영상 취득부로부터 획득한 상기 영상 데이터를 상기 컴퓨팅 서버부의 서버 통신부로 전송하고, 상기 컴퓨팅 서버부 로부터 다양한 로봇 제어 데이터(로봇 구동을 제어하는 데이터 또는 주행해야 하는 목적지 좌표 등을 포 함함)를 수신하는 기능을 수행한다. 또한 상기 통신부는 후술되는 상기 자동판매 모듈에서 발생하는 여러 이벤트 데이터(사용자의 상품 구매, 사용자의 결제 정보 등)에 관련된 정보 또한 상기 컴퓨팅 서버부으로 송신하거나 상기 컴퓨팅 서버 부로부터 상기 자동판매와 관련된 데이터를 수신할 수 있다. 또한 상기 통신부와 상기 서버 통신부 사이의 통신 방식에는 블루투스, Wi-Fi, LTE-M, 5G 등 매우 다양한 무선통신 방식이 사용될 수도 있고, 이러한 무선 통신시 데이터의 보안을 위해, 몇가지 보안 스킴 (scheme)을 구현할 수도 있다. 보다 구체적으로 상기 보안 스킴은 상기 모바일 로봇가 임베디드 디바이스 의 형태로 구현되어, 컴퓨팅 파워가 높지 않기 때문에 경량 해시 함수와 같이 컴퓨팅 파워가 높게 들지 않는 단 방향 암호화 보안 방식을 사용할 수 있다. 마지막으로, 도면으로 자세히 도시하지는 않았지만, 상기 자동판매 모듈의 경우, 사용자에게 상품을 공급 하거나 일정한 서비스를 제공하고, 그에 대한 사용자의 피드백을 받는 기능을 제공하기 위해, 부가적으로 디스 플레이부(도면부호 미도시)를 포함할 수 있다. 또한 상기 자동판매 모듈은 부가적으로 사용자 입력부(도 면부호 미도시)를 더 포함하거나, 상품을 보관할 수용공간을 제공하며 상기 컴퓨터 서버부로부터의 데이 터(예를 들어 적절한 사용자 지불이 완료되었으니, 상품을 공급해도 됨)를 수신해야만 상품을 공급할 수 있도록 적절한 잠금수단을 제공하는 상품보관부를 추가로 포함할 수도 있다. 도 2는 본 발명의 일 실시예에 따른 모바일 로봇과, 컴퓨팅 서버부를 포함하는 AI 기반 자율주행 로봇 시스템을 도시하는 도면이다. 상기 모바일 로봇의 세부 구성과 그 동작에 대해서는 이미 전술하였으므로, 여기서는 컴퓨팅 서버부 에 대해서 기술하기로 한다. 상기 컴퓨팅 서버부는 상기 모바일 로봇의 상기 통신부를 통해 수신한 상기 영상 데이터로부 터 특정한 객체 및 객체의 특정 제스처를 인식하는 제스처 인식 모듈를 더 포함할 수 있다. 또한 상기 컴퓨팅 서버부는 상기 모바일 로봇으로부터 획득한 복수의 센서 데이터를 이용하여 상기 모바일 로봇의 이동경로를 제어할 수 있도록 목적지 좌표(waypoint)를 연산하고, 연산한 상기 목적지 좌 표에 따라, 상기 모바일 로봇이 일정한 경로를 순회할 수 있도록 제어하는 경로 순회 제어 모듈을 더 포함할 수 있다. 보다 구체적으로 상기 경로 순회 제어 모듈에서 연산한 목적지 좌표 들은 상기 서버 통신부를 통해 상기 모바일 로봇으로 전송되고 이는 상기 모바일 로봇의 통신부를 거쳐 제어부으로 전달되어, 상기 제어부에서 상기 구동부를 제어할 수 있도록 이용된다. 또한 상기 컴퓨팅 서버부는 상기 목적지 좌표에 따라, 상기 모바일 로봇의 항해(navigation)을 제어하는 항해 모듈; 및 상기 모바일 로봇과의 데이터 송신 및 수신을 제어하는 서버통신부을 포함할 수 있다. 또한, 상기 제스처 인식 모듈은 인공지능, 즉 AI를 이용하여 상기 영상 데이터의 객체와 객체의 제스처를 정확하게 인식하도록, 다음과 같은 세부구성을 더 포함한다. 보다 구체적으로 상기 제스처 인식모듈은 상기 영상 데이터를 신경망 학습시키는 학습부 및 상기 학습부 로부터 학습된 결과를 바탕으로 객체 및 객체의 제스처를 판단하는 AI 처리부를 더 포함한다.특히 상기 학습부와 상기 AI 처리부에서는 상기 객체의 특정한 제스처만을 빠르고 정확하게 인식할 수 있도록, 여러 신경망 알고리즘 중, 객체의 빠른 인식과 특정한 제스처의 유무만을 정확하게 판단할 수 있어야 한다. 보다 구체적으로, 상기 AI 처리부는 상기 객체를 개별 클래스로 인식하기 위한 신경망으로 Mask R-CNN(Regional Convolutional Neural Network)을 사용하며, 상기 개별 클래스로는 사람과 백그라운드로 이루어진 바이너리 (binary) 클래시피케이션(classification)을 사용하여, 상기 사람 클래스로 인식된 경우에만 상기 영상 데이터 의 상기 사람 객체의 영역에 마스크(Mask) 처리한다. 즉, 인식하고자하는 클래스를 사람과 백그라운드, 단 2가지 클래스로 분류하여 신경망 학습의 정확도를 높일 수 있도록 하였다. 또한 해당 신경망에서는 입력으로 RGB를 받으며, 출력으로는 사람의 형상을 검출한 마스크 이미 지를 출력하게 된다. 특히 R-CNN을 통해 취득한 영상 데이터에서 객체가 있을 것으로 추정되는 영역(region)을 추출하고 이 영역에 대해서만 CNN 신경망을 적용한 뒤, 원하는 객체라고 인식되는 영역에, 학습처리속도를 높이 위해 마스킹을 하여, 처리 속도를 다른 인식 방법보다 매우 빠르게 수행할 수 있다는 장점이 있다. 도 3의 경우, 상술한 AI 처리부에서 Mask R-CNN을 적용하여, 사람의 특정한 제스처(모바일 로봇을 만나기 위해 손을 드는 행위)를 인식하여 마스킹하는 것을 도시화한 것이다. 또한, 상기 학습부는 상기 객체의 제스처를 판단하기 위해, 상기 마스크 처리된 상기 영상데이터를 기반으로 Resnet(Residual Neural Network) 기반 모델 학습을 이용하는 것을 특징으로 하며, 상기 Resnet 기반 모델의 학습을 시키기 위해, 다양한 제스처의 사람 이미지를 생성하는 데이터셋 생성 프로그램을 이용한다. 상술한 Resnet의 경우, 앞서 마스킹된 객체들에 대해서, 우리가 찾기를 원하는 객체의 제스처인지를 정확하게 인식하기 위해 사용하는 신경망으로, 잔차 학습(residual learning)을 통해 신경망 학습의 최적화가 상대적으로 쉽고, 학습시의 에러율을 낮추는 데에도 효과적인 특징을 갖는다. 도 4의 경우, 상기 학습부에서 Resnet 기반의 학습을 시키기 위해, 다양한 제스처의 사람 이미지를 생성하는 데 이터셋 프로그램을 활용하는 점을 예시화한 것이다. 또한 상기 컴퓨팅 서버부의 상기 항해 모듈은 상술한 목적지 좌표로, 이동하는 경우, 상기 획득한 복수의 센서 데이터를 이용하여 이동할 수 있는SLAM(Simultaneous Localization and Mapping) 방식을 사용하는 것을 특징으로 한다. 상기 SLAM 방식을 통해, 상기 항해 모듈은 상기 모바일 로봇의 센서부(엔코더 및 IMU 등)로부터 획 득한 다양한 정보를 이용하여, 자신의 위치를 추정하면서 동시에 지도를 작성할 수 있는 특징을 가진다. 이러한 SLAM 방식을 사용하면 GPS 방식만으로 지도를 생성하고 이동하는 방식에 비해, 특히 실내에서의 이동에 적합하 다는 특징을 갖는다. 또한, 상기 경로 순회 제어 모듈은 사용자의 객체의 제스처로 결정되거나 또는 사용자가 지정한 단수 또 는 복수의 목적지 좌표를 기반으로 이동하며, 상기 복수의 목적지 좌표중 최종 목적지 좌표에 도달하면, 상기 모바일 로봇의 이동경로를 반대로(reverse) 설정하여 이동할 수 있다. 또한 상기 경로 순회 제어 모듈은 상기 제스처 인식모듈에서 상기 특정 제스처를 인식하고, 목적지 좌표를 연산한 뒤, 상기 목적지 좌표에 도착하는 경우(즉, 특정 제스처를 취한 사용자가 근접하다고 판단하는 경우), 정지한다. 이후 사용자는 상기 모바일 로봇의 자동판매 모듈을 이용하여 자신이 원하는 상 품을 구매하는 등의 행위를 할 수 있다. 또한 구체적으로 상기 경로 순회 모듈은 상기 사용자가 목적지 좌표(waypoint)를 지정하는 경우, 시각화 를 위해, Rviz 방식을 사용한다. Rviz는 ROS(Robot Operating System)에서 사용하는 3D 기반의 시각화 툴이며, 모바일 로봇의 센서 데이 터를 이용하여 시각화할 수 있다는 특징을 가지고, 상기 Rviz 방식에서 사용하는 데이터의 형태는 목적지 좌표 뿐 아니라, 상기 모바일 로봇의 자세 정보를 포함하도록 하여, 결과적으로 사용자가 상기 모바일 로봇 을 좀더 세밀하게 컨트롤 할 수 있도록 한다. 또한, 상기 항해 모듈은, 목적지 좌표로의 정확하고 빠른 이용을 하기위해, 이동시 2가지 접근 방식을 같 이 사용하는 것을 특징으로 한다.보다 구체적으로, 상기 항해 모듈은 상대적으로 원거리까지의 항해를 위한 글로벌 플래너(Global planner)와 상기 글로벌 플래너보다 가까운 근거리의 항해를 위한 로컬 플래너(Local planner)를 포함한다. 상기 글로벌 플래너의 경우에는 Dijkstra 알고리즘 또는 A*알고리즘을 사용하여, 상대적으로 원거리까지의 목적 지 좌표로의 항해를 주도하도록 할 수 있다. 반면, 상기 로컬 플래너의 경우에는 동적 윈도우 접근(Dynamic Window Approach) 방식을 사용하는 것을 특징으 로 한다. 보다 구체적으로, 상기 동적 윈도우 접근 방식(Dynamic Window Approach)는 일반적인 항해 시스템의 목적지가 x, y 좌표인 반면, 로봇과 충돌 가능한 장애물을 회피하면서 목적지까지 빠르게 다다를 수 있는 속도를 목적함 수로 선택하는 방법으로, 목적함수 G는 병진속도 v와 회전속도 w를 선택하는 것을 특징으로 한다. 즉, 이러한 방식을 통해, 상대적으로 가까운 거리에서의 이동에 목적지에 최대한 빠르게 접근할 수 있는 효과를 제시할 수 있다. 도 6은 상술한 동적 윈도우 접근방식을 설명하기 위한 도면이다."}
{"patent_id": "10-2020-0161200", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 모바일 로봇의 전체적인 구성을 나타낸 블록도이다. 도 2는 본 발명의 일 실시예에 따른 모바일 로봇과 컴퓨팅 서버부를 포함하는 AI 기반 자율주행 로봇 시스템을 도시하는 도면이다. 도 3은 본 발명의 일 실시예에 따른 AI 처리부의 Mask R-CNN을 적용한 점을 도시화한 것이다. 도 4는 AI 처리부에서 Resnet 기반의 학습을 시키기 위해, 다양한 제스처의 사람 이미지를 생성하는 데이터셋 프로그램을 예시화한 것이다. 도 5는 본 발명의 모바일 로봇의 예시적 설계도로, 좌측 도면은 정면도이고, 우측 도면은 측면도이다. 도 6은 본 발명의 모바일 로봇의 로컬 플래너의 동작방식인 다이나믹 윈도우 어프로치를 설명하기 위한 도면이 다."}
