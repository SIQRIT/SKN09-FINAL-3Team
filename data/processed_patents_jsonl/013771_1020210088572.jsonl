{"patent_id": "10-2021-0088572", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0007807", "출원번호": "10-2021-0088572", "발명의 명칭": "이미지 프로세싱을 위한 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "사커 아룹 쿠마"}}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 이미지를 처리하는 방법에 있어서,피사체를 촬영하여 제1 이미지를 획득하는 단계;상기 전자 장치로부터 상기 피사체까지의 거리에 관련된 정보를 포함하는, 깊이 이미지를 획득하는 단계;상기 제1 이미지에 빛 반사가 존재하는지 여부를 식별하는 단계;상기 제1 이미지에 빛 반사가 존재하는 경우, 상기 전자 장치로부터 상기 피사체까지의 거리를 나타내는 깊이정보를 획득하는 단계;상기 획득된 깊이 정보에 기초하여, 상기 전자 장치의 플래시가 활성화된 상태에서 상기 피사체를 촬영함으로써제2 이미지를 획득하는 단계;상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 각각을 정합하여 하나의 좌표계에 나타내기 위한 전처리를 수행하는 단계; 및상기 전처리가 수행된 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 중 적어도 하나를 이용하여, 빛반사가 제거된 이미지를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 빛 반사가 존재하는지 여부를 식별하는 단계는, 상기 제1 이미지를 빛 반사 검출 모델에 적용하여 상기 제1 이미지에 빛 반사가 존재하는지 여부를 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 깊이 정보에 기초하여, 상기 제2 이미지를 획득하는 단계는,상기 깊이 정보를 임계값과 비교하여, 상기 전자 장치의 상기 플래시를 활성화할지 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 깊이 정보를 임계값과 비교하여, 상기 플래시를 활성화할지 여부를 결정하는 단계는,상기 깊이 정보를 상기 임계값과 비교한 결과, 상기 깊이 정보가 상기 임계값 미만인 경우, 상기 플래시를 활성화하여 상기 피사체를 촬영함으로써 상기 제2 이미지를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0007807-3-제4항에 있어서,상기 빛 반사가 제거된 이미지를 획득하는 단계는,상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지를 빛 반사 제거 모델에 적용하여, 상기 빛 반사가 제거된 이미지를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 깊이 정보를 임계값과 비교하여, 상기 플래시를 활성화할지 여부를 결정하는 단계는,상기 깊이 정보를 상기 임계값과 비교한 결과, 상기 깊이 정보가 상기 임계값 이상인 경우, 상기 전자 장치의상기 플래시를 비활성화하는 단계를 포함하고,상기 빛 반사가 제거된 이미지를 획득하는 단계는,상기 전처리가 수행된 상기 제1 이미지 및 상기 전처리가 수행된 상기 깊이 이미지만을 이용하여, 상기 빛 반사가 제거된 이미지를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 전처리를 수행하는 단계는,상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지를 공통의 이미지 평면에 투영시키고, 상기 제1 이미지의 제1 픽셀들, 상기 제2 이미지의 제2 픽셀들, 상기 깊이 이미지의 제3 픽셀들을 정합시키는 단계; 및상기 제1 이미지의 제1 픽셀들, 상기 제2 이미지의 제2 픽셀들 및 상기 깊이 이미지의 제3 픽셀들 각각에 대하여, 각각의 이미지들 내 픽셀들의 밝기가 균일해지도록 캘리브레이션을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 빛 반사 제거 모델은,상기 제1 이미지를 입력 받아, 상기 빛 반사가 제거된 이미지를 출력하는 메인 모델;상기 제2 이미지를 입력 받아, 상기 메인 모델에 포함되는 신경망 레이어에 입력될, 상기 제2 이미지에 관련된적어도 하나의 피처 맵을 출력하는 제1 서브 모델;상기 깊이 이미지를 입력 받아, 상기 메인 모델에 포함되는 신경망 레이어에 입력될, 상기 깊이 이미지에 관련된 적어도 하나의 피처 맵을 출력하는 제2 서브 모델로 구성되는 것인, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 빛 반사 제거 모델은,상기 메인 모델, 상기 제1 서브 모델, 상기 제2 서브 모델에 포함되는 복수의 신경망 레이어들 중 적어도 일부에서, 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지로부터 추출된 특징 맵을 공유하는 것인, 방법.공개특허 10-2023-0007807-4-청구항 10 제5항에 있어서, 상기 빛 반사 제거 모델로부터 출력되는 빛 반사가 제거된 이미지들 및 빛 반사가 없는 다른 이미지들을 이용하여, 빛 반사가 없는 이미지를 판별하는 모델을 학습하는 단계; 및상기 학습된, 빛 반사가 없는 이미지를 판별하는 모델의 손실 함수에 기초하여, 상기 빛 반사 제거 모델을 업데이트하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "이미지를 처리하는 전자 장치에 있어서,카메라 모듈;하나 이상의 명령어들(instructions)을 저장하는 메모리; 및상기 메모리에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는,상기 카메라 모듈을 제어하여, 피사체를 촬영하여 제1 이미지를 획득하고,상기 카메라 모듈을 제어하여, 상기 전자 장치로부터 상기 피사체까지의 거리에 관련된 정보를 포함하는, 깊이이미지를 획득하고,상기 제1 이미지에 빛 반사가 존재하는지 여부를 식별하고,상기 제1 이미지에 빛 반사가 존재하는 경우, 상기 전자 장치로부터 상기 피사체까지의 거리를 나타내는 깊이정보를 획득하고,상기 획득된 깊이 정보에 기초하여, 상기 전자 장치의 플래시가 활성화된 상태에서 상기 피사체를 촬영함으로써제2 이미지를 획득하고,상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 각각을 정합하여 하나의 좌표계에 나타내기 위한 전처리를 수행하고,상기 전처리가 수행된 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 중 적어도 하나를 이용하여, 빛반사가 제거된 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 깊이 정보를 임계값과 비교하여, 상기 전자 장치의 상기 플래시를 활성화할지 여부를 결정하는, 전자장치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 깊이 정보를 상기 임계값과 비교한 결과, 상기 깊이 정보가 상기 임계값 미만인 경우, 상기 카메라 모듈을이용하여, 상기 플래시가 활성화된 상태에서 상기 피사체를 촬영함으로써 상기 제2 이미지를 획득하는, 전자 장치.공개특허 10-2023-0007807-5-청구항 14 제13항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지를 빛 반사 제거 모델에 적용하여, 상기 빛 반사가 제거된 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 깊이 정보를 상기 임계값과 비교한 결과, 상기 깊이 정보가 상기 임계값 이상인 경우, 상기 전자 장치의상기 플래시를 비활성화하고,상기 전처리가 수행된 상기 제1 이미지 및 상기 전처리가 수행된 상기 깊이 이미지만을 이용하여, 상기 빛 반사가 제거된 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지를 공통의 이미지 평면에 투영시키고, 상기 제1 이미지의 제1 픽셀들, 상기 제2 이미지의 제2 픽셀들, 상기 깊이 이미지의 제3 픽셀들을 정합시키며,상기 제1 이미지의 제1 픽셀들, 상기 제2 이미지의 제2 픽셀들 및 상기 깊이 이미지의 제3 픽셀들 각각에 대하여, 각각의 이미지들 내 픽셀들의 밝기가 균일해지도록 캘리브레이션을 수행하는, 전자 장치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 빛 반사 제거 모델은,상기 제1 이미지를 입력 받아, 상기 빛 반사가 제거된 이미지를 출력하는 메인 모델;상기 제2 이미지를 입력 받아, 상기 메인 모델에 포함되는 신경망 레이어에 입력될, 상기 제2 이미지에 관련된적어도 하나의 피처 맵을 출력하는 제1 서브 모델;상기 깊이 이미지를 입력 받아, 상기 메인 모델에 포함되는 신경망 레이어에 입력될, 상기 깊이 이미지에 관련된 적어도 하나의 피처 맵을 출력하는 제2 서브 모델로 구성되는 것인, 전자 장치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 빛 반사 제거 모델은,상기 메인 모델, 상기 제1 서브 모델, 상기 제2 서브 모델에 포함되는 복수의 신경망 레이어들 중 적어도 일부에서, 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지로부터 추출된 특징 맵을 공유하는 것인, 전자 장공개특허 10-2023-0007807-6-치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서,상기 적어도 하나의 프로세서는,상기 빛 반사 제거 모델로부터 출력되는 빛 반사가 제거된 이미지들 및 빛 반사가 없는 다른 이미지들을 이용하여, 빛 반사가 없는 이미지를 판별하는 모델을 학습하고,상기 학습된, 빛 반사가 없는 이미지를 판별하는 모델의 손실 함수에 기초하여, 상기 빛 반사 제거 모델을 업데이트하는, 전자 장치."}
{"patent_id": "10-2021-0088572", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2021-0088572", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "피사체를 촬영하여 제1 이미지를 획득하는 단계; 상기 전자 장치로부터 상기 피사체까지의 거리에 관련된 정보를 포함하는, 깊이 이미지를 획득하는 단계; 상기 제1 이미지에 빛 반사가 존재하는지 여부를 식별하는 단계; 상기 제1 이미지에 빛 반사가 존재하는 경우, 상기 전자 장치로부터 상기 피사체까지의 거리를 나타내는 깊이 정보를 획득하는 단계; 상기 획득된 깊이 정보에 기초하여, 상기 전자 장치의 플래시가 활성화된 상태에서 상기 피사체 를 촬영함으로써 제2 이미지를 획득하는 단계; 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 각각을 정합하여 하나의 좌표계에 나타내기 위한 전처리를 수행하는 단계; 상기 전처리가 수행된 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 중 적어도 하나를 이용하여, 빛 반사가 제거된 이미지를 획득하는 단계를 포함 하는, 전자 장치가 이미지를 처리하는 방법이 제공된다."}
{"patent_id": "10-2021-0088572", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 실시예들은, 이미지 프로세싱을 수행하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0088572", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 장치가 사진을 촬영하기 위한 촬영 수단으로써 RGB 카메라, 깊이 카메라 등의 카메라 인터페이스가 제공되 고 있다. 전자 장치는 카메라를 이용하여 피사체를 촬영하고, 촬영된 이미지에 이미지 프로세싱을 수행하여 노 이즈 등을 제거함으로써, 사용자에게 개선된 카메라 사용 경험을 제공할 수 있다. 전자 장치의 사용자가 피사체를 촬영하는 경우, 피사체 이외의 다른 물질(예를 들어, 유리 등)로부터 반사된 빛 이 카메라에 입사됨으로써, 촬영된 이미지에 빛 반사로 인한 노이즈가 존재할 수 있으며, 이를 제거하는 것이 필요하다. 이에 따라, 이미지 내의 빛 반사로 인한 노이즈를 제거하기 위한 구체적인 이미지 프로세싱 방법을 제시하고자 한다."}
{"patent_id": "10-2021-0088572", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은, 전술한 문제를 해결하기 위한 것으로서, 이미지 내에서 빛 반사로 인한 노이즈를 제거하는 전자 장치 및 그 동작 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2021-0088572", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 전자 장치가 이미지를 처리하 는 방법에 있어서, 피사체를 촬영하여 제1 이미지를 획득하는 단계; 상기 전자 장치로부터 상기 피사체까지의 거리에 관련된 정보를 포함하는, 깊이 이미지를 획득하는 단계; 상기 제1 이미지에 빛 반사가 존재하는지 여부 를 식별하는 단계; 상기 제1 이미지에 빛 반사가 존재하는 경우, 상기 전자 장치로부터 상기 피사체까지의 거리 를 나타내는 깊이 정보를 획득하는 단계; 상기 획득된 깊이 정보에 기초하여, 상기 전자 장치의 플래시가 활성 화된 상태에서 상기 피사체를 촬영함으로써 제2 이미지를 획득하는 단계; 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 각각을 정합하여 하나의 좌표계에 나타내기 위한 전처리를 수행하는 단계; 상기 전처리가 수 행된 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 중 적어도 하나를 이용하여, 빛 반사가 제거된 이미지를 획득하는 단계를 포함하는, 방법을 제공할 수 있다. 또한, 본 개시의 제2 측면은, 이미지를 처리하는 전자 장치에 있어서, 카메라 모듈; 하나 이상의 명령어들 (instructions)을 저장하는 메모리; 및 상기 메모리에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는, 상기 카메라 모듈을 제어하여, 피사체를 촬영하여 제1 이미지를 획득하고, 상기 카메라 모듈을 제어하여, 상기 전자 장치로부터 상기 피사체까지의 거리에 관련된 정 보를 포함하는, 깊이 이미지를 획득하고, 상기 제1 이미지에 빛 반사가 존재하는지 여부를 식별하고, 상기 제1 이미지에 빛 반사가 존재하는 경우, 상기 전자 장치로부터 상기 피사체까지의 거리를 나타내는 깊이 정보를 획 득하고, 상기 획득된 깊이 정보에 기초하여, 상기 전자 장치의 플래시가 활성화된 상태에서 상기 피사체를 촬영 함으로써 제2 이미지를 획득하고, 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 각각을 정합하여 하 나의 좌표계에 나타내기 위한 전처리를 수행하고, 상기 전처리가 수행된 상기 제1 이미지, 상기 제2 이미지 및 상기 깊이 이미지 중 적어도 하나를 이용하여, 빛 반사가 제거된 이미지를 획득하는, 전자 장치를 제공할 수 있 다. 또한, 본 개시의 제3 측면은, 제1 측면의 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 제공할 수 있 다."}
{"patent_id": "10-2021-0088572", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하는 방법을 개략적으로 설명하기 위한 도면이다. 도 1을 참조하면, 일 실시예에 따른 전자 장치는 다양한 방식으로 피사체를 촬영함으로써 복수 타입의 이 미지들을 획득하고, 획득된 이미지들에 기초하여 빛 반사가 제거된 이미지를 획득할 수 있다. 일 실시예에 따른 전자 장치는 카메라를 이용하여 피사체를 촬영할 수 있는 디바이스일 수 있다. 예를 들 어, 전자 장치는 스마트폰, 태블릿 PC, 노트북 PC, 데스크탑 PC, TV 등의 디바이스일 수 있으나, 이에 한 정되지 않는다. 일 실시예에서, 전자 장치는 복수의 카메라로 구성되는 카메라 모듈을 포함할 수 있다. 카메라 모듈은 깊 이 이미지를 획득하는 깊이 카메라, RGB 이미지를 획득하는 RGB 카메라를 포함할 수 있다. 전자 장치는 카메라 모듈을 이용하여 복수 타입의 이미지들을 획득할 수 있다. 예를 들어, 전자 장치는 RGB 카메라를 이용하여 제1 이미지 및 제2 이미지를 획득할 수 있다. 이 경우, 제1 이미지는 플래시 없이 피 사체를 촬영함으로써 획득된 이미지일 수 있다. 또한, 제2 이미지는 플래시를 이용하여 피사체를 촬영함으 로써 획득된 이미지일 수 있다. 또한, 전자 장치는 깊이 카메라를 이용하여 깊이 이미지를 획득할 수 있다. 일 실시예에서, 전자 장치는 사용자가 피사체를 촬영하기 위해 전자 장치를 조작하는 사용자 입력 에 기초하여, 피사체를 촬영하고, 이미지를 획득할 수 있다. 이하에서는, 전자 장치가 피사체를 촬영하여 획득한 이미지는, 전자 장치의 플래시가 비활성화된 상태로 피사체를 촬영하여 획득한 제1 이미지 (이하, 제1 이미지)를 기준으로 설명하기로 한다. 일 실시예에서 전자 장치 카메라 모듈을 이용하여 피사체를 촬영하는 경우, 전자 장치와 피사체 사 이의 투명한 매질이 존재함으로 인해, 제1 이미지 내에 빛 반사가 있을 수 있다. 또는, 피사체 주변의 다른 물 체로부터 반사된 빛이 카메라에 입사됨으로써, 제1 이미지 내에 빛 반사가 있을 수 있다. 따라서, 전자 장치 는 피사체를 촬영한 이미지에서 빛 반사로 인한 노이즈를 제거하기 위하여, 플래시를 이용하여 피사체를 촬영함으로써 획득된 제2 이미지(이하, 제2 이미지) 및 깊이 이미지를 획득할 수 있다.일 실시예에서, 전자 장치는 제1 이미지에 빛 반사가 존재하는지 여부를 식별할 수 있다. 제1 이미 지에 빛 반사가 존재하는 것으로 식별되는 경우, 전자 장치는 제2 이미지 및 깊이 이미지(10 6)를 이용하여 제1 이미지에서 빛 반사를 제거할 수 있다. 일 실시예에 따른 전자 장치는 제1 이미지, 제2 이미지 깊이 이미지 각각에 소정의 전처 리를 수행할 수 있다. 전자 장치는 전처리된 이미지들을 이용하여, 후술하는 실시예들에 따른 이미지 처 리 방법을 수행함으로써 빛 반사가 제거된 이미지를 획득할 수 있다. 도 2는 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하기 위해 이용하는 복수의 모듈들의 동 작들을 설명하기 도면이다. 일 실시예에서, 전자 장치는 카메라 모듈을 이용하여 제1 이미지 및 깊이 이미지를 획득 할 수 있다. 카메라 모듈은 복수의 카메라 및 플래시를 포함할 수 있으며, 복수의 카메라는 서로 다른 유 형의 카메라일 수 있다. 예를 들어, 전자 장치는 RGB 카메라를 이용하여 제1 이미지를 획득할 수 있 고, 깊이 카메라를 이용하여 깊이 이미지를 획득할 수 있다. 전자 장치는 획득한 제1 이미지 및 깊이 이미지를 빛 반사 검출 모듈 및 깊이 센싱 모듈을 이용하여 분석할 수 있다. 일 실시예에서, 전자 장치는 빛 반사 검출 모듈을 이용하여, 제1 이미지를 분석하고, 제1 이미 지 내에 빛 반사가 존재하는지 여부를 나타내는 빛 반사 정보를 획득할 수 있다. 예를 들어, 전자 장치 는 제1 이미지를 빛 반사 검출 모델에 적용하여, 제1 이미지 내에 빛 반사가 존재하는지 여부 를 검출할 수 있다. 이에 대하여는 도 3에 대한 설명에서 더 서술하기로 한다. 전자 장치는 제1 이미지에 빛 반사가 존재하는 경우, 깊이 센싱 모듈을 이용하여, 깊이 이미지(20 4)를 분석하고, 전자 장치로부터 피사체까지의 거리를 나타내는 깊이 정보를 획득할 수 있다. 예를 들어, 전자 장치는 Time-Of-flight 방식의 깊이 센싱 알고리즘을 이용하여, 깊이 정보를 획득할 수 있다. 이에 대하여는 도 4에 대한 설명에서 더 서술하기로 한다. 일 실시예에서, 전자 장치는 빛 반사 검출 모듈을 이용하여 획득된 빛 반사 정보에 기초하여, 빛 반 사가 제거된 이미지를 생성할 지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 빛 반사 정보에 기초하여, 제1 이미지에 빛 반사가 존재하는 것으로 판단되는 경우, 개시된 실시예들에 따른 전자 장치 가 빛 반사를 제거하기 위한 동작들을 수행할 수 있다. 일 실시예에서, 전자 장치는 깊이 센싱 모듈을 이용하여 전자 장치로부터 피사체까지의 거리 를 나타내는 깊이 정보를 획득할 수 있다. 전자 장치는 깊이 정보에 기초하여, 전자 장치의 카메라 모듈에 포함되는 플래시를 활성화할 지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 깊이 정보 에 기초하여, 전자 장치로부터 피사체까지의 거리가 임계값 미만인 경우, 플래시를 활성화하고 피사체를 촬영함으로써 제2 이미지를 획득할 수 있다. 전자 장치가 피사체까지의 거리에 기초하여 플래시를 활성화 하고 제2 이미지를 획득할 지 여부를 결정하는 방법에 대하여는 도 5에 대한 설명에서 더 서술하기로 한다. 일 실시예에서, 전자 장치는 이미지 전처리 모듈을 이용하여, 제1 이미지, 깊이 이미지 및 제2 이미지에 전처리를 수행할 수 있다. 예를 들어, 전자 장치는 제1 이미지, 깊이 이미지 및 제2 이미지를 이용하여 빛 반사가 제거된 이미지를 생성하기 위해, 제1 이미지, 깊이 이미지 및 제2 이미지를 정합하여 하나의 좌표계에 나타내기 위한 전처리를 수행할 수 있다. 전자 장 치가 제1 이미지, 깊이 이미지 및 제2 이미지에 전처리를 수행하는 방법은, 도 6에 대한 설명에서 더 서술하기로 한다. 일 실시예에서, 전자 장치는 이미지 처리 모듈을 이용하여, 빛 반사가 제거된 이미지를 생성할 수 있다. 이 경우, 이미지 처리 모듈은 제1 이미지, 깊이 이미지, 제2 이미지를 입력 받아, 빛 반사가 제거된 이미지를 출력할 수 있다. 이미지 처리 모듈은 하나 이상의 인공지능 모델을 포함할 수 있다. 예를 들어, 이미지 처리 모듈은 메인 모델, 제1 서브 모델, 제2 서브 모델 의 조합으로 구성되는 하나의 인공지능 모델인, 빛 반사 제거 모델을 포함할 수 있다. 다른 예에서, 이미 지 처리 모듈은 메인 모델, 제1 서브 모델, 제2 서브 모델 각각으로 구성되는 복수의 인공 지능 모델을 포함할 수 있다. 일 실시예에서, 메인 모델은 제1 이미지를 입력 받아, 빛 반사가 제거된 이미지를 출력하는 인 공지능 모델일 수 있다. 메인 모델은 하나 이상의 신경망 레이어를 포함할 수 있다.일 실시예에서, 제1 서브 모델은 깊이 이미지를 입력 받아, 깊이 이미지로부터 획득된 피처 맵 을 출력하는 인공지능 모델일 수 있다. 제1 서브 모델은 하나 이상의 신경망 레이어를 포함할 수 있다. 일 실시예에서, 제2 서브 모델은 제2 이미지를 입력 받아, 제2 이미지로부터 획득된 피처 맵을 출력하는 인공지능 모델일 수 있다. 제2 서브 모델은 하나 이상의 신경망 레이어를 포함할 수 있다. 일 실시예에 따른 전자 장치는 이미지 처리 모듈을 이용하여, 제1 이미지, 깊이 이미지 및 제2 이미지를 융합함으로써 빛 반사가 제거된 이미지를 생성할 수 있다. 이에 대하여는, 도 7 내 지 도 11에 대한 설명에서 더 서술하기로 한다. 도 3은 일 실시예에 따른 전자 장치가 촬영한 이미지에 빛 반사가 존재하는지 여부를 검출하는 방법을 설명하기 위한 도면이다. 도 3을 참조하여, 도 2에서 전술한 빛 반사 검출 모듈의 동작을 보다 상세하게 설명하기로 한다. 일 실시예에서, 빛 반사 검출 모듈은 빛 반사 검출 모델을 포함할 수 있다. 개시된 실시예에서, 빛 반사 검출 모델은, 컨볼루션 연산을 수행하는 하나 이상의 컨볼루션 레이어 및 인접한 레이어 간 노드들을 완전 연결하는 하나 이상의 완전 연결 레이어를 포함하는 인공지능 모델일 수 있다. 빛 반사 검출 모델은 입력된 이미지에 빛 반사가 존재하는지 여부를 검출하기 위하여, 학습 데이터셋 (training dataset)에 기초하여 학습된(trained) 인공지능 모델일 수 있다. 이 경우, 학습 데이터셋은 빛 반사 를 포함하는 이미지와 빛 반사를 포함하지 않는 이미지들로 구성되는 데이터셋일 수 있다. 또한, 학습 데이터셋 에 포함되는 이미지들은 각각의 이미지가 빛 반사를 포함하는지 여부를 나타내는, 트루 레이블 값이 레이블링 된 이미지들일 수 있다. 빛 반사 검출 모델은 이미지가 입력되는 경우, 입력된 이미지에 빛 반사가 존재하는지 여부를 검출할 수 있다. 예를 들어, 빛 반사 검출 모델은 ‘빛 반사 있음’ 또는 ‘빛 반사 없음’의 두 종류의 클래스 중 어느 하나로 입력된 이미지를 분류할 수 있다. 일 실시예에서, 빛 반사 검출 모델은 제1 이미지, 제2 이미지, 깊이 이미지 중 적어도 하나의 이미지를 입 력 받아, 입력된 이미지에 빛 반사가 존재하는지 여부를 나타내는 빛 반사 정보를 출력할 수 있다. 일 실시예에 따른 전자 장치는 빛 반사 검출 모듈로부터 획득되는 빛 반사 정보에 기초하여 빛 반사가 제거된 이미지를 생성할 지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 제1 이미지에 빛 반 사가 존재하는 것으로 판단되는 경우, 개시된 실시예들에 따른, 전자 장치가 빛 반사를 제거하기 위한 동 작들을 수행할 수 있다. 도 4는 일 실시예에 따른 전자 장치가 깊이 정보를 획득하는 방법을 설명하기 위한 도면이다. 도 4를 참조하여, 도 2에서 전술한 깊이 센싱 모듈의 동작을 보다 상세하게 설명하기로 한다. 일 실시예에서, 깊이 센싱 모듈은 깊이 카메라를 이용하여 깊이 정보 및 깊이 이미지를 획 득할 수 있다. 여기서, 깊이 정보는 전자 장치로부터 피사체까지의 거리를 나타내는 정보를 말하며, 깊이 이미지는 전자 장치로부터 피사체까지의 거리들을 픽셀 값의 크기에 대응시킨, 이미지 형태의 데이 터를 말한다. 일 실시예에 따른 깊이 카메라는 깊이 정보를 획득할 수 있는 다양한 방식의 카메라(예를 들어, 스테레오 카메라, 구조광 카메라, Time-of-Flight (ToF) 카메라)일 수 있다. 다만, 깊이 카메라는 이에 한정되지 않 으며, 깊이 정보를 획득할 수 있는 다양한 방식의 카메라가 이용될 수 있다. 일 실시예에서, 깊이 카메라는 Time-of-Flight (ToF) 방식으로 깊이 정보를 획득하는 카메라일 수 있다. 이 경우, 깊이 카메라는 ToF 센서를 이용하여 피사체로부터 반사되는 빛에 따라 축적되는 전하의 양 을 측정하고, 측정된 전하량의 차이를 기초하여 피사체와의 거리를 계산할 수 있다. 예를 들어, ToF 센서는 광 원으로부터 빛이 방출되는 시간 동안(시간 t) 반사된 빛을 수용하여 전하를 축적하는 리셉터 A 및 광원으로부터 빛이 방출되지 않는 시간 동안 반사된 빛을 수용하여 전하를 축적하는 리셉터 B을 포함할 수 있다. 이 경우, 깊이 카메라로부터 피사체까지의 거리(거리 d)를 나타내는 깊이 정보는 아래의 수학식 1을 이용하여 획득될 수 있다.[수학식 1]"}
{"patent_id": "10-2021-0088572", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, c는 빛의 속도, t는 광원으로부터 빛이 방출되는 시간 길이, Q1은 리셉터 A에 축적된 전하의 양, Q2는 리셉터 B에 축적된 전하의 양을 말한다. 일 실시예에서, 깊이 센싱 모듈은 피사체를 촬영하여, 깊이 정보 및 깊이 이미지를 획득할 수 있다. 일 실시예에 따른 전자 장치는 깊이 센싱 모듈로부터 획득되는 깊이 정보에 기초하여, 플래시 를 활성화하여 피사체를 촬영한 제2 이미지를 획득할 지 여부를 결정할 수 있다. 예를 들어, 전자 장치 는 전자 장치로부터 피사체까지의 거리가 임계값 미만인 경우, 플래시를 활성화하고 피사체 를 촬영함으로써 제2 이미지를 획득할 수 있다. 도 5는 일 실시예에 따른 전자 장치가 제2 이미지를 획득할지 여부를 결정하는 방법을 설명하기 위한 도면이다. 일 실시예에 따른 전자 장치는 전술한 실시예들에 따라 획득된 빛 반사 정보 및 깊이 정보에 기초하여, 전자 장치의 플래시를 활성화하고 피사체를 촬영함으로써 제2 이미지를 획득할지 여부를 결정할 수 있다. 도 5를 설명함에 있어서, 빛 반사로 인한 노이즈를 발생시키는 투명 매질은 전자 장치와 피사체 사이에 존재하는 경우를 예로 들어 설명하기로 한다. 그러나, 빛 반사로 인한 노이즈를 발생시키는 투명 매질의 위치가 이에 한정되는 것은 아니다. 빛 반사로 인한 노이즈를 발생시키는 투명 매질은 전자 장치와 피사체 사이 외 다른 위치에 존재할 수 있다. 또한, 투명 매질 외에, 다른 물질이 빛을 반사하여 전자 장치가 피사체 를 촬영할 때 빛 반사로 인한 노이즈를 발생시킬 수 있다. 일 실시예에서, 전자 장치는 플래시가 비활성화된 상태에서 피사체를 촬영하여 제1 이미지를 획득할 수 있다. 이 경우, 전자 장치의 카메라 모듈은 피사체로부터 방출된 빛을 센싱함으로써 피사체를 촬영 한 이미지를 획득한다. 그러나, 전자 장치와 피사체 사이에 투명 매질 존재로 인해, 투명 매질로부 터 반사된 빛 또한 전자 장치의 카메라 모듈에 입사되어, 제1 이미지 내에 빛 반사가 있을 수 있다. 이 경우, 전자 장치는 전술한 실시예들에 따라, 제1 이미지 내에 빛 반사가 존재하는지 여부를 나타내는 빛 반사 정보를 획득할 수 있다. 전자 장치는 빛 반사 정보에 기초하여, 제1 이미지 내에 빛 반사가 존재하는 것으로 판단되는 경우, 빛 반사를 제거하기 위한 동작들을 수행하기 위해 깊이 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 깊이 정보에 기초하여, 전자 장치의 플래시를 활성화할지 여부를 결정 할 수 있다. 전자 장치 획득된 깊이 정보를 임계값과 비교할 수 있다. 예를 들어, 전자 장치가 깊이 정보를 임계값과 비교한 결과 깊이 정보가 임계값 미만인 경우, 전자 장치 가 제1 이미지를 획득할 때 포커스된 피사체는 근거리 포커스된 피사체일 수 있다. 이 경우, 전자 장치와 근거리 포커스된 피사체의 거리가 소정 기준보다 가깝기 때문에, 전자 장치의 플래시 를 활성화하는 경우 개선된 조도 환경에서 근거리 포커스된 피사체의 디테일한 부분들이 촬영될 수 있다. 전자 장치는 플래시를 활성화하여, 플래시가 비춰진 근거리 포커스된 피사체를 촬영한 제2 이미지를 획득할 수 있다. 다른 예에서, 전자 장치가 깊이 정보를 임계값과 비교한 결과 깊이 정보가 임계값 이상인 경우, 전자 장 치가 제1 이미지를 획득할 때 포커스된 피사체는 원거리 포커스된 피사체일 수 있다. 이 경우, 전자 장치와 원거리 포커스된 피사체의 거리가 소정 기준보다 멀기 때문에, 전자 장치의 플래시를 활성화하더라도 조도 환경이 개선되지 않을 수 있다. 따라서, 전자 장치는 플래시를 비활성화하고, 제2 이미지를 획득하지 않을 수 있다. 후술하는 실시예들에서, 제2 이미지가 획득되지 않는 경우, 전자 장치 는 제1 이미지 및 깊이 이미지만을 이용하여 빛 반사가 제거된 이미지를 획득할 수 있다. 다른 예에서, 전자 장치가 깊이 정보를 임계값과 비교한 결과 깊이 정보가 임계값 이상인 경우, 전자 장 치가 제1 이미지를 획득할 때 포커스된 피사체는 원거리 포커스된 피사체일 수 있다. 이 경우, 전자 장치와 원거리 포커스된 피사체의 거리가 소정 기준보다 멀더라도, 전자 장치는 플래시를 활성화하여, 플래시가 비춰진 원거리 포커스된 피사체를 촬영한 제2 이미지를 획득할 수 있다. 이 경우, 전 자 장치가 제1 이미지, 깊이 이미지 및 제2 이미지를 이용하여 빛 반사가 제거된 이미지를 생성할 때, 원 거리 포커스된 피사체를 촬영하여 획득된 제2 이미지는 가중치가 낮게 설정될 수 있다. 일 실시예에 따른 전자 장치는 제2 이미지가 획득된 경우, 제1 이미지, 깊이 이미지 및 제2 이미지를 융 합하기 위해, 제1 이미지, 깊이 이미지 및 제2 이미지에 전처리를 수행할 수 있다. 도 6은 일 실시예에 따른 전자 장치가 이미지에 전처리를 수행하는 방법을 설명하기 위한 흐름도이다. 도 6을 참조하여, 도 2에서 전술한 이미지 전처리 모듈의 동작을 보다 상세하게 설명하기로 한다. 단계 S610에서, 전자 장치는 제1 이미지, 제2 이미지 및 깊이 이미지를 공통의 이미지 평면에 투영시킬 수 있다. 여기서 공통의 이미지 평면이란, 하나의 좌표계에 포함되는 하나의 평면을 말한다. 일 실시예에서, 전자 장치가 획득한 제1 이미지, 제2 이미지 및 깊이 이미지는, 전자 장치의 카메 라 모듈 내 서로 다른 카메라를 이용하여 촬영됨으로써, 서로 다른 시점에서 피사체를 촬영한 이미지일 수 있다. 예를 들어, 제1 이미지 및 제2 이미지는 RGB 카메라를 이용하여 획득되고, 깊이 이미지는 깊이 카메라를 이용하 여 획득된 것일 수 있다. 다른 예에서, 제1 이미지는 제1 RGB 카메라를 이용하여 획득되고, 제2 이미지는 제2 RGB 카메라를 이용하여 획득되고, 깊이 이미지는 깊이 카메라를 이용하여 획득된 것일 수 있다. 전자 장치 는 제1 이미지, 제2 이미지 및 깊이 이미지 각각에 포함되는 픽셀들 중에서, 실제 현실 공간의 동일한 지 점을 나타내는 픽셀을 정합시키기 위하여 제1 이미지, 제2 이미지 및 깊이 이미지를 공통의 이미지 평면에 투영 시킬 수 있다. 이 경우, 전자 장치는 각각의 이미지들을 3차원 공간 상에서 회전시키고, 비틀어서 공통의 이미지 평면에 투영되도록 할 수 있다. 단계 S620에서, 전자 장치는 제1 이미지의 제1 픽셀들, 제2 이미지의 제2 픽셀들, 깊이 이미지의 제3 픽 셀들을 정합시킬 수 있다. 전자 장치는 실제 현실 공간의 동일한 지점을 나타내는 픽셀들인 대응점들을 정합시킬 때, 에피폴라 제약조건(epipolar constraint)을 이용할 수 있다. 전자 장치는 에피폴라 제약 조 건을 이용하여 대응점의 후보군들을 나타내는 에피폴라 라인을 계산하고, 에피폴라 라인을 일치시키는 이미지 렉티피케이션(image rectification)을 수행할 수 있다. 전자 장치는 이미지 렉티피케이션 과정으로 변환 된 이미지들을 비교하여, 현실 공간의 동일한 지점을 나타내는 픽셀들인 대응점들을 검색하고, 검색된 대응점들 을 정합시킬 수 있다. 단계 S630에서, 전자 장치는 제1 이미지의 제1 픽셀들, 제2 이미지의 제2 픽셀들 및 깊이 이미지의 제3 픽셀들 각각에 대하여, 각각의 이미지들 내 픽셀들의 밝기가 균일해지도록 캘리브레이션을 수행할 수 있다. 일 실시예에서, 전자 장치는 전처리가 수행된 제1 이미지, 제2 이미지 및 깊이 이미지를 중 적어도 하나 를 이용하여, 제1 이미지로부터 빛 반사가 제거된 이미지인, 빛 반사가 제거된 이미지를 획득할 수 있다. 도 7은 일 실시예에 따른 전자 장치가 제1 이미지, 제2 이미지 및 깊이 이미지를 이용하여, 빛 반사가 제거된 이미지를 획득하는 방법을 설명하기 위한 도면이다. 도 7을 참조하여, 도 2에서 전술한 이미지 처리 모듈의 동작을 보다 상세하게 설명하기로 한다. 일 실시예에서, 전자 장치는 전술한 실시예들에 따라 전처리된 제1 이미지, 전처리된 깊이 이미지 , 전처리된 제2 이미지를 이미지 처리 모듈에 입력할 수 있다. 일 실시예에서, 이미지 처리 모듈은 하나 이상의 인공지능 모델의 조합으로 구성되는 인공지능 모델인, 빛 반사 제거 모델을 포함할 수 있다. 예를 들어, 이미지 처리 모듈은 메인 모델, 제1 서브 모델 및 제2 서브 모델의 조합으로 구성되는, 빛 반사 제거 모델을 포함할 수 있다. 일 실시예에서, 이미지 처리 모듈은 하나 이상의 인공지능 모델을 포함할 수 있다. 예를 들어, 이미지 처 리 모듈은 메인 모델, 제1 서브 모델 및 제2 서브 모델을 포함할 수 있다. 일 실시예에서, 메인 모델은 제1 이미지를 입력 받아, 빛 반사가 제거된 이미지를 출력하는 인 공지능 모델일 수 있다. 메인 모델은 신경망 레이어들을 포함할 수 있다. 일 실시예에서, 제1 서브 모델은 깊이 이미지를 입력 받아, 깊이 이미지에 관련된 적어도 하나 의 피처 맵을 출력하는 인공지능 모델일 수 있다. 제1 서브 모델은 신경망 레이어들을 포함할 수 있으며,깊이 이미지에 관련된 적어도 하나의 피처 맵은 제1 서브 모델내의 신경망 레이어들 중 적어도 하나 로부터 출력될 수 있다. 일 실시예에서, 제2 서브 모델은 제2 이미지를 입력 받아, 제2 이미지에 관련된 적어도 하나의 피처 맵을 출력하는 인공지능 모델일 수 있다. 제2 서브 모델은 신경망 레이어들을 포함할 수 있으며, 제2 이미지에 관련된 적어도 하나의 피처 맵은 제2 서브 모델내의 신경망 레이어들 중 적어도 하나로부터 출력될 수 있다. 또한, 개시된 실시예에서, 메인 모델, 제1 서브 모델, 제2 서브 모델 각각에 포함되는 신경망 레이어들 중 적어도 일부에서, 신경망 레이어로부터 출력되는 피처 맵이 공유될 수 있다. 예를 들어, 제1 서브 모델에 포함되는 신경망 레이어들 중 적어도 일부에서 출력되는 피처 맵이 메인 모델 로 공유될 수 있다. 이 경우, 제1 서브 모델에 포함되는 적어도 하나의 신경망 레이어로부터 출력된 피처 맵은, 메인 모델에 포함되는 적어도 하나의 신경망 레이어에 입력 데이터로써 입력될 수 있다. 또한, 제2 서브 모델에 포함되는 신경망 레이어들 중 적어도 일부에서 출력되는 피처 맵이 메인 모델(72 2)로 공유될 수 있다. 이 경우, 제2 서브 모델에 포함되는 적어도 하나의 신경망 레이어로부터 출력된 피 처 맵은, 메인 모델에 포함되는 적어도 하나의 신경망 레이어에 입력 데이터로써 입력될 수 있다. 이미지 처리 모듈에 포함되는 메인 모델, 제1 서브 모델, 제2 서브 모델이 피처 맵을 공유 하는 구체적인 네트워크 구조는, 도 8 및 도 9를 참조하여 더 서술하기로 한다. 도 8은 일 실시예에 따른 전자 장치가 이용하는, 빛 반사가 제거된 이미지를 생성하는 빛 반사 제거 모델의 네 트워크 구조를 설명하기 위한 도면이다. 일 실시예에서, 빛 반사 제거 모델은, 전처리된 제1 이미지, 전처리된 깊이 이미지, 전처리된 제2 이 미지를 입력 받아, 빛 반사가 제거된 이미지를 출력하는 뉴럴 네트워크일 수 있다. 또한, 빛 반사 제 거 모델은, 하나 이상의 뉴럴 네트워크의 조합으로 구성될 수 있다. 예를 들어, 빛 반사 제거 모델은, 메인 모 델, 제1 서브 모델 및 제2 서브 모델로 구성될 수 있다. 메인 모델, 제1 서브 모델 및 제2 서브 모델 각각은 복수의 신경망 레이어를 포함할 수 있으며, 복수의 신경망 레이어를 이용하여 컨 볼루션 연산 또는 디컨볼루션 연산을 수행할 수 있다. 일 실시예에서, 메인 모델, 제1 서브 모델 및 제2 서브 모델은 피처 맵을 공유할 수 있다. 구체 적으로, 제1 서브 모델의 적어도 일부의 신경망 레이어로부터 출력되는 피처 맵 및 제2 서브 모델의 적어도 일부의 신경망 레이어로부터 출력되는 피처 맵이 메인 모델로 공유될 수 있다. 일 실시예에서, 메인 모델은 덧셈 레이어를 포함할 수 있다. 예를 들어, 메인 모델은 네트워크의 i번째 레벨에 제1 덧셈 레이어 및 제2 덧셈 레이어를 포함 할 수 있다. 이 경우, 제1 덧셈 레이어는 제2 서브 모델의 i번째 레벨의 레이어로부터 출력되는 피처맵의 덧셈을 수행할 수 있다. 또한, 제2 덧셈 레이어는 제1 서브 모델의 i번째 레벨의 레이어 로부터 출력되는 피처맵의 덧셈을 수행할 수 있다. 같은 방식으로, 메인 모델은 네트워크의 j번째 레벨에 제3 덧셈 레이어 및 제4 덧셈 레이어를 포함할 수 있다. 이 경우, 제3 덧셈 레이어는 제2 서브 모델의 j번째 레벨의 레이어로부터 출력 되는 피처맵의 덧셈을 수행할 수 있다. 또한, 제4 덧셈 레이어는 제1 서브 모델의 j번째 레벨의 레이 어로부터 출력되는 피처맵의 덧셈을 수행할 수 있다. 일 실시예에 따른 전자 장치는 메인 모델에 포함되는 덧셈 레이어들을 이용하여, 제1 이미지, 깊이 이미지 및 제2 이미지를 융합함으로써 빛 반사가 제거된 이미지를 생성할 수 있다. 도 9는 일 실시예에 따른 전자 장치가 이용하는, 빛 반사가 제거된 이미지를 생성하는 빛 반사 제거 모델의 다 른 네트워크 구조를 설명하기 위한 도면이다. 도 9의 블록 900은 빛 반사가 제거된 이미지를 출력하는 빛 반사 제거 모델의 뉴럴 네트워크의 일부를 도시한 것이다. 도 9를 참조하면, 빛 반사가 제거된 이미지를 출력하는 빛 반사 제거 모델은, 하나 이상의 뉴럴 네트워크의 조 합으로 구성될 수 있다. 예를 들어, 빛 반사 제거 모델은, 메인 모델, 제1 서브 모델 및 제2 서브 모델로 구성될 수 있다. 메인 모델, 제1 서브 모델 및 제2 서브 모델 각각은 복수의 신경망 레이어를 포함할 수 있으며, 복수의 신경망 레이어를 이용하여 컨볼루션 연산 또는 디컨볼루션 연산을 수행할 수 있다. 또한, 빛 반사가 제거된 이미지를 출력하는 뉴럴 네트워크는, 하나 이상의 덧셈 레이어를 포함할 수 있다. 예를 들어, 빛 반사가 제거된 이미지를 출력하는 뉴럴 네트워크는, 제1 덧셈 레이어, 제2 덧셈 레이 어, 제3 덧셈 레이어, 제4 덧셈 레이어를 포함할 수 있다. 일 실시예에서, 메인 모델, 제1 서브 모델 및 제2 서브 모델에 포함되는 적어도 일부의 신경망 레이어로부터 출력되는 피처 맵의 부분 합이 획득될 수 있다. 예를 들어, 제1 덧셈 레이어는, 메인 모델의 i번째 레벨의 레이어로부터 출력되는 피처맵, 제1 서브 모델의 i번째 레벨의 레이어로부터 출력되는 피처맵 및 제2 서브 모델의 i번째 레벨의 레 이어로부터 출력되는 피처맵의 덧셈을 수행함으로써, 부분합 A를 출력할 수 있다. 또한, 제2 덧셈 레이어는 메인 모델의 k번째 레벨의 레이어로부터 출력되는 피처맵, 제1 서브 모델의 k번째 레벨의 레이어로부터 출력되는 피처맵 및 제2 서브 모델의 k번째 레벨의 레이어 로부터 출력되는 피처맵의 덧셈을 수행함으로써, 부분합 B를 출력할 수 있다. 또한, 제3 덧셈 레이어는, 메인 모델의 n번째 레벨의 레이어로부터 출력되는 피처맵, 제1 서브 모델의 n번째 레벨의 레이어로부터 출력되는 피처맵 및 제2 서브 모델의 n번째 레벨의 레이어 로부터 출력되는 피처맵의 덧셈을 수행함으로써, 부분합 C를 출력할 수 있다. 또한, 제4 덧셈 레이어는, 부분합 A, 부분합 B 및 부분합 C의 덧셈을 수행함으로써, 전체 합을 출력할 수 있다. 이 경우, 부분합 A의 배치(batch) 사이즈는, 부분합 C의 배치 사이즈보다 작을 수 있다. 일 실시예에 서, 부분합 A는 부분합 A의 배치 사이즈가 부분합 C의 배치 사이즈에 일치되도록 업샘플링될 수 있다. 업샘플링 된 부분합 A는 제4 덧셈 레이어로 입력될 수 있다. 또한, 부분합 B의 배치 사이즈는 부분합 C의 배치 사이즈보다 작을 수 있다. 일 실시예에서, 부분합 B는 부분합 B의 배치 사이즈가 부분합 C의 배치 사이즈에 일치되도록 업샘플링 될 수 있다. 업 샘플링 된 부분합 B는 제4 덧셈 레이어로 입력될 수 있다. 일 실시예에 따른 전자 장치는 빛 반사가 제거된 이미지를 출력하는 빛 반사 제거 모델에 포함되는 덧셈 레이어들을 이용하여, 제1 이미지, 깊이 이미지 및 제2 이미지를 융합함으로써 빛 반사가 제거된 이미지를 생성 할 수 있다. 도 10은 일 실시예에 따른 전자 장치가 제1 이미지, 깊이 이미지 및 제2 이미지를 이용하여 빛 반사가 제거된 이미지를 획득하는 예를 설명하기 위한 도면이다. 도 10을 참조하면, 전술한 실시예들에 따라 깊이 이미지, 제1 이미지 및 제2 이미지 각각에 전처리가 수행될 수 있다. 이에 따라, 제1 이미지의 제1 픽셀들, 제2 이미지의 제2 픽셀들, 깊이 이미지의 제3 픽셀들이 정합되어 있을 수 있다. 일 실시예에 따른 전자 장치는 깊이 이미지, 제1 이미지 및 제2 이미지중 적어도 일부 를 이용하여, 빛 반사가 제거된 이미지를 생성할 수 있다. 이하에서는, 설명의 편의를 위하여 이미지 내 픽셀들이 정합된 제1 이미지, 제2 이미지 및 깊이 이미지의 일부 영역을 기준으로, 제1 이미지, 제2 이미지 및 깊이 이미지를 융합함으로써 빛 반사가 제거된 이미지가 생 성되는 실시예를 설명하기로 한다. 일 실시예에서, 전자 장치는 이미지 처리 모듈을 이용하여 깊이 이미지의 일부 영역, 제1 이 미지의 일부 영역, 제2 이미지의 일부 영역을 융합함으로써, 빛 반사가 제거된 이미지의 일부 영역 을 획득할 수 있다. 이 경우, 깊이 이미지의 일부 영역에 포함되는 픽셀들은, 전자 장치로부 터 피사체까지의 거리가 가까울수록 큰 픽셀 값을 가질 수 있다. 또한, 제1 이미지의 일부 영역에 포함되 는 픽셀들은, 피사체에 조사된 광량이 낮음으로 인해 피사체의 디테일한 부분들의 픽셀 값들의 대비가 낮을 수 있다. 또한, 제2 이미지의 일부 영역에 포함되는 픽셀들은, 플래시를 활성화한 상태에서 피사체를 촬영함 으로써, 피사체에 조사된 광량이 높아 피사체의 디테일한 부분들의 픽셀 값들의 대비가 높을 수 있으나, 플래시 로 인해 그림자가 제2 이미지의 일부 영역 내에 존재할 수 있다.일 실시예에서, 전자 장치는 이미지 처리 모듈을 이용하여, 깊이 이미지의 일부 영역, 제1 이 미지의 일부 영역, 제2 이미지의 일부 영역을 융합시킴으로써, 빛 반사가 없고, 피사체의 디테일한 부분들의 대비가 선명한 픽셀들로 구성되는, 빛 반사가 제거된 이미지의 일부 영역을 획득할 수 있다. 다른 실시예에서, 전자 장치는 제2 이미지 내에 빛 반사가 소정 기준 이상 존재하는 영역을 식별할 수 있다. 전자 장치는 이미지 내의 빛 반사 정도에 기초하여, 빛 반사가 제거된 이미지를 생성하기 위하 여 사용될 이미지를 결정할 수 있다. 예를 들어, 전자 장치는 제2 이미지의 일부 영역에 빛 반사가 소정 기준 미만임을 식별하고, 빛 반사가 제거된 이미지의 일부 영역을 생성하기 위해 사용될 이미지들로, 깊이 이미지의 일부 영역, 제1 이미지의 일부 영역, 제2 이미지의 일부 영역을 선택할 수 있다. 다른 예에서, 전자 장치는 제2 이미지의 일부 영역에 빛 반사가 소정 기준 미만임 을 식별하고, 빛 반사가 제거된 이미지의 일부 영역을 생성하기 위해 사용될 이미지들로 제1 이미지의 일 부 영역, 제2 이미지의 일부 영역을 선택할 수 있다. 전자 장치는, 빛 반사가 제거된 이미지 의 일부 영역을 생성하기 위해 사용될 이미지들로 제1 이미지의 일부 영역, 제2 이미지의 일부 영 역을 선택되면, 이미지 처리 모듈을 이용하여, 제1 이미지의 일부 영역, 제2 이미지의 일부 영역을 융합시킴으로써, 빛 반사가 제거된 이미지의 일부 영역을 획득할 수 있다. 일 실시예에 따른 전자 장치는 이미지 처리 모듈을 이용하여, 메인 모델, 제1 서브 모델 및 제2 서 브 모델에 포함되는 컨볼루션 레이어들 중 적어도 일부에서, 제1 이미지, 깊이 이미지 및 제2 이미지로부터 추 출된 특징 맵을 공유하고, 제1 이미지, 깊이 이미지 및 제1 이미지를 융합함으로써 빛 반사가 제거된 이미지를 생성할 수 있다. 도 11은 일 실시예에 따른 전자 장치가 제1 이미지, 깊이 이미지 및 제2 이미지를 이용하여 빛 반사가 제거된 이미지를 획득하는 다른 예를 설명하기 위한 도면이다. 도 11을 참조하면, 전술한 실시예들에 따라 깊이 이미지, 제1 이미지 및 제2 이미지 각각에 전처리가 수행될 수 있다. 이에 따라, 제1 이미지의 제1 픽셀들, 제2 이미지의 제2 픽셀들, 깊이 이미지의 제3 픽셀들이 정합되어 있을 수 있다. 일 실시예에 따른 전자 장치는 깊이 이미지, 제1 이미지 및 제2 이미지중 적어도 일부 를 이용하여, 빛 반사가 제거된 이미지를 생성할 수 있다. 이하에서는, 설명의 편의를 위하여 이미지 내 픽셀들이 정합된 제1 이미지, 제2 이미지 및 깊이 이미지의 일부 영역을 기준으로, 제1 이미지, 제2 이미지 및 깊이 이미지를 융합함으로써 빛 반사가 제거된 이미지가 생 성되는 실시예를 설명하기로 한다. 일 실시예에서, 전자 장치는 이미지 처리 모듈을 이용하여 깊이 이미지의 일부 영역, 제1 이 미지의 일부 영역, 제2 이미지의 일부 영역을 융합함으로써, 빛 반사가 제거된 이미지의 일부 영역 을 획득할 수 있다. 이 경우, 깊이 이미지의 일부 영역에 포함되는 픽셀들은, 전자 장치로부 터 피사체까지의 거리가 가까울수록 큰 픽셀 값을 가질 수 있다. 또한, 제1 이미지의 일부 영역에 포함되 는 픽셀들은, 피사체에 조사된 광량이 낮음으로 인해 피사체의 디테일한 부분들의 픽셀 값들의 대비가 낮을 수 있다. 또한, 제2 이미지의 일부 영역에 포함되는 픽셀들은, 플래시를 활성화한 상태에서 피사체를 촬영함 으로써, 플래시로 인한 노이즈가 존재할 수 있다. 일 실시예에 따른 전자 장치는 이미지 처리 모듈을 이용하여, 깊이 이미지의 일부 영역, 제1 이미지의 일부 영역, 제2 이미지의 일부 영역을 융합시킴으로써, 빛 반사가 없고, 피사체의 디테일 한 부분들의 대비가 선명한 픽셀들로 구성되는, 빛 반사가 제거된 이미지의 일부 영역을 획득할 수 있다. 다른 실시예에서, 전자 장치는 제2 이미지 내에 빛 반사가 소정 기준 이상 존재하는 영역을 식별할 수 있다. 전자 장치는 이미지 내의 빛 반사 정도에 기초하여, 빛 반사가 제거된 이미지를 생성하기 위하 여 사용될 이미지를 결정할 수 있다. 예를 들어, 전자 장치는 제2 이미지의 일부 영역에 빛 반사가 소정 기준 이상임을 식별할 수 있다. 이 경우, 제2 이미지의 일부 영역 내에 빛 반사가 소정 기준 이상인 영역은 플래시로 인한 노이즈가 존재할 수 있다. 전자 장치는 빛 반사가 제거된 이미지의 일부 영 역을 생성하기 위해 사용될 이미지들로, 깊이 이미지의 일부 영역, 제1 이미지의 일부 영역 만을 선택할 수 있다. 전자 장치는, 빛 반사가 제거된 이미지의 일부 영역을 생성하기 위해 사용될 이미지들로 깊이 이미지의 일부 영역, 제1 이미지의 일부 영역만이 선택되면, 이미지 처리 모듈 을 이용하여, 깊이 이미지의 일부 영역, 제1 이미지의 일부 영역을 융합시킴으로써, 빛 반사가 제거된 이미지의 일부 영역을 획득할 수 있다. 일 실시예에 따른 전자 장치는 이미지 처리 모듈을 이용하여, 메인 모델, 제1 서브 모델 및 제2 서 브 모델에 포함되는 컨볼루션 레이어들 중 적어도 일부에서, 제1 이미지, 깊이 이미지 및 제2 이미지로부터 추 출된 특징 맵을 공유하고, 제1 이미지, 깊이 이미지 및 제1 이미지를 융합함으로써 빛 반사가 제거된 이미지를 생성할 수 있다. 도 12는 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하는 방법을 도시한 흐름도이다. 단계 S1210에서, 일 실시예에 따른 전자 장치는 피사체를 촬영하여, 제1 이미지 및 깊이 이미지를 획득할 수 있다. 전자 장치는 RGB 카메라를 이용하여 제1 이미지를 획득하고, 깊이 카메라를 이용하여 깊이 이미 지를 획득할 수 있다. 단계 S1220에서, 일 실시예에 따른 전자 장치는 자동 반사 센싱 옵션의 켜짐/꺼짐 여부를 식별할 수 있다. 일 실시예에서, 전자 장치는 제1 이미지에 빛 반사가 존재하는지 여부를 자동으로 식별하는 자동 반사 센 싱 옵션이 켜져 있으면, 단계 S1230을 수행할 수 있다. 또한, 전자 장치는 자동 반사 센싱 옵션이 꺼져 있으면, 단계 S1225를 수행할 수 있다. 단계 S1225에서, 일 실시예에 따른 전자 장치는 수동 반사 센싱 옵션의 켜짐/꺼짐 여부를 식별할 수 있다. 일 실시예에서, 전자 장치의 사용자가 제1 이미지에 빛 반사가 존재하는지 여부를 식별하기 위해서 수동 반사 센싱 옵션을 켜는 사용자 입력을 입력할 수 있다. 전자 장치는 수동 반사 센싱 옵션이 켜지는 경우, 단계 S1230을 수행할 수 있다. 단계 S1230에서, 일 실시예에 따른 전자 장치는 제1 이미지에 빛 반사가 존재하는지 여부를 식별할 수 있 다 일 실시예에서, 전자 장치는 제1 이미지를 빛 반사 검출 모델에 적용하여, 제1 이미지에 빛 반사가 존재 하는지 여부를 검출할 수 있다. 다른 실시예에서, 전자 장치는 제1 이미지 및 깊이 이미지를 빛 반사 검출 모델에 적용하여, 제1 이미지 에 빛 반사가 존재하는지 여부를 검출할 수 있다. 일 실시예에 따른 전자 장치가 빛 반사 검출 모델을 이용하여 제1 이미지에 빛 반사가 존재하는지 여부를 검출하는 방법은 도 3에 대한 설명에서 서술하였으므로, 동일한 설명은 생략하기로 한다. 단계 S1250에서, 일 실시예에 따른 전자 장치는 깊이 정보를 임계값과 비교할 수 있다. 전자 장치 가 전자 장치로부터 피사체까지의 거리를 나타내는 깊이 정보를 획득하는 방법은, 도 4에 대한 설명에서 서술하였으므로, 동일한 설명은 생략하기로 한다. 전자 장치는 획득된 깊이 정보가 임계값 이상인 경우, 단계 S1255를 수행할 수 있다. 또한, 전자 장치는 획득된 깊이 정보가 임계값 미만인 경우, 단계 S1260을 수행할 수 있다. 단계 S1255에서, 일 실시예에 따른 전자 장치는 전자 장치의 플래시를 비활성화시킬 수 있다. 이 경우, 전자 장치의 플래시를 활성화함으로써 피사체를 촬영한 이미지인 제2 이미지가 획득되지 않을 수 있다. 단계 S1260에서, 일 실시예에 따른 전자 장치는 전자 장치의 플래시가 활성화된 상태에서 피사체를 촬영함으로써 제2 이미지를 획득할 수 있다. 단계 S1270에서, 일 실시예에 따른 전자 장치는 제1 이미지, 제2 이미지 및 깊이 이미지 각각을 정합하여 하나의 좌표계에 나타내기 위한 전처리를 수행할 수 있다. 전자 장치는 제1 이미지, 제2 이미지 및 깊이 이미지 각각에 포함되는 픽셀들 중에서, 실제 현실 공간의 동일한 지점을 나타내는 픽셀을 정합시키기 위하여 제1 이미지, 제2 이미지 및 깊이 이미지를 공통의 이미지 평면에 투영시킬 수 있다. 이 경우, 전자 장치 는 각각의 이미지들을 3차원 공간 상에서 회전시키고, 비틀어서 공통의 이미지 평면에 투영되도록 할 수 있다. 일 실시예에 따른 전자 장치는 제1 이미지의 제1 픽셀들, 제2 이미지의 제2 픽셀들, 깊이 이미지의 제3 픽셀들을 정합시킬 수 있다. 전자 장치는 실제 현실 공간의 동일한 지점을 나타내는 픽셀들인 대응점들을정합시킬 때, 에피폴라 제약조건(epipolar constraint)을 이용할 수 있다. 이는, 도 6에 대한 설명에서 서술하 였으므로, 동일한 설명은 생략하기로 한다. 일 실시예에서, 단계 S1255에 의하여 전자 장치가 제2 이미지를 획득하지 않은 경우, 전자 장치는 제1 이미지 및 깊이 이미지에만 전처리를 수행할 수 있다. 단계 S1280에서, 일 실시예에 따른 전자 장치는 전처리가 수행된 제1 이미지, 전처리가 수행된 제2 이미 지 및 전처리가 수행된 깊이 이미지 중 적어도 하나를 이용하여, 빛 반사가 제거된 이미지를 획득할 수 있다. 전자 장치는 하나 이상의 인공지능 모델을 이용하여 빛 반사가 제거된 이미지를 획득할 수 있다. 예를 들어, 전자 장치는 제1 이미지, 깊이 이미지 및 제2 이미지를, 메인 모델, 제1 서브 모델 및 제2 서 브 모델의 조합으로 구성되는 하나의 인공지능 모델에 적용하고, 인공지능 모델로부터 출력되는 빛 반사가 제거 된 이미지를 획득할 수 있다. 다른 예에서, 전자 장치는 제1 이미지를 메인 모델에 적용하고, 깊이 이미지를 제1 서브 모델에 적용하고, 제2 이미지를 제2 서브 모델에 적용할 수 있다. 이 경우, 제1 서브 모델로부터 출력되는 데이터 및 제2 서브 모델로부터 출력되는 데이터는 메인 모델로 입력될 수 있다. 저자 장치는 메인 모델로부터 출력 되는 빛 반사가 제거된 이미지를 획득할 수 있다. 일 실시예에서, 전자 장치가 제2 이미지를 획득하지 않은 경우, 전자 장치는 제1 이미지 및 깊이 이미지만을 이용하여 빛 반사가 제거된 이미지를 획득할 수 있다. 이 경우, 전자 장치는 메인 모델 및 제 1 서브 모델만을 이용하여 빛 반사가 제거된 이미지를 획득할 수 있다. 도 13은 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하기 위해 이미지 처리 모듈의 인공지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 13을 설명함에 있어서, 제1 데이터셋은 이미지 내에 빛 반사가 존재하는 깊이 이미지들, 제1 이미지들 및 제2 이미지들로 구성되는 데이터셋일 수 있다. 또한, 제2 데이터셋은 이미지 내에 빛 반사가 없는 이 미지들로 구성되는 데이터셋일 수 있다. 일 실시예에 따른 전자 장치는 제1 데이터셋으로부터 제1 이미지, 깊이 이미지, 제2 이미지를 획득할 수 있다. 전자 장치는 제1 데이터셋에 포함되는 이미지들 중에서 제1 이미지, 깊이 이미지, 제2 이미지를 각각 하나씩 획득할 수 있다. 이 경우, 제1 이미지, 깊이 이미지, 제2 이미지 는 이미지 합성이 가능하도록 동일한 현실 공간 및 피사체를 촬영한 이미지일 수 있다. 전자 장치는 제1 이미지, 깊이 이미지, 제2 이미지를 이미지 처리 모듈에 적용 하고, 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지를 획득할 수 있다. 전자 장치는 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지를 레이블 값 ‘1’ 로 레이 블링 할 수 있다. 이 경우, 레이블링 값 ‘1’은 ‘빛 반사가 없는 이미지’ 클래스에 대응되는 레이블 값을 말 한다. 전자 장치는 이미지 분석 모듈을 이용하여 레이블 값 1로 레이블링된, 이미지 처리 모듈로부터 출 력된 빛 반사가 제거된 이미지를 분석할 수 있다. 이 경우, 이미지 분석 모듈은 입력된 이미지의 빛 반사 존재 여부를 식별하는 인공지능 모델을 포함할 수 있다. 이미지 분석 모듈에 포함되는 인공지능 모델은, 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지 및 제2 데이터셋으로부터 획득된 빛 반 사 없는 이미지에 기초하여 학습될 수 있다. 이에 대하여는 도 14에 대한 설명에서 더 서술하기로 한다. 전자 장치는 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지를 이미지 분석 모듈에 적용 하고, 이미지 처리 모듈로부터 출력된 빛 반사 없는 이미지에 대하여 빛 반사 존재 여부를 식별함으로써, 이미지 분석 모듈에 포함되는 인공지능 모델의 손실 함수를 계산할 수 있다. 전자 장치는 손 실 함수의 손실 값에 기초하여 이미지 처리 모듈 내 인공지능 모델의 가중치를 업데이트할 수 있다. 도 14는 일 실시예에 따른 전자 장치가 도 13의 이미지 처리 모듈의 인공지능 모델 및 이미지 분석 모듈의 인공 지능 모델을 학습시키는 방법을 설명하기 위한 흐름도이다.도 14를 참조하여, 도 13에서 전술한 이미지 처리 모듈의 인공지능 모델 및 이미지 분석 모듈의 인공지능 모델 을 학습 방법을 상세하게 설명하기로 한다. 개시된 실시예에서, 이미지 처리 모듈의 인공지능 모델 및 이미지 분석 모듈의 인공지능 모델은, 생성적 적대 신경망(Generative Adversarial Networks) 방식으로 구현될 수 있다. 이 경우, 빛 반사가 제거된 이미지를 생 성하는 생성자(Generator)는 이미지 처리 모듈의 인공지능 모델에 대응되고, 빛 반사가 없는 이미지를 판별하는 감별자(Discriminator)는 이미지 분석 모듈의 인공지능 모델에 대응될 수 있다. 도 14를 설명함에 있어서, 제2 데이터셋으로부터 획득된 빛 반사 없는 이미지는 실제로 빛 반사가 없는 이미지 들로 구성된 제2 데이터셋에서 획득한 빛 반사 없는 이미지를 말한다. 또한, 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지는, 실제로 빛 반사가 있는 이미지를 이미지 처리 모듈을 이용하여 빛 반사를 제거한 이미 지를 말한다. 이 경우, 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지는, 이미지 처리 모듈에 의해 빛 반사가 제거되더라도 일부 영역에는 빛 반사가 존재함으로 인해 제2 데이터셋으로부터 획득된 빛 반사 없는 이미지와 상이한 특성을 지닐 수 있다. 단계 S1410에서, 일 실시예에 따른 전자 장치 제1 반복 계수의 초기 값을 0으로 설정할 수 있다. 여기서, 제1 반복 계수는 전자 장치가 이미지 분석 모듈의 인공지능 모델의 학습 및 이미지 처리 모듈 내 인공지 능 모델의 학습을 반복하기 반복 횟수를 말한다. 단계 S1405에서, 일 실시예에 따른 전자 장치는 제1 반복 계수가 제1 임계값에 도달하였는지 여부를 식별 할 수 있다. 일 실시예에서, 전자 장치는 반복 횟수가 임계값 미만이면 단계 S1410을 수행할 수 있다. 단계 S1410에서, 일 실시예에 따른 전자 장치는 제2 반복 계수의 초기값을 0으로 설정할 수 있다. 여기서 제2 반복 계수는 이미지 분석 모듈의 인공지능 모델의 학습을 위한 반복 횟수를 말한다. 단계 S1415에서, 일 실시예에 따른 전자 장치는 제2 반복 계수가 제2 임계값보다 작은지 여부를 식별할 수 있다. 전자 장치는 제2 반복 계수가 제2 임계값보다 작은 경우, 단계 S1420 내지 S1445를 반복하여 수 행할 수 있다. 또한, 전자 장치는 제2 반복 계수가 제2 임계값보다 크거나 같은 경우, 단계 S1450을 수행 할 수 있다. 단계 S1420 내지 단계 S1445의 동작들은, 이미지 분석 모듈의 인공지능 모델을 훈련하기 위한 동작들이다. 단계 S1420에서, 일 실시예에 따른 전자 장치는 제2 데이터셋으로부터 획득된, 빛 반사 없는 이미지에 기 초하여, 이미지 분석 모듈의 인공지능 모델의 가중치를 업데이트 할 수 있다. 전자 장치는 제2 데이터셋 으로부터 획득된 빛 반사 없는 이미지를 레이블 값 ‘1’로 레이블링할 수 있다. 전자 장치는, 제2 데이 터셋으로부터 획득된 빛 반사 없는 이미지에 기초하여 이미지 분석 모듈의 인공지능 모델을 학습시킬 수 있다. 이 경우, 레이블링 값 ‘1’은 ‘빛 반사가 없는 이미지’ 클래스에 대응되는 레이블 값을 말한다. 단계 S1430에서, 일 실시예에 따른 전자 장치는 이미지 처리 모듈을 이용하여, 빛 반사가 제거된 이미지 를 획득할 수 있다. 전자 장치는 전술한 실시예들에 따라 제1 이미지, 제2 이미지 및 깊이 이미지를 획득 하고, 이미지 처리 모듈에 의해 출력되는 빛 반사가 제거된 이미지를 획득할 수 있다. 단계 S1440에서, 일 실시예에 따른 전자 장치는 이미지 처리 모듈로부터 출력된, 빛 반사가 제거된 이미 지에 기초하여, 이미지 분석 모듈의 인공지능 모델의 가중치를 업데이트 할 수 있다. 일 실시예에서, 이미지 처 리 모듈로부터 출력된 빛 반사가 제거된 이미지는 이미지 처리 모듈에 의해 빛 반사가 제거되더라도 일부 영역 에는 빛 반사가 잔존할 수 있다. 전자 장치는 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지를 레이블 값 ‘0’으로 레이블링할 수 있다. 전자 장치는, 이미지 처리 모듈로부터 출력된 빛 반사가 제거 된 이미지에 기초하여 이미지 분석 모듈의 인공지능 모델을 학습시킬 수 있다. 이 경우, 레이블링 값 ‘0’은 ‘빛 반사가 있는 이미지’ 클래스에 대응되는 레이블 값을 말한다. 단계 S1445에서, 일 실시예에 따른 전자 장치는 제2 반복 계수의 값을 1 증가시킬 수 있다. 전자 장치 는 제2 반복 계수의 값을 1 증가시키고, 단계 S1415를 수행하여, 제2 반복 계수가 제2 임계값 보다 작은 경우 단계 S1420 내지 S1430을 반복 수행함으로써, 이미지 분석 모듈의 인공지능 모델을 학습시킬 수 있다. 단계 S1415에서, 일 실시예에 따른 전자 장치는 제2 반복 계수가 제2 임계값 이상인 경우, 단계 S1450을 수행할 수 있다. 단계 S1450에서, 일 실시예에 따른 전자 장치는 이미지 처리 모듈을 이용하여 빛 반사가 제거된 다른 이 미지를 획득할 수 있다. 여기서, 이미지 처리 모듈로부터 출력된, 빛 반사가 제거된 이미지는, 단계 S1430에서 획득했던 빛 반사가 제거된 이미지와 상이한 이미지를 말한다. 전자 장치는 제1 데이터셋에서 다른 제1 이미지, 깊이 이미지 및 제2 이미지를 획득하고, 다른 제1 이미지, 깊이 이미지 및 제2 이미지를 이미지 처리 모듈을 적용하여 빛 반사가 제거된 다른 이미지를 획득할 수 있다. 일 실시예에서, 전자 장치는 이미지 처리 모듈의 인공지능 모델을 학습할 수 있다. 전자 장치는 이 미지 내 빛 반사를 제거함으로써, 이미지 처리 모듈로부터 출력된 빛 반사가 제거된 이미지가 이미지 분석 모듈 의 인공지능 모델에 의해 ‘빛 반사가 없는 이미지’로 식별되도록 하게 하기 위하여, 이미지 처리 모듈의 인공 지능 모델의 가중치들을 업데이트 할 수 있다. 전자 장치는 이미지 처리 모듈로부터 출력된, 빛 반사가 제거된 다른 이미지를 레이블 값 ‘1’로 레이블링할 수 있다. 이 경우, 레이블링 값 ‘1’은 ‘빛 반사가 없는 이미지’ 클래스에 대응되는 레이블 값을 말한다. 단계 S1460에서, 일 실시예에 따른 전자 장치는 이미지 처리 모듈로부터 출력된, 빛 반사가 없는 다른 이 미지를 이미지 분석 모듈의 인공지능 모델에 적용하고, 손실 값을 계산할 수 있다. 단계 S1470에서, 일 실시예에 따른 전자 장치는 계산된 손실 값에 기초하여, 이미지 처리 모듈의 인공지 능 모델의 가중치들을 업데이트 할 수 있다. 도 14의 단계 S1405 내지 S1470의 수행이 반복되면서, 이미지 처리 모듈의 인공지능 모델 및 이미지 분석 모듈 의 인공지능 모델이 학습됨에 따라, 이미지 처리 모듈의 인공지능 모델은 점차적으로 빛 반사가 더 잘 제거된 이미지를 생성하게 되고, 이미지 분석 모듈의 인공지능 모델은 점차적으로 빛 반사가 없는 이미지와 빛 반사가 있는 이미지를 더 잘 구별할 수 있다. 이미지 분석 모듈의 인공지능 모델이 이미지 처리 모듈로부터 출력되는 빛 반사가 제거된 이미지를 빛 반사가 없는 이미지와 더 이상 구별하지 못하게 될 때, 이미지 분석 모듈의 인공 지능 모델과 이미지 처리 모듈의 인공지능 모델의 학습이 종료될 수 있다. 도 15는 일 실시예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 15를 참조하면, 일 실시예에 따른 전자 장치는 통신 인터페이스, 카메라 모듈, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 서버(미도시)와 데이터 통신을 수행할 수 있다. 또한, 통신 인터페이스는 서버(미도시)뿐 아니라, 다른 주변 전자 장치들(미도시)과도 데이터 통신을 수행할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), 블루투스 (Bluetooth), 지그비(zigbee), WFD(Wi-Fi Direct), 적외선 통신(IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Allicance, WiGig) 및 RF 통신을 포함하는 데이터 통신 방식 중 적어도 하나를 이 용하여 서버 또는 다른 주변 전자 장치들과 데이터 통신을 수행할 수 있다. 일 실시예에 따른 통신 인터페이스는 빛 반사가 제거된 이미지를 획득하기 위한 데이터를 외부 장치(미도 시)와 송수신할 수 있다. 예를 들어, 통신 인터페이스는 빛 반사가 제거된 이미지를 획득하기 위하여 학 습된 빛 반사 검출 모델, 메인 모델, 제1 서브 모델, 제2 서브 모델 등을 외부의 서버(미도시)로부터 수신할 수 있다. 카메라 모듈은 프로세서의 제어에 의해 피사체를 촬영할 수 있다. 카메라 모듈은 RGB 카메라 및 깊이 카메라를 포함할 수 있다. RGB 카메라와 깊이 카메라는 하나 이상일 수 있다. RGB 카메라는 피사체를 촬영할 수 있다. 프로세서는 RGB 카메라를 제어하여, 플래시가 비활 성화된 상태에서 피사체를 촬영한 제1 이미지 및 플래시가 활성화된 상태에서 피사체를 촬영한 제2 이미지를 획 득할 수 있다. 깊이 카메라는 피사체를 촬영하여 깊이 이미지를 획득할 수 있다. 깊이 이미지는 전자 장치로부터 피사체까지의 거리를 나타내는 깊이 정보와 관련된 데이터를 포함할 수 있다. 예를 들어, 깊이 이미지 내 픽셀 들은 전자 장치로부터 피사체까지의 거리가 가까울수록 큰 픽셀 값을 갖는 이미지일 수 있다. 깊이 카메 라는 Time-of-Flight 카메라(ToF 카메라), RGB-Depth 카메라 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비휘발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모리를 포함할 수 있다. 일 실시예에 따른 메모리는 빛 반사가 제거된 이미지를 획득하는데 이용될 수 있는 다양한 종류의 데이터 를 저장할 수 있다. 예를 들어, 메모리에는 빛 반사 검출 모듈, 깊이 센싱 모듈, 이미지 전 처리 모듈, 이미지 처리 모듈 및 이미지 분석 모듈이 저장될 수 있다. 일 실시예에서, 빛 반사 검출 모듈은 이미지 내 빛 반사가 존재하는지 여부를 검출하는 빛 반사 검출 모 델을 포함할 수 있다. 일 실시예에서, 이미지 처리 모듈은 이미지들을 융합하여 이미지 내 존재하는 빛 반사를 제거하기 위한 인공지능 모델을 포함할 수 있다. 예를 들어, 이미지 처리 모듈은 제1 이미지를 입력 받아 빛 반사가 제 거된 이미지를 출력하는 메인 모델, 깊이 이미지를 입력 받아 메인 모델로 피처 맵을 출력하는 제1 서브 모델, 제2 이미지를 입력 받아 메인 모델로 피처 맵을 출력하는 제2 서브 모델을 포함할 수 있다. 일 실시예에서, 이미지 분석 모듈은 빛 반사가 없는 이미지를 식별하는, 빛 반사가 없는 이미지 식별 모 델을 포함할 수 있다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 통신 인터페이스, 카 메라 모듈 등을 전반적으로 제어할 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), AP(Application Processor), 뉴럴 프로세서(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전용 프로세서 중 적 어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에서, 프로세서는 빛 반사 검출 모듈을 실행하여, 이미지 내 빛 반사가 존재하는지 여부 를 식별할 수 있다. 프로세서는 빛 반사 검출 모듈의 빛 반사 검출 모델을 이용하여, 이미지를 입 력 받고, 입력된 이미지에 빛 반사가 존재하는지 여부를 검출할 수 있다. 프로세서는 이미지를 입력 받아 ‘빛 반사 있음’ 또는 ‘빛 반사 없음’의 두 종류의 클래스 중 어느 하나로 입력된 이미지를 분류할 수 있다. 예를 들어, 빛 반사 검출 모델은 제1 이미지, 제2 이미지, 깊이 이미지 중 적어도 하나의 이미지를 입력 받아, 입력된 이미지에 빛 반사가 존재하는지 여부를 나타내는 빛 반사 정보를 출력할 수 있다. 프로세서는 빛 반사 검출 모듈로부터 획득되는 빛 반사 정보에 기초하여 빛 반사가 제거된 이미지 를 생성할 지 여부를 결정할 수 있다. 예를 들어, 프로세서는 제1 이미지에 빛 반사가 존재하는 것으로 판단되는 경우, 전술한 실시예들에 따른, 전자 장치가 빛 반사를 제거하기 위한 동작들을 수행할 수 있다. 일 실시예에서, 프로세서는 깊이 센싱 모듈을 실행하여, 전자 장치로부터 피사체까지의 거리 를 나타내는 깊이 정보를 획득할 수 있다. 프로세서는 깊이 센싱 모듈로부터 획득되는 깊이 정보에 기초하여, 플래시를 활성화하여 피사체를 촬영한 제2 이미지를 획득할 지 여부를 결정할 수 있다. 예를 들어, 프로세서는 전자 장치로부터 피사체까지의 거리가 임계값 미만인 경우, 플래시를 활성화하고 피사 체를 촬영함으로써 제2 이미지를 획득하도록 카메라 모듈을 제어할 수 있다.일 실시예에서, 프로세서는 이미지 전처리 모듈을 실행하여, 빛 반사가 제거된 이미지를 생성하기 위해 이미지 처리 모듈에 이미지들을 입력하기 위한 전처리 과정들을 수행할 수 있다. 일 실시예에서, 제1 이미지, 제2 이미지 및 깊이 이미지는 카메라 모듈 내 서로 다른 카메라를 이용하여 촬영됨으로써, 서로 다른 시점에서 피사체를 촬영한 이미지일 수 있다. 프로세서는 제1 이미지, 제2 이미 지 및 깊이 이미지 각각에 포함되는 픽셀들 중에서, 실제 현실 공간의 동일한 지점을 나타내는 픽셀을 정합시키 기 위하여 제1 이미지, 제2 이미지 및 깊이 이미지를 공통의 이미지 평면에 투영시킬 수 있다. 이 경우, 프로세 서는 각각의 이미지들을 3차원 공간 상에서 회전시키고, 비틀어서 공통의 이미지 평면에 투영되도록 할 수 있다. 프로세서는 제1 이미지의 제1 픽셀들, 제2 이미지의 제2 픽셀들, 깊이 이미지의 제3 픽셀들을 정합시킬 수 있다. 프로세서는 실제 현실 공간의 동일한 지점을 나타내는 픽셀들인 대응점들을 정합시킬 때, 에피 폴라 제약조건(epipolar constraint)을 이용할 수 있다. 프로세서는 에피폴라 제약 조건을 이용하여 대응 점의 후보군들을 나타내는 에피폴라 라인을 계산하고, 에피폴라 라인을 일치시키는 이미지 렉티피케이션(image rectification)을 수행할 수 있다. 프로세서는 이미지 렉티피케이션 과정으로 변환된 이미지들을 비교하 여, 현실 공간의 동일한 지점을 나타내는 픽셀들인 대응점들을 검색하고, 검색된 대응점들을 정합시킬 수 있다. 프로세서는 제1 이미지의 제1 픽셀들, 제2 이미지의 제2 픽셀들 및 깊이 이미지의 제3 픽셀들 각각에 대 하여, 각각의 이미지들 내 픽셀들의 밝기가 균일해지도록 캘리브레이션을 수행할 수 있다. 일 실시예에서, 프로세서는 이미지 처리 모듈을 실행하여, 빛 반사가 제거된 이미지를 획득할 수 있다. 프로세서는 이미지 처리 모듈에 포함되는 하나 이상의 인공지능 모델을 이용하여, 빛 반사가 제거된 이미지를 획득할 수 있다. 예를 들어, 프로세서는 제1 이미지를 메인 모델에 적용하고, 깊이 이미지를 제1 서브 모델에 적용하고, 제2 이미지를 제2 서브 모델에 적용할 수 있다. 이 경우, 제1 서브 모델 및 제2 서브 모델의 출력 데이터는 메 인 모델에 포함되는 신경망 레이어 중 적어도 일부로 입력될 수 있다. 메인 모델은, 빛 반사가 제거된 이미지를 출력할 수 있다. 프로세서가 빛 반사가 제거된 이미지를 획득하는 구체적인 방법은, 전술한 실시예들에서 설명한 내용과 동일하므로, 설명을 생략하기로 한다. 일 실시예에서, 프로세서는 이미지 처리 모듈에 포함되는 메인 모델, 제1 서브 모델 및 제2 서브 모델을 업데이트할 수 있다. 이 경우, 이미지 분석 모듈의 빛 반사가 없는 이미지 식별 모델이 이용될 수 있다. 이는, 도 14에 대한 설명에서 전술하였으므로, 동일한 설명은 생략하기로 한다. 도 16은 일 실시예에 따른 서버의 구성을 나타내는 블록도이다. 일 실시예에 따른 서버는 전자 장치와 유선 통신 또는 무선 통신 방식으로 상호 연결되고, 데이터 통신을 수행할 수 있다. 일 실시예에 따른 서버는 적어도 통신 인터페이스, DB, 메모리, 프로세서를 포 함할 수 있다. 일 실시예에 따른 통신 인터페이스는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 통하여 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있 다. 일 실시예에 따른 통신 인터페이스는 전자 장치로 빛 반사 검출 모델, 메인 모델, 제1 서브 모델 및 제2 서브 모델 및 빛 반사가 없는 이미지 식별 모델들을 전송할 수 있다. 또한, 통신 인터페이스는 전 자 장치로부터 빛 반사 검출 모델, 메인 모델, 제1 서브 모델 및 제2 서브 모델 및 빛 반사가 없는 이미 지 식별 모델들을 수신할 수 있다. 통신 인터페이스는 수신된 인공지능 모델을 업데이트하여, 업데이트된 빛 반사 검출 모델, 메인 모델, 제1 서브 모델 및 제2 서브 모델 및 빛 반사가 없는 이미지 식별 모델들을 전자 장치로 전송할 수 있다. DB는 전자 장치로부터 수신한 데이터 및 기타 외부 장치(미도시)로부터 수신된 데이터를 저장할 수 있다. DB는 학습을 통하여 생성된 빛 반사 검출 모델, 메인 모델, 제1 서브 모델 및 제2 서브 모델 및 빛 반사가 없는 이미지 식별 모델들 및 각각의 인공지능 모델들을 학습하는데 이용될 학습용 데이터셋을 저장할 수있다. 메모리는 서버를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 메모리에 저장되는 프로그램은 하나 이상의 명령어들을 포함할 수 있다. 메모리에 저장된 프 로그램(하나 이상의 명령어들) 또는 어플리케이션은 프로세서에 의해 실행될 수 있다. 메모리에는 전자 장치에 저장된 모듈과 동일한 기능을 수행하는 모듈이 저장되어 있을 수 있다. 예를 들어, 메모리 에는 빛 반사 검출 모듈(미도시), 깊이 센싱 모듈(미도시), 이미지 전처리 모듈(미도시), 이미지 처리 모 듈(미도시), 이미지 분석 모듈(미도시) 에 대응되는 데이터 및 프로그램 명령어 코드들이 저장될 수 있다. 프로세서는 서버를 전반적으로 제어할 수 있다. 일 실시예에 따른 프로세서는 메모리 에 저장되는 하나 이상의 프로그램들을 실행할 수 있다. 일 실시예에 따른 프로세서는 AP(Application Processor), CPU(Central Processing unit)), GPU(Graphic Processing Unit), 뉴럴 프로세서(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구 조로 설계된 인공지능 전용 프로세서 등을 포함할 수 있다. 프로세서는, 전술한 실시예들에 따른, 전자 장치에서 수행 가능한 동작들을 수행할 수 있다. 프로세서는 빛 반사가 제거된 이미지를 획득할 수 있다. 프로세서는 전자 장치로부터 제1 이 미지, 제2 이미지 및 깊이 이미지를 수신하고, DB에 저장된 빛 메인 모델, 제1 서브 모델 및 제2 서브 모 델을 이용하여, 빛 반사가 제거된 이미지를 획득할 수 있다. 서버가 빛 반사가 제거된 이미지를 획득하는 방법은, 전자 장치가 빛 반사가 제거된 이미지를 획득하는 방법과 대응되므로, 동일한 설명은 생략하기로 한다. 이 경우, 빛 반사가 제거된 이미지를 획득하기 위한 이미지 전처리 과정들은 전자 장치에서 수행되 거나, 서버에서 수행될 수 있다. 일 실시예에서, 서버에 저장된 인공지능 모델들은, 전자 장치에 저장된 인공지능 모델들보다 더 많 은 연산의 수행이 가능한, 고성능 모델일 수 있다. 한편, 도 15에 도시된 전자 장치의 블록도 및 도 16에 도시된 서버의 블록도는, 일 실시예를 위한 블록도이다. 블록도의 각 구성요소는 실제 구현되는 각 장치의 사양에 따라 통합, 추가 또는 생략될 수 있다. 즉 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요 소로 세분되어 구성될 수 있다. 또한, 각 블록에서 수행하는 기능은 실시예들을 설명하기 위한 것이며, 그 구체 적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 일 실시예에 따른 전자 장치의 동작 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발 명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수 도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체 (magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장 하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지 는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코 드를 포함한다. 또한, 개시된 실시예들에 따른 전자 장치의 동작 방법은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 클라이언트 장치로 구성되는 시스템에서, 서버의 저장매체 또는 클라이언트 장치의 저장매체를 포함할 수 있다. 또는, 서버 또는 클라이언트 장치와 통신 연결되는 제3 장치(예,스마트폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프 로그램 제품은 서버로부터 클라이언트 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 클라이언트 장치로 전 송되는 S/W 프로그램 자체를 포함할 수 있다. 이 경우, 서버, 클라이언트 장치 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수 있다. 또는, 서버, 클라이언트 장치 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버(예로, 클라우드 서버 또는 인공 지능 서버 등)가 서버에 저장된 컴퓨터 프로그램 제품을 실행 하여, 서버와 통신 연결된 클라이언트 장치가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16"}
{"patent_id": "10-2021-0088572", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하는 방법을 개략적으로 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하기 위해 이용하는 복수의 모듈들의 동 작들을 설명하기 도면이다. 도 3은 일 실시예에 따른 전자 장치가 촬영한 이미지에 빛 반사가 존재하는지 여부를 검출하는 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 전자 장치가 깊이 정보를 획득하는 방법을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 전자 장치가 제2 이미지를 획득할지 여부를 결정하는 방법을 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 전자 장치가 이미지에 전처리를 수행하는 방법을 설명하기 위한 흐름도이다. 도 7은 일 실시예에 따른 전자 장치가 제1 이미지, 제2 이미지 및 깊이 이미지를 이용하여, 빛 반사가 제거된 이미지를 획득하는 방법을 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 전자 장치가 이용하는, 빛 반사가 제거된 이미지를 생성하는 빛 반사 제거 모델의 네 트워크 구조를 설명하기 위한 도면이다. 도 9는 일 실시예에 따른 전자 장치가 이용하는, 빛 반사가 제거된 이미지를 생성하는 빛 반사 제거 모델의 다 른 네트워크 구조를 설명하기 위한 도면이다. 도 10은 일 실시예에 따른 전자 장치가 제1 이미지, 깊이 이미지 및 제2 이미지를 이용하여 빛 반사가 제거된 이미지를 획득하는 예를 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 전자 장치가 제1 이미지, 깊이 이미지 및 제2 이미지를 이용하여 빛 반사가 제거된 이미지를 획득하는 다른 예를 설명하기 위한 도면이다. 도 12는 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하는 방법을 도시한 흐름도이다. 도 13은 일 실시예에 따른 전자 장치가 빛 반사가 제거된 이미지를 획득하기 위해 이미지 처리 모듈의 인공지능 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 14는 일 실시예에 따른 전자 장치가 도 13의 이미지 처리 모듈의 인공지능 모델 및 이미지 분석 모듈의 인공 지능 모델을 학습시키는 방법을 설명하기 위한 흐름도이다. 도 15는 일 실시예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 16은 일 실시예에 따른 서버의 구성을 나타내는 블록도이다."}
