{"patent_id": "10-2023-0087911", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0007892", "출원번호": "10-2023-0087911", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "강성민"}}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,제1 센서부;제2 센서부;적어도 하나의 인스트럭션(instruction)을 저장하는 메모리;상기 메모리와 연결되어 상기 전자 장치를 제어하는 적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는,상기 제1 센서부를 통해 센싱 데이터를 획득하고,상기 제2 센서부를 통해 복수의 촬영 이미지를 획득하고, 상기 센싱 데이터에 기초하여 식별된 복수의 주행 위치 및 상기 복수의 촬영 이미지를 상기 메모리에 저장하고,주행 불가 이벤트가 식별되면, 상기 주행 불가 이벤트가 발생한 제1 시점을 식별하고,제1 시점에서 임계 시간 이전의 제2 시점을 식별하고,상기 복수의 주행 위치 중 상기 제2 시점에 대응되는 위치를 획득하고,상기 복수의 촬영 이미지 중 상기 제2 시점에 대응되는 촬영 이미지를 획득하고,상기 제2 시점에 대응되는 위치 및 상기 제2 시점에 대응되는 촬영 이미지를 포함하는 이벤트 정보에 기초하여상기 주행 불가 이벤트를 등록하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 시점에 대응되는 제1 위치, 상기 제1 시점에 대응되는 제1 촬영 이미지를 획득하고,상기 제2 시점에 대응되는 위치는 제2 위치이고,상기 제2 시점에 대응되는 촬영 이미지는 제2 촬영 이미지이고,상기 제2 시점은 상기 제1 시점보다 이전 시점인, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 적어도 하나의 프로세서는,상기 제2 촬영 이미지에 기초하여 상기 주행 불가 이벤트와 관련된 타겟 오브젝트를 식별하고,상기 제2 위치, 상기 제2 촬영 이미지 및 상기 타겟 오브젝트를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 적어도 하나의 프로세서는,공개특허 10-2025-0007892-3-상기 타겟 오브젝트가 이동 불가능한 오브젝트를 나타내는 기 설정된 오브젝트이면, 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 위치, 상기 제2 위치, 상기 제1 촬영 이미지 및 상기 제2 촬영 이미지를 포함하는 상기 이벤트 정보에기초하여 상기 주행 불가 이벤트를 등록하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 센서부를 통해 상기 복수의 주행 위치를 획득하고,상기 제2 센서부를 통해 상기 복수의 촬영 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 적어도 하나의 프로세서는,상기 주행 불가 이벤트를 등록한 후, 제3 시점에 대응되는 제3 위치, 상기 제3 시점에 대응되는 제3 촬영 이미지를 획득하고,상기 제3 위치가 상기 제2 위치에 대응되면, 상기 제2 촬영 이미지와 상기 제3 촬영 이미지 사이의 유사도를 획득하고,상기 유사도가 임계값 이상이면, 상기 제3 위치를 회피하도록 주행하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 적어도 하나의 프로세서는,상기 전자 장치가 주행하는 복수의 주행 방향을 획득하고,상기 제1 시점에 대응되는 제1 방향을 획득하고, 상기 제2 시점에 대응되는 제2 방향을 획득하고,상기 제2 위치, 상기 제2 방향 및 상기 제2 촬상 이미지를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 적어도 하나의 프로세서는,상기 제3 시점에 대응되는 제3 방향을 획득하고, 상기 제3 위치가 상기 제2 위치에 대응되면, 상기 제3 주행 방향이 상기 제2 방향에 대응되는지 여부를 식별하고,상기 제3 주행 방향이 상기 제2 방향에 대응되면, 상기 제2 촬영 이미지와 상기 제3 촬영 이미지 사이의 상기유사도를 획득하는, 전자 장치.공개특허 10-2025-0007892-4-청구항 10 제2항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 위치를 나타내는 UI(User Interface)를 포함하는 화면을 제공하는, 전자 장치."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 제어 방법에 있어서,센싱 데이터를 획득하는 단계;복수의 촬영 이미지를 획득하는 단계;상기 센싱 데이터에 기초하여 식별된 복수의 주행 위치 및 상기 복수의 촬영 이미지를 저장하는 단계;주행 불가 이벤트가 식별되면, 상기 주행 불가 이벤트가 발생한 제1 시점을 식별하는 단계;제1 시점에서 임계 시간 이전의 제2 시점을 식별하는 단계;상기 복수의 주행 위치 중 상기 제2 시점에 대응되는 위치를 획득하는 단계;상기 복수의 촬영 이미지 중 상기 제2 시점에 대응되는 촬영 이미지를 획득하는 단계; 및상기 제2 시점에 대응되는 위치 및 상기 제2 시점에 대응되는 촬영 이미지를 포함하는 이벤트 정보에 기초하여상기 주행 불가 이벤트를 등록하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제어 방법은,상기 제1 시점에 대응되는 제1 위치, 상기 제1 시점에 대응되는 제1 촬영 이미지를 획득하는 단계;를 더 포함하고,상기 제2 시점에 대응되는 위치는 제2 위치이고,상기 제2 시점에 대응되는 촬영 이미지는 제2 촬영 이미지이고,상기 제2 시점은 상기 제1 시점보다 이전 시점인, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제어 방법은,상기 제2 촬영 이미지에 기초하여 상기 주행 불가 이벤트와 관련된 타겟 오브젝트를 식별하는 단계;를 더 포함하고,상기 등록하는 단계는,상기 제2 위치, 상기 제2 촬영 이미지 및 상기 타겟 오브젝트를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 등록하는 단계는,상기 타겟 오브젝트가 이동 불가능한 오브젝트를 나타내는 기 설정된 오브젝트이면, 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록하는, 제어 방법.공개특허 10-2025-0007892-5-청구항 15 제12항에 있어서,상기 등록하는 단계는,상기 제1 위치, 상기 제2 위치, 상기 제1 촬영 이미지 및 상기 제2 촬영 이미지를 포함하는 상기 이벤트 정보에기초하여 상기 주행 불가 이벤트를 등록하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 제어 방법은,상기 복수의 주행 위치를 획득하는 단계; 및상기 복수의 촬영 이미지를 획득하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 제어 방법은,상기 주행 불가 이벤트를 등록한 후, 제3 시점에 대응되는 제3 위치, 상기 제3 시점에 대응되는 제3 촬영 이미지를 획득하는 단계;상기 제3 위치가 상기 제2 위치에 대응되면, 상기 제2 촬영 이미지와 상기 제3 촬영 이미지 사이의 유사도를 획득하는 단계;상기 유사도가 임계값 이상이면, 상기 제3 위치를 회피하도록 주행하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 제어 방법은,상기 전자 장치가 주행하는 복수의 주행 방향을 획득하는 단계;상기 제1 시점에 대응되는 제1 방향을 획득하는 단계; 및상기 제2 시점에 대응되는 제2 방향을 획득하는 단계;를 더 포함하고,상기 등록하는 단계는,상기 제2 위치, 상기 제2 방향 및 상기 제2 촬상 이미지를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 제어 방법은,상기 제3 시점에 대응되는 제3 방향을 획득하는 단계;상기 제3 위치가 상기 제2 위치에 대응되면, 상기 제3 주행 방향이 상기 제2 방향에 대응되는지 여부를 식별하는 단계; 및상기 제3 주행 방향이 상기 제2 방향에 대응되면, 상기 제2 촬영 이미지와 상기 제3 촬영 이미지 사이의 상기유사도를 획득하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2025-0007892-6-제12항에 있어서,상기 제어 방법은,상기 제1 위치를 나타내는 UI(User Interface)를 포함하는 화면을 제공하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0087911", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 전자 장치는 제1 센서부, 제2 센서부, 적어도 하나의 인스트럭션(instruction)을 저장하는 메모리, 메모리와 연결되어 전자 장치를 제어하는 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는 제1 센서부를 통 해 센싱 데이터를 획득하고, 제2 센서부를 통해 복수의 촬영 이미지를 획득하고, 상기 센싱 데이터에 기초하여 식별된 복수의 주행 위치 및 복수의 촬영 이미지를 메모리에 저장하고, 주행 불가 이벤트가 식별되면, 주행 불가 이벤트가 발생한 제1 시점을 식별하고, 제1 시점에서 임계 시간 이전의 제2 시점을 식별하고, 복수의 주행 위치 중 제2 시점에 대응되는 위치를 획득하고, 복수의 촬영 이미지 중 제2 시점에 대응되는 촬영 이미지를 획득하고, 제2 시점에 대응되는 위치 및 제2 시점에 대응되는 촬영 이미지를 포함하는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록한다."}
{"patent_id": "10-2023-0087911", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어방법에 관한 것으로, 더욱 상세하게는 주행 불가 이벤트를 등록하여 주행을 제 어하는 전자 장치 및 그 제어방법에 대한 것이다."}
{"patent_id": "10-2023-0087911", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이동형 전자 장치가 주행하는 중 이동을 방해 받는 이벤트가 발생할 수 있다. 예를 들어, 전선 등의 얇고 긴 물 체가 주행 경로 상에 존재할 수 있다. 의류나 애완동물 배변 패드, 작은 발 매트 등 가벼운 옷감이 주행 경로 상에 존재할 수 있다. 식탁 의자, 빨래 건조대 등 좁은 공간에 전자 장치가 주행할 수 있다. 현관 문틀 등에 전 자 장치가 걸리는 상황이 존재할 수 있다. 복잡한 구조물 사이에서 전자 장치가 갇히는 상황이 존재할 수 있다. 이미지 센서를 통해 장애물 또는 구조물을 인식하는 경우, 인식 시간이 오래 걸리거나 인식도가 낮다는 문제점 이 있었다. 특히, 조도가 낮은 경우 인식률이 떨어지는 문제점이 있었다."}
{"patent_id": "10-2023-0087911", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 상술한 문제를 개선하기 위해 고안된 것으로, 본 개시의 목적은 이벤트가 발생한 시점보다 이전 시점 의 위치 및 이미지를 이용하여 주행 불가 이벤트를 등록하는 전자 장치 및 그의 제어 방법을 제공함에 있다. 일 실시 예에 따른 전자 장치는 센서부, 적어도 하나의 인스트럭션(instruction)을 저장하는 메모리, 상기 메모 리와 연결되어 상기 전자 장치를 제어하는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는 상기 제1 센서부를 통해 센싱 데이터를 획득하고, 상기 제2 센서부를 통해 복수의 촬영 이미지를 획득하고, 상 기 센싱 데이터에 기초하여 식별된 복수의 주행 위치 및 상기 복수의 촬영 이미지를 상기 메모리에 저장하고, 주행 불가 이벤트가 식별되면, 상기 주행 불가 이벤트가 발생한 제1 시점을 식별하고, 제1 시점에서 임계 시간 이전의 제2 시점을 식별하고, 상기 복수의 주행 위치 중 상기 제2 시점에 대응되는 위치를 획득하고, 상기 복수 의 촬영 이미지 중 상기 제2 시점에 대응되는 촬영 이미지를 획득하고, 상기 제2 시점에 대응되는 위치 및 상기 제2 시점에 대응되는 촬영 이미지를 포함하는 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록한다. 상기 적어도 하나의 프로세서는 상기 제1 시점에 대응되는 제1 위치, 상기 제1 시점에 대응되는 제1 촬영 이미 지를 획득하고, 상기 제2 시점에 대응되는 위치는 제2 위치이고, 상기 제2 시점에 대응되는 촬영 이미지는 제2 촬영 이미지이고, 상기 제2 시점은 상기 제1 시점보다 이전 시점일 수 있다. 상기 적어도 하나의 프로세서는 상기 제2 촬영 이미지에 기초하여 상기 주행 불가 이벤트와 관련된 타겟 오브젝 트를 식별하고, 상기 제2 위치, 상기 제2 촬영 이미지 및 상기 타겟 오브젝트를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 적어도 하나의 프로세서는 상기 타겟 오브젝트가 이동 불가능한 오브젝트를 나타내는 기 설정된 오브젝트 이면, 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 적어도 하나의 프로세서는 상기 제1 위치, 상기 제2 위치, 상기 제1 촬영 이미지 및 상기 제2 촬영 이미지 를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 적어도 하나의 프로세서는 상기 제1 센서부를 통해 상기 복수의 주행 위치를 획득하고, 상기 제2 센서부를 통해 상기 복수의 촬영 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세서는 상기 주행 불가 이벤트를 등록한 후, 제3 시점에 대응되는 제3 위치, 상기 제3 시점에 대응되는 제3 촬영 이미지를 획득하고, 상기 제3 위치가 상기 제2 위치에 대응되면, 상기 제2 촬영 이미 지와 상기 제3 촬영 이미지 사이의 유사도를 획득하고, 상기 유사도가 임계값 이상이면, 상기 제3 위치를 회피하도록 주행할 수 있다. 상기 적어도 하나의 프로세서는 상기 전자 장치가 주행하는 복수의 주행 방향을 획득하고, 상기 제1 시점에 대 응되는 제1 방향을 획득하고, 상기 제2 시점에 대응되는 제2 방향을 획득하고, 상기 제2 위치, 상기 제2 방향 및 상기 제2 촬상 이미지를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 적어도 하나의 프로세서는 상기 제3 시점에 대응되는 제3 방향을 획득하고, 상기 제3 위치가 상기 제2 위 치에 대응되면, 상기 제3 주행 방향이 상기 제2 방향에 대응되는지 여부를 식별하고, 상기 제3 주행 방향이 상 기 제2 방향에 대응되면, 상기 제2 촬영 이미지와 상기 제3 촬영 이미지 사이의 상기 유사도를 획득할 수 있다. 상기 적어도 하나의 프로세서는 상기 제1 위치를 나타내는 UI(User Interface)를 포함하는 화면을 제공할 수 있 다. 일 실시 예에 따른 전자 장치의 제어 방법은 센싱 데이터를 획득하는 단계, 복수의 촬영 이미지를 획득하는 단 계, 상기 센싱 데이터에 기초하여 식별된 복수의 주행 위치 및 상기 복수의 촬영 이미지를 저장하는 단계, 주행 불가 이벤트가 식별되면, 상기 주행 불가 이벤트가 발생한 제1 시점을 식별하는 단계, 제1 시점에서 임계 시간 이전의 제2 시점을 식별하는 단계, 상기 복수의 주행 위치 중 상기 제2 시점에 대응되는 위치를 획득하는 단계, 상기 복수의 촬영 이미지 중 상기 제2 시점에 대응되는 촬영 이미지를 획득하는 단계 및 상기 제2 시점에 대응 되는 위치 및 상기 제2 시점에 대응되는 촬영 이미지를 포함하는 이벤트 정보에 기초하여 상기 주행 불가 이벤 트를 등록하는 단계를 포함할 수 있다. 상기 제어 방법은 상기 제1 시점에 대응되는 제1 위치, 상기 제1 시점에 대응되는 제1 촬영 이미지를 획득하는 단계를 더 포함하고, 상기 제2 시점에 대응되는 위치는 제2 위치이고, 상기 제2 시점에 대응되는 촬영 이미지는 제2 촬영 이미지이고, 상기 제2 시점은 상기 제1 시점보다 이전 시점일 수 있다. 상기 제어 방법은 상기 제2 촬영 이미지에 기초하여 상기 주행 불가 이벤트와 관련된 타겟 오브젝트를 식별하는 단계를 더 포함하고, 상기 등록하는 단계는 상기 제2 위치, 상기 제2 촬영 이미지 및 상기 타겟 오브젝트를 포 함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 등록하는 단계는 상기 타겟 오브젝트가 이동 불가능한 오브젝트를 나타내는 기 설정된 오브젝트이면, 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 등록하는 단계는 상기 제1 위치, 상기 제2 위치, 상기 제1 촬영 이미지 및 상기 제2 촬영 이미지를 포함하 는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 제어 방법은 상기 복수의 주행 위치를 획득하는 단계 및 상기 복수의 촬영 이미지를 획득하는 단계를 더 포함할 수 있다. 상기 제어 방법은 상기 주행 불가 이벤트를 등록한 후, 제3 시점에 대응되는 제3 위치, 상기 제3 시점에 대응되 는 제3 촬영 이미지를 획득하는 단계, 상기 제3 위치가 상기 제2 위치에 대응되면, 상기 제2 촬영 이미지와 상 기 제3 촬영 이미지 사이의 유사도를 획득하는 단계, 상기 유사도가 임계값 이상이면, 상기 제3 위치를 회피하 도록 주행하는 단계를 더 포함할 수 있다. 상기 제어 방법은 상기 전자 장치가 주행하는 복수의 주행 방향을 획득하는 단계, 상기 제1 시점에 대응되는 제 1 방향을 획득하는 단계 및 상기 제2 시점에 대응되는 제2 방향을 획득하는 단계를 더 포함하고, 상기 등록하는 단계는 상기 제2 위치, 상기 제2 방향 및 상기 제2 촬상 이미지를 포함하는 상기 이벤트 정보에 기초하여 상기 주행 불가 이벤트를 등록할 수 있다. 상기 제어 방법은 상기 제3 시점에 대응되는 제3 방향을 획득하는 단계, 상기 제3 위치가 상기 제2 위치에 대응 되면, 상기 제3 주행 방향이 상기 제2 방향에 대응되는지 여부를 식별하는 단계 및 상기 제3 주행 방향이 상기 제2 방향에 대응되면, 상기 제2 촬영 이미지와 상기 제3 촬영 이미지 사이의 상기 유사도를 획득하는 단계를 더 포함할 수 있다. 상기 제어 방법은 상기 제1 위치를 나타내는 UI(User Interface)를 포함하는 화면을 제공하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0087911", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다.본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프로세서 (미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 1은 다양한 실시 예에 따라 전자 장치를 도시한 블록도이다. 전자 장치는 센서부, 메모리 또는 적어도 하나의 프로세서 중 적어도 하나를 포함할 수 있 다. 전자 장치는 이동형 전자 장치 또는 이동형 기기를 제어하기 위한 전자 장치를 의미할 수 있다. 예를 들어, 전자 장치는 주행이 가능한 이동형 로봇 또는 이동형 로봇을 제어하기 위한 기기를 의미할 수 있다. 전자 장치는 기기의 주행을 제어하기 위한 분석 동작을 수행하는 서버일 수 있다. 다양한 실시 예에 따라, 전자 장치는 청소 동작을 수행하는 이동형 청소 로봇일 수 있다. 센서부는 센싱 데이터를 센싱할 수 있다. 센서부는 적어도 하나의 센서를 포함할 수 있다. 적어도 하 나의 센서는 위치를 센싱하는 라이다 센서, 이미지를 촬영하는 이미지 센서 또는 회전 각도를 센싱하는 가속도 센서(또는 자이로 센서) 중 하나일 수 있다. 다양한 실시 예에 따라, 하나의 센서가 위치, 이미지, 회전 각도 등을 모두 센싱할 수 있다. 센서부는 센싱 데이터를 센싱할 수 있다. 센서부는 제1 센서부 및 제2 센서부를 포함하고, 적어도 하나의 프로세서는 제1 센서부를 통해 복수 의 주행 위치를 획득하고, 제2 센서부를 통해 복수의 촬영 이미지를 획득할 수 있다. 제1 센서부는 주변 환경에 대한 센싱 데이터를 획득하는 센서일 수 있다. 제1 센서부는 라이더 센서, IR(Infra- Red) 센서, 3D 뎁스 카메라, 3d 비주얼 센서 등일 수 있다. 적어도 하나의 프로세서는 제1 센서부에서 획 득되는 센싱 데이터에 기초하여 전자 장치의 주행 위치를 획득할 수 있다. 제1 센서부의 번호를 110-1로 제2 센서부의 번호를 110-2로 기재할 수 있다. 제2 센서부는 이미지 센서일 수 있다. 이미지 센서는 카메라를 포함할 수 있다. 적어도 하나의 프로세서는 제2 센서부에서 획득되는 센싱 데이터에 기초하여 전자 장치 주변의 촬영 이미지를 획득할 수 있다. 메모리는 센싱 데이터 또는 가공된 센싱 데이터를 저장할 수 있다. 메모리는 적어도 하나의 인스트럭 션(instruction)을 저장할 수 있다. 적어도 하나의 프로세서프로세서는 전자 장치의 전반적인 제어 동작을 수행할 수 있다. 구체적으로, 적어도 하나의 프로세서 는 전자 장치의 전반적인 동작을 제어하는 기능을 한다. 적어도 하나의 프로세서 는 메모리와 연결되어 전자 장치를 제어할 수 있다. 적어도 하나의 프로세서는 센서부를 통해 획득한 복수의 주행 위치 및 복수의 촬영 이미지를 메모리 에 저장하고, 주행 불가 이벤트가 식별되면, 주행 불가 이벤트가 발생한 제1 시점을 식별하고, 제1 시점에 서 임계 시간 이전의 제2 시점을 식별하고, 복수의 주행 위치 중 제2 시점에 대응되는 위치를 획득하고, 복수의 촬영 이미지 중 제2 시점에 대응되는 촬영 이미지를 획득하고, 제2 시점에 대응되는 위치 및 제2 시점에 대응되 는 촬영 이미지를 포함하는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다. 적어도 하나의 프로세서는 제1 센서부를 통해 센싱 데이터를 획득할 수 있다. 적어도 하나의 프로세서 는 센싱 데이터에 기초하여 전자 장치의 주행 위치를 판단할 수 있다. 제1 센서부는 위치 정보를 식 별하는데 이용되는 데이터를 수집하는 센서일 수 있다. 센싱 데이터는 위치 정보를 식별하는데 이용되는 데이터 를 포함할 수 있다. 예를 들어, 제1 센서부는 위치 인식 센서일 수 있다. 예를 들어, 제1 센서부는 라이더 센서, IR(Infra Red) 센 서, 3D 뎁스 카메라, 3d 비주얼 센서 중 적어도 하나를 포함할 수 있다. 적어도 하나의 프로세서는 위치 인식 센서에서 획득되는 센싱 데이터를 획득할 수 있다. 일 실시 예에 따라, 적어도 하나의 프로세서는 제1 센서부를 통해 획득한 센싱 데이터 및 메모리에 저장된 맵 정보에 기초하여 전자 장치의 주행 위치를 판단할 수 있다. 맵 정보는 전자 장치가 주행하는 장소 의 위치 정보 또는 공간 정보 중 적어도 하나를 포함할 수 있다. 적어도 하나의 프로세서는 제1 센서부를 통해 획득한 센싱 데이터 및 맵 정보에 기초하여 전자 장치 의 상대적 주행 위치를 식별할 수 있다. 위치 정보는 전자 장치가 주행할 가능성이 있는 장소의 좌표 정보를 포함할 수 있다. 공간 정보는 적어도 하나의 공간에 대한 식별 정보를 포함할 수 있다. 예를 들어, 식별 정보는, 거실, 방1, 방 2, 방3 등을 나타내는 정보일 수 있다. 적어도 하나의 프로세서는 맵 정보에 포함된 복수의 위치 중 센싱 데이터에 대응되는 특정 위치를 식별할 수 있다. 적어도 하나의 프로세서는 특정 위치에 따라 전자 장치의 주행 위치를 판단할 수 있다. 맵 정보는 전자 장치가 주행하는 장소의 위치 정보 및 공간 정보가 맵핑된 정보를 저장할 수 있다. 예를 들어, 맵 정보는 거실에 대응되는 위치 정보, 방1에 대응되는 위치 정보, 방2에 대응되는 위치 정보, 방3에 대 응되는 위치 정보를 포함할 수 있다. 다양한 구현 예에 따라, 맵 정보는 공간 구분이 되어 있지 않은 상태에서 위치 정보를 포함할 수 있다. 적어도 하나의 프로세서는 제1 센서부를 통해 획득한 센싱 데이터에 기초하여 맵 정보에 포함된 복수의 위 치 중 전자 장치의 주행 위치를 식별할 수 있다. 전자 장치의 주행 위치는 전자 장치의 현재 위 치 또는 센싱 데이터에 대응되는 위치로 기재될 수 있다. 일 실시 예에 따라, 적어도 하나의 프로세서는 제1 센서부를 통해 획득한 센싱 데이터에 기초하여 직접적 으로 전자 장치의 주행 위치를 판단할 수 있다. 센싱 데이터는 기기의 위치를 특정할 수 있는 위치 정보를 포함할 수 있다. 다양한 실시 예에 따라, 제1 센서부는 절대적인 위치를 인식하는 센서를 포함할 수 있다. 예를 들어, 제1 센서 부는 GPS 센서를 포함할 수 있다. 적어도 하나의 프로세서는 GPS 센서를 통해 전자 장치의 절대적인 위치를 식별할 수 있다. 적어도 하나의 프로세서는 전자 장치의 절대적인 위치 및 맵 정보에 기초하 여 전자 장치의 주행 위치를 식별할 수 있다. 적어도 하나의 프로세서는 센서부를 통해 수신된 센싱 데이터에 기초하여 전자 장치의 주행 위치 및 촬영 이미지를 실시간으로 획득할 수 있다. 적어도 하나의 프로세서는 실시간으로 전자 장치의 위치를 획득 및 저장할 수 있다. 적어도 하나의 프로세서는 각 위치에서 촬영된 촬영 이미지를 획득 및 저장할 수 있다. 적어도 하나의 프로세서는 주행 불가 이벤트가 식별될 때까지 주행 동작을 진행할 수 있다. 적어도 하나의 프로세서는 주행이 완료될 때까지 주행 동작을 진행할 수 있다. 주행 불가 이벤트가 식별되면, 적어도 하나의 프로세서는 주행 동작을 정지할 수 있다. 주행 불가 이벤트 는 전자 장치의 주행이 더 이상 불가능한 이벤트 또는 전자 장치의 주행을 멈출 필요성이 있는 이벤 트를 포함할 수 있다. 예를 들어, 주행 불가 이벤트는 전자 장치가 갇힌 상태를 포함할 수 있다. 이와 관 련된 설명은 도 5에서 기재한다. 적어도 하나의 프로세서는 전자 장치의 위치의 변화량에 기초하여 주행 불가 이벤트를 식별할 수 있 다. 다양한 실시 예에 따라, 모터가 구동하고 있음에도 불구하고 위치 변화가 임계 범위 이내이면, 적어도 하나의 프로세서는 주행 불가 이벤트가 식별된 것으로 판단할 수 있다. 다양한 실시 예에 따라, 예정된 주행 경로 정보가 존재함에도 불구하고 위치 변화가 임계 범위 이내이면, 적어 도 하나의 프로세서는 주행 불가 이벤트가 식별된 것으로 판단할 수 있다. 다양한 실시 예에 따라, 모터 구동 명령에도 불구하고 모터가 구동하지 않는 경우, 적어도 하나의 프로세서 는 주행 불가 이벤트가 식별된 것으로 판단할 수 있다. 주행 위치 및 촬영 이미지가 메모리에 저장된 후, 적어도 하나의 프로세서는 저장된 주행 위치 및 촬 영 이미지를 제1 임계 시간 동안 저장할 수 있다. 제1 임계 시간이 경과하면, 적어도 하나의 프로세서는 메모리에 저장된 주행 위치 및 촬영 이미지를 메모리에서 삭제할 수 있다. 적어도 하나의 프로세서는 센서부를 통해 제1 시점에 대응되는 제1 위치, 제1 시점에 대응되는 제1 촬영 이미지를 획득하고, 제2 시점에 대응되는 위치는 제2 위치이고, 제2 시점에 대응되는 촬영 이미지는 제2 촬영 이미지이고, 제2 시점은 제1 시점보다 이전 시점일 수 있다. 주행 불가 이벤트가 식별되면, 적어도 하나의 프로세서는 주행 불가 이벤트가 발생한 시점을 제1 시점으로 식별할 수 있다. 제1 시점은 도 11의 t5에 대응될 수 있다. 제1 시점이 식별되면, 적어도 하나의 프로세서는 제1 시점에서 제2 임계 시점 이전의 제2 시점을 식별할 수 있다. 적어도 하나의 프로세서는 제2 시점에 대응되는 제2 위치, 제2 촬영 이미지를 획득할 수 있다. 다양한 실시 예에 따라, 제1 임계 시점과 제2 임계 시점이 상이할 수 있다. 제1 임계 시점은 제2 임계 시점보다 클 수 있다. 예를 들어, 제1 임계 시점은 5초이고, 제2 임계 시점은 2초일 수 있다. 다양한 실시 예에 따라, 제1 임계 시점과 제2 임계 시점이 동일할 수 있다. 예를 들어, 제1 임계 시점 및 제2 임계 시점은 2초일 수 있다. 제1 임계 시점과 제2 임계 시점이 동일하면 메모리에 저장되는 데이터의 양을 최소 화시킬 수 있다. 적어도 하나의 프로세서는 제2 촬영 이미지에 기초하여 주행 불가 이벤트와 관련된 타겟 오브젝트를 식별 하고, 제2 위치, 제2 촬영 이미지 및 타겟 오브젝트를 포함하는 이벤트 정보에 기초하여 주행 불가 이벤트를 등 록할 수 있다. 적어도 하나의 프로세서는 제2 촬영 이미지를 분석하여 주행 불가 이벤트의 원인을 식별할 수 있다. 적어 도 하나의 프로세서는 제2 촬영 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 적어도 하나 의 프로세서는 식별된 적어도 하나의 오브젝트 중 주행 불가 이벤트와 관련된 타겟 오브젝트를 식별할 수 있다. 타겟 오브젝트는 전자 장치의 주행을 방해할 가능성이 있는 오브젝트일 수 있다. 타겟 오브젝트는 미리 정해진 오브젝트일 수 있다. 타겟 오브젝트와 관련된 설명은 도 8에서 기재한다. 적어도 하나의 프로세서는 타겟 오브젝트가 이동 불가능한 오브젝트를 나타내는 기 설정된 오브젝트이면, 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다. 이동 불가능한 오브젝트는 기 설정된 오브젝트일 수 있다. 예를 들어, 이동 불가능한 오브젝트는 침대, 소파, 벽 등을 포함할 수 있다. 이와 관련된 설명은 도 9에서 기재한다. 이동 불가능한 오브젝트는 제거 불가능한 오브젝트로 대체될 수 있다. 적어도 하나의 프로세서는 제1 위치, 제2 위치, 제1 촬영 이미지 및 제2 촬영 이미지를 포함하는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다. 적어도 하나의 프로세서는 제2 시점에 대응되는 정보(제2 위치, 제2 촬영 이미지) 뿐 아니라 제1 시점에 대응되는 정보(제1 위치, 제1 촬영 이미지)를 이벤트 정보에 포함시킬 수 있다. 적어도 하나의 프로세서는 제1 시점 및 제2 시점을 모두 이용하여 주행 불가 이벤트를 등록할 수 있다. 제1 시점에 대응되는 정보는 이벤 트의 발생과 관련된 정보일 수 있다. 제2 시점에 대응되는 정보는 이벤트의 발생의 예상과 관련된 정보일 수 있 다. 제1 시점 및 제2 시점과 관련된 정보는 도 11에서 기재한다. 적어도 하나의 프로세서는 주행 불가 이벤트를 등록한 후, 센서부를 통해 제3 시점에 대응되는 제3 위치, 제3 시점에 대응되는 제3 촬영 이미지를 획득하고, 제3 위치가 제2 위치에 대응되면, 제2 촬영 이미지와 제3 촬영 이미지 사이의 유사도를 획득하고, 유사도가 임계값 이상이면, 제3 위치를 회피하도록 주행할 수 있다. 주행 불가 이벤트를 등록한 이후, 적어도 하나의 프로세서는 계속하여 실시간으로 전자 장치의 위치 및 촬영 이미지를 획득할 수 있다. 주행 불가 이벤트가 발생한 시점을 제1 시점으로 기재하였으며, 제 주행 불 가 이벤트를 등록한 제1 시점 이후의 제3 시점을 가정한다. 적어도 하나의 프로세서는 제3 시점에 대응되 는 정보(제3 위치, 제3 촬영 이미지)를 획득할 수 있다. 적어도 하나의 프로세서는 제3 시점에서 획득되는 정보에 기초하여 등록된 이벤트와 관련된 동작을 수행할 수 있다. 등록된 이벤트와 관련된 동작은 등록된 이벤트에 대응되는 위치에 대하여 회피 동작을 수행할지 여부 를 결정하는 것을 포함할 수 있다. 이와 관련된 구체적인 설명은 도 19에서 기재한다. 적어도 하나의 프로세서는 센서부를 통해 전자 장치가 주행하는 복수의 주행 방향을 획득하고, 제1 시점에 대응되는 제1 방향을 획득하고, 제2 시점에 대응되는 제2 방향을 획득하고, 제2 위치, 제2 방향 및 제2 촬상 이미지를 포함하는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다. 다양한 실시 예에 따라, 센서부는 제3 센서부를 포함할 수 있으며, 적어도 하나의 프로세서는 제3 센 서부를 통해 주행 방향을 획득할 수 있다. 제3 센서부는 가속도 센서 또는 자이로 센서일 수 있다. 주행 방향은 전자 장치가 이동하는 진행 방향을 의미할 수 있다. 주행 방향은 절대적인 방향 값을 포함할 수 있다. 이와 관련된 설명은 도 11에서 기재한다. 적어도 하나의 프로세서는 제3 시점에 대응되는 제3 방향을 획득하고, 제3 위치가 제2 위치에 대응되면, 제3 주행 방향이 제2 방향에 대응되는지 여부를 식별하고, 제3 주행 방향이 제2 방향에 대응되면, 제2 촬영 이 미지와 제3 촬영 이미지 사이의 유사도를 획득할 수 있다. 이와 관련된 구체적인 설명은 도 20에서 기재한다. 적어도 하나의 프로세서는 제1 위치를 나타내는 UI(User Interface)를 포함하는 화면을 제공할 수 있다. 이와 관련된 설명은 도 18에서 기재한다. 주행 불가 이벤트를 등록하는 과정은 도 6 내지 도 18에서 기재한다. 주행 불가 이벤트를 등록한 이후의 과정은 도 19 내지 도 29에서 기재한다. 주행 불가 이벤트와 관련된 동작을 수행하는 주체는 전자 장치, 서버, 단말 장치 등일 수 있다. 이와 관련된 다양한 실시 예는 도 13, 도14, 도 25, 도26에서 기재한다. 주행 불가 이벤트와 관련된 화면이 사용자에게 제공할 수 있다. 이와 관련된 다양한 실시 예는 도 15, 도16, 도 17, 도18, 도27, 도28, 도29에서 기재한다. 주행 불가 이벤트를 등록함으로써 전자 장치는 회피 동작을 미리 수행할 수 있다. 회피 동작을 미리 수행 하는 경우 주행 안정성을 향상시킬 수 있다. 전자 장치가 2개의 센서부를 포함하는 것으로 기재하였다. 다양한 실시 예에 따라, 전자 장치는 하나 의 센서부를 포함할 수 있다. 하나의 센서부는 이미지 센서만을 포함할 수 있다. 이미지 센서는 비젼 센서 또는 RGB 센서로 기재될 수 있다. 전자 장치는 이미지 센서를 통해 획득되는 촬영 이미지를 이용하여 주변 오브 젝트를 분석할 수 있다. 전자 장치는 청소 대상 공간에 포함된 적어도 하나의 오브젝트들의 위치 및 주행 공간과 관련된 좌표 정보를 포함하는 맵 정보를 저장할 수 있다. 전자 장치는 이미지를 통해 분석된 오브 젝트 및 맵 정보에 기초하여 전자 장치의 상대적인 주행 위치를 식별할 수 있다. 도 2는 도 1의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 2를 참조하면, 전자 장치는 센서부, 메모리, 적어도 하나의 프로세서, 통신 인터페이스 , 조작 인터페이스, 구동부, 스피커 또는 마이크 중 적어도 하나를 포함할 수 있다. 센서부, 메모리 및 적어도 하나의 프로세서의 동작 중에서 앞서 설명한 것과 동일한 동작에 대 해서는 중복 설명은 생략한다. 메모리는 프로세서에 포함된 롬(ROM)(예를 들어, EEPROM(electrically erasable programmable read- only memory)), 램(RAM) 등의 내부 메모리로 구현되거나, 프로세서와 별도의 메모리로 구현될 수도 있다. 이 경우, 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전 자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 전자 장 치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결 가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 프로세서는 디지털 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프 로세서(microprocessor), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙 처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤 러(controller), 어플리케이션 프로세서(application processor(AP)), GPU(graphics-processing unit) 또는 커 뮤니케이션 프로세서(communication processor(CP)), ARM(advanced reduced instruction set computer (RISC) machines) 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 프로세서는 프로세 싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 프로세서는 메모리에 저장된 컴퓨터 실행가능 명령어 (computer executable instructions)를 실행함으로써 다양한 기능을 수행할 수 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 장치와 통신을 수행하는 구성이다. 통신 인터페이스는 무선 통신 모듈 또는 유선 통신 모듈을 포함할 수 있다. 각 통신 모듈은 적 어도 하나의 하드웨어 칩 형태로 구현될 수 있다. 무선 통신 모듈은 무선으로 외부 장치와 통신하는 모듈일 수 있다. 예를 들어, 무선 통신 모듈은 와이파이 모듈, 블루투스 모듈, 적외선 통신 모듈 또는 기타 통신 모듈 중 적어도 하나의 모듈을 포함할 수 있다. 와이파이 모듈, 블루투스 모듈은 각각 와이파이 방식, 블루투스 방식으로 통신을 수행할 수 있다. 와이파이 모 듈이나 블루투스 모듈을 이용하는 경우에는 SSID(service set identifier) 및 세션 키 등과 같은 각종 연결 정 보를 먼저 송수신하여, 이를 이용하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 적외선 통신 모듈은 가시 광선과 밀리미터파 사이에 있는 적외선을 이용하여 근거리에 무선으로 데이터를 전송 하는 적외선 통신(IrDA, infrared Data Association)기술에 따라 통신을 수행한다. 기타 통신 모듈은 상술한 통신 방식 이외에 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통신 칩을 포함할 수 있다. 유선 통신 모듈은 유선으로 외부 장치와 통신하는 모듈일 수 있다. 예를 들어, 유선 통신 모듈은 LAN(Local Area Network) 모듈, 이더넷 모듈, 페어 케이블, 동축 케이블, 광섬유 케이블 또는 UWB(Ultra Wide-Band) 모듈 중 적어도 하나를 포함할 수 있다. 조작 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기 능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린으로도 구현될 수 있다. 버튼은 전자 장치의 본체외관의 전면부나 측면부, 배면부 등의 임의의 영역에 형성된 기계적 버튼, 터치 패드, 휠 등과 같은 다양한 유 형의 버튼이 될 수 있다. 구동부는 전자 장치의 주행을 제어하는 물리적인 힘을 생성 및 전달하는 구성일 수 있다. 구동부 는 모터를 포함할 수 있다. 스피커는 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지 등을 출력하는 구성요소일 수 있 다. 전자 장치는 마이크를 포함할 수 있다. 마이크는 사용자 음성이나 기타 소리를 입력 받아 오디오 데이터로 변환하기 위한 구성이다. 마이크 는 활성화 상태에서 사용자의 음성을 수신할 수 있다. 예를 들어, 마이크는 전자 장치의 상측이나 전 면 방향, 측면 방향 등에 일체형으로 형성될 수 있다. 마이크는 아날로그 형태의 사용자 음성을 수집하는 마이크, 수집된 사용자 음성을 증폭하는 앰프 회로, 증폭된 사용자 음성을 샘플링하여 디지털 신호로 변환하는 A/D 변환회로, 변환된 디지털 신호로부터 노이즈 성분을 제거하는 필터 회로 등과 같은 다양한 구성을 포함할 수 있다. 도 3은 전자 장치에 포함된 위치 인식 모듈을 설명하기 위한 도면이다. 도 3을 참조하면, 전자 장치는 센서부 및 프로세서를 포함할 수 있다. 센서부는 제1 센서 또는 제2 센서 중 적어도 하나를 포함할 수 있다. 제1 센서는 공간 또는 위치를 분석하는 데이터를 센싱하는 센서일 수 있다. 예를 들어, 제1 센서는 라이다 센서일 수 있다. 제2 센서는 이미지를 분석하는 데이터를 센싱하는 센서일 수 있다. 예를 들어, 제2 센서는 이미지 센 서일 수 있다. 프로세서는 위치 분석 모듈, 이미지 분석 모듈 또는 위치 인식 모듈 중 적어도 하나를 포 함할 수 있다. 위치 분석 모듈은 제1 센서를 통해 획득한 제1 센싱 데이터에 기초하여 전자 장치의 위치를 분 석하거나 전자 장치가 위치한 공간을 분석할 수 있다. 분석된 결과 데이터를 제1 결과 데이터로 기재할 수 있다. 이미지 분석 모듈은 제2 센서를 통해 획득한 제2 센싱 데이터에 기초하여 촬영된 이미지에 포함된 특 징 데이터를 획득할 수 있다. 분석된 결과 데이트를 제2 결과 데이터로 기재할 수 있다. 위치 인식 모듈은 위치 분석 모듈을 통해 획득된 제1 결과 데이터 및 이미지 분석 모듈을 통해 획득된 제2 결과 데이터에 기초하여 전자 장치의 위치를 인식(또는 식별)할 수 있다. 다양한 실시 예에 따라, 전자 장치의 센서부는 3D 뎁스 센서 또는 RGB 센서를 포함할 수 있다. 다양한 실시 예에 따라, 전자 장치는 객체 인식 모델, 인식 결과 후처리부, 위치 정보 조장부, 이미지 정 보 저장부, 위치 비교부, 이미지 비교부 중 적어도 하나를 포함할 수 있다. 도 4는 전자 장치의 회전 각도를 설명하기 위한 도면이다. 도 4의 실시 예는 x, y, z축에 따른 회전 방향을 정의한 그래프이다. x축을 기준으로 회전하는 것을 roll 로 정의하고, y축을 기준으로 회전하는 것을 pitch로 정의하고, z축을 기준으로 회전하는 것을 yaw로 정의할 수 있다. 도 4의 실시 예는 전자 장치의 회전 방향을 실시 예에서 정의한 회전 방향으로 설명할 수 있다. 전자 장치의 x축 회전 정보는 전자 장치의 x축에 기초하여 회전하는 roll에 해당할 수 있다. 전자 장치의 y축 회전 정보는 전자 장치의 y축에 기초하여 회전하는 pitch에 해당할 수 있다. 전자 장치의 z축 회전 정보는 전자 장치의 z축에 기초하여 회전하는 yaw에 해당할 수 있다. x축 회전 정보는 제1축 회전 정보, 제1 축 기울기 정보 또는 수평 틀어짐 정보로 기재될 수 있다. y축 회전 정 보는 제2 축 회전 정보, 제2 축 기울기 정보 또는 수직 기울기 정보로 기재될 수 있다. z축 회전 정보는 제3 축 회전 정보, 제3축 기울기 정보 또는 수평 기울기 정보로 기재될 수 있다.센서부는 전자 장치의 상태 정보(또는 기울기 정보)를 획득할 수 있다. 전자 장치의 상태 정보 는 전자 장치의 회전 상태를 의미할 수 있다. 센서부는 중력 센서, 가속도 센서 또는 자이로 센서 중 적어도 하나를 포함할 수 있다. 전자 장치의 x축 회전 정보 및 전자 장치의 y축 회전 정보는 센서부 를 통해 획득된 센싱 데이터에 기초하여 결정될 수 있다. z축 회전 정보는 전자 장치의 움직임에 따라 얼마만큼 회전되었는지 여부에 기초하여 획득될 수 있다. 다양한 실시 예에 따라, z축 회전 정보는 기 설정된 시간 동안 z축으로 얼마만큼 회전되었는지를 나타낼 수 있 다. 예를 들어, z축 회전 정보는 제1 시점을 기준으로 제2 시점에 전자 장치가 z축으로 얼마만큼 회전되었 는지를 나타낼 수 있다. 도 5는 주행 불가 이벤트를 설명하기 위한 도면이다. 도 5의 실시 예를 참조하면, 전자 장치는 바닥에 놓여져 있는 전선 위를 주행할 수 있다. 전선이 바 닥에 존재한 상태에서 전선을 밝고 주행하는 경우, 전자 장치는 이동이 불가능한 상태에 놓여질 수 있다. 도 5의 실시 예를 참조하면, 전자 장치는 커튼 내지 카펫과 같은 면직물과 접촉할 수 있다. 전자 장 치가 이동하면서 바퀴 내지 청소 부재 등에 면직물이 엉키는 경우, 전자 장치는 이동이 불가능한 상 태에 놓여질 수 있다. 도 5의 실시 예를 참조하면, 전자 장치는 고정된 물체(또는 객체)와 접촉할 수 있다. 전자 장치(10 0)는 이동하면서 고정된 물체의 아래 또는 내부로 진입할 수 있으며, 고정된 물체로 인하여 이동이 불가능한 상 태에 놓여질 수 있다. 도 6은 본 개시의 일 실시 예에 따른 주행 불가 이벤트를 등록하는 동작을 설명하기 위한 흐름도이다. 도 6을 참조하면, 전자 장치는 맵 정보 및 주행 경로 정보에 기초하여 주행할 수 있다 (S605). 맵 정보는 전자 장치가 존재하는 공간에 대한 정보를 포함할 수 있다. 맵 정보는 전자 장치가 이동해야 할 공간 에 대한 정보를 포함할 수 있다. 주행 경로 정보는 맵 정보에 기초하여 실제로 전자 장치가 이동하는 경로 와 관련된 정보를 포함할 수 있다. 맵 정보는 공간에 대한 정보를 포함하고, 주행 경로 정보는 전자 장치 의 이동에 대한 정보를 포함할 수 있다. 맵 정보는 글로벌 지도 정보로 기재될 수 있다. 전자 장치는 실시간 주행 정보 및 실시간 촬영 이미지를 획득할 수 있다 (S610). 전자 장치는 실시간 주행 정보 및 실시간 촬영 이미지를 임계 시간 동안 메모리에 저장할 수 있다. 임계 시간은 사용자의 설정 에 변경될 수 있다. 전자 장치는 임계 시간이 경과한 후 실시간 주행 정보 및 실시간 촬영 이미지를 메모 리에서 삭제할 수 있다. 촬영 이미지는 환경 정보에 포함될 수 있다. 주행 정보는 주행 위치 또는 주행 방향 중 적어도 하나를 포함할 수 있다. 주행 위치는 전자 장치가 주행 중 위치하는 좌표를 포함할 수 있다. 예를 들어, 주행 위치는 맵 정보 상에 (x, y) 등의 2차원 좌표 또는 (x, y, z) 등의 3차원 좌표로 기재될 수 있다. 주행 방향은 전자 장치가 주행 중 기 설정된 부분의 방향을 포 함할 수 있다. 주행 방향은 일반적인 주행 시(후진이 아닌 주행 시) 기 설정된 부분(청소 부재가 존재하는 부분 또는 카메라가 존재하는 부분)이 향하는 방향을 포함할 수 있다. 주행 방향은 전자 장치의 헤드 방향으로 기재될 수 있다. 주행 위치 및 주행 방향과 관련된 기준은 도 4 또는 도 11에서 기재한다. 전자 장치는 주행 불가 이벤트가 식별되는지 판단할 수 있다 (S615). 주행 불가 이벤트는 전자 장치 의 주행이 불가능한 상황에 놓여져 있는 이벤트를 포함할 수 있다. 전자 장치는 실시간 주행 정보 또는 실 시간 촬영 이미지 중 적어도 하나에 기초하여 주행 불가 이벤트를 식별할 수 있다. 일 예로, 전자 장치는 실시간 주행 정보에 기초하여 주행 불가 이벤트를 식별할 수 있다. 주행 정보는 주 행 위치 또는 주행 방향 중 적어도 하나를 포함할 수 있다. 전자 장치는 주행 동작을 위해 모터에 구동 명 령을 전송함에도 불구하고 전자 장치의 위치가 임계 시간 동안 변경되지 않는 경우 주행 불가 이벤트가 발 생하였다고 식별할 수 있다. 일 예로, 전자 장치는 실시간 촬영 이미지에 기초하여 주행 불가 이벤트를 식별할 수 있다. 전자 장치 는 임계 시간 동안 획득되는 촬영 이미지가 변경되지 않는 경우 주행 불가 이벤트가 발생하였다고 식별할 수 있다.일 예로, 전자 장치는 실시간 주행 정보 및 실시간 촬영 이미지에 기초하여 주행 불가 이벤트를 식별할 수 있다. 주행 불가 이벤트가 식별되지 않으면 (S615-N), 전자 장치는 실시간 주행 정보 및 실시간 촬영 이미지를 반복하여 획득할 수 있다. 주행 불가 이벤트가 식별되면 (S615-Y), 전자 장치는 임계 시간 동안의 이벤트 정보를 획득할 수 있다 (S620). 이벤트 정보는 이벤트를 등록하는데 이용되는 적어도 하나의 정보를 포함할 수 있다. 전자 장치는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다 (S625). 전자 장치는 임계 시간 동안 획득된 이벤트 정보에 기초하여 전자 장치가 주행이 불가능한 상황을 나타내는 주행 불가 이벤 트를 메모리에 등록(또는 저장)할 수 있다. 이벤트 정보는 복수의 정보를 포함할 수 있다. 이벤트 정보는 임계 시간 동안 획득된 주행 정보 내지 임계 시간 동안 획득된 촬영 이미지 중 적어도 하나를 포함할 수 있다. 도 7은 본 개시의 일 실시 예에 따른 주행 불가 이벤트를 등록하는 동작을 설명하기 위한 흐름도이다. 도 7의 S705, S710, S715, S725 단계는 도 6의 S605, S610, S615, S625 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 주행 불가 이벤트가 식별되면 (S715-Y), 전자 장치는 이벤트 발생 시점에서 임계 시간 이전의 주행 정보 및 촬영 이미지를 이벤트 정보로써 획득할 수 있다. 임계 시간은 사용자의 설정에 따라 달라질 수 있다. 전자 장치는 주행 불가 이벤트가 발생한 위치에서 일부 떨어진 위치에 도달하는 경우 회피를 시도해볼 수 있다. 따라서, 전자 장치는 주행 불가 이벤트가 발생한 위치에 대한 정보가 아닌 이벤트가 발생하기 직전 의 위치에 대한 정보가 필요할 수 있다. 임계 시간은 이벤트가 발생하기 직전을 나타내는 값일 수 있다. 전자 장치는 이벤트가 발생한 시점을 획득(또는 식별)할 수 있다. 전자 장치는 이벤트가 발생한 시점 에서 임계 시간 이전의 시점을 획득(또는 식별 또는 계산)할 수 있다. 이벤트가 발생한 시점을 제1 시점으로 기 재하고, 이벤트가 발생한 시점에서 임계 시간 이전의 시점을 제2 시점으로 기재할 수 있다. 제2 시점은 제1 시 점보다 절대적인 시간이 앞선 시점일 수 있다. 전자 장치는 제1 시점에서 주행 불가 이벤트를 식별할 수 있다. 전자 장치는 제1 시점 및 임계 시간 에 기초하여 제2 시점을 계산할 수 있다. 전자 장치는 제2 시점에 대응되는 주행 정보 또는 제2 시점에 대 응되는 촬영 이미지 중 적어도 하나를 획득할 수 있다. 전자 장치는 제2 시점과 관련된 정보(주행 정보 및 /또는 촬영 이미지)를 이벤트 정보로써 획득할 수 있다. 예를 들어, t=5초 인 시점에 이벤트가 발생하였다고 가정한다. 임계 시간이 2초이면, 전자 장치는 t=3초인 시점의 주행 정보 및 촬영 이미지를 이벤트 정보로써 획득할 수 있다. 이와 관련된 구체적인 설명은 도 11에서 기재한다. 일 실시 예에 따라, 전자 장치는 제1시점과 관련된 정보 (주행 정보 및/또는 촬영 이미지) 및 제2 시점과 관련된 정보(주행 정보 및/또는 촬영 이미지)를 이벤트 정보로써 획득(또는 저장)할 수 있다. 이벤트 정보는 제1 시점과 관련된 정보(주행 정보 및/또는 촬영 이미지) 또는 제2 시점과 관련된 정보(주행 정 보 및/또는 촬영 이미지) 중 적어도 하나를 포함할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 오브젝트를 식별하는 동작을 설명하기 위한 흐름도이다. 도 8의 S805, S810, S815, S820, S825 단계는 도 7의 S705, S710, S715, S720, S725 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 이벤트 발생 시점에서 임계 시점 이전의 주행 정보 및 촬영 이미지를 이벤트 정보로써 획득한 후, 전자 장치 는 촬영 이미지(제2 촬영 이미지)에 기초하여 주행 불가 이벤트와 관련된 오브젝트(또는 타겟 오브젝트)를 이벤트 정보로써 획득(또는 식별)할 수 있다 (S821). 주행 불가 이벤트와 관련된 오브젝트는 타겟 오브젝트 또 는 원인 오브젝트로 기재될 수 있다. 전자 장치는 이미지 분석을 통하여 주행 불가 이벤트와 관련된 오브젝트를 식별할 수 있다. 주행 불가 이 벤트와 관련된 오브젝트는 주행 불가의 원인을 제공하는(또는 유발하는) 오브젝트를 나타낼 수 있다. 주행 불가 이벤트와 관련된 오브젝트는 복수의 오브젝트 중 전자 장치의 주행을 방해할 가능성이 가장 높 은 것으로 판단되는 오브젝트일 수 있다. 전자 장치는 이미지 분석을 위하여 인공 지능 모델을 이용할 수 있다. 전자 장치는 이벤트 정보에 포 함된 촬영 이미지를 입력 데이터로써 인공 지능 모델에 입력할 수 있다. 전자 장치는 촬영 이미지에 포함 된 복수의 오브젝트 중 주행 불가 이벤트와 관련된 오브젝트를 출력 데이터로써 획득할 수 있다. 이벤트 정보는 제1 시점과 관련된 정보(주행 정보 및/또는 촬영 이미지), 제2 시점과 관련된 정보(주행 정보 및 /또는 촬영 이미지) 또는 주행 불가 이벤트와 관련된 오브젝트 중 적어도 하나를 포함할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 오브젝트의 성질을 판단하는 동작을 설명하기 위한 흐름도이다. 도 9의 S905, S910, S915, S920, S921, S925 단계는 도 8의 S805, S810, S815, S820, S821, S825 단계에 대응 될 수 있다. 따라서, 중복 설명을 생략한다. 주행 불가 이벤트와 관련된 오브젝트(타겟 오브젝트)를 획득한 후, 전자 장치는 타겟 오브젝트가 이동 불 가능한 오브젝트인지 식별할 수 있다 (S922). 이동 불가능한 오브젝트는 오브젝트의 성질에 따라 기 설정된 오 브젝트일 수 있다. 이동 불가능한 오브젝트는 기 분류된 오브젝트일 수 있다. 이동 불가능한 오브젝트는 복수 개일 수 있다. 예를 들어, 이동 불가능한 오브젝트는 소파, 책상, 벽, 계단 등을 포함할 수 있다. 타겟 오브젝트가 이동 불가능한 오브젝트가 아니면 (S922-N), 전자 장치는 S910, S915, S920, S921, S922 단계를 반복 수행할 수 있다. 타겟 오브젝트가 이동이 가능하면, 전자 장치는 타겟 오브젝트가 일시적으로 주행 경로 상에 놓여져 있는 오브젝트라고 판단할 수 있다. 전자 장치는 타겟 오브젝트가 다음 주행 시에는 주행 경로 상에 없을 확률 이 높다고 판단할 수 있다. 전자 장치는 해당 이벤트를 별도로 등록할 필요성이 없다고 판단할 수 있다. 타겟 오브젝트가 이동 불가능한 오브젝트이면 (S922-Y), 전자 장치는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다 (S925). 타겟 오브젝트가 이동 불가능한 오브젝트이면, 전자 장치는 다음 주행 시에도 타겟 오브젝트가 주행에 방 해가 될 확률이 높다고 판단할 수 있다. 전자 장치는 해당 이벤트를 등록하여 주행 시 등록된 이벤트를 고 려할 수 있다. 예를 들어, 전자 장치는 해당 이벤트가 발생된 위치를 회피하여 주행할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 이벤트 정보의 기 저장 여부를 판단하는 동작을 설명하기 위한 흐름도이 다. 도 10의 S1005, S1010, S1015, S1020, S1021, S1025 단계는 도 8의 S805, S810, S815, S820, S821, S825 단계 에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 타겟 오브젝트를 이벤트 정보로써 획득한 후, 전자 장치는 이벤트 정보가 기 등록된 정보인지 식별할 수 있다 (S1022). 주행 불가 이벤트가 발생한다고 하여도 이미 메모리에 등록된 이벤트일 수 있다. 전자 장치 는 중복 저장(또는 중복 등록)을 방지하기 위하여 획득된 이벤트 정보가 기 등록되었는지 여부를 판단할 수 있다. 전자 장치는 기 등록된 적어도 하나의 이벤트 정보를 저장할 수 있다. 전자 장치는 복수의 이벤트 정 보를 기 등록한 상태일 수 있다. 새로운 이벤트 정보가 획득되면, 전자 장치는 수신된 이벤트 정보가 기 등록된 이벤트 정보에 포함되는지 여부를 판단할 수 있다. 이벤트 정보가 기 등록된 정보이면 (S1022-Y), 전자 장치는 S1010, S1015, S1020, S1021, S1022 단계를 반복 수행할 수 있다. 이벤트 정보가 기 등록된 정보가 아니면 (S1022-N), 전자 장치는 이벤트 정보에 기초하여 주행 불가 이벤 트를 등록할 수 있다 (S1025). 전자 장치는 주행 불가 이벤트가 새로운 이벤트에 해당하는 경우 관련 정보를 메모리에 등록할 수 있 다. 만약, 기존에 발생된 이벤트와 동일한 이벤트가 발생한 경우, 전자 장치는 별도의 등록 절차를 진행할 필요성이 없을 수 있다. 도 11은 전자 장치에서 실시간으로 획득하는 정보를 설명하기 위한 도면이다. 도 11의 실시 예는 t=1에서 t-5 까지의 전자 장치의 주행을 나타낼 수 있다. 전자 장치는 북쪽 으로 주행하다가 특정 시점에 동족으로 주행 방향을 변경할 수 있다. 전자 장치는 동쪽으로 주행 중 주행 불가 이벤트를 식별할 수 있다. 도 11의 실시 예는 t=1,2,3,4,5 각 시점에서 획득되는 주행 정보 및 촬영 이미지를 나타낼 수 있다. t=1에서, 전자 장치는 좌표(x1, y1)에 위치할 수 있다. t=1에서, 전자 장치의 주행 방향은 정북향일 수 있다. 정북향은 (N) 또는 (N, 0)으로 표현될 수 있다. t=1에서, 전자 장치는 촬영 이미지를 획득 할 수 있다. t=2에서, 전자 장치는 좌표(x2, y2)에 위치할 수 있다. t=2에서, 전자 장치의 주행 방향은 정북향일 수 있다. 정북향은 (N) 또는 (N, 0)으로 표현될 수 있다. t=2에서, 전자 장치는 촬영 이미지를 획득 할 수 있다. t=3에서, 전자 장치는 좌표(x3, y3)에 위치할 수 있다. t=3에서, 전자 장치의 주행 방향은 정동향일 수 있다. 정동향은 (E) 또는 (E, 90)으로 표현될 수 있다. t=3에서, 전자 장치는 촬영 이미지를 획 득할 수 있다. t=4에서, 전자 장치는 좌표(x4, y4)에 위치할 수 있다. t=4에서, 전자 장치의 주행 방향은 정동향일 수 있다. 정동향은 (E) 또는 (E, 90)으로 표현될 수 있다. t=4에서, 전자 장치는 촬영 이미지를 획 득할 수 있다. t=5에서, 전자 장치는 좌표(x5, y5)에 위치할 수 있다. t=5에서, 전자 장치의 주행 방향은 정동향일 수 있다. 정동향은 (E) 또는 (E, 90)으로 표현될 수 있다. t=5에서, 전자 장치는 촬영 이미지를 획 득할 수 있다. 도 12는 이벤트 정보를 설명하기 위한 도면이다. 도 12의 표는 전자 장치가 획득한 이벤트 정보를 나타낼 수 있다. 이벤트 정보는 이벤트가 발생한 시점(제1 시점, t5)과 관련된 정보, 이벤트가 발생한 시점에서 임계 시간 이전의 시점(제2 시점, t3)과 관련된 정보 또는 타겟 오브젝트와 관련된 정보 중 적어도 하나를 포함할 수 있다. 제1 시점과 관련된 정보는 제1 시점의 주행 위치, 제1 시점의 주행 방향, 제1 시점의 촬영 이미지 중 적어도 하 나를 포함할 수 있다. 제2 시점과 관련된 정보는 제2 시점의 주행 위치, 제2 시점의 주행 방향, 제2 시점의 촬영 이미지 중 적어도 하 나를 포함할 수 있다. 도 13은 본 개시의 일 실시 예에 따른 전자 장치 및 서버의 동작을 설명하기 위한 흐름도이다. 도 13의 S1305, S1310, S1315. S1320, S1321 단계는 도 10의 S1005, S1010, S1015. S1020, S1021 단계에 대응 될 수 있다. 따라서, 중복 설명을 생략한다. 주행 정보, 촬영 이미지 또는 타겟 오브젝트 중 적어도 하나를 이벤트 정보로써 획득한 후, 전자 장치는 이벤트 정보를 서버에 전송할 수 있다 (S1321-2). 서버는 전자 장치로부터 이벤트 정보를 수신할 수 있다. 서버는 이벤트 정보가 기 등록된 정보 인지 여부를 판단할 수 있다 (S1322). 서버는 기 등록된 적어도 하나의 이벤트 정보를 저장할 수 있다. 서버는 복수의 이벤트 정보를 기 등 록한 상태일 수 있다. 전자 장치로부터 새로운 이벤트 정보가 수신되면, 서버는 수신된 이벤트 정보 가 기 등록된 이벤트 정보에 포함되는지 여부를 판단할 수 있다. 이벤트 정보가 기 등록된 정보이면 (S1322-Y), 서버는 이벤트 정보의 삭제를 전자 장치에 요청할 수 있다 (S1322-2). 서버는 이벤트 정보를 삭제하기 위한 요청을 전자 장치에 전송할 수 있다. 서버 는 이벤트 정보를 삭제하기 위한 제어 명령을 포함하는 신호를 전자 장치에 전송할 수 있다. 전자 장치는 서버로부터 이벤트 정보의 삭제 요청을 수신할 수 있다. 전자 장치는 이벤트 정보 의 삭제 요청에 기초하여 이벤트 정보를 삭제할 수 있다 (S1322-3). 전자 장치는 이벤트 정보의 삭제 요청 에 응답하여 이벤트 정보를 삭제할 수 있다. 이벤트 정보가 기 등록된 정보가 아니면 (S1322-N), 서버는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다 (S1325). 다양한 실시 예에 따라, 서버는 등록이 완료된 후 전자 장치에서 이벤트 정보를 삭제하는 요청을 전 자 장치에 전송할 수 있다. 도 14는 본 개시의 일 실시 예에 따른 전자 장치, 서버 및 단말 장치의 동작을 설명하기 위한 흐름도이다. 도 14의 S1405, S1410, S1415, S1420, S1421, S1421-2, S1422, S1422-2, S1422-3, S1425 단계는 도 12의 S1205, S1210, S1215, S1220, S1221, S1221-2, S1222, S1222-2, S1222-3, S1225 단계에 대응될 수 있다. 따라 서, 중복 설명을 생략한다. 이벤트 정보가 기 등록된 정보가 아니면 (S1422-N), 서버는 이벤트 화면을 단말 장치에 전송할 수 있 다 (S1422-4). 단말 장치는 사용자에게 전자 장치의 주행과 관련된 다양한 정보를 제공하기 위한 기 기일 수 있다. 예를 들어, 단말 장치는 사용자의 스마트폰, 태블릿 또는 개인 컴퓨터일 수 있다. 단말 장치는 서버로부터 이벤트 화면을 수신할 수 있다. 단말 장치는 이벤트 화면을 단말 장치 의 디스플레이에 표시할 수 있다 (S1422-5). 이벤트 화면은 주행 불가 이벤트를 등록하기 위한 화면을 나 타낼 수 있다. 이벤트 화면은 이벤트 등록 화면 또는 이벤트 등록 가이드 화면으로 기재될 수 있다. 이벤트 화면을 표시한 후, 단말 장치는 이벤트 등록을 위한 사용자 입력의 수신 여부를 판단할 수 있다 (S1422-6). 단말 장치는 이벤트 화면을 통해 이벤트 등록을 위한 사용자 입력이 수신되었는지 여부를 판단 할 수 있다. 이벤트 등록을 위한 사용자 입력이 수신되지 않으면 (S1422-6-N), 단말 장치는 S1422-5, S1422-6 단계를 반복할 수 있다. 이벤트 등록을 위한 사용자 입력이 수신되면 (S1422-6-Y), 단말 장치는 이벤트 등록을 서버에 요청할 수 있다 (S1422-7). 단말 장치는 이벤트 등록을 위한 신호를 서버에 전송할 수 있다. 서버는 단말 장치로부터 이벤트 등록을 위한 요청을 수신할 수 있다. 서버는 이벤트 등록을 위 한 요청이 수신되면, 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다 (S1425). 도 15는 본 개시의 일 실시 예에 따른 이벤트 등록 화면을 설명하기 위한 도면이다. 도 15의 화면은 이벤트 정보를 등록하기 위한 가이드 정보, 이벤트 정보 또는 사용자 입력을 위한 UI (User Interface)(1530, 1540, 1550) 중 적어도 하나를 포함할 수 있다. 가이드 정보는 화면에 포함되는 정보가 이벤트 등록과 관련된 정보를 나타내는 텍스트 또는 이미지 중 적어도 하나를 포함할 수 있다. 이벤트 정보는 전자 장치가 주행 불가 이벤트와 관련하여 이벤트 정보로써 획득한 적어도 하나의 정 보를 포함할 수 있다. 이벤트 정보는 도 12의 표에 대응될 수 있다. UI는 이벤트 정보를 등록하기 위한 UI일 수 있다. UI가 선택되면, 전자 장치는 이벤트 정보 를 등록할 수 있다. UI는 이벤트 정보를 수정하기 위한 UI일 수 있다. UI가 선택되면, 전자 장치는 이벤트 정보 에 포함된 정보를 수정하기 위한 화면을 표시할 수 있다. UI는 이벤트 정보의 등록을 무시하기 위한 UI일 수 있다. UI가 선택되면, 전자 장치는 이벤트 정보를 등록하지 않을 수 있다. 전자 장치는 임시 저장된 이벤트 정보를 삭제할 수 있다. 도 16은 본 개시의 일 실시 예에 따른 이벤트 등록 화면을 설명하기 위한 도면이다. 도 16의 화면은 전자 장치의 정상적인 주행을 위한 가이드 정보, 이벤트 등록과 관련된 정보 중 적어도 하나를 포함할 수 있다. 가이드 정보는 정상적인 전자 장치의 주행을 위해 사용자에게 가이드되는 동작을 포함할 수 있다. 예를 들어, 가이드 정보는 특정 기능(청소)을 위해 타겟 오브젝트(장애물)를 치워달라는 텍스트를 포함할 수 있다.이벤트 등록과 관련된 정보는 이벤트 등록을 진행할 것인지 질의하는 정보, 제2 시점에 대응되는 촬영 이미지, 제1 시점에 대응되는 촬영 이미지, 사용자 입력을 위한 UI (1624, 1625, 1626) 중 적어도 하나를 포함할 수 있다. 이벤트 등록을 진행할 것인지 질의하는 정보는 화면이 사용자에게 이벤트 등록과 관련된 정보 를 나타내는 텍스트 또는 이미지 중 적어도 하나를 포함할 수 있다. 제2 시점에 대응되는 촬영 이미지는 주행 불가 이벤트가 발생한 시점으로부터 임계 시간 이전의 시점에서 촬영된 이미지를 포함할 수 있다. 제1 시점에 대응되는 촬영 이미지는 주행 불가 이벤트가 발생한 시점에서 촬영된 이미지를 포함할 수 있 다. UI는 이벤트 정보를 등록하기 위한 UI일 수 있다. UI가 선택되면, 전자 장치는 이벤트 정보를 등록할 수 있다. UI는 이벤트 정보를 수정하기 위한 UI일 수 있다. UI가 선택되면, 전자 장치는 이벤트 정보 를 수정하기 위한 화면을 표시할 수 있다. UI는 이벤트 정보의 등록을 무시하기 위한 UI일 수 있다. UI가 선택되면, 전자 장치는 이벤트 정보를 등록하지 않을 수 있다. 전자 장치는 임시 저장된 이벤트 정보를 삭제할 수 있다. 도 17은 본 개시의 일 실시 예에 따른 이벤트 사진을 선택하는 동작을 설명하기 위한 도면이다. 도 17의 화면은 최종 등록 과정에 이용되는 촬영 이미지를 선택하기 위한 화면일 수 있다. 화면은 촬영 이미지를 선택할 것을 가이드하기 위한 정보, 사용자가 선택 가능한 적어도 하나의 촬영 이미지를 포함하는 정보 또는 선택 완료를 알리기 위한 UI 중 적어도 하나를 포함할 수 있다. 정보는 최종 등록될 사진을 선택할 것을 가이드하는 텍스트 또는 이미지 중 적어도 하나를 포함할 수 있 다. 정보는 전자 장치가 획득한 복수의 촬영 이미지를 포함할 수 있다. 정보는 전자 장치가 촬영한 복수의 촬영 이미지 중 적어도 하나의 이미지를 포함할 수 있다. 정보에 포함된 복수의 촬영 이미지 중 사용자가 직접 등록될 촬영 이미지를 선택할 수 있다. 촬영 이미지 에 포함된 타겟 오브젝트는 촬영 거리에 따라 외형적인 모습이 상이할 수 있다. 전자 장치는 최종 등록되 는 촬영 이미지에 기초하여 주행할 수 있다. 사용자는 화면을 통해 복수의 이미지 중 타겟 오브젝트가 명확하게 인식된 이미지를 선택할 수 있다. 다양한 실시 예에 따라, 정보에 포함되는 촬영 이미지는 주행 불가 이벤트가 식별된 시점(t=5)부터 임계 시간 이전까지의 시점(t=3) 사이에 획득된 촬영 이미지를 포함할 수 있다. UI는 선택 완료를 나타내는 UI일 수 있다. UI가 선택되면, 정보를 통해 선택된 최종 촬영 이 미지를 등록할 수 있다. 도 18은 본 개시의 일 실시 예에 따른 이벤트 위치를 선택하는 동작을 설명하기 위한 도면이다. 도 18의 화면은 최종 등록 과정에서 이용되는 주행 위치를 선택하기 위한 화면일 수 있다. 화면은 주행 위치를 선택할 것을 가이드하기 위한 정보, 사용자가 선택 가능한 적어도 하나의 주행 위치를 포함 하는 정보 또는 선택 완료를 알리기 위한 UI 중 적어도 하나를 포함할 수 있다. 정보는 주행 불가 이벤트가 발생된 위치를 선택할 것을 가이드하는 텍스트 또는 이미지 중 적어도 하나를 포함할 수 있다. 정보는 전자 장치가 주행한 공간과 관련된 맵을 포함할 수 있다. 전자 장치는 맵에서 나타내는 복수의 위치 중 하나의 위치를 사용자 입력을 통해 획득할 수 있다. 사용자 입력이 수신되면, 전자 장치는 사용자 입력에 의해 선택된 위치를 주행 불가 이벤트가 발생한 주행 위치로 결정할 수 있다. 정보는 전자 장치가 예측(또는 추정)한 주행 불가 이벤트가 발생된 위치를 나타내는 UI(삼각형 안의 느낌표)를 포함할 수 있다. 사용자는 UI를 통해 대략적인 이벤트 발생 위치를 인식할 수 있다. 사용자는 UI를 참고하여 정확한 이 벤트 발생 위치를 직접 선택할 수 있다. 전자 장치는 사용자에 의해 선택(또는 입력)된 이벤트 발생 위치를 획득(또는 수신)할 수 있다. 사용자 입력이 획득되지 않으면, 전자 장치는 예측(또는 추정)된 위치를 최종 이벤트 발생 위치로 결정할 수 있다. UI는 선택 완료를 나타내는 UI일 수 있다. UI가 선택되면, 정보를 통해 선택된 최종 주행 위 치를 등록할 수 있다. 최종 주행 위치는 주행 불가 이벤트가 발생한 위치를 나타낼 수 있다. 최종 주행 위치는 주행 불가 이벤트가 발생한 제1 시점의 주행 위치일 수 있다. 도 19는 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 19의 S1905, S1910 단계는 도 6의 S605, S610 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 도 6 의 실시 예는 전자 장치가 주행 불가 이벤트를 식별하는 실시 예를 나타낸다. 도 19의 실시 예는 주행 불 가 이벤트를 등록한 후 전자 장치가 주행하는 실시 예를 나타낸다. 따라서, S1910 단계에서 획득되는 정보 는 S610 단계에서 획득되는 정보와 획득 시점이 상이할 수 있다. 실시간으로 주행 정보 또는 촬영 이미지 중 적어도 하나를 획득한 후, 전자 장치는 현재 위치(또는 현재 주행 위치 또는 제3 위치)가 기 설정된 위치인지 판단할 수 있다 (S1915). 기 설정된 위치는 등록된 이벤트에 대응되는 위치일 수 있다. 기 설정된 위치는 제2 시점에서의 주행 위치일 수 있다. 제2 시점은 주행 불가 이벤트가 발생한 시점으로부터 임계 시간 이전 시점일 수 있다. 기 설정된 위치는 이벤트 위치, 기 등록된 위치, 기 등록된 이벤트 위치, 이벤트 등록 위치, 이벤트 인접 위치 등으로 기재될 수 있다. 이벤트 위치는 이벤트 발생 위치 또는 이벤트 발생 인접 위치 중 적어도 하나를 포함할 수 있다. 이벤트 위치는 실시 예에 따라 이벤트가 발생한 제1 시점의 위치 또는 이벤트가 발생하기 이전인 제2 시점의 위치 중 적어도 하나를 포함할 수 있다. 전자 장치는 주행 불가 이벤트가 발생하기 직전의 시점(제2 시점)에서 전자 장치가 위치한 좌표를 기 설정된 위치로 등록(또는 저장)할 수 있다. 다양한 실시 예에 따라, 전자 장치는 주행 불가 이벤트가 발생한 시점(제1 시점)에서 전자 장치가 위 치한 좌표를 기 설정된 위치로 등록(또는 저장)할 수 있다. 다양한 실시 예에 따라, 전자 장치는 주행 불가 이벤트가 발생한 시점의 주행 위치( 현재 위치가 기 설정된 위치가 아니면 (S1915-N), 전자 장치는 S1910, S1915 단계를 반복 수행할 수 있다. 현재 위치가 기 설정된 위치이면 (S1915-Y), 전자 장치는 현재 촬영 이미지(또는 제3 촬영 이미지)와 기 설정된 이미지 사이의 유사도를 획득할 수 있다 (S1920). 유사도가 높을수록, 비교 대상의 이미지들이 더 유사 할 수 있다. 전자 장치는 유사도가 임계값 이상인지 여부를 판단할 수 있다 (S1925). 유사도가 임계값 미만이면 (S1922-N), 전자 장치는 S1910, S1915, S1920, S1925 단계를 반복 수행할 수 있다. 다양한 실시 예에 따라, 유사도가 임계값 미만이면 (S1922-N), 전자 장치는 등록된 주행 불가 이벤트를 삭 제할 수 있다. 전자 장치는 기존에 등록된 주행 불가 이벤트가 더 이상 발생하지 않는다고 판단할 수 있다. 이벤트 삭제 동작은 기 등록된 이벤트의 위치에서 임계 횟수 이상 주행 불가 이벤트가 식별되지 않는 경 우 수행될 수 있다. 유사도가 임계값 이상이면 (S1922-Y), 전자 장치는 이벤트 발생 위치를 회피할 수 있다 (S1930). 이벤트 발생 위치는 제1 시점에서의 주행 위치일 수 있다. 이벤트 발생 위치는 제1 위치로 기재될 수 있다. 제1 위치는 주행 불가 이벤트가 발생한 제1 시점에서의 전자 장치의 위치일 수 있다. 기 설정된 위치는 제2 시점에서의 주행 위치일 수 있다. 기 설정된 위치는 제2 위치로 기재될 수 있다. 제2 위 치는 주행 불가 이벤트가 발생한 제1 시점에서 임계 시점 이전의 제2 시점에서의 전자 장치의 위치일 수 있다. 기 설정된 위치는 이벤트 발생 인접 위치로 기재될 수 있다. 다양한 실시 예에 따라, 전자 장치는 인공 지능 모델을 이용하여 이미지들 사이의 유사도를 획득할 수 있 다. 전자 장치는 현재 촬영 이미지와 기 설정된 이미지를 인공 지능 모델에 입력 데이터로써 입력할 수 있 다. 전자 장치는 인공 지능 모델을 통해 현재 촬영 이미지와 기 설정된 이미지 사이의 유사한 정도를 나타내는 결과값을 출력 데이터로써 획득할 수 있다. 도 19의 S1920 단계에서는 제2 촬영 이미지 및 제3 촬영 이미지를 비교하는 것으로 기재하였다. 다양한 실시 예 에 따라, 유사도를 획득함에 있어 복수의 이미지가 이용될 수 있다. 등록된 이벤트에 대응되는 촬영 이미지가 복수 개 일 수 있다. 현재 촬영 이미지 역시 복수 개 일 수 있다. 제2 촬영 이미지는 적어도 하나의 서브 이미 지를 포함할 수 있으며, 제3 촬영 이미지는 적어도 하나의 서브 이미지를 포함할 수 있다. 도 20은 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 20의 S2005, S2010, S2015, S2020, S2025, S2030 단계는 도 19의 S1905, S1910, S1915, S1920, S1925, S1930 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 현재 위치가 기 설정된 위치(제2 위치)이면 (S2015-Y), 전자 장치는 현재 주행 방향(또는 제3 주행 방향) 이 기 설정된 방향과 동일한지 여부를 판단할 수 있다 (S2016). 기 설정된 방향은 제2 시점에서의 전자 장치 의 주행 방향일 수 있다. 기 설정된 방향은 제2 방향으로 기재될 수 있다. 현재 주행 방향이 기 설정된 방향과 동일하지 않으면 (S2016-N), 전자 장치는 S2010, S2015, S2016 단계 를 반복 수행할 수 있다. 현재 주행 방향이 기 설정된 방향과 동일하면 (S2016-Y), 전자 장치는 S2020, S2025, S2030 단계를 수행 할 수 있다. 주행 불가 이벤트가 발생한 시점은 제1 시점으로 기재될 수 있다. 제1 시점에서의 전자 장치의 주행 방향 을 제1 방향(또는 제1 주행 방향)으로 기재할 수 있다. 주행 불가 이벤트가 발생한 제1 시점에서 임계 시간 이전의 시점은 제2 시점으로 기재될 수 있다. 제2 시점에서 의 전자 장치의 주행 방향을 제2 방향(또는 제2 주행 방향)으로 기재할 수 있다. 제2 방향은 기 설정된 방 향으로 기재될 수 있다. 도 21은 이벤트 위치에 대응되는 영역을 이용하여 회피 주행을 수행하는 동작을 설명하기 위한 도면이다. 도 21의 실시 예를 참조하면, 전자 장치는 제1 시점에서의 주행 위치(x5, y5)를 기준으로 이벤트 영 역을 설정할 수 있다. 이벤트 영역은 제1 시점에서의 주행 위치(x5, y5)를 기준으로 임계 거리(r) 이내의 영역을 의미할 수 있다. 전자 장치가 이벤트 영역에 위치하는 것으로 식별되면, 전자 장치는 주행 위치(x5, y5)를 회피 할지 여부를 판단할 수 있다. 전자 장치가 이벤트 영역에 위치하는 것으로 식별되면, 전자 장치 는 현재 촬영 이미지와 기 설정된 이미지(제2 촬영 이미지) 사이의 유사도를 획득하는 동작을 수행할 수 있다. 즉, 전자 장치가 이벤트 영역에 위치하는 것으로 식별되면, 전자 장치는 도 19의 S1925, S1930 단계를 수행할 수 있다. 도 22는 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 22의 S2205, S2210, S2215, S2220, S2225, S2230 단계는 도 19의 S1905, S1910, S1915, S1920, S1925, S1930 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 현재 촬영 이미지와 기 설정된 이미지(제2 촬영 이미지) 사이의 유사도가 임계값 이상이면 (S2225-Y), 전자 장 치는 현재 촬영 이미지에 포함된 오브젝트를 식별할 수 있다 (S2226). 전자 장치는 현재 촬영 이미지 를 분석하여 현재 촬영 이미지에 포함된 적어도 하나의 오브젝트를 식별할 수 있다. 전자 장치는 식별된 적어도 하나의 오브젝트에 기초하여 현재 촬영 이미지에 기 설정된 오브젝트가 포함되 어 있는지 여부를 판단할 수 있다 (S2227). 다양한 실시 예에 따라, 전자 장치는 현재 촬영 이미지를 분석하기 위해 인공지능 모델을 이용할 수 있다. 전자 장치는 현재 촬영 이미지를 인공지능 모델에 입력 데이터로써 입력할 수 있다. 전자 장치는 현 재 촬영 이미지에 포함된 적어도 하나의 오브젝트 각각에 대한 확률값을 출력 데이터로써 획득할 수 있다. 전자 장치는 출력 데이터에 포함된 확률값에 기초하여 현재 촬영 이미지에 포함된 적어도 하나의 오브젝트를 결 정할 수 있다. 전자 장치는 현재 촬영 이미지에 포함된 적어도 하나의 오브젝트가 기 설정된 오브젝트에 해당하는지 여부 를 판단할 수 있다. 기 설정된 오브젝트는 주행 불가 이벤트의 원인이 되는 오브젝트일 수 있다. 기 설정된 오브젝트는 사용자의 설 정에 의해 기 저장된 오브젝트일 수 있다. 기 설정된 오브젝트는 복수 개 일 수 있다. 기 설정된 오브젝트는 타 겟 오브젝트로 기재될 수 있다. 현재 촬영 이미지이 기 설정된 오브젝트가 포함되어 있지 않으면 (S2227-N), 전자 장치는 S2210, S2215, S2220, S2225, S2226, S2227 단계를 반복 수행할 수 있다. 현재 촬영 이미지이 기 설정된 오브젝트가 포함되어 있으면 (S2227-Y), 전자 장치는 이벤트 발생 위치(제1 위치)를 회피하여 주행할 수 있다 (S2230). 도 23은 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 23의 S2305, S2310, S2315, S2330 단계는 도 19의 S1905, S1910, S1915, S1930 단계에 대응될 수 있다. 따 라서, 중복 설명을 생략한다. 도 23의 S2320, S2325 단계는 도 22의 S2226, S2227 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 전자 장치의 현재 위치가 기 설정된 위치(제2 위치)이면 (S2315-Y), 전자 장치는 현재 촬영 이미지에 포함된 오브젝트를 식별할 수 있다 (S2320). 전자 장치는 현재 촬영 이미지에 기 설정된 오브젝트가 포함되어 있는지 여부를 식별할 수 있다 (S2325). 현재 촬영 이미지에 기 설정된 오브젝트가 포함되어 있지 않으면 (S2325-N), 전자 장치는 S2310, S2315, S2320, S2325 단계를 반복 수행할 수 있다. 현재 촬영 이미지에 기 설정된 오브젝트가 포함되어 있으면 (S2325-Y), 전자 장치는 이벤트 발생 위치(제1 위치)를 회피하도록 주행할 수 있다 (S2330). 도 24는 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 24의 S2405, S2410, S2430 단계는 도 19의 S1905, S1910, S1930 단계에 대응될 수 있다. 도 24의 S2415, S2420 단계는 도 19의 S1920, S1925 단계에 대응될 수 있다. 다만, 도 19의 실시 예에서 수행되는 동작들의 순 서와 도 24의 실시 예에서 수행되는 동작들의 순서가 일부 상이할 수 있다. 실시간 주행 정보 및 실시간 촬영 이미지를 획득한 후, 전자 장치는 현재 촬영 이미지와 기 설정된 이미지 (제2 촬영 이미지) 사이의 유사도를 획득할 수 있다 (S2415). 유사도가 임계값 미만이면 (S2420-N), 전자 장치는 S2410, S2415, S2420 단계를 반복 수행할 수 있다. 유사도가 임계값 이상이면 (S2420-Y), 전자 장치는 현재 위치가 기 설정된 위치(제2 위치)인지 판단할 수 있다 (S2425). 현재 위치가 기 설정된 위치이면 (S2425-Y), 전자 장치는 이벤트 발생 위치(제1 위치)를 회피하도록 주행 할 수 있다 (S2430). 현재 위치가 기 설정된 위치가 아니면 (S2425-N), 전자 장치는 사용자에게 알림을 제공할 수 있다 (S2435). 알림이 제공되는 동안 전자 장치는 일시 정지 상태에 있을 수 있다. 알림이 제공되면 사용자는 현재 위치와 관련하여 전자 장치의 주행을 제어할 수 있다. 다양한 실시 예에 따라, 사용자로부터 현재 위치를 주행 불가 이벤트가 발생된 위치로 등록하기 위한 사용자 입 력이 수신되면, 전자 장치는 현재 위치를 등록할 수 있다. 이벤트 등록 후, 전자 장치는 현재 위치를 회피하도록 주행할 수 있다. 다양한 실시 예에 따라, 임계 시간 동안 사용자로부터 어떤 입력이 수신되지 않으면, 전자 장치는 현재 위 치를 주행 불가 이벤트가 발생된 위치로 등록하지 않을 수 있다. 전자 장치는 현재 위치를 회피하도록 주 행할 수 있다. 다양한 실시 예에 따라, 현재 위치가 기 설정된 위치가 아니면 (S2425-N), 전자 장치는 현재 위치를 주행 불가 이벤트가 발생된 위치로 등록할 수 있다. 이벤트 등록 후, 전자 장치는 현재 위치를 회피하도록 주행 할 수 있다.도 25는 본 개시의 일 실시 예에 따른 전자 장치 및 서버의 동작을 설명하기 위한 흐름도이다. 도 25의 S2505, S2510 단계는 도 20의 S2005, S2010 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 실시간 주행 정보 또는 실시간 촬영 이미지 중 적어도 하나를 획득한 후, 전자 장치는 주행 정보 및/또는 촬영 이미지를 서버에 전송할 수 있다 (S2511). 도 25의 S2515, S2516, S2520, S2525 단계는 도 20의 S2015, S2016, S2020, S2025 단계에 대응될 수 있다. 따 라서, 중복 설명을 생략한다. 도 20에서는 해당 동작들이 전자 장치에서 수행되었지만, 도 25에서는 해당 동작들이 서버에서 수행될 수 있다. 서버는 전자 장치로부터 주행 정보 및/또는 촬영 이미지를 수신할 수 있다. 서버는 전자 장치 의 현재 위치가 기 설정된 위치(제2 위치)인지 식별할 수 있다 (S2515). 전자 장치의 현재 위치가 기 설정된 위치이면 (S2515-Y), 서버는 전자 장치의 현재 주행 방향과 기 설정된 방향(제2 방향)이 동일한지 여부를 식별할 수 있다 (S2516). 전자 장치의 현재 주행 방향과 기 설정된 방향(제2 방향)이 동일하면 (S2516-Y), 서버는 현재 촬영 이미지와 기 설정된 이미지(제2 촬영 이미지) 사이의 유사도를 획득할 수 있다 (S2520). 서버는 유사도가 임계값 이상인지 여부를 판단할 수 있다 (S2525). 유사도가 임계값 이상이면 (S2525), 서버는 이벤트 발생 위치에 대한 회피 요청을 전자 장치에 전송 할 수 있다 (S2526). 서버는 이벤트 발생 위치를 회피하기 위한 신호를 전자 장치에 전송할 수 있다. 전자 장치는 서버로부터 이벤트 발생 위치에 대한 회피 요청을 수신할 수 있다. 전자 장치는 수 신된 회피 요청에 기초하여 이벤트 발생 위치(제1 위치)를 회피하도록 주행할 수 있다 (S2530). 도 26은 본 개시의 일 실시 예에 따른 전자 장치, 서버 및 단말 장치의 동작을 설명하기 위한 흐름도이다. 도 26의 S2505, S2510, S2511, . . . , S2526, S2530 단계는 도 25의 S2505, S2510, S2511, . . . , S2526, S2530 단계에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 이벤트 발생 위치에 대한 회피 요청을 전송한 후, 서버는 주행 완료 여부를 판단할 수 있다 (S2535). 주행 이 완료되지 않으면 (S2535-N), 서버는 주행이 완료(또는 정지)될때까지 주행을 계속하여 진행할 수 있다. 주행이 완료되면 (S2535-Y), 서버는 리포트 화면을 단말 장치에 전송할 수 있다 (S2540). 서버(20 0)는 수신된 주행 정보 및/또는 촬영 이미지에 기초하여 리포트 화면을 생성할 수 있다. 서버는 생성된 리 포트 화면을 단말 장치에 전송할 수 있다. 단말 장치는 서버로부터 리포트 화면을 수신할 수 있다. 단말 장치는 리포트 화면을 표시할 수 있다 (S2545). 단말 장치는 회피 위치를 청소하기 위한 사용자 입력이 수신 되었는지를 판단할 수 있다 (S2550). 회피 위치를 청소하기 위한 사용자 입력이 수신되지 않으면 (S2550-N), 단말 장치는 S2545, S2550 단계를 반복 수행할 수 있다. 회피 위치를 청소하기 위한 사용자 입력이 수신되면 (S2550-Y), 단말 장치는 회피 위치에 대한 청소 요청 을 서버에 전송할 수 있다 (S2555). 서버는 단말 장치로부터 회피 위치에 대한 청소 요청을 수신할 수 있다. 서버는 회피 위치에 대 한 청소 요청을 전자 장치에 전송할 수 있다 (S2560). 전자 장치는 서버로부터 회피 위치에 대한 청소 요청을 수신할 수 있다. 전자 장치는 회피 위치 에 대하여 주행을 할 수 있다 (S2565). 사용자는 단말 장치에 표시된 리포트 화면을 통해 회피가 일어난 위치를 파악할 수 있다. 사용자는 회피가 일어난 원인을 제거(예를 들어, 장애물 제거)할 수 있다. 사용자가 전자 장치가 청소하지 않은 영역을 추 가로 청소하길 원할 수 있다. 사용자는 S2550 단계를 통해 추가 청소 명령을 입력할 수 있다. 단말 장치를 통해 사용자 입력이 수신되면, 추가 청소 명령이 전자 장치에 전달될 수 있다. 전자 장치는 사용자명령에 따라 회피가 일어난 위치에 대하여 청소를 시작할 수 있다. 추가 청소 동작이 수행되는 경우, 전자 장치는 회피 동작이 발생했던 위치(또는 영역)에 대해서만 청소 동 작을 수행할 수 있다. 다양한 실시 예에 따라, 도 27 내지 도 30의 리포트 화면은 전자 장치에 표시될 수 있다. 전자 장치 는 디스플레이를 포함할 수 있다. 전자 장치는 내장 디스플레이를 통해 리포트 화면을 표시할 수 있다. 다양한 실시 예에 따라, 도 27 내지 도 30의 리포트 화면은 서버에 표시될 수 있다. 서버는 특정 웹 사이트 주소를 통해 해당 결과 화면을 제공할 수 있다. 다양한 실시 예에 따라, 도 27 내지 도 30의 리포트 화면은 단말 장치에 표시될 수 있다. 단말 장치 는 디스플레이를 포함할 수 있다. 단말 장치는 내장 디스플레이를 통해 리포트 화면을 표시할 수 있다. 도 27은 본 개시의 일 실시 예에 따른 리포트 화면을 설명하기 위한 도면이다. 도 27의 화면은 전자 장치의 주행 결과를 나타내는 화면일 수 있다. 화면은 이동 정보, 주행 결과 정보, 회피 정보, 가이드 정보 중 적어도 하나를 포함할 수 있다. 이동 정보는 전자 장치가 주행한 공간에 대한 맵 정보 및/또는 전자 장치의 주행 경로 정보를 포함할 수 있다. 이동 정보는 맵 정보 상에 회피 동작이 일어난 위치를 나타내는 UI(2711, 2712)를 포함 할 수 있다. 사용자는 UI(2711, 2712)를 통해 회피가 일어난 위치를 쉽게 파악할 수 있다. 회피 원인에 따라 표시되는 UI의 모양이 상이할 수 있다. 제1 원인으로 회피가 발생한 경우, 이동 정보는 해당 위치에 표시되는 제1 모양의 UI를 포함할 수 있다. 제2 원인으로 회피가 발생한 경우, 이동 정보는 해당 위치에 표시되는 제2 모양의 UI를 포함할 수 있다. 주행 결과 정보는 전자 장치가 수행한 동작에 대한 결과 정보를 포함할 수 있다. 예를 들어, 주행 결과 정보는 전자 장치가 청소 동작을 수행한 공간에 대한 정보 및/또는 완료 여부를 포함할 수 있 다. 회피 정보는 전자 장치가 일부 위치(또는 영역)에 대하여 주행을 완료하지 못하고 회피한 결과 정보 를 포함할 수 있다. 예를 들어, 장애물을 회피하기 위해 2개의 위치에 대하여 회피 동작이 이루어짐을 가정한다. 회피 정보는 회피 횟수, 회피 원인, 회피 위치 중 적어도 하나를 포함할 수 있다. 회피 정보는 미완료 결과 정보로 기재될 수 있다. 가이드 정보는 회피 위치에 대한 추가 동작을 가이드하는 정보를 포함할 수 있다. 가이드 정보는 추가 동작을 가이드하는 텍스트, 사용자 입력을 가이드하는 UI(2741, 2742) 중 적어도 하나를 포함할 수 있다. 추가 동작을 가이드하는 텍스트는 추가 보완 동작의 수행 여부를 질의하는 텍스트(예를 들어, 회피된 위치를 다 시 청소할까요?) 및/또는 회피 원인을 제거하도록 가이드하는 텍스트(예를 들어, 청소를 위해 장애물을 치워주 세요)를 포함할 수 있다. UI를 선택하는 사용자 입력이 수신되면, 전자 장치는 추가 보완 동작을 수행할 수 있다. UI를 선택하는 사용자 입력이 수신되면, 전자 장치는 추가 보완 동작을 수행하지 않을 수 있다. 도 28은 본 개시의 일 실시 예에 따른 리포트 화면을 설명하기 위한 도면이다. 도 28의 화면은 전자 장치의 주행 결과를 나타내는 화면일 수 있다. 화면은 이동 정보, 주행 결과 정보, 이벤트 발생 정보, 가이드 정보 중 적어도 하나를 포함할 수 있다. 도 28의 이동 정보, 주행 결과 정보는 도 27의 이동 정보, 주행 결과 정보에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 도 28의 이동 정보는 주행 불가 이벤트를 나타내는 UI를 포함할 수 있다. 주행 불가 이벤트가 식별 되면, 이동 정보는 주행 불가 이벤트가 발생된 위치에 표시되는 UI를 포함할 수 있다. 사용자는 UI를 통해 전체 공간 중 주행 불가 이벤트가 발생한 위치를 쉽게 파악할 수 있다. 이벤트 발생 정보는 주행 중 주행 불가 이벤트가 발생되었는지 여부를 나타내는 정보를 포함할 수 있다. 이벤트 발생 정보는 주행 불가 이벤트의 식별 횟수, 주행 불가 이벤트의 식별 위치 중 적어도 하나를 포 함할 수 있다.가이드 정보는 주행 불가 이벤트를 등록하기 위해 사용자를 가이드하는 정보를 포함할 수 있다. 가이드 정보는 이벤트 등록을 가이드하는 텍스트, 사용자 입력을 가이드하는 UI(2841, 2842, 2843) 중 적어도 하 나를 포함할 수 있다. UI를 선택하는 사용자 입력이 수신되면, 주행 불가 이벤트가 등록될 수 있다. 해당 동작의 주체는, 전자 장치, 서버 또는 단말 장치일 수 있다. UI를 선택하는 사용자 입력이 수신되면, 주행 불가와 관련된 상세 정보가 제공될 수 있다. 상세 정보는 이벤트 정보를 포함할 수 있다. 해당 동작의 주체는, 전자 장치, 서버 또는 단말 장치일 수 있 다. UI를 선택하는 사용자 입력이 수신되면, 이벤트 등록 과정이 더 이상 진행되지 않을 수 있다. 도 29는 본 개시의 일 실시 예에 따른 리포트 화면을 설명하기 위한 도면이다. 도 29의 화면은 전자 장치의 주행 결과를 나타내는 화면일 수 있다. 화면은 이동 정보, 주행 결과 정보, 이벤트 발생 정보, 가이드 정보 중 적어도 하나를 포함할 수 있다. 도 29의 이동 정보, 주행 결과 정보는 도 28의 이동 정보, 주행 결과 정보에 대응될 수 있다. 따라서, 중복 설명을 생략한다. 이동 정보는 등록된 위치에서 회피 동작이 수행되었음을 나타내는 UI(2911, 2912)를 포함할 수 있다. 이동 정보는 등록된 위치에서 더이상 주행 불가 이벤트가 식별되지 않음을 나타내는 UI를 포함할 수 있다. UI(2911, 2912)와 UI는 모양 또는 색상이 상이할 수 있다. 도 29의 UI와 도 28의 UI는 모양 또는 색상이 상이할 수 있다. 주행 불가 이벤트가 발생된 위치가 등록되어 있음을 가정한다. 하지만, 전자 장치의 주행 결과 등록 위치 에서 더 이상 주행 불가 이벤트가 발생하지 않을 수 있다. 더 이상 등록 위치에 이벤트와 관련된 판단 동작(예 를 들어, 도 19의 실시 예)이 필요하지 않을 수 있다. 등록된 이벤트를 삭제하기 위한 알림 정보가 사용자에게 제공될 수 있다. UI를 통해 사용자는 등록된 이벤트를 취소(또는 삭제)할 수 있음을 쉽게 인지할 수 있다. 이벤트 발생 정보는 주행 불가 이벤트의 발생 여부에 대한 정보를 포함할 수 있다. 주행 불가 이벤트가 발생하지 않음을 가정한다. 이벤트 발생 정보는 주행 불가 이벤트가 발생하지 않았음을 나타내는 텍스트 를 포함할 수 있다. 가이드 정보는 등록된 이벤트를 삭제할 것을 가이드하는 텍스트, 사용자 입력을 가이드하는 UI(2941, 2942, 2943) 중 적어도 하나를 포함할 수 있다. UI를 선택하는 사용자 입력이 수신되면, 등록된 이벤트가 삭제되지 않고 유지될 수 있다. UI를 선택하는 사용자 입력이 수신되면, 등록된 이벤트와 관련된 상세 정보가 사용자에게 제공될 수 있다. UI를 선택하는 사용자 입력이 수신되면, 등록된 이벤트는 삭제될 수 있다. 도 29에서는 이벤트의 삭제를 위해 사용자에게 질의하는 실시 예를 설명하였다. 다양한 실시 예에 따라, 사용자 에게 별도로 질의하지 않고 자동으로 등록된 주행 불가 이벤트를 삭제할 수 있다. 전자 장치는 등록된 이 벤트의 기 설정된 위치에 더 이상 주행 불가 이벤트가 식별되지 않으면, 기존 등록된 이벤트를 삭제할 수 있다. 도 30은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 30을 참조하면, 전자 장치의 제어 방법은 복수의 주행 위치 및 복수의 촬영 이미지를 저장하는 단계 (S3005), 주행 불가 이벤트가 식별되면, 주행 불가 이벤트가 발생한 제1 시점을 식별하는 단계 (S3010), 제1 시 점에서 임계 시간 이전의 제2 시점을 식별하는 단계 (S3015), 복수의 주행 위치 중 제2 시점에 대응되는 위치를 획득하는 단계 (S3020), 복수의 촬영 이미지 중 제2 시점에 대응되는 촬영 이미지를 획득하는 단계 (S3025) 및 제2 시점에 대응되는 위치 및 제2 시점에 대응되는 촬영 이미지를 포함하는 이벤트 정보에 기초하여 주행 불가이벤트를 등록하는 단계 (S3030)를 포함할 수 있다. 제어 방법은 제1 시점에 대응되는 제1 위치, 제1 시점에 대응되는 제1 촬영 이미지를 획득하는 단계를 더 포함 하고, 제2 시점에 대응되는 위치는 제2 위치이고, 제2 시점에 대응되는 촬영 이미지는 제2 촬영 이미지이고, 제 2 시점은 제1 시점보다 이전 시점일 수 있다. 제어 방법은 제2 촬영 이미지에 기초하여 주행 불가 이벤트와 관련된 타겟 오브젝트를 식별하는 단계를 더 포함 하고, 등록하는 단계 (S3030)는 제2 위치, 제2 촬영 이미지 및 타겟 오브젝트를 포함하는 이벤트 정보에 기초하 여 주행 불가 이벤트를 등록할 수 있다. 등록하는 단계 (S3030)는 타겟 오브젝트가 이동 불가능한 오브젝트를 나타내는 기 설정된 오브젝트이면, 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다. 등록하는 단계 (S3030)는 제1 위치, 제2 위치, 제1 촬영 이미지 및 제2 촬영 이미지를 포함하는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다. 전자 장치는 제1 센서부 및 제2 센서부를 포함하고, 제어 방법은 제1 센서부를 통해 복수의 주행 위치를 획득하 는 단계 및 제2 센서부를 통해 복수의 촬영 이미지를 획득하는 단계를 더 포함할 수 있다. 제어 방법은 주행 불가 이벤트를 등록한 후, 제3 시점에 대응되는 제3 위치, 제3 시점에 대응되는 제3 촬영 이 미지를 획득하는 단계, 제3 위치가 제2 위치에 대응되면, 제2 촬영 이미지와 제3 촬영 이미지 사이의 유사도를 획득하는 단계, 유사도가 임계값 이상이면, 제3 위치를 회피하도록 주행하는 단계를 더 포함할 수 있다. 제어 방법은 전자 장치가 주행하는 복수의 주행 방향을 획득하는 단계, 제1 시점에 대응되는 제1 방향을 획득하 는 단계 및 제2 시점에 대응되는 제2 방향을 획득하는 단계를 더 포함하고, 등록하는 단계 (S3030)는 제2 위치, 제2 방향 및 제2 촬상 이미지를 포함하는 이벤트 정보에 기초하여 주행 불가 이벤트를 등록할 수 있다. 제어 방법은 제3 시점에 대응되는 제3 방향을 획득하는 단계, 제3 위치가 제2 위치에 대응되면, 제3 주행 방향 이 제2 방향에 대응되는지 여부를 식별하는 단계 및 제3 주행 방향이 제2 방향에 대응되면, 제2 촬영 이미지와 제3 촬영 이미지 사이의 유사도를 획득하는 단계를 더 포함할 수 있다. 제어 방법은 제1 위치를 나타내는 UI(User Interface)를 포함하는 화면을 제공하는 단계를 더 포함할 수 있다. 도 30과 같은 전자 장치의 제어 방법은 도 1, 도 2, 도 3의 구성을 가지는 전자 장치 상에서 실행될 수 있으며, 그 밖의 구성을 가지는 전자 장치 상에서도 실행될 수 있다. 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태로 구현 될 수 있다. 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또는 하 드웨어 업그레이드 만으로도 구현될 수 있다. 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 및 디스플레이 장치 중 적어도 하나의 외부 서버를 통해 수행되는 것도 가능하다. 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프 로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적 (non-transitory) 저장 매체의 형태로 제공될 수 있다. '비일시적'은 저장 매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장 매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그 램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유 사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작 들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생 략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2023-0087911", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2023-0087911", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 2는 도 1의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 3은 전자 장치에 포함된 위치 인식 모듈을 설명하기 위한 도면이다. 도 4는 전자 장치의 회전 각도를 설명하기 위한 도면이다. 도 5는 주행 불가 이벤트를 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 주행 불가 이벤트를 등록하는 동작을 설명하기 위한 흐름도이다. 도 7은 본 개시의 일 실시 예에 따른 주행 불가 이벤트를 등록하는 동작을 설명하기 위한 흐름도이다. 도 8은 본 개시의 일 실시 예에 따른 오브젝트를 식별하는 동작을 설명하기 위한 흐름도이다. 도 9는 본 개시의 일 실시 예에 따른 오브젝트의 성질을 판단하는 동작을 설명하기 위한 흐름도이다. 도 10은 본 개시의 일 실시 예에 따른 이벤트 정보의 기 저장 여부를 판단하는 동작을 설명하기 위한 흐름도이 다. 도 11은 전자 장치에서 실시간으로 획득하는 정보를 설명하기 위한 도면이다. 도 12는 이벤트 정보를 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시 예에 따른 전자 장치 및 서버의 동작을 설명하기 위한 흐름도이다. 도 14는 본 개시의 일 실시 예에 따른 전자 장치 및 서버의 동작을 설명하기 위한 흐름도이다. 도 15는 본 개시의 일 실시 예에 따른 이벤트 등록 화면을 설명하기 위한 도면이다. 도 16은 본 개시의 일 실시 예에 따른 이벤트 등록 화면을 설명하기 위한 도면이다. 도 17은 본 개시의 일 실시 예에 따른 이벤트 사진을 선택하는 동작을 설명하기 위한 도면이다. 도 18은 본 개시의 일 실시 예에 따른 이벤트 위치를 선택하는 동작을 설명하기 위한 도면이다. 도 19는 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 20은 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 21은 이벤트 위치에 대응되는 영역을 이용하여 회피 주행을 수행하는 동작을 설명하기 위한 도면이다. 도 22는 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 23은 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 24는 본 개시의 일 실시 예에 따른 회피 주행을 수행하는 동작을 설명하기 위한 흐름도이다. 도 25는 본 개시의 일 실시 예에 따른 전자 장치 및 서버의 동작을 설명하기 위한 흐름도이다. 도 26은 본 개시의 일 실시 예에 따른 전자 장치 및 서버의 동작을 설명하기 위한 흐름도이다. 도 27은 본 개시의 일 실시 예에 따른 리포트 화면을 설명하기 위한 도면이다. 도 28은 본 개시의 일 실시 예에 따른 리포트 화면을 설명하기 위한 도면이다. 도 29는 본 개시의 일 실시 예에 따른 리포트 화면을 설명하기 위한 도면이다. 도 30은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
