{"patent_id": "10-2022-0035541", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0137732", "출원번호": "10-2022-0035541", "발명의 명칭": "사용자 선호 콘텐트를 생성하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "박재성"}}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 동작 방법에 있어서,이미지 또는 오디오 중 적어도 하나를 포함하는 제1 콘텐트를 획득하는 단계;상기 제1 콘텐트를 특징 검출 모델에 적용하여, 콘텐트의 스타일을 변경하기 위해 이용될 적어도 하나의 특징을검출하는 단계;상기 제1 콘텐트 및 상기 제1 콘텐트의 적어도 하나의 특징을 뉴럴 스타일 트랜스퍼(Neural Style Transfer;NST) 모델에 적용하여, 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성하되, 상기 뉴럴 스타일 트랜스퍼 모델은, 상기 제2 콘텐트에 포함될 이미지 또는 오디오를 결정하고, 상기 제1 콘텐트의 스타일을 변경한 제2 콘텐트를 생성하도록 훈련된 것인, 단계; 및상기 제2 콘텐트를 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 방법은,상기 전자 장치의 사용 이력을 획득하는 단계를 더 포함하고,상기 제2 콘텐트를 생성하는 단계는,상기 전자 장치의 사용 이력을 상기 뉴럴 스타일 트랜스퍼 모델에 더 적용하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 전자 장치의 사용 이력은,상기 전자 장치에서 실행된 애플리케이션들에 관련된 이력, 상기 전자 장치에서 재생된 콘텐트들에 관련된 이력및 상기 전자 장치에 연결되어 사용된 외부 소스들과 관련된 이력 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 방법은,상기 전자 장치가 위치한 공간의 조도 및 색도 중 적어도 하나를 포함하는, 콘텐트 시청 환경 정보를 획득하는단계를 더 포함하고,상기 제2 콘텐트를 생성하는 단계는,상기 콘텐트 시청 환경 정보를 상기 뉴럴 스타일 트랜스퍼 모델에 더 적용하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제1 콘텐트의 적어도 하나의 특징을 검출하는 단계는,상기 제1 콘텐트가 이미지인 경우, 상기 이미지로부터 하나 이상의 주요 객체를 검출하는 단계를 포함하는, 방법.공개특허 10-2023-0137732-3-청구항 6 제5항에 있어서,상기 제1 콘텐트의 적어도 하나의 특징을 검출하는 단계는,사용자 입력에 기초하여 상기 주요 객체를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 뉴럴 스타일 트랜스퍼 모델을 훈련시키기 위한 훈련 데이터는,스타일 이미지, 스타일 오디오, 상기 전자 장치의 사용 이력, 또는 콘텐트 특징 정보, 콘텐트 시청 환경 정보중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 뉴럴 스타일 트랜스퍼 모델은,이미지의 스타일을 변경하는 제1 서브 네트워크 및 오디오의 스타일을 변경하는 제2 서브 네트워크를 포함하고,상기 제1 서브 네트워크와 상기 제2 서브 네트워크 간 가중치 공유를 위해, 상기 제1 서브 네트워크의 적어도일부 레이어가 상기 제2 서브 네트워크의 적어도 일부 레이어와 연결된 것인, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 방법은,상기 제2 콘텐트에 대한 사용자 피드백에 기초하여, 상기 제1 콘텐트에 페어링 된 이미지 또는 오디오를 변경하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 방법은,상기 사용자 피드백에 기초하여 변경된, 제2 콘텐트에 포함되는 상기 이미지-오디오 쌍에 기초하여, 상기 뉴럴스타일 트랜스퍼 모델을 업데이트하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서,통신 인터페이스;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,이미지 또는 오디오 중 적어도 하나를 포함하는 제1 콘텐트를 획득하고,상기 제1 콘텐트를 특징 검출 모델에 적용하여, 콘텐트의 스타일을 변경하기 위해 이용될 적어도 하나의 특징을검출하고,상기 제1 콘텐트 및 상기 제1 콘텐트의 적어도 하나의 특징을 뉴럴 스타일 트랜스퍼(Neural Style Transfer;NST) 모델에 적용하여, 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성하되, 상기 뉴럴 스타일 트랜스퍼 모델은, 상기 제2 콘텐트에 포함될 이미지 또는 오디오를 결정하고, 상기 제1 콘텐트의 스타일을 변경한 제2 콘텐트공개특허 10-2023-0137732-4-를 생성하도록 훈련된 것이며,상기 제2 콘텐트를 출력하는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 전자 장치의 사용 이력을 획득하고,상기 전자 장치의 사용 이력을 상기 뉴럴 스타일 트랜스퍼 모델에 더 적용하는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 전자 장치의 사용 이력은,상기 전자 장치에서 실행된 애플리케이션들에 관련된 이력, 상기 전자 장치에서 재생된 콘텐트들에 관련된 이력및 상기 전자 장치에 연결되어 사용된 외부 소스들과 관련된 이력 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 전자 장치가 위치한 공간의 조도 및 색도 중 적어도 하나를 포함하는, 콘텐트 시청 환경 정보를 획득하고,상기 콘텐트 시청 환경 정보를 상기 뉴럴 스타일 트랜스퍼 모델에 더 적용하는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 콘텐트가 이미지인 경우, 상기 이미지로부터 하나 이상의 주요 객체를 검출하는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,사용자 입력에 기초하여 상기 주요 객체를 결정하는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 뉴럴 스타일 트랜스퍼 모델은,이미지의 스타일을 변경하는 제1 서브 네트워크 및 오디오의 스타일을 변경하는 제2 서브 네트워크를 포함하고,상기 제1 서브 네트워크와 상기 제2 서브 네트워크 간 가중치 공유를 위해, 상기 제1 서브 네트워크의 적어도일부 레이어가 상기 제2 서브 네트워크의 적어도 일부 레이어와 연결된 것인, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제2 콘텐트에 대한 사용자 피드백에 기초하여, 상기 제1 콘텐트에 페어링 된 이미지 또는 오디오를 변경하공개특허 10-2023-0137732-5-는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자 피드백에 기초하여 변경된, 제2 콘텐트에 포함되는 상기 이미지-오디오 쌍에 기초하여, 상기 뉴럴스타일 트랜스퍼 모델을 업데이트하는, 전자 장치."}
{"patent_id": "10-2022-0035541", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2022-0035541", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자 선호 콘텐트를 생성하는 전자 장치 및 그 동작 방법이 제공된다. 상기 방법은, 이미지 또는 오디오 중 적 어도 하나를 포함하는 제1 콘텐트를 획득하는 단계; 상기 제1 콘텐트를 특징 검출 모델에 적용하여, 콘텐트의 스 타일을 변경하기 위해 이용될 적어도 하나의 특징을 검출하는 단계; 상기 제1 콘텐트 및 상기 제1 콘텐트의 적어 도 하나의 특징을 뉴럴 스타일 트랜스퍼 모델에 적용하여, 이미지-오디오 쌍을 포함하는 사용자 선호 제2 콘텐트 를 생성하되, 상기 뉴럴 스타일 트랜스퍼 모델은, 상기 제2 콘텐트에 포함될 이미지 또는 오디오를 결정하고, 상 기 제1 콘텐트의 스타일을 변경한 제2 콘텐트를 생성하도록, 훈련된 것인, 단계; 및 상기 제2 콘텐트를 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0035541", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 사용자 선호 콘텐트를 생성하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0035541", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 인공지능을 활용하는 기술로써, 입력된 이미지를 특정 스타일로 변환하는 이미지 스타일 트랜스퍼 또는, 입력된 오디오를 특정 스타일로 변환하는 오디오 스타일 트랜스퍼 등이 있다. 그러나, 스타일이 변경된 이미지 및 스타일이 변경된 오디오를 함께 이용하고자 하는 경우, 별도로 학습된 이미 지 스타일 트랜스퍼/오디오 스타일 트랜스퍼로 각각으로 인해, 생성된 이미지 및 오디오가 상관관계가 없어 사 용자의 콘텐트 경험 만족도가 저하된다. 또한, 사용자가 오디오 입력 만으로 사용자 선호 이미지/비디오를 생성 하고 싶을 때나, 이미지/비디오 만으로 사용자 선호 오디오를 생성하고 싶은 경우도 존재한다. 사용자 선호도를 반영하고, 이미지-오디오 간 상관도가 높은 스타일 트랜스퍼 및/또는 제너레이터 모델을 통해, 전자 장치의 사용자에게 새로운 콘텐트 경험을 제공하는 것이 요구된다."}
{"patent_id": "10-2022-0035541", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은, 이미지 또는 오디오 중 어느 하나의 입력 콘텐트를 이용하여 이미지-오디오 쌍을 포함하는 사용자 선호 콘텐트를 생성할 수 있는 전자 장치 및 그 동작 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0035541", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 전자 장치가 사용자 선호 콘텐트를 생성하는 방법을 제공할 수 있다. 상기 방법은, 이미지 또는 오디오 중 적어도 하나를 포함하는 제1 콘텐트를 획득하는 단계; 상기 제1 콘텐트를 특징 검출 모델에 적용하여, 콘텐트의 스타일을 변경하기 위해 이용될 적어도 하나의 특징을 검출하는 단계; 상기 제 1 콘텐트 및 상기 제1 콘텐트의 적어도 하나의 특징을 뉴럴 스타일 트랜스퍼(Neural Style Transfer; NST) 모델 에 적용하여, 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성하되, 상기 뉴럴 스타일 트랜스퍼 모델은, 상기 제2 콘텐트에 포함될 이미지 또는 오디오를 결정하고, 상기 제1 콘텐트의 스타일을 변경한 제2 콘텐트를 생성하 도록 훈련된 것인, 단계; 및 상기 제2 콘텐트를 출력하는 단계를 포함할 수 있다. 상기 방법은, 상기 전자 장치의 사용 이력을 획득하는 단계를 더 포함하고, 상기 제2 콘텐트를 생성하는 단계는, 상기 전자 장치의 사용 이력을 상기 뉴럴 스타일 트랜스퍼 모델에 더 적용하는 단계를 포함할 수 있다. 상기 전자 장치의 사용 이력은, 상기 전자 장치에서 실행된 애플리케이션들에 관련된 이력, 상기 전자 장치에서 재생된 콘텐트들에 관련된 이력 및 상기 전자 장치에 연결되어 사용된 외부 소스들과 관련된 이력 중 적어도 하 나를 포함할 수 있다. 상기 방법은, 상기 전자 장치가 위치한 공간의 조도 및 색도 중 적어도 하나를 포함하는, 콘텐트 시청 환경 정 보를 획득하는 단계를 더 포함하고, 상기 제2 콘텐트를 생성하는 단계는, 상기 콘텐트 시청 환경 정보를 상기 뉴럴 스타일 트랜스퍼 모델에 더 적용하는 단계를 포함할 수 있다. 상기 제1 콘텐트의 적어도 하나의 특징을 검출하는 단계는, 상기 제1 콘텐트가 이미지인 경우, 상기 이미지로부 터 하나 이상의 주요 객체를 검출하는 단계를 포함할 수 있다. 상기 제1 콘텐트의 적어도 하나의 특징을 검출하는 단계는, 사용자 입력에 기초하여 상기 주요 객체를 결정하는 단계를 포함할 수 있다. 상기 뉴럴 스타일 트랜스퍼 모델을 훈련시키기 위한 훈련 데이터는, 스타일 이미지, 스타일 오디오, 상기 전자 장치의 사용 이력, 콘텐트 특징 정보, 또는 콘텐트 시청 환경 정보 중 적어도 하나를 포함할 수 있다. 상기 뉴럴 스타일 트랜스퍼 모델은, 이미지의 스타일을 변경하는 제1 서브 네트워크 및 오디오의 스타일을 변경 하는 제2 서브 네트워크를 포함하고, 상기 제1 서브 네트워크와 상기 제2 서브 네트워크 간 가중치 공유를 위해, 상기 제1 서브 네트워크의 적어도 일부 레이어가 상기 제2 서브 네트워크의 적어도 일부 레이어와 연결된 것일 수 있다. 상기 방법은, 상기 제2 콘텐트에 대한 사용자 피드백에 기초하여, 상기 제1 콘텐트에 페어링 된 이미지 또는 오 디오를 변경하는 단계를 더 포함할 수 있다. 상기 방법은, 상기 사용자 피드백에 기초하여 변경된, 제2 콘텐트에 포함되는 상기 이미지-오디오 쌍에 기초하 여, 상기 뉴럴 스타일 트랜스퍼 모델을 업데이트하는 단계를 더 포함할 수 있다. 본 개시의 일 측면에 따르면, 사용자 선호 콘텐트를 생성하는 전자 장치를 제공할 수 있다. 상기 전자 장치는, 통신 인터페이스; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상의 인스 트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 이미 지 또는 오디오 중 적어도 하나를 포함하는 제1 콘텐트를 획득하고, 상기 제1 콘텐트를 특징 검출 모델에 적용 하여, 콘텐트의 스타일을 변경하기 위해 이용될 적어도 하나의 특징을 검출하고, 상기 제1 콘텐트 및 상기 제1 콘텐트의 적어도 하나의 특징을 뉴럴 스타일 트랜스퍼(Neural Style Transfer; NST) 모델에 적용하여, 이미지- 오디오 쌍을 포함하는 제2 콘텐트를 생성하되, 상기 뉴럴 스타일 트랜스퍼 모델은, 상기 제2 콘텐트에 포함될 이미지 또는 오디오를 결정하고, 상기 제1 콘텐트의 스타일을 변경한 제2 콘텐트를 생성하도록 훈련된 것이며, 상기 제2 콘텐트를 출력하는, 전자 장치일 수 있다. 본 개시의 일 측면에 따르면, 전자 장치가 사용자 선호 콘텐트를 생성하는, 전술한 방법들 중 어느 하나를 실행 시키기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다."}
{"patent_id": "10-2022-0035541", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에 서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 사용자 선호 콘텐트를 생성하여 출력하는 예시를 나타내는 도 면이다. 도 1을 참조하면, 일 실시예에 따른 전자 장치는 디스플레이를 포함하여 영상 및/또는 동영상을 출력하는 장치일 수 있다. 예를 들어, 전자 장치는 스마트 TV, 스마트폰, 태블릿 PC, 랩탑 PC, 액자형 디스플레이 등을 포함할 수 있으나, 이에 한정되는 것은 아니며, 전자 장치 디스플레이를 포함하는 다양한 종류 및 형태의 전자 장치로 구현될 수 있다. 또한, 전자 장치는 스피커를 포함하여 오디오를 출력할 수 있다. 일 실시예에 따른 전자 장치는 원본 콘텐트를 획득하고, 원본 콘텐트의 스타일을 변경한 이미지-오디오 쌍 콘텐트를 생성할 수 있다. 예를 들면, 전자 장치는 원본 콘텐트인 이미지를 획득하고, 획득한 이미지의 특징에 기초하여, 이미지에 사용자 선호 스타일이 반영된, 결과 이미지를 생성할 수 있 다. 또한, 전자 장치는 원본 콘텐트인 이미지에 대응하는 오디오를 결정할 수 있다. 전자 장치 는 오디오의 특징에 기초하여, 오디오에 사용자 선호 스타일이 반영된, 결과 오디오를 생성할 수 있 다. 이하에서는, 원본 이미지, 즉, 스타일이 변경되기 전의 콘텐트를 제1 콘텐트라고 지칭한다. 또한, 결 과 이미지 및 결과 오디오의 이미지-오디오 쌍을 제2 콘텐트라고 지칭한다. 도 1에서는 제1 콘텐트가 이미지인 것으로 도시 되었으나, 제1 콘텐트는 오디오일 수도 있다. 이 경우에도, 전자 장치는 사용 자 선호 스타일이 반영된, 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성할 수 있다. 일 실시예에서, 전자 장치는 뉴럴 스타일 트랜스퍼 모델을 이용하여, 결과 이미지 및 결과 오디오 를 포함하는 제2 콘텐트를 생성할 수 있다. 뉴럴 스타일 트랜스퍼 모델은, 이미지 또는 오디오의 원본 콘텐트를 포함하는 제1 콘텐트가 특정 스타일을 가지 도록, 기 학습된 스타일들을 제1 콘텐트로 이전시키는, 인공지능 모델일 수 있다. 즉, 뉴럴 스타일 트랜스퍼 모 델은, 입력된 제1 콘텐트의 내용물을 포함하되, 새로운 스타일을 갖는 제2 콘텐트를 생성하는 인공지능 모델이 다. 또한, 뉴럴 스타일 트랜스퍼 모델은, 후술하는 실시예들에 따라 사용자 선호 스타일들을 학습한 인공지능 모델일 수 있다. 다시 도 1을 참조하여 설명하면, 입력된 제1 콘텐트인 이미지의 내용물은 ‘사슴’ 이며, 제2 콘텐트의 결 과 이미지는 ‘사슴’ 이미지에 새로운 스타일이 적용된 이미지이다. 한편, 제2 콘텐트의 결과 오디오 는, 원본 오디오에 새로운 스타일이 적용된 오디오이다. 이 경우, 스타일 변경 전의 원본 오디오는, 제1 콘텐트인 이미지의 내용물인 ‘사슴’에 기초하여, ‘사슴’과 상관관계가 높은 것으로 기 학습된 오디오 가 선택된 것일 수 있다. 개시된 실시예들에 따르면, 원본 콘텐트에 대응하여 사용자 선호도가 반영된 새로운 콘텐트를 획득할 수 있다. 또한, 개시된 실시예들에 따르면, 원본 콘텐트가 이미지만을 포함하는 경우에도 이에 대응하여 사용자 선호도가 반영된 이미지-오디오 콘텐트를 획득할 수 있다. 또한, 개시된 실시예들에 따르면, 원본 콘텐트가 오디오 만을 포함하는 경우에도 이에 대응하여 사용자 선호도가 반영된 이미지-오디오 콘텐트를 획득할 수 있다. 전자 장치가 제1 콘텐트를 획득하여 사용자 선호 스타일을 적용함으로써, 이미지-오디오 쌍의 제2 콘텐트 를 생성하기 위한 구체적인 동작들에 대해서는, 후술하는 도면들과 그에 대한 설명에서 더 상세하게 서술하기로 한다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 콘텐트를 생성하는 방법을 설명하기 위한 흐름도이다. 단계 S210에서, 일 실시예에 따른 전자 장치는 이미지 또는 오디오 중 적어도 하나를 포함하는 제1 콘텐 트를 획득한다. 일 실시예에서, 제1 콘텐트는 전자 장치에 의해 콘텐트의 스타일이 변경되기 전의 원본 콘텐트일 수 있다. 전자 장치의 사용자가 사용자의 선호하는 스타일을 반영하여 새로운 콘텐트인 제2 콘텐트를 생성하 고자 하는 경우, 제1 콘텐트는 변경될 콘텐트에 해당한다. 제2 콘텐트는, 사용자의 선호 스타일을 반영하여 제1 콘텐트에 기초하여 생성된 콘텐트로, 이미지-오디오 쌍을 포함한다. 일 실시예에서, 제1 콘텐트는 이미지 또는 오디오 중 어느 하나일 수 있다. 일부 실시예에서, 전자 장치 는 이미지 콘텐트를 제1 콘텐트로서 획득하고, 획득된 이미지 콘텐트에 기초하여 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성할 수 있다. 일부 실시예에서, 전자 장치는 오디오 콘텐트를 제1 콘텐트로서 획득하고, 획득된 오디오 콘텐트에 기초하여 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성할 수 있다. 일 실시예에서, 제1 콘텐트는 이미지 및 오디오일 수 있다. 일부 실시예에서, 전자 장치는 이미지 및 오 디오를 포함하는 콘텐트(예를 들어, 비디오 등)에 대하여, 이미지 및 오디오 중 어느 하나를 선택하는 사용자 입력에 기초하여, 선택된 이미지 또는 오디오를 제1 콘텐트로서 획득하고, 이미지-오디오 쌍을 포함하는 제2 콘 텐트를 생성할 수 있다. 일부 실시예에서, 전자 장치는 이미지 콘텐트 및 오디오 콘텐트를 제1 콘텐트로 서 획득하고, 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성할 수 있다. 일 실시예에서, 전자 장치는 전자 장치에서 현재 재생 중인 콘텐트를 제1 콘텐트로 획득할 수 있다. 전자 장치는 전자 장치에서 현재 재생 중인 이미지 또는 오디오 중 적어도 하나를 제1 콘텐 트로 식별할 수 있다. 일부 실시예에서, 전자 장치는 과거 특정 시점에 재생되었던 콘텐트를 제1 콘텐트 로 획득할 수 있다. 예를 들어, 전자 장치는 가장 최근에 재생되었던 콘텐트를 제1 콘텐트로 획득할 수있다. 일 실시예에서, 전자 장치는 사용자 입력에 기초하여 제1 콘텐트를 획득할 수 있다. 전자 장치는 이미지 또는 오디오 중 적어도 하나를 입력하는 사용자 입력에 기초하여, 제1 콘텐트를 획득할 수 있다. 일 실시예에서, 전자 장치는 외부 장치(예를 들어, 외부 서버)로부터 제1 콘텐트를 획득할 수 있다. 단계 S220에서, 일 실시예에 따른 전자 장치는 제1 콘텐트를 특징 검출 모델에 적용하여, 콘텐트의 스타 일을 변경하기 위해 이용될 적어도 하나의 특징을 검출한다. 본 개시에서, 특징 검출 모델은 콘텐트 특징 검출 모델로 지칭될 수도 있다. 일 실시예에서, 특징 검출 모델은 콘텐트 내의 두드러진(salient) 객체, 패턴 등의 특징을 검출하기 위한 인공 지능 모델일 수 있다. 전자 장치에는 콘텐트의 종류에 따른 콘텐트의 특징을 검출하기 위한, 다양한 종류 의 특징 검출 모델이 저장되어 있을 수 있다. 예를 들어, 제1 콘텐트가 이미지인 경우, 특징 검출 모델은 이미 지 내에서 주요 객체 등의 특징을 검출하는 모델일 수 있다. 예를 들어, 제1 콘텐트가 오디오인 경우, 특징 검 출 모델은 오디오의 주요 주파수 대역폭 등의 특징을 검출하는 모델일 수 있다. 일부 실시예에서, 주요 객체가 하나 이상인 경우, 전자 장치는 사용자 입력에 기초하여 주요 객체를 결정할 수 있다. 단계 S230에서, 일 실시예에 따른 전자 장치는 제1 콘텐트 및 제1 콘텐트의 적어도 하나의 특징을 뉴럴 스타일 트랜스퍼(Neural Style Transfer; NST) 모델에 적용하여, 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생 성한다. 일 실시예에서, 뉴럴 스타일 트랜스퍼 모델은, 입력된 콘텐트가 특정 스타일을 가지도록, 기 학습된 스타일 콘 텐트들의 스타일을 입력된 대상 콘텐트(즉, 제1 콘텐트)로 이전시키는, 인공지능 모델일 수 있다. 즉, 뉴럴 스 타일 트랜스퍼 모델은, 입력된 콘텐트의 내용물을 포함하되, 새로운 스타일을 갖는 새로운 콘텐트(즉, 제2 콘텐 트)를 생성하는 인공지능 모델이다. 뉴럴 스타일 트랜스퍼 모델은, 사용자의 콘텐트 선호도를 반영하여 콘텐트의 스타일을 변경하도록 훈련된 모델 일 수 있다. 즉, 뉴럴 스타일 트랜스퍼 모델은, 제1 콘텐트를 입력 받아, 사용자의 선호도를 반영하여 스타일이 변경되며, 이미지-오디오 쌍을 포함하는, 제2 콘텐트를 생성하도록 훈련된 모델일 수 있다. 뉴럴 스타일 트랜스 퍼 모델은, 이미지의 스타일을 변경하는 제1 서브 네트워크와 오디오의 스타일을 변경하는 제2 서브 네트워크를 포함할 수 있다. 이 경우, 상관관계가 높은 이미지-오디오 쌍을 생성하기 위해, 뉴럴 스타일 트랜스퍼 모델의 제1 서브 네트워크의 일부 레이어 및 제2 서브 네트워크의 일부 레이어가 연결되어 가중치를 공유할 수 있다. 일부 실시예에서, 뉴럴 스타일 트랜스퍼 모델은, 복수개의 모델들로 구성될 수 있다. 예를 들어, 뉴럴 스타일 트랜스퍼 모델은 이미지의 스타일을 변경하는 제1 모델과 오디오의 스타일을 변경하는 제2 모델로 구성될 수 있 다. 일 실시예에서, 전자 장치는 뉴럴 스타일 트랜스퍼 모델을 이용하여, 제2 콘텐트에 포함될 이미지 또는 오디오를 결정할 수 있다. 예를 들어, 제1 콘텐트가 이미지인 경우, 이미지에 대응하는 오디오를 결정할 수 있 다. 또한, 제1 콘텐트가 오디오인 경우, 오디오에 대응하는 이미지를 결정할 수 있다. 전자 장치는 제1 콘텐트에 대응하는 다른 콘텐트를 결정함으로써 이미지-오디오 쌍을 결정하고, 뉴럴 스타일 트랜스퍼 모델을 통 해 스타일 변환된, 제2 콘텐트를 생성할 수 있다. 한편, 일부 실시예에서, 전자 장치는 생성된 제2 콘텐 트를 대체 불가능 토큰(Non-Fungible Token; NFT)으로 블록 체인 네트워크에 기록함으로써, 디지털 아트 작품을 생성할 수 있다. 단계 S240에서, 일 실시예에 따른 전자 장치는 제2 콘텐트를 출력한다. 일 실시예에서, 제2 콘텐트는 이미지-오디오 쌍을 포함한다. 일 실시예에 따른 전자 장치는 디스플레이를 통해 이미지를 출력하고, 스피커를 통해 오디오를 출력할 수 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트를 생성하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 제1 콘텐트를 획득하고, 제1 콘텐트를 기초로 스타일화(stylization)된 이미 지-오디오 쌍을 포함하는, 제2 콘텐트를 생성한다. 도 3을 설명함에 있어서, 설명의 편의를 위해 제1 콘텐트가 이미지인 경우를 예시로 설명한다. 다만 제1 콘텐트는 이에 한정되는 것은 아니며, 오디오, 비디오 등 다 양한 미디어 콘텐트일 수 있다. 일 실시예에서, 전자 장치는 제1 콘텐트로서 이미지를 획득한다. 전자 장치는 이미지를 특징 검출 모델에 적용하여, 적어도 하나의 이미지 특징을 검출할 수 있다. 이미지 특징은 예를 들어, 이미지의 색조, 이미지 내의 주요 객체의 종류, 위치, 크기 및 서브 객체의 종류, 위치, 크기 등을 포함할 수 있으나, 이 에 한정되는 것은 아니다. 예를 들어, 전자 장치는 특징 검출 모델을 이용하여, 이미지 내의 주요 객체인 ‘사슴’을 이미지의 특징으로 검출할 수 있다. 일부 실시예에서, 주요 객체가 하나 이상인 경우, 전자 장치는 사용자 입력에 기초하여 상기 주요 객체를 결정할 수 있다. 일 실시예에서, 전자 장치는 제1 콘텐트에 대응하는 콘텐트를 결정하여, 이미지-오디오 쌍을 획득할 수 있다. 일부 실시예에서, 전자 장치는 뉴럴 스타일 트랜스퍼 모델을 이용하여, 제1 콘텐트에 대응하는 콘 텐트를 결정할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델은 이미지-오디오 간 상관 관계를 학습한, 이미지- 오디오 간 결합 가중치를 포함할 수 있다. 예를 들어, 제1 콘텐트가 이미지 이므로, 전자 장치는 복 수의 오디오들 중에서 이미지에 대응하는 오디오를 결정할 수 있다. 일 실시예에서, 전자 장치는 뉴럴 스타일 트랜스퍼 모델을 이용하여, 사용자의 선호 스타일이 반영된 제2 콘텐트를 생성할 수 있다. 제2 콘텐트는, 결과 이미지 및 결과 오디오, 즉, 이미지-오디오 쌍을 포함 한다. 제2 콘텐트의 결과 이미지는, 뉴럴 스타일 트랜스퍼 모델이 학습한 복수의 사용자 선호 이미지 스타일들 중에서 어느 하나가 이미지에 적용된 것이다. 예를 들어, 복수의 사용자 선호 이미지 스타일 중에서, 어느 한 이미지 스타일이 적용될 수 있다. 이 경우, 이미지의 특징인 ‘사슴’이 스타일이 적용될 대상 콘 텐트이며, 이미지 스타일은 ‘사슴’을 포함하는 결과 이미지에서 표현될 스타일이다. 제2 콘텐트의 결과 오디오는, 뉴럴 스타일 트랜스퍼 모델이 학습한 복수의 사용자 선호 오디오 스타일 중 에서 어느 하나가 오디오에 적용된 것이다. 예를 들어, 복수의 사용자 선호 오디오 스타일 중에서, 어느 한 오디오 스타일이 적용될 수 있다. 일부 실시예에 따른 전자 장치는 생성된 제2 콘텐트를 대체 불가능 토큰(Non-Fungible Token; NFT)으로 블록 체인 네트워크에 기록함으로써, 디지털 아트 작품을 생성할 수 있다. 전자 장치는 제2 콘텐트에 대 한 NFT를 생성함으로써, 사용자 선호 스타일이 반영된 제2 콘텐트가 사용자의 소유임이 증명되도록 할 수 있다. 일 실시예에 따른 전자 장치는 이미지 또는 오디오 중 적어도 하나를 포함하는 제1 콘텐트를 획득하고, 사용자 선호 스타일이 반영된 이미지-오디오 쌍을 포함하는 제2 콘텐트를 출력할 수 있다. 예를 들어, 전자 장 치는 결과 이미지를 디스플레이를 통해 출력하고, 결과 오디오를 스피커를 통해 출력할 수 있 다. 전자 장치가 콘텐트에 사용자 선호 스타일을 적용하는 구체적인 동작들에 대해서는, 후술하기로 한다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 인공지능 모델들을 이용하여 제1 콘텐트로부터 제2 콘텐트를 생성하는 과정을 도시한 도면이다. 일 실시예에 따른 전자 장치는 제1 콘텐트를 획득할 수 있다. 제1 콘텐트는 이미지 또는 오디 오 중 적어도 하나일 수 있다. 일 실시예에 따른 전자 장치는 콘텐트 특징 검출 모델을 이용하여, 제1 콘텐트를 콘텐트 특징 검출 모델에 적용함으로써 콘텐트 특징 검출 모델로부터 출력되는, 제1 콘텐트의 적어도 하나의 특징을 획득할 수 있다. 예를 들어, 제1 콘텐트가 이미지인 경우, 콘텐 트 특징 검출 모델은 이미지 내에서 주요 객체 등의 특징을 검출할 수 있다. 이 경우, 검출된 콘텐트의 적 어도 하나의 특징은, 뉴럴 스타일 트랜스퍼 모델이 이미지의 스타일을 변경할 때 주요 객체를 기준으로 스타일 을 변경하도록 이용될 수 있다. 또는, 제1 콘텐트가 오디오인 경우, 콘텐트 특징 검출 모델은 오디오 의 주요 주파수 대역폭 등의 특징을 검출하는 모델일 수 있다. 이 경우, 검출된 콘텐트의 적어도 하나의 특징은, 뉴럴 스타일 트랜스퍼 모델이 오디오의 스타일을 변경할 때 주요 주파수 대역폭을 기준으로 스타일을 변경하도록 이용될 수 있다. 일 실시예에 따른 전자 장치는 뉴럴 스타일 트랜스퍼 모델을 이용하여, 제2 콘텐트를 생성할 수 있다. 제2 콘텐트는 이미지-오디오 쌍을 포함하며, 제1 콘텐트의 특징을 일정 정도 유지한 채 새 로운 스타일을 적용한 것일 수 있다. 예를 들어, 제1 콘텐트가 이미지인 경우, 전자 장치는 제1 콘 텐트에 대응하는 오디오 콘텐트를 결정하고, 제1 콘텐트(이미지) 및 제1 콘텐트에 대응하는 콘텐트 (오디오)의 스타일을 변경한, 제2 콘텐트를 생성할 수 있다. 다른 예에서, 제1 콘텐트가 오디오인 경우, 전자 장치는 제1 콘텐트에 대응하는 이미지 콘텐트를 결정하고, 제1 콘텐트(오디오) 및 제1 콘 텐트에 대응하는 콘텐트(이미지)의 스타일을 변경한, 제2 콘텐트를 생성할 수 있다.일 실시예에서, 뉴럴 스타일 트랜스퍼 모델을 통해 생성된 제2 콘텐트는, 사용자의 선호도가 반영된 콘텐트이다. 일 실시예에서, 전자 장치는 전자 장치의 사용 이력(실행된 애플리케이션, 재생된 콘텐트 등)에 기 초하여, 사용자 선호 스타일을 적용한 제2 콘텐트를 생성할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델(43 0)은, 전자 장치의 사용 이력으로부터 식별된 사용자 선호 스타일을 학습한 모델일 수 있다. 일 실시예에서, 전자 장치는 전자 장치가 위치한 공간의 조도 및 색도를 포함하는, 콘텐트 시청 환 경 정보에 기초하여, 사용자 선호 스타일을 적용한 제2 콘텐트를 생성할 수 있다. 일부 실시예에서, 전자 장치 는 별도의 센서로부터 센싱된 조도 및 색도를 수신하거나, 사용자 입력에 기초하여 조도, 색도 등을 획득 함으로써 콘텐트 시청 환경 정보를 획득할 수 있다. 전자 장치는 전자 장치의 콘텐트 시청 환경 정 보에 기초하여, 콘텐트 시청 환경과 스타일이 유사(예를 들어, 유사한 조도, 유사한 색도 등)한, 사용자 선호 스타일을 적용한 제2 콘텐트를 생성할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델은, 전자 장치 의 콘텐트 시청 환경과 대응될 수 있는, 사용자 선호 스타일을 학습한 모델일 수 있다. 한편, 콘텐트 시청 환경 정보는 전술한 예시에 한정되지 않으며, 전자 장치의 주변 온도, 날씨, 주변 소음, 시간 등의 다양한 정 보를 포함할 수 있다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 제1 콘텐트의 특징을 검출하는 방법을 설명하기 위한 흐름도이 다. 단계 S510에서, 일 실시예에 따른 전자 장치는 제1 콘텐트의 종류를 식별한다. 전자 장치는 제1 콘 텐트가 이미지인지, 오디오인지, 혹은 이미지 및 오디오 모두인지(예를 들어, 비디오 등) 여부를 식별할 수 있 다. 단계 S510은, 도 2의 단계 S210이 수행된 이후에 수행될 수 있다. 단계 S520에서, 일 실시예에 따른 전자 장치는 제1 콘텐트의 종류에 대응하는 콘텐트 특징 검출 모델을 선택한다. 일 실시예에서, 전자 장치는 제1 콘텐트의 종류가 이미지인 경우, 이미지 내에서 적어도 하나의 특징을 검출하기 위한 콘텐트 특징 검출 모델을 선택할 수 있다. 이미지의 특징은 이미지의 색조, 이미지 내의 주요 객 체의 종류, 위치, 크기 및 서브 객체의 종류, 위치, 크기 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 제1 콘텐트의 종류가 오디오인 경우, 오디오 내에서 적어도 하나의 특징을 검출하기 위한 콘텐트 특징 검출 모델을 선택할 수 있다. 오디오의 특징은, 오디오의 장르, 오디오의 주요 주파 수 대역폭, 소리 크기(loudness), 스펙트럼 평탄도(spectral flatness), 스펙트럼 불규칙도(spectral irregularity), 음높이(pitch), 시간 영역의 변조(modulation in the temporal domain)(rate), 주파수 영역의 변조(modulation in the frequency domain)(scale) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 제1 콘텐트의 종류가 이미지 및 오디오 모두(예를 들어, 비디오 등)인 경우, 이미지의 특징 검출 및 오디오의 특징 검출을 위한 콘텐트 특징 검출 모델들을 각각 선택할 수 있다. 일부 실시 예에서, 제1 콘텐트가 이미지 및 오디오 모두를 포함하고, 이미지 및 오디오 중 어느 하나를 선택하는 사용자 입력이 수신되는 경우, 전자 장치는 사용자 입력에 대응되는 콘텐트에 대하여 특징을 검출하기 위한 콘텐 트 특징 검출 모델을 선택할 수 있다. 도 6a는 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 이미지 콘텐트 특징 검출 모델의 일 예를 도시한 도면이다. 일 실시예에서, 이미지 콘텐트 특징 검출 모델은, 이미지로부터 이미지 특징을 검출할 수 있다. 이미 지 특징은 이미지의 색조, 이미지 내의 주요 객체의 종류, 위치, 크기 및 서브 객체의 종류, 위치, 크기 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 도 6a에서는, 이미지 특징으로, 이미지 내 객체의 영 역을 검출하는, 돌출 맵을 검출하는 모델을 예시로 설명한다. 다만, 후술하는 이미지 콘텐트 특징 검출 모델은 예시일 뿐이며, 이미지 콘텐트 특징 검출 모델은 전술한 이미지 특징 중 적어도 하나를 검출하기 위한 다 양한 아키텍처의 인공지능 모델이 사용될 수 있다. 일 예에 따른 이미지 콘텐트 특징 검출 모델은, 돌출 예측기(Saliency Predictor) 및 적대적 네트워크 (Adversarial Network)를 포함할 수 있다. 돌출 예측기는 이미지를 입력 받아, 돌출 맵(saliency map)을 출력한다. 돌출 예측기는 돌출 예측기로부터 예측된 돌출 맵이 정답 돌출 맵에 가깝게 예측되도록 훈련된다. 돌출 예측기는 적어도 풀링(pooling), 컨볼루션(convolution), 연결(concatenation) 연산을 수행하는 컨볼루션 모듈을 포 함할 수 있다. 돌출 예측기는 예측된 돌출 맵이 실제로는 정답 돌출 맵이 아니지만, 이미지 콘 텐트 특징 검출 모델을 훈련시키기 위해, 예측된 돌출 맵을 정답 돌출 맵으로 레이블링하고, 적대적 네트워크가 정답 돌출 맵으로 레이블링 된 예측된 돌출 맵을 판별하도록 할 수 있다. 적대적 네트워크는 이미지를 입력 받으며, 돌출 예측기로부터 예측된 돌출 맵 또는 정답 (ground truth) 돌출 맵 중 하나를 입력 받아, 입력된 데이터가 예측된 돌출 맵인지 정답 돌출 맵 인지 여부를 판별하도록 훈련된다. 적대적 네트워크는 Adversarial Loss에 기초하여 적대적 네트워크 의 가중치들을 업데이트할 수 있다. 일 예에 따른 이미지 콘텐트 특징 검출 모델은, 돌출 예측기 및 적대적 네트워크를 훈련시킴으로써, Saliency Loss를 계산하고, Saliency Loss에 기초하여 이미지 콘텐트 특징 검출 모델의 가중치들을 업데이트할 수 있다. 이 경우, 학습이 완료된 이미지 콘텐트 특징 검출 모델은, 이미지로부터 이미지 특징인 '돌 출 맵'을 획득할 수 있다. 일부 실시예에서, 획득된 이미지 특징은, 스타일화(stylization)의 적용 대상이 되는 내용물(content)로써 이용될 수 있다. 일부 실시예에서, 획득된 이미지 특징은, 제1 콘텐트에 적용될 스타일을 결정하기 위한 데이터로 이용될 수 있다. 도 6b는 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 오디오 콘텐트 특징 검출 모델의 일 예를 도시한 도면이다. 일 실시예에서, 오디오 콘텐트 특징 검출 모델은, 오디오로부터 오디오 특징을 검출할 수 있다. 오디오 특징은, 오디오의 장르, 오디오의 주요 주파수 대역폭, 소리 크기(loudness), 스펙트럼 평탄도 (spectral flatness), 스펙트럼 불규칙도(spectral irregularity), 음높이(pitch), 시간 영역의 변조 (modulation in the temporal domain)(rate), 주파수 영역의 변조(modulation in the frequency domain)(scale) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 도 6b에서는, 오디오 콘텐트 특징 검출 모 델로써, 컨볼루션 뉴럴 네트워크를 예시로 설명한다. 다만, 후술하는 오디오 콘텐트 특징 검출 모델은 예시일 뿐이며, 오디오 콘텐트 특징 검출 모델은 전술한 오디오 특징 중 적어도 하나를 검출하기 위한 다양한 아 키텍처의 인공지능 모델이 사용될 수 있다. 일 예에 따른 오디오 특징 검출 모델은, 적어도 풀링(pooling), 컨볼루션(convolution), 연결(concatenation) 연산을 수행하는, 복수의 컨볼루션 레이어들을 포함할 수 있다. 일 예시에서, 오디오 특징 검출 모델은, 오디오 의 시간-주파수 스펙토그램(time-frequency spectrogram)을 입력으로 받고, 시간-주파수 스펙토그램 (time-frequency spectrogram)의 특징들을 분석함으로써 오디오 특징을 출력할 수 있다. 일 예로, 오디오 특징 검출 모델로부터, 오디오의 주요 주파수 대역폭이 출력될 수 있다. 다른 예로, 오디오 특징 검출 모델로부터, 오디오의 장르가 무엇인지 분류 결과가 출력될 수 있다. 일 실시예에서, 오디오 특징 검출 모델은, 사람 청취자의 오디오 관심 영역을 측정하여 데이터화한, 행동적 세 일리언스(Behavioral salience)를 훈련 데이터로 사용할 수 있다. 오디오 특징 검출 모델은 사람 청취자의 오디 오 관심 영역을 학습함으로써, 사람의 오디오 관심 영역이 반영된 오디오 특징을 검출할 수 있다. 일부 실시예에서, 획득된 오디오 특징은, 스타일화(stylization)의 적용 대상이 되는 내용물(content)로써 이용될 수 있다. 일부 실시예에서, 획득된 오디오 특징은, 제1 콘텐트에 적용될 스타일을 결정하기 위한 데이터로 이용될 수 있다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 뉴럴 스타일 트랜스퍼 모델의 일 예를 도시한 도면 이다. 일 실시예에서, 전자 장치는 뉴럴 스타일 트랜스퍼 모델을 이용하여, 사용자의 선호도가 반영된 스타일을 적용한, 제2 콘텐트를 생성할 수 있다. 제2 콘텐트는 이미지-오디오 쌍을 포함할 수 있다. 후술하는 뉴럴 스타일 트랜스퍼 모델은 예시일 뿐이며, 사용자 선호도를 반영하여 이미지-오디오 쌍을 포함하는 제2 콘텐 트를 생성하는, 다양한 아키텍처의 인공지능 모델이 사용될 수 있다. 일 실시예에서, 뉴럴 스타일 트랜스퍼 모델은, 제1 콘텐트 및 제1 콘텐트의 적어도 하나의 특징을 입력 받는다. 이 경우, 제1 콘텐트는 이미지 또는 오디오 중 적어도 하나일 수 있다. 전자 장치가 제1 콘텐트의 적어도하나의 특징을 검출하는 실시예는 전술하였으므로, 동일한 설명은 생략한다. 일 실시예에서, 전자 장치는 콘텐트의 스타일을 변경하기 전에, 제1 콘텐트에 대응하는 다른 콘텐트를 결 정함으로써, 이미지-오디오 쌍을 결정할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델의 이미지-오디오 간 결 합 가중치(bonding weight)가 이용될 수 있다. 이미지-오디오 간 결합 가중치는 뉴럴 스타일 트랜스퍼 모델의 훈련 및 추론 과정에서 업데이트될 수 있다. 일부 실시예에서, 제1 콘텐트는 이미지일 수 있다. 전자 장치는 전술한 실시예들에 따라, 이미지 의 적어도 하나의 특징을 획득할 수 있다. 전자 장치는 이미지-오디오 간 결합 가중치에 기초하여 이미지에 대응하는 오디오를 결정할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델이 이용될 수 있으 며, 뉴럴 스타일 트랜스퍼 모델에 이미지 및 이미지의 적어도 하나의 특징이 입력될 수 있다. 일부 실시예에서, 제1 콘텐트는 오디오일 수 있다. 전자 장치는 전술한 실시예들에 따라, 오디오 의 적어도 하나의 특징을 획득할 수 있다. 전자 장치는 이미지-오디오 간 결합 가중치에 기초하여 오디오에 대응하는 이미지를 결정할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델이 이용될 수 있으 며, 뉴럴 스타일 트랜스퍼 모델이 오디오 및 오디오의 적어도 하나의 특징이 입력될 수 있다. 일 실시예에서, 뉴럴 스타일 트랜스퍼 모델은 이미지의 스타일을 변경하는 제1 서브 네트워크(사용자 선호 이미지 스타일 트랜스퍼 네트워크) 및 오디오의 스타일을 변경하는 제2 서브 네트워크(사용자 선호 오디오 스타일 트랜스퍼 네트워크)를 포함할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델은, 제1 서브 네트워크(73 0)와 제2 서브네트워크 간의 가중치 공유를 위해, 제1 서브 네트워크의 적어도 일부 레이어가 제2 서 브 네트워크의 적어도 일부 레이어와 연결된, 페어링된 네트워크를 포함할 수 있다. 일 실시예에 따라, 제1 콘텐트로부터 이미지 및 오디오가 결정되면, 이미지는 제1 서브 네트워 크를 이용하여 스타일이 변경되고, 오디오는 제2 서브 네트워크를 이용하여 스타일이 변경될 수 있다. 일부 실시예에서, 제1 네트워크에 의해 기 학습된 사용자의 선호 이미지 스타일이 이미지에 적 용되고, 제2 네트워크에 의해 기 학습된 사용자의 선호 오디오 스타일이 오디오에 적용될 수 있다. 일 실시예에 따른 전자 장치는 제1 네트워크를 이용하여 이미지의 스타일을 사용자 선호 이미 지 스타일로 변경하고, 제2 네트워크를 이용하여 오디오의 스타일을 사용자 선호 오디오 스타일로 변 경함으로써, 사용자 선호 스타일이 적용된 이미지-오디오 쌍을 포함하는, 제2 콘텐트를 획득할 수 있다. 일 실시예에서, 뉴럴 스타일 트랜스퍼 모델은, 전자 장치가 콘텐트의 스타일을 변경할 때, 사용자 선호 스타일이 반영되도록 하기 위해, 사전 학습된 스타일 트랜스퍼 모델을 기초로 하여 사용자 선호도에 관련된 데 이터를 더 학습한 모델일 수 있다. 예를 들어, 뉴럴 스타일 트랜스퍼 모델은, 전자 장치의 사용 이력으로 부터 식별된 사용자 선호 스타일을 학습한 모델일 수 있다. 다른 예에서, 뉴럴 스타일 트랜스퍼 모델은, 전자 장치의 콘텐트 시청 환경과 대응될 수 있는, 사용자 선호 스타일을 학습한 모델일 수 있다. 전자 장치 가 사용자 선호 스타일에 관련된 데이터를 학습하는 구체적인 데이터들에 관해서는 후술한다. 일 실시예에서, 전자 장치는 제2 콘텐트를 생성하기 위하여, 전자 장치의 사용 이력을 획득하 고, 전자 장치의 사용 이력, 제1 콘텐트 및 제1 콘텐트의 적어도 하나의 특징을 뉴럴 스타일 트랜스퍼 모 델에 입력할 수 있다. 이 경우, 뉴럴 스타일 트랜스퍼 모델에 의해, 제1 콘텐트의 내용에 전자 장치의 사 용 이력에 기초하여 결정된 사용자 선호 스타일이 적용됨으로써, 제2 콘텐트가 생성될 수 있다. 예를 들어, 전자 장치는 사용 이력에 포함되는 콘텐트 시청 통계 기록에 기초하여, 사용자가 활기찬 분위기의 콘텐트(예를 들어, TV 예능 쇼, 코미디 등)를 선호하는 것으로 결정하고, 밝고 화사한 테마의 스타일 적용한, 제2 콘텐트를 생성할 수 있다. 일 실시예에서, 전자 장치는 제2 콘텐트를 생성하기 위하여, 전자 장치가 위치한 공간의 조도 및 색도를 포함하는 콘텐트 시청 환경 정보를 획득하고, 전자 장치의 콘텐트 시청 환경 정보, 제1 콘텐트 및 제1 콘텐트의 적어도 하나의 특징을 뉴럴 스타일 트랜스퍼 모델에 입력할 수 있다. 이 경우, 뉴럴 스타일 트 랜스퍼 모델에 의해, 제1 콘텐트의 내용에 전자 장치에 전자 장치의 콘텐트 시청 환경 정보에 기초 하여 결정된 사용자 선호 스타일이 적용됨으로써, 제2 콘텐트가 생성될 수 있다. 예를 들어, 전자 장치 는 전자 장치의 콘텐트 시청 환경 정보에 기초하여, 전자 장치가 위치한 공간의 조도가 낮아 어두운 공간임을 식별하고, 어둡고 잔잔한 테마의 스타일을 적용한, 제2 콘텐트를 생성할 수 있다. 일부 실시예에서, 전자 장치는 제2 콘텐트를 생성하기 위하여, 전자 장치의 사용 이력 및 전 자 장치의 콘텐트 시청 환경 정보를 모두 이용할 수 있다. 한편, 도 7에 도시된 뉴럴 스타일 트랜스퍼 모델은 예시일 뿐이다. 일부 실시예에서, 뉴럴 스타일 트랜스퍼 모 델은 복수개의 모델들로 구성될 수 있다. 뉴럴 스타일 트랜스퍼 모델은 이미지의 스타일을 변경하는 제1 모델과 오디오의 스타일을 변경하는 제2 모델로 구성될 수 있다. 이 경우, 전자 장치는 제1 모델 및 제2 모델을 이용하여, 사용자 선호 스타일이 반영된 이미지-오디오 쌍을 포함하는, 제2 콘텐트를 생성할 수 있다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 뉴럴 스타일 트랜스퍼 모델을 훈련시키는 동작을 도시한 흐름 도이다. 단계 S810에서, 일 실시예에 따른 전자 장치는 전자 장치의 사용 이력 및 콘텐트 시청 환경 정보 중 적어 도 하나를 획득한다. 일 실시예에서, 전자 장치의 사용 이력은, 전자 장치에서 실행된 애플리케이션들과 관련된 이력 및 전자 장치에 연결되어 사용된 외부 소스들의 이력을 포함할 수 있다. 전자 장치의 구체적인 사용 이력은, 도 9a에서 더 서술하기로 한다. 일 실시예에서, 전자 장치의 콘텐트 시청 환경 정보는, 전자 장치가 위치한 공간의 조도 및 색도를 포함할 수 있다. 일부 실시예에서, 뉴럴 스타일 트랜스퍼를 더 포함할 수 있다. 콘텐트 시청 환경 정보는 각 데 이터를 센싱하기 위해 전자 장치에 내장된 하나 이상의 센서, 전자 장치 외부의 별도의 센서에 의 해 수신되거나, 사용자 입력에 의해 수신되는 등, 다양한 방식으로 획득될 수 있다. 전자 장치의 사용 이력 및 콘텐트 시청 환경 정보는, 뉴럴 스타일 트랜스퍼 모델의 훈련 데이터로 이용될 수 있다. 전자 장치는 뉴럴 스타일 트랜스퍼 모델이 사용자 선호 스타일을 학습 가능하도록, 전자 장치 의 사용 이력 및 콘텐트 시청 환경 정보에 대하여 소정의 전처리를 거친 후, 뉴럴 스타일 트랜스퍼 모델 을 훈련시킬 수 있다. 단계 S820에서, 일 실시예에 따른 전자 장치는 이미지 콘텐트로부터 이미지 특징을 추출하고, 오디오 콘 텐트로부터 오디오 특징을 추출한다. 전자 장치가 콘텐트 특징을 검출하는 방법은 전술하였으므로, 동일 한 설명은 생략한다. 전자 장치는 훈련 데이터셋에 포함되는 훈련 이미지 및 훈련 오디오로부터 특징을 추출할 수 있다. 이 경우, 훈련 이미지 및 훈련 오디오는, 상관 관계 학습을 위해 페어링된 것일 수 있다. 전자 장치는 뉴럴 스타일 트랜스퍼 모델이 제1 콘텐트에 대응하는 다른 콘텐트를 결정할 수 있도록, 이미지 특 징 및 오디오 특징에 대하여 소정의 전처리를 거친 후, 뉴럴 스타일 트랜스퍼 모델을 훈련시킬 수 있다. 즉, 전 자 장치는 뉴럴 스타일 트랜스퍼 모델이 제1 콘텐트가 이미지인 경우 이미지에 대응하는 오디오를 결정하 고, 제1 콘텐트가 오디오인 경우 오디오에 대응하는 이미지를 결정할 수 있도록, 뉴럴 스타일 트랜스퍼 모델을 훈련시킬 수 있다. 단계 S830에서, 일 실시예에 따른 전자 장치는 이미지-오디오 간 상관관계 및, 콘텐트에 대한 사용자 선 호 스타일 적용을 학습하기 위해, 제1 서브 네트워크 및 제2 서브 네트워크 내 가중치들을 업데이트한다. 전자 장치는 훈련 데이터를 이용하여 뉴럴 스타일 트랜스퍼 모델을 훈련시킴으로써, 제1 서브 네트워크 및 제2 서브 네트워크 내 가중치들을 업데이트할 수 있다. 일 실시예에서, 후술하는 훈련 데이터들은, 뉴럴 스타일 트랜스퍼 모델을 훈련시키기 위한 전처리 과정이 수행 된 것일 수 있다. 일 실시예에서, 전자 장치는 훈련 데이터에 포함되는 이미지-오디오 쌍 및 이미지, 오디오 각각의 특징을 이용하여, 뉴럴 스타일 트랜스퍼 모델이 이미지-오디오 쌍을 출력할 수 있도록 하는 이미지-오디오 간 결합 가 중치들을 업데이트할 수 있다. 전자 장치는 훈련 데이터에 포함되는 스타일 이미지 및 스타일 오디오를 이용하여, 뉴럴 스타일 트랜스퍼 모델이 스타일 변경된 이미지-오디오 쌍을 출력할 수 있도록 하는, 가중치들을 업데이트할 수 있다. 일부 실시예에서, 전자 장치는 훈련 데이터에 포함되는 전자 장치의 사용 이력에 기초하여, 뉴럴 스타일 트랜스퍼 모델이 사용자 선호 스타일을 콘텐트에 적용할 수 있도록 하는, 가중치들을 업데이트할 수 있 다. 일부 실시예에서, 전자 장치는 훈련 데이터에 포함되는 콘텐트 시청 환경 정보에 기초하여, 뉴럴 스타일 트랜스퍼 모델이 사용자의 콘텐트 시청 환경과 유사한 스타일을 콘텐트에 적용할 수 있도록 하는, 가중치들을업데이트할 수 있다. 단계 S840에서, 일 실시예에 따른 전자 장치는 사용자의 선호도가 반영된 이미지-오디오 쌍이 생성되도록 훈련을 반복할 수 있다. 일 실시예에 따른 전자 장치는 훈련 데이터들을 이용하여 뉴럴 스타일 트랜스퍼 모델을 훈련시키면서 손실(loss)을 계산할 수 있다. 전자 장치는 손실 계산 및 역전파를 통해 손실이 최 소화되도록 뉴럴 스타일 트랜스퍼 모델의 훈련을 반복하여, 뉴럴 스타일 트랜스퍼 모델을 최적화할 수 있다. 도 9a는 본 개시의 일 실시예에 따른 뉴럴 스타일 트랜스퍼 모델의 훈련 데이터에 포함되는, 전자 장치의 사용 이력을 설명하기 위한 도면이다. 일 실시예에서, 훈련 데이터는 전자 장치의 사용 이력을 포함할 수 있다. 전자 장치의 사용 이력은 디바이스에서 실행된 애플리케이션들과 관련된 사용 이력 및 디바이스에 연결되어 사용된 외부 소스와 관련된 사용 이력 및 사용자의 또다른 전자 장치로부터 획득되는 사용 이력을 포함한다. 일 실시예에서, 전자 장치에는 복수의 애플리케이션들이 설치되어 있을 수 있다. 예를 들어, 전자 장치 에는 애플리케이션 A, 애플리케이션 B 및 애플리케이션 C 등이 설치되어 있을 수 있다. 일 실시예에 따른 전자 장치는, 애플리케이션들이 실행됨에 따라 획득 가능한 다양한 이력을 저장할 수 있다. 애플리케이션들과 관련된 사용 이력은 예를 들어, 애플리케이션의 이름, 애플리케이션의 실행 횟수, 애플 리케이션의 실행 시간 및 날짜, 애플리케이션의 실행 비율, 애플리케이션의 종류(예를 들어, OTT(Over The Top) 미디어 서비스 애플리케이션, 비디오 애플리케이션, 게임 애플리케이션 등), 애플리케이션에서 이용된 콘텐트 정보, 애플리케이션에서 이용된 콘텐트의 이용 시간 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치에는 다양한 종류의 외부 소스가 연결될 수 있다. 예를 들어, 전자 장치 에는 셋탑 박스, 데스크탑 PC, 모바일 폰 등의 외부 소스가 연결되어 콘텐트가 제공될 수 있다. 다만, 전술한 전자 장치에 연결되는 외부 소스의 종류는 예시일 뿐이며 이에 한정되지 않는다. 전자 장치는 전자 장치에서 외부 소스가 연결되어 사용됨에 따라 획득 가능한 다양한 이력을 저장할 수 있다. 외부 소스들 과 관련된 사용 이력은 외부 소스가 연결된 시간 및 날짜, 연결 횟수, 외부 소스가 연결되었을 때 실행되는 애 플리케이션, 외부 소스가 연결되었을 때 이용된 콘텐트 정보, 외부 소스가 연결되었을 때 이용된 콘텐트의 이용 시간 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 외부로부터 사용자의 또다른 전자 장치와 관련된 이력을 획득할 수 있다. 사 용자의 또다른 전자 장치는 예를 들어, 외부 서버(예를 들어, 클라우드 서비스), 모바일 폰, 스피커 (예를 들어, 인공지능 스피커) 등을 포함할 수 있다. 구체적으로, 외부 서버에 저장된 콘텐트, 모바 일 폰의 활동 기록(예를 들어, 재생된 음악, 방문한 장소, 찍은 사진, 메시지, SNS 활동 등), 스피커(92 4)에서 재생된 음악 등을 포함할 수 있다. 일 실시예에 따른 전자 장치는 사용자 선호 스타일이 적용될 수 있도록 뉴럴 스타일 트랜스퍼 모델을 학 습시키기 위해, 전술한 전자 장치의 사용 이력에 소정의 전처리를 수행하여 훈련 데이터를 생성할 수 있다. 도 9b는 본 개시의 일 실시예에 따른 뉴럴 스타일 트랜스퍼 모델의 훈련 데이터에 포함되는, 전자 장치의 사용 이력을 설명하기 위한 도면이다. 일 실시예에서, 훈련 데이터는 스타일 이미지들 및 스타일 오디오들을 포함할 수 있다. 스타일 이미지는 이미지에 적용될 스타일을 나타내는 이미지이며, 스타일 오디오는 오디오에 적용될 스타일을 나타내는 오디오이다. 전자 장치는 훈련 데이터에 포함되는 스타일 이미지들 및 스타일 오디오들을 학습함으로써, 획득된 제1 콘텐트의 스타일을 변경할 수 있다. 일 실시예에서, 제1 콘텐트가 획득되는 경우, 뉴럴 스타일 트랜스퍼 모델은 제1 콘텐트 및 제1 콘텐트에 대응하 는 다른 콘텐트(즉, 이미지-오디오 쌍)에, 기 학습된 이미지 스타일 및 오디오 스타일을 사용자 선호도에 기초 하여 자동으로 적용할 수 있다. 일부 실시예에서, 뉴럴 스타일 트랜스퍼 모델은, 특정 스타일 이미지 및/또는 오디오를 선택 및/또는 입력하는 사용자 입력에 기초하여, 선택/입력된 이미지/오디오의 스타일을 추출할 수 있 다. 뉴럴 스타일 트랜스퍼 모델은 추출된 스타일을 제1 콘텐트 및 제1 콘텐트에 대응하는 다른 콘텐트(즉, 이미 지-오디오 쌍)에 적용할 수 있다. 한편, 콘텐트에 사용자가 선호하는 스타일을 적용하기 위한 뉴럴 스타일 트랜스퍼 모델의 훈련 데이터는, 다른 데이터를 더 포함할 수 있다.예를 들어, 훈련 데이터는 콘텐트 특징 정보를 포함할 수 있다. 이미지 특징은 예를 들어, 이미지의 색조, 이미지 내의 주요 객체의 종류, 위치, 크기 및 서브 객체의 종류, 위치, 크기 등을 포함할 수 있으나, 이에 한 정되는 것은 아니다. 오디오의 장르, 오디오의 주요 주파수 대역폭, 소리 크기(loudness), 스펙트럼 평탄도 (spectral flatness), 스펙트럼 불규칙도(spectral irregularity), 음높이(pitch), 시간 영역의 변조 (modulation in the temporal domain)(rate), 주파수 영역의 변조(modulation in the frequency domain)(scale) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 뉴럴 스타일 트랜스퍼 모델은 이미지 특징 및 오디오 특징을 학습하여, 제1 콘텐트로 이미지가 획득되는 경우 대응되는 오디오를 결정하고, 제1 콘텐트로 오디오가 획득되는 경우 대응되는 이미지를 결정할 수 있다. 예를 들어, 훈련 데이터는 콘텐트 시청 환경 정보를 포함할 수 있다. 뉴럴 스타일 트랜스퍼 모델은 콘텐트 시청 환경 정보를 포함할 수 있다. 콘텐트 시청 환경 정보는 전자 장치가 위치한 공간의 조도 및 색도, 전자 장치의 주변 온도, 날씨, 주변 소음, 시간 등의 다양한 정보를 포함할 수 있으나, 이에 한정되는 것 은 아니다. 뉴럴 스타일 트랜스퍼 모델은 제1 콘텐트에 적용 될 사용자 선호 스타일을 결정할 때, 콘텐트 시청 환경 정보에 기초하여 콘텐트 시청 환경에 적합한 사용자 선호 스타일을 결정할 수 있다. 뉴럴 스타일 트랜스퍼 모델은, 결 정된 사용자 선호 스타일을 제1 콘텐트에 적용함으로써, 이미지-오디오 쌍을 포함하는 제2 콘텐트를 생성할 수 있다. 일 실시예에 따른 전자 장치는 사용자 선호 스타일이 반영된 제2 콘텐트가 생성되도록 뉴럴 스타일 트랜 스퍼 모델을 학습시키기 위해, 전술한 스타일 이미지, 스타일 오디오, 이미지 특징, 오디오 특징 및 콘텐트 시 청 환경 정보에 소정의 전처리를 수행하여 훈련 데이터를 생성할 수 있다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 뉴럴 스타일 트랜스퍼 모델을 훈련시키는 동작을 도시한 흐름 도이다. 도 10의 단계 S1010은, 도 2의 단계 S240이 수행된 이후에 수행될 수 있다. 단계 S1010에서, 일 실시예에 따른 전자 장치는 제2 콘텐트에 대한 사용자 피드백을 수신한다. 전자 장치 는 제2 콘텐트를 생성할 때, 하나 이상의 제2 콘텐트를 생성할 수 있다. 예를 들어, 전자 장치는 제2 콘텐트 A, 제2 콘텐트 B, 제2 콘텐트 C 등을 생성할 수 있다. 일 실시예에서 복수의 제2 콘텐트들은, 제1 콘텐트는 동일하며, 제1 콘텐트에 대응하는 것으로 결정된 다른 콘 텐트만 상이한 것일 수 있다. 예를 들어, 제1 콘텐트가 이미지 A인 경우, 제2 콘텐트 A는, 스타일 변경된 이미 지 A 및 스타일 변경된 오디오 A로 구성되는 이미지-오디오 쌍일 수 있으며, 제2 콘텐트 B는 스타일 변경된 이 미지 A 및 스타일 변경된 오디오 B로 구성되는, 이미지-오디오 쌍일 수 있다. 즉, 이미지 A는 유지된 채, 이미 지에 대응하는 것으로 결정된 오디오만 다를 수 있다. 다른 예에서, 제1 콘텐트가 오디오 A인 경우, 제2 콘텐트 A는, 스타일 변경된 이미지 A 및 스타일 변경된 오디 오 A로 구성되는 이미지-오디오 쌍일 수 있으며, 제2 콘텐트 B는 스타일 변경된 이미지 B 및 스타일 변경된 오 디오 A로 구성되는, 이미지-오디오 쌍일 수 있다. 즉, 오디오 A는 유지된 채, 오디오에 대응하는 것으로 결정된 이미지만 다를 수 있다. 제2 콘텐트가 복수 개 생성되는 경우, 생성된 제2 콘텐트들 각각은 우선순위에 따른 순서를 포함할 수 있다. 전 자 장치는 가장 높은 우선순위를 갖는 제2 콘텐트를 출력하고, 사용자의 피드백을 수신할 수 있다. 단계 S1020에서, 일 실시예에 따른 전자 장치는 사용자가 제2 콘텐트를 승인하는지 여부를 식별한다. 전 자 장치는 생성된 제2 콘텐트가 사용자의 선호도에 부합하지 않아 사용자가 제2 콘텐트를 거절하는 경우, 단계 S1030을 수행한다. 전자 장치는 생성된 제2 콘텐트가 사용자의 선호도에 부합하여 사용자가 제2 콘 텐트를 승인하는 경우, 단계 S1050.을 수행한다. 이 경우, 단계 S240에서 표시된 제2 콘텐트는 변경되지 않고 유지될 수 있다. 단계 S1030에서, 일 실시예에 따른 전자 장치는 제1 콘텐트에 페어링 된 이미지 또는 오디오를 변경한다. 전자 장치는 제1 콘텐트는 유지한 채, 제1 콘텐트에 대응하는 것으로 결정되어 제1 콘텐트에 페어링 된 다른 콘텐트를 변경할 수 있다. 예를 들어, 전자 장치는 제1 콘텐트가 이미지였던 경우, 오디오를 변경하 고, 제1 콘텐트가 오디오였던 경우, 이미지를 변경할 수 있다. 구체적으로, 제1 콘텐트가 이미지 A 이었고, 생 성된 제2 콘텐트 A는, 스타일 변경된 이미지 A 및 스타일 변경된 오디오 A로 구성되는 이미지-오디오 쌍이었을수 있다. 이 경우, 사용자가 제2 콘텐트 A를 거절하면, 전자 장치는 다음 우선순위의 제2 콘텐트 B를 선 택할 수 있다. 제2 콘텐트 B는, 스타일 변경된 이미지 A 및 스타일 변경된 오디오 B로 구성될 수 있다. 전자 장 치는 사용자가 거절한 제2 콘텐트에 포함되는 이미지-오디오 쌍에 대하여, 결합 가중치 값을 감소시킬 수 있다. 단계 S1040에서, 일 실시예에 따른 전자 장치는 새로운 제2 콘텐트를 출력한다. 예를 들어, 전자 장치 는 제2 콘텐트 A가 출력된 이후, 사용자가 제2 콘텐트 A를 거절하면, 제2 콘텐트 B를 출력할 수 있다. 일 실시예에 따른 전자 장치는 사용자 피드백에 기초하여, 사용자가 제2 콘텐트를 승인할 때까지 전술한 동 작들을 반복할 수 있다. 단계 S1050에서, 일 실시예에 따른 전자 장치는 승인된 제2 콘텐트에 기초하여, 뉴럴 스타일 트랜스퍼 모 델을 업데이트한다. 전자 장치는 사용자가 승인한 제2 콘텐트에 포함되는 이미지-오디오 쌍에 대하여, 결 합 가중치 값을 증가시킬 수 있다. 도 11은 본 개시의 일 실시예에 따른 전자 장치가 사용자로부터 선호 스타일을 입력 받는 동작을 설명하기 위한 도면이다. 일 실시예에서, 뉴럴 스타일 트랜스퍼 모델은, 제1 콘텐트를 입력 받아 사용자 선호 스타일을 자동으로 적용하 여 제2 콘텐트를 생성할 수 있으나, 사용자로부터 선호 스타일을 선택하는 입력을 수신하여 선택된 스타일을 적 용하여 제2 콘텐트를 생성할 수도 있다. 도 10에서는 설명의 편의를 위해 제1 콘텐트가 이미지인 경우를 예시로 설명한다. 그러나, 후술하는 내용들은 제1 콘텐트가 오디오인 경우에도 동일하게 적용될 수 있다. 일 실시예에서 전자 장치는 제1 콘텐트인 이미지를 획득하고, 이미지에 적용 가능한 복수의 스타일 이미지들을 표시할 수 있다. 전자 장치는 복수의 스타일 이미지들 중에서, 어느 하나 를 선택하는 사용자 입력을 수신할 수 있다. 예를 들어, 전자 장치는 사용자가 복수의 스타일 이미지들 중에서 특정 스타일 이미지를 선택하는 경우, 선택된 스타일 이미지를 이미지에 적용 할 수 있다. 이 경우, 전자 장치는 뉴럴 스타일 트랜스퍼 모델을 이용할 수 있다. 일 실시예에서, 전자 장치는 이미지에 대응하는 오디오를 결정하고, 오디오에 적용될 사용자 선호 오디오 스타일을 적용할 수 있다. 전자 장치는 사용자 선호 스타일이 적용된 이미지-오디오 쌍을 포함하 는, 제2 콘텐트를 생성할 수 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 12를 참조하면, 일 실시예에 따른 전자 장치는 통신 인터페이스, 디스플레이, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 다른 전자 장치들과 데이터 통신을 수행할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), 블루투스 (Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신(IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하는 데이터 통신 방식 중 적어도 하나를 이 용하여, 전자 장치와 다른 디바이스들 간의 데이터 통신을 수행할 수 있는, 통신 회로를 포함할 수 있다. 일 실시예에 따른 통신 인터페이스는 제2 콘텐트를 생성하기 위한 데이터를 외부 디바이스와 송신할 수 있다. 예를 들어, 통신 인터페이스는 제1 콘텐트를 수신하거나, 뉴럴 스타일 트랜스퍼 모델 및 뉴럴 스타 일 트랜스퍼 모델을 훈련시키기 위한 훈련 데이터를 수신할 수 있다. 디스플레이는 프로세서의 제어에 의해 전자 장치의 화면에 영상 신호를 출력할 수 있다. 디 스플레이는 프로세서에 의해 생성된 제2 콘텐트를 표시할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘 발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모 리를 포함할 수 있다. 일 실시예에 따른 메모리는 스타일화된 제2 콘텐트를 생성하기 위해 동작하도록 하는 하나 이상의 인스트 럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 데이터 관리 모듈, 콘텐트 분석 모듈 및 콘텐트 생성 모듈이 저장될 수 있다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 전자 장치가 제2 콘텐 트를 생성하기 위한 전반적인 동작들을 제어할 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서(Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전 용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에서, 프로세서는 데이터 관리 모듈을 실행하여, 제2 콘텐트를 생성하기 위해 이용되는 데이터들을 관리할 수 있다. 프로세서는 전자 장치의 사용 이력을 수집할 수 있다. 전자 장치의 사용 이력은, 전자 장치 에서 실행된 애플리케이션들과 관련된 이력, 전자 장치에 연결되어 사용된 외부 소스와 관련된 이 력, 전자 장치의 사용자의 또다른 전자 장치와 관련된 이력을 포함할 수 있다. 이에 대하여는 전술하였으 므로, 동일한 설명은 생략한다. 수집된 사용 이력은 뉴럴 스타일 트랜스퍼 모델의 훈련 데이터로 이용될 수 있 다. 프로세서는 전자 장치의 외부로부터 획득 가능한 데이터(예를 들어, 콘텐트 시청 정보, 뉴럴 스타 일 트랜스퍼 모델을 훈련시키기 위한 훈련 데이터, 제1 콘텐트 등)을 저장하고 관리할 수 있다. 일 실시예에서, 프로세서는 콘텐트 분석 모듈을 실행하여, 제1 콘텐트를 분석할 수 있다. 프로세서 는 제1 콘텐트를 콘텐트 특징 검출 모델에 적용하여, 콘텐트의 적어도 하나의 특징을 검출할 수 있다. 프 로세서는 제1 콘텐트의 종류를 식별하고, 제1 콘텐트의 종류에 대응하는 콘텐트 특징 검출 모델을 선택할 수 있다. 프로세서는 선택된 콘텐트 특징 검출 모델을 이용하여, 제1 콘텐트로부터 하나 이상의 특징을 검출할 수 있다. 일 실시예에서, 프로세서는 콘텐트 생성 모듈을 실행하여, 사용자 선호 스타일이 적용된 제2 콘텐 트를 생성할 수 있다. 프로세서는 제1 콘텐트 및 제1 콘텐트의 적어도 하나의 특징을, 뉴럴 스타일 트랜 스퍼 모델에 적용하여, 제2 콘텐트를 생성할 수 있다. 뉴럴 스타일 트랜스퍼 모델에 의해 생성된 제2 콘텐트는, 이미지-오디오 쌍을 포함하는, 사용자 선호 스타일이 적용된 콘텐트일 수 있다. 도 13은 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다. 일 실시예에서, 전술한 전자 장치가 제2 콘텐트를 생성하기 위한 동작들은, 서버에서 수행될 수 있 다. 일 실시예에 따른 서버는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 서 버의 통신 인터페이스, 메모리 및 프로세서는 도 12의 전자 장치의 통신 인터페 이스, 메모리 및 프로세서에 각각 대응되므로, 동일한 설명은 생략한다. 일 실시예에 따른 서버는, 전자 장치 보다 연산량이 많은 연산을 수행 가능하도록, 컴퓨팅 성능이 전자 장치보다 높은 장치일 수 있다. 서버는 추론에 비해 상대적으로 많은 연산량이 요구되는, 인공지능 모델의 훈련을 수행할 수 있다. 예를 들어, 서버는 콘텐트 특징 검출 모델 및 콘텐트 뉴럴 스타일 트랜스퍼 모델을 훈련시킬 수 있다. 일 실시예에 따른 서버는 사용자 디바이스(예를 들어, 전자 장치)로부터 제1 콘텐트를 획득하고, 전술한 실시예들에 따라 제2 콘텐트를 생성할 수 있다. 서버는 생성된 제2 콘텐트가 사용자 디바이스에서 출력될 수 있도록, 제2 콘텐트를 사용자 디바이스로 전송할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2022-0035541", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2022-0035541", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 사용자 선호 콘텐트를 생성하여 출력하는 예시를 나타내는 도 면이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 콘텐트를 생성하는 방법을 설명하기 위한 흐름도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트를 생성하는 동작을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치가 인공지능 모델들을 이용하여 제1 콘텐트로부터 제2 콘텐트를 생성하는 과정을 도시한 도면이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 제1 콘텐트의 특징을 검출하는 방법을 설명하기 위한 흐름도이 다. 도 6a는 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 이미지 콘텐트 특징 검출 모델의 일 예를 도시한 도면이다. 도 6b는 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 오디오 콘텐트 특징 검출 모델의 일 예를 도시한 도면이다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 이용하는, 뉴럴 스타일 트랜스퍼 모델의 일 예를 도시한 도면 이다. 도 8은 본 개시의 일 실시예에 따른 전자 장치가 뉴럴 스타일 트랜스퍼 모델을 훈련시키는 동작을 도시한 흐름도이다. 도 9a는 본 개시의 일 실시예에 따른 뉴럴 스타일 트랜스퍼 모델의 훈련 데이터에 포함되는, 전자 장치의 사용 이력을 설명하기 위한 도면이다. 도 9b는 본 개시의 일 실시예에 따른 뉴럴 스타일 트랜스퍼 모델의 훈련 데이터에 포함되는, 전자 장치의 사용 이력을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 전자 장치가 뉴럴 스타일 트랜스퍼 모델을 훈련시키는 동작을 도시한 흐름 도이다. 도 11은 본 개시의 일 실시예에 따른 전자 장치가 사용자로부터 선호 스타일을 입력 받는 동작을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 13은 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다."}
