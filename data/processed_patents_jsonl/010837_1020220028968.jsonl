{"patent_id": "10-2022-0028968", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0076716", "출원번호": "10-2022-0028968", "발명의 명칭": "객체 맥락화를 이용한 영상 검색 시스템", "출원인": "경기대학교 산학협력단", "발명자": "김광훈"}}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "입력된 영상 파일에 대하여 프레임 별로 객체를 검출하고, 프레임 별로 검출된 객체의 종류와 수, 객체 속성 정보, 객체의 위치 정보를 포함하는 프레임 맥락화 데이터를 생성하고, 프레임 맥락화 데이터를 결합하여 영상 데이터에 대한 객체 맥락화 데이터를 생성하여 텍스트 파일로 빅데이터 저장소에 저장하는 객체 맥락화 서버; 및검색 조건을 입력 받아 객체 맥락화 데이터를 대상으로 텍스트 검색 기반으로 검색 조건에 부합하는 영상을 검색하는 영상 검색 서버;를 포함하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 영상 검색 서버는 :검색 조건 입력을 위한 사용자 인터페이스와 검색 결과를 표시하는 사용자 인터페이스를 제공하는 프론트 엔드부; 및객체 맥락화 데이터가 저장된 텍스트 파일들을 대상으로 입력된 조건에 기초하여 영상을 검색하는 백 엔드부;를 포함하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 프론트 엔드부는 검색 조건을 입력 받아 영상 검색 결과를 대상으로 영상을 재검색하는 사용자 인터페이스를 더제공하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서, 프론트 엔드부는 검색 대상 영상 파일 리스트를 입력 받아 객체 맥락화 서버에 해당 리스트를 전달하는 사용자인터페이스를 더 제공하고,객체 맥락화 서버는 전달받은 영상 파일 리스트에 속한 영상 파일을 대상으로 객체 맥락화를 수행하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 백 엔드부는 입력된 영상 파일 리스트에 속하는 영상 파일로부터 생성된 객체 맥락화 데이터만을 대상으로 영상을 검색하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0076716-3-제 1 항에 있어서, 객체 맥락화 서버는 :하나 이상의 영상 파일 각각의 프레임에 대하여 연속된 프레임 식별자를 할당하여 입력 영상 데이터를 생성하는입력 영상 처리부;딥러닝 모델을 사용하여 입력 영상 데이터에서 프레임 별로 복수의 객체를 검출하여 객체의 종류를 분류하고,객체의 종류와 객체의 위치 정보를 포함하는 객체 속성 정보를 생성하는 객체 검출부;객체가 검출된 프레임 별로 검출된 프레임 정보, 객체의 종류와 수, 각 객체의 객체 속성 정보를 포함하는 프레임 맥락화 데이터를 생성하는 프레임 맥락화부;검출된 객체들의 리스트와 프레임 별 상기 프레임 맥락화 데이터를 포함하는 객체 맥락화 데이터를 생성하는 객체 맥락화부; 및객체 맥락화 데이터를 텍스트 파일로 빅데이터 저장소에 저장하는 맥락화 저장부;를 포함하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 객체 맥락화 서버는 :설정된 클립 구성 정보에 기초하여 논리적 클립을 구성하여 객체 맥락화 데이터에 추가하는 클립 지정부;를 더 포함하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서, 프레임 맥락화부는 설정된 프레임 간격으로 프레임 별 프레임 맥락화 데이터를 생성하는 객체 맥락화를 이용한영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6 항에 있어서, 프레임 맥락화부는 현재 프레임에 대하여 검출된 객체의 종류와 수가 이전 프레임에 대하여 검출된 객체의 종류와 수와 달라지는 경우에 현재 프레임에 대하여 프레임 맥락화 데이터를 생성하는 객체 맥락화를 이용한 영상검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,객체 맥락화 서버가 생성하는 프레임 맥락화 데이터에 포함되는 객체 속성 정보는 해당 프레임에서의 객체 이미지를 더 포함하는 객체 맥락화를 이용한 영상 검색 시스템."}
{"patent_id": "10-2022-0028968", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,영상 검색 서버가 검색한 영상 파일이 삭제된 경우 객체 속성 정보에 포함된 객체 이미지들을 결합하여 복구 영상 파일을 생성하는 객체 맥락화를 이용한 영상 검색 시스템.공개특허 10-2023-0076716-4-"}
{"patent_id": "10-2022-0028968", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 양상에 따르는 객체 맥락화를 이용한 검색 시스템은 하나 이상의 영상 파일에 대하여 검출한 객체 와 객체의 속성 정보를 프레임 별로 맥락화한 객체 맥락화 데이터를 텍스트 파일 형태로 빅데이터 저장소에 저장 하고, 저장된 객체 맥락화 데이터를 대상으로 검색 조건에 부합하는 영상을 검색한다."}
{"patent_id": "10-2022-0028968", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨터 비전 기술에 관한 것으로, 2D 영상에서 검출되는 객체들을 맥락화하여 텍스트 형태로 저장하 고 텍스트 기반으로 검색하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0028968", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 CCTV, 블랙박스, 스마트폰 등으로부터 수집되는 동영상 데이터와 페이스북 등의 소셜 미디어로부터 생산되 는 비정형데이터가 급격하게 증가하고 있으며, 그 증가속도 역시 급격히 빨라지고 있다. 이에 따라 동영상 및 소셜 미디어의 비정형 콘텐츠 빅데이터와 딥러닝 등의 인공지능 기술과의 융합적 접근방법과 이를 기반으로 하 는 다양한 활용방안에 대한 관심이 크게 확산되고 있다. 특히, 비정형 콘텐츠의 동영상과 소셜 미디어 빅데이터 를 학습 및 훈련데이터로 활용하는 딥러닝 등의 인공지능 공개 엔진들과 이들을 활용하는 서비스 플랫폼의 연구 개발 및 상용화가 각광을 받기 시작하면서 대표적인 비정형 콘텐츠 빅데이터 응용서비스인 동영상 검색 시스템 에 딥러닝 등의 인공지능 기술을 적용하는 연구개발에 대한 관심이 높아지고 있다. 동영상 프레임의 물리적 내용과 의미적 객체들을 기반으로 하는 종래기술의 동영상 검색 시스템들은 프레임의 인덱스를 구성하거나 핵심 특징을 추출하는데 충분한 성능을 보이지 못하고 있으며, 일부 접근방법들은 상대적 으로 우수한 성능을 보이더라도 추출된 특징의 차원이 너무 높거나 해당 알고리즘의 구현이 매우 어렵다는 문제 점을 가지고 있다. 동영상 검색 접근방법들과 시스템들에서의 가장 중요한 단계는 최소한의 서술자로 해당 동영 상을 묘사하기 위한 특징 추출 단계이며, 가장 기본적인 시각 특징으로서 주로 색상과 질감이 고려대상이 되고 있는데, 최근에는 다양한 질감 표현방법에 따른 패턴인식과 컴퓨터 비전을 기반으로 하는 영상 객체 기반 동영 상 검색 접근방법들과 내용 기반 동영상 검색 접근방법들에 관한 연구개발이 크게 증가하는 추세이다. 특히, 지속적으로 동영상 데이터를 생성하는 CCTV 영상 분석의 경우 동영상 자체를 저장하고 분석하는데 있어 컴퓨팅 자원이 많이 요구된다."}
{"patent_id": "10-2022-0028968", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 영상에 등장하는 객체와 그 속성을 맥락화하여 텍스트 형태로 저장하여 텍스트 기반으로 영상을 검색 하는 시스템을 제공하는 것을 목적으로 한다. 추가적으로, 본 발명은 보관기간 만료 등으로 인해 삭제된 영상에 대하여도 검색이 가능하며, 검색된 영상을 검 출된 객체들의 이미지들로 재구성하여 재생할 수 있는 시스템을 제공하는 것을 또 다른 목적으로 한다."}
{"patent_id": "10-2022-0028968", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양상에 따르는 객체 맥락화를 이용한 영상 검색 시스템은 객체 맥락화 서버와, 영상 검색 서버를 포함한다. 객체 맥락화 서버는 입력된 영상 파일에 대하여 프레임 별로 객체를 검출하고, 프레임 별로 검출된 객체의 종류 와 수, 객체 속성 정보, 객체의 위치 정보를 포함하는 프레임 맥락화 데이터를 생성하고, 프레임 맥락화 데이터 를 결합하여 영상 데이터에 대한 객체 맥락화 데이터를 생성하여 텍스트 파일로 빅데이터 저장소에 저장한다. 영상 검색 서버는 검색 조건을 입력 받아 객체 맥락화 데이터를 대상으로 텍스트 검색 기반으로 검색 조건에 부 합하는 영상을 검색한다. 구체적으로 본 발명의 일 양상에 따르는 영상 검색 서버는 프론트 엔드부와, 백 엔드부를 포함할 수 있다. 프론트 엔드부는 검색 조건 입력을 위한 사용자 인터페이스와 검색 결과를 표시하는 사용자 인터페이스를 제공 한다. 백 엔드부는 객체 맥락화 데이터가 저장된 텍스트 파일들을 대상으로 입력된 조건에 기초하여 영상을 검색한다. 본 발명의 추가적 양상에 따르면, 영상 검색 서버의 프론트 엔드부는 검색 조건을 입력 받아 영상 검색 결과를 대상으로 영상을 재검색하는 사용자 인터페이스를 더 제공할 수 있다.본 발명의 추가적 양상에 따르면, 영상 검색 서버의 프론트 엔드부는 검색 대상 영상 파일 리스트를 입력 받아 객체 맥락화 서버에 해당 리스트를 전달하는 사용자 인터페이스를 더 제공할 수 있다. 이때, 객체 맥락화 서버 는 전달받은 영상 파일 리스트에 속한 영상 파일을 대상으로 객체 맥락화를 수행할 수 있다. 또한, 백 엔드부는 입력된 영상 파일 리스트에 속하는 영상 파일로부터 생성된 객체 맥락화 데이터만을 대상으 로 영상을 검색할 수 있다. 구체적으로 본 발명의 일 양상에 따르는 객체 맥락화 서버는 입력 영상 처리부와, 객체 검출부와, 프레임 맥락 화부와, 객체 맥락화부와, 맥락화 저장부를 포함할 수 있다. 입력 영상 처리부는 하나 이상의 영상 파일 각각의 프레임에 대하여 연속된 프레임 식별자를 할당하여 입력 영 상 데이터를 생성한다. 객체 검출부는 딥러닝 모델을 사용하여 입력 영상 데이터에서 프레임 별로 복수의 객체를 검출하여 객체의 종류 를 분류하고, 객체의 종류와 객체의 위치 정보를 포함하는 객체 속성 정보를 생성한다. 프레임 맥락화부는 객체가 검출된 프레임 별로 검출된 프레임 정보, 객체의 종류와 수, 각 객체의 객체 속성 정 보를 포함하는 프레임 맥락화 데이터를 생성한다. 객체 맥락화부는 검출된 객체들의 리스트와 프레임 별 상기 프레임 맥락화 데이터를 포함하는 객체 맥락화 데이 터를 생성한다. 맥락화 저장부는 객체 맥락화 데이터를 텍스트 파일로 빅데이터 저장소에 저장한다. 본 발명의 추가적 양상에 따르면, 객체 맥락화 서버는 클립 지정부를 더 포함할 수 있고, 클립 지정부는 설정된 클립 구성 정보에 기초하여 논리적 클립을 구성하여 객체 맥락화 데이터에 추가한다. 발명의 양상에 따라서는 객체 맥락화 서버의 프레임 맥락화부는 설정된 프레임 간격으로 프레임 별 프레임 맥락 화 데이터를 생성하거나 현재 프레임에 대하여 검출된 객체의 종류와 수가 이전 프레임에 대하여 검출된 객체의 종류와 수와 달라지는 경우에 현재 프레임에 대하여 프레임 맥락화 데이터를 생성할 수 있다. 발명의 양상에 따라서는 객체 맥락화 서버가 생성하는 프레임 맥락화 데이터에 포함되는 객체 속성 정보는 해당 프레임에서의 객체 이미지를 더 포함할 수 있다. 이때, 영상 검색 서버가 검색한 영상 파일이 삭제된 경우 객체 속성 정보에 포함된 객체 이미지들을 결합하여 복구 영상 파일을 생성할 수 있다."}
{"patent_id": "10-2022-0028968", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면 영상에 등장하는 객체와 그 속성을 맥락화하여 텍스트 형태로 저장하여 텍스트 기반으로 영상 을 검색할 수 있다. 또한, 본 발명에 의하며 보관기간 만료 등으로 인해 삭제된 영상에 대하여도 검색이 가능하며, 검색된 영상을 검출된 객체들의 이미지들로 재구성하여 재생할 수 있다."}
{"patent_id": "10-2022-0028968", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한, 그리고 추가적인 양상들은 첨부된 도면을 참조하여 설명하는 실시 예들을 통해 구체화된다. 각 실시 예들의 구성 요소들은 다른 언급이나 상호간에 모순이 없는 한 실시 예 내에서 다양한 조합이 가능한 것으로 이 해된다. 블록도의 각 블록은 어느 경우에 있어서 물리적인 부품을 표현할 수 있으나 또 다른 경우에 있어서 하 나의 물리적인 부품의 기능의 일부 혹은 복수의 물리적인 부품에 걸친 기능의 논리적인 표현일 수 있다. 때로 는 블록 혹은 그 일부의 실체는 프로그램 명령어들의 집합(set)일 수 있다. 이러한 블록들은 전부 혹은 일부가 하드웨어, 소프트웨어 혹은 이들의 결합에 의해 구현될 수 있다. 도 1은 본 발명의 객체 맥락화를 이용한 영상 검색 시스템의 블록도이다. 본 발명의 일 양상에 따르는 객체 맥 락화를 이용한 영상 검색 시스템은 객체 맥락화 서버와, 영상 검색 서버를 포함한다. 객체 맥락화 서버와 영상 검색 서버는 하나의 컴퓨팅 장치로 구성되거나 네트워크로 연결된 복수의 컴퓨팅 장치로 구성될 수 있고, 하드웨어 외에 소프트웨어 개념을 포함한다. 즉, 객체 맥락화 서버와 영상 검색 서버는 물리적인 하드웨어를 지칭하기도 하지만 해당 하드웨어 상에서 실행되는 서버 프로그램을 지 칭할 수도 있다. 서버들을 구성하는 컴퓨팅 장치는 프로세서와, 프로세서와 연결되고 프로세서에 의해 실행 가 능한 프로그램 명령어들을 포함하는 메모리를 포함하는 장치이다. 해당 컴퓨팅 장치는 프로세서와, 메모리 외에 추가적으로 저장 장치, 디스플레이, 입력 장치 등을 더 포함하는 컴퓨터 장치일 수 있다. 프로세서는 서버 프로 그램을 구현하는 프로그램 명령어들을 실행하는 프로세서이고, 메모리는 프로세서와 연결되고 프로세서에 의해 실행 가능한 프로그램 명령어들과 프로세서가 연산에 사용할 데이터와 프로세서에 의해 처리된 데이터 등을 저 장한다. 객체 맥락화 서버는 입력된 영상 파일에 대하여 프레임 별로 객체를 검출하고, 프레임 별로 검출된 객체의 종류와 수, 객체 속성 정보, 객체의 위치 정보를 포함하는 프레임 맥락화 데이터를 생성하고, 프레임 맥락화 데 이터를 결합하여 영상 데이터에 대한 객체 맥락화 데이터를 생성하여 텍스트 파일로 빅데이터 저장소에 저장한 다. 구체적으로 본 발명의 일 양상에 따른 객체 맥락화 서버는 입력 영상 처리부와, 객체 검출부와, 프레임 맥락화부와, 객체 맥락화부와, 맥락화 저장부를 포함할 수 있다. 객체 맥락화 서버의 각 기능 블록들 즉, 입력 영상 처리부와, 객체 검출부와, 프레임 맥락화부 와, 객체 맥락화부와, 맥락화 저장부는 하나의 물리적인 하드웨어 즉, 컴퓨팅 장치에 포함되어 구성되거나 각 기능 블록들이 각각 다른 컴퓨팅 장치 또는 기능 블록들이 조합되어 둘 이상의 컴퓨팅 장치로 구 성될 수 있다. 도 3은 본 발명의 객체 맥락화 서버가 객체를 맥락화하는 개념을 도시한 것이다. 도 3을 참조하여 객체 맥락화 의 개념을 설명하면, 객체 맥락화 서버는 하나 이상의 CCTV 영상 등의 영상 파일을 입력 받아 처리할 수 있다. 도 3의 예에서 4개의 영상 파일이 입력된다. 4개의 영상 파일은 관련이 있는 영상 파일일 수 있다. 예를 들어, 4개의 영상 파일은 하나의 CCTV 카메라에서 연속적으로 촬영되어 저장된 영상 파일이거나 같은 지역에 위치하는 4개의 CCTV 카메라에서 유사한 시간대에 촬영되어 저장된 영상 파일일 수 있다. 도 3의 예에서 객체 맥락화 서버는 입력된 4개의 영상 파일을 입력된 순서대로 나열한 후 전체 영상 파일 들에 대하여 새로운 프레임 식별자(ID)를 할당(FRAME1부터 FRAMEn)하여 하나의 입력 영상 데이터를 생성한다. 객 체 맥락화 서버는 입력 영상 데이터의 전체 프레임에 대하여 프레임 별로 객체를 검출한다. 객체 맥락화 서버는 프레임 별로 검출된 객체 정보(객체의 종류 및 객체의 속성 정보)를 구조화하여 프레임 맥락화 데 이터를 생성한다. 도 3의 예에서 프레임 맥락화 데이터는 Object로 속성은 Item으로 구조화되었다. 객체 맥락화 서버는 프레 임 별로 구조화된 프레임 맥락화 데이터를 결합하여 입력 영상 데이터에 대한 객체 맥락화 데이터를 생성한다. 입력 영상 처리부와, 객체 검출부와, 프레임 맥락화부와, 객체 맥락화부와, 맥락화 저장부 는 적어도 그 기능의 일부가 메모리에 저장되어 프로세서에서 실행되는 컴퓨터 프로그램 명령어들로 구현 된다. 입력 영상 처리부는 입력된 하나 이상의 영상 파일 각각의 프레임에 대하여 연속된 프레임 식별자를 할당 하여 입력 영상 데이터를 생성한다. 입력 영상 처리부는 입력된 하나 이상의 영상 파일을 입력된 순서대로 나열한 후 전체 영상 파일들에 대하여 새로운 프레임 식별자(ID)를 순차적으로 할당하여 입력된 하나 이상의 영상 파일을 하나의 입력 영상 데이터로 생성한다. 객체 검출부는 영상에서 객체를 검출하도록 학습된 딥러닝 모델을 사용하여 입력 영상 데이터에서 프레임 별로 객체를 검출한다. 객체 검출부는 매 프레임마다 복수의 객체를 한번에 검출한다. 객체 검출부가 사용하는 딥러닝 모델은 COCO 데이터셋과 같이 공지된 데이터 세트를 사용하여 학습될 수 있다. 객체 검출부는 검출된 객체를 분류하여 객체의 종류를 예측하고 객체의 영상 내에서의 위치 정보를 경계상 자를 이용하여 예측한다. 또한, 객체 검출부는 프레임 별로 분류된 객체의 종류와 해당 객체의 영상 내에서의 위치 정보를 포함하는 객체 속성 정보를 생성한다. 객체 검출부가 생성하는 객체 속성 정보는 객체의 위치 정보 즉, 경계상자 좌 표로부터 산출되는 객체 크기 정보, 객체의 분류 정확도(confidence), 객체의 색상(예, 객체가 자동차인 경우 자동차의 색) 등의 정보를 포함할 수 있다. 일 예로 검출된 객체가 사람이고 성별이 인식되는 경우 객체 검출부 는 사람의 성별을 객체 속성으로 추가하여 생성할 수 있다. 객체 검출부가 생성하는 객체 속성은 앞 서 언급한 것으로 제한되지 않으며 필요에 따라 영상에서 인식할 수 있는 속성에 따라 다양하게 추가될 수 있다. 객체 검출부가 객체 검출을 위하여 사용하는 딥러닝 모델은 선택 가능하도록 구성될 수 있다. 객체 맥락화 서버가 제공하는 사용자 인터페이스를 통해 사용자가 객체 검출 딥러닝 모델을 선택할 수 있다. 객체 맥락 화 서버는 사용자 인터페이스를 제공하는 프론트 엔드부(미도시)를 더 포함할 수 있다. 다만, 해당 딥러닝 모델은 객체 검출부가 객체 검출 결과를 이용할 수 있도록 미리 약속된 포맷으로 결과를 출력할 수 있어야 한다. 객체 검출부가 객체를 검출하는데 사용되는 딥러닝 모델은 단일 단계 방식 알고리즘을 사용하는 딥러닝 모 델일 수 있다. 단일 단계 방식을 사용하는 딥러닝 모델은 YOLO 모델, SSD 모델, RetinaNet 모델 등이 있으며, 특히 YOLO 모델을 사용하는 것이 바람직하다. 단일 단계 방식 알고리즘은 속도 측면에서는 이단계 방식 알고리 즘보다 좋은 성능을 내는 것으로 알려져 있다. YOLO(You Only Look Once) 모델은 객체 검출 분야에서 가장 대중적으로 사용되는 실시간 객체 검출 모델로 공지 된 기술로 간략하게 설명한다. YOLO 모델은 카메라 영상에서 각 개체의 절대적인 크기와 위치를 좌표의 형태로 추출한다. YOLO 모델은 카메라 영상에서 2차원 이미지 데이터를 입력 받아 컨볼루션 계층(Convolution Layer)을 이용하여 객체의 절대적인 크기와 위치를 좌표의 형태로 추출하고 객체의 종류를 판별할 수 있다. 일반적으로 YOLO는 다수의 컨볼루션 계층과 완전 연결층(Fully Connected Layer)으로 구성되어 이미지의 특징을 추출한다. 완전 연결층은 추출된 결과로부터 객체의 위치와 종류를 판별한다. SSD(Single Shot Multibox Detector) 모델 또한 공지된 기술로 간략하게 설명한다. SSD 모델은 VGG-16을 백본 으로 사용하되 일부 컨볼루션 계층만 사용하여 특징을 추출하며 추출된 특징은 여러 보조 검출기들을 거치며 객 체 검출을 수행한다. YOLO는 최종 특징맵에만 경계상자와 분류 정보가 있는데 비해 SSD는 여러 히든 레이어에 정보가 분산되어 있다. SSD는 크기가 다른 특징맵에 해당하는 레이어가 6개 있으며 큰 특징맵은 작은 객체를 검 출하고 작은 특징맵은 큰 객체를 검출할 수 있다. SSD는 한 개의 객체에 대하여 다양한 크기의 경계상자를 이용 하여 예측하는 알고리즘이다. RetinaNet 모델 또한 공지된 기술로 간략하게 설명한다. RetinaNet 모델은 크로스 엔트로피 손실함수에서 변형 된 초점 손실(Focal loss) 함수를 사용한다. RetinaNet 모델은 ResNet을 백본으로 사용하며, FPN(Feature Pyramid Networks)을 적용한다. 백본 네트워크인 ResNet은 입력된 전체 이미지에 대해서 특징맵을 계산하는 역 할을 수행한다. RetinaNet 모델은 두 개의 서브네트워크를 포함하며, 첫번째 서브네트워크는 ResNet의 결과에서 객체 분류를 수행하며, 두번째 서브네트워크는 경계상자 회귀(bounding box regression)를 수행한다. 객체 검출부가 객체를 검출하는데 사용되는 딥러닝 모델은 이단계 방식 알고리즘을 사용하는 딥러닝 모델 일 수 있다. 이단계 방식을 사용하는 딥러닝 모델은 Faster R-CNN 모델, R-FCN 모델 등이 있으며, 특히 Faster R-CNN 모델을 사용하는 것이 바람직하다. 이단계 방식 알고리즘은 정확도 측면에서 단일 단계 방식 알고리즘보 다 좋은 성능을 내는 것으로 알려져 있다. Faster R-CNN 모델, R-FCN 모델은 공지된 기술로 간단하게 설명한다. Faster R-CNN 모델은 후보 영역 추출을 위해 사용되는 선택적 검색(Selective Search) 알고리즘으로 인해 발생 하는 병목현상을 해결하고자 후보 영역 추출 작업을 수행하는 RPN(Region Proposal Network)을 추가한구조이다. Faster R-CNN은 RPN과 Fast R-CNN이 합쳐진 모델이다. Faster R-CNN 모델은 원본 이미지를 사전 학 습된 CNN 모델에 입력하여 특징 맵을 얻고, 특징 맵을 RPN에 전달되어 적절한 후보 영역을 산출(region proposals)한다. 후보 영역 산출 과정과 CNN 모델을 통해 얻은 특징 맵에 대하여 RoI 풀링(Pooling)을 수행하여 고정된 크기의 특징 맵을 얻은 후 Fast R-CNN 모델에 고정된 크기의 특징 맵을 입력하여 객체 분류와 경계상자 예측을 수행한다. R-FCN 모델은 RPN을 통해 추출한 관심 영역(RoI)끼리 연산을 공유하며 위치에 대한 정보를 포함하는 특징 맵을 사용하는 구조를 갖는다. R-FCN 모델은 Faster R-CNN 모델에서 RPN 이후 단계의 서브 네트워크를 FCN(Fully Convolutional Network)으로 수정하여 사용한다. 프레임 맥락화부는 객체가 검출된 프레임 별로 검출된 프레임 정보, 객체의 종류와 수, 각 객체의 객체 속 성 정보를 포함하는 프레임 맥락화 데이터를 생성한다. 프레임 맥락화부는 영상 프레임 데이터에서 검출되 어 분류된 객체의 종류와 수, 각 객체의 객체 속성 정보를 포함하는 정보를 구조화하여 프레임 별로 프레임 맥 락화 데이터를 생성한다. 도 4는 본 발명의 객체 맥락화 서버가 하나의 프레임에 대하여 구조화한 프레임 맥락화의 예를 도시한 것이다. 도 4에 도시된 예는 10번 프레임에 대한 프레임 맥락화 데이터를 가정한 것으로, 해당 프레임 맥락화 데이터는 프레임 식별자(ID)와, 프레임에서 검출된 객체의 종류 및 그 수(DetectedObjsDict)와 개별 객체의 객체 속성 정 보(object_#)를 포함하여 구조화하고 있다. 도 4의 예에서 입력 영상 데이터 내에서 프레임을 구분하는 프레임 식별자는 10이며 해당 프레임에서 검출된 객체의 종류는 사람(person)과 자동차(car)이며 사람은 13명 등장하고 자동차는 1대 등장하는 것으로 DetectedObjsDict 항목에 구조화되어 있고, 해당 프레임 맥락화 데이터에 포함된 객체 각각은 object_1 항목부터 object_14 항목까지 구조화되어 있으며, object_8 항목으로 구조화된 객체는 자 동차로 분류된 객체이며 객체 속성 정보로 분류 정확도(confidence)와 객체 위치 정보(location)가 포함되어 프 레임 맥락화 데이터로 생성되어 있다. 도 4에 도시된 예는 하나의 예시로 객체 속성 정보는 객체의 종류에 따라 다양하게 추가될 수 있다. 본 발명의 또 다른 양상에 따르면, 프레임 맥락화부는 설정된 프레임 간격으로 샘플링된 프레임에 대하여 프레임 맥락화 데이터를 생성할 수 있다. 일 예로, 설정된 프레임 간격이 5이면, 프레임 맥락화부는 5번째 프레임, 10번째 프레임, 15번째 프레임 등 설정된 프레임 간격에 해당하는 프레임 들에 대해서만 프레임 맥락화 데이터를 생성할 수 있다. 본 발명의 또 다른 양상에 따르면, 프레임 맥락화부는 현재 프레임에 대하여 검출된 객체의 종류와 수가 이전에 프레임 맥락화 데이터를 생성했던 프레임에 대하여 검출된 객체의 종류와 수와 동일한 경우에는 현재 프 레임에 대하여는 프레임 맥락화 데이터를 생성하지 않을 수 있다. 즉, 프레임 맥락화부는 현재 프레임에 대하여 검출된 객체의 종류와 수가 이전 프레임에 대하여 검출된 객체의 종류와 수와 달라지는 경우에 현재 프 레임에 대하여 프레임 맥락화 데이터를 생성할 수 있다. 객체 맥락화부는 입력 영상 데이터에 대하여 검출된 객체들의 리스트와 프레임 별 상기 프레임 맥락화 데 이터를 포함하는 객체 맥락화 데이터를 생성한다. 객체 맥락화부는 입력 영상 데이터의 적어도 어느 하나 의 프레임에서 검출된 모든 객체들의 리스트를 생성하여 객체가 검출된 프레임들의 프레임 맥락화 데이터들과 함께 결합하여 구조화한다. 맥락화 저장부는 입력 영상 데이터에 대한 객체 맥락화 데이터를 텍스트 파일로 빅데이터 저장소에 저장한 다. 맥락화 저장부는 영상에 대하여 생성된 객체 맥락화 데이터를 저장한 텍스트 파일을 장치 내부의 빅데 이터 저장소에 저장하거나 클라우드 기반의 빅데이터 저장소에 전송하여 저장한다. 빅데이터 저장소는 일 예로 하둡 분산 파일 시스템을 이용하는 저장소이거나 NoSQL(Not-Only SQL)을 이용하는 저장소 일 수 있다. 발명의 양상에 따라서는 맥락화 저장부는 검출된 객체들의 리스트와 프레임 별 객체 맥락화 데이터를 JSON 파일 형태의 텍스트 파일로 저장할 수 있다. JSON 파일은 자바스크립트 오브젝트 표기법으로 클라이언트와 서버 간 데이터를 교환을 손쉽게 할 수 있는 장점이 있는 포맷이며, 널리 사용되고 있는 포맷이므로 상세한 설명은 생략한다. 발명의 양상에 따라서는 맥락화 저장부는 검출된 객체들의 리스트와 프레임 별 객체 맥락화 데이터를 XML 파일 형태의 텍스트 파일로 저장할 수 있다. XML은 eXtensible Markup Language의 약어로 태그를 이용하여 데이 터의 구조를 기술하는 언어로 자유로운 태그 정의 즉, 태그 확장이 가능하다. XML 파일도 데이터 교환에 널리 사용되고 있는 포맷이므로 상세한 설명은 생략한다.발명의 추가적 양상에 따르면, 맥락화 저장부는 추가적으로 객체 맥락화 데이터를 영상 파일 별로 각각 구 분하여 텍스트 파일 형태로 저장할 수 있다. 즉, 도 3의 예에서 맥락화 저장부는 FILE1, FILE2, FILE3, FILE4에 대하여 각각의 영상 파일에 속하는 프레임에 대한 객체 맥락화 데이터를 추가적으로 저장할 수 있다. 본 발명의 추가적 양상에 따르면, 객체 맥락화 서버는 클립 지정부를 더 포함할 수 있고, 클립 지정 부는 설정된 클립 구성 정보에 기초하여 논리적 클립을 구성하여 객체 맥락화 데이터에 추가한다. 클립 지정부는 입력 영상 데이터의 전체 프레임 또는 일부 프레임에 논리적 클립을 구성하고, 논리적 클립 으로 구성된 프레임의 객체 맥락화 데이터에 논리적 클립 구성 정보 즉, 논리적 클립 식별자를 추가한다. 하나 의 논리적 클립에 속하는 프레임은 다른 논리적 클립에도 속할 수 있다. 즉, 하나의 프레임은 다수의 논리적 클 립에 속할 수 있다. 일 예로, 클립 구성 정보는 논리적 클립을 구성하는 프레임 수를 포함하는 정보일 수 있다. 이 경우 클립 지정 부는 입력 영상 데이터의 전체 프레임을 대상으로 클립 구성 정보에 포함된 프레임 수에 해당하는 연속된 프레임들을 논리적 클립들로 구성하여 객체 맥락화 데이터에 추가한다. 예를 들어, 클립 지정부는 클립 구 성 정보에 포함된 프레임 수가 20이면, 입력 영상 데이터의 전체 프레임에 대하여 20개 프레임 마다 분할하여 논리적 클립을 생성하고, 모든 프레임의 객체 맥락화 데이터에 해당 프레임이 속하는 논리적 클립 식별자를 추 가한다. 또 다른 예로, 클립 구성 정보는 시작 프레임 식별자와 마지막 프레임 식별자로 구분되는 논리적 클립 리스트를 포함하는 정보일 수 있다. 이 경우 클립 지정부는 클립 구성 정보에 포함된 논리적 클립 리스트에 해당하 는 프레임들을 논리적 클립들로 구성하여 객체 맥락화 데이터에 추가한다. 예를 들어, 클립 구성 정보에 포함된 논리적 클립 리스트가 클립1(20, 40), 클립2(70, 100)이면, 클립1은 프레임 20번부터 40번까지이며, 클립2는 프 레임 70번부터 100번까지로 구성되며 클립 지정부는 해당 논리적 클립들에 포함되는 프레임의 객체 맥락화 데이터에 해당 프레임이 속하는 논리적 클립 식별자를 추가한다. 클립 구성 정보에 포함되는 논리적 클립 리스트는 사용자가 임의로 설정하는 것으로 관련 있는 영상 프레임들이 논리적 클립으로 지정되는 것이 바람직하다. 논리적 클립은 영상을 분석하여 관련성 있는 프레임들을 구분하는 별도의 딥러닝 모델이나 영상 분석 도구를 사용하여 생성할 수도 있다. 또 다른 예로, 클립 구성 정보는 시작 시간과 종료 시간으로 구분되는 논리적 클립 리스트를 포함하는 정보일 수 있다. 본 발명의 객체 맥락화 서버에 입력되는 영상 파일은 영상 촬영 시간 정보를 포함할 수 있다. 이 경우 클립 지정부는 클립 구성 정보에 포함된 논리적 클립 리스트에 해당하는 영상 촬영 시간의 프레임들 을 논리적 클립들로 구성하여 객체 맥락화 데이터에 추가한다. 예를 들어, 클립 구성 정보에 포함된 논리적 클 립 리스트가 클립1(시작 시간1, 종료 시간1), 클립2(시작 시간2, 종료 시간2)이면, 클립1은 촬영된 시간이 시작 시간1과 종료 시간1 사이에 해당하는 프레임들로 구성되고 클립2는 촬영된 시간이 시작 시간2와 종료 시간2 사 이에 해당하는 프레임들로 구성되며 클립 지정부는 해당 논리적 클립들에 포함되는 프레임의 객체 맥락화 데이터에 해당 프레임이 속하는 논리적 클립 식별자를 추가한다. 도 3에는 클립 지정부가 입력 영상 데이터의 프레임에 대하여 설정된 클립 구성 정보에 따라 논리적 클립을 구 성하고, 구성 결과를 객체 맥락화 데이터에 추가한 예가 도시되어 있다. 도 3의 예에 총 3개의 논리적 클립이 구성되어 있으며, CLIP1은 FILE1의 일부 프레임이 지정되었고, CLIP2는 FILE1과 FILE2에 걸쳐 연속적으로 지정되 었고, CLIP3은 FILE3과 FILE4에 분리되어 지정되어 있다. 도 5는 본 발명의 객체 맥락화 서버가 하나 이상의 영상 파일에 대하여 객체 맥락화를 수행한 예를 도시한 것이 고, 도 6은 본 발명의 객체 맥락화 서버의 논리적 클립 설정의 예를 도시한 것이다. 도 5에 도시된 예는 입력 영상 데이터에 대하여 객체 맥락화가 수행된 결과로 객체 맥락화 데이터의 구조화 예 이다. 객체 맥락화 데이터는 해당 영상에서 검출된 객체들의 리스트 정보(obj_to_detect)와 객체가 검출된 프레 임 별 프레임 맥락화 데이터를 포함하고 있다. 도 6에 도시된 (a)예는 클립 구성 정보가 프레임 수를 포함하는 경우로 해당 프레임 수만큼 분할하여 전체 프레 임에 대하여 논리적 클립을 CLIP1부터 CLIPm까지 생성한 예이고, (b)예는 클립 구성 정보가 시작 프레임 식별자 와 마지막 프레임 식별자로 구분되는 4개의 논리적 클립 리스트를 포함하는 경우로 지정된 프레임에 대하여 CLIP1부터 CLIP4까지 생성한 예이고, (c)예는 클립 구성 정보는 시작 시간과 종료 시간으로 구분되는 논리적 클 립 리스트를 포함하는 경우로 각 영상 파일에서 프레임의 촬영된 시간이 클립 구성 정보의 시작 시간과 종료 시간 사이에 속하는 프레임들을 논리적 클립 CLIP1로 구성한 예(논리적 클립 리스트가 하나의 논리적 클립만 포함 한 예이다)이다. 클립 지정부는 적어도 그 기능의 일부가 메모리에 저장되어 프로세서에서 실행되는 컴퓨터 프로그램 명령 어들로 구현된다. 객체 맥락화 서버가 생성하는 프레임 맥락화 데이터에 포함되는 객체 속성 정보는 해당 프레임에서의 객체 이미지를 더 포함할 수 있다. 보다 구체적으로 객체 검출부가 생성하는 객체 속성 정보는 해당 프레임에서 의 객체 이미지를 더 포함할 수 있다. 객체 검출부에서 검출된 객체는 경계상자로 표시된다. 객체 검출부 는 경계상자 내의 객체 이미지를 추출하여 객체 속성 정보에 포함시킬 수 있다. 객체 검출부가 객체 속성 정보에 포함시킨 객체 이미지는 별도의 저장 위치에 저장된 후 저장 경로가 객체 속성 정보에 포함될 수 있고, 객체 이미지가 텍스트 형태로 인코딩되어 객체 속성 정보에 포함될 수 있다. 객체 속성 정보에 포함된 객 체 이미지는 객체 맥락화 데이터에 포함된다. 영상 검색 서버는 검색 조건을 입력 받아 객체 맥락화 데이터를 대상으로 텍스트 검색 기반으로 검색 조건 에 부합하는 영상을 검색한다. 검색 조건은 검색하고자 하는 객체의 종류와 수가 될 수 있다. 이때 객체의 수는 정확한 개수일 수도 있지만 특 정 범위일 수 있다. 예를 들어, 자동차가 10대 이상 등장하는 영상을 검색하라고 조건을 설정할 수 있다. 검색 조건은 검색하고자 하는 객체의 객체 속성을 포함할 수 있다. 예를 들어, 빨간색 자동차가 등장하는 영상을 검 색하라고 조건을 설정할 수 있다. 또한, 검색 조건은 복수개의 조건에 대하여 논리 연산자를 포함할 수 있다. 영상 검색 서버는 실제 영상을 분석하며 검색하는 것이 아니라 영상에 등장하는 객체들을 맥락화하여 생성 한 JSON 또는 XML 파일 형태 등의 텍스트 데이터인 객체 맥락화 데이터를 대상으로 하는 텍스트 기반 검색이다. 본 발명의 영상 검색 시스템은 원본 영상을 계속 저장하고 있어야만 영상이 검색되는 것이 아니므로 영상 보존기간 정책에 따라 영상이 삭제되어도 된다. 일 예로 본 발명의 영상 검색 시스템이 다수의 CCTV 영상을 대상으로 하는 경우에도 CCTV 영상 보존기간이 도과하여 영상이 삭제되더라도 본 발명의 영상 검색 시스템 을 통하여 영상을 검색할 수 있다. 본 발명의 영상 검색 시스템은 영상이 삭제되었더라도 객체 속성에 각 프레임에서 검출된 객체들의 이미지들을 이용하여 일부 배경이 삭제된 영상을 복원할 수 있다. 따라서, 본 발명 의 영상 검색 시스템은 영상을 검색하기 위하여 영상을 계속 저장할 필요 없어 저장용량을 계속 늘려야 하 는 문제는 발생되지 않을 수 있다. 구체적으로 본 발명의 일 양상에 따르는 영상 검색 서버는 프론트 엔드부와, 백 엔드부를 포함 할 수 있다. 프론트 엔드부와, 백 엔드부는 적어도 그 기능의 일부가 메모리에 저장되어 프로세서에서 실행되는 컴퓨터 프로그램 명령어들로 구현된다. 프론트 엔드부는 그래픽 기반의 사용자 인터페이스 특히 웹 기반의 사용자 인터페이스를 제공한다. 프론트 엔드부가 제공하는 검색 조건 입력을 위한 사용자 인터페이스는 검색 조건을 텍스트로 입력하도록 하는 인 터페이스일 수 있고, 특정 영상 파일만을 대상으로 하는 검색인 경우 해당 영상 파일들에 등장하는 객체들의 리 스트가 제공되어 객체와 객체의 수 또는 수의 범위를 지정할 수 있는 인터페이스일 수 있다. 다만, 이에 제한되 는 것은 아니다. 또한, 프론트 엔드부는 검색 결과를 표시하는 사용자 인터페이스를 제공한다. 검색 결과를 표시하는 사용 자 인터페이스는 검색된 영상들의 리스트를 보여주는 사용자 인터페이스이며 리스트에서 영상을 선택하여 검색 조건에 부합하는 프레임부터 영상을 재생할 수 있다. 검색된 영상들의 리스트는 동일한 영상이 중복되어 표시될 수 있고, 이때는 검색 조건에 부합되는 영상 프레임이 한 영상에 중복하여 존재하는 것을 의미한다. 프론트 엔드부는 영상을 재생하는 사용자 인터페이스를 더 제공할 수 있으며, 영상을 재생하는 사용자 인 터페이스는 검색 결과에서 선택된 영상을 재생하며 영상의 프레임마다 등장하는 객체들의 리스트와 그 수의 변 화를 보여줄 수 있다. 백 엔드부는 객체 맥락화 데이터가 저장된 텍스트 파일들을 대상으로 입력된 조건에 기초하여 영상을 검색 한다. 앞서 설명한 것과 같이 백 엔드부는 실제 영상을 분석하며 검색하지 않고 이미 생성된 객체 맥락화 데이터를 대상으로 텍스트 검색 기반으로 검색한다.본 발명의 추가적 양상에 따르면, 영상 검색 서버의 프론트 엔드부는 검색 조건을 입력 받아 영상 검 색 결과를 대상으로 영상을 재검색하는 사용자 인터페이스를 더 제공할 수 있다. 검색 조건은 검색 조건식을 논 리적 연산자를 이용하여 한번에 여러 조건으로 검색할 수 있으나, 특정한 조건으로 검색이 완료된 영상들을 대 상으로 추가적으로 검색 조건을 입력하여 해당 영상들만으로 영상을 검색할 수 있다. 이때도 백 엔드부는 해당 영상들에 대한 객체 맥락화 데이터들을 대상으로 텍스트 기반으로 검색한다. 본 발명의 추가적 양상에 따르면, 영상 검색 서버의 프론트 엔드부는 검색 대상 영상 파일 리스트를 입력 받아 객체 맥락화 서버에 해당 리스트를 전달하는 사용자 인터페이스를 더 제공할 수 있다. 이때, 객 체 맥락화 서버는 전달받은 영상 파일 리스트에 속한 영상 파일을 대상으로 객체 맥락화를 수행할 수 있다. 즉, 본 발명의 영상 검색 시스템은 사용자가 검색하고자 하는 영상 파일들을 지정하여 검색 대상의 영상을 제한한 상태에서 영상을 검색할 수 있다. 이때, 백 엔드부는 입력된 영상 파일 리스트에 속하는 영상 파일로부터 생성된 객체 맥락화 데이터만을 대 상으로 영상을 검색할 수 있다. 본 발명의 영상 검색 시스템은 원본 영상을 계속 저장하지 않는다. 원본 영상 파일은 영상 보존기간 정책에 따라 삭제될 수 있으므로 객체 맥락화 데이터에 기반한 검색으로 영상이 검색되더라도 재생할 영상이 없을 수도 있다. 이와 같은 상황에도 영상을 재생할 수 있도록 본 발명의 영상 검색 시스템은 객체 맥락화 서버가 생성 하는 프레임 맥락화 데이터에 포함되는 객체 속성 정보에 해당 프레임에서의 객체 이미지를 포함시킬 수 있다. 이 경우 본 발명의 영상 검색 서버는 영상이 삭제되었더라도 객체 속성에 각 프레임에서 검출된 객체들의 이미지들을 이용하여 일부 배경이 삭제된 영상을 복원할 수 있다. 즉, 영상 검색 서버는 검색한 영상 파일 이 삭제된 경우 객체 속성 정보에 포함된 객체 이미지들을 결합하여 복구 영상 파일을 생성할 수 있다. 도 8은 본 발명의 영상 검색 서버가 객체 속성 정보로 삭제된 영상을 복구한 예를 도시한 것이다. 도 8의 (a)가 원본 영상 프레임이고, (b)가 복구된 영상 프레임이다. 도 8의 (b)는 원본 영상 프레임에서 검출된 객체를 제외 한 부분은 전부 제거되어 있는 영상이다. 이상에서 본 발명을 첨부된 도면을 참조하는 실시 예들을 통해 설명하였지만 이에 한정되는 것은 아니며, 이들 로부터 당업자라면 자명하게 도출할 수 있는 다양한 변형 예들을 포괄하도록 해석되어야 한다. 특허청구범위는 이러한 변형 예들을 포괄하도록 의도되었다."}
{"patent_id": "10-2022-0028968", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 객체 맥락화를 이용한 영상 검색 시스템의 블록도이다. 도 2는 본 발명의 객체 맥락화 서버의 블록도이다. 도 3은 본 발명의 객체 맥락화 서버가 객체를 맥락화하는 개념을 도시한 것이다. 도 4는 본 발명의 객체 맥락화 서버가 하나의 프레임에 대하여 구조화한 프레임 맥락화의 예를 도시한 것이다. 도 5는 본 발명의 객체 맥락화 서버가 하나 이상의 영상 파일에 대하여 객체 맥락화를 수행한 예를 도시한 것이다. 도 6은 본 발명의 객체 맥락화 서버의 논리적 클립 설정의 예를 도시한 것이다. 도 7은 본 발명의 영상 검색 서버의 블록도이다. 도 8은 본 발명의 영상 검색 서버가 객체 속성 정보로 삭제된 영상을 복구한 예를 도시한 것이다."}
