{"patent_id": "10-2020-0097778", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0017605", "출원번호": "10-2020-0097778", "발명의 명칭": "다중 카메라를 이용한 물체 검출 및 추적 방법 및 이를 포함하는 인공위성", "출원인": "이성호", "발명자": "이성호"}}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공위성에 있어서, 지상의 이동장치 또는 지상국과 데이터 송, 수신을 수행하는 통신부;상기 인공위성을 구동하기 위한 전력을 제공하는 전원부;상기 인공위성의 자세를 제어하는 자세제어부;상기 인공위성의 이동 및 자세변환을 위한 추력을 제공하는 추력부;상기 인공위성 내 전자장치, 보드, 모듈의 과열 상태나 저온 상태를 감지하고, 이를 정상상태로 회복시키기 위한 작업을 수행하는 구조 및 열 제어부;지상의 영상을 촬영하기 위해 서로 해상도 및 시야각이 상이한 복수의 카메라를 포함하는 멀티카메라부;상기 멀티카메라부에서 촬영한 영상에서 객체를 검출하고, 선택된 객체를 추적하도록 제어하는 객체검출 및 추적부; 및상기 인공위성의 전반적인 제어를 수행하는 프로세서부를 포함하는, 인공위성."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 멀티카메라부는,120도의 시야각과 900m의 해상도를 가지는 광각 카메라, 80도의 시야각과 5m의 해상도를 가지는 협각 카메라 및24도의 시야각과 2m의 해상도를 가지는 줌 카메라를 포함하는, 인공위성."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 객체 검출 및 추적부는, 상기 광각 카메라에서 촬영한 영상에 기초하여 객체를 검출하고, 상기 검출한 객체 중에서 추적할 객체를 선택하고,선택한 객체의 위치를 파악하고,상기 선택한 객체의 위치 및 상기 복수의 카메라 각각의 시야각에 기초하여 상기 선택한 객체가 촬영하고자 하는 카메라의 시야각 내에 포함되도록 상기 인공위성의 자세를 제어하는, 인공위성."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 객체 검출 및 추적부는,상기 광각 카메라에서 촬영한 영상 및 검출한 객체 정보를 이동장치로 전송하고,상기 이동장치로부터 수신한 제어 명령에 기초하여 상기 검출한 객체 중에서 추적할 객체를 선택하는,공개특허 10-2022-0017605-3-인공위성."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 객체 검출 및 추적부는,이동장치로부터 미리 추적하고자 하는 객체 정보를 수신하여 저장하고,상기 검출한 객체와 상기 미리 저장한 객체 정보를 비교하고,비교결과, 상기 검출한 객체 중에서 일치율이 가장 높은 객체를 선택하는, 인공위성."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 객체 검출 및 추적부는, 영상에서 객체를 검출하도록 학습된 인공지능 알고리즘에 기초하여 객체를 검출하고 추적하는, 인공위성."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 인공지능 알고리즘은 항공기에서 촬영한 영상을 흐리게 처리한 영상을 이용하여 학습된, 인공위성."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "서로 상이한 해상도 및 시야각을 갖는 복수의 카메라를 구비한 인공위성의 동작 방법에 있어서,상기 복수의 카메라 중 가장 큰 시야각을 갖는 제1 카메라를 이용하여 지상을 촬영하는 동작;상기 지상을 촬영한 영상에서 객체를 검출하는 동작;상기 검출한 객체 중에서 추적할 객체를 선택하는 동작;상기 복수의 카메라 중 적어도 하나를 이용하여 상기 선택한 객체를 추적하는 동작을 포함하는, 인공위성의 동작 방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 검출한 객체 중에서 추적할 객체를 선택하는 동작은,이동장치로 촬영된 영상 및 상기 검출된 객체를 전송하는 동작;상기 이동장치로부터 수신한 제어 명령에 기초하여 상기 검출한 객체 중에서 추적할 객체를 선택하는 동작을 포함하는, 인공위성의 동작 방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 공개특허 10-2022-0017605-4-상기 검출한 객체 중에서 추적할 객체를 선택하는 동작은,이동장치로부터 미리 추적하고자 하는 객체 정보를 수신하여 저장하는 동작;상기 검출한 객체와 상기 미리 저장한 객체 정보를 비교하는 동작;상기 비교 결과, 상기 검출한 객체 중에서 일치율이 가장 높은 객체를 추적할 객체로 선택하는 동작을포함하는, 인공위성의 동작 방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 지상을 촬영한 영상에서 객체를 검출하는 동작은,학습된 인공지능 알고리즘에 기초하여 상기 지상을 촬영한 영상에서 객체를 검출하는 동작을 포함하는, 인공위성의 동작 방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 인공지능 알고리즘은 항공기에서 촬영한 영상을 흐리게 처리한 영상을 이용하여 학습된, 인공위성의 동작방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 복수의 카메라 중 적어도 하나를 이용하여 상기 선택한 객체를 추적하는 동작은,상기 선택한 객체의 위치를 파악하는 동작;상기 파악한 위치 및 상기 복수의 카메라 각각의 시야각에 기초하여 상기 선택한 객체가 촬영하고자 하는 카메라의 시야각 내에 포함되도록 상기 인공위성의 자세를 제어하는 동작을 포함하는, 인공위성의 동작 방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "서로 상이한 해상도 및 시야각을 갖는 복수의 카메라를 구비한 인공위성의 동작 방법에 있어서,상기 복수의 카메라 중 가장 큰 시야각을 갖는 제1 카메라를 이용하여 지상을 촬영하는 동작;상기 지상을 촬영한 영상에서 객체를 검출하는 동작;상기 검출한 객체 중에서 지상 좌표가 저장되어 있는 적어도 3개의 객체를 인식하는 동작;상기 인식된 적어도 3개의 객체의 지상 좌표를 획득하는 동작;상기 획득한 적어도 3개의 지상 좌표에 기초하여 상기 인공위성의 자세를 판단하는 동작을 포함하는, 인공위성의 동작 방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 지상을 촬영한 영상에서 객체를 검출하는 동작은,공개특허 10-2022-0017605-5-학습된 인공지능 알고리즘에 기초하여 상기 지상을 촬영한 영상에서 객체를 검출하는 동작을 포함하는, 인공위성의 동작 방법."}
{"patent_id": "10-2020-0097778", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 인공지능 알고리즘은 항공기에서 촬영한 영상을 흐리게 처리한 영상을 이용하여 학습된, 인공위성의 동작방법."}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공위성에서 물체를 검출하고 추적하는 방법에 관한 것으로, 서로 상이한 해상도 및 시야각을 갖는 복수의 카메라를 구비한 인공위성의 동작 방법은 상기 복수의 카메라 중 가장 큰 시야각을 갖는 제1 카메라를 이 용하여 지상을 촬영하는 동작, 상기 지상을 촬영한 영상에서 객체를 검출하는 동작, 상기 검출한 객체 중에서 추 적할 객체를 선택하는 동작, 상기 복수의 카메라 중 적어도 하나를 이용하여 상기 선택한 객체를 추적하는 동작 을 포함할 수 있으며. 이에 따라, 지상의 넓은 범위에서의 물체 검출과 동시에 고해상도로 검출된 물체와 주변을 관측할 수 있는 방법을 제공할 수 있게 되었다."}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시 예는 물체 검출 및 추적 방법 및 이를 포함하는 인공위성에 관한 것으로, 좀 더 상세하게는 인공위 성에서 다중 카메라를 이용하여 지상의 물체를 검출하고 추적하는 방법에 관한 것이다."}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공위성 기술의 출현으로 다양한 기술 응용 분야에서 인공위성을 사용하여 데이터를 수집할 수 있게 되었다. 특히 카메라를 이용하여 지상의 물체를 인지하는 것이 가능할 수 있게 되었다. 하지만, 위성에 사용되는 기존의 카메라 해상도가 고정되어 있어서 넓은 범위에서 물체를 검출하고자 하는 욕구 와 관측하고자 하는 특정 지역을 고해상도로 보고자 하는 욕구를 동시에 만족시키지 못한다는 문제점이 있다."}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 문제를 해소하기 위하여, 본 발명의 다양한 실시 예는 해상도가 서로 다른 복수의 카메라를 이용하여 지 상의 넓은 범위에서의 물체 검출과 동시에 고해상도로 검출된 물체와 주변을 관측할 수 있는 방법 및 이를 이용 하는 인공위성을 제공함에 있다. 본 문서에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 다양한 실시 예에 따르면, 인공위성은 지상의 이동장치 또는 지상국과 데이터 송, 수신을 수행하는 통신부, 상기 인공위성을 구동하기 위한 전력을 제공하는 전원부, 상기 인공위성의 자세를 제어하는 자세제어부, 상기 인공위성의 이동 및 자세변환을 위한 추력을 제공하는 추력부, 상기 인공위성 내 전자장치, 보드, 모듈의 과열 상태나 저온 상태를 감지하고, 이를 정상상태로 회복시키기 위한 작업을 수행하는 구조 및 열 제어부, 지상의 영상을 촬영하기 위해 서로 해상도 및 시야각이 상이한 복수의 카메라를 포함하는 멀티카메 라부, 상기 멀티카메라부에서 촬영한 영상에서 객체를 검출하고, 선택된 객체를 추적하도록 제어하는 객체검출 및 추적부 및 상기 인공위성의 전반적인 제어를 수행하는 프로세서부를 포함할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 멀티카메라부는 120도의 시야각과 900m의 해상도를 가지는 광각 카메 라, 80도의 시야각과 5m의 해상도를 가지는 협각 카메라 및 24도의 시야각과 2m의 해상도를 가지는 줌 카메라를 포함할 수 있다.본 개시의 다양한 실시 예에 따르면, 상기 객체 검출 및 추적부는 상기 광각 카메라에서 촬영한 영상에 기초하 여 객체를 검출하고, 상기 검출한 객체 중에서 추적할 객체를 선택하고, 선택한 객체의 위치를 파악하고, 상기 선택한 객체의 위치 및 상기 복수의 카메라 각각의 시야각에 기초하여 상기 선택한 객체가 촬영하고자 하는 카 메라의 시야각 내에 포함되도록 상기 인공위성의 자세를 제어할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 객체 검출 및 추적부는 상기 광각 카메라에서 촬영한 영상 및 검출한 객체 정보를 이동장치로 전송하고, 상기 이동장치로부터 수신한 제어 명령에 기초하여 상기 검출한 객체 중에서 추적할 객체를 선택할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 객체 검출 및 추적부는 이동장치로부터 미리 추적하고자 하는 객체 정보를 수신하여 저장하고, 상기 검출한 객체와 상기 미리 저장한 객체 정보를 비교하고, 비교결과, 상기 검출 한 객체 중에서 일치율이 가장 높은 객체를 선택할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 객체 검출 및 추적부는 영상에서 객체를 검출하도록 학습된 인공지능 알고리즘에 기초하여 객체를 검출하고 추적할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 인공지능 알고리즘은 항공기에서 촬영한 영상을 흐리게 처리한 영상 을 이용하여 학습될 수 있다. 본 개시의 다양한 실시 예에 따르면, 서로 상이한 해상도 및 시야각을 갖는 복수의 카메라를 구비한 인공위성의 동작 방법은 상기 복수의 카메라 중 가장 큰 시야각을 갖는 제1 카메라를 이용하여 지상을 촬영하는 동작, 상기 지상을 촬영한 영상에서 객체를 검출하는 동작, 상기 검출한 객체 중에서 추적할 객체를 선택하는 동작, 상기 복수의 카메라 중 적어도 하나를 이용하여 상기 선택한 객체를 추적하는 동작을 포함할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 검출한 객체 중에서 추적할 객체를 선택하는 동작은 이동장치로 촬영 된 영상 및 상기 검출된 객체를 전송하는 동작 및 상기 이동장치로부터 수신한 제어 명령에 기초하여 상기 검출 한 객체 중에서 추적할 객체를 선택하는 동작을 포함할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 검출한 객체 중에서 추적할 객체를 선택하는 동작은 이동장치로부터 미리 추적하고자 하는 객체 정보를 수신하여 저장하는 동작, 상기 검출한 객체와 상기 미리 저장한 객체 정보를 비교하는 동작, 상기 비교 결과, 상기 검출한 객체 중에서 일치율이 가장 높은 객체를 추적할 객체로 선택하는 동작을 포함할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 지상을 촬영한 영상에서 객체를 검출하는 동작은 학습된 인공지능 알 고리즘에 기초하여 상기 지상을 촬영한 영상에서 객체를 검출하는 동작을 포함할 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 인공지능 알고리즘은 항공기에서 촬영한 영상을 흐리게 처리한 영상 을 이용하여 학습될 수 있다. 본 개시의 다양한 실시 예에 따르면, 상기 복수의 카메라 중 적어도 하나를 이용하여 상기 선택한 객체를 추적 하는 동작은 상기 선택한 객체의 위치를 파악하는 동작 및 상기 파악한 위치 및 상기 복수의 카메라 각각의 시 야각에 기초하여 상기 선택한 객체가 촬영하고자 하는 카메라의 시야각 내에 포함되도록 상기 인공위성의 자세 를 제어하는 동작을 포함할 수 있다. 본 개시의 다양한 실시 예에 따르면, 서로 상이한 해상도 및 시야각을 갖는 복수의 카메라를 구비한 인공위성의 동작 방법은 상기 복수의 카메라 중 가장 큰 시야각을 갖는 제1 카메라를 이용하여 지상을 촬영하는 동작, 상기 지상을 촬영한 영상에서 객체를 검출하는 동작, 상기 검출한 객체 중에서 지상 좌표가 저장되어 있는 적어도 3 개의 객체를 인식하는 동작, 상기 인식된 적어도 3개의 객체의 지상 좌표를 획득하는 동작, 상기 획득한 적어도 3개의 지상 좌표에 기초하여 상기 인공위성의 자세를 판단하는 동작을 포함할 수 있다."}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에서 제안하는 방법 및 장치는 넓은 범위에서 지상의 움직이는 객체를 검출하고, 검출된 객체의 움직임 을 고해상도 영상으로 관측 및 추적할 수 있는 기능을 제공할 수 있다. 또한, 본 개시에서 제안하는 방법 및 장치는 지상을 촬영하는 카메라를 이용하여 인공위성의 자세를 판단하는 기능을 제공할 수 있다.본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0097778", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하에서, 본 발명의 이해를 제공하기 위해 특정 세부 사항이 설명될 수 있다. 그러나, 본 발명이 이러한 세부 사항없이 실시될 수 있다는 것은 통상의 기술자에게 명백할 것이다. 또한, 통상의 기술자는 이하에서 설명되는 본 발명의 다양한 실시 예가 프로세스, 장치, 시스템 또는 컴퓨터 판독 가능 매체 상의 방법과 같은 다양한 방 식으로 구현될 수 있음을 인식할 것이다. 도면에 도시된 구성 요소는 본 발명의 예시적인 실시 예를 도시하고 있을 뿐이고, 발명을 모호하게 하는 것을 피하기 위한 것이다. 또한, 도면 내의 구성 요소들 간의 연결은 직접 연결로 제한되지 않는다. 오히려, 이들 구 성 요소들 사이의 데이터는 중간 구성 요소 또는 장치에 의해 수정, 재 포맷 또는 달리 변경될 수 있다. 또한 추가 또는 더 적은 연결이 사용될 수 있다. \"연결된\" 또는 \"통신적으로 연결된\"이라는 용어는 직접 연결, 하나 이상의 중개 장치를 통한 간접 연결 및 무선 연결을 포함하는 것으로 이해되어야 한다. 또한, 관련 기술을 적용함으로써, 통상의 기술자는 특정 동작이 선택적으로 수행될 수 있고, 동작들이 본 명세서에 제시된 특정 순서로 제한되지 않을 수 있으며, 특정 동작들이 다른 순서로 수행될 수 있으며, 특정 동작들은 동시에 수행될 수 있음을 인식하여야 한다. 이하에서, 용어 \"이동장치\"는 사용자가 인공위성과 직접 통신하고 실시간으로 인공위성과 데이터를 교환할 수 있게 하는 다양한 유형의 전자 장치를 지칭할 수 있다. 또한, 전자 장치는 휴대폰, 팜 컴퓨터, 태블릿 PC, 노트 북 컴퓨터, 데스크톱 컴퓨터, AR(augmented reality) 장치, VR(virtual reality) 장치, 스마트 고글, 스마트 안경 및 스마트 시계와 같은 스마트 웨어러블, 원격 제어 장치, 자동차에 내장된 컴퓨팅 장치 등을 포함할 수 있다.도 1은 다양한 실시 예에 따른 하나 또는 그 이상의 인공위성(104a-104n)과 이동장치(102a-102m) 사이의 통신을 위한 시스템의 개략도를 도시한 도면이다. 도 1에 도시된 바와 같이, 복수의 인공위성(104a-104n)이 특정 한 대형을 형성하고 비행할 수 있고, 이동장치(102a-102m)와 직접 통신적으로 연결되거나 또는 지상국을 통해 통신이 연결될 수 있다. 다양한 실시 예에서, 인공위성(104a-104n)은 지구로부터 볼 때 움직이는 것처럼 보이도록 지구에 대해 공전하는 LEO(low earth orbiting) 인공위성을 포함할 수 있다. 다양한 실시 예에서, 인공위성(104a-104n)은 또한 지구 에서 바라볼 때 이들이 동일 위치에 머물러 있는 것처럼 보이도록 지구의 회전과 동일한 속도로 지구를 공전하 는 지구 동기 인공위성 (즉, 지구의 회전 기간과 동등한 궤도 기간)을 포함할 수 있다. 다양한 실시 예에서, 인 공위성(104a-104n)은 인공위성 네트워크를 형성하기 위해 서로 통신하고, 즉 인공위성 간 통신을 수행하고 데이터를 공유할 수 있다. 다양한 실시 예에서, 각각의 인공위성(104a-104n)은 마이크로 셋(microsat), 나노셋(nanosat) 및 큐브셋 (cubesat)과 같은 다양한 크기의 인공위성일 수 있다. 또한, 인공위성 네트워크에 포함되는 인공위성 (104a-104n)의 수 및 위치는 지구의 전체 표면적을 커버하도록 결정될 수 있다. 이에 따라, 하나의 이동장치 (예를 들어, 102a)는 지구 상 임의의 위치에 있는 다른 이동장치 (예를 들어, 102m)와 통신할 수 있다. 예를 들 면, 이동장치(102a)로부터 전송된 신호는 이동장치(102a) -> 인공위성(104a) -> 인공위성(104n) -> 이동장치 (102m)를 경유하여 형성된 통신 채널을 통해 다른 이동장치(102m)로 전달될 수 있다. 다양한 실시 예에서, 인공위성(104a-104n)은 개별적으로 임무를 수행하거나 또는 연합하여 함께 임무를 수행할 수 있다. 다양한 실시 예에서, 임무는 이동장치(102a-102m)와의 직접 통신, 지표면 관측, 기상 추적, 해상 측정 및 천체의 과학적 연구 등을 포함할 수 있다. 임무는 또한 극지 풍경 및 빙산, 지구 표면과 대기, 해양 순환, 물/에너지 사이클에 대한 다양한 과학적 연구와 주어진 지역의 식물성 플랑크톤, 부유 입자상 물질 및/또는 용 존 유기물의 농도에 대한 모니터링을 포함할 수 있다. 또한, 임무는 카메라(광학, SAR(synthetic aperture radar), IR (Infrared) 등)를 사용하여 표면적 지형을 분석하고 특정 영역에서 발생하는 특정 현상을 실시간으 로 직접 인지하고 점검하는 것을 포함할 수 있으며, 또한, 임무는 지표면에 있는 특정 객체를 검출하고 추적하 는 것을 포함할 수 있다. 다양한 실시 예에서, 이동장치(102a 또는 102m)는 인공위성(104a-104n)과 실시간으로 직접 데이터 통신할 수 있 다. 여기서 데이터는 텍스트 메시지, 음성 메시지, JPEG 형식의 이미지/사진, MPEG 형식의 비디오 클립, 원격측 정 데이터(telemetry data) 등의 하나 또는 그 이상을 포함할 수 있다. 이와 같이, 인공위성(104a-104n)은 이동 장치(102a 및 102m)의 두 사용자가 서로 실시간으로 전화 통화를 하도록 할 수 있다. 직접 통신의 경우, 임의의 지상국 또는 기지국도 시스템에서 2 개의 이동장치(102a 및 102m) 사이의 통신을 위해 필요하지 않을 수 있다. (이하, 지상국이라는 용어는 지구상에서 고정된 또는 이동하는 위치를 가지는 국사를 지칭한다). 따라서, 다양한 실시 예에서, 이동장치(예를 들어 102m)가 사막 또는 원격/외딴 지역과 같은 영역에 위치하여 이동장치 (102m)가 이동장치간 무선 통신 서비스를 제공할 수 있는 임의의 지상국 또는 임의의 기지국에 도달할 수 없는 경우에도, 두 이동장치 사이의 전화 통화가 가능할 수 있다. 다양한 실시 예에서, 이동장치가 제한된 출력 전력으로 인해 인공위성(104a-104n)으로 직접 신호를 전송할 수 없을 수 없는 경우, 인공위성(104a-104n)과 직접 통신할 수 있는 이동 중계 안테나에 연결되어 인공위성(104a- 104n)과 통신을 수행할 수 있다. 다양한 실시 예에서, 이동 장치는 지상국을 통해 인공위성(104a-104n)과 통신을 수행할 수 있다. 지상국 은 인공위성(104a-104n)과 정보를 공유 (및 저장)하고 인공위성을 대신하여 다양한 작업을 수행할 수 있는 서버를 가질 수 있다. 다양한 실시 예에서, 지상국은 무선으로, 유선으로 또는 인터넷을 통해 하나 이상의 서버 (또는 컴퓨 팅 장치)와 통신 가능하게 연결할 수 있다. 다양한 실시 예에서, 서버 중 하나는 광고 회사의 컴퓨팅 장치일 수 있고, 지상국을 통해 인공위성(104a-104n)에 광고 정보를 전송할 수 있다. 또한, 서버 중 하나는 이미지에서 객체를 검출하는 인공지능 알고리즘을 학습시킬 수 있는 것일 수 있다. 다양한 실시 예에서, 이동장치(예를 들어, 102a)의 사용자는 인공위성에 저장된 데이터에 직접 접속할 수 있고, 그리고/또는 이동장치(예를 들어, 102a)의 사용자는 하나 이상의 인공위성을 제어하여 하나 이상의 우주 임무를 수행할 수 있다. 다양한 실시 예에서, 이동장치(102a)는 인공위성(예를 들어 104b)을 제어하기 위해 인공위성 (예를 들어 104a)에 데이터를 전송할 수 있는데, 여기서 데이터는 사용자 ID, 암호, 목표 인공위성, 인공위성식별 정보, 커버리지 영역 결정을 위한 각도 범위, 제어 목적, 관찰 시간 범위 등과 같은 하나 이상의 제어 파 라미터를 포함할 수 있으나 이에 제한되지는 않는다. 도 2는 다양한 실시 예에 따른 인공위성에 탑재된 복수의 카메라를 이용하여 객체를 검출하고 추적하는 예를 설 명하는 도면이다. 도 2를 참조하면 인공위성(예: 104a)은 시야각(field of view, FOV) 및 해상도가 서로 상이한 복수의 카메라 (210, 220, 230)를 탑재할 수 있다. 여기서, 시야각은 카메라가 한 번에 관측할 수 있는 영역의 크기를 각으로 표현한 것을 말할 수 있다. 예를 들면, 카메라는 120도의 시야각과 900m의 해상도를 가지는 광각 카메라일 수 있고, 카메라는 80도의 시야각과 5m의 해상도를 가지는 협각 카메라일 수 있고, 카메라는 24도의 시야각과 2m의 해상도를 가지는 줌 카메라일 수 있다. 다양한 실시 예들에 따르면 인공위성(104a)은 넓은 시야각과 해상도를 가진 카메라를 먼저 사용하여 넓은 범위의 영역에서 객체를 검출할 수 있다. 이때, 카메라에서 찍은 이미지에서 객체를 검출하기 위하여 학습된 인공지능 알고리즘을 사용할 수 있다. 카메라에서 찍은 이미지에서 객체가 검출되면, 시야각과 해상도가 더 작은 카메라(예: 협각 카메라 )를 이용하여 검출된 객체를 고해상도로 관측할 수 있으며, 또한, 시야각과 해상도가 더욱 작은 카메 라(예: 줌 카메라)를 이용하여 검출된 객체를 고해상도 영상으로 관측 및 추적할 수 있다. 도 3은 다양한 실시 예에 따른 인공위성의 개략적인 구성을 도시한 도면이다. 도 3을 참조하면, 다양한 실시 예에 따른 인공위성(104a)은 프로세서부, 통신부, 전원부, 자세 제어부, 추력부, 구조 및 열제어부 및 멀티카메라부 및 객체 검출 및 추적부를 포함 할 수 있다. 프로세서부는 인공위성(104a)을 운용하기 위한 기본 프로그램 및 인공위성(104a)에 부여된 임무를 수행하 기 다양한 응용 프로그램을 실행할 수 있다. 프로그램 실행을 위하여 프로세서부는 FPGA, EPLD, CPU, ASIC 과 같은 하나 이상의 프로세싱 유닛과 프로그램 및 관련 데이터들을 저장할 수 있는 메모리를 포함할 수 있다. 메모리로는 SSD, DRAM, SRAM 등이 사용될 수 있다. 프로세서부는 응용 프로그램을 실행하면서 임무를 수행 하는데 필요한 제어 신호를 생성하여 인공위성(104a)의 각 부로 전달할 수 있으며, 인공위성(104a)의 각 부로부 터 수신한 데이터를 처리하여 추가적인 제어 신호를 생성할 수 있다. 그뿐만 아니라 사용자에게 수행하고 있는 관련 정보를 제공하기 위하여 이동장치(102a-102m) 또는 지상국으로 데이터를 전송할 수 있다. 또한, 이동 장치(102a-102m) 또는 지상국으로부터 임무 관련 제어 신호를 수신하고, 수신한 제어 신호에 따라 제어를 실행하기 위하여 인공위성(104a)의 각 부를 위한 다른 제어 신호를 생성하여 전달한다. 일 실시 예로 프로세서 부는 이동장치(102a-102m) 또는 지상국으로부터 객체 추적 명령을 수신하면, 멀티카메라부의 적 어도 하나의 카메라가 지상을 촬영하도록 하는 제어 신호를 멀티카메라부로 전달할 수 있고, 객체를 검출 하고 추적하도록 하는 제어 신호를 객체 검출 및 추적부로 전달할 수 있다. 또 다른 일 실시 예로 프로세서부는 이동장치(102a-102m) 또는 지상국으로부터 객체 검출을 위하여 학습된 인공지능 알고리즘을 획득하고, 객체 검출 및 추적부가 해당 인공지능 알고리즘을 사용하도록 설정 할 수 있다. 일 실시 예에 따라 객체 검출을 위한 인공지능 알고리즘은 서버(110, 108)에서 학습될 수 있다. 프로세서부는 인공위성(104a)의 각 부에서 오는 제어 요청에 기초하여 인공위성(104a)의 각 부를 제어하기 위한 제어 신호를 생성할 수 있다. 예를 들면, 객체 검출 및 추적부는 검출된 객체를 추적하기 위하여 인 공위성(104a)의 자세를 변경시킬 필요가 있는 경우 프로세서부로 자세 제어 요청을 전달할 수 있다. 프로 세서부는 전달받은 자세 제어 요청에 기초하여 자세제어부로 인공위성(104a)의 자세를 변경시키도록 하는 제어 신호를 전달할 수 있다. 프로세서부는 통신부를 통해 이동장치(102a-102m) 또는 지상국과 통신할 수 있다. 통신부는 이동장치(102a-102m) 또는 지상국과의 데이터 송 수신 기능을 제공할 수 있다. 이에 따라 이동장치(102a-102m) 간 또는 이동장치(102a-102m)와 지상국간 통신을 제공할 수 있을뿐만 아니라, 인공위 성(104a)에서 생성하는 콘텐츠를 이동장치(102a-102m) 또는 지상국으로 전달할 수 있다. 통신부는 이동장치(102a-102m) 또는 지상국과의 제어 관련 데이터를 송, 수신하기 위한 기능을 제공 할 수 있고, 또한 통신부는 실제 사용자가 개발하는 응용 프로그램 또는 카메라로 찍은 영상에서 물체를 검출하고 추적하는 데 사용하는 인공지능 알고리즘을 포함하는 응용 프로그램을 운용 중에 수신하여 사용 중인 응용 프로그램을 업데이트하거나 새로운 응용 프로그램으로 변경하여 적용할 수 있다. 통신부에서 수신한 데이터는 프로세스부로 전달될 수 있다. 또한, 복수의 인공위성(104a-104n)이 인공위성 네트워크를 형성하는 경우, 통신부는 다른 인공위성과 의 데이터 송신 및 수신 기능을 제공할 수도 있다. 전원부는 인공위성(104a)을 구동하기 위한 전력을 제공하며 배터리를 포함할 수 있다. 전원부는 태양 광을 이용하여 전력을 생산할 수 있도록 태양전지판 및 태양광 발전 장치를 포함할 수 있다. 자세제어부는 인공위성(104a)의 자세를 제어할 수 있다. 프로세서부로부터의 제어명령을 수신하여 사 용자가 원하는 형태로 인공위성(104a)의 자세를 제어할 수 있다. 일 실시 예로서 자세제어부는 프로세서부 로부터의 제어명령에 따라 좌로 또는 우로 회전할 수 있다. 또한, 자세제어부는 프로세서부로부 터의 제어명령에 따라 멀티카메라부의 카메라의 시야각 내에 검출된 객체가 포함될 수 있도록 인공위 성(104a)의 자세를 제어할 수 있다. 추력부는 인공위성(104a)을 원하는 위치로 이동시키거나 특정 자세를 만들기 위한 추력을 제공한다. 큰 인 공위성의 경우에는 액체 추력기를 사용할 수 있으며, 소형 위성의 경우에는 전기 추력기를 사용할 수 있다. 추 력부는 자세제어부 또는 프로세서부의 제어 명령에 따라 추력을 제공할 수 있다. 구조 및 열제어부는 특정보드나 모듈이 과열이거나 저온이 되는 것을 회피하기 위하여 히터(heater)를 켜 거나 쿨러(cooler)를 작동시킬 수 있다. 필요한 경우에는 온도 제어를 위하여 인공위성(104a)의 자세를 제어하 도록 자세제어부에 직접 또는 프로세서부를 통해 제어 명령을 전달할 수 있다. 일 실시 예로서 저온 으로 나타난 모듈이나 보드가 태양쪽으로 위치되어 온도가 올라갈 수 있도록 하기 위하여 자세제어부에 인 공위성(104a)을 회전하도록 요청할 수 있다. 또 다른 일 실시 예로서 과열된 모듈의 온도를 내리기 위하여 과열 된 모듈이 태양의 반대 방향에 위치하도록 자세제어부에 인공위성(104a)의 회전을 요청할 수 있다. 구조 및 열제어부는 특정보드나 모듈의 온도를 측정하기 위한 온도 측정 센서를 포함할 수 있다. 멀티카메라부는 시야각 및 해상도가 서로 상이한 복수의 카메라(210, 220, 230)를 포함할 수 있다. 예를 들면, 멀티카메라부는 120도의 시야각과 900m의 해상도를 가지는 광각 카메라, 80도의 시야각과 5m의 해상도를 가지는 협각 카메라 및 24도의 시야각과 2m의 해상도를 가지는 줌 카메라를 포함할 수 있다. 이외에도 멀티카메라부는 다양한 조합의 복수의 카메라를 포함할 수 있다. 멀티카메라부에 복수의 카메라(210, 220, 230)는 프로세서부의 제어에 기초하여 적어도 하나의 카메 라가 지상을 촬영할 수 있다. 일 실시 예에 따라, 광각 카메라만으로 지상을 촬영하거나, 광각 카메라 및 줌 카메라를 이용하여 동시에 지상을 촬영할 수도 있다. 멀티카메라부는 촬영을 통해 획득 한 영상 또는 이미지를 객체 검출 및 추적부로 전달할 수 있다. 객체 검출 및 추적부는 멀티카메라부로부터 오는 영상 또는 이미지로부터 객체를 검출하고, 영상 내 에서 검출한 객체의 이동을 추적할 수 있다. 객체 검출 및 추적부는 멀티카메라부의 넓은 시야각을 가지는 광각 카메라로부터 온 영상에서 객체를 검출할 수 있다. 일 실시 예에 따라, 객체 검출 및 추적부는 프로세서부에 의해 전달된 사용 자로부터의 제어 신호에 기초하여 객체를 검출할 수 있다. 이때, 사용자는 추적하고자 하는 객체를 지정하여 제 어 신호를 통해 객체 검출 및 추적부에 알려줄 수 있다. 일 실시 예에 따라, 객체 검출 및 추적부는 학습된 인공위성 알고리즘을 이용하여 영상에서 객체를 검출할 수 있다. 객체 검출 및 추적부는 검출한 객체의 위치를 판단할 수 있다. 일 실시 예에 따라, 객체 검출 및 추적부 는 검출된 객체의 GPS 좌표를 획득할 수 있다. 객체 검출 및 추적부는 검출된 객체를 고해상도로 관측할 수 있도록 하기 위하여 멀티카메라부에 시 야각은 좁으면서 해상도가 높은 협각 카메라 또는 줌 카메라를 이용하여 영상을 촬영하도록 제어할 수 있다. 일 실시 예에 따라, 객체 검출 및 추적부는 해당 제어를 프로세서부를 통해 전달할 수 있다. 또한, 객체 검출 및 추적부는 검출된 객체를 추적하기 위해 인공위성(104a)의 자세를 제어하기 위한 명령 을 자세제어부로 전달할 수 있다. 일 실시 예에 따라, 객체 검출 및 추적부는 검출된 객체를 고해상 도로 추적하기 위해 협각 카메라 또는 줌 카메라를 이용하여 검출된 객체를 촬영하도록 할 수 있으며, 이때, 검출된 객체가 협각 카메라 또는 줌 카메라의 시야각 내에 들어오도록 객체의 위치에 기반하여 인공위성(104a)의 자세를 제어할 수 있다. 객체 검출 및 추적부는 학습된 인공지능 알고리즘을 이용하여 영상에서 객체를 검출하고 추적할 수 있다. 인공지능 알고리즘은 서버(110, 108) 또는 이동장치(102a-102m)에서 학습될 수 있다. 인공지능 알고리즘의 일 예가 도 3에 도시되어 있다. 도 4는 인공지능 알고리즘의 일 예로서 합성곱 신경망(convolutional neural network, CNN) 구조를 도시한 도 면이다. 이미지, 동영상, 문자열과 같은 구조적 공간 데이터를 식별하는 데 있어서는 도 4에 도시된 것과 같은 합성곱 신경망 구조를 가지는 인공지능 알고리즘이 효과적일 수 있다. 합성곱 신경망은 이미지의 공간 정보를 유지하면 서 인접 이미지와의 특징을 효과적으로 인식할 수 있다. 도 4를 참조하면, 합성곱 신경망은 특징 추출 층과 분류 층을 포함할 수 있다. 특징 추출 층은 합 성곱(convolution)을 이용하여 이미지에서 공간적으로 가까이에 위치한 것들을 합성하여 이미지의 특징을 추출 할 수 있다. 특징 추출 층은 합성곱 층(61, 65)과 풀링 층(63, 67)을 복수 개 쌓은 형태로 구성될 수 있다. 합성곱 층 (61, 65)은 입력 데이터에 필터를 적용한 후 활성화 함수를 적용한 것일 수 있다. 합성곱 층(61, 65)은 복수의 채널을 포함할 수 있으며, 각각의 채널은 서로 상이한 필터 및/또는 서로 상이한 활성화 함수를 적용한 것일 수 있다. 합성곱 층(61, 65)의 결과는 특징 지도(feature map)일 수 있다. 특징 지도는 2차원 행렬 형태의 데이터 일 수 있다. 풀링 층(63, 67)은 합성곱 층(61, 65)의 출력 데이터, 즉 특징 지도를 입력으로 받아서 출력 데이 터의 크기를 줄이거나, 특정 데이터를 강조하는 용도로 사용될 수 있다. 풀링 층(63, 67)은 합성곱 층(61, 65) 의 출력 데이터의 일부 데이터 중에서 가장 큰 값을 선택하는 맥스 풀링(max pooling), 평균값을 선택하는 평균 풀링(average pooling), 최소 값을 선택하는 민 풀링(min pooling)의 함수를 적용하여 출력 데이터를 생성할 수 있다. 일련의 합성곱 층과 풀링 층을 거치면서 생성되는 특징 지도는 그 크기가 점점 작아질 수 있다. 마지막 합성곱 층과 풀링 층을 거쳐 생성된 최종 특징 지도는 1차원 형태로 변환되어 분류 층으로 입력될 수 있다. 분류 층은 완전 연결된 인공 신경망 구조일 수 있다. 분류 층의 입력 노드의 개수는 최종 특징 지도의 행렬 의 원소 수에 채널의 수를 곱한 것과 동일할 수 있다. 인공 지능 알고리즘을 학습시킨다는 것은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수는 인공 지능 알고리즘의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 완전 연결된 인공 신경망의 경우, 학습에 의하여 각 시냅스의 가중치가 결정될 수 있으며, 합성곱 신 경망의 경우, 학습에 의하여 특징 지도를 추출하기 위한 합성곱 층의 필터가 결정될 수 있다. 인공지능 알고리즘의 학습은 지도 학습에 의하여 수행될 수 있다. 지도 학습은 학습 데이터에 대한 레이블 (label)이 주어진 상태에서 인공지능 알고리즘을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 지능 알고리즘에 입력되는 경우 인공지능 알고리즘이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 본 발명에서 사용하는 인공지능 알고리즘의 목적은 위성에서 촬영한 영상에서 객체를 찾아내는 것일 수 있다. 따라서, 본 발명에서 사용하는 인공지능 알고리즘의 학습을 위하여 인공위성에서 촬영한 영상과 해당 영상에서 포착한 객체를 이용할 수 있다. 또한, 더 많은 학습 데이터를 획득하기 위하여 인공위성보다 낮은 궤도에 있는 항공기에서 촬영한 영상을 흐리게 처리(blurring)한 후 학습을 위한 영상으로 사용하는 것도 가능할 수 있다. 도 5는 본 개시의 다양한 실시 예에 따른 인공위성에서 객체를 검출하고 추적하는 동작을 도시한 흐름도이다. 도 5를 참조하면, 동작 S100에서, 인공위성은 광각 카메라를 이용하여 넓은 영역의 지상을 촬영할 수 있다. 동작 S200에서, 인공위성은 촬영 영상에서 객체들을 검출할 수 있다. 일 실시 예에 따라, 영상에서의 객체 검출 은 학습된 인공지능 알고리즘에 의하여 수행될 수 있다. 동작 S300에서, 인공위성은 검출한 객체들 중 추적할 객체를 선택할 수 있다. 동작 S400에서, 인공위성은 선택된 객체에 대해 광각 카메라, 협각 카메라 또는 줌 카메라 중 적어도 하나를 이 용하여 선택된 객체를 추적할 수 있다. 도 6은 본 개시의 다양한 실시 예에 따른 인공위성에서 추적할 객체를 선택하는 동작의 일 실시 예를 도시한 흐 름도이다. 도 6을 참조하면, 동작 S310에서, 인공위성은 광각 카메라로 촬영한 영상을 이동장치(102a-102m)로 전송할 수 있다. 이동장치(102a-102m)의 사용자는 이동장치(102a-102m)에 표시되는 영상에 포함된 객체 또는 인공위성이 검출한 객체 중에서 적어도 하나를 선택할 수 있다. 일 실시 예에 따라, 미도시되어 있지만 이동장치(102a- 102m)는 더 높은 해상도의 영상을 인공위성에 요구하는 제어 명령을 인공위성으로 전달할 수 있고, 이에 응답하 여 인공위성은 협각 카메라 및/또는 줌 카메라로 촬영한 영상을 이동장치(102a-102m)로 전송할 수 있다. 동작 S320에서, 인공위성은 객체 선택 관련 제어 명령을 수신할 수 있다. 그리고 이에 기초하여 추적할 객체를 선택할 수 있다. 도 7은 본 개시의 다양한 실시 예에 따른 인공위성에서 추적할 객체를 선택하는 동작의 다른 일 실시 예를 도시 한 흐름도이다. 도 7을 참조하면, 동작 S330에서, 인공위성은 이동장치(102a-102m)로부터 미리 추적하고자 하는 객체 정보를 획 득하여 저장할 수 있다. 일 실시 예에 따라, 객체 정보는 학습된 인공지능 알고리즘의 출력 형식을 가질 수 있 다. 동작 S340에서, 인공위성은 동작 S200에서 검출된 객체와 미리 저장되어 있는 객체 정보를 비교할 수 있다. 동작 S350에서, 인공위성은 비교결과 일치율이 가장 높은 객체를 선택할 수 있다. 추가적으로 동작 S360에서, 인공위성은 이동장치(102a-102m)로 선택된 객체를 전송하고, 사용자의 확인 요청을 받을 수 있다. 이동장치(102a-102m)는 이에 응답하여 추적하고자 하는 객체가 맞는 지에 대한 정보를 제공할 수 있다. 도 8은 본 개시의 다양한 실시 예에 따른 인공위성에서 선택한 객체를 추적하는 동작의 일 실시 예를 도시한 흐 름도이다. 도 8을 참조하면, 동작 S410에서, 인공위성은 선택된 객체의 위치를 파악할 수 있다. 동작 S420에서, 인공위성은 영상을 촬영한 카메라에 기초하여 카메라의 시야각 안애 선택된 객체의 위치가 포함 되도록 그리고 이동 경로가 포함되도록 인공위성의 자세를 조정할 수 있다. 동작 S430에서, 인공위성은 광각 카메라, 협각 카메라, 줌 카메라 중 적어도 하나를 이용하여 선택된 객체를 추 적할 수 있다. 도 9는 본 개시의 다양한 실시 예에 따른 인공위성에서 객체를 검출하여 인공위성의 자세를 판단하는 동작을 도 시한 흐름도이다. 도 9를 참조하면, 동작 S100에서, 인공위성은 광각 카메라를 이용하여 넓은 영역의 지상을 촬영할 수 있다. 동작 S200에서, 인공위성은 촬영 영상에서 객체들을 검출할 수 있다. 일 실시 예에 따라, 영상에서의 객체 검출 은 학습된 인공지능 알고리즘에 의하여 수행될 수 있다. 동작 S500에서, 인공위성은 검출한 객체들 중에서 지상의 좌표를 알고 있는 객체를 검출할 수 있다. 이를 위하 여 인공위성은 협각 카메라 또는 줌 카메라 중 적어도 하나를 이용하여 지상을 더 높은 해상도로 촬영할 수 있 다. 예를 들면, 인공위성은 지상의 랜드마크 빌딩, 호수, 강, 산 등에 대한 경도, 위도 좌표를 저장하고 있고, 동작 S200에서의 촬영 영상 또는 동작 S500에서의 추가적인 촬영 영상 속에서 검출된 객체들 중에 좌표 정보가 저장되어 있는 객체를 인식할 수 있다. 이 경우 인공위성은 3개 이상의 객체를 인식하여 해당 객체에 대응하는 좌표를 획득할 수 있다.동작 S600에서, 인공위성은 획득한 3개 이상의 좌표에 기초하여 인공위성의 자세를 판단할 수 있다. 즉, 종래의 태양이나 별추적기를 이용하여 수행하던 인공위성의 자세 판단을 카메라로 촬영한 영상속의 랜드마크 객체들을 이용하여 수행할 수 있다. 본 발명에서 제안하는 인공위성 및 인공위성의 동작에 기초하면 해상도가 서로 다른 복수의 카메라를 이용하여 지상의 넓은 범위에서의 객체 검출과 함께 고해상도로 검출된 객체와 주변을 관측하면서 추적할 수 있는 방법을 제공할 수 있을 것이다. 또한, 검출된 객체 중 좌표를 인식할 수 있는 객체를 이용하여 인공위성의 자세를 판단 하는 방법도 제공할 수 있다. 본 발명의 다양한 양태를 구현하는 프로그램은 네트워크를 통해 원격 위치(예를 들어, 서버)로부터 접속될 수 있다. 이러한 데이터 및/또는 프로그램은 다양한 기계 판독가능 매체 중의 임의의 것을 통해 전달될 수 있다. 기계 판독가능 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 홀로 그래픽 장치와 같은 광학 매체, 광 자기 매체 및 ASIC(application specific integrated circuit), PLD (programmable logic device), 플래시 메모리 장치, ROM 및 RAM 장치와 같은 프로그램 코드를 저장 또는 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있으나 이에 제한되는 것은 아니다. 본 발명의 실시 예들은 동작이 수행되도록 하는 하나 이상의 프로세서 또는 처리 유닛에 대한 명령으로 하나 이 상의 비-일시적 컴퓨터 판독 가능 매체에 인코딩 될 수 있다. 하나 이상의 비-일시적 컴퓨터 판독 가능 매체는 휘발성 및 비-휘발성 메모리를 포함할 수 있다. 하드웨어 구현 또는 소프트웨어/하드웨어 구현을 포함하여 대안 적인 구현이 가능할 수 있다. 하드웨어 구현 기능은 ASIC, 프로그래머블 어레이, 디지털 신호 처리 회로 등을 사용하여 실현될 수 있다. 따라서, 임의의 청구항에서의 \"수단\"이라는 용어는 소프트웨어 및 하드웨어 구현 모 두를 포함할 수 있다. 유사하게, 본 명세서에서 사용되는 용어 \"컴퓨터 판독 가능 매체\"는 그 위에 구현된 명령 의 프로그램을 갖는 소프트웨어 및/또는 하드웨어, 또는 이들의 조합을 포함한다. 이러한 구현 대안을 염두에 두고, 도면 및 첨부된 설명은 통상의 기술자가 프로그램 코드 (즉, 소프트웨어)를 작성하고 그리고/또는 요구되 는 처리를 수행하기 위한 회로 (즉, 하드웨어)를 제조하는 데 필요한 기능 정보를 제공한다는 것을 이해해야 한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2020-0097778", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시 예에 따른 하나 또는 그 이상의 인공위성과 이동장치) 사이의 통신을 위한 시스템의 개략도 를 도시한 도면이다. 도 2는 다양한 실시 예에 따른 인공위성에 탑재된 복수의 카메라를 이용하여 객체를 검출하고 추적하는 예를 설 명하는 도면이다. 도 3은 다양한 실시 예에 따른 인공위성의 개략적인 구성을 도시한 도면이다. 도 4는 인공지능 알고리즘의 일 예로서 합성곱 신경망 구조를 도시한 도면이다. 도 5는 본 개시의 다양한 실시 예에 따른 인공위성에서 객체를 검출하고 추적하는 동작을 도시한 흐름도이다. 도 6은 본 개시의 다양한 실시 예에 따른 인공위성에서 추적할 객체를 선택하는 동작의 일 실시 예를 도시한 흐 름도이다. 도 7은 본 개시의 다양한 실시 예에 따른 인공위성에서 추적할 객체를 선택하는 동작의 다른 일 실시 예를 도시 한 흐름도이다. 도 8은 본 개시의 다양한 실시 예에 따른 인공위성에서 선택한 객체를 추적하는 동작의 일 실시 예를 도시한 흐 름도이다. 도 9는 본 개시의 다양한 실시 예에 따른 인공위성에서 객체를 검출하여 인공위성의 자세를 판단하는 동작을 도 시한 흐름도이다. 도면의 설명과 관련하여, 동일 또는 유사한 구성요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다."}
