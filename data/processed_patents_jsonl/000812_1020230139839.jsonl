{"patent_id": "10-2023-0139839", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0056003", "출원번호": "10-2023-0139839", "발명의 명칭": "얼굴데이터에 타겟이미지를 합성하는 방법 및 이를 위한 시스템", "출원인": "씨제이올리브네트웍스 주식회사", "발명자": "이주현"}}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "얼굴데이터에 타겟이미지를 합성하는 방법에 있어서,(a) 임의의 인물이 포함된 이미지프레임들을 포함하는 원본영상을 로드하는 단계; (b) 합성하고자 하는 얼굴데이터를 결정하는 단계;(c) 상기 원본영상 내 인물의 얼굴을 상기 (b)단계에서 결정된 얼굴데이터로 변환하여 제1 합성얼굴을 생성하는단계;(d) 합성하고자 하는 타겟이미지를 결정하는 단계;(e) 상기 제1 합성얼굴에 상기 타겟이미지를 합성시켜 제2 합성얼굴을 생성하는 단계;를 포함하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2 합성얼굴을 생성하는 단계는 이미지합성 알고리즘이 사용되되,상기 이미지합성 알고리즘은,임의의 3차원 모델에 이미지 텍스처를 씌우는 단계;상기 3차원 모델의 다각도 데이터를 수집하는 단계;복수 개의 상이한 얼굴들을 대상으로 상기 3차원 모델을 활용한 얼굴 합성 모델을 학습시키는 단계;이미지 세그멘테이션 모델을 학습시키는 단계;들을 포함하는 학습 방법에 의해 학습된 것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 합성하고자 하는 얼굴데이터를 결정하는 단계는,상기 (a)단계에서의 임의의 인물이 가지는 원본 얼굴데이터, 특정 인물의 얼굴을 클로닝 한 클론 얼굴데이터,또는 가상 인물의 가상 얼굴데이터 중 어느 하나의 얼굴데이터를 결정하는 단계인 것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 타겟이미지는 로고, 키 비주얼(key visual), 또는 상품이미지 중 적어도 하나인 것을 특징으로 하는,공개특허 10-2025-0056003-3-얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 (d)단계는 복수 개의 타겟이미지들을 결정하는 단계이고,상기 (e)단계는 상기 복수 개의 타겟이미지들을 상기 제1 합성얼굴에 합성시켜 제2 합성얼굴을 생성하는 단계인것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 (d)단계 이후 및 (e)단계 이전,타겟이미지를 표시할 타겟이미지 위치를 결정하는 (d1)단계;를 더 포함하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 (d1)단계는, 상기 제1 합성얼굴 상에 선택 가능한 복수 개의 위치들이 표시된 타겟이미지 설정용 인터페이스가 제공된 상태에서 사용자의 선택입력에 의해 타겟이미지 위치가 결정되는 것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 타겟이미지 설정용 인터페이스 상에 표시되는 복수 개의 위치들은, 상기 제1 합성얼굴 상의 영역들 중 상기 타겟이미지의 합성적합도가 기준값 이상인 영역들로 정의되는 것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 합성적합도는,타겟이미지 노출정도 및/또는 타겟이미지 렌더링난도에 의해 정해지는 것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법.공개특허 10-2025-0056003-4-청구항 10 제1항에 있어서,상기 (e)단계는,상기 제1 합성얼굴의 임의의 위치에 상기 타겟이미지를 합성시켜 제2 합성얼굴을 생성하되,상기 임의의 위치는, 상기 제1 합성얼굴을 생성할 시 사용된 얼굴데이터 상에서 사전에 정의된 복수 개의 타겟이미지 위치들 중 어느 하나의 위치인 것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 사전에 정의된 복수 개의 타겟이미지 위치들은, 상기 얼굴데이터에 의해 정의되는 제1 합성얼굴의 영역들중 타겟이미지 노출정도 및/또는 타겟이미지 렌더링난도에 의해 정해지는 합성적합도가 기준값 이상인 영역들인것을 특징으로 하는,얼굴데이터에 타겟이미지를 합성하는 방법."}
{"patent_id": "10-2023-0139839", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "얼굴데이터에 타겟이미지를 합성하는 서비스 서버에 있어서, 상기 서비스 서버는 중앙처리유닛 및 메모리를 포함하며,상기 중앙처리유닛은, 상기 메모리에 저장되어 있는 얼굴데이터에 타겟이미지를 합성하는 방법을 실행시키기 위한 명령어들을 실행시키는 것을 특징으로 하되,상기 얼굴데이터에 타겟이미지를 합성하는 방법은,(a) 임의의 인물이 포함된 이미지프레임들을 포함하는 원본영상을 로드하는 단계; (b) 합성하고자 하는 얼굴데이터를 결정하는 단계;(c) 상기 원본영상 내 인물의 얼굴을 상기 (b)단계에서 결정된 얼굴데이터로 변환하여 제1 합성얼굴을 생성하는단계;(d) 합성하고자 하는 타겟이미지를 결정하는 단계;(e) 상기 제1 합성얼굴에 상기 타겟이미지를 합성시켜 제2 합성얼굴을 생성하는 단계;를 포함하는,서비스 서버."}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 얼굴데이터에 타겟이미지를 합성하는 방법 및 이를 위한 시스템에 관한 것이다. 구체적으로 본 발명은 실시간으로 인물영상을 송출할 때 인물의 얼굴면에 로고, 상품이미지 등과 같은 특정 타겟이미지를 합성하되, 이 때 타겟이미지가 얼굴면에 정밀하게 합성되어 상대방이 합성된 영상을 보았을 때 이질감 없이 자연스러운 인물영 상 및 타겟이미지를 볼 수 있도록 한 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 얼굴데이터에 타겟이미지를 합성하는 방법 및 이를 위한 시스템에 관한 것이다. 구체적으로 본 발명 은 실시간으로 인물영상을 송출할 때 인물의 얼굴면에 로고, 상품이미지 등과 같은 특정 타겟이미지를 합성하되, 이 때 타겟이미지가 얼굴면에 정밀하게 합성되어 상대방이 합성된 영상을 보았을 때 이질감 없이 자 연스러운 인물영상 및 타겟이미지를 볼 수 있도록 한 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 가상인물을 구현해 내는 기술력이 크게 발전하면서 가상인물을 다양한 영역에서 활용하고자 하는 시도들이 점차 증가하고 있다. 이러한 가상인물은 기본적으로 이미지 합성기술을 활용한 것으로, 인공지능 알고리즘을 활 용한 이미지 합성기술은 종전에 비해 더 정교한 합성이 가능하게 한다. 한편, 최근에는 라이브 커머스, 온라인 화상 미팅과 같이 인물이 포함된 화면을 공유하여 커뮤니케이션을 하는 사례가 크게 증가하고 있다. 이러한 커뮤니케이션 상황에서는 인물이 전달하고자 하는 메시지를 상대방에게 더 잘 전달하기 위해 부수적인 효과도 많이 활용되곤 하는데, 현재까지 상용화 된 효과들로는 단순히 채팅창에 이 모티콘을 표시하는 정도, 화면 상에 특수 효과를 출력시키는 정도에 그치고 있다. 본 발명은 이러한 수요에 맞추어 실시간으로 송출되는 인물의 얼굴면에 타겟이미지를 합성시킴으로써 광고 효과, 또는 메시지 전달 효과를 높이기 위한 것이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2009-0090449호(2009.08.26. 공개)"}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 화상 커뮤니케이션 시 실시간으로 송출되는 얼굴데이터에 특정 타겟이미지를 합성시키는 것을 목적으 로 한다. 특히 라이브 커머스와 같이 광고 효과를 극대화 시켜야 하는 상황에서 화면 내 등장하는 인물들의 얼굴에 특정 브랜드의 로고, 키 비주얼, 상품이미지 등의 타겟이미지를 합성시켜 소비자들에게 노출이 가능하게 하는 것을 목적으로 한다. 또한 본 발명은 위 과정에서 타겟이미지가 실제 인물의 얼굴면에 그려진 것과 같은 느낌이 들도록 얼굴데이터의 다각도로 정교한 합성이 가능하게 함으로써 화상 커뮤니케이션의 상대방이 이질감을 느끼지 않도록 하는 것을 목적으로 한다. 한편, 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 위와 같은 문제점을 해결하기 위한 것으로, 본 발명에 따른 얼굴데이터에 타겟이미지를 합성하는 방 법은, (a) 임의의 인물이 포함된 이미지프레임들을 포함하는 원본영상을 로드하는 단계; (b) 합성하고자 하는 얼굴데이터를 결정하는 단계; (c) 상기 원본영상 내 인물의 얼굴을 상기 (b)단계에서 결정된 얼굴데이터로 변환 하여 제1 합성얼굴을 생성하는 단계; (d) 합성하고자 하는 타겟이미지를 결정하는 단계; (e) 상기 제1 합성얼굴 에 상기 타겟이미지를 합성시켜 제2 합성얼굴을 생성하는 단계;를 포함할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 제2 합성얼굴을 생성하는 단계는 이미지 합성 알고리즘이 사용되되, 상기 이미지합성 알고리즘은, 임의의 3차원 모델에 이미지 텍스처를 씌우는 단계; 상기 3차원 모델의 다각도 데이터를 수집하는 단계; 복수 개의 상이한 얼굴들을 대상으로 상기 3차원 모델을 활 용한 얼굴 합성 모델을 학습시키는 단계; 이미지 세그멘테이션 모델을 학습시키는 단계;들을 포함하는 학습 방 법에 의해 학습된 것일 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 합성하고자 하는 얼굴데이터를 결정하는 단계는, 상기 (a)단계에서의 임의의 인물이 가지는 원본 얼굴데이터, 특정 인물의 얼굴을 클로닝 한 클론 얼굴 데이터, 또는 가상 인물의 가상 얼굴데이터 중 어느 하나의 얼굴데이터를 결정하는 단계인 것을 특징으로 할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 타겟이미지는 로고, 키 비주얼(key visual), 또는 상품이미지 중 적어도 하나인 것을 특징으로 할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 (d)단계는 복수 개의 타겟이미지들을 결 정하는 단계이고, 상기 (e)단계는 상기 복수 개의 타겟이미지들을 상기 제1 합성얼굴에 합성시켜 제2 합성얼굴 을 생성하는 단계인 것을 특징으로 할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 (d)단계 이후 및 (e)단계 이전, 타겟이미 지를 표시할 타겟이미지 위치를 결정하는 (d1)단계; 를 더 포함할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 (d1)단계는, 상기 제1 합성얼굴 상에 선 택 가능한 복수 개의 위치들이 표시된 타겟이미지 설정용 인터페이스가 제공된 상태에서 사용자의 선택입력에 의해 타겟이미지 위치가 결정되는 것을 특징으로 할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 타겟이미지 설정용 인터페이스 상에 표시 되는 복수 개의 위치들은, 상기 제1 합성얼굴 상의 영역들 중 상기 타겟이미지의 합성적합도가 기준값 이상인 영역들로 정의되는 것을 특징으로 할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 합성적합도는, 타겟이미지 노출정도 및/ 또는 타겟이미지 렌더링난도에 의해 정해지는 것을 특징으로 할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 (e)단계는, 상기 제1 합성얼굴의 임의의 위치에 상기 타겟이미지를 합성시켜 제2 합성얼굴을 생성하되, 상기 임의의 위치는, 상기 제1 합성얼굴을 생성 할 시 사용된 얼굴데이터 상에서 사전에 정의된 복수 개의 타겟이미지 위치들 중 어느 하나의 위치인 것을 특징 으로 할 수 있다. 또한, 상기 얼굴데이터에 타겟이미지를 합성하는 방법에 있어서, 상기 사전에 정의된 복수 개의 타겟이미지 위 치들은, 상기 얼굴데이터에 의해 정의되는 제1 합성얼굴의 영역들 중 타겟이미지 노출정도 및/또는 타겟이미지 렌더링난도에 의해 정해지는 합성적합도가 기준값 이상인 영역들인 것을 특징으로 할 수 있다. 본 발명의 또 다른 실시예에 따른 얼굴데이터에 타겟이미지를 합성하는 서비스 서버에 있어서, 상기 서비스 서 버는 중앙처리유닛 및 메모리를 포함하며, 상기 중앙처리유닛은, 상기 메모리에 저장되어 있는 얼굴데이터에 타 겟이미지를 합성하는 방법을 실행시키기 위한 명령어들을 실행시키는 것을 특징으로 하되, 상기 얼굴데이터에 타겟이미지를 합성하는 방법은, (a) 임의의 인물이 포함된 이미지프레임들을 포함하는 원본영상을 로드하는 단 계; (b) 합성하고자 하는 얼굴데이터를 결정하는 단계; (c) 상기 원본영상 내 인물의 얼굴을 상기 (b)단계에서 결정된 얼굴데이터로 변환하여 제1 합성얼굴을 생성하는 단계; (d) 합성하고자 하는 타겟이미지를 결정하는 단 계; (e) 상기 제1 합성얼굴에 상기 타겟이미지를 합성시켜 제2 합성얼굴을 생성하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 사용자가 선택한 얼굴데이터 상에 타겟이미지를 정밀하게 합성하여 상대방에게 화면 상으로 이를 전달할 수 있는 효과가 있다. 또한 본 발명에 따르면 얼굴데이터의 다각도 상에서 인공지능 알고리즘을 활용한 타겟이미지 합성이 이루어질 수 있으므로 이를 보는 상대방이 이질감을 느끼지 않게 되는 효과가 있다. 또한 본 발명에 따르면 특히 라이브 커머스와 같은 상업용 화상 커뮤니케이션 시 기업 로고, 상품이미지 등을 더 효과적으로 노출시킬 수 있어 광고 효과를 극대화 할 수 있는 효과가 있다. 한편, 본 발명에 의한 효과는 이상에서 언급한 것들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 효과들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적과 기술적 구성 및 그에 따른 작용 효과에 관한 자세한 사항은 본 발명의 명세서에 첨부된 도면 에 의거한 이하의 상세한 설명에 의해 보다 명확하게 이해될 것이다. 첨부된 도면을 참조하여 본 발명에 따른 실시예를 상세하게 설명한다. 본 명세서에서 개시되는 실시예들은 본 발명의 범위를 한정하는 것으로 해석되거나 이용되지 않아야 할 것이다. 이 분야의 통상의 기술자에게 본 명세서의 실시예를 포함한 설명은 다양한 응용을 갖는다는 것이 당연하다. 따 라서, 본 발명의 상세한 설명에 기재된 임의의 실시예들은 본 발명을 보다 잘 설명하기 위한 예시적인 것이며 본 발명의 범위가 실시예들로 한정되는 것을 의도하지 않는다. 도면에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다른 구현들에서는 상세한 설명 의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다. 또한, 본 발명의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 본 발명의 기능 블록들 중 하나 이상은 동일 기능을 실행하는 다양한 하드웨어 및 소프트웨어 구성들의 조합일 수 있다. 또한, 어떤 구성요소들을 포함한다는 표현은 “개방형”의 표현으로서 해당 구성요소들이 존재하는 것을 단순히 지칭할 뿐이며, 추가적인 구성요소들을 배제하는 것으로 이해되어서는 안 된다. 나아가 어떤 구성요소가 다른 구성요소에 “연결되어” 있다거나 “접속되어” 있다고 언급될 때에는, 그 다른 구성요소에 직접적으로 연결 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 한다. 도 1은 본 발명에 따른 얼굴데이터에 타겟이미지를 합성하는 방법 및 시스템을 소개하기 위해 간략히 도시한 것 이다. 도 1을 참고할 때, 본 발명은 서비스 서버에 의해 제공될 수 있는데, 서비스 서버는 기본적으로는 화 상 커뮤니케이션이 가능하게 하는 시스템적 환경을 제공할 수 있다. 화상 커뮤니케이션이란, 일측에서 인물, 특 히 얼굴이 포함된 영상을 전송하였을 때 1인 또는 복수의 상대방들이 이를 보면서 커뮤니케이션을 할 수 있도록 한 것을 의미하며, 여기에는 예를 들어 라이브 커머스, 온라인 화상 미팅 등이 포함될 수 있다. 또한, 홈쇼핑 방송 프로그램, 쇼 프로그램 등과 같이 지상파방송, 케이블방송을 통하여 시청자들에게 콘텐츠가 전달되는 형식 의 것들도 본 발명에서 언급되는 화상 커뮤니케이션의 한 종류에 포함될 수 있다. 이렇듯 얼굴이 포함된 인물이 화면 상에 등장하고, 이를 상대방이 수신하여 보거나 채팅, 구매 등의 인터랙티브 행위까지 이어질 수 있는 시 스템적 환경이 제공될 수 있다면 본 상세한 설명에서 언급하게 될 화상 커뮤니케이션의 한 종류에 포함될 수 있 음을 이해한다. 다시 도 1을 참고할 때, 서비스 서버는 사용자의 얼굴을 입력으로 수신한 후, 후술하게 될 합성 과정을 거 쳐 최종적으로 도면 우측의 타겟이미지가 합성된 얼굴을 생성한 후 이를 상대방에게 전달하는 것을 특징으 로 할 수 있다. 쉬운 예로, 서비스 서버는 라이브 커머스를 진행하는 진행자의 실시간 사용자 얼굴을 수신할 수 있으며, 이 때 진행자의 얼굴 일부에 현재 판매가 진행 중인 상품의 상품이미지, 혹은 상품 판매의 주체가 되는 기업의 로고를 합성시킨 후 복수의 시청자들이 시청 중인 각 단말기들로 이를 전송할 수 있다. 이 때, 상기 서비스 서 버는 진행자의 실제 얼굴 그대로를 활용하여 여기에 타겟이미지를 합성시킬 수도 있으며, 또는 진행자의 실제 얼굴 대신 가상인물의 얼굴을 활용하여 여기에 타겟이미지를 합성시킬 수도 있다. 또 다른 예로, 서비스 서버는 화상 채팅 서비스를 제공하도록 구현된 것일 수 있으며, 특정 사용자가 타 사용자에게 화상 채팅을 하고자 할 때에 특정 사용자의 실시간 사용자 얼굴을 수신한 뒤 얼굴면 중 적어도 일부 의 영역에 타겟이미지를 합성시킴으로써 타 사용자가 이를 보도록 할 수 있다. 이 경우, 타 사용자 입장에서는 상기 특정 사용자가 얼굴에 페이스 페인팅, 또는 문신을 한 것처럼 느낄 수 있으며, 상기 특정 사용자는 얼굴면 에 다양한 종류의 타겟이미지들을 바꾸어 가며 합성시킴으로써 화상 채팅 서비스의 재미를 배가시킬 수 있다. 한편, 본 발명에서는 사용자의 얼굴면 위로 타겟이미지를 단순 출력시키는 것이 아니라, 다각도의 얼굴면에 타 겟이미지를 그 각도에 맞게 합성시킴으로써, 이를 통해 사용자 얼굴의 방향이 콘텐츠 진행 중 계속 바뀐다 하더라도 타겟이미지 역시 그 얼굴 방향에 맞추어 표시가 되도록 함으로써 이를 보는 타 사용자가 얼굴면과 타겟이 미지가 별개의 것처럼 움직이는 소위 이질감을 느끼지 않게 하는 것을 하나의 특징으로 할 수 있다. 본 발명의 상세한 설명에서는 이렇게 사용자의 얼굴이 수신되었을 때, 위 얼굴의 표면에 타겟이미지를 합성시키 는 과정에 대해 설명할 것이다. 참고로, 본 상세한 설명에서는 \"얼굴\"이라는 용어와 \"얼굴데이터\"라는 용어를 혼용하여 사용될 수 있는데, 서비스를 경험하게 되는 사용자들(전송측 사용자 및 수신측 사용자) 입장에서는 얼 굴에 타겟이미지가 합성된 것으로 인식될 것이며, 실제 연산을 수행하는 장치(특히 서비스 서버)의 입장에서는 얼굴데이터에 타겟이미지를 합성하는 것으로 이해하는 것이 이치에 맞으므로, 얼굴이라는 용어와 얼굴데이터라 는 용어가 각각 사용될 때에는 각 상황에 따라 달리 사용된 것임을 이해하기로 한다. 한편, 도 1에서는 전체 서비스를 제공하는 과정에 서비스 서버만 주체적으로 연산을 수행하는 것처럼 도시 하였으나, 이 때 서비스 서버는 반드시 어느 하나의 서버 컴퓨터를 의미하는 것은 아닐 수 있으며, 네트워 크에 의해 연결된 복수 개의 컴퓨팅 장치들의 집합일 수도 있다. 예를 들어, 화상 커뮤니케이션 환경을 제공하 기 위한 장치(서버)는 별도로 존재하고, 얼굴데이터에 타겟이미지를 합성시키기 위한 장치(서버)도 별도로 존재 할 수 있는데, 이들 장치들의 집합을 서비스 서버로 정의할 수도 있다. 또한, 상기 서비스 서버를 비롯하여 본 발명에 따른 타겟이미지 합성에 참여되는 모든 종류의 연산장치들 은 중앙처리유닛 및 메모리를 포함하는 것을 전제로 한다. 이 때 중앙처리유닛은 컨트롤러(controller), 마이크 로 컨트롤러(microcontroller), 마이크로 프로세서(microprocessor), 마이크로 컴퓨터(microcomputer) 등으로 도 불릴 수 있다. 또한 중앙처리유닛은 하드웨어(hardware) 또는 펌웨어(firmware), 소프트웨어, 또는 이들의 결합에 의해 구현될 수 있는데, 하드웨어를 이용하여 구현하는 경우에는 ASIC(application specific integrated circuit) 또는 DSP(digital signal processor), DSPD(digital signal processing device), PLD(programmable logic device), FPGA(field programmable gate array) 등으로, 펌웨어나 소프트웨어를 이용 하여 구현하는 경우에는 위와 같은 기능 또는 동작들을 수행하는 모듈, 절차 또는 함수 등을 포함하도록 펌웨어 나 소프트웨어가 구성될 수 있다. 또한, 메모리는 ROM(Read Only Memory), RAM(Random Access Memory), EPROM(Erasable Programmable Read Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), 플래쉬(flash) 메모리, SRAM(Static RAM), HDD(Hard Disk Drive), SSD(Solid State Drive) 등으로 구현될 수 있다. 연산장치의 종류에는 제한이 없다 할 것이나 바람직하게는 서버 컴퓨터, 휴대용 단말기(랩탑 컴퓨터, 스마트폰 등), 데스크탑 컴퓨터 등이 연산장치의 대표적인 예시들이 될 수 있다. 또한 경우에 따라 상기 연산장치는 클라 우드 서버의 형태로 이용 가능한 것일 수 있다. 도 2는 본 발명에 따른 얼굴데이터에 타겟이미지를 합성하는 방법의 각 단계들을 순서에 따라 나열한 것이다. 도 2를 참고할 때, 본 발명에 따른 얼굴데이터에 타겟이미지를 합성하는 방법은 가장 먼저 임의의 인물이 포함 된 이미지프레임들을 포함하는 원본영상을 로드하는 단계(S100)로부터 시작될 수 있다. 원본영상은, 후술하게 될 합성의 기초가 될 수 있는 영상데이터를 의미하며, 이러한 원본영상은 의도에 따라 직 접 업로드 또는 스트리밍 된 영상일 수 있고, 바람직하게는 실시간으로 스트리밍 되는 영상일 수 있다. 다만, 원본영상은 위의 설명에 의해 제한되는 것은 아니며, 상기 원본영상은 사용자의 명령입력에 따라 연산장치가 네 트워크로부터 획득한 임의의 것일 수도 있다. 이 때, 원본영상은 인물(사람)의 얼굴면을 포함한 것일 수 있다. 원본영상의 일 예로, 라이브 커머스를 위해 진행자의 얼굴면이 포함된 상태로 스트리밍 되는 영상, 또는 온라인 화상 채팅을 위해 사용자의 얼굴면이 포함된 상태로 스트리밍 되는 영상, 또는 영상 콘텐츠 제작을 위해 사용자 의 얼굴면이 포함된 상태로 업로드 된 영상 등을 들 수 있다. 한편, 원본영상은 반드시 인물을 포함하여야 할 필요는 없다. 예를 들어 원본영상은 강아지, 고양이 등과 같은 동물들, 해바라기 등과 같은 식물들, 또는 물건들을 포함할 수 있다. 다만, 원본영상 내에는 추후 특정 인물의 얼굴이 합성될 수 있는 영역 및 타겟이미지가 합성될 수 있는 영역, 즉 합성영역이 식별 가능할 정도로는 존재 하여야 한다. 합성영역은 폐곡선에 의해 형성되는 영역일 수 있으며, 바람직하게는 얼굴의 형상이 합성될 수 있 도록 원형 내지 타원형의 영역일 수 있다. 사각형, 삼각형, 또는 그 밖에 정규 도형으로 정의될 수 없는 영역이 라 할지라도 폐곡선에 의한 합성영역이 식별 가능하다면 해당 원본영상은 합성에 적절한 영상으로 판단될 수 있다. 합성영역의 식별은, 예를 들어 원본영상 내로부터 연산장치에 의한 폐곡선 인식이 가능 (이 때 폐곡선은 색 깔과 색깔의 경계선에 의한 것일 수도 있고 실제 영상 내에 실선이 존재하는 것일 수도 있는 등 다양한 상황에 의해 존재할 수 있음)하여 식별이 이루어질 수 있으며, 나아가 얼굴임을 구별할 수 있는 눈, 코, 입, 귀, 머리 카락 등의 존재여부가 폐곡선 인식에 참고될 수 있다. 참고로, 위 원본영상으로부터 식별되는 합성영역(얼굴영역) 외의 영역들은 최종적으로 가상인물 합성영상에서 사용자의 제스쳐, 또는 움직임 등을 나타낼 수 있도록 그대로 활용될 수 있다. 즉, 원본영상 내 사용자가 박수 를 치는 행위를 하였을 때, 최종 가상인물 합성영상에서는 사용자의 얼굴영역만 바뀐 채 박수 치는 행위는 동일 하게 출력될 수 있다. 경우에 따라 원본영상으로부터 인식된 사용자의 제스쳐 또는 움직임은 서비스 서버에 의 하여 재구성되어 최종 가상인물 합성영상에서 출력될 수도 있다. 예를 들어, 원본영상 내 사용자가 달리기를 하 는 제스쳐를 취하였을 때, 최종 가상인물 합성영상에서는 사용자의 얼굴영역도 바뀜과 동시에 가상인물이 실제 운동장에서 달리는 듯한 애니메이션으로 재구성되어 출력될 수 있다. 한편, 상기 원본영상 내에 사용자로부터 직접 설정된 영역이 합성영역으로 지정될 수 있다. 예를 들어 서비스 서버는 원본영상을 로드하면서 사용자에게 가상인물의 얼굴을 어느 영역에 합성시킬 것인지를 정하도록 화 면 인터페이스를 제공할 수 있으며, 사용자는 마우스, 터치펜 등을 이용하여 원하는 영역에 폐곡선을 그림으로 써, 혹은 이미 서비스 서버에 의해 선택가능한 여러 개의 합성영역 후보군들 중 하나를 선택함으로써 합성 영역을 지정할 수 있다. 원본영상을 로드하는 단계 이후에는, 합성하고자 하는 얼굴데이터를 결정하는 단계(S200)가 실행될 수 있다. 앞 선 원본영상에는 합성이 가능한 합성영역이 포함 및 식별될 수 있고, 이러한 합성영역에는 얼굴의 형상이 합성 될 수 있음에 대해 언급하였는데, S200 단계에서는 어떤 종류의 얼굴을 합성할 것인지에 대한 얼굴데이터 결정 이 이루어질 수 있다. 도 3을 참고할 때, 도면의 상단에는 사용자에 의해 선택 가능한 얼굴데이터들이 예시적으로 도시되어 있는데, 여기에는 상기 원본영상 내 인물의 얼굴과 동일한 원본 얼굴데이터, 특정 인물의 얼굴을 클로닝 한 클론 얼굴데 이터, 또는 가상 인물의 가상 얼굴데이터가 포함되어 있음을 확인할 수 있다. 즉, 일 예시에서 서비스 서버 는 사용자로 하여금 어느 얼굴데이터를 합성시킬 것인지를 결정하게 할 수 있으며, 이 과정에서 서비스 서 버는 사용자 측에 얼굴데이터 선택용 인터페이스를 제공하도록 구현될 수도 있다. 한편, S200단계에서는 서비스 서버가 상기 원본영상 내 인물의 얼굴을 먼저 식별하게 한 후, 해당 얼굴에 합성 가능한 얼굴데이터만을 선별하여 선택하게 할 수도 있다. 예를 들어, 서비스 서버는 실시간으로 입력 및 로딩되고 있는 원본영상 내 얼굴면을 분석한 뒤 원본영상 내 얼굴의 얼굴형과 유사한 얼굴형을 가지는 얼굴 데이터, 원본영상 내 얼굴과 유사한 이목구비를 가지는 얼굴데이터, 원본영상 내 얼굴과 유사한 면적을 가지는 얼굴데이터 등 원본영상 내 얼굴을 대신하여 합성하기에 적합한 얼굴데이터들을 데이터베이스(미도시)로부터 선 별하여 사용자에게 선택 가능하게 제시할 수도 있다. 이 과정에서 서비스 서버는 원본영상 내 얼굴로부터 원본 얼굴데이터를 추출해 낼 수 있으며, 추출한 원본 얼굴데이터와 데이터베이스 내에 기 저장되어 있는 복수 개의 얼굴데이터들과 비교 연산을 수행함으로써 합성하기에 적합한 얼굴데이터들을 순위화 한 후 이 중 정해진 개수의 얼굴데이터를 사용자에게 제시하여 선택하게 할 수 있다. 한편, 위 설명에서는 얼굴데이터가 사용자에 의해 선택되는 실시예에 대해서만 언급하였는데, 위 S200단계는 서 비스 서버로 하여금 자동으로 임의의 얼굴데이터를 선택 및 결정하게 하는 단계로 구현될 수도 있다. 즉, 서비스 서버가 데이터베이스 내 기 저장되어 있는 복수 개의 얼굴데이터들 중 상기 원본영상 내 얼굴을 대 체할 수 있는 최적의 얼굴데이터를 하나 선택 및 결정하게 함으로써 별도의 사용자 선택입력 없이도 최적의 합 성용 얼굴데이터가 결정되도록 할 수 있다. S200단계 이후에는 상기 원본영상 내 인물의 얼굴을 앞서 사용자(또는 서비스 서버)에 의해 선택 및 결정된 얼 굴데이터로 변환하여 제1 합성얼굴을 생성하는 단계(S300)가 실행될 수 있다. 도 3을 참고할 때, S300단계는 서 비스 서버가 얼굴합성 알고리즘을 이용하여 제1 합성얼굴을 생성해 내는 단계임을 알 수 있다. S300단계의 결과물인 제1 합성얼굴은 서비스 서버에 입력된 원본영상 내 얼굴이 원본 얼굴데이터, 클론 얼 굴데이터, 또는 가상 얼굴데이터 등으로 변환 및 재구성 된 것으로, 위 제1 합성얼굴은 서비스 서버가 연 산에 의해 편집 가능한 포맷의 것일 수 있다. 다시 말해, 서비스 서버로 입력되는 실시간 사용자 얼굴이단순 영상에 불과한 것이었다면, 얼굴합성 알고리즘에 의해 합성된 제1 합성얼굴은 3차원 모델링에 의해 재구성된 것으로서 편집이 가능한 형태의, 데이터화 된 얼굴 영상일 수 있다. S300단계 이후에는 타겟이미지를 결정하는 단계(S400)가 실행될 수 있다. 타겟이미지는 제1 합성얼굴에 합성하 고자 하는 객체를 의미하는 것으로, 여기에는 로고, 키 비주얼(key visual), 또는 상품이미지 중 적어도 하나의 것이 포함될 수 있다. 타겟이미지들은 복수 개가 데이터베이스 내에 저장되어 있을 수 있으며, 외부로부터 새로 운 타겟이미지가 입력될 경우 데이터베이스 내에 누적 저장되도록 할 수 있다. S400단계에서, 타겟이미지는 사용자에 의해 직접 선택이 가능하도록 서비스 서버가 타겟이미지 설정용 인 터페이스를 제공하게 할 수 있다. 이러한 인터페이스를 통해 사용자는 여러 개의 타겟이미지들이 나열된 상태에 서 특정 타겟이미지 하나를 선택할 수 있거나, 또는 직접 usb등의 외부저장장치로부터 타겟이미지를 로드 및 선 택할 수 있다. 다른 한편, S400단계에서 서비스 서버는 사용자에게 타겟이미지 설정용 인터페이스를 통해 타겟이미지들을 보여줄 때에 앞서 생성된 제1 합성얼굴을 고려하여 몇 가지 선별된 타겟이미지들만을 보여주도록 구현될 수도 있다. 타겟이미지는 결국 제1 합성얼굴과 합성될 것임을 고려할 때, 서비스 서버의 입장에서는 합성 시 로 드가 덜 걸리는, 혹은 리소스가 덜 소요되는 '타겟이미지 및 제1 합성얼굴 조합'을 사전에 기록하여 둘 수 있으 며, 어느 특정 얼굴데이터가 선택되어 제1 합성얼굴이 생성되었을 때, 서비스 서버는 해당 제1 합성얼굴과 의 합성적합도(로드가 덜 걸리거나 리소스가 덜 소요되는 정도)를 고려하여 몇 개의 선별된 타겟이미지들만 선 택 가능하도록 사용자에게 제공할 수 있다. 다른 한편, S400단계에서는 복수 개의 타겟이미지들이 선택 가능할 수도 있다. 라이브 커머스, 또는 온라인 화 상 채팅 서비스 시에는 반드시 타겟이미지가 하나로만 제한될 필요는 없으며, 사용자는 필요에 따라 복수 개의 타겟이미지들을 선택 및 합성시킴으로써 타겟이미지를 이용한 보다 효과적인 메시지 전달이 가능하게 할 수 있 다. 또 다른 한편, 서비스 서버는 사용자로 하여금 제1 합성얼굴 상에서 어느 위치에 타겟이미지를 합성할 것 인지를 선택하게 할 수도 있다. 예를 들어, 서비스 서버는, 앞서 타겟이미지(들)가 선택된 이후 도 5와 같 은 형식의 타겟이미지 설정용 인터페이스를 제공함으로써 사용자가 타겟이미지의 합성 위치를 선택하도록 할 수 있는데, 편의상 이렇게 인터페이스를 제공함으로써 합성 위치를 선택 및 결정하는 단계를 S450단계로 칭하기로 한다. 도 5를 참고할 때, 타겟이미지 설정용 인터페이스에는 제1 합성얼굴이 표시될 수 있고, 제1 합성얼굴 상에는 각각의 위치를 구분하는 가이드선이 표시될 수 있다. 가이드선에 의해 구분되는 각각의 영 역은 사용자에 의해 선택이 가능한 위치로 정의될 수 있다. 도 5에는 두 개의 타겟이미지들(15, 17)이 선택되어 각각 상이한 위치에 배치가 된 모습이 도시되어 있는데, 이러한 방식으로 사용자는 어느 특정 타겟이미지를 선 택한 후 원하는 위치에 배치를 합으로써 타겟이미지의 합성 위치를 정할 수 있다. 한편, 상기 타겟이미지 설정용 인터페이스 상에는 가이드선에 의해 구분되는 복수 개의 영역들 중 사용자가 선택 가능한 몇 개의 영역들만 별도로 표시가 되도록 구현될 수도 있다. 구체적으로, 서비스 서버는 타겟 이미지 설정용 인터페이스 상에 타겟이미지의 합성이 가능한 위치들을 표시하되, 제1 합성얼굴 상의 영역들 중 상기 사용자에 의해 선택된 특정 타겟이미지의 합성적합도가 기준값 이상인 영역들만 합성이 가능한 위치들로 표시되게 할 수 있다. 이 때 합성적합도란 타겟이미지의 노출정도 또는 타겟이미지의 렌더링난도에 의해 정해지 는 것일 수 있다. 타겟이미지의 노출정도란, 제1 합성얼굴의 굴곡면, 다시 말해 얼굴이 가지는 굴곡면을 고려할 때 제1 합성얼굴의 특정 영역(콧등, 귀 밑 영역 등)들은 추후 타겟이미지가 합성이 되더라도 상대방에게 노출이 잘 되지 않을 가능성이 높은데, 이러한 영역들은 사전에 선택 가능한 영역들로부터 배제를 시킬 수 있다. 또한, 타겟이미지의 모양을 고려할 때 제1 합성얼굴의 특정 영역에서는 렌더링 시 로드가 많이 걸리거나 리소스가 많 이 소요될 수 있는데, 이러한 영역들도 사전에 선택 가능한 영역들로부터 배제를 시킬 수 있다. 참고로, S400단계에서도 합성적합도라는 용어가 사용되고 있으며, S450단계에서도 합성적합도라는 용어가 사용 되고 있는데, S400단계에서의 합성적합도는 제1 합성얼굴의 형태를 고려할 때 선택 가능한 타겟이미지의 종류들 을 선별할 때에 서비스 서버가 연산할 수 있는 값이며, S450단계에서의 합성적합도는 타겟이미지가 이미 선택된 상태임을 전제로 제1 합성얼굴의 어느 위치에 합성시킬 것인지를 결정하는 과정에서 서비스 서버가 연산할 수 있는 값임을 이해한다. 위 두 개의 합성적합도 용어는 발명의 이해를 돕기 위해 제1 합성적합도(S400 단계에서의 합성적합도), 및 제2 합성적합도(S450단계에서의 합성적합도)로 나누어 정의하기로 한다. 다른 한편, 서비스 서버는 사용자에게 별도의 타겟이미지 설정용 인터페이스를 제공하지 않은 채 자체적으 로 합성 위치를 결정하도록 구현될 수도 있다. 즉, S400단계에서 타겟이미지가 선택 및 결정되었다면 서비스 서 버는 제1 합성얼굴 상에서 타겟이미지의 합성이 가장 적합한 위치를 찾아 그 위치를 합성 위치로 결정할 수 있다. S400 및 S450단계 이후에는, 서비스 서버가 상기 타겟이미지를 제1 합성얼굴에 합성하여 제2 합성얼굴을 생성하는 단계(S500)가 실행될 수 있다. 도 4를 참고할 때, 이 과정은 이미지합성 알고리즘을 활용하여 이 루어지는 것을 알 수 있는데, 이 때 이미지합성 알고리즘은 학습이 가능한 인공지능 알고리즘으로, 이미 사전에 타겟이미지를 임의의 얼굴데이터에 합성하는 과정이 학습된 상태의 것일 수 있다. 상기 이미지합성 알고리즘은, 임의의 3차원 모델에 이미지 텍스처를 씌우는 단계, 상기 3차원 모델의 다각 도 데이터를 수집하는 단계, 복수 개의 상이한 얼굴들을 대상으로 상기 3차원 모델을 활용한 얼굴 합성 모델을 학습시키는 단계, 및 이미지 세그멘테이션 모델을 학습시키는 단계 등을 거쳐 학습된 것일 수 있다. 이러한 방 식으로 학습이 된 이미지합성 알고리즘을 활용할 경우, 종전의 AR과는 달리 얼굴의 표면에 다각도로 정밀 하게 타겟이미지를 합성시킬 수 있으므로 얼굴 표면과 타겟이미지 간 이질감을 해소할 수 있는 효과가 있다. 이상 본 발명에 따른 얼굴데이터에 타겟이미지를 합성하는 방법 및 이를 위한 시스템에 대해 살펴보았다. 한편, 본 발명은 상술한 특정의 실시예 및 응용예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗"}
{"patent_id": "10-2023-0139839", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "어남이 없이 당해 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 구별되어 이해되어서는 안 될 것이다."}
{"patent_id": "10-2023-0139839", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 방법 및 시스템을 개략적으로 설명하기 위한 도면이다. 도 2는 본 발명에 따른 얼굴데이터에 타겟이미지를 합성하는 방법을 순서에 따라 도시한 것이다. 도 3은 사용자가 선택한 얼굴데이터를 합성하여 제1 합성얼굴을 생성하는 과정을 도시한 것이다. 도 4는 제1 합성얼굴에 타겟이미지를 합성하여 제2 합성얼굴을 생성하는 과정을 도시한 것이다.도 5는 사용자가 직접 입력할 수 있는 형태의 타겟이미지 설정용 인터페이스를 예시적으로 나타낸 것이다."}
