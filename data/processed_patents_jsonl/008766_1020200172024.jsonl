{"patent_id": "10-2020-0172024", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0082279", "출원번호": "10-2020-0172024", "발명의 명칭": "립싱크 영상 생성 장치 및 방법", "출원인": "주식회사 딥브레인에이아이", "발명자": "황금별"}}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 립싱크 영상 생성 장치로서, 인물 배경 영상 및 상기 인물 배경 영상과 대응하는 발화 오디오 신호를 입력으로 하여 발화 합성 영상을 생성하고, 인물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성하는 제1 인공 신경망 모델; 및기 설정된 발화 유지 영상 및 상기 제1 인공 신경망 모델로부터 사일런스 합성 영상을 입력으로 하여 상기 발화유지 영상 및 상기 사일런스 합성 영상에 대한 분류 값을 출력하는 제2 인공 신경망 모델을 포함하는, 립싱크영상 생성 장치."}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 인물 배경 영상은, 영상 속 인물의 발화와 관련된 부분이 마스크로 가려진 영상이고, 상기 발화 유지 영상은, 영상 속 인물의 발화 움직임이 일정한 영상인, 립싱크 영상 생성 장치."}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 제2 인공 신경망 모델은, 상기 발화 유지 영상을 참(True)으로 분류하고, 상기 사일런스 합성 영상은 거짓(Fake)으로 분류하도록 학습되는, 립싱크 영상 생성 장치."}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서, 상기 제1 인공 신경망 모델은, 인물 배경 영상을 입력으로 하고, 상기 입력되는 인물 배경 영상으로부터 영상 특징 벡터를 추출하는 제1 인코더;상기 인물 배경 영상과 대응하는 발화 오디오 신호를 입력으로 하고, 상기 입력되는 발화 오디오 신호로부터 음성 특징 벡터를 추출하는 제2 인코더;상기 영상 특징 벡터와 상기 음성 특징 벡터를 조합하여 조합 벡터를 생성하는 조합부; 및상기 조합 벡터를 입력으로 하고, 상기 조합 벡터를 기반으로 상기 발화 합성 영상을 생성하는 디코더를 포함하는, 립싱크 영상 생성 장치."}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0082279-3-청구항 4에 있어서, 상기 디코더는, 상기 음성 특징 벡터를 기반으로 상기 인물 배경 영상의 마스크로 가려진 부분을 복원하도록 학습되는, 립싱크영상 생성 장치."}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 2에 있어서, 상기 제1 인공 신경망 모델의 상기 발화 합성 영상의 생성을 위한 목적 함수(Lreconstruction)는 다음의 수학식을 통해 표현되는, 립싱크 영상 생성 장치.(수학식)yt : 원래 발화 영상G : 제1 인공 신경망 모델을 구성하는 신경망xt : t 시간 동안의 인물 배경 영상at : t 시간 동안의 발화 오디오 신호θg : 신경망 G의 파라미터: A와 B의 차이를 구하는 함수"}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 제2 인공 신경망 모델의 목적 함수(Ldiscriminator)는 다음의 수학식을 통해 표현되는, 립싱크 영상 생성 장치.(수학식)D : 제2 인공 신경망 모델의 신경망xidle : 발화 유지 영상θd : 신경망 D의 파라미터G(xt,0) : 제1 인공 신경망 모델이 출력하는 사일런스 합성 영상"}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 제1 인공 신경망 모델의 상기 사일런스 합성 영상의 생성을 위한 적대적 목적 함수(Ladversarial)는 다음의 수학식을 통해 표현되는, 립싱크 영상 생성 장치.공개특허 10-2022-0082279-4-(수학식)"}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 상기 제1 인공 신경망 모델의 상기 발화 합성 영상 및 상기 사일런스 합성 영상을 생성하기 위한 최종 목적 함수(LT)는 다음의 수학식을 통해 표현되는, 립싱크 영상 생성 장치.(수학식)λ : 가중치"}
{"patent_id": "10-2020-0172024", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방법으로서, 제1 인공 신경망 모델에서, 인물 배경 영상 및 상기 인물 배경 영상과 대응하는 발화 오디오 신호를 입력으로하여 발화 합성 영상을 생성하고, 인물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성하는 동작; 및제2 인공 신경망 모델에서, 기 설정된 발화 유지 영상 및 상기 제1 인공 신경망 모델로부터 사일런스 합성 영상을 입력으로 하여 상기 발화 유지 영상 및 상기 사일런스 합성 영상에 대한 분류 값을 출력하는 동작을 포함하는, 립싱크 영상 생성 방법."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "립싱크 영상 생성 장치 및 방법이 개시된다. 개시되는 일 실시예에 따른 립싱크 영상 생성 장치는, 하나 이상의 프로세서들, 및 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 립싱크 영상 생성 장치로서, 인물 배경 영상 및 인물 배경 영상과 대응하는 발화 오디오 신호를 입력으로 하여 발화 합성 영상을 생성하고, 인물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성하는 제1 인공 신경망 모델 및 기 설정된 발화 유지 영상 및 제1 인공 신경망 모델로부터 사일런스 합성 영상을 입력으로 하여 발화 유 지 영상 및 사일런스 합성 영상에 대한 분류 값을 출력하는 제2 인공 신경망 모델을 포함한다."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 립싱크 영상 생성 기술과 관련된다."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 인공 지능 분야의 기술 발전에 따라 다양한 유형의 콘텐츠가 인공 지능 기술에 기초하여 생성되고 있다. 그 일 예로, 어떤 전달하고자 하는 음 성 메시지가 있을 때, 그 음성 메시지를 유명 인물(예를 들어, 대통령 등)이 말하 는 것과 같은 발화 동영상(립싱크 동영상)을 생성하여 사람들의 주의를 끌고자 하는 경우가 있다. 이는 유명 인물의 영상에서 유명 인물이 특정 메시지를 말하는 것처럼 입 모양 등을 특정 메시지에 맞게 생성하 여 구현하게 된다. 여기서, 자연스러운 립싱크 영상을 생성하기 위해서는 립싱크 영상 생성을 위한 학습 모델이 각 입력에 따른 역 할이 구분될 수 있도록 학습되어야 한다. 즉, 학습 모델에서 음성 신호를 입력으로 하는 부분은 입 또는 턱 모 양 등 발화와 관련된 움직임을 제어하도록 학습되어야 하고, 인물 배경 영상을 입력으로 하는 부분은 얼굴 움직 임, 눈 깜박임, 형태, 위치, 및 질감 등 그 이외의 요소를 제어하도록 학습되어야 한다. 선행기술문헌특허문헌 (특허문헌 0001) 한국등록특허공보 제10-1177408호(2012.08.27)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는 인물 배경 영상이 발화와 관련된 부분을 제어하는 것을 방지할 수 있는 립싱크 영상 생성 장치 및 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시되는 일 실시예에 따른 립싱크 영상 생성 장치는, 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세서 들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 립싱크 영상 생성 장치로서, 인물 배 경 영상 및 상기 인물 배경 영상과 대응하는 발화 오디오 신호를 입력으로 하여 발화 합성 영상을 생성하고, 인 물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성하는 제1 인공 신경망 모델; 및 기 설정된 발화 유 지 영상 및 상기 제1 인공 신경망 모델로부터 사일런스 합성 영상을 입력으로 하여 상기 발화 유지 영상 및 상 기 사일런스 합성 영상에 대한 분류 값을 출력하는 제2 인공 신경망 모델을 포함한다. 상기 인물 배경 영상은, 영상 속 인물의 발화와 관련된 부분이 마스크로 가려진 영상이고, 상기 발화 유지 영상 은, 영상 속 인물의 발화 움직임이 일정한 영상일 수 있다. 상기 제2 인공 신경망 모델은, 상기 발화 유지 영상을 참(True)으로 분류하고, 상기 사일런스 합성 영상은 거짓 (Fake)으로 분류하도록 학습될 수 있다. 상기 제1 인공 신경망 모델은, 인물 배경 영상을 입력으로 하고, 상기 입력되는 인물 배경 영상으로부터 영상 특징 벡터를 추출하는 제1 인코더; 상기 인물 배경 영상과 대응하는 발화 오디오 신호를 입력으로 하고, 상기 입력되는 발화 오디오 신호로부터 음성 특징 벡터를 추출하는 제2 인코더; 상기 영상 특징 벡터와 상기 음성 특 징 벡터를 조합하여 조합 벡터를 생성하는 조합부; 및 상기 조합 벡터를 입력으로 하고, 상기 조합 벡터를 기반 으로 상기 발화 합성 영상을 생성하는 디코더를 포함할 수 있다. 상기 디코더는, 상기 음성 특징 벡터를 기반으로 상기 인물 배경 영상의 마스크로 가려진 부분을 복원하도록 학 습될 수 있다. 상기 제1 인공 신경망 모델의 상기 발화 합성 영상의 생성을 위한 목적 함수(Lreconstruction)는 다음의 수학식을 통 해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "yt : 원래 발화 영상 G : 제1 인공 신경망 모델을 구성하는 신경망 xt : t 시간 동안의 인물 배경 영상 at : t 시간 동안의 발화 오디오 신호 θg : 신경망 G의 파라미터 : A와 B의 차이를 구하는 함수 상기 제2 인공 신경망 모델의 목적 함수(Ldiscriminator)는 다음의 수학식을 통해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "D : 제2 인공 신경망 모델의 신경망 xidle : 발화 유지 영상 θd : 신경망 D의 파라미터 G(xt,0) : 제1 인공 신경망 모델이 출력하는 사일런스 합성 영상 상기 제1 인공 신경망 모델의 상기 사일런스 합성 영상의 생성을 위한 적대적 목적 함수(Ladversarial)는 다음의 수 학식을 통해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "상기 제1 인공 신경망 모델의 상기 발화 합성 영상 및 상기 사일런스 합성 영상을 생성하기 위한 최종 목적 함 수(LT)는 다음의 수학식을 통해 표현될 수 있다. (수학식)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 5, "content": "λ : 가중치 개시되는 일 실시예에 따른 립싱크 영상 생성 방법은, 하나 이상의 프로세서들, 및 상기 하나 이상의 프로세서 들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되는 방법으로서, 제1 인공 신경망 모델에서, 인물 배경 영상 및 상기 인물 배경 영상과 대응하는 발화 오디오 신호 를 입력으로 하여 발화 합성 영상을 생성하고, 인물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성하 는 동작; 및 제2 인공 신경망 모델에서, 기 설정된 발화 유지 영상 및 상기 제1 인공 신경망 모델로부터 사일런 스 합성 영상을 입력으로 하여 상기 발화 유지 영상 및 상기 사일런스 합성 영상에 대한 분류 값을 출력하는 동 작을 포함한다."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시되는 실시예에 의하면, 제1 인공 신경망 모델이 인물 배경 영상 및 발화 오디오 신호를 입력으로 하여 발화 합성 영상을 생성하고, 인물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성하도록 하며, 제2 인공 신 경망 모델이 발화 유지 영상은 참(True)으로 분류하고, 사일런스 합성 영상은 거짓(Fake)으로 분류하도록 학습 함으로써, 사일런스 합성 영상에서 인물의 발화 움직임이 일정하도록(즉, 발화와 관련된 부분이 움직이지 않도 록) 학습이 되게 되고, 그로 인해 인물 배경 영상이 발화와 관련된 부분을 제어하는 것을 방지할 수 있으며, 발 화와 관련된 부분은 발화 오디오 신호에 의해서만 제어되도록 유도할 수 있게 된다."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 이하의 설명에 있어서, 신호 또는 정보의 \"전송\", \"통신\", \"송신\", \"수신\" 기타 이와 유사한 의미의 용어는 일 구성요소에서 다른 구성요소로 신호 또는 정보가 직접 전달되는 것뿐만이 아니라 다른 구성요소를 거쳐 전달되 는 것도 포함한다. 특히 신호 또는 정보를 일 구성요소로 \"전송\" 또는 \"송신\"한다는 것은 그 신호 또는 정보의 최종 목적지를 지시하는 것이고 직접적인 목적지를 의미하는 것이 아니다. 이는 신호 또는 정보의 \"수신\"에 있 어서도 동일하다. 또한 본 명세서에 있어서, 2 이상의 데이터 또는 정보가 \"관련\"된다는 것은 하나의 데이터(또 는 정보)를 획득하면, 그에 기초하여 다른 데이터(또는 정보)의 적어도 일부를 획득할 수 있음을 의미한다. 또한, 제1, 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로 사용될 수 있다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성 요소로 명 명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 도 1은 본 발명의 일 실시예에 따른 립싱크 영상 생성 장치의 구성을 나타낸 도면이다. 도 1을 참조하면, 립싱크 영상 생성 장치는 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 포함할 수 있다. 제1 인공 신경망 모델은 인물 배경 영상 및 발화 오디오 신호를 입력으로 하여 발화 합성 영상을 생성하도 록 학습되는 모델일 수 있다. 여기서, 인물 배경 영상은 인물이 발화 하는(말을 하는) 영상으로, 영상에서 인물 의 발화와 관련된 부분이 마스킹(Masking) 처리된 영상일 수 있다. 그리고, 발화 오디오 신호는 인물 배경 영상 (즉, 인물이 발화하는 영상) 중 오디오 부분일 수 있다. 여기서, 제1 인공 신경망 모델은 입력되는 발화 오디오 신호를 통해 인물 배경 영상에서는 마스크로 가려 진 발화 관련 부분을 복원하여 발화 합성 영상을 생성하도록 학습될 수 있다. 이때, 인물 배경 영상이 발화 관 련 부분을 제어하지 못하도록 하는 것이 필요하다. 즉, 발화 관련 부분은 발화 오디오 신호를 통해서만 제어되 도록 하고, 인물 배경 영상에 의해 제어되는 것은 방지하는 것이 필요하다. 이에 개시되는 실시예에서는, 제1 인공 신경망 모델이 인물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성하도록 할 수 있다. 여기서, 사일런스 합성 영상은 오디오 신호가 없이 인물 배경 영상만으로 립싱 크 영상을 합성한 것을 의미할 수 있다. 사일런스 합성 영상은 오디오 신호 없이(즉, 오디오가 0인 상태) 인물 배경 영상만으로 생성되는 립싱크 영상이 기 때문에, 인물의 발화 움직임이 고정된 상태에서 인물 배경 영상의 마스크를 가리지 않은 부분의 움직임은 따 라가는 립싱크 영상이어야 한다. 그러나, 제1 인공 신경망 모델의 학습 과정에서 인물 배경 영상이 발화 관련 부분을 제어하도록 학습되면, 오디오 신호가 없는데도 불구하고 인물의 발화와 관련된 부분이 움직이는 사일런스 합성 영상이 생성될 수 있다. 이에 개시되는 실시예에서는, 인물 배경 영상이 발화 관련 부분을 제어하지 않도록 제2 인공 신경망 모델 을 통해 제1 인공 신경망 모델이 생성한 사일런스 합성 영상은 페이크(Fake)로 분류하도록 학습할 수 있다. 즉, 제2 인공 신경망 모델은 기 설정된 발화 유지 영상이 입력되면 이를 참(True)으로 분류하고, 제1 인공 신경망 모델이 생성한 사일런스 합성 영상이 입력되면 페이크(Fake)로 분류하도록 학습될 수 있다. 여기서, 발화 유지 영상은 해당 인물의 발화 움직임이 일정한 영상을 의미할 수 있다. 예를 들어, 발화 유지 영 상은 해당 인물이 입을 닫고 있는 영상일 수 있다. 이와 같이, 제2 인공 신경망 모델을 통해 해당 인물의 발화 유지 영상을 참으로 분류하고, 사일런스 합성 영상은 거짓으로 분류하도록 학습함으로써, 사일런스 합성 영상에서 인물의 발화 움직임이 일정하도록(즉, 발화 와 관련된 부분이 움직이지 않도록) 학습이 되게 되고, 그로 인해 인물 배경 영상이 발화와 관련된 부분을 제어 하는 것을 방지할 수 있으며, 발화와 관련된 부분은 발화 오디오 신호에 의해서만 제어되도록 유도할 수 있게 된다. 도 2는 본 발명의 일 실시예에서 제1 인공 신경망 모델이 발화 합성 영상을 생성하는 상태를 개략적으로 나타낸 도면이다. 도 2를 참조하면, 제1 인공 신경망 모델은 제1 인코더, 제2 인코더, 조합부, 및 디코더 를 포함할 수 있다. 예시적인 실시예에서, 제1 인공 신경망 모델은 합성곱 신경망 (Convolutional Neural Network : CNN) 기 반의 머신 러닝 기술로 구현될 수 있으나, 머신 러닝 기술이 이에 한정되는 것은 아니며 그 이외의 다양한 머신 러닝 기술이 적용될 수 있다. 제1 인코더는 인물 배경 영상을 입력으로 하여 영상 특징 벡터를 추출하도록 학습될 수 있다. 이하, \"벡터\"는 \"텐서\"를 포함 하는 의미로 사용될 수 있다. 여기서, 제1 인코더로 입력되는 인물 배경 영상은 인물이 발화 하는(말을 하는) 영상이다. 인물 배경 영상 은 인물의 얼굴과 상반신이 포함된 영상 일 수 있다. 즉, 인물 배경 영상은 해당 인물이 발화 할 때 나타나는 얼굴, 목, 및 어깨 등의 움직임이 보여지도록 얼굴뿐만 아니라 상반신이 포함된 영상일 수 있으나, 이에 한정되 는 것은 아니며 인물의 얼굴을 포함하는 영상일 수도 있다. 제1 인코더로 입력되는 인물 배경 영상에서 발화와 관련된 부분은 마스킹(Masking) 처리될 수 있다. 즉, 인물 배경 영상에서 발화와 관련된 부 분(예를 들어, 입 및 입 주위 부분 등)은 마스크(M)로 가려질 수 있다. 또한, 마스킹 처리 시 인물 배경 영상에서 인물의 발화에 따른 얼굴 움직임, 목 움직임, 및 어깨 움직임 등과 관련된 부분은 마스킹 처리되지 않도록 할 수 있다. 그러면, 제1 인코더에서는 인물 배경 영상에서 발화와 관련된 부분을 제외한 부분의 영상 특징 벡터를 추출하게 된다. 제1 인코더는 하나 이상의 합성곱 층(Convolutional Layer) 및 하나 이상의 풀링 층(Pooling Layer)를 포 함할 수 있다. 합성곱 층은 입력되는 인물 배경 영상에서 기 설정된 크기(예를 들어, 3Х3 픽셀 크기)의 필터를 일정 간격으로 이동시키면서 해당 필터에 대응되는 픽셀들의 특징 값을 추출할 수 있다. 풀링 층은 합성곱 층의 출력을 입력으로 받아 다운 샘플링(Down Sampling)을 수행할 수 있다. 제2 인코더는 발화 오디오 신호를 입력으로 할 수 있다. 제2 인코더는 발화 오디오 신호를 입력으로 하여 음성 특징 벡터를 추출하도록 학습될 수 있다. 여기서, 발화 오디오 신호는 제1 인코더로 입력되는 인물 배경 영상(즉, 인물이 발화하는 영상) 중 오디오 부분에 해당한다. 다시 말하면, 인물이 발화하는 동영상에서 비디오 부분은 제1 인코더로 입력되고, 오디 오 부분은 제2 인코더로 입력될 수 있다. 제2 인코더는 하나 이상의 합성곱 층(Convolutional Layer) 및 하나 이상의 풀링 층 (Pooling Layer)를 포함할 수 있으나, 제2 인코더의 신경망 구조가 이에 한정 되는 것은 아니다. 제1 인코더로 입력되는 인물 배경 영상과 제2 인코더로 입력되는 발화 오디오 신호의 시간은 서로 동 기화 될 수 있다. 즉, 인물이 발화하는 동영상에서 동일한 시간 대의 구간 중 비디오는 제1 인코더로 입력되고, 오디오는 제2 인코더로 입력될 수 있다. 예를 들어, 인물 배경 영상이 특정 시점으로부터 t 시간의 영상인 경우, 발화 오디오 신호는 동일한 시점으로부터 t 시간의 음성일 수 있다. 이때, 인물 배경 영상 및 발 화 오디오 신호는 기 설정된 단위 시간(예를 들어, 하나의 프레임 또는 복수 개의 연속된 프레임 등)마다 제1 인코더 및 제2 인코더로 입력될 수 있다. 조합부는 제1 인코더에서 출력되는 영상 특징 벡터 및 제2 인코더에서 출력되는 음성 특징 벡터 를 조합하여 조합 벡터를 생성할 수 있다. 예시적인 실시예에서, 조합부는 영상 특징 벡터와 음성 특징 벡 터를 연결(Concatenate)하여 조합 벡터를 생성할 수 있으나, 이에 한정되는 것은 아니다. 디코더는 조합부에서 출력되는 조합 벡터를 입력으로 하여 발화 합성 영상을 생성할 수 있다. 구체적 으로, 디코더는 제2 인코더에서 출력되는 음성 특징 벡터(즉, 인물이 발화하는 동영상에서 오디오 부 분의 특징)를 기반으로 제1 인코더에서 출력되는 영상 특징 벡터(즉, 인물이 발화하는 동영상에서 비디오 부분으로, 발화 관련된 부분이 마스크로 가려진 부분의 특징)의 마스크(M)로 가려진 부분(즉, 발화와 관련된 부 분)을 복원하도록 학습될 수 있다. 즉, 디코더는 인물 배경 영상에서 발화와 관련된 부분이 마스킹 된 경우, 발화 오디오 신호를 이용하여 마 스킹 된 영역을 복원하도록 학습되는 모델일 수 있다. 디코더는 생성된 발화 합성 영상과 원래의 발화 영 상(즉, 정답 값)을 비교하여 생성된 발화 합성 영상이 원래의 발화 영상에 가까워지도록(즉, 원래 발화 영상과 의 차이가 최소화되도록) 학습 파라미터(예를 들어, 손실 함수, 소프트맥스 함수 등)를 조절할 수 있다. 한편, 제1 인공 신경망 모델이 인물 배경 영상 및 발화 오디오 신호를 입력으로 하여 발화 합성 영상을 생 성하는 것에 대한 목적 함수(Lreconstruction)는 다음의 수학식 1을 통해 나타낼 수 있다."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "yt : 원래 발화 영상 G : 제1 인공 신경망 모델을 구성하는 신경망 xt : t 시간 동안의 인물 배경 영상 at : t 시간 동안의 발화 오디오 신호 θg : 신경망 G의 파라미터 : A와 B의 차이를 구하는 함수로서, 예를 들어, A와 B의 유클리디안 거리(L2 distance) 또는 맨하 튼 거리(L1 distance)를 구하는 함수 등이 포함될 수 있음 도 3은 본 발명의 일 실시예에서 사일런스 합성 영상을 페이크로 분류하여 학습하기 위한 구성을 나타낸 도면이 다. 도 3을 참조하면, 제1 인공 신경망 모델은 인물 배경 영상만을 입력으로 하여 사일런스 합성 영상을 생성 할 수 있다. 구체적으로, 제1 인코더는 인물 배경 영상을 입력으로 하여 영상 특징 벡터를 추출할 수 있다. 이때, 제2 인코더에는 별도의 오디오 신호가 입력되지 않을 수 있다. 또는, 제2 인코더에는 오 디오 값이 0인 신호가 입력될 수 있다. 조합부는 제1 인코더에서 출력하는 영상 특징 벡터와 제2 인코더에서 출력되는 음성 특징 벡터 를 조합하여 조합 벡터를 생성하게 되는데, 제2 인코더에서 출력되는 음성 특징 벡터는 0이므로, 조합 벡 터는 영상 특징 벡터와 동일하게 된다. 즉, 조합부는 제1 인코더에서 출력하는 영상 특징 벡터를 그 대로 디코더로 입력시킬 수 있다. 디코더는 영상 특징 벡터를 입력으로 하여 사일런스 합성 영상을 생성할 수 있다. 사일런스 합성 영상은 제2 인공 신경망 모델로 입력될 수 있다. 제2 인공 신경망 모델은 기 저장된 발화 유지 영상 및 사일런스 합성 영상을 입력 받고, 이를 참(True) 또 는 거짓(Fake)으로 분류하여 분류 값을 출력할 수 있다. 여기서, 발화 유지 영상은 인물 배경 영상 속 인물의발화 움직임이 일정한 영상(예를 들어, 해당 인물이 입을 닫고 있는 영상 등)일 수 있다. 예시적인 실시예에서, 발화 유지 영상은 해당 인물에 대한 영상에서 발화 움직임이 일정한 프레임을 검출하여 획득할 수 있다. 제2 인공 신경망 모델은 발화 유지 영상은 참(True)으로 분류하고, 사일런스 합성 영상은 거짓(Fake)로 분 류하도록 학습될 수 있다. 예시적인 실시예에서, 제2 인공 신경망 모델은 제3 인코더 및 분류기(12 3)를 포함할 수 있다. 제3 인코더는 입력되는 영상(발화 유지 영상 또는 사일런스 합성 영상)으로부터 영 상 특징 벡터를 추출할 수 있다. 분류기는 제3 인코더에서 출력되는 영상 특징 벡터에 기반하여 입력 된 영상을 참(True) 또는 거짓(Fake)으로 분류할 수 있다. 여기서, 사일런스 합성 영상이 제2 인공 신경망 모델에서 거짓으로 분류됨으로써, 제1 인공 신경망 모델 에서는 오디오 없이 인물 배경 영상만으로 생성하는 사일런스 합성 영상에서 인물의 발화 움직임이 일정하 도록 학습을 하게 되며, 그로 인해 인물 배경 영상이 발화와 관련된 부분을 제어하는 것을 방지할 수 있으며, 발화와 관련된 부분은 발화 오디오 신호에 의해서만 제어되도록 유도할 수 있게 된다. 여기서, 제1 인공 신경망 모델 및 제2 인공 신경망 모델은 적대적 생성 신경망(Generative Adversarial Network)을 이룰 수 있다. 제1 인공 신경망 모델은 적대적 생성 신경망 중 생성자 (Generator)에 해당하고, 제2 인공 신경망 모델은 적대적 생성 신경망 중 판별자(Discriminator)에 해당할 수 있다. 즉, 제1 인공 신경망 모델은 발화 합성 영상을 생성하는 별도의 신경망 모델이면서, 사일런스 합 성 영상을 생성하는 적대적 생성 신경망의 일부 신경망(즉, 생성자)을 구성할 수 있다. 이때, 제2 인공 신경망 모델의 목적 함수(Ldiscriminator)는 다음의 수학식 2를 통해 나타낼 수 있다. (수학식 2)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "D : 제2 인공 신경망 모델의 신경망 xidle : 발화 유지 영상 θd : 신경망 D의 파라미터 G(xt,0) : 제1 인공 신경망 모델이 출력하는 사일런스 합성 영상 그리고, 제2 인공 신경망 모델의 최적화된 파라미터( )는 다음의 수학식 3을 통해 나타낼 수 있다. (수학식 3) 여기서, argminθd는 Ldiscriminator를 최소화 하는 θd를 찾는 함수를 나타낸다. 또한, 사일런스 합성 영상을 생성하는 제1 인공 신경망 모델의 적대적 목적 함수(Ladversarial)는 다음의 수학 식 4를 통해 나타낼 수 있다. (수학식 4)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "적대적 목적 함수(Ladversarial)는 제2 인공 신경망 모델에서 사일런스 합성 영상을 참(True)인 것으로 판단하 도록 제1 인공 신경망 모델을 유도하는 목적 함수일 수 있다. 즉, 적대적 목적 함수(Ladversarial)는 사일런스 합성 영상과 발화 유지 영상 간의 차이가 최소화 되도록 제1 인공 신경망 모델을 유도하는 목적 함수일 수 있다. 그리고, 발화 합성 영상 및 사일런스 합성 영상을 생성하는 제1 인공 신경망 모델의 최종 목적 함수(LT)는 다음의 수학식 5를 통해 나타낼 수 있다. (수학식 5)"}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "λ : 가중치 또한, 제1 인공 신경망 모델의 최적화된 파라미터( )는 다음의 수학식 6을 통해 나타낼 수 있다. (수학식 6) 여기서, argminθg는 LT를 최소화 하는 θg를 찾는 함수를 나타낸다. 도 4는 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하 기 위한 블록도이다. 도시된 실시예에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가 질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 립싱크 영상 생성 장치일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다."}
{"patent_id": "10-2020-0172024", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상에서 본 발명의 대표적인 실시예들을 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후술하는 특허 청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다.부호의 설명 100 : 립싱크 영상 생성 장치 102 : 제1 인공 신경망 모델 104 : 제2 인공 신경망 모델 111 : 제1 인코더 113 : 제2 인코더 115 : 조합부 117 : 디코더 121 : 제3 인코더 123 : 분류기"}
{"patent_id": "10-2020-0172024", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 립싱크 영상 생성 장치의 구성을 나타낸 도면 도 2는 본 발명의 일 실시예에서 제1 인공 신경망 모델이 발화 합성 영상을 생성하는 상태를 개략적으로 나타낸 도면도 3은 본 발명의 일 실시예에서 사일런스 합성 영상을 페이크로 분류하여 학습하기 위한 구성을 나타낸 도면 도 4는 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위 한 블록도"}
