{"patent_id": "10-2022-0074549", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0173814", "출원번호": "10-2022-0074549", "발명의 명칭": "소실점을 이용한 3D 바운딩 박스 생성 방법 및 교통신호 제어를 위한 객체 감응형 차량 흐름", "출원인": "유에프엠시스템즈 주식회사", "발명자": "박정인"}}
{"patent_id": "10-2022-0074549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치의 인공지능 기반 영상분석부에 의해 구현되며,(a) 카메라 설치각도와 상기 카메라가 촬영한 영상의 방향성을 분석하여 종방향 소실점 VP1과 횡방향 소실점VP2를 도출하는 단계;(b) 분석 대상 영상에서 이동하는 객체를 특정하는 단계;(c) 상기 VP1에서 상기 객체의 외연에 접하도록 이어진 좌단 하부 소실선 Van-L1과 우단 상부 소실선 Van-L2를생성하는 단계;(d) 상기 VP2에서 상기 객체의 외연에 접하도록 이어진 전단 하부 소실선 Van-L3와 후단 상부 소실선 Van-L4를생성하여, 상기 Van-L1과 Van-L3의 교차점 P1과, 상기 Van-L2와 Van-L4의 교차점 P2가 생성되는 단계;(e) 상기 객체 최좌단이 접하는 좌측 후방 수직선 Ver-L1과, 상기 객체 최우단이 접하는 우측 전방 수직선 Ver-L2를 생성하여, 상기 Ver-L1과 Van-L1의 교차점 P3와, 상기 Ver-L2와 Van-L3의 교차점 P4와, 상기 Ver-L1과Van-N4의 교차점 P5와, 상기 Ver-L2와 Van-L2의 교차점 P6가 생성되는 단계; (f) 상기 VP2에서 P3를 지나는 소실선 Van-L5와, 상기 VP2에서 P6를 지나는 소실선 Van-L6를 생성하는 단계;(g) 상기 P1을 지나는 좌측 전방 수직선 Ver-L3와, 상기 P2를 지나는 우측 후방 수직선 Ver-L4를 생성하여, 상기 Ver-L3와 Van-L6의 교차점 P7과, 상기 Ver-L4와 Van-L5의 교차점 P8이 생성되는 단계; 및(h) 상기 P2, P5, P7, P6가 상단 꼭지점을 이루고, 상기 P1, P4, P8, P3가 하단 꼭지점을 이루는 6면체 바운딩박스를 생성하는 단계; 를 포함하는,소실점을 이용한 3D 바운딩 박스 생성 방법."}
{"patent_id": "10-2022-0074549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "감지영역인 적어도 하나 이상의 도로를 촬영하여 영상을 획득하는 카메라들과, 상기 감지영역에 설치되는 신호등들의 동작을 제어하는 교통신호 제어기와, 컨트롤러를 포함하는 차량 흐름 제어 시스템의 동작 과정인 객체감응형 차량 흐름 제어 방법으로서,(A) 상기 카메라들이 자신에게 할당된 도로를 촬영하여 영상을 획득한 후, 상기 컨트롤러로 획득된 영상들을 전송하는 단계;(B) 상기 컨트롤러가 딥-러닝(Deep learning) 기반의 객체분석 알고리즘을 이용하여, 상기 (A)단계를 통해 전송받은 영상들을 분석하여 제1항의 소실점을 이용한 3D 바운딩 박스 생성 방법에 따라 객체를 감지함과 동시에 감지된 객체의 위치, 종류 및 크기 중 적어도 하나 이상을 포함하는 객체정보를 검출하는 단계;(C) 상기 컨트롤러가 상기 (B)단계에 의해 검출된 객체정보들과, 기 설정된 각 카메라의 촬영영역의 위치정보,기 도로의 위치정보를 참조하여, 감지된 객체를 트래킹하여 각 객체가 위치한 차로종류, 차선위치, 이동속도 및방향 중 적어도 하나 이상을 포함하는 객체분석정보를 생성하는 단계;(D) 상기 컨트롤러가 상기 (C)단계에 의해 생성된 객체분석정보를 활용 및 가공하여, 각 연결차로의 대기열, 대기시간 및 교통량 중 적어도 하나 이상을 포함하는 교통정보를 생성하는 단계;(E) 상기 컨트롤러가 상기 (D)단계에 의해 생성된 교통정보를 기반으로 최적 신호체계를 수립하는 단계; 및 (F) 상기 컨트롤러가 상기 (E)단계에 의해 수립된 최적 신호체계 정보를 교통신호 제어기로 전송하고, 상기 교통신호 제어기가 상기 컨트롤러로부터 전송받은 최적 신호체계 정보에 따라 상기 신호등들이 운영되도록 상기신호등들을 제어하는 단계; 를 포함하는 것을 특징으로 하는 객체 감응형 차량 흐름 제어 방법.공개특허 10-2023-0173814-3-청구항 3 제2항에서,상기 (B)단계는, 상기 컨트롤러가 카메라 설치각도 및 거리 정보를 반영한 바운딩 박스 분석에 따라 감지된 객체의 종류와 크기를 추정함으로써 객체정보를 검출하는 것을 특징으로 하는 객체 감응형 차량 흐름 제어 방법."}
{"patent_id": "10-2022-0074549", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 영상 내 객체 인식 정확도를 높이기 위해 소실점을 이용하여 객체에 대한 3D 바운딩 박스를 생성하는 방법과, 이러한 3D 바운딩 박스 생성 방법을 인공지능의 객체 검출 수단으로 적용하여 검출된 객체정보를 기반으 로 신호체계를 제어하는 객체 감응형 차량 흐름 제어 방법에 관한 것이다. (뒷면에 계속)"}
{"patent_id": "10-2022-0074549", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 내 객체 인식 정확도를 높이기 위해 소실점을 이용하여 객체에 대한 3D 바운딩 박스를 생성하는 방법과, 이러한 3D 바운딩 박스 생성 방법을 인공지능의 객체 검출 수단으로 적용하여 검출된 객체정보를 기반 으로 신호체계를 제어하는 객체 감응형 차량 흐름 제어 방법에 관한 것이다."}
{"patent_id": "10-2022-0074549", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "차량 보급률이 증가하고 도심이 확장됨에 따라 교통 혼잡이 일상화되어 경제적 손실을 발생시키고 있다. 또한, 응급 환자, 화재 발생 등의 응급상황에서 도심지의 차량 정체 상황은 돌이킬 수 없는 손실을 야기할 수 있다. 따라서 교차로들의 신호체계를 최적화하여 차량 대기시간을 절감시키기 위한 다양한 연구가 진행되고 있다. 종 래의 대표적인 교차로 신호체계로는 차량검지수단에 의해 검출된 누적데이터들을 활용하여 TOD(Time Of Day)에 따라 고정된 신호주기 및 현시시간을 출력하는 정주기식 신호 운영방식과, 수집된 교통정보를 이용하여 교통상 황에 따라 신호를 제어하는 능동형 신호 운영방식으로 분류된다. 특히 능동형 신호 운영방식은 현재 교통상황에 따라 유동적으로 대응하여 차량 정체현상을 효과적으로 절감시킬 수 있는 장점으로 인해 이에 대한 다양한 연구가 이루어지고 있다. 한편, 최근 들어 딥-러닝(Deep learning) 기법을 이용하여 객체 감지, 종류, 트래킹 등을 수행하기 위한 영상 분석 기술에 대한 연구가 활발하게 이루어지고 있고, 이러한 딥-러닝을 활용한 영상 분석 기술은 학습을 통해 자체적으로 오차율을 줄이기 때문에 감지의 정확성 및 정밀도를 현저히 높일 수 있는 장점으로 인해 그 적용 분 야가 기하급수적으로 증가하고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 공개특허 10-2021-0103865 \"소실점 추출 장치 및 소실점 추출 방법\" (특허문헌 0002) 2. 등록특허 10-2311236 \"딥러닝 사물 인지 및 추적을 통한 속도 측정 방법 및 그 시스템\" (특허문헌 0003) 3. 등록특허 10-2391853 \"영상 정보 처리 시스템 및 방법\" (특허문헌 0004) 4. 공개특허 10-202000141834 \"영상기반 교통신호 제어 장치 및 방법\""}
{"patent_id": "10-2022-0074549", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 영상 내 객체에 대한 인식 정확도를 높이기 위한 3D 객체 탐지 방법을 제공함에 그 목적이 있다. 또한 본 발명은, 카메라들에 의해 촬영된 영상을 분석하여 객체정보 및 교통정보를 생성한 후, 생성된 교통정보 에 따라 최적 현시체계를 생성한 후, 생성된 최적 현시체계에 따라 교통신호가 제어되도록 구성됨으로써 차량 정체율 및 대기시간을 현저히 절감시킬 수 있을 뿐만 아니라 이에 따른 연비소모 및 오염가스 배출량을 효과적 으로 줄여 사회적 비용 소모를 절감시킬 수 있는 객체 감응형 차량 흐름 제어 방법을 제공함에 또 다른 목적이 있다."}
{"patent_id": "10-2022-0074549", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 과제 해결을 위해 본 발명은, 「컴퓨터 장치의 인공지능 기반 영상분석부에 의해 구현되며, (a) 카메라 설치각도와 상기 카메라가 촬영한 영상의 방향성을 분석하여 종방향 소실점 VP1과 횡방향 소실점 VP2를 도출하 는 단계; (b) 분석 대상 영상에서 이동하는 객체를 특정하는 단계; (c) 상기 VP1에서 상기 객체의 외연에 접하 도록 이어진 좌단 하부 소실선 Van-L1과 우단 상부 소실선 Van-L2를 생성하는 단계; (d) 상기 VP2에서 상기 객 체의 외연에 접하도록 이어진 전단 하부 소실선 Van-L3와 후단 상부 소실선 Van-L4를 생성하여, 상기 Van-L1과 Van-L3의 교차점 P1과, 상기 Van-L2와 Van-L4의 교차점 P2가 생성되는 단계; (e) 상기 객체 최좌단이 접하는 좌 측 후방 수직선 Ver-L1과, 상기 객체 최우단이 접하는 우측 전방 수직선 Ver-L2를 생성하여, 상기 Ver-L1과 Van-L1의 교차점 P3와, 상기 Ver-L2와 Van-L3의 교차점 P4와, 상기 Ver-L1과 Van-N4의 교차점 P5와, 상기 Ver- L2와 Van-L2의 교차점 P6가 생성되는 단계; (f) 상기 VP2에서 P3를 지나는 소실선 Van-L5와, 상기 VP2에서 P6 를 지나는 소실선 Van-L6를 생성하는 단계; (g) 상기 P1을 지나는 좌측 전방 수직선 Ver-L3와, 상기 P2를 지나 는 우측 후방 수직선 Ver-L4를 생성하여, 상기 Ver-L3와 Van-L6의 교차점 P7과, 상기 Ver-L4와 Van-L5의 교차 점 P8이 생성되는 단계; 및 (h) 상기 P2, P5, P7, P6가 상단 꼭지점을 이루고, 상기 P1, P4, P8, P3가 하단 꼭 지점을 이루는 6면체 바운딩 박스를 생성하는 단계; 를 포함하는, 소실점을 이용한 3D 바운딩 박스 생성 방법」 을 제공한다. 또한 본 발명은, 「감지영역인 적어도 하나 이상의 도로를 촬영하여 영상을 획득하는 카메라들과, 상기 감지영 역에 설치되는 신호등들의 동작을 제어하는 교통신호 제어기와, 컨트롤러를 포함하는 차량 흐름 제어 시스템의 동작 과정인 객체 감응형 차량 흐름 제어 방법으로서, (A) 상기 카메라들이 자신에게 할당된 도로를 촬영하여 영상을 획득한 후, 상기 컨트롤러로 획득된 영상들을 전송하는 단계; (B) 상기 컨트롤러가 딥-러닝(Deep learning) 기반의 객체분석 알고리즘을 이용하여, 상기 (A)단계를 통해 전송받은 영상들을 분석하여 상기 소실 점을 이용한 3D 바운딩 박스 생성 방법에 따라 객체를 감지함과 동시에 감지된 객체의 위치, 종류 및 크기 중 적어도 하나 이상을 포함하는 객체정보를 검출하는 단계; (C) 상기 컨트롤러가 상기 (B)단계에 의해 검출된 객 체정보들과, 기 설정된 각 카메라의 촬영영역의 위치정보, 기 도로의 위치정보를 참조하여, 감지된 객체를 트래 킹하여 각 객체가 위치한 차로종류, 차선위치, 이동속도 및 방향 중 적어도 하나 이상을 포함하는 객체분석정보 를 생성하는 단계; (D) 상기 컨트롤러가 상기 (C)단계에 의해 생성된 객체분석정보를 활용 및 가공하여, 각 연 결차로의 대기열, 대기시간 및 교통량 중 적어도 하나 이상을 포함하는 교통정보를 생성하는 단계; (E) 상기 컨 트롤러가 상기 (D)단계에 의해 생성된 교통정보를 기반으로 최적 신호체계를 수립하는 단계; 및 (F) 상기 컨트 롤러가 상기 (E)단계에 의해 수립된 최적 신호체계 정보를 교통신호 제어기로 전송하고, 상기 교통신호 제어기 가 상기 컨트롤러로부터 전송받은 최적 신호체계 정보에 따라 상기 신호등들이 운영되도록 상기 신호등들을 제 어하는 단계; 를 포함하는 것을 특징으로 하는 객체 감응형 차량 흐름 제어 방법」을 함께 제공한다. 상기 (B)단계에서는 상기 컨트롤러가 카메라 설치각도 및 거리 정보를 반영한 바운딩 박스 분석에 따라 감지된 객체의 종류와 크기를 추정함으로써 객체정보를 검출하도록 구성할 수 있다."}
{"patent_id": "10-2022-0074549", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명이 제공하는 소실점을 이용한 3D 바운딩 박스 생성 방법에 따르면 객체 인식률을 개선시켜 분석의 분석 의 정확성 및 신뢰도를 획기적으로 높일 수 있다. 또한, 본 발명이 제공하는 교통신호 제어를 위한 객체 감응형 차량 흐름 제어 방법에 따르면 카메라들에 의해 촬영된 영상을 분석하여 객체정보 및 교통정보를 생성한 후, 생성된 교통정보에 따라 최적 현시체계를 생성한후, 생성된 최적 현시체계에 따라 교통신호가 제어되도록 구성됨으로써 차량 정체율 및 대기시간을 현저히 절감 시킬 수 있을 뿐만 아니라 이에 따른 연비소모 및 오염가스 배출량을 효과적으로 줄여 사회적 비용 소모를 절감 시킬 수 있게 된다."}
{"patent_id": "10-2022-0074549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "1. 소실점을 이용한 3D 바운딩 박스 생성 방법 본 발명은 아래의 (a)단계 내지 (h)단계에 따라 구현되는 \"소실점을 이용한 3D 바운딩 박스 생성 방법\"을 제공 한다. 상기 (a)단계 내지 (h)단계는 모두 컴퓨터 장치의 인공지능 기반 영상분석부에 의해 구현되는 것이며, 후 술할 \"객체 감응형 차량 흐름 제어 방법\"에서는 \"컨트롤러\"가 상기 \"컴퓨터 장치의 인공지능 기반 영상분석부\" 역할을 수행한다. 이하에서는 첨부된 도면과 함께 \"소실점을 이용한 3D 바운딩 박스 생성 방법\"의 각 단계를 설명한다. 따라서 이 하의 전·후, 상·하, 좌·우 등의 위치 개념은 도면을 기준으로 설정된 것이다. (a)단계에서는 [도 1a]에 도시된 바와 같이 카메라 설치각도와 상기 카메라가 촬영한 영상의 방향성을 분석하여 종방향 소실점 VP1과 횡방향 소실점 VP2를 도출한다. (b)단계에서는 [도 1b]에 도시된 바와 같이 분석 대상 영상에서 이동하는 객체를 특정한다. [도 1b]에서는 Object 1, Object 2가 이동하는 객체이며, 이들 각각에 3D 바운딩 박스를 생성할 것이나, 설명의 편의를 위해 이하에서는 Object 1을 대상으로 설명을 이어간다. 이하에서 \"객체\"는 \"Obcect 1\"에 해당한다. (c)단계에서는 [도 1c]에 도시된 바와 같이 상기 VP1에서 상기 객체의 외연에 접하도록 이어진 좌단 하부 소실 선 Van-L1과 우단 상부 소실선 Van-L2를 생성한다. Van-L1은 VP1에서 객체의 좌단 하부에 접하는 소실선이고, Van-L2는 객체의 우단 상부에 접하는 소실선이다. (d)단계에서는 [도 1d]에 도시된 바와 같이 상기 VP2에서 상기 객체의 외연에 접하도록 이어진 전단 하부 소실 선 Van-L3와 후단 상부 소실선 Van-L4를 생성한다. Van-L3은 VP2에서 객체의 전단 하부에 접하는 소실선이고, Van-L4는 VP2에서 객체의 후단 상부에 접하는 소실선이다. 이에 따라 (d)단계에서는 상기 Van-L1과 Van-L3의 교차점 P1과, 상기 Van-L2와 Van-L4의 교차점 P2가 생성된다. P1은 객체에 대한 3D 바운딩 박스(이하, '바운딩 박 스'로 약칭)의 전방 좌측 하단 꼭지점이고, P2는 바운딩 박스의 후방 우측 상단 꼭지점이다. (e)단계에서는 [도 1e]에 도시된 바와 같이 상기 객체 최좌단이 접하는 좌측 후방 수직선 Ver-L1과, 상기 객체 최우단이 접하는 우측 전방 수직선 Ver-L2를 생성한다. Ver-L1은 객체의 가장 왼쪽 단부 지점에서 생성된 수직 선이고, 상기 Ver-L2는 상기 객체의 가장 오른쪽 단부 지점에서 생성된 수직선이다. 이에 따라 (e)단계에서는 상기 Ver-L1과 Van-L1의 교차점 P3와, 상기 Ver-L2와 Van-L3의 교차점 P4와, 상기 Ver-L1과 Van-N4의 교차점 P5와, 상기 Ver-L2와 Van-L2의 교차점 P6가 생성된다. P3는 바운딩 박스의 후방 좌측 하단 꼭지점이고, P4는 바 운딩 박스의 전방 우측 하단 꼭지점이고, P5는 바운딩 박스의 후방 좌측 상단 꼭지점이고, P6는 바운딩 박스의 전방 우측 상단 꼭지점이다. (f)단계에서는 [도 1f]에 도시된 바와 같이 상기 VP2에서 P3를 지나는 소실선 Van-L5와, 상기 VP2에서 P6를 지 나는 소실선 Van-L6를 생성한다. Van-L5에 의해 바운딩 박스의 후방 하단 수평 라인이 형성되고, Van-L6에 의해 서는 바운딩 박스의 전방 상단 수평 라인이 형성된다. (g)단계에서는 상기 P1을 지나는 좌측 전방 수직선 Ver-L3와, 상기 P2를 지나는 우측 후방 수직선 Ver-L4를 생 성한다. Ver-L3은 바운딩 박스의 전방 좌측 수직 라인을 형성하고, Ver-L4는 바운딩 박스의 후방 우측 수직 라 인을 형성한다. 이에 따라 (g)단계에서는 상기 Ver-L3와 Van-L6의 교차점 P7과, 상기 Ver-L4와 Van-L5의 교차점 P8이 생성된다. P7은 바운딩 박스의 전방 좌측 상단 꼭지점이고, P8은 바운딩 박스의 후방 우측 하단 꼭지점이 다. (h)단계에서는 상기 P2, P5, P7, P6가 상단 꼭지점을 이루고, 상기 P1, P4, P8, P3가 하단 꼭지점을 이루는 6면 체 바운딩 박스를 생성한다. 카메라 설치 위치와 객체와의 거리 정보를 반영하여 생성된 바운딩 박스의 실 사이즈와 종횡비 등을 분석할 수 있으며, 이에 따라 감지된 객체의 종류와 크기를 추정할 수 있다. 2. 객체 감응형 차량 흐름 제어 방법 [도 2]는 본 발명의 일실시예인 객체 감응형 차량 흐름 제어 방법이 적용되는 차량 흐름 제어 시스템을 나타내 는 구성도이고, [도 3]은 [도 2]를 나타내는 예시도이다. 본 발명의 객체 감응형 차량 흐름 제어 방법(S1)이 적용되는 차량 흐름 제어 시스템은 [도 2]와 [도 3]에 도 시된 바와 같이, 교차로의 각 차로군을 촬영하는 카메라(5-1), , (5-N)들과, 딥-러닝(Deep learning) 기반의 객 체분석 알고리즘을 이용하여 각 카메라의 촬영에 의해 획득된 영상들을 분석하여 객체분석정보를 검출한 후, 검출된 객체분석정보에 대응하는 최적 신호체계를 생성하여 생성된 최적 신호체계에 따른 감응신호를 후술되는 교통신호 제어기로 전송하는 컨트롤러와, 컨트롤러로부터 전송받은 최적 신호체계에 따른 감응신호에 따라 신호등들의 동작을 제어하는 교통신호 제어기와, 도로 갓길 또는 신호등 지주에 설치되어 컨트롤러 의 제어에 따라 기 설정된 경고문구를 디스플레이 하는 전시수단들과, 컨트롤러로부터 전송받은 객체 분석정보, 교통정보, 위반정보, 위반 영상을 저장 및 모니터링 하는 관제센터서버와, 컨트롤러 및 관제센 터서버 사이의 데이터 이동경로를 제공하는 통신망으로 이루어진다. 카메라(5-1), , (5-N)들은 교차로(S)에 연결되는 각 연결차로들을 촬영하도록 설치되며, 해당 연결차로를 촬영 하여 획득된 영상을 컨트롤러로 전송한다. [도 4]는 본 발명의 일실시예인 객체 감응형 차량 흐름 제어 방법(S1)을 나타내는 플로차트이다. 본 발명의 일실시예인 객체 감응형 차량 흐름 제어 방법(S1)은 입력영상으로부터 객체를 감지하기 위한 딥-러닝 (Deep learning) 알고리즘의 모델을 도로 환경에 적합하도록 최적화시킴과 동시에 카메라의 촬영에 의해 영상획득 시, 딥-러닝을 이용하여 영상을 분석하여 객체(차량 및 보행자)를 검출한 후, 검출된 객체정보를 기반으로 신호체계를 수립함으로써 영상분석을 통한 객체 감지 및 트래킹의 정확성을 현저히 높임에 따라 신호 제어의 신 뢰도를 높일 수 있을 뿐만 아니라 교차로의 차량 대기시간이 현저히 절감되며, 현장에서 실시간 영상처리가 가 능하게 된다. 본 발명의 객체 감응형 차량 흐름 제어 방법(S1)은 [도 4]에 도시된 바와 같이, 학습단계(S10)와, 카메라 촬영 단계(S20), 영상전송단계(S30), 영상분류단계(S40), 인공지능 기반 영상 분석단계(S50), 사용량 모니터링 단계 (S60), 객체상세정보 생성단계(S70), 교통정보 생성단계(S80), 번호인식단계(S90), 위반차량 판별단계(S100), 신호체계 수립단계(S110), 신호제어단계(S120), 분류테이블 최적화단계(S130)로 구분할 수 있다. 이하에서는 첨부된 도면과 함께 \"객체 감응형 차량 흐름 제어 방법\"을 (A)단계 내지 (E)단계로 구분하여 설명한 다. (A)단계는 상기 카메라들이 자신에게 할당된 도로를 촬영하여 영상을 획득한 후, 상기 컨트롤러로 획득된 영상 들을 전송하는 단계로, 본 (A)단계에는 상기 학습단계(S10), 카메라 촬영단계(S20) 및 영상전송단계(S30)가 포 함된다. 상기 학습단계(S10)는 기 설정된 주기1(T1) 마다 진행되며, 컨트롤러가 딥-러닝(Deep learning) 기반의 객체 분석 알고리즘을 학습화하는 단계이다. 또한 학습단계(S10)는 주기1(T1) 동안 수집된 영상과 기 설정된 객체종 류를 활용하여, 영상 및 객체종류 간의 상관관계를 학습할 수 있는 학습데이터를 생성하고 생성된 학습데이터를 활용하여 객체영상 및 객체종류 간의 상관관계에 대한 파라미터 값들의 집합인 추출모델을 도출한다. 상기 카메라 촬영단계(S20)는 카메라들이 자신에게 할당된 연결차로를 촬영하여 영상을 획득하는 단계이다. 이때 카메라들은 기 설정된 촬영영역인 연결차로를 촬영 가능하도록 교차로(S)에 다양한 방식으로 설치될 수 있으며, 상세하게로는 기존에 설치되어 있던 신호등 지주의 상단부에 별도의 보조-암을 통해 결합됨에 따라 촬 영 각도가 상부에서 하부를 향하는 방향으로 설치되며 PTZ(Pan-Tilt-Zoom) 제어가 가능한 통상의 PTZ 카메라로 구현되는 것이 바람직하다. 상기 영상전송단계(S30)는 카메라들이 촬영된 영상을 컨트롤러로 전송하는 단계이다. (B)단계는 상기 컨트롤러가 딥-러닝(Deep learning) 기반의 객체분석 알고리즘을 이용하여, 상기 (A)단계를 통 해 전송받은 영상들을 분석하여 전술한 \"소실점을 이용한 3D 바운딩 박스 생성 방법\"에 따라 객체를 감지함과 동시에 감지된 객체의 위치, 종류 및 크기 중 적어도 하나 이상을 포함하는 객체정보를 검출하는 단계이다. 본 (B)단계에는 영상분류단계(S40) 및 인공지능 기반 영상 분석단계(S50)가 포함될 수 있다. [도 5]는 [도 4]의 영상분류단계(S40)를 나타내는 플로차트이다. 상기 영상분류단계(S40)는 도 7에 도시된 바와 같이, 영상입력단계(S41)와, 비교단계(S42), 분류모드 판별단계 (S43), 일대일기반 분류단계(S44), 분류테이블기반 분류단계(S45)로 이루어진다. 상기 영상입력단계(S41)는 컨트롤러가 영상전송단계(S30)를 통해 카메라들로부터 전송받은 영상을 입력받 는 단계이다. 상기 비교단계(S42)는 컨트롤러가 영상입력단계(S41)를 통해 입력받은 영상들의 수량(N)과, 컨트롤러에 구비된 GPU(Graphic Processing Unit)의 전체 수량(M)을 비교하는 단계이다. 상기 분류모드 판별단계(S43)는 비교단계(S42)에서, 1) 입력된 영상 수량(N)이 GPU 수량(M) 이하(N ≤ M)이면, 각 영상이 단일 GPU에서 처리(일대일기반 영상분류)되어야 한다고 판단하며, 2) 입력된 영상 수량(N)이 GPU 수 량(M)을 초과(N > M)하면, 적어도 하나 이상의 GPU에서 2개 이상의 영상을 처리(분류테이블기반 영상분류)되어 야 한다고 판단한다. 상기 일대일기반 분류단계(S44)는 분류모드 판별단계(S43)에서, 입력된 영상 수량(N)이 GPU 수량(N) 이하(N ≤ M)일 때 진행되며, 각 카메라의 영상이 단일 GPU에서 처리되도록 영상들을 각 GPU로 분류하여 입력한다. 이때 컨트롤러는 일대일기반일 때, 각 카메라의 영상이 분류되는 GPU 정보가 기 설정되어 저장된다. 즉 일대일기반 분류단계(S44)는 카메라의 촬영에 의해 획득된 영상들을 일대일로 각 GPU에 입력한다. 분류테이블기반 분류단계(S45)는 분류모드 판별단계(S33)에서, 입력된 영상 수량(N)이 GPU 수량(N)을 초과(N > M)할 때 진행되며, 후술되는 분류테이블 최적화단계(S120)에 의해 최적화된 분류테이블을 메모리(M)로부터 추출 한 후, 추출된 분류테이블에 따라, 카메라로부터 전송받은 영상들을 GPU들로 분류하며, 각 영상을 분류된 GPU로 입력하는 단계이다. 이때 분류테이블은 각 카메라로부터 입력된 영상을 처리할 대상인 GPU가 매칭되는 데이터를 의미하고, 후술되는 분류테이블 최적화단계(S130)에 의해 기 설정된 주기2(T2) 마다 최적화되어 메모리(M)에 저장된다. [도 6]은 [도 4]의 인공지능 기반 영상 분석단계(S50)를 나타내는 플로차트이다. 상기 인공지능 기반 영상 분석단계(S50)는 [도 6]에 도시된 바와 같이, 영상입력단계(S51-1, …, 51-N)들과, 알 고리즘 추출단계(S52), 영상분석단계(S53-1, …, S53-N)들로 이루어진다. 상기 영상입력단계(S51-1, …, S51-N)들은 컨트롤러가 전술하였던 영상분류단계(S40)에 의해 분류된 바에 따 라, 카메라로부터 전송받은 영상을 각 GPU로 입력하는 단계이다. 즉 각 GPU에는 영상분류단계(S40)에 의해 분류된 바에 따라, 영상을 입력받는다. 상기 알고리즘 추출단계(S52)는 컨트롤러가 학습단계(S10)에 의해 학습되어 메모리(M)에 저장된 객체분석 알 고리즘을 추출하는 단계이다. 상기 영상분석단계(S53-1, …, S53-N)들은 각 GPU가 알고리즘 추출단계(S52)에 의해 추출된 객체분석 알고리즘 을 이용하여, 영상입력단계(S51)를 통해 자신에게 입력된 영상을 분석하여 객체정보(인식, 위치, 종류, 크기 등)를 출력하는 단계이다. 이 때 객체 분석은 전술한 \"소실점을 이용한 3D 바운딩 박스 생성 방법\"에 따라 생성 된 3D 바운딩 박스를 매개로 실시한다. 상기 컨트롤러는 카메라 설치각도 및 거리 정보를 반영한 바운딩 박 스 분석에 따라 감지된 객체의 종류와 크기를 추정함으로써 객체정보를 검출할 수 있다. (C)단계는 상기 컨트롤러가 상기 (B)단계에 의해 검출된 객체정보들과, 기 설정된 각 카메라의 촬영영역의 위치 정보, 기 도로의 위치정보를 참조하여, 감지된 객체를 트래킹하여 각 객체가 위치한 차로종류, 차선위치, 이동 속도 및 방향 중 적어도 하나 이상을 포함하는 객체분석정보를 생성하는 단계이다. 본 (C)단계에는 사용량 모니 터링 단계(S60) 및 객체상세정보 생성단계(S70)가 포함될 수 있다. 상기 사용량 모니터링 단계(S60)는 전술하였던 영상분석단계(S53-1, …, S53-N)들을 통해 GPU들 중 적어도 하나 이상에서 영상처리가 이루어질 때 진행되며, 영상처리가 수행된 GPU에서 영상분석을 위한 사용량(부하량)을 검 출하며, 검출된 사용량 정보를 메모리(M)에 저장하는 단계이다. 이때 사용량 모니터링 단계(S60)는 각 GPU의 영상분석단계(S53-1, …, S53-N)들이 모두 진행되지 않는 경우에는 별도로 진행되지 않는다. 즉 사용량 모니터링 단계(S60)는 영상 분석을 위한 연산처리로 인한 각 GPU의 사용량 을 실시간 검출한 후, 이를 메모리(M)에 저장한다. 상기 객체상세정보 생성단계(S70)는 컨트롤러가 영상분석단계(35-1, …, 35-M)들에 의해 검출된 객체정보들 과, 기 설정된 각 카메라의 감지영역의 위치정보와, 교차로(S) 및 각 연결차로(S1, S2, S3, S4)의 위치정보 를 참조하며, 감지된 객체를 트래킹하여, 각 객체가 위치한 차로종류, 차선위치, 이동속도 및 방향 등을 포함하 는 객체분석정보를 생성하는 단계이다. (D)단계는 상기 컨트롤러가 상기 (C)단계에 의해 생성된 객체분석정보를 활용 및 가공하여, 각 연결차로의 대기 열, 대기시간 및 교통량 중 적어도 하나 이상을 포함하는 교통정보를 생성하는 단계이다. 본 (D)단계에는 교통 정보 생성단계(S80), 번호인식단계(S90) 및 위반차량 판별단계(S100)가 포함될 수 있다. 상기 교통정보 생성단계(S80)는 객체분석정보 생성단계(S70)에 의해 생성된 객체분석정보를 활용 및 가공하여, 각 연결차로의 대기열, 대기시간 및 교통량 등을 포함하는 교통정보를 생성하는 단계이다. [도 7]은 [도 4]의 번호인식단계(S90)를 설명하기 위한 예시도이다. 상기 번호인식단계(S90)는 객체상세정보 생성단계(S70) 이후에, 교통정보 생성단계(S80)와 병렬로 진행되며, 컨 트롤러가 객체상세정보 생성단계(S70)에 의해 생성된 객체분석정보와, 교통신호 제어기의 현재 현시정보, 교차로(S) 및 각 연결차로(S1, S2, S3, S4)의 위치정보를 활용하여, 차량이 각 연결차로가 교차로(S)와 연결되 는 구간을 통과하는 차량의 영상을 분석하여 차량번호를 인식하는 단계이다. [도 8]은 도 4의 위반차량 판별단계에 의해 판별되는 꼬리 물기 위반 차량을 나타내는 예시도이다. 상기 위반차량 판별단계(S100)는 컨트롤러가 객체상세정보 생성단계(S70)에 의해 생성된 객체분석정보와, 교 통신호 제어기의 현재 현시정보, 교차로(S) 및 각 연결차로(S1, S2, S3, S4)의 위치정보를 활용하여, [도 8]에 도시된 바와 같이, 꼬리물기 등의 위반차량을 검출하는 단계이다. (E)단계는 상기 컨트롤러가 상기 (D)단계에 의해 생성된 교통정보를 기반으로 최적 신호체계를 수립하는 단계이 다. 본 (E)단계는 신호체계 수립단계(S110)라 칭할 수 있으며, 상기 신호체계 수립단계(S110)는 컨트롤러가 기 설정된 최적 신호 검출 알고리즘을 이용하여, 교통정보 생성단계(S80)에 의해 생성된 교통정보를 분석하여, 현 재 교통정보에 따른 최적 신호체계를 수립하는 단계이다. (F)단계는 상기 컨트롤러가 상기 (E)단계에 의해 수립된 최적 신호체계 정보를 교통신호 제어기로 전송하고, 상 기 교통신호 제어기가 상기 컨트롤러로부터 전송받은 최적 신호체계 정보에 따라 상기 신호등들이 운영되도록 상기 신호등들을 제어하는 단계이다. 본 (F)단계에는 신호제어단계(S120) 및 분류테이블 최적화단계(S130)가 포 함될 수 있다. 상기 신호제어단계(S120)는 컨트롤러가 신호체계 수립단계(S110)에 의해 수립된 최적 신호체계 정보를 교통 신호 제어기로 전송하고, 교통신호 제어기가 컨트롤러로부터 전송받은 최적 신호체계 정보에 따라 신 호등들의 동작을 관리 및 제어하는 단계이다. 이때 교통정보를 기반으로 최적 신호체계를 수립하는 최적 신호 검출 알고리즘에 대한 기술 및 방법은 신호 제 어시스템에 있어서 통상적으로 사용되는 기술 및 방법이기 때문에 상세한 설명은 생략하기로 하고, 공지된 알고 리즘이나 향후 개발될 알고리즘이 적용될 수 있다. [도 9]는 [도 4]의 분류테이블 최적화단계(S130)를 나타내는 플로차트이다. [도 9]의 분류테이블 최적화단계(S130)는 기 설정된 주기2(T2) 마다 실행된다. 또한 분류테이블 최적화단계(S130)는 데이터 수집단계(S131)와, 각 GPU별 총사용량 산출단계(S132), 각 GPU별 평균사용량 산출단계(S133), GPU 식별번호 초기화단계(S134), GPU 선택단계(S135), 비교 및 판별단계(S136), 점 검후보 결정단계(S137), 제1 잔여 GPU 존재여부 판별단계(S138), GPU 식별번호 추가단계(S139), 제2 잔여 GPU 존재여부 판별단계(S140), 점검후보 존재여부 판별단계(S141), GPU 정렬단계(S142), 변경대상 결정단계(S143), 분류테이블 최적화단계(S144)로 이루어진다. 상기 데이터 수집단계(S131)는 컨트롤러가 기 설정된 주기2(T2) 동안 메모리(M)에 저장된 각 GPU별 사용량 데이터들을 수집하는 단계이다. 상기 각 GPU 총사용량 산출단계(S132)는 데이터 수집단계(S131)에 의해 수집된 각 GPU별 사용량 데이터들을 활 용하여, 각 GPU별 총사용량을 산출하는 단계이다. 상기 각 GPU 평균사용량 산출단계(S133)는 컨트롤러에 구비된 GPU의 수량을 ‘m’이고, 각 GPU에 1부터 m까 지의 식별번호(i)가 부여되었다고 가정할 때, 각 GPU 총사용량 산출단계(S132)에 의해 산출된 각 별 총사용량과 주기(T2)를 활용하여, 각 별로 시간당 평균사용량( )을 산출한다. 상기 GPU 식별번호 초기화단계(S134)는 점검대상인 GPU의 식별번호(i)를‘1’로 초기화하는 단계이다. 상기 GPU 선택단계(S135)는 GPU 식별번호 초기화단계(S134) 또는 GPU 식별번호 추가단계(S138)에 의해 산출된 식별번호(i)를 갖는 GPU를 선택하는 단계이다.상기 비교 및 판별단계(S136)는 GPU 선택단계(S135)에 의해 선택된 GPUi의 평균사용량( )을 기 설정된 상한 설정값(TH)과 비교하며, 상세하게로는 해당 GPUi의 평균사용량( )이 상한설정값(TH) 이상( ≥ TH)인지 를 비교하는 단계이다. 이때 상한설정값(TH)은 해당 GPU에서 과부하가 발생하였다고 판단할 수 있는 사용량 최소값으로 정의된다. 또한 비교 및 판별단계(S136)는 1) GPUi의 평균사용량( )이 상한설정값(TH) 이상( ≥ TH)이면, 해당 GPUi에 과부하가 발생하였다고 판단하여 다음 단계로 점검후보 결정단계(S137)를 진행하되, 2) GPUi의 평균사용 량( )이 상한설정값(TH) 미만( < TH)이면, 해당 GPUi에 과부하가 발생하지 않았다고 판단하여 다음 단 계로 제1 잔여 GPU 존재여부 판별단계(S138)를 진행한다. 상기 점검후보 결정단계(S137)는 비교 및 판별단계(S136)에서, GPUi의 평균사용량( )이 상한설정값(TH) 이 상( ≥ TH)임에 따라 해당 GPUi에 과부하가 발생하였다고 판단될 때 진행되며, 해당 GPUi를 점검대상으로 결정하는 단계이다. 상기 제1 잔여GPU 존재여부 판별단계(S138)는 비교 및 판별단계(S136)에서, GPUi의 평균사용량( )이 상한설 정값(TH) 미만( < TH)임에 따라 해당 GPUi에 과부하가 발생하지 않았다고 판단될 때 진행되며, 현재 식별 번호(i)가 최종 식별번호 ‘m’ 이상인지를 비교하는 단계이다. 이때 잔여GPU는 상기 단계136(S136)에서, 아직 평균사용량 및 상한설정값(TH)의 비교가 이루어지지 않은 GPU를 의미한다. 또한 제1 잔여GPU 존재여부 판별단계(S138)는 1) 만약 현재 식별번호(i)가 최종 식별번호 ‘m’ 이상이면, 잔여 GPU가 존재하지 않는다고 판단하여 다음 단계로 점검후보 존재여부 판별단계(S141)를 진행하고, 2)만약 현재 식 별번호(i)가 최종 식별번호 ‘m’ 미만이면, 잔여GPU가 존재한다고 판단하여 다음 단계로 GPU 식별번호 추가단 계(S139)를 진행한다. 상기 GPU 식별번호 추가단계(S139)는 제1 잔여GPU 존재여부 판별단계(S138)에서, 현재 식별번호(i)가 최종 식별 번호 ‘m’ 미만임에 따라 잔여GPU가 존재한다고 판단될 때 진행되며, 현재 GPU 식별번호(i)에 ‘1’을 추가하 는 단계이다. 또한 상기 GPU 식별번호 추가단계(S139)는 다음 단계로 GPU 선택단계(S135)를 진행하여 GPU 선택단계(S135)의 과정을 반복한다. 또한 상기 제2 잔여GPU 존재여부 판별단계(S140)는 점검후보 결정단계(S137) 이후에 진행되며, 현재 식별번호 (i)가 최종 식별번호 ‘m’ 이상인지를 비교하는 단계이다. 또한 제2 잔여GPU 존재여부 판별단계(S140)는 1)만약 현재 식별번호(i)가 최종 식별번호 ‘m’ 이상이면, 잔여 GPU가 존재하지 않는다고 판단하여 다음 단계로 점검후보 존재여부 판별단계(S141)를 진행하고, 2)만약 현재 식 별번호(i)가 최종 식별번호 ‘m’ 미만이면, 잔여GPU가 존재한다고 판단하여 다음 단계로 GPU 식별번호 추가단 계(S139)를 진행한다. 상기 점검후보 존재여부 판별단계(S141)는 점검후보 결정단계(S137)에 의해 적어도 하나 이상의 GPU가 점검후보 로 결정되었는지 여부를 판단하는 단계이다. 또한 상기 점검후보 존재여부 판별단계(S141)는 1)만약 점검후보로 결정된 GPU가 존재하면, 다음 단계로 GPU 정 렬단계(S142)를 진행하고, 2)만약 점검후보로 결정된 GPU가 존재하지 않으면, 다음 단계를 진행하지 않고 종료 한다. 상기 GPU 정렬단계(S142)는 점검후보 존재여부 판별단계(S141)에서, 점검후보로 결정된 GPU가 존재할 때 진행되 며, 각 GPU 평균사용량 산출단계(S133)에서 산출된 평균사용량( )들을 활용하여, 평균사용량( )이 낮은 순서부터 높은 순서까지 GPU들을 차례대로 정렬시킨다. 상기 변경대상 결정단계(S143)는 점검후보로 결정된 GPU가 L개일 때, 평균사용량( )이 낮은 순서부터 L개의 GPU를 변경대상으로 결정한다. 상기 분류테이블 최적화단계(S144)는 변경대상 결정단계(S143)에서 점검 후보로 결정된 각 GPU에 대하여, 해당 점검후보의 GPU로 입력되는 영상들 중 어느 하나가 해당 점검후보의 변경대상으로 결정된 GPU로 입력되도록 결 정한 후, 결정된 정보가 반영되도록 분류테이블을 최적화한 후, 메모리(M)에 저장한다. 이와 같이 본 발명의 일실시예인 객체 감응형 차량 흐름 제어 방법(S1)은 카메라들에 의해 촬영된 영상을 분석 하여 객체정보 및 교통정보를 생성한 후, 생성된 교통정보에 따라 최적 현시체계를 생성한 후, 생성된 최적 현 시체계에 따라 교통신호가 제어되도록 구성됨으로써 차량 정체율 및 대기시간을 현저히 절감시킬 수 있을 뿐만 아니라 이에 따른 연비소모 및 오염가스 배출량을 효과적으로 줄여 사회적 비용 소모를 절감시킬 수 있게 된다. 또한 본 발명의 객체 감응형 차량 흐름 제어 방법(S1)은 딥-러닝 알고리즘을 이용하여 입력된 영상들을 분석함 에 따라 객체 인식률을 개선시켜 분석의 정확성 및 신뢰도를 획기적으로 높일 수 있다. 또한 본 발명의 객체 감응형 차량 흐름 제어 방법(S1)은 딥-러닝 알고리즘으로 합성곱 신경망(CNN, Convolution Neural Network) 기반의 YOLO 모델을 적용시킴으로써 객체 인식률을 더욱 높일 수 있게 된다. 또한 본 발명의 객체 감응형 차량 흐름 제어 방법(S1)은 딥-러닝 알고리즘의 학습 시, 인식대상을 종래에 80종 류에서, 도로에서 자주 볼 수 있는 5종류로 제한하여 학습이 이루어지도록 구성됨으로써 객체 인식률을 더욱 개 선시킬 수 있다. 또한 본 발명의 객체 감응형 차량 흐름 제어 방법(S1)은 복수개의GPU(Graphic Processing Unit)들을 이용하여 영상을 분석함으로써 카메라들의 촬영에 의해 획득된 고용량의 영상들의 실시간 처리 및 분석이 가능하다."}
{"patent_id": "10-2022-0074549", "section": "도면", "subsection": "도면설명", "item": 1, "content": "[도 1a] 내지 [도 1h]는 본 발명이 제공하는 소실점을 이용한 3D 바운딩 박스 생성 방법의 단계별 예시도이다. [도 2]는 본 발명의 일실시예인 객체 감응형 차량 흐름 제어 방법이 적용되는 차량 흐름 제어 시스템을 나타내 는 구성도이다. [도 3]은 [도 2]를 나타내는 예시도이다. [도 4]는 본 발명의 일실시예인 객체 감응형 차량 흐름 제어 방법(S1)을 나타내는 플로차트이다. [도 5]는 [도 4]의 영상분류단계를 나타내는 플로차트이다. [도 6]은 [도 4]의 인공지능 기반 영상 분석단계를 나타내는 플로차트이다. [도 7]은 [도 4]의 번호인식단계를 설명하기 위한 예시도이다. [도 8]은 [도 4]의 위반차량 판별단계에 의해 판별되는 꼬리 물기 위반차량을 나타내는 예시도이다. [도 11]은 [도 4]의 분류테이블 최적화단계를 나타내는 플로차트이다."}
