{"patent_id": "10-2019-0083893", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0007713", "출원번호": "10-2019-0083893", "발명의 명칭": "감성 분석에 의한 토픽 결정 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "니콜렌코 세르게이 이고레비치"}}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "텍스트 문서를 수신하는 단계;토픽 모델을 사용하여 상기 텍스트 문서 내 포함된 워드들에 대한 표현(representation)을 결정하는 단계;상기 토픽 모델에 포함된 감성 사전(sentiment prior)에 기초하여 상기 결정된 표현을 측정하는 단계; 및상기 측정된 표현에 기초하여 상기 텍스트 문서의 토픽을 결정하는 단계를 포함하는 감성 분석에 의해 텍스트문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 텍스트 문서는 네트워크에 연결된 서버로부터 수신하는 것을 특징으로 하는 감성 분석에의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 결정된 표현은 의미론적 공간(semantic space)에서 워드 벡터인 것을 특징으로 하는 감성분석에 의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 토픽 모델에 포함된 상기 감성 사전은, 정규화기(regularizer)를 사용하여 분산된 표현에기초해 학습되는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 감성 사전(prior)이 학습되는 것은, 소정의 오차값 이내의 워드 벡터를 가지는 표현을 동일한 감성 사전으로 결정하는 상기 정규화기(regularizer)를 사용하여 학습되는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 감성 사전이 학습되는 것은,워드 세트를 수신하는 단계;상기 워드 세트에 기초해서 제 1 워드에 대한 가장 이웃한 워드 세트를 결정하는 단계;상기 제 1 워드에 대한 표현을 결정하되, 상기 결정된 표현은 의미론적 공간에서 워드 벡터인 것을 특징으로 하고;상기 결정된 표현과 상기 가장 이웃한 워드 세트를 사용하여 감성에서 상기 제 1 워드가 발생하는 확률을 측정함에 의해 상기 정규화기의 정규화 계수를 결정하는 단계;상기 결정된 정규화 계수에 기초하여 상기 정규화기를 정의하는 단계;상기 정규화기를 사용하여 상기 가장 유사한 워드 벡터를 가지면서 상기 가장 이웃한 워드 세트에 포함된 워드를 상기 제 1 워드와 동일 감성으로 결정하는 단계;상기 동일 감성 결정에 따라 상기 제 1 워드에 대한 표현을 분산시키는 단계; 및상기 분산된 표현을 사용하여 상기 감성 사전을 계산하는 단계를 포함하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2020-0007713-3-제6항에 있어서, 상기 가장 이웃한 워드 세트를 결정하는 것은 코사인 유사도(cosine similarity)에 기초하여상기 제 1 워드에 대하여 상기 워드 세트 내의 워드 벡터가 상기 제 1 워드의 워드 벡터와 가장 근접한 지를 판별하여 결정하는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 계산된 감성 사전(prior)을 사용하여 상기 텍스트 문서 중 적어도 일부 문서의 저자의 속성을 예측하는 단계를 포함하되, 상기 저자의 속성은 상기 저자의 위치, 성별 및 나이 중 적어도 하나를 포함하고, 및상기 예측된 저자 속성에 기초하여 상기 감성 사전(prior)을 업데이트하는 단계를 포함하는 감성 분석에 의해텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 표현을 측정하는 것은상기 토픽 모델의 가능성의 최대화를 수행하되, 상기 토픽 모델의 가능성의 최대화는 상기 정규화 계수를 업데이트하는 단계; 및상기 갱신된 정규화 계수를 가지는 정규화기를 사용하여 상기 감성 사전을 업데이트하는 단계를 포함하는 감성분석에 의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 감성 사전(prior)은 워드 사전(dictionary)으로부터 추출된 미리 정의된 사전값(priorvalue)을 가지는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치로서, 메모리; 텍스트 문서를 수신하는 입출력 인터페이스; 및프로세서를 포함하고, 상기 프로세서는상기 수신한 텍스트 문서를 상기 메모리에 저장하도록 제어하고,토픽 모델을 사용하여 상기 텍스트 문서 내 포함된 워드들에 대한 표현(representation)을 결정하고, 상기 토픽 모델에 포함된 감성 사전(sentiment prior)에 기초하여 상기 결정된 표현을 측정하고,상기 측정된 표현에 기초하여 상기 텍스트 문서의 토픽을 결정하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 입출력 인터페이스는 상기 텍스트 문서를 네트워크에 연결된 서버로부터 수신하는 것을특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 결정된 표현은 의미론적 공간(semantic space)에서 워드 벡터인 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 프로세서는 상기 토픽 모델에 포함된 상기 감성 사전을 정규화기(regularizer)를 사용하여 분산된 표현에 기초해 학습시키는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장공개특허 10-2020-0007713-4-치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 프로세서가 상기 감성 사전(prior)을 학습시키는 것은, 상기 프로세서가 소정의 오차값이내의 워드 벡터를 가지는 표현을 동일한 감성 사전으로 결정하는 상기 정규화기(regularizer)를 사용하여 학습시키는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 프로세서가 상기 감성 사전을 학습시키는 것은, 상기 프로세서가워드 세트를 수신하고;상기 워드 세트에 기초해서 제 1 워드에 대한 가장 이웃한 워드 세트를 결정하고;상기 제 1 워드에 대한 표현을 결정하되, 상기 결정된 표현은 의미론적 공간에서 워드 벡터인 것을 특징으로 하고;상기 결정된 표현과 상기 가장 이웃한 워드 세트를 사용하여 감성에서 상기 제 1 워드가 발생하는 확률을 측정함에 의해 상기 정규화기의 정규화 계수를 결정하고;상기 결정된 정규화 계수에 기초하여 상기 정규화기를 정의하고;상기 정규화기를 사용하여 상기 가장 유사한 워드 벡터를 가지면서 상기 가장 이웃한 워드 세트에 포함된 워드를 상기 제 1 워드와 동일 감성으로 결정하고;상기 동일 감성 결정에 따라 상기 제 1 워드에 대한 표현을 분산시키고; 및상기 분산된 표현을 사용하여 상기 감성 사전을 계산하는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서 상기 가장 이웃한 워드 세트를 결정하는 것은 상기 프로세서가 코사인 유사도(cosinesimilarity)에 기초하여 상기 제 1 워드에 대하여 상기 워드 세트 내의 워드 벡터가 상기 제 1 워드의 워드 벡터와 가장 근접한 상기 워드 벡터인지를 판별하여 결정하는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서, 상기 프로세서는 상기 계산된 감성 사전(prior)을 사용하여 상기 텍스트 문서 중 적어도 일부 문서의 저자의 속성을 예측하되,상기 저자의 속성은 상기 저자의 위치, 성별 및 나이 중 적어도 하나를 포함하고, 및상기 예측된 저자 속성에 기초하여 상기 감성 사전(prior)을 업데이트하는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서, 상기 프로세서가 상기 표현을 측정하는 것은,상기 토픽 모델의 가능성의 최대화를 수행하되, 상기 토픽 모델의 가능성의 최대화는 상기 정규화 계수를 업데이트하고; 및상기 갱신된 정규화 계수를 가지는 정규화기를 사용하여 상기 감성 사전을 업데이트하는 것을 특징으로 하는 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치."}
{"patent_id": "10-2019-0083893", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "텍스트 문서를 수신하는 단계;공개특허 10-2020-0007713-5-토픽 모델을 사용하여 상기 텍스트 문서 내 포함된 워드들에 대한 표현(representation)을 결정하는 단계;상기 토픽 모델에 포함된 감성 사전(sentiment prior)에 기초하여 상기 결정된 표현을 측정하는 단계; 및상기 측정된 표현에 기초하여 상기 텍스트 문서의 토픽을 결정하는 단계를 포함하는 감성 분석에 의해 텍스트문서의 토픽을 결정하는 방법을 수행하는 명령을 포함하는 컴퓨터 가독 기록 매체."}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법과 장치가 제공되는데, 텍스트 문서를 수신하는 단계, 토 픽 모델을 사용하여 상기 텍스트 문서 내 포함된 워드들에 대한 표현(representation)을 결정하는 단계, 상기 토 픽 모델에 포함된 감성 사전(sentiment prior)에 기초하여 상기 결정된 표현을 측정하는 단계, 및 상기 측정된 표현에 기초하여 상기 텍스트 문서의 토픽을 결정하는 단계를 포함한다."}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 토픽 모델링에 관한 것으로 특히, 분산(배포) 표현(distributed representation)에 기초한 토픽 모델 링 및 토픽 모델링에 기초한 감성 분석과 토픽 결정에 관한 것이다."}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자연어 처리(natural language processing)는 우리가 일생 생활에서 사용하는 언어의 의미를 분석하여 컴퓨터가"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "처리할 수 있도록 하는 과정을 의미한다. 자연어 처리는 음성 인식(speech recognition), 내용 요약, 사용자의 감성 분석(sentiment analysis), 텍스트 분류 작업(스팸 메일 분류, 뉴스 기사 카테고리 분류), 질의 응답 시스 템, 챗봇(chatbot)과 같은 곳에서 사용된다. 최근 딥 러닝(deep learning)이 주목받으면서 인공지능(AI)이 제4 차 산업혁명의 중요 키워드로 떠오르고 있다. 자연어 처리는 기계에게 인간의 언어를 이해시킨다는 점에서 가장 중요한 연구분야이면서도 아직 정복되어야 할 영역이 많은 분야이다. 토픽 모델링(topic modeling)은 기계 학습 및 자연어 처리 분야에서 토픽이라는 문서 집합의 추상적인 주제를 발견하기 위한 통계적 모델 중 하나로, 텍스트 본문의 숨겨진 의미 구조를 발견하기 위해 사용되는 텍스트 마이 닝 기법이다."}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "텍스트 문서에서 토픽을 정확하게 추출하는 정밀한 토픽 결정 모델이 필요하다."}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시에 따라 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법이 제공되는데, 상기 방법은 텍스트 문서 를 수신하는 단계; 토픽 모델을 사용하여 상기 텍스트 문서 내 포함된 단어들에 대한 표현(representation)을 결정하는 단계; 상기 토픽 모델에 포함된 감성 사전(sentiment prior)에 기초하여 상기 결정된 표현을 측정하는 단계; 및 상기 측정된 표현에 기초하여 상기 텍스트 문서의 토픽을 결정하는 단계를 포함한다. 일실시예에서, 상기 텍스트 문서는 네트워크에 연결된 서버로부터 수신하는 것을 특징으로 한다. 일실시예에서, 상기 결정된 표현은 의미론적 공간(semantic space)에서 워드 벡터인 것을 특징으로 한다. 일실시예에서, 상기 토픽 모델에 포함된 상기 감성 사전은, 정규화기(regularizer)를 사용하여 분산된 표현에 기초해 학습되는 것을 특징으로 한다. 일실시예에서, 상기 감성 사전(prior)이 학습되는 것은, 소정의 오차값 이내의 워드 벡터를 가지는 표현을 동일 한 감성 사전으로 결정하는 상기 정규화기(regularizer)를 사용하여 분산된 표현에 기초하여 학습되는 것을 특 징으로 한다. 일실시예에서, 상기 감성 사전이 학습되는 것은, 워드 세트를 수신하는 단계; 상기 워드 세트에 기초해서 제 1 워드에 대한 가장 이웃한 워드 세트를 결정하는 단계; 상기 제 1 워드에 대한 표현을 결정하되, 상기 결정된 표 현은 의미론적 공간에서 워드 벡터인 것을 특징으로 하고; 상기 결정된 표현과 상기 가장 이웃한 워드 세트를 사용하여 감성에서 상기 제 1 워드가 발생하는 확률을 측정함에 의해 상기 정규화기의 정규화 계수를 결정하는 단계; 상기 결정된 정규화 계수에 기초하여 상기 정규화기를 정의하는 단계; 상기 정규화기를 사용하여 상기 가 장 유사한 워드 벡터를 가지면서 상기 가장 이웃한 워드 세트에 포함된 워드를 상기 제 1 워드와 동일 감성으로 결정하는 단계; 상기 동일 감성 결정에 따라 상기 제 1 워드에 대한 표현을 분산시키는 단계; 및 상기 분산된 표현을 사용하여 상기 감성 사전을 계산하는 단계를 포함한다.일실시예에서, 상기 가장 이웃한 워드 세트를 결정하는 것은 코사인 유사도(cosine similarity)에 기초하여 상 기 제 1 워드에 대하여 상기 워드 세트 내의 워드 벡터가 상기 제 1 워드의 워드 벡터와 가장 근접한 상기 워드 벡터인지를 판별하여 결정하는 것을 특징으로 한다. 일실시예에서, 상기 계산된 감성 사전(prior)을 사용하여 상기 텍스트 문서 중 적어도 일부 문서의 저자의 속성 을 예측하는 단계를 포함하되, 상기 저자의 속성은 상기 저자의 위치, 성별 및 나이 중 적어도 하나를 포함하고, 및 상기 예측된 저자 속성에 기초하여 상기 감성 사전(prior)을 업데이트하는 단계를 포함한다. 일실시예에서, 상기 표현을 측정하는 것은 상기 토픽 모델의 가능성의 최대화를 수행하되, 상기 토픽 모델의 가 능성의 최대화는 상기 정규화 계수를 업데이트하는 단계; 및 상기 갱신된 정규화 계수를 가지는 정규화기를 사 용하여 상기 감성 사전을 업데이트하는 단계를 포함한다. 일실시예에서, 상기 감성 사전(prior)은 워드 사전(dictionary)으로부터 추출된 미리 정의된 사전값(prior value)을 가지는 것을 특징으로 한다. 본 개시에 따라 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 장치가 제공되는데, 상기 장치는 메모리; 텍 스트 문서를 수신하는 입출력 인터페이스; 및 프로세서를 포함하고, 상기 프로세서는 상기 수신한 텍스트 문서 를 상기 메모리에 저장하도록 제어하고, 토픽 모델을 사용하여 상기 텍스트 문서 내 포함된 단어들에 대한 표현 (representation)을 결정하고, 상기 토픽 모델에 포함된 감성 사전(sentiment prior)에 기초하여 상기 결정된 표현을 측정하고, 상기 측정된 표현에 기초하여 상기 텍스트 문서의 토픽을 결정한다. 본 개시에 따라 감성 분석에 의해 텍스트 문서의 토픽을 결정하는 방법을 수행하는 명령을 포함하는 컴퓨터 가 독 기록 매체가 제공되는데, 상기 컴퓨터 가독 기록 매체는 텍스트 문서를 수신하는 단계; 토픽 모델을 사용하 여 상기 텍스트 문서 내 포함된 단어들에 대한 표현(representation)을 결정하는 단계; 상기 토픽 모델에 포함 된 감성 사전(sentiment prior)에 기초하여 상기 결정된 표현을 측정하는 단계; 및 상기 측정된 표현에 기초하 여 상기 텍스트 문서의 토픽을 결정한다."}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면 워드 임베딩(word embedding) 공간(space) 내에서 감성 사전(sentiment prior)이 학습된다. 이를 통해 측면-관련(aspect-related) 감성 단어를 발견할 수 있고 좀더 향상된 자연어 분류가 가능하다."}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서 \"워드\"와 \"단어\"는 동일한 의미로 사용된다. 아래에서는 첨부한 도면을 참고하여 실시예들에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자 가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형식으로 구현될 수 있으 며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 1은 본 개시의 일실시예에 따른 머신 러닝 워크플로우(machine learning workflow)를 보여주는 도면이다. 도 1에 따르면, 머신 러닝 워크플로우의 1단계는 수집(acquisition) 단계이다. 머신 러닝을 하기 위해서는 기계(machine)에 학습시켜야 할 데이터가 필요하다. 자연어 처리(natural language processing)의 경우 자연어 데이터를 코퍼스(corpus)라고 부른다. 코퍼스는 조사나 연구 목적에 의해서 특정 도메인으로부터 수집된 텍스트 의 집합을 의미한다. 코퍼스, 즉, 텍스트 데이터의 파일 형식은 txt, csv, xml 파일 등 다양하며 그 출처도 음 성 데이터, 웹 수집기를 통해 수집된 데이터, 영화 리뷰 등으로 다양하다. 웹 수집기를 통해 데이터를 수집할 때는 데이터를 크롤링(crawling)하여 수집한다. 1단계를 통해 데이터가 수집되었다면 2단계는 데이터를 점검(inspection)하고 탐색(exploration)하는 단계이다 . 이 단계에서는 데이터의 구조, 노이즈 데이터, 머신 러닝 적용을 위해서 데이터를 어떻게 정제 (cleaning)해야 하는지를 결정한다. 이 단계는 탐색적 데이터 분석(exploratory data analysis, EDA) 단계라고 도 하는데, 이 단계에서는 독립 변수(independent variables), 종속 변수(dependent variables), 변수 유형 (type of variables), 변수의 데이터 타입(data type of variables) 등을 점검하며 데이터의 특징과 내재하는 구조적 관계를 알아내는 과정이다. 3단계는 전처리(preprocessing) 및 정제(cleaning)과정이다. 이 단계는 토큰화, 정제(cleaning), 정규화 (normalization), 불용어 제거(removal of stopwords) 등이 포함된다. 4단계는 모델링(modeling) 및 학습(training)과정이다. 전처리(preprocessing)가 끝났다면, 머신 러닝에 대한 코드를 작성하는 모델링 단계가 시작된다. 적절한 머신 러닝 알고리즘을 선택하여 모델링이 끝났다면 전처 리가 완료된 데이터를 머신 러닝 알고리즘을 통해 기계에게 학습(training)시킨다. 기계가 데이터에 대한 학습 을 마치고 난 후 학습이 제대로 되었다면 그 후에 기계는 사용자가 원하는 태스크(task)인 기계번역, 음성인식, 텍스트 분류 등의 자연어 처리 작업을 수행할 수 있게 된다. 5단계는 평가(evaluation)단계이다. 기계가 학습을 완료하였으며 사용자는 테스트용 데이터로 모델링된 코 드의 성능을 평가한다. 평가 방법은 기계가 예측한 데이터가 테스트용 데이터의 실제 정답과 얼마나 가까 운지를 측정하는 방법을 취한다. 만일 평가 결과가 만족스럽지 못하면 제4단계가 재수행되고 재평가가 이루어진 다. 마지막 단계는 배포(deployment)단계이다. 평가 단계에서 기계가 성공적으로 학습된 것으로 판단되면 완성 된 모델이 배포된다. 감성 분석에서 감성 스코어(sentiment score)는 감성 극성(sentiment polarity)의 좀더 정밀한(precise) 표현 (representation)이다. 감성 스코어는 단순히 +1이 긍정적, -1이 부정적, 0이 중립적이라고만 판단하게 표시할 수도 있고, 긍정적인 정 도를 1~5, 긍정적인 정도를 -1~-5와 같인 뎁스 가중치를 더 줄 수도 있다. 이와 같이 +1, -1, 0과 같은 값을 감 성 레이블이라고도 한다. 감성 분석의 보통 첫번째 단계는 프리-프로세싱(pre-processing)이다. 프리-프로세싱에는 텍스트의 노이즈를 줄 이기 위한 다양한 기술이 적용된다. 프리-프로세싱에 일반적으로 적용되는 기술로는 숫자 제거(remove numbers), 어간추출(stemming), 품사 태깅(part of speech tagging), 구두점 제거(remove punctuation), 소문자화(lowercase), 및 불용어(stopwords) 제거 등이 있다. 토픽 모델링은 문서 집합에서 토픽을 찾아내는 프로세스를 말한다. 토픽 모델링은 검색 엔진이나 고객 민원 처 리와 같이 문서의 주제(topic)를 알아내는 것이 중요한 응용에서 사용된다. 토픽 모델링은, 대용량 텍스트 수집 의 비지도 분석(unsupervised analysis)을 다루는 다수의 애플리케이션을 위해 선택되는 모델이 되었다. 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)은 토픽 모델링의 대표적인 알고리즘이다. LDA는 문서 들이 토픽들의 혼합으로 구성되어 있으며, 토픽들은 확률 분포에 기반하여 단어들을 생성한다고 가정한다. 데이 터가 주어지면, LDA는 문서가 생성되던 과정을 역추적 한다. 토픽 모델링의 중요한 응용은 감성 분석 분야이다. 최근 토픽 모델링은 측면기반의 의견 마이닝(aspect-based opinion mining)에 성공적으로 이용되고 있다. 토픽 모델링은 리뷰(텍스트) 및 다른 감성 관련 데이터세트 (datasets)에서 비지도 방식으로 감성이 포함된 잠재 토픽 측면(aspect)을 식별할 수 있다. 여기서 측면 혹은 양상(aspect)은 어느 제품의 한가지 측면과 같은 것으로서, 예를 들면 데스크탑 컴퓨터에서 하나의 측면(aspect)은 전체 디자인(overall design), 배터리, 스크린 및 CPU 라고 할 수 있다. 최근 연구는 일반적으로 리뷰에서 언급되는 제품의 속성(attribute)이나 특성(feature)을 측면(aspect)으로 정 의한다. 또한 제품의 속성이나 특성은 일관성있는(coherent) 토픽이나 측면으로 분류될 수 있다. 예를 들어, ' 컵케익(cupcake)'과 '스테이크'는 음식점에서 음식('food') 토픽의 일부이다. 감성 분석은 제품, 서비스, 이베트, 사람 혹은 아이디어에 대한 일련의 글(a pieces of writings) 혹은 의견 - 예를 들어 제품 리뷰, 영화 리뷰, 블로깅, 포럼, 트윗 등 - 이 긍정적(positive)인지, 부정적(negative)인지 혹 은 중립적(neutral)인지를 판단하는 과정이다. 감성 분석(sentiment analysis)은 마케팅 뿐만 아니라 과학 리서치에도 중요한 이슈로 떠오르고 있다. 제품 판 매자는 제품에 대한 소비자의 평가를 빠르게 관찰하고 싶을 때 감정 분석을 이용할 수 있다. 감성 분석을 다루는 토픽 모델은 일반적으로 개별 단어에 대한 감성 레이블을 포함한다. JST나 역 JST(Reverse JST), ASUM, USTM 과 같은 토픽 모델은 어떤 토픽에서 개별 단어들에 대한 감성 사전(prior)을 셋팅하기 위해 기존에 존재하는 감성 단어 사전을 이용한다. 다른 접근법으로 감성 단어의 씨드(seed) 사전(dictionary)을 시 작한 다음 기대값-최대화 접근법(expectation-maximization approach)으로 새로운 감성 사전(prior) 베타(β) 를 학습시키는 방법도 제안되고 있다. 이러한 접근법은 새로운 감성 단어, 특히 사전에 리스트할 수 없었던 측면-관련 감성 단어를 발견할 수 있도록 하며 다른 측면에서 동일한 단어에 대해 다른 감성 사전(prior)을 가지 며, 감성 분류를 대체적으로 개선하는 것으로 나타난다. 한편, 최근에는 분산 단어 표현(distributed word representation)의 발전이 현대의 자연어 처리에도 발전을 가 져왔다. (Yoav Goldberg. 2015. A primer on neural network models for natural language processing. CoRR, abs/1510.00726.) 이 접근법에서 단어(words)는 의미론적 기하학 공간에서 의미론적(semantic) 관계를 캡처하기 위해 유클리드 공간에 삽입된다. 또, 텍스트 분류, 감성 어휘 추출, 품사 태그 지정, 구문 분석 등을 포함한 수 많은 자연 언어 처리 문제에 분산 단어 표현이 적용된다. 특히 워드 임베딩에 대한 장/단기 메모리 (LSTM) 네트 워크는 감성 분석에 성공적으로 적용되어 왔다. (Xin Wang, Yuanchao Liu, Chengjie Sun, Baoxun Wang, and Xiaolong Wang. 2015. Predicting polarities of tweets by composing word embeddings with long short-term memory. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1343-1353, Beijing, China. Association for Computational Linguistics.) 토픽 모델과 단어 벡터를 결합하는 여러 접근법, 예를 들어 Cao et al. 의 신경 토픽 모델 및 Yang et al.(2015a)의 가우스 혼합 토픽 모델이 제안된 바 있지만, 이들은 감성 기반 토픽 모델까지는 확장되지 않았다. (Ziqiang Cao, Sujian Li, Yang Liu, Wenjie Li, and Heng Ji. 2015. A novel neural topic model and its super-vised extension. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA., pages 2210-2216.) (Min Yang, Tianyi Cui, and Wenting Tu. 2015a. Ordering-sensitive and semantic-aware topic modeling. CoRR, abs/1502.0363.) 감성 분석에 대한 측면 기반 접근법(aspect-based approach)은 감성 극성을 예측하기 위해 학습된 분류자 (classifier)에 의해 보여지는 사전 정의되고 보통 수동으로 구성된 어휘 또는 단어를 포함하는 어구를 추출한 다. 이 작업들은 일반적으로 느낌(\"행복\", \"실망\")을 표현하는 감성 단어와 특정 사물이나 측면에 대한 감성을 표현 하는 평가 단어(\"완벽\", \"끔찍한\")를 구분한다. 이러한 단어는 기존에 알려진 사전에서 나오지만 토픽 모델은 개별 단어의 감성을 전체 텍스트의 전체 판단과 특정 측면의 개별 평가로 결합해야 한다. 오피니언 마이닝 (opinion mining)의 최근 개관에 따르면, 감성 어휘집(sentiment lexicon)은 대부분의 방법에서 핵심적인 역할 을 한다. 최근에는 여러 주제 모델이 제안되어 감성 분석에 성공적으로 사용되고 있다. LDA (Latent Dirichlet Allocation)와 그 확장 (Lin et al., 2012, Yang et al., 2015b, Lu et al., 2011)에 기초한 확률론적 토픽 모 델은 감성에 대한 문서-특화 분포가 있음을 가정하는데, 이는 감성이 문서에 보통 기록되어 있고 토픽 모델의 사전(prior)은 어휘집(lexicon)에 기반하기 때문이다. (Chenghua Lin, Yulan He, Richard Everson, and Stefan Ruger. 2012. Weakly supervised joint sentiment-topic detection from text. IEEE Transactions on Knowledge and Data Engineering, 24:1134 -1145.) (Zaihan Yang, Alexander Kotov, Aravind Mohan, and Shiyong Lu. 2015b. Parametric and non-parametric user-aware sentiment topic models. In Proceedings of the 38-th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 413-422. ACM.) (B. Lu, M. Ott, C. Cardie, andB.K. Tsou. 2011. Multiaspect sentiment analysis with topic models. Data Mining Workshops (ICDMW), 2011 IEEE 11thInter-national Conference, pages 81- 88.) 도 2a 와 도 2b는 각각 JST 모델 및 RJST 모델을 도시한 것이다. JST(Joint Sentiment Topic) 및 RJST(Reverse Joint Sentiment Topic)는 모두 LDA의 감성 수정 모델이라고 할 수 있다. JST는 토픽은 문서의 감성 분포 qd에 의존하고 단어는 감성-토픽 쌍에 따라 조건적으로 생성된다는 가 정 하에 제안된 모델이고, RJST는 감성은 문서의 토픽 분포에 의거해서 조건적으로 생성된다는 가정을 하는 모 델이다. ASUM(Aspect and Sentiment Unification Model)은 동일한 감성을 가지는 하나의 토픽으로부터 문장 내의 모든 단어가 생성되는 모델이다. 토픽 - 리뷰로부터의 일 측면 - 은 감성의 문장 분포(distribution)로부터 생성된다. ASUM은 JST를 비롯해서 지도된 분류자(supervised classifiers) 및 다른 모델에 비해 향상된 성능을 보여준다. USTM(User-Aware Sentiment Topic Model)은 토픽과 감성에 사용자 메타데이터를 통합하는 모델이다. 이 모델에 서 토픽은 문서의 태그에 의존하며 단어는 잠재 된 토픽, 감성 및 태그에 따라 달라진다. USTM은 리뷰의 감성 예측에 있어 JST 및 ASUM에 비해 상당한 개선된 성능을 제공한다. 측면-기반 감성 분석을 위한 토픽 모델은 거의 항상 감성 단어의 미리 정의 된 사전(dictionary)을 가정하는데, LDA 모델에서 이 미리 정의된 사전이라는 정보를 단어 - 토픽 분포에 대한 사전(prior) β에 통합시킨다. 대칭 사전(symmetric prior)을 가지는 모델에 비해 문서 별 토픽-기반 감성 비례에 대한 비대칭 디리클레(Dirichlet) 사전(prior)이 분류에 있어서 더 향상된 성능을 보여주고 있음이 발견되다. 투투발리나와 니콜렌코는 반지도(semi-supervised) 방식에 따라 개별 단어에 대한 감성 레이블의 자동 업 데이트에 대한 새로운 접근법을 제안하는데, 먼저 기대값-최대화에 기초한 최적화에 따른 작은 씨드 사전(small seed dictionary)으로부터 본 방식은 시작한다. 기대값-최대화(EM) 알고리즘(이하 \"EM 알고리즘\" 혹은 \"EM\")은 관측되지 않는 잠재변수에 의존하는 확률 모델에서 최대가능도(maximum likelihood)나 최대사후확률(miximum a posteriori)을 갖는 모수의 추정값을 찾는 반복적인 알고리즘이다. (Elena Tutubalina and Sergey I. Nikolenko. 2015. Inferring sentiment-based priors in topic models. In Proc. 14th Mexican International Conference on Artificial Intelligence, volume 9414 of Lecture Notes in Computer Science, pages 92- 104.) EM 알고리즘은 기계 학습과 컴퓨터 비전의 데이터 클러스터링에 자주 사용된다. EM 알고리즘에서 필터링과 평활 화는 기대값 단계(E-step)와 최대화 단계(M-step)이라고 하는 두 단계를 반복함으로써 일어난다. EM 알고리즘의 각 기대값 단계(E-step)에서 감성 사전(βkw)은 코퍼스에서 감성 레이블 k과 함께 생성된 단어의 수 w에 비례하 여 업데이트된다. 토픽 모델에서 감성 사전(sentiment prior) β를 학습시키는 것은 사전(prior)을 최적화하기 위한 노력의 일환 으로 간주된다. 관련된 작업에서, 토픽 하이퍼파라미터 α는 로그-증거(log-evidence)를 최대화하기 위해 고정- 소수점 반복(fixed-point iterations)으로 최적화된다. 이하에서는 하이퍼파라미터에 대해서 간단히 설명한다. LDA를 수행할 때 문서 집합에서 토픽이 몇 개가 존재할 지 가정하는 것은 사용자가 해야 할 일이다. 토픽의 갯수를 의미하는 변수를 k라고 하였을 때 k를 2로 하면 사 용자는 LDA에 2개의 토픽을 찾으라는 요청을 한 것이다. k 값을 잘못 선택하면 원치않는 이상한 결과가 나올 수 있다. 이와 같이 모델의 성능에 영향을 주면서 사용자가 직접 선택하는 매개변수(parameter)를 하이퍼파라미터 (hyperparameter)라고 한다. 이러한 하이퍼파라미터의 선택은 여러 실험을 통해 얻은 값일 수도 있고, 우선 시 도해보는 값일 수도 있다. Seaghdha and Teufel 는 수사학 및 토픽 언어를 조사하기 위해 베이지안 잠재 변수 모델의 하이퍼파라미 터를 사용하는데, 이 하이퍼파라미터들은 해밀턴 몬테 카를로(Hamiltonian Monte Carlo)로 샘플링한 다.(Diarmuid O Seaghdha and Simone Teufel. 2014. Unsupervised learning of rhetorical structure with untopic models. In COLING, pages 2-13.) Hong et al. 은 변화 추론(variational inference)에서 모든 파라미터를 효과적으로 학습하기 위해 기 대값-최대화 알고리즘과 몬테 카를로 샘플러를 혼합하여 사용하였다.(Liangjie Hong, Amr Ahmed, Siva Gurumurthy, Alexander J Smola, and Kostas Tsioutsiouliklis. 2012. Discovering geographical topics in the twitter stream. In Proceedings of the 21st international conference on World Wide Web, pages 769- 778. ACM.) Diao et al.는 사용자가 매기는 등급과 사전(prior) 조건부 텍스트 관찰 확률에 따른 예측 오류로 구성되는 객관적 함수를 최소화하기 위해 경사하강법(gradient descent)을 사용하였다. (Qiming Diao, Minghui Qiu, Chao-Yuan Wu, Alexander J Smola, Jing Jiang, and Chong Wang. 2014. Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars). In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 193-202. ACM.) Li et al.는 텍스트 토픽 분포를 사용하는 사전(prior) 및 기타 파라미터를 최적화하는 지도된 사용자-항목 기 반 토픽 모델을 구성하였다.(Fangtao Li, Sheng Wang, Shenghua Liu, and Ming Zhang. 2014. Suit: A supervised user-item based topic model for sentiment analysis. In Twenty-Eighth AAAI Conference on Artificial Intelligence.) 이 모델에서 등급을 예측하기 위해 사용자 및 항목 잠재 계수를 채용하였다. 지도된 토픽 모델은 본 개시에서는 관찰된 레이블로 고려되지는 않겠지만 향후 작업에서는 가능성있는 방향으로 고려된 다. 마지막으로, 분포 단어 표현, 즉, 사전(dictionary)에서 발생하는 각각의 단어를 유클리드 공간에 매핑하는 모 델이 본 개시에서 사용된다. 즉, 유클리드 공간에서의 기하학적 관계와 같이 단어 사이의 의미론적 관계를 캡처 하는 것을 시도한다. 일반적으로 개별 단어에 대한 원-핫(one-hot) 표현으로 어휘를 구성하고 각 단어는 각자의 차원에 해당하도록 하며, 표현(representation)은 기본적으로 차원 감소 문제로 시작하는 개별 단어에 대해 학 습된다. (Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013, Distributed representations of words and phrases and their composi-tionality. CoRR, abs/1310.4546.) 원-핫(one-hot) 표현은 일정 단위의 비트 구성에서 오직 하나의 값 만을 '1'로 셋팅하고 나머지는 '0'으로 셋팅 하는 표현 방식을 말한다. 이를 위해 일반적으로 하나의 숨겨진 레이어(hidden layer)가 있는 모델을 사용하여 여러 선행하는 단어로 된 윈도우를 기반으로 다음 단어를 예측한다. 그러면 숨겨진 계층에서 학습된 표현은 단어의 특징(feature)으로 간 주된다. 토픽 모델을 구성하기 위해 분산된 워드 표현을 사용하는 여러가지 시도가 있었다. Cao et al. 에 의해 개발된 신경 토픽 모델은 문서-토픽 임베딩과 함께 n-gram 임베딩을 학습시킴으로써 토픽-워드 및 문서-토픽 분 산을 모델링한다. (Ziqiang Cao, Sujian Li, Yang Liu, Wenjie Li, and Heng Ji. 2015. A novel neural topic model and its super-vised extension. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA., pages 2210-2216.) Yang et al.은 토픽을 의미 공간(semantic space)에서 가우시안 클러스터로서 모델링하여 토픽 모델을 가우시안 혼합으로 만들었다. (Min Yang, Tianyi Cui, and Wenting Tu. 2015a. Ordering-sensitive and semantic-aware topic modeling. CoRR, abs/1502.0363.) 본 개시에 따르면 워드 임베딩 공간(space) 내에서 감성 사전(sentiment prior)이 학습된다. 이를 통해 좀더 측 면-관련 감성 단어를 발견할 수 있고 좀더 향상된 자연어 분류가 가능하다. 워드 임베딩(word embedding) 혹은 단어 임베딩은 단어를 벡터로 표현하는 대표적인 방법으로서 주로 희소 표현 (sparse representation)에서 밀집 표현(dense representation)으로 변환하는 것을 의미한다. 신경 토픽 모델과는 달리, 본 개시에서는 기존의 접근법을 감성-기반 토픽 모델링에 보다 근접하게 매칭하는 접 근법이 제공된다. 이를 위해 이미 존재하는 미리 훈련된 워드 임베딩이 사용되며 이 워드 임베딩은 감성 분류를 개량하는 데 사용된다. 첫째, 이 접근법은 매우 큰 코포라(corpora)에서 학습되고, 어떤 감성 관련 데이터 세트가 제공할 수 있는 것보 다 훨씬 많은 다른 언어 샘플을 포함하는 워드 임베딩을 사용하게 한다. 둘째, 이 접근법은 실제 상황에서 적용 하고 확장하기가 더 쉽다. 왜냐하면, 영어의 경우에는 Wikipedia와 같은 거대한 코포라에 대해 학습된 고품질 워드 임베딩을 다운로드 할 수 있으며 다른 언어의 경우 word2vec와 같은 기존 라이브러리로 워드 임베딩을 학 습시킬 수 있다. 본 개시에 따르면, 워드 임베딩 (word embedding)에 기초한 사전(priors)들로 감성 토픽 모델을 트레이닝 함으 로써 토픽 모델 및 분산 표현의 강점을 결합하는 것이 제안된다. 기본적인 아이디어는 각 단어에 대해 독립적으 로 사전(prior) β를 학습시키는 대신, 상당히 높은 정도로 유사하면서 상호 교환 가능한 단어까지 자동으로 확 장되는 의미론적 공간에서 의미론적으로 일관성(coherent) 있는 단어에 기초하여 감성 사전이 학습된다. 이러한 접근법을 사용하면 학습된 감성 사전을 상당한 정도로 확장하고 감성 분류를 향상시킬 수 있다. 또한, 예를 들 어 LSTM에 의해 제공되는 단일의 통합된 감성 예측 대신, 이 접근법은 감성 평가에 대해 보다 상세하고 쉽게 해 석 가능한 관점을 제공하는, 리뷰에서의 개별적인 측면에 대해 구체적인 긍정 및 부정 단어를 산출해 낸다. 본 개시는 분산된 표현에 기초하여 상호 교환 가능한 단어에 대한 감성 사전(prior)을 자동으로 갱신하는 기술 을 제공한다. 실험적 평가에 따르면 이 기술은 미리 정의된 사전(prior)에 기초하여 토픽 모델에 대한 사용자 속성의 예측 및 감성 분류를 향상시키고 개별 단어에 대한 감성 사전(prior)을 업데이트하는 것을 모델링한다. 토픽의 정성 분석(qualitative analysis) 결과는 업데이트된 사전(prior)을 가진 제안된 본 모델이 일관된 토픽 을 정확하게 찾을 수 있음을 보여준다. 또한, LDA 확장에서 감성 사전(prior)과 분산된 단어 표현 간의 상호 작 용을 제공할 수 있다. 또한, 분산된 단어 표현을 다른 사전(prior)에 통합하는 것이 가능하다. 본 개시의 일실시예에 따라, 분산된 표현에 기초하여 감성 사전(prior)을 갖는 토픽 모델링 방법이 제시된다. 본 방법에 따르면 토픽 모델에 리뷰(텍스트 문서)를 입력하고, 상기 리뷰에서 각각의 단어에 대한 표현 (representation)을 결정하되, 상기 표현은 의미론적 공간에서 단어 벡터이고, 상기 리뷰에 해당하는 토픽을 결정하기 위해 상기 감성 사전(prior)을 사용하여 상기 표현을 측정하되, 상기 토픽 모델은 정규화기 (regularizer)를 사용하여 분산된 표현에 기초해 학습된 감성 사전을 포함하고, 상기 정규화기(regularizer)는 유사한 단어 벡터를 가지는 단어에 대해서 동일한 감성을 정의한다. 각각의 감성 사전(prior)은 유사한 단어 벡 터를 가지는 단어들에 대해서는 동일한 것을 특징으로 한다. 여기서 유사한 단어 벡터는 서로 소정의 오차 범위 값 내에 있는 것을 의미할 수 있다. 단어 벡터의 유사도를 판별하기 위해 코사인 유사도(cosine similarity) 방 법을 사용할 수도 있다. 본 개시의 또 다른 일실시예에서, 감성 사전이 학습되는 것은, 워드 세트를 수신하는 단계, 상기 워드 세트에 기초해서 제 1 워드에 대한 가장 이웃한 워드 세트를 결정하는 단계, 상기 제 1 워드에 대한 표현을 결정하되, 상기 결정된 표현은 의미론적 공간에서 워드 벡터인 것을 특징으로 하고, 상기 결정된 표현과 상기 가장 이웃한 워드 세트를 사용하여 감성에서 상기 제 1 워드가 발생하는 확률을 측정함에 의해 상기 정규화기의 정규화 계수 를 결정하는 단계, 상기 결정된 정규화 계수에 기초하여 상기 정규화기를 정의하는 단계, 상기 정규화기를 사용 하여 상기 가장 유사한 워드 벡터를 가지면서 상기 가장 이웃한 워드 세트에 포함된 워드를 상기 제 1 워드와 동일 감성으로 결정하는 단계, 상기 동일 감성 결정에 따라 상기 제 1 워드에 대한 표현을 분산시키는 단계, 및 상기 분산된 표현을 사용하여 상기 감성 사전을 계산하는 단계를 포함하는 것을 특징으로 한다. 본 개시의 또 다른 일실시예에서, 감성 사전(prior)을 학습시키는 것은 상기 정규화기를 사용하여 분산된 표현 들에 기초하여 학습된 감성 사전(prior)을 사용하여 상기 토픽 모델에 의해 사용자 속성을 예측하는 단계를 포 함하되, 상기 사용자 속성은 사용자의 위치, 성별 및 나이 중 적어도 하나를 포함하고, 상기 예측된 사용자 속 성에 기초하여 감성 사전(prior)을 업데이트하는 단계를 포함하는 것을 특징으로 한다. 본 개시의 또 다른 일실시예에서, 감성 사전(prior)을 사용하여 표현을 측정하는 것은, 토픽 모델 가능성의 최 대화(maximum likelihood)를 포함하되, 이 최대화는 정규화 계수를 업데이트하고, 상기 업데이트된 정규화 계수 를 가지는 정규화기를 사용하여 감성 사전(prior)을 업데이트하는 것을 포함한다. 본 개시의 일실시예에 따라 분산된 표현에 기초한 감성 사전(prior)을 갖는 토픽 모델링을 위한 장치를 제공한 다. 상기 장치는 프로세서; 및 상기 토픽 모델과 상기 프로세서로 하여금 수행하도록 하는 명령을 저장하는 메 모리를 포함하되, 상기 명령은, 상기 토픽 모델에 리뷰를 입력하고, 상기 리뷰 내의 각 워드에 대한 표현을 결 정하되, 여기서 상기 표현은 의미론적 공간에서의 워드 벡터 들이고, 상기 토픽 모델에 의해, 상기 리뷰에 대응 하는 토픽을 결정하기 위해 감성 사전(prior)을 사용하여 표현들을 측정하되, 여기서 상기 토픽 모델은 정규화 기를 사용함으로써 분산된 표현에 기초해 학습된 감성 사전(prior)을 포함하고, 상기 정규화기는 유사한 워드 벡터를 갖는 워드에 동일한 감성을 정의하고, 각각의 감성 사전(prior)은 유사한 워드 벡터를 가지는 워드에 대 하여 동일한 것을 특징으로 한다. 먼저, 이하에서는 의미론적 공간(semantic space)에서 분산으로서의 감성 사전(prior)에 대해서 설명한다. 이전에는 감성 사전(prior)은 사전(dictionary)으로부터 뽑아낸 미리 정의된 사전값(prior value) 또는 EM 알고 리즘의 E-step(E-단계)에서 별도로 학습되어야 하는 감성 사전(prior)의 독립값들 βkw의 집합으로 모델에 도입 되었다. 본 개시에서는 감성 사전(prior)βkw 기본 모델은 변경된다. 모든 감성 값(혹은 감성 레이블) k 및 모든 단어 w 에 대해 완전히 독립적인 사전(prior)값 βkw 대신에, 워드 임베딩의 의미론적 유클리드 공간에서 서로 유사한 단어들에 대해 βkw가 유사해야 한다고 가정한다. 모든 단어 w에 대해 가장 가까운 이웃들의 집합(세트) Nei (w)가 발견된다고 가정해본다. 예를 들어, 이 집합 Nei (w)는 클러스터링 모델에서 비롯되거나 상당히 좋은 의 미론적 매칭을 제공하도록 튜닝된 거리를 가지는 가장 가까운 임계값으로부터 비롯될 수도 있다. 거리 d (w, w')에 대한 유사성 임계치 e가 소정의 임계치보다 높으면, 의미론적 매칭은 양호한 것이다. 거리 d(w, w')는 의 미론적 공간에서 w와 w'에 대한 워드 벡터 간의 거리이다. 감성 사전(prior)을 학습하기 위해서 EM 알고리즘이 사용된다. 기대값 단계(E-step)에서, 단어 w가 코퍼스에서 감성 값 k를 가지고 발생하는 확률 pkw는 깁스 (Gibbs) 샘플링 프로세스의 카운터 nkw로 추정된다. 그 다음, w ∈Nei(w)에 대하여 pkw = pkw '를 캡처하는 pkw의 값에 새로운 정규화기가 추가된다. 즉, 매우 유사한 벡터를 갖는 단어가 모든 확률로 동일한 감성을 가져야 한다. 정규화기는 텍스트 데이터를 정규 표현식으로 바꾸는 것 을 말한다. 최종 최적화 문제에서, 모델의 로그 가능성(log-likelihood)은 E-step에서 증가된다. 이 경우 정규화기 R (p)를 가지는 다항 분포 log L = 는 이 가정을 뒷받침한다. 최적화의 편의를 위해 정규화기 R (p)는 다음과 같이 대수 형태로 표현된다. 수학식 1"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "E-step에서 극대화(최대화)는 다음과 같이 이루어진다. 수학식 2"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 α는 정규화 계수이고 d(w, w')는 모든 w에 대하여 조건하에서 의미론적 공간에서 w와 w'에 대한 워드 벡터 간의 거리이다. 거리는 유클리드 거리와 코사인 거리 일 수 있다. 이것은 log pkw에 대한 2차원 최적화 문제이므로, 기존의 2차 옵티마이저로 해결할 수 있다. 다른 가능한 단어 벡터 정규화기 형태가 사용될 수도 있다. 일단 pkw가 발견되면, 가 셋팅될 수 있다. 를 Nei (w)에 기초하여 고정된 사전 βkw의 최대 합으로 정규화하기 위해서는 토픽 모델은 작은 파라미터 βkw를 갖는 희소성 - 유도 사전(prior) 분포를 사용하 는 것이 유익하다. 도 3은 본 개시의 일실시예에 따라 분산 표현에 기초한 감성 사전(prior)을 사용하여 토픽 모델링을 하는 방법 을 도시하는 흐름도이다. 토픽 모델링은 정규화기 R(p)를 사용하여 분산된 표현에 기초하여 학습된 감성 사전(prior) βkw를 포함하는 토 픽 모델에 의해 수행된다. 정규화기 R(p)는 유사한 단어 벡터를 갖는 단어 w에 대해 동일한 감성 값 k를 정의한 다. 이전의 각 감성 사전 βkw는 유사한 단어 벡터를 갖는 단어 w에 대해 동일하다. 301 단계에서 토픽 모델을 수행하는 장치는 리뷰(텍스트 문서)를 수신한다. 일 실시예에 따라, 토픽 모델을 수행하는 장치는 상기 텍스트 문서를 네트워크에 연결된 서버들로부터 수신할 수 있다. 서버들은 웹 서버일 수 있으며 다양한 리뷰 텍스트 문서를 저장하고 온라인으로 제공한다. 303 단계에서 토픽 모델은 리뷰에서 각각의 단어 w에 대하여 표현(representation)을 검출하고 결정한다. 표현 은 의미론적 공간에서 워드 벡터를 의미한다. 305 단계에서 토픽 모델은 감성 사전(prior)βkw를 사용하여 의미론적 공간에서 워드 벡터로서 표현들이 측정된 다. 본 305 단계에서 감성 사전(prior)βkw를 사용하여 의미론적 공간에서 워드 벡터로서 표현들이 측정되는 단 계는 토픽 모델의 가능성의 최대화(maximization of likelihood)를 수행하는 단계를 더 포함할 수 있다. 이 최 대화(maximization)는 정규화기 R(p)의 정규화 계수 α를 갱신하고 갱신된 정규화 계수 α를 갖는 정규화기 R(p)를 사용하여 감성 사전 βkw를 갱신하는 단계를 포함할 수 있다. 일 실시예에서, 텍스트 문서 내의 표현들은 앞서 기술한 바와 같이 의미론적 공간에서 워드 벡터에 대응되는데, 만일 어떤 두 개의 표현에 대응되는 두 개의 워드 벡터들이 소정의 오차값 이내에서 유사한 값을 가진다고 하면 두 표현을 동일한 감성(값)으로 결정할 수 있고 각각 동일한 감성으로 결정된 두 표현에 대한 감성 사전은 동일 하다고 결정된다. 307 단계에서 상기 결정된 표현들에 기초하여 상기 리뷰에 해당하는 토픽을 결정한다. 토픽 모델은 적절한 인공 지능 수단에 기반할 수 있다도 4는 본 개시의 일실시예에 따라 토픽 모델에서 감성 사전(prior)의 학습을 예시하는 흐름도이다. 감성 사전(prior) βkw를 학습하기 위한 훈련 과정이 도 4에 도시되어있다. 301 단계에서, 토픽 모델은 단어 집 합 w를 수신한다. 이 때 장치의 입출력 인터페이스가 단어 집합 w를 수신하는 동작을 수행할 것이다. 도시되지는 않았지만 장치의 프로세서가 아래 동작 401 단계 내지 411 단계를 수행할 것이다. 401 단계에서, 토픽 모델을 수행하는 장치의 프로세서는 각각의 단어 w에 대해 가장 가까운 이웃들 세트 Nei (w)를 결정한다. 403 단계에서, 프로세서에 의해 표현(representation)들은 각각의 단어 w에 대하여 의미론적 공간 내의 단어 벡 터로서 결정된다. 405 단계에서, 프로세서는 정규화기 R(p)의 정규화 계수 α를 계산함으로써 정규화기 R(p)를 정의하여 결정한다. 정규화 계수 α를 계산할 때, 각 단어 w에 대해, 특정 카운터 nkw를 갖는 감성(값) k에서 단어 w가 발생하는 확률 pkw는 표현 및 가장 가까운 이웃의 집합 Nei(w)를 사용하여 측정한다. 407 단계에서, 프로세서는 정규화기 R(p)를 사용하여 유사한 단어 벡터를 갖는 단어 w에 대해 동일한 감성(값) k를 정의하여 결정한다. 409 단계에서, 프로세서는 상기 결정에 따라 표현(representation)을 분산한다. 411 단계에서, 프로세서는 감성 사전(prior) βkw를 분산된 표현을 사용하여 계산한다. 학습 과정은, 정규화기를 사용하여 분산된 표현들에 기초하여 학습된 감성 사전(prior) βkw를 사용하여 토픽 모델에 의해 사용자 속성을 예측하는 단계 및 예측된 사용자 속성에 기초하여 감성 사전 βkw를 업데이트하는 단계를 포함할 수 있다. 사용자 속성은 사용자의 위치, 성별 및 연령 중 적어도 하나를 포함한다. 도 5는 본 개시의 일실시예에 따른 분산 표현에 기초하여 감성 사전(prior)을 갖는 토픽 모델링을 수행하는 장 치를 도시한다. 장치는 프로세서와 입출력 인터페이스 및 메모리로 구성된다. 입출력 인터페이스 는 통신을 통해 웹 서버로부터들로부터 텍스트 문서를 크롤링(crawling)해 오거나 사용자의 문서 입력을 수신할 수 있다. 텍스트 문서는 영화 감상평이나 상품평과 같은 리뷰(review)들이 될 수 있다. 입출력 인터페이 스는 장치 사용자에게 토픽 모델링에 따라 텍스트 문서들로부터 결정된 토픽을 디스플레이할 수도 있다. 프로세서는 본 개시에 따른 분산 표현에 기초하여 감성 사전(prior)을 갖는 토픽 모델링에 따라 본 개시 의 도 3과 도 4에 따른 과정을 수행하고 토픽을 결정한다. 메모리는 리뷰와 같은 텍스트 문서를 수신하면 이를 저장하고, 정규화기 계수, 감성 사전(prior) 등을 저장하고, 프로세서가 도 3과 도 4에 따른 과정을 수행 하기 위한 명령어를 저장한다. 이하에서는 데이터 세트 설정 과정에 관하여 설명하도록 한다. 본 개시의 일실시예에 따른 최적화 단계는 https://yadi.sk/d/82jgiXddsEtCG 를 통해 얻을 수 있는 여섯 개의 데이터 세트를 이용하도록 한다. 이는 일실시예에 불과할 뿐 데이터 세트는 여섯 개에 한정되는 것이 아니라 다 양한 수의 데이터 세트를 이용할 수 있다. 호텔 관련 데이터 세트는 TripAdvisor.com 으로부터의 작성자 이름을 알 수 있는 호텔 리뷰로 구성되어 있다. USTM을 적용하기 위해서, 300,000 개 이상의 리뷰로부터 리뷰 저자들의 메타 데이터가 크롤링되었는데, 리뷰 저 자들의 메타 데이터는 리뷰 저자들의 위치, 성별 및 나이를 포함하고, 리뷰 저자들은 가장 일반적인 최상위 50 개 위치(장소)에 속한 저자들을 조건으로 하여 리뷰들을 필터링하였다. 희소성(sparsity) 이슈를 피하기 위해 최상위 15개 장소 태그, 5개의 연령 태그 및 2개의 성별 태그가 고려된다. 위 링크를 통해 포함된 데이터 세트 중 아마존(Amazon) 데이터 세트는 Amazon.com (https://snap.stanford.edu/data/web-Amazon.html)으로부터 컴퓨터, 오토모티브, 및 가정용 툴(각각 AmazonComp, AmazonAuto, and AmazonTools 로 칭함)에 관한 제품 리뷰를 포함한다. 아마존 데이터 세트에 USTM을 적용하기 위해서 가장 일반적인 최상위 25개 위치를 필터링하여 리뷰 저자들의 메 타 데이터들이 크롤링되었다. 6개의 데이터 세트에 대한 리뷰 통계는 아래와 같이 표 1로 제시되어 있다.표 1"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "표 1에서 1열의 Dataset는 사용된 데이터 세트를 의미하고, #reviews 는 데이터 세트에서 레뷰의 수, voc.size 는 vocabulary 사이즈, 즉, 데이터 세트에서 특출난(unique) 단어들의 수, #tokens 는 데이터 세트에서 토근의 수, avg.len 는 데이터 세트에서 리뷰의 평균 길이를 의미한다. lang는 리뷰 작성 언어를 의미한다. 표 1의 Dataset에서 Restaurant 및 Cars 항목은 각각 Otzovik.com 및 Restoclub.ru 웹 사이트를 통해 크롤링한, 러시아 언어로 작성된 온라인 리뷰로 구성된다. 여기에는 리뷰 저자들에 대한 정보는 없다. 도 1에서 소개한 바와 같은 프리프로세싱을 수행함에 있어서, 구두점이 제거되었고, 워드 토큰은 소문자로 변환 되었고, https://pypi.python.org/pypi/stop-words를 응용하여 불용어(stopword) 역시 제거되었다. 데이터 세 트 내에서 5번 이내 사용되는 저사용 워드 역시 필터링되었다. 리뷰 내에서 30% 이상 나타나는 다출현(high- frequency) 워드도 필터링되었다. https://tech.yandex.ru/mystem/ 에서 찾을 수 있는 Mystem library를 사용 하여 러시안 텍스트에 대한 표제어 추출(lemmatization)이 적용되었다. 표 1은 각각의 데이터 세트에 대한 상세 한 정보를 제공한다. 워드 임베딩에 관해서는, 2.5 메가바이트 크기의 문서에서 대략 14기가 토큰을 가지는 러시아 언어 코퍼스 (corpus)에 대해 학습된 연속적인 Bag-of-Words(CBOW) 및 스킵 n-gram word2vec 모델이 사용되었다. 감성 정보는 비대칭 사전(prior) β를 사용하여 기술된 모델에 통합된다. 수동으로 작성된 러시아어 어휘는 1079개의 긍정적 단어와 1474개의 부정적 단어로 구성되며, 2718개의 긍정적 단어와 4911개 부정적 단어가 있는 MPQA 사전이 영어 언어를 위해 채택된다. 씨드(seed) 사전(dictionary)에서 찾을 수 없는 다른 단어 (아마도 중 립적 단어)에 대해서는 대칭 사전이 사용된다. 따라서, 감성 사전(prior)들은 중립, 긍정, 부정 세 가지 값으로 나뉘어진다. 먼저 사전(prior) β는 코퍼스의 모든 단어에 대해 βkw = 0.01로 설정된다. 단어가 씨드 감성 사 전에 속하면 감성 사전은 긍정 단어에 대해 β*w = (1, 0.01, 0.001) (긍정 1, 중립 0.1, 부정 0.001)로, 부정 단어는 β*w = (0.001, 0.01, 1)로 설정된다. 모든 모델에 대한 사후 추론(posterior inference)은 K = 10, α = 50 / K 및 γ = 0.1 인 1000 Gibbs 반복으로 수행된다. 앞선 내용에 따라 도출된 결과는 아래와 같다. 각 데이터 세트에 대해, 4개의 토픽 모델, 즉 JST, Reverse-JST(RJST), ASUM 및 USTM이 학습된다. JST, RJST, ASUM 및 USTM 학습 결과는 표 2에 나와 있다. 표 2는 표 1에 따른 데이터 세트에 대한 긍정, 부정 및 중립 레이블 통계이다. 표 2"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "표 2에서 열 \"Dataset\"는 사용된 데이터 집합, \"Label\"열의 하위 \"pos.\", \"neg.\", \"neutr.\" 열은 리뷰 데이터 세트에 대한 긍정, 부정 및 중립 레이블을 각각 나타내며 \"#token\"열의 하위 \"#pos.\", \"#neg.\"는 긍정 및 부정 의 여러 토큰을 나타낸다. 자연어 처리에서 잘 알려져 있는 바와 같이 프리프로세싱 초기 단계에서 이루어지는 것으로 토큰화가 있다. 토큰화는 주어진 코퍼스에서 워드를 토큰이라 불리는 단위로 나누는 작업이다. 보통 의 미있는 단위로 토큰을 정의한다. 예를 들어 간단히 구두점(punctuation)을 제외시키는 것이 가장 간단한 토큰화 작업이라 할 수 있다. 4개의 학습된 토픽 모델이 3개의 변형으로 비교된다. i) 최적화 없는 고정으로, ii) EM 최적화(\"+EM\"으로 표 시)로, 및 iii) 제안된 최적화 단계에 따라(\"+W2V\"로 표시) 비교된다. 감성 사전(prior)은 매 50회 반복마다 업 데이트된다. 호텔과 레스토랑에 대한 학습 세트의 20%가 정규화 계수 α를 세팅하기 위한 유효성 검증 세트로서 사용된다. 감성 사전(prior) βkw 를 학습하기 위해서 Theano library 를 사용하여 10-6 학습 레이트로 경사 하강법이 수행 된다. 두 코포라 에 대해 정규화 계수 α는 모든 데이터 세트에 대해 1.0으로 설정된다. 평가를 위해서, 테스트 목적으로 리뷰의 10%가 사용되고 나머지 90%는 토픽 모델의 학습에 사용된다. 서로 반대 극성을 가지는 단어 쌍들 사이에 코사인 유사성(cosine similarities)은 수작업으로 분석되고 러시아어에 대해 서는 0.77, 영어에 대해서는 0.72인 거리 d(w, w')에 대해 유사성 임계값 e가 선택된다. 레스토랑 데이터 세트에서, 각 리뷰는 음식, 인테리어, 서비스에 대해 0(최저) 내지 10(최고) 사이의 점수를 제 공하는 등급 세트와 관련된다. 리뷰의 평균 평점 점수가 7보다 크거나 같으면 이러한 리뷰는 '긍정' 감성으로 표시된다. 리뷰 평점 점수가 4 이하일 경우 '부정' 감성으로 표시된다. 다른 데이터 세트에서 각 리뷰는 등급이 0(최저) 에서 5(최고) 사이에 매겨지도록 한다. 이러한 리뷰는 5개의 데이터 세트로부터 등급 점수가 4보다 같 거나 크면 '긍정', 등급 점수가 2보다 같거나 낮은 경우 \"부정\" 감성으로 표시된다. 표시되지 않은 리뷰는 \"중 립\"으로 취급된다. 코퍼스의 통계는 표 2에 나와 있다. 레이블의 리뷰 조건부 확률 p(l|d)가 토픽-감성-워드 분포 φ에 기초해서 계산된다. 실험에서, 리뷰 d는 긍정 레이블의 확률 p(lpos|d)이 부정 및 중성 클래스 확률 p(lneg|d) 및 p(lneu|d)의 확률 보다 높으면 긍정으로 분류되며 부정으로 분류되는 경우는 반대의 경우이다. (p(A|B)는 B 조건 하에서의 A의 확 률을 의미한다.) ASUM, JST 및 RJST는 긍정 또는 부정 감성만을 고려하기 때문에 긍정적 혹은 부정적인 근거 사 실 레이블을 가진 리뷰를 기반으로 한 모든 모델의 성능을 평가한다. 표 3은 분류 결과를 나타낸다. 제시된 결과는 5-폴드 교차 검증(5-fold cross validation)에 근거하여 거시적으 로 평균화된다. 표 3에서 \"Model\"열은 사용된 방법, \"Hotel\", \"AmazonComputer\", \"AmazonAuto\"는 데이터 세트, 하위 열 \"P\", \"R\", \"F1\", \"Acc\"는 분류 정밀도, 분류에서의 리콜(recall), F-measure (즉 테스트 정확도), 정 확도를 각각 나타낸다.표 3"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "표 3는 실제 데이터 세트의 토픽 모델의 비교이다. 표 3에서 *와 †는 Wilcoxon signed rank test에 의해 측정 된, EM 알고리즘에 의해 최적화된 정적 βs와 βs가 적용된 해당 모델에 비해 통계적으로 유의미한 향상을 나타 낸다. 표 4"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "표 4는 RJST + W2V에 의해 자동 데이터 세트에서 탐색된 토픽을 보여준다. 몇 가지 중요한 결과가 표 3에서 도출된다. 첫째, 호텔 데이터 세트에 대한 4 가지 모델의 결과는 LDA (Latent Dirichlet Allocation)와 그 확장 (Lin et al., 2012, Yang et al., 2015b, Lu et al., 2011)에 기초한 확률론 적 토픽 모델과 높은 상관관계가 있다. 최첨단 모델인 USTM은 4가지 영어 데이터 세트에서 RJST, JST 및 ASUM보 다 더 나은 결과를 달성했다. 둘째, USTM의 경우, 결과는 USTM + W2V가 사전 정의된 감성 어휘 및 USTM + EM을 기반으로 하는 감성 사전(prior)을 가진 원래 모델보다 개선된 것을 명확하게 보여준다. JST 및 RJST의 경우 결 과가 혼합되어 있다. 실험의 절반에서 JST + W2V 및 RJST + W2V가 JST + EM 및 RJST + EM에 비해 더 높은 정확 도 및 F1 측정을 달성했다. ASUM + EM과 ASUM + W2V의 결과는 원래의 ASUM보다 약간 좋거나 나쁘지만 ASUM은 문 장의 모든 단어가 동일한 감성에서 생성되고 각 개별 단어들에 대해 감성 사전(prior)이 학습된다는 것을 전제 로 하기 때문에 결과는 타당하다고 보인다. 이하는 사용자 속성 예측에 대해서 살펴본다. LDA (Latent Dirichlet Allocation)와 그 확장 (Lin et al., 2012, Yang et al., 2015b, Lu et al., 2011)에 기초한 확률론적 토픽 모델과 유사하게, 본 개시에서는 어휘 컨텐트에 기초하여 리뷰의 사용자 속성이 예측된다. 이 목적을 달성하기 위해 사용자의 위치, 성별 및 사용자와 같은 3차원 사용자 속성이 있는 Hotel 데이터 세트 가 사용된다. 측정 방법으로는 Mean Average Precision(MAP)이 사용된다. 아래 표 5는 리뷰 작성자의 속성을 예 측하는 태스크의 토픽 모델 성취도 결과를 보여준다. 표 5"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "감성 예측 태스크와 유사하게, 제안된 최적화 USTM + W2V를 갖는 토픽 모델은 기저 모델 PLDA 및 USTM보다 우수 한 결과를 달성한 것을 알 수 있다. 이하에서는 유사도 임계치 및 정규화 계수 α의 영향에 대해서 살펴본다. 본 개시에 따르면, 분산된 표현에 기초한 감성 사전 β의 최적화가 제공된다. 의미론적 공간에서의 워드 벡터와 함수 R(w)에서의 정규화 계수 α 사이의 임계 거리의 영향을 보여주기 위해 분류 작업에서 최상의 결과를 얻은 USTM이 사용된다. 첫째, Hotel 데이터 세트에서 코사인 유사성 임계값의 효과(혹은 유효성)를 0.55에서 0.80까지 유효하게 하는 것이 제공된다. 평가 결과는 표 6에 제시되어있다. 표 6은 Hotel 데이터 세트에서 유사성 임계값 efmf 변화시킬 때 USTM+W2V의 효능을 보여준다. 표 6"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "확실히, 선택된 임계값이 작을수록, 생성된 적어도 하나의 가장 가까운 이웃을 가지는 단어의 수가 더 커진다. 이 임계값은 가장 가까운 단어의 사전(prior)을 클러스터링하는 밀도를 제어한다. |Nei(w)|≥ 1를 만족하는 고 유 단어들의 수는 임계값 e가 0.55, 0.60, 0.65, 0.72 및 0.80일 때 각각 13496, 11493, 8801, 4789 및 1177이 다. 이 결과를 토대로 여러 가지 관찰을 할 수 있다. 첫째, 최저 임계값 e = 0.55 및 e = 0.60을 갖는 USTM + W2V는 USTM보다 우수하다 (표 3 참조). 둘째로, e = 0.80 인 USTM + W2V는 E-step의 기능을 최대화하기 위해 어휘의 단지 6.45 %만을 사용하였고 표 6에서 가장 낮은 결과를 얻었다. 반면에 26.23 %를 사용하는 USTM + W2V는 가장 좋은 결과를 얻었다. 또한, AmazonTools 데이터 세트에 대하여 정규화 계수의 영향을 조사하였다. 도 6는 본 개시의 일 실시예에 따 라 정규화 계수를 변경함으로써 각 토픽 모델의 감성 예측 정확도를 보여주는 도면이다. 정규화 계수 α가 0.5 에서 1.5로 설정되면 거의 모든 모델에 대한 감성 예측 정확도(accuracy)가 최대값에 도달함을 보여준다. 그 중 에서도 USTM+W2V의 정확도가 가장 높음을 알 수 있다. 이하에서는 워드 임베딩의 비교에 대해서 살펴본다. 러시아어 텍스트에 대해 word2vec 모델을 사용하는 워드 벡터가 학습되었기 때문에, 상이한 워드 임베딩을 비교 하기 위한 일련의 실험을 수행한다. 서로 다른 파라미터 s(벡터 크기), w (로컬 컨텍스트의 길이), n (부정 샘 플링) 및 v (어휘 컷오프 : 어휘에 포함될 단어의 최소 빈도)를 가지고 https://github.com/ChenglongChen/word2vec_cbow에서 볼 수 있는 CBOW 모델의 고성능 GPU 구현을 통해 몇 가 지 워드 임베딩을 학습해 본다. 표 7은 Restaurant 데이터 세트, e=0.77을 사용한 다른 워드 임베딩에 대한 Reverse-JST 모델의 분류 결과를 보여준다. 표 7"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "일반적으로 단어 삽입 크기를 약 300까지 늘리면 결과가 좋아지는 반면 n 및 v 매개 변수는 거의 영향을 미치지 않음을 알 수 있다. USTM의 경우, 뉴스 와이어 텍스트 데이터 및 위키피디아로부터 60 억 단어에 대해 학습된, 공개적으로 입수 가 능한 글로베 (GloVe) 워드 벡터가 검사된다. 표 8에 나와 있듯이 200 차원(200d) GloVe 임베딩은 word2vec 임 베딩보다 Hotel 데이터 세트에서 약간 개선되었다. 표 8"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "표 9는 Hotel 데이터 세트에서 Glove 100d 벡터와 Glove 200d 벡터에 기초하여 최적화된 학습 이후 USTM의 감성 사전(prior)를 보여준다. 표 9에서 볼 수 있듯이 서로 다른 단어의 감성 사전(prior)을 수동으로 검색하면 사전(prior) 값이 100차원 벡 터보다 200차원 벡터에서 더 정확함을 확인할 수 있다.표 9"}
{"patent_id": "10-2019-0083893", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이하에서는 정성 분석 결과를 알아보도록 한다. 이하에서는, w2v 기반 최적화 단계를 갖는 RJST에 의해 발견된 토픽에 대한 정성 분석이 제시된다. 분산 워드 표현에 기초한 감성 특화 사전(prior) 수정의 주요 목표는 사전(prior)들이 관련있는 측면과 유사 감성을 표시 하기 위해 높은 확률을 가지도록 의미적으로 관련있는 워드에 대한 유사 사전(prior)을 계산하기 위함이다. 이 목표에 따른 결과를 분석하기 위해 표 4에서 발견되는 감성 토픽의 샘플이 리포팅된다. 특정 감성과 관련된 토 픽에 대해 상위 순위 용어가 표시된다. 표 4는 영어 및 러시아어로 표현되는 자동차 브랜드와 같은 명사(예 : volkswagen, toyota, ford)를 표현하는 리뷰로부터 의미론적으로 관련된 측면을 대부분 추출하는 RJST+W2V 모델을 나타낸다. 다음으로, 부정적 토픽은 사람들이 러시아 자동차 산업, 낡은 자동차 및 자동차 수리(부정 하위 항목 # 2 및 # 3)로 고통 받고 있음을 보 여준다. 마지막으로, RJST + W2V로 추출한 긍정 샘플에는 운전성(transmission, fast, drive gear)과 같은 특 정 측면이 포함되어 있고 반면, 중립 하위 토픽은 차의 구성(예) mirron, behind, panel, glass)이나 구매 프로 세스 (예 : money, option, to find)를 기술한다. 실시예들에 따른 상기 방법들은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨 터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같 은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함 한다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다."}
{"patent_id": "10-2019-0083893", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일실시예에 따른 머신 러닝 워크플로우(machine learning workflow)를 보여주는 도면이다. 도 2a는 JST 모델을 도시한 것이다. 도 2b는 역(reverse) JST 모델을 도시한 것이다. 도 3은 본 개시의 일실시예에 따라 분산 표현에 기초한 감성 사전(prior)을 사용하여 토픽 모델링을 하는 방법 을 도시하는 흐름도이다. 도 4는 본 개시의 일실시예에 따라 토픽 모델에서 감성 사전(prior)의 학습을 예시하는 흐름도이다. 도 5는 본 개시의 일실시예에 따른 분산 표현에 기초하여 감성 사전(prior)을 갖는 토픽 모델링을 수행하는 장 치를 도시한다. 도 6은 본 개시의 일실시예에 따라 정규화 계수를 변경함으로써 감성 예측의 정확도를 보여주는 도면이다. 이하의 설명에서, 달리 설명하지 않는 한, 동일한 도면 부호는 상이한 도면에 도시 될 때 동일한 요소에 대해 사용되며, 중복되는 설명은 생략 될 것이다."}
