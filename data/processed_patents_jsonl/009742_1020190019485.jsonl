{"patent_id": "10-2019-0019485", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0101186", "출원번호": "10-2019-0019485", "발명의 명칭": "전자 장치 및 그의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "허규호"}}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량에 포함된 전자 장치에 있어서,카메라;센서;회로(circuitry)를 포함하는 출력 인터페이스; 및상기 차량의 목적지까지의 경로 상에 존재하는 오브젝트에 대한 정보를 기초로 상기 경로에 대한 안내 정보를상기 출력 인터페이스를 통해 출력하는 프로세서;를 포함하며,상기 오브젝트에 대한 정보는, 상기 센서를 통해 획득된 상기 차량의 위치 정보 및 상기 카메라를 통해 획득된 상기 차량의 전방을 촬영한 이미지에 기초하여, 상기 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델로부터 획득되는, 전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 오브젝트는, 상기 경로 상에 존재하는 건물을 포함하고, 상기 프로세서는,상기 건물을 기초로 상기 차량의 진행 방향 및 진행 거리 중 적어도 하나와 관련된 상기 안내 정보를 출력하는,전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 학습된 모델 각각은,특정 위치에서 촬영된 이미지에 기초하여, 상기 이미지에 포함된 복수의 오브젝트 중에서 상기 특정 위치에서식별될 확률이 가장 높은 오브젝트를 판단하도록 학습된 모델인, 전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 복수의 학습된 모델 각각은,상기 경로가 분기점을 기준으로 구분된 상기 복수의 구간 각각에서 촬영된 이미지에 기초하여 학습된 모델인,전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 복수의 구간은, 상기 경로에 존재하는 분기점을 기준으로 구분되는, 전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,회로(circuitry)를 포함하는 통신 인터페이스;를 더 포함하고,공개특허 10-2020-0101186-3-상기 프로세서는,상기 경로에 대한 정보, 상기 센서를 통해 획득된 차량의 위치 정보 및 상기 카메라를 통해 획득된 상기 차량의전방을 촬영한 이미지를 상기 통신 인터페이스를 통해 서버로 전송하고, 상기 서버로부터 상기 안내 정보를 수신하여 상기 출력 인터페이스를 통해 출력하는,상기 서버는,기저장된 학습된 모델 중에서 상기 경로에 포함된 상기 복수의 구간에 대응되는 복수의 학습된 모델을판단하고, 상기 이미지를 상기 복수의 학습된 모델 중 상기 차량의 위치 정보에 대응되는 학습된 모델의 입력데이터로서 사용하여, 상기 오브젝트에 대한 정보를 획득하고, 상기 오브젝트에 대한 정보를 기초로 상기 안내정보를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,회로(circuitry)를 포함하는 통신 인터페이스;를 더 포함하고,상기 프로세서는,상기 경로에 대한 정보를 상기 통신 인터페이스를 통해 서버로 전송하고, 상기 서버로부터 상기 경로에 포함된 상기 복수의 구간에 대응되는 복수의 학습된 모델을 수신하고, 상기 이미지를 상기 복수의 학습된 모델 중 상기 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서사용하여, 상기 오브젝트에 대한 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 출력 인터페이스는, 스피커 및 디스플레이 중 적어도 하나를 포함하며,상기 프로세서는,상기 스피커 및 상기 디스플레이 중 적어도 하나를 통해 상기 안내 정보를 출력하는, 전자 장치."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "차량에 포함된 전자 장치의 제어 방법에 있어서,상기 차량의 위치 정보 및 상기 차량의 전방을 촬영한 이미지에 기초하여, 상기 차량의 목적지까지의 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델로부터 상기 경로 상에 존재하는 오브젝트에 대한 정보를 획득하는 단계; 및상기 차량의 목적지까지의 경로 상에 존재하는 오브젝트에 대한 정보를 기초로, 상기 경로에 대한 안내 정보를출력하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 오브젝트는, 상기 경로 상에 존재하는 건물을 포함하고, 상기 출력하는 단계는,상기 건물을 기초로 상기 차량의 진행 방향 및 진행 거리 중 적어도 하나와 관련된 상기 안내 정보를 출력하는,제어 방법."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 복수의 학습된 모델 각각은,공개특허 10-2020-0101186-4-특정 위치에서 촬영된 이미지에 기초하여, 상기 이미지에 포함된 복수의 오브젝트 중에서 상기 특정 위치에서식별될 확률이 가장 높은 오브젝트를 판단하도록 학습된 모델인, 제어 방법."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 복수의 학습된 모델 각각은,상기 경로가 분기점을 기준으로 구분된 상기 복수의 구간 각각에서 촬영된 이미지에 기초하여 학습된 모델인,제어 방법."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 복수의 구간은, 상기 경로에 존재하는 분기점을 기준으로 구분되는, 제어 방법."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 출력하는 단계는,상기 경로에 대한 정보, 상기 차량의 위치 정보 및 상기 차량의 전방을 촬영한 이미지를 서버로 전송하는 단계;및 상기 서버로부터 상기 안내 정보를 수신하여 출력하는 단계;를 더 포함하며,상기 서버는,기저장된 학습된 모델 중에서 상기 경로에 포함된 상기 복수의 구간에 대응되는 복수의 학습된 모델을판단하고, 상기 이미지를 상기 복수의 학습된 모델 중 상기 차량의 위치 정보에 대응되는 학습된 모델의 입력데이터로서 사용하여, 상기 오브젝트에 대한 정보를 획득하고, 상기 오브젝트에 대한 정보를 기초로 상기 안내정보를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 출력하는 단계는,상기 경로에 대한 정보를 서버로 전송하고, 상기 서버로부터 상기 경로에 포함된 상기 복수의 구간에 대응되는 복수의 학습된 모델을 수신하고, 상기 이미지를 상기 복수의 학습된 모델 중 상기 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서사용하여, 상기 오브젝트에 대한 정보를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0019485", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 출력하는 단계는, 스피커 및 디스플레이 중 적어도 하나를 통해 상기 안내 정보를 출력하는, 제어 방법."}
{"patent_id": "10-2019-0019485", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에서는 전자 장치 및 그 제어 방법이 제공된다. 본 개시의 전자 장치는 카메라, 센서, 회로(circuitry)를 포함하는 출력 인터페이스 및 차량의 목적지까지의 경로 상에 존재하는 오브젝트에 대한 정보를 기초로 경로에 대한 안내 정보를 출력 인터페이스를 통해 출력하는 프로세서를 포함하며, 오브젝트에 대한 정보는 센서를 통해 획득된 차량의 위치 정보 및 카메라를 통해 획득된 차량의 전방을 촬영한 이미지에 기초하여, 경로에 포함된 복 수의 구간에 대응되는 복수의 학습된 모델로부터 획득될 수 있다. 본 개시의 전자 장치는 규칙 기반 모델 또는, 기계학습, 신경망 또는 딥러닝 알고리즘 중 적어도 하나에 따라 학 습된 인공지능 모델을 이용할 수 있다."}
{"patent_id": "10-2019-0019485", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그의 제어 방법에 관한 것으로, 보다 상세하게는 사용자에게 경로를 안내하는 전자 장 치 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0019485", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 전자 기술의 발달에 따라, 사용자에게 경로를 안내하기 위해 사용자의 위치로부터 목적지까지의 경로를 실 시간으로 안내하는 기술이 대중화되었다. 특히, 사용자 경험(User Experience; UX)을 향상시키기 위해, 건물(또는 상호 등)을 기준으로 경로 안내를 제공 할 수 있다. 이를 위해서는, 데이터베이스에 건물(또는 상호) 등에 대한 맵 데이터가 미리 구축될 필요가 있다. 다만, 지역의 규모가 커질수록 저장되어야 할 맵 데이터의 양 또한 증가하게 되며, 경로 안내의 기준이 되는 건 물이 재건축되거나 상호가 변경되는 등의 경우 데이터베이스에 저장된 맵 데이터를 일일이 변경해야 한다는 문 제가 있다. 또한, 경로 안내의 기준은 가시성(visibility)이 높은 건물이 될 수 있는데, 사용자(예: 키가 큰 사용자, 작은 사용자, 적록 색약인 사용자 등), 날씨(예: 눈, 안개 등), 시간(예: 낮, 밤 등) 등과 같은 상황에 따라 가시성 (visibility)이 달라지게 되므로, 이를 획일적으로 결정할 수 없다는 문제가 있다. 한편, 실시간으로 이미지를 촬영하고 촬영된 이미지를 인공지능 모델에 입력하여 실시간으로 처리함으로써, 경 로 안내의 기준이 되는 건물을 상황에 따라 사용자의 시각에서 결정할 수 있다. 다만, 인공지능 모델을 이용하 는 경우, 지역의 규모가 커질수록 연산 속도 및 정확도가 급격히 저하되고, 학습된 모델의 크기가 비대해지는 문제가 있다."}
{"patent_id": "10-2019-0019485", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 의해 안출된 것으로, 본 개시의 목적은 사용자에게 보다 편리하고 쉽게 경로를 안내 할 수 있는 전자 장치 및 그의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0019485", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한, 본 개시의 일 실시 예에 따른 차량에 포함된 전자 장치는 카메라, 센서, 회로 (circuitry)를 포함하는 출력 인터페이스 및 차량의 목적지까지의 경로 상에 존재하는 오브젝트에 대한 정보를 기초로 경로에 대한 안내 정보를 출력 인터페이스를 통해 출력하는 프로세서를 포함하며, 오브젝트에 대한 정보 는 센서를 통해 획득된 차량의 위치 정보 및 카메라를 통해 획득된 차량의 전방을 촬영한 이미지에 기초하여, 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델로부터 획득될 수 있다. 여기에서, 오브젝트는 경로 상에 존재하는 건물을 포함하고, 프로세서는 건물을 기초로 차량의 진행 방향 및 진 행 거리 중 적어도 하나와 관련된 안내 정보를 출력할 수 있다. 한편, 복수의 학습된 모델 각각은 특정 위치에서 촬영된 이미지에 기초하여, 이미지에 포함된 복수의 오브젝트 중에서 특정 위치에서 식별될 확률이 가장 높은 오브젝트를 판단하도록 학습된 모델을 포함할 수 있다. 여기에서, 복수의 학습된 모델 각각은 경로가 분기점을 기준으로 구분된 복수의 구간 각각에서 촬영된 이미지에 기초하여 학습된 모델을 포함할 수 있다. 한편, 복수의 구간은 경로에 존재하는 분기점을 기준으로 구분될 수 있다. 한편, 본 개시의 전자 장치는 회로(circuitry)를 포함하는 통신 인터페이스를 더 포함하고, 프로세서는 경로에 대한 정보, 센서를 통해 획득된 차량의 위치 정보 및 카메라를 통해 획득된 차량의 전방을 촬영한 이미지를 통 신 인터페이스를 통해 서버로 전송하고, 서버로부터 안내 정보를 수신하여 출력 인터페이스를 통해 출력할 수 있다. 이때, 서버는 기저장된 학습된 모델 중에서 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델을 판단하고, 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서 사용 하여, 오브젝트에 대한 정보를 획득하고, 오브젝트에 대한 정보를 기초로 안내 정보를 획득할 수 있다. 한편, 본 개시의 전자 장치는 회로(circuitry)를 포함하는 통신 인터페이스를 더 포함하고, 프로세서는 경로에 대한 정보를 통신 인터페이스를 통해 서버로 전송하고, 서버로부터 경로에 포함된 복수의 구간에 대응되는 복수 의 학습된 모델을 수신하고, 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 안내 정보를 획득할 수 있다.한편, 출력 인터페이스는 스피커 및 디스플레이 중 적어도 하나를 포함하며, 프로세서는 스피커 및 디스플레이 중 적어도 하나를 통해 안내 정보를 출력할 수 있다. 본 개시의 일 실시 예에 따른 차량에 포함된 전자 장치의 제어 방법은 차량의 위치 정보 및 차량의 전방을 촬영 한 이미지에 기초하여, 차량의 목적지까지의 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델로부터 경로 상에 존재하는 오브젝트에 대한 정보를 획득하는 단계 및 차량의 목적지까지의 경로 상에 존재하는 오브젝 트에 대한 정보를 기초로, 경로에 대한 안내 정보를 출력하는 단계를 포함할 수 있다. 여기에서, 오브젝트는 경로 상에 존재하는 건물을 포함하고, 출력하는 단계는 건물을 기초로 차량의 진행 방향 및 진행 거리 중 적어도 하나와 관련된 안내 정보를 출력할 수 있다. 한편, 복수의 학습된 모델 각각은 특정 위치에서 촬영된 이미지에 기초하여, 이미지에 포함된 복수의 오브젝트 중에서 특정 위치에서 식별될 확률이 가장 높은 오브젝트를 판단하도록 학습된 모델을 포함할 수 있다. 여기에서, 상기 복수의 학습된 모델 각각은 경로가 분기점을 기준으로 구분된 복수의 구간 각각에서 촬영된 이 미지에 기초하여 학습된 모델을 포함할 수 있다. 한편, 복수의 구간은 경로에 존재하는 분기점을 기준으로 구분될 수 있다. 한편, 출력하는 단계는 경로에 대한 정보, 차량의 위치 정보 및 차량의 전방을 촬영한 이미지를 서버로 전송하 는 단계 및 서버로부터 안내 정보를 수신하여 출력하는 단계를 더 포함할 수 있다. 이때, 서버는 기저장된 학습 된 모델 중에서 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델을 판단하고, 이미지를 복수의 학습 된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 오브젝트에 대한 정보를 획 득하고, 오브젝트에 대한 정보를 기초로 안내 정보를 획득할 수 있다. 한편, 출력하는 단계는 경로에 대한 정보를 서버로 전송하고, 서버로부터 경로에 포함된 복수의 구간에 대응되 는 복수의 학습된 모델을 수신하고, 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델 의 입력 데이터로서 사용하여, 오브젝트에 대한 정보를 획득할 수 있다. 한편, 출력하는 단계는 스피커 및 디스플레이 중 적어도 하나를 통해 안내 정보를 출력할 수 있다."}
{"patent_id": "10-2019-0019485", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 사용자에게 보다 편리하고 쉽게 경로를 안내할 수 있는 전자 장치 및 그의 제어 방법을 제공할 수 있다. 그리고, 본 개시의 다양한 실시 예에 따르면, 사용자 시각에서 상황에 따른 오브젝트를 기준으로 경로를 안내할 수 있는 전자 장치 및 그의 제어 방법을 제공할 수 있다. 또한, 사용자에게 경로 안내에 대한 사용자 경험(User Experience; UX)이 향상된 서비스를 제공할 수 있다."}
{"patent_id": "10-2019-0019485", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위 하여 제공되는 것이다. 본 개시에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시 예의 다양한 변경 (modifications), 균등물(equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 상기 구성요소들을 한정하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \" 포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 상기 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메 모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 상기 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시의 다양한 실시 예들에 따른 전자 장치는, 예를 들면, 스마트폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 영상 전화기, 전자책 리더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 워크 스테이션(workstation), 서버, PDA(personal digital assistant), PMP(portable multimedia player), MP3 플 레이어, 모바일 의료기기, 카메라(camera), 또는 웨어러블 장치(wearable device) 중 적어도 하나를 포함할 수 있다. 다양한 실시 예에 따르면, 웨어러블 장치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택 트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD)), 직물 또는 의류 일체형(예: 전자 의복), 신체 부 착형(예: 스킨 패드(skin pad) 또는 문신), 또는 생체 이식형(예: implantable circuit) 중 적어도 하나를 포 함할 수 있다. 또한, 일 실시 예들에서, 전자 장치는 가전 제품(home appliance)일 수 있다. 가전 제품은, 예를 들면, 텔레비 전, DVD(digital video disk) 플레이어, 오디오, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청 정기, 셋톱 박스(set-top box), 홈 오토매이션 컨트롤 패널(home automation control panel), 보안 컨트롤 패 널(security control panel), TV 박스(예: 삼성 HomeSync쪠, 애플TV쪠, 또는 구글 TV쪠), 게임 콘솔(예: Xbox 쪠, PlayStation쪠), 전자 사전, 전자 키, 캠코더(camcorder), 또는 전자 액자 중 적어도 하나를 포함할 수 있 다.다른 실시 예에서, 전자 장치는, 각종 의료기기(예: 각종 휴대용 의료측정기기(혈당 측정기, 심박 측정기, 혈압 측정기, 또는 체온 측정기 등), MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 또는 초음파기 등), 네비게이션(navigation) 장치, 위성 항법 시스템 (GNSS(global navigation satellite system)), EDR(event data recorder), FDR(flight data recorder), 자동 차 인포테인먼트(infotainment) 장치, 선박용 전자 장비(예: 선박용 항법 장치, 자이로 콤파스 등), 항공 전자 기기(avionics), 보안 기기, 차량용 헤드 유닛(head unit), 산업용 또는 가정용 로봇, 금융 기관의 ATM(automatic teller's machine), 상점의 POS(point of sales), 또는 사물 인터넷 장치(internet of things) (예: 전구, 각종 센서, 전기 또는 가스 미터기, 스프링클러 장치, 화재경보기, 온도조절기(thermostat), 가로등, 토스터(toaster), 운동기구, 온수탱크, 히터, 보일러 등) 중 적어도 하나를 포함할 수 있다. 또 다른 실시 예에 따르면, 전자 장치는 가구(furniture) 또는 건물/구조물의 일부, 전자 보드(electronic board), 전자 사인 수신 장치(electronic signature receiving device), 프로젝터(projector), 또는 각종 계측 기기(예: 수도, 전기, 가스, 또는 전파 계측 기기 등) 중 적어도 하나를 포함할 수 있다. 다양한 실시 예에서, 전자 장치는 전술한 다양한 장치들 중 하나 또는 그 이상의 조합일 수 있다. 어떤 실시 예에 따른 전자 장치는 플렉서블 전자 장치일 수 있다. 또한, 본 문서의 실시 예에 따른 전자 장치는 전술한 기기들에 한정되지 않으며, 기술 발전에 따른 새로운 전자 장치를 포함할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 시스템을 설명하기 위한 도면이다. 도 1을 참조하여, 본 개시의 시스템은 전자 장치 및 서버를 포함할 수 있다. 도 1에 도시된 바와 같이, 전자 장치는 차량(vehicle)과 일체의 장치로서 차량에 내장되거나 차량과 별도 의 장치로서 차량에 결합 또는 분리 될 수 있다. 여기서, 차량은 주행할 수 있는 이동 수단으로서, 자동차, 오 토바이뿐만 아니라 자전거, 로봇, 기차, 선박, 비행체 등과 같은 다양한 이동 수단으로 구현될 수도 있다. 또한, 차량은 자율 주행 시스템 또는 ADAS(첨단 운전자 보조 시스템, Advanced Driver Assistance System)이 적용된 주행 시스템으로 구현될 수도 있다. 이하에서는 설명의 편의를 위해 도 1에 도시된 바와 같이 차량은 자 동차로 가정하여 설명하도록 한다. 전자 장치는 차량(vehicle)을 이용하는 사용자에게 차량의 목적지까지의 경로를 안내할 수 있는 장치로서, 서버와 다양한 방식의 통신을 수행하여 다양한 종류의 데이터를 송수신할 수 있으며, 서버와 클라우 드 방식 등으로 연동하여 실시간으로 데이터를 동기화할 수도 있다. 서버는 다양한 방식의 통신을 수행할 수 있는 외부 전자 장치로서, 전자 장치의 사용자에게 차량의 목적지까지의 경로를 안내하기 위해 다양한 종류의 데이터를 송수신하거나 처리할 수 있다. 이를 위해, 서버는 통신 인터페이스(미도시)를 포함할 수 있으며, 이에 대한 설명은 후술하는 전자 장치 의 통신 인터페이스에 대한 설명이 동일하게 적용될 수 있다. 이때, 서버는 다양한 기능을 모두 수행(또는 처리)할 수 있는 단일한 서버 또는 기능이 분담되어 수행(또 는 처리)되도록 설계된 복수의 서버로 구성된 서버 시스템으로 구현될 수 있다. 일 실시 예로서, 외부 전자 장치는 인터넷으로 가상화된 IT(Information Technology) 자원을 서비스로 제 공하는 클라우드(cloud) 서버 또는 데이터가 발생한 위치와 근접한 거리에서 실시간으로 데이터를 처리하는 방 식으로 데이터의 경로를 단순화시키는 엣지(edge) 서버로 구현되거나, 이들의 조합으로 구현될 수 있다. 다른 실시 예로서, 서버는 크라우드 소싱(crowd sourcing) 등을 이용하여 데이터를 수집하도록 설계된 서 버 장치, 차량의 경로를 안내하기 위한 맵 데이터를 수집하고 제공하도록 설계된 서버 장치 또는 인공 지능 (Artificial Intelligence, AI) 모델을 처리하도록 설계된 서버 장치를 포함할 수 있다. 전자 장치는 차량(vehicle)을 이용하는 사용자에게 차량의 목적지까지의 경로를 안내할 수 있다. 구체적으로, 전자 장치는 목적지를 설정하기 위한 사용자 명령(command)이 수신되면, 차량의 위치 정보 및 목적지에 대한 정보에 기초하여 탐색된 차량의 위치로부터 목적지까지의 경로에 대한 안내 정보를 출력할 수 있 다. 예를 들어, 전자 장치는 목적지를 설정하기 위한 사용자 명령(command)이 수신되면 차량의 위치 정보 및 목적지에 대한 정보를 서버로 전송하고, 서버로부터 탐색된 경로에 대한 안내 정보를 수신하여, 수신 된 안내 정보를 출력할 수 있다.한편, 전자 장치는 차량(vehicle)을 이용하는 사용자에게 경로 상에 존재하는 기준 오브젝트를 기초로, 차 량의 목적지까지의 경로에 대한 안내 정보를 출력할 수 있다. 여기서, 기준 오브젝트는 경로 상에 존재하는 건물 또는 상호 등과 같은 오브젝트 중에서, 사용자에게 경로를 안내하는 기준이 되는 오브젝트가 될 수 있다. 이를 위해, 기준 오브젝트는 사용자의 시야에 존재하는 복수의 오브젝트 중에서 다른 오브젝트들과 구별될 수 있는 가장 식별력(discrimination)(또는 가시성(visibility))이 높은 오브젝트가 결정될 수 있다. 예를 들어, 기준 오브젝트가 경로 상에 존재하는 복수의 오브젝트 중에 우체국인 경우를 가정하면, 전자 장치 는 사용자에게 기준 오브젝트를 기초로, 차량의 목적지까지의 경로에 대한 안내 정보(예: 우체국 앞에서 우회전입니다)를 출력할 수 있다. 또한, 사용자(예: 키가 큰 사용자, 작은 사용자, 적록 색약인 사용자 등), 날씨(예: 눈, 안개 등), 시간(예: 낮, 밤 등) 등과 같은 상황에 따라 다른 오브젝트가 기준 오브젝트로 결정될 수 있다. 이에 따른 본 개시의 전자 장치는 사용자 맞춤형의 오브젝트를 기준으로 목적지까지의 경로를 안내할 수 있으며, 경로 안내에 대한 사용자 편의성 및 사용자 경험을 향상시킬 수 있다. 한편, 서버는 이미지에 포함된 복수의 오브젝트 중에서 가장 식별력이 높은 오브젝트로 판단하기 위한 판 단 기준을 갖는 복수의 학습된 모델을 기저장할 수 있다. 이때, 학습된 모델은 인공 지능 모델 중 하나를 포함 할 수 있으며, 머신러닝 또는 딥러닝과 같이 입력된 데이터를 이용하여 특정한 패턴을 컴퓨터로 학습하고 결과 데이터를 출력하도록 설계된 것을 의미할 수 있다. 일 예로서, 학습된 모델은 신경망 모델, 유전자 모델, 확률 통계 모델 등이 될 수 있다. 예를 들어, 서버는 거리(avenue), 날씨, 시간 등에 따라 각각 촬영된 이미지에 포함된 오브젝트 중에서 가 장 식별력이 높은 오브젝트를 판단하도록 학습된 복수의 모델을 기저장할 수 있다. 나아가, 복수의 학습된 모델 은 사용자의 키, 사용자의 색약 등을 고려하여 이미지에 포함된 오브젝트 중에서 가장 식별력이 높은 오브젝트 를 판단하도록 학습될 수도 있다. 이하에서는 도 2를 참조하여, 서버가 학습 데이터에 따라 모델을 학습하는 방법을 설명하도록 한다. 도 2를 참조하여, 서버는 학습 데이터를 획득하기 위한 차량으로부터 획득된 학습 데이터를 수신할 수 있다. 이때, 학습 데이터는 차량의 위치 정보, 차량 전방을 촬영한 이미지 및 이미지에 포함된 복수의 오브 젝트에 대한 정보를 포함할 수 있다. 나아가, 학습 데이터에는 이미지가 촬영된 시각, 날씨, 사용자의 키, 사용 자의 색약 여부 등에 따라 이미지에 포함된 복수의 오브젝트에 대해 식별력을 판단한 결과 정보 등을 포함할 수 있다. 여기서, 학습 데이터를 획득하기 위한 차량은 차량의 전방을 촬영한 이미지 및 이미지가 촬영된 위치 정보를 획득할 수 있다. 이를 위해, 학습 데이터를 획득하기 위한 차량은 카메라(미도시), 센서(미도시)를 포함할 수 있으며, 이는 후술하는 본 개시의 전자 장치의 카메라 및 센서에 대한 설명이 동일하 게 적용될 수 있다. 서버는 학습 데이터를 획득하기 위한 차량으로부터 학습 데이터가 수신되면, 학습 데이터를 이용하여 이미지에 포함된 복수의 오브젝트 중에서 어떤 오브젝트가 가장 식별력이 높은 오브젝트인지 판단하는 판단 기 준을 갖는 복수의 모델을 학습 또는 갱신시킬 수 있다. 이때, 복수의 모델은 기설정된 거리(distance)마다 기설 정된 영역을 커버리지(coverage)로 하도록 설계되거나, 거리(avenue) 단위의 영역을 커버리지로 하도록 설계된 복수의 모델을 포함할 수 있다. 일 실시 예로서, 복수의 모델 각각은 거리(avenue)가 분기점을 기준으로 구분된 복수의 구간 각각에서 촬영된 이미지에 기초하여 학습된 모델을 포함할 수 있다. 예를 들어, 도 2에 도시된 바와 같이, 모델 1-A는 분기점을 기준으로 거리의 제1 구간을 커버리지로 하는 것을 가정한다. 여기서, 제1 구간은 제1 분기점 및 제2 분기점 사이를 연결하는 거리를 의미할 수 있다. 이 경우, 모델 1-A 는 분기점을 기준으로 구분된 제1 구간에서 학습 데이터를 획득하기 위한 차량의 전방을 촬영한 이미지를 학습 데이터로 이용하여 학습될 수 있다. 이때, 이미지를 모델의 학습 데이터(또는 입 력 데이터)로 이용하기 위해, 이미지가 n차원(n은 자연수)의 공간 상의 점에 대응되는 하나의 특징 값으로 변환되는 특징 추출(feature extraction) 과정을 거칠 수 있다. 또한, 모델 1-A는 학습 데이터를 획득하기 위한 차량의 전방을 촬영한 이미지에 포함된 복수의 오브젝트 중에서 우체국 건물이 식별력이 가장 높은 오브젝트라고 기판단된 결과 정보를 학습 데이터로 이용하고, 이미지에 포함된 복수의 오브젝트 중에서 식별력이 가장 높은 오브젝트를 판단한 결과 정보가 기판단된 결과 정 보와 일치하도록 학습될 수 있다. 이때, 모델에 의해 출력되는 판단된 결과 정보는 이미지에 포함된 복수의 오 브젝트에 대한 정보, 복수의 오브젝트 중에서 특정 위치에서 식별될 확률에 대한 정보를 포함할 수 있다. 이와 같이, 모델 1-A는 거리의 제1 구간을 커버리지로 할 수 있다. 즉, 모델 A는 학습 데이터를 획득하기 위한 차량에 의해 제1 구간에서 촬영된 이미지를 이용하여 학습되며, 전자 장치에 의해 제1 구 간에서 촬영된 이미지가 입력되면 입력된 이미지에 포함된 복수의 오브젝트 중에서 식별력이 가장 높은 오 브젝트를 판단한 결과 정보를 출력할 수 있다. 다른 실시 예로서, 복수의 모델 각각은 특정 위치에서 촬영된 이미지 및 환경 정보에 기초하여 학습된 모델을 포함할 수 있다. 이때, 환경 정보는 이미지가 촬영된 시각, 날씨, 사용자의 키, 사용자의 색약 여부 등에 대한 정보를 포함할 수 있다. 상술한 예와 동일한 거리의 제1 구간의 특정 위치에서 촬영된 이미지에 대해서도, 이미지가 촬영된 시각, 날씨, 사용자의 키, 사용자의 색약 여부 등에 따라 이미지에 포함된 복수의 오브젝트 중에서 식별력이 가장 높 은 오브젝트가 달라질 수 있다. 예를 들어, 모델 1-B 는 제1 구간에서 학습 데이터를 획득하기 위한 차량의 전방을 야간에 촬영한 이 미지 및 야간을 기준으로 오브젝트가 판단된 결과 정보를 학습 데이터로 이용하여 학습될 수 있다. 다른 예로서, 모델 1-C는 사용자가 색약인 경우에 학습 데이터를 획득하기 위한 차량의 전방을 촬영한 이미지 및 색약인 사용자를 기준으로 오브젝트가 판단된 결과 정보를 학습 데이터로 이용하여 학습될 수 있다. 이상과 같은 본 개시의 다양한 실시 예에 따르면, 다양한 상황에 대해서도 사용자의 시각에 적합한 오브젝트를 판단하도록 인공 지능 모델을 학습시킬 수 있다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 전자 장치는 카메라, 센서, 출력 인터페이스 및 프로세서를 포함할 수 있다. 카메라는 렌즈를 통해 특정한 방향 또는 공간을 촬영하여 이미지를 획득할 수 있다. 특히, 카메라는 차량이 주행하는 방향인 차량의 전방을 촬영한 이미지를 획득할 수 있다. 이후, 카메라에 의해 획득된 이 미지는 서버로 전송되거나, 영상 처리부(미도시)에서 처리되어 디스플레이(미도시)에 표시될 수 있다. 센서는 전자 장치의 위치에 대한 위치 정보를 획득할 수 있다. 이를 위해, 센서는 GPS(Global Positioning System), 관성 측정 장치(IMU, Inertial Measurement Unit), 레이더(Radar, Radio Detection And Ranging), 라이다(Lidar, Light Detection and Ranging), 초음파 센서 등과 같은 다양한 센서를 포함할 수 있 다. 이때, 위치 정보는 전자 장치의 위치 또는 이미지가 촬영된 위치를 추정하기 위한 정보를 포함할 수 있다. 구체적으로, GPS(Global Positioning System)는 위성을 이용한 항법 시스템으로서 인공위성 및 GPS 수신기의 거 리를 측정해 그 거리 벡터를 교차시켜 위치 정보를 획득할 수 있으며, IMU는 가속도계, 회전 속도계 및 자력계 중 적어도 하나 또는 이들의 조합을 이용해 축의 위치 변화 및/또는 축의 회전 변화를 감지하여 위치 정보를 획 득할 수 있다. 예를 들어, 축은 3DoF 또는 6DoF 등으로 구성될 수 있으며, 이는 일 실시 예일 뿐 다양하게 변형 되어 실시될 수 있다. 한편, 레이더(Radar, Radio Detection And Ranging), 라이다(Lidar, Light Detection and Ranging), 초음파 센 서 등의 센서는 신호(예: 전자기파, 레이저, 초음파 등)를 방출하고, 방출된 신호가 전자 장치의 주위에 존재하는 오브젝트(예: 건물, 랜드마크 등)에 반사되는 경우 반사되어 되돌아오는 신호를 감지하고, 감지된 신 호의 세기, 시간, 파장에 따른 흡수차 및/또는 파장 이동 등으로부터 오브젝트와 전자 장치 사이의 거리, 오브젝트의 형상, 오브젝트의 형태 및/또는 오브젝트의 크기 등에 대한 정보를 획득할 수 있다. 이 경우, 프로세서는 획득된 오브젝트의 형상, 오브젝트의 형태, 오브젝트의 크기 등에 대한 정보로부터 맵 데이터에서 매칭되는 오브젝트를 판단할 수 있다. 이를 위해, 전자 장치(또는 전자 장치의 메모리 (미도시))에는 오브젝트, 위치, 거리 등에 대한 정보가 포함된 맵 데이터가 기저장될 수 있다.그리고, 프로세서는 오브젝트와 전자 장치 사이의 거리에 대한 정보 및 오브젝트의 위치에 기초하여, 삼변측량(또는 삼각측량) 등을 이용하여 전자 장치의 위치 정보를 획득할 수 있다. 예를 들어, 프로세서는 제1 내지 제3 원의 교점을 전자 장치의 위치로 결정할 수 있으며, 이때 제1 원은 제1 오브젝트의 위치를 원의 중심으로 하며 전자 장치와 제1 오브젝트와의 거리를 반지름으로 하고, 제2 원은 제2 오브젝트의 위치를 원의 중심으로 하며 전자 장치와 제2 오브젝트와의 거리를 반지름으로 하 고, 제3원은 제3 오브젝트의 위치를 원의 중심으로 하며 전자 장치와 제3 오브젝트와의 거리를 반지름으로 할 수 있다, 상술한 설명에서는 위치 정보가 전자 장치에 의해 획득되는 것으로 설명하였으나, 전자 장치는 서버 와 연계(또는 연동)하여 위치 정보를 획득할 수도 있다. 즉, 전자 장치는 위치 정보를 획득하기 위해 요구되는 정보(예: 센서에 의해 획득된 오브젝트와 전자 장치 사이의 거리, 오브젝트의 형상, 오브젝 트의 형태 및/또는 오브젝트의 크기 등에 대한 정보 등)를 서버로 전송하고, 서버는 상술한 프로세서 의 동작을 수행하여 수신된 정보에 기초해 전자 장치의 위치 정보를 획득하고, 전자 장치로 전 송할 수 있다. 이를 위해, 전자 장치 및 서버는 다양한 방식의 유무선 통신을 수행할 수 있다. 한편, 위치 정보는 카메라에 의해 촬영된 이미지를 이용하여 획득될 수도 있다. 구체적으로, 프로세서는 다양한 방식의 이미지 분석 알고리즘(또는 인공지능 모델 등)을 활용하여 카메라 에 의해 촬영된 이미지에 포함된 오브젝트를 인식하고, 이미지에 포함된 오브젝트의 크기, 위치, 방향, 각 도 등에 기초해 상술한 삼변측량 등에 의해 전자 장치의 위치 정보를 획득할 수 있다. 일 실시 예로서, 프로세서는 거리(또는 도로)의 특정한 위치마다 차량이 주행하는 방향으로 촬영된 거리 뷰(또는 도로 뷰) 이미지 및 거리 뷰 이미지에 대응되는 위치 정보가 포함된 맵 데이터에 기초하여, 카메라 에 의해 촬영된 이미지를 거리 뷰 이미지와 비교하여 유사도를 획득하고, 유사도가 가장 높은 거리 뷰 이 미지에 대응되는 위치가 이미지가 촬영된 위치로 판단하여, 실시간으로 전자 장치의 위치 정보를 획득할 수 있다. 이와 같이, 위치 정보는 센서 및 카메라 각각 또는 조합에 의해 획득될 수 있다. 이에 따라, 자율 주 행 차량 등과 같은 차량이 이동하는 경우에도, 차량에 내재되거나 분리된 전자 장치는 카메라에 의해 실시간으로 촬영된 이미지를 이용해 위치 정보를 획득할 수 있다. 한편, 센서에 대해 상술한 설명과 같이 전자 장치는 서버와 연계(또는 연동)하여 위치 정보를 획득할 수 있음은 물론이다. 출력 인터페이스는 이미지, 맵(예: 도로, 건물 등), 맵 상에 전자 장치의 현재 위치를 나타내기 위해 전자 장치에 대응되는 비주얼 요소(예: 화살표, 차량 등의 아이콘 또는 이모지 등), 전자 장치가 이 동하거나 이동할 예정인 경로에 대한 안내 정보 등과 같은 정보를 출력하기 위한 구성으로서, 적어도 하나의 회 로를 포함할 수 있다. 이때, 출력되는 정보는 이미지 또는 오디오 등과 같은 형태로 구현될 수 있다. 예를 들어, 출력 인터페이스는 디스플레이(미도시), 스피커(미도시)를 포함할 수 있다. 디스플레이는 영상 처리부(미도시)에서 처리한 영상 데이터를 디스플레이 영역(또는 디스플레이)에 표시할 수 있다. 디스플레이 영 역은 전자 장치의 하우징의 일면에 노출된 디스플레이의 적어도 일부를 의미할 수 있다. 디스플레이 의 적어도 일부는 플렉서블 디스플레이(flexible display)의 형태로 전자 장치의 전면 영역 및, 측면 영역 및 후면 영역 중 적어도 하나에 결합될 수도 있다. 플렉서블 디스플레이는 종이처럼 얇고 유연한 기판을 통해 손상 없이 휘거나 구부리거나 말 수 있는 것을 특징으로 할 수 있다. 스피커는 전자 장치에 내장된 것으로 오디 오 처리부(미도시)에 의해 디코딩이나 증폭, 노이즈 필터링과 같은 다양한 처리 작업이 수행된 각종 오디오 데 이터뿐만 아니라 각종 알림음이나 음성 메시지를 직접 소리로 출력할 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어할 수 있다. 프로세서는 차량의 목적지까지의 경로 상에 존재하는 오브젝트에 대한 정보를 기초로 경로에 대한 안내 정 보를 출력 인터페이스를 통해 출력할 수 있다. 예를 들어, 프로세서는 전자 장치가 탑재된 차량 의 목적지까지의 경로를 안내하는 안내 정보를 출력 인터페이스를 통해 출력할 수 있다. 프로세서는 전자 장치가 탑재된 차량의 전방을 촬영한 이미지에 의해 인식되는 오브젝트들 중에서, 차량의 위치에서 식별 가능성이 최대인 오브젝트를 기준으로 경로를 안내할 수 있다. 이때, 식별 가능성은 경로에 포함된 각 구 간 별로 마련된 복수의 학습 모델 중 차량의 위치에서 학습된 학습 모델에 의해 판단될 수 있다. 여기에서, 오브젝트에 대한 정보는 센서를 통해 획득된 차량의 위치 정보 및 카메라를 통해 획득된 차량의 전방을 촬영한 이미지에 기초하여, 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델로부터 획 득될 수 있다. 한편, 복수의 학습된 모델 각각은 특정 위치에서 촬영된 이미지에 기초하여, 이미지에 포함된 복수의 오브젝트 중에서 특정 위치에서 식별될 확률이 가장 높은 오브젝트를 판단하도록 학습된 모델을 포함할 수 있다. 이때, 특정 위치는 이미지가 촬영된 위치를 의미할 수 있으며, 이미지가 촬영된 시점에서의 차량(또는 전자 장치 )의 위치 정보에 기초하여 결정될 수 있다. 여기서, 식별될 확률이 가장 높은 오브젝트(또는 기준 오브젝트)는 사용자에게 경로를 안내하는 기준이 되는 것으로서, 사용자의 시야에 존재하는 복수의 오브젝트 중에서 다른 오브젝트들과 구별될 수 있는 가장 식별력 (discrimination)(또는 가시성(visibility))이 높은 오브젝트를 의미할 수 있다. 이 경우, 복수의 학습된 모델 각각은 경로가 분기점을 기준으로 구분된 복수의 구간 각각에서 촬영된 이미지에 기초하여 학습된 모델을 포함할 수 있다. 이때, 복수의 구간은 경로에 존재하는 분기점을 기준으로 구분될 수 있다. 즉, 각 구간은 경로 내에 포함된 분 기점을 기준으로 구분될 수 있다. 이 경우, 분기점은 거리(avenue)가 여러 갈래로 갈라지는 지점으로서 거리 (avenue)가 교차되는 지점(교차로)을 의미할 수 있다. 예를 들어, 복수의 구간 각각은 거리(avenue)를 분기점과 분기점 사이를 연결하는 구간으로 각각 구분될 수 있다. 한편, 오브젝트는 경로 상에 존재하는 건물을 포함할 수 있다. 즉, 오브젝트는 분기점을 기준으로 구분된 복수 의 구간 중에서 차량의 목적지까지의 경로에 포함되는 적어도 하나의 구간(또는 구간 주변)에 존재하는 건물을 포함할 수 있다. 한편, 프로세서는 건물을 기초로 차량의 진행 방향 및 진행 거리 중 적어도 하나와 관련된 안내 정보를 출 력하도록 출력 인터페이스를 제어할 수 있다. 이때, 안내 정보는 오브젝트의 식별 가능성을 판단하기 위한 학습 모델이 저장된 서버로부터, 경로에 대한 정보, 차량의 위치 정보, 이미지에 기초하여 생성될 수 있다. 예를 들어, 안내 정보는 “100m 앞 우체국에서 우 회전 입니다”, “100m 앞 우체국을 지나 곧바로 우회전 입니다” 등과 같이, 건물을 기준으로 경로를 안내하는 오디오 유형의 정보일 수 있다. 이 경우, 프로세서는 맵 데이터에 기초하여, 맵 상에 차량의 위치를 나타내는 차량에 대응되는 비주얼 요 소(예: 화살표, 차량 등의 아이콘 또는 이모지 등), 도로, 건물, 경로를 안내하기 위한 이미지 유형의 정보를 표시하도록 출력 인터페이스를 제어할 수 있다. 한편, 프로세서는 스피커 및 디스플레이 중 적어도 하나를 통해 안내 정보를 출력할 수 있다. 구체적으로, 프로세서는 안내 정보가 오디오 유형인 경우 안내 정보를 출력하도록 스피커를 제어할 수 있으며, 안내 정 보가 이미지 유형인 경우 안내 정보를 출력하도록 디스플레이를 제어할 수 있다. 나아가, 프로세서는 안내 정보를 외부 전자 장치로 전송하여, 외부 전자 장치가 안내 정보를 출력하도록 제어할 수도 있다. 본 개시의 다양한 실시 예에 따르면, 전자 장치는 도 7과 같이 통신 인터페이스를 더 포함할 수 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 기기와 통신을 수행하여 다 양한 유형의 데이터를 송수신할 수 있는 구성으로서, 적어도 하나의 회로를 포함할 수 있다. 본 개시의 제1 실시 예로서, 프로세서는 경로에 대한 정보, 센서를 통해 획득된 차량의 위치 정보 및 카메라를 통해 획득된 차량의 전방을 촬영한 이미지를 통신 인터페이스를 통해 서버로 전송하고, 서버로부터 안내 정보를 수신하여 출력 인터페이스를 통해 출력할 수 있다. 이때, 서버 는 기저장된 학습된 모델 중에서 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델을 판단하고, 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 오브 젝트에 대한 정보를 획득하고, 오브젝트에 대한 정보를 기초로 안내 정보를 획득할 수 있다. 구체적으로, 프로세서는 입력 인터페이스(미도시)를 통해 목적지를 설정하기 위한 사용자 명령(command)을 수신할 수 있다. 이때, 입력 인터페이스는 사용자의 터치, 사용자의 음성, 사용자의 제스쳐 등과 같은 다양한 유형의 사용자 명 령(command)을 수신하여 프로세서로 전달할 수 있는 구성으로서, 구체적인 내용은 도 7에서 후술하여 설명 하도록 한다.그리고, 프로세서는 입력 인터페이스(미도시)를 통해 목적지를 설정하기 위한 사용자 명령(command)이 수 신되면, 차량의 목적지까지의 경로에 대한 정보(또는 차량의 목적지에 대한 정보), 센서를 통해 획득된 차 량의 위치 정보 및 카메라를 통해 획득된 차량의 전방을 촬영한 이미지를 서버로 전송하도록 통신 인 터페이스를 제어할 수 있다. 나아가, 프로세서는 환경 정보를 서버로 전송하도록 통신 인터페이스를 제어할 수 있다. 이때, 환경 정보는 이미지가 촬영된 시각, 날씨, 사용자의 키, 사용자의 색약 여부 등에 대한 정보를 포함할 수 있다. 그리고, 프로세서는 서버로부터 차량의 목적지까지의 경로를 안내하는 안내 정보가 통신 인터페이스 를 통해 수신되면, 수신된 안내 정보를 출력 인터페이스를 통해 출력할 수 있다. 이를 위해, 서버는 기저장된 학습된 모델 중에서 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모 델을 판단할 수 있다. 구체적으로, 서버는 전자 장치로부터 수신된 차량의 위치, 목적지까지의 경로에 대한 정보 및 기저장 된 경로 탐색 알고리즘에 기초하여, 차량의 목적지까지의 경로를 결정할 수 있다. 이때, 결정된 경로는 차량이 목적지까지 주행할 경우에 경유되는 분기점을 포함할 수 있다. 이때, 경로 탐색 알고리즘은 최단 주행 거리를 탐색하게 하는 에이 스타(A Star; A*), 다익스트라(Dijkstra), 벨만-포드(Bellman-Ford), 플로이드 등과 같은 알고리즘으로 구현될 수 있으며, 여기에 교통 정보(예: 교통 체 증, 교통 사고, 도로 파손, 날씨 등)에 따라 분기점 사이를 연결하는 구간에 가중치를 다르게 적용하여 최단 주 행 시간을 탐색하게 하는 알고리즘으로 구현될 수도 있다. 서버는 결정된 경로에 기초하여, 기저장된 학습된 모델 중에서 결정된 경로에 포함되는 복수의 구간에 대 응되는 복수의 학습된 모델을 판단할 수 있다. 이 경우, 서버는 수신된 환경 정보에 기초하여, 기저장된 학습된 모델 중에서 결정된 경로에 포함되는 복수의 구간에 대응되는 복수의 학습된 모델을 판단할 수도 있다. 예를 들어, 서버는 결정된 경로에 제1 구간이 포함된 경우, 기저장된 학습된 모델 중에서 제1 구간을 커버 리지로 하는 학습된 모델을 제1 구간에 대응되는 학습된 모델로 판단할 수 있다. 이 경우, 서버는 기저장 된 학습된 모델(또는 제1 구간에 대응되는 학습된 모델) 중에서 환경 정보에 대응되는 학습된 모델을 판단할 수 도 있다. 그리고, 서버는 전자 장치로부터 수신된 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되 는 학습된 모델의 입력 데이터로서 사용하여, 오브젝트에 대한 정보를 획득할 수 있다. 나아가, 서버는 수 신된 이미지를 복수의 학습된 모델 중 환경 정보에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 오브젝 트에 대한 정보를 획득할 수 있다. 그리고, 서버는 오브젝트에 대한 정보를 기초로 안내 정보를 획득할 수 있으며, 안내 정보를 전자 장치 로 전송할 수 있다. 구체적으로, 서버는 이미지를 모델의 입력 데이터로 이용하기 위해, 특징 추출(feature extraction) 과정 을 통해 전자 장치로부터 수신된 이미지를 n차원(n은 자연수)의 공간 상의 점에 대응되는 하나의 특징 값 으로 변환시킬 수 있다. 이 경우, 서버는 변환된 특징 값을 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입 력 데이터로서 사용하여, 오브젝트에 대한 정보를 획득할 수 있다. 그리고, 서버는 복수의 학습된 모델 각각으로부터 획득된 오브젝트에 대한 정보에 기초하여, 이미지에 포 함된 복수의 오브젝트 중에서 식별될 확률이 가장 높은 오브젝트(또는 기준 오브젝트)를 판단할 수 있다. 이 경 우, 오브젝트에 대한 정보는 오브젝트의 식별력에 대한 확률 값(예: 0 에서 1 사이의 값)을 포함할 수 있다. 여기에서, 서버는 이미지에 포함된 식별될 확률이 가장 높은 기준 오브젝트를 기초로, 차량의 위치 정보 및 이미지의 시야각(Field of View, FOV)를 이용하여 맵 데이터에 포함된 복수의 맵 오브젝트 중에서 기준 오브 젝트와 매칭되는 맵 오브젝트를 판단할 수 있다. 이때, 이미지의 시야각은 이미지에 포함된 차선의 각도에 따라 결정될 수 있다. 이를 위해, 서버는 차량의 목적지까지의 경로를 제공하기 위한 맵 데이터를 기저장할 수 있다. 이 경우, 서버는 기준 오브젝트와 매칭되는 맵 데이터에 포함된 맵 오브젝트로부터 기준 오브젝트에 대한 정보(예: 기준 오브젝트의 명칭, 위치 등)를 획득할 수 있다. 그리고, 서버는 차량의 위치 정보 및 기준 오브젝트에 대한 정보에 기초하여, 경로에 대한 안내 정보(예: 차량의 위치로부터 기준 오브젝트까지의 거리 및 기준 오브젝트를 기준으로 차량이 경로를 따라 진행될 방향 등)를 획득할 수 있으며, 안내 정보를 전자 장치로 전송할 수 있다. 예를 들어, 서버는 위치, 목적지 정보 및 경로 탐색 알고리즘에 기초해 획득된 정보(예: “100m 앞 우회전 ”)와 이미지 및 학습된 모델에 기초해 획득된 기준 오브젝트에 대한 정보(예: “100m 앞 우체국”)를 결합하여 안내 정보(예: “100m 앞 우체국에서 우회전”)를 획득하고, 안내 정보를 전자 장치로 전송할 수 있다. 이 경우, 서버는 단일한 장치로 구현되거나, 목적지 정보 및 경로 탐색 알고리즘에 기초해 정보를 획득하 는 제1 서버 장치 및 이미지 및 학습된 모델에 기초해 오브젝트에 대한 정보를 획득하는 제2 서버 장치와 같이 복수의 장치로 구현될 수도 있다. 한편, 상술한 실시 예에서는 서버가 제1 안내 정보 및 제2 안내 정보를 모두 획득하는 것으로 설명하였으 나, 전자 장치의 프로세서가 위치, 목적지 및 경로 탐색 알고리즘에 기초하여 제1 안내 정보를 획득 하고, 서버에서 획득된 제2 안내 정보가 서버로부터 수신되면, 제1 안내 정보 및 제2 안내 정보를 결 합하여 안내 정보를 출력하는 것 또한 가능하다. 한편, 본 개시의 제2 실시 예로서, 프로세서는 경로에 대한 정보를 통신 인터페이스를 통해 서버 로 전송하고, 서버로부터 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델을 수신하고, 카 메라에 의해 획득된 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데 이터로서 사용하여, 안내 정보를 획득할 수 있다. 구체적으로, 프로세서는 경로에 대한 정보를 통신 인터페이스를 통해 서버로 전송할 수 있다. 이 경우, 서버는 수신된 경로에 대한 정보에 기초하여, 기저장된 학습된 모델 중에서 결정된 경로에 포함 되는 복수의 구간에 대응되는 복수의 학습된 모델을 판단하여, 전자 장치로 전송할 수 있다. 이 경우, 서 버는 수신된 환경 정보에 기초하여, 기저장된 학습된 모델 중에서 결정된 경로에 포함되는 복수의 구간에 대응되는 복수의 학습된 모델을 판단할 수도 있다. 여기서, 서버는 전자 장치의 위치 및/또는 이동 방향에 기초하여 경로에 포함되는 복수의 구간에 대 응되는 복수의 학습된 모델을 전자 장치로 전부 또는 일부를 전송할 수 있다. 이 경우, 서버는 경로 에 포함되는 복수의 구간 중 전자 장치의 위치에서 가장 인접한 구간에 대응되는 학습된 모델을 우선적으 로 전자 장치로 전송할 수 있다. 이를 위해, 프로세서는 전자 장치의 위치 정보를 서버로 실시간 또는 기설정된 시간마다 주기적 으로 전송하도록 통신 인터페이스를 제어할 수 있다. 그리고, 프로세서는 서버로부터 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델이 수신되 면, 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 안내 정보를 획득할 수 있다. 이에 대한 설명은 상술한 본 개시의 일 실시 예에 대한 설명과 동일하게 적용될 수 있다. 이와 같이, 전자 장치는 경로에 대한 정보에 기반하여 서버로부터 복수의 학습된 모델을 수신하고, 이미지 및 수신된 복수의 학습된 모델을 이용하여 오브젝트를 기준으로 하는 안내 정보를 획득한 이후에, 전자 장치가 이동한 경우에도 전자 장치는 전자 장치의 위치에 기반하여 서버로부터 복수의 학 습된 모델을 수신하고, 이미지 및 수신된 복수의 학습된 모델을 이용하여 오브젝트를 기준으로 하는 안내 정보 를 획득할 수 있다. 이에 따라, 본 개시의 전자 장치는 이미지를 서버로 전송하는 것 대신 서버로부터 복수의 학습 된 모델을 수신하여 이미지를 처리할 수 있어, 데이터 전송 및 처리에 대한 효율성을 향상시킬 수 있다. 한편, 상술한 제1 및 제2 실시 예에서 서버가 수행하는 동작을 모두 전자 장치가 수행하도록 변형되 어 실시될 수 있다. 이 경우, 전자 장치는 서버로 데이터를 송수신하는 동작을 수행할 필요가 없는 점에서 전자 장치 및 서버의 동작 중 이를 데이터를 송수신하는 동작을 제외한 동작만으로 실시될 수 있다. 이상과 같은, 본 개시의 다양한 실시 예에 따르면, 사용자 시각에서 상황에 따른 오브젝트를 기준으로 경로를 안내할 수 있는 전자 장치 및 그의 제어 방법을 제공할 수 있다. 또한, 사용자에게 경로 안내에 대한 사용자 경 험(User Experience; UX)이 향상된 서비스를 제공할 수 있다. 이하에서는 설명의 편의를 위해 본 개시의 제1 실시 예를 기준으로 설명하도록 한다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 4를 참조하여, 전자 장치가 포함된 차량이 차량의 위치로부터 목적지까지의 경로를 따 라 주행하며, 경로는 분기점을 기준으로 제1 구간, 제2 구간, 제3 구간, 제4 구간 으로 구분된 복수의 구간 중에서 제1 구간, 제2 구간을 포함하는 것을 가정하도록 한다. 프로세서는 입력 인터페이스(미도시)를 통해 목적지를 설정하기 위한 사용자 명령(command)이 수신되 면, 차량의 목적지에 대한 정보(또는 경로에 대한 정보), 카메라를 통해 획득된 차량의 전방을 촬영한 이미지 및 센서를 통해 획득된 차량의 위치 정보를 서버로 전송하도록 통신 인터페이스 를 제어할 수 있다. 이 경우, 서버는 수신된 정보에 기초하여 기저장된 학습된 모델 중에서 경로에 포함된 제1 및 제2 구 간(461, 462)에 대응되는 복수의 학습된 모델을 판단할 수 있다. 그리고, 서버는 전자 장치로부터 수신된 이미지를 복수의 학습된 모델 중 이미지가 촬영된 위치(43 0)가 속하는 제1 구간에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 오브젝트 A 및 오브젝트 B에 대한 정보를 획득할 수 있다. 이 경우, 서버는 학습된 모델로부터 획득된 오브젝트 A 및 오브젝트 B에 대한 정보에 기초하여, 이미지에 포함된 오브젝트 A 및 오브젝트 B 중에서 특정 위치에서 식별될 확률이 가장 높은 오 브젝트를 판단할 수 있다. 예를 들어, 서버는 오브젝트 A에 대한 확률 값이 오브젝트 B에 대한 확률 값보다 큰 경우, 이미 지에 포함된 오브젝트 A 및 오브젝트 B 중에서 식별될 확률이 가장 높은 오브젝트를 오브젝트 A(41 0)로 판단할 수 있다. 이 경우, 서버는 위치, 목적지 및 경로 탐색 알고리즘에 기초해 획득된 정보(예: 50m 앞 좌회전)에 오브젝 트 A에 대한 정보(예: 50m 앞 오브젝트 A)를 결합한 안내 정보(예: 50m 앞 오브젝트 A에서 좌회 전)를 획득할 수 있다. 그리고, 프로세서는 서버로부터 차량의 목적지까지의 경로 상에 존재하는 오브젝트 A(41 0)에 대한 정보에 기초하여 획득된 안내 정보가 수신되면, 경로에 대한 안내 정보를 출력하도록 출력 인터페이 스를 제어할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 오브젝트를 판단하는 방법을 설명하기 위한 도면이다. 도 5를 참조하여, 경로는 분기점을 기초로 구분된 복수의 구간 중 제1 내지 제4 구간을 포함하고, 이미지 는 복수의 구간 중 경로에 포함된 제1 구간에서 촬영된 이미지로서 오브젝트 A 및 오브젝트 B를 포함하고, 학습 된 모델 A, B, C, D는 서버에 기저장된 복수의 학습된 모델 중 일부인 것으로 가정 한다. 일 실시 예로서, 학습된 모델 A, B, C, D은 제1 내지 제4 구간에 대응되는 것으로 가정하 면, 경로에 기초하여 기저장된 복수의 학습된 모델 중 경로에 포함된 제1 내지 제4 구간에 대응되는 학습된 모 델 A, B, C, D를 판단할 수 있다. 이 경우, 제1 구간에서 촬영된 이미지는 제1 구간에 대응되는 학습된 모델 A의 입력 데이터로서 사용 하여, 오브젝트 A 및 오브젝트 B에 대한 확률 값을 획득할 수 있다. 그리고, 오브젝트 A 및 오브젝트 B에 대한 확률 값 중에서 높은 확률 값을 갖는 오브젝트를 이미지에 포함 된 오브젝트 A 및 오브젝트 B 중에서 식별력이 가장 높은 기준 오브젝트라고 판단하고, 기준 오브젝트에 대한 판단 결과를 획득할 수 있다. 다른 실시 예로서, 학습된 모델 A은 제1 구간 및 키가 작은 사용자, 학습된 모델 B는 제1 구간 및 색 약 사용자, 학습된 모델 C는 제1 구간 및 야간 시간, 학습된 모델 D는 제1 구간 및 우천 날씨에 대응 되는 것으로 가정한다. 이 경우, 제1 구간에서 촬영된 이미지 및 환경 정보(차량의 사용자는 키가 작으며 색약이고, 야간에 비가 오는 상황인 경우)에 기초하여, 기저장된 복수의 학습된 모델 중 경로에 포함된 제1 구간 및 환경 정보에 대응 되는 복수의 학습된 모델 A, B, C, D를 판단할 수 있다. 그리고, 제1 구간에서 촬영된 이미지는 제1 구간에 대응되는 복수의 학습된 모델 A, B, C, D의 입력 데이터로서 사용하여, 오브젝트 A 및 오브젝트 B에 대한 확률 값을 각각 획득할 수 있다. 이 경우, 8개의 확률 값 중에서 가장 높은 확률 값을 갖는 오브젝트를 이미지에 포함된 오브젝트 A 및 오 브젝트 B 중에서 식별력이 가장 높은 기준 오브젝트라고 판단하고, 기준 오브젝트에 대한 판단 결과를 획 득할 수 있다. 다만, 이는 일 실시 예일 뿐이며, 복수의 학습된 모델마다 가장 큰 확률 값을 갖는 오브젝트의 수를 비교하여 수가 가장 많은 오브젝트를 기준 오브젝트라고 판단하거나, 복수의 학습된 모델 A, B, C, D 각각에 다른 가중치(또는 인자)가 부여되고 가중치(또는 인자)와 출력된 오브젝트 A 및 오브젝트 B에 대 한 확률 값을 곱한 값을 비교하는 등 다양한 방식에 따라 변형되어 실시될 수 있음은 물론이다. 도 6은 본 개시의 일 실시 예에 따른 학습부 및 인식부를 나타내는 블록도이다. 도 6의 (a)를 참조하면, 서버는 학습부 및 인식부 중 적어도 하나를 포함할 수 있다. 학습부는 이미지에 포함된 복수의 오브젝트 중에서 가장 식별력이 높은 오브젝트로 판단하기 위한 판단 기 준을 갖는 모델을 생성하거나 학습시킬 수 있다. 일 예로, 학습부는 학습 데이터(예: 차량의 전방을 촬영한 이미지, 위치 정보, 이미지에 포함된 복수의 오 브젝트 중에서 가장 식별력이 높은 오브젝트에 대해 판단한 결과 정보 등)를 이용하여 이미지에 포함된 복수의 오브젝트 중에서 어떤 오브젝트가 가장 식별력이 높은 오브젝트인지 판단하는 판단 기준을 갖는 모델을 학습 또 는 갱신시킬 수 있다. 인식부는 이미지 및 이미지에 대응되는 데이터를 학습된 모델의 입력 데이터로 사용하여, 이미지에 포함된 오브젝트를 추정할 수 있다. 일 예로, 인식부는 이미지에 포함된 적어도 하나의 오브젝트에 대한 특징 값을 학습된 모델의 입력 데이터 로 사용하여 오브젝트의 식별력을 나타내는 확률 값을 획득(또는, 추정, 추론)할 수 있다. 학습부의 적어도 일부 및 인식부의 적어도 일부는, 소프트웨어 모듈로 구현되거나 적어도 하나의 하 드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 학습부 및 인식부 중 적어도 하 나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치 또는 객체 인식 장치에 탑재될 수도 있다. 이 때, 인공 지능을 위한 전용 하드웨어 칩은 확률 연산에 특화된 전용 프로세서로서, 기존의 범용 프로세서보다 병렬처리 성능이 높아 기계 학습과 같은 인 공 지능 분야의 연산 작업을 빠르게 처리할 수 있다. 학습부 및 인식부가 소프트웨어 모듈(또는, 인 스트럭션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 이 경 우, 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션 에 의해 제공될 수 있다. 이 경우, 학습부 및 인식부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 학습부 및 인식부 중 하나는 본 개시의 전자 장치에 포함되 고, 나머지 하나는 외부의 서버에 포함될 수 있다. 또한, 학습부 및 인식부는 유/무선 방식의 통신을 수행하여, 학습부가 구축한 모델 정보를 인식부로 제공할 수도 있고, 인식부로 입력된 데이터가 추가 학습 데이터로서 학습부로 제공될 수도 있다. 도 7의 (b)를 참조하면, 일 실시 예에 따른 학습부는 학습 데이터 획득부(210-1) 및 모델 학습부(210-4)를 포함할 수 있다. 또한, 학습부는 학습 데이터 전처리부(210-2), 학습 데이터 선택부(210-3) 및 모델 평가 부(210-5) 중 적어도 하나를 선택적으로 더 포함할 수 있다. 학습 데이터 획득부(210-1)는 이미지에 포함된 오브젝트의 식별력을 판단하기 위한 모델에 필요한 학습 데이터 를 획득할 수 있다. 본 문서의 실시 예로, 학습 데이터 획득부(210-1)는 오브젝트를 포함하는 전체 이미지, 오 브젝트 영역에 대응하는 이미지, 오브젝트에 대한 정보 및 컨텍스트 정보 중 적어도 하나를 학습 데이터로서 획 득할 수 있다. 학습 데이터는 학습부 또는 학습부의 제조사가 수집 또는 테스트한 데이터가 될 수도 있다. 모델 학습부(210-4)는 학습 데이터를 이용하여, 모델이 이미지에 포함된 오브젝트를 어떻게 판단할 지에 관한 판단 기준을 갖도록 학습시킬 수 있다. 예로, 모델 학습부(210-4)는 학습 데이터 중 적어도 일부를 판단 기준으 로 이용하는 지도 학습(supervised learning)을 통하여, 분류 모델을 학습시킬 수 있다. 또는, 모델 학습부 (210-4)는, 예를 들어, 별다른 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 상황의 판단을 위한 판 단 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 분류 모델을 학습시킬 수 있다. 또한, 모델 학습부(210-4)는, 예를 들어, 학습에 따른 상황 판단의 결과가 올바른 지에 대한 피드백을 이용하는 강화 학습 (reinforcement learning)을 통하여, 분류 모델을 학습시킬 수 있다. 또한, 모델 학습부(210-4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 분류 모델을 학습시킬 수 있다 또한, 모델 학습부(210-4)는 입력 데이터를 이용하여 이미지에 포함된 오브젝트에 대한 식별력을 판단하기 위하 여 어떤 학습 데이터를 이용해야 하는 지에 대한 선별 기준을 학습할 수도 있다. 모델이 학습되면, 모델 학습부(210-4)는 학습된 모델을 저장할 수 있다. 이 경우, 모델 학습부(210-4)는 학습된 모델을 서버의 메모리(미도시) 또는 서버와 유/무선 네트워크로 연결되는 전자 장치의 메모리 에 저장할 수 있다. 학습부는 분류 모델의 분석 결과를 향상시키거나, 분류 모델의 생성에 필요한 자원 또는 시간을 절약하기 위하여, 학습 데이터 전처리부(210-2) 및 학습 데이터 선택부(210-3)를 더 포함할 수도 있다. 학습 데이터 전처리부(210-2)는 상황 판단을 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 학습 데이터 전처리부(210-2)는 모델 학습부(210-4)가 상황 판단을 위한 학습을 위하여 획득 된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부(210-3)는 학습 데이터 획득부(210-1)에서 획득된 데이터 또는 학습 데이터 전처리부(210- 2)에서 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 학습 데이터는 모델 학습부 (210-4)에 제공될 수 있다. 학습 데이터 선택부(210-3)는 기 설정된 선별 기준에 따라, 획득되거나 전처리된 데 이터 중에서 학습에 필요한 학습 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부(210-3)는 모델 학습부 (210-4)에 의한 학습에 의해 기 설정된 선별 기준에 따라 학습 데이터를 선택할 수도 있다. 학습부는 데이터 분류 모델의 분석 결과를 향상시키기 위하여, 모델 평가부(210-5)를 더 포함할 수도 있다. 모델 평가부(210-5)는 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부(210-4)로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 모 델을 평가하기 위한 기 정의된 데이터일 수 있다. 예를 들어, 모델 평가부(210-5)는 평가 데이터에 대한 학습된 분류 모델의 분석 결과 중에서, 분석 결과가 정확 하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 한편, 학습된 분류 모델이 복수 개가 존재하는 경우, 모델 평가부(210-5)는 각각의 학습된 분류 모델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 분류 모델로서 결정할 수 있다. 이 경 우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부(210-5)는 평가 점수가 높은 순으로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 분류 모델로서 결정할 수 있다. 도 7의 (c)를 참조하면, 일 실시 예에 따른 인식부는 인식 데이터 획득부(220-1) 및 인식 결과 제공부 (220-4)를 포함할 수 있다. 또한, 인식부는 인식 데이터 전처리부(220-2), 인식 데이터 선택부(220-3) 및 모델 갱신부(220-5) 중 적어 도 하나를 선택적으로 더 포함할 수 있다. 인식 데이터 획득부(220-1)는 상황 판단에 필요한 데이터를 획득할 수 있다. 인식 결과 제공부(220-4)는 인식 데이터 획득부(220-1)에서 획득된 데이터를 입력 값으로 학습된 분류 모델에 적용하여 상황을 판단할 수 있다. 인식 결과 제공부(220-4)는 데이터의 분석 목적에 따른 분석 결과를 제공할 수 있다. 인식 결과 제공부(220- 4)는 후술할 인식 데이터 전처리부(220-2) 또는 인식 데이터 선택부(220-3)에 의해 선택된 데이터를 입력 값으 로 모델에 적용하여 분석 결과를 획득할 수 있다. 분석 결과는 모델에 의해 결정될 수 있다. 인식부는 분류 모델의 분석 결과를 향상시키거나, 분석 결과의 제공을 위한 자원 또는 시간을 절약하기 위 하여, 인식 데이터 전처리부(220-2) 및 인식 데이터 선택부(220-3)를 더 포함할 수도 있다. 인식 데이터 전처리부(220-2)는 상황 판단을 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 인식 데이터 전처리부(220-2)는 인식 결과 제공부(220-4)가 상황 판단을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 정의된 포맷으로 가공할 수 있다. 인식 데이터 선택부(220-3)는 인식 데이터 획득부(220-1)에서 획득된 데이터 또는 인식 데이터 전처리부(220- 2)에서 전처리된 데이터 중에서 상황 판단에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 인식 결과 제공 부(220-4)에게 제공될 수 있다. 인식 데이터 선택부(220-3)는 상황 판단을 위한 기 설정된 선별 기준에 따라, 획득되거나 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 인식 데이터 선택부(220-3)는 모 델 학습부(210-4)에 의한 학습에 의해 기 설정된 선별 기준에 따라 데이터를 선택할 수도 있다. 모델 갱신부(220-5)는 인식 결과 제공부(220-4)에 의해 제공되는 분석 결과에 대한 평가에 기초하여, 학습된 모 델이 갱신되도록 제어할 수 있다. 예를 들어, 모델 갱신부(220-5)는 인식 결과 제공부(220-4)에 의해 제공되는 분석 결과를 모델 학습부(210-4)에게 제공함으로써, 모델 학습부(210-4)가 학습된 모델을 추가 학습 또는 갱신 하도록 요청할 수 있다. 한편, 서버는 프로세서(미도시)를 더 포함할 수 있으며, 프로세서는 서버의 전반적인 동작을 제어하 고, 상술한 학습부 또는 인식부를 포함하는 구성일 수 있다. 또한 서버는 이외에도 통신 인터페이스(미도시), 메모리(미도시), 프로세서(미도시)출력 인터페이스 중 하 나 이상을 더 포함할 수 있다. 이들에 대해서는 도 7의 전자 장치의 구성에 대한 설명이 동일하게 적용될 수 있다. 서버의 구성에 대한 설명은 전자 장치의 구성에 대한 설명과 중복된다는 점에서 생략하고, 이하에서는 전자 장치의 구성에 대해 구체적으로 설명하기로 한다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 상세히 도시한 블록도이다. 도 7을 참조하면, 전자 장치는 카메라, 센서, 출력 인터페이스, 프로세서 외에도 통 신 인터페이스, 메모리, 입력 인터페이스 중 하나 이상을 더 포함할 수 있다. 프로세서는 RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스(145-1~145- n), 버스를 포함할 수 있다. 이때, RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스(145-1~145-n) 등은 버스를 통해 서로 연결될 수 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 기기와 통신을 수행하여 다양한 유형의 데이터를 송수신할 수 있다. 통신 인터페이스는 무선 통신을 수행하는 블루투스 칩, 와이파이 칩, 무선 통신 칩 및 NFC 칩, 유선 통신을 수행하는 이더넷 모듈(미도시) 및 USB 모듈(미도시) 중 적어도 하나를 포함할 수 있다. 이 경우, 유선 통신을 수행하는 이더넷 모듈(미도시) 및 USB 모듈(미도시)은 입출력 포트(미도시)를 통하여 외부 기기와 통신을 수행할 수 있다. 메모리에는 전자 장치 또는 프로세서의 동작에 필요한 각종 명령어(instruction), 프로그램 또 는 데이터가 저장될 수 있다. 예를 들어, 메모리에는 카메라에 의해 획득된 이미지, 센서에 의 해 획득된 위치 정보, 서버로부터 수신된 학습된 모델 또는 데이터가 저장될 수 있다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서에 의해 액세스되며, 프로 세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시의 메모리라는 용어는 메모 리, 프로세서 내의 RAM, ROM 또는 전자 장치에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모리 스틱 등)를 포함할 수 있다. 입력 인터페이스는 다양한 방식의 사용자 명령(command)을 수신하여 프로세서로 전달할 수 있다. 즉, 프로세서는 입력 인터페이스를 통해 수신된 다양한 방식의 사용자 명령(command)에 따라 목적지를 설정할 수 있다. 입력 인터페이스는 예를 들면, 터치 패널, (디지털) 펜 센서 또는 키를 포함할 수 있다. 터치 패널은, 예 를 들면, 정전식, 감압식, 적외선 방식, 또는 초음파 방식 중 적어도 하나의 방식을 사용할 수 있다. 또한, 터 치 패널은 제어 회로를 더 포함할 수도 있다. 터치 패널은 택타일 레이어(tactile layer)를 더 포함하여, 사용 자에게 촉각 반응을 제공할 수 있다. (디지털) 펜 센서는 예를 들면, 터치 패널의 일부이거나, 별도의 인식용 쉬트를 포함할 수 있다. 키는 예를 들면, 물리적인 버튼, 광학식 키 또는 키패드를 포함할 수 있다. 또는, 입력 인터페이스는 키보드, 마우스 등과 같은 외부 장치(미도시)로부터 유선으로 연결되거나 또는 무선으로 연 결되어 사용자 입력을 수신할 수 있다. 입력 인터페이스는 사용자의 음성을 수신할 수 있는 마이크를 포함할 수 있다. 마이크는 전자 장치에 내장되거나 외부 장치로 구현되어 전자 장치에 유선 또는 무선으로 연결될 수 있다. 마이크는 사용자의 음 성을 직접 수신할 수 있으며, 디지털 변환부(미도시)에 의해 아날로그 신호인 사용자의 음성을 디지털로 변환하 여 오디오 신호를 획득할 수 있다. 한편, 전자 장치는 입출력 포트(미도시)를 더 포함할 수 있다. 입출력 포트는 전자 장치가 외부 장치(미도시)와 이미지 및/또는 음성에 대한 신호를 송신 및/또는 수신할 수 있도록, 전자 장치 및 외부 장치(미도시)를 유선으로 연결해주는 구성이다. 이를 위해, 입출력 포트는 HDMI 포트, 디스플레이 포트, RGB 포트, DVI(Digital Visual Interface) 포트, 썬더 볼트 포트, USB 포트 및 컴포넌트 포트 등 유선 포트로 구현될 수 있다. 일 예로, 전자 장치가 이미지 및/또는 음성을 출력할 수 있도록, 전자 장치는 입출력 포트를 통해 이 미지 및/또는 음성에 대한 신호를 외부 장치(미도시)로부터 수신할 수 있다. 다른 예로, 외부 장치(미도시)가 이미지 및/또는 음성을 출력할 수 있도록, 전자 장치는 입출력포트(미도시)를 통해 특정한 이미지 및/또는 음성에 대한 신호를 외부 장치로 송신할 수 있다. 이와 같이, 입출력 포트를 통해 이미지 및/또는 음성에 대한 신호가 일방향으로 전송될 수 있다. 다만, 이는 일 실시 예일 뿐, 입출력 포트를 통해 이미지 및/또는 음성에 대한 신호가 양방향으로 전송될 수 있음은 물론이다. 도 8은 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다. 도 8을 참조하면, 본 개시의 일 실시 예에 따른 차량에 포함된 전자 장치의 제어 방법은 차량의 위치 정보 및 차량의 전방을 촬영한 이미지에 기초하여, 차량의 목적지까지의 경로에 포함된 복수의 구간에 대응되는 복수 의 학습된 모델로부터 경로 상에 존재하는 오브젝트에 대한 정보를 획득하는 단계 및 차량의 목적지까지의 경로 상에 존재하는 오브젝트에 대한 정보를 기초로, 경로에 대한 안내 정보를 출력하는 단계를 포함할 수 있다. 구체적으로, 먼저 차량의 위치 정보 및 차량의 전방을 촬영한 이미지에 기초하여, 차량의 목적지까지의 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델로부터 경로 상에 존재하는 오브젝트에 대한 정보를 획득할 수 있다(S810). 여기에서, 오브젝트는 경로 상에 존재하는 건물을 포함할 수 있다. 이때, 복수의 학습된 모델 각각은 특정 위치에서 촬영된 이미지에 기초하여, 이미지에 포함된 복수의 오브젝트 중에서 특정 위치에서 식별될 확률이 가장 높은 오브젝트를 판단하도록 학습된 모델을 포함할 수 있다. 그리고, 복수의 학습된 모델 각각은 경로가 분기점을 기준으로 구분된 복수의 구간 각각에서 촬영된 이미지에 기초하여 학습된 모델을 포함할 수 있다. 또한, 복수의 구간은 경로에 존재하는 분기점을 기준으로 구분될 수 있다. 다음으로, 차량의 목적지까지의 경로 상에 존재하는 오브젝트에 대한 정보를 기초로, 경로에 대한 안내 정보를 출력할 수 있다(S820). 이 경우, 건물을 기초로 차량의 진행 방향 및 진행 거리 중 적어도 하나와 관련된 안내 정보를 출력할 수 있다. 또한, 출력하는 단계는 스피커 및 디스플레이 중 적어도 하나를 통해 안내 정보를 출력 할 수 있다. 한편, 본 개시의 일 실시 예에 따르면, 출력하는 단계는 경로에 대한 정보, 차량의 위치 정보 및 차량의 전방을 촬영한 이미지를 서버로 전송하는 단계 및 서버로부터 안내 정보를 수신하여 출력하는 단계를 더 포 함할 수 있다. 구체적으로, 경로에 대한 정보, 차량의 위치 정보 및 차량의 전방을 촬영한 이미지를 서버로 전송할 수 있 다. 이 경우, 서버는 기저장된 학습된 모델 중에서 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델을 판단하고, 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 오브젝트에 대한 정보를 획득하고, 오브젝트에 대한 정보를 기초로 안내 정보를 획득할 수 있다. 그리고, 서버로부터 경로에 대한 안내 정보를 수신하고, 경로에 대한 안내 정보를 출력할 수 있다. 한편, 본 개시의 다른 일 실시 예에 따르면, 본 개시의 출력하는 단계는 경로에 대한 정보를 서버로 전송 하고, 서버로부터 경로에 포함된 복수의 구간에 대응되는 복수의 학습된 모델을 수신하고, 이미지를 복수 의 학습된 모델 중 차량의 위치 정보에 대응되는 학습된 모델의 입력 데이터로서 사용하여, 오브젝트에 대한 정 보를 획득할 수 있다. 구체적으로, 경로에 대한 정보를 서버로 전송할 수 있다. 이 경우, 서버로부터 경로에 포함된 복수의 구간 에 대응되는 복수의 학습된 모델을 수신하고, 이미지를 복수의 학습된 모델 중 차량의 위치 정보에 대응되는 학 습된 모델의 입력 데이터로서 사용하여, 오브젝트에 대한 정보를 획득할 수 있다. 그리고, 오브젝트에 대한 정 보에 기초하여, 경로에 대한 안내 정보를 출력할 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는 저장 매체로부터 저장된 명령 어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치(예: 전자 장치)를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세 서의 제어 하에 다른 구성요소들을 이용하여 상기 명령에 상기하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는 비일시적 (non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하 지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분 하지 않는다. 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽 을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 상기 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 상기 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2019-0019485", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 시스템을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 학습 데이터에 따라 모델을 학습시키는 방법을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 오브젝트를 판단하는 방법을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 학습부 및 인식부를 나타내는 블록도이다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 상세히 도시한 블록도이다. 도 8은 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다."}
