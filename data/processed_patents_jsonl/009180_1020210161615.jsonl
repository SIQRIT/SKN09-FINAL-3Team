{"patent_id": "10-2021-0161615", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0030494", "출원번호": "10-2021-0161615", "발명의 명칭": "대화 모델 훈련 방법 및 장치", "출원인": "하이퍼커넥트 유한책임회사", "발명자": "서석준"}}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에서 대화 모델을 훈련하는 방법에 있어서, 컨텍스트(context)와 그에 대응되는 응답(response) 쌍(pair)을 하나 이상 포함하는 제1 대화 데이터 세트(dialogue data set)에서 제1 컨텍스트를 선택하는 단계;제1 대화 모델을 통해 상기 제1 컨텍스트에 대응되는 제1 응답을 생성하는 단계;상기 제1 컨텍스트와 그에 대응되는 상기 제1 응답 쌍을 상기 제1 대화 데이터 세트에 포함시켜 증강된 대화 데이터 세트(augmented dialogue dataset)를 생성하는 단계; 및상기 증강된 대화 데이터 세트를 기초로 제2 대화 모델을 학습시키는 단계를 포함하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 대화 모델은 주어진(given) 컨텍스트에 대하여 응답을 생성하는 생성 기반 대화 모델이고, 상기 제2대화 모델은 상기 주어진 컨텍스트에 대하여 응답을 검색하는 검색 기반 대화 모델인, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 대화 데이터 세트의 응답 및 상기 제1 응답을 포함하는 증강된 응답 세트(augmented response set)를생성하는 단계를 더 포함하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 학습시키는 단계는,상기 증강된 대화 데이터 세트에 포함된 제2 컨텍스트에 대응하는 제1 응답 서브 세트 및 임의로 선택된 제2 응답 서브 세트를 포함하는 응답 세트를 획득하는 단계; 상기 제1 대화 모델을 기반으로 상기 제2 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제1 스코어를계산하는 단계; 상기 제2 대화 모델을 기반으로 상기 제2 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제2 스코어를계산하는 단계; 및상기 제1 스코어 및 상기 제2 스코어를 기반으로 상기 제2 대화 모델을 학습시키는 단계를 포함하는, 대화 모델훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2023-0030494-3-상기 제1 스코어 및 상기 제2 스코어를 기반으로 상기 제2 대화 모델을 학습시키는 단계는:상기 제1 스코어 및 상기 제2 스코어에 기초하여 손실(loss)을 계산하는 단계; 및상기 손실이 최소화 되도록 상기 제2 대화 모델을 학습시키는 단계를 포함하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "전자 장치에서 대화 모델을 훈련하는 방법에 있어서,제1 대화 데이터 세트에서 제1 컨텍스트에 대응하는 제1 응답 서브 세트 및 임의로 선택된 제2 응답 서브 세트를 포함하는 응답 세트를 획득하는 단계; 제1 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제1 스코어를 계산하는 단계; 제2 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제2 스코어를 계산하는 단계; 및상기 제1 스코어 및 상기 제2 스코어를 기반으로 상기 제2 대화 모델을 학습시키는 단계를 포함하는, 대화 모델훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1 대화 모델은 주어진 컨텍스트에 대하여 응답을 생성하는 생성 기반 대화 모델이고, 상기 제2 대화 모델은 상기 주어진 컨텍스트에 대하여 응답을 검색하는 검색 기반 대화 모델인, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,컨텍스트와 그에 대응되는 응답 쌍을 하나 이상 포함하는 제2 대화 데이터 세트에서 제2 컨텍스트를 선택하는단계;상기 제1 대화 모델을 통해 상기 제2 컨텍스트에 대응되는 응답을 생성하는 단계; 및상기 제2 컨텍스트와 그에 대응되는 응답 쌍을 상기 제2 대화 데이터 세트에 포함시켜 상기 제1 대화 데이터 세트를 생성하는 단계를 포함하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 제2 스코어를 계산하는 단계는:상기 제1 컨텍스트 및 상기 응답 세트에 포함된 응답에 대하여 고정 길이 임베딩(fixed-length embedding)으로인코딩하는 단계; 및상기 제1 컨텍스트에 대응되는 임베딩 값 및 상기 응답 세트에 포함된 응답 각각에 대응되는 임베딩 값에 기초하여, 상기 응답 세트에 포함된 응답 각각의 상기 제1 컨텍스트에 대한 관련성 스코어(relevance score)를 계산하는 단계를 포함하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2023-0030494-4-제6항에 있어서,상기 제1 스코어는, 상기 응답 세트에 포함된 응답 각각의 길이에 기초하여 정규화된 로그 가능도(loglikelihood)를 이용하여 계산되는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항에 있어서,상기 제1 스코어는, 상기 응답 세트에 포함된 응답 각각의 상기 제1 컨텍스트에 대한 상호 정보(MutualInformation) 점수에 기초하여 계산되는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제6항에 있어서,상기 제2 대화 모델을 학습시키는 단계는:상기 제1 스코어 및 상기 제2 스코어에 기초하여 손실(loss)을 계산하는 단계; 및상기 손실이 최소화 되도록 상기 제2 대화 모델을 학습시키는 단계를 포함하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 손실은, 상기 제1 응답 서브 세트에 대응되는 스코어에 대한 교차 엔트로피(cross entropy) 손실 및 상기응답 세트에 포함된 응답에 대응되는 스코어에 대한 지식 증류(knowledge distillation) 손실을 포함하는, 대화모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 손실이 최소화 되도록 상기 제2 대화 모델을 학습하는 단계는, 상기 제1 응답 서브 세트에 대응되는 스코어를 최대화하여 상기 교차 엔트로피 손실이 최소화되도록 학습하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 손실이 최소화 되도록 상기 제2 대화 모델을 학습하는 단계는, 상기 제1 스코어와 상기 제2 스코어가 일치하여 상기 지식 증류 손실이 최소화되도록 학습하는, 대화 모델 훈련 방법."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제6항의 대화 모델 훈련 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 비일시적 기록매체."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2023-0030494-5-대화 모델을 훈련시키기 위한 전자 장치에 있어서,저장 디바이스; 및 제어부(controller)를 포함하고,상기 제어부는,상기 저장 디바이스를 통해, 제1 대화 데이터 세트에서 제1 컨텍스트에 대응하는 제1 응답 서브 세트 및 임의로선택된 제2 응답 서브 세트를 포함하는 응답 세트를 획득하고,제1 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제1 스코어를 계산하고,제2 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제2 스코어를 계산하고,상기 제1 스코어 및 상기 제2 스코어를 기반으로 상기 제2 대화 모델을 학습시키는, 전자 장치."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 제어부는, 컨텍스트와 그에 대응되는 응답 쌍을 하나 이상 포함하는 제2 대화 데이터 세트에서 제2 컨텍스트를 선택하고,상기 제1 대화 모델을 통해 상기 제2 컨텍스트에 대응되는 응답을 생성하고,상기 제2 컨텍스트와 그에 대응되는 응답 쌍을 상기 제2 대화 데이터 세트에 포함시켜 상기 제1 대화 데이터 세트를 생성하는, 전자 장치."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 제어부는,상기 제2 대화 데이터 세트의 응답 및 상기 제2 컨텍스트에 대응되는 응답을 포함하는 증강된 응답 세트를 생성하고,상기 저장 디바이스를 통해 상기 증강된 응답 세트를 저장하는, 전자 장치."}
{"patent_id": "10-2021-0161615", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,상기 제어부는, 상기 제2 대화 모델을 학습시키기 위해,상기 제1 스코어 및 상기 제2 스코어에 기초하여 손실을 계산하고,상기 손실이 최소화 되도록 상기 제2 대화 모델을 학습시키며,상기 손실은, 상기 제1 응답 서브 세트에 대응되는 스코어에 대한 교차 엔트로피 손실 및 상기 응답 세트에 포함된 응답에 대응되는 스코어에 대한 지식 증류 손실을 포함하는, 전자 장치."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 전자 장치를 통해 대화 모델을 훈련하는 방법은, 컨텍스트와 그에 대응되는 응답 쌍을 하나 이상 포함 하는 제1 대화 데이터 세트에서 제1 컨텍스트를 선택하는 단계; 제1 대화 모델을 통해 상기 제1 컨텍스트에 대응 되는 제1 응답을 생성하는 단계; 상기 제1 컨텍스트와 그에 대응되는 상기 제1 응답 쌍을 상기 제1 대화 데이터 세트에 포함시켜 증강된 대화 데이터 세트를 생성하는 단계; 및 상기 증강된 대화 데이터 세트를 기초로 제2 대 화 모델을 학습시키는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 사용자 대화 모델을 훈련하는 방법 및 이를 위한 장치에 관한 것이다."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술이 발달함에 따라 사람들은 실존하는 인물이 아닌 가상의 인물로서 챗봇과 대화할 수 있게 되었다. 이와 같은 챗봇은 정해진 대화 주제에 따라 정해진 응답을 검색하여 출력할 수도 있고, 또는 자유로운 대화 주제에 대해 적절한 응답을 생성하여 출력할 수도 있다. 이러한 특정한 대화 주제가 정해지지 않은 대화를 오픈 도메인 대화(open domain conversation)라고 할 수 있다. 오픈 도메인 대화에서 응답을 도출하기 위해 크게 두 가지의 대화 모델로서 생성 기반 대화 모델과 검색 기반 대화 모델이 사용된다. 생성 기반 대화 모델은 입력된 대화 컨텍스트(context)를 기반으로 적절한 답변을 생성 하여 답변으로 반환하는 모델이다. 그리고 검색 기반 대화 모델은 답변으로 사용될 수 있는 응답 세트(response set)를 미리 정의한 뒤 입력된 대화 컨텍스트에 가장 적절한 답변을 응답 세트에서 검색하여 답변으로 반환하는 모델이다. 이와 같은 생성 기반 대화 모델은 큰 규모(large-scale)의 언어 모델을 함께 사용하였을 때, 해당 언어 모델의 풍부한 지식을 기반으로 주어진 대화 컨텍스트에 어울리는 답변을 생성할 수 있다. 그러나, 생성 기반 대화 모 델은 시퀀스 대 시퀀스 구조의 디코더가 자기 회귀적인(autoregressive) 디코딩 과정에 많은 시간을 소요하므로, 답변 생성에 높은 레이턴시(latency)를 갖는다. 실제 대화 상황에서 챗봇은 사용자에게 실시간으로 답변을 반환해줘야 하므로, 생성 기반 대화 모델의 이러한 무겁고 느린 특성은 오픈 도메인 대화에 적용되기 어 려운 실정이다. 반면에 검색 기반 대화 모델은 고성능 검색 라이브러리와 함께 사용하였을 때 생성 기반 대화 모델보다 훨씬 빠 르게 주어진 컨텍스트에 적절한 답변을 반환해줄 수 있다. 그러나, 검색 기반 대화 모델은 사전에 정의된 응답 세트에 존재하는 답변만을 반환하여 줄 수 있기 때문에 입력된 대화 컨텍스트에 적절한 응답이 응답 세트에 포 함되어 있지 않은 경우, 진행되고 있던 대화와 관계없는 엉뚱한 대답을 반환할 우려가 있다. 또한, 검색 기반 대화 모델은 사전에 정의된 응답 세트에 매우 의존적이기 때문에 생성 기반 모델에 비해 유창하지 못한 답변을 반환할 수도 있다."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 대화 컨텍스트에 대해 생성 기반 대화 모델을 통해 응답을 생성하고, 생성된 응답을 기반으로 검색 기반 대화 모델을 위한 응답 세트를 구축함으로써, 생성 기반 대화 모델의 높은 응답 레이턴시 문제를 해결하기 위한 것이다. 본 개시는 대화 컨텍스트에 대해 생성 기반 대화 모델을 통해 응답을 생성하고, 생성된 응답을 기반으로 검색 기반 대화 모델을 학습함으로써, 검색 기반 대화 모델의 상대적으로 낮은 답변 퀄리티를 해결하기 위한 것이다. 본 개시에서 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 이하의 실시예 들로부터 또 다른 기술적 과제들이 유추될 수 있다."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 과제를 해결하기 위한 전자 장치에서 수행되는 대화 모델 훈련 방법은, 컨텍스트(context)와 그에 대응되는 응답(response) 쌍(pair)을 하나 이상 포함하는 제1 대화 데이터 세트(dialogue data set)에서 제1 컨텍스트를 선택하는 단계; 제1 대화 모델을 통해 상기 제1 컨텍스트에 대응되는 제1 응답을 생성하는 단계; 상 기 제1 컨텍스트와 그에 대응되는 상기 제1 응답 쌍을 상기 제1 대화 데이터 세트에 포함시켜 증강된 대화 데이 터 세트(augmented dialogue dataset)를 생성하는 단계; 및 상기 증강된 대화 데이터 세트를 기초로 제2 대화 모델을 학습시키는 단계를 포함할 수 있다. 또한, 상기와 같은 과제를 해결하기 위한 전자 장치에서 수행되는 또 다른 대화 모델 훈련 방법은, 제1 대화 데 이터 세트에서 제1 컨텍스트에 대응하는 제1 응답 서브 세트 및 임의로 선택된 제2 응답 서브 세트를 포함하는 응답 세트를 획득하는 단계; 제1 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제1 스코어를 계산하는 단계; 제2 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제2 스코어를 계산하는 단계; 및 상기 제1 스코어 및 상기 제2 스코어를 기반으로 상기 제2 대화 모델을 학습시키는 단계를 포함할 수 있다. 또한, 상기와 같은 과제를 해결하기 위한 대화 모델을 훈련시키기 위한 전자 장치는 저장 디바이스; 및 제어부 (controller)를 포함하고, 상기 제어부는, 상기 저장 디바이스를 통해, 제1 대화 데이터 세트에서 제1 컨텍스트 에 대응하는 제1 응답 서브 세트 및 임의로 선택된 제2 응답 서브 세트를 포함하는 응답 세트를 획득하고, 제1 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제1 스코어를 계산하고, 제2 대화 모델을 기반으로 상기 제1 컨텍스트에 대한 상기 응답 세트에 포함된 응답에 대한 제2 스코어를 계산 하고, 상기 제1 스코어 및 상기 제2 스코어를 기반으로 상기 제2 대화 모델을 학습시킬 수 있다. 기타 실시 예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 검색 기반 대화 모델이, 큰 규모의 언어 모델의 풍부한 지식을 바탕으로 유창한 답변을 생성 해내는 생성 기반 대화 모델의 답변 퀄리티에 대응되는 답변을 반환해 줄 수 있다. 또한, 본 개시에 따르면, 생성 기반 대화 모델의 높은 레이턴시 문제를 해결하고, 검색 기반 대화 모델의 답변 퀄리티를 높일 수 있는 효과가 있다."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "발명의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부 터 당해 기술 분야의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시 예들에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또 는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서 기재된 \"a, b, 및 c 중 적어도 하나\"의 표현은, 'a 단독', 'b 단독', 'c 단독', 'a 및 b', 'a 및 c', 'b 및 c', 또는 'a, b, 및 c 모두'를 포괄할 수 있다. 이하에서 언급되는 \"단말\"은 네트워크를 통해 서버나 타 단말에 접속할 수 있는 컴퓨터나 이동 단말기로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop) 등을 포함하고, 이동 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, IMT(International Mobile Telecommunication), CDMA(Code Division Multiple Access), W-CDMA(W-Code Division Multiple Access), LTE(Long Term Evolution) 등의 통신 기반 단말, 스마트폰, 태블릿 PC 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다.본 개시의 기술 분야인 오픈 도메인 대화의 작업은 검색 모델, 생성 모델 또는 둘 다를 사용하여 연구되었다. 검색 모델이 미리 정의된 응답 세트에서 주어진 컨텍스트와 관련된 응답을 검색하는 동안 생성 모델은 자동 회 귀 디코딩을 사용하여 주어진 컨텍스트를 기반으로 응답을 생성한다. 검색 및 생성 모델은 추론의 효율성과 생 성된 응답의 품질에서 각각 장점이 있는 것으로 알려져 있다. 두 가지 이점을 모두 취하기 위해 최근에는 검색 모델과 생성 모델을 결합하여 몇 가지 예제 기반 생성 모델이 제안되었다. 본 개시에서 제안되는 훈련 방법과 예제 기반 생성 모델의 주요 차이점은 예제 기반 생성 모델은 생성 모델에 검색 모델에 대한 지식을 제공하는 반면, 제안된 교육 방법은 생성 모델에 대한 지식을 검색 모델에 전달하여 오픈 도메인 대화 시스템의 효율성에 중점을 둔다는 점에 있다. 보다 구체적으로, 오픈 도메인 대화에서 대규모 생성 모델은 그 놀라운 성능에도 불구하고 높은 레이턴시로 인 해 실시간 대화 시스템을 구축하는 데 실용적이지 않은 것으로 알려져 있다. 반면, 검색 모델은 훨씬 짧은 레이 턴시로 응답을 반환할 수 있지만 대화 품질이 미리 정의된 응답 집합에 의해 제한되기 때문에 대규모 생성 모델 보다 열등한 성능을 보인다. 두 가지 접근 방식을 모두 활용하기 위해, 본 개시는 생성 모델에 대한 지식을 검 색 모델에 주입하여 대규모 생성 모델의 대화 능력을 활용하면서 검색 모델의 효율성을 유지하는 G2R(Generative-to-Retrieval distillation)이라는 새로운 학습 방법을 제안한다. G2R은 두 가지 고유한 증류 (distillation) 기술로 구성될 수 있다. 먼저, 데이터 수준(data-level) G2R은 대규모 생성 모델에 의해 생성된 추가 응답으로 대화 데이터 세트를 보강하고, 모델 수준(model-level) G2R은 생성 모델에 의해 평가된 응답 품 질 점수를 지식 증류 손실에 의한 검색 모델의 점수로 이전한다. 인적 평가를 포함한 광범위한 실험을 통해 본 개시의 G2R로 훈련된 검색 기반 대화 시스템이 기본 검색 모델에 비해 상당히 향상된 성능을 보여주면서도 대규 모 생성 모델보다 훨씬 낮은 추론 지연 시간을 보여준다는 것을 확인할 수 있다. 이를 위해 실시 예에서는 검색 모델의 학습을 위한 컨텍스트-응답 쌍의 대화 데이터 세트들 중 적어도 일부의 컨텍스트를 선택하여 생성 모델을 활용하여 응답을 생성함으로써 새로운 컨텍스트-응답 쌍을 생성하고, 생성된 컨텍스트-응답 쌍의 증강된 대화 데이터 세트를 활용하여 검색 모델을 학습시킴으로써 검색 모델이 보다 다양한 답변을 생성할 수 있다. 또한 실시 예에서 특정 컨텍스트에 대해서 복수의 응답 세트를 확인하고, 이를 각기 다른 모델을 통해 응답 세 트의 각 응답의 스코어를 도출하고, 각 모델의 응답 세트의 스코어 차이를 줄이는 방향으로 하나의 모델을 학습 시킬 수 있다. 보다 구체적으로 생성 모델을 교사 모델로 하고, 검색 모델을 학생 모델로 하여 응답 세트에 대 한 스코어의 교차 엔트로피 손실을 도출하고, 각 스코어 사이의 차이를 줄이는 방향으로 검색 모델을 학습시킴 으로써 검색 모델의 성능을 보다 향상시킬 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 또한, 본 개시에서 언급된 '제1' 및 '제2' 등과 같은 표현은 용어들 간에 구분을 위하여 기재된 것으로, 해당 표현에 의해 의미가 제한되지는 않는다. 도 1은 일 실시 예에 따른 데이터 수준 대화 모델 훈련 방법을 나타낸 흐름도이다. 단계 S101에서 컨텍스트와 그에 대응되는 응답 쌍을 하나 이상 포함하는 제1 대화 데이터 세트에서 제1 컨텍스 트를 선택할 수 있다. 일 실시 예에 따르면, 제1 대화 데이터 세트의 응답은 사전에 정의된 응답 세트에 포함된 응답일 수 있다. 단계 S102에서 제1 대화 모델을 통해 제1 컨텍스트에 대응되는 제1 응답을 확인할 수 있다. 일 실시 예에 따르 면, 제1 대화 모델은 주어진(given) 컨텍스트에 대하여 응답을 생성하는 생성 기반 대화 모델일 수 있다. 단계 S103에서 제1 컨텍스트와 그에 대응되는 제1 응답 쌍을 포함하는 증강된 대화 데이터 세트(augmented dialogue dataset)를 생성할 수 있다. 일 실시 예에 따르면, 본 개시의 대화 모델 훈련 방법은, 제1 대화 데이 터 세트의 응답 및 생성된 제1 응답을 포함하는 증강된 응답 세트(augmented response set)를 생성하여 이후에 입력되는 대화 컨텍스트에 대한 고정된 응답 세트로 활용할 수도 있다. 단계 S104에서 증강된 대화 데이터 세트를 기초로 제2 대화 모델을 학습시킬 수 있다. 일 실시 예에 따르면, 제 2 대화 모델은 주어진 컨텍스트에 대하여 응답을 검색하는 검색 기반 대화 모델일 수 있다. 일 실시 예에 따르면, 제2 대화 모델을 학습하는 일환으로, 증강된 대화 데이터 세트에 포함된 제2 컨텍스트를 확인하고, 제2 컨텍스트에 대응하는 제1 응답 서브 세트 및 임의로 선택된 제2 응답 서브 세트를 포함하는 응답세트를 획득할 수 있다. 그리고, 제1 대화 모델을 기반으로 제2 컨텍스트에 대한 응답 세트에 포함된 응답에 대 한 제1 스코어를 계산하고, 제2 대화 모델을 기반으로 제2 컨텍스트에 대한 응답 세트에 포함된 응답에 대한 제 2 스코어를 계산할 수 있다. 그리고, 제1 스코어 및 제2 스코어를 기반으로 제2 대화 모델을 학습할 수 있다. 이때 제1 스코어를 기초로 제2 스코어에 대한 손실(loss)을 계산하여, 손실이 최소화 되는 방향으로 제2 대화 모델을 학습할 수 있다. 도 2는 일 실시 예에 따른 모델 수준 대화 모델 훈련 방법을 나타낸 흐름도이다. 단계 S201에서 제1 대화 데이터 세트에서 제1 컨텍스트에 대응하는 제1 응답 서브 세트 및 임의로 선택된 제2 응답 서브 세트를 포함하는 응답 세트를 획득할 수 있다. 일 실시 예에 따르면, 컨텍스트와 그에 대응되는 응답 쌍을 하나 이상 포함하는 제2 대화 데이터 세트에서 제2 컨텍스트를 선택하고, 제1 대화 모델을 통해 제2 컨텍 스트에 대응되는 응답을 생성하고, 제2 컨텍스트와 그에 대응되는 응답 쌍을 제2 대화 데이터 세트에 포함시켜 제1 대화 데이터 세트를 생성할 수 있다. 이에 따라 제1 대화 데이터 세트는 증강된 대화 데이터 세트일 수 있 다. 단계 S202에서 제1 대화 모델을 기반으로, 제1 컨텍스트에 대한 응답 세트에 포함된 응답에 대한 제1 스코어를 계산할 수 있다. 일 실시 예에 따르면, 제1 스코어는, 응답 세트에 포함된 응답 각각의 길이에 기초하여 정규화 된 로그 가능도(log likelihood)를 이용하여 계산될 수 있다. 또는, 제1 스코어는, 응답 세트에 포함된 응답 각 각의 제1 컨텍스트에 대한 상호 정보(Mutual Information) 점수에 기초하여 계산될 수도 있다. 단계 S203에서 제2 대화 모델을 기반으로, 제1 컨텍스트에 대한 응답 세트에 포함된 응답에 대한 제2 스코어를 계산할 수 있다. 일 실시 예에 따르면, 제1 컨텍스트 및 응답 세트에 포함된 응답에 대하여 고정 길이 임베딩 (fixed-length embedding)으로 인코딩하고, 제1 컨텍스트에 대응되는 임베딩 값 및 응답 세트에 포함된 응답 각 각에 대응되는 임베딩 값에 기초하여 응답 세트에 포함된 응답 각각의 제1 컨텍스트에 대한 관련성 스코어 (relevance score)를 계산하여, 제2 스코어를 계산할 수 있다. 단계 S204에서 제1 스코어 및 제2 스코어를 기반으로 제2 대화 모델을 학습시킬 수 있다. 일 실시 예에 따르면, 제1 스코어 및 제2 스코어에 기초하여 손실을 계산하고, 이러한 손실이 최소화 되도록 제2 대화 모델을 학습시 킬 수 있다. 이때 손실은, 제1 응답 서브 세트에 대응되는 스코어에 대한 교차 엔트로피(cross entropy) 손실 및 응답 세트에 포함된 응답에 대응되는 스코어에 대한 지식 증류(knowledge distillation) 손실을 포함할 수 있다. 또한, 제2 대화 모델은, 제1 응답 서브 세트에 대응되는 스코어를 최대화하여 교차 엔트로피 손실이 최소 화되도록 학습할 수 있으며, 제1 스코어와 제2 스코어가 일치하여 지식 증류 손실이 최소화되도록 학습할 수도 있다. 도 3은 오픈 도메인 대화 모델들에 대한 레이턴시 대 인적 평가 점수를 나타낸 그래프이다. 이하에서는 검색 기 반 대화 모델을 '검색 모델'로, 생성 기반 대화 모델을 '생성 모델'로 지칭하기로 한다. 최근, 생성 모델은 대규모 언어 모델의 개발과 함께 오픈 도메인 대화에서 큰 성공을 거두었으며 유창하고 유익 한 응답을 제공했다. 그러나, 생성 모델은 응답 생성을 위한 자동 회귀 디코딩과 큰 GPU 메모리 공간으로 인해 실시간 대화 시스템을 구축하기 위한 레이턴시 및 계산 리소스 문제가 있었다. 한편, 이중 인코더(Bi-encoder) 및 폴리 인코더(Poly-encoder)와 같은 검색 모델은 응답 세트를 미리 정의하고 응답 세트에서 주어진 컨텍스트에 가장 관련성이 높은 응답을 검색하여 효율적인 오픈 도메인 대화 시스템을 구 축할 수 있었다. 또한 이중 인코더는 FAISS 및 ScaNN과 같은 효율적인 MIPS(Maximum Inner Product Search) 라 이브러리를 채택할 때의 레이턴시를 크게 줄일 수 있다. 이러한 뛰어난 효율성에도 불구하고 검색 모델은 생성 모델에 비해 대화 능력이 다소 부족한 것으로 나타난다. 특히 검색 모델은 미리 정의된 응답 세트가 주어진 컨 텍스트에 대한 적절한 응답을 포함하지 않을 때 잘못된 응답을 반환하는 것으로 알려져 있는 반면, 생성 모델은 이러한 경우를 보다 유연하게 처리하는 경향이 있다. 이러한 문제를 완화하려고 시도하기 위해, 두 접근 방식의 장점을 결합하는 예제 기반 생성 모델(Exemplar- based generative models)이 고려되었으나, 생성 모델의 고유한 비효율성은 여전히 남아 있었다. 이는 예제 기 반 생성 모델이 응답 생성을 위해 생성 모델을 사용하기 때문이다. 이에 따라 본 개시는 실제 적용에 필수인 효 율적이면서도 유창한 오픈 도메인 대화 시스템을 만들기 위해 G2R(Generative-to-Retrieval distillation)이라 는 검색 모델에 대한 새로운 훈련 방법을 제안한다. 일 실시 예에 따르면, G2R을 사용하면 검색 모델이 데이터 수준과 모델 수준 모두에서 대규모 생성 모델에 대한 지식을 활용할 수 있다. 첫째, 데이터 수준 G2R은 원래 대화 데이터 세트의 컨텍스트를 사용하여 대규모 생성모델에서 생성된 응답으로 원래 대화 데이터 세트를 보강하고, 생성된 응답을 미리 정의된 응답 집합에 추가할 수 있다. 이렇게 증강된 대화 데이터 세트와 응답 세트는 각각 훈련 단계에서 검색 모델을 훈련하고 추론 단계 에서 응답을 반환하는 데 사용된다. 한편, 데이터 수준 G2R은 검색 모델이 대규모 생성 모델에서 생성된 고품질 응답을 활용할 수 있도록 하지만 개별 응답의 품질에 대한 생성 모델의 세부적인 지식을 전달하지 않는다. 이를 해결하기 위하여 모델 수준의 G2R은 대규모 교사(teacher) 생성 모델에서 평가한 응답 품질 점수를 학생 검색 모델의 점수로 전송하는 지식 증류 방식을 이용한다. 이 방법은 검색 모델이 응답 품질 측면에서 더 나은 응답 을 선택하도록 유도할 수 있다. 이러한 더 큰 규모의 교사 신경망에서 소규모의 학생 신경망으로 지식을 전송하는 것은 데이터 증강 및 지식 증 류를 포함하여 학생 모델의 성능을 향상시키기 위해 구현되었다. 데이터 증강 관점에서 여러 연구들은 사전 훈 련된 언어 모델의 생성 결과를 텍스트 분류 작업에 대한 레이블이 지정된 예제로 활용한다. 일부 연구는 검색 모델과 생성 모델의 추론 결과를 학생 검색 모델 훈련을 위한 준음성(semi-negative) 데이터 세트로 활용한다. 한편, 지식 증류는 학생 로짓(logit)을 연화된 교사 로짓(softened teacher logit)과 일치시켜 교사 모델의 지 식을 학생 모델로 전달한다. 시퀀스 생성 작업, 검색 모델 및 트랜스포머 아키텍처와 같은 특정 작업 또는 모델 아키텍처를 위해 특별히 설계된 지식 증류가 존재한다. 본 개시의 대화 모델 훈련 방법과 가장 관련된 작업은 대화 증류(Dialogue Distillation)로, 대화 증류는 오픈 도메인 대화 모델에 대한 데이터 수준 및 모델 수준 증류를 제안한다. 그러나 본 개시의 대화 모델 훈련 방법은 세 가지 측면에서 대화 증류와 다르다. 첫째, 대화 증류는 짝을 이루지 않은 추가 텍스트 말뭉치를 필요로 하며 이는 특정 상황에서 얻기 어려울 수 있다. 대신에 대화 증류 작업은 추가 데이터를 보강하기 위해 대규모 생성 모델에 대한 지식을 활용하는 데 중점을 둔다. 또한 대화 증류는 사전 정의된 응답 세트를 풍부하게 하지 않는 다. 이는 본 개시의 대화 모델 훈련 방법에 대한 실험 결과에서도 볼 수 있듯이 검색 모델의 성능을 향상시키는 데 중요하다. 마지막으로 대화 증류는 생성-생성(Generative-to-Generative) 또는 검색-검색(Retrieval-to- Retrieval)과 같은 균질한(homogeneous) 아키텍처 내에서만 지식 증류를 고려하지만, 본 개시의 대화 모델 훈련 방법은 각 아키텍처의 이점을 활용하기 위해 이기종(heterogeneous) 아키텍처, 특히 생성-검색(Generative-to- Retrieval) 사이의 모델 수준 증류에 중점을 둔다. 도 3을 참조하면, 흰색 원은 생성 기반 대화 모델, 검정색 원은 검색 기반 대화 모델, 별은 본 개시의 대 화 모델 훈련 방법을 통해 훈련된 대화 모델(예를 들어, G2R)을 나타낸다. 도 3을 통해 본 개시의 대화 모델이 검색 기반 대화 모델보다 훨씬 더 나은 인적 평가 점수를 보여주고 생성 기반 대화 모델보다 훨씬 짧은 레이턴 시를 보여주는 것을 확인할 수 있으며, 다양한 모델들 중에서 최적의 점수, 즉, \"스위트 스팟(sweet-spot)\"을 달성하는 것을 알 수 있다. G2R을 적용한 검색 모델과 MIPS 라이브러리로 구성된 검색 기반 대화 시스템은 도 3과 같이 빠른 추론 속도를 보여주면서 상당한 대화 능력을 보이는 것을 실증적으로 입증한다. 예를 들어, 본 개시의 검색 기반 대화 시스 템은 블렌더(blender) 모델(90M 매개변수)에 비해 약 20배의 속도 향상을 보여주면서도 대화 능력에 대한 유사 한 인적 평가 결과를 보여준다. 여기서 블렌더 모델은 오픈 도메인 대화 작업의 최첨단 모델로서, Blender 90M, Blender 2.7B 및 Blender 9.4B와 같은 다양한 매개변수가 존재한다. 블렌더 모델은 응답 생성을 위해 디코딩 하 이퍼 파라미터를 따른다. 도 4는 일 실시 예에 따른 데이터 수준 대화 모델 훈련 방법을 나타낸 도면이다. 도 4에 대하여 설명하기에 앞서, 먼저 오픈 도메인 대화를 위한 검색 모델에 대해 살펴본다. 아래의 수학식 1은 n개의 컨텍스트-응답 쌍을 포함하는 대화 데이터 세트를 나타낸다. 여기서 ci 및 ri는 각각 컨텍스트 및 i번째 예제의 대응되는 적절한 응답인 골드(gold) 응답이다. 훈련 단계에서 검색 모델은 부정적인 응답의 점수와 비교 하여 주어진 컨텍스트 ci에 대한 골드 응답 ri의 점수를 최대화하도록 훈련된다. 그리고 추론 단계에서 검색 모 델은 대화 데이터 세트 D에서 구성된 미리 정의된 응답 세트 R에서 주어진 컨텍스트 c에 대한 가장 높은 점수를 가진 응답을 반환한다. 수학식 2는 n개의 응답을 포함하는 미리 정의된 응답 세트 R을 나타낸다. 수학식 1 수학식 2"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다음으로 지식 증류는 학생 모델 zs의 로짓과 교사 모델 zt의 로짓을 일치시키는 손실을 추가하여 교사 모델의 지식을 학생 모델로 전달하는 방법이다. l개의 클래스가 있는 분류 작업의 경우 지식 증류 손실은 학생 모델의 연화된(softened) 출력 확률과 교사 모델 간의 교차 엔트로피로 정의될 수 있다. 수학식 3은 지식 증류 손실 LKD 를 나타낸다. 수학식 3"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 p(y|x) 및 z(x, y)는 각각 입력 x 및 클래스 y에 대한 모델의 연화 확률 및 로짓 값이고, T는 로짓 값을 평활화(smoothing)하기 위한 온도 매개변수이다. 본 개시의 목표는 검색 모델을 기반으로 하는 효율적인 오픈 도메인 대화 시스템을 만드는 것이다. 그러나 검색 모델을 순진하게 활용하면 검색 모델이 모든 응답 후보에 대한 점수를 계산해야 하기 때문에 응답 집합 R의 크 기가 클 때 효율성이 떨어질 수 있다. 이를 해결하기 위해 본 개시는 효율적인 MIPS 라이브러리(예를 들어, FAISS)가 있는 이중 인코더 모델을 채택하여 모든 응답 후보에 대한 점수를 계산하지 않고도 적절한 응답을 효 율적으로 선택할 수 있도록 한다. 구체적으로, 이중 인코더는 Transformer 아키텍처를 사용하여 컨텍스트 c와 응답 r을 각각 고정 길이 임베딩으로 인코딩하고, c와 r 사이의 관련성 점수를 두 임베딩의 내적으로 정의할 수 있다. 이를 통해 검색 프로세스 속도가 높아질 수 있다. 한편, 추가 고품질 대화 데이터 세트를 활용하면 검색 모델의 성능을 향상시키는 데 도움이 된다. 또한 사전 정 의된 응답 집합 R을 보다 다양한 응답으로 강화하면 적절한 응답을 선택할 기회가 넓어지기 때문에 검색 모델이 다양한 입력 컨텍스트에 적절하게 응답하는 데 도움이 될 수 있다. 그러나 휴먼-인-루프(Human-in-the-loop) 주 석을 통해 이러한 고품질 대화 데이터 세트 또는 응답을 얻는 것은 노동 집약적이고 비용이 많이 든다. 잘 조정된 대규모 생성 모델은 인간에 가까운 대화 능력을 달성할 수 있으므로, 본 개시의 대화 모델 훈련 방법 은 검색 모델을 훈련하기 위한 대화 데이터 세트뿐만 아니라 응답 세트를 확장하기 위해 대규모 생성 모델의 생 성 결과를 활용할 수 있다. 먼저, 대화 데이터 세트(dialogue data set) D의 각 컨텍스트 ci에 대해 대규모 생성 모델 G는 m개의 응답 rG i,j 를 생성할 수 있다. 수학식 4는 응답 rG i,j를 나타낸다. 수학식 4"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "그리고 생성된 응답을 주어진 컨텍스트 ci의 골드 응답으로 간주하여 수학식 5와 같이 대화 데이터 세트 D와 미 리 정의된 응답 세트 R에 추가할 수 있다. 여기서 DG 및 RG는 각각 증강된 대화 데이터 세트 및 증강된 응답 세 트를 나타낸다. 수학식 5"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "대화 데이터 세트와 응답 세트를 증강한 후, 검색 모델 R은 무작위로 샘플링된 음성 응답 R-의 세트 중에서 정답 응답 r을 선택할 확률을 최대화하는 교차 엔트로피 손실 LCE를 최소화하도록 학습된다. 수학식 6은 교차 엔트로 피 손실 LCE를 나타낸다. 수학식 6"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 R(c, r)은 주어진 컨텍스트 c와 응답 r에 대해 검색 모델 R에 의해 계산된 점수이다. 수학식 6에서 R-는 교체 없이 RG에서 응답을 무작위로 샘플링하여 모든 반복에 대해 다르게 생성된다. 일 예로 대규모 생성 모델 G 로 사용 가능한 가장 큰 오픈 도메인 대화 모델인 Blender 9.4B 모델이 사용될 수 있다. 빔 검색(beam search) 알고리즘은 동일한 컨텍스트 내에서 유사한 응답을 생성하는 경향이 있기 때문에 응답의 다양성을 위해 top-k 샘플링을 적용할 수 있다. 또한, 생성된 응답의 특이성과 길이를 다양화하기 위해 서로 다른 최소 길이 제약 조 건으로 응답을 여러 번 샘플링할 수 있다. 도 4의 데이터 수준 대화 모델 훈련 모델을 참조하면, 먼저, 주어진 컨텍스트와 그에 대응되는 응답 쌍을 하나 이상 포함하는 대화 데이터 세트 D를 이용하여 생성 모델 G을 훈련할 수 있다. 이를 위해 대화 데이터 세트 D에서 임의의 컨텍스트 c를 추출하여 생성 모델 G의 입력으로 할 수 있다. 일 실시 예에 따르면, 대화 데이터 세트 D에서의 컨텍스트와 그에 대응되는 응답은 기존의 검색 모델 R이 주 어진 컨텍스트에 대해 검색을 통해 반환하던 응답일 수 있다. 생성 모델 G은 큰 규모(large-scale)의 언어 모델에 기반한 생성 모델일 수 있다. 일 실시 예에 따르면, 생성 모델 G은 컨텍스트 c를 입력으로 하여 새로운 응답 rG를 생성할 수 있다. 이에 따라 생성 모델 G은 컨텍스트 c와 대응되는 새로운 응답 rG 쌍을 하나 이상 포함하 는 새로운 대화 데이터 세트를 생성할 수 있다. 다음으로, 대화 데이터 세트 D와 새로운 대화 데이터 세트를 결합하여 증강된 대화 데이터 세트 DG를 생성할 수 있다. 증강된 대화 데이터 세트 DG는 이하의 도 5에서 모델 수준 대화 모델 훈련 모델의 입력으로 활용될 수 있다. 검색 모델 R은 증강된 대화 데이터 세트 DG를 이용하여 학습될 수 있다. 한편, 새로운 응답 rG는 기존의 응답 세트에 추가되어 증강된 사전 정의된 응답 세트(augmented pre-defined response set) RG로 구성될 수 있으며, 검색 모델 R은 이후 어떠한 컨텍스트가 대화 모델에 입력되었을 때 증강된 사전 정의된 응답 세트 RG를 검색하 여 적절한 응답을 반환할 수 있다. 도 5는 일 실시 예에 따른 모델 수준 대화 모델 훈련 방법을 나타낸 도면이다. 데이터 수준의 대화 모델 훈련 방법은 추가 고품질 대화 데이터와 다양한 응답을 제공하지만, 대규모 생성 모델 G에서 개별 응답의 품질에 대한 세부적인 지식을 전달하지 않는다. 본 개시의 모델 수준 대화 모델 훈련 방법은 이러한 문제를 해결하기 위해 설계되었다. 일 실시 예에 따르면, 데이터 수준의 대화 모델 훈련 방법은 대규모 교사 생성 모델 G에 의해 평가된 개별 응답 수준 품질 점수를 학생 검색 모델 R로 전송하여 문제를 해결한다. 구체적으로, 먼저 교사 생성 모델 G의 관점에서 응답 품질 점수를 다음과 같이 정의한다: G(c, r). 그런 다음, 학생 검색 모델은 기존 지식 증류 기법과 유사하게 학생 검색 모델의 점수 R(c, r)과 교사 생성 모델의 점수 G(c, r)가 일치하도록 학습한다. 일 실시 예에 따르면 교사 생성 모델의 점수 G(c, r)는 수학식 7과 같이 응답 길이로 정규화된 로그 가능도 (log-likelihood)로 정의될 수 있다. 수학식 7"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 PG(r|c)는 생성 모델 G의 주어진 컨텍스트 c에 대한 응답 r의 확률이고, |r|은 응답 r의 토큰 수이다. 로그 가능도는 더 짧은 응답을 선호하는 문제를 완화하기 위해 응답 길이로 정규화 될 수 있다. 교사 생성 모델 의 점수 G(c, r) 및 학생 검색 모델의 점수 R(c, r)을 각각 교사 및 학생 모델의 로짓으로 간주하여 증류 손실 LKD를 도출할 수 있다. 이에 따라 수학식 6은 다음의 수학식 8로 바뀐다. 수학식 8"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 Ri는 DG의 컨텍스트 ci에 대응하는 긍정 응답 세트이다. 한편, 음성 응답에 대한 교사 생성 모델의 점수 G(ci, r-)를 계산하려면 많은 추가 계산이 필요하므로, 무작위로 샘플링된 음성 응답 r- ∈ R-에 대해 수학식 9와 같이 근사화하여 계산을 단순화할 수 있다.수학식 9"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "마지막으로, 모델 수준 대화 모델 훈련 방법에 대한 최종 손실 L은 수학식 10을 참조하면, 수학식 6의 원래 교 차 엔트로피 손실 LCE과 하이퍼 파라미터 α가 각 항의 가중치를 제어하는 지식 증류 손실 LKD의 합으로 나타낼 수 있다. 수학식 10"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 10, "content": "도 5의 모델 수준 대화 모델 훈련 모델을 참조하면, 먼저, 임의의 컨텍스트 ci에 대응하는 응답 세트 Ri를 구성할 수 있다. 일 실시 예에 따르면, 컨텍스트 ci는 도 4에서의 증강된 대화 데이터 세트 DG에 포함된 컨텍스트일 수 있다. 또한, 응답 세트 Ri는 새로운 응답 rG에서 컨텍스트 ci에 적절한 긍정 응답과 새로운 응답 rG에서 긍정 응답을 제외하고 임의로 선택된 하나 이상의 임의 응답(또는 음성 응답)을 포함할 수 있다. 응답 세트 Ri에서 긍정 응답은 한 개만 있을 수도 있다. 다음으로, 응답 세트 Ri를 기반으로 교사 모델인 생성 모델 G와 학생 모델인 검색 모델 R이 컨 텍스트 ci에 대하여 응답을 반환할 수 있다. 생성 모델 G가 컨텍스트 ci에 대하여 반환하는 응답 에 대한 점수 G(ci, r)를 응답 세트 Ri에 포함된 각각의 응답에 대하여 확인할 수 있다. 또한, 검색 모델 R이 컨텍스트 ci에 대하여 반환하는 응답에 대한 점수 R(ci, r)을 응답 세트 Ri에 포 함된 각각의 응답에 대하여 확인할 수 있다. 일 실시 예에 따르면, 생성 모델 G는 응답 r의 길이로 정규화된 로그 가능도를 계산하여 G(ci, r)를 계산할 수 있다. 또한, 검색 모델 R은 컨텍스트 ci와 응답 r을 각각 고정 길이 임베딩으로 인코딩하 고, 두 임베딩의 내적으로 컨텍스트 ci와 응답 r 사이의 관련성 점수를 정의하여 R(ci, r)로 정의할 수 있다. 일 실시 예에 따르면, G(ci, r)와 R(ci, r) 각각에 대하여 응답 세트 Ri에서 긍정 응답을 선택할 확률을 나타내는 교차 엔트로피 손실 LCE를 계산할 수 있다. 특히, 생성 모델 G는 대규모 언어 모델을 기초로 하므로 음성 응답보다 긍정 응답을 선택할 확률이 더 높다. 이에 따라 검색 모델 R은 무작위로 샘 플링된 음성 응답들에 대해 정답 응답을 선택할 확률을 최대화하기 위해 교차 엔트로피 손실 LCE를 최소화 하도록 학습될 것이다. 다음으로 G(ci, r)와 R(ci, r)을 각각 교사 및 학생 모델의 로짓으로 간주하 여 증류 손실 LKD를 도출할 수 있다. 검색 모델 R은 증류 손실 LKD가 최소화되도록, G(ci, r)와 R(ci, r)가 일치하도록 학습할 수 있다. 한편 실시 예에서 스코어를 일치하도록 학습하도록 설 명하는 것은 학습의 방향을 설명하는 것으로 학습의 결과 두 모델의 스코어가 일치하지 않을 수도 있다. 이하에서는 본 개시의 대화 모델 훈련 방법을 사용하여 오픈 도메인 대화를 수행한 경우에 대한 평가와 그 결과 를 나타낸다. 먼저 데이터 세트는 Blended Skill Talk, ConvAI2, Empathetic Dialogues 및 Wizard of Wikipedia로 구성된 오 픈 도메인 대화 데이터 세트를 이용한다. 실험에서는 위의 4개의 데이터 세트를 모두 함께 사용하며, 병합된 데 이터 세트를 BST+라고 지칭할 수 있다. 인적 평가는 BST+ 테스트 데이터 세트에서 무작위로 샘플링된 200개의 예제에 대해 수행될 수 있다. 인간 심사 위원은 생성된 응답의 품질을 0-2 척도의 두 가지 기준으로 평가해야 한다. 먼저, 생성된 응답이 유창하고 논리 적이며 주어진 컨텍스트에 적절한지 평가하기 위한 적절성(Appr.) 을 평가하고, 생성된 응답이 주어진 컨텍스트 와 관련된 의미 있는 정보를 가지고 있는지 여부를 나타내는 정보성(Info.)을 평가할 수 있다. 각 예는 최소 3 명의 고유한 인간 심사 위원이 평가하며 모든 인적 평가는 Amazon Mechanical Turk를 통해 수행될 수 있다. 또한 실험을 통해 다양한 종류의 자동화된 메트릭(metric)을 보고할 수 있다. MaUdE는 참조되지 않은 (unreferenced) 대화 응답 평가 메트릭으로, ConvAI2 데이터 세트를 사용하여 구문 및 의미상 부정적인 응답을 0으로 채점하고 긍정적인 응답을 1로 채점하도록 훈련된 모델에 의해 계산된다. MaUdE는 응답의 유창성과 흥미 에 대한 인간의 판단과 높은 상관관계를 보여주기 때문에 MaUdE를 각 모델에서 생성된 응답의 전반적인 품질을 평가하기 위한 프록시 메트릭으로 사용한다. 또한, 실험에서는 생성된 응답의 어휘적 다양성을 측정하기 위해 Dist-2 및 Dist-3 모델을 사용할 수 있다. 여기서 Dist-n은 각 모델에 의해 생성된 모든 응답의 총 n-그램 수에 대한 고유한 n-그램의 비율을 뜻한다. 생성된 응답의 평균 토큰 수인 길이는 참조용으로 보고된다. 마지막으로, 실험에서는 본 개시의 모델의 효율성을 검증하기 위해 단일 입력 컨텍스트에 대한 응답을 생성하기 위한 레이턴 시를 측정하고 보고한다. 일반적으로 GPU 지원 환경에서 측정한 레이턴시를 보고하지만, CPU만 사용하여 측정한 레이턴시를 보고할 수도 있다. 본 개시의 모델 수준 대화 모델 훈련 방법과 더 큰 생성 모델에서 추출한 작은 블렌더 모델을 이용하여 지식 증 류 기술을 사용하는 생성 모델과의 결과를 비교한다. 여기서 증류된 블렌더(Distilled Blender)로 표시된 TinyBERT 스타일 증류와 함께 Blender 2.7B에서 증류된 400M 매개변수 블렌더 모델을 사용한다. 한편, Pushshift Reddit 주석 데이터 세트로 사전 훈련되고 BST+ 데이터 세트에서 미세 조정된 256M 매개변수가 있는 이중 인코더 및 폴리 인코더는 검색 모델의 베이스라인(baseline)이 될 수 있다. 앞서 설명한 바와 같이 MIPS 라이브러리와 통합된 이중 인코더 모델은 Bi-encoder(w/FAISS)로 표시된다. RetNRef는 검색 모델의 응답을 생성 모델의 입력에 통합하는 예제 기반 생성 모델(exemplar-based generative model)이다. 본 개시의 대화 모델 훈 련 모델 중 하나인 G2R과 달리 RetNRef는 검색 모델을 활용하여 생성 모델을 개선하는 반면, G2R은 생성 모델에 대한 지식을 활용하여 검색 모델을 개선한다. 특히 G2R은 α-blending 기법으로 훈련된 대화 검색 모델을 사용 한다. 일 실시 예에 따르면, 대화 모델에 대한 인간의 응답은 BST+ 데이터 세트에 주석이 달린 실측 레이블을 나타낸다. 본 개시의 대화 모델 훈련 방법에서 이중 인코더 R은 Blender 9.4B를 교사 생성 모델 G로 사용하여 G2R로 훈련 된다. G2R-DM은 데이터 수준 G2R 및 모델 수준 G2R로 훈련된 모델을 나타낸다. 본 개시에서는 포괄적인 분석을 위해 두 가지 변형을 고려하였다. 예를 들어, G2R-D는 데이터 수준 G2R로만 훈련되고 G2R-D(FAISS 제외)는 G2R- D에서 MIPS 라이브러리인 FAISS의 사용을 추가로 제거한다. 표 1은 오픈 도메인 대화의 여러 대화 모델 중 인적 평가 결과와 자동화된 메트릭의 결과를 나타낸 표이다. 여 기서 Latency(Speedup) 열은 Blender 90M의 레이턴시와 비교한 각 모델의 상대적인 속도 향상을 나타낸다. 표 1 에서 본 개시의 대화 모델 훈련 방법(G2R)으로 훈련된 시스템이 대화 능력과 효율성 사이의 \"스위트 스팟\"을 달 성한 것을 확인할 수 있다. 본 개시의 시스템은 Bi-encoder(w/ FAISS)의 낮은 레이턴시를 유지하면서 인적 평가 결과를 크게 향상시켜 Blender 90M 및 사람의 응답과 각각 비슷하거나 더 나은 인적 평가 점수를 달성한다. 표 1 더 자세히 살펴보면 Dist-2 및 Dist-3 점수에서 볼 수 있듯이 블렌더 생성 모델과 증류된 블렌더 모델은 높은 인적 평가 점수를 보여 주는 반면 다양성 부족과 함께 상대적으로 긴 레이턴시를 보여준다. 검색 베이스라인 (Retrieval baselines)(Bi-encoder 및 Poly-encoder)은 반대 경향을 보여 훨씬 낮은 레이턴시와 상대적으로 높 은 응답 다양성을 나타내지만 인적 평가 점수 측면에서 상대적으로 낮은 대화 능력을 보여준다. 인적 평가 결과 와 달리 Bi-encoder와 Poly-Encoder의 MaUdE 점수는 예상외로 높다. 그러나 이러한 결과는 MaUdE 항목이 BST+ 데이터 세트의 하위 집합인 ConvAI2 데이터 세트에 대해 훈련되고 이러한 검색 모델의 유사한 훈련 목표를 가지 고 있기 때문이다. 본 개시의 G2R 기반 모델은 원래 모델인 Bi-encoder(w/ FAISS)에 비해 훨씬 더 나은 인적 평 가 결과를 달성한다. 데이터 수준 G2R 전용(G2R-D)을 적용하면 모델의 성능이 크게 향상되므로, 모델 성능이 인 적 평가 측면에서 골드 인간 응답과 비교될 수 있다. 데이터 수준 G2R을 사용하면 미리 정의된 응답 집합 RG의 응답 수가 10배 이상 증가하므로, FAISS가 없는 Bi-encoder(G2R-D(w/o FAISS))를 사용한다면 레이턴시가 늘어 날 것이다. 응답 집합의 크기가 작은 경우(Bi-encoder(w/FAISS)의 경우) FAISS를 사용하면 레이턴시 오버헤드가 발생하지만 G2R-D와 같이 더 큰 응답 집합에서 FAISS를 사용하면 낮은 레이턴시를 유지할 수 있다. 다만, FAISS 가 없는 버전에 비해 응답 품질이 약간 저하될 수 있다. 모델 수준의 G2R의 추가적인 적용은 검색 모델의 성능을 추가로 향상시킬 수 있다. 데이터 수준 G2R 및 모델 수 준 G2R로 훈련된 G2R-DM은 데이터 수준 G2R로만 훈련된 G2R-D보다 더 높은 인적 평가 점수와 MaUdE 점수를 보여 주며 훨씬 더 빠르게 실행 가능하면서 Blender 90M 모델에 필적하는 인적 평가 점수를 나타낸다. G2R-DM은 더 큰 Blender 생성 모델에 비해 다소 부족한 인적 평가 점수를 보여주지만 상당히 낮은 레이턴시를 보여준다(증류 된 블렌더 모델에 비해 23.0배 속도 향상, Blender 2.7B에 비해 44.7배 속도 향상). 또한 G2R-DM은 블렌더 생성 모델에 비해 훨씬 높은 응답 다양성을 나타낸다. 반면 RetNRef 모델은 G2R-DM 모델에 비해 더 나쁜 성능을 보여 주고 훨씬 더 높은 레이턴시를 제공한다. 표 2는 데이터 수준 G2R에 의해 생성된 원래 응답 세트 R과 새로운 응답 세트 RG의 기본 통계를 나타낸다. 데이 터 수준 G2R을 적용한 후 RG는 원래 응답 세트 R에 비해 약 11배 더 많은 후보를 갖게 된다. 새로운 응답 세트 RG의 응답이 원래 응답 세트 R에 비해 더 많은 다양성을 보이는지 확인하기 위해 각 응답 세트에 나타나는 고유 토큰 및 바이그램(bi-gram)/트라이그램(tri-gram)의 수를 계산할 수 있다. 표 2를 참조하면, 증강 응답 세트 RG 는 원래 응답 세트보다 훨씬 더 고유한 토큰과 바이그램/트라이그램을 가지고 있어 더 다양한 주제, 엔티티를 다루고 구문과 표현 측면에서 더 다양성을 보여줄 수 있다. 표 2"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "이하에서는 데이터 수준의 G2R 방식에서 생성된 응답을 어떻게 사용하느냐에 따라 모델의 성능이 어떻게 변화하 는지 자세히 분석하기 위해 ablation 연구를 수행한다. 데이터 수준 G2R에서 생성된 응답은 검색 모델 R의 훈련 대화 데이터 세트 DG를 증대하고 증강 응답 세트 RG를 구축하는 데에 활용된다. Ablation 연구를 통해 이 두 가 지 활용 방법을 분리하고 각 방법만 사용하는 경우에 대해 모델을 평가할 수 있다. 표 3은 이러한 ablation 모델의 평가 결과를 보여준다. 인적 평가 메트릭 및 자동화된 메트릭과 함께 검색 모델 의 성능을 평가하기 위해 널리 채택된 BST+ 테스트 세트에서 훈련된 이중 인코더 모델의 Hits@1/K 및 Hits@5/K 를 활용한다. 표 3에서 제일 하단을 제외하고 상단에서부터 차례대로, 검색 모델을 기존의 대화 데이터 세트 D 를 이용하여 훈련하고 원래의 응답 세트 R을 구축하는 경우(즉, 기존의 대화 모델), 검색 모델을 기존의 대화 데이터 세트 D를 이용하여 훈련하고 모델 수준 G2R에 의해 증강된 응답 세트 RG를 구축하는 경우(즉, ablation 모델), 검색 모델을 데이터 수준 G2R에 의해 증강된 대화 데이터 세트 DG를 이용하여 훈련하고 원래의 응답 세트 R을 구축하는 경우(즉, ablation 모델), 및 검색 모델을 데이터 수준 G2R에 의해 증강된 대화 데이터 세트 DG를 이용하여 훈련하고 모델 수준 G2R에 의해 증강된 응답 세트 RG를 구축하는 경우(즉, 본 개시의 G2R-DM)에 따른 인적 평가 및 자동화된 메트릭의 결과이다. 표 3"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "표 3에서 볼 수 있듯이 두 가지 방법을 모두 사용하는 모델에 비해 한 가지 방법만 사용하는 것이 더 나은 성능 을 보여주지는 않는다. 또한, RG 구축을 위해 생성된 응답을 활용하면 모델의 적합성 점수가 향상되며, 이는 다 양한 응답 세트를 사용하는 것이 모델이 더 적절하게 응답하는 데 도움이 된다는 본 개시의 대화 모델 훈련 방 법을 뒷받침한다. R을 구축하기 위한 증강 대화 데이터 세트 DG의 사용은 적절성과 정보성 메트릭 모두에 대한 인적 평가 점수를 높이는 데 도움이 된다. 또한, 증강 대화 데이터 세트 DG를 사용한 훈련은 검색 모델의 Hits 메트릭을 상당히 향상시킨다. 그럼에도 불구하고 두 가지 방법을 모두 사용하면 모든 ablation 모델 중에서 최 고의 인적 평가 성능을 보이므로, 검색 모델을 훈련하고 응답 세트를 구축하는 데 새로운 예제를 사용하는 것이 좋은 성능을 유도하는 데 중요하다는 것을 알 수 있다. 표 3에서 이미 훈련된 검색 모델의 상위 m 개의 응답을 활용하여 이중 인코더 모델을 훈련하여 생성된 증강 대 화 데이터 세트를 DR이라고 할 수 있다. 증강 대화 데이터 세트 DR을 이용하는 대화 모델과 데이터 수준 G2R에 의해 증강된 대화 데이터 세트 DG를 이용하는 대화 모델을 비교하면, 대규모 생성 모델을 사용하는 방법이 단순 히 검색 모델을 사용하는 것보다 더 나은 품질의 교육 데이터 세트를 생성한다는 것을 확인할 수 있다. 표 3에 서 볼 수 있듯이 인적 평가 점수와 조회수 메트릭을 모두 향상시키는 DG를 사용하는 경우와 달리 DR을 훈련 데이 터 세트로 사용하면 모든 메트릭에 대해 상당한 성능 향상으로 이어지지 않는다. 이 결과는 데이터 수준 G2R에 서와 같이 대화 증대를 위해 대규모 생성 모델을 사용하는 것이 검색 모델을 사용하는 것보다 훨씬 더 효과적인 증대 전략임을 강력하게 나타낸다. 일 실시 예에 따르면, 모델 수준 G2R에서 교사 생성 모델의 점수 G(c, r)를 정의하기 위해 로그 가능도 점수(LL 점수)를 사용하지만 다른 방법도 사용할 수 있다. 한 가지 예는 상호 정보(Mutual Information) 점수(MI 점수) 를 이용하는 것이다. MI 점수는 주어진 컨텍스트 c와 응답 r 사이의 포인트별(point-wise) 상호 정보로, 일반적 인 응답에 더 낮은 값을 할당하는 반면 주어진 컨텍스트에 더 구체적인 응답의 점수를 높이는 것으로 알려져 있 다. MI 점수를 사용하면 LL 점수에 비해 더 구체적이고 다양한 응답이 생성되는 동시에 입력 컨텍스트와 관련하 여 부적절한 세부 정보가 포함된 응답을 반환할 위험이 약간 더 높을 수 있다. 따라서 이하에서는 MI 점수를 G(c, r)로 사용하는 모델 수준 G2R과 LL 점수를 사용하는 모델의 성능을 비교한다. 표 4는 교사 생성 모델의 점수 G(c, r)를 정의하기 위해 MI 점수를 사용하는 모델 수준 G2R 모델에 대한 인적 평가 결과 및 자동화된 메트릭 결과를 나타낸다. 표 4"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "모델 수준의 G2R에 대해 MI 점수를 사용하는 것은 특히 적합성 점수에 대해 LL 점수를 사용하는 것보다 약간 낮 은 인적 평가 점수를 나타내므로 MI 점수를 사용하는 것이 적절하고 정확한 답변을 생성할 수 없음을 의미한다. 그러나 자동화된 메트릭 측면에서 MI 점수는 더 높은 MaUdE 점수를 보여준다. 즉, MI 점수를 사용하는 것이 LL 점수에 비해 더 높은 응답 다양성을 보여 대화 시스템의 더 다양한 응답에 MI 점수를 사용할 수 있음을 나타낸 다. 표 5는 베이스라인(baseline) 모델과 G2R 모델에서 반환된 응답의 예를 제공한다. 표 5에 관련된 실험에서는 입 력 컨텍스트로 챗봇 A(\"Amazon is a great place to order books\")의 구문에 대하여 컨텍스트 B(\"Oh yeah that is a fact\")가 입력되는 경우를 가정하였다. 표 5"}
{"patent_id": "10-2021-0161615", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "표 5를 참조하면, 이 예에서 Bi-encoder(w/ FAISS)는 주어진 컨텍스트에 관련 없는 응답(\"Comics is at the top of the list in interest\")을 반환한다. 블렌더 모델의 응답은 논리적으로 적절하지만 단순히 토픽을 변경 하거나(Blender 90M, 증류된 블렌더의 경우: \"Do you have any other hobbies that you like to do on the weekends? I like to read\", \"What else do you like to do in your spare time? I like to go to the beach\") 특정 세부 사항이 상대적으로 부족한 결과를 제공한다(Blender 2.7B, Blender 9.4B의 경우: \"What kind of books do you buy on amazon? I like to read science fiction and fantasy\", \"What kind of books do you like to read? I like romance novels and mystery novels\"). 데이터 수준 G2R(G2R-D)은 상세하게 응답 하려고 하지만 응답에는 주제에 대한 다소 관련 없는 문구가 포함되어 있다(\"Do you ever order grocerys? I love amazon's selection of books and videos\"). 대조적으로, G2R-DM은 특정 세부사항과 함께 적절하게 응답 하는 것을 확인할 수 있다(\"What is your favourite book? Mine is \"the cat in the hat\" by dr suess\"). 한편 검색 모델을 통한 대화 모델을 생성할 때 도 4 및 도 5에서 설명된 방법을 병행하여 활용할 수 있다. 도 6은 일 실시 예에 따른 모델 수준 대화 모델을 훈련시키기 위한 전자 장치를 나타낸 블록도이다. 전자 장치는 일 실시 예에 따라, 저장 디바이스(storage device) 및 프로세서를 포함할 수 있으며, 이에 한정되지 않는다. 저장 디바이스는 오픈 도메인 대화에 필요한 컨텍스트와 응답을 저장할 수 있다. 저장 디바이스는 전자 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서의 처리 및 제어를 위한 프로 그램을 저장할 수 있다. 저장 디바이스는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard diskdrive), SSD(solid state drive), 또는 플래시 메모리를 포함할 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어하고 데이터 및 신호를 처리할 수 있다. 일 실시 예에서 프로세서는 적어도 하나의 프로세서를 포함할 수 있다. 일 실시 예에 따라, 프로세서는 저장 디바이스 를 통해 제1 대화 데이터 세트에서 제1 컨텍스트에 대응하는 제1 응답 서브 세트 및 임의로 선택된 제2 응 답 서브 세트를 포함하는 응답 세트를 획득할 수 있다. 또한, 프로세서는 제1 대화 모델을 기반으로 제1 컨 텍스트에 대한 응답 세트에 포함된 응답에 대한 제1 스코어를 계산하고, 제2 대화 모델을 기반으로 제1 컨텍스 트에 대한 응답 세트에 포함된 응답에 대한 제2 스코어를 계산할 수 있다. 그리고 프로세서는 제1 스코어 및 제2 스코어를 기반으로 제2 대화 모델을 학습시킬 수 있다. 본 개시의 전자 장치는 통신 디바이스(미도시)를 더 포함할 수도 있다. 통신 디바이스는 유무선 통신 기술 을 이용하여 외부의 전자 장치와 통신할 수 있으며 트랜시버를 포함할 수 있다. 외부의 전자 장치는 단말 또는 서버가 될 수 있다. 또한, 통신 디바이스가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신 (Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있을 수 있으며, 이에 한정 되는 것은 아니다. 전술한 실시 예들에 따른 장치는 프로그램 데이터를 저장하고 실행하는 메모리, 디스크 드라이브와 같은 영구 저장부(permanent storage), 외부 장치와 통신하는 통신 포트, 터치 패널, 키(key), 버튼 등과 같은 사용자 인 터페이스 장치 등을 포함할 수 있다. 소프트웨어 모듈 또는 알고리즘으로 구현되는 방법들은 상기 프로세서 상 에서 실행 가능한 컴퓨터가 읽을 수 있는 코드들 또는 프로그램 명령들로서 컴퓨터가 읽을 수 있는 기록 매체 상에 저장될 수 있다. 여기서 컴퓨터가 읽을 수 있는 기록 매체로 마그네틱 저장 매체(예컨대, ROM(read-only memory), RAM(random-Access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판독 매체(예컨대, 시디롬 (CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있는 기록 매체는 네트워크 로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 본 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들은 특정 기능들을 실행하는 다양한 개수의 하드웨어 또는/및 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 실시 예 는 하나 이상의 마이크로프로세서들의 제어 또는 다른 제어 장치들에 의해서 다양한 기능들을 실행할 수 있는, 메모리, 프로세싱, 로직(logic), 룩 업 테이블(look-up table) 등과 같은 직접 회로 구성들을 채용할 수 있다. 구성 요소들이 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행될 수 있는 것과 유사하게, 본 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조합으로 구현되는 다양한 알고리즘을 포함하 여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기 능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 실시 예는 전자 적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. \"매커니즘\", \"요소\", \"수단\", \"구성\"과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 상기 용어는 프로세서 등과 연계하여 소프트웨어의 일련의 처리들(routines)의 의미를 포함할 수 있다. 전술한 실시 예들은 일 예시일 뿐 후술하는 청구항들의 범위 내에서 다른 실시 예들이 구현될 수 있다. 도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2021-0161615", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른 데이터 수준 대화 모델 훈련 방법을 나타낸 흐름도이다. 도 2는 일 실시 예에 따른 모델 수준 대화 모델 훈련 방법을 나타낸 흐름도이다. 도 3은 오픈 도메인 대화 모델들에 대한 레이턴시 대 인적 평가 점수를 나타낸 그래프이다. 도 4는 일 실시 예에 따른 데이터 수준 대화 모델 훈련 방법을 나타낸 도면이다. 도 5는 일 실시 예에 따른 모델 수준 대화 모델 훈련 방법을 나타낸 도면이다. 도 6은 일 실시 예에 따른 모델 수준 대화 모델을 훈련시키기 위한 전자 장치를 나타낸 블록도이다."}
