{"patent_id": "10-2022-0163504", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0080014", "출원번호": "10-2022-0163504", "발명의 명칭": "공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치 및 방법", "출원인": "한국전자기술연구원", "발명자": "김병수"}}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공유 메모리를 포함하는 뉴런 라우터; 및N개의 뉴런 셀을 포함하고,상기 뉴런 라우터는 N개의 특징 데이터로 구성된 학습 데이터를 입력받아 상기 공유 메모리에 저장하며, 상기공유 메모리에 저장된 상기 학습 데이터를 기초로 상기 N개의 뉴런 셀 각각에 대한 중심값 데이터를 결정하는것인 뉴런 퍼실리티 장치."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 뉴런 라우터는,상기 N개의 뉴런 셀 각각에 대한 중심값 데이터를 상기 공유 메모리에 저장하는 것인 뉴런 퍼실리티 장치."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "공유 메모리를 포함하는 뉴런 라우터; 및N개의 뉴런 셀을 포함하고,상기 뉴런 라우터는 추론용 특징 데이터를 입력받아 상기 공유 메모리에 저장하고, 상기 공유 메모리에 저장된상기 추론용 특징 데이터를 상기 N개의 뉴런 셀에 전달하며,상기 N개의 뉴런 셀은 상기 추론용 특징 데이터와 자신의 중심값 데이터 간의 거리 정보를 생성하여 상기 뉴런라우터에 전송하는 것인 뉴런 퍼실리티 장치."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 뉴런 라우터는,상기 N개의 뉴런 셀에서 전송한 거리 정보 중 최소값을 구하여 최소 거리 정보를 생성하는 것 인 뉴런 퍼실리티 장치."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 뉴런 라우터는,상기 N개의 뉴런 셀에서 전송한 거리 정보를 상기 공유 메모리에 저장하는 것 인 뉴런 퍼실리티 장치."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "뉴런 라우터가 제1 특징 데이터를 입력받는 단계;상기 뉴런 라우터가 상기 제1 특징 데이터를 기초로 뉴런 셀의 제1 중심값 데이터를 결정하는 단계; 및상기 뉴런 라우터가 상기 제1 중심값 데이터를 상기 뉴런 라우터의 공유 메모리에 저장하는 단계;를 포함하는 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 뉴런 셀 학습 방법.공개특허 10-2024-0080014-3-청구항 7 제6항에 있어서,상기 뉴런 라우터가 제2 특징 데이터를 입력받는 단계; 및상기 뉴런 라우터가 상기 제1 중심값 데이터를 상기 공유 메모리에서 읽어들이고, 상기 제1 중심값 데이터와 상기 제2 특징 데이터를 기초로 상기 뉴런 셀의 제2 중심값 데이터를 결정하는 단계를 더 포함하는,공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 뉴런 셀 학습 방법."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제2 중심값 데이터를 생성하는 단계는,상기 뉴런 라우터가 상기 제2 중심값 데이터를 상기 공유 메모리에 저장하는 것을 더 포함하는, 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 뉴런 셀 학습 방법."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "복수의 뉴런 셀을 포함하는 뉴런 퍼실리티 모듈;상기 뉴런 퍼실리티 모듈을 1개 이상 포함하는 타일 퍼실리티 모듈; 및상기 타일 퍼실리티 모듈을 1개 이상 포함하는 클러스터 퍼실리티 모듈을 포함하고,상기 클러스터 퍼실리티 모듈은 상기 타일 퍼실리티 모듈에 특징 데이터를 전달하고, 상기 타일 퍼실리티 모듈은 상기 뉴런 퍼실리티 모듈에 상기 특징 데이터를 전달하며,상기 뉴런 퍼실리티 모듈은 상기 복수의 뉴런 셀 각각이 가지고 있는 중심값 데이터와 상기 특징 데이터 간의거리 정보를 상기 뉴런 퍼실리티 모듈의 공유 메모리에 저장하는 것인 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치."}
{"patent_id": "10-2022-0163504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 뉴런 퍼실리티 모듈은,상기 공유 메모리에 저장된 거리 정보의 최소값을 구하여 상기 뉴런 퍼실리티 모듈의 최소 거리 정보를 생성하는 것인 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치."}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치 및 방법에 관한 것이다. 본 발명은 뉴런 셀의 특징 메모리(feature memory)를 병합한 공유 메모리 구조에 기반한 경량 인공지능 연산 처리 장치 및 방법을 제 공한다. 본 발명에 따른 경량 인공지능 연산 처리 장치 및 방법은 공유 메모리 구조의 하드웨어 아키텍처를 활용하여 하 드웨어 복잡도를 줄이고, 칩 제작 시 메모리 배치 및 배선을 용이하게 하며, PnR 과정의 설계를 용이하게 하는 효과가 있다."}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 연산 처리 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "RCE-NN(restricted coulomb energy neural network) 알고리즘의 저 복잡도 연산을 활용한 경량 인공지능 연산 처리 장치는 단순 이미지 분류뿐만 아니라 다양한 센서 데이터 정보를 바탕으로 동작 및 상황 인식이 가능하다. 최근 인공지능 하드웨어는, 사용자의 다양한 환경 및 데이터를 처리하고자 하는 요구에 따라, 데이터의 복잡도 가 증가하고 다양한 유형의 데이터 처리가 필요해졌으며 이를 위해 더 많은 뉴런의 탑재를 필요로 한다. 그러나 RCE-NN 알고리즘의 멀티캐스트 연산 특성에 따라, 뉴런 개수가 증가할수록 뉴런마다 존재하는 특징 메모리 (feature memory)로 인하여 하드웨어 칩의 제작이 더욱 어려워지는 문제가 있다. 특히, 사용하는 뉴런만큼 필요 하게 되는 메모리 인스턴스는 칩 제작 중 PnR 과정에서 디자인의 배치 및 배선을 어렵게 하는 문제가 있다."}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 경량 인공지능 연산 처리 장치의 실제 칩 제작의 PnR 난이도를 낮추기 위하여, 뉴런 셀의 특징 메모 리(feature memory)를 병합한 공유 메모리 구조에 기반한 경량 인공지능 연산 처리 장치 및 방법을 제공하는 것 을 그 목적으로 한다. 또한, 본 발명은 RCE-NN 알고리즘의 멀티캐스팅 통신을 수용할 수 있는 공유 메모리 구조의 하드웨어 아키텍처 에 기반한 경량 인공지능 연산 처리 장치 및 방법을 제공하는 것을 그 목적으로 한다. 본 발명의 목적은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로 부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 뉴런 퍼실리티 장치는 공유 메모리를 포함하는 뉴런 라우터; 및 N개의 뉴런 셀을 포함한다. 상기 뉴런 라우터는 N개의 특징 데이터로 구성된 학습 데이터를 입력받아 상기 공유 메모리에 저장하며, 상기 공유 메모리에 저장된 상기 학습 데이터를 기초로 상기 N개의 뉴런 셀 각각에 대한 중심값 데이터를 결정한다. 본 발명의 일 실시예에서, 상기 뉴런 라우터는, 상기 N개의 뉴런 셀 각각에 대한 중심값 데이터를 상기 공유 메 모리에 저장할 수 있다. 그리고, 본 발명의 일 실시예에 따른 뉴런 퍼실리티 장치는, 공유 메모리를 포함하는 뉴런 라우터; 및 N개의 뉴 런 셀을 포함한다. 상기 뉴런 라우터는 추론용 특징 데이터를 입력받아 상기 공유 메모리에 저장하고, 상기 공유 메모리에 저장된 상기 추론용 특징 데이터를 상기 N개의 뉴런 셀에 전달한다. 상기 N개의 뉴런 셀은 상기 추론용 특징 데이터와 자신의 중심값 데이터 간의 거리 정보를 생성하여 상기 뉴런 라우터에 전송한다. 본 발명의 일 실시예에서, 상기 뉴런 라우터는, 상기 N개의 뉴런 셀에서 전송한 거리 정보 중 최소값을 구하여 최소 거리 정보를 생성한다. 본 발명의 일 실시예에서, 상기 뉴런 라우터는, 상기 N개의 뉴런 셀에서 전송한 거리 정보를 상기 공유 메모리 에 저장할 수 있다. 그리고, 본 발명의 일 실시예에 따른, 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 뉴런 셀 학습 방법은, 뉴런 라우터가 제1 특징 데이터를 입력받는 단계; 상기 뉴런 라우터가 상기 제1 특징 데이터를 기초로 뉴런 셀의 제1 중심값 데이터를 결정하는 단계; 및 상기 뉴런 라우터가 상기 제1 중심값 데이터를 상기 뉴런 라 우터의 공유 메모리에 저장하는 단계를 포함한다. 본 발명의 일 실시예에서, 상기 뉴런 셀 학습 방법은, 상기 뉴런 라우터가 제2 특징 데이터를 입력받는 단계; 및 상기 뉴런 라우터가 상기 제1 중심값 데이터를 상기 공유 메모리에서 읽어들이고, 상기 제1 중심값 데이터와 상기 제2 특징 데이터를 기초로 상기 뉴런 셀의 제2 중심값 데이터를 결정하는 단계를 더 포함할 수 있다. 본 발명의 일 실시예에서, 상기 제2 중심값 데이터를 생성하는 단계는, 상기 뉴런 라우터가 상기 제2 중심값 데 이터를 상기 공유 메모리에 저장하는 것을 더 포함할 수 있다. 그리고, 본 발명의 일 실시예에 따른, 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치는, 복수의 뉴런 셀을 포함하는 뉴런 퍼실리티 모듈; 상기 뉴런 퍼실리티 모듈을 1개 이상 포함하는 타일 퍼실리티 모듈; 및 상 기 타일 퍼실리티 모듈을 1개 이상 포함하는 클러스터 퍼실리티 모듈을 포함한다. 상기 클러스터 퍼실리티 모듈은 상기 타일 퍼실리티 모듈에 특징 데이터를 전달하고, 상기 타일 퍼실리티 모듈 은 상기 뉴런 퍼실리티 모듈에 상기 특징 데이터를 전달한다.상기 뉴런 퍼실리티 모듈은 상기 복수의 뉴런 셀 각각이 가지고 있는 중심값 데이터와 상기 특징 데이터 간의 거리 정보를 상기 뉴런 퍼실리티 모듈의 공유 메모리에 저장한다. 본 발명의 일 실시예에서, 상기 뉴런 퍼실리티 모듈은, 상기 공유 메모리에 저장된 거리 정보의 최소값을 구하 여 상기 뉴런 퍼실리티 모듈의 최소 거리 정보를 생성한다."}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 경량 인공지능 연산 처리 장치 및 방법은 공유 메모리 구조의 하드웨어 아키텍처를 활용하여 하 드웨어 복잡도를 줄이고, 칩 제작 시 메모리 배치 및 배선을 용이하게 하며, PnR 과정의 설계를 용이하게 하는 효과가 있다. 본 발명에 따른 경량 인공지능 연산 처리 장치 및 방법은 공유 메모리 구조를 가진 특징 메모리(feature memory)를 통해, 메모리에 사용되는 로직을 줄일 수 있으며, 따라서 하드웨어 칩의 크기를 줄이는 효과가 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치 및 방법에 관한 것이다. 본 발명은 경량 인 공지능 연산 장치의 하드웨어 복잡도를 줄이고 및 칩 제작 시 배치 및 배선을 쉽게 할 수 있는 공유 메모리 구 조 기반의 경량 인공지능 연산 처리 장치 및 방법을 제안한다. 본 발명의 특징은 다음과 같다. ① 뉴런 셀마다 특징 메모리를 배치하지 않고, 복수의 뉴런 셀 중 일부 뉴런 셀 또는 전부를 그룹으로 묶어 하 나의 병합된 특징 메모리를 사용한다. ② 병합된 특징 메모리와 연관된 특정 뉴런 셀 학습 시, 메모리 쓰기 과정에서, 학습된 다른 뉴런 셀에 대한 특 징 정보를 유지하기 위해, 특징 메모리에 대하여 메모리 쓰기 이전에 메모리 읽기 과정을 수행한다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0163504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 한편, 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포 함한다. 명세서에서 사용되는 \"포함한다(comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성소자, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성소자, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로 사용될 수 있다. 예를 들어, 본 발명의 권리 범위로부터 이탈되지 않은 채 제1 구성요소는 제2 구성요소로 명명될 수있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 발명을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 이하, 본 발명의 실시예를 첨부한 도면들을 참조하여 상세히 설명한다. 본 발명을 설명함에 있어 전체적인 이해 를 용이하게 하기 위하여 도면 번호에 상관없이 동일한 수단에 대해서는 동일한 참조 번호를 사용하기로 한다. 도 1은 본 발명의 일 실시예에 따른 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 구성과 하드웨어 아키텍처 구조를 나타낸 블록도이다. 본 발명의 일 실시예에 따른 경량 인공지능 연산 처리 장치(10, 이하 '인공지능 연산 처리 장치'로 약칭함)는 클러스터 퍼실리티 모듈을 포함한다. 클러스터 퍼실리티 모듈은 클러스터 라우터 및 1개 이상의 타일 퍼실리티 모듈을 포함한다. 또 한, 각각의 타일 퍼실리티 모듈은 타일 라우터와 1개 이상의 뉴런 퍼실리티 모듈을 포함한다. 그리고, 각각의 뉴런 퍼실리티 모듈은 뉴런 라우터와 1개 이상의 뉴런 셀을 포함한다. 뉴런 라 우터는 공유 메모리를 포함한다. 도 1에 도시한 바와 같이, 본 발명에서 제안하는 공유 메모리 구조 기반의 하드웨어 아키텍처를 가진 인공지능 연산 처리 장치는 3계층으로 존재하는 라우터 컨트롤러(110, 210, 310)를 통해 RCE-NN 알고리즘 연산을 처 리한다. 인공지능 연산 처리 장치에서 뉴런 퍼실리티 모듈은 1단계인 최하위 계층에 해당하며, 뉴런 퍼실리티 모듈의 뉴런 라우터는 각 뉴런 셀과 데이터를 송수신하며, 뉴런 퍼실리티 모듈이 포함된 타일 퍼실리티 모듈의 타일 라우터와 데이터를 송수신한다. 타일 퍼실리티 모듈은 2단계 계층에 해당하며, 타일 퍼실리티 모듈의 타일 라우터는 해당 타일 퍼실리티 모듈에 포함된 뉴런 퍼실리티 모듈의 뉴런 라우터와 데이터를 송수신하며, 타일 퍼실 리티 모듈이 포함된 클러스터 퍼실리티 모듈의 클러스터 라우터와 데이터를 송수신한다. 클러스터 퍼실리티 모듈은 3단계인 최상위 계층에 해당하며, 클러스터 퍼실리티 모듈의 클러스터 라 우터는 해당 클러스터 퍼실리티 모듈에 포함된 타일 퍼실리티 모듈의 타일 라우터와 데이 터를 송수신하며, 외부 장치와 특징 데이터를 포함한 데이터를 송수신한다. 구조적으로 최상위 계층인 3단계에서 클러스터 라우터에 입력된 특징 벡터는 계층별 라우터(310 -> 210 -> 110)를 거쳐 최하위 계층(1단계)인 뉴런 라우터의 공유 메모리(111, shared feature memory)에 저장된다. 구체적으로, 클러스터 라우터는 외부에서 수신한 특징 벡터를 클러스터 퍼실리티 모듈에 포함된 타일 퍼실리티 모듈의 타일 라우터에 전달한다. 그리고, 타일 라우터는 해당 타일 퍼실리티 모듈 에 포함된 뉴런 퍼실리티 모듈의 뉴런 라우터에 특징 벡터를 전달한다. 뉴런 라우터는 내 장된 공유 메모리에 특징 벡터를 저장한다. 본 발명에서 '특징 벡터'는 특징 데이터(feature data)가 벡터 의 형태를 가지는 경우를 의미한다. 뉴런 라우터에 포함된 공유 메모리는 하위 노드인 뉴런 셀의 특징 메모리를 병합한 형태이다. 뉴런 라우터는, 공유 메모리에 저장된 특징 데이터를, 설정에 따라 모든 뉴런 셀 또는 일부 뉴 런 셀에 멀티캐스팅한다. 뉴런 라우터는 뉴런 셀에 대한 데이터 입출력을 제어한다. 뉴런 라우 터에 의해 제어되는 1개 이상의 뉴런 셀은 특징 벡터와 기 설정된 자신의 중심값 벡터 간의 거리 정 보를 계산하고, 상기 거리 정보를 기초로 학습 및 인지에 필요한 연산을 수행한다. 예를 들어, 뉴런 셀은 특징 벡터와 중심값 벡터 간의 거리 정보를 계산하고, 거리 정보가 기 설정된 반경 이하인지 여부를 판단하는비교 연산을 수행할 수 있다. 뉴런 셀의 학습 시에는 레이블 값이 특징 벡터와 동일한 경로로 공유 메모리 에 저장되고, 각 뉴런 셀에 멀티캐스팅될 수 있다. 이 경우 뉴런 셀은 특징 벡터와 레이블 값을 기초로 학습을 통해 자신의 반경을 조정할 수 있다. 각 뉴런 셀은 특징 벡터와 해당 뉴런 셀에 지정된 중심값 벡터 간의 거리 정보를 계산하여 뉴런 라우 터에 전달한다. 뉴런 라우터는 각 뉴런 셀에서 계산된 거리 정보를 비교하여 최소 거리 정보를 가진 뉴런 셀의 정보를 획득한다. 뉴런 라우터는 뉴런 퍼실리티 모듈의 각 뉴런 셀에서 전 달한 거리 정보, 최소 거리 정보 및 최소 거리 정보를 가진 뉴런 셀의 정보를 공유 메모리에 저장할 수 있다. 뉴런 라우터는 각 뉴런 셀에서 계산한 거리 정보를 타일 라우터에 전달한다. 각 라우 터 컨트롤러(110, 210, 310)는 전달받은 거리 정보의 최소값(최소 거리 정보)을 구하며, 최상위 계층의 클러스 터 라우터는 최종적인 거리 정보 최소값을 구하고, 이를 바탕으로 RCE-NN 알고리즘의 학습 및 인지 결과를 생성한다. 도 2a 및 도 2b는 공유 메모리를 사용하지 않는 아키텍처에서의 뉴런 셀 학습에 대한 블록도와 타이밍도이다. 도 2a는 공유 메모리를 사용하지 않는 경우의 뉴런 셀의 구성을 나타낸 블록도인데, 뉴런 셀마다 자신의 특징 메모리를 가지고 있다. 예를 들어, 뉴런 셀은 자신의 특징 메모리에 고유의 중심값 데이터를 저장한다. 도 2b는 공유 메모리를 사용하지 않는 아키텍처에서 뉴런 셀 학습에 대한 타이밍도인데, 도 2b에 도시한 바와 같이, 각 뉴런 셀마다 존재하는 특징 메모리에 메모리 쓰기 작업이 연속적으로 이루어지는 모습을 볼 수 있다. 도 3a 및 도 3b는 공유 메모리를 사용하는 아키텍처에서의 뉴런 셀 학습에 대한 블록도와 타이밍도이다. 도 3a는 본 발명의 일 실시예에 따른, 공유 메모리를 사용하는 경우의 뉴런 라우터의 구성을 나타낸 블록 도이다. 뉴런 라우터는 공유 메모리를 포함한다. 뉴런 라우터에 포함된 공유 메모리는 하 위 노드인 뉴런 셀의 특징 메모리를 병합한 형태이다. 도 3b에 도시한 바와 같이, 뉴런 라우터는 뉴런 셀의 학습 과정에서, 과거에 학습한 뉴런 셀에 관련 된 특징 데이터(예: 중심값 벡터)를 유지하기 위하여 메모리 쓰기 이전에 메모리 읽기를 통해 데이터 병합 (concatenation)을 수행한 후, 메모리 쓰기 동작을 수행한다. 공유 메모리를 이용한 뉴런 셀의 학습 과정을 아래에 구체적으로 기술한다. 인공지능 연산 처리 장치는, RCE-NN 알고리즘에 따라, 아키텍처에 존재하는 모든 뉴런 셀을 순차적으 로 학습시킨다. 뉴런 셀의 학습은 고유의 중심값 데이터(예: 중심값 벡터)를 결정하는 것부터 시작된다. 뉴런 셀의 중심값은 입력되는 특징 데이터(학습용 특징 데이터)를 기반으로 생성된다. 예를 들어, 뉴런 셀 에 입력되는 첫 번째 특징 데이터가 해당 뉴런 셀의 고유의 중심값 데이터가 된다. 뉴런 라우터(11 0)는 특정 뉴런 셀의 중심값 데이터로 정해진 특징 데이터를 공유 메모리에 저장한다. 공유 메모리 에 한번 저장된 뉴런 셀의 중심값은, 재학습으로 인해 업데이트되기 전에는 변동되지 않는다. 상술한 방식을 통해 모든 학습된 뉴런 셀은 고유의 중심값 데이터를 가진다. 뉴런 라우터는 모든 학습된 뉴 런 셀의 중심값 데이터를 공유 메모리에 저장한다. 뉴런 셀은 결정된 중심값 데이터와 중심값 결정 이후 입력되는 특징 데이터 간의 거리정보를 계산하게 된 다. 뉴런 셀이 재학습되는 경우, 뉴런 라우터는 해당 뉴런 셀의 중심값을 업데이트하기 위해, 새롭 게 입력된 특징 데이터를 기초로 공유 메모리에 쓰기 과정을 수행한다. 이 경우, 과거에 학습했던 뉴런 셀 의 중심값을 유지할 필요가 있으므로, 뉴런 라우터는 도 3b에 도시한 바와 같이, 재학습 대상이 되 는 뉴런 셀의 기존의 중심값을 공유 메모리에서 읽어들이고, 새롭게 입력된 특징 데이터와 기존의 중 심값을 병합(concatenation)한 후, 병합된 데이터를 공유 메모리에 쓰는 방식으로 해당 뉴런 셀에 대 한 재학습을 수행할 수 있다. 새롭게 입력된 특징 데이터와 기존의 중심값을 병합하는 방법은 다양한 방법이 있 을 수 있다. 예를 들어, 뉴런 라우터는 특징 데이터와 기존의 중심값의 가중 평균값을 공유 메모리에 쓸 수 있다.한편, 도 3a를 참조하여, 뉴런 라우터의 각 구성요소의 기능을 하기에 설명한다. 도 3a에 도시된 일 실시예에서, 뉴런 라우터는 입력 버퍼(Input Buffer), 라우팅 결정부(Routing Decision Unit), 스위치 아비터(Switch Arbiter), 송신부, 입력 스케쥴러(Input Scheduler), 계산부 (Computation Unit), 패킷 생성기(Packet Generator), 네트워크 인터페이스(Network Interface) 및 공유 메모 리를 포함한다. 여기서 입력 버퍼(Input Buffer)는 상위 라우팅 컨트롤러에서 데이터 패킷을 수신하는 입력 버퍼(Input Buffer(from top))와 하위 라우팅 컨트롤러 또는 뉴런 셀에서 데이터 패킷을 수신하는 입력 버퍼(Input Buffer(from bottom))의 두 가지가 있다. 그리고 네트워크 인터페이스(Network Interface)는 패킷 인코더 (Packet Encoder)와 패킷 디코더(Packet Decoder)를 포함한다. 타일 라우터와 클러스터 라우터는 뉴런 라우터의 구성요소와 동일한 구성요소를 가질 수 있다. 즉, 뉴런 라우터의 각 구성요소의 기능에 대한 설명은, 타일 라우터 및 클러스터 라우터의 동일 한 이름의 구성요소에 마찬가지로 적용될 수 있다. 다만, 편의상 뉴런 라우터를 기준으로 그 구성요소에 대해서 설명한다. 뉴런 라우터는 타일 퍼실리티 모듈의 타일 라우터가 뉴런 퍼실리티 모듈에 전송하는 데이 터 패킷을 수신하여 입력 버퍼(Input Buffer(from top)) 또는 공유 메모리에 저장한다. 타일 라우터(21 0)가 전송하는 데이터 패킷은 특징 벡터를 포함한다. 타일 라우터가 전송하는 데이터 패킷은 다른 형태의 특징 데이터를 포함할 수도 있다. 라우팅 결정부(Routing Decision Unit) 또한 상기 데이터 패킷을 수신한다. 라우팅 결정부(Routing Decision Unit)는 타일 라우터가 전송한 데이터 패킷의 헤더 부분(header)의 컨텍스트(context) 정보를 추출한다. 라우팅 결정부(Routing Decision Unit)는 컨텍스트 정보를 현재 학습된(committed) 뉴런 셀의 정보와 조 합하고, 컨텍스트 정보와 부합하는 뉴런 셀과 RTL(Ready to Learn) 상태의 뉴런을 가진 뉴런 셀이 데 이터를 수신할 수 있도록 라우팅 정보를 생성한다. 라우팅 결정부(Routing Decision Unit)는 상술한 동작을 수 행하기 위하여 헤더 파싱 로직(Header Parsing Logic), 라우팅 테이블(Routing Table), 테이블 업데이트 로직 (Table Updating Logic), 라우팅 결정 로직(Routing Decision Logic)을 구비한다. 라우팅 테이블(Routing Table)은 복수의 컨텍스트 레지스터(Context Register)와 학습된 뉴런 셀의 개수와 뉴런 셀 정보를 관리하는 카 운터(Counter)를 포함한다. 스위치 아비터(Switch Arbiter)는, 라우팅 결정부(Routing Decision Unit)의 라우팅 과정을 거쳐 생성된 라우 팅 정보에 따라, 수신처로 정해진 뉴런 셀에 헤더를 포함한 데이터 패킷과 제어 신호(control signal)을 송신부를 통해 전송한다. 이 경우, 송신부는 입력 버퍼에서 데이터 패킷(타일 라우터에서 전송한 데이터 패킷)을 읽어들인 후, 읽어들인 데이터 패킷을 라우팅 정보에 따라 수신처로 정해진 뉴런 셀에 전송할 수 있다. 스위치 아비터는 수신처로 정해진 뉴런 셀의 고유의 중심값 벡터를 공유 메모리에서 추출하여 상기 수신처로 정해진 뉴런 셀에 전송할 데이터 패킷에 포함시킬 수 있다. 즉, 뉴런 라우터에서 뉴런 셀 에 전송되는 데이터 패킷에는 특징 벡터와 해당 뉴런 셀의 중심값 벡터가 포함될 수 있다. 뉴런 셀은 뉴런 라우터에서 수신한 제어 신호에 따라 특징 벡터와 중심값 벡터 간의 거리 정보를 계 산하고, 계산된 거리 정보를 뉴런 라우터에 송신한다. 뉴런 라우터의 스위치 아비터에는 최대 노드 설정값이 지정될 수 있다. 이 경우, 스위치 아비터는 최대 노 드 설정값에 따라 제어 가능한 뉴런 셀의 범위를 판단하고, 상기 범위에 포함된 뉴런 셀에 데이터 패 킷과 제어 신호를 전송한다. 데이터 패킷과 제어 신호를 전송받는 뉴런 셀은 복수 개일 수 있다. 뉴런 라우터는 뉴런 셀이 전송한 데이터 패킷을 입력 버퍼(Input Buffer(from bottom)) 또는 공유 메모리에 저장할 수 있다. 뉴런 라우터는 뉴런 셀에서 수신한 데이터 패킷을 입력 스케쥴러 (Input Scheduler) 또는 네트워크 인터페이스(Network Interface)에 전달한다. 뉴런 셀이 전송한 데이터 패킷에는 거리 정보가 포함되어 있는데, 이 거리 정보는 특징 벡터와 뉴런 셀에 지정된 중심값 벡터 간의 거리 정보이다. 뉴런 라우터는 상기 거리 정보를 공유 메모리에 저장하고, 추후 최소 거리 정보 판단 시 활용할 수 있다. 입력 스케쥴러는 뉴런 셀에서 데이터 패킷이 전송되는지 여부를 확인한다. 네트워크 인터페이스는 입력 스 케쥴러의 스케쥴링 결과에 따라 뉴런 셀에서 전송한 데이터 패킷을 수신한다. 네트워크 인터페이스에 포 함된 패킷 디코더는 뉴런 셀이 전송한 데이터 패킷을 디코딩하여 계산부(Computation Unit)에 전달한다. 계산부(Computation Unit)는 1개 이상의 뉴런 셀에서 전송한 데이터 패킷에 포함된 거리 정보를 기초로 최 소 거리를 판별하고, 최소 거리에 해당하는 뉴런 셀을 식별한다. 계산부(Computation Unit)는 공유 메모리 에서 추출한 거리 정보를 기초로 최소 거리 정보를 생성하고, 최소 거리에 해당하는 뉴런 셀을 식별 할 수 있다. 계산부는 최소 거리 정보와 해당 뉴런 셀 정보(최소 거리에 해당하는 뉴런 셀의 정보)를 패킷 생성 기(Packet Generator)에 전달한다. 이때 계산부는 최소 거리 정보와 해당 뉴런 셀 정보를 공유 메모리에 저장할 수 있다. 패킷 생성기(Packet Generator)는 최소 거리 정보와 최소 거리에 해당하는 뉴런 셀의 정보를 포함한 데이터 패 킷과 계산 완료 신호를 생성한다. 패킷 생성기(Packet Generator)가 생성한 데이터 패킷과 계산 완료 신호는 타 일 퍼실리티 모듈에 전송하기 위한 패킷과 신호이다. 네트워크 인터페이스는 패킷 인코더(Packet Encoder)를 통해 데이터 패킷을 인코딩하여 타일 퍼실리티 모듈 의 타일 라우터에 전송한다. 한편, 뉴런 셀은 네트워크 인터페이스, 계산부(Computation Unit) 및 패킷 생성기(Packet Generator)를 포함한다. 뉴런 셀은 네트워크 인터페이스를 통하여 뉴런 라우터와 데이터와 제어 신호를 송수신한다. 뉴런 셀의 네트워크 인터페이스는 패킷 인코더와 패킷 디코더를 포함한다. 뉴런 셀은 뉴 런 라우터에서 수신한 데이터 패킷을 디코딩하고, 데이터 패킷에서 특징 벡터를 추출한다. 뉴런 셀의 계산부는 특징 벡터와 뉴런 셀에 지정된 중심값 벡터 간의 거리를 계산하여 거리 정보를 생성한다. 뉴런 셀의 패킷 생성기(Packet Generator)는 상기 거리 정보를 기초로 데이터 패킷을 생성한다. 뉴런 셀의 네트워크 인터페이스는 패킷 생성기가 생성한 데이터 패킷을 패킷 인코더를 통해 인코딩하여 뉴런 라우터 에 전송한다. 도 4는 본 발명의 일 실시예에 따른 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 뉴런 셀 학습 방 법을 설명하기 위한 흐름도이다. 본 발명의 일 실시예에 따른 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 뉴런 셀 학습 방법은 S410 단계 내지 S440 단계를 포함한다. 다만, 도 4에 도시된 뉴런 셀 학습 방법은 일 실시예에 따른 것이고, 본 발명에 따른 뉴런 셀 학습 방법의 단계들이 도 4에 도시된 실시예에 한정되는 것은 아니며, 필요에 따라 부가, 변경 또는 삭제될 수 있다. 예를 들어, S430 단계와 S440 단계는 뉴런 셀의 재학습 과정에 관한 단계들로서, 인 공지능 연산 처리 장치가 재학습 과정을 수행하지 않을 경우 삭제될 수 있다. S410 단계는 제1 특징 데이터 입력 단계이다. 뉴런 라우터는 타일 라우터에서 제1 특징 데이터를 입 력받는다. 제1 특징 데이터는 특정한 뉴런 셀의 학습을 위한 데이터이다. 뉴런 라우터는 제1 특징 데 이터를 공유 메모리에 저장한다. S420 단계는 제1 중심값 데이터 결정 단계이다. 뉴런 라우터는 제1 특징 데이터를 기초로 뉴런 셀의 제1 중심값 데이터를 결정한다. 예를 들어, 뉴런 라우터는 제1 특징 데이터를 뉴런 셀의 제1 중심값 데이터로 결정할 수 있다. 그리고, 뉴런 라우터는 제1 중심값 데이터를 공유 메모리에 저장한다. S430 단계는 제2 특징 데이터 입력 단계이다. 뉴런 라우터는 타일 라우터에서 제2 특징 데이터를 입 력받는다. 제2 특징 데이터는 상기 특정한 뉴런 셀의 재학습을 위한 데이터이다. 뉴런 라우터는 제2 특징 데이터를 공유 메모리에 저장한다. S440 단계는 제2 중심값 데이터 결정 단계이다. 뉴런 라우터는 뉴런 셀의 제1 중심값 데이터를 공유 메모리에서 읽어 들인다. 뉴런 라우터는 제1 중심값 데이터와 제2 특징 데이터를 기초로 뉴런 셀 의 제2 중심값 데이터를 결정한다. 제2 중심값 데이터는 뉴런 셀에 대하여 업데이트된 중심값 데이터 이다. 예를 들어, 뉴런 라우터는 제1 중심값 데이터와 제2 특징 데이터의 가중치 평균 데이터를 뉴런 셀 의 새로운 중심값 데이터(제2 중심값 데이터)로 결정할 수 있다. 그리고, 뉴런 라우터는 제2 중심값 데이터를 공유 메모리에 저장한다.전술한 뉴런 셀 학습 방법은 도면에 제시된 흐름도를 참조로 하여 설명되었다. 간단히 설명하기 위하여 상기 방 법은 일련의 블록들로 도시되고 설명되었으나, 본 발명은 상기 블록들의 순서에 한정되지 않고, 몇몇 블록들은 다른 블록들과 본 명세서에서 도시되고 기술된 것과 상이한 순서로 또는 동시에 일어날 수도 있으며, 동일한 또 는 유사한 결과를 달성하는 다양한 다른 분기, 흐름 경로, 및 블록의 순서들이 구현될 수 있다. 또한, 본 명세 서에서 기술되는 방법의 구현을 위하여 도시된 모든 블록들이 요구되지 않을 수도 있다. 한편 도 4를 참조한 설명에서, 각 단계는 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적 은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 아울러, 기타 생략된 내용이라 하더라도 도 1 내지 도 3b의 내용은 도 4의 내용에 적용될 수 있다. 또한, 도 4의 내용은 도 1 내지 도 3b의 내용에 적용될 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0163504", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 구성과 하드웨어 아키텍처 구조를 나타낸 블록도. 도 2a 및 도 2b는 공유 메모리를 사용하지 않는 아키텍처에서의 뉴런 셀 학습에 대한 블록도와 타이밍도. 도 3a 및 도 3b는 공유 메모리를 사용하는 아키텍처에서의 뉴런 셀 학습에 대한 블록도와 타이밍도. 도 4는 본 발명의 일 실시예에 따른 공유 메모리 구조 기반의 경량 인공지능 연산 처리 장치의 뉴런 셀 학습 방 법을 설명하기 위한 흐름도."}
