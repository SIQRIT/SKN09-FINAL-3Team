{"patent_id": "10-2023-0068484", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0118634", "출원번호": "10-2023-0068484", "발명의 명칭": "객체 인식 인공지능 모델의 정확도를 산출하는 방법", "출원인": "주식회사 컴패니언즈", "발명자": "한상우"}}
{"patent_id": "10-2023-0068484", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서가 객체 추출 인공지능 모델을 통해 객체 이미지와 배경 이미지를 포함하는 이미지로부터 객체 이미지만을 추출하여 상기 이미지를 전처리하는 단계;상기 프로세서가 객체 인식 인공지능 모델을 통해 상기 객체 이미지로부터 상기 객체 이미지가 나타내는 객체의종류를 인식하여 객체 인식 데이터를 생성하는 단계; 및상기 프로세서가 상기 객체 인식 인공지능 모델의 제1 로스값이 최소가 되도록 파라미터 최적화 알고리즘을 통해 상기 객체 인식 인공지능 모델의 파라미터를 보정하는 단계;를 포함하고,상기 이미지를 전처리하는 단계는상기 프로세서가 상기 이미지를 복수의 단위 픽셀로 분할하고, 상기 복수의 단위 픽셀에 대응되는 제1 특징맵을생성하는 단계;상기 프로세서가 상기 제1 특징맵의 차원을 복수회 축소시키는 단계;상기 프로세서가 차원이 복수회 축소된 상기 제1 특징맵의 차원을 복수회 확장시키는 단계;상기 프로세서가 차원이 복수회 확장된 상기 제1 특징맵으로부터 상기 복수의 단위 픽셀이 객체인지 여부를 나타내는 세그멘테이션 맵을 생성하는 단계; 및상기 세그멘테이션 맵에 기초하여 상기 이미지에서 상기 배경 이미지가 제외된 상기 객체 이미지를 추출하는 단계;를 포함하고,상기 객체 인식 데이터를 생성하는 단계는상기 프로세서가 상기 객체 인식 인공지능 모델의 백본 모듈을 통해 상기 객체 이미지의 제2 특징맵을 생성하는단계; 및상기 프로세서가 상기 객체 인식 인공지능 모델의 헤드 모듈을 통해 상기 제2 특징맵에 기초하여 상기 객체 이미지가 나타내는 상기 객체의 종류를 인식 후 객체 인식 데이터를 생성하는 단계;를 포함하고,상기 객체 인식 데이터를 생성하는 단계는상기 프로세서가 훈련 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델을 학습시키는 단계;상기 프로세서가 검증 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델의 제2 로스값을 산출하는 단계;상기 프로세서가 상기 제2 로스값의 증감에 기초하여 상기 훈련 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델을 재학습시킬지 여부를 결정하는 단계; 및상기 프로세서가 테스트 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델의 정확도를 산출하는 단계;를더 포함하고상기 파라미터를 보정하는 단계는상기 프로세서가 이전에 생성된 객체 인식 데이터의 전체 개수 대비 인식된 객체의 종류 각각의 개수를 종류 비율로 산출하는 단계;상기 프로세서가 상기 종류 비율이 가장 높은 객체의 종류에 대한 종류 비율이 포함되는 비율 구간을 확인하는단계;상기 프로세서가 상기 비율 구간에 미리 매칭된 매칭 파라미터로 상기 파라미터를 보정하는 단계;를 포함하는것을 특징으로 하는객체 인식 인공지능 모델의 정확도를 산출하는 방법.공개특허 10-2024-0118634-3-"}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명에 따른 방법은 프로세서가 객체 추출 인공지능 모델을 통해 객체 이 미지와 배경 이미지를 포함하는 이미지로부터 객체 이미지만을 추출하여 상기 이미지를 전처리하는 단계; 상기 프로세서가 객체 인식 인공지능 모델을 통해 상기 객체 이미지로부터 상기 객체 이미지가 나타내는 객체의 종류 를 인식하여 객체 인식 데이터를 생성하는 단계; 및 상기 프로세서가 상기 객체 인식 인공지능 모델의 제1 로스 값이 최소가 되도록 파라미터 최적화 알고리즘을 통해 상기 객체 인식 인공지능 모델의 파라미터를 보정하는 단 계;를 포함할 수 있다."}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 배경 이미지와 객체 이미지가 포함된 이미지로부터 객체 이미지만을 추출하고, 객체 인식 인공지능 모델을 통해 추출된 객체 이미지가 나타내는 객체의 종류를 인식하여 객체 인식 데이터를 생성하고, 객체 인식 인공지능 모델의 로스값이 최소가 되도록 파라미터를 보정하는 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 관한 것이다."}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 딥러닝 모델의 성능은 일반적으로 모델의 학습을 위한 데이터의 양에 크게 의존하는 경향이 있다. 예를 들어, 기존 딥러닝 모델이 일정 수준 이상의 정확도로 객체를 검출하기 위해서는, 관심 객체에 대한 바운딩 박 스(bounding box)가 정확하게 어노테이션(annotation)된 수백만 개에 이르는 방대한 양의 학습 데이터가 필요하 다. 양질의 학습 데이터가 충분히 확보되지 못한 경우, 과적합(overfitting), 추론 편향(bias) 등의 오류로 인 해 딥러닝 모델이 객체 검출이라는 태스크(task)를 제대로 해결하지 못하는 문제가 발생할 수 있다. 따라서, 딥 러닝 모델의 성능을 담보하기 위해서는, 현실을 충분히 잘 반영할 정도로 다양하고 품질이 우수한 학습 데이터 를 충분히 많은 양으로 확보하는 것이 필요하다고 볼 수 있다. 앞서 살펴본 바와 같이 기존에는 딥러닝 모델의 정확한 성능을 담보하기 위해서 딥러닝 모델의 학습 단계에서 양질의 학습 데이터를 충분히 많은 양으로 확보하는 것이 필요하다. 다만, 인간의 사물 인식 방식과 비교해 볼 때, 대량의 학습 데이터를 전제로 하는 딥러닝 모델의 학습 방식은 상당히 비효율적이라고 볼 수 있다. 예를 들 어, 인간은 단 몇 장의 사진(i.e. 학습 데이터)을 가지고도 생애 처음으로 본 사물을 충분히 구분할 수 있다. 반면, 기존의 딥러닝 모델은 인간과 같이 단 몇 장의 학습 데이터만으로는 이미지 내에 포함된 객체를 정확하게 구분해낼 수 없다. 따라서, 일부 객체의 범주에 대한 자연적인 예가 거의 없거나 객체에 대한 어노테이션을 얻 기 어려운 경우, 기존의 딥러닝 모델은 대부분 인간의 사물 인식에 한참 못 미치는 수준의 인식 결과를 보여준 다. 이에 따라, 최근 당 업계에서는 인간처럼 소량의(few-shot) 데이터만으로도 효과적인 학습을 수행하고 정확한 사물 인식 성능을 보장할 수 있는 딥러닝 알고리즘에 대한 논의가 진행되고 있는 상황이다. 선행기술문헌 특허문헌 (특허문헌 0001) 미국등록특허 제10,872,276호"}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 배경 이미지와 객체 이미지가 포함된 이미지로부터 객체 이미지만을 추출하고, 객체 인식 인공지능 모델을 통해 추출된 객체 이미지가 나타내는 객체의 종류를 인식하여 객체 인식 데이터를 생성하고, 객체 인식 인공지능 모델의 로스값이 최소가 되도록 파라미터를 보정할 수 있는 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 관한 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명에 따른 방법은 프로세서가 객체 추출 인공지능 모델을 통해 객체 이 미지와 배경 이미지를 포함하는 이미지로부터 객체 이미지만을 추출하여 상기 이미지를 전처리하는 단계; 상기 프로세서가 객체 인식 인공지능 모델을 통해 상기 객체 이미지로부터 상기 객체 이미지가 나타내는 객체의 종류 를 인식하여 객체 인식 데이터를 생성하는 단계; 및 상기 프로세서가 상기 객체 인식 인공지능 모델의 제1 로스 값이 최소가 되도록 파라미터 최적화 알고리즘을 통해 상기 객체 인식 인공지능 모델의 파라미터를 보정하는 단 계;를 포함할 수 있다. 상기 이미지를 전처리하는 단계는 상기 프로세서가 상기 이미지를 복수의 단위 픽셀로 분할하고, 상기 복수의 단위 픽셀에 대응되는 제1 특징맵을 생성하는 단계; 상기 프로세서가 상기 제1 특징맵의 차원을 복수회 축소시 키는 단계; 상기 프로세서가 차원이 복수회 축소된 상기 제1 특징맵의 차원을 복수회 확장시키는 단계; 상기 프 로세서가 차원이 복수회 확장된 상기 제1 특징맵으로부터 상기 복수의 단위 픽셀이 객체인지 여부를 나타내는 세그멘테이션 맵을 생성하는 단계; 및 상기 세그멘테이션 맵에 기초하여 상기 이미지에서 상기 배경 이미지가 제외된 상기 객체 이미지를 추출하는 단계;를 포함할 수 있다. 바람직하게, 상기 객체 인식 데이터를 생성하는 단계는 상기 프로세서가 상기 객체 인식 인공지능 모델의 백본 모듈을 통해 상기 객체 이미지의 제2 특징맵을 생성하는 단계; 및 상기 프로세서가 상기 객체 인식 인공지능 모 델의 헤드 모듈을 통해 상기 제2 특징맵에 기초하여 상기 객체 이미지가 나타내는 상기 객체의 종류를 인식 후 객체 인식 데이터를 생성하는 단계;를 포함할 수 있다. 바람직하게, 상기 객체 인식 데이터를 생성하는 단계는 상기 프로세서가 훈련 데이터 세트를 이용하여 상기 객 체 인식 인공지능 모델을 학습시키는 단계; 상기 프로세서가 검증 데이터 세트를 이용하여 상기 객체 인식 인공 지능 모델의 제2 로스값을 산출하는 단계; 상기 프로세서가 상기 제2 로스값의 증감에 기초하여 상기 훈련 데이 터 세트를 이용하여 상기 객체 인식 인공지능 모델을 재학습시킬지 여부를 결정하는 단계; 및 상기 프로세서가 테스트 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델의 정확도를 산출하는 단계;를 포함할 수 있다. 바람직하게, 상기 객체 인식 인공지능 모델을 재학습시킬지 여부를 결정하는 단계는 상기 제2 로스값이 증가되 지 않으면 상기 훈련 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델을 재학습시키는 것으로 결정하는 단계; 및 상기 제2 로스값이 증가되면 상기 훈련 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델을 재학 습시키지 않고 상기 테스트 데이터 세트를 이용하여 상기 객체 인식 인공지능 모델의 정확도를 산출하는 것으로 결정하는 단계;를 포함할 수 있다. 바람직하게, 상기 파라미터를 보정하는 단계는 상기 프로세서가 상기 객체 인식 인공지능 모델의 파라미터를 초 기값으로 설정하는 단계; 상기 프로세서가 초기값으로 파라미터가 설정된 상기 객체 인식 인공지능 모델의 상기 제1 로스값을 산출하는 제1 로스 함수의 기울기를 산출하는 단계; 및 상기 프로세서가 상기 제1 로스 함수의 기 울기에 기초하여 상기 파라미터를 보정하는 단계;를 포함할 수 있다. 바람직하게, 상기 제1 로스 함수의 기울기에 기초하여 상기 파라미터를 보정하는 단계는 상기 제1 로스 함수의 기울기가 양수이면 상기 파라미터를 감소시켜 보정하는 단계; 및 상기 제1 로스 함수의 기울기가 음수이면 상기 파라미터를 증가시켜 보정하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 배경 이미지와 객체 이미지가 포함된 이미지로부터 객체 이미지만을 추출하고, 객체 인식 인 공지능 모델을 통해 추출된 객체 이미지가 나타내는 객체의 종류를 인식하여 객체 인식 데이터를 생성함으로써, 객체 인식의 대상이 아닌 배경 이미지는 제외시키고 객체 이미지만으로부터 객체 인식을 수행함으로써, 객체 인 식의 정확도와 객체 인식에 소요되는 연산처리를 감소시킬 수 있다."}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 발명을 특정한 실시 형 태에 대해 한정하려는 것이 아니며, 본 발명의 실시 예의 다양한 변경(modification), 균등물(equivalent), 및/ 또는 대체물(alternative)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대 해서는 유사한 참조 부호가 사용될 수 있다. 본 문서에서, \"가진다\", \"가질 수 있다\", \"포함한다\", 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B\", \"A 또는/및 B 중 적어도 하나\", 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B\", \"A 및 B 중 적어도 하나\", 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \"제1\", \"제2\", \"첫째\", 또는 \"둘째\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 예를 들면, 제1 착용자 기기와 제2 착용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 착용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 바꾸어 명명될 수 있다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도 록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성(또는 설정)된\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\"것만 을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성 (또는 설정)된 “서버\" 또는 “장치”는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또 는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 문서에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 실시 예의 범위를 한 정하려는 의도가 아닐 수 있다. 단수의 표현은 컨텍스트 상 명백하게 다르게 뜻하지 않는 한, 제1 내지 제3 표 현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 문서에 사용된 용어들 중 일반적인 사전에 정의된 용어들은 관련 기술의 컨텍스트 상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해 석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해석될 수 없다. 도 1은 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 제 어되는 전자 장치 및 데이터 서버를 도시한 도면이고, 도 2는 본 발명의 일 실시 예에 따른 인공지능 모델을 이 용하여 이미지로부터 객체를 인식하는 방법에 의해 제어되는 전자 장치의 구성도이다. 도 1 및 도 2를 참조하면, 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하 는 방법에 의해 제어되는 전자 장치는 데이터 서버로부터 객체 인식의 대상이 되는 이미지, 인공지능 모델을 학습시키는데 이용되는 훈련 데이터 세트, 인공지능 모델을 검증하는데 이용되는 검증 데이터 세트 및 인공지능 모델을 테스트하는데 이용되는 테스트 데이터 세트를 수신할 수 있다. 여기서, 이미지는 데이터 서버에 의해 운영되는 컨텐츠 공유 플랫폼에 업로드되는 이미지일 수 있다. 예를 들어, 데이터 서버에 의해 운영되는 컨텐츠 공유 플랫폼은 반려동물과 관련한 컨텐츠를 공유하는 플 랫폼일 수 있고, 반려동물과 관련한 컨텐츠는 상술된 이미지로 사진 및 영상 중 하나 이상일 수 있다. 이를 위해, 컨텐츠 공유 플랫폼에 대응되는 애플리케이션이 설치 및 구동되는 창작자 장치로부터 데이터 서버 는 컨텐츠에 대한 컨텐츠 데이터(이미지)를 획득하고 획득된 컨텐츠 데이터를 컨텐츠 공유 플랫폼에 업로 드하여 컨텐츠가 게시되도록 할 수 있다. 여기서, 컨텐츠는 사진, 동영상 및 텍스트 등 그 유형이 정해지지 않을 수 있다. 바람직하게, 본 발명에서 창작 물 컨텐츠는 크기가 정해진 사진 및 재생시간이 미리 설정된 시간 이내인 동영상일 수 있다. 또한, 본 발명에서 창작물 컨텐츠는 반려동물과 관련된 주제의 컨텐츠를 포함할 수 있다. 데이터 서버는 상술한 바와 같이, 컨텐츠 공유 플랫폼을 운영하는 전자 장치이며, 컨텐츠 공유 플랫폼의 운영자에 의해 제어되는 장치일 수 있다. 이러한, 데이터 서버는 컨텐츠 공유 플랫폼을 운영하고 관리하는데 필요한 정보 및 데이터를 송수신 및 관 리할 수 있다. 여기서, 컨텐츠 공유 플랫폼은 특정 주제에 대한 컨텐츠가 창작자에 의해 게시되는 플랫폼일 수 있다. 이때, 컨텐츠 공유 플랫폼의 회원으로 창작자 및 사용자가 등록될 수 있다. 즉, 창작자는 창작한 컨텐츠를 컨텐츠 공유 플랫폼에 게시하고, 사용자는 컨텐츠 공유 플랫폼에 게시된 컨텐츠 를 열람할 수 있다. 또한, 사용자는 열람한 컨텐츠에 의견을 게시하거나 선호 여부 정보를 게시할 수 있다. 즉, 전자 장치는 데이터 서버로부터 컨텐츠 공유 플랫폼에 업로드된 이미지를 수신하고, 본 발명의 일 실시 예에 따른 인공 지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법을 통해서 이미지로부터 객체 이미지를 추출하며, 추 출된 객체 이미지가 나타내는 객체의 종류를 인식하여 객체 인식 데이터를 생성할 수 있다. 한편, 전자 장치는 객체 인식 인공지능 모델을 통해 객체 인식 데이터를 생성할 수 있다. 또한, 전자 장치는 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법을 통해서 객체 인식 인공지능 모델의 제1 로스값이 최소가 되도록 파라미터 최적화 알고리즘을 통해 객체 인식 인공지능 모델의 파라미터를 보정할 수 있다. 이를 위해, 전자 장치는, 메모리, 프로세서 및 통신부를 포함할 수 있다. 메모리는 전자 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 프로세서는 메모리에 저장된 각종 프로그램을 이용하여 전자 장치의 전반적인 동작을 제어할 수 있다. 프로세서는 RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스 및 버스로 구성될 수 있다.이때, RAM, ROM, 그래픽 처리부, 메인 CPU, 제1 내지 n 인터페이스 등은 버스를 통해 서로 연결될 수 있다. RAM은 O/S 및 어플리케이션 프로그램을 저장한다. 구체적으로, 전자 장치가 부팅되면 O/S가 RAM에 저장되 고, 사용자가 선택한 각종 어플리케이션 데이터가 RAM에 저장될 수 있다. ROM에는 시스템 부팅을 위한 명령어 세트 등이 저장된다. 턴 온 명령이 입력되어 전원이 공급되면, 메인 CPU는 ROM에 저장된 명령어에 따라 메모리에 저장된 O/S를 RAM에 복사하고, O/S를 실행시켜 시스템을 부팅시킨다. 부팅이 완료되면, 메인 CPU는 메모리에 저장된 각종 어플리케이션 프로그램을 RAM에 복사하고, RAM에 복사된 어플리케이션 프로그램을 실행시켜 각종 동작을 수행한다. 메인 CPU는 메모리에 액세스하여, 메모리에 저장된 OS를 이용하여 부팅을 수행한다. 그리고, 메인 CPU는 메모리에 저장된 각종 프로그램, 컨텐츠, 데이터 등을 이용하여 다양한 동작을 수행한다. 제1 내지 n 인터페이스는 상술한 각종 구성요소들과 연결된다. 제1 내지 n 인터페이스 중 하나는 네트워크를 통 해 외부 장치와 연결되는 네트워크 인터페이스가 될 수도 있다. 한편, 프로세서는 하나 이상의 코어(core, 미도시) 및 그래픽 처리부(미도시) 및/또는 다른 구성 요소와 신호를 송수신하는 연결 통로(예를 들어, 버스(bus) 등)를 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 본 발명과 관련하여 설명된 방법을 수행한다. 한편, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저 장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리에는 프로세서의 처리 및 제어를 위한 프로그램들(하나 이상의 인스트럭션들)을 저장할 수 있 다. 메모리에 저장된 프로그램들은 기능에 따라 복수 개의 모듈들로 구분될 수 있다. 통신부는 데이터 서버와 통신을 수행할 수 있다. 특히, 통신부는 와이파이 칩, 블루투스 칩, 무 선 통신 칩, NFC칩, 저전력 블루투스 칩(BLE 칩) 등과 같은 다양한 통신 칩을 포함할 수 있다. 이때, 와이파이 칩, 블루투스 칩, NFC 칩은 각각 LAN 방식, WiFi 방식, 블루투스 방식, NFC 방식으로 통신을 수행한다. 와이파 이 칩이나 블루투스칩을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신 하여, 이 를 이용하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신칩은 IEEE, 지그비, 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), 5G(5th Generation) 등 과 같은 다양한 통신 규격에 따라 통신을 수행하는 칩을 의미한다. 도 3은 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법의 순서도이 다. 도 3을 참조하면, 전자 장치의 프로세서는 객체 추출 인공지능 모델을 통해 객체 이미지와 배경 이미 지를 포함하는 이미지로부터 객체 이미지만을 추출하여 이미지를 전처리할 수 있다(S1). 프로세서는 이미지를 복수의 단위 픽셀로 분할하고, 복수의 단위 픽셀에 대응되는 제1 특징맵을 생성할 수 있다. 이후, 프로세서는 제1 특징맵의 차원을 복수회 축소시키고, 차원이 복수회 축소된 제1 특징맵의 차원을 복 수회 확장시킬 수 있다. 이때, 프로세서는 제1 특징맵의 차원을 n회 축소시키고, 차원이 n회 축소된 제1 특징맵의 차원을 n회 확장 시킬 수 있다. 여기서, n은 1이상의 자연수이고, 최대값은 s일 수 있다. 또한, 프로세서는 제1 특징맵의 차원을 n회 확장시키는 경우, 차원이 n-1회 확장된 제1 특징맵과 차원이 s-n+1회 축소된 제1 특징맵이 결합된 특징맵을 이용하여 제1 특징맵의 차원을 확장시킬 수 있다. 이후, 프로세서는 프로세서가 차원이 복수회 확장된 제1 특징맵으로부터 복수의 단위 픽셀이 객체인지 여 부를 나타내는 세그멘테이션 맵을 생성할 수 있다.여기서, 세그멘테이션 맵은 이미지 내에서 복수의 단위 픽셀 각각의 위치를 나타내는 위치 정보와 해당 단위 픽 셀이 객체인지 여부를 나타내는 객체 여부 정보가 포함될 수 있다. 예를 들어, 위치 정보 (1,1)의 단위 픽셀이 객체인 경우, 세그멘테이션 맵은 (1,1) 위치의 객체 여부 정보가 1 로 정해지고, 위치 정보 (1,1)의 단위 픽셀이 객체가 아닌 경우, 세그멘테이션 맵은 (1,1) 위치의 객체 여부 정 보가 0으로 정해질 수 있다. 이후, 프로세서는 객체 여부 정보가 객체임을 나타내는 단위 픽셀들을 추출하여 객체 이미지로 추출할 수 있다. 도 4는 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 이 용되는 객체 추출 인공지능 모델의 일 예를 도시한 도면이다. 프로세서의 객체 이미지 추출은 객체 추출 인공지능 모델을 이용하여 수행될 수 있으며, 객체 추출 인공지 능 모델은 도 4에 도시된 “U-Net” 모델로 구현될 수 있다. 즉, 프로세서는 이미지를 “U-Net” 모델에 입력 데이터로 입력하고 출력 데이터로 세그멘테이션 맵을 출 력받으며, 세그멘테이션 맵을 이용하여 객체 이미지를 추출할 수 있다. 하지만, 이미지로부터 객체 이미지를 추출할 수 있는 한, 객체 추출 인공지능 모델의 종류는 제한되지 않을 수 있다. 도 5는 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 이 용되는 객체 인식 인공지능 모델의 일 예를 도시한 도면이다. 도 5를 더 참조하면, 프로세서는 객체 인식 인공지능 모델을 통해 객체 이미지로부터 객체 이미지가 나타 내는 객체의 종류를 인식하여 객체 인식 데이터를 생성할 수 있다(S2). 구체적으로, 프로세서는 객체 인식 인공지능 모델의 백본 모듈을 통해 객체 이미지의 제2 특징맵을 생성할 수 있다. 즉, 프로세서는 객체 이미지를 객체 인식 인공지능 모델의 백본 모듈에 입력 데이터로 입력하고 출력 데이 터로 제2 특징맵을 출력받을 수 있다. 이후, 프로세서는 객체 인식 인공지능 모델의 헤드 모듈을 통해 제2 특징맵에 기초하여 객체 이미지가 나 타내는 객체의 종류를 인식 후 객체 인식 데이터를 생성할 수 있다. 즉, 프로세서는 제2 특징맵을 객체 인식 인공지능 모델의 헤드 모듈에 입력 데이터로 입력하고 출력 데이 터로 객체 인식 데이터를 출력받을 수 있다. 여기서, 객체 인식 데이터는 객체 이미지가 나타내는 객체의 종류에 대한 데이터일 수 있다. 한편, 객체 인식 인공지능 모델의 백본 모듈은 “ResNet50” 모델로 구현될 수 있다. 즉, 프로세서는 객체 이미지를 “ResNet50” 모델로 구현된 객체 인식 인공지능 모델의 백본 모듈에 입력 데이터로 입력하고 출력 데이터로 제2 특징맵을 출력받을 수 있다. 즉, 본 발명에 따른 객체 인식 인공지능 모델은 백본 모듈과 헤드 모듈로 구성된 “YoLo” 모델로 구현되고, 백 본 모듈이 “ResNet50” 모델로 구현되는 인공지능 모델일 수 있다. 하지만, 객체 이미지가 나타내는 객체의 종류를 인식하는 한, 객체 인식 인공지능 모델의 종류는 제한되지 않을 수 있다. 도 6은 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 이 용되는 파라미터 최적화 알고리즘의 일 예를 도시한 도면이다. 한편, 프로세서는 검증 데이터를 이용하여 객체 인식 인공지능 모델의 학습을 조절할 수 있다. 구체적으로, 프로세서는 데이터 서버로부터 복수의 이미지(컨텐츠)를 수신하도록 통신부를 제어 하고, 복수의 이미지를 데이터 세트로 구성하며, 해당 데이터 세트를 훈련 데이터 세트(Training), 검증 데이터 세트(Validation), 테스트 데이터 세트(Test)로 분류할 수 있다.이때, 훈련 데이터 세트, 검증 데이터 세트, 테스트 데이터 세트 각각은 중복되지 않는 데이터 세이트이며, 개 수는 6:2:2일 수 있다. 이후, 프로세서는 훈련 데이터 세트를 이용하여 객체 인식 인공지능 모델을 학습시킬 수 있다. 이어서, 프로세서는 검증 데이터 세트를 이용하여 객체 인식 인공지능 모델의 제2 로스값을 산출할 수 있 다. 이때, 프로세서는 제2 로스값의 증감에 기초하여 훈련 데이터 세트를 이용하여 객체 인식 인공지능 모델을 재학습시킬지 여부를 결정할 수 있다. 구체적으로, 프로세서는 제2 로스값이 증가되지 않으면 훈련 데이터 세트를 이용하여 객체 인식 인공지능 모델을 재학습시키는 것으로 결정할 수 있다. 반대로, 프로세서는 제2 로스값이 증가되면 훈련 데이터 세트를 이용하여 객체 인식 인공지능 모델을 재학 습시키지 않고 테스트 데이터 세트를 이용하여 객체 인식 인공지능 모델의 정확도를 산출하는 것으로 결정할 수 있다. 객체 인식 인공지능 모델의 정확도를 산출하는 것으로 결정되면, 프로세서는 테스트 데이터 세트를 이용하 여 객체 인식 인공지능 모델의 정확도를 산출할 수 있다. 이때, 프로세서는 테스트 데이터 세트를 객체 인식 인공지능 모델에 입력하여 출력된 출력 데이터와, 테스 트 데이터 세트의 실제 객체 종류 데이터 간의 차이를 정확도로 산출할 수 있다. 이를 통해, 프로세서는 객체 인식 인공지능 모델의 오버피팅을 방지할 수 있다. 다른 실시 예에 따른, 프로세서는 객체 인식 인공지능 모델을 구성하는 백본 모듈에 대해서만 훈련 데이터 세트를 이용하여 학습시킬 수 있다. 프로세서는 훈련 데이터 세트를 이용하여 백본 모듈을 학습시킬 수 있다. 이어서, 프로세서는 검증 데이터 세트를 이용하여 백본 모듈의 제3 로스값을 산출할 수 있다. 이때, 프로세서는 제3 로스값의 증감에 기초하여 훈련 데이터 세트를 이용하여 백본 모듈을 재학습시킬지 여부를 결정할 수 있다. 구체적으로, 프로세서는 제3 로스값이 증가되지 않으면 훈련 데이터 세트를 이용하여 백본 모듈을 재학습 시키는 것으로 결정할 수 있다. 반대로, 프로세서는 제3 로스값이 증가되면 훈련 데이터 세트를 이용하여 백본 모듈을 재학습시키지 않고 테스트 데이터 세트를 이용하여 백본 모듈의 정확도를 산출하는 것으로 결정할 수 있다. 백본 모듈의 정확도를 산출하는 것으로 결정되면, 프로세서는 테스트 데이터 세트를 이용하여 백본 모듈의 정확도를 산출할 수 있다. 이때, 프로세서는 테스트 데이터 세트를 백본 모듈에 입력하여 출력된 출력 데이터와, 테스트 데이터 세트 의 실제 객체 종류 데이터 간의 차이를 정확도로 산출할 수 있다. 이를 통해, 프로세서는 백본 모듈의 오버피팅을 방지할 수 있다. 또 다른 실시 예에 따른, 프로세서는 객체 인식 인공지능 모델을 구성하는 헤드 모듈에 대해서만 훈련 데 이터 세트를 이용하여 학습시킬 수 있다. 프로세서는 훈련 데이터 세트를 이용하여 헤드 모듈을 학습시킬 수 있다. 이어서, 프로세서는 검증 데이터 세트를 이용하여 헤드 모듈의 제4 로스값을 산출할 수 있다. 이때, 프로세서는 제4 로스값의 증감에 기초하여 훈련 데이터 세트를 이용하여 헤드 모듈을 재학습시킬지 여부를 결정할 수 있다. 구체적으로, 프로세서는 제4 로스값이 증가되지 않으면 훈련 데이터 세트를 이용하여 헤드 모듈을 재학습 시키는 것으로 결정할 수 있다. 반대로, 프로세서는 제4 로스값이 증가되면 훈련 데이터 세트를 이용하여 헤드 모듈을 재학습시키지 않고 테스트 데이터 세트를 이용하여 헤드 모듈의 정확도를 산출하는 것으로 결정할 수 있다. 헤드 모듈의 정확도를 산출하는 것으로 결정되면, 프로세서는 테스트 데이터 세트를 이용하여 헤드 모듈의 정확도를 산출할 수 있다. 이때, 프로세서는 테스트 데이터 세트를 헤드 모듈에 입력하여 출력된 출력 데이터와, 테스트 데이터 세트 의 실제 객체 종류 데이터 간의 차이를 정확도로 산출할 수 있다. 이를 통해, 프로세서는 헤드 모듈의 오버피팅을 방지할 수 있다. 한편, 프로세서는 객체 인식 인공지능 모델의 제1 로스값이 최소가 되도록 파라미터 최적화 알고리즘을 통 해 객체 인식 인공지능 모델의 파라미터를 보정할 수 있다(S3). 구체적으로, 프로세서는 프로세서가 객체 인식 인공지능 모델의 파라미터를 초기값으로 설정하고, 초기값 으로 파라미터가 설정된 객체 인식 인공지능 모델의 제1 로스값을 산출하는 제1 로스 함수의 기울기를 산출할 수 있다. 여기서, 제1 로스 함수는 파라미터에 대응되어 변경되는 함수일 수 있다. 여기서, 파라미터는 객체 인식 인공지 능 모델의 백본 모듈과 헤드 모듈을 구성하는 레이어(컨볼루젼 레이어)의 가중치(Weight) 및 편향치(Bias)일 수 있다. 이후, 프로세서는 제1 로스 함수의 기울기에 기초하여 파라미터를 보정할 수 있다. 구체적으로, 프로세서는 제1 로스 함수의 기울기가 양수이면 파라미터를 감소시켜 보정할 수 있다. 이때, 프로세서는 제1 로스 함수의 기울기가 양수이면서 절대값이 작을수록 파라미터를 더 많이 감소시켜 보정할 수 있다. 또한, 프로세서는 제1 로스 함수의 기울기가 음수이면 파라미터를 증가시켜 보정할 수 있다. 이때, 프로세 서는 제1 로스 함수의 기울기가 음수이면서 절대값이 작을수록 파라미터를 더 많이 증가시켜 보정할 수 있 다. 이후, 프로세서는 보정된 파라미터를 객체 인식 인공지능 모델에 설정 및 적용하고, 보정된 파라미터가 설 정 및 적용된 객체 인식 인공지능 모델을 통해 객체 이미지로부터 객체 이미지가 나타내는 객체의 종류를 인식 하여 객체 인식 데이터를 생성할 수 있다. 이를 통해, 프로세서는 객체 인식 인공지능 모델의 정확도는 증가시키고 로스는 감소시킬수 있다. 한편, 또 다른 실시 예에 따른 프로세서는 이전에 생성된 객체 인식 데이터의 비율에 기초하여 상술된 파 라미터를 보정할 수 있다. 구체적으로, 프로세서는 이전에 생성된 객체 인식 데이터가 나타내는 객체의 종류 각각에 대한 종류 비율 을 산출할 수 있다. 즉, 프로세서는 이전에 생성된 객체 인식 데이터의 전체 개수 대비 인식된 객체의 종류 각각의 개수를 종 류 비율로 산출할 수 있다. 이후, 프로세서는 가장 높은 객체의 종류에 대한 종류 비율이 포함되는 비율 구간을 확인하고, 비율 구간 에 미리 매칭된 매칭 파라미터로 파라미터를 보정할 수 있다. 예를 들어, 상술한 바와 같이, 이미지가 반려 동물이 촬영된 컨텐츠인 경우, 이미지에서 추출된 객체 이미지로 부터 인식되는 객체는 반려 동물일 수 있고, 객체의 종류는 반려 동물의 종류일 수 있다. 상술된 예를 이어서 설명하면, 프로세서는 이전에 생성된 객체 인식 데이터가 100개이고, 이전에 생성된 객체 인식 데이터가 나타내는 객체인 반려 동물의 종류가 3개(예를 들어, 개, 고양이, 새)인 경우, 이전에 생성 된 객체 인식 데이터 100개 대비, 종류 3개에 대응되는 객체 인식 데이터 각각의 종류 비율을 산출할 수 있다. 프로세서는 객체의 종류 3개에 대응되는 객체 인식 데이터가 각각 80개, 15개, 5개이면, 종류 3개에 대응 되는 객체 인식 데이터 각각의 종류 비율을 80%(80개/100개), 15%(15개/100개), 5%(5개/100개)로 산출하고, 산 출된 종류 비율 80%, 15%, 5% 중에서 가장 높은 종류 비율 80%가 포함되는 비율 구간을 확인하고, 확인된 비율 구간에 미리 매칭된 매칭 파라미터로 파라미터를 보정할 수 있다. 예를 들어, 비율 구간은 0% 이상 20% 미만, 20% 이상 40% 미만, 40% 이상 60% 미만, 60% 이상 80% 미만, 80% 이상 100%이하로 구성되고, 각 비율 구간에는 매칭 파라미터가 매칭되어 있을 수 있다. 이때, 비율 구간 각각에 매칭되는 매칭 파라미터는 해당 객체의 종류에 따라 상이할 수 있다. 즉, 동일한 비율 구간이더라도 해당 객체의 종류가 상이한 경우, 비율 구간 각각에 매칭된 매칭 파라미터는 상이할 수 있다. 이를 통해, 이전에 자주 인식되는 객체의 종류 중에서 가장 빈번하게 인식되는 객체의 종류가 차지하는 비율에 대응하여 객체 인식 인공지능 모델의 파라미터를 보정함으로써, 객체 인식 인공지능 모델의 정확도를 향상시킬 수 있다. 이제까지 본 발명에 대하여 바람직한 실시 예를 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자는 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 본 발명을 구현할 수 있 음을 이해할 것이다. 그러므로 상기 개시된 실시 예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모 든 차이점은 본 발명에 포함된 것으로 해석되어야 한다. 이상과 같이, 본 발명은 비록 한정된 실시 예와 도면에 의해 설명되었으나, 본 발명은 이것에 의해 한정되지 않"}
{"patent_id": "10-2023-0068484", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "으며 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 본 발명의 기술사상과 아래에 기재될 특허 청구범위의 균등범위 내에서 다양한 수정 및 변형이 가능함은 물론이다."}
{"patent_id": "10-2023-0068484", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 제 어되는 전자 장치 및 데이터 서버를 도시한 도면이다. 도 2는 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 제 어되는 전자 장치의 구성도이다. 도 3은 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법의 순서도이 다. 도 4는 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 이 용되는 객체 추출 인공지능 모델의 일 예를 도시한 도면이다. 도 5는 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 이 용되는 객체 인식 인공지능 모델의 일 예를 도시한 도면이다. 도 6은 본 발명의 일 실시 예에 따른 인공지능 모델을 이용하여 이미지로부터 객체를 인식하는 방법에 의해 이 용되는 파라미터 최적화 알고리즘의 일 예를 도시한 도면이다."}
