{"patent_id": "10-2023-0121099", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0038416", "출원번호": "10-2023-0121099", "발명의 명칭": "딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템", "출원인": "주식회사 공간의파티", "발명자": "김회준"}}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대상자를 촬영하는 CCTV(Closed-Circuit Television);상기 CCTV를 통해 촬영된 CCTV 영상을 입력 이미지로 입력받아 얼굴 검출 딥러닝 모델을 이용하여 상기 입력 이미지에서 얼굴 영역과 얼굴 영역 좌표를 검출하고, 상기 얼굴 검출 딥러닝 모델에서 검출된 얼굴 영역 좌표와얼굴 영역 이미지를 입력받아 얼굴 랜드마크 검출 딥러닝 모델을 이용하여 랜드마크 특징을 검출하고, 검출된랜드마크 특징을 좌표로 변환하여 얼굴 랜드마크 좌표를 생성한 후, 생성된 얼굴 랜드마크 좌표를 기반으로 피부 영역을 추출하는 얼굴 및 랜드마크 검출부;상기 얼굴 및 랜드마크 검출부에서 추출된 피부 영역을 입력받아 생체 신호 분석 딥러닝 모델을 이용하여 피부혈류의 변화를 측정하여 맥박 및 호흡 파형을 획득하고, 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 생체 신호 분석부; 상기 생체 신호 분석부에서 측정된 맥박수와 호흡수를 이용하여 스트레스 지수를 계산하는 스트레스 지수 산출부; 및상기 생체 신호 분석부에서 측정된 맥박 및 호흡 파형과 상기 스트레스 지수 산출부에서 산출된 스트레스 지수를 시각화 및 수치화하여 출력하는 생체 정보 출력부;를 포함하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 얼굴 및 랜드마크 검출부는 상기 얼굴 랜드마크 검출 딥러닝 모델을 이용하여 랜드마크 특징을 검출할 때,상기 얼굴 검출 딥러닝 모델의 특징 맵의 크기와 동일한 크기의 특징 맵이 존재하는 레이어(layer)에서 상기 얼굴 랜드마크 검출 딥러닝 모델의 특징 맵과 상기 얼굴 검출 딥러닝 모델의 특징 맵을 연결(concatenation) 기법을 이용하여 랜드마크 특징을 누적시킨 후 상기 얼굴 랜드마크 검출 딥러닝 모델의 가중치로 연산하여 랜드마크특징을 검출하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 생체 신호 분석부는 상기 생체 신호 분석 딥러닝 모델을 이용하여 피부 혈류의 변화를 측정하여 맥박 및호흡 파형을 획득할 때, 상기 얼굴 및 랜드마크 검출부로부터 입력된 피부 영역 이미지를 길이가 고정된 원형버퍼를 이용하여 누적하고 누적된 피부 영역 이미지들을 상기 생체 신호 분석 딥러닝 모델의 입력으로 사용하는딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 생체 신호 분석부는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을제거한 후 분당 맥박수와 호흡수를 측정하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템.공개특허 10-2025-0038416-3-청구항 5 제 1 항에 있어서, 상기 생체 신호 분석부는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을버터워스 필터(butterworth filter)로 제거하거나, 상기 버터워스 필터(butterworth filter)로 제거한 후 이동평균 필터(moving average filter)와 컨볼루션 필터(convolution filter)를 각각 적용하여 전체적인 잡음을 제거한 후 맥박 및 호흡 파형 각각의 피크 지점을 계산하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 스트레스 지수 산출부는 맥박 및 호흡 상관관계를 이용하여 스트레스 지수를 계산하거나, 맥박 다양성을이용하여 스트레스 지수를 계산하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체정보 제공 시스템."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "CCTV(Closed-Circuit Television)를 이용하여 대상자를 촬영하는 과정;상기 CCTV를 통해 촬영된 CCTV 영상을 입력 이미지로 입력받아 얼굴 검출 딥러닝 모델을 이용하여 상기 입력 이미지에서 얼굴 영역과 얼굴 영역 좌표를 검출하고, 상기 얼굴 검출 딥러닝 모델에서 검출된 얼굴 영역 좌표와얼굴 영역 이미지를 입력받아 얼굴 랜드마크 검출 딥러닝 모델을 이용하여 랜드마크 특징을 검출하고, 검출된랜드마크 특징을 좌표로 변환하여 얼굴 랜드마크 좌표를 생성한 후, 생성된 얼굴 랜드마크 좌표를 기반으로 피부 영역을 추출하는 과정;추출된 피부 영역을 입력받아 생체 신호 분석 딥러닝 모델을 이용하여 피부 혈류의 변화를 측정하여 맥박 및 호흡 파형을 획득하고, 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 과정;측정된 맥박수와 호흡수를 이용하여 스트레스 지수를 계산하는 과정; 및측정된 맥박 및 호흡 파형과 산출된 스트레스 지수를 시각화 및 수치화하여 출력하는 과정;을 포함하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 방법."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 생성된 얼굴 랜드마크 좌표를 기반으로 피부 영역을 추출하는 과정에서는 상기 얼굴 랜드마크 검출 딥러닝모델을 이용하여 랜드마크 특징을 검출할 때, 상기 얼굴 검출 딥러닝 모델의 특징 맵의 크기와 동일한 크기의특징 맵이 존재하는 레이어(layer)에서 상기 얼굴 랜드마크 검출 딥러닝 모델의 특징 맵과 상기 얼굴 검출 딥러닝 모델의 특징 맵을 연결(concatenation) 기법을 이용하여 랜드마크 특징을 누적시킨 후 상기 얼굴 랜드마크검출 딥러닝 모델의 가중치로 연산하여 랜드마크 특징을 검출하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 방법."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서, 상기 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 과정에서는 상기 생체 신호 분석 딥러공개특허 10-2025-0038416-4-닝 모델을 이용하여 피부 혈류의 변화를 측정하여 맥박 및 호흡 파형을 획득할 때, 상기 얼굴 및 랜드마크 검출부로부터 입력된 피부 영역 이미지를 길이가 고정된 원형 버퍼를 이용하여 누적하고 누적된 피부 영역 이미지들을 상기 생체 신호 분석 딥러닝 모델의 입력으로 사용하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 방법."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7 항에 있어서, 상기 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 과정에서는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을 제거한 후 분당 맥박수와 호흡수를 측정하는 딥러닝기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 방법."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7 항에 있어서, 상기 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 과정에서는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을 버터워스 필터(butterworth filter)로 제거하거나,상기 버터워스 필터(butterworth filter)로 제거한 후 이동 평균 필터(moving average filter)와 컨볼루션 필터(convolution filter)를 각각 적용하여 전체적인 잡음을 제거한 후 맥박 및 호흡 파형 각각의 피크 지점을 계산하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 방법."}
{"patent_id": "10-2023-0121099", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 7 항에 있어서, 상기 측정된 맥박수와 호흡수를 이용하여 스트레스 지수를 계산하는 과정에서는 맥박 및 호흡 상관관계를 이용하여 스트레스 지수를 계산하거나, 맥박 다양성을 이용하여 스트레스 지수를 계산하는 딥러닝 기반의 얼굴 및랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 방법."}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 생체 정보 분석 시스템 및 방법에 관한 것으로, 보다 상세하게는, 딥러닝 기반의 얼굴 및 랜드마크 검 출 알고리즘을 활용하여 CCTV(Closed-Circuit Television)를 통해 촬영된 CCTV 영상에서 얼굴 영역과 랜드마크 (메쉬 포함)를 실시간으로 검출하고, 이를 토대로 추출된 피부 영역에서 피부 혈류의 변화를 측정하여 맥박과 호 흡 파형을 획득하고, 획득한 파형들로부터 분당 맥박수와 호흡수를 측정하고, 이를 기반으로 스트레스 지수를 분 석하여 개인의 생체 정보를 시각화 및 수치화하여 실시간으로 모니터링할 수 있도록 제공하는 딥러닝 기반의 얼 굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 생체 정보 분석 시스템 및 방법에 관한 것으로, 보다 상세하게는, 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용하여 CCTV(Closed-Circuit Television)를 통해 촬영된 CCTV 영상에서 얼굴 영역과 랜드마 크(메쉬 포함)를 실시간으로 검출하고, 이를 토대로 추출된 피부 영역에서 피부 혈류의 변화를 측정하여 맥박과 호흡 파형을 획득하고, 획득한 파형들로부터 분당 맥박수와 호흡수를 측정하고, 이를 기반으로 스트레스 지수를 분석하여 개인의 생체 정보를 시각화 및 수치화하여 실시간으로 모니터링할 수 있도록 제공하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스트레스(stress)란 내·외부적인 자극 또는 유발 인자에 대응하는 신체의 적응 반응을 말한다. 이러한 스트레 스는 교감 신경계를 자극하여 맥박과 호흡의 증가, 혈압의 상승, 심박 출량의 증가, 복부 동맥의 수축, 동공 확 대, 간으로부터 포도당의 유리, 정신 활동의 증가, 골격근의 수축 등 다양한 신체적인 변화를 유발한다. 인체가 이러한 스트레스에 장기간 노출되면, 면역 기능 저하로 인한 신체 질환이나 정신 질환 등을 유발할 수 있다. 이에 따라 현대인들은 건강 관리 측면에서 생체 신호 분석을 통해 자신의 스트레스 지수를 측정하여 스트 레스를 관리할 필요가 있다. 특히 정부나 지자체 차원에서도 시민이나 국민들의 건강 증진과 공공 장소에서의 안전 관리를 위해 대중의 스트레스 지수를 측정하여 모니터링할 필요가 있다. 이러한 이유로 생체 신호 분석기술에 대한 기술 개발이 활발하게 이루어지고 있다. 그러나, 현재 개발되었거나 개발 중인 생체 신호 분석기술은 대부분 신체의 어느 특정 부위에 측정장치(전자장치)를 착용하여 생체 신호를 측정하는 기술로서, 개개인의 생체 신호를 측정하여 분석할 수는 있으나, 대중이 몰리는 장소에서 한 번에 많은 사람의 생체 신호를 실시간으로 측정하여 분석하는 데에는 한계가 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-1470939 B1, 2014. 12. 03. (특허문헌 0002) KR 10-2302871 B1, 2021. 09. 10. (특허문헌 0003) KR 10-1394597 B1, 2014. 05. 07. (특허문헌 0004) KR 10-1179497 B1, 2012. 08. 29."}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 전술한 종래의 제반 문제점들을 해결하기 위해 제안될 수 있다. 본 발명에서 해결하고자 하는 과제(목적)는 대중이 몰리는 장소에서 한 번에 많은 사람의 생체 신호를 실시간으 로 측정한 후 분석하여 돌발할 수 있는 안전 사고에 신속하게 대응할 수 있고, 또한 대규모 인구에 대한 스트레 스 지수를 분석하여 시민과 국민의 건강 증진을 도모할 수 있는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘 을 활용한 CCTV 기반의 생체 정보 제공 시스템 및 방법을 제공하는 것이다. 또한, 본 발명에서 해결하고자 하는 다른 과제는 감지영역 내에 위치하는 대상자들의 생체 신호를 객관적으로 실시간 분석하여 스트레스 지수를 측정한 후 시각적으로 제공하여 건강 상태를 사전에 파악하도록 하고, 더 나 아가서는 대규모 인구의 건강 상태를 간편하게 실시간으로 모니터링하도록 하여 공공 장소에서의 안전 관리를 효율적으로 관리할 수 있도록 하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템 및 방법을 제공하는 것이다. 또한, 본 발명의 해결 과제는 전술한 과제들로 제한되지 않으며, 후술하는 실시예를 통해 기재된 기술들을 통해 다양한 해결 과제들이 추가로 제공될 수 있다."}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 실시 예에 따른 본 발명은 대상자를 촬영하는 CCTV(Closed-Circuit Television); 상기 CCTV를 통해 촬영된 CCTV 영상을 입력 이미지로 입력받아 얼굴 검출 딥러닝 모델을 이용하여 상기 입력 이 미지에서 얼굴 영역과 얼굴 영역 좌표를 검출하고, 상기 얼굴 검출 딥러닝 모델에서 검출된 얼굴 영역 좌표와 얼굴 영역 이미지를 입력받아 얼굴 랜드마크 검출 딥러닝 모델을 이용하여 랜드마크 특징을 검출하고, 검출된 랜드마크 특징을 좌표로 변환하여 얼굴 랜드마크 좌표를 생성한 후, 생성된 얼굴 랜드마크 좌표를 기반으로 피 부 영역을 추출하는 얼굴 및 랜드마크 검출부; 상기 얼굴 및 랜드마크 검출부에서 추출된 피부 영역을 입력받아 생체 신호 분석 딥러닝 모델을 이용하여 피부 혈류의 변화를 측정하여 맥박 및 호흡 파형을 획득하고, 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 생체 신호 분석부; 상기 생체 신호 분석부에서 측정 된 맥박수와 호흡수를 이용하여 스트레스 지수를 계산하는 스트레스 지수 산출부; 및 상기 생체 신호 분석부에 서 측정된 맥박 및 호흡 파형과 상기 스트레스 지수 산출부에서 산출된 스트레스 지수를 시각화 및 수치화하여 출력하는 생체 정보 출력부를 포함하는 딥러닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 시스템을 제공한다. 또한, 상기 얼굴 및 랜드마크 검출부는 상기 얼굴 랜드마크 검출 딥러닝 모델을 이용하여 랜드마크 특징을 검출 할 때, 상기 얼굴 검출 딥러닝 모델의 특징 맵의 크기와 동일한 크기의 특징 맵이 존재하는 레이어(layer)에서 상기 얼굴 랜드마크 검출 딥러닝 모델의 특징 맵과 상기 얼굴 검출 딥러닝 모델의 특징 맵을 연결 (concatenation) 기법을 이용하여 랜드마크 특징을 누적시킨 후 상기 얼굴 랜드마크 검출 딥러닝 모델의 가중치 로 연산하여 랜드마크 특징을 검출할 수 있다.또한, 상기 생체 신호 분석부는 상기 생체 신호 분석 딥러닝 모델을 이용하여 피부 혈류의 변화를 측정하여 맥 박 및 호흡 파형을 획득할 때, 상기 얼굴 및 랜드마크 검출부로부터 입력된 피부 영역 이미지를 길이가 고정된 원형 버퍼를 이용하여 누적하고 누적된 피부 영역 이미지들을 상기 생체 신호 분석 딥러닝 모델의 입력으로 사 용할 수 있다. 또한, 상기 생체 신호 분석부는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을 제거한 후 분당 맥박수와 호흡수를 측정할 수 있다. 또한, 상기 생체 신호 분석부는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을 버터워스 필터(butterworth filter)로 제거하거나, 상기 버터워스 필터(butterworth filter)로 제거한 후 이동 평균 필터(moving average filter)와 컨볼루션 필터(convolution filter)를 각각 적용하여 전체적인 잡음을 제거한 후 맥박 및 호흡 파형 각각의 피크 지점을 계산할 수 있다. 또한, 상기 스트레스 지수 산출부는 맥박 및 호흡 상관관계를 이용하여 스트레스 지수를 계산하거나, 맥박 다양 성을 이용하여 스트레스 지수를 계산할 수 있다. 또한, 상기한 목적을 달성하기 위한 다른 실시 예에 따른 본 발명은 CCTV(Closed-Circuit Television)를 이용하 여 대상자를 촬영하는 과정; 상기 CCTV를 통해 촬영된 CCTV 영상을 입력 이미지로 입력받아 얼굴 검출 딥러닝 모델을 이용하여 상기 입력 이미지에서 얼굴 영역과 얼굴 영역 좌표를 검출하고, 상기 얼굴 검출 딥러닝 모델에 서 검출된 얼굴 영역 좌표와 얼굴 영역 이미지를 입력받아 얼굴 랜드마크 검출 딥러닝 모델을 이용하여 랜드마 크 특징을 검출하고, 검출된 랜드마크 특징을 좌표로 변환하여 얼굴 랜드마크 좌표를 생성한 후, 생성된 얼굴 랜드마크 좌표를 기반으로 피부 영역을 추출하는 과정; 추출된 피부 영역을 입력받아 생체 신호 분석 딥러닝 모 델을 이용하여 피부 혈류의 변화를 측정하여 맥박 및 호흡 파형을 획득하고, 획득된 맥박 및 호흡 파형을 이용 하여 맥박수와 호흡수를 측정하는 과정; 측정된 맥박수와 호흡수를 이용하여 스트레스 지수를 계산하는 과정; 및 측정된 맥박 및 호흡 파형과 산출된 스트레스 지수를 시각화 및 수치화하여 출력하는 과정을 포함하는 딥러 닝 기반의 얼굴 및 랜드마크 검출 알고리즘을 활용한 CCTV 기반의 생체 정보 제공 방법을 제공한다. 또한, 상기 생성된 얼굴 랜드마크 좌표를 기반으로 피부 영역을 추출하는 과정에서는 상기 얼굴 랜드마크 검출 딥러닝 모델을 이용하여 랜드마크 특징을 검출할 때, 상기 얼굴 검출 딥러닝 모델의 특징 맵의 크기와 동일한 크기의 특징 맵이 존재하는 레이어(layer)에서 상기 얼굴 랜드마크 검출 딥러닝 모델의 특징 맵과 상기 얼굴 검 출 딥러닝 모델의 특징 맵을 연결(concatenation) 기법을 이용하여 랜드마크 특징을 누적시킨 후 상기 얼굴 랜 드마크 검출 딥러닝 모델의 가중치로 연산하여 랜드마크 특징을 검출할 수 있다. 또한, 상기 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 과정에서는 상기 생체 신호 분석 딥러닝 모델을 이용하여 피부 혈류의 변화를 측정하여 맥박 및 호흡 파형을 획득할 때, 상기 얼굴 및 랜드마크 검출부로부터 입력된 피부 영역 이미지를 길이가 고정된 원형 버퍼를 이용하여 누적하고 누적된 피부 영역 이미 지들을 상기 생체 신호 분석 딥러닝 모델의 입력으로 사용할 수 있다. 또한, 상기 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 과정에서는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을 제거한 후 분당 맥박수와 호흡수를 측정할 수 있다. 또한, 상기 획득된 맥박 및 호흡 파형을 이용하여 맥박수와 호흡수를 측정하는 과정에서는 상기 생체 신호 분석 딥러닝 모델을 통해 획득된 맥박 및 호흡 파형에 포함된 잡음을 버터워스 필터(butterworth filter)로 제거하거 나, 상기 버터워스 필터(butterworth filter)로 제거한 후 이동 평균 필터(moving average filter)와 컨볼루션 필터(convolution filter)를 각각 적용하여 전체적인 잡음을 제거한 후 맥박 및 호흡 파형 각각의 피크 지점을 계산할 수 있다. 또한, 상기 측정된 맥박수와 호흡수를 이용하여 스트레스 지수를 계산하는 과정에서는 맥박 및 호흡 상관관계를 이용하여 스트레스 지수를 계산하거나, 맥박 다양성을 이용하여 스트레스 지수를 계산할 수 있다."}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같이, 본 발명의 실시 예에 따르면, 대상자가 특별한 장비를 착용하거나 복잡한 절차를 거치지 않고 도 얼굴을 탐지하고 생체 정보를 측정할 수 있다. 따라서, 편의성을 높이고, 생체 정보를 수집하는 과정에서 물 리적인 불편함을 줄일 수 있다. 또한, 대규모 인구의 건강 상태를 실시간으로 모니터링하여 대상자의 건강 상태 를 즉각적으로 확인할 수 있으며, 필요한 경우 즉시 대응할 수 있도록 하여 공공 장소에서의 안전 사고를 미연에 방지할 수 있다. 또한, 개개인의 스트레스 수준을 객관적으로 측정하여 현대인들의 정신 건강을 효율적으로 관리할 수 있다."}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 이점 및 특징, 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되는 실시 예들 을 참조하면 명확해질 것이다. 본 명세서 전체에 걸쳐 동일 참조부호는 동일한 구성요소를 지칭하는 것이다. 또 한, 'A 및/또는 B'라 기재된 경우 A와 B 모두를 의미하거나, 또는 A 또는 B 중 어느 하나를 의미할 수 있다. 또 한, 각 도면에 나타낸 각각의 구성요소들은 크기 및 형상이 과도하게 도시될 수도 있는데, 이는 설명의 편의를 위한 것으로 제한을 두고자 하는 것이 아니다. 도 1은 기존 얼굴 검출 딥러닝 모델(알고리즘)을 개략적으로 나타낸 도면이다. 도 1에 나타낸 기존 얼굴 검출 딥러닝 모델(얼굴 검출 알고리즘)은 입력 이미지(RGB 이미지)로부터 얼굴이 있는 영역(이하, '얼굴 영역'이라 함)을 찾는 것을 목적으로 한다. 기존 얼굴 검출 딥러닝 모델에서는 입력 이미지의 이전 프레임과 현재 프레임에서 검출된 얼굴 사이의 공간적 및 시간적 연속성을 이용하여 동일 대상자(객체)의 얼굴과 눈의 좌표를 검출한다. 그리고 이렇게 검출된 동일 대상자의 얼굴과 눈의 좌표를 이용하여 얼굴 회전각 도를 산출한 후 산출된 얼굴의 회전각도만큼 이미지를 회전시켜 얼굴의 각도가 틀어지지 않도록 보정한다. 이후 얼굴 각도가 조정된 이미지에서 얼굴 영역만을 선택적으로 잘라 피부 영역을 추출하는데 활용한다. 이러한 얼굴 검출 딥러닝 모델은 얼굴 검출기를 통해 입력 이미지인 'RGB 이미지'로부터 얼굴 특징을 추출하는 과정을 수행한다. 입력 이미지가 '3×128×128'(여기서, '3'은 RGB 3채널, '128'은 너비와 높이를 나타냄)인 경우, 인공지능 모델 연산과정에서 채널 수가 증가하여 추출되는 특징의 다양성이 증가한다. 이때, 특징 맵의 너 비와 높이는 줄어들기 때문에 적은 픽셀 수로 특징을 표현하여 함축적인 특징을 표현할 수 있다. 예를 들어, 16 ×16 크기의 특징 맵은 작은 얼굴을 검출하는데 사용하고, 8×8 크기의 특징 맵은 큰 얼굴을 검출하는데 사용할 수 있다. 경계 상자(bounding box, bbox)가 3×3 크기라고 가정하면, 16×16 크기에서 차지하는 비중이 작아서 작은 얼굴을 검출하는데 유리하고, 8×8 크기에서는 비중이 커서 큰 얼굴을 검출하는데 유리하다. 즉, 8×8 크 기의 특징 맵은 큰 특징 맵들에 비해 함축적인 얼굴의 특징을 가지고 있다. 여기서, '작은 얼굴'과 '큰 얼굴'은 이미지의 너비나 높이를 기준으로 구분할 수 있다. 가령, 이미지의 너비나 높이 기준으로 검출된 얼굴의 너비 또는 높이가 이미지의 25% 이상일 때 큰 얼굴로 판단한다. 얼굴의 너비 또는 높이가 이미지의 너비 또는 높이보 다 25% 미만일 때의 작은 얼굴로 판단한다. 도 2는 도 1에 나타낸 NMS(Non-Maximum Suppression) 전과 후의 검출 상자를 개략적으로 나타낸 예시도이다. 도 2와 같이, 얼굴 검출 딥러닝 모델은 출력값으로 입력 이미지로부터 얼굴이 포함된 사각형의 경계 상자의 좌 표나 얼굴에 대한 레이블을 출력한다. NMS(Non-Maximum Suppression)는 얼굴 검출 딥러닝 모델의 출력에서 하나 의 객체에 대해 여러 개의 검출 박스가 존재할 때 가장 점수가 높은 검출 상자를 제외하고 모두 제거한다. 도 3은 기존 얼굴 랜드마크 검출 딥러닝 모델(알고리즘)을 개략적으로 나타낸 도면이다. 도 3에 나타낸 기존 얼굴 랜드마크 검출 딥러닝 모델(얼굴 랜드마크 검출 알고리즘)은 얼굴 검출 딥러닝 모델 (도 1 참조)과 마찬가지로 입력 이미지로부터 얼굴 특징을 추출하는 과정을 수행한다. 즉, 얼굴 검출 딥러닝 모 델의 결과인 얼굴 영역을 입력으로 받고, 이 얼굴 영역에서 특정 랜드마크, 가령 눈, 코, 입, 턱 등을 검출한다. 기존 얼굴 랜드마크 검출 딥러닝 모델에서는 얼굴 검출 딥러닝 모델과 다르게 NMS를 이용하여 얼굴 좌표를 변환 하는 것이 아니라 눈과 입을 중심 특징으로 하여 얼굴 특징 추출기(Feature Extractor)를 통해 나머지 랜드마크 의 특징을 추출한다. 그리고 추출된 랜드마크 특징을 좌표로 변환하여 얼굴 랜드마크 좌표(랜드마크의 위치를 나타내는 좌표값)를 생성한다. 이렇게 생성된 얼굴 랜드마크 좌표를 기반으로 피부 영역을 추출한다. 이때, 피 부 영역은 가령 얼굴에서 눈, 눈썹, 콧구멍, 입 등 피부에 해당하지 않는 영역을 제외하고, 나머지 영역을 선택 하는 방법으로 추출할 수 있다. 그러나, 도 1 및 도 3과 같이, 각각 개별적으로 분리된 얼굴 검출 딥러닝 모델과 얼굴 랜드마크 검출 딥러닝 모 델을 이용하여 얼굴 영역과 얼굴 랜드마크를 검출하여 피부 영역을 추출하는 기존 딥러닝 모델에서는 아래와 같 은 문제점이 발생할 수 있다. 도 1 및 도 3에 나타낸 모델을 적용하는 경우에는 얼굴 검출 딥러닝 모델에서 검출이 성공하더라도, 얼굴 랜드 마크 검출 딥러닝 모델에서 특징 랜드마크의 추출에 에러가 발생하면 최종적으로 검출에 실패할 수 있다. 또한, 얼굴 검출 딥러닝 모델에서 얼굴에 대한 특징을 추출한 후, 얼굴 랜드마크 검출 딥러닝 모델에서 다시 얼굴에 대한 특징을 추출해야 하기 때문에 특징 추출 과정이 중복 실시되어 복잡해질 수 있다. 따라서, 본 발명의 바람직한 실시 예에서는 얼굴 검출 딥러닝 모델과 얼굴 랜드마크 검출 딥러닝 모델을 병합하 여 도 1 및 도 3에 나타낸 기존 딥러닝 모델에 비해 경량화된 모델을 제공한다. 즉, 하나로 병합된 딥러닝 모델 을 이용하여 얼굴 검출 딥러닝 모델의 가중치와 얼굴 랜드마크 검출 딥러닝 모델의 가중치를 사용하여 피부 영 역을 추출한다. 도 4는 본 발명의 실시 예에 따른 CCTV 기반의 생체 정보 제공 시스템을 개략적으로 나타낸 도면이다. 도 4를 참조하면, 본 발명의 실시 예에 따른 CCTV 기반의 생체 정보 제공 시스템은 CCTV(Closed-Circuit Television, 11)와, 얼굴 및 랜드마크 검출부와, 생체 신호 분석부와, 스트레스 지수 산출부와, 생 체 정보 출력부를 포함한다. CCTV는 설정된 감지영역 내에 위치하는 대상자들을 촬영하는 카메라로서, 감지영역 내에 위치하는 다수의 대상자를 실시간으로 촬영하여 CCTV 영상을 획득할 수 있다. 이때, CCTV를 통해 촬영된 CCTV 영상에는 대상 자의 얼굴을 포함한다. 얼굴 및 랜드마크 검출부는 CCTV로부터 촬영된 CCTV 영상을 입력 이미지로 입력받는다. 이때, 상기 입 력 이미지는 RGB 이미지일 수 있다. 그리고 입력받은 입력 이미지에서 도 1 및 도 3에 나타낸 기존 얼굴 검출 딥러닝 모델과 얼굴 랜드마크 검출 딥러닝 모델이 하나로 병합된 딥러닝(deep learing) 기반의 모델(이하, '얼 굴 및 랜드마크 검출 딥러닝 모델(얼굴 및 랜드마크 검출 알고리즘)'이라 함)을 사용하여 얼굴 영역을 검출고,이렇게 검출된 얼굴 영역에서 특정 랜드마크(예컨대, 눈, 코, 입, 턱 등)의 위치를 검출한 후, 이를 이용하여 피부 영역을 추출한다. 도 5는 본 발명에 따른 얼굴 및 랜드마크 검출 딥러닝 모델을 개략적으로 나타낸 도면이고, 도 6은 도 5에 나타 낸 얼굴 및 랜드마크 검출 딥러닝 모델을 상세하게 나타낸 도면이다. 도 4 내지 도 6을 참조하면, 얼굴 및 랜드마크 검출부는 도 5 및 도 6에 나타낸 딥러닝 기반의 얼굴 및 랜 드마크 검출 딥러닝 모델을 이용하여 피부 영역을 추출한다. 본 발명에 따른 얼굴 및 랜드마크 검출 딥러닝 모델은 도 1 및 도 3에 나타낸 바와 같이, 기존 분할된 얼굴 검 출 딥러닝 모델과 얼굴 랜드마크 검출 딥러닝 모델을 하나로 병합한 모델로서, 얼굴 검출과 동시에 특정 랜드마 크의 위치를 찾기 위해 얼굴 검출 딥러닝 모델의 가중치와 얼굴 랜드마크 검출 딥러닝 모델의 가중치를 사용한 다. 얼굴 및 랜드마크 검출 딥러닝 모델에서는 얼굴 검출 딥러닝 모델과 얼굴 랜드마크 검출 딥러닝 모델을 포함한 다. 얼굴 랜드마크 검출 딥러닝 모델에서는 얼굴 검출 딥러닝 모델의 가중치를 그대로 사용하여 얼굴 영역(얼굴 위치)에 대한 특징을 추출한다. 이때, 얼굴에 대해 함축적인 특징을 가지고 있는 '96×8×8'의 특징 맵을 랜드 마크 특징 검출에 사용할 수 있다. 얼굴 랜드마크 검출 딥러닝 모델에서는 얼굴 검출 딥러닝 모델의 특징 맵의 크기와 동일한 크기의 특징 맵이 존재하는 레이어(layer)에 얼굴 검출 딥러닝 모델의 '96×8×8'의 특징 맵을 연결(concatenation) 기법을 이용하여 특징을 누적시킨 후, 얼굴 랜드마크 검출 딥러닝 모델의 가중치로 연산하 여 얼굴에 대한 특징 정보를 가중한다. 이를 통해 추출되는 얼굴 특징이 더욱 견고해질 수 있고, 이때, 검출된 얼굴 위치의 특징을 더 가중하여 특징 추출에 유리하도록 할 수 있다. 특히 얼굴 검출 딥러닝 모델의 특징 맵과 얼굴 랜드마크 검출 딥러닝 모델의 특징 맵을 합하지 않고 누적한 후 연산과정에 사용하기 때문에 특징을 모두 반영할 수 있다. 기존에는 입력 이미지로부터 피부 영역을 추출하기 위해, \"이미지 입력과정→얼굴 영역 검출 과정(얼굴 검출 딥 러닝 모델)→얼굴 영역 이미지 출력과정→얼굴 영역 처리과정→얼굴 영역 이미지 입력과정→얼굴 랜드마크 특징 검출과정(얼굴 랜드마크 검출 딥러닝 모델)→랜드마크 추출과정→피부 영역 추출과정\"을 포함하는 프로세스를 수행해야 하는데 반해, 본 발명의 실시 예에서는 \"이미지 입력과정→얼굴 및 랜드마크 특징 검출과정(얼굴 및 랜드마크 검출 딥러닝 모델)→랜드마크 추출과정→ 피부 영역 추출과정\"으로 도 1 및 도 3에 나타낸 기존 딥러 닝 모델에 비해 프로세스를 현저하게 단순화시킬 수 있다. 또한, 기존 딥러닝 모델에서는 CPU 연산과 GPU 연산 과정을 번갈아 가면서 수행해야 하기 때문에 메모리 점유 과정에서 병목 현상이 발생할 수 있다. 또한 검출 실 패 확률을 낮추기 위해서는 얼굴을 2회 검출(얼굴 및 얼굴 랜드마크 검출)하기 때문에 2개의 모델 모두 정확도 가 모두 높아야 한다. 도 1에 나타낸 기존 얼굴 검출 딥러닝 모델에서는 얼굴 영역을 검출한 후 회전 및 절단(crop)하는 과정을 포함 한다. 그리고, 도 3에 나타낸 기존 얼굴 랜드마크 검출 딥러닝 모델에서는 절단된 얼굴 영역 이미지에서 얼굴 랜드마크를 검출한 후 이를 이용하여 피부 영역을 추출하는 과정을 포함한다. 그러나, 본 발명의 실시 예에서는 최종적으로 피부 영역을 추출하면 되기 때문에 도 1에 나타낸 기존 얼굴 검출 딥러닝 모델에서 얼굴 영역 회전 과정을 생략하고, 얼굴 영역을 절단하여 사용한다. 도 3과 같이, 기존 얼굴 랜드마크 검출 딥러닝 모델에서는 RGB 이미지를 입력받아 RGB 이미지로부터 얼굴 특징 을 다시 검출한 후 피부 영역을 추출한다. 이러한 방법에서는 도 1에 나타낸 얼굴 검출 딥러닝 모델에서 얼굴 특징을 검출했음에도 불구하고 도 3의 얼굴 랜드마크 검출 딥러닝 모델에서 얼굴 특징이 다시 추출되지 않으면, 최종적으로 피부 영역이 추출되지 않는다. 이러한 문제를 방지하고 얼굴 랜드마크 검출 과정을 더욱 견고히 하 기 위해 얼굴 검출 딥러닝 모델에서 사용한 딥러닝 모델의 얼굴인지 아닌지 판별하기 전에 최종 특징 맵을 활용 한다. 이는 이미지 내에서 얼굴이라고 판단되는 영역을 수치적으로 나타낸 행렬이라 볼 수 있으며, 얼굴 랜드마 크 검출 딥러닝 모델에 해당 특징 맵을 활용하면 얼굴 랜드마크 검출에 유용하다. 도 7은 본 발명에 따른 특징 맵을 설명하기 위해 개략적으로 나타낸 예시도이다. 도 7에 나타낸 이미지들 중에서 최상단 이미지는 딥러닝 연상 과정의 초입 특징 맵이며, 원본 입력 이미지와 큰 차이가 없다. 도 7에서 하단으로 갈수록 검출하고자 하는 객체의 특징을 더욱 함축적으로 표현하는 특징 맵이 된다. 도 5 및 도 6에서 얼굴 검출 딥러닝 모델의 특징 맵으로 도 7의 최하단의 이미지 특징 맵을 활용하여 얼 굴 랜드마크 검출 딥러닝 모델에서 활용할 수 있다. 즉, 얼굴 검출 딥러닝 모델에서 얼굴 검출을 위한 특징 추 출기(이하, '얼굴 특징 추출기'라 함)와 얼굴 랜드마크 검출 딥러닝 모델에서 랜드마크 특징을 검출을 위한 특징 추출기(Feature Extractor)(이하, '랜드마크 특징 추출기'라 함)가 개별적으로 작동하지만, 얼굴의 고차원 특징 맵을 랜드마크 특징 추출기에서 활용한다. 또한, 해당 특징 맵을 활용할 때, 얼굴 특징 추출기에서 추정한 얼굴의 위치 및 크기(bbox 좌표)로 특징 맵에서 얼굴 위치를 자른다. 도 5 및 도 6에서와 같이, 얼굴 랜드마크 검출 딥러닝 모델에서는 얼굴 검출 딥러닝 모델을 통해 검출된 얼굴 영역을 랜드마크 특징 추출기의 입력으로 사용한다. 그리고, 랜드마크 특징 추출기에서는 정확도를 향상시키기 위해 얼굴 특징 추출기에서 사용된 특징 맵을 넘겨 받아 얼굴 이미지와 함께 랜드마크 특징을 추출하는데 사용 한다. 이와 같이, 본 발명의 실시 예에서는 얼굴 랜드마크 검출 딥러닝 모델에서 얼굴 랜드마크 특징을 추출하기 전에 얼굴 검출 딥러닝 모델의 얼굴 특징 추출기를 통해 추출된 얼굴 특징에 대한 특징 맵을 활용함으로써 얼굴 랜드 마크 검출 딥러닝 모델의 랜드마크 특징 추출기에서 랜드마크 특징을 추출할 때 성능을 향상시킬 수 있다. 또한 얼굴 영역을 검출한 후 경계 상자의 좌표와 얼굴 영역에 ROI를 설정하기 위해 CPU 연산과 GPU 연산을 전환할 때 메모리 점유 과정에서 발생하는 병목 현상을 감소시킬 수 있다. 여기서, ROI는 관심 영역 지정으로, 영상 처리 과정에서 이미지 전체를 처리하면 특징을 추출하고 연산해야 할 영역에 불필요한 영역이 포함될 수 있으므로, 이러한 영역을 제외하고 필요한 영역에서만 연산하기 위한 영역 지정을 의미한다. 도 8은 본 발명에 따른 얼굴 랜드마크 검출 딥러닝 모델에서 연결(concatenation) 기법을 이용하여 특징 맵을 연결하는 과정을 개략적으로 나타낸 도면이다. 도 8을 참조하면, 얼굴 랜드마크 검출 딥러닝 모델에서는 랜드마크를 검출할 때, 얼굴 특징 추출기로부터 입력 되는 특징 맵을 연결(concatenation) 기법을 활용하여 두 개의 특징 맵을 합치는 것이 아닌 누적하여 두 개의 특징을 모두 반영하도록 한다. 도 9는 요소 합을 이용하여 특징 맵을 합치는 과정을 개략적으로 나타낸 예시도이다. 특징 맵은 딥러닝 모델에서 컨볼루션 연산의 중간 결과를 이미지화한 결과를 의미한다. '특징 맵을 합친다'는 것은 주로 요소 합(element-wise sum)을 의미하며, 크기가 동일한 두 이미지를 합칠 때 동일한 위치의 픽셀값이 합쳐지는 것을 의미한다. 가령, 도 9와 같이, 4×4 이미지 두 장을 요소 합하면, 한 장의 4×4 이미지가 된다. 도 10은 연결 기법을 이용하여 특징 맵을 누적시키는 과정을 개략적으로 나타낸 예시도이다. 영상 처리 과정에서 일반적으로 특징 맵의 수치가 높은 픽셀은 '사용자가 원하는 특징이 존재한다'로 파악된다. 도 9와 같이, 요소 합을 진행하면, 특징이 없는 영역과 특징이 있는 영역에서 확실하게 값이 차이나게 구분되지 만, 다양한 특징 맵에서 특징의 변화가 일어나는 구간(특징이 있는 영역과 특징이 없는 영역의 사이)과 특징이 있는 구간 또는 특징이 없는 구간과 요소 합이 진행되면, 변화량 파악에 어려움이 있으므로, 도 10과 같이 연결 기법을 사용한다. 연결 기법은 단순히 누적하는 방식으로, 연결 기법을 사용할 두 장의 4×4 이미지는 4×4 형 태의 행렬, 2채널의 이미지로 구성된다. 이와 같이 행렬을 구성하면, 두 특징 맵의 값을 유지하며 연결 기법의 다음 연산 과정(딥러닝 연산)에서 두 개의 값을 모두 활용할 수 있다. 도 4와 같이, 생체 신호 분석부는 딥러닝을 기반으로 하는 생체 신호 분석 딥러닝 모델(알고리즘)을 사용하 여 얼굴 및 랜드마크 검출부에서 검출된 피부 영역으로부터 대상자의 생체 신호를 분석한다. 가령, 생체 신 호 분석부는 얼굴 및 랜드마크 검출부를 통해 검출된 얼굴 영역에서 주요 피부 영역만 분리된 이미지를 사용하여 생체 신호를 분석함으로써 생체 신호 분석의 정확도를 향상시킬 수 있다. 도 11은 본 발명에 따른 생체 신호 분석 알고리즘에 적용되는 피부 빛 반사 모델을 설명하기 위해 개략적으로 나타낸 도면이고, 도 12는 본 발명에 따른 POS(Plane-Orthogonal-to-Skin) 알고리즘을 설명하기 위해 개략적으 로 나타낸 도면이고, 도 13은 기존 맥박 및 호흡 추정 알고리즘을 개략적으로 나타낸 도면이고, 도 14는 본 발 명에 따른 맥박 및 호흡 추정 알고리즘을 개략적으로 나타낸 도면이다. 도 11 내지 도 14를 참조하면, 본 발명에 따른 생체 신호 분석 알고리즘은 피부의 빛 반사 원리(피부 빛 반사 모델)를 활용한다. 광원으로부터 빛이 발산되면, 피부 하위 층에 존재하는 혈류에 난반사가 발생한다. 이러한 원리를 이용하여 CCTV를 통해 촬영된 CCTV 영상의 이전 프레임들과 현재 프레임의 난반사 정보를 R, G 및 B 채널로 각각 분리하고, 각각 분리된 각 채널에서 신호를 분석한다. 각각 분리된 채널에서의 난반사의 신호 분석 은 POS 알고리즘을 통해 분석하며, 각 채널에서 분석된 정보를 통합하여 도 14와 같이 맥박 및 호흡 파형을 추 론할 수 있다. 도 12와 같이, 도 5 및 도 6에 나타낸 얼굴 및 랜드마크 검출 딥러닝 모델을 통해 검출된 피부 영역의 픽셀값을 R, G 및 B 채널로 각각 분리한다. 이러한 방법은 원격 PPG(Remote Photoplethymography) 기술에서 일반적으로 사용되는 방법으로, 각 색상 채널이 혈관 내부의 피의 양을 다르게 반영하기 때문이다. 각 색상 채널에서 시간 의 흐름에 따른 변화를 추출하고, 이를 정규화한다. 이와 같이, R, G 및 B 채널을 각각 분리하여 진행하기 때문 에 피부색 영향이 제거되며, 심박의 변화에 집중될 수 있다. 이후, 정규화된 각 3개의 신호를 결합하여 도 12와 같이 PPG 신호를 생성한다. POS 알고리즘은 영상 또는 이미지에서 피부 영역을 추출한 후 피부 픽셀의 RGB 채널 을 분리한 후 x축은 시간축, y축은 픽셀값의 축으로 정하여 각 채널에 대한 그래프를 나타낸다. 도 11과 같이, 혈관과 모세혈관은 각각 R 및 B 채널의 빛을 반사한다. 이와 같이, 분리된 채널의 신호를 정규화한 후 결합하여 PPG 신호를 생성한다. 도 1 및 도 3과 같이, 기존 얼굴 검출 및 얼굴 랜드마크 검출 딥러닝 알고리즘에서는 학습을 통해 생체 신호 분 석 과정을 딥러닝 모델에서 분석하도록 하였다. 분석 과정에 피부 영역을 추출하는 과정이 포함되어 있으며, 영 상 길이에 따라 딥러닝 모델의 연산량이 변경된다. 딥러닝 모델의 연산량은 매번 재정의되고 변경되면 CPU 연산 과정에서 메모리와 버퍼의 크기를 정의하는 과정에서 병목 현상이 발생한다. 또한, 딥러닝 모델의 연산 과정에 피부 영역을 추출하는 과정이 포함되면, 이 모델이 피부 영역을 추출하지 못하는 경우, 생체 신호가 잘못 분석 될 가능성이 있다. 따라서, 본 발명의 실시 예에서는 이를 최소화하고자 고성능의 얼굴 및 랜드마크 검출 딥러닝 모델을 이용하여 피부 영역을 추출하고, 추출된 피부 영역의 결과를 생체 신호 분석 딥러닝 모델에 입력하여 불필요한 연산 과정 을 제거하였다. 딥러닝 모델을 병목 현상없이 실시간 영상에 적용하기 위해 맥박 파형과 호흡 파형을 충분히 분 석할 수 있는 최소 10초로 설정하여 딥러닝 모델을 정의하였다. 이 과정에서 본 발명의 실시 예에서는 생체 신 호 분석 딥러닝 모델의 입력 데이터 처리 과정에 원형 버퍼를 사용하여 피부 영역 이미지를 누적시키고 일정 길 이로 유지시킨다. 본 발명에 따른 생체 신호 분석 알고리즘에서는 원형 버퍼(circular buffer)를 이용하여 입력 영상의 길이를 고 정시킨다. 원형 버퍼는 고정된 크기의 버퍼를 양 끝이 연결된 것처럼 사용할 수 있게 해주는 자료 구조로서, 성 능 저하없이 단순 배열을 덱처럼 사용할 수 있다. 도 15는 본 발명에 따른 원형 버퍼를 설명하기 위해 개략적으로 나타낸 도면이다. 도 15를 참조하면, 본 발명에 따른 생체 신호 분석 알고리즘에서는 입력 데이터의 크기를 예를 들어 36×36 크 기로 비교적 작은 픽셀로 설정하여 피부 영역을 표현한 이미지를 분석할 수 있다. 이와 같이, 본 발명에서는 피 부 영역에 대한 검출 결과를 36×36 크기로 고정함으로써 입력 데이터의 전처리 과정을 생략할 수 있다. 가령, 고해상도의 얼굴 이미지의 경우, 피부 영역에 대한 픽셀 표현이 섬세하여 많은 픽셀로 표현해야 하기 때 문에 많은 잡음이 포함될 가능성이 있으나, 리사이징(resizing)을 통해 해상도를 낮춤으로써 인접 픽셀 값의 정 규화가 가능하고, 이를 통해 잡음을 제거할 수 있다. 10초(30FPS) 동안 피부 영역의 이미지를 누적하고, 생체 신호를 예측하기 때문에 원형 버퍼의 길이는 300이면 족하다. 이 과정을 생체 신호 분석을 위한 딥러닝 추론 과 정에 포함시켜 GPU 연산 과정을 진행한다. 생체 신호 분석을 위한 딥러닝 추론 과정의 전 과정이 GPU 연산 과정 을 통해 연산되므로, CPU와 GPU를 번갈아가며 사용하지 않아되 됨으로 병목 현상을 방지할 수 있다. 도 16은 도 15에 나타낸 원형 버퍼의 동작 과정을 개략적으로 나타낸 도면이다. 도 16을 참조하면, 기존 생체 신호 분석 알고리즘에서 딥러닝 모델 입력 크기는 가변 입력 데이터 크기를 갖는 다. 예를 들어, 딥러닝 모델 입력 크기는 36×36×n(프레임의 수)이므로, 실시간 영상에 적용하는 것이 아니라 이미 녹화된 영상에서 대상의 맥박 및 호흡의 파형을 추출하기 위해 촬영된 영상 전체가 입력으로 사용된다. 그러나, 본 발명의 실시 예에서는 딥러닝 모델의 입력 데이터의 크기를 고정시키고 실시간 영상에서 사용할 수 있도록 변형하였다. 이와 같이, 입력 데이터 크기를 고정하면, 연산에 사용할 스레드(thread)와 프로세스의 크 기를 지정해 놓을 수 있고 크기의 변경없이 유지하여 사용할 수 있다. 이를 통해 병목 현상을 방지한다. 원형 버퍼의 크기는 300(10초 동안의 실시간 프레임 누적)으로 고정하고, 실시간 영상의 최신 프레임에서 피부 영역이 검출된 이미지를 36×36으로 리사이징하여 적층한다. 순차적으로 적층하다가 원형 버퍼의 최대 길이 에 도달하는 순간 가장 오래된 피부 영역이 검출된 이미지를 버퍼에서 제거(300-1 오래된 이미지)하고, 남 은 이미지를 시프트로 이동하여 가장 최근 이미지가 들어올 자리를 비우며, 이 자리에 다시 최근에 검출된 피부 영역 이미지가 입력되는 형태이다. 항상 300의 길이를 유지하며 버퍼 크기의 변동이 없으므로 병목 현상 및 성 능 저하를 방지한다. 이와 같이, 최근 300개의 피부 영역 이미지들을 생체 신호 분석 딥러닝 모델의 입력으로 사용한다. 생체 신호 분석 딥러닝 모델에서는 피부 빛 반사로 일어나는 혈류 변화를 분석한다. 이때, 생체 신호 분석 딥러닝 모델의 분석 기술은 학습 데이터로 다양한 환경에서의 얼굴 영상과, 그 영상을 촬영하는 동안 측정한 PPG 센서 데이터 (호흡, 맥박, 산소포화도 포함)를 사용한다. 영상에서 시간의 흐름에 따른 피부 혈류 변화와 그 변화에 맞는 PPG 센서 데이터를 제공하여 생체 신호 분석 딥러닝 모델이 피부의 혈류 변화에 따른 생체 신호값을 분석하도록 학습한다. 이에 따라 입력 데이터로는 영상 데이터가 필요하고, 이들 영상 데이터는 시간의 흐름에 따라 배치되 어야 한다. 이 영상 데이터의 크기를 지정하고, 실시간으로 생체 신호를 분석하기 위해 본 발명의 실시 예에서 는 원형 버퍼의 크기를 300으로 지정하여 사용한다. 기존 얼굴 검출 알고리즘은 도 1 및 도 3에 나타낸 바와 같이, 입력 원본 이미지에서 얼굴 위치에 대한 좌표값 을 반환한다. 그리고 기존 생체 신호 분석 알고리즘은 피부 영역이 있을 거라고 예측되는 영역(실제로 얼굴을 검출하는 것이 아니라 이미지 중앙부를 절단 및 리사이징 함)을 사용자가 임으로 잘라서 사용하는 형태이므로 얼굴 피부를 실체로 검출하고 사용하는 것은 아니므로, 얼굴 검출 과정이 필요하다. 이러한 과정을 기존 생체 신호 분석 딥러닝 모델에 포함시켜 얼굴 검출과 피부 혈류 변화 분석을 동시에 진행한다. 이러한 방법은 얼굴 검출에 실패해도 확인할 방법이 없으며, 얼굴이 이미지 내에 없음에도 생체 신호 분석 결과가 도출되는 문제가 있다. 그 이유는 항상 사람이 있는 이미지를 학습 데이터로 사용했기 때문이다. 그러나, 본 발명의 실시 예에서는 얼굴 검출 및 피부 영역 검출 과정을 개별로 진행하여 피부 영역 검출의 정확 도를 높이고, 생체 신호 분석을 위한 딥러닝 모델에서는 피부 혈류 변화 분석만 진행하게 하여 생체 신호 분석 의 정확도를 높일 수 있다. 이러한 과정을 통해 기존의 생체 신호 분석 딥러닝 모델에서 얼굴을 검출하는데 필 요한 연산을 제거하고, 리사이징 및 크롭 과정을 도 5에 나타낸 얼굴 및 랜드마크 검출 딥러닝 모델에서 진행하 여 딥러닝 모델 경량화 및 처리 과정을 간소화하였다. 생체 신호 분석부는 생체 신호를 추론할 때, 도 5에 나타낸 얼굴 및 랜드마크 검출 딥러닝 모델을 통해 검 출된 피부 영역의 이미지를 10초간 누적한 후 생체 신호에 대한 예측을 진행한다. 이때, 멀티 쓰레딩 (multithreading) 방식을 사용하여 10초 동안 프레임을 누적하는 과정과, 10초 누적된 프레임으로 생체 신호를 추론하는 과정을 각각 다른 쓰레드를 사용하여 실시간으로 생체 신호를 추론할 수 있다. 생체 신호 분석부는 자신의 딥러닝 모델의 입력 크기에 맞추어 전처리로 36×36 크기로 이미지 크기를 변형 한다(image resize). 이와 같이 동일 크기로 변형된 피부 영역 이미지를 10초간 누적하면, 36×36×300 크기의 입력 행렬이 생성되고, 이를 생체 신호 분석부에서 시간의 흐름에 따른 피부 영역 변화를 분석한다. 추론된 맥박 및 호흡 파형은 Raw 신호(Raw Data)와 유사하며, 잡음이 많이 포함되어 있는 상태이다. 이에 따라 생체 신호 분석부에서는 추론된 Raw 신호 형태의 맥박 및 호흡 파형로부터 잡음을 제거한 후 분당 맥박수와 호흡수를 측정한다. 생체 신호 분석부는 신호 처리 과정에서 버터워스 필터(butterworth filter)로 잡음을 제거한 후 맥박 및 호흡 파형에 각각 피크 지점을 계산한다. 이때, 버퍼워스 필터로 잡음이 완벽히 제거되지 않기 때문에 여러 피 크 지점이 발생할 수 있는데, 이 경우 도 17에 나타낸 신호 처리 결과에서와 같이, 이동 평균 필터(moving average filter)와 컨볼루션 필터(conolution filter, Conv 필터)를 각각 적용하여 전체적인 잡음을 제거하고, 이를 통해 매끄러운 신호를 생성하고, 신호의 추세를 유지할 수 있다. 신호의 추세가 유지되어 피크를 분석하는 데 유리하다. 아래 [수학식 1]은 이동 평균 필터를 나타내고, [수학식 2]는 컨볼루션 필터를 나타낸다. 수학식 1 수학식 2"}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 [수학식 2]에서, 컨볼루션 필터(Conv 필터)는 딥러닝 알고리즘의 컨볼루션 1차원 커널을 참고하였다. 위 [수 학식 2]와 같은 컨볼루션 필터를 적용하면, 시계열 데이터 중앙값은 가중이 높은 결과 값으로 도출할 수 있다. 이를 통해 급격한 변화를 발생하는 값들이 원만하게 필터링되며, 신호의 추세와 피크가 유지될 수 있다. 주어진 데이터에서 피크 수를 분석하기 위해 양쪽 이웃 값보다 큰 값을 찾는다. 이렇게 찾은 최대값은 피크 간 의 거리가 최소 15가 되도록 연산한다. 로컬 최대값은 i가 리스트 내의 인덱스이고, x가 리스트일 때, 아래 [수 학식 3]을 만족하는 값을 피크로 지정한다. 10초 내의 피크 수를 계산한다. 도 18은 피크 수의 도출 결과를 나 타낸 도면이다. 계산된 피크 수에 6을 곱하여 분당 맥박 및 호흡수로 변환한다. 수학식 3"}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "스트레스 지수 산출부는 도 4에 나타낸 생체 신호 분석부를 통해 추정된 분당 맥박수와 호습수를 이용 하여 스트레스 지수를 계산한다. 일반적으로, 성인의 분당 맥박수는 60~90이고, 분당 호흡수는 12~20으로 알려 져 있다. 스트레스 지수 산출부는 이러한 성인의 분당 맥박수와 호흡수를 활용하여 스트레스 지수를 계산한 다. 또한 맥박 파형의 누적을 통해 맥박의 변동성으로 스트레스 지수를 계산한다. 측정 대상이 움직일 때 맥박 이 일정하지 않고 다양함을 띄면 움직임에 따라 맥박도 함께 변화하는 것이므로 스트레스 지수가 낮음을 의미하 고, 맥박이 일정할 경우에는 스트레스가 높은 상태를 의미한다. 이를 통해, 고정밀 스트레스 지수를 계산하고 실시간 스트레스 지수를 누적하여 이상치가 발생하는 지점을 제거한다. 도 19는 본 발명에 따른 스트레스 지수 변환 모델을 개략적으로 나타낸 도면이다. 도 19를 참조하면, 본 발명에 따른 스트레스 지수 변환 모델은 얼굴에서 피부 혈류의 변화를 측정하여 획득된 맥박/호흡 파형을 입력받아 분당 맥박수와 호흡수를 측정하고, 측정된 분당 맥박수와 호흡수를 이용하여 스트레 스 지수를 계산한다. 스트레스 지수 계산법은 맥박 및 호흡 상관관계를 이용하여 계산하는 방법(a)과 맥박 다양성을 이용하여 계산하 는 방법(b)으로 구분할 수 있다. 맥박 및 호흡 상관관계를 이용하여 계산하는 방법(a)은 [(맥박수-호흡수)/호흡 수]로 계산된다. 이 지수는 2.5미만일 때, 낮음(지수 1), 2.5이상 4.5미만일 때, 보통(지수 2), 4.5이상일 때 높음(지수 3)으로 분류된다. 이는 맥박 및 호흡의 분당 수에 영향을 많이 받으므로 가중치를 0.3으로 계산한다. 맥박 다양성을 이용하여 계산하는 방법(b)은 아래 [수학식 4]와 같다. N은 맥박 간격의 총 개수(피크 수), 는 i번째 맥박 간격이다. 수학식 4"}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "가령, 50초과이면, 스트레스 낮음(지수 1), 30초과 50이하면, 스트레스 보통(지수 2), 30이하면, 스트레스 높음 (지수 3)으로 분류된다. 아래의 [수학식 5]와 같이, 맥박 및 호흡 상관관계를 이용하여 계산하는 방법(a)과 맥박 다양성을 이용하여 계산하는 방법(b)의 결과에 가중치를 각각 곱하여 종합 스트레스 지수를 계산한다. 수학식 5"}
{"patent_id": "10-2023-0121099", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "생체 정보 출력부는 도 19에 나타낸 스트레스 지수 변환 모델을 이용하여 얻어진 종합 스트레스 지수를 도 20과 같이 출력한다. 가령, 대상자 이미지, 그리고 대상자의 맥박 및 호흡 파형, 스트레스 지수를 시각화 및 수 치화하여 제공한다. 이상에서와 같이, 본 발명의 바람직한 실시 예가 특정 용어들을 사용하여 설명 및 도시되었지만, 그러한 용어는 오로지 본 발명을 명확하게 설명하기 위한 것일 뿐이다. 그리고, 본 발명의 실시 예 및 기술된 용어는 다음의 청구범위의 기술적 사상 및 범위로부터 이탈되지 않고서 여러 가지 변경 및 변화가 가해질 수 있는 것은 자명한 일이다. 이와 같이 변형된 실시 예들은 본 발명의 사상 및 범위로부터 개별적으로 이해되어져서는 안되며, 본 발명의 청구범위 안에 속한다고 해야 할 것이다."}
{"patent_id": "10-2023-0121099", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 기존 얼굴 검출 딥러닝 모델을 나타낸 도면. 도 2는 도 1에 나타낸 NMS(Non-Maximum Suppression) 전과 후의 검출 상자를 나타낸 예시도. 도 3은 기존 얼굴 랜드마크 검출 딥러닝 모델을 나타낸 도면. 도 4는 본 발명의 실시 예에 따른 CCTV 기반의 생체 정보 제공 시스템을 나타낸 도면. 도 5는 본 발명에 따른 얼굴 및 랜드마크 검출 딥러닝 모델을 나타낸 도면. 도 6은 도 5에 나타낸 얼굴 및 랜드마크 검출 딥러닝 모델을 상세하게 나타낸 도면. 도 7은 본 발명에 따른 특징 맵을 나타낸 예시도. 도 8은 본 발명에 따른 연결(concatenation) 기법을 이용하여 특징 맵을 누적하는 과정을 나타낸 개념도. 도 9는 요소 합을 이용하여 특징 맵을 합치는 과정을 나타낸 예시도. 도 10은 연결 기법을 이용하여 특징 맵을 누적시키는 과정을 나타낸 예시도. 도 11은 본 발명에 따른 생체 신호 분석 알고리즘에 적용되는 피부 빛 반사 모델을 나타낸 도면. 도 12는 본 발명에 따른 POS(Plane-Orthogonal-to-Skin) 알고리즘을 나타낸 도면. 도 13은 기존 맥박 및 호흡 추정 알고리즘을 나타낸 도면. 도 14는 본 발명에 따른 맥박 및 호흡 추정 알고리즘을 나타낸 도면. 도 15는 본 발명에 따른 원형 버퍼를 나타낸 도면. 도 16은 도 15에 나타낸 원형 버퍼의 동작 과정을 나타낸 도면. 도 17은 본 발명에 따른 생체 신호 분석부를 통해 처리된 신호 처리 결과를 나타낸 도면. 도 18은 본 발명에 따른 생체 신호 분석부를 통해 도출된 피크 수 도출 결과를 나타낸 도면. 도 19는 본 발명에 따른 스트레스 지수 변환 모델을 나타낸 도면. 도 20은 본 발명에 따른 생체 정보 출력부를 통해 출력된 시각화된 이미지를 나타낸 도면."}
