{"patent_id": "10-2022-0031788", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0134693", "출원번호": "10-2022-0031788", "발명의 명칭": "사용자 감정 정보를 인식하는 비전기반 인공지능 인터페이스 방법 및 장치", "출원인": "전주대학교 산학협력단", "발명자": "이영재"}}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 장치에 있어서,게임 사용자의 얼굴 및 손가락을 인식하도록 구성된 입력 인터페이스; 및상기 입력 인터페이스와 동작 가능하게 결합되고, 플레이되고 있는 게임의 모드에 따라 상기 인식된 손가락에관한 정보를 상이하게 추출하고, 상기 추출된 정보를 통해 상기 게임 내의 캐릭터의 동작을 제어하는 프로세서를 포함하고,상기 프로세서는,제1 모드에서 왼손 엄지와 왼손 검지의 거리 정보를 이용하여 상기 게임의 볼륨 조정 및 게임 설정을 변경하고,오른손 손가락 각각을 인식하여 카운트하고,제2 모드에서 손가락 관절을 구분하여 디스플레이의 화면에 표시하고 왼손 주먹의 움직임을 인식하여 상기 게임내의 적 캐릭터의 공격을 수행하도록 하고,제3 모드에서 게임 중 상기 게임 내의 캐릭터의 공격 형태 및 상기 게임 사용자의 표정 변화에 기초하여 상기게임 사용자의 감정 정보를 추출하는, 비전기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 제1 모드에서 왼손 손가락 5개와 오른손 손가락 5개가 모두 인식된 경우, 상기 인식된 위치에 대응하여 상기 게임의 화면에 왼손 손가락 5개를 출력하여 표시하고,상기 제2 모드로 진행하여 왼손의 손가락 관절이 주먹 쥔 상태로 판단되면, 왼손 주먹이 인식된 위치에 대응하여 상기 게임의 화면에 왼손 주목을 출력하여 표시하고,상기 제3 모드에서 상기 적 캐릭터에 대한 공격에 따라 해당 미션이 종료되면, 상기 게임 내의 캐릭터의 공격형태 및 상기 게임 사용자의 표정 변화에 기초하여 추출된 상기 감정 정보를 화면에 표시하는, 비전 기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,상기 제3 모드에서 상기 추출된 감정 정보를 상기 게임 사용자의 얼굴이 포함된 화면의 특정 위치에 표시하고,상기 감정 정보는 angry, disgust, fear, happy, sad, surprise, neutral 항목별로 0 내지 1 사이의 값으로 표시되는, 비전 기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 게임 사용자의 눈 깜빡임, 입 벌림을 통해 감정 상태를 추출하고,상기 게임 사용자의 눈 깜빡임, 하품에 따른 몰입도를 온도 센서, 습도 센서 및 CO2 센서를 통해 획득된 센서공개특허 10-2023-0134693-3-정보 값을 이용하여 안구 건조에 따른 보상 및 공기오염에 따른 보상을 수행하고,보상결과에 따라 보정된 감정 상태를 상기 게임 사용자의 얼굴이 포함된 화면의 특정 위치에 표시하는, 비전 기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는,상기 인식된 손가락의 손가락 마디와 손끝에 3D 좌표를 21개의 특징점을 배정하고,상기 배정된 21개의 특징점들의 좌표를 입력 데이터로 머신러닝을 통해 손가락 추적 및 인식 알고리즘을 실행하는, 비전 기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 특징점들의 변경된 현재 위치에 따라 상기 손가락의 현재 위치를 업데이트하고,K-Nearest Neighbor (K-NN) 알고리즘에 따라 K개의 인접한 특징점들에 기초하여 화면상에서 손가락 이동을 추적및 인식하는, 비전 기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 제2 모드에서 상기 특징점들의 변경된 현재 위치에 따라 왼손이 주먹 쥔 상태라고 판단되면, 상기 왼손 주먹의 이동 거리 및 이동 속도에 따른 변화량으로 상기 게임 내의 적 캐릭터의 공격을 수행하도록 하는, 비전 기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 프로세서는,상기 제1 모드에서 상기 인식된 오른손 손가락에서 엄지와 중지의 2D 좌표 위치 변화와 상기 2D 좌표 사이의 거리에 따라 상기 게임 내의 캐릭터의 이동 방향 및 이동 각도와 연관된 회전량을 산출하고,상기 산출된 이동 방향 및 회전량에 따라 상기 게임 내의 캐릭터가 게임 화면 내에서 위치를 이동하도록 제어하는, 비전 기반 인공지능 인터페이스 장치."}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 장치는 게임 사용자의 얼 굴 및 손가락을 인식하도록 구성된 입력 인터페이스; 및 상기 입력 인터페이스와 동작 가능하게 결합되고, 플레 이되고 있는 게임의 모드에 따라 상기 인식된 손가락에 관한 정보를 상이하게 추출하고, 상기 추출된 정보를 통 해 상기 게임 내의 캐릭터의 동작을 제어하는 프로세서를 포함한다. 상기 프로세서는 제1 모드에서 왼손 엄지와 왼손 검지의 거리 정보를 이용하여 상기 게임의 볼륨 조정 및 게임 설정을 변경하고, 오른손 손가락 각각을 인식 하여 카운트하고, 제2 모드에서 손가락 관절을 구분하여 디스플레이의 화면에 표시하고 왼손 주먹의 움직임을 인 식하여 상기 게임 내의 적 캐릭터의 공격을 수행하도록 제어할 수 있다."}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비전기반 인공지능 인터페이스 방법 및 장치에 관한 발명으로서, 보다 상세하게는 사용자 감정 정보 를 인식하는 비전 인공지능 인터페이스 방법 및 장치에 관한 발명이다."}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 인터페이스 장치는 유선 또는 무선으로 본체에 연결되거나 컴퓨터나 기타 전자기기의 본체에 일체형으로 형성되어 기기를 작동하는 방식으로 입력되고 제어되는 방식이 주류를 형성한다. 컴퓨터 키보드는 별도의 키판 에 다수 개의 버튼을 달아 그 버튼을 조작하게 함으로써 입력할 수 있다. 스마트 폰과 같은 이동 단말기는 화면 에 키보드를 띄워 손가락으로 터치를 하게 함으로써 입력되는 방식이다. 이와 관련하여, 일반 전자제품이나 전기부품도 본체에 일체형으로 제어장치를 달거나 리모콘을 이용하여 제어를 하고 명령을 입력할 수 있다. 이런 이유로 종래의 입력장치는 별도의 모양과 크기를 갖는 입력장치를 마련하거 나 본체가 있는 곳까지 이동하여야만 제어를 하고 입력을 할 수 있어 사용자의 장비착용으로 인한 부자연스로운 사용감, 에러누적, 장비보정, 사용상의 복잡성 등의 문제가 있으며, 비용 및 시간이 소요된다는 문제점이 있었 다. 한편, 최근에는 컴퓨터를 통해 사용자가 실제 몰입감을 느낄 수 있도록 하는 인터페이스가 제공될 필요가 있다. (멀티모달 사용자 친화형 인터페이스가 필요하다는 등 강조하는 내용을 추가할 것)이러한 인터페이스와 관련하 여 사용자가 미디어 콘텐츠를 사용하기 위해 입력 인터페이스와 출력 인터페이스의 형태로 제공될 필요가 있다. 특히, 컴퓨터 게임 등과 같이 사용자와 컴퓨터간에 자연스러운 상호작용에 있어 맥락인식이 필요한 실행 장치에 있어서 사용자의 신체 부위, 특히 손, 손가락 부위의 모션을 정확하게 감지할 필요가 있다. 이와 관련하여, 컴 퓨터 게임 등이 실행되는 장치에 있어서 별도의 입력 장치 없이도 사용자의 신체 부위, 특히 손, 손가락 부위의 모션과 얼굴감정정보를 정확하게 감지할 수 있는 방법 및 장치가 구체적으로 제시되지 않았다는 문제점이 있다."}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 별도의 입력 장치 없이 사용자의 신체 부위, 특히 손, 손가락 부위의 모션을 정확하게 감지하 기 위한 것이다. 또한, 본 발명의 목적은 비전기반 인터페이스를 통해 사용자 감정 정보를 인식하기 위한 것이다."}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 사용자 감정 정보를 인식하는 비전 인공지능 인터페이스 장치는 게임 사용자의 얼굴 및 손가락을 인식하도록 구성된 입력 인터페이스; 및 상기 입력 인터페이스와 동작 가능하게 결합되고, 플레이 되고 있는 게임의 모드에 따라 상기 인식된 손가락에 관한 정보를 상이하게 추출하고, 상기 추출된 정보를 통해 상기 게임 내의 캐릭터의 동작을 제어하는 프로세서를 포함한다. 상기 프로세서는 제1 모드에서 왼손 엄지와 왼 손 검지의 거리 정보를 이용하여 상기 게임의 볼륨 조정 및 게임 설정을 변경하고, 오른손 손가락 각각을 인식 하여 카운트하고, 제2 모드에서 손가락 관절을 구분하여 디스플레이의 화면에 표시하고 왼손 주먹의 움직임을 인식하여 상기 게임 내의 적 캐릭터의 공격을 수행하도록 제어할 수 있다. 일 실시예에 따르면, 상기 프로세서는 제3 모드에서 게임 중 상기 게임 내의 캐릭터의 공격 형태 및 상기 게임 사용자의 표정 변화에 기초하여 상기 게임 사용자의 감정 정보를 추출할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 모드에서 왼손 손가락 5개와 오른손 손가락 5개가 모두 인식된 경우, 상기 인식된 위치에 대응하여 상기 게임의 화면에 왼손 손가락 5개를 출력하여 표시하고, 상기 제2 모드 로 진행하여 왼손의 손가락 관절이 주먹 쥔 상태로 판단되면, 왼손 주먹이 인식된 위치에 대응하여 상기 게임의 화면에 왼손 주목을 출력하여 표시하고, 상기 제3 모드에서 상기 적 캐릭터에 대한 공격에 따라 해당 미션이 종 료되면, 상기 게임 내의 캐릭터의 공격 형태 및 상기 게임 사용자의 표정 변화에 기초하여 추출된 상기 감정 정 보를 화면에 표시할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제3 모드에서 상기 추출된 감정 정보를 상기 게임 사용자의 얼굴이 포함된 화면의 특정 위치에 표시하고, 상기 감정 정보는 angry, disgust, fear, happy, sad, surprise, neutral 항목별로 0과 1 사이의 값으로 표시되는 것을 특징으로 한다. 일 실시예에 따르면, 상기 프로세서는 상기 게임 사용자의 눈 깜빡임, 입 벌림을 통해 감정 상태를 추출하고, 상기 게임 사용자의 눈 깜빡임, 하품에 따른 몰입도를 온도 센서, 습도 센서 및 CO2 센서를 통해 획득된 센서 정보 값을 이용하여 안구 건조에 따른 보상 및 공기오염에 따른 보상을 수행하고, 보상결과에 따라 보정된 감정 상태를 상기 게임 사용자의 얼굴이 포함된 화면의 특정 위치에 표시하는 것을 특징으로 한다. 일 실시예에 따르면, 상기 프로세서는 상기 인식된 손가락의 손가락 마디와 손끝에 3D 좌표를 21개의 특징점을 배정하고, 상기 배정된 21개의 특징점들의 좌표를 입력 데이터로 머신러닝을 통해 손가락 추적 및 인식 알고리 즘을 실행할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 특징점들의 변경된 현재 위치에 따라 상기 손가락의 현재 위치를 업 데이트하고, K-Nearest Neighbor (K-NN) 알고리즘에 따라 K개의 인접한 특징점들에 기초하여 화면상에서 손가락이동을 추적 및 인식할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제2 모드에서 상기 특징점들의 변경된 현재 위치에 따라 왼손이 주 먹 쥔 상태라고 판단되면, 상기 왼손 주먹의 이동 거리 및 이동 속도에 따른 변화량으로 상기 게임 내의 적 캐 릭터의 공격을 수행하도록 제어할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 제1 모드에서 상기 인식된 오른손 손가락에서 엄지와 중지의 2D 좌 표 위치 변화와 상기 2D 좌표 사이의 거리에 따라 상기 게임 내의 캐릭터의 이동 방향 및 이동 각도와 연관된 회전량을 산출하고, 상기 산출된 이동 방향 및 회전량에 따라 상기 게임 내의 캐릭터가 게임 화면 내에서 위치 를 이동하도록 제어할 수 있다."}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 컴퓨터 게임 등이 실행되는 장치에 있어서 별도의 입력 장치 없이도 사용자의 신체 부위, 특히 손 부위의 모션을 정확하게 감지할수 있는 방법 및 장치를 제공할 수 있다. 또한, 본 발명의 실시예에 따르면, 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법 및 장치 를 제공할 수 있다. 또한, 본 발명의 실시예에 따르면, 게이머의 실시간 감정 정보를 활용한 맞춤형 서비스 제공이 가능하다. 본 발명의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 발명의 사 상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 발명의 바람직한 실시 예와 같은 특정 실시 예는 단지 예시로 주어진 것으로 이해되어야 한다."}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시 예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시 예들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시 예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시 예들을 도면에 예시하고 본 명세서에서 상세하게 설명하고자 한다. 그러나 이는 본 발명의 개념에 따른 실시 예 들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 벗어나지 않은 채, 제1 구성 요소는 제2 구성 요소로 명명 될 수 있고 유사하게 제2 구성 요소는 제1 구성 요소로도 명명될 수 있다. 어떤 구성 요소가 다른 구성 요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성 요소 에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성 요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성 요소가 다른 구성 요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는 중간에 다른 구성 요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성 요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등 도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 본 명세서에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구 성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 본 명세서에 첨부된 도면들을 참조하여 본 발명의 실시 예들을 상세히 설명한다. 그러나 특허출원의 범위 가 이러한 실시 예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1은 본 발명의 실시예에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 장치의 구성도이 다. 도 1에 도시된 바와 같이 비전 기반 인공지능 인터페이스 장치는 입력 인터페이스, 프로세서, 디 스플레이 및 메모리를 포함하도록 구성될 수 있다. 입력 인터페이스는 카메라 및 복수의 센서 모듈을 포함하도록 구성될 수 있다. 입력 인터페이스는 게임 사용자의 얼굴 및 손가락을 인식하도록 구성될 수 있다. 프로세서는 입력 인 터페이스와 동작 가능하게 결합될 수 있다. 프로세서는 플레이되고 있는 게임의 모드에 따라 인식된 손가락에 관한 정보를 상이하게 추출하도록 구성될 수 있다. 프로세서는 추출된 정보를 통해 게임 내의 캐 릭터의 동작을 제어하도록 구성될 수 있다. 디스플레이는 플레이 (실행)되고 있는 게임 프로그램의 화면이 표시되도록 구성될 수 있다. 디스플레이 는 사용자 설정 모드와 같은 제1 모드에서 게임 사용자의 얼굴 및/또는 손가락이 표시되도록 구성될 수 있 다. 메모리는 플레이 (실행)되고 있는 게임 프로그램과 연관된 정보가 저장되도록 구성될 수 있다. 이하에서는, 본 발명에 따른 사용자 감정 정보를 인식하는 비전 인공지능 인터페이스 장치에서 실행하는 복수의 모드에서의 인터페이스 및 화면 구성에 대해 설명한다. 이와 관련하여, 도 2a는 제1 게임 모드에서 사용자의 양 손을 인식하고 왼손 모드가 출력되는 화면 구성을 나타낸다. 도 2b는 제2 게임 모드에서 사용자의 양 손 중 한 손, 예컨대 왼손의 형태가 변경된 경우 출력되는 화면 구성을 나타낸다. 또한, 도 2c는 제3 게임 모드에서 사용자의 손가락 마디를 인식하여 게임 캐릭터를 제어하는 화면 구성을 나타 낸다. 도 2c의 제3 게임 모드에서 게임 캐릭터 제어 이외에 사용자의 얼굴 부위를 인식하여 게임 중 감정 정보 를 실시간으로 확인할 수 있다. 도 2a를 참조하면, 제1 모드에서 액션 게임(Action Game)이 진행될 수 있다. 제1 모드에서 몰입 요소인 얼굴은 표시되지 않고 손과 손가락 마디 인식이 이루어질 수 있다. 손과 손가락 인식을 위한 인터페이스(Interface)를 통해 왼손, 오른손 구분, 손가락 구분이 가능하다. 왼손 엄지와 검지 거리 정보를 활용하여 볼륨(volume) 조정 및 제어가 가능하다. 또한, 오른손 5개 손가락을 카운트하고, 게임의 왼손 모드를 출력할 수도 있다. 이 경우, 게임 내 왼 손가락 5개가 출력되도록 표시할 수 있다.도 2b를 참조하면, 제2 모드에서 액션 게임(Action Game)이 진행될 수 있다. 제2 모드에서 몰입 요소인 얼굴은 표시되지 않고 손과 손가락 마디 인식이 제1 모드에 이어 계속될 수 있다. 손과 손가락 인식을 위한 인터페이스 를 통해 왼손, 오른손 구분, 손가락 관절 구분 표시 모드가 실행될 수 있다. 일 예로, 손가락 관절 구분 표시 모드에 따라 왼손 주먹 모드가 진행되고 오른손에 대한 인식도 이루어질 수 있다. 게임의 왼손 주먹 모드가 출 력되고, 왼손 주먹 모드에서 게임 내 적 캐릭터 공격용 인터페이스가 실행될 수 있다. 도 2c를 참조하면, 제3 모드에서 액션 게임(Action Game)이 진행될 수 있다. 제3 모드에서 몰입 요소인 얼굴은 표시되지 않고 손과 손가락 마디 인식이 제2 모드에 이어 계속될 수 있다. 한편, 제3 모드에서 게이머 감정 정 보가 출력될 수 있다. 감정정보의 출력 예는 angry, digust, fear... 등 7가지 세분화된 감정정보로 출력 가능 하다. 이와 관련하여, 도 3은 본 발명에 따른 사용자 얼굴 인식에 따라 화면에 7가지 감정이 표시된 화면 구성을 나타 낸다. 도 1, 도 2c 및 도 3을 참조하면, 디스플레이의 화면에 사용자 얼굴이 박스 형태로 표시되고 화면의 일 영역에 angry, disgust, fear, happy, sad, surprise, neutral 항목별로 감정 정보가 0 내지 1 사이의 값으 로 표시될 수 있다. 이러한 감정 정보의 표시를 위해 [{'box': (216, 225, 149, 149), 'emotions': {'angry': 0.01, 'disgust': 0.0, 'fear': 0.02, 'happy': 0.07, 'sad': 0.05, 'surprise': 0.0, 'neutral': 0.85}}]의 형태로 정보가 프로세서에서 디스플레이를 제어하는 디스플레이 드라이버로 제공될 수 있다. 또한, 해당 정보는 프로세서에서 메모리로 전달될 수 있다. 이를 통해, 게임 중 감정 정보를 실시간으로 확인 가능하다. 이와 관련하여 게임 중 감정 정보는 어느 정도의 시간 지연(time delay)가 존재할 수는 있지만, 이러한 시간 지연은 사용자가 다른 감정으로 전환되는 시간 간격 에 비해 매우 짧아 실질적으로 게임 중 감정 정보를 실시간으로 확인할 수 있다. 따라서, 본 발명을 통해 게이 머의 실시간 감정 정보를 활용한 맞춤형 서비스 제공이 가능하다. 나아가, 컨텐츠(contents) 사용 만족도 및 높 은 수준의 초 개인화 서비스를 구현할 수 있다. 도 1 내지 도 3을 참조하여, 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 장치 에 대해 상세하게 설명한다. 프로세서는 제1 모드에서 왼손 엄지와 왼손 검지의 거리 정보를 이용하여 상 기 게임의 볼륨 조정 및 게임 설정을 변경하고, 오른손 손가락 각각을 인식하여 카운트할 수 있다. 프로세서 는 제2 모드에서 손가락 관절을 구분하여 디스플레이의 화면에 표시하고 왼손 주먹의 움직임을 인식하여 상기 게임 내의 적 캐릭터의 공격을 수행하도록 제어할 수 있다. 프로세서는 제3 모드에서 게임 중 상기 게임 사용자의 얼굴 부위의 표정 변화에 기초하여 상기 게임 사용 자의 감정 정보를 추출할 수 있다. 한편, 프로세서는 제3 모드에서 게임 중 상기 게임 내의 캐릭터의 공격 형태 및 상기 게임 사용자의 표정 변화에 기초하여 상기 게임 사용자의 감정 정보를 추출할 수 있다. 프로세서는 상기 제1 모드에서 왼손 손가락 5개와 오른손 손가락 5개가 모두 인식된 경우, 상기 인식된 위 치에 대응하여 상기 게임의 화면에 왼손 손가락 5개를 출력하여 표시할 수 있다. 프로세서는 상기 제2 모 드로 진행하여 왼손의 손가락 관절이 주먹 쥔 상태로 판단되면, 왼손 주먹이 인식된 위치에 대응하여 상기 게임 의 화면에 왼손 주목을 출력하여 표시할 수 있다. 프로세서는 상기 제3 모드에서 상기 적 캐릭터에 대한 공격에 따라 해당 미션이 종료되면, 상기 게임 내의 캐릭터의 공격 형태 및 상기 게임 사용자의 표정 변화에 기 초하여 추출된 상기 감정 정보를 화면에 표시할 수 있다. 프로세서는 상기 제3 모드에서 상기 추출된 감정 정보를 상기 게임 사용자의 얼굴이 포함된 화면의 특정 위치에 표시할 수 있다. 상기 감정 정보는 angry, disgust, fear, happy, sad, surprise, neutral 항목별로 0 내지 1 사이의 값으로 표시될 수 있다. 한편, 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법은 외부 환경 변화에 따른 사용자의 신체 변화를 감지하여 보다 정확한 사용자 감정 정보의 인식이 가능하다. 이와 관련하여, 도 4는 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법에서 사용자 얼굴 특정 부위, 눈과 입 검출과 이의 변화 정보를 이용하는 화면 구성을 나타낸다. 도 1 내지 도 4를 참조하면, 눈과 입 검출 및 이의 변화 정보를 활용하여 외부 환경 변화에 따른 사용자의 신체 변화를 감지하여 보다 정확한 사용자 감정 정보의 인식이 가능하다. 1) 눈 깜빡임, 입벌림 등을 통하여 사용자 의 감정 상태 확인 (Blink, Mouth open)이 가능하다. 2) 온도/습도 센서 출력, CO2 센서 정보 출력을 활용하여 깜빡임, 하품 등에 따른 객관적인 몰입도 및 안구 건조 여부 판단, CO2포화상태 판단이 가능하다.이와 관련하여, 프로세서는 게임 사용자의 눈 깜빡임, 입 벌림을 통해 감정 상태를 추출할 수 있다. 프로 세서는 게임 사용자의 눈 깜빡임, 하품에 따른 몰입도를 온도 센서, 습도 센서 및 CO2 센서를 통해 획득된 센서 정보 값을 이용하여 안구 건조에 따른 보상 및 공기순환을 수행할 수 있다. 프로세서는 상기 보상된 몰입도에 따라 보정된 감정 상태를 상기 게임 사용자의 얼굴이 포함된 화면의 특정 위치에 표시할 수 있다. 한편, 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법은 인식된 손가락의 손 가락 마디와 손끝에 3D 좌표를 복수 개개의 특징점을 배정하고 손가락 추적 및 인식 알고리즘을 실행하도록 구 성될 수 있다. 이와 관련하여, 도 5는 본 발명에 따른 비전 기반 인공지능 인터페이스 방법에서 손가락 정보를 표현하는 개념도를 나타낸다. 도 5를 참조하면, 손가락 인식은 K-NN 알고리즘과 21개의 landmark 점의 좌표 변화량을 추론해 인식할 수 있다. K-NN 알고리즘은 데이터를 가장 가까운 속성에 따라 분류하여 레이블링을 하는 알고리즘이다. K-NN은 K-Nearest Neighbor의 줄임말로 K개의 가까운 이웃의 속성에 따라 분류하므로 거리를 기반으로 분류하는 알고리즘이며 따 라서 상대적으로 거리가 더 짧은 이웃이 더 가까운 이웃으로 취급된다. 즉, K-NN 알고리즘은 어떤 새로운 데이 터로부터 거리가 가까운 K개의 다른 데이터의 레이블(속성)을 참고하여 가장 빈도 수가 높게 나온 데이터의 레 이블로 분류하는 알고리즘이다. 한편, 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법은 손가락의 이동 및 회전 각도를 검출하여 게임 내 메인 캐릭터의 움직임 및 영역 이동 등에 반영할 수 있다. 이와 관련하여, 도 6 은 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법과 관련하여 손가락의 이 동 및 회전 각도를 검출하기 위한 화면 구성을 나타낸다. 도 6을 참조하면, 오른손의 경우 p1(x1, y1) p2(x2, y2)의 두 점 사이의 거리를 arctan 값을 사용하여 계산하여 main 캐릭터의 회전량으로 사용할 수 있다. 도 5 및 도 6을 참조하면, 21개의 landmark 점의 좌표 변화량을 통해 손가락의 구부러짐을 확인할 수 있다. 또한, 21개 의 landmark 점의 좌표 변화량과 두 손가락 사이의 거리 및 변화량을 통해 보다 정확하게 손가락의 구부러짐을 확인할 수 있다. 이와 관련하여, 손가락 추적 및 인식은 3D 좌표를 활용하여 손가락 마디와 손끝에 3D 좌표 21개를 배정하여 이 루어질 수 있다. 따라서. 손 크기와 위치를 파악하기 위해 손 전체 데이터를 변환하던 절차가 사라졌고 좌표를 읽어내어 정확도는 높이고 데이터 용량은 감소시킬 수 있다. 이를 위해 수만 장의 손가락 사진에 21개 좌표를 각각 입력한 뒤 머신러닝 시스템을 학습시킬 수 있다. 손 추적 및 인식 알고리즘으로 손짓 분석도 가능하다. 손 가락 추적 및 인식에서 한 단계 나아간 기술로 알고리즘이 사전에 입력된 손짓과 손가락 관절 각도를 비교해 의 미를 해석한다. 따라서 숫자나 브이(V)와 같은 손가락의 특정 동작 등을 비전 기반 인공지능 인터페이스 장치가 스스로 이해하여 이를 사용자 감정 정보를 추출하고 활용하는데 이용할 수 있다. 전술한 바와 같이 본 발명에 따른 손가락의 특정 동작을 비전 기반 인공지능 인터페이스 장치가 스스로 이해하 여 이를 사용자 감정 정보를 추출하고 활용하는 화면 구성은 도 7과 같이 구성될 수 있다. 이와 관련하여, 도 7 은 본 발명에 따른 손가락의 특정 동작을 비전 기반 인공지능 인터페이스 장치가 추출하고 추출된 정보를 화면 에 표시하는 화면 UI를 나타낸다. 도 7을 참조하면, 사용자의 얼굴 특정 부위, 눈 깜빡임 및 입 벌림 동작이 검출되고 이에 따른 정보가 표시되고 저장될 수 있다. 또한, 사용자의 얼굴 특정 부위의 동작과 외부 환경 보정에 따른 사용자의 각 항목 별 감정 지 수가 화면에 표시되고 저장될 수 있다. 또한, 사용자의 손가락 마디를 인식하고 특징점들의 이동 등의 변화량을 추출할 수 있다. 일 예로, 왼손이 후방(backward)으로 이동하는 상태 및 이동량을 감지할 수 있다. 오른손 중 엄지와 중지 사이의 거리와 거리 변화량에 따라 게임 내 캐릭터의 움직임, 이동 방향 및 이동 거리를 제어할 수 있다. 도 1 내지 도 7을 참조하여, 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법 및 장치에 대해 더 상세하게 설명한다. 프로세서는 인식된 손가락의 손가락 마디와 손끝에 3D 좌표를 복수 개의 특징점을 배정할 수 있다. 일 예로, 21개의 특징점이 배정될 수 있지만, 이에 한정되는 것은 아니다. 프로 세서는 상기 배정된 21개의 특징점들의 좌표를 입력 데이터로 머신러닝을 통해 손가락 추적 및 인식 알고 리즘을 실행할 수 있다. 프로세서는 상기 특징점들의 변경된 현재 위치에 따라 상기 손가락의 현재 위치를 업데이트할 수 있다. 프 로세서는 K-Nearest Neighbor (K-NN) 알고리즘에 따라 K개의 인접한 특징점들에 기초하여 화면상에서 손가 락 이동을 추적 및 인식할 수 있다.프로세서는 제2 모드에서 상기 특징점들의 변경된 현재 위치에 따라 왼손이 주먹 쥔 상태인지 여부를 판단 할 수 있다. 왼손이 주먹 쥔 상태라고 판단되면, 프로세서는 상기 왼손 주먹의 이동 거리 및 이동 속도에 따른 충격량으로 상기 게임 내의 적 캐릭터의 공격을 수행하도록 제어할 수 있다. 프로세서는 상기 제1 모드에서 상기 인식된 오른손 손가락에서 엄지와 중지의 2D 좌표 위치 변화와 상기 2D 좌표 사이의 거리에 따라 상기 게임 내의 캐릭터의 이동 방향 및 이동 각도와 연관된 회전량을 산출할 수 있 다. 프로세서는 상기 산출된 이동 방향 및 회전량에 따라 상기 게임 내의 캐릭터가 게임 화면 내에서 위치 를 이동하도록 제어할 수 있다. 이상에서는 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법 및 장치에 대해 설명하였다. 본 발명을 통해 손 전체 형상을 이용하는 것이 아닌 5개의 손가락 정보를 각각 개별적으로 활용한 기존의 방식보다 업그리이드된 인터페이스를 제공할 수 있다. 5개의 손가락 정보는 적외선 카메라 데이터로 형 성될 수 있지만, 이에 한정되는 것은 아니다. 또한, 본 발명에서는 센서 데이터 융합(sensor data convergence) 방법을 통한 구체적인 서비스 model을 제안할 수 있다. 나아가 본 발명에서는 눈깜빡임, 하품 등을 통한 행동변 화를 측정할 수 있는 특징추출을 통하여 사용자의 몰입도 정량화가 가능하며, 이를 통해서 사용자의 행위인식 고도화 구현이 가능하다. 이상에서는 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법 및 장치에 대해 설명하였다. 이러한 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법 및 장치"}
{"patent_id": "10-2022-0031788", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "의 기술적 효과는 다음과 같이 요약될 수 있다. 본 발명의 실시예에 따르면, 컴퓨터 게임 등이 실행되는 장치에 있어서 별도의 입력 장치 없이도 사용자의 신체 부위, 특히 손 부위의 모션을 정확하게 감지할 수 있는 방법 및 장치를 제공할 수 있다. 또한, 본 발명의 실시예에 따르면, 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법 및 장치 를 제공할 수 있다. 또한, 본 발명의 실시예에 따르면, 게이머의 실시간 감정 정보를 활용한 맞춤형 서비스 제공이 가능하다. 본 발명의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 발명의 사 상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 발명의 바람직한 실시 예와 같은 특정 실시 예는 단지 예시로 주어진 것으로 이해되어야 한다. 상술한 본 발명의 특징 및 효과는 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해 질 것이며, 그에 따라 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도면에 예시하 고 상세한 설명에 구체적으로 설명하고자 한다. 그러나 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것 이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되 어야 한다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능뿐만 아니라 각각의 구성 요소들에 대한 설계 및 파라미터 최적화는 별도의 소프트웨어 모듈로도 구현될 수 있다. 적절한 프로그램 언어로 쓰여진 소프 트웨어 어플리케이션으로 소프트웨어 코드가 구현될 수 있다. 상기 소프트웨어 코드는 메모리에 저장되고, 제어 부(controller) 또는 프로세서(processor)에 의해 실행될 수 있다."}
{"patent_id": "10-2022-0031788", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 장치의 구성도이 다. 도 2a는 제1 게임 모드에서 사용자의 양 손을 인식하고 왼손 모드가 출력되는 화면 구성을 나타낸다. 도 2b는 제2 게임 모드에서 사용자의 양 손 중 한 손, 예컨대 왼손의 형태가 변경된 경우 출력되는 화면 구성을 나타낸다. 도 2c는 제3 게임 모드에서 사용자의 손가락 마디를 인식하여 게임 캐릭터를 제어하는 화면 구성을 나타낸다. 도 3은 본 발명에 따른 사용자 얼굴 인식에 따라 화면에 7가지 감정이 표시된 화면 구성을 나타낸다. 도 4는 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법에서 사용자 얼굴 특 정 부위, 눈과 입 검출과 이의 변화 정보를 이용하는 화면 구성을 나타낸다. 도 5는 본 발명에 따른 비전 기반 인공지능 인터페이스 방법에서 손가락 정보를 표현하는 개념도를 나타낸다. 도 6은 본 발명에 따른 사용자 감정 정보를 인식하는 비전 기반 인공지능 인터페이스 방법과 관련하여 손가락의 이동 및 회전 각도를 검출하기 위한 화면 구성을 나타낸다. 도 7은 본 발명에 따른 손가락의 특정 동작을 비전 인공지능 인터페이스 장치가 추출하고 추출된 정보를 화면에 표시하는 화면 UI를 나타낸다."}
