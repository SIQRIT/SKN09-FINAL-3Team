{"patent_id": "10-2025-7010078", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055594", "출원번호": "10-2025-7010078", "발명의 명칭": "통신 방법 및 장치", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "첸 지아슈안"}}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "통신 방법으로서, 인코더에 의해, 적어도 두 개의 인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축하여, N개의 압축된정보를 획득하는 단계 - 상기 N개의 압축된 정보 각각은 상기 적어도 두 개의 AI 모델 중 적어도 하나를 사용하여 상기 M개의 층의 채널 정보 중 일부 층의 채널 정보를 압축함으로써 획득되며, N 및 M은 1보다 큰 정수이고,N은 M보다 작음 - 와, 상기 인코더에 의해, 상기 N개의 압축된 정보를 디코더로 전송하는 단계를 포함하는, 통신 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 N개의 압축된 정보는 적어도 하나의 제1 압축된 정보와 적어도 하나의 제2 압축된 정보를 포함하며, 상기 제1 압축된 정보는 상기 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용하여 상기 M개의 층의 채널 정보중 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행하여 획득되고, 상기 제2 압축된 정보는 상기 적어도 두 개의 AI 모델 중 제2 AI 모델을 사용하여 상기 M개의 층의 채널 정보 중 한 개의 층의 채널 정보에 대해개별 압축을 수행하여 획득되는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 M개의 층의 채널 정보의 압축 방식은, 상기 인코더의 컴퓨팅 자원, 상기 디코더의 컴퓨팅 자원, 상기 인코더의 AI 모델, 상기 디코더의 AI 모델, 상기 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 공동 압축(joint compression)을 수행하는 성능, 상기 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 개별 압축(separate compression)을 수행하는 성능, 및 M의 값 중 적어도 하나에 기초하여 결정되고, 상기 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 상기 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 방법은, 상기 인코더에 의해, 상기 M개의 층의 채널 정보의 압축 방식을 결정하는 단계를 더 포함하되, 상기 M개의 층의채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 상기 M개의 층의 채널 정보의 압축 방식은 공동 압축및 개별 압축을 포함하는, 공개특허 10-2025-0055594-3-방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 방법은, 상기 인코더에 의해, 상기 M개의 층의 채널 정보의 압축 방식을 상기 디코더로 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 방법은, 상기 인코더에 의해, 상기 M개의 층의 채널 정보의 압축 방식을 수신하는 단계를 더 포함하되, 상기 M개의 층의채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 상기 M개의 층의 채널 정보의 압축 방식은 공동 압축및 개별 압축을 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서, 상기 방법은, 상기 인코더에 의해, 상기 디코더로부터 참조 신호를 수신하는 단계와, 상기 인코더에 의해, 상기 참조 신호에 기초하여 채널 측정을 수행하여, 상기 M개의 층의 채널 정보를 획득하는단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 방법은, 상기 인코더에 의해, 상기 채널 측정의 결과에 기초하여 상기 M의 값을 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 상기 인코더에 의해, 적어도 두 개의 인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축하는 것은, 상기 인코더에 의해, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 제1 AI 모델을 결정하는 것 - 상기 적어도 두 개의 AI 모델은 상기 제1 AI 모델을 포함하고, 상기 M개의 층은 상기 X개의 층을포함하며, X는 1보다 크고 M보다 작은 정수임 - 과, 공개특허 10-2025-0055594-4-상기 인코더에 의해, 상기 제1 AI 모델을 사용하여 상기 X개의 층의 채널 정보에 대해 공동 압축을 수행하여 제1 압축된 정보를 획득하는 것 - 상기 N개의 압축된 정보는 상기 제1 압축된 정보를 포함함 - 을 포함하고, 상기 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은, 동일한 층에서의 서로 다른 서브밴드의 채널 정보의 인접 배열 및 동일한 서브밴드 내의 서로 다른 층의 채널 정보의 인접 배열 중 어느 하나를포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 방법은, 상기 인코더에 의해, 상기 디코더로부터 상기 X개의 층의 각 층 및 이 층들 사이의 상기 채널 정보의 배열 방식을 수신하는 단계, 또는 상기 인코더에 의해, 상기 X개의 층의 각 층 및 이 층들 사이의 상기 채널 정보의 배열 방식을 상기 디코더로전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항에 있어서, 상기 방법은, 상기 인코더에 의해, 제1 정보를 상기 디코더로 전송하는 단계를 더 포함하되, 상기 제1 정보는 상기 M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 수행되는 공동 압축 동안의 서로 다른 층들의 채널 정보의 순서를 나타내는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제11항 중 어느 한 항에 있어서, 상기 인코더는 단말 디바이스이고, 상기 디코더는 네트워크 디바이스인, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제12항 중 어느 한 항에 있어서, 각각의 상기 N개의 압축된 정보에 대응하는 채널 정보는 중복되지 않는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "통신 방법으로서, 디코더에 의해, 인코더로부터 N개의 압축된 정보를 수신하는 단계 - 상기 N개의 압축된 정보는 적어도 두 개의공개특허 10-2025-0055594-5-인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축하여 획득되고, 각각의 상기 N개의 압축된 정보는상기 적어도 두 개의 AI 모델 중 적어도 하나를 사용하여 상기 M개의 층의 채널 정보 중 일부 층의 채널 정보를압축함으로써 획득되며, N 및 M은 1보다 큰 정수이고, N은 M보다 작음 - 와, 상기 디코더에 의해, 상기 N개의 압축된 정보를 디코딩하여 상기 M개의 층의 채널 정보를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 N개의 압축된 정보는 적어도 하나의 제1 압축된 정보와 적어도 하나의 제2 압축된 정보를 포함하며, 상기 제1 압축된 정보는 상기 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용하여 상기 M개의 층의 채널 정보중 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행하여 획득되고, 상기 제2 압축된 정보는 상기 적어도 두 개의 AI 모델 중 제2 AI 모델을 사용하여 상기 M개의 층의 채널 정보 중 한 개의 층의 채널 정보에 대해개별 압축을 수행하여 획득되는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항 또는 제15항에 있어서, 상기 M개의 층의 채널 정보의 압축 방식은, 상기 인코더의 컴퓨팅 자원, 상기 디코더의 컴퓨팅 자원, 상기 인코더의 AI 모델, 상기 디코더의 AI 모델, 상기 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 공동 압축을수행하는 성능, 상기 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 개별 압축을 수행하는 성능, 및 M의값 중 적어도 하나에 기초하여 결정되고, 상기 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 상기 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항 내지 제16항 중 어느 한 항에 있어서, 상기 디코더에 의해, 상기 N개의 압축된 정보를 디코딩하는 것은, 상기 디코더에 의해, 상기 M개의 층의 채널 정보의 압축 방식에 기초하여 상기 N개의 압축된 정보를 디코딩하는것을 포함하되, 상기 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 상기 M개의 층의 채널정보의 압축 방식은 공동 압축 및 개별 압축을 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항 내지 제17항 중 어느 한 항에 있어서, 상기 방법은, 상기 디코더에 의해, 상기 M개의 층의 채널 정보의 압축 방식을 결정하는 단계를 더 포함하는, 공개특허 10-2025-0055594-6-방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 방법은, 상기 디코더에 의해, 상기 M개의 층의 채널 정보의 압축 방식을 상기 인코더로 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항 내지 제19항 중 어느 한 항에 있어서, 상기 방법은, 상기 디코더에 의해, 상기 M개의 층의 채널 정보의 압축 방식을 상기 인코더로부터 수신하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제14항 내지 제20항 중 어느 한 항에 있어서, 상기 디코더에 의해, 상기 N개의 압축된 정보를 디코딩하여 상기 M개의 층의 채널 정보를 획득하는 단계는, 상기 디코더에 의해, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 상기 제1 압축된정보를 디코딩하여, 상기 X개의 층의 채널 정보를 획득하는 단계를 더 포함하되, 상기 제1 압축된 정보는 상기적어도 두 개의 AI 모델 중 상기 제1 AI 모델을 사용하여 상기 X개의 층의 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, 상기 N개의 압축된 정보는 상기 제1 압축된 정보를 포함하며, 상기 M개의 층은 X개의 층을포함하고, X는 1보다 크고 M보다 작은 정수인, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 방법은, 상기 디코더에 의해, 상기 X개의 층의 각 층 및 이 층들 사이의 상기 채널 정보의 배열 방식을 상기 인코더로전송하는 단계와, 상기 디코더에 의해, 상기 인코더로부터 상기 X개의 층의 각 층 및 이 층들 사이의 상기 채널 정보의 배열 방식을 수신하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제14항 내지 제22항 중 어느 한 항에 있어서, 상기 방법은, 공개특허 10-2025-0055594-7-상기 디코더에 의해, 상기 인코더로부터 제1 정보를 수신하는 단계를 더 포함하되, 상기 제1 정보는 상기 M개의층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 수행되는 공동 압축 동안의 서로 다른 층들의 채널정보의 순서를 나타내는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제14항 내지 제23항 중 어느 한 항에 있어서, 상기 인코더는 단말 디바이스이고, 상기 디코더는 네트워크 디바이스인, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제14항 내지 제24항 중 어느 한 항에 있어서, 각각의 상기 N개의 압축된 정보에 대응하는 채널 정보는 중복되지 않는, 방법."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "통신 장치로서, 제1항 내지 제25항 중 어느 한 항에 따른 방법을 수행하도록 구성된 모듈 또는 유닛을 포함하는, 통신 장치."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "통신 장치로서, 프로세서를 포함하며, 상기 프로세서는 메모리에 저장된 컴퓨터 프로그램 또는 명령어를 실행하여 상기 장치로하여금 제1항 내지 제25항 중 어느 한 항에 따른 방법을 수행하게 하도록 구성되는, 통신 장치."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 상기 통신 장치는 상기 메모리 및/또는 통신 인터페이스를 더 포함하고, 상기 통신 인터페이스는 상기 프로세서에 결합되며, 상기 통신 인터페이스는 정보를 입력 및/또는 출력하도록 구성되는, 통신 장치."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "프로세서로서, 제1항 내지 제25항 중 어느 한 항에 따른 방법을 수행하도록 구성된, 공개특허 10-2025-0055594-8-프로세서."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "컴퓨터 판독가능한 저장 매체로서, 상기 컴퓨터 판독가능한 저장 매체는 컴퓨터 프로그램 또는 명령어를 저장하며, 상기 컴퓨터 프로그램 또는 상기 명령어가 통신 장치에서 실행되는 경우, 상기 통신 장치가 제1항 내지 제25항 중 어느 한 항에 따른 방법을수행할 수 있게 되는, 컴퓨터 판독가능한 저장 매체."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램 제품은 제1항 내지 제25항 중 어느 한 항에 따른 방법을 수행하는 데 사용되는 컴퓨터 프로그램 또는 명령어를 포함하는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "칩으로서, 상기 칩은 메모리에 결합되며, 상기 메모리에 저장된 프로그램 명령어를 판독하고 실행하여, 제1항 내지 제25항중 어느 한 항에 따른 방법을 구현하도록 구성된, 칩."}
{"patent_id": "10-2025-7010078", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "통신 시스템으로서, 인코딩 장치 및 디코딩 장치를 포함하되, 상기 인코딩 장치는 제1항 내지 제13항 중 어느 한 항에 따른 방법을수행하도록 구성되고, 상기 디코딩 장치는 제14항 내지 제25항 중 어느 한 항에 따른 방법을 수행하도록구성된, 통신 시스템."}
{"patent_id": "10-2025-7010078", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원의 실시예들은 통신 방법 및 장치를 제공한다. 이 방법은 인코더가 적어도 두 개의 인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축하여, N개의 압축된 정보를 획득하는 것을 포함하며, 여기서 N개의 압축된 정보 각각은 M개의 층의 채널 정보 중 일부 층의 채널 정보를 압축함으로써 획득되고, N 및 M은 1보다 큰 정수이 (뒷면에 계속)"}
{"patent_id": "10-2025-7010078", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2022년 8월 29일 중국특허청에 출원된, 발명의 명칭이 \"통신 방법 및 장치(COMMUNICATION METHOD AND APPARATUS)\"인 중국 특허출원번호 202211038332.X호를 우선권 주장하며, 그 전체가 참조로 본 명세서에 포 함된다."}
{"patent_id": "10-2025-7010078", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "기술분야 본 출원은 통신 기술 분야, 보다 구체적으로는 통신 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2025-7010078", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "네트워크 디바이스가 복수의 데이터 스트림을 단말 디바이스에 병렬로 전송할 수 있도록 지원하려면, 네트워크 디바이스는 단말 디바이스에 의해 피드백되는 채널 정보(예컨대, 채널 상태 정보(CSI))에 기초하여 복수의 스트림에 대한 사전 코딩 매트릭스를 결정해야 한다. 스트림의 수를 랭크(rank) 수 또는 층(layer) 수라고도 한다. 채널 정보 피드백의 오버헤드는 스트림의 수에 따라 증가한다. 본 출원은 채널 정보 피드백으로 인한 오버헤드를 줄이기 위한 통신 방법 및 장치를 제공한다. 제1 양태에 따르면, 통신 방법이 제공된다. 이 방법은 인코더에 의해 수행되거나 또는 인코더에 사용되는 칩 또는 회로에 의해 수행될 수 있다. 이는 본 출원에서 제한되지 않는다. 설명을 쉽게 하기 위해, 이하에서는 방법이 인코더에 의해 수행되는 예를 사용하여 설명한다. 방법은, 인코더가 적어도 두 개의 인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축하여, N개의 압축 된 정보를 획득하는 것을 포함하는데, 여기서, N개의 압축된 정보 각각은 적어도 두 개의 AI 모델 중 적어도 하 나를 사용하여 M개의 층의 채널 정보에서 일부 층의 채널 정보를 압축함으로써 획득되며, N과 M은 1보다 큰 정 수이고, N은 M보다 작다. 인코더는 N개의 압축된 정보를 디코더로 전송한다. 전술한 기술 솔루션에 기초하여, 인코더는 적어도 두 개의 AI 모델을 사용하여 M개의 층의 채널 정보를 압축하 여 N개의 압축된 정보를 획득하고, N개의 압축된 정보를 디코더로 전송하며, 이에 따라 디코더는 N개의 압축된 정보에 기초하여 디코딩을 수행하여 M개의 층의 채널 정보를 복원할 수 있다. 이런 방식으로, 복수의 층의 채 널 정보가 AI 네트워크를 사용하여 피드백될 수 있다. 기존의 방식에 비해, 이 방식은 채널 정보를 피드백함으 로써 발생하는 오버헤드를 줄일 수 있다. 또한, M개의 층의 채널 정보에 기초하여 N개의 압축된 정보가 획득되 며, N은 M보다 작다. 즉, M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 공동 압축(joint compression)이 수행된다. M개의 층의 각 층의 채널 정보에 대한 개별 압축과 비교하여, 이는 층들 사이의 서 로 다른 채널 정보 사이의 관계를 이용하여 피드백 오버헤드를 더욱 줄일 수 있다. 또한, N은 1보다 더 크다. 한 번에 M개의 층의 채널 정보에 대해 공동 압축하는 것에 비해, 이는 계산 복잡도를 줄일 수 있다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, N개의 압축된 정보는 적어도 하나의 제1 압축된 정보와 적 어도 하나의 제2 압축된 정보를 포함한다. 제1 압축된 정보는 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용 하여 M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, 제2 압축된 정보는 적어도 두 개의 AI 모델 중 제2 AI 모델을 사용하여 M개의 층의 채널 정보 중 한 개의 층의 채널 정보에 대해 개별 압축을 수행함으로써 획득된다. 전술한 기술 솔루션에 기초하여, M개의 층의 채널 정보의 압축 방식은 개별 압축 및 공동 압축을 포함한다. 이 런 방식으로, M개의 층의 채널 정보에 대한 개별 압축으로 인한 오버헤드뿐만 아니라, M개의 층의 채널 정보에 대한 한 번의 공동 압축으로 인한 계산 복잡도도 감소될 수 있다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, M개의 층의 채널 정보의 압축 방식은 다음 정보들, 즉, 인 코더의 컴퓨팅 자원, 디코더의 컴퓨팅 자원, 인코더의 AI 모델, 디코더의 AI 모델, M개의 층의 채널 정보 중 일 부 층의 채널 정보에 대한 공동 압축 수행의 성능, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 개별 압축 수행의 성능 및 M의 값 중 적어도 하나에 기초하여 결정된다. M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 개별 압축은 한 층의 채널 정보에 대해 개별 압축이 수행되었음을 나타낸다. 예를 들어, 한 층의 채널 정보는 AI 모델에 독립적으로 입력되어 하나의 압축된 정보를 획득한다. 공동 압축은 적어도 두 층의 채널 정보에 대해 공동 압축이 수행되었음을 나타낸다. 예를 들어, 적어도 두 개 의 층의 채널 정보가 AI 모델에 입력되어 하나의 압축된 정보를 획득한다. 일례에서, M개의 층의 채널 정보의 압축 방식은 인코더의 컴퓨팅 자원에 기초하여 결정된다. 예를 들어, 인코 더의 컴퓨팅 자원이 크다면, 예를 들어, 인코더가 채널 정보를 압축하는 데 사용되는 가용 컴퓨팅 파워가 사전 설정된 값보다 크거나 같으면, M개의 층의 채널 정보 압축 방식은 공동 압축을 포함할 수 있다. 또 다른 예에 서, 인코더가 채널 정보를 압축하는 데 사용하는 가용 컴퓨팅 파워가 사전 설정된 값보다 작으면, 각 층의 채널 정보에 대해 개별 압축이 수행될 수 있다. 또 다른 예에서, M개의 층의 채널 정보 압축 방식은 디코더의 컴퓨팅 자원에 기초하여 결정된다. 예를 들어, 디코더의 컴퓨팅 자원이 크다면, 예를 들어, 채널 정보를 압축하기 위해 디코더가 사용하는 가용 컴퓨팅 파워가 사전 설정된 값보다 크거나 같으면, M개의 층의 채널 정보 압축 방식은 공동 압축을 포함할 수 있다.또 다른 예에서, M개의 층의 채널 정보의 압축 방식은 인코더의 AI 모델에 기초하여 결정된다. 예를 들어, 인 코더의 AI 모델이 공동 압축에 적용 가능한 경우(예컨대, 개별 압축에 적용 가능한 AI 모델이 업데이트되는 경 우), M개의 층의 채널 정보의 압축 방식은 공동 압축일 수 있다. 인코더의 AI 모델이 개별 압축에 적용될 수 있는 경우(예컨대, 공동 압축에 적용되는 AI 모델이 업데이트되는 경우), M개의 층의 채널 정보의 압축 방식은 개별 압축일 수 있다. 또 다른 예에서, M개의 층의 채널 정보의 압축 방식은 디코더의 AI 모델에 기초하여 결정된다. 예를 들어, 디 코더의 AI 모델이 공동 압축의 디코딩에 적용될 수 있는 경우, M개의 층의 채널 정보의 압축 방식은 공동 압축 을 포함할 수 있다. 디코더의 AI 모델이 개별 압축의 디코딩에 적용될 수 있는 경우, M개의 층의 채널 정보의 압축 방식은 개별 압축을 포함할 수 있다. 또 다른 예에서, M개의 층의 채널 정보의 압축 방식은 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 공 동 압축을 수행하는 성능에 기초하여 결정된다. 예를 들어, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 공동 압축을 수행하는 성능이 사전 설정된 값보다 크거나 같으면, M개의 층의 채널 정보의 압축 방식은 공 동 압축을 포함할 수 있다. 또 다른 예에서, M개의 층의 채널 정보의 압축 방식은 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 개 별 압축을 수행하는 성능에 기초하여 결정된다. 예를 들어, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 개별 압축을 수행하는 성능이 사전 설정된 값보다 크거나 같으면, M개의 층의 채널 정보의 압축 방식은 개 별 압축을 포함할 수 있다. 또 다른 예에서, M개의 층의 채널 정보의 압축 방식은 M의 값에 기초하여 결정된다. 예를 들어 M이 1보다 크면, M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함한다. 또 다른 예에서, M이 1보다 크고 제1 사전 설정 값보다 작거나 같으면, M개의 층의 채널 정보의 압축 방식은 개별 압축이고, 또는 M이 제1 사전 설정 값보 다 크면, M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함한다. 전술한 예들 중 하나 이상은 M개의 층의 채널 정보의 압축 방식을 결정하기 위해 조합하여 사용될 수 있는데, 예를 들면, 압축 방식은 컴퓨팅 자원 및 인코더의 AI 모델에 기초하여 결정된다. 채널 정보를 압축하기 위해 디코더에 의해 사용되는 가용 컴퓨팅 파워가 사전 설정된 값보다 크거나 같고, 인코더의 AI 모델이 공동 압축에 적용될 수 있는 경우, M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함할 수 있다. 전술한 기술 솔루션에 기초하여, M개의 층의 채널 정보의 압축 방식은 전술한 하나 이상의 정보에 기초하여 결 정될 수 있다. 이런 방식으로, 실제 통신 상태, 예컨대, 인코더 및/또는 디코더의 일부 정보, 층의 수(M), 또 는 개별 압축 또는 공동 압축의 성능에 기초하여 적절한 압축 방식이 동적으로 선택될 수 있다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 방법은 인코더가 M개의 층의 채널 정보의 압축 방식을 결정 하는 것을 더 포함하며, 여기서 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나 또는 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 전술한 기술 솔루션에 기초하여, 인코더는 M개의 층의 채널 정보의 압축 방식을 결정할 수 있고, 인코더에 의해 결정된 M개의 층의 채널 정보의 압축 방식에 기초하여 M개의 층의 채널 정보를 추가로 압축하여, N개의 압축된 정보를 획득할 수 있다. 이런 방식으로, 인코더는 실제 통신 상태에 기초하여 적절한 압축 방식을 동적으로 선 택할 수 있으며, 그 방식은 유연하다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 방법은 인코더가 M개의 층의 채널 정보의 압축 방식을 디코 더로 보내는 것을 더 포함한다. 전술한 기술 솔루션에 기초하여, 인코더는 M개의 층의 채널 정보의 압축 방식을 디코더로 보낼 수 있다. 이런 방식으로, 디코더는 M개의 층의 채널 정보의 압축 방식 및 수신된 N개의 압축된 정보에 기초하여 디코딩을 통해 M개의 층의 채널 정보를 획득한다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 방법은 인코더가 M개의 층의 채널 정보의 압축 방식을 수신 하는 것을 더 포함하며, 여기서 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나 또는 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 전술한 기술 솔루션에 기초하여, 디코더는 M개의 층의 채널 정보의 압축 방식을 결정하고 압축 방식을 디코더로 보낼 수 있다. 이런 방식으로, 디코더는 실제 통신 상태에 기초하여 적절한 압축 방식을 동적으로 선택할 수있으며, 인코더에 의해 압축 방식을 결정함으로써 발생된 오버헤드가 감소될 수 있다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 방법은 인코더가 디코더로부터 참조 신호를 수신하고, 인코 더가 참조 신호에 기초하여 채널 측정을 수행하여, M개의 층의 채널 정보를 획득하는 것을 더 포함한다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 방법은 채널 측정의 결과에 기초하여 인코더가 M의 값을 결 정하는 것을 더 포함한다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 인코더가 적어도 두 개의 인공 지능(AI) 모델을 사용하여 M 개의 층의 채널 정보를 압축하는 것은, 인코더가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 제1 AI 모델을 결정하는 것을 포함하고, 여기서, 적어도 두 개의 AI 모델은 제1 AI 모델을 포함하고, M개의 층은 X개의 층을 포함하며, X는 1보다 크고 M보다 작은 정수이다. 인코더는 제1 AI 모델을 사용하여 X개 의 층의 채널 정보에 대해 공동 압축을 수행하여 제1 압축된 정보를 획득하며, 여기서 N개의 압축된 정보는 제1 압축된 정보를 포함한다. 예를 들어, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은, 동일한 층에서의 서로 다른 서브밴 드의 채널 정보의 인접 배열 및 동일한 서브밴드 내의 서로 다른 층의 채널 정보의 인접 배열 중 어느 하나를 포함한다. 예를 들어, 인코더가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 제1 AI 모델을 결 정하는 것은 인코더가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여, 공동 압축 방식 으로 채널 정보를 피드백하는 것의 정확도를 계산하고, 또한 공동 압축에 사용되는 AI 모델, 즉 제1 AI 모델을 결정하는 것을 포함한다. 전술한 기술 솔루션에 기초하여, 인코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초 하여 X개의 층의 채널 정보에 대해 공동 압축을 수행할 수 있다. 디코더는 X개의 층의 채널 정보를 압축하여 획득된 압축된 정보에 기초하여 디코딩을 수행하고, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방 식에 기초하여 디코더의 출력을 정확하게 파싱하여, X개의 층의 채널 정보를 획득할 수 있다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 방법은 인코더가 디코더로부터 X개의 층의 각 층 및 이 층 들 사이의 채널 정보의 배열 방식을 수신하거나, 또는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 디코더로 전송하는 것을 더 포함한다. 예를 들어, 인덱스 값과 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식 사이에는 대응 관계가 있 다. 예를 들어, 인코더는 디코더로부터 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 수신한 다. 가능한 구현예에서, 인코더는 디코더로부터 인덱스 값을 수신하고, 인덱스 값은 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 나타낸다. 즉, 인코더는 인덱스 값과 X개의 층의 각 층 및 이 층들 사이 의 채널 정보의 배열 방식 사이의 대응 관계에 기초하여 인덱스 값에 대응하는 배열 방식을 결정할 수 있다. 전술한 기술 솔루션에 기초하여, 디코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정 하고, 배열 방식을 인코더로 보낼 수 있다. 이런 방식으로, 인코더는 디코더에 의해 표시된 배열 방식에 기초 하여 인코딩을 수행할 수 있으며, 이에 따라 디코더는 디코딩된 정보를 정확하게 파싱할 수 있다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 방법은 인코더가 M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행하는 동안 서로 다른 층의 채널 정보의 순서를 나타내는 제1 정보를 디 코더로 전송하는 것을 더 포함한다. 예를 들어, 인덱스 값과 서로 다른 층의 채널 정보의 순서 사이에 대응 관계가 있다. 가능한 구현예에서, 제1 정보는 인덱스 값이고, 인덱스 값은 서로 다른 층의 채널 정보의 순서를 나타낸다. 즉, 디코더는 인덱스 값 및 인덱스 값과 서로 다른 층의 채널 정보의 순서 사이의 대응 관계에 기초하여, 인덱스 값에 대응하는, 서로 다른 층의 채널 정보의 순서를 결정할 수 있다. 전술한 기술 솔루션에 기초하여, 인코더는 공동 압축 동안 채널 정보 시퀀스에 기초하여 공동 압축된 채널 정보 를 압축할 수 있으며, 디코더는 공동 압축 동안 채널 정보 시퀀스에 기초하여 디코더의 출력을 정확하게 파싱할 수 있다. 제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 인코더는 단말 디바이스이고, 디코더는 네트워크 디바이스 이다.제1 양태와 관련하여, 제1 양태의 일부 구현예에서, 각각의 N개의 압축된 정보에 대응하는 채널 정보는 중복되 지 않는다. 제2 양태에 따르면, 통신 방법이 제공된다. 이 방법은 디코더에 의해 수행되거나 또는 디코더에 사용되는 칩 또는 회로에 의해 수행될 수 있다. 이는 본 출원에서 제한되지 않는다. 설명을 쉽게 하기 위해, 이하에서는 설명을 위해 방법이 디코더에 의해 수행되는 예를 사용한다. 이 방법은, 디코더가 인코더로부터 N개의 압축된 정보를 수신하는 것을 포함할 수 있으며, 여기서 N개의 압축된 정보는 적어도 두 개의 인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축함으로써 획득되고, 각 N개 의 압축된 정보는 적어도 두 개의 AI 모델 중 적어도 하나를 사용하여 M개의 층의 채널 정보 중 일부 층의 채널 정보를 압축함으로써 획득되며, N과 M은 1보다 큰 정수이고, N은 M보다 작다. 디코더는 N개의 압축된 정보를 디코딩하여 M개의 층의 채널 정보를 획득한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, N개의 압축된 정보는 적어도 하나의 제1 압축된 정보와 적 어도 하나의 제2 압축된 정보를 포함한다. 제1 압축된 정보는 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용 하여 M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, 제2 압축된 정보는 적어도 두 개의 AI 모델 중 제2 AI 모델을 사용하여 M개의 층의 채널 정보 중 한 개의 층의 채널 정보에 대해 개별 압축을 수행함으로써 획득된다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, M개의 층의 채널 정보의 압축 방식은 다음 정보들, 즉, 인 코더의 컴퓨팅 자원, 디코더의 컴퓨팅 자원, 인코더의 AI 모델, 디코더의 AI 모델, M개의 층의 채널 정보 중 일 부 층의 채널 정보에 대한 공동 압축 수행의 성능, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 개별 압축 수행의 성능 및 M의 값 중 적어도 하나에 기초하여 결정된다. M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 디코더가 N개의 압축된 정보를 디코딩하는 것은, 디코더가 M개의 층의 채널 정보의 압축 방식에 기초하여 N개의 압축된 정보를 디코딩하는 것을 포함하며, 여기서 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나 또는 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 방법은 디코더가 M개의 층의 채널 정보의 압축 방식을 결정 하는 것을 더 포함한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 방법은 디코더가 M개의 층의 채널 정보의 압축 방식을 인코 더로 보내는 것을 더 포함한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 방법은 디코더가 M개의 층의 채널 정보의 압축 방식을 인코 더로부터 수신하는 것을 더 포함한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 디코더가 N개의 압축된 정보를 디코딩하여 M개의 층의 채널 정보를 획득하는 것은, 디코더가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 제1 압축된 정보를 디코딩하여, X개의 층의 채널 정보를 획득하는 것을 더 포함하되, 여기서 제1 압축된 정보는 적 어도 두 개의 AI 모델 중 상기 제1 AI 모델을 사용하여 X개의 층의 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, N개의 압축된 정보는 제1 압축된 정보를 포함하며, M개의 층은 X개의 층을 포함하고, X는 1보다 크고 M보다 작은 정수이다. 예를 들어, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은, 동일한 층에서의 서로 다른 서브밴 드의 채널 정보의 인접 배열 및 동일한 서브밴드 내의 서로 다른 층의 채널 정보의 인접 배열 중 어느 하나를 포함한다. 전술한 기술 솔루션에 기초하여, 디코더는 제1 압축된 정보를 AI 모델에 디코딩하고, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 출력을 파싱하여, X개의 층의 채널 정보를 획득할 수 있다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 방법은 디코더가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 인코더로 전송하거나, 또는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 인코더로부터 수신하는 것을 더 포함한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 방법은 디코더가 M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행하는 동안 서로 다른 층의 채널 정보의 순서를 나타내는 제1 정보를 인 코더로부터 수신하는 것을 더 포함한다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 인코더는 단말 디바이스이고, 디코더는 네트워크 디바이스 이다. 제2 양태와 관련하여, 제2 양태의 일부 구현예에서, 각각의 N개의 압축된 정보에 대응하는 채널 정보는 중복되 지 않는다. 제2 양태 및 가능한 설계의 유익한 효과에 대해서는, 제1 양태의 관련 설명을 참조한다. 세부 사항은 본 명세 서에서 반복하지 않는다. 제3 양태에 따르면, 통신 장치가 제공된다. 이 장치는 제1 양태 내지 제2 양태 중 어느 하나에서 제공된 방법 을 수행하도록 구성된다. 구체적으로, 이 장치는 제1 양태 또는 제2 양태의 전술한 구현예들 중 어느 하나에서 제공된 방법을 수행하도록 구성된 유닛 및/또는 모듈, 예를 들면 처리 유닛 및/또는 통신 유닛을 포함할 수 있 다. 구현예에서, 장치는 통신 디바이스(예컨대, 인코더 또는 디코더)이다. 장치가 통신 디바이스인 경우, 통신 유 닛은 트랜시버 또는 입력/출력 인터페이스일 수 있고, 처리 유닛은 적어도 하나의 프로세서일 수 있다. 선택적 으로, 트랜시버는 트랜시버 회로일 수 있다. 선택적으로, 입력/출력 인터페이스는 입력/출력 회로일 수 있다. 다른 구현예에서, 장치는 칩, 칩 시스템 또는 통신 디바이스에 사용되는 회로이다. 장치가 칩, 칩 시스템, 또 는 단말 디바이스에 사용되는 회로인 경우, 통신 유닛은 칩, 칩 시스템, 또는 회로 상의 입력/출력 인터페이스, 인터페이스 회로, 출력 회로, 입력 회로, 핀, 관련 회로 등일 수 있고, 처리 유닛은 적어도 하나의 프로세서, 처리 회로, 논리 회로 등일 수 있다. 제4 양태에 따르면, 통신 장치가 제공된다. 장치는 프로그램을 저장하도록 구성된 메모리와, 메모리에 저장된 컴퓨터 프로그램 또는 명령어를 실행하여 제1 양태 또는 제2 양태의 전술한 구현예들 중 어느 하나에서 제공된 방법을 수행하도록 구성된 적어도 하나의 프로세서를 포함한다. 구현예에서, 장치는 통신 디바이스(예컨대, 인코더 또는 디코더)이다. 다른 구현예에서, 장치는 칩, 칩 시스템 또는 통신 디바이스에 사용되는 회로이다. 제5 양태에 따르면, 본 출원은 전술한 양태들에서 제공된 방법을 수행하도록 구성된 프로세서를 제공한다. 프로세서와 관련된 전송 및 획득/수신과 같은 동작들은, 달리 특정되거나 또는 동작들이 실제 동작 또는 관련 설명에서의 동작의 내부 로직에 반하지 않는 한, 프로세서의 출력 및 입력과 같은 동작, 또는 무선 주파수 회로 및 안테나에 의해 수행되는 전송 및 수신과 같은 동작으로 이해될 수 있다. 이는 본 출원에서 제한되지 않는다. 제 6 양태에 따르면, 컴퓨터 판독 가능 저장 매체가 제공된다. 컴퓨터 판독 가능 저장 매체는 디바이스에 의해 실행되는 프로그램 코드를 저장하고, 크로그램 코드는 제1 양태 또는 제2 양태의 구현예들 중 어느 하나에서 제 공된 방법을 수행하는 데 사용된다. 제7 양태에 따르면, 명령어를 포함하는 컴퓨터 프로그램 제품이 제공된다. 컴퓨터 프로그램 제품이 컴퓨터에서 실행될 경우, 컴퓨터는 제1 양태 또는 제2 양태의 구현예들 중 어느 하나에서 제공된 방법을 수행할 수 있게 된 다. 제8 양태에 따르면, 칩이 제공된다. 칩은 프로세서 및 통신 인터페이스를 포함한다. 프로세서는 통신 인터페 이스를 사용하여 메모리에 저장된 명령어를 실행하여 제1 양태 또는 제2 양태의 전술한 구현예들 중 어느 하나 에서 제공된 방법을 수행한다. 선택적으로, 한 구현예에서, 칩은 메모리를 더 포함하고, 메모리는 컴퓨터 프로그램 또는 명령어를 저장하며, 프로세서는 메모리에 저장된 컴퓨터 프로그램 또는 명령어를 실행하도록 구성된다. 컴퓨터 프로그램 또는 명령 어가 실행되는 경우, 프로세서는 제1 양태 또는 제2 양태의 구현예들 중 어느 하나에서 제공된 방법을 수행하도 록 구성된다. 제9 양태에 따르면, 인코더 및 디코더를 포함하는 통신 시스템이 제공된다. 본 출원에서, 인코더는 인코딩 장치로 지칭될 수도 있고, 인코딩 외의 다른 기능을 가질 수도 있다. 디코더는 디코딩 장치로 지칭될 수도 있고, 디코딩 외의 다른 기능을 가질 수도 있다."}
{"patent_id": "10-2025-7010078", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음은 첨부 도면을 참조하여 본 출원의 실시예에서의 기술 솔루션을 설명한다. 본 출원에서 제공하는 기술 솔루션은 5세대(5th generation, 5G) 시스템, 뉴라디오(new radio, NR) 시스템, 롱 텀 에볼루션(long term evolution, LTE) 시스템, LTE 주파수 분할 듀플렉스(frequency division duplex, FDD) 시스템, LTE 시분할 듀플렉스(time division duplex, TDD) 시스템과 같은 다양한 통신 시스템에 적용될 수 있다. 본 출원에 제공된 기술적 솔루션은 또한 미래의 통신 시스템(예컨대, 6세대 이동통신 시스템)에 적용될 수 있다. 본 출원에 제공된 기술적 솔루션은 또한 디바이스간(device-to-device, D2D) 통신, 차량-만물 (vehicle-to-everything, V2X) 통신, 기계 간(machine-to-machine, M2M) 통신, 기계 유형 통신(machine type communication, MTC), 사물 인터넷(internet of thing, IoT) 통신 시스템 또는 다른 통신 시스템에 적용될 수 있다. 본 출원의 실시예서 단말 디바이스는 무선 통신 기능을 갖는 다양한 디바이스를 포함하며, 사람, 사물, 기계 등 에 연결되도록 구성될 수 있다. 단말 디바이스는 다양한 시나리오, 예를 들어, 셀룰러 통신, D2D, V2X, 피어 투 피어(peer to peer, P2P), M2M, MTC, IoT, 가상 현실(virtual reality, VR), 증강 현실(augmented reality, AR), 산업 제어, 자율 주행, 원격 의료, 스마트 그리드, 스마트 가구, 스마트 오피스, 스마트 웨어러블, 스마트 교통, 스마트 시티 드론, 로봇, 원격 감지, 수동 감지, 포지셔닝, 내비게이션 및 추적, 자율 배송에서 널리 사 용될 수 있다. 단말 디바이스는 전술한 시나리오 중 어느 하나에서의 단말기, 예컨대 MTC 단말기 또는 IoT 단 말기일 수 있다. 단말 디바이스는 3세대 파트너십 프로젝트(3rd generation partnership project, 3GPP) 표준 의 사용자 장비(user equipment, UE), 단말(terminal), 고정 디바이스, 이동국(mobile station) 디바이스 또는 모바일 디바이스, 가입자 유닛(subscriber unit), 휴대용 디바이스, 차량 탑재 디바이스, 웨어러블 디바이스, 휴대전화(cellular phone), 스마트폰(smartphone), SIP 전화기, 무선 데이터 카드, 개인용 디지털 비서 (personal digital assistant, PDA), 컴퓨터, 태블릿 컴퓨터, 노트북 컴퓨터, 무선 모뎀, 핸드셋(handset), 랩 톱 컴퓨터(laptop computer), 무선 트랜시버 기능을 갖춘 컴퓨터, 스마트북, 차량, 위성, 글로벌 포지셔닝 시스 템(global positioning system, GPS) 디바이스, 목표 추적 디바이스, 비행 디바이스(예컨대, 무인 항공기, 헬 리콥터, 멀티-헬리콥터, 4-헬리콥터, 비행기), 선박, 원격 제어 디바이스, 스마트 홈 디바이스, 산업용 디바이 스일 수도 있고, 전술한 디바이스에 내장된 장치(예컨대, 전술한 디바이스의 통신 모듈, 모뎀 또는 칩)일 수도 있고, 또는 무선 모뎀에 연결된 다른 처리 디바이스일 수도 있다. 설명을 쉽게 하기 위해, 다음 설명에서는 단 말기 또는 UE를 단말기 장치의 예로 사용한다.일부 시나리오에서는 UE가 기지국 역할을 할 수도 있다는 점을 이해해야 한다. 예를 들어, UE는 V2X, D2D 또는 P2P와 같은 시나리오에서 UE들 사이에 사이드링크 신호를 제공하는 스케줄링 엔티티 역할을 할 수 있다. 본 출원의 실시예에서, 단말 디바이스의 기능을 구현하도록 구성된 장치는 단말 디바이스일 수도 있고, 또는 단 말 디바이스가 그 기능을 구현하도록 지원할 수 있는 장치, 예컨대, 칩 시스템 또는 칩일 수도 있으며, 여기서 장치는 단말 디바이스에 설치될 수 있다. 본 출원의 실시예에서, 칩 시스템은 칩을 포함할 수도 있고, 칩 및 다른 개별 구성 요소를 포함할 수도 있다. 본 출원의 실시예에서 네트워크 디바이스는 단말 디바이스와 통신하도록 구성된 디바이스일 수 있다. 네트워크 디바이스는 액세스 네트워크 디바이스 또는 무선 액세스 네트워크 디바이스라고도 할 수 있다. 예를 들어, 네 트워크 디바이스는 기지국일 수 있다. 본 출원의 실시예에서 네트워크 디바이스는 단말 디바이스를 무선 네트 워크에 연결하는 무선 액세스 네트워크(무선 액세스 네트워크, RAN) 노드(또는 디바이스)일 수 있다. 기지국은 넓은 의미에서 다음의 다양한 명칭을 포함할 수 있으며, 또는 다음 명칭들, 예를 들어 NodeB(NodeB), 발전된 NodeB(evolved NodeB, eNB), 차세대 NodeB(next-generation NodeB, gNB), 중계국, 액세스 포인트, 송수신 지점 (transmission point, TRP), 송신 지점(transmission point, TP), 1차 스테이션, 2차 스테이션, 모터 슬라이드 리테이너(motor slide retainer, MSR) 노드, 홈베이스 스테이션, 네트워크 컨트롤러, 액세스 노드, 무선 노드, 액세스 포인트(AP), 전송 노드, 트랜시버 노드, 베이스밴드 유닛(BBU), 원격 무선 유닛(remote radio unit, RRU), 액티브 안테나 유닛(active antenna unit, AAU), 원격 무선 헤드(remote radio head, RRH), 중앙 유닛 (central unit, CU), 분산 유닛(distributed unit, DU), 포지셔닝 노드 등으로 대체될 수 있다. 기지국은 매 크로 기지국, 마이크로 기지국, 중계 노드, 도너 노드 등 또는 이들의 조합일 수 있다. 또는, 기지국은 전술한 디바이스 또는 장치에 배치된 통신 모듈, 모뎀 또는 칩일 수도 있다. 또는, 기지국은 모바일 스위칭 센터, D2D, V2X, 및 M2M 통신에서 기지국 기능을 구현하는 디바이스, 6G 네트워크에서의 네트워크 측 디바이스, 미래 의 통신 시스템에서 기지국 기능을 구현하는 디바이스 등일 수도 있다. 기지국은 동일한 액세스 기술 또는 서 로 다른 액세스 기술을 지원하는 네트워크를 지원할 수 있다. 네트워크 디바이스에 사용되는 특정 기술 및 특 정 디바이스 형태는 본 출원의 실시예에 한정되지 않는다. 기지국은 고정형 또는 이동형일 수 있다. 예를 들어, 헬리콥터 또는 무인 항공기를 이동형 기지국으로 구성할 수 있으며, 하나 이상의 셀이 이동형 기지국의 위치에 기초하여 이동할 수 있다. 다른 예에서, 헬리콥터 또는 무인 항공기는 다른 기지국과 통신하기 위한 디바이스로 구성될 수 있다. 본 출원의 실시예에서, 네트워크 디바이스의 기능을 구현하도록 구성된 장치는 단말 디바이스일 수도 있고, 또 는 네트워크 디바이스가 기능을 구현하도록 지원할 수 있는 장치, 예컨대, 칩 시스템 또는 칩일 수도 있으며, 여기서 장치는 네트워크 디바이스에 설치될 수 있다. 본 출원의 실시예에서, 칩 시스템은 칩을 포함할 수도 있 고, 칩 및 다른 개별 구성 요소를 포함할 수도 있다. 네트워크 디바이스와 단말 디바이스는 실내 또는 실외, 휴대용 또는 차량 탑재 시나리오를 포함하여 지상에 배 치될 수도 있고, 수면에 배치될 수도 있으며, 공중의 비행기, 풍선, 위성에 배치될 수도 있다. 네트워크 디바 이스와 단말 디바이스가 배치되는 시나리오는 본 출원의 실시예에 한정되지 않는다. 먼저, 본 출원의 실시예에 적용 가능한 네트워크 아키텍처를 이하에서 간략하게 설명한다. 도 1은 본 출원의 실시예에 적용할 수 있는 무선 통신 시스템의 도면이다. 도 1에 도시된 바와 같이, 무 선 통신 시스템은 도 1에 도시된 네트워크 디바이스와 같은 적어도 하나의 네트워크 디바이스를 포함 할 수 있다. 무선 통신 시스템은 도 1에 도시된 단말 디바이스와 단말 디바이스와 같은 적어도 하나의 단말 디바이스를 추가로 포함할 수 있다. 네트워크 디바이스와 단말 디바이스 모두에 대해 복수의 안테 나가 구성될 수 있으며, 네트워크 디바이스와 단말 디바이스는 다중 안테나 기술을 사용하여 서로 통신할 수 있 다. 단말 디바이스들 또한 서로 통신할 수 있다. 예를 들어, 단말 디바이스들은 서로 직접 통신할 수 있다. 또 다른 예에서, 단말 디바이스들은 다른 통신 장치, 예컨대, 네트워크 디바이스 또는 다른 단말 디바이스를 사 용하여 서로 통신할 수 있다. 네트워크 디바이스가 단말 디바이스와 통신할 때, 네트워크 디바이스는 하나 이상의 셀을 관리할 수 있으며, 하 나의 셀은 정수개의 단말 디바이스를 가질 수 있다. 선택적으로, 네트워크 디바이스와 단말 디바이스 는 단일 셀 통신 시스템을 형성한다. 일반성을 잃지 않고, 셀을 셀 #1이라고 한다. 네트워크 디바이스 는 셀 #1에 있는 네트워크 디바이스일 수도 있고, 셀 #1에 있는 단말 디바이스(예컨대, 단말 디바이스 )에 서비스를 제공하는 네트워크 디바이스일 수도 있다.셀은 네트워크 디바이스의 무선 신호 범위 내에 있는 영역으로 이해될 수 있다는 점에 유의해야 한다. 도 1은 이해를 돕기 위한 예의 단순화된 도면일 뿐이라는 점을 이해해야 한다. 무선 통신 시스템은 도 1 에 나타나 있지 않은 다른 네트워크 디바이스 또는 다른 단말 디바이스를 추가로 포함할 수 있다. 본 출원의 실시예는 송신단 디바이스가 수신단 디바이스와 통신하는 임의의 통신 시나리오에 적용될 수 있다. 본 출원의 실시예를 쉽게 이해할 수 있도록 하기 위해, 먼저 본 출원의 실시예에서 사용되는 용어를 간략하게 설명한다. 1. 인공지능(artificial intelligence, AI)은 기계가 학습 능력을 가지게 하고, 경험을 축적하며, 인간이 경험 을 통해 해결할 수 있는 자연어 이해, 이미지 인식, 체스 게임과 같은 문제를 해결할 수 있게 해준다. 2. 머신 러닝(machine learning)은 인공지능의 구현예이다. 머신 러닝은 기계가 직접 프로그래밍을 통해 구현 할 수 없는 기능을 완료할 수 있는 학습 기능을 제공하는 방법이다. 실제로 머신 러닝은 데이터를 사용하여 모 델을 트레이닝한 다음, 그 모델을 예측에 사용하는 방법이다. 3. 신경망(neural network)은 머신 러닝 방법의 구체적인 구현이다. 신경망은 동물 신경망의 행동 특징을 모방 하고 정보를 처리하는 수학적 모델이다. 신경망은 입력층, 은닉층, 출력층의 세 가지 유형의 컴퓨팅 층을 포함 할 수 있다. 각 층은 하나 이상의 논리적 결정 유닛을 가지며, 논리적 결정 유닛은 뉴런(neuron)으로 지칭될 수 있다. 일반적인 신경망 구조에는 순방향 신경망(feedforward neural network, FNN), 컨볼루션 신경망 (convolutional neural network, CNN), 순환 신경망(recurrent neural network, RNN) 등이 있다. 이러한 네트 워크 구조는 뉴런에 기초하여 형성된다. 각 뉴런은 뉴런의 입력 값에 가중 합산 연산을 수행하고, 비선형 함수 를 사용하여 가중 합산 결과에 기반한 출력을 생성할 수 있다. 신경망에서 뉴런에 의한 가중 합산 연산을 수행 하는 가중치 및 비선형 함수는 신경망의 파라미터로 지칭될 수 있다. 신경망에서 뉴런들 사이의 연결 관계는 신경망의 구조로 지칭될 수 있으며, 신경망에 있는 모든 뉴런의 파라미터는 신경망의 파라미터를 형성할 수 있 다. 4. 심층 신경망(deep neural network)은 복수의 은닉 층을 가진 신경망이다. 5. 딥 러닝(deep learning)은 심층 신경망에 기초하여 하는 머신 러닝이다. 6. 프리코딩 매트릭스 인디케이터(precoding matrix indicator, PMI)는 프리코딩 매트릭스를 나타낼 수 있다. 프리코딩 매트릭스는 각 주파수 대역의 채널 매트릭스에 기초하여 단말 디바이스에 의해 결정된 프리코딩 매트 릭스일 수 있다. 예를 들어, 채널 매트릭스는 채널 추정 방식으로 단말 디바이스에 의해 결정될 수 있다. 프 리코딩 매트릭스의 벡터는 프리코딩 벡터로 지칭될 수 있다. 예를 들어, 채널에 적응할 수 있는 프리코딩 매트릭스를 얻기 위해, 네트워크 디바이스는 단말 디바이스에 참조 신호를 보내 사전에 채널 측정을 수행할 수 있으며, 단말 디바이스는 각 주파수 대역의 채널 매트릭스에 기초하 여 각 주파수 대역의 프리코딩 벡터를 결정할 수 있다. 주파수 대역의 채널 매트릭스가 H라고 가정하면, 단말 디바이스는 채널 매트릭스 H 또는 채널 매트릭스의 공분 산 매트릭스 HHH에 대해 특이값 분해(singular value decomposition, SVD)를 수행하여 주파수 대역의 프리코딩 매트릭스를 결정할 수 있다. 위첨자 H는 켤레 전치를 나타낸다. 예를 들어, HH는 매트릭스(또는 벡터) H의 켤 레 전치(transpose)를 나타낸다. 그 다음에, 단말 디바이스는 각 주파수 대역의 프리코딩 매트릭스에 있는 각 요소를 양자화할 수 있고, PMI를 사용하여 네트워크 디바이스에 양자화된 값을 피드백함으로써, 네트워크 디바 이스가 PMI에 기초하여 프리코딩 매트릭스를 복원할 수 있도록 한다. PMI에 대한 앞의 설명은 단지 예시일 뿐이며, 본 출원에 대한 어떠한 제한도 구성하지 않는다. 무선 통신 기술의 발달로 점점 더 많은 서비스가 지원되고 있으며, 시스템 용량 및 통신 지연과 같은 지표 측면 에서 통신 시스템에 대한 요구 사항이 점점 더 높아지고 있다. UE에 사용할 수 있는 대역폭을 확장하면 통신 속도를 효과적으로 향상시킬 수 있다. 더 넓은 사용 가능한 대역폭을 지원하기 위해, 복수의 인접하거나 인접 하지 않은 주파수 대역이 통신을 위해 UE에 할당될 수 있다. 각 주파수 대역에서 효과적인 통신을 지원하기 위 해, 네트워크 디바이스는 각 주파수 대역에 대한 채널 상태 정보(channel state information, CSI)를 획득해야 한다. 가능한 방식으로, UE는 업링크 피드백을 수행하여 네트워크 디바이스가 다운링크 CSI를 획득하도록 한다. 구체적으로, 네트워크 디바이스는 다운링크 참조 신호를 UE로 전송하고, UE는 다운링크 참조 신호를 수 신한다. UE는 다운링크 참조 신호의 송신 정보를 알고 있다. 따라서, UE는 다운링크 참조 신호의 송신 정보와UE가 수신하는 다운링크 참조 신호에 기초하여 다운링크 참조 신호가 통과하는 다운링크 채널을 추정(또는 측정)할 수 있고, UE는 측정에 기초하여 다운링크 채널 매트릭스를 획득하며, CSI를 생성하고, 생성된 CSI를 네 트워크 디바이스에 피드백한다. CSI 피드백의 중요한 부분은 PMI이다. 구체적으로, 채널 매트릭스 또는 프리코딩 매트릭스를 정량화하기 위해 CSI에서 하나 이상의 비트 값이 사용된다. 예를 들어, 채널 매트릭스 또는 프리코딩 매트릭스는 \"0\" 비트 값 및/또는 \"1\" 비트 값을 사용하여 정량화될 수 있다. 전술한 바와 같이, 프리코딩 매트릭스는 각 주파수 대역의 채널 매트릭스에 기초하여 UE에 의해 결정된 프리코딩 매트릭스일 수 있다. 기존의 PMI 설계(또는 코드북 설계라고도 함) 방법에서는, 일련의 프리코딩 매트릭스와 대응 숫자가 프로토콜에 미리 정의된다. 이들 프리코딩 매트릭스는 코드워드 또는 프리코딩 정보라고도 한다. 채널 매트릭스 또는 프 리코딩 매트릭스는 미리 정의된 코드워드 또는 복수의 미리 정의된 코드워드의 선형 조합을 사용하여 근사화될 수 있다. 따라서, UE는 PMI를 사용하여 코드워드에 대응하는 숫자와 적어도 하나의 가중 계수를 네트워크 디바 이스에 피드백하여, 네트워크 디바이스 측이 채널 매트릭스 또는 프리코딩 매트릭스를 복원하도록 한다. UE가 피드백하는 CSI의 정밀도가 더 높다는 것은 CSI에 기초하여 네트워크 디바이스에서 복원하는 채널 정보가 더 정 확하고 정보가 더 풍부하다는 것을 나타낸다. 따라서, 네트워크 디바이스에 의해 결정되는 프리코딩 매트릭스 가 더 정확하고, UE가 수신하는 신호의 신호 대 간섭 + 잡음 비율이 더 높으며, 시스템 용량이 더 크다. 그러 나, 시스템의 안테나 어레이 규모가 커질수록 지원할 수 있는 안테나 포트의 수가 증가한다. 완전한 채널 매트 릭스의 크기는 안테나 포트의 수에 정비례하기 때문에, 대규모 다중입출력(massive multiple-input multiple- output, Massive MIMO) 시스템에서 CSI를 사용하여 완전한 채널 매트릭스를 네트워크 디바이스에 피드백하는 것 은 막대한 피드백 오버헤드를 의미한다. UE에 대한 멀티스트림 데이터의 병렬 전송을 지원하기 위해, 네트워크 디바이스는 CSI 피드백 정보에 기초하여 멀티스트리밍을 위한 프리코딩 매트릭스를 복원해야 한다. 여기서 스트림의 수량은 랭크(rank) 수 또는 층 수 라고도 하며, 다음에서 층 수로 집합적으로 표현된다. 기존의 다중 층 CSI 피드백 방식에서는 각 층의 프리코 딩 매트릭스에 대해, 전술한 방법을 사용하여 코드북에 기초하여 피드백 정보가 생성되어, 네트워크 디바이스가 층의 프리코딩 매트릭스를 복원할 수 있도록 한다. 따라서, 층 수가 증가함에 따라 CSI 피드백 오버헤드가 증 가한다. 예를 들어, 딥러닝과 같은 머신 러닝은 강력한 비선형 특징 추출 능력을 가지고 있으며, 서로 다른 층들 간의 상관관계를 추출할 수 있다. 따라서, 기존의 솔루션과 비교했을 때, 머신 러닝은 동일한 규모의 피드백에 더 많은 채널 정보를 포함할 수 있다. 이는 CSI 압축 피드백의 정보 손실을 줄이고 네트워크 디바이스 측에서 채 널 복원의 정확도를 향상시킨다. 또한, 기존 솔루션과 비교하여, 동일한 채널 정보를 표현하는 데 더 적은 피 드백 양을 사용할 수 있어 피드백 오버헤드를 더욱 줄일 수 있다. 이러한 관점에서, 본 출원은 다층의 채널 정보를 피드백하기 위해 AI 네트워크를 사용하는 방식을 제공하여, 피 드백 오버헤드를 줄이고 AI 네트워크의 계산 복잡성도 줄일 수 있다. AI 네트워크를 사용하여 채널 정보를 피드백하는 원리는, 인코더에 배치된 AI 모델의 입력은 채널 정보 그룹이 고, 인코더에 배치된 AI 모델의 출력은 압축된 정보의 조각이며, 디코더에 배치된 AI 모델의 입력은 압축된 정 보의 조각이고, 디코더에 배치된 AI 모델의 출력은 채널 정보 그룹인 것으로 이해할 수 있다. 설명을 위해 단 말 디바이스가 네트워크 디바이스에 채널 정보를 피드백하는 예를 사용한다. 예를 들어, 단말 디바이스는 트레 이닝 세트를 사용하고, 트레이닝 세트의 채널 데이터를 인코더에 입력하여 출력을 획득한다. 채널 데이터를 압 축하는 과정에서 발생하는 오류는 손실 함수로 사용될 수 있으며, 손실 함수는 인코더의 AI 모델의 가중치의 함 수이다. 손실 함수가 임계값보다 작으면 트레이닝이 중단된다. 그렇지 않으면, 인코더의 가중치가 업데이트되 어 손실 함수가 감소한다. AI 모델은 하드웨어 회로, 소프트웨어 또는 소프트웨어와 하드웨어의 조합을 사용하여 구현될 수 있다. 이는 제한되지 않는다. 소프트웨어의 제한되지 않는 예로는 프로그램 코드, 프로그램, 서브프로그램, 명령어, 명령 어 세트, 코드, 코드 세그먼트, 소프트웨어 모듈, 애플리케이션, 소프트웨어 애플리케이션 등이 있다. 본 출원에서 \"표시\"는 직접 표시, 간접 표시, 명시적 표시 및 암시적 표시를 포함할 수 있다는 점에 유의해야 한다. 표시 정보가 A를 나타내기 위해 기술되는 경우, 이는 표시 정보가 A를 포함하거나, A를 직접적으로 표시 하거나, A를 간접적으로 표시한다고 이해할 수 있다. 본 출원에서 표시 정보로 나타낸 정보는 표시될 정보(to-be-indicated information)로 지칭된다. 특정 구현 프 로세스에서, 표시될 정보는 복수의 방식으로 표시되는데, 예를 들면 표시될 정보가 직접 표시되거나, 또는 표시 될 정보 또는 표시될 정보의 인덱스가 표시되는 방식으로 표시될 수 있지만, 이에 한정되지는 않는다. 또는, 표시될 정보는 다른 정보를 표시함으로써 간접적으로 표시될 수도 있으며, 다른 정보와 표시될 정보 사이에 연 관 관계가 있다. 또는, 표시될 정보의 일부만 표시될 수 있으며, 표시될 정보의 다른 부분은 알려져 있거나 사 전에 합의된다. 예를 들어, 특정 정보는 사전에 합의된(예컨대, 프로토콜에서 규정된) 복수의 정보의 배열 순 서를 사용하여 표시될 수 있어, 표시 오버헤드를 어느 정도 줄일 수 있다. 또한, 표시될 정보는 전체로 전송될 수도 있고, 개별 전송을 위해 복수의 하위 정보로 분할될 수도 있다. 또한, 이들 하위 정보의 전송 주기 및/또 는 전송 시기는 동일할 수도 있고 상이할 수도 있다. 다음은 첨부 도면을 참조하여 본 출원의 실시예에서 제공된 통신 방법을 상세하게 설명한다. 본 출원에서 제공 되는 실시예는 도 1에 도시된 네트워크 구조에 적용될 수 있다. 이는 제한되지 않는다. 다음 실시예에서, 예를 들어, 인코더가 단말 디바이스이고, 디코더는 네트워크 디바이스이거나, 또는 인코더는 단말 디바이스이고, 디코더는 다른 단말 디바이스이거나, 또는 인코더는 네트워크 디바이스이고, 디코더는 다른 네트워크 디바이스이거나, 또는 인코더는 네트워크 디바이스이고, 디코더는 단말 디바이스이다. 이는 제한되지 않는다. 이하에서 인코더는 인코딩 장치로 대체될 수 있고, 디코더는 디코딩 장치로 대체될 수 있음을 이해할 수 있을 것이다. 또한, 이하에서 인코더는 AI 모델 이외의 회로(예컨대, 처리 회로, 저장 회로, 트랜시버 회로)를 포함할 수 있음을 또한 이해할 수 있을 것이다. 다음 실시예에서, 복수의 AI 모델이 인코더에 배치될 수 있으며, 따라서 인코더가 배치된 AI 모델에 기초하여 인코딩을 수행할 수 있다(예컨대, 채널 정보를 압축할 수 있다). 복수의 AI 모델이 디코더에 배치될 수 있으며, 따라서 디코더는 배치된 AI 모델에 기초하여 디코딩을 수행할 수 있다(예컨대, 압축된 정보를 복원하여 채널 정보를 획득할 수 있다). 간결성을 위해, 인코더에 의해 배치된 AI 모델을 인코더의 AI 모델이라고 하고, 디코더에 의해 배치된 AI 모델을 디코더의 AI 모델이라고 한다. 도 2는 본 출원의 실시예에 따른 통신 방법의 도면이다. 방법은 다음 단계들을 포함할 수 있다. 210: 인코더가 적어도 두 개의 AI 모델을 사용하여 M개의 층의 채널 정보를 압축하여 N개의 압축된 정보를 획득 하며, 여기서 N과 M은 1보다 큰 정수이고, N은 M보다 작다. 가능한 구현예에서, 인코더는 디코더로부터 참조 신호를 수신하고, 인코더는 참조 신호에 기초하여 채널 측정을 수행하여, M개의 층의 채널 정보를 획득한다. N개의 압축된 정보 각각은 적어도 두 개의 AI 모델 중 적어도 하나를 사용하여 M개의 층의 채널 정보 중 일부 층의 채널 정보를 압축함으로써 획득된다. 즉, N개의 압축된 정보 각각은 적어도 두 개의 AI 모델 중 적어도 하나의 AI 모델을 사용하여 M개의 층의 채널 정보 중 일부 층의 채널 정보를 압축함으로써 획득된다. 예를 들어, M개의 층의 채널 정보는 N개의 채널 정보 그룹으로 나누어지고, 각 채널 정보 그룹은 AI 모델을 사 용하여 압축되어 N개의 압축된 정보를 획득한다. 각 채널 정보 그룹은 적어도 하나의 층의 채널 정보를 포함한 다. N개의 채널 정보 그룹은 겹치지 않을 수 있다. 예를 들어, 각 채널 정보 그룹의 압축 방식은 개별 압축 또는 공동 압축일 수 있다. 본 출원의 실시예에서, 압 축 방식은 여러 차례 언급되며, 그 압축 방식은 개별 압축 및 공동 압축을 포함한다. 개별 압축은 한 층의 채널 정보가 개별적으로 압축됨을 나타낸다. 예를 들어, 층의 채널 정보가 AI 모델에 입 력되어 하나의 압축된 정보를 획득한다. 공동 압축은 적어도 두 개의 층의 채널 정보(예컨대, 두 개의 층의 채널 정보, 세 개의 층의 채널 정보, 또는 네 개의 층의 채널 정보)에 대해 공동 압축이 수행됨을 나타낸다. 예를 들어, 적어도 두 개의 층의 채널 정보 가 AI 모델에 입력되어 하나의 압축된 정보를 획득한다. 선택적으로, M개의 층의 채널 정보의 압축 방식은 공동 압축이거나, 또는 M개의 층의 채널 정보의 압축 방식은 개별 압축 및 공동 압축을 포함한다. 가능한 경우, M개의 층의 채널 정보의 압축 방식은 개별 압축 및 공동 압축을 포함한다. 이 경우에 기초하여, N개의 압축된 정보는 적어도 하나의 제1 압축된 정보와 적어도 하나의 제2 압축된 정보를 포함한다. 제1 압축 된 정보는 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용하여 M개의 층의 채널 정보 중 적어도 두 개의 층에 대한 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, 제2 압축된 정보는 적어도 두 개의 AI 모델 중 제2AI 모델을 사용하여 M개의 층의 채널 정보 중 단일 층의 채널 정보에 대해 개별 압축을 수행함으로써 획득된다. 다시 말해서, M개의 층의 채널 정보는 N개의 채널 정보 그룹으로 나누어지고, N개의 채널 정보 그룹 중 일부 채 널 정보 그룹은 공동 압축 방식으로 압축되고, N개의 채널 정보 그룹 중 나머지 일부 채널 정보 그룹은 개별 압 축 방식으로 압축된다. 제1 AI 모델은 공동 압축에 사용되는 AI 모델을 나타낼 수 있고, 제2 AI 모델은 개별 압축에 사용되는 AI 모델을 나타낼 수 있다. 또 다른 가능한 경우, M개의 층의 채널 정보의 압축 방식은 공동 압축이다. 즉, M개의 층의 채널 정보는 N개의 채널 정보 그룹으로 나누어지고, 각 채널 정보 그룹은 공동 압축 방식으로 압축된다. 이 경우에, N개의 압축된 정보는 적어도 두 개의 제1 압축된 정보를 포함하고, 제1 압축된 정보는 적어도 두 개의 AI 모델 중 제1 AI 모 델을 사용하여 M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대한 공동 압축을 수행함으로써 획득 된다. 예를 들어, 압축 방식은 어레이 방식으로 표현될 수 있다. 예를 들어, M개의 층의 채널 정보는 N개의 채널 정 보 그룹으로 나뉘며, M개의 층의 채널 정보의 압축 방식은 N개의 그룹 및 각 그룹의 요소를 수치 방식으로 나타 낼 수 있다. 예를 들어, M개의 층의 채널 정보의 압축 방식은 [층 1, 층 2], 및 [층 3]으로 표현되는데, 이는 M개의 층의 채널 정보가 두 그룹으로 나뉘어지고, 제1 세트의 제1 층 및 제2 층의 채널 정보에 대해 공동 압축 이 수행되고, 제2 세트의 제3 층의 채널 정보에 대해 개별 압축이 수행됨을 나타낸다. 다른 예에서, M개의 층 의 채널 정보의 압축 방식은 [층 1, 층 2], 및 [층 3, 층 4]로 표현되는데, 이는 M개의 층의 채널 정보가 두 그 룹으로 나뉘어지고, 제1 세트의 제1 층 및 제2 층의 채널 정보에 대해 공동 압축이 수행되고, 제2 세트의 제3 층의 채널 정보에 대해 공동 압축이 수행됨을 나타낸다. 또 다른 예에서, M개의 층의 채널 정보의 압축 방식은, [층 1], [층 2, 층 3, 층 4], 및 [층 5]로 표현되는데, 이는 M개의 층의 채널 정보가 세 그룹으로 나뉘 어지고, 제1 세트의 제1 층의 채널 정보에 대해 개별 압축이 수행되고, 제2 세트의 제2 층, 제3 층, 제4 층의 채널 정보에 대해 공동 압축이 수행되며, 제3 세트의 제5 층의 채널 정보에 대해 개별 압축이 수행된다. 선택적으로, N개의 압축된 정보에 대응하는 AI 모델은 부분적으로 동일하거나, 완전히 동일하거나, 완전히 상이 할 수 있다. 즉, 본 출원의 실시예에서, 모든 그룹의 채널 정보에 대응하는 AI 모델은 부분적으로 동일하거나, 완전히 동일하거나, 또는 완전히 상이할 수 있다. 가능한 경우, 상이한 압축 방식은 상이한 AI 모델에 대응한다. 예를 들어, 개별 압축은 제2 AI 모델에 대응하 고, 공동 압축은 제1 AI 모델에 대응한다. 인코더가 한 층의 채널 정보에 대해 개별 압축을 수행하면, 제2 AI 모델이 사용된다. 인코더가 적어도 두 층의 채널 정보에 대해 공동 압축을 수행하면, 제1 AI 모델이 사용된다. 또 다른 가능한 경우, 각각의 채널 정보 그룹은 다른 AI 모델에 대응한다. 예를 들어, M개의 층의 채널 정보가 세 그룹으로 나뉘어져 있다고 가정하는데, 이는 제1 채널 정보 그룹, 제2 채널 정보 그룹, 제3 채널 정보 그룹 으로 표시된다. 인코더는 제1 AI 모델을 사용하여 제1 채널 정보 그룹을 압축하고, 제2 AI 모델을 사용하여 제 2 채널 정보 그룹을 압축하며, 제3 AI 모델을 사용하여 제3 채널 정보 그룹을 압축한다. 본 출원의 실시예에서, AI 모델의 구조는 제한되지 않는다. 예를 들어, AI 모델의 구조는, 예컨대, 완전 연결 층, 컨볼루션 신경망 또는 트랜스포머 구조에 기반한 AI 모델 중 어느 하나일 수 있다. 본 출원의 실시예에서, 인코더에 배치된 AI 모델의 경우, AI 모델의 입력은 채널 정보 그룹이고, AI 모델의 출력은 압축된 정보이며, 압축된 정보의 차원은 입력 채널 정보의 차원보다 작다. 디코더에 배치된 AI 모델의 경우, AI 모델의 입력은 압축된 정보이고, AI 모델의 출력은 채널 정보 그룹이며, 압축된 정보의 차원은 입력 채널 정보의 차원보다 작 다. 또한, 인코더와 디코더가 사용하는 AI 모델, 즉 인코더가 M개의 층의 채널 정보를 압축하는 데 사용하는 AI 모 델과 디코더가 N개의 정보를 디코딩하는 데 사용하는 AI 모델을 결정하는 방식은 제한되지 않는다. 가능한 구 현예에서, 이 방식은 미리 정의되는데, 예를 들면 표준에서 미리 정의되거나 또는 사전 합의된다. 또 다른 가 능한 구현예에서, 인코더는 디코더에 M개의 층의 채널 정보를 압축하는 데 사용되는 AI 모델에 대한 정보(예컨 대, 인코더가 M개의 층의 채널 정보를 압축하는 데 사용하는 AI 모델 또는 인코더가 M개의 층의 채널 정보를 압 축하는 데 사용하는 AI 모델의 식별자)를 제공한다. 디코더는 인코더가 제공하는 AI 모델에 관한 정보에 기초 하여, N개의 압축된 정보를 디코딩하는 데 사용되는 AI 모델을 결정한다. 또 다른 가능한 구현예에서, 인코더 또는 디코더는 압축 방식에 기초하여 인코더 또는 디코더가 사용하는 AI 모델을 결정한다. 예를 들어, 인코더 는 디코더에 압축 방식을 제공하고, 디코더는 압축 방식에 기초하여, N개의 압축된 정보를 디코딩하는 데 사용 되는 AI 모델을 결정할 수 있다. 또 다른 예에서, 디코더는 인코더에 압축 방식을 제공하고, 인코더는 압축 방 식에 기초하여, M개의 층의 채널 정보를 압축하는 데 사용되는 AI 모델을 결정할 수 있다.220: 인코더가 N개의 압축된 정보를 디코더로 전송한다. 이에 따라, 디코더는 N개의 압축된 정보를 수신한다. 선택적으로, 방법은 단계 230을 더 포함한다. 230: 디코더가 N개의 압축된 정보를 디코딩하여 M개의 층의 채널 정보를 획득한다. 본 출원의 실시예에 기초하여, 인코더는 적어도 두 개의 AI 모델을 사용하여 M개의 층의 채널 정보를 압축하여 N개의 압축된 정보를 획득하고, N개의 압축된 정보를 디코더로 전송하여, 디코더가 N개의 압축된 정보에 기초하 여 디코딩을 수행하여 M개의 층의 채널 정보를 복원할 수 있도록 한다. 이런 방식으로, 복수의 층의 채널 정보 가 AI 네트워크를 사용하여 피드백될 수 있다. 기존의 방식에 비해, 이 방식은 채널 정보를 피드백함으로써 발 생하는 오버헤드를 줄일 수 있다. 또한, M개의 층의 채널 정보에 기초하여 N개의 압축된 정보가 획득되며, N은 M보다 작다. 즉, M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 공동 압축이 수행된다. 각 층의 채널 정보에 대한 개별 압축과 비교하여, 이는 층들 사이의 서로 다른 채널 정보 사이의 관계를 이용하여 피드백 오버헤드를 더욱 줄일 수 있다. 또한, N은 1보다 더 크다. 한 번에 M개의 층의 채널 정보에 대해 공동 압축하는 것에 비해, 이는 계산 복잡도를 줄일 수 있다. 선택적으로, 방법은 인코더와 디코더가 M개의 층의 채널 정보의 압축 방식을 학습하는 것을 더 포함한다. 이런 방식으로, 인코더는 M개의 층의 채널 정보의 압축 방식에 기초하여 M개의 층의 채널 정보를 압축하여 N개 의 압축된 정보를 획득할 수 있다. 디코더는 M개의 층의 채널 정보의 압축 방식에 기초하여 N개의 압축된 정보 를 디코딩하여 M개의 층의 채널 정보를 획득할 수 있다. 다음은 가능한 몇 가지 솔루션을 설명한다. 솔루션 1: 인코더가 M개의 층의 채널 정보의 압축 방식을 결정한다. 이 솔루션에 기초하여, 인코더는 M개의 층의 채널 정보의 압축 방식을 결정할 수 있고, 인코더에 의해 결정된 M 개의 층의 채널 정보의 압축 방식에 기초하여 M개의 층의 채널 정보를 추가로 압축하여, N개의 압축된 정보를 획득할 수 있으며, N개의 압축된 정보를 디코더로 전송할 수 있다. 이 솔루션에 따르면, 인코더는 실제 통신 상태에 기초하여 적절한 압축 방식을 동적으로 선택할 수 있으며, 그 방식이 유연하다. 선택적으로, 솔루션 1에서 인코더는 M개의 층의 채널 정보의 압축 방식을 디코더로 보낸다. 이런 방식으로, 디 코더는 M개의 층의 채널 정보의 압축 방식 및 수신된 N개의 압축된 정보에 기초하여 디코딩을 통해 M개의 층의 채널 정보를 획득한다. 솔루션 1에 적용되는 절차는 방법을 참조하여 아래에 자세히 설명한다. 솔루션 2: 디코더가 M개의 층의 채널 정보의 압축 방식을 결정한다. 이 솔루션에 기초하여, 디코더는 M개의 층의 채널 정보의 압축 방식을 결정할 수 있으며, 디코더에 의해 결정된 M개의 층의 채널 정보의 압축 방식 및 수신된 N개의 압축된 정보에 기초하여 디코딩을 통해 M개의 층의 채널 정 보를 추가로 획득할 수 있다. 이 솔루션에 따르면, 디코더는 실제 통신 상태에 기초하여 적절한 압축 방식을 동적으로 선택할 수 있으며, 그 방식이 유연하다. 선택적으로, 솔루션 2에서 디코더는 M개의 층의 채널 정보의 압축 방식을 인코더로 보낸다. 이런 방식으로, 인 코더는 네트워크 디바이스에 의해 표시되는 M개의 층의 채널 정보의 압축 방식에 기초하여 M개의 층의 채널 정 보를 압축하여, N개의 압축된 정보를 획득하고, N개의 압축된 정보를 디코더로 보낸다. 솔루션 2에 적용할 수 있는 절차는 방법을 참조하여 아래에 자세히 설명한다. 솔루션 3: 다른 장치가 M개의 층의 채널 정보의 압축 방식을 결정한다. 이 솔루션에 기초하여, 다른 장치는 M개의 층의 채널 정보의 압축 방식을 결정할 수 있다. 이 솔루션에 따르면, 다른 장치는 M개의 층의 채널 정보의 압축 방식을 결정할 수 있다. 이는 인코더와 디코더가 M개의 층 의 채널 정보의 압축 방식을 결정함으로써 발생하는 오버헤드를 줄인다. 솔루션 3에서, 다른 장치는 M개의 층의 채널 정보의 압축 방식을 디코더 및/또는 인코더로 전송할 수 있다. 예 를 들어, 다른 장치는 M개의 층의 채널 정보의 압축 방식을 디코더와 인코더로 개별적으로 전송한다. 또 다른 예에서, 다른 장치는 M개의 층의 채널 정보의 압축 방식을 디코더로 보낸다. M개의 층의 채널 정보의 압축 방 식을 수신한 후, 디코더는 M개의 층의 채널 정보의 압축 방식을 인코더로 보낸다. 또 다른 예에서, 다른 장치 는 M개의 층의 채널 정보의 압축 방식을 인코더로 보낸다. M개의 층의 채널 정보의 압축 방식을 수신한 후, 인코더는 M개의 층의 채널 정보의 압축 방식을 디코더로 보낸다. 솔루션 4: 사전 정의(Predefinition). 예를 들어, M개의 층의 채널 정보의 압축 방식은 표준에 미리 정의되어 있다. 이 솔루션에 기초하여, 인코더와 디코더는 사전 정의에 기초하여 M개의 층의 채널 정보의 압축 방식을 결정할 수 있다. 이 솔루션에 따르면, 인코더와 디코더는 사전 정의에 기초하여 M개의 층의 채널 정보의 압축 방식을 직접 결정할 수 있다. 이는 M개의 층의 채널 정보의 압축 방식을 인코더와 디코더에 통지함으로써 발생하는 신 호 처리 오버헤드를 감소시킨다. 선택적으로, M개의 층의 채널 정보의 압축 방식은, 인코더의 기능 정보, 디코더의 기능 정보, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 공동 압축 수행의 성능, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 개별 압축 수행의 성능, M 값 중 적어도 하나에 기초하여 결정된다. 예를 들어, 인코더의 기능 정보는 인코더의 컴퓨팅 자원과 인코더의 AI 모델 중 적어도 하나를 포함할 수 있다. 예를 들어, 디코더의 기능 정보는 디코더의 컴퓨팅 자원과 디코더의 AI 모델 중 적어도 하나를 포함할 수 있다. 여기서 \"기능 정보\"는 간결성을 위해 사용된 것으로, \"기능 정보\"의 명칭은 본 출원의 실시예의 보호 범위를 제 한하지 않는다. 가능한 경우, 전술한 솔루션 1이 예로서 사용된다. 인코더는 M개의 층의 채널 정보의 압축 방식을 결정한다. 이 경우, 인코더는 인코더의 기능 정보 및/또는 디코더의 기능 정보에 기초하여 M개의 층의 채널 정보의 압축 방식을 결정할 수 있다. 예를 들어, 디코더는 디코더의 기능 정보를 인코더로 보낸다. 또 다른 예에서, 인코 더는 인코더와 디코더 사이의 과거 통신 상태에 기초하여 디코더의 기능 정보를 추정할 수 있는데, 예를 들면, 디코더의 컴퓨팅 자원 및/또는 디코더의 AI 모델을 추정할 수 있다. 또 다른 가능한 경우, 앞의 솔루션 2가 예로 사용된다. 디코더는 M개의 층의 채널 정보의 압축 방식을 결정한 다. 이 경우, 디코더는 인코더의 기능 정보 및/또는 디코더의 기능 정보에 기초하여 M개의 층의 채널 정보의 압축 방식을 결정할 수 있다. 예를 들어, 인코더는 인코더의 기능 정보를 디코더로 보낸다. 또 다른 예에서, 디코더는 디코더와 인코더 사이의 과거 통신 상태에 기초하여 인코더의 기능 정보를 추정할 수 있는데, 예를 들 면, 인코더의 컴퓨팅 자원 및/또는 인코더의 AI 모델을 추정할 수 있다. 다음은 M개의 층의 채널 정보의 압축 방식을 결정하는 몇 가지 예를 설명한다. M개의 층의 채널 정보의 압축 방식을 결정하는 다음 장치는 인코더(즉, 앞의 솔루션 1)일 수도 있고, 디코더(즉, 앞의 솔루션 2)일 수도 있으 며, 또는 다른 장치(즉, 앞의 솔루션 3)일 수도 있다. 이는 제한되지 않는다. 예 1: M개의 층의 채널 정보의 압축 방식은 인코더의 컴퓨팅 자원에 기초하여 결정된다. 인코더의 컴퓨팅 자원은 채널 정보를 압축하기 위해 인코더가 사용할 수 있는 컴퓨팅 파워를 나타낼 수 있다. 예를 들어, 인코더의 컴퓨팅 자원은 인코더의 컴퓨팅 자원(예컨대, 소프트웨어 자원 또는 하드웨어 자원)의 구 성 상태에 기초하여 인코더에 의해 결정되거나, 또는 인코더의 컴퓨팅 자원은 인코더의 사용 가능한 컴퓨팅 자 원에 기초하여 인코더에 의해 결정된다. 인코더의 가용 컴퓨팅 자원은 인코더가 채널 정보를 압축할 때 인코더 의 가용 컴퓨팅 자원에 기초하여 결정될 수 있다. 예를 들어, 인코더의 컴퓨팅 자원이 크고, 예를 들어, 인코더가 채널 정보를 압축하는 데 사용하는 가용 컴퓨팅 파워가 사전 설정된 값보다 크거나 같다면, M개의 층의 채널 정보 압축 방식은 공동 압축을 포함할 수 있다. 예를 들어, M개의 층의 채널 정보는 N개의 채널 정보 그룹으로 나누어지고, 일부 채널 정보 그룹에 대해 공동 압축이 개별적으로 수행되며, 나머지 채널 정보 그룹에 대해 개별 압축이 수행된다. 또 다른 예에서, 인코더가 채널 정보를 압축하는 데 사용하는 가용 컴퓨팅 파워가 사전 설정된 값보다 작으면, 각 층의 채널 정보에 대해 개별 압축이 수행될 수 있다. 예 2: M개의 층의 채널 정보 압축 방식은 디코더의 컴퓨팅 자원에 기초하여 결정된다. 디코더의 컴퓨팅 자원에 대해서는, 인코더의 컴퓨팅 자원에 대한 전술한 설명을 참조한다. 세부 사항은 본 명 세서에서 반복하지 않는다. 예를 들어, 디코더의 컴퓨팅 자원이 크다면, 예를 들어, 채널 정보를 압축하기 위해 디코더가 사용하는 가용 컴 퓨팅 파워가 사전 설정된 값보다 크거나 같으면, M개의 층의 채널 정보 압축 방식은 공동 압축을 포함할 수 있 다. 예를 들어, M개의 층의 채널 정보가 N개의 채널 정보의 그룹으로 균등하게 분할되고, 각 채널 정보 그룹에대해 공동 압축이 수행된다. 예 3: M개의 층의 채널 정보의 압축 방식은 인코더의 AI 모델에 기초하여 결정된다. 예를 들어, 인코더의 AI 모델이 공동 압축에 적용 가능한 경우(예컨대, 개별 압축에 적용 가능한 AI 모델이 업 데이트되는 경우), M개의 층의 채널 정보의 압축 방식은 공동 압축일 수 있다. 인코더의 AI 모델이 개별 압축 에 적용될 수 있는 경우(예컨대, 공동 압축에 적용되는 AI 모델이 업데이트되는 경우), M개의 층의 채널 정보의 압축 방식은 개별 압축일 수 있다. 예 4: M개의 층의 채널 정보의 압축 방식은 디코더의 AI 모델에 기초하여 결정된다. 예를 들어, 디코더의 AI 모델이 공동 압축의 디코딩에 적용될 수 있는 경우, M개의 층의 채널 정보의 압축 방식 은 공동 압축을 포함할 수 있다. 디코더의 AI 모델이 개별 압축의 디코딩에 적용될 수 있는 경우, M개의 층의 채널 정보의 압축 방식은 개별 압축을 포함할 수 있다. 예 5: M개의 층의 채널 정보의 압축 방식은 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 공동 압축을 수행하는 성능에 기초하여 결정된다. 예를 들어, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 공동 압축을 수행하는 성능이 사전 설정된 값 보다 크거나 같으면, M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함할 수 있다. 또 다른 예에서, M개 의 층의 채널 정보는 N개의 채널 정보 그룹으로 나누어진다. 인코더는 N이 1, 2, ..., 또는 M-1일 때 획득한 채널 정보에 대해 개별적으로 공동 인코딩을 수행하고, 공동 압축의 성능을 결정한다. 인코더는 성능이 최적일 때 N의 값을 결정하여, N개의 채널 정보 그룹에 대해 공동 압축을 수행한다. 예 6: M개의 층의 채널 정보의 압축 방식은 M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 개별 압축을 수행하는 성능에 기초하여 결정된다. 예를 들어, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대해 개별 압축을 수행하는 성능이 사전 설정된 값 보다 크거나 같으면, M개의 층의 채널 정보의 압축 방식은 개별 압축을 포함할 수 있다. 또 다른 예에서, 인코 더는 한 층의 채널 정보, 두 층의 채널 정보, ..., M개 층의 채널 정보에 대해 각각 별도의 인코딩을 수행하고, 개별 압축의 성능을 결정한다. 인코더는 성능이 최적일 때(예컨대, M=M1), M1 층의 채널 정보에 대해 개별 압 축을 수행하고, 나머지 채널 정보에 대해 공동 압축을 수행하도록 M 값을 결정한다. 예 7: M개의 층의 채널 정보의 압축 방식은 M의 값에 기초하여 결정된다. 예를 들어, M이 1보다 크면, M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하며, 어느 층의 채널 정보 에 대해서는 공동 압축이 수행되고, 어떤 층의 채널 정보는 개별 압축이 수행되어 무작위로 선택될 수 있다. 또 다른 예에서, M이 1보다 크고 제1 사전 설정 값보다 작거나 같으면, M개의 층의 채널 정보의 압축 방식은 개 별 압축이고, 또는 M이 제1 사전 설정 값보다 크면, M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하며, 어느 층의 채널 정보에 대해서는 공동 압축이 수행되고, 어떤 층의 채널 정보는 개별 압축이 수행되 어 무작위로 선택될 수 있다. 위에서는 압축 방식이 전술한 정보 중 어느 하나에 기초하여 결정된다. 전술한 정보는 조합해서 사용될 수도 있다. 다음은 전술한 정보를 조합해서 사용하는 예를 간략하게 나열한다. 전술한 정보를 조합해서 사용하는 다른 예는 여기에 반복하지 않는다. 예 8: M개의 층의 채널 정보 압축 방식은 디코더의 컴퓨팅 자원 및 인코더의 AI 모델에 기초하여 결정된다. 예를 들어, 디코더의 컴퓨팅 자원이 크고, 예를 들어, 채널 정보를 압축하기 위해 디코더에 의해 사용되는 가용 컴퓨팅 파워가 사전 설정된 값보다 크거나 같고, 인코더의 AI 모델이 공동 압축에 적용될 수 있는 경우, M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함할 수 있다. 선택적으로, 방법은 인코더와 디코더가 X개의 층에 있는 각 층 및 이 층들 사이의 채널 정보의 배열 방식 을 학습하는 것을 더 포함하며, 여기서 X는 1보다 크고 M보다 작은 정수이다. 이런 방식으로, 인코더는 X개의 층에 있는 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 X개의 층의 채널 정보를 압축하여, 하나 의 압축된 정보(예컨대, 제1 압축된 정보로 표시됨)를 획득할 수 있다. 디코더는 제1 압축된 정보를 디코딩하 고, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 디코더의 출력을 정확하게 파싱하 여, X개의 층의 채널 정보를 획득할 수 있다. 예를 들어, 디코더는 제1 압축된 정보를 AI 모델에 입력하고, X개의 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 AI 모델에서 출력된 정보를 파싱하여 X개의 층의 채널 정보를 획득할 수 있다. 일반적으로, 디코더의 출력은 개의 열을 포함하고, 각 열은 길이가 Nt인 복소 벡터이며, 채널 고유벡터 를 나타낸다. 채널 고유벡터는 디코더에 피드백된 후 프리코딩에 사용될 수 있다. 채널 고유벡터는 프리코딩 벡터라고도 할 수 있으며, 복수의 프리코딩 벡터가 프리코딩 매트릭스를 형성할 수 있다. Nt는 디코더의 송신 안테나 포트의 수를 나타내고, Nsub는 서브밴드의 수를 나타내며, M은 층의 수를 나타낸다. 디코더의 출력을 정확하게 파싱하기 위해서는, 디코더의 출력에서 각 요소에 대응하는 물리적 의미를 명확히 해 야 하는데, 즉, 요소에 대응하는 안테나 포트, 요소에 대응하는 서브밴드, 및 요소에 대응하는 층, 즉 M개의 층 의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 명확히 해야 한다. X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은 디코더가 압축된 정보를 디코딩한 후 디코더가 출력하는 각 요소에 대응하는 물리적 의미, 예컨대, 요소에 대응하는 안테나 포트, 요소에 대응하는 서브밴드, 요소에 대응하는 층을 나타낸다. M개의 층의 채널 정보는 N개의 채널 정보 그룹으로 나뉘어질 것으로 가정하고, N개의 채널 정보 그룹 중 N1개의 채널 정보 그룹에 대해서는 공동 압축이 사용된다. N1개의 채널 정 보 그룹 내의 각 채널 정보 그룹에 대해서는, 각 층 및 이 층들 사이의 채널 정보의 배열 방식이 동일하거나 또 는 다를 수 있다. 이는 제한되지 않는다. 다음은 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식 을 사용하여 관련 솔루션을 설명한다. 가능한 배열 방식에서, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은 레이어-비포-서브밴드 (layer-before-subband) 배열 방식인데, 즉, 동일한 서브밴드에 있는 다른 층의 채널 정보가 인접하게 배열된다. 예를 들어, 인코더는 배열 방식에 기초하여 X개의 층의 채널 정보에 대해 공동 압축을 수행하여 하나의 압축된 정보(예컨대, 제1 압축된 정보로 표시됨)를 획득할 수 있는데, 즉, 인코더에 의해 입력되는 X개의 층의 채널 정 보의 배열 방식은 레이어-비포-서브밴드 배열 방식이다. 이에 따라, 디코더는 배열 방식에 기초하여 제1 압축 된 정보를 디코딩할 수 있는데, 즉, 디코더에 의해 출력되는 X개의 층의 채널 정보의 배열 방식은 레이어-비포- 서브밴드 배열 방식이다. 도 3은 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 나타낸 도면이다. 도 3에서 볼 수 있듯 이, X개의 층은 각각 층 x, 층 y, 층 z로 표시되는 세 개의 층이라고 가정하고, X개의 층의 채널 정보는 각각 서브밴드 1, 서브밴드 2, 서브밴드 3으로 표시되는 세 개의 서브밴드(subband)에 대응한다. 도 3에 도시된 바 와 같이, 디코더가 출력하는 배열 방식은 레이어-비포-서브밴드 배열 방식이다. 구체적으로 말하면, 동일한 서 브밴드 내의 상이한 층에서의 고유벡터가 먼저 인접하게 배열되어 서브밴드의 고유벡터 그룹을 형성하고, 그 다 음에 서로 다른 서브밴드의 고유벡터 그룹이 순차적으로 배열된다. 또 다른 가능한 배열 방식에서, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식이 서브밴드-비포- 레이어(subband-before-layer) 배열 방식, 즉 동일한 층에서 서로 다른 서브밴드의 채널 정보가 인접하게 배열 되는 방식이다. 예를 들어, 인코더는 배열 방식에 기초하여 X개의 층의 채널 정보에 대해 공동 압축을 수행하여 하나의 압축된 정보(예컨대, 제1 압축된 정보로 표시됨)를 획득할 수 있는데, 즉, 인코더에 의해 입력되는 X개의 층의 채널 정 보의 배열 방식은 서브밴드-비포-레이어 배열 방식이다. 이에 따라, 디코더는 배열 방식에 기초하여 제1 압축 된 정보를 디코딩할 수 있는데, 즉, 디코더에 의해 출력되는 X개의 층의 채널 정보의 배열 방식이 서브밴드-비 포-레이어 배열 방식이다. 도 4는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 대한 다른 도면이다. 도 4에서 볼 수 있 듯이, X개의 층은 각각 층 x, 층 y, 층 z로 표시되는 세 개의 층이라고 가정하고, X개의 층의 채널 정보는 각각 서브밴드 1, 서브밴드 2, 서브밴드 3으로 표시되는 세 개의 서브밴드에 대응한다. 도 4에 도시된 바와 같이, 디코더가 출력하는 배열 방식은 서브밴드-비포-레이어 배열 방식이다. 구체적으로, 같은 층에 있는 서로 다른 서브밴드의 고유벡터가 먼저 인접하게 배열되어 층의 고유벡터 그룹을 형성하고, 그 다음에 서로 다른 층의 고 유벡터 그룹이 순차적으로 배열된다. 전술한 두 가지 배열 방식은 예일 뿐이며, 본 출원의 실시예는 이에 국한되지 않는다. 예를 들어, 각 층 및 이 층들 사이에 안테나 포트를 배치하는 방식이 대안으로 사용될 수 있다. 인코더와 디코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 다음의 방식으로 학습할 수 있다. 방식 1: 인코더가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정한다. 이 방식에 기초하여, 인코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정할 수 있으며, 인코더가 결정한 배열 방식에 기초하여 X개의 층의 채널 정보에 대한 공동 압축을 추가로 수행하여 하 나의 압축된 정보를 얻고, 압축된 정보를 디코더로 보낼 수 있다. 선택적으로, 방식 1에서, 인코더는 X개의 층의 각 층 및 층 사이의 채널 정보의 배열 방식을 디코더로 보낸다. 이런 방식으로, 디코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식과 수신된 압축된 정보에 기초하여 디코딩함으로써 X개의 층의 채널 정보를 획득할 수 있다. 또한, 선택적으로 인코더는 디코더에 인덱 스 값을 전송하고, 인덱스 값은 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 나타낸다. 예를 들어, 인덱스 값과 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식 사이에는 대응 관계가 있다. 따라서, 인코더는 인덱스 값을 디코더로 전송하고, 디코더는 인덱스 값과 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식 사이의 대응 관계에 기초하여 인덱스 값에 대응하는 배열 방식을 결정할 수 있다. 예를 들어, 레이어-비포-서브밴드 배열 방식은 제1 인덱스 값에 대응하고, 서브밴드-비포-서브밴드 배열 방식은 제2 인덱스 값에 대응한다. 이 경우, 배열 방식이 레이어-비포-서브밴드 배열 방식이면, 인코더가 제1 인덱스 값을 디코더로 보낸다. 배열 방식이 서브밴드-비포-서브밴드 배열 방식이면, 인코더가 제2 인덱스 값을 디코더로 보 낸다. 방식 2: 디코더가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정한다. 이 방식에 기초하여, 디코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정할 수 있으며, 디코더가 결정한 배열 방식과 수신된 압축된 정보에 기초하여 디코딩함으로써 X개의 층의 채널 정보를 추가로 획득할 수 있다. 선택적으로, 방식 2에서, 디코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 인코더로 보 낸다. 이런 방식으로, 인코더는 네트워크 디바이스에 의해 표시되는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 X개의 층의 채널 정보에 대해 공동 압축을 수행하여, 하나의 압축된 정보를 획득 하고, 그 압축된 정보를 디코더로 보낸다. 또한, 선택적으로 디코더는 인덱스 값을 인코더로 전송하며, 인덱스 값은 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 나타낸다. 자세한 내용은 방식 1의 설명을 참조한다. 세부 사항은 본 명세서에서 반복하지 않는다. 방식 3: 다른 장치가 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정한다. 이 방식에 기초하여, 다른 장치는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정할 수 있 다. 이 방식에 기초하여, 다른 장치는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 결정할 수 있다. 방식 3에서, 다른 장치는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 디코더 및/또는 인코더 로 전송할 수 있다. 예를 들어, 다른 장치는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 디 코더와 인코더에 개별적으로 보낸다. 또 다른 예에서, 다른 장치는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 디코더로 보낸다. 디코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 수신한 후, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 인코더로 보낸다. 또 다른 예에서, 다른 장치는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 인코더로 보낸다. X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 수신한 후, 인코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 디코더로 보낸다. 또한, 선택적으로, 다른 장치는 디코더 및/또는 인코더에 인덱스 값을 보낼 수 있으며, 인덱스 값은 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 나타낸다. 자세한 내용은 방식 1의 설명을 참조한다. 세부 사항은 본 명세서에서 반복하지 않는다. 방식 4: 사전 정의(Predefinition). 예를 들어, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은 표준에 사전 정의된다. 이 방식에 기초하여, 인코더와 디코더는 사전 정의에 기초하여 X개의 층의 각 층 및 이 층들 사이의 채널 정보 의 배열 방식을 결정할 수 있다. 이런 방식으로, 인코더와 디코더는 사전 정의에 기초하여 X개의 층의 각 층및 이 층들 사이의 채널 정보의 배열 방식을 직접 결정할 수 있다. 선택적으로, 인코더는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 AI 모델을 결정 할 수 있다. 인코더는 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여, 공동 압축 방식으로 채널 정보를 피드백 하는 것의 정확도와 같은 지표를 계산하여, 공동 압축에 사용되는 AI 모델을 결정하거나 업데이트할 수 있다. 예를 들어, 채널 정보를 공동 압축 방식으로 피드백하는 것의 정확도를 계산하기 위해, 인코더는 인코더에 채널 정보를 입력하여 압축된 정보를 획득한다. 그런 다음, 인코더는 압축된 정보를 참조 디코더에 입력하여 출력 결과를 획득하고, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 참조 디코더의 출력 결과를 파싱하여 X개의 층의 채널 고유벡터를 복원하며, 채널 고유벡터를 정확한 채널 고유벡터(즉, 인코더가 입력한 채널 정보에 대응하는 채널 고유벡터)와 비교하여, 공동 압축 방식으로 채널 정보를 피드백하는 것의 정 확도를 추정한다. 참조 디코더는 인코더 측에서 알려진 디코더를 나타낼 수 있으며, 참조 디코더에 의해 구현 되는 기능은 기본적으로 디코더 측의 디코더에 의해 구현되는 기능과 동일할 수 있다. 선택적으로, 방법은, 인코더와 디코더가 M개의 층 중 일부의 채널 정보에 대해 수행되는 공동 압축 동안 서로 다른 층의 채널 정보 시퀀스를 학습하는 것을 더 포함한다. 이 방식으로, 인코더는 공동 압축 동안 서로 다른 층의 채널 정보 시퀀스에 기초하여 공동 압축된 채널 정보를 압축할 수 있으며, 디코더는 공동 압축 동안 서로 다른 층의 채널 정보 시퀀스에 기초하여 디코더의 출력을 정확하게 파싱할 수 있다. 예를 들어, M=3이고, M개의 층의 채널 정보의 압축 방식은 [층 1, 층 2], [층 3]으로 표현된다고 가정하는데, 이는 제1 세트의 제1 층과 제2 층의 채널 정보에 대해 공동 압축이 수행되고, 제2 세트의 제3 층의 채널 정보에 대해 개별 압축이 수행됨을 나타낸다. 예를 들어, 인코더는 도 5의 모델 A를 사용하여 [층 1, 층 2] 세트에 대 응하는 채널 정보에 대해 공동 압축을 수행할 수 있고, 도 5의 모델 B를 사용하여 [층 3] 세트에 대응하는 채널 정보에 대해 개별 압축을 수행할 수 있다. 도 5는 M개의 층의 채널 정보를 압축하기 위한 인코딩과 디코딩의 다이어그램이다. 도 5에서 볼 수 있듯이, 인 코더 측과 디코더 측에 배치된 AI 모델은, 예컨대 모델 A와 모델 B의 두 가지 모델을 포함한다. 인코더가 도 5 의 모델 A를 사용하여 제1 층 및 제2 층의 채널 정보에 대해 공동 압축을 수행할 때, 디코더의 출력을 정확하게 파싱하기 위해, 디코더의 모델 A의 출력 시퀀스에서의 층 x와 층 y, 그리고 층 1과 층 2 사이의 대응 관계가 지 정될 필요가 있다. 다시 말해서, 디코더는 모델 A가 출력하는 채널 정보의 순서를 알아야 하는데, 예를 들면, [층 1, 층 2] 집합에서 층 1이 층 2 앞에 있고, 층 1이 층 2 앞에 있다는 것은 층 x가 층 1에 해당하고 층 y가 층 2에 대응한다는 것을 의미한다. 도 6은 디코더의 출력의 도면이다. 예를 들어, 모델 A의 디코더의 출력은 도 6의 에 표시되어 있으며, 레이 어-비포-서브밴드 배열 방식이다. 서로 다른 층의 채널 정보의 순서는 제1 층 1이 층 2보다 앞서는 것인데, 즉, 동일한 서브밴드에 서로 다른 층의 고유벡터가 층 1이 층 2보다 앞서는 순서로 인접하게 배열되어, 서브밴 드의 고유벡터 그룹을 형성하고, 그 다음에 서로 다른 서브밴드의 고유벡터 그룹이 순서대로 배열된다. 모델 B 의 디코더의 배열은 도 6의 에 도시되어 있는데, 즉, 한 층의 서로 다른 서브밴드의 고유벡터가 인접하게 배 열되어 있다. 인코더와 디코더는 다음과 같은 여러 가지 방식으로 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 학습할 수 있다. 방식 1: 인코더가 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 결정한다. 이 방식에 기초하여, 인코더는 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 결정할 수 있으며, 공동 압 축 동안 인코더가 결정한 서로 다른 층의 채널 정보의 순서에 기초하여 공동 압축된 채널 정보를 추가로 압축할 수 있다. 선택적으로, 방식 1에서 인코더는 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 디코더로 보낸다. 이런 방식으로, 디코더는 공동 압축 동안 서로 다른 층의 채널 정보의 순서에 기초하여 디코더의 출력을 정확하게 파 싱할 수 있다. 또한, 선택적으로 인코더는 디코더에 인덱스 값을 전송하며, 인덱스 값은 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 나타낸다. 예를 들어, 공동 압축 동안, 인덱스 값과 서로 다른 층의 채널 정보 의 순서 사이에 대응 관계가 있다. 따라서, 인코더는 인덱스 값을 디코더로 전송하고, 디코더는 인덱스 값과 공동 압축 동안 서로 다른 층의 채널 정보의 순서 사이의 대응 관계에 기초하여, 인덱스 값에 대응하는 순서를결정할 수 있다. 방식 2: 디코더가 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 결정한다. 이 방식에 기초하여, 디코더는 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 결정할 수 있으며, 그 다음 에 공동 압축 동안 디코더에 의해 결정된 서로 다른 층의 채널 정보의 순서에 기초하여 디코더의 출력을 정확하 게 파싱할 수 있다. 선택적으로, 방식 2에서, 디코더는 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 인코더로 보낸다. 이런 방식으로, 인코더는 공동 압축 동안 네트워크 디바이스에 의해 표시되는 서로 다른 층의 채널 정보의 순서에 기 초하여 공동 압축 채널 정보를 압축할 수 있다. 또한, 선택적으로, 디코더는 인덱스 값을 인코더로 전송하며, 인덱스 값은 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 나타낸다. 자세한 내용은 방식 1의 설명을 참 조한다. 세부 사항은 본 명세서에서 반복하지 않는다. 방법 3: 사전 정의. 예를 들어, 공동 압축 동안 서로 다른 층의 채널 정보의 순서는 표준에 미리 정의되어 있 다. 이 방법에 기초하여, 인코더와 디코더는 사전 정의에 기초하여 공동 압축 동안 서로 다른 층의 채널 정보의 순 서를 결정할 수 있다. 이 방법에 기초하여, 인코더와 디코더는 사전 정의에 기초하여 공동 압축 동안 서로 다 른 층의 채널 정보의 순서를 직접 결정할 수 있다. 전술한 방식은 설명을 위한 예이며, 이에 국한되지 않는다. 예를 들어, 다른 장치는 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 결정하고, 공동 압축 동안 서로 다른 층의 채널 정보의 순서를 인코더 및/또는 디코더 로 보낼 수 있다. 또한, 인코더가 디코더에게 다음 정보, 즉, M개의 층의 채널 정보의 압축 방식, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식, 및 공동 압축 동안 서로 다른 층의 채널 정보의 순서 중 적어도 두 가지 정보를 통지하는 경우, 이들 정보는 동일한 시그널링으로 전달되거나 또는 상이한 시그널링으로 전달될 수 있다. 이는 제한되지 않는다. 마찬가지로, 디코더가 다음 정보, 즉, M개의 층의 채널 정보의 압축 방식, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식, 및 공동 압축 동안 서로 다른 층의 채널 정보의 순서 중 적어도 두 가지 정보를 인코더에 통지하는 경우, 이들 정보는 동일한 신호로 전달되거나 상이한 신호로 전달될 수 있다. 이는 제한되지 않는다. 이해를 쉽게 할 수 있도록 하기 위해, 다음은 인코더가 단말 디바이스이고 디코더가 네트워크 디바이스인 예를 사용하여 다양한 절차에 대해 설명한다. 간결성을 위해, M개의 층의 채널 정보의 압축 방식을 이하에서는 간단 히 M개의 층의 압축 방식이라고 하고, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 이하에서 는 줄여서 배열 방식이라고 한다. 먼저, 솔루션 1에 적용할 수 있는 가능한 절차를 도 7을 참조하여 설명한다. 도 7은 본 출원의 실시예에 따른 통신 방법의 도면이다. 도 7에 도시된 바와 같이, 방법은 단말 디 바이스와 네트워크 디바이스 간의 상호 작용을 예로 사용하여 설명된다. 도 7에 도시된 방법은 본 출원의 실시예에 따른 단말 디바이스에 의한 압축 방식 결정 도면에 적용할 수 있다. 도 7에 도시된 방법은 다음 단계들을 포함할 수 있다. 선택적으로, 방법은 단계 701: 네트워크 디바이스가 단말 디바이스에 배열 방식을 전송하는 것을 포함한다. 단계 701에서, 네트워크 디바이스는 단말 디바이스에 배열 방식을 전송할 수 있다. 이런 방식으로, 단말 디바 이스가 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행해야 하는 경우, 단말 디바이스는 네트워크 디 바이스에 의해 표시된 배열 방식에 기초하여 공동 압축을 수행할 수 있다. 네트워크 디바이스가 단말 디바이스에 배열 방식을 전송하는 예는 본 명세서에서 설명을 위해 사용된 것으로 이 해될 수 있다. 도 2의 실시예에 설명된 바와 같이, 단말 디바이스는 또한 배열 방식을 결정할 수도 있고, 배열 방식은 미리 정의될 수도 있다. 배열 방식에 대해서는 도 2의 실시예에 대한 설명을 참조한다. 세부 사항은 본 명세서에서 반복하지 않는다. 선택적으로, 방법은 단계 702: 단말 디바이스가 적어도 하나의 AI 모델에 대한 정보를 네트워크 디바이스 로 전송하는 것을 포함한다. 단말 디바이스는 적어도 하나의 AI 모델에 대한 정보를 네트워크 디바이스로 전송하여, 네트워크 디바이스가 적 어도 하나의 AI 모델에 대응하는 AI 모델을 사용하여 단말 디바이스로부터의 정보를 처리할 수 있도록 한다. 예를 들어, 단말 디바이스는 적어도 하나의 AI 모델을 사용하여 채널 정보를 압축하고, 압축된 채널 정보를 네 트워크 디바이스로 전송한다. 네트워크 디바이스는 적어도 하나의 AI 모델에 대응하는 AI 모델을 사용하여 압 축된 채널 정보를 디코딩할 수 있다. 예를 들어, 단말 디바이스는 적어도 하나의 AI 모델을, 예컨대 AI 모델 목록의 형태로, 네트워크 디바이스에 전 송한다. 또 다른 예에서, 단말 디바이스는 적어도 하나의 AI 모델의 식별자를 네트워크 디바이스로 전송하고, 대응하는 AI 모델은 해당 식별자에 기초하여 학습될 수 있다. 적어도 하나의 AI 모델은 단말 디바이스에 배포 된 모든 AI 모델일 수도 있고, 또는 단말 디바이스의 모든 AI 모델 중 일부 AI 모델일 수도 있다. AI 모델의 일부는 단말 디바이스 측에서 사용할 수 있는 AI 모델일 수 있다. 이는 제한되지 않는다. 선택적으로, 단말 디바이스는 단말 디바이스에 배치된 AI 모델의 성능을 모니터링한다. 예를 들어, 단말 디바 이스는 모델 모니터링 단계(예컨대, 미리 설정된 기간)에서, 단말 디바이스에 배치된 AI 모델의 성능을 모니터 링한다. 예를 들어, 단말 디바이스가 모델 모니터링 단계에서 AI 모델의 성능이 임계값보다 낮아진 것을 발견 하면, 단말 디바이스는 AI 모델을 업데이트할 수 있다. AI 모델이 업데이트되기 전에, AI 모델은 일시적으로 사용할 수 없다. 선택적으로, 단말 디바이스는 단계 701에서 수신한 배열 방식에 기초하여 AI 모델을 결정하거 나 업데이트할 수 있다. 자세한 내용은 방법의 관련 설명을 참조한다. 세부 사항은 본 명세서에서 반복 하지 않는다. 가능한 구현예에서, 단말 디바이스는 주기적으로 적어도 하나의 AI 모델을 네트워크 디바이스로 보낸다. 또는, 다른 가능한 구현예에서, 미리 설정된 조건이 충족될 때, 단말 디바이스는 적어도 하나의 AI 모델을 네트워크 디바이스로 보낸다. 예를 들어, 미리 설정된 조건은 단말 디바이스의 AI 모델이 업데이트되는 것일 수도 있고, 미리 설정된 조건은 단말 디바이스가 네트워크 디바이스에서 보낸 배열 방식을 수신하는 것일 수도 있다. 703: 네트워크 디바이스가 단말 디바이스에 다운링크 참조 신호를 보낸다. 다운링크 참조 신호는 예를 들어, 채널 상태 정보 참조 신호(채널 상태 정보 참조 신호, CSI-RS)일 수 있다. 단말 디바이스는 다운링크 참조 신호를 수신하고, 수신된 다운링크 참조 신호에 기초하여 채널 추정을 수행하여 대응하는 채널 고유벡터를 획득한다. 다음은 채널 고유벡터의 계산 방식을 간략하게 설명한다. 다음 방식은 단지 가능한 구현 방식일 뿐이며, 본 출 원의 실시예의 보호 범위를 제한하지 않는다는 것을 이해할 수 있다. 단말 디바이스는 채널 추정 작업을 수행하고, 채널 정보를 획득한다. 단말 디바이스는 채널 정보를 처리하며, 채널 정보의 차원은 [Ntx, Nrx, NRB]이다. 여기서 Ntx는 송신단의 안테나 수 또는 안테나 포트 수를 나타내고, Nrx는 수신단의 안테나 수 또는 안테나 포트 수를 나타내며, NRB는 주파수 영역 유닛의 수를 나타내는데, 예를 들 면, NRB는 RB의 수를 나타낸다. [Ntx, Nrx, NRB]-차원의 원 채널은 SVD 연산을 통해 M개의 [Ntx, Nsb]-차원의 고유 부분공간으로 변환되며, 여기서 M은 층 수(또는 스트림 수, 또는 랭크 수라고도 함)를 나타내고, Nsb는 주파수 영역 유닛의 수를 나타내는데, 예컨대, Nsb는 주파수 영역 서브밴드의 수를 나타낸다. 주파수 영역 서브밴드의 일반적인 수량은 1 RB, 2 RB 또는 4 RB이다. 예를 들어, 4 RB가 사용되고, Nsb=NRB/4이다. NRB와 Nsb는 모두 주 파수 영역 유닛의 수를 나타내며, NRB와 Nsb는 서로 다른 값에 대응할 수 있다. 전술한 바와 같이, NRB는 RB의 수량을 나타내고, Nsb는 서브밴드의 수량을 나타낸다. 서로 다른 층의 처리는 다음과 같다. L번째 층의 특정 처리 과정은 다음과 같다. 각 서브밴드 m은 T RB를 포함하고, T RB의 채널은 결합되어 등가 채널을 계산한다. i번째 RB의 채널은 Hi라고 가정하고, 서브밴드의 등가 채널은 다음과 같이 표시된다. 에 대해 SVD 분해를 수행하여 다음 결과를 얻는다."}
{"patent_id": "10-2025-7010078", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "앞의 공식에서, 각 Hi의 차원은 (Ntx, Nrx)이고, 의 차원은 (Ntx, Ntx)이며, L번째 층에서 m번째 서브밴드의 채널 고유벡터 값은 의 L번째 열이고, 서브밴드의 차원은 (Ntx, 1)인데, 즉, L번째 층에서 m번째 서브밴드의 고유벡터는 이다. 여기서, 는 값이 인 L번째 열을 나타낸다. 여기에서 콜론 \":\"은 단 지 가능한 표현 방식일 뿐이며, 의 L번째 열을 나타낼 수 있는 어떠한 표현 방식도 본 출원의 이 실시예에 적 용 가능하다. 각 층에 대응하는 채널 고유벡터는 전술한 작업을 수행함으로써 획득할 수 있다. 선택적으로, 방법은 단계 704: 단말 디바이스가 층의 수 M을 결정하는 것을 포함한다. 이런 방식으로, M개의 층의 압축 방식을 결정할 때, 단말 디바이스는 층의 수 M을 추가로 참조할 수 있다. 다운링크 참조 신호를 수신한 후, 단말 디바이스는 채널 추정 결과에 기초하여 층의 수를 결정할 수 있다. 예 를 들어, 단말 디바이스는 채널 추정 결과와 일부 통신 파라미터(예컨대, 신호 대 간섭 플러스 잡음 비)에 기초 하여 단말 디바이스에 적합한 층 수를 결정할 수 있다. 단말 디바이스에 의해 결정된 층 수는 M이고, M은 1보 다 큰 정수라고 가정한다. 705: 단말 디바이스가 M개의 층의 압축 방식을 결정한다. 단말 디바이스는 단말 디바이스의 기능 정보, 네트워크 디바이스의 기능 정보, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 공동 압축 수행 기능, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 개별 압축 수행 기능, M의 값 중 적어도 하나에 기초하여 M개의 층의 압축 방식을 결정할 수 있다. 네트워크 디바이스의 기능 정보는 네트워크 디바이스에 의해 단말 디바이스로 전송될 수 있는데, 예를 들면, 단계 701에서의 배열 방 식과 함께 단말 디바이스로 전송되거나(즉, 네트워크 디바이스의 기능 정보 및 배열 방식이 하나의 시그널링으 로 전달됨), 또는 단말 디바이스로 개별적으로 전송될 수 있다. 또는, 네트워크 디바이스의 기능 정보는 단말 디바이스에 의해 추정될 수 있는데, 예를 들면, 과거 통신 상태에 기초하여 추정될 수 있다. 구체적인 결정 방 식은 전술한 방법의 관련 설명을 참조한다. 세부 사항은 본 명세서에서 반복하지 않는다. M개의 층의 압축 방식은 집합을 사용하여 표현될 수 있다. 예를 들어, M=3이라고 가정한다. 예를 들어, M 층 의 압축 방식은 [층 1], [층 2], [층 3]일 수 있는데, 즉, 서로 다른 층의 채널 고유벡터에 대해 개별 압축이 수행된다. 또 다른 예에서, M개의 층의 압축 방식은 [층 1, 층 2], 및 [층 3]일 수 있는데, 즉, 제1 층 및 제2 층의 채널 고유벡터에 대해 공동 압축이 수행되고, 제3 층의 채널 고유벡터에 대해 개별 압축이 수행된다. 또 다른 예에서, M개의 층의 압축 방식은 [층 1, 층 2, 층 3]일 수 있는데, 즉, 세 층의 채널 고유벡터에 대해 공 동 압축이 수행된다. 706: 단말 디바이스는 M개의 층의 압축 방식을 네트워크 디바이스로 보낸다. 단말 디바이스는 M개의 층의 압축 방식을 네트워크 디바이스에 피드백하여, 네트워크 디바이스가 M개의 층의 압 축 방식에 기초하여 대응하는 AI 모델을 선택하여 디코딩할 수 있도록 한다. 선택적으로, 단말 디바이스는 또한 M의 값을 네트워크 디바이스로 전송한다. 예를 들어, 방법이 단계 704 를 포함하는 경우, 단말 디바이스는 또한 M의 값을 네트워크 디바이스로 전송한다. M개의 층의 압축 방식과 M 의 값은 동일한 시그널링으로 전달될 수도 있고, 또는 다른 시그널링으로 전달될 수도 있다. 이는 제한되지 않 는다. 선택적으로, 단말 디바이스는 공동 압축 동안 서로 다른 층들의 채널 정보의 순서를 네트워크 디바이스에 추가 로 전송한다. 공동 압축 동안, 서로 다른 층들의 채널 정보의 순서와 M개의 층의 압축 방식 및 M의 값 중 하나 이상이 동일한 시그널링으로 전달되거나, 또는 다른 시그널링으로 전달될 수 있다. 이는 제한되지 않는다. 707: 단말 디바이스가 M개의 층의 압축 방식에 기초하여 M개의 층의 채널 정보를 압축하여 N개의 압축된 정보를 획득한다. 예를 들어, 단말 디바이스에 의해 결정되는 M개의 층의 압축 방식은 [층 1, 층 2], [층 3]이다. 따라서, 단말 디바이스는 도 5의 모델 A를 사용하여 제1층 및 제2층의 채널 고유벡터에 대해 공동 압축을 수행할 수 있고, 단 말 디바이스는 도 5의 모델 B를 사용하여 제3층의 채널 고유벡터에 대해 개별 압축을 수행하여, 두 개의 압축된 정보를 획득할 수 있다. 하나의 압축된 정보는 제1 층 및 제2 층의 채널 고유벡터의 공동 압축 정보에 대응하 고, 다른 압축된 정보는 제3 층의 채널 고유벡터의 압축 정보에 대응한다. 또한, 단말 디바이스는 단계 701에서 수신된 배열 방식 및 서로 다른 층들의 채널 정보의 순서에 기초하여 압축 을 수행할 수 있다. 예를 들어, 배열 방식이 레이어-비포-서브밴드 배열 방식이면, 서로 다른 층들의 채널 정 보의 순서는 층 1이 층 2보다 앞에 오는 순서인데, 즉, 동일한 서브밴드에 있는 서로 다른 층들의 고유벡터가 층 1이 층 2보다 앞에 오는 순서로 인접하게 배열된다. 이 경우, 단말 디바이스에 의해 AI 모델에 입력될 수 있는, 제1 층과 제2 층의 채널 고유벡터의 배열 방식은 레이어-비포-서브밴드 배열 방식이고, 동일한 서브밴드 내의 서로 다른 층들의 고유벡터는 층 1이 층 2보다 앞에 오는 순서로 인접하게 배열된다. 또 다른 예에서, 배 열 방식이 서브밴드-비포-레이어 배열 방식인 경우, 서로 다른 층들의 채널 정보의 순서는 층 1이 층 2보다 앞 에 오는 순서인데, 즉, 같은 층에 있는 서로 다른 서브밴드의 고유벡터가 인접하게 배열되고, 서로 다른 층들이 층 1이 층 2보다 앞에 오는 순서로 배열된다. 이 경우, 단말 디바이스에 의해 AI 모델에 입력될 수 있는, 제1 층 및 제2 층의 채널 고유벡터의 배열 방식은 서브밴드-비포-레이어 배열 방식이고, 서로 다른 층들은 층 1이 층 2보다 앞에 오는 순서로 배열된다. 서로 다른 층들의 채널 정보의 순서는 네트워크 디바이스에 의해 표시될 수도 있고(예컨대, 단계 701에서 표시되거나 또는 별도로 표시됨), 또는 단말 디바이스에 의해 결정되거나 사전 정의될 수도 있다. 자세한 내용은 방법의 관련 설명을 참조한다. 세부 사항은 본 명세서에서 반복하지 않는다. 708: 단말 디바이스가 N개의 압축된 정보를 네트워크 디바이스로 보낸다. 709: 네트워크 디바이스가 M개의 층의 압축 방식에 기초하여 N개의 압축된 정보를 디코딩해서 M개의 층의 채널 정보를 획득한다. 위 예가 여전히 예로서 사용된다. M개의 층의 압축 방식은 [층 1, 층 2], 및 [층 3]이라고 가정하면, 네트워크 디바이스는 단말 디바이스가 c1과 c2로 제각기 표시된 두 개의 압축된 정보를 전송한다는 것을 알 수 있다. 또 한, 네트워크 디바이스는 c1이 [층 1, 층 2]의 공동 압축 정보에 대응한다는 것을 학습할 수 있으며, 따라서 두 층에 대해 디코더(예컨대, 도 5의 모델 A)를 사용하여 디코딩을 수행할 수 있고, c2가 [층 3]의 압축 정보에 대 응한다는 것을 학습할 수 있으며, 따라서 단일 층에 대해 디코더(예컨대, 도 5의 모델 B)를 사용하여 디코딩을 수행할 수 있다. 또한, 네트워크 디바이스는 공동 압축 동안 서로 다른 층의 채널 정보의 순서와 모델 A 및 모 델 B의 디코더 출력의 배열 방식에 기초하여, 모델 A에 c1을 입력함으로써 도 8에 도시된 채널 정보가 획득되고, 모델 B에 c2를 입력함으로써 도 9에 도시된 채널 정보가 획득된다는 것을 학습할 수 있다. 이상, 도 7에 도시된 단계 701 내지 709를 참조하여 단말 디바이스가 압축 방식을 결정하는 절차의 예를 설명하 였다. 전술한 단계들은 설명을 위한 예에 불과하며, 엄격하게 제한되는 것은 아님을 이해해야 한다. 또한, 전 술한 프로세스의 순번은 실행 순서를 의미하지 않는다. 프로세스의 실행 순서는 프로세스의 기능과 내부 논리 에 기초하여 결정되어야 하며, 본 출원의 실시예의 구현 프로세스에 대한 어떠한 제한도 구성하지 않아야 한다. 예를 들어, 단계 701과 단계 706은 동시에 수행될 수도 있다. 구체적으로, 단말 디바이스는 M개의 층의 배열 방식, 압축 방식, 및 M의 값을 네트워크 디바이스로 전송한다. 또한, 배열 방식, M개의 층의 압축 방식, 및 M 의 값 중 하나 이상은 동일한 시그널링으로 전달될 수도 있고, 상이한 시그널링으로 전달될 수 있다. 이는 제 한되지 않는다. 또한, 예를 들어, 단계 701 및 702는 모델 배치 단계 또는 모델 모니터링 단계로 간주될 수 있고, 단계 703 내 지 709는 모델 추론 단계 또는 모델 실행 단계로 간주될 수 있다. 전술한 기술 솔루션에 기초하여, 단말 디바이스는 M개의 층의 압축 방식을 결정할 수 있는데, 예를 들면, 단말 디바이스의 컴퓨팅 능력, 이용 가능한 AI 모델 등에 기초하여 적절한 압축 방식을 동적으로 선택할 수 있다. 단말 디바이스는 네트워크 디바이스에 의해 표시된 배열 방식, 단말 디바이스에 의해 결정된 압축 방식, 및 서 로 다른 층들의 채널 정보의 순서에 기초하여 압축을 수행할 수 있다. 디코더는 배열 방식, 압축 방식, 및 서 로 다른 층들의 채널 정보의 순서에 기초하여 디코딩을 수행하므로, 네트워크 디바이스 측에서 디코딩에 사용되 는 AI 모델이 단말 디바이스 측에서 압축에 사용되는 AI 모델과 정렬될 수 있고, 네트워크 디바이스 측이 디코딩에 사용되는 AI 모델의 출력을 정확하게 파싱할 수 있다. 다음은 도 10을 참조하여, 솔루션 2에 적용될 수 있는 가능한 절차를 설명한다. 도 10은 본 출원의 실시예에 따른 통신 방법의 도면이다. 도 10에 도시된 바와 같이, 방법은 단말 디바이스와 네트워크 디바이스 사이의 상호작용을 예로 들어 설명한다. 도 10에 도시된 방법은 본 출원 의 실시예에 따른 네트워크 디바이스에 의한 압축 방식 결정의 도면에 적용 가능하다. 도 10에 도시된 방법 은 다음 단계들을 포함할 수 있다. 선택적으로, 방법은 단계 1001: 네트워크 디바이스가 단말 디바이스에 배열 방식을 전송하는 것을 포함한 다. 선택적으로, 방법은 단계 1002: 단말 디바이스가 적어도 하나의 AI 모델에 대한 정보를 네트워크 디바이 스로 전송하는 것을 포함한다. 1003: 네트워크 디바이스가 단말 디바이스에 다운링크 참조 신호를 보낸다. 선택적으로, 방법은 단계 1004: 단말 디바이스가 층의 수 M을 결정하는 것을 포함한다. 단계 1001 내지 1004는 단계 701 내지 704와 유사하며, 자세한 내용은 반복하지 않는다. 선택적으로, 방법은 단계 1005를 포함한다. 단말 디바이스는 M 값을 네트워크 디바이스로 보낸다. 1006: 네트워크 디바이스가 M개의 층의 압축 방식을 결정한다. 네트워크 디바이스는 단말 디바이스의 기능 정보, 네트워크 디바이스의 기능 정보, M개의 층의 채널 정보 중 일 부 층의 채널 정보에 대한 공동 압축 수행 성능, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 개별 압 축 수행 성능, M의 값 중 적어도 하나에 기초하여 M개의 층의 압축 방식을 결정할 수 있다. 단말 디바이스의 기능 정보는 단말 디바이스에 의해 네트워크 디바이스로 전송될 수 있는데, 예를 들면, 단계 1002에서 적어도 하나의 AI 모델과 함께 네트워크 디바이스로 전송될 수도 있고(즉, 단말 디바이스의 기능 정보와 적어도 하나의 AI 모델이 하나의 시그널링으로 전달됨), 또는 단계 1005에서 층의 수와 함께 네트워크 디바이스로 전송될 수도 있으며(즉, 단말 디바이스의 기능 정보와 층 수는 하나의 시그널링으로 전달됨), 또는 네트워크 디바이스에 개 별적으로 전송될 수도 있다. 또는, 단말 디바이스의 기능 정보는 네트워크 디바이스에 의해 추정될 수 있는데, 예를 들어, 과거 통신 상태에 기초하여 추정되거나, 또는 단말 디바이스에 의해 전송된 적어도 하나의 AI 모델 에 대한 정보에 기초하여 추정될 수 있다. 구체적인 결정 방식은 전술한 방법의 관련 설명을 참조한다. 세부 사항은 본 명세서에서 반복하지 않는다. 1007: 네트워크 디바이스가 M개의 층의 압축 방식을 단말 디바이스로 보낸다. M개의 층의 압축 방식은 집합을 사용하여 표현될 수 있다. 예를 들어, M=3이라고 가정한다. 예를 들어, M 층 의 압축 방식은 [층 1], [층 2], [층 3]일 수 있는데, 즉, 서로 다른 층의 채널 고유벡터에 대해 개별 압축이 수행된다. 또 다른 예에서, M개의 층의 압축 방식은 [층 1, 층 2], 및 [층 3]일 수 있는데, 즉, 제1 층 및 제2 층의 채널 고유벡터에 대해 공동 압축이 수행되고, 제3 층의 채널 고유벡터에 대해 개별 압축이 수행된다. 또 다른 예에서, M개의 층의 압축 방식은 [층 1, 층 2, 층 3]일 수 있는데, 즉, 세 층의 채널 고유벡터에 대해 공 동 압축이 수행된다. 1008: 단말 디바이스가 M개의 층의 압축 방식에 기초하여 M개의 층의 채널 정보를 압축하여 N개의 압축된 정보 를 획득한다. 단말 디바이스는 단계 1007에서 수신되는 M개의 층의 압축 방식에 기초하여 M개의 층의 채널 정보를 압축할 수 있다. 단계 1008은 단계 707과 유사하며, 자세한 내용은 반복하지 않는다. 1009: 단말 디바이스가 N개의 압축된 정보를 네트워크 디바이스로 보낸다. 1010: 네트워크 디바이스는 M개의 층의 압축 방식에 기초하여 N개의 압축된 정보를 디코딩하여 M개의 층의 채널 정보를 획득한다. 네트워크 디바이스는 네트워크 디바이스에 의해 결정된 M개의 층의 압축 방식에 기초하여 단계 1009에서 수신된 N개의 압축된 정보를 디코딩할 수 있다.단계 1010은 단계 709와 유사하며, 세부 사항은 여기서 반복하지 않는다. 이상, 도 10에 도시된 단계 1001 내지 1010과 관련하여, 네트워크 디바이스가 압축 방식을 결정하는 절차의 예 를 설명하였다. 전술한 단계들은 설명을 위한 예에 불과하며, 엄격하게 제한되는 것은 아님을 이해해야 한다. 또한, 전술한 프로세스의 순번은 실행 순서를 의미하지 않는다. 프로세스의 실행 순서는 프로세스의 기능과 내 부 논리에 기초하여 결정되어야 하며, 본 출원의 실시예의 구현 프로세스에 대한 어떠한 제한도 구성하지 않아 야 한다. 예를 들어, 단계 1001과 단계 1007은 동시에 수행될 수도 있는데, 즉, 네트워크 디바이스는 M개의 층 의 배열 방식 및 압축 방식을 단말 디바이스로 전송한다. 또한, M개의 층의 배열 방식과 압축 방식은 동일한 시그널링으로 전달될 수도 있고, 또는 상이한 시그널링으로 전달될 수도 있다. 이는 제한되지 않는다. 또한, 예를 들어, 단계 1001 및 1002는 모델 배포 단계 또는 모델 모니터링 단계로 간주될 수 있으며, 단계 1003 내지 1010은 모델 추론 단계 또는 모델 실행 단계로 간주될 수 있다. 전술한 기술 솔루션에 기초하여, 네트워크 디바이스는 M개의 층의 압축 방식을 결정할 수 있는데, 예를 들면, 네트워크 디바이스의 컴퓨팅 능력, 이용 가능한 AI 모델 등에 기초하여 적절한 압축 방식을 동적으로 선택하고, 압축 방식을 단말 디바이스에 표시할 수 있다. 단말 디바이스는 네트워크 디바이스에 의해 표시된 배열 방식, 네트워크 디바이스에 의해 표시된 압축 방식, 및 서로 다른 층의 채널 정보의 순서에 기초하여 압축을 수행할 수 있다. 디코더는 배열 방식, 압축 방식, 및 서로 다른 층들의 채널 정보의 순서에 기초하여 디코딩을 수행하 므로, 네트워크 디바이스 측에서 디코딩에 사용되는 AI 모델이 단말 디바이스 측에서 압축에 사용되는 AI 모델 과 정렬될 수 있고, 네트워크 디바이스 측이 디코딩에 사용되는 AI 모델의 출력을 정확하게 파싱할 수 있다. 도 7과 도 10의 실시예에서, 단말 디바이스와 네트워크 디바이스 사이의 상호 작용은 주로 설명을 위한 예로서 사용된다는 것을 이해할 수 있을 것이다. 본 출원은 이에 국한되지 않는다. 단말 디바이스는 수신단 디바이스 로 대체될 수 있으며, 수신단 디바이스는 단말 디바이스 또는 네트워크 디바이스일 수 있다. 네트워크 디바이 스는 송신단 디바이스로 대체될 수 있으며, 송신단 디바이스는 단말 디바이스 또는 네트워크 디바이스일 수 있 다. 예를 들어, \"단말 디바이스\"는 \"제1 단말 디바이스\"로 대체될 수 있고, \"네트워크 디바이스\"는 \"제2 단말 디바이스\"로 대체될 수 있다. 또한, 전술한 실시예들 중 일부에서, 하나의 채널 정보 또는 적어도 두 개의 채널 정보가 언급된다는 것을 이해 할 수 있을 것이다. 하나의 채널 정보는 한 층의 채널 정보를 나타내는데, 즉, 하나의 채널 정보는 한 층의 채 널 정보로 대체될 수도 있다. 마찬가지로, 적어도 두 개의 채널 정보는 적어도 두 개의 층의 채널 정보를 나타 내는데, 즉, 적어도 두 개의 채널 정보는 적어도 두 개의 층의 채널 정보로 대체될 수도 있다. 또한, 전술한 실시예들 중 일부에서는 단말 디바이스가 네트워크 디바이스에 대한 AI 모델에 대한 정보를 제공 하는 예가 설명에 사용된다는 것을 알 수 있다. 이는 제한되지 않는다. 예를 들어, 단말 디바이스는 네트워크 디바이스에 압축 방식을 제공하고, 네트워크 디바이스는 압축 방식에 기초하여 해당 AI 모델을 결정할 수 있다. 마찬가지로, 단말 디바이스는 네트워크 디바이스에 AI 모델에 대한 정보를 제공하고, 네트워크 디바이스는 단말 디바이스에서 제공하는 AI 모델에 대한 정보에 기초하여 압축 방식을 알 수도 있다. 본 출원의 실시예에 있는 일부 선택적 특징은 일부 시나리오에서 다른 특징과 독립적이거나, 일부 시나리오에서 다른 특징과 결합될 수 있다는 것을 추가로 이해할 수 있다. 이는 제한되지 않는다. 본 출원의 실시예에서의 솔루션은 사용을 위해 적절하게 결합될 수 있으며, 실시예에서의 용어에 대한 설명 또 는 서술은 실시예에서 상호 참조되거나 설명될 수 있다는 것을 또한 이해할 수 있을 것이다. 이는 제한되지 않 는다. 전술한 방법 실시예에서, 인코더에 의해 구현되는 방법 및 동작은 인코더의 구성요소(예컨대, 칩 또는 회로)에 의해 대안적으로 구현될 수 있다는 것을 또한 이해할 수 있다. 또한, 디코더에 의해 구현되는 방법 및 동작은 대안적으로 디코더의 구성요소(예컨대, 칩 또는 회로)에 의해 구현될 수 있다. 이는 제한되지 않는다. 본 출원의 실시예에서 제공되는 방법은 도 2 내지 도 10을 참조하여 앞에서 상세히 설명하였다. 다음은 도 11 내지 도 13을 참조하여 본 출원의 실시예에서의 데이터 전송 장치를 상세히 설명한다. 장치 실시예의 설명은 방법 실시예의 설명에 대응한다는 것을 이해해야 한다. 따라서, 상세히 설명되지 않은 내용은 앞의 방법 실시 예들을 참조한다. 간결성을 위해, 상세한 내용은 여기서 반복하지 않는다. 도 11은 본 출원의 실시예에 따른 통신 장치의 블록도이다. 장치는 트랜시버 유닛과 처리 유닛을 포함한다. 트랜시버 유닛은 대응하는 통신 기능을 구현하도록 구성될 수 있다. 트랜시버유닛은 통신 인터페이스 또는 통신 유닛이라고도 한다. 처리 유닛은 데이터 처리를 수행하도록 구 성될 수 있다. 선택적으로, 장치는 저장 유닛을 더 포함할 수 있다. 저장 유닛은 명령어 및/또는 데이터를 저장하도록 구성될 수 있다. 처리 유닛은 저장 유닛 내의 명령어 및/또는 데이터를 판독하여, 장치가 전술한 방법 실시 예를 구현할 수 있게 할 수 있다. 설계에서, 장치는 전술한 방법 실시예에서 인코더가 수행하는 단계 또는 절차, 예를 들면, 도 2에 도시된 실시예에서 인코더가 수행하는 단계 또는 절차, 도 7 또는 도 10에 도시된 실시예에서 단말 디바이스가 수행하 는 단계 또는 절차를 수행하도록 구성된다. 트랜시버 유닛은 전술한 실시예에서 인코더 측에서의 트랜시 버 관련 동작을 수행하도록 구성되고, 처리 유닛은 전술한 실시예에서 인코더 측에서의 처리 관련 동작을 수행하도록 구성된다. 가능한 구현예에서, 처리 유닛은 적어도 두 개의 인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축하도록 구성되어, N개의 압축된 정보를 획득하며, 여기서, N개의 압축된 정보 각각은 적어도 두 개의 AI 모 델 중 적어도 하나를 사용하여 M개의 층의 채널 정보에서 일부 층의 채널 정보를 압축함으로써 획득되며, N과 M 은 1보다 큰 정수이고, N은 M보다 작다. 트랜시버 유닛은 N개의 압축된 정보를 디코더로 전송하도록 구 성된다. 예를 들어, N개의 압축된 정보는 적어도 하나의 제1 압축된 정보와 적어도 하나의 제2 압축된 정보를 포함한다. 제1 압축된 정보는 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용하여 M개의 층의 채널 정보 중 적어도 두 개 의 층의 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, 제2 압축된 정보는 적어도 두 개의 AI 모델 중 제2 AI 모델을 사용하여 M개의 층의 채널 정보 중 한 개의 층의 채널 정보에 대해 개별 압축을 수행함으로써 획 득된다. 또 다른 예에서, M개의 층의 채널 정보의 압축 방식은 다음 정보들, 즉, 인코더의 컴퓨팅 자원, 디코더의 컴퓨 팅 자원, 인코더의 AI 모델, 디코더의 AI 모델, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 공동 압 축 수행의 성능, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 개별 압축 수행의 성능 및 M의 값 중 적 어도 하나에 기초하여 결정된다. M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 M개의 층 의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 또 다른 예에서, 처리 장치는 M개의 층의 채널 정보의 압축 방식을 결정하도록 추가로 구성되는데, 여기 서 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나 또는 M개의 층의 채널 정보의 압축 방식은 공 동 압축 및 개별 압축을 포함한다. 또 다른 예에서, 트랜시버 유닛은 또한 M개의 층의 채널 정보의 압축 방식을 디코더로 전송하도록 구성된 다. 또 다른 예에서, 트랜시버 유닛은 또한 M개의 층의 채널 정보의 압축 방식을 수신하도록 구성되는데, 여 기서 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나 또는 M개의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 또 다른 예에서, 트랜시버 유닛은 또한 디코더로부터 참조 신호를 수신하도록 구성된다. 처리 유닛 은 또한 참조 신호에 기초하여 채널 측정을 수행하여 M개의 층의 채널 정보를 획득하도록 구성된다. 또 다른 예에서, 처리 유닛은 또한 채널 측정 결과에 기초하여 M의 값을 결정하도록 구성된다. 또 다른 예에서, 처리 유닛은 구체적으로, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 제1 AI 모델을 결정하고 - 여기서, 적어도 두 개의 AI 모델은 제1 AI 모델을 포함하고, M개의 층은 X 개의 층을 포함하며, X는 1보다 크고 M보다 작은 정수임 -, 제1 AI 모델을 사용하여 X개의 층의 채널 정보에 대 한 공동 압축을 수행하여 제1 압축된 정보를 얻도록 구성되며, 여기서 N개의 압축된 정보가 제1 압축된 정보를 포함하고, X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은 동일한 층에 있는 서로 다른 서브밴드 의 채널 정보의 인접 배열, 및 동일한 서브밴드에 있는 서로 다른 층의 채널 정보의 인접 배열 중 어느 하나를 포함한다. 또 다른 예에서, 트랜시버 유닛은 또한, 디코더로부터 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 수신하거나, 또는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 디코더로 전송하도록 구성된다. 또 다른 예에서, 트랜시버 유닛은 또한 제1 정보를 디코더로 전송하도록 구성되며, 여기서 M개의 층의 채 널 정보 중 적어도 두 층의 채널 정보에 대해 공동 압축이 수행되는 동안 서로 다른 층의 채널 정보의 순서를 나타낸다. 또 다른 예에서, 인코더는 단말 디바이스이고, 디코더는 네트워크 디바이스이다. 또 다른 설계에서, 장치는 전술한 방법 실시예에서 디코더가 수행하는 단계 또는 절차, 예를 들면, 도 2 에 도시된 실시예에서 디코더가 수행하는 단계 또는 절차, 및 도 7 또는 도 10에 도시된 실시예에서 네트워크 디바이스가 수행하는 단계 또는 절차를 수행하도록 구성된다. 트랜시버 유닛은 전술한 실시예에서 디코 더 측에서 트랜시버 관련 동작을 수행하도록 구성되고, 처리 유닛은 전술한 실시예에서 디코더 측에서 처 리 관련 동작을 수행하도록 구성된다. 가능한 구현예에서, 트랜시버 유닛은 인코더로부터 N개의 압축된 정보를 수신하도록 구성되며, 여기서 N 개의 압축된 정보는 적어도 두 개의 인공지능(AI) 모델을 사용하여 M개의 층의 채널 정보를 압축함으로써 획득 되고, 각 N개의 압축된 정보는 적어도 두 개의 AI 모델 중 적어도 하나를 사용하여 M개의 층의 채널 정보 중 일 부 층의 채널 정보를 압축함으로써 획득되며, N과 M은 1보다 큰 정수이고, N은 M보다 작다. 처리 유닛은 N개의 압축된 정보를 디코딩하여 M개의 층의 채널 정보를 획득하도록 구성된다. 예를 들어, N개의 압축된 정보는 적어도 하나의 제1 압축된 정보와 적어도 하나의 제2 압축된 정보를 포함한다. 제1 압축된 정보는 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용하여 M개의 층의 채널 정보 중 적어도 두 개 의 층의 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, 제2 압축된 정보는 적어도 두 개의 AI 모델 중 제2 AI 모델을 사용하여 M개의 층의 채널 정보 중 한 개의 층의 채널 정보에 대해 개별 압축을 수행함으로써 획 득된다. 또 다른 예에서, M개의 층의 채널 정보의 압축 방식은 다음 정보들, 즉, 인코더의 컴퓨팅 자원, 디코더의 컴퓨 팅 자원, 인코더의 AI 모델, 디코더의 AI 모델, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 공동 압 축 수행의 성능, M개의 층의 채널 정보 중 일부 층의 채널 정보에 대한 개별 압축 수행의 성능 및 M의 값 중 적 어도 하나에 기초하여 결정된다. M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 M개의 층 의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 또 다른 예에서, 처리 유닛은 구체적으로 M개의 층의 채널 정보의 압축 방식에 기초하여 N개의 압축된 정 보를 디코딩하도록 구성되는데, 여기서 M개의 층의 채널 정보의 압축 방식은 공동 압축을 포함하거나, 또는 M개 의 층의 채널 정보의 압축 방식은 공동 압축 및 개별 압축을 포함한다. 또 다른 예에서, 처리 유닛은 또한 M개의 층의 채널 정보의 압축 방식을 결정하도록 구성된다. 또 다른 예에서, 트랜시버 유닛는 또한 M개의 층의 채널 정보의 압축 방식을 인코더로 전송하도록 구성된 다. 또 다른 예에서, 트랜시버 유닛은 또한 인코더로부터 M개의 층의 채널 정보의 압축 방식을 수신하도록 구 성된다. 또 다른 예에서, 처리 유닛은 구체적으로 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식에 기초하여 제1 압축된 정보를 디코딩하여 X개의 층의 채널 정보를 획득하도록 구성되며, 여기서 제1 압축된 정보 는 적어도 두 개의 AI 모델 중 제1 AI 모델을 사용하여 X개의 층의 채널 정보에 대해 공동 압축을 수행함으로써 획득되고, N개의 압축된 정보는 제1 압축된 정보를 포함하고, M개의 층은 X개의 층을 포함하며, X는 1보다 크고 M보다 작은 정수이다. X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식은 동일한 층에서의 서로 다 른 서브밴드의 채널 정보의 인접한 배열 및 동일한 서브밴드에서의 서로 다른 층의 채널 정보의 인접한 배열을 포함한다. 또 다른 예에서, 트랜시버 유닛은 또한 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 인 코더로 전송하거나, 인코더로부터 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식을 수신하도록 구 성된다. 또 다른 예에서, 트랜시버 유닛은 또한 M개의 층의 채널 정보 중 적어도 두 개의 층의 채널 정보에 대해 공동 압축을 수행하는 동안 서로 다른 층의 채널 정보의 순서를 나타내는 제1 정보를 인코더로부터 수신하도록구성된다. 또 다른 예에서, 인코더는 단말 디바이스이고, 디코더는 네트워크 디바이스이다. 유닛들이 전술한 대응 단계를 수행하는 구체적인 프로세스는 전술한 방법 실시예에 상세히 설명되어 있다는 것 을 이해해야 한다. 간결성을 위해, 상세한 내용은 여기서 반복하지 않는다. 본 명세서에서 장치는 기능 단위 유닛의 형태로 제시된다는 것을 이해해야 한다. 여기서 \"유닛\"이라는 용어는 하나 이상의 소프트웨어 또는 펌웨어 프로그램을 실행하도록 구성된 애플리케이션 특정 집적 회로 (application-specific integrated circuit, ASIC), 전자 회로, 프로세서(예컨대, 공유 프로세서, 전용 프로세 서 또는 그룹 프로세서), 메모리, 병합 논리 회로 및/또는 설명된 기능을 지원하는 다른 적절한 구성 요소를 지 칭할 수 있다. 선택적 예에서, 장치는 구체적으로 전술한 실시예에서 제1 단말 디바이스일 수 있으며, 전술한 방법 실시예에서 제1 단말 디바이스에 대응하는 절차 및/또는 단계를 수행하도록 구성될 수 있음을 당업 자는 이해할 수 있을 것이다. 또는, 장치는 구체적으로 전술한 실시예에서 제2 단말 디바이스일 수 있으 며, 전술한 방법 실시예에서 제2 단말 디바이스에 대응하는 절차 및/또는 단계를 수행하도록 구성될 수 있다. 반복을 피하기 위해, 상세한 설명은 여기서 다시 설명하지 않는다. 전술한 솔루션에서 장치는 전술한 방법에서 제1 단말 디바이스에 의해 수행되는 대응하는 단계를 구현하 는 기능을 갖거나, 또는 전술한 솔루션의 장치는 전술한 방법에서 제2 단말 디바이스에 의해 수행되는 대 응하는 단계를 구현하는 기능을 갖는다. 이들 기능은 하드웨어에 의해 구현될 수도 있고, 또는 대응하는 소프 트웨어를 실행함으로써 하드웨어에 의해 구현될 수도 있다. 하드웨어 또는 소프트웨어는 전술한 기능에 대응하 는 하나 이상의 모듈을 포함한다. 예를 들어, 트랜시버 유닛은 트랜시버로 대체될 수 있다(예컨대, 트랜시버 유닛의 송신 유닛은 송신기로, 트랜시버 유닛의 수신 유닛은 수신기로 대체될 수 있다). 처리 유닛과 같은 다 른 유닛은 각 방법 실시예에서 송수신 동작 및 관련 처리 동작을 개별적으로 수행하는 프로세서로 대체될 수 있 다. 또한, 트랜시버 유닛은 트랜시버 회로(예컨대, 수신 회로 및 송신 회로를 포함할 수 있음)일 수도 있고, 처리 유닛은 처리 회로일 수도 있다. 도 11의 장치는 전술한 실시예에서 네트워크 요소 또는 디바이스일 수도 있고, 또는 칩 또는 칩 시스템(예컨대, 시스템 온 칩(system-on-a-chip, SoC))일 수도 있다는 점에 유의해야 한다. 트랜시버 유닛은 입출력 회로 및/ 또는 통신 인터페이스일 수 있다. 처리 유닛은 집적 프로세서, 마이크로프로세서 또는 칩의 집적 회로이다. 이는 본 명세서에서 제한되지 않는다. 도 12는 본 출원의 실시예에 따른 다른 통신 장치의 도면이다. 장치는 프로세서를 포함한다. 프로세서는 메모리에 연결되어 있다. 메모리는 컴퓨터 프로그램 또는 명령어 및 /또는 데이터를 저장하도록 구성된다. 프로세서는 메모리에 저장된 컴퓨터 프로그램 또는 명령어 를 실행하거나 또는 메모리에 저장된 데이터를 판독하여 전술한 방법 실시예의 방법을 수행하도록 구성된 다. 선택적으로, 하나 이상의 프로세서가 존재한다. 선택적으로, 하나 이상의 메모리가 존재한다. 선택적으로, 메모리는 프로세서와 통합되거나 별도로 배치된다. 선택적으로, 도 12에 도시된 바와 같이, 장치는 트랜시버를 더 포함할 수 있다. 트랜시버는 신호를 수신 및/또는 송신하도록 구성된다. 예를 들어, 프로세서는 트랜시버를 제어하여 신호를 수신 및/또는 송신하도록 구성된다. 예를 들어, 프로세서는 도 11에 도시된 처리 유닛의 기능을 가질 수 있고, 메모리는 저장 유 닛의 기능을 가질 수 있으며, 트랜시버는 도 11에 도시된 트랜시버 유닛의 기능을 가질 수 있다. 솔루션에서, 장치는 전술한 방법 실시예에서 인코더에 의해 수행되는 동작을 구현하도록 구성된다. 예를 들어, 프로세서는 메모리에 저장된 컴퓨터 프로그램 또는 명령어를 실행하여, 전술한 방법 실 시예에서 인코더의 관련 동작, 예를 들면, 도 2에 도시된 실시예에서 인코더에 의해 수행되는 방법 또는 도 7 또는 도 10 중 하나에 도시된 실시예에서 단말 디바이스에 의해 수행되는 방법을 구현하도록 구성된다.또 다른 솔루션에서, 장치는 전술한 방법 실시예에서 디코더에 의해 수행되는 동작을 구현하도록 구성된 다. 예를 들어, 프로세서는 메모리에 저장된 컴퓨터 프로그램 또는 명령어를 실행하여, 전술한 방법 실 시예에서 디코더의 관련 동작, 예를 들면, 도 2에 도시된 실시예에서 디코더에 의해 수행되는 방법 또는 도 7 또는 도 10 중 하나에 도시된 실시예에서 단말 디바이스에 의해 수행되는 방법을 구현하도록 구성된다. 본 출원의 실시예에서 언급된 프로세서는 중앙처리장치(central processing unit, CPU)일 수 있으며, 또한 다른 범용 프로세서, 디지털 신호 처리기(digital signal processor, DSP), 애플리케이션 특정 집적 회로 (application-specific integrated circuit, ASIC), 필드 프로그래머블 게이트 어레이(field programmable gate array, FPGA), 또는 다른 프로그래머블 로직 디바이스, 개별 게이트 또는 트랜지스터 로직 디바이스, 개별 하드웨어 구성 요소 등일 수도 있음을 이해해야 한다. 범용 프로세서는 마이크로프로세서일 수 있고, 또는 프 로세서는 기존의 프로세서 등일 수 있다. 본 출원의 실시예에서 언급된 메모리는 휘발성 메모리 및/또는 비휘발성 메모리일 수 있다는 것을 또한 이해해 야 한다. 비휘발성 메모리는 읽기 전용 메모리(read-only memory, ROM), 프로그램 가능 읽기 전용 메모리 (programmable read-only memory, PROM), 지울 수 있는 프로그램 가능 읽기 전용 메모리(erasable programmable read-only memory, EPROM), 전기적으로 지울 수 있는 프로그램 가능 읽기 전용 메모리 (electrically erasable programmable read-only memory, EEPROM), 또는 플래시 메모리일 수 있다. 휘발성 메 모리는 랜덤 액세스 메모리(random access memory, RAM)일 수 있다. 예를 들어, RAM은 외부 캐시로 사용될 수 있다. 예를 들어, 제한 없이 RAM은 정적 랜덤 액세스 메모리(SRAM), 동적 랜덤 액세스 메모리(DRAM), 동기식 동적 랜덤 액세스 메모리(SDRAM), 이중 데이터 전송률 동기식 동적 랜덤 액세스 메모리(double data rate SDRAM, DDR SDRAM), 향상된 동기식 동적 랜덤 액세스 메모리(enhanced SDRAM, ESDRAM), 싱크링크 동적 랜덤 액 세스 메모리(synchlink DRAM, SLDRAM), 및 다이렉트 램버스 랜덤 액세스 메모리(direct rambus RAM, DR RAM)와 같은 복수의 형태를 포함한다. 프로세서가 범용 프로세서, 즉, DSP, ASIC, FPGA 또는 다른 프로그래머블 로직 디바이스, 개별 게이트 또는 트 랜지스터 로직 디바이스, 개별 하드웨어 구성 요소인 경우, 메모리(저장 모듈)는 프로세서에 통합될 수 있다는 점에 유의해야 한다. 또한, 본 명세서에 설명된 메모리는 이들 메모리 및 다른 적절한 유형의 메모리를 포함하는 것을 목표로 하지만, 이에 국한되지 않는다는 점에 유의해야 한다. 도 13은 본 출원의 실시예에 따른 칩 시스템의 도면이다. 칩 시스템(또는 처리 시스템이라고도 함)은 논리 회로 및 입력/출력 인터페이스(input/output interface)을 포함한다. 논리 회로는 칩 시스템의 처리 회로일 수 있다. 논리 회로는 저장 유닛에 결합될 수 있고, 저장 유닛으로부터 명령어를 호출할 수 있으므로, 칩 시스템은 본 출원의 실시예에서 방법과 기능을 구현 할 수 있다. 입력/출력 인터페이스는 칩 시스템의 입력/출력 회로일 수 있으며, 칩 시스템 에 의해 처리된 정보를 출력하거나, 처리될 데이터 또는 시그널링 정보를 처리를 위해 칩 시스템에 입력 한다. 구체적으로, 예를 들어 칩 시스템이 인코더에 설치되고, 논리 회로가 입력/출력 인터페이스 에 연결되어 있는 경우, 논리 회로는 입력/출력 인터페이스을 통해 압축된 정보를 디코더로 보낼 수 있으며, 여기서 압축된 정보는 채널 정보를 압축함으로써 논리 회로에 의해 획득될 수 있다. 또는, 입력/출력 인터페이스는 처리를 위해 제2 단말 디바이스로부터 논리 회로에 메시지를 입력할 수 있 다. 또 다른 예에서, 칩 시스템이 디코더에 설치되어 있고, 논리 회로가 입력/출력 인터페이스 에 연결되어 있는 경우, 입력/출력 인터페이스은 인코더로부터 압축된 정보를 처리를 위해 논리 회 로에 입력할 수 있다. 솔루션에서, 칩 시스템은 전술한 실시예에서 인코더에 의해 수행되는 동작을 구현하도록 구성된다. 예를 들어, 논리 회로는 전술한 방법 실시예에서 디코더에 의해 수행되는 처리 관련 동작, 예컨대, 도 2 에 도시된 실시예에서 인코더에 의해 수행되는 처리 관련 동작, 또는 도 7 또는 도 10 중 어느 하나에 도시된 실시예에서 단말 디바이스에 의해 수행되는 처리 관련 동작을 구현하도록 구성된다. 입력/출력 인터페이스 는 전술한 방법 실시예에서 인코더에 의해 수행되는 송신 및/또는 수신 관련 동작, 예컨대, 도 2에 도시된 실시예에서 인코더에 의해 수행되는 송신 및/또는 수신 관련 동작, 또는 도 7 또는 도 10 중 어느 하나에 도 시된 실시예에서 단말 디바이스에 의해 수행되는 송신 및/또는 수신 관련 동작을 구현하도록 구성된다. 또 다른 솔루션에서, 칩 시스템은 전술한 방법 실시예에서 디코더에 의해 수행되는 동작을 구현하도록 구 성된다. 예를 들어, 논리 회로는 전술한 방법 실시예에서 디코더에 의해 수행되는 처리 관련 동작을 구현하도록 구성되는데, 예를 들어, 도 2에 도시된 실시예에서 디코더에 의해 수행되는 처리 관련 동작, 또는 도 7 또는 도 10 중 어느 하나에 도시된 실시예에서 네트워크 디바이스에 의해 수행되는 처리 관련 동작을 구현하도록 구성된 다. 입력/출력 인터페이스는 전술한 방법 실시예에서 디코더에 의해 수행되는 송신 및/또는 수신 관련 동작, 예컨대, 도 2에 도시된 실시예에서 디코더에 의해 수행되는 송신 및/또는 수신 관련 동작, 또는 도 7 또 는 도 10 중 어느 하나에 도시된 실시예에서 네트워크 디바이스에 의해 수행되는 송신 및/또는 수신 관련 동작 을 구현하도록 구성된다. 본 출원의 실시예는 또한 컴퓨터 판독 가능 저장 매체를 제공한다. 컴퓨터 판독 가능 저장 매체는 전술한 방법 실시예에서 인코더 또는 디코더에 의해 수행되는 방법을 구현하는 데 사용되는 컴퓨터 명령어를 저장한다. 예를 들어, 컴퓨터 프로그램이 컴퓨터에 의해 실행될 때, 컴퓨터는 전술한 방법 실시예에서 인코더 또는 디코더 에 의해 수행되는 방법을 구현할 수 있다. 본 출원의 실시예는 또한 컴퓨터 프로그램 제품(지침 포함)을 제공한다. 컴퓨터에 의해 명령어가 실행될 때, 전술한 방법 실시예에서 인코더 또는 디코더에 의해 수행되는 방법이 구현된다. 본 출원의 실시예는 또한 통신 시스템을 제공한다. 통신 시스템은 전술한 실시예에서 인코더 및 디코더를 포함 한다. 예를 들어, 시스템은 도 2에 도시된 실시예에서의 인코더와 디코더를 포함한다. 또 다른 예에 있어서, 시스템은 도 7 또는 도 10에 도시된 실시예에서의 단말 디바이스와 네트워크 디바이스를 포함한다. 위에서 제공된 장치들 중 어느 하나의 관련 내용의 설명 및 유용한 효과는, 위에서 제공된 대응하는 방법 실시 예를 참조한다. 세부 사항은 본 명세서에서 반복하지 않는다. 본 출원에서 제공된 여러 실시예에서, 개시된 시스템, 장치 및 방법은 다른 방식으로 구현될 수 있음을 이해해 야 한다. 예를 들어, 설명된 장치 실시예는 단지 예일 뿐이다. 예를 들어, 유닛들로의 분할은 단지 논리적 기 능 분할일 뿐이며, 실제 구현에서는 다른 분할일 수도 있다. 예를 들어, 복수의 유닛 또는 구성요소가 다른 시 스템에 결합되거나 통합될 수도 있고, 일부 특징은 무시되거나 수행되지 않을 수도 있다. 또한, 개시되거나 논 의된 상호 연결 또는 직접 연결 또는 통신 연결은 일부 인터페이스를 통해 구현될 수도 있다. 장치들 또는 유 닛들 사이의 간접 연결 또는 통신 연결은 전기적, 기계적 또는 기타 형태로 구현될 수 있다. 전술한 실시예들 전부 또는 그 일부는 소프트웨어, 하드웨어, 펌웨어 또는 이들의 임의의 조합을 사용하여 구현 될 수 있다. 실현예를 구현하기 위해 소프트웨어가 사용될 때, 실시예들 전부 또는 일부는 컴퓨터 프로그램 제 품의 형태로 구현될 수 있다. 컴퓨터 프로그램 제품은 하나 이상의 컴퓨터 명령어를 포함한다. 컴퓨터 프로그 램 명령어가 컴퓨터에 로드되어 실행될 때, 본 출원의 실시예에 따른 절차 또는 기능이 전부 또는 부분적으로 생성된다. 컴퓨터는 범용 컴퓨터, 전용 컴퓨터, 컴퓨터 네트워크 또는 다른 프로그래밍 가능한 장치일 수 있다. 예를 들어, 컴퓨터는 개인용 컴퓨터, 서버 또는 네트워크 디바이스일 수 있다. 컴퓨터 명령어는 컴퓨터 판독 가능한 저장 매체에 저장되거나, 또는 하나의 컴퓨터 판독 가능한 저장 매체로부터 다른 컴퓨터 판독 가능 한 저장 매체로 전송될 수 있다. 예를 들어, 컴퓨터 명령어는 한 웹사이트, 컴퓨터, 서버, 또는 데이터 센터로 부터 다른 웹사이트, 컴퓨터, 서버, 또는 데이터 센터로 유선(예컨대, 동축 케이블, 광섬유, 또는 디지털 가입 자 회선(DSL)) 또는 무선(예컨대, 적외선, 무선, 또는 마이크로파) 방식으로 전송될 수 있다. 컴퓨터 판독 가 능 저장 매체는 컴퓨터가 액세스할 수 있는 모든 사용 가능한 매체, 또는 하나 이상의 사용 가능한 매체와 통합 된 서버 또는 데이터 센터와 같은 데이터 저장 디바이스일 수 있다. 사용 가능한 매체는 자기 매체(예컨대, 플 로피 디스크, 하드 디스크 또는 자기 테이프), 광학 매체(예컨대, DVD), 반도체 매체(예컨대, SSD(solid-state disk)) 등일 수 있다. 예를 들어, 전술한 사용 가능한 매체는 USB 플래시 드라이브, 이동식 하드 디스크 드라 이브, 읽기 전용 메모리(read-only memory, ROM), 랜덤 액세스 메모리(random access memory, RAM), 자기 디스 크 또는 광학 디스크와 같은 프로그램 코드를 저장할 수 있는 임의의 매체를 포함할 수 있으며 이에 제한되지 않는다. 전술한 설명은 단지 본 출원의 특정 구현예일 뿐이며, 본 출원의 보호 범위를 제한하고자 하는 것은 아니다. 본 출원에 개시된 기술 범위 내에서 당업자가 쉽게 파악할 수 있는 모든 변형 또는 대체는 본 출원의 보호 범위에 속한다. 따라서, 본 출원의 보호 범위는 청구항의 보호 범위에 따른다."}
{"patent_id": "10-2025-7010078", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 출원의 실시예에 적용 가능한 무선 통신 시스템의 도면이다. 도 2는 본 출원의 실시예에 따른 통신 방법의 도면이다. 도 3은 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식의 도면이다. 도 4는 X개의 층의 각 층 및 이 층들 사이의 채널 정보의 배열 방식의 또 다른 도면이다. 도 5는 M개의 층의 채널 정보를 압축하기 위한 인코딩 및 디코딩의 도면이다. 도 6은 디코더의 출력의 도면이다. 도 7은 본 출원의 실시예에 따른 통신 방법의 도면이다. 도 8은 모델 A에 의해 출력된 채널 정보의 도면이다. 도 9는 모델 B에 의해 출력된 채널 정보의 도면이다. 도 10은 본 출원의 실시예에 따른 통신 방법의 도면이다. 도 11은 본 출원의 실시예에 따른 통신 장치의 블록도이다. 도 12는 본 출원의 실시예에 따른 다른 통신 장치의 도면이다. 도 13은 본 출원의 실시예에 따른 칩 시스템의 도면이다."}
