{"patent_id": "10-2020-0149896", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0063231", "출원번호": "10-2020-0149896", "발명의 명칭": "딥 화이트-밸런싱 편집을 위한 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "아피피 마흐무드 나서"}}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "렌즈 모듈 및 상기 렌즈 모듈을 통해 수집된 빛을 이용하여 제1 영상 데이터를 획득하는 영상 센싱 모듈을 포함하는 카메라 모듈;촬영 조건(shooting condition)에 대한 정보를 획득하는 센서 모듈;화이트밸런스 조정을 위한 복수의 인공지능 모델에 관한 정보를 저장하고 있는 저장 모듈; 상기 저장된 인공지능 모델 중 적어도 하나를 처리하여 제2 영상 데이터를 획득하는 영상 신호 프로세서; 및적어도 하나의 애플리케이션 프로세서를 포함하고,상기 적어도 하나의 애플리케이션 프로세서는,상기 센서 모듈을 통해 획득된 상기 촬영 조건에 대한 정보에 기초하여, 상기 저장 모듈에 저장된 화이트밸런스조정을 위한 복수의 인공지능 모델 중, 상기 촬영 조건에 대응하는 인공지능 모델을 결정하고,상기 결정된 인공지능 모델이 상기 영상 신호 프로세서에 로딩되도록 제어하며,상기 영상 신호 프로세서는,상기 결정된 인공지능 모델에 상기 제1 영상 데이터를 입력하여, 상기 촬영 조건에 대응하도록 화이트밸런스 조정된 제2 영상 데이터를 획득하는 것을 특징으로 하는 모바일 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제1 영상 데이터는 원본 컬러 필터 어레이(Color Filter Array) 데이터인 것을 특징으로 하는 모바일장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 제 1 영상 데이터는 원본 RGB 데이터인 것을 특징으로 하는 모바일 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 복수의 인공지능 모델 각각의 인공지능 모델은 부호화부 모델과 복호화부 모델을 포함하고, 상기 복수의인공지능 모델은 서로 다른 복호화부 모델을 포함하는 것을 특징으로 하는 모바일 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 센서 모듈은 GPS 센서 정보를 획득하는 GPS 센싱 모듈;조도 센서 정보를 획득하는 조도 센싱 모듈; 및 공개특허 10-2021-0063231-3-네트워크 상태 정보를 획득하는 네트워크 상태 정보 획득 모듈을 포함하고,상기 적어도 하나의 프로세서는 GPS 센서 정보, 조도 센서 정보 및 네트워크 상태 정보 중 적어도 하나를 기초로, 상기 모바일 장치가 실내 또는 실외에 위치하는지를 식별하고,상기 저장 모듈에 저장된 화이트밸런스 조정을 위한 복수의 인공지능 모델 중, 상기 식별 결과에 대응하는 인공지능 모델을 결정하는 것을 특징으로 하는 모바일 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,상기 적어도 하나의 프로세서는 GPS 센서 정보, 조도 센서 정보 및 네트워크 상태 정보 중 적어도 하나를 기초로, 상기 모바일 장치가 실내 또는 실외에 위치하는지를 식별할 때, 상기GPS 센서 정보가 업데이트되지 않는 경우, 상기 모바일 장치가 실내에 위치한다고 식별하고, 상기 GPS 센서 정보가 업데이트되는 경우, 상기 모바일장치가 실외에 위치한다고 식별하는 것을 특징으로 하는 모바일 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 5 항에 있어서,상기 적어도 하나의 프로세서는 GPS 센서 정보, 조도 센서 정보 및 네트워크 상태 정보 중 적어도 하나를 기초로, 상기 모바일 장치가 실내 또는 실외에 위치하는지를 식별할 때, 상기 조도 센서 정보의 센서 값이 소정의제1 값보다 크거나 같은 경우, 상기 모바일 장치가 실외에 위치한다고 식별하고, 상기 조도 센서 정보의 센서 값이 소정의 제2 값보다 작거나 같은 경우, 상기 모바일 장치가 실내에 위치한다고식별하는 것을 특징으로 하는 모바일 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 5 항에 있어서, 상기 네트워크 상태 정보는 스캔된 적어도 하나의 AP(Access Point)의 RSSI(Received Signal StrengthIndication) 정보 및 스캔된 적어도 하나의 AP의 SSID(Service Set Identifier) 정보 중 적어도 하나를 포함하고,상기 적어도 하나의 프로세서는 GPS 센서 정보, 조도 센서 정보 및 네트워크 상태 정보 중 적어도 하나를 기초로, 상기 모바일 장치가 실내 또는 실외에 위치하는지를 식별할 때, 상기 스캔된 AP의 RSSI의 평균값이 소정의 제1값보다 크거나 같은 경우, 상기 모바일 장치가 실내에 위치한다고식별하고, 상기 스캔된 AP의 RSSI의 평균값이 소정의 제2값보다 작은 경우, 상기 모바일 장치가 실외에 위치한다고 식별하거나,스캔된 AP중 RSSI가 소정의 제1 값보다 크거나 같은 AP의 개수가 소정의 제1 개수보다 크거나 같은 경우, 상기모바일 장치가 실내에 위치한다고 식별하고, 스캔된 AP 중 RSSI가 소정의 제2값보다 작거나 같은 AP의 개수가소정의 제2 개수보다 크거나 같거나, 상기 소정의 제1값보다 크거나 같은 AP의 개수가 소정의 제1 개수보다 작은 경우, 상기 모바일 장치가 실외에 위치한다고 식별하는 것을 특징으로 하는 모바일 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "딥 화이트-밸런싱 편집(deep white-balancing editing)을 위한 장치에 있어서,인스트럭션들을 저장하는 메모리; 및상기 인스트럭션들을 수행하는 적어도 하나의 프로세서를 포함하고, 공개특허 10-2021-0063231-4-상기 적어도 하나의 프로세서는, 영상 신호 처리(image signal processing)에 의해 보정(correct)된 원본 화이트 밸런스(original white balance)를 갖는 입력 영상을 획득하고, 제1 뉴럴 네트워크(neural network)를 이용하여, 상기 영상 신호 처리에 의해 보정되지 않은 원본 화이트 밸런스를 갖는, 상기 획득된 입력 영상의 중간 표현(intermediate representation)을 획득하고,상기 획득된 중간 표현을 기초로, 제2 뉴럴 네트워크를 이용하여, 상기 원본 화이트 밸런스와 다른 제1 화이트밸런스를 갖는 제1 출력 영상을 획득하기 위한 상기 인스트럭션들을 수행하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 적어도 하나의 프로세서는 상기 획득된 중간 표현을 기초로, 제 3 뉴럴 네트워크를 이용하여, 상기 제1 화이트 밸런스 및 상기 원본 화이트 밸런스와 다른 제2 화이트 밸런스를 갖는 제 2 출력 영상을 획득하기 위한 상기 인스트럭션들을 더 수행하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 적어도 하나의 프로세서는 복수의 화이트 밸런스들 중 하나의 화이트 밸런스를 선택하기 위한 슬라이더를디스플레이하도록 제어하고,상기 복수의 화이트 밸런스들 중 상기 하나의 화이트 밸런스를 선택하는 사용자 입력을 기초로, 상기 디스플레이된 슬라이더를 이용하여, 상기 획득된 제1 출력 영상, 상기 획득된 제2 출력 영상 및 상기 제1 출력 영상 및상기 제2 출력 영상의 블랜딩 영상(blended image) 중 어느 하나 또는 어느 조합을 이용하여, 상기 복수의 화이트 밸런스들 중 상기 하나의 화이트 밸런스를 갖는 결과 영상을 디스플레이하도록 제어하기 위한 상기 인스트럭션들을 더 수행하는 것을 특징으로 하는 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9 항에 있어서, 상기 적어도 하나의 프로세서는 상기 획득된 입력 영상을 다운샘플링(downsample)하고,상기 제1 뉴럴 네트워크를 이용하여, 상기 다운샘플링된 입력 영상의 다운 샘플링된 중간 표현을 획득하고, 상기 다운샘플링된 중간 표현은 상기 영상 신호 처리에 의해 보정되지 않은 상기 원본 화이트 밸런스를 갖는 다운샘플링된 중간 표현이고,상기 제2 뉴럴 네트워크를 이용하여, 상기 획득된 다운샘플링된 중간 표현을 기초로, 상기 원본 화이트 밸런스와 다른 상기 제 1 화이트 밸런스를 갖는 다운샘플링된 출력 영상을 획득하고, 상기 원본 화이트 밸런스와 다른 상기 제1 화이트 밸런스를 갖는 상기 제 1 출력 영상을 획득하기 위해 상기 획득된 다운샘플링된 출력 영상에 컬러 맵핑(color mapping)을 적용하기 위한 상기 인스트럭션들을 더 수행하는것을 특징으로 하는 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 컬러 맵핑은 상기 다운샘플링된 입력 영상의 컬러들을 상기 다운샘플링된 출력 영상의 컬러들에 맵핑하는맵핑 매트릭스를 기초로 하는 다항식 함수인 것을 특징으로 하는 장치.공개특허 10-2021-0063231-5-청구항 14 제 9 항에 있어서,상기 제 1 뉴럴 네트워크는, 하나 이상의 제1 컨볼루션 레이어, 하나 이상의 제1 정류된 선형 단위(rectifiedlinear unit; ReLu) 레이어, 및 적어도 하나의 제1 맥스-풀링(max-pooling) 레이어; 및하나 이상의 제2 컨볼루션 레이어, 하나 이상의 제2 정류된 선형 단위 레이어, 및 적어도 하나의 제 2 맥스-풀링 레이어를 포함하고,상기 하나 이상의 제2 컨볼루션 레이어, 상기 하나 이상의 제2 정류된 선형 단위 레이어 및 상기 적어도 하나의제2 맥스-풀링 레이어의 제2 개수의 채널은 상기 하나 이상의 제1 컨볼루션 레이어, 상기 하나 이상의 제1 정류된 선형 단위 레이어 및 상기 적어도 하나의 제1 맥스-풀링 레이어의 제1 개수의 채널의 2배인 것을 특징으로하는 장치."}
{"patent_id": "10-2020-0149896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9 항에 있어서, 상기 장치, 상기 제1 뉴럴 네트워크 및 상기 제2 뉴럴 네트워크는 서버에 구현되고, 전자 장치의 영상 신호 프로세서로부터, 상기 영상 신호 프로세서의 상기 영상 신호 처리에 의해 보정된 상기원본 화이트 밸런스를 갖는 상기 입력 영상을 수신하고, 상기 획득된 제1 출력 영상을 상기 전자 장치로 전송하기 위한 상기 인스트럭션들을 더 수행하는 것을 특징으로하는 장치."}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "딥 화이트 밸런싱 편집을 위한 장치는 인스트럭션을 저장하는 메모리와, 영상 신호 처리에 의해 보정된 원본 화 이트 밸런스를 갖는 입력 영상을 획득하고, 제1 뉴럴 네트워크를 이용하여 상기 획득된 입력 영상의 중간 표현을 획득하기 위한 상기 인스트럭션들을 실행하도록 구성된 적어도 하나의 프로세서를 포함한다. 이때, 상기 중간 표 현은 상기 영상 신호 처리에 의해 보정되지 않은 원본 화이트 밸런스를 가질 수 있다. 적어도 하나의 프로세서는 획득된 중간 표현에 기초하여, 제2 뉴럴 네트워크를 이용하여, 원본 화이트 밸런스와 다른 제1 화이트 밸런스를 갖는 제1 출력 영상을 획득하기 위한 인스트럭션을 실행하도록 추가로 구성된다."}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예들과 일치하는 방법 및 장치는 딥 화이트 밸런싱 편집(deep white-balancing editing)과 관련된다."}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "화이트 밸런스(White Balance, 이하 'WB'라 함)는 모든 카메라 영상에 적용되는 로우-레벨 컴퓨터 비전 작업 (low-level computer vision tasks)이다. WB는 다른 조명 조건들에서 촬영된 경우에도, 장면 객체들(scene objects)이 동일한 컬러로 나타나도록 수행된다. 개념적으로, WB는 캡처된 장면의 조명 효과를 정규화 (normalize)하여 모든 객체들이 이상적인 \"백색광\" 아래에서 캡처된 것처럼 보이도록 하기 위한 것이다. WB는 카메라의 온보드(onboard) 통합된 신호 프로세서(Integrated Signal Processor, 이하 'ISP'라 함)에 의해, 센 서의 처리되지 않은 raw-RGB 영상(unprocessed raw-RGB image)에 적용되는 최초의 컬러 조작 단계들 중 하나이 다. WB가 수행된 후, raw-RGB 영상을 최종 표준 RGB(sRGB) 인코딩으로 더 처리하기 위해 추가적인 컬러 렌더링 단계들이 ISP에 의해 적용된다. WB의 목표는 장면의 조명 효과를 정규화하기 위한 것이지만 ISP는 종종 사진 선호도(photographic preference s)를 기초로, 컬러 렌더링에 미적 고려 사항(aesthetic considerations)을 통합한다. 이러한 선호도는 항상 백 색광 가정을 따르는 것은 아니며 문화적 선호도(cultural preference) 및 장면 콘텐츠(scene content)와 같은 다양한 요인에 따라 달라질 수 있다. 대부분의 디지털 카메라는 영상 캡처링(또는 촬영) 도중에 WB 설정을 조정하는 옵션을 제공한다. 그러나, 일단 WB 설정이 선택되고, 영상이 ISP에 의해 최종 sRGB 인코딩으로 완전히 처리되면, 처리되지 않은 원본 raw-RGB 영상에 접근 없이 WB 편집을 수행하기가 어려워진다. 이러한 문제는 WB 설정이 잘못된 경우 더욱 어려워지고, 결국 최종 sRGB 영상에서 강한 컬러 캐스트(cast)가 발생하게 된다. sRGB 영상의 WB를 편집하는 기능은 사진 관점에서 유용할 뿐만 아니라, 객체 인식(object recognition), 장면 이해(scene understanding) 및 컬러 어그맨테이션(color augmentation)과 같은 컴퓨터 비전 어플리케이션들에유용할 수 있다. 최근 연구는 잘못된 WB 설정으로 캡처한 영상은 딥 뉴럴 네트워크(Deep Neural Network, 이하 'DNN'이라 함) 모 델들에 대한 대상이 정해지지 않은 적대적 공격(untargeted adversarial attack)과 유사한 효과를 생성함을 보 여준다. sRGB 영상들에서 WB 편집의 어려움를 이해하려면, 카메라가 WB를 수행하는 방법을 검토하는 것이 유용하다. WB 는 ISP에 의해 나란히(in tandem) 수행하는 두 단계로 구성된다: raw-RGB 벡터의 형태로, 장면 조명에 대한 카메라 센서의 응답을 추정하는 단계; 및 raw-RGB 영상의 각 컬러 R / G / B 컬러 채널을 raw-RGB 벡터의 대응 채널 응답으로 나누는 단계. 조명 벡터를 추정하는 첫 번째 단계는 카메라의 자동 화이트 밸런스(Auto White Balance, 이하, 'AWB'라 함) 절 차로 구성된다. AWB 외에도 대부분의 카메라를 사용하면 카메라 제조업체에 의해 각 카메라에 대한 raw-RGB 벡 터가 결정된 WB 사전 설정들(preset) 중에서 사용자가 수동으로 하나의 WB 사전 설정을 선택할 수 있다. 이러한 사전 설정들은 일반적인 장면 조명(예: 일광, 쉐이드(shade) 및 백열등)에 해당한다. 장면의 조명 raw-RGB 벡터가 정의되면, 조명을 정규화하기 위해 각 컬러 채널에 개별적으로 선형 스케일링이 독 립적으로 적용된다. 이 스케일링 작업은 3x3 대각 행렬을 이용하여 수행된다. 화이트 밸런스된(또는 화이트 밸 런싱된) raw-RGB 영상은 출력 참조 컬러 스페이스, 즉 sRGB 컬러 스페이스에서 최종 영상을 렌더링하기 위해 사 실상 많은 비선형적인 카메라 별 ISP 단계들에 의해 추가로 처리된다. 이러한 비선형 작업은 카메라 WB 오류로 인한 강한 컬러 캐스트로 렌더링된 영상을 보정하기 위해, 기존의 대각 보정(traditional diagonal correctio n)을 이용하기 어렵게 만든다. 정확한 포스트-캡처 WB 편집을 수행하려면, 렌더링된 sRGB 값을 적절하게 반전하여 해당 처리되지 않은 raw-RGB 값을 얻은 다음, 다시 렌더링(재-랜더링)해야 한다. 이는 이러한 컬러 역-렌더링(de-rendering)에 대한 메타 데 이터를 계산하는 정확한 방사 측정 보정 방법들(radiometric calibration methods)로 달성될 수 있다. 최근 연 구에서는 잘못된 WB 설정으로 캡처한 sRGB 영상을 직접 수정하는 방법이 제안되었다. 이 연구는 잘못된 WB 설정 으로, 소프트웨어 카메라 파이프 라인에 의해 렌더링된 60,000 개 이상의 sRGB 영상이 넘는 대규모 데이터 셋을 이용하는 모델-기반 프레임 워크(exemplar-based)를 제안했다. 이러한 각 sRGB 영상들에는 올바른 WB 설정으로 렌더링된 해당 sRGB 영상을 갖는다. 입력 영상이 주어지면, 그들의 접근 방식은 k- 최근접 이웃들(k-nearest neighbors, 이하, 'KNN'이라 함) 전략을 이용하여 데이터 셋에서 유사한 영상들을 검색하고, 대응하는 올바른 WB 영상에 대한 맵핑 함수를 계산했다. 이 연구는 모델(exemplars)로부터 구성된 이 계산된 컬러 맵핑이 입력 영상을 수정하는 것에 효과적이라는 것을 보여주었다. 나중에, 이 연구는 딥 뉴럴 네트워크 훈련을 위한 영상 어그맨테이션을 위해, 올바른 WB 영상을 잘못 보이도록 맵핑하는 것으로 KNN 아이디어를 확장했다."}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예들과 일치하는 방법 및 장치는 딥 화이트 밸런싱 편집(deep white-balacing editing)과 관련된다."}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예들은 딥 화이트 밸런싱 편집을 위한 방법 및 장치를 제공한다. 본 개시의 일 측면에 따르면, 딥 화이트 밸런싱 편집 장치가 제공되며, 상기 장치는 인스트럭션들을 저장하는 메모리를 포함하고, 상기 인스트럭션들을 수행하는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프 로세서는, 영상 신호 처리에 의해 원본 화이트 밸런스를 갖는 입력 영상을 획득하고, 제1 뉴럴 네트워크를 이용 하여, 상기 영상 신호 처리에 의해 보정되지 않은 원본 화이트 밸런스를 갖는, 상기 획득된 입력 영상의 중간 표현을 획득한다. 상기 적어도 하나의 프로세서는 획득된 중간 표현에 기초하여, 제2 뉴럴 네트워크를 이용하여, 원본 화이트 밸런스와 다른 제1 화이트 밸런스를 갖는 제1 출력 영상을 획득하기 위한 인스트럭션들 을 실행하도록 추가로 구성된다. 본 개시의 일 측면에 따르면, 딥 화이트 밸런싱 편집 방법이 제공되는데, 상기 방법은 적어도 하나의 프로세서 에 의해 수행되며, 영상 신호 처리에 의해 보정된 원본 화이트 밸런스를 갖는 입력 영상을 획득하는 단계; 및제1 뉴럴 네트워크를 이용하여, 상기 영상 신호 처리에 의해 보정되지 않은 입력 영상의 중간 표현을 획득하는 단계를 포함한다. 이 방법은 획득된 중간 표현에 기초하여, 제2 뉴럴 네트워크를 이용하여, 원본 화이트 밸런스 와 다른 제1 화이트 밸런스를 갖는 제1 출력 영상을 획득하는 단계를 더 포함한다. 본 개시의 일 측면에 따르면, 딥 화이트 밸런싱 편집을 위해 적어도 하나의 프로세서에 의해 실행될 때, 적어도 하나의 프로세서가 다음의 동작을 수행하기 위한 인스트럭션들을 저장하는 컴퓨터 기록 매체가 제공된다. 상기 인스트럭션들은 상기 적어도 하나의 프로세서가 영상 신호 처리에 의해 원본 화이트 밸런스를 갖는 입력 영상을 획득하고, 제1 뉴럴 네트워크를 이용하여, 상기 영상 신호 처리에 의해 보정되지 않은 원본 화이트 밸런스를 갖 는, 상기 획득된 입력 영상의 중간 표현을 획득하게 한다. 상기 인스트럭션들은, 또한 적어도 하나의 프로세서 가 제2 뉴럴 네트워크를 이용하여, 획득된 중간 표현에 기초하여 원본 화이트 밸런스와 다른 제1 화이트 밸런스 를 갖는 제1 출력 영상을 획득하게 한다. 전술한 방법, 장치 및 컴퓨터 기록매체가 개별적으로 설명되었지만, 이러한 설명은 그 사용 범위 또는 기능에 대한 어떠한 제한도 제시하려는 의도가 아니다. 실제로, 이러한 방법, 장치 및 컴퓨터 기록매체는 본 개시의 다 른 측면들과 결합될 수 있다."}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 실시예들은 딥 화이트 밸런싱 편집을 위한 방법 및 장치를 제공한다. 구체적으로 sRGB 영상의 화이트 밸런스를 현실적으로 편집하는 딥 러닝 접근 방식이 소개된다. 카메라는 ISP가 sRGB 컬러 스페이스 인코딩으로 렌더링된 센서 영상을 캡처한다. ISP 렌더링은 장면 조명의 컬러 캐스트를 제거 하는데 사용되는 화이트 밸런스 절차로 시작된다. 그런 다음, ISP는 일련의 비선형 컬러 조작들을 적용하여 최 종 sRGB 영상의 시각적 품질을 향상시킨다. 최근 연구는 잘못된 화이트 밸런스로 렌더링된 sRGB 영상은 ISP의 비선형 렌더링으로 인해 쉽게 수정할 수 없음을 보여준다. 이 연구는 수만 개(tens of thousands)의 영상 쌍 (image pairs)을 기반으로 한 KNN 솔루션을 제안했다. 그러나 ISP는 프로세스 초기에 영상의 WB를 잘못 수정할 수 있기 때문에 이러한 오류는 KNN 솔루션에서도 프로세스 전체에 걸쳐서 전파될 수 있다. 상기 실시예들은 정확한 화이트 밸런스를 학습하기 위해 엔드-투-엔드 방식으로 훈련된 DNN 아키텍처로 이 문제 를 해결한다. 상기 DNN 아키텍처는 입력 영상을 실내 및 실외 조명에 해당하는 두 개의 추가 화이트 밸런스 설 정에 맵핑한다. 상기 실시예들은 잘못된 화이트 밸런스 설정을 수정하는 측면에서 KNN 접근법보다 정확할뿐만아니라 사용자에게 sRGB 영상의 화이트 밸런스를 다른 조명 설정들로 편집할 수 있는 자유를 제공한다. 상기 실시예들은 sRGB 영상의 사실적인 포스트-캡쳐 WB 편집을 허용하는 딥 러닝 프레임 워크를 제공한다. 프레 임 워크에는 다음 WB 설정들을 타겟으로 하는 3 개의 복호화부 네트워크들과 결합된 단일 부호화부 네트워크가 포함된다: \"올바른\" AWB 설정; 실내 WB 설정; 및 실외 WB 설정 제1 복호화부는 화이트 밸런스가 잘 못 조정된 sRGB 영상을 올바른 WB를 갖도록 편집할 수 있다. 이는 포스트-캡쳐 WB 보정 작업(post-capture WB correction)에 유용하다. 추가적인 실내 및 실외 복호화부들은 복호화부들의 두 출력들을 블랜딩하여 넓은 범위 의 WB 형태들(WB appearances)을 생성할 수 있는 기능을 사용자에게 제공한다. 이 것은 영상의 미적 WB 속성 (aesthetic WB properties)을 조정하기 위한 사진 편집 작업을 지원한다. 상기 프레임 워크는 훈련 데이터 외부 의 영상들에 잘 일반화되고, 위에서 논의한 작업에 대한 최신 결과를 얻는다. 본 개시는 다양한 변경 및 다수의 예제들을 허용하므로, 상기 실시예들은 도면에 예시되고 서면 설명에서 상세 하게 설명될 것이다. 그러나 이는 본 개시를 실행 모드들(modes of practice)로 제한하려는 것이 아니며, 본 개 시의 정신 및 기술적 범위를 벗어나지 않는 모든 변경, 등가물 및 대체물(all changes, equivalents, and substitutes)이 본 개시에 포함된다는 것을 이해할 것이다. 상기 실시예들을 설명함에 있어서 관련 기술에 대한 상세한 설명은 본 개시의 본질을 불필요하게 흐릴 수 있다 고 판단되는 경우 생략한다. 또한, 명세서 설명에 사용되는 숫자 (예를 들어, 제1, 제2 등)는 한 요소를 다른 요소와 구별하기 위한 식별자 코드들이다. 또한, 본 명세서에서 구성 요소들이 서로 \"연결\"(connected)되거나 \"결합\"(coupled)될 때, 구성 요소들은 서로 직접 연결되거나 결합될 수 있지만, 대안적으로, 달리 명시되지 않는 한 그 사이의 중간 요소가 그 사이에 존재 하여 서로 연결되거나 결합될 수 있음을 당업자는 이해할 것이다. 본 명세서에서 후술하는 각 구성 요소는 자신의 주요 기능 외에 다른 구성 요소가 수행하는 기능의 일부 또는 전부를 추가적으로 수행할 수 있으며, 각 구성 요소의 주요 기능 중 일부는 전적으로 다른 구성 요소에 의해 수 행될 수 있다. 본 명세서에서 '영상'은 정지 영상(still image), 연속된 복수의 정지 영상들(또는 프레임들)을 포함하는 동영 상 또는 비디오를 의미할 수 있다. 상기 영상은 2차원(2D)영상 또는 3차원(3D)영상일 수 있다. 또한, 본 명세서에서 뉴럴 네트워크(Neural network)는 인공 지능 모델의 대표적인 예이지만, 상기 실시예들은 알고리즘을 이용한 인공 지능 모델에 한정되지 않는다. 또한, 본 명세서에서 '파라메터' 또는 '뉴럴 네트워크 파라메터'는 뉴럴 네트워크를 구성하는 각 레이어의 동작 과정에서 사용되는 값으로, 예를 들어 입력 값이 연산식에 적용될 때 이용되는 가중치를 포함할 수 있다. 여기 서, 파라메터는 행렬 형태로 표현될 수 있다. 파라메터는 훈련의 결과로 설정되는 값이며 필요한 경우 별도의 훈련 데이터를 통해 업데이트될 수 있다. 본 명세서에서 \"a, b 또는 c 중 적어도 하나\"라는 표현은 a 만, b 만, c 만, a와 b 모두, a와 c 모두, b와 c 모 두, a, b 및 c 모두 또는 그 변형을 나타낸다. 도 1은 실시예들에 따른 딥 화이트 밸런싱 편집을 위한 장치의 도면이다. 도 1을 참조하면, 장치는 부호화부, 제1 WB 복호화부 및 제2 WB 복호화부를 포함한다. 장치는 전자 장치(예를 들어, 모바일 장치) 및/또는 서버로 구현될 수 있다. 부호화부는 카메라 ISP의 영상 신호 처리에 의해 보정된 원본 화이트 밸런스를 갖는 입력 영상(예를 들어, sRGB 영상)을 획득(수신)하도록 구성된다. 부호화부는 또한, 획득된 입력 영상의 중간 표현을 획득하고 전 송하도록 구성되며, 중간 표현은 영상 신호 처리에 의해 보정되지 않은 원본 화이트 밸런스를 갖는다. 부호화부 는 예를 들어, 아래 도 2에서 설명될 컨볼루션 뉴럴 네트워크(CNN) 또는 DNN과 같은 뉴럴 네트워크를 포함 한다. 제1 WB 복호화부는 획득된 중간 표현에 기초하여 원본 화이트 밸런스와 다른 제1 화이트 밸런스를 갖는 제 1 출력 영상을 획득하고 전송하도록 구성된다. 제1 WB 복호화부는 예를 들어 CNN 또는 DNN과 같은 뉴럴 네 트워크를 포함하는데, 이는 아래 도 3에서 설명될 것이다. 예를 들어, 제1 화이트 밸런스는 AWB(Auto White Balance)일 수 있다.제2 WB 복호화부는 획득된 중간 표현에 기초하여 원본 화이트 밸런스 및 제1 화이트 밸런스와 다른 제2 화 이트 밸런스를 갖는 제2 출력 영상을 획득하도록 구성된다. 제2 WB 복호화부는 예를 들어 CNN 또는 DNN과 같은 뉴럴 네트워크를 포함하는데, 이는 아래 도 4에서 설명될 것이다. 제2 화이트 밸런스는 예를 들어, 각각 2850K (K) 및 7500K 색온도(color temperatures)와 상관 관계가 있는 쉐이드 WB(shade WB) 또는 백열등 WB(Indecedent WB)일 수 있다. 자세하게는, 임의의 WB 설정 WB(in)과 함께 알려지지 않은 카메라 ISP를 통해 렌더링된 입력 sRGB 영상 IWB(in)을 고려하면, 목표는 타겟 WB 설정 WB(t)와 함께 재-렌더링된 것처럼 보이기 위해 입력 sRGB 영상 IWB(in)의 컬러들을 편집하는 것이다. 처리되지 않은 원본 raw-RGB 영상이 이용가능한 경우, 위의 작업을 정확하게 수행할 수 있다. 처리되지 않은 원 본 raw-RGB 값들이 복원되면, 임의의 WB 설정 WB(in) 이 타겟 WB 설정 WB(t)으로 변경되고, 그러고 나서 상기 sRGB 영상이 다시 소프트웨어-기반 ISP에 의해 원래 sRGB 컬러 스페이스로 재-랜더링되어 돌아갈 수 있다. 이 프로세스는 다음 수학식에 의해 설명될 수 있다. 수학식 1"}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "F : IWB(in) -> DWB(in) 은 카메라-렌더링된 sRGB 영상을 임의의 WB 설정 WB(in)가 적용된 그것의 대응 raw-RGB 영상 D으로 되돌리는, 알려지지 않은 복원 함수이다. G : DWB(in) -> IWB(t) 은 임의의 WB 설정 WB(in)를 편집하고, 최종 sRGB 영상 IWB(t) 를 재-랜더링하기 위한 알려지지 않은 카메라 렌더링 함수이다. 심볼 ·는 함수 합성을 나타낸다. 목표는 최종 sRGB 영상 IWB(t)를 생성하기 위해 G·F 의 기능을 모델링하는 것이다. 첫번째로, 어떻게 함수들 G 및 F가 최종 sRGB 영상 IWB(t) 를 생성하기 위해 협력할 수 있는지가 분석된다. 수학식 1로부터, 함수 G가 중간 표현을 받아들이고, 이를 타겟 WB 설정 WB(t)을 갖도록 sRGB 컬러 스페이스 인코딩으로 렌더링하고, 함수 F는 입 력 sRGB 영상 IWB(in)을 중간 표현(즉, 캡쳐된 WB 설정을 갖는 raw-RGB 영상 D)으로 변환(transform)한다. ISP의 렌더링 체인에 의해 적용되는 비선형성으로 인해 함수 G는 일련의 서브 함수(a set of sub-functions)를 포함하는 하이브리드 함수로 생각할 수 있으며, 각 하위 함수는 특정 WB 설정으로 중간 표현을 렌더링하는 역할 을 한다. 목표는 원본 raw-RGB 값을 재구성/재-렌더링하는 것이 아니라, 타겟 WB 설정 WB(t)로 최종 sRGB 영상 IWB(t)를 생 성하는 것이다. 그러므로, G·F 의 기능은 부호화부/복호화부 스킴으로 모델링될 수 있다. 복호화부 g1,g2, ... (즉, 제1 및 제2 WB 복호화부(110 및 115))의 각각이 다른 WB 설정으로 최종 sRGB 영상들을 생성하는 반면, 부 호화부 f(즉, 도 1의 부호화부)는 입력 sRGB 영상 IWB(in)를 잠재적인 표현(latent representation)으로 전 송한다. 수학식 1과 유사하게, 프레임 워크는 다음과 같이 공식화될 수 있다: 수학식 2"}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이고, 는 원본 입력 sRGB 영상 의 중간 표현(즉, 잠재적인 표현)일 수 있다. 목표는 수학식 1에서의 케이스처럼, 함수 를 다른 WB 설정 를 타겟으로 하는 새로운 함수 로 변경하는 것이 함수 의 어떠한 변경을 요구하지 않는 것과 같이, 함수들 및 를 독립적으로 만드는 것이다. 실시예들에서, 세 가지 다른 WB 설정이 타겟화된다: (i) : AWB- 캡쳐된 영상의 장면의 올바른 조명을 나타냄; (ii) : 텅스텐/백열등(Tungsten/incandescent) - 실내 조명을 위한 WB를 나타냄; 및 (iii) : 쉐이드(shade) - 실외 조명을 위한 WB를 나타냄. 이것은 AWB, 백열등 WB 및 쉐이드 WB에 각각 해당하는 출력 영상들을 생성하는 역할을 하는 세 가지 다른 복호 화부 , 및 를 발생시킨다. 백열등 및 쉐이드 WB는 컬러 속성들(color properties)에 따라 선택된다. 이 것은 상관 색온도 측면에서 조명을 고려할 때 이해될 수 있다. 예를 들어, 백열등 및 쉐이드 WB 설정은 각각 2850K 및 7500K 색 온도와 상관 관계 가 있다. 이 조명 색온도들의 광범위는 만족스러운 조명(pleasing illuminations)의 범위로 간주된다. 게다가, 백열등 WB와 쉐이드 WB 사이의 넓은 색온도 범위는 보간법을 통해 이 범위 내의 색온도를 가진 영상의 근사치를 허용한다. 이 보간 프로세스의 세부 사항은 아래 도 9에서 설명된다. AWB 모드에는 입력 영상의 조명 조건에 따 라 변하기 때문에 고정된 상관 색온도가 없다. 도 1을 다시 참조하면, DNN의 아키텍처에 대한 개요가 도시된다. U-Net 아키텍처는 부호화부와 제1 및 제2 WB 복호화부(110 및 115) 사이의 멀티-스케일 스킵 연결과 함께 이용될 수 있다. 프레임 워크에는 두 개의 메인 유닛이 포함된다. 첫 번째 메인 유닛은 입력 영상의 멀티-스케일 잠재 표현 (중간 표현)을 추출하는 4-레 벨 부호화부 유닛인 부호화부이다. 두 번째 메인 유닛은 적어도 2 개의 4-레벨 복호화부(예를 들어, 제1 및 제2 WB 복호화부(110, 115))들을 포함한다. 각 유닛에는 서로 다른 보틀넥(bottleneck) 및 업샘플링 구성요 소(component)가 있다. 부호화부의 제1 레벨과 제1 및 제2 WB 복호화부(110, 115)의 각각의 마지막 레벨에 서, 각 컨볼루션 레이어는 24 개의 채널을 갖는다. 각각의 후속 또는 이전 레벨에 대해, 채널의 개수가 두 배가 된다. (예를 들어, 부호화부의 제3 레벨은 각 컨볼루션 레이어에 대해 192 개의 채널을 갖는다) 도 2는 도 1의 딥 화이트 밸런싱 편집을 위한 장치의 부호화부의 블록도이다. 도 2를 참조하면, 부호화부는 제1 레벨, 제2 레벨 및 제3 레벨을 포함할 수 있다. 입력 영 상은 제1 레벨, 제2 레벨 및 제3 레벨의 각 레이어를 통해 전송되어 제1 WB 복호화부 및/ 또는 제2 WB 복호화부로 출력되는 중간 표현을 획득할 수 있다. 제1 레벨은 스트라이드(stride) 1 및 패딩(padding) 1을 갖는 3x3 컨볼루션 레이어들(205a 및 205b), 및 ReLU (rectified linear unit) 레이어(205c 및 205d)를 포함할 수 있다. ReLU 레이어(205c)는 컨볼루션 레이어 (205a, 205b) 사이에 위치될 수 있고, 컨볼루션 레이어(205b)는 ReLU 레이어(205c, 205d) 사이에 위치될 수 있 다. 예를 들어, 컨볼루션 레이어(205a, 205b) 및 ReLU 레이어(205c, 205d) 각각은 128x128x24의 크기를 가질 수 있다. 제2 레벨은 스트라이드 2를 갖는 2x2 최대 풀링(max-pooling; 맥스-풀링) 레이어(210a 및 210b), 스트라 이드 1 및 패딩 1을 갖는 3x3 컨볼 루션 레이어(210c 및 210d), 및 ReLU 레이어(210e 및 210f)를 포함할 수 있 다. ReLU 레이어(210e)는 컨볼루션 레이어(210c, 210d) 사이에 위치될 수 있고, 컨볼루션 레이어(210d)은 ReLU 레이어(210e 및 210f) 사이에 위치될 수 있으며, 컨볼루션 레이어(210c 및 210d)와 ReLU 레이어(210e 및 210f)가 최대 풀링 레이어(210a 및 210b) 사이에 위치될 수 있다. 예를 들어, 컨볼루션 레이어(210c, 210d)와 ReLU 레이어(210e, 210f)는 각각 64x64x48의 크기를 가질 수 있고, 최대 풀링 레이어(210a)는 64x64x24의 크기를 가 질 수 있으며, 최대 풀링 레이어(210b)는 32x32x48의 크기를 가질 수 있다. 제3 레벨은 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼 루션 레이어(215a 및 215b), ReLU 레이어(215c 및 215d), 및 스트라이드 2를 갖는 2x2 최대 풀링 레이어(215e)를 포함할 수 있다. ReLU 레이어(215c)는 컨볼루션 레이어(215a, 215b) 사이에 위치될 수 있고, 컨볼루션 레이어(215b)는 ReLU 레이어(215c, 215d) 사이에 위치될 수 있으며, 최대 풀링 레이어(215e)는 컨볼루션 레이어(215a, 215b)와 ReLU 레이어(215c 및 215d) 뒤에 배치될 수 있다. 예를 들어, 컨볼 루션 레이어(215a, 215b)와 ReLU 레이어(215c, 215d)는 각각 16x16x192의 크기를 가질 수 있고, 최대 풀링 레이어(215e)는 8x8x192의 크기를 가질 수 있다. 도 3은 도 1의 딥 화이트 밸런싱 편집 장치의 제1 WB 복호화부의 블록도이다. 도 3을 참조하면, 제1 WB 복호화부는 제1 레벨, 제2 레벨, 제3 레벨 및 제4 레벨을 포함한다. 중간 표현은 제1 레벨, 제2 레벨, 제3 레벨 및 제4 레벨의 각 레이어를 통해 전 달되어 제1 출력 영상을 획득할 수 있다. 제1 레벨은 ReLU 레이어(305a 및 305b) 및 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어(305c 및 305d)를 포함할 수 있다. 컨볼루션 레이어(305c)는 ReLU 레이어(305a, 305b) 사이에 위치될 수 있고, ReLU 레 이어(305b)는 컨볼루션 레이어(305c, 305d) 사이에 위치될 수 있다. 예를 들어, ReLU 레이어(305a, 305b)와 컨 볼루션 레이어(305c, 305d)는 각각 8x8x384의 크기를 가질 수 있다. 제2 레벨은 2x2 업샘플링 레이어(310a), 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어(310b, 310c 및 310d), 뎁스 연결 레이어(depth concatenation layer)(310e) 및 ReLU 레이어(310f 및 310g)를 포함할 수 있 다. 제2 레벨의 레이어들은 입력에서 출력까지, 업샘플링 레이어(310a), 컨볼루션 레이어(310b), 뎁스 연 결 레이어(310e), ReLU 레이어(310f), 컨볼루션 레이어(310c), ReLU 레이어(310g) 및 컨볼루션 레이어(310d)의 순서일 수 있다. 예를 들어, 업샘플링 레이어(310a), 컨볼루션 레이어(310b, 310c, 310d) 및 ReLU 레이어 (310f, 310g)는 각각 16x16x192의 크기를 가질 수 있고, 뎁스 연결 레이어(310e)는 16x16x384의 크기를 가질 수 있다. 제3 레벨은 2x2 업샘플링 레이어(315a), 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어(315b, 315c 및 315d), 뎁스 연결 레이어(315e) 및 ReLU 레이어(315f 및 315g)를 포함할 수 있다. 제3 레벨의 레이어 는, 입력에서 출력까지, 업샘플링 레이어(315a), 컨볼루션 레이어(315b), 뎁스 연결 레이어(315e), ReLU 레이어 (315f), 컨볼루션 레이어(315c), ReLU 레이어(315g) 및 컨볼루션 레이어(315d)의 순서일 수 있다. 예를 들어, 업샘플링 레이어(315a), 컨볼루션 레이어(315b, 315c, 315d) 및 ReLU 레이어(315f, 315g)는 각각 64x64x48의 크기를 가질 수 있고, 뎁스 연결 레이어(315e)는 64x64x96의 크기를 가질 수 있다. 제4 레벨은 2x2 업샘플링 레이어(320a), 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어(320b, 320c 및 320d), 깊이 연결 레이어(320e), ReLU 레이어들(320f 및 320g) 및 스트라이드 1 및 패딩 1을 갖는 1x1 컨볼 루션 레이어(320h)를 포함할 수 있다. 제4 레벨의 레이어는, 입력에서 출력까지, 업샘플링 레이어(320a), 컨볼루션 레이어(320b), 뎁스 연결 레이어(320e), ReLU 레이어(320f), 컨볼루션 레이어(320c), ReLU 레이어 (320g) 및 컨볼루션 레이어(320d) 및 컨볼루션 레이어(320h)의 순서일 수 있다. 예를 들어, 업샘플링 레이어 (320a), 컨볼루션 레이어(320b, 320c, 320d) 및 ReLU 레이어(320f, 320g)는 각각 128x128x24의 크기를 가질 수 있고, 뎁스 연결 레이어(320e)는 128x128x48의 크기를 가질 수 있으며, 컨볼루션 레이어(320h)의 크기는 128x128x3이다. 도 4는 도 1의 딥 화이트 밸런싱 편집 장치의 제2 WB 복호화부의 블록도이다. 도 4를 참조하면, 제2 WB 복호화부는 제1 레벨, 제2 레벨, 제3 레벨 및 제4 레벨을 포함한다. 중간 표현은 제1 레벨, 제2 레벨, 제3 레벨 및 제4 레벨의 각 레이어를 통해 전 달되어 제2 출력 영상을 얻을 수 있다. 제1 레벨은 ReLU 레이어들(405a 및 405b) 및 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어들(405c 및 405d)를 포함할 수 있다. 컨볼루션 레이어(405c)는 ReLU 레이어(405a, 405b) 사이에 위치될 수 있고, ReLU 레이어(405b)는 컨볼루션 레이어(405c, 405d) 사이에 위치될 수 있다. 예를 들어, ReLU 레이어(405a, 405b) 및 컨볼루션 레이어(405c, 405d) 각각은 8x8x384의 크기를 가질 수 있다.제2 레벨은 2x2 업샘플링 레이어(410a), 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어(410b, 410c 및 410d), 뎁스 연결 레이어(410e) 및 ReLU 레이어(410f 및 410g)를 포함할 수 있다. 제2 레벨의 레이어 는, 입력에서 출력까지, 업샘플링 레이어(410a), 컨볼루션 레이어(410b), 뎁스 연결 레이어(410e), ReLU 레이어 (410f), 컨볼루션 레이어(410c), ReLU 레이어(410g) 및 컨볼루션 레이어(410d)의 순서일 수 있다. 예를 들어, 업샘플링 레이어(410a), 컨볼루션 레이어(410b, 410c, 410d) 및 ReLU 레이어(410f, 410g)는 각각 16x16x192의 크기를 가질 수 있고, 뎁스 연결 레이어(410e)는 16x16x384의 크기를 가질 수 있다. 제3 레벨은 2x2 업샘플링 레이어(415a), 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어(415b, 415c 및 415d), 뎁스 연결 레이어(415e) 및 ReLU 레이어(415f 및 415g)를 포함할 수 있다. 제3 레벨의 레이어 는, 입력에서 출력까지, 업샘플링 레이어(415a), 컨볼루션 레이어(415b), 뎁스 연결 레이어(415e), ReLU 레이어 (415f), 컨볼루션 레이어(415c), ReLU 레이어(415g) 및 컨볼루션 레이어(415d)의 순서일 수 있다. 예를 들어, 업샘플링 레이어(415a), 컨볼루션 레이어(415b, 415c, 415d) 및 ReLU 레이어(415f, 415g)는 각각 64x64x48의 크기를 가질 수 있고, 뎁스 연결 레이어(415e)는 64x64x96의 크기를 가질 수 있다. 제4 레벨은 2x2 업샘플링 레이어(420a), 스트라이드 1 및 패딩 1을 갖는 3x3 컨볼루션 레이어(420b, 420c 및 420d), 뎁스 연결 레이어(420e), ReLU 레이어(420f 및 420g) 및 스트라이드 1 및 패딩 1을 갖는 1x1 컨볼루 션 레이어(420h)을 포함할 수 있다. 제4 레벨의 레이어는, 입력에서 출력까지, 업샘플링 레이어(420a), 컨 볼루션 레이어(420b), 뎁스 연결 레이어(420e), ReLU 레이어(420f), 컨볼루션 레이어(420c), ReLU 레이어 (420g), 컨볼루션 레이어(420d), 컨볼루션 레이어(420h)의 순서일 수 있다. 예를 들어, 업샘플링 레이어(420a), 컨볼루션 레이어(420b, 420c, 420d) 및 ReLU 레이어(420f, 420g)는 각각 128x128x24의 크기를 가질 수 있고, 뎁스 연결 레이어(420e)는 128x128x48의 크기를 가질 수 있으며, 컨볼루션 레이어(420h)의 크기는 128x128x3일 수 있다. 도 2 내지 도 4를 참조하면, 스킵 연결(120a)은 부호화부의 제1 레벨을 제1 WB 복호화부의 제4 레벨 및/또는 제2 WB 복호화부의 제4 레벨과 연결할 수 있다. 스킵 연결(120b)은 부호화부(10 5)의 제2 레벨을 제1 WB 복호화부의 제3 레벨 및/또는 제2 WB 복호화부의 제3 레벨 과 연결할 수 있다. 스킵 연결(120c)은 부호화부의 제3 레벨을 제1 WB 복호화부의 제2 레벨 및/또는 제2 WB 복호화부의 제2 레벨과 연결할 수 있다. 도 5는 실시예들에 따른 딥 화이트 밸런싱 편집 방법의 흐름도이다. 방법은 도 1의 딥 화이트 밸런싱 편집 장치를 이용하는 적어도 하나의 프로세서에 의해 수행될 수 있 다. 도 5를 참조하면, 동작에서, 방법은 영상 신호 처리에 의해 보정된 원본 화이트 밸런스를 갖는 입력 영상을 획득하는 단계를 포함한다. 동작 510에서, 방법은 제1 뉴럴 네트워크를 이용하여, 상기 획득된 입력 영상의 중간 표현을 획득하는 단 계를 포함하며, 상기 중간 표현은 영상 신호 처리에 의해 보정되지 않은 원본 화이트 밸런스를 갖는다. 동작 515에서, 방법은 상기 획득된 중간 표현에 기초하여, 제2 뉴럴 네트워크를 이용하여, 원본 화이트 밸 런스와 다른 제1 화이트 밸런스를 갖는 제1 출력 영상을 획득하는 단계를 포함한다. 동작 520에서, 방법은 상기 획득된 중간 표현에 기초하여, 제3 뉴럴 네트워크를 이용하여, 원본 화이트 밸 런스 및 제1 화이트 밸런스와 상이한 제2 화이트 밸런스를 갖는 제2 출력 영상을 획득하는 단계를 포함한다. 상기 방법은 복수의 화이트 밸런스들 중 하나를 선택하기 위한 슬라이더를 표시하고, 복수의 화이트 밸런 스들 중 하나를 선택하는 사용자 입력을 기초로, 표시된 슬라이더를 이용하여, 상기 획득된 제1 출력 영상 상기 획득된 제2 출력 영상 및 상기 획득된 제1 출력 영상 및 상기 획득된 제2 출력 영상의 블렌딩 영상 중 임의의 하나 또는 임의의 조합을 이용하여 복수의 화이트 밸런스들 중 선택된 하나의 화이트 밸런스를 갖는 결과 영상 을 표시하는 단계를 더 포함할 수 있다. 적어도 하나의 프로세서, 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크는 서버에서 구현될 수 있으며, 상기 방법 은 전자 장치의 영상 신호 프로세서로부터 원본 화이트 밸런스가 보정된 입력 영상을 수신하는 단계; 및 영상 신호 프로세서의 영상 신호 처리에 의해, 획득된 제1 출력 영상을 전자 장치로 전송하는 단계를 더 포함할 수 있다.도 6은 실시예들에 따른 딥 화이트 밸런싱 편집을 위한 훈련(또는 학습)(training) 방법의 흐름도이다. 방법은 도 1의 딥 화이트 밸런싱 편집을 위한 장치를 훈련하는 적어도 하나의 프로세서에 의해 수행 될 수 있다. 도 6을 참조하면, 동작 605에서, 방법은 렌더링된 WB 데이터 셋을 획득하는 것을 포함한다. 렌더링된 WB 데이터 셋은 딥 화이트 밸런싱 편집을 위한 장치를 훈련시키고 검증하는데 이용된다. 이 데이터 셋에는 쉐 이드 및 백열등 설정을 포함하여, 다양한 카메라 모델과 다양한 WB 설정으로 렌더링된 ~ 65,000개의 sRGB 영상 들이 포함될 수 있다. 각 영상에 대해 올바른 WB 설정(즉, 올바른 AWB 결과로 간주된)으로 렌더링된 해당 그라 운드-트루쓰 영상(ground-truth image)도 있다. 이 데이터 셋에는 학습 셋(셋 1)와 테스트 셋(셋 2)의 두 가지 서브셋이 포함된다. 장치를 훈련시키고 검증하기 위해 셋 1을 이용한 쓰리-폴드(3-겹) 크로스-검증(Three- fold cross-validation)이 수행된다. 특히, 12,000 개의 훈련 영상이 투 폴드(two folds)로부터 무작위로 선택 되고, 나머지 폴드에서 2,000 개의 검증 영상이 무작위로 선택된다. 각 훈련 영상에 대해, (i) 올바른(correct) WB(AWB로 표시), (ii) 쉐이드 WB 및 (iii) 백열등 WB와 함께 세 개의 그라운드-트루쓰 영상이 렌더링된다. 세 가지 모델들은 훈련 및 검증 폴드(겹)들을 변경하며 훈련된다. 동작에서, 방법은 획득된 렌더링된 WB 데이터 셋을 어그맨테이팅하는 단계를 포함한다. 자세하게는, 렌더링된 WB 데이터 셋에 포함된 동일한 장면의 추가 1,029개의 raw-RGB 영상들을 렌더링하지만 임의의 색온도 를 사용하여 학습 영상이 어그맨테이팅된다. 각 에포크(epoch)에서 각 복호화부에 대해 각 훈련 영상과 해당 그 라운드-트루쓰 영상으로부터 무작위로 4 개의 128x128 패치들이 선택된다. 기하학적 어그맨테이션(로테이션 및 플리핑, rotation and flipping)은 오버피팅(overfitting)을 피하기 위해 추가적인 데이터 어그맨테이션으로서 선택된 패치에 적용될 수 있다. 동작 615에서, 방법은 정확한 WB(correct WB), 쉐이드 WB 및 백열등 WB에 각각 대응하는 재구성된 영상(패 치)을 획득하기 위해 장치를 이용하여 어그맨테이션된 렌더링된 WB 데이터 셋을 처리하는 단계를 포함한다. 동작에서, 방법은 정확한 WB, 쉐이드 WB 및 백열등 WB에 각각 대응하는 재구성된 영상과 그라운드-트 루쓰 영상(패치) 사이의 손실을 획득하는 단계를 포함한다. 예를 들어, 장치는 재구성된 패치와 그라운드- 트루쓰 패치 사이의 스퀘어드 L2-norm 손실 함수를 최소화하도록 훈련된다. 수학식 3"}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "h 및 w는 패치의 너비와 높이를 나타내며, p는 각각 훈련 패치 P 및 그라운드-트루쓰 카메라 렌더링된 패치 C의 각 픽셀에 대한 인덱스이다. 인덱스 는 세개의 타겟 WB 설정들을 나타낸다. 대안적으로, 장치 를 훈련시키기 위해 L1-norm 손실 함수가 이용될 수 있다. 동작 625에서, 방법은 획득된 손실을 최소화하기 위해 장치(예를 들어, 부호화부, 제1 WB 복호 화부 및 제2 WB 복호화부)에서 뉴럴 네트워크의 파라메터를 업데이트하는 단계를 포함한다. 예를 들 어, 장치의 컨볼루션 레이어의 가중치를 초기화한 다음, 그래디언트 이동 평균 감쇠율 및 스퀘어 드 그래디언트 이동 평균의 감쇠율 을 갖는 적응적 모멘트 추정(Adam) 최적화기(adaptive moment estimation optimizer)를 이용하여 165,000 회 반복하여 훈련 과정이 수행될 수 있다. 학습률 이 이용될수 있고, 매 25 에포크마다 0.5만큼 감소될 수 있다. L2 정규화 비율은 와 같이 설정할 수 있고, 미니 배 치 크기는 반복당 32 개의 훈련 패치가 될 수 있다. 도 7은 실시예들에 따른 딥 화이트 밸런싱 편집 방법에서 컬러 맵핑 절차의 도면이다. 실시예들에 따른 DNN 모델은 완전히 컨볼루션 네트워크이며, 2x2 최대 풀링 레이어 및 업샘플링 레이어가 있는 4-레벨 부호화부/복호화부가 이용되기 때문에 차원들이 24의 배수여야 한다는 제한과 함께 입력 영상을 원래 차 원으로 처리할 수 있다. 그러나 모든 크기의 입력 영상에 대해 일관된 실행 시간을 보장하기 위해 모든 입력 영상의 크기를 최대 656 픽 셀로 조정할 수 있다. DNN 모델은 이러한 크기 조정된 영상에 적용된다. 그런 다음, 크기가 조정된 입력 영상과 출력 영상 사이의 컬러 맵핑 함수가 계산되고, 컬러 맵핑 함수가 전체-크기 입력 영상에 적용된다. 도 7을 참조하면, 입력 영상 ( 픽셀들) 및 부호화부 705 및 복호화부들 중 하나(즉, 복호화부 710) 으로부터 생성된 대응 출력 영상 ( 픽셀들, 이때, 및 )에 대하여, 컬러 맵핑 절차는 원본 입력 영상의 해상도(즉, 픽셀들)에서 을 생성하는 것을 목표로 한다. 다운 샘플링된 입력 영상 의 컬러들을 상기 생성된 출력 영상 의 컬러들로 글로벌하게 맵핑하는 맵핑 행렬 을 기초로 하 는 다항식 함수가 채택될 수 있다. 예를 들어, 맵핑 행렬 은 다음과 같이 폐쇄형(closed-form) 솔루션에서 계 산될 수 있다. 수학식 4"}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "은 로부터 를 구축하는 리쉐이프 함 수(reshape function)이고, 는 영상의 RGB 벡터들을 더 높은 n-차원 공간으로 맵핑하는 다 항 커널 함수(polynomial kernel function)일 수 있다. 예를 들어, 11 차원 다항식 맵핑이 이용될 수 있다. 맵핑 행렬 이 계산되면 다음 수학식을 이용하여 동일한 입력 영상 해상도의 최종 결과가 계산될 수 있다. 수학식 5"}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 6, "content": "도 8은 다른 실시예들에 따른 딥 화이트 밸런싱 편집 방법의 흐름도이다. 방법은 도 1의 딥 화이트 밸런싱을 위한 장치를 이용하는 적어도 하나의 프로세서에 의해 수행될 수 있다. 동작 805에서, 방법은 영상 신호 처리에 의해 보정된 원본 화이트 밸런스를 갖는 입력 영상을 획득하는 단 계를 포함한다. 동작 810에서, 방법은 획득된 입력 영상을 다운샘플링하는 것을 포함한다. 동작 815에서, 방법은 제1 뉴럴 네트워크를 이용하여 다운샘플링된 입력 영상의 다운 샘플링된 중간 표현 을 획득하는 단계를 포함하고, 다운샘플링된 중간 표현은 영상 신호 처리에 의해 보정되지 않은 원본 화이트 밸 런스를 갖는다. 동작 820에서, 방법은 획득된 다운샘플링 된 중간 표현에 기초하여, 제2 뉴럴 네트워크를 이용하여, 원본 화이트 밸런스와 상이한 제1 화이트 밸런스를 갖는 다운 샘플링된 출력 영상을 획득하는 단계를 포함한다. 동작 825에서, 방법은 획득된 다운 샘플링된 출력 영상에 컬러 맵핑을 적용하여 원본 화이트 밸런스와 상 이한 제1 화이트 밸런스를 갖는 제1 출력 영상을 획득하는 단계를 포함한다. 도 9는 실시예들에 따른 딥 화이트 밸런싱 편집을 위한 사용자 인터페이스의 도면이다. 사용자 인터페이스는 입력 영상 및 슬라이더를 보여주며, 사용자가 예를 들어 AWB 설정, 쉐이드 WB 설정 및 백열등 WB 설정과 같은 세 가지 이용가능한 WB 설정을 기초로 출력 영상들 중 어떠한 영상을 생성하 는 것 사이에서 선택할 수 있게 한다. 예를 들어, 백열등 WB(2850K)를 갖는 제1 출력영상 또는 쉐이드 WB(7500K)를 갖는 제2 출력 영상이 생성되어, 다음의 도 9의 (a) 및 (b) 부분의 사용자 인터페이스에 각각 표시될 수 있다. 슬라이더는 켈빈의 범위, 예를 들어 2850K 내지 7500K, 내에 있을 수 있고, 사 용자는 슬라이더를 선택된 값으로 슬라이딩함으로써 범위 내 임의의 켈빈 값을 선택할 수 있다. 상기 값을 선택하는 사용자 입력에 기초하여, 사용자 인터페이스는 선택된 값에 대응하는 출력 영상을 보여줄 수 있다. 쉐이드 및 백열등 WB 설정과 범위에서 사용자에 의해 선택된 값을 이용하여 사용자는 도 9의 (c) 부분에 도시된 바와 같이, 입력 영상를 색온도 측면에서 쉐이드 WB 또는 백열등 WB가 아닌 특정 WB(예 : 3500K)를 갖는 제3 출력 영상이 되도록 추가 편집할 수 있다. 복호화부들 중 하나(예를 들어, 제1 WB 복호화부 )에 의해 생성되지 않는 색온도 로 새로운 타겟 WB 설정의 효과를 생성하기 위해, 각각 백열등 및 쉐이드 WB 설정들로 생성된 제1 및 제2 출력 영상(915 및 920)사이의 보간이 수행될 수 있다. 이 동작은 다음 수학식에 의해 설명될 수 있다. 수학식 6"}
{"patent_id": "10-2020-0149896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "및 는 백열등 및 쉐이드 WB 설정들로 각각 생성된 제1 및 제2 출력 영상들(915 및 920)이고, 는 에 의해 주어진 보간 비율(interpolation ratio)일 수 있다. 사용자 인터페이스는 전자 장치, 예를 들어, 모바일 장치에 설치된 사용자 애플리케이션에서 구현될 수 있 다. 사용자 애플리케이션은 영상이 전자 장치의 카메라에 의해 캡처되고 전자 장치의 영상 신호 프로세서에 의 해 처리된 후에 영상의 WB를 편집하기 위한 것일 수 있다. 사용자 애플리케이션은 갤러리 편집 서비스의 일부일 수 있다. 도 10은 실시예들에 따른 컴퓨터 시스템의 블록도이다. 도 10에 도시된 바와 같이, 컴퓨터 시스템은 프로세서, 메모리, 입출력 인터페이스 및 디스플레이를 포함할 수 있다. 컴퓨터 시스템은 전자 장치(예를 들어, 모바일 장치) 및/또는서버로 구현될 수 있다. 프로세서는 도 1의 딥 화이트 밸런싱 편집 장치의 전반적인 제어를 수행할 수 있고, 메모리에 저장된 하나 이상의 프로그램을 실행할 수 있다. 프로세서는 하드웨어, 펌웨어 또는 하드웨어와 소프트웨 어의 조합으로 구현된다. 프로세서는 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 가속 처리 장치 (APU), 마이크로 프로세서, 마이크로 컨트롤러, 디지털 신호 프로세서(DSP), 현장 프로그래밍 가능 게이트 어레 이(FPGA), ASIC(application-specific integrated circuit) 또는 다른 유형의 처리 구성 요소이다. 일부 구현 들에서, 프로세서는 기능을 수행하도록 프로그래밍 될 수 있는 하나 이상의 프로세서를 포함한다. 본 개시의 실시예들에 따른 프로세서는 도 1 내지 도 9를 참조하여 설명된 부호화부, 제1 WB 복호화 부 및 제2 WB 복호화부를 이용하여 동작들 중 임의의 하나 또는 임의의 조합을 수행할 수 있다. 메모리는 해당 드라이브와 함께 하드 디스크 (예: 자기 디스크, 광 디스크, 광 자기 디스크 및/또는 솔리 드 스테이트 디스크), CD (Compact Disc), DVD (Digital Versatile Disc), 플로피 디스크, 카트리지, 자기 테 이프 및/또는 다른 유형의 비 일시적 컴퓨터 판독 가능 매체를 포함할 수 있다. 메모리는 또한 RAM (Random Access Memory), ROM (Read Only Memory) 및/또는 다른 유형의 동적 또는 정적 저장 장치(예를 들어, 플래시 메모리, 자기 메모리 및/또는 광학 메모리)를 포함할 수 있다. 메모리는 장치의 구동 및 제어를 위한 각종 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 메모리에 저장된 프로그램은 하나 이상의 명령어를 포함할 수 있다. 메모리에 저장된 하나 이상의 인스트럭션 또는 어플리케이션을 포함하는 프로그램은 프로세서에 의해 실행될 수 있다. 입 / 출력 인터페이스는 컴퓨터 시스템이 유선 연결, 무선 연결 또는 유선 및 무선 연결의 조합을 통해, 예를 들어, 다른 전자 장치 및 다른 서버와 같은 다른 장치와 통신할 수 있도록 할 수 있다. 예를 들어, 장치 및 컴퓨터 시스템이 서버에 구현된 경우, 프로세서는 입/출력 인터페이스를 통해 전자 장치의 영상 신호 프로세서로부터, 영상 신호 프로세서의 영상 신호 처리에 의해 보정된 원본 화이트 밸런 스를 갖는 입력 영상을 수신할 수 있다. 프로세서는 입/출력 인터페이스를 통해 원래의 화이트 밸 런스와 다른 화이트 밸런스를 갖는 출력 영상을 전자 장치로 더 전송할 수 있다. 디스플레이는, 예를 들면, 프로세서로부터 데이터를 획득하고, 획득된 데이터를 디스플레이할 수있 다. 디스플레이는 예를 들어, 터치 스크린, 텔레비전, 컴퓨터 모니터 또는 이들의 임의의 조합을 포함할 수 있다. 본 개시의 실시예들에 따르면, WB 편집을 위한 딥 러닝 프레임 워크가 제시된다. 프레임 워크는 화이트 밸런스 가 잘못된 영상의 WB를 정확하게 수정한다. 또한 프레임 워크는 사용자에게 sRGB 영상의 WB를 다른 조명 설정으 로 자유롭게 편집할 수 있도록 한다. 프레임 워크에는 단일 부호화부와 멀티 복호화부가 포함된다. 멀티 복호화 부 모델은 종단 간 방식(end-to-end manner)으로 여러 WB 설정을 생성하도록 훈련된다. 상기 프레임 워크는 WB 수정 및 조작에 대한 최첨단 결과를 달성하고, WB 수정 및 조작에 대한 이전 작업에 비하여 더 효율적인 컴파일 결과를 생성할 수 있다. 도 11은 일 실시예에 따른 모바일 장치의 블록도를 도시한다. 도 11을 참조하면, 모바일 장치는 카메라 모듈, 프로세서를 포함한다. 이에 제한되지 않고, 모바일 장치는 디스플레이, 사용자 인터페이스 모듈, 조도 센싱 모듈, GPS 센싱 모듈, 네트워크 정보 획득 모듈 및 저장 모듈을 더 포함할 수 있다. 카메라 모듈은 렌즈 모듈, 영상 센싱 모듈 및 영상 신호 프로세서을 포함할 수 있다. 렌즈 모듈은 피사체에 대해 반사되는 빛을 수집하여 영상 센싱 모듈로 전달하는 적어도 하나의 렌 즈를 포함할 수 있다. 일 실시예에 따르면, 카메라 모듈은 복수의 렌즈 모듈을 포함할 수 있다. 이때, 복 수의 렌즈 모듈은 동일한 렌즈 속성(예를 들어, 화각, 초점거리, 자동초점, f넘버 또는 광학 줌)을 가질 수 있 다. 또는, 적어도 하나의 렌즈 모듈은 다른 렌즈 모듈의 렌즈 속성과 다른 적어도 하나의 렌즈 속성을 가질 수 있다. 예를 들어, 렌즈 모듈은 광각 렌즈, 초광각 렌즈 또는 망원 렌즈 중 적어도 하나의 렌즈를 포함할 수 있다. 영상 센싱 모듈은 렌즈 모듈을 통해 수집되어 전달되는 빛을 전기적 신호로 변환하기 위한 적어도 하나의 영상 센서를 포함할 수 있다. 또한, 영상 센싱 모듈는 변환된 전기적 신호를 이용하여 피사체에 대응하는 영상을 획득할 수 있다. 영상 센싱 모듈을 통해 획득된 영상을 RAW 영상 데이터로 설명한다. 예 를 들어, 적어도 하나의 영상 센서는 CCD(Charged Coupled Device) 센서, CMOS(Complementary Metal-Oxide Semiconductor) 센서일 수 있고, 영상 센싱 모듈은 베이어 패턴(Bayer Pattern)으로 구성된 컬러 필터 어레이와 함께 이에 대응하는 적어도 하나의 CCD 센서, CMOS 센서로 구성된 픽셀 어레이를 포함할 수 있다. 이 에 제한되지 않고, 영상 센싱 모듈은 다양한 형태로 구현될 수 있다. 예를 들어, 영상 센싱 모듈은 포베온 센서로 구현될 수 있다. RAW 영상 데이터란 영상 신호 프로세서에 의해 영상 처리되지 않고, 영상 센싱 모듈로부터 직접 획득된 영상 데이터를 의미할 수 있고, 예를 들어, RAW 베이어 패턴 데이터과 같은, 컬러 필터 어레이 데이터일 수 있다. 영상 신호 프로세서는 RAW 영상 데이터를 영상 처리하여 소정의 영상 포맷의 데이터를 출력할 수 있다. 소정의 영상 포맷이란, 출력 장치(예를 들어, 디스플레이 장치나, 프린터 장치 등과 같은 장치)에서 영상을 출 력하거나 출력 전 저장 장치에 저장하기 위하여, 출력 장치가 나타낼 수 있는 소정의 컬러 스페이스를 갖는 영 상 포맷을 의미할 수 있다. 예를 들어, 소정의 영상 포맷은 RGB 기반 포맷, CMYK 기반 포맷, YCbCr 기반 포맷 등이 있다. RGB 포맷의 일 예로, sRGB, Adobe RGB, Prophoto RGB 포맷 등이 있고, CMYK 기반 포맷의 일 예로, SWOP CMYK 포맷 등이 있다. 예를 들어, 영상 신호 프로세서는 RAW 영상 데이터를 처리하여 sRGB 영상 데이터를 출력할 수 있다. 영상 신호 프로세서는 하드웨어에 의해 구현될 수 있다. 그러나, 이에 제한되지 않고, 소프트웨어와의 결 합에 의해 구현될 수 있다. 이때, 영상 신호 프로세서는 카메라 모듈 외부에 위치하는 프로세서 내에 SW 모듈로 구현될 수 있다. 또한, 영상 신호 프로세서는 카메라 모듈 및 프로세서 와 별개의 하드웨어로 구현될 수 있다. 또한 영상 신호 프로세서는 카메라 모듈 외부에 위치 하는 프로세서와 연동하여 RAW 영상 데이터 처리 기능을 수행할 수 있다. 다른 실시예에서, 영상 신호 프 로세서는 카메라 모듈 내에 SoC(System on Chip)로 구현될 수 있다. 영상 신호 프로세서 또는 프로세서는 디모자이킹 모듈, 노이즈 리덕션 모듈, 화이트- 밸런싱 조정 모듈, 컬러 공간 변환 모듈 및 컬러 보정 모듈 및 영상 출력 모듈을 포함 할 수 있다. 디모자이킹 모듈은, RAW 영상 데이터에 대하여 디모자이킹을 수행할 수 있다. 예를 들어, 디모자이킹 모 듈은, RAW 영상 데이터에 대하여 RGB 디모자이킹을 수행하여 RGB 영상 데이터를 획득할 수 있다. 디모자 이킹은 일종의 컬러 인터폴레이션일 수 있다. 노이즈 리덕션 모듈은 RGB 데이터에 대한 노이즈 리덕션 프로세스를 수행하여 노이즈가 감소된 RGB 영상 데이터를 획득할 수 있다. 화이트-밸런싱 조정 모듈은 입력되는 제 1 영상 데이터에 대하여 화이트 밸런스가 조정된 제 2 영상 데이 터를 출력할 수 있다. 제 1 영상 데이터는 원본 RGB 데이터일 수 있고, 제 2 영상 데이터는 화이트밸런스 조정 된 RGB 데이터일 수 있다. 이때, 제 1 영상 데이터는, 디모자이킹 모듈 및 노이즈 리덕션 모듈 등 중 적어도 하나를 거친 sRGB 영상 데이터일 수 있다. 또는, 제 1 영상 데이터는 원본 컬러 필터 어레이 데이터이고, 제 2 영상 데이터는 화이트밸런스 조정된 컬러 필터 어레이 데이터일 수 있다. 일 실시예에 의하면, 화이트-밸런싱 조정 모듈은 복수의 인공지능 모델 중 적어도 하나의 인공지능 모델 에 제 1 영상 데이터를 입력하여 적어도 하나의 화이트밸런스 조정된 제 2 영상 데이터를 획득할 수 있다. 이때, 복수의 인공지능 모델은 뉴럴 네트워크로 구성되며, 각각의 인공지능 모델은 부호화부 모델과 복호화부 모델을 포함할 수 있다. 복수의 인공지능 모델은 서로 다른 복호화부 모델을 포함할 수 있다. 복수의 인공지능 모델은 하나의 동일한 부호화부 모델을 포함할 수 있다. 예를 들어, 화이트-밸런싱 조정 모듈은 도 1의 부호화부(인코더 모델에 대응), 제1 WB 복호화부 및 제2 WB 복호화부(디코더 모델에 대응) 등을 포함할 수 있다. 다만, 제1 WB 복호화부 및 제2 WB 복호화부에 제한되지 않고, 제3 WB 복호화부, 제4 WB 복호화부, ... 등을 포함할 수 있음을 당업자는 이해할 수 있다. 제1 WB 복호화부 및 제2 WB 복호화부는, 프로세서 또는 영상 신호 프로세서를 이용하여 선택적 으로 사용될 수 있으며, 부호화부를 통해 처리된 데이터를 입력 데이터로 처리한다. 부호화부 및 복수 개의 WB 복호화부는 뉴럴 네트워크로 구성되며, 원본 sRGB 영상 또는 WB가 변경된 sRGB 영상 을 훈련 데이터로 이용하여 훈련될 수 있다. 또한, 부호화부 및 복수 개의 WB 복호화부는 원본 Raw 영상과 WB가 변경된 Raw 영상을 훈련 데이터로 이용하여 훈련될 수도 있다. 여기서, '원본'은 'WB가 변경된'에 대응하는 표현으로 사용하였으며, '원본'은 영상 센싱 모듈을 통해 획 득된 원본 Raw 영상 데이터에 대하여, 영상 신호 프로세서 등에 의해 화이트밸런스 조정이 수행되지 않은 영상만을 의미하는 것에 제한되지 않고, 원본 Raw 영상 데이터에 대하여, 영상 신호 프로세서에 의해 화 이트밸런스 조정이 수행된 영상을 의미할 수도 있다. 이때, 영상 센싱 모듈을 통해 획득된 원본 Raw 영상 데이터에 대하여 영상 신호 프로세서 등에 의 해 화이트밸런스 조정이 수행되지 않은 영상을 입력 데이터로 하는 화이트-밸런싱 조정 모듈은 원본 WB 조정 모듈이라고 하고, 영상 센싱 모듈을 통해 획득된 원본 Raw 영상 데이터에 대하여 영상 신호 프로세 서 등에 의해 화이트밸런스 조정이 수행된 영상을 입력 데이터로 하는 화이트-밸런싱 조정 모듈은 포스트 WB 조정 모듈이라고 구분할 수 있다. 도 11 전의 도면들을 참조하여, 전술한 WB 조정에 관한 내용은, 포 스트 WB 조정 모듈에 관한 설명이나, 이에 제한되지 않고, 도 11 전 도면들을 참조하여 설명된 내용이 원본 WB 조정 모듈에도 적용될 수 있음을 당업자는 이해할 수 있다. 'WB가 변경된'의 의미는, 소정의 WB 복호화부의 출력으로 기대되는 WB 속성(예를 들어, AWB, 백열등 WB 및 쉐이 드 WB)을 갖도록 WB가 변경된 것을 의미할 수 있다. 부호화부는 제1 뉴럴 네트워크로 구성되며, sRGB 영상 데이터를 입력데이터로 입력받을 수 있으며, 입력된 sRGB 영상 데이터에 대응하는 Raw 영상 데이터를 출력데이터로 출력할 수 있다. 일 실시예에서는, 부호화부는, Raw 영상 데이터를 입력데이터로 입력받을 수 있으며, 입력된 Raw 영상 데이터에 대응하는 중간 표현(intermediate representation)을 출력데이터로 출력할 수 있다. 복수의 복호화부 각각은 제1 뉴럴 네트워크와는 상이한 구조를 갖는 제2 뉴럴 네트워크로 구성되며, 부호화부에 서 출력된 Raw 영상 데이터를 입력데이터로 입력받을 수 있다. 부호화부는, 영상 센싱 모듈을 통해 획득 된 원본 Raw 영상 데이터를 입력데이터로 입력받을 수 있다. 이 경우, 복호화부로만 구성된 인공지능 모델이 모 바일 장치에 탑재되어, 영상 센싱 모듈을 통해 획득된 원본 Raw 영상 데이터를 처리할 수 있다. 즉, 인공지능 모델의 학습 단계에서는 복호화부와 부호화부를 하나의 학습 과정을 통해 학습할 수 있으나, 학습 된 인공지능 모델을 모바일 장치에 적용하는 경우에는 복호화부만을 선별하여 모바일 장치의 저장 모듈에 저장할 수 있다. 일 실시예에서는, 복호화부 각각은, 부호화부에서 출력된 중간 표현(intermediate representation)을 입력데이 터로 입력받을 수 있다. 복수의 복호화부는 미리 지정된 WB 속성에 대응하도록 입력 데이터를 변환하여 출력한 다. 복호화부가 Raw 영상 데이터를 입력데이터로 입력받는 경우에는 각 복호화부에 대응하는 WB 속성에 따라 Raw 영 상 데이터를 변환하여 WB 속성이 반영된 sRGB 영상 데이터를 생성하여 출력한다. 일 실시예에서는, 사용자와의 인터페이스를 위해, sRGB 영상 데이터로 변환하여 표시하고 표시된 화면을 통해 사용자가 선호하는 WB 셋팅 값을 입력 받지만, 사용자가 선호하는 WB 셋팅 값을 적용한 영상을 재획득하기 위해 서 화이트-밸런싱 조정 모듈은 먼저 표시된 sRGB 영상에 대응하는 Raw 영상 데이터를 부호화부를 통해 획득하고, 사용자 선호 WB 셋팅에 대응하는 복호화부를 통해 WB가 변경된 sRGB 영상 데이터를 획득할 수 있다. 다른 실시예에서는, 별도의 센서 모듈을 통해 획득한 촬영 조건(shooting condition)에 대한 정보에 기초 하여, 복수의 인공지능 모델 중 하나를 선택하고 선택된 인공지능 모델을 통해 촬영 조건에 대응하는 WB 셋팅값 이 적용된 영상을 획득할 수 있다. 이 경우, 인공지능 모델은 복호화부로만 구성된 인공지능 모델일 수 있으며, 영상 센싱 모듈을 통해 획득된 원본 Raw 영상 데이터를 입력데이터로 입력받을 수 있다. 또한, 복호화부가 입력된 Raw 영상 데이터에 대응하는 중간 표현(intermediate representation)을 입력데이터로 입력받는 경우에는 각 복호화부에 대응하는 WB 속성에 따라 변환된 Raw 영상 데이터를 생성하여 출력한다. 즉, 사용자의 인터페이스가 필요하지 않은 경우, 사용자가 선호하는 WB 셋팅 값을 적용한 영상을 재획득하기 위해서 화이트-밸런싱 조정 모듈은 Raw 영상 데이터에 대응하는 중간 표현을 부호화부를 통해 획득하고, 사용자 선호 WB 셋팅에 대응하는 복호화부를 통해 WB가 변경된 Raw 영상 데이터를 획득할 수 있다. 제 1 뉴럴 네트워크와 적어도 하나의 제 2 뉴럴 네트워크의 가중치 및 바이어스는 미리 훈련되어 설정될 수 있 다. 일 실시예에서는, 프로세서 또는 영상 신호 프로세서는 별도의 훈련 장치로부터 미리 훈련되어 저장된 제1 뉴럴 네트워크와 적어도 하나의 제 2 뉴럴 네트워크의 가중치 및 바이어스를 수신하고, 저장 모듈 에 저장된 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크가 수신된 적어도 하나의 가중치 및 바이어스로 설정 되도록 제어할 수 있다. 화이트-밸런싱 조정 모듈은 센서 모듈을 통해 획득된 촬영 조건에 대한 정보에 기초하여, 저장 모 듈에 저장된 복수의 인공지능 모델 중 촬영 조건에 대응하는 인공지능 모델을 결정하고, 결정된 인공지능 모델에 제 1 영상 데이터를 입력하여 촬영 조건에 대응하도록 화이트밸런스 조정된 제2 영상 데이터를 획득할 수 있다. 이와 관련하여, 하기 센서 모듈을 설명한 후에, 관련 내용을 상술하겠다. 컬러 공간 변환 모듈은 입력되는 영상 데이터에 대한 컬러 공간 변환을 수행하여 변환된 컬러 공간(color space)을 갖는 영상 데이터를 획득할 수 있다. 예를 들어, 컬러 공간 변환 모듈은 RGB 영상 데이터에 대 하여 컬러 공간 변환을 수행하여 CIE-XYZ 영상 데이터를 획득할 수 있다. 컬러 보정 모듈는 변환된 컬러 공간을 갖는 영상 데이터에 대하여 컬러 보정을 수행하여 컬러 보정된 영 상 데이터를 획득할 수 있다. 컬러 보정(color manipulation)은 감마 보정을 포함할 수 있으며, photo- finishing이라 칭할 수 있다. 영상 출력 모듈는 컬러 보정된 영상 데이터에 대한 맵핑을 수행하여 영상 데이터를 출력할 수 있다. 예를 들어, 출력되는 영상 데이터는 sRGB 영상 데이터일 수 있다. 센서 모듈는 촬영 조건(shooting condition)에 대한 정보를 획득할 수 있다. 예를 들어, 센서 모듈 은 조도 센싱 모듈, GPS 센싱 모듈 및 네트워크 정보 획득 모듈를 포함할 수 있다. 조도 센싱 모듈는 조도 센서 정보를 획득할 수 있다. 조도 센서 정보는 조도 센서에 의해 센싱되는 럭스 (lux)를 나타낼 수 있다. GPS 센싱 모듈는 GPS 센서 정보를 획득할 수 있다. GPS 센서 정보는 GPS 센서에 의해 획득되는 위도/경도 /고도 중 적어도 하나를 나타낼 수 있다. GPS 센서 정보는 주기적으로 또는 요청에 따라 비주기적으로 획득되어 업데이트될 수 있다. 네트워크 정보 획득 모듈는 네트워크 상태 정보를 획득할 수 있다. 네트워크 상태 정보는 스캔된 AP(Access Point)의 적어도 하나의 AP(Access Point)의 RSSI(Received Signal Strength Indication) 정보 및 스캔된 적어도 하나의 AP의 SSID(Service Set Identifier) 정보 중 적어도 하나를 포함할 수 있으나, 이에 제한 되지 않는다. 화이트-밸런싱 조정 모듈은 센서 모듈을 통해 획득된 상기 촬영 조건에 대한 정보에 기초하여, 저 장 모듈에 저장된 화이트밸런스 조정을 위한 복수의 인공지능 모델 중, 상기 촬영 조건에 대응하는 인공 지능 모델을 결정하고, 결정된 인공지능 모델에 제1 영상 데이터를 입력하여, 상기 촬영 조건에 대응하도록 화 이트밸런스 조정된 제2 영상 데이터를 획득할 수 있다. 예를 들어, 화이트-밸런싱 조정 모듈은 GPS 센서 정보, 조도 센서 정보 및 네트워크 상태 정보 중 적어도 하나를 기초로, 모바일 장치가 실내 또는 실외에 위치하는지를 식별할 수 있다. 화이트-밸런싱 조정 모듈 은 식별 결과를 기초로, 식별 결과에 대응하는 인공지능 모델을 결정할 수 있다. 예를 들어, 실내의 조명(lighting)을 나타내는 텅스텐/백열등(Incandescent) 화이트 밸런스 설정(또는 형광등 화이트 밸런스 설정)을 실외의 조명(lighting)을 나타내는 쉐이드(Shade) 화이트 밸런스 설정 등이 존재할 수 있고, 화이트-밸런싱 조 정 모듈은 모바일 장치가 실내 또는 실외에 위치하는지를 식별하고, 식별 결과를 기초로, 다양한 화이트 밸런스 설정 중에 식별 결과와 관련된 화이트 밸런스 설정에 대응하는 인공지능 모델을 결정할 수 있다. 도 11 전 도면들을 참조하여, 소정의 WB 설정(예를 들어, AWB 설정, 백열등 WB 설정 및 쉐이드 WB 설정)에 대응 하는 WB 복호화부를 각각 이용하여 소정의 WB 설정이 된 출력 영상 데이터를 획득하는 내용을 설명하였으나, 이 에 제한되지 않고, 도 11 전 도면들의 실시예에서도 촬영 조건(실내/실외)에 대한 정보에 기초하여, 제1 영상 데이터로부터 촬영 조건에 대응하도록 화이트밸런스 조정된 제2 영상 데이터를 획득할 수 있음을 당업자는 이해 할 수 있다. AWB 설정이 일반적으로 올바른 WB 설정이긴 하나, 촬영 조건(실내/실외)에 대한 정보에 기초하여 결정된 WB 설 정에 대응하는 WB복호화부를 이용하여 보다 알맞은 WB 설정을 갖는 출력 영상을 획득할 수 있다. 이에 제한되지 않고, AWB 설정의 출력 영상과 실내 WB 설정/실외 WB 설정 중 촬영 조건에 대응하는 WB 설정의 출력 영상이 동 시에 획득되고, 디스플레이에 출력 영상들을 표시하여 사용자가 그 중 하나를 선택할 수 있다. 일 실시예로, 프로세서은 적어도 하나의 센서 모듈을 통해 획득된 촬영 조건에 대한 정보를 이용하 여 획득된 정보에 대응하는 WB 설정을 결정할 수 있다. 프로세서는 저장 모듈에 저장된 복수의 인 공지능 모델 중 결정된 WB 설정에 대응하는 인공지능 모델을 결정할 수 있다. 프로세서은, 결정된 인공지 능 모델이 영상 신호 프로세서에 로딩(loading)되어 영상 센싱 모듈로부터 획득한 CFA 영상 데이터 를 처리하도록, 영상 신호 프로세서를 제어할 수 있다. 좀 더 상세하게는, 프로세서은 저장 모듈 에 저장된 복수의 인공지능 모델 중 결정된 인공지능 모델에 대한 데이터를 영상 신호 프로세서 내 에 위치한 메모리(미도시)에 로딩(loading)하도록 제어할 수 있다. 영상 신호 프로세서는, 영상 센싱 모 듈로부터 입력된 CFA 영상 데이터를 메모리에 로딩된 인공지능 모델에 대한 데이터를 이용하여 처리할 수 있다. 영상 신호 프로세서는, CFA 영상 데이터를 인공지능 모델로 처리하여 RGB 영상 데이터를 획득할 수 있다. 일 실시예에서, 영상 신호 프로세서 내에 저장 모듈(미도시)은 복수의 인공지능 모델을 저장할 수 있다. 여기서, 저장 모듈은 영상 신호 프로세서 내에 위치한 메모리와 상이하다. 즉, 저장 모듈은 플래쉬 메모 리, DRAM일 수 있으며, 메모리는 SRAM일 수 있다. 이 경우, 영상 신호 프로세서은 프로세서으로부 터 적어도 하나의 센서 모듈을 통해 획득된 정보를 이용하여 획득된 정보에 대응하는 WB 설정에 대한 데 이터를 수신한다. 영상 신호 프로세서은 수신된 WB 설정에 대한 데이터를 이용하여 처리할 인공지능 모델 을 결정할 수 있다. 영상 신호 프로세서은 결정된 인공지능 모델을 영상 신호 프로세서 내에 위치 한 메모리(미도시)에 로딩(loading)하도록 제어할 수 있다. 영상 신호 프로세서는, 영상 센싱 모듈(111 4)로부터 입력된 CFA 영상 데이터를 메모리에 로딩된 인공지능 모델에 대한 데이터를 이용하여 처리할 수 있다. 영상 신호 프로세서는, CFA 영상 데이터를 인공지능 모델로 처리하여 RGB 영상 데이터를 획득할 수 있다. 화이트-밸런싱 조정 모듈은 GPS 센서 정보가 업데이트되지 않는 경우, 모바일 장치가 실내에 위치한다고 식별하고, GPS 센서 정보가 업데이트되는 경우, 모바일 장치가 실외에 위치한다고 식별할 수 있다. 화이트-밸런싱 조정 모듈은 조도 센서 정보의 센서 값(예를 들어, lux 값)이 소정의 제 1 값보다 크거나 같은 경우, 모바일 장치가 실외에 위치한다고 식별할 수 있다. 이때, 화이트-밸런싱 조정 모듈은 현재 시 간 정보를 기초로, 해가 떠있는지를 식별하고, 현재 시간에 대응하는 해의 위치에 따라 예상되는 값이 소정의 제 1 값으로 설정될 수 있다. 해가 떠있지 않을 것으로 예상되는 시간에는 인위적인 조명만이 존재하므로, 조도 센서 정보의 센서 값에 관계없이 실내에 위치하는 것과 다르지 않게 식별될 수 있다. 화이트-밸런싱 조정 모듈은 GPS 조도 센서 정보의 센서 값(예를 들어, lux 값)이 소정의 제2 값보다 작거 나 같은 경우, 모바일 장치가 실내에 위치한다고 식별할 수 있다. 화이트-밸런싱 조정 모듈은 스캔된 AP의 RSSI의 평균값이 소정의 제1값보다 크거나 같은 경우, 모바일 장 치가 실내에 위치한다고 식별하고, 스캔된 AP의 RSSI의 평균값이 소정의 제2값보다 작은 경우, 상기 모바일 장 치가 실외에 위치한다고 식별할 수 있다. 또는, 화이트-밸런싱 조정 모듈은 스캔된 AP 중 RSSI가 소정의 제2값보다 작거나 같은 AP의 개수가 소정 의 제2 개수보다 크거나 같거나, 상기 소정의 제1값보다 크거나 같은 AP의 개수가 소정의 제1 개수보다 작은 경 우, 모바일 장치가 실외에 위치한다고 식별할 수 있다.화이트-밸런싱 조정 모듈은 스캔된 AP중 RSSI가 소정의 제1 값보다 크거나 같은 AP의 개수가 소정의 제1 개수보다 크거나 같은 경우, 상기 모바일 장치가 실내에 위치한다고 식별할 수 있다. 화이트-밸런싱 조정 모듈은 스캔된 AP 중 RSSI가 소정의 제2값보다 작거나 같은 AP의 개수가 소정의 제2 개수보다 크거나 같거나, 상기 소정의 제1값보다 크거나 같은 AP의 개수가 소정의 제1 개수보다 작은 경우, 모 바일 장치가 실외에 위치한다고 식별할 수 있다. 한편, SSID의 일부분이 소정의 문자열에 대응되는 AP만이 상기 조건 만족 여부 결정시에 고려될 수 있다. 이에 제한되지 않고, 해당 AP를 제외하거나, 해당 AP의 그룹 및 그 외 AP의 그룹을 구별하여 각 그룹의 중간 조건 만 족 여부에 관한 결과에 서로 다른 가중치를 부여하여 최종 조건의 만족 여부가 결정될 수 있다. 화이트-밸런싱 조정 모듈이 GPS 센서 정보, 조도 센서 정보 및 네트워크 상태 정보 중 적어도 하나를 기 초로, 모바일 장치가 실내 또는 실외에 위치하는지를 식별하는 구체적인 실시예에 대하여, 도 12을 참조 하여 후술하겠다. 디스플레이는 다양한 영상 데이터를 표시할 수 있다. 특히, 디스플레이는 영상 신호 프로세서 등을 통해 출력되는 소정의 영상 포맷의 데이터를 표시하도록 프로세서에 의해 제어된다. 사용자 인터페이스 모듈은 다양한 형태의 사용자 입력을 수신할 수 있다. 디스플레이와 사용자 인 터페이스 모듈은 터치 센서와 디스플레이 패널(예를 들어, LCD 또는 AMOLED)를 포함하는 터치 스크린 형 태로 구현될 수 있다. 프로세서는 사용자 인터페이스 모듈을 통해 수신한 사용자 입력에 기초하여, 카메라 모듈을 구동하도록 제어할 수 있다. 즉, 프로세서은 디스플레이 패널에 이미지 촬영을 개시 하는 UI(User Interface) 아이콘 및 이미지 촬영 조건을 설정하기 위한 UI 아이콘이 표시되도록 디스플레이 패 널을 제어할 수 있다. 프로세서은 터치 센서를 통해 입력받은 사용자 입력을 수신하면 카메라 모듈 내 렌즈 모듈을 통해 수집된 빛을 영상 센싱 모듈이 전기적 신호로 변환하도록 제어할 수 있다. 저장 모듈은 다양한 영상 데이터를 저장할 수 있다. 특히, 저장 모듈은 영상 신호 프로세서 등을 통해 출력되는 소정의 영상 포맷의 데이터를 저장하도록 프로세서에 의해 제어된다. 저장 모듈 에 저장되는 영상 포맷은, 디스플레이에 출력되는 영상 포맷과 상이할 수 있다. 예를 들어, 프로세 서는 화이트-밸런싱 조정 모듈로부터 획득된 적어도 하나의 출력 영상을 소정의 압축 표준(예를 들 어, JPEG 표준)에 따라 손실/무손실 압축하고, 압축된 출력 영상을 저장 모듈에 저장하도록 제어할 수 있 다. 또한, 저장 모듈은 화이트-밸런싱 조정 모듈에서 이용되는 인공지능 모델에 관한 정보를 저장할 수 있다. 도 12는 일 실시예에 따라, 모바일 장치가 획득한 다양한 정보를 기초로 실내인지 실외인지를 식별하고, 식별된 결과를 기초로 화이트 밸런싱 조정을 수행하는 것을 설명하기 위한 도면이다. 도 12를 참조하면, 모바일 장치는 실내등(예를 들어, 형광등 또는 백열등)으로부터 나오는 빛을 조 도 센서를 이용하여 센싱함으로써 조도 센서 정보를 획득할 수 있다. 모바일 장치는 조도 센서 정 보의 값이 소정의 제 1 값보다 작거나 같은 경우, 모바일 장치가 실내에 위치한다고 식별할 수 있다. 일 반적으로, 실내에서의 조도 값은 실외에서의 조도 값에 비하여 상당히 작기 때문이다. 한편, 모바일 장치는 GPS 센서를 이용하여 GPS 위성으로부터 GPS 센서 정보를 획득할 수 있다. 모 바일 장치는 GPS 센서 정보가 업데이트되지 않는 경우, 모바일 장치는 실내에 위치한다고 식별할 수 있다. 일반적으로, 모바일 장치가 실내에 위치하는 경우, GPS 센서 정보를 수신하기 어렵기 때문이다. 모바일 장치는 주변의 AP를 스캔하여 적어도 하나의 스캔된 AP 리스트를 획득할 수 있다. 모바일 장치는 스캔된 AP의 SSID 개수를 기초로, 스캔된 AP의 개수를 식별할 수 있고, 스캔된 AP의 RSSI를 기초로, AP의 신호 세기를 식별할 수 있다. 모바일 장치는 스캔된 AP의 RSSI의 평균값이 소정의 제1값보다 크거나 같은 경우, 모바일 장 치가 실내에 위치한다고 식별할 수 있다. 일반적으로, 모바일 장치가 실내에 위치하는 경우, AP가 가깝게 위치하고 있기 때문에, AP의 RSSI의 평균값이 작기 때문이다. 또는, 모바일 장치는 스캔된 AP중 RSSI가 소정의 제1 값보다 크거나 같은 AP의 개수가 소정 의 제1 개수보다 크거나 같은 경우, 모바일 장치가 실내에 위치한다고 식별할 수 있다. 일반적으로, 모바일 장치가 실내에 위치하는 경우, 많은 AP가 모바일 장치가 가깝게 위치하고 있기 때문에, RSSI가 큰 AP가 실외에 비하여 많기 때문이다. 한편, 모바일 장치는 태양으로부터 나오는 빛을 조도 센서를 이용하여 센싱함으로써 조도 센 서 정보를 획득할 수 있다. 모바일 장치는 조도 센서 정보의 값이 소정의 제 2 값보다 크거나 같은 경우, 모바일 장치가 실외에 위치한다고 식별할 수 있다. 일반적으로, 실외에서의 조도 값은 실내에서의 조도 값에 비하여 상당히 크기 때문이다. 모바일 장치는 GPS 센서를 이용하여 GPS 위성으로부터 GPS 센서 정보를 획득할 수 있다. 모바일 장 치는 GPS 센서 정보가 업데이트되는 경우, 모바일 장치가 실외에 위치한다고 식별할 수 있다. 일반 적으로, 모바일 장치가 실외에 위치하는 경우, 실내에 비하여 GPS 센서 정보를 수신하기 쉽기 때문에 대 부분의 경우 요청에 따라 GPS 센서 정보가 업데이트될 수 있기 때문이다. 모바일 장치는 주변의 AP를 스캔할 수 있다. 모바일 장치는 스캔된 AP의 SSID 개수를 기초로, 스캔된 AP의 개수를 식별할 수 있고, 스캔된 AP의 RSSI를 기초로, AP의 신호 세기를 식별할 수 있다. 모바일 장치는 스캔된 AP의 RSSI의 평균값이 소정의 제2값보다 작은 경우, 모바일 장치 가 실외에 위치한다고 식별할 수 있다. 일반적으로, 모바일 장치가 실외에 위치하는 경우, AP가 멀리 위치하거나 다양한 장애물에 의하여 AP의 RSSI의 평균값이 작기 때문이다. 또는, 모바일 장치는 스캔된 AP중 RSSI가 소정의 제2 값보다 작거나 같은 AP의 개수가 소정 의 제2 개수보다 크거나 같은 경우, 모바일 장치이 실외에 위치한다고 식별할 수 있다. 일반적으로, 모바 일 장치이 실외에 위치하는 경우, AP가 멀리 위치하거나 다양한 장애물에 의하여 RSSI가 작은 AP가 실내에 비하여 많기 때문이다. 다만 이에 제한되지 않고, 모바일 장치는 스캔된 AP중 RSSI가 소정의 제 1 값보다 크거나 같 은 AP의 개수가 소정의 제1 개수보다 작은 경우, 모바일 장치가 실외에 위치한다고 식별할 수 있다. 일반 적으로, 모바일 장치가 실외에 위치하는 경우, 모바일 장치와 가까이 위치하는 AP가 실내에 비하여 적기 때문이다. 다만 이에 제한되지 않고, 모바일 장치는 다양한 기법에 따라, 조도 센서 정보, GPS 센서 정보 및 네트워 크 상태 정보 중 적어도 하나를 기초로, 모바일 장치가 실내에 위치하는지 또는 실외에 위치하는지를 식 별할 수 있다. 모바일 장치는 식별된 결과를 기초로 화이트 밸런싱 조정을 수행할 수 있다. 예를 들어, 실내의 조명 (lighting)을 나타내는 텅스텐/백열등(Incandescent) 화이트 밸런스 설정(또는 형광등 화이트 밸런스 설정)을 실외의 조명(lighting)을 나타내는 쉐이드(Shade) 화이트 밸런스 설정(또는 일광 화이트 밸런스 설정)이 존재할 수 있고, 모바일 장치는 모바일 장치가 실내 또는 실외에 위치하는지를 식별하고, 식별 결과를 기 초로, 복수의 화이트 밸런스 설정과 관련된 복수의 인공지능 모델들 중 하나의 화이트 밸런스 설정과 관련된 인 공지능 모델을 결정하고, 결정된 인공지능 모델을 이용하여 출력 영상을 획득할 수 있다. 본 개시의 실시예가 도면을 참조하여 설명되었지만, 당업자는 다음 청구항에 의해 정의된 사상 및 범위를 벗어 나지 않고, 형태 및 세부 사항의 다양한 변경이 이루어질 수 있음을 이해할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2020-0149896", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예들의 상기 측면들 및 다른 측면들 및 특징들은 첨부 도면들과 함께 취해진 다음 설명으로부터 더 명백해질 것이다. 도 1은 실시예들에 따른 딥 화이트 밸런싱 편집을 위한 장치의 블록도이다. 도 2는 도 1의 딥 화이트 밸런싱 편집 장치의 부호화부의 블록도이다. 도 3은 도 1의 딥 화이트 밸런싱 편집 장치의 제1 WB 복호화부의 블록도이다. 도 4는 도 1의 딥 화이트 밸런싱 편집 장치의 제2 WB 복호화부의 블록도이다. 도 5는 실시예들에 따른 딥 화이트 밸런싱 편집 방법의 흐름도이다. 도 6은 실시예들에 따른 딥 화이트 밸런싱 편집을 위한 훈련 방법의 흐름도이다. 도 7은 실시예들에 따른 딥 화이트 밸런싱 편집 방법에서 컬러 맵핑 절차의 도면이다. 도 8은 다른 실시예들에 따른 딥 화이트 밸런싱 편집 방법의 흐름도이다. 도 9는 실시예들에 따른 딥 화이트 밸런싱 편집을 위한 사용자 인터페이스의 도면이다. 도 10은 실시예들에 따른 컴퓨터 시스템의 블록도이다. 도 11은 일 실시예에 따른 모바일 장치의 블록도를 도시한다. 도 12는 일 실시예에 따라, 모바일 장치가 획득한 다양한 정보를 기초로 실내인지 실외인지를 식별하고, 식별된 결과를 기초로 화이트 밸런싱 조정을 수행하는 것을 설명하기 위한 도면이다."}
