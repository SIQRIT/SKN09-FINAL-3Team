{"patent_id": "10-2022-0116027", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0038180", "출원번호": "10-2022-0116027", "발명의 명칭": "자율 주행 차량 및 그것의 원격 제어 방법", "출원인": "(주)디엔에이모티브", "발명자": "송영기"}}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자율 주행 차량의 외부의 객체를 탐지하기 위한 적어도 하나의 센서; 및상기 적어도 하나의 센서를 통해 획득한 제1 데이터를 원격 제어 장치로 전송하고, 상기 원격 제어 장치가 상기제1 데이터에 응답하여 전송하는 제2 데이터를 수신하는 데이터 처리 유닛을 포함하고,상기 제2 데이터에 기초하여 상기 적어도 하나의 센서의 관측 시야(field of view, FOV)를 조정하는, 자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 적어도 하나의 센서는,라이다(LiDAR), 레이더(Radar), 또는 카메라(Camera)를 포함하는,자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 라이다는,상기 자율 주행 차량의 상부 프레임 위로 돌출되게 설치되고, 상기 상부 프레임으로부터 상기 라이다까지의 높이가 조정 가능한,자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 레이더는,상기 자율 주행 차량의 전방 또는 후방에 설치되고, 상기 레이더의 탐지 범위가 조정 가능한,자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 카메라는,상기 자율 주행 차량의 전방, 후방, 또는 측방에 설치되고, 상기 카메라의 탐지 범위가 조정 가능한,자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 관측 시야의 조정은,상기 제2 데이터에 기초하여 상기 적어도 하나의 센서의 높이, 시야각, 시야거리, 또는 탐지 방향을 조정하는것을 포함하는,공개특허 10-2024-0038180-3-자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 원격 제어 장치는,상기 제1 데이터를 기초로 상기 제1 데이터 내 객체 중 이동식 객체를 식별하고, 상기 적어도 하나의 센서가 상기 이동식 객체를 포커스(focus)하도록 상기 제2 데이터를 생성하는,자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 원격 제어 장치는,상기 제1 데이터와 미리 저장된 레퍼런스 데이터를 비교하고, 상기 제1 데이터와 상기 레퍼런스 데이터 간 차이에 기초하여 상기 이동식 객체를 식별하는,자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 제2 데이터에 기초하여 상기 자율 주행 차량의 주행 속도를 조정하는,자율 주행 차량."}
{"patent_id": "10-2022-0116027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨팅 장치에 의해 수행되는 자율 주행 차량의 원격 제어 방법에 있어서,적어도 하나의 센서를 통해 자율 주행 차량의 외부의 객체를 탐지하여 제1 데이터를 생성하는 단계;상기 제1 데이터를 원격 제어 장치로 전송하는 단계;상기 원격 제어 장치가 상기 제1 데이터에 응답하여 전송하는 제2 데이터를 수신하는 단계; 및상기 제2 데이터에 기초하여 상기 적어도 하나의 센서의 관측 시야(field of view, FOV)를 조정하는 단계를 포함하는,자율 주행 차량의 원격 제어 방법."}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "자율 주행 차량 및 그것의 원격 제어 방법이 제공된다. 본 발명에 따른 자율 주행 차량은, 자율 주행 차량의 외 부의 객체를 탐지하기 위한 적어도 하나의 센서, 및 상기 센서를 통해 획득한 제1 데이터를 원격 제어 장치로 전 송하고 상기 원격 제어 장치가 상기 제1 데이터에 응답하여 전송하는 제2 데이터를 수신하는 데이터 처리 유닛을 (뒷면에 계속)"}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율 주행 차량 및 그것의 원격 제어 방법에 관한 것이다. 보다 자세하게는, 원격의 관제 센터가 자 율 주행 차량과 데이터를 송수신하며 이를 기초로 자율 주행 차량을 원격 제어하는 자율 주행 차량 및 그것의 원격 제어 방법에 관한 것이다."}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율 주행 차량은 운전자 또는 탑승객의 조작 없이 스스로 운행이 가능한 자동차로서, 소프트웨어, 인공지능, 통신, 센서 기술을 기반으로 주변 환경을 인식하여 위험을 판단하고 경로를 계획하여 운전자 개입 없이 자율적 인 주행이 가능한 차량이다. 자율 주행 차량은 운전자 또는 탑승객의 개입 없이 센서 기술에 의존하여 주변 환경을 인식하고 도로를 주행하 므로, 센서 기술의 수준이 자율 주행 차량의 안전도와 직결된다고 볼 수 있다. 자율 주행 차량에 이용되는 센서로는. 차량 주변 객체를 광학적으로 식별하는 카메라, 주변 객체와의 거리 및 차량의 속도 등을 측정하는 레이더, 차량 주변 객체의 원근감과 형태를 인식하는 라이다 등이 있으며, 자율 주 행 차량은 주변 환경을 종합적으로 감지 및 식별하기 위해 이들 센서를 복합적으로 이용하는 것이 일반적이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-2031619호 (2022.08.08 공고)"}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들을 통해 해결하고자 하는 기술적 과제는, 자율 주행 차량의 데이터를 기초로 최적의 관측 시 야(Field of View, FOV)를 갖도록, 자율 주행 차량의 센서가 조정될 수 있는 자율 주행 차량 및 그것의 원격 제 어 방법을 제공하는 것이다. 본 발명의 실시예들을 통해 해결하고자 하는 다른 기술적 과제는, 자율 주행 차량의 데이터를 기초로 차량 주변 환경을 인식하여 안전 주행을 위한 원격 제어가 수행되는 자율 주행 차량 및 그것의 원격 제어 방법을 제공하는 것이다. 본 발명의 실시예들을 통해 해결하고자 하는 또 다른 기술적 과제는, 자율 주행 차량의 원격 제어에 적합한 센 서 시스템 및 데이터 처리 유닛이 구비된 자율 주행 차량 및 그것의 원격 제어 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 아래의 기재로부터 본 발명의 기술분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 자율 주행 차량은, 자율 주행 차량의 외부의 객체를 탐지하기 위한 적어도 하나의 센서, 및 상기 적어도 하나의 센서를 통해 획득한 제1 데이터를 원격 제어 장치로 전송하고 상기 원격 제어 장치가 상기 제1 데이터에 응답하여 전송하는 제2 데이터를 수신하는 데이터 처리 유닛을 포함하고, 상기 제2 데이터에 기초하여 상기 적어도 하나의 센서의 관측 시야(field of view, FOV)를 조정할 수 있다. 일 실시예로서, 상기 적어도 하나의 센서는 라이다(LiDAR), 레이더(Radar), 또는 카메라(Camera)를 포함할 수 있다. 일 실시예로서, 상기 라이다는 상기 자율 주행 차량의 상부 프레임 위로 돌출되게 설치되고, 상기 상부 프레임 으로부터 상기 라이다까지의 높이가 조정 가능할 수 있다. 일 실시예로서, 상기 레이더는 상기 자율 주행 차량의 전방 또는 후방에 설치되고, 상기 레이더의 탐지 범위가 조정 가능할 수 있다. 일 실시예로서, 상기 카메라는 상기 자율 주행 차량의 전방, 후방, 또는 측방에 설치되고, 상기 카메라의 탐지 범위가 조정 가능할 수 있다. 일 실시예로서, 상기 관측 시야의 조정은 상기 제2 데이터에 기초하여 상기 적어도 하나의 센서의 높이, 시야각, 시야거리, 또는 탐지 방향을 조정하는 것을 포함할 수 있다. 일 실시예로서, 상기 원격 제어 장치는 상기 제1 데이터를 기초로 상기 제1 데이터 내 객체 중 이동식 객체를 식별하고, 상기 적어도 하나의 센서가 상기 이동식 객체를 포커스(focus)하도록 상기 제2 데이터를 생성할 수 있다. 일 실시예로서, 상기 원격 제어 장치는 상기 제1 데이터와 미리 저장된 레퍼런스 데이터를 비교하고, 상기 제1 데이터와 상기 레퍼런스 데이터 간 차이에 기초하여 상기 이동식 객체를 식별할 수 있다.일 실시예로서, 상기 제2 데이터에 기초하여 상기 자율 주행 차량의 주행 속도를 조정할 수 있다. 상기 기술적 과제를 해결하기 위한 컴퓨팅 장치에 의해 수행되는 자율 주행 차량의 원격 제어 방법은, 적어도 하나의 센서를 통해 자율 주행 차량의 외부의 객체를 탐지하여 제1 데이터를 생성하는 단계, 상기 제1 데이터를 원격 제어 장치로 전송하는 단계, 상기 원격 제어 장치가 상기 제1 데이터에 응답하여 전송하는 제2 데이터를 수신하는 단계, 및 상기 제2 데이터에 기초하여 상기 적어도 하나의 센서의 관측 시야(field of view, FOV)를 조정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 본 발명의 실시예들에 따르면, 자율 주행 차량의 데이터를 기초로 자율 주행 차량의 센서를 원격으로 조 정함으로써, 자율 주행 차량의 최적의 FoV(Field of View)로 주변 객체 및 환경을 탐지할 수 있다. 또한, 자율 주행 차량의 데이터를 기초로 차량 주변 환경을 인식하여 안전 주행을 위한 원격 제어를 수행할 수 있다. 또한, 자율 주행 차량의 원격 제어에 적합한 센서 장치 및 데이터 처리 유닛을 구비한 자율 주행 차량 시스템이 제안될 수 있다. 본 발명의 유리한 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 유리한 효과들"}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "이 아래의 기재로부터 본 발명의 기술분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명한다. 본 발명의 이점 및 특징, 그리고 그것들 을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러 나 본 발명의 기술적 사상은 이하의 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으"}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "며, 단지 이하의 실시예들은 본 발명의 기술적 사상을 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명의 기술적 사상은 청구 항의 범주에 의해 정의될 뿐이다. 각 도면의 구성요소들에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시 되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관련 된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세 한 설명은 생략한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니 다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 이하, 본 발명의 몇몇 실시예들에 대하여 첨부된 도면에 따라 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른, 자율 주행 차량의 원격 제어 시스템을 개략적으로 나타내는 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 자율 주행 차량 은, 그 원격 제어를 위해, 원격 제어 장치와 유/무선 네트워크를 통해 연결될 수 있으며, 상호간 통신을 수행할 수 있다. 상기 네트워크는 이동하는 자율 주행 차량의 특성 상 이동 통신망(mobile radio communication network), 위성 통신망, 블루투스(Bluetooth), Wibro(Wireless Broadband Internet), HSDPA(High Speed Downlink Packet Access), LTE(Long Term Evolution) 등과 같은 무선 네트워크로 구현되는 것이 바람직하다. 다만, 필요에 따라서, 네트워크는 유선 및 무선이 혼용된 네트워크로 구성될 수 있다. 이때 혼용되는 유선 네트워크로는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network, WAN) 또는 부가가치 통신망(Value Added Network; VAN) 등이 포함될 수 있다. 자율 주행 차량은, 적어도 하나의 센서를 기반으로 주변 환경을 인식하여 위험을 판단하고, 주행 경로를 계획하여 운전자 개입 없이 자율적인 주행이 가능한 차량이다. 자율 주행 차량은 적어도 하나의 센서를 통 해 주변 환경을 탐지한 센싱 데이터를 기초로, 원격 제어를 위한 제1 데이터를 생성하고 이를 원격 제어 장치 로 전송한다. 일 실시예로서, 상기 제1 데이터는 상기 센싱 데이터 외에 자율 주행 차량의 속도, 가속도, 조향각, 또는 변속 상태 등 자율 주행 차량의 주행 데이터를 더 포함할 수 있다. 원격 제어 장치는, 네트워크를 통해 제1 데이터를 수신하고, 제1 데이터에 응답하여 자율 주행 차량 을 원격 제어하기 위한 제2 데이터를 생성한다. 생성된 제2 데이터는 네트워크를 통해 자율 주행 차 량으로 회신된다. 자율 주행 차량은 상기 제2 데이터에 기초하여 상기 적어도 하나의 센서의 관측 시 야(Field of View, FOV)를 조정하거나, 자율 주행 차량의 주행 속도를 조정할 수 있다. 일 실시예로서, 제2 데이터는 자율 주행 차량에 구비된 적어도 하나의 센서의 관측 시야를 조정하기 위한 제어 신호를 포함할 수 있다. 상기 제어 신호는 상기 적어도 하나의 센서의 높이, 시야각, 시야거리, 또는 탐지 방향의 조정을 직접 지시하는 제어 신호일 수 있다. 또는, 상기 제어 신호는 상기 적어도 하나의 센서가 포커스 할 지점 또는 객체를 가리키는 제어 신호일 수도 있다. 일 실시예로서, 상기 제2 데이터는 상기 제1 데이터로부터 식별된 이동식 객체를 상기 적어도 하나의 센서가 포 커스하도록, 상기 적어도 하나의 센서의 관측 시야를 조정하는 제어 신호를 포함할 수 있다. 예를 들어, 자율 주행 차량 주변에 이동식 객체가 존재하는 경우, 상기 이동식 객체가 자율 주행 차량의 주행 경로로 끼어들거나 간섭할 수 있어, 그로 인한 충돌 위험을 줄이기 위해 이동식 객체를 상세히 모니터링할 필요가 있다. 따라서, 원격 제어 장치는 제1 데이터로부터 이동식 객체가 식별되는 경우, 상기 적어도 하나의 센 서가 상기 이동식 객체를 포커스하도록 하는 제2 데이터를 전송함으로써, 자율 주행 차량이 상기 이동식 객체를 더욱 상세히 모니터링하도록 할 수 있다. 일 실시예로서, 제2 데이터는 상기 자율 주행 차량의 주행 속도를 조정하도록 하는 제어 신호를 포함할 수 있다. 예를 들어, 자율 주행 차량 주변에 이동식 객체가 존재하는 경우, 상기 이동식 객체가 자율 주행 차 량의 주행 경로로 끼어들거나 간섭할 수 있어, 그로 인한 충돌 위험을 줄이기 위해 자율 주행 차량의 속도를 저속으로 조정할 필요가 있다. 따라서, 원격 제어 장치는 제1 데이터로부터 이동식 객체가 식별되 는 경우, 자율 주행 차량의 속도를 저속으로 조정하도록 하는 제2 데이터를 전송함으로써, 자율 주행 차량 이 주행 속도를 낮추도록 할 수 있다. 도 2는 본 발명의 일 실시예에 따른, 자율 주행 차량의 주요 구성을 도시한 블록도이다. 도 2를 참조하면, 자율 주행 차량은 적어도 하나의 센서, 데이터 처리 유닛, 및 주행 제어 유닛을 포함할 수 있다. 적어도 하나의 센서는 자율 주행 차량에 구비된 센서 시스템으로서, 라이다(10, LiDAR), 레이더(20, Radar), 카메라(30, Camera), 및/또는 다른 카메라를 포함하는 복합 센서 시스템일 수 있다. 이때, 카메라 는 상대적으로 좁은 탐지 범위를 갖는 AVM 카메라이고, 카메라는 상대적으로 넓은 탐지 범위와 높은 해 상도를 갖는 고성능 카메라일 수 있다. 라이다, 레이더, 및 카메라에 대한 구체적인 설명은 도 3 이하에서 상세히 후술되므로 여기서는 그에 대한 설명을 생략한다. 데이터 처리 유닛은 자율 주행 차량의 주변 환경에 대해 적어도 하나의 센서가 탐지한 센싱 데 이터를 수신 및 저장하고, 상기 센싱 데이터를 기초로 제1 데이터를 생성한 후, 제1 데이터를 원격 제어 장치로 전송한다. 데이터 처리 유닛은 프로세서, 스토리지, 및/또는 라우터를 포함할 수 있다. 프로세서는 자율 주행 차량의 각 구성의 동작 및 구동을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또 한, 프로세서는 자율 주행 차량의 각 구성의 동작을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 스토리지는 데이터 처리 유닛의 구동에 필요한 데이터 저장 수단을 제공한다. 예를 들어, 스토리지 는 적어도 하나의 센서를 통해 수집되는 센싱 데이터, 주행 제어 유닛을 통해 수집되는 주행 데 이터, 상기 센싱 데이터 및/또는 상기 주행 데이터를 기초로 생성된 제1 데이터, 및/또는 원격 제어 장치로부터 수신되는 제2 데이터를 저장할 수 있다. 라우터는 자율 주행 차량과 원격 제어 장치간 데이터 통신을 수행한다. 예를 들어, 라우터는 제 1 데이터를 원격 제어 장치로 전송하고, 원격 제어 장치로부터 제1 데이터에 응답하여 제공되는 제2 데이터를 수신할 수 있다. 주행 제어 유닛은 자율 주행 차량의 주행을 제어한다. 예를 들어, 주행 제어 유닛은 가속 장치 를 통해 자율 주행 차량의 가속을 제어하고, 브레이크를 통해 자율 주행 차량의 감속 및 제동을 제어하고, 조향 장치를 통해 자율 주행 차량의 주행 방향을 제어할 수 있다. 도 3은 본 발명의 일 실시예에 따른, 자율 주행 차량의 센서 시스템 및 그것의 예시적인 배치 위치를 나타내는 도면이다. 도 3의 (a)는 자율 주행 차량 및 그것의 센서 시스템(10, 20, 30)을 위에서 내려다 본 평면도이 고, 도 3의 (b)는 자율 주행 차량 및 그것의 센서 시스템(10, 20, 30)을 옆에서 바라본 측면도이다. 도 3을 참조하면, 자율 주행 차량은 1개의 라이다, 2개의 레이더, 및 4개의 카메라(30, AVM 카메 라)를 포함한다. 다만, 도 3에 도시된 각 센서의 개수 및 배치 위치는 예시적인 것으로서, 본 발명의 범위가 이 에 한정되지는 않으며, 도 3에 도시된 것과 다르게, 센서의 개수가 증가 또는 감소되거나 각 센서의 배치 위치 가 달라질 수 있다. 라이다는 레이저 펄스를 발사하고, 레이저 펄스가 주변의 대상 객체에서 반사되어 돌아오는 것을 수신하여, 대상 객체까지의 거리, 대상 객체의 속도 및 방향, 또는 온도 등을 측정함으로써, 주변의 모습을 정밀하게 탐지 하는 센서이다. 라이다는 360도의 시야각을 갖는 3D 라이다일 수 있다. 일 실시예로서, 라이다는 자율 주행 차량의 중앙부에 설치되되, 자율 주행 차량의 상부 프레임 위로 돌출되게 설치될 수 있다. 이때, 상부 프레임으로부터 라이다까지의 높이(h)는 주행 환경에 따 라 가변되는 조정 가능한 높이일 수 있다. 일 실시예로서, 라이다는 지면으로부터 130cm 내지 160cm 높이에 위치하도록 상부 프레임과의 높이(h)가 설정될 수 있다. 이는 사람의 키에 맞추어 라이다의 높이를 설정한 것으로서, 보행자를 더욱 잘 감지하여 보행자와의 충돌을 잘 회피할 수 있도록 하기 위함이다. 레이더는 전자기파를 발사하고, 전자기파가 주변의 대상 객체에서 반사되어 돌아오는 것을 수신하여, 객체 를 식별하거나 객체의 위치 및 속도 등을 탐지하는 센서이다. 레이더는 일정 범위의 시야각 및 방향성 있는 탐지 범위를 갖는 센서일 수 있다. 일 실시예로서, 레이더는 자율 주행 차량의 전방 및 후방에 각각 설치되되, 자율 주행 차량의 하 부 프레임의 전방 중앙 부분 및 하부 프레임의 후방 중앙 부분에 각각 설치될 수 있다. 카메라는 렌즈를 이용하여 주변 환경을 광학적으로 촬영하는 센서이다. 카메라는 상대적으로 좁은 탐지 범위를 갖지만 가격이 저렴하여 같은 비용으로 더 많은 수의 카메라를 구비할 수 있는 AVM 카메라일 수 있다. 일 실시예로서, 카메라는 자율 주행 차량의 전방, 후방, 및 측방에 각각 설치되되, 자율 주행 차량 의 상부 프레임의 전방 중앙 부분, 상부 프레임의 후방 중앙 부분, 및 상부 프레임의 양 측방 중 앙 부분에 각각 설치될 수 있다. 이처럼, 카메라를 자율 주행 차량의 전방, 후방, 양 측방에 각각 배 치하는 것은, 카메라의 사각을 최소화함으로써 자율 주행 차량 주변으로 이동식 객체가 갑자기 돌출하 는 것을 신속하게 잘 탐지하도록 하기 위함이다. 도 4는 자율 주행 차량의 센서 중 라이다의 관측 시야 및 그것의 조정 방법을 부연설명하기 위한 도면이다. 도 4의 (a)는 라이다의 관측 시야를 나타내는 도면이고, 도 4의 (b)는 라이다의 관측 시야를 조정하는 방 법을 나타내는 도면이다. 라이다는 360도 시야각을 갖는 센서로서, 도 4의 (a)와 같이 라이다를 중심으로 반경이 d인 원형의 관 측 시야(10a)를 갖는다. 라이다는 보행자를 특히 잘 탐지하기 위해, 사람의 키에 맞추어 그 높이가 설정될 수 있다. 예를 들어, 라 이다는 지면으로부터 130cm 내지 160cm 높이에 위치하도록 상부 프레임과의 높이가 설정될 수 있다. 그러나, 자율 주행 차량의 주변 환경에 따라, 라이다의 높이가 조정되는 것이 바람직한 경우 있다. 가령, 자율 주행 차량이 주행하는 도로에 비해 인도의 높이가 더 높은 경우, 보행자를 잘 탐지하기 위해, 도로와 인도 의 높이 차를 고려하여 라이다의 높이가 조정될 수 있다. 예를 들어, 보행자의 키에 맞추어, 라이다의 높이가 지면으로부터 150cm 높이에 위치하도록 상부 프레임 과의 높이가 h1으로 설정되었다고 가정하자. 이때, 자율 주행 차량 주변의 인도 높이가 도로보다 50cm가 더 높으면, 인도 위에 있는 보행자를 더욱 잘 탐지하기 위해, 라이다의 높이가 50cm만큼 더 높아지도록, 라이 다와 상부 프레임 간 높이를 h2로 조정할 수 있다. 이때, 라이다의 높이 조정은 원격 제어 장치로부터 수신된 제2 데이터를 기초로 수행될 수 있다. 가령, 원 격 제어 장치가 자율 주행 차량의 제1 데이터를 분석한 결과, 자율 주행 차량이 위치한 지역의 인도의 높이가 도로의 높이보다 50cm 더 높다고 식별되면, 원격 제어 장치는 라이다와 상부 프레임 간 높이를 더 높게 조정하기 위한 제어 신호가 포함된 제2 데이터를 자율 주행 차량으로 전송하고, 자율 주행 차량은 제2 데이터에 포함된 제어 신호를 기초로 라이다와 상부 프레임 간 높이를 h2로 조정할 수 있다. 도 5는 자율 주행 차량의 센서 중 레이더의 관측 시야 및 그것의 조정 방법을 부연설명하기 위한 도면이다. 도 5를 참조하면, 레이더는 자율 주행 차량의 전방 및 후방에 각각 설치될 수 있다. 레이더는 일정 범위의 시야각 및 방향성 있는 탐지 범위를 갖는 센서로서, 시야각 및 시야 거리가 상이한 복수의 탐지 범위(20a, 20b, 20c) 중 어느 하나의 탐지 범위로 동작하도록 제어될 수 있다. 상기 복수의 탐지 범위(20a, 20b, 20c)는 넓은 제1 시야각과 짧은 제1 시야 거리를 갖는 제1 탐지 범위(20a), 제1 시야각보다 더 좁은 제2 시야각과 제1 시야 거리보다 긴 제2 시야 거리를 는 제2 탐지 범위(20b), 제2 시야 각보다 더 좁은 제3 시야각과 제2 시야 거리보다 긴 제3 시야 거리를 는 제3 탐지 범위(20c)를 포함하고, 레이 더는 관심 영역 및/또는 관심 객체에 따라 복수의 탐지 범위(20a, 20b, 20c) 중 어느 하나의 탐지 범위로 동작하도록 제어될 수 있다. 예를 들어, 근거리의 넓은 영역을 탐지하고자 하는 경우 레이더는 제1 탐지 범 위(20a)로 동작되고, 중간거리의 보통 넓이의 영역을 탐지하고자 하는 경우 레이더는 제2 탐지 범위(20b)로 동작되고, 원거리의 좁은 영역을 탐지하고자 하는 경우 레이더는 제3 탐지 범위(20c)로 동작될 수 있다. 이때, 레이더의 탐지 범위 조정은 원격 제어 장치로부터 수신된 제2 데이터를 기초로 수행될 수 있다. 가령, 원격 제어 장치가 자율 주행 차량의 제1 데이터를 분석한 결과, 관심 객체가 근거리의 측면 방향에서 식 별되면, 원격 제어 장치는 레이더가 관심 객체를 포커스 하도록, 레이더를 제1 탐지 범위(20a)로 동작 시키는 제어 신호가 포함된 제2 데이터를 자율 주행 차량으로 전송하고, 자율 주행 차량은 제2 데이터에 포함된 제어 신호를 기초로 레이더의 탐지 범위를 제1 탐지 범위(20a)로 조정할 수 있다. 또는, 원격 제어 장치가 자율 주행 차량의 제1 데이터를 분석한 결과, 관심 객체가 원거리의 정면 방향에서 식별되면, 원격 제어 장치는 레이더가 관심 객체를 포커스 하도록, 레이더를 제3 탐지 범위(20c)로 동작시키는 제어 신호가 포함된 제2 데이터를 자율 주행 차량으로 전송하고, 자율 주행 차량은 제2 데이터에 포함된 제어 신호를 기초로 레이더의 탐지 범위를 제3 탐지 범위(20c)로 조정할 수 있다. 일 실시예로서, 상기 관심 객체는 자율 주행 차량이 전송하는 제1 데이터로부터 식별된 이동식 객체일 수 있다. 상기, 이동식 객체는 사람, 차량, 동물, 또는 전동 킥보드와 같이 이동 가능한 객체일 수 있다. 한편, 도 5에서 각 탐지 범위(20a, 20b, 20c)는 탐지 방향이 전방 또는 후방을 향하는 것으로 도시되어 있으나, 본 발명의 범위는 이에 한정되지 않는다. 예를 들어, 레이더는 관심 영역 및/또는 관심 객체에 따라, 또는 제2 데이터의 제어 신호에 따라 각 탐지 범위(20a, 20b, 20c)의 방향을 자율 주행 차량을 기준으로 우측 또는 좌측으로 조정할 수 있다. 도 6은 자율 주행 차량의 센서 중 카메라의 관측 시야 및 그것의 조정 방법을 부연설명하기 위한 도면이다. 도 6에서, 카메라는 자율 주행 차량의 전방, 후방, 및 양 측방에 각각 설치된 것으로 도시된다. 이처럼, 카 메라를 자율 주행 차량의 전방, 후방, 양 측방에 각각 배치함으로써, 카메라의 사각을 최소화하고 자율 주행 차량 주변으로 이동식 객체가 갑자기 돌출하는 것을 신속하게 잘 탐지할 수 있다. 한편, 카메라을 자율 주행 차량의 전방, 후방, 양 측방에 각각 배치하는 경우, 카메라의 전체 탐지 범 위(30a)는 도 6에 도시된 바와 같이 타원형의 형상이 된다. 따라서, 상대적으로 자율 주행 차량을 기준으로 대 각 방향의 객체에 대해서는 탐지 거리가 더 짧아지게 된다. 이 경우, 카메라는 관심 영역 및/또는 관심 객체에 따라 타원형 탐지 범위(30a)의 장축(30b)이 대각 방향을 향하도록 그 탐지 범위가 조정될 수 있다. 예를 들어, 관심 영역 및/또는 관심 객체가 자율 주행 차량의 우측 대각 방향에 위치한 경우, 카메라는 관 심 영역 및/또는 관심 객체를 포커스 하도록 각 카메라의 시야를 틸팅하여 장축(30b)이 상기 우측 대각 방 향을 향하도록 탐지 범위(30a)를 조정할 수 있다. 이때, 카메라의 탐지 범위 조정은 원격 제어 장치로부터 수신된 제2 데이터를 기초로 수행될 수 있다. 가령, 원격 제어 장치가 자율 주행 차량의 제1 데이터를 분석한 결과, 관심 객체가 자율 주행 차량의 우측 대각 방향에서 식별되면, 원격 제어 장치는 장축(30b)이 자율 주행 차량의 우측 대각 방향을 향하도록 하는 제어 신 호가 포함된 제2 데이터를 자율 주행 차량으로 전송하고, 자율 주행 차량은 제2 데이터에 포함된 제어 신호를 기초로 각 카메라의 시야를 틸팅하여 장축(30b)이 자율 주행 차량의 우측 대각 방향을 향하도록 탐지 범위 (30a)를 조정할 수 있다. 일 실시예로서, 상기 관심 객체는 자율 주행 차량이 전송하는 제1 데이터로부터 식별된 이동식 객체일 수 있다. 상기, 이동식 객체는 사람, 차량, 동물, 또는 전동 킥보드와 같이 이동 가능한 객체일 수 있다. 도 7은 라이다, 레이더, 및 카메라가 포함된 자율 주행 차량의 전체 관측 시야를 나타내는 도면이다. 도 7을 참 조하면, 라이다의 탐지 범위(10a), 레이더의 탐지 범위(20a, 20b, 20c), 및 카메라의 탐지 범위(30a)가 중첩된 형태의 관측 시야가 도시된다. 앞서 설명한 바와 같이, 관측 시야의 조정은 원격 제어 장치가 전송하는 제2 데이터에 기초하여 수행될 수 있고, 상기 관측 시야의 조정은 관심 객체 및/또는 관심 영역을 포커스 하도록 라이다, 레이더, 및 카메라 중 적어도 하나의 높이, 시야각, 시야거리, 또는 탐지 방향을 조정하는 것을 포함할 수 있다. 도 8은 원격 제어 장치가 제1 데이터와 레퍼런스 데이터를 비교하여, 제1 데이터로부터 이동식 객체를 식별하는 방법을 부연설명하기 위한 도면이다. 원격 제어 장치는 제1 데이터를 기초로 제2 데이터를 생성하되, 제2 데이터는 제1 데이터로부터 식별된 관심 객 체 및/또는 관심 영역을 더 잘 탐지할 수 있도록 자율 주행 차량의 관측 시야를 조정하기 위한 제어 신호를 포 함한다. 본 실시예는 원격 제어 장치가 제1 데이터로부터 관심 객체 및/또는 관심 영역을 식별하는 예시적인 방 법을 설명한다. 여기서, 관심 객체는 제1 데이터로부터 식별되는 이동식 객체이고, 관심 영역은 상기 이동식 객 체가 위치한 영역일 수 있다. 부연설명을 위해 도 8을 참조하면, 원격 제어 장치는 자율 주행 차량으로부터 수신된 제1 데이터와 레퍼런 스 데이터를 비교한다. 레퍼런스 데이터는 제1 데이터가 나타내는 지리적 영역(이하, 제1 영역)을 미리 촬영한 데이터로서, 별도의 센싱 장비를 통해 제1 영역을 사전 촬영한 데이터이거나, 앞서 제1 영역을 먼 저 지나간 다른 자율 주행 차량에 의해 제1 영역을 촬영한 데이터일 수 있다. 상기 비교를 통해, 원격 제어 장치는 제1 데이터와 레퍼런스 데이터의 차이를 식별한다. 도 8을 예로 들면, 제1 데이터와 레퍼런스 데이터에는 공통적으로 제1 객체(51, 61) 및 제2 객체(52, 62)가 나타난 다. 그러나, 제3 객체는 제1 데이터에만 나타나고 레퍼런스 데이터에는 나타나지 않는다. 이 경우, 제3 객체는 레퍼런스 데이터가 촬영된 이후 제1 영역에 새롭게 나타난 객체로서, 이동 가능한 이동식 객체인 것으로 추정될 수 있다. 이러한 방법으로, 원격 제어 장치는 제1 데이터와 레퍼런스 데이터 간 차이에 기초하여 제1 데이터 내 관심 객체, 여기서는 이동식 객체를 식별할 수 있고, 상기 관심 객체를 자율 주 행 차량의 적어도 하나의 센서가 포커스하도록 하는 제2 데이터를 생성하여, 이를 자율 주행 차량으로 전송할 수 있다. 도 9는 본 발명의 일 실시예에 따른, 자율 주행 차량의 원격 제어 방법을 나타내는 순서도이다. 도 9의 원격 제어 방법은 도 1의 자율 주행 차량에 의해 수행된다. 따라서, 이하의 단계들에서 수행주체가 생략된 경우, 그 수행주체는 상기 자율 주행 차량인 것으로 전제한다. 한편, 도 1 내지 도 8에서 설명한 내용과 실질적으로 동일한 내용에 대해서는, 설명의 간명화를 위해 도 9에서 관련 설명을 생략하기로 한다. S100 단계에서, 자율 주행 차량에 구비된 적어도 하나의 센서를 통해 자율 주행 차량의 외부 객체를 탐지하여 제1 데이터가 생성된다. 일 실시예로서, 상기 적어도 하나의 센서는 라이다, 레이더, 또는 카메라를 포함할 수 있다. 일 실시예로서, 상기 제1 데이터는 상기 적어도 하나의 센서를 통해 자율 주행 차량의 외부 객체를 탐지한 센싱 데이터일 수 있다. S200 단계에서, 제1 데이터가 원격 제어 장치로 전송된다. 제1 데이터는 자율 주행 차량의 라우터를 통해 원격 제어 장치로 전송될 수 있다. S300 단계에서, 원격 제어 장치가 제1 데이터에 응답하여 전송하는 제2 데이터가 수신된다. 제2 데이터는 자율 주행 차량의 라우터를 통해 원격 제어 장치로부터 수신될 수 있다. 일 실시예로서, 상기 제2 데이터는 원격 제어 장치가 제1 데이터를 기초로 제1 데이터 내 객체 중 이동식 객체 를 식별하고, 자율 주행 차량의 적어도 하나의 센서가 상기 식별된 이동식 객체를 포커스 하도록 하는 제어 신 호를 포함한 데이터일 수 있다. S400 단계에서, 제2 데이터에 기초하여 적어도 하나의 센서의 관측 시야가 조정된다. 일 실시예로서, 상기 관측 시야의 조정은 제2 데이터에 기초하여 자율 주행 차량의 적어도 하나의 센서의 높이, 시야각, 시야거리, 또는 탐지 방향을 조정하는 것일 수 있다. 또한, 상기 관측 시야의 조정은 앞서 원격 제어 장치가 식별한 제1 데이터 내 이동식 객체를 상기 적어도 하나의 센서가 포커스 하도록 상기 적어도 하나의 센 서의 높이, 시야각, 시야거리, 또는 탐지 방향을 조정하는 것일 수 있다. 지금까지 설명한 본 발명의 실시예들에 따르면, 자율 주행 차량의 데이터를 기초로 자율 주행 차량의 센서를 원 격으로 조정함으로써, 자율 주행 차량의 최적의 FoV(Field of View)로 주변 객체 및 환경을 탐지할 수 있다. 또 한, 자율 주행 차량의 데이터를 기초로 차량 주변 환경을 인식하여 안전 주행을 위한 원격 제어를 수행할 수 있 다. 또한, 자율 주행 차량의 원격 제어에 적합한 센서 장치 및 데이터 처리 유닛을 구비한 자율 주행 차량 시스 템이 제안될 수 있다. 이하에서는, 도 10을 참조하여 본 발명의 다양한 실시예에서 설명된 방법들이 구현되는 예시적인 컴퓨팅 장치 에 대하여 설명하도록 한다. 예를 들어, 도 10의 컴퓨팅 장치는 도 1의 자율 주행 차량 또는 원 격 제어 장치일 수 있다. 도 10는 컴퓨팅 장치를 나타내는 예시적인 하드웨어 구성도이다. 도 10에 도시된 바와 같이, 컴퓨팅 장치는 하나 이상의 프로세서, 버스, 통신 인터페이스, 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리와, 컴퓨터 프로그램 를 저장하는 스토리지를 포함할 수 있다. 다만, 도 10에는 본 발명의 실시예와 관련 있는 구성요소들"}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "만이 도시되어 있다. 따라서, 본 발명이 속한 기술분야의 통상의 기술자라면 도 10에 도시된 구성요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit)또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또 한, 프로세서는 본 발명의 다양한 실시예들에 따른 방법/동작을 실행하기 위한 적어도 하나의 애플리케이 션 또는 프로그램에 대한 연산을 수행할 수 있다. 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예들에 따른 방법/동작들을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드(load) 할 수 있다. 메 모리의 예시는 RAM이 될 수 있으나, 이에 한정되는 것은 아니다. 버스는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(Address Bus), 데 이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원한다. 통신 인터페이스는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 스토리지는 하나 이상의 컴퓨터 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 지휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알 려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 본 발명의 다양한 실시예들에 따른 방법/동작들이 구현된 하나 이상의 인스트럭션 (Instruction)들을 포함할 수 있다. 예를 들어, 컴퓨터 프로그램은 적어도 하나의 센서를 통해 자율 주행 차량의 외부의 객체를 탐지하여 제1 데이터를 생성하는 동작, 상기 제1 데이터를 원격 제어 장치로 전송하는 동 작, 상기 원격 제어 장치가 상기 제1 데이터에 응답하여 전송하는 제2 데이터를 수신하는 동작, 및 상기 제2 데 이터에 기초하여 상기 적어도 하나의 센서의 관측 시야(field of view, FOV)를 조정하는 동작을 수행하기 위한 인스트럭션들을 포함할 수 있다. 컴퓨터 프로그램이 메모리에 로드 되면, 프로세서는 상기 하나 이상의 인스트럭션들을 실행시킴 으로써 본 발명의 다양한 실시예들에 따른 방법/동작들을 수행할 수 있다. 지금까지 설명된 본 발명의 기술적 사상은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨터가 읽을 수 있는 코드로 구 현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매체(CD, DVD, 블루레이 디스 크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨터 구비 형 하드 디스크)일 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인터넷 등의 네트워크를 통 하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상기 다른 컴퓨팅 장치에 서 사용될 수 있다."}
{"patent_id": "10-2022-0116027", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 본 발명이 다른 구체적인 형태로도 실시될 수 있다는 것을 이해할 수 있다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로 이해해야만 한다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명에 의해 정의되는 기술적 사상의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2022-0116027", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른, 자율 주행 차량의 원격 제어 시스템을 개략적으로 나타내는 도면이다. 도 2는 본 발명의 일 실시예에 따른, 자율 주행 차량의 주요 구성을 도시한 블록도이다. 도 3은 본 발명의 일 실시예에 따른, 자율 주행 차량의 센서 시스템 및 그것의 예시적인 배치 위치를 나타내는 도면이다. 도 4는 자율 주행 차량의 센서 중 라이다의 관측 시야 및 그것의 조정 방법을 부연설명하기 위한 도면이다. 도 5는 자율 주행 차량의 센서 중 레이더의 관측 시야 및 그것의 조정 방법을 부연설명하기 위한 도면이다. 도 6은는 자율 주행 차량의 센서 중 카메라의 관측 시야 및 그것의 조정 방법을 부연설명하기 위한 도면이다. 도 7은 라이다, 레이더, 및 카메라가 포함된 자율 주행 차량의 전체 관측 시야를 나타내는 도면이다. 도 8은 원격 제어 장치가 제1 데이터와 레퍼런스 데이터를 비교하여, 제1 데이터로부터 이동식 객체를 식별하는 방법을 부연설명하기 위한 도면이다. 도 9는 본 발명의 일 실시예에 따른, 자율 주행 차량의 원격 제어 방법을 나타내는 순서도이다. 도 10은 본 발명의 다양한 실시예들이 구현되는 컴퓨팅 장치의 예시적인 하드웨어 구성을 나타내는 블록도이다."}
