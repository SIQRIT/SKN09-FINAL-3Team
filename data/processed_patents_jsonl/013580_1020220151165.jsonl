{"patent_id": "10-2022-0151165", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0070740", "출원번호": "10-2022-0151165", "발명의 명칭": "안전 기능이 구현된 방역 로봇", "출원인": "주식회사 제타뱅크", "발명자": "최동완"}}
{"patent_id": "10-2022-0151165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "바디;상기 바디의 자세를 감지하는 센싱부;상기 바디에 장착되어 바닥으로 단파장 자외선 광을 출력하는 UV-C 램프 장치; 및상기 바디의 자세에 대한 정보에 기초하여, 단파장 자외선 광의 조사 방향을 제어하는 제어부;를 포함하는 안전기능이 구현된 방역 로봇."}
{"patent_id": "10-2022-0151165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 제어부는,상기 바디의 기울어진 각도값이 제1 기준값 이상인 것으로 판단되는 경우, 상기 각도값에 기초하여 상기 광의조사 방향을 변경하는 안전 기능이 구현된 방역 로봇."}
{"patent_id": "10-2022-0151165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 제어부는,상기 바디의 기울어진 각도값이 제2 기준값 이상인 것으로 판단되는 경우, 상기 UV-C 램프 장치에 제공되는 전력을 차단하는 안전 기능이 구현된 방역 로봇."}
{"patent_id": "10-2022-0151165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 제어부는,전력이 차단된 상태에서, 상기 바디의 기울어진 각도값이 제2 기준값보다 작은 것으로 판단되는 경우, 상기 UV-C 램프 장치에 다시 전력을 공급하는 안전 기능이 구현된 방역 로봇."}
{"patent_id": "10-2022-0151165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 UV-C 램프는,단파장 자외선 광을 생성하여 위쪽 방향으로 출력하는 광원; 및아래쪽 방향으로 상기 단파장 자외선 광을 반사하는 반사부;를 포함하는 안전 기능이 구현된 방역 로봇."}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 바디; 상기 바디의 자세를 감지하는 센싱부; 상기 바디에 장착되어 바닥으로 단파장 자외선 광을 출력 하는 UV-C 램프 장치; 및 상기 바디의 자세에 대한 정보에 기초하여, 단파장 자외선 광의 조사 방향을 제어하는 제어부;를 포함하는 안전 기능이 구현된 방역 로봇에 관한 것이다."}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 안전 기능이 구현된 방역 로봇에 관한 것이다."}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 최근 산업 현장뿐만 아니라 가정이나 사무실, 관공서 등 일반 건물내에서 가사일이나 사무 보조로서 활 용되고 있다. 이러한 로봇은 공간 내에서 이동을 하면서 탑재된 고유의 기능을 수행한다. 청소 로봇, 안내 로 봇, 방범 로봇, 방역 로봇 등을 예로 들 수 있다. 방역 로봇의 일종으로 한국등록특허 제10-1742489호와 같이 자외선 살균램프를 구비한 이동 로봇에 대한 연구도 있으며, 특히, 이동 로봇이 이동하면서 바닥에 UV-C 광을 조사하는 기술도 개발이 이루어지고 있다. 이동 로봇이 넘어지는 경우 UV-C 광이 주변에 위치한 인체를 향하게 될 수 있다. 이경우, 인체의 눈, 피부에 자 외선이 노출되어 안전상 문제가 발생될 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록번호 10-1742489"}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여, 바닥에 UV-C 광을 조사하는 방역 로봇에 있어서 안전 기능을 구현 한 방역 로봇을 제공하는데 목적이 있다. 본 발명의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재 로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇은, 바디의 자세에 대한 정보에 기초하여, 단파장 자외선 광의 조사 방향을 제어한다. 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇은, 바디; 상기 바디의 자세를 감지하는 센싱부; 상기 바디에 장착되어 바닥으로 단파장 자외선 광을 출력하는 UV-C 램프 장치; 및 상기 바디의 자세에 대한 정보에 기초하여, 단파장 자외선 광의 조사 방향을 제어하는 제어부;를 포함한다. 상기 제어부는, 상기 바디의 기울어진 각도값이 제1 기준값 이상인 것으로 판단되는 경우, 상기 각도값에 기초 하여 상기 광의 조사 방향을 변경한다. 상기 제어부는, 상기 바디의 기울어진 각도값이 제2 기준값 이상인 것으로 판단되는 경우, 상기 UV-C 램프 장치 에 제공되는 전력을 차단한다. 상기 제어부는, 전력이 차단된 상태에서, 상기 바디의 기울어진 각도값이 제2 기준값보다 작은 것으로 판단되는 경우, 상기 UV-C 램프 장치에 다시 전력을 공급한다. 상기 UV-C 램프는, 단파장 자외선 광을 생성하여 위쪽 방향으로 출력하는 광원; 및 아래쪽 방향으로 상기 단파 장 자외선 광을 반사하는 반사부;를 포함한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 다음과 같은 효과가 하나 혹은 그 이상 있다. 첫째, 단파장 자외선 광을 이용하여 바닥을 살균 소독하면서도, 돌발 상황에 따라 로봇이 넘어지는 경우에도 안 전성이 확보되는 효과가 있다. 둘째, 이동 로봇이 주행하는 바닥의 상황에 따라 단파장 자외선 광의 조사 방향을 변경함으로써 상황에 맞게 단 파장 자외선 광이 바닥을 향하도록 유지하여, 안전성을 확보함과 동시에 소독, 살균 기능을 유지하는 효과가 있 다."}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0151165", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇의 외관을 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 방역 로봇의 하부를 도시한 도면이다. 도면을 참조하면, 안전 기능이 구현된 방역 로봇(이하, 로봇)은, 공간에서 이동하면서, 살균 또는 소독 동 작을 수행할 수 있다. 로봇은, 자율 주행할 수 있다. 로봇은, 정해진 경로로 주행할 수 있다. 로봇은, 원격 신호에 따 라 주행할 수 있다. 그에 따라 로봇은, 이동 로봇으로 명명될 수 있다. 로봇은, 단파장 자외선 광(UV-C)을 통해 살균 또는 소독 동작을 수행할 수 있다. 로봇은, UV-C 램프 장치를 포함할 수 있다. 로봇은, 바디 및 UV-C 램프 장치를 포함할 수 있다. 바디는, 이동 로봇의 외관을 형 성하는 바디, 구동부(바퀴 포함), 제어부, 센서부, 통신부, HMI, 전원부 등을 포함할 수 있다. UV-C 램프 장치는, 제어부에서 제공되는 제어 신호에 기초하여, 단파장 자외선 광(UV-C)을 로봇의 외 부로 출력하여, 살균 또는 소독 동작을 수행할 수 있다. UV-C 램프 장치는, 바디의 하부에 장착될 수 있다. UV-C 램프 장치는, 바디의 하방으로 자 외선 광을 조사함으로써, 로봇이 위치한 공간의 바닥 살균 또는 소독 동작을 수행할 수 있다. UV-C 램프 장치가 바닥을 향해 자외선 광을 조사하는 상태에서, 로봇은, 주행할 수 있다. 이를 통해, 건물 내부의 방역을 용이하게 수행할 수 있다. 로봇의 이동에 의해, 바닥에 있는 다양한 이물질이 튀어 UV-C 램프를 오염시키는 일이 발생한다. UV-C 램 프에 이물질이 묻은 상태로 자외선 광을 출력하게 되면, 출력되는 광량이 감소하게 되어 살균력이 떨어지는 문 제가 있다. 또한, 액상의 이물질이 UV-C 램프의 전기적 연결부에 튀게 되면, 고장 발생의 원인이 되기도 한다. 로봇이 장애물을 지나거나 넘어지는 경우, 바닥을 향하던 자외선 광이 의도되지 않은 방향으로 향할 수 있 다. 이경우, 주변에 위치한 사람들에게 자외선 광이 조사될 수 있고, 안전상 문제가 될 수 있다. 한편, 본 명세서에서 전방은, 로봇이 전진 주행할 때 향하는 방향으로 정의되고, 후방은, 전방의 반대 방 향으로 정의될 수 있다. 본 명세서에서 설명되는 구성 요소에서 방향을 설명할 때 로봇의 전진 주행 방향 은 전방으로 후진 주행 방향은 후방으로 설명될 수 있다. 도 3은 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇의 제어 블럭도이다. 도면을 참조하면, 로봇은, 특정 공간에서 스스로 이동하면서 동작을 수행한다. 로봇은, 자율 주행 이 동 로봇으로 명명될 수 있다. 로봇은, 자율 주행할 수 있다. 로봇은, 센싱부 및 인공지능 모듈 에서 생성된 데이터에 기초하여 주행 경로를 생성하고, 생성된 경로를 따라 자율 주행할 수 있다. 로봇은, 센싱부, 인공지능 모듈, 통신부, 입력부, 메모리, 제어부, 구동 부, UV-C 램프 장치, HMI 및 충전부를 포함할 수 있다. 센싱부, 인공지능 모듈, 통신부, 입력부, 메모리, 제어부, 구동부, UV-C 램프 장치, HMI 및 충전부는, 바디의 내부 또는 외부에 배치될 수 있다. 센싱부는, 로봇 내부 또는 외부의 상황을 감지할 수 있다. 센싱부는, 적어도 하나의 센서에서 생성된 데이터를 제어부에 제공할 수 있다. 제어부는, 센싱부로부터 수신된 데이터에 기초하여 동작을 수행할 수 있다. 센싱부는, 대상 공간에서 사람을 검출할 수 있다. 예를 들면, 센싱부는, 카메라로 촬영된 영상 분석 을 통해, 대상 공간에서 사람을 검출할 수 있다. 센싱부는, 대상 공간의 오염도를 측정할 수 있다. 예를 들면, 센싱부는, 환경 센서에서 생성된 데이 터를 통해, 대상 공간의 오염도를 측정할 수 있다. 한편, 센싱부는, 로봇이 자율 주행하는 도중에 내부 또는 외부의 상황을 감지할 수 있다. 센싱부는, 복수의 센서를 포함한다. 센싱부는, 초음파 센서, 라이다, 레이다, 적외선 센서, 카메라, 환경 센서, IMU(Inertial Measurement Unit)를 포함할 수 있다. 초음파 센서는, 초음파를 이용하여, 로봇 외부의 오브젝트를 감지할 수 있다. 초음파 센서는, 초음파 송신부, 수신부를 포함할 수 있다. 실시예에 따라, 초음파 센서는, 초음파 송신부, 수신 부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성 하는 적어도 하나의 제어부를 더 포함할 수 있다. 초음파 센서의 제어부 기능은 제어부에서 구현될 수도 있다. 초음파 센서는, 초음파를 기초로 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 초음파 센서는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇 외부의 적 절한 위치에 배치될 수 있다. 라이다는, 레이저 광을 이용하여, 로봇 외부의 오브젝트를 감지할 수 있다. 라이다는, 광 송신부 및 광 수신부를 포함할 수 있다. 실시예에 따라, 라이다는, 광 송신부 및 광 수신부와 전 기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적 어도 하나의 제어부를 더 포함할 수 있다. 라이다의 제어부 기능은 제어부에서 구현될 수도 있다.라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는, 모터에 의해 회전되며, 로봇 주변의 오브젝트를 검출할 수 있다. 비구동식으로 구현되는 경우, 라이다는, 광 스티어링에 의해, 로봇을 기준으로 소정 범위 내에 위치하는 오브젝트를 검출할 수 있다. 로봇은 복수의 비구동식 라이다를 포함할 수 있다. 라이다는, 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇 외부의 적절한 위치에 배치될 수 있다. 레이다는, 전자파 송신부, 수신부를 포함할 수 있다. 레이더는 전파 발사 원리상 펄스 레이더(Pulse Radar) 방 식 또는 연속파 레이더(Continuous Wave Radar) 방식으로 구현될 수 있다. 레이더는 연속파 레이더 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keying) 방식으 로 구현될 수 있다. 레이더는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브 젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 레이더는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇의 외부의 적절한 위치에 배치될 수 있다. 적외선 센서는, 적외선 송신부, 수신부를 포함할 수 있다. 적외선 센서는, 적외선 광을 기초로 오브젝트를 검출 하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 적외선 센서는, 로봇의 전방, 후방 또는 측방에 위치하는 오브젝트를 감지하기 위해 로봇의 외부의 적절한 위치에 배치될 수 있다. 카메라는, 로봇 외부 영상을 촬영할 수 있다. 카메라는, 영상을 이용하여 로봇 외부의 오브젝트에 대한 정보를 생성할 수 있다. 카메라는 적어도 하나의 렌즈, 적어도 하나의 이미지 센서 및 이미지 센서와 전기적으로 연결되어 수신되는 신호를 처리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 제어부를 포함할 수 있다. 카메라는, 모노 카메라, 스테레오 카메라 중 적어도 어느 하나일 수 있다. 카메라는, 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오브젝트와의 거리 정보 또는 오브젝 트와의 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 획득된 영상에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 핀홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는, 스테레오 카메라에서 획득된 스테레오 영상에서 디스패러티(disparity) 정보를 기초로 오 브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 카메라는, 로봇 외부를 촬영하기 위해 FOV(field of view) 확보가 가능한 위치에 장착될 수 있다. 로봇은, 복수의 카메라를 포함할 수 있다. 예를 들면, 로봇은, 전방 카메라, 후방 카메라, 좌측방 카 메라, 우측방 카메라를 구성된 4채널 카메라를 포함할 수 있다. 환경 센서는, 대상 공간에 대한 오염도를 센싱할 수 있다. 예를 들면, 환경 센서는, 대상 공간에서의 방역 대상 이 되는 생화학적 오염 물질의 유무, 농도 등을 센싱할 수 있다. IMU(Inertial Measurement Unit)는, 로봇의 관성을 측정할 수 있다. IMU는, 가속도계와 회전 속도계, 때 로는 자력계의 조합을 사용하여 로봇의 특정한 힘, 각도 비율 및 때로는 로봇을 둘러싼 자기장을 측 정하는 전자 장치로 설명될 수 있다. 제어부는, IMU로부터 수신되는 데이터에 기초하여 로봇의 자세 에 대한 정보를 생성할 수 있다. IMU는, 가속도 센서, 자이로 센서, 자기 센서 중 적어도 어느 하나를 포함할 수 있다. 센싱부는, 바디의 자세를 감지할 수 있다. 센싱부는, 적어도 하나의 센서 데이터에 기초하여 바 디의 자세를 감지할 수 있다. 인공지능 모듈은, 머신 러닝으로 사물, 공간, 로봇의 속성을 학습할 수 있다. 머신 러닝은 컴퓨터에 게 사람이 직접 로직(Logic)을 지시하지 않아도 데이터를 통해 컴퓨터가 학습을 하고 이를 통해 컴퓨터가 알아 서 문제를 해결하게 하는 것을 의미한다. 딥러닝(Deep Learning)은. 인공지능(artificial intelligence)을 구성하기 위한 인공신경망(Artificial Neural Networks: ANN)에 기반으로 해 컴퓨터에게 사람의 사고방식을 가르치는 방법으로 사람이 가르치지 않아도 컴퓨 터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 상기 인공신경망(ANN)은 소프트웨어 형태로 구현되거나 칩(chip) 등 하드웨어 형태로 구현될 수 있다. 인공지능 모듈은 공간의 속성, 장애물 등 사물의 속성이 학습된 소프트웨어 또는 하드웨어 형태의 인공신 경망(ANN)을 포함할 수 있다. 예를 들어, 인공지능 모듈은 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함 할 수 있다. 인공지능 모듈은 상기 심층신경망(DNN)에 포함된 노드들 사이의 가중치(weight)들에 기초하여 입력되는 영 상 데이터에 포함되는 공간, 사물의 속성을 판별할 수 있다. 인공지능 모듈은, 머신 러닝(machine learning)으로 기학습된 데이터에 기초하여 상기 선택된 특정 시점 영상에 포함되는 공간, 장애물의 속성을 인식할 수 있다. 한편, 메모리에는 공간, 사물 속성 판별을 위한 입력 데이터, 상기 심층신경망(DNN)을 학습하기 위한 데이 터가 저장될 수 있다. 메모리에는 카메라가 획득한 원본 영상과 소정 영역이 추출된 추출 영상들이 저장될 수 있다. 또한, 실시예에 따라서는, 메모리에는 상기 심층신경망(DNN) 구조를 이루는 웨이트(weight), 바이어스 (bias)들이 저장될 수 있다. 또는, 실시예에 따라서는, 상기 심층신경망 구조를 이루는 웨이트(weight), 바이어스(bias)들은 인공지능 모듈 의 임베디드 메모리(embedded memory)에 저장될 수 있다. 한편, 인공지능 모듈은 센싱부를 통해 수신한 데이터를 트레이닝(training) 데이터로 사용하여 학습 과정을 수행할 수 있다. 로봇은 통신부를 통하여 상기 소정 서버로부터 머신 러닝과 관련된 데이터를 수신할 수 있다. 이 경 우에, 로봇은, 상기 소정 서버로부터 수신된 머신 러닝과 관련된 데이터에 기초하여 인공지능 모듈을 업데이트(update)할 수 있다. 로봇의 동작으로 획득되는 데이터가 서버로 전송될 수 있다. 로봇은, 서버로 공간(space), 사물 (Object), 사용(Usage) 관련 데이터(Data)를 서버로 전송할 수 있다. 여기서, 공간(space), 사물(Object) 관련 데이터는 로봇이 인식한 공간(space)과 사물(Object)의 인식 관련 데이터이거나, 카메라가 획득한 공간 (space)과 사물(Object)에 대한 이미지 데이터일 수 있다. 또한, 사용(Usage) 관련 데이터(Data)는 소정 제품, 예를 들어, 로봇의 사용에 따라 획득되는 데이터로, 사용 이력 데이터, 센싱부에서 획득된 센싱 데이 터 등이 해당될 수 있다. 한편, 로봇의 인공지능 모듈에는 CNN(Convolutional Neural Network) 등 심층신경망 구조(DNN)가 탑 재될 수 있다. 상기 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 입력 데이터에 포함된 사 물, 공간의 속성을 인식하여, 그 결과를 출력할 수 있다. 또한, 상기 학습된 심층신경망 구조(DNN)는 인식용 입 력 데이터를 입력받고, 로봇의 사용(Usage) 관련 데이터(Data)를 분석하고 학습하여 사용 패턴, 사용 환경등을 인식할 수 있다. 한편, 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)는 통신부를 통하여 서버로 전송될 수 있다. 서버는 학습된 웨이트(weight)들의 구성을 생성할 수 있고, 서버는 심층신경망(DNN) 구조를 트레이닝 (training) 데이터를 사용하여 학습할 수 있다. 서버는 수신한 데이터에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이터를 로봇으로 전송하여 업데이트하게 할 수 있다. 이에 따라, 로봇은 점점 더 똑똑해지고, 사용할수록 진화되는 사용자 경험(UX)을 제공할 수 있다. 인공지능 모듈은, 센싱부를 통해 수신한 데이터를 트레이닝 데이터로 사용하여 오브젝트를 검출 동작 의 학습 과정을 수행할 수 있다. 여기서, 오브젝트는, 로봇 주변의 사물, 사람, 구조물 등 로봇의 이 동에 직접적 또는 간접적으로 영향을 주는 객체로 정의할 수 있다. 인공지능 모듈은, 소프트웨어로 구현되거나, 하드웨어 형태로 구현될 수 있다. 인공지능 모듈이 프로 세서(예를 들면, GPU)로 구현되는 경우, 인공지능 모듈이 구현된 프로세서로 명명될 수 있다. 한편, 실시예에 따라, 인공지능 모듈은, 제어부의 하위 개념으로 분류될 수 있다. 이경우, 인공지능 모듈의 동작은 제어부의 동작으로 설명될 수 있다. 통신부는, 로봇 외부의 전자 장치(예를 들면, 사용자 단말기, 서버, 다른 이동 로봇, 충전 스테이션 등)와 신호를 교환할 수 있다. 통신부는, 외부의 전자 장치와 데이터를 교환할 수 있다. 통신부는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 입력부는, 사용자로부터 정보를 입력받기 위한 것으로, 입력부에서 수집한 데이터는, 제어부에 의해 분석되어, 사용자의 제어 명령으로 처리될 수 있다. 입력부는, 음성 입력부, 터치 입력부를 포함할 수 있다. 실시예에 따라, 제스쳐 입력부 또는 기계식 입력 부를 포함할 수 있다. 음성 입력부는, 사용자의 음성 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는, 제어부에 제 공될 수 있다. 음성 입력부는, 하나 이상의 마이크로 폰을 포함할 수 있다. 터치 입력부는, 사용자의 터치 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는 제어부에 제 공될 수 있다. 터치 입력부는, 사용자의 터치 입력을 감지하기 위한 터치 센서를 포함할 수 있다. 실시예에 따라, 터치 입력부는 디스플레이와 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이 러한, 터치 스크린은, 로봇과 사용자 사이의 입력 인터페이스 및 출력 인터페이스를 함께 제공할 수 있다. 제스쳐 입력부는, 사용자의 제스쳐 입력을 전기적 신호로 전환할 수 있다. 전환된 전기적 신호는 제어부에 제공될 수 있다. 제스쳐 입력부는, 사용자의 제스쳐 입력을 감지하기 위한 적외선 센서 및 이미지 센서 중 적어도 어느 하나를 포함할 수 있다. 기계식 입력부는, 버튼, 돔 스위치(dome switch), 조그 휠 및 조그 스위치 중 적어도 어느 하나를 포함할 수 있 다. 기계식 입력부에 의해 생성된 전기적 신호는, 제어부에 제공될 수 있다. 메모리는, 제어부와 전기적으로 연결된다. 메모리는 유닛에 대한 기본데이터, 유닛의 동작제어 를 위한 제어데이터, 입출력되는 데이터를 저장할 수 있다. 메모리는, 제어부에서 처리된 데이터를 저장할 수 있다. 메모리는, 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 중 적어도 어느 하나로 구성될 수 있다. 메모리는 제어부의 처리 또는 제어를 위한 프로그램 등, 로봇 전 반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 제어부와 일체형으로 구현될 수 있다. 실시예에 따라, 메모리는, 제어부의 하위 구성으로 분류될 수 있다. 구동부는, 로봇의 이동 동력을 제공할 수 있다. 구동부는, 동력 생성부 및 동력 전달부를 포함 할 수 있다.동력 생성부는, 전기 에너지를 힘 에너지로 전환할 수 있다. 이를 위해 동력 생성부는, 적어도 하나의 모터로 구성될 수 있다. 동력 전달부는, 동력 생성부에서 생성된 동력을 구동 바퀴에 전달할 수 있다. 동력 전달부는, 적어도 하나의 기 어 또는 적어도 하나의 벨트를 포함할 수 있다. UV-C 램프 장치는, 대상 공간에 대한 방역 동작을 수행할 수 있다. UV-C 램프 장치는, 광출력부를 포함할 수 있다. 광출력부는, 단파장 자외선 광을 외부로 출력할 수 있다. 광출력부는 UV-C LED를 포함할 수 있다. 광출력부는, 제어부에서 제공되는 신호에 따라 전자식으로 제어될 수 있다. 제어부는, 광출력부에 제어 신호를 제 공하여 광 출력 여부, 광출력 양 등을 제어할 수 있다. 광출력부는, 복수의 UV-C LED 모듈을 포함할 수 있다. 로봇은 4개의 캐스터휠을 포함할 수 있다. 복수의 UV-C LED 모듈는, 4개의 캐스터휠 사이사이에 배치될 수 있다. UV-C 램프 장치는, 바디에 장착될 수 있다. UV-C 램프 장치는, 바닥으로 단파장 자외선 광을 출력할 수 있다. HMI(Human Machine Interface)는, 대상 공간에 위치한 사람과 인터렉션을 수행할 수 있다. 이를 위해 HMI는, 출력 장치로 디스플레이 및 스피커를 포함할 수 있다. 상술한 입력부는 HMI의 하위 개념으로 분류될 수 있다. 디스플레이는, 다양한 정보에 대응되는 그래픽 객체를 표시할 수 있다. 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 디스플레이는 터치 입력부와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현 할 수 있다. 디스플레이는 복수로 구성될 수 있다. 예를 들면, 디스플레이는, 터치 스크린으로 구성되어 터치 입 력을 수신할 수 있는 제1 디스플레이 및 정보 출력을 위한 제2 디스플레이로 구성될 수 있다. 스피커는, 제어부로부터 제공되는 전기 신호를 오디오 신호로 변환하여 출력한다. 이를 위해, 스피커 는, 하나 이상의 스피커를 포함할 수 있다. 충전부는, 충전 스테이션으로부터 전기 에너지를 공급받을 수 있다. 충전부는. 공급받은 전기 에너지 를 배터리에 저장할 수 있다. 제어부는, 로봇의 각 유닛의 전반적인 동작을 제어할 수 있다. 제어부는 ECU(Electronic Control Unit)로 명명될 수 있다. 제어부는, 로봇의 각 유닛과 전기적으로 연결된다. 제어부는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 제어부는, 인공 지능 모듈에서 생성한 스케줄에 기초하여, 구동부, UV-C 램프 장치, HMI 및 충전부 중 적어도 어느 하나를 제어할 수 있다. 제어부는, 센싱부로부터 센싱 데이터를 수신할 수 있다. 제어부는, 센싱 데이터에 기초하여 바디의 자세에 대한 정보를 생성할 수 있다. 예를 들면, 제어부 는, 카메라를 통해 획득된 영상에서 적어도 하나의 오브젝트의 움직임의 변화에 기초하여, 바디의 자 세에 대한 정보를 생성할 수 있다. 예를 들면, 제어부는, 라이다를 통해 획득된 신호에서 적어도 하나의 오브젝트의 움직임의 변화에 기초하여, 바디의 자세에 대한 정보를 생성할 수 있다. 예를 들면, 제어부는, IMU 데이터에 기초하여 바디의 자세에 대한 정보를 생성할 수 있다. 제어부는, 바디의 자세에 대한 정보에 기초하여, 단파장 자외선 광의 조사 방향을 제어할 수 있다. 제어부의 동작은 도 3을 더 참조하여 설명한다. 도 4는 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇의 플로우 차트이다. 도면을 참조하면, 제어부는, 바디의 자세 정보를 획득할 수 있다(S410). 제어부는, 센싱부(11 0)에서 수신된 데이터에 기초하여, 바디의 자세 정보를 획득할 수 있다. 제어부는, 바디의 기울어진 각도값이 제1 기준값 이상인 것으로 판단되는 경우(S420), 각도값에 기초 하여 광의 조사 방향을 변경할 수 있다(S430). 제어부는, 바디의 기울어진 각도값이 제2 기준값 이상인 것으로 판단되는 경우(S440), UV-C 램프 장 치에 제공되는 전력을 차단할 수 있다(S450). 제어부는, 전력이 차단된 상태에서, 바디의 기울어진 각도값이 제2 기준값보다 작은 것으로 판단되는 경우, UV-C 램프 장치에 다시 전력을 공급할 수 있다. 도 5 내지 도 10은 본 발명의 실시예에 따라 안전 기능을 구현하기 위한 요소들을 설명하는데 참조되는 도면이 다. 도면을 참조하면, UV-C 램프 장치는, 베이스, 복수의 광원, 가이드부 및 반사부를 포 함할 수 있다. 베이스는, 바디의 하부 플레이트로 구현될 수 있다. 베이스는, 적어도 하나의 개구부(OP)가 형 성될 수 있다. 개구부(OP)는, 광원에서 생성된 광을 외부로 통과시킬 수 있다. UV-C 램프 장치는, 개 구부(OP)를 통해, 바닥을 향해 광을 조사할 수 있다. 한편, 베이스는, 플레이트 형상일 수 있다. 광원은, 베이스위에 배치될 수 있다. 광원은, 단파장 자외선 광을 출력하는 발광 소자를 포함할 수 있다. 예를 들면, 광원은, UV-C LED를 포함할 수 있다. 광원, 전기 에너지를 광 에너지로 전환할 수 있다. 광원은, 단파장 자외선 광을 생성하여 위쪽 방향 으로 출력할 수 있다. 광원은, 단파장 자외선 광을 수직 방향으로 출력할 수 있다. 광원이 베이스 위에 배치된 상태에 서, 단파장 자외선 광을 수직 방향으로 출력할 수 있다. 광원은, 제어부에서 생성된 제어 신호에 기초하여, 광을 생성할 수 있다. 가이드부, 광원에서 생성된 광을 반사부까지 가이드할 수 있다. 가이드부는, 광원에 서 생성되는 광의 조사 범위를 좁힐 수 있다. 반사부, 광원에서 출력된 광을 반사할 수 있다. 반사부는, 아래쪽 방향으로 단파장 자외선 광을 반사할 수 있다. 반사부는, 베이스와 마주보게 배치될 수 있다. 반사부는, 광원에서 생성된 광을 개구부 (OP)를 통해 바닥을 향해 반사할 수 있다. 반사부는, UV-C 램프 장치 내부에 회전 가능하게 배치될 수 있다. 반사부는, 제어부에서 수신되는 제어 신호에 따라 좌우 방향으로 형성된 축를 기준으로 회전할 수 있다. 이를 위해, UV-C 램프 장치는, 회전 구동부 및 구동력 전달부를 포함할 수 있다. 제어부는, 회전 구동부를 제어할 수 있고, 회전 구동부는, 제어부의 제어에 따라 구동력을 생성할 수 있다. 생성된 구동력은, 구동력 전달부를 통해 반사부에 전달되고, 반사부는, 회전할 수 있다. 한편, 반사부는, 플레이트 형상일 수 있다. 도 5를 참조하면, 제어부는, 반사부의 회전을 제어함으로써, 광 조사 영역을 변경할 수 있다. 제어부 는, 베이스과 반사부가 형성하는 각의 크기가 커지게 반사부의 회전을 제어함으로써, 로봇으로부터 더 먼 영역까지 광이 조사되도록 광 조사 영역을 변경할 수 있다. 이와 같이, 광 조사 영역을 변경함으로써, 로봇이 구조물 근처에 접근한 상태에서, 구조물과의 충돌을 예 방하면서, 빠지는 부분 없이 방역 동작을 수행할 수 있다. 도 6을 참조하면, 로봇은, 가변 서스펜션을 포함할 수 있다. 가변 서스펜션은, 제어부의 제어에 따라, 로봇을 승강시키거나 하강시킬 수 있다. 제어부는, 로봇이 승강하도록 가변 서스펜션을 제어할 수 있다. 로봇이 승강함에 따라, 베이스 와 바닥(FL)과의 거리는 더 멀어질 수 있다. 제어부는, 가변 서스펜션의 제어을 통해 로봇을 승 강시킴으로써, 광 조사 영역을 변경할 수 있다. 제어부는, 로봇으로부터 더 먼 영역까지 광이 조사되 도록 광 조사 영역을 변경할 수 있다. 이와 같이, 광 조사 영역을 변경함으로써, 로봇이 구조물 근처에 접근한 상태에서, 구조물과의 충돌을 예 방하면서, 빠지는 부분 없이 방역 동작을 수행할 수 있다. 도 7을 참조하면, 로봇이 장애물을 밟거나 외력에 의해 기울어지는 경우, 제어부는, 바디의 기 울어진 각도값을 획득할 수 있다. 제어부는, 센싱부에서 생성된 데이터에 기초하여, 각도값을 획득할 수 있다. 한편, 각도값은, 베이스와 지면(FL)이 이루는 각도로 이해될 수 있다. 제어부는, 각도값이 제1 기준값 이상인 것으로 판단되는 경우, 반사부를 회전시킴으로써, 광의 조사 방향을 변경할 수 있다. 제어부는, 각도값에 기초하여 반사부를 회전시킬 수 있다. 제어부는, 각도값에 반비례하도록 반 사부를 바디가 기울어지는 방향과 반대 방향으로 회전시킬 수 있다. 바디가 기울어진 상태에서 베이스와 반사부가 형성하는 제1 각도값은 바디가 기울어지지 않은 상태에서 베이스와 반사부가 형성하는 제2 각도값보다 더 작을 수 있다. 도 8을 참조하면, 로봇이 장애물을 밟거나 외력에 의해 넘어지는 경우, 제어부는, 바디의 기울 어진 각도값을 획득할 수 있다. 제어부는, 센싱부에서 생성된 데이터에 기초하여, 각도값을 획득할 수 있다. 한편, 각도값은, 베이스와 지면(FL)이 이루는 각도로 이해될 수 있다. 제어부는, 각도값이 제2 기준값 이상인 것으로 판단되는 경우, UV-C 램프 장치에 공급되는 전력을 차 단할 수 있다. 이경우, 제어부는, 구동부에 공급되는 전력도 함께 차단할 수 있다. 전력이 차단된 상태에서, 로봇이 다시 세워짐으로 인해, 각도값이 제2 기준값보다 작은 것으로 판단되는 경우, 제어부는, UV-C 램프 장치에 다시 전력을 공급할 수 있다. 이경우, 제어부는, 구동부 에도 전력을 다시 공급할 수 있다. 도 9를 참조하면, 가이드부는, 베이스와 수직하게 배치될 수 있다. 가이드부는 내측이 반사 재 질로 형성된 복수의 플레이트 형상으로 구성될 수 있다. 복수의 플레이트는 베이스에 수직하게 배치될 수 있다. 복수의 플레이트 중 어느 하나(530a)는 내측이 베이스와 둔각을 가지게 배치될 수 있다. 이경우, 광이 확 산되어, 바닥에 조사되는 광의 영역이 확장될 수 있다. 도 10을 참조하면, 베이스에는 복수의 광원(520a, 520b)이 배치될 수 있다. 로봇이 기울어지거나 넘 어갈때 제어부는, 복수의 광원(520a, 520b)에 공급되는 전력을 순차적으로 차단할 수 있다. 제어부는, 지면과의 거리에 따라 복수의 광원(520a, 520b)에 공급되는 전력을 순차적으로 차단할 수 있다. 로봇이 기울어짐에 따라, 제1 광원(520a)이 제2 광원(520b)에 비해 지면으로부터 더 멀어지는 경우, 제어 부는, 제1 광원(520a)에 공급되는 전력을 제2 광원(520b)에 비해 더 먼저 차단할 수 있다. 한편, 실시예에 따라, 제어부는, 카메라를 통해 획득된 영상에 반려 동물이 접근하여, 로봇으로부터 기 설정 거리 이내에 위치하는 것으로 판단되는 경우, UV-C 램프 장치에 공급되는 전력을 차단할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(SiliconDisk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 프로세서 또는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석 되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2022-0151165", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇의 외관을 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 방역 로봇의 하부를 도시한 도면이다. 도 3은 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇의 제어 블럭도이다. 도 4는 본 발명의 실시예에 따른 안전 기능이 구현된 방역 로봇의 플로우 차트이다. 도 5 내지 도 10은 본 발명의 실시예에 따라 안전 기능을 구현하기 위한 요소들을 설명하는데 참조되는 도면이 다."}
