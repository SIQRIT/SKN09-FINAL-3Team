{"patent_id": "10-2023-0091242", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0147391", "출원번호": "10-2023-0091242", "발명의 명칭": "인공지능 모델에 대한 연산 및 메모리 최적화 장치 및 방법", "출원인": "주식회사 딥이티", "발명자": "조용범"}}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 모델에 대한 연산 및 메모리 최적화 방법에 있어서,(a) 인공지능 모델의 훈련 및/또는 추론을 위한 연산에 대하여 SIMD(Single Instruction Multiple Data) 기반최적화를 수행하는 단계;(b) 상기 인공지능 모델과 연계된 가중치와 관련한 메모리 관리 방식 및 데이터 구조를 최적화 하는 단계; 및(c) 상기 인공지능 모델을 이루는 복수의 레이어에 병렬화를 적용하는 단계,를 포함하는, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 모델은 트랜스포머(Transformer) 기반의 딥러닝 모델을 포함하는 것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 (a) 단계는,상기 연산 중 행렬 곱셈 연산을 복수의 단위 행렬 곱셈 연산으로 분할하고, 상기 복수의 단위 행렬 곱셈 연산이동시에 수행되도록 스케줄링 하는 단계,를 포함하는 것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 (a) 단계는,상기 트랜스포머 기반의 딥러닝 모델의 어텐션(Attention) 메커니즘과 관련하여 병렬 수행 가능한 복수의 단위연산을 탐색하는 단계,를 포함하는 것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 (a) 단계는,ARM 아키텍쳐 기반의 Neon 명령어를 이용하여 상기 인공지능 모델에 대하여 상기 SIMD 기반 최적화를 적용하는것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 (b) 단계는,상기 가중치와 연계된 가중치 행렬을 복수의 블록으로 분할하고, 상기 복수의 블록 각각에 대하여 연속된 메모리 주소를 할당하는 단계,공개특허 10-2024-0147391-3-를 포함하는 것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 (b) 단계는,상기 가중치 및 활성화 값의 정밀도를 감소시키는 단계,를 포함하는 것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 (c) 단계는,(c1) 상기 복수의 레이어 간의 의존성 분석 정보를 도출하는 단계;(c2) 상기 의존성 분석 정보를 고려하여 상기 복수의 레이어 각각에 대하여 수행되는 연산을 상호 독립적인 작업 태스크로 분할하고, 상기 작업 태스크를 기 구축된 작업 큐에 추가하는 단계; 및(c3) 상기 작업 큐로부터 상기 인공지능 모델의 구동을 위한 컴퓨팅 장치의 코어 각각에 상기 작업 태스크를 할당하여 상기 작업 태스크가 개별 코어에서 병렬적으로 수행되도록 하는 단계,를 포함하는 것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 복수의 레이어 각각의 상기 작업 태스크에 대한 수행 결과를 조합하여 상기 인공지능 모델의 출력을 생성하는 단계,를 더 포함하는 것인, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 인공지능 모델은 임베디드 플랫폼 환경에서 동작하는 것을 특징으로 하는, 최적화 방법."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공지능 모델에 대한 연산 및 메모리 최적화 장치에 있어서,인공지능 모델의 훈련 및/또는 추론을 위한 연산에 대하여 SIMD(Single Instruction Multiple Data) 기반 최적화를 수행하는 연산 최적화부;상기 인공지능 모델과 연계된 가중치와 관련한 메모리 관리 방식 및 데이터 구조를 최적화 하는 구조 최적화부;및상기 인공지능 모델을 이루는 복수의 레이어에 병렬화를 적용하는 레이어 최적화부,를 포함하는, 최적화 장치."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인공지능 모델은 트랜스포머(Transformer) 기반의 딥러닝 모델을 포함하는 것인, 최적화 장치."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,공개특허 10-2024-0147391-4-상기 연산 최적화부는,상기 연산 중 행렬 곱셈 연산을 복수의 단위 행렬 곱셈 연산으로 분할하고, 상기 복수의 단위 행렬 곱셈 연산이동시에 수행되도록 스케줄링 하고, 상기 트랜스포머 기반의 딥러닝 모델의 어텐션(Attention) 메커니즘과 관련하여 병렬 수행 가능한 복수의 단위 연산을 탐색하는 것인, 최적화 장치."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 구조 최적화부는,상기 가중치와 연계된 가중치 행렬을 복수의 블록으로 분할하고, 상기 복수의 블록 각각에 대하여 연속된 메모리 주소를 할당하는 것인, 최적화 장치."}
{"patent_id": "10-2023-0091242", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 레이어 최적화부는,상기 복수의 레이어 간의 의존성 분석 정보를 도출하고, 상기 의존성 분석 정보를 고려하여 상기 복수의 레이어각각에 대하여 수행되는 연산을 상호 독립적인 작업 태스크로 분할하고, 상기 작업 태스크를 기 구축된 작업 큐에 추가하고, 상기 작업 큐로부터 상기 인공지능 모델의 구동을 위한 컴퓨팅 장치의 코어 각각에 상기 작업 태스크를 할당하여 상기 작업 태스크가 개별 코어에서 병렬적으로 수행되도록 하는 것인, 최적화 장치."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델에 대한 연산 및 메모리 최적화 장치 및 방법이 개시되며, 본원의 일 실시예에 따른 인공지능 모델 에 대한 연산 및 메모리 최적화 방법은, (a) 인공지능 모델의 훈련 및/또는 추론을 위한 연산에 대하여 SIMD(Single Instruction Multiple Data) 기반 최적화를 수행하는 단계, (b) 상기 인공지능 모델과 연계된 가중 치와 관련한 메모리 관리 방식 및 데이터 구조를 최적화 하는 단계 및 (c) 상기 인공지능 모델을 이루는 복수의 레이어에 병렬화를 적용하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 인공지능 모델에 대한 연산 및 메모리 최적화 장치 및 방법에 관한 것이다. 예를 들면, 본원은 연산 및 메모리 최적화 기술을 활용한 임베디드 환경에서의 트랜스포머(Transformer) 기반 딥러닝 모델 최적화 기법에 관한 것이다."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "트랜스포머(Transformer)는 단어나 문장과 같은 입력 데이터에서 중요한 정보를 추출하고 출력 데이터를 생성하 는데 주로 사용되는 딥러닝 모델로서, 입력 데이터의 단어들 간의 상호작용을 고려하는 Self-Attention Mechanism을 사용하는 특징이 있다."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "특히, 트랜스포머는 자연어 처리 분야에서 주로 활용되어 대용량의 데이터를 학습하여 번역, 요약, 질문 응답 등 다양한 자연어 처리 태스크에서 높은 성능을 보인다. 나아가, 트랜스포머 딥러닝 모델은 자연어 처리 분야뿐 만 아니라, 최근에는 이미지 처리 분야에서도 활용될 수 있는데, 트랜스포머를 이용한 이미지 처리 기술은 Vision Transformer(ViT)이라고 지칭된다. ViT는 기존의 CNN(Convolutional Neural Network) 기반의 이미지 처리 기술과는 달리, 입력 이미지를 패치 (patch) 단위로 분할하고, 이를 행렬 형태로 변환하여 입력으로 사용하므로, CNN 기반의 이미지 처리 기술과 비 교하여 입력 이미지의 크기에 상관없이 일관된 성능을 보이고, 적은 수의 파라미터로 높은 정확도를 보인다는 이점이 있다. 그러나, 임베디드 플랫폼 환경과 같이 메모리 크기가 작고, 연산 능력이 제한된 환경에서 트랜스포머 기반의 딥 러닝 모델을 구동하기 위하여, 컴퓨팅 장치의 하드웨어 리소스의 제약을 고려한 인공지능 모델 설계 및 하드웨 어 최적화를 제공하는 기법에 대한 연구 개발은 미비한 실정이다. 본원의 배경이 되는 기술은 한국공개특허공보 제10-2022-0094564호에 개시되어 있다."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 임베디드 플랫폼(Embedded platform)과 같은 메 모리 크기가 작고, 연산 능력이 제한된 환경에서 트랜스포머 모델의 효율적인 실행을 가능케 하는 인공지능 모 델에 대한 연산 및 메모리 최적화 장치 및 방법을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 방법은, (a) 인공지능 모델의 훈련 및/또는 추론을 위한 연산에 대하여 SIMD(Single Instruction Multiple Data) 기반 최적화를 수행하는 단계, (b) 상기 인공지능 모델과 연계된 가중치와 관련한 메모리 관리 방식 및 데이터 구조를 최적화 하는 단계 및 (c) 상기 인공지능 모델을 이루는 복수의 레이어에 병 렬화를 적용하는 단계를 포함할 수 있다. 또한, 상기 인공지능 모델은 트랜스포머(Transformer) 기반의 딥러닝 모델을 포함할 수 있다. 또한, 상기 (a) 단계는, 상기 연산 중 행렬 곱셈 연산을 복수의 단위 행렬 곱셈 연산으로 분할하고, 상기 복수 의 단위 행렬 곱셈 연산이 동시에 수행되도록 스케줄링 하는 단계를 포함할 수 있다. 또한, 상기 (a) 단계는, 상기 트랜스포머 기반의 딥러닝 모델의 어텐션(Attention) 메커니즘과 관련하여 병렬 수행 가능한 복수의 단위 연산을 탐색하는 단계를 포함할 수 있다. 또한, 상기 (a) 단계는, ARM 아키텍쳐 기반의 Neon 명령어를 이용하여 상기 인공지능 모델에 대하여 상기 SIMD 기반 최적화를 적용할 수 있다. 또한, 상기 (b) 단계는, 상기 가중치와 연계된 가중치 행렬을 복수의 블록으로 분할하고, 상기 복수의 블록 각 각에 대하여 연속된 메모리 주소를 할당하는 단계를 포함할 수 있다. 또한, 상기 (b) 단계는, 상기 가중치 및 활성화 값의 정밀도를 감소시키는 단계를 포함할 수 있다. 또한, 상기 (c) 단계는, (c1) 상기 복수의 레이어 간의 의존성 분석 정보를 도출하는 단계, (c2) 상기 의존성 분석 정보를 고려하여 상기 복수의 레이어 각각에 대하여 수행되는 연산을 상호 독립적인 작업 태스크로 분할하 고, 상기 작업 태스크를 기 구축된 작업 큐에 추가하는 단계 및 (c3) 상기 작업 큐로부터 상기 인공지능 모델의 구동을 위한 컴퓨팅 장치의 코어 각각에 상기 작업 태스크를 할당하여 상기 작업 태스크가 개별 코어에서 병렬 적으로 수행되도록 하는 단계를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 방법은, 상기 복수의 레이어 각각 의 상기 작업 태스크에 대한 수행 결과를 조합하여 상기 인공지능 모델의 출력을 생성하는 단계를 포함할 수 있 다. 또한, 상기 인공지능 모델은 임베디드 플랫폼 환경에서 동작할 수 있다. 한편, 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 장치는, 인공지능 모델의 훈련 및 /또는 추론을 위한 연산에 대하여 SIMD(Single Instruction Multiple Data) 기반 최적화를 수행하는 연산 최적 화부, 상기 인공지능 모델과 연계된 가중치와 관련한 메모리 관리 방식 및 데이터 구조를 최적화 하는 구조 최 적화부 및 상기 인공지능 모델을 이루는 복수의 레이어에 병렬화를 적용하는 레이어 최적화부를 포함할 수 있다. 또한, 상기 연산 최적화부는, 상기 연산 중 행렬 곱셈 연산을 복수의 단위 행렬 곱셈 연산으로 분할하고, 상기 복수의 단위 행렬 곱셈 연산이 동시에 수행되도록 스케줄링 하고, 상기 트랜스포머 기반의 딥러닝 모델의 어텐 션(Attention) 메커니즘과 관련하여 병렬 수행 가능한 복수의 단위 연산을 탐색할 수 있다. 또한, 상기 구조 최적화부는, 상기 가중치와 연계된 가중치 행렬을 복수의 블록으로 분할하고, 상기 복수의 블 록 각각에 대하여 연속된 메모리 주소를 할당할 수 있다. 또한, 상기 레이어 최적화부는, 상기 복수의 레이어 간의 의존성 분석 정보를 도출하고, 상기 의존성 분석 정보 를 고려하여 상기 복수의 레이어 각각에 대하여 수행되는 연산을 상호 독립적인 작업 태스크로 분할하고, 상기 작업 태스크를 기 구축된 작업 큐에 추가하고, 상기 작업 큐로부터 상기 인공지능 모델의 구동을 위한 컴퓨팅 장치의 코어 각각에 상기 작업 태스크를 할당하여 상기 작업 태스크가 개별 코어에서 병렬적으로 수행되도록 할수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 임베디드 플랫폼(Embedded platform)과 같은 메모리 크기가 작고, 연 산 능력이 제한된 환경에서 트랜스포머 모델의 효율적인 실행을 가능케 하는 인공지능 모델에 대한 연산 및 메 모리 최적화 장치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 임베디드 플랫폼에서 사용 가능한 다중 코어를 활용하여 트랜스포머 모델의 연산 속도를 향상시킬 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 모델 크기를 줄이거나, 메모리 압축 기술을 적절히 적용함으로써 인공 지능 모델의 실행을 위한 메모리 사용량을 줄일 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 인공지능 모델에 대한 연산 및 메모리 최적화 장치 및 방법에 관한 것이다. 예를 들면, 본원은 연산 및 메모리 최적화 기술을 활용한 임베디드 환경에서의 트랜스포머(Transformer) 기반 딥러닝 모델 최적화 기법에 관한 것이다. 도 1을 참조하면, 본원의 일 실시예에 따른 인공지능 기반의 연산 시스템은 본원의 일 실시예에 따른 인공 지능 모델에 대한 연산 및 메모리 최적화 장치(이하, '최적화 장치'라 한다.) 및 컴퓨팅 장치를 포함할 수 있다. 최적화 장치 및 컴퓨팅 장치 상호간은 네트워크를 통해 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 컴퓨팅 장치는 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 특히, 본 원에서의 컴퓨팅 장치는 임베디드 환경에서 구동하는 IoT 단말, 엣지 디바이스, 임베디드 보드 등을 의미 하는 것일 수 있다. 달리 말해, 본원에서의 컴퓨팅 장치는 임베디드 환경에서 구동하는 디바이스를 의미하는 것일 수 있다. 이 와 관련하여, 최근에는 임베디드 시스템 환경에서도 GPU(Graphics Processing Unit)를 탑재한 임베디드 디바이 스들이 등장함에 따라 이를 이용한 고속 병렬 연산이 가능해져, 방대한 연산량을 요구하는 심층신경망을 임베디 드 환경에서 구현하는 것에 대한 요구가 높아지고 있다. 그러나, 종래의 대부분의 인공지능 프레임워크들은 데 스크탑 환경, 서버 환경 등 리소스/성능이 충분한 컴퓨팅 환경에서 빠른 학습을 위해 가능한 많은 병렬 컴퓨팅 자원을 활용하는데 초점이 맞추어져 있어 추론(Inference)의 실시간 성능과 저전력, 낮은 메모리 소모량 등이 중요한 임베디드 환경에 대하여 그대로 적용하기 어려운 문제가 있었다. 한편, 도 1에는 최적화 장치가 컴퓨팅 장치와 독립적으로 구비되는 것으로 도시되어 있으나, 이에만 한정되는 것은 아니고, 본원의 구현예에 따라서 최적화 장치가 컴퓨팅 장치의 하위 구성(모듈)로서 탑재되어 컴퓨팅 장치에 구비되는 프로세싱 유닛(연산 유닛)을 이용한 인공지능 모델의 가속 연산을 위하 여 후술하는 최적화 기법(예를 들면, ARM Neon 최적화, 정교한 메모리 관리 및 데이터 구조 설계 등)을 적용하 는 형태로 본원에서 개시하는 인공지능 기반의 연산 시스템이 설계되는 것일 수 있다. 또한, 도 1을 참조하면, 컴퓨팅 장치는 연산 유닛 및 메모리 유닛을 구비할 수 있다. 또한, 도면 에는 도시되지 않았으나, 컴퓨팅 장치의 연산 유닛은 제1연산 유닛(미도시) 및 제2연산 유닛(미도시) 을 포함하는 다중 코어 구조로 이루어질 수 있다. 예시적으로 제1연산 유닛(미도시)은 CPU(Central Processing Unit)를 포함하고, 제2연산 유닛(미도시)은 FPGA(Field Programmable Gate Array)를 포함하는 것일 수 있으나, 이에만 한정되는 것은 아니고, 본원의 구현예에 따라 제1연산 유닛(미도시) 및 제2연산 유닛(미도시) 각각은 인 공지능 모델의 학습/추론 과정에서 필요한 연산을 처리하기 위한 특성(예를 들면, 병렬 작업에 대한 적합도 등)이 상호 구분되는 다양한 프로세서, 연산 모듈 등을 폭넓게 포함할 수 있다. 도 2는 트랜스포머(Transformer) 기반의 딥러닝 모델의 아키텍처를 나타낸 개념도이다. 도 2를 참조하면, 본원의 실시예에 관한 설명에서 인공지능 모델은 예시적으로, 트랜스포머(Transformer) 기 반의 딥러닝 모델을 포함할 수 있다. 구체적으로 도 2를 참조하면, 트랜스포머 기반의 딥러닝 모델은 소스 시퀀스를 압축하는 인코더(Encoder) 및 타겟 시퀀스를 생성하는 디코더(Decoder)로 이루어질 수 있으며, 셀프 어텐션(Self-Attention)을 적용하는 특징 이 있다. 참고로, 트랜스포머 기반의 딥러닝 방식에 대한 설명은 통상의 기술자에게 자명한 사항인바, 이와 관 련한 상세한 설명은 생략하도록 한다. 한편, 최적화 장치는 이하에서 상세히 설명하는 바와 같이, ARM Neon 최적화, 정교한 메모리 관리 및 데이 터 구조 설계, 다중 코어 병렬 연산 가속화, ARM big.LITTLE CPU 스케줄링 최적화 및 직접 메모리 제로 복사 참 조를 통한 네트워크 모델 로드 사용 등을 적용하여 트랜스포머(Transformer) 딥러닝 모델의 최적화를 수행하도 록 동작할 수 있다. 다만, 인공지능 모델은 전술한 트랜스포머 기반 모델에만 한정되는 것은 아니다. 다른 예로, 본원에서 개시 하는 인공지능 모델은 컨볼루션 뉴럴 네트워크(CNN, convolutional neural network), 순환 신경망(RNN, Recurrent Neural Network), 심층 신뢰 신경망(DBN, Deep Belief Network), GAN(Generative Adversarial Network. 생성 대립 신경망), 관계형 신경망 네트워크(RL, Relation Networks), 심층 신경망(Deep Neural Network, DNN), 딥러닝 네트워크 등 종래에 이미 공지되었거나 향후 개발되는 다양한 인공지능 기반의 모델을폭넓게 포함할 수 있다. 이하에서는 최적화 장치의 구체적인 기능 및 동작에 대하여 설명하도록 한다. 최적화 장치는 인공지능 모델의 훈련 및/또는 추론을 위한 연산에 대하여 SIMD(Single Instruction Multiple Data) 기반 최적화를 수행할 수 있다. 예를 들어, 최적화 장치는 트랜스포머 기반의 인공지능 모 델의 각 레이어에서 ARM Neon 명령어 등을 사용하여 SIMD 병렬화를 수행할 수 있으며, 이를 위해 행렬 곱셈, 어텐션 메커니즘, 레이어 정규화 등의 주요 연산에 SIMD 명령어를 적용할 수 있다. 또한, 예시적으로 최적화 장치는 인공지능 모델과 연계된 복수의 연산 중 행렬 곱셈 연산을 복수의 단 위 행렬 곱셈 연산으로 분할할 수 있다. 또한, 최적화 장치는 분할된 복수의 단위 행렬 곱셈 연산이 동시 에 수행되도록 하는 스케줄링을 결정할 수 있다. 보다 구체적으로 본원의 일 실시예에 따르면, 최적화 장치는 트랜스포머 기반의 인공지능 모델의 핵심 연산 중 하나인 행렬 곱셈이 병렬화가 적용되기에 적합한 연산 유형인 점을 고려하여, ARM Neon 명령어를 사용 하여 행렬 곱셈을 분할하고, 분할된 각각의 단위 행렬 곱셈이 동시에 병렬적으로 실행되도록 할 수 있다. 이를 위해 본원의 일 실시예에 따르면, 최적화 장치는 컴퓨팅 장치가 8-bit, 16-bit 또는 32-bit 데이터 형식의 벡터화된 행렬 곱셈 명령어를 사용하여 각각의 작은 행렬 곱셈을 동시에 처리하도록 할 수 있다. 또한, 본원의 일 실시예에 따르면, 최적화 장치는 트랜스포머 기반의 딥러닝 모델의 어텐션(Attention) 메 커니즘과 관련하여 병렬 수행 가능한 복수의 단위 연산을 탐색할 수 있다. 이와 관련하여 트랜스포머 기반의 인공지능 모델에서 수행되는 어텐션 메커니즘은 병렬 연산을 수행할 수 있 는 부분이 많은 특성을 가지며, 보다 구체적으로 각각의 Q, K, V 행렬에 대해 ARM Neon 명령어를 사용하여 독립 적으로 연산이 수행되도록 할 수 있다. 예시적으로, 스케일링 닷 프로덕트 어텐션 연산은 병렬 처리에 적합한 연산 특성을 가진다. 또 다른 예로, 멀티-헤드 어텐션에서 각 헤드의 어텐션 연산은 독립적으로 수행될 수 있으며, 최적화 장치(10 0)는 ARM Neon 명령어를 사용하여 각 헤드의 연산을 동시에 처리할 수 있다. 달리 말해, 최적화 장치는 전 술한 다양한 병렬화 기법을 적용함으로써, 트랜스포머 기반의 인공지능 모델의 전체 실행 시간을 줄이고, 이 에 따라 임베디드 플랫폼 환경에서 동작하는 컴퓨팅 장치에서 인공지능 모델이 효율적으로 실행되도록 할 수 있다. 종합하면, 본원의 일 실시예에 따르면, 최적화 장치는 ARM 아키텍쳐 기반의 Neon 명령어를 이용하여 인공 지능 모델에 대하여 SIMD 기반 최적화를 적용할 수 있다. 구체적으로 최적화 장치는 컴퓨팅 장치에 ARM 아키텍처 기반의 프로세서가 연산 유닛으로서 탑재 되는 경우, 트랜스포머 기반의 인공지능 모델의 연산 속도를 향상시키기 위해 벡터 연산을 최적화 할 수 있 으며, 보다 구체적으로 최적화 장치는 트랜스포머의 핵심 연산인 행렬 곱셈 및 주요 연산에 ARM Neon 명령 어를 사용하여 속도를 향상시키는 최적화를 적용할 수 있다. 최적화 장치는 인공지능 모델과 연계된 가중치와 관련한 메모리 관리 방식 및 데이터 구조를 최적화 할 수 있다. 이와 관련하여, 인공지능 모델 실행 시의 컴퓨팅 장치의 메모리 유닛에서의 메모리 사용 량을 줄이기 위해 트랜스포머 모델의 데이터 구조 및 연산이 최적화 되어야 하며, 이를 위하여 최적화 장치 는 인공지능 모델의 가중치 및 활성화 값을 상대적으로 효율적인 데이터 구조에 기반하여 저장되도록 하는 최적화를 적용할 수 있다. 구체적으로, 최적화 장치는 인공지능 모델의 가중치와 연계된 가중치 행렬을 복수의 블록으로 분할할 수 있다. 또한, 최적화 장치는 분할된 복수의 블록 각각에 대하여 연속된 메모리 주소를 할당할 수 있다. 이 에 따라, 컴퓨팅 장치에서의 캐시 지역성이 개선될 수 있고, 메모리 유닛과 연계된 메모리 사용량이 줄어들 수 있다. 또한, 활성화 값은 인공지능 모델의 연산 중 임시로 사용되는 데이터(값)이므로, 해당 연산이 완료된 후 메 모리를 해제함으로써 메모리 유닛의 메모리 사용량이 줄어들 수 있게 된다. 또한, 본원의 일 실시예에 따르면, 최적화 장치는 인공지능 모델의 가중치 및 활성화 값의 정밀도를 감 소시킬 수 있다. 이와 관련하여, 최적화 장치에 의해 수행되는 정밀도 하향 조정은, 인공지능 모델 실 행 시의 컴퓨팅 장치의 메모리 유닛에서의 메모리 사용량을 줄이기 위한 것일 수 있다.예시적으로 최적화 장치가 32비트 부동소수점(FP32)에서 16비트 부동소수점(FP16)으로 정밀도를 낮추는 최 적화를 적용하는 경우, 인공지능 모델과 연계된 메모리 사용량이 절반으로 줄어들게 된다. 한편, 최적화 장치는 전술한 바와 같이 정밀도를 낮추는 과정에서 발생할 수 있는 인공지능 모델의 수 치(결과) 안정성 문제를 해소(방지)하기 위해, 정밀도 감소 최적화가 적용될 경우, 인공지능 모델의 추론 과 정에서 소정의 복원 작업(프로세스)이 수행되도록 컴퓨팅 장치를 제어할 수 있다. 또한, 인공지능 모델과 연계된 데이터 구조 설계와 관련하여 최적화 장치는, 트랜스포머 모델의 데이터 구조를 조정하여 메모리 사용량을 최소화 할 수 있으며, 예를 들어, 최적화 장치는 희소 행렬을 사용하여 메모리 사용량을 줄일 수 있다. 구체적으로 최적화 장치는 인공지능 모델의 실행 시의 컴퓨팅 장치의 메모리 유닛에 대한 메 모리 접근 패턴을 최적화하여 캐시 효율성을 높일 수 있고, 이를 위하여 인공지능 모델의 연산 중 행렬 연산 의 실행 순서를 재배열하거나, 데이터 구조의 정렬을 조정할 수 있다. 또한, 인공지능 모델과 연계된 동적 메모리 관리와 관련하여 최적화 장치는, 컴퓨팅 장치의 메모 리 유닛의 메모리 사용량을 실시간 모니터링 하여 능동적으로 메모리 할당 및 해제를 수행할 수 있고, 이를 통해 메모리 사용량이 상대적으로 높은 작업(태스크)의 상태, 실행 등을 조절하고, 컴퓨팅 장치에서 발생 가능한 메모리 부족 문제를 방지(해소)할 수 있다. 또한, 최적화 장치는 메모리 유닛의 가용 메모리에 따라 정밀도 조정 프로세스가 동적으로 수행되도록 하거나, 연산 순서를 능동적으로 변경하여 메모리 사용량을 최적화 할 수 있다. 최적화 장치는 인공지능 모델을 이루는 복수의 레이어에 병렬화를 적용할 수 있으며, 이러한 최적화 절 차를 통해 트랜스포머 모델의 메모리 사용량을 줄이고, 임베디드 플랫폼에서 효율적으로 실행할 수 있게 된다. 이와 관련하여 트랜스포머 기반의 인공지능 모델의 인코더(Encoder)와 디코더(Decoder)는 복수 개의 레이어 로 이루어질 수 있으며, 각 레이어의 연산은 독립적으로 수행될 수 있으므로, 최적화 장치는 ARM Neon 명 령어 등을 사용하여 인공지능 모델의 레이어 간 병렬 연산이 이루어 지도록 할 수 있다. 구체적으로 최적화 장치는 인공지능 모델을 이루는 복수의 레이어 간의 의존성 분석 정보를 도출할 수 있다. 본원의 일 실시예에 따르면, 최적화 장치는 트랜스포머 기반 인공지능 모델에서 인코더와 디코더 의 각 레이어는 서로 독립적으로 실행될 수 있지만, 이전 레이어의 출력이 다음 레이어의 입력으로 사용되는 특 성 등을 고려하여 레이어 간 의존성을 분석함으로써 인공지능 모델을 이루는 복수의 레이어 중 병렬 실행(동 시 실행)이 가능한 레이어를 결정할 수 있다. 또한, 최적화 장치는 도출된 의존성 분석 정보를 고려하여 복수의 레이어 각각에 대하여 수행되는 연산을 상호 독립적인 작업 태스크로 분할할 수 있다. 또한, 최적화 장치는 분할된 작업 태스크를 기 구축된 작업 큐에 추가할 수 있다. 달리 말해, 최적화 장치 는 각 레이어의 연산을 독립적인 작업으로 분할하여 컴퓨팅 장치의 다중 코어 프로세스에서 각 코어 가 병렬적으로 실행되도록 각 태스크(작업)를 관리하기 위한 작업 큐에 분할된 작업을 추가할 수 있다. 또한, 최적화 장치는 작업 큐로부터 인공지능 모델의 구동을 위한 컴퓨팅 장치의 코어 각각에 작업 태스크를 할당하여, 각 작업 태스크가 개별 코어에서 병렬적으로 수행되도록 컴퓨팅 장치를 제어하거나, 컴퓨팅 장치에서 수행될 작업의 스케줄링 내용을 결정할 수 있다. 이 때, 최적화 장치는 작업 큐에서 연산 유닛의 각 코어에 할당할 작업을 선택할 수 있으며, 이 과정 에서 ARM Neon 명령어 등을 사용하여 각 레이어의 연산을 병렬로 처리할 수 있다. 또한, 최적화 장치는 병렬적으로 실행되는 인공지능 모델의 각 레이어 간에 데이터 전달을 위해 동기화 메커니즘을 사용할 수 있으며, 이러한 동기화 메커니즘은 각 레이어가 완료되면 해당 레이어의 출력 데이터를 다음 레이어로 전달한 후 동기화를 통해 다음 레이어의 실행을 개시하기 위한 메커니즘을 포함할 수 있다. 최적화 장치는 복수의 레이어 각각의 작업 태스크에 대한 수행 결과를 조합하여 인공지능 모델의 출력 을 생성할 수 있다. 구체적으로 최적화 장치는 병렬적으로 실행된 개별 레이어의 결과(출력 데이터)를 컴퓨팅 장치로부터 수집하고, 이를 이용하여 인공지능 모델의 최종 출력을 생성할 수 있으며, 이 과정에서 각 레이어의 출력을조합하여 트랜스포머 모델의 최종 출력을 획득할 수 있다. 이러한 절차를 통해 최적화 장치는 트랜스포머 모델의 레이어 간 병렬화를 수행하고, ARM Neon 명령어를 사용하여 효율적으로 연산을 처리할 수 있고, 임베디 드 플랫폼에서 트랜스포머 모델의 전체 실행 시간을 줄일 수 있다. 도 3은 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 장치의 개략적인 구성도이다. 도 3을 참조하면, 최적화 장치는 연산 최적화부, 구조 최적화부, 레이어 최적화부 및 출력 생성부를 포함할 수 있다. 연산 최적화부는 인공지능 모델의 훈련 및/또는 추론을 위한 연산에 대하여 SIMD(Single Instruction Multiple Data) 기반 최적화를 수행할 수 있다. 예시적으로, 연산 최적화부는 인공지능 모델과 연계된 복수의 연산 중 행렬 곱셈 연산을 복수의 단위 행렬 곱셈 연산으로 분할할 수 있다. 또한, 연산 최적화부는 분할된 복수의 단위 행렬 곱셈 연산이 동시에 수행되도록 하는 스케줄링을 결정할 수 있다. 또한, 본원의 일 실시예에 따르면, 연산 최적화부는 트랜스포머 기반의 딥러닝 모델의 어텐션(Attention) 메커니즘과 관련하여 병렬 수행 가능한 복수의 단위 연산을 탐색할 수 있다. 또한, 본원의 일 실시예에 따르면, 연산 최적화부는 ARM 아키텍쳐 기반의 Neon 명령어를 이용하여 인공지 능 모델에 대하여 SIMD 기반 최적화를 적용할 수 있다. 구조 최적화부는 인공지능 모델과 연계된 가중치와 관련한 메모리 관리 방식 및 데이터 구조를 최적화 할 수 있다. 구체적으로, 구조 최적화부는 인공지능 모델의 가중치와 연계된 가중치 행렬을 복수의 블록으로 분할할 수 있다. 또한, 구조 최적화부는 분할된 복수의 블록 각각에 대하여 연속된 메모리 주소를 할당할 수 있다. 또한, 본원의 일 실시예에 따르면, 구조 최적화부는 인공지능 모델의 가중치 및 활성화 값의 정밀도를 감소시킬 수 있다. 레이어 최적화부는 인공지능 모델을 이루는 복수의 레이어에 병렬화를 적용할 수 있다. 구체적으로 레이어 최적화부는 인공지능 모델을 이루는 복수의 레이어 간의 의존성 분석 정보를 도출할 수 있다. 또한, 레이어 최적화부는 도출된 의존성 분석 정보를 고려하여 복수의 레이어 각각에 대하여 수행되는 연 산을 상호 독립적인 작업 태스크로 분할할 수 있다. 또한, 레이어 최적화부는 분할된 작업 태스크를 기 구축된 작업 큐에 추가할 수 있다. 또한, 레이어 최적화부는 작업 큐로부터 인공지능 모델의 구동을 위한 컴퓨팅 장치의 코어 각각에 작 업 태스크를 할당하여, 각 작업 태스크가 개별 코어에서 병렬적으로 수행되도록 컴퓨팅 장치를 제어하거나, 컴퓨팅 장치에서 수행될 작업의 스케줄링 내용을 결정할 수 있다. 출력 생성부는 복수의 레이어 각각의 작업 태스크에 대한 수행 결과를 조합하여 인공지능 모델의 출력 을 생성할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 4는 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 방법에 대한 동작 흐름도이다. 도 4에 도시된 인공지능 모델에 대한 연산 및 메모리 최적화 방법은 앞서 설명된 최적화 장치에 의하여 수 행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 최적화 장치에 대하여 설명된 내용은 인공지능 모델에 대한 연산 및 메모리 최적화 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 4를 참조하면, 단계 S11에서 연산 최적화부는 (a) 인공지능 모델의 훈련 및/또는 추론을 위한 연산 에 대하여 SIMD(Single Instruction Multiple Data) 기반 최적화를 수행할 수 있다. 본원의 일 실시예에 따르면, 단계 S11에서 연산 최적화부는 인공지능 모델과 연계된 복수의 연산 중 행 렬 곱셈 연산을 복수의 단위 행렬 곱셈 연산으로 분할할 수 있다. 또한, 단계 S11에서 연산 최적화부는 분 할된 복수의 단위 행렬 곱셈 연산이 동시에 수행되도록 하는 스케줄링을 결정할 수 있다.또한, 본원의 일 실시예에 따르면, 단계 S11에서 연산 최적화부는 트랜스포머 기반의 딥러닝 모델의 어텐 션(Attention) 메커니즘과 관련하여 병렬 수행 가능한 복수의 단위 연산을 탐색할 수 있다. 또한, 본원의 일 실시예에 따르면, 단계 S11에서 연산 최적화부는 ARM 아키텍쳐 기반의 Neon 명령어를 이 용하여 인공지능 모델에 대하여 SIMD 기반 최적화를 적용할 수 있다. 다음으로, 단계 S12에서 구조 최적화부는 (b) 인공지능 모델과 연계된 가중치와 관련한 메모리 관리 방 식 및 데이터 구조를 최적화 할 수 있다. 본원의 일 실시예에 따르면, 단계 S12에서 구조 최적화부는 인공지능 모델의 가중치와 연계된 가중치 행렬 을 복수의 블록으로 분할할 수 있다. 또한, 단계 S12에서 구조 최적화부는 분할된 복수의 블록 각각에 대 하여 연속된 메모리 주소를 할당할 수 있다. 또한, 본원의 일 실시예에 따르면, 단계 S12에서 구조 최적화부는 인공지능 모델의 가중치 및 활성화 값의 정밀도를 감소시킬 수 있다. 다음으로, 단계 S13에서 레이어 최적화부는 (c) 인공지능 모델을 이루는 복수의 레이어에 병렬화를 적 용할 수 있다. 상술한 설명에서, 단계 S11 내지 S13은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 도 5는 인공지능 모델에 대하여 수행되는 레이어 병렬화 프로세스에 대한 세부 동작 흐름도이다. 도 5에 도시된 인공지능 모델에 대하여 수행되는 레이어 병렬화 프로세스는 앞서 설명된 최적화 장치에 의 하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 최적화 장치에 대하여 설명된 내용은 도 5에 대한 설명에도 동일하게 적용될 수 있다. 도 5를 참조하면, 단계 S131에서 레이어 최적화부는 (c1) 인공지능 모델을 이루는 복수의 레이어 간의 의존성 분석 정보를 도출할 수 있다. 다음으로, 단계 S132에서 레이어 최적화부는 (c2) 의존성 분석 정보를 고려하여 복수의 레이어 각각에 대 하여 수행되는 연산을 상호 독립적인 작업 태스크로 분할할 수 있다. 또한, 단계 S132에서 레이어 최적화부 는 분할된 작업 태스크를 기 구축된 작업 큐에 추가할 수 있다. 다음으로, 단계 S133에서 레이어 최적화부는 (c3) 작업 큐로부터 인공지능 모델의 구동을 위한 컴퓨팅 장 치의 코어 각각에 작업 태스크를 할당하여, 각 작업 태스크가 개별 코어에서 병렬적으로 수행되도록 컴퓨 팅 장치를 제어하거나, 컴퓨팅 장치에서 수행될 작업의 스케줄링 내용을 결정할 수 있다. 상술한 설명에서, 단계 S131 내지 S133은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있 다. 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 방법은 다양한 컴퓨터 수단을 통하여 수 행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예 에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해 서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 인공지능 모델에 대한 연산 및 메모리 최적화 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되"}
{"patent_id": "10-2023-0091242", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 컴퓨터 프로그램 또는 애플리케이션의 형태로도 구현될 수 있다.전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2023-0091242", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 장치를 포함하는 인공지능 기반 의 연산 시스템의 개략적인 구성도이다. 도 2는 트랜스포머(Transformer) 기반의 딥러닝 모델의 아키텍처를 나타낸 개념도이다. 도 3은 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 장치의 개략적인 구성도이다. 도 4는 본원의 일 실시예에 따른 인공지능 모델에 대한 연산 및 메모리 최적화 방법에 대한 동작 흐름도이다. 도 5는 인공지능 모델에 대하여 수행되는 레이어 병렬화 프로세스에 대한 세부 동작 흐름도이다."}
