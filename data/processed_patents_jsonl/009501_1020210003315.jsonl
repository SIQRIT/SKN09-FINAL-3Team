{"patent_id": "10-2021-0003315", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0102172", "출원번호": "10-2021-0003315", "발명의 명칭": "실시간 영상을 통해 획득되는 병변 판단 시스템의 제어 방법, 장치 및 프로그램", "출원인": "한림대학교 산학협력단", "발명자": "방창석"}}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "실시간 영상을 통해 획득되는 병변 판단 시스템의 제어 방법에 있어서,내시경 장치가, 위 내시경 영상을 획득하는 단계;상기 내시경 장치가, 상기 획득된 위 내시경 영상을 서버로 전송하는 단계;상기 서버가, 상기 위 내시경 영상을 제1 인공지능 모델에 입력하여, 상기 위 내시경 영상에 포함된 병변을 판단하는 단계;상기 서버가, 상기 위 내시경 영상 중 병변이 판단된 경우, 상기 병변을 포함하는 이미지를 획득하여, 상기 서버의 데이터베이스로 전송하는 단계; 상기 서버가, 상기 이미지를 제2 인공지능 모델에 입력하여, 상기 이미지에 포함된 병변의 종류를 판단하는 단계; 및상기 위 내시경 영상 중 병변이 판단된 경우, 디스플레이 장치가, 상기 위 내시경 영상 내에서, 상기 병변의 위치를 안내하기 위한 UI를 표시하는 단계; 를 포함하는 제어 방법."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 병변을 판단하는 단계는,상기 내시경 장치에 의해 실시간 영상이 촬영되는 중, 시술자로부터 영상 판독 명령을 수신한 경우, 상기 서버는, 상기 영상 판독 명령이 입력된 시점으로부터 기 설정된 시간 이전의 영상에 대한 복수의 이미지를 획득하는단계; 상기 서버가, 상기 복수의 이미지를 상기 제2 인공지능 모델에 입력하여, 상기 복수의 이미지에 병변이 포함되었는지 여부 및 병변의 종류를 판단하는 단계;상기 서버가, 상기 복수의 이미지 중, 병변이 포함된 것으로 판단된 경우, 상기 실시간 영상 중, 상기 병변이포함되었는지 여부를 판단하는 단계; 및상기 병변이 포함된 경우, 상기 디스플레이 장치가 상기 실시간 영상 내에 상기 병변의 위치를 안내하기 위한UI를 표시하는 단계; 를 포함하는 제어 방법."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 인공지능 모델에 상기 내시경 영상이 입력된 경우, 상기 서버가, 상기 영상이 위 내시경 영상인지 여부를 판단하는 단계; 및상기 디스플레이 장치가, 상기 영상이 위 내시경 영상이 아닌 경우, 새로운 환자 정보를 입력하기 위한 UI를 표시하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 영상이 위 내시경 영상인지 여부를 판단하는 단계는,상기 서버가, 상기 내시경 영상이 촬영되는 내시경실의 평균 명암에 대응되는 데이터를 획득하는 단계; 및상기 서버가, 상기 데이터를 바탕으로, 상기 내시경 장치가 인체 밖에 위치하는지 판단하는 단계; 를 포함하는공개특허 10-2022-0102172-3-제어 방법."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 이미지에 포함된 병변의 종류를 판단하는 단계는,상기 서버가, 조직검사로 인해 출혈이 발생하였는지 여부를 판단하는 단계; 및상기 출혈 발생이 판단된 경우, 상기 출혈이 발생한 위치에 대한 병변 판단을 수행하지 않는 단계; 를 포함하는제어 방법."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제어 방법은, 상기 서버가, 상기 내시경 영상을 복수의 프레임으로 분할하는 단계; 및상기 서버가, 상기 복수의 프레임 중, 기 설정된 수 이상의 연속된 프레임에 병변이 판단되면, 상기 연속된 프레임에 대응되는 병변을 동일 병변으로 판단하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 UI를 표시하는 단계는,환자 정보 입력을 위한 제1 아이콘, 판단된 병변을 포함하는 이미지를 확인하기 위한 제2 아이콘, 검사결과 이미지를 확인하기 위한 제3 아이콘, 설정값 변경을 위한 제4 아이콘 및 실시간 영상으로 복귀하기 위한 제5 아이콘을 표시하는 단계;상기 제1 아이콘에 대한 사용자 명령이 입력되면, 환자명, 환자 차트 번호, 성별 및 출생연도 입력을 위한 제1UI를 표시하는 단계;상기 제2 아이콘에 대한 사용자 명령이 입력되면, 병변을 포함하는 이미지 리스트를 안내하기 위한 제2 UI를 표시하는 단계;상기 제3 아이콘에 대한 사용자 명령이 입력되면, 상기 병변별 판단결과를 나타내는 리스트를 안내하기 위한 제3 UI를 표시하는 단계;상기 제4 아이콘을 통한 사용자 명령이 입력되면, 설정값 변경을 위한 제4 UI를 표시하는 단계; 및상기 제5 아이콘을 통한 사용자 명령이 입력되면, 실시간 영상을 표시하기 위한 제5 UI를 표시하는 단계; 및 상기 제5 UI를 표시하는 동안, 상기 제1 아이콘, 상기 제2 아이콘, 상기 제3 아이콘 및 상기 제4 아이콘 중 하나의 아이콘에 대한 제1 사용자 명령이 입력되면, 상기 제1 사용자 명령에 대응되는 UI를 제1 레이어에 표시하는단계; 를 포함하는 제어 방법."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 위 내시경 영상에 포함된 병변을 판단하는 단계는,상기 판단된 병변이 실시간 시술이 필요한 병변인지 여부를 판단하는 단계;상기 판단된 병변이 실시간 시술이 필요한 병변인 경우, 상기 내시경 장치로부터 상기 위 내시경 장치를 수신한시간과, 상기 위 내시경 영상에 포함된 병변을 판단한 시간과의 차이값을 산출하는 단계; 및상기 차이값이 기 설정된 값 이상인 경우, 상기 제5 UI에 시술이 필요한 병변에 대한 정보 및 상기 차이값을 표시하는 단계; 를 포함하는 제어 방법.공개특허 10-2022-0102172-4-청구항 9 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 제1 항의 방법을 수행하는, 장치."}
{"patent_id": "10-2021-0003315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어인 컴퓨터와 결합되어, 제1 항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된컴퓨터프로그램."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시간 영상을 통해 획득되는 병변 판단 시스템의 제어 방법이 제공된다. 상기 제어 방법은, 내시경 장치가, 위 내시경 영상을 획득하는 단계; 상기 내시경 장치가, 상기 획득된 위 내시경 영상을 서버로 전송하는 단계; 상기 서버가, 상기 위 내시경 영상을 제1 인공지능 모델에 입력하여, 상기 위 내시경 영상에 포함된 병변을 판단하는 단계 상기 서버가, 상기 위 내시경 영상 중 병변이 판단된 경우, 상기 병변을 포함하는 이미지를 획득하여, 상기 서버의 데이터베이스로 전송하는 단계; 상기 서버가, 상기 이미지를 제2 인공지능 모델에 입력하여, 상기 이미지 에 포함된 병변의 종류를 판단하는 단계; 및 상기 위 내시경 영상 중 병변이 판단된 경우, 디스플레이 장치가, 상기 위 내시경 영상 내에서, 상기 병변의 위치를 안내하기 위한 UI를 표시하는 단계를 포함한다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 실시간 영상을 통해 획득되는 병변 판단 시스템의 제어 방법, 장치 및 프로그램에 관한 것으로, 보다 상세하게는 상부위장관 내시경 실제검사 영상에서 딥러닝을 이용하여 병변을 자동으로 발견하고 판단하고 위벽 침윤깊이 정보를 제공하는 내시경 검사 판단보조장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "우리나라는 위암발생률이 전세계에서 가장 높은 국가로 위암 및 그 전구 병변인 위 신생물의 판단을 위해 상부 위장관 내시경 검사가 널리 시행되고 있다. 위암을 포함한 위 신생물의 판단은 내시경 의사가 검사 도중 육안소 견으로 병변을 의심하면 내시경 겸자를 통한 조직검사를 통해 병리조직의 판독으로 이루어진다. 또한 육안으로 판단을 내리기 어려운 병변도 암종이나 신생물이 아님을 확인하기 위한 목적으로 조직검사가 시행되고 있다. 하지만, 육안소견과 조직검사가 일치하는 비율은 낮으며 (내시경 의사의 육안 추정판단과 실제판단이 일치하지 않는 경우), 조직검사를 통한 일차 판단(전체 병변의 일부만 검사)과 수술 및 내시경절제술을 통한 치료 후 전 체조직의 최종병리소견의 불일치 비율 또한 20~60%로 의사의 경험과 실력에 따라 다양하게 보고되고 있다. 따라 서 낮은 초기 판단율로 인해 치료방침의 변화나 환자의 예후 예측에 혼란이 있는 실정이다. 또한 내시경 검사 도중 병변을 발견하지 못하고 놓칠 경우 환자의 예후에 직접 영향을 미치게 되는데 최근 국내 소화기내시경의사 의 번아웃 현상이 심각하다고 알려져 있다. 체력적인 이유로 면밀한 검사가 어렵거나 집중도 있는 검사가 어려 워 병변을 놓칠 가능성 또한 지속적으로 제기되고 있다. 즉, 위 신생물의 발견 및 육안판단에 미충족 의료요구 가 있는 실정이다. 판단 이외에도 위암이나 위신생물의 치료방침을 결정하기 위해서는 병변의 위벽 침윤깊이를 예측해야 한다. 이 는 주로 의사의 육안소견과 내시경 초음파(endoscopic ultrasound) 등의 검사를 통해 판단하는데, 위암이나 위 신생물이 점막내에 국한되었거나 점막하 침윤 깊이가 500㎛이하인 경우에만 내시경 절제 시술의 대상이 된다. 하지만 육안소견의 정확도는 내시경 의사 개인에 따라 차이가 크고, 내시경 초음파의 점막하 침윤 예측정도는 최고수준의 전문가의 경우에도 72-84% 정도로 보고되고 있다. 따라서 내시경 절제술 이후에 점막하 침윤이 깊은 암으로 최종 판단되는 경우 추가적인 위절제수술이 필요하여 위암과 위 신생물의 위벽 침윤깊이 판단에 미충족 의료요구가 있는 실정이다. 본 발명의 배경이 되는 기술은 한국등록특허공보 제10-2168485호에 개시되어 있다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 실시간 영상을 통해 획득되는 병변 판단 시스템의 제어 방법을 제공하는 것 이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 면에 따른 실시간 영상을 통해 획득되는 병변 판단 시스템의 제어 방법은, 내시경 장치가, 위 내시경 영상을 획득하는 단계; 상기 내시경 장치가, 상기 획득된 위 내시경 영상을 서버로 전송하는 단계; 상기 서버가, 상기 위 내시경 영상을 제1 인공지능 모델에 입력하여, 상기 위 내시경 영 상에 포함된 병변을 판단하는 단계 상기 서버가, 상기 위 내시경 영상 중 병변이 판단된 경우, 상기 병변을 포 함하는 이미지를 획득하여, 상기 서버의 데이터베이스로 전송하는 단계; 상기 서버가, 상기 이미지를 제2 인공 지능 모델에 입력하여, 상기 이미지에 포함된 병변의 종류를 판단하는 단계; 및 상기 위 내시경 영상 중 병변이 판단된 경우, 디스플레이 장치가, 상기 위 내시경 영상 내에서, 상기 병변의 위치를 안내하기 위한 UI를 표시하 는 단계를 포함한다. 이때, 상기 병변을 판단하는 단계는, 상기 내시경 장치에 의해 실시간 영상이 촬영되는 중, 시술자로부터 영상 판독 명령을 수신한 경우, 상기 서버는, 상기 영상 판독 명령이 입력된 시점으로부터 기 설정된 시간 이전의 영 상에 대한 복수의 이미지를 획득하는 단계; 상기 서버가, 상기 복수의 이미지를 상기 제2 인공지능 모델에 입력 하여, 상기 복수의 이미지에 병변이 포함되었는지 여부 및 병변의 종류를 판단하는 단계; 상기 서버가, 상기 복 수의 이미지 중, 병변이 포함된 것으로 판단된 경우, 상기 실시간 영상 중, 상기 병변이 포함되었는지 여부를 판단하는 단계; 및 상기 병변이 포함된 경우, 상기 디스플레이 장치가 상기 실시간 영상 내에 상기 병변의 위치 를 안내하기 위한 UI를 표시하는 단계를 포함할 수 있다. 이때, 상기 제1 인공지능 모델에 상기 내시경 영상이 입력된 경우, 상기 서버가, 상기 영상이 위 내시경 영상인 지 여부를 판단하는 단계; 및상기 디스플레이 장치가, 상기 영상이 위 내시경 영상이 아닌 경우, 새로운 환자 정보를 입력하기 위한 UI를 표시하는 단계를 포함할 수 있다. 이때, 상기 영상이 위 내시경 영상인지 여부를 판단하는 단계는, 상기 서버가, 상기 내시경 영상이 촬영되는 내 시경실의 평균 명암에 대응되는 데이터를 획득하는 단계; 및 상기 서버가, 상기 데이터를 바탕으로, 상기 내시 경 장치가 인체 밖에 위치하는지 판단하는 단계; 를 포함할 수 있다. 이때, 상기 이미지에 포함된 병변의 종류를 판단하는 단계는, 상기 서버가, 조직검사로 인해 출혈이 발생하였는 지 여부를 판단하는 단계; 및 상기 출혈 발생이 판단된 경우, 상기 출혈이 발생한 위치에 대한 병변 판단을 수 행하지 않는 단계를 포함할 수 있다. 이때, 상기 제어 방법은, 상기 서버가, 상기 내시경 영상을 복수의 프레임으로 분할하는 단계; 및 상기 서버가, 상기 복수의 프레임 중, 기 설정된 수 이상의 연속된 프레임에 병변이 판단되면, 상기 연속된 프레임에 대응되 는 병변을 동일 병변으로 판단하는 단계를 포함할 수 있다. 이때, 상기 UI를 표시하는 단계는, 환자 정보 입력을 위한 제1 아이콘, 판단된 병변을 포함하는 이미지를 확인 하기 위한 제2 아이콘, 검사결과 이미지를 확인하기 위한 제3 아이콘, 설정값 변경을 위한 제4 아이콘 및 실시 간 영상으로 복귀하기 위한 제5 아이콘을 표시하는 단계; 상기 제1 아이콘에 대한 사용자 명령이 입력되면, 환 자명, 환자 차트 번호, 성별 및 출생연도 입력을 위한 제1 UI를 표시하는 단계; 상기 제2 아이콘에 대한 사용자 명령이 입력되면, 병변을 포함하는 이미지 리스트를 안내하기 위한 제2 UI를 표시하는 단계; 상기 제3 아이콘에 대한 사용자 명령이 입력되면, 상기 병변별 판단결과를 나타내는 리스트를 안내하기 위한 제3 UI를 표시하는 단 계; 상기 제4 아이콘을 통한 사용자 명령이 입력되면, 설정값 변경을 위한 제4 UI를 표시하는 단계; 상기 제5 아이콘을 통한 사용자 명령이 입력되면, 실시간 영상을 표시하기 위한 제5 UI를 표시하는 단계; 및 상기 제5 UI 를 표시하는 동안, 상기 제1 아이콘, 상기 제2 아이콘, 상기 제3 아이콘 및 상기 제4 아이콘 중 하나의 아이콘 에 대한 제1 사용자 명령이 입력되면, 상기 제1 사용자 명령에 대응되는 UI를 제1 레이어에 표시하는 단계; 를 포함할 수 있다. 이때, 상기 위 내시경 영상에 포함된 병변을 판단하는 단계는, 상기 판단된 병변이 실시간 시술이 필요한 병변 인지 여부를 판단하는 단계; 상기 판단된 병변이 실시간 시술이 필요한 병변인 경우, 상기 내시경 장치로부터 상기 위 내시경 장치를 수신한 시간과, 상기 위 내시경 영상에 포함된 병변을 판단한 시간과의 차이값을 산출하 는 단계; 및 상기 차이값이 기 설정된 값 이상인 경우, 상기 제5 UI에 시술이 필요한 병변에 대한 정보 및 상기 차이값을 표시하는 단계를 포함할 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 본 발명의 다양한 실시예에 따라, 인공지능 모델을 이용한 병변 판단을 실시간으로 수행함으로써, 위 내 시경 영상 촬영 및 시술의 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 명세서에서 사용되는 \"부\" 또는 “모듈”이라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소 를 의미하며, \"부\" 또는 “모듈”은 어떤 역할들을 수행한다. 그렇지만 \"부\" 또는 “모듈”은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\" 또는 “모듈”은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수 도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 \"부\" 또는 “모 듈”은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라 이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 \"부\" 또는 “모듈”들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 \"부\" 또는 “모듈”들로 결합되거나 추가적인 구성요소들과 \"부\" 또는 “모듈”들로 더 분리될 수 있다. 공간적으로 상대적인 용어인 \"아래(below)\", \"아래(beneath)\", \"하부(lower)\", \"위(above)\", \"상부(upper)\" 등 은 도면에 도시되어 있는 바와 같이 하나의 구성요소와 다른 구성요소들과의 상관관계를 용이하게 기술하기 위 해 사용될 수 있다. 공간적으로 상대적인 용어는 도면에 도시되어 있는 방향에 더하여 사용시 또는 동작시 구성 요소들의 서로 다른 방향을 포함하는 용어로 이해되어야 한다. 예를 들어, 도면에 도시되어 있는 구성요소를 뒤 집을 경우, 다른 구성요소의 \"아래(below)\"또는 \"아래(beneath)\"로 기술된 구성요소는 다른 구성요소의 \"위 (above)\"에 놓여질 수 있다. 따라서, 예시적인 용어인 \"아래\"는 아래와 위의 방향을 모두 포함할 수 있다. 구성요소는 다른 방향으로도 배향될 수 있으며, 이에 따라 공간적으로 상대적인 용어들은 배향에 따라 해석될 수 있 다. 본 명세서에서, 컴퓨터는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이해될 수 있다. 예 를 들어, 컴퓨터는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애 플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 본 명세서에서 설명되는 각 단계들은 컴퓨터에 의하여 수행되는 것으로 설명되나, 각 단계의 주체는 이에 제한 되는 것은 아니며, 실시 예에 따라 각 단계들의 적어도 일부가 서로 다른 장치에서 수행될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 시스템도이다. 도 1에 도시된 바와 같이, 실시간 영상을 통해 획득되는 병변 판단 시스템은 서버, 내시경 장치 및 디스플레이 장치를 포함할 수 있다. 본 발명의 일 실시예에 따른 시스템은, 서버, 내시경 장치 및 디스플레이 장치 간의 정보 공유 를 위한 네트워크의 일 예로는 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 유무선 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스(Bluetooth) 네트워크, Wifi 네트워크, NFC(Near Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함될 수 있으며, 이에 한정된 것은 아니다. 서버는 내시경 장치로부터 이미지를 획득하여 위 병변을 판단하기 위한 구성이다. 본 발명의 일 실시 예에 따른 서버는 이미지 획득부, 데이터 생성부, 전처리부, 학습부 및 병변 판단부를 포함할 수 있다. 다 만, 서버의 구성이 앞서 개시된 것들로 한정되는 것은 아니다. 예를 들어, 서버는 정보를 저장하기 위한 데이터베이스를 더 포함할 수 있다. 이미지 획득부는 복수의 위 병변 이미지를 획득할 수 있다. 이미지 획득부는 내시경 장치에 구비된 촬영 장치로부터 위 병변 이미지를 수신할 수 있다. 이미지 획득부는 위 내시경 진료에 사용되고 있는 내시경 촬영 장치(디지털 카메라)로 획득된 위 병변 이미지를 획득할 수 있다. 이미지 획득부는 병리학적으로 확인된 위 병 변의 내시경 백색광 이미지를 수집할 수 있다. 또한, 이미지 획득부는 복수의 병원의 영상 보관 장치 및 데이터 베이스 시스템으로부터 복수의 위 병변 이미지를 수신할 수 있다. 복수의 병원의 영상 보관 장치는, 다수의 병 원에서 위 내시경 수행 시 획득된 위 병변 이미지를 저장한 장치일 수 있다. 또한, 이미지 획득부는 피검사체의 위의 제1 영역을 각도, 방향 및 거리 중 어느 하나를 달리하여 촬영된 영상 (이미지)을 획득할 수 있다. 이미지 획득부는 JPEG 형식의 위 병변 이미지를 획득할 수 있다. 위 병변 이미지는 1280 x 640 픽셀의 해상도로 각도 35도 필드의 스타일을 적용한 것일 수 있다. 한편, 이미지 획득부는 각 위 병 변 이미지에 대한 개별 식별자 정보가 제거된 이미지를 획득할 수 있다. 이미지 획득부는 중앙에 병변이 위치하 고, 위 병변 이미지 중 검은색 프레임 영역이 제거된 이미지를 획득할 수 있다. 반면, 이미지 획득부는 이미지 획득 과정에서 초점 이탈, 인공물, 음역 등 품질이 낮거나 낮은 해상도의 이미지 가 획득되는 경우, 해당 이미지를 배제할 수 있다. 달리 말해, 이미지 획득부는 딥러닝 알고리즘에 적용 가능하 지 않은 이미지인 경우, 해당 이미지를 배제할 수 있다. 데이터 생성부는 복수의 위 병변 이미지와 환자 정보를 연계하여 데이터 세트를 생성할 수 있다. 환자 정보는 대상자(피검자)의 성별, 나이, 키, 몸무게, 인종, 국적, 흡연량, 음주량, 가족력 등의 다양한 정보를 포함할 수 있다. 또한, 환자 정보는 임상 정보를 포함할 수 있다. 임상정보란 병원에서 판단을 내리는 의사가 특정 판단 에 활용하는 모든 데이터를 의미할 수 있다. 특히, 진료과정에서 생성되는 성별, 나이를 포함하는 자료, 특정 치료 여부 자료, 급여 청구 및 처방 자료 등을 포함하는 전자 의무 기록 자료일 수 있다. 또한, 임상정보는 유 전자 정보와 같은 생물학적 데이터 자료를 포함할 수 있다. 생물학적 데이터 자료는 심박수, 심전도, 운동량, 산소포화도, 혈압, 체중, 당료와 같은 수치적 데이터를 갖는 개인 건강 정보를 포함할 수 있다. 환자 정보는 이하 설명되는 학습부에서 합성곱신경망 구조의 결과물과 함께 완전 연결 신경망에 입력되는 데이 터이며, 위 병변 이미지 외의 정보를 인공신경망을 입력으로 함으로써 보다 정확도를 향상시키는 효과를 기대할수 있다. 또한, 데이터 생성부는 딥러닝 알고리즘 적용을 위한 학습용 데이터 세트 및 검증용 데이터 세트를 생성할 수 있다. 데이터 세트를 인공신경망 학습에 요구되는 학습용 데이터 세트 및 인공신경망의 학습의 진행 정보를 검 증하기 위한 검증용 데이터 세트로 분류하여 데이터 세트를 생성할 수 있다. 일예로, 데이터 생성부는 이미지 획득부로부터 획득된 위 병변 이미지 중 랜덤하게 학습용 데이터 세트에 활용될 이미지 및 검증용 데이터 세트 에 활용된 이미지를 분류할 수 있다. 또한, 데이터 생성부는 검증용 데이터 세트를 선택한 나머지를 데이터 세 트를 학습용 데이터 세트로 사용할 수 있다. 검증용 데이터 세트는 랜덤하게 선택될 수 있다. 검증용 데이터 세 트 및 학습용 데이터 세트의 비율은 미리 설정된 기준값에 의해 결정될 수 있다. 이때, 미리 설정된 기준값은 검증용 데이터 세트의 비율이 10%, 학습용 데이터 세트의 비율이 90%로 설정될 수 있으나, 이에 한정되는 것은 아니다. 데이터 생성부는 과적합 상태를 방지하기 위해 학습용 데이터 세트 및 검증용 데이터 세트를 구분하여 데이터 세트를 생성할 수 있다. 예를 들어, 신경망 구조의 학습 특성상 학습용 데이터 세트는 과적합 상태가 될 수 있 기 때문에, 데이터 생성부는 검증용 데이터 세트를 활용하여, 인공신경망의 과적합 상태가 되는 것을 방지할 수 있다. 이때, 검증용 데이터 세트는 학습용 데이터 세트와 중복되지 않는 데이터 세트일 수 있다. 검증용 데이터는 인 공신경망 구축에 사용되지 않은 데이터이므로, 검증 작업 시에 인공신경망에서 처음 접하는 데이터이다. 따라서 검증용 데이터 세트는 새로운 이미지(학습에 사용되지 않은 신규 이미지)가 입력으로 들어올 경우, 인공신경망 의 성능 평가에 적절한 데이터 세트일 수 있다. 전처리부는 딥러닝 알고리즘에 적용 가능하도록 데이터 세트를 전처리할 수 있다. 전처리부는 딥러닝 알고리즘 에서 인식 성능을 높이고 환자 간 영상과의 유사성을 최소화하기 위해 데이터 세트를 전처리할 수 있다. 딥러닝 알고리즘은 합성곱신경망(Convolutional Neural Networks) 구조와 완전연결 심층 신경망 (Fully-connected Neural Networks) 구조 두 부분으로 이루어질 수 있다. 본 발명의 실시예에 따른 인공지능 모델은, UNet의 변형 모델인 UNet++ 에서 edge smoothing 알고리즘이 적용된 Modified UNet++일 수 있다. 이때, Modified UNet++의 Backbone은 DenseNet121일 수 있다. 한편, 도 2에 도시된 바와 같이, 본 발명에 따른 인공지능 모델은, 진행성위암(advanced gastric cancer), 조기 위암(early gastric cancer), 고등급선종(high grade dysplasia), 저등급선종(low grade dysplasia), 정상병변 (normal category)의 5단 분류 모델일 수 있다. 이 경우, 인공지능 모델은 a) Weight Initialization with ImageNet, b) Augmentation: Horizontal/Vertical Flip, Rotate(-10°~ +10°), c) Batch Size: 6, d) Learning Rate: 4e-04 e) Epoch: 100 f) Optimizer: Adam, g) Loss Function: categorical crossentropy를 파라미터로 사용할 수 있다. 또 다른 예로, 도 3에 도시된 바와 같이, 본 발명에 따른 인공지능 모델은 병변이 점막에 국한되어 있는지 (mucosa-confined lesion) 및 점막하 침윤이 있는지(submucosa-invaded lesion)에 대한 2단 분류 모델일 수 있 다. 이 경우, 인공지능 모델은 a) Augmentation: Horizontal/Vertical Flip, Rotate(-5°~ +5°), Horizontal/Vertical Shift(-10% ~ +10%), Zoom(0.8 ~ 1.2), b) Batch Size: 2, c) Learning Rate: 1.25e-4, d) Epoch: 200, e) Dropout: 0.4, f) Learning Rate Scheduler with 0.97 decay was used를 파라미터로 사용 할 수 있다. 다양한 실시예에 따라, 본 발명에 따른 인공지능 모델은 진행성위암(advanced gastric cancer), 조기위암(early gastric cancer), 선종(dysplasia), 정상병변(normal category)로 4단 분류 모델일 수 있다. 전처리부는 위 병변 이미지 데이터의 데이터 수를 증가시키기 위한 이미지 데이터를 증폭하는 증폭부(미도시)를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 합성곱신경망을 포함하는 딥러닝 알고리즘을 이용하는 경우, 데이터의 양이 많 을수록 좋은 성능을 달성하는 데 유리하지만, 위 내시경 이미지는 그 검사 건수가 다른 검사에 비해 상당히 적 은 편으로, 이미지 획득부에서 검출된 위 병변 이미지 데이터 수집량은 합성곱 신경망을 활용하기에 매우 부족 할 수 있다. 따라서, 증폭부(미도시)는 학습용 데이터 세트를 기반으로 데이터 증폭(augmentation)과정을 수행 할 수 있다. 증폭부(미도시)는 위 병변 이미지의 회전, 뒤집기, 자르기, 소음 섞기 중 적어도 어느 하나의 방법을 적용하여 데이터 증폭(augmentation)과정을 수행할 수 있다. 전처리부는 미리 설정된 기준값에 대응되도록 전처리 과정을 수행할 수 있다. 미리 설정된 기준값은 사용자가 임의로 지정한 값일 수 있다. 또한, 미리 설정된 기준값을 획득된 위 병변 이미지의 평균값에 의해 결정된 값을 수 있다. 전처리부를 거친 데이터 세트는 학습부로 제공될 수 있다. 학습부는 전처리 과정을 거친 데이터 세트를 입력으로 하고 위 병변 분류 결과에 관한 항목을 출력으로 하는 학 습을 통해 인공신경망을 구축할 수 있다. 본 발명의 일 실시예에 따르면, 학습부는 합성곱신경망(Convolutional Neural Networks) 구조와 완전연결 심층 신경망 (Fully-connected Neural Networks) 구조 두 부분으로 이루어진 딥러닝 알고리즘을 적용하여 위 병변 분 류 결과를 출력으로 할 수 있다. 완전연결 심층 신경망은 노드 간에 횡적/종적으로 2차원적 연결을 이루고, 서 로 같은 층에 위치한 노드 간에는 연결 관계가 존재하지 않으며, 바로 인접한 층에 위치한 노드들 간에만 연결 관계가 존재한다는 것을 특징으로 하는 신경망이다. 학습부는 전처리 과정을 거친 학습용 데이터 세트를 입력으로 하는 합성곱신경망과, 합성곱신경망의 출력을 완 전연결 심층 신경망의 입력으로 하는 학습을 통한 훈련 모델을 구축할 수 있다. 본 발명의 일 실시예에 따르면 합성곱신경망은 위 병변 이미지를 분석하는 복수의 특정 특징 패턴을 추출할 수 있다. 이때, 추출된 특정 특징 패턴은 완전연결 심층 신경망에서 최종 분류를 하는데 사용될 수 있다. 합성곱신경망(Convolutional Neural Networks)은 음성 인식이나 이미지 인식에서 주로 사용되는 신경망의 한 종 류이다. 다차원 배열 데이터를 처리하도록 구성되어 있어, 컬러 이미지와 같은 다차원 배열 처리에 특화되어 있 다. 따라서 이미지 인식 분야에서 딥러닝을 활용한 기법은 대부분 합성곱신경망을 기초로 한다. 합성곱신경망(CNN)은 이미지를 하나의 데이터가 아닌, 여러 개로 분할하여 처리한다. 이렇게 하면 이미지가 왜 곡되더라도 이미지의 부분적 특성을 추출할 수 있어 올바른 성능을 낼 수 있다. 합성곱신경망은 복수의 층 구조로 이루어질 수 있다. 각각의 층을 구성하는 요소는 합성곱 층, 활성화 함수, max pooling 층, 활성화 함수, dropout 층으로 구성될 수 있다. 합성곱 층은 kernel이라 불리는 필터 역할을 하 여 전체 이미지(또는 생성된 새로운 특징 패턴)를 부분적으로 처리한 것들이 이미지와 같은 크기의 새로운 특징 패턴(feature pattern)을 추출할 수 있다. 합성곱 층은 특징 패턴에서 활성화 함수를 통해 특징 패턴의 값들을 처리하기 편하게 보정할 수 있다. max pooling 층은 일부 위 병변 이미지를 샘플링(sampling) 하여 크기를 조절 하여 이미지의 크기를 줄일 수 있다. 합성곱신경망은 합성곱 층 및 max pooling 층을 거쳐, 특징 패턴(feature pattern)의 크기는 줄어들게 되지만, 복수의 kernel 활용을 통해 복수의 특징 패턴(feature pattern)을 추출할 수 있다. dropout층은 합성곱신경망의 가중치들을 훈련할 때 효율적인 훈련을 위해 일부 가중치들을 의도적으로 고려하지 않는 방법일 수 있다. 한편, dropout층은 훈련된 모델을 통해 실제 테스트를 하는 경우에는 적용하지 않을 수 있다. 합성곱신경망에서 추출된 복수의 특징 패턴(feature pattern)은 다음 단계인 완전연결 심층 신경망으로 전달되 어 분류 작업을 하는 데 활용될 수 있다. 합성곱신경망은 층의 개수를 조절할 수 있다. 합성곱신경망은 층의 개 수는 모델 훈련을 위한 훈련용 데이터의 양에 맞추어 조절함으로써 보다 안정된 모델을 구축할 수 있다. 또한, 학습부는 전처리 과정을 거친 학습용 데이터 세트를 합성곱신경망의 입력으로 하고, 합성곱신경망의 출력 및 환자 정보를 완전연결 심층 신경망의 입력으로 하는 학습을 통한 판단(훈련) 모델을 구축할 수 있다. 달리 말해, 학습부는 전처리 과정을 거친 이미지 데이터가 우선적으로 합성곱신경망으로 들어가도록 하고, 합성곱신 경망을 거치고 나온 결과물이 완전연결 심층 신경망에 들어가도록 할 수 있다. 또한, 학습부는 임의로 추출된 특징(feature)들은 합성곱신경망을 거치지 않고, 곧바로 완전연결 심층 신경망으로 들어가도록 할 수 있다. 이때, 환자 정보는 대상자(피검자)의 성별, 나이, 키, 몸무게, 인종, 국적, 흡연량, 음주량, 가족력 등의 다양 한 정보를 포함할 수 있다. 또한, 환자 정보는 임상 정보를 포함할 수 있다. 임상정보란 병원에서 판단을 내리 는 의사가 특정 판단에 활용하는 모든 데이터를 의미할 수 있다. 특히, 진료과정에서 생성되는 성별, 나이를 포 함하는 자료, 특정 치료 여부 자료, 급여 청구 및 처방 자료 등을 포함하는 전자 의무 기록 자료일 수 있다. 또 한, 임상정보는 유전자 정보와 같은 생물학적 데이터 자료를 포함할 수 있다. 생물학적 데이터 자료는 심박수, 심전도, 운동량, 산소포화도, 혈압, 체중, 당료와 같은 수치적 데이터를 갖는 개인 건강 정보를 포함할 수 있다. 환자 정보는 학습부에서 합성곱신경망 구조의 결과물과 함께 완전 연결 신경망에 입력되는 데이터이며, 환자 정 보를 인공신경망을 입력으로 함으로써 위 병변 이미지만을 이용하여 도출된 결과보다 정확도를 향상시키는 효과 를 기대할 수 있다. 일예로, 암이 고령에 많다는 점이 학습용 데이터 세트의 임상정보를 통해 학습하게 되면, 이미지 특징과 함께 42세 또는 79세의 나이가 입력되었을 경우, 위 병변 분류 결과에서 암 또는 양성 구분이 어려운 애매모호한 병 변의 구분에서 고령의 환자는 암일 확률이 높아지는 쪽으로 결과를 도출할 수 있다. 학습부는 트레이닝 데이터를 딥러닝 알고리즘 구조(합성곱신경망을 거쳐 완전연결 심층 신경망으로 형성된 구조)에 적용시켜 도출되는 결과와 실제 결과와의 오차를 비교하여 해당 오차에 해당하는 만큼 신경망 구조의 가중치를 점차적으로 변화시켜주는 역전파(backpropagation) 알고리즘을 통해 결과가 피드백되어 학습될 수 있 다. 역전파(backpropagation) 알고리즘은 결과의 오차(실제값과 결과값이 차이)를 줄이기 위해 각 노드에서 다 음 노드로 이어지는 가중치를 조절하는 것일 수 있다. 학습부는 학습용 데이터 세트와 검증용 데이터 세트를 이 용하여 신경망을 학습시켜 가중치 매개 변수를 구하여 최종 판단 모델을 도출하는 것일 수 있다. 병변 판단부는 신규 데이터 세트를 전처리 과정을 거친 후 인공신경망을 통해 위 병변 판단을 수행할 수 있다. 달리 말해, 병변 판단부는 앞서 설명된 학습부에서 도출된 최종 판단 모델을 이용하여 신규 데이터에 대한 판단 을 도출할 수 있다. 신규 데이터는 사용자가 판단하고자 하는 위 병변 이미지를 포함하는 데이터 일 수 있다. 신규 데이터 세트는 신규 위 병변 이미지를 환자 정보와 연계하여 생성된 데이터 세트일 수 있다. 신규 데이터 세트는 전처리부의 전처리 과정을 거쳐 딥러닝 알고리즘에 적용 가능한 상태로 전처리될 수 있다. 이후 전처리 된 신규 데이터 세트는 학습부에 입력되어, 학습 파라미터를 기반으로 위 병변 이미지가 판단될 수 있다. 본 발명의 일 실시예에 따르면, 병변 판단부는 진행 위암(advanced gastric cancer), 조기 위암(early gastric cancer), 고도 이형성증(high-grade dysplasia), 저이형성증(low-grade dysplasia) 및 비종양(non-neoplasm) 중 적어도 어느 하나로 어느 하나로 상기 위 병변 판단 분류를 수행할 수 있다. 또한, 병변 판단부는 암과 비암 으로 분류할 수 있다. 또한, 병변 판단부는 신생물과 비신생물 2가지의 범주로 분류하여 위 병변 판단 분류를 수행할 수 있다. 신생물 분류에는 AGC, EGC, HGD 및 LGD가 포함될 수 있다. 비 종양 범주에는 위염, 양성 궤양, 기형, 용종, 장상피화 또는 상피 종양과 같은 병변이 포함될 수 있다. 서버는 모호한 병변을 분류 및 판단하기 위해 불필요한 생체검사나 내시경 절제로 인해 발생되는 부작용을 감소시키기 위해 내시경 장치로 획득된 이미지를 분석하여 모호한 병변을 자동으로 분류 및 판단해 주고, 신생물(위험 종양)일 경우, 내시경 절제 시술을 시행하도록 할 수 있다. 내시경 장치는 위 내시경 검사 시 사용되는 장치일 수 있다. 내시경 장치는 조작부 및 몸체부를 포함 할 수 있다. 내시경 장치는 신체 내로 삽입되는 몸체부 및 몸체부의 후단에 마련된 조작부를 포함할 수 있 다. 몸체부의 전단에는 신체 내부를 촬영하기 위한 촬영부, 촬영부위에 빛을 조사하기 위한 조명부, 촬영이 용 이하도록 신체 내부를 세척하는 물 분사부, 신체 내의 이물질이나 공기 등을 흡입하는 석션부 등이 포함될 수 있으며, 몸체부 내에는 이러한 복수의 유닛(부)들 각각에 대응하는 채널이 마련될 수 있다. 또한, 삽입부 내에 는 바이옵시 채널(biopsy channel)이 마련될 수 있으며, 내시경 시술자는 이 바이옵시 채널로 메스를 삽입하여 신체 내부의 조직을 채취할 수 있다. 내시경 장치에 구비된 신체 내부를 촬영하는 촬영부(즉, 카메라)의 경우에는, 소형 카메라가 구비될 수 있다. 촬영 장치는 백색광 위 내시경 이미지를 획득할 수 있다. 내시경 장치의 촬영부는 획득된 위 병변 이미지를 서버로 네트워크를 통해 송신할 수 있다. 서버 는 위 병변 판단 결과에 기반하여 바이옵시 유닛을 제어하기 위한 제어 신호를 생성할 수 있다. 바이옵시 유닛은 신체 내부의 조직을 채취하기 위한 유닛일 수 있다. 신체 내부의 조직을 채취함으로써, 해당 조직의 양 성 및 음성을 판단할 수 있다. 또한, 신체 내부의 조직을 절제함으로써, 암 조직을 제거할 수 있다. 예시적으로, 서버는 위 내시경 이미지를 획득하고, 신체 내부의 조직을 채취하는 내시경 장치에 포함 될 수 있다. 달리 말해, 내시경 장치로부터 실시간으로 획득되는 위 내시경 이미지를, 학습으로 통하여 구 축된 인공신경망에 입력으로 하여 위 병변 판단 결과에 관한 항목 중 적어도 어느 하나로 구분되어 위 병변에 대한 판단 및 예측이 가능할 수 있다. 본 발명의 다른 일 실시예에 따르면, 내시경 장치는 캡슐형태로 형성될 수 있다. 예를 들어, 내시경 장치 는 캡슐형태로 형성되어, 피검자의 체내로 삽입되어 위 내시경 이미지를 획득할 수 있다. 캡슐형 내시경 장치는 피검자의 식도, 위, 소장 및 대장 중 어디에 위치하는지에 대한 위치 정보도 함께 제공할 수 있다. 달리 말해, 캡슐형 내시경 장치는 피검자(환자)의 체내에 위치하고, 실시간으로 획득되는 영상(이미지)을 네트워크를 통해 서버로 제공할 수 있다. 이때, 캡슐형 내시경 장치는 위 내시경 이미지뿐만 아니라,위 내시경 이미지가 획득된 위치 정보를 함께 제공함으로써, 서버의 판단 분류 결과가 진행 위암(advanced gastric cancer), 조기 위암(early gastric cancer), 고도 이형성증(high-grade dysplasia) 및 저이형성증 (low-grade dysplasia) 중 적어도 어느 하나에 속하는 경우, 달리 말해, 비종양 위험성 종양에 해당하는 경우, 사용자(의사)가 해당 병변의 위치를 파악하여 바로 절제술이 가능하도록 할 수 있다. 본 발명의 일 실시예에 따르면, 내시경 장치에서 실시간으로 획득된 위 병변 내시경 이미지를 서버는 학습을 통해 생성된 알고리즘에 입력으로 하여 위 병변 판단을 수행하고, 내시경 장치는 신생물 의심 병변 을 내시경 점막 절제술 또는 내시경 점막하박리술을 이용하여 해당 병변을 절제할 수 있다. 본 발명의 일 실시예에 따르면, 내시경 장치는 조작부를 이용하여 촬영부를 제어할 수 있다. 조작부는 촬 영부가 목표 병변의 위치가 시야에 놓이게 하기 위해 사용자로부터 조작 입력 신호를 수신할 수 있다. 조작부는 사용자로부터 입력받는 조작 입력 신호에 기반하여 촬영부의 위치를 제어할 수 있다. 또한, 조작부는 촬영부의 시야가 목표 병변에 위치하는 경우, 해당 이미지를 캡처하기 위한 조작 입력 신호를 제공받고, 해당 위 병변 이 미지를 캡처하기 위한 신호를 생성할 수 있다. 본 발명의 다른 일 실시예에 따르면, 내시경 장치는 캡슐 형태로 형성된 장치일 수 있다. 캡슐 내시경 장 치는 대상자(피검자)의 인체 내부에 삽입되고, 원격에서 조작될 수 있다. 캡슐 내시경 장치로부터 획 득되는 위 병변 이미지는 사용자가 캡처를 원하는 영역의 이미지뿐만 아니라, 동영상 촬영으로 획득되는 모든 영상을 이미지화하여 획득할 수 있다. 캡슐 내시경 장치는 촬영부 및 조작부를 포함할 수 있다. 촬영부는 인체 내부에 삽입되고, 조작부의 조작 신호에 기반하여 인체 내부에서 제어될 수 있다. 디스플레이 장치는 예를 들면, 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이, 유기 발광 다이오 드(OLED) 디스플레이, 또는 마이크로 전자기계 시스템(MEMS) 디스플레이를 포함할 수 있다. 디스플레이 장치 는 사용자에게 내시경 장치로부터 획득되는 위 내시경 이미지 및 서버로부터 판단되는 위 병변 판단 정보를 표시할 수 있다. 디스플레이 장치는 터치 스크린을 포함할 수 있으며, 예를 들면, 전자 펜 또 는 사용자의 신체의 일부를 이용한 터치, 제스처, 근점 또는 호버링 입력을 수신할 수 있다. 디스플레이 장치 는 내시경 장치에서 획득되는 위 병변 이미지를 출력할 수 있다. 또한, 디스플레이 장치는 위 병변 판단 결과를 출력할 수 있다. 한편, 본 발명의 다른 일 실시예에 따르면, 내시경 장치는 조작부, 몸체부, 프로세서, 병변 위치 획득부 및 디스플레이부를 포함할 수 있다. 이 경우, 내시경 장치는 인공지능 모델을 포함하며, 병변 판단을 수행할 수 있다. 구체적으로, 인공지능 모델이 병변 판단을 하는 경우 발생하는 시간 차이로 인해 실시간 위 내시경 검사가 방해되는 것을 막기 위하여, 검사자에 방해를 줄 수 있는 탐지에 관련한 알고리즘은 내시경 장치가, 나머지 전처리와 판독에 관련한 알고리즘은 서버가 수행할 수 있다. 조작부는 몸체부의 후단에 마련되어 사용자의 입력 정보에 기반하여 조작될 수 있다. 조작부는 내시경 시술자에 의하여 파지되는 부분으로서, 피검자의 체내로 삽입되는 몸체부를 조작할 수 있다. 또한, 조작부는 몸체부가 수 용하고 있는 내시경 시술시 필요한 복수의 유닛 장치의 동작을 조작할 수 있다. 조작부는 회전 프로세서를 포함 할 수 있다. 회전 프로세서는 제어 신호를 생성하는 기능 및 회전력을 제공하는 기능(예를 들어, 모터)을 담당 하는 부분을 포함할 수 있다. 조작부는 촬영부(미도시)를 조작하기 위한 버튼을 포함할 수 있다. 버튼은 촬영부 (미도시)의 위치를 제어하기 위한 버튼으로서, 사용자가 상하좌우, 전진, 후진 등과 같은 몸체부의 위치를 변경 하기 위한 것일 수 있다. 몸체부는 피검자의 체내로 삽입되는 부분으로서, 복수의 유닛 장치를 수용할 수 있다. 복수의 유닛 장치는 피검 자의 체내를 촬영하는 촬영부(미도시), 체내로 공기를 공급하는 에어 공급 유닛, 체내로 물을 공급하는 물 공급 유닛, 체내로 빛을 조사하는 조명 유닛, 체내의 조직의 일부를 채취하거나 치료하기 위한 바이옵시(biopsy) 유 닛 및 체내로부터의 공기 또는 이물질을 흡입하는 석션 유닛 중 적어도 하나를 포함할 수 있다. 바이옵시 유닛 은 생체에서 조직 일부를 채취하기 위한 매스, 바늘 등 각종 의료기기들을 포함할 수 있으며, 매스, 바늘 등의 바이옵시 유닛은 내시경 시술자에 의하여 바이옵시 채널을 통해 체내로 삽입됨으로써 체내의 세포를 채취할 수 있다. 촬영부(미도시)는 몸체부의 직경에 대응하는 크기를 갖는 카메라를 수용할 수 있다. 촬영부(미도시)는 몸체부의 전단에 구비되어 위 병변 이미지를 촬영하고, 네트워크를 통해 병변 판단부 및 디스플레이부로 촬영한 위 병변 이미지를 제공할 수 있다. 프로세서는 조작부에서 제공받은 사용자의 입력 정보 및 서버의 판단 결과에 기반하여 몸체부의 동작을 제 어하는 제어 신호를 생성할 수 있다. 프로세서는 조작부에 포함된 버튼 중 사용자로부터 어느 하나의 선택 입력 을 수신한 경우, 해당 버튼에 대응하도록 몸체부의 동작을 제어하는 제어 신호를 생성할 수 있다. 예를 들어, 프로세서는 사용자가 몸체부를 전진하도록 하는 버튼을 입력한 경우, 몸체부가 일정 속도로 대상체(환자)의 체 내를 전진할 수 있도록 동작 제어 신호를 생성할 수 있다. 몸체부는 프로세서의 제어 신호에 기반하여 대상체 (환자)의 체내에서 전진할 수 있다. 또한, 프로세서는 촬영부(미도시)의 동작을 제어하기 위한 제어 신호를 생성할 수 있다. 촬영부(미도시)의 동작 을 제어하기 위한 제어 신호는, 병변 영역에 위치한 촬영부(미도시)가 위 병변 이미지를 캡처하기 위한 신호일 수 있다. 달리 말해, 사용자는 조작부로부터 특정 병변 영역에 위치한 촬영부(미도시)가 이미지를 획득하길 원 하는 경우, 캡처 획득 버튼을 클릭할 수 있다. 프로세서는 조작부로부터 제공받은 입력 정보에 기반하여 촬영 부(미도시)기 해당 병변 영역에서 이미지를 획득할 수 있도록 제어 신호를 생성할 수 있다. 프로세서는 촬영부 (미도시)가 촬영중인 영상으로부터 특정 위 병변 이미지를 획득하기 위한 제어 신호를 생성할 수 있다. 또한, 프로세서는 서버의 판단 결과에 기반하여 대상체의 조직의 일부를 채취하기 위한 바이옵시 유닛의 동작을 제어하기 위한 제어 신호를 생성할 수 있다. 프로세서는 서버의 판단 결과가 진행 위암(advanced gastric cancer), 조기 위암(early gastric cancer), 고도 이형성증(high-grade dysplasia) 및 저이형성증 (low-grade dysplasia) 중 적어도 어느 하나에 속하는 경우 절제술을 시행할 수 있도록 바이옵시 유닛의 동작을 제어하기 위한 제어 신호를 생성할 수 있다. 바이옵시 유닛은 생체에서 조직 일부를 채취하기 위한 매스, 바늘 등 각종 의료기기들을 포함할 수 있으며, 매스, 바늘 등의 바이옵시 유닛은 내시경 시술자에 의하여 바이옵시 채널을 통해 체내로 삽입됨으로써 체내의 세포를 채취할 수 있다. 또한, 프로세서는 조작부로부터 제공받는 사 용자 입력 신호에 기반하여 바이옵시 유닛의 동작을 제어하기 위한 제어 신호를 생성할 수 있다. 체내의 세포를 채취, 절제, 제거하는 동작은 사용자가 조작부를 이용하여 수행하는 것일 수 있다. 본 발명의 일 실시예에 따르면, 병변 위치 획득부는 촬영부(미도시)에서 제공받은 위 병변 이미지와 위치 정보 를 연계하여 위 병변 정보를 생성할 수 있다. 위치 정보는 몸체부가 현재 체내에 위치한 위치정보일 수 있다. 달리 말해, 몸체부가 대상체(환자)의 위의 제1지점에 위치하고, 제1지점으로부터 위 병변 이미지가 획득된 경우, 병변 위치 획득부는 상기 위 병변 이미지와 위치 정보를 연계하여 위 병변 정보를 생성할 수 있다. 병변 위치 획득부는 획득된 위 병변 이미지와 위치 정보를 연계하여 생성된 위 병변 정보를 사용자(의사)에게 제공할 수 있다. 병변 판단부의 판단 결과 및 병변 위치 획득부의 위 병변 정보를 디스플레이부를 통해 사 용자에게 제공함으로써, 해당 병변을 절제(제거)하는 시술 및 수술 시 해당 병변 위치가 아닌 곳에서 절제술이 수행될 수 있는 상황을 방지할 수 있다. 또한, 프로세서는 병변 위치 획득부에서 제공한 위치 정보를 이용하여 바이옵시 유닛이 해당 병변 위치에 위치 하지 않을 경우, 상기 바이옵시 유닛의 위치를 제어하기 위한 제어신호를 생성할 수 있다. 서버에서 바이옵시 유닛을 제어하기 위한 제어 신호를 생성하여, 체내의 세포를 채취 또는 제거함으로써, 더욱 빠른 조직 검사를 수행할 수 있다. 더불어, 암으로 판단된 세포를 내시경 판단 과정에서 바로 제거함으로 써 빠른 치료가 가능할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본 발명의 동작 흐름을 간단히 살펴보기로 한다. 구체적으로, 도 7에 도시된 바와 같이, 단계 S110에서, 내시경 장치가, 위 내시경 영상을 획득할 수 있다. 단계 S120에서, 내시경 장치가, 획득된 위 내시경 영상을 서버로 전송할 수 있다. 단계 S130에서, 서버가, 위 내시경 영상을 제1 인공지능 모델에 입력하여, 위 내시경 영상에 포함된 병변 을 판단할 수 있다. 일 실시예로, 내시경 장치에 의해 실시간 영상이 촬영되는 중, 시술자로부터 영상 판독 명령을 수신하면, 서버는, 영상 판독 명령이 입력된 시점으로부터 기 설정된 시간 이전의 영상에 대한 복수의 이미지를 획득 할 수 있다. 구체적으로, 서버가 병변으로 판단하지 않은 경우라고 하더라도, 시술자가 의심되는 이미지를 발견한 경우, 서버는, 시술자에 의한 영상 판독 명령을 수신할 수 있다. 이때, 영상 판독 명령은 음성 명령일 수 있다. 예를 들어, 시술자가 \"영상 판독\"이라는 음성을 발산하면, 내시 경 장치는 해당 명령을 영상 판독 명령으로 인식하고, 서버로 영상 판독을 위한 제어 신호를 전송할 수 있다. 또 다른 예로, 영상 판독 명령은 내시경 장치에 포함된 기 설정된 버튼을 푸쉬하는 동작, 또는 디스플레이 장치의 특정 UI를 터치하는 동작일 수 있음은 물론이다. 서버는 영상 판독 명령을 수신하면, 영상 판독 명령이 입력된 시점으로부터 기 설정된 시간 이전의 영상에 대한 복수의 이미지 프레임을 획득하고, 해당 프레임에 대한 병변 판단 분석을 수행할 수 있다. 일 실시예로, 서버는, 복수의 이미지를 제3 인공지능 모델에 입력하여, 복수의 이미지에 병변이 포함되었 는지 여부 및 병변의 종류를 판단할 수 있다. 이때, 제1 인공지능 모델 및 제2 인공지능 모델은, 빠른 결과를 출력하기 위한 경량 인공지능 모델이고, 제3 인 공지능 모델은 정확한 결과를 도출하기 위한 인공지능 모델일 수 있다. 즉, 위 내시경 검사를 실시간으로 보조 하기 위하여 빠른 결과를 도출할 수 있는 제1 인공지능 모델 및 제2 인공지능 모델이 이용될 수 있으며, 의사의 영상 판독 명령이 있는 경우, 정밀 분석을 위해 오랜 시간이 걸리는 대신 정밀한 결과를 도출할 수 있는 제3 인 공지능 모델을 이용할 수 있다. 이후, 복수의 이미지 중, 병변이 포함된 것으로 판단된 경우, 서버는, 실시간 영상 중, 병변이 포함되었는 지 여부를 판단할 수 있다. 병변이 포함된 경우, 서버는, 실시간 영상 내에 병변의 위치를 안내하기 위한 UI를 표시할 수 있다. 단계 S140에서, 서버가, 위 내시경 영상 중 병변이 판단된 경우, 병변을 포함하는 이미지를 획득하여, 서 버의 데이터베이스로 전송할 수 있다. 일 실시예로, 데이터베이스에 저장된 병변을 포함하는 이미지는, 후술하는 바와 같이, 제2 아이콘을 통해 표시 되는 제2 UI에서 확인할 수 있다. 단계 S150에서, 서버가, 이미지를 제2 인공지능 모델에 입력하여, 이미지에 포함된 병변의 종류를 판단할 수 있다. 일 실시예로, 제2 인공지능 모델은 YOLO_v3 및 EfficientNet를 응용한 Detection 알고리즘이 적용될 수 있다. 제2 인공지능 모델은 병변을 인식하고, 병변이 포함된 이미지에서 환자 텍스트와 빛반사를 제거한 후, 병변 종 류를 판독해 그 결과를 검사 도중 실시간으로 디스플에이 장치에 표시할 수 있다. 일 실시예로, 서버는, 조직검사로 인해 출혈이 발생하였는지 여부를 판단할 수 있다. 구체적으로, 서버는 출혈을 감지하기 위한 제4 인공지능 모델을 포함할 수 있다. 서버는 제1 인공지 능 모델 및 제2 인공지능 모델에 영상 이미지를 입력하기 전 단계에서, 영상 이미지를 제4 인공지능 모델에 입 력할 수 있다. 출혈 발생이 판단된 경우, 서버는, 출혈이 발생한 위치에 대한 병변 판단을 수행하지 않을 수 있다. 즉, 제4 인공지능 모델을 통해 입력된 영상 이미지가 출혈이 발생한 것으로 판단된 경우, 서버는 해당 영 상 이미지를 제1 인공지능 모델 및 제2 인공지능 모델에 입력하지 않고, 제4 인공지능 모델을 통해 입력된 영상 이미지가 출혈이 발생하지 않은 것으로 판단된 경우에만, 해당 영상 이미지를 제1 인공지능 모델 및 제2 인공지 능 모델에 입력하여 병변 판단을 수행할 수 있다. 단계 S160에서, 서버가, 위 내시경 영상 중 병변이 판단된 경우, 위 내시경 영상 내에서, 병변의 위치를 안내하기 위한 UI를 표시할 수 있다. 이때, 병변의 위치를 안내하기 위한 UI는 디스플레이 장치에 의해 표 시될 수 있다. 구체적으로, 도 4 및 도 5에 도시된 바와 같이, 환자 정보 입력을 위한 제1 아이콘, 판단된 병변을 포함하 는 이미지를 확인하기 위한 제2 아이콘, 검사결과 이미지를 확인하기 위한 제3 아이콘, 설정값 변경 을 위한 제4 아이콘 및 실시간 영상으로 복귀하기 위한 제5 아이콘을 표시할 수 있다. 제1 아이콘은 환자 정보를 입력하기 위한 아이콘이다. 도 4에 도시된 바와 같이, 제1 아이콘에 대한 사용자 명령이 입력되면, 디스플레이 장치는, 환자명, 환자 차트 번호, 성별 및 출생연도 입력을 위한 제1 UI를 표시할 수 있다. 환자 정보는 내시경 검사가 진행되는 중에도 수정할 수 있다. 나아가, 제1 UI가 디스플레이 장치에 표시되 는 경우, 제1 아이콘은 다른 아이콘과 다른 색상으로 하이라이트 표시될 수 있으며, 제1 아이콘을 통한 사용자명령이 입력되지 않을 수 있다. 한편, 제1 UI에 포함된 복수의 입력창 중, 일부만 입력될 수 있다. 즉, 복수의 입력창 모두에 대한 정보가 입력 되지 않더라도, 위 내시경을 수행할 수 있다. 이때, 출생년도는 \"1988' 또는 \"88\"과 같이 숫자로만 입력될 수 있으며, 출생년도는 현재 시점 이전의 년도만 입력할 수 있다. 다양한 실시예에 따라, 출생년도는 현재 시점에서 기 설정된 범위 이전의 년도만 입력할 수 있 음은 물론이다. 한편, 출생년도는 현재 시점을 기준으로, 기 설정된 범위 내에서만 입력될 수 있다. 예를 들어, 현재 시점이 2020년인 경우, 기 설정된 년도(예를 들어 200년)을 기준으로 1820년 이전의 년도는 입력할 수 없다. 범위를 벗 어나는 출생년도가 입력되는 경우, 디스플레이 장치는 \"출생년도를 확인해 주세요\"와 같은 경고 메시지를 출력할 수 있다. 한편, 내시경 검사가 진행중이거나, 진행이 완료되었으나, 환자 정보가 불충분하게 입력된 경우, 서버는, 징행된 내시경 검사에 대한 인덱싱을 수행할 수 있다. 이때, 환자 정보가 불충분하게 입력된 경우란, 다른 내시 경 결과와 구분할 수 없는 경우를 의미할 수 있다. 예를 들어, 환자명 또는 출생정보만 입력되었으나, 동일한 환자명 또는 출생 정보을 가진 환자의 내시경이 진행되었거나 진행될 예정인 경우, 서버는 동일한 환자 데 이터를 구분하기 위해 인덱싱을 수행할 수 있다. 예를 들어, 서버는 환자 정보가 불충분한 경우, 임의의 차트 번호를 생성하여 환자 정보에 추가할 수 있다. 서버에 의해 생성된 임의의 차트 번호는 정상적으로 기록된 차트 번호화 다른 형식을 가지거나 다른 색상으로 표시될 수 있다. 일 실시예로, 제1 UI에 표시된 완료 아이콘 또는 취소 아이콘을 통한 사용자 명령이 입력되면, 디스플레이 장치 는 실시간 영상을 표시하는 제5 UI를 표시할 수 있다. 제2 아이콘은 서버의 데이터베이스에 저장된 이미지를 확인하기 위한 아이콘이다. 제2 아이콘에 대한 사용자 명령이 입력되면, 디스플레이 장치는, 병변을 포함하는 이미지 리스트를 안내하 기 위한 제2 UI를 표시할 수 있다. 일 실시예로, 제2 아이콘은 이미지 리스트의 개수를 함께 표시할 수 있으며, 이미지 리스트가 기 설정된 개수 (예를 들어 99개)를 초과하는 경우, 기 설정된 개수(예를 들어, 99개)만을 제2 아이콘에 함께 표시할 수 있다. 제3 아이콘은 병변별 판단 결과를 표시하기 위한 아이콘이다. 제3 아이콘에 대한 사용자 명령이 입력되면, 디스플레이 장치는, 도 6에 도시된 바와 같이, 병변별 판단결 과를 나타내는 리스트를 안내하기 위한 제3 UI를 표시할 수 있다. 제4 아이콘은, 설정값 변경을 위한 아이콘이다. 제4 아이콘을 통한 사용자 명령이 입력되면, 설정값 변경을 위한 제4 UI를 표시할 수 있다. 제5 아이콘은, 실시간 영상으로 복귀하기 위한 아이콘이다. 제5 아이콘을 통한 사용자 명령이 입력되면, 디스플레이 장치는, 실시간 영상을 표시하기 위한 제5 UI를 표시할 수 있다. 일 실시예로, 제5 UI를 표시하는 동안, 디스플레이 장치는, 제1 아이콘, 제2 아이콘, 제3 아이콘 및 제4 아이콘 중 하나의 아이콘에 대한 제1 사용자 명령이 입력되면, 제1 사용자 명령에 대응되는 UI를 제1 레이어에 표시할 수 있다. 다만, 이 경우에도 서버 및 디스플레이 장치는 영상 화면을 실시간으로 감지할 수 있다. 이를 위해 제1 UI 내지 제4 UI는 제5 UI와 다른 레이어에서 구현될 수 있다. 한편, 도 5에 도시된 바와 같이, 디스플레이 장치는, 제 5 UI가 표시되는 동안, 제6 아이콘, 제7아이 콘, 제8 아이콘, 제9 아이콘 및 제10 아이콘를 표시할 수 있다. 제6 아이콘은, 서버에서 병변에 대한 분석이 진행중인 경우 생성될 수 있다. 시술자는 제6 아이콘 이 제5 UI에 표시되면, 의심 부위가 존재하여 서버가 해당 부위를 판독중이라고 판단할 수 있다. 제7 아이콘은 서버가 이미지 중 병변을 획득한 경우, 해당 병변의 위치 및 상태를 표시하기 위한 아 이콘이다. 제7아이콘은 병변의 크기에 대응되게 생성될 수 있으며, 나아가, 병변의 상태에 따라 다른 색으로 표시될 수 있다. 예를 들어, 정상인 경우, 초록색으로, LGD의 경우 노란색으로, HGD인 경우 진한 노란색으로, EGC 인 경우 주황색으로, AGC인 경우 빨간색으로 표시될 수 있다. 제8 아이콘은 상술한 바와 같이, 이미지 리스트의 개수 표시와 관련될 수 있다. 제9 아이콘은 제1 UI를 통해 획득된 환자 정보를 표시하기 위한 구성이다. 이때, 환자 정보는 이름, 성별, 나이, 차트 정보를 포함할 수 있으며, 환자 정보가 미입력 된 경우, \"―\"와 같이 표시될 수 있다. 제10 아이콘은 내시경 진행동안 판단된 병변의 개수를 표시하기 위한 구성이다. 의심 병변을 포함하는 이 미지의 개수가 추가되는 경우, 제10 아이콘에 표시된 숫자의 개수가 변경될 수 있다. 이때, 제5 UI가 표시되는 동안에는, 제5 아이콘이 표시되지 않을 수 있다. 한편, 본 발명의 다양한 실시예에 따라, 서버는, 판단된 병변이 실시간 시술이 필요한 병변인지 여부를 판 단할 수 있다. 구체적으로, 위 내시경을 진행하는 경우, 병변의 판단과 함께 시술이 진행되어야 할 필요성이 존재한다. 따라서, 서버는 병변의 종류를 판단할 때, 판단된 병변이 시술 가능한 병변인지 여부를 함께 판단할 수 있 다. 이후, 판단된 병변이 실시간 시술이 필요한 병변인 경우, 서버는, 내시경 장치로부터 위 내시경 장치 를 수신한 시간과, 위 내시경 영상에 포함된 병변을 판단한 시간과의 차이값을 산출할 수 있다. 차이값이 기 설정된 값 이상인 경우, 디스플레이 장치는, 제5 UI에 시술이 필요한 병변에 대한 정보 및 상 기 차이값을 표시할 수 있다. 즉, 인공지능 모델이 위 내시경 영상의 이미지가 병변인지 판단하는 동안, 시술자는 이미 확인한 부위를 지나칠 수 있으므로, 서버는 위 내시경 장치를 수신한 시간과, 위 내시경 영상에 포함된 병변을 판단한 시간과의 차이값을 계산하여 시술자에게 알림으로써, 위 내시경 도중 실시간으로 병변에 대한 시술을 진행할 수 있다. 한편, 본 발명의 다양한 실시예에 따라, 제1 인공지능 모델에 내시경 영상이 입력된 경우, 영상이 서버가, 영상이 위 내시경 영상인지 여부를 판단할 수 있다. 이후, 서버는, 영상이 위 내시경 영상이 아닌 경우, 새로운 환자 정보를 입력하기 위한 UI를 표시할 수 있 다. 또는, 서버는, 영상이 위 내시경 영상이 아닌 경우, 이전 위 내시경 영상이 완료되고, 새로운 환자에 대한 위 내시경이 시작된 것으로 판단하고, 이전에 촬영한 위 내시경 영상과 구분하여 표시할 수 있다. 상술한 방법을 통해, 서버는 환자 정보가 입력되지 않은 경우라고 하더라도, 환자에 따라 위 내시경 영상 을 분류할 수 있다. 구체적으로, 서버는 위 내시경 영상 중 식도 부분이 위치한 이미지 및 환자 입안의 혀 이미지를 추출하여 위장이 아닌 부분에 대한 하나의 클래스를 획득할 수 있다. 나아가, 서버는 위장 내부를 촬영한 이미지를 또 다른 클래스로 획득할 수 있다. 서버는 획득된 두개의 클래스 각각을 2단계 구분 인공지능 알고리즘으 로 학습시킬 수 있다. 일 실시예로, 서버가 이미지에 대한 판독 요청을 수신한 경우라도, 상술한 2단계 구분 인공지능 알고리즘 에 의한 판독 결과 판독 요청 이미지가 위장이 아닌 부분이라고 판단된 경우, 병변 판단 과정을 수행하지 않을 수 있다. 또 다른 실시예로, 서버는, 내시경 영상이 촬영되는 내시경실의 평균 명암에 대응되는 데이터를 획득하고, 획득된 데이터를 바탕으로, 내시경 장치가 인체 밖에 위치하는지 판단할 수 있다. 구체적으로, 서버 는, 내시경 장치가 획득하는 이미지의 조도, 채도 및 명암 정보를 바탕으로 촬영된 이미지가 인체 밖인지 여부를 판단할 수 있다. 구체적으로, 서버는, 내시경실 환경의 평균 명암 값을 획득하고, 획득된 평균 명 암값과 내시경 장치를 통해 획득되는 이미지의 명암값을 비교하여, 촬영된 이미지가 인체 밖에서 촬영된 것인지 여부를 판단할 수 있다. 예를 들어, 서버는, 내시경 장치를 통해 획득된 이미지가 특정 밝기 범위에 포함되면, 해당 이미지를 인체 밖 이미지로 판단하여 인공지능 알고리즘 시스템을 오프할 수 있다. 상술한 본 발명의 다양한 실시예에 따라, 서버는 환자명이 입력되지 않더라도, 한 명의 내시경 검사가 종 료된 후 다시 다른 환자의 내시경 검사가 시작될 경우, 환자를 자동으로 구별하여 인식하고 판독소견을 저장 장치에 저장할 수 있다. 나아가, 서버는, 위와 연결되어 있는 식도와 입, 인체의 바깥부위를 내시경 영상에서 자동으로 인식하고 구별하여, 해당 부위에 대한 인공지능 판독을 수행하지 않음으로써, 서버의 리소스를 위 병변의 발견과 판 단에만 집중할 수 있다. 한편, 본 발명의 또 다른 실시예에 따라, 서버는, 내시경 영상을 복수의 프레임으로 분할할 수 있다. 이후, 서버는, 복수의 프레임 중, 기 설정된 수 이상의 연속된 프레임에 병변이 판단되면, 연속된 프레임 에 대응되는 병변을 동일 병변으로 판단할 수 있다. 구체적으로, 서버는, 위 내시경 영상이 포함하는 복수의 이미지 프레임에서 동일한 부위에 대한 병변 판독 이 수행된 경우, 해당 병변을 동일 병변으로 판단할 수 있다. 서버는 동일 병변에 대응되는 이미지 프레임 에 대하여 가장 높은 빈도수로 검출되는 병변 클래스(예를 들어 LGD)를 판단된 병변으로 획득할 수 있다. 한편, 본 발명의 또 다른 실시예에 따라, 서버는 내시경 검사 도중 조직검사로 인한 출혈이 발생하였는지 여부를 판단할 수 있다. 서버는 출혈이 발생한 경우, 이를 병변으로 판단하지 않을 수 있다. 구체적으로, 서버는 출혈이 발생한 복수의 이미지를 학습데이터로 학습시켜, 위 병변에 대한 이미지와 구별할 수 있다. 또 다른 실시예로, 서버는 위 내시경 검사도중 보이는 병변 이외의 다양한 영상내 noise를 검출하고, 제거 할 수 있다. 예를 들어, 서버는, 위 내시경 화면에서 환자 텍스트가 검출된 경우, 검출된 환자 텍스트를 제거할 수 있다. 또 다른 예로, 서버는 내시경기구에서 분출되는 공기와 위내 액체가 만나서 발생하는 화 면의 빛 반사가 검출된 경우, 해당 빛 반사를 보정하여 인식하지 않을 수 있다. 도 다른 예로, 서버는, 위 내시경 장치와 별도로 구성된 조직검사 기구에 대한 데이터를 미리 저장하여, 조직검사 기구가 촬영된 경 우, 해당 이미지를 병변 판단에서 제외할 수 있다. 또 다른 예로, 서버는, 내시경 장치에 의해 촬영 된 이미지에 대한 색보정을 수행할 수 있다. 예를 들어, 서버는 분할 인공지능 알고리즘을 활용해, 환자 텍스트를 모두 인식해 제거함으로써, 오직 입 력 영상만 판독하거나, 내시경 장치에서 나오는 빛 반사는 해당 이미지의 평균 명암 값을 데이터화 함으로 써 구분하고, 특정 명암 값 이상이나 이하이면 해당 이미지는 판독을 요청해도 판독되지 않도록 할 수 있다. 나 아가, 조직검사 기구와 같은 외부 기구가 촬영되면, YOLO_v3를 변형한 탐지 알고리즘으로 외부 기구를 인식하고, 해당 이미지는 판독을 요청해도 판독되지 않도록 제어할 수 있다. 한편, 도 5에 도시된 바와 같이, 서버는 위 내시경 검사 도중 시술자가 인공지능 기기 화면을 보지 않거나 탐지된 병변을 놓치는 것을 방지하기 위해 한 번 서버 가 발견한 병변이 다시 영상에 나타나면, 제7 아이 콘을 디스플레이 장치에 표시하여 시술자의 주의를 환기시킬 수 있다. 나아가, 서버는 병변이 발견되면 컴퓨터 알림음을 동시에 발생시키며 디스플레이 장치의 UI에 병변별로 지정된 색을 포함하는 아 이콘을 표시할 수 있다. 구체적으로, 서버는 프레임간의 RGB 일치도가 특정값 이상이나 특정값 이하일 때, 현 프레임에서 병변이 탐지되지 않더라도 이전 프레임의 병변 위치를 그대로 유지할 수 있다. 이때, 병변의 위치는 제7 아이콘과 같이 직사각형으로 실시간으로 표시될 수 있다. 한편, 병변이 탐지되지 않으면 제7 아이콘이 제거될 수 있 다. 한편, 본 발명에 따른 인공지능 모델 중, 진행성위암(advanced gastric cancer), 조기위암(early gastric cancer), 선종(dysplasia), 정상병변(normal category)로 4단 분류하는 Max Overall Accuracy는 89.67%이고 이 때 민감도(sensitivity)는 98.62%, 특이도(specificity)는 85.28% 로 나타났으며, 진행성위암(advanced gastric cancer), 조기위암(early gastric cancer), 고등급선종(high grade dysplasia), 저등급선종(low grade dysplasia), 정상병변(normal category)로 5단 분류하는 Max Overall Accuracy는 77%이고 이때 민감도 (sensitivity)는 85.56%, 특이도(specificity)는 94.17% 로 나타났으며, 병변이 점막에 국한되어 있는지 (mucosa-confined lesion) 또는 점막하 침윤이 있는지 (submucosa-invaded lesion) 2단 분류하는 Max Overall Accuracy는 89.9%이고 이때 민감도(sensitivity)는 93.13%, 특이도(specificity)는89.08% 로 나타났다. 도 8은 일 실시 예에 따른 장치의 구성도이다. 프로세서는 하나 이상의 코어(core, 미도시) 및 그래픽 처리부(미도시) 및/또는 다른 구성 요소와 신호를 송수신하는 연결 통로(예를 들어, 버스(bus) 등)를 포함할 수 있다.일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 도 7과 관련 하여 설명된 방법을 수행한다. 예를 들어, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써 신규 학습용 데이터를 획 득하고, 학습된 모델을 이용하여, 상기 획득된 신규 학습용 데이터에 대한 테스트를 수행하고, 상기 테스트 결 과, 라벨링된 정보가 소정의 제1 기준값 이상의 정확도로 획득되는 제1 학습용 데이터를 추출하고, 상기 추출된 제1 학습용 데이터를 상기 신규 학습용 데이터로부터 삭제하고, 상기 추출된 학습용 데이터가 삭제된 상기 신규 학습용 데이터를 이용하여 상기 학습된 모델을 다시 학습시킬 수 있다. 한편, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저 장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리에는 프로세서의 처리 및 제어를 위한 프로그램들(하나 이상의 인스트럭션들)을 저장할 수 있 다. 메모리에 저장된 프로그램들은 기능에 따라 복수 개의 모듈들로 구분될 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다."}
{"patent_id": "10-2021-0003315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2021-0003315", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 시스템도이다. 도 2 및 도 3은 본 발명의 일 실시예에 따른 인공지능 모델의 전처리 방법을 설명하기 위한 예시도이다. 도 4 내지 도 6은 본 발명의 일 실시예에 따른 UI 화면 표시 방법을 설명하기 위한 예시도이다. 도 7은 본 발명의 일 실시예에 따른 흐름도이다. 도 8은 본 발명의 일 실시예에 따른 장치의 구성도이다."}
