{"patent_id": "10-2022-0122866", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0169822", "출원번호": "10-2022-0122866", "발명의 명칭": "부호화 이미지로부터 특징점을 획득하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "구본곤"}}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "광을 출력하는 광원(141);소정의 패턴이 형성되어 투과되는 광의 경로가 변경되는 패턴 마스크(1421);상기 광원(141)에서 출력되고 안구에 의해 반사된 광이 상기 패턴 마스크(1421)를 투과한 광을 수광하는 이미지센서(1422); 및적어도 하나의 프로세서(150);를 포함하고,상기 적어도 하나의 프로세서(150)는,상기 패턴 마스크(1421)를 투과하여 상기 이미지 센서(1422)를 통해 수광된 광을 이용하여, 위상 변조된 부호화이미지(coded image)(20)를 획득하고,상기 부호화 이미지로부터 상기 안구에 관한 특징점(30)을 획득하고,상기 특징점(30)에 기초하여 사용자의 시선 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 특징점(30)은 상기 안구의 위치 좌표 및 형태 중 적어도 하나에 대한 정보를 포함하는, 전자 장치(100)."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 특징점(30)은 동공의 특징점(pupil feature point)(32) 및 눈의 반짝임 특징점(glint feature point)(31)중 적어도 하나를 포함하는, 전자 장치(100)."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(150)는,상기 부호화 이미지(20)로부터 상기 안구에 관한 원본 이미지(400)를 복원하고,상기 원본 이미지(400)에 기초하여 상기 사용자의 인증 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 적어도 하나의 프로세서(150)는,상기 원본 이미지(400)에 기초하여 상기 사용자의 홍채 정보를 식별하고(S1410),공개특허 10-2023-0169822-3-상기 식별된 홍채 정보를 사용하여 상기 인증 정보를 획득하는(S1420), 전자 장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항 내지 제5항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(150)는,상기 사용자의 상황에 기초하여 프로세스 결정 정보를 획득하고,상기 프로세스 결정 정보에 기초하여, 상기 사용자의 시선 정보 또는 인증 정보를 선택적으로 획득하는, 전자장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 하나의 항에 있어서,상기 이미지 센서(1422)는 광을 수광함으로써 깊이 정보를 획득하는 TOF(Time of Flight) 센서를 포함하고,상기 적어도 하나의 프로세서(150)는,상기 패턴 마스크(1421)를 투과하여 상기 TOF 센서를 통해 수광된 광을 이용하여, 상기 부호화 이미지(20)를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 TOF 센서를 통해 수광된 광을 이용하여 획득된 부호화 이미지(20)는, 상기 객체에 대응되는 깊이 정보를포함하되, 상기 패턴 마스크(1421)에 의해 변조된 이미지인 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제6항 중 어느 하나의 항에 있어서, 상기 이미지 센서(1422)는 깊이 정보를 획득하는 TOF(Time of Flight) 센서 및 대상에 관한 이미지를 획득하는광센서를 포함하고,상기 적어도 하나의 프로세서(150)는,상기 패턴 마스크(1421)를 투과하여 상기 TOF 센서를 통해 수광된 광에 기초하여 제1 부호화 이미지를획득하고,상기 패턴 마스크(1421)를 투과하여 광센서에 의해 수광된 광에 기초하여, 제2 부호화 이미지를 획득하고,상기 제1 부호화 이미지 및 상기 제2 부호화 이미지 중 적어도 하나를 이용하여, 상기 특징점을 획득하는, 전자장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(150)는,상기 부호화 이미지(20)로부터 상기 안구에 관한 특징점(30)만(only)을 획득하는 것을 특징으로 하는, 전자 장치.공개특허 10-2023-0169822-4-청구항 11 제1항 내지 제10항 중 어느 하나의 항에 있어서,소정의 패턴에 의해 위상 변조된 이미지로부터 특징점을 추출하도록 학습된(trained) 인공지능 모델(180)을 더포함하고,상기 적어도 하나의 프로세서(150)는,상기 학습된 인공지능 모델(180)을 이용하여, 상기 부호화 이미지(20)로부터 상기 특징점(30)을 획득하는 것을특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "패턴 마스크(1421)를 투과하여 이미지 센서(1422)를 통해 수광된 광을 이용하여, 위상 변조된 부호화 이미지(coded image)(20)를 획득하는 단계;상기 부호화 이미지로부터 안구에 관한 특징점(30)을 획득하는 단계; 및상기 특징점(30)에 기초하여 사용자의 시선 정보를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 특징점(30)은 상기 안구의 위치 좌표 및 형태 중 적어도 하나에 대한 정보를 포함하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 특징점(30)은 동공의 특징점(pupil feature point)(32) 및 눈의 반짝임 특징점(glint feature point)(31)중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항 내지 제14항 중 어느 하나의 항에 있어서,상기 부호화 이미지(20)로부터 상기 안구에 관한 원본 이미지(400)를 복원하는 단계; 및상기 원본 이미지(400)에 기초하여 상기 사용자의 인증 정보를 획득하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 사용자의 인증 정보를 획득하는 단계는,상기 원본 이미지(400)에 기초하여 상기 사용자의 홍채 정보를 식별하는 단계; 및상기 식별된 홍채 정보를 사용하여 상기 인증 정보를 획득하는 단계를 포함하는, 방법.공개특허 10-2023-0169822-5-청구항 17 제15항 내지 제16항 중 어느 하나의 항에 있어서,상기 사용자의 시선 정보를 획득하는 단계와 상기 사용자의 인증 정보를 획득하는 단계는,상기 사용자의 상황에 기초하여 프로세스 결정 정보를 획득하는 단계; 및상기 프로세스 결정 정보에 기초하여, 상기 사용자의 시선 정보 또는 인증 정보를 선택적으로 획득하는 단계를포함하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항 내지 제17항 중 어느 하나의 항에 있어서,상기 이미지 센서(1422)는 광을 수광함으로써 깊이 정보를 획득하는 TOF(Time of Flight) 센서를 포함하고,상기 부호화 이미지(20)를 획득하는 단계는,상기 패턴 마스크(1421)를 투과하여 상기 TOF 센서를 통해 수광된 광을 이용하여, 상기 부호화 이미지(20)를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 TOF 센서를 통해 수광된 광을 이용하여 획득된 부호화 이미지(20)는, 상기 객체에 대응되는 깊이 정보를포함하되, 상기 패턴 마스크(1421)에 의해 변조된 이미지인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항 내지 제17항 중 어느 하나의 항에 있어서,상기 이미지 센서(1422)는 깊이 정보를 획득하는 TOF(Time of Flight) 센서 및 대상에 관한 이미지를 획득하는광센서를 포함하고,상기 부호화 이미지(20)를 획득하는 단계는,상기 패턴 마스크(1421)를 투과하여 상기 TOF 센서를 통해 수광된 광게 기초하여 제1 부호화 이미지를 획득하는단계; 및상기 패턴 마스크(1421)를 투과하여 광센서를 통해 수광된 광에 기초하여, 제2 부호화 이미지를 획득하는 단계를 포함하고,상기 특징점(30)을 획득하는 단계는,상기 제1 부호화 이미지 및 상기 제2 부호화 이미지 중 적어도 하나를 이용하여, 상기 특징점(30)을 획득하는단계를 포함하는, 방법."}
{"patent_id": "10-2022-0122866", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "부호화된 이미지(coded image)로부터 특징점을 획득하는 전자 장치 및 그 동작 방법을 제공한다. 본 개시의 일 실시 예에 따른 전자 장치는 이미지 센서를 통해 패턴 마스크를 투과한 광을 수광하여 위상 변조된 부호화 이미 지를 획득하고, 부호화 이미지로부터 안구에 관한 특징점을 획득할 수 있다. 전자 장치는 특징점에 기초하여 사 용자의 시선 정보를 획득할 수 있다."}
{"patent_id": "10-2022-0122866", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 부호화 이미지(coded image)로부터 특징점(feature point)을 획득하는 전자 장치 및 그 동작 방법에 관한 것이다. 구체적으로, 본 개시는 패턴 마스크를 투과함으로써 왜곡된 이미지로부터 특징점을 추출하고, 특 징점에 기초하여 시선을 추적하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0122866", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 증강 현실(augmented reality, AR) 또는 가상 현실(virtual reality, VR) 장치를 이용한 다양한 애플리케 이션에서는, 장치를 착용한 사용자의 시선 방향에 대한 정보가 요구되는 경우가 많다. 시선 방향 정보는 사 용자 인터페이스를 구축하거나, 사용자에게 제공되는 이미지의 렌더링(예를 들어, 포비티드 렌더링(foveated rendering))을 최적화하거나, 사용자가 바라보는 객체까지의 거리를 결정하는 등, 다양한 동작들에 이용될 수 있다. 시선 방향 정보는 사용자의 안구 추적 센서(eye-tracking sensor, ET sensor)에 의해 생성될 수 있다. 그러나 시선을 추적하기 위한 카메라 시스템은 부피가 큰 렌즈 어셈블리를 포함하는 경우가 많으며, 카메라 시 스템이 실장되는 증강 현실 장치를 성능 저하 없이 소형화하기 위한 노력이 이어지고 있다. 또한, 종래 카메라 시스템에서는, 렌즈를 포함하는 광학 시스템이 설계된 후, 보다 선명한 이미지를 출력할 수 있도록 이미지 처리 알고리즘 내 파라미터들이 조정될 수 있다."}
{"patent_id": "10-2022-0122866", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위하여 본 개시는 일 실시 예는 부호화 이미지(coded image)로부터 특징점을 획 득하는 전자 장치를 제공한다. 본 개시의 일 실시 예에 따른 전자 장치는 광원, 패턴 마스크, 이미지 센서 및 적어도 하나의 프로세서를 포함할 수 있다. 광원은 광을 출력할 수 있다. 패턴 마스크는 소정의 패턴이 형성되 어 투과되는 광의 경로가 변경될 수 있다. 이미지 센서는 광원에서 출력되고 안구에 의해 반사된 광이 패턴 마 스크를 투과한 광을 수광할 수 있다. 적어도 하나의 프로세서는 패턴 마스크를 투과하여 이미지 센서를 통해 수 광된 광을 이용하여, 위상 변조된 부호화 이미지(coded iamge)를 획득할 수 있다. 적어도 하나의 프로세서는 부 호화 이미지로부터 안구에 관한 특징점을 획득할 수 있다. 적어도 하나의 프로세서는 특징점에 기초하여 사용자 의 시선 정보를 획득할 수 있다. 본 개시의 일 실시 예에 따른 방법은 패턴 마스크를 투과하여 이미지 센서를 통해 수광된 광을 이용하여, 위상 변조된 부호화 이미지(coded iamge)를 획득하는 단계를 포함할 수 있다. 상기 방법은 부호화 이미지로부터 안구 에 관한 특징점을 획득하는 단계를 포함할 수 있다. 상기 방법은 특징점에 기초하여 사용자의 시선 정보를 획득 할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 본 개시의 다른 실시 예는 컴퓨터에서 실행시키기 위한 프로그램을 기 록한 컴퓨터로 읽을 수 있는 기록매체를 제공한다."}
{"patent_id": "10-2022-0122866", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도 록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시 스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수 행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 또한, 본 개시에서 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존 재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것 이다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치가 패턴 마스크를 이용하여 부호화 이미지(coded image)를 획득 하고, 획득된 부호화 이미지로부터 특징점을 추출하는 동작을 도시한 개념도이다.도 1을 참조하면, 전자 장치는 광원, 패턴 마스크 및 이미지 센서를 포함할 수 있다. 광원은 광을 출력할 수 있다. 광원은 예를 들어, 적외선을 출력하는 적외선 광원일 수 있다. 광원 은 750nm 내지 1mm에 걸친 영역의 파장을 갖는 적외선을 방출할 수 있는 광원일 수 있다. 단, 광원의 종류는 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 광원은 자외선 광원, 엑스 선 광원 및 감마선 광원 중 하나일 수도 있다. 일반적으로 광원은 LED(Light Emitting Diode : 발광 다이 오드)로 구성될 수 있으며, 하나의 LED 또는 복수의 LED를 포함하는 발광 장치로 구성될 수도 있다. 패턴 마스크는 소정의 패턴이 형성된 마스크일 수 있다. 패턴 마스크의 패턴에 따라 투과하는 광의 경로가 변경될 수 있다. 예를 들어, 패턴 마스크를 투과하는 광은 광원으로부터 출력된 광일 수 있 다. 패턴 마스크는 두께 차이를 형성하는 스크래치를 통해 형성된 패턴을 가질 수 있다. 즉, 예를 들어, 패턴 마스크가 플라스틱 재질을 포함하는 경우, 플라스틱 표면에 스크래치를 의도적으로 가함으로써 패턴이 형 성될 수 있다. 단, 패턴 마스크의 재질은 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 패 턴 마스크 상에 형성된 패턴에 관하여는 도 7 내지 도 9를 이용하여 구체적으로 설명한다. 이미지 센서는 패턴 마스크를 투과한 광을 수광함으로써, 부호화 이미지를 획득할 수 있다. 상 기 패턴 마스크를 투과하는 광은 광원으로부터 출력된 광이 객체에 의해 반사된 광일 수 있다. 도시 된 바와 같이, 패턴 마스크를 투과하는 광은 눈(E)으로부터 반사된 광일 수 있다. 눈(E)에 의해 반사된 광은 패턴 마스크에 도달하고, 패턴 마스크에 의해 광의 경로가 변경되어 위상이 변조될 수 있다. 위상 변조된 광은 이미지 센서에 의해 수광된다. 예를 들어, 이미지 센서는 행렬로 배열된 복수의 픽셀을 포함하는 어레이(Array) 형태로 집합된 2차원 형태의 센서일 수 있고, 복수의 픽셀 각각은 적어도 하나 의 광전 변환 소자를 포함할 수 있다. 이미지 센서는 광전 변환 소자를 이용하여 빛을 감지하고, 감지된 빛에 따른 전기적 신호인 이미지 신호를 출력할 수 있다. 전자 장치는 이미지 센서를 통해 수광된 광을 전기적 신호로 변환함으로써 부호화 이미지를 획득할 수 있다. 광원으로부터 출력된 광이 반사되는 객체는 눈을 포함하는 사용자의 얼굴 중 일부 영역으로 도시되었으나, 이는 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 출력된 광이 반사되는 객체는 사 물(예를 들어, 노트북, 선풍기, 우산 등)일 수 있고, 얼굴이 아닌 사용자의 다른 신체 일부(예를 들어, 손, 발, 무릎 등)일 수 있다. 전자 장치는 이미지 센서에 의해 수광된 광에 기초하여 부호화 이미지를 획득할 수 있다. 전자 장치 는 이미지 센서를 통해 패턴 마스크를 투과한 광을 수광하여, 위상 변조된 부호화 이미지를 획 득할 수 있다. 광원으로부터 출력된 광이 패턴 마스크를 투과함에 따라, 이미지 센서가 획득하는 데이터는 부호화된(coded) 이미지 데이터일 수 있다. 부호화 이미지는 대상 이미지 즉, 광원으로부터 출력 된 광이 반사되는 객체 및 패턴 마스크의 패턴 형태 중 적어도 하나에 따라 다를 수 있다. 일반적으로, 패턴 마스크에 의해 위상 변조된 부호화 이미지 내에 표현된 객체는 육안으로 식별하기 어려울 수 있 다. 대상 이미지는 소정의 객체를 포함할 수 있다. 도 1에서, 객체는 사용자의 눈(E)인 것으로 도시되었으나, 이는 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 객체는 노트북, 핸드폰, 커피 등 전자 장치가 인식하고자 하는 모든 객체를 의미할 수 있다. 전자 장치는 프로세서에 의해, 부호화 이미지로부터 특징점을 획득할 수 있다. 프로세서는 특징점을 획득하기 위한 인공지능 알고리즘 또는 인공지능 네트워크를 포함할 수 있다. 프로세서에 포 함된 인공지능 알고리즘은 변조된 이미지, 즉 부호화 이미지로부터 특징점을 추출하도록 학습된 (trained) 알고리즘일 수 있다. 프로세서는 이미지 센서에 의해 처리된 부호화 이미지를 획득할 수 있다. 프로세서는 부호 화 이미지로부터 객체에 대응되는 특징점을 획득할 수 있다. 여기서, 객체는 검출(detect)하고자 하는 객체를 의미할 수 있다. 예를 들어, 시선을 추적하고자 하는 경우, 객 체는 동공 및 눈의 반짝임(glint) 중 적어도 하나를 포함할 수 있다. 다른 예로, 특정 객체의 위치를 파악하고자 하는 경우, 객체는 위치 파악의 대상이 되는 노트북, 선풍기, 우산, 연필 등일 수 있다. 특징점의 출력 정보 형태는 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 특징점은 이미지 형태로 출력될 수 있다. 이 경우, 특징점의 데이터량은 이미지의 크기, 색 상의 수 및 글린트와 동공의 존재 여부에 기초하여 결정될 수 있다. 구체적인 예로, 특징점의 데이터량은 320*240*1*2 bits일 수 있다. 여기서, 이미지 형태의 특징점이 320*240의 해상도를 갖는 것으로 예를 들었을 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 또한, 이미 지 형태의 특징점은 단일 색상으로 표현될 수 있으므로, 특징점의 데이터량은 1이 곱해진 값일 수 있다. 또한, 이미지 형태의 특징점은 글린트가 포함된 영역인지, 동공이 포함된 영역인지 및 글린트와 동공 이 모두 포함되지 않은 영역인지를 표현하기 위해 2bit로 저장될 수 있다. 다른 예로, 특징점은 동공 이미지 및 글린트 좌표를 포함하는 데이터 형태로 출력될 수 있다. 이 경우, 특 징점의 데이터량은 동공 이미지의 크기, 동공 이미지의 색상의 수, 동공의 존재 여부 및 글린트의 개수에 기초하여 결정될 수 있다. 구체적인 예로, 특징점의 데이터량은 320*240*1*1 bits + N*2*8 bits일 수 있다. 동공 이미지의 데이터량은 320*240*1*1 bits이고, 글린트 좌표의 데이터량은 N*2*8 bits일 수 있다. 여기서, 동공 이미지의 크기가 320*240의 해상도를 갖는 것으로 예를 들었을 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 또한, 동공 이미지는 단일 색상으로 표현될 수 있으므로, 동공 이미지의 데이터량은 1이 곱해진 값일 수 있다. 동공 이미지 의 데이터량은 동공이 포함된 영역인지 여부를 표현하기 위해 1bit로 표현될 수 있다. 글린트 좌표의 데이터량 은 글린트 개수(N), 2개의 좌표값(즉, 2차원 좌표의 경우, x좌표 및 y좌표) 및 각 좌표를 표현하는 8bit의 곱으 로 계산될 수 있다. 다른 예로, 특징점은 동공 파라미터 및 글린트 좌표를 포함하는 데이터 형태로 출력될 수 있다. 이 경우, 특징점의 데이터량은 동공 파라미터의 개수 및 글린트의 개수에 기초하여 결정될 수 있다. 구체적인 예로, 특징점의 데이터량은 5*8 bits + N*2*8 bits일 수 있다. 동공 파라미터의 데이터량은 5*8 bits이고, 글린트 좌표의 데이터량은 N*2*8 bits일 수 있다. 여기서, 동공 파라미터는 타원 방정식에 따른 5개 의 파라미터 및 각 파라미터를 표현하는 8bit의 곱으로 계산될 수 있다. 동공 파라미터에 관하여 구체적인 설명 은 아래 수학식 1을 이용하여 후술한다. 글린트 좌표의 데이터량은 글린트 개수(N), 2개의 좌표값(즉, 2차원 좌 표의 경우, x좌표 및 y좌표) 및 각 좌표를 표현하는 8bit의 곱으로 계산될 수 있다. 특징점은 동공 특징점(pupil feature point) 및 눈의 반짝임 특징점(glint feature point) 중 적 어도 하나를 포함할 수 있다. 눈의 반짝임 특징점(glint feature point)은 점으로 표현가능한 데이터일 수 있다. 눈의 반짝임 특징점(3 1)은 눈의 반짝임(glint)의 위치 좌표값에 대한 데이터일 수 있다. 일 실시 예에서, 눈의 반짝임(glint)은, 광원으로부터 출력된 광이 눈에 반사된 후 이미지 센서에 의해 수광됨에 따라 검출되는 반사광을 의미할 수 있다. 눈의 반짝임 특징점(glint feature point)은 눈의 반짝임(glint)의 위치 좌표값에 대한 데이터를 포함할 수 있다. 눈의 반짝임 특징점은 눈의 검출된 영역 중 에서 소정 수치 이상의 밝기를 가지는 부분일 수 있다. 동공 특징점은 동공(pupil)의 모양에 대한 데이터일 수 있다. 구체적으로 설명하면, 동공은 타원형일 수 있다. 타원형의 동공의 모양은 수학식 1에 따라 설명 가능하다. [수학식 1]"}
{"patent_id": "10-2022-0122866", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, a 및 b는 타원의 장축 및 단축에 관련된 파라미터이다. a > b > 0인 경우, 장축의 길이는 2a이고, 단축 의 길이는 2b이다. b > a > 0인 경우, 장축의 길이는 2b이고, 단축의 길이는 2a이다. 여기서, x0 및 y0는 타원의 위치에 관련된 파라미터이다. 즉, (x0, y0)는 타원의 중심의 좌표이다. 동공의 모양에 대한 정보를 포함하기 위해, 동공 특징점은 a, b, x0 및 y0에 대응되는 수치값 즉, 동공 파라 미터를 포함할 수 있다. 추가적으로, 동공 특징점은 회전된 타원 모양을 표현하기 위해, 회전 각도에 대한 수치값(예를 들어, θ)을 포함할 수 있다. 따라서, 동공 특징점은 a, b, x0, y0 및 θ에 대응되는 수치값을 포함할 수 있다. 동공 특 징점은 a, b, x0, y0 및 θ에 대응되는 수치값을 통해 모든 형태의 타원에 대한 데이터를 표현할 수 있다. 즉, 본 개시의 일 실시 예에 따른 전자 장치는 위치 좌표값으로 표현 가능한 눈의 반짝임 특징점과 타원에 대한 데이터 즉, 상기 수학식 1에 따른 a, b, x0, y0 및 θ에 대응되는 수치값으로 표현 가능한 동공 특징점(3 2)을 출력할 수 있다. 출력된 특징점들은 최소한의 수치값으로 표현되므로 적은 데이터량을 가질 수 있다. 본 개시의 일 실시 예에 따른 전자 장치는 부호화 이미지로부터 데이터량이 적은 특징점만을 추출하므로, 연산 속도를 증가시킬 수 있는 장점이 있다. (기술적 효과를 제공한다) 일 실시 예에 따른 전자 장치는 획득된 특징점에 기초하여, 사용자의 시선을 추적할 수 있다. 전자 장치는 사용 자의 시선의 방향을 결정할 수 있다. 전자 장치는 특징점의 위치, 모양 등을 고려하여 사용자의 시선을 추적할 수 있다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 도 2를 참조하면, 단계 S210에서, 일 실시 예에 따른 전자 장치는 패턴 마스크를 투과하여 이미지 센서를 통해 수광된 광을 이용하여 위상 변조된 부호화 이미지를 획득할 수 있다. 전자 장치는 광원을 이용하여 광을 출력할 수 있다. 출력된 광은 객체로부터 반사되어 패턴 마스크를 투과할 수 있다. 출력된 광은 패턴 마스크를 투과함에 따라 변조될 수 있다. 전자 장치는 이미지 센서를 통해 패턴 마스크 를 투과한 광을 수광할 수 있다. 전자 장치는 수광된 광의 휘도 또는 세기에 관한 정보를 전기적 신호로 변환함 으로써 부호화 이미지를 획득할 수 있다. 본 개시에서, 이미지 센서에 의해 수광된 광은 광원으로부터 출력되고, 객체에 의해 반사되고, 패턴 마스크를 투과함에 따라 경로가 변경된 광을 의미할 수 있다. 단계 S220에서, 일 실시 예에 따른 전자 장치는 부호화 이미지로부터 안구에 관한 특징점을 획득할 수 있다. 전자 장치의 프로세서는 부호화 이미지로부터 특징점을 획득하기 위한 인공지능 알고리즘 또는 인공지능 네트워 크를 포함할 수 있다. 일 실시 예에서, 인공지능 알고리즘 또는 인공지능 네트워크는 특징점 추출 알고리즘을 포함하는 인공지능 모델일 수 있다. 전자 장치는 프로세서에 의해 부호화 이미지로부터 안구에 관한 특징점을 획득할 수 있다. 특징점을 획득하기 위해, 전자 장치의 프로세서는 특징점 추출 알고리즘을 포함하는 인공지능 모델을 이용할 수 있다. 특징점에 포 함된 출력 정보 형태는 본 개시의 기술적 사상을 한정하지 않으며, 예를 들어, 특징점은 동공 이미지 및 글린트 좌표를 포함하는 정보 형태로 출력될 수 있다. 단계 S230에서, 일 실시 예에 따른 전자 장치는 특징점에 기초하여 사용자의 시선 정보를 획득할 수 있다. 예를 들어, 인식 대상이 되는 객체가 사용자의 눈인 경우, 눈에 대한 특징점의 위치, 모양 및 배치에 기초하여 사용 자의 시선 정보를 획득할 수 있다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 설명의 편의상, 도 1 및 도 2를 이용하여 설명한 것과 중복되는 것은 간략히 하거나 생략한다. 전자 장치는 광원 및 광 검출부를 포함하는 카메라를 이용하여 현실 객체를 촬영함으로써 이미 지를 획득하는 디바이스일 수 있다. 전자 장치는 예를 들어, 모바일 디바이스, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 데스크 탑, 태블릿 PC, 웨어러블 디바이스, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 캠코 더 등과 같은 다양한 디바이스로 구현될 수 있다. 본 개시의 일 실시예에서, 전자 장치는 증강 현실 디바 이스일 수 있다. 증강 현실 디바이스는 '증강 현실(Augmented Reality)'을 표현할 수 있는 장치로서, 일반적으 로 사용자가 안면부(顔面部)에 착용하는 안경 형상의 증강 현실 안경 장치(Augmented Reality Glasses) 뿐만 아 니라, 두부(頭部)에 착용하는 헤드 마운트 디스플레이 장치 (HMD; Head Mounted Display Apparatus)나, 증강 현실 헬멧(Augmented Reality Helmet) 등을 포괄할 수 있다. 도 3을 참조하면, 전자 장치는 광원, 광 검출부, 프로세서, 및 메모리를 포함할 수 있다. 광 검출부는 패턴 마스크 및 이미지 센서를 포함할 수 있다. 패턴 마스크, 이미 지 센서, 프로세서, 및 메모리는 각각 전기적 및/또는 물리적으로 서로 연결될 수 있다. 도 3에 도시된 구성 요소는 본 개시의 일 실시예에 따른 것일 뿐, 전자 장치가 포함하고 있는 구성 요소가 도 3에 도시된 바와 같이 한정되는 것은 아니다. 전자 장치는 도 3에 도시된 구성 요소 중 일부를 포함하 지 않을 수 있고, 도 3에 도시되지 않은 구성 요소를 더 포함할 수도 있다. 예를 들어, 전자 장치는 광원 , 패턴 마스크, 이미지 센서, 프로세서, 및 메모리에 구동 전력을 공급하는 전력 공급부(예를 들어, 배터리)를 더 포함할 수 있다. 다른 예를 들어, 전자 장치는 촬영 대상체의 깊이 값 정보를 획득하는 저해상도 라이다 센서(low resolution Light Detection And Ranging sensor) 또는 TOF(Time of Flight) 센서를 더 포함할 수도 있다. 전 자 장치는 TOF 센서를 통해 광을 수광함으로써 부호화 이미지를 획득할 수 있고, 획득된 부호화 이미지에 기초하여 특징점을 획득할 수 있다. 즉, 광을 수광하는 이미지 센서의 종류는 본 개시의 기술적 사상을 한정하지 않는다. 광원은 광을 출력할 수 있다. 예를 들어, 광원은 객체를 향해 광을 조사할 수 있다. 광원에 의 해 출력된 광은 객체로부터 반사되고, 패턴 마스크를 투과할 수 있다. 본 발명의 시선 추적 센서나 TOF 센서는 적외선(IR : Infrared) 광원을 이용하는 것이 일반적이다. 시선 추적 센서를 이용하여 시선을 추적하기 위하여, 적외선 광원에서 출력된 적외선 대역의 광이 안구로부터 반사되고 패 턴 마스크를 투과할 수 있다. 안구로부터 반사되고 패턴 마스크를 투과한 광은 시선 추적 센서에 의해 수광될 수 있다. TOF 센서를 이용하여 깊이 정보를 획득하기 위하여, 적외선 광원에서 출력된 적외선 대역 의 광이 객체로부터 반사되고 패턴 마스크를 투과할 수 있다. 객체로부터 반사되고 패턴 마스크를 투과한 광은 TOF 센서에 의해 수광될 수 있다. 이 때, 시선 추적 센서 및 TOF 센서에 대응되는 광원은 별 도의 적외선 광원이 복수 개로 사용될 수 있다. 패턴 마스크는 소정의 패턴이 형성된 마스크일 수 있다. 패턴 마스크는 패턴에 따라 투과한 광의 경로가 변경될 수 있다. 패턴 마스크는 서로 다른 패턴을 가질 수 있고, 패턴을 구성하는 복수의 영역들 은 다양한 두께로 형성될 수 있다. 다양한 두께로 형성된 복수의 영역들을 포함하는 패턴 형태에 따라 패턴 마 스크를 투과하는 광의 투과량 및 경로가 달라지고, 광의 투과량 및 경로에 따라 원본 이미지는 왜곡될 수 있다. 패턴 마스크 상의 패턴에 관하여는 도 7 내지 도 9를 이용하여 구체적으로 설명한다. 이미지 센서는 패턴 마스크를 투과한 광을 수광하고, 수광된 광의 휘도 또는 세기를 전기적 신호로 변환하고, 전기적 신호를 이미지화 함으로써, 부호화 이미지(coded image)를 획득하도록 구성된 촬영 소자이다. 이미지 센서는 예를 들어, CCD(Charge Coupled Device) 또는 CMOS(Complementary Metal-Oxide Semiconductor)로 구현될 수 있으나, 이에 한정되는 것은 아니다. 프로세서는 메모리에 저장된 하나 이상의 명령어들(instruction) 또는 프로그램 코드를 실행하고, 명 령어들 또는 프로그램 코드에 대응되는 기능 및/또는 동작을 수행할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 프로세서(Graphic Processing Unit), 애플리케이션 프로세서(Application Processor, AP), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 도 3에는 프로세서가 하나의 엘리먼트로 도시되었으나, 이에 한정되는 것은 아니다. 일 실시예에서, 프로 세서는 하나 또는 하나 이상의 복수 개로 구성될 수 있다. 본 개시의 일 실시예에서, 프로세서는 인공 지능(Artificial Intelligence; AI) 학습을 수행하는 전용 하 드웨어 칩으로 구성될 수도 있다. 메모리에는 프로세서가 판독할 수 있는 명령어들 및 프로그램 코드(program code)가 저장될 수 있다. 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미 디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어, SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), Mask ROM, Flash ROM 등), 하드 디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 중 적어도 하나를 포함할 수 있다. 메모리에는 전자 장치의 기능 또는 동작들을 수행하기 위한 명령어들 또는 프로그램 코드가 저장될 수 있다. 본 개시의 일 실시예에서, 메모리에는 프로세서가 판독할 수 있는 명령어들, 알고리즘 (algorithm), 데이터 구조, 프로그램 코드(program code), 및 애플리케이션 프로그램(application program) 중 적어도 하나가 저장될 수 있다. 메모리에 저장되는 명령어들, 알고리즘, 데이터 구조, 및 프로그램 코드는 예를 들어, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 메모리에는 부호화 이미지로부터 특징점을 추출하기 위한 인공지능 모델에 관한 명령어들, 알고리즘, 데이 터 구조, 또는 프로그램 코드가 저장되어 있을 수 있다. 메모리에 포함되는 '모듈'은 프로세서에 의 해 수행되는 기능이나 동작을 처리하는 단위를 의미하고, 이는 명령어들, 알고리즘, 데이터 구조, 또는 프로그 램 코드와 같은 소프트웨어로 구현될 수 있다. 이하의 실시예에서, 프로세서는 메모리에 저장된 명령어들 또는 프로그램 코드들을 실행함으로써 구 현될 수 있다. 프로세서는 패턴 마스크를 투과하여 이미지 센서를 통해 수광된 광을 이용하여, 위상 변조된 부호화 이미지를 획득할 수 있다. 일 실시 예에서, 이미지 센서는 광을 수광함으로써 깊이 정보를 획득하는 TOF(Time of Flight) 센서를 포 함할 수 있다. 프로세서는 패턴 마스크를 투과하여 TOF 센서를 통해 수광된 광을 이용하여 부호화 이미지를 획득할 수 있다. TOF 센서를 통해 수광된 광을 이용하여 획득된 부호화 이미지는, 객체에 대응되는 깊 이 정보를 포함하되, 패턴 마스크에 의해 변조된 이미지인 것을 특징으로 할 수 있다. 일 실시 예에서, 이미지 센서는 대상에 관한 이미지를 획득하는 광센서를 포함할 수 있다. 프로세서(15 0)는 패턴 마스크를 투과하여 광센서에 의해 수광된 광에 기초하여, 부호화 이미지를 획득할 수 있다. 일 실시 예에서, 전자 장치는 TOF 센서 및 광센서를 포함할 수 있다. 프로세서는 TOF 센서를 통해 수 광된 광에 기초하여 제1 부호화 이미지를 획득할 수 있다. 프로세서는 광센서를 통해 수광된 광에 기초하 여 제2 부호화 이미지를 획득할 수 있다. 프로세서는 제1 부호화 이미지 및 제2 부호화 이미지 중 적어도 하나를 선택적으로 이용하여, 특징점을 획득할 수 있다. 프로세서는 복수 개로 구성될 수 있고, 예를 들어, 제1 프로세서 및 제2 프로세서를 포함할 수 있다. 일 실시 예에서, 제1 프로세서는 제1 부호화 이미지를 이용하여 특징점을 획득하고, 제2 프로세서는 제2 부호화 이 미지를 이용하여 특징점을 획득할 수도 있다. 이 때, 제1 부호화 이미지를 획득하기 위한 광원과 제2 부호화 이 미지를 획득하기 위한 광원으로서, 파장 대역이 다른 복수의 광원들이 이용될 수도 있다. 또한, 제1 부호화 이 미지를 획득하기 위한 광원과 제2 부호화 이미지를 획득하기 위한 광원으로서, 복수의 파장 대역의 광을 출력하 는 복수의 LED들을 포함하는 발광 장치로 구성된 광원이 이용될 수도 있다. 프로세서는 부호화 이미지로부터 안구에 관한 특징점을 획득할 수 있다. 프로세서는 소정의 패턴에 의해 위상 변조된 부호화 이미지로부터 특징점을 추출하도록 학습된 인공지능 알고리즘을 이용함으로써, 특징점을 획 득할 수 있다. 특징점은 안구의 위치 좌표 및 형태 중 적어도 하나에 대한 정보를 포함할 수 있다. 또는, 특징점은 동공의 특 징점(pupil feature point) 및 눈의 반짝임 특징점(glint feature point) 중 적어도 하나를 포함할 수 있다. 일 실시 예에서, 프로세서는 부호화 이미지로부터 안구에 관한 특징점만(only)을 획득할 수 있다. 즉, 프 로세서는 원본 이미지를 복원하지 않고 부호화 이미지로부터 바로 특징점을 획득할 수 있다. 프로세서는 특징점에 기초하여 사용자의 시선 정보를 획득할 수 있다. 즉, 프로세서는 동공의 형태, 글린트 좌표의 위치 등을 고려하여, 사용자의 시선 방향을 결정할 수 있다. 일 실시 예에서, 프로세서는 부호화 이미지로부터 안구에 관한 원본 이미지를 복원할 수 있다. 원본 이미 지는 패턴 마스크에 의해 광이 변조되기 이전의 광에 기초한 이미지를 의미할 수 있다. 프로세서는 부호화 이미지로부터 원본 이미지를 복원하도록 학습된 인공지능 알고리즘을 이용함으로써, 원본 이미지를 복원할 수 있다. 원본 이미지는, 적외선 광원에서 출력되고 안구에 의해 반사되고 패턴 마스크를 투과한 광을 수광함으로 써 획득된, 적외선 이미지일 수 있다. 프로세서는 원본 이미지에 기초하여 사용자의 인증 정보를 획득할 수 있다. 프로세서는 사용자의 인 증 정보에 기초하여 사용자 인증을 수행할 수 있다. 구체적으로, 프로세서는 원본 이미지에 기초하여 사용 자의 홍채 정보를 식별할 수 있다. 프로세서는 식별된 홍채 정보를 사용하여 인증 정보를 획득할 수 있다. 일 실시 예에서, 프로세서는 사용자의 상황에 관한 프로세스 결정 정보를 획득할 수 있다. 프로세서 는 프로세스 결정 정보에 기초하여, 사용자의 시선 정보 또는 인증 정보를 선택적으로 획득할 수 있다. 즉, 일 실시 예에 따른 전자 장치는 사용자의 상황을 고려하여, 사용자의 시선을 추적할지, 사용자에 대한 인증을 수행 할지 여부를 결정할 수 있고, 결정에 따라 동작을 수행할 수 있다. 본 개시에서 '부호화 이미지'는 패턴 마스크를 투과함에 따라 위상이 변조된 광을 이용하여 획득된 이미 지로서, 초점이 왜곡된 이미지일 수 있다. 패턴에 따라 왜곡된 원본 이미지, 즉, 부호화 이미지는 육안으로 인식하지 못할 수 있다. 일 실시 예에 따른 전자 장치의 프로세서는 원본 이미지로부터 특징점을 추출하도록 트레이닝된 인공지능 모델 을 이용할 수 있다. 본 개시의 일 실시예에서, 인공지능 모델은 기 획득된 복수의 원본 이미지를 입력 데이터로 적용하고, 복수의 원본 이미지 각각에 대응되는 복수의 특징점을 출력 정답값(ground truth)으로 적용하여 지도 학습(supervised learning) 방식에 의해 트레이닝된(trained) 심층 신경망 모델(deep neural network model)일 수 있다. '학습(training)'은 신경망에 대한 입력 데이터들을 분석하는 방법, 입력 데이터들을 분류하는 방법 및/또는 입력 데이터들에서 결과 데이터 생성에 필요한 특징을 추출하는 방법 등을 신경망이 스스로 발견 또는 터득할 수 있도록 훈련시키는 것을 의미할 수 있다. 구체적으로, 학습 과정을 통하여 심층 신경망 모델은 학습 데이터(예를 들어, 복수의 원본 이미지 및 복수의 특징점)를 학습(training)하여 신경망 내부의 가중치(weight) 값들을 최적화할 수 있다. 심층 신경망 모델은 최적화된 가중치 값을 가지는 신경망을 통하여, 입력 데이터를 처리함으로써, 목적하는 결과를 출력한다. 인공지능 모델의 종류는 본 개시의 기술적 사상을 한정하지 않으며, 인공지능 모델은 컨볼루션 신경망 모델 (Convolutional Neural Network, CNN), 재귀적 신경망 모델(Recurrent Neural Network, RNN), 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 중 어느 하나로 구현될 수 있다. 또한, 인공지능 모 델은 세분화될 수 있다. 예를 들어, 컨볼루션 신경망 모델은 D-CNN(Deep Convolution Neural Network) 또는 캡 스넷(Capsnet) 신경망(미도시) 등으로 세분화 될 수 있다. 프로세서는 기 학습된 인공지능 모델을 이용하여, 부호화 이미지로부터 특징점을 획득할 수 있다. 본 개시 의 일 실시예에서, 프로세서는 인공지능 모델에 이미지 센서를 통해 획득된 부호화 이미지를 입력하 고, 인공지능 모델을 이용한 추론을 수행함으로써 부호화 이미지에 대응되는 특징점(feature point)을 획득할 수 있다. 인공지능 모델은 전자 장치의 메모리에 저장될 수도 있다. 단 이는 예시일 뿐, 본 개시의 기술적 사 상을 한정하지 않는다. 예를 들어, 인공지능 모델은 외부 서버에 저장되어 있을 수 있다. 이 경우, 전자 장치 는 외부 서버와 데이터 통신을 수행할 수 있는 통신 인터페이스를 더 포함하고, 통신 인터페이스를 통해 외부 서버로부터 인공지능 모델 또는 인공지능 모델에 의한 추론 결과 데이터(예를 들어, 특징점)를 수신할 수 있다. 일반적으로, 전자 장치는 메모리 저장 용량, 연산의 처리 속도, 학습 데이터 셋의 수집 능력 등이 서버에 비하여 제한적일 수 있다. 따라서, 대용량 데이터의 저장 및 대용량의 연산량이 필요한 동작은 서버에서 수행한 후, 통신 네트워크를 통하여 필요한 데이터 및/또는 인공지능 모델을 전자 장치에 전송할 수 있다. 이 경우, 전자 장치는 대용량의 메모리 및 빠른 연산 능력을 갖는 프로세서 없이도, 서버를 통하여 인공지능 모델 또는 인공지능 모델에 의한 추론 데이터를 수신하여 이용함으로써, 빠르고 용이하게 필요한 동작을 수 행할 수 있다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 구조를 도시한 도면들이다. 도 4를 참조하면, 사용자는 전자 장치를 착용한 상태에서 현실 객체를 볼 수 있다. 전자 장치는 시선 추적 센서를 포함할 수 있다. 그러나, 도 4에는 전자 장치의 동작을 설명하기 위한 필수적인 구성만 이 도시되었을 뿐, 전자 장치가 포함하는 구성 요소가 도시된 바와 같이 한정되는 것은 아니다. 본 개시에서, 시선 추적 센서는 도 3에 도시된 광 검출부 즉, 패턴 마스크 및 이미지 센서 를 포함하는 구성 요소를 의미할 수 있다. 또한, 전자 장치는 사용자가 안면부(顔面部)에 착용하는 안경 형상의 증강 현실 안경 장치(Augmented Reality Glasses)로 도시되었을 뿐, 두부(頭部)에 착용하는 헤드 마운트 디스플레이 장치 (HMD; Head Mounted Display Apparatus)나, 증강 현실 헬멧(Augmented Reality Helmet) 등을 포괄할 수 있다. 본 개시의 일 실시예에서, 전자 장치는 시선 추적 센서를 이용하여 사용자의 눈에 의해 반사된 반사 광을 수광함으로써 특징점을 검출하고, 특징점에 기초하여 사용자의 시선 방향을 결정할 수 있다. 본 개시의 다 른 실시예에서, 전자 장치는 시선 추적 센서를 이용하여 사용자의 눈에 의해 반사된 반사광을 수광함 으로써 특징점을 검출하고, 특징점에 기초하여 사용자에 대한 인증을 수행할 수 있다. 도 5는 본 개시의 일 실시예에 따른 전자 장치의 광 검출부의 구조를 세부적으로 도시한 평면도이다. 참고적으 로, 도 5는 도 4의 R1 영역을 확대하여 시선 추적 센서의 내부를 설명하기 위한 확대도이다. 설명의 편의상, 도 1 내지 도 4를 이용하여 설명한 것과 중복되는 것은 간략히 하거나 생략한다. 도 5를 참조하면, 일 실시 예에 따른 시선 추적 센서(140; 140R로 도시되었으나 140L도 동일)는 광 검출부 즉, 패턴 마스크 및 이미지 센서를 포함할 수 있다. 일 실시 예에서, 광 검출부는 광원으로부터 출력되고 객체로부터 반사된 광(L)을 수광할 수 있다. 객 체로부터 반사된 광(L)은 패턴 마스크에 의해 투과될 수 있다. 객체로부터 반사된 광(L)은 패턴 마스크에 의해 투과됨에 따라 위상 변조될 수 있다. 위상 변조된 광(L)은 이미지 센서에 의해 수광될 수 있다. 이미지 센서에 의해 광을 수광함으로써, 전자 장치는 부호화 이미지를 획득할 수 있다. 전자 장치 는 부호화 이미지로부터 특징점을 획득할 수도 있고, 원본 이미지를 복원할 수도 있다. 또한, 렌즈의 다양한 조합을 이용하는 기존 시선 추적용 카메라 시스템은, 복수의 렌즈 두께로 인하여 소형화에 불리한 문제가 있었다. 본 개시의 일 실시 예에 따른 전자 장치를 이용한 시선 추적 센서는 렌즈를 얇은 패턴 마스크로 대체함에 따라, 소형화에 유리할 수 있다(소형 폼팩터를 구현할 수 있다). 예를 들어, 증강 현실 안경(AR Glass)의 안경테에 본 개시의 전자 장치를 이용한 카메라 모듈이 삽입될 수 있고, 카메라 모듈이 삽입됨에 따라 발생될 수 있는 안경테의 돌출부는 최소화될 수 있다. 도 6 및 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 패턴 마스크를 설명하기 위한 도면들이다. 도 8는 본 개시의 일 실시 예에 따른 전자 장치가 패턴 마스크를 이용하여 부호화 이미지를 획득하는 동작을 구체적으로 도시한 개념도이다. 일 실시 예에서, 도 8의 패턴 마스크는 도 7의 패턴 마스크(1421b)를 A-B에 따라 절단한 단면을 예시적으 로 도시한다. 도 6 및 도 7을 참조하면, 일 실시 예에 따른 패턴 마스크(1421a, 1421b)가 도시된다. 도시된 바와 같이, 패턴 마스크(1421a)는 예를 들어, 원형으로 형성된 패턴을 가질 수 있다. 패턴 마스크(1421a)는 일정한 형태가 규칙 적으로 반복되는 패턴을 가질 수 있다. 즉, 패턴 마스크(1421a)는 서로 다른 크기의 반지름을 갖는 원형 패턴이 반복되는 동심원 패턴을 가질 수 있다. 단, 도 6 및 도 7에 도시된 패턴 마스크의 패턴의 형태는 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 패턴 마스크(1421a)는 사각형으로 형성된 패턴을 가질 수 있다. 패턴 마스크(1421a)는 사각형 모양 이 반복되는 패턴을 가질 수 있다. 다른 예로, 도 7에 도시된 바와 같이, 패턴 마스크(1421b)는 불규칙적인 형 태의 패턴을 가질 수 있다. 도 8을 참조하면, 일 실시 예에서, 전자 장치는 패턴 마스크를 투과한 광을 이미지 센서를 통 해 수광하여, 위상 변조된 부호화 이미지를 획득할 수 있다. 광이 투과되는 패턴 마스크는 제1 두께(D1)의 제1 영역(A1) 및 제2 두께(D2)의 제2 영역(A2)을 포함할 수 있다. 패턴 마스크를 투과하는 광은 투과하는 영역의 두께에 따라 굴절하는 정도가 다를 수 있고, 이에 따라 전자 장치는 부호화 이미지를 획득할 수 있다. 구체적으로 설명하면, 광원은 제1 광(L1) 및 제2 광(L2)을 출력할 수 있다. 제1 광(L1) 및 제2 광(L2)은 객체를 향하여 조사될 수 있다. 객체는 사용자의 눈(E)으로 도시되었으나, 이는 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 객체는 노트북(도 9의 PC), 손(도 10의 H), 선풍기, 핸드폰 등일 수 있다. 먼저, 제1 광(L1)을 기준으로 설명하면, 제1 광(L1)은 객체, 즉 눈(E)에 도달할 수 있다. 객체에 도달된 제1 광 (L1)은 객체의 표면으로부터 반사될 수 있다. 객체의 표면으로부터 반사된 제1 반사광(RL1)은 패턴 마스크 를 향하여 진행할 수 있다. 제1 반사광(RL1)은 패턴 마스크를 투과할 수 있다. 제1 반사광(RL1)은 패턴 마스크의 제1 영역(A 1)을 투과할 수 있다. 제1 영역(A1)은 제1 두께(D1)를 가지는 패턴 마스크의 패턴 영역일 수 있다. 제1 반사광(RL1)은 제1 두께(D1)의 제1 영역(A1)을 투과함으로써, 굴절될 수 있다. 제1 두께(D1)는 후술할 제2 두께 (D2)보다 상대적으로 얇을 수 있다. 이에 따라, 제1 반사광(RL1)은 상대적으로 적게 굴절되어 이미지 센서 에 도달할 수 있다. 이미지 센서는 제1 영역(A1)을 투과한 제1 투과광(TL1)을 수광할 수 있다. 제2 광(L2)을 기준으로 설명하면, 제2 광(L2)은 객체에 도달할 수 있다. 객체에 도달된 제2 광(L2)은 객체의 표 면으로부터 반사될 수 있다. 객체의 표면으로부터 반사된 제2 반사광(RL2)은 패턴 마스크를 향하여 진행 할 수 있다. 제2 반사광(RL2)은 패턴 마스크를 투과할 수 있다. 제2 반사광(RL2)은 패턴 마스크의 제2 영역(A 2)을 투과할 수 있다. 제2 영역(A2)은 제2 두께(D2)를 가지는 패턴 마스크의 패턴 영역일 수 있다. 제2 반사광(RL2)은 제2 두께(D2)의 제2 영역(A2)을 투과함으로써, 굴절될 수 있다. 제2 두께(D2)는 제1 두께(D1)보 다 상대적으로 두꺼울 수 있다. 이에 따라, 제2 반사광(RL2)은 상대적으로 많이 굴절되어 이미지 센서에 도달할 수 있다. 이미지 센서는 제2 영역(A2)을 투과한 제2 투과광(TL2)을 수광할 수 있다. 이미지 센서는 광원으로부터 출력되어 패턴 마스크를 투과한 광을 수광함으로써, 위상 변조된 부호화 이미지를 획득할 수 있다. 패턴 마스크를 투과하는 광은 광원으로부터 출력되어 사용자 의 눈으로부터 반사되는 반사광을 포함할 수 있다. 이미지 센서는 제1 투과광(TL1) 및 제2 투과광(TL2)을 수광함으로써, 부호화 이미지를 획득할 수 있다. 제1 투과광(TL1) 및 제2 투과광(TL2)은 패턴 마스크(142 1)의 제1 영역(A1) 및 제2 영역(A2)을 각각 투과함에 따라 서로 굴절된 정도가 다르므로, 부호화 이미지는 육안으로 인식할 수 없는 객체에 대한 정보를 포함할 수 있다. 도 8에서, 패턴 마스크는 도 7의 패턴 마스크(1421b)에 기초하여 제1 두께(D1)를 갖는 제1 영역(A1) 및 제2 두께(D2)를 갖는 제2 영역(A2)이 불규칙적인 분포로 배치된 패턴의 형태를 가지는 것으로 도시되었으나, 패 턴 마스크의 패턴 형태는 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 패턴 마스크는 제1 영역(A1) 및 제2 영역(A2)이 규칙적으로 반복되는 단면의 패턴을 가질 수 있다. 다른 예로, 패턴 마스크는 제1 두께를 갖는 제1 영역, 제2 두께를 갖는 제2 영역 및 제3 두께를 갖는 제3 영역을 포 함하는 단면의 패턴을 가질 수도 있다. 도 9 및 도 10은 본 개시의 일 실시 예에 따른 전자 장치가 부호화 이미지로부터 추출한 다양한 유형의 특징점 을 통해 객체를 인식하는 동작을 도시한 개념도들이다. 설명의 편의상, 도 1 내지 도 8를 이용하여 설명한 것과 중복되는 것은 간략히 하거나 생략한다. 도 9를 참조하면, 전자 장치는 원본 이미지(10b)를 획득할 수 있다. 원본 이미지(10b)는 소정의 객체를 포 함할 수 있으며, 상기 객체는 전자 장치가 인식하고자 하는 대상일 수 있다. 도시된 바와 같이, 원본 이미 지(10b)는 노트북(PC)을 포함할 수 있다. 도 9에서, 객체는 노트북(PC)인 것으로 도시되었으나, 이는 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 객체는 노트북, 핸드폰, 커피 등 전자 장치가 인식하고자 하는 모든 객체를 의미할 수 있다. 다른 예로, 도 10에 도시된 바와 같이, 객체는 사용자의 손(도 10의 H)일 수 있다. 전자 장치는 부호화 이미지(20b)를 획득할 수 있다. 부호화 이미지(20b)는 패턴 마스크를 투과함에 따라 부호화된 이미지일 수 있다. 전자 장치는 광원으로부터 출력되어 객체, 즉 노트북(PC)에 반사되 고 패턴 마스크를 투과한 광을, 이미지 센서를 통해 수광함으로써 부호화 이미지(20b)를 획득할 수 있다. 전자 장치는 특징점(30b)을 획득할 수 있다. 특징점(30b)은 원본 이미지(10b) 내의 전자 장치가 인식 하고자 하는 객체에 대응될 수 있다. 특징점(30b)은 도 1에서 설명한 바와 같이, 점 좌표로 표현가능한 데이터 일 수도 있고, 모양과 형태를 나타내는 파라미터에 관한 데이터일 수도 있다. 단, 특징점의 표현 방식은 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 특징점(30 b)이 위치 좌표값을 데이터로 포함하는 것은 동일하나, 특징점은 점으로 표현될 수 있고, 텍스트로 표현될 수도 있다. 다른 예로, 노트북의 형태는 사각형을 포함할 수 있다. 따라서, 노트북의 형태를 표현하기 위해, 특징점(30b)은 사각형의 모양에 관련된 파라미터에 대응되는 수치값을 포함할 수 있다. 구체적으로 마름모 형태의 노트북을 특 징점에 대응시키기 위하여, 특징점(30b)은 마름모의 중심의 좌표, 장변의 길이, 단변의 길이, 내각 중 작은 내 각의 각도 중 적어도 하나를 포함할 수 있다. 이 경우, 노트북에 대응되는 특징점(30b)은 도 1에서 설명된 동공 특징점과 같은 방식으로 저장되는 데이터일 수 있다. 일 실시 예에서, 이미지 센서는 TOF 센서를 포함할 수도 있다. 전자 장치는 TOF 센서를 통해 수광된 광을 이용하여 부호화 이미지를 획득할 수 있다. TOF 센서를 통해 수광된 광을 이용하여 획득된 부호화 이미지는, 객 체에 대응되는 깊이 정보를 포함하되, 패턴 마스크에 의해 변조된 이미지인 것을 특징으로 할 수 있다. 일 실시 예에서, 프로세서는 TOF 센서를 이용하여 획득된 부호화 이미지에 기초하여, 대상 객체까지의 깊 이 정보를 포함하는 깊이 맵(Depth Map)을 획득할 수도 있다. 프로세서는 소정의 패턴에 의해 위상 변조된 부호 화 이미지로부터 깊이 맵을 추출하도록 학습된 인공지능 알고리즘을 이용함으로써, 깊이 맵을 획득할 수 있다. 일 실시 예에서, 이미지 센서는 깊이 정보를 획득하는 TOF 센서 및 대상에 관한 이미지를 획득하는 광센서를 포 함할 수 있다. 프로세서는 광센서에 의해 수광된 광에 기초한 제1 부호화 이미지 및 TOF 센서에 의해 수광 된 광에 기초한 제2 부호화 이미지 중 하나를 선택할 수 있다. 프로세서는 제1 부호화 이미지 및 제2 부호화 이미지 중 적어도 하나를 선택적으로 이용하여, 특징점 또는 깊이 정보를 획득할 수 있다. 또한, 프로세서는 제1 부호화 이미지 및 제2 부호화 이미지 중 적어도 하나 를 선택적으로 이용하여, 원본 이미지 또는 깊이 정보를 획득할 수 있다. 프로세서가 복수 개로 구성되는 경우, 제1 프로세서는 제1 부호화 이미지를 이용하여 원본 이미지를 획득하고, 제2 프로세서는 제2 부호화 이미지를 이용하여 깊이 정보를 획득할 수 있다. 또는, 제1 프로세서는 제1 부호화 이미지를 이용하여 특징점을 획득하고, 제2 프로세서는 제2 부호화 이미지를 이용하여 깊이 정보를 획득할 수 있다. 참고적으로, 프로세서가 원본 이미지를 획득하는 동작에 관하여 도 11을 이용하여 후술한다. 설명의 편의상, 도 9를 이용하여 설명한 것과 중복되는 것은 간략히 하거나 생략한다. 도 10을 참조하면, 전자 장치는 원본 이미지(10c)를 획득할 수 있다. 원본 이미지(10c)는 소정의 객체를 포함할 수 있으며, 상기 객체는 사용자의 손(H)일 수 있다. 전자 장치는 부호화 이미지(20c)를 획득할 수 있다. 전자 장치는 패턴 마스크를 투과함에 따라 경로가 변 경된 광을 수광함으로써, 부호화 이미지(20c)를 획득할 수 있다. 전자 장치는 하나 이상의 특징점(30c)을 획득할 수 있다. 하나 이상의 특징점(30c)은 전자 장치에 의해 인식하 고자 하는 객체에 대응되는 데이터일 수 있다. 도 10에 도시된 바와 같이, 객체, 즉, 사용자의 손(H)에 대응되 는 하나 이상의 특징점(30c)은 점으로 표현 가능하므로 위치 좌표값일 수 있다. 사용자의 손에 대응되는 하나 이상의 특징점(30c)은 도 1에서 설명된 눈의 반짝임 특징점과 같은 방식으로 저장되는 데이터일 수 있다.일 실시 예에서, 사용자의 손의 경우 하나 이상의 특징점(30c)은 손에 포함된 하나 이상의 관절에 대응될 수 있 다. 일 실시예에서, 전자 장치는 부호화 이미지(20c)에 기초하여 손의 인식 결과에 따라 손에 포함된 하나 이상 의 관절의 x축, y축 및 z축에 관한 위치 정보인 3차원 위치 좌표값인 관절값을 획득할 수 있다. 하나 이상의 특 징점(30c)은 각 관절값을 포함하는 데이터일 수 있다. 참고적으로, 손의 3차원 포즈는 ‘손 골격 감지 및 추적(hand skeleton detection and tracking)’기술을 통해 인식될 수 있다. 손 골격 감지 및 추적 기술은, 사람의 손 이미지 상에서 움직이는 관절 부위를 탐지하여, 미리 정해진 골격(skeleton) 구조를 분할해서 투영해 주는 기술이다. 사람의 손의 골격 구조는 각 손가락의 끝점(5개), 각 손가락의 관절점(5*3=15개), 손바닥 점(1개) 및 손목 점(1개)을 포함할 수 있으나, 이에 한정되 는 것은 아니다. 일 실시 예에서, 하나 이상의 특징점(30c)은 손 골격 감지 및 추적 기술을 이용하여 인식되는 사람의 손의 골격 구조에 대응되는 관절값을 포함하는 데이터일 수 있다. 단, 특징점의 표현 방식은 예시일 뿐, 본 개시의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 사용자의 손에 대응되는 특징점(30c)은 하나 이상의 점으로 표현되지 않고, 사용자의 손의 위치를 대표할 수 있는 하나의 점으로 표현될 수 있다. 구체적으로, 특징점(30c)은 사용자 의 손의 중심이 되는 지점에 대한 위치 좌표값일 수 있다. 다른 예로, 사용자의 손의 형태는 손의 윤곽을 포함하는 타원 형태로 표현될 수 있다. 이 경우, 사용자의 손을 표현하기 위해, 특징점(30c)은 타원 모양에 관련된 파라미터에 대응되는 수치값을 포함할 수 있다. 타원 모양에 관련된 파라미터로 저장되는 특징점(30c)은 도 1에서 설명된 동공 특징점과 같은 방식으로 저장되는 데이터 일 수 있다. 일 실시 예에서, 손의 골격 구조에 대응되는 관절값을 포함하는 특징점(30c)를 획득하기 위한 이미지 센서 는 TOF 센서를 포함할 수도 있다. 일 실시 예에서, 프로세서는 TOF 센서를 이용하여 획득된 부호화 이미지에 기초하여, 대상 객체까지의 깊이 정보를 획득할 수 있다. 이에 관하여, 도 9를 이용하여 설명한 것과 중복되므로 생략한다. 이 때, 대상 객체는 손이 될 수 있으며, 프로세서는 손의 골격 구조에 대응되는 관 절들을 포함하는 손가락, 손바닥, 손등 등을 포함하는 손의 부위들의 깊이 정보를 획득할 수 있다. 프로세서 는 획득된 깊이 정보에 기초하여 손가락의 각 관절들의 특징점(30c)의 3차원 위치 정보를 획득함으로써 손 의 3차원 포즈 또는 손동작을 인식할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치가 패턴 마스크를 이용하여 부호화 이미지(coded image)를 획득 하고, 획득된 부호화 이미지로부터 원본 이미지를 복원하는 동작을 도시한 개념도이다. 설명의 편의상, 도 1을 이용하여 설명한 것과 중복되는 것은 간략히 하거나 생략한다. 일 실시 예에서, 전자 장치는 이미지 센서를 통해 패턴 마스크를 투과한 광을 수광하여, 위상 변조 된 부호화 이미지를 획득할 수 있다. 부호화 이미지는 대상 이미지에 포함된 객체로부터 반사된 광 이 패턴 마스크를 투과함으로써 변조된 이미지일 수 있다. 전자 장치는 프로세서에 의해, 부호화 이미지로부터 원본 이미지를 복원할 수 있다. 프로세서 는 원본 이미지를 복원하기 위한 인공지능 알고리즘 또는 인공지능 네트워크를 포함할 수 있다. 프로 세서에 포함된 인공지능 알고리즘은 변조된 이미지, 즉 부호화 이미지로부터 원본 이미지를 복원 하도록 학습된(trained) 알고리즘일 수 있다. 프로세서는 이미지 센서에 의해 처리된 부호화 이미지를 획득할 수 있다. 프로세서는 부호 화 이미지로부터 복원된 원본 이미지를 획득할 수 있다. 프로세서는 복원된 원본 이미지에 기초하여 사용자의 인증 정보를 획득할 수 있다. 프로세서는 사용자에 대한 인증을 수행할 수 있다. 도 12 및 도 13은 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 단계 S1310에서, 전자 장치는 패턴 마스크를 투과하여 이미지 센서를 통해 수광된 광을 이용하여, 위상 변조된 부호화 이미지를 획득할 수 있다. 단계 S1310에 관한 설명은 단계 S210에 관한 설명과 동일할 수 있으므로, 생 략한다. 단계 S1320에서, 전자 장치는 부호화 이미지로부터 안구에 관한 원본 이미지를 복원할 수 있다. 전자 장치는 패턴 마스크를 투과한 광을 이미지 센서에 의해 수광할 수 있다. 수광된 광은 대상 이미지에 포함 된 객체(예를 들어, 눈)로부터 반사된 광일 수 있다. 수광된 광은 패턴 마스크를 투과함에 따라 변조될 수 있다. 이미지 센서는 수광된 광을 이용하여 부호화 이미지를 획득할 수 있다. 전자 장치는 프로세서에 의해, 부호화 이미지로부터 객체(예를 들어, 눈)에 관한 원본 이미지를 복원할 수 있다. 프로세서는 원본 이미지를 복원하기 위한 인공지능 알고리즘을 이용하여, 부호화 이미지로부터 원본 이미 지를 복원할 수 있다. 단계 S1330에서, 전자 장치는 원본 이미지에 기초하여 사용자의 인증 정보를 획득할 수 있다. 원본 이미지는 사 용자의 안구 중, 홍채에 관한 이미지를 포함할 수 있다. 도 13을 더 참조하면, 단계 S1410에서, 전자 장치는 원본 이미지에 기초하여 사용자의 홍채 정보를 식별할 수 있다. 홍채 정보는 사용자의 홍채를 다른 사용자의 홍채와 구별하기 위한 정보를 의미할 수 있다. 일 실시 예에서, 전자 장치는 원본 이미지로부터 홍채 영역을 추출할 수 있다. 전자 장치는 홍채 영역에 관한 이미지를 암호화함으로써, 사용자의 홍채 정보를 식별할 수 있다. 전자 장치는 식별된 사용자의 홍채 정보를 메 모리에 저장할 수 있다. 전자 장치의 메모리는 다양한 사용자의 홍채 정보를 저장하고 있을 수 있다. 일 실시 예에서, 전자 장치는 추출된 홍채 영역 중 홍채가 아닌 객체들을 제거할 수 있다. 예를 들어, 전자 장 치는 원본 이미지로부터, 홍채 영역 중 검출된 눈꺼풀(eyelid)을 제거할 수 있다. 이에 따라, 전자 장치는 보다 명확한 홍채 영역을 식별할 수 있다. 전자 장치는 추출된 홍채 영역에 기초하여 사용자의 홍채 정보를 식별할 수 있다. 단계 S1420에서, 전자 장치는 식별된 홍채 정보를 사용하여 인증 정보를 획득할 수 있다. 인증 정보는 홍채 정 보를 사용함으로써, 사용자를 식별한 결과에 대한 정보를 포함할 수 있다. 예를 들어, 홍채 정보는 사람마다 고 유한 홍채 패턴에 대한 정보를 포함할 수 있으나, 홍채 인식의 방법은 본 개시의 기술적 사상이 한정하지 않는 다. 인증 정보는 식별된 사용자가 본 전자 장치에 접근 가능한 사용자인지 여부에 대한 정보를 포함할 수 있다. 일 실시 예에서, 전자 장치는 메모리로부터 저장된 다양한 사용자의 홍채 정보를 획득할 수 있다. 전자 장치는 메모리에 저장된 다양한 사용자의 홍채 정보를, 획득된 사용자의 홍채 정보와 비교할 수 있다. 전자 장치는 상 기 비교를 통해, 식별된 사용자가 본 전자 장치에 접근 가능한 사용자인지 여부를 판단할 수 있다. 예를 들어, 전자 장치는 본 전자 장치에 접근 가능한 사용자에 대한 홍채 정보를 메모리에 저장할 수 있다. 전 자 장치는 메모리에 저장된 접근 가능한 사용자에 대한 홍채 정보와 새로 식별된 사용자의 홍채 정보와 동일하 다고 판단되는 경우, 새로 식별된 사용자가 본 전자 장치에 접근 가능한 사용자라고 판단할 수 있다. 다른 예로, 전자 장치는 메모리에 저장된 접근 가능한 사용자에 대한 홍채 정보와 새로 식별된 사용자의 홍채 정보와 다르다고 판단되는 경우, 새로 식별된 사용자가 본 전자 장치에 접근 불가능한 사용자라고 판단할 수 있 다. 도 14는 본 개시의 일 실시 예에 따른 전자 장치가 획득된 부호화 이미지로부터 특징점을 추출하거나 원본 이미 지를 복원하는 동작을 선택적으로 수행하는 방법을 도시한 개념도이다. 설명의 편의상, 도 1 및 도 11를 이용하여 설명한 것과 중복되는 것은 간략히 하거나 생략한다. 참고적으로, 프 로세서가 부호화 이미지를 이용하여 특징점을 추출하는 동작은 도 1에서 설명한 것과 중복되고, 프로세서가 부호화 이미지를 이용하여 원본 이미지를 복원하는 동작은 도 12에서 설명한 것과 중 복된다. 도 14를 참조하면, 프로세서는 부호화 이미지를 이용하여 특징점을 추출하거나, 원본 이미지(40 0)를 복원할 수 있다. 일 실시 예에서, 프로세서는 사용자의 상황에 기초하여 프로세스 결정 정보를 획득할 수 있다. 프로세스 결정 정보는 사용자의 상황에 따라 획득될 수 있다. 예를 들어, 사용자가 전자 장치를 착용한 상황에서, 전자 장치는 사용자에 대한 인증을 수행할 필요가 있다. 이 때, 전자 장치는 사용자 인증을 수행해야 한다는 프로세스 결정 정보를 획득할 수 있다.다른 예로, 사용자가 전자 장치의 착용을 지속하고 있는 상황에서, 전자 장치는 사용자의 시선을 추적해야 할 필요가 있다. 이 때, 전자 장치는 시선 추적을 수행해야 한다는 프로세스 결정 정보를 획득할 수 있다. 일 실시 예에서, 프로세서는 프로세스 결정 정보에 기초하여, 사용자의 시선 정보 또는 인증 정보를 선택 적으로 획득할 수 있다. 일 실시 예에서, 프로세서는 프로세스 결정 정보에 따라 시선 추적을 수행해야 하는 상황에서, 사용자의 시선 정보를 획득할 것을 선택할 수 있다. 이 때, 프로세서는 부호화 이미지를 이용하여, 특징점 을 획득할 수 있다. 프로세서는 특징점에 기초하여 사용자의 시선을 추적할 수 있다. 일 실시 예에서, 프로세서는 프로세스 결정 정보에 따라 사용자 인증을 수행해야 하는 상황에서, 인증 정 보를 획득할 것을 선택할 수 있다. 이 때, 프로세서는 부호화 이미지를 이용하여, 원본 이미지를 복원할 수 있다. 프로세서는 원본 이미지에 기초하여 사용자에 대한 인증을 수행할 수 있다. 일 실시 예에서, 프로세서가 복수 개로 구성되는 경우, 제1 프로세서는 부호화 이미지를 이용하여 특징점 을 획득하고, 제2 프로세서는 원본 이미지를 복원하도록 구성될 수 있다. 도 15는 본 개시의 일 실시 예에 따른 인공지능 모델이 특징점을 추출하고, 특징점에 기초하여 패턴을 최적화하 도록 학습된 방법을 도시한 개념도이다. 참고적으로, 도 1 내지 도 14와 달리, 도 15에 표현된 광원, 패턴 마스크 및 이미지 센서는 인공지능 모델의 학습을 위해 각자의 역할을 수행하는 가상의 구성일 수 있다. 도 15를 참조하면, 이미지 센서를 통해 패턴 마스크를 투과한 광을 수광하여, 위상 변조된 부호화 이미지가 획득될 수 있다. 인공지능 모델은 광원으로부터 출력된 광이 객체로부터 반사되고, 패턴 마스크를 투과하고, 이미지 센서를 통해 수광하는 과정을 가상 시뮬레이션으로 수행함으로써 학습된 모델일 수 있다. 인공지능 모델에 의해 수행되는 가상 시뮬레이션은 예를 들어, 광선 추적법(Ray Tracing)을 이용할 수 있 다. 즉, 인공지능 모델은 광의 궤적을 추적하는 방식을 이용하여, 이미지 센서를 통해 가상의 광을 수광함으로써 부호화 이미지를 획득할 수 있다. 단, 광의 궤적을 시뮬레이션하는 방법은 예시일 뿐, 본 개 시의 기술적 사상은 이에 한정되지 않는다. 상기 가상 시뮬레이션을 이용하여, 이미지 센서에 의해 수광된 광에 기초하여 부호화 이미지가 획득 될 수 있다. 이미지 센서를 통해 패턴 마스크를 투과한 광을 수광하여, 위상 변조된 부호화 이미지 가 획득될 수 있다. 부호화 이미지를 획득하는 과정은 도 8을 이용하여 설명한 것과 동일하므로 간략히 한다. 일 실시 예에서, 인공지능 모델은 특징점 추출 알고리즘 및 패턴 최적화 알고리즘을 수행함으로 써 학습된 모델일 수 있다. 특징점 추출 알고리즘은 변조된 이미지로부터 특징점을 추출하도록 학습된 알고리즘일 수 있다. 인공지능 모델은 특징점 추출 알고리즘을 이용하여, 부호화 이미지로부터 특징점을 추출할 수 있다. 예를 들어, 특징점 추출 알고리즘에 의해, 추출한 특징점과 대상 이미지에 기초한 정답값(ground truth) 간의 차이가 획득될 수 있다. 인공지능 모델은 특징점 추출 알고리즘을 통해, 특징점과 정답값 간의 차이에 기초하여, 부호화 이미지로부터 보다 정확한 특징점을 추출할 수 있도록 학습될 수 있 다. 특징점 추출 알고리즘을 통해, 특징점과 정답값 간의 차이에 관련된 손실 함수에 기초하여, 손실 함수의 결과값이 최소화될 수 있다. 인공지능 모델은 최소화된 손실 함수에 따라 학습될 수 있다. 패턴 최적화 알고리즘은 특징점을 추출하기 위해 최적화된 패턴 마스크의 최적화 패턴을 추출하도록 학습된 알고리즘일 수 있다. 예를 들어, 패턴 최적화 알고리즘을 통해, 추출한 특징점과 대상 이미지에 기초한 정답값(ground truth) 간의 차이가 획득될 수 있다. 패턴 최적화 알고리즘을 통해, 특징점과 정답값 간의 차이에 기 초하여, 패턴 마스크의 패턴이 업데이트될 수 있다. 결과적으로, 인공지능 모델은 패턴 최적화 알고 리즘을 통해, 부호화 이미지로부터 정확한 특징점을 획득하기 위한 패턴 마스크의 패턴을 최적화할 수 있다. 전자 장치는 최적화 패턴을 갖는 패턴 마스크를 포함하는 시선 추적용 카메라 시스템의 구성으로 실 제로 설계될 수 있다. 실제로 설계된 시선 추적용 카메라 시스템을 포함하는 장치는 증강 현실 디바이스(AR Device; Augmented Device)일 수도 있고, 머리 착용 디스플레이(HMD; Head Mounted Display)일 수도 있으나, 본 개시의 기술적 사상은 이에 한정되지 않는다. 업데이트된 패턴 마스크 또는 최적화 패턴을 갖는 패턴 마스크에 기초하여 수행되는 특징점 추출 알고리즘 및 패턴 최적화 알고리즘은 서로 페어(pair)를 이룰 수 있다. 인공지능 모델은 특징점 추출 알 고리즘을 수행함과 동시에 특징점을 추출하기 위해 최적화된 패턴 마스크의 최적화 패턴을 추출하도록 학 습된 패턴 최적화 알고리즘을 수행함으로써 학습될 수 있다. 따라서, 패턴 최적화 알고리즘에 의해 획득된 최적화 패턴에 대하여, 패턴 최적화 알고리즘과 페어를 이루는 특징점 추출 알고리즘은 최적화 패턴을 갖는 패턴 마스크에 의해 변조된 부호화 이미 지로부터 정확한 특징점을 추출하도록 학습된 알고리즘일 수 있다. 이와 반대로, 패턴 최적화 알고리즘에 의해 획득된 최적화 패턴에 대하여, 패턴 최적화 알고리즘과 페어를 이루지 않는 특징점 추출 알고리즘은 최적화 패턴을 갖는 패턴 마스크에 의해 변조된 부호화 이미지로부터 정확한 특징점을 추출할 수 없다. 도 16은 본 개시의 일 실시 예에 따른 인공지능 모델이 원본 이미지를 복원하고, 원본 이미지에 기초하여 패턴 을 최적화하도록 학습된 방법을 도시한 개념도이다. 참고적으로, 도 1 내지 도 14와 달리, 도 16에 표현된 광원, 패턴 마스크 및 이미지 센서는 인공지능 모델의 학습을 위해 각자의 역할을 수행하는 가상의 구성일 수 있다. 도 16을 참조하면, 일 실시 예에 따른 이미지 센서를 통해 패턴 마스크를 투과한 광을 수광하여, 위상 변조된 부호화 이미지가 획득될 수 있다. 인공지능 모델은 광원으로부터 출력된 광이 객체로부터 반사되고, 패턴 마스크를 투과하고, 이미지 센서를 통해 수광하는 과정을 가상 시뮬레이션으로 수행함으로써 학습된 모델일 수 있다. 인공지능 모델에 의해 수행되는 가상 시뮬레이션은 예를 들어, 광선 추적법(Ray Tracing)을 이용할 수 있 다. 즉, 인공지능 모델은 광의 궤적을 추적하는 방식을 이용하여, 이미지 센서를 통해 가상의 광을 수광함으로써 부호화 이미지를 획득할 수 있다. 단, 광의 궤적을 시뮬레이션하는 방법은 예시일 뿐, 본 개 시의 기술적 사상은 이에 한정되지 않는다. 상기 가상 시뮬레이션을 이용하여, 이미지 센서에 의해 수광된 광에 기초하여 부호화 이미지가 획득 될 수 있다. 부호화 이미지를 획득하는 과정은 도 8을 이용하여 설명한 것과 동일하므로 간략히 한다. 일 실시 예에서, 인공지능 모델은 원본 복원 알고리즘 및 패턴 최적화 알고리즘을 수행함으로써 학습된 모델일 수 있다. 원본 복원 알고리즘은 변조된 이미지로부터 원본 이미지를 복원하도록 학습된 리즘일 수 있다. 원본 복원 알고리즘은 변조된 이미지로부터 원본 이미지를 복원하는 프로그램 코드로 구성될 수 있다. 원본 복원 알 고리즘은, 패턴 마스크에 의해 위상 변조된 부호화 이미지로부터 원본 이미지를 복원하는 프로그램 코드일 수 있다. 따라서, 전자 장치는 원본 복원 알고리즘을 이용하여, 부호화 이미지로부터 원본 이 미지를 복원할 수 있다. 예를 들어, 원본 복원 알고리즘을 통해, 복원된 원본 이미지와 입력된 대상 이미지에 기초한 정 답값(ground truth) 간의 차이가 획득될 수 있다. 인공지능 모델은 원본 복원 알고리즘을 통해, 복원 된 원본 이미지 정답값 간의 차이에 기초하여, 부호화 이미지로부터 보다 정확한 원본 이미지를 복원 할 수 있도록 학습될 수 있다. 원본 복원 알고리즘을 통해, 복원된 원본 이미지와 정답값 간의 차이 에 관련된 손실 함수를 획득하고, 손실 함수의 결과값이 최소화될 수 있다. 인공지능 모델은 최소화된 손 실 함수에 따라 학습될 수 있다. 패턴 최적화 알고리즘은 원본 이미지를 복원하기 위해 최적화된 패턴 마스크의 최적화 패턴을 추출하 도록 학습된 알고리즘일 수 있다. 예를 들어, 패턴 최적화 알고리즘을 통해, 복원된 원본 이미지와 입력된 대상 이미지에 기초한 정답값(ground truth) 간의 차이를 획득할 수 있다. 패턴 최적화 알고리즘을 통해, 원본 이미지와 정답값 간의 차이에 기초하여, 패턴 마스크의 패턴이 업데이트될 수 있다. 결과적으로, 인공지능 모델은 패 턴 최적화 알고리즘을 통해, 부호화 이미지로부터 정확한 원본 이미지를 획득하기 위한 패턴 마스크 의 패턴을 최적화할 수 있다. 전자 장치는 최적화 패턴을 갖는 패턴 마스크를 포함하는 시선 추적용 카메라 시스템의 구성으로 실 제로 설계될 수 있다. 실제로 설계된 시선 추적용 카메라 시스템을 포함하는 장치는 증강 현실 디바이스(AR Device; Augmented Device)일 수도 있고, 머리 착용 디스플레이(HMD; Head Mounted Display)일 수도 있으나, 본 개시의 기술적 사상은 이에 한정되지 않는다. 업데이트된 패턴 마스크 또는 최적화 패턴을 갖는 패턴 마스크에 기초하여 수행되는 원본 복원 알고리즘 및 패턴 최적화 알고리즘은 서로 페어(pair)를 이룰 수 있다. 인공지능 모델은 원본 복원 알고 리즘을 수행함과 동시에 원본 이미지를 복원하기 위해 최적화된 패턴 마스크의 최적화 패턴을 추출하도록 학습된 패턴 최적화 알고리즘을 수행함으로써 학습될 수 있다. 예를 들어, 패턴 최적화 알고리즘은 원본 복원 알고리즘에 의해 획득된 원본 이미지와 정답값 간의 차이에 기초하여 패턴을 최적화할 수 있다. 패턴 최적화 알고리즘은 원본 복원 알고리즘에 의해 획득된 원본 이미지를 데이터로 이용하여 학습하므로, 원본 복원 알고리즘과 페어(pair)를 이룰 수 있다. 따라서, 패턴 최적화 알고리즘에 의해 획득된 최적화 패턴에 대하여, 패턴 최적화 알고리즘과 페어를 이루는 원본 복원 알고리즘은 최적화 패턴을 갖는 패턴 마스크에 의해 변조된 부호화 이미지 로부터 정확한 원본 이미지를 복원하도록 학습된 알고리즘일 수 있다. 이와 반대로, 패턴 최적화 알고리즘(18 4)에 의해 획득된 최적화 패턴에 대하여, 패턴 최적화 알고리즘과 페어를 이루지 않는 원본 복원 알 고리즘은 최적화 패턴을 갖는 패턴 마스크에 의해 변조된 부호화 이미지로부터 정확한 원본 이미지를 복원 할 수 없다. 본 개시의 일 실시 예에 따른 전자 장치는 광원, 패턴 마스크, 이미지 센서 및 적어도 하나의 프로세서를 포함 할 수 있다. 광원은 광을 출력할 수 있다. 패턴 마스크는 소정의 패턴이 형성되어 투과되는 광의 경로가 변경될 수 있다. 이미지 센서는 광원에서 출력되고 안구에 의해 반사된 광이 패턴 마스크를 투과한 광을 수광할 수 있 다. 적어도 하나의 프로세서는 패턴 마스크를 투과하여 이미지 센서를 통해 수광된 광을 이용하여, 위상 변조된 부호화 이미지(coded image)를 획득할 수 있다. 적어도 하나의 프로세서는 부호화 이미지로부터 안구에 관한 특 징점을 획득할 수 있다. 적어도 하나의 프로세서는 특징점에 기초하여 사용자의 시선 정보를 획득할 수 있다. 일 실시 예에서, 특징점은 안구의 위치 좌표 및 형태 중 적어도 하나에 대한 정보를 포함할 수 있다. 일 실시 예에서, 특징점은 동공의 특징점(pupil feature point) 및 눈의 반짝임 특징점(glint feature point) 중 적어도 하나를 포함할 수 있다. 일 실시 예에서, 적어도 하나의 프로세서는 부호화 이미지로부터 상기 안구에 관한 원본 이미지를 복원할 수 있 다. 적어도 하나의 프로세서는 원본 이미지에 기초하여 상기 사용자의 인증 정보를 획득할 수 있다. 일 실시 예에서, 적어도 하나의 프로세서는 원본 이미지에 기초하여 사용자의 홍채 정보를 식별할 수 있다. 적 어도 하나의 프로세서는 식별된 홍채 정보를 사용하여 인증 정보를 획득할 수 있다. 일 실시 예에서, 적어도 하나의 프로세서는 사용자의 상황에 기초하여 프로세스 결정 정보를 획득할 수 있다. 적어도 하나의 프로세서는 프로세스 결정 정보에 기초하여, 사용자의 시선 정보 또는 인증 정보를 선택적으로 획득할 수 있다. 일 실시 예에서, 이미지 센서는 광을 수광함으로써 깊이 정보를 획득하는 TOF(Time of Flight) 센서를 포함할 수 있다. 적어도 하나의 프로세서는 패턴 마스크를 투과하여 TOF 센서를 통해 수광된 광을 이용하여, 부호화 이 미지를 획득할 수 있다. 일 실시 예에서, TOF 센서를 통해 수광된 광을 이용하여 획득된 부호화 이미지는, 객체에 대응되는 깊이 정보를 포함하되, 패턴 마스크에 의해 변조된 이미지인 것을 특징으로 할 수 있다. 일 실시 예에서, 이미지 센서는 깊이 정보를 획득하는 TOF(Time of Flight) 센서 및 대상에 관한 이미지를 획득 하는 광센서를 포함할 수 있다. 적어도 하나의 프로세서는 패턴 마스크를 투과하여 TOF 센서를 통해 수광된 광 에 기초하여 제1 부호화 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 패턴 마스크를 투과하여 광센서에 의해 수광된 광에 기초하여, 제2 부호화 이미지를 획득할 수 있다. 적어도 하나의 프로세서는 제1 부호화 이미 지 및 제2 부호화 이미지 중 적어도 하나를 선택적으로 이용하여, 특징점을 획득할 수 있다. 일 실시 예에서, 적어도 하나의 프로세서는 부호화 이미지로부터 안구에 관한 특징점만(only)을 획득할 수 있다. 즉, 원본 이미지를 복원하지 않고 부호화 이미지로부터 바로 특징점을 획득할 수 있다. 일 실시 예에 따른 전자 장치는, 소정의 패턴에 의해 위상 변조된 이미지로부터 특징점을 추출하도록 학습된 (trained) 인공지능 모델을 더 포함할 수 있다. 전자 장치의 적어도 하나의 프로세서는 학습된 인공지능 모델을 이용하여, 부호화 이미지로부터 특징점을 획득할 수 있다. 본 개시의 일 실시 예에 따른 방법은 패턴 마스크를 투과하여 이미지 센서를 통해 수광된 광을 이용하여, 위상 변조된 부호화 이미지(coded image)를 획득하는 단계를 포함할 수 있다. 상기 방법은 부호화 이미지로부터 안구 에 관한 특징점을 획득하는 단계를 포함할 수 있다. 상기 방법은 특징점에 기초하여 사용자의 시선 정보를 획득 하는 단계를 포함할 수 있다. 일 실시 예에서, 특징점은 안구의 위치 좌표 및 형태 중 적어도 하나에 대한 정보를 포함할 수 있다. 일 실시 예에서, 특징점은 동공의 특징점(pupil feature point) 및 눈의 반짝임 특징점(glint feature point) 중 적어도 하나를 포함할 수 있다. 일 실시 예에서, 상기 방법은 부호화 이미지로부터 안구에 관한 원본 이미지를 복원하는 단계를 더 포함할 수 있다. 상기 방법은 원본 이미지에 기초하여 사용자의 인증 정보를 획득하는 단계를 더 포함할 수 있다. 일 실시 예에서, 상기 사용자의 인증 정보를 획득하는 단계는 원본 이미지에 기초하여 사용자의 홍채 정보를 식 별하는 단계를 포함할 수 있다. 상기 사용자의 인증 정보를 획득하는 단계는 식별된 홍채 정보를 사용하여 인증 정보를 획득하는 단계를 포함할 수 있다. 일 실시 예에서, 상기 사용자의 시선 정보를 획득하는 단계와 상기 사용자의 인증 정보를 획득하는 단계는, 사 용자의 상황에 기초하여 프로세스 결정 정보를 획득하는 단계를 포함할 수 있다. 상기 사용자의 시선 정보를 획 득하는 단계와 상기 사용자의 인증 정보를 획득하는 단계는, 프로세스 결정 정보에 기초하여 사용자의 시선 정 보 또는 인증 정보를 선택적으로 획득하는 단계를 포함할 수 있다. 일 실시 예에서, 이미지 센서는 광을 수광함으로써 깊이 정보를 획득하는 TOF(Time of Flight) 센서를 포함할 수 있다. 상기 부호화 이미지를 획득하는 단계는, 패턴 마스크를 투과하여 TOF 센서를 통해 수광된 광을 이용하 여, 부호화 이미지를 획득하는 단계를 포함할 수 있다. 일 실시 예에서, TOF 센서를 통해 수광된 광을 이용하여 획득된 부호화 이미지는, 객체에 대응되는 깊이 정보를 포함하되, 패턴 마스크에 의해 변조된 이미지일 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16"}
{"patent_id": "10-2022-0122866", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시는, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호 (reference numerals)들은 구조적 구성요소(structural elements)를 의미한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치가 패턴 마스크를 이용하여 부호화 이미지(coded image)를 획득 하고, 획득된 부호화 이미지로부터 특징점을 추출하는 동작을 도시한 개념도이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성 요소를 도시한 블록도이다. 도 4는 본 개시의 일 실시예에 따른 전자 장치의 구조를 도시한 도면들이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치의 광 검출부의 구조를 세부적으로 도시한 평면도이다. 도 6 및 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 패턴 마스크를 설명하기 위한 도면들이다. 도 8은 본 개시의 일 실시 예에 따른 전자 장치가 패턴 마스크를 이용하여 부호화 이미지를 획득하는 동작을 구 체적으로 도시한 개념도이다. 도 9 및 도 10은 본 개시의 일 실시 예에 따른 전자 장치가 부호화 이미지로부터 추출한 다양한 유형의 특징점을 통해 객체를 인식하는 동작을 도시한 개념도들이다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치가 패턴 마스크를 이용하여 부호화 이미지(coded image)를 획득 하고, 획득된 부호화 이미지로부터 원본 이미지를 복원하는 동작을 도시한 개념도이다. 도 12 및 도 13은 본 개시의 일 실시 예에 따른 전자 장치의 동작 방법을 도시한 흐름도이다. 도 14는 본 개시의 일 실시 예에 따른 전자 장치가 획득된 부호화 이미지로부터 특징점을 추출하거나 원본 이미 지를 복원하는 동작을 선택적으로 수행하는 방법을 도시한 개념도이다. 도 15는 본 개시의 일 실시 예에 따른 인공지능 모델이 특징점을 추출하고, 특징점에 기초하여 패턴을 최적화하 도록 학습된 방법을 도시한 개념도이다. 도 16은 본 개시의 일 실시 예에 따른 인공지능 모델이 원본 이미지를 복원하고, 원본 이미지에 기초하여 패턴 을 최적화하도록 학습된 방법을 도시한 개념도이다."}
