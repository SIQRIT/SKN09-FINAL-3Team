{"patent_id": "10-2021-0016311", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0112590", "출원번호": "10-2021-0016311", "발명의 명칭": "인공지능 기반 수계오염원 모니터링 시스템 및 방법", "출원인": "창원대학교 산학협력단", "발명자": "박경훈"}}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치를 통해 구현되는 인공지능 기반 수계오염원 모니터링 방법에 있어서, 모니터링 대상 지역의 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 이용하여 입력 데이터를생성하는 단계; 상기 입력 데이터를 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류 또는 상태에 대한 정보를분석하는 단계; 및 상기 오염원을 모니터링하도록 이미지의 위치 정보를 활용하여 상기 오염원의 종류 또는 상태에 대한 정보를 표시하는 단계를 포함하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,드론의 자율비행 경로의 설정을 통한 오염원에 대한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 획득하는 단계를 더 포함하고, 상기 영상을 이용하여 상기 입력 데이터를 생성하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 영상을 획득하는 단계는, 드론의 자율비행 경로의 설정에 따라 모니터링 대상 지역의 영상을 RGB, 다중분광 및 열적외선으로 촬영한 후,이미지 처리를 통해 정사영상으로 변환하고, 상기 입력 데이터를 생성하는 단계는, 상기 정사영상에서 오염원으로 의심되는 영역의 RGB, 다중분광 및 열적외선 영상을 이용하여 입력 데이터를 형성하는 것을 특징으로 하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 영상을 획득하는 단계는, 드론이 모니터링 지역을 소정 높이의 고도에서 스캔하며 이동하여, RGB 영상을 획득하는 단계; 상기 RGB 영상을 오브젝트 디텍션(object detection)을 통해 오염원의 유무를 확인하는 단계; 상기 오브젝트 디텍션을 통해 오염원이 검출되는 경우, 상기 드론이 상기 오염원이 검출된 영역을 집중 촬영하도록 비행경로를 설정하는 단계; 및 설정된 상기 비행경로에 따라 상기 드론이 이동하며 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 집중 촬영하는 단계를 포함하는, 수계오염원 모니터링 방법.공개특허 10-2022-0112590-3-청구항 5 제4항에 있어서, 상기 집중 촬영하는 단계는, 상기 드론이 위치, 각도 및 포커싱 중 적어도 어느 하나 이상의 설정을 변경하여 집중 촬영하여 서로 다른 관점에서의 영상을 획득하는 것을 특징으로 하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 오염원의 종류 또는 상태에 대한 정보를 표시하는 단계는, 상기 오염원의 종류 또는 상태에 대한 정보를 정사영상에 매칭하여 표시하여 비점오염원을 모니터링하는 것을 특징으로 하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,오염원을 촬영한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상과, 오염원 종류별로 레이블을 결합하여 학습 데이터를 생성하는 단계; 및 생성된 상기 학습 데이터를 이용하여 상기 이미지 딥러닝 뉴럴 네트워크를 학습시키는 단계를 더 포함하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 이미지 딥러닝 뉴럴 네트워크를 학습시키는 단계는, 생성된 상기 학습 데이터를 상기 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류를 이미지 분류(imageclassification)하는 단계; 및 분류된 각 상기 오염원을 이미지 세그멘테이션(image segmentation)을 통해 오염원의 상태를 파악하는 단계를 포함하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 이미지 딥러닝 뉴럴 네트워크는, RGB, 다중분광 및 열적외선 영상을 정합한 하나의 영상으로 학습하여 구성하거나, RGB, 다중분광 및 열적외선영상을 개별적으로 학습한 후 최종적으로 결합하여 구성하는 것을 특징으로 하는, 수계오염원 모니터링 방법."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 기반 수계오염원 모니터링 시스템에 있어서, 모니터링 대상 지역의 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 이용하여 입력 데이터를생성하는 입력 데이터 생성부; 상기 입력 데이터를 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류 또는 상태에 대한 정보를분석하는 분석 및 해석부; 및 공개특허 10-2022-0112590-4-상기 오염원을 모니터링하도록 이미지의 위치 정보를 활용하여 상기 오염원의 종류 또는 상태에 대한 정보를 표시하는 정보 표시부를 포함하는, 수계오염원 모니터링 시스템."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,드론의 자율비행 경로의 설정을 통한 오염원에 대한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 획득하는 영상 수집부를 더 포함하고, 상기 영상을 이용하여 상기 입력 데이터를 생성하는, 수계오염원 모니터링 시스템."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 영상 수집부는, 드론의 자율비행 경로의 설정에 따라 모니터링 대상 지역의 영상을 RGB, 다중분광 및 열적외선으로 촬영한 후,이미지 처리를 통해 정사영상으로 변환하고, 상기 입력 데이터 생성부는, 상기 정사영상에서 오염원으로 의심되는 영역의 RGB, 다중분광 및 열적외선 영상을 이용하여 입력 데이터를 형성하는 것을 특징으로 하는, 수계오염원 모니터링 시스템."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 영상 수집부는, 드론이 모니터링 지역을 소정 높이의 고도에서 스캔하며 이동하여, RGB 영상을 획득하고, 상기 RGB 영상을 오브젝트 디텍션(object detection)을 통해 오염원의 유무를 확인한 후, 상기 오브젝트 디텍션을 통해 오염원이 검출되는 경우, 상기 드론이 상기 오염원이 검출된 영역을 집중 촬영하도록 비행경로를 설정하고, 설정된 상기 비행경로에 따라 상기 드론이 이동하며 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 집중 촬영하는 것을 특징으로 하는, 수계오염원 모니터링 시스템."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 영상 수집부는, 상기 드론이 위치, 각도 및 포커싱 중 적어도 어느 하나 이상의 설정을 변경하여 집중 촬영하여 서로 다른 관점에서의 영상을 획득하는 것을 특징으로 하는, 수계오염원 모니터링 시스템."}
{"patent_id": "10-2021-0016311", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,오염원을 촬영한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상과, 오염원 종류별로 레이블을 결합하여 학습 데이터를 생성하고, 생성된 상기 학습 데이터를 이용하여 상기 이미지 딥러닝 뉴럴 네트워크를 학습시키는 모델 학습부공개특허 10-2022-0112590-5-를 더 포함하는, 수계오염원 모니터링 시스템."}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반 수계오염원 모니터링 시스템 및 방법이 제시된다. 일 실시예에 따른 컴퓨터 장치를 통해 구현되 는 인공지능 기반 수계오염원 모니터링 방법은, 모니터링 대상 지역의 RGB, 다중분광 및 열적외선 중 적어도 어 느 하나 이상의 영상을 이용하여 입력 데이터를 생성하는 단계; 상기 입력 데이터를 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류 또는 상태에 대한 정보를 분석하는 단계; 및 상기 오염원을 모니터링하도록 이미지의 위치 정보를 활용하여 상기 오염원의 종류 또는 상태에 대한 정보를 표시하는 단계를 포함하여 이루어 질 수 있다."}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 실시예들은 인공지능 기반 수계오염원 모니터링 시스템 및 방법에 관한 것으로, 더욱 상세하게는 이미지 딥러닝을 기반으로 오염원의 종류와 정보를 판별하는 인공지능 기반 수계오염원 모니터링 시스템 및 방법에 관 한 것이다."}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "비점오염원(非點汚染源)은 도시, 도로, 농지, 산지, 공사장 등 불특정 장소에서 불특정하게 수질오염물질을 배 출하는 배출원을 의미한다. 점오염원(點汚染源)은 오염물질의 유출경로가 명확하여 수집이 쉽고, 계절에 따른 영향이 상대적으로 적은 만큼 연중 발생량 예측이 가능하여 관거 및 처리장 등 처리시설의 설계와 유지/관리가 용이하다. 반면, 비점오염원은 오염물질의 유출 및 배출 경로가 명확하게 구분되지 않아 수집이 어렵고, 발생 량/배출량이 강수량 등 기상조건에 크게 좌우되기 때문에 처리시설의 설계 및 유지관리가 어려운 문제가 있다. 또한, 우수 유출로 인하여 부하가 발생되는 비점오염원은 그 발생원과 운반과정이 다양하므로 관리방법도 다양 하며 점오염원과 같이 간단하게 처리하기는 매우 곤란하다. 따라서 초기 우수를 하수처리 수준으로 처리한다는 것은 불가능하며, 처리에 있어서도 어느 한가지의 처리방법을 이용하여 제어하기는 어렵다. 현재 정부는 장기계획으로 비점오염원에 대한 단계별 대책을 추진하고 있다. 구체적으로 비점오염원 관리를 위 한 법령 및 규정을 마련하고, 주요 사업장의 비점오염원의 관리의무를 부과하며 관리 대책을 반영한 개발 및 정 비사업을 시행 중이며, 비점오염원을 모니터링하기 위한 사업을 추진 중이다. 따라서, 광활한 지역에 지엽적으 로 분포된 다양한 종류의 비점오염원을 관리, 모니터링 할 수 있는 기술 개발이 시급하다. 한국등록특허 10-1659433호는 이러한 하천오염 관리시스템 및 그 운용방법에 관한 것으로, 도심하천으로 유입하 는 점 및 비점오염원의 배후농도 분석 및 오염도를 평가하고, 조사 분석된 오염원 속성자료와 지형공간정보의 융합모니터링 기법을 활용하는 기술을 기재하고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 10-1659433호"}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예들은 인공지능 기반 수계오염원 모니터링 시스템 및 방법에 관하여 기술하며, 보다 구체적으로 이미지 딥 러닝을 기반으로 오염원의 종류와 정보를 판별하는 기술을 제공한다. 실시예들은 RGB, 다중분광, 열적외선 영상을 각각 또는 정합하여 학습시킨 이미지 딥러닝 뉴럴 네트워크를 통해 오염원을 자동 판별하는 인공지능 기반 수계오염원 모니터링 시스템 및 방법을 제공하는데 있다. 또한, 실시예들은 드론의 자율 비행을 오염원의 위치를 기반으로 설계하여 광범위한 영역을 자율 비행하는 알고 리즘을 통해 모니터링 인력 소모를 최소화할 수 있는 인공지능 기반 수계오염원 모니터링 시스템 및 방법을 제 공하는데 있다."}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 컴퓨터 장치를 통해 구현되는 인공지능 기반 수계오염원 모니터링 방법은, 모니터링 대상 지 역의 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 이용하여 입력 데이터를 생성하는 단계; 상기 입력 데이터를 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류 또는 상태에 대한 정보를 분석하는 단계; 및 상기 오염원을 모니터링하도록 이미지의 위치 정보를 활용하여 상기 오염원의 종류 또는 상태에 대한 정보를 표시하는 단계를 포함하여 이루어질 수 있다. 드론의 자율비행 경로의 설정을 통한 오염원에 대한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영 상을 획득하는 단계를 더 포함하고, 상기 영상을 이용하여 상기 입력 데이터를 생성할 수 있다. 상기 영상을 획득하는 단계는, 드론의 자율비행 경로의 설정에 따라 모니터링 대상 지역의 영상을 RGB, 다중분 광 및 열적외선으로 촬영한 후, 이미지 처리를 통해 정사영상으로 변환하고, 상기 입력 데이터를 생성하는 단계 는, 상기 정사영상에서 오염원으로 의심되는 영역의 RGB, 다중분광 및 열적외선 영상을 이용하여 입력 데이터를 형성할 수 있다. 상기 영상을 획득하는 단계는, 드론이 모니터링 지역을 소정 높이의 고도에서 스캔하며 이동하여, RGB 영상을 획득하는 단계; 상기 RGB 영상을 오브젝트 디텍션(object detection)을 통해 오염원의 유무를 확인하는 단계; 상기 오브젝트 디텍션을 통해 오염원이 검출되는 경우, 상기 드론이 상기 오염원이 검출된 영역을 집중 촬영하 도록 비행경로를 설정하는 단계; 및 설정된 상기 비행경로에 따라 상기 드론이 이동하며 RGB, 다중분광 및 열적 외선 중 적어도 어느 하나 이상의 영상을 집중 촬영하는 단계를 포함하여 이루어질 수 있다. 상기 집중 촬영하는 단계는, 상기 드론이 위치, 각도 및 포커싱 중 적어도 어느 하나 이상의 설정을 변경하여 집중 촬영하여 서로 다른 관점에서의 영상을 획득할 수 있다. 상기 오염원의 종류 또는 상태에 대한 정보를 표시하는 단계는, 상기 오염원의 종류 또는 상태에 대한 정보를 정사영상에 매칭하여 표시하여 비점오염원을 모니터링할 수 있다. 오염원을 촬영한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상과, 오염원 종류별로 레이블을 결 합하여 학습 데이터를 생성하는 단계; 및 생성된 상기 학습 데이터를 이용하여 상기 이미지 딥러닝 뉴럴 네트워 크를 학습시키는 단계를 더 포함할 수 있다. 상기 이미지 딥러닝 뉴럴 네트워크를 학습시키는 단계는, 생성된 상기 학습 데이터를 상기 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류를 이미지 분류(image classification)하는 단계; 및 분류된 각 상기 오염원 을 이미지 세그멘테이션(image segmentation)을 통해 오염원의 상태를 파악하는 단계를 포함할 수 있다. 상기 이미지 딥러닝 뉴럴 네트워크는, RGB, 다중분광 및 열적외선 영상을 정합한 하나의 영상으로 학습하여 구 성하거나, RGB, 다중분광 및 열적외선 영상을 개별적으로 학습한 후 최종적으로 결합하여 구성할 수 있다. 다른 실시예에 따른 인공지능 기반 수계오염원 모니터링 시스템은, 모니터링 대상 지역의 RGB, 다중분광 및 열 적외선 중 적어도 어느 하나 이상의 영상을 이용하여 입력 데이터를 생성하는 입력 데이터 생성부; 상기 입력 데이터를 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류 또는 상태에 대한 정보를 분석하는 분 석 및 해석부; 및 상기 오염원을 모니터링하도록 이미지의 위치 정보를 활용하여 상기 오염원의 종류 또는 상태 에 대한 정보를 표시하는 정보 표시부를 포함하여 이루어질 수 있다. 드론의 자율비행 경로의 설정을 통한 오염원에 대한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영 상을 획득하는 영상 수집부를 더 포함하고, 상기 영상을 이용하여 상기 입력 데이터를 생성할 수 있다. 상기 영상 수집부는, 드론의 자율비행 경로의 설정에 따라 모니터링 대상 지역의 영상을 RGB, 다중분광 및 열적 외선으로 촬영한 후, 이미지 처리를 통해 정사영상으로 변환하고, 상기 입력 데이터 생성부는, 상기 정사영상에 서 오염원으로 의심되는 영역의 RGB, 다중분광 및 열적외선 영상을 이용하여 입력 데이터를 형성할 수 있다. 상기 영상 수집부는, 드론이 모니터링 지역을 소정 높이의 고도에서 스캔하며 이동하여, RGB 영상을 획득하고, 상기 RGB 영상을 오브젝트 디텍션(object detection)을 통해 오염원의 유무를 확인한 후, 상기 오브젝트 디텍션 을 통해 오염원이 검출되는 경우, 상기 드론이 상기 오염원이 검출된 영역을 집중 촬영하도록 비행경로를 설정 하고, 설정된 상기 비행경로에 따라 상기 드론이 이동하며 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이 상의 영상을 집중 촬영할 수 있다. 상기 영상 수집부는, 상기 드론이 위치, 각도 및 포커싱 중 적어도 어느 하나 이상의 설정을 변경하여 집중 촬 영하여 서로 다른 관점에서의 영상을 획득할 수 있다. 오염원을 촬영한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상과, 오염원 종류별로 레이블을 결 합하여 학습 데이터를 생성하고, 생성된 상기 학습 데이터를 이용하여 상기 이미지 딥러닝 뉴럴 네트워크를 학 습시키는 모델 학습부를 더 포함할 수 있다."}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들에 따르면 RGB, 다중분광, 열적외선 영상을 각각 또는 정합하여 학습시킨 이미지 딥러닝 뉴럴 네트워크 를 통해 오염원을 자동 판별하는 인공지능 기반 수계오염원 모니터링 시스템 및 방법을 제공할 수 있다. 또한, 실시예들에 따르면 드론의 자율 비행을 오염원의 위치를 기반으로 설계하여 광범위한 영역을 자율 비행하 는 알고리즘을 통해 모니터링 인력 소모를 최소화할 수 있는 인공지능 기반 수계오염원 모니터링 시스템 및 방 법을 제공할 수 있다."}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 실시예들을 설명한다. 그러나, 기술되는 실시예들은 여러 가지 다른 형태로 변 형될 수 있으며, 본 발명의 범위가 이하 설명되는 실시예들에 의하여 한정되는 것은 아니다. 또한, 여러 실시"}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예들은 당해 기술분야에서 평균적인 지식을 가진 자에게 본 발명을 더욱 완전하게 설명하기 위해서 제공되는 것 이다. 도면에서 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 아래의 실시예들은 RGB 영상뿐만 아니라 열적외선 영상 및 다중분광 영상을 입력 데이터로 하여, 개별적 오염원 들의 특성을 파악하여 학습된 이미지 딥러닝 뉴럴 네트워크를 이용하여 오염원의 종류를 파악하고, 오염원의 상 태를 판별해 모니터링하는 인공지능 오염원 모니터링 시스템을 제공할 수 있다. 실시예들에 따르면 광범위한 영역에 다양한 종류의 점오염원, 비점오염원을 구분하여 모니터링하는 오염원 모니 터링 시스템을 제공할 수 있다. 또한, 실시예들에 따르면 이미지 딥러닝을 기반으로 오염원의 종류와 정보를 판별하여, 오염원 상태별로 관리의 필요성을 파악하고 경고해줄 수 있는 모니터링 시스템을 제공할 수 있다. 또한, 실시예들에 따르면 드론의 자율 비행을 오염원의 위치를 기반으로 설계하여, 광범위한 영역을 자율 비행 하는 알고리즘을 통해 모니터링 인력 소모를 최소화할 수 있다. 도 1은 일 실시예에 따른 컴퓨터 장치(시스템)의 내부 구성의 일례를 설명하기 위한 블록도이다. 예를 들어, 본 발명의 실시예들에 따른 수계오염원 모니터링 시스템이 도 1의 컴퓨터 시스템을 통해 구현될 수 있다. 도 1에 도시한 바와 같이, 컴퓨터 시스템은 수계오염원 모니터링 방법을 실행하기 위한 구성요소로서 프로세서, 메모리, 영구 저장 장치, 버스, 입출력 인터페이스 및 네트워크 인터페이스 를 포함할 수 있다. 프로세서는 명령어들의 임의의 시퀀스를 처리할 수 있는 임의의 장치를 포함하거나 그의 일부일 수 있다. 프로세서는 예를 들어 컴퓨터 프로세서, 이동 장치 또는 다른 전자 장치 내의 프로세서 및/또는 디지털 프 로세서를 포함할 수 있다. 프로세서는 예를 들어, 서버 컴퓨팅 디바이스, 서버 컴퓨터, 일련의 서버 컴퓨 터들, 서버 팜, 클라우드 컴퓨터, 컨텐츠 플랫폼, 이동 컴퓨팅 장치, 스마트폰, 태블릿, 셋톱 박스, 미디어 플 레이어 등에 포함될 수 있다. 프로세서는 버스를 통해 메모리에 접속될 수 있다. 메모리는 컴퓨터 시스템에 의해 사용되거나 그에 의해 출력되는 정보를 저장하기 위한 휘발성 메모리, 영구, 가상 또는 기타 메모리를 포함할 수 있다. 메모리는 예를 들어 랜덤 액세스 메모리(RAM: random access memory) 및/또는 동적 RAM(DRAM: dynamic RAM)을 포함할 수 있다. 메모리는 컴퓨터 시스 템의 상태 정보와 같은 임의의 정보를 저장하는 데 사용될 수 있다. 메모리는 예를 들어 수계오염원 모니터링을 위한 명령어들을 포함하는 컴퓨터 시스템의 명령어들을 저장하는 데에도 사용될 수 있다. 컴 퓨터 시스템은 필요에 따라 또는 적절한 경우에 하나 이상의 프로세서를 포함할 수 있다. 버스는 컴퓨터 시스템의 다양한 컴포넌트들 사이의 상호작용을 가능하게 하는 통신 기반 구조를 포함 할 수 있다. 버스는 예를 들어 컴퓨터 시스템의 컴포넌트들 사이에, 예를 들어 프로세서와 메 모리 사이에 데이터를 운반할 수 있다. 버스는 컴퓨터 시스템의 컴포넌트들 간의 무선 및/또는 유선 통신 매체를 포함할 수 있으며, 병렬, 직렬 또는 다른 토폴로지 배열들을 포함할 수 있다. 영구 저장 장치는 (예를 들어, 메모리에 비해) 소정의 연장된 기간 동안 데이터를 저장하기 위해 컴 퓨터 시스템에 의해 사용되는 바와 같은 메모리 또는 다른 영구 저장 장치와 같은 컴포넌트들을 포함할 수 있다. 영구 저장 장치는 컴퓨터 시스템 내의 프로세서에 의해 사용되는 바와 같은 비휘발성 메 인 메모리를 포함할 수 있다. 영구 저장 장치는 예를 들어 플래시 메모리, 하드 디스크, 광 디스크 또는 다른 컴퓨터 판독 가능 매체를 포함할 수 있다. 입출력 인터페이스는 키보드, 마우스, 음성 명령 입력, 디스플레이 또는 다른 입력 또는 출력 장치에 대한 인터페이스들을 포함할 수 있다. 구성 명령들 및/또는 수계오염원 모니터링을 위한 정보가 입출력 인터페이스 를 통해 수신될 수 있다. 네트워크 인터페이스는 근거리 네트워크 또는 인터넷과 같은 네트워크들에 대한 하나 이상의 인터페이스를 포함할 수 있다. 네트워크 인터페이스는 유선 또는 무선 접속들에 대한 인터페이스들을 포함할 수 있다. 구성 명령들 및/또는 수계오염원 모니터링을 위한 정보는 네트워크 인터페이스를 통해 수신될 수 있다. 또한, 다른 실시예들에서 컴퓨터 시스템은 도 1의 구성요소들보다 더 많은 구성요소들을 포함할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴퓨터 시스템 은 상술한 입출력 인터페이스와 연결되는 입출력 장치들 중 적어도 일부를 포함하도록 구현되거나 또 는 트랜시버(transceiver), GPS(Global Positioning System) 모듈, 카메라, 각종 센서, 데이터베이스 등과 같 은 다른 구성요소들을 더 포함할 수도 있다. 도 2는 일 실시예에 따른 이미지 딥러닝 뉴럴 네트워크의 학습 방법을 설명하기 위한 도면이다. 도 2를 참조하면, 일 실시예에 따른 이미지 딥러닝 뉴럴 네트워크를 이용하여 자동으로 오염원을 검출 및 분류 할 수 있다. 이미지 딥러닝 뉴럴 네트워크의 학습을 위해 데이터를 수집한 후, 이미지 딥러닝 뉴럴 네트 워크의 입력 데이터를 생성할 수 있다. 이미지 딥러닝 뉴럴 네트워크를 통해 입력 데이터를 분석 및 해석 하고, 영상을 분류할 수 있으며, 결과를 통해 정확성을 검증할 수 있다. 예를 들어, 데이터의 수집 시 드론(무인비행체)을 이용하여 영상을 촬영하고, 촬영된 영상을 전처리하여 정사영상을 생성할 수 있고, 입력 데이터의 생성 시 NDVI, NDRE, NDBI, 열적외선 정보 및 높이, 위치, 경 사, 평면 정보 등을 활용할 수 있다. 또한, 분석 및 해석 시 구역통계기법, 사분위수기법, Norm.dist 함수 등을 활용하여 분석하고, 프로파일, 상자그림, 분산 그래프 등으로 분석결과를 표시 할 수 있으며, 분석결과에 대한 해석을 할 수 있다. 분석 후 분류항목을 설정하고, 학습 데이터 를 통한 영상을 분류할 수 있다. 이후, 정확성을 검증하고 효율성을 비교할 수 있다. 보다 구체적으로, 이미지 딥러닝 뉴럴 네트워크의 학습을 위해 각종 오염원을 RGB, 다중분광, 열적외선 카메라 로 촬영한 영상과, 오염원 종류별로 레이블을 결합하여 학습 데이터를 생성할 수 있다. 이 때, 비점오염원이 등록된 위치로 드론을 무인비행하여, 비점오염원에 대한 RGB, 다중분광, 열적외선 영상 데이터를 자동으로 획득 할 수 있다. 또한, 오브젝트 디텍션(object detection)을 통해 오염원으로 판별된 영역의 영상을 집중 촬영하 도록 무인비행경로 설정할 수 있다. 오브젝트 디텍션을 통해 검출된 영역을 적어도 1회 이상의 서로 다른 관점 에서 촬영할 수 있으며, 예를 들어 촬영 각도, 위치, 포커싱 등을 변경하여 서로 다른 관점에서 촬영할 수 있다. 생성된 학습 데이터를 통해 이미지 딥러닝 뉴럴 네트워크를 학습할 수 있다. 이 때, RGB, 다중분광, 열적외선 영상을 정합한 하나의 영상으로 학습시키는 이미지 딥러닝 뉴럴 네트워크의 구성이 가능하고, 개별적으로 학습 한 후 최종적으로 합치는 이미지 딥러닝 뉴럴 네트워크의 구성도 가능하다. 이미지 딥러닝 뉴럴 네트워크의 학습이 완료되면, 모니터링하고자 하는 지역의 영상을 획득한 후 이미지 처리를 통해 정사영상으로 변환할 수 있다. 그리고, 정사영상에서 오염원으로 의심되는 영역의 RGB, 다중분광, 열적외 선 영상을 이미지 딥러닝 뉴럴 네트워크에 입력하여, 오염원의 종류 및 상태 파악하여 정사영상에 매칭하여 표 시할 수 있다. 정사영상에 매칭된 오염원의 종류 및/또는 상태에 따라 비점오염원을 모니터링할 수 있다. 아래에서는 드론의 자율비행 경로 설정을 통한 오염원 분석 영상을 획득하는 방법을 예를 들어 설명한다. 드론은 모니터링 지역을 높은 고도에서 스캔하며 이동할 수 있다. 이 때 드론은 RGB 영상만 촬영할 수 있다. 이후, 드론이 스캔한 영상들을 가벼운 프로그램인 오브젝트 디텍션을 통해 오염원의 유무만을 파악할 수 있다. 오브젝트 디텍션으로 오염원 검출되면, 드론이 오염원 영역 측으로 자율비행 할 수 있다. 오염원 영역 (bounding box)을 통해 파악한 후, 적어도 둘 이상의 위치, 각도, 포커싱을 달리하여 촬영하며, 이 때 RGB 영상 뿐만 아니라 다중분광, 열적외선 영상을 획득할 수 있다. 각 영상들을 각각 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원 종류를 이미지 분류(image classification)할 수 있다. 그리고 각 분류된 오염원을 이미지 세그멘테이션(image segmentation)을 통해 오 염원의 상태까지 정밀 파악할 수 있다. 이후, 파악된 오염원의 정보를 정사영상에 매칭하여, 전체영역에서 오 염원 분포 및 정보를 모니터링 하도록 제공할 수 있다. 도 3은 일 실시예에 따른 수계오염원 모니터링 시스템을 나타내는 블록도이다. 도 3은 도 1의 일 실시예에 따른 컴퓨터 시스템의 프로세서가 포함할 수 있는 구성요소의 예를 도시한 도 면이다. 여기서, 컴퓨터 시스템의 프로세서는 일 실시예에 따른 수계오염원 모니터링 시스템을 포함할 수 있다. 일 실시예에 따른 수계오염원 모니터링 시스템은 입력 데이터 생성부, 분석 및 해 석부, 그리고 정보 표시부를 포함하여 이루어질 수 있다. 또한 실시예에 따라 영상 수집부, 모 델 학습부를 더 포함하여 이루어질 수 있다. 프로세서 및 프로세서의 구성요소들은 도 4의 수계오염원 모니터링 방법이 포함하는 단계들(410 내지 460)을 수행할 수 있다. 예를 들어, 프로세서 및 프로세서의 구성요소들은 메모리가 포함하는 운영체제의 코드와 상술한 적어도 하나의 프로그램 코드에 따른 명령(instruction)을 실행하도록 구현될 수 있 다. 여기서, 적어도 하나의 프로그램 코드는 수계오염원 모니터링 방법을 처리하기 위해 구현된 프로그램의 코 드에 대응될 수 있다. 수계오염원 모니터링 방법은 도시된 순서대로 발생하지 않을 수 있으며, 단계들 중 일부가 생략되거나 추가의 과정이 더 포함될 수 있다. 도 4는 일 실시예에 따른 수계오염원 모니터링 방법을 나타내는 흐름도이다. 도 4를 참조하면, 일 실시예에 따른 컴퓨터 장치를 통해 구현되는 인공지능 기반 수계오염원 모니터링 방법은, 모니터링 대상 지역의 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 이용하여 입력 데이터를 생성하는 단계, 입력 데이터를 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류 또는 상태 에 대한 정보를 분석하는 단계, 및 오염원을 모니터링하도록 이미지의 위치 정보를 활용하여 오염원의 종 류 또는 상태에 대한 정보를 표시하는 단계를 포함하여 이루어질 수 있다. 또한, 드론의 자율비행 경로의 설정을 통한 오염원에 대한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이 상의 영상을 획득하는 단계를 더 포함하고, 영상을 이용하여 입력 데이터를 생성할 수 있다. 또한, 오염원을 촬영한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상과, 오염원 종류별로 레이 블을 결합하여 학습 데이터를 생성하는 단계, 및 생성된 학습 데이터를 이용하여 이미지 딥러닝 뉴럴 네트 워크를 학습시키는 단계를 더 포함할 수 있다. 아래에서는 일 실시예에 따른 수계오염원 모니터링 방법을 일 실시예에 따른 수계오염원 모니터링 시스템을 예 를 들어 설명한다. 먼저, 단계에서, 영상 수집부는 드론의 자율비행 경로의 설정을 통한 오염원에 대한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 획득할 수 있다. 이 때, 영상 수집부는 오염원에 대한 RGB, 다중분광 및 열적외선 영상을 모두 획득하여 입력 데이터를 생성할 수 있다. 영상 수집부는 오염원에 대한 RGB, 다중분광 및 열적외선 영상을 이용하여 입력 데이터를 형성하거나, 획 득한 오염원에 대한 RGB, 다중분광 및 열적외선 영상을 후처리 프로그램을 통해 정사영상으로 변환하여 입력 데 이터를 형성할 수 있다. 예를 들어, 영상 수집부는 드론의 자율비행 경로의 설정에 따라 모니터링 대상 지역의 영상을 RGB, 다중분광 및 열적외선으로 촬영한 후, 이미지 처리를 통해 정사영상으로 변환할 수 있다. 그리고, 입력 데이터 생성부는 정사영상에서 오염원으로 의심되는 영역의 RGB, 다중분광 및 열적외선 영상 을 이용하여 입력 데이터를 형성할 수 있다. 영상 수집부는 드론이 모니터링 지역을 소정 높이의 고도에서 스캔하며 이동하여, RGB 영상을 획득하고, RGB 영상을 오브젝트 디텍션(object detection)을 통해 오염원의 유무를 확인한 후, 오브젝트 디텍션을 통해 오 염원이 검출되는 경우, 드론이 오염원이 검출된 영역을 집중 촬영하도록 비행경로를 설정하고, 설정된 비행경로 에 따라 드론이 이동하며 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 집중 촬영할 수 있다. 이 때, 영상 수집부는 드론이 위치, 각도 및 포커싱 중 적어도 어느 하나 이상의 설정을 변경하여 집중 촬 영하여 서로 다른 관점에서의 영상을 획득할 수 있다. 한편, 모델 학습부를 통해 이미지 딥러닝 뉴럴 네트워크를 학습시킬 수 있다. 단계에서, 모델 학습부는 오염원을 촬영한 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상과, 오염원 종류별로 레이블을 결합하여 학습 데이터를 생성할 수 있다. 단계에서, 모델 학습부는 생성된 학습 데이터를 이용하여 이미지 딥러닝 뉴럴 네트워크를 학습시킬 수 있다. 모델 학습부는 생성된 학습 데이터를 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원의 종류를 이미지 분류(image classification)한 후, 분류된 각 오염원을 이미지 세그멘테이션(image segmentation)을 통 해 오염원의 상태를 파악할 수 있다. 여기서, 이미지 딥러닝 뉴럴 네트워크는 RGB, 다중분광 및 열적외선 영상 을 정합한 하나의 영상으로 학습하여 구성하거나, RGB, 다중분광 및 열적외선 영상을 개별적으로 학습한 후 최 종적으로 결합하여 구성할 수 있다. 이에 따라 학습된 이미지 딥러닝 뉴럴 네트워크에 모니터링 대상 지역의 영상을 입력하여 오염원의 정보를 분석 할 수 있다. 단계에서, 입력 데이터 생성부는 모니터링 대상 지역의 RGB, 다중분광 및 열적외선 중 적어도 어느 하나 이상의 영상을 이용하여 입력 데이터를 생성할 수 있다. 단계에서, 분석 및 해석부는 입력 데이터를 학습된 이미지 딥러닝 뉴럴 네트워크에 입력하여 오염원 의 종류 또는 상태에 대한 정보를 분석할 수 있다. 단계에서, 정보 표시부는 오염원을 모니터링하도록 이미지의 위치 정보를 활용하여 오염원의 종류 또 는 상태에 대한 정보를 표시할 수 있다. 예를 들어, 정보 표시부는 오염원의 종류 또는 상태에 대한 정보 를 정사영상에 매칭하여 표시하여 비점오염원을 모니터링할 수 있다. 이와 같이, 일 실시예에 따른 인공지능 기반 수계오염원 모니터링 시스템 및 방법은 드론을 이용한 촬영을 통해 RGB, 다중분광 및 열적외선 영상을 획득하여, 이미지 딥러닝 뉴럴 네트워크를 학습시켜 오염원 탐지를 실행시킬 수 있고, 탐지 결과를 표시하여 모니터링할 수 있다.도 5는 일 실시예에 따른 이미지 딥러닝 뉴럴 네트워크의 기초 학습 및 강화 학습의 수행 예시를 나타내는 도면 이다. 도 5의 (a) 내지 (c)에 도시된 바와 같이, 획득한 영상을 이미지 딥러닝 뉴럴 네트워크에 입력하여 인공지능을 이용한 오염원을 탐지할 수 있다. 최적의 알고리즘 기반의 학습 모델을 통해 기초 학습 및 강화 학습 과정을 반복 수행함으로써 이미지 딥러닝 뉴럴 네트워크를 학습시킬 수 있다. 도 6은 일 실시예에 따른 이미지 딥러닝 뉴럴 네트워크의 오염원 탐지 예시를 나타내는 도면이다. 도 6에 도시된 바와 같이, 드론에서 촬영한 이미지를 등록(a)하여 오염원을 탐지(b)할 수 있다. 예를 들어, 오 염원 탐지는 임계점에 해당하는 이미지 분류하고, 식생지수 및 주변환경 등 정보를 이용하여 오염원과 비슷할수 록 가중치를 적용할 수 있다. 이는 다시 학습 모델(이미지 딥러닝 뉴럴 네트워크)에 적용하여 재학습시킬 수 있다. 도 7은 일 실시예에 따른 히트맵 및 클러스터 분포의 예시를 나타내는 도면이다. 도 7의 (a) 내지 (c)에 도시된 바와 같이, 오염원의 탐지 결과를 히트맵 또는 클러스터 분포 등으로 나타낼 수 있다. 즉, 오염원의 탐지 결과를 이용하여 탐지 결과에 대한 위치 정보 기반 데이터베이스(예컨대, GIS DB)를 구축하거나, 웹 (Web) 기반 GIS DB 검색 시스템, Heat Map 형태의 분포지도, 클러스터 형태의 분포지도 등으로 나타낼 수 있다. 아래에서는 인공지능 기반 수계오염원 모니터링 시스템을 이용한 실험 예시로서, 야적퇴비 탐지 방법 및 결과에 대해 설명한다. 도 8은 일 실시예에 따른 야적퇴비 탐지를 위한 모듈 구조의 예시를 나타내는 도면이다. 도 8을 참조하면, 단계에서, 전처리에서 YOLO 모델에 적합한 데이터 형태로 만들어 주기 위해서 이미지 크 기를 [5472x3648] 사이즈에서 [416x416] 사이즈로 크기조정(resizing)을 하였으며, 이미지 픽셀값(pixel value)은 [0,255]에서 [0,1] 범위로 스케일링하여 분석하였다. 단계에서, 이미지 레이블링(image labeling)을 통해 야적퇴비 탐지 학습 데이터를 구축할 수 있다. 하나의 예시로서, 단계에서, Hyperparameters 중에서 score_threshold는 0.5로 설정하고, IOU_threshold는 0.3으로 설정할 수 있다. 출력 값이 설정된 임계값 보다 큰 경우, 단계에서 YOLO 모델에 전달하고, 단계에서 출력을 표시하며, 단계 에서 결과를 저장한다. 한편, 출력값이 설정된 임계값 보다 작거나 같은 경우, 단계에서 입력 데이 터를 폐기한다. 도 9는 일 실시예에 따른 야적퇴비 탐지 결과의 예시를 나타낸다. 도 9에 도시된 바와 같이, 야적퇴비 탐지 결 과를 이미지에 표시하여 모니터링하도록 할 수 있다. 도 10은 일 실시예에 따른 드론을 이용한 학습 데이터 구축 방법을 설명하기 위한 도면이다. 도 10을 참조하면, 먼저 드론 촬영을 위해 촬영 계획을 수립하고, 촬영 및 비행 승인을 허가 받을 수 있다. 이후, 드론 촬영을 통해 드론의 이미지 기반 학습 데이터를 구축하거나 드론 정사영상 기반 학습 데 이터를 구축할 수 있다. 일 예로, 드론 촬영을 통해 RGB, 다중분광, 열적외선 영상을 획득하고, 드론의 이미지 기반 학습 데이터를 구축할 수 있다. 드론 이미지 기반 학습 데이터를 이용하여 학습을 한 경우 이미지의 위치 정 보를 활용하여 오염원의 위치 정보를 표기할 수 있다. 다른 예로, 드론 영상을 후처리 프로그램을 통해 이미지의 왜곡 및 위치 정확도를 보정(1060, 1070)하고, 영상 정합을 통해 드론 정사영상(2차원 영상지도)을 획득함으로써, 드론 정사영상 기반 학습 데이터를 구축 할 수 있다. 드론 정사영상 기반 학습 데이터를 이용하여 학습을 한 경우 오브젝트 디텍션 영역을 공간 적인 위치와 형태를 표현할 수 있는 shape 파일 형식으로 변환함으로써, 오염원의 위치 정보를 표기할 수 있다. 도 11은 일 실시예에 따른 오염원 분류 정확도 향상 방법을 설명하기 위한 도면이다. 도 11을 참조하면, 단계에서, 영상 정보의 특성을 분석하고 영상을 분류할 수 있다. 예를 들어 학습 이 미지의 GPS, 날짜 정보 등을 활용하여 오염원을 분류하여 1차 데이터베이스(DB)를 구축하고 분류 확률을 산정할 수 있다.단계에서, 오염원을 분류할 수 있으며, 여기서 식생지수, 피복도 등 관련 학습 정보를 활용하여 가중치를 설정할 수 있고, 1차 분류 확률에 부여된 가중치를 적용하여 2차 분류 확률을 산정할 수 있다. 단계에서, 데이터를 학습할 수 있다. 예를 들어 2차 분류 확률이 1차 임계값 미포함일 경우 분류된 학습 이미지는 학습 데이터로 활용할 수 있고, 1차 임계값 포함일 경우 분류된 학습 이미지를 휴리스틱 기법으로 재 분류한 뒤 학습 데이터로 활용할 수 있다. 단계에서, 데이터를 저장할 수 있다. 예를 들어 학습 및 분류 완료된 이미지의 관련 학습 정보를 1차 데 이터베이스에 추가하여 2차 데이터베이스를 구축할 수 있다. 이와 같이, 기초 모델 학습부터 기초 학습 및 강화학습 과정을 반복 수행하여 정확도를 향상시킬 수 있다. 또 한 학습 모델의 정확도를 향상시키기 위해 요인을 분석하고, 국가공간정보 자료, 식생지수 자료 등 추가적인 학 습 데이터를 활용하여 가중치를 부여함으로써 학습 모델의 정확도를 향상시킬 수 있다. 이상과 같이, 실시예들에 따르면 RGB, 다중분광, 열적외선 영상을 각각 또는 정합하여 학습시킨 이미지 딥러닝 뉴럴 네트워크를 통해 오염원 자동 판별할 수 있다. 또한, 오브젝트 디텍션을 통한 드론 자율비행을 통해 오염 원 영역의 영상 데이터를 획득할 수 있다. 그리고 판별된 오염원을 정사지도에 매칭시켜 정확한 오염원 위치에 오염원 정보를 표기함으로써 감시 영역을 모니터링할 수 있다. 도 12는 일 실시예에 따른 인공지능 기반 수계오염원 모니터링 시스템의 활용 방법을 설명하기 위한 도면이다. 도 12를 참조하면, 드론을 이용한 촬영 영상, 항공 사진, 위성 영상 등의 영상 정보를 획득하여, 인공지 능 기반으로 오염원을 추출할 수 있으며, 이 때 오염원의 분포 정보를 추출할 수 있다. 이에 따라 중앙 부처 등에서는 환경 공간 정보 서비스 등 오염원의 정보를 제공하여 오염원을 모니터링하고 관리할 수 있 다. 또한, 지자체 등에서는 지적도 내 오염원 정보를 구축하여 오염원의 배출을 감시하고 관리할 수 있 다. 또한, 강우 대비 오염원 관리를 안내할 수 있으며, 예컨대 기상 정보를 활용하여 사용자 단말 등으로 오염 원 관리를 요하는 알림 메시지를 발송할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 컨트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2021-0016311", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2021-0016311", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 컴퓨터 장치(시스템)의 내부 구성의 일례를 설명하기 위한 블록도이다. 도 2는 일 실시예에 따른 이미지 딥러닝 뉴럴 네트워크의 학습 방법을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 수계오염원 모니터링 시스템을 나타내는 블록도이다. 도 4는 일 실시예에 따른 수계오염원 모니터링 방법을 나타내는 흐름도이다. 도 5는 일 실시예에 따른 이미지 딥러닝 뉴럴 네트워크의 기초 학습 및 강화 학습의 수행 예시를 나타내는 도면 이다. 도 6은 일 실시예에 따른 이미지 딥러닝 뉴럴 네트워크의 오염원 탐지 예시를 나타내는 도면이다. 도 7은 일 실시예에 따른 히트맵 및 클러스터 분포의 예시를 나타내는 도면이다. 도 8은 일 실시예에 따른 야적퇴비 탐지를 위한 모듈 구조의 예시를 나타내는 도면이다. 도 9는 일 실시예에 따른 야적퇴비 탐지 결과의 예시를 나타낸다. 도 9에 도시된 바와 같이, 야적퇴비 탐지 결 과를 이미지에 표시하여 모니터링하도록 할 수 있다. 도 10은 일 실시예에 따른 드론을 이용한 학습 데이터 구축 방법을 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 오염원 분류 정확도 향상 방법을 설명하기 위한 도면이다. 도 12는 일 실시예에 따른 인공지능 기반 수계오염원 모니터링 시스템의 활용 방법을 설명하기 위한 도면이다."}
