{"patent_id": "10-2023-0066866", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0014027", "출원번호": "10-2023-0066866", "발명의 명칭": "음성 및 텍스트 데이터 생성시스템", "출원인": "김운", "발명자": "김운"}}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상컨텐츠에서 딥러닝 기반의 음성인식모델을 통해 추출된 제1 언어의 음성데이터를 제2 언어의 텍스트데이터로 기계 번역처리하는 음성 및 텍스트데이터 생성시스템으로서, 상기 제1 언어의 음성데이터로부터 추출되는 특정프레임마다 검출되는 특정문장의 소리높낮이를 기설정된 주파수대역 그래프에 맵핑함에 따라, 음성주파수 곡선을 드로잉하는 드로잉부;상기 음성주파수 곡선을 인공지능 기반의 장르유형 분류모델에 적용함에 따라 도출되는 출력값에 기초하여, 상기 대상키워드에 대한 장르유형을 분류하는 장르분류부;상기 특정문장으로부터 검출된 대상키워드에 기초하여, 상기 장르유형에 따라 기수집된 동의어 단어사전으로부터 장르키워드를 탐색하는 키워드탐색부; 및상기 장르키워드에 기초하여, 상기 제2 언어의 텍스트데이터의 상기 대상키워드에 대응되는 번역키워드를 수정하는 번역관리부를 포함하는, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 대상키워드는 제1 언어이고, 상기 번역키워드와 상기 장르키워드는 제2 언어인, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 번역관리부는 기설정된 Levenshtein Distance 알고리즘을 이용하여 상기 번역키워드와 기등록된 비속어 단어 간의 편집거리 유사도 값을 산출하고, 상기 편집거리 유사도 값에 기초하여, 상기 번역키워드를 특수기호문자로 변환처리하는, 음성 및 텍스트데이터생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 번역관리부는 상기 제1 언어의 텍스트데이터로부터 확인되는 프레임구간별 글자수에 따라 영상재생속도가조절된 검수용 영상컨텐츠를 음성검수 서비스를 기등록된 검수자단말에 제공하고, 상기 기등록된 검수자단말로부터 상기 음성검수 서비스를 통해 입력받는 상기 제1 언어의 텍스트데이터에 대한텍스트 검수개수에 기초하여, 상기 검수용 영상컨텐츠에 대한 자막 글자 크기를 조절하는, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 번역관리부는 기등록된 검수자단말에 목소리별 청각 호감도 테스트를 제공함에 따라 응답받는 응답정보에기초하여, 음도, 속도, 음질, 강도, 쉼, 억양, 공명에 대한 호감특성 파라미터를 추정하고, 상기 호감특성 파라미터에 따라, 상기 검수용 영상컨텐츠의 제1 언어의 음성데이터를 기설정된 음성변조 프로그램을 통해 변조하며, 상기 기설정된 음성변조 프로그램은 마이 에딧, 파워디렉터, 보이스모드, AV 보이스 체인저, 오다시티, VOXAL공개특허 10-2024-0014027-3-중 어느 하나인, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서, 상기 번역관리부는 상기 기설정된 음성변조 프로그램을 통해 변조할 때, 기본음성 주파수의 음성세기를 증가시키는 동시에 저주파 및 고주파 신호의 음성세기를 감소시키며, 상기 기본음성 주파수는 85 ~ 120Hz 주파수 범위이고, 상기 저주파 신호는 0 ~ 85 Hz 주파수 범위이며, 상기 고주파 신호는 120 ~ 400 Hz 주파수 범위인, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 번역관리부는 상기 대상키워드에 대응되는 적어도 하나의 영상프레임으로부터 얼굴 인식된 화자객체와 상기 음성주파수 곡선으로부터 음절구간별 진폭세기범위와 시간구간에 따라 식별되는 화자객체별 음성에기초하여, 상기 영상컨텐츠에 대한 인물관계 네트워크를 도식화하는, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 번역관리부는 상기 제1 및 제2 언어의 텍스트데이터를 상기 영상컨텐츠에 표시하여 재생시킴에 따라 일정시간마다 캡쳐링되는 캡쳐링이미지를 이용하여, 번역참가 자격을 부여하기 위한 번역테스트용 콘텐츠를 생성하고, 상기 번역테스트용 콘텐츠를 프로젝트게시판에 공유함에 따라 복수의 참여자단말로부터 전송받는 각 응답정보에기초하여, 상기 제2 언어의 텍스트데이터에 대한 접속권한을 선택적으로 부여하는, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 번역관리부는 상기 영상컨텐츠로부터 상기 제1 언어의 음성데이터를 추출하는 음성추출부; 상기 제1 언어의 음성데이터를 재생함에 따라 출력되는 음성을 번역제공 웹서버를 통해 인식하여 제1 언어의 텍스트데이터를 생성하는 텍스트생성부;상기 영상컨텐츠에 상기 제1 언어의 텍스트데이터를 자막으로 표시하여 음성검수 서비스를 통해 기등록된 검수자단말에 검수용 영상컨텐츠를 제공함에 따라 응답받는 검수데이터에 기초하여, 상기 제1 언어의 텍스트데이터를 검수하는 검수부; 및상기 제1 언어의 텍스트데이터를 상기 번역제공 웹서버를 통해 제2 언어의 텍스트데이터로 자동으로 기계 번역하는 번역처리부를 포함하고, 상기 검수부는 상기 검수용 영상컨텐츠를 기등록된 검수자단말에 제공할 때, 상기 제1 언어의 텍스트데이터의프레임구간별 글자수에 반비례하도록 상기 검수용 영상컨텐츠에 대한 재생속도를 조절하는, 음성 및 텍스트데이터 생성시스템."}
{"patent_id": "10-2023-0066866", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 검수부는 상기 검수용 영상컨텐츠를 상기 기등록된 검수자단말에 제공할 때, 상기 기등록된 검수자단말에구비된 레이더 센서를 통해 측정된 검수자의 심박 및 호흡신호에 기초하여, 상기 검수데이터에 대한 피드백 제한기간을 연장하도록 스케줄링하는, 음성 및 텍스트데이터 생성시스템.공개특허 10-2024-0014027-4-"}
{"patent_id": "10-2023-0066866", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 음성 및 텍스트데이터 생성시스템에 관한 것으로서, 영상컨텐츠에서 인식된 음성을 텍스트화하는 동시 에 기계 번역한 텍스트데이터에 대하여, 장르유형에 따른 맞춤형키워드를 반영할 수 있는 음성 및 텍스트데이터 생성시스템에 관한 것이다. 이를 위해, 영상컨텐츠에서 딥러닝 기반의 음성인식모델을 통해 추출된 제1 언어의 (뒷면에 계속)"}
{"patent_id": "10-2023-0066866", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 및 텍스트데이터 생성시스템에 관한 것으로서, 영상컨텐츠에서 인식된 음성을 텍스트화하는 동 시에 기계 번역한 텍스트데이터에 대하여, 장르유형에 따른 맞춤형키워드를 반영할 수 있는 음성 및 텍스트데이 터 생성시스템에 관한 것이다."}
{"patent_id": "10-2023-0066866", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어 네트워크(인터넷 망) 및 전자 기술을 발전으로 네트워크에 가입하는 가입자들이 폭발적으로 증가하고 있으며, 이에 따라 네트워크를 통해 제공되는 서비스의 종류 역시 다양해지고 있다. 일반적인 네트워크 서비스는 포탈 사이트를 통한 검색 서비스, 블로그 서비스, 메일 서비스 등이 있으나, 최근 많은 가입자들은 서비스 제공자에 의해 제공되는 정보를 이용하는 수동적인 입장에 그치지 않고, 능동적으로 컨 텐츠를 제작하여 네트워크를 통해 공유하고 있다. 동영상은 네트워크 상에서 가입자들간의 새로운 문화로 자리매김하여 많은 가입자들이 네트워크의 포탈 사이트 를 통해 동영상을 이용하거나, 동영상을 자체 제작하여 다른 가입자들에게 제공하고 있으며, 가입자 입장에서 컨텐츠의 재창조 또는 재해석 등과 같은 측면에서 긍정적인 역할을 하고 있다. 이러한, 동영상은 네트워크 상으로 제공되기 때문에 지역적 구분없이 모든 가입자들이 제공받을 수 있다는 장점 을 가지는데 반해, 제작되는 동영상의 언어가 각 국가 또는 사용 언어별 지역에 따라 상이하기 때문에 외국어 번역 능력에 따라 가입자들이 사용할 수 있는 동영상이 제한적이 될 수밖에 없는 현실이다. 예를 들어, 영어권 국가의 가입자가 국내 가입자가 자체 제작한 동영상을 이용하고자 하는 경우, 국내 가입자는 한국어를 기반으로 동영상을 제작하기 때문에 영어권 가입자가 한국어 능력이 떨어지면, 한국어 기반의 동영상 을 적절하게 이용하지 못하게 된다. 한편, 기계 번역은 컴퓨터를 이용하여 서로 다른 언어를 번역하는 것을 의미한다. 예를 들어, 기계 번역은 소스 언어인 제1 언어(예컨대, 한국어)의 텍스트를 타겟 언어인 제2 언어(예컨대, 영어)의 텍스트로 번역할 수 있다. 한국어로 제작된 동영상을 영어권 가입자가 용이하게 감상할 수 있도록 전술한 기계 번역을 이용할 수 있다. 그 러나, 현재 개발된 다양한 기계 번역 엔진은 한국어를 영어로 번역할 때, 영어의 일상 생활 표현을 명확히 표현 하지 못하고 있는 실정이다. 따라서, 영어의 일상 생활 표현을 명확히 표현할 수 있도록 기계 번역 결과를 수정 및 보완할 수 있는 기술이 필요하다."}
{"patent_id": "10-2023-0066866", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위한 것으로서, 본 발명의 목적은 영상컨텐츠에서 인식된 음성을 텍 스트화하는 동시에 기계 번역한 텍스트데이터에 대하여, 장르유형에 따른 맞춤형키워드를 반영할 수 있는 음성 및 텍스트데이터 생성시스템을 제공하기 위한 것이다. 본 발명의 상기 및 다른 목적과 이점은 바람직한 실시예를 설명한 하기의 설명으로부터 분명해질 것이다."}
{"patent_id": "10-2023-0066866", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명의 일실시예에 따른 영상컨텐츠에서 딥러닝 기반의 음성인식모델을 통해 추출된 제1 언어의 음성데이터를 제2 언어의 텍스트데이터로 기계 번역처리하는 음성 및 텍스트데이터 생 성시스템으로서, 상기 제1 언어의 음성데이터로부터 추출되는 특정프레임마다 검출되는 특정문장의 소리높낮이 를 기설정된 주파수대역 그래프에 맵핑함에 따라, 음성주파수 곡선을 드로잉하는 드로잉부, 상기 음성주파수 곡 선을 인공지능 기반의 장르유형 분류모델에 적용함에 따라 도출되는 출력값에 기초하여, 상기 대상키워드에 대 한 장르유형을 분류하는 장르분류부, 상기 특정문장으로부터 검출된 대상키워드에 기초하여, 상기 장르유형에 따라 기수집된 동의어 단어사전으로부터 장르키워드를 탐색하는 키워드탐색부 및 상기 장르키워드에 기초하여,상기 제2 언어의 텍스트데이터의 상기 대상키워드에 대응되는 번역키워드를 수정하는 번역관리부를 포함한다. 실시예에 있어서, 상기 대상키워드는 제1 언어이고, 상기 번역키워드와 상기 장르키워드는 제2 언어이다. 실시예에 있어서, 상기 번역관리부는 기설정된 Levenshtein Distance 알고리즘을 이용하여 상기 번역키워드와 기등록된 비속어 단어 간의 편집거리 유사도 값을 산출하고, 상기 편집거리 유사도 값에 기초하여, 상기 번역키 워드를 특수기호문자로 변환처리한다. 실시예에 있어서, 상기 번역관리부는 상기 제1 언어의 텍스트데이터로부터 확인되는 프레임구간별 글자수에 따 라 영상재생속도가 조절된 검수용 영상컨텐츠를 음성검수 서비스를 기등록된 검수자단말에 제공하고, 상기 기등 록된 검수자단말로부터 상기 음성검수 서비스를 통해 입력받는 상기 제1 언어의 텍스트데이터에 대한 텍스트 검 수개수에 기초하여, 상기 검수용 영상컨텐츠에 대한 자막 글자 크기를 조절한다. 실시예에 있어서, 상기 번역관리부는 기등록된 검수자단말에 목소리별 청각 호감도 테스트를 제공함에 따라 응 답받는 응답정보에 기초하여, 음도, 속도, 음질, 강도, 쉼, 억양, 공명에 대한 호감특성 파라미터를 추정하고, 상기 호감특성 파라미터에 따라, 상기 검수용 영상컨텐츠의 제1 언어의 음성데이터를 기설정된 음성변조 프로그 램을 통해 변조하며, 상기 기설정된 음성변조 프로그램은 마이 에딧, 파워디렉터, 보이스모드, AV 보이스 체인 저, 오다시티, VOXAL 중 어느 하나이다. 실시예에 있어서, 상기 번역관리부는 상기 기설정된 음성변조 프로그램을 통해 변조할 때, 기본음성 주파수의 음성세기를 증가시키는 동시에 저주파 및 고주파 신호의 음성세기를 감소시키며, 상기 기본음성 주파수는 85 ~ 120Hz 주파수 범위이고, 상기 저주파 신호는 0 ~ 85 Hz 주파수 범위이며, 상기 고주파 신호는 120 ~ 400 Hz 주 파수 범위이다. 실시예에 있어서, 상기 번역관리부는 상기 대상키워드에 대응되는 적어도 하나의 영상프레임으로부터 얼굴 인식 된 화자객체와 상기 음성주파수 곡선으로부터 음절구간별 진폭세기범위와 시간구간에 따라 식별되는 화자객체별 음성에 기초하여, 상기 영상컨텐츠에 대한 인물관계 네트워크를 도식화한다. 실시예에 있어서, 상기 번역관리부는 상기 제1 및 제2 언어의 텍스트데이터를 상기 영상컨텐츠에 표시하여 재생 시킴에 따라 일정시간마다 캡쳐링되는 캡쳐링이미지를 이용하여, 번역참가 자격을 부여하기 위한 번역테스트용 콘텐츠를 생성하고, 상기 번역테스트용 콘텐츠를 프로젝트게시판에 공유함에 따라 복수의 참여자단말로부터 전 송받는 각 응답정보에 기초하여, 상기 제2 언어의 텍스트데이터에 대한 접속권한을 선택적으로 부여한다. 실시예에 있어서, 상기 번역관리부는 상기 영상컨텐츠로부터 상기 제1 언어의 음성데이터를 추출하는 음성추출 부, 상기 제1 언어의 음성데이터를 재생함에 따라 출력되는 음성을 번역제공 웹서버를 통해 인식하여 제1 언어 의 텍스트데이터를 생성하는 텍스트생성부, 상기 영상컨텐츠에 상기 제1 언어의 텍스트데이터를 자막으로 표시 하여 음성검수 서비스를 통해 기등록된 검수자단말에 검수용 영상컨텐츠를 제공함에 따라 응답받는 검수데이터 에 기초하여, 상기 제1 언어의 텍스트데이터를 검수하는 검수부 및 상기 제1 언어의 텍스트데이터를 상기 번역 제공 웹서버를 통해 제2 언어의 텍스트데이터로 자동으로 기계 번역하는 번역처리부를 포함하고, 상기 검수부는 상기 검수용 영상컨텐츠를 기등록된 검수자단말에 제공할 때, 상기 제1 언어의 텍스트데이터의 프레임구간별 글 자수에 반비례하도록 상기 검수용 영상컨텐츠에 대한 재생속도를 조절한다. 실시예에 있어서, 상기 검수부는 상기 검수용 영상컨텐츠를 상기 기등록된 검수자단말에 제공할 때, 상기 기등 록된 검수자단말에 구비된 레이더 센서를 통해 측정된 검수자의 심박 및 호흡신호에 기초하여, 상기 검수데이터 에 대한 피드백 제한기간을 연장하도록 스케줄링한다."}
{"patent_id": "10-2023-0066866", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 영상컨텐츠에 대한 보다 정확한 번역 텍스트를 제공할 수 있다."}
{"patent_id": "10-2023-0066866", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시예와 도면을 참조하여 본 발명을 상세히 설명한다. 이들 실시예는 오로지 본 발명을 보다 구체적으로 설명하기 위해 예시적으로 제시한 것일 뿐, 본 발명의 범위가 이들 실시예에 의해 제한되지 않는다 는 것은 당업계에서 통상의 지식을 가지는 자에 있어서 자명할 것이다. 또한, 달리 정의하지 않는 한, 본 명세서에서 사용되는 모든 기술적 및 과학적 용어는 본 발명이 속하는 기술 분야의 숙련자에 의해 통상적으로 이해되는 바와 동일한 의미를 가지며, 상충되는 경우에는, 정의를 포함하는 본 명세서의 기재가 우선할 것이다. 도면에서 제안된 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하 여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 그리고, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포 함할 수 있는 것을 의미한다. 또한, 명세서에서 기술한 \"부\"란, 특정 기능을 수행하는 하나의 단위 또는 블록을 의미한다. 각 단계들에 있어 식별부호(제1, 제2, 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순 서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르 게 실시될 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 실시될 수도 있고 실질적으로 동시에 실시될 수도 있으며 반대의 순서대로 실시될 수도 있다. 도 1은 본 발명의 실시예에 따른 음성 및 텍스트데이터 생성시스템을 개략적으로 나타내는 도이고, 도 2 는 음성주파수 곡선에 대한 실시예이며, 도 3a 및 도 3b는 제1 및 제2 인물관계 네트워크에 대한 예시도이다. 도 1 내지 도 3b를 참조하여 설명하면, 음성 및 텍스트데이터 생성시스템은 드로잉부, 장르분류부 , 키워드탐색부 및 번역관리부를 포함할 수 있다. 이러한 음성 및 텍스트데이터 생성시스템은 영상컨텐츠에서 딥러닝 기반의 음성인식모델을 통해 추출된 제1 언어의 음성데이터를 제2 언어의 텍스트데이터로 기계 번역처리할 수 있다. 여기서, 영상컨텐츠는 의뢰업체 단말로부터 번역을 의뢰받은 영상을 의미할 수 있다. 먼저, 드로잉부는 제1 언어의 음성데이터로부터 특정프레임마다 검출되는 특정문장의 소리높낮이를 기설정 된 주파수대역 그래프에 맵핑함에 따라, 음성주파수 곡선을 드로잉할 수 있다. 예를 들면, 음성주파수 곡선은 도 2에 도시된 바와 같이, 기설정된 피치정보에 따라 특정문장에 대한 발성시간 을 가로축으로 하고, 특정문장에 대한 음성주파수를 세로축으로 하는 그래프일 수 있다. 다음으로, 장르분류부는 드로잉부를 통해 드로잉된 음성주파수 곡선을 인공지능 기반의 장르유형 분 류모델에 적용함에 따라 도출되는 출력값에 기초하여, 영상컨텐츠에 대한 장르유형을 분류할 수 있다. 예를 들면, 영상컨텐츠에 대한 장르유형은 액션, 모험, 애니메이션, 코미디, 범죄, 다큐, 드라마, 가족, 판타지, 누와르, 역사, 공포, 뮤지컬, 미스터리, 로맨스(멜로), 공상 과학, 스포츠, 스릴러, 전쟁, 서부극일 수 있다. 여기서, 인공지능 기반의 장르유형 분류모델은 기수집된 장르유형별 음성주파수 곡선을 머신러닝을 통해 학습함 에 따라 도출되는 인공신경망으로서, 인공 신경 회로망(Artificial Neural Network), SVM(Support Vector Machine), 의사 결정 트리(Decision Tree) 및 랜덤 포레스트(Random Forest) 중 어느 하나의 알고리즘일 수 있 다. 예를 들면, 인공 신경 회로망은 주로 딥러닝에서 사용되어 지고, 기계학습과 생물학의 신경망에서 영감을 얻은 통계학적 학습 알고리즘으로서, 특징 추출 신경망과 분류 신경망을 포함하는 컨볼루션 신경망일 수 있다. 이때, 컨볼루션 신경망은 시각적 이미지를 분석하는데 사용되는 깊고 피드포워드적인 인공 신경 회로망의 한종류로,이미지의 특징을 추출하고 클래스를 분류하는 과정으로 나누어질 수 있고, 특정 이미지의 특징을 추출하고 추출 된 특징을 기반으로 이미지를 인식할 수 있다. 다음으로, 키워드탐색부는 특정문장으로부터 검출되는 대상키워드에 기초하여, 장르유형에 따라 기수집된 동의어 단어사전으로부터 장르키워드를 탐색할 수 있다. 여기서, 대상키워드는 특정문장에서의 명사와 동사를 지시하는 키워드를 의미할 수 있다. 이때, 장르키워드는 기수집된 동의어 단어사전으로부터 장르유형에 따라 사전에 분류된 키워드로서, 대상키워드 와 동의어일 수 있다. 다음으로, 번역관리부는 대상키워드에 따라 기계 번역된 번역키워드를 장르키워드로 대체하여 변경함에 따 라, 제2 언어의 텍스트데이터를 수정할 수 있다. 여기서, 대상키워드는 제1 언어이고, 번역키워드와 장르키워드는 제2 언어일 수 있다. 일 실시예에 따라, 번역관리부는 기설정된 Levenshtein Distance 알고리즘을 이용하여, 번역키워드와 기등 록된 비속어 단어 간의 편집거리 유사도 값을 산출할 수 있다. 이때, 번역관리부는 편집거리 유사도 값에 기초하여, 번역키워드를 특수기호문자로 변환처리시킬 수 있다. 예를 들면, 유사도값이 기설정된 수치 이상인 경우 번역관리부는 번역키워드를 특수기호문자인 \"***\"로 변 환처리할 수 있다. 다른 실시예에 따라, 번역관리부는 영상컨텐츠에서 얼굴 인식된 화자 객체와 화자객체별 음성주파수 곡선 에 기초하여, 대립관계와 우호관계를 나타내는 제1 및 제2 인물관계 네트워크를 도식화하여 제2 언어의 텍스트 데이터에 병합할 수 있다. 여기서, 제1 및 제2 인물관계 네트워크는 도 3a 및 도 3b에 도시된 바와 같이, 대립관계와 우호관계를 서로 다 른 색상으로 나타내는 관계도일 수 있다. 또 다른 실시예에 따라, 번역관리부는 제1 및 제2 언어의 텍스트데이터를 영상컨텐츠에 이중자막으로 표시 하여 재생시킴에 따라 일정시간마다 캡쳐링되는 캡쳐링이미지를 이용하여, 번역테스트용 콘텐츠를 생성할 수 있 다. 여기서, 번역테스트용 콘텐츠는 복수의 참여자들에 대한 번역참가 자격을 선택적으로 부여하기 위한 번역테스트 일 수 있다. 이때, 번역관리부는 번역테스트용 콘텐츠를 프로젝트게시판에 공유함에 따라 복수의 참여자단말 (20_1~20_N)로부터 입력받는 각 정답정보에 기초하여, 제2 언어의 텍스트데이터에 대한 접속권한을 선택적으로 부여함으로써, 무분별한 번역참여를 방지하고, 번역전문분야를 확인할 수 있도록 지원할 수 있다. 또 다른 실시예에 따라, 번역관리부는 복수의 참여자단말(20_1~20_N)로부터 각 정답정보를 입력받을 때, 각 단말에 구비된 마이크(미도시)를 통해 녹음되는 저주파 신호와 각 단말에 구비된(미도시) GPS모듈을 통해 수 신된 위치정보에 기초하여 동일장소 위치여부를 체크할 수 있다. 이때, 번역관리부는 동일장소 위치여부에 기초하여, 테스트 컨닝 행위로 판단함에 따라 제2 언어의 텍스 트데이터에 대한 접속권한을 해제시킬 수 있다. 또 다른 실시예에 따라, 번역관리부는 기등록된 검수자단말에 목소리별 청각 호감도 테스트를 제공함 에 따라 응답받는 응답정보에 기초하여, 음도, 속도, 음질, 강도, 쉼, 억양, 공명에 대한 호감특성 파라미터를 추정할 수 있다. 이때, 번역관리부는 호감특성 파라미터에 따라, 검수용 영상컨텐츠의 제1 언어의 음성데이터를 기설정된 음성변조 프로그램을 통해 변조할 수 있다. 여기서, 기설정된 음성변조 프로그램은 마이 에딧, 파워디렉터, 보이스모드, AV 보이스 체인저, 오다시티, VOXAL 중 어느 하나일 수 있다. 또 다른 실시예에 따라, 번역관리부는 음성검수 서비스를 통해 검수용 영상컨텐츠를 제공할 때, 검수용 영 상컨텐츠에 대한 기본음성 주파수의 음성세기를 증가시키는 동시에 저주파 및 고주파 신호의 음성세기를 감소시 킬 수 있다. 여기서, 기본음성 주파수는 85 ~ 120Hz 주파수 범위이고, 저주파 신호는 0 ~ 85 Hz 주파수 범위이며, 고주파 신 호는 120 ~ 400 Hz 주파수 범위일 수 있다. 도 4는 도 1의 번역관리부에 대한 실시예를 나타내는 블록도이다. 도 1과 도 4를 참조하면, 번역관리부는 음성추출부, 텍스트생성부, 검수부 및 번역처리부 를 포함할 수 있다. 먼저, 음성추출부는 영상컨텐츠로부터 제1 언어의 음성데이터를 추출할 수 있다. 예를 들면, 영상컨텐츠는 영상프레임과 음성신호를 포함할 수 있다. 다음으로, 텍스트생성부는 제1 언어의 음성데이터를 재생함에 따라 출력되는 음성을 번역제공 웹서버(50 0)를 통해 인식하여 제1 언어의 텍스트데이터를 생성할 수 있다. 예를 들면, 번역제공 웹서버는 도 5(A)에 도시된 바와 같이, 제1 언어의 음성신호를 입력받아 인식하여 제 1 및 제2 언어의 텍스트데이터를 출력하는 번역 웹서비스를 제공하는 서버일 수 있다. 이러한 번역제공 웹서버는 기등록된 어느 하나의 단말이나 각 서버로부터 웹을 통해 접근가능한 웹페이지 일 수 있다. 이때, 번역제공 웹서버는 도메인 특화 인공지능 기반의 번역 기술 예컨대, transformer 기반의 인코딩 및 디코딩 알고리즘을 이용하여, 번역기능을 제공할 수 있다. 예를 들면, 번역제공 웹서버는 파파고나 구글번 역과 동일한 기능의 번역기능을 가진 웹페이지를 제공하는 서버일 수 있다. 또한, 번역제공 웹서버는 영역기반(Region-based) 방법과 질감기반(Texture-based) 방법 및 모서리 기반 (Edge-based) 방법 중 어느 하나를 통해 영상컨텐츠로부터 텍스트이미지를 검출하고, 텍스트이미지에 대한 SVM(Support Vector Machine), 인공신경망(Artificial Neural Network), 로지스틱 회귀분석(Logistic Regression)을 통해 해당 텍스트를 인식할 수 있다. 다음으로, 검수부는 영상컨텐츠에 제1 언어의 텍스트데이터를 자막으로 표시한 검수용 영상컨텐츠를 음성 검수 서비스를 통해 기등록된 검수자단말에 제공함에 따라 검수받을 수 있다. 여기서, 음성검수 서비스는 기등록된 검수자단말에 제공되어 설치된 앱 또는 프로그램으로, 제1 언어의 텍 스트데이터가 자막으로 표시된 영상컨텐츠를 재생함에 따라 제1 언어의 텍스트데이터에 대한 검수데이터를 입력 및 업로드받기 위한 그래픽 유저 인터페이스로 구현될 수 있다. 일 실시예에 따라, 검수부는 검수용 영상컨텐츠를 기등록된 검수자단말에 제공할 때, 제1 언어의 텍스 트데이터의 프레임구간별 글자수에 반비례하도록 상기 검수용 영상컨텐츠에 대한 재생속도를 조절할 수 있다. 예를 들면, 검수부는 프레임구간별 글자수가 일정 글자수 이상인 경우, 검수용 영상컨텐츠에 대한 재생속 도를 1.5배속으로 빠르게 재생시키고, 레임구간별 글자수가 일정 글자수 미만인 경우, 0.8배속으로 느리게 재생 시킬 수 있다. 다른 실시예에 따라, 검수부는 검수용 영상컨텐츠를 기등록된 검수자단말에 제공할 때, 기등록된 검수 자단말에 구비된 레이더 센서(미도시)를 통해 주기적으로 측정된 검수자의 심박 및 호흡신호에 기초하여, 상기 검수데이터에 대한 피드백 제한기간을 스케줄링할 수 있다. 구체적으로, 검수자의 심박 및 호흡신호가 불안정한 상태인 경우, 검수부는 검수데이터에 대한 피드백 제 한기간을 연장하여 스케줄링하고, 검수자의 심박 및 호흡신호가 안정된 상태인 경우, 검수부는 검수데이터 에 대한 피드백 제한기간을 기설정된 기간으로 스케줄링할 수 있다. 다음으로, 번역처리부는 검수부를 통해 검수된 제1 언어의 텍스트데이터를 번역제공 웹서버를 통해 제2 언어의 텍스트데이터로 자동으로 기계 번역할 수 있다. 실시예에 따라, 번역처리부는 영상컨텐츠로부터 검출되는 텍스트이미지에 따라 텍스트를 인식할 수 있다. 이때, 번역처리부는 해당 텍스트, 텍스트이미지가 출력되기 이전의 영상프레임 및 이후의 영상프레임을 이 용하여 번역텍스트 이미지를 생성하고, 이를 기초로 영상컨텐츠를 컷 편집할 수 있다. 도 6은 도 4의 텍스트생성부에 대한 실시예를 나타내는 블록도이다. 도 4 내지 도 6을 참조하여 설명하면, 텍스트생성부는 비교부와 음성데이터 보정부를 포함할 수 있다. 먼저, 비교부는 제1 언어의 음성데이터를 재생하기 이전에, 음성추출부를 통해 추출된 제1 언어의 음 성데이터로부터 분석되는 음성특성과 저장 DB(미도시)에 기설정된 기준샘플을 비교할 수 있다. 여기서, 기준샘플은 음성인식 서비스가 음성을 정확하게 인식할 수 있게 하는 샘플음성을 의미하고, 또한, 음성 특성은 음절당 발성 속도, 발성 중 묵음시간 및 음성의 포먼트주파수 중 어느 하나를 포함할 수 있다. 이때, 음성데이터 보정부는 비교부를 통해 확인된 비교 결과에 기초하여, 제1 언어의 음성데이터를 기준샘플의 음성특징에 따라 보정할 수 있다. 예를 들면, 음절 당 발성 속도가 기준샘플에 해당하는 임계 범위를 벗어날 경우, 음성데이터 보정부는 제1 언어의 음성데이터의 발성 속도를 기준샘플에 따른 발성 속도로 보정할 수 있다. 도 7은 도 4의 검수부에 대한 실시예를 나타내는 블록도이다. 도 4 내지 도 7을 참조하면, 검수부는 공유부, 선택부, 선정부 및 갱신부를 포함할 수 있다. 먼저, 공유부는 검수데이터와 제1 및 제2 언어의 텍스트데이터를 통합하여 프로젝트게시판에 프로젝 트파일로 업로드함에 따라 등록된 각 번역수정정보를 복수의 참여자단말들(20_1~20_N)에 공유할 수 있다. 여기서, 프로젝트게시판은 도 5(B)에 도시된 바와 같이, 복수의 참여자단말들(20_1~20_N) 중 어느 하나의 참여자단말(예컨대, 20_1)로부터 번역수정정보를 입력받거나 번역수정정보를 공유할 수 있는 웹게시판일 수 있 다. 실시예에 따라, 공유부는 프로젝트파일을 비밀키를 통해 암호화하고, 복수의 참여자단말들(20_1~20_N)에 비밀키에 대응되는 공개키를 제공할 수 있다. 다음으로, 선택부는 복수의 참여자단말들(20_1~20_N)로부터 투표방식을 통해 각 번역수정정보 중 최적번역 을 선택받을 수 있다. 다음으로, 선정부는 각 번역수정정보에 대한 투표순위에 기초하여 하나의 번역수정정보를 선정할 수 있다. 다음으로, 갱신부는 선정부를 통해 선정된 하나의 번역수정정보에 따라, 제2 언어의 텍스트데이터를 갱신할 수 있다. 도 8은 도 4의 번역처리부에 대한 실시예를 나타내는 블록도이다. 도 4 내지 도 8을 참조하여 설명하면, 번역처리부는 카운팅부와 비용지급부를 포함할 수 있다. 먼저, 카운팅부는 선정부를 통해 선정된 하나의 번역수정정보와 제2 언어의 텍스트데이터를 비교함에 따라 분석되는 서로 다른 단어의 개수를 카운팅할 수 있다. 다음으로, 비용지급부는 카운팅부를 통해 카운팅된 서로 다른 단어의 개수에 대응되는 리워드와 도 5(C)에 도시된 기설정된 번역비용을 합산하여, 하나의 번역수정정보를 입력한 해당 참여자단말(예컨대, 20_1)에 지급할 수 있다. 본 명세서에서는 본 발명자들이 수행한 다양한 실시예 가운데 몇 개의 예만을 들어 설명하는 것이나 본 발명의 기술적 사상은 이에 한정하거나 제한되지 않고, 당업자에 의해 변형되어 다양하게 실시될 수 있음은 물론이다."}
{"patent_id": "10-2023-0066866", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 음성 및 텍스트데이터 생성시스템을 개략적으로 나타내는 도이다. 도 2는 음성주파수 곡선에 대한 실시예이다. 도 3a 및 도 3b는 제1 및 제2 인물관계 네트워크에 대한 예시도이다. 도 4는 도 1의 번역관리부에 대한 실시예를 나타내는 블록도이다. 도 5(A) 내지 도 5(C)는 번역제공 웹서버에서 제공하는 번역 웹서비스에 대한 실시예들이다. 도 6은 도 4의 텍스트생성부에 대한 실시예를 나타내는 블록도이다. 도 7은 도 4의 검수부에 대한 실시예를 나타내는 블록도이다. 도 8은 도 4의 번역처리부에 대한 실시예를 나타내는 블록도이다."}
