{"patent_id": "10-2023-0090843", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0010795", "출원번호": "10-2023-0090843", "발명의 명칭": "버추얼 프로덕션을 기반한 디지털 콘텐츠 제작 시스템과 방법 및 이를 위한 컴퓨터 프로그램", "출원인": "김다원", "발명자": "김다원"}}
{"patent_id": "10-2023-0090843", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터, 가상공간 및 상기 가상공간 내에 표시될 아바타 중 하나 이상을 정의하는 제1 사용자 입력, 및상기 가상공간에 상응하여 미리 설정된 3차원 모델 내에 배치될 하나 이상의 가상 카메라의 위치 및 순서 중 하나 이상을 정의하는 제2 사용자 입력을 수신하도록 구성된 사용자 인터페이스 모듈; 촬영 장치를 이용하여 사용자의 이미지 정보를 연속적으로 수신하고, 상기 이미지 정보로부터 사용자의 동작 정보를 추출하도록 구성된 동작 인식 모듈; 상기 가상공간 및 상기 아바타 각각에 상응하여 미리 설정된 3차원 모델을 저장하도록 구성된 데이터베이스; 및 상기 아바타에 상응하는 3차원 모델에 상기 동작 정보를 결합한 동적 모델을 생성하고, 상기 제2 사용자 입력에의해 정의된 상기 하나 이상의 가상 카메라에 기초하여, 상기 가상공간에 상응하는 3차원 모델 내에 배치된 상기 동적 모델을 나타내는 콘텐츠를 생성하도록 구성된 시뮬레이션 모듈을 포함하는 디지털 콘텐츠 제작 시스템."}
{"patent_id": "10-2023-0090843", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 사용자 인터페이스 모듈은, 미리 설정된 복수 개의 가상 카메라를 이용하여, 상기 복수 개의 가상 카메라의 위치, 상기 복수 개의 가상 카메라의 표시 순서, 및 상기 복수 개의 가상 카메라 각각의 줌 중 하나 이상을 각각 정의하는 복수 개의 카메라프리셋 정보를 사용자에게 제공하여, 사용자로부터 상기 복수 개의 카메라 프리셋 정보 중 어느 하나에 대한 선택을 수신함으로써 상기 제2 사용자입력을 수신하도록 더 구성된 디지털 콘텐츠 제작 시스템."}
{"patent_id": "10-2023-0090843", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 시뮬레이션 모듈은, 상기 동작 인식 모듈에 의해 상기 동작 정보가 추출되는 것에 대한 응답으로 실시간으로 상기 콘텐츠를 생성하되, 상기 동작 정보가 미리 설정된 제스처를 포함하는 것에 대한 응답으로, 상기 콘텐츠에 상응하는 상기 가상 카메라의 종류, 상기 가상 카메라의 위치, 및 상기 가상 카메라의 줌 중 하나 이상을 실시간으로 변경하도록 더 구성된 디지털 콘텐츠 제작 시스템."}
{"patent_id": "10-2023-0090843", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 사용자의 음성 정보를 수신하도록 구성된 음성 인식 모듈을 더 포함하되, 상기 시뮬레이션 모듈은, 상기 음성 정보 또는 상기 동작 인식 모듈에 의해 추출된 제스처 정보에 기초하여 상기 동적 모델 및 상기 콘텐츠의 생성을 개시 또는 중단하도록 더 구성된 디지털 콘텐츠 제작 시스템. 공개특허 10-2025-0010795-3-청구항 5 디지털 콘텐츠 제작 시스템이 사용자로부터 가상공간 및 상기 가상공간 내에 표시될 아바타 중 하나 이상을 정의하는 제1 사용자 입력을 수신하는 단계; 상기 디지털 콘텐츠 제작 시스템이 상기 가상공간에 상응하여 미리 설정된 3차원 모델 내에 배치될 하나 이상의가상 카메라의 위치 및 순서 중 하나 이상을 정의하는 제2 사용자 입력을 수신하는 단계; 상기 디지털 콘텐츠 제작 시스템이 촬영 장치를 이용하여 사용자의 이미지 정보를 연속적으로 수신하는 단계; 상기 디지털 콘텐츠 제작 시스템이 상기 이미지 정보로부터 사용자의 동작 정보를 추출하는 단계; 상기 디지털 콘텐츠 제작 시스템이 상기 아바타에 상응하여 미리 설정된 3차원 모델에 상기 동작 정보를 결합한동적 모델을 생성하는 단계; 및 상기 디지털 콘텐츠 제작 시스템이, 상기 제2 사용자 입력에 의해 정의된 상기 하나 이상의 가상 카메라에 기초하여, 상기 가상공간에 상응하는 3차원 모델 내에 배치된 상기 동적 모델을 나타내는 콘텐츠를 생성하는 단계를포함하는 디지털 콘텐츠 제작 방법."}
{"patent_id": "10-2023-0090843", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "하드웨어와 결합되어 제5항에 따른 디지털 콘텐츠 제작 방법을 실행하도록 컴퓨터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0090843", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디지털 콘텐츠 제작 시스템은, 사용자로부터, 가상공간 및 상기 가상공간 내에 표시될 아바타 중 하나 이상을 정 의하는 제1 사용자 입력, 및 상기 가상공간에 상응하여 미리 설정된 3차원 모델 내에 배치될 하나 이상의 가상 카메라의 위치 및 순서 중 하나 이상을 정의하는 제2 사용자 입력을 수신하도록 구성된 사용자 인터페이스 모듈; (뒷면에 계속)"}
{"patent_id": "10-2023-0090843", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예들은 디지털 콘텐츠 제작 시스템과 방법 및 이를 위한 컴퓨터 프로그램에 관한 것이다. 보다 상세하게는, 실시예들은 사용자가 3차원 가상공간 내 자신의 아바타를 다양한 각도에서 촬영하고, 촬영된 콘텐츠를 쉽고 빠 르게 편집, 저장 및 공유할 수 있게 함으로써 적은 인력과 비용으로 콘텐츠의 제작이 가능하게 하는 기술에 대 한 것이다."}
{"patent_id": "10-2023-0090843", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보 통신 기술의 발전 및 스마트폰의 대중화에 힘입어, 1인 미디어 콘텐츠 창작자에 의해 제작된 영상 콘텐츠 의 소비량이 증가하고 있다. 또한, 콘텐츠 제작을 전문으로 하지 않는 일반 사용자들 중에서도 본인의 콘텐츠를 직접 촬영하고, 제작 및 공유하는 1인 미디어 콘텐츠 창작자를 희망하는 경우가 많아지고 있다. 한편, 최근에는 영화 및 엔터테인먼트 산업을 중심으로, 모션 캡처(motion capture) 및 확장현실(Extended Reality; XR)과 같은 실감형 기술과 인공 지능(Artificial Intelligence; AI)을 이용하여 콘텐츠를 제작하는 방법이 부상하고 있다. 이러한 기술을 이용하면, 기존에 비해 훨씬 적은 인력, 시간 및 비용을 들이더라도 상상 을 시각화한 콘텐츠를 제작하는 것이 가능하다. 예를 들어, 미국등록특허 제8885023호는 로봇 3차원 카메라의 로봇 3차원 카메라 구성을 획득하고, 가상 환경에 서 가상 3차원 카메라를 대응적으로 제어하기 위해 로봇 3차원 카메라 구성을 사용하여 가상 렌더링 시스템을 프로그래밍하며, 가상 3차원 카메라를 사용하여 가상적으로 렌더링(rendering)된 3차원 피드를 획득하는 기술을 개시한다. 그러나, 미국등록특허 제8885023호에 개시된 것을 비롯한 종래의 기술에 따라 실감형 기술을 콘텐츠 제작에 적 용하기 위해서는 다수의 카메라 및 모션 슈트 등 고가의 장비가 필요하므로, 1인 미디어 콘텐츠 창작자가 이러 한 기술을 활용하기는 쉽지 않은 한계가 있다. 또한, 1인 미디어 콘텐츠 창작자의 경우 가상 콘텐츠로 표시될 아바타 및 배경의 제작, 촬영 및 편집 등을 혼자 처리해야 하므로 콘텐츠 제작에 많은 시간이 소요되는 문제가 있어 왔다. 선행기술문헌특허문헌 (특허문헌 0001) 미국등록특허 제8885023호"}
{"patent_id": "10-2023-0090843", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 종래와 같은 고가의 장비를 사용하지 않더라도 사용자의 움직임을 인식하고 이를 사용자가 선택한 가상공간 내의 아바타에 반영하며, 사용자가 가상공간 내 아바타를 다양한 각도에서 촬영할 수 있고 촬영된 콘텐츠를 쉽고 빠르게 편집, 저장 및 공유할 수 있도록 하는 디지털 콘텐츠 제작 시스템과 방법 및 이를 위한 컴퓨터 프로그램을 제공할 수 있다."}
{"patent_id": "10-2023-0090843", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따른 디지털 콘텐츠 제작 시스템은, 사용자로부터, 가상공간 및 상기 가상공간 내에 표시 될 아바타 중 하나 이상을 정의하는 제1 사용자 입력, 및 상기 가상공간에 상응하여 미리 설정된 3차원 모델 내 에 배치될 하나 이상의 가상 카메라의 위치 및 순서 중 하나 이상을 정의하는 제2 사용자 입력을 수신하도록 구 성된 사용자 인터페이스 모듈; 촬영 장치를 이용하여 사용자의 이미지 정보를 연속적으로 수신하고, 상기 이미 지 정보로부터 사용자의 동작 정보를 추출하도록 구성된 동작 인식 모듈; 상기 가상공간 및 상기 아바타 각각에 상응하여 미리 설정된 3차원 모델을 저장하도록 구성된 데이터베이스; 및 상기 아바타에 상응하는 3차원 모델에 상기 동작 정보를 결합한 동적 모델을 생성하고, 상기 제2 사용자 입력에 의해 정의된 상기 하나 이상의 가상 카메라에 기초하여, 상기 가상공간에 상응하는 3차원 모델 내에 배치된 상기 동적 모델을 나타내는 콘텐츠를 생 성하도록 구성된 시뮬레이션 모듈을 포함한다. 일 실시예에서, 상기 사용자 인터페이스 모듈은, 미리 설정된 복수 개의 가상 카메라를 이용하여, 상기 복수 개 의 가상 카메라의 위치, 상기 복수 개의 가상 카메라의 표시 순서, 및 상기 복수 개의 가상 카메라 각각의 줌 중 하나 이상을 각각 정의하는 복수 개의 카메라 프리셋(preset) 정보를 사용자에게 제공하여, 사용자로부터 상 기 복수 개의 카메라 프리셋 정보 중 어느 하나에 대한 선택을 수신함으로써 상기 제2 사용자 입력을 수신하도 록 더 구성된다. 일 실시예에서, 상기 시뮬레이션 모듈은, 상기 동작 인식 모듈에 의해 상기 동작 정보가 추출되는 것에 대한 응 답으로 실시간으로 상기 콘텐츠를 생성하되, 상기 동작 정보가 미리 설정된 제스처를 포함하는 것에 대한 응답 으로, 상기 콘텐츠에 상응하는 상기 가상 카메라의 종류, 상기 가상 카메라의 위치, 및 상기 가상 카메라의 줌 중 하나 이상을 실시간으로 변경하도록 더 구성된다. 일 실시예에 따른 디지털 콘텐츠 제작 시스템은, 사용자의 음성 정보를 수신하도록 구성된 음성 인식 모듈을 더 포함한다. 이때 상기 시뮬레이션 모듈은, 상기 음성 정보 또는 상기 동작 인식 모듈에 의해 추출된 제스처 정보 에 기초하여 상기 동적 모델 및 상기 콘텐츠의 생성을 개시 또는 중단하도록 더 구성된다. 본 발명의 일 측면에 따른 디지털 콘텐츠 제작 방법은, 디지털 콘텐츠 제작 시스템이 사용자로부터 가상공간 및 상기 가상공간 내에 표시될 아바타 중 하나 이상을 정의하는 제1 사용자 입력을 수신하는 단계; 상기 디지털 콘 텐츠 제작 시스템이 상기 가상공간에 상응하여 미리 설정된 3차원 모델 내에 배치될 하나 이상의 가상 카메라의 위치 및 순서 중 하나 이상을 정의하는 제2 사용자 입력을 수신하는 단계; 상기 디지털 콘텐츠 제작 시스템이 촬영 장치를 이용하여 사용자의 이미지 정보를 연속적으로 수신하는 단계; 상기 디지털 콘텐츠 제작 시스템이 상기 이미지 정보로부터 사용자의 동작 정보를 추출하는 단계; 상기 디지털 콘텐츠 제작 시스템이 상기 아바타 에 상응하여 미리 설정된 3차원 모델에 상기 동작 정보를 결합한 동적 모델을 생성하는 단계; 및 상기 디지털 콘텐츠 제작 시스템이, 상기 제2 사용자 입력에 의해 정의된 상기 하나 이상의 가상 카메라에 기초하여, 상기 가상공간에 상응하는 3차원 모델 내에 배치된 상기 동적 모델을 나타내는 콘텐츠를 생성하는 단계를 포함한다. 본 발명의 일 측면에 따른 컴퓨터 프로그램은 하드웨어와 결합되어 전술한 실시예들에 따른 디지털 콘텐츠 제작 방법을 실행하기 위한 것으로서 컴퓨터로 판독 가능한 기록매체에 저장된 것일 수 있다."}
{"patent_id": "10-2023-0090843", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 측면에 따른 디지털 콘텐츠 제작 시스템 및 방법에 의하면, 기존에 전문 산업에서 고가의 장비를 이용하여 구현되었던 버추얼 프로덕션(virtual production)과 모션 캡처(motion capture) 등 실감형 기술에 대 한 대중적인 접근을 통하여, 1인 미디어 콘텐츠 창작자를 포함한 일반인도 영상 전문 산업 기술을 적용한 콘텐 츠의 생산이 가능하여 콘텐츠 품질을 향상시킬 수 있고, 고가의 장비 없이도 콘텐츠 제작이 가능하므로 콘텐츠 제작 환경과 비용 문제를 획기적으로 개선할 수 있는 이점이 있다. 나아가, 본 발명의 일 측면에 따른 디지털 콘텐츠 제작 시스템 및 방법의 적용 분야는 1인 또는 소규모의 인원 에 의한 미디어 콘텐츠 창작에 한정되지 않으며, 영화비디오물 및 방송프로그램 제작업, 미디어 콘텐츠 창작업 등을 위해 임의의 콘텐츠를 제작함에 있어서 보다 적은 인력과 비용으로 콘텐츠를 제작하기 위한 솔루션으로 본 발명의 일 측면에 따른 디지털 콘텐츠 제작 시스템 및 방법을 적용할 수 있다. 또한, 본 발명의 일 측면에 따른 디지털 콘텐츠 제작 시스템 및 방법을 이용하는 사용자는 가상공간에 대한 테 마, 음악 등과 자신의 아바타를 선택함으로써 다양한 느낌의 결과물을 창작할 수 있으며, 디지털 콘텐츠 제작 시스템이 제공하는 카메라 프리셋(preset)을 활용하거나 이를 기반으로 각 카메라의 위치, 각도, 줌(zoom) 등을 자유롭게 선택하고 조정하여 자신이 원하는 스타일의 콘텐츠를 제작할 수 있는 이점이 있다."}
{"patent_id": "10-2023-0090843", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 도면을 참조하여 본 발명의 실시예들에 대하여 상세히 살펴본다. 도 1은 일 실시예에 따른 디지털 콘텐츠 제작 시스템의 개략적인 블록도이다. 도 1을 참조하면, 본 실시예에 따른 디지털 콘텐츠 제작 시스템은 사용자 장치로부터 콘텐츠 제작을 위한 사용자 입력을 수신할 수 있다. 또한, 디지털 콘텐츠 제작 시스템은 사용자의 동작 인식을 위한 이미지 정보 를 촬영 장치로부터 수신할 수 있다. 나아가, 디지털 콘텐츠 제작 시스템은 사용자의 음성 정보를 마이크 로부터 수신할 수 있다. 예컨대, 사용자 장치, 촬영 장치 및 마이크는 일체화된 하나의 장치로 구 현될 수도 있다. 또한, 일 실시예에서 디지털 콘텐츠 제작 시스템은 하나 이상의 외부 서버(5, 6)와 더 통신하며 동작할 수 있다. 예를 들어, 디지털 콘텐츠 제작 시스템은 촬영 장치에 의해 촬영된 사용자의 이미지 정보로부터 동 작 정보를 추출하기 위하여, 인공지능(Artificial Intelligence; AI) 모델 등 머신러닝 기반의 모델을 통한 동 작 추출 서비스를 제공하는 서비스 서버와 통신할 수 있다. 또한, 디지털 콘텐츠 제작 시스템은 생성된 콘텐츠를 사용자가 다른 사용자와 공유할 수 있도록 콘텐츠 또는 콘텐츠에 대한 접속 정보를 소셜 네트워크 서 비스(Social Network Service; SNS) 서버와 같은 외부 서버에 전송할 수도 있다. 이상의 동작을 위하여, 디지털 콘텐츠 제작 시스템은 유선 및/또는 무선 네트워크를 통하여 사용자 장치, 촬영 장치, 마이크 및 외부 서버(5, 6) 등과 통신 가능하게 구성된다. 이때 유선 및/또는 무선 네트워크 는 LAN(Local Area Network), MAN(Metropolitan Area Network), GSM(Global System for Mobile Network), EDGE(Enhanced Data GSM Environment), HSDPA(High Speed Downlink Packet Access), W-CDMA(Wideband Code Division Multiple Access), CDMA(Code Division Multiple Access), TDMA(Time Division Multiple Access), 블루투스(Bluetooth), 지그비(Zigbee), 와이-파이(Wi-Fi), VoIP(Voice over Internet Protocol), LTE Advanced, IEEE802.16m, WirelessMAN-Advanced, HSPA+, 3GPP Long Term Evolution (LTE), Mobile WiMAX (IEEE 802.16e), UMB (formerly EV-DO Rev. C), Flash-OFDM, iBurst and MBWA (IEEE 802.20) systems, HIPERMAN,Beam-Division Multiple Access (BDMA), Wi-MAX(World Interoperability for Microwave Access) 및 초음파 활 용 통신으로 이루어진 군으로부터 선택되는 하나 이상의 통신 방법에 의한 통신 네트워크를 지칭할 수 있으나, 이에 한정되는 것은 아니다. 사용자 장치는 디지털 콘텐츠 제작 시스템이 제공하는 기능을 통하여 콘텐츠를 제작하고자 하는 사용자, 예컨대, 1인 미디어 콘텐츠 창작자 등이 사용하는 장치이다. 사용자는 자신의 사용자 장치에서 소정의 애플 리케이션(또는, 앱(app))을 실행함으로써 디지털 콘텐츠 제작 시스템에 접속하고 디지털 콘텐츠 제작 시스템 이 제공하는 서비스를 사용할 수 있다. 그러나, 실시예들에 따른 디지털 콘텐츠 제작 시스템을 이용하는 사용자는 1인 미디어 콘텐츠 창작자에 한정 되는 것은 아니며, 영화비디오물 및 방송프로그램 제작업, 미디어 콘텐츠 창작업 등을 목적으로 하거나 또는 이 와 동일 또는 유사한 업무를 처리하고자 하는 임의의 사용자가 본 명세서에서 설명하는 사용자에 해당될 수 있 다. 도 1에 도시된 사용자 장치의 개수나 형태는 단지 예시적인 것이다. 예를 들어, 도 1에서 사용자 장치는 노트북 컴퓨터(notebook computer)의 형태로 도시되었으나, 다른 실시예에서 사용자 장치는 스마트폰 (smartphone) 등 이동 통신 단말기, 개인용 컴퓨터(personal computer), PDA(personal digital assistant), 태 블릿(tablet), IPTV(Internet Protocol Television) 등을 위한 셋톱박스(set-top box) 등 임의의 컴퓨팅 장치 의 형태로 구현될 수도 있다. 한편, 본 명세서에 첨부된 도면들에서 디지털 콘텐츠 제작 시스템은 사용자 장치와 별개의 장치로 도시되 었으나, 이는 예시적인 것으로서, 실시예에 따라서는 디지털 콘텐츠 제작 시스템은 사용자 장치 상에서 저장되고 실행되는 소프트웨어 애플리케이션의 형태로 구현될 수도 있다. 디지털 콘텐츠 제작 시스템은 데이터베이스(database; DB), 사용자 인터페이스(User Interface; UI) 모 듈, 동작 인식 모듈 및 시뮬레이션 모듈을 포함한다. 일 실시예에서, 디지털 콘텐츠 제작 시스템 은 음성 인식 모듈을 더 포함한다. 또한 일 실시예에서, 디지털 콘텐츠 제작 시스템은 출력 모듈(2 5)을 더 포함한다. 각각의 모듈(21-25)은 하나 이상의 기능 부(unit)를 포함할 수 있다. 한편, 이러한 각 부 또 는 모듈(21-25)은 디지털 콘텐츠 제작 시스템의 하드웨어를 적어도 부분적으로 이용하여 실현되는 것일 수 있다. 즉, 실시예들에 따른 디지털 콘텐츠 제작 시스템과 이에 포함된 각 부 또는 모듈(21-25)은, 전적으로 하드웨 어이거나, 또는 부분적으로 하드웨어이고 부분적으로 소프트웨어인 측면을 가질 수 있다. 예컨대, 디지털 콘텐 츠 제작 시스템의 각 부 및 모듈(21-25)은 특정 형식 및 내용의 데이터를 처리하거나 또는/또한 전자통신 방 식으로 주고받기 위한 하드웨어 및 이에 관련된 소프트웨어를 통칭할 수 있다. 본 명세서에서 \"부\", \"모듈\", \" 장치\", \"단말기\", \"서버\" 또는 \"시스템\" 등의 용어는 하드웨어 및 해당 하드웨어에 의해 구동되는 소프트웨어의 조합을 지칭하는 것으로 의도된다. 예를 들어, 하드웨어는 CPU 또는 다른 프로세서(processor)를 포함하는 데이 터 처리 기기일 수 있다. 또한, 하드웨어에 의해 구동되는 소프트웨어는 실행중인 프로세스, 객체(object), 실 행파일(executable), 실행 스레드(thread of execution), 프로그램(program) 등을 지칭할 수 있다. 또한, 디지털 콘텐츠 제작 시스템을 구성하는 각각의 요소는 반드시 서로 물리적으로 구분되는 별개의 장치 를 지칭하는 것으로 의도되지 않는다. 즉, 도 1에 도시된 디지털 콘텐츠 제작 시스템의 각 부 및 모듈(21- 25)은 디지털 콘텐츠 제작 시스템을 구성하는 하드웨어를 해당 하드웨어에 의해 수행되는 동작에 따라 기능 적으로 구분한 것일 뿐, 반드시 각각의 부가 서로 독립적으로 구비되어야 하는 것이 아니다. 물론, 실시예에 따 라서는 전술한 각 부 및 모듈(21-25)은 중 하나 이상이 서로 물리적으로 구분되는 별개의 장치로 구현되는 것도 가능하다. DB는 하나 이상의 가상공간과 상기 가상공간 내에 표시될 수 있는 하나 이상의 아바타 각각에 대한 3차원 모델을 저장할 수 있다. 본 명세서에서 3차원 모델이란, 현실의 물체를 묘사하거나 또는 물리적 환경을 모델링 하여 가상환경 속에서 물체의 모습을 만들어내기 위한 것으로서 렌더링(rendering) 과정을 통해 콘텐츠 내에서 목적하는 모양과 질감을 갖도록 표시될 수 있는 데이터를 의미한다. UI 모듈은 DB에 저장된 3차원 모델을 기반으로 제작할 콘텐츠를 정의하는 사용자 입력을 수신할 수 있 다. UI 모듈이 수신하는 사용자 입력은, 가상공간 및/또는 상기 가상공간 내에 표시될 아바타를 정의하는 제1 사용자 입력을 포함할 수 있다. 또한 UI 모듈이 수신하는 사용자 입력은, 가상공간의 3차원 모델 내에 배치될 하나 이상의 가상 카메라의 위치 및/또는 순서를 정의하는 제2 사용자 입력을 수신할 수 있다. 일 실시예에서, 모듈은 프리셋(preset) 제공부 및 수신부를 포함한다. 프리셋 제공부는, 가 상공간의 3차원 모델 내의 특정 위치에 배치될 수 있는 복수 개의 가상 카메라에 대하여, 복수 개의 가상 카메 라의 위치, 표시 순서 및/또는 각 카메라의 줌(zoom) 등이 사전에 정의되어 있는 카메라 프리셋 정보를 하나 또 는 복수 개 사용자에게 제공할 수 있다. 사용자는 제시된 복수 개의 카메라 프리셋 정보 중 어느 하나를 선택하 는 방식으로 제2 사용자 입력을 입력할 수 있으며, 이러한 사용자 입력은 수신부에 의해 수신된다. 또한 일 실시예에서, 수신부에 수신되는 제2 사용자 입력은 사용자가 원하는 가상 카메라의 위치, 표시 순 서 및/또는 각 카메라의 줌 등을 직접 정의한 정보를 포함할 수 있다. 사용자는 프리셋 제공부가 제공하는 프리셋 중 어느 하나를 기반으로 이를 자신이 원하는 카메라 워크 형태로 변경하거나, 또는 완전히 새로운 카메 라 프리셋을 생성할 수 있다. 프리셋 제공부는 제2 사용자 입력을 통해 정의되는 카메라 워크를 기존의 프 리셋 정보 중 어느 하나를 수정하거나 또는 새로운 프리셋을 생성하는 형태로 반영할 수 있다. 또한, 사용자는 직접 가상 카메라의 위치, 표시 순서 및/또는 각 카메라의 줌 등을 상세 조정하면서 조정된 가 상 카메라의 거동이 반영된 콘텐츠 화면을 미리보기 형태로 실시간으로 확인할 수 있다. 이상의 동작을 위하여 도 4d 내지 4f를 참조하여 후술하는 것과 같은 UI 또는 다른 적절한 형태의 UI가 디지털 콘텐츠 제작 시스템 에 의하여 제공될 수 있다. 동작 인식 모듈은 촬영 장치에 의해 촬영된 사용자의 이미지 정보를 수신하고, 이미지 정보로부터 사용 자의 동작 정보를 추출할 수 있다. 연속적인 동작의 추출을 위하여, 촬영 장치가 촬영하는 이미지 정보란 소 정의 시간 간격을 가지고 촬영된 일련의 이미지를 포함하는 동영상의 형태일 수 있다. 이때, 본 실시예들에 따른 디지털 콘텐츠 제작 시스템이 이용하는 촬영 장치는 고가의 모션 슈트나 깊이 카메라 등이 아닌 점에서 종래의 기술과 차별화된다. 예를 들어, 촬영 장치는 범용 노트북 컴퓨터에 구비되 어 있거나 개인용 컴퓨터에 부착 가능한 웹캠일 수 있으며, 동작 인식 모듈은 웹캠 등이 촬영한 평면 이미 지에 대한 AI 모델 기반의 분석을 통해 낮은 비용으로 사용자의 동작을 인식할 수 있다. 일 실시예에서, 동작 인식 모듈은 이미지 정보로부터 사용자 신체의 관절 및 신체 각 부 말단과 같은 소정 의 특징점을 인식하여 사용자의 동작 정보를 추출하기 위한 제스처 인식부를 포함할 수 있다. 제스처 인식 부는 머신러닝에 기반하여 이미지에 상응하는 제스처를 분류하도록 사전에 학습된 AI 모델을 이용하여 동 작 정보를 추출할 수도 있다. 그러나 다른 실시예에서, 동작 인식 모듈은 AI를 통한 제스쳐 인식 서비스를 제공하는 외부 서버에 이미 지 정보 또는 이미지 정보로부터 획득한 특징값을 전송할 수 있으며, 이 경우 동작 인식 모듈의 수신부 는 외부 서버로부터 사용자가 취한 제스쳐 등을 인식한 결과값에 해당하는 동작 정보를 수신할 수 있다. 시뮬레이션 모듈은, 사용자가 선택한 아바타의 3차원 모델에, 동작 인식 모듈을 통해 인식된 사용자의 동작 정보를 결합하여 아바타가 사용자의 동작에 따라 움직이는 동적 모델을 생성할 수 있다. 이러한 동적 모델 은 가상공간의 3차원 모델 내에 배치되는 것으로서, 가상공간의 3차원 모델과 아바타의 동적 모델에 대한 렌더 링을 통하여 가상공간 내 아바타가 표현된 3D 동영상 형태의 콘텐츠를 제작할 수 있다. 이때, 아바타의 동적 모델이 콘텐츠 내의 이미지로 표현되는 시점(point of view)은, 전술한 것과 같이 가상공 간 내의 가상 카메라들을 설정한 제2 사용자 입력에 의해 결정된다. 즉, 제2 사용자 입력을 통해 사용자가 정의 한 가상 카메라 위치, 표시 순서 및/또는 줌 등을 반영하여, 각 가상 카메라의 시점에서 가상공간 내의 아바타 를 바라본(즉, 가상 촬영한) 이미지들로 콘텐츠가 구성될 수 있다. 이와 같은 콘텐츠 제작 과정은 기존의 3D 물 리 시뮬레이션을 통한 콘텐츠 제작 기술로부터 용이하게 이해될 수 있으므로, 발명의 요지를 명확하게 하기 위 하여 이에 대한 자세한 설명은 생략한다. 이상의 과정에 의한 콘텐츠 제작은 실시간으로 이루어질 수 있다. 즉, 동작 인식 모듈이 사용자의 이미지 정보로부터 실시간으로 사용자의 동작 정보를 추출하면, 시뮬레이션 모듈은 사용자가 사전에 선택해 둔 가 상공간 내 아바타의 움직임에 사용자의 동작 정보가 반영되도록 가상공간과 아바타의 이미지를 실시간 렌더링하 여 콘텐츠를 생성할 수 있다. 생성된 콘텐츠는, 출력 모듈을 통하여 사용자 장치에 전송되거나 또는 SNS 서버와 같은 하나 이상의 외 부 서버에 전송될 수 있다. 본 명세서에서 콘텐츠를 전송한다는 것은, 반드시 렌더링된 콘텐츠를 그대로 전 송하는 것을 의미하지 않으며, 예컨대, 목적하는 해상도, 비트레이트 및 파일 포맷 등에 맞게 콘텐츠를 변환하여 전송하거나, 또는 콘텐츠 데이터 자체를 전송하는 대신 콘텐츠에 대해 접근 가능한 접속 정보(예컨대, URL) 를 전송하는 것을 의미할 수도 있다. 실시예들에 따른 디지털 콘텐츠 제작 시스템은 1인 미디어 콘텐츠 창작자 등 단독 사용자에 의하여 사용될 수 있으므로, 디지털 콘텐츠 제작 시스템은 1인 사용자가 아바타에 적용될 동작을 취하는 동시에 미디어 촬 영에 대한 제어가 가능하도록 음성 또는 제스처를 기반으로 동작할 수도 있다. 예컨대, 디지털 콘텐츠 제작 시스템은 마이크를 통해 사용자로부터 특정 음성 정보(예컨대, 음성 명령 어)가 수신되는 것에 대한 응답으로 동작 정보의 인식이나 콘텐츠의 생성을 개시 또는 중단할 수 있다. 또한, 디지털 콘텐츠 제작 시스템은 촬영 장치를 통해 얻어진 사용자의 이미지에서 사전에 정의된 제스처 정보 (예컨대, 특정 손 동작, 발 동작, 몸짓, 표정 등)를 검출하고, 이러한 제스처 정보가 수신되는 것에 대한 응답 으로 동작 정보의 인식이나 콘텐츠 생성을 개시 또는 중단할 수도 있다. 또한 일 실시예에서, 디지털 콘텐츠 제작 시스템이 생성하는 콘텐츠의 각 장면은 사용자가 취하는 동작에 따 라 실시간으로 변화될 수도 있다. 예컨대, 디지털 콘텐츠 제작 시스템은 촬영 장치가 촬영한 이미지로부 터 사용자의 동작 정보를 추출하고 실시간으로 콘텐츠를 생성하되, 사용자의 동작이 사전에 설정된 특정 제스처 에 해당하는 경우 콘텐츠로 생성될 가상 카메라의 종류, 가상 카메라의 위치 및/또는 가상 카메라의 줌 등을 실 시간으로 변경할 수 있으며, 이러한 변경은 콘텐츠 장면에 실시간으로 반영될 수 있다. 예를 들어, 콘텐츠 제어를 위해 미리 설정된 사용자의 제스처는, 사용자가 특정한 몸 동작(예컨대, 손짓 등)을 취하는 것, 사용자가 특정 위치나 방향을 바라보는 것, 사용자가 특정 위치로 다가가는 것 등을 포함할 수 있다. 몸 동작을 예로 들면, 사용자가 사전에 정의된 엔딩 포즈를 취하는 경우 사전에 정의된 가상 카메라 프리 셋을 무시하고 아바타 정면에 위치하는 가상 카메라를 통해 아바타를 촬영하거나, 아바타를 향해 가상 카메라가 다가가거나, 가상 카메라가 아바타를 줌인(zoom-in)하는 등 사전에 설정된 가상 카메라의 변경이 일어나게 함으 로써 콘텐츠의 스타일을 사용자가 실시간으로 제어 가능하게 할 수 있다. 도 2은 일 실시예에 따른 디지털 콘텐츠 제작 시스템의 하드웨어 구성을 나타내는 개략적인 블록도이다. 도 2을 참조하면, 실시예들에 따른 디지털 콘텐츠 제작 시스템은 하드웨어를 포함하는 컴퓨팅 장치의 형태 로 구현되며, 메모리, 프로세서, 통신 모듈 그리고 입출력부를 포함할 수 있다. 메모리는 비-일시적인 컴퓨터 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM, SSD, 플래시 메모리, 디스크 드라 이브 등과 같은 비소멸성 대용량 저장 장치는 메모리와는 구분되는 별도의 영구 저장 장치로서 상술한 장 치나 서버에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드(일례로 보안 모듈이나 특정 서비스의 제공을 위해 설치된 애플리케이션 등을 위한 코드)가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메모리와 는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판독 가능한 기 록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 모듈을 통해 메 모리에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 애플리케이션의 설치 파일 을 배포하는 파일 배포 시스템(일례로, 애플리케이션 스토어 서비스 서버)이 네트워크를 통해 제공하는 파일들 에 의해 설치되는 컴퓨터 프로그램에 기반하여 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 모듈에 의해 프로세서로 제공될 수 있다. 예를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도록 구 성될 수 있다. 통신 모듈은 네트워크를 통해 디지털 콘텐츠 제작 시스템이 사용자 장치, 촬영 장치, 마이크 및/또는 외부 서버(5, 6) 등과 통신하기 위한 기능을 제공할 수 있다. 또한, 통신 모듈은 디지털 콘텐츠 제작 시스템이 유선 및/또는 무선 네트워크를 통해 다른 하나 이상의 장치와 통신하기 위한 기능을 제공할 수 있다. 즉, 통신 모듈은 메모리를 참조하는 프로세서에 의하여 그 기능이 제어됨으로써, 도 1을참조하여 전술한 각 기능 모듈을 실현하는 부분이다. 입출력부는 외부 입력/출력장치(미도시)와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 외부 입력장 치는 키보드, 마우스, 마이크로폰, 카메라 등의 장치를, 그리고 외부 출력 장치는 디스플레이, 스피커, 햅틱 피 드백 장치(haptic feedback device) 등과 같은 장치를 포함할 수 있다. 다른 예로 입출력부는 터치스크린 과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와의 인터페이스를 위한 수단일 수도 있다. 또한, 다른 실시예들에서 디지털 콘텐츠 제작 시스템은 적용되는 장치의 성질에 따라서 도 2에 도시된 구성 요소들보다 더 많은 하드웨어 구성요소들을 포함할 수도 있다. 예를 들어, 디지털 콘텐츠 제작 시스템이 사 용자가 사용하는 단말 장치에 적용되는 경우 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버(transceiver), GPS(Global Positioning System) 모듈, 카메라, 각종 센서, DB 등과 같은 다른 구성요 소들을 더 포함할 수도 있다. 보다 구체적인 예로, 단말 장치가 스마트폰(smartphone)인 경우, 일반적으로 스마 트폰이 포함하고 있는 가속도 센서나 자이로 센서, 카메라 모듈, 각종 물리적인 버튼, 터치패널을 이용한 버튼, 입출력 포트, 진동을 위한 진동기 등의 다양한 구성요소들이 더 포함되도록 구현될 수 있다. 그러나 본 명세서에서 설명하는 컴퓨팅 장치의 구성요소 및 형태는 단지 예시적인 것으로서, 디지털 콘텐츠 제 작 시스템이 구현되는 컴퓨팅 장치의 구성은 다른 공지 기술의 채용 또는 향후 정보통신 기술의 발전에 따라 본 명세서에서 설명된 것과 상이하게 될 수 있다. 이하에서 설명하는 디지털 콘텐츠 제작 방법은, 도 2를 참조하여 전술한 하드웨어 구성을 포함하는 컴퓨팅 장치 형태로 구현된 디지털 콘텐츠 제작 시스템에 의하여 수행될 수 있다. 일 예로, 디지털 콘텐츠 제작 방법은 사용자 장치 및/또는 서버에 기초하여 동작하는 애플리케이션, 소프트웨어 및 그 밖의 프로그램 중 적어도 어느 하나에 기초한 서비스의 형태로 사용자에게 제공될 수 있다. 도 3은 일 실시예에 따른 디지털 콘텐츠 제작 방법의 각 단계를 나타내는 순서도이다. 도 3을 참조하면, 사용자 장치, 촬영 장치, 마이크 등은 사용자와 직접 접하여 사용자로부터 다양한 형태의 입력을 획득하기 위한 사용자측 장비를 나타낸다. 사용자측 장비는 반드시 사용자가 해당 장 비를 보유하는 것을 의미하는 것은 아니며, 예컨대, 디지털 콘텐츠 제작 시스템의 운영자가 정해진 공간에 해당 장비들을 배치하여 두고 사용자가 공간에 방문하여 해당 장비들을 통해 콘텐츠를 제작하게 한 경우에도 상 기 공간에 배치된 장비들이 사용자측 장비에 해당될 수 있다. 또한 일 실시예에서, 사용자측 장비는 디지털 콘텐츠 제작 시스템과 일체로 구현된 것일 수도 있다. 사용자는, 사용자 장치를 이용하여 디지털 콘텐츠 제작 시스템에 사용자 입력을 입력할 수 있다. 예컨대, 사용자는 디지털 콘텐츠 제작 시스템이 제공하는 선택지 중 어느 하나를 선택하는 방식으로 가상공간 및 아 바타를 선택할 수 있다(S11). 또한 일 실시예에서, 디지털 콘텐츠 제작 시스템은 콘텐츠와 결합될 하나 이상 의 음악 목록을 사용자 장치에 제공하여, 사용자가 영상과 함께 콘텐츠를 구성할 음악을 선택하도록 할 수도 있다(S12). 일 실시예에서, 디지털 콘텐츠 제작 시스템은 가상공간 내에 배치될 하나 이상의 가상 카메라의 위치, 표시 순서 및/또는 줌 등이 사전에 정의되어 있는 카메라 프리셋 정보를 사용자에게 제공하고(S13), 사용자가 프리셋 정보 중 어느 하나를 선택하거나 또는/또한 각 가상 카메라의 위치, 순서 및/또는 줌 등을 수동으로 조정함으로 써 가상공간과 아바타를 이미지로 변환할 시점을 정의할 수 있도록 할 수 있다(S14). 도 4a 내지 4f는 일 실시예에 따른 디지털 콘텐츠 제작 시스템이 제공하는 예시적인 UI의 개념도이다. 도 4a를 참조하면, 디지털 콘텐츠 제작 시스템은 사용자에게 사전에 설정된 가상공간을 보여주는 복수 개의 썸 네일(thumbnail) 이미지(409-411)를 제공하고, 사용자는 이 중 어느 하나를 선택하는 방식으로 자신이 콘텐츠로 생성하고자 하는 가상공간을 정의할 수 있다. 이때 각각의 이미지(409-411)는 특정 가상공간에 대응될 뿐만 아 니라, 해당 가상공간에 표시 가능한 아바타의 종류 및/또는 콘텐츠에 결합될 음악을 가상공간과 함께 정의하는 특정 테마를 나타내는 것일 수도 있다. 그러나 이는 예시적인 것으로서, 다른 실시예에서 디지털 콘텐츠 제작 시스템은 콘텐츠에 결합될 음악을 UI 요 소 등을 통해 사용자에게 표시하며, 사용자는 UI 요소(401, 402)를 이용하여 가상공간과 별도로 콘텐츠에 들어갈 음악을 직접 선택할 수도 있다. 사용자가 썸네일 이미지(409-411)를 통해 가상공간을 선택하면, 도 4b에 도시된 것과 같이, 해당 가상공간(50 0)과 가상공간 내에 배치될 아바타 및 가상 카메라(511-513) 등을 사용자가 확인할 수 있도록 하는프리뷰(preview) 화면이 제공될 수 있다. 또한, 사용자는 디지털 콘텐츠 제작 시스템이 제공하는 복수 개의 아 바타 이미지(521-523) 중 어느 하나를 선택함으로써 자신의 동작을 가상공간 내에서 표현할 아바타를 선택할 수 있다. 일 실시예에서는, 사용자가 선택 가능한 아바타의 종류는 사용자가 선택한 가상공간(또는, 선택한 테마)에 따라 제한될 수도 있다. 예를 들어, 디지털 콘텐츠 제작 시스템은 각각의 가상공간 별로 해당 가상공간 내에서 표시 가능한 아바타의 목록을 정의해두고, 사용자가 가상공간을 선택하면 이에 해당하는 아바타 목록 중 어느 하나를 사용자가 선택하도록 할 수도 있다. 또한, 도 4a 및 4b에 도시된 UI 구성은 단지 설명의 편의를 위한 예시적인 것이다. 도 4a 및 4b에서는 사용자가 먼저 가상공간이나 테마를 선택한 후 이에 해당하는 가상공간 내에 표현될 아바타를 선택하는 것으로 설명되었 으나, 다른 실시예에서 사용자는 가상공간이나 테마에 앞서 아바타를 먼저 선택할 수도 있고, 또한 사용자가 아 바타를 선택하면 선택된 아바타에 따라 가상공간이 자동으로 결정되거나 또는 아바타의 종류에 따라 제한된 가 상공간의 목록이 사용자에게 제공되어 사용자가 가상공간을 선택하도록 할 수도 있다. 도 4c를 참조하면, 일 실시예에서 디지털 콘텐츠 제작 시스템은 서로 상이한 스타일을 갖도록 사전에 설정된 복 수 개의 카메라 프리셋 정보(601-603)를 사용자에게 제공하여, 사용자가 어느 하나의 프리셋을 선택할 수 있게 할 수 있다. 이때, 디지털 콘텐츠 제작 시스템이 제공하는 화면은 현재 선택되어 있는 카메라 프리셋에서 정의하는 가상 카메라의 위치, 표시 순서 및/또는 줌에 따라 가상공간과 아바타를 이미지로 변환한 예시적인 결 과를 프리뷰 형태로 제공할 수 있다. 각각의 카메라 프리셋 정보(601-603)는, 시간의 흐름에 따라 표시할 가상 카메라의 종류나 가상 카메라의 위치 및/또는 줌(소위, 카메라 워크)이 변화하도록 미리 정의된 것이다. 이때, 디지털 콘텐츠 제작 시스템은 사용자 가 콘텐츠 진행 시간에 따른 가상 카메라의 움직임을 확인할 수 있도록 사용자가 콘텐츠 진행 시간을 변경 가능 한 슬라이더 바를 제공할 수도 있다. 도 4d를 참조하면, 사용자는 디지털 콘텐츠 제작 시스템이 제공하는 카메라 프리셋 정보 중 어느 하나를 선택한 후 또는 프리셋 정보를 선택하지 않은 상태에서 가상 카메라의 카메라 워크를 직접 조정하는 것도 가능하다. 예 를 들어, 디지털 콘텐츠 제작 시스템은 복수 개의 가상 카메라에 의해 획득되는 가상공간과 아바타의 이미지를 썸네일 이미지(701-704) 형태로 사용자에게 표시하며, 사용자는 이러한 썸네일 이미지(701-704)을 클릭 또는 드 래그(drag) 등의 동작에 의해 화면 일정 영역에 배치함으로써 특정 콘텐츠 진행 시간에 사용하고자 하는 가상 카메라를 선택할 수 있다. 도 4d에 도시된 예에서는 화면 하단의 영역이 사용자가 선택한 가상 카메라가 표시되는 영역이며, 썸네일 이미 지는 슬라이더 바가 표시하는 시간에 대해 사용되도록 사용자가 선택한 가상 카메라에 대응되는 시점 을 나타낸다. 사용자는 화면 하단 영역에서 슬라이더 바의 진행 시간을 따라 썸네일 이미지를 나열하 는 방식으로 각각의 콘텐츠 진행 시간에 사용될 가상 카메라를 정의할 수 있다. 도 4e는 도 4d에 도시된 상태에서 썸네일 이미지를 더 이동시킴으로써, 사용자가 선택한 썸네일 이미지 (711, 712)들이 서로 이어 붙여진 상태를 나타낸다. 이는 썸네일 이미지에 상응하는 제1 가상 카메라에 이 어서 썸네일 이미지에 상응하는 제2 가상 카메라로 시점의 전환이 이루어지도록 사용자가 가상 카메라의 카메라 워크를 설정하였음을 의미한다. 또한 사용자는, 각각의 썸네일 이미지(711, 712)에서 슬라이더 바 의 진행 방향을 따라 전단 및/또는 후단에 위치하는 제어 영역(711', 712')을 클릭 또는 드래그함으로써 각각의 썸네일 이미지(711, 712)에 상응하는 가상 카메라가 사용될 시간 구간을 정의할 수 있다. 도 4f는 이상에서 설명한 것과 같은 UI를 이용하여 사용자가 슬라이더 바 상의 콘텐츠 진행 시간 전체를 채우도록 썸네일 이미지(711-715)들을 배치한 결과를 나타낸다. 이를 통하여, 각각의 썸네일 이미지(711-715)에 해당하는 콘텐츠 진행 시간에 각각의 썸네일 이미지(711-715)에 상응하는 가상 카메라의 시점에서 바라본 가상 공간과 아바타가 이미지로 변환되도록 콘텐츠가 생성될 수 있다. 실시예들에 따른 디지털 콘텐츠 제작 시스템은 저가의 촬영 장치를 이용하여 사용자를 하나의 방향에서 촬영한 이미지만으로 동작하지만, 콘텐츠로 표현될 가상공간 내에는 복수 개의 가상 카메라를 배치하여 사용자가 선택 한 아바타를 다양한 각도에서 촬영함으로써, 촬영 공간, 장비 및 전문적인 편집 지식이 없는 일반인이더라도 높 은 품질을 갖는 1인 미디어 콘텐츠를 쉽고 빠르게 생성할 수 있다. 일 실시예에서, 디지털 콘텐츠 제작 시스템은 가상 카메라의 조정에 더하여 사용자가 콘텐츠 이미지에 적용될 하나 이상의 영상 필터를 선택 가능하게 할 수도 있다. 예를 들어, 영상 필터는 흑백 효과, 잡음 효과, 렌즈 플레어(lens flare) 효과, 하프톤(halftone) 효과 등 공지된 또는 향후 개발될 임의의 이미지 처리를 콘텐츠의 각 이미지 프레임에 적용하기 위한 것일 수 있으며, 특정 필터로 한정되지 않는다. 다시 도 3을 참조하면, 촬영 장치에 의해 촬영되도록 사전에 설정된 공간에 사용자가 들어가 동작을 취하면, 디지털 콘텐츠 제작 시스템은 촬영 장치를 통해 사용자의 이미지 정보를 수신할 수 있다(S16). 일 실시예 에서, 촬영 장치에 의한 촬영 개시나 콘텐츠의 생성 개시 등 동작은 사용자의 명령을 통해 제어될 수도 있다. 일 실시예에서, 사용자 명령은 마이크를 통하여 입력되고 디지털 콘텐츠 제작 시스템에 전송되는 음성 명 령일 수도 있다(S14). 또한 이 경우, 디지털 콘텐츠 제작 시스템은 사용자의 음성 명령에 상응하는 디지털 콘텐츠 제작 시스템의 응답(예컨대, \"촬영을 시작하겠습니다\" 등)을 사용자 장치를 통해 사용자에게 음성 으로 출력하는 것도 가능하다. 도 5는 일 실시예에 따른 디지털 콘텐츠 제작 시스템이 사용자의 이미지 촬영을 위해 제공하는 예시적인 UI의 개념도이다. 촬영 장치가 사용자의 이미지를 촬영할 수 있는 위치가 고정되어 있는 경우, 디지털 콘텐츠 제작 시스템은 도 5에 도시된 것과 같이 사용자를 촬영할 수 있는 공간의 범위와 사용자에 상응하는 이미지 (예컨대, 아바타 이미지)를 포함하는 UI를 제공함으로써 사용자가 자신의 동작 범위를 이해하도록 할 수 있다. 또한, 일 실시예에서 디지털 콘텐츠 제작 시스템은 가상공간 내의 동작 범위와 실제 공간에서의 사용자의 동 작 범위를 서로 매칭하기 위하여, 동작 가능한 범위 설정을 위한 하나 이상의 기준 위치(811, 812)를 UI상에 노 출시키고, 사용자가 이러한 기준 위치(811, 812) 중 하나 이상으로 이동할 것을 요구할 수 있다. 예컨대, 기준 위치(811, 812)는 가상공간의 경계선 또는 가상공간 내에서 범위 설정을 위해 결정된 특정 위치에 대응될 수 있으며, 사용자가 실제 공간에서 이동함에 따라 사용자의 이미지가 어느 하나의 기준 위치(811, 812)에 위치하면, 디지털 콘텐츠 제작 시스템은 이때의 촬영 장치의 촬영 각도를 기준 위치(811, 812)에 상 응하는 가상공간 내의 위치 정보와 서로 매핑(mapping)시켜 저장할 수 있다. 촬영 장치의 촬영 각도와 가상공간 내의 위치에 대한 매핑 정보는, 사용자의 동작을 가상공간 내의 아바타에 반영하여 동적 모델을 생성할 때 가상 공간 내에서 아바타의 동작 범위를 결정하기 위해 사용될 수 있다. 다시 도 3을 참조하면, 이미지 정보를 수신한 디지털 콘텐츠 제작 시스템에서는, 이미지 정보로부터 사용자 신체 상에 위치하는 하나 이상의 특징점을 검출하고, 이러한 시간 간격을 둔 복수 개의 이미지 정보(예컨대, 각 이미지 프레임)에서 이러한 특징점의 위치 변화를 통하여 사용자의 동작 정보를 추출할 수 있다(S18). 도 6은 일 실시예에 따른 디지털 콘텐츠 제작 시스템이 사용자의 동작 정보를 인식하는 것을 설명하기 위한 개 념도이다. 도 6을 참조하면, 실시예들에 따른 디지털 콘텐츠 제작 시스템은 고가의 모션 캡처 장비나 깊이 카메라 등을 사 용하지 않고도 웹캠과 같은 범용 촬영 장치를 통해 촬영된 평면 이미지 상에서 사용자의 얼굴, 신체 각 관절부 (예컨대, 어깨, 팔꿈치, 손목, 허리, 무릎, 발목 등) 및/또는 신체 말단(예컨대, 머리, 손끝, 발끝, 발꿈치 등)에 해당하는 하나 이상의 특징점(900 내지 912)을 검출하고, 특징점(900 내지 912)의 위치 변화를 통하여 사 용자의 신체, 손, 발 등의 3차원 좌표를 트래킹(tracking)함으로써 사용자의 제스쳐를 인식할 수 있다. 일 실시예에서, 디지털 콘텐츠 제작 시스템에 의한 제스처 인식은 BlazePose 탐지기(Blazepose GHUM 3D Mode l)과 같은 공지된 또는 향후 개발될 임의의 포즈 감지 모델을 이용하여 수행될 수 있으며, 특정 방법에 의한 것으로 제한되지 않는다. 또한 일 실시예에서, 디지털 콘텐츠 제작 시스템은 제스처 인식을 위해 사용자의 이미지 나 이로부터 추출된 특징점의 위치 정보를 포즈 감지 모델이 구현된 외부 서버(미도시)에 전송하고, 외부 서버 로부터 인식된 제스처 정보를 수신할 수도 있다. 다시 도 3을 참조하면, 디지털 콘텐츠 제작 시스템은 사용자의 동작 정보를 사용자가 선택한 아바타의 3차원 모델에 결합함으로써, 아바타가 사용자의 동작에 따라 움직이는 동적 모델을 생성할 수 있다(S18). 이때, 디지 털 콘텐츠 제작 시스템은 도 5를 참조하여 전술한 위치 조정 과정을 통해 획득된 실제 공간과 가상공간의 위 치 매핑 정보를 활용하여, 아바타의 동적 모델의 동작 범위를 결정할 수 있다. 또한 디지털 콘텐츠 제작 시스템은, 이러한 동적 모델을 가상공간 내에 배치하고 가상공간 내에서 하나 이상 의 가상 카메라가 아바타를 촬영한 시점을 이미지로 변환한 3차원 콘텐츠를 생성할 수 있다(S19). 본 발명의 실시예들에서, 가상공간 및 동적 모델에 대한 물리 시뮬레이션을 통해 이를 3차원 콘텐츠로 생성하는 과정은, 유니티(Unity) 등과 같은 물리 시뮬레이션 엔진을 제공하는 외부 서버(미도시)와의 통신을 통해 이루어 질 수도 있다. 또한 디지털 콘텐츠 제작 시스템은, 콘텐츠를 생성함에 있어서 사용자가 선택한 음악을 콘텐 츠에 결합하거나, 가상환경 및/또는 아바타의 테마에 맞는 음악을 콘텐츠에 결합할 수 있다. 시뮬레이션을 통한 이미지 생성 과정과 마찬가지로, 콘텐츠에 결합될 음악의 결정 및 음악 데이터의 결합 과정 역시 유니티 등의 물리 시뮬레이션 엔진을 통하여 이루어질 수도 있다. 일 실시예에서, 디지털 콘텐츠 제작 시스템은 가상공간과 아바타의 동적 모델에 대한 콘텐츠를 출력하기 전 에 사용자가 동작의 촬영, 아바타를 통한 표현, 카메라 워크 등이 잘 이루어졌는지를 확인할 수 있도록 하는 프 리뷰 이미지를 제공할 수 있다(S20). 예를 들어, 프리뷰 이미지는 가상공간 및 아바타를 완전한 3D 콘텐츠로 렌 더링하기에 앞서 생성되는 간소화된 콘텐츠로서, 이미지 프레임의 개수, 해상도, 가상공간 또는 아바타의 텍스 쳐(texture) 등이 최종 콘텐츠에 비해 낮은 품질을 갖는 이미지 또는 동영상을 지칭할 수 있다. 사용자가 사용자 장치를 통해 프리뷰 이미지를 승인하면, 디지털 콘텐츠 제작 시스템은 가상공간과 가상 공간 내의 동적 모델을 가상 카메라에 의해 촬영한 시점에 상응하는 일련의 이미지를 포함하도록 3D 콘텐츠를 생성하고 출력할 수 있다. 출력을 위해 생성된 3D 콘텐츠는, 그래픽 품질 및 프레임 등이 출력 대상에 맞게 최 적화된 데이터 파일의 형태일 수 있다. 콘텐츠의 출력은, 디지털 콘텐츠 제작 시스템이 사용자 장치에 이메일 등을 통하여 콘텐츠의 데이터 파일 을 전송하거나(S21), 또는 사용자가 사전에 설정한 SNS 서버 등 외부 서버에 디지털 콘텐츠 제작 시스템 이 콘텐츠의 데이터 파일 또는 이에 대한 접속 정보를 전송하는 방식으로 이루어질 수 있고(S22), 특정 데이터 형식 및/또는 통신 방식에 의한 것으로 제한되지 않는다. 이상에서 설명한 실시예들에 따른 디지털 콘텐츠 제작 방법에 의한 동작은 적어도 부분적으로 컴퓨터 프로그램 으로 구현되고 컴퓨터로 읽을 수 있는 기록매체에 기록될 수 있다. 실시예들에 따른 디지털 콘텐츠 제작 방법에 의한 동작을 구현하기 위한 프로그램이 기록되고 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있다. 또한 컴퓨터가 읽을 수 있는 기록매 체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실 행될 수도 있다. 또한, 본 실시예를 구현하기 위한 기능적인 프로그램, 코드 및 코드 세그먼트(segment)들은 본 실시예가 속하는 기술 분야의 통상의 기술자에 의해 용이하게 이해될 수 있을 것이다. 이상에서 살펴본 본 발명은 도면에 도시된 실시예들을 참고로 하여 설명하였으나 이는 예시적인 것에 불과하며 당해 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 실시예의 변형이 가능하다는 점을 이해할 것이다. 그러나, 이와 같은 변형은 본 발명의 기술적 보호범위 내에 있다고 보아야 한다. 따라서, 본 발명의 진 정한 기술적 보호범위는 첨부된 청구범위의 기술적 사상에 의해서 정해져야 할 것이다.도면 도면1 도면2 도면3 도면4a 도면4b 도면4c 도면4d 도면4e 도면4f 도면5 도면6"}
{"patent_id": "10-2023-0090843", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 디지털 콘텐츠 제작 시스템의 구성을 나타내는 개략적인 블록도이다. 도 2는 일 실시예에 따른 디지털 콘텐츠 제작 시스템의 하드웨어 구성을 나타내는 개략적인 블록도이다. 도 3은 일 실시예에 따른 디지털 콘텐츠 제작 방법의 각 단계를 나타내는 순서도이다. 도 4a 내지 4f는 일 실시예에 따른 디지털 콘텐츠 제작 시스템이 제공하는 예시적인 사용자 인터페이스(User Interface; UI)의 개념도이다. 도 5는 일 실시예에 따른 디지털 콘텐츠 제작 시스템이 제공하는 또 다른 예시적인 UI의 개념도이다. 도 6은 일 실시예에 따른 디지털 콘텐츠 제작 시스템이 사용자의 동작 정보를 인식하는 것을 설명하기 위한 개 념도이다."}
