{"patent_id": "10-2022-0037790", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0139920", "출원번호": "10-2022-0037790", "발명의 명칭": "인공지능 모델 생성 장치 및 방법", "출원인": "서울시립대학교 산학협력단", "발명자": "송경우"}}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 및 제2 입력 데이터가 제공되는 입력 모듈;제1 및 제2 웨이트 데이터가 저장되는 저장 모듈;상기 제1 입력 데이터와 상기 제1 웨이트 데이터를 이용하여 제1 연산 데이터를 생성하고, 상기 제2 입력 데이터와 상기 제2 웨이트 데이터를 이용하여 제2 연산 데이터를 생성하는 연산 모듈;상기 제1 연산 데이터를 이용하여 제1 출력 데이터를 생성하고, 상기 제2 연산 데이터를 이용하여 제2 출력 데이터를 생성하는 출력 모듈; 상기 제1 출력 데이터와 제1 정답 데이터를 비교하여, 상기 제1 출력 데이터의 오류 값을 결정하고, 상기 제1출력 데이터의 오류 값에 따라 상기 연산 모듈에 제1 피드백 데이터를 제공하는 오류 결정 모듈; 및제1 및 제2 랜덤 계수를 생성하고, 상기 제1 및 제2 웨이트 데이터와 상기 제1 및 제2 랜덤 계수를 이용하여 제1 조합 웨이트 데이터를 생성하는 웨이트 조합 모듈을 포함하되,상기 제2 웨이트 데이터는 상기 제1 웨이트 데이터와 상기 제1 피드백 데이터를 이용하여 생성되는, 인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 저장 모듈은 상기 제1 웨이트 데이터가 저장되는 제1 저장 영역 및 상기 제2 웨이트 데이터가 저장되는 제2 저장 영역을 포함하는,인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 제1 조합 웨이트 데이터는 상기 연산 모듈에 제공되어, 제1 인공지능 모델을 생성하는,인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 웨이트 조합 모듈은 상기 제1 웨이트 데이터와 상기 제1 랜덤 계수의 곱과, 상기 제2 웨이트 데이터와 상기 제2 랜덤 계수의 곱을 합하여, 상기 제1 조합 웨이트 데이터를 생성하는, 인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,공개특허 10-2023-0139920-3-상기 웨이트 조합 모듈은 제3 및 제4 랜덤 계수를 더 생성하고, 상기 제1 및 제2 웨이트 데이터와 상기 제3 및제4 랜덤 계수를 이용하여 제2 조합 웨이트 데이터를 생성하는, 인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 웨이트 조합 모듈은 상기 제1 및 제2 조합 웨이트 데이터를 이용하여, 제3 조합 웨이트 데이터를생성하는,인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 웨이트 조합 모듈은 상기 제1 및 제2 랜덤 계수를 포함하는 복수의 랜덤 계수를 생성하고, 상기 복수의 랜덤 계수의 총합은 1인,인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 복수의 랜덤 계수는 디리클레 분포(Dirichlet distribution)에 기초하여 결정되는,인공지능 모델 생성 장치."}
{"patent_id": "10-2022-0037790", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능 모델 생성 장치에서 수행되는 인공지능 모델 생성 방법으로서, 상기 인공지능 모델 생성 방법은,제1 입력 데이터 및 제1 웨이트 데이터를 이용하여, 제1 출력 데이터를 생성하는 단계;상기 제1 출력 데이터와, 상기 제1 입력 데이터와 연관된 제1 정답 데이터를 이용하여, 제1 피드백 데이터를 생성하는 단계;상기 제1 웨이트 데이터와 상기 제1 피드백 데이터를 이용하여, 제2 웨이트 데이터를 생성하는 단계;제2 입력 데이터 및 상기 제2 웨이트 데이터를 이용하여, 제2 출력 데이터를 생성하는 단계;상기 제2 출력 데이터와, 상기 제2 입력 데이터와 연관된 제2 정답 데이터를 이용하여, 제2 피드백 데이터를 생성하는 단계;상기 제2 웨이트 데이터와 상기 제2 피드백 데이터를 이용하여, 제3 웨이트 데이터를 생성하는 단계;총합이 1인 복수의 제1 랜덤 계수를 생성하는 단계;상기 제1 내지 제3 웨이트 데이터와 상기 복수의 제1 랜덤 계수를 이용하여, 제1 조합 웨이트 데이터를 생성하는 단계; 및상기 제1 조합 웨이트 데이터를 이용하여 제1 인공지능 모델을 생성하는 단계를 포함하는, 인공지능 모델 생성 방법.공개특허 10-2023-0139920-4-청구항 10 제9 항에 있어서,총합이 1인 복수의 제2 랜덤 계수를 생성하는 단계;상기 제1 내지 제3 웨이트 데이터와 상기 복수의 제2 랜덤 계수를 이용하여, 제2 조합 웨이트 데이터를 생성하는 단계; 및상기 제2 조합 웨이트 데이터를 이용하여 제2 인공지능 모델을 생성하는 단계를 더 포함하는,인공지능 모델 생성 방법."}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델 생성 장치 및 방법이 제공된다. 상기 인공지능 모델 생성 장치는 제1 및 제2 입력 데이터가 제공 되는 입력 모듈, 제1 및 제2 웨이트 데이터가 저장되는 저장 모듈, 상기 제1 입력 데이터와 상기 제1 웨이트 데 이터를 이용하여 제1 연산 데이터를 생성하고, 상기 제2 입력 데이터와 상기 제2 웨이트 데이터를 이용하여 제2 (뒷면에 계속)"}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델을 생성하는 장치 및 방법에 관한 것이다. 보다 상세하게, 본 발명은 인공지능 모델의 학습 과정에서의 웨이트 데이터를 이용하여, 새로운 인공지능 모델을 생성하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할뿐 종래기술을 구성하는 것은 아니다. 머신 러닝(machine learning)은 인공 지능의 한 분야로서 컴퓨터가 특정 문제에 대한 올바른 답을 도출할 수 있 도록 학습 데이터를 통해 문제와 답 사이의 연관 관계를 스스로 학습하게 하는 기술을 의미한다. 최근에는 하나의 기계 학습 알고리즘을 통해 생성된 인공지능 모델을 사용할 뿐만 아니라, 동일한 학습 데이터 에 여러 가지 기계 학습 알고리즘을 적용하여 생성한 다양한 인공지능 모델을 조합하여 결과를 도출하는 앙상블 알고리즘에 대한 연구가 활발히 진행되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-1828503호"}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 인공지능 모델의 학습시 도출된 복수의 웨이트 데이터를 이용하여, 인공지능 모델을 생성하 는 장치 및 방법을 제공하는 것이다. 본 발명의 다른 목적은, 복수의 웨이트 데이터를 이용하여, 다양한 인공지능 모델을 생성하는 장치 및 방법을 제공하는 것이다. 본 발명의 또 다른 목적은, 학습 데이터의 개수가 제한적인 상황에서 상대적으로 성능이 높은 인공지능 모델을 생성하는 장치 및 방법을 제공하는 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치는 제1 및 제2 입력 데이터 가 제공되는 입력 모듈, 제1 및 제2 웨이트 데이터가 저장되는 저장 모듈, 상기 제1 입력 데이터와 상기 제1 웨 이트 데이터를 이용하여 제1 연산 데이터를 생성하고, 상기 제2 입력 데이터와 상기 제2 웨이트 데이터를 이용 하여 제2 연산 데이터를 생성하는 연산 모듈, 상기 제1 연산 데이터를 이용하여 제1 출력 데이터를 생성하고, 상기 제2 연산 데이터를 이용하여 제2 출력 데이터를 생성하는 출력 모듈, 상기 제1 출력 데이터와 제1 정답 데 이터를 비교하여, 상기 제1 출력 데이터의 오류 값을 결정하고, 상기 제1 출력 데이터의 오류 값에 따라 상기 연산 모듈에 제1 피드백 데이터를 제공하는 오류 결정 모듈 및 제1 및 제2 랜덤 계수를 생성하고, 상기 제1 및 제2 웨이트 데이터와 상기 제1 및 제2 랜덤 계수를 이용하여 제1 조합 웨이트 데이터를 생성하는 웨이트 조합 모듈을 포함하되, 상기 제2 웨이트 데이터는 상기 제1 웨이트 데이터와 상기 제1 피드백 데이터를 이용하여 생 성된다. 몇몇 실시예에서, 상기 저장 모듈은 상기 제1 웨이트 데이터가 저장되는 제1 저장 영역 및 상기 제2 웨이트 데 이터가 저장되는 제2 저장 영역을 포함할 수 있다. 몇몇 실시예에서, 상기 제1 조합 웨이트 데이터는 상기 연산 모듈에 제공되어, 제1 인공지능 모델을 생성할 수 있다. 몇몇 실시예에서, 상기 웨이트 조합 모듈은 상기 제1 웨이트 데이터와 상기 제1 랜덤 계수의 곱과, 상기 제2 웨 이트 데이터와 상기 제2 랜덤 계수의 곱을 합하여, 상기 제1 조합 웨이트 데이터를 생성할 수 있다. 몇몇 실시예에서, 상기 웨이트 조합 모듈은 제3 및 제4 랜덤 계수를 더 생성하고, 상기 제1 및 제2 웨이트 데이 터와 상기 제3 및 제4 랜덤 계수를 이용하여 제2 조합 웨이트 데이터를 생성할 수 있다. 몇몇 실시예에서, 상기 웨이트 조합 모듈은 상기 제1 및 제2 조합 웨이트 데이터를 이용하여, 제3 조합 웨이트 데이터를 생성할 수 있다. 몇몇 실시예에서, 상기 웨이트 조합 모듈은 상기 제1 및 제2 랜덤 계수를 포함하는 복수의 랜덤 계수를 생성하 고, 상기 복수의 랜덤 계수의 총합은 1일 수 있다. 몇몇 실시예에서, 상기 복수의 랜덤 계수는 디리클레 분포(Dirichlet distribution)에 기초하여 결정될 수 있다. 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 방법은, 제1 입력 데이터 및 제1 웨이트 데이터를 이용하여, 제1 출력 데이터를 생성하는 단계, 상기 제1 출력 데이터와, 상기 제1 입력 데이터와 연관된 제1 정답 데이터를 이용하여, 제1 피드백 데이터를 생성하는 단계, 상기 제1 웨이트 데이터와 상기 제1 피드백 데이터를 이용하여, 제2 웨이트 데이터를 생성하는 단계, 제2 입력 데이터 및 상기 제2 웨이트 데이터를 이용하여, 제2 출력 데이터 를 생성하는 단계, 상기 제2 출력 데이터와, 상기 제2 입력 데이터와 연관된 제2 정답 데이터를 이용하여, 제2 피드백 데이터를 생성하는 단계, 상기 제2 웨이트 데이터와 상기 제2 피드백 데이터를 이용하여, 제3 웨이트 데 이터를 생성하는 단계, 총합이 1인 복수의 제1 랜덤 계수를 생성하는 단계, 상기 제1 내지 제3 웨이트 데이터와 상기 복수의 제1 랜덤 계수를 이용하여, 제1 조합 웨이트 데이터를 생성하는 단계 및 상기 제1 조합 웨이트 데 이터를 이용하여 제1 인공지능 모델을 생성하는 단계를 포함한다. 몇몇 실시예에서, 총합이 1인 복수의 제2 랜덤 계수를 생성하는 단계, 상기 제1 내지 제3 웨이트 데이터와 상기 복수의 제2 랜덤 계수를 이용하여, 제2 조합 웨이트 데이터를 생성하는 단계 및 상기 제2 조합 웨이트 데이터를 이용하여 제2 인공지능 모델을 생성하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 인공지능 모델 생성 장치 및 방법은, 종래 학습에 이용된 웨이트 데이터를 이용하여 새로운 인공지능 모델을 생성할 수 있다는 장점이 있다. 본 발명의 인공지능 모델 생성 장치 및 방법은, 동일한 웨이트 데이터를 이용하여 복수의 인공지능 모델을 생성 할 수 있다는 장점이 있다. 본 발명의 인공지능 모델 생성 장치 및 방법은, 학습 데이터가 부족한 환경에서 상대적으로 성능이 좋은 인공지 능 모델을 생성할 수 있다는 장점이 있다. 상술한 내용과 더불어 본 발명의 구체적인 효과는 이하"}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 또한, 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요 소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘 어져서 구현될 수도 있다. 본 발명에서 인공지능, 머신 러닝(Machine Learning) 또는 딥러닝(Deep Learning)은 서로 혼용될 수 있다. 머 신 러닝 기술은 인공지능 기술의 일종이며, 딥러닝 기술은 머신러닝 기술의 일종이다. 딥러닝 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학습하는 것이다. 딥러닝은, 단계를 높여가면서 복수의 데이터들로부터 핵심적인 데이터를 추출하는 머신 러닝(Machine Learning) 알고리즘의 집합을 나타낸다. 본 명세서에서 언급하는 인공지능 모델은 공지의 인공지능 모델을 의미할 수 있다. 예를 들어, 인공지능 모델은 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network), GNN(Graph Neural Network) 등의 구조를 이용할 수 있다. 다만, 본 발명에 따른 인공지능 모델 생성 장치 및 방법은 GNN에 더욱 큰 효과를 갖는 것으로 입증되었다. 그러나, 본 발명의 실시예들이 이에 제한되는 것은 아니며, 본 발명의 인공지능 모델 생성 장치 및 방법은 상술한 구조 외에도 다양한 구조에 적용될 수 있는 포괄적인 기술이다. CNN은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출한 다음 뇌 속에서 복잡한 계산을 거쳐 그 결과 를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모사한 모델이다. RNN은 자연어 처리 등에 많이 이용되며, 시간의 흐름에 따라 변하는 시계열 데이터(Time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아올려 인공신경망 구조를 구성할 수 있다. DBN은 딥러닝 기법인 RBM(Restricted Boltzman Machine)을 다층으로 쌓아 구성되는 딥러닝 구조이다. RBM 학습 을 반복하여 일정 수의 레이어가 되면, 해당 개수의 레이어를 가지는 DBN이 구성될 수 있다. GNN(Graphic Neural Network)은 특정 파라미터 간 매핑된 데이터를 기초로 모델링된 모델링 데이터를 이용하여, 모델링 데이터 간의 유사도와 특징점을 도출하는 방식으로 구현된 인공신경망 구조를 나타낸다. 한편, 인공지능 모델의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight) 를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공지능 모델은 학습에 의 해 웨이트(weight) 값을 지속적으로 업데이트 시킬 수 있다. 또한, 인공지능 모델의 학습에는 역전파(Back Propagation) 등의 방법이 사용될 수 있다. 인공지능 모델의 학습 방법으로는 비지도학습(unsupervised learning)과 지도학습(supervised learning)이 모 두 사용될 수 있다. 다만, 이하에서는 설명의 편의를 위하여, 인공지능 모델이 지도학습을 통해 학습되는 것을 예로 들어 설명하도록 한다. 도 1은 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치의 구성을 개략적으로 설명하기 위한 도면이다. 도 1을 참조하면, 인공지능 모델 생성 장치는 인공지능 모델 학습부, 인공지능 모델 생성부 및 인 공지능 모델 실행부를 포함할 수 있다. 인공지능 모델 학습부는 학습 데이터 셋을 이용하여, 인공지능 모델을 이용한 예측에 이용되는 웨이트 데 이터(WT_D)를 학습할 수 있다. 다시 말해서, 인공지능 모델 학습부는 학습 데이터 셋을 이용하여 웨이트 데이터(WT_D)를 반복적으로 업데이트할 수 있다. 예를 들어, 인공지능 모델 학습부는 제1 웨이트 데이터를 업데이트하여 제2 웨이트 데이터를 생성할 수 있다. 이때, 제1 웨이트 데이터 및 제2 웨이트 데이터는 모두 인 공지능 모델 학습부에 저장되고, 인공지능 모델 학습부에 저장된 제1 및 제2 웨이트 데이터는 인공지 능 모델 생성부로 제공될 수 있다. 다시 말해서, 웨이트 데이터(WT_D)는 업데이트 전 웨이트 데이터인 제1 웨이트 데이터와, 업데이트 후 웨이트 데이터인 제2 웨이트 데이터를 모두 포함하는 의미로 사용된다. 인공지능 모델 생성부는 인공지능 모델 학습부로부터 웨이트 데이터(WT_D)를 수신할 수 있다. 전술한 바와 같이, 웨이트 데이터(WT_D)는 업데이트 전 웨이트 데이터인 제1 웨이트 데이터와, 업데이트 후 웨이트 데 이터인 제2 웨이트 데이터를 포함할 수 있다. 인공지능 모델 생성부는 웨이트 데이터(WT_D)를 이용하여 조 합 웨이트 데이터(WT_C)를 생성할 수 있다. 인공지능 모델 생성부는 예를 들어, 웨이트 데이터(WT_D)와, 디리클레 분포(Dirichlet distribution)를 이용하여 조합 웨이트 데이터(WT_C)를 생성할 수 있다. 이에 대한 구 체적인 설명은 후술한다. 인공지능 모델 생성부는 생성된 조합 웨이트 데이터(WT_C)를 인공지능 모델 실행 부에 제공할 수 있다. 인공지능 모델 실행부는 수신한 조합 웨이트 데이터(WT_C)를 적용하여, 새로운 인공지능 모델을 생성할 수 있다. 본 명세서에서는 인공지능 모델 학습부와 인공지능 모델 실행부를 각각 별개로 설명하나, 인공 지능 모델 실행부는 인공지능 모델 학습부와 실질적으로 동일할 수 있다. 다만, 본 명세서에서는 설 명의 편의상 학습 단계에서의 인공지능 모델을 인공지능 모델 학습부로 표현하고, 실행 단계에서의 인공지 능 모델을 인공지능 모델 실행부로 표현한다. 보다 구체적인 설명을 위해 도 2를 더 참조한다. 도 2는 본 발명의 몇몇 실시예에 따른 인공지능 모델 및 조합 웨이트 데이터 생성부에 대한 설명을 위한 도면이 다. 도 2는 인공지능 모델 학습부의 학습 과정과, 인공지능 모델 학습부의 학습 과정에서 이용된 웨이트 데이터(WT_D)를 이용하여 새로운 인공지능 모델을 생성하는 과정에서의 데이터의 흐름을 도시한다. 도 2를 참조하면, 인공지능 모델 학습부는 제1 입력 모듈(INM1), 제1 연산 모듈(OPM1), 제1 출력 모듈 (OUTM1), 오류 결정 모듈(ERRM) 및 저장 모듈(STRM)을 포함할 수 있다. 제1 입력 모듈(INM1)은 학습 입력 데이터(tIN_D)를 제공받아 이를 제1 연산 모듈(OPM1)에 제공할 수 있다. 학습 입력 데이터(tIN_D)는 인공지능 모델을 학습하기 위해 입력되는 데이터일 수 있다. 이때, 학습 입력 데이터 (tIN_D)는 데이터의 종류에 국한되지 않으며, 이미지 데이터, 비디오 데이터, 텍스트 데이터, 센싱 데이터 등 인공지능 모델에 따라 다양한 데이터를 포함할 수 있다. 제1 연산 모듈(OPM1)은 제1 입력 모듈(INM1)로부터 학습 입력 데이터(tIN_D)를 제공받고, 저장 모듈(STRM)로부 터 웨이트 데이터(WT_D)를 제공받을 수 있다. 제1 연산 모듈(OPM1)은 학습 입력 데이터(tIN_D)와 웨이트 데이터 (WT_D)에 대한 연산을 수행하여, 학습 연산 데이터(tOP_D)를 생성할 수 있다. 이때, 제1 연산 모듈(OPM1)은 1차 원 연산뿐만 아니라, 2차원 이상의 연산을 수행할 수도 있다. 예를 들어, 제1 연산 모듈(OPM1)은 학습 입력 데 이터(tIN_D)와 웨이트 데이터(WT_D)의 콘볼루션 연산을 수행할 수 있으나, 실시예들이 이에 제한되는 것은 아니 다. 또한, 제1 연산 모듈(OPM1)은 하나 이상의 레이어에 대한 연산을 수행할 수 있다. 예를 들어, 웨이트 데이 터(WT_D)가 복수의 레이어를 포함하는 경우, 제1 연산 모듈(OPM1)은 학습 입력 데이터(tIN_D)와 웨이트 데이터 (WT_D)의 첫번째 레이어와 연산을 수행하고, 학습 입력 데이터(tIN_D)와 웨이트 데이터(WT_D)의 첫번째 레이어 와의 연산 결과를 다시 웨이트 데이터(WT_D)의 두번째 레이어와 연산할 수 있다. 다만, 이는 하나의 예시적인 설명이며, 실시예들이 이에 제한되는 것은 아니다. 제1 연산 모듈(OPM1)은 생성한 학습 연산 데이터(tOP_D)를 제1 출력 모듈(OUTM1)에 제공할 수 있다. 제1 출력 모듈(OUTM1)은 제1 연산 모듈(OPM1)로부터 학습 연산 데이터(tOP_D)를 수신할 수 있다. 제1 출력 모듈 (OUTM1)은 학습 연산 데이터(tOP_D)를 액티베이션하여 학습 출력 데이터(tOUT_D)를 생성할 수 있다. 학습 출력 데이터(tOUT_D)는 인공지능 모델이 학습 입력 데이터(tIN_D)를 통해 얻고자하는 예측값일 수 있다. 학습 출력 데이터(tOUT_D)는 오류 결정 모듈(ERRM)에 제공될 수 있다. 오류 결정 모듈(ERRM)은 제1 출력 모듈(OUTM1)로부터 학습 출력 데이터(tOUT_D)를 제공받을 수 있다. 또한, 오 류 결정 모듈(ERRM)은 정답 데이터(ERRM)를 제공받을 수 있다. 정답 데이터(ERRM)는 학습 데이터 셋에 포함되어 있을 수 있다. 오류 결정 모듈(ERRM)은 학습 출력 데이터(tOUT_D)와 정답 데이터(ERRM)를 비교하여, 피드백 데 이터(FB_D)를 생성할 수 있다. 다만, 본 실시예는 설명의 편의를 위해 인공지능 모델이 지도학습에 따라 학습되 는 것으로 설명하였으나, 실시예들이 이에 제한되는 것은 아니다. 오류 결정 모듈(ERRM)은 생성한 피드백 데이 터(FB_D)를 제1 연산 모듈(OPM1)에 다시 제공할 수 있다. 제1 연산 모듈(OPM1)은 피드백 데이터(FB_D)를 이용하여 웨이트 데이터(WT_D)를 업데이트할 수 있다. 이때, 피 드백 데이터(FB_D)는 역전파(backpropagation) 방식으로 제1 연산 모듈(OPM1)에 제공되어, 웨이트 데이터 (WT_D)를 업데이트할 수 있으나, 실시예들이 이에 제한되는 것은 아니다. 제1 연산 모듈(OPM1)이 피드백 데이터 (FB_D)를 이용하여 웨이트 데이터(WT_D)를 업데이트 하는 과정에 대한 예시적인 설명을 위해, 도 3을 더 참조한 다. 도 3은 본 발명의 몇몇 실시예들에 따른 웨이트 데이터의 업데이트 과정을 설명하기 위한 예시적인 도면이다. 도 3은 설명의 편의를 위해, 학습 입력 데이터(tIN_D) 및 피드백 데이터(FB_D)에 대한 도시는 생략하고, 웨이트 데이터(WT_D)에 대해서만 도시하여 설명한다. 도 2 및 도 3을 참조하면, 제1 연산 모듈(OPM1)은 미리 저장된 초기 웨이트 데이터(WT_0)를 이용하여 제1 반복 연산 단계(iteration 1)를 수행할 수 있다. 예를 들어, 제1 연산 모듈(OPM1)은 제1 반복 연산 단계(iteration 1)에서, 초기 웨이트 데이터(WT_0)와 제1 학 습 입력 데이터를 연산하여, 제1 학습 연산 데이터를 생성할 수 있다. 제1 연산 모듈(OPM1)은 제1 학습 연산 데 이터를 제1 출력 모듈(OUTM1)에 제공할 수 있다. 제1 출력 모듈(OUTM1)은 제1 학습 연산 데이터를 이용하여 제1 학습 출력 데이터를 생성하고, 제1 학습 출력 데이터를 오류 결정 모듈(ERRM)에 제공할 수 있다. 오류 결정 모 듈(ERRM)은 제1 학습 출력 데이터와 제1 정답 데이터를 비교하여, 제1 피드백 데이터를 생성할 수 있다. 오류 결정 모듈(ERRM)은 제1 피드백 데이터를 다시 제1 연산 모듈(OPM1)에 제공할 수 있다. 제1 연산 모듈(OPM1)은 초기 웨이트 데이터(WT_0)와, 제1 피드백 데이터를 이용하여 제1 웨이트 데이터(WT_1)를 생성할 수 있다. 다시 말해서, 제1 연산 모듈(OPM1)은 제1 피드백 데이터를 이용하여 초기 웨이트 데이터(WT_ 0)를 업데이트할 수 있다. 이때, 업데이트된 초기 웨이트 데이터(WT_0)를 제1 웨이트 데이터(WT_1)로 지칭한다. 제1 연산 모듈(OPM1)은 생성한 제1 웨이트 데이터(WT_1)를 저장 모듈(STRM)의 제1 저장 영역(SR1)에 저장할 수 있다. 제1 저장 영역(SR1)에 저장된 제1 웨이트 데이터(WT_1)는 추후 제2 반복 연산 단계(iteration 2)에서 이 용될 수 있다. 제2 반복 연산 단계(iteration 2)에서, 제1 연산 모듈(OPM1)은 제1 저장 영역(SR1)에 저장된 제1 웨이트 데이터 (WT_1)를 로드(load)할 수 있다. 제1 연산 모듈(OPM1)은 제1 반복 연산 단계(iteration 1)에서 생성된 제1 웨 이트 데이터(WT_1)와, 제1 입력 모듈(INM1)에서 제공받은 제2 학습 입력 데이터를 연산하여, 제2 학습 연산 데 이터를 생성할 수 있다. 제1 연산 모듈(OPM1)은 제2 학습 연산 데이터를 제1 출력 모듈(OUTM1)에 제공할 수 있 다. 제1 출력 모듈(OUTM1)은 제2 학습 연산 데이터를 이용하여 제2 학습 출력 데이터를 생성하고, 제2 학습 출 력 데이터를 오류 결정 모듈(ERRM)에 제공할 수 있다. 오류 결정 모듈(ERRM)은 제2 학습 출력 데이터와 제2 정 답 데이터를 비교하여, 제2 피드백 데이터를 생성할 수 있다. 오류 결정 모듈(ERRM)은 제2 피드백 데이터를 제1 연산 모듈(OPM1)에 제공할 수 있다. 제1 연산 모듈(OPM1)은 제1 웨이트 데이터(WT_1)와, 제2 피드백 데이터를 이용하여 제2 웨이트 데이터(WT_2)를 생성할 수 있다. 다시 말해서, 제1 연산 모듈(OPM1)은 제2 피드백 데이터를 이용하여 제1 웨이트 데이터(WT_1) 를 업데이트할 수 있다. 이때, 업데이트된 제1 웨이트 데이터(WT_1)를 제2 웨이트 데이터(WT_2)로 지칭한다. 제 1 연산 모듈(OPM1)은 생성한 제2 웨이트 데이터(WT_2)를 저장 모듈(STRM)의 제2 저장 영역(SR2)에 저장할 수 있 다. 제2 저장 영역(SR2)에 저장된 제2 웨이트 데이터(WT_2)는 추후 제3 반복 연산 단계(iteration 3)에서 이용 될 수 있다. 이와 유사한 과정으로, 제3 반복 연산 단계(iteration 3)에서, 제1 연산 모듈(OPM1)은 제2 저장 영역(SR2)에 저 장된 제2 웨이트 데이터(WT_2)를 로드할 수 있다. 제1 연산 모듈(OPM1)은 제3 웨이트 데이터(WT_3)를 생성하고, 생성한 제3 웨이트 데이터(WT_3)를 저장 모듈(STRM)의 제3 저장 영역(SR3)에 저장할 수 있다. 몇몇 실시예에 따르면, 제1 연산 모듈(OPM1)의 반복 연산 과정에서 생성된 제1 웨이트 데이터(WT_1), 제2 웨이 트 데이터(WT_2) 및 제3 웨이트 데이터(WT_3)는 각각 저장 모듈(STRM)의 제1 저장 영역(SR1), 제2 저장 영역 (SR2) 및 제3 저장 영역(SR3)에 저장될 수 있다. 다시 말해서, 웨이트 데이터(WT_D)가 업데이트되더라도, 업데 이트 전의 웨이트 데이터(WT_D)와 업데이트 후의 웨이트 데이터(WT_D)는 모두 저장 모듈(STRM)에 저장될 수 있 다. 다시 도 2를 참조하면, 인공지능 모델 생성부는 저장 모듈(STRM) 및 웨이트 조합 모듈(WCM)을 포함할 수 있다. 도 2는 인공지능 모델 학습부와 인공지능 모델 생성부가 서로 저장 모듈(STRM)을 공유하는 것으로 도시하였으나, 실시예들이 이에 제한되는 것은 아니다. 예를 들어, 인공지능 모델 학습부와 인공지능 모델 생성부는 각각 별개의 저장 모듈(STRM)을 포함할 수도 있다. 웨이트 조합 모듈(WCM)은 저장 모듈(STRM)로부터 웨이트 데이터(WT_D)를 수신할 수 있다. 웨이트 조합 모듈 (WCM)은 웨이트 데이터(WT_D)를 이용하여 조합 웨이트 데이터(WT_C)를 생성할 수 있다. 웨이트 조합 모듈(WCM) 은 생성한 조합 웨이트 데이터(WT_C)를 저장 모듈(STRM)에 저장할 수 있다. 웨이트 조합 모듈(WCM)이 조합 웨이 트 데이터(WT_C)를 생성하는 과정에 대한 예시적인 설명을 위해, 도 4를 더 참조한다. 도 4는 본 발명의 몇몇 실시예에 따른 웨이트 조합 모듈이 조합 웨이트 데이터를 생성하는 과정을 설명하기 위 한 예시적인 도면이다. 도 2 및 도 4를 참조하면, 웨이트 조합 모듈(WCM)은 랜덤 계수 생성기(RPG) 및 벡터 연산기(VOP)를 포함할 수 있다. 랜덤 계수 생성기(RPG)는 랜덤 계수 세트(random parameter set)를 생성할 수 있다. 랜덤 계수 생성기(RPG)에서 생성되는 랜덤 계수 세트는 복수의 랜덤 계수를 포함할 수 있으며, 복수의 랜덤 계수의 총합은 1일 수 있다. 다 만, 이는 하나의 실시예일 뿐 본 발명이 이에 제한되는 것은 아니다. 예를 들어, 본 발명의 기술 분야에서 통상 의 지식을 가진 자는 총합이 N인 복수의 랜덤 계수를 생성한 뒤 이후 연산 단계에서 N을 나눗셈하여 결과적으로 본 발명의 랜덤 계수와 동일한 조건을 달성할 수 있다. 다만, 본 발명에서는 설명의 편의상 복수의 랜덤 계수의 총합이 1인 것으로 가정하여 설명한다. 랜덤 계수 생성기(RPG)에서 생성하는 복수의 랜덤 계수의 개수는, 저장 모듈(STRM)에 저장된 웨이트 데이터 (WT_D)의 개수와 대응될 수 있다. 다시 말해서, 랜덤 계수 생성기(RPG)는 저장 모듈(STRM)에 저장된 웨이트 데 이터(WT_D)의 개수와 대응되도록, 복수의 랜덤 계수를 생성할 수 있다. 즉, 랜덤 계수 생성기(RPG)에서 생성한 랜덤 계수 세트에 포함된 랜덤 계수의 개수는, 저장 모듈(STRM)에 저장된 웨이트 데이터(WT_D)의 개수와 대응될 수 있다. 몇몇 실시예에 따르면, 랜덤 계수 생성기(RPG)는 디리클레 분포(Dirichlet distribution)에 따라 복수의 랜덤 계수를 생성할 수 있다. 디리클레 분포는 연속 확률분포의 하나로, k차원의 실수 벡터 중 벡터의 요소가 양수이 며 모든 요소를 더한 값이 1인 경우에 대해 확률값이 정의되는 분포이다. 다시 말해서, 랜덤 계수 생성기(RPG) 에서 생성된 랜덤 계수 세트는 디리클레 분포에 따라 결정된 복수의 랜덤 계수를 포함할 수 있다. 벡터 연산기(VOP)는 랜덤 계수 생성기(RPG)에서 생성된 랜덤 계수 세트와, 저장 모듈(STRM)에 저장된 웨이트 데 이터(WT_D)를 연산하여 조합 웨이트 데이터(WT_C)를 생성할 수 있다. 다시 말해서, 벡터 연산기(VOP)는 복수의 랜덤 계수 각각과, 저장 모듈(STRM)에 저장된 복수의 웨이트 데이터(WT_D) 각각을 연산하여 조합 웨이트 데이터 (WT_C)를 생성할 수 있다. 예를 들어, 벡터 연산기(VOP)는 저장 모듈(STRM)의 제1 저장 영역(SR1)에서 제1 웨이트 데이터(WT_1)를 제공받 을 수 있다. 또한, 벡터 연산기(VOP)는 저장 모듈(STRM)의 제2 저장 영역(SR2)에서 제2 웨이트 데이터(WT_2)를 제공받을 수 있다. 또한, 벡터 연산기(VOP)는 저장 모듈(STRM)의 제3 저장 영역(SR3)에서 제3 웨이트 데이터 (WT_3)를 제공받을 수 있다. 벡터 연산기(VOP)는 랜덤 계수 생성기(RPG)로부터 제1 랜덤 계수 세트(RS1)를 제공받을 수 있다. 제1 랜덤 계수 세트(RS1)는 제1 랜덤 계수(P1), 제2 랜덤 계수(P2) 및 제3 랜덤 계수(P3)를 포함할 수 있다. 벡터 연산기(VO P)는 제1 웨이트 데이터(WT_1) 내지 제3 웨이트 데이터(WT_3) 각각과, 제1 랜덤 계수(P1) 내지 제3 랜덤 계수 (P3) 각각을 곱하고, 이를 더하여 조합 웨이트 데이터(WT_C)를 생성할 수 있다. 즉 도 4의 경우 조합 웨이트 데 이터(WT_C)는 벡터 연산기(VOP)에서 아래 수학식 1에 따라 생성될 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0037790", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "벡터 연산기(VOP)는 생성된 제1 조합 웨이트 데이터(WT_C1)를 저장 모듈(STRM)의 제4 저장 영역(SR4)에 저장할 수 있다. 벡터 연산기(VOP)에서 생성된 제1 조합 웨이트 데이터(WT_C1)는 새로운 인공지능 모델의 웨이트 데이 터로 이용될 수 있다. 몇몇 실시예에 따르면, 웨이트 조합 모듈(WCM)은 복수개의 조합 웨이트 데이터를 생성할 수 있다. 예를 들어, 랜덤 계수 생성기(RPG)는 제1 랜덤 계수 세트(RS1)와 다른 제2 랜덤 계수 세트를 생성할 수 있다. 벡터 연산기 (VOP)는 제1 웨이트 데이터(WT_1) 내지 제3 웨이트 데이터(WT_3)와, 제2 랜덤 계수 세트를 연산하여, 제2 조합 웨이트 데이터를 생성할 수 있다. 제1 랜덤 계수 세트와 제2 랜덤 계수 세트는 서로 다르기 때문에, 제1 조합 웨이트 데이터(WT_C1)와 제2 조합 웨이트 데이터는 서로 다를 수 있다. 제2 조합 웨이트 데이터는 다른 인공지 능 모델의 웨이트 데이터로 이용될 수 있다. 마찬가지로, 웨이트 조합 모듈(WCM)은 또 다른 제3 랜덤 계수 세트 를 이용하여, 또 다른 인공지능 모델에서 이용될 제3 조합 웨이트 데이터를 생성할 수 있다. 이와 같이, 웨이트 조합 모듈(WCM)은 하나의 웨이트 데이터(WT_D), 즉 제1 웨이트 데이터(WT_1) 내지 제3 웨이트 데이터(WT_3)를 이용하여 복수개의 다양한 조합 웨이트 데이터(WT_C)를 생성할 수 있다. 다시 말해서, 웨이트 조합 모듈(WCM)은 웨이트 데이터(WT_D)를 디리클레 분포에 따라 조합함으로써, 다양한 조합 웨이트 데이터(WT_C)를 생성할 수 있 다. 즉, 웨이트 조합 모듈(WCM)은 하나의 웨이트 데이터(WT_D)를 이용하여 다양한 인공지능 모델을 생성할 수 있다. 예시적인 설명을 위해, 이를 도식화한 도 5를 더 참조하여 설명한다. 도 5는 본 발명의 몇몇 실시예에 따른 웨이트 데이터와, 웨이트 조합 모듈이 생성하는 조합 웨이트 데이터를 도 식화한 도면이다. 도 4 및 도 5를 참조하면, 제1 웨이트 데이터(WT_1), 제2 웨이트 데이터(WT_2) 및 제3 웨이트 데이터(WT_3)는 동일한 그래프 뉴럴 네트워크(GNN)의 웨이트 데이터일 수 있다. 다만, 제1 웨이트 데이터(WT_1) 내지 제3 웨이 트 데이터(WT_3)는 전술한 바와 같이, 서로 다른 반복 연산 단계에서 생성된 웨이트 데이터일 수 있다. 제1 조합 웨이트 데이터(WT_C1)는 제1 웨이트 데이터(WT_1)에 제1 랜덤 계수(P1)를 곱하고, 제2 웨이트 데이터 (WT_2)에 제2 랜덤 계수(P2)를 곱하고, 제3 웨이트 데이터(WT_3)에 제3 랜덤 계수(P3)를 곱한 값을 모두 더하여 결정된 값일 수 있다. 이때, 제1 랜덤 계수(P1) 내지 제3 랜덤 계수(P3)의 총합은 1이기 때문에, 제1 웨이트 데 이터(WT_1) 내지 제3 웨이트 데이터(WT_3)와 제1 조합 웨이트 데이터(WT_C1)는 동일한 스케일(scale)을 가질 수 있다. 마찬가지로, 제2 조합 웨이트 데이터(WT_C2) 및 제3 조합 웨이트 데이터(WT_C3)도 각각 제1 웨이트 데이터 (WT_1) 내지 제3 웨이트 데이터(WT_3)와, 제2 랜덤 계수 세트 및 제3 랜덤 계수 세트를 각각 연산하여 생성될 수 있다. 제1 랜덤 계수 세트 내지 제3 랜덤 계수 세트는 서로 다르므로, 제1 조합 웨이트 데이터(WT_C1) 내지 제3 조합 웨이트 데이터(WT_C3)는 서로 다를 수 있다. 즉, 웨이트 조합 모듈(WCM)은 서로 다른 랜덤 계수 세트 를 생성함으로써, 동일한 웨이트 데이터(WT_D)를 이용하더라도 서로 다른 조합 웨이트 데이터(WT_C)를 생성할 수 있다. 즉, 웨이트 조합 모듈(WCM)에 의해 생성되는 서로 다른 조합 웨이트 데이터(WT_C)는 각각 서로 다른 인공지능 모델의 웨이트 데이터로서 이용될 수 있다. 다시 도 1 및 도 2를 참조하면, 인공지능 모델 실행부는 제2 입력 모듈(INM2), 제2 연산 모듈(OPM2), 제2 출력 모듈(OUTM2) 및 저장 모듈(STRM)을 포함할 수 있다. 이때, 인공지능 모델 학습부, 인공지능 모델 생 성부 및 인공지능 모델 실행부가 서로 동일한 저장 모듈(STRM)을 공유하는 것으로 도시하였으나, 실 시예들이 이에 제한되지는 않는다. 인공지능 모델 학습부, 인공지능 모델 생성부 및 인공지능 모델 실행부 중 적어도 일부는 다른 저장 모듈로 구현될 수도 있다. 또한, 전술한 바와 같이, 본 명세서에서는 인공지능 모델 학습부와 인공지능 모델 실행부를 서로 별개인 것으로 설명하였으나, 이는 설명의 편 의를 위한 것일 뿐 실시예들이 이에 제한되는 것은 아니다. 인공지능 모델 학습부와 인공지능 모델 실행부 는 서로 실질적으로 동일한 구성일 수 있다. 몇몇 실시예에 따르면, 웨이트 조합 모듈(WCM)에서 생성된 조합 웨이트 데이터(WT_C)는 저장 모듈(STRM)에 저장 되고, 이는 인공지능 모델 실행부의 제2 연산 모듈(OPM2)에 제공될 수 있다. 제2 입력 모듈(INM2)은 입력 데이터(IN_D)를 제공받아 이를 제2 연산 모듈(OPM2)에 제공할 수 있다. 입력 데이 터(IN_D)는 인공지능 모델을 실행하기 위해 입력되는 데이터일 수 있다. 이때, 입력 데이터(IN_D)는 학습 입력 데이터(tIN_D)와 동일한 종류의 데이터일 수 있다. 제2 연산 모듈(OPM2)은 제2 입력 모듈(INM2)로부터 입력 데이터(IN_D)를 제공받고, 저장 모듈(STRM)로부터 조합 웨이트 데이터(WT_C)를 제공받을 수 있다. 제2 연산 모듈(OPM2)은 입력 데이터(IN_D)와 조합 웨이트 데이터 (WT_C)에 대한 연산을 수행하여, 연산 데이터(OP_D)를 생성할 수 있다. 제2 연산 모듈(OPM2)은 생성한 연산 데 이터(OP_D)를 제2 출력 모듈(OUTM2)에 제공할 수 있다. 제2 출력 모듈(OUTM2)은 제2 연산 모듈(OPM2)로부터 연산 데이터(OP_D)를 수신할 수 있다. 제2 출력 모듈 (OUTM2)은 연산 데이터(OP_D)를 액티베이션하여 출력 데이터(OUT_D)를 생성할 수 있다. 출력 데이터(OUT_D)는 인공지능 모델이 입력 데이터(IN_D)를 통해 얻고자하는 최종 예측값일 수 있다. 다시 말해서, 인공지능 모델 실행부는 인공지능 모델 학습부에서 생성된 복수의 웨이트 데이터(WT_ D)를 이용하여 생성된 조합 웨이트 데이터(WT_C)를 이용하여, 인공지능 모델을 실행할 수 있다. 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치에 의해 생성된 인공지능 모델은 보다 높은 성능을 가지게 된다. 이에 대한 실험 결과를 도 6을 통해 설명한다. 도 6은 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치에서 생성된 인공지능 모델의 성능을 설명하기 위한 도면이다. 도 6은 Cora, CiteSeer, PubMed 데이터셋을 이용한 Cheby, GCN, GAT, SGC, ARMA, APPNP 모델 각각의 정확도 및 표준 편차를 나타낸다. Fixed는 주어진 학습, 검증 및 테스트 세팅을 이용한 것을 의미하며, Random은 랜덤 스 플릿을 이용한 것을 의미한다. Cora 데이터 셋에서, APPNP 모델이 Fixed와 Random에서 모두 가장 높은 성능을 가지는 것으로 확인되었다. APPNP 모델은 Fixed의 경우 83.3%의 정확도와, 0.5의 표준편차를 가지며, Random의 경우 82.2%의 정확도와 1.5의 표준편차를 가진다. 한편, 본 발명의 몇몇 실시예에 따라, Cora 데이터 셋에서, APPNP 모델의 학습 과정에서 이용된 웨이트 데이터 를 이용하여 생성된 조합 웨이트 데이터를 이용한 인공지능 모델의 경우, Fixed의 경우 83.3%의 정확도와 0.1의 표준편차, Random의 경우 82.7%의 정확도와 1.1의 표준편차를 가지는 것으로 확인되었다. 즉, APPNP 모델을 그 대로 사용하는 것 보다, APPNP 모델의 학습 과정에서 이용된 웨이트 데이터를 이용하여 조합 웨이트 데이터를 생성한 경우 더 높은 성능을 가지는 것으로 확인되었다. 마찬가지로, CiteSeer 데이터 셋과, PubMed 데이터 셋에서 모두 본 발명의 몇몇 실시예에 따라 생성된 조합 웨 이트 데이터를 이용한 인공지능 모델의 성능이 가장 뛰어난 것으로 확인된다. 한편, 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치에서 생성된 인공지능 모델은 학습 데이터 셋 이 적은 경우에 더욱 효과적으로 이용될 수 있다. 이에 대해 도 7을 통해 설명한다. 도 7은 기존의 인공지능 모델과, 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치에서 생성된 인공지능 모델의 학습 데이터의 개수에 따른 정확도 개선율을 나타내는 그래프이다. 도 7을 참조하면, 각 막대 그래프는 본 발명의 몇몇 실시예에 따라 생성된 인공지능 모델의 정확도 증가율을 의 미하며, 3-shot, 5-shot, 10-shot은 각각 학습 데이터의 개수를 나타낸다. 도 7에서 확인할 수 있는 바와 같이, 본 발명의 몇몇 실시예에 따라 생성된 인공지능 모델은, 학습 데이터의 개 수가 적을수록, 종래의 인공지능 모델에 비해 더 높은 정확도 개선율을 갖는 것으로 확인되었다. 도 8은 본 발명의 몇몇 실시예에 따른 인공지능 모델의 생성 방법을 설명하기 위한 도면이다. 설명의 편의를 위 해, 전술한 내용과 동일하거나 유사한 내용은 생략하거나 간단히 설명한다. 도 2, 도 3 및 도 8을 참조하면, 인공지능 모델 생성 장치는, 제1 인공지능 모델에 제1 학습 입력 데이터 (tIN_D) 및 제1 웨이트 데이터(WT_1)를 이용하여, 제1 학습 출력 데이터(tOUT_D)를 생성할 수 있다(S100). 제1 인공지능 모델은 인공지능 모델 학습부에서 이용하는 인공지능 모델일 수 있다. 몇몇 실시예에 따르면, 제 1 웨이트 데이터(WT_1)는 저장 모듈(STRM)의 제1 저장 영역(SR1)에 저장되어 있을 수 있다. 제1 학습 출력 데이터(tOUT_D)와 제1 정답 데이터(ERRM)를 비교하여, 제1 피드백 데이터(FB_D)를 생성할 수 있 다(S200). 제1 피드백 데이터(FB_D)를 이용하여, 제1 웨이트 데이터(WT_1)를 업데이트할 수 있다. 업데이트된 제1 웨이트 데이터(WT_1)를 제2 웨이트 데이터(WT_2)로 지칭한다(S300). 제2 웨이트 데이터(WT_2)는 저장 모듈(STRM)의 제2 저장 영역(SR2)에 저장될 수 있다. 단계 S100 내지 단계 S300과 유사하게, 제2 웨이트 데이터(WT_2)를 업데이트하여, 제3 웨이트 데이터(WT_3)를 생성할 수 있다(S400~S600). 제3 웨이트 데이터(WT_3)는 저장 모듈(STRM)의 제3 저장 영역(SR3)에 저장될 수 있 다. 제1 웨이트 데이터(WT_1) 내지 제3 웨이트 데이터(WT_3)와, 복수의 랜덤 계수를 이용하여 제1 조합 웨이트 데이 터(WT_C1)를 생성할 수 있다(S700). 복수의 랜덤 계수는 디리클레 분포에 따라 결정된 값일 수 있다. 제1 조합 웨이트 데이터(WT_C1)를 이용하여 제2 인공지능 모델을 생성할 수 있다(S800). 제2 인공지능 모델은 제1 인공지능 모델과 동일하나, 웨이트 데이터만 서로 다른 모델일 수 있다. 도 9는 본 발명의 다른 몇몇 실시예에 따른 인공지능 모델 생성 장치를 설명하기 위한 도면이다. 설명의 편의를 위해, 전술한 내용과 동일하거나 유사한 내용은 생략하거나 간단히 설명한다. 도 9를 참조하면, 웨이트 조합 모듈(WCM)은 평균 연산기(AOP)를 더 포함할 수 있다. 벡터 연산기(VOP)는 제1 웨이트 데이터(WT_1) 내지 제3 웨이트 데이터(WT_3)와, 제1 랜덤 계수 세트(RS1)를 이 용하여, 제1 조합 웨이트 데이터(WT_C1)를 생성할 수 있다. 또한, 벡터 연산기(VOP)는 제1 웨이트 데이터(WT_1) 내지 제3 웨이트 데이터(WT_3)와, 제2 랜덤 계수 세트(RS2)를 이용하여, 제2 조합 웨이트 데이터(WT_C2)를 생성할 수 있다. 또한, 벡터 연산기(VOP)는 제1 웨이트 데이터(WT_1) 내지 제3 웨이트 데이터(WT_3)와, 제3 랜덤 계 수 세트(RS3)를 이용하여, 제3 조합 웨이트 데이터(WT_C3)를 생성할 수 있다. 벡터 연산기(VOP)에서 생성된 제1 조합 웨이트 데이터(WT_C1) 내지 제3 조합 웨이트 데이터(WT_C3)는 평균 연산 기(AOP)에 제공될 수 있다. 평균 연산기(AOP)는 제1 조합 웨이트 데이터(WT_C1) 내지 제3 조합 웨이트 데이터 (WT_C3)를 평균하여, 제4 조합 웨이트 데이터(WT_C4)를 생성할 수 있다. 평균 연산기(AOP)에서 생성된 제4 조합 웨이트 데이터(WT_C4)는 저장 모듈(STRM)에 저장될 수 있다. 제4 조합 웨이트 데이터(WT_C4)는 새로운 인공지능 모델의 웨이트 데이터로 이용될 수 있다. 다시 말해서, 웨이트 조합 모듈(WCM)은 벡터 연산기(VOP)에서 생성된 복수의 조합 웨이트 데이터를 평균하여, 새로운 조합 웨이트 데이터를 생성할 수 있으며, 이를 통해 새로운 인 공지능 모델을 생성할 수 있다. 도 10은 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치의 하드웨어 구현을 설명하기 위한 도면이다. 도 10을 참조하면, 본 발명의 몇몇 실시예들에 따른 인공지능 모델 생성 장치는 전자 장치로 구현될 수 있다. 전자 장치는 컨트롤러(1010, controller), 입출력 장치(1020, I/O), 메모리 장치(1030, memory device), 인터페이스(1040, interface) 및 버스(1050, bus)를 포함할 수 있다. 컨트롤러, 입출력 장치 , 메모리 장치 및/또는 인터페이스는 버스를 통하여 서로 결합될 수 있다. 이때, 버스 는 데이터들이 이동되는 통로(path)에 해당한다. 구체적으로, 컨트롤러는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit), 디지털 신호 프로세스, 마이 크로컨트롤러, 어플리케이션 프로세서(AP, application processor) 및 이들과 유사한 기능을 수행할 수 있는 논 리 소자들 중에서 적어도 하나를 포함할 수 있다. 입출력 장치는 키패드(keypad), 키보드, 터치스크린 및 디스플레이 장치 중 적어도 하나를 포함할 수 있 다. 메모리 장치는 데이터 및/또는 프로그램 등을 저장할 수 있다. 인터페이스는 통신 네트워크로 데이터를 전송하거나 통신 네트워크로부터 데이터를 수신하는 기능을 수행 할 수 있다. 인터페이스는 유선 또는 무선 형태일 수 있다. 예컨대, 인터페이스는 안테나 또는 유 무선 트랜시버 등을 포함할 수 있다. 도시하지 않았지만, 메모리 장치는 컨트롤러의 동작을 향상시 키기 위한 동작 메모리로서, 고속의 디램 및/또는 에스램 등을 더 포함할 수도 있다. 메모리 장치는 내부 에 프로그램 또는 어플리케이션을 저장할 수 있다. 본 발명의 실시예들에 따른 인공지능 모델 생성 장치는 각각 복수의 전자 장치가 네트워크를 통해서 서로 연결되어 형성된 시스템일 수 있다. 이러한 경우에는 각각의 모듈 또는 모듈의 조합들이 전자 장치 로 구현될 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 추가적으로, 인공지능 모델 생성 장치는 워크스테이션(workstation), 데이터 센터, 인터넷 데이터 센터 (internet data center(IDC)), DAS(direct attached storage) 시스템, SAN(storage area network) 시스템, NAS(network attached storage) 시스템, RAID(redundant array of inexpensive disks, or redundant array of independent disks) 시스템, 및 EDMS(Electronic Document Management) 시스템 중 적어도 하나로 구현될 수 있 으나, 본 실시예가 이에 제한되는 것은 아니다. 또한, 인공지능 모델 생성 장치에 포함된 적어도 일부 구성은 네트워크를 통해서 데이터를 교환할 수 있다. 네트워크는 유선 인터넷 기술, 무선 인터넷 기술 및 근거리 통신 기술에 의한 네트워크를 포함할 수 있다. 유선 인터넷 기술은 예를 들어, 근거리 통신망(LAN, Local area network) 및 광역 통신망(WAN, wide area network) 중 적어도 하나를 포함할 수 있다. 무선 인터넷 기술은 예를 들어, 무선랜(Wireless LAN: WLAN), DMNA(Digital Living Network Alliance), 와이브 로(Wireless Broadband: Wibro), 와이맥스(World Interoperability for Microwave Access: Wimax), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), IEEE 802.16, 롱 텀 에볼루션(Long Term Evolution: LTE), LTE-A(Long Term Evolution-Advanced), 광대역 무선 이동 통신 서비스 (Wireless Mobile Broadband Service: WMBS) 및 5G NR(New Radio) 기술 중 적어도 하나를 포함할 수 있다. 단,본 실시예가 이에 제한되는 것은 아니다. 근거리 통신 기술은 예를 들어, 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신 (Infrared Data Association: IrDA), UWB(Ultra-Wideband), 지그비(ZigBee), 인접 자장 통신(Near Field Communication: NFC), 초음파 통신(Ultra Sound Communication: USC), 가시광 통신(Visible Light Communication: VLC), 와이 파이(Wi-Fi), 와이 파이 다이렉트(Wi-Fi Direct), 5G NR (New Radio) 중 적어도 하 나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 네트워크를 통해서 통신하는 인공지능 모델 생성 장치는 이동통신을 위한 기술표준 및 표준 통신 방식을 준 수할 수 있다. 예를 들어, 표준 통신 방식은 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTEA(Long Term Evolution-Advanced) 및 5G NR(New Radio) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0037790", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치의 구성을 개략적으로 설명하기 위한 도면이다. 도 2는 본 발명의 몇몇 실시예에 따른 인공지능 모델 및 조합 웨이트 데이터 생성부에 대한 설명을 위한 도면이 다. 도 3은 본 발명의 몇몇 실시예들에 따른 웨이트 데이터의 업데이트 과정을 설명하기 위한 예시적인 도면이다. 도 4는 본 발명의 몇몇 실시예에 따른 웨이트 조합 모듈이 조합 웨이트 데이터를 생성하는 과정을 설명하기 위 한 예시적인 도면이다. 도 5는 본 발명의 몇몇 실시예에 따른 웨이트 데이터와, 웨이트 조합 모듈이 생성하는 조합 웨이트 데이터를 도 식화한 도면이다. 도 6은 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치에서 생성된 인공지능 모델의 성능을 설명하기 위한 도면이다. 도 7은 기존의 인공지능 모델과, 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치에서 생성된 인공지능 모델의 학습 데이터의 개수에 따른 정확도 개선율을 나타내는 그래프이다. 도 8은 본 발명의 몇몇 실시예에 따른 인공지능 모델의 생성 방법을 설명하기 위한 도면이다. 도 9는 본 발명의 다른 몇몇 실시예에 따른 인공지능 모델 생성 장치를 설명하기 위한 도면이다. 도 10은 본 발명의 몇몇 실시예에 따른 인공지능 모델 생성 장치의 하드웨어 구현을 설명하기 위한 도면이다."}
