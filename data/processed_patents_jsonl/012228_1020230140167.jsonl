{"patent_id": "10-2023-0140167", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0056439", "출원번호": "10-2023-0140167", "발명의 명칭": "이미지 캡셔닝 장치 및 그 방법", "출원인": "한국기술교육대학교 산학협력단", "발명자": "오흥선"}}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시키는 사전학습부;다운스트림 데이터셋이 입력될 경우 상기 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포함하는데이터쌍을 생성하는 데이터쌍생성부;생성된 상기 데이터쌍을 상기 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키는 데이터추가부; 및상기 보정데이터셋을 사전 학습된 상기 인공지능모델에 입력시켜 전이학습을 수행하는 전이학습부;를 포함하는 이미지 캡셔닝 장치."}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 데이터쌍생성부는,상기 다운스트림 데이터셋의 각 문장(sentence)에 대응하는 형태를 갖는 상기 추가텍스트를 생성하는 텍스트생성블록; 및상기 추가텍스트에 대응하여 상기 추가이미지를 복수개 생성하는 이미지생성블록;을 포함하는 이미지 캡셔닝 장치."}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 텍스트생성블록은,상기 문장에서 명사 및 형용사를 추출하고, 상기 추출된 명사 및 형용사에서 객체(object) 및 상태(state)를 선택하는 방식으로 샘플링한 후에, 상기 객체 및 상태를 이용하여 상기 다운스트림 데이터셋의 각 문장에 대응하는 형태를 갖는 신규텍스트를 생성하고, 상기 신규텍스트의 스타일전이를 수행하는 방식으로 상기 추가텍스트를생성하는이미지 캡셔닝 장치."}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 텍스트생성블록은,상기 다운스트림 데이터셋으로부터 랜덤문장(random sentence)을 복수개 추출하고, 상기 랜덤문장과 상기 신규텍스트에 대해 이미지뷰(image view)와 관련된 단어구를 추가하는 방식으로 상기 스타일전이를 수행하는이미지 캡셔닝 장치."}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0056439-3-사전학습부에서 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시키는 단계;데이터쌍생성부에서 다운스트림 데이터셋이 입력될 경우 상기 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포함하는 데이터쌍을 생성하는 단계;데이터추가부에서 생성된 상기 데이터쌍을 상기 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키는 단계; 및전이학습부에서 상기 보정데이터셋을 사전 학습된 상기 인공지능모델에 입력시켜 전이학습을 수행하는 단계;를 포함하는 이미지 캡셔닝 방법."}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 데이터쌍을 생성하는 단계는,상기 데이터쌍생성부에 구비되는 텍스트생성블록에서 상기 다운스트림 데이터셋의 각 문장에 대응하는 형태를갖는 상기 추가텍스트를 생성하는 단계; 및상기 데이터쌍생성부에 구비되는 이미지생성블록에서 상기 추가텍스트에 대응하여 상기 추가이미지를 복수개 생성하는 단계;를 포함하는 이미지 캡셔닝 방법."}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 추가텍스트를 생성하는 단계는,상기 텍스트생성블록에서 상기 문장에서 명사 및 형용사를 추출하고, 상기 추출된 명사 및 형용사에서 객체(object) 및 상태(state)를 선택하는 방식으로 샘플링한 후에, 상기 객체 및 상태를 이용하여 상기 다운스트림데이터셋의 각 문장에 대응하는 형태를 갖는 신규텍스트를 생성하고, 상기 신규텍스트의 스타일전이를 수행하는방식으로 상기 추가텍스트를 생성하는이미지 캡셔닝 방법."}
{"patent_id": "10-2023-0140167", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 추가텍스트를 생성하는 단계는,상기 텍스트생성블록에서 상기 다운스트림 데이터셋으로부터 랜덤문장(random sentence)을 복수개 추출하고, 상기 랜덤문장과 상기 신규텍스트에 대해 이미지뷰(image view)와 관련된 단어구를 추가하는 방식으로 상기 스타일전이를 수행하는이미지 캡셔닝 방법."}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이미지 캡셔닝 장치 및 그 방법에 관한 것으로, 기준데이터셋을 이용한 사전 학습을 통해 인공지능모 델을 사전 학습시키는 사전학습부; 다운스트림 데이터셋이 입력될 경우 상기 다운스트림 데이터셋에 대응하는 추 가텍스트와 추가이미지를 포함하는 데이터쌍을 생성하는 데이터쌍생성부; 생성된 상기 데이터쌍을 상기 다운스트 림 데이터셋에 추가하여 보정데이터셋을 입력시키는 데이터추가부; 및 상기 보정데이터셋을 사전 학습된 상기 인 공지능모델에 입력시켜 전이학습을 수행하는 전이학습부;를 포함함으로써, 적은 크기의 데이터셋의 입력으로도 이미지 캡셔닝 성능을 향상시킬 수 있어 인공지능모델의 강건성을 효과적으로 확보할 수 있다."}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시킨 후에, 다운스트림 데이터셋 이 입력될 경우 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포함하는 데이터쌍을 생성하고, 이 데이터쌍을 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키며, 보정데이터셋을 사전 학습된 인공지능모델에 입력시켜 전이학습을 수행함으로써, 적은 크기의 데이터셋의 입력으로도 이미지 캡셔닝 성능을 향상시킬 수 있어 인공지능모델의 강건성을 효과적으로 확보할 수 있는 이미지 캡셔닝 장치 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "잘 알려진 바와 같이, 최근 고성능 GPU(Graphic Processing Unit)의 사용으로 처리 가능한 연산량이 대폭 증가 함에 따라, 패턴을 인식하는데 연산량이 많이 필요한 딥러닝기술이 계속 연구되고 있다. 예를 들면, 합성곱신경망(CNN : Convolution neural network) 등과 같은 신경망의 발달과 함께 객체인식, 이미 지분류 등과 같은 이미지프로세싱 연구가 상당히 빠른 속도로 진행되고 있는데, 헬스케어 분야의 딥러닝기술 적 용으로 인하여, 사람이 포함된 영상이해, 상황인식 등과 같은 연구가 심도있게 진행되면서, 딥러닝기반의 이미 지 캡셔닝의 중요도가 부각되고 있다. 여기에서, 이미지 캡셔닝(Image captioning)은 입력된 이미지를 인공지능모델(예를 들면, 합성곱신경망(CNN) 등)을 통하여 특징을 추출하고, 학습된 단어특징공간에 매핑함으로써, 입력된 이미지의 설명문을 생산하는 기법 으로서, 영상이해 및 상황인식에 가장 근접한 연구 중 하나이다. 예를 들면, 이미지 캡셔닝은 도 1에 도시한 바와 같이 이미지의 컨텐츠를 단어(word)와 문장(sentence)을 포함 하는 언어(language)로 설명하는 기법으로, 대량의 데이터셋(large-scale dataset)을 이용하여 인공지능모델을 사전 학습(pre-training)시킨 후에, 상대적으로 적은 데이터(downstream)를 사전 학습된 인공지능모델에 입력시 켜 파인튜닝(fin-tuning)하는 방식으로 수행될 수 있는데, 일반적으로 큰 모델(large model), 큰 데이터셋 (large dataset)의 경우 다운스트림 입력에 대응하는 출력 성능이 높게 나타날 수 있다. 하지만, 큰 데이터셋(large data)을 사용한 사전학습모델들과는 달리, 다운스트림데이터는 상대적으로 적은 데 이터이기 때문에, 인공지능모델의 강건성(robustness)을 달성하기 어려운 문제점이 있고, 현실세계(real worl d)의 분포가 다운스트림 데이터셋 분포보다 상대적으로 크기 때문에, 다운스트림 데이터셋은 실용응용분야 (practical application)에 맞지 않아 제로샷러닝(Zero-shot learning), 퓨샷러닝(Few-shot learning)에 적용 하기 어려운 문제점이 있다. 예를 들면, 다운스트림 태스크(task)마다 분포가 존재하기 때문에, 동일 인공지능모델을 사용할 경우 다운스트 림 데이터셋에서의 성능이 일관되지 못하게 되는데, 개 검출(Dog Detection)을 기반으로 고양이 검출(Cat Detection)이 불가하능하여 서로 다른 데이터셋들에 대해서는 인퍼런스(inference)성능을 보장하기 어려운 문제 점이 있다. 또한, 이미지 캡셔닝의 성능이 데이터셋에 의존적이기 때문에, 다운스트림 태스트를 진행하기 위해서는 각 데이 터셋으로 매번 학습을 진행해야 하는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국등록특허 제10-2293950호(2021.08.20.등록)"}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시킨 후에, 다운스트림 데이터셋 이 입력될 경우 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포함하는 데이터쌍을 생성하고, 이 데이터쌍을 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키며, 보정데이터셋을 사전 학습된 인공지능 모델에 입력시켜 전이학습을 수행함으로써, 적은 크기의 데이터셋의 입력으로도 이미지 캡셔닝 성능을 향상시킬 수 있어 인공지능모델의 강건성을 효과적으로 확보할 수 있는 이미지 캡셔닝 장치 및 그 방법을 제공하고자 한 다. 본 발명의 실시예들의 목적은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아 래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시키는 사전학 습부; 다운스트림 데이터셋이 입력될 경우 상기 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포 함하는 데이터쌍을 생성하는 데이터쌍생성부; 생성된 상기 데이터쌍을 상기 다운스트림 데이터셋에 추가하여 보 정데이터셋을 입력시키는 데이터추가부; 및 상기 보정데이터셋을 사전 학습된 상기 인공지능모델에 입력시켜 전 이학습을 수행하는 전이학습부;를 포함하는 이미지 캡셔닝 장치가 제공될 수 있다. 또한, 본 발명의 일 측면에 따르면, 상기 데이터쌍생성부는, 상기 다운스트림 데이터셋의 각 문장에 대응하는 형태를 갖는 상기 추가텍스트를 생성하는 텍스트생성블록; 및 상기 추가텍스트에 대응하여 상기 추가이미지를 복수개 생성하는 이미지생성블록;을 포함하는 이미지 캡셔닝 장치가 제공될 수 있다. 또한, 본 발명의 일 측면에 따르면, 상기 텍스트생성블록은, 상기 문장에서 명사 및 형용사를 추출하고, 상기 추출된 명사 및 형용사에서 객체(object) 및 상태(state)를 선택하는 방식으로 샘플링한 후에, 상기 객체 및 상 태를 이용하여 상기 다운스트림 데이터셋의 각 문장에 대응하는 형태를 갖는 신규텍스트를 생성하고, 상기 신규 텍스트의 스타일전이를 수행하는 방식으로 상기 추가텍스트를 생성하는 이미지 캡셔닝 장치가 제공될 수 있다. 또한, 본 발명의 일 측면에 따르면, 상기 텍스트생성블록은, 상기 다운스트림 데이터셋으로부터 랜덤문장 (random sentence)을 복수개 추출하고, 상기 랜덤문장과 상기 신규텍스트에 대해 이미지뷰(image view)와 관련 된 단어구를 추가하는 방식으로 상기 스타일전이를 수행하는 이미지 캡셔닝 장치가 제공될 수 있다. 본 발명의 다른 측면에 따르면, 사전학습부에서 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시키는 단계; 데이터쌍생성부에서 다운스트림 데이터셋이 입력될 경우 상기 다운스트림 데이터셋에 대응하 는 추가텍스트와 추가이미지를 포함하는 데이터쌍을 생성하는 단계; 데이터추가부에서 생성된 상기 데이터쌍을 상기 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키는 단계; 및 전이학습부에서 상기 보정데이터셋 을 사전 학습된 상기 인공지능모델에 입력시켜 전이학습을 수행하는 단계;를 포함하는 이미지 캡셔닝 방법이 제 공될 수 있다. 또한, 본 발명의 다른 측면에 따르면, 상기 데이터쌍을 생성하는 단계는, 상기 데이터쌍생성부에 구비되는 텍스 트생성블록에서 상기 다운스트림 데이터셋의 각 문장(sentence)에 대응하는 형태를 갖는 상기 추가텍스트를 생 성하는 단계; 및 상기 데이터쌍생성부에 구비되는 이미지생성블록에서 상기 추가텍스트에 대응하여 상기 추가이 미지를 복수개 생성하는 단계;를 포함하는 이미지 캡셔닝 방법이 제공될 수 있다. 또한, 본 발명의 다른 측면에 따르면, 상기 추가텍스트를 생성하는 단계는, 상기 텍스트생성블록에서 상기 문장 에서 명사 및 형용사를 추출하고, 상기 추출된 명사 및 형용사에서 객체(object) 및 상태(state)를 선택하는 방 식으로 샘플링한 후에, 상기 객체 및 상태를 이용하여 상기 다운스트림 데이터셋의 각 문장에 대응하는 형태를 갖는 신규텍스트를 생성하고, 상기 신규텍스트의 스타일전이를 수행하는 방식으로 상기 추가텍스트를 생성하는 이미지 캡셔닝 방법이 제공될 수 있다. 또한, 본 발명의 다른 측면에 따르면, 상기 추가텍스트를 생성하는 단계는, 상기 텍스트생성블록에서 상기 다운 스트림 데이터셋으로부터 랜덤문장(random sentence)을 복수개 추출하고, 상기 랜덤문장과 상기 신규텍스트에 대해 이미지뷰(image view)와 관련된 단어구를 추가하는 방식으로 상기 스타일전이를 수행하는 이미지 캡셔닝 방법이 제공될 수 있다."}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시킨후에, 다운스트림 데이터셋이 입력될 경우 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포함하는 데이터쌍을 생성하고, 이 데 이터쌍을 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키며, 보정데이터셋을 사전 학습된 인공지능모 델에 입력시켜 전이학습을 수행함으로써, 적은 크기의 데이터셋의 입력으로도 이미지 캡셔닝 성능을 향상시킬 수 있어 인공지능모델의 강건성을 효과적으로 확보할 수 있다."}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 실시예들에 대한 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후 술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하"}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "고, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되 는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세히 설명하기로 한다. 도 2는 본 발명의 일 실시예에 따른 이미지 캡셔닝 장치의 블록구성도이고, 도 3 내지 도 8은 본 발명의 일 실 시예에 따른 이미지 캡셔닝 장치의 상세구성을 설명하기 위한 도면이다. 도 2 내지 도 8을 참조하면, 본 발명의 일 실시예에 따른 이미지 캡셔닝 장치는 사전학습부, 데이터쌍생성 부, 데이터추가부, 전이학습부 등을 포함할 수 있다. 사전학습부는 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시키는 구성부로, 기준데 이터셋은 데이터베이스에 미리 수집된 대량의 데이터셋, 네트워크를 통해 크롤링 등의 방식으로 수집되는 대량 의 데이터셋 등을 포함할 수 있으며, 이러한 데이터셋은 이미지(Image)와 캡션(Caption)의 데이터쌍으로 입력될 수 있다. 여기에서, 인공지능모델은 예를 들면, 합성곱신경망(CNN), 순환신경망(RNN : recurrent Neural Network), NIC(Neural Image Caption)모델, BUTD(Bottom-Up and Top-Down Attention)모델, BERT(Bidirectional Encoder Representations from Transformers)모델, CNN 및 RNN을 결합한 하이브리드모델 등을 포함할 수 있다. 데이터쌍생성부는 다운스트림 데이터셋이 입력될 경우 다운스트림 데이터셋에 대응하는 추가텍스트와 추가 이미지를 포함하는 데이터쌍을 생성하는 구성부로, 텍스트생성블록, 이미지생성블록 등을 포함할 수 있다. 여기에서, 텍스트생성블록은 다운스트림 데이터셋의 각 문장(sentence)에 대응하는 형태(또는 표현, 단어, 스타일)를 갖는 추가텍스트를 생성하는 것으로, 문장에서 명사 및 형용사를 추출하고, 추출된 명사 및 형용사에 서 객체(object) 및 상태(state)를 선택하는 방식으로 샘플링한 후에, 객체 및 상태를 이용하여 다운스트림 데 이터셋의 각 문장에 대응하는 형태(또는 표현, 단어, 스타일)를 갖는 신규텍스트를 생성하고, 신규텍스트의 스 타일전이를 수행하는 방식으로 추가텍스트를 생성할 수 있다. 또한, 텍스트생성블록은 다운스트림 데이터셋으로부터 랜덤문장(random sentence)을 복수개 추출하고, 랜 덤문장과 신규텍스트에 대해 이미지뷰(image view)와 관련된 단어구를 추가하는 방식으로 스타일전이를 수행할 수 있다. 예를 들면, 텍스트생성블록은 도 4에 도시한 바와 같이 텍스트제너레이터(Text generator)를 포함하여 다 운스트림 데이터셋에 존재하는 문장과 유사한 문장을 캡션항목에 대응하여 생성할 수 있는데, NER추출기(Named Entity Recognition extractor)를 통해 다운스트림 데이터셋의 캡션항목에서 랜덤으로 복수개의 문장을 추출하 여 샘플링하고, 샘플링된 복수의 문장에서 각각의 객체 및 상태를 추출하는 방식으로 객체에 대응하는 명사와 상태에 대응하는 형용사를 NER셋으로 하여 추출할 수 있다. 또한, 텍스트생성블록은 도 4에 도시한 바와 같이 NER샘플러(Named Entity Recognition sampler)를 이용 하여 NER추출기를 통해 추출된 NER셋에 존재하는 객체와 상태를 랜덤하게 샘플링하여 복수개의 객체와 복수개의 상태를 생성하는 방식으로 추가텍스트에 추가할 객체 및 상태를 선택할 수 있다. 여기에서, 객체는 예를 들면,3-4개를 생성할 수 있고, 상태는 예를 들면, 1-2개를 생성할 수 있다. 그리고, 텍스트생성블록은 도 4에 도시한 바와 같이 설명기반 텍스트제너레이터(Instruction-based Text Generator)를 통해 선택된 객체 및 상태를 포함하는 새로운 신규텍스트(generated text)를 생성할 수 있는데, 설명(Instruction)과 입력(input)을 통해 어떤 단어를 추가할 것인지에 대한 정보를 제너레이터에 전달할 수 있 고, 입력은 선택된 객체 및 상태를 사용할 수 있다. 예를 들면, 설명(Instruction)은 \"Make a description of specific picture, Use word in input. Do not write word like the picture shows\"이고, 입력(Input)은 \"wine, fishing, boat\"인 포맷으로 제너레이터에 입 력될 수 있다. 다음에, 텍스트제너레이터(Text generator)를 통해 획득된 문장(즉, 설명(Instruction)과 입력(Input))은 다운 스트림 데이터셋의 스타일과 차이가 존재할 수 있기 때문에, 텍스트생성블록은 도 5에 도시한 바와 같이 설명기반 스타일트랜스퍼(Instruction-based Style transfer)를 통해 문장의 스타일을 변환시킬 수 있다. 이러한 텍스트생성블록은 다운스트림 데이터셋으로부터 복수개(N개)의 랜덤문장을 추출하여 추출된 문장을 설명(instruction)으로 구성하고, 생성된 신규텍스트(generated text)를 변환시킬 문장인 입력(input)으로 구성 할 수 있다. 여기에서, 설명(Instruction)은 \"Change text style of given input sentence into {sentence 1 },.. {sentence N }\"이고, 입력(Input)은 \"generated text\"인 포맷으로 구성할 수 있고, 예를 들면, \"A bottle of wine and two glasses are placed outdoors, while a fishing boat sails in tanzania.\"를 \"A bottle of wine and two glasses are placed outdoors, while a fishing boat sails in the Zanzibar Channel, Tanzania.\"로 하여 스타일을 변환시킬 수 있다. 또한, 텍스트생성블록은 랜덤문장과 신규텍스트를 이용하여 스타일이 변환된 문장에 대해 이미지뷰와 관련 된 단어구를 추가할 수 있는데, 도 5에 도시한 바와 같이 사진의 구도인 이미지뷰와 관련된 단어구를 뷰사전데 이터베이스(View dictionary)에서 추출하여 변환된 문장에 추가할 수 있다. 이러한 텍스트생성블록은 도 5에 도시한 바와 같이 뷰선택기(View selector)를 통해 사진의 구도와 관련된 단어구들(예를 들면, A wide shot of ~, A straight view ~ 등)을 변환된 문장에 추가한 후 설명(instructio n)에 입력시킬 수 있고, 이 후 설명기반 모델을 이용하여 가장 자연스러운 구도를 선택할 수 있다. 예를 들면, 설명(Instruction)은 \"Choose the best composition when you taking picture of {생성된 문장}\"이 고, 입력(Input)은 \"무작위로 선정한 구도 N개\"인 포맷으로 입력할 수 있고, 예를 들면, \"A bottle of wine and two glasses are placed outdoors, while a fishing boat sails in the Zanzibar Channel, Tanzania.\"를 \"A straight view of bottle of wine and two glasses are placed outdoors, while a fishing boat sails in the Zanzibar Channel, Tanzania.\"로 하여 스타일변환 텍스트로 생성할 수 있다. 이러한 스타일변환 텍스트는 추가텍스트로 하여 이미지생성블록 및 데이터추가부로 제공될 수 있다. 이미지생성블록은 추가텍스트에 대응하여 추가이미지를 복수개 생성하는 것으로, 이미지제너레이터(Image generator)를 통해 스타일변환 텍스트(즉, 추가텍스트)에 대응하는 이미지를 생성할 수 있는데, 도 6에 도시한 바와 같이 다운스트림 데이터셋에 대응하여 유사하게 변환된 스타일변환 텍스트를 이용하여 신규이미지를 생성 할 수 있다. 여기에서, 신규이미지는 하나의 스타일변환 텍스트에 대해 복수개(N개)의 이미지를 생성하여 스타일변환 텍스트 에 대한 다양성을 보존할 수 있으며, 이미지제너레이터 모델은 디퓨전(diffusion)을 기반으로 하는 모델뿐만 아 니라 종래에 제시된 다양한 모델을 사용할 수 있다. 예를 들면, 이미지생성블록은 추가텍스트가 \"A group of farmers can be seen discussing and examining the bright red tomatoes in the greenhouse.\"인 경우 및 \"A young girl with freckles is seen in close up, smiling and waving at the camera on a sunny day.\"인 경우 도 7에 도시한 바와 같은 추가이미지를 각각 생성 할 수 있다. 상술한 바와 같이 생성된 추가이미지는 데이터추가부로 제공될 수 있다. 데이터추가부는 생성된 데이터쌍을 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키는 구성부로, 텍스트생성블록을 통해 생성된 추가텍스트와 이미지생성블록을 통해 생성된 추가이미지는 데이터쌍으로 하여 데이터쌍생성부로부터 제공될 수 있으며, 이러한 데이터쌍에서 추가텍스트는 도 8에 도시한 바와 같이 다운스트림 데이터셋의 캡션항목에 추가할 수 있고, 추가이미지는 다운스트림 데이터셋의 이미지항목에 추 가하여 보정데이터셋을 입력시킬 수 있다. 전이학습부는 보정데이터셋을 사전 학습된 인공지능모델에 입력시켜 전이학습을 수행하는 구성부로, 데이 터추가부로부터 입력되는 보정데이터셋을 이용하여 사전학습부를 통해 사전 학습된 인공지능모델에 해당 보정데이터셋을 입력하여 파인튜닝(fine-tuning)을 수행한 후 출력함으로써, 이미지캡셔닝을 수행할 수 있 다. 따라서, 본 발명의 일 실시예에 따르면, 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시 킨 후에, 다운스트림 데이터셋이 입력될 경우 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포함 하는 데이터쌍을 생성하고, 이 데이터쌍을 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키며, 보정데 이터셋을 사전 학습된 인공지능모델에 입력시켜 전이학습을 수행함으로써, 적은 크기의 데이터셋의 입력으로도 이미지 캡셔닝 성능을 향상시킬 수 있어 인공지능모델의 강건성을 효과적으로 확보할 수 있다. 도 9 및 도 10은 본 발명의 다른 실시예에 따라 이미지 캡셔닝을 수행하는 과정을 나타낸 플로우차트이다. 도 9를 참조하면, 사전학습부에서 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습시킬 수 있다(단계210). 여기에서, 기준데이터셋은 데이터베이스에 미리 수집된 대량의 데이터셋, 네트워크를 통해 크롤링 등의 방식으 로 수집되는 대량의 데이터셋 등을 포함할 수 있으며, 이러한 데이터셋은 이미지(Image)와 캡션(Caption)의 데 이터쌍으로 입력될 수 있다. 여기에서, 인공지능모델은 예를 들면, 합성곱신경망(CNN), 순환신경망(RNN), NIC모델, BUTD모델, BERT모델, CNN 및 RNN을 결합한 하이브리드모델 등을 포함할 수 있다. 그리고, 데이터쌍생성부에서 다운스트림 데이터셋이 입력될 경우 다운스트림 데이터셋에 대응하는 추가텍 스트와 추가이미지를 포함하는 데이터쌍을 생성할 수 있다(단계220). 상기 데이터쌍을 생성하는 단계는, 데이터쌍생성부에 구비되는 텍스트생성블록에서 다운스트림 데이터셋의 각 문장(sentence)에 대응하는 형태(또는 표현, 단어, 스타일)를 갖는 추가텍스트를 생성하는 단계 와, 데이터쌍생성부에 구비되는 이미지생성블록에서 추가텍스트에 대응하여 추가이미지를 복수 개 생성하는 단계를 포함할 수 있다. 여기에서, 상기 추가텍스트를 생성하는 단계는, 텍스트생성블록에서 문장에서 명사 및 형용사를 추출 하고, 추출된 명사 및 형용사에서 객체(object) 및 상태(state)를 선택하는 방식으로 샘플링한 후에, 객체 및 상태를 이용하여 상기 다운스트림 데이터셋의 각 문장에 대응하는 형태(또는 표현, 단어, 스타일)를 갖는 신규 텍스트를 생성하고, 신규텍스트의 스타일전이를 수행하는 방식으로 추가텍스트를 생성할 수 있다. 또한, 상기 추가텍스트를 생성하는 단계는, 텍스트생성블록에서 다운스트림 데이터셋으로부터 랜덤문 장(random sentence)을 복수개 추출하고, 랜덤문장과 신규텍스트에 대해 이미지뷰(image view)와 관련된 단어구 를 추가하는 방식으로 스타일전이를 수행할 수 있다. 예를 들면, 추가텍스트를 생성하는 단계에서는 텍스트생성블록에서 텍스트제너레이터를 포함하여 다 운스트림 데이터셋에 존재하는 문장과 유사한 문장을 캡션항목에 대응하여 생성할 수 있는데, NER추출기를 통해 다운스트림 데이터셋의 캡션항목에서 랜덤으로 복수개의 문장을 추출하여 샘플링하고, 샘플링된 복수의 문장에 서 각각의 객체 및 상태를 추출하는 방식으로 객체에 대응하는 명사와 상태에 대응하는 형용사를 NER셋으로 하 여 추출할 수 있다. 또한, 추가텍스트를 생성하는 단계에서는 텍스트생성블록에서 NER샘플러를 이용하여 NER추출기를 통 해 추출된 NER셋에 존재하는 객체와 상태를 랜덤하게 샘플링하여 복수개의 객체와 복수개의 상태를 생성하는 방 식으로 추가텍스트에 추가할 객체 및 상태를 선택할 수 있다. 여기에서, 객체는 예를 들면, 3-4개를 생성할 수 있고, 상태는 예를 들면, 1-2개를 생성할 수 있다. 그리고, 추가텍스트를 생성하는 단계에서는 텍스트생성블록에서 설명기반 텍스트제너레이터를 통해 선택된 객체 및 상태를 포함하는 새로운 신규텍스트를 생성할 수 있는데, 설명과 입력을 통해 어떤 단어를 추가 할 것인지에 대한 정보를 제너레이터에 전달할 수 있고, 입력은 선택된 객체 및 상태를 사용할 수 있다.다음에, 추가텍스트를 생성하는 단계에서는 텍스트제너레이터를 통해 획득된 문장(즉, 설명과 입력)은 다 운스트림 데이터셋의 스타일과 차이가 존재할 수 있기 때문에, 텍스트생성블록에서 설명기반 스타일트랜스 퍼를 통해 문장의 스타일을 변환시킬 수 있다. 이러한 텍스트생성블록에서는 다운스트림 데이터셋으로부터 복수개(N개)의 랜덤문장을 추출하여 추출된 문 장을 설명으로 구성하고, 생성된 신규텍스트를 변환시킬 문장인 입력으로 구성할 수 있다. 또한, 추가텍스트를 생성하는 단계에서는 텍스트생성블록에서 랜덤문장과 신규텍스트를 이용하여 스 타일이 변환된 문장에 대해 이미지뷰와 관련된 단어구를 추가할 수 있는데, 사진의 구도인 이미지뷰와 관련된 단어구를 뷰사전데이터베이스에서 추출하여 변환된 문장에 추가할 수 있다. 이러한 텍스트생성블록에서는 뷰선택기를 통해 사진의 구도와 관련된 단어구들(예를 들면, A wide shot of ~, A straight view ~ 등)을 변환된 문장에 추가한 후 설명(instruction)에 입력시킬 수 있고, 이 후 설명기반 모델을 이용하여 가장 자연스러운 구도를 선택할 수 있다. 이러한 스타일변환 텍스트는 추가텍스트로 하여 이미지생성블록 및 데이터추가부로 제공될 수 있다. 한편, 추가이미지를 복수개 생성하는 단계에서는 이미지생성블록에서 이미지제너레이터를 통해 스타 일변환 텍스트(즉, 추가텍스트)에 대응하는 이미지를 생성할 수 있는데, 다운스트림 데이터셋에 대응하여 유사 하게 변환된 스타일변환 텍스트를 이용하여 신규이미지를 생성할 수 있다. 여기에서, 신규이미지는 하나의 스타일변환 텍스트에 대해 복수개(N개)의 이미지를 생성하여 스타일변환 텍스트 에 대한 다양성을 보존할 수 있으며, 이미지제너레이터 모델은 디퓨전(diffusion)을 기반으로 하는 모델뿐만 아 니라 종래에 제시된 다양한 모델을 사용할 수 있다. 상술한 바와 같이 생성된 추가이미지는 데이터추가부로 제공될 수 있다. 다음에, 데이터추가부에서 생성된 데이터쌍을 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시킬 수 있다(단계230). 예를 들면, 텍스트생성블록을 통해 생성된 추가텍스트와 이미지생성블록을 통해 생성된 추가이미지는 데이터쌍으로 하여 데이터쌍생성부로부터 데이터추가부에 제공될 수 있으며, 데이터추가부에서 는 이 데이터쌍에서 추가텍스트는 다운스트림 데이터셋의 캡션항목에 추가할 수 있고, 추가이미지는 다운스트림 데이터셋의 이미지항목에 추가하여 보정데이터셋을 입력시킬 수 있다. 이어서, 전이학습부에서 보정데이터셋을 사전 학습된 인공지능모델에 입력시켜 전이학습을 수행할 수 있다 (단계240). 이러한 전이학습부에서는 데이터추가부로부터 입력되는 보정데이터셋을 이용하여 사전학습부를 통해 사전 학습된 인공지능모델에 해당 보정데이터셋을 입력하여 파인튜닝(fine-tuning)을 수행한 후 출력함으 로써, 이미지캡셔닝을 수행할 수 있다. 따라서, 본 발명의 다른 실시예에 따르면, 기준데이터셋을 이용한 사전 학습을 통해 인공지능모델을 사전 학습 시킨 후에, 다운스트림 데이터셋이 입력될 경우 다운스트림 데이터셋에 대응하는 추가텍스트와 추가이미지를 포 함하는 데이터쌍을 생성하고, 이 데이터쌍을 다운스트림 데이터셋에 추가하여 보정데이터셋을 입력시키며, 보정 데이터셋을 사전 학습된 인공지능모델에 입력시켜 전이학습을 수행함으로써, 적은 크기의 데이터셋의 입력으로 도 이미지 캡셔닝 성능을 향상시킬 수 있어 인공지능모델의 강건성을 효과적으로 확보할 수 있다. 이상의 설명에서는 본 발명의 다양한 실시예들을 제시하여 설명하였으나 본 발명이 반드시 이에 한정되는 것은"}
{"patent_id": "10-2023-0140167", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "아니며, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명의 기술적 사상을 벗어나지 않는 범 위 내에서 여러 가지 치환, 변형 및 변경이 가능함을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2023-0140167", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 이미지 캡셔닝을 설명하기 위한 도면이며, 도 2는 본 발명의 일 실시예에 따른 이미지 캡셔닝 장치의 블록구성도이고,도 3 내지 도 8은 본 발명의 일 실시예에 따른 이미지 캡셔닝 장치의 상세구성을 설명하기 위한 도면이며, 도 9 및 도 10은 본 발명의 다른 실시예에 따라 이미지 캡셔닝을 수행하는 과정을 나타낸 플로우차트이다."}
