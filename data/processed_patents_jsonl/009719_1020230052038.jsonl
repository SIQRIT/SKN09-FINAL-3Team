{"patent_id": "10-2023-0052038", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0155567", "출원번호": "10-2023-0052038", "발명의 명칭": "서버의 구동 방법, 이를 이용해 음성 합성 모델을 학습하는 방법, 이를 제공하는 서버, 및 이", "출원인": "엔에이치엔 주식회사", "발명자": "이현정"}}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시스템 메모리 및 상기 시스템 메모리를 참조하여 동작하는 프로세서를 포함하는 서버의 구동 방법에 있어서, 하나 이상의 라벨 값을 갖는 제1 세트의 표준어 문장들을 상기 시스템 메모리에 로드하는 단계; 로드된 상기 제1 세트의 표준어 문장들과 대응하며, 대응하는 표준어 문장의 라벨 값과 같거나 또는 상이한 상기 라벨 값을 갖는 제1 사투리 문장들을 로드하는 단계; 상기 제1 세트의 표준어 문장들 및 상기 제1 사투리 문장들을 이용해 언어 변환 모델을 생성하는 단계; 하나 이상의 상기 라벨 값을 갖는 제2 세트의 표준어 문장을 로드하는 단계; 및로드한 상기 제2 세트의 표준어 문장을 상기 언어 변환 모델에 입력하여 상기 제2 세트의 표준어 문장에 대응하는 제2 사투리 문장을 생성하는 단계를 포함하는 구동 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 라벨 값은, 지역, 성별, 연령대, 감정 상태, 및 문장 종류 중 적어도 하나를 나타내는 구동 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 언어 변환 모델을 생성하는 단계는, 인코더에 상기 제1 세트의 표준어 문장들 중 어느 하나를 입력하는 단계; 상기 인코더에 입력된 표준어 문장에 대응하는 사투리 문장을 디코더로부터 획득하는 단계; 및획득한 상기 사투리 문장과 미리 준비된 사투리 문장을 비교하여 상기 인코더 및 상기 디코더를 학습하는 단계를 포함하는 구동 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제2 세트의 표준어 문장은 상기 시스템 메모리에 로드된 챗봇 모델을 상기 프로세서를 통해 실행하여 생성한 표준어 문장을 포함하는 구동 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "언어 변환 모델, 텍스트-투-스피치 모델, 및 음성 합성 모델이 로드되는 시스템 메모리 및 상기 시스템 메모리를 참조하여 동작하는 프로세서를 포함하는 서버의 음성 합성 모델을 학습하는 방법에 있어서, 하나 이상의 라벨 값을 갖는 표준어 문장을 상기 시스템 메모리에 로드하고, 상기 언어 변환 모델을 실행시켜,그에 대응하는 사투리 문장을 생성하는 단계; 상기 텍스트-투-스피치 모델을 실행시켜, 생성한 상기 사투리 문장을 상기 텍스트-투-스피치 모델에 입력하여공개특허 10-2024-0155567-3-상기 사투리 문장에 대응하는 음성 파형 데이터를 생성하는 단계; 및생성된 상기 음성 파형 데이터를 이용해 상기 음성 합성 모델을 학습하는 단계를 포함하는 음성 합성 모델을 학습하는 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 하나 이상의 라벨 값을 갖는 표준어 문장을 상기 시스템 메모리에 로드하고, 상기 언어 변환 모델을 실행시켜, 그에 대응하는 사투리 문장을 생성하는 단계는, 상기 표준어 문장을 로드하는 단계; 상기 언어 변환 모델을 실행시켜, 로드한 상기 표준어 문장을 상기 언어 변환 모델에 입력하는 단계; 및상기 표준어 문장에 대응하는 사투리 문장을 생성하는 단계를 포함하는 음성 합성 모델을 학습하는 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 라벨 값은, 지역, 성별, 연령대, 감정 상태, 및 문장 종류 중 적어도 하나를 나타내는 음성 합성 모델을학습하는 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 텍스트-투-스피치 모델은 상기 라벨 값에 대응하는 특성 값을 갖는 음성 파형 데이터를 생성하는 음성 합성 모델을 학습하는 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 특성 값은, 주파수 특성 값, 지속 기간 특성 값, 및 고저 특성 값 중 적어도 하나를 나타내는 음성 합성모델을 학습하는 방법."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "네트워크를 통해 복수의 단말기들과 통신 가능한 서버에 있어서, 언어 변환 모델을 저장하는 저장 매체; 운영 체제를 저장하는 시스템 메모리; 및상기 저장 매체에 저장된 상기 언어 변환 모델을 상기 시스템 메모리에 로드하는 프로세서를 포함하고, 상기 프로세서는, 하나 이상의 라벨 값을 갖는 표준어 문장을 로드하고, 로드한 상기 표준어 문장을 상기 언어 변환 모델에 입력하여 상기 표준어 문장에 대응하는 사투리 문장을 생성하고, 생성한 상기 사투리 문장을 상기 복수의 단말기들중 어느 하나에 전송하는 서버. 공개특허 10-2024-0155567-4-청구항 11 제10항에 있어서, 상기 라벨 값은, 지역, 성별, 연령대, 감정 상태, 및 문장 종류 중 적어도 하나를 나타내는 서버."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 표준어 문장 및 상기 라벨 값은 상기 네트워크를 통해 상기 복수의 단말기들 중 상기 어느 하나로부터 수신하는 서버."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 저장 매체는 텍스트-투-스피치 모델을 더 저장하고, 상기 프로세서는, 상기 텍스트-투-스피치 모델을 실행시켜, 생성한 상기 사투리 문장을 입력하고, 입력한 상기 사투리 문장에 상응하는 제1 음성 파형 데이터를 생성하는 서버."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 저장 매체는 음성 합성 모델을 더 저장하고, 상기 프로세서는, 상기 음성 합성 모델을 실행시켜, 상기 제1 음성 파형 데이터를 입력하고, 상기 라벨 값에 상응하는 특성 값을갖는 제2 음성 파형 데이터를 생성하는 서버."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 제2 음성 파형 데이터를 상기 네트워크를 통해 상기 복수의 단말기들 중 상기 어느 하나에 송신하고, 상기 복수의 단말기들 중 상기 어느 하나에 문장 변환 블록 및 음성 변환 블록을 표시하며, 상기 문장 변환 블록에서 상기 사투리 문장을 표시하고, 상기 음성 변환 블록에 대한 상기 어느 하나의 단말기의 입력을 받아 상기 제2 음성 파형 데이터를 전송하는 서버."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 복수의 단말기들 중 상기 어느 하나에 톤 조절 블록, 강세 조절 블록, 및 속도 조절 블록 중 적어도 하나를 표시하고, 상기 톤 조절 블록, 상기 강세 조절 블록, 및 상기 속도 조절 블록 중 적어도 하나에 대한 상기 어느 하나의 단공개특허 10-2024-0155567-5-말기의 입력을 받아 상기 제2 음성 파형 데이터의 주파수, 지속 기간, 및 고저 중 적어도 하나를 변경하고, 상기 주파수, 상기 지속 기간, 및 상기 고저 중 적어도 하나가 변경된 상기 제2 음성 파형 데이터를 상기 어느하나의 단말기에 송신하는 서버."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "복수의 단말기들; 및 네트워크를 통해 상기 복수의 단말기들과 통신 가능한 서버를 포함하고, 상기 서버는, 하나 이상의 라벨 값을 갖는 표준어 문장을 로드하고, 로드한 상기 표준어 문장을 언어 변환 모델에 입력하여상기 표준어 문장에 대응하는 사투리 문장을 생성하고, 생성한 상기 사투리 문장을 상기 복수의 단말기들 중 어느 하나에 전송하는 사투리 변환 시스템."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 표준어 문장 및 상기 라벨 값은 상기 네트워크를 통해 상기 복수의 단말기들 중 상기 어느 하나로부터 수신하는 사투리 변환 시스템."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 상기 서버는, 상기 복수의 단말기들 중 상기 어느 하나에 문장 변환 블록 및 음성 변환 블록을 표시하며, 상기 문장 변환 블록에서 상기 사투리 문장을 표시하고, 상기 음성 변환 블록에 대한 상기 복수의 단말기들 중 상기 어느 하나의 단말기의 입력을 통해, 상기 사투리 문장에 대응하는 음성 파형 데이터를 전송하는 사투리 변환 시스템."}
{"patent_id": "10-2023-0052038", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 서버는, 상기 복수의 단말기들 중 상기 어느 하나에 톤 조절 블록, 강세 조절 블록, 및 속도 조절 블록 중 적어도 하나를 표시하고, 상기 톤 조절 블록, 상기 강세 조절 블록, 및 상기 속도 조절 블록 중 적어도 하나에 대한 상기 어느 하나의 단말기의 입력을 받아 상기 음성 파형 데이터의 주파수, 지속 기간, 및 고저 중 적어도 하나를 변경하고, 상기 주파수, 상기 지속 기간, 및 상기 고저 중 적어도 하나가 변경된 상기 음성 파형 데이터를 상기 어느 하나의 단말기에 송신하는 사투리 변환 시스템."}
{"patent_id": "10-2023-0052038", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시예들은, 시스템 메모리 및 시스템 메모리를 참조하여 동작하는 프로세서를 포함하는 서버의 구동 방법에 있어서, 하나 이상의 라벨 값을 갖는 제1 세트의 표준어 문장들을 시스템 메모리에 로드하는 단계, 로드 된 제1 세트의 표준어 문장들과 대응하며, 대응하는 표준어 문장의 라벨 값과 같거나 또는 상이한 라벨 값을 갖 (뒷면에 계속)"}
{"patent_id": "10-2023-0052038", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 실시예들은 서버의 구동 방법, 이를 이용해 음성 합성 모델을 학습하는 방법, 이를 제공하는 서버, 및 이를 포함하는 사투리 변환 시스템에 관한 것이다."}
{"patent_id": "10-2023-0052038", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보화 기술이 발달함에 따라, 다양한 언어 변환 모델이 제공되고 있다. 언어 변환 모델은 일례로, 번역기와 같 은 형태로 제공되고 있다. 이러한 번역기는 서로 다른 국가에서 서로 다른 언어를 구사하는 사람들 간에 의사소 통을 가능하게 하는 기능을 제공할 수 있다. 그러나, 하나의 국가 내에서도 다양한 계층의 언어가 사용된다. 예를 들면, 하나의 국가 내에서도 표준어와, 표 준어 이외의 방언이 사용된다. 방언 중에서도, 지역에 따라 서로 다른 언어를 사용하도록 분화되는 경우가 있다. 지역에 따라 서로 다른 언어를 사용하도록 분화된 것을 통상적으로 사투리라고 한다. 한편, 사투리는 해당 지역 내에서만 집중적으로 사용되는 경우가 많다. 이에 따라, 다양한 텍스트의 사투리 문 장 데이터, 다양한 억양의 사투리 음성 파형 데이터를 획득하는 것이 어려운 실정이다."}
{"patent_id": "10-2023-0052038", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시예들이 해결하고자 하는 기술적 과제는 다양한 라벨 값(예를 들면, 지역, 연령, 성별, 감정 상태, 문장 종류 등)을 갖는 사투리 문장을 효과적으로 생성할 수 있는 서버의 구동 방법, 이를 이용해 음성 합 성 모델을 학습하는 방법, 이를 제공하는 서버, 및 이를 포함하는 사투리 변환 시스템을 제공하는 데 있다. 본 개시의 실시예들이 해결하고자 하는 기술적 과제는 유사한 특성 값(예를 들면, 주파수 특성 값, 지속 시간 특성 값, 고저 특성 값)을 갖는 음성 파형 데이터를 기초로 음성 합성 모델을 생성함으로써, 음성 합성 모델을 정교하게 생성 및/또는 학습할 수 있는 서버의 구동 방법, 이를 이용해 음성 합성 모델을 학습하는 방법, 이를 제공하는 서버, 및 이를 포함하는 사투리 변환 시스템을 제공하는 데 있다. 본 개시의 실시예들이 해결하고자 하는 기술적 과제는, 단말기의 사용자가 입력한 표준어 문장 및 이의 옵션에 부합하는 사투리 문장 및 이의 음성 파형 데이터를 단말기에 제공할 수 있는 서버의 구동 방법, 이를 이용해 음 성 합성 모델을 학습하는 방법, 이를 제공하는 서버, 및 이를 포함하는 사투리 변환 시스템을 제공하는 데 있다."}
{"patent_id": "10-2023-0052038", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시예들은, 시스템 메모리 및 상기 시스템 메모리를 참조하여 동작하는 프로세서를 포함하는 서버의 구동 방법에 있어서, 하나 이상의 라벨 값을 갖는 제1 세트의 표준어 문장들을 상기 시스템 메모리에 로드하는 단계, 로드된 상기 제1 세트의 표준어 문장들과 대응하며, 대응하는 표준어 문장의 라벨 값과 같거나 또는 상이 한 상기 라벨 값을 갖는 제1 사투리 문장들을 로드하는 단계, 상기 제1 세트의 표준어 문장들 및 상기 제1 사투 리 문장들을 이용해 언어 변환 모델을 생성하는 단계, 하나 이상의 상기 라벨 값을 갖는 제2 세트의 표준어 문 장을 로드하는 단계, 및 로드한 상기 제2 세트의 표준어 문장을 상기 언어 변환 모델에 입력하여 상기 제2 세트 의 표준어 문장에 대응하는 제2 사투리 문장을 생성하는 단계를 포함하는 구동 방법을 제공할 수 있다. 상기 라벨 값은, 지역, 성별, 연령대, 감정 상태, 및 문장 종류 중 적어도 하나를 나타낼 수 있다. 상기 언어 변환 모델을 생성하는 단계는, 인코더에 상기 제1 세트의 표준어 문장들 중 어느 하나를 입력하는 단 계, 상기 인코더에 입력된 표준어 문장에 대응하는 사투리 문장을 디코더로부터 획득하는 단계, 및 획득한 상기 사투리 문장과 미리 준비된 사투리 문장을 비교하여 상기 인코더 및 상기 디코더를 학습하는 단계를 포함할 수 있다. 상기 제2 세트의 표준어 문장은 상기 시스템 메모리에 로드된 챗봇 모델을 상기 프로세서를 통해 실행하여 생성 한 표준어 문장을 포함할 수 있다. 본 개시의 실시예들은, 언어 변환 모델, 텍스트-투-스피치 모델, 및 음성 합성 모델이 로드되는 시스템 메모리 및 상기 시스템 메모리를 참조하여 동작하는 프로세서를 포함하는 서버의 음성 합성 모델을 학습하는 방법에 있 어서, 하나 이상의 라벨 값을 갖는 표준어 문장을 상기 시스템 메모리에 로드하고, 상기 언어 변환 모델을 실행 시켜, 그에 대응하는 사투리 문장을 생성하는 단계, 상기 텍스트-투-스피치 모델을 실행시켜, 생성한 상기 사투리 문장을 상기 텍스트-투-스피치 모델에 입력하여 상기 사투리 문장에 대응하는 음성 파형 데이터를 생성하는 단계, 및 생성된 상기 음성 파형 데이터를 이용해 상기 음성 합성 모델을 학습하는 단계를 포함하는 음성 합성 모델을 학습하는 방법을 제공할 수 있다. 상기 하나 이상의 라벨 값을 갖는 표준어 문장을 상기 시스템 메모리에 로드하고, 상기 언어 변환 모델을 실행 시켜, 그에 대응하는 사투리 문장을 생성하는 단계는, 상기 표준어 문장을 로드하는 단계, 상기 언어 변환 모델 을 실행시켜, 로드한 상기 표준어 문장을 상기 언어 변환 모델에 입력하는 단계, 및 상기 표준어 문장에 대응하 는 사투리 문장을 생성하는 단계를 포함할 수 있다. 상기 라벨 값은, 지역, 성별, 연령대, 감정 상태, 및 문장 종류 중 적어도 하나를 나타낼 수 있다. 상기 텍스트-투-스피치 모델은 상기 라벨 값에 대응하는 특성 값을 갖는 음성 파형 데이터를 생성할 수 있다. 상기 특성 값은, 주파수 특성 값, 지속 기간 특성 값, 및 고저 특성 값 중 적어도 하나를 나타낼 수 있다. 본 개시의 실시예들은, 네트워크를 통해 복수의 단말기들과 통신 가능한 서버에 있어서, 언어 변환 모델을 저장 하는 저장 매체, 운영 체제를 저장하는 시스템 메모리, 및 상기 저장 매체에 저장된 상기 언어 변환 모델을 상 기 시스템 메모리에 로드하는 프로세서를 포함하고, 상기 프로세서는, 하나 이상의 라벨 값을 갖는 표준어 문장 을 로드하고, 로드한 상기 표준어 문장을 상기 언어 변환 모델에 입력하여 상기 표준어 문장에 대응하는 사투리 문장을 생성하고, 생성한 상기 사투리 문장을 상기 복수의 단말기들 중 어느 하나에 전송할 수 있다. 상기 라벨 값은, 지역, 성별, 연령대, 감정 상태, 및 문장 종류 중 적어도 하나를 나타낼 수 있다. 상기 표준어 문장 및 상기 라벨 값은 상기 네트워크를 통해 상기 복수의 단말기들 중 상기 어느 하나로부터 수 신할 수 있다. 상기 저장 매체는 텍스트-투-스피치 모델을 더 저장하고, 상기 프로세서는, 상기 텍스트-투-스피치 모델을 실행 시켜, 생성한 상기 사투리 문장을 입력하고, 입력한 상기 사투리 문장에 상응하는 제1 음성 파형 데이터를 생성 할 수 있다. 상기 저장 매체는 음성 합성 모델을 더 저장하고, 상기 프로세서는, 상기 음성 합성 모델을 실행시켜, 상기 제1 음성 파형 데이터를 입력하고, 상기 라벨 값에 상응하는 특성 값을 갖는 제2 음성 파형 데이터를 생성할 수 있 다. 상기 제2 음성 파형 데이터를 상기 네트워크를 통해 상기 복수의 단말기들 중 상기 어느 하나에 송신하고, 상기 복수의 단말기들 중 상기 어느 하나에 문장 변환 블록 및 음성 변환 블록을 표시하며, 상기 문장 변환 블록에서 상기 사투리 문장을 표시하고, 상기 음성 변환 블록에 대한 상기 어느 하나의 단말기의 입력을 받아 상기 제2 음성 파형 데이터를 전송할 수 있다. 상기 복수의 단말기들 중 상기 어느 하나에 톤 조절 블록, 강세 조절 블록, 및 속도 조절 블록 중 적어도 하나 를 표시하고, 상기 톤 조절 블록, 상기 강세 조절 블록, 및 상기 속도 조절 블록 중 적어도 하나에 대한 상기 어느 하나의 단말기의 입력을 받아 상기 제2 음성 파형 데이터의 주파수, 지속 기간, 및 고저 중 적어도 하나를 변경하고, 상기 주파수, 상기 지속 기간, 및 상기 고저 중 적어도 하나가 변경된 상기 제2 음성 파형 데이터를 상기 어느 하나의 단말기에 송신할 수 있다. 본 개시의 실시예들은, 복수의 단말기들, 및 네트워크를 통해 상기 복수의 단말기들과 통신 가능한 서버를 포함 하고, 상기 서버는, 하나 이상의 라벨 값을 갖는 표준어 문장을 로드하고, 로드한 상기 표준어 문장을 언어 변 환 모델에 입력하여 상기 표준어 문장에 대응하는 사투리 문장을 생성하고, 생성한 상기 사투리 문장을 상기 복 수의 단말기들 중 어느 하나에 전송할 수 있다. 상기 표준어 문장 및 상기 라벨 값은 상기 네트워크를 통해 상기 복수의 단말기들 중 상기 어느 하나로부터 수 신할 수 있다. 상기 서버는, 상기 복수의 단말기들 중 상기 어느 하나에 문장 변환 블록 및 음성 변환 블록을 표시하며, 상기 문장 변환 블록에서 상기 사투리 문장을 표시하고, 상기 음성 변환 블록에 대한 상기 복수의 단말기들 중 상기 어느 하나의 단말기의 입력을 통해, 상기 사투리 문장에 대응하는 음성 파형 데이터를 전송할 수 있다. 상기 서버는, 상기 복수의 단말기들 중 상기 어느 하나에 톤 조절 블록, 강세 조절 블록, 및 속도 조절 블록 중 적어도 하나를 표시하고, 상기 톤 조절 블록, 상기 강세 조절 블록, 및 상기 속도 조절 블록 중 적어도 하나에대한 상기 어느 하나의 단말기의 입력을 받아 상기 음성 파형 데이터의 주파수, 지속 기간, 및 고저 중 적어도 하나를 변경하고, 상기 주파수, 상기 지속 기간, 및 상기 고저 중 적어도 하나가 변경된 상기 음성 파형 데이터 를 상기 어느 하나의 단말기에 송신할 수 있다."}
{"patent_id": "10-2023-0052038", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예들에 따른 서버의 구동 방법, 이를 이용해 음성 합성 모델을 학습하는 방법, 이를 제공하는 서 버, 및 이를 포함하는 사투리 변환 시스템에 의하면, 다양한 라벨 값(예를 들면, 지역, 연령, 성별, 감정 상태, 문장 종류 등)을 갖는 사투리 문장을 효과적으로 생성할 수 있다. 본 개시의 실시예들에 따른 서버의 구동 방법, 이를 이용해 음성 합성 모델을 학습하는 방법, 이를 제공하는 서 버, 및 이를 포함하는 사투리 변환 시스템에 의하면, 유사한 특성 값(예를 들면, 주파수 특성 값, 지속 시간 특 성 값, 고저 특성 값)을 갖는 음성 파형 데이터를 기초로 음성 합성 모델을 생성함으로써, 음성 합성 모델을 정 교하게 생성 및/또는 학습할 수 있다. 본 개시의 실시예들에 따른 서버의 구동 방법, 이를 이용해 음성 합성 모델을 학습하는 방법, 이를 제공하는 서 버, 및 이를 포함하는 사투리 변환 시스템에 의하면, 단말기의 사용자가 입력한 표준어 문장 및 이의 옵션에 부 합하는 사투리 문장 및 이의 음성 파형 데이터를 단말기에 제공할 수 있다."}
{"patent_id": "10-2023-0052038", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참고로 하여 본 발명의 여러 실시예들에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예들에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 따라서 앞서 설명한 참조 부호는 다른 도면에 서도 사용할 수 있다. 또한, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드 시 도시된 바에 한정되지 않는다. 도면에서 여러 층 및 영역을 명확하게 표현하기 위하여 두께를 과장되게 나 타낼 수 있다. 또한, 설명에서 \"동일하다\"라고 표현한 것은, \"실질적으로 동일하다\"는 의미일 수 있다. 즉, 통상의 지식을 가 진 자가 동일하다고 납득할 수 있을 정도의 동일함일 수 있다. 그 외의 표현들도 \"실질적으로\"가 생략된 표현들 일 수 있다. 아래에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1은 본 개시의 실시예들에 따른 사투리 변환 시스템의 블록도이다. 본 개시의 실시예들에 따른 사투리 변환 시스템은 서버와, 네트워크를 통해 서버와 연결되 는 복수의 단말기들(105, 106)을 포함할 수 있다. 서버는 사투리 변환 서비스를 제공하기 위한 모델이 저장될 수 있다. 예를 들어, 서버는 표준어 문장 을 사투리 문장으로 변환하기 위한 언어 변환 모델 및/또는 사투리 억양이 적용된 사투리 음성 합성 모델이 저 장되는 메모리를 포함할 수 있다. 네트워크는 본 개시의 실시예들에서 설명되는 서버와 다른 단말기들(105, 106)과의 연결을 가능하게 하는 구성일 수 있다. 네트워크는 인터넷 등을 이용한 온라인 네트워크, 오프라인 회선 등을 통한 오프라 인 네트워크 등을 포함할 수 있다. 복수의 단말기들(105, 106)은 사투리 변환 서비스의 사용자 단말기의 형태로 제공될 수 있다. 복수의 단말기들 (105, 106)은 네트워크를 통해 서버와 연결될 수 있으면 족하며, 그 종류가 제한되지 않는다. 예를 들어, 단말기는 휴대폰, 스마트폰, 태블릿, 노트북 등을 포함하는 이동식 전자 장치일 수 있고, 데스크톱을 포 함하는 고정식 전자 장치일 수 있다. 그러나, 본 개시의 실시예들이 이에 제한되는 것은 아니다. 도 2는 본 개시의 실시예들에 따른 서버의 시스템 블록도이다. 도 2를 참조하면, 본 개시의 실시예들에 따른 서버는 프로세서, 시스템 메모리, 전원, 저 장 매체, 저장 매체 인터페이스 및 버스 등을 포함할 수 있다. 서버는 일례로, 하나 이상의 컴퓨터 장치를 포함할 수 있다. 서버는 일례로, 네트워크(104; 도 1을 참조)와 온라인 및/또는 오프 라인으로 연결될 수 있다. 프로세서는 범용 혹은 전용 프로세서 중 어느 하나일 수 있다. 프로세서는 서버의 제반 동작들 을 제어할 수 있다. 프로세서는 실행될 때 다양한 기능들을 제공하는 프로그램 코드들 및 명령어들을 시스 템 메모리에 로딩하고, 로딩된 프로그램 코드들 및 명령어들을 처리하도록 구성된다. 시스템 메모리는 프로세서의 워킹 메모리 및/또는 버퍼 메모리로서 제공될 수 있다. 실시 예로서, 시 스템 메모리는 램(RAM: Random Access Memory), 롬(ROM: Read Only Memory), 및 다른 타입의 컴퓨터에 의 해 판독 가능한 매체 중 적어도 하나를 포함할 수 있다. 시스템 메모리에는 운영 체제가 저장될 수 있다. 프로세서는 프로세서에 의해 실행될 때 제1 텍스트 데이터를 제2 텍스트 데이터로 변환하기 위한 언 어 변환 모델을 시스템 메모리에 로딩할 수 있다. 언어 변환 모델은 제1 텍스트 데이터를 그에 대응하는 제2 텍스트 데이터로 변환할 수 있다. 언어 변환 모 델의 프로그램 코드들 및/또는 명령어들은 저장 매체에 저장될 수 있다. 언어 변환 모델의 프로 그램 코드들 및/또는 명령어들은 프로세서에 의해 실행될 수 있다. 제1 텍스트 데이터는 일례로, 표준어의 텍스트 데이터(예를 들면, 교양 있는 사람들이 두루 쓰는 현대 서울말로 지칭되는 텍스트 데이터)를 포함할 수 있다. 제1 텍스트 데이터는 일례로, 표준어 문장의 텍스트 데이터를 포함 할 수 있다. 제2 텍스트 데이터는 일례로, 표준어를 제외한 방언의 텍스트 데이터(예를 들면, 지역적 기준에서 서울, 강원도, 경기도, 경상도, 전라도, 충청도 등에서 사용되는 언어의 텍스트 데이터, 또는 연령의 기준에서 청소년 층, 중장년층, 노년층 등에서 사용되는 언어의 텍스트 데이터)를 포함할 수 있다. 제2 텍스트 데이터는 일례로, 특정 지역에서 사용되는 사투리 문장의 텍스트 데이터를 포함할 수 있다. 프로세서는 프로세서에 의해 실행될 때 텍스트 데이터를 파형 데이터(또는 음성 파형 데이터)로 변환 하는 모델(Text To Speech 모델(또는 텍스트-투-스피치 모델))을 시스템 메모리에 로딩할 수 있다. 텍스트 데이터를 파형 데이터로 변환하는 모델은 TTS 모델이라고도 한다. TTS 모델의 프로그램 코드 들 및/또는 명령어들은 저장 매체에 저장될 수 있다. TTS 모델의 프로그램 코드들 및/또는 명령어들 은 프로세서에 의해 실행될 수 있다. TTS 모델은 미리 설정된 특성 값에 따라 텍스트 데이터에 대응하는 음성 파형 데이터를 생성할 수 있다. 예를 들어, TTS 모델은 미리 설정된 주파수 특성 값에 따라 텍스트 데이터를 음성 파형 데이터로 변환함으 로써, 남성 또는 여성의 목소리에 상응하는 음성 파형 데이터를 생성할 수 있다. 예를 들어, TTS 모델은 미리 설정된 지속 기간(duration) 특성 값에 따라 텍스트 데이터를 음성 파형 데이터로 변환함으로써, 목소리의 늘어지는 정도가 다르게 반영된 음성 파형 데이터를 생성할 수 있다. 예를 들어, TTS 모델은 미리 설정된 고저(pitch) 특성 값에 따라 텍스트 데이터를 음성 파형 데이터로 변환함으로써, 목소리의 크기(예를 들면, 강 세)가 다르게 반영된 음성 파형 데이터를 생성할 수 있다. TTS 모델은 특성 값(예를 들면, 지속 기간 특성 값)의 설정에 따라 서로 다른 지역의 사투리에 상응하는 음성 파형 데이터를 생성할 수 있다. TTS 모델은 특성 값(예를 들면, 주파수 특성 값)의 설정에 따라 서로 다른 성별 및/또는 서로 다른 문장 종류의 사투리에 상응하는 음성 파형 데이터를 생성할 수 있다. TTS 모델 은 특성 값(예를 들면, 고저 특성 값)에 따라 서로 다른 지역, 서로 다른 연령대, 서로 다른 감정 상태의 사투리에 상응하는 음성 파형 데이터를 생성할 수 있다. 프로세서는 프로세서에 의해 실행될 때 제1 파형 데이터를 제2 파형 데이터로 변환하는 모델을 시스 템 메모리에 로딩할 수 있다. 제1 파형 데이터를 제2 파형 데이터로 변환하는 모델은 음성 합성 모델이라고도 한다. 음성 합성 모델 의 프로그램 코드들 및/또는 명령어들은 저장 매체에 저장될 수 있다. 음성 합성 모델의 프로그 램 코드들 및/또는 명령어들은 프로세서에 의해 실행될 수 있다. 음성 합성 모델은 기계 학습을 통해 생성될 수 있다. 예를 들어, 인공 신경망(ANN: Artificial Neural Network), 심층 신경망(DNN: Deep Neural Network), 합성곱 신경망(CNN: Convolutional Neural Network), 순환 신경망(RNN: Recurrent Neural Network), 생산적 적대 신경망(GAN: Generative Adversarial Network)과 같은 딥러닝 모델을 이용하여 음성 합성 모델이 생성될 수 있다. 그러나, 본 개시의 실시예들이 이에 제한되는 것은 아니다. 예를 들어, CNN 딥러닝 모델을 사용한 음성 합성 모델은 입력된 음성 파형 데이터의 특성 값을 추 출하고, 특성 값의 패턴을 학습함으로써 생성될 수 있다. 본 개시의 실시예들에서, 음성 합성 모델은 TTS 모델에서 생성된 음성 파형 데이터를 이용해 생성 및/또는 학습될 수 있다. 프로그램 코드들 및/또는 명령어들은 서버에 의해 판독 가능한 기록 매체인 저장 매체로부터 시스템 메모리에 로딩될 수 있다. 또는, 프로그램 코드들 및/또는 명령어들은 서버의 외부로부터 통신기(미 도시)를 통해 시스템 메모리에 로드될 수도 있다. 실시예에 따라, 프로세서는 대화형 인공지능(예를 들면, 챗봇(chatbot) 등)을 제공하기 위한 모델(예를 들 면, 챗봇 모델 등)을 시스템 메모리에 로드할 수 있다. 예를 들면, 복수의 단말기들(105, 106; 도 1을 참 조) 중 어느 하나의 사용자가 단말기(105, 106)에 문장을 입력하면, 서버는 네트워크를 통해 입력된 문장의 텍스트 데이터를 수신하고, 서버의 프로세서는 챗봇 모델을 실행하여 입력된 문장에 대한 대 답을 생성할 수 있다. 생성된 대답은 네트워크를 통해 단말기(105, 106)에 입력될 수 있다. 단말기(105, 106)에 입력된 대답은 단말기(105, 106)의 출력 매체((예를 들면, 디스플레이 장치, 또는 스피커 등)를 통해 사 용자에게 제공될 수 있다. 프로세서는 운영 체제를 실행할 수 있다. 예를 들어, 프로세서는 프로세서에 의해 실행될 때 언어 변환 모델, TTS 모델, 및/또는 음성 합성 모델이 실행되기에 적합한 환경을 제공하기 위한 운영 체제를 시스템 메모리에 로딩하고, 로딩된 운영 체제를 실행할 수 있다. 운영 체제는, 언어 변환 모델, TTS 모델, 음성 합성 모델 등이 서버의 저장 매체 인 터페이스와 같은 구성 요소들을 이용할 수 있도록 인터페이싱할 수 있다. 본 개시의 실시예들에서, 저장 매체 인터페이스의 적어도 일부 기능은 운영 체제에 의해 수행될 수 있다. 도 2를 참조하면, 시스템 메모리는 프로세서와 구분된 구성으로 도시되어 있으나, 시스템 메모리 의 적어도 일부는 프로세서에 포함될 수도 있다. 시스템 메모리는 실시 예들에 따라 물리적 및/ 또는 논리적으로 서로 분리된 복수의 메모리들로서 제공될 수 있다. 전원은 프로세서, 시스템 메모리, 저장 매체 및 저장 매체 인터페이스 중 하나 이상 의 구성 요소가 구동하기 위한 전압을 제공할 수 있다. 저장 매체는 데이터를 저장하기 위해 구성된다. 저장 매체는 전원이 차단되더라도 저장된 데이터를 유지하는 다양한 타입들의 비휘발성 저장 매체들을 포함할 수 있다. 비휘발성 저장 매체들은, 일례로, 비휘발성 메모리(non-volatile memory)를 포함할 수 있다. 비휘발성 메모리는 일례로, 플래시 메모리(flash memory), 하 드 디스크(hard disk) 등을 포함할 수 있다. 저장 매체 인터페이스는 저장 매체에 연결된다. 저장 매체 인터페이스는 버스에 연결된 프 로세서 및 시스템 메모리와 같은 구성 요소들과 저장 매체 사이를 인터페이싱할 수 있다. 버스는 서버의 다양한 구성 요소들에 연결되어 데이터, 신호, 및 정보를 전달할 수 있다. 도 3은 본 개시의 실시예들에 따른 언어 변환 모델의 생성 방법을 나타내는 순서도의 예시이다. 도 3을 참조하면, 본 개시의 실시예들에 따른 언어 변환 모델의 생성 방법은 사투리 학습용 데이터를 준비 하는 단계(S310) 및 언어 변환 모델을 생성하는 단계(S320) 등을 포함할 수 있다. 사투리 학습용 데이터를 준비하는 단계(S310)에는 표준어 문장의 텍스트 데이터와, 이에 대응하는 사투리 문장 의 텍스트 데이터가 준비될 수 있다. 예를 들어, 표준어 문장의 텍스트 데이터와, 이에 대응하는 제1 지역(예를 들면, 경상도)의 사투리 문장의 텍스트 데이터가 준비될 수 있다. 실시예에 따라, 표준어 문장의 텍스트 데이터 와, 둘 이상의 지역들의 사투리 문장의 텍스트 데이터가 준비될 수 있다. 본 명세서에서, \"준비\"의 표현은 프로세서(210; 도 2를 참조)가 해당 데이터를 메모리(예를 들면, 버퍼 메모리 또는 시스템 메모리 등)에 로드하는 동작에 대응할 수 있다. 언어 변환 모델을 생성하는 단계(S320)에는 전술한 언어 변환 모델(224; 도 1을 참조)이 생성(또는 학습)될 수 있다. 언어 변환 모델을 생성하는 단계에는 표준어 문장의 텍스트 데이터와 이에 대응하는 사투리 문장을 입력 받아, 표준어 문장을 사투리 문장으로 변환하기 위한 언어 변환 모델을 생성할 수 있다. 언어 변환 모델은 일례 로, 인코더와 디코더를 포함하는 인공 신경망으로 구현될 수 있으나, 이에 제한되는 것은 아니다. 언어 변환 모 델의 일 예시에 대해서는 도 8 및 도 9를 통해 보다 자세하게 설명한다. 도 4는 도 3의 사투리 학습용 데이터를 준비하는 단계(S310)를 구체적으로 나타낸 순서도이다. 도 4를 참조하면, 본 개시의 실시예들은 각각이 하나 이상의 라벨 값을 갖는 제1 세트의 표준어 문장들을 준비 하는 단계(S410) 및 준비된 제1 세트의 표준어 문장들과 대응하며, 하나 이상의 라벨 값이 해당 표준어 문장과 같거나 또는 상이한 제1 지역의 사투리 문장들을 준비하는 단계(S420)를 포함할 수 있다. 준비된 제1 세트의 표준어 문장들 및 이에 대응하는 제1 지역의 사투리 문장들은 언어 변환 모델(224; 도 1을 참조)을 생성 및/또는 학습시키기 위한 텍스트 데이터로 이용될 수 있다. 제1 세트의 표준어 문장들 및 이에 대응하는 제1 지역의 사투리 문장들은 각각 하나 이상의 라벨 값을 포함할 수 있다. 라벨 값들은 일례로, 연령대, 성별, 감정 상태, 문장 종류 등에 대한 것일 수 있으나, 본 개시의 실시 예들이 이에 제한되는 것은 아니다. 라벨 값에 따라, 동일한 표준어 문장에 둘 이상의 사투리 문장들이 대응될 수 있다. 예를 들어, 연령대에 대응하는 라벨 값들은 \"전연령대(연령 무관)\", \"아동(6~12세)\", \"청소년(13~18세)\", \"청년(19~29세)\", \"중년(30~49세)\", \"장년(50~64세)\", \"노년(65세 이상)\" 등과 같이 분류 될 수 있다. 예를 들어, 성별에 대응하는 라벨 값들은 \"성별 무관\", \"남성(male)\", \"여성(female)\"과 같이 분류될 수 있다. 예를 들어, 감정 상태에 대응하는 라벨 값들은 \"화남\", \"지루함\", \"놀람\", \"무감정\", \"기쁨\", \"슬픔\" 등과 같이 분류될 수 있다. 예를 들어, 문장 종류에 대응하는 라벨 값들은 \"평서문\", \"명령문\", \"청유문\", \"의문문\", \"감탄문\" 등과 같이 분류될 수 있다. 예를 들어, \"그렇지 않을까?\"라는 표준어 문장은, 연령대에 대응하는 라벨 값이 \"전연령대\"이고, 성별에 대응하 는 라벨 값이 \"성별 무관\"이며, 감정 상태에 대응하는 라벨 값이 \"무감정\"이고, 문장 종류에 대응하는 라벨 값 은 \"의문문\"일 수 있다. 위와 같은 \"그렇지 않을까?\"라는 표준어 문장은 사투리 문장의 라벨 값에 따라, 둘 이상의 사투리 문장들에 대 응할 수 있다. 예를 들면, 연령대에 대응하는 라벨 값이 \"전연령대\"이고, 성별에 대응하는 라벨 값이 \"성별 무 관\"이며, 감정 상태에 대응하는 라벨 값이 \"무감정\"이고, 문장 종류에 대응하는 라벨 값은 \"의문문\"인 \"그지 않 을까?\"라는 사투리 문장에 대응할 수 있다. 예를 들면, 연령대에 대응하는 라벨 값이 \"전연령대\"이고, 성별에 대응하는 라벨 값이 \"성별 무관\"이며, 감정 상태에 대응하는 라벨 값이 \"화남\"이고, 문장 종류에 대응하는 라벨 값은 \"의문문\"인 \"그지 않겠냐니까?\"에 대응할 수 있다. 예를 들면, 연령대에 대응하는 라벨 값이 \"전연령대\"이 고, 성별에 대응하는 라벨 값이 \"성별 무관\"이며, 감정 상태에 대응하는 라벨 값이 \"지루함\"이고, 문장 종류에 대응하는 라벨 값은 \"평서문\"인 \"그지 않겠냐고.\"에 대응할 수 있다. 위에서 설명한 바와 같이, 준비되는 제1 지역의 사투리 문장들은 제1 세트의 표준어 문장들 각각과 동일한 라벨 값을 가지는 제1 지역의 사투리 문장들을 포함할 수 있다. 또한, 준비되는 제1 지역의 사투리 문장들은 제1 세 트의 표준어 문장들 각각과 적어도 하나의 라벨 값이 상이한 제1 지역의 사투리 문장을 포함할 수 있다. 도 5는 도 3의 언어 변환 모델을 생성하는 단계(S320)를 구체적으로 나타낸 순서도이다. 언어 변환 모델을 생성하는 단계(S320)는 제1 세트의 표준어 문장들 및 이에 대응하는 제1 지역의 사투리 문장 들을 입력하는 단계(S510) 및 언어 변환 모델을 생성하는 단계(S520)를 포함할 수 있다. 생성되는 언어 변환 모델은 일례로, 순환 신경망(RNN: Recurrent Neural Network)을 이용하여 생성될 수 있다. 다만, 언어 변환 모델이 이에 제한되는 것은 아니며, 표준어 문장의 텍스트 데이터를 사투리 문장의 텍스트 데 이터로 변환하기 위한 기능을 수행할 수 있다면, 언어 변환 모델은 당업자에 의해 자유롭게 선택될 수 있다. 언어 변환 모델은 일례로, 순환 신경망을 이용한 시퀀스-투-시퀀스(Sequence-to-Sequence) 모델을 포함할 수 있 다. 시퀀스-투-시퀀스 모델은 인코더와 디코더를 포함하며, 인코더는 디코더에 컨텍스트 벡터를 전송한다. 본 개시의 실시예들은 제1 세트의 표준어 문장들 및 이에 대응하는 제1 지역의 사투리 문장들을 입력하여, 언어 변 환 모델의 인코더와 디코더를 학습시키는 방식으로 언어 변환 모델을 생성할 수 있다. 시퀀스-투-시퀀스 모델을 적용한 언어 변환 모델에 대한 설명은 도 8 및 도 9를 통해 후술된다. 언어 변환 모델은, 하나 이상의 라벨 값을 가지는 표준어 문장과 그와 동일한 라벨 값을 가지는 사투리 문장을 제공하여 학습시킴으로써 생성될 수 있다. 언어 변환 모델은, 하나 이상의 라벨 값을 가지는 표준어 문장과, 그 와 상이한 라벨 값을 가지는 하나 이상의 사투리 문장을 더 제공하여 학습시킴으로써 생성될 수 있다. 이에 따 라, 언어 변환 모델은 하나의 표준어 문장에 대해 라벨 값을 달리하는 둘 이상의 사투리 문장들이 학습되어 생 성될 수 있다. 도 6은 생성된 언어 변환 모델을 이용하여 표준어 문장에 대응하는 사투리 문장들을 생성하는 방법을 나타 낸 순서도이다. 본 개시의 실시예들에 따른 표준어 문장에 대응하는 사투리 문장들을 생성하는 방법은, 각 각이 하나 이상의 라벨 값을 갖는 제2 세트의 표준어 문장을 준비하는 단계(S610), 준비된 제2 세트의 표준어 문장을 언어 변환 모델에 입력하는 단계(S620), 및 제2 세트의 표준어 문장에 대응하는 제1 지역의 사투리 문장 을 생성하는 단계(S630)를 포함할 수 있다.각각이 하나 이상의 라벨 값을 갖는 제2 세트의 표준어 문장을 준비 하는 단계(S510)에는 제2 세트의 표준어 문장 및 하나 이상의 라벨 값이 준비된다. 라벨 값은 예를 들어, 연령 대, 성별, 감정 상태, 및 문장 종류 중 적어도 하나를 포함할 수 있다. 제2 세트의 표준어 문장은, 전술한 제1 세트의 표준어 문장들에 포함되는 문장일 수도 있고, 전술한 제1 세트의 표준어 문장들에 포함되지 않는 문장일 수도 있다. 제2 세트의 표준어 문장은, 일례로, 복수의 단말기들(105, 106; 도 1을 참조) 중 어느 하나의 사용자로부터 입 력되어 서버(102; 도 1을 참조)에 입력된 것일 수 있다. 제2 세트의 표준어 문장은, 일례로, 서버(102; 도 1을 참조)의 내부에서 생성된 것일 수 있다. 도 1을 더 참조 하면, 제2 세트의 표준어 문장은 대화형 인공지능(예를 들면, 챗봇 모델 등)에서 생성된 것일 수 있다. 도 2를 더 참조하면, 제2 세트의 표준어 문장은 프로세서가 챗봇 모델을 실행시켜 생성된 것일 수 있고, 생성된 제2 세트의 표준어 문장이 네트워크를 통해 단말기들에 전송되어 표시되는 것일 수 있다. 제2 세트의 표준 어 문장은 일례로, 사용자로부터 입력된 질문에 대해 챗봇 모델에서 생성되는 대답에 대응할 수 있다. 제2 세트의 표준어 문장은 적어도 하나의 라벨 값을 가질 수 있다. 제2 세트의 표준어 문장이 가지는 라벨 값은, 전술한 제1 세트의 표준어 문장들이 가지는 라벨 값에 대응할 수 있다. 예를 들어, 전술한 제1 세트의 표 준어 문장들이 \"연령대\", \"성별\", \"감정 상태\", 및 \"문장 종류\"에 대응하는 라벨 값들을 가진 경우에, 제2 세트 의 표준어 문장들은 \"연령대\", \"성별\", \"감정 상태\", 및 \"문장 종류\" 중 적어도 하나에 대응하는 라벨 값을 가 질 수 있다. 예를 들어, \"뭐 먹었어?\"라는 제2 세트의 표준어 문장은, 연령대에 대응하는 라벨 값이 \"청년(19세~29세)\"이고, 성별에 대응하는 라벨 값이 \"남성(male)\"이며, 감정 상태에 대응하는 라벨 값이 \"무감정\"이고, 문장 종류에 대 응하는 라벨 값은 \"의문문\"일 수 있다. 실시예에 따라, 제2 세트의 표준어 문장의 라벨 값들 중 적어도 하나는 복수의 단말기들(105, 106; 도 1을 참조)의 사용자로부터 입력받는 것일 수 있다. 실시예에 따라, 제2 세트의 표준어 문장의 라벨 값들 중 적어도 하나는 서버(102; 도 1을 참조) 내부에 미리 학습된 알고리즘 등을 통해 서버의 내부에서 생성되는 것일 수 있다. 예를 들면, 연령대, 성별, 및 감정 상태에 대응하는 라벨 값들은 복수의 단말기들(105, 106) 중 어느 하나의 사용자로부터 입력받고, 문장 종류에 대응하는 라벨 값은 서버의 내부에서 생성될 수 있다. 그러나, 본 개시의 실시예들이 상술한 예시로 제한되는 것은 아니다. 준비된 제2 세트의 표준어 문장을 언어 변 환 모델에 입력하는 단계(S620)에는 미리 생성된 언어 변환 모델(224; 도 2를 참조)에 제2 세트의 표준어 문장 이 입력된다. 예를 들면, 언어 변환 모델의 인코더에 제2 세트의 표준어 문장이 입력될 수 있다. 언어 변환 모 델은 제2 세트의 표준어 문장들 각각에 대응하는 컨텍스트 벡터를 생성할 수 있다. 언어 변환 모델은 생성한 컨 텍스트 벡터를 디코더에 전송할 수 있다. 예를 들어, \"뭐 먹었어?\"라는 제2 세트의 표준어 문장과 그 라벨 값들이 언어 변환 모델의 인코더에 입력될 수 있다. 인코더에서 생성된 컨벡스트 벡터가 언어 변환 모델의 디코더에 전송될 수 있다. 제2 세트의 표준어 문장에 대응하는 제1 지역의 사투리 문장을 생성하는 단계(S630)에는 제2 세트의 표준어 문 장에 대응하는 사투리 문장이 생성된다. 예를 들면, 언어 변환 모델의 디코더는 수신한 컨텍스트 벡터와 대응하 는 사투리 문장을 출력할 수 있다. 이에 의해 제2 세트의 표준어 문장과 그 라벨 값에 대응하는 사투리 문장이 획득될 수 있다. 예를 들어, \"뭐 먹었어?\"라는 제2 세트의 표준어 문장은 라벨 값인 \"청년(19~29세)\", \"남성(male)\", \"무감정\", 및 \"의문문\"에 대응하는 라벨 값을 갖는 사투리 문장으로 변환될 수 있다. 예를 들면, \"뭐 뭇노?\"와 같은 사투 리 문장이 획득될 수 있고, 해당 사투리 문장은 입력된 제2 세트의 표준어 문장이 가지는 라벨 값과 동일한 \"청 년(19~29세)\", \"남성(male)\", \"무감정\", 및 \"의문문\"에 대응하는 라벨 값을 가질 수 있다. 본 개시의 실시예들에 따른 전자 장치(100; 도 1을 참조)의 사용자는 제2 세트의 표준어 문장과, 그에 대응하는 라벨 값을 바꾸어 가며 다양하게 설정할 수 있다. 이에 따라, 하나의 표준어 문장에 대응하는 다양한 사투리 문 장들이 생성될 수 있다. 이에 의하면, 하나의 표준어 문장을 이용해 둘 이상의 사투리 문장들을 획득할 수 있다. 따라서, 적은 수의 표준어 문장들을 이용해 서로 다른 특성 값을 가지는 많은 수의 사투리 문장들을 생성 할 수 있다. 도 7은 본 개시의 실시예들에 따른 언어 변환 모델을 생성하기 위한 사투리 학습용 데이터의 예시 이다. 사투리 학습용 데이터는, 각각이 하나 이상의 라벨 값을 갖는 제1 세트의 표준어 문장들을 준비하는 단계(S41 0)에서 준비되는 복수의 표준어 문장들 및 준비된 제1 세트의 표준어 문장들과 대응하며, 하나 이상의 라벨 값 이 해당 표준어 문장과 같거나 또는 상이한 제1 지역의 사투리 문장들을 준비하는 단계(S420)에서 준비되는 복 수의 사투리 문장들을 포함할 수 있다. 사투리 학습용 데이터는 표준어 문장과, 이에 대응하는 하나 이상의 사투리 문장이 쌍을 이룰 수 있다. 실시예 에 따라, 사투리 학습용 데이터는 표준어 단어(예를 들면, 표준어 명사)와, 이에 대응하여 쌍을 이루는 사투리 단어(예를 들면, 제1 지역의 사투리 명사)를 더 포함할 수 있다. 도 7을 참조하면, 제1 세트의 표준어 문장들 각각은 연령대, 성별, 감정 상태, 및 문장 종류에 대응하는 라벨 값들을 갖는다. 제1 지역의 사투리 문장들은, 표준어 문장과 동일한 의미 및 동일한 라벨 값을 갖는 사투리 문 장을 포함할 수 있다. 이를 통해, 표준어 문장과 동일한 의미를 갖고, 동일한 라벨 값을 갖는 사투리 문장이 학 습될 수 있다. 제1 지역의 사투리 문장들은, 표준어 문장과 동일한 의미 및 상이한 라벨 값을 갖는 사투리 문장을 더 포함할 수 있다. 이를 통해, 표준어 문장과 동일한 의미를 갖되, 서로 다른 라벨 값을 갖는 사투리 문장이 더 학습될 수 있다. 도 8은 본 개시의 실시예들에 따른 언어 변환 모델의 모식도이다. 도 8을 참조하면, 본 개시의 실시예들에 따른 언어 변환 모델은 인코더 및 디코더를 포함할 수 있다. 인코더는 표준어 문장을 수신할 수 있다. 인코더는 수신한 표준어 문장에 대응하는 컨텍스트 벡터 (CV)를 출력할 수 있다. 디코더는 입력된 컨텍스트 벡터(CV)에 대응하는 사투리 문장을 출력할 수 있다. 인코더와 디코더는 전술한 언어 변환 모델을 생성하는 단계(S520)에서 생성 및/또는 학습될 수 있다. 도 9는 도 8의 언어 변환 모델의 동작에 대한 구체적인 예시이다. 제2 세트의 표준어 문장으로 \"처음에는 조금 특이하다 생각했는데\"가 준비된 것을 예시로 설명한다. 인코더는 표준어 문장을 입력받을 수 있다. 인코더는 일례로, 장단기 메모리(LSTM: Long Short- Term Memory)를 포함할 수 있다. 장단기 메모리(LSTM)는 순환 신경망(CNN)의 일 예시로, 입력 레이어(input layer), 히든 레이어(hidden layer), 및 출력 레이어(output layer) 등을 포함할 수 있다. 장단기 메모리(LSTM)에서 학습되는 파라미터들은, 입력 레이어와 히든 레이어 사이의 파라미터, 히든 레이어에서 출력 레이어 사이의 파라미터, 및 인접한 히든 레이어들 사이의 파라미터를 포함할 수 있다. 전술한 제1 세트의 표준어 문장들 및 이에 대응하는 사투리 문장 들을 이용해, 장단기 메모리(LSTM)의 파라미터들을 학습시킬 수 있다. 예를 들어, 제1 세트의 표준어 문장들 중 어느 하나를 인코더에 입력하고, 디코더로부터 출력된 사투리 문장을 획득하며, 획득한 사투리 문장 을 미리 준비된 사투리 문장과 비교하여 파라미터들을 학습시킬 수 있다. 장단기 메모리(LSTM)(예를 들면, 장단기 메모리(LSTM)의 히든 레이어)는 히든 벡터(h11, h12, h13, ..., h1n 등; 아래에서는 참조 부호 h1으로 지칭함)를 입력받을 수 있다. 장단기 메모리(LSTM)(예를 들면, 장단기 메모리 (LSTM)의 입력 레이어)는 단어를 입력받을 수 있다. 장단기 메모리(LSTM)(예를 들면, 장단기 메모리(LSTM)의 히 든 레이어)는 입력받은 히든 벡터(h1)를 입력받은 단어에 기초하여 업데이트하고, 업데이트한 히든 벡터를 출력 할 수 있다. 장단기 메모리(LSTM)(예를 들면, 장단기 메모리(LSTM)의 출력 레이어)는 업데이트된 히든 벡터(h 1)에 상응하는 단어를 출력할 수 있다. 히든 벡터(h1)는, 해당 장단기 메모리(LSTM)의 이전에 입력된 단어들의 정보를 포함할 수 있다. 도 8을 참조하 면, 첫 번째 히든 벡터(h11)는 \"처음에는\"이라는 단어의 정보를 포함할 수 있다. 두 번째 히든 벡터(h12)는 \"처 음에는\" 및 \"조금\" 이라는 단어의 정보를 포함할 수 있다. 세 번째 히든 벡터(h13)는 \"처음에는\", \"조금\", 및 \"특이하다\"라는 단어의 정보를 포함할 수 있다. 인코더는 디코더에 컨텍스트 벡터(CV)를 출력할 수 있다. 컨텍스트 벡터(CV)는 하나 이상의 히든 벡 터(h1)를 포함할 수 있다. 도 8을 참조하면, 인코더 내에 포함되는 모든 장단기 메모리(LSTM)에서 출력되 는 히든 벡터들(h11 내지 h1n)이 출력되어 디코더에 입력되는 실시예가 도시된다. 이와 같은 실시예는 완 전히 연결된 레이어(Fully-connected layer)를 포함하는 언어 변환 모델의 예시이다. 그러나, 본 개시의 실시예 들이 이에 제한되는 것은 아니다. 예를 들면, 본 개시의 실시예들의 언어 변환 모델은 인코더에서 디코더 에 하나의 히든 벡터(예를 들면, 마지막 히든 벡터(h1n))만이 전송될 수도 있다. 디코더는 사투리 문장을 출력할 수 있다. 디코더는 일례로, 장단기 메모리(LSTM)를 포함할 수 있다. 디코더에 포함되는 장단기 메모리(LSTM)는 인코더에 포함되는 장단기 메모리(LSTM)와 실질적으 로 동일할 수 있다. 도 9를 참조하면, 디코더의 장단기 메모리(LSTM)는 입력된 히든 벡터(h21, h22, h23, h24 등; 아래에서는 참조 부호 h2로 지칭함)와 입력된 단어에 기초하여 히든 벡터(h2)를 업데이트하고, 업데이트한 히든 벡터(h2)와 상응하는 단어를 출력할 수 있다. 디코더는 디코더에서 출력되는 사투리 문장을 그 자신의 입력 값으로 받을 수 있다. 디코더가 사투리 문장을 출력하는 과정을 살펴보면 아래와 같다. 디코더의 첫 번째 장단기 메모리(LSTM)는 하나 이상의 히든 벡터(h1)를 입력받고, 문장의 시작을 지시하는 <SOS>(out0)를 입력받는다. 이에 의해 장단기 메모리(LSTM)는 히든 벡터를 업데이트하고, 업데이트한 히든 벡터 (h21)를 출력한다. 장단기 메모리(LSTM)는 업데이트한 히든 벡터(h21)에 상응하는 \"첨에는\"(out1)이라는 단어를 출력한다. 디코더의 두 번째 장단기 메모리(LSTM)는 하나 이상의 히든 벡터(h1, h21 등)를 입력받고, 직전의 장단기 메모리(LSTM)에서 출력된 단어인 \"첨에는\"(out1)을 입력받는다. 이에 의해 장단기 메모리(LSTM)는 히든 벡터를 업데이트하고, 업데이트한 히든 벡터(h22)를 출력한다. 장단기 메모리(LSTM)는 업데이트한 히든 벡터(h22)에 상 응하는 \"쫌\"(out2)이라는 단어를 출력한다. 디코더의 세 번째 장단기 메모리(LSTM)는 하나 이상의 히든 벡터(h1, h22 등)를 입력받고, 직전의 장단기 메모리(LSTM)에서 출력된 단어인 \"쫌\"(out2)을 입력받는다. 이에 의해 장단기 메모리(LSTM)는 히든 벡터를 업데 이트하고, 업데이트한 히든 벡터(h23)를 출력한다. 장단기 메모리(LSTM)는 업데이트한 히든 벡터(h23)에 상응하 는 \"특이하다\"(out3)를 출력한다. 디코더의 네 번째 장단기 메모리(LSTM)는 하나 이상의 히든 벡터(h1, h23 등)를 입력받고, 직전의 장단기 메모리(LSTM)에서 출력된 단어인 \"특이하다\"(out3)를 입력받는다. 이에 의해 장단기 메모리(LSTM)는 히든 벡터 를 업데이트하고, 업데이트한 히든 벡터(h24)를 출력한다. 장단기 메모리(LSTM)는 업데이트한 히든 벡터(h24)에 상응하는 \"생각했는데\"(out4)를 출력한다. 디코더의 마지막 장단기 메모리(LSTM)는 하나 이상의 히든 벡터(h1 등)를 입력받고, 직전의 장단기 메모리 (LSTM)에서 출력된 단어(예를 들면, \"생각했는데\"(out4))를 입력받는다. 이에 의해 장단기 메모리(LSTM)는 히든 벡터를 업데이트하고, 업데이트한 히든 벡터(미도시)를 출력할 수 있다. 장단기 메모리(LSTM)는 업데이트한 히 든 벡터에 상응하는 <EOS>(outm)를 출력한다. <EOS>는 문장의 끝을 지시할 수 있다. 위와 같은 과정을 통해 디코더는 인코더에 입력되는 표준어 문장과 대응하는 사투리 문장 을 출력할 수 있다. 이에 의해, 본 개시의 실시예들에 따르면 제2 세트의 표준어 문장들을 다양하게 준비 하여, 그에 상응하는 사투리 문장들을 다양하게 생성할 수 있다. 도 10은 생성된 사투리 문장들을 이용해 사투리 음성 합성 모델을 생성 및/또는 학습하는 방법을 나타낸 순서도이다. 본 개시의 실시예들에 따른 생성된 사투리 문장들을 이용해 사투리 음성 합성 모델을 생성 및/또는 학습하는 방 법은, 하나 이상의 라벨 값을 갖는 제2 세트의 표준어 문장들과 그에 대응하는 사투리 문장들을 준비하는 단계(S1010), 준비된 사투리 문장들을 TTS 모델에 입력하고, 준비된 사투리 문장들에 대응하는 음성 파형 데이 터를 생성하는 단계(S1020), 및 생성된 음성 파형 데이터를 이용해 음성 합성 모델을 생성 및/또는 학습하는 단 계(S1030)를 포함할 수 있다. 사투리 문장들을 준비하는 단계(S1010)에 준비되는 사투리 문장들은 각각 하나 이상의 라벨 값을 가질 수 있다. 예를 들어, 사투리 문장을 준비하는 단계(S1010)에 준비되는 사투리 문장은 \"뭐 뭇노?\"와 같은 문장일 수 있다. 그리고, 해당 사투리 문장은 \"경북 지역\", \"청년(19~29세)\", \"남성(male)\", \"무감정\", 및 \"의문문\"에 대응하는 라벨 값을 가질 수 있다. 준비된 사투리 문장의 텍스트를 TTS 모델에 입력하는 단계(S1020)에는 사투리 문장의 텍스트 데이터 및 그 라벨 값을 입력하고, 해당 텍스트 데이터 및 그 라벨 값에 대응하는 파형 데이터를 획득할 수 있다. 획득되는 파형 데이터는 입력되는 사투리 문장과, 해당 사투리 문장이 가지는 라벨 값에 따라 달라질 수 있다. 예를 들어, 같 은 \"뭐 뭇노?\"와 같은 문장이 동일하게 입력되더라도, 연령대, 성별, 감정 상태, 및 문장 종류와 같은 라벨 값 이 달라지면, 획득되는 파형 데이터는 달라질 수 있다. 앞서 설명한 것처럼, 본 개시의 실시예들에 따른 서버(102; 도 1을 참조)는 언어 변환 모델(224; 도 2를 참조) 을 이용하여 하나의 표준어 문장에 대해 라벨 값이 다른 둘 이상의 사투리 문장들을 생성할 수 있다. 예를 들면, 언어 변환 모델을 성별, 연령대, 감정 상태, 문장 종류 등이 서로 다른 사투리의 음성 파형 데이터를 획 득할 수 있다. 본 개시의 실시예들은, 서로 다른 라벨 값들(예를 들면, 성별, 연령대, 감정 상태, 문장 종류 등)을 갖는 사투리 문장들을 TTS 모델에 입력함으로써, 다양한 음성 파형 데이터들을 생성할 수 있다. 음성 합성 모델을 생성 및/또는 학습하는 단계(S1030)에는, 전술한 사투리 문장들에 대응하는 음성 파형 데이터 를 생성하는 단계(S1020)에서 생성된 다양한 음성 파형 데이터들을 기초로 음성 합성 모델을 생성 및/또는 학습 할 수 있다. 음성 합성 모델에 입력되는 음성 파형 데이터들은 서로 동일하거나, 유사한 라벨 값들을 가질 수있다. 이에 따라, 유사한 특성 값들을 갖는 음성 파형 데이터들을 이용하여 음성 합성 모델이 형성 및/또는 학 습될 수 있다. 음성 합성 모델은, 복수의 파라미터들을 포함할 수 있다. 복수의 파라미터들은 입력된 음성 파형 데이터의 특성 값(예를 들면, 주파수 특성 값, 지속 기간 특성 값, 고저 특성 값 등)을 추출하고, 추출한 특성 값에 기초하여 그 값들이 업데이트될 수 있다. 음성 합성 모델은 파라미터들이 업데이트됨에 따라 학습될 수 있다. 본 개시의 실시예들에 의하면, 언어 변환 모델(224; 도 2를 참조)을 통해 서로 유사한 특성 값들을 갖는 음성 파형 데이터 들을 충분히 많은 정도로 생성할 수 있다. 그리고, 서로 유사한 특성 값들을 갖는 음성 파형 데이터들을 이용해 해당 특성 값들이 반영된 음성 합성 모델(228; 도 2를 참조)을 생성 및/또는 학습시킬 수 있다. 이에 의하면, 음성 합성 모델을 생성 및/또는 학습하기 위해 충분한 수의 음성 파형 데이터들을 쉽고 효과적으로 생성할 수 있다. 이에 의해, 음성 합성 모델의 생성 및/또는 학습이 용이해질 수 있다. 도 11은 본 개시의 실시예들에 따른 사투리 변환 서비스를 제공하는 방법의 순서도이다. 도 11을 참조하면, 본 개시의 실시예들에 따른 사투리 변환 서비스를 제공하는 방법은, 단말기로부터 표 준어 문장을 수신하고, 수신한 표준어 문장을 사투리 문장으로 변환하는 단계(S1110), 변환된 사투리 문장에 대 응하는 음성 파형 데이터를 생성하는 단계(S1120), 및 변환된 사투리 문장 및/또는 생성된 음성 파형 데이터를 단말기에 전송하는 단계(S1130)를 포함할 수 있다. 위와 같은 단계들(S1110, S1120, S1130)은 본 개시의 실시예들에 따른 서버(102; 도 1을 참조)에서 프로세서 (210; 도 2를 참조)가 시스템 메모리(220; 도 2를 참조)를 참조하여 수행될 수 있다. 단말기로부터 표준어 문장을 수신하고, 수신한 표준어 문장을 사투리 문장으로 변환하는 단계(S1110)에는, 서버 (102; 도 1을 참조)가 복수의 단말기들(105, 106; 도 1을 참조) 중 어느 하나로부터 표준어 문장을 수신할 수 있다. 그리고, 서버는 수신한 표준어 문장에 대응하는 사투리 문장을 생성할 수 있다. 예를 들면, 프로세 서(210; 도 2를 참조)가 언어 변환 모델(224; 도 2를 참조)을 실행하여 표준어 문장에 대응하는 사투리 문장을 생성할 수 있다. 변환된 사투리 문장에 대응하는 음성 파형 데이터를 생성하는 단계(S1120)에는, 서버(102; 도 1을 참조)가 생성 된 사투리 문장에 대응하는 음성 파형 데이터를 생성할 수 있다. 예를 들면, 프로세서(210; 도 2를 참조)가 TTS 모델(226; 도 2를 참조)을 실행하여 사투리 문장에 대응하는 음성 파형 데이터를 생성하고, 음성 합성 모델 을 실행하여 특성 값이 반영된 음성 파형 데이터를 생성할 수 있다. 변환된 사투리 문장 및/또는 생성된 음성 파형 데이터를 단말기에 전송하는 단계(S1130)에는 서버(102; 도 1을 참조)가 네트워크 등을 이용해 복수의 단말기들(105, 106; 도 1을 참조) 중 어느 하나에 생성된 사투리 문장 및 /또는 특성 값이 반영된 음성 파형 데이터를 전송할 수 있다. 도 12는 도 11의 표준어 문장을 사투리 문장으로 변환하는 단계(S1110)를 구체적으로 나타낸 순서도이다. 도 12를 참조하면, 표준어 문장을 사투리 문장으로 변환하는 단계(S1110)는 하나 이상의 라벨 값을 갖는 표준어 문장을 수신하는 단계(S1210), 수신한 표준어 문장을 언어 변환 모델에 입력하는 단계(S1220), 및 수신한 표준 어 문장과 동일한 라벨 값을 갖는 사투리 문장을 출력하는 단계(S1230)를 포함할 수 있다. 하나 이상의 라벨 값을 갖는 표준어 문장을 수신하는 단계(S1210)에는, 복수의 단말기들(105,106; 도 1을 참조) 중 어느 하나로부터 표준어 문장과 하나 이상의 라벨 값을 수신할 수 있다. 예를 들면, \"그 옷 별로다.\"라는 표 준어 문장과, \"경북 지역\", \"청년(19~29세)\", \"남성(male)\", \"기쁨\", \"평서문\"의 라벨 값들을 수신할 수 있다. 수신한 표준어 문장을 언어 변환 모델에 입력하는 단계(S1220)에는, 어느 하나의 단말기로부터 수신한 표준어 문장과 그 라벨 값을 언어 변환 모델에 입력할 수 있다. 프로세서(210; 도 2를 참조)는 언어 변환 모델(224; 도 2를 참조)을 실행시키고, 수신한 표준어 문장과 그 라벨 값을 입력할 수 있다. 수신한 표준어 문장과 동일한 라벨 값을 갖는 사투리 문장을 출력하는 단계(S1230)에는, 프로세서가 언어 변환 모델(224; 도 2를 참조)을 실행시켜 표준어 문장 및 그 라벨 값에 상응하는 사투리 문장을 생성할 수 있다. 프로세서(210; 도 2를 참조)는 생성된 사투리 문장을 메모리(예를 들면, 버퍼 메모리 등)에 저장할 수 있 다. 생성된 사투리 문장은, 언어 변환 모델에 입력된 표준어 문장과 같은 라벨 값(예를 들면, \"경북 지 역\", \"청년(19~29세)\", \"남성(male)\", \"기쁨\", \"평서문\")을 가질 수 있다. 도 13은 도 11의 사투리 문장에 대응하는 음성 파형 데이터를 생성하는 단계(S1120)를 구체적으로 나타낸 순서 도이다. 사투리 문장에 대응하는 음성 파형 데이터를 생성하는 단계(S1120)는, 하나 이상의 라벨 값을 갖는 사투리 문장 을 TTS 모델에 입력하는 단계(S1310), TTS 모델을 실행시켜 생성한 제1 음성 파형 데이터를 음성 합성 모델에 입력하는 단계(S1320), 및 음성 합성 모델을 실행시켜 제2 음성 파형 데이터를 생성하는 단계(S1330)를 포함할 수 있다. 하나 이상의 라벨 값을 갖는 사투리 문장을 TTS 모델에 입력하는 단계(S1310)에, 프로세서(210; 도 2를 참조)는 TTS 모델(226; 도 2를 참조)을 실행시켜 사투리 문장을 입력할 수 있다. TTS 모델에 입력되는 사투리 문장 은, 사투리 문장을 출력하는 단계(S1230; 도 12를 참조)에서 출력된 사투리 문장이 이용될 수 있다. 프로세서 는 TTS 모델을 실행시켜 제1 음성 파형 데이터를 생성하고, 생성한 음성 파형 데이터는 메모리(예를 들면, 버퍼 메모리 등)에 저장할 수 있다. TTS 모델을 실행시켜 생성한 제1 음성 파형 데이터를 음성 합성 모델에 입력하는 단계(S1320)에, 프로세서(210; 도 2를 참조)는 음성 합성 모델(228; 도 2를 참조)을 실행시켜 제1 음성 파형 데이터를 입력할 수 있다. 음성 합성 모델은 미리 학습된 것일 수 있으며, 음성 합성 모델의 생성 및/또는 학습 방법은 전술한 도 10을 참 조하여 이루어질 수 있다. 음성 합성 모델을 실행시켜 제2 음성 파형 데이터를 생성하는 단계(S1330)에, 프로세서(210; 도 2를 참조)는 음 성 합성 모델(228; 도 2를 참조)을 실행시켜 제1 음성 파형 데이터를 입력하고, 제2 음성 파형 데이터를 생성할 수 있다. 프로세서는 생성한 제2 음성 파형 데이터를 메모리(예를 들면, 버퍼 메모리)에 저장할 수 있다. 제2 음성 파형 데이터는 학습된 음성 합성 모델의 특성 값(예를 들면, 주파수 특성 값, 지속 기간 특성 값, 고저 특성 값 등)을 반영하여 생성된 것일 수 있다. 제2 음성 파형 데이터의 특성 값은, TTS 모델에 입력된 사투리 문장의 라벨 값과 대응할 수 있다. 즉, 생성된 제2 음성 파형 데이터의 주파수 특성 값, 지속 기간 특성 값, 고저 특성 값은, TTS 모델에 입력된 사투리 문장 의 라벨 값(예를 들면, \"경북 지역\", \"청년(19~29세)\", \"남성(male)\", \"기쁨\", \"평서문\")에 대응할 수 있다. 이에 따라, 본 개시의 실시예들에 따른 서버(102; 도 1을 참조)는, 복수의 단말기들(105, 106; 도 1을 참조) 중 어느 하나로부터 수신한 표준어 문장 및 이의 라벨 값에 대응하여, 같은(또는 실질적으로 동일한) 의미를 가지 면서 선택된 라벨 값에 대응하는 특성 값을 갖는 사투리 문장 및 이의 음성 파형 데이터를 생성할 수 있다. 도 14a는 단말기의 출력 장치에서 표시되는 화면을 예시적으로 나타낸 도면이다. 도 14b는 단말기에서 출 력되는 사투리 문장 및 이의 음성 파형 데이터의 예시이다. 도 14a를 참조하면, 단말기의 출력 장치에는 표준어 문장 입력 블록, 옵션 입력 블록, 및 데 이터 전송 블록이 표시될 수 있다. 단말기의 출력 장치는 일례로, 표시 장치(display device)를 포 함할 수 있다. 단말기의 출력 장치는 일례로, 스피커(speaker)를 포함할 수 있다. 도 14는 단말기의 출력 장치에 표시 장치 및 스피커의 기능이 하나의 출력 장치 내에서 일체로 구현된 것을 예시로 들어 설명하나, 본 개시의 실시예들이 이에 제한되는 것은 아니다. 표시 장치와 스피커는 별도의 출력 장치로 구성될 수 있다. 표준어 문장 입력 블록에는 표준어 문장이 입력될 수 있다. 표준어 문장은 단말기의 사용자에 의해 입력 될 수 있으며, 단말기의 사용자는 사투리로 변환하고자 하는 표준어 문장을 단말기의 입력 장치(예를 들면, 키 보드, 터치 패드 등)를 이용해 입력할 수 있다. 옵션 입력 블록에는, 옵션이 입력될 수 있다. 단말기의 사용자로부터 선택되는 옵션은 서버(102; 도 1을 참조)의 라벨 값에 대응할 수 있다. 옵션은 예를 들어, 지역, 연령대, 성별, 감정 상태 , 및 문장 종류 등을 포함할 수 있으나, 본 개시의 실시예들이 이에 제한되는 것은 아니다. 데이터 전송 블록은 활성화 버튼을 통해 구현될 수 있다. 단말기의 사용자가 데이터 전송 블록을 클릭하면, 표준어 문장 입력 블록에 입력된 표준어 문장 및 옵션 입력 블록에 입력된 옵션이 네트 워크(104; 도 1을 참조) 등을 통해 서버(102; 도 1을 참조)에 전송될 수 있다. 서버(102; 도 1을 참조)는 단말기로부터 입력된 옵션을 라벨 값으로 갖는 표준어 문장을 수신하고, 수신한 표준 어 문장을 사투리 문장 및 음성 파형 데이터로 변환할 수 있다. 서버의 위와 같은 동작은 도 11에 도시된 순서도를 통해 설명될 수 있다. 옵션 입력 블록에는 \"무관\" 옵션이 구비될 수 있다. 실시예에 따라, 옵션 입력 블록에 \"무관\" 옵션 이 구비되지 않고 단말기의 사용자가 해당 옵션을 선택하지 않는 것으로 대체될 수 있다. 예를 들면, 단말기의 사용자는 지역, 연령대, 성별, 감정 상태, 문장 종류 중 적어도 하나를 선택하지 않거나, 또는 \"무관\" 옵션을 선택할 수 있다. 단말기로부터 \"무관\" 옵션이 선택되거나, 또는 단말기로부터 적어도 하나의 옵션의 라벨 값에 대해 입력을 받지 않으면, 서버(102; 도 1을 참조)는 해당 옵션의 라벨 값을 미리 설정된 라벨 값으로 대체할 수 있다. 또는, 실 시예에 따라, 서버는 미리 설정된 규칙 또는 무작위의 선택에 따라 여러 가지 라벨 값들 중 어느 하나를 선택하여 선택된 라벨 값으로 해당 옵션의 라벨 값을 대체할 수 있다. 도 14b를 참조하면, 단말기의 출력 장치에는 문장 변환 블록 및 음성 변환 블록이 표시될 수 있다. 실시예에 따라, 단말기의 출력 장치에는 톤(tone) 조절 블록, 강세(accent) 조절 블록, 및 속도 (tempo) 조절 블록 중 적어도 하나가 표시될 수 있다. 문장 변환 블록에는 사투리 문장이 표시될 수 있다. 문장 변환 블록에 표시되는 사투리 문장은, 표 준어 문장 입력 블록에 입력된 표준어 문장과 동일한(또는 실질적으로 동일한) 의미를 가지고, 옵션 입력 블록에 입력된 옵션과 동일한 옵션을 가질 수 있다. 문장 변환 블록에 표시되는 사투리 문장은, 서 버(102; 도 1을 참조)의 프로세서(210; 도 2를 참조)가 언어 변환 모델(224; 도 2를 참조)을 실행시켜 생성한 것일 수 있다. 음성 변환 블록은 활성화 버튼을 통해 구현될 수 있다. 예를 들면, 단말기의 사용자가 음성 변환 블록 을 선택(예를 들면, 클릭)하면, 표시 장치는 문장 변환 블록에서 표시되는 텍스트 데이터와 대응하는(예를 들면, 동일한) 음성을 출력할 수 있다. 음성 변환 블록을 클릭하여 출력되는 음성은, 서버 (102; 도 1을 참조)의 프로세서(210; 도 2를 참조)가 TTS 모델(226; 도 2를 참조) 및 음성 변환 모델을 실행시켜 생성한 것일 수 있다. 톤 조절 블록, 강세 조절 블록, 및 속도 조절 블록은 단말기의 사용자에 의해 음성 파형 데 이터의 특성 값을 조절하기 위해 구성될 수 있다. 톤 조절 블록, 강세 조절 블록, 및 속도 조절 블 록은 각각 업(up) 버튼 및 다운(down) 버튼을 포함할 수 있다. 단말기의 사용자에 의한 업 버튼 및/또는 다운 버튼의 선택(예를 들면, 클릭)에 따라, 서버는 음성 파형 데이터의 특성 값(예를 들면, 주파수 특성 값, 지속 시간 특성 값, 고저 특성 값 등)을 변경하고, 특성 값이 변경된 음성 파형 데이터를 단말기에 송신할 수 있다. 톤 조절 블록은 음성의 톤을 조절하기 위해 구성될 수 있다. 예를 들면, 톤 조절 블록의 업 버튼은 음성 파형 데이터의 주파수 특성 값을 크게 하기 위해 구성될 수 있다. 예를 들면, 톤 조절 블록의 다운 버튼은 음성 파형 데이터의 주파수 특성 값을 작게 하기 위해 구성될 수 있다. 강세 조절 블록은 음성의 강세를 조절하기 위해 구성될 수 있다. 예를 들면, 강세 조절 블록의 업 버튼은 음성 파형 데이터의 고저(pitch) 특성 값을 높이기 위해 구성될 수 있다. 예를 들면, 강세 조절 블록 의 다운 버튼은 음성 파형 데이터의 고저 특성 값을 낮추기 위해 구성될 수 있다. 속도 조절 블록은 음성의 늘어짐을 조절하기 위해 구성될 수 있다. 예를 들면, 속도 조절 블록의 업 버튼은 음성 파형 데이터의 지속 기간(duration) 특성 값을 높이기 위해 구성될 수 있다. 예를 들면, 속도 조절 블록의 다운 버튼은 음성 파형 데이터의 지속 기간 특성 값을 낮추기 위해 구성될 수 있다. 이상 설명한 바를 참조하면, 본 개시의 실시예들에 의하면 다양한 라벨 값(예를 들면, 지역, 연령, 성별, 감정 상태, 문장 종류 등)을 갖는 사투리 문장을 효과적으로 생성할 수 있다. 본 개시의 실시예에 의하면, 유사한 특 성 값(예를 들면, 주파수 특성 값, 지속 시간 특성 값, 고저 특성 값)을 갖는 음성 파형 데이터를 기초로 음성 합성 모델을 생성함으로써, 음성 합성 모델을 정교하게 생성 및/또는 학습할 수 있다. 본 개시의 실시예들에 의 하면, 단말기의 사용자가 입력한 표준어 문장 및 이의 옵션에 부합하는 사투리 문장 및 이의 음성 파형 데이터 를 단말기에 제공할 수 있다. 지금까지 참조한 도면과 기재된 발명의 상세한 설명은 단지 본 발명의 예시적인 것으로서, 이는 단지 본 발명을 설명하기 위한 목적에서 사용된 것이지 의미 한정이나 특허청구범위에 기재된 본 발명의 범위를 제한하기 위하 여 사용된 것은 아니다. 그러므로 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 특허청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0052038", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시예들에 따른 사투리 변환 시스템의 블록도이다. 도 2는 본 개시의 실시예들에 따른 서버의 시스템 블록도이다. 도 3은 본 개시의 실시예들에 따른 언어 변환 모델의 생성 방법을 나타내는 순서도의 예시이다. 도 4는 도 3의 사투리 학습용 데이터를 준비하는 단계를 구체적으로 나타낸 순서도이다. 도 5는 도 3의 언어 변환 모델을 생성하는 단계를 구체적으로 나타낸 순서도이다. 도 6은 생성된 언어 변환 모델을 이용하여 표준어 문장에 대응하는 사투리 문장들을 생성하는 방법을 나타낸 순 서도이다. 도 7은 본 개시의 실시예들에 따른 언어 변환 모델을 생성하기 위한 사투리 학습용 데이터의 예시이다. 도 8은 본 개시의 실시예들에 따른 언어 변환 모델의 모식도이다. 도 9는 도 8의 언어 변환 모델의 동작에 대한 구체적인 예시이다. 도 10은 생성된 사투리 문장들을 이용해 사투리 음성 합성 모델을 생성 및/또는 학습하는 방법을 나타낸 순서도 이다. 도 11은 본 개시의 실시예들에 따른 사투리 변환 서비스를 제공하는 방법의 순서도이다. 도 12는 도 11의 표준어 문장을 사투리 문장으로 변환하는 단계를 구체적으로 나타낸 순서도이다. 도 13은 도 11의 사투리 문장에 대응하는 음성 파형 데이터를 생성하는 단계를 구체적으로 나타낸 순서도이다. 도 14a는 단말기의 출력 장치에서 표시되는 화면을 예시적으로 나타낸 도면이다. 도 14b는 단말기에서 출력되는 사투리 문장 및 이의 음성 파형 데이터의 예시이다."}
