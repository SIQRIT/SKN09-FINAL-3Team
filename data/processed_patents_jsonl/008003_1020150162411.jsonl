{"patent_id": "10-2015-0162411", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2017-0058612", "출원번호": "10-2015-0162411", "발명의 명칭": "영상 기반 실내측위 방법 및 그의 시스템", "출원인": "(주)예사싱크", "발명자": "김선영"}}
{"patent_id": "10-2015-0162411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "센서나 인공부착물에 의하여 영상 기반 실내 측위 방법에 있어서, 지능형 카메라에 의하여 배경화면을 촬영하고 배경화면에 대한 바닥위치를 측정하는 제1 과정과, 상기 제1 과정의 배경화면에 대하여 원하는 위치 정확도를 결정하고 가상 투명 그리드를 생성하며, 가상 투명그리드에 대한 격자들의 가상 좌표 값을 생성하는 제2 과정과, 제1 과정의 배경화면과 지능형 카메라에 의하여 연속 촬영되는 실제화면 또는 실제화면들끼리 비교하여 새로운객체 생성을 인지하는 제3 과정과, 상기 제2 과정의 가상 투명 그리드와 상기 제3 과정의 실제화면의 패턴을 비교하여 상이한 패턴이 존재하는 경우에, 상이한 패턴을 추출하여 상이한 패턴의 격자들의 가상 좌표 값을 인식함으로써 개별 객체별의 위치정보를산출하는 제4 과정을 포함하는 것을 특징으로 하는 영상 기반 실내측위 방법."}
{"patent_id": "10-2015-0162411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 제4 과정의 위치정보 산출 과정에서, 하나의 개별 지능형 카메라의 커버리지 영역과 다른 개별 지능형 카메라의 커버리지 영역의 중복영역을 제외하고, 생성된 객체에 대한 상이한 패턴이 많이 생성되는 개별 지능형카메라의 커버리지 영역측으로 핸드오버되도록 결정해 주는 제5 과정을 더 포함하는 것을 특징으로 하는 영상기반 실내측위 방법."}
{"patent_id": "10-2015-0162411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1항에 있어서, 상기 제1 과정에서, 원하는 위치정확도의 결정은 아래의 식 X : Z = ΔX : ΔZΔX = (X x ΔZ) / Z여기서 X: 원하는 위치정확도(해상도) Z: 카메라 렌즈에서부터 바닥까지의 수직 거리 ΔZ: 카메라 렌즈에서부터 가상그리드까지의 수직 거리 ΔX: 가상그리드의 위치정확도(해상도)에 의하여 이루어지는 것을 특징으로 하는 영상 기반 실내측위 방법."}
{"patent_id": "10-2015-0162411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서, 상기 제3 과정 후에, 패턴매칭 알고리즘 처리 및 개별 객체별 이동경로/위치 산출부의 패턴매칭 알고리즘 처리에 의하여, 생성된 새로운 객체가 사람인지 혹은 사물인지를 판단하는 것을 특징으로 하는 영상 기반 실내측위방법."}
{"patent_id": "10-2015-0162411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서, 상기 제2 과정에서, 원하는 해상도에 따라 가상 투명 그리드를 생성하여 촬영된 배경화면과 중첩한 다음에, 촬공개특허 10-2017-0058612-3-영된 배경화면의 수직 거리를 자동 산출해 주는 것을 특징으로 하는 영상 기반 실내측위 방법."}
{"patent_id": "10-2015-0162411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 제2 과정의 가상 좌표 값에서, 가상 투명 그리드의 정 중앙을 X-Y좌표의 원점(0,0)으로 설정하고 X축의 오른 측을 (+)값, 그리고 X축의 왼 측을 (-)값을 부여하며, Y축에서 전방 측을 (+)값, 그리고 후방 측을 (-)값을부여해 주는 것을 특징으로 하는 영상 기반 실내측위 방법."}
{"patent_id": "10-2015-0162411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서, 상기 제1과정에서, 반사, 희미해지는 블러링 또는 조명으로 인한 영향을 제거하기 위해서 지능형 카메라 노출을제로로 하여 불빛 성분만 추출하는 것을 특징으로 하는 영상 기반 실내측위 방법."}
{"patent_id": "10-2015-0162411", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "별도의 센서나 인공부착물(표식, 비콘 등) 또는 핑거프린팅없이 실내 공간내의 천정에 설치된 카메라를 통해 촬 영된 화면에, 원하는 정확도의 가상 투명 그리드를 중첩하여 사람 또는 물체의 위치정보를 측위하는 방법 및 그 의 시스템에 관한 것으로서, 배경화면과 초당 30프레임의 실제화면의 비교함으로써, 상이한 패턴 인식으로 인하 여 객체 생성, 객체의 위치정보 산출, 객체의 중복영역 이동 및 핸드오버 결정에 의하여 객체의 이동경로 및 위 치정보를 파악할 수 있도록 구성되어 있다. 이에 따라 본 발명은 저가의 정확한 실내측위가 가능한 효과를 발휘할 수 있다."}
{"patent_id": "10-2015-0162411", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 실내측위방법에 관한 것으로서, 특히 천정에 부착되는 카메라에 의하여 촬영된 바닥의 영상화면에, 원하는 임의의 위치 정확도로 설정된 픽셀 가상 좌표기반의 가상 투명 그리드를 매핑하여 움직이는 사람 또는 물체의 위치정보를 측위하는 방법 및 그의 시스템에 관한 것이다."}
{"patent_id": "10-2015-0162411", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "실내측위방법은 전파, 광원 등을 이용하여 건물 내부에 있는 사용자의 위치를 파악하고, 이를 스마트폰을 포함 한 스마트 디바이스에 내장된 지도에 표시하여 물건이나 장소의 위치를 쉽게 찾아주는 방법이다. 전파를 이용하는 무선 측위는 사용자의 이동 단말기와 여러 개의 이동통신망의 기지국이나 무선랜 통신망의 액 세스 포인트나 블루투스 액세스포인트 등 WPAN, WLAN액세스 포인트에서 송출되는 신호를 측정하여 처리함으로써, 실내.외에서 사용자의 위치를 결정하게 된다. 사용자의 이동 단말기의 위치를 결정하기 위해서 사용되는 측정치에는 시각 기반으로 하는 측정치와 배열 안테나를 이용한 도래각 기반으로 하는 측정치, 및 신 호 세기를 기반으로 하는 측정치가 있다. 시각 기반으로 하는 도달시간(TOA : Time of Arrival)과 도달시간차이(TDOA : Time Difference of Arrival) 및 도래각(AOA : Angle of Arrival)과, 신호세기(RSS : Received Signal Strength)의 측정치가 얻어졌을 때, 기하 학적인 방법과 통계적인 방법을 이용하여 사용자의 이동 단말기 위치를 결정할 수 있다. AGPS(Assisted Global Positioning System)방법은 GPS 위성 및 무선 시스템 신호를 혼합한 것이다. 단말기는 위성뿐만 아니라 무선 네트워크 기지국으로부터 측위를 위한 측정치를 수집하여 위치를 측정하거나 혹은 수집된 정보를 PDE(Position Determination Entity)에 보내고 PDE에서는 단말기에서 보낸 정보와 기지국에서 생성된 정보를 혼합하여 단말기 위치를 측정한다. AOA(Angle of Arrival)방법은 두개 이상의 기지국이 단말기로부터 오는 신호의 방향을 측정하여 방향각을 구하 고 이것을 이용하여 단말기의 위치를 추정한다. 단말기의 위치를 구하기 위해서는 최소 2개 이상의 방향각이 필 요하다. Cell ID방법은 단말기의 위치를 서비스 Cell의 정보를 이용해 추정한다. 단말기의 위치는 Cell의 서비스 영역에 위치한다. Enhanced Cell ID방법은 상기 Cell ID방법에 기지국과 단말기 사이에 거리정보를 추가하여 정확도를 개선한 방 법이다. RF패턴매칭방법은 신호원으로부터 수신기의 안테나에 수신된 RF패턴을 이용한다. 이 RF패턴은 사전에 구축된 위 치에 대한 기준 RF패턴데이터베이스와 비교되어서 가장 유사한 기준 RF패턴에 해당하는 위치를 단말기의 위치로 추정하는 방법이다. TDOA(Time Difference of Arrival)방법은 서비스 기지국 신호와 주변 기지국 신호의 신호도달 시각차를 측정한 다. 이것은 기하학적으로 신호도달 시각차를 이용하여 두 기지국을 초점으로 하는 쌍곡선을 그리게 되고, 단말 기는 이 쌍곡선 위에 위치한다. 서비스 기지국과 인접 기지국의 신호 도달 시각차를 측정한 값으로부터 여러개 의 쌍곡선이 생기게 되고 이 쌍곡선들의 교점을 단말기의 위치로 추정한다. TOA(Time of Arrival)방법은 전파도달시간을 측정하여 기지국으로부터 단말기까지의 거리를 알 수 있다. 이것은 기하학적으로 기지국을 중심으로 원을 그리게 되고, 단말기는 이 원 위에 있게 된다. 서비스 기지국과 인접 기 지국으로부터 전파도달시간을 측정한 값으로 여러개의 원들이 생기게 되고, 이 원들의 교점을 단말기의 위치로 추정한다. TOA(Time of Arrival)방법은 수신기와 송신기의 시각 동기화 문제점이 있고 TDOA(Time Difference of Arriva l)방법은 네트워크상의 시각 동기화 문제가 존재하고 있다. 신호 세기(RSS)방법은 초기 시스템 구축시 상당한 시간과 노력이 소요되고 데이타베이스의 운영 관리가 어렵다 는 단점을 지니고 있다. 핑거프린트 방식은 실내 공간을 가상의 격자로 잘게 쪼개고 해당 격자마다 각 WiFi신호의 세기를 측정하여 지문 과 같은 형태로 데이터베이스화 해 놓은 후에, 자신이 측정한 WiFi신호의 세기를 데이터베이스와 비교하여 위치 를 알아낼 수 있도록 하는 방식으로써 종래의 방식보다 더 정확성을 향상시킨 방식이다. 상기 문제점 내지 단점을 극복하기 위하여 카메라를 이용하여 사람이나 혹은 사람의 위치를 측정하는 방법이 개 발되어왔다. 대한민국 특허등록공보 제10-0749923호에는 천정에 부착되는 무선 송수신 기능을 가진 n개의 표식와, 표식을 촬 영하는 카메라와, 천정에 부착된 표식을 점멸시킨 후 카메라를 이용하여 촬영한 영상에서 표식의 위치 및 ID를 획득하여 최소 두 개의 표식을 검출하는 표식 검출부와, 검출된 표식을 이용하여 이동 로봇의 위치를 계산하는 로봇위치 검출부와, 작업 공간에 새로운 표식이 부착될 경우, 새로운 표식의 절대 가상 좌표상의 위치를 계산하 는 표식위치 추정부와, 새로운 표식의 위치를 이용하여 이동 로봇의 토폴로지 맵을 만드는 토폴로지 맵 구성부 와, 토폴로지 맵을 이용하여 이동 로봇의 주행을 제어하는 로봇 제어부를 포함하여 구성되는 이동 로봇으로 이 루어지는 것을 특징으로 하는 카메라와 표식을 이용한 이동 로봇의 측위 시스템에 관한 기술이 개시되어 있다. 대한민국 특허등록번호 제10-1186733호에는 사용자의 위치 궤적과 촬영 영상을 제공하는 시스템에서, 카메라가 부착되고, 촬영부 구분자가 할당되며, 주변 영상을 촬영하는 촬영부들과, 사용자가 소지하고 사용자 인식 정보가 할당되며, 사용자 인식 정보를 발신하는 발신부들과, 수신처 인식 정보가 할당되고, 특정 거리 내의 발신부 들을 감지하기 위해 수신감도가 조절되며, 수신 안테나의 수신각이 조절되며, 발신부들에서 발신되는 사용자 인 식 정보를 수신하는 수신부들과, 수신부들이 수신한 사용자 인식 정보와 수신처 인식 정보를 주기적으로 수신하 여, 사용자 인식 정보별 판별 시간과 수신처 인식 정보를 저장하는 위치 저장부와, 촬영부들에서 촬영된 영상을 수신하여, 촬영부 구분자별로 촬영 시간과 촬영 영상을 저장하는 영상 저장부와, 사용자 인식 정보를 통해 사용 자의 위치 궤적 정보와 촬영 영상 정보를 요청하고 수신하여 화면에 표시하는 조회부를 포함하고, 사용자 위치 궤적 정보와 촬영 영상 정보를 조회부에서 요청하면, 이 요청이 위치 저장부로 전달되고 위치 저장부는 사용자 인식 정보가 판별된 시간과 수신처 인식 정보를 조회부로 송신하여 조회가 화면상에 위치 궤적을 표시하며, 위 치 저장부가 판별된 시간과 수신처 인식정보를 영상 저장부로 전송하면 영상 저장부에서 관련 영상이 저장되어 있는지를 검색하여 있으면, 관련 영상을 조회부로 송신하여 조회부에서 관련 영상을 재생하는 것을 특징으로 하 는 사용자의 위치 궤적과 촬영 영상을 제공하는 시스템에 관한 기술이 개시되어있다. 대한민국 특허등록번호 제10-1415016호에는 영상기반 실내 위치 검출방법으로서, 사용자 단말기에 내장된 카메 라를 이용하여 사용자의 하나 이상의 방향에 대한 영상을 획득하는 단계와, 획득된 사용자의 방향에 해당하는 영상에서 건물 내부의 특징을 추출하는 단계와, 사용자의 방향과 추출된 영상의 특징을 건물 실내 지도 정보와 매칭하는 단계와, 영상과 맵의 매칭 프로세스를 통해 사용자 단말기의 위치를 추정하는 단계를 포함하되, 건물 실내 지도 정보는 사용자 단말기와 네트워크를 통해 연결된 맵 데이터 서버를 통해 수신된 건물의 정보와 고도 정보에 기초하여 추출된 단말기 사용자의 개략적 위치에 해당하는 지도인 것을 특징으로 하는 영상기반 실내 위 치 검출방법이 개시되어있다. 그러나 상기 언급한 종래의 영상기반 실내측위방법들은 별도의 센서나 인공부착물(표식, 비콘 등) 또는 핑거프 린팅을 부가하여야 이용할 수 있기 때문에 시스템의 초기 설치에 비용이 많이 소모되는 단점과 배터리 수명 문 제가 있었다."}
{"patent_id": "10-2015-0162411", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "그리하여 본 발명은 상기 문제점들을 해결하기 위하여 창작한 것으로서, 별도의 센서나 인공부착물(표식, 비콘 등) 또는 핑거프린팅없이 실내 공간내의 천정에 설치된 카메라를 통해 촬영된 화면에, 원하는 정확도의 가상 투 명 그리드를 중첩하여 사람 또는 물체의 위치정보를 측위하는 방법 및 그의 시스템을 제공하는 것이 목적이다."}
{"patent_id": "10-2015-0162411", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 영상 기반 실내측위 방법은 지능형 카메라에 의하여 배경화면을 촬영하고 배경화면에 대한 바닥 위치를 측정하는 제1 과정과, 제1 과정의 배경화면에 대하여 원하는 위치정확도를 결정하고 가상 투명 그리드를 생성하며, 가상 투명 그리드에 대한 격자들의 가상 좌표 값을 생성하는 제2 과정과, 제1 과정의 배경화면과 지 능형 카메라에 의하여 연속 촬영되는 실제화면 또는 실제화면들끼리 비교하여 새로운 객체 생성을 인지하는 제3 과정과, 제2 과정의 가상 투명 그리드와 상기 제3 과정의 실제화면의 패턴을 비교하여 상이한 패턴이 존재하는 경우에, 상이한 패턴을 추출하여 상이한 패턴의 격자들의 가상 좌표 값을 인식함으로써 개별 객체별의 위치정보 를 산출하는 제4 과정을 포함한다. 본 발명에 따른 영상 기반 실내측위 방법은 제4 과정의 위치정보 산출 과정에서, 하나의 개별 지능형 카메라의 커버리지 영역과 다른 개별 지능형 카메라의 커버리지 영역의 중복영역을 제외하고, 생성된 객체에 대한 상이한 패턴이 많이 생성되는 개별 지능형 카메라의 커버리지 영역측으로 핸드오버되도록 결정해 주는 제5 과정을 더 포함한다. 본 발명에 따른 영상 기반 실내측위 방법은 제1 과정에서, 원하는 위치정확도의 결정은 아래의 식 X : Z = ΔX : ΔZ ΔX = (X x ΔZ) / Z 여기서 X: 원하는 위치정확도(해상도) Z: 카메라 렌즈에서부터 바닥까지의 수직 거리 ΔZ: 카메라 렌즈에서부터 가상그리드까지의 수직 거리 ΔX: 가상그리드의 위치정확도(해상도) 에 의하여 이루어지는 것을 특징으로 한다. 본 발명에 따른 영상 기반 실내측위 방법은 제3 과정 후에, 패턴매칭 알고리즘 처리 및 개별 객체별 이동경로/ 위치 산출부의 패턴매칭 알고리즘 처리에 의하여, 생성된 새로운 객체가 사람인지 혹은 사물인지를 판단해 주는 것을 특징으로 한다. 본 발명에 따른 영상 기반 실내측위 방법은 제2 과정에서, 원하는 해상도에 따라 가상 투명 그리드를 생성하여 촬영된 배경화면과 중첩한 다음에, 촬영된 배경화면의 수직 거리를 자동 산출해 주는 것을 특징으로 한다."}
{"patent_id": "10-2015-0162411", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 영상 기반 실내측위방법에 의하면, 별도의 인공부착물이 존재하지 않아 저가의 고 정확도 실내 측위가 가능한 효과를 발휘할 수 있다."}
{"patent_id": "10-2015-0162411", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들에 의거하여 본 발명에 따른 영상 기반 실내측위방법의작용 및 효과를 상세히 설명한다. 이에 앞서, 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정해서 해석되어서 는 아니 되고 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 발명의 가장 바람직한 일 실시예에 불과할 뿐이 고 본 발명의 기술적 사상 모두를 포함하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양 한 균등물과 변형예들로 변형 내지 수정할 수 있음을 이해하여야 한다.도 1은 본 발명에 따른 영상 기반 실내측위 방법을 설명하기 위한 실내 측위 시스템의 개요도이다. 도 1에서, 본 발명에 따른 영상 기반 실내 측위 시스템은 배경화면 및 실제화면을 촬영하고 촬영된 사람이나 물 체의 위치보정이 가능한 지능형 카메라을 포함한다. 지능형 카메라은 촬영된 영상이 매장 등의 불빛으로 인하여 반사, 희미해지는 블러링 또는 조명으로 인한 영향을 제거하기 위해서 카메라 노출을 제로로 하여 불빛 성분만 추출하고, 여러 개를 합성하여 밝은 부분 및 어두운 부분의 반사 및 조명 영향 성분을 제거할 수 있다. 도 2에 도시된 바와 같이 본 발명에 따른 영상 기반 실내 측위 시스템에서 지능형 카메라은 바닥면으로부 터 카메라 높이(Z)까지의 객체의 바닥위치를 측정하는 바닥위치측정 센서부과, 배경화면과 실제화면을 촬 영하는 촬영부와, 바닥위치측정 센서부로부터 객체의 바닥위치의 값과 배경화면 및 실제화면의 영상 정보를 받는 제어부과, 바닥위치측정 센서부로부터 객체의 바닥위치의 값을 보정하기 위하여 위치보 정의 값을 제어부로 제공하는 위치보정부과, 위치정보 및 영상정보를 실내위치정보 관리 및 분석 서 버로 제공하는 서버송수신부를 구비하고 있다. 본 발명에 따른 영상 기반 실내 측위 시스템은 지능형 카메라으로부터 촬영된 배경화면 및 실제화면을 전 송받아 저장하고 배경화면 및 실제화면의 화면평면에서 정사각형으로 가상 투명 그리드를 형성하는 격자들을 기 초로하여 가상 좌표정보를 생성하며, 객체별로 이동경로와 위치가 산출되는 실내위치정보 관리 및 분석 서버 을 구비하고 있다. 실내위치정보 관리 및 분석 서버는 산출된 객체별 이동경로 및 위치정보를 저장하고 복수개의 카메라들의 각각에 대한 중복영역의 픽셀 정보에 대한 데이터를 산출저장하며, 오브젝트별 이동에 다른 변화된 픽셀을 근거 로 핸드오버를 결정한다. 또한, 실내위치정보 관리 및 분석 서버는 카메라 수직 아래 픽셀과 가장 가까운 객체 픽셀의 위치인 객체 의 바닥 위치를 결정하고 실내지도에 대한 맵 또는 웹을 고객 단말 또는 관제센터 모니터에 제공하며, 고객 단 말로 위치정보를 전송하여 준다. 별도의 센서나 인공부착물(표식, 비콘 등) 또는 핑거프린팅없이 영상기반 실내 위치 검출을 위해서는 우선, 실 내위치정보 관리 및 분석 서버는 실내지도에 대한 맵을 기준으로 하여 실내에 설치되는 복수개의 지능형 카메라들 각각에 대하여 실내객체의 바닥위치를 측정하도록 명령정보를 개별 지능형 카메라에 전송하 면, 개별 지능형 카메라에서 제어부은 서버송수신부을 통하여 명령정보를 받아서 바닥위치측정 센서부 및 촬영부을 제어하여 촬영부가 배경화면을 촬영하고 바닥위치측정 센서부가 배경 화면에 대한 바닥위치를 측정하게 한다. 이때에 바닥위치측정 센서부는 개별 지능형 카메라를 기준으로 도 4에 도시된 바와 같이 수직방향 바 닥으로 부터의 높이(Z)를 측정하여 배경화면에 대한 바닥위치의 값을 생성한다. 제어부는 측정되는 배경화면에 대한 바닥위치의 값을 받고나서, 위치보정부으로부터 발생되는 위치보 정의 값을 받아 배경화면에 대한 바닥위치의 값을 위치보정하고 배경화면의 영상정보 및 배경화면에 대한 위치 정보를 서버송수신부을 통하여 실내위치정보 관리 및 분석 서버로 전송해 준다. 그러면 실내위치정보 관리 및 분석 서버는 개별 지능형 카메라로부터 전송해 온 배경화면의 영상정보 및 배경화면에 대한 위치정보를 받아서, 배경화면의 영상정보는 배경화면 저장부에 저장하고 배경화면에 대한 위치정보는 가상 투명 그리드 및 가상 좌표 생성부에 의하여 위치정보에 대한 가상 좌표 값이 생성되 도록 한다. 여기에서 실내위치정보 관리 및 분석 서버의 가상 투명 그리드 및 가상 좌표 생성부는 도 4와 같이 배경화면에 대하여 원하는 위치정확도(해상도)를 결정하고 배경화면에 대한 가상 투명 그리드를 생성 하며, 가상 투명 그리드에 대한 격자들의 가상 좌표 값을 생성하도록 한다. 원하는 위치정확도(해상도)의 결정은 도 4를 참조하여 아래와 같은 식에 의하여 이루어진다. X : Z = ΔX : ΔZ .... ΔX = (X x ΔZ) / Z 여기서 X: 원하는 위치정확도(해상도) Z: 카메라 렌즈에서부터 바닥까지의 수직 거리 ΔZ: 카메라 렌즈에서부터 가상그리드까지의 수직 거리 ΔX: 가상그리드의 위치정확도(해상도) 도 4(b)에 도시한 바와 같이, 가상 투명 그리드 및 가상 좌표 생성부는 도 4(a)의 가상 투명 그리드의 정 중앙을 X-Y좌표의 원점(0,0)으로 설정하고 X축의 오른 측을 (+)값, 그리고 X축의 왼 측을 (-)값을 부여한다. 또 한, X-Y좌표의 Y축에서 전방 측을 (+)값, 그리고 후방 측을 (-)값을 부여해 주도록 한다. 더욱이 X축 선상에 존재하는 픽셀의 수만큼 X값을, 그리고 Y축 선상에 존재하는 픽셀의 수만큼 Y값을 부여한다. 예를 들면 X축 선상의 픽셀 수가 320이라면 최종 X값은 320이다. 그리하여 도 4의 가상 투명 그리드의 1분면에 존재하는 어느 픽셀의 좌표값은 (+X,+Y)이고, 2분면에 존재하는 어느 픽셀의 좌표값은 (-X,+Y), 3분면에 존재하는 어느 픽셀의 좌표값은 (-X,-Y)이며, 4분면에 존재하는 어느 픽셀의 좌표값은 (+X,-Y)이다. 또한, 실내위치정보 관리 및 분석 서버는 촬영된 배경화면과 생성되는 가상 투명 그리드를 중첩하여 비교 한 후에, 원하는 해상도를 기준으로 하여 촬영된 배경화면의 수직 거리와, 생성되는 가상 투명 그리드의 수직 거리를 자동 조정해 주고 가상 투명 그리드에 대한 격자들의 가상 좌표 값을 생성해 주도록 한다. 그리고 개별 지능형 카메라에서 배경화면 촬영 및 바닥위치측정을 포함하는 초기 설정을 마친 후에, 제어 부은 촬영부을 제어하여 초당 30프레임을 촬영하여 서버송수신부을 통하여 실내위치정보 관리 및 분석 서버에 전송하도록 한다. 실내의 다수의 지점에 설치되고 영상을 촬영하는 복수개의 지능형 카메라들 중에서 어느 개별 지능형 카메 라의 촬영부에서 최초 새로운 객체가 생성되었을 경우에, 실내위치정보 관리 및 분석 서버는 배 경화면저장부과 실제화면저장부의 프레임들을 서로 비교하거나 혹은 실제화면저장부의 프레임들 끼리 서로 비교하여 새로운 객체가 생성되었음을 인식하게 된다. 만약에 실내의 다수의 지점에 설치되고 영상을 촬영하는 복수개의 지능형 카메라들 중에서 어느 개별 지능 형 카메라의 촬영부에서 새로운 객체가 생성되었을 경우에, 실내위치정보 관리 및 분석 서버는 실제화면저장부의 현재 프레임과 실제화면저장부의 이전 프레임을 비교하여 새로운 객체가 생성되었 음을 인식하게 된다. 실내위치정보 관리 및 분석 서버는 패턴매칭 알고리즘 처리 및 개별 객체별 이동경로/위치 산출부의 패턴매칭 알고리즘 처리에 의하여, 생성된 새로운 객체가 사람인지 혹은 사물인지를 판단한다. 또한, 패턴매칭 알고리즘 처리 및 개별 객체별 이동경로/위치 산출부는 생성되는 새로운 객체마다 고유식 별번호를 생성하고 부여해 준다. 생성된 개별 객체별 위치정보를 산출하기 위하여, 패턴매칭 알고리즘 처리 및 개별 객체별 이동경로/위치 산출 부는 배경화면의 가상 투명 그리드와 실제화면의 패턴을 비교하여 상이한 패턴이 존재하는 경우에, 상이한 패턴을 추출하여 상이한 패턴의 격자들의 가상 좌표 값을 인식함으로써 개별 객체별의 위치정보를 산출할 수 있 다. 이때에 산출되는 위치정보는 객체별 이동경로 및 위치정보 저장부에 저장된다. 여기에서 객체별 이동경로 및 위치정보 저장부는 객체의 고유식별번호도 함께 저장하도록 한다. 연속적으로 움직이는 개별 객체별 이동경로를 산출하기 위하여, 패턴매칭 알고리즘 처리 및 개별 객체별 이동경 로/위치 산출부는 도 5와 같이, 배경화면의 가상 투명 그리드와 실제화면의 초당 30프레임의 패턴들을 계 속하여 비교하여 상이한 패턴들이 존재하는 경우에, 상이한 패턴들을 연속적으로 추출하여 상이한 패턴의 격자 들의 가상 좌표 값을 인식함으로써 개별 객체별의 다수의 위치정보을 산출할 수 있다. 산출된 많은 위치정보는 객체별 이동경로 및 위치정보 저장부에 저장되고 그들 위치정보를 추적함으로써 개별 객체별 이동경로를 인지할 수 있다. 만약에 새로 생성되는 객체가 복수개의 지능형 카메라들 중에서 어느 개별 지능형 카메라로부터 다른 개별 지능형 카메라으로 이동하는 경우에, 도 6에 도시된 바와 같이 하나의 개별 지능형 카메라의 커 버리지 영역과 다른 개별 지능형 카메라의 커버리지 영역에 동시에 출현하기 때문에, 실내위치정보 관리 및 분석 서버은 패턴매칭 알고리즘 처리 및 개별 객체별 이동경로/위치 산출부에 의하여 계속하여 움 직이는 객체가 하나의 개별 지능형 카메라의 커버리지 영역으로부터 다른 개별 지능형 카메라의 커버 리지 영역으로 이동하고 있다는 것을 인지하게 된다. 실내위치정보 관리 및 분석 서버의 카메라별 중복영역 픽셀 정보 데이터 산출 및 저장부는 하나의 개 별 지능형 카메라의 커버리지 영역의 격자들의 가상 좌표 값과 다른 개별 지능형 카메라의 커버리지 영역의 격자들의 가상 좌표 값의 비교에 의하여 하나의 개별 지능형 카메라의 커버리지 영역의 일부 영역 이 다른 개별 지능형 카메라의 커버리지 영역의 일부 영역과 중복되는 것을 인지하고 카메라별 중복영역에 대한 격자들의 가상 좌표 값을 산출하고 그 산출된 가상 좌표 값을 저장하게 된다. 실내위치정보 관리 및 분석 서버은 패턴매칭 알고리즘 처리 및 개별 객체별 이동경로/위치 산출부에 의하여 위치 산출하는 동안에, 산출되는 위치정보가 중복영역의 위치정보인지 아닌지를 알기 위하여 카메라별 중복영역 픽셀 정보 데이터 산출 및 저장부로부터 저장된 중복영역의 위치정보를 가져와 비교한 후에,산출 되는 위치정보와 카메라별 중복영역 픽셀 정보 데이터 산출 및 저장부로부터 저장된 중복영역의 위치정보 가 동일한 경우에, 생성된 객체가 하나의 개별 지능형 카메라의 커버리지 영역과 다른 개별 지능형 카메라 의 커버리지 영역에 동시에 출현하였기 때문에, 생성된 객체가 하나의 개별 지능형 카메라의 커버리 지 영역과 다른 개별 지능형 카메라의 커버리지 영역의 중복영역에 존재함을 알게 된다. 이때에 실내위치정보 관리 및 분석 서버이 생성된 객체가 하나의 개별 지능형 카메라의 커버리지 영 역과 다른 개별 지능형 카메라의 커버리지 영역의 중복영역에 존재함을 알게 되는 경우에, 실내위치정보관리 및 분석 서버의 오브젝트별 핸드오버 결정부은 생성된 객체가 하나의 개별 지능형 카메라 의 커버리지 영역과 다른 개별 지능형 카메라의 커버리지 영역중에서 어느 영역쪽으로 치우쳐 점유하고 있 는지를 판단, 다시 말하면, 중복영역에서 생성된 객체가 하나의 개별 지능형 카메라의 커버리지 영역과 다 른 개별 지능형 카메라의 커버리지 영역중에서 어느 영역쪽의 격자들에서 상이한 패턴이 적게 생성되는지 를 판단하여서, 생성된 객체가 상이한 패턴들이 적게 생성되는 영역에 해당하는 개별 지능형 카메라측으로 핸드오버되도록 결정해 준다. 다르게 말하면, 오브젝트별 핸드오버 결정부은 하나의 개별 지능형 카메라의 커버리지 영역과 다른 개별 지능형 카메라의 커버리지 영역의 중복영역을 제외하고, 생성된 객체에 의하여 상이한 패턴이 많이 생성되는 개별 지능형 카메라의 커버리지 영역측으로 핸드오버되도록 결정해 준다. 만약에 움직이는 객체가 장애물(예를 들면, 가판대, 앞 사람 등)에 의하여 객체 바닥위치가 가려진 경우에, 객 체 바닥위치 결정부에서는 투시 원근법에 의하여 가상 바닥위치를 스케치하고 그 가상 바닥위치의 스케일 링 팩터를 구하여, 가상 바닥위치의 스케일링 팩터에 의하여 객체의 바닥위치정보를 산출해 낸다. 사용자가 도 1의 고객 단말 또는 관제센터 모니터를 통하여 객체의 위치정보 또는 이동경로를 요청하는 경 우에, 실내위치정보 관리 및 분석 서버는 객체별 이동경로 및 위치정보 저장부에 저장된 위치정보를 고객 단말별 위치정보 전송부를 통하여 고객 단말 또는 관제센터 모니터로 전송해 준다. 허용된 또는 통계적인 분석 자료수집을 위해 객체 고유 식별번호와 고객 단말과의 매칭은 고객이 매장에 고객카 드를 무선(NFC, BLE 등) 또는 다른수단으로 접촉하여 ID가 식별 가능하거나 영상매칭 등으로 매칭하여 연계한다."}
{"patent_id": "10-2015-0162411", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 영상 기반 실내측위 시스템의 개요도이다. 도 2는 본 발명에 따른 영상 기반 실내측위 시스템에서 지능형 카메라의 구성에 대한 블록도이다. 도 3은 본 발명에 따른 영상 기반 실내측위 시스템에서 실내위치정보 관리 및 분석 서버의 구성에 대한 블록도 이다. 도 4(a)는 본 발명에 따른 영상 기반 실내측위 방법에서 위치정확도(해상도)를 산출하는 과정을 설명하기 위한 도면이고 도 4(b)는 도 4(a)의 A부분의 확대도이다. 도 5는 본 발명에 따른 영상 기반 실내측위 방법에서 객체의 이동경로 및 위치정보를 산출하는 과정을 설명하기 위한 도면이다. 도 6은 본 발명에 따른 영상 기반 실내측위 방법에서 객체의 해당 카메라를 선택하는 핸드오버를 결정하는 과정 을 설명하기 위한 도면이다."}
