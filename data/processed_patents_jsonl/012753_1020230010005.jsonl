{"patent_id": "10-2023-0010005", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0029712", "출원번호": "10-2023-0010005", "발명의 명칭": "운동 영상에 기초한 합성 영상 제공 방법", "출원인": "임요셉", "발명자": "임요셉"}}
{"patent_id": "10-2023-0010005", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "스포츠 훈련 영상에 기초한 합성 영상 제공 방법에 있어서:제1 선수가 제1 운동을 수행하는 동안 상기 제1 선수의 정면 방향으로 비행하는 드론에 의하여 촬영된 제1 영상데이터에 기초하여, 제1 운동 영상을 획득하는 단계;상기 제1 운동 영상으로부터 배경 영역과 제1 선수 영역을 분리하여 제1 배경 영상 및 제1 선수 영상을 획득하는 단계;상기 드론의 비행 속도 및 상기 제1 영상 데이터가 촬영된 시간 정보에 기초하여 상기 제1 배경 영상의 복수의프레임을 합성하여 배경 이미지를 생성하는 단계;상기 드론의 비행 속도 및 상기 제1 영상 데이터가 촬영된 시간 정보에 기초하여, 상기 제1 선수 영상의 적어도하나의 프레임을 상기 배경 이미지 상에 오버레이하여 제1 합성 영상을 생성하는 단계; 및상기 제1 합성 영상을 사용자 장치에 송신하는 단계, 및상기 사용자 장치에서 상기 제1 합성 영상을 표시하는 단계를 포함하는, 합성 영상 제공 방법."}
{"patent_id": "10-2023-0010005", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 방법은: 제2 선수가 상기 제1 운동을 수행하는 동안 상기 제2 선수의 정면 방향으로 비행하는 드론에 의하여 촬영된 제2영상 데이터에 기초하여, 제2 운동 영상을 획득하는 단계;상기 제2 운동 영상으로부터 배경 영역과 제2 선수 영역을 분리하여 제2 선수 영상을 획득하는 단계; 상기 드론의 비행 속도 및 상기 제2 영상 데이터가 촬영된 시간 정보에 기초하여, 상기 제2 선수 영상의 적어도하나의 프레임을 상기 제1 합성 영상 상에 오버레이하여 제2 합성 영상을 생성하는 단계;상기 제2 합성 영상을 사용자 장치에 송신하는 단계; 및상기 사용자 장치에서 상기 제2 합성 영상을 표시하는 단계를 더 포함하는, 합성 영상 제공 방법."}
{"patent_id": "10-2023-0010005", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제2 합성 영상을 생성하는 단계는:상기 제2 선수 영상의 상기 복수의 프레임의 투명도 또는 색상을 변경하는 단계; 및상기 투명도 또는 색상이 변경된 상기 복수의 프레임을 상기 제1 합성 영상 상에 오버레이하여 제2 합성 영상을생성하는 단계;를 포함하는, 합성 영상 제공 방법."}
{"patent_id": "10-2023-0010005", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 방법은:상기 사용자 장치에서, 드론의 비행 높이를 특정하는 제1 값, 상기 드론의 제1 센서와 제1선수의 표면 상의 제1지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수의 정면 방향을 기준으로 상기 제1 지점으로부터 상기드론의 상기 제1 센서를 향하는 방향의 각변위를 특정하는 제3 값을 입력받고, 상기 서버 및 상기 드론에 상기공개특허 10-2024-0029712-3-제1 값, 상기 제2 값, 및 상기 제3 값을 전송하는 단계 - 상기 제1 지점은 상기 제1 선수의 표면 상에서 상기드론과의 거리가 가장 짧은 지점이고, 상기 제3 값은 0도 이상 360도 미만의 값을 가지고, 상기 제1 센서는 제1거리 센서 및 카메라를 포함함 -; 상기 드론이, 상기 제1 선수가 상기 제1 운동을 시작하기 전, 상기 드론에 포함된 적어도 하나의 센서의 측정값및 상기 카메라에 의하여 획득된 제2 영상 데이터를 포함하는 제2 수집 데이터를 적어도 하나 획득하는 단계; 상기 적어도 하나의 제2 수집 데이터를 분석하여, 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하는 단계;-상기 드론이, 상기 제1 선수가 상기 제1 운동을 수행하는 동안, 상기 제1 선수의 정면 방향으로 비행하면서 상기 드론에 포함된 적어도 하나의 센서의 측정값 및 상기 카메라에 의하여 획득된 상기 제1 영상 데이터를 포함하는 제1 수집 데이터를 적어도 하나 획득하는 단계; 및상기 적어도 하나의 제1 수집 데이터를 분석하여, 상기 제1 선수가 상기 제1 운동을 수행하는 동안, 상기 제1선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한적어도 하나의 명령 데이터를 도출하는 단계;를 더 포함하고,상기 제1 운동 영상을 획득하는 단계는, 상기 적어도 하나의 제1 수집 데이터에 기초하여, 상기 적어도 하나의제1 수집 데이터에 포함되는 제1 영상 데이터 중 상기 드론이 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에서 비행한 시간에 대응되는 부분을 추출하여 상기 제1 선수의 운동 영상으로서 저장하는 단계를포함하는, 합성 영상 제공 방법."}
{"patent_id": "10-2023-0010005", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 방법은, 상기 제1 선수가 운동을 시작하기 전에:0도 이상 360도 미만의 값을 갖는, 미리 결정된 복수의 기설정 각도에서 촬영된 복수의 인체 이미지를 포함하는인체 이미지 데이터베이스를 저장하는 단계;상기 인체 이미지 데이터베이스에 포함된 복수의 인체 이미지 각각으로부터 관절점 정보를 추출하는 단계; 및상기 복수의 인체 이미지가 촬영된 각도 및 상기 복수의 인체 이미지로부터 추출된 관절점 정보를 학습함으로써제1 인공지능 모델을 생성하는 단계;를 포함하고,상기 적어도 하나의 제2 수집 데이터를 분석하여, 상기 제1 선수가 상기 제1 운동을 수행하는 동안 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하는 단계는:상기 제1 선수가 상기 제2 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지, 상기 드론으로 하여금 제자리에서 지면과 수직인 회전축을 중심으로 회전하도록 하는 명령 데이터를 도출하는 단계;상기 제1 선수가 상기 제2 영상 데이터에 대응되는 영상의 중앙에 위치하는 것으로 확인되면, 상기 제1 거리 센서의 측정값이 상기 제2 값에 대응될 때까지, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제2 값보다작은 경우 상기 드론으로 하여금 상기 제1 거리 센서가 향하는 제1 방향과 반대 방향으로 이동하도록 하는 명령데이터를 도출하고, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제2 값보다 큰 경우 상기 드론으로 하여금 상기 제1 방향으로 이동하도록 하는 명령 데이터를 도출하는 단계;상기 제1 거리 센서의 측정값이 상기 제2 값에 대응된다고 확인되면, 상기 복수의 기설정 각도 중 상기 제3 값보다 작으면서 가장 큰 값을 갖는 제1 각도를 확인하는 단계;상기 제1 인공지능 모델에 기초하여 상기 제1 각도에서 촬영된 것으로 확인되는 이미지에 대응되는 상기 제2 영상 데이터가 수신될 때까지, 상기 드론으로 하여금 상기 제1 선수의 정면 방향을 기준으로 상기 제1 지점으로부터 상기 드론을 향하는 벡터의 각변위를 증가시키도록 하는 각도 증가 명령을 명령 데이터로서 도출하는 단계 -상기 각도 증가 명령은 상기 제1 방향과 수직인 방향으로 미리 설정된 제1 거리만큼 드론을 이동시키는 명령,공개특허 10-2024-0029712-4-상기 제1 선수가 상기 제2 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지 상기 드론으로 하여금 제자리에서 지면과 평행한 평면 상에서 회전하도록 하는 명령, 및 상기 제1 거리 센서의 측정값이 상기 제2 값에 대응될 때까지 상기 드론을 상기 제1 방향으로 이동시키는 명령을 포함함 -; 및상기 드론에 포함되는 IMU 센서가 나타내는 각도 값이 상기 제3 값에서 상기 제1 각도를 뺀 값이 될 때까지, 상기 각도 증가 명령을 명령 데이터로서 도출하는 단계를 포함하는, 합성 영상 제공 방법."}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 다양한 실시예에 따른, 사용자 장치, 서버, 및 드론을 포함하는, 운동 영상 획득 시스템에서 수행되는 운동 영상 획득 방법은, 상기 사용자 장치에서 사용자로부터, 상기 드론의 비행 높이를 특정하는 제1 값, 상기 드론의 제1 센서와 제1 선수의 표면 상의 제1 지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수의 정면 방 (뒷면에 계속)"}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 드론을 이용한 운동 영상 획득 시스템 및 동 시스템에서 운동 영상을 획득하는 방법에 관련된다. 본 발명은 운동 영상 획득 시스템에서 획득된 운동 영상에 기초하여 운동 데이터를 획득하는 방법에 관련된다. 본 발명은 운동 영상에 기초한 합성 영상 제공 방법에 관련된다. 본 발명에 따른, 드론을 이용한 운동 영상 획득 시스템, 운동 데이터를 획득하는 방법, 및 합성 영상 제공 방법은 특히 운동 훈련에 있어서 자세 개선 및 퍼포 먼스 향상을 목적으로 이용될 수 있다."}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "국민 소득의 증대로 운동 및 스포츠에 대한 관심이 계속해서 증가하고 있다. 달리기, 높이뛰기, 멀리뛰기 등 육 상 종목, 근육량을 증대시키기 위한 웨이트 트레이닝, 축구 및 배드민턴 등 구기 종목 등 다양한 운동이 있고, 이러한 다양한 운동 종목들은 특정한 동작을 반복 수행함으로써 바른 자세 또는 동작을 습득하고, 습득한 자세 또는 동작을 실전에 적용시키는 것이 높은 퍼포먼스를 내는 데 도움이 된다는 점에서 공통된다. 전문적인 운동 선수 또는 운동 능력 향상을 원하는 일반인의 훈련을 위하여 운동 영상을 획득하는 다양한 방법 이 개시되어 있다. 가장 기초적인 방법은 고정된 위치에 카메라를 설치하고 카메라 앵글 내에서 운동하는 모습 을 촬영하는 것이다. 큰 규모의 국제 체육 대회나 프로 리그에서는 이동하는 운동 선수를 따라 전문 촬영 기사 가 카메라를 들고 함께 이동하면서 촬영하거나, 이동하는 운동 선수를 따라 카메라를 이동시키기 위한 트랙이 이용되기도 한다. 또한, 전문적인 운동 선수 또는 운동 능력 향상을 원하는 일반인의 훈련을 위하여 훈련 과정에서의 운동 데이터 를 획득하는 다양한 방법이 개시되어 있다. 가장 전통적인 방법은 훈련이 일어나는 동안 경험이 많은 코치가 운 동 선수의 움직임을 관찰하고 자신의 경험에 입각하여 더 바람직한 자세가 무엇인지를 조언하는 것이다. 운동 영상이 획득된 경우, 경험이 많은 코치가 획득된 영상을 모니터링하여 영상에 나타난 선수의 움직임을 분석하고 평가하는 방법도 이용된다."}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "운동 영상을 획득하기 위한 종래의 방법 중 고정된 위치에 카메라를 설치하고 카메라 앵글 내에서 운동하는 모 습을 촬영하는 방법은 카메라 위치는 고정되어 있는 반면, 선수의 위치는 이동될 수 있으므로, 선수의 위치가 카메라 앵글을 벗어난 동안에는 선수의 움직임을 기록하기 어렵고, 카메라의 촬영 방향과 선수의 몸 방향 사이 의 각도가 변화할 수 있으므로 동일한 각도에서 일관적으로 촬영한 영상을 획득하기 어렵다. 카메라가 움직이기 위한 트랙을 이용하는 경우 에도, 선수가 트랙의 길이 방향과 평행한 방향으로 이동하지 않는 이상 동일한 각도 에서 일관적으로 촬영한 영상을 획득하기 어렵다. 운동 영상을 획득하기 위한 종래의 방법 중 전문 촬영 기사를 활용하는 경우 촬영 기사의 인건비 문제로 높은 비용이 소모되며, 촬영 기사의 역량에 따라 동일한 각도에서 일 관적으로 촬영한 영상을 획득하기 어려울 수 있다. 훈련 과정에서의 운동 데이터를 획득하는 종래의 방법은 코치 등 전문가의 육안으로 일어나는 관찰에 의존하므 로, 관찰 자체의 정밀도에 한계가 있어 미세한 자세 차이가 퍼포먼스에 영향을 주는 현실에서 효율적인 자세 개 선을 기대하기 어렵다. 본 발명의 목적은 드론을 이용한 운동 영상 획득 시스템 및 드론을 이용한 운동 영상 획득 방법을 제공하고, 드 론을 이용하여 획득된 스포츠 훈련 영상에 기초한 운동 데이터를 제공하는 방법을 제공하고, 드론을 이용하여획득된 스포츠 훈련 영상에 기초한 합성 영상을 제공하는 방법을 제공하는 것이다."}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일실시예에 따른, 사용자 장치, 서버, 및 드론을 포함하는, 운동 영상 획득 시스템에 있어서, 상기 사용자 장치는: 사용자로부터, 상기 드론의 비행 높이를 특정하는 제1 값, 상기 드론의 제1 센서와 제1 선수의 표면 상의 제1 지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수의 정면 방향을 기준으로 상기 제1 지점 으로부터 상기 드론의 상기 제1 센서를 향하는 방향의 각변위를 특정하는 제3 값을 입력받고 - 상기 제1 지점은 상기 제1 선수의 표면 상에서 상기 드론과의 거리가 가장 짧은 지점이고, 상기 제3 값은 0도 이상 360도 미만의 값을 가지고, 상기 제1 센서는 제1 거리 센서 및 카메라를 포함함 -, 상기 서버 및 상기 드론에 상기 제1 값, 상기 제2 값, 및 상기 제3 값을 전송하도록 구성되고; 상기 드론은: 상기 제1 값과 동일한 높이로 비행하면서, 상기 사용자 장치에 상기 제1 값과 동일한 높이에 있다는 정보를 송신하고; 상기 드론의 적어도 하나의 센서의 측정값 및 상기 제1 센서에 포함된 카메라에 의하여 획득된 영상 데이터를 적어도 하나의 수집 데이터로서 상기 사용자 장치에 송신하도록 구성되고 - 상기 사용자 장치는 상기 적어도 하나의 수집 데이터를 상기 서버에 송신 하고, 상기 적어도 하나의 센서는 제1 센서, 방사형으로 배치된 복수의 거리 센서, 및 IMU 센서를 포함함 -; 상 기 서버는: 상기 적어도 하나의 수집 데이터를 분석하여 상기 제2 값 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하여 상기 사용자 장치에 송신하고 - 상기 사용자 장 치는 상기 적어도 하나의 명령 데이터를 상기 드론에 송신함 -; 상기 제2 값 및 상기 제3 값에 대응되는 위치에 상기 드론이 위치한다고 확인되는 것에 응답하여, 초기 위치 설정 완료 신호를 상기 사용자 장치에 송신하도록 구성되고 - 상기 사용자 장치는 상기 초기 위치 설정 완료 신호를 상기 드론에 송신함 -; 상기 드론은 상기 초 기 위치 설정 완료 신호가 수신되는 것에 응답하여 스피커를 통하여 미리 설정된 소리를 출력하고, 상기 제1 선 수가 운동하는 동안 상기 제1 선수의 정면 방향으로 비행하면서 상기 적어도 하나의 수집 데이터를 상기 사용자 장치에 송신하도록 구성되고 - 상기 사용자 장치는 상기 적어도 하나의 수집 데이터를 상기 서버에 송신함 -, 상기 서버는: 상기 적어도 하나의 수집 데이터를 분석하여, 상기 제1 선수가 운동하는 동안 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하여 상기 사용자 장치에 송신하고 - 상기 사용자 장치는 상기 적어도 하나의 명령 데이터를 상기 드론에 송신함 -; 상기 적어도 하나의 수집 데이터에 기초하여, 상기 적어도 하나의 수집 데이터 에 포함되는 영상 데이터 중 상기 드론이 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에서 비행 한 시간에 대응되는 부분을 추출하여 운동 영상으로서 저장하도록 구성된다. 본 발명의 일실시예에 따른 운동 데이터 제공 방법은, 서버에 의하여, 드론으로 하여금 정지한 제1 선수 주위를 회전하도록 하는 적어도 하나의 명령 데이터를 사용자 장치에 송신하고, 상기 사용자 장치는 상기 적어도 하나 의 명령 데이터를 상기 드론에 송신하는 단계; 상기 드론이 정지한 상기 제1 선수 주위를 회전하면서 상기 드론 에 포함된 적어도 하나의 센서의 측정값 및 상기 드론에 포함된 카메라에 의하여 획득된 영상 데이터를 포함하 는 제1 수집 데이터를 적어도 하나 생성하여 상기 사용자 장치에 송신하고, 상기 사용자 장치는 적어도 하나의 제1 수집 데이터를 상기 서버에 송신하는 단계; 상기 서버가, 상기 적어도 하나의 제1 수집 데이터에 기초하여 상기 제1 선수의 3차원 인체 모델을 생성하는 단계; 상기 사용자 장치에서, 상기 드론의 비행 높이를 특정하는 제1 값, 상기 드론의 제1 센서와 제1 선수의 표면 상의 제1 지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수의 정면 방향을 기준으로 상기 제1 지점으로부터 상기 드론의 상기 제1 센서를 향하는 방향의 각변위도를 특정하는 제3 값을 입력받고, 상기 서버 및 상기 드론에 상기 제1 값, 상기 제2 값, 및 상기 제3 값을 전송하는 단계 - 상기 제1 지점은 상기 제1 선수의 표면 상에서 상기 드론과의 거리가 가장 짧은 지점이고, 상기 제3 값 은 0도 이상 360도 미만의 값을 가지고, 상기 제1 센서는 제1 거리 센서 및 상기 카메라를 포함함 -; 상기 드론 이, 상기 제1 선수가 운동하는 동안 상기 제1 선수의 정면 방향으로 비행하면서 상기 드론에 포함된 적어도 하 나의 센서의 측정값 및 상기 카메라에 의하여 획득된 영상 데이터를 포함하는 제2 수집 데이터를 적어도 하나 생성하여 상기 사용자 장치에 송신하고, 상기 사용자 장치가 적어도 하나의 제2 수집 데이터를 상기 서버에 송 신하는 단계; 상기 서버에 의하여: 상기 적어도 하나의 제2 수집 데이터를 분석하여, 상기 제1 선수가 운동하 는 동안 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하여 상기 사용자 장치에 송신하는 단계 - 상기 사용자 장치 는 상기 적어도 하나의 명령 데이터를 상기 드론에 송신함 -; 상기 적어도 하나의 제2 수집 데이터에 기초하여, 상기 적어도 하나의 제2 수집 데이터에 포함되는 영상 데이터 중 상기 드론이 상기 제1 값, 상기 제2 값, 및 상 기 제3 값에 대응되는 위치에서 비행한 시간에 대응되는 부분을 추출하여 운동 영상으로서 저장하는 단계; 상기 운동 영상으로부터 관절점을 추출하는 단계; 및 상기 운동 영상으로부터 추출된 관절점 및 상기 제1 선수의 3차원 인체 모델에 기초하여, 상기 제1 선수의 관절 가동 범위, 관절 가동 속도, 및 주기적으로 반복되는 동작에서 상기 관절 가동 범위 및 상기 관절 가동 속도의 주기별 변화를 나타내는 운동 데이터를 확인하는 단계, 상기 사 용자 장치에서 상기 운동 데이터를 표시하는 단계를 포함한다. 본 발명의 일실시예에 따른, 스포츠 훈련 영상에 기초한 합성 영상 제공 방법은, 서버에 의하여: 제1 선수의 운 동 영상을 획득하는 단계; 상기 제1 선수의 운동 영상으로부터 상기 제1 선수의 운동 데이터를 확인하는 단계; 상기 제1 선수의 운동 영상을 운동 동작의 주기별로 파싱하여 상기 제1 선수에 대응하는 복수의 부분 운동 영상 을 획득하는 단계; 상기 제1 선수에 대응하는 상기 복수의 부분 운동 영상 중 제1 부분 운동 영상과 제2 부분 운동 영상의 투명도를 증가시키고, 투명도를 증가시킨 상기 제1 부분 운동 영상에 투명도를 증가시킨 상기 제2 부분 운동 영상, 상기 제1 부분 운동 영상에 대응되는 운동 데이터, 및 상기 제2 부분 운동 영상에 대응되는 운 동 데이터를 오버레이하여 제1 합성 영상을 생성하는 단계 - 상기 운동 데이터는 상기 제1 선수의 관절 가동 범 위를 포함함 -; 및 상기 제1 합성 영상을 사용자 장치에 송신하는 단계, 및 상기 사용자 장치에서 상기 제1 합 성 영상을 표시하는 단계를 포함한다. 본 발명의 일실시예에 따른, 스포츠 훈련 영상에 기초한 합성 영상 제공 방법은, 서버에 의하여: 제1 선수가 제 1 운동을 수행하는 동안 상기 제1 선수의 정면 방향으로 비행하는 드론에 의하여 촬영된 제1 영상 데이터에 기 초하여, 제1 운동 영상을 획득하는 단계; 상기 제1 운동 영상으로부터 배경 영역과 제1 선수 영역을 분리하여 제1 배경 영상 및 제1 선수 영상을 획득하는 단계; 상기 드론의 비행 속도 및 상기 제1 영상 데이터가 촬영된 시간 정보에 기초하여 상기 제1배경 영상의 복수의 프레임을 합성하여 배경 이미지를 생성하는 단계; 상기 드론 의 비행 속도 및 상기 제1 영상 데이터가 촬영된 시간 정보에 기초하여, 상기 제1 선수 영상의 복수의 프레임을 상기 배경 이미지 상에 오버레이하여 제1 합성 영상을 생성하는 단계; 및 상기 제1 합성 영상을 사용자 장치에 송신하는 단계, 및 상기 사용자 장치에서 상기 제1 합성 영상을 표시하는 단계를 포함한다."}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일실시예에 따른, 드론을 이용한 운동 영상 획득 시스템은 피사체인 운동 선수를 기준으로 한 원기둥 좌표 상에서 드론의 위치가 미리 설정된 위치에 있는 동안 드론에 의하여 획득된 영상을 운동 영상으로서 저장 함으로써, 피사체에 대하여 일정한 상대 위치 및 각도에서 획득된 영상을 제공할 수 있다. 카메라의 피사체에 대한 상대적인 위치 및 각도가 일정하게 유지되지 않은 상태에서 획득된 영상으로는 영상 내 피사체의 위치와 뷰 각도의 변화 때문에, 피사체의 특정 관절의 각도의 변화와 같은, 운동 자세를 구성하는 수치인 운동 데이터 를 정확하게 특정할 수 없다. 반면, 본 발명의 일실시예에 따른 드론을 이용한 운동 영상 획득 시스템은, 피사 체를 기준으로 한 원기둥좌표 상의 위치가 일정한 카메라에 의하여 영상을 확보하는 것을 가능하게 한다. 카메 라의 피사체를 기준으로 한 원기둥좌표 상의 위치가 일정한 상태에서 획득된 영상의 분석을 통해 관절 각도 등 정량적인 데이터를 높은 정확도로 추출할 수 있으므로, 본 발명의 일실시예에 따른 드론을 이용한 운동 영상 획 득 시스템은 잘못된 자세를 정밀하고 정확하게 파악하는 것을 돕는다. 본 발명의 일실시예에 따른, 드론을 이용하여 획득된 스포츠 훈련 영상에 기초한 운동 데이터 제공 방법은 카메 라의 피사체를 기준으로 한 원기둥좌표 상의 위치가 일정한 상태에서 획득된 영상의 분석을 통해 관절 각도 등 정량적인 데이터를 높은 정확도로 추출할 수 있으므로, 잘못된 운동 자세를 정밀하고 정확하게 파악하는 것을 돕는다. 본 발명의 일실시예에 따른, 스포츠 훈련 영상에 기초한 합성 영상 제공 방법은 카메라의 피사체를 기준으로 한 원기둥좌표 상의 위치가 일정한 상태에서 획득된 영상을 합성하여 이미지를 제공한다. 카메라의 피사체에 대한 상대적인 위치 및 각도가 일정하게 유지되지 않은 상태에서 획득된 영상 내의 피사체 모습들을 합성하는 경우 영상 내 피사체의 위치와 뷰 각도의 변화 때문에 합성 영상을 통하여도 각자의 피사체의 특정 관절의 각도의 변 화와 같은, 운동 자세를 구성하는 수치인 운동 데이터를 정확하게 특정할 수 없으므로 정확한 자세 변화를 판단 할 수 없다. 반면, 본 발명의 일실시예에 따른, 스포츠 훈련 영상에 기초한 합성 영상 제공 방법은 카메라의 피 사체를 기준으로 한 원기둥좌표 상의 위치가 일정한 상태에서 획득된 영상을 합성하여 이미지를 제공하므로 자 세 변화를 한 눈에 확인하고 직접 비교할 수 있게 함으로써 효율적인 자세 개선을 가능하게 할 수 있다."}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 \"포함한다(comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 본 명세서의 다양한 실시예들 및 이에 사용된 용어 들은 본 명세서에 기재된 기술적 특징들을 특정한 실시예들로 한정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 명세서에서, \"A 또 는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제1\", \"제2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제1) 구성요소가 다른(예: 제 2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없이, \" 연결된다\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로(예: 유선으로), 무선으로, 또는 제 3 구성요소를 통하 여 연결될 수 있다는 것을 의미한다. 본 명세서의 다양한 실시예들은 기기(machine)의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어로서 구현될 수 있다. 예를 들면, 기기의 프로세서는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실 행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영 되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매 체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal) (예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장 되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일실시예에 따르면, 본 명세서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 단말 들(예: 스마트 폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있으며, 복수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시 예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 단계들이 생략되거나, 또는 하나 이상 의 다른 구성요소들 또는 단계들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 단계들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 단 계들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 단계들이 추가될 수 있다. 도 1a는 본 발명의 다양한 실시예에 따른 운동 영상 획득 시스템을 도시한다. 운동 영상 획득 시스템은 드론, 사용자 장치, 및 서버를 포함할 수 있다. 드론은 비행하면서 운동을 수행하는 운동 선수를 촬영할 수 있다. 여기서 운동 선수는 전문적인 운동 선수뿐 아니라 운동 영상 획득을 원하는 모든 사람 이 될 수 있다. 드론은 복수의 거리 측정 센서, IMU 센서, 및 카메라를 포함할 수 있다. 드론의 거 리 측정 센서는 드론의 외측면을 향하여 방사형으로 배치된 거리 측정 센서, 지면을 향하여 배치된 거리 측정 센서, 및 드론의 상단을 향하여 배치된 거리 측정 센서를 포함할 수 있다. 드론의 외측면을 향하여 방사형으로 배치된 거리 측정 센서들의 예시는 도 5a를 참조하여 후술한다. 드론의 거리 측정 센서는 초음파 센서, 적 외선 센서, 레이더, PSD 센서, LiDAR, ToF 센서, 및 스테레오 카메라 중 적어도 하나일 수 있다. 드론의 IMU 센서는 가속도 센서, 자이로 센서, 및 지자기 센서를 포함할 수 있다. IMU 센서에 포함되는 가속도 센서는 압전형, 압전 저항형, 정전용량형, 및 열형 중 적어도 하나일 수 있다. IMU 센서에 포함되는 자이로 센서는, 예를 들어, MEMS 형일 수 있다. IMU 센서에 포함되는 지자기 센서는 홀 효과, 자기저항효과, 및 자기임피던스 중 적어도 하나를 이용하는 지자기 센서일 수 있다. 드론은 비행을 위한 복수의 모터 및 통신 모듈을 포함 할 수 있다. 드론은 상술한 바와 같은 적어도 하나의 센서의 측정값 및 카메라에 의하여 획득된 영상 데이터를 수집 데 이터로서 사용자 장치에 송신할 수 있다. 또한, 드론은 서버에 의하여 생성된 명령 데이터를 사용자 장치로부터 수신하고, 명령 데이터에 따라 비행하기 위하여 복수의 모터를 제어할 수 있다. 사용자 장치는 운동 선수 또는 코치가 사용하는 장치로서, 스마트폰, 태블릿 PC, 또는 웨어러블 디바이스 중 적어도 하나를 포함할 수 있다. 사용자 장치는 드론에 의하여 생성된 수집 데이터를 서버에 전달하고, 서버에 의하여 생성된 명령 데이터를 드론에 전달할 수 있다. 서버는 드론에 의하여 생성된 수집 데이터에 기초하여 드론의 비행을 제어하기 위한 명령 데이 터를 생성할 수 있다. 또한, 서버는 드론에 의하여 생성된 수집 데이터에 기초하여 운동 영상을 생성 하고, 운동 영상에 기초하여 운동 데이터를 확인하고, 운동 영상에 기초하여 다양한 합성 영상을 생성할 수 있 다. 도 1b는 본 발명의 다양한 실시예에 따른 운동 영상 획득 시스템에 포함되는 서버의 구성을 도시한다. 도 1b를 참조하면, 서버는 통신 회로, 프로세서, 및 메모리를 포함할 수 있다. 통신 회로는다른 전자 장치에 정보를 송신하거나 다른 전자 장치로부터 정보를 수신할 수 있고, 통신 회로가 지원하는 통신의 종류는 제한되지 않는다. 프로세서는 통신 회로를 통하여 수신된 데이터 및/또는 메모리에 저장된 데이터에 기초하여 연 산을 수행하고, 연산의 결과의 적어도 일부를 통신 회로를 통하여 다른 전자 장치에 송신하거나, 메모리 에 저장할 수 있다. 프로세서는 데이터 학습부 및 데이터 인식부를 포함할 수 있다. 데이터 학습부는 운동 영 상의 한 프레임 이미지로부터 추출된 관절점 정보를 입력받고 해당 이미지가 촬영된 각도를 출력하는 인공 지능 모델을 생성할 수 있다. 데이터 인식부는 데이터를 전처리하고, 전처리된 데이터를 데이터 학습부에 학습을 위하여 제공할 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능을 위한 전용 하드웨어 칩 형태로 구현 되거나, 기존의 범용 프로세서(예를 들어, AP 또는 CPU) 또는 그래픽 전용 프로세서의 일부로서 구현될 수도 있 다. 다양한 실시예에 따라서, 도 2에서 데이터 학습부 및 데이터 인식부가 서버에 포함된 것으로 표 현된 것과 달리, 데이터 학습부 및 데이터 인식부는 별개의 전자 장치에 각각 탑재될 수 있다. 이 경우, 데이터 학습부 및 데이터 인식부는 유선 또는 무선으로 서로 연결되어, 데이터 학습부(13 3)에서 생성된 모델 정보가 데이터 인식부에 제공되거나, 데이터 인식부에 입력된 데이터가 추가 학 습 데이터로서 데이터 학습부에 제공될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 이 경우, 소 프트웨어 모듈은 컴퓨터로 판독 가능한 비일시적 기록 매체에 저장될 수 있다. 소프트웨어 모듈의 적어도 일부 는 OS(operating system)에 의해 제공되거나, 소정의 어플리케이션에 의하여 제공될 수 있다. 도 2a 및 도 2b는 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 운동 영상 획득 방법 을 도시한다. 210 단계에서, 사용자 장치는 선수에 대한 드론의 상대적인 위치를 특정하는 제1 값, 제2 값, 및 제3 값을 입력받을 수 있다. 도 2d를 참조하면, 제1 값은 드론(200d)의 비행 높이(h)를 특정하는 값일 수 있다. 드론(200d)의 비행 높이 (h)는 선수(210d)가 운동하고 있는 지면을 기준으로 한 드론(200d)의 높이이다. 드론의 지면을 향하여 배치된 거리 측정 센서가 드론(200d)의 비행 높이(h)를 측정하여 수집 데이터의 일부로서 포함시킬 수 있다. 도 2c를 참조하면, 제2 값은 드론(200c)의 제1 센서와 선수(210c)의 표면 상의 제1 지점 사이의 거리(r)를 특정 하는 값일 수 있다. 드론(200c)의 제1 센서는 드론의 외측면을 향하여 배치된 거리 센서 및 카메라를 포함할 수 있다. 선수(210c)의 표면 상의 제1 지점이란, 선수(210c)의 표면 상의 지점들 중 드론(200c)의 제1 센서와의 거리가 가장 짧은 지점을 의미한다. 드론(200c)의 제1 센서에 포함된 거리 측정 센서가 제1 센서와 선수(210 c)의 표면 상의 제1 지점 사이의 거리(r, 220c)를 측정하여 수집 데이터의 일부로서 포함시킬 수 있다. 도 2c를 다시 참조하면, 제3 값은 선수(210c)의 정면 방향(230c)을 기준으로 제1 지점으로부터 드론(200c)의 제 1 센서를 향하는 방향(220c)의 각변위(θ)를 특정하는 값일 수 있다. 서버는 도 3b를 참조하여 후술할 바 와 같이, IMU 센서의 측정값 및 카메라에 의하여 획득된 영상 데이터에 대한 인공지능 모델에 의한 분석 결과에 따라 선수(210c)의 정면 방향(230c)을 기준으로 제1 지점으로부터 드론(200c)의 제1 센서를 향하는 방향(220c) 의 각변위(θ)를 결정할 수 있고, 각변위(θ)와 제3 값의 비교 결과에 따라 드론(200c)을 제어할 수 있다. 다 양한 실시예에 따라서, 각변위(θ)는 선수(210c) 및 드론(200c)을 수직으로 내려다보았을 때 반시계 방향이 양 의 값을 가지고, 시계 방향이 음의 값을 가지는 것으로 정의될 수 있다. 다양한 실시예에 따라서, 각변위(θ) 는 0도 이상 360도 미만의 값으로 특정될 수 있다. 예를 들어서, -10도의 각변위는 350도와 동일하다고 정의될 수 있다. 210 단계가 이루어진 후, 사용자 장치는 드론 및 서버에 각각 제1 값, 제2 값, 및 제3 값을 전 송할 수 있다. 220 단계에서, 드론은 적어도 하나의 모터의 추력을 조절함으로써 제1 값과 동일한 높이로 비행하고, 지면 을 향하여 배치된 거리 측정 센서에 의하여 비행 높이(h)를 측정하여 제1 값과 동일한 높이에 있다고 확인되면,사용자 장치에 드론이 제1 값과 동일한 높이에 있다는 정보를 송신할 수 있다. 사용자 장치는 서버에 드론이 제1 값과 동일한 높이에 있다는 정보를 송신할 수 있고, 따라서 서버는 드론 이 제1 값과 동일한 높이에 있다는 것을 확인할 수 있다. 231 단계에서, 서버는 드론에 의하여 생성된 수집 데이터를 획득할 수 있다. 수집 데이터는 드론에 포함된 적어도 하나의 센서의 측정값 및 제1 센서에 포함된 카메라에 의하여 획득된 영상 데이터를 포함할 수 있다. 드론은 수집 데이터를 생성하여 사용자 장치에 송신하고, 사용자 장치는 수집 데이터를 서버에 송신할 수 있다. 232 단계에서, 서버는 수집 데이터를 분석하여 드론이 제2 값 및 제3 값에 대응되는 위치에 있는지 여부를 확인할 수 있다. 232 단계에서 드론이 제2 값 및 제3 값에 대응되는 위치에 있지 않다고 확인되는 경우, 서버는 233 단계에서 수집 데이터를 분석하여 제2 값 및 제3 값에 대응되는 위치에 드론을 위치시키 기 위한 적어도 하나의 명령 데이터를 도출하여 사용자 장치에 송신할 수 있다. 사용자 장치는 233 단계의 명령 데이터를 드론에 송신할 수 있다. 서버가 232 단계에서 드론이 제2 값 및 제3 값에 대응되는 위치에 있는지 여부를 확인하고, 233 단계에서 명령 데이터를 도출하는 상세한 방법은 도 3a 및 도 3b 를 참조하여 설명한다. 231 단계 내지 233단계는 드론이 제2 값 및 제3 값에 대응되는 위치에 있다고 확인 될 때까지 반복될 수 있다. 또한, 231 단계 내지 233단계는 선수가 운동을 시작하기 전, 시작 위치에 서 있을 때 수행될 수 있다. 다양한 실시예에 따라서, 231 단계 내지 233 단계에 포함되는 적어도 하나의 연산은 드론에서 수행될 수 있다. 예를 들어, 드론은 수집 데이터를 획득한 후, 드론에 포함된 프로세서에 의하여 232 단계를 수행할 수 있다. 그 후, 드론의 프로세서는 233 단계에서 제2 값 및 제3 값에 대응되는 위치로 이동하기 위한 명령 데이터를 도출하고, 도출된 명령 데이터를 이용하여 드론에 포함된 적어도 하나의 모터를 제어 할 수 있다. 도 3a 및 도 3b는 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 방법을 도시한다. 310 단계에서, 서버는 복수의 인체 이미지가 촬영된 각도 및 복수의 인체 이미지로부터 추출된 관절점 정보를 학습함으로써 제1 인공지능 모델을 생성할 수 있다. 구체적으로, 서버는 0도 이상 360도 미만의 값을 갖는, 미리 결정된 복수의 기설정 각도에서 촬영된 복수의 인체 이미지를 포함하는 인체 이미지 데이터베이스를 저장할 수 있다. 310 단계는 선수가 운동을 수행하기 전에 수행되는 단계이다. 인체 이미지 데이터베이스는 복수의 인체 이미지 및 각각의 이미지가 촬영된 각도를 연관시켜 저장할 수 있다. 복수의 기설정 각도는, 예를 들어, 도 4a에서 도시된 바와 같이, 0도, 90도, 180도, 및 270도일 수 있다. 그 후, 서버는 인체 이미지 데이터베이스에 포함된 복수의 인체 이미지 각각으로부터 관절점 정보를 추출할 수 있다. 그 후, 서버 복 수의 인체 이미지가 촬영된 각도 및 복수의 인체 이미지로부터 추출된 관절점 정보를 학습함으로써 제1 인공지 능 모델을 생성할 수 있다. 제1 인공지능 모델은 도 4b에 도시된 바와 같이, 이미지의 관절점 정보를 입력받아 해당 이미지가 촬영된 각도를 출력하는 인공지능 모델일 수 있다. 제1 인공지능 모델이 복수의 기설정 각도에 서 촬영된 이미지들을 학습하였으므로, 제1 인공지능 모델은 입력 이미지가 0도, 90도, 180도, 및 270도 중 한 각도에서 촬영된 이미지일 때, 해당 이미지가 촬영된 각도를 높은 정확도로 출력해낼 수 있다. 제1 인공지능 모 델을 생성하기 위한 학습 방법은 제한되지 않는다. 예를 들어, 제1 인공지능 모델은 다양한 머신 러닝 기법에 의하여 생성될 수 있다. 예를 들어, RNN(Recurrent Neural Network), CNN(Convolution Neural Network), ANN(Artificial Neural Network), 및 트랜스포머 모델 중 적어도 하나가 제1 인공지능 모델의 생성을 위한 학습 에 이용될 수 있다. 321 단계에서, 서버는 수집 데이터를 획득할 수 있다. 322 단계에서, 서버는 수집 데이터에 포함되는 영상 데이터를 분석하여, 제1 선수가 영상 데이터에 대응되는 영상의 중앙에 위치하는지 여부를 확인할 수 있다. 도 5a를 참조하면, 드론은 방사형으로 배치되고 드론의 측면을 향하여 거리를 측정하는 복수의 거리 센서(511, 512, 513, 514)를 포함할 수 있고, 복수의 거리 센서(511, 512, 513, 514)는 드론 몸체로부터 바깥 쪽 방향(521, 522, 523, 524)에 존재하는 외부 물체까지의 거리를 측정할 수 있다. 복수의 거리 센서(511, 512, 513, 514) 중 제1 센서는 카메라의 촬영 방향과 동일한 방향을 향하고 있다. 322 단계로 다시 돌아 와서, 제1 선수가 영상 데이터에 대응되는 영상의 중앙에 위치한다고 확인되는 것은, 제1 센서가 제1 선수 를 향하고 있다는 것을 의미할 수 있다. 322 단계에서 제1 선수가 영상 데이터에 대응되는 영상의 중앙에 위치하지 않는다고 확인되는 경우, 서버 는 323 단계에서 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지, 드론으로 하여금 제자리에서 지면과 수직인 회전축을 중심으로 회전하도록 하는 명령 데이터를 사용자 장치에 송신할 수 있다. 사용자 장치에 송신된 명령 데이터는 드론에 송신될 수 있다. 도 5b 및 도 5c는 본 발명의 다양한 실 시예에 따른, 드론이 제자리에서 회전하는 동작을 도시한다. 도 5b와 같이, 드론(500b)은 제1 센서가 향하는 방 향(521b)이 선수가 위치한 방향과 상이하게 위치할 수 있다. 드론으로 하여금 제자리에서 지면과 수직인 회전축을 중심으로 회전하도록 하는 명령 데이터를 수신한 드론은 위치는 그대로 있고 제자리에서 지면과 수직 인 회전축을 중심으로 회전하면서 계속해서 수집 데이터를 송신(321 단계)한다. 즉, 제1 센서가 선수를 향할 때까지 321 단계 내지 323 단계는 반복되고, 322 단계에서 제1 선수가 영상 데이터에 대응되는 영상의 중 앙에 위치했다고 확인되었을 때, 드론과 제1 선수의 위치관계가 도 5c에 도시되어 있다. 도 5c를 참조하면, 드 론(500c)은 드론(500b)과 비교하여 위치는 그대로 있으면서 지면과 수직인 회전축을 중심으로 회전하기만 하였 고, 제1 센서가 향하는 방향(521c)이 선수가 위치한 방향임을 알 수 있다. 다양한 실시예에 따라서, 321 단계 내지 323 단계에 포함되는 적어도 하나의 연산은 드론에서 수행될 수 있다. 예를 들어, 드론은 수집 데이터를 획득한 후, 드론에 포함된 프로세서에 의하여 322 단계를 수행할 수 있다. 그 후, 드론의 프로세서는 323 단계에서 제자리에서 지면과 수직인 회전축을 중심으로 회전하기 위한 명령 데이터를 도출하고, 도출된 명령 데이터를 이용하여 드론에 포함된 적어도 하나의 모 터를 제어할 수 있다. 322 단계에서 제1 선수가 영상 데이터에 대응되는 영상의 중앙에 위치했다고 확인되면, 서버는 331 단계에 서 다시 수집 데이터를 획득한다. 서버는 332 단계에서 제1 거리 센서의 측정값이 제2 값에 대응되는지 여 부를 확인한다. 제1 거리 센서의 측정값이 제2 값에 대응되지 않는다고 확인되는 경우, 서버는 333 단계 에서 제1 센서에 포함된 거리 센서의 측정값과 제2 값의 비교에 기초하여 명령 데이터를 사용자 장치에 송 신할 수 있다. 사용자 장치는 333 단계에서 수신한 명령 데이터를 드론에 송신할 수 있다. 333단계 에서 송신되는 명령 데이터는, 제1 센서에 포함된 거리 센서의 측정값이 제2 값보다 작은 경우 드론으로 하여금 제1 거리 센서가 향하는 제1 방향(521c)과 반대 방향으로 이동하도록 하는, 즉, 드론이 선수로부터 더 멀어지도 록 하는 명령 데이터일 수 있다. 반대로, 제1 센서에 포함된 거리 센서의 측정값이 제2 값보다 큰 경우, 명령 데이터는 드론으로 하여금 제1 방향(521c)으로 이동하도록 하는, 즉, 드론이 선수에게 더 가까워지도록 하는 명 령 데이터일 수 있다. 331 단계 내지 333단계 역시 321 단계 내지 323 단계와 마찬가지로, 제1 거리 센서의 측 정값이 제2 값에 대응된다고 확인될 때까지 반복될 수 있다. 다양한 실시예에 따라서, 331 단계 내지 333 단계에 포함되는 적어도 하나의 연산은 드론에서 수행될 수 있다. 예를 들어, 드론은 331 단계에서 수집 데이터를 획득한 후, 드론에 포함된 프로세서에 의하여 332 단계를 수행할 수 있다. 그 후, 드론의 프로세서는 333 단계에서 명령 데이터를 도출하고, 도출된 명 령 데이터를 이용하여 드론에 포함된 적어도 하나의 모터를 제어할 수 있다. 332 단계에서 제1 거리 센서의 측정값이 제2 값에 대응된다고 확인되는 경우, 서버는 340 동작을 수행한다. 340 동작에서, 서버는 복수의 기설정 각도 중 제3 값보다 작으면서 가장 큰 값을 갖는 제1 각도 를 확인할 수 있다. 예를 들어, 복수의 기설정 각도가 도 4a에 도시된 바와 같이 0도, 90도, 180도, 및 270도 이고, 제3 값이 100도인 경우, 제1 각도는 90도일 수 있다. 다른 예시로, 제3 값이 190도인 경우, 제1 각도는 180도일 수 있다. 다양한 실시예에 따라서, 340 동작은 드론의 프로세서에 의하여 수행될 수 있다. 351 단계에서, 서버는 다시 수집 데이터를 획득할 수 있다. 352 단계에서, 서버는 351 단계에서 획득 된 수집 데이터에 포함된 영상 데이터에 대응되는 이미지가 제1 각도에서 촬영된 것으로 제1 인공지능 모델에 의하여 확인되는지를 확인할 수 있다. 제1 인공지능 모델에 351 단계에서 획득된 수집 데이터에 포함된 영상 데이터에 대응되는 이미지를 입력하였을 때, 제1 각도에서 촬영된 것으로 확인되지 않는 경우, 서버는 353 단계에서 각도 증가 명령을 명령 데이터로서 사용자 장치에 송신할 수 있다. 사용자 장치는 각도 증 가 명령을 드론에 송신할 수 있다. 각도 증가 명령은 도 2c에 도시된 것과 같은 각변위(θ)가 증가하도록 드론을 비행시키는 명령으로서, 도 6a 내 지 6d를 참조하여 설명한다. 도 6a는 각도 증가 명령을 수신하기 전의 드론을 도시한 것으로, 드론(600a)은 예 시적으로 제1 방향(621a)이 제1 선수를 향해 있고, 선수의 정면 방향으로부터 각변위가 270도인 위치에 정 지하여 있다. 각도 증가 명령은 (a) 제1 방향(621a)과 수직인 방향으로 미리 설정된 제1 거리만큼 드론을 이동 시키는 명령, (b) 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지 드론으로 하여금 제자 리에서 지면과 평행한 평면 상에서 회전하도록 하는 명령, 및 (c) 제1 거리 센서의 측정값이 제2 값에 대응될 때까지 드론을 제1 방향으로 이동시키는 명령을 포함할 수 있다. 먼저, (a) 제1 방향(621a)과 수직인 방향으로 미리 설정된 제1 거리만큼 드론을 이동시키는 명령에 따라 움직인 드론(600b)의 모습이 도 6b에 도시된다. 드론의 위치를 살펴보면, 움직임 전 위치(600a)에 비하여, 제1 방향 (621a) 과 수직인 방향(601b)으로 미리 설정된 제1 거리만큼 이동하였고, 지면과 수직인 회전축에 대한 드론의 회전은 없었다. 그 결과 제1 방향(621b)은 이동 전 제1 방향(621a)과 평행하되, 제1 선수를 향하지는 않는 다. 그 다음으로, (b) 제1 선수가 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지 드론으로 하여금 제자리에 서 지면과 평행한 평면 상에서 회전하도록 하는 명령에 따라 움직인 드론(600c)의 모습이 도 6c에 도시된다. 드론의 위치를 살펴보면, 위치는 움직임 이전의 드론(600b) 위치와 동일하고, 지면과 수직인 회전축에 대하여 회전한 결과, 제1 방향(621c)이 제1 선수를 향하고, 그 결과 제1 선수가 영상 데이터에 대응되는 영상의 중앙에 위치한다. 이 때, 제1 선수가 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지 드론이 회전한 각도 (θ1)는 제1 선수를 기준으로 드론을 향하는 방향의 각변위 변화(θ1)와 동일하고, 이러한 각도 변화는 IMU 센서에 의하여 누적되어 기록된다. 따라서, 서버는 제1 선수를 기준으로 드론(600c)을 향하는 방 향의 각변위 변화, 즉, 드론이 제1 선수를 기준으로 몇 도 회전했는지를 확인할 수 있게 된다. 그 다음으로, 제1 거리 센서의 측정값이 제2 값에 대응될 때까지 드론을 제1 방향으로 이동시키는 명령에 따라 움직인 드론(600d)의 모습이 도 6d에 도시된다. 제1 방향(621d)는 이전의 제1 방향(621c)과 동일하게 유지한 채로, 드론(600d)의 위치만 변경된 것을 확인할 수 있다. 353 단계 수행 후, 351 단계, 352 단계, 및 353 단계는 제1 각도에서 촬영된 것으로 확인되는 이미지에 대응되 는 영상 데이터가 수집 데이터에 포함되어 서버에 의하여 수신될 때까지 반복될 수 있다. 영상 데이터가 제1 각도에서 촬영된 것으로 확인되는 경우, 서버는 360 단계에서 IMU 센서의 각도 값을 0으로 설정하고, 361 단계에서 다시 수집 데이터를 수신할 수 있다. 다양한 실시예에 따라서, 351 단계 내지 353 단계 및 360 단계에 포함되는 적어도 하나의 연산은 드론에서 수행될 수 있다. 예를 들어, 드론은 수집 데이터를 획득한 후, 드론에 포함된 프로세서에 의하여 352 단계를 수행할 수 있다. 그 후, 드론의 프로세서는 353 단계에서 각도 증가 명령을 생성하고, 생성된 각도 증가 명령을 이용하여 드론에 포함된 적어도 하나의 모터를 제어할 수 있다. 362 단계에서, 서버는 IMU 센서가 나타내는 각도 값이 제3 값에서 제1 각도를 뺀 값에 대응되는지를 확인 할 수 있다. IMU 센서가 나타내는 각도 값이 제3 값에서 제1 각도를 뺀 값에 대응되지 않는 경우, 363 단계에서 각도 증가 명령을 명령 데이터로서 송신할 수 있다. 361 단계, 362 단계, 및 363 단계는 IMU 센서가 나타내는 각도 값이 제3 값에서 제1 각도를 뺀 값에 대응될 때까지 반복될 수 있다. IMU 센서가 나타내는 각도 값이 제3 값에서 제1 각도를 뺀 값에 대응되는 경우, 서버는 370 단계에서 제2 값 및 제3 값에 대응되는 위치에 드 론이 위치하였다고 확인할 수 있다. 다양한 실시예에 따라서, 361 단계 내지 363 단계 및 370 단계에 포함되는 적어도 하나의 연산은 드론에서 수행될 수 있다. 예를 들어, 드론은 수집 데이터를 획득한 후, 드론에 포함된 프로세서에 의하여 362 단계를 수행할 수 있다. 그 후, 드론의 프로세서는 363 단계에서 각도 증가 명령을 생성하고, 생성된 각도 증가 명령을 이용하여 드론에 포함된 적어도 하나의 모터를 제어할 수 있다. 도 3a 및 도 3b에 도시된 과정을 통하여 232 단계에서 제2 값 및 제3 값에 대응되는 위치에 드론이 위치하 였다고 확인되는 경우, 서버는 240 단계에서 초기 위치 설정 완료 신호를 사용자 장치에 송신할 수 있다. 사용자 장치는 초기 위치 설정 완료 신호를 드론에 송신할 수 있다. 또한, 사용자 장치는 초 기 위치 설정 완료 신호가 수신되는 것에 응답하여, 미리 설정된 소리를 출력 장치(예를 들어, 스피커)를 통하 여 출력하거나, 초기 위치가 설정 완료되었다는 것을 디스플레이를 통하여 표시할 수 있다. 다양한 실시예에 따라서, 232 단계가 드론의 프로세서에 의하여 수행된 경우, 240 단계는 드론이 초 기 위치 설정 완료 신호를 생성하여 사용자 장치에 송신함으로써 수행될 수 있다. 초기 위치 설정 완료 신호를 생성하거나 수신한 드론 또한 초기 위치 설정 완료 신호가 생성되는 것에 응 답하여, 또는 초기 위치 설정 완료 신호가 수신되는 것에 응답하여 스피커를 통하여 미리 설정된 소리를 출력할 수 있다. 드론 또는 사용자 장치의 스피커를 통하여 출력되는 미리 설정된 소리는, 예를 들어, 실제 경기 시작을 알리는 소리와 동일할 수 있다. 240 동작이 수행된 후, 선수는 스피커를 통하여 출력되는 소리를 듣고, 또는 사용자 장치의 디스플레이에 표시된 메시지를 보고 운동을 시작할 수 있다. 드론은 선수가 운동하는 동안 선수의 정면 방향으로 비행하 면서 수집 데이터를 획득하여 사용자 장치에 송신하고, 사용자 장치는 수집 데이터를 서버에 송 신할 수 있다(251 단계). 서버는 252 단계에서 운동이 완료되었는지 확인할 수 있다. 다양한 실시예에 따라서, 서버는 수집 데이터 내 영상 데이터를 분석하여, 선수가 일정 속도 이하로 움직이는 시간이 미리 결정된 제1 시간 이상이 되 면 운동이 완료되었다고 판정할 수 있다. 다양한 실시예에 따라서, 서버는 선수 또는 코치의 입력을 받은 사용자 장치로부터, 운동이 끝났다는 신호를 수신하면 운동이 완료되었다고 판정할 수 있다. 운동이 완료되지 않았다고 확인되는 경우, 즉, 운동이 끝나기 전까지는 서버는 253 단계에서 제1 값, 제2 값, 및 제3 값에 대응되는 위치에 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하여 사용자 장치 에 송신할 수 있다. 사용자 장치는 253 단계의 명령 데이터를 드론에 송신할 수 있다. 운동이 완료되지 않았을 때 서버에서 명령 데이터를 도출하는 과정은 상술한 바와 유사하다. 먼저, 드론 의 비행 높이인 h 값은 수집 데이터 내에 포함되므로, 서버는 수집 데이터 내 h 값과 제1 값을 비교 하여, h 값이 제1 값보다 작으면 드론의 지면에 대한 추진력을 증가시키도록 하는 명령 데이터를 송신하고, h 값이 제1 값보다 크면 드론의 지면에 대한 추진력을 감소시키도록 하는 명령 데이터를 송신할 수 있다. 드론과 선수 사이의 거리인 r 값은 선수가 영상 데이터에 대응되는 영상의 중앙에 위치할 때 제1 센서에 포함되는 거리 센서의 측정값이다. 따라서, 서버는 321 단계 내지 323 단계, 및 331 단계 내지 333 단계를 수행함으로써 드론이 제2 값에 대응되는 위치에 있도록 드론을 제어할 수 있다. 선수의 정면 방향을 기준으로 한, 선수로부터 드론을 향한 방향의 각변위인 θ 값은 도 6c에서 상술한 바와 같 이, 선수가 영상 데이터에 대응되는 영상의 중앙에 위치하도록 드론이 회전하였을 때 회전 각도만큼 변화한다. 운동 시작 직전에 θ 값이 제3 값과 동일하도록 설정된 상태에서 시작하므로, 서버는 운동 시작 후에 각변 위를 유지할 수 있도록, 선수가 영상 데이터에 대응되는 영상의 중앙에 위치하도록 드론을 회전시키면서, 각변 위가 감소하였다고 판단되면 각도 증가 명령을 명령 데이터로서 송신하고, 각변위가 증가하였다고 판단되면 각 도 감소 명령을 명령 데이터로서 송신할 수 있다. 각도 감소 명령의 내용은 도 6a 내지 6d를 참조하여 상술한 바와 동일하되, 도 6b에서 이동 방향만 각변위가 감소하는 방향, 즉, 도 6b에 도시된 이동 방향(601b)과 반대 방향이다. 다양한 실시예에 따라서, 252 단계 내지 253 단계에 포함되는 적어도 하나의 연산은 드론에서 수행될 수 있다. 예를 들어, 드론은 251 단계에서 수집 데이터를 획득한 후, 드론에 포함된 프로세서에 의하여 252 단계를 수행할 수 있다. 그 후, 드론의 프로세서는 253 단계에서 제2 값 및 제3 값에 대응되는 위치 로 이동하기 위한 명령 데이터를 도출하고, 도출된 명령 데이터를 이용하여 드론에 포함된 적어도 하나의 모터를 제어할 수 있다. 운동이 완료되었다고 확인되면, 서버는 260 단계에서, 운동이 이뤄지는 동안의 수집 데이터, 즉, 251 단계 에서 수신된 수집 데이터에 기초하여 운동 영상을 저장할 수 있다. 운동 영상은 251 단계에서 수집된 적어도 하나의 수집 데이터에 포함되는 영상 데이터 중 드론이 제1 값, 제2 값, 및 제3 값에 대응되는 위치에서 비행한 시간에 대응되는 부분을 추출함으로써 획득될 수 있다. 다양한 실시예에 따라서, 252 단계 내지 253 단계에 포함되는 적어도 하나의 연산이 드론에서 수행된 경우, 260 단계는 드론이 운동이 이뤄지는 동안의 수집 데이터를 서버에 송신하고, 서버에서 수 집 데이터에 포함되는 영상 데이터 중 드론이 제1 값, 제2 값, 및 제3 값에 대응되는 위치에서 비행한 시간에 대응되는 부분을 추출하여 저장함으로써 수행될 수 있다. 도 7은 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 회피 기동 방법을 도시한다. 회 피 기동은 드론이 비행 중일 때 외부 물체가 드론에 접근하는 경우 드론 또는 선수를 보호하기 위하여 수행되는 동작이다. 710 단계에서, 서버는 제1 선수가 운동하는 동안의 적어도 하나의 수집 데이터에 기초하여, 미확인 물체가 드론에 접근하는 것을 확인할 수 있다. 예를 들어, 제1 센서가 선수를 향하고 있음이 영상 데이터를 통하 여 확인되는 상황에서, 제1 센서를 제외한, 드론의 측면 방향을 향하고 있는 다른 거리 센서들(예를 들어, 도 5a의 센서(512, 513, 514)) 중 하나에서 미확인 물체가 감지되고, 미확인 물체와의 거리가 가까워지고 있는 경 우, 미확인 물체가 드론에 접근하고 있다고 결정할 수 있다.720 단계에서, 서버는 미확인 물체가 드론에 접근하는 방향 및 드론의 상단에 물체가 존재하는지 여부를 확인할 수 있다. 서버는 미확인 물체를 감지한 센서가 감지하는 방향을 미확인 물체가 드론에 접근하는 방 향으로서 확인할 수 있다. 예를 들어, 도 5a의 센서를 통하여 미확인 물체가 감지되고, 미확인 물체와의 거리가 가까워지고 있는 경우, 미확인 물체가 드론에 접근하는 방향은 센서의 감지 방향의 반대 방향 이라고 확인할 수 있다. 서버는 드론의 상단을 향하여 배치된 거리 측정 센서에서의 측정값이 미리 결정 된 값 이하이면 드론의 상단에 물체가 존재한다고 결정할 수 있다. 730 단계에서, 서버는 제1 센서로부터 제1 지점을 향하는 방향과 제2 방향의 차가 미리 설정된 제2 각도보 다 큰지 여부를 확인할 수 있다. 제2 방향은 미확인 물체가 드론에 접근하는 방향을 의미한다. 730 단계에서 제1 센서로부터 제1 지점을 향하는 방향과 제2 방향의 차가 미리 설정된 제2 각도보다 크다고 결 정되는 경우, 서버는 740 단계에서 드론을 정지 비행시키는 명령 데이터를 사용자 장치에 송신할 수 있다. 사용자 장치는 명령 데이터를 드론에 송신할 수 있다. 정지 비행은 드론이 지면에 수직 인 회전축을 기준으로 회전하지도 않고, 위치를 변경시키지도 않고 제자리를 유지한다는 것을 의미한다. 730 단계에서 제1 센서로부터 제1 지점을 향하는 방향과 제2 방향의 차가 미리 설정된 제2 각도 이하라고 결정 되는 경우, 서버는 750 단계에서 드론의 상단에 물체가 존재하는지 여부를 확인할 수 있다. 750 단계에서 드론의 상단에 물체가 존재한다고 결정되는 경우, 서버는 760 단계에서 드론의 모터 동작을 차단시키는 명령 데이터를 송신할 수 있다. 사용자 장치는 명령 데이터를 드론에 송신할 수 있다. 760 단계의 명령 데이터를 수신한 드론은 모터의 동작을 차단시키게 되고, 그 결과 지상으로 즉시 낙하하 게 된다. 750 단계에서 드론의 상단에 물체가 존재하지 않는다고 결정되는 경우, 서버는 770 단계에서 드론을 미리 설정된 제1 고도 이상의 고도로 급상승시키는 명령 데이터를 송신할 수 있다. 사용자 장치는 명령 데이터 를 드론에 송신할 수 있다. 770 단계의 명령 데이터를 수신한 드론은 지면에 평행한 평면상에서의 좌 표는 그대로 유지한 채 고도만 미리 설정된 제1 고도 이상의 고도로 급상승하게 된다. 다양한 실시예에 따라서, 도 7의 각 단계에 포함되는 적어도 하나의 연산은 드론에서 수행될 수 있다. 710 단계 내지 730 단계 및 750 단계의 확인하는 동작은 드론에 포함된 프로세서에 의하여 수행될 수 있다. 740 단계, 760 단계, 및 770 단계는 드론에 포함된 프로세서에서 해당하는 명령 데이터를 생성하고, 생성 된 명령 데이터를 이용하여 드론에 포함된 적어도 하나의 모터를 제어함으로써 수행될 수 있다. 다양한 실시예에 따라서, 도 7에 도시된 바와 다른 회피 기동 방법이 수행될 수 있다. 서버 또는 드론 의 프로세서는 제1 선수가 운동하는 동안의 적어도 하나의 수집 데이터에 기초하여, 미확인 물체가 드론 과 미리 결정된 제2 거리 내에 접근하는 것을 확인할 수 있다. 드론과 미리 결정된 제2 거리 내에 접근한 미확인 물체가 확인되면, 서버 또는 드론의 프로세서는 적어도 하나의 수집 데이터에 기초하 여, 미확인 물체와 드론 사이의 거리를 지속적으로 모니터링할 수 있다. 미확인 물체와 드론 사이의 거리가 제2 거리보다 짧게 미리 결정된 제3 거리 이하로 확인되면, 서버 또는 드론의 프로세서는 수 집 데이터에 기초하여 드론의 상단에 물체가 존재하는지 여부를 확인하고, 드론의 상단에 물체가 존재하면 드론 의 모터 동작을 차단시키는 명령 데이터를 생성하고, 드론의 상단에 물체가 존재하지 않으면 드론을 미리 설정 된 제1 고도 이상의 고도로 급상승시키는 명령 데이터를 생성할 수 있다. 서버 또는 드론의 프로세서는 제1 선수가 운동하는 동안의 적어도 하나의 수집 데이터에 기초하여, 제1 선수가 드론과 미리 결정된 제2 거리 내에 접근하는 것을 확인할 수 있다. 여기서 제2 거리는 도 2c를 참조하여 상술한 제2 값보다 작은 값일 수 있다. 제1 선수가 드론으로부터 미리 결정된 제2 거리 내에 접 근하였음이 확인되면, 서버 또는 드론의 프로세서는 적어도 하나의 수집 데이터에 기초하여, 드론 과 제1 선수 사이의 거리가 제2값이 되도록 하는 명령 데이터를 생성할 수 있다. 만약 제1 선수와 드론 사이의 거리가 제2 거리보다 짧게 미리 결정된 제3 거리 이하로 확인되면, 서버 또는 드론의 프로세서는 수집 데이터에 기초하여 드론의 상단에 물체가 존재하는지 여부를 확인하고, 드론의 상단에 물체가 존재하면 드론의 모터 동작을 차단시키는 명령 데이터를 생성하고, 드론의 상단에 물체가 존재하지 않으면 드론 을 미리 설정된 제1 고도 이상의 고도로 급상승시키는 명령 데이터를 생성할 수 있다. 비록 도면상에는 도시되지 않았으나, 다양한 실시예에 따라서, 서버는 드론의 카메라가 외부 물체에 의하여 가려져 정상적인 영상 데이터의 수집이 불가능한 경우를 판단하여 대응할 수 있다. 서버는 영상 데이터에 대응되는 이미지 내에서 명도가 미리 설정된 제1 명도 이하인 영역의 비중이 미리 설정된 비중 이상인경우 카메라가 외부 물체에 의하여 가려진 상황이라고 판단할 수 있고, 이러한 상황이 감지되면 미리 설정된 제 1 시간 동안 드론의 모터 회전 속도, 기울기 각도, 및 진행 방향을 유지하도록 하는 명령 데이터를 사용자 장치 에 송신할 수 있다. 사용자 장치는 해당 명령 데이터를 드론에 송신할 수 있다. 또한, 서버는 영상 데이터에 대응되는 이미지 내에서 명도가 미리 설정된 제1 명도 이하인 영역의 비중이 미리 설정된 비중 이상인 상태가 미리 설정된 제2 시간 이상 지속되는 경우, 명령 데이터의 송신을 중단하고, 사용자 장치에 드론을 수동 모드로 전환한다는 메시지를 송신할 수 있다. 이 경우, 드론의 동작은 서버 가 아니라 운동 선수 또는 코치에 의하여 제어될 수 있다. 예를 들어, 드론을 수동으로 조종하기 위 한 신호는 사용자 장치에 입력될 수 있다. 다양한 실시예에 따라서, 서버는 계주 상황에서 주자가 바뀜에 따라 바뀐 주자를 따라 비행하도록 드론 을 제어할 수 있다. 서버는 초기 위치 설정 완료 신호를 송신하기 전, 정지한 제1 선수의 상의 색상 평균값 및 하의 색상 평균값을 저장할 수 있다. 그 후, 제1 선수의 운동이 진행되는 동안 수집되는 영상 데이터 에 대응되는 이미지 내에서 제1 선수와 상이한 제2 선수가 있는 것을 확인할 수 있다. 제2 선수의 확인에는 영 상 데이터 내에서 사람 형태를 확인할 수 있는 다양한 인공지능 모델이 이용될 수 있다. 제2 선수가 이미지 내 있다고 확인되는 경우, 서버는 제2 선수의 상의 색상 평균값 및 하의 색상 평균값을 확인할 수 있다. 서버는 제2 선수의 상의 색상 평균값과 제1 선수의 상의 색상 평균값의 차가 미리 설정된 제4 값 이하이거 나, 제2 선수의 하의 색상 평균값과 제1 선수의 하의 색상 평균값의 차가 미리 설정된 제5 값 이하인 경우, 제2 선수의 이동 방향 및 상기 제1 선수의 이동 방향을 확인할 수 있다. 여기서 제4 값 및 제5 값은 육안으로 보았 을 때 동일한 색이라고 판단될 수 있을 만큼 충분히 작은 값일 수 있다. 다양한 실시예에 따라서, 서버는 사용자 장치로부터 예외 처리 색상을 입력받고, 제2 선수의 상의 색상 평균값과 제1 선수의 상의 색상 평 균값의 차가 미리 설정된 제4 값 이하이더라도, 제2 선수의 상의 색상 평균값과 예외 처리 색상의 차가 미리 설 정된 제4 값 이하이고, 제1 선수의 상의 색상 평균값과 예외 처리 색상의 차가 미리 설정된 제4 값 이하인 경우, 제2 선수의 이동 방향을 확인하지 않고 지속해서 상기 제1 선수만 추적하도록 드론을 제어할 수 있다. 예외 처리 색상은 운동복 및 일상복으로서 흔히 사용되고 팀 구분에 거의 사용되지 않는 색상으로서, 예를 들어, 검은색 및/또는 회색 중 사용자의 입력에 따라 결정될 수 있다. 다양한 실시예에 따라서, 서버는 소셜 미디어 상의 게시물 중 운동을 나타내는 다양한 키워드를 검색하고, 검색 결과로 필터링된 게시물 상에서 사람 형태를 인식하고, 사람 형태가 인식되는 경우 상의 색 및 하의 색을 추출하고, 필터링된 게시물들에서 추 출된 상의 색 및 하의 색의 출현 빈도를 데이터베이스화하여, 출현 빈도가 높은 상의 색상 또는 하의 색상을 예 외 처리 색상으로 지정할 수 있다. 운동을 나타내는 다양한 키워드는 서버의 관리자에 의하여 미리 지정될 수 있다. 다양한 실시예에 따라서, 서버는 인터넷 오픈마켓 상의 게시물 중 운동복을 나타내는 다양한 키워드 를 검색하고, 검색 결과로 필터링된 게시물에 포함된 후기 사진의 데이터베이스를 획득하고, 후기 사진 데이터 베이스에 포함된 각 사진에서 사람 형태를 인식하고, 사람 형태가 인식되는 경우 상의 색 및 하의 색을 추출하 고, 필터링된 게시물들에서 추출된 상의 색 및 하의 색의 출현 빈도를 데이터베이스화하여, 출현 빈도가 높은 상의 색상 또는 하의 색상을 예외 처리 색상으로 지정할 수 있다. 운동복을 나타내는 다양한 키워드는 서버의 관리자에 의하여 미리 지정될 수 있다. 다양한 실시예에 따라서, 서버는 지정된 예외 처리 색상 정보를 사용자 장치에 송신하고, 사용자 장치는 예외 처리 색상들을 표시할 수 있다. 하의에 대해서도 마찬가지로, 서버는 제2 선수의 하의 색상 평균값과 제1 선수의 하의 색상 평균값의 차가 미리 설정된 제5 값 이하이더라도, 제2 선수의 하의 색상 평균값과 예외 처리 색상의 차가 미리 설정된 제5 값 이하이고, 제1 선수의 하의 색상 평균값과 예외 처리 색상의 차가 미리 설정된 제5 값 이하인 경우, 제2 선수의 이동 방향을 확인하지 않고 지속해서 제1 선수만 추적하도록 드론을 제어할 수 있다. 제2 선수의 이동 방향 및 상기 제1 선수의 이동 방향을 확인한 서버는 2 선수가 드론의 미리 설정된 제2 시간 동안의 평균 이동 방향과 동일 방향으로 이동하고, 제1 선수가 드론의 제2 시간 동안의 이동 방향과 상이 한 방향으로 이동하는 경우, 드론이 트래킹할 타겟을 제1 선수에서 제2 선수로 변경할 수 있다. 즉, 서버(13 0)는 제2 선수를 기준으로 제1 값, 제2 값, 및 제3 값에 대응되는 위치에 드론을 위치시키기 위한 적어도 하나 의 명령 데이터를 도출하여 사용자 장치에 송신할 수 있다. 사용자 장치는 적어도 하나의 명령 데이 터를 드론에 송신할 수 있다. 도 8은 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 3차원 인체 모델 생성 방법을 도 시한다. 도 8의 3차원 인체 모델 생성은 선수가 운동을 시작하기 전에 선수가 정지해있는 상태에서 이루어질 수있다. 810 단계에서, 서버는 드론에 의하여 수집된 제1 수집 데이터를 획득할 수 있다. 820 단계에서, 서버는 회전 운동이 완료되었는지를 확인할 수 있다. 회전 운동이 완료되었다는 것은 드론 이 선수 주변을 미리 결정된 횟수만큼 맴돌았다는 것을 의미한다. 서버는 복수의 기설정 각도 중 가 장 작은 각도(예를 들어, 0도)에 드론이 위치한다는 것을 이미지 분석을 통하여 확인할 수 있고, 0도를 시작으 로 각도 증가 명령을 반복하여 드론의 각변위를 증가시킬 수 있다. 서버는 도 3b의 351 단계 내지 363 단 계와 유사하게, 도 4b를 참조하여 상술한 제1 인공지능 모델에 기초하여 드론의 각변위(θ)가 복수의 기설 정 각도일 때마다 이를 확인할 수 있고, 여기에 IMU 센서의 측정값을 더한 값을 현재 드론의 각변위로서 확인할 수 있다. 도 3b의 351 단계 내지 363 단계와 유사하게, 서버는 드론의 각변위(θ)가 복수의 기설정 각도가 될 때마다 IMU 센서의 측정값을 0으로 리셋할 수 있다. 회전 운동이 완료되지 않은 경우, 서버는 830 단계에서, 정지한 제1 선수 주위를 회전하도록 하는 적어도 하나의 명령 데이터를 사용자 장치에 송신할 수 있다. 사용자 장치는 830 단계의 명령 데이터를 드 론에 송신할 수 있다. 830 단계의 명령 데이터는 드론의 제1 센서와 선수 사이의 거리를 미리 설정된 제1 거리가 되게 하는 명령 데이터 및 상술한 각도 증가 명령을 포함할 수 있다. 회전 운동이 완료된 경우, 서버는 840 단계에서, 810 단계에서 수집된 제1 수집 데이터에 기초하여 제1 선 수의 3차원 인체 모델을 생성할 수 있다. 서버는 제1 수집 데이터에 포함된 영상 데이터에 대응하는 이미 지를 대상으로 관절점을 추출하고, 여러 각도에서 획득된 관절점 정보에 기초하여 제1 선수의 3차원 인체 모델 을 생성할 수 있다. 다양한 실시예에 따라서, 도 8의 각 단계에 포함되는 적어도 하나의 연산은 서버가 아닌 드론에서 수 행될 수 있다. 820 단계의 확인하는 동작은 드론에 포함된 프로세서에 의하여 수행될 수 있다. 830 단계는 드론에 포함된 프로세서에서 명령 데이터를 생성하고, 생성된 명령 데이터를 이용하여 드론에 포함된 적어도 하나의 모터를 제어함으로써 수행될 수 있다. 840 단계 또한 드론에 포함된 프로세서에 의하여 수 행될 수 있다. 도 9는 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 운동 데이터 획득 방법을 도시한 다. 910 단계에서, 서버는 운동 영상을 획득할 수 있다. 여기서, 운동 영상이라는 것은 도 2b의 260 동작 에서 저장되는 운동 영상을 의미하고, 운동 영상은 드론의 선수에 대한 상대적 위치가 사용자 장치에 입력된 제 1 값, 제2 값, 및 제3 값에 의하여 특정되는 위치일 때 획득된 영상이다. 920 동작에서, 서버는 운동 영상의 각 프레임을 구성하는 이미지 각각으로부터 관절점을 추출할 수 있다. 930 동작에서, 서버는 운동 영상으로부터 추출된 관절점 및 제1 선수의 3차원 인체 모델에 기초하여, 운동 데이터를 확인할 수 있다. 운동 데이터는 제1 선수의 관절 가동 범위, 관절 가동 속도, 및 주기적으로 반복되 는 동작에서 관절 가동 범위 및 관절 가동 속도의 주기별 변화를 포함할 수 있다. 제1 선수의 3차원 인체 모델 은 도 8의 과정을 통하여 생성된 3차원 인체 모델을 의미한다. 서버는 확인된 운동 데이터를 사용자 장치 에 전송하거나, 확인된 운동 데이터를 운동 영상에 오버레이하여 합성 영상을 생성하고, 생성된 합성 영상을 사 용자 장치에 전송할 수 있다. 940 동작에서, 사용자 장치는 운동 데이터를 표시할 수 있다. 운동 데이터가 표시되는 예시가 도 10a 및 도 10b에 도시된다. 도 10a의 예시에서는, 관절의 가동 범위 및 선수의 몸 윤곽이 운동 데이터로서 표시되었다. 도 10b의 예시에서는, 선수가 주기적으로 반복하는 달리기 동작의 반복 주기별 관절 가동 범위의 변화 및 선수 의 몸 윤곽이 운동 데이터로서 표시되었다. 도 11은 본 발명의 다양한 실시예에 따른 합성 영상 제공 방법을 도시한다. 1110 단계에서, 서버는 운동 영상을 획득할 수 있다. 여기서, 운동 영상이라는 것은 도 2b의 260 동작에서 저장되는 운동 영상을 의미하고, 운동 영상은 드론의 선수에 대한 상대적 위치가 사용자 장치에 입력된 제1 값, 제2 값, 및 제3 값에 의하여 특 정되는 위치일 때 획득된 영상이다. 1120 단계에서, 서버는 제1 선수의 운동 영상으로부터 상기 제1 선수의 운동 데이터를 확인할 수 있다. 운동 데이터의 획득 방법에 대해서는 도 8 및 도 9를 참조하여 상술한 바 있다. 1130 단계에서, 서버는 제1 선수의 운동 영상을 파싱하여 복수의 부분 운동 영상을 획득할 수 있다. 서버 는 운동 동작이 반복되는 경우 반복 주기별로 운동 영상을 파싱할 수 있다. 또는, 서버는 미리 결정된 시간 구간에 따라 운동 영상을 파싱할 수 있다. 또는, 서버는 미리 결정된 기록 지점에 따라 운동 영 상을 파싱할 수 있다. 예를 들어,100m 달리기의 경우, 30m 지점, 50m 지점, 80m 지점, 및 100m 지점에서 운동 영상을 파싱할 수 있다. 서버는 수집 데이터들에 포함된 드론의 시간별 직선 이동 속도에 기초하여 특정한 지점(30m 지점, 50m 지점, 80m 지점, 및 100m 지점)을 지나는 시점이 운동 영상의 어느 프레임에 대응되 는지를 결정할 수 있다. 다양한 실시예에 따라서, 반복되는 운동 동작의 반복 주기별로 운동 영상을 파싱하기 위한 다양한 알고리즘이 사용될 수 있다. 예를 들어, 서버는 관절점 분석에 기초하여, 운동 영상으로부터 왼무릎-골반-오른무릎의 세 관절점이 이루는 각도 A를 추출하고, 일정한 시간 범위 내에서 각도 A의 값이 가장 큰 때를 기준으로 운동 영상을 파싱할 수 있다. 1140 단계에서, 서버는 복수의 부분 운동 영상 중 제1 부분 운동 영상, 제2 부분 운동 영상, 제1 부분 운 동 영상에 대응되는 운동 데이터, 및 제2 부분 운동 영상에 대응되는 운동 데이터에 기초하여 합성 영상을 생성 할 수 있다. 예를 들어, 도 12a에 도시된 바와 같이, 두 개의 운동 영상의 투명도를 증가시키고, 투명도를 증 가시킨 두 부분 운동 영상 및 두 개의 운동 영상에 대응되는 운동 데이터를 오버레이하여 합성 영상이 생성될 수 있다. 다양한 실시예에 따라서, 서버는 3개 이상의 부분 운동 영상들 및 그에 대응되는 운동 데이터들을 합성하 여 합성 영상을 생성할 수 있다. 예를 들어, 도 12b에 도시된 바와 같이, 4개의 부분 운동 영상들 및 그에 대 응되는 운동 데이터들이 오버레이되어 합성 영상에 표시될 수 있다. 1150 단계에서, 서버는 1140 단계에서 생성된 합성 영상을 사용자 장치에 송신할 수 있다. 1160 단계에서, 사용자 장치는 합성 영상을 표시할 수 있다. 도 12a 및 도 12b에 도시된 바와 같이, 상이한 부분 영 상에 대응되는 운동 데이터는 상이한 색상으로 표시될 수 있다. 도 11에서 설명한 방법은 동일한 선수가 한 번 운동을 수행할 때 한 번의 운동 내에서 상이한 타이밍에 대응되 는 부분 영상들을 합성하여 제공하는 방법인 것과 달리, 다양한 실시예에 따라서, 상이한 선수가 동일한 운동을 하는 동안 촬영된 운동 영상들에 기초하여, 두 운동 영상 내에서 서로 동일한 타이밍에 대응되는 부분 영상들을 합성하여 제공하는 것도 가능한다. 즉, 서버는 제2 선수의 운동 영상을 획득하고, 제2 선수의 운동 영상으 로부터 제2 선수의 운동 데이터를 확인하고, 제2 선수의 운동 영상을 운동 동작의 주기별로 파싱하여 제2 선수 에 대응하는 복수의 부분 운동 영상을 획득하고, 제2 선수에 대응하는 복수의 부분 운동 영상 중 제1 부분 운동 영상이 촬영된 시점에 대응되는 제3 부분 운동 영상의 투명도를 증가시키고, 투명도를 증가시킨 제1 부분 운동 영상에 투명도를 증가시킨 제3 부분 운동 영상, 제1 부분 운동 영상에 대응되는 운동 데이터, 및 제3 부분 운동 영상에 대응되는 운동 데이터를 오버레이하여 제2 합성 영상을 생성하고, 제2 합성 영상을 사용자 장치에 송신 할 수 있다. 사용자 장치는 도 12a 및 12b에 예시된 형태로 제2 합성 영상을 표시할 수 있다. 도 13은 본 발명의 다양한 실시예에 따른 합성 영상 제공 방법을 도시한다. 도 13은 운동을 하는 동안의 동작 변화를 한 번에 볼 수 있도록 운동의 전 과정을 하나의 합성 영상으로 제공하는 방법이다. 1310 단계에서, 서버는 제1 선수의 제1 운동 영상을 획득할 수 있다. 여기서, 운동 영상이라는 것은 도 2b 의 260 동작에서 저장되는 운동 영상을 의미하고, 운동 영상은 드론의 선수에 대한 상대적 위치가 사용자 장치 에 입력된 제1 값, 제2 값, 및 제3 값에 의하여 특정되는 위치일 때 획득된 영상이다. 1320 단계에서, 서버는 제1 운동 영상으로부터 배경 영역과 제1 선수 영역을 분리하여 제1 배경 영상 및 제1 선수 영상을 획득할 수 있다. 도 14a를 참조하면, 서버는 제1 운동 영상(1400a)으로부터 제1 배경 영 상(1410a) 및 제1 선수 영상(1420a)을 획득할 수 있다. 1330 단계에서, 서버는 제1 배경 영상의 복수의 프레임을 합성하여 배경 이미지를 생성할 수 있다. 서버 는 제1 선수의 제1 운동 영상의 기초가 되는 수집 데이터에 포함된, 드론의 비행 속도 및 제1 영상 데이터 가 촬영된 시간 정보에 기초하여 제1 배경 영상의 복수의 프레임을 합성하여 배경 이미지를 생성할 수 있다. 다양한 실시예에 따라서, 서버는 육상 트랙의 출발선과 도착선의 이미지를 학습하고, 유사도 판단에 기초 하여 영상 데이터에 나타난 출발선 및 도착선을 인식하고, 도 14b에 도시된 바와 같이, 출발선과 도착선이 배경 이미지에 나타나도록 배경 이미지를 생성할 수 있다. 1340 단계에서, 서버는 제1 선수 영상의 복수의 프레임을 배경 이미지 상에 오버레이하여 제1 합성 영상을 생성할 수 있다. 서버는 드론의 비행 속도 및 상기 제1 영상 데이터가 촬영된 시간 정보에 기초하여 제1 선수 영상의 복수의 프레임이 배경 이미지 상의 어느 위치에 대응되는지를 결정하고, 도 14c에 도시된 바와 같이 제1 선수 영상의 복수의 프레임(1411c, 1412c, 1413c, 1414c, 1415c)이 배경 이미지 상에 오버레이된 제1 합성 영상(1420c)을 생성할 수 있다. 1350 단계에서, 서버는 제1 합성 영상을 사용자 장치에 송신할 수 있다. 1360 단계에서, 사용자 장치는 제 1 합성 영상을 표시할 수 있다. 제1 합성 영상(1420c)을 재생하면, 처음에는 제1 선수 영상의 초반 프레임들 (1411c)만 표시되고, 실제 선수가 1412c 위치에 도달한 타이밍에 해당 타이밍에 대응되는 프레임들(1412c)이 재 생되고 초반 프레임들(1411c)의 마지막 프레임이 정지 상태로 남는 식으로, 제1 선수 영상의 복수의 프레임이 순차적으로 재생될 수 있다. 도 14a는 본 발명의 다양한 실시예에 따라 획득되는 배경 영상 및 선수 영상의 예시를 도시한다. 도 14b는 본 발명의 다양한 실시예에 따라 획득되는 배경 이미지의 예시를 도시한다. 도 14c는 본 발명의 다양한 실시예에 따라 획득되는 합성 영상의 예시를 도시한다. 도 15는 본 발명의 다양한 실시예에 따른 합성 영상 제공 방법을 도시한다. 1510 단계에서, 서버는 제2 선 수의 제2 운동 영상을 획득할 수 있다. 제2 운동 영상은 제2 선수가 제1 선수가 한 운동과 동일한 운동, 예를 들어, 100m 달리기를 한 장면을 촬영한 영상일 수 있다. 여기서도 마찬가지로, 운동 영상이라는 것은 도 2b의 260 동작에서 저장되는 운동 영상을 의미하고, 운동 영상은 드론의 선수에 대한 상대적 위치가 사용자 장치에 입력된 제1 값, 제2 값, 및 제3 값에 의하여 특정되는 위치일 때 획득된 영상이다. 1520 단계에서, 서버는 제2 운동 영상으로부터 배경 영역과 제2 선수 영역을 분리하여 제2 선수 영상을 획 득할 수 있다. 1530 단계에서, 서버는 제2 선수 영상의 적어도 하나의 프레임을 도 13을 참조하여 상술한 제1 합성 영상 상에 오버레이하여 제2 합성 영상을 생성할 수 있다. 서버는 제2 선수 영상을 획득하는 기초가 된 수집 데 이터에 포함된, 드론의 비행 속도 및 영상 데이터가 촬영된 시간 정보에 기초하여 제2 선수 영상의 복수의 프레 임이 배경 이미지 상의 어느 위치에 대응되는지를 결정하고, 해당 프레임을 제1 합성 영상 상에 오버레이하여 제2 합성 영상을 생성할 수 있다. 1540 단계에서 서버는 제2 합성 영상을 사용자 장치에 송신할 수 있고, 사용자 장치는 1550 단계에서 제2 합성 영상을 표시할 수 있다. 도 16a에 도시된 바와 같이 제1 선수 영상의 일부분과 제2 선수 영상의 일부분이 오버레이될 수 있고, 오버레이 된 위치는 결국 제1 선수 및 제2 선수의 실제 기록을 재현한 것에 대응된다. 도 16a에 도시된 바와 같이 레이스 초반에는 제1 선수(1610a)가 제2 선수(1620a)보다 뒤쳐지는 반면, 도 16b에 도시된 바와 같이 레이스 중반에서 는 제1 선수(1610b)가 제2 선수(1620b)보다 앞서는 것을 확인할 수 있다. 선수는 다른 선수와 자신의 페이스를 비교함으로써 자신의 페이스 전략 수립에 참고할 수 있다. 본 발명의 다양한 실시예에 따라서, 드론은 영상 데이터로부터 육상 트랙의 출발선을 인식한 것을 기초로, 운동 선수가 운동을 시작한 후 운동 선수를 따라 비행하면서, 자신의 비행 속도 및 비행 방향에 기초하여, 드론이 출 발선으로부터 직선 주로에서의 운동 선수의 진행 방향으로 몇 m 전진한 상태인지 계산할 수 있다. 또한, 드론 은 출발선으로부터 드론이 전진한 거리, 사용자와 드론 사이의 거리, 및 선수의 정면 방향을 기준으로 선수로부 터 드론을 향하는 방향이 이루는 각도에 기초하여 선수가 출발선으로부터 몇 m 전진한 상태인지 계산하고, 이를 선수 기록으로서 저장할 수 있다. 드론은 특정한 방향으로 빛을 조사할 수 있는 광원 및 광원 제어 장치를 더 구비하고, 제2 선수가 운동하는 동안 제2 선수를 따라 비행하면서, 제2 선수의 선수 기록을 확인함과 동시에, 제1 선수의 선수 기록에 대응하는 위치에 빛이 조사되어, 주로 상에서 제1 선수의 선수 기록에 대응되는 위치가 제2 선수에게 표시되도록 광원을 제어할 수 있다. 본 발명의 다양한 실시예에 따른, 사용자 장치, 서버, 및 드론을 포함하는, 운동 영상 획득 시스템에서 수행되 는 운동 영상 획득 방법은, 상기 사용자 장치에서 사용자로부터, 상기 드론의 비행 높이를 특정하는 제1 값, 상 기 드론의 제1 센서와 제1 선수의 표면 상의 제1 지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수의 정 면 방향을 기준으로 상기 제1 지점으로부터 상기 드론의 상기 제1 센서를 향하는 방향의 각변위를 특정하는 제3 값을 입력받는 단계 - 상기 제1 지점은 상기 제1 선수의 표면 상에서 상기 드론과의 거리가 가장 짧은 지점이고, 상기 제3 값은 0도 이상 360도 미만의 값을 가지고, 상기 제1 센서는 제1 거리 센서 및 카메라를 포 함함 -, 상기 사용자 장치가 상기 서버 및 상기 드론에 상기 제1 값, 상기 제2 값, 및 상기 제3 값을 전송하는 단계; 상기 드론이 상기 제1 값과 동일한 높이에 있다는 정보를 확인하는 단계; 상기 드론의 적어도 하나의 센서의 측정값 및 상기 제1 센서에 포함된 카메라에 의하여 획득된 영상 데이터를 적어도 하나의 수집 데이터로서 획득하는 단계 -상기 적어도 하나의 센서는 제1 센서, 방사형으로 배치된 복수의 거리 센서, 및 IMU 센서를 포 함함 -; 상기 적어도 하나의 수집 데이터를 분석하여 상기 제2 값 및 상기 제3 값에 대응되는 위치에 상기 드론 을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하는 단계; 상기 제2 값 및 상기 제3 값에 대응되는 위치 에 상기 드론이 위치한다고 확인되는 것에 응답하여, 초기 위치 설정 완료 신호를 생성하는 단계; 상기 초기 위 치 설정 완료 신호에 응답하여 상기 드론이 스피커를 통하여 미리 설정된 소리를 출력하고, 상기 제1 선수가 운 동하는 동안 상기 제1 선수의 정면 방향으로 비행하면서 상기 적어도 하나의 수집 데이터를 획득하는 단계; 상 기 적어도 하나의 수집 데이터를 분석하여, 상기 제1 선수가 운동하는 동안 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터 를 도출하는 단계; 및 상기 적어도 하나의 수집 데이터에 기초하여, 상기 적어도 하나의 수집 데이터에 포함되 는 영상 데이터 중 상기 드론이 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에서 비행한 시간에 대응되는 부분을 추출하여 운동 영상으로서 저장하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 방법은: 0도 이상 360도 미만의 값을 갖는, 미리 결정된 복수의 기설 정 각도에서 촬영된 복수의 인체 이미지를 포함하는 인체 이미지 데이터베이스를 저장하는 단계; 상기 인체 이 미지 데이터베이스에 포함된 복수의 인체 이미지 각각으로부터 관절점 정보를 추출하는 단계; 상기 복수의 인체 이미지가 촬영된 각도 및 상기 복수의 인체 이미지로부터 추출된 관절점 정보를 학습함으로써 제1 인공지능 모 델을 생성하는 단계; 상기 제2 값 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위하여: 상기 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지, 상기 드론으로 하여금 제자리에서 지면과 수직인 회전축을 중심으로 회전하도록 하는 명령 데이터를 도출하는 단계; 상기 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치하는 것으로 확인되면, 상기 제1 거리 센서의 측정값이 상기 제2 값에 대응될 때까 지, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제2 값보다 작은 경우 상기 드론으로 하여금 상기 제1 거리 센서가 향하는 제1 방향과 반대 방향으로 이동하도록 하는 명령 데이터를 상기 사용자 장치에 송신하고, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제2 값보다 큰 경우 상기 드론으로 하여금 상기 제1 방향으 로 이동하도록 하는 명령 데이터를 도출하는 단계; 상기 제1 거리 센서의 측정값이 상기 제2 값에 대응된다고 확인되면, 상기 복수의 기설정 각도 중 상기 제3 값보다 작으면서 가장 큰 값을 갖는 제1 각도를 확인하는 단계; 상기 제1 인공지능 모델에 기초하여 상기 제1 각도에서 촬영된 것으로 확인되는 이미지에 대응되는 상기 영상 데이터가 수신될 때까지, 상기 드론으로 하여금 상기 제1 선수의 정면 방향을 기준으로 상기 제1 지점으로 부터 상기 드론을 향하는 방향의 각변위를 증가시키도록 하는 각도 증가 명령을 명령 데이터로서 도출하는 단계 - 상기 각도 증가 명령은 상기 제1 방향과 수직인 방향으로 미리 설정된 제1 거리만큼 드론을 이동시키는 명령, 상기 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지 상기 드론으로 하여금 제자리에서 지면과 평행한 평면 상에서 회전하도록 하는 명령, 및 상기 제1 거리 센서의 측정값이 상기 제2 값에 대응될 때 까지 상기 드론을 상기 제1 방향으로 이동시키는 명령을 포함함 -; 및 상기 IMU 센서가 나타내는 각도 값이 상 기 제3 값에서 상기 제1 각도를 뺀 값이 될 때까지, 상기 각도 증가 명령을 명령 데이터로서 도출하는 단계 를 더 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 제1 선수가 운동하는 동안의 상기 적어도 하나의 수집 데이터에 기초 하여, 미확인 물체가 상기 드론에 접근하는 것을 확인하는 단계; 상기 미확인 물체가 상기 드론에 접근하는 것 이 확인되는 것에 기초하여, 상기 미확인 물체가 상기 드론에 접근하는 방향인 제2 방향 및 상기 드론의 상단에 물체가 존재하는지 여부를 확인하는 단계; 상기 제1 센서로부터 상기 제1 지점을 향하는 방향과 상기 제2 방향 의 차가 미리 설정된 제2 각도 이하이고, 상기 드론의 상단에 물체가 존재하지 않는다고 확인되면, 상기 드론을 미리 설정된 제1 고도 이상의 고도로 급상승시키는 명령 데이터를 도출하는 단계; 상기 제1 센서로부터 상기 제 1 지점을 향하는 방향과 상기 제2 방향의 차가 미리 설정된 제2 각도 이하이고, 상기 드론의 상단에 물체가 존 재한다고 확인되면, 상기 드론의 모터 동작을 차단시키는 명령 데이터를 도출하는 단계; 및 상기 제2 방향과 상 기 제1 방향의 차가 미리 설정된 제2 각도보다 크면 상기 드론을 정지 비행시키는 명령 데이터를 도출하는 단계 를 더 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 방법은, 상기 제1 선수가 운동하는 동안, 영상 데이터에 대응되는 이 미지 내에서 명도가 미리 설정된 제1 명도 이하인 영역의 비중이 미리 설정된 비중 이상인 경우, 미리 설정된 제1 시간 동안 상기 드론의 모터 회전 속도, 기울기 각도, 및 진행 방향을 유지하도록 하는 명령 데이터를 도출 하는 단계; 상기 영상 데이터에 대응되는 이미지 내에서 명도가 미리 설정된 제1 명도 이하인 영역의 비중이 미 리 설정된 비중 이상인 상태가 미리 설정된 제2 시간 이상 지속되는 경우, 명령 데이터의 도출을 중단하고, 상기 사용자 장치에 드론을 수동 모드로 전환한다는 메시지를 송신하는 단계를 더 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 방법은, 초기 위치 설정 완료 신호를 생성하기 전, 정지한 상기 제1 선수의 상의 색상 평균값 및 하의 색상 평균값을 저장하는 단계; 상기 영상 데이터에 대응되는 이미지 내에서 상기 제1 선수와 상이한 제2 선수가 있는 것으로 확인되는 경우, 상기 제2 선수의 상의 색상 평균값 및 하의 색 상 평균값을 확인하는 단계; 상기 제2 선수의 상의 색상 평균값과 상기 제1 선수의 상의 색상 평균값의 차가 미 리 설정된 제4 값 이하이거나, 상기 제2 선수의 하의 색상 평균값과 상기 제1 선수의 하의 색상 평균값의 차가 미리 설정된 제5 값 이하인 경우, 상기 제2 선수의 이동 방향 및 상기 제1 선수의 이동 방향을 확인하는 단계; 및 상기 제2 선수가 상기 드론의 제2 시간 동안의 평균 이동 방향과 동일 방향으로 이동하고, 상기 제1 선수가 상기 드론의 제2 시간 동안의 이동 방향과 상이한 방향으로 이동하는 경우, 상기 제2 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터 를 도출하는 단계; 를 더 포함할 수 있다. 본 발명의 다양한 실시예에 따른, 운동 데이터 제공 방법은, 드론으로 하여금 정지한 제1 선수 주위를 회전하도 록 하는 적어도 하나의 명령 데이터를 도출하는 단계; 상기 드론이 정지한 상기 제1 선수 주위를 회전하면서 상 기 드론에 포함된 적어도 하나의 센서의 측정값 및 상기 드론에 포함된 카메라에 의하여 획득된 영상 데이터를 포함하는 제1 수집 데이터를 적어도 하나 획득하는 단계; 상기 적어도 하나의 제1 수집 데이터에 기초하여 상기 제1 선수의 3차원 인체 모델을 생성하는 단계; 상기 사용자 장치에서, 상기 드론의 비행 높이를 특정하는 제1 값, 상기 드론의 제1 센서와 제1 선수의 표면 상의 제1 지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수 의 정면 방향을 기준으로 상기 제1 지점으로부터 상기 드론의 상기 제1 센서를 향하는 방향의 각변위도를 특정 하는 제3 값을 입력받고, 상기 서버 및 상기 드론에 상기 제1 값, 상기 제2 값, 및 상기 제3 값을 전송하는 단 계 - 상기 제1 지점은 상기 제1 선수의 표면 상에서 상기 드론과의 거리가 가장 짧은 지점이고, 상기 제3 값은 0도 이상 360도 미만의 값을 가지고, 상기 제1 센서는 제1 거리 센서 및 상기 카메라를 포함함 -; 상기 드론이, 상기 제1 선수가 운동하는 동안 상기 제1 선수의 정면 방향으로 비행하면서 상기 드론에 포함된 적어도 하나의 센서의 측정값 및 상기 카메라에 의하여 획득된 영상 데이터를 포함하는 제2 수집 데이터를 적어도 하나 획득하 는 단계; 상기 적어도 하나의 제2 수집 데이터를 분석하여, 상기 제1 선수가 운동하는 동안 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하는 단계; 상기 적어도 하나의 제2 수집 데이터에 기초하여, 상기 적어도 하나의 제 2 수집 데이터에 포함되는 영상 데이터 중 상기 드론이 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에서 비행한 시간에 대응되는 부분을 추출하여 운동 영상으로서 저장하는 단계; 상기 운동 영상으로부터 관 절점을 추출하는 단계; 상기 운동 영상으로부터 추출된 관절점 및 상기 제1 선수의 3차원 인체 모델에 기초하 여, 상기 제1 선수의 관절 가동 범위, 관절 가동 속도, 및 주기적으로 반복되는 동작에서 상기 관절 가동 범위 및 상기 관절 가동 속도의 주기별 변화를 나타내는 운동 데이터를 확인하는 단계; 및 상기 사용자 장치에서 상 기 운동 데이터를 표시하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 운동 영상에 상기 운동 데이터를 오버레이하여 합성 영상을 생성하고, 생성된 상기 합성 영상을 사용자 장치에 전송하는 단계를 더 포함하고, 상기 사용자 장치에서 상기 운동 데이터 를 표시하는 단계는 상기 합성 영상을 표시하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 방법은: 0도 이상 360도 미만의 값을 갖는, 미리 결정된 복수의 기설 정 각도에서 촬영된 복수의 인체 이미지를 포함하는 인체 이미지 데이터베이스를 저장하는 단계; 상기 인체 이 미지 데이터베이스에 포함된 복수의 인체 이미지 각각으로부터 관절점 정보를 추출하는 단계; 및 상기 복수의 인체 이미지가 촬영된 각도 및 상기 복수의 인체 이미지로부터 추출된 관절점 정보를 학습함으로써 제1 인공지 능 모델을 생성하는 단계; 를 더 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 드론으로 하여금 정지한 제1 선수 주위를 회전하도록 하는 적어도 하 나의 명령 데이터를 도출하는 단계는; 상기 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치할 때 까지, 상기 드론으로 하여금 제자리에서 지면과 수직인 회전축을 중심으로 회전하도록 하는 명령 데이터를 도출 하는 단계; 상기 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치하는 것으로 확인되면, 상기 제1 거리 센서의 측정값이 미리 설정된 제1 거리에 대응될 때까지, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제1 거리보다 작은 경우 상기 드론으로 하여금 상기 제1 거리 센서가 향하는 제1 방향과 반대 방향으로 이 동하도록 하는 명령 데이터를 도출하고, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제1 거리보다 큰 경우 상기 드론으로 하여금 상기 제1 방향으로 이동하도록 하는 명령 데이터를 도출하는 단계; 상기 제1 거리 센서의 측정값이 상기 제1 거리에 대응된다고 확인되면, 상기 제1 인공지능 모델에 기초하여, 상기 복수의 기설정 각도 중 가장 작은 각도인 제1 각도에서 촬영된 것으로 확인되는 이미지에 대응되는 상기 영상 데이터가 수 신될 때까지, 상기 드론으로 하여금 상기 제1 선수의 정면 방향을 기준으로 상기 제1 지점으로부터 상기 드론을 향하는 방향의 각변위를 증가시키도록 하는 각도 증가 명령을 명령 데이터로서 도출하는 단계 - 상기 각도 증가 명령은 상기 제1 방향과 수직인 방향으로 미리 설정된 제1 거리만큼 드론을 이동시키는 명령, 상기 제1 선수가 상기 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지 상기 드론으로 하여금 제자리에서 지면과 평행한 평 면 상에서 회전하도록 하는 명령, 및 상기 제1 거리 센서의 측정값이 상기 제2 값에 대응될 때까지 상기 드론을 상기 제1 방향으로 이동시키는 명령을 포함함 -; 상기 제1 인공지능 모델에 기초하여, 상기 복수의 기설정 각도 중 두 번째로 작은 각도인 제2 각도에서 촬영된 것으로 확인되는 이미지에 대응되는 상기 영상 데이터가 수신될 때까지, 상기 각도 증가 명령을 명령 데이터로서 도출하는 단계; 및 상기 제1 각도에서 촬영된 이미지에 대응되 는 영상 데이터가 수신된 후, 상기 제2 각도에서 촬영된 이미지에 대응되는 영상 데이터가 수신되기 전까지, 상 기 제1 각도에 상기 드론에 포함되는 IMU 센서가 나타내는 각도 값을 더한 값을 상기 제1 선수의 정면 방향과 상기 제1 지점으로부터 상기 드론의 상기 제1 센서를 향하는 방향 사이의 각도로서 확인하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 복수의 기설정 각도는, 0도, 90도, 180도, 및 270도를 포함할 수 있다. 본 발명의 다양한 실시예에 따른, 스포츠 훈련 영상에 기초한 합성 영상 제공 방법은: 제1 선수의 운동 영상을 획득하는 단계; 상기 제1 선수의 운동 영상으로부터 상기 제1 선수의 운동 데이터를 확인하는 단계; 상기 제1 선수의 운동 영상을 운동 동작의 주기별로 파싱하여 상기 제1 선수에 대응하는 복수의 부분 운동 영상을 획득하 는 단계; 상기 제1 선수에 대응하는 상기 복수의 부분 운동 영상 중 제1 부분 운동 영상과 제2 부분 운동 영상 의 투명도를 증가시키고, 투명도를 증가시킨 상기 제1 부분 운동 영상에 투명도를 증가시킨 상기 제2 부분 운동 영상, 상기 제1 부분 운동 영상에 대응되는 운동 데이터, 및 상기 제2 부분 운동 영상에 대응되는 운동 데이터 를 오버레이하여 제1 합성 영상을 생성하는 단계 - 상기 운동 데이터는 상기 제1 선수의 관절 가동 범위를 포함 함 -; 상기 제1 합성 영상을 사용자 장치에 송신하는 단계; 및 상기 사용자 장치에서 상기 제1 합성 영상을 표 시하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 운동 데이터는 상기 제1 선수의 운동 영상에서 추출된 상기 제1 선수 의 신체의 윤곽선을 더 포함하고, 상기 합성 영상에서, 상기 제1 부분 운동 영상에 대응되는 운동 데이터와 상 기 제2 부분 운동 영상에 대응되는 운동 데이터는 상이한 색상으로 표시될 수 있다. 본 발명의 다양한 실시예에 따라서, 제2 선수의 운동 영상을 획득하는 단계; 상기 제2 선수의 운동 영상으로부 터 상기 제2 선수의 운동 데이터를 확인하는 단계; 상기 제2 선수의 운동 영상을 운동 동작의 주기별로 파싱하 여 상기 제2 선수에 대응하는 복수의 부분 운동 영상을 획득하는 단계; 상기 제2 선수에 대응하는 상기 복수의 부분 운동 영상 중 상기 제1 부분 운동 영상이 촬영된 시점에 대응되는 제3 부분 운동 영상의 투명도를 증가시 키고, 투명도를 증가시킨 상기 제1 부분 운동 영상에 투명도를 증가시킨 상기 제3 부분 운동 영상, 상기 제1 부 분 운동 영상에 대응되는 운동 데이터, 및 상기 제3 부분 운동 영상에 대응되는 운동 데이터를 오버레이하여 제 2 합성 영상을 생성하는 단계; 및 상기 제2 합성 영상을 사용자 장치에 송신하는 단계, 및 상기 사용자 장치에 서 상기 제2 합성 영상을 표시하는 단계 를 더 포함할 수 있다. 다양한 실시예에 따라서, 상기 방법은: 상기 사용자 장치에서, 드론의 비행 높이를 특정하는 제1 값, 상기 드론의 제1 센서와 제1선수의 표면 상의 제1 지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수의 정면 방향을 기준으로 상기 제1 지점으로부터 상기 드론의 상기 제1 센서를 향하는 방향의 각변위를 특정하는 제3 값을 입력받고, 상기 서버 및 상기 드론에 상기 제1 값, 상기 제2 값, 및 상기 제3 값을 전송하는 단계 - 상기 제1 지점은 상기 제1 선수의 표면 상에서 상기 드론과의 거리가 가장 짧은 지점이고, 상기 제3 값은 0도 이상 360도 미만의 값을 가지고, 상기 제1 센서는 제1 거리 센 서 및 카메라를 포함함 -; 상기 드론이, 상기 제1 선수가 운동하는 동안 상기 제1 선수의 정면 방향으로 비행 하면서 상기 드론에 포함된 적어도 하나의 센서의 측정값 및 상기 카메라에 의하여 획득된 영상 데이터를 포함 하는 제1 수집 데이터를 적어도 하나 획득하는 단계; 및 상기 적어도 하나의 제1 수집 데이터를 분석하여, 상기 제1 선수가 운동하는 동안 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위 치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하는 단계; 를 더 포함하고, 제1 선수의 운동 영상을 획득하는 단계는, 상기 적어도 하나의 제1 수집 데이터에 기초하여, 상기 적어도 하나의 제1 수집 데이터에 포함되는 영상 데이터 중 상기 드론이 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 서 비행한 시간에 대응되는 부분을 추출하여 상기 제1 선수의 운동 영상으로서 저장하는 단계를 포함할 수 있다.본 발명의 다양한 실시예에 따라서, 상기 방법은, 상기 제1 선수가 운동을 시작하기 전에: 상기 드론으로 하여 금 정지한 상기 제1 선수의 주위를 회전하도록 하는 적어도 하나의 명령 데이터를 도출하는 단계; 상기 드론이 정지한 제1 선수 주위를 회전하면서 상기 드론에 포함된 적어도 하나의 센서의 측정값 및 상기 카메라에 의하여 획득된 영상 데이터를 포함하는 제2 수집 데이터를 획득하는 단계; 및 상기 적어도 하나의 제2 수집 데이터에 기초하여 상기 제1 선수의 3차원 인체 모델을 생성하는 단계 를 더 포함하고, 상기 제1 선수의 운동 영상으로부 터 추출된 관절점에 기초하여, 상기 제1 선수의 관절 가동 범위를 확인하는 단계는, 상기 운동 영상으로부터 추 출된 관절점 및 상기 제1 선수의 상기 3차원 인체 모델에 기초하여 상기 제1 선수의 관절 가동 범위를 확인하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따른, 스포츠 훈련 영상에 기초한 합성 영상 제공 방법은: 제1 선수가 제1 운동을 수행하는 동안 상기 제1 선수의 정면 방향으로 비행하는 드론에 의하여 촬영된 제1 영상 데이터에 기초하여, 제 1 운동 영상을 획득하는 단계; 상기 제1 운동 영상으로부터 배경 영역과 제1 선수 영역을 분리하여 제1 배경 영 상 및 제1 선수 영상을 획득하는 단계; 상기 드론의 비행 속도 및 상기 제1 영상 데이터가 촬영된 시간 정보에 기초하여 상기 제1배경 영상의 복수의 프레임을 합성하여 배경 이미지를 생성하는 단계; 상기 드론의 비행 속도 및 상기 제1 영상 데이터가 촬영된 시간 정보에 기초하여, 상기 제1 선수 영상의 적어도 하나의 프레임을 상기 배경 이미지 상에 오버레이하여 제1 합성 영상을 생성하는 단계; 및 상기 제1 합성 영상을 사용자 장치에 송신 하는 단계, 및 상기 사용자 장치에서 상기 제1 합성 영상을 표시하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 방법은: 제2 선수가 상기 제1 운동을 수행하는 동안 상기 제2 선수의 정면 방향으로 비행하는 드론에 의하여 촬영된 제2 영상 데이터에 기초하여, 제2 운동 영상을 획득하는 단계; 상기 제2 운동 영상으로부터 배경 영역과 제2 선수 영역을 분리하여 제2 선수 영상을 획득하는 단계; 상기 드 론의 비행 속도 및 상기 제2 영상 데이터가 촬영된 시간 정보에 기초하여, 상기 제2 선수 영상의 적어도 하나의 프레임을 상기 제1 합성 영상 상에 오버레이하여 제2 합성 영상을 생성하는 단계; 상기 제2 합성 영상을 사용자 장치에 송신하는 단계; 및 상기 사용자 장치에서 상기 제2 합성 영상을 표시하는 단계 를 더 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 제2 합성 영상을 생성하는 단계는: 상기 제2 선수 영상의 상기 복수의 프레임의 투명도 또는 색상을 변경하는 단계; 및 상기 투명도 또는 색상이 변경된 상기 복수의 프레임을 상기 제1 합성 영상 상에 오버레이하여 제2 합성 영상을 생성하는 단계; 를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서 상기 방법은: 상기 사용자 장치에서, 드론의 비행 높이를 특정하는 제1 값, 상기 드론의 제1 센서와 제1선수의 표면 상의 제1 지점 사이의 거리를 특정하는 제2 값, 및 상기 제1 선수의 정 면 방향을 기준으로 상기 제1 지점으로부터 상기 드론의 상기 제1 센서를 향하는 방향의 각변위를 특정하는 제3 값을 입력받고, 상기 서버 및 상기 드론에 상기 제1 값, 상기 제2 값, 및 상기 제3 값을 전송하는 단계 - 상기 제1 지점은 상기 제1 선수의 표면 상에서 상기 드론과의 거리가 가장 짧은 지점이고, 상기 제3 값은 0도 이상 360도 미만의 값을 가지고, 상기 제1 센서는 제1 거리 센서 및 카메라를 포함함 -; 상기 드론이, 상기 제1 선 수가 상기 제1 운동을 시작하기 전, 상기 드론에 포함된 적어도 하나의 센서의 측정값 및 상기 카메라에 의하여 획득된 제2 영상 데이터를 포함하는 제2 수집 데이터를 적어도 하나 획득하는 단계; 상기 적어도 하나의 제2 수집 데이터를 분석하여, 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위 치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하는 단계;- 상기 드론이, 상기 제1 선수 가 상기 제1 운동을 수행하는 동안, 상기 제1 선수의 정면 방향으로 비행하면서 상기 드론에 포함된 적어도 하 나의 센서의 측정값 및 상기 카메라에 의하여 획득된 상기 제1 영상 데이터를 포함하는 제1 수집 데이터를 적어 도 하나 획득하는 단계; 및 상기 적어도 하나의 제1 수집 데이터를 분석하여, 상기 제1 선수가 상기 제1 운동을 수행하는 동안, 상기 제1 선수를 기준으로 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도출하는 단계; 를 더 포함하고, 상기 제1 운동 영상을 획득하는 단계는, 상기 적어도 하나의 제1 수집 데이터에 기초하여, 상기 적어도 하나의 제1 수집 데이터에 포 함되는 제1 영상 데이터 중 상기 드론이 상기 제1 값, 상기 제2 값, 및 상기 제3 값에 대응되는 위치에서 비행 한 시간에 대응되는 부분을 추출하여 상기 제1 선수의 운동 영상으로서 저장하는 단계를 포함할 수 있다. 본 발명의 다양한 실시예에 따라서, 상기 방법은, 상기 제1 선수가 운동을 시작하기 전에: 0도 이상 360도 미 만의 값을 갖는, 미리 결정된 복수의 기설정 각도에서 촬영된 복수의 인체 이미지를 포함하는 인체 이미지 데이 터베이스를 저장하는 단계; 상기 인체 이미지 데이터베이스에 포함된 복수의 인체 이미지 각각으로부터 관절점 정보를 추출하는 단계; 및 상기 복수의 인체 이미지가 촬영된 각도 및 상기 복수의 인체 이미지로부터 추출된 관절점 정보를 학습함으로써 제1 인공지능 모델을 생성하는 단계; 를 포함하고, 상기 적어도 하나의 제2 수집 데이터를 분석하여, 상기 제1 선수가 상기 제1 운동을 수행하는 동안 상기 제1 선수를 기준으로 상기 제1 값,상기 제2 값, 및 상기 제3 값에 대응되는 위치에 상기 드론을 위치시키기 위한 적어도 하나의 명령 데이터를 도 출하는 단계는: 상기 제1 선수가 상기 제2 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지, 상기 드론으 로 하여금 제자리에서 지면과 수직인 회전축을 중심으로 회전하도록 하는 명령 데이터를 도출하는 단계; 상기 제1 선수가 상기 제2 영상 데이터에 대응되는 영상의 중앙에 위치하는 것으로 확인되면, 상기 제1 거리 센서의 측정값이 상기 제2 값에 대응될 때까지, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제2 값보다 작은 경우 상기 드론으로 하여금 상기 제1 거리 센서가 향하는 제1 방향과 반대 방향으로 이동하도록 하는 명령 데이 터를 도출하고, 상기 제1 센서에 포함된 거리 센서의 측정값이 상기 제2 값보다 큰 경우 상기 드론으로 하여금 상기 제1 방향으로 이동하도록 하는 명령 데이터를 도출하는 단계; 상기 제1 거리 센서의 측정값이 상기 제2 값 에 대응된다고 확인되면, 상기 복수의 기설정 각도 중 상기 제3 값보다 작으면서 가장 큰 값을 갖는 제1 각도를 확인하는 단계; 상기 제1 인공지능 모델에 기초하여 상기 제1 각도에서 촬영된 것으로 확인되는 이미지에 대응 되는 상기 제2 영상 데이터가 수신될 때까지, 상기 드론으로 하여금 상기 제1 선수의 정면 방향을 기준으로 상 기 제1 지점으로부터 상기 드론을 향하는 벡터의 각변위를 증가시키도록 하는 각도 증가 명령을 명령 데이터로 서 도출하는 단계 - 상기 각도 증가 명령은 상기 제1 방향과 수직인 방향으로 미리 설정된 제1 거리만큼 드론을 이동시키는 명령, 상기 제1 선수가 상기 제2 영상 데이터에 대응되는 영상의 중앙에 위치할 때까지 상기 드론으 로 하여금 제자리에서 지면과 평행한 평면 상에서 회전하도록 하는 명령, 및 상기 제1 거리 센서의 측정값이 상 기 제2 값에 대응될 때까지 상기 드론을 상기 제1 방향으로 이동시키는 명령을 포함함 -; 및 상기 드론에 포함 되는 IMU 센서가 나타내는 각도 값이 상기 제3 값에서 상기 제1 각도를 뺀 값이 될 때까지, 상기 각도 증가 명 령을 명령 데이터로서 도출하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0010005", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0010005", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 발명의 다양한 실시예에 따른 운동 영상 획득 시스템을 도시한다. 도 1b는 본 발명의 다양한 실시예에 따른 운동 영상 획득 시스템에 포함되는 서버의 구성을 도시한다.도 2a 및 도 2b는 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 운동 영상 획득 방법 을 도시한다. 도 2c 및 도 2d는 본 발명의 다양한 실시예에 따른, 운동 영상 획득 방법에서 제1 값, 제2 값, 및 제3 값의 정 의를 도시한다. 도 3a 및 도 3b는 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 방법을 도시한다. 도 4a는 본 발명의 다양한 실시예에 따른, 미리 결정된 복수의 기설정 각도의 예시를 도시한다. 도 4b는 본 발명의 다양한 실시예에 따른, 제1 인공지능 모델의 입력 및 출력을 도시한다. 도 5a는 본 발명의 다양한 실시예에 따른, 드론을 도시한다. 도 5b 및 도 5c는 본 발명의 다양한 실시예에 따른, 드론이 제자리에서 회전하는 동작을 도시한다. 도 6a 내지 6d는 본 발명의 다양한 실시예에 따른, 각도 증가 명령에 따른 드론의 동작을 도시한다. 도 7은 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 회피 기동 방법을 도시한다. 도 8은 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 3차원 인체 모델 생성 방법을 도 시한다. 도 9는 본 발명의 다양한 실시예에 따른, 운동 영상 획득 시스템에서 수행되는 운동 데이터 획득 방법을 도시한 다. 도 10a 및 도 10b는 본 발명의 다양한 실시예에 따른, 운동 데이터가 표시되는 예시를 도시한다. 도 11은 본 발명의 다양한 실시예에 따른 합성 영상 제공 방법을 도시한다. 도 12a 및 도 12b는 본 발명의 다양한 실시예에 따라 제공되는 합성 영상의 예시를 도시한다. 도 13은 본 발명의 다양한 실시예에 따른 합성 영상 제공 방법을 도시한다. 도 14a는 본 발명의 다양한 실시예에 따라 획득되는 배경 영상 및 선수 영상의 예시를 도시한다. 도 14b는 본 발명의 다양한 실시예에 따라 획득되는 배경 이미지의 예시를 도시한다. 도 14c는 본 발명의 다양한 실시예에 따라 획득되는 합성 영상의 예시를 도시한다. 도 15는 본 발명의 다양한 실시예에 따른 합성 영상 제공 방법을 도시한다. 도 16a 및 도 16b는 본 발명의 다양한 실시예에 따라 제공되는 합성 영상의 예시를 도시한다."}
