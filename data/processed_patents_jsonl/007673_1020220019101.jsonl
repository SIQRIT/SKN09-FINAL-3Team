{"patent_id": "10-2022-0019101", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0158598", "출원번호": "10-2022-0019101", "발명의 명칭": "AI에 기반한 프레임 보간 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "최나래"}}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상의 연속적인 프레임들 중에서, 제1 프레임에 대한 복수의 레벨의 제1 특징 맵들 및 제2 프레임에 대한 복수의 레벨의 제2 특징 맵들을 획득하는 단계;플로우 예측 신경망을 통해, 소정 레벨의 제1 특징 맵에서 제2 특징 맵으로의 제1 옵티컬 플로우 및 상기 소정레벨의 상기 제2 특징 맵에서 상기 제1 특징 맵으로의 제2 옵티컬 플로우를 획득하는 단계;상기 제1 옵티컬 플로우를 이용하여 상기 제1 특징 맵이 순방향 워핑된 제1 순방향 워핑 특징 맵을 획득하고,상기 제2 옵티컬 플로우를 이용하여 상기 제2 특징 맵이 순방향 워핑된 제2 순방향 워핑 특징 맵을 획득하는 단계; 상기 제1 순방향 워핑 특징 맵을 이용하여 상기 제1 옵티컬 플로우를 업데이트하고, 상기 제2 순방향 워핑 특징맵을 이용하여 상기 제2 옵티컬 플로우를 업데이트하는 단계;상기 업데이트된 제1 옵티컬 플로우를 상기 소정 레벨의 상위 레벨에 대응하도록 업스케일하여 상위 레벨의 제1옵티컬 플로우를 획득하고, 상기 업데이트된 제2 옵티컬 플로우를 상기 상위 레벨에 대응하도록 업스케일하여상위 레벨의 제2 옵티컬 플로우를 획득하는 단계;보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬플로우를 이용하여, 상기 제1 프레임과 상기 제2 프레임 사이의 제3 프레임에 대한 AI 기반 프레임 보간 필터를결정하는 단계; 및상기 제1 프레임, 상기 제2 프레임, 및 상기 AI 기반 프레임 보간 필터를 이용하여, 상기 제3 프레임을 획득하는 단계를 포함하는 것을 특징으로 하는 AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 상위 레벨은 최상위 레벨이고, 상기 최상위 레벨은 상기 제1 프레임 및 상기 제2 프레임에 대응하는 레벨인, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,최상위 레벨에 대응하는 제1 프레임의 제1 특징 맵 및 최상위 레벨에 대응하는 제2 프레임의 제2 특징 맵은 제1신경망을 통해 획득되고,상기 최상위 레벨의 아래 레벨들의 제1 특징 맵들 및 상기 최상위 레벨의 아래 레벨들의 제2 특징 맵들은 다운샘플링 신경망을 통해 획득되고,상기 복수의 레벨의 상기 제1 특징 맵들 및 상기 복수의 레벨의 상기 제2 특징 맵들은 상기 최상위 레벨의 아래레벨들의 제1 특징 맵들 및 상기 최상위 레벨의 아래 레벨들의 제2 특징 맵들인, AI에 기반한 프레임 보간방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 플로우 예측 신경망을 통해 상기 상위 레벨의 제1 옵티컬 플로우, 상기 제2 옵티컬 플로우를 획득하는 단계는:상기 소정 레벨의 제1 중요도 가중치를 획득하되, 상기 제1 중요도 가중치는 상기 소정 레벨의 제1 특징 맵의공개특허 10-2022-0158598-3-복수의 픽셀들이 상기 소정 레벨의 제2 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타내는 단계;상기 소정 레벨의 제2 중요도 가중치를 획득하되, 상기 제2 중요도 가중치는 상기 소정 레벨의 제2 특징 맵의복수의 픽셀들이 상기 소정 레벨의 제1 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타내는 단계;를 더포함하는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 소정 레벨의 상기 제1 중요도 가중치를 추가로 이용하여, 상기 제1 순방향 워핑 특징 맵이 획득되고, 상기 소정 레벨의 상기 제2 중요도 가중치를 추가로 이용하여, 상기 제2 순방향 워핑 특징 맵이 획득되는, AI에기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 상위 레벨의 상기 제1 옵티컬 플로우에 기초하여 상기 상위 레벨의 제1 중요도 가중치가 획득되고, 상기상위 레벨의 상기 제2 옵티컬 플로우에 기초하여 상기 상위 레벨의 제2 중요도 가중치가 획득되는, AI에 기반한프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 4 항에 있어서,상기 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2옵티컬 플로우를 이용하여, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는:상기 상위 레벨의 제1 옵티컬 플로우, 상기 상위 레벨의 제2 옵티컬 플로우, 상기 상위 레벨의 제1 중요도 가중치, 상기 상위 레벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 상기 제3 프레임에서상기 제1 프레임으로의 제1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬플로우를 획득하는 단계;상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 상기 제3 프레임의 시간 t에 기초한 순방향워핑된 제1 프레임, 상기 시간 t에 기초한 순방향 워핑된 제2 프레임, 상기 시간 t에 기초한 역방향 워핑된 제1프레임, 상기 시간 t에 기초한 역방향 워핑된 제2 프레임을 획득하는 단계; 및 순방향 워핑된 제1 프레임, 순방향 워핑된 제2 프레임, 역방향 워핑된 제1 프레임, 역방향 워핑된 제2 프레임에기초하여, 상기 보간 필터 신경망를 통해, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계;를 더 포함하는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 4 항에 있어서,상기 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2옵티컬 플로우를 이용하여, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는:상기 상위 레벨의 제1 옵티컬 플로우, 상기 상위 레벨의 제2 옵티컬 플로우, 상기 상위 레벨의 제1 중요도 가중치, 상기 상위 레벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 상기 제3 프레임에서상기 제1 프레임으로의 제1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬플로우를 획득하는 단계;상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 상기 제3 프레임의 시간 t에 기초한 순방향워핑된 제1 프레임, 상기 시간 t에 기초한 순방향 워핑된 제2 프레임을 획득하는 단계; 및 순방향 워핑된 제1 프레임, 순방향 워핑된 제2 프레임에 기초하여, 상기 보간 필터 신경망를 통해, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계;를 더 포함하는, AI에 기반한 프레임 보간 방법.공개특허 10-2022-0158598-4-청구항 9 제 4 항에 있어서,상기 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2옵티컬 플로우를 이용하여, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는:상기 상위 레벨의 제1 옵티컬 플로우, 상기 상위 레벨의 제2 옵티컬 플로우, 상기 상위 레벨의 제1 중요도 가중치, 상기 상위 레벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 상기 제3 프레임에서상기 제1 프레임으로의 제1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬플로우를 획득하는 단계;상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 상기 제3 프레임의 시간 t에 기초한 역방향워핑된 제1 프레임, 상기 시간 t에 기초한 역방향 워핑된 제2 프레임을 획득하는 단계; 및 역방향 워핑된 제1 프레임, 역방향 워핑된 제2 프레임에 기초하여, 상기 보간 필터 신경망를 통해, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계;를 더 포함하는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 소정 레벨의 상기 제1 옵티컬 플로우는 상기 제1 순방향 워핑 특징 맵과 상기 소정 레벨의 제2 특징 맵 사이의 제1 상관 값에 기초하여 업데이트되고,상기 소정 레벨의 상기 제2 옵티컬 플로우는 상기 제2 순방향 워핑 특징 맵과 상기 소정 레벨의 제1 특징 맵 사이의 제2 상관 값에 기초하여 업데이트되는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 소정 레벨의 제1 옵티컬 플로우의 미리 정해진 범위 내의 후보 픽셀들에 기초하여 상기 소정 레벨의 제1옵티컬 플로우가 업데이트되고, 상기 소정 레벨의 제2 옵티컬 플로우의 미리 정해진 범위 내의 후보 픽셀들에 기초하여 상기 소정 레벨의 제2옵티컬 플로우가 업데이트되는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 상기 미리 정해진 범위는 상기 소정 레벨의 특징 맵의 크기에 따라 달라지는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 제1 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중에서 사용자에 의해 설정된필터에 의해 결정되고,상기 제2 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중에서 사용자에 의해 설정된필터에 의해 결정되는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 제1 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중에서 훈련된 신경망에 기초한 필터에 의해 결정되고,상기 제2 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중에서 훈련된 신경망에 기초한 필터에 의해 결정되는, AI에 기반한 프레임 보간 방법.공개특허 10-2022-0158598-5-청구항 15 제 1 항에 있어서,상기 소정 레벨의 상기 제2 특징 맵의 미리 정해진 범위 내의 픽셀과의 상관 값 중 가장 높은 상관 값이 제1 상관 값으로 결정되고,상기 소정 레벨의 상기 제1 특징 맵의 미리 정해진 범위 내의 픽셀과의 상관 값 중 가장 높은 상관 값이 제2 상관 값으로 결정되는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1 항에 있어서,상기 복수의 레벨 중 최하위 레벨에서 초기에 획득되는 제1 옵티컬 플로우와 제2 옵티컬 플로우는 0으로 설정되는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 1 항에 있어서,상기 AI 기반 프레임 보간 필터는 상기 제1 프레임 및 상기 제2 프레임 내의 픽셀들 각각에 대응하는 하나의 필터 커널을 포함하는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 AI 기반 프레임 보간 필터를 결정하기 위해, 상기 보간 필터 신경망에 상기 제1 프레임 및 상기 제2 프레임의 문맥적 특징 맵이 추가로 입력되고,상기 문맥적 특징 맵은 상기 제1 프레임 및 상기 제2 프레임을 입력으로하는 제2 신경망의 출력 값과 상기 제1프레임 및 상기 제2 프레임을 입력으로하는 미리결정된 분류 네트워크의 출력 값의 합으로 결정되는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 1 항에 있어서,상기 AI 기반 프레임 보간 필터는 서브 픽셀의 계산을 위해 이용되는 바이리니어 보간에 대한 필터 커널을 더포함하는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 1 항에 있어서,상기 AI 기반 프레임 보간 필터는 제3 프레임의 시간 및 Z-map 중 적어도 하나에 기초한 필터 커널을 더 포함하는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 1 항에 있어서,상기 AI 기반 프레임 보간 필터는 상기 제1 프레임에 적용되는 제1 프레임 보간 필터와 상기 제2 프레임에 적용되는 제2 프레임 보간 필터를 포함하는, AI에 기반한 프레임 보간 방법."}
{"patent_id": "10-2022-0019101", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 1 항에 있어서,상기 제1 프레임에 대한 깊이 정보 및 상기 제2 프레임에 대한 깊이 정보가 존재하면, 상기 제1 프레임에 대한깊이 정보 및 상기 제2 프레임에 대한 깊이 정보가 상기 보간 필터 신경망에 추가로 입력되는, AI에 기반한 프레임 보간 방법.공개특허 10-2022-0158598-6-청구항 23 메모리; 및프로세서를 포함하고,상기 프로세서는:영상의 연속적인 프레임들 중에서, 제1 프레임에 대한 복수의 레벨의 제1 특징 맵들 및 제2 프레임에 대한 복수의 레벨의 제2 특징 맵들을 획득하는 단계;플로우 예측 신경망을 통해, 소정 레벨의 제1 특징 맵에서 제2 특징 맵으로의 제1 옵티컬 플로우 및 상기 소정레벨의 상기 제2 특징 맵에서 상기 제1 특징 맵으로의 제2 옵티컬 플로우를 획득하는 단계; 상기 제1 옵티컬 플로우를 이용하여 상기 제1 특징 맵이 순방향 워핑된 제1 순방향 워핑 특징 맵을 획득하고,상기 제2 옵티컬 플로우를 이용하여 상기 제2 특징 맵이 순방향 워핑된 제2 순방향 워핑 특징 맵을 획득하는 단계; 상기 제1 순방향 워핑 특징 맵을 이용하여 상기 제1 옵티컬 플로우를 업데이트하고, 상기 제2 순방향 워핑 특징맵을 이용하여 상기 제2 옵티컬 플로우를 업데이트하는 단계;상기 업데이트된 제1 옵티컬 플로우를 상기 소정 레벨의 상위 레벨에 대응하도록 업스케일하여, 상위 레벨의 제1 옵티컬 플로우를 획득하고, 상기 업데이트된 제2 옵티컬 플로우를 상기 상위 레벨에 대응하도록업스케일하여, 상위 레벨의 제2 옵티컬 플로우를 획득하는 단계;보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬플로우를 이용하여, 상기 제1 프레임과 상기 제2 프레임 사이의 제3 프레임에 대한 AI 기반 프레임 보간 필터를결정하는 단계; 및상기 제1 프레임, 상기 제2 프레임, 및 상기 AI 기반 프레임 보간 필터를 이용하여 상기 제3 프레임을 획득하는단계를 수행하는, AI에 기반한 프레임 보간 장치."}
{"patent_id": "10-2022-0019101", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상의 연속적인 프레임들 중에서, 제1 프레임에 대한 복수의 레벨의 제1 특징 맵들 및 제2 프레임에 대한 복수 의 레벨의 제2 특징 맵들을 획득하는 단계; 플로우 예측 신경망을 통해, 소정 레벨의 제1 특징 맵에서 제2 특징 맵으로의 제1 옵티컬 플로우 및 상기 소정 레벨의 상기 제2 특징 맵에서 상기 제1 특징 맵으로의 제2 옵티컬 플 (뒷면에 계속)"}
{"patent_id": "10-2022-0019101", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상의 프레임의 보간 방법 및 장치에 관한 것이다. 보다 구체적으로, 본 개시는 AI(Artificial Intelligence), 예를 들어, 신경망에 기반한 영상의 프레임을 보간하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0019101", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(artificial intelligence) 관련 기술의 발달과 고해상도/고화질의 영상을 재생, 저장할 수 있는 하드 웨어의 개발 및 보급에 따라, 신경망을 이용하여 영상을 고화질/고해상도 영상으로 효과적으로 복원하는 방법 및 장치에 대한 필요성이 증대하고 있다."}
{"patent_id": "10-2022-0019101", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예에 따른 AI에 기반한 영상의 프레임 보간 방법 및 장치는 플로우 예측 신경망에 기반하여 두 프레임 사이의 보다 정확한 양방향 옵티컬 플로우를 획득하고, 양방향 옵티컬 플로우에 기초하여 보간 필터 신경망을 통해 프레임의 각 픽셀 별로 다른 필터 계수를 가지는 AI 기반 보간 필터를 획득하고, AI 기반 보간 필터를 이 용하여 두 프레임 사이의 새로운 프레임을 보간함으로써, 영상의 복원 성능 및 화질을 향상시키는 것을 과제로 한다."}
{"patent_id": "10-2022-0019101", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 AI에 기반한 프레임 보간 방법은, 영상의 연속적인 프레임들 중에서, 제1 프레임에 대한 복수 의 레벨의 제1 특징 맵들 및 제2 프레임에 대한 복수의 레벨의 제2 특징 맵들을 획득하는 단계; 플로우 예측 신 경망을 통해, 소정 레벨의 제1 특징 맵에서 제2 특징 맵으로의 제1 옵티컬 플로우 및 상기 소정 레벨의 상기 제2 특징 맵에서 상기 제1 특징 맵으로의 제2 옵티컬 플로우를 획득하는 단계; 상기 제1 옵티컬 플로우를 이용하 여 제1 특징 맵이 순방향 워핑된 제1 순방향 워핑 특징 맵을 획득하고, 상기 제2 옵티컬 플로우를 이용하여 상 기 제2 특징 맵이 순방향 워핑된 제2 순방향 워핑 특징 맵을 획득하는 단계; 상기 제1 순방향 워핑 특징 맵을 이용하여 상기 제1 옵티컬 플로우를 업데이트하고, 상기 제2 순방향 워핑 특징 맵을 이용하여 상기 제2 옵티컬 플로우를 업데이트하는 단계; 상기 업데이트된 제1 옵티컬 플로우를 상기 소정 레벨의 상위 레벨에 대응하도록 업스케일하여, 상위 레벨의 제1 옵티컬 플로우를 획득하는 단계; 및 상기 업데이트된 제2 옵티컬 플로우를 상기 상위 레벨에 대응하도록 업스케일하여, 상위 레벨의 제2 옵티컬 플로우를 획득하는 단계; 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 상기 제1 프레임과 상기 제2 프레임 사이의 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계; 및 상기 제1 프레임, 상기 제2 프레임, 및 상기 AI 기반 프레임 보간 필터를 이용하여 상기 제3 프레임을 획득하는 단계를 포함할 수 있다. 상위 레벨은 최상위 레벨이고, 최상위 레벨은 제1 프레임 및 제2 프레임에 대응하는 레벨일 수 있다. 최상위 레벨에 대응하는 제1 프레임의 제1 특징 맵 및 최상위 레벨에 대응하는 제2 프레임의 제2 특징 맵은 제1 신경망을 통해 획득되고, 최상위 레벨의 아래 레벨들의 제1 특징 맵들 및 최상위 레벨의 아래 레벨들의 제2 특 징 맵들은 다운샘플링 신경망을 통해 획득되고, 복수의 레벨의 제1 특징 맵들 및 복수의 레벨의 제2 특징 맵들 은 최상위 레벨의 아래 레벨들의 제1 특징 맵들 및 최상위 레벨의 아래 레벨들의 제2 특징 맵들일 수 있다. 상기 플로우 예측 신경망을 통해 상기 상위 레벨의 제1 옵티컬 플로우, 상기 제2 옵티컬 플로우를 획득하는 단 계는: 상기 소정 레벨의 제1 중요도 가중치를 획득하되, 상기 제1 중요도 가중치는 상기 소정 레벨의 제1 특징 맵의 복수의 픽셀들이 상기 소정 레벨의 제2 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타내는 단계; 및 상기 소정 레벨의 제2 중요도 가중치를 획득하되, 상기 제2 중요도 가중치는 상기 소정 레벨의 제2 특징 맵 의 복수의 픽셀들이 상기 소정 레벨의 제1 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타내는 단계;를 포함할 수 있다. 상기 소정 레벨의 상기 제1 중요도 가중치를 추가로 이용하여, 상기 제1 순방향 워핑 특징 맵이 획득되고, 상기 소정 레벨의 상기 제2 중요도 가중치를 추가로 이용하여, 상기 제2 순방향 워핑 특징 맵이 획득될 수 있다. 상기 상위 레벨의 상기 제1 옵티컬 플로우에 기초하여 상기 상위 레벨의 제1 중요도 가중치가 획득되고, 상기 상위 레벨의 상기 제2 옵티컬 플로우에 기초하여 상기 상위 레벨의 제2 중요도 가중치가 획득될 수 있다. 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는: 상기 상위 레벨의 제1 옵티컬 플로우, 상기 상위 레벨의 제2 옵티컬 플로우, 상기 상위 레벨의 제1 중요도 가중치, 상기 상위 레 벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 상기 제3 프레임에서 상기 제1 프레임으 로의 제1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬 플로우를 획득하는 단계; 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 상기 제3 프레임의 시간 t에 대하여 순방 향 워핑된 제1 프레임, 상기 시간 t에 대하여 순방향 워핑된 제2 프레임, 상기 시간 t에 대하여 역방향 워핑된 제1 프레임, 상기 시간 t에 대하여 역방향 워핑된 제2 프레임을 획득하는 단계; 및 순방향 워핑된 제1 프레임, 순방향 워핑된 제2 프레임, 역방향 워핑된 제1 프레임, 역방향 워핑된 제2 프레임에 기초하여, 상기 보간 필터 신경망를 통해, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계;를 포함할 수 있다. 제1 프레임, 제2 프레임, 제1 순방향 옵티컬 플로우, 제2 순방향 옵티컬 플로우, 제1 역방향 옵티컬 플로우, 제 2 역방향 옵티컬 플로우 중 적어도 하나를 추가로 이용하여, 보간 필터 신경망를 통해, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정할 수 있다. 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는: 상기 상위 레벨의 제1 옵티컬 플로우, 상기 상위 레벨의 제2 옵티컬 플로우, 상기 상위 레벨의 제1 중요도 가중치, 상기 상위 레 벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 상기 제3 프레임에서 상기 제1 프레임으 로의 제1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬 플로우를 획득하는 단계; 상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 상기 제3 프레임의 시간 t에 기초한 순방향 워핑된 제1 프레임, 상기 시간 t에 기초한 순방향 워핑된 제2 프레임을 획득하는 단계; 및 순방향 워핑 된 제1 프레임, 순방향 워핑된 제2 프레임에 기초하여, 상기 보간 필터 신경망를 통해, 상기 제3 프레임에 대한AI 기반 프레임 보간 필터를 결정하는 단계;를 더 포함할 수 있다. 제1 프레임, 제2 프레임, 제1 순방향 옵티컬 플로우, 제2 순방향 옵티컬 플로우, 제1 역방향 옵티컬 플로우, 제 2 역방향 옵티컬 플로우를 추가로 이용하여, 보간 필터 신경망를 통해, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정할 수 있다. 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 상기 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는: 상위 레벨의 제1 옵 티컬 플로우, 상기 상위 레벨의 제2 옵티컬 플로우, 상기 상위 레벨의 제1 중요도 가중치, 상기 상위 레벨의 제 2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 상기 제3 프레임에서 상기 제1 프레임으로의 제 1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬 플로우를 획득하는 단계; 상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 상기 제3 프레임의 시간 t에 기초한 역방향 워핑된 제1 프레임, 상기 시간 t에 기초한 역방향 워핑된 제2 프레임을 획득하는 단계; 및 역방향 워핑된 제1 프레임, 역방향 워핑된 제2 프레임에 기초하여, 상기 보간 필터 신경망를 통해, 상기 제3 프레임에 대한 AI 기 반 프레임 보간 필터를 결정하는 단계;를 더 포함할 수 있다. 제1 프레임, 제2 프레임, 제1 순방향 옵티컬 플로우, 제2 순방향 옵티컬 플로우, 제1 역방향 옵티컬 플로우, 제 2 역방향 옵티컬 플로우를 추가로 이용하여, 보간 필터 신경망를 통해, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정할 수 있다. 상기 소정 레벨의 상기 제1 옵티컬 플로우는 상기 제1 순방향 워핑 특징 맵과 상기 소정 레벨의 제2 특징 맵 사 이의 제1 상관 값에 기초하여 업데이트되고, 상기 소정 레벨의 상기 제2 옵티컬 플로우는 상기 제2 순방향 워핑 특징 맵과 상기 소정 레벨의 제1 특징 맵 사이의 제2 상관 값에 기초하여 업데이트될 수 있다. 상기 소정 레벨의 제1 옵티컬 플로우의 미리 정해진 범위 내의 후보 픽셀들에 기초하여 상기 소정 레벨의 제1 옵티컬 플로우가 업데이트되고, 상기 소정 레벨의 제2 옵티컬 플로우의 미리 정해진 범위 내의 후보 픽셀들에 기초하여 상기 소정 레벨의 제2 옵티컬 플로우가 업데이트될 수 있다. 미리 정해진 범위는 상기 소정 레벨의 특징 맵의 크기에 따라 달라질 수 있다. 상기 제1 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중에서 사용자에 의해 설정된 필터에 의해 결정되고, 상기 제2 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중에 서 사용자에 의해 설정된 필터에 의해 결정될 수 있다. 상기 제1 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중에서 훈련된 신경망에 기초 한 필터에 의해 결정되고, 상기 제2 상관 값의 계산에 이용되는 픽셀들은 상기 미리 정해진 범위내의 픽셀들 중 에서 훈련된 신경망에 기초한 필터에 의해 결정될 수 있다. 상기 소정 레벨의 상기 제2 특징 맵의 미리 정해진 범위 내의 픽셀과의 상관 값 중 가장 높은 상관 값이 제1 상 관 값으로 결정되고, 상기 소정 레벨의 상기 제1 특징 맵의 미리 정해진 범위 내의 픽셀과의 상관 값 중 가장 높은 상관 값이 제2 상관 값으로 결정될 수 있다. 상기 복수의 레벨 중 최하위 레벨에서 초기에 획득되는 제1 옵티컬 플로우와 제2 옵티컬 플로우는 0으로 설정될 수 있다. 상기 AI 기반 프레임 보간 필터는 상기 제1 프레임 및 상기 제2 프레임 내의 픽셀들 각각에 대응하는 하나의 필 터 커널을 포함할 수 있다. 상기 AI 기반 프레임 보간 필터를 결정하기 위해, 상기 보간 필터 신경망에 상기 제1 프레임 및 상기 제2 프레 임의 문맥적 특징 맵이 추가로 입력되고, 상기 문맥적 특징 맵은 상기 제1 프레임 및 상기 제2 프레임을 입력으 로하는 제2 신경망의 출력 값과 상기 제1 프레임 및 상기 제2 프레임을 입력으로하는 미리결정된 분류 네트워크 의 출력 값의 합으로 결정될 수 있다. 상기 AI 기반 프레임 보간 필터는 서브 픽셀의 계산을 위해 이용되는 바이리니어 보간에 대한 필터 커널을 포함 할 수 있다. 상기 AI 기반 프레임 보간 필터는 제3 프레임의 시간 및 Z-map 중 적어도 하나에 기초한 필터 커널을 포함할 수 있다.상기 AI 기반 프레임 보간 필터는 상기 제1 프레임에 적용되는 제1 프레임 보간 필터와 상기 제2 프레임에 적용 되는 제2 프레임 보간 필터를 포함할 수 있다. 상기 제1 프레임에 대한 깊이 정보 및 상기 제2 프레임에 대한 깊이 정보가 존재하면, 상기 제1 프레임에 대한 깊이 정보 및 상기 제2 프레임에 대한 깊이 정보가 상기 보간 필터 신경망에 추가로 입력될 수 있다. 일 실시예에 따른 AI에 기반한 프레임 보간 장치는 메모리; 및 프로세서를 포함하고, 상기 프로세서는: 영상의 연속적인 프레임들 중에서, 제1 프레임에 대한 복수의 레벨의 제1 특징 맵들 및 제2 프레임에 대한 복수의 레벨 의 제2 특징 맵들을 획득하는 단계; 플로우 예측 신경망을 통해, 소정 레벨의 제1 특징 맵에서 제2 특징 맵으로 의 제1 옵티컬 플로우 및 상기 소정 레벨의 상기 제2 특징 맵에서 상기 제1 특징 맵으로의 제2 옵티컬 플로우를 획득하는 단계; 상기 제1 옵티컬 플로우를 이용하여 상기 제1 특징 맵이 순방향 워핑된 제1 순방향 워핑 특징 맵을 획득하고, 상기 제2 옵티컬 플로우를 이용하여 상기 제2 특징 맵이 순방향 워핑된 제2 순방향 워핑 특징 맵을 획득하는 단계; 상기 제1 순방향 워핑 특징 맵을 이용하여 상기 제1 옵티컬 플로우를 업데이트하고, 상기 제2 순방향 워핑 특징 맵을 이용하여 상기 제2 옵티컬 플로우를 업데이트하는 단계; 상기 업데이트된 제1 옵티 컬 플로우를 상기 소정 레벨의 상위 레벨에 대응하도록 업스케일하여, 상위 레벨의 제1 옵티컬 플로우를 획득하 고, 상기 업데이트된 제2 옵티컬 플로우를 상기 상위 레벨에 대응하도록 업스케일하여, 상위 레벨의 제2 옵티 컬 플로우를 획득하는 단계; 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획 득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 상기 제1 프레임과 상기 제2 프레임 사이의 제3 프레임에 대 한 AI 기반 프레임 보간 필터를 결정하는 단계; 및 상기 제1 프레임, 상기 제2 프레임, 및 상기 AI 기반 프레임 보간 필터를 이용하여 상기 제3 프레임을 획득하는 단계를 수행할 수 있다."}
{"patent_id": "10-2022-0019101", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따른 AI에 기반한 영상의 프레임 보간 방법 및 장치는 플로우 예측 신경망에 기반하여 보다 정확한 양방향 옵티컬 플로우를 획득하고, 양방향 옵티컬 플로우에 기초하여 보간 필터 신경망을 통해 프레임의 각 픽 셀 별로 다른 필터 계수를 가지는 AI 기반 보간 필터를 획득하고, AI 기반 보간 필터를 이용하여 프레임을 보간 함으로써, 영상의 복원 성능을 향상시킬 수 있다."}
{"patent_id": "10-2022-0019101", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고, 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 개시의 실시 형태에 대해 한정 하려는 것이 아니며, 본 개시는 여러 실시예들의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 실시예를 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제 1, 제 2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에서 '~부(유닛)', '모듈' 등으로 표현되는 구성요소는 2개 이상의 구성요소가 하나의 구성요소 로 합쳐지거나 또는 하나의 구성요소가 보다 세분화된 기능별로 2개 이상으로 분화될 수도 있다. 또한, 이하에 서 설명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다른 구성요소 에 의해 전담되어 수행될 수도 있음은 물론이다. 또한, 본 명세서에서, '영상(image)'은 정지영상, 복수의 연속된 정지영상(또는 프레임)으로 구성된 동영상, 또 는 비디오를 나타낼 수 있다. 또한, 본 명세서에서 '신경망(neural network)'은 뇌 신경을 모사한 인공신경망 모델의 대표적인 예시로서, 특 정 알고리즘을 사용한 인공신경망 모델로 한정되지 않는다. 신경망은 심층 신경망(deep neural network)으로 참 조될 수도 있다. 또한, 본 명세서에서 '파라미터(parameter)'는 신경망을 이루는 각 레이어의 연산 과정에서 이용되는 값으로서 예를 들어, 입력 값을 소정 연산식에 적용할 때 이용될 수 있다. 파라미터는 훈련의 결과로 설정되는 값으로서, 필요에 따라 별도의 훈련 데이터(training data)를 통해 갱신될 수 있다. 또한, 본 명세서에서 '특징 맵'은 신경망에 영상 데이터를 입력함으로써 출력되는 이미지 맵을 의미한다. 특징 맵은 입력된 데이터의 잠재적인 특징들을 나타낸다. 또한, 본 명세서에서 '현재 레벨의 옵티컬 플로우'는 현재 레벨의 특징 맵에 대한 옵티컬 플로우를 의미하고, ''상위 레벨의 옵티컬 플로우'는 현재 레벨의 상위 레벨의 특징 맵에 대한 옵티컬 플로우를 의미 한다. 또한, 본 명세서에서, '샘플'은 영상 또는 특징 맵 내 샘플링 위치에 할당된 데이터로서 처리 대상이 되는 데이 터를 의미한다. 예를 들어, 공간 영역의 프레임에서 픽셀 값일 수 있다. 도 1은 AI에 기반한 영상의 프레임 보간 과정의 일 예를 도시하는 도면이다. 도 1을 참고하면, 영상의 연속적인 프레임들 중 제1 프레임 I0 과 제2 프레임 I1 을 특징 맵을 생성하 기 위한 제1 신경망에 입력함으로써, 제1 프레임에 대한 제1 특징 맵과 제2 프레임에 대한 제2 특징 맵을 획득 한다. 또한, 제1 특징 맵과 제2 특징 맵을 다운샘플링용 신경망에 입력함으로써, 복수의 레벨의 다운샘플링된 제1 특징 맵들(110, 120, 130)과 복수의 레벨의 다운샘플링된 제2 특징 맵(115, 125, 135)을 획득한다. 제1 신경망은 입력 이미지의 특징을 추출하는 일반적인 신경망일 수 있다. 예를 들어, 일반적인 콘볼루션 신경 망(CNN)일 수 있다. 다만, 이에 한정되지 않는다. 다운샘플링용 신경망은 하나의 특징 맵을 입력으로 하여 복수의 레벨의 다운샘플링된 특징 맵들을 출력으로 획 득하도록 훈련될 수 있다. 또한, 하나의 특징 맵을 입력으로 하여 특정 비율만큼 다운샘플링하도록 훈련된 다운샘플링용 신경망을 여러 번 사용하여 복수의 레벨의 다운샘플링된 특징 맵들을 획독할 수 있다. 연속적인 프레임들 사이의 새로운 프레임을 보간하기 위해, 옵티컬 플로우가 이용될 수 있다. 옵티컬 플로우는 연속적인 두 프레임, 즉, 제1 프레임과 제2 프레임 내의 샘플들 사이의 위치 차이로 정의될 수 있다. 즉, 옵티컬 플로우는 제1 프레임 내의 샘플들의 위치가 제2 프레임 내에서 어떻게 변경되었는지 또는 제2 프레임의 샘플들이 제1 프레임 내에서 어디에 위치하는지를 나타낸다. 예를 들어, 제1 프레임 내 (x, y)에 위치한 샘플이 제2 프레임 내 (x+f(x), y+f(y))에 위치한다면, 해당 샘플에 대한 옵티컬 플로우는 (f(x), f(y))로 도출될 수 있다. 워핑은 영상 내 샘플들의 위치를 이동시키는 기하학적 변형의 한 종류이다. 제1 프레임 내 샘플들과 제2 프레임 내 샘플들 사이의 상대적인 위치 관계를 나타내는 옵티컬 플로우에 따라 제2 프레임을 워핑함으로써 제1 프레임과 유사한 순방향 워핑 프레임이 획득된다. 예를 들어, 제1 프레임 내 (1, 1)에 위치한 샘플이 제2 프레임 내 (2, 1)에 위치하는 샘플과 가장 유사하다면, 워핑을 통해 제1 프레임 내 (1, 1)에 위치한 샘플의 위치가 (2, 1)로 변경될 수 있다. 플로우 예측 신경망은 피라미드 구조의 복수의 레벨의 특징 맵들을 이용하여 제1 프레임에서 제2 프 레임으로의 제1 옵티컬 플로우(flow0→1)와 제2 프레임에서의 제1 프레임으로의 제2 옵티컬 플로 우(flow1→0)를 획득하도록 훈련된 신경망이다. 먼저, 제1 프레임의 최하위 레벨의 제1 특징 맵으로부터 제2 프레임의 최하위 레벨의 제2 특징 맵으로의 최하위 레벨의 제1 옵티컬 플로우(flow1 0→1)의 초기 값을 0으로 설정하고, 제2 프레임의 최 하위 레벨의 제2 특징 맵으로부터 제1 프레임의 최하위 레벨의 제1 특징 맵으로의 최하위 레벨 의 제2 옵티컬 플로우(flow1 1→0)의 초기 값을 0으로 설정한다. 이하에서, 최하위 레벨은 레벨 1이라 한다. 레벨 1의 제1 특징 맵으로부터 레벨 1의 제2 특징 맵으로의 레벨 1의 제1 옵티컬 플로우를 획득하고, 레벨 1의 제1 옵티컬 플로우를 이용하여 레벨 1의 제2 특징 맵에 순방향 워핑하여 레벨 1의 순방향 워핑된 제1 특징 맵을 획득한다. 최하위 레벨의 순방향 워핑된 제1 특징 맵과 최하위 레벨의 제2 특징 맵 사이의 상관 값들을 계 산하여, 가장 높은 상관 값을 가지는 픽셀의 위치를 결정하여 레벨 1의 제1 옵티컬 플로우(flow1 0→1)를 업데이트 한다. 반대로, 레벨 1의 제2 특징 맵으로부터 레벨 1의 제2 특징 맵으로의 레벨 1의 제2 옵티컬 플로우를 획득하고, 레벨 1의 제2 옵티컬 플로우를 이용하여 레벨 1의 제1 특징 맵에 순방향 워핑하여 레벨 1의 순방향 워핑된 제2 특징 맵을 획득한다. 레벨 1의 순방향 워핑된 제2 특징 맵과 레벨 1의 제2 특징 맵 사이의 상관 값들을 계산하여, 가장 높은 상관 값을 가지는 픽셀의 위치를 결정하여 레벨 1의 제2 옵티컬 플로우(flow1 1 →0)를 업데이트한다. 여기서, 레벨 1의 제1 옵티컬 플로우와 레벨 1의 제2 옵티컬 플로우는 초기 값이 0이기 때문에 레벨 1의 순방향 워핑된 제1 특징 맵과 레벨 1의 순방향 워핑된 제2 특징 맵은 레벨 1의 제1 특징 맵 및 레벨 1의 제2 특징 맵과 동일할 수 있다. 레벨 1의 제1 특징 맵 및 제2 특징 맵을 서로 비교하여 상관 값을 계산하여, 레벨 1의 제1 옵 티컬 플로우와 레벨 1의 제2 옵티컬 플로우가 0이 아닌 값으로 업데이트된다. 그 후, 최하위 레벨의 제1 옵티컬 플로우와 최하위 레벨의 제2 옵티컬 플로우를 최하위 레벨의 상위 레벨인 레 벨 2에 대응하는 크기로 업스케일하여 레벨 2의 제1 옵티컬 플로우(flow2 0→1)와 제2 옵티컬 플로우(flow2 1→ 0)가 획득된다. 상관 값을 계산하는 것은 예를 들어, 순방향 워핑된 제1 특징 맵과 제2 특징 맵을 비교하여 서로 유사한지 확인 하기 위한 것이다. 옵티컬 플로우가 정확하다면 순방향 워핑된 제1 특징 맵과 제2 특징 맵은 동일하여야 하기 때문이다. 그러나, 워핑된 이미지가 대상 이미지와 완전히 동일할 수 없으므로, 상관 값 계산을 통해 옵티컬 플 로우를 업데이트하는 것이다. 옵티컬 플로우와 옵티컬 플로우를 이용한 워핑 방법은 도 2에서 후술되고, 옵티컬 플로우와 순방향 워핑을 이용 하여 상관 값을 계산하는 방법은 도 3c에서 후술된다. 또한, 플로우 예측 신경망을 통해, 최하위 레벨인 레벨 1의 제1 중요도 가중치 및 레벨 1의 제2 중요도 가 중치가 획득될 수 있다. 레벨 1의 제1 중요도 가중치는 레벨 1의 제1 특징 맵의 복수의 픽셀들이 레벨 1의 제2 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타내고, 레벨 1의 제2 중요도 가중치는 레벨 1의 제2 특징 맵의 복수의 픽셀들이 레벨 1의 제1 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타낸다. 레벨 1의 제1 중요도 가중치(w1 0)와 레벨 1의 제2 중요도 가중치(w1 1)의 초기 값은 0으로 설정된다. 레벨 2의 제1 옵티컬 플로우(flow2 0→1)와 제2 옵티컬 플로우(flow2 1→0)가 획득된 후, 레벨 2의 제1 옵티컬 플로 우(flow2 0→1)와 제2 옵티컬 플로우(flow2 1→0)에 기초하여, 레벨 2의 제1 중요도 가중치 및 레벨 2의 제2 중요도 가중치가 획득된다.레벨 2의 제1 중요도 가중치(w2 0) 및 레벨 2의 제2 중요도 가중치(w2 1)는 레벨 2의 제1 옵티컬 플로우(flow2 0→1) 와 제2 옵티컬 플로우(flow2 1→0)의 업데이트를 위한 레벨 2의 제1 순방향 워핑 특징 맵 및 레벨 2의 제2 순방향 워핑 특징 맵을 획득되는데 추가로 이용될 수 있다. 획득된 레벨 2의 제1 옵티컬 플로우(flow2 0→1)와 제2 옵티컬 플로우(flow2 1→0), 최하위 레벨의 상위 레벨인 레벨 2의 제1 특징 맵과 제2 특징 맵을 이용하여 최하위 레벨 1에서의 과정을 동일하게 반복적으로 수행함으로써, 레 벨 2의 제1 옵티컬 플로우와 제2 옵티컬 플로우를 업데이트하고 업스케일함으로써 레벨 2의 상위 레벨인 레벨 3 의 제1 옵티컬 플로우와 제2 옵티컬 플로우를 획득한다. 레벨 3의 제1 옵티컬 플로우(flow3 0→1)와 제2 옵티컬 플로우(flow3 1→0)가 획득된 후, 레벨 3의 제1 옵티컬 플로 우(flow3 0→1)와 제2 옵티컬 플로우(flow3 1→0)에 기초하여, 레벨 3의 제1 중요도 가중치 및 레벨 3의 제2 중요도 가중치가 획득된다. 레벨 3의 제1 중요도 가중치(w3 0) 및 레벨 3의 제2 중요도 가중치(w3 1)는 레벨 3의 제1 옵티컬 플로우(flow3 0→1) 와 제2 옵티컬 플로우(flow3 1→0)의 업데이트를 위한 레벨 3의 제1 순방향 워핑 특징 맵 및 레벨 3의 제2 순방향 워핑 특징 맵을 획득되는데 추가로 이용될 수 있다. 플로우 예측 신경망 내에서 이러한 과정을 반복하여, 최상위 레벨의 아래 레벨 단계에서, 최상위 레벨의 아래 레벨이 레벨 L-1이라 하면, 최상위 레벨의 아래 레벨의 제1 옵티컬 플로우(flowL-1 0→1)와 최상위 레벨의 아 래 레벨의 제2 옵티컬 플로우(flowL-1 1→0)가 획득되고, 최상위 레벨의 아래 레벨의 제1 옵티컬 플로우 (flowL-1 0→1)와 최상위 레벨의 제2 옵티컬 플로우(flowL-1 1→0)가 업데이트된 후, 최상위 레벨로 업스케일이 수행되 어, 제1 프레임에 대응하는 최상위 레벨의 제1 옵티컬 플로우(flow0→1)와 제2 프레임에 대응하는 최상위 레벨의 제2 옵티컬 플로우(flow1→0)로 결정된다. 최종 획득된 제1 프레임의 제1 옵티컬 플로우와 제2 프레임의 제2 옵 티컬 플로우는 복수개의 특징 맵을 이용하여 최하위 레벨에서부터 순차적으로 업데이트되고 업스케일되어 획득 되므로, 플로우 예측 신경망은 복수의 레벨의 특징 맵에 대하여 순차적으로 옵티컬 플로우를 업데이트하고 업스케일하면서 신경망의 파라미터를 공유함으로써 신경망의 파라미터를 늘리지 않으면서 효과적으로 수용 필드 (receptive field)를 확장함으로써, 보다 정확한 옵티컬 플로우들을 획득할 수 있다. 수용 필드는 특징 맵을 생 성하는 입력 영역의 크기를 나타낸다. 또한, 제1 프레임의 제1 옵티컬 플로우와 제2 프레임의 제2 옵티컬 플로우에 기초하여 제1 프레임에 대응하는 최상위 레벨의 제1 최종 중요도 가중치(w0)와 제2 프레임에 대응하는 제2 최종 중요도 가중치(w1)도 획득될 수 있다. 플로우 예측 신경망은 입력 대상이 되는 특징 맵의 프레임과 최종 옵티컬 플로우로 워핑된 프레임 사이의 손실을 최소로하도록 훈련될 수 있다. 획득된 제1 프레임의 제1 옵티컬 플로우와 제2 프레임의 제2 옵티컬 플로우는 제1 프레임과 제2 프레임 사이의 양방향 옵티컬 플로우에 해당한다. 이러한 양방향 옵티컬 플로우를 이용하여 중간 옵티컬 플로우 예측 신경망 를 통해, 제1 프레임과 제2 프레임 사이의 제3 프레임의 시간 t에 대한 각각의 중간 옵티컬 플로우를 예측 한다. 중간 옵티컬 플로우는 제1 프레임과 제2 프레임 사이의 시간 t에 기초하여 제3 프레임에서 제1 프레임으 로의 제1 중간 옵티컬 플로우(flowt→0), 제3 프레임에서 제2 프레임으로의 제2 중간 옵티컬 플로우(flowt→1)들을 포함할 수 있다. 중간 옵티컬 플로우 예측 신경망에는 제1 프레임의 제1 중요도 가중치와 제2 프레임의 제2 중요도 가중치 도 추가로 이용될 수 있다. 예측된 중간 옵티컬 플로우에 기초하여 훈련된 보간 필터 신경망을 통해, 제1 프레임과 제2 프레임 사이의 제3 프레임에 대한 AI 기반 프레임 보간 필터를 획득한다. 구체적으로, 제1 프레임, 제2 프레임, 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우을 이용하여 순방향 워핑된 제1 프레임, 순방향 워핑된 제2 프레임, 역방향 워핑된 제1 프레임, 역방향 워핑된 제2 프레임이 획득될 수 있다. 그 후, 획득된 순방향 워핑된 제1 프레임, 순방향 워핑된 제2 프레임, 역방향 워핑된 제1 프레임, 역 방향 워핑된 제2 프레임이 보간 필터 신경망에 입력되어, AI 기반 프레임 보간 필터가 획득될 수 있 다. 또한, 보간 필터 신경망에는 제1 프레임 및 제2 프레임이 추가로 입력되어, AI 기반 프레임 보간 필터 를 획득하는데 이용될 수 있다. 또한, 보간 필터 신경망에는 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우가 추가로 입력되어, AI 기반 프레임 보간 필터를 획득하는데 이용될 수 있다. 또한, 보간 필터 신경망에는 제1 프레임, 제2 프레임, 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우 가 추가로 입력되어, AI 기반 프레임 보간 필터를 획득하는데 이용될 수 있다. 다른 예로, 제1 프레임, 제2 프레임, 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우을 이용하여 순방향 워 핑된 제1 프레임, 순방향 워핑된 제2 프레임이 획득될 수 있다. 그 후, 획득된 순방향 워핑된 제1 프레임, 순방 향 워핑된 제2 프레임이 보간 필터 신경망에 입력되어, AI 기반 프레임 보간 필터가 획득될 수 있다. 또한, 보간 필터 신경망에는 제1 프레임 및 제2 프레임이 추가로 입력되어, AI 기반 프레임 보간 필터 를 획득하는데 이용될 수 있다. 또한, 보간 필터 신경망에는 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우가 추가로 입력되어, AI 기반 프레임 보간 필터를 획득하는데 이용될 수 있다. 또한, 보간 필터 신경망에는 제1 프레임, 제2 프레임, 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우 가 추가로 입력되어, AI 기반 프레임 보간 필터를 획득하는데 이용될 수 있다. 다른 예로, 제1 프레임, 제2 프레임, 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우을 이용하여 역방향 워 핑된 제1 프레임, 역방향 워핑된 제2 프레임이 획득될 수 있다. 그 후, 획득된 역방향 워핑된 제1 프레임, 역방 향 워핑된 제2 프레임이 보간 필터 신경망에 입력되어, AI 기반 프레임 보간 필터가 획득될 수 있다. 또한, 보간 필터 신경망에는 제1 프레임 및 제2 프레임이 추가로 입력되어, AI 기반 프레임 보간 필터 를 획득하는데 이용될 수 있다. 또한, 보간 필터 신경망에는 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우가 추가로 입력되어, AI 기반 프레임 보간 필터를 획득하는데 이용될 수 있다. 또한, 보간 필터 신경망에는 제1 프레임, 제2 프레임, 제1 중간 옵티컬 플로우 및 제2 중간 옵티컬 플로우 가 추가로 입력되어, AI 기반 프레임 보간 필터를 획득하는데 이용될 수 있다. 또한, 제1 프레임의 문맥적 특징 맵, 제2 프레임의 문맥적 특징 맵이 추가로 입력되어, AI 기반 프레임 보간 필 터가 획득될 수 있다. AI 기반 보간 프레임 필터는 제1 프레임과 제2 프레임 각각의 픽셀들에 대하여 각각 다른 필터 커널을 가진다. 또한, 보간 필터 신경망에는 제1 중간 옵티컬 플로우의 반대 방향의 흐름을 나타내는 제1 중간 옵티컬 플 로우 리버설(reversal) 및 제2 중간 옵티컬 플로우의 반대 방향의 흐름을 나타내는 제2 중간 옵티컬 플로우 리 버설이 추가로 입력되어, AI 기반 프레임 보간 필터를 획득하는데 이용될 수 있다. AI 기반 프레임 보간 필터를 이용하여 제1 프레임과 제2 프레임 사이의 제3 프레임을 보간한다. AI 기반 프레임 보간 필터는 픽셀 별로 동적으로 필터 커널이 결정되므로, 더 정확하게 제3 프레임이 보 간될 수 있다. 이러한 보간 방법은 데이터 생성이 필요한 분야인 광-필드 데이터 합성(Light-field data synthesis), 프레임율 변환(frame rate up-conversion), 3D 렌더링의 분야에 적용될 수 있다. 도 2는 프레임 사이의 옵티컬 플로우에 기초한 역방향 워핑 및 순방향 워핑의 일 예를 설명하기 위한 도면이다. 도 2를 참고하면, 제1 프레임에서 제2 프레임으로의 옵티컬 플로우에 기초하여 제1 프레임 또는 제2 프레임을 워핑한다. 무엇을 워핑하는지에 따라 순방향 워핑 또는 역방향 워핑이라 한다. 구체적으로, 제 2프레임을 옵티컬 플로우의 방향과 반대 방향에 해당하는 제1 프레임으로 워핑하는 것을 역방향 워핑이라 하고, 제 1 프레임을 옵티컬 플로우의 방향에 해당하는 제2 프레임으로 워핑하는 것을 순방향 워핑이라 한 다. 역방향 워핑된 이미지는 워핑 결과 오클루젼(occlusion) 영역이 중복되어 나타날 수 있는 반면에, 순방향 워핑된 이미지는 워핑 결과 오클루젼(occlusion) 영역에 대한 픽셀 값을 0으로 하여 홀(hole) 영역이 나타 날 수 있다. 역방향 워핑은 오클루젼(occlusion) 영역이 중복되어 나타나기 때문에 상관(correlation) 값을 계 산하여 플로우를 계산하기 어렵다. 그러나, 순방향 워핑은 홀(hole) 영역이 나타나 일치하는 영역이 하나가 되 어 상관(correlation) 값을 계산하여 플로우를 보정하기 적합하다. 도 3a는 역방향 워핑된 특징 맵을 이용하여 상관 값을 계산하는 방법의 일 예를 도시하고, 도 3b는 역방향 워핑 된 특징 맵을 이용하여 상관 값을 계산하는 방법의 다른 예를 도시하고, 도 3c는 순방향 워핑된 특징 맵을 이용 하여 상관 값을 계산하는 방법의 일 예를 도시한다. 도 3a를 참고하면, 제1 특징 맵을 역방향 워핑하여 획득된 제1 역방향 워핑 특징 맵과 제2 특징 맵 사이에 상관 값을 계산한다. 상관 값 계산을 위해 제1 역방향 워핑 특징 맵 내의 픽셀을 중심으로 (2r+1)(2r+1) 만큼의 범위 내에서 제2 특징 맵의 픽셀들의 상관 값을 계산하여 상관 값이 가장 높은 픽셀 을 구한다. 제1 역방향 워핑 특징 맵 내의 모든 픽셀을 이용하여 상관 값을 계산하게 되면, 공간 복잡도는 해상도가 증가할수록 공간 복잡도의 제곱으로 증가하게 되므로, 특정 범위 내에서 상관 값을 계산한다. 도 3b를 참고하면, 제1 특징 맵 내의 픽셀을 중심으로 (2r+1)(2r+1) 만큼의 범위 내에서 역방향 워핑하여 획득된 제1 역방향 워핑 특징 맵과 제2 특징 맵 사이에 상관 값을 계산한다. 상관 값 계산을 위해 제 1 역방향 워핑 특징 맵 내의 픽셀을 중심으로 (2r+1)(2r+1) 만큼의 범위 내에서 제2 특징 맵의 픽셀 들의 상관 값을 계산하여 상관 값이 가장 높은 픽셀을 구한다. 여기서, r은 피라미드 레벨에 따라 또는 해당 특징 맵의 크기에 따라 달라질 수 있다. 또한, r은 프레임 보간 장치 내의 하드웨어(예를 들어, 메모리 등)의 성능 또는 개수에 따라 달라질 수 있다. 도 3a 및 도 3b는 역방향 워핑된 특징 맵을 이용하여 상관 값을 계산하므로, 도 2에서 전술된 바와 같이, 역방 향 워핑에 의한 중복되는 오클루젼 영역으로 인해 잔상(blur)가 발생할 수 있어 플로우를 보정하기 위한 상관 값 계산에 혼동을 줄 수 있다. 도 3c를 참고하면, 제1 특징 맵을 순방향 워핑하여 획득된 제1 순방향 워핑 특징 맵과 제2 특징 맵 사이에 상관 값을 계산한다. 상관 값 계산을 위해 제1 순방향 워핑 특징 맵 내의 픽셀과 제2 특징 맵의 픽셀을 중심으로 (2r+1)(2r+1) 만큼의 범위 내의 픽셀들의 상관 값을 계산하여 상관 값이 가장 높은 픽셀을 구한다. 도 3c는 순방향 워핑된 특징 맵을 이용하여 상관 값을 계산하므로, 역방향 워핑과 같이, 오클루젼 영역이 발생 하지 않으므로, 플로우를 보정하기 용이하다. 구체적으로, 오클루젼 영역을 플로우 후보에서 제외함으로써, 중 복되는 플로우 후보가 발생할 가능성이 낮아진다. 이에 따라 플로우 후보의 정확도가 높아진다. 또한, 도 3a 및 도 3b와 같이 워핑된 특징 맵의 (2r+1)(2r+1) 만큼의 범위 내의 픽셀들을 이용하여 상관 값을 계산하면, 워핑 시에 필연적으로 발생하는 주변 픽셀과의 블렌딩 때문에 흐릿한 결과가 획득될 가능성이 있다. 이를 방지하기 위해, 도 3c에서는 특징 맵의 픽셀을 중심으로 (2r+1)(2r+1) 만큼의 범위 내의 픽셀들의 상 관 값을 계산한다. 도 1의 플로우 예측 신경망에서 플로우의 업데이트하기 위한 상관 값 계산은 도 3c의 방법에 따라 수행된 다. 상관 값 계산 및 플로우 업데이트 방법은 도 5에서 후술된다. 도 4는 상관 값 계산 시에 계산의 대상이 되는 픽셀의 후보를 선택하기 위해 이용되는 필터의 일 예를 설명하기 위한 도면이다. 도 4를 참고하면, 상관 값 계산의 대상이 되는 제2 특징 맵 내의 픽셀들은 하나의 픽셀을 중심으로 (2r+1)(2r+1)의 범위 내의 픽셀들일 수 있다. 이러한 후보 픽셀들을 모두 계산하기 보다 기하학적 필터를 통해 (2r+1)(2r+1)의 범위 내에서도 일부 픽셀들만 계산하여 계산량을 줄일 수 있다. 이에 따른 필터링된 제2 특징 맵과 순방향 워핑된 제1 특징 맵 사이의 상관 값을 계산할 수 있다.구체적으로, (2r+1)(2r+1)의 범위 내에서 상관 값을 계산하더라도, (2r+1)(2r+1)의 값이 커지면 플로우를 정확 하게 찾을 수 있지만, 공간복잡도가 커지고, 비교 영역의 범위가 커지면서 불필요한 샘플이 많아짐에 따라 학습 이 어려워져 신경망의 플로우 예측 성능의 열화가 발생할 수 있는 반면에 (2r+1)(2r+1)의 값을 작게 하면, 플로 우 값이 국소 최저점(local minima)이 되거나 잘못 추정된 값일 수 있다. 이를 해결하기 위해, 큰 비교 영역 내에서 적절한 후보군을 정제하도록 하는 신경망에 기초한 필터를 이용할 수 있다. 즉, (2r+1)(2r+1)의 범위 내에서도 n개의 후보들을 추출할 수 있는 기하학적 필터를 이용하면, 적은 공간복잡도 상에서 최적의 플로우를 보정할 수 있다. 이에 따라, 도 4를 참고하면, 제2 특징 맵의 (2r+1)2만큼의 범위에서 기하학적 필터의 (2r+1)2 범위 내의 N개의 픽셀을 선택하여, 필터링된 제2 특징 맵은 (2r+1)2 범위 내의 N개의 픽셀들만을 이용하여 상관 값을 계산 한다. 여기서, H는 특징 맵의 높이, W는 특징 맵의 너비, C는 특징 맵의 채널을 의미한다. 기하학적 필터는 사용자에 의해 미리 설정될 수 있고, 훈련된 신경망을 통해 획득된 것일 수 있다. 또한, 기하학적 필터는 (2r+1)(2r+1)의 범위 내의 픽셀들 중 일부만 선택하도록 결정된 것뿐만 아니라, (2r+1)(2r+1)의 범위보다 더 넓은 범위를 가지되, 그 중에서 (2r+1)(2r+1)의 픽셀들을 이용하도록 결정된 것일 수 있다. 플로우 예측 신경망에서 플로우 업데이트에 기하학적 필터를 추가로 이용하면, 상관 값 계산의 대상 픽셀을 선별하여, 메모리의 낭비가 감소되고, 플로우 예측 신경망에서 플로우 후보의 선별 정확도가 높아 질 수 있다. 도 5는 옵티컬 플로우를 업데이트하는 방법의 일 예를 설명하기 위한 도면이다. 도 5를 참고하면, 피라미드 구조의 복수 레벨의 특징 맵들을 이용하여 현재 레벨에서 상위 레벨로 옵티컬 플로 우를 업데이트한다. 구체적으로, 하위 레벨에서 업데이트된 후 현재 레벨(n-1)에 대응하도록 업스케일하여 획득된 옵티컬 플로우 (f_warp(Flown-1 1→2))는 상관 값이 가장 높은 픽셀의 좌표를 가지고 있다. 상관 값이 가장 높은 픽셀의 좌 표를 기준으로 특정 범위 내의 픽셀들의 플로우 후보로 더한다. 현재 레벨의 순방향 워핑된 제1 특징 맵(Featn-1 1→2)과 현재 레벨의 제2 특징 맵(Featn-1 2)의 특정 범위 내의 픽셀들 사이의 내적의 결과를 소프트 아그맥스(Soft argmax) 함수에 입력하여 상관 값의 값이 가장 큰 픽셀의 위치를 획득한다. 현재 레벨의 순방향 워핑된 제1 특징 맵은 쿼리(query)의 역할을 수행하 고, 현재 레벨의 제2 특징 맵은 키(key)의 역할을 수행하여, 상관 값의 값이 가장 큰 픽셀의 위치를 결과 로 얻게 된다. 하위 레벨에서 업데이트된 후 현재 레벨에 대응하도록 업스케일하여 획득된 옵티컬 플로우에 기초한 플로우 후 보들과 상관 값 계산에 결과에 따른 상관 값의 값이 가장 큰 좌표의 위치를 내적함으로써, 업데이트된 현재 레 벨의 옵티컬 플로우(f_warp(Flown-1 1→2)')가 획득될 수 있다. 업데이트된 현재 레벨의 옵티컬 플로우 (f_warp(Flown-1 1→2)')를 현재 레벨의 상위 레벨(n)에 대응하도록 업스케일함으로써, 상위 레벨의 옵티컬 플로우 가 획득될 수 있다. 레벨 마다 이러한 단계를 반복하여, 최상위 레벨의 아래 레벨에서 최상위 레벨의 아래 레벨의 옵티컬 플로우를 업데이트한 후, 최상위 레벨로 업스케일을 수행함으로써, 제1 프레임 및 제2 프레임에 대응하는 최상위 레벨의 최종 옵티컬 플로우들이 획득될 수 있다. 한정된 범위 내에서 비교를 통해 상관 값을 계산함으로써 공간복잡도를 줄이면서 최적의 옵티컬 플로우가 예측 될 수 있다. 하위 레벨에서 업데이트된 후 현재 레벨에 대응하도록 업스케일하여 획득된 옵티컬 플로우의 (H, W, 2)는 옵티 컬 플로우의 높이(H), 너비(W), 픽셀의 x 및 y 좌표를 나타내는 정보를 나타낸다. 현재 레벨의 순방향 워핑 된 특징 맵의 (H, W, C, 1)은 특징 맵의 높이(H), 특징 맵의 너비(W), 특징 맵의 채널(C), 현재 업데이트 하고 자 하는 픽셀 을 나타낸다. 또한, 현재 레벨의 제2 특징 맵의 (H, W, C, (2r+1)2)는 특징 맵의 높이(H), 특징 맵의 너비(W), 특징 맵의 채널(C), 상관 값 계산의 대상 픽셀들의 범위 ((2r+1)2)를 나타낸다. 도 6은 AI에 기반한 프레임 보간 필터를 통해 프레임을 보간하는 과정의 일 예를 설명하기 위한 도면이다. 도 6을 참고하면, 보간 필터 신경망을 통해 제1 프레임의 각 픽셀에 대한 제1 프레임 보간 필터와 제 2 프레임의 각 픽셀에 대한 제2 프레임 보간 필터가 획득된다. 제1 프레임 보간 필터와 제2 프 레임 보간 필터는 각 프레임의 픽셀 각각에 대하여 다른 필터 계수를 가진다. 이에 따라, 제1 프레임(61 0)에 제1 프레임 보간 필터를 적용하고 제2 프레임에 제2 프레임 보간 필터를 적용하여 제1 프 레임과 제2 프레임 사이의 제3 프레임을 보간한다. 프레임을 워핑하면, 필연적으로 화질의 저하가 발생하여, 옵티컬 플로우을 이용하여 워핑된 이미지를 이용하여 블렌딩하게 되면 결과 이미지 또한 잔상이 발생하거나 화질이 떨어지게 된다. 이를 해결하기 위해, 훈련된 보간 필터 신경망을 통해, 제1 프레임의 각 픽셀에 대하여 다른 필터 계수를 가지는 제1 프레임 보간 필터와 제2 프 레임의 각 픽셀에 대하여 다른 필터 계수를 가지는 제2 프레임 보간 필터를 획득하고, 이를 이용하여 제3 프레 임을 보간한다. 각 픽셀 별로 다른 변환 커널을 예측하여 사용함으로써, 프레임 간의 워핑 불일치가 보정되어 플로우가 보정되고, 밝기도 보정되어, 보간된 프레임의 정확도가 향상된다. 이에 따라, 4K와 같은 고화질 영상 의 복원 성능 및 정확도 향상에 도움이 될 수 있다. 도 7은 AI에 기반한 프레임 보간 필터의 일 예를 설명하기 위한 도면이다. 도 7를 참고하면, 보간 필터 신경망을 통해 획득된 AI에 기반한 프레임 보간 필터는 보간 필터 신경망의 학습된 파라미터를 통해 워핑에 대한 변환 커널과 오클루젼에 대한 변환 커널을 포함하는 필터 커널을 포함한다. 또한, AI에 기반한 프레임 보간 필터에는 바이리니어 보간 커널과 어텐션 커널이 추가로 포함될 수 있다. 바이리니어 보간 커널은 서브 픽셀 계산을 위한 변환 커널이고, 어텐션 커널은 제3 프레임의 시간 t, 제1 프레임 및 제2 프레임이 깊이 맵 정보를 포함하고 있는 경우의 깊이 맵 정보, 제1 프레임 및 제2 프레임의 기하학 정보 등의 사전에 알고 있는 정보에 기초하여 계산된 커널이다. 어텐션 커널은 훈련된 신경망을 통 해 도출될 수도 있다. 바이리니어 보간 커널은 예측된 플로우에 의해 결정될 수 있고, 어텐션 커널은 커널 위치 별 가중치, 예를 들어, 가우시안 가중치가 이용될 수 있다. 이는 두 입력 프레임 간의 일치성(consistency)을 추정하기 쉽게 하기 위해 보간 필터 신경망에 의해 학습된 파 라미터 외에 이미 알고 있는 정보를 이용함으로써 결과를 향상시키기 위한 것이다. 또한, 워핑에 대한 변환 커널과 오클루젼에 대한 변환 커널은 하나의 보간 필터 신경망이 아닌 워핑 에 대한 변환 커널과 오클루젼에 대한 변환 커널 각각에 대한 신경망들에 의해 학습되어 출력될 수 있다. 워핑에 대한 변환 커널을 위한 신경망은 옵티컬 플로우에 대한 입력 데이터를 주로 이용하여 훈련되고, 오 클루젼에 대한 변환 커널을 위한 신경망은 중요도 가중치를 주로 이용하여 훈련된 것일 수 있다. 도 8은 일 실시예에 따른 AI에 기반한 프레임 보간 방법의 순서도이다. S810 단계에서, AI에 기반한 프레임 보간 장치는 영상의 연속적인 프레임들 중에서, 제1 프레임에 대한 복 수의 레벨의 제1 특징 맵들 및 제2 프레임에 대한 복수의 레벨의 제2 특징 맵들을 획득한다. 일 실시예에 따라, 최상위 레벨에 대응하는 제1 프레임의 제1 특징 맵 및 최상위 레벨에 대응하는 제2 프레임의 제2 특징 맵은 제1 신경망을 통해 획득되고, 최상위 레벨의 아래 레벨들의 제1 특징 맵들 및 최상위 레벨의 아 래 레벨들의 제2 특징 맵들은 다운샘플링 신경망을 통해 획득되고, 복수의 레벨의 제1 특징 맵들 및 복수의 레 벨의 제2 특징 맵들은 최상위 레벨의 아래 레벨들의 제1 특징 맵들 및 최상위 레벨의 아래 레벨들의 제2 특징 맵들일 수 있다. S820 단계에서, AI에 기반한 프레임 보간 장치는 플로우 예측 신경망을 통해, 소정 레벨의 제1 특징 맵에 서 제2 특징 맵으로의 제1 옵티컬 플로우 및 상기 소정 레벨의 상기 제2 특징 맵에서 상기 제1 특징 맵으로의 제2 옵티컬 플로우를 획득한다.S830 단계에서, AI에 기반한 프레임 보간 장치는 상기 제1 옵티컬 플로우를 이용하여 상기 제1 특징 맵이 순방향 워핑된 제1 순방향 워핑 특징 맵을 획득하고, 상기 제2 옵티컬 플로우를 이용하여 상기 제2 특징 맵이 순방향 워핑된 제2 순방향 워핑 특징 맵을 획득한다. S840 단계에서, AI에 기반한 프레임 보간 장치는 상기 제1 순방향 워핑 특징 맵을 이용하여 상기 제1 옵티 컬 플로우를 업데이트하고, 상기 제2 순방향 워핑 특징 맵을 이용하여 상기 제2 옵티컬 플로우를 업데이트한다. S850 단계에서, AI에 기반한 프레임 보간 장치는 상기 업데이트된 제1 옵티컬 플로우를 상기 소정 레벨의 상위 레벨에 대응하도록 업스케일하여, 상위 레벨의 제1 옵티컬 플로우를 획득하고, 상기 업데이트된 제2 옵티 컬 플로우를 상기 상위 레벨에 대응하도록 업스케일하여, 상위 레벨의 제2 옵티컬 플로우를 획득한다. 일 실시예에 따라, 상위 레벨이 최상위 레벨이고, 최상위 레벨은 제1 프레임 및 제2 프레임에 대응하는 레벨일 수 있다. 다른 실시예에 따라, 소정 레벨이 최상위 레벨이면, 최상위 레벨의 제1 옵티컬 플로우 및 최상위 레벨의 제2 옵 티컬 플로우는 업데이트된 후 업스케일되지 않을 수 있다. 구체적으로, 최상위 레벨의 제1 옵티컬 플로우를 이 용하여 최상위 레벨의 제1 특징 맵이 순방향 워핑된 제1 순방향 워핑 특징 맵이 획득되고, 최상위 레벨의 제2 옵티컬 플로우를 이용하여 최상위 레벨의 제2 특징 맵이 순방향 워핑된 제2 순방향 워핑 특징 맵이 획득되고, 제1 순방향 워핑 특징 맵을 이용하여 최상위 레벨의 제1 옵티컬 플로우가 업데이트되고, 상기 제2 순방향 워핑 특징 맵을 이용하여 최상위 레벨의 제2 옵티컬 플로우가 업데이트되고, 최상위 레벨의 제1 옵티컬 플로우와 최 상위 레벨의 제2 옵티컬 플로우는 업스케일되지 않고, 이용될 수 있다. 일 실시예에 따라, 플로우 예측 신경망을 통해 상기 상위 레벨의 제1 옵티컬 플로우, 상위 레벨의 제2 옵티컬 플로우를 획득하는 단계는: 소정 레벨의 제1 중요도 가중치를 획득하되, 제1 중요도 가중치는 소정 레벨의 제1 특징 맵의 복수의 픽셀들이 소정 레벨의 제2 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타내는 단계; 및 소정 레벨의 제2 중요도 가중치를 획득하되, 제2 중요도 가중치는 소정 레벨의 제2 특징 맵의 복수의 픽셀들 이 소정 레벨의 제1 특징 맵의 하나의 픽셀에 얼마만큼 매핑되는지를 나타내는 단계를 더 포함할 수 있다. 일 실시예에 따라, 소정 레벨의 제1 중요도 가중치를 추가로 이용하여, 제1 순방향 워핑 특징 맵이 획득되고, 소정 레벨의 제2 중요도 가중치를 추가로 이용하여, 상기 제2 순방향 워핑 특징 맵이 획득될 수 있다. 일 실시예에 따라, 상위 레벨의 제1 옵티컬 플로우에 기초하여 상위 레벨의 제1 중요도 가중치가 획득되고, 상 위 레벨의 제2 옵티컬 플로우에 기초하여 상위 레벨의 제2 중요도 가중치가 획득될 수 있다. 일 실시예에 따라, 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는: 상위 레벨의 제1 옵티컬 플로우, 상위 레벨의 제2 옵티컬 플로우, 상위 레벨의 제1 중요도 가중치, 상위 레벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 제상기 제3 프레임에서 상기 제1 프레임으로의 제 1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬 플로우를 획득하는 단계; 상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 제3 프레임의 시간 t에 대하여 순방향 워핑 된 제1 프레임, 시간 t에 대하여 순방향 워핑된 제2 프레임, 시간 t에 대하여 역방향 워핑된 제1 프레임, 시간 t에 대하여 역방향 워핑된 제2 프레임을 획득하는 단계; 및 순방향 워핑된 제1 프레임, 순방향 워핑된 제2 프레 임, 역방향 워핑된 제1 프레임, 역방향 워핑된 제2 프레임에 기초하여, 보간 필터 신경망를 통해, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계;를 더 포함할 수 있다. 일 실시예에 따라, 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는: 상위 레벨의 제1 옵티컬 플로우, 상위 레벨의 제2 옵티컬 플로우, 상위 레벨의 제1 중요도 가중치, 상위 레벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 제상기 제3 프레임에서 상기 제1 프레임으로의 제 1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬 플로우를 획득하는 단계; 상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 제3 프레임의 시간 t에 대하여 순방향 워핑 된 제1 프레임, 시간 t에 대하여 순방향 워핑된 제2 프레임을 획득하는 단계; 및 순방향 워핑된 제1 프레임, 순 방향 워핑된 제2 프레임에 기초하여, 보간 필터 신경망를 통해, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계;를 더 포함할 수 있다. 일 실시예에 따라, 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계는: 상위 레벨의 제1 옵티컬 플로우, 상위 레벨의 제2 옵티컬 플로우, 상위 레벨의 제1 중요도 가중치, 상위 레벨의 제2 중요도 가중치에 기초하여, 중간 플로우 예측 신경망을 통해, 제상기 제3 프레임에서 상기 제1 프레임으로의 제 1 중간 옵티컬 플로우, 상기 제3 프레임에서 상기 제2 프레임으로의 제2 중간 옵티컬 플로우를 획득하는 단계; 상기 제1 중간 옵티컬 플로우, 제2 중간 옵티컬 플로우에 기초하여, 제3 프레임의 시간 t에 대하여 역방향 워핑 된 제1 프레임, 시간 t에 대하여 역방향 워핑된 제2 프레임을 획득하는 단계; 및 역방향 워핑된 제1 프레임, 역 방향 워핑된 제2 프레임에 기초하여, 보간 필터 신경망를 통해, 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정하는 단계;를 더 포함할 수 있다. 일 실시예에 따라, 소정 레벨의 제1 옵티컬 플로우는 제1 순방향 워핑 특징 맵과 소정 레벨의 제2 특징 맵 사이 의 제1 상관 값에 기초하여 업데이트되고, 소정 레벨의 제2 옵티컬 플로우는 제2 순방향 워핑 특징 맵과 소정 레벨의 제1 특징 맵 사이의 제2 상관 값에 기초하여 업데이트될 수 있다. 일 실시예에 따라, 소정 레벨의 제1 순방향 워핑 특징 맵의 미리 정해진 범위 내의 후보 픽셀들과 제1 상관 값 에 기초하여 소정 레벨의 제1 옵티컬 플로우가 업데이트되고, 소정 레벨의 제2 순방향 워핑 특징 맵의 미리 정 해진 범위 내의 후보 픽셀들과 제2 상관 값에 기초하여 소정 레벨의 제2 옵티컬 플로우가 업데이트될 수 있다. 일 실시예에 따라, 미리 정해진 범위는 소정 레벨의 크기에 따라 달라질 수 있다. 구체적으로, 미리 정해진 범 위는 특징 맵의 상관 값 계산의 대상이 되는 픽셀을 중심으로 반경 r 만큼의 범위이고, 대상 픽셀의 좌표가 (x, y)라면, (x-r≤x≤x+r, y-r≤y≤y+r)의 범위이다. 여기서, 반경 r의 크기가 소정 레벨의 크기에 따라 달라질 수 있다. 일 실시예에 따라, 제1 상관 값의 계산에 이용되는 픽셀들은 사용자에 의해 설정된 필터에 의해 결정되고, 제2 상관 값의 계산에 이용되는 픽셀들은 사용자에 의해 설정된 필터에 의해 결정될 수 있다. 일 실시예에 따라, 제1 상관 값의 계산에 이용되는 픽셀들은 훈련된 신경망에 기초하여 결정되고, 제2 상관 값 의 계산에 이용되는 픽셀들은 훈련된 신경망에 기초하여 결정될 수 있다. 일 실시예에 따라, 소정 레벨의 제2 특징 맵의 미리 정해진 범위 내의 픽셀과의 상관 값 중 가장 높은 상관 값 이 제1 상관 값으로 결정되고, 소정 레벨의 상기 제1 특징 맵의 미리 정해진 범위 내의 픽셀과의 상관 값 중 가 장 높은 상관 값이 제2 상관 값으로 결정될 수 있다. 일 실시예에 따라, 복수의 레벨 중 최하위 레벨에서 초기에 획득되는 제1 옵티컬 플로우와 제2 옵티컬 플로우는 0으로 설정될 수 있다. S860 단계에서, AI에 기반한 프레임 보간 장치는 보간 필터 신경망을 통해, 상기 획득된 상위 레벨의 제1 옵티컬 플로우 및 상기 획득된 상위 레벨의 제2 옵티컬 플로우를 이용하여, 제1 프레임과 제2 프레임 사이의 제 3 프레임에 대한 AI 기반 프레임 보간 필터를 결정한다. 일 실시예에 따라, AI 기반 프레임 보간 필터는 상기 제1 프레임 및 상기 제2 프레임 내의 픽셀들 각각에 대응 하는 하나의 필터 커널을 포함할 수 있다. 일 실시예에 따라, AI 기반 프레임 보간 필터를 결정하기 위해, 보간 필터 신경망에 제1 프레임 및 제2 프레임 의 문맥적 특징 맵이 추가로 입력되고, 문맥적 특징 맵은 제1 프레임 및 제2 프레임을 입력으로하는 제2 신경망 의 출력 값과 제1 프레임 및 제2 프레임을 입력으로하는 미리결정된 분류 네트워크의 출력 값의 합으로 결정될 수 있다. 미리결정된 분류 네트워크는 옥스포드 대학의 연구팀 VGG에 의해 개발된 VGGNet의 구조 중 하나인 VGG16 또는 ResNet 중 하나일 수 있다. 또한, 미리결정된 분류 네트워크의 출력 값은 네트워크의 최종 레이어의 출력 값, 네트워크의 중간 레이어에서의 출력 값, 네트워크의 일부 레이어의 출력 값, 중간 레이어 또는 최종 레이어에서의 출력 값 중 일부 중 하나일 수 있다. 일 실시예에 따라, AI 기반 프레임 보간 필터는 서브 픽셀의 계산을 위해 이용되는 바이리니어 보간에 대한 필 터 커널을 더 포함할 수 있다. 일 실시예에 따라, AI 기반 프레임 보간 필터는 제3 프레임의 시간 및 Z-map 중 적어도 하나에 기초한 필터 커 널을 더 포함할 수 있다. 일 실시예에 따라, 제1 프레임에 대한 깊이 정보 및 제2 프레임에 대한 깊이 정보가 존재하면, 제1 프레임에 대 한 깊이 정보 및 제2 프레임에 대한 깊이 정보가 보간 필터 신경망에 추가로 입력될 수 있다.S870 단계에서, AI에 기반한 프레임 보간 장치는 제1 프레임, 제2 프레임, 및 AI 기반 프레임 보간 필터를 이용하여 제3 프레임을 획득한다. 일 실시예에 따라, AI 기반 프레임 보간 필터는 제1 프레임에 적용되는 제1 프레임 보간 필터와 제2 프레임에 적용되는 제2 프레임 보간 필터를 포함할 수 있다. 도 9는 일 실시예에 따른 AI에 기반한 프레임 보간 장치의 구성을 도시하는 도면이다. 도 9를 참조하면, AI에 기반한 프레임 보간 장치는 특징 맵 획득부, 옵티컬 플로우 획득부, 순 방향 워핑 특징맵 획득부, 옵티컬 플로우 업데이트부, 옵티컬 플로우 업스케일부, 보간 필터 획 득부 및 프레임 획득부를 포함한다. 특징 맵 획득부, 순방향 워핑 특징맵 획득부, 옵티컬 플로우 업데이트부, 옵티컬 플로우 업스케 일부, 보간 필터 획득부 및 프레임 획득부는 프로세서로 구현될 수 있고, 특징 맵 획득부, 순방향 워핑 특징맵 획득부, 옵티컬 플로우 업데이트부, 옵티컬 플로우 업스케일부, 보간 필터 획득부 및 프레임 획득부는 메모리(미도시)에 저장된 인스트럭션에 따라 동작할 수 있다. 도 9는 특징 맵 획득부, 순방향 워핑 특징맵 획득부, 옵티컬 플로우 업데이트부, 옵티컬 플로우 업스케일부, 보간 필터 획득부 및 프레임 획득부를 개별적으로 도시하고 있으나, 특징 맵 획득 부, 순방향 워핑 특징맵 획득부, 옵티컬 플로우 업데이트부, 옵티컬 플로우 업스케일부, 보간 필터 획득부 및 프레임 획득부는 하나의 프로세서를 통해 구현될 수 있다. 이 경우, 특징 맵 획 득부, 순방향 워핑 특징맵 획득부, 옵티컬 플로우 업데이트부, 옵티컬 플로우 업스케일부, 보간 필터 획득부 및 프레임 획득부는 전용 프로세서로 구현되거나, AP(application processor), CPU(central processing unit) 또는 GPU(graphic processing unit)와 같은 범용 프로세서와 소프트웨어의 조합 을 통해 구현될 수도 있다. 또한, 전용 프로세서의 경우, 본 개시의 실시예를 구현하기 위한 메모리를 포함하거 나, 외부 메모리를 이용하기 위한 메모리 처리부를 포함할 수 있다. 특징 맵 획득부, 순방향 워핑 특징맵 획득부, 옵티컬 플로우 업데이트부, 옵티컬 플로우 업스케 일부, 보간 필터 획득부 및 프레임 획득부는 복수의 프로세서로 구성될 수도 있다. 이 경우, 전 용 프로세서들의 조합으로 구현되거나, AP, CPU 또는 GPU와 같은 다수의 범용 프로세서들과 소프트웨어의 조합 을 통해 구현될 수도 있다. 특징 맵 획득부는 영상의 연속적인 프레임들 중에서, 제1 프레임에 대한 복수의 레벨의 제1 특징 맵들 및 제2 프레임에 대한 복수의 레벨의 제2 특징 맵들을 획득한다. 옵티컬 플로우 획득부는 플로우 예측 신경망을 통해, 소정 레벨의 제1 특징 맵에서 제2 특징 맵으로의 제1 옵티컬 플로우 및 상기 소정 레벨의 상기 제2 특징 맵에서 상기 제1 특징 맵으로의 제2 옵티컬 플로우를 획득한 다. 순방향 워핑 특징맵 획득부는 상기 제1 옵티컬 플로우를 이용하여 상기 제1 특징 맵이 순방향 워핑된 제1 순방향 워핑 특징 맵을 획득하고, 상기 제2 옵티컬 플로우를 이용하여 상기 제2 특징 맵이 순방향 워핑된 제2 순방향 워핑 특징 맵을 획득한다. 옵티컬 플로우 업데이트부는 상기 제1 순방향 워핑 특징 맵을 이용하여 상기 제1 옵티컬 플로우를 업데이 트하고, 상기 제2 순방향 워핑 특징 맵을 이용하여 상기 제2 옵티컬 플로우를 업데이트한다. 옵티컬 플로우 업스케일부는 상기 업데이트된 제1 옵티컬 플로우를 상기 소정 레벨의 상위 레벨에 대응하 도록 업스케일하여 상위 레벨의 제1 옵티컬 플로우를 획득하고, 상기 업데이트된 제2 옵티컬 플로우를 상기 상 위 레벨에 대응하도록 업스케일하여 상위 레벨의 제2 옵티컬 플로우를 획득한다. 보간 필터 획득부는 보간 필터 신경망을 통해, 상위 레벨의 제1 옵티컬 플로우, 상위 레벨의 제2 옵티컬 플로우를 이용하여, 제1 프레임과 제2 프레임 사이의 제3 프레임에 대한 AI 기반 프레임 보간 필터를 결정한다. 프레임 획득부는 제1 프레임, 제2 프레임, 및 AI 기반 프레임 보간 필터를 이용하여 제3 프레임을 획득한 다. 한편, 상술한 본 개시의 실시예들은 컴퓨터에서 실행될 수 있는 프로그램으로 작성가능하고, 작성된 프로그램은 기기로 읽을 수 있는 저장매체에 저장될 수 있다.기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2022-0019101", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 AI에 기반한 영상의 프레임 보간 과정의 일 예를 도시하는 도면이다. 도 2는 프레임 사이의 옵티컬 플로우에 기초한 역방향 워핑 및 순방향 워핑의 일 예를 설명하기 위한 도면이다. 도 3a는 역방향 워핑된 특징 맵을 이용하여 상관 값을 계산하는 방법의 일 예를 도시하고, 도 3b는 역방향 워핑 된 특징 맵을 이용하여 상관 값을 계산하는 방법의 다른 예를 도시하고, 도 3c는 순방향 워핑된 특징 맵을 이용 하여 상관 값을 계산하는 방법의 일 예를 도시한다. 도 4는 상관 값 계산 시에 계산의 대상이 되는 픽셀의 후보를 선택하기 위해 이용되는 필터의 일 예를 설명하기 위한 도면이다. 도 5는 옵티컬 플로우를 업데이트하는 방법의 일 예를 설명하기 위한 도면이다. 도 6은 AI에 기반한 프레임 보간 필터를 통해 프레임을 보간하는 과정의 일 예를 설명하기 위한 도면이다. 도 7은 AI에 기반한 프레임 보간 필터의 일 예를 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 AI에 기반한 프레임 보간 방법의 순서도이다. 도 9는 일 실시예에 따른 AI에 기반한 프레임 보간 장치의 구성을 도시하는 도면이다."}
