{"patent_id": "10-2018-0046511", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0122955", "출원번호": "10-2018-0046511", "발명의 명칭": "인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치, 이를 위한 방법 및 이 방법을 수", "출원인": "(주)이스트소프트", "발명자": "권택순"}}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치에 있어서, 실제 안경을 착용한 사람의 영상인 원본착용영상이 입력되면, 가중치가 적용되는 복수의 연산을 통해 상기 원본착용영상으로부터 가공된 안경을 미착용한 사람의 영상인 가공미착용영상 및 상기 가공미착용영상 중 상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내는 가공안경마스크를 생성하는 생성기; 실제 안경을 미착용한 사람의 영상인 원본미착용영상 및 상기 가공미착용영상 중 어느 하나의 영상이 입력되면,입력된 영상에 대해 가중치가 적용되는 복수의 연산을 통해 상기 입력된 영상이 실제인지 혹은 가공된 것인지여부를 출력하는 글로벌판별기; 상기 원본미착용영상의 일부 영역인 원본로컬영상 및 상기 가공미착용영상의 일부 영역인 가공로컬영상 중 어느하나의 로컬 영상을 입력받고, 입력된 로컬 영상에 대해 가중치가 적용되는 복수의 연산을 통해 상기 입력된 로컬 영상이 실제인지 혹은 가공된 것인지 여부를 출력하는 로컬판별기; 및 상기 글로벌판별기에 상기 원본미착용영상이 입력되면 실제인 것으로 출력하고 상기 가공미착용영상이 입력되면가공된 것으로 출력하도록 상기 글로벌판별기를 학습시키고, 상기 로컬판별기에 상기 원본로컬영상이 입력되면실제인 것으로 출력하고 상기 가공로컬영상이 입력되면 가공된 것으로 출력하도록 상기 로컬판별기를 학습시키며, 상기 글로벌판별기가 상기 입력된 가공미착용영상을 실제인 것으로 출력하고 상기 로컬판별기가 상기 입력된 가공로컬영상을 실제인 것으로 출력하도록 상기 생성기를 학습시키는 학습부;를 포함하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 장치."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 가공미착용영상은 상기 원본착용영상의 각 픽셀에 대응하는 RGB 값으로 이루어지며, 상기 가공안경마스크는 상기 원본착용영상의 각 픽셀에 대응하여 상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내는지 여부를 나타내는 플래그값으로 이루어지는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 장치."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 안경을 착용한 사용자를 촬영하여 사용자의 원본착용영상을 생성하는 카메라부; 및 상기 사용자의 원본착용영상을 상기 생성기에 입력하여 사용자의 가공미착용영상을 생성하는 영상생성부;를 더포함하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 장치."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 복수의 안경 이미지를 표시하는 표시부;를 더 포함하며, 상기 영상생성부는 사용자의 선택에 따라 복수의 안경 이미지 중 선택된 안경 이미지를 상기 사용자의 가공미착용영상에 합성하여 합성착용영상을 생성하고, 생성된 합성착용영상을 상기 표시부를 통해 표시하는 것을 특징으공개특허 10-2019-0122955-3-로 하는 안경 착용 영상을 생성하기 위한 장치."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 학습부는, 상기 글로벌판별기 및 상기 로컬판별기를 학습시키는 절차와, 상기 생성기를 학습시키는 절차를 교대로 반복하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 장치."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 학습부는, 상기 글로벌판별기 및 상기 로컬판별기를 학습시킬 때, 상기 글로벌판별기가 상기 가공미착용영상이 입력되면가공된 것으로 출력하도록 상기 글로벌판별기의 가중치를 수정하고, 상기 로컬판별기가 상기 가공로컬영상이 입력되면 가공된 것으로 출력하도록 상기 로컬판별기의 가중치를 수정하는 것을 특징으로 하는 안경 착용 영상을생성하기 위한 장치."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 학습부는, 상기 생성기를 학습시킬 때, 상기 글로벌판별기가 상기 가공미착용영상이 입력되면 실제인 것으로 출력하고, 상기 로컬판별기가 상기 가공로컬영상이 입력되면 실제인 것으로 출력하도록 상기 생성기의 가중치를 수정하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 장치."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공신경망을 이용한 안경 착용 영상을 생성하기 위한 방법에 있어서, 생성기가, 실제 안경을 착용한 사람의 영상인 원본착용영상이 입력되면, 가중치가 적용되는 복수의 연산을 통해상기 원본착용영상으로부터 가공된 안경을 미착용한 사람의 영상인 가공미착용영상 및 상기 가공미착용영상 중상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내는 가공안경마스크를 생성하는 단계; 학습부가, 상기 글로벌판별기가 실제 안경을 미착용한 사람의 영상인 원본미착용영상이 입력되면 실제인 것으로출력하고, 상기 가공미착용영상이 입력되면 가공된 것으로 출력하도록 하고, 상기 로컬판별기가 상기 원본미착용영상의 일부 영역인 원본로컬영상이 입력되면 실제인 것으로 출력하고, 상기 가공미착용영상의 일부 영역인가공로컬영상이 입력되면 가공된 것으로 출력하도록 상기 글로벌판별기 및 상기 로컬판별기를 학습시키는 단계;및 상기 학습부가, 상기 글로벌판별기가 상기 가공미착용영상을 실제인 것으로 출력하고, 상기 로컬판별기가 상기가공로컬영상을 실제인 것으로 출력하도록 상기 생성기를 학습시키는 단계;를 포함하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 방법."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 공개특허 10-2019-0122955-4-상기 가공미착용영상은 상기 원본착용영상의 각 픽셀에 대응하는 RGB 값으로 이루어지며, 상기 가공안경마스크는 상기 원본착용영상의 각 픽셀에 대응하여 상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내는지 여부를 나타내는 플래그값으로 이루어지는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 방법."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 제어부가 카메라부를 통해 안경을 착용한 사용자를 촬영하여 사용자의 원본착용영상을 생성하는 단계; 및 영상생성부가 상기 사용자의 원본착용영상을 상기 생성기에 입력하여 사용자의 가공미착용영상을 생성하는단계;를 더 포함하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 방법."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 영상생성부가 복수의 안경 이미지 중 선택된 안경 이미지를 상기 사용자의 가공미착용영상에 합성하여 합성착용영상을 생성하는 단계; 및 상기 영상생성부가 상기 생성된 합성착용영상을 표시부를 통해 표시하는 단계;를 더 포함하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 방법."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 글로벌판별기 및 상기 로컬판별기를 학습시키는 단계와 상기 생성기를 학습시키는 단계를 교대로 반복하는것을 특징으로 하는 안경 착용 영상을 생성하기 위한 방법."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 글로벌판별기 및 상기 로컬판별기를 학습시키는 단계는, 상기 학습부가 상기 글로벌판별기가 상기 가공미착용영상이 입력되면 가공된 것으로 출력하도록 상기 글로벌판별기의 가중치를 수정하고, 상기 로컬판별기가 상기 가공로컬영상이 입력되면 가공된 것으로 출력하도록 상기로컬판별기의 가중치를 수정하는 것을 특징으로 하는 안경 착용 영상을 생성하기 위한 방법."}
{"patent_id": "10-2018-0046511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 생성기를 학습시키는 단계는,상기 학습부가 상기 글로벌판별기가 상기 가공미착용영상이 입력되면 실제인 것으로 출력하고, 상기 로컬판별기가 상기 가공로컬영상이 입력되면 실제인 것으로 출력하도록 상기 생성기의 가중치를 수정하는 것을 특징으로하는 안경 착용 영상을 생성하기 위한 방법. 공개특허 10-2019-0122955-5-청구항 15 제8항 내지 제14항 중 어느 한 항에 따른 안경 착용 영상을 생성하기 위한 방법을 수행하는 프로그램이 기록된컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체에 관한 것으로, 이러한 본 발명은 원본착용영상이 입력되면, 가 중치가 적용되는 복수의 연산을 통해 원본착용영상으로부터 가공미착용영상 및 가공안경마스크를 생성하는 생성 (뒷면에 계속)"}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 처리 기술에 관한 것으로, 보다 상세하게는, 얼굴 영상에 안경을 착용한 영상을 합성하는 영상 처리를 위한 장치, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체에 관한 것이다."}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능이라는 개념은 1956년 미국 다트머스 대학에 있던 존 매카시 교수가 개최한 다트머스 회의에서 처음 등장했으며, 최근 몇 년 사이 폭발적으로 성장하고 있는 중이다. 특히, 2015년 이후 신속하고 강력한 병렬 처리 성능을 제공하는 GPU의 도입으로 더욱 가속화되고 있다. 폭발적으로 늘어나고 있는 저장 용량과 이미지, 텍스트, 매핑 데이터 등 모든 영역의 데이터가 범람하게 된 '빅데이터' 시대의 도래도 이러한 성장세에 큰 영향 을 미치고 있다. 1956년 당시 인공 지능의 선구자들은 최종적으로 인간의 지능과 유사한 특성을 가진 복잡한 컴 퓨터를 제작하고자 했다. 이렇듯 인간의 감각, 사고력을 지닌 채 인간처럼 생각하는 인공 지능을 '일반 AI(General AI)'라고 하지만, 현재의 기술 발전 수준에서 만들 수 있는 인공지능은 '좁은 AI(Narrow AI)'의 개 념에 포함된다. 좁은 AI는 소셜 미디어의 이미지 분류 서비스나 얼굴 인식 기능 등과 같이 특정 작업을 인간 이 상의 능력으로 해낼 수 있는 것이 특징이다. 한편, 머신 러닝은 기본적으로 알고리즘을 이용해 데이터를 분석하 고, 분석을 통해 학습하며, 학습한 내용을 기반으로 판단이나 예측을 수행한다. 따라서 궁극적으로는 의사 결정 기준에 대한 구체적인 지침을 소프트웨어에 직접 코딩해 넣는 것이 아닌, 대량의 데이터와 알고리즘을 통해 컴 퓨터 그 자체를 '학습'시켜 작업 수행 방법을 익히는 것을 목표로 한다. 초기 머신 러닝 연구자들이 만들어 낸 또 다른 알고리즘인 인공 신경망(artificial neural network)에 영감을 준 것은 인간의 뇌가 지닌 생물학적 특 성, 특히 뉴런의 연결 구조다. 그러나 물리적으로 근접한 어떤 뉴런이든 상호 연결이 가능한 뇌와는 달리, 인공 신경망은 레이어 연결 및 데이터 전파 방향이 일정하다. 예를 들어, 이미지를 수많은 타일로 잘라 신경망의 첫 번째 레이어에 입력하면, 그 뉴런들은 데이터를 다음 레이어로 전달하는 과정을 마지막 레이어에서 최종 출력이 생성될 때까지 반복한다. 그리고 각 뉴런에는 수행하는 작업을 기준으로 입력의 정확도를 나타내는 가중치가 할 당되며, 그 후 가중치를 모두 합산해 최종 출력이 결정된다. 딥 러닝은 인공신경망에서 발전한 형태의 인공 지 능으로, 뇌의 뉴런과 유사한 정보 입출력 계층을 활용해 데이터를 학습한다. 딥 러닝의 등장으로 인해 머신 러 닝의 실용성은 강화됐고, 인공 지능의 영역은 확장됐다. 딥 러닝은 컴퓨터 시스템을 통해 지원 가능한 모든 방 식으로 작업을 세분화한다. [선행기술문헌] [특허문헌] 한국공개특허 제2013-0103153호 2013년 09월 23일 공개 (명칭: 고객 맞춤형 안경 및 콘택트렌즈 버추얼 피팅 방 법 및 그 시스템)"}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 안경을 착용한 사람의 영상에 기존의 안경을 소거하고 사용자가 선택한 새로운 안경을 착용한 영상을 가상으로 생성하여 안경 착용자가 착용한 안경을 벗지 않고도 자신이 선택한 안경을 가상으로 피팅한 영 상을 살펴볼 수 있도록 하는 장치, 이를 위한 방법 및 이 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능 한 기록매체를 제공함에 있다."}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 바와 같은 목적을 달성하기 위한 본 발명의 바람직한 실시예에 따른 인공신경망을 이용한 안경 착용 영 상을 생성하기 위한 장치는 실제 안경을 착용한 사람의 영상인 원본착용영상이 입력되면, 가중치가 적용되는 복 수의 연산을 통해 상기 원본착용영상으로부터 가공된 안경을 미착용한 사람의 영상인 가공미착용영상 및 상기 가공미착용영상 중 상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내는 가공안경마스크를 생성 하는 생성기와, 실제 안경을 미착용한 사람의 영상인 원본미착용영상 및 상기 가공미착용영상 중 어느 하나의 영상이 입력되면, 입력된 영상에 대해 가중치가 적용되는 복수의 연산을 통해 상기 입력된 영상이 실제인지 혹 은 가공된 것인지 여부를 출력하는 글로벌판별기와, 상기 원본미착용영상의 일부 영역인 원본로컬영상 및 상기 가공미착용영상의 일부 영역인 가공로컬영상 중 어느 하나의 로컬 영상을 입력받고, 입력된 로컬 영상에 대해 가중치가 적용되는 복수의 연산을 통해 상기 입력된 로컬 영상이 실제인지 혹은 가공된 것인지 여부를 출력하는 로컬판별기와, 상기 글로벌판별기에 상기 원본미착용영상이 입력되면 실제인 것으로 출력하고 상기 가공미착용 영상이 입력되면 가공된 것으로 출력하도록 상기 글로벌판별기를 학습시키고, 상기 로컬판별기에 상기 원본로컬 영상이 입력되면 실제인 것으로 출력하고 상기 가공로컬영상이 입력되면 가공된 것으로 출력하도록 상기 로컬판 별기를 학습시키며, 상기 글로벌판별기가 상기 입력된 가공미착용영상을 실제인 것으로 출력하고 상기 로컬판별 기가 상기 입력된 가공로컬영상을 실제인 것으로 출력하도록 상기 생성기를 학습시키는 학습부를 포함한다. 상기 가공미착용영상은 상기 원본착용영상의 각 픽셀에 대응하는 RGB 값으로 이루어지며, 상기 가공안경마스크 는 상기 원본착용영상의 각 픽셀에 대응하여 상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내 는지 여부를 나타내는 플래그값으로 이루어지는 것을 특징으로 한다. 상기 장치는 안경을 착용한 사용자를 촬영하여 사용자의 원본착용영상을 생성하는 카메라부와, 상기 사용자의 원본착용영상을 상기 생성기에 입력하여 사용자의 가공미착용영상을 생성하는 영상생성부를 더 포함한다. 또한, 상기 장치는 복수의 안경 이미지를 표시하는 표시부를 더 포함한다. 상기 영상생성부는 사용자의 선택에 따라 복수의 안경 이미지 중 선택된 안경 이미지를 상기 사용자의 가공미착 용영상에 합성하여 합성착용영상을 생성하고, 생성된 합성착용영상을 상기 표시부를 통해 표시하는 것을 특징으 로 한다. 상기 학습부는 상기 글로벌판별기 및 상기 로컬판별기를 학습시키는 절차와, 상기 생성기를 학습시키는 절차를 교대로 반복하는 것을 특징으로 한다. 상기 학습부는, 상기 글로벌판별기 및 상기 로컬판별기를 학습시킬 때, 상기 글로벌판별기가 상기 가공미착용영 상이 입력되면 가공된 것으로 출력하도록 상기 글로벌판별기의 가중치를 수정하고, 상기 로컬판별기가 상기 가 공로컬영상이 입력되면 가공된 것으로 출력하도록 상기 로컬판별기의 가중치를 수정하는 것을 특징으로 한다. 상기 학습부는, 상기 생성기를 학습시킬 때, 상기 글로벌판별기가 상기 가공미착용영상이 입력되면 실제인 것으 로 출력하고, 상기 로컬판별기가 상기 가공로컬영상이 입력되면 실제인 것으로 출력하도록 상기 생성기의 가중 치를 수정하는 것을 특징으로 한다. 상술한 바와 같은 목적을 달성하기 위한 본 발명의 바람직한 실시예에 따른 인공신경망을 이용한 안경 착용 영 상을 생성하기 위한 방법은 생성기가, 실제 안경을 착용한 사람의 영상인 원본착용영상이 입력되면, 가중치가 적용되는 복수의 연산을 통해 상기 원본착용영상으로부터 가공된 안경을 미착용한 사람의 영상인 가공미착용영 상 및 상기 가공미착용영상 중 상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내는 가공안경마 스크를 생성하는 단계와, 학습부가, 상기 글로벌판별기가 실제 안경을 미착용한 사람의 영상인 원본미착용영상 이 입력되면 실제인 것으로 출력하고, 상기 가공미착용영상이 입력되면 가공된 것으로 출력하도록 하고, 상기 로컬판별기가 상기 원본미착용영상의 일부 영역인 원본로컬영상이 입력되면 실제인 것으로 출력하고, 상기 가공 미착용영상의 일부 영역인 가공로컬영상이 입력되면 가공된 것으로 출력하도록 상기 글로벌판별기 및 상기 로컬 판별기를 학습시키는 단계와, 상기 학습부가, 상기 글로벌판별기가 상기 가공미착용영상을 실제인 것으로 출력 하고, 상기 로컬판별기가 상기 가공로컬영상을 실제인 것으로 출력하도록 상기 생성기를 학습시키는 단계를 포 함한다. 상기 가공미착용영상은 상기 원본착용영상의 각 픽셀에 대응하는 RGB 값으로 이루어지며, 상기 가공안경마스크 는 상기 원본착용영상의 각 픽셀에 대응하여 상기 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내 는지 여부를 나타내는 플래그값으로 이루어지는 것을 특징으로 한다. 상기 방법은 제어부가 카메라부를 통해 안경을 착용한 사용자를 촬영하여 사용자의 원본착용영상을 생성하는 단 계와, 영상생성부가 상기 사용자의 원본착용영상을 상기 생성기에 입력하여 사용자의 가공미착용영상을 생성하 는 단계를 더 포함한다. 상기 방법은 상기 영상생성부가 복수의 안경 이미지 중 선택된 안경 이미지를 상기 사용자의 가공미착용영상에 합성하여 합성착용영상을 생성하는 단계와, 상기 영상생성부가 상기 생성된 합성착용영상을 표시부를 통해 표시 하는 단계를 더 포함한다. 특히, 상기 글로벌판별기 및 상기 로컬판별기를 학습시키는 단계와 상기 생성기를 학습시키는 단계는 교대로 반 복되는 것을 특징으로 한다. 상기 글로벌판별기 및 상기 로컬판별기를 학습시키는 단계는 상기 학습부가 상기 글로벌판별기가 상기 가공미착 용영상이 입력되면 가공된 것으로 출력하도록 상기 글로벌판별기의 가중치를 수정하고, 상기 로컬판별기가 상기 가공로컬영상이 입력되면 가공된 것으로 출력하도록 상기 로컬판별기의 가중치를 수정하는 것을 특징으로 한다. 상기 생성기를 학습시키는 단계는 상기 학습부가 상기 글로벌판별기가 상기 가공미착용영상이 입력되면 실제인 것으로 출력하고, 상기 로컬판별기가 상기 가공로컬영상이 입력되면 실제인 것으로 출력하도록 상기 생성기의 가중치를 수정하는 것을 특징으로 한다. 상술한 바와 같은 목적을 달성하기 위해 전술한 본 발명의 실시예에 따른 안경 착용 영상을 생성하기 위한 방법 을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록매체를 제공한다."}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "안경을 착용한 사용자의 영상에서 안경을 소거하지 않고 단순히 안경을 합성할 경우, 착용한 안경과 새로운 안 경이 겹쳐져 새로운 안경을 착용한 영상이 부자연스럽다. 따라서 사용자는 안경을 벗은 채로 촬영한 후, 새로운 안경을 합성한 영상을 생성한다. 하지만, 시력이 좋지 않은 안경 착용자는 안경을 벗은 상태에서 사물이 흐릿하 게 보이기 때문에 새로운 안경을 착용한 영상을 확인하기 위해서는 흐릿하게 보이는 영상을 확인하거나, 다시 안경을 착용해야 하는 번거로움이 있다. 하지만, 본 발명에 따르면, 안경 쓴 영상에서 안경을 소거한 후, 새로 운 안경을 착용한 영상을 제공한다. 따라서 안경 쓴 사람은 자신의 사진을 촬영할 때 안경을 벗은 채로 촬영할 필요가 없으며, 새로운 안경을 착용한 영상을 확인하기 위해 안경을 다시 착용하는 번거로움도 해소할 수 있다."}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 상세한 설명에 앞서, 이하에서 설명되는 본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거 나 사전적인 의미로 한정해서 해석되어서는 아니 되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명 하기 위해 용어의 개념으로 적절하게 정의할 수 있다는 원칙에 입각하여 본 발명의 기술적 사상에 부합하는 의 미와 개념으로 해석되어야만 한다. 따라서 본 명세서에 기재된 실시예와 도면에 도시된 구성은 본 발명의 가장 바람직한 실시예에 불과할 뿐, 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 출원시점에 있어서 이들을 대체할 수 있는 다양한 균등물과 변형 예들이 있을 수 있음을 이해하여야 한다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예들을 상세히 설명한다. 이때, 첨부된 도면에서 동일한 구성 요소는 가능한 동일한 부호로 나타내고 있음을 유의해야 한다. 또한, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략할 것이다. 마찬가지의 이유로 첨부 도면에 있어서 일부 구성요소 는 과장되거나 생략되거나 또는 개략적으로 도시되었으며, 각 구성요소의 크기는 실제 크기를 전적으로 반영하 는 것이 아니다. 먼저, 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치의 구성에 대해서 설 명하기로 한다. 도 1은 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치의 구성을 설명하기 위한 도면이다. 도 2는 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성 하기 위한 장치의 인공신경망의 세부 구성을 설명하기 위한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치(이하, '영상생성장치'로 칭함)는 카메라부, 입력부, 표시부, 저장부 및 제어부를 포함한다. 카메라부는 사용자의 영상, 즉, 사용자가 안경을 착용한 영상을 촬영하기 위한 것이다. 이러한 카메라부 는 이미지 센서를 포함한다. 이미지 센서는 피사체에서 반사되는 빛을 입력받아 전기신호로 변환하며, CCD(Charged Coupled Device), CMOS(Complementary Metal-Oxide Semiconductor) 등을 기반으로 구현될 수 있다. 카메라부는 아날로그-디지털 변환기(Analog to Digital Converter)를 더 포함할 수 있으며, 이미지 센서에서 출력되는 전기신호를 디지털 수열로 변환하여 제어부로 출력할 수 있다. 입력부는 사용자 장치의 각 종 기능, 동작 등을 제어하기 위한 사용자의 키 조작을 입력받고 입력 신 호를 생성하여 제어부에 전달한다. 입력부는 특수키, 키패드, 키보드, 마우스, 트랙볼 등을 예시할 수 있다. 특히, 입력부는 전원 on/off를 위한 전원 키, 문자 키, 숫자 키, 방향키 중 적어도 하나를 포함 할 수 있다. 입력부의 기능은 표시부가 터치스크린으로 구현된 경우, 표시부에서 이루어질 수 있으며, 표시부만으로 모든 기능을 수행할 수 있는 경우, 입력부는 생략될 수도 있다. 표시부는 제어부로부터 화면 표시를 위한 데이터를 수신하여 수신된 데이터를 화면으로 표시할 수 있 다. 또한, 표시부는 사용자 장치의 메뉴, 데이터, 기능 설정 정보 및 기타 다양한 정보를 사용자에게 시각적으로 제공할 수 있다. 표시부가 터치스크린으로 형성되는 경우, 입력부의 기능의 일부 또는 전 부를 대신 수행할 수 있다. 표시부는 액정표시장치(LCD, Liquid Crystal Display), 유기 발광 다이오드 (OLED, Organic Light Emitting Diodes), 능동형 유기 발광 다이오드(AMOLED, Active Matrix Organic Light Emitting Diodes) 등으로 형성될 수 있다. 저장부는 사용자 장치의 동작에 필요한 각 종 데이터, 어플리케이션, 사용자 장치의 동작에 따 라 발생된 각 종 데이터를 저장하는 역할을 수행한다. 이러한 저장부는 스토리지, 메모리 등이 될 수 있다. 이러한 저장부는 사용자 장치의 부팅(booting) 및 운영(operation)을 위한 운영체제(OS, Operating System), 본 발명의 실시예에 따른 게임을 제공하기 위한 애플리케이션을 저장할 수 있다. 저장부 에 저장되는 각 종 데이터는 사용자의 조작에 따라, 삭제, 변경, 추가될 수 있다. 제어부는 사용자 장치의 전반적인 동작 및 사용자 장치의 내부 블록들 간 신호 흐름을 제어하고, 데이터를 처리하는 데이터 처리 기능을 수행할 수 있다. 이러한 제어부는 중앙 처리 장치 (Central Processing Unit : CPU), 어플리케이션 프로세서(Application Processor), GPU(Graphic Processing Unit) 등이 될 수 있다. 제어부는 인공신경망(artificial neural network: 200), 학습부 및 영상생성부를 포함한다. 이 러한 인공신경망, 학습부 및 영상생성부는 하드웨어 형태로 제어부의 일 구성으로 구현되 거나, 소프트웨어 형태로 제어부에서 구동될 수 있다. 이러한 인공신경망, 학습부 및 영상생성 부를 포함하는 제어부의 동작은 아래에서 보다 상세하게 설명될 것이다. 또한 도시되진 않았으나, 본 발명의 실시예에 따른 사용자 장치는 메모리 카드와 같은 외부 저장 매체를 삽입하여 데이터 저장을 가능토록 하는 저장매체 삽입부, 외부 디지털 기기와의 데이터 교환을 위한 연결 단자, 충전용 단자를 구비할 수 있다. 또한, 사용자 장치는 마이크 및 스피커를 통해 오디오 신호를 입력 혹은 출력하는 오디오 처리부, 디지털 음원 재생을 위한 MP3 모듈 등의 부가 기능을 갖는 유닛들을 선택적으로 더 포 함하여 구성될 수 있다. 디지털 기기의 컨버전스(convergence) 추세에 따라 휴대 기기의 변형이 매우 다양하여"}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "모두 열거할 수는 없으나, 상기 언급된 유닛들과 동등한 수준의 유닛이 본 발명에 따른 사용자 장치에 추가로 더 포함되어 구성될 수 있다는 것은 본 기술분야의 통상의 지식을 가진 자라면 쉽게 이해할 수 있을 것이다. 그러면, 본 발명의 실시예에 따른 인공신경망에 대해서 보다 상세하게 설명하기로 한다. 도 2는 본 발명의 실시예에 따른 인공신경망의 구성을 설명하기 위한 도면이다. 도 3은 본 발명의 실시예에 따른 인공신경망의 생 성기의 출력값을 설명하기 위한 도면이다. 도 2를 참조하면, 인공신경망은 생성기, 글로벌판별기 및 로컬판별기를 포함한다. 생성기, 글로벌판별기 및 로컬판별기 각각이 독립적인 인공신경망이 될 수 있다. 이에 따라, 생 성기, 글로벌판별기 및 로컬판별기 각각은 복수의 계층으로 이루어져 있으며, 복수의 계층 각각 은 가중치가 적용되는 복수의 연산을 포함한다. 여기서, 복수의 계층은 컨볼루션 계층(convolution layer), 디 컨볼루션 계층(deconvolution layer), 풀링 계층(pooling layer), 완전연결계층(fully-connected layer) 등을 예시할 수 있다. 또한, 연산은 컨볼루션(convolution) 연산, 디컨볼루션(deconvolution) 연산, 최대 풀링(max- pooling) 연산, 최소 풀링(min-pooling) 연산, 소프트맥스(soft-max) 연산 등을 예시할 수 있다. 이러한 연산 들은 모두 각각 가중치를 포함한다. 예컨대, 컨볼루션 연산, 풀링 연산 등은 필터를 이용하며, 이러한 필터는 행렬로 이루어지고, 행렬의 각 원소의 값은 가중치가 될 수 있다. 생성기는 원본착용영상이 입력되면, 가중치가 적용되는 복수의 연산을 통해 가공미착용영상 및 가 공안경마스크를 출력한다. 여기서, 원본착용영상은 실제 안경을 착용한 사람의 영상을 의미한다. 또한, 가공미착용영상은 원본착용영상으로부터 가공된 안경을 미착용한 사람의 영상을 의미한다. 그리고 가공 안경마스크는 가공미착용영상 중 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타낸다. 도 3을 참조하여 보다 자세히 설명하면, 생성기는 원본착용영상의 각 픽셀에 대응하여 가중치가 적용 되는 복수의 연산을 통해 각 픽셀의 픽셀값(예컨대, RGB값)과 플래그값(예컨대, 비트 0 혹은 1)을 출력한다. 가 공미착용영상은 원본착용영상의 각 픽셀에 대응하여 복수의 연산을 통해 출력된 각 픽셀의 픽셀값(예컨 대, RGB값)으로 이루어진다. 또한, 가공안경마스크는 원본착용영상의 각 픽셀에 대응하여 복수의 연산 을 통해 출력된 플래그값(예컨대, 비트 0 혹은 1)으로 이루어진다. 예컨대, 원본착용영상의 픽셀 P01에 대 응하여 픽셀 P11의 픽셀값과 플래그값 F1이 출력될 수 있다. 또한, 원본착용영상의 P02에 대응하여 픽셀 P12의 픽셀값과 플래그값 F2가 출력될 수 있다. 즉, 플래그값은 도 3의 플래그값 F1과 같이, 원본착용영상 에서 안경이 위치한 영역(픽셀 P01)로부터 생성된 픽셀인지 혹은 도 3의 플래그값 F2와 같이, 안경이 위치하지 않은 영역(픽셀 P02)으로부터 생성된 픽셀인지 여부를 나타낸다. 도시된 바에 따르면, 픽셀 P11에 대응하는 플 래그값 F1은 비트 1이고, 이는 가공미착용영상 중 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타낸다. 또한, 픽셀 P11에 대응하는 플래그값 F2는 비트 0이고, 가공미착용영상 중 원본착용영상의 안경이 위치한 영역을 가공한 영역 이외의 영역을 나타낸다. 생성기는 단순히 원본착용영상으로부터 가중치가 적용되는 복수의 연산을 통해 가공미착용영상 뿐 만 아니라 가공안경마스크도 출력한다. 따라서 생성기는 학습을 통해 픽셀값인 3개의 채널, 즉, R(빨 강) 채널, G(초록) 채널, B(파랑) 채널뿐만 아니라, 해당 픽셀이 안경 영역에 속하는지 여부를 나타내는 플래그 값(마스크)에 대한 채널을 추가로 학습할 수 있다. 따라서 단순히 픽셀값으로 3개의 채널(RGB 채널)만을 학습하 는 것에 비교하였을 때, 안경을 벗었을 때 안경을 착용했던 영역에 대한 특징을 보다 명확하게 학습하고 보다 자연스러운 가공미착용영상을 생성할 수 있다. 글로벌판별기는 원본미착용영상 및 가공미착용영상 중 어느 하나의 영상이 입력되면, 입력된 영상에 대해 가중치가 적용되는 복수의 연산을 통해 입력된 영상이 실제인지 혹은 가공된 것인지 여부를 출력한다. 여기서, 원본미착용영상은 실제 안경을 미착용한 사람의 영상을 나타낸다. 또한, 가공미착용영상은 생성기가 생성 한 영상을 나타낸다. 로컬판별기는 원본미착용영상에서 임의의 일부 영역을 추출한 로컬 영상인 원본로컬영상 및 가공미착용영 상에서 임의의 일부 영역을 추출한 로컬 영상인 가공로컬영상을 입력받고, 입력된 로컬 영상에 대해 가중치가 적용되는 복수의 연산을 통해 입력된 로컬 영상이 실제인지 혹은 가공된 것인지 여부를 출력한다. 여기서, 원본 로컬영상의 원본미착용영상에서의 위치 및 크기와, 가공로컬영상의 가공미착용영상에서의 위치 및 크기는 랜덤 으로 결정된다. 다음으로, 보다 자세히 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하기 위한 방법에 대해서 설며하기로 한다. 본 발명은 인공신경망을 이용하기 위하여 인공신경망을 학습시킨다. 이러한학습 방법에 대해서 설명하기로 한다. 본 발명은 글로벌판별기 및 로컬판별기에 대한 학습과 생성기에 대한 학습을 번갈아가면서 수행 한다. 먼저, 글로벌판별기 및 로컬판별기에 대한 학습에 대해서 설명하기로 한다. 먼저, 글로벌판별기 및 로컬판별기에 대한 학습에 대해서 설명하기로 한다. 도 4는 본 발명의 실시예 에 따른 글로벌판별기 및 로컬판별기에 대한 학습 방법을 설명하기 위한 도면이다. 도 5는 본 발명의 실시예에 따른 글로벌판별기 및 로컬판별기에 대한 학습 방법을 설명하기 위한 흐름도이다. 먼저, 도 4를 참조하면, 글로벌판별기 및 로컬판별기를 포함하는 판별기를 학습시키기 위한 학습 데 이터는 원본 영상 및 가공 영상을 이용할 수 있다. 즉, 학습 데이터는 원본착용영상, 원본미착용영상, 원본로컬영상, 가공미착용영상 및 가공로컬영상을 포함한다. 원본착용영상은 사람이 안경을 착 용한 영상이다. 그리고 원본미착용영상은 사람이 안경을 미착용한 영상이다. 또한, 원본로컬영상은 원 본미착용영상으로부터 추출된 원본미착용영상의 일부이다. 원본착용영상 및 원본미착용영상은 실제 사람을 촬영한 영상이며, 원본로컬영상은 원본미착용영상으로부터 생성된다. 반면, 가공미착용영 상 및 가공로컬영상는 생성기에 의해 원본착용영상으로부터 가공된 영상이다. 즉, 생성기 는 원본착용영상이 입력되면, 복수의 연산을 통해 원본착용영상의 안경 부분을 제거하고, 제거된 부분에 안경을 착용하지 않았다면 보이는 얼굴 부분을 채워 넣은 가공미착용영상을 출력한다. 이때, 생성기 는 원본착용영상의 각 픽셀에 대응하여 복수의 연산을 통해 RGB 값을 출력한다. 이에 따라, 가공미착 용영상은 원본착용영상의 각 픽셀에 대응하여 생성기로부터 출력된 RGB 값으로 이루어진다. 이와 함께, 생성기는 가공미착용영상의 안경을 제거하고 얼굴을 채워 넣은 부분, 즉, 원본착용영상의 안경이 위치한 영역을 가공한 영역을 나타내는 가공안경마스크를 생성한다. 여기서, 가공로컬영상은 가 공안경마스크와는 별개로 가공미착용영상으로부터 추출된 가공미착용영상의 일부이다. 즉, 가공로 컬영상은 가공미착용영상으로부터 생성된다. 도 4 및 도 5를 참조하면, 학습부는 S110 단계에서 글로벌판별기 및 로컬판별기에 학습 데이터 를 입력한다. 학습부는 글로벌판별기에 원본미착용영상 및 가공미착용영상 중 어느 하나를 학습 데이터로 입력할 수 있다. 또한, 학습부는 원본미착용영상으로부터 원본로컬영상을 추출하거 나, 가공미착용영상으로부터 가공로컬영상을 추출하여 로컬판별기에 원본로컬영상 및 가공로 컬영상 중 어느 하나의 로컬 영상을 학습 데이터로 입력할 수 있다. 원본미착용영상 및 이로부터 추출 되는 원본로컬영상은 저장부에 미리 저장된 것을 이용할 수 있다. 또한, 가공미착용영상 및 이로 부터 추출되는 가공로컬영상은 생성기에 원본착용영상을 입력하여 생성기를 통해 생성한 것 을 사용한다. 학습 데이터가 입력되면, 글로벌판별기 및 로컬판별기는 S120 단계에서 복수의 연산을 통해 입력된 학습 데이터가 실제(real)인지 혹은 가공(fake)된 것인지를 나타내는 출력값을 출력한다. 여기서, 출력값은 입 력된 학습 데이터가 실제(real)일 확률 및 가공(fake)된 것일 확률을 포함한다. 즉, 글로벌판별기는 원본 미착용영상이 입력되면, 복수의 가중치가 적용되는 연산을 통해 원본미착용영상이 실제(real)일 확률 및 가공(fake)된 것일 확률을 출력값으로 출력할 수 있다. 또한, 글로벌판별기는 가공미착용영상이 입 력되면, 복수의 가중치가 적용되는 연산을 통해 가공미착용영상이 실제일 확률 및 가공된 것일 확률을 출력 값으로 출력할 수 있다. 예컨대, 출력값은 실제일 확률 93%, 가공된 것일 확률 7%가 될 수 있다. 마찬가지로, 로컬판별기는 원본로컬영상 또는 가공로컬영상이 입력되면, 복수의 가중치가 적용되 는 연산을 통해 입력된 원본로컬영상 또는 가공로컬영상이 실제(real)일 확률 및 가공(fake)된 것일 확 률을 출력값으로 출력한다. 예컨대, 출력값은 실제일 확률 15%, 가공된 것일 확률 85%가 될 수 있다. 한편, 글로벌판별기 및 로컬판별기를 학습시키기 위한 목표는 글로벌판별기 및 로컬판별기 각각이 원본미착용영상 및 원본로컬영상을 실제인 것으로 판별하고, 가공미착용영상 및 가공로컬영 상을 가공된 것으로 판별하도록 하는 것이다. 이에 따라, 학습 데이터 각각에 대응하여 목표값이 설정되며, 예컨대, 목표값은 원본미착용영상 또는 원본로컬영상의 경우, 실제일 확률 100%, 가공된 것일 확률 0% 로 설정될 수 있다. 또한, 가공미착용영상 또는 가공로컬영상의 경우, 목표값은 실제일 확률 0%, 가공 된 것일 확률 100%로 설정될 수 있다. 하지만, 학습이 충분히 완료되기 전, 글로벌판별기 및 로컬판별기의 출력값은 목표값과 차이가 있다. 따라서 학습부는 S130 단계에서 글로벌판별기 및 로컬판별기의 출력값과 목표값을 비교하여,S140 단계에서 목표값과 출력값의 차이가 최소가 되도록 역전파(back-propagation) 알고리즘을 통해 글로벌판별 기 및 로컬판별기의 가중치를 수정한다. 이는 즉, 글로벌판별기가 원본미착용영상이 입력되 면, 입력된 원본미착용영상을 실제인 것으로 출력하고, 가공미착용영상이 입력되면, 가공미착용영상 이 가공된 것으로 출력하도록 학습하는 것을 의미한다. 또한, 로컬판별기가 원본로컬영상이 입력 되면, 입력된 원본로컬영상을 실제인 것으로 출력하도록 학습하고, 가공로컬영상이 입력되면, 입력된 가공로컬영상을 가공된 것으로 출력하도록 학습하는 것을 의미한다. 이와 같이, 도 4 및 도 5를 참조로 하는 실시예에서 생성기의 가중치를 수정하는 학습은 이루어지지 않는 다는 점에 유의하여야 한다. 전술한 바와 같이, 글로벌판별기 및 로컬판별기에 대한 학습 후, 생성기 에 대한 학습을 수행한다. 그러면, 생성기에 대한 학습에 대해서 설명하기로 한다. 도 6은 본 발명의 실시예에 따른 생성기에 대한 학습 방법을 설명하기 위한 도면이다. 도 7은 본 발명의 실시예에 따른 생성기에 대한 학습 방법을 설명하기 위한 흐름도이다. 먼저, 도 6을 참조하면, 생성기를 학습시키기 위한 학습 데이터는 원본착용영상을 이용한다. 전술한 바와 같이, 원본착용영상은 사람이 안경을 착용한 영상이다. 도 7을 참조하면, 학습부는 S210 단계에서 원본착용영상을 생성기에 입력한다. 그러면, 생성기 는 S220 단계에서 가각이 가중치가 적용되는 복수의 연산을 통해 가공미착용영상 및 가공안경마스크 를 출력한다. 가공미착용영상은 원본착용영상의 각 픽셀에 대응하여 생성기로부터 출력된 RGB 값으로 이루어진다. 또한, 가공안경마스크는 원본착용영상의 각 픽셀에 대응하여 생성기로부터 출 력된 플래그값으로 이루어진다. 플래그값은 도 3의 플래그값 F1과 같이, 원본착용영상에서 안경이 위치한 영역(픽셀 P01)로부터 생성된 픽셀인지 혹은 도 3의 플래그값 F2와 같이, 안경이 위치하지 않은 영역(픽셀 P0 2)으로부터 생성된 픽셀인지 여부를 나타낸다. 그러면, 학습부는 S230 단계에서 글로벌판별기에 가공미착용영상을 입력시키고, 가공미착용영상 으로부터 가공로컬영상을 추출한 후, 추출된 가공로컬영상을 로컬판별기에 입력한다. 이에 따 라, S240 단계에서 글로벌판별기 및 로컬판별기 각각은 가중치가 적용되는 복수의 연산을 통해 가공 미착용영상 및 가공로컬영상 각각이 실제(real)일 확률과 가공(fake)된 것일 확률을 출력한다. 한편, 생성기를 학습시키기 위한 목표는 생성기가 생성한 영상, 즉, 가공미착용영상 및 가공로컬 영상을 글로벌판별기 및 로컬판별기가 실제인 것으로 판별하도록 하는 것이다. 이에 따라, 목표 값이 설정되며, 예컨대, 목표값은 판별기(220, 230) 학습과는 반대로 실제일 확률 100%, 가공된 것일 확률 0%로 설정될 수 있다. 하지만, 학습이 충분히 완료되기 전, 글로벌판별기 및 로컬판별기의 출력값은 목표값과 차이가 있다. 따라서 학습부는 S250 단계에서 글로벌판별기 및 로컬판별기의 출력값과 목표값을 비교하여, S260 단계에서 목표값과 출력값의 차이가 최소가 되도록 역전파(back-propagation) 알고리즘을 통해 글로벌판별 기 및 로컬판별기의 가중치를 수정하지 않고, 생성기의 가중치만 수정한다. 이는 즉, 생성기 가 생성한 가공미착용영상이 글로벌판별기에 입력되면, 글로벌판별기가 가공미착용영상(3 0)이 실제인 것으로 출력하도록 학습하고, 가공로컬영상이 로컬판별기에 입력되면, 로컬판별기가 입력된 가공로컬영상을 실제인 것으로 출력하도록 학습하는 것을 의미한다. 이와 같이, 도 6 및 도 7을 참 조로 하는 실시예에서 생성기의 가중치를 수정하지만, 글로벌판별기 및 로컬판별기에 대한 가중 치를 수정하지 않는다는 점에 유의하여야 한다. 한편, 전술한 바와 같이, 도 4 및 도 5를 참조로 하는 판별기 학습 절차와 도 6 및 도 7을 참조로 하는 학습 절 차가 번갈아가면서 수행된다. 이러한 학습 절차는 생성기, 글로벌판별기 및 로컬판별기의 가중 치의 변화가 없을 때까지 반복하여 수행된다. 본 발명은 전술한 도 4 내지 도 7에서 설명된 바와 같은 절차에 따라 학습이 충분히 이루어진 인공신경망을 이 용하여 안경 착용 영상을 생성한다. 이러한 안경 착용 영상을 생성하는 방법에 대해서 설명하기로 한다. 도 8은 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하는 방법을 설명하기 위한 흐름도이다. 도 8에서 사용자는 안경을 착용한 사람이며, 새로운 안경을 구매하기 위한 상황을 가정한다. 제어부는 S310 단계에서 표시부를 통해 복수의 서로 다른 안경 이미지를 표시할 수 있다. 사용자는 입력부 또 는 표시부를 통해 복수의 안경 이미지 중 어느 하나를 선택할 수 있다. 사용자가 어느 하나를 선택하면, 제어부는 S320 단계에서 입력부 또는 표시부를 통해 사용자가 선택한 안경(안경 이미지)을 특정할 수 있다. 다음으로, 제어부는 S330 단계에서 카메라부를 통해 안경을 착용한 사용자를 촬영하여 사용자의 원본 착용영상을 생성한다. 그러면, 제어부의 영상생성부는 S340 단계에서 앞서 생성된 사용자의 원본 착용영상을 인공신경망의 생성기에 입력하여 생성기로부터 사용자의 가공미착용영상을 도출한다. 즉, 생성기는 사용자의 원본착용영상이 입력되면, 가중치가 적용되는 복수의 연산을 통해 사용자의 가공미착용영상을 출력한다. 사용자의 가공미착용영상이 얻어지면, 영상생성부는 S350 단계에서 사용자의 가공미착용영상에 앞 서 사용자가 선택한 안경 이미지를 합성하여 합성착용영상을 생성한다. 그런 다음, 영상생성부는 S360 단 계에서 합성착용영상을 표시부를 통해 표시한다. 이에 따라, 사용자는 안경을 벗지 않아도 다른 안경을 착용한 자신의 모습을 표시부를 통해 확인할 수 있 다. 이는 특히, 시력이 좋지 않은 사용자가 자신의 새로운 안경을 고르기 위해 안경을 쓰고 벗는 것을 반복하는 번거로움을 해소할 수 있다. 한편, 본 발명의 실시예에 따른 인공신경망은 영상을 이루는 복수의 RGB 픽셀 각각에 대해 3개의 채널, 즉, R(빨강) 채널, G(초록) 채널, B(파랑) 채널과, 이에 추가로, 해당 픽셀이 안경 영역에 속하는지 여부를 나 타내는 마스크에 대한 채널을 학습시킨다. 따라서 RGB 채널만 이용하는 경우에 비해 안경의 형상 및 안경을 벗 었을 때 안경을 착용했던 영역에 대한 특징을 보다 명확하게 학습시킬 수 있다. 따라서 보다 자연스러운 가공미 착용영상을 생성할 수 있고, 더 나아가 가공미착용영상에 새로운 디자인의 안경을 합성할 때 보다 자연 스러운 합성착용영상을 생성할 수 있다. 한편, 앞서 설명된 본 발명의 실시예에 따른 다양한 방법들은 다양한 컴퓨터수단을 통하여 판독 가능한 프로그 램 형태로 구현되어 컴퓨터로 판독 가능한 기록매체에 기록될 수 있다. 여기서, 기록매체는 프로그램 명령, 데 이터 파일, 데이터구조 등을 단독으로 또는 조합하여 포함할 수 있다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예컨대 기록매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치를 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 와이어뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 와이어를 포함 할 수 있다. 이러한 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하 도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상 본 발명을 몇 가지 바람직한 실시예를 사용하여 설명하였으나, 이들 실시예는 예시적인 것이며 한정적인"}
{"patent_id": "10-2018-0046511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "것이 아니다. 이와 같이, 본 발명이 속하는 기술분야에서 통상의 지식을 지닌 자라면 본 발명의 사상과 첨부된 특허청구범위에 제시된 권리범위에서 벗어나지 않으면서 균등론에 따라 다양한 변화와 수정을 가할 수 있음을 이해할 것이다."}
{"patent_id": "10-2018-0046511", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치의 구성을 설명하기 위한 도면이다. 도 2는 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하기 위한 장치의 인공신경망의 세 부 구성을 설명하기 위한 도면이다. 도 3은 본 발명의 실시예에 따른 인공신경망의 생성기의 출력값을 설명하기 위한 도면이다. 도 4는 본 발명의 실시예에 따른 글로벌판별기 및 로컬판별기에 대한 학습 방법을 설명하기 위한 도면이다. 도 5는 본 발명의 실시예에 따른 글로벌판별기 및 로컬판별기에 대한 학습 방법을 설명하기 위한 흐름도이다. 도 6은 본 발명의 실시예에 따른 생성기에 대한 학습 방법을 설명하기 위한 도면이다. 도 7은 본 발명의 실시예에 따른 생성기에 대한 학습 방법을 설명하기 위한 흐름도이다. 도 8은 본 발명의 실시예에 따른 인공신경망을 이용한 안경 착용 영상을 생성하는 방법을 설명하기 위한 흐름도 이다."}
