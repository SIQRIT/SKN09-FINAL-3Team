{"patent_id": "10-2023-0120832", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0038294", "출원번호": "10-2023-0120832", "발명의 명칭": "영화 장면 메타데이터 구축 시스템 및 방법", "출원인": "주식회사 에이아이오투오", "발명자": "안성민"}}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "선택된 영화에 대한 데이터 소스로부터 정형 및 비정형 데이터를 포함하는 텍스트 데이터를 수집하는 데이터 수집부;상기 선택된 영화의 프레임 별로 장면 전환이 이루어지는 프레임을 판별하는 장면 전환 판별부;선택된 프레임의 장면에 대한 장면 이미지를 인공지능 모델에 입력 가능하게 변환하고, 변환된 해당 장면 이미지를 텍스트로 변환하는 이미지 투 텍스트 변환부;변환된 텍스트와 수집된 텍스트에 대해 지정된 프롬프트를 실행하여 자연어 모델로부터 해당 장면 이미지에 대한 메타데이터를 생성하는 메타데이터 생성부; 및생성된 메타데이터에 대해 수집된 텍스트 데이터의 메타데이터와 비교하여 유사도가 높은 메타데이터를 선택하는 검증부;를 포함하는 영화 장면 메타데이터 구축 시스템."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 장면 전환 판별부는,상기 선택된 영화를 설정된 프레임 별로 분할하는 프레임 분할부;상기 프레임 간 픽셀 오차값(Pixel error value)을 계산하는 픽셀 오차값 계산부; 및상기 픽셀 오차값이 설정값 이상인 프레임을 장면 전환으로 판단하여 선택하는 장면 선택부;를 포함하는 영화 장면 메타데이터 구축 시스템."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 이미지 투 텍스트 변환부는,상기 인공지능 모델에의 입력을 위한 입력 형식과 일치하도록 상기 장면 이미지의 크기를 조정하는 이미지 크기조정부;크기가 조정된 장면 이미지를 미리 설정된 변환 규칙에 따라 정규화하는 정규화부; 및정규화된 장면 이미지를 텍스트로 변환하는 변환부;를 포함하는 영화 장면 메타데이터 구축 시스템."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 메타데이터 생성부는,변환된 텍스트와 수집된 텍스트 데이터를 자연어 모델에 각각 입력하는 입력부;상기 자연어 모델로부터 메타데이터를 각각 추출하는 메타데이터 추출부; 및추출된 메타데이터를 해당 장면 이미지와 텍스트 데이터들과 함께 저장하는 저장부;를 포함하는 영화 장면 메타데이터 구축 시스템.공개특허 10-2025-0038294-3-청구항 5 제4항에 있어서,상기 검증부는,추출된 각 메타데이터를 각각 텍스트 임베딩 모델을 통해 벡터 형태로 변환하는 벡터화부;변환된 벡터에 대해 미리 설정된 유사도 측정 방법을 통해 유사도를 측정하는 유사도 측정부; 및측정된 유사도가 설정값 이상인 메타데이터를 선택하여 저장부에 저장된 메타데이터를 업데이트하는업데이트부;를 포함하는 영화 장면 메타데이터 구축 시스템."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "(a) 데이터 수집부에서, 선택된 영화에 대한 데이터 소스로부터 정형 및 비정형 데이터를 포함하는 텍스트 데이터를 수집하는 단계;(b) 장면 전환 판별부에서, 상기 선택된 영화의 프레임 별로 장면 전환이 이루어지는 프레임을 판별하는 단계;(c) 이미지 투 텍스트 변환부에서, 선택된 프레임의 장면에 대한 장면 이미지를 인공지능 모델에 입력 가능하게변환하고, 변환된 해당 장면 이미지를 텍스트로 변환하는 단계;(d) 메타데이터 생성부에서, 변환된 텍스트와 수집된 텍스트에 대해 지정된 프롬프트를 실행하여 자연어 모델로부터 해당 장면 이미지에 대한 메타데이터를 생성하는 단계; 및(e) 검증부에서, 생성된 메타데이터에 대해 수집된 텍스트 데이터의 메타데이터와 비교하여 유사도가 높은 메타데이터를 선택하는 단계;를 포함하는 영화 장면 메타데이터 구축 방법."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 (b) 단계는,선택된 영화를 설정된 프레임 별로 분할하는 단계;프레임 간 픽셀 오차값(Pixel error value)을 계산하는 단계; 및픽셀 오차값이 설정값 이상인 프레임을 장면 전환으로 판단하여 선택하는 단계;를 포함하는 영화 장면 메타데이터 구축 방법."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 (c) 단계는,상기 인공지능 모델에의 입력을 위한 입력 형식과 일치하도록 상기 장면 이미지의 크기를 조정하는 단계;크기가 조정된 장면 이미지를 미리 설정된 변환 규칙에 따라 정규화하는 단계; 및정규화된 장면 이미지를 텍스트로 변환하는 단계;를 포함하는 영화 장면 메타데이터 구축 방법."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 (d) 단계는,공개특허 10-2025-0038294-4-변환된 텍스트와 수집된 텍스트 데이터를 자연어 모델에 각각 입력하는 단계;상기 자연어 모델로부터 메타데이터를 각각 추출하는 메타데이터 단계; 및추출된 메타데이터를 해당 장면 이미지와 텍스트 데이터들과 함께 저장하는 단계;를 포함하는 영화 장면 메타데이터 구축 방법."}
{"patent_id": "10-2023-0120832", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 (e) 단계는,추출된 각 메타데이터를 각각 텍스트 임베딩 모델을 통해 벡터 형태로 변환하는 단계;변환된 벡터에 대해 미리 설정된 유사도 측정 방법을 통해 유사도를 측정하는 단계; 및측정된 유사도가 설정값 이상인 메타데이터를 선택하여 저장된 메타데이터를 업데이트하는 단계;를 포함하는 영화 장면 메타데이터 구축 방법."}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영화 장면 메타데이터 구축 시스템 및 방법이 개시된다. 본 발명에 의한 영화 장면 메타데이터 구축 시스템 및 방법은, 데이터 수집부에서, 선택된 영화에 대한 데이터 소스로부터 정형 및 비정형 데이터를 포함하는 텍스트 데이터를 수집하고, 장면 전환 판별부에서, 선택된 영화의 프레임 별로 장면 전환이 이루어지는 프레임을 판별하 며, 이미지 투 텍스트 변환부에서, 선택된 프레임의 장면에 대한 장면 이미지를 인공지능 모델에 입력 가능하게 변환하고, 변환된 해당 장면 이미지를 텍스트로 변환하고, 메타데이터 생성부에서, 변환된 텍스트와 수집된 텍스 트에 대해 지정된 프롬프트를 실행하여 자연어 모델로부터 해당 장면 이미지에 대한 메타데이터를 생성하며, 검 증부에서, 생성된 메타데이터에 대해 수집된 텍스트 데이터의 메타데이터와 비교하여 유사도가 높은 메타데이터 를 선택한다. 본 발명에 따르면, 메타데이터를 통해 영화를 더욱 깊이 이해하는데 도움을 줄 수 있다."}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영화 메타데이터 구축 기술에 관한 것이다. 더 구체적으로는 영화의 영상 자체를 텍스트로 변환하고 해당 텍스트 및 영화 관련 정보에 대해 프롬프트 엔지니어링을 통해 메타데이터를 구축하는 영화 장면 메타데이 터 구축 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영화는 대부분의 사람들에게 친숙한 엔터테인먼트 형태이며, 다양한 매체와 형식을 통해 소비된다. 영화는 시각 과 청각을 통한 감각적인 경험을 제공하며, 고유의 내러티브(narrative)와 표현 수단으로 인해 전 세계에서 매 우 널리 관람되고 있다. 그러나 영화의 내용을 정확하게 이해하고 분석하려면 시청자가 복잡한 시각적 정보와 다양한 사운드를 실시간으 로 처리해야 한다. 이는 종종 인간의 인지 능력을 넘어설 수 있으며, 이로 인해 영화의 풍부한 정보를 완전히 활용하는 데 어려움이 발생할 수 있다. 그렇기 때문에 영화를 온전히 이해하고 평가하기 위한 중개자로서의 메타데이터의 중요성이 점점 강조되어지고 있다. 메타데이터는 영화의 주요 특성, 내용, 그리고 사용자의 반응 등을 종합적으로 나타낼 수 있어, 사용자들이 영 화를 선택하거나 이해하는 데 큰 도움이 된다. 따라서 영화의 복잡한 정보를 간단하고 명확하게 표현하기 위해 서는 다양한 유형의 메타데이터를 구축하고 활용하는 것이 중요하다. 예를 들어, 타이타닉 영화는 다음과 같은 메타데이터들로 표현할 수 있다. 제목은 \"타이타닉\", 감독은 \"제임스 카메론\", 개봉 년도는 \"1997년\", 주요 배우로는 \"레오나르도 디카프리오\"와 \"케이트 윈슬렛\"이 있으며, 장르는 \"드라마\"와 \"로맨스\"로 분류된다. 또한, 주요 특성으로는 \"역사적 사건 기반\", \"러브 스토리\", \"배에서의 생존 투쟁\"이 있고, 사용자 평점은 \"4.7/5.0\"으로 기록되었다. 관련 키워드로 는 \"아이스버그\", \"로즈\", \"잭\", \"사랑\", \"생존\", \"비극\" 등이 있다. 이러한 메타데이터는 사용자에게 영화의 주요 정보와 특징을 간략하게 제공하여, 영화 선택 시 참고 자료로 활 용될 수 있다. 또한, 이러한 메타데이터를 활용하여 사용자의 취향과 관련된 영화를 추천하는 시스템 등에도 적 용될 수 있다. 그래서 최근에는 영화 데이터를 처리하고 분석하는 데에 인공지능(AI) 기술이 활용되고 있는 추세이다. 특히, 이미지 인식, 영상 분석, 자연어 처리 등의 분야에서의 발전은 컴퓨터가 사람과 유사하게 영화를 '이해'할 수 있는 기술을 제공하고 있다. 그러나, 아직까지는 제목, 감독, 배우, 주요 특성, 사용자 평점 및 관련 키워드 등으로 이루어진 메타데이터를 생성 및 관리하고 있을 뿐, 영화의 영상 자체(장면)에 대한 메타데이터는 생성 및 관리하는 기술은 알려져 있지 않다. 또한, 메타데이터를 추출하기 위해 아직까지도 대부분 사람의 수작업을 통해 메타데이터가 생성되고 있어, 메타 데이터 생성의 효율성이 저하되는 한계가 있다. 게다가, 영화는 시각적으로 복잡하므로, 이를 이해하고 분석하 기 위해서는 고도의 인지 능력과 전문 지식이 요구되기도 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 문헌 1. 대한민국특허청 특허등록번호 제10-0828166호, \"동영상의 음성 인식과 자막 인식을 통 한 메타데이터 추출방법, 메타데이터를 이용한 동영상 탐색 방법 및 이를 기록한 기록매체\" (특허문헌 0002) 문헌 2. 대한민국특허청 특허공개번호 제10-2009-0061844호, \"온톨로지 기반 시맨틱 메타데이 터 추출 시스템 및 그 방법\" (특허문헌 0003) 문헌 3. 대한민국특허청 특허등록번호 제10-2148392호, \"동영상 메타데이터 태깅 시스템 및 그 방법\""}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 상기한 종래 기술의 문제점을 해결하기 위해 이루어진 것으로서, 본 발명의 목적은 영화의 영상 자체에 관한 정보를 텍스트로 변환한 텍스트 데이터와 추가로 수집된 텍스트 데이터를 포함하는 텍스트를 프롬프트 엔지니어링을 통해 메타데이터를 구축할 수 있도록 하는 영화 장면 메타데이터 구축 시스템 및 방법을 제공하는데 있다."}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명의 영화 장면 메타데이터 구축 시스템은, 바람직하게는 선택된 영화 에 대한 데이터 소스로부터 정형 및 비정형 데이터를 포함하는 텍스트 데이터를 수집하는 데이터 수집부; 상기 선택된 영화의 프레임 별로 장면 전환이 이루어지는 프레임을 판별하는 장면 전환 판별부; 선택된 프레임의 장 면에 대한 장면 이미지를 인공지능 모델에 입력 가능하게 변환하고, 변환된 해당 장면 이미지를 텍스트로 변환 하는 이미지 투 텍스트 변환부; 변환된 텍스트와 수집된 텍스트에 대해 지정된 프롬프트를 실행하여 자연어 모 델로부터 해당 장면 이미지에 대한 메타데이터를 생성하는 메타데이터 생성부; 및 생성된 메타데이터에 대해 수 집된 텍스트 데이터의 메타데이터와 비교하여 유사도가 높은 메타데이터를 선택하는 검증부;를 포함할 수 있다. 이 때, 상기 장면 전환 판별부는, 상기 선택된 영화를 설정된 프레임 별로 분할하는 프레임 분할부; 상기 프레 임 간 픽셀 오차값(Pixel error value)을 계산하는 픽셀 오차값 계산부; 및 상기 픽셀 오차값이 설정값 이상인 프레임을 장면 전환으로 판단하여 선택하는 장면 선택부;를 포함할 수 있다. 또한, 상기 이미지 투 텍스트 변환부는, 상기 인공지능 모델에의 입력을 위한 입력 형식과 일치하도록 상기 장 면 이미지의 크기를 조정하는 이미지 크기 조정부; 크기가 조정된 장면 이미지를 미리 설정된 변환 규칙에 따라 정규화하는 정규화부; 및 정규화된 장면 이미지를 텍스트로 변환하는 변환부;를 포함할 수 있다. 또한, 상기 메타데이터 생성부는, 변환된 텍스트와 수집된 텍스트 데이터를 자연어 모델에 각각 입력하는 입력 부; 상기 자연어 모델로부터 메타데이터를 각각 추출하는 메타데이터 추출부; 및 추출된 메타데이터를 해당 장 면 이미지와 텍스트 데이터들과 함께 저장하는 저장부;를 포함할 수 있다. 그리고, 상기 검증부는, 추출된 각 메타데이터를 각각 텍스트 임베딩 모델을 통해 벡터 형태로 변환하는 벡터화 부; 변환된 벡터에 대해 미리 설정된 유사도 측정 방법을 통해 유사도를 측정하는 유사도 측정부; 및 측정된 유 사도가 설정값 이상인 메타데이터를 선택하여 저장부에 저장된 메타데이터를 업데이트하는 업데이트부;를 포함 할 수 있다. 한편, 본 발명의 영화 장면 메타데이터 구축 방법은, 바람직하게는 (a) 데이터 수집부에서, 선택된 영화에 대한 데이터 소스로부터 정형 및 비정형 데이터를 포함하는 텍스트 데이터를 수집하는 단계; (b) 장면 전환 판별부에 서, 상기 선택된 영화의 프레임 별로 장면 전환이 이루어지는 프레임을 판별하는 단계; (c) 이미지 투 텍스트 변환부에서, 선택된 프레임의 장면에 대한 장면 이미지를 인공지능 모델에 입력 가능하게 변환하고, 변환된 해 당 장면 이미지를 텍스트로 변환하는 단계; (d) 메타데이터 생성부에서, 변환된 텍스트와 수집된 텍스트에 대해 지정된 프롬프트를 실행하여 자연어 모델로부터 해당 장면 이미지에 대한 메타데이터를 생성하는 단계; 및 (e) 검증부에서, 생성된 메타데이터에 대해 수집된 텍스트 데이터의 메타데이터와 비교하여 유사도가 높은 메타데이 터를 선택하는 단계;를 포함할 수 있다. 이 때, 상기 (b) 단계는, 선택된 영화를 설정된 프레임 별로 분할하는 단계; 프레임 간 픽셀 오차값(Pixel error value)을 계산하는 단계; 및 픽셀 오차값이 설정값 이상인 프레임을 장면 전환으로 판단하여 선택하는 단 계;를 포함할 수 있다. 또한, 상기 (c) 단계는, 상기 인공지능 모델에의 입력을 위한 입력 형식과 일치하도록 상기 장면 이미지의 크기 를 조정하는 단계; 크기가 조정된 장면 이미지를 미리 설정된 변환 규칙에 따라 정규화하는 단계; 및 정규화된 장면 이미지를 텍스트로 변환하는 단계;를 포함할 수 있다. 또한, 상기 (d) 단계는, 변환된 텍스트와 수집된 텍스트 데이터를 자연어 모델에 각각 입력하는 단계; 상기 자 연어 모델로부터 메타데이터를 각각 추출하는 메타데이터 단계; 및 추출된 메타데이터를 해당 장면 이미지와 텍 스트 데이터들과 함께 저장하는 단계;를 포함할 수 있다. 그리고, 상기 (e) 단계는, 추출된 각 메타데이터를 각각 텍스트 임베딩 모델을 통해 벡터 형태로 변환하는 단계; 변환된 벡터에 대해 미리 설정된 유사도 측정 방법을 통해 유사도를 측정하는 단계; 및 측정된 유사도가 설정값 이상인 메타데이터를 선택하여 저장된 메타데이터를 업데이트하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이, 본 발명에 의한 영화 장면 메타데이터 구축 시스템 및 방법에 따르면, 영화의 영상 자체의 텍스트화 및 프롬프트 엔지니어링을 통해 메타데이터를 추출하므로 영화의 전체 또는 필요 부분에 대한 정보를 추출할 수 있다. 즉, 영화의 시각적 정보를 빠르고 효과적으로 분석할 수 있으며, 더욱 다양한 메타데이터를 추 출할 수 있다. 궁극적으로, 메타데이터를 통해 영화를 더욱 깊이 이해하는데 도움을 줄 수 있다. 한편, 영화 추천, 영화 내용 분석, 자동화된 콘텐츠 생성 등 다양한 분야에서 효율적인 데이터 분석과 처리를 실현할 수 있다."}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명의 바람직한 실시예 및 첨부하는 도면을 참조하여 본 발명을 상세히 설명하되, 도면의 동일 한 참조부호는 동일한 구성요소를 지칭함을 전제하여 설명하기로 한다.발명의 상세한 설명 또는 특허청구범위에서 어느 하나의 구성요소가 다른 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 당해 구성요소만으로 이루어지는 것으로 한정되어 해석되지 아니하며, 다른 구 성요소들을 더 포함할 수 있는 것으로 이해되어야 한다. 또한, 발명의 상세한 설명 또는 특허청구범위에서 \"~수단\", \"~부\", \"~모듈\", \"~블록\"으로 명명된 구성요소들은 적어도 하나 이상의 기능이나 동작을 처리하는 단위를 의미하며, 이들 각각은 소프트웨어 또는 하드웨어, 또는 이들의 결합에 의하여 구현될 수 있다. 본 발명에서는 이미지를 텍스트로 변환하는 기술을 활용하여 영상 데이터를 텍스트 데이터로 전환하고, 영화와 관련된 텍스트 데이터를 추가로 수집한 다음, 이들 텍스트 데이터에 대해 프롬프트 엔지니어링을 통해 메타데이 터를 추출하는 기술을 제시하고자 한다. 해당 기술은 머신 러닝, 인공지능, 자연어 처리, 컴퓨터 비전 등의 분 야에 연관될 수 있다. 이에 본 발명에서 제시하는 주요 기술 중 하나는, 이미지를 텍스트로 변환하는 모델이다. 이 모델 중 하나로서, CLIP(Contrastive Language-Image Pre-training model)과 같은 이미지 투 텍스트 변환 모델이 존재하며, 이는 대형 데이터 셋에서 사전 학습되어 특정 이미지를 설명하는 텍스트를 생성하는 능력을 가지고 있다. 구체적으로, 영화 장면에서의 중요한 시각적 요소, 예를 들면 배경, 주인공의 행동, 감정 표현 등의 이미지 데 이터를 사람이 이해할 수 있는 언어로, \"젊은 여성이 해변에서 파도를 바라보며 웃고 있다.\"와 같이 변환한다. 이러한 텍스트화된 설명은 영화와 관련된 기존의 텍스트 데이터와 결합될 수 있으며, 이를 프롬프트 엔지니어링 을 통해 해당 텍스트를 설명하는 여러 메타데이터로 구성하는 기술의 주요한 구성 요소가 된다. 이로 인해 시각 적 데이터의 복잡성을 크게 줄일 수 있으며, 사용자들에게 보다 정확하고 압축된 정보를 제공하는데 도움이 될 수 있다. 여기서, 본 발명에 개시된 \"모델\"은 실제 프로세스를 수학적 또는 계산적으로 표현하는 시스템을 의미하며, 해 당 시스템이 입력 데이터로부터 패턴과 관계를 학습하여 예측, 결정을 내리는 작업을 수행하는 것을 포함한다. 또한, 주요 기술 중 다른 하나는, 프롬프트 엔지니어링(Prompt Engineering)이다. 프롬프트 엔지니어링은 자연 어 처리 모델을 활용하여, 모델이 원하는 출력을 생성하도록 유도하는 기법이다. 이 기법은 입력 문장, 즉 '프 롬프트'의 신중한 설계를 통해 진행된다. 예를 들면, 이미지를 텍스트로 변환한 결과 \"젊은 여성이 해변에서 파 도를 바라보며 웃고 있다.\"라는 설명이 나왔을 때, 프롬프트 엔지니어링을 활용하여 해당 텍스트를 \"젊은 여 성\", \"해변\", \"파도\"이라는 메타데이터를 추출할 수 있다. 이러한 기술들은 자체적으로도 강력하지만, 이들을 통합하여 시스템을 구축하면 영화의 시각적 내용과 이에 대 한 설명을 효과적으로 연결할 수 있게 된다. 이를 통해, 영화의 각 부분에 대한 깊이 있는 데이터를 생성할 수 있으며, 이는 영화 분석, 추천 시스템, 자동화된 콘텐츠 생성 등 다양한 응용 분야에 활용될 수 있다. 이에 본 발명에서는 영화 데이터를 이미지 투 텍스트 모델을 활용하여 텍스트 형태로 변환하고, 이후 프롬프트 엔지니어링을 통해 영화의 특정 부분을 설명하는 메타데이터를 생성하는 새로운 시스템과 방법을 제안하고자 한 다. 이러한 시스템을 효과적으로 구축하고 활용하려면 여러 도전 과제를 극복해야 한다. 특히, 영화 데이터의 다양 성과 복잡성, 시각적 내용과 텍스트 사이의 연결을 자동으로 구축하는 데 필요한 알고리즘, 그리고 프롬프트 엔 지니어링의 복잡성 등이 이에 해당한다. 또한, 영화 데이터의 효과적인 이해와 분석을 가능하게 함으로써, 영화 추천, 영화 내용 분석, 자동화된 콘텐츠 생성 등 다양한 응용 분야에서 이를 활용할 수 있는 기반을 제공하고자 한다. 이하에서는 본 발명의 영화 장면 메타데이터 구축 시스템 및 방법이 구현된 일 예를 특정한 실시예를 통해 설명 하기로 한다. 도 1은 본 발명의 일 실시예에 의한 영화 장면 메타데이터 구축 시스템의 구성도이다. 도 1을 참조하면, 본 발명의 영화 장면 메타데이터 구축 시스템은, 선택된 영화에 대한 데이터 소스로부터 정형 및 비정형 데이터를 포함하는 텍스트 데이터를 수집하는 데이터 수집부와, 선택된 영화의 프레임 별로 장면 전환이 이루어지는 프레임을 판별하는 장면 전환 판별부와, 선택된 프레임의 장면에 대한 장면 이미지를 인 공지능 모델에 입력 가능하게 변환하고, 변환된 해당 장면 이미지를 텍스트로 변환하는 이미지 투 텍스트 변환 부와, 변환된 텍스트와 수집된 텍스트에 대해 지정된 프롬프트를 실행하여 자연어 모델로부터 해당 장면 이 미지에 대한 메타데이터를 생성하는 메타데이터 생성부와, 생성된 메타데이터에 대해 수집된 텍스트 데이터의 메타데이터와 비교하여 유사도가 높은 메타데이터를 선택하는 검증부를 포함한다. 여기서, 본 실시예에서는 메타데이터 생성부에서 변환된 텍스트와 수집된 텍스트로부터 메타데이터를 각각 추출하는 경우를 설명하고 있으나, 데이터 수집부에서 수집된 텍스트 데이터에 대해 지정된 프롬프트를 실행 하여 인공지능 모델로부터 메타데이터를 미리 생성할 수도 있다. 도 2는 본 발명의 일 실시예에 의한 장면 전환 판별부의 구성도이다. 도 2를 참조하면, 본 발명의 장면 전환 판별부는, 선택된 영화를 설정된 프레임 별로 분할하는 프레임 분할 부와, 프레임 간 픽셀 오차값(Pixel error value)을 계산하는 픽셀 오차값 계산부와, 픽셀 오차값이 설 정값 이상인 프레임을 장면 전환으로 판단하여 선택하는 장면 선택부를 포함한다. 도 3은 본 발명의 일 실시예에 의한 이미지 투 텍스트 변환부의 구성도이다. 도 3을 참조하면, 본 발명의 이미지 투 텍스트 변환부는, 인공지능 모델에의 입력을 위한 입력 형식과 일치 하도록 장면 이미지의 크기를 조정하는 이미지 크기 조정부와, 크기가 조정된 장면 이미지를 미리 설정된 변환 규칙에 따라 정규화하는 정규화부와, 정규화된 장면 이미지를 텍스트로 변환하는 변환부를 포함한 다. 여기서, 선택된 장면에 대한 장면 이미지 크기 조정 및 정규화에 대해 설명하고 있으나, 장면 이미지에 대해 잡 음 제거, 색상 보정, 명암 대비 개선 등의 전처리가 이루어질 수 있다. 이러한 전처리 과정을 통해 장면 이미지 의 데이터 품질을 향상시킬 수 있으며, 이에 이미지 투 텍스트 변환 알고리즘이 더욱 정확한 결과를 내놓을 수 있다. 한편, 이미지 투 텍스트 변환부로는 CLIP(Contrastive Language-Image Pretraining) 모델을 이용할 수 있다. CLIP 모델은 딥러닝 모델로서, 이미지를 기반으로 텍스트를 이해하고 생성할 수 있으며, 또한 텍스트를 기반으로 이미지를 이해하고 생성할 수도 있다. 그리고, 변환된 텍스트 데이터는 자연어 처리 알고리즘을 통해 필터링될 수 있다. 도 4는 본 발명의 일 실시예에 의한 메타데이터 생성부의 구성도이다. 도 4를 참조하면, 본 발명의 메타데이터 생성부는, 변환된 텍스트와 수집된 텍스트 데이터를 자연어 모델에 각각 입력하는 입력부와, 자연어 모델로부터 메타데이터를 각각 추출하는 메타데이터 추출부와, 추출된 메타데이터를 해당 장면 이미지와 텍스트 데이터들(변환된 텍스트와 수집된 텍스트 데이터)과 함께 저장하는 저 장부를 포함한다. 도 5는 본 발명의 일 실시예에 의한 검증부의 구성도이다. 도 5를 참조하면, 본 발명의 검증부는, 추출된 각 메타데이터를 각각 텍스트 임베딩 모델을 통해 벡터 형태 로 변환하는 벡터화부와, 변환된 벡터에 대해 미리 설정된 유사도 측정 방법을 통해 유사도를 측정하는 유 사도 측정부와, 측정된 유사도가 설정값 이상인 메타데이터를 선택하여 저장부에 저장된 메타데이터를 업데이트하는 업데이트부를 포함한다. 이 때, 메타데이터의 내용 중에서 동일한 메타데이터에 대해서는 가중치를 부여하는 가중치 부여부를 더 포함할 수 있다. 이에, 동일한 내용에 대해 가중치를 부여한 상태에서 벡터화가 이루어지는 것이 바람직하다. 한편, 벡터화되는 메타데이터로는 해당 영화의 줄거리를 포함하는 비정형 데이터를 기반하는 것이 바람직하다. 그러면, 여기서 상기와 같이 구성된 시스템을 이용한 본 발명의 영화 장면 메타데이터 구축 방법에 대해 설명하 기로 한다. 도 6은 본 발명의 일 실시예에 의한 영화 장면 메타데이터 구축 방법의 흐름도이다. 여기서, 본 발명의 일 실시예에 의한 영화 장면 메타데이터 구축 방법은 상기한 시스템의 각 구성에 의해 동작 이 연계되며, 시스템의 각 구성은 프로세서 및 메모리 간의 구동에 의해 실현될 수 있다. 도 6을 참조하면, 본 발명의 영화 장면 메타데이터 구축 방법은, 선택된 영화에 대한 데이터 소스로부터 정형 및 비정형 데이터를 포함하는 텍스트 데이터를 수집하는 단계와(S1), 선택된 영화의 프레임 별로 장면 전환이 이루어지는 프레임을 판별하는 단계와(S2), 선택된 프레임의 장면에 대한 장면 이미지를 인공지능 모델에 입력 가능하게 변환하고, 변환된 해당 장면 이미지를 텍스트로 변환하는 단계와(S3), 변환된 텍스트와 수집된 텍스트에 대해 지정된 프롬프트를 실행하여 자연어 모델로부터 해당 장면 이미지에 대한 메타데이터를 생성하는 단계 와(S4), 생성된 메타데이터에 대해 수집된 텍스트 데이터의 메타데이터와 비교하여 유사도가 높은 메타데이터를 선택하는 단계를 포함한다(S5). 여기서, 본 실시예에서는 변환된 텍스트와 수집된 텍스트로부터 메타데이터를 각각 추출하는 경우를 설명하고 있으나, 수집된 텍스트 데이터에 대해 지정된 프롬프트를 실행하여 인공지능 모델로부터 메타데이터를 미리 생 성할 수도 있다. 도 7은 본 발명의 일 실시예에 의한 장면 전환 판별 과정을 나타낸 흐름도이다. 도 7을 참조하면, 본 발명의 장면 전환 판별 과정은, 선택된 영화를 설정된 프레임 별로 분할하는 단계와(S21), 프레임 간 픽셀 오차값(Pixel error value)을 계산하는 단계와(S22), 픽셀 오차값이 설정값 이상인 프레임을 장 면 전환으로 판단하여 선택하는 단계를 포함한다(S23). 도 8은 본 발명의 일 실시예에 의한 이미지 투 텍스트 변환 과정을 나타낸 흐름도이다. 도 8을 참조하면, 본 발명의 이미지 투 텍스트 변환 과정은, 인공지능 모델에의 입력을 위한 입력 형식과 일치 하도록 장면 이미지의 크기를 조정하는 단계와(S31), 크기가 조정된 장면 이미지를 미리 설정된 변환 규칙에 따 라 정규화하는 단계와(S32), 정규화된 장면 이미지를 텍스트로 변환하는 단계를 포함한다(S33). 여기서, 선택된 장면에 대한 장면 이미지 크기 조정 및 정규화에 대해 설명하고 있으나, 장면 이미지에 대해 잡 음 제거, 색상 보정, 명암 대비 개선 등의 전처리가 이루어질 수 있다. 이러한 전처리 과정을 통해 장면 이미지 의 데이터 품질을 향상시킬 수 있으며, 이에 이미지 투 텍스트 변환 알고리즘이 더욱 정확한 결과를 내놓을 수 있다. 한편, 이미지 투 텍스트 변환부로는 CLIP(Contrastive Language-Image Pretraining) 모델을 이용할 수 있다. CLIP 모델은 딥러닝 모델로서, 이미지를 기반으로 텍스트를 이해하고 생성할 수 있으며, 또한 텍스트를 기반으로 이미지를 이해하고 생성할 수도 있다. 그리고, 변환된 텍스트 데이터는 자연어 처리 알고리즘을 통해 필터링될 수 있다. 도 9는 본 발명의 일 실시예에 의한 메타데이터 생성 과정을 나타낸 흐름도이다. 도 9를 참조하면, 본 발명의 메타데이터 생성 과정은, 변환된 텍스트와 수집된 텍스트 데이터를 자연어 모델에 각각 입력하는 단계와(S41), 자연어 모델로부터 메타데이터를 각각 추출하는 메타데이터 단계와(S42), 추출된 메타데이터를 해당 장면 이미지와 텍스트 데이터들(변환된 텍스트와 수집된 텍스트 데이터)과 함께 저장하는 단 계를 포함한다(S43). 도 10은 본 발명의 일 실시예에 의한 검증 과정을 나타낸 흐름도이다. 도 10을 참조하면, 본 발명의 검증 과정은, 추출된 각 메타데이터를 각각 텍스트 임베딩 모델을 통해 벡터 형태 로 변환하는 단계와(S51), 변환된 벡터에 대해 미리 설정된 유사도 측정 방법을 통해 유사도를 측정하는 단계와 (S52), 측정된 유사도가 설정값 이상인 메타데이터를 선택하여 저장된 메타데이터를 업데이트하는 단계를 포함 한다(S53). 이 때, 메타데이터의 내용 중에서 동일한 메타데이터에 대해서는 가중치를 부여하는 가중치 부여부를 더 포함할 수 있다. 이에, 동일한 내용에 대해 가중치를 부여한 상태에서 벡터화가 이루어지는 것이 바람직하다. 한편, 벡터화되는 메타데이터로는 해당 영화의 줄거리를 포함하는 비정형 데이터를 기반하는 것이 바람직하다. [실시예] 영화의 데이터 수집 본 발명에서는 영화의 이미지 데이터와 함께 관련된 텍스트 데이터를 확보하기 위한 첫 단계로 영화 데이터 소 스의 선택이 이루어진다. 이 선택 과정은 여러 고려 사항들을 바탕으로 진행된다. 주로 공개적으로 접근 가능하고 법적 제약이 없는 영화 데이터베이스에서 데이터를 확보하며, 이는 다양한 온라 인 플랫폼, 공개적으로 이용 가능한 데이터 세트, 또는 공개 API를 통해 접근할 수 있는 영화 정보 등이 될 수 있다. 이와 같은 데이터 소스는 다양한 장르, 감독, 연도, 국가 등으로 구성된 폭넓은 영화 데이터를 포함한다. 선택된 데이터 소스는 그 후 데이터 수집 및 저장 과정에 활용되며, 후에 있을 프롬프트 엔지니어링을 통한 메 타 추출 과정에서 활용될 기반 데이터이다. 따라서 영화 데이터 소스의 선택은 본 발명의 핵심 구성 요소 중 하 나로서, 효과적인 이미지 투 텍스트 모델 및 프롬프트 엔지니어링을 통한 메타데이터 구축에 있어서 기초를 제 공한다. 장면 전환 판별 본 발명에서는 영화의 영상에서 메타데이터를 수집하기 위해 영화의 중요한 장면을 포착 해당 부분을 이미지 투 텍스트 모델을 활용하고자 한다. 이에 영상을 이루는 전체 이미지 프레임 중 중요한 장면을 찾아내기 위해 프레 임 간의 픽셀 오차값을 계산하는 알고리즘을 통해 중요한 장면을 찾아낸다. 이 알고리즘은 연속적인 프레임 간 에 눈에 띄는 변화가 있는 경우를 감지하기 위해 사용된다. 연속된 프레임 간 픽셀 오차값을 통해 장면들을 찾는 과정을 간략하게 설명하면 다음과 같다. 먼저, 영화 데이터를 프레임 단위로 분할하여 각 프레임의 픽셀 값을 확보한다. 이렇게 확보한 픽셀 값은 컴퓨 터 시스템에서 숫자로 표현된다. 그런 다음 이 픽셀 값들을 통해 연속된 두 프레임 사이의 픽셀 차이를 계산한 다. 이 차이는 RGB 채널의 값이나 흑백 값 등을 기반으로 계산할 수 있다. 각 프레임 간의 픽셀 차이를 계산하는 과정은 영화의 중요한 장면을 파악하는 데 있어 굉장히 중요하다. 픽셀 오차값이 크다는 것은 해당 프레임에서 큰 변화가 일어났음을 의미한다. 이런 변화는 영화 내에서 중요한 장면 의 전환, 즉, 주요 사건의 발생 또는 종료, 캐릭터의 중요한 변화 등을 암시할 수 있다. 따라서 픽셀 오차값을 분석함으로써 영화의 핵심적인 부분을 효율적으로 추출할 수 있게 된다. 예를 들어, 어느 영화에서 주인공이 기존의 평화로운 삶에서 급격한 사건에 휘말려 들어가는 장면이 있다고 가 정하자. 이런 장면 전환은 주인공의 주변 환경, 감정, 행동 등에 큰 변화를 초래하게 된다. 이런 변화는 영상에 서도 뚜렷이 나타날 것이다. 예컨대, 주인공이 평화로운 공원에서 산책을 하고 있던 장면에서 갑자기 폭발 사건 이 발생하여 주인공이 놀라며 주변 환경이 파괴되는 장면으로 전환될 수 있다. 이런 경우, 평화로운 공원의 장 면과 폭발 후의 파괴된 장면 사이에는 확연한 픽셀 차이가 나타날 것이다. 본 발명의 알고리즘은 이런 급격한 장면 전환을 픽셀의 차이를 통해 감지할 수 있다. 평화로운 공원에서의 프레 임과 폭발 후의 프레임은 RGB 채널 값에서 큰 차이를 보이게 될 것이다. 예컨대, 공원의 장면에서는 초록색이 주를 이루는 반면, 폭발 후의 장면에서는 불꽃과 연기 때문에 검정색과 빨간색이 두드러질 수 있다. 이러한 색 상의 변화는 픽셀 차이로 확연하게 나타나게 되며, 이를 통해 중요한 장면 전환을 탐지할 수 있다. 따라서, 본 발명은 이런 픽셀의 차이를 기반으로 영화에서의 핵심적인 장면 전환을 효과적으로 감지할 수 있게 되며, 이를 통해 영화의 중요한 부분을 정확하게 포착하고 메타데이터로 변환하는 데 큰 도움을 받게 된다. 전처리 주요 장면이 선정되면, 이 장면을 표현하는 이미지 데이터는 전처리 과정을 거친다. 이 전처리 과정은 이미지 데이터의 품질을 향상시키고, 이미지 투 텍스트 변환 알고리즘이 더욱 효과적으로 작동하도록 도와준다. 전처리 과정에는 여러 단계가 포함될 수 있다. 예를 들어, 잡음 제거, 색상 보정, 명암 대비 개선, 이미지 크기 조정 등의 단계가 있을 수 있다. 이러한 전처리 과정을 거친 이미지 데이터는 훨씬 더 명확하고 선명한 정보를 제공하므로, 이미지 투 텍스트 변환 알고리즘이 더욱 정확한 결과를 내놓을 수 있다. 이미지 투 텍스트 변환 본 발명의 핵심적인 부분은 이미지 데이터를 텍스트로 변환하는 과정이며, 이 과정을 수행하기 위해 CLIP 같은 이미지 투 텍스트 변환 모델이 사용된다. CLIP 같은 이미지 투 텍스트 변환 모델은 텍스트 데이터와 이미지 데이터를 동시에 인식하고 이해하는 능력을 가지고 있다. 그래서 이를 사용하면, 이미지를 설명하는 텍스트 데이터를 생성할 수 있다. 예를 들어, 한 영화에서 특정 장면에 나타나는 주요한 이미지를 가지고 해당 이미지를 설명하는 텍스트 데이터 를 필요로 할 때, CLIP과 같은 이미지를 텍스트로 변환하는 모델을 사용하여 이미지의 내용을 텍스트로 변환할 수 있다. 이 변환된 텍스트는 \"젊은 여성이 해변에서 파도를 바라보며 웃고 있다.\"와 같은 형태로 표현될 수 있 다. 이렇게 변환된 텍스트 데이터는 영화와 관련된 기존의 텍스트 데이터와 함께 수집되어, 프롬프트 엔지니어 링을 통해 메타데이터로 구성될 수 있다. 본 발명에서는 전처리된 영화 이미지 데이터를 CLIP 같은 이미지 투 텍스트 변환 모델에 입력으로 제공한다. 그 리고 이 모델은 해당 이미지 데이터를 기반으로 해당 장면을 설명하는 텍스트 데이터를 출력한다. 이렇게 생성 된 텍스트 데이터는 영화의 중요한 장면을 설명하는데 사용되며, 이는 영화의 메타데이터 생성에 필수적인 부분 이다. CLIP 같은 이미지 투 텍스트 변환 모델을 통해 생성된 텍스트 데이터는 그림을 기반으로 하기 때문에, 이 데이 터는 영화의 중요한 장면을 설명하는 풍부한 정보를 담고 있다. 이 텍스트 데이터는 자연어 처리 알고리즘을 통 해 더욱 의미있는 정보로 변환될 수 있다. 예를 들어, 자연어 처리 알고리즘은 텍스트 데이터에서 주요 키워드나 구문을 추출하거나, 텍스트의 감정 톤을 분석하는 등의 작업을 수행할 수 있다. 이러한 작업을 통해 얻은 정보는 영화의 메타데이터를 구축하는 데 주요 한 역할을 한다. 이렇게 해석된 텍스트 데이터는 컴퓨터 시스템에 저장되어, 후속 작업에 사용된다. 저장 과정에서는 데이터베이 스 시스템, 파일 시스템 등 다양한 방법을 사용할 수 있다. 따라서, 영화의 이미지 데이터를 텍스트 데이터로 변환하고, 그 결과를 해석하고 저장하는 본 발명의 방법은 영 화의 메타데이터를 구축하는 데 주요한 역할을 한다. 메타데이터 생성 본 발명의 또 다른 핵심적인 부분은 생성된 텍스트 데이터를 의미있는 메타데이터로 바꾸는 과정이며, 이 과정 에서는 자연어 모델이 사용된다. 자연어 모델로는 GPT 3.5-Turbo 등이 사용될 수 있다. 자연어 모델은 텍스트 데이터의 문맥을 이해하고 그에 맞는 응답을 생성하는 능력이 있다. 본 발명에서는 CLIP 같은 이미지 투 텍스트 변환 모델을 통해 얻은 텍스트 데이터를 자연어 모델에 기존에 수집 한 텍스트 데이터와 함께 입력으로 제공한다. 그리고 이 모델은 해당 텍스트 데이터를 기반으로 의미 있는 메타 데이터를 생성한다. 생성된 메타데이터는 영화의 중요한 부분을 자세히 설명하고, 이를 통해 사용자에게 보다 정확한 정보를 제공할 수 있다. 메타데이터 생성 과정에서 주요한 부분은 프롬프트 엔지니어링이다. 프롬프트 엔지니어링은 언어 모델에 특정한 입력을 제공함으로써 원하는 출력을 얻는 기법이다. 본 발명에서는 프롬프트 엔지니어링 기법을 사용하여, 자연어 모델로부터 원하는 형태의 메타데이터를 생성한다. 예를 들어, 영화와 연관된 텍스트 데이터를 주고 \"주어진 텍스트를 기반으로 메타데이터를 추출해 줘\"와 같은 프롬프트를 제공함으로써, 해당 장면의 설명하는 메타데이터를 생성할 수 있다. 검증 이렇게 생성된 메타데이터는 영화의 각 부분들에 대한 장면과 표현들이 반영된 정보로 볼 수 있다. 그러나, 메 타 생성 시에 GPT 3.5-Turbo와 같은 자연어 모델에 입력으로 넣은 데이터는 영화 전체를 고려한 데이터보다는 특정 부분을 중점적으로 고려한 데이터가 많기 때문에, 생성된 메타데이터 전부가 영화를 완벽하게 표현한다는 것은 보장하기 어렵다. 이러한 이유로, 영화와 관련도가 높은 메타데이터를 선정하고 이를 검증할 필요가 있다. 이를 위해 메타데이터 와 원본 영화 줄거리와 같은 영화를 잘 표현하는 비정형 데이터와의 유사성을 측정하고, 유사성이 높은 메타데 이터를 추가적으로 선별하는 작업을 진행한다. 한편, 본 실시예에서는 비정형 데이터와의 비교를 설명하지만, 수집된 정형 데이터와의 유사성 비교도 이루어질 수 있다. 일례로서, 생성된 메타데이터는 원본 영화의 줄거리와 같은 영화를 표현하는 비정형 데이터와의 일치도를 검증 한다. 먼저, 메타데이터와 원본 영화 줄거리는 각각의 텍스트 임베딩 모델을 통해 벡터 형태로 변환된다. 이어서, 임베딩된 메타데이터 벡터와 원본 영화 줄거리 벡터는 코사인 유사도 등의 다양한 유사도 측정 방법을 통해 유사성을 측정한다. 예를 들어, '인터스텔라'라는 영화에 대한 메타데이터 벡터가 [0.5, 0.3, 0.7]이고, 원본 영화 줄거리 벡터가 [0.6, 0.25, 0.75]일 때, 이 두 벡터 사이의 코사인 유사도를 계산하여 높은 유사성을 가지는지 확인할 수 있다. 여기서 중요한 것은, 두 종류의 텍스트 데이터에서 생성된 메타데이터 집단 간의 일치성을 검증하는 것이다. 예 를 들어, '인터스텔라'에 대한 영상 분석을 통해 '우주', '블랙홀', '가족' 등의 메타데이터가 추출되었고, 동시에 기존 텍스트에서 '우주', '시간여행', '블랙홀' 이라는 메타데이터가 추출되었다면, '우주'와 '블랙홀'이 라는 메타데이터는 두 데이터에서 모두 도출되어 높은 신뢰성을 가진다고 판단하고 추가적인 가중치를 부여한다. 이렇게 부여된 가중치는 후속 유사도 측정 과정에서 핵심 요소로 작용한다. 유사도 계산 시, 가중치가 부여된 메타데이터는 해당 영화의 특성을 더욱 강조하여 표현한다. '블랙홀' 특성을 동일하게 강조하는 메타데이터가 두 데이터에서 모두 도출될 경우, '인터스텔라'는 '블랙홀' 특성을 갖는다는 것이 확실하다고 판단되어, 유사도 측정에서 이 특성을 중점적으로 고려하게 된다. 이러한 메타데이터 검증 과정은 본 발명의 정확성과 효율성을 높이는 주요한 단계로, 영화 데이터를 분석하고 이해하는 데 있어 중심 역할을 한다. 결국, 본 발명은 영상에서 추출한 메타데이터와 기존 수집된 텍스트에서 추출한 메타데이터의 속성을 모두 반영하여, 사용자의 요청과 가장 일치하는 영화를 효과적으로 추천하는 방법 을 제시한다. 따라서, 본 발명의 방법은 언어 모델과 프롬프트 엔지니어링, 그리고 메타데이터의 검증을 통해, 영화의 메타데 이터를 효과적으로 생성하고 관리하는 데 도움이 될 수 있다. 이상 몇 가지의 실시예를 통해 본 발명의 기술적 사상을 살펴보았다."}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명의 기재사항으로부터 상기 살펴본 실시예를 다 양하게 변형하거나 변경할 수 있음은 자명하다. 또한, 비록 명시적으로 도시되거나 설명되지 아니하였다 하여도"}
{"patent_id": "10-2023-0120832", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명의 기재사항으로부터 본 발명에 의한 기술적 사상을 포함하는 다양한 형태의 변형을 할 수 있음은 자명하며, 이는 여전히 본 발명의 권리범위에 속한다. 첨 부하는 도면을 참조하여 설명된 상기의 실시예들은 본 발명을 설명하기 위한 목적으로 기술된 것이며 본 발명의 권리범위는 이러한 실시예에 국한되지 아니한다."}
{"patent_id": "10-2023-0120832", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 의한 영화 장면 메타데이터 구축 시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 의한 장면 전환 판별부의 구성도이다. 도 3은 본 발명의 일 실시예에 의한 이미지 투 텍스트 변환부의 구성도이다. 도 4는 본 발명의 일 실시예에 의한 메타데이터 생성부의 구성도이다. 도 5는 본 발명의 일 실시예에 의한 검증부의 구성도이다. 도 6은 본 발명의 일 실시예에 의한 영화 장면 메타데이터 구축 방법의 흐름도이다. 도 7은 본 발명의 일 실시예에 의한 장면 전환 판별 과정을 나타낸 흐름도이다. 도 8은 본 발명의 일 실시예에 의한 이미지 투 텍스트 변환 과정을 나타낸 흐름도이다. 도 9는 본 발명의 일 실시예에 의한 메타데이터 생성 과정을 나타낸 흐름도이다. 도 10은 본 발명의 일 실시예에 의한 검증 과정을 나타낸 흐름도이다."}
