{"patent_id": "10-2022-0110055", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0030695", "출원번호": "10-2022-0110055", "발명의 명칭": "클라이언트 장치로부터 전송된 영상 데이터를 처리하는 장치 및 방법", "출원인": "엔에이치엔클라우드 주식회사", "발명자": "김연규"}}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "네트워크와 연결되는 통신기; 및상기 통신기를 통해 상기 네트워크 상의 클라이언트 장치와 통신하는 적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는,상기 통신기를 통해 상기 클라이언트 장치로부터 제 1 영상 데이터를 수신하고;상기 제 1 영상 데이터에 포함된 하나 또는 그 이상의 오브젝트들을 식별하여 상기 하나 또는 그 이상의 오브젝트들을 각각 나타내는 하나 또는 그 이상의 식별자들의 적어도 일부를 상기 통신기를 통해 상기 클라이언트 장치에 전송하고;상기 통신기를 통해 상기 클라이언트 장치로부터 상기 하나 또는 그 이상의 오브젝트들 중 적어도 하나를 선택하는 커맨드를 수신하고;상기 하나 또는 그 이상의 오브젝트들 중 상기 커맨드에 의해 선택된 오브젝트와 연관된 영상 처리를 수행하여생성된 제 2 영상 데이터를 상기 통신기를 통해 상기 클라이언트 장치에 전송하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제 1 영상 데이터는 복수의 영상 프레임들의 스트림을 포함하고,상기 적어도 하나의 프로세서는 상기 복수의 영상 프레임들에서 상기 하나 또는 그 이상의 식별된 오브젝트들각각을 추적(track)하여 태깅(tagging) 정보를 생성하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 적어도 하나의 프로세서는 상기 태깅 정보에 기반하여, 상기 복수의 영상 프레임들에 대해 상기 선택된 오브젝트와 연관된 상기 영상 처리를 수행하여 상기 제 2 영상 데이터를 생성하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 적어도 하나의 프로세서는 상기 하나 또는 그 이상의 식별자들의 적어도 일부와 함께 상기 태깅 정보를 상기 클라이언트 장치에 전송하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 복수의 영상 프레임들은 순차적인 스트림을 형성하는 제 1 영상 프레임들, 제 2 영상 프레임들, 및 제 3영상 프레임들을 포함하고,상기 하나 또는 그 이상의 오브젝트들 중 제 1 오브젝트는 제 1 영상 프레임들 및 제 3 영상 프레임들에서 식별되고,상기 태깅 정보는 상기 제 1 오브젝트의 상기 제 1 영상 프레임들과 연관된 정보 및 상기 제 1 오브젝트의 상기제 3 영상 프레임들과 연관된 정보를 포함하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0030695-3-제 5 항에 있어서,상기 적어도 하나의 프로세서는 상기 제 1 영상 프레임들과 상기 제 3 영상 프레임들에 대해 상기 선택된 오브젝트와 연관된 영상 처리를 수행하여, 상기 영상 처리된 상기 제 1 영상 프레임들, 상기 제 2 영상 프레임들,그리고 상기 영상 처리된 상기 제 3 영상 프레임들을 상기 제 2 영상 데이터로서 제공하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 하나 또는 그 이상의 식별자들은 상기 하나 또는 그 이상의 오브젝트들을 상기 제 1 영상 데이터 상에서시각적으로 하이라이트하기 위한 메타 데이터를 포함하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서상기 하나 또는 그 이상의 오브젝트들 각각은 얼굴, 텍스트, 및 심볼 중 어느 하나에 대응하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 적어도 하나의 프로세서는 상기 제 1 영상 데이터에서 상기 선택된 오브젝트를 블러링하여 상기 제 2 영상데이터를 생성하는 영상 처리 서버."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "네트워크를 통해 클라이언트 장치와 통신하는 방법에 있어서:상기 네트워크를 통해 상기 클라이언트 장치로부터 제 1 영상 데이터를 수신하는 단계;상기 제 1 영상 데이터에 포함된 하나 또는 그 이상의 오브젝트들을 식별하여 상기 하나 또는 그 이상의 오브젝트들을 각각 나타내는 하나 또는 그 이상의 식별자들을 생성하는 단계;상기 하나 또는 그 이상의 식별자들의 적어도 일부를 상기 네트워크를 통해 상기 클라이언트 장치에 전송하는단계;상기 네트워크를 통해 상기 클라이언트 장치로부터 상기 하나 또는 그 이상의 오브젝트들 중 적어도 하나를 선택하는 커맨드를 수신하는 단계;상기 하나 또는 그 이상의 오브젝트들 중 상기 커맨드에 의해 선택된 오브젝트와 연관된 영상 처리를 수행하여제 2 영상 데이터를 생성하는 단계; 및상기 제 2 영상 데이터를 상기 네트워크를 통해 상기 클라이언트 장치에 전송하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 제 1 영상 데이터는 복수의 영상 프레임들의 스트림을 포함하고,상기 하나 또는 그 이상의 식별자들을 생성하는 단계는 상기 복수의 영상 프레임들에서 상기 하나 또는 그 이상의 식별된 오브젝트들 각각을 추적하여 태깅 정보를 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 클라이언트 장치에 전송하는 단계는 상기 하나 또는 그 이상의 식별자들의 적어도 일부와 함께 상기 태깅정보를 상기 클라이언트 장치에 전송하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2024-0030695-4-제 11 항에 있어서,상기 제 2 영상 데이터를 생성하는 단계는 상기 태깅 정보에 기반하여, 상기 복수의 영상 프레임들에 대해 상기선택된 오브젝트와 연관된 영상 처리를 수행하여 상기 제 2 영상 데이터를 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 하나 또는 그 이상의 식별자들은 상기 하나 또는 그 이상의 오브젝트들을 상기 제 1 영상 데이터 상에서시각적으로 하이라이트하기 위한 메타 데이터를 포함하는 방법."}
{"patent_id": "10-2022-0110055", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 10 항에 있어서,상기 제 2 영상 데이터를 생성하는 단계는 상기 제 1 영상 데이터에서 상기 선택된 오브젝트를 블러링하여 상기제 2 영상 데이터를 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0110055", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "영상 처리 서버는, 네트워크와 연결되는 통신기; 통신기를 통해 네트워크 상의 클라이언트 장치와 통신하는 적어 도 하나의 프로세서를 포함한다. 프로세서는, 통신기를 통해 클라이언트 장치로부터 제 1 영상 데이터를 수신하 고, 제 1 영상 데이터에 포함된 하나 또는 그 이상의 오브젝트들을 식별하여 하나 또는 그 이상의 오브젝트들을 각각 나타내는 하나 또는 그 이상의 식별자들의 적어도 일부를 통신기를 통해 클라이언트 장치에 전송하고, 통신 기를 통해 클라이언트 장치로부터 하나 또는 그 이상의 오브젝트들 중 적어도 하나를 선택하는 커맨드를 수신하 고, 하나 또는 그 이상의 오브젝트들 중 커맨드에 의해 선택된 오브젝트와 연관된 영상 처리를 수행하여 생성된 제 2 영상 데이터를 통신기를 통해 클라이언트 장치에 전송한다."}
{"patent_id": "10-2022-0110055", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 네트워크를 통해 통신하는 장치 및 방법에 관한 것으로, 좀 더 구체적으로는 클라이언트 장치로부터 전송된 영상 데이터를 처리하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0110055", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷의 발달에 따라, 네트워크 통신을 지원하는 다양한 사용자 단말기들이 사용되고 있다. 사용자 단말기들은 다양한 기능들을 지원하며, 특히 비디오 데이터와 같은 영상 데이터를 수신하고, 재생하는 기능들을 포함할 수 있다. 영상 데이터는 다양한 형태들을 통해 정보를 전달하는 컨텐츠를 포함할 수 있다. 컨텐츠는 제작자의 의도에 부 합하지 않거나, 노출되지 않는 것이 적합한 오브젝트들을 포함할 수 있다. 예를 들면, 컨텐츠는 사람의 얼굴, 차량의 번호판, 특정 상표 등과 같은 오브젝트들을 포함할 수 있으며, 그러한 컨텐츠가 그대로 대중에게 배포되 는 경우 예를 들면 저작권 침해, 초상권 침해 등과 같은 문제들이 발생할 수 있다. 위 기재된 내용은 오직 본 발명의 기술적 사상들에 대한 배경 기술의 이해를 돕기 위한 것이며, 따라서 그것은 본 발명의 기술 분야의 당업자에게 알려진 선행 기술에 해당하는 내용으로 이해될 수 없다."}
{"patent_id": "10-2022-0110055", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "위와 같은 문제를 고려하여, 사람들은 영상 데이터를 직접 확인하면서, 등장하는 오브젝트들 각각을 영상 처리 하여 노출되지 않도록 하는 작업들을 수행할 수 있는데, 이는 상당한 시간과 노력을 요할 수 있다. 본 발명의 실시 예들은 상대적으로 적은 소요 자원들로 영상 데이터의 오브젝트들에 대한 영상 처리를 수행할 수 있는 영상 처리 장치 및 그것의 동작 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2022-0110055", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 영상 처리 서버는, 네트워크와 연결되는 통신기; 상기 통신기를 통해 상기 네트워크 상의 클라이언트 장치와 통신하는 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는, 상기 통신기를 통해 상기 클라이언트 장치로부터 제 1 영상 데이터를 수신하고; 상기 제 1 영상 데이터에 포함된 하 나 또는 그 이상의 오브젝트들을 식별하여 상기 하나 또는 그 이상의 오브젝트들을 각각 나타내는 하나 또는 그 이상의 식별자들의 적어도 일부를 상기 통신기를 통해 상기 클라이언트 장치에 전송하고; 상기 통신기를 통해 상기 클라이언트 장치로부터 상기 하나 또는 그 이상의 오브젝트들 중 적어도 하나를 선택하는 커맨드를 수신하 고; 상기 하나 또는 그 이상의 오브젝트들 중 상기 커맨드에 의해 선택된 오브젝트와 연관된 영상 처리를 수행하여 생성된 제 2 영상 데이터를 상기 통신기를 통해 상기 클라이언트 장치에 전송한다. 상기 제 1 영상 데이터는 복수의 영상 프레임들의 스트림을 포함할 수 있고, 상기 적어도 하나의 프로세서는 상 기 복수의 영상 프레임들에서 상기 하나 또는 그 이상의 식별된 오브젝트들 각각을 추적하여 태깅 정보를 생성 할 수 있다. 상기 적어도 하나의 프로세서는 상기 태깅 정보에 기반하여, 상기 복수의 영상 프레임들에 대해 상기 선택된 오 브젝트와 연관된 상기 영상 처리를 수행하여 상기 제 2 영상 데이터를 생성할 수 있다. 상기 적어도 하나의 프로세서는 상기 하나 또는 그 이상의 식별자들의 적어도 일부와 함께 상기 태깅 정보를 상 기 클라이언트 장치에 전송할 수 있다. 상기 복수의 영상 프레임들은 순차적인 스트림을 형성하는 제 1 영상 프레임들, 제 2 영상 프레임들, 및 제 3 영상 프레임들을 포함할 수 있고, 상기 하나 또는 그 이상의 오브젝트들 중 제 1 오브젝트는 제 1 영상 프레임 들 및 제 3 영상 프레임들에서 식별될 수 있고, 상기 태깅 정보는 상기 제 1 오브젝트의 상기 제 1 영상 프레임 들과 연관된 정보 및 상기 제 1 오브젝트의 상기 제 3 영상 프레임들과 연관된 정보를 포함할 수 있다. 상기 적어도 하나의 프로세서는 상기 제 1 영상 프레임들과 상기 제 3 영상 프레임들에 대해 상기 선택된 오브 젝트와 연관된 영상 처리를 수행하여, 상기 영상 처리된 상기 제 1 영상 프레임들, 상기 제 2 영상 프레임들, 그리고 상기 영상 처리된 상기 제 3 영상 프레임들을 상기 제 2 영상 데이터로서 제공할 수 있다. 상기 하나 또는 그 이상의 식별자들은 상기 하나 또는 그 이상의 오브젝트들을 상기 제 1 영상 데이터 상에서 시각적으로 하이라이트하기 위한 메타 데이터를 포함할 수 있다. 상기 하나 또는 그 이상의 오브젝트들 각각은 얼굴, 텍스트, 및 심볼 중 어느 하나에 대응할 수 있다. 상기 적어도 하나의 프로세서는 상기 제 1 영상 데이터에서 상기 선택된 오브젝트를 블러링하여 상기 제 2 영상 데이터를 생성할 수 있다. 본 발명의 다른 일면은 네트워크를 통해 클라이언트 장치와 통신하는 방법에 관한 것이다. 상기 방법은, 상기 네트워크를 통해 상기 클라이언트 장치로부터 제 1 영상 데이터를 수신하는 단계; 상기 제 1 영상 데이터에 포 함된 하나 또는 그 이상의 오브젝트들을 식별하여 상기 하나 또는 그 이상의 오브젝트들을 각각 나타내는 하나 또는 그 이상의 식별자들을 생성하는 단계; 상기 하나 또는 그 이상의 식별자들의 적어도 일부를 상기 네트워크 를 통해 상기 클라이언트 장치에 전송하는 단계; 상기 네트워크를 통해 상기 클라이언트 장치로부터 상기 하나 또는 그 이상의 오브젝트들 중 적어도 하나를 선택하는 커맨드를 수신하는 단계; 상기 하나 또는 그 이상의 오 브젝트들 중 상기 커맨드에 의해 선택된 오브젝트와 연관된 영상 처리를 수행하여 제 2 영상 데이터를 생성하는 단계; 및 상기 제 2 영상 데이터를 상기 네트워크를 통해 상기 클라이언트 장치에 전송하는 단계를 포함한다. 상기 제 1 영상 데이터는 복수의 영상 프레임들의 스트림을 포함할 수 있고, 상기 하나 또는 그 이상의 식별자 들을 생성하는 단계는 상기 복수의 영상 프레임들에서 상기 하나 또는 그 이상의 식별된 오브젝트들 각각을 추 적하여 태깅 정보를 생성하는 단계를 포함할 수 있다. 상기 클라이언트 장치에 전송하는 단계는 상기 하나 또는 그 이상의 식별자들의 적어도 일부와 함께 상기 태깅 정보를 상기 클라이언트 장치에 전송하는 단계를 포함할 수 있다. 상기 제 2 영상 데이터를 생성하는 단계는 상기 태깅 정보에 기반하여, 상기 복수의 영상 프레임들에 대해 상기 선택된 오브젝트와 연관된 영상 처리를 수행하여 상기 제 2 영상 데이터를 생성하는 단계를 포함할 수 있다. 상기 하나 또는 그 이상의 식별자들은 상기 하나 또는 그 이상의 오브젝트들을 상기 제 1 영상 데이터 상에서 시각적으로 하이라이트하기 위한 메타 데이터를 포함할 수 있다. 상기 제 2 영상 데이터를 생성하는 단계는 상기 제 1 영상 데이터에서 상기 선택된 오브젝트를 블러링하여 상기 제 2 영상 데이터를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0110055", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따르면, 상대적으로 적은 소요 자원들로 영상 데이터의 오브젝트들에 대한 영상 처리를 수행할 수 있는 영상 처리 장치 및 그것의 동작 방법이 제공된다. 실시예들에 따른 효과는 이상에서 예시된 내용에 의해 제한되지 않으며, 더욱 다양한 효과들이 본 명세서 내에 포함되어 있다."}
{"patent_id": "10-2022-0110055", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 본문에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 이하의 설명에서 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라 그 중간에 다른 소자를 사이에 두고 전기적으로 연결되어 있는 경우도 포함한다. 본 발명의 일 실시예에 있어서 두 구성들 간의 \"연결\"이라 함은 전기적 연결 및 물리적 연결을 모두 포괄하여 사용하는 것임을 의미할 수 있다. 도 1은 본 발명의 실시 예에 따른 네트워크 시스템을 보여주는 블록도이다. 도 1을 참조하면, 네트워크 시스템은 네트워크, 클라이언트 장치, 및 영상 처리 서버를 포 함할 수 있다.네트워크 시스템은 여기에 설명된 본 발명의 실시 예들에 따른 다양한 방법들을 수행하도록 동작하는 복수 의 장치들, 서버들, 및/또는 소프트웨어 구성들을 포함할 수 있다. 도 1에 도시된 장치들 및/또는 서버들은 다 른 방식들로 구성될 수 있으며, 장치들 및/또는 서버들에 의해 제공되는 동작들 및 서비스들은 여기에 설명된 실시 예들을 위해 결합되거나 분리될 수 있으며, 더 많은 수 혹은 더 적은 수의 장치들 및/또는 서버들에 의해 수행될 수 있다. 하나 또는 그 이상의 장치들 및/또는 서버들은 동일 혹은 상이한 기업체들에 의해 구동 및/또 는 유지될 수 있다. 네트워크는 네트워크, 클라이언트 장치, 및 영상 처리 서버와 같은 네트워크 시스템 내 구성 요소들을 연결한다. 네트워크는 공용 네트워크(public network), 적어도 하나의 사설 네트워크 (private network), 유선 네트워크, 무선 네트워크, 다른 적절한 타입의 네트워크, 및 그것들의 조합들 중 적어 도 하나를 포함할 수 있다. 네트워크 시스템 내 구성 요소들 각각은 유선 통신 기능 및 무선 통신 기능 중 적어도 하나를 포함할 수 있으며, 그에 따라 네트워크를 통해 상호 간 통신할 수 있다. 클라이언트 장치는 네트워크를 통해 영상 처리 서버와 통신할 수 있다. 실시 예들에서, 클라이 언트 장치는 영상 처리 서버와 인터렉션할 수 있는 응용 애플리케이션(예를 들면, 웹 브라우저 혹은 전용 애플리케이션)을 포함하며, 해당 응용 애플리케이션은 사용자 입력들에 응답하여 영상 처리 서버에 액세스하여 영상 처리 서버와 데이터 및/또는 정보를 통신할 수 있다. 실시 예로서, 클라이언트 장치는 컴퓨터, UMPC(Ultra Mobile PC), 워크스테이션, 넷북(net-book), PDA(Personal Digital Assistants), 포터블(portable) 컴퓨터, 웹 타블렛(web tablet), 무선 전화기(wireless phone), 모바일 폰(mobile phone), 스마트폰(smart phone), e-북(e-book), PMP(portable multimedia player), 휴대용 게임기 등과 같은 정보를 유선 및/또는 무선 환경에서 송수신할 수 있는 장치 등을 포함할 수 있다. 영상 처리 서버는 네트워크를 통해 클라이언트 장치와 통신할 수 있다. 영상 처리 서버는 클라이언트 장치로부터 영상 데이터를 수신하고, 수신된 영상 데이터를 처리할 수 있다. 본 발명의 실시 예들에 따르면, 영상 처리 서버는 클라이언트 장치로부터의 영상 데이터에 포함된 오브젝트들을 감지 하고, 감지된 오브젝트들 중 적어도 일부를 블러링하는 등의 영상 처리를 수행하고, 처리된 영상 데이터를 클라 이언트 장치에 제공할 수 있다. 도 2는 도 1의 영상 처리 서버의 실시 예를 보여주는 블록도이다. 도 3은 클라이언트 장치에 디스플레이되는, 영상 데이터 및 그것에 표시된 하이라이트들을 포함하는 영상 데이터를 보여주는 도면이다. 도 1 및 도 2를 참조하면, 영상 처리 서버는 네트워크 통신기, 메모리, 및 영상 처리 장치(23 0)를 포함할 수 있다. 네트워크 통신기는 네트워크를 통해 외부의 장치들과 통신을 수행하도록 구성된다. 메모리는 영상 처리 장치의 워킹 메모리 및/또는 버퍼 메모리로서 동작할 수 있다. 예를 들면, 메모 리는 영상 처리 장치에 연결된 SRAM(Static Random Access Memory), DRAM(Dynamic Random Access Memory), SDRAM(Synchronous Dynamic Random Access Memory) 등과 같은 RAM(Random Access Memory)을 포함할 수 있다. 영상 처리 장치는 네트워크 통신기 및 메모리에 연결된다. 영상 처리 장치는 네트워크 통 신기를 통해 클라이언트 장치와 데이터 및/또는 정보를 통신할 수 있다. 영상 처리 장치는 클라이언트 인터페이스(I/F), 오브젝트 식별기, 및 영상 처리기를 포함 할 수 있다. 클라이언트 인터페이스는 네트워크 통신기를 이용하여 클라이언트 장치와 통신함으로써, 영상 처리 장치와 클라이언트 장치 사이의 인터페이스를 제공할 수 있다. 클라이언트 인터페이스는 클라이언트 장치 혹은 그것에 설치된 응용 애플리케이션으로부터 데이터를 수신하고, 수신된 데이터를 오 브젝트 식별기 및/또는 영상 처리기에 제공할 수 있다. 또한, 클라이언트 인터페이스는 오브젝 트 식별기 및 영상 처리기로부터의 데이터를 클라이언트 장치 혹은 그것에 설치된 응용 애플리 케이션에 제공할 수 있다. 오브젝트 식별기는 클라이언트 인터페이스를 통해 클라이언트 장치와 통신할 수 있으며, 메모리 에 액세스할 수 있다. 오브젝트 식별기는 클라이언트 장치로부터 원(original) 영상 데이터를 수신할 수 있다. 오브젝트 식별기는 수신된 원 영상 데이터에서 하나 또는 그 이상의 후보 오브젝트들을식별하여 후보 오브젝트들에 대한 정보를 포함하는 오브젝트 데이터(OD)를 생성할 수 있다. 실시 예들에서, 오 브젝트 식별기는 후보 오브젝트들을 식별하도록 학습된, 딥 러닝 기반의 신경망 네트워크들을 포함할 수 있다. 오브젝트 식별기는 생성된 오브젝트 데이터(OD)의 적어도 일부를 클라이언트 장치에 제공하여 사용자 로 하여금 후보 오브젝트들을 확인하도록 할 수 있다. 또한, 오브젝트 식별기는 오브젝트 데이터(OD)를 메 모리에 저장할 수 있다. 오브젝트 데이터(OD)는 후보 오브젝트들의 오브젝트 아이디들, 그리고 영상 데이터 상에서 후보 오브젝트들을 시각적으로 하이라이트하기 위한 메타 데이터를 포함할 수 있다. 예를 들면, 메타 데이터는 각 후보 오브젝트의 영상 데이터에서의 영역(혹은 세그먼트)을 나타낼 수 있다. 오브젝트 데이터(OD)를 수신한 클라이언트 장치 는, 도 3에 도시된 바와 같이, 원 영상 데이터(IMG)를 디스플레이하면서 메타 데이터에 기반하여 후보 오 브젝트들에 대한 하이라이트들(HL1, HL2, HL3)을 시각화할 수 있다. 도 3에서, 제 1 하이라이트(HL1)는 특정 심 볼 혹은 텍스트를 하이라이트하며, 제 2 하이라이트(HL2)는 사람의 얼굴을 하이라이트하며, 제 3 하이라이트 (HL3)는 차량의 번호판을 하이라이트할 수 있다. 이와 같이, 후보 오브젝트들은 원 영상 데이터(IMG)가 그대로 대중에게 배포되는 경우 예를 들면 저작권 침해, 초상권 침해 등과 같은 문제들을 야기할 수 있는 오브젝트들일 수 있다. 클라이언트 장치는 사용자로부터 후보 오브젝트들 중 적어도 하나를 선택하는 입력을 수신할 수 있다. 예 를 들면, 도 3의 제 1 내지 제 3 하이라이트들(HL1~HL3) 중 적어도 하나를 선택하는 사용자 입력을 수신할 때, 클라이언트 장치는 선택된 후보 오브젝트의 오브젝트 아이디를 나타내는 커맨드를 영상 처리 서버에 전송할 수 있다. 영상 처리기는 클라이언트 인터페이스를 통해 클라이언트 장치와 통신할 수 있으며, 메모리 에 액세스할 수 있다. 클라이언트 장치로부터 수신된 커맨드에 응답하여, 영상 처리기는 오브젝 트 데이터(OD)를 참조하여 선택된 후보 오브젝트와 연관된 영상 처리를 수행할 수 있다. 예를 들면, 영상 처리 기는 오브젝트 데이터(OD) 및/또는 그것의 메타 데이터를 참조하여 원 영상 데이터 내에서의 선택된 후보 오브젝트의 영역(혹은 세그먼트)를 식별할 수 있다. 실시 예들에서, 영상 처리기는 선택된 후보 오브젝트 를 블러링한 영상 데이터를 생성할 수 있다. 예를 들면, 도 3의 제 1 내지 제 3 하이라이트들(HL1~HL3)의 후보 오브젝트들 모두가 선택될 때, 영상 처리기는 제 1 내지 제 3 하이라이트들(HL1~HL3)의 후보 오브젝트들을 블러링한 영상 데이터를 생성할 수 있다. 영상 처리기는 처리된 영상 데이터를 클라이언트 인터페이스 를 통해 클라이언트 장치에 제공할 수 있다. 이에 따라, 클라이언트 장치는, 예를 들면 영상 데 이터를 직접 확인하면서 후보 오브젝트들 각각을 영상 처리하여 노출되지 않도록 하는 작업들을 수행하는 번거 로움 없이, 영상 처리된 영상 데이터를 획득할 수 있다. 이와 같이, 상대적으로 적은 소요 자원들을 통해 영상 데이터의 오브젝트들에 대한 영상 처리를 수행할 수 있는 영상 처리 장치가 제공된다. 도 4는 도 2의 오브젝트 식별기의 실시 예를 보여주는 블록도이다. 도 5는 도 4의 오브젝트 감지부 및 오브젝트 식별부에 의해 생성된 식별자데이터의 예를 개념적으로 보여주는 도면이다. 도 4를 참조하면, 오브젝트 식별기는 오브젝트 감지부, 오브젝트 식별부, 및 오브젝트 추적부 를 포함할 수 있다. 오브젝트 감지부는 영상 데이터(IMG)로부터 감지되는 오브젝트들을 후보 오브젝트들로서 결정할 수 있다. 오브젝트 감지부는 이 분야에 알려진, 다양한 타입들(예를 들면, 텍스트, 사람, 심볼 등)의 오브젝트들을 감지하기 위한 알고리즘들 중 적어도 하나를 채용할 수 있다. 실시 예들에서, 오브젝트 감지부는 딥러닝 기반의 신경망 네트워크를 이용하여 후보 오브젝트들을 감지할 수 있다. 오브젝트 감지부는 감지된 후보 오브젝트들에 대한 정보를 오브젝트 식별부에 제공할 수 있다. 각 후 보 오브젝트에 대한 정보는 메타 데이터 및 오브젝트 아이디를 포함할 수 있다. 메타 데이터는 영상 데이터 (IMG) 상에서 후보 오브젝트가 위치하는 영역(혹은 세그먼트)을 나타낼 수 있다. 도 5를 참조하면, 오브젝트 감 지부는 영상 데이터(IMG) 내의 제 1 내지 제 3 영역들(P1~P3)에서 후보 오브젝트들을 감지할 때, 제 1 내 지 제 3 영역들(P1~P3)을 메타 데이터로 제공할 수 있다. 또한, 오브젝트 감지부는 감지된 후보 오브젝트 들의 아이디들을 \"10000\", \"10001\", 및 \"10002\"로 결정할 수 있다. 다시 도 4를 참조하면, 오브젝트 식별부는 오브젝트 감지부와 연결된다. 오브젝트 식별부는 텍 스트 인식부, 얼굴 감지부, 얼굴 인증부, 및 심볼 인식부를 포함할 수 있다.텍스트 인식부는 오브젝트 감지부에 의해 감지된 후보 오브젝트들 중 텍스트에 해당하는 오브젝트(이 하, 텍스트 오브젝트)를 식별하도록 구성된다. 텍스트 인식부는 이 분야에 알려진, 텍스트를 식별하기 위 한 다양한 방식들 중 적어도 하나를 채용할 수 있다. 실시 예들에서, 텍스트 인식부는 광학적 문자 인식 (optical character recognition) 알고리즘을 채용함으로써 텍스트 오브젝트를 식별할 수 있다. 얼굴 감지부는 오브젝트 감지부에 의해 감지된 후보 오브젝트들 중 사람의 얼굴에 해당하는 오브젝트 (이하, 얼굴 오브젝트)를 감지하도록 구성된다. 얼굴 감지부는 사람의 얼굴을 식별하고, 식별된 얼굴을 정 렬하도록 구성된다. 얼굴 인증(verification)부는 얼굴 감지부에 의해 감지된 얼굴 오브젝트로부터 특징점들을 추출하도록 구성된다. 얼굴 감지부 및 얼굴 인증부는 이 분야에 알려진 얼굴 감지(face recognition) 알고리즘들 중 적어도 하나를 채용할 수 있다. 심볼 인식부는 오브젝트 감지부에 의해 감지된 후보 오브젝트들 중 캐릭터 및 로고와 같은 심볼에 해 당하는 오브젝트(이하, 심볼 오브젝트)를 감지하도록 구성된다. 실시 예들에서, 심볼 인식부는 후보 오브 젝트들 각각을 데이터베이스(DB)에 포함된 기준 심볼 이미지(RSI)와 비교하고, 기준 심볼 이미지(RSI)와 매치되 는 후보 오브젝트를 심볼 오브젝트로 검출할 수 있다. 데이터베이스(DB)는 영상 처리 서버에 포함되거나, 영상 처리 서버의 외부에 배치되어 네트워크(105, 도 1 참조)를 통해 영상 처리 서버와 통신할 수 있 다. 이와 같이, 오브젝트 식별부는 후보 오브젝트들로부터 텍스트 오브젝트, 얼굴 오브젝트, 및 심볼 오브젝트 를 식별하도록 구성된다. 다시 도 5를 참조하면, 오브젝트 아이디 \"10000\"은 텍스트 인식부에 의해 텍스트 (Text)로 인식되고, 해당 인식 값은 \"NHN\"으로 결정된다. 오브젝트 아이디\"10001\"은 얼굴 감지부에 의해 얼굴(Face)로 인식되고, 해당 인식 값은 얼굴 인증부에 의해 \"Face_1\"으로 정의된다. 예를 들면, 얼굴 인 증부는 인식되는 각 얼굴 오브젝트에 인식 값 \"Face_x\"(x는 1보다 크거나 같은 정수)을 부여할 수 있다. 오브젝트 아이디 \"10002\"는 텍스트 인식부에 의해 텍스트로 인식되고, 해당 인식 값은 \"123가4567\"로 결정 된다. 각 후보 오브젝트의 메타 데이터, 오브젝트 아이디, 오브젝트 타입, 및 인식 값은 해당 후보 오브젝트의 식별자 데이터(IDNTF)를 형성할 수 있다. 각 후보 오브젝트의 식별자 데이터(IDNTF)는 도 2의 오브젝트 데이터(OD)에 포함될 수 있다. 오브젝트 식별기 는 도 2를 참조하여 설명된 바와 같이 오브젝트 데이터(OD)의 적어도 일부, 예를 들면 오브젝트 아이디들 및 그 메타 데이터들을 클라이언트 장치에 전송할 수 있다. 도 6은 비디오 데이터에 포함된 영상 프레임들의 일 예를 개념적으로 보여주는 도면이다. 도 4 및 도 6을 참조하면, 영상 데이터(IMG)는 비디오 데이터(VD)일 수 있다. 비디오 데이터(VD)는 순차적인 비 디오 스트림(stream)을 형성하는 제 1 내지 제 q 영상 프레임들(VF1~VFq)을 포함할 수 있다. 오브젝트 식별부는 제 1 영상 프레임(VF1)으로부터 제 1 후보 오브젝트(OB1)를 식별할 수 있다. 오브젝트 추적부는 식별된 제 1 후보 오브젝트(OB1)를 태그(tag)한 후, 이후 비디오 스트림(즉 VF2~VFq)에서 제 1 후보 오브젝트(OB1)를 추적(track)하여 태깅(tagging) 정보를 생성하도록 구성된다. 오브젝트 추적부는 이 분야에 알려진 오브젝트 추적을 위한 다양한 방식들을 채용할 수 있다. 실시 예들에서, 오브젝트 추적부는 칼만 필터(Kalman filter)와 헝가리안 매칭(hungarian matching) 알고리즘을 채용하여 제 1 후보 오브젝트 (OB1)를 추적할 수 있다. 도 6에서, 제 1 내지 제 p 영상 프레임들(VF1~VFp) 각각에 제 1 후보 오브젝트(OB1)가 존재하는 것으로 개념적으로 도시된다(p는 1보다 크고 q보다 작은 정수). 오브젝트 추적부는 제 1 내지 제 p 영상 프레임들(VF1~VFp)에 걸쳐 존재하는 제 1 후보 오브젝트(OB1)에 대한 태깅 정보를 생성할 수 있다. 도 7은 비디오 데이터로부터 추출된 식별자 데이터의 예를 개념적으로 보여주는 도면이다. 도 4 및 도 7을 참조하면, 도 5의 식별자 데이터(IDNTF)에 더하여, 태깅 정보(TG)가 생성된다. 영상 데이터 (IMG)가 비디오 데이터일 때, 도 2의 오브젝트 데이터(OD)는 식별자 데이터(IDNTF) 및 태깅 정보(TG)를 포함할 수 있다. 태깅 정보(TG)는 각 오브젝트 아이디의 등장 시작 시간과 등장 종료 시간을 나타낼 수 있다. 도 7에서, 오브젝 트 아이디 \"10000\"은 시간 T1부터 T1+a까지 등장하며, 오브젝트 아이디 \"10001\"는 시간 T2부터 T2+b까지 등장하 며, 오브젝트 아이디 \"10002\"는 시간 T3부터 T3+c까지 등장하는 것으로 예시된다. 오브젝트 추적부는 오브젝트 데이터(OD)의 적어도 일부, 예를 들면 오브젝트 아이디들, 해당 메타 데이터 들, 및 해당 태깅 정보(TG)를 클라이언트 장치에 전송할 수 있다.영상 처리기(233, 도 2 참조)는 선택된 후보 오브젝트와 연관된 영상 처리를 수행할 수 있다. 영상 처리기(23 3)는 오브젝트 데이터(OD)의 태깅 정보(TG), 즉 등장 시작 시간 및 등장 종료 시간에 기반하여, 선택된 후보 오 브젝트(예를 들면, 도 6의 OB1)가 존재하는 영상 프레임들(예를 들면 도 6의 VF1~VFp 참조)을 식별할 수 있다. 영상 처리기는 식별된 영상 프레임들에서 선택된 후보 오브젝트에 대한 영상 처리(예를 들면, 블러링 처리)를 수행함으로써 처리된 영상 데이터를 생성할 것이다. 도 8은 비디오 데이터에 포함된 영상 프레임들의 다른 예를 개념적으로 보여주는 도면이다. 도 4 및 도 8을 참조하면, 영상 데이터(IMG)는 비디오 데이터(VD')일 수 있다. 비디오 데이터(VD')는 순차적인 비디오 스트림을 형성하는 제 1 내지 제 k 영상 프레임들(VF1~VFy)을 포함할 수 있다. 오브젝트 식별부는 제 1 영상 프레임(VF1)으로부터 제 2 후보 오브젝트(OB2)를 식별할 수 있다. 오브젝트 추적부는 식별된 제 2 후보 오브젝트(OB2)를 태그한 후, 이후 비디오 스트림에서 제 2 후보 오브젝트(OB 2)를 추적하여 태깅 정보를 생성할 수 있다. 이러한 경우, 오브젝트 추적부는 제 1 내지 제 i 영상 프레임 들(VF1~VFi, i는 1보다 크거나 같고 k 보다 작은 정수)에 걸쳐 존재하는 제 2 후보 오브젝트(OB2)에 대한 태깅 정보를 생성할 수 있다. 이후, 오브젝트 식별부는 제 j+1 영상 프레임(VFj+1, j는 i보다 크고 k보다 작은 정수)으로부터 제 2 후보 오브젝트(OB2)를 동일한 후보 오브젝트로서 다시 식별할 수 있다. 오브젝트 추적부는 제 2 후보 오브젝트 (OB2)를 동일한 오브젝트 아이디로 다시 태그한 후, 이후 비디오 스트림에서 제 2 후보 오브젝트(OB2)를 추적하 여 태깅 정보를 업데이트할 수 있다. 오브젝트 추적부는 각 비디오 프레임에서 제 2 후보 오브젝트(OB2)의 위치가 변하더라도 태그된 제 2 후보 오브젝트(OB2)를 계속적으로 추적할 수 있다. 도 9는 비디오 데이터로부터 추출된 식별자 데이터의 다른 예를 개념적으로 보여주는 도면이다. 도 4 및 도 9를 참조하면, 도 7의 식별자 데이터(IDNTF) 및 태깅 정보(TG)에 더하여, 오브젝트 아이디 \"10001\" 에 대응하는 태깅 정보(TG)가 더 추가되어 있다. 도 9에서, 오브젝트 아이디 \"10001\"은 시간 T2부터 T2+b까지 등장하며, 시간 T4부터 T4+d까지 재등장하는 것으로 예시된다. 예를 들면, 오브젝트 아이디 \"10001\"는 도 8의 제 2 후보 오브젝트(OB2)에 대응할 수 있다. 시간 T2부터 T2+b는 제 1 내지 제 i 영상 프레임들(VF1~VFi)에 대 응할 수 있다. 시간 T4부터 T4+d는 제 j+1 내지 제 y 영상 프레임들(VFj+1~VFy)에 대응할 수 있다. 오브젝트 추적부는 오브젝트 데이터(OD)의 적어도 일부, 예를 들면 오브젝트 아이디들, 해당 메타 데이터 들, 및 해당 태깅 정보(TG)를 클라이언트 장치에 전송할 수 있다. 영상 처리기(233, 도 2 참조)는 선택된 후보 오브젝트와 연관된 영상 처리를 수행할 수 있다. 영상 처리기(23 3)는 선택된 후보 오브젝트(예를 들면, 도 8의 OB2)가 존재하는 영상 프레임들(예를 들면 도 8의 VF1~VFi 및 VFj+1~VFy 참조)을 오브젝트 데이터(OD)의 태깅 정보(TG)에 기반하여 식별할 수 있다. 영상 처리기는 식별 된 영상 프레임들에서 선택된 후보 오브젝트에 대한 영상 처리를 수행함으로써 처리된 영상 데이터를 생성할 것 이다. 이와 같이, 태깅 정보(TG)를 이용함으로써 복수의 영상 프레임들이 선택된 후보 오브젝트와 연관하여 처리될 수 있다. 이에 따라, 클라이언트 장치(110, 도 1 참조)의 사용자는 후보 오브젝트를 선택하는 입력을 제공함으로써, 해당 후보 오브젝트에 대한 영상 처리가 수행된 비디오 데이터를 제공 받을 수 있다. 따라서, 저 작권 침해, 초상권 침해 등과 같은 문제들을 야기할 수 있는 오브젝트들에 대한 영상 처리가 수행된 비디오 데 이터가 상대적으로 적은 자원들을 이용하여 수행될 수 있다. 도 10은 도 4의 오브젝트 감지부의 실시 예를 보여주는 블록도이다. 도 10을 참조하면, 오브젝트 감지부는 인공지능 모델 및 인공지능 프로세서를 포함할 수 있다. 인공지능 모델은 영상 데이터(IMG)를 입력하면 후보 오브젝트들(COBJ) 혹은 후보 오브젝트들(COBJ)의 정보 (예를 들면 영상 데이터(IMG) 내에서의 위치 혹은 세그먼트)를 출력하도록 사전에 학습될 수 있다. 실시 예들에 서, 인공지능 모델은 하나 또는 그 이상의 뉴럴 네트워크들(L1, L2, ... , L_k-1, L_k)을 포함할 수 있으 며, 그것들은 영상 데이터와 그 후보 오브젝트들을 포함하는 학습 데이터를 사전에 학습할 수 있다. 예를 들면, 뉴럴 네트워크들(L1, L2, ... , L_k-1, L_k)은 영상 데이터(IMG)로부터 특징 정보를 나타내는 벡터들을 출력하 기 위한 인코더에 해당하는 뉴럴 네트워크들, 그리고 특징 정보를 나타내는 벡터들을 후보 오브젝트들(COBJ)로 변환하기 위한 디코더에 해당하는 뉴럴 네트워크들을 포함할 수 있다. 인공지능 프로세서는 인공지능 모델을 제어하도록 구성된다. 인공지능 프로세서는 데이터 학습 부 및 데이터 처리부를 포함할 수 있다. 데이터 학습부는 영상 데이터와 그 후보 오브젝트들을 포함하는 학습 데이터를 이용하여, 영상 데이터가 인공지능 모델에 입력되면 해당 후보 오브젝트들 혹은 해당 후보 오브젝트들의 정보가 출력되도록 인공지능 모델을 학습시킬 수 있다. 데이터 처리부는 학 습된 인공지능 모델에 영상 데이터(IMG)를 입력함으로써 후보 오브젝트들(COBJ) 혹은 후보 오브젝트들 (COBJ)의 정보를 획득할 수 있다. 실시 예들에서, 인공지능 모델 및 인공지능 프로세서는 프로세서 및 메모리로 구현될 수 있다. 프로 세서는 싱글 코어, 듀얼 코어, 쿼드 코어 등과 같이 하나 또는 그 이상의 코어들을 포함할 수 있다. 프로세서는 프로그램 및/또는 명령어들을 메모리에 로드하고, 로드된 프로그램 및/또는 명령어들을 실행함으로써 인공지능 모델 및 인공지능 프로세서 각각을 제공할 수 있다. 도 11은 본 발명의 실시 예에 따른 클라이언트 장치로부터 전송된 영상 데이터를 처리하는 방법을 보여주는 순 서도이다. 도 1 및 도 11을 참조하면, S110단계에서, 영상 처리 서버는 클라이언트 장치로부터 원(original) 영 상 데이터를 수신한다. S120단계에서, 영상 처리 서버는 원 영상 데이터에서 오브젝트가 감지되는지 여부 에 따라 S130단계를 수행한다. 원 영상 데이터에서 오브젝트가 감지되지 않을 때, S180단계가 수행된다. 실시 예들에서, 후보 오브젝트들은 이 분야에 알려진, 다양한 타입들(예를 들면, 텍스트, 사람, 심볼 등)의 오브젝트 들의 감지하기 위한 알고리즘들 중 적어도 하나를 이용함으로써 감지될 수 있다. 실시 예들에서, 후보 오브젝트 들은 딥러닝 기반의 신경망 네트워크를 이용하여 감지될 수 있다. S130단계에서, 영상 처리 서버는 감지된 후보 오브젝트들을 식별하여 식별자 데이터를 생성한다. 후보 오 브젝트들 중 일부는 텍스트 오브젝트로 인식되고, 이때 해당 인식 값이 결정될 수 있다. 후보 오브젝트들 중 다 른 일부는 얼굴 오브젝트로 인식되고, 이때 해당 인식 값이 결정될 수 있다. 후보 오브젝트들 중 또 다른 일부 는 캐릭터, 로고 등과 같은 심볼 오브젝트로 인식되고, 이때 해당 인식 값이 결정될 수 있다. 이와 같은 오브젝 트의 타입과 인식 값, 그리고 원 영상 데이터 상에서 후보 오브젝트가 위치하는 영역(혹은 세그먼트)을 나타내 는 메타 데이터는 해당 오브젝트 아이디와 함께 해당 후보 오브젝트의 식별자 데이터를 형성할 수 있다. S140단계에서, 영상 처리 서버는 식별자 데이터의 적어도 일부를 클라이언트 장치에 전송한다. 예를 들면, 영상 처리 서버는 각 후보 오브젝트의 오브젝트 아이디와 메타 데이터를 클라이언트 장치에 전 송할 수 있다. S150단계에서, 영상 처리 서버는 클라이언트 장치로부터 후보 오브젝트들 중 적어도 하나를 선택하는 커맨드를 수신할 수 있다. 예를 들면, 클라이언트 장치는 원 영상 데이터를 디스플레이하면서 메타 데이터 에 기반하여 후보 오브젝트들에 대한 하이라이트들(HL1~HL3, 도 3 참조)을 디스플레이할 수 있다. 후보 오브젝 트들 중 적어도 하나를 선택하는 사용자 입력을 수신할 때, 클라이언트 장치는 선택된 후보 오브젝트에 대 응하는 오브젝트 아이디를 나타내는 커맨드를 영상 처리 서버에 제공할 수 있다. S160단계에서, 영상 처리 서버는 선택된 후보 오브젝트와 연관된 영상 처리를 수행하여, 해당 후보 오브젝 트가 적어도 부분적으로 가려진 영상 데이터를 생성할 수 있다. S170단계에서, 영상 처리 서버는 처리된 영상 데이터를 클라이언트 장치에 전송한다. S180단계에서, 영상 처리 서버는 후보 오브젝트가 존재하지 않음을 클라이언트 장치에 알릴 수 있다. 도 12는 도 10의 S130단계의 실시 예를 보여주는 순서도이다. 도 1 및 도 12를 참조하면, S210단계에서, 원 영상 데이터가 복수의 영상 프레임들의 스트림을 포함하는 비디오 데이터일 때 S220단계가 수행된다. S220단계에서, 식별된 후보 오브젝트가 태깅된다. S230단계에서, 이후 영상 프레임들에서 태깅된 후보 오브젝트 가 추적되어 태깅 정보를 생성한다. 이 분야에 알려진 오브젝트 추적을 위한 다양한 방식들이 사용될 수 있다. 실시 예들에서, 칼만 필터(Kalman filter)와 헝가리안 매칭(hungarian matching) 알고리즘이 채용되어 후보 오 브젝트가 추적될 수 있으며, 그에 따른 태깅 정보가 생성될 수 있다. 도 13은 도 10의 S160단계의 실시 예를 보여주는 순서도이다. 도 1 및 도 12를 참조하면, S310단계에서, 영상 처리 서버는 태깅 정보에 기반하여, 선택된 후보 오브젝트 와 연관된 영상 처리를 복수의 영상 프레임들에 대해 수행할 수 있다. 태깅 정보에 기반하여 선택된 후보 오브젝트를 포함하는 영상 프레임들이 식별될 수 있으며, 식별된 영상 프레임들에서 해당 후보 오브젝트가 블러링 처리될 수 있다. 도 14는 도 2의 영상 처리 서버를 구현하기에 적합한 컴퓨터 장치의 실시 예를 보여주는 블록도이다. 도 14를 참조하면, 컴퓨터 장치는 버스, 적어도 하나의 프로세서, 시스템 메모리, 스 토리지 인터페이스(I/F), 통신 인터페이스, 저장 매체, 및 통신기를 포함한다. 버스는 컴퓨터 장치의 다양한 구성 요소들에 연결되어 데이터, 신호, 및 정보를 전달한다. 프로세 서는 범용 혹은 전용 프로세서 중 어느 하나일 수 있으며, 컴퓨터 장치의 제반 동작들을 제어할 수 있다. 프로세서는 실행될 때 다양한 기능들을 제공하는 프로그램 코드들 및 명령어들을 시스템 메모리에 로딩하고, 로딩된 프로그램 코드들 및 명령어들을 처리하도록 구성된다. 시스템 메모리는 프로세서(120 0)의 워킹 메모리로서 제공될 수 있다. 실시 예로서, 시스템 메모리는 램(Random Access Memory, RAM), 롬(Read Only Memory, ROM), 및 다른 타입의 컴퓨터에 의해 판독 가능한 매체 중 적어도 하나를 포함할 수 있다. 프로세서는 프로세서에 의해 실행될 때 도 2의 영상 처리 장치의 기능들을 제공하는 영상 처 리 모듈을 시스템 메모리에 로딩할 수 있다. 그러한 프로그램 코드들 및/또는 명령어들은 프로세서 에 의해 실행되어 도 2의 영상 처리 장치의 기능들 및/또는 동작들을 수행할 수 있다. 다시 말해, 프로세서에 의해 실행되는 영상 처리 모듈은 도 2의 영상 처리 장치로서 제공될 수 있다. 그 러한 기능들 및/또는 동작들을 수행하기 위해, 프로세서에 의해 실행되는 영상 처리 모듈은 스토리 지 인터페이스 및 통신 인터페이스와 같은 컴퓨터 장치의 구성 요소들을 이용할 수 있다. 예 를 들면, 영상 처리 모듈은 통신 인터페이스 및 통신기를 통해 도 1의 네트워크 상 클 라이언트 장치와 통신할 수 있다. 프로그램 코드들 및/또는 명령어들은 별도의 컴퓨터에 의해 판독 가능한 기록 매체인 저장 매체로부터 시 스템 메모리에 로딩될 수 있다. 또는, 프로그램 코드들 및/또는 명령어들은 컴퓨터 장치의 외부로 부터 통신기을 통해 시스템 메모리에 로딩될 수도 있다. 이 밖에도, 시스템 메모리는 영상 처리 모듈를 위한 버퍼 메모리 및/또는 워킹 메모리로서 기능할 수 있다. 예를 들면, 시스템 메모리 는 도 2의 메모리로서 제공될 수 있다. 도 14에서, 시스템 메모리는 프로세서와 구분된 구성으로 도시되어 있으나, 시스템 메모리의 적어도 일부는 프로세서에 포함될 수도 있다. 시스템 메모리는 실시 예들에 따라 물리적 및/또는 논리적으로 서로 분리된 복수의 메모리들로서 제공될 수 있다. 스토리지 인터페이스는 저장 매체에 연결된다. 스토리지 인터페이스는 버스에 연결된 프로세서 및 시스템 메모리와 같은 구성 요소들과 저장 매체 사이를 인터페이싱할 수 있다. 통신 인터페이스는 통신기에 연결된다. 통신 인터페이스는 버스에 연결된 구성 요소들 과 통신기 사이를 인터페이싱할 수 있다. 실시 예들에서, 버스, 프로세서, 및 시스템 메모리는 하나의 칩에 통합될 수 있다. 예 를 들면, 버스, 프로세서, 및 시스템 메모리는 하나의 반도체 칩에 실장될 수 있다. 실시 예들에서, 반도체 칩은 스토리지 인터페이스 및 통신 인터페이스를 더 포함할 수 있다. 저장 매체는 전원이 차단되더라도 저장된 데이터를 유지하는 다양한 타입들의 불휘발성 저장 매체들, 예 를 들면 플래시 메모리(flash memory), 하드 디스크(hard disk) 등을 포함할 수 있다. 저장 매체의 적어 도 일부는 도 4의 데이터베이스(DB)로서 제공될 수 있다. 통신기(1700, 혹은 트랜시버)는 네트워크를 통해 컴퓨터 장치와 네트워크 시스템(100, 도 1 참조) 내 다른 장치들 및/또는 서버들 사이의 신호들을 송수신할 수 있다. 통신기는 도 2의 네트워크 통신기 로서 제공될 수 있다. 이상에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자 또는 해당 기술 분야에 통상의 지식을 갖는 자라면, 후술될 특허청구범위에 기재된 본 발명의 사상 및 기술 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.따라서, 본 발명의 기술적 범위는 명세서의 상세한 설명에 기재된 내용으로 한정되는 것이 아니라 특허청구범위 에 의해 정해져야만 할 것이다."}
{"patent_id": "10-2022-0110055", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 네트워크 시스템을 보여주는 블록도이다. 도 2는 도 1의 영상 처리 서버의 실시 예를 보여주는 블록도이다. 도 3은 클라이언트 장치에 디스플레이되는, 영상 데이터 및 그것에 표시된 하이라이트들을 포함하는 영상 데이 터를 보여주는 도면이다. 도 4는 도 2의 오브젝트 식별기의 실시 예를 보여주는 블록도이다. 도 5는 도 4의 오브젝트 감지부 및 오브젝트 식별부에 의해 생성된 식별자데이터의 예를 개념적으로 보여주는 도면이다. 도 6은 비디오 데이터에 포함된 영상 프레임들의 일 예를 개념적으로 보여주는 도면이다. 도 7은 비디오 데이터로부터 추출된 식별자 데이터의 예를 개념적으로 보여주는 도면이다. 도 8은 비디오 데이터에 포함된 영상 프레임들의 다른 예를 개념적으로 보여주는 도면이다. 도 9는 비디오 데이터로부터 추출된 식별자 데이터의 다른 예를 개념적으로 보여주는 도면이다. 도 10은 도 4의 오브젝트 감지부의 실시 예를 보여주는 블록도이다. 도 11은 본 발명의 실시 예에 따른 클라이언트 장치로부터 전송된 영상 데이터를 처리하는 방법을 보여주는 순 서도이다. 도 12는 도 10의 S130단계의 실시 예를 보여주는 순서도이다. 도 13은 도 10의 S160단계의 실시 예를 보여주는 순서도이다. 도 14는 도 2의 영상 처리 서버를 구현하기에 적합한 컴퓨터 장치의 실시 예를 보여주는 블록도이다."}
