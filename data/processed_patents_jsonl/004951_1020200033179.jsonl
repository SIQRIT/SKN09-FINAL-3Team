{"patent_id": "10-2020-0033179", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0109407", "출원번호": "10-2020-0033179", "발명의 명칭": "학습에 의한 머신 러닝 실행 관리 플랫폼 시스템 및 방법", "출원인": "숭실대학교산학협력단", "발명자": "홍지만"}}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "머신 러닝(machine learning)이 수행되는 태스크(task)를 입력받는 외부 입력 모듈(10)과;상기 입력된 태스크(task)에 대해 머신 러닝을 수행하되, 수행 중이거나 수행을 마친 적어도 하나 이상의 태스크에 대한 정보를 제공하는 워커 노드(20)와;상기 워커 노드(20)에서 제공된 태스크 정보를 분석하고, 태스크별로 상기 머신 러닝에 소요되는 컴퓨팅 자원을산출하는 세션 노드(30); 및상기 외부 입력 모듈(10)을 통해 새로 입력된 태스크에 대한 머신 러닝 수행 명령을 전달하는 마스터 노드(40);를 포함하되,상기 세션 노드(30)는 미리 산출된 태스크의 컴퓨팅 자원을 기반으로 새로 입력된 태스크의 컴퓨팅 자원을 예측하고, 예측 결과에 따라 상기 새로 입력된 태스크가 할당되는 워커 노드(20)를 선택하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 워커 노드(20)는,태스크의 머신 러닝에 소요되는 컴퓨팅 자원 정보를 로그(Log) 형식으로 제공하는 것을 특징으로 하는 학습에의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 워커 노드(20)는,CPU 사용량, 메모리 사용량, 디스크 사용량, GPU 플롭(Flops), 머신 러닝 태스크의 총 에폭(epoch) 및 머신 러닝 총 수행 시간을 상기 컴퓨팅 자원 정보로 제공하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 세션 노드(30)는,상기 워커 노드(20)로부터 제공된 컴퓨팅 자원을 분석하여 머신 러닝 태스크의 에폭(epoch)당 컴퓨팅 비용 및수행 시간을 산출하여 상기 새로 입력된 태스크에서 소요되는 컴퓨팅 자원을 예측하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 세션 노드(30)는,각 에폭당 상기 CPU 사용량, 메모리 사용량, 디스크 사용량 및 GPU 플롭을 참조하되,진행된 모든 에폭에서의 CPU 사용량, 메모리 사용량, 디스크 사용량 각각에 대한 평균값으로 상기 컴퓨팅 비용을 산출하여,GPU 플롭에서의 에폭당 CPU 사용량, 메모리 사용량 및 디스크 사용량의 평균값으로 상기 새로 입력된 태스크를공개특허 10-2021-0109407-3-예측하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 세션 노드(30)는,상기 머신 러닝 태스크의 총 에폭, 머신 러닝 총 수행 시간 및 GPU 플롭을 참조하되,상기 머신 러닝 태스크의 총 에폭 및 머신 러닝 총 수행 시간으로 에폭당 수행 시간을 산출하여, GPU 플롭에서의 에폭당 수행 시간으로 상기 새로 입력된 태스크를 예측하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서,상기 세션 노드(30)는 다수개이며,각각의 세션 노드(30)는 동일하거나 동일한 그룹으로 분류되는 프레임워크(frame work)로 구성된 워커 노드(20)를 관리하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서,상기 세션 노드(30)는,상기 새로 입력된 태스크에 대해 머신 러닝을 수행하는데 소요되는 컴퓨팅 자원을 추가하여, 상기 예측에 이용되는 태스크의 컴퓨팅 자원에 대한 기록을 갱신하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 마스터 노드(40) 및 세션 노드(30) 중 어느 하나 이상은,상기 워커 노드(20)에 대해 네트워크 핑 테스트(ping test)를 수행하여, 태스크의 할당이 가능한 노드를 추출하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 머신 러닝이 수행된 태스크에 대한 정보가 예측 신뢰도를 획득하는 수준으로 축적되지 않은 경우, 이미 머신 러닝이 수행된 태스크에 대한 정보에 선형 보간법을 적용하는 초기 구동 모듈을 더 포함하되,상기 초기 구동 모듈은,상기 선형 보간법으로 예상한 태스크에 대한 정보로 상기 새로 입력된 태스크의 컴퓨팅 자원을 예측하기 위한태스크 정보를 생성하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "워커 노드(20)에서 태스크에 대해 머신 러닝을 수행하되, 수행 중이거나 수행을 마친 적어도 하나 이상의 태스크에 대한 정보를 제공하는 정보 제공 단계(S10)와;세션 노드(30)에서 상기 워커 노드(20)로부터 제공된 태스크 정보를 분석하고, 태스크별로 상기 머신 러닝에 소요되는 컴퓨팅 자원을 산출하는 자원 산출 단계(S20)와;외부 입력 모듈(10)을 통해 머신 러닝이 수행되는 새로운 태스크를 입력받아 등록하는 태스크 등록공개특허 10-2021-0109407-4-단계(S30)와;상기 세션 노드(30)에서 미리 산출된 태스크의 컴퓨팅 자원을 기반으로 상기 새로 입력된 태스크의 컴퓨팅 자원을 예측하고, 예측 결과에 따라 상기 새로 입력된 태스크가 할당되는 워커 노드(20)를 선택하는 노드 선택 단계(S40)와;마스터 노드(40)에서 상기 외부 입력 모듈(10)을 통해 새로 입력된 태스크에 대한 머신 러닝 수행 명령을 전달하는 실행 명령 단계(S50); 및상기 워커 노드(20)에서 상기 머신 러닝 수행 명령을 입력받아 상기 새로 입력된 태스크에 대한 머신 러닝을 수행하는 머신 러닝 단계(S60);를 포함하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 방법."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 마스터 노드(40) 및 세션 노드(30) 중 어느 하나 이상에서,상기 워커 노드(20)에 대해 네트워크 핑 테스트(ping test)를 수행하여, 상기 태스크의 할당이 가능한 노드를분석하는 상태 검색 단계를 더 포함하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 방법."}
{"patent_id": "10-2020-0033179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 머신 러닝이 수행된 태스크에 대한 정보가 예측 신뢰도를 획득하는 수준으로 축적되지 않은 경우, 초기 구동 모듈에 의해 이미 머신 러닝이 수행된 태스크에 대한 정보에 선형 보간법을 적용하는 데이터 보간 단계(S1)를 더 포함하되,상기 데이터 보간 단계(S1)에서는,상기 선형 보간법으로 예상한 태스크에 대한 정보로 상기 새로 입력된 태스크의 컴퓨팅 자원을 예측하기 위한태스크 정보를 생성하는 것을 특징으로 하는 학습에 의한 머신 러닝 실행 관리 방법."}
{"patent_id": "10-2020-0033179", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 머신 러닝 태스크에 대한 로그 정보를 분석하여 태스크에 소요되는 컴퓨팅 자원을 예측하고, 그 예측 결과를 기반으로 최적의 워커 노드를 선택하여 머신 러닝을 수행하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템 및 방법에 관한 것이다. 나아가 본 발명은 네트워크 오류를 비롯하여 플랫폼 외부에서의 장애 요인에 따라 플랫폼 구조나 기능에 이상이 발생하는 경우 이를 감지하여 머신 러닝 수행 노드의 변경을 가능하게 하는 학습에 의한 머신 러닝 실행 관리 플 랫폼 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0033179", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 머신 러닝 태스크에 대한 로그 정보를 분석하여 태스크에 소요되는 컴퓨팅 자원을 예측하고, 그 예측 결과를 기반으로 최적의 워커 노드를 선택하여 머신 러닝을 수행하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템 및 방법에 관한 것이다. 나아가 본 발명은 네트워크 오류를 비롯하여 플랫폼 외부에서의 장애 요인에 따라 플랫폼 구조나 기능에 이상이 발생하는 경우 이를 감지하여 머신 러닝 수행 노드의 변경을 가능하게 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2020-0033179", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "머신 러닝(machine learning)은 패턴 인식과 컴퓨터 학습 이론의 연구로부터 진화한 인공지능(AI)의 한 분야로, 경험적 데이터를 기반으로 학습 및 예측을 수행하고 스스로의 성능을 향상시키는 시스템과 그 알고리즘을 구축 한다. 이러한 머신 러닝을 위한 통합 원격 실행 플랫폼은 그 상위 레이어부터 마스터 노드, 세션 노드 및 워커 노드로 구성된다. 또한 별도의 외부 네트워크 저장소를 가지며, 사용자는 외부 프로그램을 통해 플랫폼에 접근한다. 또한, 플랫폼에 접근한 사용자가 머신 러닝을 수행할 대상인 태스크(task)를 등록하면, 그 등록된 태스크는 먼 저 머신 러닝을 수행할 프레임워크에 맞게 세션 노드(session node)에 할당된다.세션 노드는 해당 태스크의 수행이 가능하면서도 연산처리 능력이 가장 좋은 워커 노드에 태스크를 할당하고, 사용자가 워커 노드에서 수행할 머신 러닝 관련 명령어를 내리면 사용자의 명령에 따라 머신 러닝을 수행한다. 그러나, 종래의 머신 러닝을 위한 통합 원격 실행 플랫폼은 세션 노드에서 워커 노드 중 어느 하나에 머신 러닝 태스크를 할당할 때 태스크와는 무관하게 오직 워커 노드의 성능만을 고려하였다. 따라서, 워커 노드의 성능이 머신 러닝 태스크가 요구하는 하드웨어 성능보다 낮은 경우 머신 러닝 태스크 수행 속도가 현저히 저하되며, 심한 경우에는 워커 노드가 셧다운 되어 더 이상 사용할 수 없는 문제가 있다. 나아가, 네트워크 등 플랫폼 외부적 장애 요인에 대해 대응할 수 없어 플랫폼 구조에 문제가 발생할 수 있다. 예컨대 작업 수행 전이나 수행 중인 워커 노드에서 발생한 네트워크 장애 등에 대응할 수 없다는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 미국등록특허 US 16/248,560 (특허문헌 0002) 대한민국 공개특허 제10-2012-0001688호"}
{"patent_id": "10-2020-0033179", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 바와 같은 문제점을 해결하기 위한 것으로, 머신 러닝 태스크에 대한 로그 정보를 분석하여 태스크에 소요되는 컴퓨팅 자원을 예측하고, 그 예측 결과를 기반으로 최적의 워커 노드를 선택하는 학습에 의 한 머신 러닝 실행 관리 플랫폼 시스템 및 방법을 제공하고자 한다. 나아가 본 발명은 네트워크 오류를 비롯하여 플랫폼 외부에서의 장애 요인 발생에 따라 플랫폼 구조나 기능에 이상이 발생하는 경우 이를 감지하여 머신 러닝 수행 노드의 변경을 가능하게 하는 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템 및 방법을 제공하고자 한다."}
{"patent_id": "10-2020-0033179", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이를 위해 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템은 머신 러닝(machine learning)이 수행되는 태스크(task)를 입력받는 외부 입력 모듈과; 상기 입력된 태스크(task)에 대해 머신 러닝을 수행하되, 수행 중이거나 수행을 마친 적어도 하나 이상의 태스크에 대한 정보를 제공하는 워커 노드와; 상기 워커 노드에 서 제공된 태스크 정보를 분석하고, 태스크별로 상기 머신 러닝에 소요되는 컴퓨팅 자원을 산출하는 세션 노드; 및 상기 외부 입력 모듈을 통해 새로 입력된 태스크에 대한 머신 러닝 수행 명령을 전달하는 마스터 노드;를 포 함하되, 상기 세션 노드는 미리 산출된 태스크의 컴퓨팅 자원을 기반으로 새로 입력된 태스크의 컴퓨팅 자원을 예측하고, 예측 결과에 따라 상기 새로 입력된 태스크가 할당되는 워커 노드를 선택하는 것을 특징으로 한다. 이때, 상기 워커 노드는 태스크의 머신 러닝에 소요되는 컴퓨팅 자원 정보를 로그(Log) 형식으로 제공하는 것이 바람직하다. 또한, 상기 워커 노드는 CPU 사용량, 메모리 사용량, 디스크 사용량, GPU 플롭(Flops), 머신 러닝 태스크의 총 에폭(epoch) 및 머신 러닝 총 수행 시간을 상기 컴퓨팅 자원 정보로 제공하는 것이 바람직하다. 또한, 상기 세션 노드는 상기 워커 노드로부터 제공된 컴퓨팅 자원을 분석하여 머신 러닝 태스크의 에폭(epoc h)당 컴퓨팅 비용 및 수행 시간을 산출하여 상기 새로 입력된 태스크에서 소요되는 컴퓨팅 자원을 예측하는 것 이 바람직하다. 또한, 상기 세션 노드는 각 에폭당 상기 CPU 사용량, 메모리 사용량, 디스크 사용량 및 GPU 플롭을 참조하되, 진행된 모든 에폭에서의 CPU 사용량, 메모리 사용량, 디스크 사용량 각각에 대한 평균값으로 상기 컴퓨팅 비용을 산출하여, GPU 플롭에서의 에폭당 CPU 사용량, 메모리 사용량 및 디스크 사용량의 평균값으로 상기 새로 입 력된 태스크를 예측하는 것이 바람직하다. 또한, 상기 세션 노드는 상기 머신 러닝 태스크의 총 에폭, 머신 러닝 총 수행 시간 및 GPU 플롭을 참조하되, 상기 머신 러닝 태스크의 총 에폭 및 머신 러닝 총 수행 시간으로 에폭당 수행 시간을 산출하여, GPU 플롭에서 의 에폭당 수행 시간으로 상기 새로 입력된 태스크를 예측하는 것이 바람직하다. 또한, 상기 세션 노드는 다수개이며 각각의 세션 노드는 동일하거나 동일한 그룹으로 분류되는 프레임워크 (frame work)로 구성된 워커 노드를 관리하는 것이 바람직하다. 또한, 상기 세션 노드는 상기 새로 입력된 태스크에 대해 머신 러닝을 수행하는데 소요되는 컴퓨팅 자원을 추가 하여, 상기 예측에 이용되는 태스크의 컴퓨팅 자원에 대한 기록을 갱신하는 것이 바람직하다. 또한, 상기 마스터 노드 및 세션 노드 중 어느 하나 이상은 상기 워커 노드에 대해 네트워크 핑 테스트(ping test)를 수행하여, 태스크의 할당이 가능한 노드를 추출하는 것이 바람직하다. 또한, 상기 머신 러닝이 수행된 태스크에 대한 정보가 예측 신뢰도를 획득하는 수준으로 축적되지 않은 경우, 이미 머신 러닝이 수행된 태스크에 대한 정보에 선형 보간법을 적용하는 초기 구동 모듈을 더 포함하되, 상기 초기 구동 모듈은 상기 선형 보간법으로 예상한 태스크에 대한 정보로 상기 새로 입력된 태스크의 컴퓨팅 자원 을 예측하기 위한 태스크 정보를 생성하는 것이 바람직하다. 한편, 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 방법은 워커 노드에서 태스크에 대해 머신 러닝을 수행 하되, 수행 중이거나 수행을 마친 적어도 하나 이상의 태스크에 대한 정보를 제공하는 정보 제공 단계와; 세션 노드에서 상기 워커 노드로부터 제공된 태스크 정보를 분석하고, 태스크별로 상기 머신 러닝에 소요되는 컴퓨팅 자원을 산출하는 자원 산출 단계와; 외부 입력 모듈을 통해 머신 러닝이 수행되는 새로운 태스크를 입력받아 등 록하는 태스크 등록 단계와; 상기 세션 노드에서 미리 산출된 태스크의 컴퓨팅 자원을 기반으로 상기 새로 입력 된 태스크의 컴퓨팅 자원을 예측하고, 예측 결과에 따라 상기 새로 입력된 태스크가 할당되는 워커 노드를 선택 하는 노드 선택 단계와; 마스터 노드에서 상기 외부 입력 모듈을 통해 새로 입력된 태스크에 대한 머신 러닝 수 행 명령을 전달하는 실행 명령 단계; 및 상기 워커 노드에서 상기 머신 러닝 수행 명령을 입력받아 상기 새로 입력된 태스크에 대한 머신 러닝을 수행하는 머신 러닝 단계;를 포함하는 것을 특징으로 한다. 이때, 상기 마스터 노드 및 세션 노드 중 어느 하나 이상에서, 상기 워커 노드에 대해 네트워크 핑 테스트(ping test)를 수행하여, 상기 태스크의 할당이 가능한 노드를 분석하는 상태 검색 단계를 더 포함하는 것이 바람직하 다. 또한, 상기 머신 러닝이 수행된 태스크에 대한 정보가 예측 신뢰도를 획득하는 수준으로 축적되지 않은 경우, 초기 구동 모듈에 의해 이미 머신 러닝이 수행된 태스크에 대한 정보에 선형 보간법을 적용하는 데이터 보간 단 계를 더 포함하되, 상기 데이터 보간 단계에서는 상기 선형 보간법으로 예상한 태스크에 대한 정보로 상기 새로 입력된 태스크의 컴퓨팅 자원을 예측하기 위한 태스크 정보를 생성하는 것이 바람직하다."}
{"patent_id": "10-2020-0033179", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 발명은 머신 러닝 태스크에 대한 로그 정보를 분석하여 태스크에 소요되는 컴퓨팅 자원을 예측 하고, 그 예측 결과를 기반으로 최적의 워커 노드를 선택한다. 따라서, 최적 상태로 태스크를 처리할 수 있는 워커 노드에서 태스크를 할당받아 머신 러닝을 수행하게 한다. 나아가 본 발명은 핑 테스트를 통해 플랫폼 외부에서의 장애 요인에 의해 플랫폼 구조나 기능에 이상이 발생하 는 경우 이를 감지한다. 따라서, 이상 발생시 이를 감지하여 머신 러닝 수행 노드의 변경을 가능하게 하므로 지 속적이면서 효율적인 머신 러닝의 수행을 가능하게 한다."}
{"patent_id": "10-2020-0033179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예에 따른 학습에 의한 머신 러닝 실행 관리 플랫폼 시 스템 및 방법에 대해 상세히 설명한다. 도 1과 같이, 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템은 외부 입력 모듈, 워커 노 드, 세션 노드 및 마스터 노드를 포함한다. 바람직한 다른 실시예로 초기 구동 모듈을 더 포함한다. 이러한 구성에 의하면 외부 입력 모듈을 통해 입력된 태스크(task)를 마스터 노드에서 등록하고, 세션 노드는 등록된 태스크를 워커 노드에 할당하여 워커 노드에서 태스크에 대한 머신 러닝이 이루어지 게 한다. 특히, 본 발명은 머신 러닝 태스크에 대한 로그 형태의 정보를 분석하여 태스크에 소요되는 컴퓨팅 자원을 예측 하고, 머신 러닝이 수행될 태스크에 대한 예측 결과를 기반으로 최적의 워커 노드를 선택한다. 또한 네트워크 오류를 비롯하여 플랫폼 외부에서의 장애 요인 발생에 따라 플랫폼 구조나 기능에 이상이 발생하 는 경우 이를 감지하여 머신 러닝 수행 노드인 워커 노드의 변경을 가능하게 한다. 본 발명의 특징적인 구성들에 대한 구체적인 설명에 앞서 머신 러닝 태스크에 대한 통합 원격 수행 관리를 위한 구성들에 대해 먼저 살펴보면, 본 발명은 각 노드들 이외에 별도의 외부 네트워크 저장소(DB-O)를 가진다. 워커 노드, 세션 노드 및 마스터 노드를 포함하는 각 노드들은 머신 러닝을 위한 프로세스의 처리 가 가능한 컴퓨팅 모듈의 일종으로, 이들 노드는 외부 네트워크 저장소(DB-O)에 접속하여 데이터 처리를 수행할 수 있다. 외부 네트워크 저장소(DB-O)는 머신 러닝의 데이터셋(dataset)을 제공하는 것으로 머신 러닝 수행 환경을 셋팅 한 워커 노드는 상기 외부 네트워크 저장소(DB-O)에서 데이터셋을 다운로드하여 머신 러닝을 수행한다. 사용자는 외부 입력 모듈을 통해 본 발명의 플랫폼에 접근한다. 외부 입력 모듈은 일 예로 API(Application Programming Interface) 등과 같은 외부 프로그램으로 구현되어 있어서 손쉽게 플랫폼에 접근 한다. 또한 사용자는 외부 입력 모듈을 이용하여 머신 러닝을 수행할 대상인 태스크를 입력한다. 입력된 태스크는 머신 러닝을 수행할 프레임워크에 맞게 세션 노드에 할당된다. 세션 노드는 해당 태스크를 워커 노드 에 할당한다. 이때, 사용자가 외부 입력 모듈을 통해 워커 노드에서 수행할 머신 러닝 관련 명령어를 입력하면 해당 명령어가 워커 노드에 전달되어 실행된다. 대표적으로 '러닝 머신 실행 명령'을 내리면 머신 러닝이 시작된 다. 마스터 노드는 플랫폼 내 워커 노드들의 자원 모니터링, 태스크의 머신 러닝 진행 상황 확인, 태스크를 플랫폼에 업로드, 외부 입력 모듈로부터 입력된 사용자의 명령의 전달 및 태스크와 데이터셋을 관리하는 기 능을 가진다. 세션 노드는 동일하거나 동일한 그룹으로 분류되는 프레임워크로 구성된 워커 노드들을 관리한다. 각 세션 노드는 워커 노드들의 자원을 모니터링하고 마스터 노드로부터 받은 명령어를 워커 노드 에 전달한다. 워커 노드는 세션 노드로부터 전달받은 태스크에 해당하는 머신 러닝을 수행한다. 또한 주기적으로 당 해 워커 노드의 자원상황을 세션 노드에 보고한다. 따라서, 워커 노드는 '태스크 실행기'를 통해 머신 러닝 수행환경을 세팅하고 머신 러닝 데이터셋을 외부 네트워크 저장소(DB-O)로부터 다운로드 받으며, 머신 러닝 수행 명령이 전달되면 준비된 수행환경에서 머신 러 닝을 수행한다. 또한 자원관리 모듈을 통해 워커 노드의 자원상황을 세션 노드에 보고한다. 자원상황은 실시간 혹은 주 기적으로 세션 노드에 보고됨에 따라 플랫폼에 할당된 태스크를 수행하는 워커 노드의 선정에 활용된다. 한편, 위에서 설명한 바와 같이 본 발명은 머신 러닝 태스크에 대한 로그 정보를 분석하여 태스크에 소요되는 컴퓨팅 자원을 예측하고, 머신 러닝이 수행될 태스크에 대한 예측 결과를 기반으로 워커 노드를 선택한다. 이를 위해, 도 2와 같이 워커 노드는 외부 입력 모듈을 통해 입력된 태스크에 대해 머신 러닝을 수행하 고, 수행 중이거나 수행을 마친 태스크에 대한 정보를 세션 노드에 제공한다. 태크스에 대한 정보는 워커 노드에서 태스크의 머신 러닝에 소요되는 컴퓨팅 자원 정보를 의미하는 것으로 로그(Log) 형식으로 제공된다. 또한 태스크 정보는 적어도 하나 이상이다. 바람직하게는 신뢰성 높은 데이터 산 출을 위해 설정된 횟수 이상 축적된 머신 러닝 태스크에 대한 데이터가 이용되게 한다. 실시예로써 워커 노드는 CPU 사용량, 메모리 사용량, 디스크 사용량, GPU 플롭(Graphic Process Unit Flops), 머신 러닝 태스크의 총 에폭(epoch) 및 머신 러닝 총 수행 시간을 컴퓨팅 자원 정보로 제공한다. 후술하는 바와 같이 컴퓨팅 자원에 '컴퓨팅 비용'과 '수행 시간'을 포함하는 경우, CPU 사용량, 메모리 사용량 및 디스크 사용량은 컴퓨팅 비용 산출에 이용된다. 총 에폭과 총 수행 시간은 컴퓨터 연산처리 단위인 에폭당 수행 시간의 산출에 이용된다. 세션 노드는 상술한 바와 같이 워커 노드에서 제공된 머신 러닝 태스크 정보(즉, 로그 형식 정보)를 분 석하고, 태스크별로 머신 러닝에 소요되는 컴퓨팅 자원을 산출한다. 특히, 세션 노드는 미리 산출된 태스크의 컴퓨팅 자원을 기반으로 새로 입력된 태스크의 컴퓨팅 자원을 예 측하고, 예측 결과에 따라 새로 입력된 태스크가 할당되는 워커 노드를 선택한다. 즉, 세션 노드는 컴퓨팅 자원에 대한 정보를 미리 산출하고, 이를 근거로 후속의 새로운 머신 러닝을 수행 할 태스크에 사용되는 컴퓨팅 자원을 예측한다. 이를 기반으로 워커 노드를 결정한다. 이에, 세션 노드는 워커 노드로부터 제공된 컴퓨팅 자원을 분석하여 머신 러닝 태스크의 에폭(epoch)당 컴퓨팅 비용 및 수행 시간을 산출하고, 새로 입력된 태스크에서 소요되는 컴퓨팅 자원을 예측한다. 물론 경과될 것으로 예측되는 수행 시간을 이용하여 예상 종료 시간 역시 예측할 수 있다. 이러한 세션 노드는 '컴퓨팅 비용'의 산출을 위해 각 에폭당 CPU 사용량, 메모리 사용량, 디스크 사용량 및 GPU 플롭을 참조한다. 이를 통해 진행된 모든 에폭에서의 CPU 사용량, 메모리 사용량, 디스크 사용량 각각에 대 한 평균값을 계산한다. 이를 통해 컴퓨팅 비용을 결정한다. 따라서, 워커 노드로부터 제공된 GPU 플롭에서의 에폭당 CPU 사용량, 메모리 사용량 및 디스크 사용량의 평 균값으로 새로 입력된 태스크를 예측한다. 즉, 해당 GPU 플롭마다 그에 대응하는 태스크를 예측한다. 이를 바탕으로 세션 노드에서 새로 입력된 태스크를 워커 노드에 할당할 때 그 할당 대상이 되는 워커 노드의 플롭(Flops)을 참조하여 새로 입력된 태스크의 머신 러닝 수행에 필요한 컴퓨팅 정보를 예측할 수 있게 된다. 따라서, 예측한 컴퓨팅 비용이 워커 노드의 하드웨어 성능보다 높게 요구된다면 해당 워커 노드에 할당 하지 않고 새로운 머신 러닝 태스크의 수행이 가능한 다른 워커 노드를 검색하여 태스크를 할당하게 된다.또한, 세션 노드는 '수행 시간'의 산출을 위해 머신 러닝 태스크의 총 에폭, 머신 러닝 총 수행 시간 및 GPU 플롭을 참조한다. 이를 통해 머신 러닝 태스크의 총 에폭 및 머신 러닝 총 수행 시간으로 에폭당 수행 시간 을 산출한다. 에폭당 수행 시간은 총 수행 시간을 총 에폭의 수로 나누어 산출된다. 따라서, 워커 노드로부터 제공된 GPU 플롭에서의 에폭당 수행 시간으로 새로 입력된 태스크를 예측한다. 즉, 해당 GPU 플롭마다 그에 대응하는 수행 시간을 산출한다. 다만, 수행 시간은 일정 시점부터 종료 시간까지 의 시간이므로 해당 수행 시간으로부터 종료 시간을 산출할 수도 있다. 이와 같이 플롭(Flops)을 기준으로 해당 플롭일 때의 에폭 당 수행 시간을 계산하며, 차후 새로운 머신 러닝 태 스크를 할당시 새로운 머신 러닝 태스크의 총 에폭과 할당 대상이 되는 워커 노드의 플롭을 참고하여 머신 러닝 태스크의 종료 시간을 예측한다. 다만, 상술한 세션 노드는 다수개이며 각각의 세션 노드는 동일하거나 동일한 그룹으로 분류되는 프레 임워크(frame work)로 구성된 워커 노드를 관리하는 것이 바람직하다. 세션 노드는 동일 혹은 동일 그룹의 프레임워크로 구성된 워커 노드들을 관리함으로써, 입력된 머신 러 닝 태스크에 따라 세션 노드를 할당하고, 그에 의해 일괄 관리되는 프레임워크 내에서 워커 노드를 선 택한다. 또한, 세션 노드는 새로 입력된 태스크에 대해 머신 러닝을 수행하는데 소요되는 컴퓨팅 자원을 추가하여, 예측에 이용되는 태스크의 컴퓨팅 자원에 대한 기록을 갱신하는 것이 바람직하다. 이와 같이 예측을 통해 머신 러닝 태스크를 워커 노드에 할당하고, 그 할당된 워커 노드에서 실제 머신 러닝이 이루어진 태스크의 정보를 추가하여 다음의 예측에 반영하는 과정을 반복, 연속함으로써 점차 신뢰성을 높이게 된다. 마스터 노드는 외부 입력 모듈을 통해 새로 입력된 태스크에 대한 머신 러닝 수행 명령을 전달한다. 마 스터 노드로부터 전달된 명령은 일 예로 세션 노드를 통해 워커 노드로 전달된다. 또한, 위에서 설명한 바와 같이 마스터 노드는 외부 입력 모듈을 통해 입력된 태스크를 프레임워크의 구성에 따라 세션 노드에 할당함으로써, 세션 노드에서 다시 워커 노드를 할당하게 한다. 초기 구동 모듈은 머신 러닝이 수행된 태스크에 대한 정보가 예측 신뢰도를 획득하는 수준으로 축적되지 않은 경우 예상되는 데이터를 추가하여 데이터 표본을 확장한다. 이러한 초기 구동 모듈을 실시예로써 마스터 노드 에 일체로 구현될 수 있다. 플랫폼 구동 초기나 자주 사용되지 않는 GPU 플롭의 경우에는 머신 러닝 태스크 정보가 충분히 축적되지 않아서 평균값 등을 이용하여 새로 입력된 태스크에 대한 예측을 진행하기 어렵거나 신뢰성이 낮다. 이에, 초기 구동 모듈은 이미 머신 러닝이 수행된 소수의 태스크 정보에 선형 보간법을 적용하고, 선형 보간법 으로 예상한 태스크에 대한 정보로 새로 입력된 태스크의 컴퓨팅 자원을 예측하기 위한 태스크 정보를 생성한다. 한편, 또 다른 실시예로써 본 발명은 네트워크 오류를 비롯하여 플랫폼 외부에서의 장애 요인 발생에 따라 플랫 폼 구조나 기능에 이상이 발생하는 경우 이를 감지하여 머신 러닝 수행 노드의 변경을 가능하게 한다. 이를 위해 마스터 노드 및 세션 노드 중 어느 하나 이상은 워커 노드에 대해 네트워크 핑 테스트 (ping test)를 수행하여, 태스크의 할당이 가능한 노드를 추출한다. 또한, 마스터 노드에서 핑 테스트를 수 행하는 경우에는 세션 노드를 감시할 수도 있다. 핑 테스트는 테스트 신호의 전송과 그에 따른 응답 여부를 확인하는 네트워크 상의 신호 전송 기술로, 여기서는 노드 간에 신호를 정상적으로 주고받는지 확인하여 접속 속도나 끊김 현상 등을 확인하도록 ping 명령어를 이용 한다.마스터 노드와 세션 노드는 머신 러닝 수행을 위한 일종의 네트워크 상의 관리 노드(management node) 에 해당하므로, 이들 중 어느 노드에서도 핑 테스트를 수행할 수 있다. 본 발명은 워커 노드 측에서도 핑 테스트를 수행하여 관리 노드측에 머신 러닝의 진행이 준비됨을 알릴 수 있다. 하지만 태스크를 할당하는 마스터 노드나 세션 노드에서 핑 테스트를 수행하는 것이 관리 측면에 서 유리한 점이 있다. 따라서, 마스터 노드나 세션 노드(이하, '마스터 노드'라 함)에서 핑 테스트를 사용함으로써, 각 노드 에서 여러 가지 이유로 문제가 발생하여 플랫폼에서 역할을 하지 못하는 경우를 판단하고 이에 즉각적으로 대응 하게 된다. 예컨대, 플랫폼 내부 동작 중 과부하로 인한 노드 셧다운, 하드웨어적 요인으로 인한 셧다운, 네트워크 오류로 인한 인식 불가 등의 이유로 해당 노드가 더 이상 작업을 진행하지 못하는 상황을 인지하기 위해 네트워크 핑을 사용할 수 있다. 마스터 노드는 플랫폼 내의 각 노드에 네트워크 핑을 전달하고 수신받은 핑으로 노드의 활성 여부를 판단한 다. 만약 핑 송수신 중 특정 노드가 일정 시간 이상 반응하지 않으면 해당 노드는 장애가 발생하여 더 이상 노 드의 역할을 하지 못하는 것으로 판단한다. 특정 노드에서 장애가 발생하면 마스터 노드는 사용자에게 장애 발생 여부를 전달하고 해당 노드의 응답을 기다린다. 또한 장애 발생 후 일정 시간 내에 노드가 재연결되어 응답이 이루어지면 해당 노드의 작업을 재개한 다. 반면, 일정 시간 내에 노드가 재연결 되지 않으면 해당 노드는 더 이상 플랫폼 내에서 노드의 역할을 하지 못하 는 것으로 판단한다. 이러한 경우 플랫폼 DB(DB-I)에 저장된 머신 러닝 태스크의 작업 정보를 바탕으로 머신 러 닝 태스크를 다른 워커 노드에 할당한다. 세션 노드의 경우 새로운 세션 노드를 생성하고 플랫폼 DB(DB-I)에 저장된 기존 세션 노드의 정보 를 바탕으로 새로운 세션 노드의 정보를 갱신한다. 이후 기존 세션 노드에서 관리하던 워커 노드들 을 새로운 세션 노드에 할당하여 관리한다. 해당 작업 이후 장애가 발생한 노드가 재연결되면 워커 노드의 경우에는 진행 중이던 작업을 초기화하고 세 션 노드에 재할당한다. 세션 노드의 경우에는 정보를 초기화하고 새로운 세션 노드가 생성되어 할 당이 필요할 때까지 대기한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 방법에 대해 설명한다. 다만, 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 방법은 바람직한 실시예로써 위에서 설명한 플랫폼 시 스템상에서 구현된다. 따라서, 이하에서는 가급적 중복적인 설명은 생략한다. 도 3 및 도 4와 같이, 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 방법은 정보 제공 단계(S10), 자원 산 출 단계(S20), 태스크 등록 단계(S30), 노드 선택 단계(S40), 실행 명령 단계(S50) 및 머신 러닝 단계(S60)를 포함한다. 나아가 바람직한 다른 실시예로써 일정 기간마다 주기적으로 핑 테스트를 수행하는 상태 검색 단계 및 플랫폼 초기 구동시 등에 부족한 데이터에 대해 선형 보간법을 적용하는 데이터 보간 단계(S1)를 더 포함한다. 여기서, 상기한 정보 제공 단계(S10)에서는 워커 노드에서 태스크에 대해 머신 러닝을 수행하되, 수행 중이 거나 수행을 마친 적어도 하나 이상의 태스크에 대한 정보를 제공한다. 워커 노드에서 제공되는 머신 러닝 태스크 정보는 워커 노드에서 태스크의 머신 러닝에 소요되는 컴퓨 팅 자원 정보를 의미하는 것으로 그 상위 레이어인 세션 노드에 로그(Log) 형식으로 제공한다. 실시예로, 워커 노드는 CPU 사용량, 메모리 사용량, 디스크 사용량, GPU 플롭(Graphic Process Unit Flops), 머신 러닝 태스크의 총 에폭(epoch) 및 머신 러닝 총 수행 시간을 상기 컴퓨팅 자원 정보로 제공한다. 따라서, 새로 입력된 태스크의 예측을 위해 필요한 컴퓨팅 자원을 예측시 CPU 사용량, 메모리 사용량 및 디스크 사용량은 '컴퓨팅 비용' 산출에 이용된다. 총 에폭과 총 수행 시간은 에폭당 '수행 시간'의 산출에 이용된다. 다음, 자원 산출 단계(S20)에서는 세션 노드에서 위와 같이 워커 노드로부터 제공된 태스크 정보를 분 석하고, 태스크별로 머신 러닝에 소요되는 컴퓨팅 자원을 산출한다. 즉, 세션 노드는 컴퓨팅 자원에 대한 정보를 미리 산출하고, 이를 근거로 후속의 새로운 머신 러닝을 수행 할 태스크에 사용될 것으로 예측되는 컴퓨팅 자원을 예측한다. 이를 기반으로 후속 단계에서 워커 노드를 결정할 수 있다. 구체적으로 세션 노드는 워커 노드로부터 제공된 컴퓨팅 자원을 분석하여 머신 러닝 태스크의 에폭당 컴퓨팅 비용 및 수행 시간을 산출하여 새로 입력된 태스크에서 소요되는 컴퓨팅 자원을 예측한다. 다음, 태스크 등록 단계(S30)에서는 외부 입력 모듈을 통해 머신 러닝이 수행되는 새로운 태스크를 입력받 아 등록한다. 예컨대, 사용자가 명령한 머신 러닝 태스크가 새로 입력되며, 입력된 태스크는 마스터 노드에 의해 플랫폼 DB(DB-I)에 등록된다. 마스터 노드에 의해 등록된 머신 러닝 태스크는 프레임워크 구조에 따라 적합한 것으로 판단되는 세션 노드 에 할당된다. 세션 노드에서는 아래와 같이 컴퓨팅 자원을 예측하여 머신 러닝을 수행할 워커 노드(2 0)를 결정한다. 다음, 노드 선택 단계(S40)에서는 세션 노드에서 미리 산출된 태스크의 컴퓨팅 자원을 기반으로 새로 입력 된 태스크의 컴퓨팅 자원을 예측하고, 예측 결과에 따라 새로 입력된 태스크가 할당되는 워커 노드를 선택 한다. 따라서, 머신 러닝을 위한 통합 원격 실행 플랫폼에서 워커 노드에 머신 러닝 태스크를 할당할 때 워커 노 드 자체의 성능뿐만 아니라 머신 러닝 태스크에 필요한 컴퓨팅 자원까지 고려하여 최적의 노드를 선택하게 된다. 구체적으로, 노드 선택 단계(S40)에서 세션 노드는 컴퓨팅 비용의 산출을 위해 각 에폭당 CPU 사용량, 메모 리 사용량, 디스크 사용량 및 GPU 플롭을 참조한다. 이를 통해 진행된 모든 에폭에서의 CPU 사용량, 메모리 사 용량, 디스크 사용량 각각에 대한 평균값을 계산한다. 이를 통해 컴퓨팅 비용이 결정된다. 또한, 세션 노드는 수행 시간의 산출을 위해 머신 러닝 태스크의 총 에폭, 머신 러닝 총 수행 시간 및 GPU 플롭을 참조한다. 머신 러닝 태스크의 총 에폭 및 머신 러닝 총 수행 시간으로 에폭당 수행 시간을 산출하는데, 에폭당 수행 시간은 총 수행 시간을 총 에폭의 수로 나누어 산출될 수 있다. 따라서, 새로 입력되어 머신 러닝을 위한 워커 노드의 할당이 필요한 태스크에 대해, 머신 러닝 수행시 필 요한 컴퓨팅 자원을 예측하고, 그 예측된 컴퓨팅 자원을 만족하는 워커 노드에 태스크를 할당하게 된다. 또한, 세션 노드는 새로 입력된 태스크에 대해 머신 러닝을 수행하는데 소요된 컴퓨팅 자원을 추가하여, 차 후의 예측에 이용되는 컴퓨팅 자원 기록을 갱신함으로써 예측 결과를 반영하는 과정을 반복, 연속하여 점차 신 뢰성을 높일 수 있게 된다. 다음, 실행 명령 단계(S50)에서는 마스터 노드에서 외부 입력 모듈을 통해 새로 입력된 태스크에 대한 머신 러닝 수행 명령을 전달한다. 수행 명령은 일 예로 마스터 노드에서 세션 노드로, 상기 세션 노드 에서 워커 노드로 전달된다. 이와 같이 사용자로부터 머신 러닝 실행 명령이 전달되면 머신 러닝 단계(S60)에서는 워커 노드에서 머신 러닝 수행 명령을 입력받아 새로 입력된 태스크에 대한 머신 러닝을 수행한다. 머신 러닝의 수행을 위해 워커 노드는 일 예로 '태스크 실행기'를 통해 머신 러닝 수행환경을 세팅하고 머 신 러닝 데이터셋을 외부 네트워크 저장소(DB-O)로부터 다운로드 받아 머신 러닝을 수행한다.한편, 상태 검색 단계(미도시)에서는 마스터 노드 및 세션 노드 중 어느 하나 이상에서, 워커 노드(2 0)와 같은 다른 노드에 대해 네트워크 핑 테스트(ping test)를 수행하여, 태스크의 할당이 가능한 노드를 분석 한다. 이와 같이 핑 테스트를 진행하는 상태 검색 단계는 플랫폼이 구동되기 이전은 물론 플랫폼이 구동되는 중에도 실행 가능하다. 따라서, 정보 제공 단계(S10), 자원 산출 단계(S20), 태스크 등록 단계(S30), 노드 선택 단계(S40), 실행 명령 단계(S50) 및 머신 러닝 단계(S60) 어디에서도 가능하며 각 단계들의 진행 전에도 가능하다. 다음, 데이터 보간 단계(S1)에서는 머신 러닝이 수행된 태스크에 대한 정보가 예측 신뢰도를 획득하는 수준으로 축적되었는지 판단(S1a)하고, 판단결과 충분히 축적되지 않은 것으로 판단된 경우 상술한 초기 구동 모듈에서 머신 러닝이 수행된 태스크에 대한 정보에 선형 보간법을 적용한다. 플랫폼 구동 초기나 자주 사용되지 않는 GPU 플롭의 경우에는 머신 러닝 태스크에 대한 정보가 충분히 축적되지 않아서 평균값 등을 이용하여 새로 입력된 태스크에 대한 예측이 무의미하거나 산출결과의 신뢰성이 낮다. 따라서, 초기 구동 모듈은 이미 머신 러닝이 수행된 태스크에 대한 정보에 선형 보간법을 적용하고, 선형 보간 법으로 예상한 태스크에 대한 정보로 새로 입력된 태스크의 컴퓨팅 자원을 예측하기 위한 태스크 정보를 생성한 다. 이와 같이 본 발명은 기존 머신 러닝을 위한 통합 원격 학습 실행 관리 플랫폼 구조에서 플랫폼의 성능 향상을 위해 워커 노드가 이전에 실행한 기계학습 태스크의 정보를 로그 형태로 저장한다. 또한, 이를 통해 다음에 수행될 기계학습 태스크의 정보를 예측하여 보다 효율적인 기계학습 태스크의 분배를 수행한다. 또한 네트워크 상황을 주기적으로 확인하여 플랫폼의 장애 상황을 유연하게 대응할 수 있게 한다. 이상, 본 발명의 특정 실시예에 대하여 상술하였다. 그러나, 본 발명의 사상 및 범위는 이러한 특정 실시예에 한정되는 것이 아니라, 본 발명의 요지를 변경하지 않는 범위 내에서 다양하게 수정 및 변형 가능하다는 것을 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 이해할 것이다. 따라서, 이상에서 기술한 실시예들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주 를 완전하게 알려주기 위해 제공되는 것이므로, 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 하며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다."}
{"patent_id": "10-2020-0033179", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템의 전체 구성도이다. 도 2는 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 플랫폼 시스템의 연결 상태도이다.도 3은 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 방법을 나타낸 흐름도이다. 도 4는 본 발명에 따른 학습에 의한 머신 러닝 실행 관리 방법을 나타낸 구체적인 실시예이다."}
