{"patent_id": "10-2023-0097799", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0017035", "출원번호": "10-2023-0097799", "발명의 명칭": "현실 객체를 입력 도구로 이용하는 방법 및 이를 수행하는 전자 장치", "출원인": "삼성전자주식회사", "발명자": "고재우"}}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 이미지를 획득하는 카메라(210);적어도 하나의 인스트럭션을 저장하는 메모리(260); 및상기 메모리에 저장된 상기 적어도 하나의 인스트럭션을 실행하는 적어도 하나의 프로세서(250);를 포함하되,상기 적어도 하나의 프로세서(250)는:상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하고,상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하고,상기 식별된 기 등록된 기능을 수행하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 프로세서(250)는:상기 획득된 이미지로부터 상기 현실 객체를 검출하고,상기 검출된 현실 객체를 복수의 부위들로 분할하고,상기 복수의 부위들 중 상기 사용자의 손에 의해 폐색된 적어도 하나의 부위를 검출하고,상기 폐색된 적어도 하나의 부위에 기초하여 상기 기 등록된 기능을 식별하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 및 제2항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(250)는:상기 획득된 이미지로부터 상기 현실 객체를 검출하고,상기 검출된 현실 객체를 복수의 부위들로 분할하고,상기 분할 결과에 기초하여 상기 사용자의 손이 상기 현실 객체를 파지하는 위치를 결정하고,상기 결정된 위치에 기초하여 상기 기 등록된 기능을 식별하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 및 제3항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(250)는:상기 복수의 부위들 중 어느 부위를 향하여 상기 사용자의 손이 상기 현실 객체를 파지하는지를 나타내는 파지방향을 결정하고,상기 결정된 파지 방향에 기초하여 상기 기 등록된 기능을 식별하는, 전자 장치(200).공개특허 10-2025-0017035-3-청구항 5 제1항 내지 제4항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(250)는:상기 획득된 이미지로부터 상기 현실 객체를 검출하고,상기 검출된 현실 객체를 복수의 부위들로 분할하고,상기 사용자의 손이 상기 복수의 부위들 중 적어도 하나의 부위를 터치하는 동작을 인식하고,상기 인식된 동작에 기초하여 상기 기 등록된 기능을 식별하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(250)는:상기 획득된 이미지에 기초하여 상기 현실 객체의 움직임을 추적하고,상기 추적된 움직임에 기초하여 가상 객체를 생성하거나 삭제하는 기능을 수행하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 적어도 하나의 프로세서(250)는:상기 획득된 이미지로부터 상기 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나를 인식하고,상기 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나에 기초하여 상기 가상 객체의 색상 및 크기 중적어도 하나를 결정하고,상기 결정된 색상 및 크기 중 적어도 하나를 갖는 상기 가상 객체를 생성하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항 및 제7항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(250)는:상기 획득된 이미지로부터 상기 현실 객체가 가리키는 대상 객체를 인식하고,상기 대상 객체의 색상, 형태, 및 형상 중 적어도 하나에 기초하여 상기 가상 객체의 색상, 형태, 및 형상 중적어도 하나를 결정하고,상기 결정된 상기 색상, 형태, 및 형상 중 적어도 하나를 갖는 상기 가상 객체를 생성하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항 내지 제8항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(250)는: 상기 가상 객체에 대응하는 가상 이미지를 입력으로 하는, 인공지능 모델을 이용하여 상기 가상 객체를 분류하고,공개특허 10-2025-0017035-4-상기 분류 결과에 기 매핑된 색상을 상기 가상 객체의 색상으로 결정하고,상기 결정된 색상을 갖는 상기 가상 객체를 생성하는, 전자 장치(200)."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서,상기 기 등록된 기능은, 상기 이미지로부터 상기 현실 객체를 인식하고, 상기 인식된 현실 객체를 상기 입력 도구로 등록하고, 상기 등록된 현실 객체와 상기 사용자의 손과의 인터랙션을 기 정의된 기능과 매핑함으로써 등록되는, 전자 장치."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "현실 객체를 전자 장치의 입력 도구로 이용하는 방법에 있어서,현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 이미지를 획득하는 단계(S310);상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하는 단계(S320);상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하는 단계(S330); 및상기 식별된 기 등록된 기능을 수행하는 단계(S340)를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하는 단계(S320)는:상기 획득된 이미지로부터 상기 현실 객체를 검출하는 단계;상기 검출된 현실 객체를 복수의 부위들로 분할하는 단계; 및상기 복수의 부위들 중 상기 사용자의 손에 의해 폐색된 적어도 하나의 부위를 검출하는 단계를 포함하고,상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하는 단계(S330)는:상기 폐색된 적어도 하나의 부위에 기초하여 상기 기 등록된 기능을 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항 및 제12항 중 어느 한 항에 있어서,상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하는 단계(S320)는:상기 획득된 이미지로부터 상기 현실 객체를 검출하는 단계;상기 검출된 현실 객체를 복수의 부위들로 분할하는 단계; 및상기 분할 결과에 기초하여 상기 사용자의 손이 상기 현실 객체를 파지하는 위치를 결정하는 단계를 포함하고,상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하는 단계(S330)는:상기 결정된 위치에 기초하여 상기 기 등록된 기능을 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2025-0017035-5-제12항 및 제13항 중 어느 한 항에 있어서,상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하는 단계(S320)는:상기 복수의 부위들 중 어느 부위를 향하여 상기 사용자의 손이 상기 현실 객체를 파지하는지를 나타내는 파지방향을 결정하는 단계를 포함하고,상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하는 단계(S330)는:상기 결정된 파지 방향에 기초하여 상기 기 등록된 기능을 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제14항 중 어느 한 항에 있어서,상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하는 단계(S320)는:상기 획득된 이미지로부터 상기 현실 객체를 검출하는 단계;상기 검출된 현실 객체를 복수의 부위들로 분할하는 단계; 및상기 사용자의 손이 상기 복수의 부위들 중 적어도 하나의 부위를 터치하는 동작을 인식하는 단계를 포함하고,상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하는 단계(S330)는:상기 인식된 동작에 기초하여 상기 기 등록된 기능을 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항 내지 제15항 중 어느 한 항에 있어서,상기 식별된 기 등록된 기능을 수행하는 단계(S340)는:상기 획득된 이미지에 기초하여 상기 현실 객체의 움직임을 추적하는 단계(S1010; S1110); 및상기 추적된 움직임에 기초하여 가상 객체를 생성하거나 삭제하는 기능을 수행하는 단계(S1020; S1120)를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 식별된 기 등록된 기능을 수행하는 단계(S340)는:상기 획득된 이미지로부터 상기 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나를 인식하는 단계(S1130);상기 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나에 기초하여 상기 가상 객체의 색상 및 크기 중적어도 하나를 결정하는 단계(S1140); 및상기 결정된 색상 및 크기 중 적어도 하나를 갖는 상기 가상 객체를 생성하는 단계(S1150)를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항 및 제17항 중 어느 한 항에 있어서,상기 추적된 움직임에 기초하여 가상 객체를 생성하거나 삭제하는 기능을 수행하는 단계는:상기 획득된 이미지로부터 상기 현실 객체가 가리키는 대상 객체를 인식하는 단계;공개특허 10-2025-0017035-6-상기 대상 객체의 색상, 형태, 및 형상 중 적어도 하나에 기초하여 상기 가상 객체의 색상, 형태, 및 형상 중적어도 하나를 결정하는 단계;상기 결정된 상기 색상, 형태, 및 형상 중 적어도 하나를 갖는 상기 가상 객체를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항 내지 제18항 중 어느 한 항에 있어서,상기 추적된 움직임에 기초하여 가상 객체를 생성하거나 삭제하는 기능을 수행하는 단계는: 상기 가상 객체에 대응하는 가상 이미지를 입력으로 하는, 인공지능 모델을 이용하여 상기 가상 객체를 분류하는 단계;상기 분류 결과에 기 매핑된 색상을 상기 가상 객체의 색상으로 결정하는 단계; 및상기 결정된 색상을 갖는 상기 가상 객체를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0097799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항 내지 제19항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0097799", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "현실 객체를 입력 도구로 이용하는 방법 및 이를 수행하는 전자 장치가 제공될 수 있다. 전자 장치는 현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 이미지를 획득하는 카메라, 적어도 하나의 인스트럭션을 저장하는 메 모리, 메모리에 저장된 적어도 하나의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함하고, 적어도 하나 의 프로세서는 획득된 이미지로부터 사용자의 손과 인터랙션하는 현실 객체를 인식하고, 인식된 현실 객체를 입 력 도구로 사용하는 기 등록된 기능을 식별하고, 식별된 기 등록된 기능을 수행할 수 있다."}
{"patent_id": "10-2023-0097799", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 현실(real-world) 객체를 입력 도구로 이용하는 전자 장치 및 방법에 관한 것이다. 좀 더 상세하게는, 본 개시는 전자 장치와 통신하지 않는 현실 객체를 검출하고, 검출 결과에 따라 기 결정된 기능을 수행하는 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0097799", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(Augmented Reality)은 현실 세계의 물리적 환경 공간이나 현실 객체(real world object) 상에 가상 이미지를 오버레이(overlay)하여 함께 보여주는 기술이며, 가상 현실(Virtual Reality)은 가상적인 환경 내에서 실제 존재하지 않는 가상 객체와 상호작용하거나 가상 객체를 독립적으로 보여주는 기술이다. 최근에는 증강 현 실 기술 및 가상 현실 기술을 활용한 증강 현실 디바이스(예를 들어, 스마트 글래스(Smart Glass)) 또는 가상 현실 디바이스가 정보 검색, 길 안내, 카메라 촬영, 게임과 같이 일상 생활에서 유용하게 사용되고 있다. 증강 현실 디바이스 또는 가상 현실 디바이스는 특성 상 터치 조작이 불가능하므로, 서비스를 제공하기 위해서 는 입력 수단으로써 사용자의 손의 제스처 또는 페어링된 전자 기기를 통한 신호 송수신이 입력 인터페이스로서 활용되고 있다."}
{"patent_id": "10-2023-0097799", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 있어서, 전자 장치가 제공될 수 있다. 전자 장치는 현실 공간 내의 현실 객체 및 사용자 의 손을 촬영하여 이미지를 획득하는 카메라를 포함할 수 있다. 전자 장치는 적어도 하나의 인스트럭션을 저장 하는 메모리를 포함할 수 있다. 전자 장치는 상기 메모리에 저장된 상기 적어도 하나의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 상기 획득된 이미지로부터 상기 사 용자의 손과 인터랙션하는 상기 현실 객체를 인식할 수 있다. 상기 적어도 하나의 프로세서는 상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별할 수 있다. 상기 적어도 하나의 프로세서는 상기 식별된기 등록된 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체를 전자 장치의 입력 도구로 이용하는 방법이 제공될 수 있다. 방법은 현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 이미지를 획득하는 단계를 포함할 수 있다. 방법은 상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하는 단계를 포함할 수 있다. 방 법은 상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하는 단계를 포함할 수 있다. 방법 은 상기 식별된 기 등록된 기능을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체를 전자 장치의 입력 도구로 이용하는 방법을 컴퓨터에서 수행하기 위 한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체가 제공될 수 있다. 본 개시의 일 실시예에 있어서, 본 개시의 일 실시예에 있어서, 전자 장치가 제공될 수 있다. 전자 장치는 현실 공간 내의 현실 객체를 촬영하여 이미지를 획득하는 카메라를 포함할 수 있다. 전자 장치는 적어도 하나의 인스 트럭션을 저장하는 메모리를 포함할 수 있다. 전자 장치는 상기 메모리에 저장된 상기 적어도 하나의 인스트럭 션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 상기 획득된 이미지 로부터 상기 현실 객체를 인식할 수 있다. 상기 적어도 하나의 프로세서는 상기 인식된 현실 객체를 입력 도구 로 등록할 수 있다. 상기 적어도 하나의 프로세서는 상기 등록된 현실 객체와 사용자의 손과의 인터랙션을 기 정의된 기능과 매핑할 수 있다."}
{"patent_id": "10-2023-0097799", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도 록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시 스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수 행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 또한, 본 개시에서 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존 재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것 이다. 본 개시에서, '증강 현실(Augmented Reality)'은 현실의 물리적 환경 공간 내에 가상 객체(또는 가상 이미지)를 함께 보여주거나 현실 객체와 가상 객체(또는 가상 이미지)를 함께 보여주는 것을 의미한다. 본 개시에서, '가상 현실(Virtual Reality)'은 가상적인 환경 내에서 실제 존재하지 않는 가상 객체(또는 가상 이미지)와 상호작용하거나 가상 객체(또는 가상 이미지)를 독립적으로 보여주는 것을 의미한다. 본 개시에서, '증강 현실 디바이스' 또는 '가상 현실 디바이스'는 증강 현실 또는 가상 현실을 표현할 수 있는 장치로서, 예를 들어, 사용자가 안면부(顔面部)에 착용하는 안경 형상의 증강 현실 글래스(Augmented Reality Glasses) 뿐만 아니라, 두부(頭部)에 착용하는 헤드 마운트 디스플레이 장치 (HMD : Head Mounted Display Apparatus)나, 증강 현실 헬멧(Augmented Reality Helmet) 등일 수 있다. 본 개시에서, '인공지능(Artificial Intelligence)'과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로 세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP,DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저 장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 본 개시에서, '인공지능 모델'은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망 모델은 심층 신경 망(DNN: Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크(Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시에서, '객체 인식'은 이미지를 인공지능 모델에 입력하고, 인공지능 모델을 이용하는 추론을 통해 입력 된 이미지로부터 객체를 검출(detection)하거나, 객체를 추적(tracking)하거나, 객체를 특정 카테고리로 분류 (classification)하거나, 또는 객체를 분할(segmentation)하는 이미지 신호 처리(image signal processing)를 의미한다. 본 개시의 일 실시예에 있어서, 객체 인식은 인공지능 모델을 이용하여, 카메라를 통해 촬영된 이미 지로부터 객체를 검출하고, 객체를 분할하고, 객체를 추적하고, 객체에 포함된 복수의 특징점(예를 들어, 관절 들)을 위치 정보를 획득하는, 이미지 프로세싱을 의미할 수 있다. 본 개시에서, '객체 검출(Object Detection)'은 인공지능 모델을 이용하여 이미지나 동영상에서 특정한 객체의 위치와 경계를 식별하고, 해당 객체를 다른 배경과 구분하는 작업을 의미한다. 본 개시에서, '객체 추적(Object Tracking)'은 인공지능 모델을 이용하여 동영상에서 특정 객체의 움직임을 지 속적으로 감지하고, 그 객체를 시간에 따라 식별하며 추적하는 작업을 의미한다. 본 개시에서, '객체 분할(Object Segmentation)'은 인공지능 모델을 이용하여 이미지나 동영상에서 픽셀 수준에 서 복수의 객체들(또는 하나의 객체의 복수의 부위들)을 구분하고, 각 객체(또는 각 부위)의 경계를 추출하는 작업을 의미한다. 본 개시에서, '객체 분류(Object Classification)'는 인공지능 모델을 이용하여 이미지나 비디오에서 객체의 종 류 또는 카테고리를 식별하고, 해당 객체를 사전 정의된 클래스 또는 범주로 분류하는 작업을 의미한다. 본 개시에서, '객체 자세 추정(Object Pose Estimation)'은 인공지능 모델을 이용하여 이미지나 동영상에서 객 체의 위치와 동작에 대한 자세 정보를 추정하는 작업을 의미한다. 예를 들어, '객체 자세 추정(Object Pose Estimation)'은 특정 객체의 골격, 또는 특징점(keypoint)을 식별하여 객체의 자세, 방향, 관절 등의 동작을 추 론하고 추정하는 작업을 의미할 수 있다. 본 개시에서, '관절(joint)'은 뼈와 뼈가 서로 연결되는 인체의 부분 으로서, 손가락, 손목, 손바닥 등 손 뿐만 아니라, 목, 팔, 어깨 등 상체에 포함되는 하나 이상의 부위를 나타 낸다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다.이하에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1은 본 개시의 일 실시예에 따른 현실 객체를 전자 장치의 입력 도구로 이용하는 동작을 설명하기 위한 개념 도이다. 도 1을 참조하면, 전자 장치는 카메라를 포함하는 장치일 수 있다. 그러나, 본 개시는 이에 제한되지 않으 며, 카메라의 기능은 외부 장치에 의해 수행될 수 있다. 전자 장치는 카메라를 통해 현실 객체를 포 함하는 적어도 하나의 이미지 또는 동영상을 획득하고, 현실 객체를 전자 장치의 입력 도구로 이용하 고, 현실 객체를 이용하여 미리 설정된 기능을 수행하는 장치일 수 있다. 예를 들어, 전자 장치는 증 강 현실 디바이스, 가상 현실 디바이스, 스마트 TV, 스마트 폰, 태블릿 PC, 랩탑 PC, 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 도 1에는 전자 장치가 증강 현실 디바이스 또는 가상 현실 디바이스로 도시되 었으나, 이에 한정되는 것은 아니다. 이하에서, 설명의 편의를 위해, 전자 장치가 증강 현실 디바이스 또 는 가상 현실 디바이스인 것을 가정하여 설명한다. 전자 장치의 구성 요소에 대해서는 도 2에서 상세하게 설명하기로 한다. 본 개시의 일 실시예에 있어서, 전자 장치의 카메라는 현실 공간 내의 현실 객체 및 사용자의 손을 촬영하 여 적어도 하나의 이미지 또는 동영상을 획득할 수 있다. 전자 장치는 객체 인식을 통해 현실 객체를 검출할 수 있다. 전자 장치는 현실 객체에 대응하는 검출 결과에 기초하여 미리 설정된 기능을 수행 할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체는 전자 장치와 통신하거나 페어링하지 않는 현실에 존재하 는 모든 물리적 객체를 포함할 수 있다. 현실 객체는 전자 장치와의 통신 및 연결에 관련된 기능을 갖지 않을 수 있다. 예를 들어, 현실 객체는 전기적 신호를 송수신하는 기능을 갖지 않을 수 있다. 예를 들어, 현실 객체는 전자 장치와의 데이터 교환 또는 연결을 위한 프로토콜을 지원하지 않을 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체는 전자 장치와 통신할 수 있으나, 본 개시의 일 실시예에 따른 방법을 수행하는 과정에서 현실 객체는 전자 장치와의 데이터 교환을 수행하지 않을 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체는 다양한 형태와 크기를 가지는 물리적 사물들을 포괄하는 개념 이다. 예를 들어, 현실 객체는 사용자가 손으로 잡을 수 있는 크기의 물체(예컨대, 컵, 용기, 컵홀더, 펜, 연필, 보드마카, 망치, 드라이버, 톱, 드릴, 과일, 곡물, 시계, 목걸이, 지갑, 안경, 스포츠용품, 책, 장난감, 전자 제품, 가구 등)일 수 있으나, 본 개시는 이에 제한되지 않는다. 본 개시의 일 실시예에 있어서, 전자 장치는 획득된 이미지로부터 사용자의 손과 인터랙션하는 현실 객체 를 인식할 수 있다. 예를 들어, 사용자의 손과 현실 객체 간의 인터랙션은, 사용자의 손이 현실 객체를 파지하 거나, 잡거나, 터치하거나, 또는 움직이는 상황을 나타내거나, 사용자의 손이 현실 객체와 가까워지거나, 또는 멀어지는 상황을 나타낼 수 있으나, 본 개시는 이에 한정되지 않는다. 본 개시의 일 실시예에 있어서, 전자 장치는 동영상 또는 적어도 하나의 이미지로부터 현실 객체 및 사용자의 손을 검출할 수 있다. 예를 들어, 전자 장치는 객체 검출 모델을 이용하여 현실 객체 및 사 용자의 손을 검출할 수 있다. 예를 들어, 전자 장치는 검출된 사용자의 손과 검출된 현실 객체에 기초 하여 사용자의 손과 인터랙션하는 현실 객체를 인식할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체 또는 현실 객체의 적어도 일부를 추적할 수 있다. 예를 들어, 전자 장치는 객체 추적 모델을 이용하여 현실 객체의 적어도 일부를 추적할 수 있다. 예를 들어, 전자 장치는 현실 객체(예컨대, 연필)의 일측 부분(예컨대, 연필 팁 부분)을 추적 할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 추적된 현실 객체의 움직임에 기초하여 가상 객체 를 생성할 수 있다. 예를 들어, 전자 장치는 현실 객체(예컨대, 연필)의 일측 부분(예컨대, 연필 팁 부분)의 움직임 및 위치에 기초하여 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 디스플레이를 포함할 수 있다. 전자 장치는 가상 객체 를 디스플레이에 표시할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 이미지에 가상 객체를 합성할 수 있다. 예를 들어, 가상 객체는 현실 객체의 검출 결과 및 추적 결과에 기초하여 생성될 수 있다. 전자 장치(10 0)는 합성된 이미지를 디스플레이에 표시할 수 있다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 보여주는 블록도이다. 전자 장치의 구 성, 동작, 및 기능은 도 1의 전자 장치의 구성, 동작, 및 기능에 대응할 수 있다. 설명의 편의를 위해, 도 1에서 설명한 내용과 중복되는 내용은 생략한다. 도 2를 참조하면, 본 개시의 일 실시예에 따른 전자 장치는 카메라, 센서, 통신 인터페이스 , 사용자 인터페이스, 프로세서, 및 메모리를 포함할 수 있다. 그러나, 도 2에 도시된 구 성요소가 필수 구성요소인 것은 아니며, 전자 장치는 구성요소를 생략하거나, 추가 구성요소를 더 포함할 수 있다. 예를 들어, 본 개시의 일 실시예에 따른 전자 장치에, 도 2에 도시된 바와 달리, 전자 장치(20 0)는 카메라 및 센서 중 적어도 하나가 생략될 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 휴대용 장치로 구현되고, 이 경우 전자 장치는 카메라 , 센서, 통신 인터페이스, 사용자 인터페이스, 프로세서, 및 메모리에 전원을 공급하는 배터리를 더 포함할 수 있다. 카메라는 현실 공간의 현실 객체(예컨대, 현실 객체(도 1, 110))를 촬영함으로써, 현실 객체에 관한 적어 도 하나의 이미지 또는 동영상을 획득할 수 있다. 본 개시의 일 실시예에 있어서, 카메라는 현실 객체를 파지하는 사용자의 손을 촬영하여, 사용자 손을 포함하는 2차원 이미지를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 카메라는 적어도 두 개의 카메라를 포함할 수 있다. 예를 들어, 카메라 는 제1 카메라 및 제2 카메라를 포함할 수 있다. 예를 들어, 제1 카메라는 좌안에 대응하고, 제2 카메라는 우안에 대응할 수 있으나, 본 개시는 이에 제한되지 않는다. 제1 카메라 및 제2 카메라는 시야(Field of View) 가 겹치는 영역에서 획득된 2차원 이미지와 카메라 간의 위치 관계에 기초하여 삼각측량법(triangulation)을 통 해 객체의 3차원 위치 좌표값을 획득하는 스테레오 카메라를 구성할 수 있다. 본 개시의 일 실시예에 있어서, 카메라는 가상 현실 디바이스 또는 증강 현실 디바이스에 장착될 수 있도 록 소형 폼 팩터(form factor)로 구현되고, 저전력을 소비하는 경량 RGB 카메라일 수 있다. 그러나, 이에 한정 되는 것은 아니며, 본 개시의 일 실시예에 있어서, 카메라는 깊이 추정 기능을 포함하는 RGB-depth 카메라, 스테레오 어안 카메라, 그레이스케일 카메라, 또는 적외선 카메라 등 공지의 모든 종류의 카메라로 구 현될 수 있다. 본 개시의 일 실시예에 있어서, 카메라는 렌즈 모듈, 이미지 센서, 및 이미지 프로세싱 모듈을 포함할 수 있다. 카메라는 이미지 센서(예를 들어, CMOS 또는 CCD)에 의해 현실 객체 및 사용자의 손에 관한 정지 이 미지(still image) 또는 동영상(video)을 획득할 수 있다. 동영상은 카메라를 통해 현실 객체 및 사용자의 손을 포함하는 현실 장면(또는 현실 공간)을 촬영함으로써 실시간으로 획득되는 복수의 이미지 프레임을 포함할 수 있다. 이미지 프로세싱 모듈은 이미지 센서를 통해 획득된 단일 이미지 프레임으로 구성된 정지 이미지 또는 복수의 이미지 프레임으로 구성된 동영상 데이터를 인코딩할 수 있다. 센서는 물리량을 계량하거나 감지함으로써, 계량 또는 감지된 정보를 전기 신호로 변환할 수 있다. 센서 는 변환된 전기 신호를 프로세서에 전달할 수 있다. 프로세서는 전기 신호를 프로세싱하여 센서 데이터를 생성할 수 있다. 예를 들어, 센서는 터치 입력을 위한 적어도 하나의 버튼, 마이크 센서, 제스처 센서, 자이로스코프, 자이로 센서, 기압 센서, 자기 센서, 자력계, 가속도 센서, 가속도계, 그립 센서, 근접 센 서, RGB 센서, 생체물리 센서, 온도 센서, 습도 센서, 조도 센서, 자외선 센서, 근전도 센서, 뇌파 센서, 심전 도 센서, 적외선 센서, 초음파 센서, 홍채 센서, 또는 지문 센서 중 적어도 하나를 포함할 수 있으나, 본 개시 는 이에 한정되지 않는다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체 및 사용자의 손에 대응하는 검출 결과에 기초하여 센서를 활성화할 수 있다. 전자 장치는 활성화된 센서를 이용하여 센서 데이터를 획득할 수 있 다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체의 형상, 형태, 색채, 재질, 및 기능 중 적어도 일부에 기초하여 센서 데이터를 변조할 수 있다. 통신 인터페이스는 전자 장치와 외부의 다른 전자 장치(미도시) 또는 서버(미도시) 사이의 유선 또는 무선 통신 채널의 수립 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 일 실시 예에 있어서, 통신인터페이스는 유선 또는 무선 통신을 통해 외부의 다른 전자 장치(미도시) 또는 서버(미도시)로부터 데이 터를 수신하거나 외부의 다른 전자 장치(미도시) 또는 서버(미도시)로 데이터를 송신할 수 있다. 본 개시의 일 실시예에 있어서, 통신 인터페이스는 무선 통신 모듈(예컨대, 셀룰러 통신 모듈, 근거리 무 선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예컨대, LAN(local area network) 통신 모듈, 또는 전력선 통신 모듈)을 포함할 수 있고, 그 중 어느 하나의 통신 모듈 을 이용하여 적어도 하나의 네트워크(예컨대, 근거리 통신 네트워크(예컨대, 블루투스, WiFi direct 또는 IrDA(infrared data association)) 또는 원거리 통신 네트워크(예컨대, 셀룰러 네트워크, 인터넷, 또는 컴퓨터 네트워크(예컨대, LAN 또는 WAN)))를 통하여 외부의 다른 전자 장치(미도시) 또는 서버(미도시)와 통신할 수 있 다. 사용자 인터페이스는 입력 인터페이스 및 출력 인터페이스를 포함할 수 있다. 입력 인터페이스는, 사용자로부터의 입력(이하에서, 사용자 입력)을 수신하기 위한 것이다. 입력 인터페이 스는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조 그 스위치 중 적어도 하나일 수 있으나, 이에 한정되는 것은 아니다. 본 개시의 일 실시예에 있어서, 입력 인터페이스는 마이크를 포함할 수 있다. 도 2에서 마이크 와 센서는 별개의 블록으로 도시되었으나, 센서는 마이크를 포함할 수 있다. 본 개시의 일 실시 예에 있어서, 마이크는 소리를 수신할 수 있다. 예를 들어, 마이크는 사용자 음성을 수신할 수 있다. 마이크는 사용자 음성을 전기적 신호인 오디오 신호로 변환할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체 및 사용자의 손에 대응하는 검출 결과에 기초하여 마이크를 활성화할 수 있다. 전자 장치는 활성화된 마이크를 이용하여 사용자 음성에 대응하는 오디오 신호를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체의 형상, 형태, 색 채, 재질, 및 기능 중 적어도 일부에 기초하여 오디오 신호를 변조할 수 있다. 출력 인터페이스는 오디오 신호 또는 비디오 신호의 출력을 위한 것으로, 예컨대 디스플레이 또는 스 피커 등을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 디스플레이를 통해서 이미지 또는 동영상을 표시할 수 있다. 예를 들어, 전자 장치는 디스플레이를 통해서 가상 객체를 포함하는 가상 이미지를 표시할 수 있다. 예를 들어, 전자 장치는 디스플레이를 통해서 현실 장면에 대응하는 이미지에 가상 객체가 합 성된 이미지를 표시할 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 발광 다이오드(LED, light- emitting diode), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나 를 포함할 수 있다. 그리고 전자 장치의 구현 형태에 따라 디스플레이를 2개 이상 포함할 수도 있다. 스피커는 통신 인터페이스로부터 수신되거나 메모리에 저장된 오디오 신호를 출력할 수 있다. 프로세서는 AP(application processor), CPU(central processing unit) 또는 GPU(graphic processing unit)와 같은 범용 프로세서와 소프트웨어의 조합을 통해 구현될 수도 있다. 전용 프로세서의 경우, 본 개시의 실시예를 구현하기 위한 메모리를 포함하거나, 외부 메모리를 이용하기 위한 메모리 처리부를 포함할 수 있다. 프로세서는 복수의 프로세서로 구성될 수도 있다. 이 경우, 전용 프로세서들의 조합으로 구현될 수도 있고, AP, CPU 또는 GPU와 같은 다수의 범용 프로세서들과 소프트웨어의 조합을 통해 구현될 수도 있다. 일 실시예에 있어서, 프로세서는, 인공지능(AI) 프로세서를 탑재할 수도 있다. 인공지능(AI) 프로세서는, 인공지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전자 장치에 탑재될 수도 있다. 예를 들어, 인공지능 프로세서는 적어도 하나의 인공지능 모델과 관련된 학습 및/또는 추론에 필요한 데 이터 처리를 수행할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하 나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델(예컨대, 심층 신경망 모델)에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델 의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 메모리는, 프로세서의 처리 및 제어를 위한 프로 그램을 저장할 수도 있고, 입/출력되는 데이터들을 저장할 수도 있다. 메모리는 적어도 하나의 인공지능 모델을 저장할 수도 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 전자 장치는 인터넷(internet)상에서 저장 기능을 수행하는 웹 스토리지(web storage) 또는 클라우드 서버를 운영할 수도 있 다. 본 개시의 일 실시예에 있어서, 메모리에는 프로세서에 의하여 처리되거나 처리될 예정인 데이터, 펌 웨어, 소프트웨어, 및 프로세스 코드 등이 저장될 수 있다. 본 개시의 일 실시예에 있어서, 메모리에는 객 체 인식 모듈, 객체 검출 모듈, 객체 추적 모듈, 객체 분류 모듈, 객체 분할 모듈, 객체 자세 추정 모듈, 가상 객체 관리 모듈, 및 기능 식별 모듈 중 적어도 하나에 대응되는 데 이터 및 프로그램 코드들이 저장될 수 있다. 본 개시의 일 실시예에 있어서, 객체 인식 모듈은 객체 검출 모듈, 객체 추적 모듈, 객체 분류 모듈, 객체 분할 모듈, 및 객체 자세 추정 모듈을 포함할 수 있다. 객체 인식 모듈은 이미 지 또는 동영상을 입력으로 하는 적어도 하나의 인공지능 모델을 이용하여, 이미지에 포함되는 객체에 대응하는 데이터를 출력할 수 있다. 본 개시의 일 실시예에 있어서, 객체 검출 모듈은 적어도 하나의 이미지를 입력으로 하는 인공지능 모델 (객체 검출 모델로도 지칭될 수 있음)을 이용하여 적어도 하나의 이미지에 포함되는 객체를 검출할 수 있다. 객 체 검출 모듈은 검출된 객체의 위치 정보와 경계 정보를 추정할 수 있다. 예를 들어, 객체 검출 모듈(26 2)은 현실 객체와 사용자의 손을 포함하는 이미지를 수신할 수 있다. 객체 검출 모듈은 이미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체와 사용자의 손 각각의 위치 정보와 경계 정보를 추정할 수 있다. 본 개시에서, '검출 결과'는 위치 정보와 경계 정보를 포함하는 값들을 포함할 수 있다. 예를 들어, 위치 정보는 이미지나 동영상 프레임에서 객체가 어디에 위치하는지를 나타낼 수 있다. 예를 들어, 경계 정보는 이미지나 동 영상 프레임에서 객체의 경계선이나 윤곽을 나타낼 수 있다. 본 개시의 일 실시예에 있어서, 객체 검출 모듈 은 검출 결과에 기초하여 사용자의 손과 인터랙션하는 현실 객체를 인식할 수 있다. 본 개시의 일 실시예에 있어서, 객체 추적 모듈은 적어도 하나의 이미지를 입력으로 하는 인공지능 모델 (객체 추적 모델로도 지칭될 수 있음)을 이용하여 동영상에 포함되는 객체(또는 객체의 부분)의 움직임을 추적 할 수 있다. 객체 추적 모듈은 객체의 연속적인 위치 정보와 움직임 패턴을 추정할 수 있다. 예를 들어, 객체 검출 모듈은 현실 객체를 포함하는 동영상 또는 연속된 이미지 시퀀스를 수신할 수 있다. 객체 검출 모듈은 동영상 또는 연속된 이미지 시퀀스를 입력으로 하는 인공지능 모델을 이용하여 현실 객체의 적어도 일부의 연속적인 위치 정보와 움직임 패턴을 추정할 수 있다. 본 개시에서, '추적 결과'는 연속적인 위치 정보 와 움직임 패턴을 포함하는 값들을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 객체 분류 모듈은 적어도 하나의 이미지를 입력으로 하는 인공지능 모델 (객체 분류 모델로도 지칭될 수 있음)을 이용하여 적어도 하나의 이미지에 포함되는 적어도 하나의 객체들을 미 리 정의한 클래스로 분류할 수 있다. 객체 분류 모듈은 객체의 클래스 레이블을 추정할 수 있다. 예를 들어, 객체 분류 모듈은 현실 객체를 포함하는 적어도 하나의 이미지를 수신할 수 있다. 객체 분류 모듈 은 적어도 하나의 이미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체를 미리 정해진 클래스로 분류할 수 있다. 본 개시의 일 실시예에 있어서, 객체 분할 모듈은 적어도 하나의 이미지를 입력으로 하는 인공지능 모델 (객체 분할 모델로도 지칭될 수 있음)을 이용하여 적어도 하나의 이미지에 포함되는 복수의 객체들 또는 하나의 객체의 복수의 부위들로 분할할 수 있다. 객체 분할 모듈은 복수의 객체들 또는 하나의 객체의 복수의 부 위들의 경계와 영역 정보를 추정할 수 있다. 예를 들어, 객체 분할 모듈은 현실 객체를 포함하는 적어도 하나의 이미지를 수신할 수 있다. 객체 분할 모듈은 적어도 하나의 이미지를 입력으로 하는 인공지능 모델 을 이용하여 현실 객체를 복수의 부위들로 분할할 수 있다. 본 개시의 일 실시예에 있어서, 객체 자세 추정 모듈은 적어도 하나의 이미지를 입력으로 하는 인공지능 모델(객체 자세 추정 모델로도 지칭될 수 있음)을 이용하여 적어도 하나의 이미지에 포함되는 객체의 위치, 방 향, 관절 등의 자세 정보를 추론할 수 있다. 객체 자세 추정 모듈은 객체의 특징점을 식별하고, 객체의 자 세, 동작, 및 관절의 움직임을 추론할 수 있다. 예를 들어, 객체 자세 추정 모듈은 현실 객체를 파지하는 사용자의 손을 포함하는 적어도 하나의 이미지를 수신할 수 있다. 객체 분할 모듈은 적어도 하나의 이미지 를 입력으로 하는 인공지능 모델을 이용하여 사용자의 손이 현실 객체를 파지하는 위치, 방향, 방식 등을 추론 할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체 관리 모듈은 가상 객체를 생성하거나, 삭제하는 기능을 수행할 수 있다. 가상 객체 관리 모듈은 전자 장치의 식별된 기능에 따라 가상 객체를 생성하거나, 삭제할 수 있다. 예를 들어, 제1 기능에서, 전자 장치는 현실 객체의 추적 결과에 따라 가상 객체를 생성할 수 있 다. 예를 들어, 제2 기능에서, 전자 장치는 현실 객체의 추적 결과에 따라 가상 객체를 삭제할 수 있다. 본 개시의 일 실시예에 있어서, 기능 식별 모듈은 객체 인식 모듈의 객체 인식 결과에 기초하여 현실 객체를 입력 도구로 이용하는 전자 장치의 기 등록된 기능을 식별할 수 있다. 예를 들어, 기 등록된 기능 은, 가상 객체를 생성하는 기능, 가상 객체를 삭제하는 기능, 가상 객체의 특성을 변경하는 기능 등을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 객체 인식 모듈, 객체 검출 모듈, 객체 추적 모듈, 객체 분류 모듈, 객체 분할 모듈, 객체 자세 추정 모듈, 가상 객체 관리 모듈, 및 기능 식별 모듈 중 적어도 하나의 기능 중 적어도 일부는 프로세서에 의해 실행될 수 있으나, 본 개시는 이제 한정 되지 않으며, 외부 서버(미도시)에 의해 실행될 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 증강 현실 디바이스 또는 가상 현실 디바이스일 수 있다. 일 반적으로, 증강 현실 디바이스 또는 가상 현실 디바이스는 사람의 안면에 착용하는 글래스 형태 또는 사람의 머 리에 착용하는 헤드 마운티드 디바이스로 구현되는 바, 휴대를 위하여 소형 폼 팩터로 설계된다. 따라서, 증강 현실 디바이스 또는 가상 현실 디바이스의 메모리의 저장 용량, 프로세서의 연산 처리 속도 등은 서 버(미도시)에 비하여 제한적일 수 있다. 따라서, 서버(미도시)는 대용량 데이터의 저장 및 대용량의 연산량이 필요한 동작을 수행한 이후, 통신 네트워크를 통하여 필요한 데이터(예를 들어, 검출 결과, 추적 결과 등)를 증 강 현실 디바이스에 전송할 수 있다. 이와 같은 방식으로, 증강 현실 디바이스 또는 가상 현실 디바이스는 대용 량의 메모리 및 빠른 연산 능력을 갖는 프로세서 없이도 서버(미도시)로부터 검출 결과 또는 추적 결과에 대응 하는 데이터(예컨대, 객체의 위치 정보와 경계 정보, 연속적인 위치 정보, 움직임 패턴 정보 등)를 수신하여 이 용함으로써, 이미지를 처리하는데 소요되는 프로세싱 타임(processing time)을 단축시키고, 실시간 객체 인식을 구현할 수 있다. 도 3은 본 개시의 일 실시예에 따른 현실 객체를 전자 장치의 입력 도구로 이용하는 방법을 보여주는 흐름도이 다. 도 1 및 2에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 3을 설 명한다. 도 3을 참조하면, 현실 객체를 전자 장치의 입력 도구로 이용하는 방법은 단계 S310 내지 S340을 포함할 수 있다. 일 실시 예에 있어서, 단계 S310 내지 S340은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시의 일 실시예에 따른 전자 장치가 현실 객체를 입력 도구로 이용하는 방법은 도 3에 도시된 바에 한정되지 않으며, 도 3에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 3에 도시되지않은 단계를 더 포함할 수도 있다. 단계 S310에서, 전자 장치는 현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 이미지를 획득할 수 있 다. 카메라는 현실 객체 및 사용자의 손을 포함하는 현실 공간을 촬영할 수 있다. 프로세서 또는 카 메라의 이미지 프로세싱 모듈은 촬영된 현실 장면에 기초하여 동영상을 생성할 수 있다. 단계 S320에서, 전자 장치는 획득된 이미지로부터 사용자의 손과 인터랙션하는 현실 객체를 인식할 수 있 다. 전자 장치는 인식 결과를 획득할 수 있다. 예를 들어, 인식 결과는 현실 객체 및 사용자의 손 각각의 위치 정보(예컨대, 바운딩 박스(bounding box) 등) 및 경계 정보(예컨대, 다각형, 점들의 집합, 또는 픽셀 마스 크 등) 중 적어도 하나를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 적어도 하나의 이 미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체 및 사용자의 손을 검출할 수 있다. 단계 S330에서, 전자 장치는 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별할 수 있다. 본 개시의 일 실시예에 있어서, 기 등록된 기능은 사용자 또는 제조사의 설정에 의해 미리 결정되어 메모리 에 저장될 수 있다. 본 개시의 일 실시예에 있어서, 기 등록된 기능은 가상 객체를 생성하거나 삭제하는 기능일 수 있다. 본 개시의 일 실시예에 있어서, 기 등록된 기능은 현실 객체의 특성(예컨대, 색상, 재질, 형태 등)에 따라 가상 객체의 성능 값을 결정하는 기능일 수 있다. 본 개시의 일 실시예에 있어서, 기 등록된 기능은 기 결정된 움직임에 따라 기 결정된 가상 객체를 생성하는 기능일 수 있다. 본 개시의 일 실시예에 있어서, 기 등록된 기능은 기 결정된 적어도 하나의 센서를 활성화하는 기능일 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 기 등록된 (미리 저장된) 현실 객체 또는 현실 객체와 사용자 의 손 간의 인터랙션을 검출한 것에 기초하여, 검출된 현실 객체에 매핑된 기 등록된 기능을 식별할 수 있다. 예를 들어, 전자 장치는 메모리 (또는 스토리지) 또는 외부 장치에 저장된 매핑 테이블에 액세스할 수 있다. 매핑 테이블은 검출 결과와 기능 간의 관계 정보를 포함할 수 있다. 예를 들어, 매핑 테이블은 현실 객체의 종류와 기능 간의 관계 정보, 현실 객체의 형태와 기능 간의 관계 정보, 사용자의 손과 현실 객체 간의 인터랙션과 기능 간의 관계 정보 등을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 매핑 테이블은 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 전자 장치는 매핑 테이블에 기초하여 기 등록된 기능을 식별할 수 있다. 단계 S340에서, 전자 장치는 식별된 기 등록된 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전 자 장치는 가상 객체를 생성하는 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치 는 미리 생성된 가상 객체를 삭제하는 기능을 수행할 수 있다. 도 4a 및 4b는 본 개시의 일 실시예에 따른 현실 객체를 이용하여 가상 객체를 생성하거나 삭제하는 동작을 설 명하기 위한 개념도이다. 도 1 내지 3에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2 를 참조하여, 도 4a 및 4b를 설명한다. 도 4a를 참조하면, 전자 장치는 이미지로부터 현실 객체 및 사용자의 손을 인식(또는 검출)할 수 있다. 전자 장치는 인식된 현실 객체의 전체 또는 적어도 일부의 움직임을 추적할 수 있다. 예를 들 어, 전자 장치는 현실 객체의 일측(예컨대, 연필의 팁 부분)의 움직임을 추적할 수 있다. 사용 자의 손의 움직임에 따라 현실 객체의 일측의 움직임이 발생할 수 있다. 예를 들어, 현실 객체 의 일측은 경로를 따라 움직일 수 있다. 본 개시의 일 실시예에 있어서, 추적의 대상이 되는 현실 객체의 부위는 미리 결정될 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체를 복수의 부위들로 분할할 수 있다. 예를 들어, 전자 장 치는 동영상을 입력으로 하는 인공지능 모델을 이용하여 현실 객체를 복수의 부위들로 분할할 수 있 다. 예를 들어, 도시된 바와 같이 현실 객체가 연필인 경우, 전자 장치는 흑연심이 배치되는 연필의 일측을 제1 부위로, 지우개가 배치되는 연필의 타측을 제2 부위로, 연필의 몸통 부위(예컨대, 연필의 일측으로 부터의 거리와 연필의 타측으로부터의 거리가 동일한 지점)을 제3 부위로 분할할 수 있다. 전자 장치는 추적된 움직임에 기초하여 가상 객체를 생성할 수 있다. 예를 들어, 전자 장치는 인식 결과에 기초하여 사용자의 손이 흑연심이 배치되는 연필의 일측을 향하여 위치함을 인식할 수 있 다. 전자 장치는 인식 결과에 기초하여 가상 객체를 생성하는 기능(또는 그리기 기능으로도 지칭될 수 있 음)을 수행할 수 있다. 전자 장치는 추적된 움직임에 기초하여 연필의 일측이 움직인 경로를 획 득할 수 있다. 전자 장치는 연필의 일측이 움직인 경로를 따라 가상 객체를 생성할 수있다. 본 개시의 일 실시예에 있어서, 가상 객체는 디스플레이에 표시될 수 있다. 도 4b를 참조하면, 전자 장치는 이미지로부터 현실 객체 및 사용자의 손을 인식(또는 검출)할 수 있다. 전자 장치는 인식된 현실 객체의 적어도 일부의 움직임을 추적할 수 있다. 예를 들어, 전자 장 치는 현실 객체의 타측(예컨대, 연필의 지우개 부분 또는 연필의 팁 부분으로부터의 거리가 가 장 먼 부분)의 움직임을 추적할 수 있다. 사용자의 손의 움직임에 따라 현실 객체의 타측의 움직 임이 발생할 수 있다. 예를 들어, 현실 객체의 타측은 경로를 따라 움직일 수 있다. 전자 장치는 추적된 움직임에 기초하여 가상 객체를 삭제할 수 있다. 예를 들어, 전자 장치는 인식 결과에 기초하여 사용자의 손이 지우개가 배치되는 연필의 타측을 향하여 위치함을 인식할 수 있 다. 전자 장치는 인식 결과에 기초하여 가상 객체를 삭제하는 기능(또는 지우기 기능으로도 지칭될 수 있 음)을 수행할 수 있다. 전자 장치는 추적된 움직임에 기초하여 연필의 타측이 움직인 경로를 획 득할 수 있다. 전자 장치는 연필의 타측이 움직인 경로를 따라 가상 객체를 삭제할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체 중 연필의 타측이 움직인 경로에 대응하는 부분 이 삭제되고, 나머지 부분만이 디스플레이에 표시될 수 있다. 도 5a 및 5b는 본 개시의 일 실시예에 따른 현실 객체를 이용하여 가상 객체를 생성하거나 삭제하는 동작을 설 명하기 위한 개념도이다. 도 1 내지 4b에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 4a 및 4b를 설명한다. 도 5a를 참조하면, 전자 장치는 이미지로부터 현실 객체 및 사용자의 손을 인식(또는 검출)할 수 있다. 전자 장치는 인식된 현실 객체의 전체 또는 적어도 일부의 움직임을 추적할 수 있다. 도 5a 및 5b에서 현실 객체는 종이 컵홀더인 것으로 도시되었으나, 현실 객체는 적어도 하나의 날카로운 모서 리(sharp edge) 또는 뾰족한 모서리(pointy edge)을 포함하는 임의의 객체일 수 있다. 예를 들어, 전자 장치 는 현실 객체의 모서리(예컨대, 종이 컵홀더의 모서리들 중 하나)의 움직임을 추적할 수 있다. 사용자의 손의 움직임에 따라 현실 객체의 모서리의 움직임이 발생할 수 있다. 예를 들어, 현실 객체의 모서리는 경로를 따라 움직일 수 있다. 전자 장치는 추적된 움직임에 기초하여 가상 객체를 생성할 수 있다. 예를 들어, 전자 장치는 인식 결과에 기초하여 사용자의 손이 종이 컵홀더의 모서리를 향하여 위치함을 인식할 수 있다. 전자 장치는 인식 결과에 기초하여 가상 객체를 생성하는 기능(또는 그리기 기능으로도 지칭될 수 있음)을 수행 할 수 있다. 전자 장치는 인식 결과에 기초하여 종이 컵홀더의 모서리가 움직인 경로를 획득할 수 있다. 전자 장치는 종이 컵홀더의 모서리가 움직인 경로를 따라 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체는 디스플레이에 표시될 수 있다. 도 5b를 참조하면, 전자 장치는 이미지로부터 현실 객체 및 사용자의 손을 인식(또는 검출)할 수 있다. 전자 장치는 인식된 현실 객체의 전체 또는 적어도 일부의 움직임을 추적할 수 있다. 예를 들 어, 전자 장치는 현실 객체의 전체 영역(예컨대, 종이 컵홀더를 바라보는 시야에서의 종이 컵홀 더의 전체 영역)의 움직임을 추적할 수 있다. 사용자의 손의 움직임에 따라 현실 객체의 전체 영역 의 움직임이 발생할 수 있다. 예를 들어, 현실 객체의 전체 영역은 경로를 따라 움직일 수 있다. 전자 장치는 추적된 움직임에 기초하여 가상 객체를 삭제할 수 있다. 예를 들어, 전자 장치는 인식 결과에 기초하여 사용자의 손에 현실 객체가 끼워진 형상을 인식할 수 있다. 전자 장치는 인식 결과에 기초하여 가상 객체를 삭제하는 기능(또는 지우기 기능으로도 지칭될 수 있음)을 수행할 수 있다. 전자 장치는 추적된 움직임에 기초하여 현실 객체의 전체 영역이 움직인 경로를 획득할 수 있다. 전자 장치는 현실 객체의 전체 영역이 움직인 경로를 따라 가상 객체를 삭제할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체 중 현실 객체의 전체 영역이 움직인 경로 에 대응하는 부분이 삭제되고, 나머지 부분만이 디스플레이에 표시될 수 있다. 도 4a 내지 5b를 참조하면, 본 개시의 일 실시예에 있어서, 현실 객체(410, 510)는 전자 장치의 입력 도구 로 기 등록(또는 저장)될 수 있다. 예를 들어, 전자 장치는 현실 객체(410, 510)의 특징을 추출할 수 있다. 예를 들어, 현실 객체(410, 510)의 특징은 현실 객체(410, 510)의 형상, 형태, 색상, 텍스처 중 적어도 하나를 포함할 수 있으며, 현실 객체(410, 510)를 고유하게 식별할 수 있는 임의의 특성일 수 있다. 본 개시의일 실시예에 있어서, 전자 장치는 적어도 하나의 이미지로부터 현실 객체(410, 510)를 검출할 수 있다. 전 자 장치는 검출된 현실 객체(410, 510)의 특징과 기 등록된 입력 도구의 특징을 비교할 수 있다. 예를 들 어, 전자 장치는 특징 간의 거리 측정, 유클리드 거리, 코사인 유사도 등을 이용하여 검출된 현실 객체 (410, 510)의 특징과 기 등록된 입력 도구의 특징을 비교할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체(410, 510)의 어떠한 부분을 추적할 것인지를 미리 등록할 수 있다. 예를 들어, 전자 장치는 현실 객체(410, 510)의 형태, 사용자의 손의 형태, 및 사용 자의 손과 현실 객체(410, 510)간의 인터랙션의 특징 (예컨대, 사용자의 손이 현실 객체(410, 510)를 파지하는 형태, 및 사용자의 손이 현실 객체(410, 510)를 파지하는 위치) 중 적어도 하나에 기초하여 현실 객체(410, 510)의 어떠한 부분을 추적할 것인지를 미리 등록할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체(410, 510)의 추적 결과에 따른 가상 객체(420, 520)의 특성(예컨대, 색상, 두께 등)을 미리 등록할 수 있다. 예를 들어, 전자 장치는 현실 객체(410, 510)의 형태, 사용자의 손이 현실 객체(410, 510)를 파지하는 형태, 및 사용자의 손이 현실 객체(410, 510)를 파지하는 위치에 기초하여 가상 객체(420, 520)의 특성을 미리 등록할 수 있다. 본 개시의 일 실시예에 따르면, 현실 객체, 현실 객체의 추적 대상, 현실 객체의 기능을 미리 등록함으로써 정 확하고 신속한 검출 및 추적 동작을 수행할 수 있다. 도 6은 본 개시의 일 실시예에 따른 입력 도구로 이용되는 현실 객체의 적어도 일부의 색상에 기초하여 가상 객 체의 색상을 결정하는 동작을 설명하기 위한 개념도이다. 도 1 내지 5b에서 설명한 내용과 중복되는 내용은 생 략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 6을 설명한다. 도 6을 참조하면, 전자 장치는 현실 객체와 사용자의 손을 검출할 수 있다. 전자 장치는 현 실 객체의 일측의 움직임을 추적할 수 있다. 전자 장치는 검출 결과 및 추적 결과에 기초하여 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체의 일측 의 색상에 기초하여 가상 객체의 색상을 결정할 수 있다. 예를 들어, 도 6에 도시된 바와 같이, 현실 객체의 일측의 색상이 검은색이라고 가정하나, 본 개시는 이에 한정되지 않으며, 현실 객체의 일측의 색상은 임의의 색상일 수 있다. 전자 장치는 현실 객체의 일측(예컨대, 연필의 팁 부분)의 색상이 검은색인 것을 인식할 수 있다. 전자 장치는 현실 객체의 일측의 색상이 검은색 인 것에 기초하여 가상 객체의 색상을 검은색으로 결정할 수 있다. 전자 장치는 결정된 색상(예컨대, 검은색)의 가상 객체를 생성할 수 있다. 도 7은 본 개시의 일 실시예에 따른 현실 객체가 가리키는 대상 객체의 색상에 기초하여 가상 객체의 색상을 결 정하는 동작을 설명하기 위한 개념도이다. 도 1 내지 5b에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 7을 설명한다. 도 7을 참조하면, 전자 장치는 현실 객체, 현실 객체를 파지하는 사용자의 손, 및 대상 객 체를 포함하는 이미지를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 대상 객체는 디스플레이에 표시되는 별도의 이미지에 포함되는 객체일 수 있다. 이 경우, 이미지는 별도의 이미지와 현실 객체 와 사용자의 손을 포함할 수 있다. 전자 장치는 이미지로부터 현실 객체, 사용자의 손, 및 대상 객체를 검출할 수 있다. 본 개 시의 일 실시예에 있어서, 전자 장치는 현실 객체의 일측의 움직임을 추적할 수 있다. 전자 장 치는 추적 결과에 기초하여 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 이미지로부터 현실 객체의 일측이 가리키는 대상 객체를 인식할 수 있다. 전자 장치는 대상 객체의 색상, 형태, 및 형상 중 적어도 하나에 기초 하여 가상 객체의 색상, 형태, 및 형상 중 적어도 하나를 결정할 수 있다. 전자 장치는 결정된 상기 색상, 형태, 및 형상 중 적어도 하나를 갖는 가상 객체를 생성할 수 있다. 예를 들어, 도 7에 도시된 바와 같이, 대상 객체의 색상은 빨간색이라고 가정하나, 본 개시는 이에 한정되지 않으며, 대상 객체의 색 상은 임의의 색상일 수 있다. 전자 장치는 대상 객체의 색상의 색상이 빨간색인 것을 인식할 수 있다. 전자 장치는 대상 객체의 색상의 색상이 빨간색인 것에 기초하여 가상 객체의 색상을 빨간색으로 결정할 수 있다. 전자 장치는 결정된 색상(예컨대, 빨간색)을 갖는 가상 객체를 생성할 수 있다. 도 8은 본 개시의 일 실시예에 따른 가상 객체의 형태에 기초하여 가상 객체의 색상을 결정하는 동작을 설명하 기 위한 개념도이다. 도 1 내지 5b에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 8을 설명한다. 도 8을 참조하면, 전자 장치는 이미지로부터 현실 객체 및 사용자의 손을 인식(또는 검출)할 수 있다. 전자 장치는 인식된 현실 객체의 적어도 일부의 움직임을 추적할 수 있다. 전자 장치 는 추적 결과에 기초하여 가상 객체(831, 832)를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객 체(831, 832)는 디스플레이에 표시되는 이미지 상에 합성될 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 가상 객체(831, 832)의 종류를 결정할 수 있다. 예를 들어, 전자 장치는 가상 객체(831, 832)에 대응하는 가상 이미지를 입력으로 하는, 인공지능 모델을 이용하여 가 상 객체(831, 832)를 분류할 수 있다. 예를 들어, 전자 장치는 가상 객체(831, 832)를 미리 정해진 클래스 로 분류할 수 있다. 예를 들어, 인공지능 모델은 가상 객체를 하트 클래스로 분류할 수 있다. 예를 들어, 인공지능 모델은 가상 객체를 왕관 클래스로 분류할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 분류 결과(예컨대, 인공지능 모델의 출력인 클래스 정보)에 기 매핑된 색상을 가상 객체(831, 832)의 색상으로 결정할 수 있다. 예를 들어, 전자 장치는 메모리 (또는 스토리지) 또는 외부 장치에 저장된 매핑 테이블에 액세스할 수 있다. 예를 들어, 매핑 테이블은 클래스 와 색상 간의 관계 정보를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 매핑 테이블은 사용자 또는 제조사 의 설정에 의해 미리 결정될 수 있다. 전자 장치는 매핑 테이블에 기초하여 클래스에 매핑된 색상을 가상 객체(831, 832)의 색상으로 결정할 수 있다. 예를 들어, 하트 클래스는 빨간색에 매핑되고, 왕관 클래스는 노란 색에 매핑될 수 있다. 전자 장치는 가상 객체의 색상을 빨간색으로 결정하고, 가상 객체의 색상 을 노란색으로 결정할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체(831, 832)의 색상은 가상 객체(831, 832)의 윤곽선의 색상 및 가상 객체(831, 832)가 차지하는 영역의 색상 중 적어도 하나를 나타낼 수 있다. 전자 장치는 결정된 색상을 갖는 가상 객체(831, 832)를 생성할 수 있다. 도 9는 본 개시의 일 실시예에 따른 현실 객체의 적어도 일부의 크기에 기초하여 가상 객체의 크기를 결정하는 동작을 설명하기 위한 개념도이다. 도 1 내지 5b에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 9를 설명한다. 도 9를 참조하면, 전자 장치는 이미지로부터 현실 객체 및 사용자의 손을 인식(또는 검출)할 수 있다. 전자 장치는 인식된 현실 객체의 적어도 일부의 움직임을 추적할 수 있다. 도 9에서 현실 객체 는 붓인 것으로 도시되었으나, 본 개시는 이에 제한되지 않으며, 현실 객체는 추적의 대상이 되는 부 분이 특정 크기(예컨대, 너비)를 갖는 임의의 객체일 수 있다. 예를 들어, 전자 장치는 현실 객체의 일측(예컨대, 붓의 머리 부분)의 움직임을 추적할 수 있다. 사용자의 손의 움직임에 따라 현실 객체 의 일측의 움직임이 발생할 수 있다. 예를 들어, 현실 객체의 일측는 경로를 따라 움 직일 수 있다. 전자 장치는 추적 결과에 기초하여 가상 객체를 생성할 수 있다. 예를 들어, 전자 장치는 인식 결과에 기초하여 사용자의 손이 현실 객체의 일측(예컨대, 붓의 머리 부분)을 향하여 위치함을 인식할 수 있다. 전자 장치는 인식 결과에 기초하여 가상 객체 생성 기능을 수행할 수 있다. 전자 장치 는 추적 결과에 기초하여 현실 객체의 일측(예컨대, 붓의 머리 부분)이 움직인 경로를 획득 할 수 있다. 전자 장치는 현실 객체의 일측(예컨대, 붓의 머리 부분)이 움직인 경로를 따라 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체의 일측 (예컨대, 붓의 머리 부분)의 크기(예컨대, 너비)에 기초하여 가상 객체의 크기(예컨대, 너비)를 결정 할 수 있다. 전자 장치는 인식 결과에 기초하여 현실 객체의 일측(예컨대, 붓의 머리 부분)의 너비를 결정할 수 있다. 전자 장치는 현실 객체의 일측(예컨대, 붓의 머리 부분)이 움직인 경로 를 중심축으로 하여 현실 객체의 일측(예컨대, 붓의 머리 부분)의 너비를 가진 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체는 디스플레이에 표시될 수 있다.도 10은 본 개시의 일 실시예에 따른 현실 객체의 적어도 일부를 추적함으로써 가상 객체를 생성하거나 삭제하 는 기능을 수행하는 방법을 보여주는 흐름도이다. 도 1 내지 9에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2 및 도 3을 참조하여, 도 10을 설명한다. 도 10을 참조하면, 도 3의 단계 S340는 단계 S1010 및 S1020을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S1010 및 S1020은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시 에 따른 단계 S340의 세부 단계들은 도 10에 도시된 바에 한정되지 않으며, 도 10에 도시된 단계 중 어느 하나 를 생략할 수도 있고, 도 10에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S1010에서, 전자 장치는 획득된 이미지에 기초하여 현실 객체의 적어도 일부의 움직임을 추적할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 적어도 하나의 이미지를 입력으로 하는 인공지능 모델 을 이용하여, 현실 객체의 적어도 일부의 움직임을 추적할 수 있다. 예를 들어, 추적 대상이 되는 현실 객체의 적어도 일부는 기 설정될 수 있다. 이 경우, 전자 장치는 기 설정된 현실 객체의 적어도 일부에 대응하는 정보를 인공지능 모델에 추가적으로 입력할 수 있다. 예를 들어, 미리 설정된 현실 객체의 적어도 일부에 대응 하는 정보는 현실 객체의 적어도 일부의 위치 정보 또는 경계 정보일 수 있다. 위치 정보 또는 경계 정보는 인 식 결과에 포함될 수 있다. 추적 결과는 추적 대상의 위치, 속도, 방향, 움직임 패턴 중 적어도 하나를 포함할 수 있다. 단계 S1020에서, 전자 장치는 추적 결과(추적된 움직임으로도 지칭될 수 있음)에 기초하여 가상 객체를 생 성하거나 삭제하는 기능을 수행할 수 있다. 예를 들어, 전자 장치는 현실 객체의 적어도 일부가 형성하는 움직임 경로(즉, 추적 결과)를 따라 가상 객체를 생성할 수 있다. 예를 들어, 전자 장치는 현실 객체의 적 어도 일부가 형성하는 움직임 경로(즉, 추적 결과)를 따라 이미 생성된 가상 객체를 삭제할 수 있다. 전자 장치 가 가상 객체를 생성하는 기능을 수행할 것인지, 가상 객체를 삭제하는 기능을 수행할 것인지는, 인식 결 과(예컨대, 인식된 사용자의 손과 현실 객체 간의 인터랙션)에 기초하여 결정될 수 있다. 예를 들어, 인식 결과 는 현실 객체의 형태, 사용자의 손의 형태, 및 현실 객체와 사용자의 손 간의 인터랙션(예컨대, 사용자의 손이 현실 객체를 파지하는 형태, 및 사용자의 손이 현실 객체를 파지하는 위치) 중 적어도 하나를 포함할 수 있다. 도 11은 본 개시의 일 실시예에 따른 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나에 기초하여 가상 객체의 색상 및 크기 중 적어도 하나를 결정하는 방법을 보여주는 흐름도이다. 도 1 내지 10에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2, 도 3, 및 도 10을 참조하여, 도 11을 설명한다. 도 11을 참조하면, 단계 S1110는 도 10의 단계 S1010에 대응할 수 있다. 단계 S1120는 도 10의 단계 S1020에 대응할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S1110 내지 S1150은 전자 장치 또는 전자 장치(20 0)의 프로세서에 의해 수행될 수 있다. 단계 S340의 세부 단계들은 도 11에 도시된 바에 한정되지 않으며, 도 11에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 11에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S1110에서, 전자 장치는 획득된 이미지에 기초하여 현실 객체의 움직임을 추적할 수 있다. 단계 S1210은 도 10의 단계 S1010에 대응하므로, 구체적인 설명은 생략한다. 단계 S1120에서, 전자 장치는 추적된 움직임에 기초하여 가상 객체를 생성하거나 삭제하는 기능을 수행할 수 있다. 단계 S1220은 도 10의 단계 S1020에 대응하므로, 구체적인 설명은 생략한다. 단계 S1130에서, 전자 장치는 획득된 이미지로부터 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하 나를 인식할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 획득된 이미지로부터 현실 객체의 적어 도 일부의 색상을 인식할 수 있다. 예를 들어, 전자 장치는 현실 객체의 일측(예컨대, 색연필의 팁 부분) 의 색상을 인식할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 획득된 이미지로부터 현실 객체의 적어도 일부의 크기를 인식할 수 있다. 예를 들어, 전자 장치는 현실 객체의 일측(예컨대, 붓의 머리 부분)의 크기을 인식할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체의 적어도 일부는, 현실 객체 중 추 적 대상에 대응하는 부분일 수 있다. 단계 S1140에서, 전자 장치는 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나에 기초하여, 가상 객체의 색상 및 크기 중 적어도 하나를 결정할 수 있다. 예를 들어, 현실 객체의 적어도 일부(즉, 추적 대상)의 색상이 빨간색인 경우, 전자 장치는 가상 객체의 색상을 빨간색으로 결정할 수 있다. 예를 들어, 현실 객체의 적어도 일부(즉, 추적 대상)의 크기가 특정 크기인 경우, 전자 장치는 가상 객체의 크기를 특정 크기 로 결정할 수 있다. 단계 S1150에서, 전자 장치는 결정된 색상 및 크기 중 적어도 하나를 갖는 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체는 디스플레이에 표시될 수 있다. 도 12는 본 개시의 일 실시예에 따른 현실 객체가 가리키는 대상 객체의 색상, 형태, 및 형상에 기초하여 가상 객체의 색상, 형태, 및 형상을 결정하는 방법을 보여주는 흐름도이다. 도 1 내지 11에서 설명한 내용과 중복되 는 내용은 생략한다. 설명의 편의를 위해, 도 2, 도 3, 및 도 10을 참조하여, 도 12를 설명한다. 도 12를 참조하면, 단계 S1210는 도 10의 단계 S1010에 대응할 수 있다. 단계 S1220는 도 10의 단계 S1020에 대응할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S1210 내지 S1250은 전자 장치 또는 전자 장치(20 0)의 프로세서에 의해 수행될 수 있다. 단계 S340의 세부 단계들은 도 12에 도시된 바에 한정되지 않으며, 도 12에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 12에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S1210에서, 전자 장치는 획득된 이미지에 기초하여 현실 객체의 움직임을 추적할 수 있다. 단계 S1210은 도 10의 단계 S1010에 대응하므로, 구체적인 설명은 생략한다. 단계 S1220에서, 전자 장치는 추적된 움직임에 기초하여 가상 객체를 생성하거나 삭제하는 기능을 수행할 수 있다. 단계 S1220은 도 10의 단계 S1020에 대응하므로, 구체적인 설명은 생략한다. 단계 S1230에서, 전자 장치는 획득된 이미지로부터 현실 객체가 가리키는 대상 객체를 인식할 수 있다. 대 상 객체는, 획득된 이미지에 포함되나, 사용자의 손과 인터랙션하는 현실 객체와는 다른 현실 객체일 수 있다. 전자 장치는 이미지로부터 대상 객체를 검출할 수 있다. 전자 장치는 추적 결과에 기초하여 현실 객 체의 적어도 일부가 대상 객체를 가리키는지를 결정할 수 있다. 예를 들어, 전자 장치는 현실 객체의 적어 도 일부의 위치, 속도, 방향 중 적어도 하나에 기초하여 대상 객체의 위치에 현실 객체의 적어도 일부가 위치하 는지를 결정할 수 있다. 전자 장치는 대상 객체의 위치에 현실 객체의 적어도 일부가 위치하는 것으로 결 정한 것에 기초하여, 현실 객체의 적어도 일부가 대상 객체를 가리키는 것으로 결정할 수 있다. 본 개시의 일 실시예에 있어서, 대상 객체는 디스플레이에 표시되는 이미지 내의 표시되는 객체일 수 있다. 본 개시의 일 실 시예에 있어서, 대상 객체는 현실의 물리적 환경 공간 내의 실제 객체일 수 있다. 단계 S1240에서, 전자 장치는 대상 객체의 색상, 형태, 및 형상 중 적어도 하나에 기초하여, 가상 객체의 색상, 형태, 및 형상 중 하나를 결정할 수 있다. 예를 들어, 대상 객체의 색상이 빨간색인 경우, 전자 장치 는 가상 객체의 색상을 빨간색으로 결정할 수 있다. 예를 들어, 현실 객체가 가리키는 위치에 대응하는 대 상 객체의 부분의 색상이 파란색인 경우, 전자 장치는 가상 객체의 색상을 파란색으로 결정할 수 있다. 단계 S1250에서, 전자 장치는 결정된 색상, 형태, 및 형상 중 적어도 하나를 갖는 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 가상 객체는 디스플레이에 표시될 수 있다. 도 13은 본 개시의 일 실시예에 따른 현실 이미지에 가상 객체를 합성한 이미지를 획득하는 방법을 보여주는 흐 름도이다. 도 1 내지 12에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 13을 설명한다. 도 13을 참조하면, 본 개시의 일 실시예에 따른 현실 이미지에 가상 객체를 합성한 이미지를 획득하는 방법은, 단계 S1020 이후에 단계 S1310 및 S1320을 포함할 수 있다. 일 실시 예에 있어서, 단계 S1310 및 S1320은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시의 일 실시예에 따른 현실 이 미지에 가상 객체를 합성한 이미지를 획득하는 방법은 도 13 도시된 바에 한정되지 않으며, 도 13 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 13에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S1310에서, 전자 장치는 카메라를 이용하여 현실 공간을 촬영하여 획득한 제1 이미지에, 가상 객체를 합성한 제2 이미지를 획득할 수 있다. 예를 들어, 제1 이미지는 도 1의 현실 이미지에 대응할 수 있다. 예를 들어, 제2 이미지는 도 1의 합성 이미지에 대응할 수 있다. 단계 S1320에서, 전자 장치는 디스플레이 또는 외부 장치에 디스플레이에 제2 이미지를 표시할 수 있 다.도 14a 내지 14d는 본 개시의 일 실시예에 따른 현실 객체의 폐색된 부위에 기초하여 기 등록된 기능을 식별하 는 동작을 설명하기 위한 개념도이다. 도 1 내지 13에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의 를 위해, 도 2를 참조하여, 도 14a 내지 14d를 설명한다. 도 14a를 참조하면, 전자 장치는 이미지로부터 현실 객체을 검출할 수 있다. 전자 장치는 현실 객체를 복수의 부위들로 분할할 수 있다. 예를 들어, 전자 장치는 동영상을 입력으로 하는 인공지능 모델을 이용하여 현실 객체를 복수의 부위들로 분할할 수 있다. 예를 들어, 전자 장치는 현실 객체 의 일측(예컨대, 보드마카의 머리 부분)을 제1 부위로, 현실 객체의 타측(예컨대, 보드마카 의 꼬리 부분 또는 보드마카의 일측으로부터의 거리가 가장 먼 부분)을 제2 부위로, 현실 객체의 몸통 부위(예컨대, 보드마카의 일측으로부터의 거리와 보드마카의 타측으로부터의 거리가 동일한 부분)을 제3 부위로 분할할 수 있다. 도 14a 내지 14d에서, 현실 객체가 세 개의 부위들로 분할되는 예시를 도 시하였으나, 본 개시는 이에 한정되지 않는다. 본 개시의 일 실시예에 있어서, 전자 장치는 분할된 복수의 부위들 각각에 대응하는 적어도 하나의 위치 값을 획득할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치 는 현실 객체를 기 결정된 위치에 따라 복수의 부위들로 분할할 수 있다. 도 14b를 참조하면, 전자 장치는 이미지로부터 현실 객체 및 현실 객체를 파지하는 사용자의 손을 검출할 수 있다. 전자 장치는 검출 결과에 기초하여 현실 객체를 복수의 부위들(1411, 1412, 1413)로 분할할 수 있다. 전자 장치는 복수의 부위들(1411, 1412, 1413) 중 사용자의 손에 의 해 폐색된 적어도 하나의 부위를 검출할 수 있다. 예를 들어, 도 14b에 도시된 바와 같이, 현실 객체를 파지하는 사용자의 손에 의해 현실 객체의 타측(예컨대, 보드마카의 꼬리 부분 또는 보드마카의 일측 으로부터의 거리가 가장 먼 부분)인 제2 부위가 폐색될 수 있다. 전자 장치는 현실 객체의 제 2 부위가 폐색된 것으로 검출된 것에 기초하여, 기 등록된 기능을 식별할 수 있다. 예를 들어, 기 등록된 기능은 가상 객체를 생성하는 기능일 수 있다. 전자 장치는 현실 객체의 일측(예컨대, 보드마카의 머리 부분)인 제1 부위의 움직임을 추적할 수 있다. 전자 장치는 추적 결과에 기초하여 가상 객체를 생성할 수 있다. 도 14c를 참조하면, 전자 장치는 복수의 부위들(1411, 1412, 1413) 중 사용자의 손에 의해 폐색된 적 어도 하나의 부위를 검출할 수 있다. 예를 들어, 도 14c에 도시된 바와 같이, 현실 객체를 파지하는 사용 자의 손에 의해 현실 객체의 일측(예컨대, 보드마카의 머리 부분)인 제1 부위가 폐색될 수 있 다. 전자 장치는 현실 객체의 제1 부위가 폐색된 것으로 검출된 것에 기초하여, 기 등록된 기 능을 식별할 수 있다. 예를 들어, 기 등록된 기능은 가상 객체를 삭제하는 기능일 수 있다. 전자 장치는 현실 객체의 타측(예컨대, 보드마카의 꼬리 부분 또는 보드마카의 일측으로부터의 거리가 가장 먼 부분) 인 제2 부위의 움직임을 추적할 수 있다. 전자 장치는 추적 결과에 기초하여 미리 생성된 가상 객체 를 삭제할 수 있다. 도 14d를 참조하면, 전자 장치는 복수의 부위들(1411, 1412, 1413) 중 사용자의 손에 의해 폐색된 적 어도 하나의 부위를 검출할 수 있다. 예를 들어, 도 14d에 도시된 바와 같이, 현실 객체를 파지하는 사용 자의 손에 의해 현실 객체의 몸통 부위(예컨대, 보드마카의 일측으로부터의 거리와 보드마카의 타측 으로부터의 거리가 동일한 부분)을 제3 부위가 폐색될 수 있다. 전자 장치는 현실 객체의 제3 부위가 폐색된 것으로 검출된 것에 기초하여, 기 설정된 기능을 수행할 수 있다. 예를 들어, 기 설정된 기능은 가상 객체의 특성(예컨대, 색상, 두께 등)을 설정하는 모드로 전환하는 기능일 수 있다. 전자 장치(20 0)는 현실 객체의 일측(예컨대, 보드마카의 머리 부분)인 제1 부위 또는 현실 객체의 타측 (예컨대, 보드마카의 꼬리 부분 또는 보드마카의 일측으로부터의 거리가 가장 먼 부분)인 제2 부위를 터 치하는 사용자의 손의 동작을 검출할 수 있다. 본 개시에서, 터치(touch)는 사용자의 손이 현실 객체 에 접촉하는 동작을 나타낼 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 검출된 동작에 기초하여 가상 객체의 특성(예컨대, 색상, 두 께 등)을 설정하는 모드로 전환하는 기능을 수행할 수 있다. 예를 들어, 가상 객체의 특성을 설정하는 모드에서, 사용자의 손이 현실 객체의 제1 부위를 연속하여 기 결정된 횟수만큼 터치하는 동작 이 검출된 경우, 전자 장치는 디스플레이를 통해 가상 객체의 색상을 결정하는 버튼 또는 슬라이더 등을 포함하는 사용자 인터페이스를 제공할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객 체의 위치 또는 움직임에 기초하여 가상 객체의 색상을 결정할 수 있다. 예를 들어, 가상 객체의 특성을설정하는 모드에서, 사용자의 손이 현실 객체의 제2 부위를 연속하여 기 결정된 횟수만큼 터치 하는 동작이 검출된 경우, 전자 장치는 디스플레이를 통해 가상 객체의 두께를 결정하는 버튼 또는 슬라이더 등을 포함하는 사용자 인터페이스를 제공할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치 는 현실 객체의 위치 또는 움직임에 기초하여 가상 객체의 두께를 결정할 수 있다. 예를 들어, 사용자의 손이 현실 객체의 제2 부위를 기 결정된 시간 동안 터치하는 동작이 검출된 경우, 전자 장치 는 현실 장면에 대응하는 이미지와 디스플레이에 표시된 가상 객체가 합성된 이미지를 획득할 수 있다. 도 15는 본 개시의 일 실시예에 따른 현실 객체의 폐색된 부위에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 1 내지 14d에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2 및 도 14c를 참조하여, 도 15를 설명한다. 도 15를 참조하면, 도 3의 단계 S320는 단계 S1510 내지 S1530을 포함할 수 있다. 도 3의 단계 S330는 단계 S1540을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S1510 내지 S1540은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S330 및 S340의 세부 단계들은 도 15 에 도시된 바에 한정되지 않으며, 도 15에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 15에 도시되지 않 은 단계를 더 포함할 수도 있다. 단계 S1510에서, 전자 장치는 획득된 이미지로부터 현실 객체를 검출할 수 있다. 본 개시의 일 실시 예에 있어서, 전자 장치는 적어도 하나의 이미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체 를 검출할 수 있다. 단계 S1520에서, 전자 장치는 검출된 현실 객체를 복수의 부위들(1411, 1412, 1413)로 분할할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체의 복수의 부위들의 개수 또는 복수의 부위들의 위치는 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현 실 객체를 포함하는 이미지를 입력으로 하는 인공지능 모델을 이용하여, 현실 객체를 복수의 부위 들(1411, 1412, 1413)의 위치 정보 또는 경계 정보를 추론할 수 있다. 본 개시의 일 실시예에 있어서, 복수의 부위들(1411, 1412, 1413)의 위치 정보 또는 경계 정보는 미리 저장될 수 있다. 이 경우, 단계 S1510은 생략될 수 있다. 단계 S1530에서, 전자 장치는 복수의 부위들(1411, 1412, 1413) 중 사용자의 손에 의해 폐색된 적어도 하나의 부위를 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 분할 결과에 기초하여 복수의 부위들(1411, 1412, 1413)의 위치를 식별할 수 있다. 전자 장치는 식별된 위치와 사용자의 손의 위치 를 비교할 수 있다. 전자 장치는 비교 결과에 기초하여 복수의 부위들(1411, 1412, 1413) 중 사용자의 손 에 의해 폐색된 적어도 하나의 부위를 식별할 수 있다. 본 개시의 일 실시예에 있어서, 복수의 부위들 (1411, 1412, 1413)의 위치 정보 또는 경계 정보가 미리 저장된 경우, 전자 장치는 미리 저장된 복수의 부 위들(1411, 1412, 1413)의 위치 정보 또는 경계 정보에 기초하여 사용자의 손에 의해 폐색된 적어도 하나의 부위를 추론할 수 있다. 단계 S1540에서, 전자 장치는 폐색된 적어도 하나의 부위에 기초하여 기 등록된 기능을 식별할 수 있다. 예를 들어, 전자 장치는 제1 부위, 제2 부위, 및 제3 부위 중 적어도 하나가 폐색된 것 에 기초하여 복수의 기 등록된 기능들 중 매핑된 기능을 식별할 수 있다. 예를 들어, 기 등록된 기능은 가상 객 체를 생성하는 기능, 가상 객체를 삭제하는 기능, 또는 가상 객체의 특성을 설정하는 기능 중 하나일 수 있으나, 본 개시는 이에 제한되지 않는다. 도 16은 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 동작을 설명하기 위한 개념도이다. 도 1 내지 14a에서 설명한 내용과 중복되는 내용은 생략한다. 설명 의 편의를 위해, 도 2를 참조하여, 도 16을 설명한다. 도 16을 참조하면, 전자 장치는 이미지로부터 현실 객체을 검출할 수 있다. 전자 장치는 현실 객체를 복수의 부위들로 분할할 수 있다. 예를 들어, 전자 장치는 적어도 하나의 이미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체를 복수의 부위들로 분할할 수 있다. 예를 들어, 전자 장치 는 현실 객체의 일측(예컨대, 펜의 팁 부분)을 제1 부위로, 현실 객체의 타측(예컨대, 펜의 꼬리 부분 또는 펜의 팁 부분으로부터의 거리가 가장 먼 부분)을 제2 부위로, 현실 객체의 몸통 부위(예컨대, 펜의 일측으로부터의 거리와 보드마카의 펜으로부터의 거리가 동일한 부분)을 제3 부위 로 분할할 수 있다. 도 16에서, 현실 객체가 세 개의 부위들로 분할되는 예시를 도시하였으나, 본 개시는 이에 한정되지 않는다. 본 개시의 일 실시예에 있어서, 전자 장치는 분할된 복수의 부위들 각각에 대응하 는 적어도 하나의 위치 값을 획득할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체 를 기 결정된 위치에 따라 복수의 부위들로 분할할 수 있다. 전자 장치는 분할 결과에 기초하여 사용자의 손이 현실 객체를 파지하는 위치를 결정할 수 있다. 전자 장치는 분할된 복수의 부위들 각각에 대응하는 적어도 하나의 위치 값에 기초하여, 사용자의 손이 현실 객체를 파지하는 상대적인 위치를 결정할 수 있다. 예를 들어, 전자 장치는 제1 부위 및 제3 부위 사이에 대응하는 위치에 사용자의 손이 현실 객체를 파지하고 있음을 결정 할 수 있다. 예를 들어, 사용자의 손이 현실 객체를 파지하는 위치가 제1 부위 및 제3 부위 사이로 결정된 경우, 전자 장치는 가상 객체를 생성하는 기능을 수행할 수 있다. 예를 들어, 사용 자의 손이 현실 객체를 파지하는 위치가 제2 부위 및 제3 부위 사이로 결정된 경우, 전 자 장치는 가상 객체를 삭제하는 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 복수의 부위들(1611, 1612, 1613) 중 어느 부위를 향하여 사 용자의 손이 현실 객체를 파지하는지를 나타내는 파지 방향을 결정할 수 있다. 본 개시의 일 실시예 에 있어서, 전자 장치는 사용자의 손을 포함하는 이미지를 입력으로 하는 인공지능 모델을 이용하여 사용자의 손의 자세를 추정할 수 있다. 예를 들어, 전자 장치는 사용자의 손을 검출하고, 사용자 의 손에 포함된 관절들(예컨대, 손에 포함되는 복수의 뼈가 서로 연결되는 부분으로서, 손목, 손가락, 손등, 또는 손바닥에 포함되는 하나 이상의 부위를 나타낼 수 있음)에 대한 특징점을 검출할 수 있다. 특징점은 이미지 내에서 주위 배경과 구분되거나 식별이 용이한 지점을 의미할 수 있다. 예를 들어, 손 관절의 특징점은 예를 들어, 손목 관절의 특징점, 손바닥 관절의 특징점, 손등 관절의 특징점, 및 손가락(엄지, 검지, 중지, 약 지, 소지)의 특징점 중 적어도 하나를 포함할 수 있다. 예를 들어, 특징점은 2차원 또는 3차원 좌표 값을 포함 할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 특징점에 기초하여 사용자의 손의 파지 방향을 결정할 수 있다. 예를 들어, 전자 장치는 사용자의 손의 적어도 하나의 손가락(예컨대, 엄지(11a), 검지(11b), 중지(11c))의 특징점에 기초하여, 손가락의 위치와 형태를 식별할 수 있다. 전자 장치는 손가락의 위치와 형태에 기초하여 사용자의 손의 파지 방향을 결정할 수 있다. 예를 들어, 전자 장치는 엄지(11a), 검 지(11b), 중지(11c)가 제3 부위에서 제1 부위를 향하여 현실 객체를 파지하는 것을 식별할 수 있다. 전자 장치는 파지 방향에 기초하여 기 등록된 기능을 식별하고 수행할 수 있다. 예를 들어, 사용자의 손 이 현실 객체를 파지하는 방향이 제3 부위에서 제1 부위를 향하는 것으로 결정된 경우, 전자 장치는 가상 객체를 생성하는 기능을 수행할 수 있다. 예를 들어, 사용자의 손이 현실 객체 를 파지하는 방향이 제3 부위에서 제2 부위를 향하는 것으로 결정된 경우, 전자 장치는 가상 객체를 삭제하는 기능을 수행할 수 있다. 본 개시의 일 실시예에 따르면, 파지 위치뿐만 아니라 파지 방향도 고려함으로써 현실 객체와 사용자의 손 간의 인터랙션을 더 정확하게 파악할 수 있다. 도 17은 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 1 내지 16에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편 의를 위해, 도 2, 도 15, 및 도 16을 참조하여, 도 17을 설명한다. 도 17를 참조하면, 도 3의 단계 S320는 단계 S1710 내지 S1730을 포함할 수 있다. 도 3의 단계 S330는 단계 S1740을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S1710 내지 S1740은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S330 및 S340의 세부 단계들은 도 17 에 도시된 바에 한정되지 않으며, 도 17에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 17에 도시되지 않 은 단계를 더 포함할 수도 있다. 단계 S1710은 도 15의 S1510에 대응하고, 단계 S1720은 도 15의 S1520에 대응 하므로, 구체적인 설명은 생략한다. 단계 S1730에서, 전자 장치는 분할 결과에 기초하여 사용자의 손이 현실 객체를 파지하는 위치 를 결정할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 분할 결과에 기초하여 복수의 부위들 (1611, 1612, 1613)의 위치를 식별할 수 있다. 전자 장치는 식별된 위치와 사용자의 손의 위치를 비교 할 수 있다. 전자 장치는 비교 결과에 기초하여 복수의 부위들(1611, 1612, 1613)의 위치 대비 사용자의 손의 상대적인 위치를 결정할 수 있다. 본 개시의 일 실시예에 있어서, 복수의 부위들(1611, 1612, 1613)의 위치 정보 또는 경계 정보가 미리 저장된 경우, 전자 장치는 미리 저장된 복수의 부위들(1611, 1612, 1613)의 위치 정보 또는 경계 정보에 기초하여 사용자의 손의 상대적인 위치를 추론할 수 있다. 단계 S1740에서, 전자 장치는 결정된 위치에 기초하여 기 등록된 기능을 식별할 수 있다. 예를 들어, 전자 장치는 제1 부위, 제2 부위, 및 제3 부위 중 적어도 두 개의 부위 사이에 사용자의 손 이 위치한 것에 기초하여 복수의 기 등록된 기능들 중 매핑된 기능을 식별할 수 있다. 예를 들어, 기 등록 된 기능은 가상 객체를 생성하는 기능, 가상 객체를 삭제하는 기능, 또는 가상 객체의 특성을 설정하는 기능 중 하나일 수 있으나, 본 개시는 이에 제한되지 않는다. 도 18은 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 1 내지 17에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편 의를 위해, 도 2, 및 도 15 내지 도 17을 참조하여, 도 18을 설명한다. 도 18을 참조하면, 도 3의 단계 S320는 단계 S1810 내지 S1835을 포함할 수 있다. 도 3의 단계 S330는 단계 S1840을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S1810 내지 S1840은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S330 및 S340의 세부 단계들은 도 18 에 도시된 바에 한정되지 않으며, 도 18에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 18에 도시되지 않 은 단계를 더 포함할 수도 있다. 단계 S1810은 도 15의 S1510에 대응하고, 단계 S1820은 도 15의 S1520에 대응 하고, 단계 S1830은 도 17의 S1730에 대응하므로, 구체적인 설명은 생략한다. 단계 S1835에서, 전자 장치는 복수의 부위들(1611, 1612, 1613) 중 어느 부위를 향하여 사용자의 손이 현실 객체를 파지하는지를 나타내는 파지 방향을 결정할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 인공지능 모델을 이용하여 사용자의 손의 자세 추정을 수행할 수 있다.. 본 개시의 일 실시예 에 있어서, 전자 장치는 자세 추정 결과에 기초하여 사용자의 손의 적어도 하나의 손가락이 현실 객체 를 파지하는 방향을 결정할 수 있다. 단계 S1840에서, 전자 장치는 결정된 위치 및 결정된 파지 방향에 기초하여 기 등록된 기능을 식별할 수 있다. 예를 들어, 전자 장치는 제1 부위, 제2 부위, 및 제3 부위 중 적어도 두 개의 부위 사이에 사용자의 손이 위치한 것과 더불어 사용자의 손이 한 부위에서 다른 부위를 향하여 파지한 것에 기초하여 복수의 기 등록된 기능들 중 매핑된 기능을 식별할 수 있다. 예를 들어, 기 등록된 기능은 가상 객체를 생성하는 기능, 가상 객체를 삭제하는 기능, 또는 가상 객체의 특성을 설정하는 기능 중 하나일 수 있으 나, 본 개시는 이에 제한되지 않는다. 도 19는 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 1 내지 18에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편 의를 위해, 도 2 및 도 15를 참조하여, 도 19를 설명한다. 도 19를 참조하면, 도 3의 단계 S320는 단계 S1910 내지 S1930을 포함할 수 있다. 도 3의 단계 S330는 단계 S1940을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S1910 내지 S1940은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S330 및 S340의 세부 단계들은 도 19 에 도시된 바에 한정되지 않으며, 도 19에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 19에 도시되지 않 은 단계를 더 포함할 수도 있다. 단계 S1910은 도 15의 S1510에 대응하고, 단계 S1920은 도 15의 S1520에 대응 하므로, 구체적인 설명은 생략한다. 단계 S1930에서, 전자 장치는 사용자의 손이 현실 객체의 복수의 부위들(1411, 1412, 1413) 중 적어도 하나의 부위를 터치하는 동작을 인식(또는 검출)할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치 는 사용자의 손의 동작을 추적할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 손의 자세 추정을 수행할 수 있다. 전자 장치는 사용자의 손의 자세 추정 결과에 기초하여 사용자 의 손의 동작을 추정할 수 있다. 예를 들어, 사용자의 손이 현실 객체의 복수의 부위들(1411,1412, 1413) 중 적어도 하나의 부위를 터치하는 동작은, 사용자의 손이 현실 객체의 복수의 부위들 (1411, 1412, 1413) 중 적어도 하나의 부위를 미리 정해진 횟수만큼 터치하는 동작 또는 미리 정해진 시간만큼 터치하는 동작을 포함할 수 있다. 단계 S1940에서, 전자 장치는 인식된 동작에 기초하여 기 설정된 기능을 식별할 수 있다. 예를 들어, 전자 장치는 사용자의 손이 현실 객체의 복수의 부위들(1411, 1412, 1413) 중 적어도 하나의 부위를 미리 정해진 횟수만큼 터치하는 동작을 인식(또는 검출)할 수 있다. 전자 장치는 검출된 동작에 기초하여 가상 객체의 색상 또는 두께를 변경하는 가상 객체를 설정하는 모드로 전환하는 기능을 수행할 수 있다. 도 20은 본 개시의 일 실시예에 따른 사용자의 손과 현실 객체 간의 거리에 따라 기 결정된 기능을 수행할지 여 부를 결정하는 방법을 보여주는 흐름도이다. 도 1 내지 19에서 설명한 내용과 중복되는 내용은 생략한다. 설명 의 편의를 위해, 도 2 및 도 3을 참조하여, 도 20을 설명한다. 도 20을 참조하면, 도 3의 단계 S320과 단계 S330 사이에 단계 S2010을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S2010은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 단계 S2010에서, 전자 장치는 사용자의 손과 현실 객체 간의 거리가 임계 값을 초과하는지 여부를 결정할 수 있다. 임계 값은 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 임계 값을 초과한 경우, 절차는 종료된다. 이 경우, 전자 장치는 현실 객체를 더 이상 입력 도구로 이용하지 않을 수 있다. 임계 값을 초 과하지 않은 경우, 절차는 단계 S330으로 이동한다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 손과 현실 객체 간의 거리를 측정할 수 있다. 전자 장치는 측정된 거리가 기 정의된 임계 값을 초과하지 않은 경우, 현실 객체를 입력 도구로 사용하는 것으 로 결정할 수 있다. 전자 장치는 측정된 거리가 기 정의된 임계 값을 초과한 경우, 현실 객체를 입력 도구 로 사용하지 않는 것으로 결정할 수 있다. 도 21은 본 개시의 일 실시예에 따른 현실 객체의 특성에 따라 가상 객체의 성능 값을 결정하는 기능을 수행하 는 동작을 설명하기 위한 개념도이다. 도 1 내지 20에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의 를 위해, 도 2를 참조하여, 도 21을 설명한다. 도 21을 참조하면, 전자 장치는 이미지로부터 현실 객체(2110a, 2110b, 2110c) 및 사용자의 손을 검출 할 수 있다. 예를 들어, 도 21에 도시된 바와 같이, 현실 객체(2110a, 2110b, 2110c)는 탁구채일 수 있으나, 본 개시는 이에 제한되지 않으며, 사용자의 손으로 파지할 수 있는 임의의 객체일 수 있다. 전자 장치는 이미지로부터 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 색상, 재질, 형태, 사용자의 손의 형태, 사용자의 손의 위치 중 적어도 하나를 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 종류를 분류할 수 있 다. 예를 들어, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)인 탁구채가 펜홀더 라켓(예컨대, 현실 객체(2110a))인지 또는 셰이크핸드 라켓(예컨대, 현실 객체(2110b_1, 2110b_2))인지를 분류할 수 있다. 본 개시 의 일 실시예에 있어서, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)를 포함하는 이미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체(2110a, 2110b_1, 2110b_2)의 종류를 분류할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 손이 현실 객체(2110a, 2110b_1, 2110b_2)를 파지하는 방식에 기초하여 현실 객체(2110a, 2110b_1, 2110b_2)의 종류를 분류할 수 있다. 예를 들어, 전자 장치는 사용자 의 손의 자세 추정을 수햄함으로써 사용자의 손이 현실 객체(2110a, 2110b_1, 2110b_2)를 파지하는 방 식을 식별할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 재질을 검출(또는 분류)할 수 있다. 예를 들어, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)인 탁구채의 타 면의 러버(rubber)가 평면 러버인지 또는 돌출 러버인지를 분류할 수 있다. 본 개시의 일 실시예에 있어서, 전 자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)를 포함하는 이미지를 입력으로 하는 인공지능 모델을 이용 하여 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 재질을 분류할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 색상을 검출(또는 분류)할 수 있다. 예를 들어, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)인 탁구채의 타면의 색상이 빨간색인지 또는 검은색인지를 분류할 수 있다. 예를 들어, 탁구채의 제1 면(예컨대, 현실 객체 (2110b_1))은 빨간색이고, 제2 면(현실 객체(2110b_2))은 검은색일 수 있다. 본 개시의 일 실시예에 있어서, 전 자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)를 포함하는 이미지를 입력으로 하는 인공지능 모델을 이용 하여 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 색상을 분류할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 검출 결과에 기초하여 현실 객체(2110a, 2110b_1, 2110b_2)에 대응하는 가상 객체(2131, 2132)의 성능 값을 결정할 수 있다. 예를 들어, 현실 객체(2110a)인 탁구채가 펜홀더 라켓인지 또는 셰이크핸드 라켓인지에 기초하여 기 결정된 성능 값을 결정할 수 있다. 예를 들어, 전자 장치 는 메모리 (또는 스토리지) 또는 외부 장치에 저장된 매핑 테이블에 액세스할 수 있다. 예를 들어, 매핑 테이블은 탁구채의 종류와 성능 값 간의 관계 정보를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 매 핑 테이블은 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 전자 장치는 매핑 테이블에 기초하 여 라켓의 종류별로 매핑된 성능 값을 가상 객체의 성능 값으로 결정할 수 있다. 예를 들어, 펜홀더 라켓 은 제1 스핀 값 및 제1 파워 값에 매핑되고, 셰이크핸드 라켓은 제2 스핀 값 및 제2 파워 값에 매핑될 수 있다. 제1 스핀 값은 제2 스핀 값보다 작을 수 있다. 제1 파워 값은 제2 파워 값보다 클 수 있다. 예를 들어, 현실 객체(2110a)인 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 재질에 기초하여 기 결정 된 성능 값을 결정할 수 있다. 예를 들어, 전자 장치는 메모리 (또는 스토리지) 또는 외부 장치에 저 장된 매핑 테이블에 액세스할 수 있다. 예를 들어, 매핑 테이블은 탁구채의 타면의 재질과 성능 값 간의 관계 정보를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 매핑 테이블은 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 전자 장치는 매핑 테이블에 기초하여 탁구채의 타면의 재질 별로 매핑된 성능 값을 가상 객체의 성능 값으로 결정할 수 있다. 예를 들어, 돌출 러버는 제3 파워 값에 매핑되고, 평면 러버는 제4 파워 값에 매핑될 수 있다. 제3 파워 값은 제4 파워 값보다 클 수 있다. 예를 들어, 현실 객체(2110a)인 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 색상에 기초하여 기 결정 된 성능 값을 결정할 수 있다. 예를 들어, 전자 장치는 메모리 (또는 스토리지) 또는 외부 장치에 저 장된 매핑 테이블에 액세스할 수 있다. 예를 들어, 매핑 테이블은 탁구채의 타면의 색상과 성능 값 간의 관계 정보를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 매핑 테이블은 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 전자 장치는 매핑 테이블에 기초하여 탁구채의 타면의 색상 별로 매핑된 성능 값을 가상 객체의 성능 값으로 결정할 수 있다. 예를 들어, 빨간색 타면은 제3 스핀 값 및 제5 파워 값에 매핑되고, 검은색 타면은 제4 스핀 값 및 제6 파워 값에 매핑될 수 있다. 제3 스핀 값은 제4 스핀 값보다 클 수 있다. 제5 파워 값은 제6 파워 값보다 작을 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 디스플레이 또는 외부 장치의 디스플레이를 통해 가상 현실 게임을 표시할 수 있다. 예를 들어, 도 21에 도시된 바와 같이, 가상 현실 게임은 탁구 게임 일 수 있으나, 본 개시는 이에 제한되지 않으며, 사용자의 손으로 파지할 수 있는 임의의 객체를 사용하는 게임일 수 있다. 가상 현실 게임은 가상 객체(2131, 2132)를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 움직임 을 추적할 수 있다. 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 움직임에 대응하는 추적 결과에 기초하여 이에 대응하는 가상 객체의 움직임을 디스플레이에 표시할 수 있다. 가상 객체의 움 직임에 따라, 가상 객체가 가상 객체에 충돌할 수 있다. 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 움직임의 속도, 방향, 위치, 및 결정된 가상 객체의 성능 값 중 적어도 하나에 기초 하여, 가상 객체의 충돌 후 물리량을 계산할 수 있다. 전자 장치는 계산된 물리량에 기초하여 가상 객체의 움직임의 속도, 방향, 위치, 스핀방향 중 적어도 하나를 결정할 수 있다. 도 22는 본 개시의 일 실시예에 따른 현실 객체의 특성에 따라 가상 객체의 성능 값을 결정하는 방법을 보여주 는 흐름도이다. 도 1 내지 21에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2, 3, 및 21을 참조하여, 도 22를 설명한다. 도 22를 참조하면, 도 3의 단계 S340는 단계 S2210을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S2210은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S340의 세부 단계들은 도 22에 도시된 바에 한정되지 않으며, 도 22에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 22에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S2210에서, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 색상, 재질, 형태, 사용자의 손의 형태, 및 사용자의 손의 위치 중 적어도 하나에 기초하여 가상 객체의 성능 값을 결정하 는 기능을 수행할 수 있다. 그러나 본 개시는 이에 제한되지 않으며, 이미지에서 획득할 수 있는 현실 객체 (2110a, 2110b_1, 2110b_2)의 임의의 특성에 기초하여 가상 객체의 성능 값을 결정할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체(2110a, 2110b_1, 2110b_2)의 임의의 특성과 성능 값 간의 관계 정보는 매핑 테 이블에 미리 저장되어 있을 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체(2110a, 2110b_1, 2110b_2)의 적어도 일부의 움직임 을 추적할 수 있다. 전자 장치는 추적 결과를 따르는 가상 객체의 움직임을 디스플레이에 표시 할 수 있다. 전자 장치는 결정된 성능 값에 기초하여 가상 객체의 움직임에 대응하는 제1 물리량을 계산할 수 있다. 전자 장치는 제1 물리량에 기초하여 가상 객체와 충돌하는 다른 가상 객체의 충돌 후 물리량인 제2 물리량을 계산할 수 있다. 도 23은 본 개시의 일 실시예에 따른 매핑될 가상 객체와 유사한 현실 객체를 입력 도구로 이용하는 동작을 설 명하기 위한 개념도이다. 도 1 내지 22에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2 및 21를 참조하여, 도 23을 설명한다. 도 23를 참조하면, 현실 객체의 목적과 기능은 가상 현실 게임의 가상 객체의 목적과 기능은 상이하지만, 현실 객체의 형상 및 형태가 가상 객체의 형상 및 형태와 유사할 수 있다. 예를 들어, 현실 객체는, 가상 객체의 형상과 유사하게, 타면 및 손잡이를 포함할 수 있다. 현실 객체는 가상 객체의 용도와 동일한 용도로 사용되도록 전자 장치의 입력 도구로 활용될 수 있 다. 예를 들어, 전자 장치는 현실 객체를 포함하는 동영상을 획득할 수 있다. 전자 장치는 이 미지로부터 현실 객체 및 현실 객체를 파지하는 사용자의 손을 검출할 수 있다. 전자 장치 는 검출 결과에 기초하여 현실 객체의 적어도 일부의 움직임(예컨대, 타면)을 추적할 수 있다. 전자 장치는 추적 결과에 기초하여 현실 객체에 매핑된 가상 객체의 움직임을 디스플레 이에 표시할 수 있다. 도 24는 본 개시의 일 실시예에 따른 기 결정된 움직임에 기초하여 가상 객체를 생성하는 동작을 설명하기 위한 개념도이다. 도 1 내지 23에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 24를 설명한다. 도 24를 참조하면, 전자 장치는 제3 현실 객체를 포함하는 현실 이미지를 획득할 수 있다. 예 를 들어, 도 24에 제3 현실 객체는 문서인 것으로 도시되었으나, 본 개시는 이제 한정되지 않는다. 전자 장치는 제4 현실 객체 및 사용자의 손을 포함하는 이미지를 획득할 수 있다. 전자 장치는 이미지로부터 제4 현실 객체 및 사용자의 손을 검출할 수 있다. 전자 장치는 인식된 제4 현실 객체의 기 결정된 움직임을 검출할 수 있다. 전자 장치는 검출된 움직임이 기 결정된 움직임인지 결 정할 수 있다. 전자 장치는 검출된 움직임이 기 결정된 움직임인 것으로 결정한 것에 기초하여, 기 결정된 가상 객체를 생성하는 기능을 수행할 수 있다. 예를 들어, 가상 객체는 사용자의 서명 또는 임의의 스탬프일 수 있다. 예를 들어, 전자 장치의 기능을 트리거링하는 제4 현실 객체의 움직임은 사용자 또는 제조사의 설정에 의해 미리 설정될 수 있다. 예를 들어, 전자 장치는 제4 현실 객체가 움직이 는 거리, 방향, 속도, 횟수 중 적어도 하나에 기초하여 전자 장치의 기능을 트리거링할 수 있다. 예를 들 어, 가상 객체는 사용자 또는 제조사의 설정에 의해 미리 설정될 수 있다. 본 개시의 일 실시예에 따르면, 사용자는 문서의 검토 완료 여부를 직관적으로 확인할 수 있다. 도 25는 본 개시의 일 실시예에 따른 기 결정된 움직임에 기초하여 가상 객체를 생성하는 동작을 설명하기 위한 개념도이다. 도 1 내지 24에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 25를 설명한다. 도 25를 참조하면, 전자 장치는 현실 이미지를 획득할 수 있다. 예를 들어, 도 25에 현실 이미지 는 현실 장소를 촬영한 이미지인 것으로 도시되었으나, 본 개시는 이제 한정되지 않는다. 전자 장치는 현실 객체 및 사용자의 손을 포함하는 이미지를 획득할 수 있다. 전자 장치는 이미지로부 터 현실 객체 및 사용자의 손을 검출할 수 있다. 전자 장치는 인식된 현실 객체의 움직임 을 검출할 수 있다. 전자 장치는 검출된 움직임이 기 결정된 움직임인지를 결정할 수 있다. 전자 장치 는 검출된 움직임이 기 결정된 움직임인 것으로 결정한 것에 기초하여, 기 결정된 가상 객체를 생성 하는 기능을 수행할 수 있다. 예를 들어, 가상 객체는 장소에 대한 본인의 평가에 대응하는 스탬프일 수 있다. 본 개시의 일 실시예에 따르면, 사용자는 이미 와본 장소에 대한 본인의 평가를 직관적으로 확인할 수 있 다. 도 26은 본 개시의 일 실시예에 따른 기 결정된 움직임에 기초하여 가상 객체를 생성하는 방법을 보여주는 흐름 도이다. 도 1 내지 25에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2, 3, 및 24를 참 조하여, 도 26을 설명한다. 도 26을 참조하면, 도 3의 단계 S340는 단계 S2610 내지 S2630을 포함할 수 있다. 본 개시의 일 실시예에 있어 서, 단계 S2610 내지 S2630은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S340의 세부 단계들은 도 26에 도시된 바에 한정되지 않으며, 도 26에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 26에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S2610에서, 전자 장치는 인식된 현실 객체의 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있어 서, 전자 장치는 현실 객체의 적어도 일부의 움직임을 추적할 수 있다. 본 개시의 일 실시예에 있어서, 전 자 장치는 복수의 이미지 프레임들 내의 객체의 특징점 매칭을 통하여, 객체의 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체 및 사용자의 손 중 적어도 하나의 움직 임을 추적할 수 있다. 전자 장치는 추적 결과에 기초하여 기 결정된 움직임 발생 여부를 결정할 수 있다. 단계 S2620에서, 전자 장치는 검출된 움직임이 기 결정된 움직임인지를 결정할 수 있다. 예를 들어, 현실 객체의 움직임은 현실 객체의 움직임의 거리, 속도, 방향, 횟수 중 적어도 하나에 기초하여 미리 결정될 수 있다. 단계 S2630에서, 전자 장치는 기 결정된 움직임이 기 결정된 움직임인 것으로 결정한 것에 기초하여 기 결 정된 가상 객체를 생성하는 기능을 수행할 수 있다. 전자 장치는 디스플레이 또는 외부 장치에 디스플레이를 통해 가상 객체를 표시할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체의 움직임이 발생한 위치에 가상 객체를 생성할 수 있다. 도 27은 본 개시의 일 실시예에 따른 기 결정된 움직임과 개인 인증 입력에 기초하여 가상 객체를 생성하는 동 작을 설명하기 위한 개념도이다. 도 1 내지 26에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위 해, 도 2를 참조하여, 도 27을 설명한다. 도 27를 참조하면, 전자 장치는 디스플레이를 통해 사용자의 서명을 요구하는 보안 문서 화면 을 표시할 수 있다. 전자 장치는 현실 객체 및 사용자의 손을 포함하는 이미지를 획득할 수 있 다. 전자 장치는 이미지로부터 현실 객체 및 사용자의 손을 검출할 수 있다. 전자 장치는 현실 객체의 기 결정된 움직임의 발생 여부를 결정할 수 있다. 전자 장치는 기 결정된 움직임이 발 생한 것으로 결정된 것에 기초하여, 개인 인증 입력을 요구하는 인증 모드를 활성화할 수 있다. 본 개시의 일 실시예에 있어서, 인증 모드는 홍채 인증 모드일 수 있다. 예를 들어, 전자 장치는 센서(예컨대, 홍 채 센서)를 이용하여 사용자의 홍채를 인식할 수 있다. 예를 들어, 전자 장치가 가상 현실 디바이스 또는 증강 현실 디바이스인 경우, 센서는 좌안 센서 및 우안 센서를 포함할 수 있다. 좌안 센서는 사용자 의 좌안의 홍채를 향하여 배치될 수 있으며, 우안 센서는 사용자의 우안의 홍채를 향하여 배치될 수 있다. 전자 장치는 개인 인증 입력에 응답하여 기 결정된 가상 객체를 생성할 수 있다. 예를 들어, 전자 장치 는 홍채 인식 결과와 미리 저장된 사용자 정보를 비교할 수 있다. 홍채 인식 결과와 사용자 정보가 일치하 는 것으로 결정된 것에 기초하여, 전자 장치는 기 결정된 가상 객체을 생성할 수 있다. 예를 들어, 기 결정된 가상 객체는 사용자가 미리 저장한 사용자의 서명, 인장, 또는 인감일 수 있다. 전자 장치 는 디스플레이에 보안 문서 화면과 함께 기 결정된 가상 객체를 표시할 수 있다.도 28은 본 개시의 일 실시예에 따른 기 결정된 움직임과 개인 인증 입력에 기초하여 가상 객체를 생성하는 방 법을 보여주는 흐름도이다. 도 1 내지 27에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2, 26, 및 27을 참조하여, 도 28을 설명한다. 도 28을 참조하면, 도 26의 단계 S2630은 단계 S2810 내지 S2840을 포함할 수 있다. 본 개시의 일 실시예에 있 어서, 단계 S2810 내지 S2840은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S2630의 세부 단계들은 도 28에 도시된 바에 한정되지 않으며, 도 28에 도시된 단계 중 어 느 하나를 생략할 수도 있고, 도 28에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S2810에서, 전자 장치는 현실 객체의 인식된 현실 객체의 움직임이 기 결정된 움직임인 것으로 결정한 것에 기초하여, 개인 인증 입력을 요구하는 인증 모드를 활성화할 수 있다. 단계 S2820에서, 전자 장치는 센서를 이용하여 개인 인증 입력을 획득할 수 있다. 예를 들어, 센서 는 홍채 인식 센서일 수 있으나, 본 개시는 이에 제한되지 않으며, 사용자의 신원을 확인할 수 있는 임의 의 센서일 수 있다.. 예를 들어, 개인 인증 입력은 사용자의 홍채 인식 데이터일 수 있으나, 본 개시는 이제 제 한되지 않으며, 센서가 센싱한 임의의 데이터에 대응할 수 있다. 단계 S2830에서, 전자 장치는 개인 인증 입력에 응답하여, 기 결정된 가상 객체를 생성할 수 있다. 전자 장치는 메모리에 저장된 가상 객체를 생성할 수 있다. 예를 들어, 생성된 가상 객체 의 위치는 현실 객체의 움직임이 발생한 위치일 수 있으나, 사용자 입력에 따라 가상 객체의 위치는 달라질 수 있다. 단계 S2840에서, 전자 장치는 디스플레이에 기 결정된 가상 객체를 표시할 수 있다. 전자 장치 는 디스플레이에 보안 문서 화면에 가상 객체를 합성할 수 있다. 도 29는 본 개시의 일 실시예에 따른 검출 결과에 기초하여 기 결정된 센서를 활성화하는 기능을 수행하는 동작 을 설명하기 위한 개념도이다. 도 1 내지 28에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 29를 설명한다. 도 29를 참조하면, 전자 장치는 사용자가 착용하는 증강 현실 디바이스일 수 있다. 현실 객체는 사용자의 손에 의해 파지될 수 있다. 전자 장치는 카메라를 이용하여 사용자의 손이 현실 객체를 파지하는 장면을 포함하는 동영상을 획득할 수 있다. 전자 장치는 동영상에 기초하여 현실 객체 및 사용자의 손을 검출할 수 있다. 예를 들어, 전자 장치는 현실 객체의 종 류를 식별할 수 있다. 예를 들어, 전자 장치는 동영상을 입력으로 하는 인공지능 모델(예컨대, 객체 분류 모델)을 이용하여 현실 객체의 종류를 획득할 수 있다. 예를 들어, 도 29에 도시된 바와 같이, 전자 장치 는 현실 객체가 숟가락임을 식별할 수 있다. 전자 장치는 사용자의 손이 현실 객체를 파지하고 있음을 식별할 수 있다. 전자 장치는 검출 결과에 기초하여 기 결정된 적어도 하나의 센서를 활성화하는 기능을 수행할 수 있 다. 예를 들어, 전자 장치는 사용자의 손이 현실 객체인 숟가락을 파지하고 있음을 식별함에 기초하여, 마이크를 활성화할 수 있다. 전자 장치는 메모리 (또는 스토리지) 또는 외부 장치에 저장된 매핑 테이블에 액세스할 수 있다. 예를 들어, 매핑 테이블은 현실 객체의 종류와 활성화할 센서 간의 관계 정보를 포함할 수 있다. 예를 들어, 숟가락은 마이크에 매핑될 수 있다. 본 개시의 일 실시예에 있어서, 매핑 테이블은 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 전자 장치는 매핑 테이블 에 기초하여 현실 객체의 종류에 매핑된 센서를 활성화할 것을 결정할 수 있다. 전자 장치는 활성화 된 마이크를 이용하여 사용자 음성을 수신할 수 있다. 도 30은 본 개시의 일 실시예에 따른 전자 장치의 동작을 설명하기 위한 블록도이다. 도 1 내지 29에서 설명한 내용과 중복되는 내용은 생략한다. 전자 장치의 구성, 동작, 및 기능은 도 2의 전자 장치의 구성, 동작, 및 기능에 대응할 수 있다. 도 30를 참조하면, 일 실시예에 따른 전자 장치는 마이크, 카메라, 스피커, 및 프로세 서를 포함할 수 있다. 그러나, 도 30에 도시된 구성요소가 필수 구성요소인 것은 아니며, 전자 장치 는 구성요소를 생략하거나, 추가 구성요소를 더 포함할 수 있다. 예를 들어, 본 개시의 일 실시예에 따른전자 장치 전자 장치는, 도 2에 도시된 바와 같이, 카메라, 센서, 통신 인터페이스, 사용 자 인터페이스, 및 메모리 중 적어도 하나를 더 포함할 수 있다. 마이크, 카메라, 스피 커, 및 프로세서의 구성, 동작, 및 기능은 도 2의 마이크, 카메라, 스피커, 및 프 로세서의 구성, 동작, 및 기능에 대응되므로, 중복되는 내용은 생략한다. 카메라는 사용자의 손과 현실 객체를 포함하는 장면을 촬영하고, 이에 대응하는 동영상을 생성할 수 있다. 프로세서는 이미지로부터 사용자의 손과 현실 객체를 검출할 수 있다. 프로세서는 검출 결과 에 기초하여 현실 객체에 매핑된 마이크를 활성화할 수 있다. 활성화된 마이크는 사용자 음성을 수신할 수 있다. 마이크는 아날로그 신호인 사용자 음성을 샘플 링하여 디지털 신호로 변환할 수 있다. 마이크는 사용자 음성이 디지털 신호로 변환된 제1 오디오 신호를 프로세서에 전달할 수 있다. 프로세서는 현실 객체의 종류에 기초하여 제1 오디오 신호를 변조할 수 있다. 예를 들어, 프로세서는 주파수 대역 필터를 이용하여 제1 오디오 신호의 특정 주파수 대역을 강 조하거나 억제할 수 있다. 예를 들어, 프로세서는 제1 오디오 신호의 시간 스케일 또는 음량을 조정할 수 있다. 예를 들어, 프로세서는 제1 오디오 신호에 음향합성을 수행함으로써 음향효과를 추가할 수 있다. 본 개시의 일 실시예에 있어서, 프로세서는 현실 객체의 특성에 기초하여 제1 오디오 신호의 변조 방식을 결정할 수 있다. 본 개시의 일 실시예에 있어서, 프로세서는 메모리 (또는 스토리지) 또는 외부 장치에 저장된 매핑 테이블에 액세스할 수 있다. 예를 들어, 매핑 테이블은 현실 객체의 종류와 오디오 변조 방 식 간의 관계 정보를 포함할 수 있다. 예를 들어, 숟가락은 웅장하고 큰 음성에 매핑되고, 면도기는 날카롭고 째진 음성에 매핑되고, 장난감은 귀여운 음성에 매핑되고, 핫도그는 뚱뚱한 캐릭터 음성에 매핑될 수 있다. 본 개시의 일 실시예에 있어서, 매핑 테이블은 사용자 또는 제조사의 설정에 의해 미리 결정될 수 있다. 프로세서 는 매핑 테이블에 기초하여 현실 객체의 종류에 매핑된 오디오 변조 방식으로 제1 오디오 신호를 변조할 것을 결정할 수 있다. 프로세서는 제1 오디오 신호를 변조한 제2 오디오 신호를 생성할 수 있다. 스피커는 제2 오디오 신호를 수신할 수 있다. 스피커는 제2 오디오 신호를 아날로그 신호로 변환할 수 있다. 스피커는 변환된 아날로그 신호인 변조된 사용자 음성을 공간에 출력할 수 있다. 도 31은 본 개시의 일 실시예에 따른 검출 결과에 기초하여 기 결정된 센서를 활성화하는 기능을 수행하는 방법 을 보여주는 흐름도이다. 도 1 내지 27에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2, 3 및 30을 참조하여, 도 31을 설명한다. 도 31을 참조하면, 도 3의 단계 S330는 단계 S3110을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S3110은 전자 장치(200, 3000) 또는 전자 장치(200, 3000)의 프로세서(250, 3050)에 의해 수행될 수 있다. 단계 S3110에서, 전자 장치는 기 결정된 적어도 하나의 센서를 활성화하는 기능을 수행할 수 있다. 본 개 시의 일 실시예에 있어서, 전자 장치는 활성화된 적어도 하나의 센서를 이용하여 센서 데이터를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체의 형상, 형태, 색채, 재질, 및 기능 중 적어도 일부에 기초하여 센서 데이터를 변조할 수 있다. 도 32는 본 개시의 일 실시예에 따른 현실 객체를 전자 장치의 입력 도구로 등록하는 방법을 보여주는 흐름도이 다. 도 1 및 31에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 32를 설명한다. 도 32를 참조하면, 현실 객체를 전자 장치의 입력 도구로 등록하는 방법은 단계 S3210 내지 S3240을 포함 할 수 있다. 본 개시의 일 실시 예에 있어서, 단계 S3210 내지 S3240은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시의 일 실시예에 따른 전자 장치가 현실 객체를 입력 도구로 이용하는 방법은 도 32에 도시된 바에 한정되지 않으며, 도 32에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 32에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S3210에서, 전자 장치는 (전자 장치와 통신하지 않는) 현실 객체를 포함하는 적어도 하나의 이 미지를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 카메라를 이용하여 현실 객체를 포함하는 적어도 하나의 이미지를 획득할 수 있다.단계 S3220에서, 전자 장치는 적어도 하나의 이미지에 기초하여 현실 객체를 인식(또는 검출)할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 적어도 하나의 이미지를 입력으로 하는 인공지능 모델을 이용 하여 현실 객체의 위치 정보 및 경계 정보를 포함하는 데이터를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 적어도 하나의 이미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체의 종류 를 포함하는 데이터를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 적어도 하나의 이미지를 입력으로 하는 인공지능 모델을 이용하여 현실 객체를 3D 렌더링한 데이터를 획득할 수 있다. 단계 S3230에서, 전자 장치는 현실 객체를 전자 장치의 입력 도구로 등록(또는 저장)할 수 있다. 전 자 장치는 현실 객체에 관한 정보를 포함하는 데이터를 메모리에 저장할 수 있다. 본 개시의 일 실시 예에 있어서, 전자 장치가 등록된 현실 객체를 검출하는 경우, 전자 장치는 현실 객체에 매핑된 기능 을 수행할 수 있다. 단계 S3240에서, 전자 장치는 등록된 현실 객체와 사용자의 손과의 인터랙션을 기 정의된 기능과 매핑할 수 있다. 본 개시의 일 실시예에 있어서, 적어도 하나의 이미지는 객체를 파지하는 사용자의 손을 포함할 수 있 다. 전자 장치는 적어도 하나의 이미지로부터 사용자의 손을 검출할 수 있다. 전자 장치는 현실 객체 의 형태, 사용자의 손의 형태, 사용자 손과 현실 객체 간의 인터랙션 중 적어도 하나에 기초하여 상기 현실 객 체를 상기 입력 도구로 이용하는 기 정의된 기능과 매핑할 수 있다. 전자 장치는 현실 객체의 형태, 사용 자의 손의 형태, 사용자 손과 현실 객체 간의 인터랙션 중 적어도 하나와 기 정의된 기능 간의 관계 정보를 포 함하는 매핑 테이블울 메모리에 저장할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치가 등록된 기 정의된 기능에 대응하는 현실 객체의 형태, 사용자의 손의 형태, 사용자 손과 현실 객체 간의 인터랙션 중 적어도 하나를 검출하는 경우, 전자 장치는 등록된 기 정의된 기능을 식별하고 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체를 복수의 부위들로 분할할 수 있다. 전자 장치 는 복수의 부위들 중 사용자의 손에 의해 폐색된 적어도 하나의 부위를 검출할 수 있다. 전자 장치는 폐색된 적어도 하나의 부위에 기초하여, 현실 객체를 입력 도구로 이용하는 기 정의된 기능을 등록할 수 있다. 전자 장치는 현실 객체의 복수의 부위들 중 사용자의 손에 의해 폐색된 적어도 하나의 부위와 기 정의된 기능 간의 관계 정보를 포함하는 매핑 테이블을 메모리에 저장할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치가 등록된 기 정의된 기능에 대응하는 복수의 부위들 중 사용자의 손에 의해 폐색된 적어도 하나 의 부위를 검출하는 경우, 전자 장치는 등록된 기 정의된 기능을 식별하고 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체를 복수의 부위들로 분할할 수 있다. 전자 장치 는 분할 결과에 기초하여, 사용자의 손이 현실 객체를 파지하는 위치를 결정할 수 있다. 전자 장치는 결정된 위치에 기초하여 현실 객체를 입력 도구로 이용하는 기 정의된 기능을 등록할 수 있다. 전자 장치 는 사용자의 손이 현실 객체를 파지하는 위치와 기 정의된 기능 간의 관계 정보를 포함하는 매핑 테이블을 메모 리에 저장할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치가 등록된 기 정의된 기능에 대응하 는 사용자의 손이 현실 객체를 파지하는 위치를 검출하는 경우, 전자 장치는 등록된 기 정의된 기능을 식 별하고 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체의 복수의 부위들 중 어느 부위를 향하여 사용자의 손이 현실 객체를 파지하는지를 나타내는 파지 방향을 결정할 수 있다. 전자 장치는 결정된 파지 방향에 기초하여 기 정의된 기능을 등록할 수 있다. 전자 장치는 사용자의 손이 현실 객체를 파지하는 방향 및 파 지하는 위치 중 적어도 하나와 기 정의된 기능 간의 관계 정보를 포함하는 매핑 테이블을 메모리에 저장할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치가 등록된 기 정의된 기능에 대응하는 사용자의 손이 현실 객체를 파지하는 방향 및 파지하는 위치 중 적어도 하나를 검출하는 경우, 전자 장치는 등록된 기 정 의된 기능을 식별하고 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 손이 복수의 부위들 중 적어도 하나의 부위를 터지 하는 동작을 검출할 수 있다. 전자 장치는 검출된 동작에 기초하여, 현실 객체를 입력 도구로 이용하는 기 정의된 기능을 등록할 수 있다. 전자 장치는 사용자의 손이 복수의 부위들 중 적어도 하나의 부위를 터지 하는 동작과 기 정의된 기능 간의 관계 정보를 포함하는 매핑 테이블을 메모리에 저장할 수 있다. 본 개시 의 일 실시예에 있어서, 전자 장치가 등록된 기 정의된 기능에 대응하는 사용자의 손이 복수의 부위들 중 적어도 하나의 부위를 터지하는 동작을 검출하는 경우, 전자 장치는 등록된 기 정의된 기능을 식별하고 수 행할 수 있다.도 33은 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 기 등록된 기 능을 수행하는 방법을 설명하기 위한 개념도이다. 도 1 내지 32에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 33를 설명한다. 도 33을 참조하면, 전자 장치는 제1 카메라(210a)를 이용하여 현실 공간 내의 현실 객체 및 사용자 의 손을 촬영하여 이미지를 획득할 수 있다. 전자 장치는 이미지로부터 사용자의 손과 인터 랙션하는 현실 객체를 인식할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 손 에 의해 쥐어진 현실 객체를 인식할 수 있다. 도 33에서, 현실 객체는 빨대인 것으로 도시되었 으나, 본 개시는 이에 한정되지 않으며, 현실 객체는 사람이 손으로 잡을 수 있는 크기의 물체일 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 현실 객체와 사용자의 입 간의 거리를 획득(측정 또 는 추정)할 수 있다. 전자 장치는 현실 객체(또는 현실 객체의 일측)과 사용자의 입 간의 거리가 기-정의된 임계 값보다 작거나 같은지를 결정할 수 있다. 현실 객체과 사용자의 입 간의 거리 가 기-정의된 임계 값보다 작거나 같은 것으로 결정한 것에 기초하여, 전자 장치는 현실 객체를 기- 등록된 기능을 수행하는 입력 도구로 이용할 것을 결정할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체를 기-등록된 기능을 수행하는 입력 도구로 이용할 것을 결정한 것에 기초하여, 전자 장치는 제2 카메라(210b)를 활성화할 수 있다. 전자 장치는 제2 카메라(210b)를 이용하여 사용자의 볼을 촬영한 이미지를 획득할 수 있다. 제2 카메라(210b)는 사용자의 볼을 촬영 하는 시야각을 갖도록 전자 장치에 배치될 수 있다. 전자 장치는 사용자가 현실 객체를 사용자의 입에 가까이 한 상태에서 숨을 들이 마시거나(들 숨) 숨을 내뱉는(날숨) 동작을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 이미지로부터 사용자의 볼의 움직임 또는 사용자의 볼의 형태를 검출할 수 있다. 예를 들어, 전자 장치는 사용자의 볼이 팽창되는 움직임 또는 사용자의 볼이 팽창된 형태를 검출할 수 있다. 예를 들어, 전 자 장치는 사용자의 볼이 수축되는 움직임 또는 사용자의 볼이 수축된 형태를 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 마이크를 이용하여 사용자의 숨소리를 수신할 수 있다. 마 이크는 사용자의 숨소리를 전기적 신호인 오디오 신호로 변환할 수 있다. 전자 장치는 사용자의 숨 소리에 대응하는 오디오 신호를 들숨의 소리 또는 날숨의 소리 중 하나로 분류할 수 있다. 이 경우, 제2 카메라 (210b)는 생략될 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 카메라를 포함할 수 있다. 카메라는 제1 카메라 (210a)를 포함할 수 있다. 제1 카메라(210a)의 방향은 사용자의 눈이 바라보는 방향과 일치할 수 있다. 제1 카메라(210a)는 사용자 전방의 사용자의 손 및 현실 객체를 촬영할 수 있다. 카메라는 제 2 카메라(210b)를 포함할 수 있다. 제2 카메라(210b)는 사용자의 볼을 촬영하는 시야각을 갖도록 전자 장 치에 배치될 수 있다. 제2 카메라(210b)는 사용자의 볼을 촬영할 수 있다. 도 34a 및 34b는 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 가상 객체를 제어하는 기능을 수행하는 방법을 설명하기 위한 개념도이다. 도 1 내지 33에서 설명한 내용과 중 복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 34a 및 34b를 설명한다. 도 34a 및 34b를 참조하면, 전자 장치는 제1 카메라(210a)를 이용하여 현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 이미지를 획득할 수 있다. 전자 장치는 획득된 이미지로부터 사용자의 손과 인터랙션하는 현실 객체를 인식할 수 있다. 예를 들어, 전자 장치는 획득된 이미지로부터 현실 객체를 잡는 사용자의 손을 인식할 수 있다. 전자 장치는 인식 결과에 기초하여 가상 객체를 생성할 수 있다. 예를 들어, 가상 객체는 거품 형상일 수 있으나, 본 개시는 이에 한정되지 않으며, 가상 객체의 형상은 사용자 또는 제조사의 설정에 따라 미리 결정될 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 인식 결과에 기초하여 제2 카메라(210b)를 활성화할 수 있으 나, 본 개시는 이에 한정되지 않으며, 제2 카메라(210b)는 이미 활성화된 상태일 수 있다. 전자 장치는 제2 카메라(210b)를 이용하여 사용자의 볼을 촬영하여 이미지를 획득할 수 있다. 전자 장치는 획득된 이미지로부터 사용자의 볼의 움직임 또는 사용자의 볼의 형태를 검출할 수 있다. 전자 장치는 사용자의 볼의 움직임 또는 사용자의 볼의 형태를 검출함으로써, 사용자의 날숨 또는 들숨을 인 식할 수 있다. 도 34a를 참조하면, 가상 객체는 현실 객체의 일측에 접촉될 수 있다. 본 개시의 일 실시예에 있어 서, 전자 장치는 사용자의 날숨을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 볼이 팽창되는 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사 용자의 볼이 팽창된 형태를 검출할 수 있다. 전자 장치는 검출 결과에 기초하여 가상 객체의 크기를 확대할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 들숨을 인식할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 볼이 수축되는 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있 어서, 전자 장치는 사용자의 볼이 수축된 형태를 검출할 수 있다. 전자 장치는 검출 결과에 기 초하여 가상 객체의 크기를 축소할 수 있다. 도 34b를 참조하면, 가상 객체는 현실 객체의 일측과 기 정의된 거리만큼 이격될 수 있다. 본 개시 의 일 실시예에 있어서, 전자 장치는 사용자의 날숨을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 볼이 팽창되는 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전 자 장치는 사용자의 볼이 팽창된 형태를 검출할 수 있다. 전자 장치는 검출 결과에 기초하여, 가상 객체와 현실 객체간의 거리가 멀어지도록 가상 객체를 이동시킬 수 있다. 예를 들어, 가상 객체는 제1 위치(L1)에서 제2 위치(L2)로 이동할 수 있다. 제1 위치(L1)는 제2 위치(L2)보다 현실 객체에 가까울 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 들숨을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 볼이 수축되는 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있 어서, 전자 장치는 사용자의 볼이 수축된 형태를 검출할 수 있다. 전자 장치는 검출 결과에 기 초하여, 가상 객체와 현실 객체간의 거리가 가까워지도록 가상 객체를 이동시킬 수 있다. 예 를 들어, 가상 객체는 제3 위치(L3)에서 제4 위치(L4)로 이동할 수 있다. 제3 위치(L3)는 제4 위치(L4)보 다 현실 객체에 멀 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 가상 현실 상의 가상 객체 의 움직임을 애니메이션으로 표현할 수 있다. 도 35a 및 35b는 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기 초하여 가상 스크린의 크기를 제어하는 기능을 수행하는 방법을 설명하기 위한 개념도이다. 도 1 내지 34b에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 35a 및 35b를 설명한다. 도 35a 및 35b를 참조하면, 전자 장치는 가상 스크린을 가상 공간 상에 표시할 수 있다. 전자 장치 는 사용자의 볼의 움직임 또는 사용자의 볼의 형태를 검출할 수 있다. 전자 장치는 사용 자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 가상 스크린의 크기를 조절할 수 있 다. 도 35a를 참조하면, 전자 장치는 사용자의 날숨을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전 자 장치는 사용자의 볼이 팽창되는 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 볼이 팽창된 형태를 검출할 수 있다. 전자 장치는 검출 결과에 기초하여 가상 스크린의 크기를 확대할 수 있다. 도 35b를 참조하면, 전자 장치는 사용자의 들숨을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전 자 장치는 사용자의 볼이 수축되는 움직임을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 사용자의 볼이 수축된 형태를 검출할 수 있다. 전자 장치는 검출 결과에 기초하여 가상 스크린의 크기를 축소할 수 있다. 도 35a 및 35b에 도시된 바와 달리, 전자 장치는 검출 결과에 기초하여 가상 스크린의 위치를 조절 할 수 있다. 예를 들어, 전자 장치는 사용자의 볼이 확대되는 움직임 사용자의 볼이 확대된 형태에 기초하여 가상 스크린의 위치를 전자 장치에 먼 위치로 이동시킬 수 있다. 예를 들어, 전자 장치는 사용자의 볼이 수축되는 움직임 사용자의 볼이 수축된 형태에 기초하여 가상 스크린의 위치를 전자 장치에 가까운 위치로 이동시킬 수 있다. 도 36a 및 36b는 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 기 식 별된 기능을 수행하거나, 수행된 기능을 취소(undo)하는 기능을 수행하는 방법을 설명하기 위한 개념도이다. 도 1 내지 35b에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2를 참조하여, 도 36a 및 36b를 설명한다. 도 36a를 참조하면, 전자 장치는 디스플레이를 통해 이미지 편집 창을 표시할 수 있다. 도 4a 내지 20에 도시된 바와 같이, 전자 장치는 현실 공간 내의 현실 객체 및 사용자의 손을 촬영 하여 이미지를 획득할 수 있다. 전자 장치는 획득된 이미지로부터 사용자의 손과 인터랙션하는 현 실 객체를 인식할 수 있다. 전자 장치는 인식된 현실 객체를 입력 도구로 사용하여 가상 객체 를 생성하는 기능을 식별할 수 있다. 전자 장치는 현실 객체의 적어도 일부(예컨대, 연필의 팁 부분)의 움직임에 기초하여 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치 는 이미지 편집 창에 표시되는 대상 이미지 상에 가상 객체를 생성할 수 있다. 전자 장치는 현실 객체와 사용자의 입 간의 거리를 획득(측정 또는 추정)할 수 있다. 전자 장치 는 현실 객체와 사용자의 입 간의 거리가 기-정의된 임계 값보다 작거나 같은지를 결정할 수 있다. 현실 객체과 사용자의 입 간의 거리가 기-정의된 임계 값보다 작거나 같은 것으로 결정한 것에 기초하여, 전자 장치는 현실 객체를 기-등록된 기능을 수행하는 입력 도구로 이용할 것을 결정할 수 있다. 전자 장치는 제2 카메라(210b)를 이용하여 사용자의 볼을 촬영한 이미지를 획득할 수 있다. 본 개시 의 일 실시예에 있어서, 현실 객체를 기-등록된 기능을 수행하는 입력 도구로 이용할 것을 결정한 것에 기초하여, 전자 장치는 제2 카메라(210b)를 활성화할 수 있다. 전자 장치는 사용자가 현실 객체를 사용자의 입에 가까이 한 상태에서 숨을 내뱉는(날숨) 동 작을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 이미지로부터 사용자의 볼의 움 직임 또는 사용자의 볼의 형태를 검출할 수 있다. 전자 장치는 사용자의 볼이 팽창되는 움직 임 또는 사용자의 볼이 팽창된 형태를 검출할 수 있다. 전자 장치는 사용자의 볼이 팽창되는 움직임 또는 사용자의 볼이 팽창된 형태에 기초하여 가상 객체를 삭제할 수 있다. 예를 들어, 전자 장치는 사용자의 볼이 팽창되는 움직임 또는 사용자의 볼이 팽창된 형태에 기초하여, 이미지 편집 창의 대상 이미지 상에 생성된 모든 가상 객체를 삭제할 수 있다. 도 36b를 참조하면, 전자 장치는 디스플레이를 통해 이미지 편집 창을 표시할 수 있다. 전자 장치는 사용자가 현실 객체를 사용자의 입에 가까이 한 상태에서 숨을 들이 마시는(들숨) 동 작을 검출할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 이미지로부터 사용자의 볼의 움 직임 또는 사용자의 볼의 형태를 검출할 수 있다. 전자 장치는 사용자의 볼이 수축되는 움직 임 또는 사용자의 볼이 수축된 형태를 검출할 수 있다. 전자 장치는 사용자의 볼이 수축되는 움직임 또는 사용자의 볼이 수축된 형태에 기초하여 기 수행된 기능을 취소할 수 있다. 예를 들어, 전자 장치는 가상 객체를 삭제하는 기능을 취소할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 취소에 기초하여 대상 이미지 상에 가상 객체를 생성할 수 있다. 예를 들어, 전자 장치는 이전 단계에서 생성된 가상 객체를 삭제하는 기능을 수행할 때, 가상 객체에 대한 정보를 메모리(예컨대, 버퍼 메모리)에 저장할 수 있다. 전자 장치는 사용자 의 볼이 수축되는 움직임 또는 사용자의 볼이 수축된 형태에 기초하여 메모리에 저장된 가상 객체 에 대한 정보를 로드할 수 있다. 전자 장치는 로드된 가상 객체에 대한 정보에 기초하여 대상 이미지 상에 가상 객체를 생성할 수 있다. 도 37은 본 개시의 일 실시예에 따른 현실 객체와 사용자의 입 간의 거리에 기초하여 기 등록된 기능을 식별하 는 방법을 보여주는 흐름도이다. 도 1 내지 36b에서 설명한 내용과 중복되는 내용은 생략한다. 설명의 편의를 위해, 도 2 및 도 3을 참조하여, 도 37을 설명한다. 도 37을 참조하면, 도 3의 단계 S330는 단계 S3710 및 S3720을 포함할 수 있다. 본 개시의 일 실시예에 있어서, 단계 S3710 및 S3720은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S340의 세부 단계들은 도 37에 도시된 바에 한정되지 않으며, 도 37에 도시된 단계 중 어느 하나 를 생략할 수도 있고, 도 37에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S3710에서, 전자 장치는 현실 객체와 사용자의 입 간의 거리가 기 정의된 임계 값보다 작거나 같은지 를 결정할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 획득된 이미지 및/또는 센서 데이터(예컨 대, 깊이 값)에 기초하여 현실 객체와 사용자의 입 간의 거리를 측정할 수 있다. 현실 객체와 사용자의 입 간의 거리가 기 정의된 임계 값보다 큰 경우, 절차는 종료된다. 현실 객체와 사용자의 입 간의 거리가 기 정의된 임 계 값보다 작거나 같은 경우, 절차는 S3720으로 이동한다. 단계 S3720에서, 전자 장치는 현실 객체와 사용자의 입 간의 거리가 기 정의된 임계 값보다 작거나 같은 것으로 결정한 것에 기초하여, 인식된 현실 객체를 입력 도구로 하는 기 등록된 기능을 식별할 수 있다. 예를 들어, 기 등록된 기능은 사용자의 볼의 형태 또는 사용자의 볼의 움직임에 기초하여 기 등록된 서브 기능을 식 별하고 수행하는 기능일 수 있다. 그러나 본 개시는 이에 한정되지 않으며, 기 등록된 기능은 제1 서브 기능 및 제2 서브 기능을 포함할 수 있다. 예를 들어, 제1 서브 기능은 가상 객체를 생성하는 기능일 수 있다. 예를 들 어, 제2 서브 기능은 사용자의 볼의 형태 또는 사용자의 볼의 움직임에 기초하여 제1 서브 기능에 의해 생성된 가상 객체를 제어하는 기능일 수 있다. 도 38은 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 기 등록된 기 능을 수행하는 방법을 보여주는 흐름도이다. 도 1 내지 37에서 설명한 내용과 중복되는 내용은 생략한다. 설명 의 편의를 위해, 도 2 및 도 3을 참조하여, 도 38을 설명한다. 도 38을 참조하면, 도 3의 단계 S340는 단계 S3810 내지 S3850을 포함할 수 있다. 본 개시의 일 실시예에 있어 서, 단계 S3810 내지 S3850은 전자 장치 또는 전자 장치의 프로세서에 의해 수행될 수 있다. 본 개시에 따른 단계 S340의 세부 단계들은 도 38에 도시된 바에 한정되지 않으며, 도 38에 도시된 단계 중 어느 하나를 생략할 수도 있고, 도 38에 도시되지 않은 단계를 더 포함할 수도 있다. 단계 S3810에서, 전자 장치는 식별 결과에 기초하여 기 결정된 적어도 하나의 센서를 활성화할 수 있다. 예를 들어, 전자 장치는 제1 카메라 및 제2 카메라를 포함할 수 있다. 예를 들어, 제1 카메라는 현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 제1 이미지를 획득할 수 있다. 예를 들어, 제2 카메라는 사용자의 볼을 촬영하여 제2 이미지를 획득할 있다. 전자 장치는 식별 결과에 기초하여 제2 카메라를 활성화할 수 있다. 그러나 본 개시는 이에 한정되지 않으며, 제2 카메라는 생략되고 제1 카메라가 사용자의 볼을 촬영할 수 도 있고, 제2 카메라는 이미 활성화되어 있을 수 있다. 본 개시의 일 실시예에 있어서, 단계 S3810은 생략될 수 있다. 단계 S3820에서, 전자 장치는 사용자의 볼을 촬영한 제2 이미지를 획득할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치는 제1 카메라 및 제2 카메라 중 적어도 하나를 이용하여 사용자의 볼을 촬영할 수 있다. 단계 S3830에서, 전자 장치는 제2 이미지로부터 사용자의 볼의 움직임을 검출할 수 있다. 본 개시의 일 실 시예에 있어서, 전자 장치는 제2 이미지로부터 사용자의 볼의 형태를 검출할 수 있다. 예를 들어, 전자 장 치는 제2 이미지로부터 사용자의 볼이 팽창되거나 수축되는 움직임(또는 형태)를 검출할 수 있다. 단계 S3840에서, 전자 장치는 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 기 등록된 서브 기능을 식별할 수 있다. 예를 들어, 기 등록된 서브 기능은 가상 객체를 제어(예컨대, 가상 객체의 크기 또는 위치를 제어)하는 기능, 가상 스크린(또는 가상 윈도우로도 지칭될 수 있음)를 제어(예컨대, 가상 스크린의 크 기 또는 위치를 제어)하는 기능, 가상 객체를 삭제하는 기능, 기 수행된 기능을 취소(undo)하는 기능, 및 취소 된 기능을 다시 실행(redo)하는 기능 중 적어도 하나를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 사용자 의 볼의 움직임 또는 사용자의 볼의 형태에 대응하는 서브 기능이 미리 등록되어 있을 수 있다. 본 개시의 일 실시예에 있어서, 사용자의 볼이 팽창되는 움직임(또는 형태)에 대응하는 제1 서브 기능과 사용자의 볼이 수축 되는 움직임(또는 형태)에 대응하는 제2 서브 기능은 하나의 기능 쌍으로 매핑될 수 있다. 단계 S3850에서, 전자 장치는 기 등록된 서브 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 전자 장치가 제공될 수 있다. 전자 장치는 현실 공간 내의 현실 객체 및 사용자 의 손을 촬영하여 이미지를 획득하는 카메라를 포함할 수 있다. 전자 장치는 적어도 하나의 인스트럭션을 저장 하는 메모리를 포함할 수 있다. 전자 장치는 상기 메모리에 저장된 상기 적어도 하나의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 상기 획득된 이미지로부터 상기 사 용자의 손과 인터랙션하는 상기 현실 객체를 인식할 수 있다. 상기 적어도 하나의 프로세서는 상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별할 수 있다. 상기 적어도 하나의 프로세서는 상기 식별된 기 등록된 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 획득된 이미지로부터 상기 현실 객체를 검 출할 수 있다. 상기 적어도 하나의 프로세서는 상기 검출된 현실 객체를 복수의 부위들로 분할할 수 있다. 상기 적어도 하나의 프로세서는 상기 복수의 부위들 중 상기 사용자의 손에 의해 폐색된 적어도 하나의 부위를 검출 할 수 있다. 상기 폐색된 적어도 하나의 부위에 기초하여 상기 기 등록된 기능을 식별할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 획득된 이미지로부터 상기 현실 객체를 검 출할 수 있다. 상기 적어도 하나의 프로세서는 상기 검출된 현실 객체를 복수의 부위들로 분할할 수 있다. 상기 적어도 하나의 프로세서는 상기 분할 결과에 기초하여 상기 사용자의 손이 상기 현실 객체를 파지하는 위치를 결정할 수 있다. 상기 적어도 하나의 프로세서는 상기 결정된 위치에 기초하여 상기 기 등록된 기능을 식별할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는, 상기 복수의 부위들 중 어느 부위를 향하여 상 기 사용자의 손이 상기 현실 객체를 파지하는지를 나타내는 파지 방향을 결정할 수 있다. 상기 적어도 하나의 프로세서는 상기 결정된 파지 방향에 기초하여 상기 기 등록된 기능을 식별할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 획득된 이미지로부터 상기 현실 객체를 검 출할 수 있다. 상기 적어도 하나의 프로세서는 상기 검출된 현실 객체를 복수의 부위들로 분할할 수 있다. 상기 적어도 하나의 프로세서는 상기 사용자의 손이 상기 복수의 부위들 중 적어도 하나의 부위를 터치하는 동작을 인식할 수 있다. 상기 적어도 하나의 프로세서는 상기 인식된 동작에 기초하여 상기 기 등록된 기능을 식별할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 획득된 이미지에 기초하여 상기 현실 객체 의 움직임을 추적할 수 있다. 상기 적어도 하나의 프로세서는 상기 추적된 움직임에 기초하여 가상 객체를 생성 하거나 삭제하는 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 획득된 이미지로부터 상기 현실 객체의 적 어도 일부의 색상 및 크기 중 적어도 하나를 인식할 수 있다. 상기 적어도 하나의 프로세서는 상기 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나에 기초하여 상기 가상 객체의 색상 및 크기 중 적어도 하나를 결정 할 수 있다. 상기 적어도 하나의 프로세서는 상기 결정된 색상 및 크기 중 적어도 하나를 갖는 상기 가상 객체 를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 획득된 이미지로부터 상기 현실 객체가 가 리키는 대상 객체를 인식할 수 있다. 상기 적어도 하나의 프로세서는 상기 대상 객체의 색상, 형태, 및 형상 중 적어도 하나에 기초하여 상기 가상 객체의 색상, 형태, 및 형상 중 적어도 하나를 결정할 수 있다. 상기 적어도 하나의 프로세서는 상기 결정된 상기 색상, 형태, 및 형상 중 적어도 하나를 갖는 상기 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 가상 객체에 대응하는 가상 이미지를 입력 으로 하는, 인공지능 모델을 이용하여 상기 가상 객체를 분류할 수 있다. 상기 적어도 하나의 프로세서는 상기 분류 결과에 기 매핑된 색상을 상기 가상 객체의 색상으로 결정할 수 있다. 상기 적어도 하나의 프로세서는 상 기 결정된 색상을 갖는 상기 가상 객체를 생성할 수 있다. 본 개시의 일 실시예에 있어서, 상기 기 등록된 기능은, 상기 이미지로부터 상기 현실 객체를 인식하고, 상기 인식된 현실 객체를 상기 입력 도구로 등록하고, 상기 등록된 현실 객체와 상기 사용자의 손과의 인터랙션을 기 정의된 기능과 매핑함으로써 등록될 수 있다.본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 사용자의 손과 상기 현실 객체 간의 거리 를 측정할 수 있다. 상기 적어도 하나의 프로세서는 상기 거리가 기 정의된 임계 값을 초과하지 않은 경우, 상 기 인식된 현실 객체를 입력 도구로 사용하는 것으로 결정할 수 있다. 상기 적어도 하나의 프로세서는 상기 거 리가 기 정의된 임계 값을 초과한 경우, 상기 인식된 현실 객체를 입력 도구로 사용하지 않는 것으로 결정할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 인식된 현실 객체의 색상, 재질, 형태, 상 기 사용자의 손의 형태, 및 상기 사용자의 손의 위치 중 적어도 하나에 기초하여 상기 가상 객체의 성능 값을 결정하는 기능을 수행할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 인식된 현실 객체의 움직임을 검출할 수 있다. 상기 적어도 하나의 프로세서는 상기 검출된 움직임이 기 결정된 움직임인지 결정할 수 있다. 상기 적어 도 하나의 프로세서는 상기 검출된 움직임이 상기 결정된 움직임인 것으로 결정한 것에 기초하여, 기 결정된 가 상 객체를 생성하는 기능을 수행할 수 있다.. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 상기 인식된 현실 객체의 움직임이 상기 기 결 정된 움직임인 것으로 결정한 것에 기초하여, 개인 인증 입력을 요구하는 인증 모드를 활성화할 수 있다. 상기 적어도 하나의 프로세서는 개인 인증 입력을 획득할 수 있다. 상기 적어도 하나의 프로세서는 상기 개인 인증 입력에 응답하여 상기 기 결정된 가상 객체를 생성할 수 있다. 상기 적어도 하나의 프로세서는 디스플레이에 기 결정된 가상 객체를 표시할 수 있다. 본 개시의 일 실시예에 있어서, 상기 적어도 하나의 프로세서는 기 결정된 적어도 하나의 센서를 활성화할 수 있다. 본 개시의 일 실시예에 있어서, 본 개시의 일 실시예에 있어서, 전자 장치가 제공될 수 있다. 전자 장치는 현실 공간 내의 현실 객체를 촬영하여 이미지를 획득하는 카메라를 포함할 수 있다. 전자 장치는 적어도 하나의 인스 트럭션을 저장하는 메모리를 포함할 수 있다. 전자 장치는 상기 메모리에 저장된 상기 적어도 하나의 인스트럭 션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 상기 획득된 이미지 로부터 상기 현실 객체를 인식할 수 있다. 상기 적어도 하나의 프로세서는 상기 인식된 현실 객체를 입력 도구 로 등록할 수 있다. 상기 적어도 하나의 프로세서는 상기 등록된 현실 객체와 사용자의 손과의 인터랙션을 기 정의된 기능과 매핑할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체를 전자 장치의 입력 도구로 이용하는 방법이 제공될 수 있다. 방법은 현실 공간 내의 현실 객체 및 사용자의 손을 촬영하여 이미지를 획득하는 단계를 포함할 수 있다. 방법은 상기 획득된 이미지로부터 상기 사용자의 손과 인터랙션하는 상기 현실 객체를 인식하는 단계를 포함할 수 있다. 방 법은 상기 인식된 현실 객체를 입력 도구로 사용하는 기 등록된 기능을 식별하는 단계를 포함할 수 있다. 방법 은 상기 식별된 기 등록된 기능을 수행하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 있어서, 현실 객체를 전자 장치의 입력 도구로 이용하는 방법을 컴퓨터에서 수행하기 위 한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체가 제공될 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서,‘비일 시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5a 도면5b 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14a 도면14b 도면14c 도면14d 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34a 도면34b 도면35a 도면35b 도면36a 도면36b 도면37 도면38"}
{"patent_id": "10-2023-0097799", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시는, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호 (reference numerals)들은 구조적 구성요소(structural elements)를 의미한다. 도 1은 본 개시의 일 실시예에 따른 현실 객체를 전자 장치의 입력 도구로 이용하는 동작을 설명하기 위한 개 념도이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치의 구성 요소를 보여주는 블록도이다. 도 3은 본 개시의 일 실시예에 따른 현실 객체를 전자 장치의 입력 도구로 이용하는 방법을 보여주는 흐름도이 다. 도 4a 및 4b는 본 개시의 일 실시예에 따른 현실 객체를 이용하여 가상 객체를 생성하거나 삭제하는 동작을 설 명하기 위한 개념도이다. 도 5a 및 5b는 본 개시의 일 실시예에 따른 현실 객체를 이용하여 가상 객체를 생성하거나 삭제하는 동작을 설 명하기 위한 개념도이다. 도 6은 본 개시의 일 실시예에 따른 입력 도구로 이용되는 현실 객체의 적어도 일부의 색상에 기초하여 가상 객 체의 색상을 결정하는 동작을 설명하기 위한 개념도이다. 도 7은 본 개시의 일 실시예에 따른 현실 객체가 가리키는 대상 객체의 색상에 기초하여 가상 객체의 색상을 결 정하는 동작을 설명하기 위한 개념도이다. 도 8은 본 개시의 일 실시예에 따른 가상 객체의 형태에 기초하여 가상 객체의 색상을 결정하는 동작을 설명하 기 위한 개념도이다. 도 9는 본 개시의 일 실시예에 따른 현실 객체의 적어도 일부의 크기에 기초하여 가상 객체의 크기를 결정하는 동작을 설명하기 위한 개념도이다. 도 10은 본 개시의 일 실시예에 따른 현실 객체의 적어도 일부를 추적함으로써 가상 객체를 생성하거나 삭제하 는 기능을 수행하는 방법을 보여주는 흐름도이다. 도 11은 본 개시의 일 실시예에 따른 현실 객체의 적어도 일부의 색상 및 크기 중 적어도 하나에 기초하여 가상 객체의 색상 및 크기 중 적어도 하나를 결정하는 방법을 보여주는 흐름도이다. 도 12는 본 개시의 일 실시예에 따른 현실 객체가 가리키는 대상 객체의 색상, 형태, 및 형상에 기초하여 가상 객체의 색상, 형태, 및 형상을 결정하는 방법을 보여주는 흐름도이다.도 13은 본 개시의 일 실시예에 따른 현실 이미지에 가상 객체를 합성한 이미지를 획득하는 방법을 보여주는 흐 름도이다. 도 14a 내지 14d는 본 개시의 일 실시예에 따른 현실 객체의 폐색된 부위에 기초하여 기 등록된 기능을 식별하 는 동작을 설명하기 위한 개념도이다. 도 15는 본 개시의 일 실시예에 따른 현실 객체의 폐색된 부위에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 16은 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 동작을 설명하기 위한 개념도이다. 도 17은 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 18은 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 19는 본 개시의 일 실시예에 따른 사용자의 손이 현실 객체를 파지하는 방식에 기초하여 기 등록된 기능을 식별하는 방법을 보여주는 흐름도이다. 도 20은 본 개시의 일 실시예에 따른 사용자의 손과 현실 객체 간의 거리에 따라 기 등록된 기능을 수행할지 여 부를 결정하는 방법을 보여주는 흐름도이다. 도 21은 본 개시의 일 실시예에 따른 현실 객체의 특성에 따라 가상 객체의 성능 값을 결정하는 기능을 수행하 는 동작을 설명하기 위한 개념도이다. 도 22는 본 개시의 일 실시예에 따른 현실 객체의 특성에 따라 가상 객체의 성능 값을 결정하는 방법을 보여주 는 흐름도이다. 도 23은 본 개시의 일 실시예에 따른 매핑될 가상 객체와 유사한 현실 객체를 입력 도구로 이용하는 동작을 설 명하기 위한 개념도이다. 도 24는 본 개시의 일 실시예에 따른 기 결정된 움직임에 기초하여 가상 객체를 생성하는 동작을 설명하기 위한 개념도이다. 도 25는 본 개시의 일 실시예에 따른 기 결정된 움직임에 기초하여 가상 객체를 생성하는 동작을 설명하기 위한 개념도이다. 도 26은 본 개시의 일 실시예에 따른 기 결정된 움직임에 기초하여 가상 객체를 생성하는 방법을 보여주는 흐름 도이다. 도 27은 본 개시의 일 실시예에 따른 기 결정된 움직임과 개인 인증 입력에 기초하여 가상 객체를 생성하는 동 작을 설명하기 위한 개념도이다. 도 28은 본 개시의 일 실시예에 따른 기 결정된 움직임과 개인 인증 입력에 기초하여 가상 객체를 생성하는 방 법을 보여주는 흐름도이다. 도 29는 본 개시의 일 실시예에 따른 검출 결과에 기초하여 기 결정된 센서를 활성화하는 기능을 수행하는 동작 을 설명하기 위한 개념도이다. 도 30은 본 개시의 일 실시예에 따른 전자 장치의 동작을 설명하기 위한 블록도이다. 도 31은 본 개시의 일 실시예에 따른 기 결정된 센서를 활성화하는 기능을 수행하는 방법을 보여주는 흐름도이 다. 도 32는 본 개시의 일 실시예에 따른 현실 객체를 전자 장치의 입력 도구로 등록하는 방법을 보여주는 흐름도이 다. 도 33은 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 기 등록된 기 능을 수행하는 방법을 설명하기 위한 개념도이다. 도 34a 및 34b는 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 가상객체를 제어하는 기능을 수행하는 방법을 설명하기 위한 개념도이다. 도 35a 및 35b는 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 가상 스크린의 크기를 제어하는 기능을 수행하는 방법을 설명하기 위한 개념도이다. 도 36a 및 36b는 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 기 식 별된 기능을 수행하거나, 수행된 기능을 취소하는 기능을 수행하는 방법을 설명하기 위한 개념도이다. 도 37은 본 개시의 일 실시예에 따른 현실 객체와 사용자의 입 간의 거리에 기초하여 기 등록된 기능을 식별하 는 방법을 보여주는 흐름도이다. 도 38은 본 개시의 일 실시예에 따른 사용자의 볼의 움직임 또는 사용자의 볼의 형태에 기초하여 기 등록된 기 능을 수행하는 방법을 보여주는 흐름도이다."}
