{"patent_id": "10-2023-0107199", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0026033", "출원번호": "10-2023-0107199", "발명의 명칭": "가상 의상 착장방법 및 착장시스템", "출원인": "주식회사 교원", "발명자": "박정훈"}}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "아바타와 상기 아바타에 착장할 가상 의상을 입력받는 단계;상기 아바타와 상기 가상 의상 각각으로부터 본 정보를 포함하는 리깅 데이터를 추출하는 단계;상기 가상 의상의 본 정보 및 포즈가 상기 아바타의 본 정보 및 포즈에 매칭되도록 상기 가상 의상의 본 정보및 포즈를 보정하는 단계;상기 아바타와 상기 가상 의상을 기설정된 본 기준으로 분할하여, 복수의 아바타 파츠와 복수의 가상 의상 파츠를 생성하는 단계; 및상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠 각각의 본 정보를 기반으로 상기 복수의 아바타 파츠와상기 복수의 가상 의상 파츠를 병합하여 상기 가상 의상이 상기 아바타에 착장된 3D 모델을 생성하는 단계를 포함하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 리깅 데이터를 추출하는 단계 이후에,상기 가상 의상에 대한 리깅 상태를 판단하는 단계; 및상기 가상 의상을 리깅하는 단계를 더 포함하고,상기 리깅하는 단계에서는사전에 리깅되지 않은 상기 가상 의상을 리깅하는 것을 특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 리깅하는 단계는상기 아바타 및 상기 가상 의상으로부터 정면 2D 이미지를 추출하여 아바타 2D 이미지 및 가상 의상 2D 이미지를 획득하는 단계와,상기 아바타 2D 이미지 및 상기 가상 의상 2D 이미지를 기반으로 상기 아바타가 상기 가상 의상을 피팅한 피팅2D 이미지를 획득하는 단계와,상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지 각각으로부터 상기 가상 의상의 특징점을 나타내는 제1 랜드마크와 제2 랜드마크를 획득하는 단계와,상기 제1 랜드마크와 상기 제2 랜드마크 간의 변화량을 산출하는 단계와,상기 변화량을 상기 가상 의상에 적용하여 상기 가상 의상을 변환하는 단계를 포함하는 것을 특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 랜드마크와 상기 제2 랜드마크를 추출하는 단계에서는상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지 각각을 특징점 추출알고리즘에 적용하여 상기 가상 의상의특징점을 추출하고,공개특허 10-2025-0026033-3-상기 특징점 추출알고리즘은상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지 각각에 이미지 분할을 수행하여 상기 가상 의상 2D 이미지및 상기 피팅 2D 이미지에서 상기 가상 의상을 인식하고,상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지에서 인식한 상기 가상 의상을 사전에 학습된 카테고리를 기반으로 상기 인식한 가상 의상의 카테고리를 분류하고,상기 카테고리에 따라 기설정된 의상의 특징점 위치 및 개수를 기반으로 상기 인식한 가상 의상의 특징점을 추출하는 것을 특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 특징점 추출알고리즘은상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지에서 바운딩 박스를 생성하여 상기 가상 의상을 인식하는 것을 특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 피팅 2D 이미지를 획득하는 단계에서는상기 아바타 2D 이미지 및 상기 가상 의상 2D 이미지를 의상피팅 알고리즘에 적용하여 상기 피팅 2D 이미지를획득하고,상기 의상피팅 알고리즘은상기 아바타 2D 이미지에서 상기 아바타의 포즈를 추정하여 상기 아바타의 관절 2D 데이터를 획득하고,상기 관절 2D 데이터로부터 상기 아바타 2D 이미지의 스켈레톤 이미지를 생성하고,상기 아바타 2D 이미지에서 유지할 영역과 변형할 영역을 설정하여 어그노스틱 맵(Agnostic Map)획득하고,상기 아바타 2D 이미지, 상기 가상 의상 2D 이미지, 상기 스켈레톤 이미지 및 상기 어그노스틱 맵을 기반으로상기 피팅 2D 이미지를 생성하는 것을 특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 의상피팅 알고리즘은상기 아바타 2D 이미지에 휴먼 파싱 기법을 적용하여 파싱 맵을 획득하고,상기 파싱 맵을 기반으로 상기 아바타 2D 이미지에서 상기 유지할 영역을 설정하고,상기 관절 2D 데이터와 상기 파싱 맵을 기반으로 상기 아바타 2D 이미지에서 상기 변형할 영역을 설정하는 것을특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서,상기 변화량은상기 가상 의상이 상기 아바타에 피팅되기 전과 피팅된 후 간의 형상 변화량인 것을 특징으로 하는 가상 의상착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,공개특허 10-2025-0026033-4-상기 가상 의상의 본 정보 및 포즈를 보정하는 단계에서는상기 아바타의 본 정보 및 상기 가상 의상의 본 정보에서 각 본의 평균 길이로 보정하는 것을 특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 아바타에 착장된 3D 모델을 생성하는 단계에서는상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠를 병합하기 이전에, 상기 복수의 아바타 파츠 중 상기가상 의상 파츠의 본 정보와 동일한 본 정보를 가지는 아바타 파츠를 제거하여 상기 아바타 파츠와 상기 가상의상 파츠의 중첩 면을 제거하는 것을 특징으로 하는 가상 의상 착장방법."}
{"patent_id": "10-2023-0107199", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "아바타와 상기 아바타에 착장할 가상 의상을 입력받는 입력유닛; 및상기 가상 의상이 상기 아바타에 착장된 3D 모델을 생성하는 착장유닛을 포함하고,상기 착장유닛은,상기 아바타와 상기 가상 의상 각각으로부터 본 정보를 포함하는 리깅 데이터를 추출하는 전처리 모듈과,상기 가상 의상의 본 정보 및 포즈가 상기 아바타의 본 정보 및 포즈에 매칭되도록 상기 가상 의상의 본 정보및 포즈를 보정하고 상기 아바타와 상기 가상 의상을 기설정된 본 기준으로 분할하여 복수의 아바타 파츠와 복수의 가상 의상 파츠를 생성하는 피팅 모듈과, 상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠 각각의 본 정보를 기반으로 상기 복수의 아바타 파츠와상기 복수의 가상 의상 파츠를 병합하여 상기 가상 의상이 상기 아바타에 착장된 3D 모델을 생성하는 병합 모듈을 포함하는 가상 의상 착장시스템."}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 원본 아바타 정보의 존재 유무와 상관없이 인공지능 기술을 이용하여 가상 의상의 착장 공정을 자동화 하는 가상 의상 착장 방법 및 착장 시스템을 제공하기 위해, 아바타와 상기 아바타에 착장할 가상 의상을 입력받 는 단계 및 상기 아바타와 상기 가상 의상 각각으로부터 본 정보를 포함하는 리깅 데이터를 추출하는 단계 및 상 (뒷면에 계속)"}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가상 의상 착장방법 및 착장시스템에 관한 것으로, 보다 상세하게는 가상 객체에 가상 의상을 착장하 는 가상 의상 착장방법 및 착장시스템에 관한 것이다."}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "아바타 시스템은 가상 공간에서 사용자를 일정 형태의 아바타로 표현하는 시스템을 의미한다. 아바타 시스템에 서는 의상 착장시스템을 활용하여 아바타에 가상 의상을 착장할 수 있다. 착장시스템은 가상 의상에 대한 리깅 공정, 피팅 공정 및 병합 공정을 포함하는 공정으로 가상의상을 아바타에 착장할 수 있다. 착장 시스템에 대한 종래 기술은 \"대한민국 등록특허공보 제10-1808726호(3D 의상 착장 시뮬레이션 방법 및 장 치, 2017. 12. 07.)\"에 의해 공개되어 있다. 상기 등록발명은 2D 의상의 패턴들을 아바타에 드래이핑한다. 그리 고 상기 등록발명은 드래이핑된 2D 의상의 패턴에 매칭되는 패턴 블록의 재봉 정보에 따라 2D 의상의 패턴을 재 봉하여 아바타에 3D 의상을 착장한다. 한편, 착장된 가상 의상은 활용도를 높이기 위하여 아바타 간에 가상 의상을 전이시키는 기술이 적용되고 있다. 일례로, 가상 의상 전이 기술은 원본 아바타와 대상 아바타 각각의 아바타 정보를 기반으로 원본 아바타의 가상 의상을 대상 아바타에 전이시킨다. 다만, 원본 아바타 정보가 없는 경우에는 전술한 공정과 같이, 전이할 가상 의상에 대한 별도의 공정이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-1808726호(3D 의상 착장 시뮬레이션 방법 및 장치, 2017. 12. 07.)"}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 원본 아바타 정보의 존재 유무와 상관없이 인공지능 기술을 이용하여 가상 의상의 착장 공정 을 자동화하는 가상 의상 착장 방법 및 착장 시스템을 제공하기 위한 것이다."}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 가상 의상 착장방법은 아바타와 상기 아바타에 착장할 가상 의상을 입력받는 단계 및 상기 아바 타와 상기 가상 의상 각각으로부터 본 정보를 포함하는 리깅 데이터를 추출하는 단계 및 상기 가상 의상의 본 정보 및 포즈가 상기 아바타의 본 정보 및 포즈에 매칭되도록 상기 가상 의상의 본 정보 및 포즈를 보정하는 단 계 및 상기 아바타와 상기 가상 의상을 기설정된 본 기준으로 분할하여, 복수의 아바타 파츠와 복수의 가상 의 상 파츠를 생성하는 단계 및 상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠 각각의 본 정보를 기반으 로 상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠를 병합하여 상기 가상 의상이 상기 아바타에 착장된 3D 모델을 생성하는 단계를 포함한다. 상기 가상 의상 착장방법은 상기 리깅 데이터를 추출하는 단계 이후에, 상기 가상 의상에 대한 리깅 상태를 판 단하는 단계 및 상기 가상 의상을 리깅하는 단계를 더 포함하고, 상기 리깅하는 단계에서는 사전에 리깅되지 않 은 상기 가상 의상을 리깅할 수 있다. 상기 리깅하는 단계는 상기 아바타 및 상기 가상 의상으로부터 정면 2D 이미지를 추출하여 아바타 2D 이미지 및 가상 의상 2D 이미지를 획득하는 단계와, 상기 아바타 2D 이미지 및 상기 가상 의상 2D 이미지를 기반으로 상기 아바타가 상기 가상 의상을 피팅한 피팅 2D 이미지를 획득하는 단계와, 상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지 각각으로부터 상기 가상 의상의 특징점을 나타내는 제1 랜드마크와 제2 랜드마크를 획득하는 단계와, 상기 제1 랜드마크와 상기 제2 랜드마크 간의 변화량을 산출하는 단계와, 상기 변화량을 상기 가상 의상에 적용 하여 상기 가상 의상을 변환하는 단계를 포함할 수 있다. 상기 제1 랜드마크와 상기 제2 랜드마크를 추출하는 단계에서는 상기 가상 의상 2D 이미지 및 상기 피팅 2D 이 미지 각각을 특징점 추출알고리즘에 적용하여 상기 가상 의상의 특징점을 추출하고, 상기 특징점 추출알고리즘 은 상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지 각각에 이미지 분할을 수행하여 상기 가상 의상 2D 이미 지 및 상기 피팅 2D 이미지에서 상기 가상 의상을 인식하고, 상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지 에서 인식한 상기 가상 의상을 사전에 학습된 카테고리를 기반으로 상기 인식한 가상 의상의 카테고리를 분류하 고, 상기 카테고리에 따라 기설정된 의상의 특징점 위치 및 개수를 기반으로 상기 인식한 가상 의상의 특징점을 추출할 수 있다. 상기 특징점 추출알고리즘은 상기 가상 의상 2D 이미지 및 상기 피팅 2D 이미지에서 바운딩 박스를 생성하여 상 기 가상 의상을 인식할 수 있다. 상기 피팅 2D 이미지를 획득하는 단계에서는 상기 아바타 2D 이미지 및 상기 가상 의상 2D 이미지를 의상피팅 알고리즘에 적용하여 상기 피팅 2D 이미지를 획득하고, 상기 의상피팅 알고리즘은 상기 아바타 2D 이미지에서 상기 아바타의 포즈를 추정하여 상기 아바타의 관절 2D 데이터를 획득하고, 상기 관절 2D 데이터로부터 상기 아 바타 2D 이미지의 스켈레톤 이미지를 생성하고, 상기 아바타 2D 이미지에서 유지할 영역과 변형할 영역을 설정 하여 어그노스틱 맵(Agnostic Map)을 획득하고, 상기 아바타 2D 이미지, 상기 가상 의상 2D 이미지, 상기 스켈 레톤 이미지 및 상기 어그노스틱 맵을 기반으로 상기 피팅 2D 이미지를 생성할 수 있다. 상기 의상피팅 알고리즘은 상기 아바타 2D 이미지에 휴먼 파싱 기법을 적용하여 파싱 맵을 획득하고, 상기 파싱 맵을 기반으로 상기 아바타 2D 이미지에서 상기 유지할 영역을 설정하고, 상기 관절 2D 데이터와 상기 파싱 맵 을 기반으로 상기 아바타 2D 이미지에서 상기 변형할 영역을 설정할 수 있다. 상기 변화량은 상기 가상 의상이 상기 아바타에 피팅되기 전과 피팅된 후 간의 형상 변화량일 수 있다. 상기 가상 의상의 본 정보 및 포즈를 보정하는 단계에서는 상기 아바타의 본 정보 및 상기 가상 의상의 본 정보 에서 각 본의 평균 길이로 보정할 수 있다.상기 아바타에 착장된 3D 모델을 생성하는 단계에서는 상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠 를 병합하기 이전에, 상기 복수의 아바타 파츠 중 상기 가상 의상 파츠의 본 정보와 동일한 본 정보를 가지는 아바타 파츠를 제거하여 상기 아바타 파츠와 상기 가상 의상 파츠의 중첩 면을 제거할 수 있다. 한편, 본 발명에 따른 가상 의상 착장시스템은 아바타와 상기 아바타에 착장할 가상 의상을 입력받는 입력유닛 및 상기 가상 의상이 상기 아바타에 착장된 3D 모델을 생성하는 착장유닛을 포함하고, 상기 착장유닛은 상기 아 바타와 상기 가상 의상 각각으로부터 본 정보를 포함하는 리깅 데이터를 추출하는 전처리 모듈과, 상기 가상 의 상의 본 정보 및 포즈가 상기 아바타의 본 정보 및 포즈에 매칭되도록 상기 가상 의상의 본 정보 및 포즈를 보 정하고 상기 아바타와 상기 가상 의상을 기설정된 본 기준으로 분할하여 복수의 아바타 파츠와 복수의 가상 의 상 파츠를 생성하는 피팅 모듈과, 상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠 각각의 본 정보를 기 반으로 상기 복수의 아바타 파츠와 상기 복수의 가상 의상 파츠를 병합하여 상기 가상 의상이 상기 아바타에 착 장된 3D 모델을 생성하는 병합 모듈을 포함한다."}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 가상 의상 착장방법 및 착장시스템은 가상 의상에 대한 입력처리를 간소화하면서, 아바타에 가 상 의상을 착장하는 공정을 자동화하는 효과를 포함한다. 이상과 같은 본 발명의 기술적 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 또 다른 기술적 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명의 실시예를 상세히 설명한다. 그러나 본 실시예는 이하에서 개시되는 실 시예에 한정되는 것이 아니라 서로 다양한 형태로 구현될 수 있으며, 단지 본 실시예는 본 발명의 개시가 완전 하도록 하며, 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 도면에서의 요소의 형상 등은 보다 명확한 설명을 위하여 과장되게 표현된 부분이 있을 수 있으며, 도면 상에서 동일 부호 로 표시된 요소는 동일 요소를 의미한다. 도 1은 본 실시예에 따른 가상 의상 착장시스템을 개략적으로 나타낸 흐름도이다. 도 1을 참조하면, 본 실시예에 따른 가상 의상 착장시스템(이하 '착장시스템' 이라 칭한다)은 아바타에 가 상 의상을 착장한다. 아바타는 게임, 메타버스 및 영화 등과 같은 디지털 콘텐츠에 사용되는 3차원 캐 릭터 모델을 포함할 수 있다. 이러한 아바타는 사전에 리깅 처리된 것일 수 있다. 아바타에는 리깅 데이터와 아바타의 형상을 나 타내는 매쉬 데이터가 저장된 상태일 수 있다. 리깅 데이터는 3D 모델의 버텍스와 페이스 간의 연관정보, 3D 모 델의 디폼 벡터 생성을 위한 본(Bone) 정보, 3D 모델의 하위계층 우선순위 정보 및 3D 모델의 본 매핑 정보를 포함할 수 있다. 가상 의상은 아바타에 착장하기 위한 3차원 의상 모델을 포함할 수 있다. 가상 의상은 사전에 리깅 처리가 된 것일 수 있으나, 가상 의상의 리깅 상태에 대해서는 한정하지 않는다. 일례로, 가상 의상은 리깅 처리되지 않고, 3D 모델 형상만이 입력될 수 있다. 일례로, 착장시스템은 입력 유닛 및 착장 유닛을 포함할 수 있다. 먼저, 입력 유닛은 유무선 방식을 통해 서버 및 저장부 등으로부터 제공되는 아바타와 가상 의상 에 대한 정보를 수신하여 착장 유닛에 입력하는 수단일 수 있다. 그리고 착장 유닛은 아바타에 가상 의상을 착장시킬 수 있다. 일례로, 착장 유닛은 전처리 모듈, 리깅 모듈, 피팅 모듈 및 병합 모듈을 포함할 수 있다. 먼저, 전처리 모듈은 착장 공정을 수행하기 이전에 아바타 및 가상 의상에 대한 전처리를 수행할 수 있다. 전처리 모듈은 아바타로부터 아바타의 리깅 데이터와 매쉬 데이터를 추출할 수 있다. 그 리고 전처리 모듈은 가상 의상으로부터 가상 의상의 리깅 데이터와 매쉬 데이터를 추출할 수 있다. 그리고 전처리 모듈은 아바타 및 가상 의상 각각의 리깅 데이터와 매쉬 데이터를 피팅 모듈 에 제공할 수 있다. 다만, 전처리 모듈은 가상 의상에서 리깅 데이터가 존재하지 않는 경우, 가상 의 상의 리깅처리를 위해 가상 의상을 리깅 모듈에 제공할 수 있다. 또한, 전처리 모듈은 가상 의상의 리깅 처리를 위해 추출한 아바타 데이터를 리깅 모듈에 제공할 수 있다. 한편, 리깅 모듈은 리깅 처리되지 않은 가상 의상에 대하여 리깅 처리를 수행할 수 있다. 여기서, 리 깅 모듈은 아바타의 본에 가상 의상의 매쉬 데이터를 바인딩하는 방식으로 리깅을 수행할 수 있다. 도 2는 본 실시예에 따른 가상 의상 착장시스템의 리깅 공정에 대한 흐름도이고, 도 3은 리깅 공정의 가상 의상 디폼에 대한 순서도이다. 도 2 및 도 3에 도시된 바와 같이, 본 실시예에 따른 리깅 모듈은 아바타의 정면 2D 이미지를 추출하 여 아바타 2D 이미지를 획득한다(S210). 그리고 리깅 모듈은 가상 의상의 정면 2D 이미지를 추출하여 가상 의상 2D 이미지를 획득한다(S220). 그리고 리깅 모듈은 가상 의상 2D 이미지를 랜드마크 추출알고리즘에 적용하여 가상 의상 2D 이미지로부터 특징점을 추출할 수 있다(S230). 랜드마크 추출알고리즘은 이미지 분할을 수행하여 가상 의상 2D 이미지 내의 의상이 존재하는 영역에 바운딩 박 스를 생성할 수 있다. 랜드마크 추출알고리즘은 이미지 분할하는 과정에서 복수의 의상이 감지되면 각 의상을 인식하는 바운딩 박스를 생성할 수 있다. 그리고 랜드마크 추출알고리즘은 바운딩 박스 내에 인식된 의상에 대하여 카테고리를 분류할 수 있다. 일례로, 랜드마크 추출알고리즘은 셔츠, 나시, 바지 및 치마 등과 같이 의상의 카테고리별 이미지를 기반으로 학습된 것 일 수 있다. 랜드마크 추출알고리즘은 바운딩 박스 내의 의상의 형상을 사전에 학습된 각 카테고리의 형상 중 유사한 카테고리로 분류할 수 있다. 그리고 랜드마크 추출알고리즘은 카테고리에 따라 기설정된 특징점의 위치 및 개수로 가상 의상 2D 이미지의 특 징점을 추출할 수 있다. 이에 따라, 랜드마크 추출알고리즘은 의상 2D 이미지의 특징점을 추출함으로써 제1 랜 드마크를 획득할 수 있다. 그리고 리깅 모듈은 가상 의상 2D 이미지를 아바타 2D 이미지에 피팅시킨다(S240). 여기서, 리깅 모듈 은 가상 의상 2D 이미지 및 아바타 2D 이미지를 의상피팅 알고리즘에 적용하여 피팅시킬 수 있다. 의상피팅 알고리즘은 아바타 2D 이미지의 아바타 포즈를 추정하여 아바타 관절의 2D 데이터를 추출할 수 있다. 그리고 의상피팅 알고리즘은 아바타 2D 이미지에 휴먼파싱 기법을 적용하여 분할을 수행한다. 여기서, 의상피팅 알고리즘은 아바타 2D 이미지를 기설정된 기준으로 분할하여 파싱 맵을 생성할 수 있다. 일례로, 의상피팅 알고 리즘은 상의, 하의 및 피부로 분류하는 파싱 맵을 생성할 수 있다. 그리고 의상피팅 알고리즘은 파싱맵을 이용하여 아바타 2D 이미지에서 유지할 영역을 설정할 수 있다. 의상피팅 알고리즘은 아바타 관절 2D 데이터와 파싱 맵을 이용하여 아바타 2D 이미지에서 변형할 영역을 설정할 수 있다. 의상피팅 알고리즘은 유지할 영역과 변형할 영역으로 어그노스틱 맵(Agnostic Map)을 생성할 수 있다. 그리고 의상피팅 알고리즘은 아바타 관절 2D 데이터로 아바타 스켈레톤 이미지를 생성할 수 있다. 의상피팅 알 고리즘은 아바타 2D 이미지, 가상 의상 2D 이미지, 어그노스틱 맵, 스켈레톤 이미지를 이용하여, 아바타 2D 이 미지에 가상 의상 2D 이미지를 피팅한 피팅 2D 이미지를 생성할 수 있다. 그리고 리깅 모듈은 피팅 2D 이미지를 전술한 랜드마크 추출알고리즘에 적용하여, 피팅 2D 이미지에서 피 팅된 의상 2D 이미지의 특징점을 추출할 수 있다(S250). 리깅 모듈은 피팅 2D 이미지로부터 추출된 특징점을 제2 랜드마크로 이용할 수 있다. 리깅 모듈은 제1 랜드마크와 제2 랜드마크를 상호 비교하여, 제1 랜드 마크와 제2 랜드마크 간의 변화량을 산출할 수 있다. 즉, 리깅 모듈은 가상 의상 2D 이미지가 아바타 2D 이미지에 피팅 전과 피팅 후 간의 형상의 변화량을 획득할 수 있다. 리깅 모듈은 제1 랜드마크 및 제2 랜드마크를 기반으로 디폼 가이드를 생성할 수 있다(S261). 리깅 모듈 은 제1 랜드마크 및 제2 랜드마크 각각의 특징점을 가상 의상의 와이어 흐름에 영향을 주지않도록 확 장시켜 가이드 포인트를 생성할 수 있다. 그리고 리깅 모듈은 제1 랜드마크 및 제2 랜드마크 각각으로 생 성된 가이드 포인트에 가상 의상의 볼륨을 기반으로 가이드 영역을 생성할 수 있다. 리깅 모듈은 제1 랜드마크로 생성된 제1 가이드 영역과 제2 랜드마크로 생성된 제2 가이드 영역 간의 인접 가이드 정보를 기반으 로 가상 의상의 디폼에 사용할 가중치를 결정할 수 있다. 그리고 리깅 모듈은 전술한 과정에서 생성된 가이드 정보를 기반으로 가상 의상의 변형영역을 설정할 수 있다(S263). 리깅 모듈은 제1 가이드 영역에 가상 의상을 각 영역으로 매핑시킬 수 있다. 그리고 리깅 모듈은 매핑된 제1 가이드 영역에 따라 가상 의상의 변형영역으로 설정할 수 있다. 그리고 리깅 모듈은 제1 가이드 영역을 기반으로 설정된 가상 의상의 각 변형영역에 대한 3차원 공간 에서의 축, 위치 및 크기를 산출할 수 있다. 그리고 리깅 모듈은 기설정된 인벌스 매트릭스를 통해 산출된 축, 위치 및 크기를 정규화시킬 수 있다. 그리고 리깅 모듈은 전술한 변화량과 가중치를 가상 의상의 각 변형영역에 적용하여 재생성 가상 의상 으로 디폼할 수 있다. 리깅 모듈은 가상 의상의 각 변형영역에 대하여 가이드 영역의 중심거리에 따른 가변 스케일값을 적용할 수 있다. 그리고 리깅 모듈은 가변 스케일이 적용된 가상 의상의 변형영역에 전술한 가중치를 적용할 수 있다. 그리고 리깅 모듈은 전술한 변화량을 기반으로 재생성 가상 의상을 생성하기 위한 디폼 매트릭스를 생성할 수 있다. 여기서, 디폼 매트릭스는 제1 가이드 영역, 제2 가이드 영역과 전술한 가중치로 매트릭스 연산을 수행 하여 생성될 수 있다. 그리고 디폼 매트릭스는 가상 의상에 대하여 3차원 공간상의 변형영역간의 연산을 이 용하여 가상 의상의 형태를 유지하며 변형시킬 수 있다. 이에, 리깅 모듈은 가중치가 적용된 가상 의 상을 디폼 매트릭스에 적용하여 변형시킴으로써 재생성 가상 의상을 생성할 수 있다. 또한, 리깅 모듈은 재생성 가상 의상을 생성하는 과정에서 아바타에 재생성 가상 의상을 정렬시킬 수 있다(S270). 최종적으로, 리깅 모듈은 아바타에 재생성 가상 의상을 바인딩함으로써 가상 의상에 대한 리깅을 마무리할 수 있다. 한편, 다시 도 1을 참조하면, 본 실시에에 따른 리깅 모듈은 리깅 처리된 가상 의상을 피팅 모듈(23 0)에 제공할 수 있다. 피팅 모듈은 전처리 모듈로부터 제공받은 아바타의 데이터 및 가상 의상 의 데이터와, 리깅 모듈로부터 제공받은 가상 의상의 데이터를 이용하여 피팅 공정을 수행할 수 있다. 피팅 모듈은 가상 의상을 아바타의 체형 즉, 형상에 맞게 변환하는 피팅 공정을 수행할 수 있다. 도 4는 본 실시예에 따른 가상 의상 착장시스템의 피팅 공정에 대한 흐름도이다. 도 4에 도시된 바와 같이, 본 실시예에 따른 피팅 모듈은 아바타의 포즈에 가상 의상의 포즈를 매 칭시키기 위하여 가상 의상의 본 스케일을 보정할 수 있다. 이때, 피팅 모듈은 아바타 및 가상 의 상 각각의 본 정보에서 각 본의 평균 길이로 가상 의상의 본 스케일을 보정할 수 있다. 그리고 피팅 모듈은 하위계층 우선순위 정보를 기반으로 스케일이 보정된 가상 의상의 포즈를 아바타 의 포즈에 매칭시킬 수 있다(S310). 일례로, 피팅 모듈은 기생성된 아바타 본 정보를 기반으로 가상 의상의 포즈를 매칭시킬 수 있다. 아 바타 본 정보는 아바타의 본의 이동 반경 및 회전 반경과, 회전축 변화량을 포함할 수 있다. 또한, 피팅 모 듈은 아바타 본 정보에 FK(Forward Kinematics)방식을 적용하여 가상 의상의 포즈를 매칭시킬 수 있다. 그리고 피팅 모듈은 아바타와 포즈 매칭이 완료된 가상 의상을 분할하여 복수의 아바타 파츠 와 복수의 가상 의상 파츠를 획득할 수 있다(S320). 일례로, 피팅 모듈은 아바타 및 포즈 매칭이 완료된 가상 의상 각각의 본 정보를 기준으로 중간 본을 생성하여 분할할 수 있다.피팅 모듈은 각 가상 의상 파츠에 아바타 파츠를 등록할 수 있다. 피팅 모듈은 의상 파츠 의 본 정보와 인접한 본 정보를 가지는 아바타 파츠를 가상 의상 파츠에 등록할 수 있다. 이 과정 에서, 피팅 모듈은 가중치가 할당된 유효 본 정보를 획득할 수 있다. 그리고 피팅 모듈은 각 가상 의상 파츠별 아바타 파츠의 버텍스의 포지션을 변환시킬 수 있다. 이 때, 피팅 모듈은 인접한 본 정보를 기반으로 생성된 노멀 벡터로 포지션을 변환시킬 수 있다. 그리고 피팅 모듈은 히트 처리된 페이스의 버텍스 웨이트 값을 복사할 수 있다. 여기서, 피팅 모듈은 가상 의상의 리깅 데이터를 아바타의 리깅 데이터로 대체하여 리그 병합과정을 수행할 수 있다. 그리고 피팅 모듈은 히트 처리되지 않은 버텍스에 대하여 주변 버텍스의 인접 점 거리에 기반한 가중치로 보정할 수 있다. 이에 따라, 피팅 모듈은 가상 의상 파츠별 아바타 파츠의 매쉬를 디폼하여 피팅 공정을 마무리할 수 있다(S330). 한편, 다시 도 1을 참조하면, 본 실시예에 따른 피팅 모듈은 피팅 공정이 마무리되어 생성된 아바타 파츠 와 가상 의상 파츠를 병합 모듈에 제공할 수 있다. 병합 모듈은 아바타 파츠와 가상 의 상 파츠를 병합하여 아바타에 가상 의상이 착장된 3D 모델을 생성할 수 있다. 도 5는 본 실시예에 따른 가상 의상 착상시스템의 병합 공정에 대한 흐름도이다. 도 5에 도시된 바와 같이, 본 실시예에 따른 병합 모듈은 병합하기 이전에 아바타 파츠 중 본 정보가 가상 의상 파츠의 본 정보와 중첩되는 아바타 파츠를 제거할 수 있다. 여기서, 병합 모듈은 피팅 모듈이 획득한 인접 본 정보를 기반으로 제거할 수 있다. 병합 모듈은 가상 의상 파츠의 리깅 데 이터에서 웨이트가 할당된 본 정보를 기준으로 제거 유무를 판단할 수 있다. 이때, 병합 모듈은 가상 의상 파츠의 본 정보와 인접한 본 정보를 가지는 아바타 파츠의 제거 순위를 높여 제거할 수 있다(S410). 이 에, 병합 모듈은 가상 의상을 착장한 아바타가 가상 의상과 아바타가 중첩되는 외형을 제 거할 수 있다. 그리고 병합 모듈은 하위계층 우선순위 정보를 기반으로 생성된 아바타 파츠 및 가상 의상 파츠를 병합하여 가상 의상을 착장한 아바타를 생성할 수 있다(S420). 이와 같이, 본 발명에 따른 가상 의상 착장시스템은 가상 의상의 리깅 데이터의 유무를 확인하고, 인공지능 기 술을 이용하여 가상 의상의 리깅 처리를 자동화할 수 있다. 한편, 본 실시예의 랜드마크 추출 알고리즘 및 의상 피팅 알고리즘은 딥러닝 모델을 기반으로 학습된 모델일 수 있으나, 이를 한정하지는 않는다. 이에, 본 발명은 가상 의상에 대한 입력처리를 간소화하면서, 아바타에 가상 의상을 착장하는 공정을 자동화하 는 효과를 포함한다. 앞에서 설명되고, 도면에 도시된 본 발명의 일 실시예는 본 발명의 기술적 사상을 한정하는 것으로 해석되어서"}
{"patent_id": "10-2023-0107199", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 안 된다. 본 발명의 보호범위는 청구범위에 기재된 사항에 의하여만 제한되고, 본 발명의 기술분야에서 통상 의 지식을 가진 자는 본 발명의 기술적 사상을 다양한 형태로 개량 변경하는 것이 가능하다. 따라서 이러한 개 량 및 변경은 통상의 지식을 가진 자에게 자명한 것인 한 본 발명의 보호범위에 속하게 될 것이다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2023-0107199", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 실시예에 따른 가상 의상 착장시스템을 개략적으로 나타낸 흐름도이다. 도 2는 본 실시예에 따른 가상 의상 착장시스템의 리깅 공정에 대한 흐름도이다. 도 3은 리깅 공정의 가상 의상 디폼에 대한 순서도이다. 도 4는 본 실시예에 따른 가상 의상 착장시스템의 피팅 공정에 대한 흐름도이다. 도 5는 본 실시예에 따른 가상 의상 착상시스템의 병합 공정에 대한 흐름도이다."}
