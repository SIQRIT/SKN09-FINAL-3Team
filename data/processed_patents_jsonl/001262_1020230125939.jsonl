{"patent_id": "10-2023-0125939", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0042616", "출원번호": "10-2023-0125939", "발명의 명칭": "다계층 위성을 이용한 지능형 교통 시스템 및 이를 이용한 통신 방법", "출원인": "경희대학교 산학협력단", "발명자": "홍충선"}}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "위성을 이용한 지능형 교통 시스템으로서, 제1 위성;상기 제1 위성과 통신 커버리지, 통신 비용, 및 통신 관련 리소스 중 하나 이상이 다른 제2 위성;상기 제1 위성 및 상기 제2 위성과 통신 커버리지, 통신 비용, 및 통신 관련 리소스 중 하나 이상이 다른 제3위성; 및상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상과 데이터 통신을 수행하며, 통신 장비가 장착된이동 수단인 하나 이상의 모바일 노드를 포함하는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 제1 위성은, 제1 통신 커버리지, 제1 통신 비용, 및 제1 통신 관련 리소스를 가지고, 상기 제2 위성은, 상기 제1 통신 커버리지 보다 좁은 제2 통신 커버리지, 상기 제1 통신 비용 보다 적은 제2 통신 비용, 및 상기 제1 통신 관련 리소스 보다 작은 제2 통신 관련 리소스를 가지며, 상기 제3 위성은, 상기 제2 통신 커버리지 보다 좁은 제3 통신 커버리지, 상기 제2 통신 비용 보다 적은 제3 통신 비용, 및 상기 제2 통신 관련 리소스 보다 작은 제3 통신 관련 리소스를 가지는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 제2 위성은, 상기 제1 위성의 제1 통신 커버리지 내에서 제2 통신 커버리지를 가지고, 상기 제3 위성은, 상기 제2 위성의 제2 통신 커버리지 내에서 제3 통신 커버리지를 가지며, 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성은 각각 모바일 에지 컴퓨팅(Mobile Edge Computing: MEC) 기능을 지원하도록 마련되고, 상기 모바일 노드는, 오프로딩 작업을 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상으로 전달하는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서, 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성은, 상기 오프로딩 작업을 처리하기 위한 컴퓨팅 유닛 및 상기 오프로딩 작업의 순서를 스케줄링 하기 위한 스케줄러를 각각 포함하는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2025-0042616-3-청구항 3에 있어서, 상기 제1 위성은, 상기 모바일 노드로부터 오프로딩 작업을 수신하는 경우, 상기 제1 위성의 제1 통신 커버리지 내에 제2 위성 및제3 위성이 있는지를 확인하고, 상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성 중 하나 이상으로 상기 오프로딩 작업을 할당하는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서, 상기 제1 위성은, 상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성의 통신 관련 리소스, 통신 대역폭, 통신 비용, 및 오프로딩작업 처리 마감시간 중 하나 이상을 고려하여 상기 오프로딩 작업을 상기 제2 위성 및 상기 제3 위성 중 하나이상으로 할당하는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서, 상기 제1 위성은, 상기 오프로딩 작업의 처리 시간 및 통신 비용을 최소화 하면서 상기 오프로딩 작업을 수행할 위성의 선택, 상기 통신 대역폭, 및 상기 통신 관련 리소스의 할당을 최적화 하되, 각 위성들을 에이전트로 하는 다중 에이전트강화 학습 모델(Multi Agent Reinforcement Learning Model)을 이용하여 최적화 하는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서, 상기 다중 에이전트 강화 학습 모델은, 입력되는 상태 정보에 대해 기 설정된 정책에 기초하여 상기 에이전트의행동을 결정하는 정책 네트워크 및 상기 정책 네트워크가 결정한 행동에 대해 피드백을 제공하여 상기 정책을업데이트 하도록 하는 가치 네트워크를 포함하고, 상기 상태 정보는, 위성 상태 정보 및 노드 상태 정보를 포함하고상기 위성 상태 정보는, 각 위성의 위치, 각 위성의 통신 관련 리소스, 각 위성의 통신 대역폭, 각 위성의 통신비용, 및 각 위성의 통신 범위 중 하나 이상을 포함하며, 상기 노드 상태 정보는, 각 모바일 노드의 위치, 각 모바일 노드가 요청한 오프로딩 작업량, 및 각 모바일 노드가 설정된 오프로딩 작업의 마감 시간 중 하나 이상을 포함하는, 지능형 교통 시스템."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서, 상기 다중 에이전트 강화 학습 모델은,상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동을 입력 받고, 상기 상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동에 기초하여 상기 행동에 대한 보상과 관련된 다른 에이전트들의 어텐션 가중치를 생성하는 어텐션 네트워크를 더 포함하는, 지능형 교통 시스템.공개특허 10-2025-0042616-4-청구항 10 제1 위성, 제2 위성, 제3 위성, 및 모바일 노드를 포함하는 지능형 교통 시스템의 통신 방법으로서, 상기 제1 위성은, 제1 통신 커버리지, 제1 통신 비용, 및 제1 통신 관련 리소스를 가지고, 상기 제2 위성은, 상기 제1 통신 커버리지 보다 좁은 제2 통신 커버리지, 상기 제1 통신 비용 보다 적은 제2 통신 비용, 및 상기 제1 통신 관련 리소스 보다 작은 제2 통신 관련 리소스를 가지며, 상기 제3 위성은, 상기 제2 통신 커버리지 보다 좁은 제3 통신 커버리지, 상기 제2 통신 비용 보다 적은 제3 통신 비용, 및 상기 제2 통신 관련 리소스 보다 작은 제3 통신 관련 리소스를 가지고, 상기 통신 방법은,상기 모바일 노드에서, 오프로딩 작업을 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상으로 전달하는 단계를 포함하는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서, 상기 제2 위성은, 상기 제1 위성의 제1 통신 커버리지 내에서 제2 통신 커버리지를 가지고, 상기 제3 위성은, 상기 제2 위성의 제2 통신 커버리지 내에서 제3 통신 커버리지를 가지며, 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성은, 각각 모바일 에지 컴퓨팅(Mobile Edge Computing: MEC)기능을 지원하도록 마련되는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서, 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성은,상기 오프로딩 작업을 처리하기 위한 컴퓨팅 유닛 및 상기 오프로딩 작업의 순서를 스케줄링 하기 위한 스케줄러를 각각 포함하는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 11에 있어서,상기 통신 방법은, 상기 제1 위성에서, 상기 모바일 노드로부터 오프로딩 작업을 수신하는 경우, 상기 제1 위성의 제1 통신 커버리지 내에 제2 위성 및제3 위성이 있는지를 확인하는 단계; 및상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성 중 하나 이상으로 상기 오프로딩 작업을 할당하는 단계를더 포함하는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 13에 있어서, 상기 오프로딩 작업을 할당하는 단계는, 상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성의 통신 관련 리소스, 통신 대역폭, 통신 비용, 및 오프로딩작업 처리 마감시간 중 하나 이상을 고려하여 상기 오프로딩 작업을 상기 제2 위성 및 상기 제3 위성 중 하나공개특허 10-2025-0042616-5-이상으로 할당하는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 14에 있어서, 상기 오프로딩 작업을 할당하는 단계는, 상기 오프로딩 작업의 처리 시간 및 통신 비용을 최소화 하면서 상기 오프로딩 작업을 수행할 위성의 선택, 상기 통신 대역폭, 및 상기 통신 관련 리소스의 할당을 최적화 하되, 각 위성들을 에이전트로 하는 다중 에이전트강화 학습 모델(Multi Agent Reinforcement Learning Model)을 이용하여 최적화 하는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서, 상기 다중 에이전트 강화 학습 모델은, 입력되는 상태 정보에 대해 기 설정된 정책에 기초하여 상기 에이전트의행동을 결정하는 정책 네트워크 및 상기 정책 네트워크가 결정한 행동에 대해 피드백을 제공하여 상기 정책을업데이트 하도록 하는 가치 네트워크를 포함하고, 상기 상태 정보는, 위성 상태 정보 및 노드 상태 정보를 포함하고상기 위성 상태 정보는, 각 위성의 위치, 각 위성의 통신 관련 리소스, 각 위성의 통신 대역폭, 각 위성의 통신비용, 및 각 위성의 통신 범위 중 하나 이상을 포함하며, 상기 노드 상태 정보는, 각 모바일 노드의 위치, 각 모바일 노드가 요청한 오프로딩 작업량, 및 각 모바일 노드가 설정된 오프로딩 작업의 마감 시간 중 하나 이상을 포함하는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서, 상기 다중 에이전트 강화 학습 모델은,상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동을 입력 받고, 상기 상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동에 기초하여 상기 행동에 대한 보상과 관련된 다른 에이전트들의 어텐션 가중치를 생성하는 어텐션 네트워크를 더 포함하는, 통신 방법."}
{"patent_id": "10-2023-0125939", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "위성을 이용한 지능형 교통 시스템으로서, 지상에서 제1 고도에 위치하고 제1 통신 커버리지를 갖는 제1 위성;상기 제1 고도 보다 낮은 제2 고도에 위치하고 상기 제1 통신 커버리지 보다 좁은 제2 커버리지를 갖는 하나 이상의 제2 위성;상기 제2 고도 보다 낮은 제3 고도에 위치하고 상기 제2 통신 커버리지 보다 좁은 제3 커버리지를 갖는 하나 이상의 제3 위성; 및상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상과 데이터 통신을 수행하며, 통신 장비가 장착된이동 수단인 하나 이상의 모바일 노드를 포함하고, 상기 모바일 노드는, 오프로딩 작업을 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상으로 전달하는, 지능형 교통 시스템.공개특허 10-2025-0042616-6-"}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다계층 위성을 이용한 지능형 교통 시스템 및 이를 이용한 통신 방법이 개시된다. 개시되는 일 실시예에 따른 위 성을 이용한 지능형 교통 시스템은, 제1 위성, 제1 위성과 통신 커버리지, 통신 비용, 및 통신 관련 리소스 중 하나 이상이 다른 제2 위성, 제1 위성 및 제2 위성과 통신 커버리지, 통신 비용, 및 통신 관련 리소스 중 하나 이상이 다른 제3 위성, 및 제1 위성, 제2 위성, 및 제3 위성 중 하나 이상과 데이터 통신을 수행하며, 통신 장비 가 장착된 이동 수단인 하나 이상의 모바일 노드를 포함한다."}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 다계층 위성을 이용한 지능형 교통 시스템 및 이를 이용한 통신 방법과 관련된다."}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "지상파 액세스 네트워크(Terrestrial Access Network: TAN)는 인구 밀도가 높은 개발된 지역에서 경제적 이점을 위해 활용된다. 그러나, 지상파 액세스 네트워크(TAN)는 네트워크 인프라의 가용성 부족으로 인해 넓은 영상, 해상, 및 사막 지역 등은 커버할 수 없다. 6G 네트워크는 교통, 산업, 에너지 등 다양한 분야에서 애플리케이션 을 제공하게 되므로, 미래 네트워크를 발전시키기 위해서는 다른 지역으로 통신 연결을 확장하는 것이 중요해진 다. 이에, 지구 표면과 독립적인 네트워크 인프라를 구축하기 위해 위성을 활용하는 방안이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-0842465호(2008.07.01)"}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는 다계층 위성을 이용한 지능형 교통 시스템 및 이를 이용한 통신 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개시되는 일 실시예에 따른 지능형 교통 시스템은, 위성을 이용한 지능형 교통 시스템으로서, 제1 위성; 상기 제1 위성과 통신 커버리지, 통신 비용, 및 통신 관련 리소스 중 하나 이상이 다른 제2 위성; 상기 제1 위성 및 상기 제2 위성과 통신 커버리지, 통신 비용, 및 통신 관련 리소스 중 하나 이상이 다른 제3 위성; 및 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상과 데이터 통신을 수행하며, 통신 장비가 장착된 이동 수 단인 하나 이상의 모바일 노드를 포함한다. 상기 제1 위성은, 제1 통신 커버리지, 제1 통신 비용, 및 제1 통신 관련 리소스를 가지고, 상기 제2 위성은, 상 기 제1 통신 커버리지 보다 좁은 제2 통신 커버리지, 상기 제1 통신 비용 보다 적은 제2 통신 비용, 및 상기 제 1 통신 관련 리소스 보다 작은 제2 통신 관련 리소스를 가지며, 상기 제3 위성은, 상기 제2 통신 커버리지 보다 좁은 제3 통신 커버리지, 상기 제2 통신 비용 보다 적은 제3 통신 비용, 및 상기 제2 통신 관련 리소스 보다 작 은 제3 통신 관련 리소스를 가질 수 있다. 상기 제2 위성은, 상기 제1 위성의 제1 통신 커버리지 내에서 제2 통신 커버리지를 가지고, 상기 제3 위성은, 상기 제2 위성의 제2 통신 커버리지 내에서 제3 통신 커버리지를 가지며, 상기 제1 위성, 상기 제2 위성, 및 상 기 제3 위성은 각각 모바일 에지 컴퓨팅(Mobile Edge Computing: MEC) 기능을 지원하도록 마련되고, 상기 모바 일 노드는, 오프로딩 작업을 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상으로 전달할 수 있 다. 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성은, 상기 오프로딩 작업을 처리하기 위한 컴퓨팅 유닛 및 상기 오프로딩 작업의 순서를 스케줄링 하기 위한 스케줄러를 각각 포함할 수 있다.상기 제1 위성은, 상기 모바일 노드로부터 오프로딩 작업을 수신하는 경우, 상기 제1 위성의 제1 통신 커버리지 내에 제2 위성 및 제3 위성이 있는지를 확인하고, 상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성 중 하나 이상으로 상기 오프로딩 작업을 할당할 수 있다. 상기 제1 위성은, 상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성의 통신 관련 리소스, 통신 대역폭, 통신 비용, 및 오프로딩 작업 처리 마감시간 중 하나 이상을 고려하여 상기 오프로딩 작업을 상기 제2 위성 및 상기 제3 위성 중 하나 이상으로 할당할 수 있다. 상기 제1 위성은, 상기 오프로딩 작업의 처리 시간 및 통신 비용을 최소화 하면서 상기 오프로딩 작업을 수행할 위성의 선택, 상기 통신 대역폭, 및 상기 통신 관련 리소스의 할당을 최적화 하되, 각 위성들을 에이전트로 하 는 다중 에이전트 강화 학습 모델(Multi Agent Reinforcement Learning Model)을 이용하여 최적화 할 수 있다. 상기 다중 에이전트 강화 학습 모델은, 입력되는 상태 정보에 대해 기 설정된 정책에 기초하여 상기 에이전트의 행동을 결정하는 정책 네트워크 및 상기 정책 네트워크가 결정한 행동에 대해 피드백을 제공하여 상기 정책을 업데이트 하도록 하는 가치 네트워크를 포함하고, 상기 상태 정보는, 위성 상태 정보 및 노드 상태 정보를 포함 하며, 상기 위성 상태 정보는, 각 위성의 위치, 각 위성의 통신 관련 리소스, 각 위성의 통신 대역폭, 각 위성 의 통신 비용, 및 각 위성의 통신 범위 중 하나 이상을 포함하고, 상기 노드 상태 정보는, 각 모바일 노드의 위 치, 각 모바일 노드가 요청한 오프로딩 작업량, 및 각 모바일 노드가 설정된 오프로딩 작업의 마감 시간 중 하 나 이상을 포함할 수 있다. 상기 다중 에이전트 강화 학습 모델은, 상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동을 입력 받고, 상기 상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동에 기초하여 상기 행동에 대한 보상과 관련된 다른 에이전트들의 어텐션 가중치를 생성하는 어텐션 네트워 크를 더 포함할 수 있다. 개시되는 일 실시예에 따른 통신 방법은, 제1 위성, 제2 위성, 제3 위성, 및 모바일 노드를 포함하는 지능형 교 통 시스템의 통신 방법으로서, 상기 제1 위성은, 제1 통신 커버리지, 제1 통신 비용, 및 제1 통신 관련 리소스 를 가지고, 상기 제2 위성은, 상기 제1 통신 커버리지 보다 좁은 제2 통신 커버리지, 상기 제1 통신 비용 보다 적은 제2 통신 비용, 및 상기 제1 통신 관련 리소스 보다 작은 제2 통신 관련 리소스를 가지며, 상기 제3 위성 은, 상기 제2 통신 커버리지 보다 좁은 제3 통신 커버리지, 상기 제2 통신 비용 보다 적은 제3 통신 비용, 및 상기 제2 통신 관련 리소스 보다 작은 제3 통신 관련 리소스를 가지고, 상기 통신 방법은, 상기 모바일 노드에 서, 오프로딩 작업을 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하나 이상으로 전달하는 단계를 포함 한다. 상기 제2 위성은, 상기 제1 위성의 제1 통신 커버리지 내에서 제2 통신 커버리지를 가지고, 상기 제3 위성은, 상기 제2 위성의 제2 통신 커버리지 내에서 제3 통신 커버리지를 가지며, 상기 제1 위성, 상기 제2 위성, 및 상 기 제3 위성은, 각각 모바일 에지 컴퓨팅(Mobile Edge Computing: MEC) 기능을 지원하도록 마련될 수 있다. 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성은, 상기 오프로딩 작업을 처리하기 위한 컴퓨팅 유닛 및 상기 오프로딩 작업의 순서를 스케줄링 하기 위한 스케줄러를 각각 포함할 수 있다. 상기 통신 방법은, 상기 제1 위성에서, 상기 모바일 노드로부터 오프로딩 작업을 수신하는 경우, 상기 제1 위성 의 제1 통신 커버리지 내에 제2 위성 및 제3 위성이 있는지를 확인하는 단계; 및 상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성 중 하나 이상으로 상기 오프로딩 작업을 할당하는 단계를 더 포함할 수 있다. 상기 오프로딩 작업을 할당하는 단계는, 상기 제1 통신 커버리지 내의 제2 위성 및 제3 위성의 통신 관련 리소 스, 통신 대역폭, 통신 비용, 및 오프로딩 작업 처리 마감시간 중 하나 이상을 고려하여 상기 오프로딩 작업을 상기 제2 위성 및 상기 제3 위성 중 하나 이상으로 할당할 수 있다. 상기 오프로딩 작업을 할당하는 단계는, 상기 오프로딩 작업의 처리 시간 및 통신 비용을 최소화 하면서 상기 오프로딩 작업을 수행할 위성의 선택, 상기 통신 대역폭, 및 상기 통신 관련 리소스의 할당을 최적화 하되, 각 위성들을 에이전트로 하는 다중 에이전트 강화 학습 모델(Multi Agent Reinforcement Learning Model)을 이용 하여 최적화 할 수 있다. 상기 다중 에이전트 강화 학습 모델은, 입력되는 상태 정보에 대해 기 설정된 정책에 기초하여 상기 에이전트의 행동을 결정하는 정책 네트워크 및 상기 정책 네트워크가 결정한 행동에 대해 피드백을 제공하여 상기 정책을 업데이트 하도록 하는 가치 네트워크를 포함하고, 상기 상태 정보는, 위성 상태 정보 및 노드 상태 정보를 포함하며, 상기 위성 상태 정보는, 각 위성의 위치, 각 위성의 통신 관련 리소스, 각 위성의 통신 대역폭, 각 위성 의 통신 비용, 및 각 위성의 통신 범위 중 하나 이상을 포함하고, 상기 노드 상태 정보는, 각 모바일 노드의 위 치, 각 모바일 노드가 요청한 오프로딩 작업량, 및 각 모바일 노드가 설정된 오프로딩 작업의 마감 시간 중 하 나 이상을 포함할 수 있다. 상기 다중 에이전트 강화 학습 모델은, 상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동을 입력 받고, 상기 상기 위성 상태 정보, 상기 노드 상태 정보, 및 상기 정책 네트워크가 결정한 행동에 기초하여 상기 행동에 대한 보상과 관련된 다른 에이전트들의 어텐션 가중치를 생성하는 어텐션 네트워 크를 더 포함할 수 있다. 개시되는 다른 실시예에 따른 시스템은, 위성을 이용한 지능형 교통 시스템으로서, 지상에서 제1 고도에 위치하 고 제1 통신 커버리지를 갖는 제1 위성; 상기 제1 고도 보다 낮은 제2 고도에 위치하고 상기 제1 통신 커버리지 보다 좁은 제2 커버리지를 갖는 하나 이상의 제2 위성; 상기 제2 고도 보다 낮은 제3 고도에 위치하고 상기 제2 통신 커버리지 보다 좁은 제3 커버리지를 갖는 하나 이상의 제3 위성; 및 상기 제1 위성, 상기 제2 위성, 및 상 기 제3 위성 중 하나 이상과 데이터 통신을 수행하며, 통신 장비가 장착된 이동 수단인 하나 이상의 모바일 노 드를 포함하고, 상기 모바일 노드는, 오프로딩 작업을 상기 제1 위성, 상기 제2 위성, 및 상기 제3 위성 중 하 나 이상으로 전달한다."}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시되는 실시예에 의하면, 6G 네트워크 내에서 위성 기반 지능형 교통 시스템(ITS)의 오프로딩 및 컴퓨팅 기능 을 통합하여 수행할 수 있고, 네트워크 리소스의 할당을 최적화 하여 전반적인 성능을 개선할 수 있게 된다. 또 한, 다계층 위성 네트워크를 이용함으로써 추가 스펙트럼 리소스가 제공되어 향상된 광대역 서비스를 제공할 수 있게 된다."}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 이하의 설명에 있어서, 신호 또는 정보의 \"전송\", \"통신\", \"송신\", \"수신\" 기타 이와 유사한 의미의 용어는 일 구성요소에서 다른 구성요소로 신호 또는 정보가 직접 전달되는 것뿐만이 아니라 다른 구성요소를 거쳐 전달되 는 것도 포함한다. 특히 신호 또는 정보를 일 구성요소로 \"전송\" 또는 \"송신\"한다는 것은 그 신호 또는 정보의 최종 목적지를 지시하는 것이고 직접적인 목적지를 의미하는 것이 아니다. 이는 신호 또는 정보의 \"수신\"에 있 어서도 동일하다. 또한 본 명세서에 있어서, 2 이상의 데이터 또는 정보가 \"관련\"된다는 것은 하나의 데이터(또 는 정보)를 획득하면, 그에 기초하여 다른 데이터(또는 정보)의 적어도 일부를 획득할 수 있음을 의미한다. 또한, 제1, 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로 사용될 수 있다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성 요소는 제2 구성 요소로 명 명될 수 있고, 유사하게 제2 구성 요소도 제1 구성 요소로 명명될 수 있다. 도 1은 본 발명의 일 실시예에 따른 다계층 위성을 이용한 지능형 교통 시스템(Intelligent Transportation System)의 서비스 아키텍처를 개략적으로 나타낸 도면이고, 도 2는 본 발명의 일 실시예에 따른 다계층 위성들 의 통신 범위를 개략적으로 나타낸 도면이다. 도 1 및 도 2를 참조하면, 지능형 교통 시스템은 제1 위성, 제2 위성, 제3 위성, 및 모바 일 노드를 포함할 수 있다. 지능형 교통 시스템은 제1 위성, 제2 위성, 및 제3 위성(10 6)을 이용하여 모바일 노드의 오프로딩 작업 및 컴퓨팅 서비스 중 하나 이상을 수행할 수 있다. 위성, 제2 위성, 제3 위성, 및 모바일 노드는 각각 어플리케이션 계층(application layer)을 구비한다. 도 1에서는 설명의 편의 상 어플리케이션 계층을 별도로 표시하였다. 어플리케이션 계층은 신호등 제어, 비정상 교통 감지, 날씨 업데이트, GPS 정보 업데이트, 긴급 알림, 및 교통 흐름 예측 등 다양한 ITS(Intelligent Transportation System) 기능을 처리할 수 있다. 이러한 기능은 각 모바일 노드로부터 수집한 데이터를 이용하여 처리될 수 있다. 제1 위성은 제1 통신 커버리지(A)를 갖는 위성일 수 있다. 제1 위성은 위성들 중 상공의 가장 높은 고도에서 가장 넓은 커버리지를 갖는 위성으로 GEO(Geostationary Earth Orbit) 위성일 수 있다. 모바일 노드 는 제1 위성에 오프로딩 작업을 전달할 수 있으며, 제1 위성을 이용함에 따른 제1 통신 비용을 지불할 수 있다. 제1 위성은 위성들 중 가장 많은 제1 통신 관련 리소스(예를 들어, 채널, 전력, 컴퓨팅 자원 등)를 가지고 있을 수 있다. 제1 위성은 통신 커버리지 및 통신 관련 리소스가 가장 큰 계층의 위성 일 수 있다. 제2 위성은 제1 통신 커버리지(A) 보다 좁은 제2 통신 커버리지(B)를 갖는 위성일 수 있다. 제2 위성(10 4)은 제1 위성의 제1 통신 커버리지(A) 내에서 제2 통신 커버리지(B)를 가질 수 있다. 제1 통신 커버리지 (A) 내에는 하나 이상의 제2 위성이 위치할 수 있다. 제2 위성은 제1 위성 보다 낮은 고도를 갖 는 위성일 수 있다. 일 실시예로, 제2 위성은 LEO(Low Earth Orbit) 위성 또는 MEO(Middle Earth Orbit) 위성일 수 있다. 모바일 노드는 제2 위성에 오프로딩 작업을 전달할 수 있으며, 제2 위성을 이용함에 따른 제1 통신 비용보다 적은 제2 통신 비용을 지불할 수 있다. 제2 위성은 제1 통신 관련 리소스보다 작은 제2 통 신 관련 리소스를 가질 수 있다. 제2 위성은 통신 커버리지 및 통신 관련 리소스가 중간인 계층의 위성일 수 있다. 제3 위성은 제2 통신 커버리지(B) 보다 좁은 제3 통신 커버리지(C)를 갖는 위성일 수 있다. 제3 위성(10 6)은 제2 위성의 제2 통신 커버리지(B) 내에서 제3 통신 커버리지(C)를 가질 수 있다. 제2 통신 커버리지 (B) 내에는 하나 이상의 제3 위성이 위치할 수 있다. 제3 위성은 제2 위성 보다 낮은 고도를 갖 는 위성일 수 있다. 일 실시예로, 제3 위성은 큐브 위성(즉, CubeSat)일 수 있다. 모바일 노드는 제3 위성에 오프로딩 작업을 전달할 수 있으며, 제3 위성을 이용함에 따른 제2 통신 비용보다 적은 제3 통신 비용을 지불할 수 있다. 제3 위성은 제2 통신 관련 리소스보다 작은 제3 통 신 관련 리소스를 가질 수 있다. 제3 위성은 통신 커버리지 및 통신 관련 리소스가 가장 낮은 계층의 위성 일 수 있다. 모바일 노드는 제1 위성, 제2 위성, 및 제3 위성을 이용하여 데이터 통신을 수행할 수 있 다. 모바일 노드는 데이터를 수집, 생성, 및 처리하는 기능을 구비할 수 있다. 일 실시예에서, 모바일 노드는 통신 장비가 장착된 이동 수단(예를 들어, 항공기, 선박, 기차, 차량 등)일 수 있다. 모바일 노드 는 다양한 종류의 센서를 구비하여 다양한 종류의 데이터를 수집할 수 있다. 여기서, 제1 위성, 제2 위성, 및 제3 위성은 각각 모바일 에지 컴퓨팅(Mobile Edge Computing: MEC) 기능을 지원하도록 마련될 수 있다. 일 실시예에서, 제1 위성, 제2 위성, 및 제3 위성은 모바일 노드의 오프로딩 작업을 수신하여 처리하도록 마련될 수 있다. 이를 위해, 제1 위성, 제2 위 성, 및 제3 위성은 각각 오프로딩 작업을 처리하기 위한 컴퓨팅 유닛 및 오프로딩 작업의 순서를 스 케줄링 하기 위한 스케줄러를 포함할 있다. 제1 위성은 백본 네트워크의 코어 네트워크 서버의 역할을 할 수 있다. 제1 위성은 제1 통신 커버리 지 내에 제2 위성 및 제3 위성이 없는 경우, 모바일 노드의 오프로딩 작업을 직접 수신하여 처 리할 수 있다. 모바일 노드는 글로벌 연결 가용성으로 인해 언제든지 제1 위성과 통신하여 오프로딩 작업을 전달할 수 있으나, 제1 위성을 이용하면 제2 위성 또는 제3 위성을 이용하는 경우보다 높은 통신 비용 을 지불해야 한다. 또한, 제2 위성 및 제3 위성은 제1 위성 보다 지구 표면에 가까워 지연 시간 이 짧기 때문에 오프로딩 작업을 수행하기에도 실용적이다. 이에, 모바일 노드로부터 오프로딩 작업을 수신하는 경우, 제1 위성은 제1 통신 커버리지 내에 제2 위성 및 제3 위성이 있는지를 확인하고, 태스크를 제1 통신 커버리지 내에 위치하는 제2 위성 및 제3 위성 중 하나 이상으로 오프로드 할 수 있다. 이때, 제1 위성은 서브 태스크의 작업량(즉, 오 프로딩 작업량), 제2 위성 및 제3 위성의 통신 관련 리소스, 통신 대역폭, 및 오프로딩 처리 마감시 간(데드라인) 등을 고려하여 오프로딩 작업을 제2 위성 및 제3 위성 중 하나 이상에 할당할 수 있다. 여기서, 오프로딩 작업의 처리 시간 및 통신 비용을 최소화 하면서 오프로딩 작업을 수행할 위성의 선택, 통신 대역폭, 및 통신 관련 리소스 할당 등을 최적화 할 필요가 있다. 이러한 최적화 문제를 해결하기 위해 개시되는 실시예에서는 각 위성이 분산 에이전트 역할을 하는 다중 에이전트 강화 학습 모델을 이용할 수 있다. 이에 대 한 자세한 설명은 후술하기로 한다. 도 3은 본 발명의 일 실시예에 따른 다중 에이전트 강화 학습을 위한 개략도를 나타낸 것이다. 도 3을 참조하면, ITS(Intelligent Transportation System) 네트워크 환경은 제1 위성, 제2 위성, 제3 위성 , 및 모바일 노드의 모든 정보를 포함하는 전체 네트워크 환경을 의미할 수 있다. 네트워크 내 정보는 각 위성(에이전트)을 공동으로 학습하는데 사용될 수 있다. 각 에이전트는 네트워크 환경으 로부터 상태에 대한 관찰을 받을 수 있다. 여기서, 각 위성은 에이전트(agent)의 역할을 하게 된다. 이하에서, 위성과 에이전트의 용어는 혼용되어 사용될 수 있다. 다중 에이전트 강화 학습 모델은 각 위성에 설치될 수 있 다. 이때, 각 위성들은 협력적 다중 에이전트 근거리 정책 최적화(cooperative multi-agent proximal policy optimization)를 통해 해당 모델에 대해 심층 강화 학습을 수행할 수 있다. 다중 에이전트 강화 학습 모델은 정책 네트워크(policy network)와 가치 네트워크(value network)를 가질 수 있다. 여기서, 정책 네트워크 및 가치 네트워크는 다중 에이전트 강화 학습 을 위한 인공 신경망일 수 있다. 가치 네트워크는 각 에이전트의 로컬 비평가 역할을 할 수 있다. 가치 네 트워크는 각 에이전트(위성)가 새 정책을 학습하면 그 정확성에 대한 즉각적인 피드백을 제공할 수 있다. 정책 네트워크는 주요 정책의 학습 단위 역할을 할 수 있다. 정책은 각 에이전트에서 의사 결정(즉, 행 동)을 내리는데 사용될 수 있다. 각 에이전트가 분산적으로 취한 행동(action)은 비평가(critic)에서 평가에 사용될 수 있다. 비평가는 모든 에 이전트 간의 협력을 보장하며, 모든 에이전트의 전역 손실을 계산하고 시스템의 성능이 전역적으로 수렴되도록 할 수 있다. 분산된 각 에이전트의 결과를 분석하기 위해 비평가(Critic)에게 현재의 보상(reward)을 보낼 수 있으며, 각 보상 및 상태는 경험 풀(Experience Pool)에 저장될 수 있다. 정책 네트워크는 액터(actor)로 지칭되고, 가치 네트워크는 비평가(critic)로 지칭될 수 있다. 정책 네트워크(액터)는 입력되는 상태에 대해 기 설정된 정책에 기초하여 행동을 결정하는 신경망일 수 있다. 가치 네트워크(크리틱)는 정책 네트워크가 결정한 행동에 대해 피드백을 제공하여 정책 네트워크 의 정책을 업데이트하도록 하는 신경망일 수 있다. 정책 네트워크(즉, 액터)는 로컬 정보(즉, 해당에이전트의 정보)만 보고 이를 기반으로 행동(action)을 생성하나, 가치 네트워크(즉, 비평가)는 자신을 더 잘 최적화하기 위해 다른 에이전트(즉, 다른 위성들)의 전체 정보를 볼 수 있다. 다중 에이전트 강화 학습 모델로 입력되는 상태 정보는 위성 상태 정보 및 노드 상태 정보를 포함할 수 있 다. 위성 상태 정보는 각 위성에 대한 상태 정보로서, 각 위성의 위치(고도, 앙각, 방위각 등), 각 위성의 컴퓨 팅 리소스(예를 들어, CPU 처리 속도, 메모리 량, 및 잔여 메모리 량 등), 각 위성의 통신 대역폭, 각 위성의 통신 비용, 및 각 위성의 통신 범위 등을 포함할 수 있다. 노드 상태 정보는 각 모바일 노드에 대한 상태 정보 로서, 모바일 노드의 위치, 모바일 노드가 요청한 오프로딩 작업량, 및 모바일 노드가 설정한 오프로딩 작업의 마감시간 등을 포함할 수 있다. 각 모바일 노드는 자신의 노드 상태 정보를 위성으로 전달할 수 있다. 각 위성 은 위성 상태 정보 및 노드 상태 정보를 포함하는 상태 정보를 다중 에이전트 강화 학습 모델로 전달할 수 있다. 각 위성(에이전트)은 담당 지역에서 최적의 전력을 얻은 후, 상태 정보(위성 상태 정보 및 노드 상태 정보를 포 함)를 정책 네트워크에게 전달할 수 있다. 정책 네트워크는 상태 정보에 기초하여 행동(action)을 결 정할 수 있다. 정책 네트워크는 상태 정보에 기초하여 행동 확률(action probability)을 생성한 후, 로컬 환경과 상호 작용하는 행동 분포를 행동 확률에 따라 샘플링하고 다음 상태로 이동하기 전에 보상을 얻을 수 있 다. 이때, 보상은 데이터 처리량과 QoS(Quality of Service)의 공정성을 즉각적인 보상으로 할 수 있다. 각 위성은 위성의 위치, 컴퓨팅 리소스, 및 통신 대역폭 중 하나 이상을 변경하는 행동을 결정할 수 있다. 이때, 결정되는 행동은 다중 에이전트 강화 학습 모델의 정책으로부터 획득되며, 강화 학습 알고리즘을 통 해 훈련될 수 있다. 에이전트에서 행동을 실행하게 되면 실행된 행동의 행동 확률(또는 행동 분포)에 따라 상태가 변경되게 된다. 이때, 네트워크 환경으로부터 보상(reward)를 얻게 되며 경험 풀에 이에 따른 경험이 저장된다. 또한, 각 에이전트들의 협력을 강화하기 위해 글로벌 보상을 받을 수 있다. 글로벌 보상은 모든 에이전트들이 공유하며, 강화 학습 모델은 최적의 행동을 통해 글로벌 보상이 최대화 되도록 학습될 수 있다. 한편, 다중 에이전트 강화 학습 모델은 어텐션 네트워크를 더 포함할 수 있다. 네트워크 환경으로부 터 관찰된 상태 정보(위성 상태 정보 및 노드 상태 정보) 및 정책 네트워크가 결정한 행동은 어텐션 네트 워크로 각각 입력될 수 있다. 각 에이전트는 어텐션 네트워크를 통해 정책을 학습하는 동안 자신이 결정한 행동에 대한 보상과 관련되어 다른 에이전트들의 영향력 또는 중요도를 나타내는 어텐션 가중치를 생성 할 수 있다. 즉, 어텐션 네트워크는 상태 정보 및 행동에 기초하여 쿼리를 생성하고, 키-값 함수를 통해 다른 에이전트들의 어텐션 가중치를 생성하여 다른 에이전트들에 대한 우선 순위를 설정할 수 있다. 개시되는 실시예에 의하면, 6G 네트워크 내에서 위성 기반 지능형 교통 시스템(ITS)의 오프로딩 및 컴퓨팅 기능 을 통합하여 수행할 수 있고, 네트워크 리소스의 할당을 최적화 하여 전반적인 성능을 개선할 수 있게 된다. 또 한, 다계층 위성 네트워크를 이용함으로써 추가 스펙트럼 리소스가 제공되어 향상된 광대역 서비스를 제공할 수 있게 된다. 도 4는 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하 기 위한 블록도이다. 도시된 실시예에서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가 질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 일 실시예에서, 컴퓨팅 장치는 제1 위성일 수 있다. 또한, 컴퓨팅 장치는 제2 위성일 수 있다. 또한, 컴퓨팅 장치는 제3 위성일 수 있다. 또한, 컴퓨팅 장치는 모바일 노드일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워 크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다."}
{"patent_id": "10-2023-0125939", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서 본 발명의 대표적인 실시예들을 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후술하는 특허 청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2023-0125939", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 다계층 위성을 이용한 지능형 교통 시스템(Intelligent Transportation System)의 서비스 아키텍처를 개략적으로 나타낸 도면 도 2는 본 발명의 일 실시예에 따른 다계층 위성들의 통신 범위를 개략적으로 나타낸 도면 도 3은 본 발명의 일 실시예에 따른 다중 에이전트 강화 학습을 위한 개략도 도 4는 예시적인 실시예들에서 사용되기에 적합한 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위 한 블록도"}
