{"patent_id": "10-2022-0162976", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0079749", "출원번호": "10-2022-0162976", "발명의 명칭": "채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "강기동"}}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 연산 장치를 포함하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법에 있어서, 데이터 병렬화 처리 적용 여부를 판단하는 단계;상기 복수의 연산 장치에 대하여 입력 데이터를 균등 분배할 때의 연산 시간 및 통신 시간을 산출하는 단계; 및상기 연산 시간 및 통신 시간에 기반하여 상기 복수의 연산 장치에 상기 입력 데이터를 불균등 분배하는 단계를 포함하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 입력 데이터를 불균등 분배하는 단계는상기 복수의 연산 장치가 채널에 순차적으로 접근할 수 있도록 각 연산 장치에 분배된 입력 데이터 간의 크기차이가 일정하게 상기 입력 데이터를 분배하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기는 상기 연산 시간에서 상기 통신 시간에 비례하는값을 뺀 목표 연산 시간에 상응하도록 설정되는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능모델 분산 학습 방법."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서,상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기는 하기 수학식 1에 의해 결정되고, [수학식 1]상기 수학식 1에서tnew는 상기 목표 연산 시간이고,tori는 상기 연산 시간이고,c는 상기 통신 시간이고, d는 복수 연산 장치의 수인 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 분배된 입력 데이터 간의 크기 차이는공개특허 10-2024-0079749-3-상기 통신 시간을 상기 복수 연산 장치의 수로 나눈 값에 상응하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 목표 연산 시간이 음수로 산출되면, 상기 목표 연산 시간으로 기설정된 양의 값을 이용하는 것을 특징으로하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 복수의 연산 장치는상기 불균등 분배된 입력 데이터의 크기에 기반하여 상기 공유 채널을 타임 디비전 방식으로 공유하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "복수의 연산 장치를 포함하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치에 있어서, 데이터 병렬화 처리 적용 여부를 판단하는 병렬화 식별부;상기 복수의 연산 장치에 대하여 입력 데이터를 균등 분배할 때의 연산 시간 및 통신 시간을 산출하는 프로파일링부; 및상기 연산 시간 및 통신 시간에 기반하여 상기 복수의 연산 장치에 상기 입력 데이터를 불균등 분배하는 데이터분배부를 포함하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 데이터 분배부는 상기 복수의 연산 장치가 채널에 순차적으로 접근할 수 있도록 각 연산 장치에 분배된 입력 데이터 간의 크기차이가 일정하게 상기 입력 데이터를 분배하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 데이터 분배부는 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기가 상기 연산 시간에서 상기 통신 시간에 비례하는값을 뺀 목표 연산 시간에 상응하도록 설정하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능모델 분산 학습 장치."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 9에 있어서,상기 데이터 분배부는 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기를 하기 수학식 1에 의해 결정하고, 공개특허 10-2024-0079749-4-[수학식 1]상기 수학식 1에서tnew는 상기 목표 연산 시간이고,tori는 상기 연산 시간이고,c는 상기 통신 시간이고, d는 복수 연산 장치의 수인 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 분배된 입력 데이터 간의 크기 차이는상기 통신 시간을 상기 복수 연산 장치의 수로 나눈 값에 상응하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 12에 있어서,상기 목표 연산 시간이 음수로 산출되면, 상기 목표 연산 시간으로 기설정된 양의 값을 이용하는 것을 특징으로하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치."}
{"patent_id": "10-2022-0162976", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 8에 있어서,상기 복수의 연산 장치는상기 불균등 분배된 입력 데이터의 크기에 기반하여 상기 공유 채널을 타임 디비전 방식으로 공유하는 것을 특징으로 하는 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치."}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법은 데이터 병렬화 처 리 적용 여부를 판단하는 단계, 상기 복수의 연산 장치에 대하여 입력 데이터를 균등 분배할 때의 연산 시간 및 통신 시간을 산출하는 단계 및 상기 연산 시간 및 통신 시간에 기반하여 상기 복수의 연산 장치에 상기 입력 데 이터를 불균등 분배하는 단계를 포함한다."}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 채널을 공유하는 네트워크 환경에서 다수의 연산 장치를 활용하여 인공지능 모델을 분산 학습하는 기 술에 관한 것이다. 구체적으로, 본 발명은 인공지능 모델의 병렬 처리 시 각 장치에 입력 데이터를 불균등하게 분배하여 통신 효율 을 향상시키는 기술에 관한 것이다."}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "AI 모델의 병렬 처리를 위해 현재 가장 일반적으로 적용되고 있는 기법은 데이터 병렬화(Data Parallelism)이다. 데이터 병렬화는 각 연산 장치(e.g., GPU)에 동일한 AI 모델을 복사하고, 입력 데이터를 분 산하여 동시에 처리하는 병렬화 기법이다. AI 모델 학습은 크게 입력 데이터를 처리하는 단계(forward)와 처리 된 결과를 모델에 반영하는 단계(backward)로 구성된다. AI 모델 학습에서 데이터 병렬화를 적용할 경우, 상기 처리된 결과를 반영하는 단계에서 모델의 동기화를 위해 각 장치 간에 통신이 발생한다. 이때, 장치 간 통신이 PCIe와 같은 통신 채널을 공유하는 네트워크 환경에서 이뤄지는 경우, 채널에 복수의 장 치가 동시에 접근함에 따라 통신 성능이 저하될 수 있으며, 이러한 통신 비효율을 개선하기 위한 기술에 대한 필요성이 절실히 대두된다. 선행기술문헌 특허문헌 (특허문헌 0001) 국내 공개특허공보 제10-2022-0098949호(발명의 명칭: 딥러닝 모델 분산 학습 시스템 및 방법)"}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 인공지능 모델의 병렬 처리 시 각 장치에 입력 데이터를 불균등하게 분배하여 통신 효율을 향 상시키는 것이다. 또한, 본 발명의 목적은 통신 채널을 공유하는 네트워크 환경에서 발생하는 통신 병목 현상을 완화하는 것이다."}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법은 데이터 병렬화 처리 적용 여부를 판단하는 단계, 상기 복수의 연산 장치에 대하여 입력 데이터를 균등 분배할 때의 연산 시간 및 통신 시간을 산출하는 단계 및 상기 연산 시간 및 통신 시간에 기반하여 상기 복수의 연산 장치에 상기 입력 데이터를 불균등 분배하는 단계를 포함한다. 이때, 상기 입력 데이터를 불균등 분배하는 단계는 상기 복수의 연산 장치가 채널에 순차적으로 접근할 수 있도 록 각 연산 장치에 분배된 입력 데이터 간의 크기 차이가 일정하게 상기 입력 데이터를 분배할 수 있다. 이때, 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기는 상기 연산 시간에서 상기 통신 시간에 비례 하는 값을 뺀 목표 연산 시간에 상응하도록 설정될 수 있다. 이때, 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기는 하기 수학식 1에 의해 결정되고, [수학식 1]"}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "상기 수학식 1에서 tnew는 상기 목표 연산 시간이고, tori는 상기 연산 시간이고, c는 상기 통신 시간이고, d는 복수 연산 장치의 수일 수 있다. 이때, 상기 분배된 입력 데이터 간의 크기 차이는 상기 통신 시간을 상기 복수 연산 장치의 수로 나눈 값에 상 응할 수 있다. 이때, 상기 목표 연산 시간이 음수로 산출되면, 상기 목표 연산 시간으로 기설정된 양의 값을 이용할 수 있다. 이때, 상기 복수의 연산 장치는 상기 불균등 분배된 입력 데이터의 크기에 기반하여 상기 공유 채널을 타임 디 비전 방식으로 공유할 수 있다. 또한, 상기한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치는 데이터 병렬화 처리 적용 여부를 판단하는 병렬화 식별부, 상기 복수의 연산 장치에 대하여 입력 데이터를 균등 분배할 때의 연산 시간 및 통신 시간을 산출하는 프로파일링부 및 상기 연산 시간 및 통신 시간에 기반하여 상기 복수의 연산 장치에 상기 입력 데이터를 불균등 분배하는 데이터 분배부를 포함한다. 이때, 상기 데이터 분배부는 상기 복수의 연산 장치가 채널에 순차적으로 접근할 수 있도록 각 연산 장치에 분 배된 입력 데이터 간의 크기 차이가 일정하게 상기 입력 데이터를 분배할 수 있다. 이때, 상기 데이터 분배부는 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기가 상기 연산 시간에서 상기 통신 시간에 비례하는 값을 뺀 목표 연산 시간에 상응하도록 설정할 수 있다. 이때, 상기 데이터 분배부는 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기를 하기 수학식 1에 의 해 결정하고, [수학식 1]"}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "상기 수학식 1에서 tnew는 상기 목표 연산 시간이고, tori는 상기 연산 시간이고, c는 상기 통신 시간이고, d는 복수 연산 장치의 수일 수 있다. 이때, 상기 분배된 입력 데이터 간의 크기 차이는 상기 통신 시간을 상기 복수 연산 장치의 수로 나눈 값에 상 응할 수 있다. 이때, 상기 목표 연산 시간이 음수로 산출되면, 상기 목표 연산 시간으로 기설정된 양의 값을 이용할 수 있다. 이때, 상기 복수의 연산 장치는 상기 불균등 분배된 입력 데이터의 크기에 기반하여 상기 공유 채널을 타임 디 비전 방식으로 공유할 수 있다."}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능 모델의 병렬 처리 시 각 장치에 입력 데이터를 불균등하게 분배하여 통신 효율을 향상시킬 수 있다. 또한, 본 발명은 통신 채널을 공유하는 네트워크 환경에서 발생하는 통신 병목 현상을 완화할 수 있다."}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 비록 \"제1\" 또는 \"제2\" 등이 다양한 구성요소를 서술하기 위해서 사용되나, 이러한 구성요소는 상기와 같은 용 어에 의해 제한되지 않는다. 상기와 같은 용어는 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용될 수 있다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있다. 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세 서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 또는 \"포함하는(comprising)\"은 언급된 구성요소 또는 단계가 하나 이상의 다른 구성요소 또는 단 계의 존재 또는 추가를 배제하지 않는다는 의미를 내포한다. 본 명세서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함 께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다."}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 해석될 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 도 1은 데이터 병렬화를 적용한 예시를 개념적으로 나타낸 도면이다. 도 1에서, 처리된 결과를 모델에 반영하는 단계(backward)에서 발생하는 연산(computation)은 통신 (communication)과 함께 발생하기 때문에 연산 표기는 생략한다. 도 1을 참조하면, 2개의 GPU간에 입력 데이터 처리 결과의 동기화를 위해 통신(communication)이 발생하는 것을 알 수 있다. 도 2는 메시 네트워크 환경에서의 데이터 병렬화 방법을 개념적으로 나타낸 도면이다. 도 2를 참조하면, 메시 네트워크 환경과 채널 공유 네트워크 환경에서 4개의 GPU에 데이터 병렬화를 적용한 것 을 볼 수 있다. Nvidia사의 NVLink 및 NVSwitch와 같은 전용 하드웨어를 도입할 경우, 메시(mesh) 네트워크를 구축함으로써 장 치 간 통신에서 장치 수가 늘어나더라도 채널에 간섭이 발생하지 않는다. 그러나, 해당 기술은 고가의 전용 하 드웨어를 요구할 뿐 만 아니라, Nvidia 사의 GPU들에만 적용 가능하므로 타사의 GPU나 FPGA 등 다른 NPU를 지원 하지 않는다. 이러한 전용 하드웨어 지원이 없다면, 장치 간 통신을 위해 PCIe와 같은 통신 채널을 공유하는 네트워크를 활용 하는데, 이러한 채널 공유 네트워크는 시분할 방식 등으로 활용되므로 여러 장치가 동시에 네트워크에 접근할 경우 통신 성능이 저하될 수 있다. 도 3은 채널 공유 네트워크 환경에서의 데이터 병렬화 방법을 개념적으로 나타낸다. 도 3을 참조하면, 도 2에 비하여 통신(Communication)에 많은 시간이 소요되는 것을 확인할 수 있다. 본 발명은 통신 채널을 공유하고 있는 네트워크 환경에서 다수의 연산 장치를 활용해 AI 모델을 분산 처리할 때, 통신 효율을 향상시킬 수 있는 분산 학습 방법이다. AI 모델을 분산 학습하는 가장 일반적인 방법은 데이터 병렬화다. 데이터 병렬화는 AI 모델을 각 연산 장치에 복제하고, 입력 데이터를 분할하여 분산 처리하는 방법이다. 이 때 각 연산 장치는 병렬적으로 입력 데이터를 처리한 뒤에 모델의 동기화를 위해 장치 간 통신이 발생하는데, 별도의 하드웨어 지원이 없다면 모든 연산 장치 가 동시에 통신을 시도함에 따라 통신 채널 병목 현상에 의해 학습 성능 저하가 발생할 수 있다. 본 발명은 이 와 같은 통신 채널 병목 현상에 따른 AI 모델 학습 성능 저하를 완화하기 위해, 각 연산 장치가 서로 다른 시간 에 독점적으로 네트워크를 활용하도록 입력 데이터를 분산하는 방법이다. 도 4는 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법을 나타낸 흐 름도이다. 도 4를 참조하면, 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법은 데이터 병렬화 처리 적용 여부를 판단하는 단계(S110), 상기 복수의 연산 장치에 대하여 입력 데이터를 균등 분 배할 때의 연산 시간 및 통신 시간을 산출하는 단계(S120) 및 상기 연산 시간 및 통신 시간에 기반하여 상기 복 수의 연산 장치에 상기 입력 데이터를 불균등 분배하는 단계(S130)를 포함한다. 이때, 상기 입력 데이터를 불균등 분배하는 단계(S130)는 상기 복수의 연산 장치가 채널에 순차적으로 접근할 수 있도록 각 연산 장치에 분배된 입력 데이터 간의 크기 차이가 일정하게 상기 입력 데이터를 분배할 수 있다. 이때, 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기는 상기 연산 시간에서 상기 통신 시간에 비례 하는 값을 뺀 목표 연산 시간에 상응하도록 설정될 수 있다. 이때, 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기는 하기 수학식 1에 의해 결정되고, [수학식 1]"}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기 수학식 1에서 tnew는 상기 목표 연산 시간이고, tori는 상기 연산 시간이고, c는 상기 통신 시간이고, d는 복수 연산 장치의 수일 수 있다. 이때, 상기 분배된 입력 데이터 간의 크기 차이는 상기 통신 시간을 상기 복수 연산 장치의 수로 나눈 값에 상 응할 수 있다. 이때, 상기 목표 연산 시간이 음수로 산출되면, 상기 목표 연산 시간으로 기설정된 양의 값을 이용할 수 있다. 이때, 상기 복수의 연산 장치는 상기 불균등 분배된 입력 데이터의 크기에 기반하여 상기 공유 채널을 타임 디 비전 방식으로 공유할 수 있다. 도 5는 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치의 구성을 나 타낸다. 도 5를 참조하면, 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치는 데이터 병렬화 식별부, 프로파일링부, 데이터 분할부, 데이터 병렬화 제어부로 구성된다. 데이터 병렬화 식별부는 데이터 병렬화 기술을 적용할 수 있는지 판단하고, 프로파일링부는 학습하려 는 AI 모델의 실행시간을 측정한다. 또한, 데이터 분할부는 측정된 실행시간을 기반으로 각 연산 장치에 입력할 데이터의 분할을 결정하고, 데이터 병렬화 제어부는 분할된 데이터를 각 장치에 전달하고 실제 데 이터 병렬화를 수행한다. 도 6은 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법을 상세히 나 타낸 흐름도이다. 도 6을 참조하면, 본 발명의 일 실시예에 따른 인공지능 모델 분산 학습 방법은 AI 모델 개발자가 데이터 병렬 화를 적용하는지를 판단한다(S310). 만약 데이터 병렬화를 적용하지 않는다면, 기존 방식대로(병렬화 없이 혹은 다른 병렬화 기법 적용) AI 모델 학습을 시작한다(S370). 데이터 병렬화를 적용하려 한다면 현재 네트워크 환경 이 채널 공유 네트워크인지 확인한다(S320). 만약 채널 공유 네트워크가 아니라면, 네트워크 채널 간섭에 따른 오버헤드가 없을 것으로 판단하여 기존 데이터 병렬화 기법을 적용한다(S360). 만약 채널 공유 네트워크를 사용 하고 있다면 본 발명의 적용을 시작한다. 본 발명을 적용하기 위해서는 기존 데이터 병렬화 사용시의 연산 및 통신 시간에 대한 정보가 필요하다. 해당 정보는 사전 프로파일링 혹은 온라인 프로파일링 등의 방법으로 얻을 수 있다(S330). 연산 및 통신에 소요되는 시간을 얻고 나면, 각 장치에 입력 데이터를 어떻게 분할해야 하는지 결정한다(S340). 각 장치에 입력 데이터를 분할하는 방법은 하기의 [수학식 1]을 이용하여 수행될 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "tnew는 첫 번째 연산 장치에 분배할 데이터(가장 작은 값)에 상응하는 연산 시간을 나타내며, d는 사용할 연산 장치의 수를, tori과 c는 각각 프로파일링 단계에서 측정된 연산 시간과 통신 시간을 나타낸다. 즉, tori 및 c는 프로파일링 단계에서 획득할 수 있고, d는 사전에 입력 가능한 값이므로 tnew를 획득할 수 있다. tnew 값을 구하면 다음 장치는 tnew + c/d, 그 다음 장치는 tnew + 2c/d … 마지막 장치는 tnew +((d-1)c)/d 와 같 이 연산 시간에 상응하는 데이터를 분배할 수 있다. 즉, 장치 간의 연산 시간 차이는 통신 시간을 장치의 수로 나눈 값에 상응할 수 있다. 만약 상기 수학식에서 tori 값 대비 c 값이 지나치게 크면, tnew 값이 음수가 될 수 있는데, 이 경우에 tnew 값 은 분배 가능한 최소 값을 설정(e.g., 1)한 뒤 각 장치에 전달할 데이터 값의 차이가 일정하도록 분배한다. 해 당 수식을 기반으로 각 연산 장치에 전달할 데이터가 결정되면, 실제 입력 데이터를 분할하여 각 장치에 전달하 고 데이터 병렬화를 적용 및 AI 모델 학습을 시작한다. 도 7은 본 발명의 일 실시예에 따른 방법과 기존 방법을 적용한 경우 통신 시간을 비교한 도면이다. 도 7을 참조하면, 본 발명의 일 실시예에 따른 방법을 적용하는 경우 각 장치가 공유 네트워크에 간섭 없이 순 차적으로 접근하게 되어 전체 실행시간(AI 모델 학습시간)을 개선할 수 있다. 도 8은 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치를 나타낸 블 록도이다. 도 8을 참조하면, 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치는 데이터 병렬화 처리 적용 여부를 판단하는 병렬화 식별부, 상기 복수의 연산 장치에 대하여 입력 데이터를 균등 분배할 때의 연산 시간 및 통신 시간을 산출하는 프로파일링부 및 상기 연산 시간 및 통신 시간에 기 반하여 상기 복수의 연산 장치에 상기 입력 데이터를 불균등 분배하는 데이터 분배부를 포함한다. 이때, 상기 데이터 분배부는 상기 복수의 연산 장치가 채널에 순차적으로 접근할 수 있도록 각 연산 장치 에 분배된 입력 데이터 간의 크기 차이가 일정하게 상기 입력 데이터를 분배할 수 있다. 이때, 상기 데이터 분배부는 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기가 상기 연산 시간 에서 상기 통신 시간에 비례하는 값을 뺀 목표 연산 시간에 상응하도록 설정할 수 있다. 이때, 상기 데이터 분배부는 상기 불균등 분배된 입력 데이터의 크기 중 가장 작은 크기를 하기 수학식 1 에 의해 결정하고, [수학식 1]"}
{"patent_id": "10-2022-0162976", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "상기 수학식 1에서 tnew는 상기 목표 연산 시간이고, tori는 상기 연산 시간이고, c는 상기 통신 시간이고, d는 복수 연산 장치의 수일 수 있다. 이때, 상기 분배된 입력 데이터 간의 크기 차이는 상기 통신 시간을 상기 복수 연산 장치의 수로 나눈 값에 상 응할 수 있다. 이때, 상기 목표 연산 시간이 음수로 산출되면, 상기 목표 연산 시간으로 기설정된 양의 값을 이용할 수 있다. 이때, 상기 복수의 연산 장치는 상기 불균등 분배된 입력 데이터의 크기에 기반하여 상기 공유 채널을 타임 디 비전 방식으로 공유할 수 있다. 도 9는 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다. 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치는 컴퓨터로 읽을 수 있는 기록매 체와 같은 컴퓨터 시스템에서 구현될 수 있다. 컴퓨터 시스템은 버스를 통하여 서로 통신하는 하나 이상의 프로세서, 메모리, 사용자 인터페이스 입력 장치, 사용자 인터페이스 출력 장치 및 스토리지를 포함할 수 있다. 또한, 컴퓨터 시스템은 네트워크에 연결되는 네트워크 인터페이스를 더 포함할 수 있다. 프로세서 는 중앙 처리 장치 또는 메모리나 스토리지에 저장된 프로그램 또는 프로세싱 인스트럭션들 을 실행하는 반도체 장치일 수 있다. 메모리 및 스토리지는 휘발성 매체, 비휘발성 매체, 분리형 매체, 비분리형 매체, 통신 매체, 또는 정보 전달 매체 중에서 적어도 하나 이상을 포함하는 저장 매체일 수 있 다. 예를 들어, 메모리는 ROM이나 RAM을 포함할 수 있다. 본 발명에서 설명하는 특정 실행들은 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어시스템들, 소프트웨어, 상기 시스템들의 다른 기능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재 들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “ 필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요 소가 아닐 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐만 아 니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한다 고 할 것이다."}
{"patent_id": "10-2022-0162976", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 데이터 병렬화를 적용한 예시를 개념적으로 나타낸 도면이다. 도 2는 메시 네트워크 환경에서의 데이터 병렬화 방법을 개념적으로 나타낸 도면이다. 도 3은 채널 공유 네트워크 환경에서의 데이터 병렬화 방법을 개념적으로 나타낸다. 도 4는 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법을 나타낸 흐 름도이다. 도 5는 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치의 구성을 나 타낸다. 도 6은 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 방법을 상세히 나 타낸 흐름도이다. 도 7은 본 발명의 일 실시예에 따른 방법과 기존 방법을 적용한 경우 통신 시간을 비교한 도면이다. 도 8은 본 발명의 일 실시예에 따른 채널 공유 네트워크 환경에서의 인공지능 모델 분산 학습 장치를 나타낸 블 록도이다. 도 9는 실시예에 따른 컴퓨터 시스템의 구성을 나타낸 도면이다."}
