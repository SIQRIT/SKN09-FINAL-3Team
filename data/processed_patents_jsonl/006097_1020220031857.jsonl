{"patent_id": "10-2022-0031857", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0055457", "출원번호": "10-2022-0031857", "발명의 명칭": "사용자 인터페이스 기반의 수술과정 분석 제공 방법 및 서버", "출원인": "(주)휴톰", "발명자": "임자연"}}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버에 의해 수행되는 사용자 인터페이스(User Interface) 기반의 수술과정 분석 제공 방법에 있어서,촬영된 전체 수술영상에서, 수술단계학습모델을 이용하여 개별 수술단계를 인식하는 단계;상기 인식된 수술단계 별로 스위칭 횟수 및 소요시간을 산출하는 단계;상기 인식된 수술단계 별로 출혈이벤트의 발생여부를 판단하는 단계; 및상기 스위칭 횟수, 소요시간 및 출혈이벤트를 기초로 수술단계별로 수술결과를 분석할 수 있는 상기 UI를 제공하는 단계를 포함하는,상기 UI는, 선택된 수술단계에 대한 영상이 재생되는 제1 영역, 전체 수술과정에 대한 요약을 표시하는 제2 영역 및 상기 제1 영역에서 재생되는 영역의 해당 부분의 분석 데이터를 표시하는 제3 영역 중 적어도 하나를 포함하는, 사용자 인터페이스 기반의 수술과정 분석 제공 방법."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 스위칭 횟수를 산출하는 단계는,상기 인식된 수술 단계가 이어지지 못하고 단절된 횟수를 카운팅 하는 단계를 포함하는, 사용자 인터페이스 기반의 수술과정 분석 제공 방법."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 수술단계학습모델은, 수술데이터를 이용하여 대상체의 수술에 필요한 적어도 하나 이상의 단계를 레이블로정의하고, 정의된 레이블 별로 학습영상을 입력하여 기계학습 된 것이며,상기 수술단계학습모델을 이용하여 상기 대상체의 수술단계를 인식하는 단계는, CNN(Convolutional neuralnetwork)을 이용한 딥러닝 기반의 학습에 기초하여 수술영상에서 특징 정보를 추출하고, 추출된 특징 정보를 기초로 수술단계를 인식하는 것인, 사용자 인터페이스 기반의 수술과정 분석 제공 방법."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 출혈이벤트의 발생여부를 판단하는 단계는,딥러닝 기반의 학습을 기초로 상기 촬영된 전체 수술영상에서 프레임 단위로 출혈 이벤트 발생 여부를 판단하는단계; 및상기 분리된 시간 영역을 이용하여 상기 출혈이벤트 발생여부를 상기 수술단계 인식결과에 연결하는 단계; 를포함하는 것인, 사용자 인터페이스 기반의 수술과정 분석 제공 방법."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 출혈이벤트의 발생여부를 판단하는 단계는,산출된 출혈량을 기초로 수술에 간섭이 있는 출혈인지 여부를 판단하고, 수술에 간섭이 없었던 경우는 제1 출혈이벤트로 인식하고, 수술에 간섭이 있었던 경우는 제2 출혈이벤트로 인식하는 단계를 더 포함하는, 사용자 인터공개특허 10-2022-0055457-3-페이스 기반의 수술과정 분석 제공 방법."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,상기 제1 출혈이벤트 또는 제2 출현이벤트 인지 여부는, 출혈이 발생한 시점에서의 상기 스위칭 횟수 및 상기수술단계의 소요시간을 기초로 판단되는 것인, 사용자 인터페이스 기반의 수술과정 분석 제공 방법."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "하드웨어인 컴퓨터와 결합되어, 제1항 내지 제6항 중 어느 한 항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "수술 과정 분석 결과를 사용자에게 제공하기 위한 사용자 인터페이스(User Interface)를 표시하는디스플레이부; 및하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의한 실행 시, 상기 하나 이상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하는 제어부를 포함하고,상기 제어부에서 수행되는 연산은,의료영상 촬영장비로부터 촬영된 전체 수술영상에서, 수술단계학습모델을 이용하여 개별 수술단계를 인식하고각각의 수술단계에 해당하는 시간영역을 분리하는 연산;상기 인식된 수술단계별로 스위칭 횟수 및 소요시간을 산출하는 연산;상기 인식된 수술단계별로 출혈이벤트의 발생여부를 판단하는 연산; 및상기 스위칭 횟수, 소요시간 및 출혈이벤트를 기초로 수술단계별로 수술결과를 분석할 수 있는 사용자인터페이스를 제공하는 연산을 포함하고,상기 UI는, 선택된 수술단계에 대한 영상이 재생되는 제1 영역, 전체 수술과정에 대한 요약을 표시하는 제2 영역 및 상기 제1 영역에서 재생되는 영역의 해당 부분의 분석 데이터를 표시하는 제3 영역 중 적어도 하나를 포함하는, 사용자 인터페이스 기반의 수술과정 분석 제공하는 서버."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 스위칭 횟수를 산출하는 연산은,상기 인식된 수술 단계가 이어지지 못하고 단절된 횟수를 카운팅 하는 연산을 포함하는, 사용자 인터페이스 기반의 수술과정 분석 제공하는 서버."}
{"patent_id": "10-2022-0031857", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서,상기 출혈 이벤트의 발생여부를 판단하는 연산은,산출된 출혈량을 기초로 수술을 중지할 필요가 있는 출혈인지 여부를 판단하고, 수술을 중지할 필요가 없었던경우는 제1 출혈이벤트로 인식하고, 수술을 중지할 필요가 있었던 경우는 제2 출혈이벤트로 인식하는 연산을 포함하는, 사용자 인터페이스 기반의 수술과정 분석 제공하는 서버."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자 인터페이스 기반의 수술과정 분석 제공 방법 및 서버를 개시한다. 일 실시예에 따른 사용자 인터페이스 기반의 수술과정 분석 방법은, 촬영된 전체 수술영상에서, 수술단계학습모 델을 이용하여 개별 수술단계를 인식하고 각각의 수술단계에 해당하는 시간영역을 분리하는 단계, 상기 인식된 수술단계별로 스위칭 횟수 및 소요시간을 산출하는 단계, 상기 인식된 수술단계별로 출혈이벤트의 발생여부를 판 단하는 단계, 및 상기 스위칭 횟수, 소요시간 및 출혈이벤트를 기초로 수술단계별로 수술결과를 분석할 수 있는 사용자인터페이스를 제공하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 수술 후 수술과정 분석 방법 및 시스템에 관한 것이다. 보다 상세하게는 본 건은 수술 후 영상의 개 별단계(Phase)를 학습모델을 통해 인식하고, 인식된 단계별 수술영상의 스위칭 결과, 소요시간 및 출혈 발생횟수를 카운팅하여 사용자에게 제공하는 것을 제공하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 의사들이 수술 전후로 환자의 수술 계획을 수립할 때, 환자의 CT(Computed Tomographic) 또는 MRI(Magnetic Resonance Imaging) 사진 등의 2차원 의료 영상을 참고한다. 이 경우, 대부분 환자의 장기 내부 에 존재하는 병변의 위치나 병변의 위치에 따른 혈관과의 관계 등을 2차원 의료 영상에 매칭하기 어려우며, 수 술 전에 장기 촬영 정보로 활용할 수단이 없으므로, 수술시 장기 내부 병변의 위치와 주위 혈관 분포 등을 파악 하는데 많은 한계가 있다. 또한, 수술 프로세스를 최적화하기 위한 시나리오 구상을 위해서는 사전에 촬영된 의료영상을 참고하거나 매우 숙련된 의사의 자문을 받아야 했는데, 의료영상만으로는 불필요한 프로세스의 판단이 어려웠으며 숙련된 의사의 자문은 특정 환자에 맞는 자문을 받기에 어려운 문제점이 있었다. 즉, 단순히 촬영된 의료영상만으로는 수술프 로세스의 최적화 및 평가를 위한 용도로는 활용되기 어려운 점이 많았다. 따라서, 3차원 의료영상(예를 들어, 3차원 수술도구 움직임 및 도구의 움직임으로 인해 발생하는 장기 내부의 변화에 대한 가상영상)을 이용하여 수술을 행하는데 있어서 불필요한 프로세스를 최소화하여 수술 프로세스를 최적화하고, 이에 기반한 수술보조 정보를 제공할 수 있는 방법에 대한 개발이 요구된다. 또한, 최근에는 의료영상의 분석에 딥러닝이 널리 이용되고 있다. 딥 러닝은 여러 비선형 변환기법의 조합을 통"}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "해 높은 수준의 추상화(abstractions, 다량의 데이터나 복잡한 자료들 속에서 핵심적인 내용 또는 기능을 요약 하는 작업)를 시도하는 기계학습 알고리즘의 집합으로 정의된다. 딥 러닝은 큰 틀에서 사람의 사고방식을 컴퓨 터에게 가르치는 기계학습의 한 분야로 볼 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2019-0080736호, 2019.07.08."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 수술결과 영상에서 수술단계(phase) 학습모델을 이용하여 개별 수술단계를 인식하고, 인식된 수술 단계별로 스위칭 횟수, 소요시간 및 출혈 이벤트를 발생여부를 표시한 UI를 사용자에게 제공하는 것이다. 또한, 수술결과 영상에서 인식된 각각의 수술 단계에서 출혈이 발생하였는지 여부를 판단하고, 출혈 발생 영역 및 출혈량을 측정하여 수술오류가 있었는지 판단하는 방법을 개시한다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 실시예에 따른 수술 후 수술과정 분석 방법은, 촬영된 전체 수술영 상에서, 수술단계학습모델을 이용하여 개별 수술단계를 인식하고 각각의 수술단계에 해당하는 시간영역을 분리 하는 단계; 상기 인식된 수술단계별로 스위칭 횟수 및 소요시간을 산출하는 단계; 상기 인식된 수술단계별로 출 혈이벤트의 발생여부를 판단하는 단계; 및 상기 스위칭 횟수, 소요시간 및 출혈이벤트를 기초로 수술단계별로 수술결과를 분석할 수 있는 사용자인터페이스를 제공하는 단계;를 포함할 수 있다. 또한, 상기 스위칭 횟수를 산출하는 단계는, 상기 인식된 수술 단계가 이어지지 못하고 단절된 횟수를 카운팅 하는 단계를 포함할 수 있다. 또한, 상기 수술단계학습모델은, 수술데이터를 이용하여 상기 대상체의 수술에 필요한 적어도 하나 이상의 단계 를 레이블로 정의하고, 정의된 레이블 별로 학습영상을 입력하여 기계학습 된 것이며, 상기 수술단계학습모델을이용하여 대상체의 수술단계를 인식하는 단계는, CNN(Convolutional neural network)을 이용한 딥러닝 기반의 학습에 기초하여 수술영상에서 특징 정보를 추출하고, 추출된 특징 정보를 기초로 수술단계를 인식할 수 있다. 또한, 상기 출혈 이벤트의 발생여부를 판단하는 단계는, 딥러닝 기반의 학습을 기초로 상기 인식된 수술단계의 수술영상 내 출혈 영역이 존재하는지 판단하는 단계; 상기 판단결과를 기초로 출혈영역의 위치를 판단하는 단계; 및 상기 출혈영역의 위치를 기초로 출혈량을 산출하는 단계를 포함할 수 있다. 또한, 상기 출혈이벤트의 발생여부를 판단하는 단계는, 산출된 출혈량을 기초로 수술을 중지할 필요가 있는 출 혈인지 여부를 판단하고, 수술을 중지할 필요가 없었던 경우는 제1 출혈이벤트로 인식하고, 수술을 중지할 필요 가 있었던 경우는 제2 출혈이벤트로 인식하는 단계를 더 포함할 수 있다. 또한, 상기 제1 출혈이벤트 또는 제2 출현이벤트 인지 여부는, 출혈이 발생한 시점에서의 상기 스위칭 횟수 및 상기 수술단계의 소요시간을 기초로 판단될 수 있다. 본 발명의 일 실시예에 따른 컴퓨터 프로그램은 하드웨어인 컴퓨터와 결합되어, 상기 수술과정 분석 방법을 수 행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장될 수 있다. 본 발명의 일 실시예에 따른 수술과정 분석 시스템은, 수술영상을 촬영하기 위한 의료영상 촬영장비; 수술 과정 분석 결과를 사용자에게 제공하기 위한 디스플레이부; 및 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서 에 의한 실행 시, 상기 하나 이상의 프로세서가 연산을 수행하도록 하는 명령들이 저장된 하나 이상의 메모리를 포함하는 제어부를 포함하고, 상기 제어부에서 수행되는 연산은, 촬영된 전체 수술영상에서, 수술단계학습모델 을 이용하여 개별 수술단계를 인식하고 각각의 수술단계에 해당하는 시간영역을 분리하는 연산; 상기 인식된 수 술단계별로 스위칭 횟수 및 소요시간을 산출하는 연산; 상기 인식된 수술단계별로 출혈이벤트의 발생여부를 판 단하는 연산; 및 상기 스위칭 횟수, 소요시간 및 출혈이벤트를 기초로 수술단계별로 수술결과를 분석할 수 있는 사용자인터페이스를 제공하는 연산;을 포함할 수 있다. 또한, 상기 스위칭 횟수를 산출하는 연산은, 상기 인식된 수술 단계가 이어지지 못하고 단절된 횟수를 카운팅 하는 연산을 포함할 수 있다. 또한, 상기 출혈 이벤트의 발생여부를 판단하는 연산은, 산출된 출혈량을 기초로 수술을 중지할 필요가 있는 출 혈인지 여부를 판단하고, 수술을 중지할 필요가 없었던 경우는 제1 출혈이벤트로 인식하고, 수술을 중지할 필요 가 있었던 경우는 제2 출혈이벤트로 인식하는 연산을 포함할 수 있다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 본 발명의 일 실시 예에 따르면, 수술결과 영상에서 각 수술단계에 대응하는 분석결과를 사용자에게 제공 함으로써 수술 오류를 판단하는데 도움을 주고, 사용자가 피드백을 통해 수술 프로세스를 최적화할 수 있도록 할 수 있다. 특히, 각 수술 단계별로 특화된 스위칭 횟수, 소요시간 및 출혈 이벤트를 발생여부를 표시한 UI를 사용자 선택 적으로 제공하여, 사용자의 수술 숙련도를 높임과 동시에 수술에서 원치 않는 출혈을 발생시키거나 장기를 손상 시킬 가능성을 낮출 수 있도록 효율적으로 평가 결과를 제공할 수 있다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서 \"영상\"은 이산적인 영상 요소들(예를 들어, 2차원 영상에 있어서의 픽셀들 및 3D 영상에 있어서 의 복셀들)로 구성된 다차원(multi-dimensional) 데이터를 의미할 수 있다. 예를 들어, 영상은 CT 촬영 장치에 의해 획득된 대상체의 의료 영상 등을 포함할 수 있다. 본 명세서에서 \"대상체(object)\"는 사람 또는 동물, 또는 사람 또는 동물의 일부 또는 전부일수 있다. 예를 들 어, 대상체는 간, 심장, 자궁, 뇌, 유방, 복부 등의 장기, 및 혈관 중 적어도 하나를 포함할 수 있다. 본 명세서에서 \"사용자\"는 의료 전문가로서 의사, 간호사, 임상 병리사, 의료 영상 전문가 등이 될 수 있으며, 의료 장치를 수리하는 기술자가 될 수 있으나, 이에 한정되지 않는다. 본 명세서에서 \"의료영상데이터\"는 의료영상 촬영장비로 촬영되는 의료영상으로서, 대상체의 신체를 3차원 모델 로 구현 가능한 모든 의료영상을 포함한다. \"의료영상데이터\"는 컴퓨터 단층촬영(Computed Tomography;CT)영상, 자기공명영상(Magnetic Resonance Imaging; MRI), 양전자 단층촬영(Positron Emission Tomography; PET) 영상 등을 포함할 수 있다. 본 명세서에서 \"가상신체모델\"은 의료영상데이터를 기반으로 실제 환자의 신체에 부합하게 생성된 모델을 의미 한다. \"가상신체모델\"은 의료영상데이터를 그대로 3차원으로 모델링하여 생성한 것일 수도 있고, 모델링 후에 실제 수술 시와 같게 보정한 것일 수도 있다. 본 명세서에서 \"가상수술데이터\"는 가상신체모델에 대해 수행되는 리허설 또는 시뮬레이션 행위를 포함하는 데 이터를 의미한다. \"가상수술데이터\"는 가상공간에서 가상신체모델에 대해 리허설 또는 시뮬레이션이 수행된 영 상데이터일 수도 있고, 가상신체모델에 대해 수행된 수술동작에 대해 기록된 데이터일 수도 있다. 또한, \"가상 수술데이터\"는 수술학습모델을 학습시키기 위한 학습데이터를 포함할 수도 있다. 본 명세서에서 \"실제수술데이터\"는 실제 의료진이 수술을 수행함에 따라 획득되는 데이터를 의미한다. \"수술데 이터\"는 실제 수술과정에서 수술부위를 촬영한 영상데이터일 수도 있고, 실제 수술과정에서 수행된 수술동작에 대해 기록된 데이터일 수도 있다. 본 명세서에서 수술단계(phase)는 특정한 수술유형의 전체 수술에서 순차적으로 수행되는 기본단계를 의미한다. 본 명세서에서 \"컴퓨터\"는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들이 모두 포함 된다. 예를 들어, 컴퓨터는 데스크 탑 PC, 노트북(Note Book) 뿐만 아니라 스마트폰(Smart phone), 태블릿 PC, 셀룰러폰(Cellular phone), 피씨에스폰(PCS phone; Personal Communication Service phone), 동기식/비동기식 IMT-2000(International Mobile Telecommunication-2000)의 이동 단말기, 팜 PC(Palm Personal Computer), 개인용 디지털 보조기(PDA; Personal Digital Assistant) 등도 해당될 수 있다. 또한, 헤드마운트 디스플레이 (Head Mounted Display; HMD) 장치가 컴퓨팅 기능을 포함하는 경우, HMD장치가 컴퓨터가 될 수 있다. 또한, 컴 퓨터는 클라이언트로부터 요청을 수신하여 정보처리를 수행하는 서버가 해당될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 일 실시 예에 따른 로봇수술 시스템을 도시한 도면이다. 도 1을 참조하면, 일 실시 예에 따라 로봇수술을 수행할 수 있는 시스템을 간략하게 도식화한 도면이 도시되어 있다. 도 1에 따르면, 로봇수술 시스템은 의료영상 촬영장비, 서버 및 수술실에 구비된 제어부, 영상촬영 부, 디스플레이 및 수술로봇을 포함한다. 실시 예에 따라서, 의료영상 촬영장비는 일 실시예에 따른 로봇수술 시스템에서 생략될 수 있다. 일 실시 예에서, 로봇수술은 사용자가 제어부를 이용하여 수술용 로봇을 제어함으로써 수행된다. 일 실 시 예에서, 로봇수술은 사용자의 제어 없이 제어부에 의하여 자동으로 수행될 수도 있다. 서버는 적어도 하나의 프로세서, 메모리 및 통신부를 포함하는 컴퓨팅 장치이다. 제어부는 적어도 하나의 프로세서, 메모리 및 통신부를 포함하는 컴퓨팅 장치를 포함한다. 일 실시 예에서, 제어부는 수술용 로봇을 제어하기 위한 하드웨어 및 소프트웨어 인터페이스를 포함한다. 영상촬영부는 적어도 하나의 이미지 센서를 포함한다. 즉, 영상촬영부는 적어도 하나의 카메라 장치를 포함하여, 수술부위를 촬영하는 데 이용된다. 일 실시 예에서, 영상촬영부는 수술로봇과 결합되어 이용 된다. 예를 들어, 영상촬영부는 수술로봇의 수술 암(Arm)과 결합된 적어도 하나의 카메라를 포함할 수 있다. 일 실시 예에서, 영상촬영부에서 촬영된 영상은 디스플레이에 표시된다. 제어부는 서버로부터 수술에 필요한 정보를 수신하거나, 수술에 필요한 정보를 생성하여 사용자에게 제 공한다. 예를 들어, 제어부는 생성 또는 수신된, 수술에 필요한 정보를 디스플레이에 표시한다. 예를 들어, 사용자는 디스플레이를 보면서 제어부를 조작하여 수술로봇의 움직임을 제어함으로써 로봇수술을 수행한다. 서버는 의료영상 촬영장비로부터 사전에 촬영된 대상체(환자)의 의료영상데이터를 이용하여 로봇수술에 필요한 정보를 생성하고, 생성된 정보를 제어부에 제공한다. 제어부는 서버로부터 수신된 정보를 디스플레이에 표시함으로써 사용자에게 제공하거나, 서버 로부터 수신된 정보를 이용하여 수술로봇을 제어한다. 일 실시 예에서, 의료영상 촬영장비에서 사용될 수 있는 수단은 제한되지 않으며, 예를 들어 CT, X-Ray, PET, MRI 등 다른 다양한 의료영상 획득수단이 사용될 수 있다. 이하에서는, 설명의 편의를 위하여 각 단계들이 \"컴퓨터\"에 의하여 수행되는 것으로 서술하나, 각 단계의 수행 주체는 특정 장치에 제한되지 않고, 그 전부 또는 일부가 서버 또는 제어부에서 수행될 수 있다. 일 실시 예에서, 의료영상 촬영장비에서 촬영된 수술 영상은 다양한 기준으로 분할될 수 있다. 일 예로, 수 술 영상은 영상에 포함된 객체의 종류를 기초로 하여 분할될 수 있다. 객체의 종류를 기초로 하는 분할방법은 컴퓨터가 각 객체를 인식하는 단계를 필요로 한다. 수술 영상에서 인식되는 객체는 크게 인체, 외부에서 유입된 객체 및 자체적으로 생성된 객체를 포함한다. 인체 는 수술에 선행되는 의료영상 촬영(예를 들어, CT)에 의하여 촬영되는 신체부위와 촬영되지 않는 신체부위를 포 함한다. 예를 들어, 의료영상 촬영에 의하여 촬영되는 신체부위는 장기, 혈관, 뼈, 힘줄 등을 포함하며, 이러한 신체부 위는 의료영상에 기초하여 생성되는 3D 모델링 영상에 기초하여 인식될 수 있다. 구체적으로, 각 신체부위의 위치와 크기, 모양 등이 의료영상에 기초한 3D 분석방법에 의하여 사전에 인지된다. 컴퓨터는 실시간으로 수술영상에 대응하는 신체부위의 위치를 파악할 수 있는 알고리즘을 정의하고, 이에 기초 하여 별도의 이미지 인식을 수행하지 않아도 수술영상에 포함되는 각 신체부위의 위치, 크기 및 모양 등에 대한정보를 획득할 수 있다. 또한, 의료영상 촬영에 의하여 촬영되지 않는 신체부위는 오멘텀(omentum) 등을 포함하 며, 이는 의료영상에 의하여 촬영되지 않으므로 수술 중에 실시간으로 인식하는 것이 필요하다. 예를 들어, 컴 퓨터는 이미지 인식방법을 통하여 오멘텀의 위치 및 크기를 판단하고, 오멘텀 내부에 혈관이 있는 경우 혈관의 위치 또한 예측할 수 있다. 외부에서 유입된 객체는, 예를 들어 수술도구, 거즈, 클립 등을 포함한다. 이는 기 설정된 형태적 특징을 가지 므로, 컴퓨터가 수술 중에 이미지 분석을 통하여 실시간으로 인식할 수 있다. 내부에서 생성되는 객체는, 예를 들어 신체부위에서 발생하는 출혈 등을 포함한다. 이는 컴퓨터가 수술 중에 이 미지 분석을 통하여 실시간으로 인식할 수 있다. 신체부위에 포함된 장기나 오멘텀의 움직임, 그리고 객체가 내부에서 생성되는 원인은 모두 외부에서 유입된 객 체의 움직임에 기인한다. 따라서, 수술 영상은 각 객체를 인식하는 것에 더하여, 각 객체의 움직임에 기초하여 여러 수술 단계(phase)로 분할될 수 있다. 일 실시 예에서, 수술 영상은 외부에서 유입된 객체의 움직임, 즉 액션에 기초하여 분할될 수 있다. 컴퓨터는 수술영상에서 인식된 각 객체의 종류를 판단하고, 각 객체의 종류에 따라 사전에 정의된 특정한 동작, 일련의 동작, 동작에 따라 발생하는 상황이나 결과 등에 기초하여, 각 객체의 움직임, 즉 액션을 인식할 수 있 다. 컴퓨터는 각 액션의 종류를 인식하고, 나아가 각 액션의 원인 또한 인식할 수 있다. 컴퓨터는 인식되는 액션에 기초하여 수술영상을 분할할 수 있고, 단계적 분할을 통해 각각의 세부수술동작부터 전체 수술의 종류까지 인식 할 수 있다. 예를 들면, 컴퓨터는 컨볼루션신경망네트워크(Convolutional Neural Network) 방식의 기계학습을 수행하는 수술단계학습모델을 기초로 촬영된 수술영상에서 특징정보를 추출하고, 특징정보를 기초로 수술단계별 로 영상을 분할하거나 현재 어떤 수술단계에 위치하는지 인식할 수 있다. 나아가, 컴퓨터는 액션에 대한 판단으로부터 수술영상에 대응하는, 기 정의된 수술의 종류를 판단할 수 있다. 수술의 종류를 판단하는 경우, 전체 수술 프로세스에 대한 정보를 획득할 수 있다. 동일한 종류의 수술에 대하 여 복수 개의 수술 프로세스가 존재하는 경우, 의사의 선택에 따라서, 또는 특정 시점까지 인식된 액션들에 기 초하여 하나의 수술 프로세스를 선택할 수 있다. 컴퓨터는 획득된 수술 프로세스에 기초하여 수술단계를 인식 및 예측할 수 있다. 예를 들어, 일련의 수술 프로 세스 중 특정 단계가 인식되는 경우, 이에 후속되는 단계들을 예측하거나 가능한 단계들의 후보를 추려낼 수 있 다. 따라서, 오멘텀 등에 의하여 발생하는 수술영상 인식의 오류 율을 크게 낮출 수 있다. 또한, 수술영상이 예 측 가능한 수술단계로부터 소정의 오차범위 이상 크게 벗어나는 경우, 수술오류(surgical error)상황이 발생한 것으로 인식할 수도 있다. 예를 들면, 정해진 수술 프로세스를 벗어나는 수술단계 스위칭이 빈번히 일어난다면 수술 오류 상황이 발생한 것으로 인식할 수 있다. 또한 컴퓨터는 수술단계에 대한 영상 인식에 기반하여, 각 수술단계에 대응하는 주요혈관들 및 혈액 흐름에 따 라 주요혈관에 분기된 혈관들에 대한 네비게이션 정보를 추출하여 사용자에게 제공함으로써 효과적인 수술이 되 도록 보조할 수 있다. 또한, 컴퓨터는 수술단계에 대한 영상 인식에 기반하여, 수술오류로 인한 출혈이 발생하였는지 판단할 수 있다. 구체적으로, 컴퓨터는 각각의 출혈의 위치, 시간, 규모를 판단을 할 수 있다. 또한, 출혈로 인해 수술이 중단되 어야 하는지 여부를 판단할 수 있다. 따라서, 일 실시예에 따라 컴퓨터는 오류 상황 및 출혈 상황에 대한 데이 터를 수술결과 리포트로 제공하고, 수술과정에서 불필요한 동작이나 실수를 배제하고, 수술 과정을 효율화하는 데 이용될 수 있다. 일 실시예에 다라 수술 후 수술과정 분석방법을 제공하기 위해, 컴퓨터에서 수행되는 연산은, 촬영된 수술영상 에서, 수술단계학습모델을 이용하여 개별 수술단계를 인식하는 연산; 상기 인식된 수술단계별로 스위칭 횟수 및 소요시간을 산출하는 연산; 상기 인식된 수술단계별로 출혈이벤트의 발생여부를 판단하는 연산; 및 상기 스위칭 횟수, 소요시간 및 출혈이벤트를 기초로 수술단계별로 수술결과를 분석할 수 있는 사용자인터페이스를 제공하는 연산을 포함할 수 있다. 또한, 스위칭 횟수를 산출하는 연산은, 상기 인식된 수술 단계가 이어지지 못하고 단절된 횟수를 카운팅 하는 연산을 포함할 수 있다. 또한, 출혈 이벤트의 발생여부를 판단하는 연산은, 산출된 출혈량을 기초로 수술을 중지할 필요가 있는 출혈인 지 여부를 판단하고, 수술을 중지할 필요가 없었던 경우는 제1 출혈이벤트로 인식하고, 수술을 중지할 필요가 있었던 경우는 제2 출혈이벤트로 인식하는 연산을 포함할 수 있다. 이하에서는 도면을 참조하여 수술 후 수술과정 분석 방법에 대하여 보다 상세하게 설명한다. 도 2은 일 실시예에 따른 수술 후 수술과정 분석 방법을 설명하기 위한 순서도이다. 도 2에 도시된 각 단계들은 도 1에 도시된 서버 또는 제어부에서 시계열적으로 수행된다. 이하에서는, 설명의 편의를 위하여 각 단계들이 \"컴퓨터\"에 의하여 수행되는 것으로 서술하나, 각 단계의 수행주체는 특정 장치에 제한되지 않고, 그 전부 또는 일부가 서버 또는 제어부에서 수행될 수 있다. 단계 S200에서, 일 실시예에 따른 컴퓨터는, 촬영된 전체 수술영상에서, 수술단계학습모델을 이용하여 개별 수 술단계를 인식하고 각각의 수술단계에 해당하는 시간영역을 분리한다. 예를 들면, 수술데이터를 이용하여 상기 대상체의 수술에 필요한 적어도 하나 이상의 단계를 레이블로 정의하고, 정의된 레이블 별로 학습영상을 입력하여 CNN(Convolutional neural network)을 이용한 딥러닝 기반 의 학습을 수행하고, 학습된 수술단계학습모델에서 수술영상에서 특징 정보를 추출하고, 추출된 특징 정보를 기 초로 수술단계를 인식할 수 있다. 예를 들면, 도 3은 일 실시예에 따른 수술단계학습모델을 설명하기 위한 순서도이다. 도 3을 참조하면, 단계 S300에서 컴퓨터는 수술 종류를 선정한다. 수술 종류는 입력된 영상에서 객체 또는 대상 체를 인식하여 자동으로 선정될 수도 있으며 사용자가 직접 입력할 수도 있다. 다음으로 단계 S310에서 컴퓨터는 수술데이터를 이용하여 수술을 단계별 레이블로 정의한다. 각각의 수술 단계(phase)는 카메라의 움직임, 롯봇암 등의 장비 들의 움직임 및 장기들을 영상들의 인식함으로 써 자동으로 분할될 수도 있으며, 사용자가 정형화된 수술 프로세스에 맞는 영상을 학습영상으로 분류하여 미리 학습시킬 수도 있다. 예를 들면, 도 4를 참조하면, 위암을 수술하는 경우, 도 4의 표에 도시된 것과 같이 수술단계를 약 21개로 정의할 수 있다. 다음으로 단계 S320에서 컴퓨터는 정의된 레이블에 해당하는 학습영상을 선정한다. 학습영상은 컴퓨터가 입력된 수술영상을 자동으로 분할하여 선정할 수도 있으며, 사용자가 미리 실제의 수술데이터를 기반으로 학습영상을 선정하여 입력할 수도 있다. 다음으로 단계 S330에서 컴퓨터는 선정된 학습영상들을 기초로 컨볼루션 신경망 네트워크를 이용한 기계학습을 수행할 수 있다. 예를 들면, 이렇게 정의된 수술단계 각각의 수술 영상의 프레임을 Low-Fast-Net 모델을 이용하 여 학습한 경우 정확도 높은 수술단계학습모델을 훈련시킬 수 있다. 이와 같이, 훈련된 수술단계학습모델은 수술 후에 분석될 수술영상에서 수술단계를 보다 정확하게 인식하는데 활용될 수 있다. 예를 들면, 촬영된 전체 수술영상에서, 수술단계학습모델을 이용하여 개별 수술단계를 인식하고 각각의 수술단 계에 해당하는 시간영역을 분리하는 방법으로 촬영된 전체 영상에서 각각의 수술단계를 분할 수 있다. 다시 도2의 단계 S210에서, 일 실시예에 따른 컴퓨터는 인식된 수술단계별로 스위칭 횟수 및 소요시간을 산출한 다. 예를 들면, 위암 수술을 하기 위해 21단계의 수술단계가 정의된 경우 각 단계는 수선대로 진행되는 것이 가장 이상적이다. 그런데, 이러한 수술단계가 이어지지 못하고 단절되는 것은 수술 중에 실수나 오류가 발생한 것으 로 추측할 수 있다. 따라서, 정해진 수술 프로세스를 벗어나는 수술단계 스위칭이 빈번히 일어나거나 특정 수술 단계가 상대적으로 긴 소요시간을 갖는다면 수술 오류 상황이 발생한 것으로 인식할 수 있다. 예를 들면, 도 5는 일 실시예에 따른 수술단계별 스위칭 횟수 및 소요시간을 워크플로우로 나타내는 일 예 를 도시한다. 도 5를 참조하면, 수술단계 5(예컨대, 위암 수술에서 partial omentectomy를 진행해야 하는 단계)에서 단계가 연속되지 못하고 다른 단계로 넘어가기 위해 최소 6번의 스위칭이 발생한 것을 알 수 있다. 위암수술에서 수술단계 5의 경우 일반적으로 harmonic이라는 커팅기계가 사용되는 단계인데 순간적으로 커팅기 계가 화면에서 인식되지 않는다거나 화면이 다른 장비로 이동한다는 등의 이벤트가 발생하였기 때문에 스위칭이 발생한 것으로 추측할 수 있다. 따라서 수술단계 5에서 출혈 등의 수술 오류가 발생하였음을 예측할 수 있으며, 컴퓨터는 이를 수술과정 분석 결과에 포함시켜 사용자에게 제공할 수 있다. 다시 도2를 참조하면, 단계 S220에서, 일 실시예에 따른 컴퓨터는 인식된 수술 단계별로 출혈이벤트 발생 여부 를 판단한다. 일 실시예에 따라 컴퓨터는 각각의 출혈의 위치, 시간, 규모를 판단을 할 수 있다. 또한, 출혈로 인해 수술에 간섭이 있었는지 여부를 판단할 수 있다. 예를 들면, 도 6은 일 실시예에 따른 수술단계별 출혈 평가 방법을 설명하기 위한 순서도이다. 도 6을 참조하면, 컴퓨터는 딥러닝 기반의 학습을 기초로 단계 S100에서 촬영된 전체 수술영상에서 프레임 단위 로 내 출혈 영역이 존재하는지 여부를 인식할 수 있다(S600). 일 실시예로, 컴퓨터는 단계 S600에서 획득된 전체수술영상의 각프레임이 출혈 영역을 포함하고 있는 출혈영상 인지 여부를 인식(즉, 수술영상 내 출혈 영역이 존재하는지 여부를 인식)하기 위해서 미리 학습된 학습 모델을 이용할 수 있다. 이때, 미리 학습된 학습 모델을 이용함에 있어서, 컴퓨터는 먼저 수술영상 데이터셋을 기초로 딥러닝을 이용하 여 수술영상 내 출혈 영역의 유무를 인식하는 학습을 수행할 수 있다. 수술영상 데이터셋은 수술영상에 대해 다 양한 학습 방법을 통해 레이블링을 수행한 학습 데이터셋일 수 있다. 예를 들어, 수술영상 데이터셋은 지도학습, 비지도학습, 강화학습 등의 기계학습 방법을 사용하여 학습된 데이터일 수 있다. 따라서, 컴퓨터는 학습 데이터로서 수술영상 데이터셋을 획득하고, 이를 이용하여 수술영상에서 출혈이 발생한 부분(즉, 출혈 영 역)의 유무를 인식하는 학습을 수행하여 학습 모델(예컨대, 출혈유무 인식모델)을 미리 구축하여 둘 수 있다. 이때, 컴퓨터는 수술영상 데이터셋을 기초로 학습된 학습 모델을 미리 구축하여 저장하여 둘 수도 있고, 또는 다른 장치에서 구축된 학습 모델을 이용할 수도 있다. 이후, 컴퓨터는 새로운 수술영상(즉, 단계 S600에서의 수술영상)을 획득하면, 수술영상 데이터셋을 기초로 학습 된 학습 모델(예컨대, 출혈유무 인식모델)을 이용하여 새로운 수술영상 내 출혈 영역이 존재하는지 여부를 인식 할 수 있다. 즉, 컴퓨터는 딥러닝 기반의 미리 구축된 학습 모델(예컨대, 출혈유무 인식모델)을 통해 새로 획득 된 수술영상이 출혈 영역을 포함하고 있는 출혈영상인지 비출혈영상인지 여부를 신속하고 효과적으로 판단할 수 있다. 컴퓨터는 단계 S610의 수술영상 인식 결과(즉, 수술영상이 출혈영상인지 비 출혈영상인지 인식 결과)를 기반으 로, 수술영상으로부터 출혈 영역의 위치를 추정할 수 있다(S620). 일 실시 예로, 컴퓨터는 딥러닝 기반의 학습을 기초로 수술영상 내 출혈 영역이 존재하는 출혈영상인 것으로 인 식한 경우, 수술영상 내 출혈 영역을 특정하고, 특정된 출혈 영역의 위치를 추정할 수 있다. 예를 들어, 컴퓨터 는 딥러닝 기반의 학습을 통해 수술영상으로부터 특징(feature) 정보를 추출하고, 추출된 특징 정보를 기초로 수술영상 내 출혈 영역을 인식하여 특정할 수 있다. 이때, 특징 정보는 출혈의 특징을 나타내는 정보로, 출혈을 특정할 수 있는 색상, 형태, 질감 등의 텍스처(texture) 정보를 이용할 수 있다. 컴퓨터는 단계 S620에서 추정된 출혈 영역의 위치를 기초로, 출혈 영역에서의 출혈량을 산출할 수 있다(S630). 일 실시 예로, 컴퓨터는 수술영상 내 출혈 영역의 픽셀 정보를 이용하여 출혈량을 산출할 수 있다. 또는, 수술 영상이 스테레오스코픽 영상인 경우, 컴퓨터는 수술영상의 깊이맵(depth map)을 기초로 수술영상 내 출혈 영역 의 깊이 정보를 획득하고, 이를 기초로 출혈 영역에 대응하는 부피를 추정하여 출혈량을 산출할 수 있다. 또는, 수술영상 내 거즈가 포함된 경우, 컴퓨터는 거즈 정보를 이용하여 출혈 영역에서의 출혈량을 산출할 수 있다. 또한, 컴퓨터는 수술영상 내 출혈 영역의 위치 및 산출된 출혈량을 기초로 수술에 간섭(intervention)이 있는 출혈인지 여부를 판단하고, 수술에 간섭이 없었던 경우는 제1 출혈이벤트로 인식하고, 수술에 간섭이 있었던 경 우는 제2 출혈이벤트로 인식할 수 있다. 예를 들면, 제1 출혈이벤트는 긁힘 등과 같이 수술에 영향이 없는 출혈 을 의미하고, 제2 출혈이벤트는 동맥에 손상이 가는 등의 수술을 중지해야 하는 출혈을 의미할 수 있다. 또한, 컴퓨터는 피가 고여있는 조직 (bleeding collected)이 인식되거나 피가 묻어있는 조직 (bleeding stainedtissue)이 발견되는 경우를 제2 출혈 이벤트로 인식할 수 있다. 또는 피가 고여 있는 조직이 인식된 경우를 제3 출혈 이벤트로 정의하고 피가 묻어 있는 조직이 인식된 경우를 제4 출혈 이벤트로 정의할 수도 있을 것이다. 상술한 바에 따라, 수술영상은 수술단계 인식모델에 입력됨에 따라 수술단계별로 분할이 되고, 수술영상을 출혈 인식모델에 입력함에 따라 수술영상 내에 제1 출혈이벤트와 제 2출혈이벤트가 존재하는 프레임과 프레임 내의 영역을 추출하게 된다. 그런 후에 수술단계 분할 결과를 기반으로 스위칭 횟수와 소요시간을 산출하고, 각 수술 단계 분할결과와 출혈인식결과를 연결하여, 각 수술단계 내의 출혈 이벤트 발생 횟수에 대해 산출이 이루어 진 다. 즉, 상술한 수술단계인식과 출혈인식이 병렬적으로 이루어 질 수 있다. 한편, 상기 제1 출혈이벤트 또는 제2 출현이벤트 인지 여부는, 출혈이 발생한 시점에서의 상기 스위칭 횟수 및 상기 수술단계의 소요시간을 기초로도 판단할 수 있다. 도 7 은 일 실시예에 따른 수술단계별 출혈이벤트를 표시하는 일 예를 도시한다. 도 7을 참조하면, 출혈이 발생하지 않은 단계, 제1 출혈이벤트가 발생한 단계 및 제2 출혈 이벤트 가 발생한 단계가 시인 성 높은 형태로 도식화되어 표시 수 있다. 물론 반드시 이러한 구성에 한정되는 것 은 아니며 선형 그래프, 막대 그래프 또는 원형 그래프 등 다양한 형태로 수술단계별 출혈이벤트 발생 여부 및 지속 시간이 도시될 수 있다. 예를 들면, 도 7에서는 수술단계 5 및 수술단계 15에서 제2 출혈이벤트가 가장 길게 발생한 것을 판단할 수 있 다. 다시 도2를 참조하면, 단계 S230에서, 일 실시예에 따른 컴퓨터는 스위칭 횟수, 소요시간 및 출혈이벤트를 기초 로 수술단계별로 수술결과를 분석할 수 있는 사용자인터페이스를 제공한다. 따라서, 사용자는 수술 단계별로 오류 상황 및 출혈 상황에 대한 데이터를 수술결과 리포트로 제공받고, 수술과 정에서 불필요한 동작이나 실수를 배제하고, 수술 과정을 효율화하는 데 이용할 수 있다. 도 8은 일 실시예에 따른 수술과정 분석 결과를 도시하는 일 예이다. 도 8을 참조하면, 일 실시예에 따른 사용자 인터페이스는 동영상 재생영역, 전체 수술과정에 대한 요 약을 표시하는 영역, 동영상이 재생되면 해당 부분에 대한 분석 데이터를 노출하는 영역 및 동영상 관련 부가기능을 제공하는 영역을 포함할 수 있다. 우선, 동영상 재생영역에는 선택된 수술단계에 대한 영상이 0.5~7배속으로 재생될 수 있다. 또한 수술 기 구 및 출혈 지점을 인식하여 제1 출혈이벤트 또는 제2 출혈이벤트가 발생한 것인지를 표시해 줄 수 있다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전체 수술과정에 대한 요약을 표시하는 영역에서는 전체 수술시간에서 각 수술단계에 대한 부분을 소정 색 상으로 표시할 수 있다. 예를 들면 사용자가 특정 수술단계를 선택하면, 해당 단계에서의 수술과정만을 살펴볼 수 있다. 또한 전체 수술 시간에서 출혈 지점이 표시될 수 있으며, 사용자 선택에 의해 해당 부분의 동영상이 재생되도록 할 수 있다. 동영상이 재생되면 해당 부분에 대한 분석 데이터를 노출하는 영역에서는 사용자에게 스위칭 횟수, 소요시 간 및 출혈이벤트와 관련된 그래프 및 각각의 분석 결과가 도시될 수 있다. 동영상 관련 부가기능을 제공하는 영역에서는 사용자가 원하는 부분만 저장하는 비디오 클립 기능이 제공 될 수 있다. 추가로, 본 발명의 일 실시예에 따라 수술과정 분석 결과는 리포트 형태로 사용자에게 제공할 수 있다. 예를 들면, 도 5와 도7에 도시된 차트와 같이 사용자가 사용자 인터페이스를 통해 확인 가능한 분석 결과 를 자동으로 분석하여 리포트 형태로 제공할 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다."}
{"patent_id": "10-2022-0031857", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2022-0031857", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른 로봇수술 시스템을 도시한 도면이다. 도 2은 일 실시예에 따른 수술과정 분석방법을 설명하기 위한 순서도이다. 도 3은 일 실시예에 따른 수술단계학습모델을 설명하기 위한 순서도이다. 도 4는 일 실시예에 따른 분할된 수술단계의 일 예를 도시한다. 도 5는 일 실시예에 따른 수술단계별 스위칭 횟수 및 소요시간을 나타내는 일 예를 도시한다 도 6은 일 실시예에 따른 수술단계별 출혈 평가 방법을 설명하기 위한 순서도이다. 도 7 은 일 실시예에 따른 수술단계별 출혈이벤트를 표시하는 일 예를 도시한다.도 8은 일 실시예에 따른 수술과정 분석 결과를 도시하는 일 예이다."}
